<article class="ltx_document ltx_authors_1line">
 <h1 class="ltx_title ltx_title_document">
  NoteChat: A Dataset of Synthetic Patient-Physician Conversations Conditioned on Clinical Notes
 </h1>
 <div class="ltx_authors">
  <span class="ltx_creator ltx_role_author">
   <span class="ltx_personname">
    Junda Wang
    <sup class="ltx_sup" id="id14.14.id1">
     1
    </sup>
    , Zonghai Yao
    <span class="ltx_note ltx_role_footnotemark" id="footnotex1">
     <sup class="ltx_note_mark">
      1
     </sup>
     <span class="ltx_note_outer">
      <span class="ltx_note_content">
       <sup class="ltx_note_mark">
        1
       </sup>
       <span class="ltx_note_type">
        footnotemark:
       </span>
       <span class="ltx_tag ltx_tag_note">
        1
       </span>
      </span>
     </span>
    </span>
    <sup class="ltx_sup" id="id15.15.id2">
     1
    </sup>
    ,
    <span class="ltx_text ltx_font_bold" id="id13.13.11">
     Zhichao Yang
     <sup class="ltx_sup" id="id13.13.11.1">
      <span class="ltx_text ltx_font_medium" id="id13.13.11.1.1">
       1
      </span>
     </sup>
     , Huixue Zhou
     <sup class="ltx_sup" id="id13.13.11.2">
      <span class="ltx_text ltx_font_medium" id="id13.13.11.2.1">
       2
      </span>
     </sup>
     , Rumeng Li
     <sup class="ltx_sup" id="id13.13.11.3">
      <span class="ltx_text ltx_font_medium" id="id13.13.11.3.1">
       1
      </span>
     </sup>
     <br class="ltx_break"/>
     Xun Wang
     <sup class="ltx_sup" id="id13.13.11.4">
      <span class="ltx_text ltx_font_medium" id="id13.13.11.4.1">
       3
      </span>
     </sup>
     , Yucheng Xu
     <sup class="ltx_sup" id="id13.13.11.5">
      <span class="ltx_text ltx_font_medium" id="id13.13.11.5.1">
       4
      </span>
     </sup>
     , Hong Yu
     <sup class="ltx_sup" id="id13.13.11.6">
      <span class="ltx_text ltx_font_medium ltx_font_italic" id="id13.13.11.6.1">
       1,5
      </span>
     </sup>
     <br class="ltx_break"/>
     University of Massachusetts, Amherst
     <sup class="ltx_sup" id="id13.13.11.7">
      <span class="ltx_text ltx_font_medium" id="id13.13.11.7.1">
       1
      </span>
     </sup>
     , University of Minnesota
     <sup class="ltx_sup" id="id13.13.11.8">
      <span class="ltx_text ltx_font_medium" id="id13.13.11.8.1">
       2
      </span>
     </sup>
     , Microsoft
     <sup class="ltx_sup" id="id13.13.11.9">
      <span class="ltx_text ltx_font_medium" id="id13.13.11.9.1">
       3
      </span>
     </sup>
     <br class="ltx_break"/>
     University of Edinburgh
     <sup class="ltx_sup" id="id13.13.11.10">
      <span class="ltx_text ltx_font_medium" id="id13.13.11.10.1">
       4
      </span>
     </sup>
     , University of Massachusetts, Lowell
     <sup class="ltx_sup" id="id13.13.11.11">
      <span class="ltx_text ltx_font_medium" id="id13.13.11.11.1">
       5
      </span>
     </sup>
     <br class="ltx_break"/>
    </span>
    <span class="ltx_text ltx_font_typewriter" id="id16.16.id3">
     {jundawang, zonghaiyao, zhichaoyang, hongyu}@umass.edu
     <br class="ltx_break"/>
    </span>
   </span>
   <span class="ltx_author_notes">
    * indicates equal contribution
   </span>
  </span>
 </div>
 <div class="ltx_abstract">
  <h6 class="ltx_title ltx_title_abstract">
   Abstract
  </h6>
  <p class="ltx_p" id="id17.id1">
   We introduce NoteChat, a novel cooperative multi-agent framework leveraging Large Language Models (LLMs) to generate patient-physician dialogues. NoteChat embodies the principle that an ensemble of role-specific LLMs, through structured role-play and strategic prompting, can perform their assigned roles more effectively. The synergy among these role-playing LLMs results in a cohesive and efficient dialogue generation. Evaluation on MTS-dialogue
   <cite class="ltx_cite ltx_citemacro_cite">
    Abacha et al. (
    <a class="ltx_ref" href="#bib.bib1" title="">
     2023
    </a>
    ); Ben Abacha et al. (
    <a class="ltx_ref" href="#bib.bib8" title="">
     2023
    </a>
    )
   </cite>
   , a benchmark dataset for patient-physician dialogues-note pairs, shows that models trained with the augmented synthetic patient-physician dialogues by NoteChat
   <span class="ltx_note ltx_role_footnote" id="footnote1">
    <sup class="ltx_note_mark">
     1
    </sup>
    <span class="ltx_note_outer">
     <span class="ltx_note_content">
      <sup class="ltx_note_mark">
       1
      </sup>
      <span class="ltx_tag ltx_tag_note">
       1
      </span>
      Our synthetic patient-physician dialogue data is publicly available at
      <a class="ltx_ref ltx_url ltx_font_sansserif" href="https://huggingface.co/datasets/akemiH/NoteChat" target="_blank" title="">
       https://huggingface.co/datasets/akemiH/NoteChat
      </a>
      .
     </span>
    </span>
   </span>
   outperforms other state-of-the-art models for generating clinical notes. Our comprehensive automatic and human evaluation demonstrates that NoteChat substantially surpasses state-of-the-art models like ChatGPT and GPT-4 up to 22.78% by domain experts in generating superior synthetic patient-physician dialogues based on clinical notes
   <span class="ltx_note ltx_role_footnote" id="footnote2">
    <sup class="ltx_note_mark">
     2
    </sup>
    <span class="ltx_note_outer">
     <span class="ltx_note_content">
      <sup class="ltx_note_mark">
       2
      </sup>
      <span class="ltx_tag ltx_tag_note">
       2
      </span>
      Our codes and prompts are publicly available at
      <a class="ltx_ref ltx_url ltx_font_sansserif" href="https://github.com/believewhat/Dr.NoteAid" target="_blank" title="">
       https://github.com/believewhat/Dr.NoteAid
      </a>
      .
     </span>
    </span>
   </span>
   . NoteChat has the potential to engage patients directly and help clinical documentation, a leading cause of physician burnout
   <cite class="ltx_cite ltx_citemacro_cite">
    Budd (
    <a class="ltx_ref" href="#bib.bib10" title="">
     2023
    </a>
    )
   </cite>
   .
  </p>
 </div>
 <section class="ltx_section" id="S1">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    1
   </span>
   Introduction
  </h2>
  <div class="ltx_para" id="S1.p1">
   <p class="ltx_p" id="S1.p1.1">
    Clinical dialogue is an essential part of clinical workflow. Clinical documentation is a two-step process. It first engages patients through conversation to collect patient-specific information such as demographic information, family history of diseases, and signs and symptoms and then generates electronic health records (EHRs) from the dialogues.
Currently clinical documentation is mainly done by physicians at both steps, a labor intensive process that contributes to physician burnout, defined as a state of emotional, physical, and mental exhaustion caused by prolonged stress in the workplace
    <cite class="ltx_cite ltx_citemacro_cite">
     Ortega et al. (
     <a class="ltx_ref" href="#bib.bib40" title="">
      2023
     </a>
     ); Budd (
     <a class="ltx_ref" href="#bib.bib10" title="">
      2023
     </a>
     )
    </cite>
    .
In this paper, we introduce NoteChat, a novel cooperative multi-agent framework leveraging Large Language Models (LLMs) to generate patient-physician conversations conditioned on clinical notes. NoteChat has the potential to help clinical documentation at both steps.
   </p>
  </div>
  <figure class="ltx_table" id="S1.T1">
   <div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S1.T1.1" style="width:269.1pt;height:148.5pt;vertical-align:-0.0pt;">
    <span class="ltx_transformed_inner" style="transform:translate(-44.9pt,24.8pt) scale(0.75,0.75) ;">
     <table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S1.T1.1.1">
      <tbody class="ltx_tbody">
       <tr class="ltx_tr" id="S1.T1.1.1.1.1">
        <th class="ltx_td ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S1.T1.1.1.1.1.1">
        </th>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.1.1.1.1.2">
         <span class="ltx_text ltx_font_bold" id="S1.T1.1.1.1.1.2.1">
          Ours-PMC
         </span>
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.1.1.1.1.3">
         ChatDoctor
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S1.T1.1.1.1.1.4">
         DoctorGLM
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.1.1.1.1.5">
         <span class="ltx_text ltx_font_bold" id="S1.T1.1.1.1.1.5.1">
          Ours-MTS
         </span>
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.1.1.1.1.6">
         MTS-Dialog
        </td>
       </tr>
       <tr class="ltx_tr" id="S1.T1.1.1.2.2">
        <th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S1.T1.1.1.2.2.1">
         #dial.
        </th>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.1.1.2.2.2">
         30k
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.1.1.2.2.3">
         112k
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S1.T1.1.1.2.2.4">
         3.4M
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.1.1.2.2.5">
         20
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.1.1.2.2.6">
         87
        </td>
       </tr>
       <tr class="ltx_tr" id="S1.T1.1.1.3.3">
        <th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S1.T1.1.1.3.3.1">
         #utt.
        </th>
        <td class="ltx_td ltx_align_center" id="S1.T1.1.1.3.3.2">
         633k
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.1.1.3.3.3">
         224k
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r" id="S1.T1.1.1.3.3.4">
         11.2M
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.1.1.3.3.5">
         1.25k
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.1.1.3.3.6">
         4.79k
        </td>
       </tr>
       <tr class="ltx_tr" id="S1.T1.1.1.4.4">
        <th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S1.T1.1.1.4.4.1">
         Chat
        </th>
        <td class="ltx_td ltx_align_center" id="S1.T1.1.1.4.4.2">
         ✓
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.1.1.4.4.3">
         ✗
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r" id="S1.T1.1.1.4.4.4">
         ✗
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.1.1.4.4.5">
         ✓
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.1.1.4.4.6">
         ✓
        </td>
       </tr>
       <tr class="ltx_tr" id="S1.T1.1.1.5.5">
        <th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S1.T1.1.1.5.5.1">
         Note
        </th>
        <td class="ltx_td ltx_align_center" id="S1.T1.1.1.5.5.2">
         ✓
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.1.1.5.5.3">
         ✗
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r" id="S1.T1.1.1.5.5.4">
         ✗
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.1.1.5.5.5">
         ✓
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.1.1.5.5.6">
         ✓
        </td>
       </tr>
       <tr class="ltx_tr" id="S1.T1.1.1.6.6">
        <th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S1.T1.1.1.6.6.1">
         Syn.
        </th>
        <td class="ltx_td ltx_align_center" id="S1.T1.1.1.6.6.2">
         AI
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.1.1.6.6.3">
         ✗
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r" id="S1.T1.1.1.6.6.4">
         ✗
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.1.1.6.6.5">
         AI
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.1.1.6.6.6">
         Human
        </td>
       </tr>
       <tr class="ltx_tr" id="S1.T1.1.1.7.7">
        <th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S1.T1.1.1.7.7.1">
         Lang
        </th>
        <td class="ltx_td ltx_align_center" id="S1.T1.1.1.7.7.2">
         EN
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.1.1.7.7.3">
         EN
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r" id="S1.T1.1.1.7.7.4">
         CN
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.1.1.7.7.5">
         EN
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.1.1.7.7.6">
         EN
        </td>
       </tr>
       <tr class="ltx_tr" id="S1.T1.1.1.8.8">
        <th class="ltx_td ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S1.T1.1.1.8.8.1">
        </th>
        <td class="ltx_td ltx_align_center ltx_border_t" colspan="5" id="S1.T1.1.1.8.8.2">
         # of utterances in a dialogue
        </td>
       </tr>
       <tr class="ltx_tr" id="S1.T1.1.1.9.9">
        <th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S1.T1.1.1.9.9.1">
         Avg
        </th>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.1.1.9.9.2">
         21.1
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.1.1.9.9.3">
         2
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S1.T1.1.1.9.9.4">
         3.3
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.1.1.9.9.5">
         62.5
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.1.1.9.9.6">
         55.1
        </td>
       </tr>
       <tr class="ltx_tr" id="S1.T1.1.1.10.10">
        <th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S1.T1.1.1.10.10.1">
         Max
        </th>
        <td class="ltx_td ltx_align_center" id="S1.T1.1.1.10.10.2">
         61
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.1.1.10.10.3">
         2
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r" id="S1.T1.1.1.10.10.4">
         198
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.1.1.10.10.5">
         112
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.1.1.10.10.6">
         131
        </td>
       </tr>
       <tr class="ltx_tr" id="S1.T1.1.1.11.11">
        <th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r" id="S1.T1.1.1.11.11.1">
         Min
        </th>
        <td class="ltx_td ltx_align_center ltx_border_b" id="S1.T1.1.1.11.11.2">
         3
        </td>
        <td class="ltx_td ltx_align_center ltx_border_b" id="S1.T1.1.1.11.11.3">
         2
        </td>
        <td class="ltx_td ltx_align_center ltx_border_b ltx_border_r" id="S1.T1.1.1.11.11.4">
         2
        </td>
        <td class="ltx_td ltx_align_center ltx_border_b" id="S1.T1.1.1.11.11.5">
         22
        </td>
        <td class="ltx_td ltx_align_center ltx_border_b" id="S1.T1.1.1.11.11.6">
         7
        </td>
       </tr>
      </tbody>
     </table>
    </span>
   </div>
   <figcaption class="ltx_caption ltx_centering">
    <span class="ltx_tag ltx_tag_table">
     Table 1:
    </span>
    Statistics of our NoteChat dataset and related publicly available resources: PMC-based and MTS-based datasets (OursP and OursM, respectively) and muti-round question answering (Chat).
We use "Note" to determine whether we can generate a full clinical note from the data.
We use "Syn" to determine whether the data is generated (by annotators or AI).
   </figcaption>
  </figure>
  <figure class="ltx_figure" id="S1.F1">
   <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="207" id="S1.F1.g1" src="/html/2310.15959/assets/x1.png" width="368"/>
   <figcaption class="ltx_caption ltx_centering">
    <span class="ltx_tag ltx_tag_figure">
     Figure 1:
    </span>
    An illustration of NoteChat.
    <span class="ltx_text" id="S1.F1.4.1" style="color:#FFAD7A;">
     Apricot
    </span>
    indicates that our pipeline can generate smooth patient-physician conversations.
    <span class="ltx_text" id="S1.F1.5.2" style="color:#00FFFF;">
     Blue
    </span>
    shows the characteristics of information seeking, where physicians can actively ask questions to advance the conversation, thanks to ② Roleplay module. In addition, compared with the corresponding note content, the generated utterances are more colloquial, but the key medical concepts are highly overlapped, which reflects NoteChat’s control over factuality (mainly from ① Planning module).
    <span class="ltx_text" id="S1.F1.6.3" style="color:#FF85FF;">
     Lavender
    </span>
    means that NoteChat can generate reasonable explanations for patients, and a lot of information in the chat is reasonable imagination instead of hallucination.
The two modules of ② Roleplay and ③ Polish can stimulate the imaginative potential of LLMs and reduce unreasonable hallucination through self-examination.
   </figcaption>
  </figure>
  <div class="ltx_para" id="S1.p2">
   <p class="ltx_p" id="S1.p2.1">
    NoteChat leverages LLMs, powerful artificial intelligence (AI) systems extensively trained on a large amount of textual data which represent a significant breakthrough in AI
    <cite class="ltx_cite ltx_citemacro_cite">
     Brown et al. (
     <a class="ltx_ref" href="#bib.bib9" title="">
      2020
     </a>
     ); Longpre et al. (
     <a class="ltx_ref" href="#bib.bib37" title="">
      2023
     </a>
     )
    </cite>
    .
The GPT series by OpenAI
    <cite class="ltx_cite ltx_citemacro_cite">
     OpenAI (
     <a class="ltx_ref" href="#bib.bib39" title="">
      2023
     </a>
     )
    </cite>
    have demonstrated impressive outcomes and hold significant potential in revolutionizing a broad range of sectors, including marketing, education, and customer service. However, recent work
    <cite class="ltx_cite ltx_citemacro_cite">
     Ben Abacha et al. (
     <a class="ltx_ref" href="#bib.bib8" title="">
      2023
     </a>
     )
    </cite>
    found ChatGPT does not perform well enough in generating either patient-physician encounter conversation or its corresponding EHR notes. The exploration of open-source LLMs (e.g., LLaMA2)
    <cite class="ltx_cite ltx_citemacro_cite">
     Touvron et al. (
     <a class="ltx_ref" href="#bib.bib54" title="">
      2023
     </a>
     ); Taori et al. (
     <a class="ltx_ref" href="#bib.bib53" title="">
      2023
     </a>
     ); Chiang et al. (
     <a class="ltx_ref" href="#bib.bib12" title="">
      2023
     </a>
     )
    </cite>
    in the medical field remains relatively untapped
    <cite class="ltx_cite ltx_citemacro_cite">
     Gilson et al. (
     <a class="ltx_ref" href="#bib.bib23" title="">
      2023
     </a>
     )
    </cite>
    , despite their immense potential for transforming healthcare communication and decision-making
    <cite class="ltx_cite ltx_citemacro_cite">
     Abacha and Zweigenbaum (
     <a class="ltx_ref" href="#bib.bib2" title="">
      2015
     </a>
     )
    </cite>
    . We suspect that one main reason is the lack of high-quality medical datasets that meet various needs.
   </p>
  </div>
  <div class="ltx_para" id="S1.p3">
   <p class="ltx_p" id="S1.p3.1">
    Although efforts have been made to create benchmark datasets, the datasets relevant to clinical documentation are small scale
    <cite class="ltx_cite ltx_citemacro_cite">
     Abacha et al. (
     <a class="ltx_ref" href="#bib.bib1" title="">
      2023
     </a>
     ); Ben Abacha et al. (
     <a class="ltx_ref" href="#bib.bib8" title="">
      2023
     </a>
     ); Yim et al. (
     <a class="ltx_ref" href="#bib.bib62" title="">
      2023
     </a>
     )
    </cite>
    .
    <cite class="ltx_cite ltx_citemacro_citet">
     Yunxiang et al. (
     <a class="ltx_ref" href="#bib.bib65" title="">
      2023
     </a>
     )
    </cite>
    collected 100k real-world patient-physician conversations from online medical consultation websites as ChatDoctor dataset.
    <cite class="ltx_cite ltx_citemacro_citet">
     Xiong et al. (
     <a class="ltx_ref" href="#bib.bib58" title="">
      2023
     </a>
     )
    </cite>
    converted the ChatDoctor data into Chinese and additionally added relevant Chinese dialogue
    <cite class="ltx_cite ltx_citemacro_cite">
     Zeng et al. (
     <a class="ltx_ref" href="#bib.bib66" title="">
      2020
     </a>
     )
    </cite>
    and question-answering. However, none of the aforementioned datasets include dialogue-note pairs. Moreover,
as indicated in Table 1, the maximum average number of utterances in the existing datasets
    <cite class="ltx_cite ltx_citemacro_cite">
     Zeng et al. (
     <a class="ltx_ref" href="#bib.bib66" title="">
      2020
     </a>
     )
    </cite>
    is 3.3, which is a typical representation of online medical consultation websites but markedly less than face-to-face communication between patient and physician encounters
    <cite class="ltx_cite ltx_citemacro_cite">
     Drew et al. (
     <a class="ltx_ref" href="#bib.bib16" title="">
      2001
     </a>
     )
    </cite>
    .
   </p>
  </div>
  <div class="ltx_para" id="S1.p4">
   <p class="ltx_p" id="S1.p4.1">
    The primary challenge of creating benchmark datasets in the clinical domain is HIPAA regulation
    <cite class="ltx_cite ltx_citemacro_cite">
     Rindfleisch (
     <a class="ltx_ref" href="#bib.bib47" title="">
      1997
     </a>
     ); Annas (
     <a class="ltx_ref" href="#bib.bib4" title="">
      2003
     </a>
     )
    </cite>
    . This impediment prevents the use of state-of-the-art LLMs, such as GPTs, on real patient data. NoteChat circumvents it by generating high-quality synthetic patient-physician conversations conditioned on clinical notes. This synthetic dialogue data can then be used to help train downstream tasks such as clinical note generation conditioned on patient-physician dialogues. Therefore, NoteChat helps both steps of clinical documentation, this is in contrast to the existing models, which mainly focused on clinical dialogue generation only
    <cite class="ltx_cite ltx_citemacro_cite">
     Yunxiang et al. (
     <a class="ltx_ref" href="#bib.bib65" title="">
      2023
     </a>
     ); Zeng et al. (
     <a class="ltx_ref" href="#bib.bib66" title="">
      2020
     </a>
     )
    </cite>
    .
   </p>
  </div>
  <div class="ltx_para" id="S1.p5">
   <p class="ltx_p" id="S1.p5.1">
    In this study, we introduce NoteChat, which is built upon a novel cooperative multi-agent framework to generate synthetic patient-physician conversations conditioned on clinical documents (e.g., HIPAA-compliant clinical notes
    <span class="ltx_note ltx_role_footnote" id="footnote3">
     <sup class="ltx_note_mark">
      3
     </sup>
     <span class="ltx_note_outer">
      <span class="ltx_note_content">
       <sup class="ltx_note_mark">
        3
       </sup>
       <span class="ltx_tag ltx_tag_note">
        3
       </span>
       <a class="ltx_ref ltx_url ltx_font_sansserif" href="https://github.com/abachaa/MTS-Dialog" target="_blank" title="">
        https://github.com/abachaa/MTS-Dialog
       </a>
      </span>
     </span>
    </span>
    and case reports
    <span class="ltx_note ltx_role_footnote" id="footnote4">
     <sup class="ltx_note_mark">
      4
     </sup>
     <span class="ltx_note_outer">
      <span class="ltx_note_content">
       <sup class="ltx_note_mark">
        4
       </sup>
       <span class="ltx_tag ltx_tag_note">
        4
       </span>
       <a class="ltx_ref ltx_url ltx_font_sansserif" href="https://github.com/zhao-zy15/PMC-Patients" target="_blank" title="">
        https://github.com/zhao-zy15/PMC-Patients
       </a>
      </span>
     </span>
    </span>
    ).
NoteChat comprises three modules: Planning, Roleplay, and Polish.
The planning module is responsible for knowledge organization, aiming to decrease hallucination and enhance the consistency of medical logic.
The Roleplay module includes two ChatGPT agents
    <span class="ltx_note ltx_role_footnote" id="footnote5">
     <sup class="ltx_note_mark">
      5
     </sup>
     <span class="ltx_note_outer">
      <span class="ltx_note_content">
       <sup class="ltx_note_mark">
        5
       </sup>
       <span class="ltx_tag ltx_tag_note">
        5
       </span>
       We use OpenAI’s GPT-3.5 model
       <span class="ltx_text ltx_font_typewriter" id="footnote5.1">
        gpt-3.5-turbo-0613
       </span>
       .
      </span>
     </span>
    </span>
    take on the roles of physician and patient, respectively. This setup facilitates the generation of interactive dialogues in a looped format.
The Polish module is then utilized to refine these dialogues, ensuring they are more closely aligned with the expectations and preferences of medical professionals, following the feedback and suggestions obtained from physicians and medical students.
Extensive automatic and human evaluations demonstrate the efficacy of our cooperative multi-agent framework and show that NoteChat holds great promise for promoting high-quality synthetic patient-physician conversations.
   </p>
  </div>
  <div class="ltx_para ltx_noindent" id="S1.p6">
   <p class="ltx_p" id="S1.p6.1">
    <span class="ltx_text ltx_font_bold" id="S1.p6.1.1">
     In summary, our contributions are as follows:
    </span>
   </p>
   <ul class="ltx_itemize" id="S1.I1">
    <li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
     <span class="ltx_tag ltx_tag_item">
      •
     </span>
     <div class="ltx_para" id="S1.I1.i1.p1">
      <p class="ltx_p" id="S1.I1.i1.p1.1">
       We created a novel multiple roleplay LLMs cooperating framework and successfully deployed the framework for the task of generating patient-physician conversations conditioning on clinical notes.
Although synthetic data generation is an active field in the clinical domain especially to overcome privacy concerns
       <cite class="ltx_cite ltx_citemacro_cite">
        Pereira et al. (
        <a class="ltx_ref" href="#bib.bib42" title="">
         2022
        </a>
        ); Shafquat et al. (
        <a class="ltx_ref" href="#bib.bib48" title="">
         2022
        </a>
        ); Mishra et al. (
        <a class="ltx_ref" href="#bib.bib38" title="">
         2023
        </a>
        )
       </cite>
       , to our knowledge, this is the first work to present an instance of multiple LLMs cooperating
       <cite class="ltx_cite ltx_citemacro_cite">
        Li et al. (
        <a class="ltx_ref" href="#bib.bib32" title="">
         2023a
        </a>
        )
       </cite>
       to complete a patient-physician conversation conditioned on clinical notes.
      </p>
     </div>
    </li>
    <li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
     <span class="ltx_tag ltx_tag_item">
      •
     </span>
     <div class="ltx_para" id="S1.I1.i2.p1">
      <p class="ltx_p" id="S1.I1.i2.p1.1">
       We evaluated the quality of the synthetic patient-physician conversations generated by NoteChat with the state-of-the-art OpenAI’s ChatGPT and GPT-4 using extensive intrinsic and extrinsic evaluation methods. Through comprehensive human evaluations, we demonstrate that NoteChat holds promise to generate high-quality synthetic patient-physician dialogues.
      </p>
     </div>
    </li>
    <li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
     <span class="ltx_tag ltx_tag_item">
      •
     </span>
     <div class="ltx_para" id="S1.I1.i3.p1">
      <p class="ltx_p" id="S1.I1.i3.p1.1">
       In this study, we released the first large and high-quality synthetic dialogue data conditioned on 167k case reports that can be used to train both dialogue systems and EHR note-generation systems using dialogues.
      </p>
     </div>
    </li>
   </ul>
  </div>
 </section>
 <section class="ltx_section" id="S2">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    2
   </span>
   Methods
  </h2>
  <section class="ltx_subsection" id="S2.SS1">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     2.1
    </span>
    Data Resource and Preprocessing
   </h3>
   <section class="ltx_paragraph" id="S2.SS1.SSS0.Px1">
    <h5 class="ltx_title ltx_title_paragraph">
     PMC-Patients
    </h5>
    <div class="ltx_para" id="S2.SS1.SSS0.Px1.p1">
     <p class="ltx_p" id="S2.SS1.SSS0.Px1.p1.1">
      is a comprehensive dataset comprising 167K patient case reports and relations extracted from a diverse range of case reports available in the PubMed Central (PMC) repository
      <cite class="ltx_cite ltx_citemacro_cite">
       Zhao et al. (
       <a class="ltx_ref" href="#bib.bib68" title="">
        2023
       </a>
       )
      </cite>
      .
PMC-Patient dataset encompasses a vast array of case reports, many of which pertain to rare conditions. To maintain the quality of the generated dialogue in our study, we instruct ChatGPT to exclude exceptionally rare cases. Furthermore, we also instruct ChatGPT to omit case reports related to animal diseases, as they typically bear less relevance to our objective of focusing on human clinical dialogues.
     </p>
    </div>
   </section>
   <section class="ltx_paragraph" id="S2.SS1.SSS0.Px2">
    <h5 class="ltx_title ltx_title_paragraph">
     MTS-Dialog
    </h5>
    <div class="ltx_para" id="S2.SS1.SSS0.Px2.p1">
     <p class="ltx_p" id="S2.SS1.SSS0.Px2.p1.1">
      is a new collection
      <cite class="ltx_cite ltx_citemacro_cite">
       Abacha et al. (
       <a class="ltx_ref" href="#bib.bib1" title="">
        2023
       </a>
       ); Ben Abacha et al. (
       <a class="ltx_ref" href="#bib.bib8" title="">
        2023
       </a>
       )
      </cite>
      of 1.7k short patient-physician conversations and corresponding summaries with section headers and contents following SOAP format
      <cite class="ltx_cite ltx_citemacro_cite">
       Podder et al. (
       <a class="ltx_ref" href="#bib.bib43" title="">
        2021
       </a>
       )
      </cite>
      to foster advancements in the field of automatic clinical note generation from patient-physician conversations.
This 1.7k short version dataset has a corresponding long version
      <cite class="ltx_cite ltx_citemacro_cite">
       Yim et al. (
       <a class="ltx_ref" href="#bib.bib62" title="">
        2023
       </a>
       )
      </cite>
      of 87 complete dialogues and clinical notes, all of which we use for our evaluation.
However, due to the API’s stringent maximum token restriction, incorporating the complete dialogue into a single prompt proved impracticable.
Consequently, we implemented a strategy that involved segmenting a clinical note into several sections according to the traditional SOAP format
      <span class="ltx_note ltx_role_footnote" id="footnote6">
       <sup class="ltx_note_mark">
        6
       </sup>
       <span class="ltx_note_outer">
        <span class="ltx_note_content">
         <sup class="ltx_note_mark">
          6
         </sup>
         <span class="ltx_tag ltx_tag_note">
          6
         </span>
         SOAP structure details can be found in the Appendix
         <a class="ltx_ref" href="#A1.SS1" title="A.1 SOAP Structure ‣ Appendix A Appendix ‣ NoteChat: A Dataset of Synthetic Patient-Physician Conversations Conditioned on Clinical Notes">
          <span class="ltx_text ltx_ref_tag">
           A.1
          </span>
         </a>
         .
        </span>
       </span>
      </span>
      .
We used each section header to construct a distinct prompt with the corresponding content in the note, thereby aiding the model in generating individual chats for every section.
We added a corresponding postprocessing step for MTS-Dialog with the Combine Prompt in Appendix Table
      <a class="ltx_ref" href="#A1.T14" title="Table 14 ‣ A.4 Color for Polish Promopt ‣ Appendix A Appendix ‣ NoteChat: A Dataset of Synthetic Patient-Physician Conversations Conditioned on Clinical Notes">
       <span class="ltx_text ltx_ref_tag">
        14
       </span>
      </a>
      , where we concatenated all the small chats from different sections to create a complete dialogue.
     </p>
    </div>
   </section>
  </section>
  <section class="ltx_subsection" id="S2.SS2">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     2.2
    </span>
    NoteChat: Generating patient-physician dialogues from notes in the GPT Era
   </h3>
   <div class="ltx_para" id="S2.SS2.p1">
    <p class="ltx_p" id="S2.SS2.p1.1">
     To ensure that our synthetic datasets closely resemble authentic dialogues, we first use the prompts in Appendix
     <a class="ltx_ref" href="#A1.SS2" title="A.2 Prompts for ChatGPT&amp;GPT4 ‣ Appendix A Appendix ‣ NoteChat: A Dataset of Synthetic Patient-Physician Conversations Conditioned on Clinical Notes">
      <span class="ltx_text ltx_ref_tag">
       A.2
      </span>
     </a>
     to guide the roleplay of ChatGPT and GPT4 in generating high-quality data as our baselines.
In this section, we introduce our NoteChat Framework for this task. All our NoteChat experiments in this paper are based on ChatGPT API (gpt-3.5-turbo), but NoteChat can be used in any model that can handle the instructions.
    </p>
   </div>
   <section class="ltx_subsubsection" id="S2.SS2.SSS1">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      2.2.1
     </span>
     Main dialogue generation loop
    </h4>
    <section class="ltx_paragraph" id="S2.SS2.SSS1.Px1">
     <h5 class="ltx_title ltx_title_paragraph">
      Planning module
     </h5>
     <div class="ltx_para" id="S2.SS2.SSS1.Px1.p1">
      <p class="ltx_p" id="S2.SS2.SSS1.Px1.p1.1">
       Typically, a physician’s diagnostic process adheres to a logical sequence, which may be outlined as follows
       <cite class="ltx_cite ltx_citemacro_cite">
        First et al. (
        <a class="ltx_ref" href="#bib.bib19" title="">
         2013
        </a>
        ); Johnson (
        <a class="ltx_ref" href="#bib.bib27" title="">
         2003
        </a>
        ); Tsichlis et al. (
        <a class="ltx_ref" href="#bib.bib55" title="">
         2021
        </a>
        )
       </cite>
       : 1) Eliciting symptoms, such as chest pain, 2) Inquiring about the duration of these symptoms, 3) Obtaining medical history, including personal and familial records, 4) Conducting diagnostic tests, 5) Reaching a conclusion and prescribing appropriate medication.
Thus, an effective dialogue dataset should accurately reflect the logical sequence of real-world interactions between physicians and patients.
Therefore, before generating dialogues, it is crucial to ensure that the model follows such logic.
However, we found models often tend to overlook crucial information, create hallucination information, or messily skip content that should logically be in the first half of the dialogue and go to generating first with content that should logically appear later.
This is often caused by the LLMs lacking sufficient medical knowledge
       <cite class="ltx_cite ltx_citemacro_cite">
        Dave et al. (
        <a class="ltx_ref" href="#bib.bib15" title="">
         2023
        </a>
        )
       </cite>
       or low-level planning abilities
       <cite class="ltx_cite ltx_citemacro_cite">
        Valmeekam et al. (
        <a class="ltx_ref" href="#bib.bib56" title="">
         2023
        </a>
        )
       </cite>
       .
      </p>
     </div>
     <div class="ltx_para" id="S2.SS2.SSS1.Px1.p2">
      <p class="ltx_p" id="S2.SS2.SSS1.Px1.p2.1">
       To circumvent these issues, we first extract clinical domain-specific keywords using CUI (Clinical Uniform Identifier) from MedSpaCy
       <cite class="ltx_cite ltx_citemacro_citep">
        (Eyre et al.,
        <a class="ltx_ref" href="#bib.bib17" title="">
         2021
        </a>
        )
       </cite>
       with QuickUMLS
       <cite class="ltx_cite ltx_citemacro_citep">
        (Soldaini,
        <a class="ltx_ref" href="#bib.bib50" title="">
         2016
        </a>
        )
       </cite>
       and require the LLM to build dialogues around these keywords exclusively, where we design the prompt in Appendix Table
       <a class="ltx_ref" href="#A1.T11" title="Table 11 ‣ A.4 Color for Polish Promopt ‣ Appendix A Appendix ‣ NoteChat: A Dataset of Synthetic Patient-Physician Conversations Conditioned on Clinical Notes">
        <span class="ltx_text ltx_ref_tag">
         11
        </span>
       </a>
       with the list of keywords to help the LLM generates the dialogue draft.
With this, we inject external clinical knowledge resources for semantic grounding to reduce hallucination.
The Planning module is responsible only for high-level planning, which pertains to the general distribution of different pieces of information within the dialogue.
However, the control of each specific utterance at a low level is delegated to the Roleplay module (
       <a class="ltx_ref" href="#S2.SS2.SSS1.Px2" title="Roleplay module ‣ 2.2.1 Main dialogue generation loop ‣ 2.2 NoteChat: Generating patient-physician dialogues from notes in the GPT Era ‣ 2 Methods ‣ NoteChat: A Dataset of Synthetic Patient-Physician Conversations Conditioned on Clinical Notes">
        <span class="ltx_text ltx_ref_tag">
         2.2.1
        </span>
       </a>
       ).
Therefore, the output of the Planning module is not this draft, but a checklist. Each CUI in the checklist is extracted in sequence from the generated draft.
Then, the Planning module will accompany the entire Roleplay module. That is, every time the Roleplay module completes a new round of dialogue generation, the planning module will count the newly added CUIs in the dialogue and remove them from the checklist.
Therefore, the Planning module not only assumes the responsibility for the correct correlation of the facts but also helps the entire conversation narrow in a more definite direction until the end.
      </p>
     </div>
    </section>
    <section class="ltx_paragraph" id="S2.SS2.SSS1.Px2">
     <h5 class="ltx_title ltx_title_paragraph">
      Roleplay module
     </h5>
     <div class="ltx_para" id="S2.SS2.SSS1.Px2.p1">
      <p class="ltx_p" id="S2.SS2.SSS1.Px2.p1.1">
       The dialogue draft we generated in the Planning module is not high-quality dialogue data. Previous work
       <cite class="ltx_cite ltx_citemacro_cite">
        Yunxiang et al. (
        <a class="ltx_ref" href="#bib.bib65" title="">
         2023
        </a>
        )
       </cite>
       shows that dialogues generated by a single LLM often have issues in language diversity and role homogeneity.
These are manifestations of the shortcomings of LLMs in handling low-level planning for each utterance in an entire dialogue.
Therefore, in order to generate better quality dialogues, we use the checklist in the Planning module to generate multiple rounds of dialogues using two LLMs to play the roles of patients and physicians, respectively.
This strategy enables us to use distinct prompts based on different requirements of the corresponding role so that the physician’s responses appear more professional and the patient’s dialogue sounds more normal.
Furthermore, we can control the direction of each dialogue round by modifying the prompts. More specifically, we determine the keywords covered in each round based on the current checklist, allowing two roleplay LLMs to advance the dialogue further and maximize the coverage of the keywords. We then let the Planning module update the checklist.
Subsequently, we let the patient-LLM respond to the physician in as colloquial a manner as possible, ensuring the patient’s utterance lay language style.
All prompts can be found in Table
       <a class="ltx_ref" href="#A1.T12" title="Table 12 ‣ A.4 Color for Polish Promopt ‣ Appendix A Appendix ‣ NoteChat: A Dataset of Synthetic Patient-Physician Conversations Conditioned on Clinical Notes">
        <span class="ltx_text ltx_ref_tag">
         12
        </span>
       </a>
       .
      </p>
     </div>
    </section>
    <section class="ltx_paragraph" id="S2.SS2.SSS1.Px3">
     <h5 class="ltx_title ltx_title_paragraph">
      Polish module
     </h5>
     <figure class="ltx_table" id="S2.T2">
      <div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S2.T2.1" style="width:164.0pt;height:162pt;vertical-align:-0.0pt;">
       <span class="ltx_transformed_inner" style="transform:translate(-27.3pt,27.0pt) scale(0.75,0.75) ;">
        <table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S2.T2.1.1">
         <tbody class="ltx_tbody">
          <tr class="ltx_tr" id="S2.T2.1.1.1.1">
           <th class="ltx_td ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S2.T2.1.1.1.1.1">
           </th>
           <td class="ltx_td ltx_align_center ltx_border_t" id="S2.T2.1.1.1.1.2">
            NoteChat
           </td>
           <td class="ltx_td ltx_align_center ltx_border_t" id="S2.T2.1.1.1.1.3">
            ChatGPT
           </td>
           <td class="ltx_td ltx_align_center ltx_border_t" id="S2.T2.1.1.1.1.4">
            GPT4
           </td>
          </tr>
          <tr class="ltx_tr" id="S2.T2.1.1.2.2">
           <th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S2.T2.1.1.2.2.1">
            total #dial.
           </th>
           <td class="ltx_td ltx_align_center ltx_border_t" id="S2.T2.1.1.2.2.2">
            10k
           </td>
           <td class="ltx_td ltx_align_center ltx_border_t" id="S2.T2.1.1.2.2.3">
            10k
           </td>
           <td class="ltx_td ltx_align_center ltx_border_t" id="S2.T2.1.1.2.2.4">
            10k
           </td>
          </tr>
          <tr class="ltx_tr" id="S2.T2.1.1.3.3">
           <th class="ltx_td ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S2.T2.1.1.3.3.1">
           </th>
           <td class="ltx_td ltx_align_center ltx_border_t" colspan="3" id="S2.T2.1.1.3.3.2">
            avg # in a dialogue
           </td>
          </tr>
          <tr class="ltx_tr" id="S2.T2.1.1.4.4">
           <th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S2.T2.1.1.4.4.1">
            utterance
           </th>
           <td class="ltx_td ltx_align_center ltx_border_t" id="S2.T2.1.1.4.4.2">
            25.4
           </td>
           <td class="ltx_td ltx_align_center ltx_border_t" id="S2.T2.1.1.4.4.3">
            20.5
           </td>
           <td class="ltx_td ltx_align_center ltx_border_t" id="S2.T2.1.1.4.4.4">
            17.4
           </td>
          </tr>
          <tr class="ltx_tr" id="S2.T2.1.1.5.5">
           <th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S2.T2.1.1.5.5.1">
            word
           </th>
           <td class="ltx_td ltx_align_center" id="S2.T2.1.1.5.5.2">
            534
           </td>
           <td class="ltx_td ltx_align_center" id="S2.T2.1.1.5.5.3">
            352
           </td>
           <td class="ltx_td ltx_align_center" id="S2.T2.1.1.5.5.4">
            390
           </td>
          </tr>
          <tr class="ltx_tr" id="S2.T2.1.1.6.6">
           <th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S2.T2.1.1.6.6.1">
            medical.
           </th>
           <td class="ltx_td ltx_align_center" id="S2.T2.1.1.6.6.2">
            59.70
           </td>
           <td class="ltx_td ltx_align_center" id="S2.T2.1.1.6.6.3">
            44.5
           </td>
           <td class="ltx_td ltx_align_center" id="S2.T2.1.1.6.6.4">
            51.2
           </td>
          </tr>
          <tr class="ltx_tr" id="S2.T2.1.1.7.7">
           <th class="ltx_td ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S2.T2.1.1.7.7.1">
           </th>
           <td class="ltx_td ltx_align_center ltx_border_t" colspan="3" id="S2.T2.1.1.7.7.2">
            avg # of words in an utterance
           </td>
          </tr>
          <tr class="ltx_tr" id="S2.T2.1.1.8.8">
           <th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S2.T2.1.1.8.8.1">
            physician
           </th>
           <td class="ltx_td ltx_align_center ltx_border_t" id="S2.T2.1.1.8.8.2">
            30.2
           </td>
           <td class="ltx_td ltx_align_center ltx_border_t" id="S2.T2.1.1.8.8.3">
            25.1
           </td>
           <td class="ltx_td ltx_align_center ltx_border_t" id="S2.T2.1.1.8.8.4">
            33.6
           </td>
          </tr>
          <tr class="ltx_tr" id="S2.T2.1.1.9.9">
           <th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S2.T2.1.1.9.9.1">
            patient
           </th>
           <td class="ltx_td ltx_align_center" id="S2.T2.1.1.9.9.2">
            12.0
           </td>
           <td class="ltx_td ltx_align_center" id="S2.T2.1.1.9.9.3">
            11.7
           </td>
           <td class="ltx_td ltx_align_center" id="S2.T2.1.1.9.9.4">
            9.4
           </td>
          </tr>
          <tr class="ltx_tr" id="S2.T2.1.1.10.10">
           <th class="ltx_td ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S2.T2.1.1.10.10.1">
           </th>
           <td class="ltx_td ltx_align_center ltx_border_t" colspan="3" id="S2.T2.1.1.10.10.2">
            avg medical term density %
           </td>
          </tr>
          <tr class="ltx_tr" id="S2.T2.1.1.11.11">
           <th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S2.T2.1.1.11.11.1">
            physician
           </th>
           <td class="ltx_td ltx_align_center ltx_border_t" id="S2.T2.1.1.11.11.2">
            15.3
           </td>
           <td class="ltx_td ltx_align_center ltx_border_t" id="S2.T2.1.1.11.11.3">
            15.0
           </td>
           <td class="ltx_td ltx_align_center ltx_border_t" id="S2.T2.1.1.11.11.4">
            16.9
           </td>
          </tr>
          <tr class="ltx_tr" id="S2.T2.1.1.12.12">
           <th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r" id="S2.T2.1.1.12.12.1">
            patient
           </th>
           <td class="ltx_td ltx_align_center ltx_border_b" id="S2.T2.1.1.12.12.2">
            11.2
           </td>
           <td class="ltx_td ltx_align_center ltx_border_b" id="S2.T2.1.1.12.12.3">
            13.4
           </td>
           <td class="ltx_td ltx_align_center ltx_border_b" id="S2.T2.1.1.12.12.4">
            13.0
           </td>
          </tr>
         </tbody>
        </table>
       </span>
      </div>
      <figcaption class="ltx_caption ltx_centering">
       <span class="ltx_tag ltx_tag_table">
        Table 2:
       </span>
       Statistics of three synthetic patient-physician dialogue datasets conditioned on PMC-Patient notes
       <span class="ltx_note ltx_role_footnote" id="footnote8">
        <sup class="ltx_note_mark">
         8
        </sup>
        <span class="ltx_note_outer">
         <span class="ltx_note_content">
          <sup class="ltx_note_mark">
           8
          </sup>
          <span class="ltx_tag ltx_tag_note">
           8
          </span>
          For the issue of cost and rate limit, up to now, we only have all 167k ChatGPT synthetic data and only generated 10k synthetic data for GPT4 and NoteChat. For a fair comparison, all experiments and statistics in this paper are based on the same 10k PMC-Patient notes. But we will generate and release all 167k data in the future.
         </span>
        </span>
       </span>
       . In the table, we bifurcated the dialogue into two constituent segments: one representing the physician and the other the patient, for which we separately computed their corresponding scores. We computed the average count of words in both the physician and patient utterances across each dialogue in the triad of datasets. Additionally, we derived a metric, indicated as medical term density, which signifies the proportion of the count of Clinical Uniform Identifier (CUI) codes encapsulated within each utterance of physician and patient to the overall count of words.
      </figcaption>
     </figure>
     <div class="ltx_para" id="S2.SS2.SSS1.Px3.p1">
      <p class="ltx_p" id="S2.SS2.SSS1.Px3.p1.1">
       Although the two modules of Planning and Roleplay bring NoteChat more fine-grained control over LLM, restoring patient-physician dialogue from clinical notes requires LLM to balance several challenging requirements, including the planning of key information in the clinical note, reasonable information not occurring in the note but would appear in the dialogues, the language style characteristics of different roles, and the authenticity after combining everything into one complete dialogue.
In the previous Planning and Roleplay modules, LLMs will promote new dialogues based on historical dialogues.
Inspired by recent work of rethinking and reranking
       <cite class="ltx_cite ltx_citemacro_cite">
        Gabriel et al. (
        <a class="ltx_ref" href="#bib.bib21" title="">
         2021
        </a>
        ); Cobbe et al. (
        <a class="ltx_ref" href="#bib.bib14" title="">
         2021
        </a>
        ); Ravaut et al. (
        <a class="ltx_ref" href="#bib.bib46" title="">
         2022
        </a>
        ); Jiang et al. (
        <a class="ltx_ref" href="#bib.bib26" title="">
         2022
        </a>
        ); Shinn et al. (
        <a class="ltx_ref" href="#bib.bib49" title="">
         2023
        </a>
        )
       </cite>
       , we added the Polish module to give LLM another chance for self-reflection and correction post-Roleplay module.
To do this, we invited human experts who summarized the rules based on the preliminary results of NoteChat to help our synthetic data align with experts’ preferences, and they came up with 10 special rules:
1) Make the conversation as colloquial as possible,
2) Increase the number of rounds of interaction,
3) Professional terms and vocabulary should come from the physicians, and patients should be more colloquial,
4) Basic symptoms and medical history should come from the patient, not the physician,
5) The patients’ self-reported signs and symptoms should be around the inputs,
6) Physician inquiries should be logical,
7) If there are multiple consultation records, you can split a conversation into multiple ones and then link them with transfer words (e.g., a few days later),
8) Range of rounds of interaction,
9) Must contain the given keywords,
10) Do not generate duplicate information.
Specifically, we added these requirements to the Polish Prompt in Appendix Table
       <a class="ltx_ref" href="#A1.T13" title="Table 13 ‣ A.4 Color for Polish Promopt ‣ Appendix A Appendix ‣ NoteChat: A Dataset of Synthetic Patient-Physician Conversations Conditioned on Clinical Notes">
        <span class="ltx_text ltx_ref_tag">
         13
        </span>
       </a>
       and asked the LLM to polish the existing dialogue accordingly.
We found that multiple iterations of the Polish step can improve the quality of the final synthetic dialogue
       <span class="ltx_note ltx_role_footnote" id="footnote9">
        <sup class="ltx_note_mark">
         9
        </sup>
        <span class="ltx_note_outer">
         <span class="ltx_note_content">
          <sup class="ltx_note_mark">
           9
          </sup>
          <span class="ltx_tag ltx_tag_note">
           9
          </span>
          After balancing the time, cost, and final performance, we set the number of iterations to 2 in our experiments
         </span>
        </span>
       </span>
       .
      </p>
     </div>
    </section>
   </section>
  </section>
 </section>
 <section class="ltx_section" id="S3">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    3
   </span>
   Automatic Evaluation
  </h2>
  <div class="ltx_para" id="S3.p1">
   <p class="ltx_p" id="S3.p1.1">
    MTS-Dialog provides the human-annotated ground truth conversation data for every clinical note, but the PMC-Patient dataset only has case reports. So, we use intrinsic evaluation for MTS-Dialog synthetic data but extrinsic and human evaluation for PMC-Patient synthetic data.
   </p>
  </div>
  <section class="ltx_subsection" id="S3.SS1">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     3.1
    </span>
    Intrinsic Evaluation
   </h3>
   <div class="ltx_para" id="S3.SS1.p1">
    <p class="ltx_p" id="S3.SS1.p1.1">
     We measure this task of note-to-conversation from four aspects of the MTS-Dialog dataset.
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S3.SS1.p2">
    <p class="ltx_p" id="S3.SS1.p2.1">
     <span class="ltx_text ltx_font_bold" id="S3.SS1.p2.1.1">
      Similarity
     </span>
     We use ROUGE-F1 scores
     <cite class="ltx_cite ltx_citemacro_citep">
      (Lin,
      <a class="ltx_ref" href="#bib.bib34" title="">
       2004
      </a>
      )
     </cite>
     to measure the similarity of the generated conversation and the references.
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S3.SS1.p3">
    <p class="ltx_p" id="S3.SS1.p3.1">
     <span class="ltx_text ltx_font_bold" id="S3.SS1.p3.1.1">
      Factuality
     </span>
     We follow recent work
     <cite class="ltx_cite ltx_citemacro_cite">
      Adams et al. (
      <a class="ltx_ref" href="#bib.bib3" title="">
       2023
      </a>
      ); Ramprasad et al. (
      <a class="ltx_ref" href="#bib.bib45" title="">
       2023
      </a>
      )
     </cite>
     using medical concepts to evaluate factuality and make some improvements. Specifically, we use QuickUMLS
     <cite class="ltx_cite ltx_citemacro_citep">
      (Soldaini,
      <a class="ltx_ref" href="#bib.bib50" title="">
       2016
      </a>
      )
     </cite>
     to extract medical concepts from model-generated dialogues and ground truth dialogues to get two corresponding concept lists.
Then, we calculate the overlap of medical concept lists between two documents, offering insight into the model’s grasp of medical knowledge and terminology.
In Table
     <a class="ltx_ref" href="#S3.T3" title="Table 3 ‣ 3.2 Extrinsic Evaluation ‣ 3 Automatic Evaluation ‣ NoteChat: A Dataset of Synthetic Patient-Physician Conversations Conditioned on Clinical Notes">
      <span class="ltx_text ltx_ref_tag">
       3
      </span>
     </a>
     , we report the Concept-P/R/F1 as the Factuality metric.
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S3.SS1.p4">
    <p class="ltx_p" id="S3.SS1.p4.1">
     <span class="ltx_text ltx_font_bold" id="S3.SS1.p4.1.1">
      Extractiveness
     </span>
     We calculate the ROUGE-F1 of src-&gt;hypo (clinical note to model-generated dialogue) as our extractiveness metrics to demonstrate how much information in dialogue is extracted from the clinical note. For AI, a shortcut to improve Factuality is to improve Extractiveness. However, recent work shows increasing the factuality by this way might not be ideal in many scenarios
     <cite class="ltx_cite ltx_citemacro_cite">
      Ladhak et al. (
      <a class="ltx_ref" href="#bib.bib31" title="">
       2022
      </a>
      ); Goyal et al. (
      <a class="ltx_ref" href="#bib.bib24" title="">
       2022
      </a>
      )
     </cite>
     .
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S3.SS1.p5">
    <p class="ltx_p" id="S3.SS1.p5.1">
     <span class="ltx_text ltx_font_bold" id="S3.SS1.p5.1.1">
      Diversity
     </span>
     We use Self-BLEU (SBLEU)
     <cite class="ltx_cite ltx_citemacro_cite">
      Zhu et al. (
      <a class="ltx_ref" href="#bib.bib70" title="">
       2018
      </a>
      )
     </cite>
     to evaluate the diversity of the generated conversation for the patient utterances, physician utterances, and overall.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S3.SS2">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     3.2
    </span>
    Extrinsic Evaluation
   </h3>
   <div class="ltx_para ltx_noindent" id="S3.SS2.p1">
    <p class="ltx_p" id="S3.SS2.p1.1">
     <span class="ltx_text ltx_font_bold" id="S3.SS2.p1.1.1">
      Medical Chat Assistant:
     </span>
     We used the PMC-Patient synthetic dialogues generated by ChatGPT, GPT4, and NoteChat to fine-tune the LLaMA2-7B
     <span class="ltx_note ltx_role_footnote" id="footnote10">
      <sup class="ltx_note_mark">
       10
      </sup>
      <span class="ltx_note_outer">
       <span class="ltx_note_content">
        <sup class="ltx_note_mark">
         10
        </sup>
        <span class="ltx_tag ltx_tag_note">
         10
        </span>
        https://huggingface.co/meta-llama/Llama-2-7b-chat-hf
       </span>
      </span>
     </span>
     , where we only used physician utterances as the training labels. Then, we evaluated these fine-tuned LLaMA2 chatbots on the ground truth dialogues from MTS-Dialog. For evaluation, recent work shows a higher human evaluation correlation for GPT-4 eval than traditional metrics
     <cite class="ltx_cite ltx_citemacro_cite">
      Liu et al. (
      <a class="ltx_ref" href="#bib.bib36" title="">
       2023b
      </a>
      ); Gao et al. (
      <a class="ltx_ref" href="#bib.bib22" title="">
       2023
      </a>
      ); Fu et al. (
      <a class="ltx_ref" href="#bib.bib20" title="">
       2023
      </a>
      ); Zheng et al. (
      <a class="ltx_ref" href="#bib.bib69" title="">
       2023
      </a>
      )
     </cite>
     , so we also used the GPT4 preference as measurements to evaluate chatbots’ response quality.
Specifically, we instruct GPT4 to give preference ranking
     <span class="ltx_note ltx_role_footnote" id="footnote11">
      <sup class="ltx_note_mark">
       11
      </sup>
      <span class="ltx_note_outer">
       <span class="ltx_note_content">
        <sup class="ltx_note_mark">
         11
        </sup>
        <span class="ltx_tag ltx_tag_note">
         11
        </span>
        Prompts can be found in Appendix
        <a class="ltx_ref" href="#A1.T8" title="Table 8 ‣ A.4 Color for Polish Promopt ‣ Appendix A Appendix ‣ NoteChat: A Dataset of Synthetic Patient-Physician Conversations Conditioned on Clinical Notes">
         <span class="ltx_text ltx_ref_tag">
          8
         </span>
        </a>
        .
       </span>
      </span>
     </span>
     based on the conversation history and the real response.
We follow
     <cite class="ltx_cite ltx_citemacro_citet">
      Yao et al. (
      <a class="ltx_ref" href="#bib.bib59" title="">
       2023a
      </a>
      )
     </cite>
     to report the Mean Reciprocal Rank (MRR)
     <cite class="ltx_cite ltx_citemacro_cite">
      Radev et al. (
      <a class="ltx_ref" href="#bib.bib44" title="">
       2002
      </a>
      )
     </cite>
     of each model’s final ranking in Figure
     <a class="ltx_ref" href="#S3.F2" title="Figure 2 ‣ 3.2 Extrinsic Evaluation ‣ 3 Automatic Evaluation ‣ NoteChat: A Dataset of Synthetic Patient-Physician Conversations Conditioned on Clinical Notes">
      <span class="ltx_text ltx_ref_tag">
       2
      </span>
     </a>
     .
Generally, a higher MRR implies that evaluators have a better alignment with the evaluators’ preferences.
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S3.SS2.p2">
    <p class="ltx_p" id="S3.SS2.p2.1">
     <span class="ltx_text ltx_font_bold" id="S3.SS2.p2.1.1">
      Conversation2Note and Note2Conversation:
     </span>
     We also used the NoteChat dataset as data augmentation for two MTS-dialog tasks. We used the same evaluation metrics (ROUGE) following
     <cite class="ltx_cite ltx_citemacro_citet">
      Ben Abacha et al. (
      <a class="ltx_ref" href="#bib.bib8" title="">
       2023
      </a>
      )
     </cite>
     .
    </p>
   </div>
   <figure class="ltx_table" id="S3.T3">
    <div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S3.T3.3" style="width:191.1pt;height:183.6pt;vertical-align:-0.0pt;">
     <span class="ltx_transformed_inner" style="transform:translate(-63.7pt,61.2pt) scale(0.6,0.6) ;">
      <table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S3.T3.3.3">
       <tbody class="ltx_tbody">
        <tr class="ltx_tr" id="S3.T3.3.3.4.1">
         <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S3.T3.3.3.4.1.1">
          <span class="ltx_text ltx_font_bold" id="S3.T3.3.3.4.1.1.1">
           Similarity
          </span>
         </th>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.3.3.4.1.2">
          ROUGE1
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.3.3.4.1.3">
          ROUGE2
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.3.3.4.1.4">
          ROUGELsum
         </td>
        </tr>
        <tr class="ltx_tr" id="S3.T3.3.3.5.2">
         <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S3.T3.3.3.5.2.1">
          ChatGPT
         </th>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.3.3.5.2.2">
          48.56
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.3.3.5.2.3">
          16.74
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.3.3.5.2.4">
          46.36
         </td>
        </tr>
        <tr class="ltx_tr" id="S3.T3.3.3.6.3">
         <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S3.T3.3.3.6.3.1">
          GPT4
         </th>
         <td class="ltx_td ltx_align_center" id="S3.T3.3.3.6.3.2">
          53.29
         </td>
         <td class="ltx_td ltx_align_center" id="S3.T3.3.3.6.3.3">
          20.20
         </td>
         <td class="ltx_td ltx_align_center" id="S3.T3.3.3.6.3.4">
          50.81
         </td>
        </tr>
        <tr class="ltx_tr" id="S3.T3.3.3.7.4">
         <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S3.T3.3.3.7.4.1">
          NoteChat
         </th>
         <td class="ltx_td ltx_align_center" id="S3.T3.3.3.7.4.2">
          56.48
         </td>
         <td class="ltx_td ltx_align_center" id="S3.T3.3.3.7.4.3">
          19.74
         </td>
         <td class="ltx_td ltx_align_center" id="S3.T3.3.3.7.4.4">
          53.41
         </td>
        </tr>
        <tr class="ltx_tr" id="S3.T3.3.3.8.5">
         <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S3.T3.3.3.8.5.1">
          <span class="ltx_text ltx_font_bold" id="S3.T3.3.3.8.5.1.1">
           Factulity
          </span>
         </th>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.3.3.8.5.2">
          Concept-P
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.3.3.8.5.3">
          Concept-R
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.3.3.8.5.4">
          Concept-F1
         </td>
        </tr>
        <tr class="ltx_tr" id="S3.T3.3.3.9.6">
         <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S3.T3.3.3.9.6.1">
          ChatGPT
         </th>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.3.3.9.6.2">
          67.54
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.3.3.9.6.3">
          35.75
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.3.3.9.6.4">
          46.23
         </td>
        </tr>
        <tr class="ltx_tr" id="S3.T3.3.3.10.7">
         <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S3.T3.3.3.10.7.1">
          GPT4
         </th>
         <td class="ltx_td ltx_align_center" id="S3.T3.3.3.10.7.2">
          71.46
         </td>
         <td class="ltx_td ltx_align_center" id="S3.T3.3.3.10.7.3">
          45.69
         </td>
         <td class="ltx_td ltx_align_center" id="S3.T3.3.3.10.7.4">
          55.17
         </td>
        </tr>
        <tr class="ltx_tr" id="S3.T3.3.3.11.8">
         <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S3.T3.3.3.11.8.1">
          NoteChat
         </th>
         <td class="ltx_td ltx_align_center" id="S3.T3.3.3.11.8.2">
          48.23
         </td>
         <td class="ltx_td ltx_align_center" id="S3.T3.3.3.11.8.3">
          51.23
         </td>
         <td class="ltx_td ltx_align_center" id="S3.T3.3.3.11.8.4">
          49.68
         </td>
        </tr>
        <tr class="ltx_tr" id="S3.T3.3.3.12.9">
         <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S3.T3.3.3.12.9.1">
          <span class="ltx_text ltx_font_bold" id="S3.T3.3.3.12.9.1.1">
           Extractiveness
          </span>
         </th>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.3.3.12.9.2">
          src-&gt;hypo R1
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.3.3.12.9.3">
          src-&gt;hypo R2
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.3.3.12.9.4">
          src-&gt;hypo R-L
         </td>
        </tr>
        <tr class="ltx_tr" id="S3.T3.3.3.13.10">
         <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S3.T3.3.3.13.10.1">
          ChatGPT
         </th>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.3.3.13.10.2">
          43.73
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.3.3.13.10.3">
          19.72
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.3.3.13.10.4">
          40.54
         </td>
        </tr>
        <tr class="ltx_tr" id="S3.T3.3.3.14.11">
         <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S3.T3.3.3.14.11.1">
          GPT4
         </th>
         <td class="ltx_td ltx_align_center" id="S3.T3.3.3.14.11.2">
          52.70
         </td>
         <td class="ltx_td ltx_align_center" id="S3.T3.3.3.14.11.3">
          25.70
         </td>
         <td class="ltx_td ltx_align_center" id="S3.T3.3.3.14.11.4">
          49.63
         </td>
        </tr>
        <tr class="ltx_tr" id="S3.T3.3.3.15.12">
         <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S3.T3.3.3.15.12.1">
          NoteChat
         </th>
         <td class="ltx_td ltx_align_center" id="S3.T3.3.3.15.12.2">
          37.24
         </td>
         <td class="ltx_td ltx_align_center" id="S3.T3.3.3.15.12.3">
          20.83
         </td>
         <td class="ltx_td ltx_align_center" id="S3.T3.3.3.15.12.4">
          36.04
         </td>
        </tr>
        <tr class="ltx_tr" id="S3.T3.3.3.16.13">
         <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S3.T3.3.3.16.13.1">
          Human
         </th>
         <td class="ltx_td ltx_align_center" id="S3.T3.3.3.16.13.2">
          35.29
         </td>
         <td class="ltx_td ltx_align_center" id="S3.T3.3.3.16.13.3">
          14.38
         </td>
         <td class="ltx_td ltx_align_center" id="S3.T3.3.3.16.13.4">
          32.89
         </td>
        </tr>
        <tr class="ltx_tr" id="S3.T3.3.3.3">
         <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S3.T3.3.3.3.4">
          <span class="ltx_text ltx_font_bold" id="S3.T3.3.3.3.4.1">
           Diversity
          </span>
         </th>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.1.1.1">
          all-sbleu
          <math alttext="\downarrow" class="ltx_Math" display="inline" id="S3.T3.1.1.1.1.m1.1">
           <semantics id="S3.T3.1.1.1.1.m1.1a">
            <mo id="S3.T3.1.1.1.1.m1.1.1" stretchy="false" xref="S3.T3.1.1.1.1.m1.1.1.cmml">
             ↓
            </mo>
            <annotation-xml encoding="MathML-Content" id="S3.T3.1.1.1.1.m1.1b">
             <ci id="S3.T3.1.1.1.1.m1.1.1.cmml" xref="S3.T3.1.1.1.1.m1.1.1">
              ↓
             </ci>
            </annotation-xml>
            <annotation encoding="application/x-tex" id="S3.T3.1.1.1.1.m1.1c">
             \downarrow
            </annotation>
           </semantics>
          </math>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.2.2.2.2">
          physician-sbleu
          <math alttext="\downarrow" class="ltx_Math" display="inline" id="S3.T3.2.2.2.2.m1.1">
           <semantics id="S3.T3.2.2.2.2.m1.1a">
            <mo id="S3.T3.2.2.2.2.m1.1.1" stretchy="false" xref="S3.T3.2.2.2.2.m1.1.1.cmml">
             ↓
            </mo>
            <annotation-xml encoding="MathML-Content" id="S3.T3.2.2.2.2.m1.1b">
             <ci id="S3.T3.2.2.2.2.m1.1.1.cmml" xref="S3.T3.2.2.2.2.m1.1.1">
              ↓
             </ci>
            </annotation-xml>
            <annotation encoding="application/x-tex" id="S3.T3.2.2.2.2.m1.1c">
             \downarrow
            </annotation>
           </semantics>
          </math>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.3.3.3.3">
          patient-sbleu
          <math alttext="\downarrow" class="ltx_Math" display="inline" id="S3.T3.3.3.3.3.m1.1">
           <semantics id="S3.T3.3.3.3.3.m1.1a">
            <mo id="S3.T3.3.3.3.3.m1.1.1" stretchy="false" xref="S3.T3.3.3.3.3.m1.1.1.cmml">
             ↓
            </mo>
            <annotation-xml encoding="MathML-Content" id="S3.T3.3.3.3.3.m1.1b">
             <ci id="S3.T3.3.3.3.3.m1.1.1.cmml" xref="S3.T3.3.3.3.3.m1.1.1">
              ↓
             </ci>
            </annotation-xml>
            <annotation encoding="application/x-tex" id="S3.T3.3.3.3.3.m1.1c">
             \downarrow
            </annotation>
           </semantics>
          </math>
         </td>
        </tr>
        <tr class="ltx_tr" id="S3.T3.3.3.17.14">
         <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S3.T3.3.3.17.14.1">
          ChatGPT
         </th>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.3.3.17.14.2">
          0.017
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.3.3.17.14.3">
          0.006
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.3.3.17.14.4">
          0.017
         </td>
        </tr>
        <tr class="ltx_tr" id="S3.T3.3.3.18.15">
         <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S3.T3.3.3.18.15.1">
          GPT4
         </th>
         <td class="ltx_td ltx_align_center" id="S3.T3.3.3.18.15.2">
          0.019
         </td>
         <td class="ltx_td ltx_align_center" id="S3.T3.3.3.18.15.3">
          0.009
         </td>
         <td class="ltx_td ltx_align_center" id="S3.T3.3.3.18.15.4">
          0.019
         </td>
        </tr>
        <tr class="ltx_tr" id="S3.T3.3.3.19.16">
         <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r" id="S3.T3.3.3.19.16.1">
          NoteChat
         </th>
         <td class="ltx_td ltx_align_center ltx_border_b" id="S3.T3.3.3.19.16.2">
          0.014
         </td>
         <td class="ltx_td ltx_align_center ltx_border_b" id="S3.T3.3.3.19.16.3">
          0.007
         </td>
         <td class="ltx_td ltx_align_center ltx_border_b" id="S3.T3.3.3.19.16.4">
          0.014
         </td>
        </tr>
       </tbody>
      </table>
     </span>
    </div>
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_table">
      Table 3:
     </span>
     Intrinsic eval results on MTS-dialog
     <span class="ltx_note ltx_role_footnote" id="footnote13">
      <sup class="ltx_note_mark">
       13
      </sup>
      <span class="ltx_note_outer">
       <span class="ltx_note_content">
        <sup class="ltx_note_mark">
         13
        </sup>
        <span class="ltx_tag ltx_tag_note">
         13
        </span>
        All experiments are done under the zero-shot setting.
       </span>
      </span>
     </span>
     .
    </figcaption>
   </figure>
   <figure class="ltx_figure" id="S3.F2">
    <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="227" id="S3.F2.g1" src="/html/2310.15959/assets/images/dialogue_extrinsic_eval.jpg" width="299"/>
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_figure">
      Figure 2:
     </span>
     Extrinsic eval results for Medical Chatbot task. LLaMA2-7B is fine-tuned on different PMC-Patient synthetic conversations, and then we use MTS-dialog as the evaluation dataset. NoteChat has the highest score, indicating the most preferred by GPT4.
    </figcaption>
   </figure>
   <figure class="ltx_table" id="S3.T4">
    <div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S3.T4.1" style="width:200.2pt;height:108.9pt;vertical-align:-0.0pt;">
     <span class="ltx_transformed_inner" style="transform:translate(-81.9pt,44.6pt) scale(0.55,0.55) ;">
      <table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S3.T4.1.1">
       <thead class="ltx_thead">
        <tr class="ltx_tr" id="S3.T4.1.1.1.1">
         <th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S3.T4.1.1.1.1.1">
          Model
         </th>
         <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T4.1.1.1.1.2">
          ROUGE-1
         </th>
         <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T4.1.1.1.1.3">
          ROUGE-2
         </th>
         <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T4.1.1.1.1.4">
          ROUGE-L
         </th>
         <th class="ltx_td ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T4.1.1.1.1.5">
          ROUGE-L
         </th>
        </tr>
        <tr class="ltx_tr" id="S3.T4.1.1.2.2">
         <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_t" colspan="5" id="S3.T4.1.1.2.2.1">
          Note2Conversation
         </th>
        </tr>
       </thead>
       <tbody class="ltx_tbody">
        <tr class="ltx_tr" id="S3.T4.1.1.3.1">
         <th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S3.T4.1.1.3.1.1">
          LLaMA2 (No Train)
         </th>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T4.1.1.3.1.2">
          24.60
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T4.1.1.3.1.3">
          9.26
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T4.1.1.3.1.4">
          16.19
         </td>
         <td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" id="S3.T4.1.1.3.1.5">
          22.92
         </td>
        </tr>
        <tr class="ltx_tr" id="S3.T4.1.1.4.2">
         <th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T4.1.1.4.2.1">
          LLaMA2 (Notechat only)
         </th>
         <td class="ltx_td ltx_align_center" id="S3.T4.1.1.4.2.2">
          36.70
         </td>
         <td class="ltx_td ltx_align_center" id="S3.T4.1.1.4.2.3">
          22.02
         </td>
         <td class="ltx_td ltx_align_center" id="S3.T4.1.1.4.2.4">
          29.70
         </td>
         <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T4.1.1.4.2.5">
          35.21
         </td>
        </tr>
        <tr class="ltx_tr" id="S3.T4.1.1.5.3">
         <th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T4.1.1.5.3.1">
          LLaMA2 (MTS only)
         </th>
         <td class="ltx_td ltx_align_center" id="S3.T4.1.1.5.3.2">
          31.09
         </td>
         <td class="ltx_td ltx_align_center" id="S3.T4.1.1.5.3.3">
          12.80
         </td>
         <td class="ltx_td ltx_align_center" id="S3.T4.1.1.5.3.4">
          24.30
         </td>
         <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T4.1.1.5.3.5">
          30.05
         </td>
        </tr>
        <tr class="ltx_tr" id="S3.T4.1.1.6.4">
         <th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T4.1.1.6.4.1">
          LLaMA2 (MTS+Notechat)
         </th>
         <td class="ltx_td ltx_align_center" id="S3.T4.1.1.6.4.2">
          42.54
         </td>
         <td class="ltx_td ltx_align_center" id="S3.T4.1.1.6.4.3">
          19.17
         </td>
         <td class="ltx_td ltx_align_center" id="S3.T4.1.1.6.4.4">
          38.67
         </td>
         <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T4.1.1.6.4.5">
          38.70
         </td>
        </tr>
        <tr class="ltx_tr" id="S3.T4.1.1.7.5">
         <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="5" id="S3.T4.1.1.7.5.1">
          Conversation2Note
         </th>
        </tr>
        <tr class="ltx_tr" id="S3.T4.1.1.8.6">
         <th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S3.T4.1.1.8.6.1">
          LLaMA2 (No Train)
         </th>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T4.1.1.8.6.2">
          22.14
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T4.1.1.8.6.3">
          7.65
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T4.1.1.8.6.4">
          15.85
         </td>
         <td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" id="S3.T4.1.1.8.6.5">
          16.38
         </td>
        </tr>
        <tr class="ltx_tr" id="S3.T4.1.1.9.7">
         <th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T4.1.1.9.7.1">
          LLaMA2 (Notechat only)
         </th>
         <td class="ltx_td ltx_align_center" id="S3.T4.1.1.9.7.2">
          23.82
         </td>
         <td class="ltx_td ltx_align_center" id="S3.T4.1.1.9.7.3">
          9.08
         </td>
         <td class="ltx_td ltx_align_center" id="S3.T4.1.1.9.7.4">
          17.37
         </td>
         <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T4.1.1.9.7.5">
          17.48
         </td>
        </tr>
        <tr class="ltx_tr" id="S3.T4.1.1.10.8">
         <th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T4.1.1.10.8.1">
          LLaMA2 (MTS only)
         </th>
         <td class="ltx_td ltx_align_center" id="S3.T4.1.1.10.8.2">
          38.35
         </td>
         <td class="ltx_td ltx_align_center" id="S3.T4.1.1.10.8.3">
          18.99
         </td>
         <td class="ltx_td ltx_align_center" id="S3.T4.1.1.10.8.4">
          33.87
         </td>
         <td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T4.1.1.10.8.5">
          33.94
         </td>
        </tr>
        <tr class="ltx_tr" id="S3.T4.1.1.11.9">
         <th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S3.T4.1.1.11.9.1">
          LLaMA2 (MTS+Notechat)
         </th>
         <td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T4.1.1.11.9.2">
          43.84
         </td>
         <td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T4.1.1.11.9.3">
          24.34
         </td>
         <td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T4.1.1.11.9.4">
          41.05
         </td>
         <td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb" id="S3.T4.1.1.11.9.5">
          41.06
         </td>
        </tr>
       </tbody>
      </table>
     </span>
    </div>
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_table">
      Table 4:
     </span>
     Performance for LLaMA2 fine-tuned on different dataset with Conversation2Note and Note2Conversation extrinsic evaluation tasks.
    </figcaption>
   </figure>
  </section>
  <section class="ltx_subsection" id="S3.SS3">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     3.3
    </span>
    Automatic Evaluation Results
   </h3>
   <div class="ltx_para" id="S3.SS3.p1">
    <p class="ltx_p" id="S3.SS3.p1.1">
     The
     <span class="ltx_text ltx_font_bold" id="S3.SS3.p1.1.1">
      intrinsic evaluation
     </span>
     results, as illustrated in Table
     <a class="ltx_ref" href="#S3.T3" title="Table 3 ‣ 3.2 Extrinsic Evaluation ‣ 3 Automatic Evaluation ‣ NoteChat: A Dataset of Synthetic Patient-Physician Conversations Conditioned on Clinical Notes">
      <span class="ltx_text ltx_ref_tag">
       3
      </span>
     </a>
     , show that the overall similarity of the conversations generated by NoteChat and Human (MTS-dialog ground truth) is higher than that of GPT4 and ChatGPT baselines.
GPT4 outperformed NoteChat and ChatGPT in both factuality and extractiveness metrics. NoteChat outperformed ChatGPT in factuality but had a lower and closer to human extractiveness score. In Section
     <a class="ltx_ref" href="#S4.SS4" title="4.4 Heuristic Evaluation with Experts ‣ 4 Human Evaluation ‣ NoteChat: A Dataset of Synthetic Patient-Physician Conversations Conditioned on Clinical Notes">
      <span class="ltx_text ltx_ref_tag">
       4.4
      </span>
     </a>
     , we will discuss the impact of the different factuality and extractiveness scores of the three methods on human expert preferences on our task.
Finally, we found that the diversity of NoteChat, especially for patient utterances, is significantly better than the baselines.
The
     <span class="ltx_text ltx_font_bold" id="S3.SS3.p1.1.2">
      extrinsic evaluation Medical Chat Assistant
     </span>
     results are illustrated in Figure
     <a class="ltx_ref" href="#S3.F2" title="Figure 2 ‣ 3.2 Extrinsic Evaluation ‣ 3 Automatic Evaluation ‣ NoteChat: A Dataset of Synthetic Patient-Physician Conversations Conditioned on Clinical Notes">
      <span class="ltx_text ltx_ref_tag">
       2
      </span>
     </a>
     .
In this experiment, LLaMA2-7B is first fine-tuned on different PMC-Patient synthetic conversations. Then we use MTS-dialog as the evaluation dataset.
NoteChat-based LLaMA2 has the highest score, indicating the most preferred by GPT4 when generating real physician utterances.
It is worth noting that this evaluation is also a kind of transfer learning because the model is only trained on different versions of PMC-Patient synthetic dialogue (NoteChat, ChatGPT, GPT4) and then tested its zero-shot performance on human-labeled dialogue in MTS-dialog.
The
     <span class="ltx_text ltx_font_bold" id="S3.SS3.p1.1.3">
      extrinsic evaluation Conversation2Note and Note2Conversation
     </span>
     results are illustrated in Table
     <a class="ltx_ref" href="#S3.T4" title="Table 4 ‣ 3.2 Extrinsic Evaluation ‣ 3 Automatic Evaluation ‣ NoteChat: A Dataset of Synthetic Patient-Physician Conversations Conditioned on Clinical Notes">
      <span class="ltx_text ltx_ref_tag">
       4
      </span>
     </a>
     .
We found that training on NoteChat-only can observe significant improvements in MTS-dialogue test results. The best results can be obtained if NoteChat is used as data augmentation of the original MTS-dialogue training data.
Therefore, the results of this extrinsic evaluation show that the models trained on the NoteChat dataset are generalizable to the real human-annotated dataset.
    </p>
   </div>
  </section>
 </section>
 <section class="ltx_section" id="S4">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    4
   </span>
   Human Evaluation
  </h2>
  <div class="ltx_para" id="S4.p1">
   <p class="ltx_p" id="S4.p1.1">
    To assess the quality of synthetic conversations generated by different methods (ChatGPT, GPT-4, NoteChat), we conducted a human evaluation using crowd-sourcing and domain experts.
   </p>
  </div>
  <section class="ltx_subsection" id="S4.SS1">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     4.1
    </span>
    Human Evaluation Settings
   </h3>
   <div class="ltx_para" id="S4.SS1.p1">
    <p class="ltx_p" id="S4.SS1.p1.1">
     The goal of
     <span class="ltx_text ltx_font_bold" id="S4.SS1.p1.1.1">
      expert evaluation
     </span>
     is to have human domain experts evaluate whether these machine-generated conversations are comparable to real patient-physician encounter conversations from a professional perspective (e.g. medical commonsense, knowledge, logic).
To do so, we recruited 5 medical practitioners
     <span class="ltx_note ltx_role_footnote" id="footnote14">
      <sup class="ltx_note_mark">
       14
      </sup>
      <span class="ltx_note_outer">
       <span class="ltx_note_content">
        <sup class="ltx_note_mark">
         14
        </sup>
        <span class="ltx_tag ltx_tag_note">
         14
        </span>
        Four licensed physicians and one medical student with hospital internship experience. These experts were not involved in the research, only the human evaluation.
       </span>
      </span>
     </span>
     , and their tasks are to read clinical notes and provide qualitative feedback on whether the machine-generated dialogues can be defined as high-quality patient-physician interactions in terms of factual accuracy and logical coherence; if not, how should they be improved?
    </p>
   </div>
   <div class="ltx_para" id="S4.SS1.p2">
    <p class="ltx_p" id="S4.SS1.p2.1">
     The goal of
     <span class="ltx_text ltx_font_bold" id="S4.SS1.p2.1.1">
      crowd evaluation
     </span>
     is to allow the general public to provide ratings for different synthetic conversations based on their lived experience. Since the crowds do not have professional medical knowledge, participants will first read the clinical notes and medical expert annotated conversations as references for high-quality data and then rank different machine-generated conversations for quantitative measurement of their preference.
We recruited 10 human evaluators to participate in our crowd evaluation.
     <span class="ltx_note ltx_role_footnote" id="footnote15">
      <sup class="ltx_note_mark">
       15
      </sup>
      <span class="ltx_note_outer">
       <span class="ltx_note_content">
        <sup class="ltx_note_mark">
         15
        </sup>
        <span class="ltx_tag ltx_tag_note">
         15
        </span>
        All the evaluators have bachelor’s degrees but do not have any medical education background.
       </span>
      </span>
     </span>
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S4.SS2">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     4.2
    </span>
    Human Evaluation Measurements
   </h3>
   <div class="ltx_para" id="S4.SS2.p1">
    <p class="ltx_p" id="S4.SS2.p1.1">
     We mainly use human preference as measurements to evaluate synthetic conversation quality.
Specifically, the participants are provided with the following instructions “
     <em class="ltx_emph ltx_font_italic" id="S4.SS2.p1.1.1">
      The following three conversations are generated by AI based on this clinical note. Please rank them according to the quality you think, from high to low.
     </em>
     ”.
We collect the preference ranking from experts, crowds, and GPT4.
We report the Mean Reciprocal Rank (MRR) of each model’s final ranking in Figure
     <a class="ltx_ref" href="#S4.F3" title="Figure 3 ‣ 4.3 Human Evaluation Outcome ‣ 4 Human Evaluation ‣ NoteChat: A Dataset of Synthetic Patient-Physician Conversations Conditioned on Clinical Notes">
      <span class="ltx_text ltx_ref_tag">
       3
      </span>
     </a>
     .
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S4.SS3">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     4.3
    </span>
    Human Evaluation Outcome
   </h3>
   <div class="ltx_para" id="S4.SS3.p1">
    <p class="ltx_p" id="S4.SS3.p1.1">
     All the preference feedback from experts, crowds, and AI are shown in Figure
     <a class="ltx_ref" href="#S4.F3" title="Figure 3 ‣ 4.3 Human Evaluation Outcome ‣ 4 Human Evaluation ‣ NoteChat: A Dataset of Synthetic Patient-Physician Conversations Conditioned on Clinical Notes">
      <span class="ltx_text ltx_ref_tag">
       3
      </span>
     </a>
     .
In the most crucial results concerning expert preferences, NoteChat’s MRR score significantly outperforms that of GPT4, indicating that from an expert’s perspective, the quality of dialogue data from NoteChat is higher.
In terms of preferences among the crowds and AI, NoteChat also clearly surpasses GPT4, demonstrating consistency with expert preferences.
Finally, in all three human evaluations, both NoteChat and GPT4 perform better than ChatGPT.
    </p>
   </div>
   <figure class="ltx_figure" id="S4.F3">
    <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="314" id="S4.F3.g1" src="/html/2310.15959/assets/images/human_eval.jpg" width="419"/>
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_figure">
      Figure 3:
     </span>
     Human&amp;AI preference for 50 samples.
    </figcaption>
   </figure>
  </section>
  <section class="ltx_subsection" id="S4.SS4">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     4.4
    </span>
    Heuristic Evaluation with Experts
   </h3>
   <div class="ltx_para" id="S4.SS4.p1">
    <p class="ltx_p" id="S4.SS4.p1.1">
     We interviewed 5 medical practitioners:
    </p>
   </div>
   <div class="ltx_para" id="S4.SS4.p2">
    <p class="ltx_p" id="S4.SS4.p2.1">
     Q1)
     <span class="ltx_text ltx_font_bold" id="S4.SS4.p2.1.1">
      What are the shortcomings of AI synthetic conversation compared with real-world patient-physician encounter conversation?
     </span>
     Experts think that synthetic conversations cover too much information from the clinical note compared to real-world conversations, because some factual information is not provided to note through conversation (such as lab test results). For example, in Table
     <a class="ltx_ref" href="#footnote17" title="footnote 17 ‣ Table 5 ‣ 4.4 Heuristic Evaluation with Experts ‣ 4 Human Evaluation ‣ NoteChat: A Dataset of Synthetic Patient-Physician Conversations Conditioned on Clinical Notes">
      <span class="ltx_text ltx_ref_tag">
       17
      </span>
     </a>
     Example 1, the detailed dosage information will be not in the conversation.
In Example 2, the patient acts too professionally. In the answer, a lot of medical knowledge that physicians will know is described by the patient.
    </p>
   </div>
   <div class="ltx_para" id="S4.SS4.p3">
    <p class="ltx_p" id="S4.SS4.p3.1">
     Q2)
     <span class="ltx_text ltx_font_bold" id="S4.SS4.p3.1.1">
      What is the difference between ChatGPT, GPT4, and NoteChat synthetic conversations?
     </span>
     All medical practitioners believe that GPT4 and NoteChat lead ChatGPT in terms of factuality. Since our NoteChat is based upon ChatGPT, this human observation shows that our modules successfully inject medical concept knowledge to improve the factuality level from ChatGPT to the level of GPT4.
So, as shown in Figure
     <a class="ltx_ref" href="#S4.F3" title="Figure 3 ‣ 4.3 Human Evaluation Outcome ‣ 4 Human Evaluation ‣ NoteChat: A Dataset of Synthetic Patient-Physician Conversations Conditioned on Clinical Notes">
      <span class="ltx_text ltx_ref_tag">
       3
      </span>
     </a>
     , ChatGPT is ranked last in all cases.
    </p>
   </div>
   <div class="ltx_para" id="S4.SS4.p4">
    <p class="ltx_p" id="S4.SS4.p4.1">
     Regarding the comparison between NoteChat and GPT4, medical practitioners actually believe that the data quality of NoteChat-synthetic conversations is generally better than the GPT4 synthetic dataset, which aligns with their expert preference in Figure
     <a class="ltx_ref" href="#S4.F3" title="Figure 3 ‣ 4.3 Human Evaluation Outcome ‣ 4 Human Evaluation ‣ NoteChat: A Dataset of Synthetic Patient-Physician Conversations Conditioned on Clinical Notes">
      <span class="ltx_text ltx_ref_tag">
       3
      </span>
     </a>
     .
We further conducted a heuristic evaluation to explore the reason here as well as the deficiency of NoteChat and GPT4 synthetic conversations and potential improvement.
We further conducted a heuristic evaluation to explore the reason here as well as the deficiency of NoteChat and GPT4 synthetic conversations and potential improvement. First of all, GPT4 prefers to copy the information directly in the note to meet the requirements of factuality, but this will make the conversation unreal. In Table
     <a class="ltx_ref" href="#footnote17" title="footnote 17 ‣ Table 5 ‣ 4.4 Heuristic Evaluation with Experts ‣ 4 Human Evaluation ‣ NoteChat: A Dataset of Synthetic Patient-Physician Conversations Conditioned on Clinical Notes">
      <span class="ltx_text ltx_ref_tag">
       17
      </span>
     </a>
     Example 2, the information is highly summarized and put together on the note, but it is unnatural for the same content to appear directly in the dialogue. Compared with the utterance generated by GPT4, a better way is to use multiple conversation rounds to obtain information one by one. This is a problem common to all AIs in this paper, but GPT4’s problem is most obvious. Second, in reality, physicians are expected to not only answer questions but also advance the discussion by asking professional questions. We observe that the physician in NoteChat is more likely to advance the conversation compared to the physician in GPT4 due to our Roleplay module.
    </p>
   </div>
   <div class="ltx_para" id="S4.SS4.p5">
    <p class="ltx_p" id="S4.SS4.p5.1">
     To better control language models, it’s important to specify which information is spoken by the physician and which by the patient. In the Table
     <a class="ltx_ref" href="#footnote17" title="footnote 17 ‣ Table 5 ‣ 4.4 Heuristic Evaluation with Experts ‣ 4 Human Evaluation ‣ NoteChat: A Dataset of Synthetic Patient-Physician Conversations Conditioned on Clinical Notes">
      <span class="ltx_text ltx_ref_tag">
       17
      </span>
     </a>
     Example 3, GPT-4 let the patient speculate about their symptoms and dismiss physical activities as a cause. Using a specific prompt, the NoteChat Roleplay module was adjusted to ensure both the physician and patient roles are accurately portrayed and cooperate logically.
Finally, The dialogue should start like a real conversation, with the patient sharing symptoms and medical history. Usually, doctors don’t know a patient’s history, so patients need to express or be asked about their symptoms and history. This approach sets the direction for tests and treatment plans. In GPT-4 generated dialogues, this format should be followed, but often, the physician character incorrectly presents this information first, which is not typical in real clinical settings (Example 5 of Table
     <a class="ltx_ref" href="#footnote17" title="footnote 17 ‣ Table 5 ‣ 4.4 Heuristic Evaluation with Experts ‣ 4 Human Evaluation ‣ NoteChat: A Dataset of Synthetic Patient-Physician Conversations Conditioned on Clinical Notes">
      <span class="ltx_text ltx_ref_tag">
       17
      </span>
     </a>
     ).
    </p>
   </div>
   <figure class="ltx_table" id="S4.T5">
    <div class="ltx_inline-block ltx_transformed_outer" id="S4.T5.1" style="width:217.2pt;height:30043.3pt;vertical-align:-0.0pt;">
     <span class="ltx_transformed_inner" style="transform:translate(-27.2pt,3755.4pt) scale(0.8,0.8) ;">
      <table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T5.1.1">
       <tbody class="ltx_tbody">
        <tr class="ltx_tr" id="S4.T5.1.1.1.1">
         <th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt" id="S4.T5.1.1.1.1.1" rowspan="2" style="padding-left:2.0pt;padding-right:2.0pt;">
          <span class="ltx_text" id="S4.T5.1.1.1.1.1.1">
           1
          </span>
         </th>
         <td class="ltx_td ltx_align_justify ltx_border_tt" id="S4.T5.1.1.1.1.2" style="padding-left:2.0pt;padding-right:2.0pt;">
          <span class="ltx_inline-block ltx_align_top" id="S4.T5.1.1.1.1.2.1">
           <span class="ltx_p" id="S4.T5.1.1.1.1.2.1.1">
            <span class="ltx_text ltx_font_bold" id="S4.T5.1.1.1.1.2.1.1.1">
             Some information in the note does not come from the conversation, so it is not necessary to mention it in the dialogue, such as dosage information.
            </span>
           </span>
          </span>
         </td>
        </tr>
        <tr class="ltx_tr" id="S4.T5.1.1.2.2">
         <td class="ltx_td ltx_align_justify" id="S4.T5.1.1.2.2.1" style="background-color:#F2F2F2;padding-left:2.0pt;padding-right:2.0pt;">
          <span class="ltx_inline-block ltx_align_top" id="S4.T5.1.1.2.2.1.1">
           <span class="ltx_p" id="S4.T5.1.1.2.2.1.1.1">
            <em class="ltx_emph ltx_font_italic" id="S4.T5.1.1.2.2.1.1.1.1" style="background-color:#F2F2F2;">
             Her medications were tab. vildagliptin/metformin (50/1000) (mg) BID, tab. amlodipine/valsartan (5/160) (mg) once daily, and tab. levothyroxine 75 mcg once daily …
            </em>
           </span>
          </span>
         </td>
        </tr>
        <tr class="ltx_tr" id="S4.T5.1.1.3.3">
         <th class="ltx_td ltx_th ltx_th_row" id="S4.T5.1.1.3.3.1" style="padding-left:2.0pt;padding-right:2.0pt;">
         </th>
         <td class="ltx_td ltx_align_justify" id="S4.T5.1.1.3.3.2" style="padding-left:2.0pt;padding-right:2.0pt;">
          <span class="ltx_inline-block ltx_align_top" id="S4.T5.1.1.3.3.2.1">
           <span class="ltx_p" id="S4.T5.1.1.3.3.2.1.1">
            (
            <span class="ltx_text ltx_font_italic" id="S4.T5.1.1.3.3.2.1.1.1" style="color:#FF0000;">
             GPT4
            </span>
            )
            <span class="ltx_text ltx_font_bold" id="S4.T5.1.1.3.3.2.1.1.2">
             Patient
            </span>
            : I take vildagliptin/metformin 50/1000 mg twice a day, amlodipine/valsartan 5/160 mg once daily, and levothyroxine 75 mcg once daily.
           </span>
          </span>
         </td>
        </tr>
        <tr class="ltx_tr" id="S4.T5.1.1.4.4">
         <th class="ltx_td ltx_th ltx_th_row" id="S4.T5.1.1.4.4.1" style="padding-left:2.0pt;padding-right:2.0pt;">
         </th>
         <td class="ltx_td ltx_align_justify" id="S4.T5.1.1.4.4.2" style="padding-left:2.0pt;padding-right:2.0pt;">
          <span class="ltx_inline-block ltx_align_top" id="S4.T5.1.1.4.4.2.1">
           <span class="ltx_p" id="S4.T5.1.1.4.4.2.1.1">
            (
            <span class="ltx_text ltx_font_italic" id="S4.T5.1.1.4.4.2.1.1.1" style="color:#0000FF;">
             NoteChat
            </span>
            )
            <span class="ltx_text ltx_font_bold" id="S4.T5.1.1.4.4.2.1.1.2">
             Patient
            </span>
            : I have arterial hypertension, diabetes, and hypothyroidism. I take vildagliptin/metformin, amlodipine/valsartan, and levothyroxine.
           </span>
          </span>
         </td>
        </tr>
        <tr class="ltx_tr" id="S4.T5.1.1.5.5">
         <th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T5.1.1.5.5.1" rowspan="2" style="padding-left:2.0pt;padding-right:2.0pt;">
          <span class="ltx_text" id="S4.T5.1.1.5.5.1.1">
           2
          </span>
         </th>
         <td class="ltx_td ltx_align_justify ltx_border_t" id="S4.T5.1.1.5.5.2" style="padding-left:2.0pt;padding-right:2.0pt;">
          <span class="ltx_inline-block ltx_align_top" id="S4.T5.1.1.5.5.2.1">
           <span class="ltx_p" id="S4.T5.1.1.5.5.2.1.1">
            <span class="ltx_text ltx_font_bold" id="S4.T5.1.1.5.5.2.1.1.1">
             Patients sometimes act too professionally.
            </span>
           </span>
          </span>
         </td>
        </tr>
        <tr class="ltx_tr" id="S4.T5.1.1.6.6">
         <td class="ltx_td ltx_align_justify" id="S4.T5.1.1.6.6.1" style="background-color:#F2F2F2;padding-left:2.0pt;padding-right:2.0pt;">
          <span class="ltx_inline-block ltx_align_top" id="S4.T5.1.1.6.6.1.1">
           <span class="ltx_p" id="S4.T5.1.1.6.6.1.1.1">
            <em class="ltx_emph ltx_font_italic" id="S4.T5.1.1.6.6.1.1.1.1" style="background-color:#F2F2F2;">
             Two months postoperatively, the patient came to our institution and underwent MRI for reevaluation of the cervical spine in three different positions: neutral, flexion, and extension. While neutral MRI did not show any significant stenosis, flexion and extension MRIs …
            </em>
           </span>
          </span>
         </td>
        </tr>
        <tr class="ltx_tr" id="S4.T5.1.1.7.7">
         <th class="ltx_td ltx_th ltx_th_row" id="S4.T5.1.1.7.7.1" style="padding-left:2.0pt;padding-right:2.0pt;">
         </th>
         <td class="ltx_td ltx_align_justify" id="S4.T5.1.1.7.7.2" style="padding-left:2.0pt;padding-right:2.0pt;">
          <span class="ltx_inline-block ltx_align_top" id="S4.T5.1.1.7.7.2.1">
           <span class="ltx_p" id="S4.T5.1.1.7.7.2.1.1">
            (
            <span class="ltx_text ltx_font_italic" id="S4.T5.1.1.7.7.2.1.1.1" style="color:#FF0000;">
             GPT4
            </span>
            )
            <span class="ltx_text ltx_font_bold" id="S4.T5.1.1.7.7.2.1.1.2">
             Patient
            </span>
            : The MRI was done in three different positions: neutral, flexion, and extension. The neutral position didn’t show any significant stenosis, but the flexion and extension MRIs showed cervical compression due to spondylosis…
           </span>
          </span>
         </td>
        </tr>
        <tr class="ltx_tr" id="S4.T5.1.1.8.8">
         <th class="ltx_td ltx_th ltx_th_row" id="S4.T5.1.1.8.8.1" style="padding-left:2.0pt;padding-right:2.0pt;">
         </th>
         <td class="ltx_td ltx_align_justify" id="S4.T5.1.1.8.8.2" style="padding-left:2.0pt;padding-right:2.0pt;">
          <span class="ltx_inline-block ltx_align_top" id="S4.T5.1.1.8.8.2.1">
           <span class="ltx_p" id="S4.T5.1.1.8.8.2.1.1">
            (
            <span class="ltx_text ltx_font_italic" id="S4.T5.1.1.8.8.2.1.1.1" style="color:#0000FF;">
             NoteChat
            </span>
            )
            <span class="ltx_text ltx_font_bold" id="S4.T5.1.1.8.8.2.1.1.2">
             physician:
            </span>
            Thank you. Let me review your medical history records. (physician reviews the medical history records) Based on your medical history records, it seems that the previous surgery did not completely resolve your symptoms. We will need to perform a reevaluation of your cervical spine to determine the cause of your symptoms..
            <span class="ltx_text ltx_font_bold" id="S4.T5.1.1.8.8.2.1.1.3">
             Patient:
            </span>
            Okay, I understand.
           </span>
          </span>
         </td>
        </tr>
        <tr class="ltx_tr" id="S4.T5.1.1.9.9">
         <th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T5.1.1.9.9.1" rowspan="2" style="padding-left:2.0pt;padding-right:2.0pt;">
          <span class="ltx_text" id="S4.T5.1.1.9.9.1.1">
           3
          </span>
         </th>
         <td class="ltx_td ltx_align_justify ltx_border_t" id="S4.T5.1.1.9.9.2" style="padding-left:2.0pt;padding-right:2.0pt;">
          <span class="ltx_inline-block ltx_align_top" id="S4.T5.1.1.9.9.2.1">
           <span class="ltx_p" id="S4.T5.1.1.9.9.2.1.1">
            <span class="ltx_text ltx_font_bold" id="S4.T5.1.1.9.9.2.1.1.1">
             Highly generalized sentences in notes tend to contain a lot of important information, but in dialogues, they are usually collected by multiple rounds.
            </span>
           </span>
          </span>
         </td>
        </tr>
        <tr class="ltx_tr" id="S4.T5.1.1.10.10">
         <td class="ltx_td ltx_align_justify" id="S4.T5.1.1.10.10.1" style="background-color:#F2F2F2;padding-left:2.0pt;padding-right:2.0pt;">
          <span class="ltx_inline-block ltx_align_top" id="S4.T5.1.1.10.10.1.1">
           <span class="ltx_p" id="S4.T5.1.1.10.10.1.1.1">
            <em class="ltx_emph ltx_font_italic" id="S4.T5.1.1.10.10.1.1.1.1" style="background-color:#F2F2F2;">
             Her diagnosis at admission included a gallstone, acute attack of chronic cholecystitis, biliary pancreatitis, septic shock, and multiple organ dysfunction syndrome …
            </em>
           </span>
          </span>
         </td>
        </tr>
        <tr class="ltx_tr" id="S4.T5.1.1.11.11">
         <th class="ltx_td ltx_th ltx_th_row" id="S4.T5.1.1.11.11.1" style="padding-left:2.0pt;padding-right:2.0pt;">
         </th>
         <td class="ltx_td ltx_align_justify" id="S4.T5.1.1.11.11.2" style="padding-left:2.0pt;padding-right:2.0pt;">
          <span class="ltx_inline-block ltx_align_top" id="S4.T5.1.1.11.11.2.1">
           <span class="ltx_p" id="S4.T5.1.1.11.11.2.1.1">
            (
            <span class="ltx_text ltx_font_italic" id="S4.T5.1.1.11.11.2.1.1.1" style="color:#FF0000;">
             GPT4
            </span>
            )
            <span class="ltx_text ltx_font_bold" id="S4.T5.1.1.11.11.2.1.1.2">
             physician
            </span>
            : So, I see from your chart that you were admitted with a gallstone, acute attack of chronic cholecystitis, biliary pancreatitis, septic shock, and multiple organ dysfunction syndrome. Can you tell me more about your symptoms?
            <span class="ltx_text ltx_font_bold" id="S4.T5.1.1.11.11.2.1.1.3">
             Patient
            </span>
            : Well, I had severe abdominal pain and vomiting.
           </span>
          </span>
         </td>
        </tr>
        <tr class="ltx_tr" id="S4.T5.1.1.12.12">
         <th class="ltx_td ltx_th ltx_th_row" id="S4.T5.1.1.12.12.1" style="padding-left:2.0pt;padding-right:2.0pt;">
         </th>
         <td class="ltx_td ltx_align_justify" id="S4.T5.1.1.12.12.2" style="padding-left:2.0pt;padding-right:2.0pt;">
          <span class="ltx_inline-block ltx_align_top" id="S4.T5.1.1.12.12.2.1">
           <span class="ltx_p" id="S4.T5.1.1.12.12.2.1.1">
            (
            <span class="ltx_text ltx_font_italic" id="S4.T5.1.1.12.12.2.1.1.1" style="color:#0000FF;">
             NoteChat
            </span>
            )
            <span class="ltx_text ltx_font_bold" id="S4.T5.1.1.12.12.2.1.1.2">
             physician:
            </span>
            Great, I appreciate your cooperation. Now, could you please provide me with your medical history records?
            <span class="ltx_text ltx_font_bold" id="S4.T5.1.1.12.12.2.1.1.3">
             Patient:
            </span>
            Sure, here they are.
            <span class="ltx_text ltx_font_bold" id="S4.T5.1.1.12.12.2.1.1.4">
             physician:
            </span>
            Thank you. Based on your medical history records, it seems that you were admitted with a diagnosis of a gallstone, an acute attack of chronic cholecystitis, biliary pancreatitis…
           </span>
          </span>
         </td>
        </tr>
        <tr class="ltx_tr" id="S4.T5.1.1.13.13">
         <th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T5.1.1.13.13.1" rowspan="2" style="padding-left:2.0pt;padding-right:2.0pt;">
          <span class="ltx_text" id="S4.T5.1.1.13.13.1.1">
           4
          </span>
         </th>
         <td class="ltx_td ltx_align_justify ltx_border_t" id="S4.T5.1.1.13.13.2" style="padding-left:2.0pt;padding-right:2.0pt;">
          <span class="ltx_inline-block ltx_align_top" id="S4.T5.1.1.13.13.2.1">
           <span class="ltx_p" id="S4.T5.1.1.13.13.2.1.1">
            <span class="ltx_text ltx_font_bold" id="S4.T5.1.1.13.13.2.1.1.1">
             The logic of the different roles in the dialogue. It is necessary to distinguish which information will be advanced by the physician and which information will be provided by the patient.
            </span>
           </span>
          </span>
         </td>
        </tr>
        <tr class="ltx_tr" id="S4.T5.1.1.14.14">
         <td class="ltx_td ltx_align_justify" id="S4.T5.1.1.14.14.1" style="background-color:#F2F2F2;padding-left:2.0pt;padding-right:2.0pt;">
          <span class="ltx_inline-block ltx_align_top" id="S4.T5.1.1.14.14.1.1">
           <span class="ltx_p" id="S4.T5.1.1.14.14.1.1.1">
            <em class="ltx_emph ltx_font_italic" id="S4.T5.1.1.14.14.1.1.1.1" style="background-color:#F2F2F2;">
             A 66-year-old woman presented at the emergency department of our hospital complaining of sudden onset dizziness and fatigue over the past thirty minutes. Before her arrival, she was at home relaxing and not engaged in any physical activity …
            </em>
           </span>
          </span>
         </td>
        </tr>
        <tr class="ltx_tr" id="S4.T5.1.1.15.15">
         <th class="ltx_td ltx_th ltx_th_row" id="S4.T5.1.1.15.15.1" style="padding-left:2.0pt;padding-right:2.0pt;">
         </th>
         <td class="ltx_td ltx_align_justify" id="S4.T5.1.1.15.15.2" style="padding-left:2.0pt;padding-right:2.0pt;">
          <span class="ltx_inline-block ltx_align_top" id="S4.T5.1.1.15.15.2.1">
           <span class="ltx_p" id="S4.T5.1.1.15.15.2.1.1">
            (
            <span class="ltx_text ltx_font_italic" id="S4.T5.1.1.15.15.2.1.1.1" style="color:#FF0000;">
             GPT4
            </span>
            )
            <span class="ltx_text ltx_font_bold" id="S4.T5.1.1.15.15.2.1.1.2">
             Patient
            </span>
            : Hi, physician. About thirty minutes ago, I suddenly started feeling dizzy and fatigued while I was at home relaxing.
            <span class="ltx_text" id="S4.T5.1.1.15.15.2.1.1.3" style="color:#FF8000;">
             I wasn’t even engaged in any physical activity.
            </span>
            <span class="ltx_text ltx_font_bold" id="S4.T5.1.1.15.15.2.1.1.4">
             physician
            </span>
            : I see. Can you please tell me about your past medical history?
           </span>
          </span>
         </td>
        </tr>
        <tr class="ltx_tr" id="S4.T5.1.1.16.16">
         <th class="ltx_td ltx_th ltx_th_row" id="S4.T5.1.1.16.16.1" style="padding-left:2.0pt;padding-right:2.0pt;">
         </th>
         <td class="ltx_td ltx_align_justify" id="S4.T5.1.1.16.16.2" style="padding-left:2.0pt;padding-right:2.0pt;">
          <span class="ltx_inline-block ltx_align_top" id="S4.T5.1.1.16.16.2.1">
           <span class="ltx_p" id="S4.T5.1.1.16.16.2.1.1">
            (
            <span class="ltx_text ltx_font_italic" id="S4.T5.1.1.16.16.2.1.1.1" style="color:#0000FF;">
             NoteChat
            </span>
            )
            <span class="ltx_text ltx_font_bold" id="S4.T5.1.1.16.16.2.1.1.2">
             physician
            </span>
            : I see. Can you tell me more about your symptoms?
            <span class="ltx_text" id="S4.T5.1.1.16.16.2.1.1.3" style="color:#FF8000;">
             Were you relaxing or engaged in any physical activity before the symptoms occurred?
            </span>
            <span class="ltx_text ltx_font_bold" id="S4.T5.1.1.16.16.2.1.1.4">
             Patient
            </span>
            : I was just at home relaxing before the symptoms started.
           </span>
          </span>
         </td>
        </tr>
        <tr class="ltx_tr" id="S4.T5.1.1.17.17">
         <th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T5.1.1.17.17.1" rowspan="2" style="padding-left:2.0pt;padding-right:2.0pt;">
          <span class="ltx_text" id="S4.T5.1.1.17.17.1.1">
           5
          </span>
         </th>
         <td class="ltx_td ltx_align_justify ltx_border_t" id="S4.T5.1.1.17.17.2" style="padding-left:2.0pt;padding-right:2.0pt;">
          <span class="ltx_inline-block ltx_align_top" id="S4.T5.1.1.17.17.2.1">
           <span class="ltx_p" id="S4.T5.1.1.17.17.2.1.1">
            <span class="ltx_text ltx_font_bold" id="S4.T5.1.1.17.17.2.1.1.1">
             NoteChat handles the beginning of the conversation more naturally. So experts prefer NoteChat when other aspects of quality are similar.
            </span>
           </span>
          </span>
         </td>
        </tr>
        <tr class="ltx_tr" id="S4.T5.1.1.18.18">
         <td class="ltx_td ltx_align_justify" id="S4.T5.1.1.18.18.1" style="background-color:#F2F2F2;padding-left:2.0pt;padding-right:2.0pt;">
          <span class="ltx_inline-block ltx_align_top" id="S4.T5.1.1.18.18.1.1">
           <span class="ltx_p" id="S4.T5.1.1.18.18.1.1.1">
            <em class="ltx_emph ltx_font_italic" id="S4.T5.1.1.18.18.1.1.1.1" style="background-color:#F2F2F2;">
             A 71-year-old man with a history of atrial fibrillation, acute appendicitis, and early esophageal cancer treated with endoscopic submucosal dissection underwent distal pancreatectomy …
            </em>
           </span>
          </span>
         </td>
        </tr>
        <tr class="ltx_tr" id="S4.T5.1.1.19.19">
         <th class="ltx_td ltx_th ltx_th_row" id="S4.T5.1.1.19.19.1" style="padding-left:2.0pt;padding-right:2.0pt;">
         </th>
         <td class="ltx_td ltx_align_justify" id="S4.T5.1.1.19.19.2" style="padding-left:2.0pt;padding-right:2.0pt;">
          <span class="ltx_inline-block ltx_align_top" id="S4.T5.1.1.19.19.2.1">
           <span class="ltx_p" id="S4.T5.1.1.19.19.2.1.1">
            (
            <span class="ltx_text ltx_font_italic" id="S4.T5.1.1.19.19.2.1.1.1" style="color:#FF0000;">
             GPT4
            </span>
            )
            <span class="ltx_text ltx_font_bold" id="S4.T5.1.1.19.19.2.1.1.2">
             physician:
            </span>
            Hello, I see from your history that you have atrial fibrillation, acute appendicitis, and early esophageal cancer. You were treated with endoscopic submucosal dissection for esophageal cancer, correct?
            <span class="ltx_text ltx_font_bold" id="S4.T5.1.1.19.19.2.1.1.3">
             Patient
            </span>
            : Yes, that’s right.
           </span>
          </span>
         </td>
        </tr>
        <tr class="ltx_tr" id="S4.T5.1.1.20.20">
         <th class="ltx_td ltx_th ltx_th_row ltx_border_bb" id="S4.T5.1.1.20.20.1" style="padding-left:2.0pt;padding-right:2.0pt;">
         </th>
         <td class="ltx_td ltx_align_justify ltx_border_bb" id="S4.T5.1.1.20.20.2" style="padding-left:2.0pt;padding-right:2.0pt;">
          <span class="ltx_inline-block ltx_align_top" id="S4.T5.1.1.20.20.2.1">
           <span class="ltx_p" id="S4.T5.1.1.20.20.2.1.1">
            (
            <span class="ltx_text ltx_font_italic" id="S4.T5.1.1.20.20.2.1.1.1" style="color:#0000FF;">
             NoteChat
            </span>
            )
            <span class="ltx_text ltx_font_bold" id="S4.T5.1.1.20.20.2.1.1.2">
             Patient:
            </span>
            physician, hello. I have an irregular posterior wall and a submucosal tumor in the anterior wall of my gastric antrum.
            <span class="ltx_text ltx_font_bold" id="S4.T5.1.1.20.20.2.1.1.3">
             physician:
            </span>
            Can you give me your medical records?
            <span class="ltx_text ltx_font_bold" id="S4.T5.1.1.20.20.2.1.1.4">
             Patient:
            </span>
            Here you go.
           </span>
          </span>
         </td>
        </tr>
       </tbody>
      </table>
     </span>
    </div>
    <figcaption class="ltx_caption">
     <span class="ltx_tag ltx_tag_table">
      Table 5:
     </span>
     Expert evaluation case study
     <span class="ltx_note ltx_role_footnote" id="footnote17">
      <sup class="ltx_note_mark">
       17
      </sup>
      <span class="ltx_note_outer">
       <span class="ltx_note_content">
        <sup class="ltx_note_mark">
         17
        </sup>
        <span class="ltx_tag ltx_tag_note">
         17
        </span>
        Due to the obvious gap in factuality of ChatGPT, our cases focus on the difference between NoteChat and GPT4.
       </span>
      </span>
     </span>
     .
    </figcaption>
   </figure>
  </section>
 </section>
 <section class="ltx_section" id="S5">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    5
   </span>
   Related Work
  </h2>
  <div class="ltx_para" id="S5.p1">
   <p class="ltx_p" id="S5.p1.1">
    <span class="ltx_text ltx_font_bold" id="S5.p1.1.1">
     Clinical note and conversations generation:
    </span>
    A task closely related to our work, but with an inverse direction, is the automatic generation of clinical notes from patient-physician conversations
    <cite class="ltx_cite ltx_citemacro_cite">
     Krishna et al. (
     <a class="ltx_ref" href="#bib.bib29" title="">
      2020
     </a>
     ); Song et al. (
     <a class="ltx_ref" href="#bib.bib51" title="">
      2020
     </a>
     ); Yim and Yetisgen-Yildiz (
     <a class="ltx_ref" href="#bib.bib63" title="">
      2021
     </a>
     ); Su et al. (
     <a class="ltx_ref" href="#bib.bib52" title="">
      2022
     </a>
     ); Yao et al. (
     <a class="ltx_ref" href="#bib.bib59" title="">
      2023a
     </a>
     )
    </cite>
    .
Recently, the MEDIQA-Chat 2023
    <span class="ltx_note ltx_role_footnote" id="footnote18">
     <sup class="ltx_note_mark">
      18
     </sup>
     <span class="ltx_note_outer">
      <span class="ltx_note_content">
       <sup class="ltx_note_mark">
        18
       </sup>
       <span class="ltx_tag ltx_tag_note">
        18
       </span>
       https://sites.google.com/view/mediqa2023
      </span>
     </span>
    </span>
    introduced tasks in both directions (Dialogue2Note Summarization and Note2Dialogue Generation).
However, their dataset is either private or limited to less than 2k examples.
One of the main themes of recent data-centric AI is the synthetic data to overcome privacy concerns
    <cite class="ltx_cite ltx_citemacro_cite">
     Pereira et al. (
     <a class="ltx_ref" href="#bib.bib42" title="">
      2022
     </a>
     ); Shafquat et al. (
     <a class="ltx_ref" href="#bib.bib48" title="">
      2022
     </a>
     ); Mishra et al. (
     <a class="ltx_ref" href="#bib.bib38" title="">
      2023
     </a>
     )
    </cite>
    .
To the best of our knowledge, we are the first to introduce a large-scale publicly available patient-physician conversation dataset in English, each accompanied by corresponding medical documents, with an average number of utterances exceeding 20 rounds.
In addition, our extrinsic eval shows that the NoteChat can be used as auxiliary data for Conversation2Note or Note2Conversation tasks and can also be used as a synthetic medical dialogue dataset alone to engage patients directly and help clinical documentation
    <cite class="ltx_cite ltx_citemacro_cite">
     Zhang et al. (
     <a class="ltx_ref" href="#bib.bib67" title="">
      2023
     </a>
     ); Li et al. (
     <a class="ltx_ref" href="#bib.bib33" title="">
      2023b
     </a>
     ); Wang et al. (
     <a class="ltx_ref" href="#bib.bib57" title="">
      2023
     </a>
     ); Liu et al. (
     <a class="ltx_ref" href="#bib.bib35" title="">
      2023a
     </a>
     ); Xiong et al. (
     <a class="ltx_ref" href="#bib.bib58" title="">
      2023
     </a>
     ); Zeng et al. (
     <a class="ltx_ref" href="#bib.bib66" title="">
      2020
     </a>
     )
    </cite>
    .
   </p>
  </div>
  <div class="ltx_para ltx_noindent" id="S5.p2">
   <p class="ltx_p" id="S5.p2.1">
    <span class="ltx_text ltx_font_bold" id="S5.p2.1.1">
     Multiple LLMs cooperation:
    </span>
    Our work builds upon the recent advances in deploying two LLMs as cooperative agents
    <cite class="ltx_cite ltx_citemacro_citep">
     (Panait and Luke,
     <a class="ltx_ref" href="#bib.bib41" title="">
      2005
     </a>
     )
    </cite>
    for multi-round conversation generation.
In particular, NoteChat is inspired by CAMEL
    <cite class="ltx_cite ltx_citemacro_citep">
     (Li et al.,
     <a class="ltx_ref" href="#bib.bib32" title="">
      2023a
     </a>
     )
    </cite>
    , which assigns roles to two LLMs (e.g. student and teacher) in order to facilitate conversation between the two agents for a particular task (e.g. teaching). Similar to CAMEL’s findings, we found that roleplay by itself may hallucinate
or generate fake replies that repeat most of the previous utterances. To solve this issue, we proposed a novel Planning module to ground agents to certain keywords.
    <cite class="ltx_cite ltx_citemacro_citet">
     Cho et al. (
     <a class="ltx_ref" href="#bib.bib13" title="">
      2023
     </a>
     )
    </cite>
    also addresses the challenges of using LLM to craft a dialogue dataset with specified personas. They emphasize the importance of grounding and context in conversation generation. Similarly, NoteChat relies on structured clinical notes segmented using the SOAP format to provide context for our dialogue synthesis to diagnose a patient. However, their work is limited to generating open-domain dialogue, while we focus on task-oriented dialogue.
   </p>
  </div>
 </section>
 <section class="ltx_section" id="S6">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    6
   </span>
   Conclusion
  </h2>
  <div class="ltx_para" id="S6.p1">
   <p class="ltx_p" id="S6.p1.1">
    In this study, we present
    <em class="ltx_emph ltx_font_bold ltx_font_italic" id="S6.p1.1.1">
     NoteChat
    </em>
    , a cooperative multi-agent framework leveraging LLMs for generating synthetic patient-physician conversations conditioned on clinical notes. NoteChat consists of Planning, Roleplay, and Polish modules. Extensive evaluations demonstrate that NoteChat facilitates high-quality synthetic patient-physician conversations, underscoring the untapped potential of LLMs in healthcare and offering promising avenues for the intersection of AI and healthcare.
   </p>
  </div>
 </section>
 <section class="ltx_section" id="S7">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    7
   </span>
   Limitations and Ethical Considerations
  </h2>
  <div class="ltx_para" id="S7.p1">
   <p class="ltx_p" id="S7.p1.1">
    This study offers valuable insights, but with a few limitations, we would like to note.
   </p>
  </div>
  <div class="ltx_para" id="S7.p2">
   <p class="ltx_p" id="S7.p2.1">
    Due to cost and time constraints, we could not try out many possibilities and alternatives in this paper. First of all, the current amount of data for human evaluation is not particularly sufficient. We are conducting more human evaluations. Secondly, due to cost issues, we currently do not use GPT-4 extensively to try the NoteChat pipeline. When OpenAI updates the Stateful API
    <span class="ltx_note ltx_role_footnote" id="footnote19">
     <sup class="ltx_note_mark">
      19
     </sup>
     <span class="ltx_note_outer">
      <span class="ltx_note_content">
       <sup class="ltx_note_mark">
        19
       </sup>
       <span class="ltx_tag ltx_tag_note">
        19
       </span>
       https://www.reuters.com/technology/openai-plans-major-updates-lure-developers-with-lower-costs-sources-2023-10-11/
      </span>
     </span>
    </span>
    , we will use this version to generate NoteChat-GPT4. Third, we extracted relevant UMLS-CUI codes for our Planning module, aiming to guide subsequent conversations around these critical terms. Such a checklist can help our pipeline improve factuality
    <cite class="ltx_cite ltx_citemacro_cite">
     Asai et al. (
     <a class="ltx_ref" href="#bib.bib7" title="">
      2023
     </a>
     ); Huang et al. (
     <a class="ltx_ref" href="#bib.bib25" title="">
      2023
     </a>
     )
    </cite>
    , and can be very flexibly combined with other tools to meet different purposes, like information retrieval
    <cite class="ltx_cite ltx_citemacro_cite">
     Khattab et al. (
     <a class="ltx_ref" href="#bib.bib28" title="">
      2022
     </a>
     )
    </cite>
    , entity&amp;relation extraction
    <cite class="ltx_cite ltx_citemacro_cite">
     Cai et al. (
     <a class="ltx_ref" href="#bib.bib11" title="">
      2023
     </a>
     )
    </cite>
    , medical jargon extraction
    <cite class="ltx_cite ltx_citemacro_cite">
     Kwon et al. (
     <a class="ltx_ref" href="#bib.bib30" title="">
      2022
     </a>
     )
    </cite>
    , causal inference
    <cite class="ltx_cite ltx_citemacro_cite">
     Yuan et al. (
     <a class="ltx_ref" href="#bib.bib64" title="">
      2023
     </a>
     )
    </cite>
    , evidence and reasoning path retrieval
    <cite class="ltx_cite ltx_citemacro_cite">
     Asai et al. (
     <a class="ltx_ref" href="#bib.bib6" title="">
      2019
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib5" title="">
      2021
     </a>
     )
    </cite>
    , and many other knowledge injection ideas
    <cite class="ltx_cite ltx_citemacro_cite">
     Fei et al. (
     <a class="ltx_ref" href="#bib.bib18" title="">
      2021
     </a>
     ); Yao and Yu (
     <a class="ltx_ref" href="#bib.bib61" title="">
      2021
     </a>
     ); Yao et al. (
     <a class="ltx_ref" href="#bib.bib60" title="">
      2023b
     </a>
     )
    </cite>
    .
   </p>
  </div>
  <div class="ltx_para" id="S7.p3">
   <p class="ltx_p" id="S7.p3.1">
    Consider Privacy Implications, LLMs can present privacy concerns in using clinical notes to generate patient-physician conversation, potentially violating HIPAA regulations. However, in this study, all experiments were sourced from publicly available real patient data collected from research articles with at least CC BY-NC-SA license. We also present an approach for generating synthetic conversations from case reports in the PubMed Central repository.
   </p>
  </div>
  <div class="ltx_para" id="S7.p4">
   <p class="ltx_p" id="S7.p4.1">
    Consider Biases, LLMs trained on vast amounts of text data may inadvertently capture and reproduce biases present in the data. For example, they may prefer certain questions related to Metformin or link particular health conditions to specific populations. Thus the physician bot trained from our synthetic data may perpetuate incorrect information or provide inaccurate answers. Moreover, the case reports used to generate synthetic conversations usually focus on unusual observations and rare conditions. Thus the physician bot may hallucinate or overtreat patients with common diseases.
   </p>
  </div>
  <div class="ltx_para" id="S7.p5">
   <p class="ltx_p" id="S7.p5.1">
    Considering Broader Impacts, we have performed a preliminary study to generate synthetic conversation from case reports within research articles indexed from January 2002 to July 2022 by PubMed Central. The credibility of these case reports is ensured as they are peer-reviewed and published in academic journals. Moreover, the type of disease is diverse as they are sourced from various hospital departments and are not limited to intensive care units (such as MIMIC). Thus, models trained using our synthetic data may benefit from these characteristics.
   </p>
  </div>
 </section>
 <section class="ltx_bibliography" id="bib">
  <h2 class="ltx_title ltx_title_bibliography">
   References
  </h2>
  <ul class="ltx_biblist">
   <li class="ltx_bibitem" id="bib.bib1">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Abacha et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Asma Ben Abacha, Wen-wai Yim, Yadan Fan, and Thomas Lin. 2023.
    </span>
    <span class="ltx_bibblock">
     An empirical study of clinical note generation from doctor-patient
encounters.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">
      Proceedings of the 17th Conference of the European Chapter
of the Association for Computational Linguistics
     </em>
     , pages 2283–2294.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib2">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Abacha and Zweigenbaum (2015)
    </span>
    <span class="ltx_bibblock">
     Asma Ben Abacha and Pierre Zweigenbaum. 2015.
    </span>
    <span class="ltx_bibblock">
     Means: A medical question-answering system combining nlp techniques
and semantic web technologies.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">
      Information processing &amp; management
     </em>
     , 51(5):570–594.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib3">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Adams et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Griffin Adams, Jason Zucker, and Noémie Elhadad. 2023.
    </span>
    <span class="ltx_bibblock">
     A meta-evaluation of faithfulness metrics for long-form
hospital-course summarization.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">
      arXiv preprint arXiv:2303.03948
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib4">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Annas (2003)
    </span>
    <span class="ltx_bibblock">
     George J Annas. 2003.
    </span>
    <span class="ltx_bibblock">
     Hipaa regulations: a new era of medical-record privacy?
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">
      New England Journal of Medicine
     </em>
     , 348:1486.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib5">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Asai et al. (2021)
    </span>
    <span class="ltx_bibblock">
     Akari Asai, Matt Gardner, and Hannaneh Hajishirzi. 2021.
    </span>
    <span class="ltx_bibblock">
     Evidentiality-guided generation for knowledge-intensive nlp tasks.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">
      arXiv preprint arXiv:2112.08688
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib6">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Asai et al. (2019)
    </span>
    <span class="ltx_bibblock">
     Akari Asai, Kazuma Hashimoto, Hannaneh Hajishirzi, Richard Socher, and Caiming
Xiong. 2019.
    </span>
    <span class="ltx_bibblock">
     Learning to retrieve reasoning paths over wikipedia graph for
question answering.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">
      arXiv preprint arXiv:1911.10470
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib7">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Asai et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Akari Asai, Sewon Min, Zexuan Zhong, and Danqi Chen. 2023.
    </span>
    <span class="ltx_bibblock">
     Retrieval-based language models and applications.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">
      Proceedings of the 61st Annual Meeting of the Association
for Computational Linguistics (Volume 6: Tutorial Abstracts)
     </em>
     , pages 41–46.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib8">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Ben Abacha et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Asma Ben Abacha, Wen-wai Yim, Griffin Adams, Neal Snider, and Meliha
Yetisgen. 2023.
    </span>
    <span class="ltx_bibblock">
     Overview of the mediqa-chat 2023 shared tasks on the summarization
and generation of doctor-patient conversations.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">
      ACL-ClinicalNLP 2023
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib9">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Brown et al. (2020)
    </span>
    <span class="ltx_bibblock">
     Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan,
Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda
Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan,
Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter,
Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray,
Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford,
Ilya Sutskever, and Dario Amodei. 2020.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="https://proceedings.neurips.cc/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf" target="_blank" title="">
      Language models are few-shot learners
     </a>
     .
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">
      Advances in Neural Information Processing Systems
     </em>
     ,
volume 33, pages 1877–1901.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib10">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Budd (2023)
    </span>
    <span class="ltx_bibblock">
     Jeffrey Budd. 2023.
    </span>
    <span class="ltx_bibblock">
     Burnout related to electronic health record use in primary care.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">
      Journal of Primary Care &amp; Community Health
     </em>
     ,
14:21501319231166921.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib11">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Cai et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Pengshan Cai, Zonghai Yao, Fei Liu, Dakuo Wang, Meghan Reilly, Huixue Zhou,
Lingxi Li, Yi Cao, Alok Kapoor, Adarsha Bajracharya, et al. 2023.
    </span>
    <span class="ltx_bibblock">
     Paniniqa: Enhancing patient education through interactive question
answering.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">
      arXiv preprint arXiv:2308.03253
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib12">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Chiang et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Wei-Lin Chiang, Zhuohan Li, Zi Lin, Ying Sheng, Zhanghao Wu, Hao Zhang, Lianmin
Zheng, Siyuan Zhuang, Yonghao Zhuang, Joseph E. Gonzalez, Ion Stoica, and
Eric P. Xing. 2023.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="https://vicuna.lmsys.org" target="_blank" title="">
      Vicuna: An open-source chatbot
impressing gpt-4 with 90%* chatgpt quality
     </a>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib13">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Cho et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Won Ik Cho, Yoon Kyung Lee, Seoyeon Bae, Ji-Hwan Kim, Sangah Nancy Park,
Moosung Kim, Sowon Hahn, and Nam Soo Kim. 2023.
    </span>
    <span class="ltx_bibblock">
     When crowd meets persona: Creating a large-scale open-domain persona
dialogue corpus.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">
      ArXiv
     </em>
     , abs/2304.00350.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib14">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Cobbe et al. (2021)
    </span>
    <span class="ltx_bibblock">
     Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz
Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano,
et al. 2021.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2110.14168" target="_blank" title="">
      Training verifiers to solve
math word problems
     </a>
     .
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">
      ArXiv preprint
     </em>
     , abs/2110.14168.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib15">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Dave et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Tirth Dave, Sai Anirudh Athaluri, and Satyam Singh. 2023.
    </span>
    <span class="ltx_bibblock">
     Chatgpt in medicine: an overview of its applications, advantages,
limitations, future prospects, and ethical considerations.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">
      Frontiers in Artificial Intelligence
     </em>
     , 6:1169595.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib16">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Drew et al. (2001)
    </span>
    <span class="ltx_bibblock">
     Paul Drew, John Chatwin, and Sarah Collins. 2001.
    </span>
    <span class="ltx_bibblock">
     Conversation analysis: a method for research into interactions
between patients and health-care professionals.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">
      Health Expectations
     </em>
     , 4(1):58–70.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib17">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Eyre et al. (2021)
    </span>
    <span class="ltx_bibblock">
     H. Eyre, A. B. Chapman, K. S. Peterson, J. Shi, P. R. Alba, M. M. Jones, T. L.
Box, S. L. DuVall, and O. V. Patterson. 2021.
    </span>
    <span class="ltx_bibblock">
     Launching into clinical space with medspaCy: a new clinical text
processing toolkit in Python.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">
      AMIA Annu Symp Proc
     </em>
     , 2021:438–447.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib18">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Fei et al. (2021)
    </span>
    <span class="ltx_bibblock">
     Hao Fei, Yafeng Ren, Yue Zhang, Donghong Ji, and Xiaohui Liang. 2021.
    </span>
    <span class="ltx_bibblock">
     Enriching contextualized language model from knowledge graph for
biomedical information extraction.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">
      Briefings in bioinformatics
     </em>
     , 22(3):bbaa110.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib19">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     First et al. (2013)
    </span>
    <span class="ltx_bibblock">
     Lewis R First, Humayun J Chaudhry, and Donald E Melnick. 2013.
    </span>
    <span class="ltx_bibblock">
     Quality, cost, and value of clinical skills assessment.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">
      New England Journal of Medicine
     </em>
     , 368(10):963–964.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib20">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Fu et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Jinlan Fu, See-Kiong Ng, Zhengbao Jiang, and Pengfei Liu. 2023.
    </span>
    <span class="ltx_bibblock">
     Gptscore: Evaluate as you desire.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">
      arXiv preprint arXiv:2302.04166
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib21">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Gabriel et al. (2021)
    </span>
    <span class="ltx_bibblock">
     Saadia Gabriel, Antoine Bosselut, Jeff Da, Ari Holtzman, Jan Buys, Kyle Lo,
Asli Celikyilmaz, and Yejin Choi. 2021.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2021.eacl-main.34" target="_blank" title="">
      Discourse
understanding and factual consistency in abstractive summarization
     </a>
     .
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">
      Proceedings of the 16th Conference of the European Chapter
of the Association for Computational Linguistics: Main Volume
     </em>
     , pages
435–447, Online. Association for Computational Linguistics.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib22">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Gao et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Mingqi Gao, Jie Ruan, Renliang Sun, Xunjian Yin, Shiping Yang, and Xiaojun Wan.
2023.
    </span>
    <span class="ltx_bibblock">
     Human-like summarization evaluation with chatgpt.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">
      arXiv preprint arXiv:2304.02554
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib23">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Gilson et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Aidan Gilson, Conrad W Safranek, Thomas Huang, Vimig Socrates, Ling Chi,
Richard Andrew Taylor, David Chartash, et al. 2023.
    </span>
    <span class="ltx_bibblock">
     How does chatgpt perform on the united states medical licensing
examination? the implications of large language models for medical education
and knowledge assessment.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">
      JMIR Medical Education
     </em>
     , 9(1):e45312.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib24">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Goyal et al. (2022)
    </span>
    <span class="ltx_bibblock">
     Tanya Goyal, Junyi Jessy Li, and Greg Durrett. 2022.
    </span>
    <span class="ltx_bibblock">
     News summarization and evaluation in the era of gpt-3.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">
      arXiv preprint arXiv:2209.12356
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib25">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Huang et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Lei Huang, Weijiang Yu, Weitao Ma, Weihong Zhong, Zhangyin Feng, Haotian Wang,
Qianglong Chen, Weihua Peng, Xiaocheng Feng, Bing Qin, and Ting Liu. 2023.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="https://api.semanticscholar.org/CorpusID:265067168" target="_blank" title="">
      A survey
on hallucination in large language models: Principles, taxonomy, challenges,
and open questions
     </a>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib26">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Jiang et al. (2022)
    </span>
    <span class="ltx_bibblock">
     Dongfu Jiang, Bill Yuchen Lin, and Xiang Ren. 2022.
    </span>
    <span class="ltx_bibblock">
     Pairreranker: Pairwise reranking for natural language generation.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib26.1.1">
      arXiv preprint arXiv:2212.10555
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib27">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Johnson (2003)
    </span>
    <span class="ltx_bibblock">
     Hillary Johnson. 2003.
    </span>
    <span class="ltx_bibblock">
     A critical review of standardized patient examinations as part of the
usmle.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">
      AMA Journal of Ethics
     </em>
     , 5(12):426–429.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib28">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Khattab et al. (2022)
    </span>
    <span class="ltx_bibblock">
     Omar Khattab, Keshav Santhanam, Xiang Lisa Li, David Hall, Percy Liang,
Christopher Potts, and Matei Zaharia. 2022.
    </span>
    <span class="ltx_bibblock">
     Demonstrate-search-predict: Composing retrieval and language models
for knowledge-intensive nlp.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib28.1.1">
      arXiv preprint arXiv:2212.14024
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib29">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Krishna et al. (2020)
    </span>
    <span class="ltx_bibblock">
     Kundan Krishna, Sopan Khosla, Jeffrey P Bigham, and Zachary C Lipton. 2020.
    </span>
    <span class="ltx_bibblock">
     Generating soap notes from doctor-patient conversations using modular
summarization techniques.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib29.1.1">
      arXiv preprint arXiv:2005.01795
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib30">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Kwon et al. (2022)
    </span>
    <span class="ltx_bibblock">
     Sunjae Kwon, Zonghai Yao, Harmon S Jordan, David A Levy, Brian Corner, and Hong
Yu. 2022.
    </span>
    <span class="ltx_bibblock">
     Medjex: A medical jargon extraction model with wiki’s hyperlink span
and contextualized masked language model score.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib30.1.1">
      arXiv preprint arXiv:2210.05875
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib31">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Ladhak et al. (2022)
    </span>
    <span class="ltx_bibblock">
     Faisal Ladhak, Esin Durmus, He He, Claire Cardie, and Kathleen McKeown. 2022.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2022.acl-long.100" target="_blank" title="">
      Faithful or
extractive? on mitigating the faithfulness-abstractiveness trade-off in
abstractive summarization
     </a>
     .
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib31.1.1">
      Proceedings of the 60th Annual Meeting of the Association
for Computational Linguistics (Volume 1: Long Papers)
     </em>
     , pages 1410–1421,
Dublin, Ireland. Association for Computational Linguistics.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib32">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Li et al. (2023a)
    </span>
    <span class="ltx_bibblock">
     G. Li, Hasan Abed Al Kader Hammoud, Hani Itani, Dmitrii Khizbullin, and Bernard
Ghanem. 2023a.
    </span>
    <span class="ltx_bibblock">
     Camel: Communicative agents for "mind" exploration of large scale
language model society.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib32.1.1">
      ArXiv
     </em>
     , abs/2303.17760.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib33">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Li et al. (2023b)
    </span>
    <span class="ltx_bibblock">
     Jianquan Li, Xidong Wang, Xiangbo Wu, Zhiyi Zhang, Xiaolong Xu, Jie Fu, Prayag
Tiwari, Xiang Wan, and Benyou Wang. 2023b.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2305.01526" target="_blank" title="">
      Huatuo-26m, a large-scale
chinese medical qa dataset
     </a>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib34">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Lin (2004)
    </span>
    <span class="ltx_bibblock">
     Chin-Yew Lin. 2004.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="https://aclanthology.org/W04-1013" target="_blank" title="">
      ROUGE: A package for
automatic evaluation of summaries
     </a>
     .
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib34.1.1">
      Text Summarization Branches Out
     </em>
     , pages 74–81, Barcelona,
Spain. Association for Computational Linguistics.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib35">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Liu et al. (2023a)
    </span>
    <span class="ltx_bibblock">
     Hongcheng Liu, Yusheng Liao, Yutong Meng, Yu Wang, and Yanfeng Wang.
2023a.
    </span>
    <span class="ltx_bibblock">
     Medicalgpt-zh.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_url ltx_font_sansserif" href="https://github.com/MediaBrain-SJTU/MedicalGPT-zh" target="_blank" title="">
      https://github.com/MediaBrain-SJTU/MedicalGPT-zh
     </a>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib36">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Liu et al. (2023b)
    </span>
    <span class="ltx_bibblock">
     Yang Liu, Dan Iter, Yichong Xu, Shuohang Wang, Ruochen Xu, and Chenguang Zhu.
2023b.
    </span>
    <span class="ltx_bibblock">
     Gpteval: Nlg evaluation using gpt-4 with better human alignment.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib36.1.1">
      arXiv preprint arXiv:2303.16634
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib37">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Longpre et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Shayne Longpre, Le Hou, Tu Vu, Albert Webson, Hyung Won Chung, Yi Tay, Denny
Zhou, Quoc V. Le, Barret Zoph, Jason Wei, and Adam Roberts. 2023.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="https://doi.org/10.48550/ARXIV.2301.13688" target="_blank" title="">
      The flan
collection: Designing data and methods for effective instruction tuning
     </a>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib38">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Mishra et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Prakamya Mishra, Zonghai Yao, Shuwei Chen, Beining Wang, Rohan Mittal, and Hong
Yu. 2023.
    </span>
    <span class="ltx_bibblock">
     Synthetic imitation edit feedback for factual alignment in clinical
summarization.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib38.1.1">
      arXiv preprint arXiv:2310.20033
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib39">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     OpenAI (2023)
    </span>
    <span class="ltx_bibblock">
     OpenAI. 2023.
    </span>
    <span class="ltx_bibblock">
     Gpt-4 technical report.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib39.1.1">
      arXiv preprint arXiv:2303.08774
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib40">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Ortega et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Marcus V Ortega, Michael K Hidrue, Sara R Lehrhoff, Dan B Ellis, Rachel C
Sisodia, William T Curry, Marcela G Del Carmen, and Jason H Wasfy. 2023.
    </span>
    <span class="ltx_bibblock">
     Patterns in physician burnout in a stable-linked cohort.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib40.1.1">
      JAMA Network Open
     </em>
     , 6(10):e2336745–e2336745.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib41">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Panait and Luke (2005)
    </span>
    <span class="ltx_bibblock">
     Liviu Panait and Sean Luke. 2005.
    </span>
    <span class="ltx_bibblock">
     Cooperative multi-agent learning: The state of the art.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib41.1.1">
      Autonomous Agents and Multi-Agent Systems
     </em>
     , 11:387–434.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib42">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Pereira et al. (2022)
    </span>
    <span class="ltx_bibblock">
     Mayana Pereira, Sikha Pentyala, Anderson Nascimento, Rafael T de Sousa Jr, and
Martine De Cock. 2022.
    </span>
    <span class="ltx_bibblock">
     Secure multiparty computation for synthetic data generation from
distributed data.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib42.1.1">
      arXiv preprint arXiv:2210.07332
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib43">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Podder et al. (2021)
    </span>
    <span class="ltx_bibblock">
     V Podder, V Lew, and S Ghassemzadeh. 2021.
    </span>
    <span class="ltx_bibblock">
     Soap notes.[updated 2021 sep 2].
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib43.1.1">
      StatPearls [Internet]. StatPearls Publishing. Available from:
https://www. ncbi. nlm. nih. gov/books/NBK482263
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib44">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Radev et al. (2002)
    </span>
    <span class="ltx_bibblock">
     Dragomir R Radev, Hong Qi, Harris Wu, and Weiguo Fan. 2002.
    </span>
    <span class="ltx_bibblock">
     Evaluating web-based question answering systems.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib44.1.1">
      LREC
     </em>
     . Citeseer.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib45">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Ramprasad et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Sanjana Ramprasad, Elisa Ferracane, and Sai P Selvaraj. 2023.
    </span>
    <span class="ltx_bibblock">
     Generating more faithful and consistent soap notes using
attribute-specific parameters.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib46">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Ravaut et al. (2022)
    </span>
    <span class="ltx_bibblock">
     Mathieu Ravaut, Shafiq Joty, and Nancy Chen. 2022.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2022.acl-long.309" target="_blank" title="">
      SummaReranker: A multi-task mixture-of-experts re-ranking framework for
abstractive summarization
     </a>
     .
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib46.1.1">
      Proceedings of the 60th Annual Meeting of the Association
for Computational Linguistics (Volume 1: Long Papers)
     </em>
     , pages 4504–4524,
Dublin, Ireland. Association for Computational Linguistics.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib47">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Rindfleisch (1997)
    </span>
    <span class="ltx_bibblock">
     Thomas C Rindfleisch. 1997.
    </span>
    <span class="ltx_bibblock">
     Privacy, information technology, and health care.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib47.1.1">
      Communications of the ACM
     </em>
     , 40(8):92–100.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib48">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Shafquat et al. (2022)
    </span>
    <span class="ltx_bibblock">
     Afrah Shafquat, Jason Mezey, Mandis Beigi, Jimeng Sun, and Jacob W Aptekar.
2022.
    </span>
    <span class="ltx_bibblock">
     A source data privacy framework for synthetic clinical trial data.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib48.1.1">
      NeurIPS 2022 Workshop on Synthetic Data for Empowering ML
Research
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib49">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Shinn et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Noah Shinn, Federico Cassano, Beck Labash, Ashwin Gopinath, Karthik Narasimhan,
and Shunyu Yao. 2023.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2303.11366" target="_blank" title="">
      Reflexion: Language agents
with verbal reinforcement learning
     </a>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib50">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Soldaini (2016)
    </span>
    <span class="ltx_bibblock">
     Luca Soldaini. 2016.
    </span>
    <span class="ltx_bibblock">
     Quickumls: a fast, unsupervised approach for medical concept
extraction.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib51">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Song et al. (2020)
    </span>
    <span class="ltx_bibblock">
     Yan Song, Yuanhe Tian, Nan Wang, and Fei Xia. 2020.
    </span>
    <span class="ltx_bibblock">
     Summarizing medical conversations via identifying important
utterances.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib51.1.1">
      Proceedings of the 28th International Conference on
Computational Linguistics
     </em>
     , pages 717–729, Barcelona, Spain (Online).
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib52">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Su et al. (2022)
    </span>
    <span class="ltx_bibblock">
     Jing Su, Longxiang Zhang, Hamidreza Hassanzadeh, and Thomas Schaaf. 2022.
    </span>
    <span class="ltx_bibblock">
     Extract and abstract with bart for clinical notes from doctor-patient
conversations.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib52.1.1">
      Interspeech
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib53">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Taori et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos
Guestrin, Percy Liang, and Tatsunori B. Hashimoto. 2023.
    </span>
    <span class="ltx_bibblock">
     Stanford alpaca: An instruction-following llama model.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_url ltx_font_sansserif" href="https://github.com/tatsu-lab/stanford_alpaca" target="_blank" title="">
      https://github.com/tatsu-lab/stanford_alpaca
     </a>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib54">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Touvron et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne
Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric
Hambro, Faisal Azhar, Aurelien Rodriguez, Armand Joulin, Edouard Grave, and
Guillaume Lample. 2023.
    </span>
    <span class="ltx_bibblock">
     Llama: Open and efficient foundation language models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib54.1.1">
      arXiv preprint arXiv:2302.13971
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib55">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Tsichlis et al. (2021)
    </span>
    <span class="ltx_bibblock">
     Jason T Tsichlis, Andrew M Del Re, and J Bryan Carmody. 2021.
    </span>
    <span class="ltx_bibblock">
     The past, present, and future of the united states medical licensing
examination step 2 clinical skills examination.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib55.1.1">
      Cureus
     </em>
     , 13(8).
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib56">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Valmeekam et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Karthik Valmeekam, Matthew Marquez, Sarath Sreedharan, and Subbarao
Kambhampati. 2023.
    </span>
    <span class="ltx_bibblock">
     On the planning abilities of large language models–a critical
investigation.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib56.1.1">
      arXiv preprint arXiv:2305.15771
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib57">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wang et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Haochun Wang, Chi Liu, Nuwa Xi, Zewen Qiang, Sendong Zhao, Bing Qin, and Ting
Liu. 2023.
    </span>
    <span class="ltx_bibblock">
     Huatuo: Tuning llama model with chinese medical knowledge.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib57.1.1">
      arXiv preprint arXiv:2304.06975
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib58">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Xiong et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Honglin Xiong, Sheng Wang, Yitao Zhu, Zihao Zhao, Yuxiao Liu, Qian Wang, and
Dinggang Shen. 2023.
    </span>
    <span class="ltx_bibblock">
     Doctorglm: Fine-tuning your chinese doctor is not a herculean task.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib58.1.1">
      arXiv preprint arXiv:2304.01097
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib59">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Yao et al. (2023a)
    </span>
    <span class="ltx_bibblock">
     Zonghai Yao, Benjamin J Schloss, and Sai P Selvaraj. 2023a.
    </span>
    <span class="ltx_bibblock">
     Improving summarization with human edits.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib59.1.1">
      arXiv preprint arXiv:2310.05857
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib60">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Yao et al. (2023b)
    </span>
    <span class="ltx_bibblock">
     Zonghai Yao, Jack Tsai, Weisong Liu, David A Levy, Emily Druhl, Joel I Reisman,
and Hong Yu. 2023b.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="https://doi.org/10.1093/jamia/ocad081" target="_blank" title="">
      Automated
identification of eviction status from electronic health record notes
     </a>
     .
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib60.1.1">
      Journal of the American Medical Informatics Association
     </em>
     .
    </span>
    <span class="ltx_bibblock">
     Ocad081.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib61">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Yao and Yu (2021)
    </span>
    <span class="ltx_bibblock">
     Zonghai Yao and Hong Yu. 2021.
    </span>
    <span class="ltx_bibblock">
     Improving formality style transfer with context-aware rule injection.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib61.1.1">
      arXiv preprint arXiv:2106.00210
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib62">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Yim et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Wen-wai Yim, Yujuan Fu, Asma Ben Abacha, Neal Snider, Thomas Lin, and
Meliha Yetisgen. 2023.
    </span>
    <span class="ltx_bibblock">
     Aci-bench: a novel ambient clinical intelligence dataset for
benchmarking automatic visit note generation.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib62.1.1">
      Submitted to Nature Scientific Data
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib63">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Yim and Yetisgen-Yildiz (2021)
    </span>
    <span class="ltx_bibblock">
     Wen-wai Yim and Meliha Yetisgen-Yildiz. 2021.
    </span>
    <span class="ltx_bibblock">
     Towards automating medical scribing: Clinic visit dialogue2note
sentence alignment and snippet summarization.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib63.1.1">
      Proceedings of the Second Workshop on Natural Language
Processing for Medical Conversations
     </em>
     , pages 10–20.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib64">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Yuan et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Siyu Yuan, Deqing Yang, Jinxi Liu, Shuyu Tian, Jiaqing Liang, Yanghua Xiao, and
Rui Xie. 2023.
    </span>
    <span class="ltx_bibblock">
     Causality-aware concept extraction based on knowledge-guided
prompting.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib64.1.1">
      arXiv preprint arXiv:2305.01876
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib65">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Yunxiang et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Li Yunxiang, Li Zihan, Zhang Kai, Dan Ruilong, and Zhang You. 2023.
    </span>
    <span class="ltx_bibblock">
     Chatdoctor: A medical chat model fine-tuned on llama model using
medical domain knowledge.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib65.1.1">
      arXiv preprint arXiv:2303.14070
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib66">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Zeng et al. (2020)
    </span>
    <span class="ltx_bibblock">
     Guangtao Zeng, Wenmian Yang, Zeqian Ju, Yue Yang, Sicheng Wang, Ruisi Zhang,
Meng Zhou, Jiaqi Zeng, Xiangyu Dong, Ruoyu Zhang, et al. 2020.
    </span>
    <span class="ltx_bibblock">
     Meddialog: Large-scale medical dialogue datasets.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib66.1.1">
      Proceedings of the 2020 Conference on Empirical Methods in
Natural Language Processing (EMNLP)
     </em>
     , pages 9241–9250.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib67">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Zhang et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Hongbo Zhang, Junying Chen, Feng Jiang, Fei Yu, Zhihong Chen, Jianquan Li,
Guiming Chen, Xiangbo Wu, Zhiyi Zhang, Qingying Xiao, Xiang Wan, Benyou Wang,
and Haizhou Li. 2023.
    </span>
    <span class="ltx_bibblock">
     Huatuogpt, towards taming language models to be a doctor.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib67.1.1">
      arXiv preprint arXiv:2305.15075
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib68">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Zhao et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Zhengyun Zhao, Qiao Jin, Fangyuan Chen, Tuorui Peng, and Sheng Yu. 2023.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2202.13876" target="_blank" title="">
      Pmc-patients: A large-scale
dataset of patient summaries and relations for benchmarking retrieval-based
clinical decision support systems
     </a>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib69">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Zheng et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao
Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric. P Xing, Hao Zhang, Joseph E.
Gonzalez, and Ion Stoica. 2023.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2306.05685" target="_blank" title="">
      Judging llm-as-a-judge with
mt-bench and chatbot arena
     </a>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib70">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Zhu et al. (2018)
    </span>
    <span class="ltx_bibblock">
     Yaoming Zhu, Sidi Lu, Lei Zheng, Jiaxian Guo, Weinan Zhang, Jun Wang, and Yong
Yu. 2018.
    </span>
    <span class="ltx_bibblock">
     Texygen: A benchmarking platform for text generation models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib70.1.1">
      SIGIR
     </em>
     .
    </span>
   </li>
  </ul>
 </section>
 <div class="ltx_pagination ltx_role_newpage">
 </div>
 <section class="ltx_appendix" id="A1">
  <h2 class="ltx_title ltx_title_appendix">
   <span class="ltx_tag ltx_tag_appendix">
    Appendix A
   </span>
   Appendix
  </h2>
  <section class="ltx_subsection" id="A1.SS1">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     A.1
    </span>
    SOAP Structure
   </h3>
   <div class="ltx_para" id="A1.SS1.p1">
    <p class="ltx_p" id="A1.SS1.p1.1">
     The SOAP (Subjective, Objective, Assessment, and Plan) structure is commonly used by providers
     <cite class="ltx_cite ltx_citemacro_cite">
      Podder et al. (
      <a class="ltx_ref" href="#bib.bib43" title="">
       2021
      </a>
      )
     </cite>
     .
    </p>
   </div>
   <div class="ltx_para" id="A1.SS1.p2">
    <ol class="ltx_enumerate" id="A1.I1">
     <li class="ltx_item" id="A1.I1.i1" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       1.
      </span>
      <div class="ltx_para" id="A1.I1.i1.p1">
       <p class="ltx_p" id="A1.I1.i1.p1.1">
        The Subjective section is a detailed report of the patient’s current conditions, such as source, onset, and duration of symptoms, mainly based on the patient’s self-report. This section usually includes chief ccomplaint, history of present illness and symptoms, current medications, and allergies.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="A1.I1.i2" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       2.
      </span>
      <div class="ltx_para" id="A1.I1.i2.p1">
       <p class="ltx_p" id="A1.I1.i2.p1.1">
        The Objective section documents the results of physical exam findings, laboratory data, vital signs, and descriptions of imaging results.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="A1.I1.i3" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       3.
      </span>
      <div class="ltx_para" id="A1.I1.i3.p1">
       <p class="ltx_p" id="A1.I1.i3.p1.1">
        The Assessment section typically contains medical diagnoses and reasons that lead to medical diagnoses. The assessment is typically based on the content from the chief complaint, and the subjective and objective sections.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="A1.I1.i4" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       4.
      </span>
      <div class="ltx_para" id="A1.I1.i4.p1">
       <p class="ltx_p" id="A1.I1.i4.p1.1">
        The Plan section addresses treatment plans based on the assessment.
       </p>
      </div>
     </li>
    </ol>
   </div>
  </section>
  <section class="ltx_subsection" id="A1.SS2">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     A.2
    </span>
    Prompts for ChatGPT&amp;GPT4
   </h3>
   <div class="ltx_para" id="A1.SS2.p1">
    <p class="ltx_p" id="A1.SS2.p1.1">
     We use the following prompts to instruct ChatGPT and GPT4 to generate the synthetic patient-physician dialogue based on the provided clinical note.
    </p>
   </div>
   <div class="ltx_para" id="A1.SS2.p2">
    <p class="ltx_p" id="A1.SS2.p2.1">
     <em class="ltx_emph ltx_font_italic" id="A1.SS2.p2.1.1">
      Generate the conversation between physician and patient. But for some cases, if the patient eventually dies (according to the clinical note), you can add the patient’s family at the end of the conversation to make it more reasonable. The conversation should include all the information in the following note, especially paying attention to those numbers and medical concepts. The conversation can be more colloquial. When the physician is speaking, the patient can have many modal particles (e.g. hmm, yes, okay) to increase interaction. All the numbers and medical concepts that appear in the note should be mentioned by the physician. Professional medical terms and numbers should more likely occur in the physician’s utterances but not in the patient’s answer. The physician may describe and explain professional judgment to the patient and instruct the patient on follow-up requirements but not ask questions that require professional medical knowledge to answer. The patient’s answer should be succinct and accurate in a colloquial lay language style.
     </em>
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="A1.SS3">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     A.3
    </span>
    Experimental Settings
   </h3>
   <div class="ltx_para" id="A1.SS3.p1">
    <p class="ltx_p" id="A1.SS3.p1.1">
     In our study on generating conversation datasets using ChatGPT and GPT-4, we adopted a temperature setting of 0.7. This setting was consistently applied across our methodologies. For each round of dialogue, we set the max tokens for physician role-play as 200 tokens and the patient role-play as 100 tokens. For the intrinsic evaluation phase, we selected a subset of 20 data points from the MT-Dialog dataset and randomly chose 100 datasets from the pmc dataset for testing. In terms of external evaluation, we selected three random data points from each model’s output on the pmc dataset to use as few-shot examples. These were inputted into GPT-4, which then generated dialogues from clinical notes or clincal notes from conversations based 20 data sets from the MT-Dialog dataset. During the external chatbot evaluation, we used 10k datasets generated by ChatGPT, GPT-4, and NoteChat-ChatGPT to fine-tune LLaMA2-7b on two A100-40g gpus. During the fine-tuning process, we used DeepSpeed Zero-2 for training, with a learning rate of 2e-5, a batch size of 16, max tokens of 4048 and 1 training epochs. We employ the same settings to train LLaMA2-7b for the generation of clinical tasks from dialogues and the dialogues from clinical notes.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="A1.SS4">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     A.4
    </span>
    Color for Polish Promopt
   </h3>
   <div class="ltx_para" id="A1.SS4.p1">
    <p class="ltx_p" id="A1.SS4.p1.1">
     We have used consistently different colors to indicate in the polish prompt, as shown in Table
     <a class="ltx_ref" href="#A1.T13" title="Table 13 ‣ A.4 Color for Polish Promopt ‣ Appendix A Appendix ‣ NoteChat: A Dataset of Synthetic Patient-Physician Conversations Conditioned on Clinical Notes">
      <span class="ltx_text ltx_ref_tag">
       13
      </span>
     </a>
     , which parts of our prompt have achieved these ten different functions.
    </p>
   </div>
   <div class="ltx_para" id="A1.SS4.p2">
    <ol class="ltx_enumerate" id="A1.I2">
     <li class="ltx_item" id="A1.I2.i1" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       1.
      </span>
      <div class="ltx_para" id="A1.I2.i1.p1">
       <p class="ltx_p" id="A1.I2.i1.p1.1">
        <span class="ltx_text" id="A1.I2.i1.p1.1.1" style="color:#FFFF00;">
         Yellow:
        </span>
        Make the conversation as colloquial as possible
       </p>
      </div>
     </li>
     <li class="ltx_item" id="A1.I2.i2" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       2.
      </span>
      <div class="ltx_para" id="A1.I2.i2.p1">
       <p class="ltx_p" id="A1.I2.i2.p1.1">
        <span class="ltx_text" id="A1.I2.i2.p1.1.1" style="color:#AD5CFF;">
         Orchid:
        </span>
        Increase the number of rounds of interaction
       </p>
      </div>
     </li>
     <li class="ltx_item" id="A1.I2.i3" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       3.
      </span>
      <div class="ltx_para" id="A1.I2.i3.p1">
       <p class="ltx_p" id="A1.I2.i3.p1.1">
        <span class="ltx_text" id="A1.I2.i3.p1.1.1" style="color:#FFBFBF;">
         Pink:
        </span>
        Professional terms and vocabulary should come from the physicians, and patients should be more colloquial
       </p>
      </div>
     </li>
     <li class="ltx_item" id="A1.I2.i4" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       4.
      </span>
      <div class="ltx_para" id="A1.I2.i4.p1">
       <p class="ltx_p" id="A1.I2.i4.p1.1">
        <span class="ltx_text" id="A1.I2.i4.p1.1.1" style="color:#808080;">
         Gray:
        </span>
        Basic symptoms and medical history should come from the patient, not the physician
       </p>
      </div>
     </li>
     <li class="ltx_item" id="A1.I2.i5" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       5.
      </span>
      <div class="ltx_para" id="A1.I2.i5.p1">
       <p class="ltx_p" id="A1.I2.i5.p1.1">
        <span class="ltx_text" id="A1.I2.i5.p1.1.1" style="color:#B80000;">
         BrickRed:
        </span>
        The questions asked by the physician should be around the case (to avoid hallucination)
       </p>
      </div>
     </li>
     <li class="ltx_item" id="A1.I2.i6" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       6.
      </span>
      <div class="ltx_para" id="A1.I2.i6.p1">
       <p class="ltx_p" id="A1.I2.i6.p1.1">
        <span class="ltx_text" id="A1.I2.i6.p1.1.1" style="color:#61FFE0;">
         SkyBlue:
        </span>
        Physician inquiries should be logical
       </p>
      </div>
     </li>
     <li class="ltx_item" id="A1.I2.i7" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       7.
      </span>
      <div class="ltx_para" id="A1.I2.i7.p1">
       <p class="ltx_p" id="A1.I2.i7.p1.1">
        <span class="ltx_text" id="A1.I2.i7.p1.1.1" style="color:#00FF80;">
         Emerald:
        </span>
        If there are multiple consultation records, you can split a conversation into multiple ones and then link them with transfer words (e.g., a few days later)
       </p>
      </div>
     </li>
     <li class="ltx_item" id="A1.I2.i8" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       8.
      </span>
      <div class="ltx_para" id="A1.I2.i8.p1">
       <p class="ltx_p" id="A1.I2.i8.p1.1">
        <span class="ltx_text" id="A1.I2.i8.p1.1.1" style="color:#FF7D00;">
         BurntOrange:
        </span>
        Range of rounds of interaction
       </p>
      </div>
     </li>
     <li class="ltx_item" id="A1.I2.i9" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       9.
      </span>
      <div class="ltx_para" id="A1.I2.i9.p1">
       <p class="ltx_p" id="A1.I2.i9.p1.1">
        <span class="ltx_text" id="A1.I2.i9.p1.1.1" style="color:#E069FF;">
         Thistle:
        </span>
        Must contain the given keywords
       </p>
      </div>
     </li>
     <li class="ltx_item" id="A1.I2.i10" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       10.
      </span>
      <div class="ltx_para" id="A1.I2.i10.p1">
       <p class="ltx_p" id="A1.I2.i10.p1.1">
        <span class="ltx_text" id="A1.I2.i10.p1.1.1" style="color:#6E73FF;">
         Periwinkle:
        </span>
        Do not generate duplicate information
       </p>
      </div>
     </li>
    </ol>
   </div>
   <div class="ltx_para" id="A1.SS4.p3">
    <p class="ltx_p" id="A1.SS4.p3.1">
     Note that there are some similar and repeated parts in the prompt, which are because we found that mentioning a certain point multiple times in different places in the prompt is more helpful for LLM to avoid certain problems.
    </p>
   </div>
   <figure class="ltx_table" id="A1.T6">
    <div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="A1.T6.1" style="width:196.2pt;height:37.8pt;vertical-align:-0.0pt;">
     <span class="ltx_transformed_inner" style="transform:translate(-42.0pt,8.1pt) scale(0.7,0.7) ;">
      <table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="A1.T6.1.1">
       <thead class="ltx_thead">
        <tr class="ltx_tr" id="A1.T6.1.1.1.1">
         <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A1.T6.1.1.1.1.1">
          <span class="ltx_text ltx_font_bold" id="A1.T6.1.1.1.1.1.1">
           Group
          </span>
         </th>
         <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A1.T6.1.1.1.1.2">
          <span class="ltx_text ltx_font_bold" id="A1.T6.1.1.1.1.2.1">
           Our Score
          </span>
         </th>
         <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A1.T6.1.1.1.1.3">
          <span class="ltx_text ltx_font_bold" id="A1.T6.1.1.1.1.3.1">
           GPT-4 Score
          </span>
         </th>
         <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A1.T6.1.1.1.1.4">
          <span class="ltx_text ltx_font_bold" id="A1.T6.1.1.1.1.4.1">
           ChatGPT Score
          </span>
         </th>
        </tr>
       </thead>
       <tbody class="ltx_tbody">
        <tr class="ltx_tr" id="A1.T6.1.1.2.1">
         <td class="ltx_td ltx_align_center ltx_border_t" id="A1.T6.1.1.2.1.1">
          physicians
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="A1.T6.1.1.2.1.2">
          0.78
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="A1.T6.1.1.2.1.3">
          0.80
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="A1.T6.1.1.2.1.4">
          0.93
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T6.1.1.3.2">
         <td class="ltx_td ltx_align_center ltx_border_b" id="A1.T6.1.1.3.2.1">
          Crowd
         </td>
         <td class="ltx_td ltx_align_center ltx_border_b" id="A1.T6.1.1.3.2.2">
          0.70
         </td>
         <td class="ltx_td ltx_align_center ltx_border_b" id="A1.T6.1.1.3.2.3">
          0.75
         </td>
         <td class="ltx_td ltx_align_center ltx_border_b" id="A1.T6.1.1.3.2.4">
          0.90
         </td>
        </tr>
       </tbody>
      </table>
     </span>
    </div>
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_table">
      Table 6:
     </span>
     To evaluate the annotation consistency of the annotators, we calculated the agreement score (Cohen’s kappa coefficient) for both the expert group and the crowd group. For each group, we calculated the agreement score for the annotators ranking NoteChat, GPT-4, and ChatGPT as the first, to determine whether the annotators consistently labeled the same model as the best.
    </figcaption>
   </figure>
   <figure class="ltx_table" id="A1.T7">
    <div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="A1.T7.1" style="width:192.6pt;height:64.8pt;vertical-align:-0.0pt;">
     <span class="ltx_transformed_inner" style="transform:translate(-10.7pt,3.6pt) scale(0.9,0.9) ;">
      <table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="A1.T7.1.1">
       <thead class="ltx_thead">
        <tr class="ltx_tr" id="A1.T7.1.1.1.1">
         <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A1.T7.1.1.1.1.1">
          <span class="ltx_text ltx_font_bold" id="A1.T7.1.1.1.1.1.1">
           Comparison
          </span>
         </th>
         <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A1.T7.1.1.1.1.2">
          <span class="ltx_text ltx_font_bold" id="A1.T7.1.1.1.1.2.1">
           Win Rate
          </span>
         </th>
        </tr>
       </thead>
       <tbody class="ltx_tbody">
        <tr class="ltx_tr" id="A1.T7.1.1.2.1">
         <td class="ltx_td ltx_align_center ltx_border_t" id="A1.T7.1.1.2.1.1">
          NoteChat-GPT-4 -&gt; our
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="A1.T7.1.1.2.1.2">
          0.7
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T7.1.1.3.2">
         <td class="ltx_td ltx_align_center" id="A1.T7.1.1.3.2.1">
          NoteChat-GPT-4 -&gt; GPT-4
         </td>
         <td class="ltx_td ltx_align_center" id="A1.T7.1.1.3.2.2">
          0.7
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T7.1.1.4.3">
         <td class="ltx_td ltx_align_center ltx_border_b" id="A1.T7.1.1.4.3.1">
          NoteChat-GPT-4 -&gt; ChatGPT
         </td>
         <td class="ltx_td ltx_align_center ltx_border_b" id="A1.T7.1.1.4.3.2">
          1.0
         </td>
        </tr>
       </tbody>
      </table>
     </span>
    </div>
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_table">
      Table 7:
     </span>
     To empirically validate the superiority of our approach over GPT-4, we employed the NoteChat-GPT4 version to demonstrate that our model consistently outperforms GPT-4. After replacing the gpt3.5-turbo module in NoteChat model with GPT-4, we generated a new set of dialogues and compared them with NoteChat-GPT3, GPT4, and ChatGPT respectively. For each comparison, we asked GPT-4 to judge and choose the best dialogue. For the same dialogue comparison between different models, we changed the order to avoid the order influencing GPT-4’s judgment. Finally, we obtained the win rate as shown in the experimental results:
    </figcaption>
   </figure>
   <figure class="ltx_table" id="A1.T8">
    <table class="ltx_tabular ltx_centering ltx_align_middle" id="A1.T8.2">
     <tbody class="ltx_tbody">
      <tr class="ltx_tr" id="A1.T8.2.2">
       <td class="ltx_td ltx_align_justify ltx_border_bb ltx_border_tt" id="A1.T8.2.2.2" style="padding:0.25pt 3.9pt;">
        <span class="ltx_inline-block ltx_align_top" id="A1.T8.2.2.2.2">
         <span class="ltx_p" id="A1.T8.2.2.2.2.2">
          In this task, we ask for your expertise in annotating the quality of system-generated replies by machine learning models. Mainly we provide the history dialogue along with system-generated replies and ask for your preference.
          <br class="ltx_break"/>
          <br class="ltx_break"/>
          Output your ranking for system-generated replies. Use the following format, and do not add any other text.
          <br class="ltx_break"/>
          <br class="ltx_break"/>
          Some examples:
          <br class="ltx_break"/>
          <math alttext="a&gt;b&gt;c&gt;d&gt;e" class="ltx_Math" display="inline" id="A1.T8.1.1.1.1.1.m1.1">
           <semantics id="A1.T8.1.1.1.1.1.m1.1a">
            <mrow id="A1.T8.1.1.1.1.1.m1.1.1" xref="A1.T8.1.1.1.1.1.m1.1.1.cmml">
             <mi id="A1.T8.1.1.1.1.1.m1.1.1.2" xref="A1.T8.1.1.1.1.1.m1.1.1.2.cmml">
              a
             </mi>
             <mo id="A1.T8.1.1.1.1.1.m1.1.1.3" xref="A1.T8.1.1.1.1.1.m1.1.1.3.cmml">
              &gt;
             </mo>
             <mi id="A1.T8.1.1.1.1.1.m1.1.1.4" xref="A1.T8.1.1.1.1.1.m1.1.1.4.cmml">
              b
             </mi>
             <mo id="A1.T8.1.1.1.1.1.m1.1.1.5" xref="A1.T8.1.1.1.1.1.m1.1.1.5.cmml">
              &gt;
             </mo>
             <mi id="A1.T8.1.1.1.1.1.m1.1.1.6" xref="A1.T8.1.1.1.1.1.m1.1.1.6.cmml">
              c
             </mi>
             <mo id="A1.T8.1.1.1.1.1.m1.1.1.7" xref="A1.T8.1.1.1.1.1.m1.1.1.7.cmml">
              &gt;
             </mo>
             <mi id="A1.T8.1.1.1.1.1.m1.1.1.8" xref="A1.T8.1.1.1.1.1.m1.1.1.8.cmml">
              d
             </mi>
             <mo id="A1.T8.1.1.1.1.1.m1.1.1.9" xref="A1.T8.1.1.1.1.1.m1.1.1.9.cmml">
              &gt;
             </mo>
             <mi id="A1.T8.1.1.1.1.1.m1.1.1.10" xref="A1.T8.1.1.1.1.1.m1.1.1.10.cmml">
              e
             </mi>
            </mrow>
            <annotation-xml encoding="MathML-Content" id="A1.T8.1.1.1.1.1.m1.1b">
             <apply id="A1.T8.1.1.1.1.1.m1.1.1.cmml" xref="A1.T8.1.1.1.1.1.m1.1.1">
              <and id="A1.T8.1.1.1.1.1.m1.1.1a.cmml" xref="A1.T8.1.1.1.1.1.m1.1.1">
              </and>
              <apply id="A1.T8.1.1.1.1.1.m1.1.1b.cmml" xref="A1.T8.1.1.1.1.1.m1.1.1">
               <gt id="A1.T8.1.1.1.1.1.m1.1.1.3.cmml" xref="A1.T8.1.1.1.1.1.m1.1.1.3">
               </gt>
               <ci id="A1.T8.1.1.1.1.1.m1.1.1.2.cmml" xref="A1.T8.1.1.1.1.1.m1.1.1.2">
                𝑎
               </ci>
               <ci id="A1.T8.1.1.1.1.1.m1.1.1.4.cmml" xref="A1.T8.1.1.1.1.1.m1.1.1.4">
                𝑏
               </ci>
              </apply>
              <apply id="A1.T8.1.1.1.1.1.m1.1.1c.cmml" xref="A1.T8.1.1.1.1.1.m1.1.1">
               <gt id="A1.T8.1.1.1.1.1.m1.1.1.5.cmml" xref="A1.T8.1.1.1.1.1.m1.1.1.5">
               </gt>
               <share href="#A1.T8.1.1.1.1.1.m1.1.1.4.cmml" id="A1.T8.1.1.1.1.1.m1.1.1d.cmml" xref="A1.T8.1.1.1.1.1.m1.1.1">
               </share>
               <ci id="A1.T8.1.1.1.1.1.m1.1.1.6.cmml" xref="A1.T8.1.1.1.1.1.m1.1.1.6">
                𝑐
               </ci>
              </apply>
              <apply id="A1.T8.1.1.1.1.1.m1.1.1e.cmml" xref="A1.T8.1.1.1.1.1.m1.1.1">
               <gt id="A1.T8.1.1.1.1.1.m1.1.1.7.cmml" xref="A1.T8.1.1.1.1.1.m1.1.1.7">
               </gt>
               <share href="#A1.T8.1.1.1.1.1.m1.1.1.6.cmml" id="A1.T8.1.1.1.1.1.m1.1.1f.cmml" xref="A1.T8.1.1.1.1.1.m1.1.1">
               </share>
               <ci id="A1.T8.1.1.1.1.1.m1.1.1.8.cmml" xref="A1.T8.1.1.1.1.1.m1.1.1.8">
                𝑑
               </ci>
              </apply>
              <apply id="A1.T8.1.1.1.1.1.m1.1.1g.cmml" xref="A1.T8.1.1.1.1.1.m1.1.1">
               <gt id="A1.T8.1.1.1.1.1.m1.1.1.9.cmml" xref="A1.T8.1.1.1.1.1.m1.1.1.9">
               </gt>
               <share href="#A1.T8.1.1.1.1.1.m1.1.1.8.cmml" id="A1.T8.1.1.1.1.1.m1.1.1h.cmml" xref="A1.T8.1.1.1.1.1.m1.1.1">
               </share>
               <ci id="A1.T8.1.1.1.1.1.m1.1.1.10.cmml" xref="A1.T8.1.1.1.1.1.m1.1.1.10">
                𝑒
               </ci>
              </apply>
             </apply>
            </annotation-xml>
            <annotation encoding="application/x-tex" id="A1.T8.1.1.1.1.1.m1.1c">
             a&gt;b&gt;c&gt;d&gt;e
            </annotation>
           </semantics>
          </math>
          <br class="ltx_break"/>
          <math alttext="e&gt;d&gt;c&gt;b&gt;a" class="ltx_Math" display="inline" id="A1.T8.2.2.2.2.2.m2.1">
           <semantics id="A1.T8.2.2.2.2.2.m2.1a">
            <mrow id="A1.T8.2.2.2.2.2.m2.1.1" xref="A1.T8.2.2.2.2.2.m2.1.1.cmml">
             <mi id="A1.T8.2.2.2.2.2.m2.1.1.2" xref="A1.T8.2.2.2.2.2.m2.1.1.2.cmml">
              e
             </mi>
             <mo id="A1.T8.2.2.2.2.2.m2.1.1.3" xref="A1.T8.2.2.2.2.2.m2.1.1.3.cmml">
              &gt;
             </mo>
             <mi id="A1.T8.2.2.2.2.2.m2.1.1.4" xref="A1.T8.2.2.2.2.2.m2.1.1.4.cmml">
              d
             </mi>
             <mo id="A1.T8.2.2.2.2.2.m2.1.1.5" xref="A1.T8.2.2.2.2.2.m2.1.1.5.cmml">
              &gt;
             </mo>
             <mi id="A1.T8.2.2.2.2.2.m2.1.1.6" xref="A1.T8.2.2.2.2.2.m2.1.1.6.cmml">
              c
             </mi>
             <mo id="A1.T8.2.2.2.2.2.m2.1.1.7" xref="A1.T8.2.2.2.2.2.m2.1.1.7.cmml">
              &gt;
             </mo>
             <mi id="A1.T8.2.2.2.2.2.m2.1.1.8" xref="A1.T8.2.2.2.2.2.m2.1.1.8.cmml">
              b
             </mi>
             <mo id="A1.T8.2.2.2.2.2.m2.1.1.9" xref="A1.T8.2.2.2.2.2.m2.1.1.9.cmml">
              &gt;
             </mo>
             <mi id="A1.T8.2.2.2.2.2.m2.1.1.10" xref="A1.T8.2.2.2.2.2.m2.1.1.10.cmml">
              a
             </mi>
            </mrow>
            <annotation-xml encoding="MathML-Content" id="A1.T8.2.2.2.2.2.m2.1b">
             <apply id="A1.T8.2.2.2.2.2.m2.1.1.cmml" xref="A1.T8.2.2.2.2.2.m2.1.1">
              <and id="A1.T8.2.2.2.2.2.m2.1.1a.cmml" xref="A1.T8.2.2.2.2.2.m2.1.1">
              </and>
              <apply id="A1.T8.2.2.2.2.2.m2.1.1b.cmml" xref="A1.T8.2.2.2.2.2.m2.1.1">
               <gt id="A1.T8.2.2.2.2.2.m2.1.1.3.cmml" xref="A1.T8.2.2.2.2.2.m2.1.1.3">
               </gt>
               <ci id="A1.T8.2.2.2.2.2.m2.1.1.2.cmml" xref="A1.T8.2.2.2.2.2.m2.1.1.2">
                𝑒
               </ci>
               <ci id="A1.T8.2.2.2.2.2.m2.1.1.4.cmml" xref="A1.T8.2.2.2.2.2.m2.1.1.4">
                𝑑
               </ci>
              </apply>
              <apply id="A1.T8.2.2.2.2.2.m2.1.1c.cmml" xref="A1.T8.2.2.2.2.2.m2.1.1">
               <gt id="A1.T8.2.2.2.2.2.m2.1.1.5.cmml" xref="A1.T8.2.2.2.2.2.m2.1.1.5">
               </gt>
               <share href="#A1.T8.2.2.2.2.2.m2.1.1.4.cmml" id="A1.T8.2.2.2.2.2.m2.1.1d.cmml" xref="A1.T8.2.2.2.2.2.m2.1.1">
               </share>
               <ci id="A1.T8.2.2.2.2.2.m2.1.1.6.cmml" xref="A1.T8.2.2.2.2.2.m2.1.1.6">
                𝑐
               </ci>
              </apply>
              <apply id="A1.T8.2.2.2.2.2.m2.1.1e.cmml" xref="A1.T8.2.2.2.2.2.m2.1.1">
               <gt id="A1.T8.2.2.2.2.2.m2.1.1.7.cmml" xref="A1.T8.2.2.2.2.2.m2.1.1.7">
               </gt>
               <share href="#A1.T8.2.2.2.2.2.m2.1.1.6.cmml" id="A1.T8.2.2.2.2.2.m2.1.1f.cmml" xref="A1.T8.2.2.2.2.2.m2.1.1">
               </share>
               <ci id="A1.T8.2.2.2.2.2.m2.1.1.8.cmml" xref="A1.T8.2.2.2.2.2.m2.1.1.8">
                𝑏
               </ci>
              </apply>
              <apply id="A1.T8.2.2.2.2.2.m2.1.1g.cmml" xref="A1.T8.2.2.2.2.2.m2.1.1">
               <gt id="A1.T8.2.2.2.2.2.m2.1.1.9.cmml" xref="A1.T8.2.2.2.2.2.m2.1.1.9">
               </gt>
               <share href="#A1.T8.2.2.2.2.2.m2.1.1.8.cmml" id="A1.T8.2.2.2.2.2.m2.1.1h.cmml" xref="A1.T8.2.2.2.2.2.m2.1.1">
               </share>
               <ci id="A1.T8.2.2.2.2.2.m2.1.1.10.cmml" xref="A1.T8.2.2.2.2.2.m2.1.1.10">
                𝑎
               </ci>
              </apply>
             </apply>
            </annotation-xml>
            <annotation encoding="application/x-tex" id="A1.T8.2.2.2.2.2.m2.1c">
             e&gt;d&gt;c&gt;b&gt;a
            </annotation>
           </semantics>
          </math>
          <br class="ltx_break"/>
          <br class="ltx_break"/>
          History Conversation:
          <br class="ltx_break"/>
          [
          <em class="ltx_emph ltx_font_italic" id="A1.T8.2.2.2.2.2.1">
           History Conversation
          </em>
          ]
          <br class="ltx_break"/>
          <br class="ltx_break"/>
          Conversation snippet:
          <br class="ltx_break"/>
          [
          <em class="ltx_emph ltx_font_italic" id="A1.T8.2.2.2.2.2.2">
           utterance
          </em>
          ]
          <br class="ltx_break"/>
          <br class="ltx_break"/>
          <br class="ltx_break"/>
          <br class="ltx_break"/>
          System-generated summaries:
          <br class="ltx_break"/>
          1. [
          <em class="ltx_emph ltx_font_italic" id="A1.T8.2.2.2.2.2.3">
           Utterance1
          </em>
          ]
          <br class="ltx_break"/>
          2. [
          <em class="ltx_emph ltx_font_italic" id="A1.T8.2.2.2.2.2.4">
           Utterance2
          </em>
          ]
          <br class="ltx_break"/>
          3. [
          <em class="ltx_emph ltx_font_italic" id="A1.T8.2.2.2.2.2.5">
           Utterance3
          </em>
          ]
          <br class="ltx_break"/>
          4. [
          <em class="ltx_emph ltx_font_italic" id="A1.T8.2.2.2.2.2.6">
           Utterance4
          </em>
          ]
          <br class="ltx_break"/>
          5. [
          <em class="ltx_emph ltx_font_italic" id="A1.T8.2.2.2.2.2.7">
           Utterance5
          </em>
          ]
          <br class="ltx_break"/>
          <br class="ltx_break"/>
          Now, output your ranking:
         </span>
        </span>
       </td>
      </tr>
     </tbody>
    </table>
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_table">
      Table 8:
     </span>
     GPT-4 Prompt for preference ranking in extrinsic evaluation.
    </figcaption>
   </figure>
   <figure class="ltx_table" id="A1.T9">
    <table class="ltx_tabular ltx_centering ltx_align_middle" id="A1.T9.2">
     <tbody class="ltx_tbody">
      <tr class="ltx_tr" id="A1.T9.2.2">
       <td class="ltx_td ltx_align_justify ltx_border_bb ltx_border_tt" id="A1.T9.2.2.2" style="padding:0.25pt 3.9pt;">
        <span class="ltx_inline-block ltx_align_top" id="A1.T9.2.2.2.2">
         <span class="ltx_p" id="A1.T9.2.2.2.2.2">
          In this task, we ask for your expertise in annotating the quality of the system-generated dialogues by machine learning models. Mainly we provide the ground truth dialogue and the clinical note along with system-generated dialogues and ask for your preference.
          <br class="ltx_break"/>
          <br class="ltx_break"/>
          Output your ranking for system-generated dialogues. Use the following format, and do not add any other text.
          <br class="ltx_break"/>
          <br class="ltx_break"/>
          Some examples:
          <br class="ltx_break"/>
          <math alttext="a&gt;b&gt;c" class="ltx_Math" display="inline" id="A1.T9.1.1.1.1.1.m1.1">
           <semantics id="A1.T9.1.1.1.1.1.m1.1a">
            <mrow id="A1.T9.1.1.1.1.1.m1.1.1" xref="A1.T9.1.1.1.1.1.m1.1.1.cmml">
             <mi id="A1.T9.1.1.1.1.1.m1.1.1.2" xref="A1.T9.1.1.1.1.1.m1.1.1.2.cmml">
              a
             </mi>
             <mo id="A1.T9.1.1.1.1.1.m1.1.1.3" xref="A1.T9.1.1.1.1.1.m1.1.1.3.cmml">
              &gt;
             </mo>
             <mi id="A1.T9.1.1.1.1.1.m1.1.1.4" xref="A1.T9.1.1.1.1.1.m1.1.1.4.cmml">
              b
             </mi>
             <mo id="A1.T9.1.1.1.1.1.m1.1.1.5" xref="A1.T9.1.1.1.1.1.m1.1.1.5.cmml">
              &gt;
             </mo>
             <mi id="A1.T9.1.1.1.1.1.m1.1.1.6" xref="A1.T9.1.1.1.1.1.m1.1.1.6.cmml">
              c
             </mi>
            </mrow>
            <annotation-xml encoding="MathML-Content" id="A1.T9.1.1.1.1.1.m1.1b">
             <apply id="A1.T9.1.1.1.1.1.m1.1.1.cmml" xref="A1.T9.1.1.1.1.1.m1.1.1">
              <and id="A1.T9.1.1.1.1.1.m1.1.1a.cmml" xref="A1.T9.1.1.1.1.1.m1.1.1">
              </and>
              <apply id="A1.T9.1.1.1.1.1.m1.1.1b.cmml" xref="A1.T9.1.1.1.1.1.m1.1.1">
               <gt id="A1.T9.1.1.1.1.1.m1.1.1.3.cmml" xref="A1.T9.1.1.1.1.1.m1.1.1.3">
               </gt>
               <ci id="A1.T9.1.1.1.1.1.m1.1.1.2.cmml" xref="A1.T9.1.1.1.1.1.m1.1.1.2">
                𝑎
               </ci>
               <ci id="A1.T9.1.1.1.1.1.m1.1.1.4.cmml" xref="A1.T9.1.1.1.1.1.m1.1.1.4">
                𝑏
               </ci>
              </apply>
              <apply id="A1.T9.1.1.1.1.1.m1.1.1c.cmml" xref="A1.T9.1.1.1.1.1.m1.1.1">
               <gt id="A1.T9.1.1.1.1.1.m1.1.1.5.cmml" xref="A1.T9.1.1.1.1.1.m1.1.1.5">
               </gt>
               <share href="#A1.T9.1.1.1.1.1.m1.1.1.4.cmml" id="A1.T9.1.1.1.1.1.m1.1.1d.cmml" xref="A1.T9.1.1.1.1.1.m1.1.1">
               </share>
               <ci id="A1.T9.1.1.1.1.1.m1.1.1.6.cmml" xref="A1.T9.1.1.1.1.1.m1.1.1.6">
                𝑐
               </ci>
              </apply>
             </apply>
            </annotation-xml>
            <annotation encoding="application/x-tex" id="A1.T9.1.1.1.1.1.m1.1c">
             a&gt;b&gt;c
            </annotation>
           </semantics>
          </math>
          <br class="ltx_break"/>
          <math alttext="c&gt;b&gt;a" class="ltx_Math" display="inline" id="A1.T9.2.2.2.2.2.m2.1">
           <semantics id="A1.T9.2.2.2.2.2.m2.1a">
            <mrow id="A1.T9.2.2.2.2.2.m2.1.1" xref="A1.T9.2.2.2.2.2.m2.1.1.cmml">
             <mi id="A1.T9.2.2.2.2.2.m2.1.1.2" xref="A1.T9.2.2.2.2.2.m2.1.1.2.cmml">
              c
             </mi>
             <mo id="A1.T9.2.2.2.2.2.m2.1.1.3" xref="A1.T9.2.2.2.2.2.m2.1.1.3.cmml">
              &gt;
             </mo>
             <mi id="A1.T9.2.2.2.2.2.m2.1.1.4" xref="A1.T9.2.2.2.2.2.m2.1.1.4.cmml">
              b
             </mi>
             <mo id="A1.T9.2.2.2.2.2.m2.1.1.5" xref="A1.T9.2.2.2.2.2.m2.1.1.5.cmml">
              &gt;
             </mo>
             <mi id="A1.T9.2.2.2.2.2.m2.1.1.6" xref="A1.T9.2.2.2.2.2.m2.1.1.6.cmml">
              a
             </mi>
            </mrow>
            <annotation-xml encoding="MathML-Content" id="A1.T9.2.2.2.2.2.m2.1b">
             <apply id="A1.T9.2.2.2.2.2.m2.1.1.cmml" xref="A1.T9.2.2.2.2.2.m2.1.1">
              <and id="A1.T9.2.2.2.2.2.m2.1.1a.cmml" xref="A1.T9.2.2.2.2.2.m2.1.1">
              </and>
              <apply id="A1.T9.2.2.2.2.2.m2.1.1b.cmml" xref="A1.T9.2.2.2.2.2.m2.1.1">
               <gt id="A1.T9.2.2.2.2.2.m2.1.1.3.cmml" xref="A1.T9.2.2.2.2.2.m2.1.1.3">
               </gt>
               <ci id="A1.T9.2.2.2.2.2.m2.1.1.2.cmml" xref="A1.T9.2.2.2.2.2.m2.1.1.2">
                𝑐
               </ci>
               <ci id="A1.T9.2.2.2.2.2.m2.1.1.4.cmml" xref="A1.T9.2.2.2.2.2.m2.1.1.4">
                𝑏
               </ci>
              </apply>
              <apply id="A1.T9.2.2.2.2.2.m2.1.1c.cmml" xref="A1.T9.2.2.2.2.2.m2.1.1">
               <gt id="A1.T9.2.2.2.2.2.m2.1.1.5.cmml" xref="A1.T9.2.2.2.2.2.m2.1.1.5">
               </gt>
               <share href="#A1.T9.2.2.2.2.2.m2.1.1.4.cmml" id="A1.T9.2.2.2.2.2.m2.1.1d.cmml" xref="A1.T9.2.2.2.2.2.m2.1.1">
               </share>
               <ci id="A1.T9.2.2.2.2.2.m2.1.1.6.cmml" xref="A1.T9.2.2.2.2.2.m2.1.1.6">
                𝑎
               </ci>
              </apply>
             </apply>
            </annotation-xml>
            <annotation encoding="application/x-tex" id="A1.T9.2.2.2.2.2.m2.1c">
             c&gt;b&gt;a
            </annotation>
           </semantics>
          </math>
          <br class="ltx_break"/>
          <br class="ltx_break"/>
          Clinical Note:
          <br class="ltx_break"/>
          [
          <em class="ltx_emph ltx_font_italic" id="A1.T9.2.2.2.2.2.1">
           Clinical Note
          </em>
          ]
          <br class="ltx_break"/>
          <br class="ltx_break"/>
          Ground Truth Dialogue:
          <br class="ltx_break"/>
          [
          <em class="ltx_emph ltx_font_italic" id="A1.T9.2.2.2.2.2.2">
           dialogue
          </em>
          ]
          <br class="ltx_break"/>
          <br class="ltx_break"/>
          <br class="ltx_break"/>
          <br class="ltx_break"/>
          System-generated summaries:
          <br class="ltx_break"/>
          1. [
          <em class="ltx_emph ltx_font_italic" id="A1.T9.2.2.2.2.2.3">
           dialogue1
          </em>
          ]
          <br class="ltx_break"/>
          2. [
          <em class="ltx_emph ltx_font_italic" id="A1.T9.2.2.2.2.2.4">
           dialogue2
          </em>
          ]
          <br class="ltx_break"/>
          3. [
          <em class="ltx_emph ltx_font_italic" id="A1.T9.2.2.2.2.2.5">
           dialogue3
          </em>
          ]
          <br class="ltx_break"/>
          <br class="ltx_break"/>
          <br class="ltx_break"/>
          Now, output your ranking:
         </span>
        </span>
       </td>
      </tr>
     </tbody>
    </table>
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_table">
      Table 9:
     </span>
     GPT-4 Prompt for preference ranking in human evaluation.
    </figcaption>
   </figure>
   <figure class="ltx_table" id="A1.T10">
    <table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="A1.T10.1">
     <tbody class="ltx_tbody">
      <tr class="ltx_tr" id="A1.T10.1.1.1">
       <th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_t" id="A1.T10.1.1.1.1">
        <span class="ltx_inline-block ltx_align_top" id="A1.T10.1.1.1.1.1">
         <span class="ltx_p" id="A1.T10.1.1.1.1.1.1" style="width:71.1pt;">
          Section
         </span>
        </span>
       </th>
       <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A1.T10.1.1.1.2">
        <span class="ltx_inline-block ltx_align_top" id="A1.T10.1.1.1.2.1">
         <span class="ltx_p" id="A1.T10.1.1.1.2.1.1" style="width:142.3pt;">
          Subsection
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A1.T10.1.1.1.3">
        <span class="ltx_inline-block ltx_align_top" id="A1.T10.1.1.1.3.1">
         <span class="ltx_p" id="A1.T10.1.1.1.3.1.1" style="width:204.9pt;">
          Definition
         </span>
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="A1.T10.1.2.2">
       <th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_t" id="A1.T10.1.2.2.1">
        <span class="ltx_inline-block ltx_align_top" id="A1.T10.1.2.2.1.1">
         <span class="ltx_p" id="A1.T10.1.2.2.1.1.1" style="width:71.1pt;">
          Subjective
         </span>
        </span>
       </th>
       <td class="ltx_td ltx_align_top ltx_border_t" id="A1.T10.1.2.2.2">
       </td>
       <td class="ltx_td ltx_align_top ltx_border_t" id="A1.T10.1.2.2.3">
       </td>
      </tr>
      <tr class="ltx_tr" id="A1.T10.1.3.3">
       <th class="ltx_td ltx_align_top ltx_th ltx_th_row" id="A1.T10.1.3.3.1">
       </th>
       <td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T10.1.3.3.2">
        <span class="ltx_inline-block ltx_align_top" id="A1.T10.1.3.3.2.1">
         <span class="ltx_p" id="A1.T10.1.3.3.2.1.1" style="width:142.3pt;">
          Chief Complaint
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T10.1.3.3.3">
        <span class="ltx_inline-block ltx_align_top" id="A1.T10.1.3.3.3.1">
         <span class="ltx_p" id="A1.T10.1.3.3.3.1.1" style="width:204.9pt;">
          Patient’s primary motivation for the visit and type of visit
         </span>
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="A1.T10.1.4.4">
       <th class="ltx_td ltx_align_top ltx_th ltx_th_row" id="A1.T10.1.4.4.1">
       </th>
       <td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T10.1.4.4.2">
        <span class="ltx_inline-block ltx_align_top" id="A1.T10.1.4.4.2.1">
         <span class="ltx_p" id="A1.T10.1.4.4.2.1.1" style="width:142.3pt;">
          Review of Systems
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T10.1.4.4.3">
        <span class="ltx_inline-block ltx_align_top" id="A1.T10.1.4.4.3.1">
         <span class="ltx_p" id="A1.T10.1.4.4.3.1.1" style="width:204.9pt;">
          Patient’s report of system related health and symptoms
         </span>
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="A1.T10.1.5.5">
       <th class="ltx_td ltx_align_top ltx_th ltx_th_row" id="A1.T10.1.5.5.1">
       </th>
       <td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T10.1.5.5.2">
        <span class="ltx_inline-block ltx_align_top" id="A1.T10.1.5.5.2.1">
         <span class="ltx_p" id="A1.T10.1.5.5.2.1.1" style="width:142.3pt;">
          Past Medical History
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T10.1.5.5.3">
        <span class="ltx_inline-block ltx_align_top" id="A1.T10.1.5.5.3.1">
         <span class="ltx_p" id="A1.T10.1.5.5.3.1.1" style="width:204.9pt;">
          Patient’s reported diagnoses/conditions (when and what, excluding laboratory and imaging results and surgeries)
         </span>
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="A1.T10.1.6.6">
       <th class="ltx_td ltx_align_top ltx_th ltx_th_row" id="A1.T10.1.6.6.1">
       </th>
       <td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T10.1.6.6.2">
        <span class="ltx_inline-block ltx_align_top" id="A1.T10.1.6.6.2.1">
         <span class="ltx_p" id="A1.T10.1.6.6.2.1.1" style="width:142.3pt;">
          Past Surgical History
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T10.1.6.6.3">
        <span class="ltx_inline-block ltx_align_top" id="A1.T10.1.6.6.3.1">
         <span class="ltx_p" id="A1.T10.1.6.6.3.1.1" style="width:204.9pt;">
          Patient’s reported prior surgeries (what, when, where)
         </span>
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="A1.T10.1.7.7">
       <th class="ltx_td ltx_align_top ltx_th ltx_th_row" id="A1.T10.1.7.7.1">
       </th>
       <td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T10.1.7.7.2">
        <span class="ltx_inline-block ltx_align_top" id="A1.T10.1.7.7.2.1">
         <span class="ltx_p" id="A1.T10.1.7.7.2.1.1" style="width:142.3pt;">
          Family Medical History
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T10.1.7.7.3">
        <span class="ltx_inline-block ltx_align_top" id="A1.T10.1.7.7.3.1">
         <span class="ltx_p" id="A1.T10.1.7.7.3.1.1" style="width:204.9pt;">
          Conditions affecting patient’s close genetic relatives
         </span>
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="A1.T10.1.8.8">
       <th class="ltx_td ltx_align_top ltx_th ltx_th_row" id="A1.T10.1.8.8.1">
       </th>
       <td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T10.1.8.8.2">
        <span class="ltx_inline-block ltx_align_top" id="A1.T10.1.8.8.2.1">
         <span class="ltx_p" id="A1.T10.1.8.8.2.1.1" style="width:142.3pt;">
          Social History
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T10.1.8.8.3">
        <span class="ltx_inline-block ltx_align_top" id="A1.T10.1.8.8.3.1">
         <span class="ltx_p" id="A1.T10.1.8.8.3.1.1" style="width:204.9pt;">
          Patient’s alcohol, tobacco, and drug related behaviors
         </span>
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="A1.T10.1.9.9">
       <th class="ltx_td ltx_align_top ltx_th ltx_th_row" id="A1.T10.1.9.9.1">
       </th>
       <td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T10.1.9.9.2">
        <span class="ltx_inline-block ltx_align_top" id="A1.T10.1.9.9.2.1">
         <span class="ltx_p" id="A1.T10.1.9.9.2.1.1" style="width:142.3pt;">
          Medications
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T10.1.9.9.3">
        <span class="ltx_inline-block ltx_align_top" id="A1.T10.1.9.9.3.1">
         <span class="ltx_p" id="A1.T10.1.9.9.3.1.1" style="width:204.9pt;">
          Patient’s list of medications (not prescribed during visit)
         </span>
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="A1.T10.1.10.10">
       <th class="ltx_td ltx_align_top ltx_th ltx_th_row" id="A1.T10.1.10.10.1">
       </th>
       <td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T10.1.10.10.2">
        <span class="ltx_inline-block ltx_align_top" id="A1.T10.1.10.10.2.1">
         <span class="ltx_p" id="A1.T10.1.10.10.2.1.1" style="width:142.3pt;">
          Allergies
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T10.1.10.10.3">
        <span class="ltx_inline-block ltx_align_top" id="A1.T10.1.10.10.3.1">
         <span class="ltx_p" id="A1.T10.1.10.10.3.1.1" style="width:204.9pt;">
          Patient’s list of allergies (primarily medicinal)
         </span>
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="A1.T10.1.11.11">
       <th class="ltx_td ltx_align_top ltx_th ltx_th_row" id="A1.T10.1.11.11.1">
       </th>
       <td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T10.1.11.11.2">
        <span class="ltx_inline-block ltx_align_top" id="A1.T10.1.11.11.2.1">
         <span class="ltx_p" id="A1.T10.1.11.11.2.1.1" style="width:142.3pt;">
          Miscellaneous
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T10.1.11.11.3">
        <span class="ltx_inline-block ltx_align_top" id="A1.T10.1.11.11.3.1">
         <span class="ltx_p" id="A1.T10.1.11.11.3.1.1" style="width:204.9pt;">
          Patient’s clinically relevant social and other circumstances
         </span>
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="A1.T10.1.12.12">
       <th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_t" id="A1.T10.1.12.12.1">
        <span class="ltx_inline-block ltx_align_top" id="A1.T10.1.12.12.1.1">
         <span class="ltx_p" id="A1.T10.1.12.12.1.1.1" style="width:71.1pt;">
          Objective
         </span>
        </span>
       </th>
       <td class="ltx_td ltx_align_top ltx_border_t" id="A1.T10.1.12.12.2">
       </td>
       <td class="ltx_td ltx_align_top ltx_border_t" id="A1.T10.1.12.12.3">
       </td>
      </tr>
      <tr class="ltx_tr" id="A1.T10.1.13.13">
       <th class="ltx_td ltx_align_top ltx_th ltx_th_row" id="A1.T10.1.13.13.1">
       </th>
       <td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T10.1.13.13.2">
        <span class="ltx_inline-block ltx_align_top" id="A1.T10.1.13.13.2.1">
         <span class="ltx_p" id="A1.T10.1.13.13.2.1.1" style="width:142.3pt;">
          Immunizations
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T10.1.13.13.3">
        <span class="ltx_inline-block ltx_align_top" id="A1.T10.1.13.13.3.1">
         <span class="ltx_p" id="A1.T10.1.13.13.3.1.1" style="width:204.9pt;">
          Vaccination record (not frequently discussed)
         </span>
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="A1.T10.1.14.14">
       <th class="ltx_td ltx_align_top ltx_th ltx_th_row" id="A1.T10.1.14.14.1">
       </th>
       <td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T10.1.14.14.2">
        <span class="ltx_inline-block ltx_align_top" id="A1.T10.1.14.14.2.1">
         <span class="ltx_p" id="A1.T10.1.14.14.2.1.1" style="width:142.3pt;">
          Laboratory and Imaging Results
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T10.1.14.14.3">
        <span class="ltx_inline-block ltx_align_top" id="A1.T10.1.14.14.3.1">
         <span class="ltx_p" id="A1.T10.1.14.14.3.1.1" style="width:204.9pt;">
          Clinician’s discussion of laboratory/imaging results
         </span>
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="A1.T10.1.15.15">
       <th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_t" id="A1.T10.1.15.15.1">
        <span class="ltx_inline-block ltx_align_top" id="A1.T10.1.15.15.1.1">
         <span class="ltx_p" id="A1.T10.1.15.15.1.1.1" style="width:71.1pt;">
          Assessment
         </span>
        </span>
       </th>
       <td class="ltx_td ltx_align_top ltx_border_t" id="A1.T10.1.15.15.2">
       </td>
       <td class="ltx_td ltx_align_top ltx_border_t" id="A1.T10.1.15.15.3">
       </td>
      </tr>
      <tr class="ltx_tr" id="A1.T10.1.16.16">
       <th class="ltx_td ltx_align_top ltx_th ltx_th_row" id="A1.T10.1.16.16.1">
       </th>
       <td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T10.1.16.16.2">
        <span class="ltx_inline-block ltx_align_top" id="A1.T10.1.16.16.2.1">
         <span class="ltx_p" id="A1.T10.1.16.16.2.1.1" style="width:142.3pt;">
          Assessment
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T10.1.16.16.3">
        <span class="ltx_inline-block ltx_align_top" id="A1.T10.1.16.16.3.1">
         <span class="ltx_p" id="A1.T10.1.16.16.3.1.1" style="width:204.9pt;">
          Synthesis of reason for visit and pertinent diagnosis
         </span>
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="A1.T10.1.17.17">
       <th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_t" id="A1.T10.1.17.17.1">
        <span class="ltx_inline-block ltx_align_top" id="A1.T10.1.17.17.1.1">
         <span class="ltx_p" id="A1.T10.1.17.17.1.1.1" style="width:71.1pt;">
          Plan
         </span>
        </span>
       </th>
       <td class="ltx_td ltx_align_top ltx_border_t" id="A1.T10.1.17.17.2">
       </td>
       <td class="ltx_td ltx_align_top ltx_border_t" id="A1.T10.1.17.17.3">
       </td>
      </tr>
      <tr class="ltx_tr" id="A1.T10.1.18.18">
       <th class="ltx_td ltx_align_top ltx_th ltx_th_row" id="A1.T10.1.18.18.1">
       </th>
       <td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T10.1.18.18.2">
        <span class="ltx_inline-block ltx_align_top" id="A1.T10.1.18.18.2.1">
         <span class="ltx_p" id="A1.T10.1.18.18.2.1.1" style="width:142.3pt;">
          Diagnostics &amp; Appointments
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T10.1.18.18.3">
        <span class="ltx_inline-block ltx_align_top" id="A1.T10.1.18.18.3.1">
         <span class="ltx_p" id="A1.T10.1.18.18.3.1.1" style="width:204.9pt;">
          Plan for future tests, appointments, or surgeries
         </span>
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="A1.T10.1.19.19">
       <th class="ltx_td ltx_align_top ltx_th ltx_th_row ltx_border_b" id="A1.T10.1.19.19.1">
       </th>
       <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_b" id="A1.T10.1.19.19.2">
        <span class="ltx_inline-block ltx_align_top" id="A1.T10.1.19.19.2.1">
         <span class="ltx_p" id="A1.T10.1.19.19.2.1.1" style="width:142.3pt;">
          Prescriptions &amp; Therapeutics
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_b" id="A1.T10.1.19.19.3">
        <span class="ltx_inline-block ltx_align_top" id="A1.T10.1.19.19.3.1">
         <span class="ltx_p" id="A1.T10.1.19.19.3.1.1" style="width:204.9pt;">
          Plan for medications and therapeutics
         </span>
        </span>
       </td>
      </tr>
     </tbody>
    </table>
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_table">
      Table 10:
     </span>
     Details of the SOAP structure.
    </figcaption>
   </figure>
   <figure class="ltx_table" id="A1.T11">
    <div class="ltx_inline-block ltx_transformed_outer" id="A1.T11.2" style="width:405.0pt;height:271.2pt;vertical-align:-0.8pt;">
     <span class="ltx_transformed_inner" style="transform:translate(-67.5pt,45.1pt) scale(0.75,0.75) ;">
      <table class="ltx_tabular ltx_align_middle" id="A1.T11.2.2">
       <tbody class="ltx_tbody">
        <tr class="ltx_tr" id="A1.T11.2.2.3.1">
         <td class="ltx_td ltx_align_left ltx_border_t" id="A1.T11.2.2.3.1.1" rowspan="18">
          <span class="ltx_text ltx_font_bold" id="A1.T11.2.2.3.1.1.1">
           Planning Module
          </span>
         </td>
         <td class="ltx_td ltx_align_left ltx_border_t" id="A1.T11.2.2.3.1.2">
          Apply the physician and Patient prompt to generate the beginning and lead the physician LLM to ask about the
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T11.2.2.4.2">
         <td class="ltx_td ltx_align_left" id="A1.T11.2.2.4.2.1">
          medical record. Continue to generate 20 to 40 utterances conversations between physician and patient to ask
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T11.2.2.5.3">
         <td class="ltx_td ltx_align_left" id="A1.T11.2.2.5.3.1">
          or tell the patient regarding the case(you must follow up the history conversation). The conversations you
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T11.2.2.6.4">
         <td class="ltx_td ltx_align_left" id="A1.T11.2.2.6.4.1">
          generate must cover all the keywords I gave you. You cannot revise or eliminate any keywords and
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T11.2.2.7.5">
         <td class="ltx_td ltx_align_left" id="A1.T11.2.2.7.5.1">
          you cannot use synonyms of the keywords. Your conversation should also include all information.
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T11.2.2.8.6">
         <td class="ltx_td ltx_align_left" id="A1.T11.2.2.8.6.1">
          If it’s difficult to include all the information and key words, you can use the
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T11.2.2.9.7">
         <td class="ltx_td ltx_align_left" id="A1.T11.2.2.9.7.1">
          original sentences in the clinical note.
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T11.2.2.10.8">
         <td class="ltx_td ltx_align_left" id="A1.T11.2.2.10.8.1">
          The Clinical Note:
          <span class="ltx_text" id="A1.T11.2.2.10.8.1.1" style="color:#0000FF;">
           Clinical Note
          </span>
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T11.2.2.2">
         <td class="ltx_td ltx_align_left" id="A1.T11.2.2.2.2">
          The Key Words:
          <math alttext="key_{1}" class="ltx_Math" display="inline" id="A1.T11.1.1.1.1.m1.1">
           <semantics id="A1.T11.1.1.1.1.m1.1a">
            <mrow id="A1.T11.1.1.1.1.m1.1.1" xref="A1.T11.1.1.1.1.m1.1.1.cmml">
             <mi id="A1.T11.1.1.1.1.m1.1.1.2" mathcolor="#FF0000" xref="A1.T11.1.1.1.1.m1.1.1.2.cmml">
              k
             </mi>
             <mo id="A1.T11.1.1.1.1.m1.1.1.1" lspace="0em" rspace="0em" xref="A1.T11.1.1.1.1.m1.1.1.1.cmml">
              ​
             </mo>
             <mi id="A1.T11.1.1.1.1.m1.1.1.3" mathcolor="#FF0000" xref="A1.T11.1.1.1.1.m1.1.1.3.cmml">
              e
             </mi>
             <mo id="A1.T11.1.1.1.1.m1.1.1.1a" lspace="0em" rspace="0em" xref="A1.T11.1.1.1.1.m1.1.1.1.cmml">
              ​
             </mo>
             <msub id="A1.T11.1.1.1.1.m1.1.1.4" xref="A1.T11.1.1.1.1.m1.1.1.4.cmml">
              <mi id="A1.T11.1.1.1.1.m1.1.1.4.2" mathcolor="#FF0000" xref="A1.T11.1.1.1.1.m1.1.1.4.2.cmml">
               y
              </mi>
              <mn id="A1.T11.1.1.1.1.m1.1.1.4.3" mathcolor="#FF0000" xref="A1.T11.1.1.1.1.m1.1.1.4.3.cmml">
               1
              </mn>
             </msub>
            </mrow>
            <annotation-xml encoding="MathML-Content" id="A1.T11.1.1.1.1.m1.1b">
             <apply id="A1.T11.1.1.1.1.m1.1.1.cmml" xref="A1.T11.1.1.1.1.m1.1.1">
              <times id="A1.T11.1.1.1.1.m1.1.1.1.cmml" xref="A1.T11.1.1.1.1.m1.1.1.1">
              </times>
              <ci id="A1.T11.1.1.1.1.m1.1.1.2.cmml" xref="A1.T11.1.1.1.1.m1.1.1.2">
               𝑘
              </ci>
              <ci id="A1.T11.1.1.1.1.m1.1.1.3.cmml" xref="A1.T11.1.1.1.1.m1.1.1.3">
               𝑒
              </ci>
              <apply id="A1.T11.1.1.1.1.m1.1.1.4.cmml" xref="A1.T11.1.1.1.1.m1.1.1.4">
               <csymbol cd="ambiguous" id="A1.T11.1.1.1.1.m1.1.1.4.1.cmml" xref="A1.T11.1.1.1.1.m1.1.1.4">
                subscript
               </csymbol>
               <ci id="A1.T11.1.1.1.1.m1.1.1.4.2.cmml" xref="A1.T11.1.1.1.1.m1.1.1.4.2">
                𝑦
               </ci>
               <cn id="A1.T11.1.1.1.1.m1.1.1.4.3.cmml" type="integer" xref="A1.T11.1.1.1.1.m1.1.1.4.3">
                1
               </cn>
              </apply>
             </apply>
            </annotation-xml>
            <annotation encoding="application/x-tex" id="A1.T11.1.1.1.1.m1.1c">
             key_{1}
            </annotation>
           </semantics>
          </math>
          <span class="ltx_text" id="A1.T11.2.2.2.2.1" style="color:#FF0000;">
           ,
           <math alttext="key_{2}" class="ltx_Math" display="inline" id="A1.T11.2.2.2.2.1.m1.1">
            <semantics id="A1.T11.2.2.2.2.1.m1.1a">
             <mrow id="A1.T11.2.2.2.2.1.m1.1.1" xref="A1.T11.2.2.2.2.1.m1.1.1.cmml">
              <mi id="A1.T11.2.2.2.2.1.m1.1.1.2" mathcolor="#FF0000" xref="A1.T11.2.2.2.2.1.m1.1.1.2.cmml">
               k
              </mi>
              <mo id="A1.T11.2.2.2.2.1.m1.1.1.1" lspace="0em" rspace="0em" xref="A1.T11.2.2.2.2.1.m1.1.1.1.cmml">
               ​
              </mo>
              <mi id="A1.T11.2.2.2.2.1.m1.1.1.3" mathcolor="#FF0000" xref="A1.T11.2.2.2.2.1.m1.1.1.3.cmml">
               e
              </mi>
              <mo id="A1.T11.2.2.2.2.1.m1.1.1.1a" lspace="0em" rspace="0em" xref="A1.T11.2.2.2.2.1.m1.1.1.1.cmml">
               ​
              </mo>
              <msub id="A1.T11.2.2.2.2.1.m1.1.1.4" xref="A1.T11.2.2.2.2.1.m1.1.1.4.cmml">
               <mi id="A1.T11.2.2.2.2.1.m1.1.1.4.2" mathcolor="#FF0000" xref="A1.T11.2.2.2.2.1.m1.1.1.4.2.cmml">
                y
               </mi>
               <mn id="A1.T11.2.2.2.2.1.m1.1.1.4.3" mathcolor="#FF0000" xref="A1.T11.2.2.2.2.1.m1.1.1.4.3.cmml">
                2
               </mn>
              </msub>
             </mrow>
             <annotation-xml encoding="MathML-Content" id="A1.T11.2.2.2.2.1.m1.1b">
              <apply id="A1.T11.2.2.2.2.1.m1.1.1.cmml" xref="A1.T11.2.2.2.2.1.m1.1.1">
               <times id="A1.T11.2.2.2.2.1.m1.1.1.1.cmml" xref="A1.T11.2.2.2.2.1.m1.1.1.1">
               </times>
               <ci id="A1.T11.2.2.2.2.1.m1.1.1.2.cmml" xref="A1.T11.2.2.2.2.1.m1.1.1.2">
                𝑘
               </ci>
               <ci id="A1.T11.2.2.2.2.1.m1.1.1.3.cmml" xref="A1.T11.2.2.2.2.1.m1.1.1.3">
                𝑒
               </ci>
               <apply id="A1.T11.2.2.2.2.1.m1.1.1.4.cmml" xref="A1.T11.2.2.2.2.1.m1.1.1.4">
                <csymbol cd="ambiguous" id="A1.T11.2.2.2.2.1.m1.1.1.4.1.cmml" xref="A1.T11.2.2.2.2.1.m1.1.1.4">
                 subscript
                </csymbol>
                <ci id="A1.T11.2.2.2.2.1.m1.1.1.4.2.cmml" xref="A1.T11.2.2.2.2.1.m1.1.1.4.2">
                 𝑦
                </ci>
                <cn id="A1.T11.2.2.2.2.1.m1.1.1.4.3.cmml" type="integer" xref="A1.T11.2.2.2.2.1.m1.1.1.4.3">
                 2
                </cn>
               </apply>
              </apply>
             </annotation-xml>
             <annotation encoding="application/x-tex" id="A1.T11.2.2.2.2.1.m1.1c">
              key_{2}
             </annotation>
            </semantics>
           </math>
           ,…
          </span>
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T11.2.2.11.9">
         <td class="ltx_td ltx_align_left" id="A1.T11.2.2.11.9.1">
          Your conversations must include all the keywords I provided to you, and if it’s not possible to
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T11.2.2.12.10">
         <td class="ltx_td ltx_align_left" id="A1.T11.2.2.12.10.1">
          include them all, you can make slight modifications based on the original wording in the notes.
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T11.2.2.13.11">
         <td class="ltx_td ltx_align_left" id="A1.T11.2.2.13.11.1">
          You cannot revise or eliminate any key words and you cannot use synonyms of the keywords.
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T11.2.2.14.12">
         <td class="ltx_td ltx_align_left" id="A1.T11.2.2.14.12.1">
          Your conversation should also include all information. If it’s difficult to include all the information
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T11.2.2.15.13">
         <td class="ltx_td ltx_align_left" id="A1.T11.2.2.15.13.1">
          and key words, you can use the original sentences in the clinical note. Your generation must
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T11.2.2.16.14">
         <td class="ltx_td ltx_align_left" id="A1.T11.2.2.16.14.1">
          follow the logical sequence of a physician’s inquiry. Your conversations must follow the logical
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T11.2.2.17.15">
         <td class="ltx_td ltx_align_left" id="A1.T11.2.2.17.15.1">
          sequence of a physician’s inquiry. For example, the general logical order of the conversation is: first
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T11.2.2.18.16">
         <td class="ltx_td ltx_align_left" id="A1.T11.2.2.18.16.1">
          discussing symptoms, then discussing the medical history, followed by discussing testing and
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T11.2.2.19.17">
         <td class="ltx_td ltx_align_left" id="A1.T11.2.2.19.17.1">
          results, and finally discussing the conclusion and treatment options, etc. The physician didn’t know
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T11.2.2.20.18">
         <td class="ltx_td ltx_border_b" id="A1.T11.2.2.20.18.1">
         </td>
         <td class="ltx_td ltx_align_left ltx_border_b" id="A1.T11.2.2.20.18.2">
          any information of medical history or symptoms. This information should be told by the patient
         </td>
        </tr>
       </tbody>
      </table>
     </span>
    </div>
    <figcaption class="ltx_caption">
     <span class="ltx_tag ltx_tag_table">
      Table 11:
     </span>
     Planning Module prompt.
    </figcaption>
   </figure>
   <figure class="ltx_table" id="A1.T12">
    <div class="ltx_inline-block ltx_transformed_outer" id="A1.T12.2" style="width:408.5pt;height:697.7pt;vertical-align:-0.8pt;">
     <span class="ltx_transformed_inner" style="transform:translate(-68.1pt,116.2pt) scale(0.75,0.75) ;">
      <table class="ltx_tabular ltx_align_middle" id="A1.T12.2.2">
       <tbody class="ltx_tbody">
        <tr class="ltx_tr" id="A1.T12.2.2.3.1">
         <td class="ltx_td ltx_align_left ltx_border_t" id="A1.T12.2.2.3.1.1" rowspan="26">
          <span class="ltx_text ltx_font_bold" id="A1.T12.2.2.3.1.1.1">
           Physician Prompt
          </span>
         </td>
         <td class="ltx_td ltx_align_left ltx_border_t" id="A1.T12.2.2.3.1.2">
          Please role-play as a physician and further generate questions or conclusion, or the test
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T12.2.2.4.2">
         <td class="ltx_td ltx_align_left" id="A1.T12.2.2.4.2.1">
          result(such as medication test result or vital signs) based on the above dialogue and clinical
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T12.2.2.5.3">
         <td class="ltx_td ltx_align_left" id="A1.T12.2.2.5.3.1">
          note(after mentioned examination, you have to know test results and vital signs so you shouldn’t ask
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T12.2.2.6.4">
         <td class="ltx_td ltx_align_left" id="A1.T12.2.2.6.4.1">
          the patient about a test result or vital signs). Add ’physician:’ before each round. Your question,
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T12.2.2.7.5">
         <td class="ltx_td ltx_align_left" id="A1.T12.2.2.7.5.1">
          answer or conclusion(tell the patient the test result) should be around the keywords (I gave you)
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T12.2.2.8.6">
         <td class="ltx_td ltx_align_left" id="A1.T12.2.2.8.6.1">
          corresponding to the clinical note(finally, the whole conversation should include all the keywords).
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T12.2.2.9.7">
         <td class="ltx_td ltx_align_left" id="A1.T12.2.2.9.7.1">
          the answer of your questions can be found on the clinical note. You cannot modify these key
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T12.2.2.10.8">
         <td class="ltx_td ltx_align_left" id="A1.T12.2.2.10.8.1">
          words or use synonyms. You need to ensure the treatment plan, medication, and dosage you give to
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T12.2.2.11.9">
         <td class="ltx_td ltx_align_left" id="A1.T12.2.2.11.9.1">
          the patient must also be totally consistent with the clinical note. Do not ask questions which
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T12.2.2.12.10">
         <td class="ltx_td ltx_align_left" id="A1.T12.2.2.12.10.1">
          answers cannot be found in the clinical note. You may describe and explain professional judgment to
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T12.2.2.13.11">
         <td class="ltx_td ltx_align_left" id="A1.T12.2.2.13.11.1">
          the patient and instruct the patient on follow-up requirements, but not ask questions that require
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T12.2.2.14.12">
         <td class="ltx_td ltx_align_left" id="A1.T12.2.2.14.12.1">
          professional medical knowledge to answer. The order of the questions you ask must match the order
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T12.2.2.15.13">
         <td class="ltx_td ltx_align_left" id="A1.T12.2.2.15.13.1">
          of the keywords I provided. If it’s not possible to include them all, you can make slight modifications
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T12.2.2.16.14">
         <td class="ltx_td ltx_align_left" id="A1.T12.2.2.16.14.1">
          based on the original wording in the notes. If the history conversation has included
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T12.2.2.17.15">
         <td class="ltx_td ltx_align_left" id="A1.T12.2.2.17.15.1">
          the keywords, there is no need to include them again. The treatment plan and conclusions
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T12.2.2.18.16">
         <td class="ltx_td ltx_align_left" id="A1.T12.2.2.18.16.1">
          you provide must align completely with the clinical notes. Do not add treatment plans
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T12.2.2.19.17">
         <td class="ltx_td ltx_align_left" id="A1.T12.2.2.19.17.1">
          that is not present in the clinical notes. You don’t know the patient’s medical history and symptoms.
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T12.2.2.20.18">
         <td class="ltx_td ltx_align_left" id="A1.T12.2.2.20.18.1">
          You should ask or lead the patient to tell you the symptoms and his medical history, and you
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T12.2.2.21.19">
         <td class="ltx_td ltx_align_left" id="A1.T12.2.2.21.19.1">
          don’t have any information about his medical history and symptoms. All the information of medical
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T12.2.2.22.20">
         <td class="ltx_td ltx_align_left" id="A1.T12.2.2.22.20.1">
          history, symptoms, medication history, and vaccination history should be told by the patient. You can
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T12.2.2.23.21">
         <td class="ltx_td ltx_align_left" id="A1.T12.2.2.23.21.1">
          tell the patient the test results, vital signs, and some conclusions.
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T12.2.2.24.22">
         <td class="ltx_td ltx_align_left" id="A1.T12.2.2.24.22.1">
          The Clinical Note:
          <span class="ltx_text" id="A1.T12.2.2.24.22.1.1" style="color:#0000FF;">
           Clinical Note
          </span>
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T12.2.2.2">
         <td class="ltx_td ltx_align_left" id="A1.T12.2.2.2.2">
          The Key Words:
          <math alttext="key_{1}" class="ltx_Math" display="inline" id="A1.T12.1.1.1.1.m1.1">
           <semantics id="A1.T12.1.1.1.1.m1.1a">
            <mrow id="A1.T12.1.1.1.1.m1.1.1" xref="A1.T12.1.1.1.1.m1.1.1.cmml">
             <mi id="A1.T12.1.1.1.1.m1.1.1.2" mathcolor="#FF0000" xref="A1.T12.1.1.1.1.m1.1.1.2.cmml">
              k
             </mi>
             <mo id="A1.T12.1.1.1.1.m1.1.1.1" lspace="0em" rspace="0em" xref="A1.T12.1.1.1.1.m1.1.1.1.cmml">
              ​
             </mo>
             <mi id="A1.T12.1.1.1.1.m1.1.1.3" mathcolor="#FF0000" xref="A1.T12.1.1.1.1.m1.1.1.3.cmml">
              e
             </mi>
             <mo id="A1.T12.1.1.1.1.m1.1.1.1a" lspace="0em" rspace="0em" xref="A1.T12.1.1.1.1.m1.1.1.1.cmml">
              ​
             </mo>
             <msub id="A1.T12.1.1.1.1.m1.1.1.4" xref="A1.T12.1.1.1.1.m1.1.1.4.cmml">
              <mi id="A1.T12.1.1.1.1.m1.1.1.4.2" mathcolor="#FF0000" xref="A1.T12.1.1.1.1.m1.1.1.4.2.cmml">
               y
              </mi>
              <mn id="A1.T12.1.1.1.1.m1.1.1.4.3" mathcolor="#FF0000" xref="A1.T12.1.1.1.1.m1.1.1.4.3.cmml">
               1
              </mn>
             </msub>
            </mrow>
            <annotation-xml encoding="MathML-Content" id="A1.T12.1.1.1.1.m1.1b">
             <apply id="A1.T12.1.1.1.1.m1.1.1.cmml" xref="A1.T12.1.1.1.1.m1.1.1">
              <times id="A1.T12.1.1.1.1.m1.1.1.1.cmml" xref="A1.T12.1.1.1.1.m1.1.1.1">
              </times>
              <ci id="A1.T12.1.1.1.1.m1.1.1.2.cmml" xref="A1.T12.1.1.1.1.m1.1.1.2">
               𝑘
              </ci>
              <ci id="A1.T12.1.1.1.1.m1.1.1.3.cmml" xref="A1.T12.1.1.1.1.m1.1.1.3">
               𝑒
              </ci>
              <apply id="A1.T12.1.1.1.1.m1.1.1.4.cmml" xref="A1.T12.1.1.1.1.m1.1.1.4">
               <csymbol cd="ambiguous" id="A1.T12.1.1.1.1.m1.1.1.4.1.cmml" xref="A1.T12.1.1.1.1.m1.1.1.4">
                subscript
               </csymbol>
               <ci id="A1.T12.1.1.1.1.m1.1.1.4.2.cmml" xref="A1.T12.1.1.1.1.m1.1.1.4.2">
                𝑦
               </ci>
               <cn id="A1.T12.1.1.1.1.m1.1.1.4.3.cmml" type="integer" xref="A1.T12.1.1.1.1.m1.1.1.4.3">
                1
               </cn>
              </apply>
             </apply>
            </annotation-xml>
            <annotation encoding="application/x-tex" id="A1.T12.1.1.1.1.m1.1c">
             key_{1}
            </annotation>
           </semantics>
          </math>
          <span class="ltx_text" id="A1.T12.2.2.2.2.1" style="color:#FF0000;">
           ,
           <math alttext="key_{2}" class="ltx_Math" display="inline" id="A1.T12.2.2.2.2.1.m1.1">
            <semantics id="A1.T12.2.2.2.2.1.m1.1a">
             <mrow id="A1.T12.2.2.2.2.1.m1.1.1" xref="A1.T12.2.2.2.2.1.m1.1.1.cmml">
              <mi id="A1.T12.2.2.2.2.1.m1.1.1.2" mathcolor="#FF0000" xref="A1.T12.2.2.2.2.1.m1.1.1.2.cmml">
               k
              </mi>
              <mo id="A1.T12.2.2.2.2.1.m1.1.1.1" lspace="0em" rspace="0em" xref="A1.T12.2.2.2.2.1.m1.1.1.1.cmml">
               ​
              </mo>
              <mi id="A1.T12.2.2.2.2.1.m1.1.1.3" mathcolor="#FF0000" xref="A1.T12.2.2.2.2.1.m1.1.1.3.cmml">
               e
              </mi>
              <mo id="A1.T12.2.2.2.2.1.m1.1.1.1a" lspace="0em" rspace="0em" xref="A1.T12.2.2.2.2.1.m1.1.1.1.cmml">
               ​
              </mo>
              <msub id="A1.T12.2.2.2.2.1.m1.1.1.4" xref="A1.T12.2.2.2.2.1.m1.1.1.4.cmml">
               <mi id="A1.T12.2.2.2.2.1.m1.1.1.4.2" mathcolor="#FF0000" xref="A1.T12.2.2.2.2.1.m1.1.1.4.2.cmml">
                y
               </mi>
               <mn id="A1.T12.2.2.2.2.1.m1.1.1.4.3" mathcolor="#FF0000" xref="A1.T12.2.2.2.2.1.m1.1.1.4.3.cmml">
                2
               </mn>
              </msub>
             </mrow>
             <annotation-xml encoding="MathML-Content" id="A1.T12.2.2.2.2.1.m1.1b">
              <apply id="A1.T12.2.2.2.2.1.m1.1.1.cmml" xref="A1.T12.2.2.2.2.1.m1.1.1">
               <times id="A1.T12.2.2.2.2.1.m1.1.1.1.cmml" xref="A1.T12.2.2.2.2.1.m1.1.1.1">
               </times>
               <ci id="A1.T12.2.2.2.2.1.m1.1.1.2.cmml" xref="A1.T12.2.2.2.2.1.m1.1.1.2">
                𝑘
               </ci>
               <ci id="A1.T12.2.2.2.2.1.m1.1.1.3.cmml" xref="A1.T12.2.2.2.2.1.m1.1.1.3">
                𝑒
               </ci>
               <apply id="A1.T12.2.2.2.2.1.m1.1.1.4.cmml" xref="A1.T12.2.2.2.2.1.m1.1.1.4">
                <csymbol cd="ambiguous" id="A1.T12.2.2.2.2.1.m1.1.1.4.1.cmml" xref="A1.T12.2.2.2.2.1.m1.1.1.4">
                 subscript
                </csymbol>
                <ci id="A1.T12.2.2.2.2.1.m1.1.1.4.2.cmml" xref="A1.T12.2.2.2.2.1.m1.1.1.4.2">
                 𝑦
                </ci>
                <cn id="A1.T12.2.2.2.2.1.m1.1.1.4.3.cmml" type="integer" xref="A1.T12.2.2.2.2.1.m1.1.1.4.3">
                 2
                </cn>
               </apply>
              </apply>
             </annotation-xml>
             <annotation encoding="application/x-tex" id="A1.T12.2.2.2.2.1.m1.1c">
              key_{2}
             </annotation>
            </semantics>
           </math>
           ,…
          </span>
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T12.2.2.25.23">
         <td class="ltx_td ltx_align_left" id="A1.T12.2.2.25.23.1">
          The History Conversation:
          <span class="ltx_text" id="A1.T12.2.2.25.23.1.1" style="color:#BF0040;">
           History Dialogue
          </span>
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T12.2.2.26.24">
         <td class="ltx_td ltx_align_left" id="A1.T12.2.2.26.24.1">
          You should only generate one utterance based on history conversation. Remember, you are the physician, not the patient.
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T12.2.2.27.25">
         <td class="ltx_td ltx_align_left" id="A1.T12.2.2.27.25.1">
          Don’t mention the information that has been mentioned in history conversation. If you feel that the patient’s
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T12.2.2.28.26">
         <td class="ltx_td" id="A1.T12.2.2.28.26.1">
         </td>
         <td class="ltx_td ltx_align_left" id="A1.T12.2.2.28.26.2">
          information is incomplete, you can supplement it based on the clinical note and include relevant
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T12.2.2.29.27">
         <td class="ltx_td" id="A1.T12.2.2.29.27.1">
         </td>
         <td class="ltx_td ltx_align_left" id="A1.T12.2.2.29.27.2">
          keywords. However, please refrain from saying, ’based on medical record or clinical note.’
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T12.2.2.30.28">
         <td class="ltx_td" id="A1.T12.2.2.30.28.1">
         </td>
         <td class="ltx_td ltx_align_left" id="A1.T12.2.2.30.28.2">
          Instead, you should say, ’I guess…’
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T12.2.2.31.29">
         <td class="ltx_td ltx_align_left ltx_border_tt" id="A1.T12.2.2.31.29.1" rowspan="16">
          <span class="ltx_text ltx_font_bold" id="A1.T12.2.2.31.29.1.1">
           Patient Prompt
          </span>
         </td>
         <td class="ltx_td ltx_align_left ltx_border_tt" id="A1.T12.2.2.31.29.2">
          Act as a patient to reply to the physician. Add ’Patient:’ before each round. Your answer should
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T12.2.2.32.30">
         <td class="ltx_td ltx_align_left" id="A1.T12.2.2.32.30.1">
          align with the clinical notes. You are just an ordinary person. Your response should be made as
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T12.2.2.33.31">
         <td class="ltx_td ltx_align_left" id="A1.T12.2.2.33.31.1">
          colloquial as possible. Don’t mention any experimental results, conclusions, or medical dosage.
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T12.2.2.34.32">
         <td class="ltx_td ltx_align_left" id="A1.T12.2.2.34.32.1">
          because you’re just an ordinary person and may not understand the meaning of these results.
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T12.2.2.35.33">
         <td class="ltx_td ltx_align_left" id="A1.T12.2.2.35.33.1">
          But you could tell the physician your medical history, medication history, or vaccination history
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T12.2.2.36.34">
         <td class="ltx_td ltx_align_left" id="A1.T12.2.2.36.34.1">
          (medical history, medication history, or vaccination history are all long to medical history).
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T12.2.2.37.35">
         <td class="ltx_td ltx_align_left" id="A1.T12.2.2.37.35.1">
          Your response should revolve around the physician’s words and avoid adding information that was not mentioned.
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T12.2.2.38.36">
         <td class="ltx_td ltx_align_left" id="A1.T12.2.2.38.36.1">
          The Clinical Note:
          <span class="ltx_text" id="A1.T12.2.2.38.36.1.1" style="color:#0000FF;">
           Clinical Note
          </span>
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T12.2.2.39.37">
         <td class="ltx_td ltx_align_left" id="A1.T12.2.2.39.37.1">
          The History Conversation:
          <span class="ltx_text" id="A1.T12.2.2.39.37.1.1" style="color:#BF0040;">
           History Dialogue
          </span>
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T12.2.2.40.38">
         <td class="ltx_td ltx_align_left" id="A1.T12.2.2.40.38.1">
          Your reply should be succinct and accurate in a colloquial lay language style and must be aligned
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T12.2.2.41.39">
         <td class="ltx_td ltx_align_left" id="A1.T12.2.2.41.39.1">
          with clinical notes. Don’t generate the part which should be said by the physician. Do not say all the
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T12.2.2.42.40">
         <td class="ltx_td ltx_align_left" id="A1.T12.2.2.42.40.1">
          information unless the physician asks about it. You cannot say any information about your test result
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T12.2.2.43.41">
         <td class="ltx_td ltx_align_left" id="A1.T12.2.2.43.41.1">
          or vital signs. Your medical history, vaccination history, and medication history all belong to
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T12.2.2.44.42">
         <td class="ltx_td ltx_align_left" id="A1.T12.2.2.44.42.1">
          medical history. Your reply must be completely aligned with the clinical note. But you cannot say any
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T12.2.2.45.43">
         <td class="ltx_td ltx_align_left" id="A1.T12.2.2.45.43.1">
          examination or test results because you are not a physician. You must not be able to use highly
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T12.2.2.46.44">
         <td class="ltx_td ltx_align_left" id="A1.T12.2.2.46.44.1">
          specialized terms or medical terminology. You can only describe limited common symptoms.
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T12.2.2.47.45">
         <td class="ltx_td" id="A1.T12.2.2.47.45.1">
         </td>
         <td class="ltx_td ltx_align_left" id="A1.T12.2.2.47.45.2">
          You shouldn’t use the abbreviation if you know the full name(you should use the full name, not the abbreviation,
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T12.2.2.48.46">
         <td class="ltx_td ltx_border_b" id="A1.T12.2.2.48.46.1">
         </td>
         <td class="ltx_td ltx_align_left ltx_border_b" id="A1.T12.2.2.48.46.2">
          such as D9 must be day 9, D7 must be day 7
         </td>
        </tr>
       </tbody>
      </table>
     </span>
    </div>
    <figcaption class="ltx_caption">
     <span class="ltx_tag ltx_tag_table">
      Table 12:
     </span>
     Roleplay module prompt for physician role and patient role.
    </figcaption>
   </figure>
   <figure class="ltx_table" id="A1.T13">
    <div class="ltx_inline-block ltx_transformed_outer" id="A1.T13.2" style="width:406.2pt;height:884.2pt;vertical-align:-0.8pt;">
     <span class="ltx_transformed_inner" style="transform:translate(-67.7pt,147.2pt) scale(0.75,0.75) ;">
      <table class="ltx_tabular ltx_align_middle" id="A1.T13.2.2">
       <tbody class="ltx_tbody">
        <tr class="ltx_tr" id="A1.T13.2.2.3.1">
         <td class="ltx_td ltx_align_left ltx_border_t" id="A1.T13.2.2.3.1.1" rowspan="61">
          <span class="ltx_text ltx_font_bold" id="A1.T13.2.2.3.1.1.1">
           Polish Prompt
          </span>
         </td>
         <td class="ltx_td ltx_align_left ltx_border_t" id="A1.T13.2.2.3.1.2">
          <span class="ltx_text" id="A1.T13.2.2.3.1.2.1" style="background-color:#AD5CFF;">
           Expand the conversation.
          </span>
          <span class="ltx_text" id="A1.T13.2.2.3.1.2.2" style="background-color:#FFFF00;">
           The conversation for patient parts can be more colloquial.
          </span>
          When the physician
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T13.2.2.4.2">
         <td class="ltx_td ltx_align_left" id="A1.T13.2.2.4.2.1">
          is speaking,
          <span class="ltx_text" id="A1.T13.2.2.4.2.1.1" style="background-color:#00FF00;">
           the patient can have many modal particles (e.g. hmm, yes, okay) to increase interaction.
          </span>
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T13.2.2.5.3">
         <td class="ltx_td ltx_align_left" id="A1.T13.2.2.5.3.1">
          <span class="ltx_text" id="A1.T13.2.2.5.3.1.1" style="background-color:#FFBFBF;">
           All the numbers and medical concepts that appear in the note should be mentioned by the physician.
          </span>
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T13.2.2.6.4">
         <td class="ltx_td ltx_align_left" id="A1.T13.2.2.6.4.1">
          <span class="ltx_text" id="A1.T13.2.2.6.4.1.1" style="background-color:#FFBFBF;">
           Professional medical terms and numbers should always occur in the physician’s utterances but not in
          </span>
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T13.2.2.7.5">
         <td class="ltx_td ltx_align_left" id="A1.T13.2.2.7.5.1">
          <span class="ltx_text" id="A1.T13.2.2.7.5.1.1" style="background-color:#FFBFBF;">
           the patient’s answer.
          </span>
          The physician may describe and explain professional judgment to the patient
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T13.2.2.8.6">
         <td class="ltx_td ltx_align_left" id="A1.T13.2.2.8.6.1">
          and instruct the patient on follow-up requirements,
          <span class="ltx_text" id="A1.T13.2.2.8.6.1.1" style="background-color:#FFBFBF;">
           but not ask questions that require professional
          </span>
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T13.2.2.9.7">
         <td class="ltx_td ltx_align_left" id="A1.T13.2.2.9.7.1">
          <span class="ltx_text" id="A1.T13.2.2.9.7.1.1" style="background-color:#FFBFBF;">
           medical knowledge to answer
          </span>
          <span class="ltx_text" id="A1.T13.2.2.9.7.1.2" style="background-color:#B80000;">
           and the question must be around the clinical note(the patient could
          </span>
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T13.2.2.10.8">
         <td class="ltx_td ltx_align_left" id="A1.T13.2.2.10.8.1">
          <span class="ltx_text" id="A1.T13.2.2.10.8.1.1" style="background-color:#B80000;">
           find the answer on the clinical note).
          </span>
          <span class="ltx_text" id="A1.T13.2.2.10.8.1.2" style="background-color:#808080;">
           All the information of medical history, symptoms and medication
          </span>
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T13.2.2.11.9">
         <td class="ltx_td ltx_align_left" id="A1.T13.2.2.11.9.1">
          <span class="ltx_text" id="A1.T13.2.2.11.9.1.1" style="background-color:#808080;">
           history should be told by patient.
          </span>
          <span class="ltx_text" id="A1.T13.2.2.11.9.1.2" style="background-color:#FFFF00;">
           The patient’s answer should be succinct and accurate in a
          </span>
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T13.2.2.12.10">
         <td class="ltx_td ltx_align_left" id="A1.T13.2.2.12.10.1">
          <span class="ltx_text" id="A1.T13.2.2.12.10.1.1" style="background-color:#FFFF00;">
           colloquial lay language style. The answer should align with the clinical notes and as colloquial
          </span>
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T13.2.2.13.11">
         <td class="ltx_td ltx_align_left" id="A1.T13.2.2.13.11.1">
          <span class="ltx_text" id="A1.T13.2.2.13.11.1.1" style="background-color:#FFFF00;">
           as possible.
          </span>
          <span class="ltx_text" id="A1.T13.2.2.13.11.1.2" style="background-color:#00FF80;">
           You can add some transitional phrases to make the conversation more logical.
          </span>
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T13.2.2.14.12">
         <td class="ltx_td ltx_align_left" id="A1.T13.2.2.14.12.1">
          For example:
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T13.2.2.15.13">
         <td class="ltx_td ltx_align_left" id="A1.T13.2.2.15.13.1">
          Example 1:
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T13.2.2.16.14">
         <td class="ltx_td ltx_align_left" id="A1.T13.2.2.16.14.1">
          Patient: I understand, please go ahead.
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T13.2.2.17.15">
         <td class="ltx_td ltx_align_left" id="A1.T13.2.2.17.15.1">
          (After examination)
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T13.2.2.18.16">
         <td class="ltx_td ltx_align_left" id="A1.T13.2.2.18.16.1">
          physician: The result shows….
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T13.2.2.19.17">
         <td class="ltx_td ltx_align_left" id="A1.T13.2.2.19.17.1">
          Example 2:
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T13.2.2.20.18">
         <td class="ltx_td ltx_align_left" id="A1.T13.2.2.20.18.1">
          Patient: Thank you for the diagnosis, physician.
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T13.2.2.21.19">
         <td class="ltx_td ltx_align_left" id="A1.T13.2.2.21.19.1">
          (After two years)
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T13.2.2.22.20">
         <td class="ltx_td ltx_align_left" id="A1.T13.2.2.22.20.1">
          physician: Hi…
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T13.2.2.23.21">
         <td class="ltx_td ltx_align_left" id="A1.T13.2.2.23.21.1">
          Example 3:
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T13.2.2.24.22">
         <td class="ltx_td ltx_align_left" id="A1.T13.2.2.24.22.1">
          Patient: Okay, I understand.
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T13.2.2.25.23">
         <td class="ltx_td ltx_align_left" id="A1.T13.2.2.25.23.1">
          (Few days latter)
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T13.2.2.26.24">
         <td class="ltx_td ltx_align_left" id="A1.T13.2.2.26.24.1">
          physician: Hi…
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T13.2.2.27.25">
         <td class="ltx_td ltx_align_left" id="A1.T13.2.2.27.25.1">
          <span class="ltx_text" id="A1.T13.2.2.27.25.1.1" style="background-color:#61FFE0;">
           Your conversations must follow the logical sequence of a physician’s inquiry. For example, the general
          </span>
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T13.2.2.28.26">
         <td class="ltx_td ltx_align_left" id="A1.T13.2.2.28.26.1">
          <span class="ltx_text" id="A1.T13.2.2.28.26.1.1" style="background-color:#61FFE0;">
           logical order of the conversation is: first discussing symptoms, then discussing the
          </span>
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T13.2.2.29.27">
         <td class="ltx_td ltx_align_left" id="A1.T13.2.2.29.27.1">
          <span class="ltx_text" id="A1.T13.2.2.29.27.1.1" style="background-color:#61FFE0;">
           medical history, followed by discussing testing and results, and finally discussing treatment
          </span>
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T13.2.2.30.28">
         <td class="ltx_td ltx_align_left" id="A1.T13.2.2.30.28.1">
          <span class="ltx_text" id="A1.T13.2.2.30.28.1.1" style="background-color:#61FFE0;">
           options, conclusioin etc."
          </span>
          <span class="ltx_text" id="A1.T13.2.2.30.28.1.2" style="background-color:#00FF80;">
           If you find this conversation to be incoherent, you can try dividing it
          </span>
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T13.2.2.31.29">
         <td class="ltx_td ltx_align_left" id="A1.T13.2.2.31.29.1">
          <span class="ltx_text" id="A1.T13.2.2.31.29.1.1" style="background-color:#00FF80;">
           into two separate coherent conversations.
          </span>
          <span class="ltx_text" id="A1.T13.2.2.31.29.1.2" style="background-color:#AD5CFF;">
           Patients should not say too much information at once.
          </span>
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T13.2.2.32.30">
         <td class="ltx_td ltx_align_left" id="A1.T13.2.2.32.30.1">
          The Clinical Note:
          <span class="ltx_text" id="A1.T13.2.2.32.30.1.1" style="color:#0000FF;">
           Clinical Note
          </span>
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T13.2.2.2">
         <td class="ltx_td ltx_align_left" id="A1.T13.2.2.2.2">
          The Key Words:
          <math alttext="key_{1}" class="ltx_Math" display="inline" id="A1.T13.1.1.1.1.m1.1">
           <semantics id="A1.T13.1.1.1.1.m1.1a">
            <mrow id="A1.T13.1.1.1.1.m1.1.1" xref="A1.T13.1.1.1.1.m1.1.1.cmml">
             <mi id="A1.T13.1.1.1.1.m1.1.1.2" mathcolor="#FF0000" xref="A1.T13.1.1.1.1.m1.1.1.2.cmml">
              k
             </mi>
             <mo id="A1.T13.1.1.1.1.m1.1.1.1" lspace="0em" rspace="0em" xref="A1.T13.1.1.1.1.m1.1.1.1.cmml">
              ​
             </mo>
             <mi id="A1.T13.1.1.1.1.m1.1.1.3" mathcolor="#FF0000" xref="A1.T13.1.1.1.1.m1.1.1.3.cmml">
              e
             </mi>
             <mo id="A1.T13.1.1.1.1.m1.1.1.1a" lspace="0em" rspace="0em" xref="A1.T13.1.1.1.1.m1.1.1.1.cmml">
              ​
             </mo>
             <msub id="A1.T13.1.1.1.1.m1.1.1.4" xref="A1.T13.1.1.1.1.m1.1.1.4.cmml">
              <mi id="A1.T13.1.1.1.1.m1.1.1.4.2" mathcolor="#FF0000" xref="A1.T13.1.1.1.1.m1.1.1.4.2.cmml">
               y
              </mi>
              <mn id="A1.T13.1.1.1.1.m1.1.1.4.3" mathcolor="#FF0000" xref="A1.T13.1.1.1.1.m1.1.1.4.3.cmml">
               1
              </mn>
             </msub>
            </mrow>
            <annotation-xml encoding="MathML-Content" id="A1.T13.1.1.1.1.m1.1b">
             <apply id="A1.T13.1.1.1.1.m1.1.1.cmml" xref="A1.T13.1.1.1.1.m1.1.1">
              <times id="A1.T13.1.1.1.1.m1.1.1.1.cmml" xref="A1.T13.1.1.1.1.m1.1.1.1">
              </times>
              <ci id="A1.T13.1.1.1.1.m1.1.1.2.cmml" xref="A1.T13.1.1.1.1.m1.1.1.2">
               𝑘
              </ci>
              <ci id="A1.T13.1.1.1.1.m1.1.1.3.cmml" xref="A1.T13.1.1.1.1.m1.1.1.3">
               𝑒
              </ci>
              <apply id="A1.T13.1.1.1.1.m1.1.1.4.cmml" xref="A1.T13.1.1.1.1.m1.1.1.4">
               <csymbol cd="ambiguous" id="A1.T13.1.1.1.1.m1.1.1.4.1.cmml" xref="A1.T13.1.1.1.1.m1.1.1.4">
                subscript
               </csymbol>
               <ci id="A1.T13.1.1.1.1.m1.1.1.4.2.cmml" xref="A1.T13.1.1.1.1.m1.1.1.4.2">
                𝑦
               </ci>
               <cn id="A1.T13.1.1.1.1.m1.1.1.4.3.cmml" type="integer" xref="A1.T13.1.1.1.1.m1.1.1.4.3">
                1
               </cn>
              </apply>
             </apply>
            </annotation-xml>
            <annotation encoding="application/x-tex" id="A1.T13.1.1.1.1.m1.1c">
             key_{1}
            </annotation>
           </semantics>
          </math>
          <span class="ltx_text" id="A1.T13.2.2.2.2.1" style="color:#FF0000;">
           ,
           <math alttext="key_{2}" class="ltx_Math" display="inline" id="A1.T13.2.2.2.2.1.m1.1">
            <semantics id="A1.T13.2.2.2.2.1.m1.1a">
             <mrow id="A1.T13.2.2.2.2.1.m1.1.1" xref="A1.T13.2.2.2.2.1.m1.1.1.cmml">
              <mi id="A1.T13.2.2.2.2.1.m1.1.1.2" mathcolor="#FF0000" xref="A1.T13.2.2.2.2.1.m1.1.1.2.cmml">
               k
              </mi>
              <mo id="A1.T13.2.2.2.2.1.m1.1.1.1" lspace="0em" rspace="0em" xref="A1.T13.2.2.2.2.1.m1.1.1.1.cmml">
               ​
              </mo>
              <mi id="A1.T13.2.2.2.2.1.m1.1.1.3" mathcolor="#FF0000" xref="A1.T13.2.2.2.2.1.m1.1.1.3.cmml">
               e
              </mi>
              <mo id="A1.T13.2.2.2.2.1.m1.1.1.1a" lspace="0em" rspace="0em" xref="A1.T13.2.2.2.2.1.m1.1.1.1.cmml">
               ​
              </mo>
              <msub id="A1.T13.2.2.2.2.1.m1.1.1.4" xref="A1.T13.2.2.2.2.1.m1.1.1.4.cmml">
               <mi id="A1.T13.2.2.2.2.1.m1.1.1.4.2" mathcolor="#FF0000" xref="A1.T13.2.2.2.2.1.m1.1.1.4.2.cmml">
                y
               </mi>
               <mn id="A1.T13.2.2.2.2.1.m1.1.1.4.3" mathcolor="#FF0000" xref="A1.T13.2.2.2.2.1.m1.1.1.4.3.cmml">
                2
               </mn>
              </msub>
             </mrow>
             <annotation-xml encoding="MathML-Content" id="A1.T13.2.2.2.2.1.m1.1b">
              <apply id="A1.T13.2.2.2.2.1.m1.1.1.cmml" xref="A1.T13.2.2.2.2.1.m1.1.1">
               <times id="A1.T13.2.2.2.2.1.m1.1.1.1.cmml" xref="A1.T13.2.2.2.2.1.m1.1.1.1">
               </times>
               <ci id="A1.T13.2.2.2.2.1.m1.1.1.2.cmml" xref="A1.T13.2.2.2.2.1.m1.1.1.2">
                𝑘
               </ci>
               <ci id="A1.T13.2.2.2.2.1.m1.1.1.3.cmml" xref="A1.T13.2.2.2.2.1.m1.1.1.3">
                𝑒
               </ci>
               <apply id="A1.T13.2.2.2.2.1.m1.1.1.4.cmml" xref="A1.T13.2.2.2.2.1.m1.1.1.4">
                <csymbol cd="ambiguous" id="A1.T13.2.2.2.2.1.m1.1.1.4.1.cmml" xref="A1.T13.2.2.2.2.1.m1.1.1.4">
                 subscript
                </csymbol>
                <ci id="A1.T13.2.2.2.2.1.m1.1.1.4.2.cmml" xref="A1.T13.2.2.2.2.1.m1.1.1.4.2">
                 𝑦
                </ci>
                <cn id="A1.T13.2.2.2.2.1.m1.1.1.4.3.cmml" type="integer" xref="A1.T13.2.2.2.2.1.m1.1.1.4.3">
                 2
                </cn>
               </apply>
              </apply>
             </annotation-xml>
             <annotation encoding="application/x-tex" id="A1.T13.2.2.2.2.1.m1.1c">
              key_{2}
             </annotation>
            </semantics>
           </math>
           ,…
          </span>
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T13.2.2.33.31">
         <td class="ltx_td ltx_align_left" id="A1.T13.2.2.33.31.1">
          The History Conversation:
          <span class="ltx_text" id="A1.T13.2.2.33.31.1.1" style="color:#BF0040;">
           Conversation
          </span>
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T13.2.2.34.32">
         <td class="ltx_td ltx_align_left" id="A1.T13.2.2.34.32.1">
          There are only one patient and one physician and just return the conversation. You conversation must
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T13.2.2.35.33">
         <td class="ltx_td ltx_align_left" id="A1.T13.2.2.35.33.1">
          include all the key words I gave you.
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T13.2.2.36.34">
         <td class="ltx_td ltx_align_left" id="A1.T13.2.2.36.34.1">
          Your conversation should also include all information.
          <span class="ltx_text" id="A1.T13.2.2.36.34.1.1" style="background-color:#E069FF;">
           if it’s difficult to include them all, you
          </span>
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T13.2.2.37.35">
         <td class="ltx_td ltx_align_left" id="A1.T13.2.2.37.35.1">
          <span class="ltx_text" id="A1.T13.2.2.37.35.1.1" style="background-color:#E069FF;">
           can use the original sentences in the notes.
          </span>
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T13.2.2.38.36">
         <td class="ltx_td ltx_align_left" id="A1.T13.2.2.38.36.1">
          <span class="ltx_text" id="A1.T13.2.2.38.36.1.1" style="background-color:#808080;">
           The common symptoms and common medical history should be told by the patient.
          </span>
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T13.2.2.39.37">
         <td class="ltx_td ltx_align_left" id="A1.T13.2.2.39.37.1">
          <span class="ltx_text" id="A1.T13.2.2.39.37.1.1" style="background-color:#FFBFBF;">
           Some specific symptoms and medical history should be added by the physician
          </span>
          <span class="ltx_text" id="A1.T13.2.2.39.37.1.2" style="background-color:#808080;">
           after the patient has
          </span>
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T13.2.2.40.38">
         <td class="ltx_td ltx_align_left" id="A1.T13.2.2.40.38.1">
          <span class="ltx_text" id="A1.T13.2.2.40.38.1.1" style="background-color:#808080;">
           finished describing his symptoms and medical history.
          </span>
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T13.2.2.41.39">
         <td class="ltx_td ltx_align_left" id="A1.T13.2.2.41.39.1">
          For example:
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T13.2.2.42.40">
         <td class="ltx_td ltx_align_left" id="A1.T13.2.2.42.40.1">
          physician: Can you give me your medical history record?
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T13.2.2.43.41">
         <td class="ltx_td ltx_align_left" id="A1.T13.2.2.43.41.1">
          Patient: Here you are.
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T13.2.2.44.42">
         <td class="ltx_td ltx_align_left" id="A1.T13.2.2.44.42.1">
          physician: Based on your medical history record…
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T13.2.2.45.43">
         <td class="ltx_td ltx_align_left" id="A1.T13.2.2.45.43.1">
          Because after the patient has finished describing common symptoms or medical history, he will give
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T13.2.2.46.44">
         <td class="ltx_td ltx_align_left" id="A1.T13.2.2.46.44.1">
          physician his medical history records.
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T13.2.2.47.45">
         <td class="ltx_td ltx_align_left" id="A1.T13.2.2.47.45.1">
          After patient gives the physician his medical history record, the physician could know medical
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T13.2.2.48.46">
         <td class="ltx_td ltx_align_left" id="A1.T13.2.2.48.46.1">
          history record. Otherwise he didn’t know any information of the medical history.
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T13.2.2.49.47">
         <td class="ltx_td ltx_align_left" id="A1.T13.2.2.49.47.1">
          Some results should not come from history clinical note they should come from the examination.
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T13.2.2.50.48">
         <td class="ltx_td ltx_align_left" id="A1.T13.2.2.50.48.1">
          All the examination results, history examination results, vital sigh and medical number must be told by physician.
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T13.2.2.51.49">
         <td class="ltx_td ltx_align_left" id="A1.T13.2.2.51.49.1">
          <span class="ltx_text" id="A1.T13.2.2.51.49.1.1" style="background-color:#FF7D00;">
           The revised conversation should be at least around 30 to 40 utterances
          </span>
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T13.2.2.52.50">
         <td class="ltx_td ltx_align_left" id="A1.T13.2.2.52.50.1">
          (the physician or patient should say too much information at once).
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T13.2.2.53.51">
         <td class="ltx_td ltx_align_left" id="A1.T13.2.2.53.51.1">
          <span class="ltx_text" id="A1.T13.2.2.53.51.1.1" style="background-color:#E069FF;">
           The conversation must include all the information on the clinical note.
          </span>
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T13.2.2.54.52">
         <td class="ltx_td ltx_align_left" id="A1.T13.2.2.54.52.1">
          <span class="ltx_text" id="A1.T13.2.2.54.52.1.1" style="background-color:#E069FF;">
           You must include all the key words I gave you. If it is difficult to include all the key words you
          </span>
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T13.2.2.55.53">
         <td class="ltx_td ltx_align_left" id="A1.T13.2.2.55.53.1">
          <span class="ltx_text" id="A1.T13.2.2.55.53.1.1" style="background-color:#E069FF;">
           could use original the sentences of clinical note.
          </span>
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T13.2.2.56.54">
         <td class="ltx_td ltx_align_left" id="A1.T13.2.2.56.54.1">
          <span class="ltx_text" id="A1.T13.2.2.56.54.1.1" style="background-color:#E069FF;">
           You cannot revise or eliminate any key words and you cannot use synonyms of the key words.
          </span>
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T13.2.2.57.55">
         <td class="ltx_td ltx_align_left" id="A1.T13.2.2.57.55.1">
          You shouldn’t use the abbreviation if you know the full name(you should use full name not
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T13.2.2.58.56">
         <td class="ltx_td ltx_align_left" id="A1.T13.2.2.58.56.1">
          abbreviation, such as D9 must be day 9, D7 must be day 7. If both the full name and the abbreviation
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T13.2.2.59.57">
         <td class="ltx_td ltx_align_left" id="A1.T13.2.2.59.57.1">
          appear, it’s better to use the full name rather than the abbreviation.
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T13.2.2.60.58">
         <td class="ltx_td ltx_align_left" id="A1.T13.2.2.60.58.1">
          <span class="ltx_text" id="A1.T13.2.2.60.58.1.1" style="background-color:#FFBFBF;">
           Patients must not say any highly specialized terms, medical terminology or medical dosage.
          </span>
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T13.2.2.61.59">
         <td class="ltx_td ltx_align_left" id="A1.T13.2.2.61.59.1">
          <span class="ltx_text" id="A1.T13.2.2.61.59.1.1" style="background-color:#808080;">
           They can only describe limited common symptoms.
          </span>
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T13.2.2.62.60">
         <td class="ltx_td ltx_align_left" id="A1.T13.2.2.62.60.1">
          The physician should supplement the remaining information based on test results.
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T13.2.2.63.61">
         <td class="ltx_td" id="A1.T13.2.2.63.61.1">
         </td>
         <td class="ltx_td ltx_align_left" id="A1.T13.2.2.63.61.2">
          <span class="ltx_text" id="A1.T13.2.2.63.61.2.1" style="background-color:#6E73FF;">
           Don’t repeat the same information in long paragraphs. The utterance of the dialogue needs to be
          </span>
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T13.2.2.64.62">
         <td class="ltx_td ltx_border_b" id="A1.T13.2.2.64.62.1">
         </td>
         <td class="ltx_td ltx_align_left ltx_border_b" id="A1.T13.2.2.64.62.2">
          <span class="ltx_text" id="A1.T13.2.2.64.62.2.1" style="background-color:#6E73FF;">
           expanded as much as possible.
          </span>
         </td>
        </tr>
       </tbody>
      </table>
     </span>
    </div>
    <figcaption class="ltx_caption">
     <span class="ltx_tag ltx_tag_table">
      Table 13:
     </span>
     Polish prompt.
    </figcaption>
   </figure>
   <figure class="ltx_table" id="A1.T14">
    <div class="ltx_inline-block ltx_transformed_outer" id="A1.T14.1" style="width:380.8pt;height:270.8pt;vertical-align:-0.8pt;">
     <span class="ltx_transformed_inner" style="transform:translate(-63.5pt,45.0pt) scale(0.75,0.75) ;">
      <table class="ltx_tabular ltx_align_middle" id="A1.T14.1.1">
       <tbody class="ltx_tbody">
        <tr class="ltx_tr" id="A1.T14.1.1.2.1">
         <td class="ltx_td ltx_align_left ltx_border_t" id="A1.T14.1.1.2.1.1" rowspan="19">
          <span class="ltx_text ltx_font_bold" id="A1.T14.1.1.2.1.1.1">
           Combine Prompt
          </span>
         </td>
         <td class="ltx_td ltx_align_left ltx_border_t" id="A1.T14.1.1.2.1.2">
          The above two paragraphs were extracted from a complete conversation.
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T14.1.1.3.2">
         <td class="ltx_td ltx_align_left" id="A1.T14.1.1.3.2.1">
          Please concatenate the two dialogues together. Add ’physician:’ before the physician’s words
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T14.1.1.4.3">
         <td class="ltx_td ltx_align_left" id="A1.T14.1.1.4.3.1">
          and ’Patient:’ before the patient’s words for easier differentiation.
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T14.1.1.5.4">
         <td class="ltx_td ltx_align_left" id="A1.T14.1.1.5.4.1">
          Please combine these two dialogues.
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T14.1.1.6.5">
         <td class="ltx_td ltx_align_left" id="A1.T14.1.1.6.5.1">
          It means that your generation should include all the information
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T14.1.1.7.6">
         <td class="ltx_td ltx_align_left" id="A1.T14.1.1.7.6.1">
          such as dosage of the medication which is mentioned in the clinical note
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T14.1.1.8.7">
         <td class="ltx_td ltx_align_left" id="A1.T14.1.1.8.7.1">
          if the dosage is not mentioned in the clinical not
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T14.1.1.9.8">
         <td class="ltx_td ltx_align_left" id="A1.T14.1.1.9.8.1">
          you should not mention it and the length should be longer than
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T14.1.1.10.9">
         <td class="ltx_td ltx_align_left" id="A1.T14.1.1.10.9.1">
          both of these two conversations even longer than the sum of them.
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T14.1.1.11.10">
         <td class="ltx_td ltx_align_left" id="A1.T14.1.1.11.10.1">
          You should try to ensure that the dialogue is smooth,
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T14.1.1.12.11">
         <td class="ltx_td ltx_align_left" id="A1.T14.1.1.12.11.1">
          and don’t use any greetings such as ’Hi there’, ’how are you feeling today?’,
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T14.1.1.13.12">
         <td class="ltx_td ltx_align_left" id="A1.T14.1.1.13.12.1">
          ’Hey’, ’Hello’ or any farewells in the dialogue.
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T14.1.1.14.13">
         <td class="ltx_td ltx_align_left" id="A1.T14.1.1.14.13.1">
          The entire conversation takes place at the same time and place,
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T14.1.1.15.14">
         <td class="ltx_td ltx_align_left" id="A1.T14.1.1.15.14.1">
          and revolves around the same patient and physician.
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T14.1.1.16.15">
         <td class="ltx_td ltx_align_left" id="A1.T14.1.1.16.15.1">
          Try to make the conversation smoother. Try to make these two dialogues into one dialogue
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T14.1.1.17.16">
         <td class="ltx_td ltx_align_left" id="A1.T14.1.1.17.16.1">
          that takes place at the same time and place. Modify this conversation
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T14.1.1.18.17">
         <td class="ltx_td ltx_align_left" id="A1.T14.1.1.18.17.1">
          by deleting all greeting sentences
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T14.1.1.19.18">
         <td class="ltx_td ltx_align_left" id="A1.T14.1.1.19.18.1">
          such as ’Hi’, ’Hey’, ’Hi there’, ’How are you feeling today’, and ’Good Morning’.
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T14.1.1.1">
         <td class="ltx_td ltx_align_left" id="A1.T14.1.1.1.1">
          The conversation must include these key words:
          <math alttext="key_{1},key_{2},..." class="ltx_Math" display="inline" id="A1.T14.1.1.1.1.m1.3">
           <semantics id="A1.T14.1.1.1.1.m1.3a">
            <mrow id="A1.T14.1.1.1.1.m1.3.3.2" xref="A1.T14.1.1.1.1.m1.3.3.3.cmml">
             <mrow id="A1.T14.1.1.1.1.m1.2.2.1.1" xref="A1.T14.1.1.1.1.m1.2.2.1.1.cmml">
              <mi id="A1.T14.1.1.1.1.m1.2.2.1.1.2" mathcolor="#FF0000" xref="A1.T14.1.1.1.1.m1.2.2.1.1.2.cmml">
               k
              </mi>
              <mo id="A1.T14.1.1.1.1.m1.2.2.1.1.1" lspace="0em" rspace="0em" xref="A1.T14.1.1.1.1.m1.2.2.1.1.1.cmml">
               ​
              </mo>
              <mi id="A1.T14.1.1.1.1.m1.2.2.1.1.3" mathcolor="#FF0000" xref="A1.T14.1.1.1.1.m1.2.2.1.1.3.cmml">
               e
              </mi>
              <mo id="A1.T14.1.1.1.1.m1.2.2.1.1.1a" lspace="0em" rspace="0em" xref="A1.T14.1.1.1.1.m1.2.2.1.1.1.cmml">
               ​
              </mo>
              <msub id="A1.T14.1.1.1.1.m1.2.2.1.1.4" xref="A1.T14.1.1.1.1.m1.2.2.1.1.4.cmml">
               <mi id="A1.T14.1.1.1.1.m1.2.2.1.1.4.2" mathcolor="#FF0000" xref="A1.T14.1.1.1.1.m1.2.2.1.1.4.2.cmml">
                y
               </mi>
               <mn id="A1.T14.1.1.1.1.m1.2.2.1.1.4.3" mathcolor="#FF0000" xref="A1.T14.1.1.1.1.m1.2.2.1.1.4.3.cmml">
                1
               </mn>
              </msub>
             </mrow>
             <mo id="A1.T14.1.1.1.1.m1.3.3.2.3" mathcolor="#FF0000" xref="A1.T14.1.1.1.1.m1.3.3.3.cmml">
              ,
             </mo>
             <mrow id="A1.T14.1.1.1.1.m1.3.3.2.2" xref="A1.T14.1.1.1.1.m1.3.3.2.2.cmml">
              <mi id="A1.T14.1.1.1.1.m1.3.3.2.2.2" mathcolor="#FF0000" xref="A1.T14.1.1.1.1.m1.3.3.2.2.2.cmml">
               k
              </mi>
              <mo id="A1.T14.1.1.1.1.m1.3.3.2.2.1" lspace="0em" rspace="0em" xref="A1.T14.1.1.1.1.m1.3.3.2.2.1.cmml">
               ​
              </mo>
              <mi id="A1.T14.1.1.1.1.m1.3.3.2.2.3" mathcolor="#FF0000" xref="A1.T14.1.1.1.1.m1.3.3.2.2.3.cmml">
               e
              </mi>
              <mo id="A1.T14.1.1.1.1.m1.3.3.2.2.1a" lspace="0em" rspace="0em" xref="A1.T14.1.1.1.1.m1.3.3.2.2.1.cmml">
               ​
              </mo>
              <msub id="A1.T14.1.1.1.1.m1.3.3.2.2.4" xref="A1.T14.1.1.1.1.m1.3.3.2.2.4.cmml">
               <mi id="A1.T14.1.1.1.1.m1.3.3.2.2.4.2" mathcolor="#FF0000" xref="A1.T14.1.1.1.1.m1.3.3.2.2.4.2.cmml">
                y
               </mi>
               <mn id="A1.T14.1.1.1.1.m1.3.3.2.2.4.3" mathcolor="#FF0000" xref="A1.T14.1.1.1.1.m1.3.3.2.2.4.3.cmml">
                2
               </mn>
              </msub>
             </mrow>
             <mo id="A1.T14.1.1.1.1.m1.3.3.2.4" mathcolor="#FF0000" xref="A1.T14.1.1.1.1.m1.3.3.3.cmml">
              ,
             </mo>
             <mi id="A1.T14.1.1.1.1.m1.1.1" mathcolor="#FF0000" mathvariant="normal" xref="A1.T14.1.1.1.1.m1.1.1.cmml">
              …
             </mi>
            </mrow>
            <annotation-xml encoding="MathML-Content" id="A1.T14.1.1.1.1.m1.3b">
             <list id="A1.T14.1.1.1.1.m1.3.3.3.cmml" xref="A1.T14.1.1.1.1.m1.3.3.2">
              <apply id="A1.T14.1.1.1.1.m1.2.2.1.1.cmml" xref="A1.T14.1.1.1.1.m1.2.2.1.1">
               <times id="A1.T14.1.1.1.1.m1.2.2.1.1.1.cmml" xref="A1.T14.1.1.1.1.m1.2.2.1.1.1">
               </times>
               <ci id="A1.T14.1.1.1.1.m1.2.2.1.1.2.cmml" xref="A1.T14.1.1.1.1.m1.2.2.1.1.2">
                𝑘
               </ci>
               <ci id="A1.T14.1.1.1.1.m1.2.2.1.1.3.cmml" xref="A1.T14.1.1.1.1.m1.2.2.1.1.3">
                𝑒
               </ci>
               <apply id="A1.T14.1.1.1.1.m1.2.2.1.1.4.cmml" xref="A1.T14.1.1.1.1.m1.2.2.1.1.4">
                <csymbol cd="ambiguous" id="A1.T14.1.1.1.1.m1.2.2.1.1.4.1.cmml" xref="A1.T14.1.1.1.1.m1.2.2.1.1.4">
                 subscript
                </csymbol>
                <ci id="A1.T14.1.1.1.1.m1.2.2.1.1.4.2.cmml" xref="A1.T14.1.1.1.1.m1.2.2.1.1.4.2">
                 𝑦
                </ci>
                <cn id="A1.T14.1.1.1.1.m1.2.2.1.1.4.3.cmml" type="integer" xref="A1.T14.1.1.1.1.m1.2.2.1.1.4.3">
                 1
                </cn>
               </apply>
              </apply>
              <apply id="A1.T14.1.1.1.1.m1.3.3.2.2.cmml" xref="A1.T14.1.1.1.1.m1.3.3.2.2">
               <times id="A1.T14.1.1.1.1.m1.3.3.2.2.1.cmml" xref="A1.T14.1.1.1.1.m1.3.3.2.2.1">
               </times>
               <ci id="A1.T14.1.1.1.1.m1.3.3.2.2.2.cmml" xref="A1.T14.1.1.1.1.m1.3.3.2.2.2">
                𝑘
               </ci>
               <ci id="A1.T14.1.1.1.1.m1.3.3.2.2.3.cmml" xref="A1.T14.1.1.1.1.m1.3.3.2.2.3">
                𝑒
               </ci>
               <apply id="A1.T14.1.1.1.1.m1.3.3.2.2.4.cmml" xref="A1.T14.1.1.1.1.m1.3.3.2.2.4">
                <csymbol cd="ambiguous" id="A1.T14.1.1.1.1.m1.3.3.2.2.4.1.cmml" xref="A1.T14.1.1.1.1.m1.3.3.2.2.4">
                 subscript
                </csymbol>
                <ci id="A1.T14.1.1.1.1.m1.3.3.2.2.4.2.cmml" xref="A1.T14.1.1.1.1.m1.3.3.2.2.4.2">
                 𝑦
                </ci>
                <cn id="A1.T14.1.1.1.1.m1.3.3.2.2.4.3.cmml" type="integer" xref="A1.T14.1.1.1.1.m1.3.3.2.2.4.3">
                 2
                </cn>
               </apply>
              </apply>
              <ci id="A1.T14.1.1.1.1.m1.1.1.cmml" xref="A1.T14.1.1.1.1.m1.1.1">
               …
              </ci>
             </list>
            </annotation-xml>
            <annotation encoding="application/x-tex" id="A1.T14.1.1.1.1.m1.3c">
             key_{1},key_{2},...
            </annotation>
           </semantics>
          </math>
         </td>
        </tr>
        <tr class="ltx_tr" id="A1.T14.1.1.20.19">
         <td class="ltx_td ltx_border_b" id="A1.T14.1.1.20.19.1">
         </td>
         <td class="ltx_td ltx_align_left ltx_border_b" id="A1.T14.1.1.20.19.2">
          and you should also eliminate the repeat parts.
         </td>
        </tr>
       </tbody>
      </table>
     </span>
    </div>
    <figcaption class="ltx_caption">
     <span class="ltx_tag ltx_tag_table">
      Table 14:
     </span>
     Combine prompt.
    </figcaption>
   </figure>
  </section>
 </section>
</article>
