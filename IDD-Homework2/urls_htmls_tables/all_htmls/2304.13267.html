<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2304.13267] Bayesian Federated Learning: A Survey</title><meta property="og:description" content="Federated learning (FL) demonstrates its advantages in integrating distributed infrastructure, communication, computing and learning in a privacy-preserving manner. However, the robustness and capabilities of existing â€¦">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Bayesian Federated Learning: A Survey">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Bayesian Federated Learning: A Survey">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2304.13267">

<!--Generated on Thu Feb 29 12:33:57 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Bayesian Federated Learning: A Survey</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Longbing Cao<sup id="id13.2.id1" class="ltx_sup"><span id="id13.2.id1.1" class="ltx_text ltx_font_italic">1,2</span></sup>
</span></span>
<span class="ltx_author_before">â€ƒâ€ƒ</span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Hui Chen<sup id="id14.2.id1" class="ltx_sup">1</sup>
</span></span>
<span class="ltx_author_before">â€ƒâ€ƒ</span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Xuhui Fan<sup id="id15.2.id1" class="ltx_sup"><span id="id15.2.id1.1" class="ltx_text ltx_font_italic">3</span></sup>
</span></span>
<span class="ltx_author_before">â€ƒâ€ƒ</span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Joao Gama<sup id="id16.2.id1" class="ltx_sup">4</sup>
</span></span>
<span class="ltx_author_before">â€ƒâ€ƒ</span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Yew-Soon Ong<sup id="id17.9.id1" class="ltx_sup">5</sup>&amp;Vipin Kumar<sup id="id18.10.id2" class="ltx_sup">6</sup>
<sup id="id19.11.id3" class="ltx_sup">1</sup>University of Technology Sydney, Australia
<br class="ltx_break"><sup id="id20.12.id4" class="ltx_sup">2</sup>Macquarie University, Australia
<br class="ltx_break"><sup id="id21.13.id5" class="ltx_sup">3</sup>University of New Castle, Australia
<br class="ltx_break"><sup id="id22.14.id6" class="ltx_sup">4</sup>University of Porto, Portugal
<br class="ltx_break"><sup id="id23.15.id7" class="ltx_sup">5</sup>Nanyang Technological University, Singapore
<br class="ltx_break"><sup id="id24.16.id8" class="ltx_sup">6</sup>University of Minnesota, USA
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id25.id1" class="ltx_p">Federated learning (FL) demonstrates its advantages in integrating distributed infrastructure, communication, computing and learning in a privacy-preserving manner. However, the robustness and capabilities of existing FL methods are challenged by limited and dynamic data and conditions, complexities including heterogeneities and uncertainties, and analytical explainability. <span id="id25.id1.1" class="ltx_text ltx_font_italic">Bayesian federated learning</span> (BFL) has emerged as a promising approach to address these issues. This survey presents a critical overview of BFL, including its basic concepts, its relations to Bayesian learning in the context of FL, and a taxonomy of BFL from both Bayesian and federated perspectives. We categorize and discuss client- and server-side and FL-based BFL methods and their pros and cons. The limitations of the existing BFL methods and the future directions of BFL research further address the intricate requirements of real-life FL applications.</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Decentralized AI (DeAI) and machine learning (DeML) address new demands for engaging decentralized edge devices, nodes and servers to undertake secure edge-level and distributed AI and learning tasks <cite class="ltx_cite ltx_citemacro_cite">Cao (<a href="#bib.bib14" title="" class="ltx_ref">2022c</a>); McMahan <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib44" title="" class="ltx_ref">2017</a>)</cite>. A critical DeAI and ML technique is federated learning (FL) <cite class="ltx_cite ltx_citemacro_cite">Kairouz <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib32" title="" class="ltx_ref">2021</a>); Yang (<a href="#bib.bib60" title="" class="ltx_ref">2021</a>)</cite>, which ensures decentralized learning on local data without sharing but with properties including privacy, security, heterogeneity, and personalization. FL has seen significant developments to leverage distributed and centralized ML techniques, catering to centralized, decentralized, heterogeneous, or personalized settings and requirements with privacy preservation. These include algorithms for preserving privacy <cite class="ltx_cite ltx_citemacro_cite">Liu <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib42" title="" class="ltx_ref">2022</a>); Elgabli <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib24" title="" class="ltx_ref">2022</a>)</cite>, reducing communication consumption <cite class="ltx_cite ltx_citemacro_cite">Zhang <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib64" title="" class="ltx_ref">2021</a>)</cite>, handling system heterogeneity <cite class="ltx_cite ltx_citemacro_cite">Zong <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib66" title="" class="ltx_ref">2021</a>)</cite>, and addressing personalized requirements <cite class="ltx_cite ltx_citemacro_cite">TÂ Dinh <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib53" title="" class="ltx_ref">2020</a>); Fallah <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib25" title="" class="ltx_ref">2020</a>)</cite>.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">However, FL faces various fundamental challenges in enabling DeAI and DeML for real-world applications. First, client data on edge nodes and devices may be very limited and it may be costly to obtain labelled samples. Second, client conditions and behaviors are often dynamic, presenting strong uncertainties. Last but not least, decentralized applications are non-IID, involving heterogeneities of devices, behaviors, goals, and data and their interactions <cite class="ltx_cite ltx_citemacro_cite">Cao (<a href="#bib.bib13" title="" class="ltx_ref">2022b</a>)</cite>. These are challenges facing existing FL algorithms and inspire a promising direction - Bayesian Federated Learning (BFL) <cite class="ltx_cite ltx_citemacro_cite">Zhang <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib65" title="" class="ltx_ref">2022</a>)</cite>, which integrates the advantages of Bayesian learning (BL) into FL.
In existing BFL methods, BL approaches incorporate prior knowledge about data to leverage a limited number of samples and learn distributions over FL parameters and statistical heterogeneity to quantify uncertainties and dynamics. Further, the strengths of FL in handling privacy, communication and heterogeneity are fused with BL. Consequently, BFL enables more robust, well-calibrated and dynamic predictions for safety- and privacy-critical applications. BFL has demonstrated various applications, such as for FinTech, driverless cars, Industry 4.0, medical diagnosis, and differential privacy <cite class="ltx_cite ltx_citemacro_cite">Achituve <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib2" title="" class="ltx_ref">2021</a>); Snell and Zemel (<a href="#bib.bib50" title="" class="ltx_ref">2021</a>); Kendall and
Gal (<a href="#bib.bib34" title="" class="ltx_ref">2017</a>); Blundell <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib6" title="" class="ltx_ref">2015</a>); Triastcyn and Faltings (<a href="#bib.bib56" title="" class="ltx_ref">2019</a>); Yang (<a href="#bib.bib60" title="" class="ltx_ref">2021</a>)</cite>.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">BFL shows a promising potential to substantially expand the existing FL and complex real-world requirements for DeAI, DeML and FL. Here, we systematically review the relevant work on BFL, conduct a critical analysis of their pros and cons, and present the challenges and opportunities for comprehensive BFL research. First, we briefly discuss the transfer from FL and BL to their integrative BFL. Then, a BFL taxonomy offers a structure of BFL in terms of both BL methods and FL research issues. We discuss and compare the advantages and disadvantages of different methods for client- and server-side BFL and various categories of BFL from the FL perspective. Lastly, we discuss the gaps and future directions of BFL in addressing broad-reaching, more realistic and actionable <cite class="ltx_cite ltx_citemacro_cite">Cao and Zhang (<a href="#bib.bib8" title="" class="ltx_ref">2006</a>); Cao (<a href="#bib.bib10" title="" class="ltx_ref">2013</a>)</cite> FL, BL, DeAI, and DeML settings and tasks and real-world FL scenarios and requirements.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>From Federated and Bayesian Learning to Bayesian Federated Learning</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">We summarize FL concepts, topics and challenges. Then, BL methods and advantages are discussed. BFL integrates BL into FL addressing FL challenges using BL advantages.</p>
</div>
<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Federated Learning and Challenges</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p"><span id="S2.SS1.p1.1.1" class="ltx_text ltx_font_bold">FL concepts</span>. Federated learning initially aims to address privacy leakage in distributed learning systems <cite class="ltx_cite ltx_citemacro_cite">Yang (<a href="#bib.bib60" title="" class="ltx_ref">2021</a>); Kairouz <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib32" title="" class="ltx_ref">2021</a>)</cite>. In general, an FL system has a server and multiple clients and utilizes an iterative learning process through server-client communications. In each communication round, the server trains a global model and sends its model parameters to participating clients. Each client trains its local model on local data. Clients share model parameters (rather than local data) with the server, which pools and aggregates these local updates to update its global model for the next communication round. This process iterates until convergence or it reaches some stopping conditions.</p>
</div>
<div id="S2.SS1.p2" class="ltx_para">
<p id="S2.SS1.p2.10" class="ltx_p">Typically, FL achieves an objective function as follows:</p>
<table id="S2.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E1.m1.5" class="ltx_Math" alttext="\min_{\boldsymbol{w}}F(\boldsymbol{w})=\sum_{m=1}^{M}\frac{\left|D_{m}\right|}{|D|}F_{m}(\boldsymbol{w})," display="block"><semantics id="S2.E1.m1.5a"><mrow id="S2.E1.m1.5.5.1" xref="S2.E1.m1.5.5.1.1.cmml"><mrow id="S2.E1.m1.5.5.1.1" xref="S2.E1.m1.5.5.1.1.cmml"><mrow id="S2.E1.m1.5.5.1.1.2" xref="S2.E1.m1.5.5.1.1.2.cmml"><mrow id="S2.E1.m1.5.5.1.1.2.2" xref="S2.E1.m1.5.5.1.1.2.2.cmml"><munder id="S2.E1.m1.5.5.1.1.2.2.1" xref="S2.E1.m1.5.5.1.1.2.2.1.cmml"><mi id="S2.E1.m1.5.5.1.1.2.2.1.2" xref="S2.E1.m1.5.5.1.1.2.2.1.2.cmml">min</mi><mi id="S2.E1.m1.5.5.1.1.2.2.1.3" xref="S2.E1.m1.5.5.1.1.2.2.1.3.cmml">ğ’˜</mi></munder><mo lspace="0.167em" id="S2.E1.m1.5.5.1.1.2.2a" xref="S2.E1.m1.5.5.1.1.2.2.cmml">â¡</mo><mi id="S2.E1.m1.5.5.1.1.2.2.2" xref="S2.E1.m1.5.5.1.1.2.2.2.cmml">F</mi></mrow><mo lspace="0em" rspace="0em" id="S2.E1.m1.5.5.1.1.2.1" xref="S2.E1.m1.5.5.1.1.2.1.cmml">â€‹</mo><mrow id="S2.E1.m1.5.5.1.1.2.3.2" xref="S2.E1.m1.5.5.1.1.2.cmml"><mo stretchy="false" id="S2.E1.m1.5.5.1.1.2.3.2.1" xref="S2.E1.m1.5.5.1.1.2.cmml">(</mo><mi id="S2.E1.m1.3.3" xref="S2.E1.m1.3.3.cmml">ğ’˜</mi><mo stretchy="false" id="S2.E1.m1.5.5.1.1.2.3.2.2" xref="S2.E1.m1.5.5.1.1.2.cmml">)</mo></mrow></mrow><mo rspace="0.111em" id="S2.E1.m1.5.5.1.1.1" xref="S2.E1.m1.5.5.1.1.1.cmml">=</mo><mrow id="S2.E1.m1.5.5.1.1.3" xref="S2.E1.m1.5.5.1.1.3.cmml"><munderover id="S2.E1.m1.5.5.1.1.3.1" xref="S2.E1.m1.5.5.1.1.3.1.cmml"><mo movablelimits="false" id="S2.E1.m1.5.5.1.1.3.1.2.2" xref="S2.E1.m1.5.5.1.1.3.1.2.2.cmml">âˆ‘</mo><mrow id="S2.E1.m1.5.5.1.1.3.1.2.3" xref="S2.E1.m1.5.5.1.1.3.1.2.3.cmml"><mi id="S2.E1.m1.5.5.1.1.3.1.2.3.2" xref="S2.E1.m1.5.5.1.1.3.1.2.3.2.cmml">m</mi><mo id="S2.E1.m1.5.5.1.1.3.1.2.3.1" xref="S2.E1.m1.5.5.1.1.3.1.2.3.1.cmml">=</mo><mn id="S2.E1.m1.5.5.1.1.3.1.2.3.3" xref="S2.E1.m1.5.5.1.1.3.1.2.3.3.cmml">1</mn></mrow><mi id="S2.E1.m1.5.5.1.1.3.1.3" xref="S2.E1.m1.5.5.1.1.3.1.3.cmml">M</mi></munderover><mrow id="S2.E1.m1.5.5.1.1.3.2" xref="S2.E1.m1.5.5.1.1.3.2.cmml"><mfrac id="S2.E1.m1.2.2" xref="S2.E1.m1.2.2.cmml"><mrow id="S2.E1.m1.1.1.1.1" xref="S2.E1.m1.1.1.1.2.cmml"><mo id="S2.E1.m1.1.1.1.1.2" xref="S2.E1.m1.1.1.1.2.1.cmml">|</mo><msub id="S2.E1.m1.1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.1.cmml"><mi id="S2.E1.m1.1.1.1.1.1.2" xref="S2.E1.m1.1.1.1.1.1.2.cmml">D</mi><mi id="S2.E1.m1.1.1.1.1.1.3" xref="S2.E1.m1.1.1.1.1.1.3.cmml">m</mi></msub><mo id="S2.E1.m1.1.1.1.1.3" xref="S2.E1.m1.1.1.1.2.1.cmml">|</mo></mrow><mrow id="S2.E1.m1.2.2.2.3" xref="S2.E1.m1.2.2.2.2.cmml"><mo stretchy="false" id="S2.E1.m1.2.2.2.3.1" xref="S2.E1.m1.2.2.2.2.1.cmml">|</mo><mi id="S2.E1.m1.2.2.2.1" xref="S2.E1.m1.2.2.2.1.cmml">D</mi><mo stretchy="false" id="S2.E1.m1.2.2.2.3.2" xref="S2.E1.m1.2.2.2.2.1.cmml">|</mo></mrow></mfrac><mo lspace="0em" rspace="0em" id="S2.E1.m1.5.5.1.1.3.2.1" xref="S2.E1.m1.5.5.1.1.3.2.1.cmml">â€‹</mo><msub id="S2.E1.m1.5.5.1.1.3.2.2" xref="S2.E1.m1.5.5.1.1.3.2.2.cmml"><mi id="S2.E1.m1.5.5.1.1.3.2.2.2" xref="S2.E1.m1.5.5.1.1.3.2.2.2.cmml">F</mi><mi id="S2.E1.m1.5.5.1.1.3.2.2.3" xref="S2.E1.m1.5.5.1.1.3.2.2.3.cmml">m</mi></msub><mo lspace="0em" rspace="0em" id="S2.E1.m1.5.5.1.1.3.2.1a" xref="S2.E1.m1.5.5.1.1.3.2.1.cmml">â€‹</mo><mrow id="S2.E1.m1.5.5.1.1.3.2.3.2" xref="S2.E1.m1.5.5.1.1.3.2.cmml"><mo stretchy="false" id="S2.E1.m1.5.5.1.1.3.2.3.2.1" xref="S2.E1.m1.5.5.1.1.3.2.cmml">(</mo><mi id="S2.E1.m1.4.4" xref="S2.E1.m1.4.4.cmml">ğ’˜</mi><mo stretchy="false" id="S2.E1.m1.5.5.1.1.3.2.3.2.2" xref="S2.E1.m1.5.5.1.1.3.2.cmml">)</mo></mrow></mrow></mrow></mrow><mo id="S2.E1.m1.5.5.1.2" xref="S2.E1.m1.5.5.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.E1.m1.5b"><apply id="S2.E1.m1.5.5.1.1.cmml" xref="S2.E1.m1.5.5.1"><eq id="S2.E1.m1.5.5.1.1.1.cmml" xref="S2.E1.m1.5.5.1.1.1"></eq><apply id="S2.E1.m1.5.5.1.1.2.cmml" xref="S2.E1.m1.5.5.1.1.2"><times id="S2.E1.m1.5.5.1.1.2.1.cmml" xref="S2.E1.m1.5.5.1.1.2.1"></times><apply id="S2.E1.m1.5.5.1.1.2.2.cmml" xref="S2.E1.m1.5.5.1.1.2.2"><apply id="S2.E1.m1.5.5.1.1.2.2.1.cmml" xref="S2.E1.m1.5.5.1.1.2.2.1"><csymbol cd="ambiguous" id="S2.E1.m1.5.5.1.1.2.2.1.1.cmml" xref="S2.E1.m1.5.5.1.1.2.2.1">subscript</csymbol><min id="S2.E1.m1.5.5.1.1.2.2.1.2.cmml" xref="S2.E1.m1.5.5.1.1.2.2.1.2"></min><ci id="S2.E1.m1.5.5.1.1.2.2.1.3.cmml" xref="S2.E1.m1.5.5.1.1.2.2.1.3">ğ’˜</ci></apply><ci id="S2.E1.m1.5.5.1.1.2.2.2.cmml" xref="S2.E1.m1.5.5.1.1.2.2.2">ğ¹</ci></apply><ci id="S2.E1.m1.3.3.cmml" xref="S2.E1.m1.3.3">ğ’˜</ci></apply><apply id="S2.E1.m1.5.5.1.1.3.cmml" xref="S2.E1.m1.5.5.1.1.3"><apply id="S2.E1.m1.5.5.1.1.3.1.cmml" xref="S2.E1.m1.5.5.1.1.3.1"><csymbol cd="ambiguous" id="S2.E1.m1.5.5.1.1.3.1.1.cmml" xref="S2.E1.m1.5.5.1.1.3.1">superscript</csymbol><apply id="S2.E1.m1.5.5.1.1.3.1.2.cmml" xref="S2.E1.m1.5.5.1.1.3.1"><csymbol cd="ambiguous" id="S2.E1.m1.5.5.1.1.3.1.2.1.cmml" xref="S2.E1.m1.5.5.1.1.3.1">subscript</csymbol><sum id="S2.E1.m1.5.5.1.1.3.1.2.2.cmml" xref="S2.E1.m1.5.5.1.1.3.1.2.2"></sum><apply id="S2.E1.m1.5.5.1.1.3.1.2.3.cmml" xref="S2.E1.m1.5.5.1.1.3.1.2.3"><eq id="S2.E1.m1.5.5.1.1.3.1.2.3.1.cmml" xref="S2.E1.m1.5.5.1.1.3.1.2.3.1"></eq><ci id="S2.E1.m1.5.5.1.1.3.1.2.3.2.cmml" xref="S2.E1.m1.5.5.1.1.3.1.2.3.2">ğ‘š</ci><cn type="integer" id="S2.E1.m1.5.5.1.1.3.1.2.3.3.cmml" xref="S2.E1.m1.5.5.1.1.3.1.2.3.3">1</cn></apply></apply><ci id="S2.E1.m1.5.5.1.1.3.1.3.cmml" xref="S2.E1.m1.5.5.1.1.3.1.3">ğ‘€</ci></apply><apply id="S2.E1.m1.5.5.1.1.3.2.cmml" xref="S2.E1.m1.5.5.1.1.3.2"><times id="S2.E1.m1.5.5.1.1.3.2.1.cmml" xref="S2.E1.m1.5.5.1.1.3.2.1"></times><apply id="S2.E1.m1.2.2.cmml" xref="S2.E1.m1.2.2"><divide id="S2.E1.m1.2.2.3.cmml" xref="S2.E1.m1.2.2"></divide><apply id="S2.E1.m1.1.1.1.2.cmml" xref="S2.E1.m1.1.1.1.1"><abs id="S2.E1.m1.1.1.1.2.1.cmml" xref="S2.E1.m1.1.1.1.1.2"></abs><apply id="S2.E1.m1.1.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1.1">subscript</csymbol><ci id="S2.E1.m1.1.1.1.1.1.2.cmml" xref="S2.E1.m1.1.1.1.1.1.2">ğ·</ci><ci id="S2.E1.m1.1.1.1.1.1.3.cmml" xref="S2.E1.m1.1.1.1.1.1.3">ğ‘š</ci></apply></apply><apply id="S2.E1.m1.2.2.2.2.cmml" xref="S2.E1.m1.2.2.2.3"><abs id="S2.E1.m1.2.2.2.2.1.cmml" xref="S2.E1.m1.2.2.2.3.1"></abs><ci id="S2.E1.m1.2.2.2.1.cmml" xref="S2.E1.m1.2.2.2.1">ğ·</ci></apply></apply><apply id="S2.E1.m1.5.5.1.1.3.2.2.cmml" xref="S2.E1.m1.5.5.1.1.3.2.2"><csymbol cd="ambiguous" id="S2.E1.m1.5.5.1.1.3.2.2.1.cmml" xref="S2.E1.m1.5.5.1.1.3.2.2">subscript</csymbol><ci id="S2.E1.m1.5.5.1.1.3.2.2.2.cmml" xref="S2.E1.m1.5.5.1.1.3.2.2.2">ğ¹</ci><ci id="S2.E1.m1.5.5.1.1.3.2.2.3.cmml" xref="S2.E1.m1.5.5.1.1.3.2.2.3">ğ‘š</ci></apply><ci id="S2.E1.m1.4.4.cmml" xref="S2.E1.m1.4.4">ğ’˜</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E1.m1.5c">\min_{\boldsymbol{w}}F(\boldsymbol{w})=\sum_{m=1}^{M}\frac{\left|D_{m}\right|}{|D|}F_{m}(\boldsymbol{w}),</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<table id="S2.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E2.m1.5" class="ltx_Math" alttext="\quad\text{ where }\quad F_{m}(\boldsymbol{w})=\frac{1}{\left|D_{m}\right|}\sum_{i}l\left(\boldsymbol{x}_{i},y_{i};\boldsymbol{w}\right)." display="block"><semantics id="S2.E2.m1.5a"><mrow id="S2.E2.m1.5.5.1" xref="S2.E2.m1.5.5.1.1.cmml"><mrow id="S2.E2.m1.5.5.1.1" xref="S2.E2.m1.5.5.1.1.cmml"><mrow id="S2.E2.m1.5.5.1.1.1.1" xref="S2.E2.m1.5.5.1.1.1.2.cmml"><mtext id="S2.E2.m1.4.4" xref="S2.E2.m1.4.4a.cmml">Â whereÂ </mtext><mspace width="1em" id="S2.E2.m1.5.5.1.1.1.1.2" xref="S2.E2.m1.5.5.1.1.1.2.cmml"></mspace><mrow id="S2.E2.m1.5.5.1.1.1.1.1" xref="S2.E2.m1.5.5.1.1.1.1.1.cmml"><msub id="S2.E2.m1.5.5.1.1.1.1.1.2" xref="S2.E2.m1.5.5.1.1.1.1.1.2.cmml"><mi id="S2.E2.m1.5.5.1.1.1.1.1.2.2" xref="S2.E2.m1.5.5.1.1.1.1.1.2.2.cmml">F</mi><mi id="S2.E2.m1.5.5.1.1.1.1.1.2.3" xref="S2.E2.m1.5.5.1.1.1.1.1.2.3.cmml">m</mi></msub><mo lspace="0em" rspace="0em" id="S2.E2.m1.5.5.1.1.1.1.1.1" xref="S2.E2.m1.5.5.1.1.1.1.1.1.cmml">â€‹</mo><mrow id="S2.E2.m1.5.5.1.1.1.1.1.3.2" xref="S2.E2.m1.5.5.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.E2.m1.5.5.1.1.1.1.1.3.2.1" xref="S2.E2.m1.5.5.1.1.1.1.1.cmml">(</mo><mi id="S2.E2.m1.2.2" xref="S2.E2.m1.2.2.cmml">ğ’˜</mi><mo stretchy="false" id="S2.E2.m1.5.5.1.1.1.1.1.3.2.2" xref="S2.E2.m1.5.5.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo id="S2.E2.m1.5.5.1.1.4" xref="S2.E2.m1.5.5.1.1.4.cmml">=</mo><mrow id="S2.E2.m1.5.5.1.1.3" xref="S2.E2.m1.5.5.1.1.3.cmml"><mfrac id="S2.E2.m1.1.1" xref="S2.E2.m1.1.1.cmml"><mn id="S2.E2.m1.1.1.3" xref="S2.E2.m1.1.1.3.cmml">1</mn><mrow id="S2.E2.m1.1.1.1.1" xref="S2.E2.m1.1.1.1.2.cmml"><mo id="S2.E2.m1.1.1.1.1.2" xref="S2.E2.m1.1.1.1.2.1.cmml">|</mo><msub id="S2.E2.m1.1.1.1.1.1" xref="S2.E2.m1.1.1.1.1.1.cmml"><mi id="S2.E2.m1.1.1.1.1.1.2" xref="S2.E2.m1.1.1.1.1.1.2.cmml">D</mi><mi id="S2.E2.m1.1.1.1.1.1.3" xref="S2.E2.m1.1.1.1.1.1.3.cmml">m</mi></msub><mo id="S2.E2.m1.1.1.1.1.3" xref="S2.E2.m1.1.1.1.2.1.cmml">|</mo></mrow></mfrac><mo lspace="0em" rspace="0em" id="S2.E2.m1.5.5.1.1.3.3" xref="S2.E2.m1.5.5.1.1.3.3.cmml">â€‹</mo><mrow id="S2.E2.m1.5.5.1.1.3.2" xref="S2.E2.m1.5.5.1.1.3.2.cmml"><munder id="S2.E2.m1.5.5.1.1.3.2.3" xref="S2.E2.m1.5.5.1.1.3.2.3.cmml"><mo movablelimits="false" id="S2.E2.m1.5.5.1.1.3.2.3.2" xref="S2.E2.m1.5.5.1.1.3.2.3.2.cmml">âˆ‘</mo><mi id="S2.E2.m1.5.5.1.1.3.2.3.3" xref="S2.E2.m1.5.5.1.1.3.2.3.3.cmml">i</mi></munder><mrow id="S2.E2.m1.5.5.1.1.3.2.2" xref="S2.E2.m1.5.5.1.1.3.2.2.cmml"><mi id="S2.E2.m1.5.5.1.1.3.2.2.4" xref="S2.E2.m1.5.5.1.1.3.2.2.4.cmml">l</mi><mo lspace="0em" rspace="0em" id="S2.E2.m1.5.5.1.1.3.2.2.3" xref="S2.E2.m1.5.5.1.1.3.2.2.3.cmml">â€‹</mo><mrow id="S2.E2.m1.5.5.1.1.3.2.2.2.2" xref="S2.E2.m1.5.5.1.1.3.2.2.2.3.cmml"><mo id="S2.E2.m1.5.5.1.1.3.2.2.2.2.3" xref="S2.E2.m1.5.5.1.1.3.2.2.2.3.cmml">(</mo><msub id="S2.E2.m1.5.5.1.1.2.1.1.1.1.1" xref="S2.E2.m1.5.5.1.1.2.1.1.1.1.1.cmml"><mi id="S2.E2.m1.5.5.1.1.2.1.1.1.1.1.2" xref="S2.E2.m1.5.5.1.1.2.1.1.1.1.1.2.cmml">ğ’™</mi><mi id="S2.E2.m1.5.5.1.1.2.1.1.1.1.1.3" xref="S2.E2.m1.5.5.1.1.2.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S2.E2.m1.5.5.1.1.3.2.2.2.2.4" xref="S2.E2.m1.5.5.1.1.3.2.2.2.3.cmml">,</mo><msub id="S2.E2.m1.5.5.1.1.3.2.2.2.2.2" xref="S2.E2.m1.5.5.1.1.3.2.2.2.2.2.cmml"><mi id="S2.E2.m1.5.5.1.1.3.2.2.2.2.2.2" xref="S2.E2.m1.5.5.1.1.3.2.2.2.2.2.2.cmml">y</mi><mi id="S2.E2.m1.5.5.1.1.3.2.2.2.2.2.3" xref="S2.E2.m1.5.5.1.1.3.2.2.2.2.2.3.cmml">i</mi></msub><mo id="S2.E2.m1.5.5.1.1.3.2.2.2.2.5" xref="S2.E2.m1.5.5.1.1.3.2.2.2.3.cmml">;</mo><mi id="S2.E2.m1.3.3" xref="S2.E2.m1.3.3.cmml">ğ’˜</mi><mo id="S2.E2.m1.5.5.1.1.3.2.2.2.2.6" xref="S2.E2.m1.5.5.1.1.3.2.2.2.3.cmml">)</mo></mrow></mrow></mrow></mrow></mrow><mo lspace="0em" id="S2.E2.m1.5.5.1.2" xref="S2.E2.m1.5.5.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.E2.m1.5b"><apply id="S2.E2.m1.5.5.1.1.cmml" xref="S2.E2.m1.5.5.1"><eq id="S2.E2.m1.5.5.1.1.4.cmml" xref="S2.E2.m1.5.5.1.1.4"></eq><list id="S2.E2.m1.5.5.1.1.1.2.cmml" xref="S2.E2.m1.5.5.1.1.1.1"><ci id="S2.E2.m1.4.4a.cmml" xref="S2.E2.m1.4.4"><mtext id="S2.E2.m1.4.4.cmml" xref="S2.E2.m1.4.4">Â whereÂ </mtext></ci><apply id="S2.E2.m1.5.5.1.1.1.1.1.cmml" xref="S2.E2.m1.5.5.1.1.1.1.1"><times id="S2.E2.m1.5.5.1.1.1.1.1.1.cmml" xref="S2.E2.m1.5.5.1.1.1.1.1.1"></times><apply id="S2.E2.m1.5.5.1.1.1.1.1.2.cmml" xref="S2.E2.m1.5.5.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.E2.m1.5.5.1.1.1.1.1.2.1.cmml" xref="S2.E2.m1.5.5.1.1.1.1.1.2">subscript</csymbol><ci id="S2.E2.m1.5.5.1.1.1.1.1.2.2.cmml" xref="S2.E2.m1.5.5.1.1.1.1.1.2.2">ğ¹</ci><ci id="S2.E2.m1.5.5.1.1.1.1.1.2.3.cmml" xref="S2.E2.m1.5.5.1.1.1.1.1.2.3">ğ‘š</ci></apply><ci id="S2.E2.m1.2.2.cmml" xref="S2.E2.m1.2.2">ğ’˜</ci></apply></list><apply id="S2.E2.m1.5.5.1.1.3.cmml" xref="S2.E2.m1.5.5.1.1.3"><times id="S2.E2.m1.5.5.1.1.3.3.cmml" xref="S2.E2.m1.5.5.1.1.3.3"></times><apply id="S2.E2.m1.1.1.cmml" xref="S2.E2.m1.1.1"><divide id="S2.E2.m1.1.1.2.cmml" xref="S2.E2.m1.1.1"></divide><cn type="integer" id="S2.E2.m1.1.1.3.cmml" xref="S2.E2.m1.1.1.3">1</cn><apply id="S2.E2.m1.1.1.1.2.cmml" xref="S2.E2.m1.1.1.1.1"><abs id="S2.E2.m1.1.1.1.2.1.cmml" xref="S2.E2.m1.1.1.1.1.2"></abs><apply id="S2.E2.m1.1.1.1.1.1.cmml" xref="S2.E2.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E2.m1.1.1.1.1.1.1.cmml" xref="S2.E2.m1.1.1.1.1.1">subscript</csymbol><ci id="S2.E2.m1.1.1.1.1.1.2.cmml" xref="S2.E2.m1.1.1.1.1.1.2">ğ·</ci><ci id="S2.E2.m1.1.1.1.1.1.3.cmml" xref="S2.E2.m1.1.1.1.1.1.3">ğ‘š</ci></apply></apply></apply><apply id="S2.E2.m1.5.5.1.1.3.2.cmml" xref="S2.E2.m1.5.5.1.1.3.2"><apply id="S2.E2.m1.5.5.1.1.3.2.3.cmml" xref="S2.E2.m1.5.5.1.1.3.2.3"><csymbol cd="ambiguous" id="S2.E2.m1.5.5.1.1.3.2.3.1.cmml" xref="S2.E2.m1.5.5.1.1.3.2.3">subscript</csymbol><sum id="S2.E2.m1.5.5.1.1.3.2.3.2.cmml" xref="S2.E2.m1.5.5.1.1.3.2.3.2"></sum><ci id="S2.E2.m1.5.5.1.1.3.2.3.3.cmml" xref="S2.E2.m1.5.5.1.1.3.2.3.3">ğ‘–</ci></apply><apply id="S2.E2.m1.5.5.1.1.3.2.2.cmml" xref="S2.E2.m1.5.5.1.1.3.2.2"><times id="S2.E2.m1.5.5.1.1.3.2.2.3.cmml" xref="S2.E2.m1.5.5.1.1.3.2.2.3"></times><ci id="S2.E2.m1.5.5.1.1.3.2.2.4.cmml" xref="S2.E2.m1.5.5.1.1.3.2.2.4">ğ‘™</ci><vector id="S2.E2.m1.5.5.1.1.3.2.2.2.3.cmml" xref="S2.E2.m1.5.5.1.1.3.2.2.2.2"><apply id="S2.E2.m1.5.5.1.1.2.1.1.1.1.1.cmml" xref="S2.E2.m1.5.5.1.1.2.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E2.m1.5.5.1.1.2.1.1.1.1.1.1.cmml" xref="S2.E2.m1.5.5.1.1.2.1.1.1.1.1">subscript</csymbol><ci id="S2.E2.m1.5.5.1.1.2.1.1.1.1.1.2.cmml" xref="S2.E2.m1.5.5.1.1.2.1.1.1.1.1.2">ğ’™</ci><ci id="S2.E2.m1.5.5.1.1.2.1.1.1.1.1.3.cmml" xref="S2.E2.m1.5.5.1.1.2.1.1.1.1.1.3">ğ‘–</ci></apply><apply id="S2.E2.m1.5.5.1.1.3.2.2.2.2.2.cmml" xref="S2.E2.m1.5.5.1.1.3.2.2.2.2.2"><csymbol cd="ambiguous" id="S2.E2.m1.5.5.1.1.3.2.2.2.2.2.1.cmml" xref="S2.E2.m1.5.5.1.1.3.2.2.2.2.2">subscript</csymbol><ci id="S2.E2.m1.5.5.1.1.3.2.2.2.2.2.2.cmml" xref="S2.E2.m1.5.5.1.1.3.2.2.2.2.2.2">ğ‘¦</ci><ci id="S2.E2.m1.5.5.1.1.3.2.2.2.2.2.3.cmml" xref="S2.E2.m1.5.5.1.1.3.2.2.2.2.2.3">ğ‘–</ci></apply><ci id="S2.E2.m1.3.3.cmml" xref="S2.E2.m1.3.3">ğ’˜</ci></vector></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E2.m1.5c">\quad\text{ where }\quad F_{m}(\boldsymbol{w})=\frac{1}{\left|D_{m}\right|}\sum_{i}l\left(\boldsymbol{x}_{i},y_{i};\boldsymbol{w}\right).</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p id="S2.SS1.p2.9" class="ltx_p">Here, <math id="S2.SS1.p2.1.m1.1" class="ltx_Math" alttext="M" display="inline"><semantics id="S2.SS1.p2.1.m1.1a"><mi id="S2.SS1.p2.1.m1.1.1" xref="S2.SS1.p2.1.m1.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.1.m1.1b"><ci id="S2.SS1.p2.1.m1.1.1.cmml" xref="S2.SS1.p2.1.m1.1.1">ğ‘€</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.1.m1.1c">M</annotation></semantics></math> denotes the number of activated clients, <math id="S2.SS1.p2.2.m2.1" class="ltx_Math" alttext="D" display="inline"><semantics id="S2.SS1.p2.2.m2.1a"><mi id="S2.SS1.p2.2.m2.1.1" xref="S2.SS1.p2.2.m2.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.2.m2.1b"><ci id="S2.SS1.p2.2.m2.1.1.cmml" xref="S2.SS1.p2.2.m2.1.1">ğ·</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.2.m2.1c">D</annotation></semantics></math> and <math id="S2.SS1.p2.3.m3.1" class="ltx_Math" alttext="D_{m}" display="inline"><semantics id="S2.SS1.p2.3.m3.1a"><msub id="S2.SS1.p2.3.m3.1.1" xref="S2.SS1.p2.3.m3.1.1.cmml"><mi id="S2.SS1.p2.3.m3.1.1.2" xref="S2.SS1.p2.3.m3.1.1.2.cmml">D</mi><mi id="S2.SS1.p2.3.m3.1.1.3" xref="S2.SS1.p2.3.m3.1.1.3.cmml">m</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.3.m3.1b"><apply id="S2.SS1.p2.3.m3.1.1.cmml" xref="S2.SS1.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S2.SS1.p2.3.m3.1.1.1.cmml" xref="S2.SS1.p2.3.m3.1.1">subscript</csymbol><ci id="S2.SS1.p2.3.m3.1.1.2.cmml" xref="S2.SS1.p2.3.m3.1.1.2">ğ·</ci><ci id="S2.SS1.p2.3.m3.1.1.3.cmml" xref="S2.SS1.p2.3.m3.1.1.3">ğ‘š</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.3.m3.1c">D_{m}</annotation></semantics></math> denote the aggregated dataset from all participating clients and the dataset of the <math id="S2.SS1.p2.4.m4.1" class="ltx_Math" alttext="m" display="inline"><semantics id="S2.SS1.p2.4.m4.1a"><mi id="S2.SS1.p2.4.m4.1.1" xref="S2.SS1.p2.4.m4.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.4.m4.1b"><ci id="S2.SS1.p2.4.m4.1.1.cmml" xref="S2.SS1.p2.4.m4.1.1">ğ‘š</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.4.m4.1c">m</annotation></semantics></math>-th client, respectively, <math id="S2.SS1.p2.5.m5.1" class="ltx_Math" alttext="\boldsymbol{w}" display="inline"><semantics id="S2.SS1.p2.5.m5.1a"><mi id="S2.SS1.p2.5.m5.1.1" xref="S2.SS1.p2.5.m5.1.1.cmml">ğ’˜</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.5.m5.1b"><ci id="S2.SS1.p2.5.m5.1.1.cmml" xref="S2.SS1.p2.5.m5.1.1">ğ’˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.5.m5.1c">\boldsymbol{w}</annotation></semantics></math> denotes the model parameters of Bayesian neural networks and <math id="S2.SS1.p2.6.m6.1" class="ltx_Math" alttext="F_{m}(\boldsymbol{w})" display="inline"><semantics id="S2.SS1.p2.6.m6.1a"><mrow id="S2.SS1.p2.6.m6.1.2" xref="S2.SS1.p2.6.m6.1.2.cmml"><msub id="S2.SS1.p2.6.m6.1.2.2" xref="S2.SS1.p2.6.m6.1.2.2.cmml"><mi id="S2.SS1.p2.6.m6.1.2.2.2" xref="S2.SS1.p2.6.m6.1.2.2.2.cmml">F</mi><mi id="S2.SS1.p2.6.m6.1.2.2.3" xref="S2.SS1.p2.6.m6.1.2.2.3.cmml">m</mi></msub><mo lspace="0em" rspace="0em" id="S2.SS1.p2.6.m6.1.2.1" xref="S2.SS1.p2.6.m6.1.2.1.cmml">â€‹</mo><mrow id="S2.SS1.p2.6.m6.1.2.3.2" xref="S2.SS1.p2.6.m6.1.2.cmml"><mo stretchy="false" id="S2.SS1.p2.6.m6.1.2.3.2.1" xref="S2.SS1.p2.6.m6.1.2.cmml">(</mo><mi id="S2.SS1.p2.6.m6.1.1" xref="S2.SS1.p2.6.m6.1.1.cmml">ğ’˜</mi><mo stretchy="false" id="S2.SS1.p2.6.m6.1.2.3.2.2" xref="S2.SS1.p2.6.m6.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.6.m6.1b"><apply id="S2.SS1.p2.6.m6.1.2.cmml" xref="S2.SS1.p2.6.m6.1.2"><times id="S2.SS1.p2.6.m6.1.2.1.cmml" xref="S2.SS1.p2.6.m6.1.2.1"></times><apply id="S2.SS1.p2.6.m6.1.2.2.cmml" xref="S2.SS1.p2.6.m6.1.2.2"><csymbol cd="ambiguous" id="S2.SS1.p2.6.m6.1.2.2.1.cmml" xref="S2.SS1.p2.6.m6.1.2.2">subscript</csymbol><ci id="S2.SS1.p2.6.m6.1.2.2.2.cmml" xref="S2.SS1.p2.6.m6.1.2.2.2">ğ¹</ci><ci id="S2.SS1.p2.6.m6.1.2.2.3.cmml" xref="S2.SS1.p2.6.m6.1.2.2.3">ğ‘š</ci></apply><ci id="S2.SS1.p2.6.m6.1.1.cmml" xref="S2.SS1.p2.6.m6.1.1">ğ’˜</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.6.m6.1c">F_{m}(\boldsymbol{w})</annotation></semantics></math> denotes the empirical risk of the <math id="S2.SS1.p2.7.m7.1" class="ltx_Math" alttext="m" display="inline"><semantics id="S2.SS1.p2.7.m7.1a"><mi id="S2.SS1.p2.7.m7.1.1" xref="S2.SS1.p2.7.m7.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.7.m7.1b"><ci id="S2.SS1.p2.7.m7.1.1.cmml" xref="S2.SS1.p2.7.m7.1.1">ğ‘š</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.7.m7.1c">m</annotation></semantics></math>-th client with the loss function <math id="S2.SS1.p2.8.m8.1" class="ltx_Math" alttext="l" display="inline"><semantics id="S2.SS1.p2.8.m8.1a"><mi id="S2.SS1.p2.8.m8.1.1" xref="S2.SS1.p2.8.m8.1.1.cmml">l</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.8.m8.1b"><ci id="S2.SS1.p2.8.m8.1.1.cmml" xref="S2.SS1.p2.8.m8.1.1">ğ‘™</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.8.m8.1c">l</annotation></semantics></math> over each instance <math id="S2.SS1.p2.9.m9.2" class="ltx_Math" alttext="(\boldsymbol{x}_{i},y_{i})" display="inline"><semantics id="S2.SS1.p2.9.m9.2a"><mrow id="S2.SS1.p2.9.m9.2.2.2" xref="S2.SS1.p2.9.m9.2.2.3.cmml"><mo stretchy="false" id="S2.SS1.p2.9.m9.2.2.2.3" xref="S2.SS1.p2.9.m9.2.2.3.cmml">(</mo><msub id="S2.SS1.p2.9.m9.1.1.1.1" xref="S2.SS1.p2.9.m9.1.1.1.1.cmml"><mi id="S2.SS1.p2.9.m9.1.1.1.1.2" xref="S2.SS1.p2.9.m9.1.1.1.1.2.cmml">ğ’™</mi><mi id="S2.SS1.p2.9.m9.1.1.1.1.3" xref="S2.SS1.p2.9.m9.1.1.1.1.3.cmml">i</mi></msub><mo id="S2.SS1.p2.9.m9.2.2.2.4" xref="S2.SS1.p2.9.m9.2.2.3.cmml">,</mo><msub id="S2.SS1.p2.9.m9.2.2.2.2" xref="S2.SS1.p2.9.m9.2.2.2.2.cmml"><mi id="S2.SS1.p2.9.m9.2.2.2.2.2" xref="S2.SS1.p2.9.m9.2.2.2.2.2.cmml">y</mi><mi id="S2.SS1.p2.9.m9.2.2.2.2.3" xref="S2.SS1.p2.9.m9.2.2.2.2.3.cmml">i</mi></msub><mo stretchy="false" id="S2.SS1.p2.9.m9.2.2.2.5" xref="S2.SS1.p2.9.m9.2.2.3.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.9.m9.2b"><interval closure="open" id="S2.SS1.p2.9.m9.2.2.3.cmml" xref="S2.SS1.p2.9.m9.2.2.2"><apply id="S2.SS1.p2.9.m9.1.1.1.1.cmml" xref="S2.SS1.p2.9.m9.1.1.1.1"><csymbol cd="ambiguous" id="S2.SS1.p2.9.m9.1.1.1.1.1.cmml" xref="S2.SS1.p2.9.m9.1.1.1.1">subscript</csymbol><ci id="S2.SS1.p2.9.m9.1.1.1.1.2.cmml" xref="S2.SS1.p2.9.m9.1.1.1.1.2">ğ’™</ci><ci id="S2.SS1.p2.9.m9.1.1.1.1.3.cmml" xref="S2.SS1.p2.9.m9.1.1.1.1.3">ğ‘–</ci></apply><apply id="S2.SS1.p2.9.m9.2.2.2.2.cmml" xref="S2.SS1.p2.9.m9.2.2.2.2"><csymbol cd="ambiguous" id="S2.SS1.p2.9.m9.2.2.2.2.1.cmml" xref="S2.SS1.p2.9.m9.2.2.2.2">subscript</csymbol><ci id="S2.SS1.p2.9.m9.2.2.2.2.2.cmml" xref="S2.SS1.p2.9.m9.2.2.2.2.2">ğ‘¦</ci><ci id="S2.SS1.p2.9.m9.2.2.2.2.3.cmml" xref="S2.SS1.p2.9.m9.2.2.2.2.3">ğ‘–</ci></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.9.m9.2c">(\boldsymbol{x}_{i},y_{i})</annotation></semantics></math> <cite class="ltx_cite ltx_citemacro_cite">Chen and Chao (<a href="#bib.bib17" title="" class="ltx_ref">2022</a>)</cite>.</p>
</div>
<div id="S2.SS1.p3" class="ltx_para">
<p id="S2.SS1.p3.1" class="ltx_p"><span id="S2.SS1.p3.1.1" class="ltx_text ltx_font_bold">FL research topics</span>. FL has seen diversified rapid developments, which include the following categories. (1) Privacy-preserving FL <cite class="ltx_cite ltx_citemacro_cite">Liu <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib42" title="" class="ltx_ref">2022</a>); Elgabli <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib24" title="" class="ltx_ref">2022</a>)</cite> for differential privacy; (2) Communication-efficient FL <cite class="ltx_cite ltx_citemacro_cite">Lin <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib39" title="" class="ltx_ref">2022</a>); Li <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib38" title="" class="ltx_ref">2022</a>)</cite> addressing communication bottlenecks, <cite class="ltx_cite ltx_citemacro_cite">Dinh <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib22" title="" class="ltx_ref">2020</a>)</cite> on resource allocation, <cite class="ltx_cite ltx_citemacro_cite">Zang <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib63" title="" class="ltx_ref">2022</a>)</cite> on sparsified and compressed communication, and <cite class="ltx_cite ltx_citemacro_cite">Liu <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib40" title="" class="ltx_ref">2020</a>)</cite> for propagating channels; (3) Heterogeneous and personalized FL <cite class="ltx_cite ltx_citemacro_cite">Ghari and Shen (<a href="#bib.bib27" title="" class="ltx_ref">2022</a>); TÂ Dinh <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib53" title="" class="ltx_ref">2020</a>)</cite> to address heterogeneities of local clients; and (4) FL optimization with different settings <cite class="ltx_cite ltx_citemacro_cite">Liu <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib41" title="" class="ltx_ref">2021</a>); Malinovskiy <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib43" title="" class="ltx_ref">2020</a>)</cite> for federated SGD, <cite class="ltx_cite ltx_citemacro_cite">McMahan <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib44" title="" class="ltx_ref">2017</a>)</cite> for federated averaging, <cite class="ltx_cite ltx_citemacro_cite">Chen <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib18" title="" class="ltx_ref">2021</a>)</cite> for dynamic aggregation, and <cite class="ltx_cite ltx_citemacro_cite">Durmus <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib23" title="" class="ltx_ref">2021</a>)</cite> for dynamic regularization. In addition, there are many other (1) FL tasks, such as hierarchical FL, non-IID FL, unsupervised to semi-supervised FL, multitask FL, robust FL, fair and unbiased FL; and (2) FL application settings, such as blockchained FL, multimodal FL, secure FL, energy-aware and green FL.</p>
</div>
<div id="S2.SS1.p4" class="ltx_para">
<p id="S2.SS1.p4.1" class="ltx_p"><span id="S2.SS1.p4.1.1" class="ltx_text ltx_font_bold">FL challenges</span>. However, these previous work on FL still faces various challenges as mentioned in the introduction. In particular, FL suffers from uncertain, dynamic, limited, and unsupervised problems and also data. These techniques also cannot provide robust and analytically explainable results.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Bayesian Learning and Advantages</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.5" class="ltx_p"><span id="S2.SS2.p1.5.1" class="ltx_text ltx_font_bold">BL concepts</span>. Bayesian learning (BL) builds on Bayesâ€™ theorem <cite class="ltx_cite ltx_citemacro_cite">Benavoli and de Campos (<a href="#bib.bib4" title="" class="ltx_ref">2021</a>); Sun <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib52" title="" class="ltx_ref">2020</a>)</cite>.
It aims at learning the posterior distribution <math id="S2.SS2.p1.1.m1.1" class="ltx_Math" alttext="p(\boldsymbol{w}\mid D)" display="inline"><semantics id="S2.SS2.p1.1.m1.1a"><mrow id="S2.SS2.p1.1.m1.1.1" xref="S2.SS2.p1.1.m1.1.1.cmml"><mi id="S2.SS2.p1.1.m1.1.1.3" xref="S2.SS2.p1.1.m1.1.1.3.cmml">p</mi><mo lspace="0em" rspace="0em" id="S2.SS2.p1.1.m1.1.1.2" xref="S2.SS2.p1.1.m1.1.1.2.cmml">â€‹</mo><mrow id="S2.SS2.p1.1.m1.1.1.1.1" xref="S2.SS2.p1.1.m1.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.SS2.p1.1.m1.1.1.1.1.2" xref="S2.SS2.p1.1.m1.1.1.1.1.1.cmml">(</mo><mrow id="S2.SS2.p1.1.m1.1.1.1.1.1" xref="S2.SS2.p1.1.m1.1.1.1.1.1.cmml"><mi id="S2.SS2.p1.1.m1.1.1.1.1.1.2" xref="S2.SS2.p1.1.m1.1.1.1.1.1.2.cmml">ğ’˜</mi><mo id="S2.SS2.p1.1.m1.1.1.1.1.1.1" xref="S2.SS2.p1.1.m1.1.1.1.1.1.1.cmml">âˆ£</mo><mi id="S2.SS2.p1.1.m1.1.1.1.1.1.3" xref="S2.SS2.p1.1.m1.1.1.1.1.1.3.cmml">D</mi></mrow><mo stretchy="false" id="S2.SS2.p1.1.m1.1.1.1.1.3" xref="S2.SS2.p1.1.m1.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.1.m1.1b"><apply id="S2.SS2.p1.1.m1.1.1.cmml" xref="S2.SS2.p1.1.m1.1.1"><times id="S2.SS2.p1.1.m1.1.1.2.cmml" xref="S2.SS2.p1.1.m1.1.1.2"></times><ci id="S2.SS2.p1.1.m1.1.1.3.cmml" xref="S2.SS2.p1.1.m1.1.1.3">ğ‘</ci><apply id="S2.SS2.p1.1.m1.1.1.1.1.1.cmml" xref="S2.SS2.p1.1.m1.1.1.1.1"><csymbol cd="latexml" id="S2.SS2.p1.1.m1.1.1.1.1.1.1.cmml" xref="S2.SS2.p1.1.m1.1.1.1.1.1.1">conditional</csymbol><ci id="S2.SS2.p1.1.m1.1.1.1.1.1.2.cmml" xref="S2.SS2.p1.1.m1.1.1.1.1.1.2">ğ’˜</ci><ci id="S2.SS2.p1.1.m1.1.1.1.1.1.3.cmml" xref="S2.SS2.p1.1.m1.1.1.1.1.1.3">ğ·</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.1.m1.1c">p(\boldsymbol{w}\mid D)</annotation></semantics></math> for parameter <math id="S2.SS2.p1.2.m2.1" class="ltx_Math" alttext="\boldsymbol{w}" display="inline"><semantics id="S2.SS2.p1.2.m2.1a"><mi id="S2.SS2.p1.2.m2.1.1" xref="S2.SS2.p1.2.m2.1.1.cmml">ğ’˜</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.2.m2.1b"><ci id="S2.SS2.p1.2.m2.1.1.cmml" xref="S2.SS2.p1.2.m2.1.1">ğ’˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.2.m2.1c">\boldsymbol{w}</annotation></semantics></math> based on its prior distribution <math id="S2.SS2.p1.3.m3.1" class="ltx_Math" alttext="p(\boldsymbol{w})" display="inline"><semantics id="S2.SS2.p1.3.m3.1a"><mrow id="S2.SS2.p1.3.m3.1.2" xref="S2.SS2.p1.3.m3.1.2.cmml"><mi id="S2.SS2.p1.3.m3.1.2.2" xref="S2.SS2.p1.3.m3.1.2.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S2.SS2.p1.3.m3.1.2.1" xref="S2.SS2.p1.3.m3.1.2.1.cmml">â€‹</mo><mrow id="S2.SS2.p1.3.m3.1.2.3.2" xref="S2.SS2.p1.3.m3.1.2.cmml"><mo stretchy="false" id="S2.SS2.p1.3.m3.1.2.3.2.1" xref="S2.SS2.p1.3.m3.1.2.cmml">(</mo><mi id="S2.SS2.p1.3.m3.1.1" xref="S2.SS2.p1.3.m3.1.1.cmml">ğ’˜</mi><mo stretchy="false" id="S2.SS2.p1.3.m3.1.2.3.2.2" xref="S2.SS2.p1.3.m3.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.3.m3.1b"><apply id="S2.SS2.p1.3.m3.1.2.cmml" xref="S2.SS2.p1.3.m3.1.2"><times id="S2.SS2.p1.3.m3.1.2.1.cmml" xref="S2.SS2.p1.3.m3.1.2.1"></times><ci id="S2.SS2.p1.3.m3.1.2.2.cmml" xref="S2.SS2.p1.3.m3.1.2.2">ğ‘</ci><ci id="S2.SS2.p1.3.m3.1.1.cmml" xref="S2.SS2.p1.3.m3.1.1">ğ’˜</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.3.m3.1c">p(\boldsymbol{w})</annotation></semantics></math> and the corresponding likelihood <math id="S2.SS2.p1.4.m4.1" class="ltx_Math" alttext="p(D\mid\boldsymbol{w})" display="inline"><semantics id="S2.SS2.p1.4.m4.1a"><mrow id="S2.SS2.p1.4.m4.1.1" xref="S2.SS2.p1.4.m4.1.1.cmml"><mi id="S2.SS2.p1.4.m4.1.1.3" xref="S2.SS2.p1.4.m4.1.1.3.cmml">p</mi><mo lspace="0em" rspace="0em" id="S2.SS2.p1.4.m4.1.1.2" xref="S2.SS2.p1.4.m4.1.1.2.cmml">â€‹</mo><mrow id="S2.SS2.p1.4.m4.1.1.1.1" xref="S2.SS2.p1.4.m4.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.SS2.p1.4.m4.1.1.1.1.2" xref="S2.SS2.p1.4.m4.1.1.1.1.1.cmml">(</mo><mrow id="S2.SS2.p1.4.m4.1.1.1.1.1" xref="S2.SS2.p1.4.m4.1.1.1.1.1.cmml"><mi id="S2.SS2.p1.4.m4.1.1.1.1.1.2" xref="S2.SS2.p1.4.m4.1.1.1.1.1.2.cmml">D</mi><mo id="S2.SS2.p1.4.m4.1.1.1.1.1.1" xref="S2.SS2.p1.4.m4.1.1.1.1.1.1.cmml">âˆ£</mo><mi id="S2.SS2.p1.4.m4.1.1.1.1.1.3" xref="S2.SS2.p1.4.m4.1.1.1.1.1.3.cmml">ğ’˜</mi></mrow><mo stretchy="false" id="S2.SS2.p1.4.m4.1.1.1.1.3" xref="S2.SS2.p1.4.m4.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.4.m4.1b"><apply id="S2.SS2.p1.4.m4.1.1.cmml" xref="S2.SS2.p1.4.m4.1.1"><times id="S2.SS2.p1.4.m4.1.1.2.cmml" xref="S2.SS2.p1.4.m4.1.1.2"></times><ci id="S2.SS2.p1.4.m4.1.1.3.cmml" xref="S2.SS2.p1.4.m4.1.1.3">ğ‘</ci><apply id="S2.SS2.p1.4.m4.1.1.1.1.1.cmml" xref="S2.SS2.p1.4.m4.1.1.1.1"><csymbol cd="latexml" id="S2.SS2.p1.4.m4.1.1.1.1.1.1.cmml" xref="S2.SS2.p1.4.m4.1.1.1.1.1.1">conditional</csymbol><ci id="S2.SS2.p1.4.m4.1.1.1.1.1.2.cmml" xref="S2.SS2.p1.4.m4.1.1.1.1.1.2">ğ·</ci><ci id="S2.SS2.p1.4.m4.1.1.1.1.1.3.cmml" xref="S2.SS2.p1.4.m4.1.1.1.1.1.3">ğ’˜</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.4.m4.1c">p(D\mid\boldsymbol{w})</annotation></semantics></math> on observed evidence <math id="S2.SS2.p1.5.m5.1" class="ltx_Math" alttext="D" display="inline"><semantics id="S2.SS2.p1.5.m5.1a"><mi id="S2.SS2.p1.5.m5.1.1" xref="S2.SS2.p1.5.m5.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.5.m5.1b"><ci id="S2.SS2.p1.5.m5.1.1.cmml" xref="S2.SS2.p1.5.m5.1.1">ğ·</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.5.m5.1c">D</annotation></semantics></math>.
BL then learns the posterior as follows:</p>
<table id="S2.E3" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E3.m1.4" class="ltx_Math" alttext="p(\boldsymbol{w}\mid D)=\frac{p(D\mid\boldsymbol{w})p(\boldsymbol{w})}{p(D)}," display="block"><semantics id="S2.E3.m1.4a"><mrow id="S2.E3.m1.4.4.1" xref="S2.E3.m1.4.4.1.1.cmml"><mrow id="S2.E3.m1.4.4.1.1" xref="S2.E3.m1.4.4.1.1.cmml"><mrow id="S2.E3.m1.4.4.1.1.1" xref="S2.E3.m1.4.4.1.1.1.cmml"><mi id="S2.E3.m1.4.4.1.1.1.3" xref="S2.E3.m1.4.4.1.1.1.3.cmml">p</mi><mo lspace="0em" rspace="0em" id="S2.E3.m1.4.4.1.1.1.2" xref="S2.E3.m1.4.4.1.1.1.2.cmml">â€‹</mo><mrow id="S2.E3.m1.4.4.1.1.1.1.1" xref="S2.E3.m1.4.4.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.E3.m1.4.4.1.1.1.1.1.2" xref="S2.E3.m1.4.4.1.1.1.1.1.1.cmml">(</mo><mrow id="S2.E3.m1.4.4.1.1.1.1.1.1" xref="S2.E3.m1.4.4.1.1.1.1.1.1.cmml"><mi id="S2.E3.m1.4.4.1.1.1.1.1.1.2" xref="S2.E3.m1.4.4.1.1.1.1.1.1.2.cmml">ğ’˜</mi><mo id="S2.E3.m1.4.4.1.1.1.1.1.1.1" xref="S2.E3.m1.4.4.1.1.1.1.1.1.1.cmml">âˆ£</mo><mi id="S2.E3.m1.4.4.1.1.1.1.1.1.3" xref="S2.E3.m1.4.4.1.1.1.1.1.1.3.cmml">D</mi></mrow><mo stretchy="false" id="S2.E3.m1.4.4.1.1.1.1.1.3" xref="S2.E3.m1.4.4.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S2.E3.m1.4.4.1.1.2" xref="S2.E3.m1.4.4.1.1.2.cmml">=</mo><mfrac id="S2.E3.m1.3.3" xref="S2.E3.m1.3.3.cmml"><mrow id="S2.E3.m1.2.2.2" xref="S2.E3.m1.2.2.2.cmml"><mi id="S2.E3.m1.2.2.2.4" xref="S2.E3.m1.2.2.2.4.cmml">p</mi><mo lspace="0em" rspace="0em" id="S2.E3.m1.2.2.2.3" xref="S2.E3.m1.2.2.2.3.cmml">â€‹</mo><mrow id="S2.E3.m1.2.2.2.2.1" xref="S2.E3.m1.2.2.2.2.1.1.cmml"><mo stretchy="false" id="S2.E3.m1.2.2.2.2.1.2" xref="S2.E3.m1.2.2.2.2.1.1.cmml">(</mo><mrow id="S2.E3.m1.2.2.2.2.1.1" xref="S2.E3.m1.2.2.2.2.1.1.cmml"><mi id="S2.E3.m1.2.2.2.2.1.1.2" xref="S2.E3.m1.2.2.2.2.1.1.2.cmml">D</mi><mo id="S2.E3.m1.2.2.2.2.1.1.1" xref="S2.E3.m1.2.2.2.2.1.1.1.cmml">âˆ£</mo><mi id="S2.E3.m1.2.2.2.2.1.1.3" xref="S2.E3.m1.2.2.2.2.1.1.3.cmml">ğ’˜</mi></mrow><mo stretchy="false" id="S2.E3.m1.2.2.2.2.1.3" xref="S2.E3.m1.2.2.2.2.1.1.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S2.E3.m1.2.2.2.3a" xref="S2.E3.m1.2.2.2.3.cmml">â€‹</mo><mi id="S2.E3.m1.2.2.2.5" xref="S2.E3.m1.2.2.2.5.cmml">p</mi><mo lspace="0em" rspace="0em" id="S2.E3.m1.2.2.2.3b" xref="S2.E3.m1.2.2.2.3.cmml">â€‹</mo><mrow id="S2.E3.m1.2.2.2.6.2" xref="S2.E3.m1.2.2.2.cmml"><mo stretchy="false" id="S2.E3.m1.2.2.2.6.2.1" xref="S2.E3.m1.2.2.2.cmml">(</mo><mi id="S2.E3.m1.1.1.1.1" xref="S2.E3.m1.1.1.1.1.cmml">ğ’˜</mi><mo stretchy="false" id="S2.E3.m1.2.2.2.6.2.2" xref="S2.E3.m1.2.2.2.cmml">)</mo></mrow></mrow><mrow id="S2.E3.m1.3.3.3" xref="S2.E3.m1.3.3.3.cmml"><mi id="S2.E3.m1.3.3.3.3" xref="S2.E3.m1.3.3.3.3.cmml">p</mi><mo lspace="0em" rspace="0em" id="S2.E3.m1.3.3.3.2" xref="S2.E3.m1.3.3.3.2.cmml">â€‹</mo><mrow id="S2.E3.m1.3.3.3.4.2" xref="S2.E3.m1.3.3.3.cmml"><mo stretchy="false" id="S2.E3.m1.3.3.3.4.2.1" xref="S2.E3.m1.3.3.3.cmml">(</mo><mi id="S2.E3.m1.3.3.3.1" xref="S2.E3.m1.3.3.3.1.cmml">D</mi><mo stretchy="false" id="S2.E3.m1.3.3.3.4.2.2" xref="S2.E3.m1.3.3.3.cmml">)</mo></mrow></mrow></mfrac></mrow><mo id="S2.E3.m1.4.4.1.2" xref="S2.E3.m1.4.4.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.E3.m1.4b"><apply id="S2.E3.m1.4.4.1.1.cmml" xref="S2.E3.m1.4.4.1"><eq id="S2.E3.m1.4.4.1.1.2.cmml" xref="S2.E3.m1.4.4.1.1.2"></eq><apply id="S2.E3.m1.4.4.1.1.1.cmml" xref="S2.E3.m1.4.4.1.1.1"><times id="S2.E3.m1.4.4.1.1.1.2.cmml" xref="S2.E3.m1.4.4.1.1.1.2"></times><ci id="S2.E3.m1.4.4.1.1.1.3.cmml" xref="S2.E3.m1.4.4.1.1.1.3">ğ‘</ci><apply id="S2.E3.m1.4.4.1.1.1.1.1.1.cmml" xref="S2.E3.m1.4.4.1.1.1.1.1"><csymbol cd="latexml" id="S2.E3.m1.4.4.1.1.1.1.1.1.1.cmml" xref="S2.E3.m1.4.4.1.1.1.1.1.1.1">conditional</csymbol><ci id="S2.E3.m1.4.4.1.1.1.1.1.1.2.cmml" xref="S2.E3.m1.4.4.1.1.1.1.1.1.2">ğ’˜</ci><ci id="S2.E3.m1.4.4.1.1.1.1.1.1.3.cmml" xref="S2.E3.m1.4.4.1.1.1.1.1.1.3">ğ·</ci></apply></apply><apply id="S2.E3.m1.3.3.cmml" xref="S2.E3.m1.3.3"><divide id="S2.E3.m1.3.3.4.cmml" xref="S2.E3.m1.3.3"></divide><apply id="S2.E3.m1.2.2.2.cmml" xref="S2.E3.m1.2.2.2"><times id="S2.E3.m1.2.2.2.3.cmml" xref="S2.E3.m1.2.2.2.3"></times><ci id="S2.E3.m1.2.2.2.4.cmml" xref="S2.E3.m1.2.2.2.4">ğ‘</ci><apply id="S2.E3.m1.2.2.2.2.1.1.cmml" xref="S2.E3.m1.2.2.2.2.1"><csymbol cd="latexml" id="S2.E3.m1.2.2.2.2.1.1.1.cmml" xref="S2.E3.m1.2.2.2.2.1.1.1">conditional</csymbol><ci id="S2.E3.m1.2.2.2.2.1.1.2.cmml" xref="S2.E3.m1.2.2.2.2.1.1.2">ğ·</ci><ci id="S2.E3.m1.2.2.2.2.1.1.3.cmml" xref="S2.E3.m1.2.2.2.2.1.1.3">ğ’˜</ci></apply><ci id="S2.E3.m1.2.2.2.5.cmml" xref="S2.E3.m1.2.2.2.5">ğ‘</ci><ci id="S2.E3.m1.1.1.1.1.cmml" xref="S2.E3.m1.1.1.1.1">ğ’˜</ci></apply><apply id="S2.E3.m1.3.3.3.cmml" xref="S2.E3.m1.3.3.3"><times id="S2.E3.m1.3.3.3.2.cmml" xref="S2.E3.m1.3.3.3.2"></times><ci id="S2.E3.m1.3.3.3.3.cmml" xref="S2.E3.m1.3.3.3.3">ğ‘</ci><ci id="S2.E3.m1.3.3.3.1.cmml" xref="S2.E3.m1.3.3.3.1">ğ·</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E3.m1.4c">p(\boldsymbol{w}\mid D)=\frac{p(D\mid\boldsymbol{w})p(\boldsymbol{w})}{p(D)},</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<p id="S2.SS2.p1.10" class="ltx_p">It thus converts a prior probability <math id="S2.SS2.p1.6.m1.1" class="ltx_Math" alttext="p(\boldsymbol{w})" display="inline"><semantics id="S2.SS2.p1.6.m1.1a"><mrow id="S2.SS2.p1.6.m1.1.2" xref="S2.SS2.p1.6.m1.1.2.cmml"><mi id="S2.SS2.p1.6.m1.1.2.2" xref="S2.SS2.p1.6.m1.1.2.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S2.SS2.p1.6.m1.1.2.1" xref="S2.SS2.p1.6.m1.1.2.1.cmml">â€‹</mo><mrow id="S2.SS2.p1.6.m1.1.2.3.2" xref="S2.SS2.p1.6.m1.1.2.cmml"><mo stretchy="false" id="S2.SS2.p1.6.m1.1.2.3.2.1" xref="S2.SS2.p1.6.m1.1.2.cmml">(</mo><mi id="S2.SS2.p1.6.m1.1.1" xref="S2.SS2.p1.6.m1.1.1.cmml">ğ’˜</mi><mo stretchy="false" id="S2.SS2.p1.6.m1.1.2.3.2.2" xref="S2.SS2.p1.6.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.6.m1.1b"><apply id="S2.SS2.p1.6.m1.1.2.cmml" xref="S2.SS2.p1.6.m1.1.2"><times id="S2.SS2.p1.6.m1.1.2.1.cmml" xref="S2.SS2.p1.6.m1.1.2.1"></times><ci id="S2.SS2.p1.6.m1.1.2.2.cmml" xref="S2.SS2.p1.6.m1.1.2.2">ğ‘</ci><ci id="S2.SS2.p1.6.m1.1.1.cmml" xref="S2.SS2.p1.6.m1.1.1">ğ’˜</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.6.m1.1c">p(\boldsymbol{w})</annotation></semantics></math> into a posterior probability <math id="S2.SS2.p1.7.m2.1" class="ltx_Math" alttext="p(\boldsymbol{w}\mid D)" display="inline"><semantics id="S2.SS2.p1.7.m2.1a"><mrow id="S2.SS2.p1.7.m2.1.1" xref="S2.SS2.p1.7.m2.1.1.cmml"><mi id="S2.SS2.p1.7.m2.1.1.3" xref="S2.SS2.p1.7.m2.1.1.3.cmml">p</mi><mo lspace="0em" rspace="0em" id="S2.SS2.p1.7.m2.1.1.2" xref="S2.SS2.p1.7.m2.1.1.2.cmml">â€‹</mo><mrow id="S2.SS2.p1.7.m2.1.1.1.1" xref="S2.SS2.p1.7.m2.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.SS2.p1.7.m2.1.1.1.1.2" xref="S2.SS2.p1.7.m2.1.1.1.1.1.cmml">(</mo><mrow id="S2.SS2.p1.7.m2.1.1.1.1.1" xref="S2.SS2.p1.7.m2.1.1.1.1.1.cmml"><mi id="S2.SS2.p1.7.m2.1.1.1.1.1.2" xref="S2.SS2.p1.7.m2.1.1.1.1.1.2.cmml">ğ’˜</mi><mo id="S2.SS2.p1.7.m2.1.1.1.1.1.1" xref="S2.SS2.p1.7.m2.1.1.1.1.1.1.cmml">âˆ£</mo><mi id="S2.SS2.p1.7.m2.1.1.1.1.1.3" xref="S2.SS2.p1.7.m2.1.1.1.1.1.3.cmml">D</mi></mrow><mo stretchy="false" id="S2.SS2.p1.7.m2.1.1.1.1.3" xref="S2.SS2.p1.7.m2.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.7.m2.1b"><apply id="S2.SS2.p1.7.m2.1.1.cmml" xref="S2.SS2.p1.7.m2.1.1"><times id="S2.SS2.p1.7.m2.1.1.2.cmml" xref="S2.SS2.p1.7.m2.1.1.2"></times><ci id="S2.SS2.p1.7.m2.1.1.3.cmml" xref="S2.SS2.p1.7.m2.1.1.3">ğ‘</ci><apply id="S2.SS2.p1.7.m2.1.1.1.1.1.cmml" xref="S2.SS2.p1.7.m2.1.1.1.1"><csymbol cd="latexml" id="S2.SS2.p1.7.m2.1.1.1.1.1.1.cmml" xref="S2.SS2.p1.7.m2.1.1.1.1.1.1">conditional</csymbol><ci id="S2.SS2.p1.7.m2.1.1.1.1.1.2.cmml" xref="S2.SS2.p1.7.m2.1.1.1.1.1.2">ğ’˜</ci><ci id="S2.SS2.p1.7.m2.1.1.1.1.1.3.cmml" xref="S2.SS2.p1.7.m2.1.1.1.1.1.3">ğ·</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.7.m2.1c">p(\boldsymbol{w}\mid D)</annotation></semantics></math> with the likelihood <math id="S2.SS2.p1.8.m3.1" class="ltx_Math" alttext="p(D\mid\boldsymbol{w})" display="inline"><semantics id="S2.SS2.p1.8.m3.1a"><mrow id="S2.SS2.p1.8.m3.1.1" xref="S2.SS2.p1.8.m3.1.1.cmml"><mi id="S2.SS2.p1.8.m3.1.1.3" xref="S2.SS2.p1.8.m3.1.1.3.cmml">p</mi><mo lspace="0em" rspace="0em" id="S2.SS2.p1.8.m3.1.1.2" xref="S2.SS2.p1.8.m3.1.1.2.cmml">â€‹</mo><mrow id="S2.SS2.p1.8.m3.1.1.1.1" xref="S2.SS2.p1.8.m3.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.SS2.p1.8.m3.1.1.1.1.2" xref="S2.SS2.p1.8.m3.1.1.1.1.1.cmml">(</mo><mrow id="S2.SS2.p1.8.m3.1.1.1.1.1" xref="S2.SS2.p1.8.m3.1.1.1.1.1.cmml"><mi id="S2.SS2.p1.8.m3.1.1.1.1.1.2" xref="S2.SS2.p1.8.m3.1.1.1.1.1.2.cmml">D</mi><mo id="S2.SS2.p1.8.m3.1.1.1.1.1.1" xref="S2.SS2.p1.8.m3.1.1.1.1.1.1.cmml">âˆ£</mo><mi id="S2.SS2.p1.8.m3.1.1.1.1.1.3" xref="S2.SS2.p1.8.m3.1.1.1.1.1.3.cmml">ğ’˜</mi></mrow><mo stretchy="false" id="S2.SS2.p1.8.m3.1.1.1.1.3" xref="S2.SS2.p1.8.m3.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.8.m3.1b"><apply id="S2.SS2.p1.8.m3.1.1.cmml" xref="S2.SS2.p1.8.m3.1.1"><times id="S2.SS2.p1.8.m3.1.1.2.cmml" xref="S2.SS2.p1.8.m3.1.1.2"></times><ci id="S2.SS2.p1.8.m3.1.1.3.cmml" xref="S2.SS2.p1.8.m3.1.1.3">ğ‘</ci><apply id="S2.SS2.p1.8.m3.1.1.1.1.1.cmml" xref="S2.SS2.p1.8.m3.1.1.1.1"><csymbol cd="latexml" id="S2.SS2.p1.8.m3.1.1.1.1.1.1.cmml" xref="S2.SS2.p1.8.m3.1.1.1.1.1.1">conditional</csymbol><ci id="S2.SS2.p1.8.m3.1.1.1.1.1.2.cmml" xref="S2.SS2.p1.8.m3.1.1.1.1.1.2">ğ·</ci><ci id="S2.SS2.p1.8.m3.1.1.1.1.1.3.cmml" xref="S2.SS2.p1.8.m3.1.1.1.1.1.3">ğ’˜</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.8.m3.1c">p(D\mid\boldsymbol{w})</annotation></semantics></math> for parameter <math id="S2.SS2.p1.9.m4.1" class="ltx_Math" alttext="\boldsymbol{w}" display="inline"><semantics id="S2.SS2.p1.9.m4.1a"><mi id="S2.SS2.p1.9.m4.1.1" xref="S2.SS2.p1.9.m4.1.1.cmml">ğ’˜</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.9.m4.1b"><ci id="S2.SS2.p1.9.m4.1.1.cmml" xref="S2.SS2.p1.9.m4.1.1">ğ’˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.9.m4.1c">\boldsymbol{w}</annotation></semantics></math> on observed evidence <math id="S2.SS2.p1.10.m5.1" class="ltx_Math" alttext="D" display="inline"><semantics id="S2.SS2.p1.10.m5.1a"><mi id="S2.SS2.p1.10.m5.1.1" xref="S2.SS2.p1.10.m5.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.10.m5.1b"><ci id="S2.SS2.p1.10.m5.1.1.cmml" xref="S2.SS2.p1.10.m5.1.1">ğ·</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.10.m5.1c">D</annotation></semantics></math>.</p>
</div>
<div id="S2.SS2.p2" class="ltx_para">
<p id="S2.SS2.p2.1" class="ltx_p"><span id="S2.SS2.p2.1.1" class="ltx_text ltx_font_bold">BL methods</span>. Bayesâ€™ theorem has been widely applied in various settings and has generated numerous BL methods <cite class="ltx_cite ltx_citemacro_cite">Jospin <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib31" title="" class="ltx_ref">2022</a>); Gershman and
Blei (<a href="#bib.bib26" title="" class="ltx_ref">2012</a>)</cite> for tasks such as Bayesian classification, regression, clustering, representation, and optimization. In addition, these can be categorized in terms of modeling mechanisms and settings, learning tasks, and application scenarios, for example (1) Bayesian classification, such as naive Bayes and Bayesian belief networks for classification or optimization; (2) Bayesian approximation, inference and optimization, such as Laplaceâ€™s approximation, expectation propagation, and variational approximation and Markov chain Monte Carlo (MCMC) methods such as Gibbs sampling; (3) hierarchical Bayesian models with hierarchical variable/parameter dependence, such as Beta-Poisson models; (4) dynamic BL such as Bayesian nonparametric models; (5) BL for other settings and tasks, such as Bayesian continual learning, Bayesian model averaging, and Bayesian posterior decomposition; and (6) hybrid BL methods, such as Bayesian neural networks, and Bayesian model ensemble.</p>
</div>
<div id="S2.SS2.p3" class="ltx_para">
<p id="S2.SS2.p3.1" class="ltx_p"><span id="S2.SS2.p3.1.1" class="ltx_text ltx_font_bold">BL advantages</span>. BL shows various advantages. (1) <span id="S2.SS2.p3.1.2" class="ltx_text ltx_font_italic">Quantifying uncertainty</span> over probability distributions rather than specific values, which captures the model or epistemic uncertainty of model parameters <cite class="ltx_cite ltx_citemacro_cite">Kendall and
Gal (<a href="#bib.bib34" title="" class="ltx_ref">2017</a>)</cite>. This can justify the reliability of results, such as for safety-critical applications. (2) <span id="S2.SS2.p3.1.3" class="ltx_text ltx_font_italic">Enhancing robustness</span> by evidence-based likelihood estimates, which learns the parameter distributions and regularizes the model for more robust parameters. (3) <span id="S2.SS2.p3.1.4" class="ltx_text ltx_font_italic">Improving performance on limited data</span> using prior distribution for each model parameter, which captures prior knowledge about the data and problem. This can greatly improve modeling performance particularly with limited data <cite class="ltx_cite ltx_citemacro_cite">Sun <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib51" title="" class="ltx_ref">2019</a>)</cite>.</p>
</div>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>BFL: Bayesian Federated Learning</h3>

<div id="S2.SS3.p1" class="ltx_para">
<p id="S2.SS3.p1.1" class="ltx_p">The discussed challenges facing FL can be mostly overcome by taking advantage of BL to address various real-life needs. Consequently, Bayesian federated learning (BFL) has been explored to incorporate BL principles and advantages into FL frameworks and tasks for stronger model robustness and learning improved performance on small-scale data <cite class="ltx_cite ltx_citemacro_cite">Zhang <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib65" title="" class="ltx_ref">2022</a>)</cite>. BFL could lead to more robust, better explainable, and higher performance in handling uncertainties and process-oriented (rather than point-based) challenges. Such advantages could benefit various applications with strong uncertainties, such as estimating financial market dynamics, medical conditions, infectious diseases, financial crisis, and natural disaster.</p>
</div>
<div id="S2.SS3.p2" class="ltx_para">
<p id="S2.SS3.p2.5" class="ltx_p">Although no unified definitions are available for BFL, Figure <a href="#S2.F1" title="Figure 1 â€£ 2.3 BFL: Bayesian Federated Learning â€£ 2 From Federated and Bayesian Learning to Bayesian Federated Learning â€£ Bayesian Federated Learning: A Survey" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> illustrates (1) the general framework of BFL, which integrates mechanisms of FL and BL; and (2) a general iterative learning process of BFL. Differing from pure FL, a BFL system learns global posterior <math id="S2.SS3.p2.1.m1.1" class="ltx_Math" alttext="p(\boldsymbol{w}\mid D)" display="inline"><semantics id="S2.SS3.p2.1.m1.1a"><mrow id="S2.SS3.p2.1.m1.1.1" xref="S2.SS3.p2.1.m1.1.1.cmml"><mi id="S2.SS3.p2.1.m1.1.1.3" xref="S2.SS3.p2.1.m1.1.1.3.cmml">p</mi><mo lspace="0em" rspace="0em" id="S2.SS3.p2.1.m1.1.1.2" xref="S2.SS3.p2.1.m1.1.1.2.cmml">â€‹</mo><mrow id="S2.SS3.p2.1.m1.1.1.1.1" xref="S2.SS3.p2.1.m1.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.SS3.p2.1.m1.1.1.1.1.2" xref="S2.SS3.p2.1.m1.1.1.1.1.1.cmml">(</mo><mrow id="S2.SS3.p2.1.m1.1.1.1.1.1" xref="S2.SS3.p2.1.m1.1.1.1.1.1.cmml"><mi id="S2.SS3.p2.1.m1.1.1.1.1.1.2" xref="S2.SS3.p2.1.m1.1.1.1.1.1.2.cmml">ğ’˜</mi><mo id="S2.SS3.p2.1.m1.1.1.1.1.1.1" xref="S2.SS3.p2.1.m1.1.1.1.1.1.1.cmml">âˆ£</mo><mi id="S2.SS3.p2.1.m1.1.1.1.1.1.3" xref="S2.SS3.p2.1.m1.1.1.1.1.1.3.cmml">D</mi></mrow><mo stretchy="false" id="S2.SS3.p2.1.m1.1.1.1.1.3" xref="S2.SS3.p2.1.m1.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.1.m1.1b"><apply id="S2.SS3.p2.1.m1.1.1.cmml" xref="S2.SS3.p2.1.m1.1.1"><times id="S2.SS3.p2.1.m1.1.1.2.cmml" xref="S2.SS3.p2.1.m1.1.1.2"></times><ci id="S2.SS3.p2.1.m1.1.1.3.cmml" xref="S2.SS3.p2.1.m1.1.1.3">ğ‘</ci><apply id="S2.SS3.p2.1.m1.1.1.1.1.1.cmml" xref="S2.SS3.p2.1.m1.1.1.1.1"><csymbol cd="latexml" id="S2.SS3.p2.1.m1.1.1.1.1.1.1.cmml" xref="S2.SS3.p2.1.m1.1.1.1.1.1.1">conditional</csymbol><ci id="S2.SS3.p2.1.m1.1.1.1.1.1.2.cmml" xref="S2.SS3.p2.1.m1.1.1.1.1.1.2">ğ’˜</ci><ci id="S2.SS3.p2.1.m1.1.1.1.1.1.3.cmml" xref="S2.SS3.p2.1.m1.1.1.1.1.1.3">ğ·</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.1.m1.1c">p(\boldsymbol{w}\mid D)</annotation></semantics></math> for the server and local posterior <math id="S2.SS3.p2.2.m2.1" class="ltx_Math" alttext="p_{m}(\boldsymbol{w}_{m}\mid D_{m})" display="inline"><semantics id="S2.SS3.p2.2.m2.1a"><mrow id="S2.SS3.p2.2.m2.1.1" xref="S2.SS3.p2.2.m2.1.1.cmml"><msub id="S2.SS3.p2.2.m2.1.1.3" xref="S2.SS3.p2.2.m2.1.1.3.cmml"><mi id="S2.SS3.p2.2.m2.1.1.3.2" xref="S2.SS3.p2.2.m2.1.1.3.2.cmml">p</mi><mi id="S2.SS3.p2.2.m2.1.1.3.3" xref="S2.SS3.p2.2.m2.1.1.3.3.cmml">m</mi></msub><mo lspace="0em" rspace="0em" id="S2.SS3.p2.2.m2.1.1.2" xref="S2.SS3.p2.2.m2.1.1.2.cmml">â€‹</mo><mrow id="S2.SS3.p2.2.m2.1.1.1.1" xref="S2.SS3.p2.2.m2.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.SS3.p2.2.m2.1.1.1.1.2" xref="S2.SS3.p2.2.m2.1.1.1.1.1.cmml">(</mo><mrow id="S2.SS3.p2.2.m2.1.1.1.1.1" xref="S2.SS3.p2.2.m2.1.1.1.1.1.cmml"><msub id="S2.SS3.p2.2.m2.1.1.1.1.1.2" xref="S2.SS3.p2.2.m2.1.1.1.1.1.2.cmml"><mi id="S2.SS3.p2.2.m2.1.1.1.1.1.2.2" xref="S2.SS3.p2.2.m2.1.1.1.1.1.2.2.cmml">ğ’˜</mi><mi id="S2.SS3.p2.2.m2.1.1.1.1.1.2.3" xref="S2.SS3.p2.2.m2.1.1.1.1.1.2.3.cmml">m</mi></msub><mo id="S2.SS3.p2.2.m2.1.1.1.1.1.1" xref="S2.SS3.p2.2.m2.1.1.1.1.1.1.cmml">âˆ£</mo><msub id="S2.SS3.p2.2.m2.1.1.1.1.1.3" xref="S2.SS3.p2.2.m2.1.1.1.1.1.3.cmml"><mi id="S2.SS3.p2.2.m2.1.1.1.1.1.3.2" xref="S2.SS3.p2.2.m2.1.1.1.1.1.3.2.cmml">D</mi><mi id="S2.SS3.p2.2.m2.1.1.1.1.1.3.3" xref="S2.SS3.p2.2.m2.1.1.1.1.1.3.3.cmml">m</mi></msub></mrow><mo stretchy="false" id="S2.SS3.p2.2.m2.1.1.1.1.3" xref="S2.SS3.p2.2.m2.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.2.m2.1b"><apply id="S2.SS3.p2.2.m2.1.1.cmml" xref="S2.SS3.p2.2.m2.1.1"><times id="S2.SS3.p2.2.m2.1.1.2.cmml" xref="S2.SS3.p2.2.m2.1.1.2"></times><apply id="S2.SS3.p2.2.m2.1.1.3.cmml" xref="S2.SS3.p2.2.m2.1.1.3"><csymbol cd="ambiguous" id="S2.SS3.p2.2.m2.1.1.3.1.cmml" xref="S2.SS3.p2.2.m2.1.1.3">subscript</csymbol><ci id="S2.SS3.p2.2.m2.1.1.3.2.cmml" xref="S2.SS3.p2.2.m2.1.1.3.2">ğ‘</ci><ci id="S2.SS3.p2.2.m2.1.1.3.3.cmml" xref="S2.SS3.p2.2.m2.1.1.3.3">ğ‘š</ci></apply><apply id="S2.SS3.p2.2.m2.1.1.1.1.1.cmml" xref="S2.SS3.p2.2.m2.1.1.1.1"><csymbol cd="latexml" id="S2.SS3.p2.2.m2.1.1.1.1.1.1.cmml" xref="S2.SS3.p2.2.m2.1.1.1.1.1.1">conditional</csymbol><apply id="S2.SS3.p2.2.m2.1.1.1.1.1.2.cmml" xref="S2.SS3.p2.2.m2.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.SS3.p2.2.m2.1.1.1.1.1.2.1.cmml" xref="S2.SS3.p2.2.m2.1.1.1.1.1.2">subscript</csymbol><ci id="S2.SS3.p2.2.m2.1.1.1.1.1.2.2.cmml" xref="S2.SS3.p2.2.m2.1.1.1.1.1.2.2">ğ’˜</ci><ci id="S2.SS3.p2.2.m2.1.1.1.1.1.2.3.cmml" xref="S2.SS3.p2.2.m2.1.1.1.1.1.2.3">ğ‘š</ci></apply><apply id="S2.SS3.p2.2.m2.1.1.1.1.1.3.cmml" xref="S2.SS3.p2.2.m2.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.SS3.p2.2.m2.1.1.1.1.1.3.1.cmml" xref="S2.SS3.p2.2.m2.1.1.1.1.1.3">subscript</csymbol><ci id="S2.SS3.p2.2.m2.1.1.1.1.1.3.2.cmml" xref="S2.SS3.p2.2.m2.1.1.1.1.1.3.2">ğ·</ci><ci id="S2.SS3.p2.2.m2.1.1.1.1.1.3.3.cmml" xref="S2.SS3.p2.2.m2.1.1.1.1.1.3.3">ğ‘š</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.2.m2.1c">p_{m}(\boldsymbol{w}_{m}\mid D_{m})</annotation></semantics></math> for each participating client <math id="S2.SS3.p2.3.m3.1" class="ltx_Math" alttext="m" display="inline"><semantics id="S2.SS3.p2.3.m3.1a"><mi id="S2.SS3.p2.3.m3.1.1" xref="S2.SS3.p2.3.m3.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.3.m3.1b"><ci id="S2.SS3.p2.3.m3.1.1.cmml" xref="S2.SS3.p2.3.m3.1.1">ğ‘š</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.3.m3.1c">m</annotation></semantics></math> on its local data <math id="S2.SS3.p2.4.m4.1" class="ltx_Math" alttext="D_{m}" display="inline"><semantics id="S2.SS3.p2.4.m4.1a"><msub id="S2.SS3.p2.4.m4.1.1" xref="S2.SS3.p2.4.m4.1.1.cmml"><mi id="S2.SS3.p2.4.m4.1.1.2" xref="S2.SS3.p2.4.m4.1.1.2.cmml">D</mi><mi id="S2.SS3.p2.4.m4.1.1.3" xref="S2.SS3.p2.4.m4.1.1.3.cmml">m</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.4.m4.1b"><apply id="S2.SS3.p2.4.m4.1.1.cmml" xref="S2.SS3.p2.4.m4.1.1"><csymbol cd="ambiguous" id="S2.SS3.p2.4.m4.1.1.1.cmml" xref="S2.SS3.p2.4.m4.1.1">subscript</csymbol><ci id="S2.SS3.p2.4.m4.1.1.2.cmml" xref="S2.SS3.p2.4.m4.1.1.2">ğ·</ci><ci id="S2.SS3.p2.4.m4.1.1.3.cmml" xref="S2.SS3.p2.4.m4.1.1.3">ğ‘š</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.4.m4.1c">D_{m}</annotation></semantics></math>. A general or localized prior <math id="S2.SS3.p2.5.m5.1" class="ltx_Math" alttext="p(\boldsymbol{w})" display="inline"><semantics id="S2.SS3.p2.5.m5.1a"><mrow id="S2.SS3.p2.5.m5.1.2" xref="S2.SS3.p2.5.m5.1.2.cmml"><mi id="S2.SS3.p2.5.m5.1.2.2" xref="S2.SS3.p2.5.m5.1.2.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S2.SS3.p2.5.m5.1.2.1" xref="S2.SS3.p2.5.m5.1.2.1.cmml">â€‹</mo><mrow id="S2.SS3.p2.5.m5.1.2.3.2" xref="S2.SS3.p2.5.m5.1.2.cmml"><mo stretchy="false" id="S2.SS3.p2.5.m5.1.2.3.2.1" xref="S2.SS3.p2.5.m5.1.2.cmml">(</mo><mi id="S2.SS3.p2.5.m5.1.1" xref="S2.SS3.p2.5.m5.1.1.cmml">ğ’˜</mi><mo stretchy="false" id="S2.SS3.p2.5.m5.1.2.3.2.2" xref="S2.SS3.p2.5.m5.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.5.m5.1b"><apply id="S2.SS3.p2.5.m5.1.2.cmml" xref="S2.SS3.p2.5.m5.1.2"><times id="S2.SS3.p2.5.m5.1.2.1.cmml" xref="S2.SS3.p2.5.m5.1.2.1"></times><ci id="S2.SS3.p2.5.m5.1.2.2.cmml" xref="S2.SS3.p2.5.m5.1.2.2">ğ‘</ci><ci id="S2.SS3.p2.5.m5.1.1.cmml" xref="S2.SS3.p2.5.m5.1.1">ğ’˜</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.5.m5.1c">p(\boldsymbol{w})</annotation></semantics></math> applies to all clients.
BFL incorporates Bayesian principles into FL for the server:</p>
<table id="S2.E4" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E4.m1.4" class="ltx_Math" alttext="p(\boldsymbol{w}_{g}\mid D)=\frac{p(D\mid\boldsymbol{w}_{g})p(\boldsymbol{w}_{g})}{p(D)}," display="block"><semantics id="S2.E4.m1.4a"><mrow id="S2.E4.m1.4.4.1" xref="S2.E4.m1.4.4.1.1.cmml"><mrow id="S2.E4.m1.4.4.1.1" xref="S2.E4.m1.4.4.1.1.cmml"><mrow id="S2.E4.m1.4.4.1.1.1" xref="S2.E4.m1.4.4.1.1.1.cmml"><mi id="S2.E4.m1.4.4.1.1.1.3" xref="S2.E4.m1.4.4.1.1.1.3.cmml">p</mi><mo lspace="0em" rspace="0em" id="S2.E4.m1.4.4.1.1.1.2" xref="S2.E4.m1.4.4.1.1.1.2.cmml">â€‹</mo><mrow id="S2.E4.m1.4.4.1.1.1.1.1" xref="S2.E4.m1.4.4.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.E4.m1.4.4.1.1.1.1.1.2" xref="S2.E4.m1.4.4.1.1.1.1.1.1.cmml">(</mo><mrow id="S2.E4.m1.4.4.1.1.1.1.1.1" xref="S2.E4.m1.4.4.1.1.1.1.1.1.cmml"><msub id="S2.E4.m1.4.4.1.1.1.1.1.1.2" xref="S2.E4.m1.4.4.1.1.1.1.1.1.2.cmml"><mi id="S2.E4.m1.4.4.1.1.1.1.1.1.2.2" xref="S2.E4.m1.4.4.1.1.1.1.1.1.2.2.cmml">ğ’˜</mi><mi id="S2.E4.m1.4.4.1.1.1.1.1.1.2.3" xref="S2.E4.m1.4.4.1.1.1.1.1.1.2.3.cmml">g</mi></msub><mo id="S2.E4.m1.4.4.1.1.1.1.1.1.1" xref="S2.E4.m1.4.4.1.1.1.1.1.1.1.cmml">âˆ£</mo><mi id="S2.E4.m1.4.4.1.1.1.1.1.1.3" xref="S2.E4.m1.4.4.1.1.1.1.1.1.3.cmml">D</mi></mrow><mo stretchy="false" id="S2.E4.m1.4.4.1.1.1.1.1.3" xref="S2.E4.m1.4.4.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S2.E4.m1.4.4.1.1.2" xref="S2.E4.m1.4.4.1.1.2.cmml">=</mo><mfrac id="S2.E4.m1.3.3" xref="S2.E4.m1.3.3.cmml"><mrow id="S2.E4.m1.2.2.2" xref="S2.E4.m1.2.2.2.cmml"><mi id="S2.E4.m1.2.2.2.4" xref="S2.E4.m1.2.2.2.4.cmml">p</mi><mo lspace="0em" rspace="0em" id="S2.E4.m1.2.2.2.3" xref="S2.E4.m1.2.2.2.3.cmml">â€‹</mo><mrow id="S2.E4.m1.1.1.1.1.1" xref="S2.E4.m1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.E4.m1.1.1.1.1.1.2" xref="S2.E4.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="S2.E4.m1.1.1.1.1.1.1" xref="S2.E4.m1.1.1.1.1.1.1.cmml"><mi id="S2.E4.m1.1.1.1.1.1.1.2" xref="S2.E4.m1.1.1.1.1.1.1.2.cmml">D</mi><mo id="S2.E4.m1.1.1.1.1.1.1.1" xref="S2.E4.m1.1.1.1.1.1.1.1.cmml">âˆ£</mo><msub id="S2.E4.m1.1.1.1.1.1.1.3" xref="S2.E4.m1.1.1.1.1.1.1.3.cmml"><mi id="S2.E4.m1.1.1.1.1.1.1.3.2" xref="S2.E4.m1.1.1.1.1.1.1.3.2.cmml">ğ’˜</mi><mi id="S2.E4.m1.1.1.1.1.1.1.3.3" xref="S2.E4.m1.1.1.1.1.1.1.3.3.cmml">g</mi></msub></mrow><mo stretchy="false" id="S2.E4.m1.1.1.1.1.1.3" xref="S2.E4.m1.1.1.1.1.1.1.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S2.E4.m1.2.2.2.3a" xref="S2.E4.m1.2.2.2.3.cmml">â€‹</mo><mi id="S2.E4.m1.2.2.2.5" xref="S2.E4.m1.2.2.2.5.cmml">p</mi><mo lspace="0em" rspace="0em" id="S2.E4.m1.2.2.2.3b" xref="S2.E4.m1.2.2.2.3.cmml">â€‹</mo><mrow id="S2.E4.m1.2.2.2.2.1" xref="S2.E4.m1.2.2.2.2.1.1.cmml"><mo stretchy="false" id="S2.E4.m1.2.2.2.2.1.2" xref="S2.E4.m1.2.2.2.2.1.1.cmml">(</mo><msub id="S2.E4.m1.2.2.2.2.1.1" xref="S2.E4.m1.2.2.2.2.1.1.cmml"><mi id="S2.E4.m1.2.2.2.2.1.1.2" xref="S2.E4.m1.2.2.2.2.1.1.2.cmml">ğ’˜</mi><mi id="S2.E4.m1.2.2.2.2.1.1.3" xref="S2.E4.m1.2.2.2.2.1.1.3.cmml">g</mi></msub><mo stretchy="false" id="S2.E4.m1.2.2.2.2.1.3" xref="S2.E4.m1.2.2.2.2.1.1.cmml">)</mo></mrow></mrow><mrow id="S2.E4.m1.3.3.3" xref="S2.E4.m1.3.3.3.cmml"><mi id="S2.E4.m1.3.3.3.3" xref="S2.E4.m1.3.3.3.3.cmml">p</mi><mo lspace="0em" rspace="0em" id="S2.E4.m1.3.3.3.2" xref="S2.E4.m1.3.3.3.2.cmml">â€‹</mo><mrow id="S2.E4.m1.3.3.3.4.2" xref="S2.E4.m1.3.3.3.cmml"><mo stretchy="false" id="S2.E4.m1.3.3.3.4.2.1" xref="S2.E4.m1.3.3.3.cmml">(</mo><mi id="S2.E4.m1.3.3.3.1" xref="S2.E4.m1.3.3.3.1.cmml">D</mi><mo stretchy="false" id="S2.E4.m1.3.3.3.4.2.2" xref="S2.E4.m1.3.3.3.cmml">)</mo></mrow></mrow></mfrac></mrow><mo id="S2.E4.m1.4.4.1.2" xref="S2.E4.m1.4.4.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.E4.m1.4b"><apply id="S2.E4.m1.4.4.1.1.cmml" xref="S2.E4.m1.4.4.1"><eq id="S2.E4.m1.4.4.1.1.2.cmml" xref="S2.E4.m1.4.4.1.1.2"></eq><apply id="S2.E4.m1.4.4.1.1.1.cmml" xref="S2.E4.m1.4.4.1.1.1"><times id="S2.E4.m1.4.4.1.1.1.2.cmml" xref="S2.E4.m1.4.4.1.1.1.2"></times><ci id="S2.E4.m1.4.4.1.1.1.3.cmml" xref="S2.E4.m1.4.4.1.1.1.3">ğ‘</ci><apply id="S2.E4.m1.4.4.1.1.1.1.1.1.cmml" xref="S2.E4.m1.4.4.1.1.1.1.1"><csymbol cd="latexml" id="S2.E4.m1.4.4.1.1.1.1.1.1.1.cmml" xref="S2.E4.m1.4.4.1.1.1.1.1.1.1">conditional</csymbol><apply id="S2.E4.m1.4.4.1.1.1.1.1.1.2.cmml" xref="S2.E4.m1.4.4.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.E4.m1.4.4.1.1.1.1.1.1.2.1.cmml" xref="S2.E4.m1.4.4.1.1.1.1.1.1.2">subscript</csymbol><ci id="S2.E4.m1.4.4.1.1.1.1.1.1.2.2.cmml" xref="S2.E4.m1.4.4.1.1.1.1.1.1.2.2">ğ’˜</ci><ci id="S2.E4.m1.4.4.1.1.1.1.1.1.2.3.cmml" xref="S2.E4.m1.4.4.1.1.1.1.1.1.2.3">ğ‘”</ci></apply><ci id="S2.E4.m1.4.4.1.1.1.1.1.1.3.cmml" xref="S2.E4.m1.4.4.1.1.1.1.1.1.3">ğ·</ci></apply></apply><apply id="S2.E4.m1.3.3.cmml" xref="S2.E4.m1.3.3"><divide id="S2.E4.m1.3.3.4.cmml" xref="S2.E4.m1.3.3"></divide><apply id="S2.E4.m1.2.2.2.cmml" xref="S2.E4.m1.2.2.2"><times id="S2.E4.m1.2.2.2.3.cmml" xref="S2.E4.m1.2.2.2.3"></times><ci id="S2.E4.m1.2.2.2.4.cmml" xref="S2.E4.m1.2.2.2.4">ğ‘</ci><apply id="S2.E4.m1.1.1.1.1.1.1.cmml" xref="S2.E4.m1.1.1.1.1.1"><csymbol cd="latexml" id="S2.E4.m1.1.1.1.1.1.1.1.cmml" xref="S2.E4.m1.1.1.1.1.1.1.1">conditional</csymbol><ci id="S2.E4.m1.1.1.1.1.1.1.2.cmml" xref="S2.E4.m1.1.1.1.1.1.1.2">ğ·</ci><apply id="S2.E4.m1.1.1.1.1.1.1.3.cmml" xref="S2.E4.m1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.E4.m1.1.1.1.1.1.1.3.1.cmml" xref="S2.E4.m1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S2.E4.m1.1.1.1.1.1.1.3.2.cmml" xref="S2.E4.m1.1.1.1.1.1.1.3.2">ğ’˜</ci><ci id="S2.E4.m1.1.1.1.1.1.1.3.3.cmml" xref="S2.E4.m1.1.1.1.1.1.1.3.3">ğ‘”</ci></apply></apply><ci id="S2.E4.m1.2.2.2.5.cmml" xref="S2.E4.m1.2.2.2.5">ğ‘</ci><apply id="S2.E4.m1.2.2.2.2.1.1.cmml" xref="S2.E4.m1.2.2.2.2.1"><csymbol cd="ambiguous" id="S2.E4.m1.2.2.2.2.1.1.1.cmml" xref="S2.E4.m1.2.2.2.2.1">subscript</csymbol><ci id="S2.E4.m1.2.2.2.2.1.1.2.cmml" xref="S2.E4.m1.2.2.2.2.1.1.2">ğ’˜</ci><ci id="S2.E4.m1.2.2.2.2.1.1.3.cmml" xref="S2.E4.m1.2.2.2.2.1.1.3">ğ‘”</ci></apply></apply><apply id="S2.E4.m1.3.3.3.cmml" xref="S2.E4.m1.3.3.3"><times id="S2.E4.m1.3.3.3.2.cmml" xref="S2.E4.m1.3.3.3.2"></times><ci id="S2.E4.m1.3.3.3.3.cmml" xref="S2.E4.m1.3.3.3.3">ğ‘</ci><ci id="S2.E4.m1.3.3.3.1.cmml" xref="S2.E4.m1.3.3.3.1">ğ·</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E4.m1.4c">p(\boldsymbol{w}_{g}\mid D)=\frac{p(D\mid\boldsymbol{w}_{g})p(\boldsymbol{w}_{g})}{p(D)},</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
<p id="S2.SS3.p2.12" class="ltx_p">and clients:</p>
<table id="S2.E5" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E5.m1.4" class="ltx_Math" alttext="p(\boldsymbol{w}_{m}\mid D_{m})=\frac{p(D_{m}\mid\boldsymbol{w}_{m})p(\boldsymbol{w}_{m})}{p(D_{m})}." display="block"><semantics id="S2.E5.m1.4a"><mrow id="S2.E5.m1.4.4.1" xref="S2.E5.m1.4.4.1.1.cmml"><mrow id="S2.E5.m1.4.4.1.1" xref="S2.E5.m1.4.4.1.1.cmml"><mrow id="S2.E5.m1.4.4.1.1.1" xref="S2.E5.m1.4.4.1.1.1.cmml"><mi id="S2.E5.m1.4.4.1.1.1.3" xref="S2.E5.m1.4.4.1.1.1.3.cmml">p</mi><mo lspace="0em" rspace="0em" id="S2.E5.m1.4.4.1.1.1.2" xref="S2.E5.m1.4.4.1.1.1.2.cmml">â€‹</mo><mrow id="S2.E5.m1.4.4.1.1.1.1.1" xref="S2.E5.m1.4.4.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.E5.m1.4.4.1.1.1.1.1.2" xref="S2.E5.m1.4.4.1.1.1.1.1.1.cmml">(</mo><mrow id="S2.E5.m1.4.4.1.1.1.1.1.1" xref="S2.E5.m1.4.4.1.1.1.1.1.1.cmml"><msub id="S2.E5.m1.4.4.1.1.1.1.1.1.2" xref="S2.E5.m1.4.4.1.1.1.1.1.1.2.cmml"><mi id="S2.E5.m1.4.4.1.1.1.1.1.1.2.2" xref="S2.E5.m1.4.4.1.1.1.1.1.1.2.2.cmml">ğ’˜</mi><mi id="S2.E5.m1.4.4.1.1.1.1.1.1.2.3" xref="S2.E5.m1.4.4.1.1.1.1.1.1.2.3.cmml">m</mi></msub><mo id="S2.E5.m1.4.4.1.1.1.1.1.1.1" xref="S2.E5.m1.4.4.1.1.1.1.1.1.1.cmml">âˆ£</mo><msub id="S2.E5.m1.4.4.1.1.1.1.1.1.3" xref="S2.E5.m1.4.4.1.1.1.1.1.1.3.cmml"><mi id="S2.E5.m1.4.4.1.1.1.1.1.1.3.2" xref="S2.E5.m1.4.4.1.1.1.1.1.1.3.2.cmml">D</mi><mi id="S2.E5.m1.4.4.1.1.1.1.1.1.3.3" xref="S2.E5.m1.4.4.1.1.1.1.1.1.3.3.cmml">m</mi></msub></mrow><mo stretchy="false" id="S2.E5.m1.4.4.1.1.1.1.1.3" xref="S2.E5.m1.4.4.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S2.E5.m1.4.4.1.1.2" xref="S2.E5.m1.4.4.1.1.2.cmml">=</mo><mfrac id="S2.E5.m1.3.3" xref="S2.E5.m1.3.3.cmml"><mrow id="S2.E5.m1.2.2.2" xref="S2.E5.m1.2.2.2.cmml"><mi id="S2.E5.m1.2.2.2.4" xref="S2.E5.m1.2.2.2.4.cmml">p</mi><mo lspace="0em" rspace="0em" id="S2.E5.m1.2.2.2.3" xref="S2.E5.m1.2.2.2.3.cmml">â€‹</mo><mrow id="S2.E5.m1.1.1.1.1.1" xref="S2.E5.m1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.E5.m1.1.1.1.1.1.2" xref="S2.E5.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="S2.E5.m1.1.1.1.1.1.1" xref="S2.E5.m1.1.1.1.1.1.1.cmml"><msub id="S2.E5.m1.1.1.1.1.1.1.2" xref="S2.E5.m1.1.1.1.1.1.1.2.cmml"><mi id="S2.E5.m1.1.1.1.1.1.1.2.2" xref="S2.E5.m1.1.1.1.1.1.1.2.2.cmml">D</mi><mi id="S2.E5.m1.1.1.1.1.1.1.2.3" xref="S2.E5.m1.1.1.1.1.1.1.2.3.cmml">m</mi></msub><mo id="S2.E5.m1.1.1.1.1.1.1.1" xref="S2.E5.m1.1.1.1.1.1.1.1.cmml">âˆ£</mo><msub id="S2.E5.m1.1.1.1.1.1.1.3" xref="S2.E5.m1.1.1.1.1.1.1.3.cmml"><mi id="S2.E5.m1.1.1.1.1.1.1.3.2" xref="S2.E5.m1.1.1.1.1.1.1.3.2.cmml">ğ’˜</mi><mi id="S2.E5.m1.1.1.1.1.1.1.3.3" xref="S2.E5.m1.1.1.1.1.1.1.3.3.cmml">m</mi></msub></mrow><mo stretchy="false" id="S2.E5.m1.1.1.1.1.1.3" xref="S2.E5.m1.1.1.1.1.1.1.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S2.E5.m1.2.2.2.3a" xref="S2.E5.m1.2.2.2.3.cmml">â€‹</mo><mi id="S2.E5.m1.2.2.2.5" xref="S2.E5.m1.2.2.2.5.cmml">p</mi><mo lspace="0em" rspace="0em" id="S2.E5.m1.2.2.2.3b" xref="S2.E5.m1.2.2.2.3.cmml">â€‹</mo><mrow id="S2.E5.m1.2.2.2.2.1" xref="S2.E5.m1.2.2.2.2.1.1.cmml"><mo stretchy="false" id="S2.E5.m1.2.2.2.2.1.2" xref="S2.E5.m1.2.2.2.2.1.1.cmml">(</mo><msub id="S2.E5.m1.2.2.2.2.1.1" xref="S2.E5.m1.2.2.2.2.1.1.cmml"><mi id="S2.E5.m1.2.2.2.2.1.1.2" xref="S2.E5.m1.2.2.2.2.1.1.2.cmml">ğ’˜</mi><mi id="S2.E5.m1.2.2.2.2.1.1.3" xref="S2.E5.m1.2.2.2.2.1.1.3.cmml">m</mi></msub><mo stretchy="false" id="S2.E5.m1.2.2.2.2.1.3" xref="S2.E5.m1.2.2.2.2.1.1.cmml">)</mo></mrow></mrow><mrow id="S2.E5.m1.3.3.3" xref="S2.E5.m1.3.3.3.cmml"><mi id="S2.E5.m1.3.3.3.3" xref="S2.E5.m1.3.3.3.3.cmml">p</mi><mo lspace="0em" rspace="0em" id="S2.E5.m1.3.3.3.2" xref="S2.E5.m1.3.3.3.2.cmml">â€‹</mo><mrow id="S2.E5.m1.3.3.3.1.1" xref="S2.E5.m1.3.3.3.1.1.1.cmml"><mo stretchy="false" id="S2.E5.m1.3.3.3.1.1.2" xref="S2.E5.m1.3.3.3.1.1.1.cmml">(</mo><msub id="S2.E5.m1.3.3.3.1.1.1" xref="S2.E5.m1.3.3.3.1.1.1.cmml"><mi id="S2.E5.m1.3.3.3.1.1.1.2" xref="S2.E5.m1.3.3.3.1.1.1.2.cmml">D</mi><mi id="S2.E5.m1.3.3.3.1.1.1.3" xref="S2.E5.m1.3.3.3.1.1.1.3.cmml">m</mi></msub><mo stretchy="false" id="S2.E5.m1.3.3.3.1.1.3" xref="S2.E5.m1.3.3.3.1.1.1.cmml">)</mo></mrow></mrow></mfrac></mrow><mo lspace="0em" id="S2.E5.m1.4.4.1.2" xref="S2.E5.m1.4.4.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.E5.m1.4b"><apply id="S2.E5.m1.4.4.1.1.cmml" xref="S2.E5.m1.4.4.1"><eq id="S2.E5.m1.4.4.1.1.2.cmml" xref="S2.E5.m1.4.4.1.1.2"></eq><apply id="S2.E5.m1.4.4.1.1.1.cmml" xref="S2.E5.m1.4.4.1.1.1"><times id="S2.E5.m1.4.4.1.1.1.2.cmml" xref="S2.E5.m1.4.4.1.1.1.2"></times><ci id="S2.E5.m1.4.4.1.1.1.3.cmml" xref="S2.E5.m1.4.4.1.1.1.3">ğ‘</ci><apply id="S2.E5.m1.4.4.1.1.1.1.1.1.cmml" xref="S2.E5.m1.4.4.1.1.1.1.1"><csymbol cd="latexml" id="S2.E5.m1.4.4.1.1.1.1.1.1.1.cmml" xref="S2.E5.m1.4.4.1.1.1.1.1.1.1">conditional</csymbol><apply id="S2.E5.m1.4.4.1.1.1.1.1.1.2.cmml" xref="S2.E5.m1.4.4.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.E5.m1.4.4.1.1.1.1.1.1.2.1.cmml" xref="S2.E5.m1.4.4.1.1.1.1.1.1.2">subscript</csymbol><ci id="S2.E5.m1.4.4.1.1.1.1.1.1.2.2.cmml" xref="S2.E5.m1.4.4.1.1.1.1.1.1.2.2">ğ’˜</ci><ci id="S2.E5.m1.4.4.1.1.1.1.1.1.2.3.cmml" xref="S2.E5.m1.4.4.1.1.1.1.1.1.2.3">ğ‘š</ci></apply><apply id="S2.E5.m1.4.4.1.1.1.1.1.1.3.cmml" xref="S2.E5.m1.4.4.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.E5.m1.4.4.1.1.1.1.1.1.3.1.cmml" xref="S2.E5.m1.4.4.1.1.1.1.1.1.3">subscript</csymbol><ci id="S2.E5.m1.4.4.1.1.1.1.1.1.3.2.cmml" xref="S2.E5.m1.4.4.1.1.1.1.1.1.3.2">ğ·</ci><ci id="S2.E5.m1.4.4.1.1.1.1.1.1.3.3.cmml" xref="S2.E5.m1.4.4.1.1.1.1.1.1.3.3">ğ‘š</ci></apply></apply></apply><apply id="S2.E5.m1.3.3.cmml" xref="S2.E5.m1.3.3"><divide id="S2.E5.m1.3.3.4.cmml" xref="S2.E5.m1.3.3"></divide><apply id="S2.E5.m1.2.2.2.cmml" xref="S2.E5.m1.2.2.2"><times id="S2.E5.m1.2.2.2.3.cmml" xref="S2.E5.m1.2.2.2.3"></times><ci id="S2.E5.m1.2.2.2.4.cmml" xref="S2.E5.m1.2.2.2.4">ğ‘</ci><apply id="S2.E5.m1.1.1.1.1.1.1.cmml" xref="S2.E5.m1.1.1.1.1.1"><csymbol cd="latexml" id="S2.E5.m1.1.1.1.1.1.1.1.cmml" xref="S2.E5.m1.1.1.1.1.1.1.1">conditional</csymbol><apply id="S2.E5.m1.1.1.1.1.1.1.2.cmml" xref="S2.E5.m1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.E5.m1.1.1.1.1.1.1.2.1.cmml" xref="S2.E5.m1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S2.E5.m1.1.1.1.1.1.1.2.2.cmml" xref="S2.E5.m1.1.1.1.1.1.1.2.2">ğ·</ci><ci id="S2.E5.m1.1.1.1.1.1.1.2.3.cmml" xref="S2.E5.m1.1.1.1.1.1.1.2.3">ğ‘š</ci></apply><apply id="S2.E5.m1.1.1.1.1.1.1.3.cmml" xref="S2.E5.m1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.E5.m1.1.1.1.1.1.1.3.1.cmml" xref="S2.E5.m1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S2.E5.m1.1.1.1.1.1.1.3.2.cmml" xref="S2.E5.m1.1.1.1.1.1.1.3.2">ğ’˜</ci><ci id="S2.E5.m1.1.1.1.1.1.1.3.3.cmml" xref="S2.E5.m1.1.1.1.1.1.1.3.3">ğ‘š</ci></apply></apply><ci id="S2.E5.m1.2.2.2.5.cmml" xref="S2.E5.m1.2.2.2.5">ğ‘</ci><apply id="S2.E5.m1.2.2.2.2.1.1.cmml" xref="S2.E5.m1.2.2.2.2.1"><csymbol cd="ambiguous" id="S2.E5.m1.2.2.2.2.1.1.1.cmml" xref="S2.E5.m1.2.2.2.2.1">subscript</csymbol><ci id="S2.E5.m1.2.2.2.2.1.1.2.cmml" xref="S2.E5.m1.2.2.2.2.1.1.2">ğ’˜</ci><ci id="S2.E5.m1.2.2.2.2.1.1.3.cmml" xref="S2.E5.m1.2.2.2.2.1.1.3">ğ‘š</ci></apply></apply><apply id="S2.E5.m1.3.3.3.cmml" xref="S2.E5.m1.3.3.3"><times id="S2.E5.m1.3.3.3.2.cmml" xref="S2.E5.m1.3.3.3.2"></times><ci id="S2.E5.m1.3.3.3.3.cmml" xref="S2.E5.m1.3.3.3.3">ğ‘</ci><apply id="S2.E5.m1.3.3.3.1.1.1.cmml" xref="S2.E5.m1.3.3.3.1.1"><csymbol cd="ambiguous" id="S2.E5.m1.3.3.3.1.1.1.1.cmml" xref="S2.E5.m1.3.3.3.1.1">subscript</csymbol><ci id="S2.E5.m1.3.3.3.1.1.1.2.cmml" xref="S2.E5.m1.3.3.3.1.1.1.2">ğ·</ci><ci id="S2.E5.m1.3.3.3.1.1.1.3.cmml" xref="S2.E5.m1.3.3.3.1.1.1.3">ğ‘š</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E5.m1.4c">p(\boldsymbol{w}_{m}\mid D_{m})=\frac{p(D_{m}\mid\boldsymbol{w}_{m})p(\boldsymbol{w}_{m})}{p(D_{m})}.</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5)</span></td>
</tr></tbody>
</table>
<p id="S2.SS3.p2.11" class="ltx_p"><math id="S2.SS3.p2.6.m1.1" class="ltx_Math" alttext="\boldsymbol{w}_{g}" display="inline"><semantics id="S2.SS3.p2.6.m1.1a"><msub id="S2.SS3.p2.6.m1.1.1" xref="S2.SS3.p2.6.m1.1.1.cmml"><mi id="S2.SS3.p2.6.m1.1.1.2" xref="S2.SS3.p2.6.m1.1.1.2.cmml">ğ’˜</mi><mi id="S2.SS3.p2.6.m1.1.1.3" xref="S2.SS3.p2.6.m1.1.1.3.cmml">g</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.6.m1.1b"><apply id="S2.SS3.p2.6.m1.1.1.cmml" xref="S2.SS3.p2.6.m1.1.1"><csymbol cd="ambiguous" id="S2.SS3.p2.6.m1.1.1.1.cmml" xref="S2.SS3.p2.6.m1.1.1">subscript</csymbol><ci id="S2.SS3.p2.6.m1.1.1.2.cmml" xref="S2.SS3.p2.6.m1.1.1.2">ğ’˜</ci><ci id="S2.SS3.p2.6.m1.1.1.3.cmml" xref="S2.SS3.p2.6.m1.1.1.3">ğ‘”</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.6.m1.1c">\boldsymbol{w}_{g}</annotation></semantics></math> and <math id="S2.SS3.p2.7.m2.1" class="ltx_Math" alttext="\boldsymbol{w}_{m}" display="inline"><semantics id="S2.SS3.p2.7.m2.1a"><msub id="S2.SS3.p2.7.m2.1.1" xref="S2.SS3.p2.7.m2.1.1.cmml"><mi id="S2.SS3.p2.7.m2.1.1.2" xref="S2.SS3.p2.7.m2.1.1.2.cmml">ğ’˜</mi><mi id="S2.SS3.p2.7.m2.1.1.3" xref="S2.SS3.p2.7.m2.1.1.3.cmml">m</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.7.m2.1b"><apply id="S2.SS3.p2.7.m2.1.1.cmml" xref="S2.SS3.p2.7.m2.1.1"><csymbol cd="ambiguous" id="S2.SS3.p2.7.m2.1.1.1.cmml" xref="S2.SS3.p2.7.m2.1.1">subscript</csymbol><ci id="S2.SS3.p2.7.m2.1.1.2.cmml" xref="S2.SS3.p2.7.m2.1.1.2">ğ’˜</ci><ci id="S2.SS3.p2.7.m2.1.1.3.cmml" xref="S2.SS3.p2.7.m2.1.1.3">ğ‘š</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.7.m2.1c">\boldsymbol{w}_{m}</annotation></semantics></math> represent the parameters of the server and the <math id="S2.SS3.p2.8.m3.1" class="ltx_Math" alttext="m" display="inline"><semantics id="S2.SS3.p2.8.m3.1a"><mi id="S2.SS3.p2.8.m3.1.1" xref="S2.SS3.p2.8.m3.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.8.m3.1b"><ci id="S2.SS3.p2.8.m3.1.1.cmml" xref="S2.SS3.p2.8.m3.1.1">ğ‘š</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.8.m3.1c">m</annotation></semantics></math>-th client respectively, <math id="S2.SS3.p2.9.m4.1" class="ltx_Math" alttext="p(D)" display="inline"><semantics id="S2.SS3.p2.9.m4.1a"><mrow id="S2.SS3.p2.9.m4.1.2" xref="S2.SS3.p2.9.m4.1.2.cmml"><mi id="S2.SS3.p2.9.m4.1.2.2" xref="S2.SS3.p2.9.m4.1.2.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S2.SS3.p2.9.m4.1.2.1" xref="S2.SS3.p2.9.m4.1.2.1.cmml">â€‹</mo><mrow id="S2.SS3.p2.9.m4.1.2.3.2" xref="S2.SS3.p2.9.m4.1.2.cmml"><mo stretchy="false" id="S2.SS3.p2.9.m4.1.2.3.2.1" xref="S2.SS3.p2.9.m4.1.2.cmml">(</mo><mi id="S2.SS3.p2.9.m4.1.1" xref="S2.SS3.p2.9.m4.1.1.cmml">D</mi><mo stretchy="false" id="S2.SS3.p2.9.m4.1.2.3.2.2" xref="S2.SS3.p2.9.m4.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.9.m4.1b"><apply id="S2.SS3.p2.9.m4.1.2.cmml" xref="S2.SS3.p2.9.m4.1.2"><times id="S2.SS3.p2.9.m4.1.2.1.cmml" xref="S2.SS3.p2.9.m4.1.2.1"></times><ci id="S2.SS3.p2.9.m4.1.2.2.cmml" xref="S2.SS3.p2.9.m4.1.2.2">ğ‘</ci><ci id="S2.SS3.p2.9.m4.1.1.cmml" xref="S2.SS3.p2.9.m4.1.1">ğ·</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.9.m4.1c">p(D)</annotation></semantics></math> denotes a normalization constant. In non-personalized BFL, <math id="S2.SS3.p2.10.m5.1" class="ltx_Math" alttext="\boldsymbol{w}_{g}" display="inline"><semantics id="S2.SS3.p2.10.m5.1a"><msub id="S2.SS3.p2.10.m5.1.1" xref="S2.SS3.p2.10.m5.1.1.cmml"><mi id="S2.SS3.p2.10.m5.1.1.2" xref="S2.SS3.p2.10.m5.1.1.2.cmml">ğ’˜</mi><mi id="S2.SS3.p2.10.m5.1.1.3" xref="S2.SS3.p2.10.m5.1.1.3.cmml">g</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.10.m5.1b"><apply id="S2.SS3.p2.10.m5.1.1.cmml" xref="S2.SS3.p2.10.m5.1.1"><csymbol cd="ambiguous" id="S2.SS3.p2.10.m5.1.1.1.cmml" xref="S2.SS3.p2.10.m5.1.1">subscript</csymbol><ci id="S2.SS3.p2.10.m5.1.1.2.cmml" xref="S2.SS3.p2.10.m5.1.1.2">ğ’˜</ci><ci id="S2.SS3.p2.10.m5.1.1.3.cmml" xref="S2.SS3.p2.10.m5.1.1.3">ğ‘”</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.10.m5.1c">\boldsymbol{w}_{g}</annotation></semantics></math> and <math id="S2.SS3.p2.11.m6.1" class="ltx_Math" alttext="\boldsymbol{w}_{m}" display="inline"><semantics id="S2.SS3.p2.11.m6.1a"><msub id="S2.SS3.p2.11.m6.1.1" xref="S2.SS3.p2.11.m6.1.1.cmml"><mi id="S2.SS3.p2.11.m6.1.1.2" xref="S2.SS3.p2.11.m6.1.1.2.cmml">ğ’˜</mi><mi id="S2.SS3.p2.11.m6.1.1.3" xref="S2.SS3.p2.11.m6.1.1.3.cmml">m</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.11.m6.1b"><apply id="S2.SS3.p2.11.m6.1.1.cmml" xref="S2.SS3.p2.11.m6.1.1"><csymbol cd="ambiguous" id="S2.SS3.p2.11.m6.1.1.1.cmml" xref="S2.SS3.p2.11.m6.1.1">subscript</csymbol><ci id="S2.SS3.p2.11.m6.1.1.2.cmml" xref="S2.SS3.p2.11.m6.1.1.2">ğ’˜</ci><ci id="S2.SS3.p2.11.m6.1.1.3.cmml" xref="S2.SS3.p2.11.m6.1.1.3">ğ‘š</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.11.m6.1c">\boldsymbol{w}_{m}</annotation></semantics></math> are equivalent.</p>
</div>
<figure id="S2.F1" class="ltx_figure"><img src="/html/2304.13267/assets/BFL-process-4.png" id="S2.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="479" height="378" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>The framework and iterative learning process of Bayesian federated learning (BFL).</figcaption>
</figure>
<div id="S2.SS3.p3" class="ltx_para">
<p id="S2.SS3.p3.7" class="ltx_p">Accordingly, a BFL model converts the FL objective function Eq. (<a href="#S2.E1" title="In 2.1 Federated Learning and Challenges â€£ 2 From Federated and Bayesian Learning to Bayesian Federated Learning â€£ Bayesian Federated Learning: A Survey" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>) to BFL for a global loss, aligned local losses, or a mixed loss with settings (e.g., privacy or security preservation, or communication efficiency) and regularization:</p>
<table id="S2.E6" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E6.m1.2" class="ltx_math_unparsed" alttext="\operatorname*{arg\,min}_{\boldsymbol{w}_{m},\boldsymbol{w}_{g}}\sum_{m=1}^{M}l(\boldsymbol{w}_{m};D_{m})+\alpha\|\boldsymbol{w}_{m},\boldsymbol{w}_{g}\|." display="block"><semantics id="S2.E6.m1.2a"><mrow id="S2.E6.m1.2b"><munder id="S2.E6.m1.2.3"><mrow id="S2.E6.m1.2.3.2"><mi id="S2.E6.m1.2.3.2.2">arg</mi><mo lspace="0.170em" rspace="0em" id="S2.E6.m1.2.3.2.1">â€‹</mo><mi id="S2.E6.m1.2.3.2.3">min</mi></mrow><mrow id="S2.E6.m1.2.2.2.2"><msub id="S2.E6.m1.1.1.1.1.1"><mi id="S2.E6.m1.1.1.1.1.1.2">ğ’˜</mi><mi id="S2.E6.m1.1.1.1.1.1.3">m</mi></msub><mo id="S2.E6.m1.2.2.2.2.3">,</mo><msub id="S2.E6.m1.2.2.2.2.2"><mi id="S2.E6.m1.2.2.2.2.2.2">ğ’˜</mi><mi id="S2.E6.m1.2.2.2.2.2.3">g</mi></msub></mrow></munder><munderover id="S2.E6.m1.2.4"><mo movablelimits="false" id="S2.E6.m1.2.4.2.2">âˆ‘</mo><mrow id="S2.E6.m1.2.4.2.3"><mi id="S2.E6.m1.2.4.2.3.2">m</mi><mo id="S2.E6.m1.2.4.2.3.1">=</mo><mn id="S2.E6.m1.2.4.2.3.3">1</mn></mrow><mi id="S2.E6.m1.2.4.3">M</mi></munderover><mi id="S2.E6.m1.2.5">l</mi><mrow id="S2.E6.m1.2.6"><mo stretchy="false" id="S2.E6.m1.2.6.1">(</mo><msub id="S2.E6.m1.2.6.2"><mi id="S2.E6.m1.2.6.2.2">ğ’˜</mi><mi id="S2.E6.m1.2.6.2.3">m</mi></msub><mo id="S2.E6.m1.2.6.3">;</mo><msub id="S2.E6.m1.2.6.4"><mi id="S2.E6.m1.2.6.4.2">D</mi><mi id="S2.E6.m1.2.6.4.3">m</mi></msub><mo stretchy="false" id="S2.E6.m1.2.6.5">)</mo></mrow><mo id="S2.E6.m1.2.7">+</mo><mi id="S2.E6.m1.2.8">Î±</mi><mo lspace="0em" rspace="0.167em" id="S2.E6.m1.2.9">âˆ¥</mo><msub id="S2.E6.m1.2.10"><mi id="S2.E6.m1.2.10.2">ğ’˜</mi><mi id="S2.E6.m1.2.10.3">m</mi></msub><mo id="S2.E6.m1.2.11">,</mo><msub id="S2.E6.m1.2.12"><mi id="S2.E6.m1.2.12.2">ğ’˜</mi><mi id="S2.E6.m1.2.12.3">g</mi></msub><mo lspace="0em" rspace="0.0835em" id="S2.E6.m1.2.13">âˆ¥</mo><mo lspace="0.0835em" id="S2.E6.m1.2.14">.</mo></mrow><annotation encoding="application/x-tex" id="S2.E6.m1.2c">\operatorname*{arg\,min}_{\boldsymbol{w}_{m},\boldsymbol{w}_{g}}\sum_{m=1}^{M}l(\boldsymbol{w}_{m};D_{m})+\alpha\|\boldsymbol{w}_{m},\boldsymbol{w}_{g}\|.</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(6)</span></td>
</tr></tbody>
</table>
<p id="S2.SS3.p3.6" class="ltx_p">Then, the posteriors <math id="S2.SS3.p3.1.m1.1" class="ltx_Math" alttext="p(\boldsymbol{w}|D)" display="inline"><semantics id="S2.SS3.p3.1.m1.1a"><mrow id="S2.SS3.p3.1.m1.1.1" xref="S2.SS3.p3.1.m1.1.1.cmml"><mi id="S2.SS3.p3.1.m1.1.1.3" xref="S2.SS3.p3.1.m1.1.1.3.cmml">p</mi><mo lspace="0em" rspace="0em" id="S2.SS3.p3.1.m1.1.1.2" xref="S2.SS3.p3.1.m1.1.1.2.cmml">â€‹</mo><mrow id="S2.SS3.p3.1.m1.1.1.1.1" xref="S2.SS3.p3.1.m1.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.SS3.p3.1.m1.1.1.1.1.2" xref="S2.SS3.p3.1.m1.1.1.1.1.1.cmml">(</mo><mrow id="S2.SS3.p3.1.m1.1.1.1.1.1" xref="S2.SS3.p3.1.m1.1.1.1.1.1.cmml"><mi id="S2.SS3.p3.1.m1.1.1.1.1.1.2" xref="S2.SS3.p3.1.m1.1.1.1.1.1.2.cmml">ğ’˜</mi><mo fence="false" id="S2.SS3.p3.1.m1.1.1.1.1.1.1" xref="S2.SS3.p3.1.m1.1.1.1.1.1.1.cmml">|</mo><mi id="S2.SS3.p3.1.m1.1.1.1.1.1.3" xref="S2.SS3.p3.1.m1.1.1.1.1.1.3.cmml">D</mi></mrow><mo stretchy="false" id="S2.SS3.p3.1.m1.1.1.1.1.3" xref="S2.SS3.p3.1.m1.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p3.1.m1.1b"><apply id="S2.SS3.p3.1.m1.1.1.cmml" xref="S2.SS3.p3.1.m1.1.1"><times id="S2.SS3.p3.1.m1.1.1.2.cmml" xref="S2.SS3.p3.1.m1.1.1.2"></times><ci id="S2.SS3.p3.1.m1.1.1.3.cmml" xref="S2.SS3.p3.1.m1.1.1.3">ğ‘</ci><apply id="S2.SS3.p3.1.m1.1.1.1.1.1.cmml" xref="S2.SS3.p3.1.m1.1.1.1.1"><csymbol cd="latexml" id="S2.SS3.p3.1.m1.1.1.1.1.1.1.cmml" xref="S2.SS3.p3.1.m1.1.1.1.1.1.1">conditional</csymbol><ci id="S2.SS3.p3.1.m1.1.1.1.1.1.2.cmml" xref="S2.SS3.p3.1.m1.1.1.1.1.1.2">ğ’˜</ci><ci id="S2.SS3.p3.1.m1.1.1.1.1.1.3.cmml" xref="S2.SS3.p3.1.m1.1.1.1.1.1.3">ğ·</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p3.1.m1.1c">p(\boldsymbol{w}|D)</annotation></semantics></math> can be approximated by Bayesian optimization, for example, variational inference (VI). Accordingly, Eq. (<a href="#S2.E6" title="In 2.3 BFL: Bayesian Federated Learning â€£ 2 From Federated and Bayesian Learning to Bayesian Federated Learning â€£ Bayesian Federated Learning: A Survey" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>) can be converted to an ELBO-like objective <math id="S2.SS3.p3.2.m2.1" class="ltx_Math" alttext="\mathcal{L}_{D}" display="inline"><semantics id="S2.SS3.p3.2.m2.1a"><msub id="S2.SS3.p3.2.m2.1.1" xref="S2.SS3.p3.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS3.p3.2.m2.1.1.2" xref="S2.SS3.p3.2.m2.1.1.2.cmml">â„’</mi><mi id="S2.SS3.p3.2.m2.1.1.3" xref="S2.SS3.p3.2.m2.1.1.3.cmml">D</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS3.p3.2.m2.1b"><apply id="S2.SS3.p3.2.m2.1.1.cmml" xref="S2.SS3.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S2.SS3.p3.2.m2.1.1.1.cmml" xref="S2.SS3.p3.2.m2.1.1">subscript</csymbol><ci id="S2.SS3.p3.2.m2.1.1.2.cmml" xref="S2.SS3.p3.2.m2.1.1.2">â„’</ci><ci id="S2.SS3.p3.2.m2.1.1.3.cmml" xref="S2.SS3.p3.2.m2.1.1.3">ğ·</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p3.2.m2.1c">\mathcal{L}_{D}</annotation></semantics></math>, the true posterior <math id="S2.SS3.p3.3.m3.2" class="ltx_Math" alttext="p(\boldsymbol{w}_{m},\boldsymbol{w}_{g}|D)" display="inline"><semantics id="S2.SS3.p3.3.m3.2a"><mrow id="S2.SS3.p3.3.m3.2.2" xref="S2.SS3.p3.3.m3.2.2.cmml"><mi id="S2.SS3.p3.3.m3.2.2.4" xref="S2.SS3.p3.3.m3.2.2.4.cmml">p</mi><mo lspace="0em" rspace="0em" id="S2.SS3.p3.3.m3.2.2.3" xref="S2.SS3.p3.3.m3.2.2.3.cmml">â€‹</mo><mrow id="S2.SS3.p3.3.m3.2.2.2.2" xref="S2.SS3.p3.3.m3.2.2.2.3.cmml"><mo stretchy="false" id="S2.SS3.p3.3.m3.2.2.2.2.3" xref="S2.SS3.p3.3.m3.2.2.2.3.cmml">(</mo><msub id="S2.SS3.p3.3.m3.1.1.1.1.1" xref="S2.SS3.p3.3.m3.1.1.1.1.1.cmml"><mi id="S2.SS3.p3.3.m3.1.1.1.1.1.2" xref="S2.SS3.p3.3.m3.1.1.1.1.1.2.cmml">ğ’˜</mi><mi id="S2.SS3.p3.3.m3.1.1.1.1.1.3" xref="S2.SS3.p3.3.m3.1.1.1.1.1.3.cmml">m</mi></msub><mo id="S2.SS3.p3.3.m3.2.2.2.2.4" xref="S2.SS3.p3.3.m3.2.2.2.3.cmml">,</mo><mrow id="S2.SS3.p3.3.m3.2.2.2.2.2" xref="S2.SS3.p3.3.m3.2.2.2.2.2.cmml"><msub id="S2.SS3.p3.3.m3.2.2.2.2.2.2" xref="S2.SS3.p3.3.m3.2.2.2.2.2.2.cmml"><mi id="S2.SS3.p3.3.m3.2.2.2.2.2.2.2" xref="S2.SS3.p3.3.m3.2.2.2.2.2.2.2.cmml">ğ’˜</mi><mi id="S2.SS3.p3.3.m3.2.2.2.2.2.2.3" xref="S2.SS3.p3.3.m3.2.2.2.2.2.2.3.cmml">g</mi></msub><mo fence="false" id="S2.SS3.p3.3.m3.2.2.2.2.2.1" xref="S2.SS3.p3.3.m3.2.2.2.2.2.1.cmml">|</mo><mi id="S2.SS3.p3.3.m3.2.2.2.2.2.3" xref="S2.SS3.p3.3.m3.2.2.2.2.2.3.cmml">D</mi></mrow><mo stretchy="false" id="S2.SS3.p3.3.m3.2.2.2.2.5" xref="S2.SS3.p3.3.m3.2.2.2.3.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p3.3.m3.2b"><apply id="S2.SS3.p3.3.m3.2.2.cmml" xref="S2.SS3.p3.3.m3.2.2"><times id="S2.SS3.p3.3.m3.2.2.3.cmml" xref="S2.SS3.p3.3.m3.2.2.3"></times><ci id="S2.SS3.p3.3.m3.2.2.4.cmml" xref="S2.SS3.p3.3.m3.2.2.4">ğ‘</ci><interval closure="open" id="S2.SS3.p3.3.m3.2.2.2.3.cmml" xref="S2.SS3.p3.3.m3.2.2.2.2"><apply id="S2.SS3.p3.3.m3.1.1.1.1.1.cmml" xref="S2.SS3.p3.3.m3.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.SS3.p3.3.m3.1.1.1.1.1.1.cmml" xref="S2.SS3.p3.3.m3.1.1.1.1.1">subscript</csymbol><ci id="S2.SS3.p3.3.m3.1.1.1.1.1.2.cmml" xref="S2.SS3.p3.3.m3.1.1.1.1.1.2">ğ’˜</ci><ci id="S2.SS3.p3.3.m3.1.1.1.1.1.3.cmml" xref="S2.SS3.p3.3.m3.1.1.1.1.1.3">ğ‘š</ci></apply><apply id="S2.SS3.p3.3.m3.2.2.2.2.2.cmml" xref="S2.SS3.p3.3.m3.2.2.2.2.2"><csymbol cd="latexml" id="S2.SS3.p3.3.m3.2.2.2.2.2.1.cmml" xref="S2.SS3.p3.3.m3.2.2.2.2.2.1">conditional</csymbol><apply id="S2.SS3.p3.3.m3.2.2.2.2.2.2.cmml" xref="S2.SS3.p3.3.m3.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S2.SS3.p3.3.m3.2.2.2.2.2.2.1.cmml" xref="S2.SS3.p3.3.m3.2.2.2.2.2.2">subscript</csymbol><ci id="S2.SS3.p3.3.m3.2.2.2.2.2.2.2.cmml" xref="S2.SS3.p3.3.m3.2.2.2.2.2.2.2">ğ’˜</ci><ci id="S2.SS3.p3.3.m3.2.2.2.2.2.2.3.cmml" xref="S2.SS3.p3.3.m3.2.2.2.2.2.2.3">ğ‘”</ci></apply><ci id="S2.SS3.p3.3.m3.2.2.2.2.2.3.cmml" xref="S2.SS3.p3.3.m3.2.2.2.2.2.3">ğ·</ci></apply></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p3.3.m3.2c">p(\boldsymbol{w}_{m},\boldsymbol{w}_{g}|D)</annotation></semantics></math> is approximated by a variational distribution <math id="S2.SS3.p3.4.m4.2" class="ltx_Math" alttext="q_{\theta}(\boldsymbol{w}_{m},\boldsymbol{w}_{g})" display="inline"><semantics id="S2.SS3.p3.4.m4.2a"><mrow id="S2.SS3.p3.4.m4.2.2" xref="S2.SS3.p3.4.m4.2.2.cmml"><msub id="S2.SS3.p3.4.m4.2.2.4" xref="S2.SS3.p3.4.m4.2.2.4.cmml"><mi id="S2.SS3.p3.4.m4.2.2.4.2" xref="S2.SS3.p3.4.m4.2.2.4.2.cmml">q</mi><mi id="S2.SS3.p3.4.m4.2.2.4.3" xref="S2.SS3.p3.4.m4.2.2.4.3.cmml">Î¸</mi></msub><mo lspace="0em" rspace="0em" id="S2.SS3.p3.4.m4.2.2.3" xref="S2.SS3.p3.4.m4.2.2.3.cmml">â€‹</mo><mrow id="S2.SS3.p3.4.m4.2.2.2.2" xref="S2.SS3.p3.4.m4.2.2.2.3.cmml"><mo stretchy="false" id="S2.SS3.p3.4.m4.2.2.2.2.3" xref="S2.SS3.p3.4.m4.2.2.2.3.cmml">(</mo><msub id="S2.SS3.p3.4.m4.1.1.1.1.1" xref="S2.SS3.p3.4.m4.1.1.1.1.1.cmml"><mi id="S2.SS3.p3.4.m4.1.1.1.1.1.2" xref="S2.SS3.p3.4.m4.1.1.1.1.1.2.cmml">ğ’˜</mi><mi id="S2.SS3.p3.4.m4.1.1.1.1.1.3" xref="S2.SS3.p3.4.m4.1.1.1.1.1.3.cmml">m</mi></msub><mo id="S2.SS3.p3.4.m4.2.2.2.2.4" xref="S2.SS3.p3.4.m4.2.2.2.3.cmml">,</mo><msub id="S2.SS3.p3.4.m4.2.2.2.2.2" xref="S2.SS3.p3.4.m4.2.2.2.2.2.cmml"><mi id="S2.SS3.p3.4.m4.2.2.2.2.2.2" xref="S2.SS3.p3.4.m4.2.2.2.2.2.2.cmml">ğ’˜</mi><mi id="S2.SS3.p3.4.m4.2.2.2.2.2.3" xref="S2.SS3.p3.4.m4.2.2.2.2.2.3.cmml">g</mi></msub><mo stretchy="false" id="S2.SS3.p3.4.m4.2.2.2.2.5" xref="S2.SS3.p3.4.m4.2.2.2.3.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p3.4.m4.2b"><apply id="S2.SS3.p3.4.m4.2.2.cmml" xref="S2.SS3.p3.4.m4.2.2"><times id="S2.SS3.p3.4.m4.2.2.3.cmml" xref="S2.SS3.p3.4.m4.2.2.3"></times><apply id="S2.SS3.p3.4.m4.2.2.4.cmml" xref="S2.SS3.p3.4.m4.2.2.4"><csymbol cd="ambiguous" id="S2.SS3.p3.4.m4.2.2.4.1.cmml" xref="S2.SS3.p3.4.m4.2.2.4">subscript</csymbol><ci id="S2.SS3.p3.4.m4.2.2.4.2.cmml" xref="S2.SS3.p3.4.m4.2.2.4.2">ğ‘</ci><ci id="S2.SS3.p3.4.m4.2.2.4.3.cmml" xref="S2.SS3.p3.4.m4.2.2.4.3">ğœƒ</ci></apply><interval closure="open" id="S2.SS3.p3.4.m4.2.2.2.3.cmml" xref="S2.SS3.p3.4.m4.2.2.2.2"><apply id="S2.SS3.p3.4.m4.1.1.1.1.1.cmml" xref="S2.SS3.p3.4.m4.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.SS3.p3.4.m4.1.1.1.1.1.1.cmml" xref="S2.SS3.p3.4.m4.1.1.1.1.1">subscript</csymbol><ci id="S2.SS3.p3.4.m4.1.1.1.1.1.2.cmml" xref="S2.SS3.p3.4.m4.1.1.1.1.1.2">ğ’˜</ci><ci id="S2.SS3.p3.4.m4.1.1.1.1.1.3.cmml" xref="S2.SS3.p3.4.m4.1.1.1.1.1.3">ğ‘š</ci></apply><apply id="S2.SS3.p3.4.m4.2.2.2.2.2.cmml" xref="S2.SS3.p3.4.m4.2.2.2.2.2"><csymbol cd="ambiguous" id="S2.SS3.p3.4.m4.2.2.2.2.2.1.cmml" xref="S2.SS3.p3.4.m4.2.2.2.2.2">subscript</csymbol><ci id="S2.SS3.p3.4.m4.2.2.2.2.2.2.cmml" xref="S2.SS3.p3.4.m4.2.2.2.2.2.2">ğ’˜</ci><ci id="S2.SS3.p3.4.m4.2.2.2.2.2.3.cmml" xref="S2.SS3.p3.4.m4.2.2.2.2.2.3">ğ‘”</ci></apply></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p3.4.m4.2c">q_{\theta}(\boldsymbol{w}_{m},\boldsymbol{w}_{g})</annotation></semantics></math> estimated on the evidence <math id="S2.SS3.p3.5.m5.1" class="ltx_Math" alttext="D" display="inline"><semantics id="S2.SS3.p3.5.m5.1a"><mi id="S2.SS3.p3.5.m5.1.1" xref="S2.SS3.p3.5.m5.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.p3.5.m5.1b"><ci id="S2.SS3.p3.5.m5.1.1.cmml" xref="S2.SS3.p3.5.m5.1.1">ğ·</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p3.5.m5.1c">D</annotation></semantics></math> with parameters <math id="S2.SS3.p3.6.m6.1" class="ltx_Math" alttext="\theta" display="inline"><semantics id="S2.SS3.p3.6.m6.1a"><mi id="S2.SS3.p3.6.m6.1.1" xref="S2.SS3.p3.6.m6.1.1.cmml">Î¸</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.p3.6.m6.1b"><ci id="S2.SS3.p3.6.m6.1.1.cmml" xref="S2.SS3.p3.6.m6.1.1">ğœƒ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p3.6.m6.1c">\theta</annotation></semantics></math>:</p>
<table id="S2.E7" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E7.m1.4" class="ltx_Math" alttext="\operatorname*{arg\,min}_{\boldsymbol{w}_{m},q_{\theta}(\boldsymbol{w}_{m})}KL(q_{\theta}(\boldsymbol{w}_{m})\|p(\boldsymbol{w}_{m}))-\mathbb{E}_{q_{\theta}(\boldsymbol{w}_{m})}[\log p(D_{m}|\boldsymbol{w}_{m})]." display="block"><semantics id="S2.E7.m1.4a"><mrow id="S2.E7.m1.4.4.1" xref="S2.E7.m1.4.4.1.1.cmml"><mrow id="S2.E7.m1.4.4.1.1" xref="S2.E7.m1.4.4.1.1.cmml"><mrow id="S2.E7.m1.4.4.1.1.1" xref="S2.E7.m1.4.4.1.1.1.cmml"><mrow id="S2.E7.m1.4.4.1.1.1.3" xref="S2.E7.m1.4.4.1.1.1.3.cmml"><munder id="S2.E7.m1.4.4.1.1.1.3.1" xref="S2.E7.m1.4.4.1.1.1.3.1.cmml"><mrow id="S2.E7.m1.4.4.1.1.1.3.1.2" xref="S2.E7.m1.4.4.1.1.1.3.1.2.cmml"><mi id="S2.E7.m1.4.4.1.1.1.3.1.2.2" xref="S2.E7.m1.4.4.1.1.1.3.1.2.2.cmml">arg</mi><mo lspace="0.170em" rspace="0em" id="S2.E7.m1.4.4.1.1.1.3.1.2.1" xref="S2.E7.m1.4.4.1.1.1.3.1.2.1.cmml">â€‹</mo><mi id="S2.E7.m1.4.4.1.1.1.3.1.2.3" xref="S2.E7.m1.4.4.1.1.1.3.1.2.3.cmml">min</mi></mrow><mrow id="S2.E7.m1.2.2.2.2" xref="S2.E7.m1.2.2.2.3.cmml"><msub id="S2.E7.m1.1.1.1.1.1" xref="S2.E7.m1.1.1.1.1.1.cmml"><mi id="S2.E7.m1.1.1.1.1.1.2" xref="S2.E7.m1.1.1.1.1.1.2.cmml">ğ’˜</mi><mi id="S2.E7.m1.1.1.1.1.1.3" xref="S2.E7.m1.1.1.1.1.1.3.cmml">m</mi></msub><mo id="S2.E7.m1.2.2.2.2.3" xref="S2.E7.m1.2.2.2.3.cmml">,</mo><mrow id="S2.E7.m1.2.2.2.2.2" xref="S2.E7.m1.2.2.2.2.2.cmml"><msub id="S2.E7.m1.2.2.2.2.2.3" xref="S2.E7.m1.2.2.2.2.2.3.cmml"><mi id="S2.E7.m1.2.2.2.2.2.3.2" xref="S2.E7.m1.2.2.2.2.2.3.2.cmml">q</mi><mi id="S2.E7.m1.2.2.2.2.2.3.3" xref="S2.E7.m1.2.2.2.2.2.3.3.cmml">Î¸</mi></msub><mo lspace="0em" rspace="0em" id="S2.E7.m1.2.2.2.2.2.2" xref="S2.E7.m1.2.2.2.2.2.2.cmml">â€‹</mo><mrow id="S2.E7.m1.2.2.2.2.2.1.1" xref="S2.E7.m1.2.2.2.2.2.1.1.1.cmml"><mo stretchy="false" id="S2.E7.m1.2.2.2.2.2.1.1.2" xref="S2.E7.m1.2.2.2.2.2.1.1.1.cmml">(</mo><msub id="S2.E7.m1.2.2.2.2.2.1.1.1" xref="S2.E7.m1.2.2.2.2.2.1.1.1.cmml"><mi id="S2.E7.m1.2.2.2.2.2.1.1.1.2" xref="S2.E7.m1.2.2.2.2.2.1.1.1.2.cmml">ğ’˜</mi><mi id="S2.E7.m1.2.2.2.2.2.1.1.1.3" xref="S2.E7.m1.2.2.2.2.2.1.1.1.3.cmml">m</mi></msub><mo stretchy="false" id="S2.E7.m1.2.2.2.2.2.1.1.3" xref="S2.E7.m1.2.2.2.2.2.1.1.1.cmml">)</mo></mrow></mrow></mrow></munder><mo lspace="0.167em" id="S2.E7.m1.4.4.1.1.1.3a" xref="S2.E7.m1.4.4.1.1.1.3.cmml">â¡</mo><mrow id="S2.E7.m1.4.4.1.1.1.3.2" xref="S2.E7.m1.4.4.1.1.1.3.2.cmml"><mi id="S2.E7.m1.4.4.1.1.1.3.2.2" xref="S2.E7.m1.4.4.1.1.1.3.2.2.cmml">K</mi><mo lspace="0em" rspace="0em" id="S2.E7.m1.4.4.1.1.1.3.2.1" xref="S2.E7.m1.4.4.1.1.1.3.2.1.cmml">â€‹</mo><mi id="S2.E7.m1.4.4.1.1.1.3.2.3" xref="S2.E7.m1.4.4.1.1.1.3.2.3.cmml">L</mi></mrow></mrow><mo lspace="0em" rspace="0em" id="S2.E7.m1.4.4.1.1.1.2" xref="S2.E7.m1.4.4.1.1.1.2.cmml">â€‹</mo><mrow id="S2.E7.m1.4.4.1.1.1.1.1" xref="S2.E7.m1.4.4.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.E7.m1.4.4.1.1.1.1.1.2" xref="S2.E7.m1.4.4.1.1.1.1.1.1.cmml">(</mo><mrow id="S2.E7.m1.4.4.1.1.1.1.1.1" xref="S2.E7.m1.4.4.1.1.1.1.1.1.cmml"><mrow id="S2.E7.m1.4.4.1.1.1.1.1.1.1" xref="S2.E7.m1.4.4.1.1.1.1.1.1.1.cmml"><msub id="S2.E7.m1.4.4.1.1.1.1.1.1.1.3" xref="S2.E7.m1.4.4.1.1.1.1.1.1.1.3.cmml"><mi id="S2.E7.m1.4.4.1.1.1.1.1.1.1.3.2" xref="S2.E7.m1.4.4.1.1.1.1.1.1.1.3.2.cmml">q</mi><mi id="S2.E7.m1.4.4.1.1.1.1.1.1.1.3.3" xref="S2.E7.m1.4.4.1.1.1.1.1.1.1.3.3.cmml">Î¸</mi></msub><mo lspace="0em" rspace="0em" id="S2.E7.m1.4.4.1.1.1.1.1.1.1.2" xref="S2.E7.m1.4.4.1.1.1.1.1.1.1.2.cmml">â€‹</mo><mrow id="S2.E7.m1.4.4.1.1.1.1.1.1.1.1.1" xref="S2.E7.m1.4.4.1.1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.E7.m1.4.4.1.1.1.1.1.1.1.1.1.2" xref="S2.E7.m1.4.4.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><msub id="S2.E7.m1.4.4.1.1.1.1.1.1.1.1.1.1" xref="S2.E7.m1.4.4.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S2.E7.m1.4.4.1.1.1.1.1.1.1.1.1.1.2" xref="S2.E7.m1.4.4.1.1.1.1.1.1.1.1.1.1.2.cmml">ğ’˜</mi><mi id="S2.E7.m1.4.4.1.1.1.1.1.1.1.1.1.1.3" xref="S2.E7.m1.4.4.1.1.1.1.1.1.1.1.1.1.3.cmml">m</mi></msub><mo stretchy="false" id="S2.E7.m1.4.4.1.1.1.1.1.1.1.1.1.3" xref="S2.E7.m1.4.4.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S2.E7.m1.4.4.1.1.1.1.1.1.3" xref="S2.E7.m1.4.4.1.1.1.1.1.1.3.cmml">âˆ¥</mo><mrow id="S2.E7.m1.4.4.1.1.1.1.1.1.2" xref="S2.E7.m1.4.4.1.1.1.1.1.1.2.cmml"><mi id="S2.E7.m1.4.4.1.1.1.1.1.1.2.3" xref="S2.E7.m1.4.4.1.1.1.1.1.1.2.3.cmml">p</mi><mo lspace="0em" rspace="0em" id="S2.E7.m1.4.4.1.1.1.1.1.1.2.2" xref="S2.E7.m1.4.4.1.1.1.1.1.1.2.2.cmml">â€‹</mo><mrow id="S2.E7.m1.4.4.1.1.1.1.1.1.2.1.1" xref="S2.E7.m1.4.4.1.1.1.1.1.1.2.1.1.1.cmml"><mo stretchy="false" id="S2.E7.m1.4.4.1.1.1.1.1.1.2.1.1.2" xref="S2.E7.m1.4.4.1.1.1.1.1.1.2.1.1.1.cmml">(</mo><msub id="S2.E7.m1.4.4.1.1.1.1.1.1.2.1.1.1" xref="S2.E7.m1.4.4.1.1.1.1.1.1.2.1.1.1.cmml"><mi id="S2.E7.m1.4.4.1.1.1.1.1.1.2.1.1.1.2" xref="S2.E7.m1.4.4.1.1.1.1.1.1.2.1.1.1.2.cmml">ğ’˜</mi><mi id="S2.E7.m1.4.4.1.1.1.1.1.1.2.1.1.1.3" xref="S2.E7.m1.4.4.1.1.1.1.1.1.2.1.1.1.3.cmml">m</mi></msub><mo stretchy="false" id="S2.E7.m1.4.4.1.1.1.1.1.1.2.1.1.3" xref="S2.E7.m1.4.4.1.1.1.1.1.1.2.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo stretchy="false" id="S2.E7.m1.4.4.1.1.1.1.1.3" xref="S2.E7.m1.4.4.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S2.E7.m1.4.4.1.1.3" xref="S2.E7.m1.4.4.1.1.3.cmml">âˆ’</mo><mrow id="S2.E7.m1.4.4.1.1.2" xref="S2.E7.m1.4.4.1.1.2.cmml"><msub id="S2.E7.m1.4.4.1.1.2.3" xref="S2.E7.m1.4.4.1.1.2.3.cmml"><mi id="S2.E7.m1.4.4.1.1.2.3.2" xref="S2.E7.m1.4.4.1.1.2.3.2.cmml">ğ”¼</mi><mrow id="S2.E7.m1.3.3.1" xref="S2.E7.m1.3.3.1.cmml"><msub id="S2.E7.m1.3.3.1.3" xref="S2.E7.m1.3.3.1.3.cmml"><mi id="S2.E7.m1.3.3.1.3.2" xref="S2.E7.m1.3.3.1.3.2.cmml">q</mi><mi id="S2.E7.m1.3.3.1.3.3" xref="S2.E7.m1.3.3.1.3.3.cmml">Î¸</mi></msub><mo lspace="0em" rspace="0em" id="S2.E7.m1.3.3.1.2" xref="S2.E7.m1.3.3.1.2.cmml">â€‹</mo><mrow id="S2.E7.m1.3.3.1.1.1" xref="S2.E7.m1.3.3.1.1.1.1.cmml"><mo stretchy="false" id="S2.E7.m1.3.3.1.1.1.2" xref="S2.E7.m1.3.3.1.1.1.1.cmml">(</mo><msub id="S2.E7.m1.3.3.1.1.1.1" xref="S2.E7.m1.3.3.1.1.1.1.cmml"><mi id="S2.E7.m1.3.3.1.1.1.1.2" xref="S2.E7.m1.3.3.1.1.1.1.2.cmml">ğ’˜</mi><mi id="S2.E7.m1.3.3.1.1.1.1.3" xref="S2.E7.m1.3.3.1.1.1.1.3.cmml">m</mi></msub><mo stretchy="false" id="S2.E7.m1.3.3.1.1.1.3" xref="S2.E7.m1.3.3.1.1.1.1.cmml">)</mo></mrow></mrow></msub><mo lspace="0em" rspace="0em" id="S2.E7.m1.4.4.1.1.2.2" xref="S2.E7.m1.4.4.1.1.2.2.cmml">â€‹</mo><mrow id="S2.E7.m1.4.4.1.1.2.1.1" xref="S2.E7.m1.4.4.1.1.2.1.2.cmml"><mo stretchy="false" id="S2.E7.m1.4.4.1.1.2.1.1.2" xref="S2.E7.m1.4.4.1.1.2.1.2.1.cmml">[</mo><mrow id="S2.E7.m1.4.4.1.1.2.1.1.1" xref="S2.E7.m1.4.4.1.1.2.1.1.1.cmml"><mrow id="S2.E7.m1.4.4.1.1.2.1.1.1.3" xref="S2.E7.m1.4.4.1.1.2.1.1.1.3.cmml"><mi id="S2.E7.m1.4.4.1.1.2.1.1.1.3.1" xref="S2.E7.m1.4.4.1.1.2.1.1.1.3.1.cmml">log</mi><mo lspace="0.167em" id="S2.E7.m1.4.4.1.1.2.1.1.1.3a" xref="S2.E7.m1.4.4.1.1.2.1.1.1.3.cmml">â¡</mo><mi id="S2.E7.m1.4.4.1.1.2.1.1.1.3.2" xref="S2.E7.m1.4.4.1.1.2.1.1.1.3.2.cmml">p</mi></mrow><mo lspace="0em" rspace="0em" id="S2.E7.m1.4.4.1.1.2.1.1.1.2" xref="S2.E7.m1.4.4.1.1.2.1.1.1.2.cmml">â€‹</mo><mrow id="S2.E7.m1.4.4.1.1.2.1.1.1.1.1" xref="S2.E7.m1.4.4.1.1.2.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.E7.m1.4.4.1.1.2.1.1.1.1.1.2" xref="S2.E7.m1.4.4.1.1.2.1.1.1.1.1.1.cmml">(</mo><mrow id="S2.E7.m1.4.4.1.1.2.1.1.1.1.1.1" xref="S2.E7.m1.4.4.1.1.2.1.1.1.1.1.1.cmml"><msub id="S2.E7.m1.4.4.1.1.2.1.1.1.1.1.1.2" xref="S2.E7.m1.4.4.1.1.2.1.1.1.1.1.1.2.cmml"><mi id="S2.E7.m1.4.4.1.1.2.1.1.1.1.1.1.2.2" xref="S2.E7.m1.4.4.1.1.2.1.1.1.1.1.1.2.2.cmml">D</mi><mi id="S2.E7.m1.4.4.1.1.2.1.1.1.1.1.1.2.3" xref="S2.E7.m1.4.4.1.1.2.1.1.1.1.1.1.2.3.cmml">m</mi></msub><mo fence="false" id="S2.E7.m1.4.4.1.1.2.1.1.1.1.1.1.1" xref="S2.E7.m1.4.4.1.1.2.1.1.1.1.1.1.1.cmml">|</mo><msub id="S2.E7.m1.4.4.1.1.2.1.1.1.1.1.1.3" xref="S2.E7.m1.4.4.1.1.2.1.1.1.1.1.1.3.cmml"><mi id="S2.E7.m1.4.4.1.1.2.1.1.1.1.1.1.3.2" xref="S2.E7.m1.4.4.1.1.2.1.1.1.1.1.1.3.2.cmml">ğ’˜</mi><mi id="S2.E7.m1.4.4.1.1.2.1.1.1.1.1.1.3.3" xref="S2.E7.m1.4.4.1.1.2.1.1.1.1.1.1.3.3.cmml">m</mi></msub></mrow><mo stretchy="false" id="S2.E7.m1.4.4.1.1.2.1.1.1.1.1.3" xref="S2.E7.m1.4.4.1.1.2.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S2.E7.m1.4.4.1.1.2.1.1.3" xref="S2.E7.m1.4.4.1.1.2.1.2.1.cmml">]</mo></mrow></mrow></mrow><mo lspace="0em" id="S2.E7.m1.4.4.1.2" xref="S2.E7.m1.4.4.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.E7.m1.4b"><apply id="S2.E7.m1.4.4.1.1.cmml" xref="S2.E7.m1.4.4.1"><minus id="S2.E7.m1.4.4.1.1.3.cmml" xref="S2.E7.m1.4.4.1.1.3"></minus><apply id="S2.E7.m1.4.4.1.1.1.cmml" xref="S2.E7.m1.4.4.1.1.1"><times id="S2.E7.m1.4.4.1.1.1.2.cmml" xref="S2.E7.m1.4.4.1.1.1.2"></times><apply id="S2.E7.m1.4.4.1.1.1.3.cmml" xref="S2.E7.m1.4.4.1.1.1.3"><apply id="S2.E7.m1.4.4.1.1.1.3.1.cmml" xref="S2.E7.m1.4.4.1.1.1.3.1"><csymbol cd="ambiguous" id="S2.E7.m1.4.4.1.1.1.3.1.1.cmml" xref="S2.E7.m1.4.4.1.1.1.3.1">subscript</csymbol><apply id="S2.E7.m1.4.4.1.1.1.3.1.2.cmml" xref="S2.E7.m1.4.4.1.1.1.3.1.2"><times id="S2.E7.m1.4.4.1.1.1.3.1.2.1.cmml" xref="S2.E7.m1.4.4.1.1.1.3.1.2.1"></times><ci id="S2.E7.m1.4.4.1.1.1.3.1.2.2.cmml" xref="S2.E7.m1.4.4.1.1.1.3.1.2.2">arg</ci><ci id="S2.E7.m1.4.4.1.1.1.3.1.2.3.cmml" xref="S2.E7.m1.4.4.1.1.1.3.1.2.3">min</ci></apply><list id="S2.E7.m1.2.2.2.3.cmml" xref="S2.E7.m1.2.2.2.2"><apply id="S2.E7.m1.1.1.1.1.1.cmml" xref="S2.E7.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E7.m1.1.1.1.1.1.1.cmml" xref="S2.E7.m1.1.1.1.1.1">subscript</csymbol><ci id="S2.E7.m1.1.1.1.1.1.2.cmml" xref="S2.E7.m1.1.1.1.1.1.2">ğ’˜</ci><ci id="S2.E7.m1.1.1.1.1.1.3.cmml" xref="S2.E7.m1.1.1.1.1.1.3">ğ‘š</ci></apply><apply id="S2.E7.m1.2.2.2.2.2.cmml" xref="S2.E7.m1.2.2.2.2.2"><times id="S2.E7.m1.2.2.2.2.2.2.cmml" xref="S2.E7.m1.2.2.2.2.2.2"></times><apply id="S2.E7.m1.2.2.2.2.2.3.cmml" xref="S2.E7.m1.2.2.2.2.2.3"><csymbol cd="ambiguous" id="S2.E7.m1.2.2.2.2.2.3.1.cmml" xref="S2.E7.m1.2.2.2.2.2.3">subscript</csymbol><ci id="S2.E7.m1.2.2.2.2.2.3.2.cmml" xref="S2.E7.m1.2.2.2.2.2.3.2">ğ‘</ci><ci id="S2.E7.m1.2.2.2.2.2.3.3.cmml" xref="S2.E7.m1.2.2.2.2.2.3.3">ğœƒ</ci></apply><apply id="S2.E7.m1.2.2.2.2.2.1.1.1.cmml" xref="S2.E7.m1.2.2.2.2.2.1.1"><csymbol cd="ambiguous" id="S2.E7.m1.2.2.2.2.2.1.1.1.1.cmml" xref="S2.E7.m1.2.2.2.2.2.1.1">subscript</csymbol><ci id="S2.E7.m1.2.2.2.2.2.1.1.1.2.cmml" xref="S2.E7.m1.2.2.2.2.2.1.1.1.2">ğ’˜</ci><ci id="S2.E7.m1.2.2.2.2.2.1.1.1.3.cmml" xref="S2.E7.m1.2.2.2.2.2.1.1.1.3">ğ‘š</ci></apply></apply></list></apply><apply id="S2.E7.m1.4.4.1.1.1.3.2.cmml" xref="S2.E7.m1.4.4.1.1.1.3.2"><times id="S2.E7.m1.4.4.1.1.1.3.2.1.cmml" xref="S2.E7.m1.4.4.1.1.1.3.2.1"></times><ci id="S2.E7.m1.4.4.1.1.1.3.2.2.cmml" xref="S2.E7.m1.4.4.1.1.1.3.2.2">ğ¾</ci><ci id="S2.E7.m1.4.4.1.1.1.3.2.3.cmml" xref="S2.E7.m1.4.4.1.1.1.3.2.3">ğ¿</ci></apply></apply><apply id="S2.E7.m1.4.4.1.1.1.1.1.1.cmml" xref="S2.E7.m1.4.4.1.1.1.1.1"><csymbol cd="latexml" id="S2.E7.m1.4.4.1.1.1.1.1.1.3.cmml" xref="S2.E7.m1.4.4.1.1.1.1.1.1.3">conditional</csymbol><apply id="S2.E7.m1.4.4.1.1.1.1.1.1.1.cmml" xref="S2.E7.m1.4.4.1.1.1.1.1.1.1"><times id="S2.E7.m1.4.4.1.1.1.1.1.1.1.2.cmml" xref="S2.E7.m1.4.4.1.1.1.1.1.1.1.2"></times><apply id="S2.E7.m1.4.4.1.1.1.1.1.1.1.3.cmml" xref="S2.E7.m1.4.4.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.E7.m1.4.4.1.1.1.1.1.1.1.3.1.cmml" xref="S2.E7.m1.4.4.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S2.E7.m1.4.4.1.1.1.1.1.1.1.3.2.cmml" xref="S2.E7.m1.4.4.1.1.1.1.1.1.1.3.2">ğ‘</ci><ci id="S2.E7.m1.4.4.1.1.1.1.1.1.1.3.3.cmml" xref="S2.E7.m1.4.4.1.1.1.1.1.1.1.3.3">ğœƒ</ci></apply><apply id="S2.E7.m1.4.4.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E7.m1.4.4.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E7.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E7.m1.4.4.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S2.E7.m1.4.4.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E7.m1.4.4.1.1.1.1.1.1.1.1.1.1.2">ğ’˜</ci><ci id="S2.E7.m1.4.4.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S2.E7.m1.4.4.1.1.1.1.1.1.1.1.1.1.3">ğ‘š</ci></apply></apply><apply id="S2.E7.m1.4.4.1.1.1.1.1.1.2.cmml" xref="S2.E7.m1.4.4.1.1.1.1.1.1.2"><times id="S2.E7.m1.4.4.1.1.1.1.1.1.2.2.cmml" xref="S2.E7.m1.4.4.1.1.1.1.1.1.2.2"></times><ci id="S2.E7.m1.4.4.1.1.1.1.1.1.2.3.cmml" xref="S2.E7.m1.4.4.1.1.1.1.1.1.2.3">ğ‘</ci><apply id="S2.E7.m1.4.4.1.1.1.1.1.1.2.1.1.1.cmml" xref="S2.E7.m1.4.4.1.1.1.1.1.1.2.1.1"><csymbol cd="ambiguous" id="S2.E7.m1.4.4.1.1.1.1.1.1.2.1.1.1.1.cmml" xref="S2.E7.m1.4.4.1.1.1.1.1.1.2.1.1">subscript</csymbol><ci id="S2.E7.m1.4.4.1.1.1.1.1.1.2.1.1.1.2.cmml" xref="S2.E7.m1.4.4.1.1.1.1.1.1.2.1.1.1.2">ğ’˜</ci><ci id="S2.E7.m1.4.4.1.1.1.1.1.1.2.1.1.1.3.cmml" xref="S2.E7.m1.4.4.1.1.1.1.1.1.2.1.1.1.3">ğ‘š</ci></apply></apply></apply></apply><apply id="S2.E7.m1.4.4.1.1.2.cmml" xref="S2.E7.m1.4.4.1.1.2"><times id="S2.E7.m1.4.4.1.1.2.2.cmml" xref="S2.E7.m1.4.4.1.1.2.2"></times><apply id="S2.E7.m1.4.4.1.1.2.3.cmml" xref="S2.E7.m1.4.4.1.1.2.3"><csymbol cd="ambiguous" id="S2.E7.m1.4.4.1.1.2.3.1.cmml" xref="S2.E7.m1.4.4.1.1.2.3">subscript</csymbol><ci id="S2.E7.m1.4.4.1.1.2.3.2.cmml" xref="S2.E7.m1.4.4.1.1.2.3.2">ğ”¼</ci><apply id="S2.E7.m1.3.3.1.cmml" xref="S2.E7.m1.3.3.1"><times id="S2.E7.m1.3.3.1.2.cmml" xref="S2.E7.m1.3.3.1.2"></times><apply id="S2.E7.m1.3.3.1.3.cmml" xref="S2.E7.m1.3.3.1.3"><csymbol cd="ambiguous" id="S2.E7.m1.3.3.1.3.1.cmml" xref="S2.E7.m1.3.3.1.3">subscript</csymbol><ci id="S2.E7.m1.3.3.1.3.2.cmml" xref="S2.E7.m1.3.3.1.3.2">ğ‘</ci><ci id="S2.E7.m1.3.3.1.3.3.cmml" xref="S2.E7.m1.3.3.1.3.3">ğœƒ</ci></apply><apply id="S2.E7.m1.3.3.1.1.1.1.cmml" xref="S2.E7.m1.3.3.1.1.1"><csymbol cd="ambiguous" id="S2.E7.m1.3.3.1.1.1.1.1.cmml" xref="S2.E7.m1.3.3.1.1.1">subscript</csymbol><ci id="S2.E7.m1.3.3.1.1.1.1.2.cmml" xref="S2.E7.m1.3.3.1.1.1.1.2">ğ’˜</ci><ci id="S2.E7.m1.3.3.1.1.1.1.3.cmml" xref="S2.E7.m1.3.3.1.1.1.1.3">ğ‘š</ci></apply></apply></apply><apply id="S2.E7.m1.4.4.1.1.2.1.2.cmml" xref="S2.E7.m1.4.4.1.1.2.1.1"><csymbol cd="latexml" id="S2.E7.m1.4.4.1.1.2.1.2.1.cmml" xref="S2.E7.m1.4.4.1.1.2.1.1.2">delimited-[]</csymbol><apply id="S2.E7.m1.4.4.1.1.2.1.1.1.cmml" xref="S2.E7.m1.4.4.1.1.2.1.1.1"><times id="S2.E7.m1.4.4.1.1.2.1.1.1.2.cmml" xref="S2.E7.m1.4.4.1.1.2.1.1.1.2"></times><apply id="S2.E7.m1.4.4.1.1.2.1.1.1.3.cmml" xref="S2.E7.m1.4.4.1.1.2.1.1.1.3"><log id="S2.E7.m1.4.4.1.1.2.1.1.1.3.1.cmml" xref="S2.E7.m1.4.4.1.1.2.1.1.1.3.1"></log><ci id="S2.E7.m1.4.4.1.1.2.1.1.1.3.2.cmml" xref="S2.E7.m1.4.4.1.1.2.1.1.1.3.2">ğ‘</ci></apply><apply id="S2.E7.m1.4.4.1.1.2.1.1.1.1.1.1.cmml" xref="S2.E7.m1.4.4.1.1.2.1.1.1.1.1"><csymbol cd="latexml" id="S2.E7.m1.4.4.1.1.2.1.1.1.1.1.1.1.cmml" xref="S2.E7.m1.4.4.1.1.2.1.1.1.1.1.1.1">conditional</csymbol><apply id="S2.E7.m1.4.4.1.1.2.1.1.1.1.1.1.2.cmml" xref="S2.E7.m1.4.4.1.1.2.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.E7.m1.4.4.1.1.2.1.1.1.1.1.1.2.1.cmml" xref="S2.E7.m1.4.4.1.1.2.1.1.1.1.1.1.2">subscript</csymbol><ci id="S2.E7.m1.4.4.1.1.2.1.1.1.1.1.1.2.2.cmml" xref="S2.E7.m1.4.4.1.1.2.1.1.1.1.1.1.2.2">ğ·</ci><ci id="S2.E7.m1.4.4.1.1.2.1.1.1.1.1.1.2.3.cmml" xref="S2.E7.m1.4.4.1.1.2.1.1.1.1.1.1.2.3">ğ‘š</ci></apply><apply id="S2.E7.m1.4.4.1.1.2.1.1.1.1.1.1.3.cmml" xref="S2.E7.m1.4.4.1.1.2.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.E7.m1.4.4.1.1.2.1.1.1.1.1.1.3.1.cmml" xref="S2.E7.m1.4.4.1.1.2.1.1.1.1.1.1.3">subscript</csymbol><ci id="S2.E7.m1.4.4.1.1.2.1.1.1.1.1.1.3.2.cmml" xref="S2.E7.m1.4.4.1.1.2.1.1.1.1.1.1.3.2">ğ’˜</ci><ci id="S2.E7.m1.4.4.1.1.2.1.1.1.1.1.1.3.3.cmml" xref="S2.E7.m1.4.4.1.1.2.1.1.1.1.1.1.3.3">ğ‘š</ci></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E7.m1.4c">\operatorname*{arg\,min}_{\boldsymbol{w}_{m},q_{\theta}(\boldsymbol{w}_{m})}KL(q_{\theta}(\boldsymbol{w}_{m})\|p(\boldsymbol{w}_{m}))-\mathbb{E}_{q_{\theta}(\boldsymbol{w}_{m})}[\log p(D_{m}|\boldsymbol{w}_{m})].</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(7)</span></td>
</tr></tbody>
</table>
<p id="S2.SS3.p3.8" class="ltx_p">KL refers to the Kullbackâ€“Leibler divergence. Such an objective function determines the optimization of a BFL system in fulfilling client or global objectives, or their mixture; and distinguishes generic FL from personalized FL.
</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>BFL Taxonomy and Analyses</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">Here, we present a taxonomy of BFL and conduct critical analyses of representative BFL methods from both Bayesian and federated perspectives.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>BFL Taxonomy</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">BFL tasks and methods can be categorized per aspects such as FL settings or BL methods. First, taking a Bayesian perspective, we categorize BFL in terms of FL architectures: client-side BFL and server-side BFL. Client-side BFL focuses on learning local models on client nodes using Bayesian methods, which involves representative methods: (1) Federated Bayesian privacy (FBP), (2) Bayesian neural networks (BNNs) for local models, (3) Bayesian optimization (BO) for local optimization, and (4) Bayesian nonparametric (BNP) models for dynamic FL. Server-side BFL aggregates local updates for global models using Bayesian methods, with typical methods including (1) Bayesian model ensemble (BME) for aggregation, (2) Bayesian posterior decomposition (BPD), and (3) Bayesian continual learning (BCL). Then, from the FL perspective, we can categorize BFL methods into heterogeneous, hierarchical, dynamic, personalized, and hybrid BFL, etc. Figure <a href="#S3.F2" title="Figure 2 â€£ 3.1 BFL Taxonomy â€£ 3 BFL Taxonomy and Analyses â€£ Bayesian Federated Learning: A Survey" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> shows a taxonomy of BFL and its connections to BL and FL, respectively.</p>
</div>
<figure id="S3.F2" class="ltx_figure"><img src="/html/2304.13267/assets/BFL-taxonomy-8.png" id="S3.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="1196" height="473" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Taxonomy of Bayesian federated learning (BFL) and its connections to Bayesian learning and federated learning. The right and left panels show the mechanisms of FL and BL to support BFL, respectively. The middle panel consists of BFL methods in terms of Bayesian (client- and server-side) and federated perspectives.</figcaption>
</figure>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Client-side BFL</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">Various Bayesian methods address client requirements and learn local models. Representative client-side methods include FBP, BNN, BO and BNP for different client-side requirements and objectives.</p>
</div>
<section id="S3.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.1 </span>Federated Bayesian Privacy</h4>

<div id="S3.SS2.SSS1.p1" class="ltx_para">
<p id="S3.SS2.SSS1.p1.1" class="ltx_p">Earlier FL models focus on privacy-preserving federated updating, communication, and aggregation, with typical progress on differential privacy <cite class="ltx_cite ltx_citemacro_cite">Elgabli <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib24" title="" class="ltx_ref">2022</a>)</cite>. Various differential privacy methods involve simple statistics and object or output perturbation. By considering the randomness of local data, Bayesian differential privacy (BDP) <cite class="ltx_cite ltx_citemacro_cite">Triastcyn and Faltings (<a href="#bib.bib56" title="" class="ltx_ref">2019</a>)</cite> ensures client privacy, instance privacy and their joint privacy by a privacy loss accounting method. In <cite class="ltx_cite ltx_citemacro_cite">Gu <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib28" title="" class="ltx_ref">2021</a>)</cite>, KL-divergence quantifies Bayesian privacy loss during data restoration, forming a federated deep learning for private passport (FDL-PP) method against FL restoration attacks.</p>
</div>
<div id="S3.SS2.SSS1.p2" class="ltx_para">
<p id="S3.SS2.SSS1.p2.1" class="ltx_p"><span id="S3.SS2.SSS1.p2.1.1" class="ltx_text ltx_font_bold">Discussion</span>. Both BDP and FDL-PP relax constraints on existing FL differential privacy by incorporating uncertainty. However, they cannot handle complex FL and BL settings and privacy-preserving requirements.</p>
</div>
</section>
<section id="S3.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.2 </span>Bayesian Neural Networks for FL Local Models</h4>

<div id="S3.SS2.SSS2.p1" class="ltx_para">
<p id="S3.SS2.SSS2.p1.1" class="ltx_p">Bayesian neural networks (BNNs) <cite class="ltx_cite ltx_citemacro_cite">Blundell <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib6" title="" class="ltx_ref">2015</a>)</cite> combine Bayesian inference with neural networks.
BNNs are incorporated into FL in various ways. pFedBayes <cite class="ltx_cite ltx_citemacro_cite">Zhang <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib65" title="" class="ltx_ref">2022</a>)</cite> uses a BNN to train local models in each communication round. Its objective is formulated as a two-level optimization problem. For each client, pFedBayes uses VI to approximate the posterior distribution of local model parameters by minimizing the loss function of the local model. On the server, pFedBayes aggregates local models and minimizes the averaged loss functions of clients. pFedBayes <cite class="ltx_cite ltx_citemacro_cite">Kairouz <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib32" title="" class="ltx_ref">2021</a>)</cite> updates local parameters again after updating them using BNN for each client, resulting in a localized global model to overcome the challenge of non-IID data. FedPPD <cite class="ltx_cite ltx_citemacro_cite">Bhatt <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib5" title="" class="ltx_ref">2022</a>)</cite> also applies a BNN to train local models. The key difference between FedPPD and pFedBayes lies in the methods of approximating posterior distributions of model parameters. pFedBayes uses VI while FedPPD uses MCMC. FedPPD utilizes a Bayesian dark knowledge method to distill the posterior prediction distribution into a single deep neural network (DNN) for each client and then sends the resulting teacher model (approximate maximum posterior sample) and student model (approximate posterior predictive distribution) to the server for aggregation.</p>
</div>
<div id="S3.SS2.SSS2.p2" class="ltx_para">
<p id="S3.SS2.SSS2.p2.1" class="ltx_p"><span id="S3.SS2.SSS2.p2.1.1" class="ltx_text ltx_font_bold">Discussion</span>. BNNs train local models and enable FL to quantify local uncertainty while using DNNs for task learning, thus improving FL robustness. BNNs also improve the FL learning performance on limited data. However, BNNs also bring challenges to FL. First, the BFL with BNNs involves huge computational and memory costs for training local models, especially when the scale of local model parameters is immense. Second, it may be challenging to choose appropriate prior distributions for local model parameters particularly when we cannot estimate complex relationships between model outputs and parameters.</p>
</div>
</section>
<section id="S3.SS2.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.3 </span>Bayesian Optimization for FL Local Optimization</h4>

<div id="S3.SS2.SSS3.p1" class="ltx_para">
<p id="S3.SS2.SSS3.p1.1" class="ltx_p">Bayesian optimization (BO) is a sequential optimization approach,
often used to tune the hyperparameters of DNNs. Various methods involve BO for FL. In <cite class="ltx_cite ltx_citemacro_cite">Dai <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib21" title="" class="ltx_ref">2020</a>)</cite>, a federated Bayesian optimization (FBO) setting uses BO to optimize local models in each communication round. They propose the algorithm FTS for FBO, where a Gaussian process (GP) is used as the surrogate for modelling the objective and acquisition functions by Thompson sampling. Random Fourier features are used to approximate GP for scalability and information exchange (the parameters of random Fourier features are shared in each communication round). FTS has a strict convergence guarantee even for non-IID data. In <cite class="ltx_cite ltx_citemacro_cite">Zang <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib63" title="" class="ltx_ref">2022</a>)</cite>, BO supports FL for traffic flow prediction (TFP), and like FTS and other BO algorithms, GP is used as an ideal objective function surrogate. Unlike FTS, since FBO for TFP utilizes BO dynamically to adjust the weights of local models for aggregation, FBO for TFP does not suffer from performance degradation when encountering heterogeneous data. Moreover, FBO for TFP involves an expected improvement instead of Thompson sampling as the acquisition function of the models without addressing the scalability problem of GP.</p>
</div>
<div id="S3.SS2.SSS3.p2" class="ltx_para">
<p id="S3.SS2.SSS3.p2.1" class="ltx_p"><span id="S3.SS2.SSS3.p2.1.1" class="ltx_text ltx_font_bold">Discussion</span>. Applying BO to FL achieves a relatively robust learning performance for non-IID local datasets due to the inherent properties of BO. Compared with traditional optimization algorithms, BO is simpler and more convenient to implement. However, the practicality of FBO is challenging for models with substantial data points. Moreover, the slow convergence rate of FBO is open to address.</p>
</div>
</section>
<section id="S3.SS2.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.4 </span>Bayesian Nonparametric models for Dynamic FL</h4>

<div id="S3.SS2.SSS4.p1" class="ltx_para">
<p id="S3.SS2.SSS4.p1.1" class="ltx_p">Bayesian nonparametric (BNP) models enable dynamic learning <cite class="ltx_cite ltx_citemacro_cite">Gershman and
Blei (<a href="#bib.bib26" title="" class="ltx_ref">2012</a>)</cite>.
In BFL, BNP models apply a Gaussian or Beta-Bernoulli process (BBP). In GP-based FL, pFedGP <cite class="ltx_cite ltx_citemacro_cite">Achituve <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib2" title="" class="ltx_ref">2021</a>)</cite> utilizes a personalized GP classifier to train a local model for each client and shares a kernel function for all clients. FedLoc <cite class="ltx_cite ltx_citemacro_cite">Yin <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib61" title="" class="ltx_ref">2020</a>)</cite> also uses GP to train local models for regression tasks. Unlike pFedGP, FedLoc cannot effectively deal with non-IID data for FL <cite class="ltx_cite ltx_citemacro_cite">Li <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib37" title="" class="ltx_ref">2020</a>)</cite>. Different from these methods, FedCor <cite class="ltx_cite ltx_citemacro_cite">Tang <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib55" title="" class="ltx_ref">2022</a>)</cite> uses GP to predict the loss change and then selects the clients that need to be activated in each communication round according to the loss change. FedCor is only applicable for the cross-silo FL framework, where the learning performance decays significantly for non-IID data.</p>
</div>
<div id="S3.SS2.SSS4.p2" class="ltx_para">
<p id="S3.SS2.SSS4.p2.1" class="ltx_p">In BBP-based FL, PFNM <cite class="ltx_cite ltx_citemacro_cite">Yurochkin <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib62" title="" class="ltx_ref">2019</a>)</cite> uses BBP to find the matched subsets of neurons among local models. However, PFNM is only applicable to a simple feedforward neural network structure. Then, a layer-wise matching algorithm FedMA based on BBP extends PFNM to other neural network structures <cite class="ltx_cite ltx_citemacro_cite">Wang <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib58" title="" class="ltx_ref">2020</a>)</cite> such as convolutional neural networks (CNNs) and long short-term memory (LSTM). However, neither PFNM nor FedMA can achieve ideal learning performance on non-IID data.</p>
</div>
<div id="S3.SS2.SSS4.p3" class="ltx_para">
<p id="S3.SS2.SSS4.p3.1" class="ltx_p"><span id="S3.SS2.SSS4.p3.1.1" class="ltx_text ltx_font_bold">Discussion</span>. Since model complexity can adapt to data, BNP methods can train local models more flexibly than parametric methods <cite class="ltx_cite ltx_citemacro_cite">Orbanz and Teh (<a href="#bib.bib48" title="" class="ltx_ref">2010</a>)</cite>. However, because the complexity of BNP models grows with an increase in data, BNP for FL raises the computational power of clients with a large amount of data.</p>
</div>
</section>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Server-side BFL</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">Various server-side BFL methods implement the global aggregation or decomposition of all updated local models for clients in each communication round. We introduce Bayesian methods BME and BPD. Further, BFL works in other settings, such as continual learning using BCL.</p>
</div>
<section id="S3.SS3.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.3.1 </span>Bayesian Model Ensemble for FL Aggregation</h4>

<div id="S3.SS3.SSS1.p1" class="ltx_para">
<p id="S3.SS3.SSS1.p1.1" class="ltx_p">BL models approximate posterior distributions over model parameters using stochastic (e.g., MCMC) or deterministic (e.g., VI) <cite class="ltx_cite ltx_citemacro_cite">Kingma and Welling (<a href="#bib.bib35" title="" class="ltx_ref">2013</a>); Wu <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib59" title="" class="ltx_ref">2023</a>)</cite> methods. For stochastic methods, the posterior distribution can be approximated by random sampling <cite class="ltx_cite ltx_citemacro_cite">Murphy (<a href="#bib.bib45" title="" class="ltx_ref">2022</a>)</cite>. Hence, each sample can be viewed as a base learner for the Bayesian model ensemble (BME).</p>
</div>
<div id="S3.SS3.SSS1.p2" class="ltx_para">
<p id="S3.SS3.SSS1.p2.1" class="ltx_p">In BME-based FL, FedBE <cite class="ltx_cite ltx_citemacro_cite">Chen and Chao (<a href="#bib.bib16" title="" class="ltx_ref">2021</a>)</cite> first utilizes the parameters of clients to construct a global posterior distribution (Gaussian or Dirichlet) in the aggregation phase of each communication round. MCMC then samples from this global posterior distribution to obtain the ensemble model, which is used on unlabeled data to obtain a pseudo-labeled dataset. Finally, a stochastic weighted averaging algorithm distills the global model on this pseudo-labeled data. Similarly, FedPPD introduces three aggregation algorithms with one serving ensemble similar to FedBE. However, in the local learning phase of each communication round, FedBE still uses the point estimation method to obtain the local model parameters of clients, while FedPPD utilizes a BNN.</p>
</div>
<div id="S3.SS3.SSS1.p3" class="ltx_para">
<p id="S3.SS3.SSS1.p3.1" class="ltx_p"><span id="S3.SS3.SSS1.p3.1.1" class="ltx_text ltx_font_bold">Discussion</span>. BME helps to implement Bayesian inference on the server using the information of all clients more effectively to prevent model performance degradation. This works especially for local models on non-IID data. Compared with other approximation methods, the sampling method is simpler and more accurate. However, obtaining an accurate ensemble model requires as many samples as possible, increasing the computational power of devices. Also, we cannot obtain a specific global parameter directly by BME. Other methods for distilling an appropriate global parameter are required for client learning in the next communication round.</p>
</div>
</section>
<section id="S3.SS3.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.3.2 </span>Bayesian Posterior Decomposition for FL Decomposition</h4>

<div id="S3.SS3.SSS2.p1" class="ltx_para">
<p id="S3.SS3.SSS2.p1.1" class="ltx_p">For some ML tasks, it is essential yet challenging to decompose a model into a combination of sub-models that can be handled more easily than the original model <cite class="ltx_cite ltx_citemacro_cite">Abrial (<a href="#bib.bib1" title="" class="ltx_ref">2009</a>)</cite>. This requires model decomposition. For Bayesian learning, Bayesian posterior decomposition (BPD) serves this purpose by decomposing the posterior of the global model to a combination of local models.</p>
</div>
<div id="S3.SS3.SSS2.p2" class="ltx_para">
<p id="S3.SS3.SSS2.p2.1" class="ltx_p">For BPD-based FL, by imposing strong constraints on uniform prior and local data independence, FedPA <cite class="ltx_cite ltx_citemacro_cite">Al-Shedivat <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib3" title="" class="ltx_ref">2021</a>)</cite> decomposes global posterior distribution into the product of local posterior distributions of clients in each communication round. A concrete expression of parameters of the global posterior distribution can be obtained by federated least squares. Since the direct calculation of parameters from the global posterior will incur high computational and communication costs, calculating the global posterior is converted into an optimization problem and solved by sampling. Since the independent approximations of local posteriors cannot guarantee an accurate global posterior approximation, FedEP <cite class="ltx_cite ltx_citemacro_cite">Guo <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib29" title="" class="ltx_ref">2023</a>)</cite> extends FedPA to approximate a global model using an expectation propagation method. QLSD <cite class="ltx_cite ltx_citemacro_cite">Vono <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib57" title="" class="ltx_ref">2022</a>)</cite> uses the same method as in FedPA to decompose the global distribution. QLSD mainly performs the update of clients per the quantised Langevin stochastic dynamics and sends the resulting compressed gradient to the server to control communication consumption in FL. Differing from these models, FOLA also uses BPD to decompose the global posterior approximation into the product of local posterior distributions with weighted terms, which does not require any strong constraints. VIRTUAL <cite class="ltx_cite ltx_citemacro_cite">Corinzia <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib20" title="" class="ltx_ref">2019</a>)</cite> also uses BPD for aggregation on the server. To avoid catastrophic forgetting, its global posterior distribution is decomposed into the product of the global posterior distribution of the previous communication round and local posterior distributions (ratios of clients) of the current communication.</p>
</div>
<div id="S3.SS3.SSS2.p3" class="ltx_para">
<p id="S3.SS3.SSS2.p3.1" class="ltx_p"><span id="S3.SS3.SSS2.p3.1.1" class="ltx_text ltx_font_bold">Discussion</span>. Most FL methods use naive parameter averaging FedAVG <cite class="ltx_cite ltx_citemacro_cite">McMahan <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib44" title="" class="ltx_ref">2017</a>)</cite> for model aggregation, which causes performance degradation when local data involves statistical heterogeneity. However, the stability of the BPD-based FL models on heterogeneous data can be significantly improved by global posterior model decomposition. More importantly, BPD also enables better interpretability of FL models. However, BPD introduces challenges to FL. First, BPD may require other algorithms to assist model learning, which may incur a large computational overhead or even be intractable. Second, some decomposition methods may involve strong constraints, which are usually not feasible when solving practical problems.</p>
</div>
</section>
<section id="S3.SS3.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.3.3 </span>Bayesian Continual Learning for Continual FL</h4>

<div id="S3.SS3.SSS3.p1" class="ltx_para">
<p id="S3.SS3.SSS3.p1.1" class="ltx_p">Continual learning updates models over a variety of datasets, which may change over time in a sequential manner <cite class="ltx_cite ltx_citemacro_cite">Nguyen <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib47" title="" class="ltx_ref">2018</a>)</cite>. Bayesian learning can facilitate the property of continual learning and use the model posterior as the prior of the next task to achieve Bayesian continual learning (BCL).</p>
</div>
<div id="S3.SS3.SSS3.p2" class="ltx_para">
<p id="S3.SS3.SSS3.p2.1" class="ltx_p">For BCL-based FL, FOLA <cite class="ltx_cite ltx_citemacro_cite">Liu <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib41" title="" class="ltx_ref">2021</a>)</cite> uses the product of local posteriors to obtain a global posterior rather than a simple mixture of local posteriors for clients in each communication round for more robust learning on non-IID data. The resulting global posterior will then be sent to all clients at the next communication round as a prior. Similar to FOLA, in each communication round of pFedBayes, the prior distribution of a local model is replaced by the global distribution of the previous communication round to improve the learning performance and interpretability. Nevertheless, there are two main differences between FOLA and pFedBayes. First, the global distribution of pFedBayes is merely obtained by means of an incremental local model averaging, while the global distribution of FOLA is obtained by the product of local posteriors. Second, the local model for each client in pFedBayes is a BNN, while FOLA is a classic neural network.</p>
</div>
<div id="S3.SS3.SSS3.p3" class="ltx_para">
<p id="S3.SS3.SSS3.p3.1" class="ltx_p"><span id="S3.SS3.SSS3.p3.1.1" class="ltx_text ltx_font_bold">Discussion</span>. By applying BCL to FL, we can leverage the information aggregated from previous communication rounds. Such an online learning approach often results in better learning performance. However, a complex prior distribution may bring substantial computational overhead to modeling and result in limited performance improvement. It is thus challenging to arrive at a trade-off between using BCL and assuming a suitable prior distribution for FL.</p>
</div>
</section>
</section>
<section id="S3.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4 </span>BFL from the Federated Perspective</h3>

<div id="S3.SS4.p1" class="ltx_para">
<p id="S3.SS4.p1.1" class="ltx_p">BFL research can also be categorized per other FL aspects as discussed in Sec. <a href="#S2.SS1" title="2.1 Federated Learning and Challenges â€£ 2 From Federated and Bayesian Learning to Bayesian Federated Learning â€£ Bayesian Federated Learning: A Survey" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.1</span></a>. Accordingly, we review specific FL tasks using heterogeneous, personalized, hierarchical, dynamic and hybrid BFL methods. Further, federated Bayesian networks implement BL using FL or in a federated structure.</p>
</div>
<div id="S3.SS4.p2" class="ltx_para">
<p id="S3.SS4.p2.1" class="ltx_p"><span id="S3.SS4.p2.1.1" class="ltx_text ltx_font_bold">Heterogeneous BFL</span>
Heterogeneous BFL handles heterogeneous clients with different prior distributions, parameter distributions, or posterior distributions for individual clients. For example, <cite class="ltx_cite ltx_citemacro_cite">Kotelevskii <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib36" title="" class="ltx_ref">2022</a>)</cite> addresses heterogeneous clients using a mixed-effect model for each client, which includes fixed effect (common representation) and random effect (personalized representation). FedBE alleviates the heterogeneity between clients by fitting a posterior distribution for all possible global models.
However, existing research generally assumes all local models share the same global model architecture with minor adjustments on priors or parameter distributions. These cannot handle complex heterogeneities, such as heterogeneous structures and relations of clients <cite class="ltx_cite ltx_citemacro_cite">Li <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib37" title="" class="ltx_ref">2020</a>); Cao (<a href="#bib.bib15" title="" class="ltx_ref">2022d</a>)</cite>.</p>
</div>
<div id="S3.SS4.p3" class="ltx_para">
<p id="S3.SS4.p3.1" class="ltx_p"><span id="S3.SS4.p3.1.1" class="ltx_text ltx_font_bold">Personalized BFL</span>
Personalized BFL defines a personalized model for each client to deal with its distinct data distributions. For example, pFedBayes uses a personalized model for each client by minimizing the KL divergence between the global model and each updated local model. Instead, pFedGP constructs a personalized GP classifier for each client on its local data.
However, existing methods may focus on client heterogeneity but not personalize model parameters, learning tasks or objectives for each client <cite class="ltx_cite ltx_citemacro_cite">Tan <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib54" title="" class="ltx_ref">2022</a>)</cite>.</p>
</div>
<div id="S3.SS4.p4" class="ltx_para">
<p id="S3.SS4.p4.1" class="ltx_p"><span id="S3.SS4.p4.1.1" class="ltx_text ltx_font_bold">Hierarchical BFL</span>
Hierarchical BFL addresses scenarios where client features or edge nodes may be grouped into another layer, involving hierarchical FL structures. To the best of our knowledge, no work extends BL to hierarchical FL. In <cite class="ltx_cite ltx_citemacro_cite">Chen <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib19" title="" class="ltx_ref">2022</a>)</cite>, a hierarchical Bayesian model captures intra- and inter-client uncertainties to optimize hyperparameters: initial value, learning rate, and a number of (early-stop) steps. Nonetheless, existing research ignores complex interactions and couplings between client features or edge nodes, leading to poor performance <cite class="ltx_cite ltx_citemacro_cite">Briggs <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib7" title="" class="ltx_ref">2020</a>)</cite>.</p>
</div>
<div id="S3.SS4.p5" class="ltx_para">
<p id="S3.SS4.p5.1" class="ltx_p"><span id="S3.SS4.p5.1.1" class="ltx_text ltx_font_bold">Dynamic BFL</span>
Dynamic BFL handles evolving, temporal, or random characteristics, settings or tasks, which may also involves drifts (shifts, changes, variations) of client features, node features, or client-server interactions over time or other dimensions. These require dynamic BL mechanisms, such as updating priors, the number of clients, feature dynamics, and posterior contributions. To address the change in client contributions, the FBO for TFP uses BO to dynamically adjust the weights of clients in each communication round. FOLA uses BCL to dynamically adjust the prior distributions of clients to accelerate model convergence.
However, these methods generally overlook the dynamic components of FL, resulting in slow model convergence and a local optimal solution <cite class="ltx_cite ltx_citemacro_cite">Chen <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib18" title="" class="ltx_ref">2021</a>)</cite> and other gaps.</p>
</div>
<div id="S3.SS4.p6" class="ltx_para">
<p id="S3.SS4.p6.1" class="ltx_p"><span id="S3.SS4.p6.1.1" class="ltx_text ltx_font_bold">Hybrid BFL</span>
Hybrid BFL is useful to address FL with mixed client structures, features, tasks, priors, posteriors, etc. In FedPPD, a BNN trains local models for FL. FedBE utilizes a model ensemble to improve the robustness of FL.
While hybrid BFL models may be able to handle diverse problems, limited existing work is available <cite class="ltx_cite ltx_citemacro_cite">Huang <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib30" title="" class="ltx_ref">2021</a>)</cite>.</p>
</div>
<div id="S3.SS4.p7" class="ltx_para">
<p id="S3.SS4.p7.1" class="ltx_p"><span id="S3.SS4.p7.1.1" class="ltx_text ltx_font_bold">Federated Bayesian networks</span>
In this review, we exclude research on federated Bayesian networks which use FL for BL. Examples are <cite class="ltx_cite ltx_citemacro_cite">Ng and Zhang (<a href="#bib.bib46" title="" class="ltx_ref">2022</a>)</cite> which collectively learns a Bayesian network from partitioned data. Note that one may interchangeably use FBN for BFL, as in <cite class="ltx_cite ltx_citemacro_cite">Corinzia <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib20" title="" class="ltx_ref">2019</a>); Kassab and Simeone (<a href="#bib.bib33" title="" class="ltx_ref">2022</a>)</cite>.</p>
</div>
<div id="S3.SS4.p8" class="ltx_para">
<p id="S3.SS4.p8.1" class="ltx_p"><span id="S3.SS4.p8.1.1" class="ltx_text ltx_font_bold">Discussion</span>. The related research on these BFL topics is very limited, immature, incomplete and imbalanced. As discussed above, some of the settings, requirements or tasks have not been explored yet. In the following section, we further discuss these and the future directions of BFL research.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Gaps and Directions</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">BFL has demonstrated significant progress and potential for improving FL on limited, dynamic and uncertain data. However, the existing BFL research also shows significant limitations and gaps in addressing theoretical and practical FL requirements, problems, and challenges.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Gap Analyses</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">Table <a href="#S4.T1" title="Table 1 â€£ 4.1 Gap Analyses â€£ 4 Gaps and Directions â€£ Bayesian Federated Learning: A Survey" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> summarizes and compares both client- and server-based BFL methods discussed in Section <a href="#S3" title="3 BFL Taxonomy and Analyses â€£ Bayesian Federated Learning: A Survey" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>. Their main limitations and gaps can be summarized as follows.</p>
</div>
<div id="S4.SS1.p2" class="ltx_para">
<p id="S4.SS1.p2.1" class="ltx_p">First, existing BFL methods have various limitations. Typical issues include high computational costs and low communication efficiency. Most BFL models involve strong constraints on (1) FL settings such as client independence and heterogeneity, privacy, resources, and communication costs, and (2) BL settings such as prior distributions and uncertainty of clients. These limit BFL performance and applications. In addition, high computation and communication overheads limit the applications of BFL, particularly for decentralized, cross-device and personalized FL tasks. Their oversimplified settings and approaches thus lead to limited capacity and performance.</p>
</div>
<div id="S4.SS1.p3" class="ltx_para">
<p id="S4.SS1.p3.1" class="ltx_p">Second, existing BFL exhibits weak-to-no capabilities in handling complex interactions and heterogeneities in FL applications with non-IID data. Real-life FL systems are non-IID, involving comprehensive non-IIDnesses <cite class="ltx_cite ltx_citemacro_cite">Cao (<a href="#bib.bib15" title="" class="ltx_ref">2022d</a>, <a href="#bib.bib13" title="" class="ltx_ref">b</a>, <a href="#bib.bib11" title="" class="ltx_ref">2016</a>)</cite>. Examples include heterogeneous, interactive, coupled and hierarchical entities, features, relations, and structures within and between clients and communities and between clients and servers <cite class="ltx_cite ltx_citemacro_cite">Cao (<a href="#bib.bib15" title="" class="ltx_ref">2022d</a>)</cite>. Existing personalized FL and BFL only weaken these non-IIDnesses through strategies such as neutralizing heterogeneities across clients, e.g., by unified global optimal parameters or simplified Gaussian processes. The statistical heterogeneity between clients requires each client to learn its personalized optimal parameters. In addition, some devices and nodes may interact and couple with each other, while existing FL and BFL overlook their client couplings <cite class="ltx_cite ltx_citemacro_cite">Cao (<a href="#bib.bib15" title="" class="ltx_ref">2022d</a>, <a href="#bib.bib13" title="" class="ltx_ref">b</a>, <a href="#bib.bib11" title="" class="ltx_ref">2016</a>); Pang <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib49" title="" class="ltx_ref">2017</a>)</cite>. In fact, most of existing references on non-IID FL do not address the above non-IIDnesses or significantly simplify these challenges <cite class="ltx_cite ltx_citemacro_cite">Cao (<a href="#bib.bib15" title="" class="ltx_ref">2022d</a>)</cite>.</p>
</div>
<div id="S4.SS1.p4" class="ltx_para">
<p id="S4.SS1.p4.1" class="ltx_p">In addition, BFL models still suffer from weak accuracy, robustness and learning performance. These may be attributed to poor-to-weak priors, heterogeneous, dynamic and hybrid clients or tasks, weak optimization, or inappropriate updating and aggregation mechanisms. There are also gaps in implementing local and global optimization in various settings, such as heterogeneous, hybrid, dynamic, and decentralized FL and for communication, updating, and aggregation. Regarding dynamic BFL, gaps exist in modeling evolving, drifting, nonstationary, or even unlimited scenarios over time or other dimensions (such as value domain, or state space). In summary, the limited research on BFL is at its early stage and focuses on simple applications of classic and main BL settings and methods in simplified FL scenarios, tasks or applications.</p>
</div>
<figure id="S4.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Categorization and comparison of various methods for Bayesian federated learning (BFL) from a Bayesian perspective.</figcaption>
<div id="S4.T1.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:429.3pt;height:179.8pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-236.5pt,99.1pt) scale(0.475750370928286,0.475750370928286) ;">
<table id="S4.T1.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T1.1.1.1.1" class="ltx_tr">
<th id="S4.T1.1.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt">Categories</th>
<th id="S4.T1.1.1.1.1.2" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt">BL</th>
<th id="S4.T1.1.1.1.1.3" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt">BFL models</th>
<th id="S4.T1.1.1.1.1.4" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt">Application</th>
<th id="S4.T1.1.1.1.1.5" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt">Advantages</th>
<th id="S4.T1.1.1.1.1.6" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt">Disadvantages</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T1.1.1.2.1" class="ltx_tr">
<th id="S4.T1.1.1.2.1.1" class="ltx_td ltx_th ltx_th_row ltx_border_t"></th>
<td id="S4.T1.1.1.2.1.2" class="ltx_td ltx_align_right ltx_border_t">FBP</td>
<td id="S4.T1.1.1.2.1.3" class="ltx_td ltx_align_right ltx_border_t">BDP <cite class="ltx_cite ltx_citemacro_cite">Triastcyn and Faltings (<a href="#bib.bib56" title="" class="ltx_ref">2019</a>)</cite>
</td>
<td id="S4.T1.1.1.2.1.4" class="ltx_td ltx_align_right ltx_border_t">Medical images</td>
<td id="S4.T1.1.1.2.1.5" class="ltx_td ltx_align_right ltx_border_t">Communication efficiency, high accuracy</td>
<td id="S4.T1.1.1.2.1.6" class="ltx_td ltx_align_right ltx_border_t">Strong constraints</td>
</tr>
<tr id="S4.T1.1.1.3.2" class="ltx_tr">
<th id="S4.T1.1.1.3.2.1" class="ltx_td ltx_th ltx_th_row"></th>
<td id="S4.T1.1.1.3.2.2" class="ltx_td ltx_align_right">FBP</td>
<td id="S4.T1.1.1.3.2.3" class="ltx_td ltx_align_right">FDL-PP <cite class="ltx_cite ltx_citemacro_cite">Gu <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib28" title="" class="ltx_ref">2021</a>)</cite>
</td>
<td id="S4.T1.1.1.3.2.4" class="ltx_td ltx_align_right">Wireless communication</td>
<td id="S4.T1.1.1.3.2.5" class="ltx_td ltx_align_right">Low complexity, high accuracy</td>
<td id="S4.T1.1.1.3.2.6" class="ltx_td ltx_align_right">High computational cost, IID</td>
</tr>
<tr id="S4.T1.1.1.4.3" class="ltx_tr">
<th id="S4.T1.1.1.4.3.1" class="ltx_td ltx_th ltx_th_row"></th>
<td id="S4.T1.1.1.4.3.2" class="ltx_td ltx_align_right">BNN</td>
<td id="S4.T1.1.1.4.3.3" class="ltx_td ltx_align_right">pFedBayes <cite class="ltx_cite ltx_citemacro_cite">Zhang <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib65" title="" class="ltx_ref">2022</a>)</cite>
</td>
<td id="S4.T1.1.1.4.3.4" class="ltx_td ltx_align_right">Finance, medicine</td>
<td id="S4.T1.1.1.4.3.5" class="ltx_td ltx_align_right">Limited data, non-IID</td>
<td id="S4.T1.1.1.4.3.6" class="ltx_td ltx_align_right">Strong constraints</td>
</tr>
<tr id="S4.T1.1.1.5.4" class="ltx_tr">
<th id="S4.T1.1.1.5.4.1" class="ltx_td ltx_th ltx_th_row"></th>
<td id="S4.T1.1.1.5.4.2" class="ltx_td ltx_align_right">BNN</td>
<td id="S4.T1.1.1.5.4.3" class="ltx_td ltx_align_right">FedPPD <cite class="ltx_cite ltx_citemacro_cite">Bhatt <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib5" title="" class="ltx_ref">2022</a>)</cite>
</td>
<td id="S4.T1.1.1.5.4.4" class="ltx_td ltx_align_right">Face perception, medical test</td>
<td id="S4.T1.1.1.5.4.5" class="ltx_td ltx_align_right">Weak constraints, non-IID</td>
<td id="S4.T1.1.1.5.4.6" class="ltx_td ltx_align_right">High computational cost</td>
</tr>
<tr id="S4.T1.1.1.6.5" class="ltx_tr">
<th id="S4.T1.1.1.6.5.1" class="ltx_td ltx_th ltx_th_row"></th>
<td id="S4.T1.1.1.6.5.2" class="ltx_td ltx_align_right">BO</td>
<td id="S4.T1.1.1.6.5.3" class="ltx_td ltx_align_right">FTS <cite class="ltx_cite ltx_citemacro_cite">Dai <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib21" title="" class="ltx_ref">2020</a>)</cite>
</td>
<td id="S4.T1.1.1.6.5.4" class="ltx_td ltx_align_right">Human activity recognition</td>
<td id="S4.T1.1.1.6.5.5" class="ltx_td ltx_align_right">Communication efficiency, non-IID</td>
<td id="S4.T1.1.1.6.5.6" class="ltx_td ltx_align_right">Low convergence rate</td>
</tr>
<tr id="S4.T1.1.1.7.6" class="ltx_tr">
<th id="S4.T1.1.1.7.6.1" class="ltx_td ltx_th ltx_th_row"></th>
<td id="S4.T1.1.1.7.6.2" class="ltx_td ltx_align_right">BO</td>
<td id="S4.T1.1.1.7.6.3" class="ltx_td ltx_align_right">FBO for TFP <cite class="ltx_cite ltx_citemacro_cite">Zang <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib63" title="" class="ltx_ref">2022</a>)</cite>
</td>
<td id="S4.T1.1.1.7.6.4" class="ltx_td ltx_align_right">Traffic flow prediction</td>
<td id="S4.T1.1.1.7.6.5" class="ltx_td ltx_align_right">Communication efficiency, non-IID</td>
<td id="S4.T1.1.1.7.6.6" class="ltx_td ltx_align_right">Poor scalability</td>
</tr>
<tr id="S4.T1.1.1.8.7" class="ltx_tr">
<th id="S4.T1.1.1.8.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Client-side</th>
<td id="S4.T1.1.1.8.7.2" class="ltx_td ltx_align_right">BNP</td>
<td id="S4.T1.1.1.8.7.3" class="ltx_td ltx_align_right">pFedGP <cite class="ltx_cite ltx_citemacro_cite">Achituve <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib2" title="" class="ltx_ref">2021</a>)</cite>
</td>
<td id="S4.T1.1.1.8.7.4" class="ltx_td ltx_align_right">Health care, legal</td>
<td id="S4.T1.1.1.8.7.5" class="ltx_td ltx_align_right">Computational efficiency, non-IID</td>
<td id="S4.T1.1.1.8.7.6" class="ltx_td ltx_align_right">High computational cost</td>
</tr>
<tr id="S4.T1.1.1.9.8" class="ltx_tr">
<th id="S4.T1.1.1.9.8.1" class="ltx_td ltx_th ltx_th_row"></th>
<td id="S4.T1.1.1.9.8.2" class="ltx_td ltx_align_right">BNP</td>
<td id="S4.T1.1.1.9.8.3" class="ltx_td ltx_align_right">FedLoc <cite class="ltx_cite ltx_citemacro_cite">Yin <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib61" title="" class="ltx_ref">2020</a>)</cite>
</td>
<td id="S4.T1.1.1.9.8.4" class="ltx_td ltx_align_right">Outdoor vehicle navigation</td>
<td id="S4.T1.1.1.9.8.5" class="ltx_td ltx_align_right">Data privacy, high accuracy</td>
<td id="S4.T1.1.1.9.8.6" class="ltx_td ltx_align_right">High computational cost, IID</td>
</tr>
<tr id="S4.T1.1.1.10.9" class="ltx_tr">
<th id="S4.T1.1.1.10.9.1" class="ltx_td ltx_th ltx_th_row"></th>
<td id="S4.T1.1.1.10.9.2" class="ltx_td ltx_align_right">BNP</td>
<td id="S4.T1.1.1.10.9.3" class="ltx_td ltx_align_right">FedCor <cite class="ltx_cite ltx_citemacro_cite">Tang <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib55" title="" class="ltx_ref">2022</a>)</cite>
</td>
<td id="S4.T1.1.1.10.9.4" class="ltx_td ltx_align_right">Precision medicine</td>
<td id="S4.T1.1.1.10.9.5" class="ltx_td ltx_align_right">Communication efficiency, fast convergence</td>
<td id="S4.T1.1.1.10.9.6" class="ltx_td ltx_align_right">Limited scenarios, IID</td>
</tr>
<tr id="S4.T1.1.1.11.10" class="ltx_tr">
<th id="S4.T1.1.1.11.10.1" class="ltx_td ltx_th ltx_th_row"></th>
<td id="S4.T1.1.1.11.10.2" class="ltx_td ltx_align_right">BNP</td>
<td id="S4.T1.1.1.11.10.3" class="ltx_td ltx_align_right">PFNM <cite class="ltx_cite ltx_citemacro_cite">Yurochkin <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib62" title="" class="ltx_ref">2019</a>)</cite>
</td>
<td id="S4.T1.1.1.11.10.4" class="ltx_td ltx_align_right">Health care, finance</td>
<td id="S4.T1.1.1.11.10.5" class="ltx_td ltx_align_right">Communication efficiency</td>
<td id="S4.T1.1.1.11.10.6" class="ltx_td ltx_align_right">Limited scenarios, IID</td>
</tr>
<tr id="S4.T1.1.1.12.11" class="ltx_tr">
<th id="S4.T1.1.1.12.11.1" class="ltx_td ltx_th ltx_th_row"></th>
<td id="S4.T1.1.1.12.11.2" class="ltx_td ltx_align_right">BNP</td>
<td id="S4.T1.1.1.12.11.3" class="ltx_td ltx_align_right">FedMA <cite class="ltx_cite ltx_citemacro_cite">Wang <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib58" title="" class="ltx_ref">2020</a>)</cite>
</td>
<td id="S4.T1.1.1.12.11.4" class="ltx_td ltx_align_right">Fingerprinting</td>
<td id="S4.T1.1.1.12.11.5" class="ltx_td ltx_align_right">Communication efficiency</td>
<td id="S4.T1.1.1.12.11.6" class="ltx_td ltx_align_right">High computational cost, IID</td>
</tr>
<tr id="S4.T1.1.1.13.12" class="ltx_tr">
<th id="S4.T1.1.1.13.12.1" class="ltx_td ltx_th ltx_th_row ltx_border_t"></th>
<td id="S4.T1.1.1.13.12.2" class="ltx_td ltx_align_right ltx_border_t">BME</td>
<td id="S4.T1.1.1.13.12.3" class="ltx_td ltx_align_right ltx_border_t">FedBE <cite class="ltx_cite ltx_citemacro_cite">Chen and Chao (<a href="#bib.bib16" title="" class="ltx_ref">2021</a>)</cite>
</td>
<td id="S4.T1.1.1.13.12.4" class="ltx_td ltx_align_right ltx_border_t">Target localization</td>
<td id="S4.T1.1.1.13.12.5" class="ltx_td ltx_align_right ltx_border_t">Deeper neural networks, non-IID</td>
<td id="S4.T1.1.1.13.12.6" class="ltx_td ltx_align_right ltx_border_t">Strong constraints</td>
</tr>
<tr id="S4.T1.1.1.14.13" class="ltx_tr">
<th id="S4.T1.1.1.14.13.1" class="ltx_td ltx_th ltx_th_row"></th>
<td id="S4.T1.1.1.14.13.2" class="ltx_td ltx_align_right">BME</td>
<td id="S4.T1.1.1.14.13.3" class="ltx_td ltx_align_right">FedPPD <cite class="ltx_cite ltx_citemacro_cite">Bhatt <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib5" title="" class="ltx_ref">2022</a>)</cite>
</td>
<td id="S4.T1.1.1.14.13.4" class="ltx_td ltx_align_right">Face perception, medical test</td>
<td id="S4.T1.1.1.14.13.5" class="ltx_td ltx_align_right">Model uncertainty, weak constraints, non-IID</td>
<td id="S4.T1.1.1.14.13.6" class="ltx_td ltx_align_right">High computational cost</td>
</tr>
<tr id="S4.T1.1.1.15.14" class="ltx_tr">
<th id="S4.T1.1.1.15.14.1" class="ltx_td ltx_th ltx_th_row"></th>
<td id="S4.T1.1.1.15.14.2" class="ltx_td ltx_align_right">BCL</td>
<td id="S4.T1.1.1.15.14.3" class="ltx_td ltx_align_right">FOLA <cite class="ltx_cite ltx_citemacro_cite">Liu <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib41" title="" class="ltx_ref">2021</a>)</cite>
</td>
<td id="S4.T1.1.1.15.14.4" class="ltx_td ltx_align_right">Medical AI</td>
<td id="S4.T1.1.1.15.14.5" class="ltx_td ltx_align_right">Aggregation error, local forgetting, non-IID</td>
<td id="S4.T1.1.1.15.14.6" class="ltx_td ltx_align_right">High computational cost</td>
</tr>
<tr id="S4.T1.1.1.16.15" class="ltx_tr">
<th id="S4.T1.1.1.16.15.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Server-side</th>
<td id="S4.T1.1.1.16.15.2" class="ltx_td ltx_align_right">BCL</td>
<td id="S4.T1.1.1.16.15.3" class="ltx_td ltx_align_right">pFedBayes <cite class="ltx_cite ltx_citemacro_cite">Zhang <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib65" title="" class="ltx_ref">2022</a>)</cite>
</td>
<td id="S4.T1.1.1.16.15.4" class="ltx_td ltx_align_right">Finance, medicine</td>
<td id="S4.T1.1.1.16.15.5" class="ltx_td ltx_align_right">Limited data, non-IID</td>
<td id="S4.T1.1.1.16.15.6" class="ltx_td ltx_align_right">Strong constraints</td>
</tr>
<tr id="S4.T1.1.1.17.16" class="ltx_tr">
<th id="S4.T1.1.1.17.16.1" class="ltx_td ltx_th ltx_th_row"></th>
<td id="S4.T1.1.1.17.16.2" class="ltx_td ltx_align_right">BPD</td>
<td id="S4.T1.1.1.17.16.3" class="ltx_td ltx_align_right">FedPA <cite class="ltx_cite ltx_citemacro_cite">Al-Shedivat <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib3" title="" class="ltx_ref">2021</a>)</cite>
</td>
<td id="S4.T1.1.1.17.16.4" class="ltx_td ltx_align_right">Pedestrian tracking</td>
<td id="S4.T1.1.1.17.16.5" class="ltx_td ltx_align_right">Computational efficiency, non-IID</td>
<td id="S4.T1.1.1.17.16.6" class="ltx_td ltx_align_right">Strong constraints</td>
</tr>
<tr id="S4.T1.1.1.18.17" class="ltx_tr">
<th id="S4.T1.1.1.18.17.1" class="ltx_td ltx_th ltx_th_row"></th>
<td id="S4.T1.1.1.18.17.2" class="ltx_td ltx_align_right">BPD</td>
<td id="S4.T1.1.1.18.17.3" class="ltx_td ltx_align_right">FedEP <cite class="ltx_cite ltx_citemacro_cite">Guo <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib29" title="" class="ltx_ref">2023</a>)</cite>
</td>
<td id="S4.T1.1.1.18.17.4" class="ltx_td ltx_align_right">Disease detection</td>
<td id="S4.T1.1.1.18.17.5" class="ltx_td ltx_align_right">Communication efficiency, non-IID</td>
<td id="S4.T1.1.1.18.17.6" class="ltx_td ltx_align_right">Strong constraints</td>
</tr>
<tr id="S4.T1.1.1.19.18" class="ltx_tr">
<th id="S4.T1.1.1.19.18.1" class="ltx_td ltx_th ltx_th_row"></th>
<td id="S4.T1.1.1.19.18.2" class="ltx_td ltx_align_right">BPD</td>
<td id="S4.T1.1.1.19.18.3" class="ltx_td ltx_align_right">QLSD <cite class="ltx_cite ltx_citemacro_cite">Vono <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib57" title="" class="ltx_ref">2022</a>)</cite>
</td>
<td id="S4.T1.1.1.19.18.4" class="ltx_td ltx_align_right">Autonomous driving</td>
<td id="S4.T1.1.1.19.18.5" class="ltx_td ltx_align_right">Communication efficiency, non-IID</td>
<td id="S4.T1.1.1.19.18.6" class="ltx_td ltx_align_right">Strong constraints</td>
</tr>
<tr id="S4.T1.1.1.20.19" class="ltx_tr">
<th id="S4.T1.1.1.20.19.1" class="ltx_td ltx_th ltx_th_row"></th>
<td id="S4.T1.1.1.20.19.2" class="ltx_td ltx_align_right">BPD</td>
<td id="S4.T1.1.1.20.19.3" class="ltx_td ltx_align_right">FOLA <cite class="ltx_cite ltx_citemacro_cite">Liu <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib41" title="" class="ltx_ref">2021</a>)</cite>
</td>
<td id="S4.T1.1.1.20.19.4" class="ltx_td ltx_align_right">Medical AI</td>
<td id="S4.T1.1.1.20.19.5" class="ltx_td ltx_align_right">Aggregation error, local forgetting, non-IID</td>
<td id="S4.T1.1.1.20.19.6" class="ltx_td ltx_align_right">High computational cost</td>
</tr>
<tr id="S4.T1.1.1.21.20" class="ltx_tr">
<th id="S4.T1.1.1.21.20.1" class="ltx_td ltx_th ltx_th_row ltx_border_bb"></th>
<td id="S4.T1.1.1.21.20.2" class="ltx_td ltx_align_right ltx_border_bb">BPD</td>
<td id="S4.T1.1.1.21.20.3" class="ltx_td ltx_align_right ltx_border_bb">VIRTUAL <cite class="ltx_cite ltx_citemacro_cite">Corinzia <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib20" title="" class="ltx_ref">2019</a>)</cite>
</td>
<td id="S4.T1.1.1.21.20.4" class="ltx_td ltx_align_right ltx_border_bb">Smart keyboards</td>
<td id="S4.T1.1.1.21.20.5" class="ltx_td ltx_align_right ltx_border_bb">Communication efficiency, non-IID</td>
<td id="S4.T1.1.1.21.20.6" class="ltx_td ltx_align_right ltx_border_bb">High computational cost</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Research Directions</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">On one hand, intricate real-world FL scenarios, requirement and applications challenge existing FL theories and systems, which could inspire promising BFL research issues and opportunities. On the other hand, BFL could transform FL and BL research and systems to a new generation. The new-generation BFL could include but may not be limited to: variational, non-IID, hierarchical, weakly-constrained, computation- and communication-efficient, hybrid, and actionable BFL theories and applications, and BFL under complex task, network and data conditions.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.1" class="ltx_p"><span id="S4.SS2.p2.1.1" class="ltx_text ltx_font_bold">Variational FL</span>. Variational deep learning has made significant progress by integrating VI with deep neural learning <cite class="ltx_cite ltx_citemacro_cite">Wu <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib59" title="" class="ltx_ref">2023</a>)</cite>.
Variational FL may expand the existing BFL research for (1) complex stochastic client/server conditions or settings; (2) diverse and efficient VI mechanisms in heterogeneous, hierarchical and hybrid FL settings; (3) large-scale and dynamic variational FL; and (4) variational FL under non-IID settings as discussed below.</p>
</div>
<div id="S4.SS2.p3" class="ltx_para">
<p id="S4.SS2.p3.1" class="ltx_p"><span id="S4.SS2.p3.1.1" class="ltx_text ltx_font_bold">Non-IID BFL</span>. Original BFL mechanisms, architectures and models are required to address non-IIDnesses <cite class="ltx_cite ltx_citemacro_cite">Cao (<a href="#bib.bib13" title="" class="ltx_ref">2022b</a>)</cite> in FL systems. Examples include (1) heterogeneous data structures, distributions, priors and parameterizations across clients, devices and nodes; (2) personalized client requirements, tasks and objectives, and sample/client importance difference; (3) interactive and coupled clients, communities and edge nodes, message sharing between clients; (4) interactions and couplings between clients and server; and (5) nonstationary, evolving, adaptive, and drifting client/server conditions. This goes beyond existing heterogeneous and personalized FL focusing on limited and neutralized heterogeneities of clients without client couplings.</p>
</div>
<div id="S4.SS2.p4" class="ltx_para">
<p id="S4.SS2.p4.1" class="ltx_p"><span id="S4.SS2.p4.1.1" class="ltx_text ltx_font_bold">BFL on complex network conditions</span>. Real-life federated networks may involve complex settings or conditions. For example, new BFL theories may need to handle (1) disconnected nodes, unstably connected clients, siloed clients, and hybrid connections with online and offline devices; (2) unavailable, unstable or forgettable clients or nodes, or unseen domains; (3) coupled and interactive networks such as with cross-domain, cross-silo, cross-client or cross-node (client node or edge network) conditions; (4) unaligned or conflicting network conditions, such as with unaligned clients (where clients share inconsistencies such as on features, distributions, or communication), client conflict, domain conflict, or objective conflict (conflicts may exist in various real-life scenarios, e.g., contrary or inconsistent circumstances, distinct objectives, or different evaluation measures); (5) insecure networks such as with data or model poisoning attacks; (6) hierarchical networks, such as client clusters, multiple client communities, hierarchical centralized servers, and mixing decentralized and centralized client/server structures; and (7) mixing asynchronous and synchronous communications.</p>
</div>
<div id="S4.SS2.p5" class="ltx_para">
<p id="S4.SS2.p5.1" class="ltx_p"><span id="S4.SS2.p5.1.1" class="ltx_text ltx_font_bold">BFL on complex data characteristics</span>. FL applications often involve complex data, challenging the existing BFL and FL capacity. They include (1) low-quality data such as noisy, irregular and unaligned client data; (2) weak data such as with small, sparse and insufficient evidence; (3) changing data such as with covariate features, feature shift, prior shift, or concept drift; (4) mixed data such as with multiple domains, communities, modalities, structures and distributions, and multi-granular data such as with client and structure granularity; and (5) mixed labelled data with unlabelled to partially labelled clients. These require new BFL theories, e.g., for data-augmented, evolving BNP networks, and mixed-supervision BL networks and optimization for FL.</p>
</div>
<div id="S4.SS2.p6" class="ltx_para">
<p id="S4.SS2.p6.1" class="ltx_p"><span id="S4.SS2.p6.1.1" class="ltx_text ltx_font_bold">Weakly-constrained BFL</span>. Existing FL and BFL involve various and often strong constraints, such as on client conditions, privacy, security, resources, client-server interactions, communication, prior and posterior distribution, parameter and message sharing, and optimization. These conflict with the diversified FL reality, where there may be siloed and coupled clients, some client features may be unbalanced and sparse, and data may be mixed, evolving and hybridized. These require substantially new and more flexible BFL theories and models catering for specific requirements.</p>
</div>
<div id="S4.SS2.p7" class="ltx_para">
<p id="S4.SS2.p7.1" class="ltx_p"><span id="S4.SS2.p7.1.1" class="ltx_text ltx_font_bold">Computation- and communication-efficient BFL</span>. Both existing FL and BFL models face the significant challenges of high computation and communication costs and low efficiency, although intensive efforts have been made to address these. Computation- and communication-efficient BFL requires more efficient, energy-aware and scalable learning theories, sampling, optimization methods, client updating, server aggregation, parameter and message sharing, and back-propagation mechanisms.</p>
</div>
<div id="S4.SS2.p8" class="ltx_para">
<p id="S4.SS2.p8.1" class="ltx_p"><span id="S4.SS2.p8.1.1" class="ltx_text ltx_font_bold">Hybrid BFL</span>. Real-life FL applications may involve (1) mixed features, modalities, and data sources; (2) hybrid priors and distributions of client data; (3) multiple to hybrid FL tasks; (4) mixing centralized and decentralized clients/server; and (5) mixing BFL with learning paradigms, etc. These require new BFL theories, architectures, and mechanisms for hybrid Bayesian learning, multi-task BFL, multi-source BFL, multimodal BFL, hybrid FL client updating, server pooling and aggregation, client-server interaction, and optimization methods. Other hybrid BFL areas include hybridizing BFL (1) with other learning systems, such as for Bayesian federated transfer learning, reinforced BFL, ensemble BFL, and BFL for anomaly detection; and (2) with various communication and computing settings, such as compressed BFL, encrypted BFL, asynchronous BFL, blockchained BFL, decentralized BFL, Bayesian federated edge learning, over-the-air BFL, sparse BFL, adaptive BFL, BFL with message sharing across devices or communities, and cross-silo BFL.</p>
</div>
<div id="S4.SS2.p9" class="ltx_para">
<p id="S4.SS2.p9.1" class="ltx_p"><span id="S4.SS2.p9.1.1" class="ltx_text ltx_font_bold">Actionable BFL</span>. Actionable BFL requires extra functional and nonfunctional requirements, settings or performance to ensure the actionability <cite class="ltx_cite ltx_citemacro_cite">Cao and Zhang (<a href="#bib.bib8" title="" class="ltx_ref">2006</a>); Cao (<a href="#bib.bib10" title="" class="ltx_ref">2013</a>, <a href="#bib.bib12" title="" class="ltx_ref">2022a</a>)</cite> of FL systems in the real world. This requires BFL theories and systems to support functions or capabilities such as fairness, unbiasedness, robustness, resilience, security, safety, responsibility, verifiability, explainability, and ethics. The evaluation of BFL algorithms and systems would have to consider both technical (such as statistical significance) and domain-driven business-oriented (such as impact on business) aspects and measures, and possibly both objective and subjective evaluation measures driven by the domain knowledge and factors, etc. <cite class="ltx_cite ltx_citemacro_cite">Cao <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib9" title="" class="ltx_ref">2010</a>)</cite>.</p>
</div>
<div id="S4.SS2.p10" class="ltx_para">
<p id="S4.SS2.p10.1" class="ltx_p">Here, we only address a few opportunities that could directly or naturally benefit from addressing intrinsic FL issues, utilizing stronger BL mechanisms, or aiming for better capacity and performance. In fact, more exciting opportunities exist in exploring intricate FL demand and challenges in the real world, and focusing on seamlessly integrating BL theories into FL settings.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusion</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">By applying Bayesian learning to the federated learning framework, Bayesian federated learning has become an important learning paradigm to handle various FL challenges and requirements for more robust uncertainty learning. While existing BFL methods exhibit significant progress and potential in learning with limited data and uncertainties, various technical gaps and hence opportunities remain. Fundamental BFL research is required to handle stochastic, heterogeneous, nonstationary, interactive, hierarchical, imbalanced, unlabeled, personalized, and hybrid challenges and requirements for robust BFL theories and actionable FL applications.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Abrial [2009]</span>
<span class="ltx_bibblock">
Jean-Raymond Abrial.

</span>
<span class="ltx_bibblock">Event model decomposition.

</span>
<span class="ltx_bibblock"><span id="bib.bib1.1.1" class="ltx_text ltx_font_italic">Technical report/ETH</span>, 626, 2009.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Achituve <span id="bib.bib2.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2021]</span>
<span class="ltx_bibblock">
Idan Achituve, Aviv Shamsian, Aviv Navon, Gal Chechik, and Ethan Fetaya.

</span>
<span class="ltx_bibblock">Personalized federated learning with gaussian processes.

</span>
<span class="ltx_bibblock">34:8392â€“8406, 2021.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Al-Shedivat <span id="bib.bib3.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2021]</span>
<span class="ltx_bibblock">
Maruan Al-Shedivat, Jennifer Gillenwater, Eric Xing, and Afshin Rostamizadeh.

</span>
<span class="ltx_bibblock">Federated learning via posterior averaging: A new perspective and
practical algorithms.

</span>
<span class="ltx_bibblock">In <span id="bib.bib3.3.1" class="ltx_text ltx_font_italic">ICLR</span>, 2021.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Benavoli and de Campos [2021]</span>
<span class="ltx_bibblock">
Alessio Benavoli and CassioÂ P. deÂ Campos.

</span>
<span class="ltx_bibblock">Bayesian independence test with mixed-type variables.

</span>
<span class="ltx_bibblock">In <span id="bib.bib4.1.1" class="ltx_text ltx_font_italic">DSAA 2021</span>, pages 1â€“13. IEEE, 2021.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bhatt <span id="bib.bib5.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2022]</span>
<span class="ltx_bibblock">
Shrey Bhatt, Aishwarya Gupta, and Piyush Rai.

</span>
<span class="ltx_bibblock">Bayesian federated learning via predictive distribution distillation.

</span>
<span class="ltx_bibblock">2022.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Blundell <span id="bib.bib6.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2015]</span>
<span class="ltx_bibblock">
Charles Blundell, Julien Cornebise, Koray Kavukcuoglu, and Daan Wierstra.

</span>
<span class="ltx_bibblock">Weight uncertainty in neural network.

</span>
<span class="ltx_bibblock">In <span id="bib.bib6.3.1" class="ltx_text ltx_font_italic">ICML</span>, pages 1613â€“1622, 2015.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Briggs <span id="bib.bib7.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2020]</span>
<span class="ltx_bibblock">
Christopher Briggs, Zhong Fan, and Peter Andras.

</span>
<span class="ltx_bibblock">Federated learning with hierarchical clustering of local updates to
improve training on non-iid data.

</span>
<span class="ltx_bibblock">In <span id="bib.bib7.3.1" class="ltx_text ltx_font_italic">IJCNN</span>, pages 1â€“9. IEEE, 2020.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cao and Zhang [2006]</span>
<span class="ltx_bibblock">
Longbing Cao and Chengqi Zhang.

</span>
<span class="ltx_bibblock">Domain-driven actionable knowledge discovery in the real world.

</span>
<span class="ltx_bibblock">In <span id="bib.bib8.1.1" class="ltx_text ltx_font_italic">Advances in Knowledge Discovery and Data Mining, 10th
Pacific-Asia Conference, PAKDD 2006, Singapore, April 9-12, 2006,
Proceedings</span>, pages 821â€“830, 2006.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cao <span id="bib.bib9.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2010]</span>
<span class="ltx_bibblock">
Longbing Cao, PhilipÂ S Yu, Chengqi Zhang, and Yanchang Zhao.

</span>
<span class="ltx_bibblock"><span id="bib.bib9.3.1" class="ltx_text ltx_font_italic">Domain Driven Data Mining</span>.

</span>
<span class="ltx_bibblock">Springer, 2010.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cao [2013]</span>
<span class="ltx_bibblock">
Longbing Cao.

</span>
<span class="ltx_bibblock">Combined mining: Analyzing object and pattern relations for
discovering and constructing complex yet actionable patterns.

</span>
<span class="ltx_bibblock"><span id="bib.bib10.1.1" class="ltx_text ltx_font_italic">Wiley Interdiscip. Rev. Data Min. Knowl. Discov.</span>,
3(2):140â€“155, 2013.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cao [2016]</span>
<span class="ltx_bibblock">
Longbing Cao.

</span>
<span class="ltx_bibblock">Non-iid recommender systems: A review and framework of recommendation
paradigm shifting.

</span>
<span class="ltx_bibblock"><span id="bib.bib11.1.1" class="ltx_text ltx_font_italic">Engineering</span>, 2(2):212â€“224, 2016.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cao [2022a]</span>
<span class="ltx_bibblock">
Longbing Cao.

</span>
<span class="ltx_bibblock">Beyond automl: Mindful and actionable AI and autoai with mind and
action.

</span>
<span class="ltx_bibblock"><span id="bib.bib12.1.1" class="ltx_text ltx_font_italic">IEEE Intell. Syst.</span>, 37(5):6â€“18, 2022.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cao [2022b]</span>
<span class="ltx_bibblock">
Longbing Cao.

</span>
<span class="ltx_bibblock">Beyond i.i.d.: non-IID thinking, informatics, and learning.

</span>
<span class="ltx_bibblock"><span id="bib.bib13.1.1" class="ltx_text ltx_font_italic">IEEE Intell Syst</span>, 37(4):5â€“17, 2022.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cao [2022c]</span>
<span class="ltx_bibblock">
Longbing Cao.

</span>
<span class="ltx_bibblock">Decentralized AI: Edge intelligence and smart blockchain,
metaverse, web3, and desci.

</span>
<span class="ltx_bibblock"><span id="bib.bib14.1.1" class="ltx_text ltx_font_italic">IEEE Intell Syst</span>, 37(3):6â€“19, 2022.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cao [2022d]</span>
<span class="ltx_bibblock">
Longbing Cao.

</span>
<span class="ltx_bibblock">Non-IID federated learning.

</span>
<span class="ltx_bibblock"><span id="bib.bib15.1.1" class="ltx_text ltx_font_italic">IEEE Intell Syst</span>, 37(2):14â€“15, 2022.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen and Chao [2021]</span>
<span class="ltx_bibblock">
Hong-You Chen and Wei-Lun Chao.

</span>
<span class="ltx_bibblock">Fed{BE}: Making Bayesian model ensemble applicable to
federated learning.

</span>
<span class="ltx_bibblock">In <span id="bib.bib16.1.1" class="ltx_text ltx_font_italic">ICLR</span>, 2021.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen and Chao [2022]</span>
<span class="ltx_bibblock">
Hong-You Chen and Wei-Lun Chao.

</span>
<span class="ltx_bibblock">On bridging generic and personalized federated learning for image
classification.

</span>
<span class="ltx_bibblock">In <span id="bib.bib17.1.1" class="ltx_text ltx_font_italic">ICLR</span>, 2022.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen <span id="bib.bib18.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2021]</span>
<span class="ltx_bibblock">
Shengbo Chen, Cong Shen, Lanxue Zhang, and Yuanmin Tang.

</span>
<span class="ltx_bibblock">Dynamic aggregation for heterogeneous quantization in federated
learning.

</span>
<span class="ltx_bibblock"><span id="bib.bib18.3.1" class="ltx_text ltx_font_italic">IEEE Trans. Wirel. Commun.</span>, 20(10):6804â€“6819, 2021.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen <span id="bib.bib19.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2022]</span>
<span class="ltx_bibblock">
Huili Chen, Jie Ding, EricÂ William Tramel, Shuang Wu, AnitÂ Kumar Sahu, Salman
Avestimehr, and Tao Zhang.

</span>
<span class="ltx_bibblock">Self-aware personalized federated learning.

</span>
<span class="ltx_bibblock">In <span id="bib.bib19.3.1" class="ltx_text ltx_font_italic">NeurIPS</span>, 2022.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Corinzia <span id="bib.bib20.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2019]</span>
<span class="ltx_bibblock">
Luca Corinzia, Ami Beuret, and JoachimÂ M Buhmann.

</span>
<span class="ltx_bibblock">Variational federated multi-task learning.

</span>
<span class="ltx_bibblock"><span id="bib.bib20.3.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1906.06268</span>, 2019.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dai <span id="bib.bib21.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2020]</span>
<span class="ltx_bibblock">
Zhongxiang Dai, Bryan KianÂ Hsiang Low, and Patrick Jaillet.

</span>
<span class="ltx_bibblock">Federated bayesian optimization via thompson sampling.

</span>
<span class="ltx_bibblock">33:9687â€“9699, 2020.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dinh <span id="bib.bib22.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2020]</span>
<span class="ltx_bibblock">
CanhÂ T Dinh, NguyenÂ H Tran, MinhÂ NH Nguyen, ChoongÂ Seon Hong, Wei Bao, AlbertÂ Y
Zomaya, and Vincent Gramoli.

</span>
<span class="ltx_bibblock">Federated learning over wireless networks: Convergence analysis and
resource allocation.

</span>
<span class="ltx_bibblock"><span id="bib.bib22.3.1" class="ltx_text ltx_font_italic">IEEE ACM Trans Netw</span>, 29(1):398â€“409, 2020.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Durmus <span id="bib.bib23.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2021]</span>
<span class="ltx_bibblock">
AlpÂ Emre Durmus, Zhao Yue, Matas Ramon, Mattina Matthew, Whatmough Paul, and
Saligrama Venkatesh.

</span>
<span class="ltx_bibblock">Federated learning based on dynamic regularization.

</span>
<span class="ltx_bibblock">In <span id="bib.bib23.3.1" class="ltx_text ltx_font_italic">ICLR</span>, 2021.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Elgabli <span id="bib.bib24.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2022]</span>
<span class="ltx_bibblock">
Anis Elgabli, ChaoukiÂ Ben Issaid, AmritÂ Singh Bedi, Ketan Rajawat, Mehdi
Bennis, and Vaneet Aggarwal.

</span>
<span class="ltx_bibblock">FedNew: A communication-efficient and privacy-preserving
newton-type method for federated learning.

</span>
<span class="ltx_bibblock">In <span id="bib.bib24.3.1" class="ltx_text ltx_font_italic">ICML</span>, pages 5861â€“5877, 2022.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fallah <span id="bib.bib25.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2020]</span>
<span class="ltx_bibblock">
Alireza Fallah, Aryan Mokhtari, and Asuman Ozdaglar.

</span>
<span class="ltx_bibblock">Personalized federated learning with theoretical guarantees: A
model-agnostic meta-learning approach.

</span>
<span class="ltx_bibblock">33:3557â€“3568, 2020.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gershman and
Blei [2012]</span>
<span class="ltx_bibblock">
SamuelÂ J Gershman and DavidÂ M Blei.

</span>
<span class="ltx_bibblock">A tutorial on bayesian nonparametric models.

</span>
<span class="ltx_bibblock"><span id="bib.bib26.1.1" class="ltx_text ltx_font_italic">J Math Psychol</span>, 56(1):1â€“12, 2012.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ghari and Shen [2022]</span>
<span class="ltx_bibblock">
PouyaÂ M. Ghari and Yanning Shen.

</span>
<span class="ltx_bibblock">Personalized online federated learning with multiple kernels.

</span>
<span class="ltx_bibblock">In <span id="bib.bib27.1.1" class="ltx_text ltx_font_italic">NeurIPS</span>, 2022.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gu <span id="bib.bib28.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2021]</span>
<span class="ltx_bibblock">
Hanlin Gu, Lixin Fan, Bowen Li, Yan Kang, Yuan Yao, and Qiang Yang.

</span>
<span class="ltx_bibblock">Federated deep learning with bayesian privacy.

</span>
<span class="ltx_bibblock"><span id="bib.bib28.3.1" class="ltx_text ltx_font_italic">CoRR</span>, abs/2109.13012, 2021.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Guo <span id="bib.bib29.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2023]</span>
<span class="ltx_bibblock">
Han Guo, Philip Greengard, Hongyi Wang, Andrew Gelman, Yoon Kim, and EricÂ P
Xing.

</span>
<span class="ltx_bibblock">Federated learning as variational inference: A scalable expectation
propagation approach.

</span>
<span class="ltx_bibblock"><span id="bib.bib29.3.1" class="ltx_text ltx_font_italic">ICLR</span>, 2023.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang <span id="bib.bib30.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2021]</span>
<span class="ltx_bibblock">
Anbu Huang, Yang Liu, Tianjian Chen, Yongkai Zhou, Quan Sun, Hongfeng Chai, and
Qiang Yang.

</span>
<span class="ltx_bibblock">Starfl: Hybrid federated learning architecture for smart urban
computing.

</span>
<span class="ltx_bibblock"><span id="bib.bib30.3.1" class="ltx_text ltx_font_italic">ACM Trans Intell Syst Technol</span>, 12(4):1â€“23, 2021.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jospin <span id="bib.bib31.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2022]</span>
<span class="ltx_bibblock">
LaurentÂ Valentin Jospin, Hamid Laga, Farid Boussaid, Wray Buntine, and Mohammed
Bennamoun.

</span>
<span class="ltx_bibblock">Hands-on bayesian neural networksâ€”a tutorial for deep learning
users.

</span>
<span class="ltx_bibblock"><span id="bib.bib31.3.1" class="ltx_text ltx_font_italic">IEEE Comput Intell Mag</span>, 17(2):29â€“48, 2022.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kairouz <span id="bib.bib32.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2021]</span>
<span class="ltx_bibblock">
Peter Kairouz, HÂ Brendan McMahan, Brendan Avent, AurÃ©lien Bellet, Mehdi
Bennis, ArjunÂ Nitin Bhagoji, Kallista Bonawitz, Zachary Charles, Graham
Cormode, Rachel Cummings, etÂ al.

</span>
<span class="ltx_bibblock">Advances and open problems in federated learning.

</span>
<span class="ltx_bibblock"><span id="bib.bib32.3.1" class="ltx_text ltx_font_italic">Found. Trends Mach. Learn.</span>, 14(1â€“2):1â€“210, 2021.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kassab and Simeone [2022]</span>
<span class="ltx_bibblock">
Rahif Kassab and Osvaldo Simeone.

</span>
<span class="ltx_bibblock">Federated generalized bayesian learning via distributed stein
variational gradient descent.

</span>
<span class="ltx_bibblock"><span id="bib.bib33.1.1" class="ltx_text ltx_font_italic">IEEE Trans. Signal Process.</span>, 70:2180â€“2192, 2022.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kendall and
Gal [2017]</span>
<span class="ltx_bibblock">
Alex Kendall and Yarin Gal.

</span>
<span class="ltx_bibblock">What uncertainties do we need in bayesian deep learning for computer
vision?

</span>
<span class="ltx_bibblock">30, 2017.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kingma and Welling [2013]</span>
<span class="ltx_bibblock">
DiederikÂ P Kingma and Max Welling.

</span>
<span class="ltx_bibblock">Auto-encoding variational bayes.

</span>
<span class="ltx_bibblock"><span id="bib.bib35.1.1" class="ltx_text ltx_font_italic">arXiv</span>, 2013.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kotelevskii <span id="bib.bib36.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2022]</span>
<span class="ltx_bibblock">
NikitaÂ Yurevich Kotelevskii, Maxime Vono, Alain Durmus, and Eric Moulines.

</span>
<span class="ltx_bibblock">Fedpop: A bayesian approach for personalised federated learning.

</span>
<span class="ltx_bibblock">In <span id="bib.bib36.3.1" class="ltx_text ltx_font_italic">NeurIPS</span>, 2022.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li <span id="bib.bib37.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2020]</span>
<span class="ltx_bibblock">
Tian Li, AnitÂ Kumar Sahu, Ameet Talwalkar, and Virginia Smith.

</span>
<span class="ltx_bibblock">Federated learning: Challenges, methods, and future directions.

</span>
<span class="ltx_bibblock"><span id="bib.bib37.3.1" class="ltx_text ltx_font_italic">IEEE Signal Process Mag</span>, 37(3):50â€“60, 2020.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li <span id="bib.bib38.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2022]</span>
<span class="ltx_bibblock">
Zhize Li, Haoyu Zhao, Boyue Li, and Yuejie Chi.

</span>
<span class="ltx_bibblock">SoteriaFL: A unified framework for private federated learning
with communication compression.

</span>
<span class="ltx_bibblock">In <span id="bib.bib38.3.1" class="ltx_text ltx_font_italic">NeurIPS</span>, 2022.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin <span id="bib.bib39.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2022]</span>
<span class="ltx_bibblock">
Shiyun Lin, Yuze Han, Xiang Li, and Zhihua Zhang.

</span>
<span class="ltx_bibblock">Personalized federated learning towards communication efficiency,
robustness and fairness.

</span>
<span class="ltx_bibblock">In <span id="bib.bib39.3.1" class="ltx_text ltx_font_italic">NeurIPS</span>, 2022.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu <span id="bib.bib40.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2020]</span>
<span class="ltx_bibblock">
Lumin Liu, Jun Zhang, SHÂ Song, and KhaledÂ B Letaief.

</span>
<span class="ltx_bibblock">Client-edge-cloud hierarchical federated learning.

</span>
<span class="ltx_bibblock">In <span id="bib.bib40.3.1" class="ltx_text ltx_font_italic">ICC</span>, pages 1â€“6, 2020.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu <span id="bib.bib41.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2021]</span>
<span class="ltx_bibblock">
Liangxi Liu, Feng Zheng, Hong Chen, Guo-Jun Qi, Heng Huang, and Ling Shao.

</span>
<span class="ltx_bibblock">A bayesian federated learning framework with online laplace
approximation.

</span>
<span class="ltx_bibblock"><span id="bib.bib41.3.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2102.01936</span>, 2021.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu <span id="bib.bib42.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2022]</span>
<span class="ltx_bibblock">
Ken Liu, Shengyuan Hu, Steven Wu, and Virginia Smith.

</span>
<span class="ltx_bibblock">On privacy and personalization in cross-silo federated learning.

</span>
<span class="ltx_bibblock">In <span id="bib.bib42.3.1" class="ltx_text ltx_font_italic">NeurIPS</span>, 2022.

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Malinovskiy <span id="bib.bib43.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2020]</span>
<span class="ltx_bibblock">
Grigory Malinovskiy, Dmitry Kovalev, Elnur Gasanov, Laurent Condat, and Peter
Richtarik.

</span>
<span class="ltx_bibblock">From local SGD to local fixed-point methods for federated learning.

</span>
<span class="ltx_bibblock">In <span id="bib.bib43.3.1" class="ltx_text ltx_font_italic">ICML</span>, pages 6692â€“6701, 2020.

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">McMahan <span id="bib.bib44.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2017]</span>
<span class="ltx_bibblock">
Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and BlaiseÂ Aguera
yÂ Arcas.

</span>
<span class="ltx_bibblock">Communication-efficient learning of deep networks from decentralized
data.

</span>
<span class="ltx_bibblock">In <span id="bib.bib44.3.1" class="ltx_text ltx_font_italic">AISTATS</span>, pages 1273â€“1282, 2017.

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Murphy [2022]</span>
<span class="ltx_bibblock">
KevinÂ P. Murphy.

</span>
<span class="ltx_bibblock"><span id="bib.bib45.1.1" class="ltx_text ltx_font_italic">Probabilistic Machine Learning: An introduction</span>.

</span>
<span class="ltx_bibblock">MIT Press, 2022.

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ng and Zhang [2022]</span>
<span class="ltx_bibblock">
Ignavier Ng and Kun Zhang.

</span>
<span class="ltx_bibblock">Towards federated bayesian network structure learning with continuous
optimization.

</span>
<span class="ltx_bibblock">In <span id="bib.bib46.1.1" class="ltx_text ltx_font_italic">AISTATS 2022</span>, volume 151, pages 8095â€“8111, 2022.

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nguyen <span id="bib.bib47.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2018]</span>
<span class="ltx_bibblock">
CuongÂ V Nguyen, Yingzhen Li, ThangÂ D Bui, and RichardÂ E Turner.

</span>
<span class="ltx_bibblock">Variational continual learning.

</span>
<span class="ltx_bibblock">In <span id="bib.bib47.3.1" class="ltx_text ltx_font_italic">ICLR</span>, 2018.

</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Orbanz and Teh [2010]</span>
<span class="ltx_bibblock">
Peter Orbanz and YeeÂ Whye Teh.

</span>
<span class="ltx_bibblock">Bayesian nonparametric models.

</span>
<span class="ltx_bibblock"><span id="bib.bib48.1.1" class="ltx_text ltx_font_italic">Encyclopedia of machine learning</span>, 1, 2010.

</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pang <span id="bib.bib49.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2017]</span>
<span class="ltx_bibblock">
Guansong Pang, Longbing Cao, Ling Chen, and Huan Liu.

</span>
<span class="ltx_bibblock">Learning homophily couplings from non-iid data for joint feature
selection and noise-resilient outlier detection.

</span>
<span class="ltx_bibblock">In <span id="bib.bib49.3.1" class="ltx_text ltx_font_italic">IJCAI 2017</span>, pages 2585â€“2591, 2017.

</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Snell and Zemel [2021]</span>
<span class="ltx_bibblock">
Jake Snell and Richard Zemel.

</span>
<span class="ltx_bibblock">Bayesian few-shot classification with one-vs-each pÃ³lya-gamma
augmented gaussian processes.

</span>
<span class="ltx_bibblock">In <span id="bib.bib50.1.1" class="ltx_text ltx_font_italic">ICLR</span>, 2021.

</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sun <span id="bib.bib51.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2019]</span>
<span class="ltx_bibblock">
Shengyang Sun, Guodong Zhang, Jiaxin Shi, and Roger Grosse.

</span>
<span class="ltx_bibblock">Functional variational Bayesian neural networks.

</span>
<span class="ltx_bibblock">In <span id="bib.bib51.3.1" class="ltx_text ltx_font_italic">ICLR</span>, 2019.

</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sun <span id="bib.bib52.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2020]</span>
<span class="ltx_bibblock">
Wenli Sun, Changgee Chang, and QiÂ Long.

</span>
<span class="ltx_bibblock">Joint bayesian variable selection and graph estimation for non-linear
SVM with application to genomics data.

</span>
<span class="ltx_bibblock">In <span id="bib.bib52.3.1" class="ltx_text ltx_font_italic">DSAA 2020</span>, pages 315â€“323. IEEE, 2020.

</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">TÂ Dinh <span id="bib.bib53.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2020]</span>
<span class="ltx_bibblock">
Canh TÂ Dinh, Nguyen Tran, and Josh Nguyen.

</span>
<span class="ltx_bibblock">Personalized federated learning with moreau envelopes.

</span>
<span class="ltx_bibblock">33:21394â€“21405, 2020.

</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tan <span id="bib.bib54.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2022]</span>
<span class="ltx_bibblock">
AlysaÂ Ziying Tan, Han Yu, Lizhen Cui, and Qiang Yang.

</span>
<span class="ltx_bibblock">Towards personalized federated learning.

</span>
<span class="ltx_bibblock"><span id="bib.bib54.3.1" class="ltx_text ltx_font_italic">IEEE Trans Neural Netw Learn Syst</span>, 2022.

</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tang <span id="bib.bib55.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2022]</span>
<span class="ltx_bibblock">
Minxue Tang, Xuefei Ning, Yitu Wang, Jingwei Sun, YuÂ Wang, Hai Li, and Yiran
Chen.

</span>
<span class="ltx_bibblock">FedCor: Correlation-based active client selection strategy for
heterogeneous federated learning.

</span>
<span class="ltx_bibblock">In <span id="bib.bib55.3.1" class="ltx_text ltx_font_italic">CVPR</span>, pages 10102â€“10111, 2022.

</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Triastcyn and Faltings [2019]</span>
<span class="ltx_bibblock">
Aleksei Triastcyn and Boi Faltings.

</span>
<span class="ltx_bibblock">Federated learning with bayesian differential privacy.

</span>
<span class="ltx_bibblock">In <span id="bib.bib56.1.1" class="ltx_text ltx_font_italic">IEEE BigData</span>, pages 2587â€“2596, 2019.

</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vono <span id="bib.bib57.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2022]</span>
<span class="ltx_bibblock">
Maxime Vono, Vincent Plassier, Alain Durmus, Aymeric Dieuleveut, and Eric
Moulines.

</span>
<span class="ltx_bibblock">QLSD: Quantised langevin stochastic dynamics for bayesian federated
learning.

</span>
<span class="ltx_bibblock">In <span id="bib.bib57.3.1" class="ltx_text ltx_font_italic">AISTATS</span>, pages 6459â€“6500, 2022.

</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang <span id="bib.bib58.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2020]</span>
<span class="ltx_bibblock">
Hongyi Wang, Mikhail Yurochkin, Yuekai Sun, Dimitris Papailiopoulos, and
Yasaman Khazaeni.

</span>
<span class="ltx_bibblock">Federated learning with matched averaging.

</span>
<span class="ltx_bibblock">In <span id="bib.bib58.3.1" class="ltx_text ltx_font_italic">ICLR</span>, 2020.

</span>
</li>
<li id="bib.bib59" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu <span id="bib.bib59.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2023]</span>
<span class="ltx_bibblock">
Zhangkai Wu, Longbing Cao, and Lei Qi.

</span>
<span class="ltx_bibblock">e-VAE: Evolutionary variational autoencoder.

</span>
<span class="ltx_bibblock"><span id="bib.bib59.3.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2301.00011</span>, 2023.

</span>
</li>
<li id="bib.bib60" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang [2021]</span>
<span class="ltx_bibblock">
Qiang Yang.

</span>
<span class="ltx_bibblock">Toward responsible AI: an overview of federated learning for
user-centered privacy-preserving computing.

</span>
<span class="ltx_bibblock"><span id="bib.bib60.1.1" class="ltx_text ltx_font_italic">ACM Trans. Interact. Intell. Syst.</span>, 11(3-4):32:1â€“32:22,
2021.

</span>
</li>
<li id="bib.bib61" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yin <span id="bib.bib61.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2020]</span>
<span class="ltx_bibblock">
Feng Yin, Zhidi Lin, Qinglei Kong, Yue Xu, Deshi Li, Sergios Theodoridis, and
ShuguangÂ Robert Cui.

</span>
<span class="ltx_bibblock">FedLoc: Federated learning framework for data-driven cooperative
localization and location data processing.

</span>
<span class="ltx_bibblock"><span id="bib.bib61.3.1" class="ltx_text ltx_font_italic">IEEE Signal Process Mag</span>, 1:187â€“215, 2020.

</span>
</li>
<li id="bib.bib62" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yurochkin <span id="bib.bib62.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2019]</span>
<span class="ltx_bibblock">
Mikhail Yurochkin, Mayank Agarwal, Soumya Ghosh, Kristjan Greenewald, Nghia
Hoang, and Yasaman Khazaeni.

</span>
<span class="ltx_bibblock">Bayesian nonparametric federated learning of neural networks.

</span>
<span class="ltx_bibblock">In <span id="bib.bib62.3.1" class="ltx_text ltx_font_italic">ICML</span>, pages 7252â€“7261, 2019.

</span>
</li>
<li id="bib.bib63" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zang <span id="bib.bib63.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2022]</span>
<span class="ltx_bibblock">
LuÂ Zang, Yang Qin, and Ruonan Li.

</span>
<span class="ltx_bibblock">Traffic flow prediction based on federated learning with joint pca
compression and bayesian optimization.

</span>
<span class="ltx_bibblock">In <span id="bib.bib63.3.1" class="ltx_text ltx_font_italic">SMC</span>, pages 3330â€“3335, 2022.

</span>
</li>
<li id="bib.bib64" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang <span id="bib.bib64.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2021]</span>
<span class="ltx_bibblock">
Xinwei Zhang, Mingyi Hong, Sairaj Dhople, Wotao Yin, and Yang Liu.

</span>
<span class="ltx_bibblock">FedPD: A federated learning framework with adaptivity to non-iid
data.

</span>
<span class="ltx_bibblock"><span id="bib.bib64.3.1" class="ltx_text ltx_font_italic">IEEE Trans. Signal Process.</span>, 69:6055â€“6070, 2021.

</span>
</li>
<li id="bib.bib65" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang <span id="bib.bib65.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2022]</span>
<span class="ltx_bibblock">
XuÂ Zhang, Yinchuan Li, Wenpeng Li, Kaiyang Guo, and Yunfeng Shao.

</span>
<span class="ltx_bibblock">Personalized federated learning via variational bayesian inference.

</span>
<span class="ltx_bibblock">In <span id="bib.bib65.3.1" class="ltx_text ltx_font_italic">ICML</span>, pages 26293â€“26310, 2022.

</span>
</li>
<li id="bib.bib66" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zong <span id="bib.bib66.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2021]</span>
<span class="ltx_bibblock">
Huixuan Zong, Qing Wang, Xiaofeng Liu, Yinchuan Li, and Yunfeng Shao.

</span>
<span class="ltx_bibblock">Communication reducing quantization for federated learning with local
differential privacy mechanism.

</span>
<span class="ltx_bibblock">In <span id="bib.bib66.3.1" class="ltx_text ltx_font_italic">IEEE/CIC ICCC</span>, pages 75â€“80, 2021.

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2304.13266" class="ar5iv-nav-button ar5iv-nav-button-prev">â—„</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2304.13267" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2304.13267">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2304.13267" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2304.13268" class="ar5iv-nav-button ar5iv-nav-button-next">â–º</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Thu Feb 29 12:33:57 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "Ã—";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
