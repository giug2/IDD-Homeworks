<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2311.00334] MetisFL: An Embarrassingly Parallelized Controller for Scalable &amp; Efficient Federated Learning Workflows</title><meta property="og:description" content="A Federated Learning (FL) system typically consists of two core processing entities: the federation controller and the learners. The controller is responsible for managing the execution of FL workflows across learners â€¦">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="MetisFL: An Embarrassingly Parallelized Controller for Scalable &amp; Efficient Federated Learning Workflows">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="MetisFL: An Embarrassingly Parallelized Controller for Scalable &amp; Efficient Federated Learning Workflows">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2311.00334">

<!--Generated on Tue Feb 27 20:12:11 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">MetisFL: An Embarrassingly Parallelized Controller for 
<br class="ltx_break">Scalable &amp; Efficient Federated Learning Workflows</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname"><span id="id1.1.id1" class="ltx_text ltx_font_bold">Dimitris Stripelis  </span><span id="id2.2.id2" class="ltx_text ltx_font_italic" style="font-size:90%;">stripeli@isi.edu 
<br class="ltx_break">Information Science Institute
<br class="ltx_break">University of Southern California
</span><span id="id3.3.id3" class="ltx_text ltx_font_bold">Chrysovalantis Anastasiou  </span><span id="id4.4.id4" class="ltx_text ltx_font_italic" style="font-size:90%;">canastas@usc.edu 
<br class="ltx_break">Viterbi School of Engineering
<br class="ltx_break">University of Southern California
</span><span id="id5.5.id5" class="ltx_text ltx_font_bold">Patrick Toral  </span><span id="id6.6.id6" class="ltx_text ltx_font_italic" style="font-size:90%;">pjtoral@isi.edu
<br class="ltx_break">Information Science Institute
<br class="ltx_break">University of Southern California
</span><span id="id7.7.id7" class="ltx_text ltx_font_bold">Armaghan Asghar  </span><span id="id8.8.id8" class="ltx_text ltx_font_italic" style="font-size:90%;">asghar@usc.edu
<br class="ltx_break">Viterbi School of Engineering
<br class="ltx_break">University of Southern California
</span><span id="id9.9.id9" class="ltx_text ltx_font_bold">JosÃ© Luis Ambite  </span><span id="id10.10.id10" class="ltx_text ltx_font_italic" style="font-size:90%;">ambite@isi.edu
<br class="ltx_break">Information Science Institute
<br class="ltx_break">University of Southern California
</span>
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id11.id1" class="ltx_p">A Federated Learning (FL) system typically consists of two core processing entities: the federation controller and the learners. The controller is responsible for managing the execution of FL workflows across learners and the learners for training and evaluating federated models over their private datasets. While executing an FL workflow, the FL system has no control over the computational resources or data of the participating learners. Still, it is responsible for other operations, such as model aggregation, task dispatching, and scheduling. These computationally heavy operations generally need to be handled by the federation controller. Even though many FL systems have been recently proposed to facilitate the development of FL workflows, most of these systems overlook the scalability of the controller. To meet this need, we designed and developed a novel FL system called MetisFL, where the federation controller is the first-class citizen. MetisFL re-engineers all the operations conducted by the federation controller to accelerate the training of large-scale FL workflows. By quantitatively comparing MetisFL against other state-of-the-art FL systems, we empirically demonstrate that MetisFL leads to a 10-fold wall-clock time execution boost across a wide range of challenging FL workflows with increasing model sizes and federation sites.</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<figure id="S1.F1" class="ltx_figure"><img src="/html/2311.00334/assets/x1.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="48" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>A typical Federated Learning workflow. The red color represents operations executed by the controller. The green color represents operations executed by the learner(s).</figcaption>
</figure>
<div id="S1.p1" class="ltx_para ltx_noindent">
<p id="S1.p1.1" class="ltx_p">Federated Learning (FL) has emerged as a standard distributed learning approach for training machine and deep learning models across dispersed data sources that cannot share data due to regulatory or privacy concerns. During the execution of an FL workflow, data always remain at the source, and sources only share their locally trained model parameters. Even though this approach mitigates the problem of direct data leakage, it creates many new system challenges related to the design, development, and deployment of FL workflows. Recently, several open-source FL frameworks have become available to meet this need, including but not limited to Nvidia FLAREÂ <cite class="ltx_cite ltx_citemacro_cite">Roth etÂ al. (<a href="#bib.bib20" title="" class="ltx_ref">2022</a>)</cite>, FlowerÂ <cite class="ltx_cite ltx_citemacro_cite">Beutel etÂ al. (<a href="#bib.bib2" title="" class="ltx_ref">2022</a>)</cite>, FedMLÂ <cite class="ltx_cite ltx_citemacro_cite">He etÂ al. (<a href="#bib.bib8" title="" class="ltx_ref">2020</a>)</cite>, IBM FLÂ <cite class="ltx_cite ltx_citemacro_cite">Ludwig etÂ al. (<a href="#bib.bib15" title="" class="ltx_ref">2020</a>)</cite>, OpenFLÂ <cite class="ltx_cite ltx_citemacro_cite">Reina etÂ al. (<a href="#bib.bib18" title="" class="ltx_ref">2021</a>)</cite>, LEAFÂ <cite class="ltx_cite ltx_citemacro_cite">Caldas etÂ al. (<a href="#bib.bib4" title="" class="ltx_ref">2018</a>)</cite>, and TensorFlow FederatedÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib7" title="" class="ltx_ref">Google </a></cite> (TFF). Some systems (e.g., Flower, TFF) make it easier to adapt the execution of centralized ML models into federated settings and implement new FL algorithms, while others (e.g., NVFlare, OpenFL, IBM FL) facilitate the transition of existing ML/DL model training pipelines into production environments.</p>
</div>
<div id="S1.p2" class="ltx_para ltx_noindent">
<p id="S1.p2.1" class="ltx_p">Even though each system offers unique solutions and optimizations, one processing entity is often overlooked: the federation controller/aggregator. Typically, a centralized FL environmentÂ <span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>In our work, we only focus on centralized environments, even though other topologies exist as wellÂ <cite class="ltx_cite ltx_citemacro_cite">Rieke etÂ al. (<a href="#bib.bib19" title="" class="ltx_ref">2020</a>)</cite>, such as decentralized and hierarchical.</span></span></span> consists of a single controller and a set of participating clients/learners. Even though the controller has no ownership over the computational resources or the data of the participating learners in the federation, it is still responsible for managing the execution of the FL workflows across learners, scheduling and dispatching the local training tasks, and receiving, storing, and aggregating learnersâ€™ model parameters. When conducting large-scale FL workflows with hundreds of learners and very large models, the controller must efficiently manage all available resources and perform all required operations with the minimum cost. On these grounds, we consider the controller the primary bottleneck of any FL system when handling the orchestration of large-scale workflows.</p>
</div>
<div id="S1.p3" class="ltx_para ltx_noindent">
<p id="S1.p3.1" class="ltx_p">In FigureÂ <a href="#S1.F1" title="Figure 1 â€£ 1 Introduction â€£ MetisFL: An Embarrassingly Parallelized Controller for Scalable &amp; Efficient Federated Learning Workflows" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, we present the sequence of these operations for a typical FL workflow. At Timestamp T1, the controller receives an update request from a participating learner(s). Timestamps T2-T4 represent learner(s)â€™ local model training and local model parameter transfer, and timestamps T4-T7 represent the reception, storing, selection, and aggregation of learner(s)â€™ locally trained model parameters by the controller. Finally, timestamps T7-T9 represent the scheduling and dispatching of the newly computed federated model to the learners for evaluation. All operations occurring between timestamps T1-T9 represent the federation round or community update request for synchronous and asynchronous settingsÂ <cite class="ltx_cite ltx_citemacro_cite">Stripelis etÂ al. (<a href="#bib.bib25" title="" class="ltx_ref">2022b</a>)</cite>, respectively. Timestamps T1-T4 represent the training round for a single (asynchronous) or multiple learners (synchronous), timestamps T4-T7 local model consolidation and aggregation, and timestamps T7-T9 the evaluation round for a single (asynchronous) or multiple learners (synchronous).</p>
</div>
<div id="S1.p4" class="ltx_para ltx_noindent">
<p id="S1.p4.1" class="ltx_p">To this end, we designed and developed from scratch a novel FL system, calledÂ <span id="S1.p4.1.1" class="ltx_text ltx_font_italic">MetisFL</span>, where the federation controller is the first-class citizen of the system. To boost the performance of the controllerâ€™s operations, we re-engineered the controller in C++ and optimized weight tensor processing and network transmission. MetisFL achieves a 10-fold to 100-fold wall-clock time execution improvement against other leading FL systems. MetisFL is the first FL system that accelerates the training of FL workflow by optimizing the controllerâ€™s operations. Our study is the first to stress-test these operations across different FL systems.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Federated Learning Systems</h2>

<div id="S2.p1" class="ltx_para ltx_noindent">
<p id="S2.p1.1" class="ltx_p">Various FL systems have been recently introducedÂ <cite class="ltx_cite ltx_citemacro_cite">He etÂ al. (<a href="#bib.bib8" title="" class="ltx_ref">2020</a>); Beutel etÂ al. (<a href="#bib.bib2" title="" class="ltx_ref">2022</a>); Caldas etÂ al. (<a href="#bib.bib4" title="" class="ltx_ref">2018</a>); <a href="#bib.bib7" title="" class="ltx_ref">Google </a>; Roth etÂ al. (<a href="#bib.bib20" title="" class="ltx_ref">2022</a>); Reina etÂ al. (<a href="#bib.bib18" title="" class="ltx_ref">2021</a>); Ludwig etÂ al. (<a href="#bib.bib15" title="" class="ltx_ref">2020</a>)</cite>, with each one aiming to optimize different aspects of a particular FL workload.
FedMLÂ <cite class="ltx_cite ltx_citemacro_cite">He etÂ al. (<a href="#bib.bib8" title="" class="ltx_ref">2020</a>)</cite> is an FL framework that supports standalone simulation, distributed training, cross-silo, and cross-device FL applications. FedML uses PyTorch as its core training engine and supports communication protocols like NCCL, MPI, and MQTT. FlowerÂ <cite class="ltx_cite ltx_citemacro_cite">Beutel etÂ al. (<a href="#bib.bib2" title="" class="ltx_ref">2022</a>)</cite> is an open-source FL framework designed to be an extensible and scalable federated ML/DL model agnostic framework targeted for heterogeneous client environments for simulation and real-world experiments. It supports a wide range of machine and deep learning computing engines (e.g., TensorFlow, PyTorch, JAX) and uses gRPC for communication between participating clients. NVIDIA Flare (NVFlare)Â <cite class="ltx_cite ltx_citemacro_cite">Roth etÂ al. (<a href="#bib.bib20" title="" class="ltx_ref">2022</a>)</cite>, OpenFLÂ <cite class="ltx_cite ltx_citemacro_cite">Reina etÂ al. (<a href="#bib.bib18" title="" class="ltx_ref">2021</a>)</cite>, and IBM FLÂ <cite class="ltx_cite ltx_citemacro_cite">Ludwig etÂ al. (<a href="#bib.bib15" title="" class="ltx_ref">2020</a>)</cite> were designed primarily for production-oriented environments. NVFlare supports a high-availability controller with fail-over capabilities and provides a domain-agnostic FL SDK for implementing a wide range of FL applications. OpenFLÂ <cite class="ltx_cite ltx_citemacro_cite">Reina etÂ al. (<a href="#bib.bib18" title="" class="ltx_ref">2021</a>)</cite> originated from the collaboration of Intel Labs and the University of Pennsylvania as part of a research project for FL applications in healthcare. The framework has now become domain-agnostic, supporting various use cases. At its core, OpenFL defines an FL plan with all the configurations necessary to execute an FL workload across learners. IBM FLâ€™s key design is its fast start-up time for enterprise applications. IBM FL aims to minimize the learning curve for a data scientist to migrate existing centralized machine learning workloads into federated settings by enabling the design of custom fusion (aggregation) algorithms and providing easy deployment of workloads across computing environments.</p>
</div>
<div id="S2.p2" class="ltx_para ltx_noindent">
<p id="S2.p2.1" class="ltx_p">When it comes to systematically comparing the various FL systems, previous studies have focused on the qualitative aspects of existing FL systems and have taxonomized them based on functional capabilities and architectural designsÂ <cite class="ltx_cite ltx_citemacro_cite">Li etÂ al. (<a href="#bib.bib12" title="" class="ltx_ref">2021b</a>); Liu etÂ al. (<a href="#bib.bib13" title="" class="ltx_ref">2022a</a>); Kairouz etÂ al. (<a href="#bib.bib10" title="" class="ltx_ref">2021</a>)</cite>. Other studiesÂ <cite class="ltx_cite ltx_citemacro_cite">Liu etÂ al. (<a href="#bib.bib14" title="" class="ltx_ref">2022b</a>); Hu etÂ al. (<a href="#bib.bib9" title="" class="ltx_ref">2022</a>)</cite> have focused on quantitatively benchmarking these systems by executing FL workloads that include challenging ML/DL model architectures and non-IID dataset distributions but whose aim was to measure the communication and computational overhead required to reach particular FL model learning performances. In our work, we take inspiration from these studies and perform a qualitative comparison between MetisFL and other leading frameworks, as shown in TableÂ <a href="#S3.T1" title="Table 1 â€£ 3 MetisFL: Design &amp; Architecture â€£ MetisFL: An Embarrassingly Parallelized Controller for Scalable &amp; Efficient Federated Learning Workflows" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. However, our quantitative analysis does not focus on traditional measures of the FL modelâ€™s performance (e.g., model accuracy, communication, and computation cost). Instead, we conduct an end-to-end stress test analysis across frameworks to quantify the system scalability occurring from the operations performed at the controller, which is often a major scalability bottleneck in FL systems.</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>MetisFL: Design &amp; Architecture</h2>

<div id="S3.p1" class="ltx_para ltx_noindent">
<p id="S3.p1.1" class="ltx_p">MetisFLÂ <span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span><a target="_blank" href="https://github.com/bioint/MetisFL" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/bioint/MetisFL</a></span></span></span> is designed from the bottom up to comply with the architectural principles of modularity (implementation of micro-services), extensibility (expanding system functionalities), and configurability (ease of use)Â <cite class="ltx_cite ltx_citemacro_cite">Beutel etÂ al. (<a href="#bib.bib2" title="" class="ltx_ref">2022</a>)</cite>. MetisFL is domain agnostic and can be used to conduct various FL workflows across organizations (a.k.a. cross-silo) or devices (a.k.a. cross-device)Â <cite class="ltx_cite ltx_citemacro_cite">Yang etÂ al. (<a href="#bib.bib26" title="" class="ltx_ref">2019</a>)</cite>. FigureÂ <a href="#S3.F2" title="Figure 2 â€£ 3 MetisFL: Design &amp; Architecture â€£ MetisFL: An Embarrassingly Parallelized Controller for Scalable &amp; Efficient Federated Learning Workflows" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> shows a detailed overview of the MetisFL internal architecture. The framework consists of three core components, the <span id="S3.p1.1.1" class="ltx_text ltx_font_italic">Federation Driver</span>, the <span id="S3.p1.1.2" class="ltx_text ltx_font_italic">Federation Controller</span>, and the <span id="S3.p1.1.3" class="ltx_text ltx_font_italic">Federation Learner</span>, similar to the programming model of the Apache Spark frameworkÂ <cite class="ltx_cite ltx_citemacro_cite">Zaharia etÂ al. (<a href="#bib.bib27" title="" class="ltx_ref">2010</a>)</cite>.</p>
</div>
<figure id="S3.F2" class="ltx_figure"><img src="/html/2311.00334/assets/x2.png" id="S3.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="96" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>MetisFL Internal Components.</figcaption>
</figure>
<div id="S3.p2" class="ltx_para ltx_noindent">
<p id="S3.p2.1" class="ltx_p">As shown in FigureÂ <a href="#S3.F3" title="Figure 3 â€£ 3 MetisFL: Design &amp; Architecture â€£ MetisFL: An Embarrassingly Parallelized Controller for Scalable &amp; Efficient Federated Learning Workflows" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, when a system user needs to run an FL workload, he/she needs to wrap the original Keras/PyTorch model architecture around the MetisFL model abstraction and materializing specific functions that the system can use to run the model operations (e.g., fit and evaluate functions for PyTorch models). Subsequently, the user needs to specify how the data will be loaded in the model (data recipe) and the federated environment (yaml file) that contains all the model (e.g., optimizer) and running environment (e.g., host machines) configurations. Once all this information is defined, the Federation Driver parses the FL workflow and creates the MetisFL Context. The MetisFL Context is responsible for initializing and monitoring the federation cluster, initializing the original model state, shipping the model state to each learner, defining the data loading recipe for each learner, and generating the security keys where needed, e.g., SSL certificates (see also FigureÂ <a href="#A2.F11" title="Figure 11 â€£ Secure Sockets Layer â€£ Appendix B MetisFL Internal Procedures â€£ MetisFL: An Embarrassingly Parallelized Controller for Scalable &amp; Efficient Federated Learning Workflows" class="ltx_ref"><span class="ltx_text ltx_ref_tag">11</span></a> in Appendix) and/or FHE key pairÂ <cite class="ltx_cite ltx_citemacro_cite">Stripelis etÂ al. (<a href="#bib.bib23" title="" class="ltx_ref">2021</a>; <a href="#bib.bib24" title="" class="ltx_ref">2022a</a>)</cite>. When all required services are alive, the Federation Controller manages the federation cluster by selecting and delegating training and evaluating tasks that need to be performed by the Federation Learners (cluster nodes) over their private datasets and storing and aggregating the learnersâ€™ local models (w/ or w/out encryption) when local training is complete.</p>
</div>
<figure id="S3.F3" class="ltx_figure"><img src="/html/2311.00334/assets/x3.png" id="S3.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="456" height="256" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>MetisFL Workflow.</figcaption>
</figure>
<div id="S3.p3" class="ltx_para ltx_noindent">
<p id="S3.p3.1" class="ltx_p">The MetisFL prototype was initially proposed in the work ofÂ <cite class="ltx_cite ltx_citemacro_cite">Stripelis etÂ al. (<a href="#bib.bib25" title="" class="ltx_ref">2022b</a>)</cite>. However, since then, substantial improvements have been made in code execution and parallelism. In its original implementation, the MetisFL controller was developed in Python. However, due to Pythonâ€™s limited memory management capabilities, the Python version led to a high latency when aggregating large-sized models and/or aggregating models from a large pool of participating clients (e.g., <math id="S3.p3.1.m1.1" class="ltx_Math" alttext="&gt;" display="inline"><semantics id="S3.p3.1.m1.1a"><mo id="S3.p3.1.m1.1.1" xref="S3.p3.1.m1.1.1.cmml">&gt;</mo><annotation-xml encoding="MathML-Content" id="S3.p3.1.m1.1b"><gt id="S3.p3.1.m1.1.1.cmml" xref="S3.p3.1.m1.1.1"></gt></annotation-xml><annotation encoding="application/x-tex" id="S3.p3.1.m1.1c">&gt;</annotation></semantics></math> 100). Moreover, in its original implementation, as more clients were considered in the federation and the size of the ML/DL models became larger, the training and evaluation tasks scheduling and dispatching became extremely slow. Given that Python relies on the Global Interpreter Lock (GIL) for proper thread management, the concurrent execution of tasks was not possible, dramatically slowing down the overall execution time of an FL workflow. For these reasons, the MetisFL architecture was redesigned and the controller was refactored in a native C++ implementation.</p>
</div>
<figure id="S3.F4" class="ltx_figure"><img src="/html/2311.00334/assets/x4.png" id="S3.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="230" height="108" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>MetisFL Parallelized Model Aggregation.</figcaption>
</figure>
<div id="S3.p4" class="ltx_para ltx_noindent">
<p id="S3.p4.1" class="ltx_p">In terms of redesign, compared to other systems (e.g., Flower, FedML), in MetisFL, the ML/DL model is transferred over the network as a sequence of tensors with each tensor being represented in a byte protobuf data type. This allows different gRPC services (i.e., controller-learners) to communicate with each other with very low overhead. This functionality is accomplished by first flattening each tensor/matrix of the ML/DL model, then dumping the tensor (as bytes), and finally constructing a proto message that represents the structure of the original tensor to enable reconstruction after proto tensor reception e.g., tensorâ€™s byte order and data type.</p>
</div>
<div id="S3.p5" class="ltx_para ltx_noindent">
<p id="S3.p5.2" class="ltx_p">With respect to the controllerâ€™s process refactoring, the controller can now leverage the underlying systemâ€™s hardware capabilities and parallelize most of its computationally heavy operations, i.e., task scheduling and dispatching and model aggregation. Especially in the case of model aggregation, by taking advantage of the tensor-based model representation, the controller parallelizes the aggregation of multiple model tensors over all available cores to speed up the operation. As shown in FigureÂ <a href="#S3.F4" title="Figure 4 â€£ 3 MetisFL: Design &amp; Architecture â€£ MetisFL: An Embarrassingly Parallelized Controller for Scalable &amp; Efficient Federated Learning Workflows" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, for a federation of N learners and a model with k tensors, MetisFL uses one thread per model tensor to compute the aggregated tensor. For instance, to calculate the aggregated tensor for the first model tensor (<math id="S3.p5.1.m1.1" class="ltx_Math" alttext="T_{1}^{C}" display="inline"><semantics id="S3.p5.1.m1.1a"><msubsup id="S3.p5.1.m1.1.1" xref="S3.p5.1.m1.1.1.cmml"><mi id="S3.p5.1.m1.1.1.2.2" xref="S3.p5.1.m1.1.1.2.2.cmml">T</mi><mn id="S3.p5.1.m1.1.1.2.3" xref="S3.p5.1.m1.1.1.2.3.cmml">1</mn><mi id="S3.p5.1.m1.1.1.3" xref="S3.p5.1.m1.1.1.3.cmml">C</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.p5.1.m1.1b"><apply id="S3.p5.1.m1.1.1.cmml" xref="S3.p5.1.m1.1.1"><csymbol cd="ambiguous" id="S3.p5.1.m1.1.1.1.cmml" xref="S3.p5.1.m1.1.1">superscript</csymbol><apply id="S3.p5.1.m1.1.1.2.cmml" xref="S3.p5.1.m1.1.1"><csymbol cd="ambiguous" id="S3.p5.1.m1.1.1.2.1.cmml" xref="S3.p5.1.m1.1.1">subscript</csymbol><ci id="S3.p5.1.m1.1.1.2.2.cmml" xref="S3.p5.1.m1.1.1.2.2">ğ‘‡</ci><cn type="integer" id="S3.p5.1.m1.1.1.2.3.cmml" xref="S3.p5.1.m1.1.1.2.3">1</cn></apply><ci id="S3.p5.1.m1.1.1.3.cmml" xref="S3.p5.1.m1.1.1.3">ğ¶</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p5.1.m1.1c">T_{1}^{C}</annotation></semantics></math>), a single thread is used to aggregate the N learnersâ€™ tensors (i.e., tensor <math id="S3.p5.2.m2.1" class="ltx_Math" alttext="T_{1}^{1}...T_{1}^{N}" display="inline"><semantics id="S3.p5.2.m2.1a"><mrow id="S3.p5.2.m2.1.1" xref="S3.p5.2.m2.1.1.cmml"><msubsup id="S3.p5.2.m2.1.1.2" xref="S3.p5.2.m2.1.1.2.cmml"><mi id="S3.p5.2.m2.1.1.2.2.2" xref="S3.p5.2.m2.1.1.2.2.2.cmml">T</mi><mn id="S3.p5.2.m2.1.1.2.2.3" xref="S3.p5.2.m2.1.1.2.2.3.cmml">1</mn><mn id="S3.p5.2.m2.1.1.2.3" xref="S3.p5.2.m2.1.1.2.3.cmml">1</mn></msubsup><mo lspace="0em" rspace="0em" id="S3.p5.2.m2.1.1.1" xref="S3.p5.2.m2.1.1.1.cmml">â€‹</mo><mi mathvariant="normal" id="S3.p5.2.m2.1.1.3" xref="S3.p5.2.m2.1.1.3.cmml">â€¦</mi><mo lspace="0em" rspace="0em" id="S3.p5.2.m2.1.1.1a" xref="S3.p5.2.m2.1.1.1.cmml">â€‹</mo><msubsup id="S3.p5.2.m2.1.1.4" xref="S3.p5.2.m2.1.1.4.cmml"><mi id="S3.p5.2.m2.1.1.4.2.2" xref="S3.p5.2.m2.1.1.4.2.2.cmml">T</mi><mn id="S3.p5.2.m2.1.1.4.2.3" xref="S3.p5.2.m2.1.1.4.2.3.cmml">1</mn><mi id="S3.p5.2.m2.1.1.4.3" xref="S3.p5.2.m2.1.1.4.3.cmml">N</mi></msubsup></mrow><annotation-xml encoding="MathML-Content" id="S3.p5.2.m2.1b"><apply id="S3.p5.2.m2.1.1.cmml" xref="S3.p5.2.m2.1.1"><times id="S3.p5.2.m2.1.1.1.cmml" xref="S3.p5.2.m2.1.1.1"></times><apply id="S3.p5.2.m2.1.1.2.cmml" xref="S3.p5.2.m2.1.1.2"><csymbol cd="ambiguous" id="S3.p5.2.m2.1.1.2.1.cmml" xref="S3.p5.2.m2.1.1.2">superscript</csymbol><apply id="S3.p5.2.m2.1.1.2.2.cmml" xref="S3.p5.2.m2.1.1.2"><csymbol cd="ambiguous" id="S3.p5.2.m2.1.1.2.2.1.cmml" xref="S3.p5.2.m2.1.1.2">subscript</csymbol><ci id="S3.p5.2.m2.1.1.2.2.2.cmml" xref="S3.p5.2.m2.1.1.2.2.2">ğ‘‡</ci><cn type="integer" id="S3.p5.2.m2.1.1.2.2.3.cmml" xref="S3.p5.2.m2.1.1.2.2.3">1</cn></apply><cn type="integer" id="S3.p5.2.m2.1.1.2.3.cmml" xref="S3.p5.2.m2.1.1.2.3">1</cn></apply><ci id="S3.p5.2.m2.1.1.3.cmml" xref="S3.p5.2.m2.1.1.3">â€¦</ci><apply id="S3.p5.2.m2.1.1.4.cmml" xref="S3.p5.2.m2.1.1.4"><csymbol cd="ambiguous" id="S3.p5.2.m2.1.1.4.1.cmml" xref="S3.p5.2.m2.1.1.4">superscript</csymbol><apply id="S3.p5.2.m2.1.1.4.2.cmml" xref="S3.p5.2.m2.1.1.4"><csymbol cd="ambiguous" id="S3.p5.2.m2.1.1.4.2.1.cmml" xref="S3.p5.2.m2.1.1.4">subscript</csymbol><ci id="S3.p5.2.m2.1.1.4.2.2.cmml" xref="S3.p5.2.m2.1.1.4.2.2">ğ‘‡</ci><cn type="integer" id="S3.p5.2.m2.1.1.4.2.3.cmml" xref="S3.p5.2.m2.1.1.4.2.3">1</cn></apply><ci id="S3.p5.2.m2.1.1.4.3.cmml" xref="S3.p5.2.m2.1.1.4.3">ğ‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p5.2.m2.1c">T_{1}^{1}...T_{1}^{N}</annotation></semantics></math>); thread parallelism is enabled using OpenMPÂ <cite class="ltx_cite ltx_citemacro_cite">Dagum &amp; Menon (<a href="#bib.bib6" title="" class="ltx_ref">1998</a>)</cite>.</p>
</div>
<figure id="S3.T1" class="ltx_table">
<table id="S3.T1.46" class="ltx_tabular ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S3.T1.46.47.1" class="ltx_tr">
<td id="S3.T1.46.47.1.1" class="ltx_td ltx_align_left ltx_border_tt"><span id="S3.T1.46.47.1.1.1" class="ltx_text ltx_font_bold" style="font-size:70%;">Dimension</span></td>
<td id="S3.T1.46.47.1.2" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T1.46.47.1.2.1" class="ltx_text" style="font-size:70%;">Nvidia FLARE</span></td>
<td id="S3.T1.46.47.1.3" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T1.46.47.1.3.1" class="ltx_text" style="font-size:70%;">Flower</span></td>
<td id="S3.T1.46.47.1.4" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T1.46.47.1.4.1" class="ltx_text" style="font-size:70%;">FedML</span></td>
<td id="S3.T1.46.47.1.5" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T1.46.47.1.5.1" class="ltx_text" style="font-size:70%;">IBM FL</span></td>
<td id="S3.T1.46.47.1.6" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T1.46.47.1.6.1" class="ltx_text" style="font-size:70%;">OpenFL</span></td>
<td id="S3.T1.46.47.1.7" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_tt"><span id="S3.T1.46.47.1.7.1" class="ltx_text" style="font-size:70%;">MetisFL*</span></td>
</tr>
<tr id="S3.T1.46.48.2" class="ltx_tr">
<td id="S3.T1.46.48.2.1" class="ltx_td ltx_align_left ltx_border_t"><span id="S3.T1.46.48.2.1.1" class="ltx_text ltx_font_bold" style="font-size:70%;">Deployment</span></td>
<td id="S3.T1.46.48.2.2" class="ltx_td ltx_border_t"></td>
<td id="S3.T1.46.48.2.3" class="ltx_td ltx_border_t"></td>
<td id="S3.T1.46.48.2.4" class="ltx_td ltx_border_t"></td>
<td id="S3.T1.46.48.2.5" class="ltx_td ltx_border_t"></td>
<td id="S3.T1.46.48.2.6" class="ltx_td ltx_border_t"></td>
<td id="S3.T1.46.48.2.7" class="ltx_td ltx_nopad_r ltx_border_t"></td>
</tr>
<tr id="S3.T1.46.49.3" class="ltx_tr">
<td id="S3.T1.46.49.3.1" class="ltx_td ltx_align_left"><span id="S3.T1.46.49.3.1.1" class="ltx_text" style="font-size:70%;">Standalone</span></td>
<td id="S3.T1.46.49.3.2" class="ltx_td ltx_align_center"><span id="S3.T1.46.49.3.2.1" class="ltx_text" style="font-size:70%;">âœ“</span></td>
<td id="S3.T1.46.49.3.3" class="ltx_td ltx_align_center"><span id="S3.T1.46.49.3.3.1" class="ltx_text" style="font-size:70%;">âœ“</span></td>
<td id="S3.T1.46.49.3.4" class="ltx_td ltx_align_center"><span id="S3.T1.46.49.3.4.1" class="ltx_text" style="font-size:70%;">âœ“</span></td>
<td id="S3.T1.46.49.3.5" class="ltx_td ltx_align_center"><span id="S3.T1.46.49.3.5.1" class="ltx_text" style="font-size:70%;">âœ“</span></td>
<td id="S3.T1.46.49.3.6" class="ltx_td ltx_align_center"><span id="S3.T1.46.49.3.6.1" class="ltx_text" style="font-size:70%;">âœ“</span></td>
<td id="S3.T1.46.49.3.7" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.T1.46.49.3.7.1" class="ltx_text" style="font-size:70%;">âœ“</span></td>
</tr>
<tr id="S3.T1.46.50.4" class="ltx_tr">
<td id="S3.T1.46.50.4.1" class="ltx_td ltx_align_left"><span id="S3.T1.46.50.4.1.1" class="ltx_text" style="font-size:70%;">Distributed</span></td>
<td id="S3.T1.46.50.4.2" class="ltx_td ltx_align_center"><span id="S3.T1.46.50.4.2.1" class="ltx_text" style="font-size:70%;">âœ“</span></td>
<td id="S3.T1.46.50.4.3" class="ltx_td ltx_align_center"><span id="S3.T1.46.50.4.3.1" class="ltx_text" style="font-size:70%;">âœ“</span></td>
<td id="S3.T1.46.50.4.4" class="ltx_td ltx_align_center"><span id="S3.T1.46.50.4.4.1" class="ltx_text" style="font-size:70%;">âœ“</span></td>
<td id="S3.T1.46.50.4.5" class="ltx_td ltx_align_center"><span id="S3.T1.46.50.4.5.1" class="ltx_text" style="font-size:70%;">âœ“</span></td>
<td id="S3.T1.46.50.4.6" class="ltx_td ltx_align_center"><span id="S3.T1.46.50.4.6.1" class="ltx_text" style="font-size:70%;">âœ“</span></td>
<td id="S3.T1.46.50.4.7" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.T1.46.50.4.7.1" class="ltx_text" style="font-size:70%;">âœ“</span></td>
</tr>
<tr id="S3.T1.46.51.5" class="ltx_tr">
<td id="S3.T1.46.51.5.1" class="ltx_td ltx_align_left"><span id="S3.T1.46.51.5.1.1" class="ltx_text" style="font-size:70%;">Cross-Silo</span></td>
<td id="S3.T1.46.51.5.2" class="ltx_td ltx_align_center"><span id="S3.T1.46.51.5.2.1" class="ltx_text" style="font-size:70%;">âœ“</span></td>
<td id="S3.T1.46.51.5.3" class="ltx_td ltx_align_center"><span id="S3.T1.46.51.5.3.1" class="ltx_text" style="font-size:70%;">âœ“</span></td>
<td id="S3.T1.46.51.5.4" class="ltx_td ltx_align_center"><span id="S3.T1.46.51.5.4.1" class="ltx_text" style="font-size:70%;">âœ“</span></td>
<td id="S3.T1.46.51.5.5" class="ltx_td ltx_align_center"><span id="S3.T1.46.51.5.5.1" class="ltx_text" style="font-size:70%;">âœ“</span></td>
<td id="S3.T1.46.51.5.6" class="ltx_td ltx_align_center"><span id="S3.T1.46.51.5.6.1" class="ltx_text" style="font-size:70%;">âœ“</span></td>
<td id="S3.T1.46.51.5.7" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.T1.46.51.5.7.1" class="ltx_text" style="font-size:70%;">âœ“</span></td>
</tr>
<tr id="S3.T1.3.3" class="ltx_tr">
<td id="S3.T1.3.3.4" class="ltx_td ltx_align_left"><span id="S3.T1.3.3.4.1" class="ltx_text" style="font-size:70%;">Cross-Device</span></td>
<td id="S3.T1.1.1.1" class="ltx_td ltx_align_center"><math id="S3.T1.1.1.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S3.T1.1.1.1.m1.1a"><mo mathsize="70%" id="S3.T1.1.1.1.m1.1.1" xref="S3.T1.1.1.1.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S3.T1.1.1.1.m1.1b"><times id="S3.T1.1.1.1.m1.1.1.cmml" xref="S3.T1.1.1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.1.1.1.m1.1c">\times</annotation></semantics></math></td>
<td id="S3.T1.3.3.5" class="ltx_td ltx_align_center"><span id="S3.T1.3.3.5.1" class="ltx_text" style="font-size:70%;">âœ“</span></td>
<td id="S3.T1.3.3.6" class="ltx_td ltx_align_center"><span id="S3.T1.3.3.6.1" class="ltx_text" style="font-size:70%;">âœ“</span></td>
<td id="S3.T1.2.2.2" class="ltx_td ltx_align_center"><math id="S3.T1.2.2.2.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S3.T1.2.2.2.m1.1a"><mo mathsize="70%" id="S3.T1.2.2.2.m1.1.1" xref="S3.T1.2.2.2.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S3.T1.2.2.2.m1.1b"><times id="S3.T1.2.2.2.m1.1.1.cmml" xref="S3.T1.2.2.2.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.2.2.2.m1.1c">\times</annotation></semantics></math></td>
<td id="S3.T1.3.3.3" class="ltx_td ltx_align_center"><math id="S3.T1.3.3.3.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S3.T1.3.3.3.m1.1a"><mo mathsize="70%" id="S3.T1.3.3.3.m1.1.1" xref="S3.T1.3.3.3.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S3.T1.3.3.3.m1.1b"><times id="S3.T1.3.3.3.m1.1.1.cmml" xref="S3.T1.3.3.3.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.3.3.3.m1.1c">\times</annotation></semantics></math></td>
<td id="S3.T1.3.3.7" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.T1.3.3.7.1" class="ltx_text" style="font-size:70%;">âœ“</span></td>
</tr>
<tr id="S3.T1.4.4" class="ltx_tr">
<td id="S3.T1.4.4.2" class="ltx_td ltx_align_left"><span id="S3.T1.4.4.2.1" class="ltx_text" style="font-size:70%;">Containerized</span></td>
<td id="S3.T1.4.4.3" class="ltx_td ltx_align_center"><span id="S3.T1.4.4.3.1" class="ltx_text" style="font-size:70%;">âœ“</span></td>
<td id="S3.T1.4.4.4" class="ltx_td ltx_align_center"><span id="S3.T1.4.4.4.1" class="ltx_text" style="font-size:70%;">âœ“</span></td>
<td id="S3.T1.4.4.5" class="ltx_td ltx_align_center"><span id="S3.T1.4.4.5.1" class="ltx_text" style="font-size:70%;">âœ“</span></td>
<td id="S3.T1.4.4.6" class="ltx_td ltx_align_center"><span id="S3.T1.4.4.6.1" class="ltx_text" style="font-size:70%;">âœ“</span></td>
<td id="S3.T1.4.4.1" class="ltx_td ltx_align_center"><math id="S3.T1.4.4.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S3.T1.4.4.1.m1.1a"><mo mathsize="70%" id="S3.T1.4.4.1.m1.1.1" xref="S3.T1.4.4.1.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S3.T1.4.4.1.m1.1b"><times id="S3.T1.4.4.1.m1.1.1.cmml" xref="S3.T1.4.4.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.4.4.1.m1.1c">\times</annotation></semantics></math></td>
<td id="S3.T1.4.4.7" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.T1.4.4.7.1" class="ltx_text" style="font-size:70%;">âœ“</span></td>
</tr>
<tr id="S3.T1.46.52.6" class="ltx_tr">
<td id="S3.T1.46.52.6.1" class="ltx_td ltx_align_left"><span id="S3.T1.46.52.6.1.1" class="ltx_text ltx_font_bold" style="font-size:70%;">ML Environment</span></td>
<td id="S3.T1.46.52.6.2" class="ltx_td"></td>
<td id="S3.T1.46.52.6.3" class="ltx_td"></td>
<td id="S3.T1.46.52.6.4" class="ltx_td"></td>
<td id="S3.T1.46.52.6.5" class="ltx_td"></td>
<td id="S3.T1.46.52.6.6" class="ltx_td"></td>
<td id="S3.T1.46.52.6.7" class="ltx_td ltx_nopad_r"></td>
</tr>
<tr id="S3.T1.10.10" class="ltx_tr">
<td id="S3.T1.10.10.7" class="ltx_td ltx_align_left"><span id="S3.T1.10.10.7.1" class="ltx_text" style="font-size:70%;">Model Types</span></td>
<td id="S3.T1.5.5.1" class="ltx_td ltx_align_center">
<span id="S3.T1.5.5.1.1" class="ltx_text" style="font-size:70%;">ML</span><math id="S3.T1.5.5.1.m1.1" class="ltx_Math" alttext="\mid" display="inline"><semantics id="S3.T1.5.5.1.m1.1a"><mo mathsize="70%" id="S3.T1.5.5.1.m1.1.1" xref="S3.T1.5.5.1.m1.1.1.cmml">âˆ£</mo><annotation-xml encoding="MathML-Content" id="S3.T1.5.5.1.m1.1b"><ci id="S3.T1.5.5.1.m1.1.1.cmml" xref="S3.T1.5.5.1.m1.1.1">âˆ£</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.5.5.1.m1.1c">\mid</annotation></semantics></math><span id="S3.T1.5.5.1.2" class="ltx_text" style="font-size:70%;">DL</span>
</td>
<td id="S3.T1.6.6.2" class="ltx_td ltx_align_center">
<span id="S3.T1.6.6.2.1" class="ltx_text" style="font-size:70%;">ML</span><math id="S3.T1.6.6.2.m1.1" class="ltx_Math" alttext="\mid" display="inline"><semantics id="S3.T1.6.6.2.m1.1a"><mo mathsize="70%" id="S3.T1.6.6.2.m1.1.1" xref="S3.T1.6.6.2.m1.1.1.cmml">âˆ£</mo><annotation-xml encoding="MathML-Content" id="S3.T1.6.6.2.m1.1b"><ci id="S3.T1.6.6.2.m1.1.1.cmml" xref="S3.T1.6.6.2.m1.1.1">âˆ£</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.6.6.2.m1.1c">\mid</annotation></semantics></math><span id="S3.T1.6.6.2.2" class="ltx_text" style="font-size:70%;">DL</span>
</td>
<td id="S3.T1.7.7.3" class="ltx_td ltx_align_center">
<span id="S3.T1.7.7.3.1" class="ltx_text" style="font-size:70%;">ML</span><math id="S3.T1.7.7.3.m1.1" class="ltx_Math" alttext="\mid" display="inline"><semantics id="S3.T1.7.7.3.m1.1a"><mo mathsize="70%" id="S3.T1.7.7.3.m1.1.1" xref="S3.T1.7.7.3.m1.1.1.cmml">âˆ£</mo><annotation-xml encoding="MathML-Content" id="S3.T1.7.7.3.m1.1b"><ci id="S3.T1.7.7.3.m1.1.1.cmml" xref="S3.T1.7.7.3.m1.1.1">âˆ£</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.7.7.3.m1.1c">\mid</annotation></semantics></math><span id="S3.T1.7.7.3.2" class="ltx_text" style="font-size:70%;">DL</span>
</td>
<td id="S3.T1.8.8.4" class="ltx_td ltx_align_center">
<span id="S3.T1.8.8.4.1" class="ltx_text" style="font-size:70%;">ML</span><math id="S3.T1.8.8.4.m1.1" class="ltx_Math" alttext="\mid" display="inline"><semantics id="S3.T1.8.8.4.m1.1a"><mo mathsize="70%" id="S3.T1.8.8.4.m1.1.1" xref="S3.T1.8.8.4.m1.1.1.cmml">âˆ£</mo><annotation-xml encoding="MathML-Content" id="S3.T1.8.8.4.m1.1b"><ci id="S3.T1.8.8.4.m1.1.1.cmml" xref="S3.T1.8.8.4.m1.1.1">âˆ£</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.8.8.4.m1.1c">\mid</annotation></semantics></math><span id="S3.T1.8.8.4.2" class="ltx_text" style="font-size:70%;">DL</span>
</td>
<td id="S3.T1.9.9.5" class="ltx_td ltx_align_center">
<span id="S3.T1.9.9.5.1" class="ltx_text" style="font-size:70%;">ML</span><math id="S3.T1.9.9.5.m1.1" class="ltx_Math" alttext="\mid" display="inline"><semantics id="S3.T1.9.9.5.m1.1a"><mo mathsize="70%" id="S3.T1.9.9.5.m1.1.1" xref="S3.T1.9.9.5.m1.1.1.cmml">âˆ£</mo><annotation-xml encoding="MathML-Content" id="S3.T1.9.9.5.m1.1b"><ci id="S3.T1.9.9.5.m1.1.1.cmml" xref="S3.T1.9.9.5.m1.1.1">âˆ£</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.9.9.5.m1.1c">\mid</annotation></semantics></math><span id="S3.T1.9.9.5.2" class="ltx_text" style="font-size:70%;">DL</span>
</td>
<td id="S3.T1.10.10.6" class="ltx_td ltx_nopad_r ltx_align_center">
<span id="S3.T1.10.10.6.1" class="ltx_text" style="font-size:70%;">ML</span><math id="S3.T1.10.10.6.m1.1" class="ltx_Math" alttext="\mid" display="inline"><semantics id="S3.T1.10.10.6.m1.1a"><mo mathsize="70%" id="S3.T1.10.10.6.m1.1.1" xref="S3.T1.10.10.6.m1.1.1.cmml">âˆ£</mo><annotation-xml encoding="MathML-Content" id="S3.T1.10.10.6.m1.1b"><ci id="S3.T1.10.10.6.m1.1.1.cmml" xref="S3.T1.10.10.6.m1.1.1">âˆ£</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.10.10.6.m1.1c">\mid</annotation></semantics></math><span id="S3.T1.10.10.6.2" class="ltx_text" style="font-size:70%;">DL</span>
</td>
</tr>
<tr id="S3.T1.21.21" class="ltx_tr">
<td id="S3.T1.21.21.12" class="ltx_td ltx_align_left"><span id="S3.T1.21.21.12.1" class="ltx_text" style="font-size:70%;">Backend</span></td>
<td id="S3.T1.12.12.2" class="ltx_td ltx_align_center">
<span id="S3.T1.12.12.2.1" class="ltx_text" style="font-size:70%;">Torch</span><math id="S3.T1.11.11.1.m1.1" class="ltx_Math" alttext="\mid" display="inline"><semantics id="S3.T1.11.11.1.m1.1a"><mo mathsize="70%" id="S3.T1.11.11.1.m1.1.1" xref="S3.T1.11.11.1.m1.1.1.cmml">âˆ£</mo><annotation-xml encoding="MathML-Content" id="S3.T1.11.11.1.m1.1b"><ci id="S3.T1.11.11.1.m1.1.1.cmml" xref="S3.T1.11.11.1.m1.1.1">âˆ£</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.11.11.1.m1.1c">\mid</annotation></semantics></math><span id="S3.T1.12.12.2.2" class="ltx_text" style="font-size:70%;">TF</span><math id="S3.T1.12.12.2.m2.1" class="ltx_Math" alttext="\mid" display="inline"><semantics id="S3.T1.12.12.2.m2.1a"><mo mathsize="70%" id="S3.T1.12.12.2.m2.1.1" xref="S3.T1.12.12.2.m2.1.1.cmml">âˆ£</mo><annotation-xml encoding="MathML-Content" id="S3.T1.12.12.2.m2.1b"><ci id="S3.T1.12.12.2.m2.1.1.cmml" xref="S3.T1.12.12.2.m2.1.1">âˆ£</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.12.12.2.m2.1c">\mid</annotation></semantics></math><span id="S3.T1.12.12.2.3" class="ltx_text" style="font-size:70%;">MONAI</span>
</td>
<td id="S3.T1.15.15.5" class="ltx_td ltx_align_center">
<span id="S3.T1.15.15.5.1" class="ltx_text" style="font-size:70%;">Torch</span><math id="S3.T1.13.13.3.m1.1" class="ltx_Math" alttext="\mid" display="inline"><semantics id="S3.T1.13.13.3.m1.1a"><mo mathsize="70%" id="S3.T1.13.13.3.m1.1.1" xref="S3.T1.13.13.3.m1.1.1.cmml">âˆ£</mo><annotation-xml encoding="MathML-Content" id="S3.T1.13.13.3.m1.1b"><ci id="S3.T1.13.13.3.m1.1.1.cmml" xref="S3.T1.13.13.3.m1.1.1">âˆ£</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.13.13.3.m1.1c">\mid</annotation></semantics></math><span id="S3.T1.15.15.5.2" class="ltx_text" style="font-size:70%;">TF</span><math id="S3.T1.14.14.4.m2.1" class="ltx_Math" alttext="\mid" display="inline"><semantics id="S3.T1.14.14.4.m2.1a"><mo mathsize="70%" id="S3.T1.14.14.4.m2.1.1" xref="S3.T1.14.14.4.m2.1.1.cmml">âˆ£</mo><annotation-xml encoding="MathML-Content" id="S3.T1.14.14.4.m2.1b"><ci id="S3.T1.14.14.4.m2.1.1.cmml" xref="S3.T1.14.14.4.m2.1.1">âˆ£</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.14.14.4.m2.1c">\mid</annotation></semantics></math><span id="S3.T1.15.15.5.3" class="ltx_text" style="font-size:70%;">MX</span><math id="S3.T1.15.15.5.m3.1" class="ltx_Math" alttext="\mid" display="inline"><semantics id="S3.T1.15.15.5.m3.1a"><mo mathsize="70%" id="S3.T1.15.15.5.m3.1.1" xref="S3.T1.15.15.5.m3.1.1.cmml">âˆ£</mo><annotation-xml encoding="MathML-Content" id="S3.T1.15.15.5.m3.1b"><ci id="S3.T1.15.15.5.m3.1.1.cmml" xref="S3.T1.15.15.5.m3.1.1">âˆ£</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.15.15.5.m3.1c">\mid</annotation></semantics></math><span id="S3.T1.15.15.5.4" class="ltx_text" style="font-size:70%;">JAX</span>
</td>
<td id="S3.T1.18.18.8" class="ltx_td ltx_align_center">
<span id="S3.T1.18.18.8.1" class="ltx_text" style="font-size:70%;">Torch</span><math id="S3.T1.16.16.6.m1.1" class="ltx_Math" alttext="\mid" display="inline"><semantics id="S3.T1.16.16.6.m1.1a"><mo mathsize="70%" id="S3.T1.16.16.6.m1.1.1" xref="S3.T1.16.16.6.m1.1.1.cmml">âˆ£</mo><annotation-xml encoding="MathML-Content" id="S3.T1.16.16.6.m1.1b"><ci id="S3.T1.16.16.6.m1.1.1.cmml" xref="S3.T1.16.16.6.m1.1.1">âˆ£</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.16.16.6.m1.1c">\mid</annotation></semantics></math><span id="S3.T1.18.18.8.2" class="ltx_text" style="font-size:70%;">TF</span><math id="S3.T1.17.17.7.m2.1" class="ltx_Math" alttext="\mid" display="inline"><semantics id="S3.T1.17.17.7.m2.1a"><mo mathsize="70%" id="S3.T1.17.17.7.m2.1.1" xref="S3.T1.17.17.7.m2.1.1.cmml">âˆ£</mo><annotation-xml encoding="MathML-Content" id="S3.T1.17.17.7.m2.1b"><ci id="S3.T1.17.17.7.m2.1.1.cmml" xref="S3.T1.17.17.7.m2.1.1">âˆ£</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.17.17.7.m2.1c">\mid</annotation></semantics></math><span id="S3.T1.18.18.8.3" class="ltx_text" style="font-size:70%;">MX</span><math id="S3.T1.18.18.8.m3.1" class="ltx_Math" alttext="\mid" display="inline"><semantics id="S3.T1.18.18.8.m3.1a"><mo mathsize="70%" id="S3.T1.18.18.8.m3.1.1" xref="S3.T1.18.18.8.m3.1.1.cmml">âˆ£</mo><annotation-xml encoding="MathML-Content" id="S3.T1.18.18.8.m3.1b"><ci id="S3.T1.18.18.8.m3.1.1.cmml" xref="S3.T1.18.18.8.m3.1.1">âˆ£</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.18.18.8.m3.1c">\mid</annotation></semantics></math><span id="S3.T1.18.18.8.4" class="ltx_text" style="font-size:70%;">JAX</span>
</td>
<td id="S3.T1.19.19.9" class="ltx_td ltx_align_center">
<span id="S3.T1.19.19.9.1" class="ltx_text" style="font-size:70%;">Torch</span><math id="S3.T1.19.19.9.m1.1" class="ltx_Math" alttext="\mid" display="inline"><semantics id="S3.T1.19.19.9.m1.1a"><mo mathsize="70%" id="S3.T1.19.19.9.m1.1.1" xref="S3.T1.19.19.9.m1.1.1.cmml">âˆ£</mo><annotation-xml encoding="MathML-Content" id="S3.T1.19.19.9.m1.1b"><ci id="S3.T1.19.19.9.m1.1.1.cmml" xref="S3.T1.19.19.9.m1.1.1">âˆ£</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.19.19.9.m1.1c">\mid</annotation></semantics></math><span id="S3.T1.19.19.9.2" class="ltx_text" style="font-size:70%;">TF</span>
</td>
<td id="S3.T1.20.20.10" class="ltx_td ltx_align_center">
<span id="S3.T1.20.20.10.1" class="ltx_text" style="font-size:70%;">Torch</span><math id="S3.T1.20.20.10.m1.1" class="ltx_Math" alttext="\mid" display="inline"><semantics id="S3.T1.20.20.10.m1.1a"><mo mathsize="70%" id="S3.T1.20.20.10.m1.1.1" xref="S3.T1.20.20.10.m1.1.1.cmml">âˆ£</mo><annotation-xml encoding="MathML-Content" id="S3.T1.20.20.10.m1.1b"><ci id="S3.T1.20.20.10.m1.1.1.cmml" xref="S3.T1.20.20.10.m1.1.1">âˆ£</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.20.20.10.m1.1c">\mid</annotation></semantics></math><span id="S3.T1.20.20.10.2" class="ltx_text" style="font-size:70%;">TF</span>
</td>
<td id="S3.T1.21.21.11" class="ltx_td ltx_nopad_r ltx_align_center">
<span id="S3.T1.21.21.11.1" class="ltx_text" style="font-size:70%;">Torch</span><math id="S3.T1.21.21.11.m1.1" class="ltx_Math" alttext="\mid" display="inline"><semantics id="S3.T1.21.21.11.m1.1a"><mo mathsize="70%" id="S3.T1.21.21.11.m1.1.1" xref="S3.T1.21.21.11.m1.1.1.cmml">âˆ£</mo><annotation-xml encoding="MathML-Content" id="S3.T1.21.21.11.m1.1b"><ci id="S3.T1.21.21.11.m1.1.1.cmml" xref="S3.T1.21.21.11.m1.1.1">âˆ£</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.21.21.11.m1.1c">\mid</annotation></semantics></math><span id="S3.T1.21.21.11.2" class="ltx_text" style="font-size:70%;">TF</span>
</td>
</tr>
<tr id="S3.T1.46.53.7" class="ltx_tr">
<td id="S3.T1.46.53.7.1" class="ltx_td ltx_align_left"><span id="S3.T1.46.53.7.1.1" class="ltx_text" style="font-size:70%;">LocalOpt</span></td>
<td id="S3.T1.46.53.7.2" class="ltx_td ltx_align_center"><span id="S3.T1.46.53.7.2.1" class="ltx_text" style="font-size:70%;">âœ“</span></td>
<td id="S3.T1.46.53.7.3" class="ltx_td ltx_align_center"><span id="S3.T1.46.53.7.3.1" class="ltx_text" style="font-size:70%;">âœ“</span></td>
<td id="S3.T1.46.53.7.4" class="ltx_td ltx_align_center"><span id="S3.T1.46.53.7.4.1" class="ltx_text" style="font-size:70%;">âœ“</span></td>
<td id="S3.T1.46.53.7.5" class="ltx_td ltx_align_center"><span id="S3.T1.46.53.7.5.1" class="ltx_text" style="font-size:70%;">âœ“</span></td>
<td id="S3.T1.46.53.7.6" class="ltx_td ltx_align_center"><span id="S3.T1.46.53.7.6.1" class="ltx_text" style="font-size:70%;">âœ“</span></td>
<td id="S3.T1.46.53.7.7" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.T1.46.53.7.7.1" class="ltx_text" style="font-size:70%;">âœ“</span></td>
</tr>
<tr id="S3.T1.46.54.8" class="ltx_tr">
<td id="S3.T1.46.54.8.1" class="ltx_td ltx_align_left"><span id="S3.T1.46.54.8.1.1" class="ltx_text" style="font-size:70%;">GlobalOpt</span></td>
<td id="S3.T1.46.54.8.2" class="ltx_td ltx_align_center"><span id="S3.T1.46.54.8.2.1" class="ltx_text" style="font-size:70%;">âœ“</span></td>
<td id="S3.T1.46.54.8.3" class="ltx_td ltx_align_center"><span id="S3.T1.46.54.8.3.1" class="ltx_text" style="font-size:70%;">âœ“</span></td>
<td id="S3.T1.46.54.8.4" class="ltx_td ltx_align_center"><span id="S3.T1.46.54.8.4.1" class="ltx_text" style="font-size:70%;">âœ“</span></td>
<td id="S3.T1.46.54.8.5" class="ltx_td ltx_align_center"><span id="S3.T1.46.54.8.5.1" class="ltx_text" style="font-size:70%;">âœ“</span></td>
<td id="S3.T1.46.54.8.6" class="ltx_td ltx_align_center"><span id="S3.T1.46.54.8.6.1" class="ltx_text" style="font-size:70%;">âœ“</span></td>
<td id="S3.T1.46.54.8.7" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.T1.46.54.8.7.1" class="ltx_text" style="font-size:70%;">âœ“</span></td>
</tr>
<tr id="S3.T1.46.55.9" class="ltx_tr">
<td id="S3.T1.46.55.9.1" class="ltx_td ltx_align_left"><span id="S3.T1.46.55.9.1.1" class="ltx_text ltx_font_bold" style="font-size:70%;">Data Partitioning</span></td>
<td id="S3.T1.46.55.9.2" class="ltx_td"></td>
<td id="S3.T1.46.55.9.3" class="ltx_td"></td>
<td id="S3.T1.46.55.9.4" class="ltx_td"></td>
<td id="S3.T1.46.55.9.5" class="ltx_td"></td>
<td id="S3.T1.46.55.9.6" class="ltx_td"></td>
<td id="S3.T1.46.55.9.7" class="ltx_td ltx_nopad_r"></td>
</tr>
<tr id="S3.T1.46.56.10" class="ltx_tr">
<td id="S3.T1.46.56.10.1" class="ltx_td ltx_align_left"><span id="S3.T1.46.56.10.1.1" class="ltx_text" style="font-size:70%;">Horizontal</span></td>
<td id="S3.T1.46.56.10.2" class="ltx_td ltx_align_center"><span id="S3.T1.46.56.10.2.1" class="ltx_text" style="font-size:70%;">âœ“</span></td>
<td id="S3.T1.46.56.10.3" class="ltx_td ltx_align_center"><span id="S3.T1.46.56.10.3.1" class="ltx_text" style="font-size:70%;">âœ“</span></td>
<td id="S3.T1.46.56.10.4" class="ltx_td ltx_align_center"><span id="S3.T1.46.56.10.4.1" class="ltx_text" style="font-size:70%;">âœ“</span></td>
<td id="S3.T1.46.56.10.5" class="ltx_td ltx_align_center"><span id="S3.T1.46.56.10.5.1" class="ltx_text" style="font-size:70%;">âœ“</span></td>
<td id="S3.T1.46.56.10.6" class="ltx_td ltx_align_center"><span id="S3.T1.46.56.10.6.1" class="ltx_text" style="font-size:70%;">âœ“</span></td>
<td id="S3.T1.46.56.10.7" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.T1.46.56.10.7.1" class="ltx_text" style="font-size:70%;">âœ“</span></td>
</tr>
<tr id="S3.T1.27.27" class="ltx_tr">
<td id="S3.T1.27.27.7" class="ltx_td ltx_align_left"><span id="S3.T1.27.27.7.1" class="ltx_text" style="font-size:70%;">Vertical</span></td>
<td id="S3.T1.22.22.1" class="ltx_td ltx_align_center"><math id="S3.T1.22.22.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S3.T1.22.22.1.m1.1a"><mo mathsize="70%" id="S3.T1.22.22.1.m1.1.1" xref="S3.T1.22.22.1.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S3.T1.22.22.1.m1.1b"><times id="S3.T1.22.22.1.m1.1.1.cmml" xref="S3.T1.22.22.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.22.22.1.m1.1c">\times</annotation></semantics></math></td>
<td id="S3.T1.23.23.2" class="ltx_td ltx_align_center"><math id="S3.T1.23.23.2.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S3.T1.23.23.2.m1.1a"><mo mathsize="70%" id="S3.T1.23.23.2.m1.1.1" xref="S3.T1.23.23.2.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S3.T1.23.23.2.m1.1b"><times id="S3.T1.23.23.2.m1.1.1.cmml" xref="S3.T1.23.23.2.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.23.23.2.m1.1c">\times</annotation></semantics></math></td>
<td id="S3.T1.24.24.3" class="ltx_td ltx_align_center"><math id="S3.T1.24.24.3.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S3.T1.24.24.3.m1.1a"><mo mathsize="70%" id="S3.T1.24.24.3.m1.1.1" xref="S3.T1.24.24.3.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S3.T1.24.24.3.m1.1b"><times id="S3.T1.24.24.3.m1.1.1.cmml" xref="S3.T1.24.24.3.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.24.24.3.m1.1c">\times</annotation></semantics></math></td>
<td id="S3.T1.25.25.4" class="ltx_td ltx_align_center"><math id="S3.T1.25.25.4.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S3.T1.25.25.4.m1.1a"><mo mathsize="70%" id="S3.T1.25.25.4.m1.1.1" xref="S3.T1.25.25.4.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S3.T1.25.25.4.m1.1b"><times id="S3.T1.25.25.4.m1.1.1.cmml" xref="S3.T1.25.25.4.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.25.25.4.m1.1c">\times</annotation></semantics></math></td>
<td id="S3.T1.26.26.5" class="ltx_td ltx_align_center"><math id="S3.T1.26.26.5.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S3.T1.26.26.5.m1.1a"><mo mathsize="70%" id="S3.T1.26.26.5.m1.1.1" xref="S3.T1.26.26.5.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S3.T1.26.26.5.m1.1b"><times id="S3.T1.26.26.5.m1.1.1.cmml" xref="S3.T1.26.26.5.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.26.26.5.m1.1c">\times</annotation></semantics></math></td>
<td id="S3.T1.27.27.6" class="ltx_td ltx_nopad_r ltx_align_center"><math id="S3.T1.27.27.6.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S3.T1.27.27.6.m1.1a"><mo mathsize="70%" id="S3.T1.27.27.6.m1.1.1" xref="S3.T1.27.27.6.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S3.T1.27.27.6.m1.1b"><times id="S3.T1.27.27.6.m1.1.1.cmml" xref="S3.T1.27.27.6.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.27.27.6.m1.1c">\times</annotation></semantics></math></td>
</tr>
<tr id="S3.T1.46.57.11" class="ltx_tr">
<td id="S3.T1.46.57.11.1" class="ltx_td ltx_align_left"><span id="S3.T1.46.57.11.1.1" class="ltx_text ltx_font_bold" style="font-size:70%;">Privacy &amp; Security</span></td>
<td id="S3.T1.46.57.11.2" class="ltx_td"></td>
<td id="S3.T1.46.57.11.3" class="ltx_td"></td>
<td id="S3.T1.46.57.11.4" class="ltx_td"></td>
<td id="S3.T1.46.57.11.5" class="ltx_td"></td>
<td id="S3.T1.46.57.11.6" class="ltx_td"></td>
<td id="S3.T1.46.57.11.7" class="ltx_td ltx_nopad_r"></td>
</tr>
<tr id="S3.T1.46.58.12" class="ltx_tr">
<td id="S3.T1.46.58.12.1" class="ltx_td ltx_align_left"><span id="S3.T1.46.58.12.1.1" class="ltx_text" style="font-size:70%;">Private Training</span></td>
<td id="S3.T1.46.58.12.2" class="ltx_td ltx_align_center"><span id="S3.T1.46.58.12.2.1" class="ltx_text" style="font-size:70%;">âœ“</span></td>
<td id="S3.T1.46.58.12.3" class="ltx_td ltx_align_center"><span id="S3.T1.46.58.12.3.1" class="ltx_text" style="font-size:70%;">âœ“</span></td>
<td id="S3.T1.46.58.12.4" class="ltx_td ltx_align_center"><span id="S3.T1.46.58.12.4.1" class="ltx_text" style="font-size:70%;">âœ“</span></td>
<td id="S3.T1.46.58.12.5" class="ltx_td ltx_align_center"><span id="S3.T1.46.58.12.5.1" class="ltx_text" style="font-size:70%;">âœ“</span></td>
<td id="S3.T1.46.58.12.6" class="ltx_td ltx_align_center"><span id="S3.T1.46.58.12.6.1" class="ltx_text" style="font-size:70%;">âœ“</span></td>
<td id="S3.T1.46.58.12.7" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.T1.46.58.12.7.1" class="ltx_text" style="font-size:70%;">âœ“</span></td>
</tr>
<tr id="S3.T1.29.29" class="ltx_tr">
<td id="S3.T1.29.29.3" class="ltx_td ltx_align_left"><span id="S3.T1.29.29.3.1" class="ltx_text" style="font-size:70%;">Secure Aggregation</span></td>
<td id="S3.T1.29.29.4" class="ltx_td ltx_align_center"><span id="S3.T1.29.29.4.1" class="ltx_text" style="font-size:70%;">FHE</span></td>
<td id="S3.T1.28.28.1" class="ltx_td ltx_align_center">
<span id="S3.T1.28.28.1.1" class="ltx_text" style="font-size:70%;">Masking</span><math id="S3.T1.28.28.1.m1.1" class="ltx_Math" alttext="\mid" display="inline"><semantics id="S3.T1.28.28.1.m1.1a"><mo mathsize="70%" id="S3.T1.28.28.1.m1.1.1" xref="S3.T1.28.28.1.m1.1.1.cmml">âˆ£</mo><annotation-xml encoding="MathML-Content" id="S3.T1.28.28.1.m1.1b"><ci id="S3.T1.28.28.1.m1.1.1.cmml" xref="S3.T1.28.28.1.m1.1.1">âˆ£</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.28.28.1.m1.1c">\mid</annotation></semantics></math><span id="S3.T1.28.28.1.2" class="ltx_text" style="font-size:70%;">FHE</span>
</td>
<td id="S3.T1.29.29.2" class="ltx_td ltx_align_center">
<span id="S3.T1.29.29.2.1" class="ltx_text" style="font-size:70%;">Masking</span><math id="S3.T1.29.29.2.m1.1" class="ltx_Math" alttext="\mid" display="inline"><semantics id="S3.T1.29.29.2.m1.1a"><mo mathsize="70%" id="S3.T1.29.29.2.m1.1.1" xref="S3.T1.29.29.2.m1.1.1.cmml">âˆ£</mo><annotation-xml encoding="MathML-Content" id="S3.T1.29.29.2.m1.1b"><ci id="S3.T1.29.29.2.m1.1.1.cmml" xref="S3.T1.29.29.2.m1.1.1">âˆ£</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.29.29.2.m1.1c">\mid</annotation></semantics></math><span id="S3.T1.29.29.2.2" class="ltx_text" style="font-size:70%;">FHE</span>
</td>
<td id="S3.T1.29.29.5" class="ltx_td ltx_align_center"><span id="S3.T1.29.29.5.1" class="ltx_text" style="font-size:70%;">FHE</span></td>
<td id="S3.T1.29.29.6" class="ltx_td ltx_align_center"><span id="S3.T1.29.29.6.1" class="ltx_text" style="font-size:70%;">TEE</span></td>
<td id="S3.T1.29.29.7" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.T1.29.29.7.1" class="ltx_text" style="font-size:70%;">FHE</span></td>
</tr>
<tr id="S3.T1.46.59.13" class="ltx_tr">
<td id="S3.T1.46.59.13.1" class="ltx_td ltx_align_left"><span id="S3.T1.46.59.13.1.1" class="ltx_text" style="font-size:70%;">Crypto Library</span></td>
<td id="S3.T1.46.59.13.2" class="ltx_td ltx_align_center"><span id="S3.T1.46.59.13.2.1" class="ltx_text" style="font-size:70%;">TenSeal</span></td>
<td id="S3.T1.46.59.13.3" class="ltx_td ltx_align_center"><span id="S3.T1.46.59.13.3.1" class="ltx_text" style="font-size:70%;">native</span></td>
<td id="S3.T1.46.59.13.4" class="ltx_td ltx_align_center"><span id="S3.T1.46.59.13.4.1" class="ltx_text" style="font-size:70%;">native</span></td>
<td id="S3.T1.46.59.13.5" class="ltx_td ltx_align_center"><span id="S3.T1.46.59.13.5.1" class="ltx_text" style="font-size:70%;">HElayers</span></td>
<td id="S3.T1.46.59.13.6" class="ltx_td ltx_align_center"><span id="S3.T1.46.59.13.6.1" class="ltx_text" style="font-size:70%;">Graphene</span></td>
<td id="S3.T1.46.59.13.7" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.T1.46.59.13.7.1" class="ltx_text" style="font-size:70%;">PALISADE</span></td>
</tr>
<tr id="S3.T1.46.60.14" class="ltx_tr">
<td id="S3.T1.46.60.14.1" class="ltx_td ltx_align_left"><span id="S3.T1.46.60.14.1.1" class="ltx_text ltx_font_bold" style="font-size:70%;">Communication</span></td>
<td id="S3.T1.46.60.14.2" class="ltx_td"></td>
<td id="S3.T1.46.60.14.3" class="ltx_td"></td>
<td id="S3.T1.46.60.14.4" class="ltx_td"></td>
<td id="S3.T1.46.60.14.5" class="ltx_td"></td>
<td id="S3.T1.46.60.14.6" class="ltx_td"></td>
<td id="S3.T1.46.60.14.7" class="ltx_td ltx_nopad_r"></td>
</tr>
<tr id="S3.T1.46.61.15" class="ltx_tr">
<td id="S3.T1.46.61.15.1" class="ltx_td ltx_align_left"><span id="S3.T1.46.61.15.1.1" class="ltx_text" style="font-size:70%;">Centralized</span></td>
<td id="S3.T1.46.61.15.2" class="ltx_td ltx_align_center"><span id="S3.T1.46.61.15.2.1" class="ltx_text" style="font-size:70%;">âœ“</span></td>
<td id="S3.T1.46.61.15.3" class="ltx_td ltx_align_center"><span id="S3.T1.46.61.15.3.1" class="ltx_text" style="font-size:70%;">âœ“</span></td>
<td id="S3.T1.46.61.15.4" class="ltx_td ltx_align_center"><span id="S3.T1.46.61.15.4.1" class="ltx_text" style="font-size:70%;">âœ“</span></td>
<td id="S3.T1.46.61.15.5" class="ltx_td ltx_align_center"><span id="S3.T1.46.61.15.5.1" class="ltx_text" style="font-size:70%;">âœ“</span></td>
<td id="S3.T1.46.61.15.6" class="ltx_td ltx_align_center"><span id="S3.T1.46.61.15.6.1" class="ltx_text" style="font-size:70%;">âœ“</span></td>
<td id="S3.T1.46.61.15.7" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.T1.46.61.15.7.1" class="ltx_text" style="font-size:70%;">âœ“</span></td>
</tr>
<tr id="S3.T1.35.35" class="ltx_tr">
<td id="S3.T1.35.35.7" class="ltx_td ltx_align_left"><span id="S3.T1.35.35.7.1" class="ltx_text" style="font-size:70%;">Decentralized</span></td>
<td id="S3.T1.30.30.1" class="ltx_td ltx_align_center"><math id="S3.T1.30.30.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S3.T1.30.30.1.m1.1a"><mo mathsize="70%" id="S3.T1.30.30.1.m1.1.1" xref="S3.T1.30.30.1.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S3.T1.30.30.1.m1.1b"><times id="S3.T1.30.30.1.m1.1.1.cmml" xref="S3.T1.30.30.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.30.30.1.m1.1c">\times</annotation></semantics></math></td>
<td id="S3.T1.31.31.2" class="ltx_td ltx_align_center"><math id="S3.T1.31.31.2.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S3.T1.31.31.2.m1.1a"><mo mathsize="70%" id="S3.T1.31.31.2.m1.1.1" xref="S3.T1.31.31.2.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S3.T1.31.31.2.m1.1b"><times id="S3.T1.31.31.2.m1.1.1.cmml" xref="S3.T1.31.31.2.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.31.31.2.m1.1c">\times</annotation></semantics></math></td>
<td id="S3.T1.32.32.3" class="ltx_td ltx_align_center"><math id="S3.T1.32.32.3.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S3.T1.32.32.3.m1.1a"><mi mathsize="70%" mathvariant="normal" id="S3.T1.32.32.3.m1.1.1" xref="S3.T1.32.32.3.m1.1.1.cmml">âœ“</mi><annotation-xml encoding="MathML-Content" id="S3.T1.32.32.3.m1.1b"><ci id="S3.T1.32.32.3.m1.1.1.cmml" xref="S3.T1.32.32.3.m1.1.1">âœ“</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.32.32.3.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S3.T1.33.33.4" class="ltx_td ltx_align_center"><math id="S3.T1.33.33.4.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S3.T1.33.33.4.m1.1a"><mo mathsize="70%" id="S3.T1.33.33.4.m1.1.1" xref="S3.T1.33.33.4.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S3.T1.33.33.4.m1.1b"><times id="S3.T1.33.33.4.m1.1.1.cmml" xref="S3.T1.33.33.4.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.33.33.4.m1.1c">\times</annotation></semantics></math></td>
<td id="S3.T1.34.34.5" class="ltx_td ltx_align_center"><math id="S3.T1.34.34.5.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S3.T1.34.34.5.m1.1a"><mo mathsize="70%" id="S3.T1.34.34.5.m1.1.1" xref="S3.T1.34.34.5.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S3.T1.34.34.5.m1.1b"><times id="S3.T1.34.34.5.m1.1.1.cmml" xref="S3.T1.34.34.5.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.34.34.5.m1.1c">\times</annotation></semantics></math></td>
<td id="S3.T1.35.35.6" class="ltx_td ltx_nopad_r ltx_align_center"><math id="S3.T1.35.35.6.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S3.T1.35.35.6.m1.1a"><mo mathsize="70%" id="S3.T1.35.35.6.m1.1.1" xref="S3.T1.35.35.6.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S3.T1.35.35.6.m1.1b"><times id="S3.T1.35.35.6.m1.1.1.cmml" xref="S3.T1.35.35.6.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.35.35.6.m1.1c">\times</annotation></semantics></math></td>
</tr>
<tr id="S3.T1.41.41" class="ltx_tr">
<td id="S3.T1.41.41.7" class="ltx_td ltx_align_left"><span id="S3.T1.41.41.7.1" class="ltx_text" style="font-size:70%;">Hierarchical</span></td>
<td id="S3.T1.36.36.1" class="ltx_td ltx_align_center"><math id="S3.T1.36.36.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S3.T1.36.36.1.m1.1a"><mo mathsize="70%" id="S3.T1.36.36.1.m1.1.1" xref="S3.T1.36.36.1.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S3.T1.36.36.1.m1.1b"><times id="S3.T1.36.36.1.m1.1.1.cmml" xref="S3.T1.36.36.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.36.36.1.m1.1c">\times</annotation></semantics></math></td>
<td id="S3.T1.37.37.2" class="ltx_td ltx_align_center"><math id="S3.T1.37.37.2.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S3.T1.37.37.2.m1.1a"><mo mathsize="70%" id="S3.T1.37.37.2.m1.1.1" xref="S3.T1.37.37.2.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S3.T1.37.37.2.m1.1b"><times id="S3.T1.37.37.2.m1.1.1.cmml" xref="S3.T1.37.37.2.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.37.37.2.m1.1c">\times</annotation></semantics></math></td>
<td id="S3.T1.38.38.3" class="ltx_td ltx_align_center"><math id="S3.T1.38.38.3.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S3.T1.38.38.3.m1.1a"><mo mathsize="70%" id="S3.T1.38.38.3.m1.1.1" xref="S3.T1.38.38.3.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S3.T1.38.38.3.m1.1b"><times id="S3.T1.38.38.3.m1.1.1.cmml" xref="S3.T1.38.38.3.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.38.38.3.m1.1c">\times</annotation></semantics></math></td>
<td id="S3.T1.39.39.4" class="ltx_td ltx_align_center"><math id="S3.T1.39.39.4.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S3.T1.39.39.4.m1.1a"><mo mathsize="70%" id="S3.T1.39.39.4.m1.1.1" xref="S3.T1.39.39.4.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S3.T1.39.39.4.m1.1b"><times id="S3.T1.39.39.4.m1.1.1.cmml" xref="S3.T1.39.39.4.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.39.39.4.m1.1c">\times</annotation></semantics></math></td>
<td id="S3.T1.40.40.5" class="ltx_td ltx_align_center"><math id="S3.T1.40.40.5.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S3.T1.40.40.5.m1.1a"><mo mathsize="70%" id="S3.T1.40.40.5.m1.1.1" xref="S3.T1.40.40.5.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S3.T1.40.40.5.m1.1b"><times id="S3.T1.40.40.5.m1.1.1.cmml" xref="S3.T1.40.40.5.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.40.40.5.m1.1c">\times</annotation></semantics></math></td>
<td id="S3.T1.41.41.6" class="ltx_td ltx_nopad_r ltx_align_center"><math id="S3.T1.41.41.6.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S3.T1.41.41.6.m1.1a"><mo mathsize="70%" id="S3.T1.41.41.6.m1.1.1" xref="S3.T1.41.41.6.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S3.T1.41.41.6.m1.1b"><times id="S3.T1.41.41.6.m1.1.1.cmml" xref="S3.T1.41.41.6.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.41.41.6.m1.1c">\times</annotation></semantics></math></td>
</tr>
<tr id="S3.T1.46.62.16" class="ltx_tr">
<td id="S3.T1.46.62.16.1" class="ltx_td ltx_align_left"><span id="S3.T1.46.62.16.1.1" class="ltx_text" style="font-size:70%;">TLS</span></td>
<td id="S3.T1.46.62.16.2" class="ltx_td ltx_align_center"><span id="S3.T1.46.62.16.2.1" class="ltx_text" style="font-size:70%;">âœ“</span></td>
<td id="S3.T1.46.62.16.3" class="ltx_td ltx_align_center"><span id="S3.T1.46.62.16.3.1" class="ltx_text" style="font-size:70%;">âœ“</span></td>
<td id="S3.T1.46.62.16.4" class="ltx_td ltx_align_center"><span id="S3.T1.46.62.16.4.1" class="ltx_text" style="font-size:70%;">âœ“</span></td>
<td id="S3.T1.46.62.16.5" class="ltx_td ltx_align_center"><span id="S3.T1.46.62.16.5.1" class="ltx_text" style="font-size:70%;">âœ“</span></td>
<td id="S3.T1.46.62.16.6" class="ltx_td ltx_align_center"><span id="S3.T1.46.62.16.6.1" class="ltx_text" style="font-size:70%;">âœ“</span></td>
<td id="S3.T1.46.62.16.7" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.T1.46.62.16.7.1" class="ltx_text" style="font-size:70%;">âœ“</span></td>
</tr>
<tr id="S3.T1.46.63.17" class="ltx_tr">
<td id="S3.T1.46.63.17.1" class="ltx_td ltx_align_left"><span id="S3.T1.46.63.17.1.1" class="ltx_text" style="font-size:70%;">Network</span></td>
<td id="S3.T1.46.63.17.2" class="ltx_td ltx_align_center"><span id="S3.T1.46.63.17.2.1" class="ltx_text" style="font-size:70%;">gRPC</span></td>
<td id="S3.T1.46.63.17.3" class="ltx_td ltx_align_center"><span id="S3.T1.46.63.17.3.1" class="ltx_text" style="font-size:70%;">gRPC</span></td>
<td id="S3.T1.46.63.17.4" class="ltx_td ltx_align_center"><span id="S3.T1.46.63.17.4.1" class="ltx_text" style="font-size:70%;">MPI</span></td>
<td id="S3.T1.46.63.17.5" class="ltx_td ltx_align_center"><span id="S3.T1.46.63.17.5.1" class="ltx_text" style="font-size:70%;">AMQP</span></td>
<td id="S3.T1.46.63.17.6" class="ltx_td ltx_align_center"><span id="S3.T1.46.63.17.6.1" class="ltx_text" style="font-size:70%;">gRPC</span></td>
<td id="S3.T1.46.63.17.7" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.T1.46.63.17.7.1" class="ltx_text" style="font-size:70%;">gRPC</span></td>
</tr>
<tr id="S3.T1.46.64.18" class="ltx_tr">
<td id="S3.T1.46.64.18.1" class="ltx_td ltx_align_left"><span id="S3.T1.46.64.18.1.1" class="ltx_text ltx_font_bold" style="font-size:70%;">Communication Protocol</span></td>
<td id="S3.T1.46.64.18.2" class="ltx_td"></td>
<td id="S3.T1.46.64.18.3" class="ltx_td"></td>
<td id="S3.T1.46.64.18.4" class="ltx_td"></td>
<td id="S3.T1.46.64.18.5" class="ltx_td"></td>
<td id="S3.T1.46.64.18.6" class="ltx_td"></td>
<td id="S3.T1.46.64.18.7" class="ltx_td ltx_nopad_r"></td>
</tr>
<tr id="S3.T1.46.65.19" class="ltx_tr">
<td id="S3.T1.46.65.19.1" class="ltx_td ltx_align_left"><span id="S3.T1.46.65.19.1.1" class="ltx_text" style="font-size:70%;">Synchronous</span></td>
<td id="S3.T1.46.65.19.2" class="ltx_td ltx_align_center"><span id="S3.T1.46.65.19.2.1" class="ltx_text" style="font-size:70%;">âœ“</span></td>
<td id="S3.T1.46.65.19.3" class="ltx_td ltx_align_center"><span id="S3.T1.46.65.19.3.1" class="ltx_text" style="font-size:70%;">âœ“</span></td>
<td id="S3.T1.46.65.19.4" class="ltx_td ltx_align_center"><span id="S3.T1.46.65.19.4.1" class="ltx_text" style="font-size:70%;">âœ“</span></td>
<td id="S3.T1.46.65.19.5" class="ltx_td ltx_align_center"><span id="S3.T1.46.65.19.5.1" class="ltx_text" style="font-size:70%;">âœ“</span></td>
<td id="S3.T1.46.65.19.6" class="ltx_td ltx_align_center"><span id="S3.T1.46.65.19.6.1" class="ltx_text" style="font-size:70%;">âœ“</span></td>
<td id="S3.T1.46.65.19.7" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.T1.46.65.19.7.1" class="ltx_text" style="font-size:70%;">âœ“</span></td>
</tr>
<tr id="S3.T1.46.46" class="ltx_tr">
<td id="S3.T1.46.46.6" class="ltx_td ltx_align_left"><span id="S3.T1.46.46.6.1" class="ltx_text" style="font-size:70%;">Asynchronous</span></td>
<td id="S3.T1.42.42.1" class="ltx_td ltx_align_center"><math id="S3.T1.42.42.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S3.T1.42.42.1.m1.1a"><mo mathsize="70%" id="S3.T1.42.42.1.m1.1.1" xref="S3.T1.42.42.1.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S3.T1.42.42.1.m1.1b"><times id="S3.T1.42.42.1.m1.1.1.cmml" xref="S3.T1.42.42.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.42.42.1.m1.1c">\times</annotation></semantics></math></td>
<td id="S3.T1.43.43.2" class="ltx_td ltx_align_center"><math id="S3.T1.43.43.2.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S3.T1.43.43.2.m1.1a"><mo mathsize="70%" id="S3.T1.43.43.2.m1.1.1" xref="S3.T1.43.43.2.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S3.T1.43.43.2.m1.1b"><times id="S3.T1.43.43.2.m1.1.1.cmml" xref="S3.T1.43.43.2.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.43.43.2.m1.1c">\times</annotation></semantics></math></td>
<td id="S3.T1.44.44.3" class="ltx_td ltx_align_center"><math id="S3.T1.44.44.3.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S3.T1.44.44.3.m1.1a"><mo mathsize="70%" id="S3.T1.44.44.3.m1.1.1" xref="S3.T1.44.44.3.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S3.T1.44.44.3.m1.1b"><times id="S3.T1.44.44.3.m1.1.1.cmml" xref="S3.T1.44.44.3.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.44.44.3.m1.1c">\times</annotation></semantics></math></td>
<td id="S3.T1.45.45.4" class="ltx_td ltx_align_center"><math id="S3.T1.45.45.4.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S3.T1.45.45.4.m1.1a"><mo mathsize="70%" id="S3.T1.45.45.4.m1.1.1" xref="S3.T1.45.45.4.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S3.T1.45.45.4.m1.1b"><times id="S3.T1.45.45.4.m1.1.1.cmml" xref="S3.T1.45.45.4.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.45.45.4.m1.1c">\times</annotation></semantics></math></td>
<td id="S3.T1.46.46.5" class="ltx_td ltx_align_center"><math id="S3.T1.46.46.5.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S3.T1.46.46.5.m1.1a"><mo mathsize="70%" id="S3.T1.46.46.5.m1.1.1" xref="S3.T1.46.46.5.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S3.T1.46.46.5.m1.1b"><times id="S3.T1.46.46.5.m1.1.1.cmml" xref="S3.T1.46.46.5.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.46.46.5.m1.1c">\times</annotation></semantics></math></td>
<td id="S3.T1.46.46.7" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.T1.46.46.7.1" class="ltx_text" style="font-size:70%;">âœ“</span></td>
</tr>
<tr id="S3.T1.46.66.20" class="ltx_tr">
<td id="S3.T1.46.66.20.1" class="ltx_td ltx_align_left"><span id="S3.T1.46.66.20.1.1" class="ltx_text ltx_font_bold" style="font-size:70%;">Software</span></td>
<td id="S3.T1.46.66.20.2" class="ltx_td"></td>
<td id="S3.T1.46.66.20.3" class="ltx_td"></td>
<td id="S3.T1.46.66.20.4" class="ltx_td"></td>
<td id="S3.T1.46.66.20.5" class="ltx_td"></td>
<td id="S3.T1.46.66.20.6" class="ltx_td"></td>
<td id="S3.T1.46.66.20.7" class="ltx_td ltx_nopad_r"></td>
</tr>
<tr id="S3.T1.46.67.21" class="ltx_tr">
<td id="S3.T1.46.67.21.1" class="ltx_td ltx_align_left"><span id="S3.T1.46.67.21.1.1" class="ltx_text" style="font-size:70%;">End-user</span></td>
<td id="S3.T1.46.67.21.2" class="ltx_td ltx_align_center"><span id="S3.T1.46.67.21.2.1" class="ltx_text" style="font-size:70%;">Python</span></td>
<td id="S3.T1.46.67.21.3" class="ltx_td ltx_align_center"><span id="S3.T1.46.67.21.3.1" class="ltx_text" style="font-size:70%;">Python</span></td>
<td id="S3.T1.46.67.21.4" class="ltx_td ltx_align_center"><span id="S3.T1.46.67.21.4.1" class="ltx_text" style="font-size:70%;">Python</span></td>
<td id="S3.T1.46.67.21.5" class="ltx_td ltx_align_center"><span id="S3.T1.46.67.21.5.1" class="ltx_text" style="font-size:70%;">Python</span></td>
<td id="S3.T1.46.67.21.6" class="ltx_td ltx_align_center"><span id="S3.T1.46.67.21.6.1" class="ltx_text" style="font-size:70%;">Python</span></td>
<td id="S3.T1.46.67.21.7" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.T1.46.67.21.7.1" class="ltx_text" style="font-size:70%;">Python</span></td>
</tr>
<tr id="S3.T1.46.68.22" class="ltx_tr">
<td id="S3.T1.46.68.22.1" class="ltx_td ltx_align_left"><span id="S3.T1.46.68.22.1.1" class="ltx_text" style="font-size:70%;">Learner</span></td>
<td id="S3.T1.46.68.22.2" class="ltx_td ltx_align_center"><span id="S3.T1.46.68.22.2.1" class="ltx_text" style="font-size:70%;">Python</span></td>
<td id="S3.T1.46.68.22.3" class="ltx_td ltx_align_center"><span id="S3.T1.46.68.22.3.1" class="ltx_text" style="font-size:70%;">Python</span></td>
<td id="S3.T1.46.68.22.4" class="ltx_td ltx_align_center"><span id="S3.T1.46.68.22.4.1" class="ltx_text" style="font-size:70%;">Python</span></td>
<td id="S3.T1.46.68.22.5" class="ltx_td ltx_align_center"><span id="S3.T1.46.68.22.5.1" class="ltx_text" style="font-size:70%;">Python</span></td>
<td id="S3.T1.46.68.22.6" class="ltx_td ltx_align_center"><span id="S3.T1.46.68.22.6.1" class="ltx_text" style="font-size:70%;">Python</span></td>
<td id="S3.T1.46.68.22.7" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.T1.46.68.22.7.1" class="ltx_text" style="font-size:70%;">Python</span></td>
</tr>
<tr id="S3.T1.46.69.23" class="ltx_tr">
<td id="S3.T1.46.69.23.1" class="ltx_td ltx_align_left ltx_border_bb"><span id="S3.T1.46.69.23.1.1" class="ltx_text" style="font-size:70%;">Aggregator</span></td>
<td id="S3.T1.46.69.23.2" class="ltx_td ltx_align_center ltx_border_bb"><span id="S3.T1.46.69.23.2.1" class="ltx_text" style="font-size:70%;">Python</span></td>
<td id="S3.T1.46.69.23.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="S3.T1.46.69.23.3.1" class="ltx_text" style="font-size:70%;">Python</span></td>
<td id="S3.T1.46.69.23.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="S3.T1.46.69.23.4.1" class="ltx_text" style="font-size:70%;">Python</span></td>
<td id="S3.T1.46.69.23.5" class="ltx_td ltx_align_center ltx_border_bb"><span id="S3.T1.46.69.23.5.1" class="ltx_text" style="font-size:70%;">Python</span></td>
<td id="S3.T1.46.69.23.6" class="ltx_td ltx_align_center ltx_border_bb"><span id="S3.T1.46.69.23.6.1" class="ltx_text" style="font-size:70%;">Python</span></td>
<td id="S3.T1.46.69.23.7" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb"><span id="S3.T1.46.69.23.7.1" class="ltx_text" style="font-size:70%;">C++</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption" style="font-size:70%;"><span class="ltx_tag ltx_tag_table">Table 1: </span>A qualitative comparison of different Federated Learning Systems.</figcaption>
</figure>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Evaluation</h2>

<div id="S4.p1" class="ltx_para ltx_noindent">
<p id="S4.p1.1" class="ltx_p">We perform a qualitative and quantitative analysis to compare the trade-offs across leading FL frameworksÂ <span id="footnote3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>We do not compare against LEAFÂ <cite class="ltx_cite ltx_citemacro_cite">Caldas etÂ al. (<a href="#bib.bib4" title="" class="ltx_ref">2018</a>)</cite> and TFFÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib7" title="" class="ltx_ref">Google </a></cite> frameworks since both frameworks are used primarily to experiment with new FL optimization algorithmsÂ <cite class="ltx_cite ltx_citemacro_cite">Li etÂ al. (<a href="#bib.bib12" title="" class="ltx_ref">2021b</a>)</cite>.</span></span></span>. The aim of our evaluation is two-fold. Through the qualitative comparison, we aim to understand the out-of-the-box support provided by the different FL frameworks, and through the quantitative evaluation, we aim to gain insights into how different implementations of the federation controller can affect the overall execution of an FL workflow. Following the taxonomy proposed in the works ofÂ <cite class="ltx_cite ltx_citemacro_cite">Li etÂ al. (<a href="#bib.bib12" title="" class="ltx_ref">2021b</a>); Kairouz etÂ al. (<a href="#bib.bib10" title="" class="ltx_ref">2021</a>); Liu etÂ al. (<a href="#bib.bib14" title="" class="ltx_ref">2022b</a>)</cite>, we report our qualitative comparison in TableÂ <a href="#S3.T1" title="Table 1 â€£ 3 MetisFL: Design &amp; Architecture â€£ MetisFL: An Embarrassingly Parallelized Controller for Scalable &amp; Efficient Federated Learning Workflows" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, while FiguresÂ <a href="#S4.F5" title="Figure 5 â€£ 4.2 Quantitative Evaluation â€£ 4 Evaluation â€£ MetisFL: An Embarrassingly Parallelized Controller for Scalable &amp; Efficient Federated Learning Workflows" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>,Â <a href="#S4.F6" title="Figure 6 â€£ 4.2 Quantitative Evaluation â€£ 4 Evaluation â€£ MetisFL: An Embarrassingly Parallelized Controller for Scalable &amp; Efficient Federated Learning Workflows" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>, andÂ <a href="#S4.F7" title="Figure 7 â€£ 4.2 Quantitative Evaluation â€£ 4 Evaluation â€£ MetisFL: An Embarrassingly Parallelized Controller for Scalable &amp; Efficient Federated Learning Workflows" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> present the execution time of the various operations, in isolation, occurring during a typical FL workflow (see FigureÂ <a href="#S1.F1" title="Figure 1 â€£ 1 Introduction â€£ MetisFL: An Embarrassingly Parallelized Controller for Scalable &amp; Efficient Federated Learning Workflows" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>). It is critical to note that in the current evaluation, we assume that all local models fit in the controllerâ€™s in-memory store (e.g., hash map). Therefore, we consider model insertion and selection operations to take constant time across all frameworks (see sectionÂ <a href="#S5" title="5 Discussion â€£ MetisFL: An Embarrassingly Parallelized Controller for Scalable &amp; Efficient Federated Learning Workflows" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>).</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Qualitative Evaluation</h3>

<div id="S4.SS1.p1" class="ltx_para ltx_noindent">
<p id="S4.SS1.p1.1" class="ltx_p">We compare leading FL systems across several categories.</p>
</div>
<div id="S4.SS1.p2" class="ltx_para ltx_noindent">
<p id="S4.SS1.p2.1" class="ltx_p">TheÂ <span id="S4.SS1.p2.1.1" class="ltx_text ltx_font_italic">Deployment</span> category refers to the case where a federation can be run in a simulated environment as parallel processes within a single server or distributed across multiple nodes (servers). All systems support standalone and distributed execution and deployment for cross-silo settings. However, OpenFL, Nvidia FLARE, and IBM FL do not support execution in cross-device settings, with OpenFL having no support for containerized execution.</p>
</div>
<div id="S4.SS1.p3" class="ltx_para ltx_noindent">
<p id="S4.SS1.p3.1" class="ltx_p">In theÂ <span id="S4.SS1.p3.1.1" class="ltx_text ltx_font_italic">ML Environment</span> category, model types describe the machine learning models each system can support, backend the machine/deep learning engine used to perform model training, evaluation, and inference, and LocalOpt and GlobalOpt whether the system allows the development of customized local (learner) and global (controller) function optimization algorithms. In this category, all frameworks support the execution of various model architectures and both the PyTorch and Tensorflow (TF) backend engines. Our system (MetisFL) currently only supports PyTorch and Tensorflow; however, it can be easily extended to support other training engines, e.g., MONAI, MXNet(MX), JAX.</p>
</div>
<div id="S4.SS1.p4" class="ltx_para ltx_noindent">
<p id="S4.SS1.p4.1" class="ltx_p">In the case ofÂ <span id="S4.SS1.p4.1.1" class="ltx_text ltx_font_italic">Data Partitioning</span>, we evaluate whether each system can support learning over different partitioning schemes. All systems readily support horizontally partitioned learning environments. In their documentation, FedML also states that their platform can be extended to support vertical learning scenarios; however, support is not provided out of the box.</p>
</div>
<div id="S4.SS1.p5" class="ltx_para ltx_noindent">
<p id="S4.SS1.p5.1" class="ltx_p">For theÂ <span id="S4.SS1.p5.1.1" class="ltx_text ltx_font_italic">Privacy &amp; Security</span> category, we assess whether a system can support private learning (differential privacy), the cryptographic method type used to perform secure aggregation operations, and which library is used for the cryptography operations. All systems support differential private learning. Nvidia FLARE, IBM FL, and MetisFL support homomorphic operations through the CKKSÂ <cite class="ltx_cite ltx_citemacro_cite">Cheon etÂ al. (<a href="#bib.bib5" title="" class="ltx_ref">2017</a>)</cite> scheme. For FHE operations, NVFlare uses the TenSeal libraryÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib16" title="" class="ltx_ref">Microsoft </a></cite>, IBM FL the HElayers libraryÂ <cite class="ltx_cite ltx_citemacro_cite">Aharoni etÂ al. (<a href="#bib.bib1" title="" class="ltx_ref">2020</a>)</cite>, and MetisFL the PALISADE libraryÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib17" title="" class="ltx_ref">PALISADE </a></cite>. OpenFL operates on a hardware-integrated trusted execution environment (TEEÂ <cite class="ltx_cite ltx_citemacro_cite">Sabt etÂ al. (<a href="#bib.bib21" title="" class="ltx_ref">2015</a>)</cite>), while Flower (SalviaÂ <cite class="ltx_cite ltx_citemacro_cite">Li etÂ al. (<a href="#bib.bib11" title="" class="ltx_ref">2021a</a>)</cite>) and FedML (LightSecAggÂ <cite class="ltx_cite ltx_citemacro_cite">So etÂ al. (<a href="#bib.bib22" title="" class="ltx_ref">2022</a>)</cite>) both utilize a mask-based encryption approach; both frameworks recently introduced the support for FHE protocols. Concerning the cryptography library, all systems (including ours) depend on an external library, while Flower and FedML provide native implementations for the required masking operations.</p>
</div>
<div id="S4.SS1.p6" class="ltx_para ltx_noindent">
<p id="S4.SS1.p6.1" class="ltx_p">In the <span id="S4.SS1.p6.1.1" class="ltx_text ltx_font_italic">Communication</span> category, we compare the federated learning topologies under which each system can operate, whether the communication across all participating parties is performed within an encrypted channel (TLS), and what network protocol is used to exchange messages. All systems can operate in a centralized federated learning environment (one aggregator, multiple clients). FedML provides support for decentralized settings (peer-to-peer), with FedML stating in their documentation support for hierarchical federated settings. Finally, every system uses gRPC to establish communication across all federation parties, except for FedML and IBM FL, which use the MPI and AMQP protocols.</p>
</div>
<div id="S4.SS1.p7" class="ltx_para ltx_noindent">
<p id="S4.SS1.p7.1" class="ltx_p">Another category in which we observe limited implementation capabilities across existing systems is theÂ <span id="S4.SS1.p7.1.1" class="ltx_text ltx_font_italic">Communication Protocol</span>. Even though systems provide support for synchronous communication and aggregation, they lack support for asynchronous protocols. In contrast, MetisFL provides both synchronous (including semi-synchronousÂ <cite class="ltx_cite ltx_citemacro_cite">Stripelis etÂ al. (<a href="#bib.bib25" title="" class="ltx_ref">2022b</a>)</cite>) and asynchronous execution. Based on other systemsâ€™ documentation, Flower and FedML are the only systems planning to support asynchronous executionÂ <cite class="ltx_cite ltx_citemacro_cite">Stripelis etÂ al. (<a href="#bib.bib24" title="" class="ltx_ref">2022a</a>)</cite>.</p>
</div>
<div id="S4.SS1.p8" class="ltx_para ltx_noindent">
<p id="S4.SS1.p8.1" class="ltx_p">Finally, compared to previously proposed metricsÂ <cite class="ltx_cite ltx_citemacro_cite">Li etÂ al. (<a href="#bib.bib12" title="" class="ltx_ref">2021b</a>); Kairouz etÂ al. (<a href="#bib.bib10" title="" class="ltx_ref">2021</a>); Liu etÂ al. (<a href="#bib.bib14" title="" class="ltx_ref">2022b</a>)</cite>, we also consider the programming language used to develop each component in the federated learning system: aggregator, learner and end-user API. All three components for all presented systems are developed in Python. However, in our framework, the aggregator is developed in C++.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Quantitative Evaluation</h3>

<div id="S4.SS2.p1" class="ltx_para ltx_noindent">
<p id="S4.SS2.p1.1" class="ltx_p">For the quantitative evaluation, presented in FiguresÂ <a href="#S4.F5" title="Figure 5 â€£ 4.2 Quantitative Evaluation â€£ 4 Evaluation â€£ MetisFL: An Embarrassingly Parallelized Controller for Scalable &amp; Efficient Federated Learning Workflows" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>,Â <a href="#S4.F6" title="Figure 6 â€£ 4.2 Quantitative Evaluation â€£ 4 Evaluation â€£ MetisFL: An Embarrassingly Parallelized Controller for Scalable &amp; Efficient Federated Learning Workflows" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>, andÂ <a href="#S4.F7" title="Figure 7 â€£ 4.2 Quantitative Evaluation â€£ 4 Evaluation â€£ MetisFL: An Embarrassingly Parallelized Controller for Scalable &amp; Efficient Federated Learning Workflows" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>, we conduct end-to-end system stress tests across all frameworks over an increasing number of participating learners: {10, 25, 50, 100, 200}, and model sizes: {100k, 1M, 10M} parameters. We test all frameworks in a synchronous FL setting, using FedAvg as the global aggregation rule and with all learners participating at every federation round. To generate the different model sizes, we define an MLP architecture with 100 densely connected (hidden) layers and a constant number of parameters per layerÂ <span id="footnote4" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span>100k: 32 params/layer, 1M: 100params/layer, 10M: 320params/layer</span></span></span>. For training and evaluating the model, we use the HousingMLP datasetÂ <cite class="ltx_cite ltx_citemacro_cite">Breiman (<a href="#bib.bib3" title="" class="ltx_ref">2017</a>)</cite> to generate the train and test datasets. Given that our analysis aims to stress test the frameworkâ€™s efficiency and not the FL modelâ€™s learning performance, we randomly pick (with replacement) and assign 100 samples per learner for model training and testing. As local model optimizer, we use Vanilla SGD, and the batch size is set to 100 (both for training and testing).</p>
</div>
<div id="S4.SS2.p2" class="ltx_para ltx_noindent">
<p id="S4.SS2.p2.1" class="ltx_p">All experiments were conducted in a simulated federated environment on the same host machine equipped with 32cores Intel(R) Xeon(R) Gold 5217 CPU @ 3.00GHz, 251GB memory, and 8TB disk space. All conducted experiments were CPU-intensive, with each learnerâ€™s workload being CPU-bound, and no GPU was employed during federated training. With regard to frameworksâ€™ versioning, we used NVFlare 2.3.1, Flower 1.2.0, FedML 0.7.6, and IBM FL 1.1.0. Our evaluation does not report OpenFL results because of the frameworkâ€™s complexity in incorporating new models and logging featuresÂ <span id="footnote5" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span>We will try to include them in a future version of our work.</span></span></span>. For all frameworks, we used gRPC as the servicesâ€™ communication layer, except for IBM FL, where we used the FLASK API. For Flower, IBM FL, and MetisFL, we used Keras as the backend NN engine, and for NVFlare and FedML, we used PyTorch.</p>
</div>
<figure id="S4.F5" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S4.F5.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2311.00334/assets/x5.png" id="S4.F5.sf1.g1" class="ltx_graphics ltx_centering ltx_img_square" width="115" height="98" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(a) </span>Train Task Dispatch</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S4.F5.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2311.00334/assets/x6.png" id="S4.F5.sf2.g1" class="ltx_graphics ltx_centering ltx_img_square" width="115" height="98" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(b) </span>Train Round</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S4.F5.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2311.00334/assets/x7.png" id="S4.F5.sf3.g1" class="ltx_graphics ltx_centering ltx_img_square" width="115" height="98" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(c) </span>Aggregation Time</figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F5.sf4" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2311.00334/assets/x8.png" id="S4.F5.sf4.g1" class="ltx_graphics ltx_centering ltx_img_square" width="115" height="102" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(d) </span>Eval Task Dispatch</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F5.sf5" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2311.00334/assets/x9.png" id="S4.F5.sf5.g1" class="ltx_graphics ltx_centering ltx_img_square" width="115" height="98" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(e) </span>Eval Round</figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S4.F5.sf6" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2311.00334/assets/x10.png" id="S4.F5.sf6.g1" class="ltx_graphics ltx_centering ltx_img_square" width="115" height="98" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(f) </span>Federation Round</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>FL frameworks operations comparison for 100k parameters (the y-axis is in logscale).</figcaption>
</figure>
<figure id="S4.F6" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S4.F6.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2311.00334/assets/x11.png" id="S4.F6.sf1.g1" class="ltx_graphics ltx_centering ltx_img_square" width="115" height="98" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(a) </span>Train Task Dispatch</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S4.F6.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2311.00334/assets/x12.png" id="S4.F6.sf2.g1" class="ltx_graphics ltx_centering ltx_img_square" width="115" height="98" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(b) </span>Train Round</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S4.F6.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2311.00334/assets/x13.png" id="S4.F6.sf3.g1" class="ltx_graphics ltx_centering ltx_img_square" width="115" height="98" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(c) </span>Aggregation Time</figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F6.sf4" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2311.00334/assets/x14.png" id="S4.F6.sf4.g1" class="ltx_graphics ltx_centering ltx_img_square" width="115" height="102" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(d) </span>Eval Task Dispatch</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F6.sf5" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2311.00334/assets/x15.png" id="S4.F6.sf5.g1" class="ltx_graphics ltx_centering ltx_img_square" width="115" height="98" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(e) </span>Eval Round</figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S4.F6.sf6" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2311.00334/assets/x16.png" id="S4.F6.sf6.g1" class="ltx_graphics ltx_centering ltx_img_square" width="115" height="98" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(f) </span>Federation Round</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>FL frameworks operations comparison for 1M parameters (the y-axis is in logscale).</figcaption>
</figure>
<div id="S4.SS2.p3" class="ltx_para ltx_noindent">
<p id="S4.SS2.p3.1" class="ltx_p">With respect to the frameworksâ€™ measurement reporting, in the FiguresÂ <a href="#S4.F5" title="Figure 5 â€£ 4.2 Quantitative Evaluation â€£ 4 Evaluation â€£ MetisFL: An Embarrassingly Parallelized Controller for Scalable &amp; Efficient Federated Learning Workflows" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>,Â <a href="#S4.F6" title="Figure 6 â€£ 4.2 Quantitative Evaluation â€£ 4 Evaluation â€£ MetisFL: An Embarrassingly Parallelized Controller for Scalable &amp; Efficient Federated Learning Workflows" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>, andÂ <a href="#S4.F7" title="Figure 7 â€£ 4.2 Quantitative Evaluation â€£ 4 Evaluation â€£ MetisFL: An Embarrassingly Parallelized Controller for Scalable &amp; Efficient Federated Learning Workflows" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>, for all other frameworks, except for FedML, we were able to capture all required metrics. For FedML, in particular, we only report the aggregation and federation time wall-clock time because it was hard to navigate into the codebase and find the required code segments where the logging functionality for the rest of the operations must be placed. Moreover, concerning execution failures, NVFlare and IBM FL did not run in the federated environment of 10M parameters for 100 and 200 learners and 200 learners, respectively.</p>
</div>
<div id="S4.SS2.p4" class="ltx_para ltx_noindent">
<p id="S4.SS2.p4.1" class="ltx_p">In the case of MetisFL, we ran each MetisFL for each environment twice, one with the OpenMP enabled (MetisFL gRPC + OpenMP) and one without (MetisFL gRPC). As expected, OpenMP model aggregation is 10 times faster than no parallelization (cf. MetisFL w/ and w/out parallelization in FiguresÂ <a href="#S4.F5.sf3" title="In Figure 5 â€£ 4.2 Quantitative Evaluation â€£ 4 Evaluation â€£ MetisFL: An Embarrassingly Parallelized Controller for Scalable &amp; Efficient Federated Learning Workflows" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5c</span></a>,Â <a href="#S4.F6.sf3" title="In Figure 6 â€£ 4.2 Quantitative Evaluation â€£ 4 Evaluation â€£ MetisFL: An Embarrassingly Parallelized Controller for Scalable &amp; Efficient Federated Learning Workflows" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6c</span></a>,Â <a href="#S4.F7.sf3" title="In Figure 7 â€£ 4.2 Quantitative Evaluation â€£ 4 Evaluation â€£ MetisFL: An Embarrassingly Parallelized Controller for Scalable &amp; Efficient Federated Learning Workflows" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7c</span></a>) and almost 100 times faster than other frameworks, especially in the case of federation environments with large models (cf. MetisFL w/ OpenMP to other FL frameworks in FigureÂ <a href="#S4.F7.sf3" title="In Figure 7 â€£ 4.2 Quantitative Evaluation â€£ 4 Evaluation â€£ MetisFL: An Embarrassingly Parallelized Controller for Scalable &amp; Efficient Federated Learning Workflows" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7c</span></a>). Since parallelization is only used during model aggregation, all other operations performed by MetisFL with and without OpenMP have similar and almost identical performances across all environments.</p>
</div>
<div id="S4.SS2.p5" class="ltx_para ltx_noindent">
<p id="S4.SS2.p5.1" class="ltx_p">When comparing each federated operation in isolation, we observe that most systemsâ€™ overhead is attributed to the dispatch time of training and evaluation tasks (cf. FiguresÂ <a href="#S4.F5.sf1" title="In Figure 5 â€£ 4.2 Quantitative Evaluation â€£ 4 Evaluation â€£ MetisFL: An Embarrassingly Parallelized Controller for Scalable &amp; Efficient Federated Learning Workflows" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5a</span></a>,Â <a href="#S4.F5.sf4" title="In Figure 5 â€£ 4.2 Quantitative Evaluation â€£ 4 Evaluation â€£ MetisFL: An Embarrassingly Parallelized Controller for Scalable &amp; Efficient Federated Learning Workflows" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5d</span></a>,Â <a href="#S4.F6.sf1" title="In Figure 6 â€£ 4.2 Quantitative Evaluation â€£ 4 Evaluation â€£ MetisFL: An Embarrassingly Parallelized Controller for Scalable &amp; Efficient Federated Learning Workflows" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6a</span></a>,Â <a href="#S4.F6.sf4" title="In Figure 6 â€£ 4.2 Quantitative Evaluation â€£ 4 Evaluation â€£ MetisFL: An Embarrassingly Parallelized Controller for Scalable &amp; Efficient Federated Learning Workflows" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6d</span></a>,Â <a href="#S4.F7.sf1" title="In Figure 7 â€£ 4.2 Quantitative Evaluation â€£ 4 Evaluation â€£ MetisFL: An Embarrassingly Parallelized Controller for Scalable &amp; Efficient Federated Learning Workflows" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7a</span></a>,Â <a href="#S4.F5.sf4" title="In Figure 5 â€£ 4.2 Quantitative Evaluation â€£ 4 Evaluation â€£ MetisFL: An Embarrassingly Parallelized Controller for Scalable &amp; Efficient Federated Learning Workflows" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5d</span></a>). MetiFL has a relatively smaller overhead for these operations than other systems because the MetisFL controller submits the tasks to the learners through asynchronous callbacks, and all model tensors are transmitted as a protobuf bytes data type.</p>
</div>
<figure id="S4.F7" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S4.F7.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2311.00334/assets/x17.png" id="S4.F7.sf1.g1" class="ltx_graphics ltx_centering ltx_img_square" width="115" height="98" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(a) </span>Train Task Dispatch</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S4.F7.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2311.00334/assets/x18.png" id="S4.F7.sf2.g1" class="ltx_graphics ltx_centering ltx_img_square" width="115" height="98" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(b) </span>Train Round</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S4.F7.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2311.00334/assets/x19.png" id="S4.F7.sf3.g1" class="ltx_graphics ltx_centering ltx_img_square" width="115" height="98" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(c) </span>Aggregation Time</figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F7.sf4" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2311.00334/assets/x20.png" id="S4.F7.sf4.g1" class="ltx_graphics ltx_centering ltx_img_square" width="115" height="102" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(d) </span>Eval Task Dispatch</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F7.sf5" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2311.00334/assets/x21.png" id="S4.F7.sf5.g1" class="ltx_graphics ltx_centering ltx_img_square" width="115" height="98" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(e) </span>Eval Round</figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S4.F7.sf6" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2311.00334/assets/x22.png" id="S4.F7.sf6.g1" class="ltx_graphics ltx_centering ltx_img_square" width="115" height="98" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(f) </span>Federation Round</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7: </span>FL frameworks operations comparison for 10M parameters (the y-axis is in logscale).</figcaption>
</figure>
<div id="S4.SS2.p6" class="ltx_para ltx_noindent">
<p id="S4.SS2.p6.1" class="ltx_p">From our evaluation, we also observe that all NVFlareâ€™s operations, especially its training and evaluation dispatch tasks times, underperform the corresponding operations from all other frameworks. When it comes to IBM FL, even though IBM FL does great work on performing extremely fast evaluation task dispatching and round execution, it underperforms other systems when executing the corresponding training operations. However, across all operations and frameworks, Flower has the most consistent behavior. As the federation size is doubled or the federation model becomes larger, Flowerâ€™s execution latency is linearly increasing.</p>
</div>
<div id="S4.SS2.p7" class="ltx_para ltx_noindent">
<p id="S4.SS2.p7.6" class="ltx_p">Finally, when comparing all frameworks holistically with respect to the federation round execution time (cf. FiguresÂ <a href="#S4.F5.sf6" title="In Figure 5 â€£ 4.2 Quantitative Evaluation â€£ 4 Evaluation â€£ MetisFL: An Embarrassingly Parallelized Controller for Scalable &amp; Efficient Federated Learning Workflows" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5f</span></a>,Â <a href="#S4.F6.sf6" title="In Figure 6 â€£ 4.2 Quantitative Evaluation â€£ 4 Evaluation â€£ MetisFL: An Embarrassingly Parallelized Controller for Scalable &amp; Efficient Federated Learning Workflows" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6f</span></a>,Â <a href="#S4.F7.sf6" title="In Figure 7 â€£ 4.2 Quantitative Evaluation â€£ 4 Evaluation â€£ MetisFL: An Embarrassingly Parallelized Controller for Scalable &amp; Efficient Federated Learning Workflows" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7f</span></a>), we observe that as the model sizes become larger and the federation size increases, the impact becomes much more significant. For instance, even though FedML is outperforming all frameworks in the federation environments with model sizes of 100k and 1M parameters, its performance starts to deteriorate when the size of the federated model becomes larger, i.e., 10M parameters. However, when comparing MetisFL to FedML in these challenging environments, we can observe that MetisFL leads to a 10-fold improvement. In general, all frameworks seem to underperform in these computationally demanding environments, with the overall federation execution time increasing almost non-linearly as the size of the federation doubles (cf. TableÂ <a href="#S4.T2" title="Table 2 â€£ 4.2 Quantitative Evaluation â€£ 4 Evaluation â€£ MetisFL: An Embarrassingly Parallelized Controller for Scalable &amp; Efficient Federated Learning Workflows" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>), e.g., 13.85s <math id="S4.SS2.p7.1.m1.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S4.SS2.p7.1.m1.1a"><mo stretchy="false" id="S4.SS2.p7.1.m1.1.1" xref="S4.SS2.p7.1.m1.1.1.cmml">â†’</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.p7.1.m1.1b"><ci id="S4.SS2.p7.1.m1.1.1.cmml" xref="S4.SS2.p7.1.m1.1.1">â†’</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p7.1.m1.1c">\rightarrow</annotation></semantics></math> 25.31s <math id="S4.SS2.p7.2.m2.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S4.SS2.p7.2.m2.1a"><mo stretchy="false" id="S4.SS2.p7.2.m2.1.1" xref="S4.SS2.p7.2.m2.1.1.cmml">â†’</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.p7.2.m2.1b"><ci id="S4.SS2.p7.2.m2.1.1.cmml" xref="S4.SS2.p7.2.m2.1.1">â†’</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p7.2.m2.1c">\rightarrow</annotation></semantics></math> 243.54 for FedML and 448.57s <math id="S4.SS2.p7.3.m3.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S4.SS2.p7.3.m3.1a"><mo stretchy="false" id="S4.SS2.p7.3.m3.1.1" xref="S4.SS2.p7.3.m3.1.1.cmml">â†’</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.p7.3.m3.1b"><ci id="S4.SS2.p7.3.m3.1.1.cmml" xref="S4.SS2.p7.3.m3.1.1">â†’</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p7.3.m3.1c">\rightarrow</annotation></semantics></math> 934.73s <math id="S4.SS2.p7.4.m4.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S4.SS2.p7.4.m4.1a"><mo stretchy="false" id="S4.SS2.p7.4.m4.1.1" xref="S4.SS2.p7.4.m4.1.1.cmml">â†’</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.p7.4.m4.1b"><ci id="S4.SS2.p7.4.m4.1.1.cmml" xref="S4.SS2.p7.4.m4.1.1">â†’</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p7.4.m4.1c">\rightarrow</annotation></semantics></math> 1,914.92s for IBM FL, while Flowerâ€™s overall federation execution time is doubled every time the number of participating learners is doubled, i.e., 60.44 <math id="S4.SS2.p7.5.m5.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S4.SS2.p7.5.m5.1a"><mo stretchy="false" id="S4.SS2.p7.5.m5.1.1" xref="S4.SS2.p7.5.m5.1.1.cmml">â†’</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.p7.5.m5.1b"><ci id="S4.SS2.p7.5.m5.1.1.cmml" xref="S4.SS2.p7.5.m5.1.1">â†’</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p7.5.m5.1c">\rightarrow</annotation></semantics></math> 116.05 <math id="S4.SS2.p7.6.m6.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S4.SS2.p7.6.m6.1a"><mo stretchy="false" id="S4.SS2.p7.6.m6.1.1" xref="S4.SS2.p7.6.m6.1.1.cmml">â†’</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.p7.6.m6.1b"><ci id="S4.SS2.p7.6.m6.1.1.cmml" xref="S4.SS2.p7.6.m6.1.1">â†’</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p7.6.m6.1c">\rightarrow</annotation></semantics></math> 216.38.</p>
</div>
<figure id="S4.T2" class="ltx_table">
<table id="S4.T2.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T2.1.1.1" class="ltx_tr">
<th id="S4.T2.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt">#Learners</th>
<th id="S4.T2.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">NVFlare</th>
<th id="S4.T2.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Flower</th>
<th id="S4.T2.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">FedML</th>
<th id="S4.T2.1.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">IBM FL</th>
<th id="S4.T2.1.1.1.6" class="ltx_td ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt">MetisFL</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T2.1.2.1" class="ltx_tr">
<th id="S4.T2.1.2.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">10</th>
<td id="S4.T2.1.2.1.2" class="ltx_td ltx_align_center ltx_border_t">62.32</td>
<td id="S4.T2.1.2.1.3" class="ltx_td ltx_align_center ltx_border_t">21.51</td>
<td id="S4.T2.1.2.1.4" class="ltx_td ltx_align_center ltx_border_t">6.21</td>
<td id="S4.T2.1.2.1.5" class="ltx_td ltx_align_center ltx_border_t">175.19</td>
<td id="S4.T2.1.2.1.6" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">4.58</td>
</tr>
<tr id="S4.T2.1.3.2" class="ltx_tr">
<th id="S4.T2.1.3.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">25</th>
<td id="S4.T2.1.3.2.2" class="ltx_td ltx_align_center">180.63</td>
<td id="S4.T2.1.3.2.3" class="ltx_td ltx_align_center">30.71</td>
<td id="S4.T2.1.3.2.4" class="ltx_td ltx_align_center">13.85</td>
<td id="S4.T2.1.3.2.5" class="ltx_td ltx_align_center">448.57</td>
<td id="S4.T2.1.3.2.6" class="ltx_td ltx_nopad_r ltx_align_center">6.10</td>
</tr>
<tr id="S4.T2.1.4.3" class="ltx_tr">
<th id="S4.T2.1.4.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">50</th>
<td id="S4.T2.1.4.3.2" class="ltx_td ltx_align_center">907.92</td>
<td id="S4.T2.1.4.3.3" class="ltx_td ltx_align_center">60.44</td>
<td id="S4.T2.1.4.3.4" class="ltx_td ltx_align_center">25.31</td>
<td id="S4.T2.1.4.3.5" class="ltx_td ltx_align_center">934.73</td>
<td id="S4.T2.1.4.3.6" class="ltx_td ltx_nopad_r ltx_align_center">14.13</td>
</tr>
<tr id="S4.T2.1.5.4" class="ltx_tr">
<th id="S4.T2.1.5.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">100</th>
<td id="S4.T2.1.5.4.2" class="ltx_td ltx_align_center">N/A</td>
<td id="S4.T2.1.5.4.3" class="ltx_td ltx_align_center">116.05</td>
<td id="S4.T2.1.5.4.4" class="ltx_td ltx_align_center">243.54</td>
<td id="S4.T2.1.5.4.5" class="ltx_td ltx_align_center">1,914.92</td>
<td id="S4.T2.1.5.4.6" class="ltx_td ltx_nopad_r ltx_align_center">21.28</td>
</tr>
<tr id="S4.T2.1.6.5" class="ltx_tr">
<th id="S4.T2.1.6.5.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb">200</th>
<td id="S4.T2.1.6.5.2" class="ltx_td ltx_align_center ltx_border_bb">N/A</td>
<td id="S4.T2.1.6.5.3" class="ltx_td ltx_align_center ltx_border_bb">216.38</td>
<td id="S4.T2.1.6.5.4" class="ltx_td ltx_align_center ltx_border_bb">683.21</td>
<td id="S4.T2.1.6.5.5" class="ltx_td ltx_align_center ltx_border_bb">N/A</td>
<td id="S4.T2.1.6.5.6" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb">45.61</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Federation Round Time (secs) for 10M Parameters.</figcaption>
</figure>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Discussion</h2>

<div id="S5.p1" class="ltx_para ltx_noindent">
<p id="S5.p1.1" class="ltx_p">We presented the Metis Federated Learning framework, a novel system for accelerating the training of large-scale FL workflows. By re-engineering the federation controller and treating it as the systemâ€™s first-class citizen, MetisFL leads to a powerful 10-fold and 100-fold wall-clock time reduction compared to existing leading FL frameworks. In our immediate future work, we plan to further enhance the computational capabilities of the controller by studying large-scale FL workflows in environments consisting of thousands and millions of learners and extremely large models (+100M parameters) in both synchronous and asynchronous settings. Given the amount of computational resources required in these environments, the controller may not be able to store all required local models in memory. In such settings, we plan to incorporate different model stores (e.g., distributed key-value or on-disk model stores) and understand their trade-offs in FL workflowsâ€™ convergence. We also plan to perform a more systematic performance analysis with respect to the cryptographic schemes employed by each framework and realize how the various FL workflows are affected.</p>
</div>
</section>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Acknowledgements</h2>

<div id="Sx1.p1" class="ltx_para ltx_noindent">
<p id="Sx1.p1.1" class="ltx_p">This research was supported in part by the Defense Advanced Research Projects Agency (DARPA) under contract HR00112090104, and in part by the National Institutes of Health (NIH) under grants U01AG068057 and RF1AG051710. The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies or endorsements, either expressed or implied, of DARPA, NIH, or the U.S. Government.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Aharoni etÂ al. (2020)</span>
<span class="ltx_bibblock">
Ehud Aharoni, Allon Adir, Moran Baruch, Nir Drucker, Gilad Ezov, Ariel Farkash, Lev Greenberg, Ramy Masalha, Guy Moshkowich, Dov Murik, etÂ al.

</span>
<span class="ltx_bibblock">Helayers: A tile tensors framework for large neural networks on encrypted data.

</span>
<span class="ltx_bibblock"><em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2011.01805</em>, 2020.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Beutel etÂ al. (2022)</span>
<span class="ltx_bibblock">
DanielÂ J Beutel, Taner Topal, Akhil Mathur, Xinchi Qiu, Javier Fernandez-Marques, Yan Gao, Lorenzo Sani, KwingÂ Hei Li, Titouan Parcollet, Pedro PortoÂ Buarque deÂ GusmÃ£o, etÂ al.

</span>
<span class="ltx_bibblock">Flower: A friendly federated learning framework.

</span>
<span class="ltx_bibblock"><em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2007.14390</em>, 2022.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Breiman (2017)</span>
<span class="ltx_bibblock">
Leo Breiman.

</span>
<span class="ltx_bibblock"><em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">Classification and regression trees</em>.

</span>
<span class="ltx_bibblock">Routledge, 2017.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Caldas etÂ al. (2018)</span>
<span class="ltx_bibblock">
Sebastian Caldas, Sai MeherÂ Karthik Duddu, Peter Wu, Tian Li, Jakub KoneÄná»³, HÂ Brendan McMahan, Virginia Smith, and Ameet Talwalkar.

</span>
<span class="ltx_bibblock">Leaf: A benchmark for federated settings.

</span>
<span class="ltx_bibblock"><em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1812.01097</em>, 2018.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cheon etÂ al. (2017)</span>
<span class="ltx_bibblock">
JungÂ Hee Cheon, Andrey Kim, Miran Kim, and Yongsoo Song.

</span>
<span class="ltx_bibblock">Homomorphic encryption for arithmetic of approximate numbers.

</span>
<span class="ltx_bibblock">In Tsuyoshi Takagi and Thomas Peyrin (eds.), <em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">Advances in Cryptology â€“ ASIACRYPT 2017</em>, pp.Â  409â€“437, 2017.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dagum &amp; Menon (1998)</span>
<span class="ltx_bibblock">
Leonardo Dagum and Ramesh Menon.

</span>
<span class="ltx_bibblock">Openmp: an industry standard api for shared-memory programming.

</span>
<span class="ltx_bibblock"><em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">IEEE computational science and engineering</em>, 5(1):46â€“55, 1998.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(7)</span>
<span class="ltx_bibblock">
Google.

</span>
<span class="ltx_bibblock">Tensorflow federated: Machine learning on decentralized data.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://www.tensorflow.org/federated" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.tensorflow.org/federated</a>.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He etÂ al. (2020)</span>
<span class="ltx_bibblock">
Chaoyang He, Songze Li, Jinhyun So, Xiao Zeng, MiÂ Zhang, Hongyi Wang, Xiaoyang Wang, Praneeth Vepakomma, Abhishek Singh, Hang Qiu, etÂ al.

</span>
<span class="ltx_bibblock">Fedml: A research library and benchmark for federated machine learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2007.13518</em>, 2020.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hu etÂ al. (2022)</span>
<span class="ltx_bibblock">
Sixu Hu, Yuan Li, XuÂ Liu, Qinbin Li, Zhaomin Wu, and Bingsheng He.

</span>
<span class="ltx_bibblock">The oarf benchmark suite: Characterization and implications for federated learning systems.

</span>
<span class="ltx_bibblock"><em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">ACM Transactions on Intelligent Systems and Technology (TIST)</em>, 13(4):1â€“32, 2022.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kairouz etÂ al. (2021)</span>
<span class="ltx_bibblock">
Peter Kairouz, HÂ Brendan McMahan, Brendan Avent, AurÃ©lien Bellet, Mehdi Bennis, ArjunÂ Nitin Bhagoji, Kallista Bonawitz, Zachary Charles, Graham Cormode, Rachel Cummings, etÂ al.

</span>
<span class="ltx_bibblock">Advances and open problems in federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">Foundations and TrendsÂ® in Machine Learning</em>, 14(1â€“2):1â€“210, 2021.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li etÂ al. (2021a)</span>
<span class="ltx_bibblock">
KwingÂ Hei Li, Pedro PortoÂ Buarque deÂ GusmÃ£o, DanielÂ J Beutel, and NicholasÂ D Lane.

</span>
<span class="ltx_bibblock">Secure aggregation for federated learning in flower.

</span>
<span class="ltx_bibblock">In <em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2nd ACM International Workshop on Distributed Machine Learning</em>, pp.Â  8â€“14, 2021a.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li etÂ al. (2021b)</span>
<span class="ltx_bibblock">
Qinbin Li, Zeyi Wen, Zhaomin Wu, Sixu Hu, Naibo Wang, Yuan Li, XuÂ Liu, and Bingsheng He.

</span>
<span class="ltx_bibblock">A survey on federated learning systems: vision, hype and reality for data privacy and protection.

</span>
<span class="ltx_bibblock"><em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Knowledge and Data Engineering</em>, 2021b.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu etÂ al. (2022a)</span>
<span class="ltx_bibblock">
JiÂ Liu, Jizhou Huang, Yang Zhou, Xuhong Li, Shilei Ji, Haoyi Xiong, and Dejing Dou.

</span>
<span class="ltx_bibblock">From distributed machine learning to federated learning: A survey.

</span>
<span class="ltx_bibblock"><em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">Knowledge and Information Systems</em>, 64(4):885â€“917, 2022a.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu etÂ al. (2022b)</span>
<span class="ltx_bibblock">
Xiaoyuan Liu, Tianneng Shi, Chulin Xie, Qinbin Li, Kangping Hu, Haoyu Kim, Xiaojun Xu, BoÂ Li, and Dawn Song.

</span>
<span class="ltx_bibblock">Unifed: A benchmark for federated learning frameworks.

</span>
<span class="ltx_bibblock"><em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2207.10308</em>, 2022b.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ludwig etÂ al. (2020)</span>
<span class="ltx_bibblock">
Heiko Ludwig, Nathalie Baracaldo, Gegi Thomas, YiÂ Zhou, Ali Anwar, Shashank Rajamoni, Yuya Ong, Jayaram Radhakrishnan, Ashish Verma, Mathieu Sinn, etÂ al.

</span>
<span class="ltx_bibblock">Ibm federated learning: an enterprise framework white paper v0. 1.

</span>
<span class="ltx_bibblock"><em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2007.10987</em>, 2020.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(16)</span>
<span class="ltx_bibblock">
Microsoft.

</span>
<span class="ltx_bibblock">Microsoft seal.

</span>
<span class="ltx_bibblock">https://github.com/Microsoft/SEAL.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(17)</span>
<span class="ltx_bibblock">
PALISADE.

</span>
<span class="ltx_bibblock">Palisade library.

</span>
<span class="ltx_bibblock">https://palisade-crypto.org/.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Reina etÂ al. (2021)</span>
<span class="ltx_bibblock">
GÂ Anthony Reina, Alexey Gruzdev, Patrick Foley, Olga Perepelkina, Mansi Sharma, Igor Davidyuk, Ilya Trushkin, Maksim Radionov, Aleksandr Mokrov, Dmitry Agapov, etÂ al.

</span>
<span class="ltx_bibblock">Openfl: An open-source framework for federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2105.06413</em>, 2021.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rieke etÂ al. (2020)</span>
<span class="ltx_bibblock">
Nicola Rieke, Jonny Hancox, Wenqi Li, Fausto Milletari, HolgerÂ R Roth, Shadi Albarqouni, Spyridon Bakas, MathieuÂ N Galtier, BennettÂ A Landman, Klaus Maier-Hein, etÂ al.

</span>
<span class="ltx_bibblock">The future of digital health with federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">NPJ digital medicine</em>, 3(1):1â€“7, 2020.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Roth etÂ al. (2022)</span>
<span class="ltx_bibblock">
HolgerÂ R Roth, Yan Cheng, Yuhong Wen, Isaac Yang, Ziyue Xu, Yuan-Ting Hsieh, Kristopher Kersten, Ahmed Harouni, Can Zhao, Kevin Lu, etÂ al.

</span>
<span class="ltx_bibblock">Nvidia flare: Federated learning from simulation to real-world.

</span>
<span class="ltx_bibblock"><em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2210.13291</em>, 2022.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sabt etÂ al. (2015)</span>
<span class="ltx_bibblock">
Mohamed Sabt, Mohammed Achemlal, and Abdelmadjid Bouabdallah.

</span>
<span class="ltx_bibblock">Trusted execution environment: what it is, and what it is not.

</span>
<span class="ltx_bibblock">In <em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">2015 IEEE Trustcom/BigDataSE/ISPA</em>, volumeÂ 1, pp.Â  57â€“64. IEEE, 2015.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">So etÂ al. (2022)</span>
<span class="ltx_bibblock">
Jinhyun So, Chaoyang He, Chien-Sheng Yang, Songze Li, Qian Yu, Ramy EÂ Ali, Basak Guler, and Salman Avestimehr.

</span>
<span class="ltx_bibblock">Lightsecagg: a lightweight and versatile design for secure aggregation in federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">Proceedings of Machine Learning and Systems</em>, 4:694â€“720, 2022.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Stripelis etÂ al. (2021)</span>
<span class="ltx_bibblock">
Dimitris Stripelis, Hamza Saleem, Tanmay Ghai, Nikhil Dhinagar, Umang Gupta, Chrysovalantis Anastasiou, Greg VerÂ Steeg, Srivatsan Ravi, Muhammad Naveed, PaulÂ M Thompson, etÂ al.

</span>
<span class="ltx_bibblock">Secure neuroimaging analysis using federated learning with homomorphic encryption.

</span>
<span class="ltx_bibblock">In <em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">17th International Symposium on Medical Information Processing and Analysis</em>, volume 12088, pp.Â  351â€“359. SPIE, 2021.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Stripelis etÂ al. (2022a)</span>
<span class="ltx_bibblock">
Dimitris Stripelis, Umang Gupta, Hamza Saleem, Nikhil Dhinagar, Tanmay Ghai, Rafael Sanchez, Chrysovalantis Anastasiou, Armaghan Asghar, GregÂ Ver Steeg, Srivatsan Ravi, etÂ al.

</span>
<span class="ltx_bibblock">Secure federated learning for neuroimaging.

</span>
<span class="ltx_bibblock"><em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2205.05249</em>, 2022a.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Stripelis etÂ al. (2022b)</span>
<span class="ltx_bibblock">
Dimitris Stripelis, PaulÂ M Thompson, and JosÃ©Â Luis Ambite.

</span>
<span class="ltx_bibblock">Semi-synchronous federated learning for energy-efficient training and accelerated convergence in cross-silo settings.

</span>
<span class="ltx_bibblock"><em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">ACM Transactions on Intelligent Systems and Technology (TIST)</em>, 13(5):1â€“29, 2022b.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang etÂ al. (2019)</span>
<span class="ltx_bibblock">
Qiang Yang, Yang Liu, Tianjian Chen, and Yongxin Tong.

</span>
<span class="ltx_bibblock">Federated machine learning: Concept and applications.

</span>
<span class="ltx_bibblock"><em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">ACM Transactions on Intelligent Systems and Technology (TIST)</em>, 10(2):1â€“19, 2019.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zaharia etÂ al. (2010)</span>
<span class="ltx_bibblock">
Matei Zaharia, Mosharaf Chowdhury, MichaelÂ J Franklin, Scott Shenker, Ion Stoica, etÂ al.

</span>
<span class="ltx_bibblock">Spark: Cluster computing with working sets.

</span>
<span class="ltx_bibblock"><em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">HotCloud</em>, 10(10-10):95, 2010.

</span>
</li>
</ul>
</section>
<section id="A1" class="ltx_appendix ltx_pruned_first">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>FL Frameworks Configuration</h2>

<section id="A1.SS0.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_font_bold ltx_title_paragraph">Flower</h4>

<div id="A1.SS0.SSS0.Px1.p1" class="ltx_para ltx_noindent">
<p id="A1.SS0.SSS0.Px1.p1.1" class="ltx_p">Flower is a widely used open-source federated learning framework. Flowerâ€™s architecture addresses critical distributed computing challenges such as scalability, client and communication heterogeneity, and system flexibility by intelligently organizing workload infrastructure between the server and client. To perform the Flower experiments, we leveraged the systemâ€™s federated averaging strategy abstraction to represent the coordinating server to the distributed client set. To set up all experimental environments, we created a Client Learner class, which defined each learnerâ€™s training and evaluation behavior in the federation. Then, we defined the client-factory function, which creates the required number of learners for the simulation and initializes each client with the model training and test data. We used system-native logging to record timestamp differences between specific code segments to benchmark performance successfully. We added timestamps wherever appropriate to record each experimentâ€™s aggregation, dispatch, and overall wall-clock time.</p>
</div>
</section>
<section id="A1.SS0.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_font_bold ltx_title_paragraph">FedML</h4>

<div id="A1.SS0.SSS0.Px2.p1" class="ltx_para ltx_noindent">
<p id="A1.SS0.SSS0.Px2.p1.1" class="ltx_p">To configure the environments for our experiments, we installed FedML using pip inside a docker container. We changed the code in the Python source files installed using pip to record timestamps for the model aggregation time, federation, training, and evaluation round times, along with the associated dispatch time for the training and test tasks. To define the simulation for our use cases, we defined a data loader class for reading the input training data to our model. We registered the model by making code changes to the function Model Hub. To stress-test the system with different communication protocols, we run the system with two different back-end communication services: gRPC and MQTT.</p>
</div>
</section>
<section id="A1.SS0.SSS0.Px3" class="ltx_paragraph">
<h4 class="ltx_title ltx_font_bold ltx_title_paragraph">IBM FL</h4>

<div id="A1.SS0.SSS0.Px3.p1" class="ltx_para ltx_noindent">
<p id="A1.SS0.SSS0.Px3.p1.1" class="ltx_p">We spawn the IBM FL framework in a containerized environment. Specific terminology within the framework designates the Aggregator as the coordinating server and the distributed clients as Parties. Arrangement of both the aggregator and parties is handled by IBM FL native python scripts that process experiment parameters to create configuration files for the aggregator and parties. The federated learning training algorithm is assigned to the aggregator defined as a fusion handler. In our experiments, we selected the native FedAvgFusionHandler. Each party is assigned our custom Housing MLP model specified with parameter size at configuration time. To execute our experiments, we spawned one process solely responsible for the aggregator and a variable number of party processes set to the number of parties. We added timestamps in the code logic surrounding the global model aggregation function, the functions that execute the dispatch and evaluate logic. Moreover, to enable easier initialization of the federated environments, we had to tailor the initialization logic of the Party class code so that it could execute model training as soon as the aggregator directed it. By doing so, we did not have to initialize the Party class through command line instructions, which was extremely cumbersome when considering multiple learners for each experiment.</p>
</div>
</section>
<section id="A1.SS0.SSS0.Px4" class="ltx_paragraph">
<h4 class="ltx_title ltx_font_bold ltx_title_paragraph">Nvidia Flare</h4>

<div id="A1.SS0.SSS0.Px4.p1" class="ltx_para ltx_noindent">
<p id="A1.SS0.SSS0.Px4.p1.1" class="ltx_p">NVFlare operates as a generic open-source software development kit (SDK) to facilitate distributed collaborative computing in multithreaded environments. Central to this frameworkâ€™s architecture is a flexible implementation of communication protocols carried out by two distinct entities: Controllers and Workers. In our FL experiments, we utilized the functionality of these communication protocols to represent the principal roles of the solitary server (Controller) and the set of distributed clients (Workers). An example of such a communication protocol used in tandem with Federated Averaging is the â€œBroadcast and Waitâ€ protocol. In this protocol, the server broadcasts a task and global information to the clients. Each client then locally executes the task and sends the clientâ€™s local updates to the orchestrating server for aggregation. The frameworkâ€™s infrastructure places a strong emphasis on workflows. Namely, we used the Scatter and Gather as well as Global Model Evaluation workflows. To execute the experiments, NVFLARE provides a robust simulator command line interface, which we employ to configure various experiment details, including the client count, number of threads, and machine learning tasks. We utilized developer-friendly built-in logging methods to record training and evaluation times and capture system-related metrics. By harnessing the robust foundational system, effective communication protocol, user-friendly simulator, and reliable logging, we successfully benchmarked the approach with metrics pertinent to this paper.</p>
</div>
</section>
</section>
<section id="A2" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>MetisFL Internal Procedures</h2>

<div id="A2.p1" class="ltx_para ltx_noindent">
<p id="A2.p1.1" class="ltx_p">In this section, we describe in more detail some of the internal mechanisms of MetisFL execution flow. Specifically, we consider a synchronous FL setting, where federated training and evaluation occur over a series of federation rounds, with every federation round consisting of a federated training round followed by a federated evaluation round.</p>
</div>
<section id="A2.SS0.SSS0.Px1" class="ltx_paragraph ltx_pruned_first">
<h4 class="ltx_title ltx_font_bold ltx_title_paragraph">Federation Round Flow</h4>

<div id="A2.SS0.SSS0.Px1.p1" class="ltx_para ltx_noindent">
<p id="A2.SS0.SSS0.Px1.p1.1" class="ltx_p">The Federation Round lifecycle (see FigureÂ <a href="#A2.F8" title="Figure 8 â€£ Federation Round Flow â€£ Appendix B MetisFL Internal Procedures â€£ MetisFL: An Embarrassingly Parallelized Controller for Scalable &amp; Efficient Federated Learning Workflows" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a>) consists of three core steps: <span id="A2.SS0.SSS0.Px1.p1.1.1" class="ltx_text ltx_font_italic">Initialization, Monitoring, Shutdown</span>. The driver initializes the controller process at the remote host (or localhost) and receives an acknowledgment when the remote process is alive. After that, the driver sends the initial state of the model (just the model tensors, not the actual architecture) to the controller and proceeds with learnersâ€™ initialization. Once all learners are initialized, the driver sends the model (model tensors &amp; architecture) to every other learner. The driver ships the actual model architecture to the learners because they are required to perform training and evaluation on their local private datasets. In contrast, the controller is only responsible for orchestrating the federation workflow and aggregating learnersâ€™ weights.</p>
</div>
<div id="A2.SS0.SSS0.Px1.p2" class="ltx_para ltx_noindent">
<p id="A2.SS0.SSS0.Px1.p2.1" class="ltx_p">Once learners register with the controller (join the federation), the training and evaluation of the federated model occur for multiple federation rounds. Within every federation round, the federated model is sent for training and, subsequently, for evaluation to all participating learners. At this point, the driver monitors the lifecycle of the federation and periodically pings (heartbeat) remote processes. Once any of the federated training termination criteria is met, such as the execution wall-clock time or a number of federation rounds, then the driver sends a shutdown signal to all processes, first to the learners and then to the controller.</p>
</div>
<figure id="A2.F8" class="ltx_figure"><img src="/html/2311.00334/assets/figures/MetisFL_Round_Federation_v1.png" id="A2.F8.g1" class="ltx_graphics ltx_centering ltx_img_portrait" width="186" height="302" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 8: </span>MetisFL Federation Round Flow.</figcaption>
</figure>
</section>
<section id="A2.SS0.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_font_bold ltx_title_paragraph">Training Round Flow</h4>

<div id="A2.SS0.SSS0.Px2.p1" class="ltx_para ltx_noindent">
<p id="A2.SS0.SSS0.Px2.p1.1" class="ltx_p">FigureÂ <a href="#A2.F9" title="Figure 9 â€£ Training Round Flow â€£ Appendix B MetisFL Internal Procedures â€£ MetisFL: An Embarrassingly Parallelized Controller for Scalable &amp; Efficient Federated Learning Workflows" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a> presents how the federated training round is executed within MetisFL. Before the training round starts, the controller creates/defines the model training task and selects the learners participating in model training. Once the learners have been selected the train task scheduler sends the training task to every participating learner (RunTask request).</p>
</div>
<div id="A2.SS0.SSS0.Px2.p2" class="ltx_para ltx_noindent">
<p id="A2.SS0.SSS0.Px2.p2.1" class="ltx_p">The Learner(s) entity receives the task through the Learner Servicer process and submits the training task to the training task pool executor running in the background. Upon task submission, the executor replies with an Acknowledgment (Ack) message that the servicer relays to the controller. Note that the status of the Ack message is false when the training task is not submitted or received or any unexpected failure occurs.</p>
</div>
<figure id="A2.F9" class="ltx_figure"><img src="/html/2311.00334/assets/figures/MetisFL_Round_Training_v1.png" id="A2.F9.g1" class="ltx_graphics ltx_centering ltx_img_portrait" width="192" height="241" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 9: </span>MetisFL Training Round Flow.</figcaption>
</figure>
<div id="A2.SS0.SSS0.Px2.p3" class="ltx_para ltx_noindent">
<p id="A2.SS0.SSS0.Px2.p3.1" class="ltx_p">The submitted training task is registered with a callback function that will handle the completed training task when it is completed. Once this occurs, the servicer sends a MarkTaskCompleted request to the controller containing the learnerâ€™s local model and other execution metadata related to model training (e.g., training time per batch, number of completed steps, and epochs). Finally, the controller stores and aggregates all received local models.</p>
</div>
<div id="A2.SS0.SSS0.Px2.p4" class="ltx_para ltx_noindent">
<p id="A2.SS0.SSS0.Px2.p4.1" class="ltx_p">To improve the scheduling of training tasks, the controller submits the tasks to the learners as asynchronous calls, meaning that the controller does not wait for the training task to complete. In other words, the controller submits the task, but the learner needs to inform the controller when its local training is complete.</p>
</div>
</section>
<section id="A2.SS0.SSS0.Px3" class="ltx_paragraph ltx_pruned_first">
<h4 class="ltx_title ltx_font_bold ltx_title_paragraph">Evaluation Round Flow</h4>

<div id="A2.SS0.SSS0.Px3.p1" class="ltx_para ltx_noindent">
<p id="A2.SS0.SSS0.Px3.p1.1" class="ltx_p">In FigureÂ <a href="#A2.F10" title="Figure 10 â€£ Evaluation Round Flow â€£ Appendix B MetisFL Internal Procedures â€£ MetisFL: An Embarrassingly Parallelized Controller for Scalable &amp; Efficient Federated Learning Workflows" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10</span></a> we present the execution of the federated evaluation round. Similar to the training round, the evaluation round starts with the controller constructing the evaluation task and selecting the learners participating in the evaluation of the global model. Once these steps are defined, the evaluation task scheduler sends an EvaluateModel request to all participating learners and receives the respective model evaluations. Compared to the training tasks, the evaluation tasks are synchronous calls, meaning that the controller keeps the connection alive till the evaluation of the model is complete.</p>
</div>
<figure id="A2.F10" class="ltx_figure"><img src="/html/2311.00334/assets/figures/MetisFL_Round_Evaluation_v1.png" id="A2.F10.g1" class="ltx_graphics ltx_centering ltx_img_square" width="196" height="178" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 10: </span>MetisFL Evaluation Round Flow.</figcaption>
</figure>
</section>
<section id="A2.SS0.SSS0.Px4" class="ltx_paragraph">
<h4 class="ltx_title ltx_font_bold ltx_title_paragraph">Secure Sockets Layer</h4>

<div id="A2.SS0.SSS0.Px4.p1" class="ltx_para ltx_noindent">
<p id="A2.SS0.SSS0.Px4.p1.1" class="ltx_p">FigureÂ <a href="#A2.F11" title="Figure 11 â€£ Secure Sockets Layer â€£ Appendix B MetisFL Internal Procedures â€£ MetisFL: An Embarrassingly Parallelized Controller for Scalable &amp; Efficient Federated Learning Workflows" class="ltx_ref"><span class="ltx_text ltx_ref_tag">11</span></a> shows how SSL is enabled within MetisFL. From the perspective of SSL connectivity, in a FL setting every participating entity (controller, learner) acts both as a client and as a server at different points of the federated execution workflow. Therefore, when establishing SSL-enabled connections we need first to generate the pair of files (private key, public certificate) that will be used by the server process running at a given host (e.g., learner/controller). This will allow the gRPC server to receive secure connections from requesting clients. When the controller receives model update requests from the learners, the controller acts as a server and the learners as the serverâ€™s clients. Similarly, when a learner receives local model training requests from the controller, the learner acts as a server and the controller as a client.</p>
</div>
<div id="A2.SS0.SSS0.Px4.p2" class="ltx_para ltx_noindent">
<p id="A2.SS0.SSS0.Px4.p2.1" class="ltx_p">In a MetisFL simulated environment, the internal mechanism for enabling SSL connectivity starts with the federation driver. The driver uses the defined SSL certificates (self-signed or trusted authority) to start the federation controller and spawn its server process with the provided key pair. Analogously, the driver initializes the learner processes using the defined pair. Finally, during the learner-controller registration, the learners share their public certificate with the controller as part of the exchanged message.</p>
</div>
<div id="A2.SS0.SSS0.Px4.p3" class="ltx_para ltx_noindent">
<p id="A2.SS0.SSS0.Px4.p3.1" class="ltx_p">In a production environment, though, it is not required for the SSL certificates to be generated by the driver. The certificates can be developed independently by each process (controller, learner), and then the public certificates can be shared with the driver to establish secure connections wherever needed.</p>
</div>
<figure id="A2.F11" class="ltx_figure"><img src="/html/2311.00334/assets/x23.png" id="A2.F11.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="230" height="125" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 11: </span>MetisFL with SSL Execution.</figcaption>
</figure>
</section>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2311.00333" class="ar5iv-nav-button ar5iv-nav-button-prev">â—„</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2311.00334" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2311.00334">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2311.00334" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2311.00335" class="ar5iv-nav-button ar5iv-nav-button-next">â–º</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Tue Feb 27 20:12:11 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "Ã—";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
