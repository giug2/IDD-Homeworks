<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2208.02507] ZeroFL: Efficient On-Device Training for Federated Learning with Local Sparsity</title><meta property="og:description" content="When the available hardware cannot meet the memory and compute requirements to efficiently train high performing machine learning models, a compromise in either the training quality or the model complexity is needed. I…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="ZeroFL: Efficient On-Device Training for Federated Learning with Local Sparsity">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="ZeroFL: Efficient On-Device Training for Federated Learning with Local Sparsity">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2208.02507">

<!--Generated on Wed Mar 13 20:48:19 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">ZeroFL: Efficient On-Device Training for 
<br class="ltx_break">Federated Learning with Local Sparsity</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
<span id="id1.1.id1" class="ltx_inline-block ltx_parbox ltx_align_middle" style="width:341.4pt;">
<span id="id1.1.id1.1" class="ltx_p">Xinchi Qiu<sup id="id1.1.id1.1.1" class="ltx_sup">1,</sup> ,
Javier Fernandez-Marques<sup id="id1.1.id1.1.2" class="ltx_sup">2,*</sup>, Pedro P. B. Gusmao<sup id="id1.1.id1.1.3" class="ltx_sup">1</sup>, Yan Gao<sup id="id1.1.id1.1.4" class="ltx_sup">1</sup>, Titouan Parcollet<sup id="id1.1.id1.1.5" class="ltx_sup">3</sup> and Nicholas D. Lane<sup id="id1.1.id1.1.6" class="ltx_sup">1</sup></span>
</span>  
<br class="ltx_break"><sup id="id2.2.id2" class="ltx_sup">1</sup> Department of Computer Science and Technology, University of Cambridge 
<br class="ltx_break"><sup id="id3.3.id3" class="ltx_sup">2</sup> Department of Computer Science, University of Oxford 
<br class="ltx_break"><sup id="id4.4.id4" class="ltx_sup">3</sup> Laboratoire Informatique d’Avignon, Avignon Université
</span><span class="ltx_author_notes">Equal contribution. Correspondence to Xinchi Qiu (<span id="id5.5.id1" class="ltx_text ltx_font_typewriter">xq227@cam.ac.uk</span>) or Javier Fernandez-Marques (<span id="id6.6.id2" class="ltx_text ltx_font_typewriter">javier.fernandezmarques@linacre.ox.ac.uk</span>).</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id7.id1" class="ltx_p">When the available hardware cannot meet the memory and compute requirements to efficiently train high performing machine learning models, a compromise in either the training quality or the model complexity is needed. In Federated Learning (FL), nodes are orders of magnitude more constrained than traditional server-grade hardware and are often battery powered, severely limiting the sophistication of models that can be trained under this paradigm. While most research has focused on designing better aggregation strategies to improve convergence rates and in alleviating the communication costs of FL, fewer efforts have been devoted to accelerating on-device training. Such stage, which repeats hundreds of times (i.e. every round) and can involve thousands of devices, accounts for the majority of the time required to train federated models and, the totality of the energy consumption at the client side. In this work, we present the first study on the unique aspects that arise when introducing sparsity at training time in FL workloads. We then propose <em id="id7.id1.1" class="ltx_emph ltx_font_italic">ZeroFL</em>, a framework that relies on highly sparse operations to accelerate on-device training. Models trained with ZeroFL and 95% sparsity achieve up to 2.3% higher accuracy compared to competitive baselines obtained from adapting a state-of-the-art sparse training framework to the FL setting.</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para ltx_noindent">
<p id="S1.p1.1" class="ltx_p">Despite it being a relatively new subfield of machine learning (ML), Federated Learning (FL) <cite class="ltx_cite ltx_citemacro_citep">(McMahan et al., <a href="#bib.bib37" title="" class="ltx_ref">2017</a>; Reddi et al., <a href="#bib.bib42" title="" class="ltx_ref">2021</a>; Horvath et al., <a href="#bib.bib27" title="" class="ltx_ref">2021</a>)</cite> has become an indispensable tool to enable privacy-preserving collaboratively learning, as well as to deliver personalised models tailored to the end-user’s local data and context <cite class="ltx_cite ltx_citemacro_citep">(Arivazhagan et al., <a href="#bib.bib2" title="" class="ltx_ref">2019</a>; Hilmkil et al., <a href="#bib.bib22" title="" class="ltx_ref">2021</a>; Cheng et al., <a href="#bib.bib6" title="" class="ltx_ref">2021</a>)</cite>. For example: next-word prediction <cite class="ltx_cite ltx_citemacro_citep">(Hard et al., <a href="#bib.bib15" title="" class="ltx_ref">2018</a>)</cite>, physical activity detection <cite class="ltx_cite ltx_citemacro_citep">(Doherty et al., <a href="#bib.bib8" title="" class="ltx_ref">2017</a>)</cite>, keyword spotting <cite class="ltx_cite ltx_citemacro_citep">(Hard et al., <a href="#bib.bib16" title="" class="ltx_ref">2020</a>)</cite>, among others.</p>
</div>
<div id="S1.p2" class="ltx_para ltx_noindent">
<p id="S1.p2.1" class="ltx_p">Unlike standard centralised training, which normally takes place on the Cloud and makes use of powerful hardware <cite class="ltx_cite ltx_citemacro_citep">(Hazelwood et al., <a href="#bib.bib17" title="" class="ltx_ref">2018</a>)</cite>, FL is envisioned to run on commodity devices such as smartphones or IoT devices often running of batteries, which are orders of magnitude more restricted in terms of compute, memory and power consumption <cite class="ltx_cite ltx_citemacro_citep">(Qiu et al., <a href="#bib.bib40" title="" class="ltx_ref">2021</a>)</cite>. This triplet of factors drastically limits the complexity of the ML models that can be trained on-device in a federated manner, ceiling their usefulness for the aforementioned applications as a result. In order to adjust the memory and compute footprints of complex ML model to the FL setting, the research community has presented a number of approaches including: the use of distillation <cite class="ltx_cite ltx_citemacro_citep">(Hinton et al., <a href="#bib.bib23" title="" class="ltx_ref">2015</a>)</cite> to enable the aggregation on the server side of heterogeneous model architectures (e.g. based on the compute capabilities of each device) that collaboratively train a single global model <cite class="ltx_cite ltx_citemacro_citep">(Lin et al., <a href="#bib.bib34" title="" class="ltx_ref">2020</a>; Zhu et al., <a href="#bib.bib61" title="" class="ltx_ref">2021</a>)</cite>; group knowledge transfer algorithm  <cite class="ltx_cite ltx_citemacro_citep">(He et al., <a href="#bib.bib18" title="" class="ltx_ref">2020</a>)</cite>; federated dropout, by which clients perform local training on a sub-model of the global model <cite class="ltx_cite ltx_citemacro_citep">(Caldas et al., <a href="#bib.bib5" title="" class="ltx_ref">2019</a>)</cite>, translates into lower overall communication costs and, enables better support for heterogeneous pools of clients regardless of their compute capabilities <cite class="ltx_cite ltx_citemacro_citep">(Horvath et al., <a href="#bib.bib27" title="" class="ltx_ref">2021</a>)</cite>; and, more generally, better aggregation strategies that enable faster convergence <cite class="ltx_cite ltx_citemacro_citep">(Li et al., <a href="#bib.bib33" title="" class="ltx_ref">2018</a>; Reddi et al., <a href="#bib.bib42" title="" class="ltx_ref">2021</a>)</cite>, reducing in this way overall device utilization (e.g. fewer local epochs) and number of communication rounds. Other optimization techniques such as quantization and sparsity have been used in the context of FL but mostly as a way to reduce communication costs <cite class="ltx_cite ltx_citemacro_citep">(Liu et al., <a href="#bib.bib35" title="" class="ltx_ref">2021</a>; Amiri et al., <a href="#bib.bib1" title="" class="ltx_ref">2020</a>; Shahid et al., <a href="#bib.bib45" title="" class="ltx_ref">2021</a>)</cite> but not to accelerate on-device training.</p>
</div>
<div id="S1.p3" class="ltx_para ltx_noindent">
<p id="S1.p3.1" class="ltx_p">The use of sparse operations (e.g. convolutions) at training time has recently been shown to be an effective technique to accelerate training in centralised settings <cite class="ltx_cite ltx_citemacro_citep">(Sun et al., <a href="#bib.bib47" title="" class="ltx_ref">2017</a>; Goli &amp; Aamodt, <a href="#bib.bib10" title="" class="ltx_ref">2020</a>; Raihan &amp; Aamodt, <a href="#bib.bib41" title="" class="ltx_ref">2020</a>)</cite>. The resulting models are as good or close to their densely-trained counterparts despite reducing by up to 90% their FLOPs budget and, resulting in an overall up to <math id="S1.p3.1.m1.1" class="ltx_math_unparsed" alttext="3.3\times" display="inline"><semantics id="S1.p3.1.m1.1a"><mrow id="S1.p3.1.m1.1b"><mn id="S1.p3.1.m1.1.1">3.3</mn><mo lspace="0.222em" id="S1.p3.1.m1.1.2">×</mo></mrow><annotation encoding="application/x-tex" id="S1.p3.1.m1.1c">3.3\times</annotation></semantics></math> training speedup. Acceleration is achieved by performing sparse convolutions during the forward and/or backward pass, which requires at least one of the operands (i.e. inputs, weights, gradients) to be sufficiently sparse and, software and hardware support for such operations. However, it is unclear how the different FL-specific challenges (i.e. data imbalance, stateless clients, periodic aggregation) will restrict the quality of the global model.</p>
</div>
<div id="S1.p4" class="ltx_para ltx_noindent">
<p id="S1.p4.1" class="ltx_p">This work considers the challenges and opportunities of inducing high levels of sparsity to accelerate training on-device for FL workloads, and provides the following contributions:</p>
</div>
<div id="S1.p5" class="ltx_para ltx_noindent">
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">The first framework for Federated Learning that leverages sparsity as a mechanism to accelerate on-device training by inducing up to 95% sparse weights and activations. This work considers three popular datasets: CIFAR-10 and FEMNIST for image classification and, SpeechCommands for audio classification.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">A study on the unique aspects that arise when introducing sparsity at training time in FL: the degree of overlap between non-zero values decreases with layer-depth index and, the locations of zero-valued weights in the global model remain constant throughout most of the training rounds. Our discussion sets the foundations for future research in this area.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i3.p1" class="ltx_para ltx_noindent">
<p id="S1.I1.i3.p1.1" class="ltx_p">A technique that alleviates the accuracy degradation when applying a state-of-the-art off-the-shelf sparsification method to the FL domain. <em id="S1.I1.i3.p1.1.1" class="ltx_emph ltx_font_italic">ZeroFL</em> achieves +2.3% and +1.5% higher accuracy than baselines when inducing 90% and 95% sparsity respectively. In addition, ZeroFL also leverages sparsity when transferring the local models to the central server reducing communication costs by <math id="S1.I1.i3.p1.1.m1.1" class="ltx_math_unparsed" alttext="3.0\times" display="inline"><semantics id="S1.I1.i3.p1.1.m1.1a"><mrow id="S1.I1.i3.p1.1.m1.1b"><mn id="S1.I1.i3.p1.1.m1.1.1">3.0</mn><mo lspace="0.222em" id="S1.I1.i3.p1.1.m1.1.2">×</mo></mrow><annotation encoding="application/x-tex" id="S1.I1.i3.p1.1.m1.1c">3.0\times</annotation></semantics></math> while still outperforming competitive baselines.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>

<div id="S2.p1" class="ltx_para ltx_noindent">
<p id="S2.p1.1" class="ltx_p">Pruning neural networks involves discarding parts of the model (e.g. individual weights or entire channels) that are <em id="S2.p1.1.1" class="ltx_emph ltx_font_italic">irrelevant</em> for solving the task at hand. This procedure generally produces a lightweight model representation more suitable for deployment on constrained devices with limited memory and compute budgets. In this section we detail how different forms of pruning or sparsification have been used to accelerate inference and, to a lesser extent, training. We also discuss how these have been introduced to reduce communication costs in distributed and federated learning.</p>
</div>
<div id="S2.p2" class="ltx_para ltx_noindent">
<p id="S2.p2.1" class="ltx_p"><span id="S2.p2.1.1" class="ltx_text ltx_font_bold">Unstructured pruning.</span> Frameworks relying on unstructured pruning <cite class="ltx_cite ltx_citemacro_citep">(Han et al., <a href="#bib.bib13" title="" class="ltx_ref">2015a</a>; <a href="#bib.bib14" title="" class="ltx_ref">b</a>; Guo et al., <a href="#bib.bib11" title="" class="ltx_ref">2016</a>; Molchanov et al., <a href="#bib.bib38" title="" class="ltx_ref">2017</a>)</cite> often achieve higher compression ratios at the expense of inference stages being as compute intensive in practice as those of the original model. This is because, assuming pruning has been homogeneously applied on the model, sparse operations can only be efficiently accelerated on supported hardware, such as modern GPUs <cite class="ltx_cite ltx_citemacro_citep">(Wang, <a href="#bib.bib52" title="" class="ltx_ref">2020</a>; Zachariadis et al., <a href="#bib.bib58" title="" class="ltx_ref">2020</a>; Hong et al., <a href="#bib.bib25" title="" class="ltx_ref">2018</a>)</cite> or custom accelerators <cite class="ltx_cite ltx_citemacro_citep">(Zhang et al., <a href="#bib.bib59" title="" class="ltx_ref">2016</a>; Lu et al., <a href="#bib.bib36" title="" class="ltx_ref">2019</a>; Srivastava et al., <a href="#bib.bib46" title="" class="ltx_ref">2020</a>)</cite>, for a sufficiently high sparsity ratio. The lower the ratio, the less likely sparse operations would translate into measurable speedups. In the case of CPUs, speedups due to sparse operations where one operand is unstructurally sparse are often only feasible at 90% sparsity ratios or higher <cite class="ltx_cite ltx_citemacro_citep">(Hong et al., <a href="#bib.bib26" title="" class="ltx_ref">2019</a>; Wang, <a href="#bib.bib53" title="" class="ltx_ref">2021</a>)</cite>.</p>
</div>
<div id="S2.p3" class="ltx_para ltx_noindent">
<p id="S2.p3.4" class="ltx_p"><span id="S2.p3.4.1" class="ltx_text ltx_font_bold">Structured pruning.</span> Methods that apply structured pruning <cite class="ltx_cite ltx_citemacro_citep">(He et al., <a href="#bib.bib20" title="" class="ltx_ref">2018</a>; <a href="#bib.bib21" title="" class="ltx_ref">2017</a>; Jian-Hao Luo &amp; Lin, <a href="#bib.bib29" title="" class="ltx_ref">2017</a>; Yu et al., <a href="#bib.bib56" title="" class="ltx_ref">2018</a>; Molchanov et al., <a href="#bib.bib39" title="" class="ltx_ref">2019</a>; Wang et al., <a href="#bib.bib51" title="" class="ltx_ref">2017</a>)</cite>, on the other hand, trade compression for acceleration potential. These approaches modify the underlying computational graph by discarding entire channels, resulting in smaller but still dense convolution operations, or by removing the nodes all together if an entire layer is set to be removed by the chosen pruning strategy. As a result, structured pruning frameworks are the preferred option when aiming to accelerate inference on general purpose hardware.
A body of work across structured and unstructured pruning methods, attempts to induce structure in otherwise randomly sparse networks <cite class="ltx_cite ltx_citemacro_cite">S. Gray &amp; Kingma (<a href="#bib.bib44" title="" class="ltx_ref">2017</a>); Ren et al. (<a href="#bib.bib43" title="" class="ltx_ref">2018</a>); Wen et al. (<a href="#bib.bib55" title="" class="ltx_ref">2020</a>); Verelst &amp; Tuytelaars (<a href="#bib.bib49" title="" class="ltx_ref">2020</a>)</cite>. This is often referred to as <span id="S2.p3.4.2" class="ltx_text ltx_font_italic">block sparsity</span> and consists in subdividing the matrix representations of inputs or weights into tiles (e.g. <math id="S2.p3.1.m1.1" class="ltx_Math" alttext="16" display="inline"><semantics id="S2.p3.1.m1.1a"><mn id="S2.p3.1.m1.1.1" xref="S2.p3.1.m1.1.1.cmml">16</mn><annotation-xml encoding="MathML-Content" id="S2.p3.1.m1.1b"><cn type="integer" id="S2.p3.1.m1.1.1.cmml" xref="S2.p3.1.m1.1.1">16</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.p3.1.m1.1c">16</annotation></semantics></math><math id="S2.p3.2.m2.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S2.p3.2.m2.1a"><mo id="S2.p3.2.m2.1.1" xref="S2.p3.2.m2.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S2.p3.2.m2.1b"><times id="S2.p3.2.m2.1.1.cmml" xref="S2.p3.2.m2.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S2.p3.2.m2.1c">\times</annotation></semantics></math><math id="S2.p3.3.m3.1" class="ltx_Math" alttext="16" display="inline"><semantics id="S2.p3.3.m3.1a"><mn id="S2.p3.3.m3.1.1" xref="S2.p3.3.m3.1.1.cmml">16</mn><annotation-xml encoding="MathML-Content" id="S2.p3.3.m3.1b"><cn type="integer" id="S2.p3.3.m3.1.1.cmml" xref="S2.p3.3.m3.1.1">16</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.p3.3.m3.1c">16</annotation></semantics></math> tiles), and restrict the training in such a way that some tiles contain only zeros while the rest remain dense and real-valued. Matrix-matrix multiplications following such a pattern can be accelerated at lower global sparsity ratios compared to those following unstructured sparsity <cite class="ltx_cite ltx_citemacro_cite">Hoefler et al. (<a href="#bib.bib24" title="" class="ltx_ref">2021</a>)</cite>. Other forms of constraining how sparsity occurs have been proposed, for example, a cache-aware reordering on the sparsity pattern of the weights <cite class="ltx_cite ltx_citemacro_cite">Elsen et al. (<a href="#bib.bib9" title="" class="ltx_ref">2020</a>)</cite>. This can be used to ensure high cache reuse on Cortex-A mobile CPUs, resulting in <math id="S2.p3.4.m4.1" class="ltx_math_unparsed" alttext="2.4\times" display="inline"><semantics id="S2.p3.4.m4.1a"><mrow id="S2.p3.4.m4.1b"><mn id="S2.p3.4.m4.1.1">2.4</mn><mo lspace="0.222em" id="S2.p3.4.m4.1.2">×</mo></mrow><annotation encoding="application/x-tex" id="S2.p3.4.m4.1c">2.4\times</annotation></semantics></math> acceleration of MobileNets.</p>
</div>
<div id="S2.p4" class="ltx_para ltx_noindent">
<p id="S2.p4.1" class="ltx_p"><span id="S2.p4.1.1" class="ltx_text ltx_font_bold">Sparse training.</span> The majority of works making use of sparsity are envisioned for either model compression or to accelerate inference. Only recently, sparse operations have been considered to accelerate training. The work of <cite class="ltx_cite ltx_citemacro_citet">Sun et al. (<a href="#bib.bib47" title="" class="ltx_ref">2017</a>)</cite> presented a mechanism to induce high levels of sparsity in the gradients during backpropagation and, demonstrated large speedups when training MLP-only models. More recently, <cite class="ltx_cite ltx_citemacro_citet">Goli &amp; Aamodt (<a href="#bib.bib10" title="" class="ltx_ref">2020</a>)</cite> build upon the observation that gradients from consecutive batches are near identical. They present a framework to reuse a random sample of previously computed gradients and their thresholded difference w.r.t gradients from the current batch, resulting in a sparse tensor. Their framework accelerates training of CNNs by performing sparse convolutions during the backward pass at the cost of pre-computing partial gradients during forward pass. Closer to our work is SWAT <cite class="ltx_cite ltx_citemacro_citep">(Raihan &amp; Aamodt, <a href="#bib.bib41" title="" class="ltx_ref">2020</a>)</cite>, a framework that relies on sparsified weights during inference and sparsified weights and activations for backward propagation.</p>
</div>
<div id="S2.p5" class="ltx_para ltx_noindent">
<p id="S2.p5.1" class="ltx_p"><span id="S2.p5.1.1" class="ltx_text ltx_font_bold">Compression on communication.</span> <cite class="ltx_cite ltx_citemacro_cite">Konečnỳ et al. (<a href="#bib.bib31" title="" class="ltx_ref">2016</a>)</cite> proposed to restricts the updates of weight matrices to have a pre-specified structure in order to reduce the total communication cost. The structure can either be random or low-rank structure. ATOMO <cite class="ltx_cite ltx_citemacro_citep">(Wang et al., <a href="#bib.bib50" title="" class="ltx_ref">2018</a>)</cite> introduced a generalised gradient decomposition and sparsification technique, aiming to reduce the gradient sizes communicated upstream. <cite class="ltx_cite ltx_citemacro_cite">Han et al. (<a href="#bib.bib12" title="" class="ltx_ref">2020</a>)</cite> proposed a different way of aggregation in the server, which instead of aggregating model weights, it aggregates the sparsified gradients after every local update step. However, since the method requires to aggregate sparsified gradient after every step, it cannot benefit from multiple local updates. Hence it might require extra communication rounds to reach the target performance. PruneFL <cite class="ltx_cite ltx_citemacro_cite">Jiang et al. (<a href="#bib.bib30" title="" class="ltx_ref">2019</a>)</cite> reduced both computation and communication overhead to minimize the overall training time by including an initial pruning at one selected client and further pruning as a part of FL process.</p>
</div>
<div id="S2.p6" class="ltx_para ltx_noindent">
<p id="S2.p6.1" class="ltx_p">Nevertheless, none of the aforementioned works explored the challenges of extending state-of-the-art sparsification methods to federated learning as a way to accelerate on-device training. With ZeroFL, a framework specifically tailored to the FL setting, achieves better accuracy retention than with existing methods that remain exclusive to the centralised training paradigm.</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Background</h2>

<div id="S3.p1" class="ltx_para ltx_noindent">
<p id="S3.p1.1" class="ltx_p">This section describes the state-of-the-art sparse training method SWAT <cite class="ltx_cite ltx_citemacro_citep">(Raihan &amp; Aamodt, <a href="#bib.bib41" title="" class="ltx_ref">2020</a>)</cite>; the way we adapt it to the FL contexts; and the related challenges that would need be addressed.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Sparse Weights and Activations Training</h3>

<div id="S3.SS1.p1" class="ltx_para ltx_noindent">
<p id="S3.SS1.p1.12" class="ltx_p">The SWAT framework embodies two strategies in the training process. During each forward pass, the weights are partitioned into active weights and non-active weights by a <span id="S3.SS1.p1.12.1" class="ltx_text ltx_font_typewriter">top-K</span> (in magnitude) operator and only the active weights are used. For the <math id="S3.SS1.p1.1.m1.1" class="ltx_Math" alttext="l^{th}" display="inline"><semantics id="S3.SS1.p1.1.m1.1a"><msup id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml"><mi id="S3.SS1.p1.1.m1.1.1.2" xref="S3.SS1.p1.1.m1.1.1.2.cmml">l</mi><mrow id="S3.SS1.p1.1.m1.1.1.3" xref="S3.SS1.p1.1.m1.1.1.3.cmml"><mi id="S3.SS1.p1.1.m1.1.1.3.2" xref="S3.SS1.p1.1.m1.1.1.3.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p1.1.m1.1.1.3.1" xref="S3.SS1.p1.1.m1.1.1.3.1.cmml">​</mo><mi id="S3.SS1.p1.1.m1.1.1.3.3" xref="S3.SS1.p1.1.m1.1.1.3.3.cmml">h</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.1b"><apply id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.1.m1.1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1">superscript</csymbol><ci id="S3.SS1.p1.1.m1.1.1.2.cmml" xref="S3.SS1.p1.1.m1.1.1.2">𝑙</ci><apply id="S3.SS1.p1.1.m1.1.1.3.cmml" xref="S3.SS1.p1.1.m1.1.1.3"><times id="S3.SS1.p1.1.m1.1.1.3.1.cmml" xref="S3.SS1.p1.1.m1.1.1.3.1"></times><ci id="S3.SS1.p1.1.m1.1.1.3.2.cmml" xref="S3.SS1.p1.1.m1.1.1.3.2">𝑡</ci><ci id="S3.SS1.p1.1.m1.1.1.3.3.cmml" xref="S3.SS1.p1.1.m1.1.1.3.3">ℎ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.1c">l^{th}</annotation></semantics></math> layer in the model, the layer maps the input activations <math id="S3.SS1.p1.2.m2.1" class="ltx_Math" alttext="a_{l-1}" display="inline"><semantics id="S3.SS1.p1.2.m2.1a"><msub id="S3.SS1.p1.2.m2.1.1" xref="S3.SS1.p1.2.m2.1.1.cmml"><mi id="S3.SS1.p1.2.m2.1.1.2" xref="S3.SS1.p1.2.m2.1.1.2.cmml">a</mi><mrow id="S3.SS1.p1.2.m2.1.1.3" xref="S3.SS1.p1.2.m2.1.1.3.cmml"><mi id="S3.SS1.p1.2.m2.1.1.3.2" xref="S3.SS1.p1.2.m2.1.1.3.2.cmml">l</mi><mo id="S3.SS1.p1.2.m2.1.1.3.1" xref="S3.SS1.p1.2.m2.1.1.3.1.cmml">−</mo><mn id="S3.SS1.p1.2.m2.1.1.3.3" xref="S3.SS1.p1.2.m2.1.1.3.3.cmml">1</mn></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.2.m2.1b"><apply id="S3.SS1.p1.2.m2.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.2.m2.1.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1">subscript</csymbol><ci id="S3.SS1.p1.2.m2.1.1.2.cmml" xref="S3.SS1.p1.2.m2.1.1.2">𝑎</ci><apply id="S3.SS1.p1.2.m2.1.1.3.cmml" xref="S3.SS1.p1.2.m2.1.1.3"><minus id="S3.SS1.p1.2.m2.1.1.3.1.cmml" xref="S3.SS1.p1.2.m2.1.1.3.1"></minus><ci id="S3.SS1.p1.2.m2.1.1.3.2.cmml" xref="S3.SS1.p1.2.m2.1.1.3.2">𝑙</ci><cn type="integer" id="S3.SS1.p1.2.m2.1.1.3.3.cmml" xref="S3.SS1.p1.2.m2.1.1.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.2.m2.1c">a_{l-1}</annotation></semantics></math> onto feature maps <math id="S3.SS1.p1.3.m3.1" class="ltx_Math" alttext="o_{l}" display="inline"><semantics id="S3.SS1.p1.3.m3.1a"><msub id="S3.SS1.p1.3.m3.1.1" xref="S3.SS1.p1.3.m3.1.1.cmml"><mi id="S3.SS1.p1.3.m3.1.1.2" xref="S3.SS1.p1.3.m3.1.1.2.cmml">o</mi><mi id="S3.SS1.p1.3.m3.1.1.3" xref="S3.SS1.p1.3.m3.1.1.3.cmml">l</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.3.m3.1b"><apply id="S3.SS1.p1.3.m3.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.3.m3.1.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1">subscript</csymbol><ci id="S3.SS1.p1.3.m3.1.1.2.cmml" xref="S3.SS1.p1.3.m3.1.1.2">𝑜</ci><ci id="S3.SS1.p1.3.m3.1.1.3.cmml" xref="S3.SS1.p1.3.m3.1.1.3">𝑙</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.3.m3.1c">o_{l}</annotation></semantics></math> using function <math id="S3.SS1.p1.4.m4.1" class="ltx_Math" alttext="f_{l}" display="inline"><semantics id="S3.SS1.p1.4.m4.1a"><msub id="S3.SS1.p1.4.m4.1.1" xref="S3.SS1.p1.4.m4.1.1.cmml"><mi id="S3.SS1.p1.4.m4.1.1.2" xref="S3.SS1.p1.4.m4.1.1.2.cmml">f</mi><mi id="S3.SS1.p1.4.m4.1.1.3" xref="S3.SS1.p1.4.m4.1.1.3.cmml">l</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.4.m4.1b"><apply id="S3.SS1.p1.4.m4.1.1.cmml" xref="S3.SS1.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.4.m4.1.1.1.cmml" xref="S3.SS1.p1.4.m4.1.1">subscript</csymbol><ci id="S3.SS1.p1.4.m4.1.1.2.cmml" xref="S3.SS1.p1.4.m4.1.1.2">𝑓</ci><ci id="S3.SS1.p1.4.m4.1.1.3.cmml" xref="S3.SS1.p1.4.m4.1.1.3">𝑙</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.4.m4.1c">f_{l}</annotation></semantics></math>: <math id="S3.SS1.p1.5.m5.2" class="ltx_Math" alttext="o_{l}=f_{l}(a_{l-1},w_{l})" display="inline"><semantics id="S3.SS1.p1.5.m5.2a"><mrow id="S3.SS1.p1.5.m5.2.2" xref="S3.SS1.p1.5.m5.2.2.cmml"><msub id="S3.SS1.p1.5.m5.2.2.4" xref="S3.SS1.p1.5.m5.2.2.4.cmml"><mi id="S3.SS1.p1.5.m5.2.2.4.2" xref="S3.SS1.p1.5.m5.2.2.4.2.cmml">o</mi><mi id="S3.SS1.p1.5.m5.2.2.4.3" xref="S3.SS1.p1.5.m5.2.2.4.3.cmml">l</mi></msub><mo id="S3.SS1.p1.5.m5.2.2.3" xref="S3.SS1.p1.5.m5.2.2.3.cmml">=</mo><mrow id="S3.SS1.p1.5.m5.2.2.2" xref="S3.SS1.p1.5.m5.2.2.2.cmml"><msub id="S3.SS1.p1.5.m5.2.2.2.4" xref="S3.SS1.p1.5.m5.2.2.2.4.cmml"><mi id="S3.SS1.p1.5.m5.2.2.2.4.2" xref="S3.SS1.p1.5.m5.2.2.2.4.2.cmml">f</mi><mi id="S3.SS1.p1.5.m5.2.2.2.4.3" xref="S3.SS1.p1.5.m5.2.2.2.4.3.cmml">l</mi></msub><mo lspace="0em" rspace="0em" id="S3.SS1.p1.5.m5.2.2.2.3" xref="S3.SS1.p1.5.m5.2.2.2.3.cmml">​</mo><mrow id="S3.SS1.p1.5.m5.2.2.2.2.2" xref="S3.SS1.p1.5.m5.2.2.2.2.3.cmml"><mo stretchy="false" id="S3.SS1.p1.5.m5.2.2.2.2.2.3" xref="S3.SS1.p1.5.m5.2.2.2.2.3.cmml">(</mo><msub id="S3.SS1.p1.5.m5.1.1.1.1.1.1" xref="S3.SS1.p1.5.m5.1.1.1.1.1.1.cmml"><mi id="S3.SS1.p1.5.m5.1.1.1.1.1.1.2" xref="S3.SS1.p1.5.m5.1.1.1.1.1.1.2.cmml">a</mi><mrow id="S3.SS1.p1.5.m5.1.1.1.1.1.1.3" xref="S3.SS1.p1.5.m5.1.1.1.1.1.1.3.cmml"><mi id="S3.SS1.p1.5.m5.1.1.1.1.1.1.3.2" xref="S3.SS1.p1.5.m5.1.1.1.1.1.1.3.2.cmml">l</mi><mo id="S3.SS1.p1.5.m5.1.1.1.1.1.1.3.1" xref="S3.SS1.p1.5.m5.1.1.1.1.1.1.3.1.cmml">−</mo><mn id="S3.SS1.p1.5.m5.1.1.1.1.1.1.3.3" xref="S3.SS1.p1.5.m5.1.1.1.1.1.1.3.3.cmml">1</mn></mrow></msub><mo id="S3.SS1.p1.5.m5.2.2.2.2.2.4" xref="S3.SS1.p1.5.m5.2.2.2.2.3.cmml">,</mo><msub id="S3.SS1.p1.5.m5.2.2.2.2.2.2" xref="S3.SS1.p1.5.m5.2.2.2.2.2.2.cmml"><mi id="S3.SS1.p1.5.m5.2.2.2.2.2.2.2" xref="S3.SS1.p1.5.m5.2.2.2.2.2.2.2.cmml">w</mi><mi id="S3.SS1.p1.5.m5.2.2.2.2.2.2.3" xref="S3.SS1.p1.5.m5.2.2.2.2.2.2.3.cmml">l</mi></msub><mo stretchy="false" id="S3.SS1.p1.5.m5.2.2.2.2.2.5" xref="S3.SS1.p1.5.m5.2.2.2.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.5.m5.2b"><apply id="S3.SS1.p1.5.m5.2.2.cmml" xref="S3.SS1.p1.5.m5.2.2"><eq id="S3.SS1.p1.5.m5.2.2.3.cmml" xref="S3.SS1.p1.5.m5.2.2.3"></eq><apply id="S3.SS1.p1.5.m5.2.2.4.cmml" xref="S3.SS1.p1.5.m5.2.2.4"><csymbol cd="ambiguous" id="S3.SS1.p1.5.m5.2.2.4.1.cmml" xref="S3.SS1.p1.5.m5.2.2.4">subscript</csymbol><ci id="S3.SS1.p1.5.m5.2.2.4.2.cmml" xref="S3.SS1.p1.5.m5.2.2.4.2">𝑜</ci><ci id="S3.SS1.p1.5.m5.2.2.4.3.cmml" xref="S3.SS1.p1.5.m5.2.2.4.3">𝑙</ci></apply><apply id="S3.SS1.p1.5.m5.2.2.2.cmml" xref="S3.SS1.p1.5.m5.2.2.2"><times id="S3.SS1.p1.5.m5.2.2.2.3.cmml" xref="S3.SS1.p1.5.m5.2.2.2.3"></times><apply id="S3.SS1.p1.5.m5.2.2.2.4.cmml" xref="S3.SS1.p1.5.m5.2.2.2.4"><csymbol cd="ambiguous" id="S3.SS1.p1.5.m5.2.2.2.4.1.cmml" xref="S3.SS1.p1.5.m5.2.2.2.4">subscript</csymbol><ci id="S3.SS1.p1.5.m5.2.2.2.4.2.cmml" xref="S3.SS1.p1.5.m5.2.2.2.4.2">𝑓</ci><ci id="S3.SS1.p1.5.m5.2.2.2.4.3.cmml" xref="S3.SS1.p1.5.m5.2.2.2.4.3">𝑙</ci></apply><interval closure="open" id="S3.SS1.p1.5.m5.2.2.2.2.3.cmml" xref="S3.SS1.p1.5.m5.2.2.2.2.2"><apply id="S3.SS1.p1.5.m5.1.1.1.1.1.1.cmml" xref="S3.SS1.p1.5.m5.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.5.m5.1.1.1.1.1.1.1.cmml" xref="S3.SS1.p1.5.m5.1.1.1.1.1.1">subscript</csymbol><ci id="S3.SS1.p1.5.m5.1.1.1.1.1.1.2.cmml" xref="S3.SS1.p1.5.m5.1.1.1.1.1.1.2">𝑎</ci><apply id="S3.SS1.p1.5.m5.1.1.1.1.1.1.3.cmml" xref="S3.SS1.p1.5.m5.1.1.1.1.1.1.3"><minus id="S3.SS1.p1.5.m5.1.1.1.1.1.1.3.1.cmml" xref="S3.SS1.p1.5.m5.1.1.1.1.1.1.3.1"></minus><ci id="S3.SS1.p1.5.m5.1.1.1.1.1.1.3.2.cmml" xref="S3.SS1.p1.5.m5.1.1.1.1.1.1.3.2">𝑙</ci><cn type="integer" id="S3.SS1.p1.5.m5.1.1.1.1.1.1.3.3.cmml" xref="S3.SS1.p1.5.m5.1.1.1.1.1.1.3.3">1</cn></apply></apply><apply id="S3.SS1.p1.5.m5.2.2.2.2.2.2.cmml" xref="S3.SS1.p1.5.m5.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p1.5.m5.2.2.2.2.2.2.1.cmml" xref="S3.SS1.p1.5.m5.2.2.2.2.2.2">subscript</csymbol><ci id="S3.SS1.p1.5.m5.2.2.2.2.2.2.2.cmml" xref="S3.SS1.p1.5.m5.2.2.2.2.2.2.2">𝑤</ci><ci id="S3.SS1.p1.5.m5.2.2.2.2.2.2.3.cmml" xref="S3.SS1.p1.5.m5.2.2.2.2.2.2.3">𝑙</ci></apply></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.5.m5.2c">o_{l}=f_{l}(a_{l-1},w_{l})</annotation></semantics></math>. In this work we consider <math id="S3.SS1.p1.6.m6.1" class="ltx_Math" alttext="f_{l}" display="inline"><semantics id="S3.SS1.p1.6.m6.1a"><msub id="S3.SS1.p1.6.m6.1.1" xref="S3.SS1.p1.6.m6.1.1.cmml"><mi id="S3.SS1.p1.6.m6.1.1.2" xref="S3.SS1.p1.6.m6.1.1.2.cmml">f</mi><mi id="S3.SS1.p1.6.m6.1.1.3" xref="S3.SS1.p1.6.m6.1.1.3.cmml">l</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.6.m6.1b"><apply id="S3.SS1.p1.6.m6.1.1.cmml" xref="S3.SS1.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.6.m6.1.1.1.cmml" xref="S3.SS1.p1.6.m6.1.1">subscript</csymbol><ci id="S3.SS1.p1.6.m6.1.1.2.cmml" xref="S3.SS1.p1.6.m6.1.1.2">𝑓</ci><ci id="S3.SS1.p1.6.m6.1.1.3.cmml" xref="S3.SS1.p1.6.m6.1.1.3">𝑙</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.6.m6.1c">f_{l}</annotation></semantics></math> being the <math id="S3.SS1.p1.7.m7.1" class="ltx_Math" alttext="3\times 3" display="inline"><semantics id="S3.SS1.p1.7.m7.1a"><mrow id="S3.SS1.p1.7.m7.1.1" xref="S3.SS1.p1.7.m7.1.1.cmml"><mn id="S3.SS1.p1.7.m7.1.1.2" xref="S3.SS1.p1.7.m7.1.1.2.cmml">3</mn><mo lspace="0.222em" rspace="0.222em" id="S3.SS1.p1.7.m7.1.1.1" xref="S3.SS1.p1.7.m7.1.1.1.cmml">×</mo><mn id="S3.SS1.p1.7.m7.1.1.3" xref="S3.SS1.p1.7.m7.1.1.3.cmml">3</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.7.m7.1b"><apply id="S3.SS1.p1.7.m7.1.1.cmml" xref="S3.SS1.p1.7.m7.1.1"><times id="S3.SS1.p1.7.m7.1.1.1.cmml" xref="S3.SS1.p1.7.m7.1.1.1"></times><cn type="integer" id="S3.SS1.p1.7.m7.1.1.2.cmml" xref="S3.SS1.p1.7.m7.1.1.2">3</cn><cn type="integer" id="S3.SS1.p1.7.m7.1.1.3.cmml" xref="S3.SS1.p1.7.m7.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.7.m7.1c">3\times 3</annotation></semantics></math> convolution in the <math id="S3.SS1.p1.8.m8.1" class="ltx_Math" alttext="l" display="inline"><semantics id="S3.SS1.p1.8.m8.1a"><mi id="S3.SS1.p1.8.m8.1.1" xref="S3.SS1.p1.8.m8.1.1.cmml">l</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.8.m8.1b"><ci id="S3.SS1.p1.8.m8.1.1.cmml" xref="S3.SS1.p1.8.m8.1.1">𝑙</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.8.m8.1c">l</annotation></semantics></math>-th layer. In the backward pass, the gradient of input activations (<math id="S3.SS1.p1.9.m9.1" class="ltx_Math" alttext="\bigtriangledown a_{l-1}" display="inline"><semantics id="S3.SS1.p1.9.m9.1a"><mrow id="S3.SS1.p1.9.m9.1.1" xref="S3.SS1.p1.9.m9.1.1.cmml"><mo rspace="0em" id="S3.SS1.p1.9.m9.1.1a" xref="S3.SS1.p1.9.m9.1.1.cmml">▽</mo><msub id="S3.SS1.p1.9.m9.1.1.2" xref="S3.SS1.p1.9.m9.1.1.2.cmml"><mi id="S3.SS1.p1.9.m9.1.1.2.2" xref="S3.SS1.p1.9.m9.1.1.2.2.cmml">a</mi><mrow id="S3.SS1.p1.9.m9.1.1.2.3" xref="S3.SS1.p1.9.m9.1.1.2.3.cmml"><mi id="S3.SS1.p1.9.m9.1.1.2.3.2" xref="S3.SS1.p1.9.m9.1.1.2.3.2.cmml">l</mi><mo id="S3.SS1.p1.9.m9.1.1.2.3.1" xref="S3.SS1.p1.9.m9.1.1.2.3.1.cmml">−</mo><mn id="S3.SS1.p1.9.m9.1.1.2.3.3" xref="S3.SS1.p1.9.m9.1.1.2.3.3.cmml">1</mn></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.9.m9.1b"><apply id="S3.SS1.p1.9.m9.1.1.cmml" xref="S3.SS1.p1.9.m9.1.1"><ci id="S3.SS1.p1.9.m9.1.1.1.cmml" xref="S3.SS1.p1.9.m9.1.1">▽</ci><apply id="S3.SS1.p1.9.m9.1.1.2.cmml" xref="S3.SS1.p1.9.m9.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p1.9.m9.1.1.2.1.cmml" xref="S3.SS1.p1.9.m9.1.1.2">subscript</csymbol><ci id="S3.SS1.p1.9.m9.1.1.2.2.cmml" xref="S3.SS1.p1.9.m9.1.1.2.2">𝑎</ci><apply id="S3.SS1.p1.9.m9.1.1.2.3.cmml" xref="S3.SS1.p1.9.m9.1.1.2.3"><minus id="S3.SS1.p1.9.m9.1.1.2.3.1.cmml" xref="S3.SS1.p1.9.m9.1.1.2.3.1"></minus><ci id="S3.SS1.p1.9.m9.1.1.2.3.2.cmml" xref="S3.SS1.p1.9.m9.1.1.2.3.2">𝑙</ci><cn type="integer" id="S3.SS1.p1.9.m9.1.1.2.3.3.cmml" xref="S3.SS1.p1.9.m9.1.1.2.3.3">1</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.9.m9.1c">\bigtriangledown a_{l-1}</annotation></semantics></math>) and the gradient of weights (<math id="S3.SS1.p1.10.m10.1" class="ltx_Math" alttext="\bigtriangledown w_{l}" display="inline"><semantics id="S3.SS1.p1.10.m10.1a"><mrow id="S3.SS1.p1.10.m10.1.1" xref="S3.SS1.p1.10.m10.1.1.cmml"><mo rspace="0em" id="S3.SS1.p1.10.m10.1.1a" xref="S3.SS1.p1.10.m10.1.1.cmml">▽</mo><msub id="S3.SS1.p1.10.m10.1.1.2" xref="S3.SS1.p1.10.m10.1.1.2.cmml"><mi id="S3.SS1.p1.10.m10.1.1.2.2" xref="S3.SS1.p1.10.m10.1.1.2.2.cmml">w</mi><mi id="S3.SS1.p1.10.m10.1.1.2.3" xref="S3.SS1.p1.10.m10.1.1.2.3.cmml">l</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.10.m10.1b"><apply id="S3.SS1.p1.10.m10.1.1.cmml" xref="S3.SS1.p1.10.m10.1.1"><ci id="S3.SS1.p1.10.m10.1.1.1.cmml" xref="S3.SS1.p1.10.m10.1.1">▽</ci><apply id="S3.SS1.p1.10.m10.1.1.2.cmml" xref="S3.SS1.p1.10.m10.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p1.10.m10.1.1.2.1.cmml" xref="S3.SS1.p1.10.m10.1.1.2">subscript</csymbol><ci id="S3.SS1.p1.10.m10.1.1.2.2.cmml" xref="S3.SS1.p1.10.m10.1.1.2.2">𝑤</ci><ci id="S3.SS1.p1.10.m10.1.1.2.3.cmml" xref="S3.SS1.p1.10.m10.1.1.2.3">𝑙</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.10.m10.1c">\bigtriangledown w_{l}</annotation></semantics></math>) are calculated represented by functions <math id="S3.SS1.p1.11.m11.1" class="ltx_Math" alttext="G_{l}" display="inline"><semantics id="S3.SS1.p1.11.m11.1a"><msub id="S3.SS1.p1.11.m11.1.1" xref="S3.SS1.p1.11.m11.1.1.cmml"><mi id="S3.SS1.p1.11.m11.1.1.2" xref="S3.SS1.p1.11.m11.1.1.2.cmml">G</mi><mi id="S3.SS1.p1.11.m11.1.1.3" xref="S3.SS1.p1.11.m11.1.1.3.cmml">l</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.11.m11.1b"><apply id="S3.SS1.p1.11.m11.1.1.cmml" xref="S3.SS1.p1.11.m11.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.11.m11.1.1.1.cmml" xref="S3.SS1.p1.11.m11.1.1">subscript</csymbol><ci id="S3.SS1.p1.11.m11.1.1.2.cmml" xref="S3.SS1.p1.11.m11.1.1.2">𝐺</ci><ci id="S3.SS1.p1.11.m11.1.1.3.cmml" xref="S3.SS1.p1.11.m11.1.1.3">𝑙</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.11.m11.1c">G_{l}</annotation></semantics></math> and <math id="S3.SS1.p1.12.m12.1" class="ltx_Math" alttext="H_{l}" display="inline"><semantics id="S3.SS1.p1.12.m12.1a"><msub id="S3.SS1.p1.12.m12.1.1" xref="S3.SS1.p1.12.m12.1.1.cmml"><mi id="S3.SS1.p1.12.m12.1.1.2" xref="S3.SS1.p1.12.m12.1.1.2.cmml">H</mi><mi id="S3.SS1.p1.12.m12.1.1.3" xref="S3.SS1.p1.12.m12.1.1.3.cmml">l</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.12.m12.1b"><apply id="S3.SS1.p1.12.m12.1.1.cmml" xref="S3.SS1.p1.12.m12.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.12.m12.1.1.1.cmml" xref="S3.SS1.p1.12.m12.1.1">subscript</csymbol><ci id="S3.SS1.p1.12.m12.1.1.2.cmml" xref="S3.SS1.p1.12.m12.1.1.2">𝐻</ci><ci id="S3.SS1.p1.12.m12.1.1.3.cmml" xref="S3.SS1.p1.12.m12.1.1.3">𝑙</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.12.m12.1c">H_{l}</annotation></semantics></math>, as shown below:</p>
<table id="A1.EGx1" class="ltx_equationgroup ltx_eqn_align ltx_eqn_table">

<tbody id="S3.E1"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S3.E1.m1.1" class="ltx_Math" alttext="\displaystyle\bigtriangledown a_{l-1}" display="inline"><semantics id="S3.E1.m1.1a"><mrow id="S3.E1.m1.1.1" xref="S3.E1.m1.1.1.cmml"><mo rspace="0em" id="S3.E1.m1.1.1a" xref="S3.E1.m1.1.1.cmml">▽</mo><msub id="S3.E1.m1.1.1.2" xref="S3.E1.m1.1.1.2.cmml"><mi id="S3.E1.m1.1.1.2.2" xref="S3.E1.m1.1.1.2.2.cmml">a</mi><mrow id="S3.E1.m1.1.1.2.3" xref="S3.E1.m1.1.1.2.3.cmml"><mi id="S3.E1.m1.1.1.2.3.2" xref="S3.E1.m1.1.1.2.3.2.cmml">l</mi><mo id="S3.E1.m1.1.1.2.3.1" xref="S3.E1.m1.1.1.2.3.1.cmml">−</mo><mn id="S3.E1.m1.1.1.2.3.3" xref="S3.E1.m1.1.1.2.3.3.cmml">1</mn></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.1b"><apply id="S3.E1.m1.1.1.cmml" xref="S3.E1.m1.1.1"><ci id="S3.E1.m1.1.1.1.cmml" xref="S3.E1.m1.1.1">▽</ci><apply id="S3.E1.m1.1.1.2.cmml" xref="S3.E1.m1.1.1.2"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.2.1.cmml" xref="S3.E1.m1.1.1.2">subscript</csymbol><ci id="S3.E1.m1.1.1.2.2.cmml" xref="S3.E1.m1.1.1.2.2">𝑎</ci><apply id="S3.E1.m1.1.1.2.3.cmml" xref="S3.E1.m1.1.1.2.3"><minus id="S3.E1.m1.1.1.2.3.1.cmml" xref="S3.E1.m1.1.1.2.3.1"></minus><ci id="S3.E1.m1.1.1.2.3.2.cmml" xref="S3.E1.m1.1.1.2.3.2">𝑙</ci><cn type="integer" id="S3.E1.m1.1.1.2.3.3.cmml" xref="S3.E1.m1.1.1.2.3.3">1</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.1c">\displaystyle\bigtriangledown a_{l-1}</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S3.E1.m2.2" class="ltx_Math" alttext="\displaystyle=G_{l}(\bigtriangledown a_{l},w_{l})" display="inline"><semantics id="S3.E1.m2.2a"><mrow id="S3.E1.m2.2.2" xref="S3.E1.m2.2.2.cmml"><mi id="S3.E1.m2.2.2.4" xref="S3.E1.m2.2.2.4.cmml"></mi><mo id="S3.E1.m2.2.2.3" xref="S3.E1.m2.2.2.3.cmml">=</mo><mrow id="S3.E1.m2.2.2.2" xref="S3.E1.m2.2.2.2.cmml"><msub id="S3.E1.m2.2.2.2.4" xref="S3.E1.m2.2.2.2.4.cmml"><mi id="S3.E1.m2.2.2.2.4.2" xref="S3.E1.m2.2.2.2.4.2.cmml">G</mi><mi id="S3.E1.m2.2.2.2.4.3" xref="S3.E1.m2.2.2.2.4.3.cmml">l</mi></msub><mo lspace="0em" rspace="0em" id="S3.E1.m2.2.2.2.3" xref="S3.E1.m2.2.2.2.3.cmml">​</mo><mrow id="S3.E1.m2.2.2.2.2.2" xref="S3.E1.m2.2.2.2.2.3.cmml"><mo stretchy="false" id="S3.E1.m2.2.2.2.2.2.3" xref="S3.E1.m2.2.2.2.2.3.cmml">(</mo><mrow id="S3.E1.m2.1.1.1.1.1.1" xref="S3.E1.m2.1.1.1.1.1.1.cmml"><mo lspace="0em" rspace="0em" id="S3.E1.m2.1.1.1.1.1.1a" xref="S3.E1.m2.1.1.1.1.1.1.cmml">▽</mo><msub id="S3.E1.m2.1.1.1.1.1.1.2" xref="S3.E1.m2.1.1.1.1.1.1.2.cmml"><mi id="S3.E1.m2.1.1.1.1.1.1.2.2" xref="S3.E1.m2.1.1.1.1.1.1.2.2.cmml">a</mi><mi id="S3.E1.m2.1.1.1.1.1.1.2.3" xref="S3.E1.m2.1.1.1.1.1.1.2.3.cmml">l</mi></msub></mrow><mo id="S3.E1.m2.2.2.2.2.2.4" xref="S3.E1.m2.2.2.2.2.3.cmml">,</mo><msub id="S3.E1.m2.2.2.2.2.2.2" xref="S3.E1.m2.2.2.2.2.2.2.cmml"><mi id="S3.E1.m2.2.2.2.2.2.2.2" xref="S3.E1.m2.2.2.2.2.2.2.2.cmml">w</mi><mi id="S3.E1.m2.2.2.2.2.2.2.3" xref="S3.E1.m2.2.2.2.2.2.2.3.cmml">l</mi></msub><mo stretchy="false" id="S3.E1.m2.2.2.2.2.2.5" xref="S3.E1.m2.2.2.2.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m2.2b"><apply id="S3.E1.m2.2.2.cmml" xref="S3.E1.m2.2.2"><eq id="S3.E1.m2.2.2.3.cmml" xref="S3.E1.m2.2.2.3"></eq><csymbol cd="latexml" id="S3.E1.m2.2.2.4.cmml" xref="S3.E1.m2.2.2.4">absent</csymbol><apply id="S3.E1.m2.2.2.2.cmml" xref="S3.E1.m2.2.2.2"><times id="S3.E1.m2.2.2.2.3.cmml" xref="S3.E1.m2.2.2.2.3"></times><apply id="S3.E1.m2.2.2.2.4.cmml" xref="S3.E1.m2.2.2.2.4"><csymbol cd="ambiguous" id="S3.E1.m2.2.2.2.4.1.cmml" xref="S3.E1.m2.2.2.2.4">subscript</csymbol><ci id="S3.E1.m2.2.2.2.4.2.cmml" xref="S3.E1.m2.2.2.2.4.2">𝐺</ci><ci id="S3.E1.m2.2.2.2.4.3.cmml" xref="S3.E1.m2.2.2.2.4.3">𝑙</ci></apply><interval closure="open" id="S3.E1.m2.2.2.2.2.3.cmml" xref="S3.E1.m2.2.2.2.2.2"><apply id="S3.E1.m2.1.1.1.1.1.1.cmml" xref="S3.E1.m2.1.1.1.1.1.1"><ci id="S3.E1.m2.1.1.1.1.1.1.1.cmml" xref="S3.E1.m2.1.1.1.1.1.1">▽</ci><apply id="S3.E1.m2.1.1.1.1.1.1.2.cmml" xref="S3.E1.m2.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E1.m2.1.1.1.1.1.1.2.1.cmml" xref="S3.E1.m2.1.1.1.1.1.1.2">subscript</csymbol><ci id="S3.E1.m2.1.1.1.1.1.1.2.2.cmml" xref="S3.E1.m2.1.1.1.1.1.1.2.2">𝑎</ci><ci id="S3.E1.m2.1.1.1.1.1.1.2.3.cmml" xref="S3.E1.m2.1.1.1.1.1.1.2.3">𝑙</ci></apply></apply><apply id="S3.E1.m2.2.2.2.2.2.2.cmml" xref="S3.E1.m2.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.E1.m2.2.2.2.2.2.2.1.cmml" xref="S3.E1.m2.2.2.2.2.2.2">subscript</csymbol><ci id="S3.E1.m2.2.2.2.2.2.2.2.cmml" xref="S3.E1.m2.2.2.2.2.2.2.2">𝑤</ci><ci id="S3.E1.m2.2.2.2.2.2.2.3.cmml" xref="S3.E1.m2.2.2.2.2.2.2.3">𝑙</ci></apply></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m2.2c">\displaystyle=G_{l}(\bigtriangledown a_{l},w_{l})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
<tbody id="S3.E2"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S3.E2.m1.1" class="ltx_Math" alttext="\displaystyle\bigtriangledown w_{l}" display="inline"><semantics id="S3.E2.m1.1a"><mrow id="S3.E2.m1.1.1" xref="S3.E2.m1.1.1.cmml"><mo rspace="0em" id="S3.E2.m1.1.1a" xref="S3.E2.m1.1.1.cmml">▽</mo><msub id="S3.E2.m1.1.1.2" xref="S3.E2.m1.1.1.2.cmml"><mi id="S3.E2.m1.1.1.2.2" xref="S3.E2.m1.1.1.2.2.cmml">w</mi><mi id="S3.E2.m1.1.1.2.3" xref="S3.E2.m1.1.1.2.3.cmml">l</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.1b"><apply id="S3.E2.m1.1.1.cmml" xref="S3.E2.m1.1.1"><ci id="S3.E2.m1.1.1.1.cmml" xref="S3.E2.m1.1.1">▽</ci><apply id="S3.E2.m1.1.1.2.cmml" xref="S3.E2.m1.1.1.2"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.2.1.cmml" xref="S3.E2.m1.1.1.2">subscript</csymbol><ci id="S3.E2.m1.1.1.2.2.cmml" xref="S3.E2.m1.1.1.2.2">𝑤</ci><ci id="S3.E2.m1.1.1.2.3.cmml" xref="S3.E2.m1.1.1.2.3">𝑙</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.1c">\displaystyle\bigtriangledown w_{l}</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S3.E2.m2.2" class="ltx_Math" alttext="\displaystyle=H_{l}(\bigtriangledown a_{l},a_{l-1})" display="inline"><semantics id="S3.E2.m2.2a"><mrow id="S3.E2.m2.2.2" xref="S3.E2.m2.2.2.cmml"><mi id="S3.E2.m2.2.2.4" xref="S3.E2.m2.2.2.4.cmml"></mi><mo id="S3.E2.m2.2.2.3" xref="S3.E2.m2.2.2.3.cmml">=</mo><mrow id="S3.E2.m2.2.2.2" xref="S3.E2.m2.2.2.2.cmml"><msub id="S3.E2.m2.2.2.2.4" xref="S3.E2.m2.2.2.2.4.cmml"><mi id="S3.E2.m2.2.2.2.4.2" xref="S3.E2.m2.2.2.2.4.2.cmml">H</mi><mi id="S3.E2.m2.2.2.2.4.3" xref="S3.E2.m2.2.2.2.4.3.cmml">l</mi></msub><mo lspace="0em" rspace="0em" id="S3.E2.m2.2.2.2.3" xref="S3.E2.m2.2.2.2.3.cmml">​</mo><mrow id="S3.E2.m2.2.2.2.2.2" xref="S3.E2.m2.2.2.2.2.3.cmml"><mo stretchy="false" id="S3.E2.m2.2.2.2.2.2.3" xref="S3.E2.m2.2.2.2.2.3.cmml">(</mo><mrow id="S3.E2.m2.1.1.1.1.1.1" xref="S3.E2.m2.1.1.1.1.1.1.cmml"><mo lspace="0em" rspace="0em" id="S3.E2.m2.1.1.1.1.1.1a" xref="S3.E2.m2.1.1.1.1.1.1.cmml">▽</mo><msub id="S3.E2.m2.1.1.1.1.1.1.2" xref="S3.E2.m2.1.1.1.1.1.1.2.cmml"><mi id="S3.E2.m2.1.1.1.1.1.1.2.2" xref="S3.E2.m2.1.1.1.1.1.1.2.2.cmml">a</mi><mi id="S3.E2.m2.1.1.1.1.1.1.2.3" xref="S3.E2.m2.1.1.1.1.1.1.2.3.cmml">l</mi></msub></mrow><mo id="S3.E2.m2.2.2.2.2.2.4" xref="S3.E2.m2.2.2.2.2.3.cmml">,</mo><msub id="S3.E2.m2.2.2.2.2.2.2" xref="S3.E2.m2.2.2.2.2.2.2.cmml"><mi id="S3.E2.m2.2.2.2.2.2.2.2" xref="S3.E2.m2.2.2.2.2.2.2.2.cmml">a</mi><mrow id="S3.E2.m2.2.2.2.2.2.2.3" xref="S3.E2.m2.2.2.2.2.2.2.3.cmml"><mi id="S3.E2.m2.2.2.2.2.2.2.3.2" xref="S3.E2.m2.2.2.2.2.2.2.3.2.cmml">l</mi><mo id="S3.E2.m2.2.2.2.2.2.2.3.1" xref="S3.E2.m2.2.2.2.2.2.2.3.1.cmml">−</mo><mn id="S3.E2.m2.2.2.2.2.2.2.3.3" xref="S3.E2.m2.2.2.2.2.2.2.3.3.cmml">1</mn></mrow></msub><mo stretchy="false" id="S3.E2.m2.2.2.2.2.2.5" xref="S3.E2.m2.2.2.2.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m2.2b"><apply id="S3.E2.m2.2.2.cmml" xref="S3.E2.m2.2.2"><eq id="S3.E2.m2.2.2.3.cmml" xref="S3.E2.m2.2.2.3"></eq><csymbol cd="latexml" id="S3.E2.m2.2.2.4.cmml" xref="S3.E2.m2.2.2.4">absent</csymbol><apply id="S3.E2.m2.2.2.2.cmml" xref="S3.E2.m2.2.2.2"><times id="S3.E2.m2.2.2.2.3.cmml" xref="S3.E2.m2.2.2.2.3"></times><apply id="S3.E2.m2.2.2.2.4.cmml" xref="S3.E2.m2.2.2.2.4"><csymbol cd="ambiguous" id="S3.E2.m2.2.2.2.4.1.cmml" xref="S3.E2.m2.2.2.2.4">subscript</csymbol><ci id="S3.E2.m2.2.2.2.4.2.cmml" xref="S3.E2.m2.2.2.2.4.2">𝐻</ci><ci id="S3.E2.m2.2.2.2.4.3.cmml" xref="S3.E2.m2.2.2.2.4.3">𝑙</ci></apply><interval closure="open" id="S3.E2.m2.2.2.2.2.3.cmml" xref="S3.E2.m2.2.2.2.2.2"><apply id="S3.E2.m2.1.1.1.1.1.1.cmml" xref="S3.E2.m2.1.1.1.1.1.1"><ci id="S3.E2.m2.1.1.1.1.1.1.1.cmml" xref="S3.E2.m2.1.1.1.1.1.1">▽</ci><apply id="S3.E2.m2.1.1.1.1.1.1.2.cmml" xref="S3.E2.m2.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E2.m2.1.1.1.1.1.1.2.1.cmml" xref="S3.E2.m2.1.1.1.1.1.1.2">subscript</csymbol><ci id="S3.E2.m2.1.1.1.1.1.1.2.2.cmml" xref="S3.E2.m2.1.1.1.1.1.1.2.2">𝑎</ci><ci id="S3.E2.m2.1.1.1.1.1.1.2.3.cmml" xref="S3.E2.m2.1.1.1.1.1.1.2.3">𝑙</ci></apply></apply><apply id="S3.E2.m2.2.2.2.2.2.2.cmml" xref="S3.E2.m2.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.E2.m2.2.2.2.2.2.2.1.cmml" xref="S3.E2.m2.2.2.2.2.2.2">subscript</csymbol><ci id="S3.E2.m2.2.2.2.2.2.2.2.cmml" xref="S3.E2.m2.2.2.2.2.2.2.2">𝑎</ci><apply id="S3.E2.m2.2.2.2.2.2.2.3.cmml" xref="S3.E2.m2.2.2.2.2.2.2.3"><minus id="S3.E2.m2.2.2.2.2.2.2.3.1.cmml" xref="S3.E2.m2.2.2.2.2.2.2.3.1"></minus><ci id="S3.E2.m2.2.2.2.2.2.2.3.2.cmml" xref="S3.E2.m2.2.2.2.2.2.2.3.2">𝑙</ci><cn type="integer" id="S3.E2.m2.2.2.2.2.2.2.3.3.cmml" xref="S3.E2.m2.2.2.2.2.2.2.3.3">1</cn></apply></apply></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m2.2c">\displaystyle=H_{l}(\bigtriangledown a_{l},a_{l-1})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
</div>
<div id="S3.SS1.p2" class="ltx_para ltx_noindent">
<p id="S3.SS1.p2.3" class="ltx_p">Then in the backward pass, the retained layer inputs <math id="S3.SS1.p2.1.m1.1" class="ltx_Math" alttext="a_{l-1}" display="inline"><semantics id="S3.SS1.p2.1.m1.1a"><msub id="S3.SS1.p2.1.m1.1.1" xref="S3.SS1.p2.1.m1.1.1.cmml"><mi id="S3.SS1.p2.1.m1.1.1.2" xref="S3.SS1.p2.1.m1.1.1.2.cmml">a</mi><mrow id="S3.SS1.p2.1.m1.1.1.3" xref="S3.SS1.p2.1.m1.1.1.3.cmml"><mi id="S3.SS1.p2.1.m1.1.1.3.2" xref="S3.SS1.p2.1.m1.1.1.3.2.cmml">l</mi><mo id="S3.SS1.p2.1.m1.1.1.3.1" xref="S3.SS1.p2.1.m1.1.1.3.1.cmml">−</mo><mn id="S3.SS1.p2.1.m1.1.1.3.3" xref="S3.SS1.p2.1.m1.1.1.3.3.cmml">1</mn></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.1.m1.1b"><apply id="S3.SS1.p2.1.m1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.1.m1.1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1">subscript</csymbol><ci id="S3.SS1.p2.1.m1.1.1.2.cmml" xref="S3.SS1.p2.1.m1.1.1.2">𝑎</ci><apply id="S3.SS1.p2.1.m1.1.1.3.cmml" xref="S3.SS1.p2.1.m1.1.1.3"><minus id="S3.SS1.p2.1.m1.1.1.3.1.cmml" xref="S3.SS1.p2.1.m1.1.1.3.1"></minus><ci id="S3.SS1.p2.1.m1.1.1.3.2.cmml" xref="S3.SS1.p2.1.m1.1.1.3.2">𝑙</ci><cn type="integer" id="S3.SS1.p2.1.m1.1.1.3.3.cmml" xref="S3.SS1.p2.1.m1.1.1.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.1.m1.1c">a_{l-1}</annotation></semantics></math> are also partitioned into active and non-active by using the same <span id="S3.SS1.p2.3.1" class="ltx_text ltx_font_typewriter">top-K</span> procedure. This results in full gradients and active weights being used in Eq. <a href="#S3.E1" title="In 3.1 Sparse Weights and Activations Training ‣ 3 Background ‣ ZeroFL: Efficient On-Device Training for Federated Learning with Local Sparsity" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, while full gradients and active activations are used in Eq. <a href="#S3.E2" title="In 3.1 Sparse Weights and Activations Training ‣ 3 Background ‣ ZeroFL: Efficient On-Device Training for Federated Learning with Local Sparsity" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. It is worth noticing that even weights and activations are sparsified in the forward and backward pass, the gradients generated through the training process are dense. Therefore, the resulting model is a dense. The compute cost of updating weights <math id="S3.SS1.p2.2.m2.1" class="ltx_Math" alttext="w_{l}" display="inline"><semantics id="S3.SS1.p2.2.m2.1a"><msub id="S3.SS1.p2.2.m2.1.1" xref="S3.SS1.p2.2.m2.1.1.cmml"><mi id="S3.SS1.p2.2.m2.1.1.2" xref="S3.SS1.p2.2.m2.1.1.2.cmml">w</mi><mi id="S3.SS1.p2.2.m2.1.1.3" xref="S3.SS1.p2.2.m2.1.1.3.cmml">l</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.2.m2.1b"><apply id="S3.SS1.p2.2.m2.1.1.cmml" xref="S3.SS1.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.2.m2.1.1.1.cmml" xref="S3.SS1.p2.2.m2.1.1">subscript</csymbol><ci id="S3.SS1.p2.2.m2.1.1.2.cmml" xref="S3.SS1.p2.2.m2.1.1.2">𝑤</ci><ci id="S3.SS1.p2.2.m2.1.1.3.cmml" xref="S3.SS1.p2.2.m2.1.1.3">𝑙</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.2.m2.1c">w_{l}</annotation></semantics></math> given a dense <math id="S3.SS1.p2.3.m3.1" class="ltx_Math" alttext="\bigtriangledown w_{l}" display="inline"><semantics id="S3.SS1.p2.3.m3.1a"><mrow id="S3.SS1.p2.3.m3.1.1" xref="S3.SS1.p2.3.m3.1.1.cmml"><mo rspace="0em" id="S3.SS1.p2.3.m3.1.1a" xref="S3.SS1.p2.3.m3.1.1.cmml">▽</mo><msub id="S3.SS1.p2.3.m3.1.1.2" xref="S3.SS1.p2.3.m3.1.1.2.cmml"><mi id="S3.SS1.p2.3.m3.1.1.2.2" xref="S3.SS1.p2.3.m3.1.1.2.2.cmml">w</mi><mi id="S3.SS1.p2.3.m3.1.1.2.3" xref="S3.SS1.p2.3.m3.1.1.2.3.cmml">l</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.3.m3.1b"><apply id="S3.SS1.p2.3.m3.1.1.cmml" xref="S3.SS1.p2.3.m3.1.1"><ci id="S3.SS1.p2.3.m3.1.1.1.cmml" xref="S3.SS1.p2.3.m3.1.1">▽</ci><apply id="S3.SS1.p2.3.m3.1.1.2.cmml" xref="S3.SS1.p2.3.m3.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p2.3.m3.1.1.2.1.cmml" xref="S3.SS1.p2.3.m3.1.1.2">subscript</csymbol><ci id="S3.SS1.p2.3.m3.1.1.2.2.cmml" xref="S3.SS1.p2.3.m3.1.1.2.2">𝑤</ci><ci id="S3.SS1.p2.3.m3.1.1.2.3.cmml" xref="S3.SS1.p2.3.m3.1.1.2.3">𝑙</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.3.m3.1c">\bigtriangledown w_{l}</annotation></semantics></math> tensor is negligible compare to the savings due to performing the underlying convolutions in Eq.<a href="#S3.E1" title="In 3.1 Sparse Weights and Activations Training ‣ 3 Background ‣ ZeroFL: Efficient On-Device Training for Federated Learning with Local Sparsity" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>&amp;<a href="#S3.E2" title="In 3.1 Sparse Weights and Activations Training ‣ 3 Background ‣ ZeroFL: Efficient On-Device Training for Federated Learning with Local Sparsity" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, as this is essentially a weighted sum.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>From Centralised to Federated Sparse Training</h3>

<div id="S3.SS2.p1" class="ltx_para ltx_noindent">
<p id="S3.SS2.p1.1" class="ltx_p">A direct adaptation of the SWAT framework to the FL setting could be done by framing each local training stage on a client as an instance of centralised training. However, one major difference between centralized training and FL is the notion of <span id="S3.SS2.p1.1.1" class="ltx_text ltx_font_italic">client statefulness</span>. In a centralised scenario, each example in the training set is seen multiple times, once per epoch, allowing for the model to converge to a stable distribution of weights. This scenario is more suitable for sparsification.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para ltx_noindent">
<p id="S3.SS2.p2.1" class="ltx_p">On the other hand, in a typical <em id="S3.SS2.p2.1.1" class="ltx_emph ltx_font_italic">cross-device</em> scenario, client’s availability is low and new data points are continuously being presented to the system as new clients participate in training rounds. This means that clients are likely to participate only once. Such training behaviour inevitably leads to distributions of weights that change over time, making the application of sparsity inducing methods more difficult as a result.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Sparse Training for Federated Learning</h2>

<div id="S4.p1" class="ltx_para ltx_noindent">
<p id="S4.p1.1" class="ltx_p">As a first step, we conduct preliminaries investigations and measure SWAT’s performance when directly applied to FL without any adaptation. This section describes the experimental protocol (Section <a href="#S4.SS1" title="4.1 Experimental Setup ‣ 4 Sparse Training for Federated Learning ‣ ZeroFL: Efficient On-Device Training for Federated Learning with Local Sparsity" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.1</span></a>), the obtained baseline results (Section <a href="#S4.SS2" title="4.2 Baselines Results ‣ 4 Sparse Training for Federated Learning ‣ ZeroFL: Efficient On-Device Training for Federated Learning with Local Sparsity" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.2</span></a>) and a sparsification effect analysis to highlight the weaknesses of this approach in Section <a href="#S4.SS3" title="4.3 Sparsification Effect Analysis ‣ 4 Sparse Training for Federated Learning ‣ ZeroFL: Efficient On-Device Training for Federated Learning with Local Sparsity" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.3</span></a>.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Experimental Setup</h3>

<div id="S4.SS1.p1" class="ltx_para ltx_noindent">
<p id="S4.SS1.p1.1" class="ltx_p">While SWAT is used across the experiments as the standard sparsification methodology, results also depend on various FL-specific hyper-parameters. Federated learning is simulated with the Virtual Client Engine (VCE) of the Flower toolkit <cite class="ltx_cite ltx_citemacro_citep">(Beutel et al., <a href="#bib.bib3" title="" class="ltx_ref">2020</a>)</cite> enabling us to scale to a large number of clients within in a single machine. Datasets and hyper-parameters are detailed below.</p>
</div>
<div id="S4.SS1.p2" class="ltx_para ltx_noindent">
<p id="S4.SS1.p2.1" class="ltx_p"><span id="S4.SS1.p2.1.1" class="ltx_text ltx_font_bold">Datasets.</span> Experiments are conducted on two image classification tasks of different complexity both in terms of the number of samples and classes: FEMNIST <cite class="ltx_cite ltx_citemacro_citep">(Caldas et al., <a href="#bib.bib4" title="" class="ltx_ref">2018</a>)</cite> and CIFAR10 <cite class="ltx_cite ltx_citemacro_citep">(Krizhevsky et al., <a href="#bib.bib32" title="" class="ltx_ref">2009</a>)</cite>. FEMNIST is constructed by partitioning the data of the Extended MNIST <cite class="ltx_cite ltx_citemacro_citep">(Cohen et al., <a href="#bib.bib7" title="" class="ltx_ref">2017</a>)</cite> based on the writers of the digit-character. We also include the Speech Commands dataset <cite class="ltx_cite ltx_citemacro_citep">(Warden, <a href="#bib.bib54" title="" class="ltx_ref">2018</a>)</cite>, where the task is to classify 1-second long audio clips. Further details for these datasets can be found in the Appendix <a href="#A1.SS5" title="A.5 Datasets ‣ Appendix A Appendix ‣ ZeroFL: Efficient On-Device Training for Federated Learning with Local Sparsity" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A.5</span></a>.</p>
</div>
<div id="S4.SS1.p3" class="ltx_para ltx_noindent">
<p id="S4.SS1.p3.5" class="ltx_p"><span id="S4.SS1.p3.5.1" class="ltx_text ltx_font_bold">Data partitioning.</span> We follow the latent Dirichlet allocation (LDA) partition method <cite class="ltx_cite ltx_citemacro_citep">(Reddi et al., <a href="#bib.bib42" title="" class="ltx_ref">2021</a>; Yurochkin et al., <a href="#bib.bib57" title="" class="ltx_ref">2019</a>; Hsu et al., <a href="#bib.bib28" title="" class="ltx_ref">2019</a>)</cite> ensuring that each client is allocated the same number of training samples. The level of heterogeneity is governed by the parameter <math id="S4.SS1.p3.1.m1.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S4.SS1.p3.1.m1.1a"><mi id="S4.SS1.p3.1.m1.1.1" xref="S4.SS1.p3.1.m1.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.1.m1.1b"><ci id="S4.SS1.p3.1.m1.1.1.cmml" xref="S4.SS1.p3.1.m1.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.1.m1.1c">\alpha</annotation></semantics></math>. As <math id="S4.SS1.p3.2.m2.1" class="ltx_Math" alttext="\alpha\to\infty" display="inline"><semantics id="S4.SS1.p3.2.m2.1a"><mrow id="S4.SS1.p3.2.m2.1.1" xref="S4.SS1.p3.2.m2.1.1.cmml"><mi id="S4.SS1.p3.2.m2.1.1.2" xref="S4.SS1.p3.2.m2.1.1.2.cmml">α</mi><mo stretchy="false" id="S4.SS1.p3.2.m2.1.1.1" xref="S4.SS1.p3.2.m2.1.1.1.cmml">→</mo><mi mathvariant="normal" id="S4.SS1.p3.2.m2.1.1.3" xref="S4.SS1.p3.2.m2.1.1.3.cmml">∞</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.2.m2.1b"><apply id="S4.SS1.p3.2.m2.1.1.cmml" xref="S4.SS1.p3.2.m2.1.1"><ci id="S4.SS1.p3.2.m2.1.1.1.cmml" xref="S4.SS1.p3.2.m2.1.1.1">→</ci><ci id="S4.SS1.p3.2.m2.1.1.2.cmml" xref="S4.SS1.p3.2.m2.1.1.2">𝛼</ci><infinity id="S4.SS1.p3.2.m2.1.1.3.cmml" xref="S4.SS1.p3.2.m2.1.1.3"></infinity></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.2.m2.1c">\alpha\to\infty</annotation></semantics></math>, partitions become more uniform (IID), and as <math id="S4.SS1.p3.3.m3.1" class="ltx_Math" alttext="\alpha\to 0" display="inline"><semantics id="S4.SS1.p3.3.m3.1a"><mrow id="S4.SS1.p3.3.m3.1.1" xref="S4.SS1.p3.3.m3.1.1.cmml"><mi id="S4.SS1.p3.3.m3.1.1.2" xref="S4.SS1.p3.3.m3.1.1.2.cmml">α</mi><mo stretchy="false" id="S4.SS1.p3.3.m3.1.1.1" xref="S4.SS1.p3.3.m3.1.1.1.cmml">→</mo><mn id="S4.SS1.p3.3.m3.1.1.3" xref="S4.SS1.p3.3.m3.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.3.m3.1b"><apply id="S4.SS1.p3.3.m3.1.1.cmml" xref="S4.SS1.p3.3.m3.1.1"><ci id="S4.SS1.p3.3.m3.1.1.1.cmml" xref="S4.SS1.p3.3.m3.1.1.1">→</ci><ci id="S4.SS1.p3.3.m3.1.1.2.cmml" xref="S4.SS1.p3.3.m3.1.1.2">𝛼</ci><cn type="integer" id="S4.SS1.p3.3.m3.1.1.3.cmml" xref="S4.SS1.p3.3.m3.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.3.m3.1c">\alpha\to 0</annotation></semantics></math>, partitions tend to be more heterogeneous. Our experimental evaluation considers <math id="S4.SS1.p3.4.m4.1" class="ltx_Math" alttext="\alpha=1.0" display="inline"><semantics id="S4.SS1.p3.4.m4.1a"><mrow id="S4.SS1.p3.4.m4.1.1" xref="S4.SS1.p3.4.m4.1.1.cmml"><mi id="S4.SS1.p3.4.m4.1.1.2" xref="S4.SS1.p3.4.m4.1.1.2.cmml">α</mi><mo id="S4.SS1.p3.4.m4.1.1.1" xref="S4.SS1.p3.4.m4.1.1.1.cmml">=</mo><mn id="S4.SS1.p3.4.m4.1.1.3" xref="S4.SS1.p3.4.m4.1.1.3.cmml">1.0</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.4.m4.1b"><apply id="S4.SS1.p3.4.m4.1.1.cmml" xref="S4.SS1.p3.4.m4.1.1"><eq id="S4.SS1.p3.4.m4.1.1.1.cmml" xref="S4.SS1.p3.4.m4.1.1.1"></eq><ci id="S4.SS1.p3.4.m4.1.1.2.cmml" xref="S4.SS1.p3.4.m4.1.1.2">𝛼</ci><cn type="float" id="S4.SS1.p3.4.m4.1.1.3.cmml" xref="S4.SS1.p3.4.m4.1.1.3">1.0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.4.m4.1c">\alpha=1.0</annotation></semantics></math> and <math id="S4.SS1.p3.5.m5.1" class="ltx_Math" alttext="\alpha=1000" display="inline"><semantics id="S4.SS1.p3.5.m5.1a"><mrow id="S4.SS1.p3.5.m5.1.1" xref="S4.SS1.p3.5.m5.1.1.cmml"><mi id="S4.SS1.p3.5.m5.1.1.2" xref="S4.SS1.p3.5.m5.1.1.2.cmml">α</mi><mo id="S4.SS1.p3.5.m5.1.1.1" xref="S4.SS1.p3.5.m5.1.1.1.cmml">=</mo><mn id="S4.SS1.p3.5.m5.1.1.3" xref="S4.SS1.p3.5.m5.1.1.3.cmml">1000</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.5.m5.1b"><apply id="S4.SS1.p3.5.m5.1.1.cmml" xref="S4.SS1.p3.5.m5.1.1"><eq id="S4.SS1.p3.5.m5.1.1.1.cmml" xref="S4.SS1.p3.5.m5.1.1.1"></eq><ci id="S4.SS1.p3.5.m5.1.1.2.cmml" xref="S4.SS1.p3.5.m5.1.1.2">𝛼</ci><cn type="integer" id="S4.SS1.p3.5.m5.1.1.3.cmml" xref="S4.SS1.p3.5.m5.1.1.3">1000</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.5.m5.1c">\alpha=1000</annotation></semantics></math>.</p>
</div>
<div id="S4.SS1.p4" class="ltx_para ltx_noindent">
<p id="S4.SS1.p4.4" class="ltx_p"><span id="S4.SS1.p4.4.1" class="ltx_text ltx_font_bold">Model Architecture.</span> Following the convention for CIFAR-10, a ResNet-18 <cite class="ltx_cite ltx_citemacro_citep">(He et al., <a href="#bib.bib19" title="" class="ltx_ref">2016</a>)</cite> architecture is instantiated in the client side and aggregated on the server. We also make use of ResNet-18 for SpeechCommands. For FEMNIST, we employ the much smaller CNN first proposed in <cite class="ltx_cite ltx_citemacro_citep">(Caldas et al., <a href="#bib.bib4" title="" class="ltx_ref">2018</a>)</cite>. Further details for these architectures can be found in Section <a href="#A1.SS6" title="A.6 Models and Hyperparameters ‣ Appendix A Appendix ‣ ZeroFL: Efficient On-Device Training for Federated Learning with Local Sparsity" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A.6</span></a> in the Appendix. The models are trained with SGD, and all experiments imply one local epoch (<span id="S4.SS1.p4.4.2" class="ltx_text ltx_font_italic">i.e.</span> client epoch). An exponential decay defined as <math id="S4.SS1.p4.1.m1.3" class="ltx_Math" alttext="\eta_{t}=\eta_{start}\exp(\frac{t}{T}\log(\eta_{\text{start}}/\eta_{\text{end}}))" display="inline"><semantics id="S4.SS1.p4.1.m1.3a"><mrow id="S4.SS1.p4.1.m1.3.3" xref="S4.SS1.p4.1.m1.3.3.cmml"><msub id="S4.SS1.p4.1.m1.3.3.3" xref="S4.SS1.p4.1.m1.3.3.3.cmml"><mi id="S4.SS1.p4.1.m1.3.3.3.2" xref="S4.SS1.p4.1.m1.3.3.3.2.cmml">η</mi><mi id="S4.SS1.p4.1.m1.3.3.3.3" xref="S4.SS1.p4.1.m1.3.3.3.3.cmml">t</mi></msub><mo id="S4.SS1.p4.1.m1.3.3.2" xref="S4.SS1.p4.1.m1.3.3.2.cmml">=</mo><mrow id="S4.SS1.p4.1.m1.3.3.1" xref="S4.SS1.p4.1.m1.3.3.1.cmml"><msub id="S4.SS1.p4.1.m1.3.3.1.3" xref="S4.SS1.p4.1.m1.3.3.1.3.cmml"><mi id="S4.SS1.p4.1.m1.3.3.1.3.2" xref="S4.SS1.p4.1.m1.3.3.1.3.2.cmml">η</mi><mrow id="S4.SS1.p4.1.m1.3.3.1.3.3" xref="S4.SS1.p4.1.m1.3.3.1.3.3.cmml"><mi id="S4.SS1.p4.1.m1.3.3.1.3.3.2" xref="S4.SS1.p4.1.m1.3.3.1.3.3.2.cmml">s</mi><mo lspace="0em" rspace="0em" id="S4.SS1.p4.1.m1.3.3.1.3.3.1" xref="S4.SS1.p4.1.m1.3.3.1.3.3.1.cmml">​</mo><mi id="S4.SS1.p4.1.m1.3.3.1.3.3.3" xref="S4.SS1.p4.1.m1.3.3.1.3.3.3.cmml">t</mi><mo lspace="0em" rspace="0em" id="S4.SS1.p4.1.m1.3.3.1.3.3.1a" xref="S4.SS1.p4.1.m1.3.3.1.3.3.1.cmml">​</mo><mi id="S4.SS1.p4.1.m1.3.3.1.3.3.4" xref="S4.SS1.p4.1.m1.3.3.1.3.3.4.cmml">a</mi><mo lspace="0em" rspace="0em" id="S4.SS1.p4.1.m1.3.3.1.3.3.1b" xref="S4.SS1.p4.1.m1.3.3.1.3.3.1.cmml">​</mo><mi id="S4.SS1.p4.1.m1.3.3.1.3.3.5" xref="S4.SS1.p4.1.m1.3.3.1.3.3.5.cmml">r</mi><mo lspace="0em" rspace="0em" id="S4.SS1.p4.1.m1.3.3.1.3.3.1c" xref="S4.SS1.p4.1.m1.3.3.1.3.3.1.cmml">​</mo><mi id="S4.SS1.p4.1.m1.3.3.1.3.3.6" xref="S4.SS1.p4.1.m1.3.3.1.3.3.6.cmml">t</mi></mrow></msub><mo lspace="0.167em" rspace="0em" id="S4.SS1.p4.1.m1.3.3.1.2" xref="S4.SS1.p4.1.m1.3.3.1.2.cmml">​</mo><mrow id="S4.SS1.p4.1.m1.3.3.1.1.1" xref="S4.SS1.p4.1.m1.3.3.1.1.2.cmml"><mi id="S4.SS1.p4.1.m1.2.2" xref="S4.SS1.p4.1.m1.2.2.cmml">exp</mi><mo id="S4.SS1.p4.1.m1.3.3.1.1.1a" xref="S4.SS1.p4.1.m1.3.3.1.1.2.cmml">⁡</mo><mrow id="S4.SS1.p4.1.m1.3.3.1.1.1.1" xref="S4.SS1.p4.1.m1.3.3.1.1.2.cmml"><mo stretchy="false" id="S4.SS1.p4.1.m1.3.3.1.1.1.1.2" xref="S4.SS1.p4.1.m1.3.3.1.1.2.cmml">(</mo><mrow id="S4.SS1.p4.1.m1.3.3.1.1.1.1.1" xref="S4.SS1.p4.1.m1.3.3.1.1.1.1.1.cmml"><mfrac id="S4.SS1.p4.1.m1.3.3.1.1.1.1.1.3" xref="S4.SS1.p4.1.m1.3.3.1.1.1.1.1.3.cmml"><mi id="S4.SS1.p4.1.m1.3.3.1.1.1.1.1.3.2" xref="S4.SS1.p4.1.m1.3.3.1.1.1.1.1.3.2.cmml">t</mi><mi id="S4.SS1.p4.1.m1.3.3.1.1.1.1.1.3.3" xref="S4.SS1.p4.1.m1.3.3.1.1.1.1.1.3.3.cmml">T</mi></mfrac><mo lspace="0.167em" rspace="0em" id="S4.SS1.p4.1.m1.3.3.1.1.1.1.1.2" xref="S4.SS1.p4.1.m1.3.3.1.1.1.1.1.2.cmml">​</mo><mrow id="S4.SS1.p4.1.m1.3.3.1.1.1.1.1.1.1" xref="S4.SS1.p4.1.m1.3.3.1.1.1.1.1.1.2.cmml"><mi id="S4.SS1.p4.1.m1.1.1" xref="S4.SS1.p4.1.m1.1.1.cmml">log</mi><mo id="S4.SS1.p4.1.m1.3.3.1.1.1.1.1.1.1a" xref="S4.SS1.p4.1.m1.3.3.1.1.1.1.1.1.2.cmml">⁡</mo><mrow id="S4.SS1.p4.1.m1.3.3.1.1.1.1.1.1.1.1" xref="S4.SS1.p4.1.m1.3.3.1.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S4.SS1.p4.1.m1.3.3.1.1.1.1.1.1.1.1.2" xref="S4.SS1.p4.1.m1.3.3.1.1.1.1.1.1.2.cmml">(</mo><mrow id="S4.SS1.p4.1.m1.3.3.1.1.1.1.1.1.1.1.1" xref="S4.SS1.p4.1.m1.3.3.1.1.1.1.1.1.1.1.1.cmml"><msub id="S4.SS1.p4.1.m1.3.3.1.1.1.1.1.1.1.1.1.2" xref="S4.SS1.p4.1.m1.3.3.1.1.1.1.1.1.1.1.1.2.cmml"><mi id="S4.SS1.p4.1.m1.3.3.1.1.1.1.1.1.1.1.1.2.2" xref="S4.SS1.p4.1.m1.3.3.1.1.1.1.1.1.1.1.1.2.2.cmml">η</mi><mtext id="S4.SS1.p4.1.m1.3.3.1.1.1.1.1.1.1.1.1.2.3" xref="S4.SS1.p4.1.m1.3.3.1.1.1.1.1.1.1.1.1.2.3a.cmml">start</mtext></msub><mo id="S4.SS1.p4.1.m1.3.3.1.1.1.1.1.1.1.1.1.1" xref="S4.SS1.p4.1.m1.3.3.1.1.1.1.1.1.1.1.1.1.cmml">/</mo><msub id="S4.SS1.p4.1.m1.3.3.1.1.1.1.1.1.1.1.1.3" xref="S4.SS1.p4.1.m1.3.3.1.1.1.1.1.1.1.1.1.3.cmml"><mi id="S4.SS1.p4.1.m1.3.3.1.1.1.1.1.1.1.1.1.3.2" xref="S4.SS1.p4.1.m1.3.3.1.1.1.1.1.1.1.1.1.3.2.cmml">η</mi><mtext id="S4.SS1.p4.1.m1.3.3.1.1.1.1.1.1.1.1.1.3.3" xref="S4.SS1.p4.1.m1.3.3.1.1.1.1.1.1.1.1.1.3.3a.cmml">end</mtext></msub></mrow><mo stretchy="false" id="S4.SS1.p4.1.m1.3.3.1.1.1.1.1.1.1.1.3" xref="S4.SS1.p4.1.m1.3.3.1.1.1.1.1.1.2.cmml">)</mo></mrow></mrow></mrow><mo stretchy="false" id="S4.SS1.p4.1.m1.3.3.1.1.1.1.3" xref="S4.SS1.p4.1.m1.3.3.1.1.2.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p4.1.m1.3b"><apply id="S4.SS1.p4.1.m1.3.3.cmml" xref="S4.SS1.p4.1.m1.3.3"><eq id="S4.SS1.p4.1.m1.3.3.2.cmml" xref="S4.SS1.p4.1.m1.3.3.2"></eq><apply id="S4.SS1.p4.1.m1.3.3.3.cmml" xref="S4.SS1.p4.1.m1.3.3.3"><csymbol cd="ambiguous" id="S4.SS1.p4.1.m1.3.3.3.1.cmml" xref="S4.SS1.p4.1.m1.3.3.3">subscript</csymbol><ci id="S4.SS1.p4.1.m1.3.3.3.2.cmml" xref="S4.SS1.p4.1.m1.3.3.3.2">𝜂</ci><ci id="S4.SS1.p4.1.m1.3.3.3.3.cmml" xref="S4.SS1.p4.1.m1.3.3.3.3">𝑡</ci></apply><apply id="S4.SS1.p4.1.m1.3.3.1.cmml" xref="S4.SS1.p4.1.m1.3.3.1"><times id="S4.SS1.p4.1.m1.3.3.1.2.cmml" xref="S4.SS1.p4.1.m1.3.3.1.2"></times><apply id="S4.SS1.p4.1.m1.3.3.1.3.cmml" xref="S4.SS1.p4.1.m1.3.3.1.3"><csymbol cd="ambiguous" id="S4.SS1.p4.1.m1.3.3.1.3.1.cmml" xref="S4.SS1.p4.1.m1.3.3.1.3">subscript</csymbol><ci id="S4.SS1.p4.1.m1.3.3.1.3.2.cmml" xref="S4.SS1.p4.1.m1.3.3.1.3.2">𝜂</ci><apply id="S4.SS1.p4.1.m1.3.3.1.3.3.cmml" xref="S4.SS1.p4.1.m1.3.3.1.3.3"><times id="S4.SS1.p4.1.m1.3.3.1.3.3.1.cmml" xref="S4.SS1.p4.1.m1.3.3.1.3.3.1"></times><ci id="S4.SS1.p4.1.m1.3.3.1.3.3.2.cmml" xref="S4.SS1.p4.1.m1.3.3.1.3.3.2">𝑠</ci><ci id="S4.SS1.p4.1.m1.3.3.1.3.3.3.cmml" xref="S4.SS1.p4.1.m1.3.3.1.3.3.3">𝑡</ci><ci id="S4.SS1.p4.1.m1.3.3.1.3.3.4.cmml" xref="S4.SS1.p4.1.m1.3.3.1.3.3.4">𝑎</ci><ci id="S4.SS1.p4.1.m1.3.3.1.3.3.5.cmml" xref="S4.SS1.p4.1.m1.3.3.1.3.3.5">𝑟</ci><ci id="S4.SS1.p4.1.m1.3.3.1.3.3.6.cmml" xref="S4.SS1.p4.1.m1.3.3.1.3.3.6">𝑡</ci></apply></apply><apply id="S4.SS1.p4.1.m1.3.3.1.1.2.cmml" xref="S4.SS1.p4.1.m1.3.3.1.1.1"><exp id="S4.SS1.p4.1.m1.2.2.cmml" xref="S4.SS1.p4.1.m1.2.2"></exp><apply id="S4.SS1.p4.1.m1.3.3.1.1.1.1.1.cmml" xref="S4.SS1.p4.1.m1.3.3.1.1.1.1.1"><times id="S4.SS1.p4.1.m1.3.3.1.1.1.1.1.2.cmml" xref="S4.SS1.p4.1.m1.3.3.1.1.1.1.1.2"></times><apply id="S4.SS1.p4.1.m1.3.3.1.1.1.1.1.3.cmml" xref="S4.SS1.p4.1.m1.3.3.1.1.1.1.1.3"><divide id="S4.SS1.p4.1.m1.3.3.1.1.1.1.1.3.1.cmml" xref="S4.SS1.p4.1.m1.3.3.1.1.1.1.1.3"></divide><ci id="S4.SS1.p4.1.m1.3.3.1.1.1.1.1.3.2.cmml" xref="S4.SS1.p4.1.m1.3.3.1.1.1.1.1.3.2">𝑡</ci><ci id="S4.SS1.p4.1.m1.3.3.1.1.1.1.1.3.3.cmml" xref="S4.SS1.p4.1.m1.3.3.1.1.1.1.1.3.3">𝑇</ci></apply><apply id="S4.SS1.p4.1.m1.3.3.1.1.1.1.1.1.2.cmml" xref="S4.SS1.p4.1.m1.3.3.1.1.1.1.1.1.1"><log id="S4.SS1.p4.1.m1.1.1.cmml" xref="S4.SS1.p4.1.m1.1.1"></log><apply id="S4.SS1.p4.1.m1.3.3.1.1.1.1.1.1.1.1.1.cmml" xref="S4.SS1.p4.1.m1.3.3.1.1.1.1.1.1.1.1.1"><divide id="S4.SS1.p4.1.m1.3.3.1.1.1.1.1.1.1.1.1.1.cmml" xref="S4.SS1.p4.1.m1.3.3.1.1.1.1.1.1.1.1.1.1"></divide><apply id="S4.SS1.p4.1.m1.3.3.1.1.1.1.1.1.1.1.1.2.cmml" xref="S4.SS1.p4.1.m1.3.3.1.1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S4.SS1.p4.1.m1.3.3.1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S4.SS1.p4.1.m1.3.3.1.1.1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S4.SS1.p4.1.m1.3.3.1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S4.SS1.p4.1.m1.3.3.1.1.1.1.1.1.1.1.1.2.2">𝜂</ci><ci id="S4.SS1.p4.1.m1.3.3.1.1.1.1.1.1.1.1.1.2.3a.cmml" xref="S4.SS1.p4.1.m1.3.3.1.1.1.1.1.1.1.1.1.2.3"><mtext mathsize="70%" id="S4.SS1.p4.1.m1.3.3.1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S4.SS1.p4.1.m1.3.3.1.1.1.1.1.1.1.1.1.2.3">start</mtext></ci></apply><apply id="S4.SS1.p4.1.m1.3.3.1.1.1.1.1.1.1.1.1.3.cmml" xref="S4.SS1.p4.1.m1.3.3.1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S4.SS1.p4.1.m1.3.3.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S4.SS1.p4.1.m1.3.3.1.1.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S4.SS1.p4.1.m1.3.3.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S4.SS1.p4.1.m1.3.3.1.1.1.1.1.1.1.1.1.3.2">𝜂</ci><ci id="S4.SS1.p4.1.m1.3.3.1.1.1.1.1.1.1.1.1.3.3a.cmml" xref="S4.SS1.p4.1.m1.3.3.1.1.1.1.1.1.1.1.1.3.3"><mtext mathsize="70%" id="S4.SS1.p4.1.m1.3.3.1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S4.SS1.p4.1.m1.3.3.1.1.1.1.1.1.1.1.1.3.3">end</mtext></ci></apply></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p4.1.m1.3c">\eta_{t}=\eta_{start}\exp(\frac{t}{T}\log(\eta_{\text{start}}/\eta_{\text{end}}))</annotation></semantics></math> with <math id="S4.SS1.p4.2.m2.1" class="ltx_Math" alttext="\eta_{\text{start}}" display="inline"><semantics id="S4.SS1.p4.2.m2.1a"><msub id="S4.SS1.p4.2.m2.1.1" xref="S4.SS1.p4.2.m2.1.1.cmml"><mi id="S4.SS1.p4.2.m2.1.1.2" xref="S4.SS1.p4.2.m2.1.1.2.cmml">η</mi><mtext id="S4.SS1.p4.2.m2.1.1.3" xref="S4.SS1.p4.2.m2.1.1.3a.cmml">start</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p4.2.m2.1b"><apply id="S4.SS1.p4.2.m2.1.1.cmml" xref="S4.SS1.p4.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS1.p4.2.m2.1.1.1.cmml" xref="S4.SS1.p4.2.m2.1.1">subscript</csymbol><ci id="S4.SS1.p4.2.m2.1.1.2.cmml" xref="S4.SS1.p4.2.m2.1.1.2">𝜂</ci><ci id="S4.SS1.p4.2.m2.1.1.3a.cmml" xref="S4.SS1.p4.2.m2.1.1.3"><mtext mathsize="70%" id="S4.SS1.p4.2.m2.1.1.3.cmml" xref="S4.SS1.p4.2.m2.1.1.3">start</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p4.2.m2.1c">\eta_{\text{start}}</annotation></semantics></math>, <math id="S4.SS1.p4.3.m3.1" class="ltx_Math" alttext="\eta_{\text{end}}" display="inline"><semantics id="S4.SS1.p4.3.m3.1a"><msub id="S4.SS1.p4.3.m3.1.1" xref="S4.SS1.p4.3.m3.1.1.cmml"><mi id="S4.SS1.p4.3.m3.1.1.2" xref="S4.SS1.p4.3.m3.1.1.2.cmml">η</mi><mtext id="S4.SS1.p4.3.m3.1.1.3" xref="S4.SS1.p4.3.m3.1.1.3a.cmml">end</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p4.3.m3.1b"><apply id="S4.SS1.p4.3.m3.1.1.cmml" xref="S4.SS1.p4.3.m3.1.1"><csymbol cd="ambiguous" id="S4.SS1.p4.3.m3.1.1.1.cmml" xref="S4.SS1.p4.3.m3.1.1">subscript</csymbol><ci id="S4.SS1.p4.3.m3.1.1.2.cmml" xref="S4.SS1.p4.3.m3.1.1.2">𝜂</ci><ci id="S4.SS1.p4.3.m3.1.1.3a.cmml" xref="S4.SS1.p4.3.m3.1.1.3"><mtext mathsize="70%" id="S4.SS1.p4.3.m3.1.1.3.cmml" xref="S4.SS1.p4.3.m3.1.1.3">end</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p4.3.m3.1c">\eta_{\text{end}}</annotation></semantics></math> the starting and last learning rates respectively is applied at training time. <math id="S4.SS1.p4.4.m4.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S4.SS1.p4.4.m4.1a"><mi id="S4.SS1.p4.4.m4.1.1" xref="S4.SS1.p4.4.m4.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p4.4.m4.1b"><ci id="S4.SS1.p4.4.m4.1.1.cmml" xref="S4.SS1.p4.4.m4.1.1">𝑇</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p4.4.m4.1c">T</annotation></semantics></math> represents the total number of FL rounds.</p>
</div>
<div id="S4.SS1.p5" class="ltx_para ltx_noindent">
<p id="S4.SS1.p5.1" class="ltx_p"><span id="S4.SS1.p5.1.1" class="ltx_text ltx_font_bold">Client partitioning.</span> Following previous works, we propose to compose a pool of 100 clients with 10 active clients training concurrently in a given round <cite class="ltx_cite ltx_citemacro_citep">(McMahan et al., <a href="#bib.bib37" title="" class="ltx_ref">2017</a>)</cite>. We do this for all experiments except for FEMNIST, which comes pre-partitioned into 3597 clients. For this dataset we consider the setting of sampling 35 clients per round as in <cite class="ltx_cite ltx_citemacro_citet">Caldas et al. (<a href="#bib.bib4" title="" class="ltx_ref">2018</a>)</cite>.</p>
</div>
<div id="S4.SS1.p6" class="ltx_para ltx_noindent">
<p id="S4.SS1.p6.2" class="ltx_p"><span id="S4.SS1.p6.2.1" class="ltx_text ltx_font_bold">Sparsity Ratios.</span> This work considers accelerating the convolutions involved during forward and backward propagation following a <span id="S4.SS1.p6.2.2" class="ltx_text ltx_font_typewriter">Top-K</span> sparsity inducing mechanism at the weight level. As a result, the expected sparse pattern would be unstructured, which can only be accelerated if tensors are sufficiently sparse. While <span id="S4.SS1.p6.2.3" class="ltx_text ltx_font_italic">sufficient</span> is mostly hardware-specific, for the target platforms often considered in FL (e.g. mobile CPUs and GPUs) we set a minimum sparsity ratio (<math id="S4.SS1.p6.1.m1.1" class="ltx_Math" alttext="sp" display="inline"><semantics id="S4.SS1.p6.1.m1.1a"><mrow id="S4.SS1.p6.1.m1.1.1" xref="S4.SS1.p6.1.m1.1.1.cmml"><mi id="S4.SS1.p6.1.m1.1.1.2" xref="S4.SS1.p6.1.m1.1.1.2.cmml">s</mi><mo lspace="0em" rspace="0em" id="S4.SS1.p6.1.m1.1.1.1" xref="S4.SS1.p6.1.m1.1.1.1.cmml">​</mo><mi id="S4.SS1.p6.1.m1.1.1.3" xref="S4.SS1.p6.1.m1.1.1.3.cmml">p</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p6.1.m1.1b"><apply id="S4.SS1.p6.1.m1.1.1.cmml" xref="S4.SS1.p6.1.m1.1.1"><times id="S4.SS1.p6.1.m1.1.1.1.cmml" xref="S4.SS1.p6.1.m1.1.1.1"></times><ci id="S4.SS1.p6.1.m1.1.1.2.cmml" xref="S4.SS1.p6.1.m1.1.1.2">𝑠</ci><ci id="S4.SS1.p6.1.m1.1.1.3.cmml" xref="S4.SS1.p6.1.m1.1.1.3">𝑝</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p6.1.m1.1c">sp</annotation></semantics></math>) of 90%, above which acceleration can be achieved <cite class="ltx_cite ltx_citemacro_citep">(Wang, <a href="#bib.bib53" title="" class="ltx_ref">2021</a>)</cite>. We include in our study <math id="S4.SS1.p6.2.m2.3" class="ltx_Math" alttext="sp\in[0.7,0.9,0.95]" display="inline"><semantics id="S4.SS1.p6.2.m2.3a"><mrow id="S4.SS1.p6.2.m2.3.4" xref="S4.SS1.p6.2.m2.3.4.cmml"><mrow id="S4.SS1.p6.2.m2.3.4.2" xref="S4.SS1.p6.2.m2.3.4.2.cmml"><mi id="S4.SS1.p6.2.m2.3.4.2.2" xref="S4.SS1.p6.2.m2.3.4.2.2.cmml">s</mi><mo lspace="0em" rspace="0em" id="S4.SS1.p6.2.m2.3.4.2.1" xref="S4.SS1.p6.2.m2.3.4.2.1.cmml">​</mo><mi id="S4.SS1.p6.2.m2.3.4.2.3" xref="S4.SS1.p6.2.m2.3.4.2.3.cmml">p</mi></mrow><mo id="S4.SS1.p6.2.m2.3.4.1" xref="S4.SS1.p6.2.m2.3.4.1.cmml">∈</mo><mrow id="S4.SS1.p6.2.m2.3.4.3.2" xref="S4.SS1.p6.2.m2.3.4.3.1.cmml"><mo stretchy="false" id="S4.SS1.p6.2.m2.3.4.3.2.1" xref="S4.SS1.p6.2.m2.3.4.3.1.cmml">[</mo><mn id="S4.SS1.p6.2.m2.1.1" xref="S4.SS1.p6.2.m2.1.1.cmml">0.7</mn><mo id="S4.SS1.p6.2.m2.3.4.3.2.2" xref="S4.SS1.p6.2.m2.3.4.3.1.cmml">,</mo><mn id="S4.SS1.p6.2.m2.2.2" xref="S4.SS1.p6.2.m2.2.2.cmml">0.9</mn><mo id="S4.SS1.p6.2.m2.3.4.3.2.3" xref="S4.SS1.p6.2.m2.3.4.3.1.cmml">,</mo><mn id="S4.SS1.p6.2.m2.3.3" xref="S4.SS1.p6.2.m2.3.3.cmml">0.95</mn><mo stretchy="false" id="S4.SS1.p6.2.m2.3.4.3.2.4" xref="S4.SS1.p6.2.m2.3.4.3.1.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p6.2.m2.3b"><apply id="S4.SS1.p6.2.m2.3.4.cmml" xref="S4.SS1.p6.2.m2.3.4"><in id="S4.SS1.p6.2.m2.3.4.1.cmml" xref="S4.SS1.p6.2.m2.3.4.1"></in><apply id="S4.SS1.p6.2.m2.3.4.2.cmml" xref="S4.SS1.p6.2.m2.3.4.2"><times id="S4.SS1.p6.2.m2.3.4.2.1.cmml" xref="S4.SS1.p6.2.m2.3.4.2.1"></times><ci id="S4.SS1.p6.2.m2.3.4.2.2.cmml" xref="S4.SS1.p6.2.m2.3.4.2.2">𝑠</ci><ci id="S4.SS1.p6.2.m2.3.4.2.3.cmml" xref="S4.SS1.p6.2.m2.3.4.2.3">𝑝</ci></apply><list id="S4.SS1.p6.2.m2.3.4.3.1.cmml" xref="S4.SS1.p6.2.m2.3.4.3.2"><cn type="float" id="S4.SS1.p6.2.m2.1.1.cmml" xref="S4.SS1.p6.2.m2.1.1">0.7</cn><cn type="float" id="S4.SS1.p6.2.m2.2.2.cmml" xref="S4.SS1.p6.2.m2.2.2">0.9</cn><cn type="float" id="S4.SS1.p6.2.m2.3.3.cmml" xref="S4.SS1.p6.2.m2.3.3">0.95</cn></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p6.2.m2.3c">sp\in[0.7,0.9,0.95]</annotation></semantics></math> in our initial evaluation. We expect minimal accuracy drop for both IID and non-IID at 0.7 sparsity.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Baselines Results</h3>

<div id="S4.SS2.p1" class="ltx_para ltx_noindent">
<p id="S4.SS2.p1.1" class="ltx_p">We begin by studying the effect of applying SWAT in both centralised learning and FL with the CIFAR10 dataset, and the results are given in Fig. <a href="#S4.F1" title="Figure 1 ‣ 4.2 Baselines Results ‣ 4 Sparse Training for Federated Learning ‣ ZeroFL: Efficient On-Device Training for Federated Learning with Local Sparsity" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. Applying SWAT in centralised training does not impact the validation accuracy much despite the high level of sparsity level, which is equivalent to the results from the original paper <cite class="ltx_cite ltx_citemacro_citep">(Raihan &amp; Aamodt, <a href="#bib.bib41" title="" class="ltx_ref">2020</a>)</cite> with a validation accuracy reaching 91.21% with a sparsity level of 95% against 93.32% for 70%.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para ltx_noindent">
<p id="S4.SS2.p2.2" class="ltx_p">We found sparse FL to be particularly sensitive to the learning rate and its scheduler. In particular, exponential decay annealing is crucial to reach relatively good performance. It is also clear from the curves that a higher learning rate of <math id="S4.SS2.p2.1.m1.1" class="ltx_Math" alttext="0.2" display="inline"><semantics id="S4.SS2.p2.1.m1.1a"><mn id="S4.SS2.p2.1.m1.1.1" xref="S4.SS2.p2.1.m1.1.1.cmml">0.2</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.1.m1.1b"><cn type="float" id="S4.SS2.p2.1.m1.1.1.cmml" xref="S4.SS2.p2.1.m1.1.1">0.2</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.1.m1.1c">0.2</annotation></semantics></math> reaches better accuracies in general than <math id="S4.SS2.p2.2.m2.1" class="ltx_Math" alttext="0.1" display="inline"><semantics id="S4.SS2.p2.2.m2.1a"><mn id="S4.SS2.p2.2.m2.1.1" xref="S4.SS2.p2.2.m2.1.1.cmml">0.1</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.2.m2.1b"><cn type="float" id="S4.SS2.p2.2.m2.1.1.cmml" xref="S4.SS2.p2.2.m2.1.1">0.1</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.2.m2.1c">0.1</annotation></semantics></math>. As expected, however, FL offers lower levels of performance across all setups compared to centralised training.</p>
</div>
<div id="S4.SS2.p3" class="ltx_para ltx_noindent">
<p id="S4.SS2.p3.1" class="ltx_p">In addition, and conversely to centralised training, plots show consistent drops in the validation accuracy with the increase of the sparsity level. It is worth noticing that the validation accuracy decreases by 4.60% and 2.78% while the sparsity level increases from 90% to 95% and 70% to 90% respectively for IID settings. Then the validation accuracy drops by 8.3% and 1.84% when sparsity levels increase from 90% to 95% and 70% to 90% respectively for non-IID settings. This highlights an important degradation of performance in non-IID settings with very high levels of sparsity.</p>
</div>
<figure id="S4.F1" class="ltx_figure"><img src="/html/2208.02507/assets/x1.png" id="S4.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="159" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Comparison of validation accuracies in percentage of both centralised learning and FL on the CIFAR10 dataset with different sparsity and non-IID ratios. While centralised training suffers from minimal degradation at very high sparsity ratios (<math id="S4.F1.3.m1.1" class="ltx_Math" alttext="95" display="inline"><semantics id="S4.F1.3.m1.1b"><mn id="S4.F1.3.m1.1.1" xref="S4.F1.3.m1.1.1.cmml">95</mn><annotation-xml encoding="MathML-Content" id="S4.F1.3.m1.1c"><cn type="integer" id="S4.F1.3.m1.1.1.cmml" xref="S4.F1.3.m1.1.1">95</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.F1.3.m1.1d">95</annotation></semantics></math>%), the opposite happens for FL: we observe a <math id="S4.F1.4.m2.1" class="ltx_Math" alttext="10" display="inline"><semantics id="S4.F1.4.m2.1b"><mn id="S4.F1.4.m2.1.1" xref="S4.F1.4.m2.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="S4.F1.4.m2.1c"><cn type="integer" id="S4.F1.4.m2.1.1.cmml" xref="S4.F1.4.m2.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.F1.4.m2.1d">10</annotation></semantics></math>% accuracy drop.</figcaption>
</figure>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Sparsification Effect Analysis</h3>

<div id="S4.SS3.p1" class="ltx_para ltx_noindent">
<p id="S4.SS3.p1.2" class="ltx_p">As shown in Fig. <a href="#S4.F1" title="Figure 1 ‣ 4.2 Baselines Results ‣ 4 Sparse Training for Federated Learning ‣ ZeroFL: Efficient On-Device Training for Federated Learning with Local Sparsity" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, high levels of sparsity with FL (<span id="S4.SS3.p1.2.1" class="ltx_text ltx_font_italic">e.g.</span> <math id="S4.SS3.p1.1.m1.1" class="ltx_Math" alttext="\geq 90" display="inline"><semantics id="S4.SS3.p1.1.m1.1a"><mrow id="S4.SS3.p1.1.m1.1.1" xref="S4.SS3.p1.1.m1.1.1.cmml"><mi id="S4.SS3.p1.1.m1.1.1.2" xref="S4.SS3.p1.1.m1.1.1.2.cmml"></mi><mo id="S4.SS3.p1.1.m1.1.1.1" xref="S4.SS3.p1.1.m1.1.1.1.cmml">≥</mo><mn id="S4.SS3.p1.1.m1.1.1.3" xref="S4.SS3.p1.1.m1.1.1.3.cmml">90</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.1.m1.1b"><apply id="S4.SS3.p1.1.m1.1.1.cmml" xref="S4.SS3.p1.1.m1.1.1"><geq id="S4.SS3.p1.1.m1.1.1.1.cmml" xref="S4.SS3.p1.1.m1.1.1.1"></geq><csymbol cd="latexml" id="S4.SS3.p1.1.m1.1.1.2.cmml" xref="S4.SS3.p1.1.m1.1.1.2">absent</csymbol><cn type="integer" id="S4.SS3.p1.1.m1.1.1.3.cmml" xref="S4.SS3.p1.1.m1.1.1.3">90</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.1.m1.1c">\geq 90</annotation></semantics></math>%) induce an significant drop of accuracy that is more noticeable than for centralised training. We aim at understanding this phenomenon to further reduce the gap between centralised and FL training by properly adapting sparsification. As a first step, we propose to investigate the behaviour of the neural weights from clients to clients under SWAT and FL with a sparsity ratio equals to <math id="S4.SS3.p1.2.m2.1" class="ltx_Math" alttext="90" display="inline"><semantics id="S4.SS3.p1.2.m2.1a"><mn id="S4.SS3.p1.2.m2.1.1" xref="S4.SS3.p1.2.m2.1.1.cmml">90</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.2.m2.1b"><cn type="integer" id="S4.SS3.p1.2.m2.1.1.cmml" xref="S4.SS3.p1.2.m2.1.1">90</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.2.m2.1c">90</annotation></semantics></math>%.</p>
</div>
<div id="S4.SS3.p2" class="ltx_para ltx_noindent">
<p id="S4.SS3.p2.2" class="ltx_p">Indeed, an undocumented effect of SWAT occurs at inference time and may motivate an extension of the technique to work properly with FL. During training, SWAT partitions the weights in two sets: active and non-active. The former set is used as a sparsity map during any forward propagation (<span id="S4.SS3.p2.2.1" class="ltx_text ltx_font_italic">i.e.</span> both at training and inference times). In fact, a part of the weights are simply dropped from the neural network. This implies that the neural network must remain sparsified when evaluating and inferring or the accuracy will drastically drops. For instance, a FL trained system on CIFAR10 that reaches an accuracy of <math id="S4.SS3.p2.1.m1.1" class="ltx_Math" alttext="82" display="inline"><semantics id="S4.SS3.p2.1.m1.1a"><mn id="S4.SS3.p2.1.m1.1.1" xref="S4.SS3.p2.1.m1.1.1.cmml">82</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.1.m1.1b"><cn type="integer" id="S4.SS3.p2.1.m1.1.1.cmml" xref="S4.SS3.p2.1.m1.1.1">82</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.1.m1.1c">82</annotation></semantics></math>% on the validation set will drop to <math id="S4.SS3.p2.2.m2.1" class="ltx_Math" alttext="10" display="inline"><semantics id="S4.SS3.p2.2.m2.1a"><mn id="S4.SS3.p2.2.m2.1.1" xref="S4.SS3.p2.2.m2.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.2.m2.1b"><cn type="integer" id="S4.SS3.p2.2.m2.1.1.cmml" xref="S4.SS3.p2.2.m2.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.2.m2.1c">10</annotation></semantics></math>% if the inference is done without sparsification. It empirically validates that sparse training has an impact on the internal representation of a neural network making it dependent on the sparsification strategy during inference.</p>
</div>
<div id="S4.SS3.p3" class="ltx_para ltx_noindent">
<p id="S4.SS3.p3.1" class="ltx_p">In practice, the latter behaviour is explained by the fact that, during centralised training, sparsified weights tend to be always the same <span id="S4.SS3.p3.1.1" class="ltx_text ltx_font_italic">i.e.</span> some parameters are simply discarded. For FL, however, one may intuitively hypothesize that different clients will lead to different sparsification maps during the local training; preventing the creation of a global federated sparsification strategy. To investigate this, we propose to analyse the variations observed on the most active weights after aggregation on the server over the communication rounds.</p>
</div>
<div id="S4.SS3.p4" class="ltx_para ltx_noindent">
<p id="S4.SS3.p4.2" class="ltx_p">Let us define the <span id="S4.SS3.p4.2.1" class="ltx_text ltx_font_typewriter">top-K</span> weights as being the per-layer set of parameters with the highest norm. During each communication round, clients only send their <span id="S4.SS3.p4.2.2" class="ltx_text ltx_font_typewriter">top-K</span> weights to the server while the remaining ones are set to zero. After aggregation on the server side, the resulting weight matrix informs us on the level of overlapping non-zero parameters observed on the clients. Indeed, every non-zero value obtained at a specific position will likely result in a non-zero value at the corresponding position in the aggregated weight matrix. For instance, if the number of non-sparse elements from the aggregated matrix is equivalent to the one of the clients (<math id="S4.SS3.p4.1.m1.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S4.SS3.p4.1.m1.1a"><mi id="S4.SS3.p4.1.m1.1.1" xref="S4.SS3.p4.1.m1.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p4.1.m1.1b"><ci id="S4.SS3.p4.1.m1.1.1.cmml" xref="S4.SS3.p4.1.m1.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p4.1.m1.1c">K</annotation></semantics></math>%) it means that all clients have the exact same <span id="S4.SS3.p4.2.3" class="ltx_text ltx_font_typewriter">top-K</span> weights. With that in mind, we can define a non-zero ratio that is the number of non-zero parameters after aggregation divided by the the total number of elements in this layer. Thus, the higher this ratio is, the more different are the <span id="S4.SS3.p4.2.4" class="ltx_text ltx_font_typewriter">top-K</span> weights sent from the clients. Fig. <a href="#S4.F2" title="Figure 2 ‣ 4.3 Sparsification Effect Analysis ‣ 4 Sparse Training for Federated Learning ‣ ZeroFL: Efficient On-Device Training for Federated Learning with Local Sparsity" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> depicts this ratio for different CNN layers for a non-IID CIFAR-10 with <math id="S4.SS3.p4.2.m2.2" class="ltx_Math" alttext="K\in\{10,30\}" display="inline"><semantics id="S4.SS3.p4.2.m2.2a"><mrow id="S4.SS3.p4.2.m2.2.3" xref="S4.SS3.p4.2.m2.2.3.cmml"><mi id="S4.SS3.p4.2.m2.2.3.2" xref="S4.SS3.p4.2.m2.2.3.2.cmml">K</mi><mo id="S4.SS3.p4.2.m2.2.3.1" xref="S4.SS3.p4.2.m2.2.3.1.cmml">∈</mo><mrow id="S4.SS3.p4.2.m2.2.3.3.2" xref="S4.SS3.p4.2.m2.2.3.3.1.cmml"><mo stretchy="false" id="S4.SS3.p4.2.m2.2.3.3.2.1" xref="S4.SS3.p4.2.m2.2.3.3.1.cmml">{</mo><mn id="S4.SS3.p4.2.m2.1.1" xref="S4.SS3.p4.2.m2.1.1.cmml">10</mn><mo id="S4.SS3.p4.2.m2.2.3.3.2.2" xref="S4.SS3.p4.2.m2.2.3.3.1.cmml">,</mo><mn id="S4.SS3.p4.2.m2.2.2" xref="S4.SS3.p4.2.m2.2.2.cmml">30</mn><mo stretchy="false" id="S4.SS3.p4.2.m2.2.3.3.2.3" xref="S4.SS3.p4.2.m2.2.3.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p4.2.m2.2b"><apply id="S4.SS3.p4.2.m2.2.3.cmml" xref="S4.SS3.p4.2.m2.2.3"><in id="S4.SS3.p4.2.m2.2.3.1.cmml" xref="S4.SS3.p4.2.m2.2.3.1"></in><ci id="S4.SS3.p4.2.m2.2.3.2.cmml" xref="S4.SS3.p4.2.m2.2.3.2">𝐾</ci><set id="S4.SS3.p4.2.m2.2.3.3.1.cmml" xref="S4.SS3.p4.2.m2.2.3.3.2"><cn type="integer" id="S4.SS3.p4.2.m2.1.1.cmml" xref="S4.SS3.p4.2.m2.1.1">10</cn><cn type="integer" id="S4.SS3.p4.2.m2.2.2.cmml" xref="S4.SS3.p4.2.m2.2.2">30</cn></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p4.2.m2.2c">K\in\{10,30\}</annotation></semantics></math>%.</p>
</div>
<figure id="S4.F2" class="ltx_figure"><img src="/html/2208.02507/assets/x2.png" id="S4.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="176" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span> Evolution of the non-zero weights ratio after server aggregation (<span id="S4.F2.7.1" class="ltx_text ltx_font_italic">i.e.</span> number of weights that are non-zero divided by the total number of parameter in that layer) of all CNN layers of a ResNet-18 trained on CIFAR10 with FL. Each of the <math id="S4.F2.2.m1.1" class="ltx_Math" alttext="100" display="inline"><semantics id="S4.F2.2.m1.1b"><mn id="S4.F2.2.m1.1.1" xref="S4.F2.2.m1.1.1.cmml">100</mn><annotation-xml encoding="MathML-Content" id="S4.F2.2.m1.1c"><cn type="integer" id="S4.F2.2.m1.1.1.cmml" xref="S4.F2.2.m1.1.1">100</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.F2.2.m1.1d">100</annotation></semantics></math> clients either send the <span id="S4.F2.8.2" class="ltx_text ltx_font_typewriter">top-10%</span> or <span id="S4.F2.9.3" class="ltx_text ltx_font_typewriter">top-30%</span> (<span id="S4.F2.10.4" class="ltx_text ltx_font_italic">i.e.</span> weights with the highest norm) to the server.</figcaption>
</figure>
<div id="S4.SS3.p5" class="ltx_para ltx_noindent">
<p id="S4.SS3.p5.3" class="ltx_p">First, a significant overlap exists between clients across all CNN layers. Indeed, the non-zero ratio almost never exceeds 0.40, meaning that at least 60% of the weights are not comprised in the <span id="S4.SS3.p5.3.1" class="ltx_text ltx_font_typewriter">top-K</span> weights of the clients. This advocates for the fact that the most important weights for the current task tend to be the same across clients. Then, we can see that the non-zero ratio does not seem to be significantly impacted by changing <math id="S4.SS3.p5.1.m1.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S4.SS3.p5.1.m1.1a"><mi id="S4.SS3.p5.1.m1.1.1" xref="S4.SS3.p5.1.m1.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p5.1.m1.1b"><ci id="S4.SS3.p5.1.m1.1.1.cmml" xref="S4.SS3.p5.1.m1.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p5.1.m1.1c">K</annotation></semantics></math> from <math id="S4.SS3.p5.2.m2.1" class="ltx_Math" alttext="10" display="inline"><semantics id="S4.SS3.p5.2.m2.1a"><mn id="S4.SS3.p5.2.m2.1.1" xref="S4.SS3.p5.2.m2.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.p5.2.m2.1b"><cn type="integer" id="S4.SS3.p5.2.m2.1.1.cmml" xref="S4.SS3.p5.2.m2.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p5.2.m2.1c">10</annotation></semantics></math>% to <math id="S4.SS3.p5.3.m3.1" class="ltx_Math" alttext="30" display="inline"><semantics id="S4.SS3.p5.3.m3.1a"><mn id="S4.SS3.p5.3.m3.1.1" xref="S4.SS3.p5.3.m3.1.1.cmml">30</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.p5.3.m3.1b"><cn type="integer" id="S4.SS3.p5.3.m3.1.1.cmml" xref="S4.SS3.p5.3.m3.1.1">30</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p5.3.m3.1c">30</annotation></semantics></math>% as it only slightly increases for most CNN layers. This is explained by the fact that while clients may have different <span id="S4.SS3.p5.3.2" class="ltx_text ltx_font_typewriter">top-10%</span> weights, they tend to have the same <span id="S4.SS3.p5.3.3" class="ltx_text ltx_font_typewriter">top-30%</span> parameters: a specific non-zero weight that is reported as a <span id="S4.SS3.p5.3.4" class="ltx_text ltx_font_typewriter">top-10%</span> element from a single client out of the selected ones is most likely to be reported as non-zero as well by more of them when we increase to <span id="S4.SS3.p5.3.5" class="ltx_text ltx_font_typewriter">top-30%</span>. In short, <span id="S4.SS3.p5.3.6" class="ltx_text ltx_font_typewriter">top-30%</span> will gather most of information about weights that are considered as being <span id="S4.SS3.p5.3.7" class="ltx_text ltx_font_italic">important</span> for the task while keeping the same level of sparsity.</p>
</div>
<div id="S4.SS3.p6" class="ltx_para ltx_noindent">
<p id="S4.SS3.p6.2" class="ltx_p">Second, we propose to examine the exact positions of the <span id="S4.SS3.p6.2.1" class="ltx_text ltx_font_typewriter">top-10%</span> weights for certain CNN layers across a pool of <math id="S4.SS3.p6.1.m1.1" class="ltx_Math" alttext="100" display="inline"><semantics id="S4.SS3.p6.1.m1.1a"><mn id="S4.SS3.p6.1.m1.1.1" xref="S4.SS3.p6.1.m1.1.1.cmml">100</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.p6.1.m1.1b"><cn type="integer" id="S4.SS3.p6.1.m1.1.1.cmml" xref="S4.SS3.p6.1.m1.1.1">100</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p6.1.m1.1c">100</annotation></semantics></math> selected clients to better evaluate the overlap. Fig. <a href="#S4.F3" title="Figure 3 ‣ 4.3 Sparsification Effect Analysis ‣ 4 Sparse Training for Federated Learning ‣ ZeroFL: Efficient On-Device Training for Federated Learning with Local Sparsity" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> shows the weight matrix recorded every <math id="S4.SS3.p6.2.m2.1" class="ltx_Math" alttext="20" display="inline"><semantics id="S4.SS3.p6.2.m2.1a"><mn id="S4.SS3.p6.2.m2.1.1" xref="S4.SS3.p6.2.m2.1.1.cmml">20</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.p6.2.m2.1b"><cn type="integer" id="S4.SS3.p6.2.m2.1.1.cmml" xref="S4.SS3.p6.2.m2.1.1">20</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p6.2.m2.1c">20</annotation></semantics></math> communication rounds after aggregation on the server. Observations validate our intuition that most of zero and non-zero weights remain the same during the whole training.</p>
</div>
<div id="S4.SS3.p7" class="ltx_para ltx_noindent">
<p id="S4.SS3.p7.1" class="ltx_p">Based on this analysis, we hypothesis that the degradation of performance observed with high levels of sparsity for FL is due to the dilution of important information during the aggregation process. For instance, a weight that would be only sent by a single client as part of its <span id="S4.SS3.p7.1.1" class="ltx_text ltx_font_typewriter">top-10%</span> parameters would not be <span id="S4.SS3.p7.1.2" class="ltx_text ltx_font_italic">diluted</span> with the noise of all the others clients. Conversely, this very same weight may be completely corrupted if we send the entire dense model for aggregation.</p>
</div>
<figure id="S4.F3" class="ltx_figure"><img src="/html/2208.02507/assets/figures/heat_new.png" id="S4.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="227" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Heatmaps of 6 CNN layers (layer 4-9) in ResNet-18 when trained on CIFAR10 with 100 clients by only keeping the top 10% of weights. The weights are recorded every 20 communication rounds and <span id="S4.F3.2.1" class="ltx_text ltx_font_italic">flatten</span> along the y-axis. The consistency across rounds (x-axis) indicates that, for the most part, the locations of non-zero weights remains constant. A larger version of this picture is given in the Appendix <a href="#A1.SS3" title="A.3 Heatmap visualizations ‣ Appendix A Appendix ‣ ZeroFL: Efficient On-Device Training for Federated Learning with Local Sparsity" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A.3</span></a></figcaption>
</figure>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>ZeroFL: local sparsification of uplink communication</h2>

<div id="S5.p1" class="ltx_para ltx_noindent">
<p id="S5.p1.1" class="ltx_p">Motivated by our previous analysis which suggests that not all weights are necessary to be transferred to the central server for aggregation, we propose <span id="S5.p1.1.1" class="ltx_text ltx_font_italic">ZeroFL</span>: a method that applies local sparsification before uplink communication. More precisely, we provide three strategies for local sparsification to improve the performance of sparse training while reducing the communication cost at the same time. By leveraging local sparsification, ZeroFL reduces the uplink communication footprint, hence reducing the noise aggregated on the central server observed in Section <a href="#S4.SS3" title="4.3 Sparsification Effect Analysis ‣ 4 Sparse Training for Federated Learning ‣ ZeroFL: Efficient On-Device Training for Federated Learning with Local Sparsity" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.3</span></a>. In particular, if some updates are only sent by few clients, we force others clients to send zero in that particular positions of updates following our three strategies. After aggregation, the magnitude of these particular updates will be averaged with the uploaded values instead of being completely corrupted by the entire set of clients. All three methods are summarized in Algorithm <a href="#alg1" title="Algorithm 1 ‣ 5 ZeroFL: local sparsification of uplink communication ‣ ZeroFL: Efficient On-Device Training for Federated Learning with Local Sparsity" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
<figure id="alg1" class="ltx_float ltx_float_algorithm ltx_framed ltx_framed_top">

<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_float"><span id="alg1.26.1.1" class="ltx_text ltx_font_bold">Algorithm 1</span> </span> <em id="alg1.27.2" class="ltx_emph ltx_font_italic">ZeroFL</em>: Let us consider a cluster of <math id="alg1.12.m1.1" class="ltx_Math" alttext="N" display="inline"><semantics id="alg1.12.m1.1b"><mi id="alg1.12.m1.1.1" xref="alg1.12.m1.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="alg1.12.m1.1c"><ci id="alg1.12.m1.1.1.cmml" xref="alg1.12.m1.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.12.m1.1d">N</annotation></semantics></math> total client with <math id="alg1.13.m2.1" class="ltx_Math" alttext="n" display="inline"><semantics id="alg1.13.m2.1b"><mi id="alg1.13.m2.1.1" xref="alg1.13.m2.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="alg1.13.m2.1c"><ci id="alg1.13.m2.1.1.cmml" xref="alg1.13.m2.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.13.m2.1d">n</annotation></semantics></math> local data set and each with a learning rate <math id="alg1.14.m3.1" class="ltx_Math" alttext="\eta_{t}" display="inline"><semantics id="alg1.14.m3.1b"><msub id="alg1.14.m3.1.1" xref="alg1.14.m3.1.1.cmml"><mi id="alg1.14.m3.1.1.2" xref="alg1.14.m3.1.1.2.cmml">η</mi><mi id="alg1.14.m3.1.1.3" xref="alg1.14.m3.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="alg1.14.m3.1c"><apply id="alg1.14.m3.1.1.cmml" xref="alg1.14.m3.1.1"><csymbol cd="ambiguous" id="alg1.14.m3.1.1.1.cmml" xref="alg1.14.m3.1.1">subscript</csymbol><ci id="alg1.14.m3.1.1.2.cmml" xref="alg1.14.m3.1.1.2">𝜂</ci><ci id="alg1.14.m3.1.1.3.cmml" xref="alg1.14.m3.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.14.m3.1d">\eta_{t}</annotation></semantics></math> at round <math id="alg1.15.m4.1" class="ltx_Math" alttext="t" display="inline"><semantics id="alg1.15.m4.1b"><mi id="alg1.15.m4.1.1" xref="alg1.15.m4.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="alg1.15.m4.1c"><ci id="alg1.15.m4.1.1.cmml" xref="alg1.15.m4.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.15.m4.1d">t</annotation></semantics></math> with <math id="alg1.16.m5.1" class="ltx_Math" alttext="T" display="inline"><semantics id="alg1.16.m5.1b"><mi id="alg1.16.m5.1.1" xref="alg1.16.m5.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="alg1.16.m5.1c"><ci id="alg1.16.m5.1.1.cmml" xref="alg1.16.m5.1.1">𝑇</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.16.m5.1d">T</annotation></semantics></math> the total number of communication rounds. The client has the data set <math id="alg1.17.m6.1" class="ltx_Math" alttext="n_{k}" display="inline"><semantics id="alg1.17.m6.1b"><msub id="alg1.17.m6.1.1" xref="alg1.17.m6.1.1.cmml"><mi id="alg1.17.m6.1.1.2" xref="alg1.17.m6.1.1.2.cmml">n</mi><mi id="alg1.17.m6.1.1.3" xref="alg1.17.m6.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="alg1.17.m6.1c"><apply id="alg1.17.m6.1.1.cmml" xref="alg1.17.m6.1.1"><csymbol cd="ambiguous" id="alg1.17.m6.1.1.1.cmml" xref="alg1.17.m6.1.1">subscript</csymbol><ci id="alg1.17.m6.1.1.2.cmml" xref="alg1.17.m6.1.1.2">𝑛</ci><ci id="alg1.17.m6.1.1.3.cmml" xref="alg1.17.m6.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.17.m6.1d">n_{k}</annotation></semantics></math>. The number of local epoch is <math id="alg1.18.m7.1" class="ltx_Math" alttext="E" display="inline"><semantics id="alg1.18.m7.1b"><mi id="alg1.18.m7.1.1" xref="alg1.18.m7.1.1.cmml">E</mi><annotation-xml encoding="MathML-Content" id="alg1.18.m7.1c"><ci id="alg1.18.m7.1.1.cmml" xref="alg1.18.m7.1.1">𝐸</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.18.m7.1d">E</annotation></semantics></math> and the number of clients participating in each round is denoted as <math id="alg1.19.m8.1" class="ltx_Math" alttext="K" display="inline"><semantics id="alg1.19.m8.1b"><mi id="alg1.19.m8.1.1" xref="alg1.19.m8.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="alg1.19.m8.1c"><ci id="alg1.19.m8.1.1.cmml" xref="alg1.19.m8.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.19.m8.1d">K</annotation></semantics></math>. <math id="alg1.20.m9.1" class="ltx_Math" alttext="w_{t}" display="inline"><semantics id="alg1.20.m9.1b"><msub id="alg1.20.m9.1.1" xref="alg1.20.m9.1.1.cmml"><mi id="alg1.20.m9.1.1.2" xref="alg1.20.m9.1.1.2.cmml">w</mi><mi id="alg1.20.m9.1.1.3" xref="alg1.20.m9.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="alg1.20.m9.1c"><apply id="alg1.20.m9.1.1.cmml" xref="alg1.20.m9.1.1"><csymbol cd="ambiguous" id="alg1.20.m9.1.1.1.cmml" xref="alg1.20.m9.1.1">subscript</csymbol><ci id="alg1.20.m9.1.1.2.cmml" xref="alg1.20.m9.1.1.2">𝑤</ci><ci id="alg1.20.m9.1.1.3.cmml" xref="alg1.20.m9.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.20.m9.1d">w_{t}</annotation></semantics></math> represent all the weights aggregated at round <math id="alg1.21.m10.1" class="ltx_Math" alttext="t" display="inline"><semantics id="alg1.21.m10.1b"><mi id="alg1.21.m10.1.1" xref="alg1.21.m10.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="alg1.21.m10.1c"><ci id="alg1.21.m10.1.1.cmml" xref="alg1.21.m10.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.21.m10.1d">t</annotation></semantics></math> and <math id="alg1.22.m11.1" class="ltx_Math" alttext="d_{t}" display="inline"><semantics id="alg1.22.m11.1b"><msub id="alg1.22.m11.1.1" xref="alg1.22.m11.1.1.cmml"><mi id="alg1.22.m11.1.1.2" xref="alg1.22.m11.1.1.2.cmml">d</mi><mi id="alg1.22.m11.1.1.3" xref="alg1.22.m11.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="alg1.22.m11.1c"><apply id="alg1.22.m11.1.1.cmml" xref="alg1.22.m11.1.1"><csymbol cd="ambiguous" id="alg1.22.m11.1.1.1.cmml" xref="alg1.22.m11.1.1">subscript</csymbol><ci id="alg1.22.m11.1.1.2.cmml" xref="alg1.22.m11.1.1.2">𝑑</ci><ci id="alg1.22.m11.1.1.3.cmml" xref="alg1.22.m11.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.22.m11.1d">d_{t}</annotation></semantics></math> the difference of weights.</figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<p id="alg1.28" class="ltx_p ltx_figure_panel"><span id="alg1.28.1" class="ltx_text ltx_font_bold">Central server does:</span></p>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<div id="alg1.29" class="ltx_listing ltx_figure_panel ltx_listing">
<div id="alg1.l1" class="ltx_listingline">
<span id="alg1.l1.1" class="ltx_text ltx_font_bold">for</span>  <math id="alg1.l1.m1.3" class="ltx_Math" alttext="t=0,...,T-1" display="inline"><semantics id="alg1.l1.m1.3a"><mrow id="alg1.l1.m1.3.3" xref="alg1.l1.m1.3.3.cmml"><mi id="alg1.l1.m1.3.3.3" xref="alg1.l1.m1.3.3.3.cmml">t</mi><mo id="alg1.l1.m1.3.3.2" xref="alg1.l1.m1.3.3.2.cmml">=</mo><mrow id="alg1.l1.m1.3.3.1.1" xref="alg1.l1.m1.3.3.1.2.cmml"><mn id="alg1.l1.m1.1.1" xref="alg1.l1.m1.1.1.cmml">0</mn><mo id="alg1.l1.m1.3.3.1.1.2" xref="alg1.l1.m1.3.3.1.2.cmml">,</mo><mi mathvariant="normal" id="alg1.l1.m1.2.2" xref="alg1.l1.m1.2.2.cmml">…</mi><mo id="alg1.l1.m1.3.3.1.1.3" xref="alg1.l1.m1.3.3.1.2.cmml">,</mo><mrow id="alg1.l1.m1.3.3.1.1.1" xref="alg1.l1.m1.3.3.1.1.1.cmml"><mi id="alg1.l1.m1.3.3.1.1.1.2" xref="alg1.l1.m1.3.3.1.1.1.2.cmml">T</mi><mo id="alg1.l1.m1.3.3.1.1.1.1" xref="alg1.l1.m1.3.3.1.1.1.1.cmml">−</mo><mn id="alg1.l1.m1.3.3.1.1.1.3" xref="alg1.l1.m1.3.3.1.1.1.3.cmml">1</mn></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l1.m1.3b"><apply id="alg1.l1.m1.3.3.cmml" xref="alg1.l1.m1.3.3"><eq id="alg1.l1.m1.3.3.2.cmml" xref="alg1.l1.m1.3.3.2"></eq><ci id="alg1.l1.m1.3.3.3.cmml" xref="alg1.l1.m1.3.3.3">𝑡</ci><list id="alg1.l1.m1.3.3.1.2.cmml" xref="alg1.l1.m1.3.3.1.1"><cn type="integer" id="alg1.l1.m1.1.1.cmml" xref="alg1.l1.m1.1.1">0</cn><ci id="alg1.l1.m1.2.2.cmml" xref="alg1.l1.m1.2.2">…</ci><apply id="alg1.l1.m1.3.3.1.1.1.cmml" xref="alg1.l1.m1.3.3.1.1.1"><minus id="alg1.l1.m1.3.3.1.1.1.1.cmml" xref="alg1.l1.m1.3.3.1.1.1.1"></minus><ci id="alg1.l1.m1.3.3.1.1.1.2.cmml" xref="alg1.l1.m1.3.3.1.1.1.2">𝑇</ci><cn type="integer" id="alg1.l1.m1.3.3.1.1.1.3.cmml" xref="alg1.l1.m1.3.3.1.1.1.3">1</cn></apply></list></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l1.m1.3c">t=0,...,T-1</annotation></semantics></math> <span id="alg1.l1.2" class="ltx_text ltx_font_bold">do</span>

</div>
<div id="alg1.l2" class="ltx_listingline">     Server randomly selects <math id="alg1.l2.m1.1" class="ltx_Math" alttext="K" display="inline"><semantics id="alg1.l2.m1.1a"><mi id="alg1.l2.m1.1.1" xref="alg1.l2.m1.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="alg1.l2.m1.1b"><ci id="alg1.l2.m1.1.1.cmml" xref="alg1.l2.m1.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l2.m1.1c">K</annotation></semantics></math> devices.

</div>
<div id="alg1.l3" class="ltx_listingline">     <span id="alg1.l3.1" class="ltx_text ltx_font_bold">for all</span>  <math id="alg1.l3.m1.1" class="ltx_Math" alttext="k" display="inline"><semantics id="alg1.l3.m1.1a"><mi id="alg1.l3.m1.1.1" xref="alg1.l3.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="alg1.l3.m1.1b"><ci id="alg1.l3.m1.1.1.cmml" xref="alg1.l3.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l3.m1.1c">k</annotation></semantics></math> in <math id="alg1.l3.m2.1" class="ltx_Math" alttext="K" display="inline"><semantics id="alg1.l3.m2.1a"><mi id="alg1.l3.m2.1.1" xref="alg1.l3.m2.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="alg1.l3.m2.1b"><ci id="alg1.l3.m2.1.1.cmml" xref="alg1.l3.m2.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l3.m2.1c">K</annotation></semantics></math> <span id="alg1.l3.2" class="ltx_text ltx_font_bold">do</span>

</div>
<div id="alg1.l4" class="ltx_listingline">         Perform TrainLocally<math id="alg1.l4.m1.2" class="ltx_Math" alttext="(k,w_{t})" display="inline"><semantics id="alg1.l4.m1.2a"><mrow id="alg1.l4.m1.2.2.1" xref="alg1.l4.m1.2.2.2.cmml"><mo stretchy="false" id="alg1.l4.m1.2.2.1.2" xref="alg1.l4.m1.2.2.2.cmml">(</mo><mi id="alg1.l4.m1.1.1" xref="alg1.l4.m1.1.1.cmml">k</mi><mo id="alg1.l4.m1.2.2.1.3" xref="alg1.l4.m1.2.2.2.cmml">,</mo><msub id="alg1.l4.m1.2.2.1.1" xref="alg1.l4.m1.2.2.1.1.cmml"><mi id="alg1.l4.m1.2.2.1.1.2" xref="alg1.l4.m1.2.2.1.1.2.cmml">w</mi><mi id="alg1.l4.m1.2.2.1.1.3" xref="alg1.l4.m1.2.2.1.1.3.cmml">t</mi></msub><mo stretchy="false" id="alg1.l4.m1.2.2.1.4" xref="alg1.l4.m1.2.2.2.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="alg1.l4.m1.2b"><interval closure="open" id="alg1.l4.m1.2.2.2.cmml" xref="alg1.l4.m1.2.2.1"><ci id="alg1.l4.m1.1.1.cmml" xref="alg1.l4.m1.1.1">𝑘</ci><apply id="alg1.l4.m1.2.2.1.1.cmml" xref="alg1.l4.m1.2.2.1.1"><csymbol cd="ambiguous" id="alg1.l4.m1.2.2.1.1.1.cmml" xref="alg1.l4.m1.2.2.1.1">subscript</csymbol><ci id="alg1.l4.m1.2.2.1.1.2.cmml" xref="alg1.l4.m1.2.2.1.1.2">𝑤</ci><ci id="alg1.l4.m1.2.2.1.1.3.cmml" xref="alg1.l4.m1.2.2.1.1.3">𝑡</ci></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="alg1.l4.m1.2c">(k,w_{t})</annotation></semantics></math>
     
</div>
<div id="alg1.l5" class="ltx_listingline">     <span id="alg1.l5.1" class="ltx_text ltx_font_bold">Aggregation</span>:

</div>
<div id="alg1.l6" class="ltx_listingline">     <span id="alg1.l6.1" class="ltx_text ltx_font_bold">If Top-K-Weight then</span> <math id="alg1.l6.m1.1" class="ltx_Math" alttext="w_{t+1}\leftarrow\sum^{K}_{k=0}\frac{n_{k}}{n}w^{k}_{t+1}" display="inline"><semantics id="alg1.l6.m1.1a"><mrow id="alg1.l6.m1.1.1" xref="alg1.l6.m1.1.1.cmml"><msub id="alg1.l6.m1.1.1.2" xref="alg1.l6.m1.1.1.2.cmml"><mi id="alg1.l6.m1.1.1.2.2" xref="alg1.l6.m1.1.1.2.2.cmml">w</mi><mrow id="alg1.l6.m1.1.1.2.3" xref="alg1.l6.m1.1.1.2.3.cmml"><mi id="alg1.l6.m1.1.1.2.3.2" xref="alg1.l6.m1.1.1.2.3.2.cmml">t</mi><mo id="alg1.l6.m1.1.1.2.3.1" xref="alg1.l6.m1.1.1.2.3.1.cmml">+</mo><mn id="alg1.l6.m1.1.1.2.3.3" xref="alg1.l6.m1.1.1.2.3.3.cmml">1</mn></mrow></msub><mo rspace="0.111em" stretchy="false" id="alg1.l6.m1.1.1.1" xref="alg1.l6.m1.1.1.1.cmml">←</mo><mrow id="alg1.l6.m1.1.1.3" xref="alg1.l6.m1.1.1.3.cmml"><msubsup id="alg1.l6.m1.1.1.3.1" xref="alg1.l6.m1.1.1.3.1.cmml"><mo id="alg1.l6.m1.1.1.3.1.2.2" xref="alg1.l6.m1.1.1.3.1.2.2.cmml">∑</mo><mrow id="alg1.l6.m1.1.1.3.1.3" xref="alg1.l6.m1.1.1.3.1.3.cmml"><mi id="alg1.l6.m1.1.1.3.1.3.2" xref="alg1.l6.m1.1.1.3.1.3.2.cmml">k</mi><mo id="alg1.l6.m1.1.1.3.1.3.1" xref="alg1.l6.m1.1.1.3.1.3.1.cmml">=</mo><mn id="alg1.l6.m1.1.1.3.1.3.3" xref="alg1.l6.m1.1.1.3.1.3.3.cmml">0</mn></mrow><mi id="alg1.l6.m1.1.1.3.1.2.3" xref="alg1.l6.m1.1.1.3.1.2.3.cmml">K</mi></msubsup><mrow id="alg1.l6.m1.1.1.3.2" xref="alg1.l6.m1.1.1.3.2.cmml"><mfrac id="alg1.l6.m1.1.1.3.2.2" xref="alg1.l6.m1.1.1.3.2.2.cmml"><msub id="alg1.l6.m1.1.1.3.2.2.2" xref="alg1.l6.m1.1.1.3.2.2.2.cmml"><mi id="alg1.l6.m1.1.1.3.2.2.2.2" xref="alg1.l6.m1.1.1.3.2.2.2.2.cmml">n</mi><mi id="alg1.l6.m1.1.1.3.2.2.2.3" xref="alg1.l6.m1.1.1.3.2.2.2.3.cmml">k</mi></msub><mi id="alg1.l6.m1.1.1.3.2.2.3" xref="alg1.l6.m1.1.1.3.2.2.3.cmml">n</mi></mfrac><mo lspace="0em" rspace="0em" id="alg1.l6.m1.1.1.3.2.1" xref="alg1.l6.m1.1.1.3.2.1.cmml">​</mo><msubsup id="alg1.l6.m1.1.1.3.2.3" xref="alg1.l6.m1.1.1.3.2.3.cmml"><mi id="alg1.l6.m1.1.1.3.2.3.2.2" xref="alg1.l6.m1.1.1.3.2.3.2.2.cmml">w</mi><mrow id="alg1.l6.m1.1.1.3.2.3.3" xref="alg1.l6.m1.1.1.3.2.3.3.cmml"><mi id="alg1.l6.m1.1.1.3.2.3.3.2" xref="alg1.l6.m1.1.1.3.2.3.3.2.cmml">t</mi><mo id="alg1.l6.m1.1.1.3.2.3.3.1" xref="alg1.l6.m1.1.1.3.2.3.3.1.cmml">+</mo><mn id="alg1.l6.m1.1.1.3.2.3.3.3" xref="alg1.l6.m1.1.1.3.2.3.3.3.cmml">1</mn></mrow><mi id="alg1.l6.m1.1.1.3.2.3.2.3" xref="alg1.l6.m1.1.1.3.2.3.2.3.cmml">k</mi></msubsup></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l6.m1.1b"><apply id="alg1.l6.m1.1.1.cmml" xref="alg1.l6.m1.1.1"><ci id="alg1.l6.m1.1.1.1.cmml" xref="alg1.l6.m1.1.1.1">←</ci><apply id="alg1.l6.m1.1.1.2.cmml" xref="alg1.l6.m1.1.1.2"><csymbol cd="ambiguous" id="alg1.l6.m1.1.1.2.1.cmml" xref="alg1.l6.m1.1.1.2">subscript</csymbol><ci id="alg1.l6.m1.1.1.2.2.cmml" xref="alg1.l6.m1.1.1.2.2">𝑤</ci><apply id="alg1.l6.m1.1.1.2.3.cmml" xref="alg1.l6.m1.1.1.2.3"><plus id="alg1.l6.m1.1.1.2.3.1.cmml" xref="alg1.l6.m1.1.1.2.3.1"></plus><ci id="alg1.l6.m1.1.1.2.3.2.cmml" xref="alg1.l6.m1.1.1.2.3.2">𝑡</ci><cn type="integer" id="alg1.l6.m1.1.1.2.3.3.cmml" xref="alg1.l6.m1.1.1.2.3.3">1</cn></apply></apply><apply id="alg1.l6.m1.1.1.3.cmml" xref="alg1.l6.m1.1.1.3"><apply id="alg1.l6.m1.1.1.3.1.cmml" xref="alg1.l6.m1.1.1.3.1"><csymbol cd="ambiguous" id="alg1.l6.m1.1.1.3.1.1.cmml" xref="alg1.l6.m1.1.1.3.1">subscript</csymbol><apply id="alg1.l6.m1.1.1.3.1.2.cmml" xref="alg1.l6.m1.1.1.3.1"><csymbol cd="ambiguous" id="alg1.l6.m1.1.1.3.1.2.1.cmml" xref="alg1.l6.m1.1.1.3.1">superscript</csymbol><sum id="alg1.l6.m1.1.1.3.1.2.2.cmml" xref="alg1.l6.m1.1.1.3.1.2.2"></sum><ci id="alg1.l6.m1.1.1.3.1.2.3.cmml" xref="alg1.l6.m1.1.1.3.1.2.3">𝐾</ci></apply><apply id="alg1.l6.m1.1.1.3.1.3.cmml" xref="alg1.l6.m1.1.1.3.1.3"><eq id="alg1.l6.m1.1.1.3.1.3.1.cmml" xref="alg1.l6.m1.1.1.3.1.3.1"></eq><ci id="alg1.l6.m1.1.1.3.1.3.2.cmml" xref="alg1.l6.m1.1.1.3.1.3.2">𝑘</ci><cn type="integer" id="alg1.l6.m1.1.1.3.1.3.3.cmml" xref="alg1.l6.m1.1.1.3.1.3.3">0</cn></apply></apply><apply id="alg1.l6.m1.1.1.3.2.cmml" xref="alg1.l6.m1.1.1.3.2"><times id="alg1.l6.m1.1.1.3.2.1.cmml" xref="alg1.l6.m1.1.1.3.2.1"></times><apply id="alg1.l6.m1.1.1.3.2.2.cmml" xref="alg1.l6.m1.1.1.3.2.2"><divide id="alg1.l6.m1.1.1.3.2.2.1.cmml" xref="alg1.l6.m1.1.1.3.2.2"></divide><apply id="alg1.l6.m1.1.1.3.2.2.2.cmml" xref="alg1.l6.m1.1.1.3.2.2.2"><csymbol cd="ambiguous" id="alg1.l6.m1.1.1.3.2.2.2.1.cmml" xref="alg1.l6.m1.1.1.3.2.2.2">subscript</csymbol><ci id="alg1.l6.m1.1.1.3.2.2.2.2.cmml" xref="alg1.l6.m1.1.1.3.2.2.2.2">𝑛</ci><ci id="alg1.l6.m1.1.1.3.2.2.2.3.cmml" xref="alg1.l6.m1.1.1.3.2.2.2.3">𝑘</ci></apply><ci id="alg1.l6.m1.1.1.3.2.2.3.cmml" xref="alg1.l6.m1.1.1.3.2.2.3">𝑛</ci></apply><apply id="alg1.l6.m1.1.1.3.2.3.cmml" xref="alg1.l6.m1.1.1.3.2.3"><csymbol cd="ambiguous" id="alg1.l6.m1.1.1.3.2.3.1.cmml" xref="alg1.l6.m1.1.1.3.2.3">subscript</csymbol><apply id="alg1.l6.m1.1.1.3.2.3.2.cmml" xref="alg1.l6.m1.1.1.3.2.3"><csymbol cd="ambiguous" id="alg1.l6.m1.1.1.3.2.3.2.1.cmml" xref="alg1.l6.m1.1.1.3.2.3">superscript</csymbol><ci id="alg1.l6.m1.1.1.3.2.3.2.2.cmml" xref="alg1.l6.m1.1.1.3.2.3.2.2">𝑤</ci><ci id="alg1.l6.m1.1.1.3.2.3.2.3.cmml" xref="alg1.l6.m1.1.1.3.2.3.2.3">𝑘</ci></apply><apply id="alg1.l6.m1.1.1.3.2.3.3.cmml" xref="alg1.l6.m1.1.1.3.2.3.3"><plus id="alg1.l6.m1.1.1.3.2.3.3.1.cmml" xref="alg1.l6.m1.1.1.3.2.3.3.1"></plus><ci id="alg1.l6.m1.1.1.3.2.3.3.2.cmml" xref="alg1.l6.m1.1.1.3.2.3.3.2">𝑡</ci><cn type="integer" id="alg1.l6.m1.1.1.3.2.3.3.3.cmml" xref="alg1.l6.m1.1.1.3.2.3.3.3">1</cn></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l6.m1.1c">w_{t+1}\leftarrow\sum^{K}_{k=0}\frac{n_{k}}{n}w^{k}_{t+1}</annotation></semantics></math>

</div>
<div id="alg1.l7" class="ltx_listingline">     <span id="alg1.l7.1" class="ltx_text ltx_font_bold">If Diff on Top-K-Weight then</span> <math id="alg1.l7.m1.1" class="ltx_Math" alttext="w_{t+1}\leftarrow w_{t}+\sum^{K}_{k=0}\frac{n_{k}}{n}d^{k}_{t+1}" display="inline"><semantics id="alg1.l7.m1.1a"><mrow id="alg1.l7.m1.1.1" xref="alg1.l7.m1.1.1.cmml"><msub id="alg1.l7.m1.1.1.2" xref="alg1.l7.m1.1.1.2.cmml"><mi id="alg1.l7.m1.1.1.2.2" xref="alg1.l7.m1.1.1.2.2.cmml">w</mi><mrow id="alg1.l7.m1.1.1.2.3" xref="alg1.l7.m1.1.1.2.3.cmml"><mi id="alg1.l7.m1.1.1.2.3.2" xref="alg1.l7.m1.1.1.2.3.2.cmml">t</mi><mo id="alg1.l7.m1.1.1.2.3.1" xref="alg1.l7.m1.1.1.2.3.1.cmml">+</mo><mn id="alg1.l7.m1.1.1.2.3.3" xref="alg1.l7.m1.1.1.2.3.3.cmml">1</mn></mrow></msub><mo stretchy="false" id="alg1.l7.m1.1.1.1" xref="alg1.l7.m1.1.1.1.cmml">←</mo><mrow id="alg1.l7.m1.1.1.3" xref="alg1.l7.m1.1.1.3.cmml"><msub id="alg1.l7.m1.1.1.3.2" xref="alg1.l7.m1.1.1.3.2.cmml"><mi id="alg1.l7.m1.1.1.3.2.2" xref="alg1.l7.m1.1.1.3.2.2.cmml">w</mi><mi id="alg1.l7.m1.1.1.3.2.3" xref="alg1.l7.m1.1.1.3.2.3.cmml">t</mi></msub><mo rspace="0.055em" id="alg1.l7.m1.1.1.3.1" xref="alg1.l7.m1.1.1.3.1.cmml">+</mo><mrow id="alg1.l7.m1.1.1.3.3" xref="alg1.l7.m1.1.1.3.3.cmml"><msubsup id="alg1.l7.m1.1.1.3.3.1" xref="alg1.l7.m1.1.1.3.3.1.cmml"><mo id="alg1.l7.m1.1.1.3.3.1.2.2" xref="alg1.l7.m1.1.1.3.3.1.2.2.cmml">∑</mo><mrow id="alg1.l7.m1.1.1.3.3.1.3" xref="alg1.l7.m1.1.1.3.3.1.3.cmml"><mi id="alg1.l7.m1.1.1.3.3.1.3.2" xref="alg1.l7.m1.1.1.3.3.1.3.2.cmml">k</mi><mo id="alg1.l7.m1.1.1.3.3.1.3.1" xref="alg1.l7.m1.1.1.3.3.1.3.1.cmml">=</mo><mn id="alg1.l7.m1.1.1.3.3.1.3.3" xref="alg1.l7.m1.1.1.3.3.1.3.3.cmml">0</mn></mrow><mi id="alg1.l7.m1.1.1.3.3.1.2.3" xref="alg1.l7.m1.1.1.3.3.1.2.3.cmml">K</mi></msubsup><mrow id="alg1.l7.m1.1.1.3.3.2" xref="alg1.l7.m1.1.1.3.3.2.cmml"><mfrac id="alg1.l7.m1.1.1.3.3.2.2" xref="alg1.l7.m1.1.1.3.3.2.2.cmml"><msub id="alg1.l7.m1.1.1.3.3.2.2.2" xref="alg1.l7.m1.1.1.3.3.2.2.2.cmml"><mi id="alg1.l7.m1.1.1.3.3.2.2.2.2" xref="alg1.l7.m1.1.1.3.3.2.2.2.2.cmml">n</mi><mi id="alg1.l7.m1.1.1.3.3.2.2.2.3" xref="alg1.l7.m1.1.1.3.3.2.2.2.3.cmml">k</mi></msub><mi id="alg1.l7.m1.1.1.3.3.2.2.3" xref="alg1.l7.m1.1.1.3.3.2.2.3.cmml">n</mi></mfrac><mo lspace="0em" rspace="0em" id="alg1.l7.m1.1.1.3.3.2.1" xref="alg1.l7.m1.1.1.3.3.2.1.cmml">​</mo><msubsup id="alg1.l7.m1.1.1.3.3.2.3" xref="alg1.l7.m1.1.1.3.3.2.3.cmml"><mi id="alg1.l7.m1.1.1.3.3.2.3.2.2" xref="alg1.l7.m1.1.1.3.3.2.3.2.2.cmml">d</mi><mrow id="alg1.l7.m1.1.1.3.3.2.3.3" xref="alg1.l7.m1.1.1.3.3.2.3.3.cmml"><mi id="alg1.l7.m1.1.1.3.3.2.3.3.2" xref="alg1.l7.m1.1.1.3.3.2.3.3.2.cmml">t</mi><mo id="alg1.l7.m1.1.1.3.3.2.3.3.1" xref="alg1.l7.m1.1.1.3.3.2.3.3.1.cmml">+</mo><mn id="alg1.l7.m1.1.1.3.3.2.3.3.3" xref="alg1.l7.m1.1.1.3.3.2.3.3.3.cmml">1</mn></mrow><mi id="alg1.l7.m1.1.1.3.3.2.3.2.3" xref="alg1.l7.m1.1.1.3.3.2.3.2.3.cmml">k</mi></msubsup></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l7.m1.1b"><apply id="alg1.l7.m1.1.1.cmml" xref="alg1.l7.m1.1.1"><ci id="alg1.l7.m1.1.1.1.cmml" xref="alg1.l7.m1.1.1.1">←</ci><apply id="alg1.l7.m1.1.1.2.cmml" xref="alg1.l7.m1.1.1.2"><csymbol cd="ambiguous" id="alg1.l7.m1.1.1.2.1.cmml" xref="alg1.l7.m1.1.1.2">subscript</csymbol><ci id="alg1.l7.m1.1.1.2.2.cmml" xref="alg1.l7.m1.1.1.2.2">𝑤</ci><apply id="alg1.l7.m1.1.1.2.3.cmml" xref="alg1.l7.m1.1.1.2.3"><plus id="alg1.l7.m1.1.1.2.3.1.cmml" xref="alg1.l7.m1.1.1.2.3.1"></plus><ci id="alg1.l7.m1.1.1.2.3.2.cmml" xref="alg1.l7.m1.1.1.2.3.2">𝑡</ci><cn type="integer" id="alg1.l7.m1.1.1.2.3.3.cmml" xref="alg1.l7.m1.1.1.2.3.3">1</cn></apply></apply><apply id="alg1.l7.m1.1.1.3.cmml" xref="alg1.l7.m1.1.1.3"><plus id="alg1.l7.m1.1.1.3.1.cmml" xref="alg1.l7.m1.1.1.3.1"></plus><apply id="alg1.l7.m1.1.1.3.2.cmml" xref="alg1.l7.m1.1.1.3.2"><csymbol cd="ambiguous" id="alg1.l7.m1.1.1.3.2.1.cmml" xref="alg1.l7.m1.1.1.3.2">subscript</csymbol><ci id="alg1.l7.m1.1.1.3.2.2.cmml" xref="alg1.l7.m1.1.1.3.2.2">𝑤</ci><ci id="alg1.l7.m1.1.1.3.2.3.cmml" xref="alg1.l7.m1.1.1.3.2.3">𝑡</ci></apply><apply id="alg1.l7.m1.1.1.3.3.cmml" xref="alg1.l7.m1.1.1.3.3"><apply id="alg1.l7.m1.1.1.3.3.1.cmml" xref="alg1.l7.m1.1.1.3.3.1"><csymbol cd="ambiguous" id="alg1.l7.m1.1.1.3.3.1.1.cmml" xref="alg1.l7.m1.1.1.3.3.1">subscript</csymbol><apply id="alg1.l7.m1.1.1.3.3.1.2.cmml" xref="alg1.l7.m1.1.1.3.3.1"><csymbol cd="ambiguous" id="alg1.l7.m1.1.1.3.3.1.2.1.cmml" xref="alg1.l7.m1.1.1.3.3.1">superscript</csymbol><sum id="alg1.l7.m1.1.1.3.3.1.2.2.cmml" xref="alg1.l7.m1.1.1.3.3.1.2.2"></sum><ci id="alg1.l7.m1.1.1.3.3.1.2.3.cmml" xref="alg1.l7.m1.1.1.3.3.1.2.3">𝐾</ci></apply><apply id="alg1.l7.m1.1.1.3.3.1.3.cmml" xref="alg1.l7.m1.1.1.3.3.1.3"><eq id="alg1.l7.m1.1.1.3.3.1.3.1.cmml" xref="alg1.l7.m1.1.1.3.3.1.3.1"></eq><ci id="alg1.l7.m1.1.1.3.3.1.3.2.cmml" xref="alg1.l7.m1.1.1.3.3.1.3.2">𝑘</ci><cn type="integer" id="alg1.l7.m1.1.1.3.3.1.3.3.cmml" xref="alg1.l7.m1.1.1.3.3.1.3.3">0</cn></apply></apply><apply id="alg1.l7.m1.1.1.3.3.2.cmml" xref="alg1.l7.m1.1.1.3.3.2"><times id="alg1.l7.m1.1.1.3.3.2.1.cmml" xref="alg1.l7.m1.1.1.3.3.2.1"></times><apply id="alg1.l7.m1.1.1.3.3.2.2.cmml" xref="alg1.l7.m1.1.1.3.3.2.2"><divide id="alg1.l7.m1.1.1.3.3.2.2.1.cmml" xref="alg1.l7.m1.1.1.3.3.2.2"></divide><apply id="alg1.l7.m1.1.1.3.3.2.2.2.cmml" xref="alg1.l7.m1.1.1.3.3.2.2.2"><csymbol cd="ambiguous" id="alg1.l7.m1.1.1.3.3.2.2.2.1.cmml" xref="alg1.l7.m1.1.1.3.3.2.2.2">subscript</csymbol><ci id="alg1.l7.m1.1.1.3.3.2.2.2.2.cmml" xref="alg1.l7.m1.1.1.3.3.2.2.2.2">𝑛</ci><ci id="alg1.l7.m1.1.1.3.3.2.2.2.3.cmml" xref="alg1.l7.m1.1.1.3.3.2.2.2.3">𝑘</ci></apply><ci id="alg1.l7.m1.1.1.3.3.2.2.3.cmml" xref="alg1.l7.m1.1.1.3.3.2.2.3">𝑛</ci></apply><apply id="alg1.l7.m1.1.1.3.3.2.3.cmml" xref="alg1.l7.m1.1.1.3.3.2.3"><csymbol cd="ambiguous" id="alg1.l7.m1.1.1.3.3.2.3.1.cmml" xref="alg1.l7.m1.1.1.3.3.2.3">subscript</csymbol><apply id="alg1.l7.m1.1.1.3.3.2.3.2.cmml" xref="alg1.l7.m1.1.1.3.3.2.3"><csymbol cd="ambiguous" id="alg1.l7.m1.1.1.3.3.2.3.2.1.cmml" xref="alg1.l7.m1.1.1.3.3.2.3">superscript</csymbol><ci id="alg1.l7.m1.1.1.3.3.2.3.2.2.cmml" xref="alg1.l7.m1.1.1.3.3.2.3.2.2">𝑑</ci><ci id="alg1.l7.m1.1.1.3.3.2.3.2.3.cmml" xref="alg1.l7.m1.1.1.3.3.2.3.2.3">𝑘</ci></apply><apply id="alg1.l7.m1.1.1.3.3.2.3.3.cmml" xref="alg1.l7.m1.1.1.3.3.2.3.3"><plus id="alg1.l7.m1.1.1.3.3.2.3.3.1.cmml" xref="alg1.l7.m1.1.1.3.3.2.3.3.1"></plus><ci id="alg1.l7.m1.1.1.3.3.2.3.3.2.cmml" xref="alg1.l7.m1.1.1.3.3.2.3.3.2">𝑡</ci><cn type="integer" id="alg1.l7.m1.1.1.3.3.2.3.3.3.cmml" xref="alg1.l7.m1.1.1.3.3.2.3.3.3">1</cn></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l7.m1.1c">w_{t+1}\leftarrow w_{t}+\sum^{K}_{k=0}\frac{n_{k}}{n}d^{k}_{t+1}</annotation></semantics></math>

</div>
<div id="alg1.l8" class="ltx_listingline">     <span id="alg1.l8.1" class="ltx_text ltx_font_bold">If Top-K Diff then</span> <math id="alg1.l8.m1.1" class="ltx_Math" alttext="w_{t+1}\leftarrow w_{t}+\sum^{K}_{k=0}\frac{n_{k}}{n}d^{k}_{t+1}" display="inline"><semantics id="alg1.l8.m1.1a"><mrow id="alg1.l8.m1.1.1" xref="alg1.l8.m1.1.1.cmml"><msub id="alg1.l8.m1.1.1.2" xref="alg1.l8.m1.1.1.2.cmml"><mi id="alg1.l8.m1.1.1.2.2" xref="alg1.l8.m1.1.1.2.2.cmml">w</mi><mrow id="alg1.l8.m1.1.1.2.3" xref="alg1.l8.m1.1.1.2.3.cmml"><mi id="alg1.l8.m1.1.1.2.3.2" xref="alg1.l8.m1.1.1.2.3.2.cmml">t</mi><mo id="alg1.l8.m1.1.1.2.3.1" xref="alg1.l8.m1.1.1.2.3.1.cmml">+</mo><mn id="alg1.l8.m1.1.1.2.3.3" xref="alg1.l8.m1.1.1.2.3.3.cmml">1</mn></mrow></msub><mo stretchy="false" id="alg1.l8.m1.1.1.1" xref="alg1.l8.m1.1.1.1.cmml">←</mo><mrow id="alg1.l8.m1.1.1.3" xref="alg1.l8.m1.1.1.3.cmml"><msub id="alg1.l8.m1.1.1.3.2" xref="alg1.l8.m1.1.1.3.2.cmml"><mi id="alg1.l8.m1.1.1.3.2.2" xref="alg1.l8.m1.1.1.3.2.2.cmml">w</mi><mi id="alg1.l8.m1.1.1.3.2.3" xref="alg1.l8.m1.1.1.3.2.3.cmml">t</mi></msub><mo rspace="0.055em" id="alg1.l8.m1.1.1.3.1" xref="alg1.l8.m1.1.1.3.1.cmml">+</mo><mrow id="alg1.l8.m1.1.1.3.3" xref="alg1.l8.m1.1.1.3.3.cmml"><msubsup id="alg1.l8.m1.1.1.3.3.1" xref="alg1.l8.m1.1.1.3.3.1.cmml"><mo id="alg1.l8.m1.1.1.3.3.1.2.2" xref="alg1.l8.m1.1.1.3.3.1.2.2.cmml">∑</mo><mrow id="alg1.l8.m1.1.1.3.3.1.3" xref="alg1.l8.m1.1.1.3.3.1.3.cmml"><mi id="alg1.l8.m1.1.1.3.3.1.3.2" xref="alg1.l8.m1.1.1.3.3.1.3.2.cmml">k</mi><mo id="alg1.l8.m1.1.1.3.3.1.3.1" xref="alg1.l8.m1.1.1.3.3.1.3.1.cmml">=</mo><mn id="alg1.l8.m1.1.1.3.3.1.3.3" xref="alg1.l8.m1.1.1.3.3.1.3.3.cmml">0</mn></mrow><mi id="alg1.l8.m1.1.1.3.3.1.2.3" xref="alg1.l8.m1.1.1.3.3.1.2.3.cmml">K</mi></msubsup><mrow id="alg1.l8.m1.1.1.3.3.2" xref="alg1.l8.m1.1.1.3.3.2.cmml"><mfrac id="alg1.l8.m1.1.1.3.3.2.2" xref="alg1.l8.m1.1.1.3.3.2.2.cmml"><msub id="alg1.l8.m1.1.1.3.3.2.2.2" xref="alg1.l8.m1.1.1.3.3.2.2.2.cmml"><mi id="alg1.l8.m1.1.1.3.3.2.2.2.2" xref="alg1.l8.m1.1.1.3.3.2.2.2.2.cmml">n</mi><mi id="alg1.l8.m1.1.1.3.3.2.2.2.3" xref="alg1.l8.m1.1.1.3.3.2.2.2.3.cmml">k</mi></msub><mi id="alg1.l8.m1.1.1.3.3.2.2.3" xref="alg1.l8.m1.1.1.3.3.2.2.3.cmml">n</mi></mfrac><mo lspace="0em" rspace="0em" id="alg1.l8.m1.1.1.3.3.2.1" xref="alg1.l8.m1.1.1.3.3.2.1.cmml">​</mo><msubsup id="alg1.l8.m1.1.1.3.3.2.3" xref="alg1.l8.m1.1.1.3.3.2.3.cmml"><mi id="alg1.l8.m1.1.1.3.3.2.3.2.2" xref="alg1.l8.m1.1.1.3.3.2.3.2.2.cmml">d</mi><mrow id="alg1.l8.m1.1.1.3.3.2.3.3" xref="alg1.l8.m1.1.1.3.3.2.3.3.cmml"><mi id="alg1.l8.m1.1.1.3.3.2.3.3.2" xref="alg1.l8.m1.1.1.3.3.2.3.3.2.cmml">t</mi><mo id="alg1.l8.m1.1.1.3.3.2.3.3.1" xref="alg1.l8.m1.1.1.3.3.2.3.3.1.cmml">+</mo><mn id="alg1.l8.m1.1.1.3.3.2.3.3.3" xref="alg1.l8.m1.1.1.3.3.2.3.3.3.cmml">1</mn></mrow><mi id="alg1.l8.m1.1.1.3.3.2.3.2.3" xref="alg1.l8.m1.1.1.3.3.2.3.2.3.cmml">k</mi></msubsup></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l8.m1.1b"><apply id="alg1.l8.m1.1.1.cmml" xref="alg1.l8.m1.1.1"><ci id="alg1.l8.m1.1.1.1.cmml" xref="alg1.l8.m1.1.1.1">←</ci><apply id="alg1.l8.m1.1.1.2.cmml" xref="alg1.l8.m1.1.1.2"><csymbol cd="ambiguous" id="alg1.l8.m1.1.1.2.1.cmml" xref="alg1.l8.m1.1.1.2">subscript</csymbol><ci id="alg1.l8.m1.1.1.2.2.cmml" xref="alg1.l8.m1.1.1.2.2">𝑤</ci><apply id="alg1.l8.m1.1.1.2.3.cmml" xref="alg1.l8.m1.1.1.2.3"><plus id="alg1.l8.m1.1.1.2.3.1.cmml" xref="alg1.l8.m1.1.1.2.3.1"></plus><ci id="alg1.l8.m1.1.1.2.3.2.cmml" xref="alg1.l8.m1.1.1.2.3.2">𝑡</ci><cn type="integer" id="alg1.l8.m1.1.1.2.3.3.cmml" xref="alg1.l8.m1.1.1.2.3.3">1</cn></apply></apply><apply id="alg1.l8.m1.1.1.3.cmml" xref="alg1.l8.m1.1.1.3"><plus id="alg1.l8.m1.1.1.3.1.cmml" xref="alg1.l8.m1.1.1.3.1"></plus><apply id="alg1.l8.m1.1.1.3.2.cmml" xref="alg1.l8.m1.1.1.3.2"><csymbol cd="ambiguous" id="alg1.l8.m1.1.1.3.2.1.cmml" xref="alg1.l8.m1.1.1.3.2">subscript</csymbol><ci id="alg1.l8.m1.1.1.3.2.2.cmml" xref="alg1.l8.m1.1.1.3.2.2">𝑤</ci><ci id="alg1.l8.m1.1.1.3.2.3.cmml" xref="alg1.l8.m1.1.1.3.2.3">𝑡</ci></apply><apply id="alg1.l8.m1.1.1.3.3.cmml" xref="alg1.l8.m1.1.1.3.3"><apply id="alg1.l8.m1.1.1.3.3.1.cmml" xref="alg1.l8.m1.1.1.3.3.1"><csymbol cd="ambiguous" id="alg1.l8.m1.1.1.3.3.1.1.cmml" xref="alg1.l8.m1.1.1.3.3.1">subscript</csymbol><apply id="alg1.l8.m1.1.1.3.3.1.2.cmml" xref="alg1.l8.m1.1.1.3.3.1"><csymbol cd="ambiguous" id="alg1.l8.m1.1.1.3.3.1.2.1.cmml" xref="alg1.l8.m1.1.1.3.3.1">superscript</csymbol><sum id="alg1.l8.m1.1.1.3.3.1.2.2.cmml" xref="alg1.l8.m1.1.1.3.3.1.2.2"></sum><ci id="alg1.l8.m1.1.1.3.3.1.2.3.cmml" xref="alg1.l8.m1.1.1.3.3.1.2.3">𝐾</ci></apply><apply id="alg1.l8.m1.1.1.3.3.1.3.cmml" xref="alg1.l8.m1.1.1.3.3.1.3"><eq id="alg1.l8.m1.1.1.3.3.1.3.1.cmml" xref="alg1.l8.m1.1.1.3.3.1.3.1"></eq><ci id="alg1.l8.m1.1.1.3.3.1.3.2.cmml" xref="alg1.l8.m1.1.1.3.3.1.3.2">𝑘</ci><cn type="integer" id="alg1.l8.m1.1.1.3.3.1.3.3.cmml" xref="alg1.l8.m1.1.1.3.3.1.3.3">0</cn></apply></apply><apply id="alg1.l8.m1.1.1.3.3.2.cmml" xref="alg1.l8.m1.1.1.3.3.2"><times id="alg1.l8.m1.1.1.3.3.2.1.cmml" xref="alg1.l8.m1.1.1.3.3.2.1"></times><apply id="alg1.l8.m1.1.1.3.3.2.2.cmml" xref="alg1.l8.m1.1.1.3.3.2.2"><divide id="alg1.l8.m1.1.1.3.3.2.2.1.cmml" xref="alg1.l8.m1.1.1.3.3.2.2"></divide><apply id="alg1.l8.m1.1.1.3.3.2.2.2.cmml" xref="alg1.l8.m1.1.1.3.3.2.2.2"><csymbol cd="ambiguous" id="alg1.l8.m1.1.1.3.3.2.2.2.1.cmml" xref="alg1.l8.m1.1.1.3.3.2.2.2">subscript</csymbol><ci id="alg1.l8.m1.1.1.3.3.2.2.2.2.cmml" xref="alg1.l8.m1.1.1.3.3.2.2.2.2">𝑛</ci><ci id="alg1.l8.m1.1.1.3.3.2.2.2.3.cmml" xref="alg1.l8.m1.1.1.3.3.2.2.2.3">𝑘</ci></apply><ci id="alg1.l8.m1.1.1.3.3.2.2.3.cmml" xref="alg1.l8.m1.1.1.3.3.2.2.3">𝑛</ci></apply><apply id="alg1.l8.m1.1.1.3.3.2.3.cmml" xref="alg1.l8.m1.1.1.3.3.2.3"><csymbol cd="ambiguous" id="alg1.l8.m1.1.1.3.3.2.3.1.cmml" xref="alg1.l8.m1.1.1.3.3.2.3">subscript</csymbol><apply id="alg1.l8.m1.1.1.3.3.2.3.2.cmml" xref="alg1.l8.m1.1.1.3.3.2.3"><csymbol cd="ambiguous" id="alg1.l8.m1.1.1.3.3.2.3.2.1.cmml" xref="alg1.l8.m1.1.1.3.3.2.3">superscript</csymbol><ci id="alg1.l8.m1.1.1.3.3.2.3.2.2.cmml" xref="alg1.l8.m1.1.1.3.3.2.3.2.2">𝑑</ci><ci id="alg1.l8.m1.1.1.3.3.2.3.2.3.cmml" xref="alg1.l8.m1.1.1.3.3.2.3.2.3">𝑘</ci></apply><apply id="alg1.l8.m1.1.1.3.3.2.3.3.cmml" xref="alg1.l8.m1.1.1.3.3.2.3.3"><plus id="alg1.l8.m1.1.1.3.3.2.3.3.1.cmml" xref="alg1.l8.m1.1.1.3.3.2.3.3.1"></plus><ci id="alg1.l8.m1.1.1.3.3.2.3.3.2.cmml" xref="alg1.l8.m1.1.1.3.3.2.3.3.2">𝑡</ci><cn type="integer" id="alg1.l8.m1.1.1.3.3.2.3.3.3.cmml" xref="alg1.l8.m1.1.1.3.3.2.3.3.3">1</cn></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l8.m1.1c">w_{t+1}\leftarrow w_{t}+\sum^{K}_{k=0}\frac{n_{k}}{n}d^{k}_{t+1}</annotation></semantics></math>

</div>
</div>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p id="alg1.23" class="ltx_p ltx_figure_panel"><span id="alg1.23.1" class="ltx_text ltx_font_bold">TrainLocally<math id="alg1.23.1.m1.2" class="ltx_Math" alttext="(k,w_{t})" display="inline"><semantics id="alg1.23.1.m1.2a"><mrow id="alg1.23.1.m1.2.2.1" xref="alg1.23.1.m1.2.2.2.cmml"><mo stretchy="false" id="alg1.23.1.m1.2.2.1.2" xref="alg1.23.1.m1.2.2.2.cmml">(</mo><mi id="alg1.23.1.m1.1.1" xref="alg1.23.1.m1.1.1.cmml">k</mi><mo id="alg1.23.1.m1.2.2.1.3" xref="alg1.23.1.m1.2.2.2.cmml">,</mo><msub id="alg1.23.1.m1.2.2.1.1" xref="alg1.23.1.m1.2.2.1.1.cmml"><mi id="alg1.23.1.m1.2.2.1.1.2" xref="alg1.23.1.m1.2.2.1.1.2.cmml">w</mi><mi id="alg1.23.1.m1.2.2.1.1.3" xref="alg1.23.1.m1.2.2.1.1.3.cmml">t</mi></msub><mo stretchy="false" id="alg1.23.1.m1.2.2.1.4" xref="alg1.23.1.m1.2.2.2.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="alg1.23.1.m1.2b"><interval closure="open" id="alg1.23.1.m1.2.2.2.cmml" xref="alg1.23.1.m1.2.2.1"><ci id="alg1.23.1.m1.1.1.cmml" xref="alg1.23.1.m1.1.1">𝑘</ci><apply id="alg1.23.1.m1.2.2.1.1.cmml" xref="alg1.23.1.m1.2.2.1.1"><csymbol cd="ambiguous" id="alg1.23.1.m1.2.2.1.1.1.cmml" xref="alg1.23.1.m1.2.2.1.1">subscript</csymbol><ci id="alg1.23.1.m1.2.2.1.1.2.cmml" xref="alg1.23.1.m1.2.2.1.1.2">𝑤</ci><ci id="alg1.23.1.m1.2.2.1.1.3.cmml" xref="alg1.23.1.m1.2.2.1.1.3">𝑡</ci></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="alg1.23.1.m1.2c">(k,w_{t})</annotation></semantics></math>:</span></p>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<div id="alg1.30" class="ltx_listing ltx_figure_panel ltx_listing">
<div id="alg1.l1a" class="ltx_listingline">
<span id="alg1.l1a.1" class="ltx_text ltx_font_bold">for</span> <math id="alg1.l1a.m1.3" class="ltx_Math" alttext="e=1,...,E" display="inline"><semantics id="alg1.l1a.m1.3a"><mrow id="alg1.l1a.m1.3.4" xref="alg1.l1a.m1.3.4.cmml"><mi id="alg1.l1a.m1.3.4.2" xref="alg1.l1a.m1.3.4.2.cmml">e</mi><mo id="alg1.l1a.m1.3.4.1" xref="alg1.l1a.m1.3.4.1.cmml">=</mo><mrow id="alg1.l1a.m1.3.4.3.2" xref="alg1.l1a.m1.3.4.3.1.cmml"><mn id="alg1.l1a.m1.1.1" xref="alg1.l1a.m1.1.1.cmml">1</mn><mo id="alg1.l1a.m1.3.4.3.2.1" xref="alg1.l1a.m1.3.4.3.1.cmml">,</mo><mi mathvariant="normal" id="alg1.l1a.m1.2.2" xref="alg1.l1a.m1.2.2.cmml">…</mi><mo id="alg1.l1a.m1.3.4.3.2.2" xref="alg1.l1a.m1.3.4.3.1.cmml">,</mo><mi id="alg1.l1a.m1.3.3" xref="alg1.l1a.m1.3.3.cmml">E</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l1a.m1.3b"><apply id="alg1.l1a.m1.3.4.cmml" xref="alg1.l1a.m1.3.4"><eq id="alg1.l1a.m1.3.4.1.cmml" xref="alg1.l1a.m1.3.4.1"></eq><ci id="alg1.l1a.m1.3.4.2.cmml" xref="alg1.l1a.m1.3.4.2">𝑒</ci><list id="alg1.l1a.m1.3.4.3.1.cmml" xref="alg1.l1a.m1.3.4.3.2"><cn type="integer" id="alg1.l1a.m1.1.1.cmml" xref="alg1.l1a.m1.1.1">1</cn><ci id="alg1.l1a.m1.2.2.cmml" xref="alg1.l1a.m1.2.2">…</ci><ci id="alg1.l1a.m1.3.3.cmml" xref="alg1.l1a.m1.3.3">𝐸</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l1a.m1.3c">e=1,...,E</annotation></semantics></math> <span id="alg1.l1a.2" class="ltx_text ltx_font_bold">do</span>

</div>
<div id="alg1.l2a" class="ltx_listingline">     Do local model training via SWAT with sparsity level <math id="alg1.l2a.m1.1" class="ltx_Math" alttext="sp" display="inline"><semantics id="alg1.l2a.m1.1a"><mrow id="alg1.l2a.m1.1.1" xref="alg1.l2a.m1.1.1.cmml"><mi id="alg1.l2a.m1.1.1.2" xref="alg1.l2a.m1.1.1.2.cmml">s</mi><mo lspace="0em" rspace="0em" id="alg1.l2a.m1.1.1.1" xref="alg1.l2a.m1.1.1.1.cmml">​</mo><mi id="alg1.l2a.m1.1.1.3" xref="alg1.l2a.m1.1.1.3.cmml">p</mi></mrow><annotation-xml encoding="MathML-Content" id="alg1.l2a.m1.1b"><apply id="alg1.l2a.m1.1.1.cmml" xref="alg1.l2a.m1.1.1"><times id="alg1.l2a.m1.1.1.1.cmml" xref="alg1.l2a.m1.1.1.1"></times><ci id="alg1.l2a.m1.1.1.2.cmml" xref="alg1.l2a.m1.1.1.2">𝑠</ci><ci id="alg1.l2a.m1.1.1.3.cmml" xref="alg1.l2a.m1.1.1.3">𝑝</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l2a.m1.1c">sp</annotation></semantics></math>.

</div>
<div id="alg1.l3a" class="ltx_listingline">     <math id="alg1.l3a.m1.1" class="ltx_Math" alttext="w_{e}\leftarrow w_{e-1}-\eta_{t}\bigtriangledown F(w_{e-1})" display="inline"><semantics id="alg1.l3a.m1.1a"><mrow id="alg1.l3a.m1.1.1" xref="alg1.l3a.m1.1.1.cmml"><msub id="alg1.l3a.m1.1.1.3" xref="alg1.l3a.m1.1.1.3.cmml"><mi id="alg1.l3a.m1.1.1.3.2" xref="alg1.l3a.m1.1.1.3.2.cmml">w</mi><mi id="alg1.l3a.m1.1.1.3.3" xref="alg1.l3a.m1.1.1.3.3.cmml">e</mi></msub><mo stretchy="false" id="alg1.l3a.m1.1.1.2" xref="alg1.l3a.m1.1.1.2.cmml">←</mo><mrow id="alg1.l3a.m1.1.1.1" xref="alg1.l3a.m1.1.1.1.cmml"><mrow id="alg1.l3a.m1.1.1.1.3" xref="alg1.l3a.m1.1.1.1.3.cmml"><msub id="alg1.l3a.m1.1.1.1.3.2" xref="alg1.l3a.m1.1.1.1.3.2.cmml"><mi id="alg1.l3a.m1.1.1.1.3.2.2" xref="alg1.l3a.m1.1.1.1.3.2.2.cmml">w</mi><mrow id="alg1.l3a.m1.1.1.1.3.2.3" xref="alg1.l3a.m1.1.1.1.3.2.3.cmml"><mi id="alg1.l3a.m1.1.1.1.3.2.3.2" xref="alg1.l3a.m1.1.1.1.3.2.3.2.cmml">e</mi><mo id="alg1.l3a.m1.1.1.1.3.2.3.1" xref="alg1.l3a.m1.1.1.1.3.2.3.1.cmml">−</mo><mn id="alg1.l3a.m1.1.1.1.3.2.3.3" xref="alg1.l3a.m1.1.1.1.3.2.3.3.cmml">1</mn></mrow></msub><mo id="alg1.l3a.m1.1.1.1.3.1" xref="alg1.l3a.m1.1.1.1.3.1.cmml">−</mo><msub id="alg1.l3a.m1.1.1.1.3.3" xref="alg1.l3a.m1.1.1.1.3.3.cmml"><mi id="alg1.l3a.m1.1.1.1.3.3.2" xref="alg1.l3a.m1.1.1.1.3.3.2.cmml">η</mi><mi id="alg1.l3a.m1.1.1.1.3.3.3" xref="alg1.l3a.m1.1.1.1.3.3.3.cmml">t</mi></msub></mrow><mo lspace="0.222em" rspace="0.222em" id="alg1.l3a.m1.1.1.1.2" xref="alg1.l3a.m1.1.1.1.2.cmml">▽</mo><mrow id="alg1.l3a.m1.1.1.1.1" xref="alg1.l3a.m1.1.1.1.1.cmml"><mi id="alg1.l3a.m1.1.1.1.1.3" xref="alg1.l3a.m1.1.1.1.1.3.cmml">F</mi><mo lspace="0em" rspace="0em" id="alg1.l3a.m1.1.1.1.1.2" xref="alg1.l3a.m1.1.1.1.1.2.cmml">​</mo><mrow id="alg1.l3a.m1.1.1.1.1.1.1" xref="alg1.l3a.m1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="alg1.l3a.m1.1.1.1.1.1.1.2" xref="alg1.l3a.m1.1.1.1.1.1.1.1.cmml">(</mo><msub id="alg1.l3a.m1.1.1.1.1.1.1.1" xref="alg1.l3a.m1.1.1.1.1.1.1.1.cmml"><mi id="alg1.l3a.m1.1.1.1.1.1.1.1.2" xref="alg1.l3a.m1.1.1.1.1.1.1.1.2.cmml">w</mi><mrow id="alg1.l3a.m1.1.1.1.1.1.1.1.3" xref="alg1.l3a.m1.1.1.1.1.1.1.1.3.cmml"><mi id="alg1.l3a.m1.1.1.1.1.1.1.1.3.2" xref="alg1.l3a.m1.1.1.1.1.1.1.1.3.2.cmml">e</mi><mo id="alg1.l3a.m1.1.1.1.1.1.1.1.3.1" xref="alg1.l3a.m1.1.1.1.1.1.1.1.3.1.cmml">−</mo><mn id="alg1.l3a.m1.1.1.1.1.1.1.1.3.3" xref="alg1.l3a.m1.1.1.1.1.1.1.1.3.3.cmml">1</mn></mrow></msub><mo stretchy="false" id="alg1.l3a.m1.1.1.1.1.1.1.3" xref="alg1.l3a.m1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l3a.m1.1b"><apply id="alg1.l3a.m1.1.1.cmml" xref="alg1.l3a.m1.1.1"><ci id="alg1.l3a.m1.1.1.2.cmml" xref="alg1.l3a.m1.1.1.2">←</ci><apply id="alg1.l3a.m1.1.1.3.cmml" xref="alg1.l3a.m1.1.1.3"><csymbol cd="ambiguous" id="alg1.l3a.m1.1.1.3.1.cmml" xref="alg1.l3a.m1.1.1.3">subscript</csymbol><ci id="alg1.l3a.m1.1.1.3.2.cmml" xref="alg1.l3a.m1.1.1.3.2">𝑤</ci><ci id="alg1.l3a.m1.1.1.3.3.cmml" xref="alg1.l3a.m1.1.1.3.3">𝑒</ci></apply><apply id="alg1.l3a.m1.1.1.1.cmml" xref="alg1.l3a.m1.1.1.1"><ci id="alg1.l3a.m1.1.1.1.2.cmml" xref="alg1.l3a.m1.1.1.1.2">▽</ci><apply id="alg1.l3a.m1.1.1.1.3.cmml" xref="alg1.l3a.m1.1.1.1.3"><minus id="alg1.l3a.m1.1.1.1.3.1.cmml" xref="alg1.l3a.m1.1.1.1.3.1"></minus><apply id="alg1.l3a.m1.1.1.1.3.2.cmml" xref="alg1.l3a.m1.1.1.1.3.2"><csymbol cd="ambiguous" id="alg1.l3a.m1.1.1.1.3.2.1.cmml" xref="alg1.l3a.m1.1.1.1.3.2">subscript</csymbol><ci id="alg1.l3a.m1.1.1.1.3.2.2.cmml" xref="alg1.l3a.m1.1.1.1.3.2.2">𝑤</ci><apply id="alg1.l3a.m1.1.1.1.3.2.3.cmml" xref="alg1.l3a.m1.1.1.1.3.2.3"><minus id="alg1.l3a.m1.1.1.1.3.2.3.1.cmml" xref="alg1.l3a.m1.1.1.1.3.2.3.1"></minus><ci id="alg1.l3a.m1.1.1.1.3.2.3.2.cmml" xref="alg1.l3a.m1.1.1.1.3.2.3.2">𝑒</ci><cn type="integer" id="alg1.l3a.m1.1.1.1.3.2.3.3.cmml" xref="alg1.l3a.m1.1.1.1.3.2.3.3">1</cn></apply></apply><apply id="alg1.l3a.m1.1.1.1.3.3.cmml" xref="alg1.l3a.m1.1.1.1.3.3"><csymbol cd="ambiguous" id="alg1.l3a.m1.1.1.1.3.3.1.cmml" xref="alg1.l3a.m1.1.1.1.3.3">subscript</csymbol><ci id="alg1.l3a.m1.1.1.1.3.3.2.cmml" xref="alg1.l3a.m1.1.1.1.3.3.2">𝜂</ci><ci id="alg1.l3a.m1.1.1.1.3.3.3.cmml" xref="alg1.l3a.m1.1.1.1.3.3.3">𝑡</ci></apply></apply><apply id="alg1.l3a.m1.1.1.1.1.cmml" xref="alg1.l3a.m1.1.1.1.1"><times id="alg1.l3a.m1.1.1.1.1.2.cmml" xref="alg1.l3a.m1.1.1.1.1.2"></times><ci id="alg1.l3a.m1.1.1.1.1.3.cmml" xref="alg1.l3a.m1.1.1.1.1.3">𝐹</ci><apply id="alg1.l3a.m1.1.1.1.1.1.1.1.cmml" xref="alg1.l3a.m1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="alg1.l3a.m1.1.1.1.1.1.1.1.1.cmml" xref="alg1.l3a.m1.1.1.1.1.1.1">subscript</csymbol><ci id="alg1.l3a.m1.1.1.1.1.1.1.1.2.cmml" xref="alg1.l3a.m1.1.1.1.1.1.1.1.2">𝑤</ci><apply id="alg1.l3a.m1.1.1.1.1.1.1.1.3.cmml" xref="alg1.l3a.m1.1.1.1.1.1.1.1.3"><minus id="alg1.l3a.m1.1.1.1.1.1.1.1.3.1.cmml" xref="alg1.l3a.m1.1.1.1.1.1.1.1.3.1"></minus><ci id="alg1.l3a.m1.1.1.1.1.1.1.1.3.2.cmml" xref="alg1.l3a.m1.1.1.1.1.1.1.1.3.2">𝑒</ci><cn type="integer" id="alg1.l3a.m1.1.1.1.1.1.1.1.3.3.cmml" xref="alg1.l3a.m1.1.1.1.1.1.1.1.3.3">1</cn></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l3a.m1.1c">w_{e}\leftarrow w_{e-1}-\eta_{t}\bigtriangledown F(w_{e-1})</annotation></semantics></math>

</div>
<div id="alg1.l4a" class="ltx_listingline">
<span id="alg1.l4a.1" class="ltx_text ltx_font_bold"> Determine which weights to send for aggregation:</span>

</div>
<div id="alg1.l5a" class="ltx_listingline">      <span id="alg1.l5a.1" class="ltx_text ltx_font_bold">If Top-K-Weight then return </span> top <math id="alg1.l5a.m1.1" class="ltx_Math" alttext="1-sp+r_{mask}" display="inline"><semantics id="alg1.l5a.m1.1a"><mrow id="alg1.l5a.m1.1.1" xref="alg1.l5a.m1.1.1.cmml"><mrow id="alg1.l5a.m1.1.1.2" xref="alg1.l5a.m1.1.1.2.cmml"><mn id="alg1.l5a.m1.1.1.2.2" xref="alg1.l5a.m1.1.1.2.2.cmml">1</mn><mo id="alg1.l5a.m1.1.1.2.1" xref="alg1.l5a.m1.1.1.2.1.cmml">−</mo><mrow id="alg1.l5a.m1.1.1.2.3" xref="alg1.l5a.m1.1.1.2.3.cmml"><mi id="alg1.l5a.m1.1.1.2.3.2" xref="alg1.l5a.m1.1.1.2.3.2.cmml">s</mi><mo lspace="0em" rspace="0em" id="alg1.l5a.m1.1.1.2.3.1" xref="alg1.l5a.m1.1.1.2.3.1.cmml">​</mo><mi id="alg1.l5a.m1.1.1.2.3.3" xref="alg1.l5a.m1.1.1.2.3.3.cmml">p</mi></mrow></mrow><mo id="alg1.l5a.m1.1.1.1" xref="alg1.l5a.m1.1.1.1.cmml">+</mo><msub id="alg1.l5a.m1.1.1.3" xref="alg1.l5a.m1.1.1.3.cmml"><mi id="alg1.l5a.m1.1.1.3.2" xref="alg1.l5a.m1.1.1.3.2.cmml">r</mi><mrow id="alg1.l5a.m1.1.1.3.3" xref="alg1.l5a.m1.1.1.3.3.cmml"><mi id="alg1.l5a.m1.1.1.3.3.2" xref="alg1.l5a.m1.1.1.3.3.2.cmml">m</mi><mo lspace="0em" rspace="0em" id="alg1.l5a.m1.1.1.3.3.1" xref="alg1.l5a.m1.1.1.3.3.1.cmml">​</mo><mi id="alg1.l5a.m1.1.1.3.3.3" xref="alg1.l5a.m1.1.1.3.3.3.cmml">a</mi><mo lspace="0em" rspace="0em" id="alg1.l5a.m1.1.1.3.3.1a" xref="alg1.l5a.m1.1.1.3.3.1.cmml">​</mo><mi id="alg1.l5a.m1.1.1.3.3.4" xref="alg1.l5a.m1.1.1.3.3.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="alg1.l5a.m1.1.1.3.3.1b" xref="alg1.l5a.m1.1.1.3.3.1.cmml">​</mo><mi id="alg1.l5a.m1.1.1.3.3.5" xref="alg1.l5a.m1.1.1.3.3.5.cmml">k</mi></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="alg1.l5a.m1.1b"><apply id="alg1.l5a.m1.1.1.cmml" xref="alg1.l5a.m1.1.1"><plus id="alg1.l5a.m1.1.1.1.cmml" xref="alg1.l5a.m1.1.1.1"></plus><apply id="alg1.l5a.m1.1.1.2.cmml" xref="alg1.l5a.m1.1.1.2"><minus id="alg1.l5a.m1.1.1.2.1.cmml" xref="alg1.l5a.m1.1.1.2.1"></minus><cn type="integer" id="alg1.l5a.m1.1.1.2.2.cmml" xref="alg1.l5a.m1.1.1.2.2">1</cn><apply id="alg1.l5a.m1.1.1.2.3.cmml" xref="alg1.l5a.m1.1.1.2.3"><times id="alg1.l5a.m1.1.1.2.3.1.cmml" xref="alg1.l5a.m1.1.1.2.3.1"></times><ci id="alg1.l5a.m1.1.1.2.3.2.cmml" xref="alg1.l5a.m1.1.1.2.3.2">𝑠</ci><ci id="alg1.l5a.m1.1.1.2.3.3.cmml" xref="alg1.l5a.m1.1.1.2.3.3">𝑝</ci></apply></apply><apply id="alg1.l5a.m1.1.1.3.cmml" xref="alg1.l5a.m1.1.1.3"><csymbol cd="ambiguous" id="alg1.l5a.m1.1.1.3.1.cmml" xref="alg1.l5a.m1.1.1.3">subscript</csymbol><ci id="alg1.l5a.m1.1.1.3.2.cmml" xref="alg1.l5a.m1.1.1.3.2">𝑟</ci><apply id="alg1.l5a.m1.1.1.3.3.cmml" xref="alg1.l5a.m1.1.1.3.3"><times id="alg1.l5a.m1.1.1.3.3.1.cmml" xref="alg1.l5a.m1.1.1.3.3.1"></times><ci id="alg1.l5a.m1.1.1.3.3.2.cmml" xref="alg1.l5a.m1.1.1.3.3.2">𝑚</ci><ci id="alg1.l5a.m1.1.1.3.3.3.cmml" xref="alg1.l5a.m1.1.1.3.3.3">𝑎</ci><ci id="alg1.l5a.m1.1.1.3.3.4.cmml" xref="alg1.l5a.m1.1.1.3.3.4">𝑠</ci><ci id="alg1.l5a.m1.1.1.3.3.5.cmml" xref="alg1.l5a.m1.1.1.3.3.5">𝑘</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l5a.m1.1c">1-sp+r_{mask}</annotation></semantics></math> weights.

</div>
<div id="alg1.l6a" class="ltx_listingline">     <math id="alg1.l6a.m1.1" class="ltx_Math" alttext="d_{t+1}^{k}\leftarrow w_{E}-w_{t}" display="inline"><semantics id="alg1.l6a.m1.1a"><mrow id="alg1.l6a.m1.1.1" xref="alg1.l6a.m1.1.1.cmml"><msubsup id="alg1.l6a.m1.1.1.2" xref="alg1.l6a.m1.1.1.2.cmml"><mi id="alg1.l6a.m1.1.1.2.2.2" xref="alg1.l6a.m1.1.1.2.2.2.cmml">d</mi><mrow id="alg1.l6a.m1.1.1.2.2.3" xref="alg1.l6a.m1.1.1.2.2.3.cmml"><mi id="alg1.l6a.m1.1.1.2.2.3.2" xref="alg1.l6a.m1.1.1.2.2.3.2.cmml">t</mi><mo id="alg1.l6a.m1.1.1.2.2.3.1" xref="alg1.l6a.m1.1.1.2.2.3.1.cmml">+</mo><mn id="alg1.l6a.m1.1.1.2.2.3.3" xref="alg1.l6a.m1.1.1.2.2.3.3.cmml">1</mn></mrow><mi id="alg1.l6a.m1.1.1.2.3" xref="alg1.l6a.m1.1.1.2.3.cmml">k</mi></msubsup><mo stretchy="false" id="alg1.l6a.m1.1.1.1" xref="alg1.l6a.m1.1.1.1.cmml">←</mo><mrow id="alg1.l6a.m1.1.1.3" xref="alg1.l6a.m1.1.1.3.cmml"><msub id="alg1.l6a.m1.1.1.3.2" xref="alg1.l6a.m1.1.1.3.2.cmml"><mi id="alg1.l6a.m1.1.1.3.2.2" xref="alg1.l6a.m1.1.1.3.2.2.cmml">w</mi><mi id="alg1.l6a.m1.1.1.3.2.3" xref="alg1.l6a.m1.1.1.3.2.3.cmml">E</mi></msub><mo id="alg1.l6a.m1.1.1.3.1" xref="alg1.l6a.m1.1.1.3.1.cmml">−</mo><msub id="alg1.l6a.m1.1.1.3.3" xref="alg1.l6a.m1.1.1.3.3.cmml"><mi id="alg1.l6a.m1.1.1.3.3.2" xref="alg1.l6a.m1.1.1.3.3.2.cmml">w</mi><mi id="alg1.l6a.m1.1.1.3.3.3" xref="alg1.l6a.m1.1.1.3.3.3.cmml">t</mi></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l6a.m1.1b"><apply id="alg1.l6a.m1.1.1.cmml" xref="alg1.l6a.m1.1.1"><ci id="alg1.l6a.m1.1.1.1.cmml" xref="alg1.l6a.m1.1.1.1">←</ci><apply id="alg1.l6a.m1.1.1.2.cmml" xref="alg1.l6a.m1.1.1.2"><csymbol cd="ambiguous" id="alg1.l6a.m1.1.1.2.1.cmml" xref="alg1.l6a.m1.1.1.2">superscript</csymbol><apply id="alg1.l6a.m1.1.1.2.2.cmml" xref="alg1.l6a.m1.1.1.2"><csymbol cd="ambiguous" id="alg1.l6a.m1.1.1.2.2.1.cmml" xref="alg1.l6a.m1.1.1.2">subscript</csymbol><ci id="alg1.l6a.m1.1.1.2.2.2.cmml" xref="alg1.l6a.m1.1.1.2.2.2">𝑑</ci><apply id="alg1.l6a.m1.1.1.2.2.3.cmml" xref="alg1.l6a.m1.1.1.2.2.3"><plus id="alg1.l6a.m1.1.1.2.2.3.1.cmml" xref="alg1.l6a.m1.1.1.2.2.3.1"></plus><ci id="alg1.l6a.m1.1.1.2.2.3.2.cmml" xref="alg1.l6a.m1.1.1.2.2.3.2">𝑡</ci><cn type="integer" id="alg1.l6a.m1.1.1.2.2.3.3.cmml" xref="alg1.l6a.m1.1.1.2.2.3.3">1</cn></apply></apply><ci id="alg1.l6a.m1.1.1.2.3.cmml" xref="alg1.l6a.m1.1.1.2.3">𝑘</ci></apply><apply id="alg1.l6a.m1.1.1.3.cmml" xref="alg1.l6a.m1.1.1.3"><minus id="alg1.l6a.m1.1.1.3.1.cmml" xref="alg1.l6a.m1.1.1.3.1"></minus><apply id="alg1.l6a.m1.1.1.3.2.cmml" xref="alg1.l6a.m1.1.1.3.2"><csymbol cd="ambiguous" id="alg1.l6a.m1.1.1.3.2.1.cmml" xref="alg1.l6a.m1.1.1.3.2">subscript</csymbol><ci id="alg1.l6a.m1.1.1.3.2.2.cmml" xref="alg1.l6a.m1.1.1.3.2.2">𝑤</ci><ci id="alg1.l6a.m1.1.1.3.2.3.cmml" xref="alg1.l6a.m1.1.1.3.2.3">𝐸</ci></apply><apply id="alg1.l6a.m1.1.1.3.3.cmml" xref="alg1.l6a.m1.1.1.3.3"><csymbol cd="ambiguous" id="alg1.l6a.m1.1.1.3.3.1.cmml" xref="alg1.l6a.m1.1.1.3.3">subscript</csymbol><ci id="alg1.l6a.m1.1.1.3.3.2.cmml" xref="alg1.l6a.m1.1.1.3.3.2">𝑤</ci><ci id="alg1.l6a.m1.1.1.3.3.3.cmml" xref="alg1.l6a.m1.1.1.3.3.3">𝑡</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l6a.m1.1c">d_{t+1}^{k}\leftarrow w_{E}-w_{t}</annotation></semantics></math>

</div>
<div id="alg1.l7a" class="ltx_listingline">     <span id="alg1.l7a.1" class="ltx_text ltx_font_bold">If Diff on Top-K-Weight then return</span> <math id="alg1.l7a.m1.1" class="ltx_Math" alttext="d_{t+1}^{k}" display="inline"><semantics id="alg1.l7a.m1.1a"><msubsup id="alg1.l7a.m1.1.1" xref="alg1.l7a.m1.1.1.cmml"><mi id="alg1.l7a.m1.1.1.2.2" xref="alg1.l7a.m1.1.1.2.2.cmml">d</mi><mrow id="alg1.l7a.m1.1.1.2.3" xref="alg1.l7a.m1.1.1.2.3.cmml"><mi id="alg1.l7a.m1.1.1.2.3.2" xref="alg1.l7a.m1.1.1.2.3.2.cmml">t</mi><mo id="alg1.l7a.m1.1.1.2.3.1" xref="alg1.l7a.m1.1.1.2.3.1.cmml">+</mo><mn id="alg1.l7a.m1.1.1.2.3.3" xref="alg1.l7a.m1.1.1.2.3.3.cmml">1</mn></mrow><mi id="alg1.l7a.m1.1.1.3" xref="alg1.l7a.m1.1.1.3.cmml">k</mi></msubsup><annotation-xml encoding="MathML-Content" id="alg1.l7a.m1.1b"><apply id="alg1.l7a.m1.1.1.cmml" xref="alg1.l7a.m1.1.1"><csymbol cd="ambiguous" id="alg1.l7a.m1.1.1.1.cmml" xref="alg1.l7a.m1.1.1">superscript</csymbol><apply id="alg1.l7a.m1.1.1.2.cmml" xref="alg1.l7a.m1.1.1"><csymbol cd="ambiguous" id="alg1.l7a.m1.1.1.2.1.cmml" xref="alg1.l7a.m1.1.1">subscript</csymbol><ci id="alg1.l7a.m1.1.1.2.2.cmml" xref="alg1.l7a.m1.1.1.2.2">𝑑</ci><apply id="alg1.l7a.m1.1.1.2.3.cmml" xref="alg1.l7a.m1.1.1.2.3"><plus id="alg1.l7a.m1.1.1.2.3.1.cmml" xref="alg1.l7a.m1.1.1.2.3.1"></plus><ci id="alg1.l7a.m1.1.1.2.3.2.cmml" xref="alg1.l7a.m1.1.1.2.3.2">𝑡</ci><cn type="integer" id="alg1.l7a.m1.1.1.2.3.3.cmml" xref="alg1.l7a.m1.1.1.2.3.3">1</cn></apply></apply><ci id="alg1.l7a.m1.1.1.3.cmml" xref="alg1.l7a.m1.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l7a.m1.1c">d_{t+1}^{k}</annotation></semantics></math> of top <math id="alg1.l7a.m2.1" class="ltx_Math" alttext="1-sp+r_{mask}" display="inline"><semantics id="alg1.l7a.m2.1a"><mrow id="alg1.l7a.m2.1.1" xref="alg1.l7a.m2.1.1.cmml"><mrow id="alg1.l7a.m2.1.1.2" xref="alg1.l7a.m2.1.1.2.cmml"><mn id="alg1.l7a.m2.1.1.2.2" xref="alg1.l7a.m2.1.1.2.2.cmml">1</mn><mo id="alg1.l7a.m2.1.1.2.1" xref="alg1.l7a.m2.1.1.2.1.cmml">−</mo><mrow id="alg1.l7a.m2.1.1.2.3" xref="alg1.l7a.m2.1.1.2.3.cmml"><mi id="alg1.l7a.m2.1.1.2.3.2" xref="alg1.l7a.m2.1.1.2.3.2.cmml">s</mi><mo lspace="0em" rspace="0em" id="alg1.l7a.m2.1.1.2.3.1" xref="alg1.l7a.m2.1.1.2.3.1.cmml">​</mo><mi id="alg1.l7a.m2.1.1.2.3.3" xref="alg1.l7a.m2.1.1.2.3.3.cmml">p</mi></mrow></mrow><mo id="alg1.l7a.m2.1.1.1" xref="alg1.l7a.m2.1.1.1.cmml">+</mo><msub id="alg1.l7a.m2.1.1.3" xref="alg1.l7a.m2.1.1.3.cmml"><mi id="alg1.l7a.m2.1.1.3.2" xref="alg1.l7a.m2.1.1.3.2.cmml">r</mi><mrow id="alg1.l7a.m2.1.1.3.3" xref="alg1.l7a.m2.1.1.3.3.cmml"><mi id="alg1.l7a.m2.1.1.3.3.2" xref="alg1.l7a.m2.1.1.3.3.2.cmml">m</mi><mo lspace="0em" rspace="0em" id="alg1.l7a.m2.1.1.3.3.1" xref="alg1.l7a.m2.1.1.3.3.1.cmml">​</mo><mi id="alg1.l7a.m2.1.1.3.3.3" xref="alg1.l7a.m2.1.1.3.3.3.cmml">a</mi><mo lspace="0em" rspace="0em" id="alg1.l7a.m2.1.1.3.3.1a" xref="alg1.l7a.m2.1.1.3.3.1.cmml">​</mo><mi id="alg1.l7a.m2.1.1.3.3.4" xref="alg1.l7a.m2.1.1.3.3.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="alg1.l7a.m2.1.1.3.3.1b" xref="alg1.l7a.m2.1.1.3.3.1.cmml">​</mo><mi id="alg1.l7a.m2.1.1.3.3.5" xref="alg1.l7a.m2.1.1.3.3.5.cmml">k</mi></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="alg1.l7a.m2.1b"><apply id="alg1.l7a.m2.1.1.cmml" xref="alg1.l7a.m2.1.1"><plus id="alg1.l7a.m2.1.1.1.cmml" xref="alg1.l7a.m2.1.1.1"></plus><apply id="alg1.l7a.m2.1.1.2.cmml" xref="alg1.l7a.m2.1.1.2"><minus id="alg1.l7a.m2.1.1.2.1.cmml" xref="alg1.l7a.m2.1.1.2.1"></minus><cn type="integer" id="alg1.l7a.m2.1.1.2.2.cmml" xref="alg1.l7a.m2.1.1.2.2">1</cn><apply id="alg1.l7a.m2.1.1.2.3.cmml" xref="alg1.l7a.m2.1.1.2.3"><times id="alg1.l7a.m2.1.1.2.3.1.cmml" xref="alg1.l7a.m2.1.1.2.3.1"></times><ci id="alg1.l7a.m2.1.1.2.3.2.cmml" xref="alg1.l7a.m2.1.1.2.3.2">𝑠</ci><ci id="alg1.l7a.m2.1.1.2.3.3.cmml" xref="alg1.l7a.m2.1.1.2.3.3">𝑝</ci></apply></apply><apply id="alg1.l7a.m2.1.1.3.cmml" xref="alg1.l7a.m2.1.1.3"><csymbol cd="ambiguous" id="alg1.l7a.m2.1.1.3.1.cmml" xref="alg1.l7a.m2.1.1.3">subscript</csymbol><ci id="alg1.l7a.m2.1.1.3.2.cmml" xref="alg1.l7a.m2.1.1.3.2">𝑟</ci><apply id="alg1.l7a.m2.1.1.3.3.cmml" xref="alg1.l7a.m2.1.1.3.3"><times id="alg1.l7a.m2.1.1.3.3.1.cmml" xref="alg1.l7a.m2.1.1.3.3.1"></times><ci id="alg1.l7a.m2.1.1.3.3.2.cmml" xref="alg1.l7a.m2.1.1.3.3.2">𝑚</ci><ci id="alg1.l7a.m2.1.1.3.3.3.cmml" xref="alg1.l7a.m2.1.1.3.3.3">𝑎</ci><ci id="alg1.l7a.m2.1.1.3.3.4.cmml" xref="alg1.l7a.m2.1.1.3.3.4">𝑠</ci><ci id="alg1.l7a.m2.1.1.3.3.5.cmml" xref="alg1.l7a.m2.1.1.3.3.5">𝑘</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l7a.m2.1c">1-sp+r_{mask}</annotation></semantics></math> weights.

</div>
<div id="alg1.l8a" class="ltx_listingline">      <span id="alg1.l8a.1" class="ltx_text ltx_font_bold">If Top-K-Weights Diff then return</span> top <math id="alg1.l8a.m1.1" class="ltx_Math" alttext="1-sp+r_{mask}" display="inline"><semantics id="alg1.l8a.m1.1a"><mrow id="alg1.l8a.m1.1.1" xref="alg1.l8a.m1.1.1.cmml"><mrow id="alg1.l8a.m1.1.1.2" xref="alg1.l8a.m1.1.1.2.cmml"><mn id="alg1.l8a.m1.1.1.2.2" xref="alg1.l8a.m1.1.1.2.2.cmml">1</mn><mo id="alg1.l8a.m1.1.1.2.1" xref="alg1.l8a.m1.1.1.2.1.cmml">−</mo><mrow id="alg1.l8a.m1.1.1.2.3" xref="alg1.l8a.m1.1.1.2.3.cmml"><mi id="alg1.l8a.m1.1.1.2.3.2" xref="alg1.l8a.m1.1.1.2.3.2.cmml">s</mi><mo lspace="0em" rspace="0em" id="alg1.l8a.m1.1.1.2.3.1" xref="alg1.l8a.m1.1.1.2.3.1.cmml">​</mo><mi id="alg1.l8a.m1.1.1.2.3.3" xref="alg1.l8a.m1.1.1.2.3.3.cmml">p</mi></mrow></mrow><mo id="alg1.l8a.m1.1.1.1" xref="alg1.l8a.m1.1.1.1.cmml">+</mo><msub id="alg1.l8a.m1.1.1.3" xref="alg1.l8a.m1.1.1.3.cmml"><mi id="alg1.l8a.m1.1.1.3.2" xref="alg1.l8a.m1.1.1.3.2.cmml">r</mi><mrow id="alg1.l8a.m1.1.1.3.3" xref="alg1.l8a.m1.1.1.3.3.cmml"><mi id="alg1.l8a.m1.1.1.3.3.2" xref="alg1.l8a.m1.1.1.3.3.2.cmml">m</mi><mo lspace="0em" rspace="0em" id="alg1.l8a.m1.1.1.3.3.1" xref="alg1.l8a.m1.1.1.3.3.1.cmml">​</mo><mi id="alg1.l8a.m1.1.1.3.3.3" xref="alg1.l8a.m1.1.1.3.3.3.cmml">a</mi><mo lspace="0em" rspace="0em" id="alg1.l8a.m1.1.1.3.3.1a" xref="alg1.l8a.m1.1.1.3.3.1.cmml">​</mo><mi id="alg1.l8a.m1.1.1.3.3.4" xref="alg1.l8a.m1.1.1.3.3.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="alg1.l8a.m1.1.1.3.3.1b" xref="alg1.l8a.m1.1.1.3.3.1.cmml">​</mo><mi id="alg1.l8a.m1.1.1.3.3.5" xref="alg1.l8a.m1.1.1.3.3.5.cmml">k</mi></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="alg1.l8a.m1.1b"><apply id="alg1.l8a.m1.1.1.cmml" xref="alg1.l8a.m1.1.1"><plus id="alg1.l8a.m1.1.1.1.cmml" xref="alg1.l8a.m1.1.1.1"></plus><apply id="alg1.l8a.m1.1.1.2.cmml" xref="alg1.l8a.m1.1.1.2"><minus id="alg1.l8a.m1.1.1.2.1.cmml" xref="alg1.l8a.m1.1.1.2.1"></minus><cn type="integer" id="alg1.l8a.m1.1.1.2.2.cmml" xref="alg1.l8a.m1.1.1.2.2">1</cn><apply id="alg1.l8a.m1.1.1.2.3.cmml" xref="alg1.l8a.m1.1.1.2.3"><times id="alg1.l8a.m1.1.1.2.3.1.cmml" xref="alg1.l8a.m1.1.1.2.3.1"></times><ci id="alg1.l8a.m1.1.1.2.3.2.cmml" xref="alg1.l8a.m1.1.1.2.3.2">𝑠</ci><ci id="alg1.l8a.m1.1.1.2.3.3.cmml" xref="alg1.l8a.m1.1.1.2.3.3">𝑝</ci></apply></apply><apply id="alg1.l8a.m1.1.1.3.cmml" xref="alg1.l8a.m1.1.1.3"><csymbol cd="ambiguous" id="alg1.l8a.m1.1.1.3.1.cmml" xref="alg1.l8a.m1.1.1.3">subscript</csymbol><ci id="alg1.l8a.m1.1.1.3.2.cmml" xref="alg1.l8a.m1.1.1.3.2">𝑟</ci><apply id="alg1.l8a.m1.1.1.3.3.cmml" xref="alg1.l8a.m1.1.1.3.3"><times id="alg1.l8a.m1.1.1.3.3.1.cmml" xref="alg1.l8a.m1.1.1.3.3.1"></times><ci id="alg1.l8a.m1.1.1.3.3.2.cmml" xref="alg1.l8a.m1.1.1.3.3.2">𝑚</ci><ci id="alg1.l8a.m1.1.1.3.3.3.cmml" xref="alg1.l8a.m1.1.1.3.3.3">𝑎</ci><ci id="alg1.l8a.m1.1.1.3.3.4.cmml" xref="alg1.l8a.m1.1.1.3.3.4">𝑠</ci><ci id="alg1.l8a.m1.1.1.3.3.5.cmml" xref="alg1.l8a.m1.1.1.3.3.5">𝑘</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l8a.m1.1c">1-sp+r_{mask}</annotation></semantics></math> of <math id="alg1.l8a.m2.1" class="ltx_Math" alttext="d_{t+1}^{k}" display="inline"><semantics id="alg1.l8a.m2.1a"><msubsup id="alg1.l8a.m2.1.1" xref="alg1.l8a.m2.1.1.cmml"><mi id="alg1.l8a.m2.1.1.2.2" xref="alg1.l8a.m2.1.1.2.2.cmml">d</mi><mrow id="alg1.l8a.m2.1.1.2.3" xref="alg1.l8a.m2.1.1.2.3.cmml"><mi id="alg1.l8a.m2.1.1.2.3.2" xref="alg1.l8a.m2.1.1.2.3.2.cmml">t</mi><mo id="alg1.l8a.m2.1.1.2.3.1" xref="alg1.l8a.m2.1.1.2.3.1.cmml">+</mo><mn id="alg1.l8a.m2.1.1.2.3.3" xref="alg1.l8a.m2.1.1.2.3.3.cmml">1</mn></mrow><mi id="alg1.l8a.m2.1.1.3" xref="alg1.l8a.m2.1.1.3.cmml">k</mi></msubsup><annotation-xml encoding="MathML-Content" id="alg1.l8a.m2.1b"><apply id="alg1.l8a.m2.1.1.cmml" xref="alg1.l8a.m2.1.1"><csymbol cd="ambiguous" id="alg1.l8a.m2.1.1.1.cmml" xref="alg1.l8a.m2.1.1">superscript</csymbol><apply id="alg1.l8a.m2.1.1.2.cmml" xref="alg1.l8a.m2.1.1"><csymbol cd="ambiguous" id="alg1.l8a.m2.1.1.2.1.cmml" xref="alg1.l8a.m2.1.1">subscript</csymbol><ci id="alg1.l8a.m2.1.1.2.2.cmml" xref="alg1.l8a.m2.1.1.2.2">𝑑</ci><apply id="alg1.l8a.m2.1.1.2.3.cmml" xref="alg1.l8a.m2.1.1.2.3"><plus id="alg1.l8a.m2.1.1.2.3.1.cmml" xref="alg1.l8a.m2.1.1.2.3.1"></plus><ci id="alg1.l8a.m2.1.1.2.3.2.cmml" xref="alg1.l8a.m2.1.1.2.3.2">𝑡</ci><cn type="integer" id="alg1.l8a.m2.1.1.2.3.3.cmml" xref="alg1.l8a.m2.1.1.2.3.3">1</cn></apply></apply><ci id="alg1.l8a.m2.1.1.3.cmml" xref="alg1.l8a.m2.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l8a.m2.1c">d_{t+1}^{k}</annotation></semantics></math>.

</div>
</div>
</div>
</div>
</figure>
<div id="S5.p2" class="ltx_para ltx_noindent">
<p id="S5.p2.1" class="ltx_p"><span id="S5.p2.1.1" class="ltx_text ltx_font_bold">Top-K-Weights.</span> As shown in Sec. <a href="#S4.SS3" title="4.3 Sparsification Effect Analysis ‣ 4 Sparse Training for Federated Learning ‣ ZeroFL: Efficient On-Device Training for Federated Learning with Local Sparsity" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.3</span></a>, only <span id="S5.p2.1.2" class="ltx_text ltx_font_typewriter">top-K</span> active weights are involved in the validation and inference stages, and an important part of these weights tend not to change during training. Therefore, the first local sparsification method is to sparsify the <span id="S5.p2.1.3" class="ltx_text ltx_font_typewriter">top-K</span> weights on the client-side before sending them back to the central server for aggregation. Then, and even though the positions of <span id="S5.p2.1.4" class="ltx_text ltx_font_typewriter">top-K</span> weights largely overlap between each clients, only sending exactly a number of weights corresponding to the sparsity level might be too restrictive and prevents natural variations in the weights. Hence, we introduce a parameter denoted as the mask ratio <math id="S5.p2.1.m1.1" class="ltx_Math" alttext="r_{mask}" display="inline"><semantics id="S5.p2.1.m1.1a"><msub id="S5.p2.1.m1.1.1" xref="S5.p2.1.m1.1.1.cmml"><mi id="S5.p2.1.m1.1.1.2" xref="S5.p2.1.m1.1.1.2.cmml">r</mi><mrow id="S5.p2.1.m1.1.1.3" xref="S5.p2.1.m1.1.1.3.cmml"><mi id="S5.p2.1.m1.1.1.3.2" xref="S5.p2.1.m1.1.1.3.2.cmml">m</mi><mo lspace="0em" rspace="0em" id="S5.p2.1.m1.1.1.3.1" xref="S5.p2.1.m1.1.1.3.1.cmml">​</mo><mi id="S5.p2.1.m1.1.1.3.3" xref="S5.p2.1.m1.1.1.3.3.cmml">a</mi><mo lspace="0em" rspace="0em" id="S5.p2.1.m1.1.1.3.1a" xref="S5.p2.1.m1.1.1.3.1.cmml">​</mo><mi id="S5.p2.1.m1.1.1.3.4" xref="S5.p2.1.m1.1.1.3.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S5.p2.1.m1.1.1.3.1b" xref="S5.p2.1.m1.1.1.3.1.cmml">​</mo><mi id="S5.p2.1.m1.1.1.3.5" xref="S5.p2.1.m1.1.1.3.5.cmml">k</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S5.p2.1.m1.1b"><apply id="S5.p2.1.m1.1.1.cmml" xref="S5.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S5.p2.1.m1.1.1.1.cmml" xref="S5.p2.1.m1.1.1">subscript</csymbol><ci id="S5.p2.1.m1.1.1.2.cmml" xref="S5.p2.1.m1.1.1.2">𝑟</ci><apply id="S5.p2.1.m1.1.1.3.cmml" xref="S5.p2.1.m1.1.1.3"><times id="S5.p2.1.m1.1.1.3.1.cmml" xref="S5.p2.1.m1.1.1.3.1"></times><ci id="S5.p2.1.m1.1.1.3.2.cmml" xref="S5.p2.1.m1.1.1.3.2">𝑚</ci><ci id="S5.p2.1.m1.1.1.3.3.cmml" xref="S5.p2.1.m1.1.1.3.3">𝑎</ci><ci id="S5.p2.1.m1.1.1.3.4.cmml" xref="S5.p2.1.m1.1.1.3.4">𝑠</ci><ci id="S5.p2.1.m1.1.1.3.5.cmml" xref="S5.p2.1.m1.1.1.3.5">𝑘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p2.1.m1.1c">r_{mask}</annotation></semantics></math>, indicating the additional amount of weights that the selected clients will choose to send to the server after the local training.</p>
</div>
<div id="S5.p3" class="ltx_para ltx_noindent">
<p id="S5.p3.6" class="ltx_p">Let <math id="S5.p3.1.m1.1" class="ltx_Math" alttext="sp" display="inline"><semantics id="S5.p3.1.m1.1a"><mrow id="S5.p3.1.m1.1.1" xref="S5.p3.1.m1.1.1.cmml"><mi id="S5.p3.1.m1.1.1.2" xref="S5.p3.1.m1.1.1.2.cmml">s</mi><mo lspace="0em" rspace="0em" id="S5.p3.1.m1.1.1.1" xref="S5.p3.1.m1.1.1.1.cmml">​</mo><mi id="S5.p3.1.m1.1.1.3" xref="S5.p3.1.m1.1.1.3.cmml">p</mi></mrow><annotation-xml encoding="MathML-Content" id="S5.p3.1.m1.1b"><apply id="S5.p3.1.m1.1.1.cmml" xref="S5.p3.1.m1.1.1"><times id="S5.p3.1.m1.1.1.1.cmml" xref="S5.p3.1.m1.1.1.1"></times><ci id="S5.p3.1.m1.1.1.2.cmml" xref="S5.p3.1.m1.1.1.2">𝑠</ci><ci id="S5.p3.1.m1.1.1.3.cmml" xref="S5.p3.1.m1.1.1.3">𝑝</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p3.1.m1.1c">sp</annotation></semantics></math> be the sparsity level of the local training. For instance, with <math id="S5.p3.2.m2.1" class="ltx_Math" alttext="sp=0.9" display="inline"><semantics id="S5.p3.2.m2.1a"><mrow id="S5.p3.2.m2.1.1" xref="S5.p3.2.m2.1.1.cmml"><mrow id="S5.p3.2.m2.1.1.2" xref="S5.p3.2.m2.1.1.2.cmml"><mi id="S5.p3.2.m2.1.1.2.2" xref="S5.p3.2.m2.1.1.2.2.cmml">s</mi><mo lspace="0em" rspace="0em" id="S5.p3.2.m2.1.1.2.1" xref="S5.p3.2.m2.1.1.2.1.cmml">​</mo><mi id="S5.p3.2.m2.1.1.2.3" xref="S5.p3.2.m2.1.1.2.3.cmml">p</mi></mrow><mo id="S5.p3.2.m2.1.1.1" xref="S5.p3.2.m2.1.1.1.cmml">=</mo><mn id="S5.p3.2.m2.1.1.3" xref="S5.p3.2.m2.1.1.3.cmml">0.9</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.p3.2.m2.1b"><apply id="S5.p3.2.m2.1.1.cmml" xref="S5.p3.2.m2.1.1"><eq id="S5.p3.2.m2.1.1.1.cmml" xref="S5.p3.2.m2.1.1.1"></eq><apply id="S5.p3.2.m2.1.1.2.cmml" xref="S5.p3.2.m2.1.1.2"><times id="S5.p3.2.m2.1.1.2.1.cmml" xref="S5.p3.2.m2.1.1.2.1"></times><ci id="S5.p3.2.m2.1.1.2.2.cmml" xref="S5.p3.2.m2.1.1.2.2">𝑠</ci><ci id="S5.p3.2.m2.1.1.2.3.cmml" xref="S5.p3.2.m2.1.1.2.3">𝑝</ci></apply><cn type="float" id="S5.p3.2.m2.1.1.3.cmml" xref="S5.p3.2.m2.1.1.3">0.9</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p3.2.m2.1c">sp=0.9</annotation></semantics></math>, and after the local training process, each selected client sparsifies their model by only keeping the top <math id="S5.p3.3.m3.1" class="ltx_Math" alttext="(1-sp+r_{mask})" display="inline"><semantics id="S5.p3.3.m3.1a"><mrow id="S5.p3.3.m3.1.1.1" xref="S5.p3.3.m3.1.1.1.1.cmml"><mo stretchy="false" id="S5.p3.3.m3.1.1.1.2" xref="S5.p3.3.m3.1.1.1.1.cmml">(</mo><mrow id="S5.p3.3.m3.1.1.1.1" xref="S5.p3.3.m3.1.1.1.1.cmml"><mrow id="S5.p3.3.m3.1.1.1.1.2" xref="S5.p3.3.m3.1.1.1.1.2.cmml"><mn id="S5.p3.3.m3.1.1.1.1.2.2" xref="S5.p3.3.m3.1.1.1.1.2.2.cmml">1</mn><mo id="S5.p3.3.m3.1.1.1.1.2.1" xref="S5.p3.3.m3.1.1.1.1.2.1.cmml">−</mo><mrow id="S5.p3.3.m3.1.1.1.1.2.3" xref="S5.p3.3.m3.1.1.1.1.2.3.cmml"><mi id="S5.p3.3.m3.1.1.1.1.2.3.2" xref="S5.p3.3.m3.1.1.1.1.2.3.2.cmml">s</mi><mo lspace="0em" rspace="0em" id="S5.p3.3.m3.1.1.1.1.2.3.1" xref="S5.p3.3.m3.1.1.1.1.2.3.1.cmml">​</mo><mi id="S5.p3.3.m3.1.1.1.1.2.3.3" xref="S5.p3.3.m3.1.1.1.1.2.3.3.cmml">p</mi></mrow></mrow><mo id="S5.p3.3.m3.1.1.1.1.1" xref="S5.p3.3.m3.1.1.1.1.1.cmml">+</mo><msub id="S5.p3.3.m3.1.1.1.1.3" xref="S5.p3.3.m3.1.1.1.1.3.cmml"><mi id="S5.p3.3.m3.1.1.1.1.3.2" xref="S5.p3.3.m3.1.1.1.1.3.2.cmml">r</mi><mrow id="S5.p3.3.m3.1.1.1.1.3.3" xref="S5.p3.3.m3.1.1.1.1.3.3.cmml"><mi id="S5.p3.3.m3.1.1.1.1.3.3.2" xref="S5.p3.3.m3.1.1.1.1.3.3.2.cmml">m</mi><mo lspace="0em" rspace="0em" id="S5.p3.3.m3.1.1.1.1.3.3.1" xref="S5.p3.3.m3.1.1.1.1.3.3.1.cmml">​</mo><mi id="S5.p3.3.m3.1.1.1.1.3.3.3" xref="S5.p3.3.m3.1.1.1.1.3.3.3.cmml">a</mi><mo lspace="0em" rspace="0em" id="S5.p3.3.m3.1.1.1.1.3.3.1a" xref="S5.p3.3.m3.1.1.1.1.3.3.1.cmml">​</mo><mi id="S5.p3.3.m3.1.1.1.1.3.3.4" xref="S5.p3.3.m3.1.1.1.1.3.3.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S5.p3.3.m3.1.1.1.1.3.3.1b" xref="S5.p3.3.m3.1.1.1.1.3.3.1.cmml">​</mo><mi id="S5.p3.3.m3.1.1.1.1.3.3.5" xref="S5.p3.3.m3.1.1.1.1.3.3.5.cmml">k</mi></mrow></msub></mrow><mo stretchy="false" id="S5.p3.3.m3.1.1.1.3" xref="S5.p3.3.m3.1.1.1.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.p3.3.m3.1b"><apply id="S5.p3.3.m3.1.1.1.1.cmml" xref="S5.p3.3.m3.1.1.1"><plus id="S5.p3.3.m3.1.1.1.1.1.cmml" xref="S5.p3.3.m3.1.1.1.1.1"></plus><apply id="S5.p3.3.m3.1.1.1.1.2.cmml" xref="S5.p3.3.m3.1.1.1.1.2"><minus id="S5.p3.3.m3.1.1.1.1.2.1.cmml" xref="S5.p3.3.m3.1.1.1.1.2.1"></minus><cn type="integer" id="S5.p3.3.m3.1.1.1.1.2.2.cmml" xref="S5.p3.3.m3.1.1.1.1.2.2">1</cn><apply id="S5.p3.3.m3.1.1.1.1.2.3.cmml" xref="S5.p3.3.m3.1.1.1.1.2.3"><times id="S5.p3.3.m3.1.1.1.1.2.3.1.cmml" xref="S5.p3.3.m3.1.1.1.1.2.3.1"></times><ci id="S5.p3.3.m3.1.1.1.1.2.3.2.cmml" xref="S5.p3.3.m3.1.1.1.1.2.3.2">𝑠</ci><ci id="S5.p3.3.m3.1.1.1.1.2.3.3.cmml" xref="S5.p3.3.m3.1.1.1.1.2.3.3">𝑝</ci></apply></apply><apply id="S5.p3.3.m3.1.1.1.1.3.cmml" xref="S5.p3.3.m3.1.1.1.1.3"><csymbol cd="ambiguous" id="S5.p3.3.m3.1.1.1.1.3.1.cmml" xref="S5.p3.3.m3.1.1.1.1.3">subscript</csymbol><ci id="S5.p3.3.m3.1.1.1.1.3.2.cmml" xref="S5.p3.3.m3.1.1.1.1.3.2">𝑟</ci><apply id="S5.p3.3.m3.1.1.1.1.3.3.cmml" xref="S5.p3.3.m3.1.1.1.1.3.3"><times id="S5.p3.3.m3.1.1.1.1.3.3.1.cmml" xref="S5.p3.3.m3.1.1.1.1.3.3.1"></times><ci id="S5.p3.3.m3.1.1.1.1.3.3.2.cmml" xref="S5.p3.3.m3.1.1.1.1.3.3.2">𝑚</ci><ci id="S5.p3.3.m3.1.1.1.1.3.3.3.cmml" xref="S5.p3.3.m3.1.1.1.1.3.3.3">𝑎</ci><ci id="S5.p3.3.m3.1.1.1.1.3.3.4.cmml" xref="S5.p3.3.m3.1.1.1.1.3.3.4">𝑠</ci><ci id="S5.p3.3.m3.1.1.1.1.3.3.5.cmml" xref="S5.p3.3.m3.1.1.1.1.3.3.5">𝑘</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p3.3.m3.1c">(1-sp+r_{mask})</annotation></semantics></math> weights w.r.t their magnitude, while setting the rest to zero. In particular, if <math id="S5.p3.4.m4.1" class="ltx_Math" alttext="sp=0.9" display="inline"><semantics id="S5.p3.4.m4.1a"><mrow id="S5.p3.4.m4.1.1" xref="S5.p3.4.m4.1.1.cmml"><mrow id="S5.p3.4.m4.1.1.2" xref="S5.p3.4.m4.1.1.2.cmml"><mi id="S5.p3.4.m4.1.1.2.2" xref="S5.p3.4.m4.1.1.2.2.cmml">s</mi><mo lspace="0em" rspace="0em" id="S5.p3.4.m4.1.1.2.1" xref="S5.p3.4.m4.1.1.2.1.cmml">​</mo><mi id="S5.p3.4.m4.1.1.2.3" xref="S5.p3.4.m4.1.1.2.3.cmml">p</mi></mrow><mo id="S5.p3.4.m4.1.1.1" xref="S5.p3.4.m4.1.1.1.cmml">=</mo><mn id="S5.p3.4.m4.1.1.3" xref="S5.p3.4.m4.1.1.3.cmml">0.9</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.p3.4.m4.1b"><apply id="S5.p3.4.m4.1.1.cmml" xref="S5.p3.4.m4.1.1"><eq id="S5.p3.4.m4.1.1.1.cmml" xref="S5.p3.4.m4.1.1.1"></eq><apply id="S5.p3.4.m4.1.1.2.cmml" xref="S5.p3.4.m4.1.1.2"><times id="S5.p3.4.m4.1.1.2.1.cmml" xref="S5.p3.4.m4.1.1.2.1"></times><ci id="S5.p3.4.m4.1.1.2.2.cmml" xref="S5.p3.4.m4.1.1.2.2">𝑠</ci><ci id="S5.p3.4.m4.1.1.2.3.cmml" xref="S5.p3.4.m4.1.1.2.3">𝑝</ci></apply><cn type="float" id="S5.p3.4.m4.1.1.3.cmml" xref="S5.p3.4.m4.1.1.3">0.9</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p3.4.m4.1c">sp=0.9</annotation></semantics></math> and <math id="S5.p3.5.m5.1" class="ltx_Math" alttext="r_{mask}=0.1" display="inline"><semantics id="S5.p3.5.m5.1a"><mrow id="S5.p3.5.m5.1.1" xref="S5.p3.5.m5.1.1.cmml"><msub id="S5.p3.5.m5.1.1.2" xref="S5.p3.5.m5.1.1.2.cmml"><mi id="S5.p3.5.m5.1.1.2.2" xref="S5.p3.5.m5.1.1.2.2.cmml">r</mi><mrow id="S5.p3.5.m5.1.1.2.3" xref="S5.p3.5.m5.1.1.2.3.cmml"><mi id="S5.p3.5.m5.1.1.2.3.2" xref="S5.p3.5.m5.1.1.2.3.2.cmml">m</mi><mo lspace="0em" rspace="0em" id="S5.p3.5.m5.1.1.2.3.1" xref="S5.p3.5.m5.1.1.2.3.1.cmml">​</mo><mi id="S5.p3.5.m5.1.1.2.3.3" xref="S5.p3.5.m5.1.1.2.3.3.cmml">a</mi><mo lspace="0em" rspace="0em" id="S5.p3.5.m5.1.1.2.3.1a" xref="S5.p3.5.m5.1.1.2.3.1.cmml">​</mo><mi id="S5.p3.5.m5.1.1.2.3.4" xref="S5.p3.5.m5.1.1.2.3.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S5.p3.5.m5.1.1.2.3.1b" xref="S5.p3.5.m5.1.1.2.3.1.cmml">​</mo><mi id="S5.p3.5.m5.1.1.2.3.5" xref="S5.p3.5.m5.1.1.2.3.5.cmml">k</mi></mrow></msub><mo id="S5.p3.5.m5.1.1.1" xref="S5.p3.5.m5.1.1.1.cmml">=</mo><mn id="S5.p3.5.m5.1.1.3" xref="S5.p3.5.m5.1.1.3.cmml">0.1</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.p3.5.m5.1b"><apply id="S5.p3.5.m5.1.1.cmml" xref="S5.p3.5.m5.1.1"><eq id="S5.p3.5.m5.1.1.1.cmml" xref="S5.p3.5.m5.1.1.1"></eq><apply id="S5.p3.5.m5.1.1.2.cmml" xref="S5.p3.5.m5.1.1.2"><csymbol cd="ambiguous" id="S5.p3.5.m5.1.1.2.1.cmml" xref="S5.p3.5.m5.1.1.2">subscript</csymbol><ci id="S5.p3.5.m5.1.1.2.2.cmml" xref="S5.p3.5.m5.1.1.2.2">𝑟</ci><apply id="S5.p3.5.m5.1.1.2.3.cmml" xref="S5.p3.5.m5.1.1.2.3"><times id="S5.p3.5.m5.1.1.2.3.1.cmml" xref="S5.p3.5.m5.1.1.2.3.1"></times><ci id="S5.p3.5.m5.1.1.2.3.2.cmml" xref="S5.p3.5.m5.1.1.2.3.2">𝑚</ci><ci id="S5.p3.5.m5.1.1.2.3.3.cmml" xref="S5.p3.5.m5.1.1.2.3.3">𝑎</ci><ci id="S5.p3.5.m5.1.1.2.3.4.cmml" xref="S5.p3.5.m5.1.1.2.3.4">𝑠</ci><ci id="S5.p3.5.m5.1.1.2.3.5.cmml" xref="S5.p3.5.m5.1.1.2.3.5">𝑘</ci></apply></apply><cn type="float" id="S5.p3.5.m5.1.1.3.cmml" xref="S5.p3.5.m5.1.1.3">0.1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p3.5.m5.1c">r_{mask}=0.1</annotation></semantics></math>, the selected clients will send the <span id="S5.p3.6.1" class="ltx_text ltx_font_typewriter">top-20%</span> to the central server for aggregation. The model produced after aggregation is not guaranteed to be sparse. If mask ratio equals to the sparsity level, the algorithm is degenerated to vanilla SWAT without local sparsification. However, and as shown in Fig.<a href="#S4.F2" title="Figure 2 ‣ 4.3 Sparsification Effect Analysis ‣ 4 Sparse Training for Federated Learning ‣ ZeroFL: Efficient On-Device Training for Federated Learning with Local Sparsity" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, the resulting model is most likely to be sparse. Here, uplink communications are saved as only <math id="S5.p3.6.m6.1" class="ltx_Math" alttext="(1-sp+r_{mask})" display="inline"><semantics id="S5.p3.6.m6.1a"><mrow id="S5.p3.6.m6.1.1.1" xref="S5.p3.6.m6.1.1.1.1.cmml"><mo stretchy="false" id="S5.p3.6.m6.1.1.1.2" xref="S5.p3.6.m6.1.1.1.1.cmml">(</mo><mrow id="S5.p3.6.m6.1.1.1.1" xref="S5.p3.6.m6.1.1.1.1.cmml"><mrow id="S5.p3.6.m6.1.1.1.1.2" xref="S5.p3.6.m6.1.1.1.1.2.cmml"><mn id="S5.p3.6.m6.1.1.1.1.2.2" xref="S5.p3.6.m6.1.1.1.1.2.2.cmml">1</mn><mo id="S5.p3.6.m6.1.1.1.1.2.1" xref="S5.p3.6.m6.1.1.1.1.2.1.cmml">−</mo><mrow id="S5.p3.6.m6.1.1.1.1.2.3" xref="S5.p3.6.m6.1.1.1.1.2.3.cmml"><mi id="S5.p3.6.m6.1.1.1.1.2.3.2" xref="S5.p3.6.m6.1.1.1.1.2.3.2.cmml">s</mi><mo lspace="0em" rspace="0em" id="S5.p3.6.m6.1.1.1.1.2.3.1" xref="S5.p3.6.m6.1.1.1.1.2.3.1.cmml">​</mo><mi id="S5.p3.6.m6.1.1.1.1.2.3.3" xref="S5.p3.6.m6.1.1.1.1.2.3.3.cmml">p</mi></mrow></mrow><mo id="S5.p3.6.m6.1.1.1.1.1" xref="S5.p3.6.m6.1.1.1.1.1.cmml">+</mo><msub id="S5.p3.6.m6.1.1.1.1.3" xref="S5.p3.6.m6.1.1.1.1.3.cmml"><mi id="S5.p3.6.m6.1.1.1.1.3.2" xref="S5.p3.6.m6.1.1.1.1.3.2.cmml">r</mi><mrow id="S5.p3.6.m6.1.1.1.1.3.3" xref="S5.p3.6.m6.1.1.1.1.3.3.cmml"><mi id="S5.p3.6.m6.1.1.1.1.3.3.2" xref="S5.p3.6.m6.1.1.1.1.3.3.2.cmml">m</mi><mo lspace="0em" rspace="0em" id="S5.p3.6.m6.1.1.1.1.3.3.1" xref="S5.p3.6.m6.1.1.1.1.3.3.1.cmml">​</mo><mi id="S5.p3.6.m6.1.1.1.1.3.3.3" xref="S5.p3.6.m6.1.1.1.1.3.3.3.cmml">a</mi><mo lspace="0em" rspace="0em" id="S5.p3.6.m6.1.1.1.1.3.3.1a" xref="S5.p3.6.m6.1.1.1.1.3.3.1.cmml">​</mo><mi id="S5.p3.6.m6.1.1.1.1.3.3.4" xref="S5.p3.6.m6.1.1.1.1.3.3.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S5.p3.6.m6.1.1.1.1.3.3.1b" xref="S5.p3.6.m6.1.1.1.1.3.3.1.cmml">​</mo><mi id="S5.p3.6.m6.1.1.1.1.3.3.5" xref="S5.p3.6.m6.1.1.1.1.3.3.5.cmml">k</mi></mrow></msub></mrow><mo stretchy="false" id="S5.p3.6.m6.1.1.1.3" xref="S5.p3.6.m6.1.1.1.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.p3.6.m6.1b"><apply id="S5.p3.6.m6.1.1.1.1.cmml" xref="S5.p3.6.m6.1.1.1"><plus id="S5.p3.6.m6.1.1.1.1.1.cmml" xref="S5.p3.6.m6.1.1.1.1.1"></plus><apply id="S5.p3.6.m6.1.1.1.1.2.cmml" xref="S5.p3.6.m6.1.1.1.1.2"><minus id="S5.p3.6.m6.1.1.1.1.2.1.cmml" xref="S5.p3.6.m6.1.1.1.1.2.1"></minus><cn type="integer" id="S5.p3.6.m6.1.1.1.1.2.2.cmml" xref="S5.p3.6.m6.1.1.1.1.2.2">1</cn><apply id="S5.p3.6.m6.1.1.1.1.2.3.cmml" xref="S5.p3.6.m6.1.1.1.1.2.3"><times id="S5.p3.6.m6.1.1.1.1.2.3.1.cmml" xref="S5.p3.6.m6.1.1.1.1.2.3.1"></times><ci id="S5.p3.6.m6.1.1.1.1.2.3.2.cmml" xref="S5.p3.6.m6.1.1.1.1.2.3.2">𝑠</ci><ci id="S5.p3.6.m6.1.1.1.1.2.3.3.cmml" xref="S5.p3.6.m6.1.1.1.1.2.3.3">𝑝</ci></apply></apply><apply id="S5.p3.6.m6.1.1.1.1.3.cmml" xref="S5.p3.6.m6.1.1.1.1.3"><csymbol cd="ambiguous" id="S5.p3.6.m6.1.1.1.1.3.1.cmml" xref="S5.p3.6.m6.1.1.1.1.3">subscript</csymbol><ci id="S5.p3.6.m6.1.1.1.1.3.2.cmml" xref="S5.p3.6.m6.1.1.1.1.3.2">𝑟</ci><apply id="S5.p3.6.m6.1.1.1.1.3.3.cmml" xref="S5.p3.6.m6.1.1.1.1.3.3"><times id="S5.p3.6.m6.1.1.1.1.3.3.1.cmml" xref="S5.p3.6.m6.1.1.1.1.3.3.1"></times><ci id="S5.p3.6.m6.1.1.1.1.3.3.2.cmml" xref="S5.p3.6.m6.1.1.1.1.3.3.2">𝑚</ci><ci id="S5.p3.6.m6.1.1.1.1.3.3.3.cmml" xref="S5.p3.6.m6.1.1.1.1.3.3.3">𝑎</ci><ci id="S5.p3.6.m6.1.1.1.1.3.3.4.cmml" xref="S5.p3.6.m6.1.1.1.1.3.3.4">𝑠</ci><ci id="S5.p3.6.m6.1.1.1.1.3.3.5.cmml" xref="S5.p3.6.m6.1.1.1.1.3.3.5">𝑘</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p3.6.m6.1c">(1-sp+r_{mask})</annotation></semantics></math> weights are sent as dense values.</p>
</div>
<div id="S5.p4" class="ltx_para ltx_noindent">
<p id="S5.p4.10" class="ltx_p"><span id="S5.p4.10.1" class="ltx_text ltx_font_bold">Diff on Top-K-Weights.</span> The idea behind this method is to send local weight-updates for the top-K weights, rather than sending the top-K weights themselves. Given <math id="S5.p4.1.m1.1" class="ltx_Math" alttext="sp" display="inline"><semantics id="S5.p4.1.m1.1a"><mrow id="S5.p4.1.m1.1.1" xref="S5.p4.1.m1.1.1.cmml"><mi id="S5.p4.1.m1.1.1.2" xref="S5.p4.1.m1.1.1.2.cmml">s</mi><mo lspace="0em" rspace="0em" id="S5.p4.1.m1.1.1.1" xref="S5.p4.1.m1.1.1.1.cmml">​</mo><mi id="S5.p4.1.m1.1.1.3" xref="S5.p4.1.m1.1.1.3.cmml">p</mi></mrow><annotation-xml encoding="MathML-Content" id="S5.p4.1.m1.1b"><apply id="S5.p4.1.m1.1.1.cmml" xref="S5.p4.1.m1.1.1"><times id="S5.p4.1.m1.1.1.1.cmml" xref="S5.p4.1.m1.1.1.1"></times><ci id="S5.p4.1.m1.1.1.2.cmml" xref="S5.p4.1.m1.1.1.2">𝑠</ci><ci id="S5.p4.1.m1.1.1.3.cmml" xref="S5.p4.1.m1.1.1.3">𝑝</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p4.1.m1.1c">sp</annotation></semantics></math> and <math id="S5.p4.2.m2.1" class="ltx_Math" alttext="r_{mask}" display="inline"><semantics id="S5.p4.2.m2.1a"><msub id="S5.p4.2.m2.1.1" xref="S5.p4.2.m2.1.1.cmml"><mi id="S5.p4.2.m2.1.1.2" xref="S5.p4.2.m2.1.1.2.cmml">r</mi><mrow id="S5.p4.2.m2.1.1.3" xref="S5.p4.2.m2.1.1.3.cmml"><mi id="S5.p4.2.m2.1.1.3.2" xref="S5.p4.2.m2.1.1.3.2.cmml">m</mi><mo lspace="0em" rspace="0em" id="S5.p4.2.m2.1.1.3.1" xref="S5.p4.2.m2.1.1.3.1.cmml">​</mo><mi id="S5.p4.2.m2.1.1.3.3" xref="S5.p4.2.m2.1.1.3.3.cmml">a</mi><mo lspace="0em" rspace="0em" id="S5.p4.2.m2.1.1.3.1a" xref="S5.p4.2.m2.1.1.3.1.cmml">​</mo><mi id="S5.p4.2.m2.1.1.3.4" xref="S5.p4.2.m2.1.1.3.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S5.p4.2.m2.1.1.3.1b" xref="S5.p4.2.m2.1.1.3.1.cmml">​</mo><mi id="S5.p4.2.m2.1.1.3.5" xref="S5.p4.2.m2.1.1.3.5.cmml">k</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S5.p4.2.m2.1b"><apply id="S5.p4.2.m2.1.1.cmml" xref="S5.p4.2.m2.1.1"><csymbol cd="ambiguous" id="S5.p4.2.m2.1.1.1.cmml" xref="S5.p4.2.m2.1.1">subscript</csymbol><ci id="S5.p4.2.m2.1.1.2.cmml" xref="S5.p4.2.m2.1.1.2">𝑟</ci><apply id="S5.p4.2.m2.1.1.3.cmml" xref="S5.p4.2.m2.1.1.3"><times id="S5.p4.2.m2.1.1.3.1.cmml" xref="S5.p4.2.m2.1.1.3.1"></times><ci id="S5.p4.2.m2.1.1.3.2.cmml" xref="S5.p4.2.m2.1.1.3.2">𝑚</ci><ci id="S5.p4.2.m2.1.1.3.3.cmml" xref="S5.p4.2.m2.1.1.3.3">𝑎</ci><ci id="S5.p4.2.m2.1.1.3.4.cmml" xref="S5.p4.2.m2.1.1.3.4">𝑠</ci><ci id="S5.p4.2.m2.1.1.3.5.cmml" xref="S5.p4.2.m2.1.1.3.5">𝑘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p4.2.m2.1c">r_{mask}</annotation></semantics></math>, we first identify the weights that are the largest in magnitude by selecting the top <math id="S5.p4.3.m3.1" class="ltx_Math" alttext="(1-sp+r_{mask})" display="inline"><semantics id="S5.p4.3.m3.1a"><mrow id="S5.p4.3.m3.1.1.1" xref="S5.p4.3.m3.1.1.1.1.cmml"><mo stretchy="false" id="S5.p4.3.m3.1.1.1.2" xref="S5.p4.3.m3.1.1.1.1.cmml">(</mo><mrow id="S5.p4.3.m3.1.1.1.1" xref="S5.p4.3.m3.1.1.1.1.cmml"><mrow id="S5.p4.3.m3.1.1.1.1.2" xref="S5.p4.3.m3.1.1.1.1.2.cmml"><mn id="S5.p4.3.m3.1.1.1.1.2.2" xref="S5.p4.3.m3.1.1.1.1.2.2.cmml">1</mn><mo id="S5.p4.3.m3.1.1.1.1.2.1" xref="S5.p4.3.m3.1.1.1.1.2.1.cmml">−</mo><mrow id="S5.p4.3.m3.1.1.1.1.2.3" xref="S5.p4.3.m3.1.1.1.1.2.3.cmml"><mi id="S5.p4.3.m3.1.1.1.1.2.3.2" xref="S5.p4.3.m3.1.1.1.1.2.3.2.cmml">s</mi><mo lspace="0em" rspace="0em" id="S5.p4.3.m3.1.1.1.1.2.3.1" xref="S5.p4.3.m3.1.1.1.1.2.3.1.cmml">​</mo><mi id="S5.p4.3.m3.1.1.1.1.2.3.3" xref="S5.p4.3.m3.1.1.1.1.2.3.3.cmml">p</mi></mrow></mrow><mo id="S5.p4.3.m3.1.1.1.1.1" xref="S5.p4.3.m3.1.1.1.1.1.cmml">+</mo><msub id="S5.p4.3.m3.1.1.1.1.3" xref="S5.p4.3.m3.1.1.1.1.3.cmml"><mi id="S5.p4.3.m3.1.1.1.1.3.2" xref="S5.p4.3.m3.1.1.1.1.3.2.cmml">r</mi><mrow id="S5.p4.3.m3.1.1.1.1.3.3" xref="S5.p4.3.m3.1.1.1.1.3.3.cmml"><mi id="S5.p4.3.m3.1.1.1.1.3.3.2" xref="S5.p4.3.m3.1.1.1.1.3.3.2.cmml">m</mi><mo lspace="0em" rspace="0em" id="S5.p4.3.m3.1.1.1.1.3.3.1" xref="S5.p4.3.m3.1.1.1.1.3.3.1.cmml">​</mo><mi id="S5.p4.3.m3.1.1.1.1.3.3.3" xref="S5.p4.3.m3.1.1.1.1.3.3.3.cmml">a</mi><mo lspace="0em" rspace="0em" id="S5.p4.3.m3.1.1.1.1.3.3.1a" xref="S5.p4.3.m3.1.1.1.1.3.3.1.cmml">​</mo><mi id="S5.p4.3.m3.1.1.1.1.3.3.4" xref="S5.p4.3.m3.1.1.1.1.3.3.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S5.p4.3.m3.1.1.1.1.3.3.1b" xref="S5.p4.3.m3.1.1.1.1.3.3.1.cmml">​</mo><mi id="S5.p4.3.m3.1.1.1.1.3.3.5" xref="S5.p4.3.m3.1.1.1.1.3.3.5.cmml">k</mi></mrow></msub></mrow><mo stretchy="false" id="S5.p4.3.m3.1.1.1.3" xref="S5.p4.3.m3.1.1.1.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.p4.3.m3.1b"><apply id="S5.p4.3.m3.1.1.1.1.cmml" xref="S5.p4.3.m3.1.1.1"><plus id="S5.p4.3.m3.1.1.1.1.1.cmml" xref="S5.p4.3.m3.1.1.1.1.1"></plus><apply id="S5.p4.3.m3.1.1.1.1.2.cmml" xref="S5.p4.3.m3.1.1.1.1.2"><minus id="S5.p4.3.m3.1.1.1.1.2.1.cmml" xref="S5.p4.3.m3.1.1.1.1.2.1"></minus><cn type="integer" id="S5.p4.3.m3.1.1.1.1.2.2.cmml" xref="S5.p4.3.m3.1.1.1.1.2.2">1</cn><apply id="S5.p4.3.m3.1.1.1.1.2.3.cmml" xref="S5.p4.3.m3.1.1.1.1.2.3"><times id="S5.p4.3.m3.1.1.1.1.2.3.1.cmml" xref="S5.p4.3.m3.1.1.1.1.2.3.1"></times><ci id="S5.p4.3.m3.1.1.1.1.2.3.2.cmml" xref="S5.p4.3.m3.1.1.1.1.2.3.2">𝑠</ci><ci id="S5.p4.3.m3.1.1.1.1.2.3.3.cmml" xref="S5.p4.3.m3.1.1.1.1.2.3.3">𝑝</ci></apply></apply><apply id="S5.p4.3.m3.1.1.1.1.3.cmml" xref="S5.p4.3.m3.1.1.1.1.3"><csymbol cd="ambiguous" id="S5.p4.3.m3.1.1.1.1.3.1.cmml" xref="S5.p4.3.m3.1.1.1.1.3">subscript</csymbol><ci id="S5.p4.3.m3.1.1.1.1.3.2.cmml" xref="S5.p4.3.m3.1.1.1.1.3.2">𝑟</ci><apply id="S5.p4.3.m3.1.1.1.1.3.3.cmml" xref="S5.p4.3.m3.1.1.1.1.3.3"><times id="S5.p4.3.m3.1.1.1.1.3.3.1.cmml" xref="S5.p4.3.m3.1.1.1.1.3.3.1"></times><ci id="S5.p4.3.m3.1.1.1.1.3.3.2.cmml" xref="S5.p4.3.m3.1.1.1.1.3.3.2">𝑚</ci><ci id="S5.p4.3.m3.1.1.1.1.3.3.3.cmml" xref="S5.p4.3.m3.1.1.1.1.3.3.3">𝑎</ci><ci id="S5.p4.3.m3.1.1.1.1.3.3.4.cmml" xref="S5.p4.3.m3.1.1.1.1.3.3.4">𝑠</ci><ci id="S5.p4.3.m3.1.1.1.1.3.3.5.cmml" xref="S5.p4.3.m3.1.1.1.1.3.3.5">𝑘</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p4.3.m3.1c">(1-sp+r_{mask})</annotation></semantics></math>. The selected clients now send only the difference <math id="S5.p4.4.m4.1" class="ltx_Math" alttext="d" display="inline"><semantics id="S5.p4.4.m4.1a"><mi id="S5.p4.4.m4.1.1" xref="S5.p4.4.m4.1.1.cmml">d</mi><annotation-xml encoding="MathML-Content" id="S5.p4.4.m4.1b"><ci id="S5.p4.4.m4.1.1.cmml" xref="S5.p4.4.m4.1.1">𝑑</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.p4.4.m4.1c">d</annotation></semantics></math> of these top <math id="S5.p4.5.m5.1" class="ltx_Math" alttext="(1-sp+r_{mask})" display="inline"><semantics id="S5.p4.5.m5.1a"><mrow id="S5.p4.5.m5.1.1.1" xref="S5.p4.5.m5.1.1.1.1.cmml"><mo stretchy="false" id="S5.p4.5.m5.1.1.1.2" xref="S5.p4.5.m5.1.1.1.1.cmml">(</mo><mrow id="S5.p4.5.m5.1.1.1.1" xref="S5.p4.5.m5.1.1.1.1.cmml"><mrow id="S5.p4.5.m5.1.1.1.1.2" xref="S5.p4.5.m5.1.1.1.1.2.cmml"><mn id="S5.p4.5.m5.1.1.1.1.2.2" xref="S5.p4.5.m5.1.1.1.1.2.2.cmml">1</mn><mo id="S5.p4.5.m5.1.1.1.1.2.1" xref="S5.p4.5.m5.1.1.1.1.2.1.cmml">−</mo><mrow id="S5.p4.5.m5.1.1.1.1.2.3" xref="S5.p4.5.m5.1.1.1.1.2.3.cmml"><mi id="S5.p4.5.m5.1.1.1.1.2.3.2" xref="S5.p4.5.m5.1.1.1.1.2.3.2.cmml">s</mi><mo lspace="0em" rspace="0em" id="S5.p4.5.m5.1.1.1.1.2.3.1" xref="S5.p4.5.m5.1.1.1.1.2.3.1.cmml">​</mo><mi id="S5.p4.5.m5.1.1.1.1.2.3.3" xref="S5.p4.5.m5.1.1.1.1.2.3.3.cmml">p</mi></mrow></mrow><mo id="S5.p4.5.m5.1.1.1.1.1" xref="S5.p4.5.m5.1.1.1.1.1.cmml">+</mo><msub id="S5.p4.5.m5.1.1.1.1.3" xref="S5.p4.5.m5.1.1.1.1.3.cmml"><mi id="S5.p4.5.m5.1.1.1.1.3.2" xref="S5.p4.5.m5.1.1.1.1.3.2.cmml">r</mi><mrow id="S5.p4.5.m5.1.1.1.1.3.3" xref="S5.p4.5.m5.1.1.1.1.3.3.cmml"><mi id="S5.p4.5.m5.1.1.1.1.3.3.2" xref="S5.p4.5.m5.1.1.1.1.3.3.2.cmml">m</mi><mo lspace="0em" rspace="0em" id="S5.p4.5.m5.1.1.1.1.3.3.1" xref="S5.p4.5.m5.1.1.1.1.3.3.1.cmml">​</mo><mi id="S5.p4.5.m5.1.1.1.1.3.3.3" xref="S5.p4.5.m5.1.1.1.1.3.3.3.cmml">a</mi><mo lspace="0em" rspace="0em" id="S5.p4.5.m5.1.1.1.1.3.3.1a" xref="S5.p4.5.m5.1.1.1.1.3.3.1.cmml">​</mo><mi id="S5.p4.5.m5.1.1.1.1.3.3.4" xref="S5.p4.5.m5.1.1.1.1.3.3.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S5.p4.5.m5.1.1.1.1.3.3.1b" xref="S5.p4.5.m5.1.1.1.1.3.3.1.cmml">​</mo><mi id="S5.p4.5.m5.1.1.1.1.3.3.5" xref="S5.p4.5.m5.1.1.1.1.3.3.5.cmml">k</mi></mrow></msub></mrow><mo stretchy="false" id="S5.p4.5.m5.1.1.1.3" xref="S5.p4.5.m5.1.1.1.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.p4.5.m5.1b"><apply id="S5.p4.5.m5.1.1.1.1.cmml" xref="S5.p4.5.m5.1.1.1"><plus id="S5.p4.5.m5.1.1.1.1.1.cmml" xref="S5.p4.5.m5.1.1.1.1.1"></plus><apply id="S5.p4.5.m5.1.1.1.1.2.cmml" xref="S5.p4.5.m5.1.1.1.1.2"><minus id="S5.p4.5.m5.1.1.1.1.2.1.cmml" xref="S5.p4.5.m5.1.1.1.1.2.1"></minus><cn type="integer" id="S5.p4.5.m5.1.1.1.1.2.2.cmml" xref="S5.p4.5.m5.1.1.1.1.2.2">1</cn><apply id="S5.p4.5.m5.1.1.1.1.2.3.cmml" xref="S5.p4.5.m5.1.1.1.1.2.3"><times id="S5.p4.5.m5.1.1.1.1.2.3.1.cmml" xref="S5.p4.5.m5.1.1.1.1.2.3.1"></times><ci id="S5.p4.5.m5.1.1.1.1.2.3.2.cmml" xref="S5.p4.5.m5.1.1.1.1.2.3.2">𝑠</ci><ci id="S5.p4.5.m5.1.1.1.1.2.3.3.cmml" xref="S5.p4.5.m5.1.1.1.1.2.3.3">𝑝</ci></apply></apply><apply id="S5.p4.5.m5.1.1.1.1.3.cmml" xref="S5.p4.5.m5.1.1.1.1.3"><csymbol cd="ambiguous" id="S5.p4.5.m5.1.1.1.1.3.1.cmml" xref="S5.p4.5.m5.1.1.1.1.3">subscript</csymbol><ci id="S5.p4.5.m5.1.1.1.1.3.2.cmml" xref="S5.p4.5.m5.1.1.1.1.3.2">𝑟</ci><apply id="S5.p4.5.m5.1.1.1.1.3.3.cmml" xref="S5.p4.5.m5.1.1.1.1.3.3"><times id="S5.p4.5.m5.1.1.1.1.3.3.1.cmml" xref="S5.p4.5.m5.1.1.1.1.3.3.1"></times><ci id="S5.p4.5.m5.1.1.1.1.3.3.2.cmml" xref="S5.p4.5.m5.1.1.1.1.3.3.2">𝑚</ci><ci id="S5.p4.5.m5.1.1.1.1.3.3.3.cmml" xref="S5.p4.5.m5.1.1.1.1.3.3.3">𝑎</ci><ci id="S5.p4.5.m5.1.1.1.1.3.3.4.cmml" xref="S5.p4.5.m5.1.1.1.1.3.3.4">𝑠</ci><ci id="S5.p4.5.m5.1.1.1.1.3.3.5.cmml" xref="S5.p4.5.m5.1.1.1.1.3.3.5">𝑘</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p4.5.m5.1c">(1-sp+r_{mask})</annotation></semantics></math> weights with respect to the originally received model <math id="S5.p4.6.m6.1" class="ltx_Math" alttext="w_{t}" display="inline"><semantics id="S5.p4.6.m6.1a"><msub id="S5.p4.6.m6.1.1" xref="S5.p4.6.m6.1.1.cmml"><mi id="S5.p4.6.m6.1.1.2" xref="S5.p4.6.m6.1.1.2.cmml">w</mi><mi id="S5.p4.6.m6.1.1.3" xref="S5.p4.6.m6.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S5.p4.6.m6.1b"><apply id="S5.p4.6.m6.1.1.cmml" xref="S5.p4.6.m6.1.1"><csymbol cd="ambiguous" id="S5.p4.6.m6.1.1.1.cmml" xref="S5.p4.6.m6.1.1">subscript</csymbol><ci id="S5.p4.6.m6.1.1.2.cmml" xref="S5.p4.6.m6.1.1.2">𝑤</ci><ci id="S5.p4.6.m6.1.1.3.cmml" xref="S5.p4.6.m6.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p4.6.m6.1c">w_{t}</annotation></semantics></math> as <math id="S5.p4.7.m7.1" class="ltx_Math" alttext="d_{t+1}=w_{E}-w_{t}" display="inline"><semantics id="S5.p4.7.m7.1a"><mrow id="S5.p4.7.m7.1.1" xref="S5.p4.7.m7.1.1.cmml"><msub id="S5.p4.7.m7.1.1.2" xref="S5.p4.7.m7.1.1.2.cmml"><mi id="S5.p4.7.m7.1.1.2.2" xref="S5.p4.7.m7.1.1.2.2.cmml">d</mi><mrow id="S5.p4.7.m7.1.1.2.3" xref="S5.p4.7.m7.1.1.2.3.cmml"><mi id="S5.p4.7.m7.1.1.2.3.2" xref="S5.p4.7.m7.1.1.2.3.2.cmml">t</mi><mo id="S5.p4.7.m7.1.1.2.3.1" xref="S5.p4.7.m7.1.1.2.3.1.cmml">+</mo><mn id="S5.p4.7.m7.1.1.2.3.3" xref="S5.p4.7.m7.1.1.2.3.3.cmml">1</mn></mrow></msub><mo id="S5.p4.7.m7.1.1.1" xref="S5.p4.7.m7.1.1.1.cmml">=</mo><mrow id="S5.p4.7.m7.1.1.3" xref="S5.p4.7.m7.1.1.3.cmml"><msub id="S5.p4.7.m7.1.1.3.2" xref="S5.p4.7.m7.1.1.3.2.cmml"><mi id="S5.p4.7.m7.1.1.3.2.2" xref="S5.p4.7.m7.1.1.3.2.2.cmml">w</mi><mi id="S5.p4.7.m7.1.1.3.2.3" xref="S5.p4.7.m7.1.1.3.2.3.cmml">E</mi></msub><mo id="S5.p4.7.m7.1.1.3.1" xref="S5.p4.7.m7.1.1.3.1.cmml">−</mo><msub id="S5.p4.7.m7.1.1.3.3" xref="S5.p4.7.m7.1.1.3.3.cmml"><mi id="S5.p4.7.m7.1.1.3.3.2" xref="S5.p4.7.m7.1.1.3.3.2.cmml">w</mi><mi id="S5.p4.7.m7.1.1.3.3.3" xref="S5.p4.7.m7.1.1.3.3.3.cmml">t</mi></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.p4.7.m7.1b"><apply id="S5.p4.7.m7.1.1.cmml" xref="S5.p4.7.m7.1.1"><eq id="S5.p4.7.m7.1.1.1.cmml" xref="S5.p4.7.m7.1.1.1"></eq><apply id="S5.p4.7.m7.1.1.2.cmml" xref="S5.p4.7.m7.1.1.2"><csymbol cd="ambiguous" id="S5.p4.7.m7.1.1.2.1.cmml" xref="S5.p4.7.m7.1.1.2">subscript</csymbol><ci id="S5.p4.7.m7.1.1.2.2.cmml" xref="S5.p4.7.m7.1.1.2.2">𝑑</ci><apply id="S5.p4.7.m7.1.1.2.3.cmml" xref="S5.p4.7.m7.1.1.2.3"><plus id="S5.p4.7.m7.1.1.2.3.1.cmml" xref="S5.p4.7.m7.1.1.2.3.1"></plus><ci id="S5.p4.7.m7.1.1.2.3.2.cmml" xref="S5.p4.7.m7.1.1.2.3.2">𝑡</ci><cn type="integer" id="S5.p4.7.m7.1.1.2.3.3.cmml" xref="S5.p4.7.m7.1.1.2.3.3">1</cn></apply></apply><apply id="S5.p4.7.m7.1.1.3.cmml" xref="S5.p4.7.m7.1.1.3"><minus id="S5.p4.7.m7.1.1.3.1.cmml" xref="S5.p4.7.m7.1.1.3.1"></minus><apply id="S5.p4.7.m7.1.1.3.2.cmml" xref="S5.p4.7.m7.1.1.3.2"><csymbol cd="ambiguous" id="S5.p4.7.m7.1.1.3.2.1.cmml" xref="S5.p4.7.m7.1.1.3.2">subscript</csymbol><ci id="S5.p4.7.m7.1.1.3.2.2.cmml" xref="S5.p4.7.m7.1.1.3.2.2">𝑤</ci><ci id="S5.p4.7.m7.1.1.3.2.3.cmml" xref="S5.p4.7.m7.1.1.3.2.3">𝐸</ci></apply><apply id="S5.p4.7.m7.1.1.3.3.cmml" xref="S5.p4.7.m7.1.1.3.3"><csymbol cd="ambiguous" id="S5.p4.7.m7.1.1.3.3.1.cmml" xref="S5.p4.7.m7.1.1.3.3">subscript</csymbol><ci id="S5.p4.7.m7.1.1.3.3.2.cmml" xref="S5.p4.7.m7.1.1.3.3.2">𝑤</ci><ci id="S5.p4.7.m7.1.1.3.3.3.cmml" xref="S5.p4.7.m7.1.1.3.3.3">𝑡</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p4.7.m7.1c">d_{t+1}=w_{E}-w_{t}</annotation></semantics></math> with <math id="S5.p4.8.m8.1" class="ltx_Math" alttext="w_{E}" display="inline"><semantics id="S5.p4.8.m8.1a"><msub id="S5.p4.8.m8.1.1" xref="S5.p4.8.m8.1.1.cmml"><mi id="S5.p4.8.m8.1.1.2" xref="S5.p4.8.m8.1.1.2.cmml">w</mi><mi id="S5.p4.8.m8.1.1.3" xref="S5.p4.8.m8.1.1.3.cmml">E</mi></msub><annotation-xml encoding="MathML-Content" id="S5.p4.8.m8.1b"><apply id="S5.p4.8.m8.1.1.cmml" xref="S5.p4.8.m8.1.1"><csymbol cd="ambiguous" id="S5.p4.8.m8.1.1.1.cmml" xref="S5.p4.8.m8.1.1">subscript</csymbol><ci id="S5.p4.8.m8.1.1.2.cmml" xref="S5.p4.8.m8.1.1.2">𝑤</ci><ci id="S5.p4.8.m8.1.1.3.cmml" xref="S5.p4.8.m8.1.1.3">𝐸</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p4.8.m8.1c">w_{E}</annotation></semantics></math> the weights obtained after local training. The remaining differences are set to zero. In this way, after the aggregation in the central server, the weights that are not in the top <math id="S5.p4.9.m9.1" class="ltx_Math" alttext="(1-sp+r_{mask})" display="inline"><semantics id="S5.p4.9.m9.1a"><mrow id="S5.p4.9.m9.1.1.1" xref="S5.p4.9.m9.1.1.1.1.cmml"><mo stretchy="false" id="S5.p4.9.m9.1.1.1.2" xref="S5.p4.9.m9.1.1.1.1.cmml">(</mo><mrow id="S5.p4.9.m9.1.1.1.1" xref="S5.p4.9.m9.1.1.1.1.cmml"><mrow id="S5.p4.9.m9.1.1.1.1.2" xref="S5.p4.9.m9.1.1.1.1.2.cmml"><mn id="S5.p4.9.m9.1.1.1.1.2.2" xref="S5.p4.9.m9.1.1.1.1.2.2.cmml">1</mn><mo id="S5.p4.9.m9.1.1.1.1.2.1" xref="S5.p4.9.m9.1.1.1.1.2.1.cmml">−</mo><mrow id="S5.p4.9.m9.1.1.1.1.2.3" xref="S5.p4.9.m9.1.1.1.1.2.3.cmml"><mi id="S5.p4.9.m9.1.1.1.1.2.3.2" xref="S5.p4.9.m9.1.1.1.1.2.3.2.cmml">s</mi><mo lspace="0em" rspace="0em" id="S5.p4.9.m9.1.1.1.1.2.3.1" xref="S5.p4.9.m9.1.1.1.1.2.3.1.cmml">​</mo><mi id="S5.p4.9.m9.1.1.1.1.2.3.3" xref="S5.p4.9.m9.1.1.1.1.2.3.3.cmml">p</mi></mrow></mrow><mo id="S5.p4.9.m9.1.1.1.1.1" xref="S5.p4.9.m9.1.1.1.1.1.cmml">+</mo><msub id="S5.p4.9.m9.1.1.1.1.3" xref="S5.p4.9.m9.1.1.1.1.3.cmml"><mi id="S5.p4.9.m9.1.1.1.1.3.2" xref="S5.p4.9.m9.1.1.1.1.3.2.cmml">r</mi><mrow id="S5.p4.9.m9.1.1.1.1.3.3" xref="S5.p4.9.m9.1.1.1.1.3.3.cmml"><mi id="S5.p4.9.m9.1.1.1.1.3.3.2" xref="S5.p4.9.m9.1.1.1.1.3.3.2.cmml">m</mi><mo lspace="0em" rspace="0em" id="S5.p4.9.m9.1.1.1.1.3.3.1" xref="S5.p4.9.m9.1.1.1.1.3.3.1.cmml">​</mo><mi id="S5.p4.9.m9.1.1.1.1.3.3.3" xref="S5.p4.9.m9.1.1.1.1.3.3.3.cmml">a</mi><mo lspace="0em" rspace="0em" id="S5.p4.9.m9.1.1.1.1.3.3.1a" xref="S5.p4.9.m9.1.1.1.1.3.3.1.cmml">​</mo><mi id="S5.p4.9.m9.1.1.1.1.3.3.4" xref="S5.p4.9.m9.1.1.1.1.3.3.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S5.p4.9.m9.1.1.1.1.3.3.1b" xref="S5.p4.9.m9.1.1.1.1.3.3.1.cmml">​</mo><mi id="S5.p4.9.m9.1.1.1.1.3.3.5" xref="S5.p4.9.m9.1.1.1.1.3.3.5.cmml">k</mi></mrow></msub></mrow><mo stretchy="false" id="S5.p4.9.m9.1.1.1.3" xref="S5.p4.9.m9.1.1.1.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.p4.9.m9.1b"><apply id="S5.p4.9.m9.1.1.1.1.cmml" xref="S5.p4.9.m9.1.1.1"><plus id="S5.p4.9.m9.1.1.1.1.1.cmml" xref="S5.p4.9.m9.1.1.1.1.1"></plus><apply id="S5.p4.9.m9.1.1.1.1.2.cmml" xref="S5.p4.9.m9.1.1.1.1.2"><minus id="S5.p4.9.m9.1.1.1.1.2.1.cmml" xref="S5.p4.9.m9.1.1.1.1.2.1"></minus><cn type="integer" id="S5.p4.9.m9.1.1.1.1.2.2.cmml" xref="S5.p4.9.m9.1.1.1.1.2.2">1</cn><apply id="S5.p4.9.m9.1.1.1.1.2.3.cmml" xref="S5.p4.9.m9.1.1.1.1.2.3"><times id="S5.p4.9.m9.1.1.1.1.2.3.1.cmml" xref="S5.p4.9.m9.1.1.1.1.2.3.1"></times><ci id="S5.p4.9.m9.1.1.1.1.2.3.2.cmml" xref="S5.p4.9.m9.1.1.1.1.2.3.2">𝑠</ci><ci id="S5.p4.9.m9.1.1.1.1.2.3.3.cmml" xref="S5.p4.9.m9.1.1.1.1.2.3.3">𝑝</ci></apply></apply><apply id="S5.p4.9.m9.1.1.1.1.3.cmml" xref="S5.p4.9.m9.1.1.1.1.3"><csymbol cd="ambiguous" id="S5.p4.9.m9.1.1.1.1.3.1.cmml" xref="S5.p4.9.m9.1.1.1.1.3">subscript</csymbol><ci id="S5.p4.9.m9.1.1.1.1.3.2.cmml" xref="S5.p4.9.m9.1.1.1.1.3.2">𝑟</ci><apply id="S5.p4.9.m9.1.1.1.1.3.3.cmml" xref="S5.p4.9.m9.1.1.1.1.3.3"><times id="S5.p4.9.m9.1.1.1.1.3.3.1.cmml" xref="S5.p4.9.m9.1.1.1.1.3.3.1"></times><ci id="S5.p4.9.m9.1.1.1.1.3.3.2.cmml" xref="S5.p4.9.m9.1.1.1.1.3.3.2">𝑚</ci><ci id="S5.p4.9.m9.1.1.1.1.3.3.3.cmml" xref="S5.p4.9.m9.1.1.1.1.3.3.3">𝑎</ci><ci id="S5.p4.9.m9.1.1.1.1.3.3.4.cmml" xref="S5.p4.9.m9.1.1.1.1.3.3.4">𝑠</ci><ci id="S5.p4.9.m9.1.1.1.1.3.3.5.cmml" xref="S5.p4.9.m9.1.1.1.1.3.3.5">𝑘</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p4.9.m9.1c">(1-sp+r_{mask})</annotation></semantics></math> part will remain the same as during the previous round, while only the top <math id="S5.p4.10.m10.1" class="ltx_Math" alttext="(1-sp+r_{mask})" display="inline"><semantics id="S5.p4.10.m10.1a"><mrow id="S5.p4.10.m10.1.1.1" xref="S5.p4.10.m10.1.1.1.1.cmml"><mo stretchy="false" id="S5.p4.10.m10.1.1.1.2" xref="S5.p4.10.m10.1.1.1.1.cmml">(</mo><mrow id="S5.p4.10.m10.1.1.1.1" xref="S5.p4.10.m10.1.1.1.1.cmml"><mrow id="S5.p4.10.m10.1.1.1.1.2" xref="S5.p4.10.m10.1.1.1.1.2.cmml"><mn id="S5.p4.10.m10.1.1.1.1.2.2" xref="S5.p4.10.m10.1.1.1.1.2.2.cmml">1</mn><mo id="S5.p4.10.m10.1.1.1.1.2.1" xref="S5.p4.10.m10.1.1.1.1.2.1.cmml">−</mo><mrow id="S5.p4.10.m10.1.1.1.1.2.3" xref="S5.p4.10.m10.1.1.1.1.2.3.cmml"><mi id="S5.p4.10.m10.1.1.1.1.2.3.2" xref="S5.p4.10.m10.1.1.1.1.2.3.2.cmml">s</mi><mo lspace="0em" rspace="0em" id="S5.p4.10.m10.1.1.1.1.2.3.1" xref="S5.p4.10.m10.1.1.1.1.2.3.1.cmml">​</mo><mi id="S5.p4.10.m10.1.1.1.1.2.3.3" xref="S5.p4.10.m10.1.1.1.1.2.3.3.cmml">p</mi></mrow></mrow><mo id="S5.p4.10.m10.1.1.1.1.1" xref="S5.p4.10.m10.1.1.1.1.1.cmml">+</mo><msub id="S5.p4.10.m10.1.1.1.1.3" xref="S5.p4.10.m10.1.1.1.1.3.cmml"><mi id="S5.p4.10.m10.1.1.1.1.3.2" xref="S5.p4.10.m10.1.1.1.1.3.2.cmml">r</mi><mrow id="S5.p4.10.m10.1.1.1.1.3.3" xref="S5.p4.10.m10.1.1.1.1.3.3.cmml"><mi id="S5.p4.10.m10.1.1.1.1.3.3.2" xref="S5.p4.10.m10.1.1.1.1.3.3.2.cmml">m</mi><mo lspace="0em" rspace="0em" id="S5.p4.10.m10.1.1.1.1.3.3.1" xref="S5.p4.10.m10.1.1.1.1.3.3.1.cmml">​</mo><mi id="S5.p4.10.m10.1.1.1.1.3.3.3" xref="S5.p4.10.m10.1.1.1.1.3.3.3.cmml">a</mi><mo lspace="0em" rspace="0em" id="S5.p4.10.m10.1.1.1.1.3.3.1a" xref="S5.p4.10.m10.1.1.1.1.3.3.1.cmml">​</mo><mi id="S5.p4.10.m10.1.1.1.1.3.3.4" xref="S5.p4.10.m10.1.1.1.1.3.3.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S5.p4.10.m10.1.1.1.1.3.3.1b" xref="S5.p4.10.m10.1.1.1.1.3.3.1.cmml">​</mo><mi id="S5.p4.10.m10.1.1.1.1.3.3.5" xref="S5.p4.10.m10.1.1.1.1.3.3.5.cmml">k</mi></mrow></msub></mrow><mo stretchy="false" id="S5.p4.10.m10.1.1.1.3" xref="S5.p4.10.m10.1.1.1.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.p4.10.m10.1b"><apply id="S5.p4.10.m10.1.1.1.1.cmml" xref="S5.p4.10.m10.1.1.1"><plus id="S5.p4.10.m10.1.1.1.1.1.cmml" xref="S5.p4.10.m10.1.1.1.1.1"></plus><apply id="S5.p4.10.m10.1.1.1.1.2.cmml" xref="S5.p4.10.m10.1.1.1.1.2"><minus id="S5.p4.10.m10.1.1.1.1.2.1.cmml" xref="S5.p4.10.m10.1.1.1.1.2.1"></minus><cn type="integer" id="S5.p4.10.m10.1.1.1.1.2.2.cmml" xref="S5.p4.10.m10.1.1.1.1.2.2">1</cn><apply id="S5.p4.10.m10.1.1.1.1.2.3.cmml" xref="S5.p4.10.m10.1.1.1.1.2.3"><times id="S5.p4.10.m10.1.1.1.1.2.3.1.cmml" xref="S5.p4.10.m10.1.1.1.1.2.3.1"></times><ci id="S5.p4.10.m10.1.1.1.1.2.3.2.cmml" xref="S5.p4.10.m10.1.1.1.1.2.3.2">𝑠</ci><ci id="S5.p4.10.m10.1.1.1.1.2.3.3.cmml" xref="S5.p4.10.m10.1.1.1.1.2.3.3">𝑝</ci></apply></apply><apply id="S5.p4.10.m10.1.1.1.1.3.cmml" xref="S5.p4.10.m10.1.1.1.1.3"><csymbol cd="ambiguous" id="S5.p4.10.m10.1.1.1.1.3.1.cmml" xref="S5.p4.10.m10.1.1.1.1.3">subscript</csymbol><ci id="S5.p4.10.m10.1.1.1.1.3.2.cmml" xref="S5.p4.10.m10.1.1.1.1.3.2">𝑟</ci><apply id="S5.p4.10.m10.1.1.1.1.3.3.cmml" xref="S5.p4.10.m10.1.1.1.1.3.3"><times id="S5.p4.10.m10.1.1.1.1.3.3.1.cmml" xref="S5.p4.10.m10.1.1.1.1.3.3.1"></times><ci id="S5.p4.10.m10.1.1.1.1.3.3.2.cmml" xref="S5.p4.10.m10.1.1.1.1.3.3.2">𝑚</ci><ci id="S5.p4.10.m10.1.1.1.1.3.3.3.cmml" xref="S5.p4.10.m10.1.1.1.1.3.3.3">𝑎</ci><ci id="S5.p4.10.m10.1.1.1.1.3.3.4.cmml" xref="S5.p4.10.m10.1.1.1.1.3.3.4">𝑠</ci><ci id="S5.p4.10.m10.1.1.1.1.3.3.5.cmml" xref="S5.p4.10.m10.1.1.1.1.3.3.5">𝑘</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p4.10.m10.1c">(1-sp+r_{mask})</annotation></semantics></math> part of the weights will be updated.</p>
</div>
<div id="S5.p5" class="ltx_para ltx_noindent">
<p id="S5.p5.2" class="ltx_p"><span id="S5.p5.2.1" class="ltx_text ltx_font_bold">Top-K-Weights Diff.</span> Conversely to Diff on Top-K-Weights, this strategy proposed to first compute all the weights differences <math id="S5.p5.1.m1.1" class="ltx_Math" alttext="d" display="inline"><semantics id="S5.p5.1.m1.1a"><mi id="S5.p5.1.m1.1.1" xref="S5.p5.1.m1.1.1.cmml">d</mi><annotation-xml encoding="MathML-Content" id="S5.p5.1.m1.1b"><ci id="S5.p5.1.m1.1.1.cmml" xref="S5.p5.1.m1.1.1">𝑑</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.p5.1.m1.1c">d</annotation></semantics></math> and then only send the top <math id="S5.p5.2.m2.1" class="ltx_Math" alttext="(1-sp+r_{mask})" display="inline"><semantics id="S5.p5.2.m2.1a"><mrow id="S5.p5.2.m2.1.1.1" xref="S5.p5.2.m2.1.1.1.1.cmml"><mo stretchy="false" id="S5.p5.2.m2.1.1.1.2" xref="S5.p5.2.m2.1.1.1.1.cmml">(</mo><mrow id="S5.p5.2.m2.1.1.1.1" xref="S5.p5.2.m2.1.1.1.1.cmml"><mrow id="S5.p5.2.m2.1.1.1.1.2" xref="S5.p5.2.m2.1.1.1.1.2.cmml"><mn id="S5.p5.2.m2.1.1.1.1.2.2" xref="S5.p5.2.m2.1.1.1.1.2.2.cmml">1</mn><mo id="S5.p5.2.m2.1.1.1.1.2.1" xref="S5.p5.2.m2.1.1.1.1.2.1.cmml">−</mo><mrow id="S5.p5.2.m2.1.1.1.1.2.3" xref="S5.p5.2.m2.1.1.1.1.2.3.cmml"><mi id="S5.p5.2.m2.1.1.1.1.2.3.2" xref="S5.p5.2.m2.1.1.1.1.2.3.2.cmml">s</mi><mo lspace="0em" rspace="0em" id="S5.p5.2.m2.1.1.1.1.2.3.1" xref="S5.p5.2.m2.1.1.1.1.2.3.1.cmml">​</mo><mi id="S5.p5.2.m2.1.1.1.1.2.3.3" xref="S5.p5.2.m2.1.1.1.1.2.3.3.cmml">p</mi></mrow></mrow><mo id="S5.p5.2.m2.1.1.1.1.1" xref="S5.p5.2.m2.1.1.1.1.1.cmml">+</mo><msub id="S5.p5.2.m2.1.1.1.1.3" xref="S5.p5.2.m2.1.1.1.1.3.cmml"><mi id="S5.p5.2.m2.1.1.1.1.3.2" xref="S5.p5.2.m2.1.1.1.1.3.2.cmml">r</mi><mrow id="S5.p5.2.m2.1.1.1.1.3.3" xref="S5.p5.2.m2.1.1.1.1.3.3.cmml"><mi id="S5.p5.2.m2.1.1.1.1.3.3.2" xref="S5.p5.2.m2.1.1.1.1.3.3.2.cmml">m</mi><mo lspace="0em" rspace="0em" id="S5.p5.2.m2.1.1.1.1.3.3.1" xref="S5.p5.2.m2.1.1.1.1.3.3.1.cmml">​</mo><mi id="S5.p5.2.m2.1.1.1.1.3.3.3" xref="S5.p5.2.m2.1.1.1.1.3.3.3.cmml">a</mi><mo lspace="0em" rspace="0em" id="S5.p5.2.m2.1.1.1.1.3.3.1a" xref="S5.p5.2.m2.1.1.1.1.3.3.1.cmml">​</mo><mi id="S5.p5.2.m2.1.1.1.1.3.3.4" xref="S5.p5.2.m2.1.1.1.1.3.3.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S5.p5.2.m2.1.1.1.1.3.3.1b" xref="S5.p5.2.m2.1.1.1.1.3.3.1.cmml">​</mo><mi id="S5.p5.2.m2.1.1.1.1.3.3.5" xref="S5.p5.2.m2.1.1.1.1.3.3.5.cmml">k</mi></mrow></msub></mrow><mo stretchy="false" id="S5.p5.2.m2.1.1.1.3" xref="S5.p5.2.m2.1.1.1.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.p5.2.m2.1b"><apply id="S5.p5.2.m2.1.1.1.1.cmml" xref="S5.p5.2.m2.1.1.1"><plus id="S5.p5.2.m2.1.1.1.1.1.cmml" xref="S5.p5.2.m2.1.1.1.1.1"></plus><apply id="S5.p5.2.m2.1.1.1.1.2.cmml" xref="S5.p5.2.m2.1.1.1.1.2"><minus id="S5.p5.2.m2.1.1.1.1.2.1.cmml" xref="S5.p5.2.m2.1.1.1.1.2.1"></minus><cn type="integer" id="S5.p5.2.m2.1.1.1.1.2.2.cmml" xref="S5.p5.2.m2.1.1.1.1.2.2">1</cn><apply id="S5.p5.2.m2.1.1.1.1.2.3.cmml" xref="S5.p5.2.m2.1.1.1.1.2.3"><times id="S5.p5.2.m2.1.1.1.1.2.3.1.cmml" xref="S5.p5.2.m2.1.1.1.1.2.3.1"></times><ci id="S5.p5.2.m2.1.1.1.1.2.3.2.cmml" xref="S5.p5.2.m2.1.1.1.1.2.3.2">𝑠</ci><ci id="S5.p5.2.m2.1.1.1.1.2.3.3.cmml" xref="S5.p5.2.m2.1.1.1.1.2.3.3">𝑝</ci></apply></apply><apply id="S5.p5.2.m2.1.1.1.1.3.cmml" xref="S5.p5.2.m2.1.1.1.1.3"><csymbol cd="ambiguous" id="S5.p5.2.m2.1.1.1.1.3.1.cmml" xref="S5.p5.2.m2.1.1.1.1.3">subscript</csymbol><ci id="S5.p5.2.m2.1.1.1.1.3.2.cmml" xref="S5.p5.2.m2.1.1.1.1.3.2">𝑟</ci><apply id="S5.p5.2.m2.1.1.1.1.3.3.cmml" xref="S5.p5.2.m2.1.1.1.1.3.3"><times id="S5.p5.2.m2.1.1.1.1.3.3.1.cmml" xref="S5.p5.2.m2.1.1.1.1.3.3.1"></times><ci id="S5.p5.2.m2.1.1.1.1.3.3.2.cmml" xref="S5.p5.2.m2.1.1.1.1.3.3.2">𝑚</ci><ci id="S5.p5.2.m2.1.1.1.1.3.3.3.cmml" xref="S5.p5.2.m2.1.1.1.1.3.3.3">𝑎</ci><ci id="S5.p5.2.m2.1.1.1.1.3.3.4.cmml" xref="S5.p5.2.m2.1.1.1.1.3.3.4">𝑠</ci><ci id="S5.p5.2.m2.1.1.1.1.3.3.5.cmml" xref="S5.p5.2.m2.1.1.1.1.3.3.5">𝑘</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p5.2.m2.1c">(1-sp+r_{mask})</annotation></semantics></math> of them to the server. With this method, only highly moving weights will be considered.</p>
</div>
<div id="S5.p6" class="ltx_para ltx_noindent">
<p id="S5.p6.1" class="ltx_p">All the aforementioned local sparsification methods lead to substantial reductions in uplink communication costs. More precisely, total communications will be reduced by a factor of <math id="S5.p6.1.m1.1" class="ltx_Math" alttext="\left(r_{mask}-sp\right)/2" display="inline"><semantics id="S5.p6.1.m1.1a"><mrow id="S5.p6.1.m1.1.1" xref="S5.p6.1.m1.1.1.cmml"><mrow id="S5.p6.1.m1.1.1.1.1" xref="S5.p6.1.m1.1.1.1.1.1.cmml"><mo id="S5.p6.1.m1.1.1.1.1.2" xref="S5.p6.1.m1.1.1.1.1.1.cmml">(</mo><mrow id="S5.p6.1.m1.1.1.1.1.1" xref="S5.p6.1.m1.1.1.1.1.1.cmml"><msub id="S5.p6.1.m1.1.1.1.1.1.2" xref="S5.p6.1.m1.1.1.1.1.1.2.cmml"><mi id="S5.p6.1.m1.1.1.1.1.1.2.2" xref="S5.p6.1.m1.1.1.1.1.1.2.2.cmml">r</mi><mrow id="S5.p6.1.m1.1.1.1.1.1.2.3" xref="S5.p6.1.m1.1.1.1.1.1.2.3.cmml"><mi id="S5.p6.1.m1.1.1.1.1.1.2.3.2" xref="S5.p6.1.m1.1.1.1.1.1.2.3.2.cmml">m</mi><mo lspace="0em" rspace="0em" id="S5.p6.1.m1.1.1.1.1.1.2.3.1" xref="S5.p6.1.m1.1.1.1.1.1.2.3.1.cmml">​</mo><mi id="S5.p6.1.m1.1.1.1.1.1.2.3.3" xref="S5.p6.1.m1.1.1.1.1.1.2.3.3.cmml">a</mi><mo lspace="0em" rspace="0em" id="S5.p6.1.m1.1.1.1.1.1.2.3.1a" xref="S5.p6.1.m1.1.1.1.1.1.2.3.1.cmml">​</mo><mi id="S5.p6.1.m1.1.1.1.1.1.2.3.4" xref="S5.p6.1.m1.1.1.1.1.1.2.3.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S5.p6.1.m1.1.1.1.1.1.2.3.1b" xref="S5.p6.1.m1.1.1.1.1.1.2.3.1.cmml">​</mo><mi id="S5.p6.1.m1.1.1.1.1.1.2.3.5" xref="S5.p6.1.m1.1.1.1.1.1.2.3.5.cmml">k</mi></mrow></msub><mo id="S5.p6.1.m1.1.1.1.1.1.1" xref="S5.p6.1.m1.1.1.1.1.1.1.cmml">−</mo><mrow id="S5.p6.1.m1.1.1.1.1.1.3" xref="S5.p6.1.m1.1.1.1.1.1.3.cmml"><mi id="S5.p6.1.m1.1.1.1.1.1.3.2" xref="S5.p6.1.m1.1.1.1.1.1.3.2.cmml">s</mi><mo lspace="0em" rspace="0em" id="S5.p6.1.m1.1.1.1.1.1.3.1" xref="S5.p6.1.m1.1.1.1.1.1.3.1.cmml">​</mo><mi id="S5.p6.1.m1.1.1.1.1.1.3.3" xref="S5.p6.1.m1.1.1.1.1.1.3.3.cmml">p</mi></mrow></mrow><mo id="S5.p6.1.m1.1.1.1.1.3" xref="S5.p6.1.m1.1.1.1.1.1.cmml">)</mo></mrow><mo id="S5.p6.1.m1.1.1.2" xref="S5.p6.1.m1.1.1.2.cmml">/</mo><mn id="S5.p6.1.m1.1.1.3" xref="S5.p6.1.m1.1.1.3.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.p6.1.m1.1b"><apply id="S5.p6.1.m1.1.1.cmml" xref="S5.p6.1.m1.1.1"><divide id="S5.p6.1.m1.1.1.2.cmml" xref="S5.p6.1.m1.1.1.2"></divide><apply id="S5.p6.1.m1.1.1.1.1.1.cmml" xref="S5.p6.1.m1.1.1.1.1"><minus id="S5.p6.1.m1.1.1.1.1.1.1.cmml" xref="S5.p6.1.m1.1.1.1.1.1.1"></minus><apply id="S5.p6.1.m1.1.1.1.1.1.2.cmml" xref="S5.p6.1.m1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S5.p6.1.m1.1.1.1.1.1.2.1.cmml" xref="S5.p6.1.m1.1.1.1.1.1.2">subscript</csymbol><ci id="S5.p6.1.m1.1.1.1.1.1.2.2.cmml" xref="S5.p6.1.m1.1.1.1.1.1.2.2">𝑟</ci><apply id="S5.p6.1.m1.1.1.1.1.1.2.3.cmml" xref="S5.p6.1.m1.1.1.1.1.1.2.3"><times id="S5.p6.1.m1.1.1.1.1.1.2.3.1.cmml" xref="S5.p6.1.m1.1.1.1.1.1.2.3.1"></times><ci id="S5.p6.1.m1.1.1.1.1.1.2.3.2.cmml" xref="S5.p6.1.m1.1.1.1.1.1.2.3.2">𝑚</ci><ci id="S5.p6.1.m1.1.1.1.1.1.2.3.3.cmml" xref="S5.p6.1.m1.1.1.1.1.1.2.3.3">𝑎</ci><ci id="S5.p6.1.m1.1.1.1.1.1.2.3.4.cmml" xref="S5.p6.1.m1.1.1.1.1.1.2.3.4">𝑠</ci><ci id="S5.p6.1.m1.1.1.1.1.1.2.3.5.cmml" xref="S5.p6.1.m1.1.1.1.1.1.2.3.5">𝑘</ci></apply></apply><apply id="S5.p6.1.m1.1.1.1.1.1.3.cmml" xref="S5.p6.1.m1.1.1.1.1.1.3"><times id="S5.p6.1.m1.1.1.1.1.1.3.1.cmml" xref="S5.p6.1.m1.1.1.1.1.1.3.1"></times><ci id="S5.p6.1.m1.1.1.1.1.1.3.2.cmml" xref="S5.p6.1.m1.1.1.1.1.1.3.2">𝑠</ci><ci id="S5.p6.1.m1.1.1.1.1.1.3.3.cmml" xref="S5.p6.1.m1.1.1.1.1.1.3.3">𝑝</ci></apply></apply><cn type="integer" id="S5.p6.1.m1.1.1.3.cmml" xref="S5.p6.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p6.1.m1.1c">\left(r_{mask}-sp\right)/2</annotation></semantics></math>.</p>
</div>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>ZeroFL: Experimental Results</h2>

<div id="S6.p1" class="ltx_para ltx_noindent">
<p id="S6.p1.1" class="ltx_p">We conducted extensive experiments on CIFAR10, Speech Commands <cite class="ltx_cite ltx_citemacro_citep">(Warden, <a href="#bib.bib54" title="" class="ltx_ref">2018</a>)</cite> and FEMNIST <cite class="ltx_cite ltx_citemacro_citep">(Caldas et al., <a href="#bib.bib4" title="" class="ltx_ref">2018</a>)</cite> datasets. The CIFAR10 experiments follow the same experimental protocol as for baselines experiments. The three local sparsification strategies are compared with various mask ratio <math id="S6.p1.1.m1.3" class="ltx_Math" alttext="r_{mask}=\{0.0,0.1,0.2\}" display="inline"><semantics id="S6.p1.1.m1.3a"><mrow id="S6.p1.1.m1.3.4" xref="S6.p1.1.m1.3.4.cmml"><msub id="S6.p1.1.m1.3.4.2" xref="S6.p1.1.m1.3.4.2.cmml"><mi id="S6.p1.1.m1.3.4.2.2" xref="S6.p1.1.m1.3.4.2.2.cmml">r</mi><mrow id="S6.p1.1.m1.3.4.2.3" xref="S6.p1.1.m1.3.4.2.3.cmml"><mi id="S6.p1.1.m1.3.4.2.3.2" xref="S6.p1.1.m1.3.4.2.3.2.cmml">m</mi><mo lspace="0em" rspace="0em" id="S6.p1.1.m1.3.4.2.3.1" xref="S6.p1.1.m1.3.4.2.3.1.cmml">​</mo><mi id="S6.p1.1.m1.3.4.2.3.3" xref="S6.p1.1.m1.3.4.2.3.3.cmml">a</mi><mo lspace="0em" rspace="0em" id="S6.p1.1.m1.3.4.2.3.1a" xref="S6.p1.1.m1.3.4.2.3.1.cmml">​</mo><mi id="S6.p1.1.m1.3.4.2.3.4" xref="S6.p1.1.m1.3.4.2.3.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S6.p1.1.m1.3.4.2.3.1b" xref="S6.p1.1.m1.3.4.2.3.1.cmml">​</mo><mi id="S6.p1.1.m1.3.4.2.3.5" xref="S6.p1.1.m1.3.4.2.3.5.cmml">k</mi></mrow></msub><mo id="S6.p1.1.m1.3.4.1" xref="S6.p1.1.m1.3.4.1.cmml">=</mo><mrow id="S6.p1.1.m1.3.4.3.2" xref="S6.p1.1.m1.3.4.3.1.cmml"><mo stretchy="false" id="S6.p1.1.m1.3.4.3.2.1" xref="S6.p1.1.m1.3.4.3.1.cmml">{</mo><mn id="S6.p1.1.m1.1.1" xref="S6.p1.1.m1.1.1.cmml">0.0</mn><mo id="S6.p1.1.m1.3.4.3.2.2" xref="S6.p1.1.m1.3.4.3.1.cmml">,</mo><mn id="S6.p1.1.m1.2.2" xref="S6.p1.1.m1.2.2.cmml">0.1</mn><mo id="S6.p1.1.m1.3.4.3.2.3" xref="S6.p1.1.m1.3.4.3.1.cmml">,</mo><mn id="S6.p1.1.m1.3.3" xref="S6.p1.1.m1.3.3.cmml">0.2</mn><mo stretchy="false" id="S6.p1.1.m1.3.4.3.2.4" xref="S6.p1.1.m1.3.4.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S6.p1.1.m1.3b"><apply id="S6.p1.1.m1.3.4.cmml" xref="S6.p1.1.m1.3.4"><eq id="S6.p1.1.m1.3.4.1.cmml" xref="S6.p1.1.m1.3.4.1"></eq><apply id="S6.p1.1.m1.3.4.2.cmml" xref="S6.p1.1.m1.3.4.2"><csymbol cd="ambiguous" id="S6.p1.1.m1.3.4.2.1.cmml" xref="S6.p1.1.m1.3.4.2">subscript</csymbol><ci id="S6.p1.1.m1.3.4.2.2.cmml" xref="S6.p1.1.m1.3.4.2.2">𝑟</ci><apply id="S6.p1.1.m1.3.4.2.3.cmml" xref="S6.p1.1.m1.3.4.2.3"><times id="S6.p1.1.m1.3.4.2.3.1.cmml" xref="S6.p1.1.m1.3.4.2.3.1"></times><ci id="S6.p1.1.m1.3.4.2.3.2.cmml" xref="S6.p1.1.m1.3.4.2.3.2">𝑚</ci><ci id="S6.p1.1.m1.3.4.2.3.3.cmml" xref="S6.p1.1.m1.3.4.2.3.3">𝑎</ci><ci id="S6.p1.1.m1.3.4.2.3.4.cmml" xref="S6.p1.1.m1.3.4.2.3.4">𝑠</ci><ci id="S6.p1.1.m1.3.4.2.3.5.cmml" xref="S6.p1.1.m1.3.4.2.3.5">𝑘</ci></apply></apply><set id="S6.p1.1.m1.3.4.3.1.cmml" xref="S6.p1.1.m1.3.4.3.2"><cn type="float" id="S6.p1.1.m1.1.1.cmml" xref="S6.p1.1.m1.1.1">0.0</cn><cn type="float" id="S6.p1.1.m1.2.2.cmml" xref="S6.p1.1.m1.2.2">0.1</cn><cn type="float" id="S6.p1.1.m1.3.3.cmml" xref="S6.p1.1.m1.3.3">0.2</cn></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.p1.1.m1.3c">r_{mask}=\{0.0,0.1,0.2\}</annotation></semantics></math> and to vanilla SWAT without ZeroFL. Similarly to results obtained in Section <a href="#S4.SS2" title="4.2 Baselines Results ‣ 4 Sparse Training for Federated Learning ‣ ZeroFL: Efficient On-Device Training for Federated Learning with Local Sparsity" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.2</span></a>, sparse training performs better with exponential learning rate decay. Hence, all setups are investigated with this scheduler. Table <a href="#S6.T1" title="Table 1 ‣ 6 ZeroFL: Experimental Results ‣ ZeroFL: Efficient On-Device Training for Federated Learning with Local Sparsity" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> reports the test accuracies achieved as well as the gain in communication cost when applying ZeroFL.</p>
</div>
<figure id="S6.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Results with ZeroFL on CIFAR10 and SpeechCommands for both IID (<math id="S6.T1.10.m1.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S6.T1.10.m1.1b"><mi id="S6.T1.10.m1.1.1" xref="S6.T1.10.m1.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S6.T1.10.m1.1c"><ci id="S6.T1.10.m1.1.1.cmml" xref="S6.T1.10.m1.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T1.10.m1.1d">\alpha</annotation></semantics></math><math id="S6.T1.11.m2.1" class="ltx_Math" alttext="=" display="inline"><semantics id="S6.T1.11.m2.1b"><mo id="S6.T1.11.m2.1.1" xref="S6.T1.11.m2.1.1.cmml">=</mo><annotation-xml encoding="MathML-Content" id="S6.T1.11.m2.1c"><eq id="S6.T1.11.m2.1.1.cmml" xref="S6.T1.11.m2.1.1"></eq></annotation-xml><annotation encoding="application/x-tex" id="S6.T1.11.m2.1d">=</annotation></semantics></math><math id="S6.T1.12.m3.1" class="ltx_Math" alttext="1.0" display="inline"><semantics id="S6.T1.12.m3.1b"><mn id="S6.T1.12.m3.1.1" xref="S6.T1.12.m3.1.1.cmml">1.0</mn><annotation-xml encoding="MathML-Content" id="S6.T1.12.m3.1c"><cn type="float" id="S6.T1.12.m3.1.1.cmml" xref="S6.T1.12.m3.1.1">1.0</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.T1.12.m3.1d">1.0</annotation></semantics></math>) and non-IID (<math id="S6.T1.13.m4.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S6.T1.13.m4.1b"><mi id="S6.T1.13.m4.1.1" xref="S6.T1.13.m4.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S6.T1.13.m4.1c"><ci id="S6.T1.13.m4.1.1.cmml" xref="S6.T1.13.m4.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T1.13.m4.1d">\alpha</annotation></semantics></math><math id="S6.T1.14.m5.1" class="ltx_Math" alttext="=" display="inline"><semantics id="S6.T1.14.m5.1b"><mo id="S6.T1.14.m5.1.1" xref="S6.T1.14.m5.1.1.cmml">=</mo><annotation-xml encoding="MathML-Content" id="S6.T1.14.m5.1c"><eq id="S6.T1.14.m5.1.1.cmml" xref="S6.T1.14.m5.1.1"></eq></annotation-xml><annotation encoding="application/x-tex" id="S6.T1.14.m5.1d">=</annotation></semantics></math><math id="S6.T1.15.m6.1" class="ltx_Math" alttext="1000" display="inline"><semantics id="S6.T1.15.m6.1b"><mn id="S6.T1.15.m6.1.1" xref="S6.T1.15.m6.1.1.cmml">1000</mn><annotation-xml encoding="MathML-Content" id="S6.T1.15.m6.1c"><cn type="integer" id="S6.T1.15.m6.1.1.cmml" xref="S6.T1.15.m6.1.1">1000</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.T1.15.m6.1d">1000</annotation></semantics></math>) settings. We report the
test accuracy at <math id="S6.T1.16.m7.1" class="ltx_Math" alttext="700" display="inline"><semantics id="S6.T1.16.m7.1b"><mn id="S6.T1.16.m7.1.1" xref="S6.T1.16.m7.1.1.cmml">700</mn><annotation-xml encoding="MathML-Content" id="S6.T1.16.m7.1c"><cn type="integer" id="S6.T1.16.m7.1.1.cmml" xref="S6.T1.16.m7.1.1">700</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.T1.16.m7.1d">700</annotation></semantics></math>, <math id="S6.T1.17.m8.1" class="ltx_Math" alttext="200" display="inline"><semantics id="S6.T1.17.m8.1b"><mn id="S6.T1.17.m8.1.1" xref="S6.T1.17.m8.1.1.cmml">200</mn><annotation-xml encoding="MathML-Content" id="S6.T1.17.m8.1c"><cn type="integer" id="S6.T1.17.m8.1.1.cmml" xref="S6.T1.17.m8.1.1">200</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.T1.17.m8.1d">200</annotation></semantics></math> and 1K communication rounds respectively for CIFAR10, Speech Commands and FEMNIST. We report the size (in MB) of the artifact to be transmitted to the server for aggregation, which has been compressed following the CSR sparse format representation. ZeroFL improves the performance while reducing the uplink communication cost up to a factor of <math id="S6.T1.18.m9.1" class="ltx_math_unparsed" alttext="7.4\times" display="inline"><semantics id="S6.T1.18.m9.1b"><mrow id="S6.T1.18.m9.1c"><mn id="S6.T1.18.m9.1.1">7.4</mn><mo lspace="0.222em" id="S6.T1.18.m9.1.2">×</mo></mrow><annotation encoding="application/x-tex" id="S6.T1.18.m9.1d">7.4\times</annotation></semantics></math> compared to vanilla SWAT. For each sparsity level and dataset, we highlight in bold the best masking strategy. For clarity we do this on the non-IID results only. More results can be found in Appendix.</figcaption>
<div id="S6.T1.38" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:407.9pt;height:230.3pt;vertical-align:-0.6pt;"><span class="ltx_transformed_inner" style="transform:translate(-147.7pt,83.2pt) scale(0.58,0.58) ;">
<table id="S6.T1.38.20" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S6.T1.38.20.21.1" class="ltx_tr">
<th id="S6.T1.38.20.21.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt"><span id="S6.T1.38.20.21.1.1.1" class="ltx_text ltx_font_bold">Dataset</span></th>
<th id="S6.T1.38.20.21.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt"><span id="S6.T1.38.20.21.1.2.1" class="ltx_text ltx_font_bold">Sp</span></th>
<th id="S6.T1.38.20.21.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt"><span id="S6.T1.38.20.21.1.3.1" class="ltx_text ltx_font_bold">Mask</span></th>
<th id="S6.T1.38.20.21.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="2"><span id="S6.T1.38.20.21.1.4.1" class="ltx_text ltx_font_bold">Full Model</span></th>
<th id="S6.T1.38.20.21.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="2"><span id="S6.T1.38.20.21.1.5.1" class="ltx_text ltx_font_bold">Top-K-W.</span></th>
<th id="S6.T1.38.20.21.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="2"><span id="S6.T1.38.20.21.1.6.1" class="ltx_text ltx_font_bold">Diff. Top-K-W.</span></th>
<th id="S6.T1.38.20.21.1.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="2"><span id="S6.T1.38.20.21.1.7.1" class="ltx_text ltx_font_bold">Top-K-W. Diff</span></th>
<th id="S6.T1.38.20.21.1.8" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt"><span id="S6.T1.38.20.21.1.8.1" class="ltx_text ltx_font_bold">File</span></th>
<th id="S6.T1.38.20.21.1.9" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S6.T1.38.20.21.1.9.1" class="ltx_text ltx_font_bold">Comms.</span></th>
</tr>
<tr id="S6.T1.38.20.22.2" class="ltx_tr">
<th id="S6.T1.38.20.22.2.1" class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r"></th>
<th id="S6.T1.38.20.22.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r"><span id="S6.T1.38.20.22.2.2.1" class="ltx_text ltx_font_bold">Level</span></th>
<th id="S6.T1.38.20.22.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r"><span id="S6.T1.38.20.22.2.3.1" class="ltx_text ltx_font_bold">Ratio</span></th>
<th id="S6.T1.38.20.22.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column">IID</th>
<th id="S6.T1.38.20.22.2.5" class="ltx_td ltx_align_center ltx_th ltx_th_column">NIID</th>
<th id="S6.T1.38.20.22.2.6" class="ltx_td ltx_align_center ltx_th ltx_th_column">IID</th>
<th id="S6.T1.38.20.22.2.7" class="ltx_td ltx_align_center ltx_th ltx_th_column">NIID</th>
<th id="S6.T1.38.20.22.2.8" class="ltx_td ltx_align_center ltx_th ltx_th_column">IID</th>
<th id="S6.T1.38.20.22.2.9" class="ltx_td ltx_align_center ltx_th ltx_th_column">NIID</th>
<th id="S6.T1.38.20.22.2.10" class="ltx_td ltx_align_center ltx_th ltx_th_column">IID</th>
<th id="S6.T1.38.20.22.2.11" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r">NIID</th>
<th id="S6.T1.38.20.22.2.12" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r"><span id="S6.T1.38.20.22.2.12.1" class="ltx_text ltx_font_bold">Size</span></th>
<th id="S6.T1.38.20.22.2.13" class="ltx_td ltx_align_center ltx_th ltx_th_column"><span id="S6.T1.38.20.22.2.13.1" class="ltx_text ltx_font_bold">Savings</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S6.T1.19.1.1" class="ltx_tr">
<th id="S6.T1.19.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" rowspan="8"><span id="S6.T1.19.1.1.2.1" class="ltx_text">
<span id="S6.T1.19.1.1.2.1.1" class="ltx_inline-block ltx_parbox ltx_align_middle" style="width:51.2pt;">
<span id="S6.T1.19.1.1.2.1.1.1" class="ltx_p">CIFAR-10 (100 clients)</span>
</span></span></th>
<th id="S6.T1.19.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" rowspan="4"><span id="S6.T1.19.1.1.3.1" class="ltx_text">90 %</span></th>
<th id="S6.T1.19.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">—</th>
<td id="S6.T1.19.1.1.5" class="ltx_td ltx_align_center ltx_border_t">82.82±0.64</td>
<td id="S6.T1.19.1.1.6" class="ltx_td ltx_align_center ltx_border_t">80.62±0.72</td>
<td id="S6.T1.19.1.1.7" class="ltx_td ltx_border_t"></td>
<td id="S6.T1.19.1.1.8" class="ltx_td ltx_border_t"></td>
<td id="S6.T1.19.1.1.9" class="ltx_td ltx_border_t"></td>
<td id="S6.T1.19.1.1.10" class="ltx_td ltx_border_t"></td>
<td id="S6.T1.19.1.1.11" class="ltx_td ltx_border_t"></td>
<td id="S6.T1.19.1.1.12" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="S6.T1.19.1.1.13" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">43.7</td>
<td id="S6.T1.19.1.1.1" class="ltx_td ltx_align_center ltx_border_t">1<math id="S6.T1.19.1.1.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S6.T1.19.1.1.1.m1.1a"><mo id="S6.T1.19.1.1.1.m1.1.1" xref="S6.T1.19.1.1.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S6.T1.19.1.1.1.m1.1b"><times id="S6.T1.19.1.1.1.m1.1.1.cmml" xref="S6.T1.19.1.1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S6.T1.19.1.1.1.m1.1c">\times</annotation></semantics></math>
</td>
</tr>
<tr id="S6.T1.20.2.2" class="ltx_tr">
<th id="S6.T1.20.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">0.0</th>
<td id="S6.T1.20.2.2.3" class="ltx_td"></td>
<td id="S6.T1.20.2.2.4" class="ltx_td"></td>
<td id="S6.T1.20.2.2.5" class="ltx_td ltx_align_center">76.52±0.28</td>
<td id="S6.T1.20.2.2.6" class="ltx_td ltx_align_center">73.87±0.50</td>
<td id="S6.T1.20.2.2.7" class="ltx_td ltx_align_center">76.62±0.42</td>
<td id="S6.T1.20.2.2.8" class="ltx_td ltx_align_center">73.22±1.18</td>
<td id="S6.T1.20.2.2.9" class="ltx_td ltx_align_center">76.91±0.75</td>
<td id="S6.T1.20.2.2.10" class="ltx_td ltx_align_center ltx_border_r">72.71±1.11</td>
<td id="S6.T1.20.2.2.11" class="ltx_td ltx_align_center ltx_border_r">10.1</td>
<td id="S6.T1.20.2.2.1" class="ltx_td ltx_align_center">4.3<math id="S6.T1.20.2.2.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S6.T1.20.2.2.1.m1.1a"><mo id="S6.T1.20.2.2.1.m1.1.1" xref="S6.T1.20.2.2.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S6.T1.20.2.2.1.m1.1b"><times id="S6.T1.20.2.2.1.m1.1.1.cmml" xref="S6.T1.20.2.2.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S6.T1.20.2.2.1.m1.1c">\times</annotation></semantics></math>
</td>
</tr>
<tr id="S6.T1.21.3.3" class="ltx_tr">
<th id="S6.T1.21.3.3.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">0.1</th>
<td id="S6.T1.21.3.3.3" class="ltx_td"></td>
<td id="S6.T1.21.3.3.4" class="ltx_td"></td>
<td id="S6.T1.21.3.3.5" class="ltx_td ltx_align_center">82.14±0.58</td>
<td id="S6.T1.21.3.3.6" class="ltx_td ltx_align_center">79.84±0.62</td>
<td id="S6.T1.21.3.3.7" class="ltx_td ltx_align_center">82.64±0.49</td>
<td id="S6.T1.21.3.3.8" class="ltx_td ltx_align_center">79.58±1.09</td>
<td id="S6.T1.21.3.3.9" class="ltx_td ltx_align_center">82.32±0.75</td>
<td id="S6.T1.21.3.3.10" class="ltx_td ltx_align_center ltx_border_r">80.17±0.48</td>
<td id="S6.T1.21.3.3.11" class="ltx_td ltx_align_center ltx_border_r">18.7</td>
<td id="S6.T1.21.3.3.1" class="ltx_td ltx_align_center">2.3<math id="S6.T1.21.3.3.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S6.T1.21.3.3.1.m1.1a"><mo id="S6.T1.21.3.3.1.m1.1.1" xref="S6.T1.21.3.3.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S6.T1.21.3.3.1.m1.1b"><times id="S6.T1.21.3.3.1.m1.1.1.cmml" xref="S6.T1.21.3.3.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S6.T1.21.3.3.1.m1.1c">\times</annotation></semantics></math>
</td>
</tr>
<tr id="S6.T1.22.4.4" class="ltx_tr">
<th id="S6.T1.22.4.4.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">0.2</th>
<td id="S6.T1.22.4.4.3" class="ltx_td"></td>
<td id="S6.T1.22.4.4.4" class="ltx_td"></td>
<td id="S6.T1.22.4.4.5" class="ltx_td ltx_align_center">82.62±0.60</td>
<td id="S6.T1.22.4.4.6" class="ltx_td ltx_align_center"><span id="S6.T1.22.4.4.6.1" class="ltx_text ltx_font_bold">81.04±0.28</span></td>
<td id="S6.T1.22.4.4.7" class="ltx_td ltx_align_center">82.67±0.26</td>
<td id="S6.T1.22.4.4.8" class="ltx_td ltx_align_center">79.74±1.35</td>
<td id="S6.T1.22.4.4.9" class="ltx_td ltx_align_center">82.71±0.37</td>
<td id="S6.T1.22.4.4.10" class="ltx_td ltx_align_center ltx_border_r">79.95±1.09</td>
<td id="S6.T1.22.4.4.11" class="ltx_td ltx_align_center ltx_border_r">27.3</td>
<td id="S6.T1.22.4.4.1" class="ltx_td ltx_align_center">1.6<math id="S6.T1.22.4.4.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S6.T1.22.4.4.1.m1.1a"><mo id="S6.T1.22.4.4.1.m1.1.1" xref="S6.T1.22.4.4.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S6.T1.22.4.4.1.m1.1b"><times id="S6.T1.22.4.4.1.m1.1.1.cmml" xref="S6.T1.22.4.4.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S6.T1.22.4.4.1.m1.1c">\times</annotation></semantics></math>
</td>
</tr>
<tr id="S6.T1.23.5.5" class="ltx_tr">
<th id="S6.T1.23.5.5.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" rowspan="4"><span id="S6.T1.23.5.5.2.1" class="ltx_text">95 %</span></th>
<th id="S6.T1.23.5.5.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">—</th>
<td id="S6.T1.23.5.5.4" class="ltx_td ltx_align_center ltx_border_t">79.13±0.91</td>
<td id="S6.T1.23.5.5.5" class="ltx_td ltx_align_center ltx_border_t">74.00±0.74</td>
<td id="S6.T1.23.5.5.6" class="ltx_td ltx_border_t"></td>
<td id="S6.T1.23.5.5.7" class="ltx_td ltx_border_t"></td>
<td id="S6.T1.23.5.5.8" class="ltx_td ltx_border_t"></td>
<td id="S6.T1.23.5.5.9" class="ltx_td ltx_border_t"></td>
<td id="S6.T1.23.5.5.10" class="ltx_td ltx_border_t"></td>
<td id="S6.T1.23.5.5.11" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="S6.T1.23.5.5.12" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">43.7</td>
<td id="S6.T1.23.5.5.1" class="ltx_td ltx_align_center ltx_border_t">1<math id="S6.T1.23.5.5.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S6.T1.23.5.5.1.m1.1a"><mo id="S6.T1.23.5.5.1.m1.1.1" xref="S6.T1.23.5.5.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S6.T1.23.5.5.1.m1.1b"><times id="S6.T1.23.5.5.1.m1.1.1.cmml" xref="S6.T1.23.5.5.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S6.T1.23.5.5.1.m1.1c">\times</annotation></semantics></math>
</td>
</tr>
<tr id="S6.T1.24.6.6" class="ltx_tr">
<th id="S6.T1.24.6.6.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">0.0</th>
<td id="S6.T1.24.6.6.3" class="ltx_td"></td>
<td id="S6.T1.24.6.6.4" class="ltx_td"></td>
<td id="S6.T1.24.6.6.5" class="ltx_td ltx_align_center">68.66±0.39</td>
<td id="S6.T1.24.6.6.6" class="ltx_td ltx_align_center">65.38±0.60</td>
<td id="S6.T1.24.6.6.7" class="ltx_td ltx_align_center">69.33±1.03</td>
<td id="S6.T1.24.6.6.8" class="ltx_td ltx_align_center">66.05±1.32</td>
<td id="S6.T1.24.6.6.9" class="ltx_td ltx_align_center">69.21±0.09</td>
<td id="S6.T1.24.6.6.10" class="ltx_td ltx_align_center ltx_border_r">64.86±0.72</td>
<td id="S6.T1.24.6.6.11" class="ltx_td ltx_align_center ltx_border_r">5.9</td>
<td id="S6.T1.24.6.6.1" class="ltx_td ltx_align_center">7.4<math id="S6.T1.24.6.6.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S6.T1.24.6.6.1.m1.1a"><mo id="S6.T1.24.6.6.1.m1.1.1" xref="S6.T1.24.6.6.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S6.T1.24.6.6.1.m1.1b"><times id="S6.T1.24.6.6.1.m1.1.1.cmml" xref="S6.T1.24.6.6.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S6.T1.24.6.6.1.m1.1c">\times</annotation></semantics></math>
</td>
</tr>
<tr id="S6.T1.25.7.7" class="ltx_tr">
<th id="S6.T1.25.7.7.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">0.1</th>
<td id="S6.T1.25.7.7.3" class="ltx_td"></td>
<td id="S6.T1.25.7.7.4" class="ltx_td"></td>
<td id="S6.T1.25.7.7.5" class="ltx_td ltx_align_center">76.15±0.75</td>
<td id="S6.T1.25.7.7.6" class="ltx_td ltx_align_center">73.65±0.54</td>
<td id="S6.T1.25.7.7.7" class="ltx_td ltx_align_center">76.72±0.46</td>
<td id="S6.T1.25.7.7.8" class="ltx_td ltx_align_center">73.03±0.32</td>
<td id="S6.T1.25.7.7.9" class="ltx_td ltx_align_center">76.44±1.12</td>
<td id="S6.T1.25.7.7.10" class="ltx_td ltx_align_center ltx_border_r">73.06±3.93</td>
<td id="S6.T1.25.7.7.11" class="ltx_td ltx_align_center ltx_border_r">14.4</td>
<td id="S6.T1.25.7.7.1" class="ltx_td ltx_align_center">3.0<math id="S6.T1.25.7.7.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S6.T1.25.7.7.1.m1.1a"><mo id="S6.T1.25.7.7.1.m1.1.1" xref="S6.T1.25.7.7.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S6.T1.25.7.7.1.m1.1b"><times id="S6.T1.25.7.7.1.m1.1.1.cmml" xref="S6.T1.25.7.7.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S6.T1.25.7.7.1.m1.1c">\times</annotation></semantics></math>
</td>
</tr>
<tr id="S6.T1.26.8.8" class="ltx_tr">
<th id="S6.T1.26.8.8.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">0.2</th>
<td id="S6.T1.26.8.8.3" class="ltx_td"></td>
<td id="S6.T1.26.8.8.4" class="ltx_td"></td>
<td id="S6.T1.26.8.8.5" class="ltx_td ltx_align_center">76.96±1.86</td>
<td id="S6.T1.26.8.8.6" class="ltx_td ltx_align_center"><span id="S6.T1.26.8.8.6.1" class="ltx_text ltx_font_bold">75.54±1.15</span></td>
<td id="S6.T1.26.8.8.7" class="ltx_td ltx_align_center">78.22±0.35</td>
<td id="S6.T1.26.8.8.8" class="ltx_td ltx_align_center">73.08±1.56</td>
<td id="S6.T1.26.8.8.9" class="ltx_td ltx_align_center">77.69±0.78</td>
<td id="S6.T1.26.8.8.10" class="ltx_td ltx_align_center ltx_border_r">72.53±2.81</td>
<td id="S6.T1.26.8.8.11" class="ltx_td ltx_align_center ltx_border_r">23.0</td>
<td id="S6.T1.26.8.8.1" class="ltx_td ltx_align_center">1.9<math id="S6.T1.26.8.8.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S6.T1.26.8.8.1.m1.1a"><mo id="S6.T1.26.8.8.1.m1.1.1" xref="S6.T1.26.8.8.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S6.T1.26.8.8.1.m1.1b"><times id="S6.T1.26.8.8.1.m1.1.1.cmml" xref="S6.T1.26.8.8.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S6.T1.26.8.8.1.m1.1c">\times</annotation></semantics></math>
</td>
</tr>
<tr id="S6.T1.27.9.9" class="ltx_tr">
<th id="S6.T1.27.9.9.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" rowspan="8"><span id="S6.T1.27.9.9.2.1" class="ltx_text">
<span id="S6.T1.27.9.9.2.1.1" class="ltx_inline-block ltx_parbox ltx_align_middle" style="width:51.2pt;">
<span id="S6.T1.27.9.9.2.1.1.1" class="ltx_p">Speech Commands (100 clients)</span>
</span></span></th>
<th id="S6.T1.27.9.9.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" rowspan="4"><span id="S6.T1.27.9.9.3.1" class="ltx_text">90 %</span></th>
<th id="S6.T1.27.9.9.4" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">—</th>
<td id="S6.T1.27.9.9.5" class="ltx_td ltx_align_center ltx_border_t">85.95±0.52</td>
<td id="S6.T1.27.9.9.6" class="ltx_td ltx_align_center ltx_border_t">82.81±1.21</td>
<td id="S6.T1.27.9.9.7" class="ltx_td ltx_border_t"></td>
<td id="S6.T1.27.9.9.8" class="ltx_td ltx_border_t"></td>
<td id="S6.T1.27.9.9.9" class="ltx_td ltx_border_t"></td>
<td id="S6.T1.27.9.9.10" class="ltx_td ltx_border_t"></td>
<td id="S6.T1.27.9.9.11" class="ltx_td ltx_border_t"></td>
<td id="S6.T1.27.9.9.12" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="S6.T1.27.9.9.13" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">43.7</td>
<td id="S6.T1.27.9.9.1" class="ltx_td ltx_align_center ltx_border_t">1<math id="S6.T1.27.9.9.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S6.T1.27.9.9.1.m1.1a"><mo id="S6.T1.27.9.9.1.m1.1.1" xref="S6.T1.27.9.9.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S6.T1.27.9.9.1.m1.1b"><times id="S6.T1.27.9.9.1.m1.1.1.cmml" xref="S6.T1.27.9.9.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S6.T1.27.9.9.1.m1.1c">\times</annotation></semantics></math>
</td>
</tr>
<tr id="S6.T1.28.10.10" class="ltx_tr">
<th id="S6.T1.28.10.10.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">0.0</th>
<td id="S6.T1.28.10.10.3" class="ltx_td"></td>
<td id="S6.T1.28.10.10.4" class="ltx_td"></td>
<td id="S6.T1.28.10.10.5" class="ltx_td ltx_align_center">73.54±2.59</td>
<td id="S6.T1.28.10.10.6" class="ltx_td ltx_align_center">71.70±1.99</td>
<td id="S6.T1.28.10.10.7" class="ltx_td ltx_align_center">74.45±0.30</td>
<td id="S6.T1.28.10.10.8" class="ltx_td ltx_align_center">67.46±2.79</td>
<td id="S6.T1.28.10.10.9" class="ltx_td ltx_align_center">81.39±1.78</td>
<td id="S6.T1.28.10.10.10" class="ltx_td ltx_align_center ltx_border_r">72.80±2.54</td>
<td id="S6.T1.28.10.10.11" class="ltx_td ltx_align_center ltx_border_r">10.1</td>
<td id="S6.T1.28.10.10.1" class="ltx_td ltx_align_center">4.3<math id="S6.T1.28.10.10.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S6.T1.28.10.10.1.m1.1a"><mo id="S6.T1.28.10.10.1.m1.1.1" xref="S6.T1.28.10.10.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S6.T1.28.10.10.1.m1.1b"><times id="S6.T1.28.10.10.1.m1.1.1.cmml" xref="S6.T1.28.10.10.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S6.T1.28.10.10.1.m1.1c">\times</annotation></semantics></math>
</td>
</tr>
<tr id="S6.T1.29.11.11" class="ltx_tr">
<th id="S6.T1.29.11.11.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">0.1</th>
<td id="S6.T1.29.11.11.3" class="ltx_td"></td>
<td id="S6.T1.29.11.11.4" class="ltx_td"></td>
<td id="S6.T1.29.11.11.5" class="ltx_td ltx_align_center">86.30±0.62</td>
<td id="S6.T1.29.11.11.6" class="ltx_td ltx_align_center">83.70±2.25</td>
<td id="S6.T1.29.11.11.7" class="ltx_td ltx_align_center">85.46±0.27</td>
<td id="S6.T1.29.11.11.8" class="ltx_td ltx_align_center">83.41±1.91</td>
<td id="S6.T1.29.11.11.9" class="ltx_td ltx_align_center">85.81±0.11</td>
<td id="S6.T1.29.11.11.10" class="ltx_td ltx_align_center ltx_border_r">83.83±1.48</td>
<td id="S6.T1.29.11.11.11" class="ltx_td ltx_align_center ltx_border_r">18.7</td>
<td id="S6.T1.29.11.11.1" class="ltx_td ltx_align_center">2.3<math id="S6.T1.29.11.11.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S6.T1.29.11.11.1.m1.1a"><mo id="S6.T1.29.11.11.1.m1.1.1" xref="S6.T1.29.11.11.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S6.T1.29.11.11.1.m1.1b"><times id="S6.T1.29.11.11.1.m1.1.1.cmml" xref="S6.T1.29.11.11.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S6.T1.29.11.11.1.m1.1c">\times</annotation></semantics></math>
</td>
</tr>
<tr id="S6.T1.30.12.12" class="ltx_tr">
<th id="S6.T1.30.12.12.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">0.2</th>
<td id="S6.T1.30.12.12.3" class="ltx_td"></td>
<td id="S6.T1.30.12.12.4" class="ltx_td"></td>
<td id="S6.T1.30.12.12.5" class="ltx_td ltx_align_center">86.11±1.11</td>
<td id="S6.T1.30.12.12.6" class="ltx_td ltx_align_center">84.90±1.77</td>
<td id="S6.T1.30.12.12.7" class="ltx_td ltx_align_center">86.50±0.99</td>
<td id="S6.T1.30.12.12.8" class="ltx_td ltx_align_center"><span id="S6.T1.30.12.12.8.1" class="ltx_text ltx_font_bold">85.11±0.90</span></td>
<td id="S6.T1.30.12.12.9" class="ltx_td ltx_align_center">86.21±0.74</td>
<td id="S6.T1.30.12.12.10" class="ltx_td ltx_align_center ltx_border_r">84.85±0.75</td>
<td id="S6.T1.30.12.12.11" class="ltx_td ltx_align_center ltx_border_r">27.3</td>
<td id="S6.T1.30.12.12.1" class="ltx_td ltx_align_center">1.6<math id="S6.T1.30.12.12.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S6.T1.30.12.12.1.m1.1a"><mo id="S6.T1.30.12.12.1.m1.1.1" xref="S6.T1.30.12.12.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S6.T1.30.12.12.1.m1.1b"><times id="S6.T1.30.12.12.1.m1.1.1.cmml" xref="S6.T1.30.12.12.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S6.T1.30.12.12.1.m1.1c">\times</annotation></semantics></math>
</td>
</tr>
<tr id="S6.T1.31.13.13" class="ltx_tr">
<th id="S6.T1.31.13.13.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" rowspan="4"><span id="S6.T1.31.13.13.2.1" class="ltx_text">95 %</span></th>
<th id="S6.T1.31.13.13.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">—</th>
<td id="S6.T1.31.13.13.4" class="ltx_td ltx_align_center ltx_border_t">83.10±0.72</td>
<td id="S6.T1.31.13.13.5" class="ltx_td ltx_align_center ltx_border_t">81.12±0.82</td>
<td id="S6.T1.31.13.13.6" class="ltx_td ltx_border_t"></td>
<td id="S6.T1.31.13.13.7" class="ltx_td ltx_border_t"></td>
<td id="S6.T1.31.13.13.8" class="ltx_td ltx_border_t"></td>
<td id="S6.T1.31.13.13.9" class="ltx_td ltx_border_t"></td>
<td id="S6.T1.31.13.13.10" class="ltx_td ltx_border_t"></td>
<td id="S6.T1.31.13.13.11" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="S6.T1.31.13.13.12" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">43.7</td>
<td id="S6.T1.31.13.13.1" class="ltx_td ltx_align_center ltx_border_t">1<math id="S6.T1.31.13.13.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S6.T1.31.13.13.1.m1.1a"><mo id="S6.T1.31.13.13.1.m1.1.1" xref="S6.T1.31.13.13.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S6.T1.31.13.13.1.m1.1b"><times id="S6.T1.31.13.13.1.m1.1.1.cmml" xref="S6.T1.31.13.13.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S6.T1.31.13.13.1.m1.1c">\times</annotation></semantics></math>
</td>
</tr>
<tr id="S6.T1.32.14.14" class="ltx_tr">
<th id="S6.T1.32.14.14.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">0.0</th>
<td id="S6.T1.32.14.14.3" class="ltx_td"></td>
<td id="S6.T1.32.14.14.4" class="ltx_td"></td>
<td id="S6.T1.32.14.14.5" class="ltx_td ltx_align_center">68.13±0.69</td>
<td id="S6.T1.32.14.14.6" class="ltx_td ltx_align_center">64.79±3.02</td>
<td id="S6.T1.32.14.14.7" class="ltx_td ltx_align_center">70.32±1.08</td>
<td id="S6.T1.32.14.14.8" class="ltx_td ltx_align_center">67.95±2.73</td>
<td id="S6.T1.32.14.14.9" class="ltx_td ltx_align_center">69.85±1.06</td>
<td id="S6.T1.32.14.14.10" class="ltx_td ltx_align_center ltx_border_r">66.96±2.44</td>
<td id="S6.T1.32.14.14.11" class="ltx_td ltx_align_center ltx_border_r">5.9</td>
<td id="S6.T1.32.14.14.1" class="ltx_td ltx_align_center">7.4<math id="S6.T1.32.14.14.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S6.T1.32.14.14.1.m1.1a"><mo id="S6.T1.32.14.14.1.m1.1.1" xref="S6.T1.32.14.14.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S6.T1.32.14.14.1.m1.1b"><times id="S6.T1.32.14.14.1.m1.1.1.cmml" xref="S6.T1.32.14.14.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S6.T1.32.14.14.1.m1.1c">\times</annotation></semantics></math>
</td>
</tr>
<tr id="S6.T1.33.15.15" class="ltx_tr">
<th id="S6.T1.33.15.15.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">0.1</th>
<td id="S6.T1.33.15.15.3" class="ltx_td"></td>
<td id="S6.T1.33.15.15.4" class="ltx_td"></td>
<td id="S6.T1.33.15.15.5" class="ltx_td ltx_align_center">84.71±0.58</td>
<td id="S6.T1.33.15.15.6" class="ltx_td ltx_align_center"><span id="S6.T1.33.15.15.6.1" class="ltx_text ltx_font_bold">82.02±0.43</span></td>
<td id="S6.T1.33.15.15.7" class="ltx_td ltx_align_center">81.55±0.28</td>
<td id="S6.T1.33.15.15.8" class="ltx_td ltx_align_center">81.60±1.02</td>
<td id="S6.T1.33.15.15.9" class="ltx_td ltx_align_center">83.67±0.24</td>
<td id="S6.T1.33.15.15.10" class="ltx_td ltx_align_center ltx_border_r">81.99±1.33</td>
<td id="S6.T1.33.15.15.11" class="ltx_td ltx_align_center ltx_border_r">14.4</td>
<td id="S6.T1.33.15.15.1" class="ltx_td ltx_align_center">3.0<math id="S6.T1.33.15.15.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S6.T1.33.15.15.1.m1.1a"><mo id="S6.T1.33.15.15.1.m1.1.1" xref="S6.T1.33.15.15.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S6.T1.33.15.15.1.m1.1b"><times id="S6.T1.33.15.15.1.m1.1.1.cmml" xref="S6.T1.33.15.15.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S6.T1.33.15.15.1.m1.1c">\times</annotation></semantics></math>
</td>
</tr>
<tr id="S6.T1.34.16.16" class="ltx_tr">
<th id="S6.T1.34.16.16.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">0.2</th>
<td id="S6.T1.34.16.16.3" class="ltx_td"></td>
<td id="S6.T1.34.16.16.4" class="ltx_td"></td>
<td id="S6.T1.34.16.16.5" class="ltx_td ltx_align_center">84.05±1.61</td>
<td id="S6.T1.34.16.16.6" class="ltx_td ltx_align_center">81.79±0.33</td>
<td id="S6.T1.34.16.16.7" class="ltx_td ltx_align_center">82.45±0.60</td>
<td id="S6.T1.34.16.16.8" class="ltx_td ltx_align_center">80.98±0.86</td>
<td id="S6.T1.34.16.16.9" class="ltx_td ltx_align_center">82.96±0.86</td>
<td id="S6.T1.34.16.16.10" class="ltx_td ltx_align_center ltx_border_r">81.79±1.42</td>
<td id="S6.T1.34.16.16.11" class="ltx_td ltx_align_center ltx_border_r">23.0</td>
<td id="S6.T1.34.16.16.1" class="ltx_td ltx_align_center">1.9<math id="S6.T1.34.16.16.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S6.T1.34.16.16.1.m1.1a"><mo id="S6.T1.34.16.16.1.m1.1.1" xref="S6.T1.34.16.16.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S6.T1.34.16.16.1.m1.1b"><times id="S6.T1.34.16.16.1.m1.1.1.cmml" xref="S6.T1.34.16.16.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S6.T1.34.16.16.1.m1.1c">\times</annotation></semantics></math>
</td>
</tr>
<tr id="S6.T1.35.17.17" class="ltx_tr">
<th id="S6.T1.35.17.17.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r ltx_border_t" rowspan="4"><span id="S6.T1.35.17.17.2.1" class="ltx_text">
<span id="S6.T1.35.17.17.2.1.1" class="ltx_inline-block ltx_parbox ltx_align_middle" style="width:56.9pt;">
<span id="S6.T1.35.17.17.2.1.1.1" class="ltx_p">FEMNIST (3597   clients)</span>
</span></span></th>
<th id="S6.T1.35.17.17.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r ltx_border_t" rowspan="4"><span id="S6.T1.35.17.17.3.1" class="ltx_text">95 %</span></th>
<th id="S6.T1.35.17.17.4" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">—</th>
<td id="S6.T1.35.17.17.5" class="ltx_td ltx_align_center ltx_border_t">—</td>
<td id="S6.T1.35.17.17.6" class="ltx_td ltx_align_center ltx_border_t">83.34±0.41</td>
<td id="S6.T1.35.17.17.7" class="ltx_td ltx_border_t"></td>
<td id="S6.T1.35.17.17.8" class="ltx_td ltx_border_t"></td>
<td id="S6.T1.35.17.17.9" class="ltx_td ltx_border_t"></td>
<td id="S6.T1.35.17.17.10" class="ltx_td ltx_border_t"></td>
<td id="S6.T1.35.17.17.11" class="ltx_td ltx_border_t"></td>
<td id="S6.T1.35.17.17.12" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="S6.T1.35.17.17.13" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">23.0</td>
<td id="S6.T1.35.17.17.1" class="ltx_td ltx_align_center ltx_border_t">1<math id="S6.T1.35.17.17.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S6.T1.35.17.17.1.m1.1a"><mo id="S6.T1.35.17.17.1.m1.1.1" xref="S6.T1.35.17.17.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S6.T1.35.17.17.1.m1.1b"><times id="S6.T1.35.17.17.1.m1.1.1.cmml" xref="S6.T1.35.17.17.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S6.T1.35.17.17.1.m1.1c">\times</annotation></semantics></math>
</td>
</tr>
<tr id="S6.T1.36.18.18" class="ltx_tr">
<th id="S6.T1.36.18.18.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">0.0</th>
<td id="S6.T1.36.18.18.3" class="ltx_td"></td>
<td id="S6.T1.36.18.18.4" class="ltx_td"></td>
<td id="S6.T1.36.18.18.5" class="ltx_td ltx_align_center">—</td>
<td id="S6.T1.36.18.18.6" class="ltx_td ltx_align_center">76.79±0.90</td>
<td id="S6.T1.36.18.18.7" class="ltx_td ltx_align_center">—</td>
<td id="S6.T1.36.18.18.8" class="ltx_td ltx_align_center">77.16±2.07</td>
<td id="S6.T1.36.18.18.9" class="ltx_td ltx_align_center">—</td>
<td id="S6.T1.36.18.18.10" class="ltx_td ltx_align_center ltx_border_r">77.02±0.93</td>
<td id="S6.T1.36.18.18.11" class="ltx_td ltx_align_center ltx_border_r">1.3</td>
<td id="S6.T1.36.18.18.1" class="ltx_td ltx_align_center">17.7 <math id="S6.T1.36.18.18.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S6.T1.36.18.18.1.m1.1a"><mo id="S6.T1.36.18.18.1.m1.1.1" xref="S6.T1.36.18.18.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S6.T1.36.18.18.1.m1.1b"><times id="S6.T1.36.18.18.1.m1.1.1.cmml" xref="S6.T1.36.18.18.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S6.T1.36.18.18.1.m1.1c">\times</annotation></semantics></math>
</td>
</tr>
<tr id="S6.T1.37.19.19" class="ltx_tr">
<th id="S6.T1.37.19.19.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">0.1</th>
<td id="S6.T1.37.19.19.3" class="ltx_td"></td>
<td id="S6.T1.37.19.19.4" class="ltx_td"></td>
<td id="S6.T1.37.19.19.5" class="ltx_td ltx_align_center">—</td>
<td id="S6.T1.37.19.19.6" class="ltx_td ltx_align_center">81.91±0.78</td>
<td id="S6.T1.37.19.19.7" class="ltx_td ltx_align_center">—</td>
<td id="S6.T1.37.19.19.8" class="ltx_td ltx_align_center">82.10±0.39</td>
<td id="S6.T1.37.19.19.9" class="ltx_td ltx_align_center">—</td>
<td id="S6.T1.37.19.19.10" class="ltx_td ltx_align_center ltx_border_r">81.71±0.79</td>
<td id="S6.T1.37.19.19.11" class="ltx_td ltx_align_center ltx_border_r">2.9</td>
<td id="S6.T1.37.19.19.1" class="ltx_td ltx_align_center">7.9 <math id="S6.T1.37.19.19.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S6.T1.37.19.19.1.m1.1a"><mo id="S6.T1.37.19.19.1.m1.1.1" xref="S6.T1.37.19.19.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S6.T1.37.19.19.1.m1.1b"><times id="S6.T1.37.19.19.1.m1.1.1.cmml" xref="S6.T1.37.19.19.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S6.T1.37.19.19.1.m1.1c">\times</annotation></semantics></math>
</td>
</tr>
<tr id="S6.T1.38.20.20" class="ltx_tr">
<th id="S6.T1.38.20.20.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r">0.2</th>
<td id="S6.T1.38.20.20.3" class="ltx_td ltx_border_bb"></td>
<td id="S6.T1.38.20.20.4" class="ltx_td ltx_border_bb"></td>
<td id="S6.T1.38.20.20.5" class="ltx_td ltx_align_center ltx_border_bb">—</td>
<td id="S6.T1.38.20.20.6" class="ltx_td ltx_align_center ltx_border_bb"><span id="S6.T1.38.20.20.6.1" class="ltx_text ltx_font_bold">83.78±0.19</span></td>
<td id="S6.T1.38.20.20.7" class="ltx_td ltx_align_center ltx_border_bb">—</td>
<td id="S6.T1.38.20.20.8" class="ltx_td ltx_align_center ltx_border_bb">83.01±0.27</td>
<td id="S6.T1.38.20.20.9" class="ltx_td ltx_align_center ltx_border_bb">—</td>
<td id="S6.T1.38.20.20.10" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">82.54±0.65</td>
<td id="S6.T1.38.20.20.11" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">4.4</td>
<td id="S6.T1.38.20.20.1" class="ltx_td ltx_align_center ltx_border_bb">5.2 <math id="S6.T1.38.20.20.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S6.T1.38.20.20.1.m1.1a"><mo id="S6.T1.38.20.20.1.m1.1.1" xref="S6.T1.38.20.20.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S6.T1.38.20.20.1.m1.1b"><times id="S6.T1.38.20.20.1.m1.1.1.cmml" xref="S6.T1.38.20.20.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S6.T1.38.20.20.1.m1.1c">\times</annotation></semantics></math>
</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div id="S6.p2" class="ltx_para ltx_noindent">
<p id="S6.p2.7" class="ltx_p">First, it is worth noticing that all three local sparsification methods with mask ratios higher than <math id="S6.p2.1.m1.1" class="ltx_Math" alttext="0.1" display="inline"><semantics id="S6.p2.1.m1.1a"><mn id="S6.p2.1.m1.1.1" xref="S6.p2.1.m1.1.1.cmml">0.1</mn><annotation-xml encoding="MathML-Content" id="S6.p2.1.m1.1b"><cn type="float" id="S6.p2.1.m1.1.1.cmml" xref="S6.p2.1.m1.1.1">0.1</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.p2.1.m1.1c">0.1</annotation></semantics></math> perform better or similarly to vanilla SWAT. The biggest improvement for <math id="S6.p2.2.m2.1" class="ltx_Math" alttext="90" display="inline"><semantics id="S6.p2.2.m2.1a"><mn id="S6.p2.2.m2.1.1" xref="S6.p2.2.m2.1.1.cmml">90</mn><annotation-xml encoding="MathML-Content" id="S6.p2.2.m2.1b"><cn type="integer" id="S6.p2.2.m2.1.1.cmml" xref="S6.p2.2.m2.1.1">90</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.p2.2.m2.1c">90</annotation></semantics></math>% sparsity is achieved with the <em id="S6.p2.7.1" class="ltx_emph ltx_font_italic">Top-K-Weights</em> method with a mask ratio of <math id="S6.p2.3.m3.1" class="ltx_Math" alttext="0.2" display="inline"><semantics id="S6.p2.3.m3.1a"><mn id="S6.p2.3.m3.1.1" xref="S6.p2.3.m3.1.1.cmml">0.2</mn><annotation-xml encoding="MathML-Content" id="S6.p2.3.m3.1b"><cn type="float" id="S6.p2.3.m3.1.1.cmml" xref="S6.p2.3.m3.1.1">0.2</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.p2.3.m3.1c">0.2</annotation></semantics></math>, which increases the test accuracy by <math id="S6.p2.4.m4.1" class="ltx_Math" alttext="0.4" display="inline"><semantics id="S6.p2.4.m4.1a"><mn id="S6.p2.4.m4.1.1" xref="S6.p2.4.m4.1.1.cmml">0.4</mn><annotation-xml encoding="MathML-Content" id="S6.p2.4.m4.1b"><cn type="float" id="S6.p2.4.m4.1.1.cmml" xref="S6.p2.4.m4.1.1">0.4</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.p2.4.m4.1c">0.4</annotation></semantics></math>%. The largest improvement for <math id="S6.p2.5.m5.1" class="ltx_Math" alttext="95" display="inline"><semantics id="S6.p2.5.m5.1a"><mn id="S6.p2.5.m5.1.1" xref="S6.p2.5.m5.1.1.cmml">95</mn><annotation-xml encoding="MathML-Content" id="S6.p2.5.m5.1b"><cn type="integer" id="S6.p2.5.m5.1.1.cmml" xref="S6.p2.5.m5.1.1">95</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.p2.5.m5.1c">95</annotation></semantics></math>% sparsity is achieved with the <em id="S6.p2.7.2" class="ltx_emph ltx_font_italic">Top-K-Weights</em> method with a mask ratio of <math id="S6.p2.6.m6.1" class="ltx_Math" alttext="0.2" display="inline"><semantics id="S6.p2.6.m6.1a"><mn id="S6.p2.6.m6.1.1" xref="S6.p2.6.m6.1.1.cmml">0.2</mn><annotation-xml encoding="MathML-Content" id="S6.p2.6.m6.1b"><cn type="float" id="S6.p2.6.m6.1.1.cmml" xref="S6.p2.6.m6.1.1">0.2</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.p2.6.m6.1c">0.2</annotation></semantics></math>, and the it increases the test accuracy by <math id="S6.p2.7.m7.1" class="ltx_Math" alttext="1.5" display="inline"><semantics id="S6.p2.7.m7.1a"><mn id="S6.p2.7.m7.1.1" xref="S6.p2.7.m7.1.1.cmml">1.5</mn><annotation-xml encoding="MathML-Content" id="S6.p2.7.m7.1b"><cn type="float" id="S6.p2.7.m7.1.1.cmml" xref="S6.p2.7.m7.1.1">1.5</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.p2.7.m7.1c">1.5</annotation></semantics></math>%.</p>
</div>
<div id="S6.p3" class="ltx_para ltx_noindent">
<p id="S6.p3.5" class="ltx_p">For SpeechCommands, we reported the performance at communication round <math id="S6.p3.1.m1.1" class="ltx_Math" alttext="200" display="inline"><semantics id="S6.p3.1.m1.1a"><mn id="S6.p3.1.m1.1.1" xref="S6.p3.1.m1.1.1.cmml">200</mn><annotation-xml encoding="MathML-Content" id="S6.p3.1.m1.1b"><cn type="integer" id="S6.p3.1.m1.1.1.cmml" xref="S6.p3.1.m1.1.1">200</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.p3.1.m1.1c">200</annotation></semantics></math> to show that ZeroFL achieves faster convergences and higher accuracies with mask ratio higher than <math id="S6.p3.2.m2.1" class="ltx_Math" alttext="0" display="inline"><semantics id="S6.p3.2.m2.1a"><mn id="S6.p3.2.m2.1.1" xref="S6.p3.2.m2.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="S6.p3.2.m2.1b"><cn type="integer" id="S6.p3.2.m2.1.1.cmml" xref="S6.p3.2.m2.1.1">0</cn></annotation-xml></semantics></math>, especially for the non-IID setting. More results can be found in appendix <a href="#A1.SS4" title="A.4 Additional results for SpeechCommands ‣ Appendix A Appendix ‣ ZeroFL: Efficient On-Device Training for Federated Learning with Local Sparsity" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A.4</span></a>, which demonstrates higher performance at round <math id="S6.p3.3.m3.1" class="ltx_Math" alttext="300" display="inline"><semantics id="S6.p3.3.m3.1a"><mn id="S6.p3.3.m3.1.1" xref="S6.p3.3.m3.1.1.cmml">300</mn><annotation-xml encoding="MathML-Content" id="S6.p3.3.m3.1b"><cn type="integer" id="S6.p3.3.m3.1.1.cmml" xref="S6.p3.3.m3.1.1">300</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.p3.3.m3.1c">300</annotation></semantics></math> when test accuracies are stabilized. With ZeroFL, the performance can be improved by <math id="S6.p3.4.m4.1" class="ltx_Math" alttext="2.3" display="inline"><semantics id="S6.p3.4.m4.1a"><mn id="S6.p3.4.m4.1.1" xref="S6.p3.4.m4.1.1.cmml">2.3</mn><annotation-xml encoding="MathML-Content" id="S6.p3.4.m4.1b"><cn type="float" id="S6.p3.4.m4.1.1.cmml" xref="S6.p3.4.m4.1.1">2.3</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.p3.4.m4.1c">2.3</annotation></semantics></math>% for <math id="S6.p3.5.m5.1" class="ltx_Math" alttext="90" display="inline"><semantics id="S6.p3.5.m5.1a"><mn id="S6.p3.5.m5.1.1" xref="S6.p3.5.m5.1.1.cmml">90</mn><annotation-xml encoding="MathML-Content" id="S6.p3.5.m5.1b"><cn type="integer" id="S6.p3.5.m5.1.1.cmml" xref="S6.p3.5.m5.1.1">90</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.p3.5.m5.1c">90</annotation></semantics></math>% sparsity in the non-IID setting.</p>
</div>
<div id="S6.p4" class="ltx_para ltx_noindent">
<p id="S6.p4.1" class="ltx_p">For FEMNIST we observe a similar trend when evaluating the different masking methods in ZeroFL: larger mask ratios result in better performing global models. However, sending the entire model from client to server seems to be key to obtain good results. We hypothesise this is because FEMNIST is a much more challenging dataset (62 classes) and the architecture used is relatively simple and less sensible to sparsification as a result.</p>
</div>
<div id="S6.p5" class="ltx_para ltx_noindent">
<p id="S6.p5.5" class="ltx_p">Overall, performance improved with mask ratios between <math id="S6.p5.1.m1.1" class="ltx_Math" alttext="0" display="inline"><semantics id="S6.p5.1.m1.1a"><mn id="S6.p5.1.m1.1.1" xref="S6.p5.1.m1.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="S6.p5.1.m1.1b"><cn type="integer" id="S6.p5.1.m1.1.1.cmml" xref="S6.p5.1.m1.1.1">0</cn></annotation-xml></semantics></math> and <math id="S6.p5.2.m2.1" class="ltx_Math" alttext="0.2" display="inline"><semantics id="S6.p5.2.m2.1a"><mn id="S6.p5.2.m2.1.1" xref="S6.p5.2.m2.1.1.cmml">0.2</mn><annotation-xml encoding="MathML-Content" id="S6.p5.2.m2.1b"><cn type="float" id="S6.p5.2.m2.1.1.cmml" xref="S6.p5.2.m2.1.1">0.2</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.p5.2.m2.1c">0.2</annotation></semantics></math>, indicating that there exist an optimal interval level. Indeed, a mask ratio equal to the sparsity level degenerates the system to the vanilla SWAT, which obtains worse results. It also implies that there is a trade-off between communication cost and performance. By using mask ratio of <math id="S6.p5.3.m3.1" class="ltx_Math" alttext="0.1" display="inline"><semantics id="S6.p5.3.m3.1a"><mn id="S6.p5.3.m3.1.1" xref="S6.p5.3.m3.1.1.cmml">0.1</mn><annotation-xml encoding="MathML-Content" id="S6.p5.3.m3.1b"><cn type="float" id="S6.p5.3.m3.1.1.cmml" xref="S6.p5.3.m3.1.1">0.1</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.p5.3.m3.1c">0.1</annotation></semantics></math>, each selected client performs local sparsification with an effective sparsity level of <math id="S6.p5.4.m4.1" class="ltx_Math" alttext="80" display="inline"><semantics id="S6.p5.4.m4.1a"><mn id="S6.p5.4.m4.1.1" xref="S6.p5.4.m4.1.1.cmml">80</mn><annotation-xml encoding="MathML-Content" id="S6.p5.4.m4.1b"><cn type="integer" id="S6.p5.4.m4.1.1.cmml" xref="S6.p5.4.m4.1.1">80</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.p5.4.m4.1c">80</annotation></semantics></math>%, hence sending more data that for lower mask ratios values. In Section <a href="#A1.SS1" title="A.1 Impact of 𝑟_{𝑚⁢𝑎⁢𝑠⁢𝑘} in global performance ‣ Appendix A Appendix ‣ ZeroFL: Efficient On-Device Training for Federated Learning with Local Sparsity" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A.1</span></a> we densely evaluate the impact of <math id="S6.p5.5.m5.2" class="ltx_Math" alttext="r_{mask}\in[0.1,0.9]" display="inline"><semantics id="S6.p5.5.m5.2a"><mrow id="S6.p5.5.m5.2.3" xref="S6.p5.5.m5.2.3.cmml"><msub id="S6.p5.5.m5.2.3.2" xref="S6.p5.5.m5.2.3.2.cmml"><mi id="S6.p5.5.m5.2.3.2.2" xref="S6.p5.5.m5.2.3.2.2.cmml">r</mi><mrow id="S6.p5.5.m5.2.3.2.3" xref="S6.p5.5.m5.2.3.2.3.cmml"><mi id="S6.p5.5.m5.2.3.2.3.2" xref="S6.p5.5.m5.2.3.2.3.2.cmml">m</mi><mo lspace="0em" rspace="0em" id="S6.p5.5.m5.2.3.2.3.1" xref="S6.p5.5.m5.2.3.2.3.1.cmml">​</mo><mi id="S6.p5.5.m5.2.3.2.3.3" xref="S6.p5.5.m5.2.3.2.3.3.cmml">a</mi><mo lspace="0em" rspace="0em" id="S6.p5.5.m5.2.3.2.3.1a" xref="S6.p5.5.m5.2.3.2.3.1.cmml">​</mo><mi id="S6.p5.5.m5.2.3.2.3.4" xref="S6.p5.5.m5.2.3.2.3.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S6.p5.5.m5.2.3.2.3.1b" xref="S6.p5.5.m5.2.3.2.3.1.cmml">​</mo><mi id="S6.p5.5.m5.2.3.2.3.5" xref="S6.p5.5.m5.2.3.2.3.5.cmml">k</mi></mrow></msub><mo id="S6.p5.5.m5.2.3.1" xref="S6.p5.5.m5.2.3.1.cmml">∈</mo><mrow id="S6.p5.5.m5.2.3.3.2" xref="S6.p5.5.m5.2.3.3.1.cmml"><mo stretchy="false" id="S6.p5.5.m5.2.3.3.2.1" xref="S6.p5.5.m5.2.3.3.1.cmml">[</mo><mn id="S6.p5.5.m5.1.1" xref="S6.p5.5.m5.1.1.cmml">0.1</mn><mo id="S6.p5.5.m5.2.3.3.2.2" xref="S6.p5.5.m5.2.3.3.1.cmml">,</mo><mn id="S6.p5.5.m5.2.2" xref="S6.p5.5.m5.2.2.cmml">0.9</mn><mo stretchy="false" id="S6.p5.5.m5.2.3.3.2.3" xref="S6.p5.5.m5.2.3.3.1.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S6.p5.5.m5.2b"><apply id="S6.p5.5.m5.2.3.cmml" xref="S6.p5.5.m5.2.3"><in id="S6.p5.5.m5.2.3.1.cmml" xref="S6.p5.5.m5.2.3.1"></in><apply id="S6.p5.5.m5.2.3.2.cmml" xref="S6.p5.5.m5.2.3.2"><csymbol cd="ambiguous" id="S6.p5.5.m5.2.3.2.1.cmml" xref="S6.p5.5.m5.2.3.2">subscript</csymbol><ci id="S6.p5.5.m5.2.3.2.2.cmml" xref="S6.p5.5.m5.2.3.2.2">𝑟</ci><apply id="S6.p5.5.m5.2.3.2.3.cmml" xref="S6.p5.5.m5.2.3.2.3"><times id="S6.p5.5.m5.2.3.2.3.1.cmml" xref="S6.p5.5.m5.2.3.2.3.1"></times><ci id="S6.p5.5.m5.2.3.2.3.2.cmml" xref="S6.p5.5.m5.2.3.2.3.2">𝑚</ci><ci id="S6.p5.5.m5.2.3.2.3.3.cmml" xref="S6.p5.5.m5.2.3.2.3.3">𝑎</ci><ci id="S6.p5.5.m5.2.3.2.3.4.cmml" xref="S6.p5.5.m5.2.3.2.3.4">𝑠</ci><ci id="S6.p5.5.m5.2.3.2.3.5.cmml" xref="S6.p5.5.m5.2.3.2.3.5">𝑘</ci></apply></apply><interval closure="closed" id="S6.p5.5.m5.2.3.3.1.cmml" xref="S6.p5.5.m5.2.3.3.2"><cn type="float" id="S6.p5.5.m5.1.1.cmml" xref="S6.p5.5.m5.1.1">0.1</cn><cn type="float" id="S6.p5.5.m5.2.2.cmml" xref="S6.p5.5.m5.2.2">0.9</cn></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.p5.5.m5.2c">r_{mask}\in[0.1,0.9]</annotation></semantics></math> and, we observe no clear benefit of choosing larger ratios over smaller ones (e.g. 0.1). We briefly elaborate on this in the Appendix.</p>
</div>
<div id="S6.p6" class="ltx_para ltx_noindent">
<p id="S6.p6.7" class="ltx_p">ZeroFL enables us to reduce the performance degradation observed with high levels of sparsity with FL while not completely alleviating it. During communication, each weight matrix from the model is vectorised and transmitted using the Compressed Sparse Row (CSR) <cite class="ltx_cite ltx_citemacro_citep">(Tinney &amp; Walker, <a href="#bib.bib48" title="" class="ltx_ref">1967</a>)</cite> format. Such representation requires exactly one integer index for each non-zero weight value in the model. Table <a href="#S6.T1" title="Table 1 ‣ 6 ZeroFL: Experimental Results ‣ ZeroFL: Efficient On-Device Training for Federated Learning with Local Sparsity" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> shows the level of compression and reduction in communication for different level of mask ratios. Compared to the original 43MB dense model, uplink communications are reduced by factors of <math id="S6.p6.1.m1.1" class="ltx_math_unparsed" alttext="7.5\times" display="inline"><semantics id="S6.p6.1.m1.1a"><mrow id="S6.p6.1.m1.1b"><mn id="S6.p6.1.m1.1.1">7.5</mn><mo lspace="0.222em" id="S6.p6.1.m1.1.2">×</mo></mrow><annotation encoding="application/x-tex" id="S6.p6.1.m1.1c">7.5\times</annotation></semantics></math>, <math id="S6.p6.2.m2.1" class="ltx_math_unparsed" alttext="3.0\times" display="inline"><semantics id="S6.p6.2.m2.1a"><mrow id="S6.p6.2.m2.1b"><mn id="S6.p6.2.m2.1.1">3.0</mn><mo lspace="0.222em" id="S6.p6.2.m2.1.2">×</mo></mrow><annotation encoding="application/x-tex" id="S6.p6.2.m2.1c">3.0\times</annotation></semantics></math> and <math id="S6.p6.3.m3.1" class="ltx_math_unparsed" alttext="1.9\times" display="inline"><semantics id="S6.p6.3.m3.1a"><mrow id="S6.p6.3.m3.1b"><mn id="S6.p6.3.m3.1.1">1.9</mn><mo lspace="0.222em" id="S6.p6.3.m3.1.2">×</mo></mrow><annotation encoding="application/x-tex" id="S6.p6.3.m3.1c">1.9\times</annotation></semantics></math> for mask ratios of <math id="S6.p6.4.m4.1" class="ltx_Math" alttext="0.0" display="inline"><semantics id="S6.p6.4.m4.1a"><mn id="S6.p6.4.m4.1.1" xref="S6.p6.4.m4.1.1.cmml">0.0</mn><annotation-xml encoding="MathML-Content" id="S6.p6.4.m4.1b"><cn type="float" id="S6.p6.4.m4.1.1.cmml" xref="S6.p6.4.m4.1.1">0.0</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.p6.4.m4.1c">0.0</annotation></semantics></math>, <math id="S6.p6.5.m5.1" class="ltx_Math" alttext="0.1" display="inline"><semantics id="S6.p6.5.m5.1a"><mn id="S6.p6.5.m5.1.1" xref="S6.p6.5.m5.1.1.cmml">0.1</mn><annotation-xml encoding="MathML-Content" id="S6.p6.5.m5.1b"><cn type="float" id="S6.p6.5.m5.1.1.cmml" xref="S6.p6.5.m5.1.1">0.1</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.p6.5.m5.1c">0.1</annotation></semantics></math> and <math id="S6.p6.6.m6.1" class="ltx_Math" alttext="0.2" display="inline"><semantics id="S6.p6.6.m6.1a"><mn id="S6.p6.6.m6.1.1" xref="S6.p6.6.m6.1.1.cmml">0.2</mn><annotation-xml encoding="MathML-Content" id="S6.p6.6.m6.1b"><cn type="float" id="S6.p6.6.m6.1.1.cmml" xref="S6.p6.6.m6.1.1">0.2</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.p6.6.m6.1c">0.2</annotation></semantics></math> respectively, with a sparsification ratio of <math id="S6.p6.7.m7.1" class="ltx_Math" alttext="95" display="inline"><semantics id="S6.p6.7.m7.1a"><mn id="S6.p6.7.m7.1.1" xref="S6.p6.7.m7.1.1.cmml">95</mn><annotation-xml encoding="MathML-Content" id="S6.p6.7.m7.1b"><cn type="integer" id="S6.p6.7.m7.1.1.cmml" xref="S6.p6.7.m7.1.1">95</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.p6.7.m7.1c">95</annotation></semantics></math>%. Communication savings are calculated as the size ratio between original and compressed models; considering both weights and indices in the CSR file.</p>
</div>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Conclusion</h2>

<div id="S7.p1" class="ltx_para ltx_noindent">
<p id="S7.p1.1" class="ltx_p">In this work, we consider the challenges of inducing high level of sparsity to accelerate on-device training for federated learning. We provide the first framework to leverage sparsity as a mechanism to accelerate on-device training without the server imposing any restrictions. We study on the unique perspective that arise when introducing sparsity at training time, hence motivating us to propose innovative state-of-the-art off-the-shelve sparsification methods to the FL domain <em id="S7.p1.1.1" class="ltx_emph ltx_font_italic">ZeroFL</em>. The method achieves +1.5% accuracy while reducing 1.9<math id="S7.p1.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S7.p1.1.m1.1a"><mo id="S7.p1.1.m1.1.1" xref="S7.p1.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S7.p1.1.m1.1b"><times id="S7.p1.1.m1.1.1.cmml" xref="S7.p1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S7.p1.1.m1.1c">\times</annotation></semantics></math> uplink communication costs compared with competitive baselines for CIFAR10 at 95% sparsity, and +2.3% accuracy for non-IID SpeechCommands at 90% sparsity. Our findings call for further investigations on the device-oriented optimisation of federated learning to motivate realistic deployments of this training methodology.</p>
</div>
</section>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Acknowledgements</h2>

<div id="Sx1.p1" class="ltx_para ltx_noindent">
<p id="Sx1.p1.1" class="ltx_p">This work was supported by the UK’s Engineering and Physical Sciences Research Council (EPSRC) with grants EP/M50659X/1 and EP/S001530/1 (the MOA project) and the European Research Council (ERC) via the REDIAL project (Grant Agreement ID: 805194). Part of this work was performed using HPC/AI resources from GENCI-IDRIS (Grant 2021-A0111012991).</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Amiri et al. (2020)</span>
<span class="ltx_bibblock">
Mohammad Mohammadi Amiri, Deniz Gunduz, Sanjeev R. Kulkarni, and H. Vincent
Poor.

</span>
<span class="ltx_bibblock">Federated learning with quantized global model updates, 2020.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Arivazhagan et al. (2019)</span>
<span class="ltx_bibblock">
Manoj Ghuhan Arivazhagan, Vinay Aggarwal, Aaditya Kumar Singh, and Sunav
Choudhary.

</span>
<span class="ltx_bibblock">Federated learning with personalization layers, 2019.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Beutel et al. (2020)</span>
<span class="ltx_bibblock">
Daniel J. Beutel, Taner Topal, Akhil Mathur, Xinchi Qiu, Titouan Parcollet, and
Nicholas D. Lane.

</span>
<span class="ltx_bibblock">Flower: A friendly federated learning research framework, 2020.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Caldas et al. (2018)</span>
<span class="ltx_bibblock">
Sebastian Caldas, Sai Meher Karthik Duddu, Peter Wu, Tian Li, Jakub
Konečnỳ, H Brendan McMahan, Virginia Smith, and Ameet Talwalkar.

</span>
<span class="ltx_bibblock">Leaf: A benchmark for federated settings.

</span>
<span class="ltx_bibblock"><em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1812.01097</em>, 2018.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Caldas et al. (2019)</span>
<span class="ltx_bibblock">
Sebastian Caldas, Jakub Konečny, H. Brendan McMahan, and Ameet Talwalkar.

</span>
<span class="ltx_bibblock">Expanding the reach of federated learning by reducing client resource
requirements, 2019.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cheng et al. (2021)</span>
<span class="ltx_bibblock">
Gary Cheng, Karan Chadha, and John Duchi.

</span>
<span class="ltx_bibblock">Fine-tuning is fine in federated learning, 2021.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cohen et al. (2017)</span>
<span class="ltx_bibblock">
Gregory Cohen, Saeed Afshar, Jonathan Tapson, and Andre Van Schaik.

</span>
<span class="ltx_bibblock">Emnist: Extending mnist to handwritten letters.

</span>
<span class="ltx_bibblock">In <em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">2017 International Joint Conference on Neural Networks
(IJCNN)</em>, pp.  2921–2926. IEEE, 2017.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Doherty et al. (2017)</span>
<span class="ltx_bibblock">
Aiden Doherty, Dan Jackson, Nils Hammerla, Thomas Plötz, Patrick Olivier,
Malcolm H Granat, Tom White, Vincent T Van Hees, Michael I Trenell,
Christoper G Owen, et al.

</span>
<span class="ltx_bibblock">Large scale population assessment of physical activity using wrist
worn accelerometers: The uk biobank study.

</span>
<span class="ltx_bibblock"><em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">PloS one</em>, 12(2):e0169649, 2017.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Elsen et al. (2020)</span>
<span class="ltx_bibblock">
Erich Elsen, Marat Dukhan, Trevor Gale, and Karen Simonyan.

</span>
<span class="ltx_bibblock">Fast sparse convnets.

</span>
<span class="ltx_bibblock">In <em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision
and Pattern Recognition (CVPR)</em>, June 2020.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Goli &amp; Aamodt (2020)</span>
<span class="ltx_bibblock">
Negar Goli and Tor M Aamodt.

</span>
<span class="ltx_bibblock">Resprop: Reuse sparsified backpropagation.

</span>
<span class="ltx_bibblock">In <em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision
and Pattern Recognition</em>, pp.  1548–1558, 2020.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Guo et al. (2016)</span>
<span class="ltx_bibblock">
Yiwen Guo, Anbang Yao, and Yurong Chen.

</span>
<span class="ltx_bibblock">Dynamic network surgery for efficient dnns.

</span>
<span class="ltx_bibblock">In <em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 30th International Conference on Neural
Information Processing Systems</em>, NIPS’16, pp.  1387–1395, Red Hook, NY,
USA, 2016. Curran Associates Inc.

</span>
<span class="ltx_bibblock">ISBN 9781510838819.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Han et al. (2020)</span>
<span class="ltx_bibblock">
Pengchao Han, Shiqiang Wang, and Kin K Leung.

</span>
<span class="ltx_bibblock">Adaptive gradient sparsification for efficient federated learning: An
online learning approach.

</span>
<span class="ltx_bibblock"><em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2001.04756</em>, 2020.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Han et al. (2015a)</span>
<span class="ltx_bibblock">
Song Han, Huizi Mao, and William J. Dally.

</span>
<span class="ltx_bibblock">Deep compression: Compressing deep neural networks with pruning,
trained quantization and huffman coding, 2015a.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Han et al. (2015b)</span>
<span class="ltx_bibblock">
Song Han, Jeff Pool, John Tran, and William J. Dally.

</span>
<span class="ltx_bibblock">Learning both weights and connections for efficient neural networks.

</span>
<span class="ltx_bibblock">In <em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 28th International Conference on Neural
Information Processing Systems - Volume 1</em>, NIPS’15, pp.  1135–1143,
Cambridge, MA, USA, 2015b. MIT Press.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hard et al. (2018)</span>
<span class="ltx_bibblock">
Andrew Hard, Chloé M Kiddon, Daniel Ramage, Francoise Beaufays, Hubert
Eichner, Kanishka Rao, Rajiv Mathews, and Sean Augenstein.

</span>
<span class="ltx_bibblock">Federated learning for mobile keyboard prediction, 2018.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://arxiv.org/abs/1811.03604" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/abs/1811.03604</a>.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hard et al. (2020)</span>
<span class="ltx_bibblock">
Andrew Hard, Kurt Partridge, Cameron Nguyen, Niranjan Subrahmanya, Aishanee
Shah, Pai Zhu, Ignacio Lopez Moreno, and Rajiv Mathews.

</span>
<span class="ltx_bibblock">Training keyword spotting models on non-iid data with federated
learning, 2020.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hazelwood et al. (2018)</span>
<span class="ltx_bibblock">
Kim Hazelwood, Sarah Bird, David Brooks, Soumith Chintala, Utku Diril, Dmytro
Dzhulgakov, Mohamed Fawzy, Bill Jia, Yangqing Jia, Aditya Kalro, James Law,
Kevin Lee, Jason Lu, Pieter Noordhuis, Misha Smelyanskiy, Liang Xiong, and
Xiaodong Wang.

</span>
<span class="ltx_bibblock">Applied machine learning at facebook: A datacenter infrastructure
perspective.

</span>
<span class="ltx_bibblock">In <em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">2018 IEEE International Symposium on High Performance
Computer Architecture (HPCA)</em>, pp.  620–629, 2018.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1109/HPCA.2018.00059</span>.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He et al. (2020)</span>
<span class="ltx_bibblock">
Chaoyang He, Murali Annavaram, and Salman Avestimehr.

</span>
<span class="ltx_bibblock">Group knowledge transfer: Federated learning of large cnns at the
edge.

</span>
<span class="ltx_bibblock"><em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2007.14513</em>, 2020.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He et al. (2016)</span>
<span class="ltx_bibblock">
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.

</span>
<span class="ltx_bibblock">Deep residual learning for image recognition.

</span>
<span class="ltx_bibblock">In <em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE conference on computer vision and
pattern recognition</em>, pp.  770–778, 2016.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He et al. (2018)</span>
<span class="ltx_bibblock">
Yang He, Guoliang Kang, Xuanyi Dong, Yanwei Fu, and Yi Yang.

</span>
<span class="ltx_bibblock">Soft filter pruning for accelerating deep convolutional neural
networks.

</span>
<span class="ltx_bibblock">In <em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 27th International Joint Conference on
Artificial Intelligence</em>, IJCAI’18, pp.  2234–2240. AAAI Press, 2018.

</span>
<span class="ltx_bibblock">ISBN 9780999241127.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He et al. (2017)</span>
<span class="ltx_bibblock">
Yihui He, Xiangyu Zhang, and Jian Sun.

</span>
<span class="ltx_bibblock">Channel pruning for accelerating very deep neural networks.

</span>
<span class="ltx_bibblock">In <em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">The IEEE International Conference on Computer Vision
(ICCV)</em>, Oct 2017.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hilmkil et al. (2021)</span>
<span class="ltx_bibblock">
Agrin Hilmkil, Sebastian Callh, Matteo Barbieri, Leon René Sütfeld,
Edvin Listo Zec, and Olof Mogren.

</span>
<span class="ltx_bibblock">Scaling federated learning for fine-tuning of large language models,
2021.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hinton et al. (2015)</span>
<span class="ltx_bibblock">
Geoffrey Hinton, Oriol Vinyals, and Jeff Dean.

</span>
<span class="ltx_bibblock">Distilling the knowledge in a neural network, 2015.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hoefler et al. (2021)</span>
<span class="ltx_bibblock">
Torsten Hoefler, Dan Alistarh, Tal Ben-Nun, Nikoli Dryden, and Alexandra Peste.

</span>
<span class="ltx_bibblock">Sparsity in deep learning: Pruning and growth for efficient inference
and training in neural networks, 2021.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hong et al. (2018)</span>
<span class="ltx_bibblock">
Changwan Hong, Aravind Sukumaran-Rajam, Bortik Bandyopadhyay, Jinsung Kim,
Süreyya Emre Kurt, Israt Nisa, Shivani Sabhlok, Ümit V.
Çatalyürek, Srinivasan Parthasarathy, and P. Sadayappan.

</span>
<span class="ltx_bibblock">Efficient sparse-matrix multi-vector product on gpus.

</span>
<span class="ltx_bibblock">In <em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 27th International Symposium on
High-Performance Parallel and Distributed Computing</em>, HPDC ’18, pp. 66–79, New York, NY, USA, 2018. Association for Computing Machinery.

</span>
<span class="ltx_bibblock">ISBN 9781450357852.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1145/3208040.3208062</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://doi.org/10.1145/3208040.3208062" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3208040.3208062</a>.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hong et al. (2019)</span>
<span class="ltx_bibblock">
Changwan Hong, Aravind Sukumaran-Rajam, Israt Nisa, Kunal Singh, and
P. Sadayappan.

</span>
<span class="ltx_bibblock">Adaptive sparse tiling for sparse matrix multiplication.

</span>
<span class="ltx_bibblock">In <em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 24th Symposium on Principles and Practice
of Parallel Programming</em>, PPoPP ’19, pp.  300–314, New York, NY, USA,
2019. Association for Computing Machinery.

</span>
<span class="ltx_bibblock">ISBN 9781450362252.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1145/3293883.3295712</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://doi.org/10.1145/3293883.3295712" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3293883.3295712</a>.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Horvath et al. (2021)</span>
<span class="ltx_bibblock">
Samuel Horvath, Stefanos Laskaridis, Mario Almeida, Ilias Leontiadis,
Stylianos I Venieris, and Nicholas D Lane.

</span>
<span class="ltx_bibblock">Fjord: Fair and accurate federated learning under heterogeneous
targets with ordered dropout.

</span>
<span class="ltx_bibblock"><em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2102.13451</em>, 2021.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hsu et al. (2019)</span>
<span class="ltx_bibblock">
Tzu-Ming Harry Hsu, Hang Qi, and Matthew Brown.

</span>
<span class="ltx_bibblock">Measuring the effects of non-identical data distribution for
federated visual classification.

</span>
<span class="ltx_bibblock"><em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1909.06335</em>, 2019.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jian-Hao Luo &amp; Lin (2017)</span>
<span class="ltx_bibblock">
Jianxin Wu Jian-Hao Luo and Weiyao Lin.

</span>
<span class="ltx_bibblock">ThiNet: A Filter Level Pruning Method for Deep Neural Network
Compression.

</span>
<span class="ltx_bibblock">In <em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">International Conference on Computer Vision (ICCV)</em>, October
2017.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jiang et al. (2019)</span>
<span class="ltx_bibblock">
Yuang Jiang, Shiqiang Wang, Victor Valls, Bong Jun Ko, Wei-Han Lee, Kin K
Leung, and Leandros Tassiulas.

</span>
<span class="ltx_bibblock">Model pruning enables efficient federated learning on edge devices.

</span>
<span class="ltx_bibblock"><em id="bib.bib30.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1909.12326</em>, 2019.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Konečnỳ et al. (2016)</span>
<span class="ltx_bibblock">
Jakub Konečnỳ, H Brendan McMahan, Felix X Yu, Peter Richtárik,
Ananda Theertha Suresh, and Dave Bacon.

</span>
<span class="ltx_bibblock">Federated learning: Strategies for improving communication
efficiency.

</span>
<span class="ltx_bibblock"><em id="bib.bib31.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1610.05492</em>, 2016.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Krizhevsky et al. (2009)</span>
<span class="ltx_bibblock">
Alex Krizhevsky, Geoffrey Hinton, et al.

</span>
<span class="ltx_bibblock">Learning multiple layers of features from tiny images.

</span>
<span class="ltx_bibblock">2009.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. (2018)</span>
<span class="ltx_bibblock">
Tian Li, Anit Kumar Sahu, Manzil Zaheer, Maziar Sanjabi, Ameet Talwalkar, and
Virginia Smith.

</span>
<span class="ltx_bibblock">Federated optimization in heterogeneous networks.

</span>
<span class="ltx_bibblock"><em id="bib.bib33.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1812.06127</em>, 2018.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin et al. (2020)</span>
<span class="ltx_bibblock">
Tao Lin, Lingjing Kong, Sebastian U Stich, and Martin Jaggi.

</span>
<span class="ltx_bibblock">Ensemble distillation for robust model fusion in federated learning.

</span>
<span class="ltx_bibblock">In H. Larochelle, M. Ranzato, R. Hadsell, M. F. Balcan, and H. Lin
(eds.), <em id="bib.bib34.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>, volume 33,
pp.  2351–2363. Curran Associates, Inc., 2020.

</span>
<span class="ltx_bibblock">URL
<a target="_blank" href="https://proceedings.neurips.cc/paper/2020/file/18df51b97ccd68128e994804f3eccc87-Paper.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://proceedings.neurips.cc/paper/2020/file/18df51b97ccd68128e994804f3eccc87-Paper.pdf</a>.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. (2021)</span>
<span class="ltx_bibblock">
Lumin Liu, Jun Zhang, Shenghui Song, and Khaled B. Letaief.

</span>
<span class="ltx_bibblock">Hierarchical quantized federated learning: Convergence analysis and
system design, 2021.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lu et al. (2019)</span>
<span class="ltx_bibblock">
L. Lu, J. Xie, R. Huang, J. Zhang, W. Lin, and Y. Liang.

</span>
<span class="ltx_bibblock">An Efficient Hardware Accelerator for Sparse Convolutional Neural
Networks on FPGAs.

</span>
<span class="ltx_bibblock">In <em id="bib.bib36.1.1" class="ltx_emph ltx_font_italic">IEEE 27th Annual International Symposium on
Field-Programmable Custom Computing Machines (FCCM)</em>, pp.  17–25, 2019.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">McMahan et al. (2017)</span>
<span class="ltx_bibblock">
Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Aguera
y Arcas.

</span>
<span class="ltx_bibblock">Communication-efficient learning of deep networks from decentralized
data.

</span>
<span class="ltx_bibblock">In <em id="bib.bib37.1.1" class="ltx_emph ltx_font_italic">Artificial intelligence and statistics</em>, pp.  1273–1282.
PMLR, 2017.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Molchanov et al. (2017)</span>
<span class="ltx_bibblock">
Dmitry Molchanov, Arsenii Ashukha, and Dmitry Vetrov.

</span>
<span class="ltx_bibblock">Variational dropout sparsifies deep neural networks.

</span>
<span class="ltx_bibblock">In Doina Precup and Yee Whye Teh (eds.), <em id="bib.bib38.1.1" class="ltx_emph ltx_font_italic">Proceedings of the
34th International Conference on Machine Learning</em>, volume 70 of
<em id="bib.bib38.2.2" class="ltx_emph ltx_font_italic">Proceedings of Machine Learning Research</em>, pp.  2498–2507. PMLR,
06–11 Aug 2017.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="http://proceedings.mlr.press/v70/molchanov17a.html" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://proceedings.mlr.press/v70/molchanov17a.html</a>.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Molchanov et al. (2019)</span>
<span class="ltx_bibblock">
Pavlo Molchanov, Arun Mallya, Stephen Tyree, Iuri Frosio, and Jan Kautz.

</span>
<span class="ltx_bibblock">Importance Estimation for Neural Network Pruning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib39.1.1" class="ltx_emph ltx_font_italic">2019 IEEE/CVF Conference on Computer Vision and Pattern
Recognition (CVPR)</em>, 2019.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Qiu et al. (2021)</span>
<span class="ltx_bibblock">
Xinchi Qiu, Titouan Parcollet, Javier Fernandez-Marques, Pedro Porto Buarque
de Gusmao, Daniel J Beutel, Taner Topal, Akhil Mathur, and Nicholas D Lane.

</span>
<span class="ltx_bibblock">A first look into the carbon footprint of federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib40.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2102.07627</em>, 2021.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Raihan &amp; Aamodt (2020)</span>
<span class="ltx_bibblock">
Md Aamir Raihan and Tor M Aamodt.

</span>
<span class="ltx_bibblock">Sparse weight activation training.

</span>
<span class="ltx_bibblock"><em id="bib.bib41.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2001.01969</em>, 2020.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Reddi et al. (2021)</span>
<span class="ltx_bibblock">
Sashank J. Reddi, Zachary Charles, Manzil Zaheer, Zachary Garrett, Keith Rush,
Jakub Konečný, Sanjiv Kumar, and Hugh Brendan McMahan.

</span>
<span class="ltx_bibblock">Adaptive federated optimization.

</span>
<span class="ltx_bibblock">In <em id="bib.bib42.1.1" class="ltx_emph ltx_font_italic">International Conference on Learning Representations</em>, 2021.

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ren et al. (2018)</span>
<span class="ltx_bibblock">
Mengye Ren, Andrei Pokrovsky, Bin Yang, and Raquel Urtasun.

</span>
<span class="ltx_bibblock">Sbnet: Sparse blocks network for fast inference, 2018.

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">S. Gray &amp; Kingma (2017)</span>
<span class="ltx_bibblock">
A. Radford S. Gray and D. P. Kingma.

</span>
<span class="ltx_bibblock">Block-sparse gpu kernels, 2017.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://blog.openai.com/block-sparse-gpu-kernels/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://blog.openai.com/block-sparse-gpu-kernels/</a>.

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shahid et al. (2021)</span>
<span class="ltx_bibblock">
Osama Shahid, Seyedamin Pouriyeh, Reza M. Parizi, Quan Z. Sheng, Gautam
Srivastava, and Liang Zhao.

</span>
<span class="ltx_bibblock">Communication efficiency in federated learning: Achievements and
challenges, 2021.

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Srivastava et al. (2020)</span>
<span class="ltx_bibblock">
N. Srivastava, H. Jin, S. Smith, H. Rong, D. Albonesi, and
Z. Zhang.

</span>
<span class="ltx_bibblock">Tensaurus: A Versatile Accelerator for Mixed Sparse-Dense Tensor
Computations.

</span>
<span class="ltx_bibblock">In <em id="bib.bib46.1.1" class="ltx_emph ltx_font_italic">2020 IEEE International Symposium on High Performance
Computer Architecture (HPCA)</em>, pp.  689–702, 2020.

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sun et al. (2017)</span>
<span class="ltx_bibblock">
Xu Sun, Xuancheng Ren, Shuming Ma, and Houfeng Wang.

</span>
<span class="ltx_bibblock">meProp: Sparsified back propagation for accelerated deep learning
with reduced overfitting.

</span>
<span class="ltx_bibblock">In <em id="bib.bib47.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 34th International Conference on Machine
Learning</em>, volume 70 of <em id="bib.bib47.2.2" class="ltx_emph ltx_font_italic">Proceedings of Machine Learning Research</em>, pp. 3299–3308, International Convention Centre, Sydney, Australia, 2017.

</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tinney &amp; Walker (1967)</span>
<span class="ltx_bibblock">
W.F. Tinney and J.W. Walker.

</span>
<span class="ltx_bibblock">Direct solutions of sparse network equations by optimally ordered
triangular factorization.

</span>
<span class="ltx_bibblock"><em id="bib.bib48.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE</em>, 55(11):1801–1809, 1967.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1109/PROC.1967.6011</span>.

</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Verelst &amp; Tuytelaars (2020)</span>
<span class="ltx_bibblock">
Thomas Verelst and Tinne Tuytelaars.

</span>
<span class="ltx_bibblock">Segblocks: Block-based dynamic resolution networks for real-time
segmentation, 2020.

</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2018)</span>
<span class="ltx_bibblock">
Hongyi Wang, Scott Sievert, Zachary Charles, Shengchao Liu, Stephen Wright, and
Dimitris Papailiopoulos.

</span>
<span class="ltx_bibblock">Atomo: Communication-efficient learning via atomic sparsification.

</span>
<span class="ltx_bibblock"><em id="bib.bib50.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1806.04090</em>, 2018.

</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2017)</span>
<span class="ltx_bibblock">
Yunhe Wang, Chang Xu, Chao Xu, and Dacheng Tao.

</span>
<span class="ltx_bibblock">Beyond Filters: Compact Feature Map for Portable Deep Model.

</span>
<span class="ltx_bibblock">In <em id="bib.bib51.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 34th International Conference on Machine
Learning (ICML)</em>, pp.  3703–3711, 2017.

</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang (2020)</span>
<span class="ltx_bibblock">
Ziheng Wang.

</span>
<span class="ltx_bibblock">Sparsert: Accelerating unstructured sparsity on gpus for deep
learning inference.

</span>
<span class="ltx_bibblock">In <em id="bib.bib52.1.1" class="ltx_emph ltx_font_italic">Proceedings of the ACM International Conference on Parallel
Architectures and Compilation Techniques</em>, PACT ’20, pp.  31–42, New York,
NY, USA, 2020. Association for Computing Machinery.

</span>
<span class="ltx_bibblock">ISBN 9781450380751.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1145/3410463.3414654</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://doi.org/10.1145/3410463.3414654" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3410463.3414654</a>.

</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang (2021)</span>
<span class="ltx_bibblock">
Ziheng Wang.

</span>
<span class="ltx_bibblock">Sparsednn: Fast sparse deep learning inference on cpus, 2021.

</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Warden (2018)</span>
<span class="ltx_bibblock">
Pete Warden.

</span>
<span class="ltx_bibblock">Speech commands: A dataset for limited-vocabulary speech recognition.

</span>
<span class="ltx_bibblock"><em id="bib.bib54.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1804.03209</em>, 2018.

</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wen et al. (2020)</span>
<span class="ltx_bibblock">
N. Wen, R. Guo, B. He, Yong Fan, and Ding Ma.

</span>
<span class="ltx_bibblock">Block-sparse cnn: towards a fast and memory-efficient framework for
convolutional neural networks.

</span>
<span class="ltx_bibblock"><em id="bib.bib55.1.1" class="ltx_emph ltx_font_italic">Applied Intelligence</em>, 51:441–452, 2020.

</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu et al. (2018)</span>
<span class="ltx_bibblock">
R. Yu, A. Li, C. Chen, J. Lai, V. I. Morariu, X. Han, M. Gao, C. Lin, and L. S.
Davis.

</span>
<span class="ltx_bibblock">Nisp: Pruning networks using neuron importance score propagation.

</span>
<span class="ltx_bibblock">In <em id="bib.bib56.1.1" class="ltx_emph ltx_font_italic">2018 IEEE/CVF Conference on Computer Vision and Pattern
Recognition (CVPR)</em>, pp.  9194–9203, Los Alamitos, CA, USA, jun 2018. IEEE
Computer Society.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1109/CVPR.2018.00958</span>.

</span>
<span class="ltx_bibblock">URL
<a target="_blank" href="https://doi.ieeecomputersociety.org/10.1109/CVPR.2018.00958" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.ieeecomputersociety.org/10.1109/CVPR.2018.00958</a>.

</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yurochkin et al. (2019)</span>
<span class="ltx_bibblock">
Mikhail Yurochkin, Mayank Agarwal, Soumya Ghosh, Kristjan Greenewald, Nghia
Hoang, and Yasaman Khazaeni.

</span>
<span class="ltx_bibblock">Bayesian nonparametric federated learning of neural networks.

</span>
<span class="ltx_bibblock">In <em id="bib.bib57.1.1" class="ltx_emph ltx_font_italic">International Conference on Machine Learning</em>, pp. 7252–7261. PMLR, 2019.

</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zachariadis et al. (2020)</span>
<span class="ltx_bibblock">
Orestis Zachariadis, Nitin Satpute, Juan Gómez-Luna, and Joaquín Olivares.

</span>
<span class="ltx_bibblock">Accelerating sparse matrix–matrix multiplication with gpu tensor
cores.

</span>
<span class="ltx_bibblock"><em id="bib.bib58.1.1" class="ltx_emph ltx_font_italic">Computers &amp; Electrical Engineering</em>, 88:106848, Dec
2020.

</span>
<span class="ltx_bibblock">ISSN 0045-7906.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1016/j.compeleceng.2020.106848</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="http://dx.doi.org/10.1016/j.compeleceng.2020.106848" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://dx.doi.org/10.1016/j.compeleceng.2020.106848</a>.

</span>
</li>
<li id="bib.bib59" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. (2016)</span>
<span class="ltx_bibblock">
S. Zhang, Z. Du, L. Zhang, H. Lan, S. Liu, L. Li, Q. Guo,
T. Chen, and Y. Chen.

</span>
<span class="ltx_bibblock">Cambricon-X: An Accelerator for Sparse Neural Networks.

</span>
<span class="ltx_bibblock">In <em id="bib.bib59.1.1" class="ltx_emph ltx_font_italic">2016 49th Annual IEEE/ACM International Symposium on
Microarchitecture (MICRO)</em>, pp.  1–12, 2016.

</span>
</li>
<li id="bib.bib60" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. (2018)</span>
<span class="ltx_bibblock">
Yundong Zhang, Naveen Suda, Liangzhen Lai, and Vikas Chandra.

</span>
<span class="ltx_bibblock">Hello edge: Keyword spotting on microcontrollers, 2018.

</span>
</li>
<li id="bib.bib61" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhu et al. (2021)</span>
<span class="ltx_bibblock">
Zhuangdi Zhu, Junyuan Hong, and Jiayu Zhou.

</span>
<span class="ltx_bibblock">Data-free knowledge distillation for heterogeneous federated
learning, 2021.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<section id="A1" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Appendix</h2>

<section id="A1.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.1 </span>Impact of <math id="A1.SS1.1.m1.1" class="ltx_Math" alttext="r_{mask}" display="inline"><semantics id="A1.SS1.1.m1.1b"><msub id="A1.SS1.1.m1.1.1" xref="A1.SS1.1.m1.1.1.cmml"><mi id="A1.SS1.1.m1.1.1.2" xref="A1.SS1.1.m1.1.1.2.cmml">r</mi><mrow id="A1.SS1.1.m1.1.1.3" xref="A1.SS1.1.m1.1.1.3.cmml"><mi id="A1.SS1.1.m1.1.1.3.2" xref="A1.SS1.1.m1.1.1.3.2.cmml">m</mi><mo lspace="0em" rspace="0em" id="A1.SS1.1.m1.1.1.3.1" xref="A1.SS1.1.m1.1.1.3.1.cmml">​</mo><mi id="A1.SS1.1.m1.1.1.3.3" xref="A1.SS1.1.m1.1.1.3.3.cmml">a</mi><mo lspace="0em" rspace="0em" id="A1.SS1.1.m1.1.1.3.1b" xref="A1.SS1.1.m1.1.1.3.1.cmml">​</mo><mi id="A1.SS1.1.m1.1.1.3.4" xref="A1.SS1.1.m1.1.1.3.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="A1.SS1.1.m1.1.1.3.1c" xref="A1.SS1.1.m1.1.1.3.1.cmml">​</mo><mi id="A1.SS1.1.m1.1.1.3.5" xref="A1.SS1.1.m1.1.1.3.5.cmml">k</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="A1.SS1.1.m1.1c"><apply id="A1.SS1.1.m1.1.1.cmml" xref="A1.SS1.1.m1.1.1"><csymbol cd="ambiguous" id="A1.SS1.1.m1.1.1.1.cmml" xref="A1.SS1.1.m1.1.1">subscript</csymbol><ci id="A1.SS1.1.m1.1.1.2.cmml" xref="A1.SS1.1.m1.1.1.2">𝑟</ci><apply id="A1.SS1.1.m1.1.1.3.cmml" xref="A1.SS1.1.m1.1.1.3"><times id="A1.SS1.1.m1.1.1.3.1.cmml" xref="A1.SS1.1.m1.1.1.3.1"></times><ci id="A1.SS1.1.m1.1.1.3.2.cmml" xref="A1.SS1.1.m1.1.1.3.2">𝑚</ci><ci id="A1.SS1.1.m1.1.1.3.3.cmml" xref="A1.SS1.1.m1.1.1.3.3">𝑎</ci><ci id="A1.SS1.1.m1.1.1.3.4.cmml" xref="A1.SS1.1.m1.1.1.3.4">𝑠</ci><ci id="A1.SS1.1.m1.1.1.3.5.cmml" xref="A1.SS1.1.m1.1.1.3.5">𝑘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.1.m1.1d">r_{mask}</annotation></semantics></math> in global performance</h3>

<div id="A1.SS1.p1" class="ltx_para ltx_noindent">
<p id="A1.SS1.p1.2" class="ltx_p">We hypothesised in Section <a href="#S6" title="6 ZeroFL: Experimental Results ‣ ZeroFL: Efficient On-Device Training for Federated Learning with Local Sparsity" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> that increasing the masking ratio, <math id="A1.SS1.p1.1.m1.1" class="ltx_Math" alttext="r_{mask}" display="inline"><semantics id="A1.SS1.p1.1.m1.1a"><msub id="A1.SS1.p1.1.m1.1.1" xref="A1.SS1.p1.1.m1.1.1.cmml"><mi id="A1.SS1.p1.1.m1.1.1.2" xref="A1.SS1.p1.1.m1.1.1.2.cmml">r</mi><mrow id="A1.SS1.p1.1.m1.1.1.3" xref="A1.SS1.p1.1.m1.1.1.3.cmml"><mi id="A1.SS1.p1.1.m1.1.1.3.2" xref="A1.SS1.p1.1.m1.1.1.3.2.cmml">m</mi><mo lspace="0em" rspace="0em" id="A1.SS1.p1.1.m1.1.1.3.1" xref="A1.SS1.p1.1.m1.1.1.3.1.cmml">​</mo><mi id="A1.SS1.p1.1.m1.1.1.3.3" xref="A1.SS1.p1.1.m1.1.1.3.3.cmml">a</mi><mo lspace="0em" rspace="0em" id="A1.SS1.p1.1.m1.1.1.3.1a" xref="A1.SS1.p1.1.m1.1.1.3.1.cmml">​</mo><mi id="A1.SS1.p1.1.m1.1.1.3.4" xref="A1.SS1.p1.1.m1.1.1.3.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="A1.SS1.p1.1.m1.1.1.3.1b" xref="A1.SS1.p1.1.m1.1.1.3.1.cmml">​</mo><mi id="A1.SS1.p1.1.m1.1.1.3.5" xref="A1.SS1.p1.1.m1.1.1.3.5.cmml">k</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="A1.SS1.p1.1.m1.1b"><apply id="A1.SS1.p1.1.m1.1.1.cmml" xref="A1.SS1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="A1.SS1.p1.1.m1.1.1.1.cmml" xref="A1.SS1.p1.1.m1.1.1">subscript</csymbol><ci id="A1.SS1.p1.1.m1.1.1.2.cmml" xref="A1.SS1.p1.1.m1.1.1.2">𝑟</ci><apply id="A1.SS1.p1.1.m1.1.1.3.cmml" xref="A1.SS1.p1.1.m1.1.1.3"><times id="A1.SS1.p1.1.m1.1.1.3.1.cmml" xref="A1.SS1.p1.1.m1.1.1.3.1"></times><ci id="A1.SS1.p1.1.m1.1.1.3.2.cmml" xref="A1.SS1.p1.1.m1.1.1.3.2">𝑚</ci><ci id="A1.SS1.p1.1.m1.1.1.3.3.cmml" xref="A1.SS1.p1.1.m1.1.1.3.3">𝑎</ci><ci id="A1.SS1.p1.1.m1.1.1.3.4.cmml" xref="A1.SS1.p1.1.m1.1.1.3.4">𝑠</ci><ci id="A1.SS1.p1.1.m1.1.1.3.5.cmml" xref="A1.SS1.p1.1.m1.1.1.3.5">𝑘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p1.1.m1.1c">r_{mask}</annotation></semantics></math>, which is used to limit the amount of non-zero weights that would be uploaded to the central server after each client completes its local training, would yield better global model performance. However, as it can be observed in Figure <a href="#A1.F4" title="Figure 4 ‣ A.1 Impact of 𝑟_{𝑚⁢𝑎⁢𝑠⁢𝑘} in global performance ‣ Appendix A Appendix ‣ ZeroFL: Efficient On-Device Training for Federated Learning with Local Sparsity" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, test accuracy does not monotonically increase with <math id="A1.SS1.p1.2.m2.1" class="ltx_Math" alttext="r_{mask}" display="inline"><semantics id="A1.SS1.p1.2.m2.1a"><msub id="A1.SS1.p1.2.m2.1.1" xref="A1.SS1.p1.2.m2.1.1.cmml"><mi id="A1.SS1.p1.2.m2.1.1.2" xref="A1.SS1.p1.2.m2.1.1.2.cmml">r</mi><mrow id="A1.SS1.p1.2.m2.1.1.3" xref="A1.SS1.p1.2.m2.1.1.3.cmml"><mi id="A1.SS1.p1.2.m2.1.1.3.2" xref="A1.SS1.p1.2.m2.1.1.3.2.cmml">m</mi><mo lspace="0em" rspace="0em" id="A1.SS1.p1.2.m2.1.1.3.1" xref="A1.SS1.p1.2.m2.1.1.3.1.cmml">​</mo><mi id="A1.SS1.p1.2.m2.1.1.3.3" xref="A1.SS1.p1.2.m2.1.1.3.3.cmml">a</mi><mo lspace="0em" rspace="0em" id="A1.SS1.p1.2.m2.1.1.3.1a" xref="A1.SS1.p1.2.m2.1.1.3.1.cmml">​</mo><mi id="A1.SS1.p1.2.m2.1.1.3.4" xref="A1.SS1.p1.2.m2.1.1.3.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="A1.SS1.p1.2.m2.1.1.3.1b" xref="A1.SS1.p1.2.m2.1.1.3.1.cmml">​</mo><mi id="A1.SS1.p1.2.m2.1.1.3.5" xref="A1.SS1.p1.2.m2.1.1.3.5.cmml">k</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="A1.SS1.p1.2.m2.1b"><apply id="A1.SS1.p1.2.m2.1.1.cmml" xref="A1.SS1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="A1.SS1.p1.2.m2.1.1.1.cmml" xref="A1.SS1.p1.2.m2.1.1">subscript</csymbol><ci id="A1.SS1.p1.2.m2.1.1.2.cmml" xref="A1.SS1.p1.2.m2.1.1.2">𝑟</ci><apply id="A1.SS1.p1.2.m2.1.1.3.cmml" xref="A1.SS1.p1.2.m2.1.1.3"><times id="A1.SS1.p1.2.m2.1.1.3.1.cmml" xref="A1.SS1.p1.2.m2.1.1.3.1"></times><ci id="A1.SS1.p1.2.m2.1.1.3.2.cmml" xref="A1.SS1.p1.2.m2.1.1.3.2">𝑚</ci><ci id="A1.SS1.p1.2.m2.1.1.3.3.cmml" xref="A1.SS1.p1.2.m2.1.1.3.3">𝑎</ci><ci id="A1.SS1.p1.2.m2.1.1.3.4.cmml" xref="A1.SS1.p1.2.m2.1.1.3.4">𝑠</ci><ci id="A1.SS1.p1.2.m2.1.1.3.5.cmml" xref="A1.SS1.p1.2.m2.1.1.3.5">𝑘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p1.2.m2.1c">r_{mask}</annotation></semantics></math> and lower values (i.e. 0.1) that enable large savings in upload communication could perform as good as with larger values (e.g. 0.6) after fine-tuning.</p>
</div>
<figure id="A1.F4" class="ltx_figure"><img src="/html/2208.02507/assets/x3.png" id="A1.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="175" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Larger masking ratios do not offer a clear advantage over smaller values (e.g. 0.1) despite them uploading a larger portion of the model parameters to the server after each round of local training. This experiment is conducted using a non-IID partitioning of CIFAR-10.</figcaption>
</figure>
</section>
<section id="A1.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.2 </span>CIFAR-10 with FedAdam strategy</h3>

<div id="A1.SS2.p1" class="ltx_para ltx_noindent">
<p id="A1.SS2.p1.1" class="ltx_p">Table <a href="#A1.T2" title="Table 2 ‣ A.2 CIFAR-10 with FedAdam strategy ‣ Appendix A Appendix ‣ ZeroFL: Efficient On-Device Training for Federated Learning with Local Sparsity" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> shows the performance of the proposed masking methods in ZeroFL when evaluating CIFAR-10 on the non-IID setting using the FedAdam <cite class="ltx_cite ltx_citemacro_citep">(Reddi et al., <a href="#bib.bib42" title="" class="ltx_ref">2021</a>)</cite> aggregation strategy. The results are inline with what was first observed in Table <a href="#S6.T1" title="Table 1 ‣ 6 ZeroFL: Experimental Results ‣ ZeroFL: Efficient On-Device Training for Federated Learning with Local Sparsity" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> in Section <a href="#S6" title="6 ZeroFL: Experimental Results ‣ ZeroFL: Efficient On-Device Training for Federated Learning with Local Sparsity" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>: at large sparisty ratios (0.95) only ZeroFL making use of</p>
</div>
<figure id="A1.T2" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>CIFAR-10 with FedAdam for the non-IID setting, 100 clients and using 10 clients per round.</figcaption>
<div id="A1.T2.10" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:383.3pt;height:159.3pt;vertical-align:-0.9pt;"><span class="ltx_transformed_inner" style="transform:translate(-26.1pt,10.8pt) scale(0.88,0.88) ;">
<table id="A1.T2.10.10" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="A1.T2.10.10.11.1" class="ltx_tr">
<th id="A1.T2.10.10.11.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt"><span id="A1.T2.10.10.11.1.1.1" class="ltx_text ltx_font_bold">Sparsity</span></th>
<th id="A1.T2.10.10.11.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt"><span id="A1.T2.10.10.11.1.2.1" class="ltx_text ltx_font_bold">Mask</span></th>
<th id="A1.T2.10.10.11.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="A1.T2.10.10.11.1.3.1" class="ltx_text ltx_font_bold">Full Model</span></th>
<th id="A1.T2.10.10.11.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="A1.T2.10.10.11.1.4.1" class="ltx_text ltx_font_bold">Top-K-W.</span></th>
<th id="A1.T2.10.10.11.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="A1.T2.10.10.11.1.5.1" class="ltx_text ltx_font_bold">Diff. Top-K-W.</span></th>
<th id="A1.T2.10.10.11.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt"><span id="A1.T2.10.10.11.1.6.1" class="ltx_text ltx_font_bold">Top-K-W. Diff</span></th>
<th id="A1.T2.10.10.11.1.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt"><span id="A1.T2.10.10.11.1.7.1" class="ltx_text ltx_font_bold">File</span></th>
<th id="A1.T2.10.10.11.1.8" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="A1.T2.10.10.11.1.8.1" class="ltx_text ltx_font_bold">Comms.</span></th>
</tr>
<tr id="A1.T2.10.10.12.2" class="ltx_tr">
<th id="A1.T2.10.10.12.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r"><span id="A1.T2.10.10.12.2.1.1" class="ltx_text ltx_font_bold">Level</span></th>
<th id="A1.T2.10.10.12.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r"><span id="A1.T2.10.10.12.2.2.1" class="ltx_text ltx_font_bold">Ratio</span></th>
<th id="A1.T2.10.10.12.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column">NIID</th>
<th id="A1.T2.10.10.12.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column">NIID</th>
<th id="A1.T2.10.10.12.2.5" class="ltx_td ltx_align_center ltx_th ltx_th_column">NIID</th>
<th id="A1.T2.10.10.12.2.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r">NIID</th>
<th id="A1.T2.10.10.12.2.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r"><span id="A1.T2.10.10.12.2.7.1" class="ltx_text ltx_font_bold">Size</span></th>
<th id="A1.T2.10.10.12.2.8" class="ltx_td ltx_align_center ltx_th ltx_th_column"><span id="A1.T2.10.10.12.2.8.1" class="ltx_text ltx_font_bold">Savings</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="A1.T2.2.2.2" class="ltx_tr">
<th id="A1.T2.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" rowspan="4"><span id="A1.T2.1.1.1.1.1" class="ltx_text">90 <math id="A1.T2.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\%" display="inline"><semantics id="A1.T2.1.1.1.1.1.m1.1a"><mo id="A1.T2.1.1.1.1.1.m1.1.1" xref="A1.T2.1.1.1.1.1.m1.1.1.cmml">%</mo><annotation-xml encoding="MathML-Content" id="A1.T2.1.1.1.1.1.m1.1b"><csymbol cd="latexml" id="A1.T2.1.1.1.1.1.m1.1.1.cmml" xref="A1.T2.1.1.1.1.1.m1.1.1">percent</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T2.1.1.1.1.1.m1.1c">\%</annotation></semantics></math></span></th>
<th id="A1.T2.2.2.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">—</th>
<td id="A1.T2.2.2.2.4" class="ltx_td ltx_align_center ltx_border_t">83.38</td>
<td id="A1.T2.2.2.2.5" class="ltx_td ltx_border_t"></td>
<td id="A1.T2.2.2.2.6" class="ltx_td ltx_border_t"></td>
<td id="A1.T2.2.2.2.7" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="A1.T2.2.2.2.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">43.7</td>
<td id="A1.T2.2.2.2.2" class="ltx_td ltx_align_center ltx_border_t">1<math id="A1.T2.2.2.2.2.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="A1.T2.2.2.2.2.m1.1a"><mo id="A1.T2.2.2.2.2.m1.1.1" xref="A1.T2.2.2.2.2.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="A1.T2.2.2.2.2.m1.1b"><times id="A1.T2.2.2.2.2.m1.1.1.cmml" xref="A1.T2.2.2.2.2.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="A1.T2.2.2.2.2.m1.1c">\times</annotation></semantics></math>
</td>
</tr>
<tr id="A1.T2.3.3.3" class="ltx_tr">
<th id="A1.T2.3.3.3.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">0.0</th>
<td id="A1.T2.3.3.3.3" class="ltx_td"></td>
<td id="A1.T2.3.3.3.4" class="ltx_td ltx_align_center">83.22</td>
<td id="A1.T2.3.3.3.5" class="ltx_td ltx_align_center">82.14</td>
<td id="A1.T2.3.3.3.6" class="ltx_td ltx_align_center ltx_border_r">83.43</td>
<td id="A1.T2.3.3.3.7" class="ltx_td ltx_align_center ltx_border_r">10.1</td>
<td id="A1.T2.3.3.3.1" class="ltx_td ltx_align_center">4.3<math id="A1.T2.3.3.3.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="A1.T2.3.3.3.1.m1.1a"><mo id="A1.T2.3.3.3.1.m1.1.1" xref="A1.T2.3.3.3.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="A1.T2.3.3.3.1.m1.1b"><times id="A1.T2.3.3.3.1.m1.1.1.cmml" xref="A1.T2.3.3.3.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="A1.T2.3.3.3.1.m1.1c">\times</annotation></semantics></math>
</td>
</tr>
<tr id="A1.T2.4.4.4" class="ltx_tr">
<th id="A1.T2.4.4.4.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">0.1</th>
<td id="A1.T2.4.4.4.3" class="ltx_td"></td>
<td id="A1.T2.4.4.4.4" class="ltx_td ltx_align_center"><span id="A1.T2.4.4.4.4.1" class="ltx_text ltx_font_bold">84.01</span></td>
<td id="A1.T2.4.4.4.5" class="ltx_td ltx_align_center">81.58</td>
<td id="A1.T2.4.4.4.6" class="ltx_td ltx_align_center ltx_border_r">83.60</td>
<td id="A1.T2.4.4.4.7" class="ltx_td ltx_align_center ltx_border_r">18.7</td>
<td id="A1.T2.4.4.4.1" class="ltx_td ltx_align_center">2.3<math id="A1.T2.4.4.4.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="A1.T2.4.4.4.1.m1.1a"><mo id="A1.T2.4.4.4.1.m1.1.1" xref="A1.T2.4.4.4.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="A1.T2.4.4.4.1.m1.1b"><times id="A1.T2.4.4.4.1.m1.1.1.cmml" xref="A1.T2.4.4.4.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="A1.T2.4.4.4.1.m1.1c">\times</annotation></semantics></math>
</td>
</tr>
<tr id="A1.T2.5.5.5" class="ltx_tr">
<th id="A1.T2.5.5.5.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">0.2</th>
<td id="A1.T2.5.5.5.3" class="ltx_td"></td>
<td id="A1.T2.5.5.5.4" class="ltx_td ltx_align_center">83.67</td>
<td id="A1.T2.5.5.5.5" class="ltx_td ltx_align_center">83.29</td>
<td id="A1.T2.5.5.5.6" class="ltx_td ltx_align_center ltx_border_r">82.79</td>
<td id="A1.T2.5.5.5.7" class="ltx_td ltx_align_center ltx_border_r">27.3</td>
<td id="A1.T2.5.5.5.1" class="ltx_td ltx_align_center">1.6<math id="A1.T2.5.5.5.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="A1.T2.5.5.5.1.m1.1a"><mo id="A1.T2.5.5.5.1.m1.1.1" xref="A1.T2.5.5.5.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="A1.T2.5.5.5.1.m1.1b"><times id="A1.T2.5.5.5.1.m1.1.1.cmml" xref="A1.T2.5.5.5.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="A1.T2.5.5.5.1.m1.1c">\times</annotation></semantics></math>
</td>
</tr>
<tr id="A1.T2.7.7.7" class="ltx_tr">
<th id="A1.T2.6.6.6.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r ltx_border_t" rowspan="4"><span id="A1.T2.6.6.6.1.1" class="ltx_text">95 <math id="A1.T2.6.6.6.1.1.m1.1" class="ltx_Math" alttext="\%" display="inline"><semantics id="A1.T2.6.6.6.1.1.m1.1a"><mo id="A1.T2.6.6.6.1.1.m1.1.1" xref="A1.T2.6.6.6.1.1.m1.1.1.cmml">%</mo><annotation-xml encoding="MathML-Content" id="A1.T2.6.6.6.1.1.m1.1b"><csymbol cd="latexml" id="A1.T2.6.6.6.1.1.m1.1.1.cmml" xref="A1.T2.6.6.6.1.1.m1.1.1">percent</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T2.6.6.6.1.1.m1.1c">\%</annotation></semantics></math></span></th>
<th id="A1.T2.7.7.7.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">—</th>
<td id="A1.T2.7.7.7.4" class="ltx_td ltx_align_center ltx_border_t">80.69</td>
<td id="A1.T2.7.7.7.5" class="ltx_td ltx_border_t"></td>
<td id="A1.T2.7.7.7.6" class="ltx_td ltx_border_t"></td>
<td id="A1.T2.7.7.7.7" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="A1.T2.7.7.7.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">43.7</td>
<td id="A1.T2.7.7.7.2" class="ltx_td ltx_align_center ltx_border_t">1<math id="A1.T2.7.7.7.2.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="A1.T2.7.7.7.2.m1.1a"><mo id="A1.T2.7.7.7.2.m1.1.1" xref="A1.T2.7.7.7.2.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="A1.T2.7.7.7.2.m1.1b"><times id="A1.T2.7.7.7.2.m1.1.1.cmml" xref="A1.T2.7.7.7.2.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="A1.T2.7.7.7.2.m1.1c">\times</annotation></semantics></math>
</td>
</tr>
<tr id="A1.T2.8.8.8" class="ltx_tr">
<th id="A1.T2.8.8.8.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">0.0</th>
<td id="A1.T2.8.8.8.3" class="ltx_td"></td>
<td id="A1.T2.8.8.8.4" class="ltx_td ltx_align_center">81.11</td>
<td id="A1.T2.8.8.8.5" class="ltx_td ltx_align_center">80.67</td>
<td id="A1.T2.8.8.8.6" class="ltx_td ltx_align_center ltx_border_r">80.45</td>
<td id="A1.T2.8.8.8.7" class="ltx_td ltx_align_center ltx_border_r">5.9</td>
<td id="A1.T2.8.8.8.1" class="ltx_td ltx_align_center">7.4<math id="A1.T2.8.8.8.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="A1.T2.8.8.8.1.m1.1a"><mo id="A1.T2.8.8.8.1.m1.1.1" xref="A1.T2.8.8.8.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="A1.T2.8.8.8.1.m1.1b"><times id="A1.T2.8.8.8.1.m1.1.1.cmml" xref="A1.T2.8.8.8.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="A1.T2.8.8.8.1.m1.1c">\times</annotation></semantics></math>
</td>
</tr>
<tr id="A1.T2.9.9.9" class="ltx_tr">
<th id="A1.T2.9.9.9.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">0.1</th>
<td id="A1.T2.9.9.9.3" class="ltx_td"></td>
<td id="A1.T2.9.9.9.4" class="ltx_td ltx_align_center">81.02</td>
<td id="A1.T2.9.9.9.5" class="ltx_td ltx_align_center">80.29</td>
<td id="A1.T2.9.9.9.6" class="ltx_td ltx_align_center ltx_border_r">80.09</td>
<td id="A1.T2.9.9.9.7" class="ltx_td ltx_align_center ltx_border_r">14.4</td>
<td id="A1.T2.9.9.9.1" class="ltx_td ltx_align_center">3.0<math id="A1.T2.9.9.9.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="A1.T2.9.9.9.1.m1.1a"><mo id="A1.T2.9.9.9.1.m1.1.1" xref="A1.T2.9.9.9.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="A1.T2.9.9.9.1.m1.1b"><times id="A1.T2.9.9.9.1.m1.1.1.cmml" xref="A1.T2.9.9.9.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="A1.T2.9.9.9.1.m1.1c">\times</annotation></semantics></math>
</td>
</tr>
<tr id="A1.T2.10.10.10" class="ltx_tr">
<th id="A1.T2.10.10.10.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r">0.2</th>
<td id="A1.T2.10.10.10.3" class="ltx_td ltx_border_bb"></td>
<td id="A1.T2.10.10.10.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="A1.T2.10.10.10.4.1" class="ltx_text ltx_font_bold">83.30</span></td>
<td id="A1.T2.10.10.10.5" class="ltx_td ltx_align_center ltx_border_bb">81.35</td>
<td id="A1.T2.10.10.10.6" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">81.25</td>
<td id="A1.T2.10.10.10.7" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">23.0</td>
<td id="A1.T2.10.10.10.1" class="ltx_td ltx_align_center ltx_border_bb">1.9<math id="A1.T2.10.10.10.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="A1.T2.10.10.10.1.m1.1a"><mo id="A1.T2.10.10.10.1.m1.1.1" xref="A1.T2.10.10.10.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="A1.T2.10.10.10.1.m1.1b"><times id="A1.T2.10.10.10.1.m1.1.1.cmml" xref="A1.T2.10.10.10.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="A1.T2.10.10.10.1.m1.1c">\times</annotation></semantics></math>
</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
<section id="A1.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.3 </span>Heatmap visualizations</h3>

<div id="A1.SS3.p1" class="ltx_para ltx_noindent">
<p id="A1.SS3.p1.1" class="ltx_p">As mentioned in Fig. <a href="#S4.F3" title="Figure 3 ‣ 4.3 Sparsification Effect Analysis ‣ 4 Sparse Training for Federated Learning ‣ ZeroFL: Efficient On-Device Training for Federated Learning with Local Sparsity" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, a bigger version of heatmap for one of the CNN layer (layer 4) is shown in Fig. <a href="#A1.F5" title="Figure 5 ‣ A.3 Heatmap visualizations ‣ Appendix A Appendix ‣ ZeroFL: Efficient On-Device Training for Federated Learning with Local Sparsity" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> for better reference. Heatmap plots for SpeechCommands can be found in Fig. <a href="#A1.F6" title="Figure 6 ‣ A.3 Heatmap visualizations ‣ Appendix A Appendix ‣ ZeroFL: Efficient On-Device Training for Federated Learning with Local Sparsity" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>, which shows the similar results.</p>
</div>
<figure id="A1.F5" class="ltx_figure"><img src="/html/2208.02507/assets/figures/heat_36_new.png" id="A1.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="266" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Heatmap, in bigger scale, of one CNN layers (layer 4) in ResNet-18 when trained on CIFAR10 with 100 clients by only keeping the top 10% of weights. The weights are recorded every 20 communication rounds and <span id="A1.F5.2.1" class="ltx_text ltx_font_italic">flatten</span> along the y-axis. The consistency across rounds (x-axis) indicates that, for the most part, the locations of non-zero weights remains constant.</figcaption>
</figure>
<figure id="A1.F6" class="ltx_figure"><img src="/html/2208.02507/assets/figures/heat_commands.png" id="A1.F6.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="237" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>Heatmap, of two CNN layers (layer 4 and 9) in ResNet-18 when trained on SpeechCommands with 100 clients by only keeping the top 10% of weights. The weights are recorded every 20 communication rounds and <span id="A1.F6.2.1" class="ltx_text ltx_font_italic">flatten</span> along the y-axis. The consistency across rounds (x-axis) indicates that, for the most part, the locations of non-zero weights remains constant.</figcaption>
</figure>
</section>
<section id="A1.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.4 </span>Additional results for SpeechCommands</h3>

<div id="A1.SS4.p1" class="ltx_para ltx_noindent">
<p id="A1.SS4.p1.4" class="ltx_p">Table <a href="#A1.T3" title="Table 3 ‣ A.4 Additional results for SpeechCommands ‣ Appendix A Appendix ‣ ZeroFL: Efficient On-Device Training for Federated Learning with Local Sparsity" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> reports the performance of ZeroFL SpeechCommands after <math id="A1.SS4.p1.1.m1.1" class="ltx_Math" alttext="300" display="inline"><semantics id="A1.SS4.p1.1.m1.1a"><mn id="A1.SS4.p1.1.m1.1.1" xref="A1.SS4.p1.1.m1.1.1.cmml">300</mn><annotation-xml encoding="MathML-Content" id="A1.SS4.p1.1.m1.1b"><cn type="integer" id="A1.SS4.p1.1.m1.1.1.cmml" xref="A1.SS4.p1.1.m1.1.1">300</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS4.p1.1.m1.1c">300</annotation></semantics></math> communication rounds for both IID and non-IID settings. Combined with Table <a href="#S6.T1" title="Table 1 ‣ 6 ZeroFL: Experimental Results ‣ ZeroFL: Efficient On-Device Training for Federated Learning with Local Sparsity" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, the results show consistent better performance for non-IID settings for mask ratio higher than <math id="A1.SS4.p1.2.m2.1" class="ltx_Math" alttext="0" display="inline"><semantics id="A1.SS4.p1.2.m2.1a"><mn id="A1.SS4.p1.2.m2.1.1" xref="A1.SS4.p1.2.m2.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="A1.SS4.p1.2.m2.1b"><cn type="integer" id="A1.SS4.p1.2.m2.1.1.cmml" xref="A1.SS4.p1.2.m2.1.1">0</cn></annotation-xml></semantics></math>. The increase in accuracy at rounds <math id="A1.SS4.p1.3.m3.1" class="ltx_Math" alttext="200" display="inline"><semantics id="A1.SS4.p1.3.m3.1a"><mn id="A1.SS4.p1.3.m3.1.1" xref="A1.SS4.p1.3.m3.1.1.cmml">200</mn><annotation-xml encoding="MathML-Content" id="A1.SS4.p1.3.m3.1b"><cn type="integer" id="A1.SS4.p1.3.m3.1.1.cmml" xref="A1.SS4.p1.3.m3.1.1">200</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS4.p1.3.m3.1c">200</annotation></semantics></math> in Table <a href="#S6.T1" title="Table 1 ‣ 6 ZeroFL: Experimental Results ‣ ZeroFL: Efficient On-Device Training for Federated Learning with Local Sparsity" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> shows faster convergence of ZeroFL compared with baselines, while improvement in accuracies at rounds <math id="A1.SS4.p1.4.m4.1" class="ltx_Math" alttext="300" display="inline"><semantics id="A1.SS4.p1.4.m4.1a"><mn id="A1.SS4.p1.4.m4.1.1" xref="A1.SS4.p1.4.m4.1.1.cmml">300</mn><annotation-xml encoding="MathML-Content" id="A1.SS4.p1.4.m4.1b"><cn type="integer" id="A1.SS4.p1.4.m4.1.1.cmml" xref="A1.SS4.p1.4.m4.1.1">300</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS4.p1.4.m4.1c">300</annotation></semantics></math> in Table <a href="#A1.T3" title="Table 3 ‣ A.4 Additional results for SpeechCommands ‣ Appendix A Appendix ‣ ZeroFL: Efficient On-Device Training for Federated Learning with Local Sparsity" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> demonstrates the better performance of ZeroFL overall.</p>
</div>
<figure id="A1.T3" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>Experimental results with ZeroFL on SpeechCommands using <math id="A1.T3.9.m1.1" class="ltx_Math" alttext="100" display="inline"><semantics id="A1.T3.9.m1.1b"><mn id="A1.T3.9.m1.1.1" xref="A1.T3.9.m1.1.1.cmml">100</mn><annotation-xml encoding="MathML-Content" id="A1.T3.9.m1.1c"><cn type="integer" id="A1.T3.9.m1.1.1.cmml" xref="A1.T3.9.m1.1.1">100</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.9.m1.1d">100</annotation></semantics></math> clients. We evaluate both IID (<math id="A1.T3.10.m2.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="A1.T3.10.m2.1b"><mi id="A1.T3.10.m2.1.1" xref="A1.T3.10.m2.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="A1.T3.10.m2.1c"><ci id="A1.T3.10.m2.1.1.cmml" xref="A1.T3.10.m2.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.10.m2.1d">\alpha</annotation></semantics></math><math id="A1.T3.11.m3.1" class="ltx_Math" alttext="=" display="inline"><semantics id="A1.T3.11.m3.1b"><mo id="A1.T3.11.m3.1.1" xref="A1.T3.11.m3.1.1.cmml">=</mo><annotation-xml encoding="MathML-Content" id="A1.T3.11.m3.1c"><eq id="A1.T3.11.m3.1.1.cmml" xref="A1.T3.11.m3.1.1"></eq></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.11.m3.1d">=</annotation></semantics></math><math id="A1.T3.12.m4.1" class="ltx_Math" alttext="1.0" display="inline"><semantics id="A1.T3.12.m4.1b"><mn id="A1.T3.12.m4.1.1" xref="A1.T3.12.m4.1.1.cmml">1.0</mn><annotation-xml encoding="MathML-Content" id="A1.T3.12.m4.1c"><cn type="float" id="A1.T3.12.m4.1.1.cmml" xref="A1.T3.12.m4.1.1">1.0</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.12.m4.1d">1.0</annotation></semantics></math>) and non-IID (<math id="A1.T3.13.m5.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="A1.T3.13.m5.1b"><mi id="A1.T3.13.m5.1.1" xref="A1.T3.13.m5.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="A1.T3.13.m5.1c"><ci id="A1.T3.13.m5.1.1.cmml" xref="A1.T3.13.m5.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.13.m5.1d">\alpha</annotation></semantics></math><math id="A1.T3.14.m6.1" class="ltx_Math" alttext="=" display="inline"><semantics id="A1.T3.14.m6.1b"><mo id="A1.T3.14.m6.1.1" xref="A1.T3.14.m6.1.1.cmml">=</mo><annotation-xml encoding="MathML-Content" id="A1.T3.14.m6.1c"><eq id="A1.T3.14.m6.1.1.cmml" xref="A1.T3.14.m6.1.1"></eq></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.14.m6.1d">=</annotation></semantics></math><math id="A1.T3.15.m7.1" class="ltx_Math" alttext="1000" display="inline"><semantics id="A1.T3.15.m7.1b"><mn id="A1.T3.15.m7.1.1" xref="A1.T3.15.m7.1.1.cmml">1000</mn><annotation-xml encoding="MathML-Content" id="A1.T3.15.m7.1c"><cn type="integer" id="A1.T3.15.m7.1.1.cmml" xref="A1.T3.15.m7.1.1">1000</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.15.m7.1d">1000</annotation></semantics></math>) settings. The table reports the highest test accuracy within <math id="A1.T3.16.m8.1" class="ltx_Math" alttext="300" display="inline"><semantics id="A1.T3.16.m8.1b"><mn id="A1.T3.16.m8.1.1" xref="A1.T3.16.m8.1.1.cmml">300</mn><annotation-xml encoding="MathML-Content" id="A1.T3.16.m8.1c"><cn type="integer" id="A1.T3.16.m8.1.1.cmml" xref="A1.T3.16.m8.1.1">300</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.16.m8.1d">300</annotation></semantics></math> rounds.</figcaption>
<div id="A1.T3.24" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:367.9pt;height:105pt;vertical-align:-0.6pt;"><span class="ltx_transformed_inner" style="transform:translate(-133.2pt,37.8pt) scale(0.58,0.58) ;">
<table id="A1.T3.24.8" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="A1.T3.24.8.9.1" class="ltx_tr">
<th id="A1.T3.24.8.9.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt"><span id="A1.T3.24.8.9.1.1.1" class="ltx_text ltx_font_bold">Sp</span></th>
<th id="A1.T3.24.8.9.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt"><span id="A1.T3.24.8.9.1.2.1" class="ltx_text ltx_font_bold">Mask</span></th>
<th id="A1.T3.24.8.9.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="2"><span id="A1.T3.24.8.9.1.3.1" class="ltx_text ltx_font_bold">Full Model</span></th>
<th id="A1.T3.24.8.9.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="2"><span id="A1.T3.24.8.9.1.4.1" class="ltx_text ltx_font_bold">Top-K-W.</span></th>
<th id="A1.T3.24.8.9.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="2"><span id="A1.T3.24.8.9.1.5.1" class="ltx_text ltx_font_bold">Diff. Top-K-W.</span></th>
<th id="A1.T3.24.8.9.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="2"><span id="A1.T3.24.8.9.1.6.1" class="ltx_text ltx_font_bold">Top-K-W. Diff</span></th>
<th id="A1.T3.24.8.9.1.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt"><span id="A1.T3.24.8.9.1.7.1" class="ltx_text ltx_font_bold">File</span></th>
<th id="A1.T3.24.8.9.1.8" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="A1.T3.24.8.9.1.8.1" class="ltx_text ltx_font_bold">Comms.</span></th>
</tr>
<tr id="A1.T3.24.8.10.2" class="ltx_tr">
<th id="A1.T3.24.8.10.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r"><span id="A1.T3.24.8.10.2.1.1" class="ltx_text ltx_font_bold">Level</span></th>
<th id="A1.T3.24.8.10.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r"><span id="A1.T3.24.8.10.2.2.1" class="ltx_text ltx_font_bold">Ratio</span></th>
<th id="A1.T3.24.8.10.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column">IID</th>
<th id="A1.T3.24.8.10.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column">NIID</th>
<th id="A1.T3.24.8.10.2.5" class="ltx_td ltx_align_center ltx_th ltx_th_column">IID</th>
<th id="A1.T3.24.8.10.2.6" class="ltx_td ltx_align_center ltx_th ltx_th_column">NIID</th>
<th id="A1.T3.24.8.10.2.7" class="ltx_td ltx_align_center ltx_th ltx_th_column">IID</th>
<th id="A1.T3.24.8.10.2.8" class="ltx_td ltx_align_center ltx_th ltx_th_column">NIID</th>
<th id="A1.T3.24.8.10.2.9" class="ltx_td ltx_align_center ltx_th ltx_th_column">IID</th>
<th id="A1.T3.24.8.10.2.10" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r">NIID</th>
<th id="A1.T3.24.8.10.2.11" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r"><span id="A1.T3.24.8.10.2.11.1" class="ltx_text ltx_font_bold">Size</span></th>
<th id="A1.T3.24.8.10.2.12" class="ltx_td ltx_align_center ltx_th ltx_th_column"><span id="A1.T3.24.8.10.2.12.1" class="ltx_text ltx_font_bold">Savings</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="A1.T3.17.1.1" class="ltx_tr">
<th id="A1.T3.17.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" rowspan="4"><span id="A1.T3.17.1.1.2.1" class="ltx_text">90 %</span></th>
<th id="A1.T3.17.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">—</th>
<td id="A1.T3.17.1.1.4" class="ltx_td ltx_align_center ltx_border_t">87.47±1.50</td>
<td id="A1.T3.17.1.1.5" class="ltx_td ltx_align_center ltx_border_t">85.36±1.21</td>
<td id="A1.T3.17.1.1.6" class="ltx_td ltx_border_t"></td>
<td id="A1.T3.17.1.1.7" class="ltx_td ltx_border_t"></td>
<td id="A1.T3.17.1.1.8" class="ltx_td ltx_border_t"></td>
<td id="A1.T3.17.1.1.9" class="ltx_td ltx_border_t"></td>
<td id="A1.T3.17.1.1.10" class="ltx_td ltx_border_t"></td>
<td id="A1.T3.17.1.1.11" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="A1.T3.17.1.1.12" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">43.7</td>
<td id="A1.T3.17.1.1.1" class="ltx_td ltx_align_center ltx_border_t">1<math id="A1.T3.17.1.1.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="A1.T3.17.1.1.1.m1.1a"><mo id="A1.T3.17.1.1.1.m1.1.1" xref="A1.T3.17.1.1.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="A1.T3.17.1.1.1.m1.1b"><times id="A1.T3.17.1.1.1.m1.1.1.cmml" xref="A1.T3.17.1.1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.17.1.1.1.m1.1c">\times</annotation></semantics></math>
</td>
</tr>
<tr id="A1.T3.18.2.2" class="ltx_tr">
<th id="A1.T3.18.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">0.0</th>
<td id="A1.T3.18.2.2.3" class="ltx_td"></td>
<td id="A1.T3.18.2.2.4" class="ltx_td"></td>
<td id="A1.T3.18.2.2.5" class="ltx_td ltx_align_center">76.06±2.23</td>
<td id="A1.T3.18.2.2.6" class="ltx_td ltx_align_center">74.99±1.85</td>
<td id="A1.T3.18.2.2.7" class="ltx_td ltx_align_center">76.55±1.37</td>
<td id="A1.T3.18.2.2.8" class="ltx_td ltx_align_center">71.60±2.88</td>
<td id="A1.T3.18.2.2.9" class="ltx_td ltx_align_center">84.51±1.10</td>
<td id="A1.T3.18.2.2.10" class="ltx_td ltx_align_center ltx_border_r">75.77±2.02</td>
<td id="A1.T3.18.2.2.11" class="ltx_td ltx_align_center ltx_border_r">-</td>
<td id="A1.T3.18.2.2.1" class="ltx_td ltx_align_center">4.3<math id="A1.T3.18.2.2.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="A1.T3.18.2.2.1.m1.1a"><mo id="A1.T3.18.2.2.1.m1.1.1" xref="A1.T3.18.2.2.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="A1.T3.18.2.2.1.m1.1b"><times id="A1.T3.18.2.2.1.m1.1.1.cmml" xref="A1.T3.18.2.2.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.18.2.2.1.m1.1c">\times</annotation></semantics></math>
</td>
</tr>
<tr id="A1.T3.19.3.3" class="ltx_tr">
<th id="A1.T3.19.3.3.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">0.1</th>
<td id="A1.T3.19.3.3.3" class="ltx_td"></td>
<td id="A1.T3.19.3.3.4" class="ltx_td"></td>
<td id="A1.T3.19.3.3.5" class="ltx_td ltx_align_center">87.63±0.42</td>
<td id="A1.T3.19.3.3.6" class="ltx_td ltx_align_center">85.44±1.46</td>
<td id="A1.T3.19.3.3.7" class="ltx_td ltx_align_center">86.60±0.31</td>
<td id="A1.T3.19.3.3.8" class="ltx_td ltx_align_center">85.97±1.31</td>
<td id="A1.T3.19.3.3.9" class="ltx_td ltx_align_center">87.40±0.41</td>
<td id="A1.T3.19.3.3.10" class="ltx_td ltx_align_center ltx_border_r">85.03±1.82</td>
<td id="A1.T3.19.3.3.11" class="ltx_td ltx_align_center ltx_border_r">-</td>
<td id="A1.T3.19.3.3.1" class="ltx_td ltx_align_center">2.3<math id="A1.T3.19.3.3.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="A1.T3.19.3.3.1.m1.1a"><mo id="A1.T3.19.3.3.1.m1.1.1" xref="A1.T3.19.3.3.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="A1.T3.19.3.3.1.m1.1b"><times id="A1.T3.19.3.3.1.m1.1.1.cmml" xref="A1.T3.19.3.3.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.19.3.3.1.m1.1c">\times</annotation></semantics></math>
</td>
</tr>
<tr id="A1.T3.20.4.4" class="ltx_tr">
<th id="A1.T3.20.4.4.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">0.2</th>
<td id="A1.T3.20.4.4.3" class="ltx_td"></td>
<td id="A1.T3.20.4.4.4" class="ltx_td"></td>
<td id="A1.T3.20.4.4.5" class="ltx_td ltx_align_center">87.52±0.44</td>
<td id="A1.T3.20.4.4.6" class="ltx_td ltx_align_center">86.20±2.31</td>
<td id="A1.T3.20.4.4.7" class="ltx_td ltx_align_center">87.35±0.48</td>
<td id="A1.T3.20.4.4.8" class="ltx_td ltx_align_center">86.69±1.07</td>
<td id="A1.T3.20.4.4.9" class="ltx_td ltx_align_center">87.97±0.96</td>
<td id="A1.T3.20.4.4.10" class="ltx_td ltx_align_center ltx_border_r">85.46±1.45</td>
<td id="A1.T3.20.4.4.11" class="ltx_td ltx_align_center ltx_border_r">-</td>
<td id="A1.T3.20.4.4.1" class="ltx_td ltx_align_center">1.6<math id="A1.T3.20.4.4.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="A1.T3.20.4.4.1.m1.1a"><mo id="A1.T3.20.4.4.1.m1.1.1" xref="A1.T3.20.4.4.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="A1.T3.20.4.4.1.m1.1b"><times id="A1.T3.20.4.4.1.m1.1.1.cmml" xref="A1.T3.20.4.4.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.20.4.4.1.m1.1c">\times</annotation></semantics></math>
</td>
</tr>
<tr id="A1.T3.21.5.5" class="ltx_tr">
<th id="A1.T3.21.5.5.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r ltx_border_t" rowspan="4"><span id="A1.T3.21.5.5.2.1" class="ltx_text">95 %</span></th>
<th id="A1.T3.21.5.5.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">—</th>
<td id="A1.T3.21.5.5.4" class="ltx_td ltx_align_center ltx_border_t">85.17±1.16</td>
<td id="A1.T3.21.5.5.5" class="ltx_td ltx_align_center ltx_border_t">83.21±1.88</td>
<td id="A1.T3.21.5.5.6" class="ltx_td ltx_border_t"></td>
<td id="A1.T3.21.5.5.7" class="ltx_td ltx_border_t"></td>
<td id="A1.T3.21.5.5.8" class="ltx_td ltx_border_t"></td>
<td id="A1.T3.21.5.5.9" class="ltx_td ltx_border_t"></td>
<td id="A1.T3.21.5.5.10" class="ltx_td ltx_border_t"></td>
<td id="A1.T3.21.5.5.11" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="A1.T3.21.5.5.12" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">43.7</td>
<td id="A1.T3.21.5.5.1" class="ltx_td ltx_align_center ltx_border_t">1<math id="A1.T3.21.5.5.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="A1.T3.21.5.5.1.m1.1a"><mo id="A1.T3.21.5.5.1.m1.1.1" xref="A1.T3.21.5.5.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="A1.T3.21.5.5.1.m1.1b"><times id="A1.T3.21.5.5.1.m1.1.1.cmml" xref="A1.T3.21.5.5.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.21.5.5.1.m1.1c">\times</annotation></semantics></math>
</td>
</tr>
<tr id="A1.T3.22.6.6" class="ltx_tr">
<th id="A1.T3.22.6.6.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">0.0</th>
<td id="A1.T3.22.6.6.3" class="ltx_td"></td>
<td id="A1.T3.22.6.6.4" class="ltx_td"></td>
<td id="A1.T3.22.6.6.5" class="ltx_td ltx_align_center">71.97±0.70</td>
<td id="A1.T3.22.6.6.6" class="ltx_td ltx_align_center">69.40±3.13</td>
<td id="A1.T3.22.6.6.7" class="ltx_td ltx_align_center">73.85±0.75</td>
<td id="A1.T3.22.6.6.8" class="ltx_td ltx_align_center">71.39±1.36</td>
<td id="A1.T3.22.6.6.9" class="ltx_td ltx_align_center">73.10±0.75</td>
<td id="A1.T3.22.6.6.10" class="ltx_td ltx_align_center ltx_border_r">69.68±0.13</td>
<td id="A1.T3.22.6.6.11" class="ltx_td ltx_align_center ltx_border_r">-</td>
<td id="A1.T3.22.6.6.1" class="ltx_td ltx_align_center">7.4<math id="A1.T3.22.6.6.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="A1.T3.22.6.6.1.m1.1a"><mo id="A1.T3.22.6.6.1.m1.1.1" xref="A1.T3.22.6.6.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="A1.T3.22.6.6.1.m1.1b"><times id="A1.T3.22.6.6.1.m1.1.1.cmml" xref="A1.T3.22.6.6.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.22.6.6.1.m1.1c">\times</annotation></semantics></math>
</td>
</tr>
<tr id="A1.T3.23.7.7" class="ltx_tr">
<th id="A1.T3.23.7.7.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">0.1</th>
<td id="A1.T3.23.7.7.3" class="ltx_td"></td>
<td id="A1.T3.23.7.7.4" class="ltx_td"></td>
<td id="A1.T3.23.7.7.5" class="ltx_td ltx_align_center">86.42±0.64</td>
<td id="A1.T3.23.7.7.6" class="ltx_td ltx_align_center">84.52±1.37</td>
<td id="A1.T3.23.7.7.7" class="ltx_td ltx_align_center">83.91±0.77</td>
<td id="A1.T3.23.7.7.8" class="ltx_td ltx_align_center">83.73±0.60</td>
<td id="A1.T3.23.7.7.9" class="ltx_td ltx_align_center">84.40±0.98</td>
<td id="A1.T3.23.7.7.10" class="ltx_td ltx_align_center ltx_border_r">84.06±2.44</td>
<td id="A1.T3.23.7.7.11" class="ltx_td ltx_align_center ltx_border_r">-</td>
<td id="A1.T3.23.7.7.1" class="ltx_td ltx_align_center">3.0<math id="A1.T3.23.7.7.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="A1.T3.23.7.7.1.m1.1a"><mo id="A1.T3.23.7.7.1.m1.1.1" xref="A1.T3.23.7.7.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="A1.T3.23.7.7.1.m1.1b"><times id="A1.T3.23.7.7.1.m1.1.1.cmml" xref="A1.T3.23.7.7.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.23.7.7.1.m1.1c">\times</annotation></semantics></math>
</td>
</tr>
<tr id="A1.T3.24.8.8" class="ltx_tr">
<th id="A1.T3.24.8.8.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r">0.2</th>
<td id="A1.T3.24.8.8.3" class="ltx_td ltx_border_bb"></td>
<td id="A1.T3.24.8.8.4" class="ltx_td ltx_border_bb"></td>
<td id="A1.T3.24.8.8.5" class="ltx_td ltx_align_center ltx_border_bb">85.07±0.64</td>
<td id="A1.T3.24.8.8.6" class="ltx_td ltx_align_center ltx_border_bb">84.31±1.56</td>
<td id="A1.T3.24.8.8.7" class="ltx_td ltx_align_center ltx_border_bb">84.79±0.66</td>
<td id="A1.T3.24.8.8.8" class="ltx_td ltx_align_center ltx_border_bb">82.86±1.81</td>
<td id="A1.T3.24.8.8.9" class="ltx_td ltx_align_center ltx_border_bb">85.29±0.45</td>
<td id="A1.T3.24.8.8.10" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">83.39±1.80</td>
<td id="A1.T3.24.8.8.11" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">-</td>
<td id="A1.T3.24.8.8.1" class="ltx_td ltx_align_center ltx_border_bb">1.9<math id="A1.T3.24.8.8.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="A1.T3.24.8.8.1.m1.1a"><mo id="A1.T3.24.8.8.1.m1.1.1" xref="A1.T3.24.8.8.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="A1.T3.24.8.8.1.m1.1b"><times id="A1.T3.24.8.8.1.m1.1.1.cmml" xref="A1.T3.24.8.8.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.24.8.8.1.m1.1c">\times</annotation></semantics></math>
</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
<section id="A1.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.5 </span>Datasets</h3>

<div id="A1.SS5.p1" class="ltx_para ltx_noindent">
<p id="A1.SS5.p1.6" class="ltx_p">This work considers two image classification tasks of different complexity both in terms of the number of samples and classes: CIFAR10 <cite class="ltx_cite ltx_citemacro_citep">(Krizhevsky et al., <a href="#bib.bib32" title="" class="ltx_ref">2009</a>)</cite> and FEMNIST <cite class="ltx_cite ltx_citemacro_citep">(Caldas et al., <a href="#bib.bib4" title="" class="ltx_ref">2018</a>)</cite> with 10 classes and 62 classes respectively. The former is comprised of 60K <math id="A1.SS5.p1.1.m1.1" class="ltx_Math" alttext="32" display="inline"><semantics id="A1.SS5.p1.1.m1.1a"><mn id="A1.SS5.p1.1.m1.1.1" xref="A1.SS5.p1.1.m1.1.1.cmml">32</mn><annotation-xml encoding="MathML-Content" id="A1.SS5.p1.1.m1.1b"><cn type="integer" id="A1.SS5.p1.1.m1.1.1.cmml" xref="A1.SS5.p1.1.m1.1.1">32</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS5.p1.1.m1.1c">32</annotation></semantics></math><math id="A1.SS5.p1.2.m2.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="A1.SS5.p1.2.m2.1a"><mo id="A1.SS5.p1.2.m2.1.1" xref="A1.SS5.p1.2.m2.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="A1.SS5.p1.2.m2.1b"><times id="A1.SS5.p1.2.m2.1.1.cmml" xref="A1.SS5.p1.2.m2.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="A1.SS5.p1.2.m2.1c">\times</annotation></semantics></math><math id="A1.SS5.p1.3.m3.1" class="ltx_Math" alttext="32" display="inline"><semantics id="A1.SS5.p1.3.m3.1a"><mn id="A1.SS5.p1.3.m3.1.1" xref="A1.SS5.p1.3.m3.1.1.cmml">32</mn><annotation-xml encoding="MathML-Content" id="A1.SS5.p1.3.m3.1b"><cn type="integer" id="A1.SS5.p1.3.m3.1.1.cmml" xref="A1.SS5.p1.3.m3.1.1">32</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS5.p1.3.m3.1c">32</annotation></semantics></math> RGB images for training and 10K images for test. The latter, results in over 652K images for training and over 165K for test. FEMNIST images are <math id="A1.SS5.p1.4.m4.1" class="ltx_Math" alttext="28" display="inline"><semantics id="A1.SS5.p1.4.m4.1a"><mn id="A1.SS5.p1.4.m4.1.1" xref="A1.SS5.p1.4.m4.1.1.cmml">28</mn><annotation-xml encoding="MathML-Content" id="A1.SS5.p1.4.m4.1b"><cn type="integer" id="A1.SS5.p1.4.m4.1.1.cmml" xref="A1.SS5.p1.4.m4.1.1">28</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS5.p1.4.m4.1c">28</annotation></semantics></math><math id="A1.SS5.p1.5.m5.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="A1.SS5.p1.5.m5.1a"><mo id="A1.SS5.p1.5.m5.1.1" xref="A1.SS5.p1.5.m5.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="A1.SS5.p1.5.m5.1b"><times id="A1.SS5.p1.5.m5.1.1.cmml" xref="A1.SS5.p1.5.m5.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="A1.SS5.p1.5.m5.1c">\times</annotation></semantics></math><math id="A1.SS5.p1.6.m6.1" class="ltx_Math" alttext="28" display="inline"><semantics id="A1.SS5.p1.6.m6.1a"><mn id="A1.SS5.p1.6.m6.1.1" xref="A1.SS5.p1.6.m6.1.1.cmml">28</mn><annotation-xml encoding="MathML-Content" id="A1.SS5.p1.6.m6.1b"><cn type="integer" id="A1.SS5.p1.6.m6.1.1.cmml" xref="A1.SS5.p1.6.m6.1.1">28</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS5.p1.6.m6.1c">28</annotation></semantics></math> and grayscale. In both scenarios we randomly extract 10% out from the training set for validation. This is done at the client level, i.e., the validation set for each client is extracted from each client’s training partition. This is done to ensure that the validation set is representative of the underlying distribution.</p>
</div>
<div id="A1.SS5.p2" class="ltx_para ltx_noindent">
<p id="A1.SS5.p2.12" class="ltx_p">In addition, we also perform analysis on the Speech Commands dataset <cite class="ltx_cite ltx_citemacro_citep">(Warden, <a href="#bib.bib54" title="" class="ltx_ref">2018</a>)</cite> which consists of <math id="A1.SS5.p2.1.m1.1" class="ltx_Math" alttext="65K" display="inline"><semantics id="A1.SS5.p2.1.m1.1a"><mrow id="A1.SS5.p2.1.m1.1.1" xref="A1.SS5.p2.1.m1.1.1.cmml"><mn id="A1.SS5.p2.1.m1.1.1.2" xref="A1.SS5.p2.1.m1.1.1.2.cmml">65</mn><mo lspace="0em" rspace="0em" id="A1.SS5.p2.1.m1.1.1.1" xref="A1.SS5.p2.1.m1.1.1.1.cmml">​</mo><mi id="A1.SS5.p2.1.m1.1.1.3" xref="A1.SS5.p2.1.m1.1.1.3.cmml">K</mi></mrow><annotation-xml encoding="MathML-Content" id="A1.SS5.p2.1.m1.1b"><apply id="A1.SS5.p2.1.m1.1.1.cmml" xref="A1.SS5.p2.1.m1.1.1"><times id="A1.SS5.p2.1.m1.1.1.1.cmml" xref="A1.SS5.p2.1.m1.1.1.1"></times><cn type="integer" id="A1.SS5.p2.1.m1.1.1.2.cmml" xref="A1.SS5.p2.1.m1.1.1.2">65</cn><ci id="A1.SS5.p2.1.m1.1.1.3.cmml" xref="A1.SS5.p2.1.m1.1.1.3">𝐾</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS5.p2.1.m1.1c">65K</annotation></semantics></math> 1-second long audio clips of <math id="A1.SS5.p2.2.m2.1" class="ltx_Math" alttext="30" display="inline"><semantics id="A1.SS5.p2.2.m2.1a"><mn id="A1.SS5.p2.2.m2.1.1" xref="A1.SS5.p2.2.m2.1.1.cmml">30</mn><annotation-xml encoding="MathML-Content" id="A1.SS5.p2.2.m2.1b"><cn type="integer" id="A1.SS5.p2.2.m2.1.1.cmml" xref="A1.SS5.p2.2.m2.1.1">30</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS5.p2.2.m2.1c">30</annotation></semantics></math> keywords, with each clip consisting of only one keyword. We train the model to classify the audio clips into one of the <math id="A1.SS5.p2.3.m3.1" class="ltx_Math" alttext="10" display="inline"><semantics id="A1.SS5.p2.3.m3.1a"><mn id="A1.SS5.p2.3.m3.1.1" xref="A1.SS5.p2.3.m3.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="A1.SS5.p2.3.m3.1b"><cn type="integer" id="A1.SS5.p2.3.m3.1.1.cmml" xref="A1.SS5.p2.3.m3.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS5.p2.3.m3.1c">10</annotation></semantics></math> keywords - “Yes”, “No”, “Up”,“Down”, “Left”, “Right”, “On”, “Off”, “Stop”, “Go”, along with “silence” (<span id="A1.SS5.p2.12.1" class="ltx_text ltx_font_italic">i.e.</span> no word spoken) and “unknown” word, representing the remaining <math id="A1.SS5.p2.4.m4.1" class="ltx_Math" alttext="20" display="inline"><semantics id="A1.SS5.p2.4.m4.1a"><mn id="A1.SS5.p2.4.m4.1.1" xref="A1.SS5.p2.4.m4.1.1.cmml">20</mn><annotation-xml encoding="MathML-Content" id="A1.SS5.p2.4.m4.1b"><cn type="integer" id="A1.SS5.p2.4.m4.1.1.cmml" xref="A1.SS5.p2.4.m4.1.1">20</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS5.p2.4.m4.1c">20</annotation></semantics></math> keywords from the dataset. The training set contains a total of <math id="A1.SS5.p2.5.m5.2" class="ltx_Math" alttext="56,196" display="inline"><semantics id="A1.SS5.p2.5.m5.2a"><mrow id="A1.SS5.p2.5.m5.2.3.2" xref="A1.SS5.p2.5.m5.2.3.1.cmml"><mn id="A1.SS5.p2.5.m5.1.1" xref="A1.SS5.p2.5.m5.1.1.cmml">56</mn><mo id="A1.SS5.p2.5.m5.2.3.2.1" xref="A1.SS5.p2.5.m5.2.3.1.cmml">,</mo><mn id="A1.SS5.p2.5.m5.2.2" xref="A1.SS5.p2.5.m5.2.2.cmml">196</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.SS5.p2.5.m5.2b"><list id="A1.SS5.p2.5.m5.2.3.1.cmml" xref="A1.SS5.p2.5.m5.2.3.2"><cn type="integer" id="A1.SS5.p2.5.m5.1.1.cmml" xref="A1.SS5.p2.5.m5.1.1">56</cn><cn type="integer" id="A1.SS5.p2.5.m5.2.2.cmml" xref="A1.SS5.p2.5.m5.2.2">196</cn></list></annotation-xml><annotation encoding="application/x-tex" id="A1.SS5.p2.5.m5.2c">56,196</annotation></semantics></math> clips with <math id="A1.SS5.p2.6.m6.2" class="ltx_Math" alttext="32,550" display="inline"><semantics id="A1.SS5.p2.6.m6.2a"><mrow id="A1.SS5.p2.6.m6.2.3.2" xref="A1.SS5.p2.6.m6.2.3.1.cmml"><mn id="A1.SS5.p2.6.m6.1.1" xref="A1.SS5.p2.6.m6.1.1.cmml">32</mn><mo id="A1.SS5.p2.6.m6.2.3.2.1" xref="A1.SS5.p2.6.m6.2.3.1.cmml">,</mo><mn id="A1.SS5.p2.6.m6.2.2" xref="A1.SS5.p2.6.m6.2.2.cmml">550</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.SS5.p2.6.m6.2b"><list id="A1.SS5.p2.6.m6.2.3.1.cmml" xref="A1.SS5.p2.6.m6.2.3.2"><cn type="integer" id="A1.SS5.p2.6.m6.1.1.cmml" xref="A1.SS5.p2.6.m6.1.1">32</cn><cn type="integer" id="A1.SS5.p2.6.m6.2.2.cmml" xref="A1.SS5.p2.6.m6.2.2">550</cn></list></annotation-xml><annotation encoding="application/x-tex" id="A1.SS5.p2.6.m6.2c">32,550</annotation></semantics></math> (<math id="A1.SS5.p2.7.m7.1" class="ltx_Math" alttext="57\%" display="inline"><semantics id="A1.SS5.p2.7.m7.1a"><mrow id="A1.SS5.p2.7.m7.1.1" xref="A1.SS5.p2.7.m7.1.1.cmml"><mn id="A1.SS5.p2.7.m7.1.1.2" xref="A1.SS5.p2.7.m7.1.1.2.cmml">57</mn><mo id="A1.SS5.p2.7.m7.1.1.1" xref="A1.SS5.p2.7.m7.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="A1.SS5.p2.7.m7.1b"><apply id="A1.SS5.p2.7.m7.1.1.cmml" xref="A1.SS5.p2.7.m7.1.1"><csymbol cd="latexml" id="A1.SS5.p2.7.m7.1.1.1.cmml" xref="A1.SS5.p2.7.m7.1.1.1">percent</csymbol><cn type="integer" id="A1.SS5.p2.7.m7.1.1.2.cmml" xref="A1.SS5.p2.7.m7.1.1.2">57</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS5.p2.7.m7.1c">57\%</annotation></semantics></math>) samples from the “unknown” class and around <math id="A1.SS5.p2.8.m8.1" class="ltx_Math" alttext="1800" display="inline"><semantics id="A1.SS5.p2.8.m8.1a"><mn id="A1.SS5.p2.8.m8.1.1" xref="A1.SS5.p2.8.m8.1.1.cmml">1800</mn><annotation-xml encoding="MathML-Content" id="A1.SS5.p2.8.m8.1b"><cn type="integer" id="A1.SS5.p2.8.m8.1.1.cmml" xref="A1.SS5.p2.8.m8.1.1">1800</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS5.p2.8.m8.1c">1800</annotation></semantics></math> samples (<math id="A1.SS5.p2.9.m9.1" class="ltx_Math" alttext="3.3\%" display="inline"><semantics id="A1.SS5.p2.9.m9.1a"><mrow id="A1.SS5.p2.9.m9.1.1" xref="A1.SS5.p2.9.m9.1.1.cmml"><mn id="A1.SS5.p2.9.m9.1.1.2" xref="A1.SS5.p2.9.m9.1.1.2.cmml">3.3</mn><mo id="A1.SS5.p2.9.m9.1.1.1" xref="A1.SS5.p2.9.m9.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="A1.SS5.p2.9.m9.1b"><apply id="A1.SS5.p2.9.m9.1.1.cmml" xref="A1.SS5.p2.9.m9.1.1"><csymbol cd="latexml" id="A1.SS5.p2.9.m9.1.1.1.cmml" xref="A1.SS5.p2.9.m9.1.1.1">percent</csymbol><cn type="float" id="A1.SS5.p2.9.m9.1.1.2.cmml" xref="A1.SS5.p2.9.m9.1.1.2">3.3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS5.p2.9.m9.1c">3.3\%</annotation></semantics></math>) from each of the remaining classes, hence the dataset is naturally unbalanced. Similarly to <cite class="ltx_cite ltx_citemacro_citep">(Zhang et al., <a href="#bib.bib60" title="" class="ltx_ref">2018</a>)</cite>, each audio clip is preprocessed and <math id="A1.SS5.p2.10.m10.1" class="ltx_Math" alttext="32" display="inline"><semantics id="A1.SS5.p2.10.m10.1a"><mn id="A1.SS5.p2.10.m10.1.1" xref="A1.SS5.p2.10.m10.1.1.cmml">32</mn><annotation-xml encoding="MathML-Content" id="A1.SS5.p2.10.m10.1b"><cn type="integer" id="A1.SS5.p2.10.m10.1.1.cmml" xref="A1.SS5.p2.10.m10.1.1">32</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS5.p2.10.m10.1c">32</annotation></semantics></math><math id="A1.SS5.p2.11.m11.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="A1.SS5.p2.11.m11.1a"><mo id="A1.SS5.p2.11.m11.1.1" xref="A1.SS5.p2.11.m11.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="A1.SS5.p2.11.m11.1b"><times id="A1.SS5.p2.11.m11.1.1.cmml" xref="A1.SS5.p2.11.m11.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="A1.SS5.p2.11.m11.1c">\times</annotation></semantics></math><math id="A1.SS5.p2.12.m12.1" class="ltx_Math" alttext="32" display="inline"><semantics id="A1.SS5.p2.12.m12.1a"><mn id="A1.SS5.p2.12.m12.1.1" xref="A1.SS5.p2.12.m12.1.1.cmml">32</mn><annotation-xml encoding="MathML-Content" id="A1.SS5.p2.12.m12.1b"><cn type="integer" id="A1.SS5.p2.12.m12.1.1.cmml" xref="A1.SS5.p2.12.m12.1.1">32</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS5.p2.12.m12.1c">32</annotation></semantics></math> MFCC features are extracted and fed to the CNN backbone, a ResNet-18 as described in Section <a href="#S4.SS1" title="4.1 Experimental Setup ‣ 4 Sparse Training for Federated Learning ‣ ZeroFL: Efficient On-Device Training for Federated Learning with Local Sparsity" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.1</span></a>.</p>
</div>
</section>
<section id="A1.SS6" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.6 </span>Models and Hyperparameters</h3>

<div id="A1.SS6.p1" class="ltx_para ltx_noindent">
<p id="A1.SS6.p1.1" class="ltx_p">For ResNet-18, all 3<math id="A1.SS6.p1.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="A1.SS6.p1.1.m1.1a"><mo id="A1.SS6.p1.1.m1.1.1" xref="A1.SS6.p1.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="A1.SS6.p1.1.m1.1b"><times id="A1.SS6.p1.1.m1.1.1.cmml" xref="A1.SS6.p1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="A1.SS6.p1.1.m1.1c">\times</annotation></semantics></math>3 convolutional layers implement sparse training as discussed in Sec. <a href="#S3.SS2" title="3.2 From Centralised to Federated Sparse Training ‣ 3 Background ‣ ZeroFL: Efficient On-Device Training for Federated Learning with Local Sparsity" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.2</span></a>. As it is common with other optimizations, we leave the input layer unchanged (i.e. performing standard dense training). This architecture results in 11M parameters.</p>
</div>
<div id="A1.SS6.p2" class="ltx_para ltx_noindent">
<p id="A1.SS6.p2.6" class="ltx_p">For FEMNIST, we borrow the much smaller CNN first proposed by <cite class="ltx_cite ltx_citemacro_citet">Caldas et al. (<a href="#bib.bib4" title="" class="ltx_ref">2018</a>)</cite>. It is comprised of two <math id="A1.SS6.p2.1.m1.1" class="ltx_Math" alttext="5" display="inline"><semantics id="A1.SS6.p2.1.m1.1a"><mn id="A1.SS6.p2.1.m1.1.1" xref="A1.SS6.p2.1.m1.1.1.cmml">5</mn><annotation-xml encoding="MathML-Content" id="A1.SS6.p2.1.m1.1b"><cn type="integer" id="A1.SS6.p2.1.m1.1.1.cmml" xref="A1.SS6.p2.1.m1.1.1">5</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS6.p2.1.m1.1c">5</annotation></semantics></math><math id="A1.SS6.p2.2.m2.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="A1.SS6.p2.2.m2.1a"><mo id="A1.SS6.p2.2.m2.1.1" xref="A1.SS6.p2.2.m2.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="A1.SS6.p2.2.m2.1b"><times id="A1.SS6.p2.2.m2.1.1.cmml" xref="A1.SS6.p2.2.m2.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="A1.SS6.p2.2.m2.1c">\times</annotation></semantics></math><math id="A1.SS6.p2.3.m3.1" class="ltx_Math" alttext="5" display="inline"><semantics id="A1.SS6.p2.3.m3.1a"><mn id="A1.SS6.p2.3.m3.1.1" xref="A1.SS6.p2.3.m3.1.1.cmml">5</mn><annotation-xml encoding="MathML-Content" id="A1.SS6.p2.3.m3.1b"><cn type="integer" id="A1.SS6.p2.3.m3.1.1.cmml" xref="A1.SS6.p2.3.m3.1.1">5</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS6.p2.3.m3.1c">5</annotation></semantics></math> convolutional layers (each followed by a <math id="A1.SS6.p2.4.m4.1" class="ltx_Math" alttext="2" display="inline"><semantics id="A1.SS6.p2.4.m4.1a"><mn id="A1.SS6.p2.4.m4.1.1" xref="A1.SS6.p2.4.m4.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="A1.SS6.p2.4.m4.1b"><cn type="integer" id="A1.SS6.p2.4.m4.1.1.cmml" xref="A1.SS6.p2.4.m4.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS6.p2.4.m4.1c">2</annotation></semantics></math><math id="A1.SS6.p2.5.m5.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="A1.SS6.p2.5.m5.1a"><mo id="A1.SS6.p2.5.m5.1.1" xref="A1.SS6.p2.5.m5.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="A1.SS6.p2.5.m5.1b"><times id="A1.SS6.p2.5.m5.1.1.cmml" xref="A1.SS6.p2.5.m5.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="A1.SS6.p2.5.m5.1c">\times</annotation></semantics></math><math id="A1.SS6.p2.6.m6.1" class="ltx_Math" alttext="2" display="inline"><semantics id="A1.SS6.p2.6.m6.1a"><mn id="A1.SS6.p2.6.m6.1.1" xref="A1.SS6.p2.6.m6.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="A1.SS6.p2.6.m6.1b"><cn type="integer" id="A1.SS6.p2.6.m6.1.1.cmml" xref="A1.SS6.p2.6.m6.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS6.p2.6.m6.1c">2</annotation></semantics></math> maxpool laye) and two linear layers. We sparsify both convolutional layers and the first linear layer but leave the final layer unchanged (i.e. dense). This architecture results in parameters 6.6M parameters, which the first linear layer accounting for 97% of the memory footprint.</p>
</div>
<div id="A1.SS6.p3" class="ltx_para ltx_noindent">
<p id="A1.SS6.p3.6" class="ltx_p">All our experiments make use of the following hyperparameters. The start and end learning rate are <math id="A1.SS6.p3.1.m1.1" class="ltx_Math" alttext="0.1" display="inline"><semantics id="A1.SS6.p3.1.m1.1a"><mn id="A1.SS6.p3.1.m1.1.1" xref="A1.SS6.p3.1.m1.1.1.cmml">0.1</mn><annotation-xml encoding="MathML-Content" id="A1.SS6.p3.1.m1.1b"><cn type="float" id="A1.SS6.p3.1.m1.1.1.cmml" xref="A1.SS6.p3.1.m1.1.1">0.1</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS6.p3.1.m1.1c">0.1</annotation></semantics></math> and <math id="A1.SS6.p3.2.m2.1" class="ltx_Math" alttext="0.01" display="inline"><semantics id="A1.SS6.p3.2.m2.1a"><mn id="A1.SS6.p3.2.m2.1.1" xref="A1.SS6.p3.2.m2.1.1.cmml">0.01</mn><annotation-xml encoding="MathML-Content" id="A1.SS6.p3.2.m2.1b"><cn type="float" id="A1.SS6.p3.2.m2.1.1.cmml" xref="A1.SS6.p3.2.m2.1.1">0.01</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS6.p3.2.m2.1c">0.01</annotation></semantics></math> respectively for CIFAR10, <math id="A1.SS6.p3.3.m3.1" class="ltx_Math" alttext="0.01" display="inline"><semantics id="A1.SS6.p3.3.m3.1a"><mn id="A1.SS6.p3.3.m3.1.1" xref="A1.SS6.p3.3.m3.1.1.cmml">0.01</mn><annotation-xml encoding="MathML-Content" id="A1.SS6.p3.3.m3.1b"><cn type="float" id="A1.SS6.p3.3.m3.1.1.cmml" xref="A1.SS6.p3.3.m3.1.1">0.01</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS6.p3.3.m3.1c">0.01</annotation></semantics></math> and <math id="A1.SS6.p3.4.m4.1" class="ltx_Math" alttext="0.001" display="inline"><semantics id="A1.SS6.p3.4.m4.1a"><mn id="A1.SS6.p3.4.m4.1.1" xref="A1.SS6.p3.4.m4.1.1.cmml">0.001</mn><annotation-xml encoding="MathML-Content" id="A1.SS6.p3.4.m4.1b"><cn type="float" id="A1.SS6.p3.4.m4.1.1.cmml" xref="A1.SS6.p3.4.m4.1.1">0.001</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS6.p3.4.m4.1c">0.001</annotation></semantics></math> for Speech Commands, and <math id="A1.SS6.p3.5.m5.1" class="ltx_Math" alttext="0.004" display="inline"><semantics id="A1.SS6.p3.5.m5.1a"><mn id="A1.SS6.p3.5.m5.1.1" xref="A1.SS6.p3.5.m5.1.1.cmml">0.004</mn><annotation-xml encoding="MathML-Content" id="A1.SS6.p3.5.m5.1b"><cn type="float" id="A1.SS6.p3.5.m5.1.1.cmml" xref="A1.SS6.p3.5.m5.1.1">0.004</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS6.p3.5.m5.1c">0.004</annotation></semantics></math> and <math id="A1.SS6.p3.6.m6.1" class="ltx_Math" alttext="0.001" display="inline"><semantics id="A1.SS6.p3.6.m6.1a"><mn id="A1.SS6.p3.6.m6.1.1" xref="A1.SS6.p3.6.m6.1.1.cmml">0.001</mn><annotation-xml encoding="MathML-Content" id="A1.SS6.p3.6.m6.1b"><cn type="float" id="A1.SS6.p3.6.m6.1.1.cmml" xref="A1.SS6.p3.6.m6.1.1">0.001</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS6.p3.6.m6.1c">0.001</annotation></semantics></math> for FEMNIST.</p>
</div>
</section>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2208.02506" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2208.02507" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2208.02507">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2208.02507" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2208.02508" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Wed Mar 13 20:48:19 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
