<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Atlas-Chat: Adapting Large Language Models for Low-Resource Moroccan Arabic Dialect</title>
<!--Generated on Thu Sep 26 14:34:55 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2409.17912v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#S1" title="In Atlas-Chat: Adapting Large Language Models for Low-Resource Moroccan Arabic Dialect"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#S2" title="In Atlas-Chat: Adapting Large Language Models for Low-Resource Moroccan Arabic Dialect"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Related work</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#S3" title="In Atlas-Chat: Adapting Large Language Models for Low-Resource Moroccan Arabic Dialect"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Data overview</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#S4" title="In Atlas-Chat: Adapting Large Language Models for Low-Resource Moroccan Arabic Dialect"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Native Darija instruction datasets</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#S4.SS1" title="In 4 Native Darija instruction datasets ‣ Atlas-Chat: Adapting Large Language Models for Low-Resource Moroccan Arabic Dialect"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Machine translation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#S4.SS2" title="In 4 Native Darija instruction datasets ‣ Atlas-Chat: Adapting Large Language Models for Low-Resource Moroccan Arabic Dialect"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Sentiment analysis</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#S4.SS3" title="In 4 Native Darija instruction datasets ‣ Atlas-Chat: Adapting Large Language Models for Low-Resource Moroccan Arabic Dialect"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3 </span>Automatic summarization</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#S5" title="In Atlas-Chat: Adapting Large Language Models for Low-Resource Moroccan Arabic Dialect"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Synthetic Darija instruction datasets</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#S5.SS1" title="In 5 Synthetic Darija instruction datasets ‣ Atlas-Chat: Adapting Large Language Models for Low-Resource Moroccan Arabic Dialect"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1 </span>MoroccanWikipedia-QA (MW-QA)</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#S5.SS2" title="In 5 Synthetic Darija instruction datasets ‣ Atlas-Chat: Adapting Large Language Models for Low-Resource Moroccan Arabic Dialect"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2 </span>MoroccanSocialMedia-MultiGen (MSM-MG)</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#S5.SS3" title="In 5 Synthetic Darija instruction datasets ‣ Atlas-Chat: Adapting Large Language Models for Low-Resource Moroccan Arabic Dialect"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.3 </span>DarijaStory-Completion</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#S6" title="In Atlas-Chat: Adapting Large Language Models for Low-Resource Moroccan Arabic Dialect"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Translated English instruction datasets</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#S7" title="In Atlas-Chat: Adapting Large Language Models for Low-Resource Moroccan Arabic Dialect"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7 </span>Training details</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#S8" title="In Atlas-Chat: Adapting Large Language Models for Low-Resource Moroccan Arabic Dialect"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">8 </span>Evaluation benchmarks</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#S9" title="In Atlas-Chat: Adapting Large Language Models for Low-Resource Moroccan Arabic Dialect"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">9 </span>Results</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#S10" title="In Atlas-Chat: Adapting Large Language Models for Low-Resource Moroccan Arabic Dialect"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">10 </span>Conclusion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#A1" title="In Atlas-Chat: Adapting Large Language Models for Low-Resource Moroccan Arabic Dialect"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A </span>Instruction data templates</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#A1.SS1" title="In Appendix A Instruction data templates ‣ Atlas-Chat: Adapting Large Language Models for Low-Resource Moroccan Arabic Dialect"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.1 </span>Machine translation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#A1.SS2" title="In Appendix A Instruction data templates ‣ Atlas-Chat: Adapting Large Language Models for Low-Resource Moroccan Arabic Dialect"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.2 </span>Transliteration</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#A1.SS3" title="In Appendix A Instruction data templates ‣ Atlas-Chat: Adapting Large Language Models for Low-Resource Moroccan Arabic Dialect"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.3 </span>Sentiment analysis</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#A1.SS4" title="In Appendix A Instruction data templates ‣ Atlas-Chat: Adapting Large Language Models for Low-Resource Moroccan Arabic Dialect"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.4 </span>Automatic summarization</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#A1.SS5" title="In Appendix A Instruction data templates ‣ Atlas-Chat: Adapting Large Language Models for Low-Resource Moroccan Arabic Dialect"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.5 </span>MoroccanWikipedia-QA</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#A1.SS6" title="In Appendix A Instruction data templates ‣ Atlas-Chat: Adapting Large Language Models for Low-Resource Moroccan Arabic Dialect"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.6 </span>MoroccanSocialMedia-MultiGen</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#A1.SS7" title="In Appendix A Instruction data templates ‣ Atlas-Chat: Adapting Large Language Models for Low-Resource Moroccan Arabic Dialect"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.7 </span>DarijaStory-Completion</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#A2" title="In Atlas-Chat: Adapting Large Language Models for Low-Resource Moroccan Arabic Dialect"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B </span>TÜLU-V2-mix and its translation</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#A2.SS1" title="In Appendix B TÜLU-V2-mix and its translation ‣ Atlas-Chat: Adapting Large Language Models for Low-Resource Moroccan Arabic Dialect"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B.1 </span>Composition of TÜLU-V2-mix</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#A2.SS2" title="In Appendix B TÜLU-V2-mix and its translation ‣ Atlas-Chat: Adapting Large Language Models for Low-Resource Moroccan Arabic Dialect"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B.2 </span>Dataset Format</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#A2.SS3" title="In Appendix B TÜLU-V2-mix and its translation ‣ Atlas-Chat: Adapting Large Language Models for Low-Resource Moroccan Arabic Dialect"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B.3 </span>Translation to Darija</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#A2.SS3.SSS1" title="In B.3 Translation to Darija ‣ Appendix B TÜLU-V2-mix and its translation ‣ Atlas-Chat: Adapting Large Language Models for Low-Resource Moroccan Arabic Dialect"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B.3.1 </span>Preprocessing</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#A2.SS3.SSS2" title="In B.3 Translation to Darija ‣ Appendix B TÜLU-V2-mix and its translation ‣ Atlas-Chat: Adapting Large Language Models for Low-Resource Moroccan Arabic Dialect"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B.3.2 </span>Translation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#A2.SS3.SSS3" title="In B.3 Translation to Darija ‣ Appendix B TÜLU-V2-mix and its translation ‣ Atlas-Chat: Adapting Large Language Models for Low-Resource Moroccan Arabic Dialect"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B.3.3 </span>Postprocessing</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#A3" title="In Atlas-Chat: Adapting Large Language Models for Low-Resource Moroccan Arabic Dialect"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">C </span>Additional details</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#A3.SS1" title="In Appendix C Additional details ‣ Atlas-Chat: Adapting Large Language Models for Low-Resource Moroccan Arabic Dialect"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">C.1 </span>Hard coded instruction samples</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#A3.SS2" title="In Appendix C Additional details ‣ Atlas-Chat: Adapting Large Language Models for Low-Resource Moroccan Arabic Dialect"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">C.2 </span>Selected keywords for tweet searching</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#A3.SS3" title="In Appendix C Additional details ‣ Atlas-Chat: Adapting Large Language Models for Low-Resource Moroccan Arabic Dialect"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">C.3 </span>Selected topics from MMLU and ArabicMMLU</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#A3.SS4" title="In Appendix C Additional details ‣ Atlas-Chat: Adapting Large Language Models for Low-Resource Moroccan Arabic Dialect"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">C.4 </span>LLM-as-Judge prompt for summarization evaluation</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#A4" title="In Atlas-Chat: Adapting Large Language Models for Low-Resource Moroccan Arabic Dialect"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">D </span>Examples of Atlas-Chat-9B responses</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document">
<h1 class="ltx_title ltx_title_document">Atlas-Chat: Adapting Large Language Models for Low-Resource Moroccan Arabic Dialect</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
<span class="ltx_text ltx_font_bold" id="id1.1.1">Guokan Shang<sup class="ltx_sup" id="id1.1.1.1">1</sup><sup class="ltx_sup" id="id1.1.1.2"><span class="ltx_text ltx_font_medium" id="id1.1.1.2.1">†</span></sup></span>,
<span class="ltx_text ltx_font_bold" id="id2.2.2">Hadi Abdine<sup class="ltx_sup" id="id2.2.2.1">1</sup><sup class="ltx_sup" id="id2.2.2.2"><span class="ltx_text ltx_font_medium" id="id2.2.2.2.1">†</span></sup></span>,
<span class="ltx_text ltx_font_bold" id="id3.3.3">Yousef Khoubrane<sup class="ltx_sup" id="id3.3.3.1">2,3</sup><sup class="ltx_sup" id="id3.3.3.2"><span class="ltx_text ltx_font_medium" id="id3.3.3.2.1">†</span></sup></span>,
<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="id7.4.id1">Amr Mohamed<sup class="ltx_sup" id="id7.4.id1.1">1</sup></span>,
<span class="ltx_text ltx_font_bold" id="id8.5.id2">Yassine Abbahaddou<sup class="ltx_sup" id="id8.5.id2.1">6</sup></span>,
<span class="ltx_text ltx_font_bold" id="id9.6.id3">Sofiane Ennadir<sup class="ltx_sup" id="id9.6.id3.1">4</sup></span>,
<span class="ltx_text ltx_font_bold" id="id10.7.id4">Imane Momayiz<sup class="ltx_sup" id="id10.7.id4.1">5</sup></span>,

<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="id11.8.id5">Xuguang Ren<sup class="ltx_sup" id="id11.8.id5.1">1</sup></span>,
<span class="ltx_text ltx_font_bold" id="id12.9.id6">Eric Moulines<sup class="ltx_sup" id="id12.9.id6.1">1,6</sup></span>,
<span class="ltx_text ltx_font_bold" id="id13.10.id7">Preslav Nakov<sup class="ltx_sup" id="id13.10.id7.1">1</sup></span>,
<span class="ltx_text ltx_font_bold" id="id14.11.id8">Michalis Vazirgiannis<sup class="ltx_sup" id="id14.11.id8.1">1,6</sup></span>,
<span class="ltx_text ltx_font_bold" id="id15.12.id9">Eric Xing<sup class="ltx_sup" id="id15.12.id9.1">1</sup></span>
<br class="ltx_break"/>
<br class="ltx_break"/><sup class="ltx_sup" id="id16.13.id10">1</sup>MBZUAI,
<sup class="ltx_sup" id="id17.14.id11">2</sup>EMINES-UM6P,
<sup class="ltx_sup" id="id18.15.id12">3</sup>LINAGORA,
<sup class="ltx_sup" id="id19.16.id13">4</sup>KTH,
<sup class="ltx_sup" id="id20.17.id14">5</sup>AtlasIA,
<sup class="ltx_sup" id="id21.18.id15">6</sup>Ecole Polytechnique
</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<span class="ltx_ERROR undefined" id="id22.id1">\setcode</span>
<p class="ltx_p" id="id23.id2">utf8
</p>
<div class="ltx_block ltx_align_bottom" id="id6.3">
<p class="ltx_p" id="id6.3.4"><span class="ltx_text ltx_font_bold" id="id6.3.4.1">Atlas-Chat: Adapting Large Language Models for Low-Resource Moroccan Arabic Dialect</span></p>
<br class="ltx_break ltx_centering"/>
<p class="ltx_p ltx_align_center" id="id6.3.3" style="width:433.6pt;"><span class="ltx_text ltx_inline-block" id="id6.3.3.3" style="width:0.0pt;">
<span class="ltx_tabular ltx_align_top" id="id6.3.3.3.3">
<span class="ltx_tbody">
<span class="ltx_tr" id="id6.3.3.3.3.3">
<span class="ltx_td ltx_align_center" id="id6.3.3.3.3.3.3"><span class="ltx_text ltx_font_bold" id="id6.3.3.3.3.3.3.3">
Guokan Shang<sup class="ltx_sup" id="id6.3.3.3.3.3.3.3.1">1</sup><sup class="ltx_sup" id="id6.3.3.3.3.3.3.3.2"><span class="ltx_text ltx_font_medium" id="id6.3.3.3.3.3.3.3.2.1">†</span></sup>,
Hadi Abdine<sup class="ltx_sup" id="id6.3.3.3.3.3.3.3.3">1</sup><sup class="ltx_sup" id="id6.3.3.3.3.3.3.3.4"><span class="ltx_text ltx_font_medium" id="id6.3.3.3.3.3.3.3.4.1">†</span></sup>,
Yousef Khoubrane<sup class="ltx_sup" id="id6.3.3.3.3.3.3.3.5">2,3</sup><sup class="ltx_sup" id="id6.3.3.3.3.3.3.3.6"><span class="ltx_text ltx_font_medium" id="id6.3.3.3.3.3.3.3.6.1">†</span></sup>,</span></span></span>
<span class="ltx_tr" id="id6.3.3.3.3.4.1">
<span class="ltx_td ltx_align_center" id="id6.3.3.3.3.4.1.1"><span class="ltx_text ltx_font_bold" id="id6.3.3.3.3.4.1.1.1">Amr Mohamed<sup class="ltx_sup" id="id6.3.3.3.3.4.1.1.1.1">1</sup></span>,
<span class="ltx_text ltx_font_bold" id="id6.3.3.3.3.4.1.1.2">Yassine Abbahaddou<sup class="ltx_sup" id="id6.3.3.3.3.4.1.1.2.1">6</sup></span>,
<span class="ltx_text ltx_font_bold" id="id6.3.3.3.3.4.1.1.3">Sofiane Ennadir<sup class="ltx_sup" id="id6.3.3.3.3.4.1.1.3.1">4</sup></span>,
<span class="ltx_text ltx_font_bold" id="id6.3.3.3.3.4.1.1.4">Imane Momayiz<sup class="ltx_sup" id="id6.3.3.3.3.4.1.1.4.1">5</sup></span>,</span></span>
<span class="ltx_tr" id="id6.3.3.3.3.5.2">
<span class="ltx_td ltx_align_center" id="id6.3.3.3.3.5.2.1"><span class="ltx_text ltx_font_bold" id="id6.3.3.3.3.5.2.1.1">Xuguang Ren<sup class="ltx_sup" id="id6.3.3.3.3.5.2.1.1.1">1</sup></span>,
<span class="ltx_text ltx_font_bold" id="id6.3.3.3.3.5.2.1.2">Eric Moulines<sup class="ltx_sup" id="id6.3.3.3.3.5.2.1.2.1">1,6</sup></span>,
<span class="ltx_text ltx_font_bold" id="id6.3.3.3.3.5.2.1.3">Preslav Nakov<sup class="ltx_sup" id="id6.3.3.3.3.5.2.1.3.1">1</sup></span>,
<span class="ltx_text ltx_font_bold" id="id6.3.3.3.3.5.2.1.4">Michalis Vazirgiannis<sup class="ltx_sup" id="id6.3.3.3.3.5.2.1.4.1">1,6</sup></span>,
<span class="ltx_text ltx_font_bold" id="id6.3.3.3.3.5.2.1.5">Eric Xing<sup class="ltx_sup" id="id6.3.3.3.3.5.2.1.5.1">1</sup></span></span></span>
<span class="ltx_tr" id="id6.3.3.3.3.6.3">
<span class="ltx_td ltx_align_center" id="id6.3.3.3.3.6.3.1"><sup class="ltx_sup" id="id6.3.3.3.3.6.3.1.1">1</sup>MBZUAI,
<sup class="ltx_sup" id="id6.3.3.3.3.6.3.1.2">2</sup>EMINES-UM6P,
<sup class="ltx_sup" id="id6.3.3.3.3.6.3.1.3">3</sup>LINAGORA,
<sup class="ltx_sup" id="id6.3.3.3.3.6.3.1.4">4</sup>KTH,
<sup class="ltx_sup" id="id6.3.3.3.3.6.3.1.5">5</sup>AtlasIA,
<sup class="ltx_sup" id="id6.3.3.3.3.6.3.1.6">6</sup>Ecole Polytechnique</span></span>
</span>
</span></span></p>
<br class="ltx_break ltx_centering"/>
</div>
<span class="ltx_note ltx_role_footnotetext" id="footnotex1"><sup class="ltx_note_mark">$\dagger$</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">$\dagger$</sup><span class="ltx_note_type">footnotetext: </span>These authors contributed equally.</span></span></span><span class="ltx_note ltx_role_footnotetext" id="footnotex2"><sup class="ltx_note_mark">$\dagger$</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">$\dagger$</sup><span class="ltx_note_type">footnotetext: </span>Correspondence: <a class="ltx_ref ltx_href" href="mailto:guokan.shang@mbzuai.ac.ae" title="">guokan.shang@mbzuai.ac.ae</a></span></span></span>
</div>
<div class="ltx_para" id="p1">
<span class="ltx_ERROR undefined" id="p1.1">\setcode</span>
<p class="ltx_p" id="p1.2">utf8
</p>
</div>
<div class="ltx_para ltx_noindent" id="p2">
<div class="ltx_block ltx_align_bottom" id="p2.3">
<p class="ltx_p" id="p2.3.4"><span class="ltx_text ltx_font_bold" id="p2.3.4.1">Atlas-Chat: Adapting Large Language Models for Low-Resource Moroccan Arabic Dialect</span></p>
<br class="ltx_break ltx_centering"/>
<p class="ltx_p ltx_align_center" id="p2.3.3" style="width:433.6pt;"><span class="ltx_text ltx_inline-block" id="p2.3.3.3" style="width:0.0pt;">
<span class="ltx_tabular ltx_align_top" id="p2.3.3.3.3">
<span class="ltx_tbody">
<span class="ltx_tr" id="p2.3.3.3.3.3">
<span class="ltx_td ltx_align_center" id="p2.3.3.3.3.3.3"><span class="ltx_text ltx_font_bold" id="p2.3.3.3.3.3.3.3">
Guokan Shang<sup class="ltx_sup" id="p2.3.3.3.3.3.3.3.1">1</sup><sup class="ltx_sup" id="p2.3.3.3.3.3.3.3.2"><span class="ltx_text ltx_font_medium" id="p2.3.3.3.3.3.3.3.2.1">†</span></sup>,
Hadi Abdine<sup class="ltx_sup" id="p2.3.3.3.3.3.3.3.3">1</sup><sup class="ltx_sup" id="p2.3.3.3.3.3.3.3.4"><span class="ltx_text ltx_font_medium" id="p2.3.3.3.3.3.3.3.4.1">†</span></sup>,
Yousef Khoubrane<sup class="ltx_sup" id="p2.3.3.3.3.3.3.3.5">2,3</sup><sup class="ltx_sup" id="p2.3.3.3.3.3.3.3.6"><span class="ltx_text ltx_font_medium" id="p2.3.3.3.3.3.3.3.6.1">†</span></sup>,</span></span></span>
<span class="ltx_tr" id="p2.3.3.3.3.4.1">
<span class="ltx_td ltx_align_center" id="p2.3.3.3.3.4.1.1"><span class="ltx_text ltx_font_bold" id="p2.3.3.3.3.4.1.1.1">Amr Mohamed<sup class="ltx_sup" id="p2.3.3.3.3.4.1.1.1.1">1</sup></span>,
<span class="ltx_text ltx_font_bold" id="p2.3.3.3.3.4.1.1.2">Yassine Abbahaddou<sup class="ltx_sup" id="p2.3.3.3.3.4.1.1.2.1">6</sup></span>,
<span class="ltx_text ltx_font_bold" id="p2.3.3.3.3.4.1.1.3">Sofiane Ennadir<sup class="ltx_sup" id="p2.3.3.3.3.4.1.1.3.1">4</sup></span>,
<span class="ltx_text ltx_font_bold" id="p2.3.3.3.3.4.1.1.4">Imane Momayiz<sup class="ltx_sup" id="p2.3.3.3.3.4.1.1.4.1">5</sup></span>,</span></span>
<span class="ltx_tr" id="p2.3.3.3.3.5.2">
<span class="ltx_td ltx_align_center" id="p2.3.3.3.3.5.2.1"><span class="ltx_text ltx_font_bold" id="p2.3.3.3.3.5.2.1.1">Xuguang Ren<sup class="ltx_sup" id="p2.3.3.3.3.5.2.1.1.1">1</sup></span>,
<span class="ltx_text ltx_font_bold" id="p2.3.3.3.3.5.2.1.2">Eric Moulines<sup class="ltx_sup" id="p2.3.3.3.3.5.2.1.2.1">1,6</sup></span>,
<span class="ltx_text ltx_font_bold" id="p2.3.3.3.3.5.2.1.3">Preslav Nakov<sup class="ltx_sup" id="p2.3.3.3.3.5.2.1.3.1">1</sup></span>,
<span class="ltx_text ltx_font_bold" id="p2.3.3.3.3.5.2.1.4">Michalis Vazirgiannis<sup class="ltx_sup" id="p2.3.3.3.3.5.2.1.4.1">1,6</sup></span>,
<span class="ltx_text ltx_font_bold" id="p2.3.3.3.3.5.2.1.5">Eric Xing<sup class="ltx_sup" id="p2.3.3.3.3.5.2.1.5.1">1</sup></span></span></span>
<span class="ltx_tr" id="p2.3.3.3.3.6.3">
<span class="ltx_td ltx_align_center" id="p2.3.3.3.3.6.3.1"><sup class="ltx_sup" id="p2.3.3.3.3.6.3.1.1">1</sup>MBZUAI,
<sup class="ltx_sup" id="p2.3.3.3.3.6.3.1.2">2</sup>EMINES-UM6P,
<sup class="ltx_sup" id="p2.3.3.3.3.6.3.1.3">3</sup>LINAGORA,
<sup class="ltx_sup" id="p2.3.3.3.3.6.3.1.4">4</sup>KTH,
<sup class="ltx_sup" id="p2.3.3.3.3.6.3.1.5">5</sup>AtlasIA,
<sup class="ltx_sup" id="p2.3.3.3.3.6.3.1.6">6</sup>Ecole Polytechnique</span></span>
</span>
</span></span></p>
<br class="ltx_break ltx_centering"/>
</div>
</div>
<span class="ltx_note ltx_role_footnotetext" id="footnotex1a"><sup class="ltx_note_mark">$\dagger$</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">$\dagger$</sup><span class="ltx_note_type">footnotetext: </span>These authors contributed equally.</span></span></span><span class="ltx_note ltx_role_footnotetext" id="footnotex2a"><sup class="ltx_note_mark">$\dagger$</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">$\dagger$</sup><span class="ltx_note_type">footnotetext: </span>Correspondence: <a class="ltx_ref ltx_href" href="mailto:guokan.shang@mbzuai.ac.ae" title="">guokan.shang@mbzuai.ac.ae</a></span></span></span>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Transformer-based Large Language Models (LLMs) have revolutionized NLP research and beyond, demonstrating exceptional performance in both natural and formal language generation <cite class="ltx_cite ltx_citemacro_citep">(Gunasekar et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#bib.bib19" title="">2023</a>)</cite>, and exhibiting advanced reasoning capabilities in arithmetic, symbolic, and logical tasks <cite class="ltx_cite ltx_citemacro_citep">(Hendrycks et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#bib.bib22" title="">2020</a>)</cite>. Despite their success and the frequent release of new, superior open models exemplified by such as Llama <cite class="ltx_cite ltx_citemacro_citep">(Dubey et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#bib.bib10" title="">2024</a>)</cite> and Mistral <cite class="ltx_cite ltx_citemacro_citep">(Jiang et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#bib.bib28" title="">2023</a>)</cite>, these breakthroughs have been concentrated in a few data-rich languages <cite class="ltx_cite ltx_citemacro_citep">(Üstün et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#bib.bib50" title="">2024</a>)</cite>, assuming access to hundreds of billions or even a dozen trillions of tokens for training, often neglecting underrepresented languages.
In this work, we explore the challenges of introducing LLMs for low-resource Dialectal Arabic (DA).
The Arabic language has a rich history and profound cultural significance, featuring an intricate script, extensive lexicon, and complex grammar, making it a unique linguistic entity.
Although interest in developing Arabic-specialized models has recently been growing, notably led by models like Jais <cite class="ltx_cite ltx_citemacro_citep">(Sengupta et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#bib.bib44" title="">2023</a>)</cite>, AceGPT <cite class="ltx_cite ltx_citemacro_citep">(Huang et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#bib.bib24" title="">2024</a>)</cite>, and ALLaM <cite class="ltx_cite ltx_citemacro_citep">(Bari et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#bib.bib4" title="">2024</a>)</cite>, these efforts primarily focus on bilingualism by balancing English and Modern Standard Arabic (MSA), while often neglecting or excluding DA.
However, MSA differs significantly from DA in terms of morphology, syntax, and other linguistic features. Moreover, various Arabic dialects also differ considerably from one another. In fact, Arabic dialects collectively have more native speakers than MSA, as DA serves as the primary mode of communication in daily life across various Arabic-speaking regions <cite class="ltx_cite ltx_citemacro_citep">(Zaidan and Callison-Burch, <a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#bib.bib54" title="">2014</a>)</cite>.
This asymmetry is due in large part to the fact that DA poses challenges not encountered with MSA.
Some are related to the lack of essential components for model development—namely, training data, benchmarks, and suitable evaluation metrics—but others stem from the very nature of the linguistic characteristics involved in DA itself more generally.
We take Moroccan Arabic, also known as Darija, as the focus of our work.
Despite being spoken by 40 million people<span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://en.wikipedia.org/wiki/Moroccan_Arabic" title="">https://en.wikipedia.org/wiki/Moroccan_Arabic</a></span></span></span>, Darija remains a low-resource language. This is because MSA is used in official domains and education in Morocco, while Darija, a blend of MSA, Amazigh, French, and Spanish, is the vernacular widely spoken in daily life.
Although Darija—previously only an oral language—has recently developed a written form through the proliferation of social networks and increased access to technology, it still lacks standardization and established grammatical or syntactic rules due to its recent emergence <cite class="ltx_cite ltx_citemacro_citep">(Gaanoun et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#bib.bib16" title="">2024</a>)</cite>.
Moreover, Darija can be represented in two forms: Arabic script or Latin script (also known as Arabizi). For example, the Darija translation of “How are you?” can be written as: “kidayr?” or “<span class="ltx_ERROR undefined" id="S1.p1.1.1">\&lt;</span>كيداير؟&gt;”.
These challenges underscore the need for dedicated LLMs tailored to this linguistic context, capable of capturing its nuances and generating culturally relevant responses that resonate with Darija-speaking communities.
To the best of our knowledge, we are the first to introduce modern LLMs specifically developed for Moroccan Arabic, as well as for DA in general.
In our work, we first constructed the <span class="ltx_text ltx_font_typewriter" id="S1.p1.1.2">Darija-SFT-Mixture<span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note"><span class="ltx_text ltx_font_serif" id="footnote3.1.1.1">3</span></span><a class="ltx_ref ltx_url" href="https://hf.co/datasets/MBZUAI-Paris/Darija-SFT-Mixture" title="">https://hf.co/datasets/MBZUAI-Paris/Darija-SFT-Mixture</a></span></span></span></span> dataset, consisting of 458K instruction samples, by consolidating existing Darija language resources, creating novel datasets both manually and synthetically, and translating English instructions under strict quality control.
Additionally, to assess LLM performance in Darija, we developed a comprehensive evaluation suite including benchmarks such as: <span class="ltx_text ltx_font_typewriter" id="S1.p1.1.3">DarijaMMLU</span>, <span class="ltx_text ltx_font_typewriter" id="S1.p1.1.4">DarijaHellaSwag</span>, and <span class="ltx_text ltx_font_typewriter" id="S1.p1.1.5">DarijaBench</span>.
These benchmarks are intended to evaluate LLM capabilities in real-world knowledge, following Darija instructions, and performing traditional NLP tasks such as machine translation, automatic summarization, and sentiment analysis. In the end, Atlas-Chat models<span class="ltx_note ltx_role_footnote" id="footnote4"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span>Inspired by the naming of the “Jais” models, UAE’s highest mountain peak. We chose “Atlas” to reflect the cultural and geographical significance of the Atlas Mountains that traverse Morocco.</span></span></span>, fine-tuned from the Gemma 2 models <cite class="ltx_cite ltx_citemacro_citep">(Team et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#bib.bib47" title="">2024</a>)</cite> on our instruction-tuning dataset, exhibit superior ability in Darija, surpassing both state-of-the-art and Arabic-specialized LLMs like LLaMa, Jais, and AceGPT, according to automatic metrics and simulated win rates.
Additionally, we conduct an experimental analysis of various fine-tuning strategies and base model choices to determine final configurations.
We provide some examples by chatting with our models in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#A4" title="Appendix D Examples of Atlas-Chat-9B responses ‣ Atlas-Chat: Adapting Large Language Models for Low-Resource Moroccan Arabic Dialect"><span class="ltx_text ltx_ref_tag">D</span></a>.
All our resources are publicly accessible, and we believe our work offers comprehensive design methodologies of instruction-tuning for low-resource language variants, which are often overlooked in favor of data-rich languages by contemporary LLMs.</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related work</h2>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.2">In this section, we begin by reviewing LLMs and benchmarks developed for Arabic, followed by an exploration of recent trends in expanding LLMs to low-resource languages. <span class="ltx_text ltx_font_bold" id="S2.p1.2.1">Arabic-specialized LLMs</span>.
Recent efforts to develop Arabic-specialized LLMs have focused on MSA, due to its status as the formal and written standard across Arabic-speaking regions.
<span class="ltx_text ltx_font_bold ltx_font_italic" id="S2.p1.2.2">Jais</span> <cite class="ltx_cite ltx_citemacro_citep">(Sengupta et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#bib.bib44" title="">2023</a>)</cite>, a 13B-parameter model trained on 395B tokens of Arabic, English, and code data. Containing 116B Arabic tokens—25% of which were translated from English—Jais was designed to enhance performance in both Arabic and English tasks, trained on a mixture of the two languages in a 1:2 ratio. However, this approach may suffer from localization issues.
<span class="ltx_text ltx_font_bold ltx_font_italic" id="S2.p1.2.3">AceGPT</span> <cite class="ltx_cite ltx_citemacro_citep">(Huang et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#bib.bib24" title="">2024</a>)</cite> aims to address localization issues by pre-training LLaMA 2 <cite class="ltx_cite ltx_citemacro_citep">(Touvron et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#bib.bib49" title="">2023</a>)</cite> 7B and 13B models on 30B and 10B token mixtures, respectively, of Arabic and English data, with the Arabic portion dominating the dataset. The models were then fine-tuned on Arabic instructions and aligned with Arabic values and culture using Reinforcement Learning from AI Feedback <cite class="ltx_cite ltx_citemacro_citep">(Lee et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#bib.bib32" title="">2023</a>)</cite>. They further introduced the Arabic Cultural and Value Alignment dataset, comprising 8,000 yes-no questions generated by GPT-3.5.
<span class="ltx_text ltx_font_bold ltx_font_italic" id="S2.p1.2.4">ALLaM</span> <cite class="ltx_cite ltx_citemacro_citep">(Bari et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#bib.bib4" title="">2024</a>)</cite> demonstrated that second-language acquisition can steer the model towards a new language without catastrophic forgetting, even with random initialization of weights. They hypothesize that low-resource languages are diluted in large volumes of high-resource languages, and pre-train a 7B model from scratch on 4T English tokens, followed by training on a 1.2T mixture of Arabic and English.
Regarding <span class="ltx_text ltx_font_bold ltx_font_italic" id="S2.p1.2.5">Darija</span>, DarijaBERT <cite class="ltx_cite ltx_citemacro_citep">(Gaanoun et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#bib.bib16" title="">2024</a>)</cite> is currently the only “LLM” dedicated to the Moroccan Arabic dialect. The model was trained on <math alttext="\sim" class="ltx_Math" display="inline" id="S2.p1.1.m1.1"><semantics id="S2.p1.1.m1.1a"><mo id="S2.p1.1.m1.1.1" xref="S2.p1.1.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S2.p1.1.m1.1b"><csymbol cd="latexml" id="S2.p1.1.m1.1.1.cmml" xref="S2.p1.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.1.m1.1c">\sim</annotation><annotation encoding="application/x-llamapun" id="S2.p1.1.m1.1d">∼</annotation></semantics></math>100M tokens. However, DarijaBERT is encoder-only, and no decoder-only models have been developed for Darija.
Despite these advancements, efforts have primarily focused on MSA, with minimal attention given to developing DA-specialized LLMs.
<span class="ltx_text ltx_font_bold" id="S2.p1.2.6">Arabic benchmarks for LLMs</span>.
Several benchmarks have been created for various tasks and domains to evaluate the Arabic capabilities of LLMs.
<span class="ltx_text ltx_font_bold ltx_font_italic" id="S2.p1.2.7">ArabicMMLU</span> <cite class="ltx_cite ltx_citemacro_citep">(Koto et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#bib.bib31" title="">2024</a>)</cite> is an Arabic adaptation of the original MMLU benchmark <cite class="ltx_cite ltx_citemacro_citep">(Hendrycks et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#bib.bib22" title="">2020</a>)</cite>, consisting of 14K multiple-choice questions across 40 tasks in MSA. The benchmark covers a wide range of subjects, including history, mathematics, science, and linguistics, reflecting educational levels from eight different Arabic-speaking countries. <span class="ltx_text ltx_font_bold ltx_font_italic" id="S2.p1.2.8">LAraBench</span> <cite class="ltx_cite ltx_citemacro_citep">(Abdelali et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#bib.bib1" title="">2024</a>)</cite>, a benchmark designed for evaluating MSA LLMs on several practical NLP tasks, such as sentiment analysis, named entity recognition, and machine translation, spanning 33 tasks across 61 datasets encompassing <math alttext="\sim 296" class="ltx_Math" display="inline" id="S2.p1.2.m2.1"><semantics id="S2.p1.2.m2.1a"><mrow id="S2.p1.2.m2.1.1" xref="S2.p1.2.m2.1.1.cmml"><mi id="S2.p1.2.m2.1.1.2" xref="S2.p1.2.m2.1.1.2.cmml"></mi><mo id="S2.p1.2.m2.1.1.1" xref="S2.p1.2.m2.1.1.1.cmml">∼</mo><mn id="S2.p1.2.m2.1.1.3" xref="S2.p1.2.m2.1.1.3.cmml">296</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.p1.2.m2.1b"><apply id="S2.p1.2.m2.1.1.cmml" xref="S2.p1.2.m2.1.1"><csymbol cd="latexml" id="S2.p1.2.m2.1.1.1.cmml" xref="S2.p1.2.m2.1.1.1">similar-to</csymbol><csymbol cd="latexml" id="S2.p1.2.m2.1.1.2.cmml" xref="S2.p1.2.m2.1.1.2">absent</csymbol><cn id="S2.p1.2.m2.1.1.3.cmml" type="integer" xref="S2.p1.2.m2.1.1.3">296</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.2.m2.1c">\sim 296</annotation><annotation encoding="application/x-llamapun" id="S2.p1.2.m2.1d">∼ 296</annotation></semantics></math> data points.
The Open Arabic LLM Leaderboard (<span class="ltx_text ltx_font_bold ltx_font_italic" id="S2.p1.2.9">OALL</span>)<span class="ltx_note ltx_role_footnote" id="footnote5"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://hf.co/blog/leaderboard-arabic" title="">https://hf.co/blog/leaderboard-arabic</a></span></span></span> aggregates various native and translated Arabic benchmarks to evaluate models’ performance across tasks such as reading comprehension, sentiment analysis, reasoning, and more.
Despite the growing number of benchmarks for evaluating Arabic LLMs, a significant gap persists in assessing models’ performance in DA. This limitation hinders the evaluation of models specialized in regional dialects, which are widely used in daily communication across the Arab world. <span class="ltx_text ltx_font_bold" id="S2.p1.2.10">LLMs for Low-resource languages</span>.
Very recently, the LLM development community has begun to focus on low-resource languages.
Multilingual <span class="ltx_text ltx_font_bold ltx_font_italic" id="S2.p1.2.11">Aya</span> model <cite class="ltx_cite ltx_citemacro_citep">(Üstün et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#bib.bib50" title="">2024</a>)</cite> was developed by fine-tuning mT5 <cite class="ltx_cite ltx_citemacro_citep">(Xue, <a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#bib.bib53" title="">2020</a>)</cite>, a 13B encoder-decoder model pre-trained on 1T tokens across 101 languages, to follow instructions in these languages. Of these, 51 are low-resource languages, including Hausa, Icelandic, Luxembourgish, Kurdish, Sinhala, and etc. Other efforts to develop models for low-resource regional languages include <span class="ltx_text ltx_font_bold ltx_font_italic" id="S2.p1.2.12">InkubaLM</span> <cite class="ltx_cite ltx_citemacro_citep">(Tonja et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#bib.bib48" title="">2024</a>)</cite>, a 0.4B parameter language model specifically designed for low-resource African languages. The model was pre-trained from scratch on 2.4B tokens from five African languages—Hausa, Yoruba, Swahili, isiZulu, and isiXhosa—along with English and French, then fine-tuned to follow instructions on several tasks. Similarly, <cite class="ltx_cite ltx_citemacro_citet">Tao et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#bib.bib46" title="">2024</a>)</cite> explored two strategies to adapt LLaMA 2 for low-resource languages: continual pre-training followed by fine-tuning and model merging. Their experiments focused on seven low-resource languages—Tamil, Telugu, Odia, Bengali, Tibetan, Uyghur, and Mongolian—using datasets ranging from 1 to 20B tokens per language. Another line of research targets a subcategory of main languages with limited resources, such as the <span class="ltx_text ltx_font_bold ltx_font_italic" id="S2.p1.2.13">Claire</span> model <cite class="ltx_cite ltx_citemacro_citep">(Hunter et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#bib.bib25" title="">2023</a>; Louradour et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#bib.bib34" title="">2024</a>)</cite>, dedicated to spontaneous French dialogue.
However, to the best of our knowledge, Atlas-Chat is the first decoder-only LLM specifically designed for Moroccan Darija and DA in general.</p>
</div>
<figure class="ltx_table" id="S2.T1">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S2.T1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S2.T1.1.2.1">
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_t" id="S2.T1.1.2.1.1" style="padding:3pt 3.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.2.1.1.1">
<span class="ltx_p" id="S2.T1.1.2.1.1.1.1" style="width:99.6pt;"><span class="ltx_text ltx_font_bold" id="S2.T1.1.2.1.1.1.1.1">Subset</span></span>
</span>
</th>
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_t" id="S2.T1.1.2.1.2" style="padding:3pt 3.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.2.1.2.1">
<span class="ltx_p" id="S2.T1.1.2.1.2.1.1" style="width:42.7pt;"><span class="ltx_text ltx_font_bold" id="S2.T1.1.2.1.2.1.1.1"># Samples</span></span>
</span>
</th>
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_t" id="S2.T1.1.2.1.3" style="padding:3pt 3.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.2.1.3.1">
<span class="ltx_p" id="S2.T1.1.2.1.3.1.1" style="width:99.6pt;"><span class="ltx_text ltx_font_bold" id="S2.T1.1.2.1.3.1.1.1">Source</span></span>
</span>
</th>
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_t" id="S2.T1.1.2.1.4" style="padding:3pt 3.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.2.1.4.1">
<span class="ltx_p" id="S2.T1.1.2.1.4.1.1" style="width:199.2pt;"><span class="ltx_text ltx_font_bold" id="S2.T1.1.2.1.4.1.1.1">Description</span></span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S2.T1.1.3.1">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S2.T1.1.3.1.1" style="padding:3pt 3.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.3.1.1.1">
<span class="ltx_p" id="S2.T1.1.3.1.1.1.1" style="width:99.6pt;">§ <a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#S4.SS1" title="4.1 Machine translation ‣ 4 Native Darija instruction datasets ‣ Atlas-Chat: Adapting Large Language Models for Low-Resource Moroccan Arabic Dialect"><span class="ltx_text ltx_ref_tag">4.1</span></a> <span class="ltx_text ltx_font_bold" id="S2.T1.1.3.1.1.1.1.1">Translation</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S2.T1.1.3.1.2" style="padding:3pt 3.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.3.1.2.1">
<span class="ltx_p" id="S2.T1.1.3.1.2.1.1" style="width:42.7pt;">85,662</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S2.T1.1.3.1.3" style="padding:3pt 3.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.3.1.3.1">
<span class="ltx_p" id="S2.T1.1.3.1.3.1.1" style="width:99.6pt;">DODa-10K, FLORES+, MADAR, NLLB-Seed</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S2.T1.1.3.1.4" style="padding:3pt 3.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.3.1.4.1">
<span class="ltx_p" id="S2.T1.1.3.1.4.1.1" style="width:199.2pt;">Darja to English, French, MSA and vice-versa</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S2.T1.1.1">
<td class="ltx_td ltx_align_justify ltx_align_top" id="S2.T1.1.1.2" style="padding:3pt 3.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.1.2.1">
<span class="ltx_p" id="S2.T1.1.1.2.1.1" style="width:99.6pt;">§ <a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#S4.SS1" title="4.1 Machine translation ‣ 4 Native Darija instruction datasets ‣ Atlas-Chat: Adapting Large Language Models for Low-Resource Moroccan Arabic Dialect"><span class="ltx_text ltx_ref_tag">4.1</span></a> <span class="ltx_text ltx_font_bold" id="S2.T1.1.1.2.1.1.1">Transliteration</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S2.T1.1.1.3" style="padding:3pt 3.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.1.3.1">
<span class="ltx_p" id="S2.T1.1.1.3.1.1" style="width:42.7pt;">16,920</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S2.T1.1.1.4" style="padding:3pt 3.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.1.4.1">
<span class="ltx_p" id="S2.T1.1.1.4.1.1" style="width:99.6pt;">DODa-10K</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S2.T1.1.1.1" style="padding:3pt 3.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.1.1.1">
<span class="ltx_p" id="S2.T1.1.1.1.1.1" style="width:199.2pt;">Darija in Arabic Script <math alttext="\leftrightarrow" class="ltx_Math" display="inline" id="S2.T1.1.1.1.1.1.m1.1"><semantics id="S2.T1.1.1.1.1.1.m1.1a"><mo id="S2.T1.1.1.1.1.1.m1.1.1" stretchy="false" xref="S2.T1.1.1.1.1.1.m1.1.1.cmml">↔</mo><annotation-xml encoding="MathML-Content" id="S2.T1.1.1.1.1.1.m1.1b"><ci id="S2.T1.1.1.1.1.1.m1.1.1.cmml" xref="S2.T1.1.1.1.1.1.m1.1.1">↔</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.1.1.1.1.1.m1.1c">\leftrightarrow</annotation><annotation encoding="application/x-llamapun" id="S2.T1.1.1.1.1.1.m1.1d">↔</annotation></semantics></math> Latin Script</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S2.T1.1.4.2">
<td class="ltx_td ltx_align_justify ltx_align_top" id="S2.T1.1.4.2.1" style="padding:3pt 3.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.4.2.1.1">
<span class="ltx_p" id="S2.T1.1.4.2.1.1.1" style="width:99.6pt;">§ <a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#S4.SS2" title="4.2 Sentiment analysis ‣ 4 Native Darija instruction datasets ‣ Atlas-Chat: Adapting Large Language Models for Low-Resource Moroccan Arabic Dialect"><span class="ltx_text ltx_ref_tag">4.2</span></a> <span class="ltx_text ltx_font_bold" id="S2.T1.1.4.2.1.1.1.1">Sentiment Analysis</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S2.T1.1.4.2.2" style="padding:3pt 3.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.4.2.2.1">
<span class="ltx_p" id="S2.T1.1.4.2.2.1.1" style="width:42.7pt;">86,212</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S2.T1.1.4.2.3" style="padding:3pt 3.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.4.2.3.1">
<span class="ltx_p" id="S2.T1.1.4.2.3.1.1" style="width:99.6pt;">MSAC, MSDA, MAC 
<br class="ltx_break"/>ElecMorocco2016, MYC</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S2.T1.1.4.2.4" style="padding:3pt 3.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.4.2.4.1">
<span class="ltx_p" id="S2.T1.1.4.2.4.1.1" style="width:199.2pt;">Sentences labeled as Positive, Negative, and Neutral</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S2.T1.1.5.3">
<td class="ltx_td ltx_align_justify ltx_align_top" id="S2.T1.1.5.3.1" style="padding:3pt 3.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.5.3.1.1">
<span class="ltx_p" id="S2.T1.1.5.3.1.1.1" style="width:99.6pt;">§ <a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#S4.SS3" title="4.3 Automatic summarization ‣ 4 Native Darija instruction datasets ‣ Atlas-Chat: Adapting Large Language Models for Low-Resource Moroccan Arabic Dialect"><span class="ltx_text ltx_ref_tag">4.3</span></a> <span class="ltx_text ltx_font_bold" id="S2.T1.1.5.3.1.1.1.1">Summarization</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S2.T1.1.5.3.2" style="padding:3pt 3.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.5.3.2.1">
<span class="ltx_p" id="S2.T1.1.5.3.2.1.1" style="width:42.7pt;">16,756</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S2.T1.1.5.3.3" style="padding:3pt 3.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.5.3.3.1">
<span class="ltx_p" id="S2.T1.1.5.3.3.1.1" style="width:99.6pt;">MArSum</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S2.T1.1.5.3.4" style="padding:3pt 3.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.5.3.4.1">
<span class="ltx_p" id="S2.T1.1.5.3.4.1.1" style="width:199.2pt;">Article titles as summaries</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S2.T1.1.6.4">
<td class="ltx_td ltx_align_justify ltx_align_top" id="S2.T1.1.6.4.1" style="padding:3pt 3.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.6.4.1.1">
<span class="ltx_p" id="S2.T1.1.6.4.1.1.1" style="width:99.6pt;">§ <a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#S5.SS1" title="5.1 MoroccanWikipedia-QA (MW-QA) ‣ 5 Synthetic Darija instruction datasets ‣ Atlas-Chat: Adapting Large Language Models for Low-Resource Moroccan Arabic Dialect"><span class="ltx_text ltx_ref_tag">5.1</span></a> <span class="ltx_text ltx_font_bold" id="S2.T1.1.6.4.1.1.1.1">MW-QA</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S2.T1.1.6.4.2" style="padding:3pt 3.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.6.4.2.1">
<span class="ltx_p" id="S2.T1.1.6.4.2.1.1" style="width:42.7pt;">30,555</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S2.T1.1.6.4.3" style="padding:3pt 3.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.6.4.3.1">
<span class="ltx_p" id="S2.T1.1.6.4.3.1.1" style="width:99.6pt;">Wikipedia</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S2.T1.1.6.4.4" style="padding:3pt 3.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.6.4.4.1">
<span class="ltx_p" id="S2.T1.1.6.4.4.1.1" style="width:199.2pt;">Synthetic dataset from Moroccan Wikipedia pages</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S2.T1.1.7.5">
<td class="ltx_td ltx_align_justify ltx_align_top" id="S2.T1.1.7.5.1" style="padding:3pt 3.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.7.5.1.1">
<span class="ltx_p" id="S2.T1.1.7.5.1.1.1" style="width:99.6pt;">§ <a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#S5.SS2" title="5.2 MoroccanSocialMedia-MultiGen (MSM-MG) ‣ 5 Synthetic Darija instruction datasets ‣ Atlas-Chat: Adapting Large Language Models for Low-Resource Moroccan Arabic Dialect"><span class="ltx_text ltx_ref_tag">5.2</span></a> <span class="ltx_text ltx_font_bold" id="S2.T1.1.7.5.1.1.1.1">MSM-MG</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S2.T1.1.7.5.2" style="padding:3pt 3.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.7.5.2.1">
<span class="ltx_p" id="S2.T1.1.7.5.2.1.1" style="width:42.7pt;">11,808</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S2.T1.1.7.5.3" style="padding:3pt 3.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.7.5.3.1">
<span class="ltx_p" id="S2.T1.1.7.5.3.1.1" style="width:99.6pt;">Twitter/X, YouTube Comments</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S2.T1.1.7.5.4" style="padding:3pt 3.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.7.5.4.1">
<span class="ltx_p" id="S2.T1.1.7.5.4.1.1" style="width:199.2pt;">Synthetic dataset from Tweets and YouTube comments</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S2.T1.1.8.6">
<td class="ltx_td ltx_align_justify ltx_align_top" id="S2.T1.1.8.6.1" style="padding:3pt 3.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.8.6.1.1">
<span class="ltx_p" id="S2.T1.1.8.6.1.1.1" style="width:99.6pt;">§ <a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#S5.SS3" title="5.3 DarijaStory-Completion ‣ 5 Synthetic Darija instruction datasets ‣ Atlas-Chat: Adapting Large Language Models for Low-Resource Moroccan Arabic Dialect"><span class="ltx_text ltx_ref_tag">5.3</span></a> <span class="ltx_text ltx_font_bold" id="S2.T1.1.8.6.1.1.1.1">Story Completion</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S2.T1.1.8.6.2" style="padding:3pt 3.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.8.6.2.1">
<span class="ltx_p" id="S2.T1.1.8.6.2.1.1" style="width:42.7pt;">48,983</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S2.T1.1.8.6.3" style="padding:3pt 3.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.8.6.3.1">
<span class="ltx_p" id="S2.T1.1.8.6.3.1.1" style="width:99.6pt;">9esa.com</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S2.T1.1.8.6.4" style="padding:3pt 3.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.8.6.4.1">
<span class="ltx_p" id="S2.T1.1.8.6.4.1.1" style="width:199.2pt;">Stories converted to a dataset with part of the story as a prompt and the continuation as a response</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S2.T1.1.9.7">
<td class="ltx_td ltx_align_justify ltx_align_top" id="S2.T1.1.9.7.1" style="padding:3pt 3.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.9.7.1.1">
<span class="ltx_p" id="S2.T1.1.9.7.1.1.1" style="width:99.6pt;">§ <a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#S6" title="6 Translated English instruction datasets ‣ Atlas-Chat: Adapting Large Language Models for Low-Resource Moroccan Arabic Dialect"><span class="ltx_text ltx_ref_tag">6</span></a>    <span class="ltx_text ltx_font_bold" id="S2.T1.1.9.7.1.1.1.1">TÜLU-Darija</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S2.T1.1.9.7.2" style="padding:3pt 3.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.9.7.2.1">
<span class="ltx_p" id="S2.T1.1.9.7.2.1.1" style="width:42.7pt;">161,259</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S2.T1.1.9.7.3" style="padding:3pt 3.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.9.7.3.1">
<span class="ltx_p" id="S2.T1.1.9.7.3.1.1" style="width:99.6pt;">TÜLU-V2-Mix</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S2.T1.1.9.7.4" style="padding:3pt 3.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.9.7.4.1">
<span class="ltx_p" id="S2.T1.1.9.7.4.1.1" style="width:199.2pt;">Translated TÜLU-V2-Mix after filtering</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S2.T1.1.10.8">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_b" id="S2.T1.1.10.8.1" style="padding:3pt 3.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.10.8.1.1">
<span class="ltx_p" id="S2.T1.1.10.8.1.1.1" style="width:99.6pt;">§ <a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#A3.SS1" title="C.1 Hard coded instruction samples ‣ Appendix C Additional details ‣ Atlas-Chat: Adapting Large Language Models for Low-Resource Moroccan Arabic Dialect"><span class="ltx_text ltx_ref_tag">C.1</span></a> <span class="ltx_text ltx_font_bold" id="S2.T1.1.10.8.1.1.1.1">Hard Coded</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_b" id="S2.T1.1.10.8.2" style="padding:3pt 3.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.10.8.2.1">
<span class="ltx_p" id="S2.T1.1.10.8.2.1.1" style="width:42.7pt;">130</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_b" id="S2.T1.1.10.8.3" style="padding:3pt 3.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.10.8.3.1">
<span class="ltx_p" id="S2.T1.1.10.8.3.1.1" style="width:99.6pt;">Manual Annotation</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_b" id="S2.T1.1.10.8.4" style="padding:3pt 3.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.10.8.4.1">
<span class="ltx_p" id="S2.T1.1.10.8.4.1.1" style="width:199.2pt;">Prompts ensuring the model correctly answers identity/creator-related questions</span>
</span>
</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Composition of our Darija-SFT-Mixture instruction-tuning dataset.</figcaption>
</figure>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Data overview</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">In developing Atlas-Chat, we chose to use instruction-tuning on a base model rather than training from scratch. This decision was primarily driven by the fact that training an LLM from the ground up requires extensive data, which is not readily available for Darija, a low-resource dialect. For the same reason, our training process does not include the additional continual pre-training phase typically seen in many language adaptation efforts. However, to mitigate this limitation, we designed a synthetic instruction dataset (see Section <a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#S5.SS3" title="5.3 DarijaStory-Completion ‣ 5 Synthetic Darija instruction datasets ‣ Atlas-Chat: Adapting Large Language Models for Low-Resource Moroccan Arabic Dialect"><span class="ltx_text ltx_ref_tag">5.3</span></a>) that, to some extent, mimics the next-word prediction task over a relatively longer context, typically performed during (continual) pre-training.
Moreover, recent studies show that multilingual LLMs often exhibit a bias toward internally solving tasks in English, even when trained on multiple languages <cite class="ltx_cite ltx_citemacro_citep">(Zhao et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#bib.bib57" title="">2024</a>)</cite>, and perform best with English prompts, followed by mixed prompts, while non-English prompts significantly underperform <cite class="ltx_cite ltx_citemacro_citep">(Kmainasi et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#bib.bib29" title="">2024</a>)</cite>. This observation led us to limit the scope of our work to a monolingual LLM, making Atlas-Chat <span class="ltx_text ltx_font_bold" id="S3.p1.1.1">Darija-centric</span>.
We focus on developing a model that accurately understands prompts written in Darija, generates Darija content, respects its cultural context, and remains accessible and adaptable for native speakers.
Therefore, we directed our efforts towards creating an extensive and diverse Darija dataset for instruction-tuning. Table <a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#S2.T1" title="Table 1 ‣ 2 Related work ‣ Atlas-Chat: Adapting Large Language Models for Low-Resource Moroccan Arabic Dialect"><span class="ltx_text ltx_ref_tag">1</span></a> summarizes the composition of our Darija-SFT-Mixture dataset.
We employed a multifaceted approach to data preparation.
<span class="ltx_text ltx_font_italic" id="S3.p1.1.2">First</span>, we reviewed previous research in Darija NLP and collected the majority of available native Darija datasets that met our quality standards.
The data selection rule established by native speakers was as follows: if the data is a mix of Darija with some MSA, it is acceptable; if it is mixed with other dialects, it is not.
In total, ten datasets covering tasks such as translation, summarization, and sentiment analysis were selected.
<span class="ltx_text ltx_font_italic" id="S3.p1.1.3">Second</span>, we synthesized high-quality instruction data using advanced proprietary models, drawing on sources such as Wikipedia pages, social media posts, and stories written in Darija.
The native and synthetic datasets were then converted into training instructions using templates, with 80% formatted as zero-shot, 10% as few-shot, and 10% as multi-turn samples. <span class="ltx_text ltx_font_italic" id="S3.p1.1.4">Third</span>, we translated high-quality English instruction datasets into Darija with stringent quality control to expand the range of scenarios, domains, and tasks covered by our dataset.
By combining these different sources, we aimed to enhance the model’s ability to understand and generate Darija across various contexts.</p>
</div>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Native Darija instruction datasets</h2>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Machine translation</h3>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">We collected four datasets containing sentence translations between Darija, MSA, English, and French. These datasets were then converted into training instructions using the templates provided in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#A1.SS1" title="A.1 Machine translation ‣ Appendix A Instruction data templates ‣ Atlas-Chat: Adapting Large Language Models for Low-Resource Moroccan Arabic Dialect"><span class="ltx_text ltx_ref_tag">A.1</span></a>.
Since our model is Darija-centric, we consider six translation directions: Darija to English, French, MSA, and vice versa. All instructions are written in Darija for each case. <span class="ltx_text ltx_font_bold" id="S4.SS1.p1.1.1">DODa-10K<span class="ltx_note ltx_role_footnote" id="footnote6"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_tag ltx_tag_note"><span class="ltx_text ltx_font_medium" id="footnote6.1.1.1">6</span></span><a class="ltx_ref ltx_url ltx_font_typewriter ltx_font_medium" href="https://hf.co/datasets/MBZUAI-Paris/DoDa-10K" title="">https://hf.co/datasets/MBZUAI-Paris/DoDa-10K</a></span></span></span></span>. The Darija Open Dataset (DODa) <cite class="ltx_cite ltx_citemacro_citep">(Outchakoucht and Es-Samaali, <a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#bib.bib39" title="">2021</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#bib.bib40" title="">2024</a>)</cite><span class="ltx_note ltx_role_footnote" id="footnote7"><sup class="ltx_note_mark">7</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">7</sup><span class="ltx_tag ltx_tag_note">7</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/darija-open-dataset" title="">https://github.com/darija-open-dataset</a></span></span></span> is an open-source collaborative project for collecting Darija language resource, including lexicons in semantic and syntactic categories, Darija-English parallel corpus, and etc. Darija is represented in Latin script, as well as in automatically converted Arabic script.
We augmented the first 10K examples of the parallel corpus, with MSA and French translated from the English text, by leveraging GPT-4.
The final DODa-10K dataset includes translation quintuples between <span class="ltx_text ltx_font_italic" id="S4.SS1.p1.1.2">Darija</span> (in both Arabic and Latin scripts), <span class="ltx_text ltx_font_italic" id="S4.SS1.p1.1.3">MSA</span>, <span class="ltx_text ltx_font_italic" id="S4.SS1.p1.1.4">English</span>, and <span class="ltx_text ltx_font_italic" id="S4.SS1.p1.1.5">French</span>.
The dataset was then extensively reviewed by groups of native Darija-speaking annotators to ensure the quality of the entire dataset.
In addition to translation, to enhance the model’s ability to convert between Darija in Arabic and Latin scripts (also known as the <span class="ltx_text ltx_font_bold ltx_font_italic" id="S4.SS1.p1.1.6">transliteration</span> task), we transformed 10K parallel forms into instructions using templates found in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#A1.SS2" title="A.2 Transliteration ‣ Appendix A Instruction data templates ‣ Atlas-Chat: Adapting Large Language Models for Low-Resource Moroccan Arabic Dialect"><span class="ltx_text ltx_ref_tag">A.2</span></a>.
<span class="ltx_text ltx_font_bold" id="S4.SS1.p1.1.7">MADAR</span> <cite class="ltx_cite ltx_citemacro_citep">(Bouamor et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#bib.bib6" title="">2018</a>)</cite><span class="ltx_note ltx_role_footnote" id="footnote8"><sup class="ltx_note_mark">8</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">8</sup><span class="ltx_tag ltx_tag_note">8</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://sites.google.com/nyu.edu/madar" title="">https://sites.google.com/nyu.edu/madar</a></span></span></span>. The Multi-Arabic Dialect Applications and Resources (MADAR) corpus is a collection of parallel sentences covering the dialects of 25 Arab cities, built upon the Basic Traveling Expression Corpus <cite class="ltx_cite ltx_citemacro_citep">(Takezawa et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#bib.bib45" title="">2007</a>)</cite>. We select the dialect of Rabat city as <span class="ltx_text ltx_font_italic" id="S4.SS1.p1.1.8">Darija</span> translation, along with <span class="ltx_text ltx_font_italic" id="S4.SS1.p1.1.9">MSA</span>, resulting in 12K sentence pairs.
The split corpus-6-test-corpus-26-test is reserved for the evaluation.
<span class="ltx_text ltx_font_bold" id="S4.SS1.p1.1.10">NLLB-Seed</span> <cite class="ltx_cite ltx_citemacro_citep">(Maillard et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#bib.bib35" title="">2023</a>)</cite><span class="ltx_note ltx_role_footnote" id="footnote9"><sup class="ltx_note_mark">9</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">9</sup><span class="ltx_tag ltx_tag_note">9</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/openlanguagedata/seed" title="">https://github.com/openlanguagedata/seed</a></span></span></span>. The Seed machine translation dataset contains 6K sentences sampled from English Wikipedia and translated into 39 low-resource languages. We extract the <span class="ltx_text ltx_font_italic" id="S4.SS1.p1.1.11">Darija</span> and <span class="ltx_text ltx_font_italic" id="S4.SS1.p1.1.12">English</span> pairs.
<span class="ltx_text ltx_font_bold" id="S4.SS1.p1.1.13">FLORES+<span class="ltx_note ltx_role_footnote" id="footnote10"><sup class="ltx_note_mark">10</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">10</sup><span class="ltx_tag ltx_tag_note"><span class="ltx_text ltx_font_medium" id="footnote10.1.1.1">10</span></span><a class="ltx_ref ltx_url ltx_font_typewriter ltx_font_medium" href="https://github.com/openlanguagedata/flores" title="">https://github.com/openlanguagedata/flores</a></span></span></span></span>. Built upon FLORES-200 <cite class="ltx_cite ltx_citemacro_citep">(Costa-jussà et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#bib.bib9" title="">2022</a>)</cite>, this corpus is specifically designed to support multilingual research and evaluation. The English sentences were sampled in equal amounts from Wikinews (an international news source), Wikijunior (a collection of age-appropriate non-fiction books), and Wikivoyage (a travel guide). These were then translated into other languages.
For each language, the dataset has 997 sentences for the dev split and 1012 sentences for the devtest split.
we selected those in <span class="ltx_text ltx_font_italic" id="S4.SS1.p1.1.14">Darija</span>, <span class="ltx_text ltx_font_italic" id="S4.SS1.p1.1.15">MSA</span>, <span class="ltx_text ltx_font_italic" id="S4.SS1.p1.1.16">English</span>, and <span class="ltx_text ltx_font_italic" id="S4.SS1.p1.1.17">French</span>.
dev is severed as training, while devtest for the evaluation.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Sentiment analysis</h3>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">We collected five datasets for sentiment analysis, primarily sourced from social networks.
Two datasets are annotated with three labels (positive, negative, and neutral), while the other three have two labels (positive and negative).
These datasets were then transformed into training instructions using templates from Appendix <a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#A1.SS3" title="A.3 Sentiment analysis ‣ Appendix A Instruction data templates ‣ Atlas-Chat: Adapting Large Language Models for Low-Resource Moroccan Arabic Dialect"><span class="ltx_text ltx_ref_tag">A.3</span></a>.
<span class="ltx_text ltx_font_bold" id="S4.SS2.p1.1.1">MSDA</span> <cite class="ltx_cite ltx_citemacro_citep">(Boujou et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#bib.bib7" title="">2021</a>)</cite><span class="ltx_note ltx_role_footnote" id="footnote11"><sup class="ltx_note_mark">11</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">11</sup><span class="ltx_tag ltx_tag_note">11</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://cc.um6p.ma/cc_datasets" title="">https://cc.um6p.ma/cc_datasets</a></span></span></span>. It is an open dataset for sentiment analysis, designed to support research in NLP for Arabic dialects and social media.
The dataset includes 52K tweets in Darija, categorized into three labels: <span class="ltx_text ltx_font_italic" id="S4.SS2.p1.1.2">positive</span>, <span class="ltx_text ltx_font_italic" id="S4.SS2.p1.1.3">neural</span>, or <span class="ltx_text ltx_font_italic" id="S4.SS2.p1.1.4">negative</span>.
The tweets are preprocessed, and emojis are retained because they play a significant role in expressing sentiment.
Labels are annotated semi-automatically and bootstrapped with human intervention.
<span class="ltx_text ltx_font_bold" id="S4.SS2.p1.1.5">MSAC</span> <cite class="ltx_cite ltx_citemacro_citep">(Oussous et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#bib.bib38" title="">2018</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#bib.bib37" title="">2020</a>)</cite><span class="ltx_note ltx_role_footnote" id="footnote12"><sup class="ltx_note_mark">12</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">12</sup><span class="ltx_tag ltx_tag_note">12</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/ososs/Arabic-Sentiment-Analysis-corpus" title="">https://github.com/ososs/Arabic-Sentiment-Analysis-corpus</a></span></span></span>. The Moroccan Sentiment Analysis Corpus (MSAC) is a manually prepared dataset consisting of reviewers’ opinions from Hespress<span class="ltx_note ltx_role_footnote" id="footnote13"><sup class="ltx_note_mark">13</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">13</sup><span class="ltx_tag ltx_tag_note">13</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.hespress.com" title="">https://www.hespress.com</a></span></span></span> on various published articles, as well as a collection of Arabic reviews and comments from Facebook, Twitter and YouTube. It includes content in both MSA and Darija, consisting of 2K sentences labeled as <span class="ltx_text ltx_font_italic" id="S4.SS2.p1.1.6">positive</span> or <span class="ltx_text ltx_font_italic" id="S4.SS2.p1.1.7">negative</span> in equal proportions.
<span class="ltx_text ltx_font_bold" id="S4.SS2.p1.1.8">ElecMorocco2016</span> <cite class="ltx_cite ltx_citemacro_citep">(Elouardighi et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#bib.bib11" title="">2017</a>)</cite><span class="ltx_note ltx_role_footnote" id="footnote14"><sup class="ltx_note_mark">14</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">14</sup><span class="ltx_tag ltx_tag_note">14</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/sentiprojects/ElecMorocco2016" title="">https://github.com/sentiprojects/ElecMorocco2016</a></span></span></span>.
The 2016 Moroccan elections (ElecMorocco2016) is a sentiment analysis dataset comprising 10K Facebook comments about Moroccan’s
legislative elections held on October 7, 2016. Each comment is labeled as either <span class="ltx_text ltx_font_italic" id="S4.SS2.p1.1.9">positive</span> or <span class="ltx_text ltx_font_italic" id="S4.SS2.p1.1.10">negative</span>. The comments are written in Darija and MSA.
<span class="ltx_text ltx_font_bold" id="S4.SS2.p1.1.11">MYC</span> <cite class="ltx_cite ltx_citemacro_citep">(Jbel et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#bib.bib27" title="">2024</a>)</cite><span class="ltx_note ltx_role_footnote" id="footnote15"><sup class="ltx_note_mark">15</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">15</sup><span class="ltx_tag ltx_tag_note">15</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/MouadJb/MYC" title="">https://github.com/MouadJb/MYC</a></span></span></span>.
The Moroccan Youtube Corpus (MYC) is a dataset of Moroccan YouTube comments designed for sentiment analysis.
The dataset prioritizes variety over size. Comments are collected from Moroccan YouTube channels covering various topics.
It contains 20K manually labeled comments, evenly divided between <span class="ltx_text ltx_font_italic" id="S4.SS2.p1.1.12">positive</span> and <span class="ltx_text ltx_font_italic" id="S4.SS2.p1.1.13">negative</span>. Notably, the 20K comments are equally balanced between those written in Arabic script and those in Latin script. <span class="ltx_text ltx_font_bold" id="S4.SS2.p1.1.14">MAC</span> <cite class="ltx_cite ltx_citemacro_citep">(Garouani and Kharroubi, <a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#bib.bib18" title="">2021</a>)</cite><span class="ltx_note ltx_role_footnote" id="footnote16"><sup class="ltx_note_mark">16</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">16</sup><span class="ltx_tag ltx_tag_note">16</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/LeMGarouani/MAC" title="">https://github.com/LeMGarouani/MAC</a></span></span></span>: The Moroccan Arabic Corpus (MAC) is a free, large-scale Darija corpus for sentiment analysis, consisting of 18K manually labeled tweets categorized as <span class="ltx_text ltx_font_italic" id="S4.SS2.p1.1.15">positive</span>, <span class="ltx_text ltx_font_italic" id="S4.SS2.p1.1.16">neutral</span>, <span class="ltx_text ltx_font_italic" id="S4.SS2.p1.1.17">negative</span>, or mixed. Only 643 tweets are labeled as mixed, so we filtered them out.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Automatic summarization</h3>
<div class="ltx_para" id="S4.SS3.p1">
<p class="ltx_p" id="S4.SS3.p1.1">We found only one Darija dataset for summarization. The documents and corresponding summaries were converted into instructions using the template in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#A1.SS4" title="A.4 Automatic summarization ‣ Appendix A Instruction data templates ‣ Atlas-Chat: Adapting Large Language Models for Low-Resource Moroccan Arabic Dialect"><span class="ltx_text ltx_ref_tag">A.4</span></a>.
<span class="ltx_text ltx_font_bold" id="S4.SS3.p1.1.1">MArSum</span> <cite class="ltx_cite ltx_citemacro_citep">(Gaanoun et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#bib.bib15" title="">2022</a>)</cite><span class="ltx_note ltx_role_footnote" id="footnote17"><sup class="ltx_note_mark">17</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">17</sup><span class="ltx_tag ltx_tag_note">17</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/KamelGaanoun/MoroccanSummarization" title="">https://github.com/KamelGaanoun/MoroccanSummarization</a></span></span></span>.
The Moroccan Articles Summarization dataset (MArSum) contains 19K news articles written in Darija, along with their titles. The articles were crawled from Goud.ma<span class="ltx_note ltx_role_footnote" id="footnote18"><sup class="ltx_note_mark">18</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">18</sup><span class="ltx_tag ltx_tag_note">18</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="http://www.goud.ma/" title="">http://www.goud.ma/</a></span></span></span>. While some content includes MSA, all titles are written in Darija. Since the articles are relatively concise and the titles are sufficiently informative, the titles are considered as summaries of the articles. The average length of the titles is 14.6 words.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Synthetic Darija instruction datasets</h2>
<section class="ltx_subsection" id="S5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>MoroccanWikipedia-QA (MW-QA)</h3>
<div class="ltx_para" id="S5.SS1.p1">
<p class="ltx_p" id="S5.SS1.p1.1"><span class="ltx_text ltx_font_bold" id="S5.SS1.p1.1.1">MW-QA<span class="ltx_note ltx_role_footnote" id="footnote19"><sup class="ltx_note_mark">19</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">19</sup><span class="ltx_tag ltx_tag_note"><span class="ltx_text ltx_font_medium" id="footnote19.1.1.1">19</span></span><a class="ltx_ref ltx_url ltx_font_typewriter ltx_font_medium" href="https://hf.co/datasets/MBZUAI-Paris/MoroccanWikipedia-QA" title="">https://hf.co/datasets/MBZUAI-Paris/MoroccanWikipedia-QA</a></span></span></span></span> is a dataset derived from Moroccan Wikipedia dump<span class="ltx_note ltx_role_footnote" id="footnote20"><sup class="ltx_note_mark">20</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">20</sup><span class="ltx_tag ltx_tag_note">20</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://dumps.wikimedia.org/arywiki/latest/" title="">https://dumps.wikimedia.org/arywiki/latest/</a></span></span></span>, developed in our work to enhance the models’ question-answering (QA) capability. The dataset is divided into four tasks: Open QA (8%), Multiple-Choice QA (40%) (MMLU-alike), Extractive QA (10%), and Multiple-Choice Extractive QA (42%) (Belebele-alike), with each percentage reflecting the proportion of Wikipedia pages used for the respective task.
The latter two tasks provide context along with the questions, whereas the former two do not. In Open QA and Extractive QA, answers are provided in sentence form. In the multiple-choice tasks, four answer options are presented, with the index of the correct option serving as the answer.
The distribution of correct answers (e.g., A, B, C, D) are balanced.
The QAs were converted into instructions with the template in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#A1.SS5" title="A.5 MoroccanWikipedia-QA ‣ Appendix A Instruction data templates ‣ Atlas-Chat: Adapting Large Language Models for Low-Resource Moroccan Arabic Dialect"><span class="ltx_text ltx_ref_tag">A.5</span></a>.
The dataset generation involved providing each Wikipedia page to Claude 3.5 Sonnet<span class="ltx_note ltx_role_footnote" id="footnote21"><sup class="ltx_note_mark">21</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">21</sup><span class="ltx_tag ltx_tag_note">21</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.anthropic.com/news/claude-3-5-sonnet" title="">https://www.anthropic.com/news/claude-3-5-sonnet</a></span></span></span> and prompting it to generate QA pairs tailored to the four task categories. The prompts followed a one-shot or two-shot format to ensure that output adhered to the desired structure. For the extractive tasks, rather than splitting the page into paragraphs—an approach that risked losing contextual meaning—we opted to present the entire page to Claude. The model was instructed to first extract a meaningful passage from the page and then generate a QA pair based on the content of that passage. Additionally, the model was directed to ensure that the extracted passages were long, self-contained, and did not lose meaning when removed from their original context.
A total of 8,730 pages were collected and pre-processed by removing scraping errors. Among these pages, some followed a uniform structure, typically consisting of a brief description of a village or community followed by statistical data (e.g., literacy rates and unemployment figures). Given that these statistical sections could become meaningless when extracted from their context, they were allocated to non-extractive tasks, which could still utilize the statistical information to enrich the fine-tuned model’s knowledge base.
The final distribution of QA pairs is as follows: 15.7% Open QA, 43.1% Multiple-Choice QA, 6.9% Extractive QA, and 34.3% Multiple-Choice Extractive QA. These percentages differ from the initial page distribution because Claude generated varying numbers of samples for each task. For example, the average number of samples generated for Open QA is 7.73, while for Extractive QA, it is 2.72.</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>MoroccanSocialMedia-MultiGen (MSM-MG)</h3>
<div class="ltx_para" id="S5.SS2.p1">
<p class="ltx_p" id="S5.SS2.p1.1"><span class="ltx_text ltx_font_bold" id="S5.SS2.p1.1.1">MSM-MG<span class="ltx_note ltx_role_footnote" id="footnote22"><sup class="ltx_note_mark">22</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">22</sup><span class="ltx_tag ltx_tag_note"><span class="ltx_text ltx_font_medium" id="footnote22.1.1.1">22</span></span><a class="ltx_ref ltx_url ltx_font_typewriter ltx_font_medium" href="https://hf.co/datasets/MBZUAI-Paris/MoroccanSocialMedia-MultiGen" title="">https://hf.co/datasets/MBZUAI-Paris/MoroccanSocialMedia-MultiGen</a></span></span></span></span>, a dataset introduced as part of this work, comprises 12,973 pairs of native Darija social media posts (tweets and YouTube comments) and their synthetic counterparts, covering various NLP tasks. The pairs were converted into instructions using the template provided in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#A1.SS6" title="A.6 MoroccanSocialMedia-MultiGen ‣ Appendix A Instruction data templates ‣ Atlas-Chat: Adapting Large Language Models for Low-Resource Moroccan Arabic Dialect"><span class="ltx_text ltx_ref_tag">A.6</span></a>.
The synthetic generations are created based on six specific tasks: <span class="ltx_text ltx_font_italic" id="S5.SS2.p1.1.2">Continuation</span>, <span class="ltx_text ltx_font_italic" id="S5.SS2.p1.1.3">Reply</span>, <span class="ltx_text ltx_font_italic" id="S5.SS2.p1.1.4">Summarization</span>, <span class="ltx_text ltx_font_italic" id="S5.SS2.p1.1.5">Rephrasing</span>, <span class="ltx_text ltx_font_italic" id="S5.SS2.p1.1.6">Explanation</span>, and <span class="ltx_text ltx_font_italic" id="S5.SS2.p1.1.7">Safe Response</span>, by prompting Claude 3.5 Sonnet to respectively consider the original post as incomplete and continue it, reply to it, summarize its content, rephrase it, explain its topic, and respond safely to potentially offensive content. 9,754 Tweets were employed for the first five tasks, while 3,219 YouTube comments were utilized for the last task.
The posts were collected from three sources:
<br class="ltx_break"/><span class="ltx_text ltx_font_italic" id="S5.SS2.p1.1.8">QADI</span> <cite class="ltx_cite ltx_citemacro_citep">(Abdelali et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#bib.bib2" title="">2021</a>)</cite><span class="ltx_note ltx_role_footnote" id="footnote23"><sup class="ltx_note_mark">23</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">23</sup><span class="ltx_tag ltx_tag_note">23</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/qcri/QADI" title="">https://github.com/qcri/QADI</a></span></span></span>: From this Arabic dialect identification dataset, 12,813 Moroccan tweets were initially sampled. After a thorough review by native Darija speakers, tweets that were no longer accessible or contained non-Darija Arabic dialects were filtered out, resulting in 6,362 valid tweets.
<span class="ltx_text ltx_font_italic" id="S5.SS2.p1.1.9">Twitter API</span>: 4,226 tweets were gathered directly from the Twitter API by searching for Darija-specific keywords. The DarijaBERT paper <cite class="ltx_cite ltx_citemacro_citep">(Gaanoun et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#bib.bib16" title="">2024</a>)</cite> identified 31 keywords exclusive to Darija, but upon review, five were found to also exist in other Arabic dialects and were excluded. The remaining 26 keywords can be found in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#A3.SS2" title="C.2 Selected keywords for tweet searching ‣ Appendix C Additional details ‣ Atlas-Chat: Adapting Large Language Models for Low-Resource Moroccan Arabic Dialect"><span class="ltx_text ltx_ref_tag">C.2</span></a>.
<span class="ltx_text ltx_font_italic" id="S5.SS2.p1.1.10">OMCD</span> <cite class="ltx_cite ltx_citemacro_citep">(Essefar et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#bib.bib12" title="">2023</a>)</cite><span class="ltx_note ltx_role_footnote" id="footnote24"><sup class="ltx_note_mark">24</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">24</sup><span class="ltx_tag ltx_tag_note">24</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/kabilessefar/OMCD-Offensive-Moroccan-Comments-Dataset" title="">https://github.com/kabilessefar/OMCD-Offensive-Moroccan-Comments-Dataset</a></span></span></span>: This is a dataset for offensive content identification collected from Moroccan YouTube comments. For the purposes of this study, only comments labeled as offensive from the training split were selected. These comments were specifically utilized for the final generation task, which involved generating safe responses to potentially offensive content.</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3 </span>DarijaStory-Completion</h3>
<div class="ltx_para" id="S5.SS3.p1">
<p class="ltx_p" id="S5.SS3.p1.1">To mitigate the limitation of performing only instruction-tuning for language adaptation without the typical continual pre-training phase—due to the lack of sufficient amount of Darija pre-training data—we designed a synthetic story completion dataset, aiming to enhance the next-word prediction capability in Darija for our models over a relatively longer context. First, we collected 4,392 long stories from 9esa<span class="ltx_note ltx_role_footnote" id="footnote25"><sup class="ltx_note_mark">25</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">25</sup><span class="ltx_tag ltx_tag_note">25</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.9esa.com" title="">https://www.9esa.com</a></span></span></span>, a website featuring a rich collection of various stories entirely written in Darija.
We denote this dataset as DarijaStory.
The scraped stories were then divided into segments of approximately 2,048 tokens, adhering to the base model tokenizer’s vocabulary. The segments were further divided into two parts of varying lengths: the beginning part and the ending part to be completed. For the two segmentation steps above, the split point is preferably placed at line breaks. Finally, the pairs were converted into story completion instructions using the template provided in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#A1.SS7" title="A.7 DarijaStory-Completion ‣ Appendix A Instruction data templates ‣ Atlas-Chat: Adapting Large Language Models for Low-Resource Moroccan Arabic Dialect"><span class="ltx_text ltx_ref_tag">A.7</span></a>.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Translated English instruction datasets</h2>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">Finally, we expanded our instruction-tuning data by translating appropriate English datasets into Darija. Since English instruction-tuning datasets incorporate diverse sources, such as human-written examples, expert-curated tasks, and synthetic data generated by advanced models. These datasets cover a wide range of scenarios and improve the model’s generalization capabilities.
We began by reviewing the most widely used datasets for fine-tuning state-of-the-art models to ensure that our translation efforts would lead to meaningful improvements. After careful consideration, we decided to focus on the <span class="ltx_text ltx_font_bold" id="S6.p1.1.1">TÜLU-V2-mix</span> <cite class="ltx_cite ltx_citemacro_citep">(Ivison et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#bib.bib26" title="">2023</a>)</cite><span class="ltx_note ltx_role_footnote" id="footnote26"><sup class="ltx_note_mark">26</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">26</sup><span class="ltx_tag ltx_tag_note">26</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://hf.co/datasets/allenai/tulu-v2-sft-mixture" title="">https://hf.co/datasets/allenai/tulu-v2-sft-mixture</a></span></span></span> dataset for several reasons. It offers a comprehensive dataset composition, including samples from some of the most widely used datasets, such as FLAN and ShareGPT, for fine-tuning state-of-the-art models.
Appendix <a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#A2.SS1" title="B.1 Composition of TÜLU-V2-mix ‣ Appendix B TÜLU-V2-mix and its translation ‣ Atlas-Chat: Adapting Large Language Models for Low-Resource Moroccan Arabic Dialect"><span class="ltx_text ltx_ref_tag">B.1</span></a> presents descriptions of each of these datasets and describes how the subset was sampled.
The dataset mixture was meticulously designed based on ablation studies of both human-annotated and AI-generated data, with a focus on complexity and diversity. Models fine-tuned on it showed significant improvements in overall performance on key benchmarks compared to those trained on individual datasets.
We adopted the user-assistant message format from TÜLU-V2-mix (see Appendix <a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#A2.SS2" title="B.2 Dataset Format ‣ Appendix B TÜLU-V2-mix and its translation ‣ Atlas-Chat: Adapting Large Language Models for Low-Resource Moroccan Arabic Dialect"><span class="ltx_text ltx_ref_tag">B.2</span></a>) to structure our entire Darija-SFT-Mixture dataset.
To ensure translation quality, we first filtered out instructions from TÜLU-V2-mix that are either inappropriate for typical Darija speakers or could lose meaning or coherence when translated, such as scientific content, translation tasks, and non-English samples. We then experimented with several open-source and closed-source models for English-to-Darija translation, including NLLB <cite class="ltx_cite ltx_citemacro_citep">(Costa-jussà et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#bib.bib9" title="">2022</a>)</cite>, GPT, and others. Our results showed that closed-source models consistently outperformed open-source alternatives, with Claude 3.5 Sonnet emerging as our final choice.
Finally, we implemented several post-processing measures to correct errors introduced by the automatic translation. All details are provided in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#A2.SS3" title="B.3 Translation to Darija ‣ Appendix B TÜLU-V2-mix and its translation ‣ Atlas-Chat: Adapting Large Language Models for Low-Resource Moroccan Arabic Dialect"><span class="ltx_text ltx_ref_tag">B.3</span></a>.</p>
</div>
</section>
<section class="ltx_section" id="S7">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Training details</h2>
<div class="ltx_para" id="S7.p1">
<p class="ltx_p" id="S7.p1.1">In this section, we outline the training details and present the experimental analysis of various fine-tuning strategies and base model choices that informed our final settings. <span class="ltx_text ltx_font_bold" id="S7.p1.1.1">Base model selection</span>.
Selecting a pre-trained model that meets the specific requirements of the target task is crucial for effective fine-tuning.
Initially, we considered two Arabic models: Jais and AceGPT.
Later, we included Gemma 2 based on positive feedback from the Arabic LLM development community, as it can serve as a strong starting point for Arabic fine-tuning tasks. We also compared the performance differences between fine-tuning on an instruction-tuned chat model and a base model.
Our experimental results indicate that <span class="ltx_text ltx_font_italic" id="S7.p1.1.2">continual fine-tuning</span> of instruction-tuned Gemma 2 models (Gemma-2-2B-It<span class="ltx_note ltx_role_footnote" id="footnote27"><sup class="ltx_note_mark">27</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">27</sup><span class="ltx_tag ltx_tag_note">27</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://hf.co/google/gemma-2-2b-it" title="">https://hf.co/google/gemma-2-2b-it</a></span></span></span> and Gemma-2-9B-It<span class="ltx_note ltx_role_footnote" id="footnote28"><sup class="ltx_note_mark">28</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">28</sup><span class="ltx_tag ltx_tag_note">28</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://hf.co/google/gemma-2-9b-it" title="">https://hf.co/google/gemma-2-9b-it</a></span></span></span>) yields significantly higher scores than other settings on our dataset.
<span class="ltx_text ltx_font_bold" id="S7.p1.1.3">Training framework</span>.
We also investigated the performance differences between full fine-tuning and parameter-efficient approaches <cite class="ltx_cite ltx_citemacro_citep">(Han et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#bib.bib21" title="">2024</a>)</cite>.
Results indicate that the latter, with Low-Rank Adaptation (LoRA) <cite class="ltx_cite ltx_citemacro_citep">(Hu et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#bib.bib23" title="">2021</a>)</cite>, proved to be more effective, whereas full fine-tuning resulted in catastrophic forgetting <cite class="ltx_cite ltx_citemacro_citep">(French, <a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#bib.bib14" title="">1999</a>)</cite>. This is supported by the recent work of <cite class="ltx_cite ltx_citemacro_citet">Biderman et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#bib.bib5" title="">2024</a>)</cite>, that shows LoRA exhibits a desirable form of regularization: it better maintains the base model’s performance on tasks outside the target domain, and it also helps maintain more diverse generations.
<span class="ltx_text ltx_font_bold" id="S7.p1.1.4">Hyperparameters</span>.
We carefully selected the hyperparameters to ensure optimal model performance while balancing memory efficiency and training speed.
The use of LoRA was configured with a <span class="ltx_text ltx_font_typewriter" id="S7.p1.1.5">lora_rank</span> of 256 and a <span class="ltx_text ltx_font_typewriter" id="S7.p1.1.6">lora_alpha</span> of 128 to enhance parameter efficiency while maintaining stability.
For the training process, we run the training for 3 epochs, and set the <span class="ltx_text ltx_font_typewriter" id="S7.p1.1.7">learning_rate</span> to 5e-5 with warmup ratio of 3%, and <span class="ltx_text ltx_font_typewriter" id="S7.p1.1.8">per_device_train_batch_size</span> to 4, with gradients accumulated over 4 steps to manage memory and training speed effectively.
The <span class="ltx_text ltx_font_typewriter" id="S7.p1.1.9">max_seq_length</span> was configured to 2048, defining the maximum input context length for the model.
We used <span class="ltx_text ltx_font_typewriter" id="S7.p1.1.10">torch_dtype</span> of <span class="ltx_text ltx_font_typewriter" id="S7.p1.1.11">bfloat16</span> to optimize training speed.
The loss is computed only on the responses, not on the prompts of instructions.
The Atlas-Chat models were trained on 8 Nvidia A100 80 GB GPUs in parallel, utilizing Fully Sharded Data Parallel (FSDP) strategy on AWS SageMaker. The training was conducted using Hugging Face Transformers library.</p>
</div>
</section>
<section class="ltx_section" id="S8">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">8 </span>Evaluation benchmarks</h2>
<div class="ltx_para" id="S8.p1">
<p class="ltx_p" id="S8.p1.1">To evaluate LLM performance in Darija, we developed a comprehensive evaluation suite that includes benchmarks such as DarijaMMLU, DarijaHellaSwag, and DarijaBench. Additionally, we evaluated using an existing benchmark, Belebele.
All our custom benchmarks are integrated into a fork<span class="ltx_note ltx_role_footnote" id="footnote29"><sup class="ltx_note_mark">29</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">29</sup><span class="ltx_tag ltx_tag_note">29</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/MBZUAI-Paris/lm-evaluation-harness-atlas-chat" title="">https://github.com/MBZUAI-Paris/lm-evaluation-harness-atlas-chat</a></span></span></span> of the LM-Evaluation-Harness repository <cite class="ltx_cite ltx_citemacro_citep">(Gao et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#bib.bib17" title="">2024</a>)</cite> to ensure reproducibility and foster future model comparison. <span class="ltx_text ltx_font_bold" id="S8.p1.1.1">DarijaMMLU<span class="ltx_note ltx_role_footnote" id="footnote30"><sup class="ltx_note_mark">30</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">30</sup><span class="ltx_tag ltx_tag_note"><span class="ltx_text ltx_font_medium" id="footnote30.1.1.1">30</span></span><a class="ltx_ref ltx_url ltx_font_typewriter ltx_font_medium" href="https://hf.co/datasets/MBZUAI-Paris/DarijaMMLU" title="">https://hf.co/datasets/MBZUAI-Paris/DarijaMMLU</a></span></span></span></span>. It is constructed by translating selected subsets from two major benchmarks into Darija from English and MSA: Massive Multitask Language Understanding (MMLU) <cite class="ltx_cite ltx_citemacro_citep">(Hendrycks et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#bib.bib22" title="">2020</a>)</cite><span class="ltx_note ltx_role_footnote" id="footnote31"><sup class="ltx_note_mark">31</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">31</sup><span class="ltx_tag ltx_tag_note">31</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://hf.co/datasets/cais/mmlu" title="">https://hf.co/datasets/cais/mmlu</a></span></span></span> and ArabicMMLU <cite class="ltx_cite ltx_citemacro_citep">(Koto et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#bib.bib31" title="">2024</a>)</cite><span class="ltx_note ltx_role_footnote" id="footnote32"><sup class="ltx_note_mark">32</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">32</sup><span class="ltx_tag ltx_tag_note">32</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://hf.co/datasets/MBZUAI/ArabicMMLU" title="">https://hf.co/datasets/MBZUAI/ArabicMMLU</a></span></span></span>.
While constructing DarijaMMLU, subsets from MMLU and ArabicMMLU that were either too technical (beyond typical user needs) or culturally inappropriate for the Moroccan context were excluded.
The remaining samples were translated into Darija using Claude 3.5 Sonnet. The benchmark consists of 22,027 multiple-choice questions, with the number of choices ranging from 2 to 5. The selected subjects are listed in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#A3.SS3" title="C.3 Selected topics from MMLU and ArabicMMLU ‣ Appendix C Additional details ‣ Atlas-Chat: Adapting Large Language Models for Low-Resource Moroccan Arabic Dialect"><span class="ltx_text ltx_ref_tag">C.3</span></a>.
<span class="ltx_text ltx_font_bold" id="S8.p1.1.2">DarijaHellaSwag<span class="ltx_note ltx_role_footnote" id="footnote33"><sup class="ltx_note_mark">33</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">33</sup><span class="ltx_tag ltx_tag_note"><span class="ltx_text ltx_font_medium" id="footnote33.1.1.1">33</span></span><a class="ltx_ref ltx_url ltx_font_typewriter ltx_font_medium" href="https://hf.co/datasets/MBZUAI-Paris/DarijaHellaSwag" title="">https://hf.co/datasets/MBZUAI-Paris/DarijaHellaSwag</a></span></span></span></span>.
HellaSwag<span class="ltx_note ltx_role_footnote" id="footnote34"><sup class="ltx_note_mark">34</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">34</sup><span class="ltx_tag ltx_tag_note">34</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://hf.co/datasets/Rowan/hellaswag" title="">https://hf.co/datasets/Rowan/hellaswag</a></span></span></span> <cite class="ltx_cite ltx_citemacro_citep">(Zellers et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#bib.bib55" title="">2019</a>)</cite> is a challenging multiple-choice dataset designed to evaluate machine reading comprehension and commonsense reasoning. It presents complex scenarios where models must select the most plausible continuation of a passage from four options, challenging nuanced language understanding and contextual inference. Using Claude 3.5 Sonnet, We translated the HellaSwag validation set into Darija.
<span class="ltx_text ltx_font_bold" id="S8.p1.1.3">Belebele_Ary</span>.
Belebele <cite class="ltx_cite ltx_citemacro_citep">(Bandarkar et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#bib.bib3" title="">2024</a>)</cite><span class="ltx_note ltx_role_footnote" id="footnote35"><sup class="ltx_note_mark">35</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">35</sup><span class="ltx_tag ltx_tag_note">35</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://hf.co/datasets/facebook/belebele" title="">https://hf.co/datasets/facebook/belebele</a></span></span></span> is a comprehensive multiple-choice machine reading comprehension dataset designed to evaluate both monolingual and multilingual models across 122 language variants. Each question is paired with a brief passage and offers four multiple-choice answers. For our work, we specifically used the Ary_Arab subset of Belebele, focusing on Darija to evaluate our models. <span class="ltx_text ltx_font_bold" id="S8.p1.1.4">DarijaBench<span class="ltx_note ltx_role_footnote" id="footnote36"><sup class="ltx_note_mark">36</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">36</sup><span class="ltx_tag ltx_tag_note"><span class="ltx_text ltx_font_medium" id="footnote36.1.1.1">36</span></span><a class="ltx_ref ltx_url ltx_font_typewriter ltx_font_medium" href="https://hf.co/datasets/MBZUAI-Paris/DarijaBench" title="">https://hf.co/datasets/MBZUAI-Paris/DarijaBench</a></span></span></span></span>.
In addition to the above benchmarks, we evaluated with the test sets from the native Darija datasets (see Section <a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#S4" title="4 Native Darija instruction datasets ‣ Atlas-Chat: Adapting Large Language Models for Low-Resource Moroccan Arabic Dialect"><span class="ltx_text ltx_ref_tag">4</span></a>). Typically, 10% of each subset is reserved for testing, unless the original source provides a pre-defined separate test set. The combined test sets, referred to as DarijaBench, encompass three tasks: Translation, Sentiment Analysis, and Summarization.</p>
</div>
<figure class="ltx_table" id="S8.T2">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S8.T2.1" style="width:433.6pt;height:179.9pt;vertical-align:-0.6pt;"><span class="ltx_transformed_inner" style="transform:translate(-138.0pt,57.1pt) scale(0.611048295524428,0.611048295524428) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S8.T2.1.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S8.T2.1.1.1.1">
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_tt" id="S8.T2.1.1.1.1.1" rowspan="2" style="padding:1pt 5.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S8.T2.1.1.1.1.1.1">
<span class="ltx_p" id="S8.T2.1.1.1.1.1.1.1" style="width:91.0pt;"><span class="ltx_text ltx_font_bold" id="S8.T2.1.1.1.1.1.1.1.1">Base Model</span></span>
</span>
</th>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S8.T2.1.1.1.1.2" rowspan="2" style="padding:1pt 5.0pt;"><span class="ltx_text" id="S8.T2.1.1.1.1.2.1">
<span class="ltx_inline-block" id="S8.T2.1.1.1.1.2.1.1">
<span class="ltx_p" id="S8.T2.1.1.1.1.2.1.1.1"><span class="ltx_text ltx_font_bold" id="S8.T2.1.1.1.1.2.1.1.1.1">Darija</span></span>
<span class="ltx_p" id="S8.T2.1.1.1.1.2.1.1.2"><span class="ltx_text ltx_font_bold" id="S8.T2.1.1.1.1.2.1.1.2.1">MMLU</span></span>
</span></span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S8.T2.1.1.1.1.3" rowspan="2" style="padding:1pt 5.0pt;"><span class="ltx_text" id="S8.T2.1.1.1.1.3.1">
<span class="ltx_inline-block" id="S8.T2.1.1.1.1.3.1.1">
<span class="ltx_p" id="S8.T2.1.1.1.1.3.1.1.1"><span class="ltx_text ltx_font_bold" id="S8.T2.1.1.1.1.3.1.1.1.1">Darija</span></span>
<span class="ltx_p" id="S8.T2.1.1.1.1.3.1.1.2"><span class="ltx_text ltx_font_bold" id="S8.T2.1.1.1.1.3.1.1.2.1">Hella</span></span>
<span class="ltx_p" id="S8.T2.1.1.1.1.3.1.1.3"><span class="ltx_text ltx_font_bold" id="S8.T2.1.1.1.1.3.1.1.3.1">Swag</span></span>
</span></span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S8.T2.1.1.1.1.4" rowspan="2" style="padding:1pt 5.0pt;"><span class="ltx_text" id="S8.T2.1.1.1.1.4.1">
<span class="ltx_inline-block" id="S8.T2.1.1.1.1.4.1.1">
<span class="ltx_p" id="S8.T2.1.1.1.1.4.1.1.1"><span class="ltx_text ltx_font_bold" id="S8.T2.1.1.1.1.4.1.1.1.1">Belebele</span></span>
<span class="ltx_p" id="S8.T2.1.1.1.1.4.1.1.2"><span class="ltx_text ltx_font_bold" id="S8.T2.1.1.1.1.4.1.1.2.1">Ary</span></span>
</span></span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S8.T2.1.1.1.1.5" rowspan="2" style="padding:1pt 5.0pt;"><span class="ltx_text" id="S8.T2.1.1.1.1.5.1">
<span class="ltx_inline-block" id="S8.T2.1.1.1.1.5.1.1">
<span class="ltx_p" id="S8.T2.1.1.1.1.5.1.1.1"><span class="ltx_text ltx_font_bold" id="S8.T2.1.1.1.1.5.1.1.1.1">Sentiment</span></span>
<span class="ltx_p" id="S8.T2.1.1.1.1.5.1.1.2"><span class="ltx_text ltx_font_bold" id="S8.T2.1.1.1.1.5.1.1.2.1">Analysis</span></span>
</span></span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="3" id="S8.T2.1.1.1.1.6" style="padding:1pt 5.0pt;"><span class="ltx_text ltx_font_bold" id="S8.T2.1.1.1.1.6.1">Translation (DODa-10K)</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="5" id="S8.T2.1.1.1.1.7" style="padding:1pt 5.0pt;"><span class="ltx_text ltx_font_bold" id="S8.T2.1.1.1.1.7.1">Summarization (MArSum)</span></td>
</tr>
<tr class="ltx_tr" id="S8.T2.1.1.2.2">
<td class="ltx_td ltx_align_center ltx_border_t" id="S8.T2.1.1.2.2.1" style="padding:1pt 5.0pt;">chrF</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S8.T2.1.1.2.2.2" style="padding:1pt 5.0pt;">BLEU</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S8.T2.1.1.2.2.3" style="padding:1pt 5.0pt;">BERTScore</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S8.T2.1.1.2.2.4" style="padding:1pt 5.0pt;">chrF</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S8.T2.1.1.2.2.5" style="padding:1pt 5.0pt;">ROUGE-1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S8.T2.1.1.2.2.6" style="padding:1pt 5.0pt;">ROUGE-L</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S8.T2.1.1.2.2.7" style="padding:1pt 5.0pt;">BERTScore</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S8.T2.1.1.2.2.8" style="padding:1pt 5.0pt;">
<span class="ltx_inline-block" id="S8.T2.1.1.2.2.8.1">
<span class="ltx_p" id="S8.T2.1.1.2.2.8.1.1">LLM as a</span>
<span class="ltx_p" id="S8.T2.1.1.2.2.8.1.2">Judge win rate</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S8.T2.1.1.3.3">
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_t" id="S8.T2.1.1.3.3.1" style="padding:1pt 5.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S8.T2.1.1.3.3.1.1">
<span class="ltx_p" id="S8.T2.1.1.3.3.1.1.1" style="width:91.0pt;"><span class="ltx_text ltx_font_bold" id="S8.T2.1.1.3.3.1.1.1.1">Jais-family-1.3B-chat</span></span>
</span>
</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S8.T2.1.1.3.3.2" style="padding:1pt 5.0pt;">35.39</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S8.T2.1.1.3.3.3" style="padding:1pt 5.0pt;">32.51</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S8.T2.1.1.3.3.4" style="padding:1pt 5.0pt;">38.33</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S8.T2.1.1.3.3.5" style="padding:1pt 5.0pt;">45.29</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S8.T2.1.1.3.3.6" style="padding:1pt 5.0pt;">6.18</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S8.T2.1.1.3.3.7" style="padding:1pt 5.0pt;">0.13</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S8.T2.1.1.3.3.8" style="padding:1pt 5.0pt;">39.17</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S8.T2.1.1.3.3.9" style="padding:1pt 5.0pt;">20.56</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S8.T2.1.1.3.3.10" style="padding:1pt 5.0pt;">6.85</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S8.T2.1.1.3.3.11" style="padding:1pt 5.0pt;">6.72</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S8.T2.1.1.3.3.12" style="padding:1pt 5.0pt;">35.77</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S8.T2.1.1.3.3.13" style="padding:1pt 5.0pt;">0.57</td>
</tr>
<tr class="ltx_tr" id="S8.T2.1.1.4.4">
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row" id="S8.T2.1.1.4.4.1" style="padding:1pt 5.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S8.T2.1.1.4.4.1.1">
<span class="ltx_p" id="S8.T2.1.1.4.4.1.1.1" style="width:91.0pt;"><span class="ltx_text ltx_font_bold" id="S8.T2.1.1.4.4.1.1.1.1">Gemma-2-2B-It</span></span>
</span>
</th>
<td class="ltx_td ltx_align_center" id="S8.T2.1.1.4.4.2" style="padding:1pt 5.0pt;">28.58</td>
<td class="ltx_td ltx_align_center" id="S8.T2.1.1.4.4.3" style="padding:1pt 5.0pt;">32.42</td>
<td class="ltx_td ltx_align_center" id="S8.T2.1.1.4.4.4" style="padding:1pt 5.0pt;">25.22</td>
<td class="ltx_td ltx_align_center" id="S8.T2.1.1.4.4.5" style="padding:1pt 5.0pt;">53.36</td>
<td class="ltx_td ltx_align_center" id="S8.T2.1.1.4.4.6" style="padding:1pt 5.0pt;">4.96</td>
<td class="ltx_td ltx_align_center" id="S8.T2.1.1.4.4.7" style="padding:1pt 5.0pt;">0.1</td>
<td class="ltx_td ltx_align_center" id="S8.T2.1.1.4.4.8" style="padding:1pt 5.0pt;">35.37</td>
<td class="ltx_td ltx_align_center" id="S8.T2.1.1.4.4.9" style="padding:1pt 5.0pt;">0.48</td>
<td class="ltx_td ltx_align_center" id="S8.T2.1.1.4.4.10" style="padding:1pt 5.0pt;">0.49</td>
<td class="ltx_td ltx_align_center" id="S8.T2.1.1.4.4.11" style="padding:1pt 5.0pt;">0.48</td>
<td class="ltx_td ltx_align_center" id="S8.T2.1.1.4.4.12" style="padding:1pt 5.0pt;">24.44</td>
<td class="ltx_td ltx_align_center" id="S8.T2.1.1.4.4.13" style="padding:1pt 5.0pt;">6.79</td>
</tr>
<tr class="ltx_tr" id="S8.T2.1.1.5.5">
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row" id="S8.T2.1.1.5.5.1" style="padding:1pt 5.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S8.T2.1.1.5.5.1.1">
<span class="ltx_p" id="S8.T2.1.1.5.5.1.1.1" style="width:91.0pt;"><span class="ltx_text ltx_font_bold" id="S8.T2.1.1.5.5.1.1.1.1">Jais-family-2.7B-chat</span></span>
</span>
</th>
<td class="ltx_td ltx_align_center" id="S8.T2.1.1.5.5.2" style="padding:1pt 5.0pt;">37.44</td>
<td class="ltx_td ltx_align_center" id="S8.T2.1.1.5.5.3" style="padding:1pt 5.0pt;">34.49</td>
<td class="ltx_td ltx_align_center" id="S8.T2.1.1.5.5.4" style="padding:1pt 5.0pt;">44.11</td>
<td class="ltx_td ltx_align_center" id="S8.T2.1.1.5.5.5" style="padding:1pt 5.0pt;">51.56</td>
<td class="ltx_td ltx_align_center" id="S8.T2.1.1.5.5.6" style="padding:1pt 5.0pt;">7.46</td>
<td class="ltx_td ltx_align_center" id="S8.T2.1.1.5.5.7" style="padding:1pt 5.0pt;">0.25</td>
<td class="ltx_td ltx_align_center" id="S8.T2.1.1.5.5.8" style="padding:1pt 5.0pt;">39.84</td>
<td class="ltx_td ltx_align_center" id="S8.T2.1.1.5.5.9" style="padding:1pt 5.0pt;">20.63</td>
<td class="ltx_td ltx_align_center" id="S8.T2.1.1.5.5.10" style="padding:1pt 5.0pt;">7.74</td>
<td class="ltx_td ltx_align_center" id="S8.T2.1.1.5.5.11" style="padding:1pt 5.0pt;">7.6</td>
<td class="ltx_td ltx_align_center" id="S8.T2.1.1.5.5.12" style="padding:1pt 5.0pt;">36.38</td>
<td class="ltx_td ltx_align_center" id="S8.T2.1.1.5.5.13" style="padding:1pt 5.0pt;">0.89</td>
</tr>
<tr class="ltx_tr" id="S8.T2.1.1.6.6">
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row" id="S8.T2.1.1.6.6.1" style="padding:1pt 5.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S8.T2.1.1.6.6.1.1">
<span class="ltx_p" id="S8.T2.1.1.6.6.1.1.1" style="width:91.0pt;"><span class="ltx_text ltx_font_bold" id="S8.T2.1.1.6.6.1.1.1.1">Jais-family-6.7B-chat</span></span>
</span>
</th>
<td class="ltx_td ltx_align_center" id="S8.T2.1.1.6.6.2" style="padding:1pt 5.0pt;">39.96</td>
<td class="ltx_td ltx_align_center" id="S8.T2.1.1.6.6.3" style="padding:1pt 5.0pt;">41.57</td>
<td class="ltx_td ltx_align_center" id="S8.T2.1.1.6.6.4" style="padding:1pt 5.0pt;">51.22</td>
<td class="ltx_td ltx_align_center" id="S8.T2.1.1.6.6.5" style="padding:1pt 5.0pt;">56.78</td>
<td class="ltx_td ltx_align_center" id="S8.T2.1.1.6.6.6" style="padding:1pt 5.0pt;">11.85</td>
<td class="ltx_td ltx_align_center" id="S8.T2.1.1.6.6.7" style="padding:1pt 5.0pt;">0.73</td>
<td class="ltx_td ltx_align_center" id="S8.T2.1.1.6.6.8" style="padding:1pt 5.0pt;">45.77</td>
<td class="ltx_td ltx_align_center" id="S8.T2.1.1.6.6.9" style="padding:1pt 5.0pt;">22.12</td>
<td class="ltx_td ltx_align_center" id="S8.T2.1.1.6.6.10" style="padding:1pt 5.0pt;">7.98</td>
<td class="ltx_td ltx_align_center" id="S8.T2.1.1.6.6.11" style="padding:1pt 5.0pt;">7.82</td>
<td class="ltx_td ltx_align_center" id="S8.T2.1.1.6.6.12" style="padding:1pt 5.0pt;">37.1</td>
<td class="ltx_td ltx_align_center" id="S8.T2.1.1.6.6.13" style="padding:1pt 5.0pt;">3.02</td>
</tr>
<tr class="ltx_tr" id="S8.T2.1.1.7.7">
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row" id="S8.T2.1.1.7.7.1" style="padding:1pt 5.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S8.T2.1.1.7.7.1.1">
<span class="ltx_p" id="S8.T2.1.1.7.7.1.1.1" style="width:91.0pt;"><span class="ltx_text ltx_font_bold" id="S8.T2.1.1.7.7.1.1.1.1">Jais-Adapted-7B-chat</span></span>
</span>
</th>
<td class="ltx_td ltx_align_center" id="S8.T2.1.1.7.7.2" style="padding:1pt 5.0pt;">39.3</td>
<td class="ltx_td ltx_align_center" id="S8.T2.1.1.7.7.3" style="padding:1pt 5.0pt;">35.19</td>
<td class="ltx_td ltx_align_center" id="S8.T2.1.1.7.7.4" style="padding:1pt 5.0pt;">43.67</td>
<td class="ltx_td ltx_align_center" id="S8.T2.1.1.7.7.5" style="padding:1pt 5.0pt;">52.72</td>
<td class="ltx_td ltx_align_center" id="S8.T2.1.1.7.7.6" style="padding:1pt 5.0pt;">9.34</td>
<td class="ltx_td ltx_align_center" id="S8.T2.1.1.7.7.7" style="padding:1pt 5.0pt;">0.6</td>
<td class="ltx_td ltx_align_center" id="S8.T2.1.1.7.7.8" style="padding:1pt 5.0pt;">45.05</td>
<td class="ltx_td ltx_align_center" id="S8.T2.1.1.7.7.9" style="padding:1pt 5.0pt;">23.2</td>
<td class="ltx_td ltx_align_center" id="S8.T2.1.1.7.7.10" style="padding:1pt 5.0pt;">7.82</td>
<td class="ltx_td ltx_align_center" id="S8.T2.1.1.7.7.11" style="padding:1pt 5.0pt;">7.63</td>
<td class="ltx_td ltx_align_center" id="S8.T2.1.1.7.7.12" style="padding:1pt 5.0pt;">36.87</td>
<td class="ltx_td ltx_align_center" id="S8.T2.1.1.7.7.13" style="padding:1pt 5.0pt;">2.82</td>
</tr>
<tr class="ltx_tr" id="S8.T2.1.1.8.8">
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row" id="S8.T2.1.1.8.8.1" style="padding:1pt 5.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S8.T2.1.1.8.8.1.1">
<span class="ltx_p" id="S8.T2.1.1.8.8.1.1.1" style="width:91.0pt;"><span class="ltx_text ltx_font_bold" id="S8.T2.1.1.8.8.1.1.1.1">AceGPT-7B-chat</span></span>
</span>
</th>
<td class="ltx_td ltx_align_center" id="S8.T2.1.1.8.8.2" style="padding:1pt 5.0pt;">35.98</td>
<td class="ltx_td ltx_align_center" id="S8.T2.1.1.8.8.3" style="padding:1pt 5.0pt;">36.57</td>
<td class="ltx_td ltx_align_center" id="S8.T2.1.1.8.8.4" style="padding:1pt 5.0pt;">30.11</td>
<td class="ltx_td ltx_align_center" id="S8.T2.1.1.8.8.5" style="padding:1pt 5.0pt;">40.23</td>
<td class="ltx_td ltx_align_center" id="S8.T2.1.1.8.8.6" style="padding:1pt 5.0pt;">11.33</td>
<td class="ltx_td ltx_align_center" id="S8.T2.1.1.8.8.7" style="padding:1pt 5.0pt;">0.44</td>
<td class="ltx_td ltx_align_center" id="S8.T2.1.1.8.8.8" style="padding:1pt 5.0pt;">45.83</td>
<td class="ltx_td ltx_align_center" id="S8.T2.1.1.8.8.9" style="padding:1pt 5.0pt;">27.18</td>
<td class="ltx_td ltx_align_center" id="S8.T2.1.1.8.8.10" style="padding:1pt 5.0pt;">7.6</td>
<td class="ltx_td ltx_align_center" id="S8.T2.1.1.8.8.11" style="padding:1pt 5.0pt;">7.55</td>
<td class="ltx_td ltx_align_center" id="S8.T2.1.1.8.8.12" style="padding:1pt 5.0pt;">37.39</td>
<td class="ltx_td ltx_align_center" id="S8.T2.1.1.8.8.13" style="padding:1pt 5.0pt;">2.27</td>
</tr>
<tr class="ltx_tr" id="S8.T2.1.1.9.9">
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_t" id="S8.T2.1.1.9.9.1" style="padding:1pt 5.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S8.T2.1.1.9.9.1.1">
<span class="ltx_p" id="S8.T2.1.1.9.9.1.1.1" style="width:91.0pt;"><span class="ltx_text ltx_font_bold" id="S8.T2.1.1.9.9.1.1.1.1">Atlas-Chat-2B</span></span>
</span>
</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S8.T2.1.1.9.9.2" style="padding:1pt 5.0pt;">44.97</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S8.T2.1.1.9.9.3" style="padding:1pt 5.0pt;">41.48</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S8.T2.1.1.9.9.4" style="padding:1pt 5.0pt;">53.89</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S8.T2.1.1.9.9.5" style="padding:1pt 5.0pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S8.T2.1.1.9.9.5.1">73.99</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S8.T2.1.1.9.9.6" style="padding:1pt 5.0pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S8.T2.1.1.9.9.6.1">44.86</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S8.T2.1.1.9.9.7" style="padding:1pt 5.0pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S8.T2.1.1.9.9.7.1">22.76</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S8.T2.1.1.9.9.8" style="padding:1pt 5.0pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S8.T2.1.1.9.9.8.1">73.72</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S8.T2.1.1.9.9.9" style="padding:1pt 5.0pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S8.T2.1.1.9.9.9.1">28.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S8.T2.1.1.9.9.10" style="padding:1pt 5.0pt;">9</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S8.T2.1.1.9.9.11" style="padding:1pt 5.0pt;">8.88</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S8.T2.1.1.9.9.12" style="padding:1pt 5.0pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S8.T2.1.1.9.9.12.1">44.71</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S8.T2.1.1.9.9.13" style="padding:1pt 5.0pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S8.T2.1.1.9.9.13.1">55.22</span></td>
</tr>
<tr class="ltx_tr" id="S8.T2.1.1.10.10">
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_t" id="S8.T2.1.1.10.10.1" style="padding:1pt 5.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S8.T2.1.1.10.10.1.1">
<span class="ltx_p" id="S8.T2.1.1.10.10.1.1.1" style="width:91.0pt;"><span class="ltx_text ltx_font_bold" id="S8.T2.1.1.10.10.1.1.1.1">Llama-3.1-8B-Instruct</span></span>
</span>
</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S8.T2.1.1.10.10.2" style="padding:1pt 5.0pt;">44.14</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S8.T2.1.1.10.10.3" style="padding:1pt 5.0pt;">38.24</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S8.T2.1.1.10.10.4" style="padding:1pt 5.0pt;">47</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S8.T2.1.1.10.10.5" style="padding:1pt 5.0pt;">44.08</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S8.T2.1.1.10.10.6" style="padding:1pt 5.0pt;">14.19</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S8.T2.1.1.10.10.7" style="padding:1pt 5.0pt;">0.92</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S8.T2.1.1.10.10.8" style="padding:1pt 5.0pt;">44.57</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S8.T2.1.1.10.10.9" style="padding:1pt 5.0pt;">28.66</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S8.T2.1.1.10.10.10" style="padding:1pt 5.0pt;"><span class="ltx_text ltx_font_bold" id="S8.T2.1.1.10.10.10.1">10.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S8.T2.1.1.10.10.11" style="padding:1pt 5.0pt;"><span class="ltx_text ltx_font_bold" id="S8.T2.1.1.10.10.11.1">9.93</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S8.T2.1.1.10.10.12" style="padding:1pt 5.0pt;">39.37</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S8.T2.1.1.10.10.13" style="padding:1pt 5.0pt;">1.27</td>
</tr>
<tr class="ltx_tr" id="S8.T2.1.1.11.11">
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row" id="S8.T2.1.1.11.11.1" style="padding:1pt 5.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S8.T2.1.1.11.11.1.1">
<span class="ltx_p" id="S8.T2.1.1.11.11.1.1.1" style="width:91.0pt;"><span class="ltx_text ltx_font_bold" id="S8.T2.1.1.11.11.1.1.1.1">Gemma-2-9B-It</span></span>
</span>
</th>
<td class="ltx_td ltx_align_center" id="S8.T2.1.1.11.11.2" style="padding:1pt 5.0pt;">35.91</td>
<td class="ltx_td ltx_align_center" id="S8.T2.1.1.11.11.3" style="padding:1pt 5.0pt;">42.43</td>
<td class="ltx_td ltx_align_center" id="S8.T2.1.1.11.11.4" style="padding:1pt 5.0pt;">31</td>
<td class="ltx_td ltx_align_center" id="S8.T2.1.1.11.11.5" style="padding:1pt 5.0pt;">59.87</td>
<td class="ltx_td ltx_align_center" id="S8.T2.1.1.11.11.6" style="padding:1pt 5.0pt;">19.16</td>
<td class="ltx_td ltx_align_center" id="S8.T2.1.1.11.11.7" style="padding:1pt 5.0pt;">3.1</td>
<td class="ltx_td ltx_align_center" id="S8.T2.1.1.11.11.8" style="padding:1pt 5.0pt;">48.96</td>
<td class="ltx_td ltx_align_center" id="S8.T2.1.1.11.11.9" style="padding:1pt 5.0pt;">25.49</td>
<td class="ltx_td ltx_align_center" id="S8.T2.1.1.11.11.10" style="padding:1pt 5.0pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S8.T2.1.1.11.11.10.1">9.83</span></td>
<td class="ltx_td ltx_align_center" id="S8.T2.1.1.11.11.11" style="padding:1pt 5.0pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S8.T2.1.1.11.11.11.1">9.64</span></td>
<td class="ltx_td ltx_align_center" id="S8.T2.1.1.11.11.12" style="padding:1pt 5.0pt;">38</td>
<td class="ltx_td ltx_align_center" id="S8.T2.1.1.11.11.13" style="padding:1pt 5.0pt;">13.8</td>
</tr>
<tr class="ltx_tr" id="S8.T2.1.1.12.12">
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row" id="S8.T2.1.1.12.12.1" style="padding:1pt 5.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S8.T2.1.1.12.12.1.1">
<span class="ltx_p" id="S8.T2.1.1.12.12.1.1.1" style="width:91.0pt;"><span class="ltx_text ltx_font_bold" id="S8.T2.1.1.12.12.1.1.1.1">Jais-family-13B-Chat</span></span>
</span>
</th>
<td class="ltx_td ltx_align_center" id="S8.T2.1.1.12.12.2" style="padding:1pt 5.0pt;">45.11</td>
<td class="ltx_td ltx_align_center" id="S8.T2.1.1.12.12.3" style="padding:1pt 5.0pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S8.T2.1.1.12.12.3.1">43.9</span></td>
<td class="ltx_td ltx_align_center" id="S8.T2.1.1.12.12.4" style="padding:1pt 5.0pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S8.T2.1.1.12.12.4.1">58.67</span></td>
<td class="ltx_td ltx_align_center" id="S8.T2.1.1.12.12.5" style="padding:1pt 5.0pt;">41.73</td>
<td class="ltx_td ltx_align_center" id="S8.T2.1.1.12.12.6" style="padding:1pt 5.0pt;">11.71</td>
<td class="ltx_td ltx_align_center" id="S8.T2.1.1.12.12.7" style="padding:1pt 5.0pt;">0.92</td>
<td class="ltx_td ltx_align_center" id="S8.T2.1.1.12.12.8" style="padding:1pt 5.0pt;">45.96</td>
<td class="ltx_td ltx_align_center" id="S8.T2.1.1.12.12.9" style="padding:1pt 5.0pt;">22.53</td>
<td class="ltx_td ltx_align_center" id="S8.T2.1.1.12.12.10" style="padding:1pt 5.0pt;">7.99</td>
<td class="ltx_td ltx_align_center" id="S8.T2.1.1.12.12.11" style="padding:1pt 5.0pt;">7.84</td>
<td class="ltx_td ltx_align_center" id="S8.T2.1.1.12.12.12" style="padding:1pt 5.0pt;">37.13</td>
<td class="ltx_td ltx_align_center" id="S8.T2.1.1.12.12.13" style="padding:1pt 5.0pt;">1.77</td>
</tr>
<tr class="ltx_tr" id="S8.T2.1.1.13.13">
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row" id="S8.T2.1.1.13.13.1" style="padding:1pt 5.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S8.T2.1.1.13.13.1.1">
<span class="ltx_p" id="S8.T2.1.1.13.13.1.1.1" style="width:91.0pt;"><span class="ltx_text ltx_font_bold" id="S8.T2.1.1.13.13.1.1.1.1">Jais-Adapted-13B-chat</span></span>
</span>
</th>
<td class="ltx_td ltx_align_center" id="S8.T2.1.1.13.13.2" style="padding:1pt 5.0pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S8.T2.1.1.13.13.2.1">45.2</span></td>
<td class="ltx_td ltx_align_center" id="S8.T2.1.1.13.13.3" style="padding:1pt 5.0pt;">40.65</td>
<td class="ltx_td ltx_align_center" id="S8.T2.1.1.13.13.4" style="padding:1pt 5.0pt;">49.67</td>
<td class="ltx_td ltx_align_center" id="S8.T2.1.1.13.13.5" style="padding:1pt 5.0pt;">66.68</td>
<td class="ltx_td ltx_align_center" id="S8.T2.1.1.13.13.6" style="padding:1pt 5.0pt;">10.52</td>
<td class="ltx_td ltx_align_center" id="S8.T2.1.1.13.13.7" style="padding:1pt 5.0pt;">0.87</td>
<td class="ltx_td ltx_align_center" id="S8.T2.1.1.13.13.8" style="padding:1pt 5.0pt;">47.91</td>
<td class="ltx_td ltx_align_center" id="S8.T2.1.1.13.13.9" style="padding:1pt 5.0pt;">23.8</td>
<td class="ltx_td ltx_align_center" id="S8.T2.1.1.13.13.10" style="padding:1pt 5.0pt;">8.86</td>
<td class="ltx_td ltx_align_center" id="S8.T2.1.1.13.13.11" style="padding:1pt 5.0pt;">8.63</td>
<td class="ltx_td ltx_align_center" id="S8.T2.1.1.13.13.12" style="padding:1pt 5.0pt;">37.67</td>
<td class="ltx_td ltx_align_center" id="S8.T2.1.1.13.13.13" style="padding:1pt 5.0pt;">1.92</td>
</tr>
<tr class="ltx_tr" id="S8.T2.1.1.14.14">
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row" id="S8.T2.1.1.14.14.1" style="padding:1pt 5.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S8.T2.1.1.14.14.1.1">
<span class="ltx_p" id="S8.T2.1.1.14.14.1.1.1" style="width:91.0pt;"><span class="ltx_text ltx_font_bold" id="S8.T2.1.1.14.14.1.1.1.1">AceGPT-13B-chat</span></span>
</span>
</th>
<td class="ltx_td ltx_align_center" id="S8.T2.1.1.14.14.2" style="padding:1pt 5.0pt;">41.09</td>
<td class="ltx_td ltx_align_center" id="S8.T2.1.1.14.14.3" style="padding:1pt 5.0pt;">38.35</td>
<td class="ltx_td ltx_align_center" id="S8.T2.1.1.14.14.4" style="padding:1pt 5.0pt;">33.11</td>
<td class="ltx_td ltx_align_center" id="S8.T2.1.1.14.14.5" style="padding:1pt 5.0pt;">59.58</td>
<td class="ltx_td ltx_align_center" id="S8.T2.1.1.14.14.6" style="padding:1pt 5.0pt;">16.7</td>
<td class="ltx_td ltx_align_center" id="S8.T2.1.1.14.14.7" style="padding:1pt 5.0pt;">0.98</td>
<td class="ltx_td ltx_align_center" id="S8.T2.1.1.14.14.8" style="padding:1pt 5.0pt;">48.48</td>
<td class="ltx_td ltx_align_center" id="S8.T2.1.1.14.14.9" style="padding:1pt 5.0pt;">26.83</td>
<td class="ltx_td ltx_align_center" id="S8.T2.1.1.14.14.10" style="padding:1pt 5.0pt;">7.92</td>
<td class="ltx_td ltx_align_center" id="S8.T2.1.1.14.14.11" style="padding:1pt 5.0pt;">7.81</td>
<td class="ltx_td ltx_align_center" id="S8.T2.1.1.14.14.12" style="padding:1pt 5.0pt;">36.91</td>
<td class="ltx_td ltx_align_center" id="S8.T2.1.1.14.14.13" style="padding:1pt 5.0pt;">2.87</td>
</tr>
<tr class="ltx_tr" id="S8.T2.1.1.15.15">
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_bb ltx_border_t" id="S8.T2.1.1.15.15.1" style="padding:1pt 5.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S8.T2.1.1.15.15.1.1">
<span class="ltx_p" id="S8.T2.1.1.15.15.1.1.1" style="width:91.0pt;"><span class="ltx_text ltx_font_bold" id="S8.T2.1.1.15.15.1.1.1.1">Atlas-Chat-9B</span></span>
</span>
</th>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S8.T2.1.1.15.15.2" style="padding:1pt 5.0pt;"><span class="ltx_text ltx_font_bold" id="S8.T2.1.1.15.15.2.1">58.23</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S8.T2.1.1.15.15.3" style="padding:1pt 5.0pt;"><span class="ltx_text ltx_font_bold" id="S8.T2.1.1.15.15.3.1">57.75</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S8.T2.1.1.15.15.4" style="padding:1pt 5.0pt;"><span class="ltx_text ltx_font_bold" id="S8.T2.1.1.15.15.4.1">74.56</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S8.T2.1.1.15.15.5" style="padding:1pt 5.0pt;"><span class="ltx_text ltx_font_bold" id="S8.T2.1.1.15.15.5.1">81.89</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S8.T2.1.1.15.15.6" style="padding:1pt 5.0pt;"><span class="ltx_text ltx_font_bold" id="S8.T2.1.1.15.15.6.1">50.48</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S8.T2.1.1.15.15.7" style="padding:1pt 5.0pt;"><span class="ltx_text ltx_font_bold" id="S8.T2.1.1.15.15.7.1">28.08</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S8.T2.1.1.15.15.8" style="padding:1pt 5.0pt;"><span class="ltx_text ltx_font_bold" id="S8.T2.1.1.15.15.8.1">76.31</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S8.T2.1.1.15.15.9" style="padding:1pt 5.0pt;"><span class="ltx_text ltx_font_bold" id="S8.T2.1.1.15.15.9.1">32.07</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S8.T2.1.1.15.15.10" style="padding:1pt 5.0pt;">9.5</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S8.T2.1.1.15.15.11" style="padding:1pt 5.0pt;">9.45</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S8.T2.1.1.15.15.12" style="padding:1pt 5.0pt;"><span class="ltx_text ltx_font_bold" id="S8.T2.1.1.15.15.12.1">47</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S8.T2.1.1.15.15.13" style="padding:1pt 5.0pt;"><span class="ltx_text ltx_font_bold" id="S8.T2.1.1.15.15.13.1">59.76</span></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Zero-shot performance comparison of Atlas-Chat and state-of-the-art models on the evaluation suite with prompts written in <span class="ltx_text ltx_font_bold" id="S8.T2.5.1">Darija</span>. The highest scores are indicated in <span class="ltx_text ltx_font_bold" id="S8.T2.6.2">bold</span> and the second-highest are <span class="ltx_text ltx_framed ltx_framed_underline" id="S8.T2.7.3">underlined</span>.</figcaption>
</figure>
</section>
<section class="ltx_section" id="S9">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">9 </span>Results</h2>
<div class="ltx_para ltx_noindent" id="S9.p1">
<p class="ltx_p" id="S9.p1.2"><span class="ltx_text ltx_font_bold" id="S9.p1.2.1">Evaluation metrics</span>.
We employed the Accuracy metric to evaluate models on multiple-choice benchmarks, including DarijaMMLU, DarijaHellaSwag, Belebele_Ary, and the discriminative Sentiment Analysis task within DarijaBench.
For translation and summarization tasks, we adopted the conventional
BLEU <cite class="ltx_cite ltx_citemacro_citep">(Papineni et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#bib.bib41" title="">2002</a>)</cite> and ROUGE-1/L <cite class="ltx_cite ltx_citemacro_citep">(Lin, <a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#bib.bib33" title="">2004</a>)</cite>, respectively.
However, since these metrics are based on <math alttext="n" class="ltx_Math" display="inline" id="S9.p1.1.m1.1"><semantics id="S9.p1.1.m1.1a"><mi id="S9.p1.1.m1.1.1" xref="S9.p1.1.m1.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S9.p1.1.m1.1b"><ci id="S9.p1.1.m1.1.1.cmml" xref="S9.p1.1.m1.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S9.p1.1.m1.1c">n</annotation><annotation encoding="application/x-llamapun" id="S9.p1.1.m1.1d">italic_n</annotation></semantics></math>-grams, they are not well-suited for assessing Darija.
For example, the same word in Darija can be written in multiple ways ("How are you?" = "<span class="ltx_ERROR undefined" id="S9.p1.2.2">\&lt;</span>كيدير&gt;" = "<span class="ltx_ERROR undefined" id="S9.p1.2.3">\&lt;</span>كيداير&gt;" = "<span class="ltx_ERROR undefined" id="S9.p1.2.4">\&lt;</span>كي داير&gt;") due to the lack of standardized spelling (e.g., code-switching, diacritics, agglutinations, borrowings), making these two metrics overly rigid in cases where slight variations still convey the same meaning.
To gain a more fine-grained insight, we also included
chrF <cite class="ltx_cite ltx_citemacro_citep">(Popović, <a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#bib.bib43" title="">2015</a>)</cite>, which operates at the level of character <math alttext="n" class="ltx_Math" display="inline" id="S9.p1.2.m2.1"><semantics id="S9.p1.2.m2.1a"><mi id="S9.p1.2.m2.1.1" xref="S9.p1.2.m2.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S9.p1.2.m2.1b"><ci id="S9.p1.2.m2.1.1.cmml" xref="S9.p1.2.m2.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S9.p1.2.m2.1c">n</annotation><annotation encoding="application/x-llamapun" id="S9.p1.2.m2.1d">italic_n</annotation></semantics></math>-grams.
Finally, to capture higher-level semantic similarity, we also used BERTScore <cite class="ltx_cite ltx_citemacro_citep">(Zhang et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#bib.bib56" title="">2019</a>)</cite>, with DarijaBERT as the reference model for summarization, and multilingual BERT<span class="ltx_note ltx_role_footnote" id="footnote37"><sup class="ltx_note_mark">37</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">37</sup><span class="ltx_tag ltx_tag_note">37</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://hf.co/google-bert/bert-base-multilingual-cased" title="">https://hf.co/google-bert/bert-base-multilingual-cased</a></span></span></span> for translation.
All our evaluations were conducted in a zero-shot setting with greedy decoding.
<span class="ltx_text ltx_font_bold" id="S9.p1.2.5">Result analysis</span>.
We compared Atlas-Chat with instruction-tuned models from the Jais series (including the <span class="ltx_text ltx_font_typewriter" id="S9.p1.2.6">-family</span> models trained from scratch and the <span class="ltx_text ltx_font_typewriter" id="S9.p1.2.7">-adapted</span> ones based on LLaMA 2), along with AceGPT, LLaMA 3.1, and Gemma 2 (our base model).
Given that Atlas-Chat features 2B and 9B sizes, we extended our comparison to the closest larger-sized model above 9B when available (e.g., AceGPT-13B-chat), while included all versions with smaller sizes.
The evaluation results are shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#S8.T2" title="Table 2 ‣ 8 Evaluation benchmarks ‣ Atlas-Chat: Adapting Large Language Models for Low-Resource Moroccan Arabic Dialect"><span class="ltx_text ltx_ref_tag">2</span></a>, demonstrating the exceptional performance of Atlas-Chat models across multiple Darija benchmarks and metrics.
When compared to other models with 7B parameters or fewer, Atlas-Chat-2B has a significantly superior performance. On the DarijaMMLU, DarijaHellaSwag, Belebele Ary, and Sentiment Analysis benchmarks, Atlas-Chat-2B achieves accuracy scores of 44.97%, 41.48%, 53.89%, and 73.99% respectively, surpassing its closest competitor in the same category, namely Jais-family-6.7B, by performance gaps of 5.01% on DarijaMMLU, 2.67% on Belebele_Ary, and 17.21% on Sentiment Analysis, while being the second in performance on DarijaHellaSwag, trailing by only 0.09% from Jais-family-6.7B, despite having approximately one-third the number of parameters. In translation tasks, Atlas-Chat-2B outperformed the other models in the same category, with chrF, BLEU, and BERTScore metrics of 44.86%, 22.76%, and 73.72%, respectively. Similarly, in summarization tasks, Atlas-Chat-2B consistently ranks as the top performer in its category, with chrF, ROUGE-1/L, and BERTScore metrics of 28.8%, 9%/8.88%, and 44.71%, respectively.
Atlas-Chat-2B’s strong performance is further complemented by its larger counterpart, Atlas-Chat-9B, which consistently outperforms other state-of-the-art models, achieving the highest scores in 9 out of 11 metrics. Its strength is especially evident in translation tasks, where it leads all three metrics (chrF: 50.48%, BLEU: 28.08%, BERTScore: 76.31%) by a significant margin. The model also excels in tasks such as DarijaMMLU (58.23%), DarijaHellaSwag (57.75%), Belebele_Ary (74.56%), and Sentiment Analysis (81.89%), surpassing larger models like AceGPT-13B-chat and Jais-family-13B-Chat.
However, in summarization tasks evaluated using metrics based on lexical overlapping, particularly ROUGE, Atlas-Chat did not demonstrate the same level of superiority. This could be because these metrics may not fully capture the nuances of Darija. Additionally, summarization is a less constrained generation task, often resulting in equally valid summaries with varying formulations <cite class="ltx_cite ltx_citemacro_citep">(Guo et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#bib.bib20" title="">2024</a>)</cite>. To further evaluate summarization performance, we employ the LLM-as-a-judge approach <cite class="ltx_cite ltx_citemacro_citep">(Zheng et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#bib.bib58" title="">2023</a>)</cite>, using Claude 3.5 Sonnet as the reference model in the following section.</p>
</div>
<figure class="ltx_figure" id="S9.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="684" id="S9.F1.g1" src="x1.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>LLM-as-a-judge results for summarization.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S9.p2">
<p class="ltx_p" id="S9.p2.1"><span class="ltx_text ltx_font_bold" id="S9.p2.1.1">LLM-as-a-judge for summarization</span>.
We evaluated the model-generated summaries by comparing them with human-written ground truths.
The pre-defined criteria, adapted from <cite class="ltx_cite ltx_citemacro_citet">Fabbri et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#bib.bib13" title="">2021</a>)</cite>, consider wordness, conciseness, and relevancy aspects. The prompt leveraged for the evaluation is provided in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#A3.SS4" title="C.4 LLM-as-Judge prompt for summarization evaluation ‣ Appendix C Additional details ‣ Atlas-Chat: Adapting Large Language Models for Low-Resource Moroccan Arabic Dialect"><span class="ltx_text ltx_ref_tag">C.4</span></a>.
This approach is particularly suitable for tasks requiring subjective evaluation, such as open-ended questions, dialogue generation, and summarization.
To mitigate biases such as verbosity and position bias identified by <cite class="ltx_cite ltx_citemacro_citet">Zheng et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#bib.bib58" title="">2023</a>)</cite>, all models were additionally instructed to limit their output.
Results in Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#S9.F1" title="Figure 1 ‣ 9 Results ‣ Atlas-Chat: Adapting Large Language Models for Low-Resource Moroccan Arabic Dialect"><span class="ltx_text ltx_ref_tag">1</span></a> and Table <a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#S8.T2" title="Table 2 ‣ 8 Evaluation benchmarks ‣ Atlas-Chat: Adapting Large Language Models for Low-Resource Moroccan Arabic Dialect"><span class="ltx_text ltx_ref_tag">2</span></a> show that, within the LLM-as-a-judge framework, the judge model selected Atlas-Chat’s responses 59.76% of the time over ground truth answers. This surpasses its closest competitor in the same model-size category, Gemma-2-9B-It, by approximately 46% in win rate on the same metric.</p>
</div>
</section>
<section class="ltx_section" id="S10">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">10 </span>Conclusion</h2>
<div class="ltx_para" id="S10.p1">
<p class="ltx_p" id="S10.p1.1">In this work, we presented Atlas-Chat, the first collection of large language models specifically developed for dialectal Arabic, with a primary focus on Moroccan Darija. We constructed a comprehensive instruction dataset by consolidating existing Darija resources, creating novel datasets both manually and synthetically, and translating English instructions with rigorous control measures.
To evaluate LLM performance in Darija, we also introduced a novel evaluation suite for Darija that includes both discriminative and generative tasks.
Our models, <span class="ltx_text ltx_font_typewriter" id="S10.p1.1.1">Atlas-Chat-2B</span> and <span class="ltx_text ltx_font_typewriter" id="S10.p1.1.2">Atlas-Chat-9B</span>, demonstrated superior performance in following Darija instructions and executing standard NLP tasks, outperforming both state-of-the-art and Arabic-specialized LLMs.
Our work highlights the potential of targeted LLM development for underrepresented languages and offers comprehensive design methodologies of instruction-tuning that can be applied to similar language adaptation challenges.
</p>
</div>
</section>
<section class="ltx_section" id="Sx1">
<h2 class="ltx_title ltx_title_section">Limitations</h2>
<div class="ltx_para" id="Sx1.p1">
<p class="ltx_p" id="Sx1.p1.1">Despite the promising results, our work has some limitations. First, the model occasionally generates hallucinations. Second, the dataset may contain inherent biases that could affect the model’s fairness and representation. Additionally, we relied heavily on Claude for translating English instructions into Darija. However, because Claude is primarily trained on English and reflects Western cultural values, it may not fully capture the unique nuances of Darija. Moreover, our models lack preference-tuning to better align with Darija speakers. We intend to address these limitations in future work.</p>
</div>
</section>
<section class="ltx_section" id="Sx2">
<h2 class="ltx_title ltx_title_section">Acknowledgments</h2>
<div class="ltx_para" id="Sx2.p1">
<p class="ltx_p" id="Sx2.p1.1">The authors would like to thank all the Moroccan Darija speakers who warmly contributed to this work from its inception, assisting with data annotation and selection, and evaluating the quality of model outputs in their language.
</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Abdelali et al. (2024)</span>
<span class="ltx_bibblock">
Ahmed Abdelali, Hamdy Mubarak, Shammur Chowdhury, Maram Hasanain, Basel Mousi, Sabri Boughorbel, Samir Abdaljalil, Yassine El Kheir, Daniel Izham, Fahim Dalvi, Majd Hawasly, Nizi Nazar, Youssef Elshahawy, Ahmed Ali, Nadir Durrani, Natasa Milic-Frayling, and Firoj Alam. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/2024.eacl-long.30" title="">LAraBench: Benchmarking Arabic AI with large language models</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">Proceedings of the 18th Conference of the European Chapter of the Association for Computational Linguistics (Volume 1: Long Papers)</em>, pages 487–520, St. Julian’s, Malta. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Abdelali et al. (2021)</span>
<span class="ltx_bibblock">
Ahmed Abdelali, Hamdy Mubarak, Younes Samih, Sabit Hassan, and Kareem Darwish. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/2021.wanlp-1.1" title="">QADI: Arabic dialect identification in the wild</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">Proceedings of the Sixth Arabic Natural Language Processing Workshop</em>, pages 1–10, Kyiv, Ukraine (Virtual). Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bandarkar et al. (2024)</span>
<span class="ltx_bibblock">
Lucas Bandarkar, Davis Liang, Benjamin Muller, Mikel Artetxe, Satya Narayan Shukla, Donald Husa, Naman Goyal, Abhinandan Krishnan, Luke Zettlemoyer, and Madian Khabsa. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/2024.acl-long.44" title="">The belebele benchmark: a parallel reading comprehension dataset in 122 language variants</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em>, pages 749–775, Bangkok, Thailand. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bari et al. (2024)</span>
<span class="ltx_bibblock">
M Saiful Bari, Yazeed Alnumay, Norah A Alzahrani, Nouf M Alotaibi, Hisham A Alyahya, Sultan AlRashed, Faisal A Mirza, Shaykhah Z Alsubaie, Hassan A Alahmed, Ghadah Alabduljabbar, et al. 2024.

</span>
<span class="ltx_bibblock">Allam: Large language models for arabic and english.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">arXiv preprint arXiv:2407.15390</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Biderman et al. (2024)</span>
<span class="ltx_bibblock">
Dan Biderman, Jose Gonzalez Ortiz, Jacob Portes, Mansheej Paul, Philip Greengard, Connor Jennings, Daniel King, Sam Havens, Vitaliy Chiley, Jonathan Frankle, et al. 2024.

</span>
<span class="ltx_bibblock">Lora learns less and forgets less.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">arXiv preprint arXiv:2405.09673</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bouamor et al. (2018)</span>
<span class="ltx_bibblock">
Houda Bouamor, Nizar Habash, Mohammad Salameh, Wajdi Zaghouani, Owen Rambow, Dana Abdulrahim, Ossama Obeid, Salam Khalifa, Fadhl Eryani, Alexander Erdmann, and Kemal Oflazer. 2018.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/L18-1535" title="">The MADAR Arabic dialect corpus and lexicon</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC 2018)</em>, Miyazaki, Japan. European Language Resources Association (ELRA).

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Boujou et al. (2021)</span>
<span class="ltx_bibblock">
ElMehdi Boujou, Hamza Chataoui, Abdellah El Mekki, Saad Benjelloun, Ikram Chairi, and Ismail Berrada. 2021.

</span>
<span class="ltx_bibblock">An open access nlp dataset for arabic dialects: Data collection, labeling, and model construction.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">arXiv preprint arXiv:2102.11000</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. (2023)</span>
<span class="ltx_bibblock">
Lin Chen, Jisong Li, Xiaoyi Dong, Pan Zhang, Conghui He, Jiaqi Wang, Feng Zhao, and Dahua Lin. 2023.

</span>
<span class="ltx_bibblock">Sharegpt4v: Improving large multi-modal models with better captions.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">arXiv preprint arXiv:2311.12793</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Costa-jussà et al. (2022)</span>
<span class="ltx_bibblock">
Marta R Costa-jussà, James Cross, Onur Çelebi, Maha Elbayad, Kenneth Heafield, Kevin Heffernan, Elahe Kalbassi, Janice Lam, Daniel Licht, Jean Maillard, et al. 2022.

</span>
<span class="ltx_bibblock">No language left behind: Scaling human-centered machine translation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">arXiv preprint arXiv:2207.04672</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dubey et al. (2024)</span>
<span class="ltx_bibblock">
Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian, Ahmad Al-Dahle, Aiesha Letman, Akhil Mathur, Alan Schelten, Amy Yang, Angela Fan, et al. 2024.

</span>
<span class="ltx_bibblock">The llama 3 herd of models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">arXiv preprint arXiv:2407.21783</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Elouardighi et al. (2017)</span>
<span class="ltx_bibblock">
Abdeljalil Elouardighi, Mohcine Maghfour, and Hafdalla Hammia. 2017.

</span>
<span class="ltx_bibblock">Collecting and processing arabic facebook comments for sentiment analysis.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">Model and Data Engineering: 7th International Conference, MEDI 2017, Barcelona, Spain, October 4–6, 2017, Proceedings 7</em>, pages 262–274. Springer.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Essefar et al. (2023)</span>
<span class="ltx_bibblock">
Kabil Essefar, Hassan Ait Baha, Abdelkader El Mahdaouy, Abdellah El Mekki, and Ismail Berrada. 2023.

</span>
<span class="ltx_bibblock">Omcd: Offensive moroccan comments dataset.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">Language Resources and Evaluation</em>, 57(4):1745–1765.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fabbri et al. (2021)</span>
<span class="ltx_bibblock">
Alexander R. Fabbri, Wojciech Kryściński, Bryan McCann, Caiming Xiong, Richard Socher, and Dragomir Radev. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1162/tacl_a_00373" title="">SummEval: Re-evaluating summarization evaluation</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">Transactions of the Association for Computational Linguistics</em>, 9:391–409.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">French (1999)</span>
<span class="ltx_bibblock">
Robert M French. 1999.

</span>
<span class="ltx_bibblock">Catastrophic forgetting in connectionist networks.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">Trends in cognitive sciences</em>, 3(4):128–135.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gaanoun et al. (2022)</span>
<span class="ltx_bibblock">
Kamel Gaanoun, Abdou Mohamed Naira, Anass Allak, and Imade Benelallam. 2022.

</span>
<span class="ltx_bibblock">Automatic text summarization for moroccan arabic dialect using an artificial intelligence approach.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">International Conference on Business Intelligence</em>, pages 158–177. Springer.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gaanoun et al. (2024)</span>
<span class="ltx_bibblock">
Kamel Gaanoun, Abdou Mohamed Naira, Anass Allak, and Imade Benelallam. 2024.

</span>
<span class="ltx_bibblock">Darijabert: a step forward in nlp for the written moroccan dialect.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">International Journal of Data Science and Analytics</em>, pages 1–13.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gao et al. (2024)</span>
<span class="ltx_bibblock">
Leo Gao, Jonathan Tow, Baber Abbasi, Stella Biderman, Sid Black, Anthony DiPofi, Charles Foster, Laurence Golding, Jeffrey Hsu, Alain Le Noac’h, Haonan Li, Kyle McDonell, Niklas Muennighoff, Chris Ociepa, Jason Phang, Laria Reynolds, Hailey Schoelkopf, Aviya Skowron, Lintang Sutawika, Eric Tang, Anish Thite, Ben Wang, Kevin Wang, and Andy Zou. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.5281/zenodo.12608602" title="">A framework for few-shot language model evaluation</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Garouani and Kharroubi (2021)</span>
<span class="ltx_bibblock">
Moncef Garouani and Jamal Kharroubi. 2021.

</span>
<span class="ltx_bibblock">Mac: an open and free moroccan arabic corpus for sentiment analysis.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">The Proceedings of the International Conference on Smart City Applications</em>, pages 849–858. Springer.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gunasekar et al. (2023)</span>
<span class="ltx_bibblock">
Suriya Gunasekar, Yi Zhang, Jyoti Aneja, Caio César Teodoro Mendes, Allie Del Giorno, Sivakanth Gopi, Mojan Javaheripi, Piero Kauffmann, Gustavo de Rosa, Olli Saarikivi, et al. 2023.

</span>
<span class="ltx_bibblock">Textbooks are all you need.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">arXiv preprint arXiv:2306.11644</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Guo et al. (2024)</span>
<span class="ltx_bibblock">
Yanzhu Guo, Guokan Shang, Michalis Vazirgiannis, and Chloé Clavel. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2024.findings-naacl.228" title="">The curious decline of linguistic diversity: Training language models on synthetic text</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">Findings of the Association for Computational Linguistics: NAACL 2024</em>, pages 3589–3604, Mexico City, Mexico. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Han et al. (2024)</span>
<span class="ltx_bibblock">
Zeyu Han, Chao Gao, Jinyang Liu, Sai Qian Zhang, et al. 2024.

</span>
<span class="ltx_bibblock">Parameter-efficient fine-tuning for large models: A comprehensive survey.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">arXiv preprint arXiv:2403.14608</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hendrycks et al. (2020)</span>
<span class="ltx_bibblock">
Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, and Jacob Steinhardt. 2020.

</span>
<span class="ltx_bibblock">Measuring massive multitask language understanding.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">arXiv preprint arXiv:2009.03300</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hu et al. (2021)</span>
<span class="ltx_bibblock">
Edward J Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu Chen. 2021.

</span>
<span class="ltx_bibblock">Lora: Low-rank adaptation of large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">arXiv preprint arXiv:2106.09685</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang et al. (2024)</span>
<span class="ltx_bibblock">
Huang Huang, Fei Yu, Jianqing Zhu, Xuening Sun, Hao Cheng, Song Dingjie, Zhihong Chen, Mosen Alharthi, Bang An, Juncai He, Ziche Liu, Junying Chen, Jianquan Li, Benyou Wang, Lian Zhang, Ruoyu Sun, Xiang Wan, Haizhou Li, and Jinchao Xu. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2024.naacl-long.450" title="">AceGPT, localizing large language models in Arabic</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)</em>, pages 8139–8163, Mexico City, Mexico. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hunter et al. (2023)</span>
<span class="ltx_bibblock">
Julie Hunter, Jérôme Louradour, Virgile Rennard, Ismaïl Harrando, Guokan Shang, and Jean-Pierre Lorré. 2023.

</span>
<span class="ltx_bibblock">The claire french dialogue dataset.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib25.1.1">arXiv preprint arXiv:2311.16840</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ivison et al. (2023)</span>
<span class="ltx_bibblock">
Hamish Ivison, Yizhong Wang, Valentina Pyatkin, Nathan Lambert, Matthew Peters, Pradeep Dasigi, Joel Jang, David Wadden, Noah A Smith, Iz Beltagy, et al. 2023.

</span>
<span class="ltx_bibblock">Camels in a changing climate: Enhancing lm adaptation with tulu 2.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib26.1.1">arXiv preprint arXiv:2311.10702</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jbel et al. (2024)</span>
<span class="ltx_bibblock">
Mouad Jbel, Mourad Jabrane, Imad Hafidi, and Abdulmutallib Metrane. 2024.

</span>
<span class="ltx_bibblock">Sentiment analysis dataset in moroccan dialect: bridging the gap between arabic and latin scripted dialect.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">Language Resources and Evaluation</em>, pages 1–30.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jiang et al. (2023)</span>
<span class="ltx_bibblock">
Albert Q Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford, Devendra Singh Chaplot, Diego de las Casas, Florian Bressand, Gianna Lengyel, Guillaume Lample, Lucile Saulnier, et al. 2023.

</span>
<span class="ltx_bibblock">Mistral 7b.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib28.1.1">arXiv preprint arXiv:2310.06825</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kmainasi et al. (2024)</span>
<span class="ltx_bibblock">
Mohamed Bayan Kmainasi, Rakif Khan, Ali Ezzat Shahroor, Boushra Bendou, Maram Hasanain, and Firoj Alam. 2024.

</span>
<span class="ltx_bibblock">Native vs non-native language prompting: A comparative analysis.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib29.1.1">arXiv preprint arXiv:2409.07054</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Köpf et al. (2024)</span>
<span class="ltx_bibblock">
Andreas Köpf, Yannic Kilcher, Dimitri von Rütte, Sotiris Anagnostidis, Zhi Rui Tam, Keith Stevens, Abdullah Barhoum, Duc Nguyen, Oliver Stanley, Richárd Nagyfi, et al. 2024.

</span>
<span class="ltx_bibblock">Openassistant conversations-democratizing large language model alignment.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib30.1.1">Advances in Neural Information Processing Systems</em>, 36.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Koto et al. (2024)</span>
<span class="ltx_bibblock">
Fajri Koto, Haonan Li, Sara Shatnawi, Jad Doughman, Abdelrahman Sadallah, Aisha Alraeesi, Khalid Almubarak, Zaid Alyafeai, Neha Sengupta, Shady Shehata, Nizar Habash, Preslav Nakov, and Timothy Baldwin. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/2024.findings-acl.334" title="">ArabicMMLU: Assessing massive multitask language understanding in Arabic</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib31.1.1">Findings of the Association for Computational Linguistics ACL 2024</em>, pages 5622–5640, Bangkok, Thailand and virtual meeting. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lee et al. (2023)</span>
<span class="ltx_bibblock">
Harrison Lee, Samrat Phatale, Hassan Mansoor, Thomas Mesnard, Johan Ferret, Kellie Lu, Colton Bishop, Ethan Hall, Victor Carbune, Abhinav Rastogi, et al. 2023.

</span>
<span class="ltx_bibblock">Rlaif: Scaling reinforcement learning from human feedback with ai feedback.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib32.1.1">arXiv preprint arXiv:2309.00267</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin (2004)</span>
<span class="ltx_bibblock">
Chin-Yew Lin. 2004.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/W04-1013" title="">ROUGE: A package for automatic evaluation of summaries</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib33.1.1">Text Summarization Branches Out</em>, pages 74–81, Barcelona, Spain. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Louradour et al. (2024)</span>
<span class="ltx_bibblock">
Jérôme Louradour, Julie Hunter, Ismaïl Harrando, Guokan Shang, Virgile Rennard, and Jean-Pierre Lorré. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/2024.jeptalnrecital-taln.36" title="">Claire: Large language models for spontaneous French dialogue</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib34.1.1">Actes de la 31ème Conférence sur le Traitement Automatique des Langues Naturelles, volume 1 : articles longs et prises de position</em>, pages 530–548, Toulouse, France. ATALA and AFPC.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Maillard et al. (2023)</span>
<span class="ltx_bibblock">
Jean Maillard, Cynthia Gao, Elahe Kalbassi, Kaushik Ram Sadagopan, Vedanuj Goswami, Philipp Koehn, Angela Fan, and Francisco Guzman. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2023.acl-long.154" title="">Small data, big impact: Leveraging minimal data for effective machine translation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib35.1.1">Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em>, pages 2740–2756, Toronto, Canada. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mukherjee et al. (2023)</span>
<span class="ltx_bibblock">
Subhabrata Mukherjee, Arindam Mitra, Ganesh Jawahar, Sahaj Agarwal, Hamid Palangi, and Ahmed Awadallah. 2023.

</span>
<span class="ltx_bibblock">Orca: Progressive learning from complex explanation traces of gpt-4.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib36.1.1">arXiv preprint arXiv:2306.02707</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Oussous et al. (2020)</span>
<span class="ltx_bibblock">
Ahmed Oussous, Fatima-Zahra Benjelloun, Ayoub Ait Lahcen, and Samir Belfkih. 2020.

</span>
<span class="ltx_bibblock">Asa: A framework for arabic sentiment analysis.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib37.1.1">Journal of Information Science</em>, 46(4):544–559.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Oussous et al. (2018)</span>
<span class="ltx_bibblock">
Ahmed Oussous, Ayoub Ait Lahcen, and Samir Belfkih. 2018.

</span>
<span class="ltx_bibblock">Improving sentiment analysis of moroccan tweets using ensemble learning.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib38.1.1">Big Data, Cloud and Applications: Third International Conference, BDCA 2018, Kenitra, Morocco, April 4–5, 2018, Revised Selected Papers 3</em>, pages 91–104. Springer.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Outchakoucht and Es-Samaali (2021)</span>
<span class="ltx_bibblock">
Aissam Outchakoucht and Hamza Es-Samaali. 2021.

</span>
<span class="ltx_bibblock">Moroccan dialect-darija-open dataset.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib39.1.1">arXiv preprint arXiv:2103.09687</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Outchakoucht and Es-Samaali (2024)</span>
<span class="ltx_bibblock">
Aissam Outchakoucht and Hamza Es-Samaali. 2024.

</span>
<span class="ltx_bibblock">The evolution of darija open dataset: Introducing version 2.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib40.1.1">arXiv preprint arXiv:2405.13016</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Papineni et al. (2002)</span>
<span class="ltx_bibblock">
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. 2002.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.3115/1073083.1073135" title="">Bleu: a method for automatic evaluation of machine translation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib41.1.1">Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics</em>, pages 311–318, Philadelphia, Pennsylvania, USA. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Peng et al. (2023)</span>
<span class="ltx_bibblock">
Baolin Peng, Chunyuan Li, Pengcheng He, Michel Galley, and Jianfeng Gao. 2023.

</span>
<span class="ltx_bibblock">Instruction tuning with gpt-4.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib42.1.1">arXiv preprint arXiv:2304.03277</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Popović (2015)</span>
<span class="ltx_bibblock">
Maja Popović. 2015.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/W15-3049" title="">chrF: character n-gram F-score for automatic MT evaluation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib43.1.1">Proceedings of the Tenth Workshop on Statistical Machine Translation</em>, pages 392–395, Lisbon, Portugal. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sengupta et al. (2023)</span>
<span class="ltx_bibblock">
Neha Sengupta, Sunil Kumar Sahu, Bokang Jia, Satheesh Katipomu, Haonan Li, Fajri Koto, William Marshall, Gurpreet Gosal, Cynthia Liu, Zhiming Chen, et al. 2023.

</span>
<span class="ltx_bibblock">Jais and jais-chat: Arabic-centric foundation and instruction-tuned open generative large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib44.1.1">arXiv preprint arXiv:2308.16149</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Takezawa et al. (2007)</span>
<span class="ltx_bibblock">
Toshiyuki Takezawa, Genichiro Kikui, Masahide Mizushima, and Eiichiro Sumita. 2007.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/O07-5005" title="">Multilingual spoken language corpus development for communication research</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib45.1.1">International Journal of Computational Linguistics &amp; Chinese Language Processing, Volume 12, Number 3, September 2007: Special Issue on Invited Papers from ISCSLP 2006</em>, pages 303–324.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib46">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tao et al. (2024)</span>
<span class="ltx_bibblock">
Mingxu Tao, Chen Zhang, Quzhe Huang, Tianyao Ma, Songfang Huang, Dongyan Zhao, and Yansong Feng. 2024.

</span>
<span class="ltx_bibblock">Unlocking the potential of model merging for low-resource languages.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib46.1.1">arXiv preprint arXiv:2407.03994</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib47">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Team et al. (2024)</span>
<span class="ltx_bibblock">
Gemma Team, Morgane Riviere, Shreya Pathak, Pier Giuseppe Sessa, Cassidy Hardin, Surya Bhupatiraju, Léonard Hussenot, Thomas Mesnard, Bobak Shahriari, Alexandre Ramé, et al. 2024.

</span>
<span class="ltx_bibblock">Gemma 2: Improving open language models at a practical size.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib47.1.1">arXiv preprint arXiv:2408.00118</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib48">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tonja et al. (2024)</span>
<span class="ltx_bibblock">
Atnafu Lambebo Tonja, Bonaventure FP Dossou, Jessica Ojo, Jenalea Rajab, Fadel Thior, Eric Peter Wairagala, Aremu Anuoluwapo, Pelonomi Moiloa, Jade Abbott, Vukosi Marivate, et al. 2024.

</span>
<span class="ltx_bibblock">Inkubalm: A small language model for low-resource african languages.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib48.1.1">arXiv preprint arXiv:2408.17024</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib49">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Touvron et al. (2023)</span>
<span class="ltx_bibblock">
Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et al. 2023.

</span>
<span class="ltx_bibblock">Llama 2: Open foundation and fine-tuned chat models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib49.1.1">arXiv preprint arXiv:2307.09288</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib50">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Üstün et al. (2024)</span>
<span class="ltx_bibblock">
Ahmet Üstün, Viraat Aryabumi, Zheng Yong, Wei-Yin Ko, Daniel D’souza, Gbemileke Onilude, Neel Bhandari, Shivalika Singh, Hui-Lee Ooi, Amr Kayid, Freddie Vargus, Phil Blunsom, Shayne Longpre, Niklas Muennighoff, Marzieh Fadaee, Julia Kreutzer, and Sara Hooker. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/2024.acl-long.845" title="">Aya model: An instruction finetuned open-access multilingual language model</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib50.1.1">Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em>, pages 15894–15939, Bangkok, Thailand. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib51">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wei et al. (2021)</span>
<span class="ltx_bibblock">
Jason Wei, Maarten Bosma, Vincent Y Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du, Andrew M Dai, and Quoc V Le. 2021.

</span>
<span class="ltx_bibblock">Finetuned language models are zero-shot learners.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib51.1.1">arXiv preprint arXiv:2109.01652</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib52">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu et al. (2023)</span>
<span class="ltx_bibblock">
Can Xu, Qingfeng Sun, Kai Zheng, Xiubo Geng, Pu Zhao, Jiazhan Feng, Chongyang Tao, and Daxin Jiang. 2023.

</span>
<span class="ltx_bibblock">Wizardlm: Empowering large language models to follow complex instructions.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib52.1.1">arXiv preprint arXiv:2304.12244</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib53">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xue (2020)</span>
<span class="ltx_bibblock">
L Xue. 2020.

</span>
<span class="ltx_bibblock">mt5: A massively multilingual pre-trained text-to-text transformer.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib53.1.1">arXiv preprint arXiv:2010.11934</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib54">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zaidan and Callison-Burch (2014)</span>
<span class="ltx_bibblock">
Omar F. Zaidan and Chris Callison-Burch. 2014.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1162/COLI_a_00169" title="">Arabic dialect identification</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib54.1.1">Computational Linguistics</em>, 40(1):171–202.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib55">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zellers et al. (2019)</span>
<span class="ltx_bibblock">
Rowan Zellers, Ari Holtzman, Yonatan Bisk, Ali Farhadi, and Yejin Choi. 2019.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/P19-1472" title="">HellaSwag: Can a machine really finish your sentence?</a>
</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib55.1.1">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</em>, pages 4791–4800, Florence, Italy. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib56">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. (2019)</span>
<span class="ltx_bibblock">
Tianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q Weinberger, and Yoav Artzi. 2019.

</span>
<span class="ltx_bibblock">Bertscore: Evaluating text generation with bert.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib56.1.1">arXiv preprint arXiv:1904.09675</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib57">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao et al. (2024)</span>
<span class="ltx_bibblock">
Yiran Zhao, Wenxuan Zhang, Guizhen Chen, Kenji Kawaguchi, and Lidong Bing. 2024.

</span>
<span class="ltx_bibblock">How do large language models handle multilingualism?

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib57.1.1">arXiv preprint arXiv:2402.18815</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib58">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zheng et al. (2023)</span>
<span class="ltx_bibblock">
Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric Xing, et al. 2023.

</span>
<span class="ltx_bibblock">Judging llm-as-a-judge with mt-bench and chatbot arena.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib58.1.1">Advances in Neural Information Processing Systems</em>, 36:46595–46623.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib59">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou et al. (2024)</span>
<span class="ltx_bibblock">
Chunting Zhou, Pengfei Liu, Puxin Xu, Srinivasan Iyer, Jiao Sun, Yuning Mao, Xuezhe Ma, Avia Efrat, Ping Yu, Lili Yu, et al. 2024.

</span>
<span class="ltx_bibblock">Lima: Less is more for alignment.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib59.1.1">Advances in Neural Information Processing Systems</em>, 36.

</span>
</li>
</ul>
</section>
<section class="ltx_appendix" id="A1">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Instruction data templates</h2>
<div class="ltx_para" id="A1.p1">
<p class="ltx_p" id="A1.p1.1">In this section, we list the instruction templates used for constructing our Darija-SFT-Mixture dataset.</p>
</div>
<section class="ltx_subsection" id="A1.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.1 </span>Machine translation</h3>
<div class="ltx_logical-block" id="A1.SS1.3">
<div class="ltx_para" id="A1.SS1.3.p1">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="A1.SS1.2.2">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A1.SS1.2.2.2">
<td class="ltx_td ltx_align_justify ltx_border_tt" id="A1.SS1.2.2.2.2">
<span class="ltx_inline-block ltx_align_top" id="A1.SS1.2.2.2.2.2"><span class="ltx_ERROR undefined" id="A1.SS1.2.2.2.2.2.3">\setcode</span>
<span class="ltx_p" id="A1.SS1.2.2.2.2.2.2">utf8
<span class="ltx_text ltx_font_bold" id="A1.SS1.2.2.2.2.2.2.2">user</span>:  <math alttext="\backslash n" class="ltx_Math" display="inline" id="A1.SS1.1.1.1.1.1.1.m1.1"><semantics id="A1.SS1.1.1.1.1.1.1.m1.1a"><mrow id="A1.SS1.1.1.1.1.1.1.m1.1.1" xref="A1.SS1.1.1.1.1.1.1.m1.1.1.cmml"><mi id="A1.SS1.1.1.1.1.1.1.m1.1.1.2" xref="A1.SS1.1.1.1.1.1.1.m1.1.1.2.cmml"></mi><mo id="A1.SS1.1.1.1.1.1.1.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="A1.SS1.1.1.1.1.1.1.m1.1.1.1.cmml">\</mo><mi id="A1.SS1.1.1.1.1.1.1.m1.1.1.3" xref="A1.SS1.1.1.1.1.1.1.m1.1.1.3.cmml">n</mi></mrow><annotation-xml encoding="MathML-Content" id="A1.SS1.1.1.1.1.1.1.m1.1b"><apply id="A1.SS1.1.1.1.1.1.1.m1.1.1.cmml" xref="A1.SS1.1.1.1.1.1.1.m1.1.1"><ci id="A1.SS1.1.1.1.1.1.1.m1.1.1.1.cmml" xref="A1.SS1.1.1.1.1.1.1.m1.1.1.1">\</ci><csymbol cd="latexml" id="A1.SS1.1.1.1.1.1.1.m1.1.1.2.cmml" xref="A1.SS1.1.1.1.1.1.1.m1.1.1.2">absent</csymbol><ci id="A1.SS1.1.1.1.1.1.1.m1.1.1.3.cmml" xref="A1.SS1.1.1.1.1.1.1.m1.1.1.3">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.1.1.1.1.1.1.m1.1c">\backslash n</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.1.1.1.1.1.1.m1.1d">\ italic_n</annotation></semantics></math><span class="ltx_text ltx_font_italic" id="A1.SS1.2.2.2.2.2.2.1">[source language text]<math alttext="\backslash n" class="ltx_Math" display="inline" id="A1.SS1.2.2.2.2.2.2.1.m1.1"><semantics id="A1.SS1.2.2.2.2.2.2.1.m1.1a"><mrow id="A1.SS1.2.2.2.2.2.2.1.m1.1.1" xref="A1.SS1.2.2.2.2.2.2.1.m1.1.1.cmml"><mi id="A1.SS1.2.2.2.2.2.2.1.m1.1.1.2" xref="A1.SS1.2.2.2.2.2.2.1.m1.1.1.2.cmml"></mi><mo id="A1.SS1.2.2.2.2.2.2.1.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="A1.SS1.2.2.2.2.2.2.1.m1.1.1.1.cmml">\</mo><mi id="A1.SS1.2.2.2.2.2.2.1.m1.1.1.3" xref="A1.SS1.2.2.2.2.2.2.1.m1.1.1.3.cmml">n</mi></mrow><annotation-xml encoding="MathML-Content" id="A1.SS1.2.2.2.2.2.2.1.m1.1b"><apply id="A1.SS1.2.2.2.2.2.2.1.m1.1.1.cmml" xref="A1.SS1.2.2.2.2.2.2.1.m1.1.1"><ci id="A1.SS1.2.2.2.2.2.2.1.m1.1.1.1.cmml" xref="A1.SS1.2.2.2.2.2.2.1.m1.1.1.1">\</ci><csymbol cd="latexml" id="A1.SS1.2.2.2.2.2.2.1.m1.1.1.2.cmml" xref="A1.SS1.2.2.2.2.2.2.1.m1.1.1.2">absent</csymbol><ci id="A1.SS1.2.2.2.2.2.2.1.m1.1.1.3.cmml" xref="A1.SS1.2.2.2.2.2.2.1.m1.1.1.3">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.2.2.2.2.2.2.1.m1.1c">\backslash n</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.2.2.2.2.2.2.1.m1.1d">\ italic_n</annotation></semantics></math></span> :<span class="ltx_text ltx_font_italic" id="A1.SS1.2.2.2.2.2.2.3">[target language]<span class="ltx_ERROR undefined" id="A1.SS1.2.2.2.2.2.2.3.1">\setcode</span></span>utf8 <span class="ltx_ERROR undefined" id="A1.SS1.2.2.2.2.2.2.4">\&lt;</span>لل&gt; <span class="ltx_text ltx_font_italic" id="A1.SS1.2.2.2.2.2.2.5">[source language]</span> <span class="ltx_ERROR undefined" id="A1.SS1.2.2.2.2.2.2.6">\&lt;</span>ترجم من&gt;</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.SS1.2.2.3.1">
<td class="ltx_td ltx_align_justify ltx_border_bb" id="A1.SS1.2.2.3.1.1">
<span class="ltx_inline-block ltx_align_top" id="A1.SS1.2.2.3.1.1.1">
<span class="ltx_p" id="A1.SS1.2.2.3.1.1.1.1"><span class="ltx_text ltx_font_bold" id="A1.SS1.2.2.3.1.1.1.1.1">assistant:</span> <span class="ltx_text ltx_font_italic" id="A1.SS1.2.2.3.1.1.1.1.2">[target language text]</span></span>
</span>
</td>
</tr>
</tbody>
</table>
</div>
</div>
</section>
<section class="ltx_subsection" id="A1.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.2 </span>Transliteration</h3>
<div class="ltx_para" id="A1.SS2.2">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="A1.SS2.2.2">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A1.SS2.2.2.2">
<td class="ltx_td ltx_align_justify ltx_border_tt" id="A1.SS2.2.2.2.2">
<span class="ltx_inline-block ltx_align_top" id="A1.SS2.2.2.2.2.2"><span class="ltx_ERROR undefined" id="A1.SS2.2.2.2.2.2.3">\setcode</span>
<span class="ltx_p" id="A1.SS2.2.2.2.2.2.2">utf8
<span class="ltx_text ltx_font_bold" id="A1.SS2.2.2.2.2.2.2.2">user</span>:  <math alttext="\backslash n" class="ltx_Math" display="inline" id="A1.SS2.1.1.1.1.1.1.m1.1"><semantics id="A1.SS2.1.1.1.1.1.1.m1.1a"><mrow id="A1.SS2.1.1.1.1.1.1.m1.1.1" xref="A1.SS2.1.1.1.1.1.1.m1.1.1.cmml"><mi id="A1.SS2.1.1.1.1.1.1.m1.1.1.2" xref="A1.SS2.1.1.1.1.1.1.m1.1.1.2.cmml"></mi><mo id="A1.SS2.1.1.1.1.1.1.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="A1.SS2.1.1.1.1.1.1.m1.1.1.1.cmml">\</mo><mi id="A1.SS2.1.1.1.1.1.1.m1.1.1.3" xref="A1.SS2.1.1.1.1.1.1.m1.1.1.3.cmml">n</mi></mrow><annotation-xml encoding="MathML-Content" id="A1.SS2.1.1.1.1.1.1.m1.1b"><apply id="A1.SS2.1.1.1.1.1.1.m1.1.1.cmml" xref="A1.SS2.1.1.1.1.1.1.m1.1.1"><ci id="A1.SS2.1.1.1.1.1.1.m1.1.1.1.cmml" xref="A1.SS2.1.1.1.1.1.1.m1.1.1.1">\</ci><csymbol cd="latexml" id="A1.SS2.1.1.1.1.1.1.m1.1.1.2.cmml" xref="A1.SS2.1.1.1.1.1.1.m1.1.1.2">absent</csymbol><ci id="A1.SS2.1.1.1.1.1.1.m1.1.1.3.cmml" xref="A1.SS2.1.1.1.1.1.1.m1.1.1.3">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.1.1.1.1.1.1.m1.1c">\backslash n</annotation><annotation encoding="application/x-llamapun" id="A1.SS2.1.1.1.1.1.1.m1.1d">\ italic_n</annotation></semantics></math><span class="ltx_text ltx_font_italic" id="A1.SS2.2.2.2.2.2.2.1">[source language text]<math alttext="\backslash n" class="ltx_Math" display="inline" id="A1.SS2.2.2.2.2.2.2.1.m1.1"><semantics id="A1.SS2.2.2.2.2.2.2.1.m1.1a"><mrow id="A1.SS2.2.2.2.2.2.2.1.m1.1.1" xref="A1.SS2.2.2.2.2.2.2.1.m1.1.1.cmml"><mi id="A1.SS2.2.2.2.2.2.2.1.m1.1.1.2" xref="A1.SS2.2.2.2.2.2.2.1.m1.1.1.2.cmml"></mi><mo id="A1.SS2.2.2.2.2.2.2.1.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="A1.SS2.2.2.2.2.2.2.1.m1.1.1.1.cmml">\</mo><mi id="A1.SS2.2.2.2.2.2.2.1.m1.1.1.3" xref="A1.SS2.2.2.2.2.2.2.1.m1.1.1.3.cmml">n</mi></mrow><annotation-xml encoding="MathML-Content" id="A1.SS2.2.2.2.2.2.2.1.m1.1b"><apply id="A1.SS2.2.2.2.2.2.2.1.m1.1.1.cmml" xref="A1.SS2.2.2.2.2.2.2.1.m1.1.1"><ci id="A1.SS2.2.2.2.2.2.2.1.m1.1.1.1.cmml" xref="A1.SS2.2.2.2.2.2.2.1.m1.1.1.1">\</ci><csymbol cd="latexml" id="A1.SS2.2.2.2.2.2.2.1.m1.1.1.2.cmml" xref="A1.SS2.2.2.2.2.2.2.1.m1.1.1.2">absent</csymbol><ci id="A1.SS2.2.2.2.2.2.2.1.m1.1.1.3.cmml" xref="A1.SS2.2.2.2.2.2.2.1.m1.1.1.3">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.2.2.2.2.2.2.1.m1.1c">\backslash n</annotation><annotation encoding="application/x-llamapun" id="A1.SS2.2.2.2.2.2.2.1.m1.1d">\ italic_n</annotation></semantics></math></span>:[<span class="ltx_text ltx_font_italic" id="A1.SS2.2.2.2.2.2.2.3">source language</span>] <span class="ltx_ERROR undefined" id="A1.SS2.2.2.2.2.2.2.4">\&lt;</span>كتب هادشي بالحروف ديال&gt;</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.SS2.2.2.3.1">
<td class="ltx_td ltx_align_justify ltx_border_bb" id="A1.SS2.2.2.3.1.1">
<span class="ltx_inline-block ltx_align_top" id="A1.SS2.2.2.3.1.1.1">
<span class="ltx_p" id="A1.SS2.2.2.3.1.1.1.1"><span class="ltx_text ltx_font_bold" id="A1.SS2.2.2.3.1.1.1.1.1">assistant:</span> <span class="ltx_text ltx_font_italic" id="A1.SS2.2.2.3.1.1.1.1.2">[target language text]</span></span>
</span>
</td>
</tr>
</tbody>
</table>
</div>
</section>
<section class="ltx_subsection" id="A1.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.3 </span>Sentiment analysis</h3>
<div class="ltx_logical-block" id="A1.SS3.6">
<div class="ltx_para" id="A1.SS3.6.p1">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="A1.SS3.5.5">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A1.SS3.1.1.1">
<td class="ltx_td ltx_align_justify ltx_border_tt" id="A1.SS3.1.1.1.1">
<span class="ltx_inline-block ltx_align_top" id="A1.SS3.1.1.1.1.1"><span class="ltx_ERROR undefined" id="A1.SS3.1.1.1.1.1.2">\setcode</span>
<span class="ltx_p" id="A1.SS3.1.1.1.1.1.1">utf8
<span class="ltx_text ltx_font_bold" id="A1.SS3.1.1.1.1.1.1.1">user</span>: <math alttext="\backslash n" class="ltx_Math" display="inline" id="A1.SS3.1.1.1.1.1.1.m1.1"><semantics id="A1.SS3.1.1.1.1.1.1.m1.1a"><mrow id="A1.SS3.1.1.1.1.1.1.m1.1.1" xref="A1.SS3.1.1.1.1.1.1.m1.1.1.cmml"><mi id="A1.SS3.1.1.1.1.1.1.m1.1.1.2" xref="A1.SS3.1.1.1.1.1.1.m1.1.1.2.cmml"></mi><mo id="A1.SS3.1.1.1.1.1.1.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="A1.SS3.1.1.1.1.1.1.m1.1.1.1.cmml">\</mo><mi id="A1.SS3.1.1.1.1.1.1.m1.1.1.3" xref="A1.SS3.1.1.1.1.1.1.m1.1.1.3.cmml">n</mi></mrow><annotation-xml encoding="MathML-Content" id="A1.SS3.1.1.1.1.1.1.m1.1b"><apply id="A1.SS3.1.1.1.1.1.1.m1.1.1.cmml" xref="A1.SS3.1.1.1.1.1.1.m1.1.1"><ci id="A1.SS3.1.1.1.1.1.1.m1.1.1.1.cmml" xref="A1.SS3.1.1.1.1.1.1.m1.1.1.1">\</ci><csymbol cd="latexml" id="A1.SS3.1.1.1.1.1.1.m1.1.1.2.cmml" xref="A1.SS3.1.1.1.1.1.1.m1.1.1.2">absent</csymbol><ci id="A1.SS3.1.1.1.1.1.1.m1.1.1.3.cmml" xref="A1.SS3.1.1.1.1.1.1.m1.1.1.3">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS3.1.1.1.1.1.1.m1.1c">\backslash n</annotation><annotation encoding="application/x-llamapun" id="A1.SS3.1.1.1.1.1.1.m1.1d">\ italic_n</annotation></semantics></math><span class="ltx_ERROR undefined" id="A1.SS3.1.1.1.1.1.1.2">\&lt;</span>شنو هو الإحساس ديال هاد الجملة؟&gt;</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.SS3.2.2.2">
<td class="ltx_td ltx_align_justify" id="A1.SS3.2.2.2.1">
<span class="ltx_inline-block ltx_align_top" id="A1.SS3.2.2.2.1.1">
<span class="ltx_p" id="A1.SS3.2.2.2.1.1.1"><math alttext="\backslash n" class="ltx_Math" display="inline" id="A1.SS3.2.2.2.1.1.1.m1.1"><semantics id="A1.SS3.2.2.2.1.1.1.m1.1a"><mrow id="A1.SS3.2.2.2.1.1.1.m1.1.1" xref="A1.SS3.2.2.2.1.1.1.m1.1.1.cmml"><mi id="A1.SS3.2.2.2.1.1.1.m1.1.1.2" xref="A1.SS3.2.2.2.1.1.1.m1.1.1.2.cmml"></mi><mo id="A1.SS3.2.2.2.1.1.1.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="A1.SS3.2.2.2.1.1.1.m1.1.1.1.cmml">\</mo><mi id="A1.SS3.2.2.2.1.1.1.m1.1.1.3" xref="A1.SS3.2.2.2.1.1.1.m1.1.1.3.cmml">n</mi></mrow><annotation-xml encoding="MathML-Content" id="A1.SS3.2.2.2.1.1.1.m1.1b"><apply id="A1.SS3.2.2.2.1.1.1.m1.1.1.cmml" xref="A1.SS3.2.2.2.1.1.1.m1.1.1"><ci id="A1.SS3.2.2.2.1.1.1.m1.1.1.1.cmml" xref="A1.SS3.2.2.2.1.1.1.m1.1.1.1">\</ci><csymbol cd="latexml" id="A1.SS3.2.2.2.1.1.1.m1.1.1.2.cmml" xref="A1.SS3.2.2.2.1.1.1.m1.1.1.2">absent</csymbol><ci id="A1.SS3.2.2.2.1.1.1.m1.1.1.3.cmml" xref="A1.SS3.2.2.2.1.1.1.m1.1.1.3">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS3.2.2.2.1.1.1.m1.1c">\backslash n</annotation><annotation encoding="application/x-llamapun" id="A1.SS3.2.2.2.1.1.1.m1.1d">\ italic_n</annotation></semantics></math><span class="ltx_text ltx_font_italic" id="A1.SS3.2.2.2.1.1.1.1">[source text]</span>:<span class="ltx_ERROR undefined" id="A1.SS3.2.2.2.1.1.1.2">\&lt;</span>العبارة&gt;</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.SS3.3.3.3">
<td class="ltx_td ltx_align_justify" id="A1.SS3.3.3.3.1">
<span class="ltx_inline-block ltx_align_top" id="A1.SS3.3.3.3.1.1"><span class="ltx_ERROR undefined" id="A1.SS3.3.3.3.1.1.2">\setcode</span>
<span class="ltx_p" id="A1.SS3.3.3.3.1.1.1">utf8 <math alttext="\backslash n" class="ltx_Math" display="inline" id="A1.SS3.3.3.3.1.1.1.m1.1"><semantics id="A1.SS3.3.3.3.1.1.1.m1.1a"><mrow id="A1.SS3.3.3.3.1.1.1.m1.1.1" xref="A1.SS3.3.3.3.1.1.1.m1.1.1.cmml"><mi id="A1.SS3.3.3.3.1.1.1.m1.1.1.2" xref="A1.SS3.3.3.3.1.1.1.m1.1.1.2.cmml"></mi><mo id="A1.SS3.3.3.3.1.1.1.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="A1.SS3.3.3.3.1.1.1.m1.1.1.1.cmml">\</mo><mi id="A1.SS3.3.3.3.1.1.1.m1.1.1.3" xref="A1.SS3.3.3.3.1.1.1.m1.1.1.3.cmml">n</mi></mrow><annotation-xml encoding="MathML-Content" id="A1.SS3.3.3.3.1.1.1.m1.1b"><apply id="A1.SS3.3.3.3.1.1.1.m1.1.1.cmml" xref="A1.SS3.3.3.3.1.1.1.m1.1.1"><ci id="A1.SS3.3.3.3.1.1.1.m1.1.1.1.cmml" xref="A1.SS3.3.3.3.1.1.1.m1.1.1.1">\</ci><csymbol cd="latexml" id="A1.SS3.3.3.3.1.1.1.m1.1.1.2.cmml" xref="A1.SS3.3.3.3.1.1.1.m1.1.1.2">absent</csymbol><ci id="A1.SS3.3.3.3.1.1.1.m1.1.1.3.cmml" xref="A1.SS3.3.3.3.1.1.1.m1.1.1.3">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS3.3.3.3.1.1.1.m1.1c">\backslash n</annotation><annotation encoding="application/x-llamapun" id="A1.SS3.3.3.3.1.1.1.m1.1d">\ italic_n</annotation></semantics></math>:<span class="ltx_ERROR undefined" id="A1.SS3.3.3.3.1.1.1.1">\&lt;</span>الإحتمالات&gt;</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.SS3.4.4.4">
<td class="ltx_td ltx_align_justify" id="A1.SS3.4.4.4.1">
<span class="ltx_inline-block ltx_align_top" id="A1.SS3.4.4.4.1.1"><span class="ltx_ERROR undefined" id="A1.SS3.4.4.4.1.1.2">\setcode</span>
<span class="ltx_p" id="A1.SS3.4.4.4.1.1.1">utf8 <math alttext="\backslash n" class="ltx_Math" display="inline" id="A1.SS3.4.4.4.1.1.1.m1.1"><semantics id="A1.SS3.4.4.4.1.1.1.m1.1a"><mrow id="A1.SS3.4.4.4.1.1.1.m1.1.1" xref="A1.SS3.4.4.4.1.1.1.m1.1.1.cmml"><mi id="A1.SS3.4.4.4.1.1.1.m1.1.1.2" xref="A1.SS3.4.4.4.1.1.1.m1.1.1.2.cmml"></mi><mo id="A1.SS3.4.4.4.1.1.1.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="A1.SS3.4.4.4.1.1.1.m1.1.1.1.cmml">\</mo><mi id="A1.SS3.4.4.4.1.1.1.m1.1.1.3" xref="A1.SS3.4.4.4.1.1.1.m1.1.1.3.cmml">n</mi></mrow><annotation-xml encoding="MathML-Content" id="A1.SS3.4.4.4.1.1.1.m1.1b"><apply id="A1.SS3.4.4.4.1.1.1.m1.1.1.cmml" xref="A1.SS3.4.4.4.1.1.1.m1.1.1"><ci id="A1.SS3.4.4.4.1.1.1.m1.1.1.1.cmml" xref="A1.SS3.4.4.4.1.1.1.m1.1.1.1">\</ci><csymbol cd="latexml" id="A1.SS3.4.4.4.1.1.1.m1.1.1.2.cmml" xref="A1.SS3.4.4.4.1.1.1.m1.1.1.2">absent</csymbol><ci id="A1.SS3.4.4.4.1.1.1.m1.1.1.3.cmml" xref="A1.SS3.4.4.4.1.1.1.m1.1.1.3">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS3.4.4.4.1.1.1.m1.1c">\backslash n</annotation><annotation encoding="application/x-llamapun" id="A1.SS3.4.4.4.1.1.1.m1.1d">\ italic_n</annotation></semantics></math><span class="ltx_ERROR undefined" id="A1.SS3.4.4.4.1.1.1.1">\&lt;</span>سلبي&gt;-</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.SS3.5.5.5">
<td class="ltx_td ltx_align_justify" id="A1.SS3.5.5.5.1">
<span class="ltx_inline-block ltx_align_top" id="A1.SS3.5.5.5.1.1"><span class="ltx_ERROR undefined" id="A1.SS3.5.5.5.1.1.2">\setcode</span>
<span class="ltx_p" id="A1.SS3.5.5.5.1.1.1">utf8 <math alttext="\backslash n" class="ltx_Math" display="inline" id="A1.SS3.5.5.5.1.1.1.m1.1"><semantics id="A1.SS3.5.5.5.1.1.1.m1.1a"><mrow id="A1.SS3.5.5.5.1.1.1.m1.1.1" xref="A1.SS3.5.5.5.1.1.1.m1.1.1.cmml"><mi id="A1.SS3.5.5.5.1.1.1.m1.1.1.2" xref="A1.SS3.5.5.5.1.1.1.m1.1.1.2.cmml"></mi><mo id="A1.SS3.5.5.5.1.1.1.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="A1.SS3.5.5.5.1.1.1.m1.1.1.1.cmml">\</mo><mi id="A1.SS3.5.5.5.1.1.1.m1.1.1.3" xref="A1.SS3.5.5.5.1.1.1.m1.1.1.3.cmml">n</mi></mrow><annotation-xml encoding="MathML-Content" id="A1.SS3.5.5.5.1.1.1.m1.1b"><apply id="A1.SS3.5.5.5.1.1.1.m1.1.1.cmml" xref="A1.SS3.5.5.5.1.1.1.m1.1.1"><ci id="A1.SS3.5.5.5.1.1.1.m1.1.1.1.cmml" xref="A1.SS3.5.5.5.1.1.1.m1.1.1.1">\</ci><csymbol cd="latexml" id="A1.SS3.5.5.5.1.1.1.m1.1.1.2.cmml" xref="A1.SS3.5.5.5.1.1.1.m1.1.1.2">absent</csymbol><ci id="A1.SS3.5.5.5.1.1.1.m1.1.1.3.cmml" xref="A1.SS3.5.5.5.1.1.1.m1.1.1.3">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS3.5.5.5.1.1.1.m1.1c">\backslash n</annotation><annotation encoding="application/x-llamapun" id="A1.SS3.5.5.5.1.1.1.m1.1d">\ italic_n</annotation></semantics></math><span class="ltx_ERROR undefined" id="A1.SS3.5.5.5.1.1.1.1">\&lt;</span>ايجابي&gt; -</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.SS3.5.5.6.1">
<td class="ltx_td ltx_align_justify ltx_border_bb" id="A1.SS3.5.5.6.1.1">
<span class="ltx_inline-block ltx_align_top" id="A1.SS3.5.5.6.1.1.1">
<span class="ltx_p" id="A1.SS3.5.5.6.1.1.1.1"><span class="ltx_text ltx_font_bold" id="A1.SS3.5.5.6.1.1.1.1.1">assistant:</span> <span class="ltx_text ltx_font_italic" id="A1.SS3.5.5.6.1.1.1.1.2">[target]</span></span>
</span>
</td>
</tr>
</tbody>
</table>
</div>
</div>
</section>
<section class="ltx_subsection" id="A1.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.4 </span>Automatic summarization</h3>
<div class="ltx_para" id="A1.SS4.2">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="A1.SS4.2.2">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A1.SS4.1.1.1">
<td class="ltx_td ltx_align_justify ltx_border_tt" id="A1.SS4.1.1.1.1">
<span class="ltx_inline-block ltx_align_top" id="A1.SS4.1.1.1.1.1"><span class="ltx_ERROR undefined" id="A1.SS4.1.1.1.1.1.2">\setcode</span>
<span class="ltx_p" id="A1.SS4.1.1.1.1.1.1">utf8
<span class="ltx_text ltx_font_bold" id="A1.SS4.1.1.1.1.1.1.1">user</span>:  <math alttext="\backslash n" class="ltx_Math" display="inline" id="A1.SS4.1.1.1.1.1.1.m1.1"><semantics id="A1.SS4.1.1.1.1.1.1.m1.1a"><mrow id="A1.SS4.1.1.1.1.1.1.m1.1.1" xref="A1.SS4.1.1.1.1.1.1.m1.1.1.cmml"><mi id="A1.SS4.1.1.1.1.1.1.m1.1.1.2" xref="A1.SS4.1.1.1.1.1.1.m1.1.1.2.cmml"></mi><mo id="A1.SS4.1.1.1.1.1.1.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="A1.SS4.1.1.1.1.1.1.m1.1.1.1.cmml">\</mo><mi id="A1.SS4.1.1.1.1.1.1.m1.1.1.3" xref="A1.SS4.1.1.1.1.1.1.m1.1.1.3.cmml">n</mi></mrow><annotation-xml encoding="MathML-Content" id="A1.SS4.1.1.1.1.1.1.m1.1b"><apply id="A1.SS4.1.1.1.1.1.1.m1.1.1.cmml" xref="A1.SS4.1.1.1.1.1.1.m1.1.1"><ci id="A1.SS4.1.1.1.1.1.1.m1.1.1.1.cmml" xref="A1.SS4.1.1.1.1.1.1.m1.1.1.1">\</ci><csymbol cd="latexml" id="A1.SS4.1.1.1.1.1.1.m1.1.1.2.cmml" xref="A1.SS4.1.1.1.1.1.1.m1.1.1.2">absent</csymbol><ci id="A1.SS4.1.1.1.1.1.1.m1.1.1.3.cmml" xref="A1.SS4.1.1.1.1.1.1.m1.1.1.3">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS4.1.1.1.1.1.1.m1.1c">\backslash n</annotation><annotation encoding="application/x-llamapun" id="A1.SS4.1.1.1.1.1.1.m1.1d">\ italic_n</annotation></semantics></math>:<span class="ltx_ERROR undefined" id="A1.SS4.1.1.1.1.1.1.2">\&lt;</span>لخص هاد المقطع&gt;</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.SS4.2.2.2">
<td class="ltx_td ltx_align_justify" id="A1.SS4.2.2.2.1">
<span class="ltx_inline-block ltx_align_top" id="A1.SS4.2.2.2.1.1">
<span class="ltx_p" id="A1.SS4.2.2.2.1.1.1"><math alttext="\backslash n" class="ltx_Math" display="inline" id="A1.SS4.2.2.2.1.1.1.m1.1"><semantics id="A1.SS4.2.2.2.1.1.1.m1.1a"><mrow id="A1.SS4.2.2.2.1.1.1.m1.1.1" xref="A1.SS4.2.2.2.1.1.1.m1.1.1.cmml"><mi id="A1.SS4.2.2.2.1.1.1.m1.1.1.2" xref="A1.SS4.2.2.2.1.1.1.m1.1.1.2.cmml"></mi><mo id="A1.SS4.2.2.2.1.1.1.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="A1.SS4.2.2.2.1.1.1.m1.1.1.1.cmml">\</mo><mi id="A1.SS4.2.2.2.1.1.1.m1.1.1.3" xref="A1.SS4.2.2.2.1.1.1.m1.1.1.3.cmml">n</mi></mrow><annotation-xml encoding="MathML-Content" id="A1.SS4.2.2.2.1.1.1.m1.1b"><apply id="A1.SS4.2.2.2.1.1.1.m1.1.1.cmml" xref="A1.SS4.2.2.2.1.1.1.m1.1.1"><ci id="A1.SS4.2.2.2.1.1.1.m1.1.1.1.cmml" xref="A1.SS4.2.2.2.1.1.1.m1.1.1.1">\</ci><csymbol cd="latexml" id="A1.SS4.2.2.2.1.1.1.m1.1.1.2.cmml" xref="A1.SS4.2.2.2.1.1.1.m1.1.1.2">absent</csymbol><ci id="A1.SS4.2.2.2.1.1.1.m1.1.1.3.cmml" xref="A1.SS4.2.2.2.1.1.1.m1.1.1.3">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS4.2.2.2.1.1.1.m1.1c">\backslash n</annotation><annotation encoding="application/x-llamapun" id="A1.SS4.2.2.2.1.1.1.m1.1d">\ italic_n</annotation></semantics></math> <span class="ltx_text ltx_font_italic" id="A1.SS4.2.2.2.1.1.1.1">[passage]</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.SS4.2.2.3.1">
<td class="ltx_td ltx_align_justify ltx_border_bb" id="A1.SS4.2.2.3.1.1">
<span class="ltx_inline-block ltx_align_top" id="A1.SS4.2.2.3.1.1.1">
<span class="ltx_p" id="A1.SS4.2.2.3.1.1.1.1"><span class="ltx_text ltx_font_bold" id="A1.SS4.2.2.3.1.1.1.1.1">assistant:</span> <span class="ltx_text ltx_font_italic" id="A1.SS4.2.2.3.1.1.1.1.2">[summary]</span></span>
</span>
</td>
</tr>
</tbody>
</table>
</div>
</section>
<section class="ltx_subsection" id="A1.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.5 </span>MoroccanWikipedia-QA</h3>
<div class="ltx_para ltx_noindent" id="A1.SS5.p1">
<p class="ltx_p" id="A1.SS5.p1.11">Template 1:</p>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="A1.SS5.p1.3.3">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A1.SS5.p1.1.1.1">
<td class="ltx_td ltx_align_justify ltx_border_tt" id="A1.SS5.p1.1.1.1.1">
<span class="ltx_inline-block ltx_align_top" id="A1.SS5.p1.1.1.1.1.1"><span class="ltx_ERROR undefined" id="A1.SS5.p1.1.1.1.1.1.2">\setcode</span>
<span class="ltx_p" id="A1.SS5.p1.1.1.1.1.1.1">utf8
<span class="ltx_text ltx_font_bold" id="A1.SS5.p1.1.1.1.1.1.1.1">user</span>:  <math alttext="\backslash n\backslash n" class="ltx_Math" display="inline" id="A1.SS5.p1.1.1.1.1.1.1.m1.1"><semantics id="A1.SS5.p1.1.1.1.1.1.1.m1.1a"><mrow id="A1.SS5.p1.1.1.1.1.1.1.m1.1.1" xref="A1.SS5.p1.1.1.1.1.1.1.m1.1.1.cmml"><mi id="A1.SS5.p1.1.1.1.1.1.1.m1.1.1.2" xref="A1.SS5.p1.1.1.1.1.1.1.m1.1.1.2.cmml"></mi><mo id="A1.SS5.p1.1.1.1.1.1.1.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="A1.SS5.p1.1.1.1.1.1.1.m1.1.1.1.cmml">\</mo><mrow id="A1.SS5.p1.1.1.1.1.1.1.m1.1.1.3" xref="A1.SS5.p1.1.1.1.1.1.1.m1.1.1.3.cmml"><mi id="A1.SS5.p1.1.1.1.1.1.1.m1.1.1.3.2" xref="A1.SS5.p1.1.1.1.1.1.1.m1.1.1.3.2.cmml">n</mi><mo id="A1.SS5.p1.1.1.1.1.1.1.m1.1.1.3.1" lspace="0.222em" rspace="0.222em" xref="A1.SS5.p1.1.1.1.1.1.1.m1.1.1.3.1.cmml">\</mo><mi id="A1.SS5.p1.1.1.1.1.1.1.m1.1.1.3.3" xref="A1.SS5.p1.1.1.1.1.1.1.m1.1.1.3.3.cmml">n</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="A1.SS5.p1.1.1.1.1.1.1.m1.1b"><apply id="A1.SS5.p1.1.1.1.1.1.1.m1.1.1.cmml" xref="A1.SS5.p1.1.1.1.1.1.1.m1.1.1"><ci id="A1.SS5.p1.1.1.1.1.1.1.m1.1.1.1.cmml" xref="A1.SS5.p1.1.1.1.1.1.1.m1.1.1.1">\</ci><csymbol cd="latexml" id="A1.SS5.p1.1.1.1.1.1.1.m1.1.1.2.cmml" xref="A1.SS5.p1.1.1.1.1.1.1.m1.1.1.2">absent</csymbol><apply id="A1.SS5.p1.1.1.1.1.1.1.m1.1.1.3.cmml" xref="A1.SS5.p1.1.1.1.1.1.1.m1.1.1.3"><ci id="A1.SS5.p1.1.1.1.1.1.1.m1.1.1.3.1.cmml" xref="A1.SS5.p1.1.1.1.1.1.1.m1.1.1.3.1">\</ci><ci id="A1.SS5.p1.1.1.1.1.1.1.m1.1.1.3.2.cmml" xref="A1.SS5.p1.1.1.1.1.1.1.m1.1.1.3.2">𝑛</ci><ci id="A1.SS5.p1.1.1.1.1.1.1.m1.1.1.3.3.cmml" xref="A1.SS5.p1.1.1.1.1.1.1.m1.1.1.3.3">𝑛</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS5.p1.1.1.1.1.1.1.m1.1c">\backslash n\backslash n</annotation><annotation encoding="application/x-llamapun" id="A1.SS5.p1.1.1.1.1.1.1.m1.1d">\ italic_n \ italic_n</annotation></semantics></math>:<span class="ltx_ERROR undefined" id="A1.SS5.p1.1.1.1.1.1.1.2">\&lt;</span>قرا هاد النص وجاوب على السؤال&gt;</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.SS5.p1.2.2.2">
<td class="ltx_td ltx_align_justify" id="A1.SS5.p1.2.2.2.1">
<span class="ltx_inline-block ltx_align_top" id="A1.SS5.p1.2.2.2.1.1">
<span class="ltx_p" id="A1.SS5.p1.2.2.2.1.1.1"><math alttext="\backslash n\backslash n" class="ltx_Math" display="inline" id="A1.SS5.p1.2.2.2.1.1.1.m1.1"><semantics id="A1.SS5.p1.2.2.2.1.1.1.m1.1a"><mrow id="A1.SS5.p1.2.2.2.1.1.1.m1.1.1" xref="A1.SS5.p1.2.2.2.1.1.1.m1.1.1.cmml"><mi id="A1.SS5.p1.2.2.2.1.1.1.m1.1.1.2" xref="A1.SS5.p1.2.2.2.1.1.1.m1.1.1.2.cmml"></mi><mo id="A1.SS5.p1.2.2.2.1.1.1.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="A1.SS5.p1.2.2.2.1.1.1.m1.1.1.1.cmml">\</mo><mrow id="A1.SS5.p1.2.2.2.1.1.1.m1.1.1.3" xref="A1.SS5.p1.2.2.2.1.1.1.m1.1.1.3.cmml"><mi id="A1.SS5.p1.2.2.2.1.1.1.m1.1.1.3.2" xref="A1.SS5.p1.2.2.2.1.1.1.m1.1.1.3.2.cmml">n</mi><mo id="A1.SS5.p1.2.2.2.1.1.1.m1.1.1.3.1" lspace="0.222em" rspace="0.222em" xref="A1.SS5.p1.2.2.2.1.1.1.m1.1.1.3.1.cmml">\</mo><mi id="A1.SS5.p1.2.2.2.1.1.1.m1.1.1.3.3" xref="A1.SS5.p1.2.2.2.1.1.1.m1.1.1.3.3.cmml">n</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="A1.SS5.p1.2.2.2.1.1.1.m1.1b"><apply id="A1.SS5.p1.2.2.2.1.1.1.m1.1.1.cmml" xref="A1.SS5.p1.2.2.2.1.1.1.m1.1.1"><ci id="A1.SS5.p1.2.2.2.1.1.1.m1.1.1.1.cmml" xref="A1.SS5.p1.2.2.2.1.1.1.m1.1.1.1">\</ci><csymbol cd="latexml" id="A1.SS5.p1.2.2.2.1.1.1.m1.1.1.2.cmml" xref="A1.SS5.p1.2.2.2.1.1.1.m1.1.1.2">absent</csymbol><apply id="A1.SS5.p1.2.2.2.1.1.1.m1.1.1.3.cmml" xref="A1.SS5.p1.2.2.2.1.1.1.m1.1.1.3"><ci id="A1.SS5.p1.2.2.2.1.1.1.m1.1.1.3.1.cmml" xref="A1.SS5.p1.2.2.2.1.1.1.m1.1.1.3.1">\</ci><ci id="A1.SS5.p1.2.2.2.1.1.1.m1.1.1.3.2.cmml" xref="A1.SS5.p1.2.2.2.1.1.1.m1.1.1.3.2">𝑛</ci><ci id="A1.SS5.p1.2.2.2.1.1.1.m1.1.1.3.3.cmml" xref="A1.SS5.p1.2.2.2.1.1.1.m1.1.1.3.3">𝑛</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS5.p1.2.2.2.1.1.1.m1.1c">\backslash n\backslash n</annotation><annotation encoding="application/x-llamapun" id="A1.SS5.p1.2.2.2.1.1.1.m1.1d">\ italic_n \ italic_n</annotation></semantics></math> <span class="ltx_text ltx_font_italic" id="A1.SS5.p1.2.2.2.1.1.1.1">[passage]</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.SS5.p1.3.3.3">
<td class="ltx_td ltx_align_justify" id="A1.SS5.p1.3.3.3.1">
<span class="ltx_inline-block ltx_align_top" id="A1.SS5.p1.3.3.3.1.1">
<span class="ltx_p" id="A1.SS5.p1.3.3.3.1.1.1"><math alttext="\backslash n\backslash n" class="ltx_Math" display="inline" id="A1.SS5.p1.3.3.3.1.1.1.m1.1"><semantics id="A1.SS5.p1.3.3.3.1.1.1.m1.1a"><mrow id="A1.SS5.p1.3.3.3.1.1.1.m1.1.1" xref="A1.SS5.p1.3.3.3.1.1.1.m1.1.1.cmml"><mi id="A1.SS5.p1.3.3.3.1.1.1.m1.1.1.2" xref="A1.SS5.p1.3.3.3.1.1.1.m1.1.1.2.cmml"></mi><mo id="A1.SS5.p1.3.3.3.1.1.1.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="A1.SS5.p1.3.3.3.1.1.1.m1.1.1.1.cmml">\</mo><mrow id="A1.SS5.p1.3.3.3.1.1.1.m1.1.1.3" xref="A1.SS5.p1.3.3.3.1.1.1.m1.1.1.3.cmml"><mi id="A1.SS5.p1.3.3.3.1.1.1.m1.1.1.3.2" xref="A1.SS5.p1.3.3.3.1.1.1.m1.1.1.3.2.cmml">n</mi><mo id="A1.SS5.p1.3.3.3.1.1.1.m1.1.1.3.1" lspace="0.222em" rspace="0.222em" xref="A1.SS5.p1.3.3.3.1.1.1.m1.1.1.3.1.cmml">\</mo><mi id="A1.SS5.p1.3.3.3.1.1.1.m1.1.1.3.3" xref="A1.SS5.p1.3.3.3.1.1.1.m1.1.1.3.3.cmml">n</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="A1.SS5.p1.3.3.3.1.1.1.m1.1b"><apply id="A1.SS5.p1.3.3.3.1.1.1.m1.1.1.cmml" xref="A1.SS5.p1.3.3.3.1.1.1.m1.1.1"><ci id="A1.SS5.p1.3.3.3.1.1.1.m1.1.1.1.cmml" xref="A1.SS5.p1.3.3.3.1.1.1.m1.1.1.1">\</ci><csymbol cd="latexml" id="A1.SS5.p1.3.3.3.1.1.1.m1.1.1.2.cmml" xref="A1.SS5.p1.3.3.3.1.1.1.m1.1.1.2">absent</csymbol><apply id="A1.SS5.p1.3.3.3.1.1.1.m1.1.1.3.cmml" xref="A1.SS5.p1.3.3.3.1.1.1.m1.1.1.3"><ci id="A1.SS5.p1.3.3.3.1.1.1.m1.1.1.3.1.cmml" xref="A1.SS5.p1.3.3.3.1.1.1.m1.1.1.3.1">\</ci><ci id="A1.SS5.p1.3.3.3.1.1.1.m1.1.1.3.2.cmml" xref="A1.SS5.p1.3.3.3.1.1.1.m1.1.1.3.2">𝑛</ci><ci id="A1.SS5.p1.3.3.3.1.1.1.m1.1.1.3.3.cmml" xref="A1.SS5.p1.3.3.3.1.1.1.m1.1.1.3.3">𝑛</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS5.p1.3.3.3.1.1.1.m1.1c">\backslash n\backslash n</annotation><annotation encoding="application/x-llamapun" id="A1.SS5.p1.3.3.3.1.1.1.m1.1d">\ italic_n \ italic_n</annotation></semantics></math> <span class="ltx_text ltx_font_italic" id="A1.SS5.p1.3.3.3.1.1.1.1">[question]</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.SS5.p1.3.3.4.1">
<td class="ltx_td ltx_align_justify ltx_border_bb" id="A1.SS5.p1.3.3.4.1.1">
<span class="ltx_inline-block ltx_align_top" id="A1.SS5.p1.3.3.4.1.1.1">
<span class="ltx_p" id="A1.SS5.p1.3.3.4.1.1.1.1"><span class="ltx_text ltx_font_bold" id="A1.SS5.p1.3.3.4.1.1.1.1.1">assistant:</span> <span class="ltx_text ltx_font_italic" id="A1.SS5.p1.3.3.4.1.1.1.1.2">[answer]</span></span>
</span>
</td>
</tr>
</tbody>
</table>
<p class="ltx_p" id="A1.SS5.p1.12">Template 2:</p>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="A1.SS5.p1.7.4">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A1.SS5.p1.7.4.4">
<td class="ltx_td ltx_align_justify ltx_border_tt" id="A1.SS5.p1.7.4.4.4">
<span class="ltx_inline-block ltx_align_top" id="A1.SS5.p1.7.4.4.4.4">
<span class="ltx_p" id="A1.SS5.p1.7.4.4.4.4.4"><span class="ltx_text ltx_font_bold" id="A1.SS5.p1.7.4.4.4.4.4.2">user</span>:  <math alttext="\backslash n\backslash n" class="ltx_Math" display="inline" id="A1.SS5.p1.4.1.1.1.1.1.m1.1"><semantics id="A1.SS5.p1.4.1.1.1.1.1.m1.1a"><mrow id="A1.SS5.p1.4.1.1.1.1.1.m1.1.1" xref="A1.SS5.p1.4.1.1.1.1.1.m1.1.1.cmml"><mi id="A1.SS5.p1.4.1.1.1.1.1.m1.1.1.2" xref="A1.SS5.p1.4.1.1.1.1.1.m1.1.1.2.cmml"></mi><mo id="A1.SS5.p1.4.1.1.1.1.1.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="A1.SS5.p1.4.1.1.1.1.1.m1.1.1.1.cmml">\</mo><mrow id="A1.SS5.p1.4.1.1.1.1.1.m1.1.1.3" xref="A1.SS5.p1.4.1.1.1.1.1.m1.1.1.3.cmml"><mi id="A1.SS5.p1.4.1.1.1.1.1.m1.1.1.3.2" xref="A1.SS5.p1.4.1.1.1.1.1.m1.1.1.3.2.cmml">n</mi><mo id="A1.SS5.p1.4.1.1.1.1.1.m1.1.1.3.1" lspace="0.222em" rspace="0.222em" xref="A1.SS5.p1.4.1.1.1.1.1.m1.1.1.3.1.cmml">\</mo><mi id="A1.SS5.p1.4.1.1.1.1.1.m1.1.1.3.3" xref="A1.SS5.p1.4.1.1.1.1.1.m1.1.1.3.3.cmml">n</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="A1.SS5.p1.4.1.1.1.1.1.m1.1b"><apply id="A1.SS5.p1.4.1.1.1.1.1.m1.1.1.cmml" xref="A1.SS5.p1.4.1.1.1.1.1.m1.1.1"><ci id="A1.SS5.p1.4.1.1.1.1.1.m1.1.1.1.cmml" xref="A1.SS5.p1.4.1.1.1.1.1.m1.1.1.1">\</ci><csymbol cd="latexml" id="A1.SS5.p1.4.1.1.1.1.1.m1.1.1.2.cmml" xref="A1.SS5.p1.4.1.1.1.1.1.m1.1.1.2">absent</csymbol><apply id="A1.SS5.p1.4.1.1.1.1.1.m1.1.1.3.cmml" xref="A1.SS5.p1.4.1.1.1.1.1.m1.1.1.3"><ci id="A1.SS5.p1.4.1.1.1.1.1.m1.1.1.3.1.cmml" xref="A1.SS5.p1.4.1.1.1.1.1.m1.1.1.3.1">\</ci><ci id="A1.SS5.p1.4.1.1.1.1.1.m1.1.1.3.2.cmml" xref="A1.SS5.p1.4.1.1.1.1.1.m1.1.1.3.2">𝑛</ci><ci id="A1.SS5.p1.4.1.1.1.1.1.m1.1.1.3.3.cmml" xref="A1.SS5.p1.4.1.1.1.1.1.m1.1.1.3.3">𝑛</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS5.p1.4.1.1.1.1.1.m1.1c">\backslash n\backslash n</annotation><annotation encoding="application/x-llamapun" id="A1.SS5.p1.4.1.1.1.1.1.m1.1d">\ italic_n \ italic_n</annotation></semantics></math> <span class="ltx_text ltx_font_italic" id="A1.SS5.p1.5.2.2.2.2.2.1">[question]<math alttext="\backslash n" class="ltx_Math" display="inline" id="A1.SS5.p1.5.2.2.2.2.2.1.m1.1"><semantics id="A1.SS5.p1.5.2.2.2.2.2.1.m1.1a"><mrow id="A1.SS5.p1.5.2.2.2.2.2.1.m1.1.1" xref="A1.SS5.p1.5.2.2.2.2.2.1.m1.1.1.cmml"><mi id="A1.SS5.p1.5.2.2.2.2.2.1.m1.1.1.2" xref="A1.SS5.p1.5.2.2.2.2.2.1.m1.1.1.2.cmml"></mi><mo id="A1.SS5.p1.5.2.2.2.2.2.1.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="A1.SS5.p1.5.2.2.2.2.2.1.m1.1.1.1.cmml">\</mo><mi id="A1.SS5.p1.5.2.2.2.2.2.1.m1.1.1.3" xref="A1.SS5.p1.5.2.2.2.2.2.1.m1.1.1.3.cmml">n</mi></mrow><annotation-xml encoding="MathML-Content" id="A1.SS5.p1.5.2.2.2.2.2.1.m1.1b"><apply id="A1.SS5.p1.5.2.2.2.2.2.1.m1.1.1.cmml" xref="A1.SS5.p1.5.2.2.2.2.2.1.m1.1.1"><ci id="A1.SS5.p1.5.2.2.2.2.2.1.m1.1.1.1.cmml" xref="A1.SS5.p1.5.2.2.2.2.2.1.m1.1.1.1">\</ci><csymbol cd="latexml" id="A1.SS5.p1.5.2.2.2.2.2.1.m1.1.1.2.cmml" xref="A1.SS5.p1.5.2.2.2.2.2.1.m1.1.1.2">absent</csymbol><ci id="A1.SS5.p1.5.2.2.2.2.2.1.m1.1.1.3.cmml" xref="A1.SS5.p1.5.2.2.2.2.2.1.m1.1.1.3">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS5.p1.5.2.2.2.2.2.1.m1.1c">\backslash n</annotation><annotation encoding="application/x-llamapun" id="A1.SS5.p1.5.2.2.2.2.2.1.m1.1d">\ italic_n</annotation></semantics></math></span> :<span class="ltx_ERROR undefined" id="A1.SS5.p1.7.4.4.4.4.4.3">\&lt;</span>ودابا جاوب على هاد السؤال&gt; <math alttext="\backslash n\backslash n" class="ltx_Math" display="inline" id="A1.SS5.p1.6.3.3.3.3.3.m2.1"><semantics id="A1.SS5.p1.6.3.3.3.3.3.m2.1a"><mrow id="A1.SS5.p1.6.3.3.3.3.3.m2.1.1" xref="A1.SS5.p1.6.3.3.3.3.3.m2.1.1.cmml"><mi id="A1.SS5.p1.6.3.3.3.3.3.m2.1.1.2" xref="A1.SS5.p1.6.3.3.3.3.3.m2.1.1.2.cmml"></mi><mo id="A1.SS5.p1.6.3.3.3.3.3.m2.1.1.1" lspace="0.222em" rspace="0.222em" xref="A1.SS5.p1.6.3.3.3.3.3.m2.1.1.1.cmml">\</mo><mrow id="A1.SS5.p1.6.3.3.3.3.3.m2.1.1.3" xref="A1.SS5.p1.6.3.3.3.3.3.m2.1.1.3.cmml"><mi id="A1.SS5.p1.6.3.3.3.3.3.m2.1.1.3.2" xref="A1.SS5.p1.6.3.3.3.3.3.m2.1.1.3.2.cmml">n</mi><mo id="A1.SS5.p1.6.3.3.3.3.3.m2.1.1.3.1" lspace="0.222em" rspace="0.222em" xref="A1.SS5.p1.6.3.3.3.3.3.m2.1.1.3.1.cmml">\</mo><mi id="A1.SS5.p1.6.3.3.3.3.3.m2.1.1.3.3" xref="A1.SS5.p1.6.3.3.3.3.3.m2.1.1.3.3.cmml">n</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="A1.SS5.p1.6.3.3.3.3.3.m2.1b"><apply id="A1.SS5.p1.6.3.3.3.3.3.m2.1.1.cmml" xref="A1.SS5.p1.6.3.3.3.3.3.m2.1.1"><ci id="A1.SS5.p1.6.3.3.3.3.3.m2.1.1.1.cmml" xref="A1.SS5.p1.6.3.3.3.3.3.m2.1.1.1">\</ci><csymbol cd="latexml" id="A1.SS5.p1.6.3.3.3.3.3.m2.1.1.2.cmml" xref="A1.SS5.p1.6.3.3.3.3.3.m2.1.1.2">absent</csymbol><apply id="A1.SS5.p1.6.3.3.3.3.3.m2.1.1.3.cmml" xref="A1.SS5.p1.6.3.3.3.3.3.m2.1.1.3"><ci id="A1.SS5.p1.6.3.3.3.3.3.m2.1.1.3.1.cmml" xref="A1.SS5.p1.6.3.3.3.3.3.m2.1.1.3.1">\</ci><ci id="A1.SS5.p1.6.3.3.3.3.3.m2.1.1.3.2.cmml" xref="A1.SS5.p1.6.3.3.3.3.3.m2.1.1.3.2">𝑛</ci><ci id="A1.SS5.p1.6.3.3.3.3.3.m2.1.1.3.3.cmml" xref="A1.SS5.p1.6.3.3.3.3.3.m2.1.1.3.3">𝑛</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS5.p1.6.3.3.3.3.3.m2.1c">\backslash n\backslash n</annotation><annotation encoding="application/x-llamapun" id="A1.SS5.p1.6.3.3.3.3.3.m2.1d">\ italic_n \ italic_n</annotation></semantics></math><span class="ltx_text ltx_font_italic" id="A1.SS5.p1.7.4.4.4.4.4.4">[passage]</span> <math alttext="\backslash n\backslash n" class="ltx_Math" display="inline" id="A1.SS5.p1.7.4.4.4.4.4.m3.1"><semantics id="A1.SS5.p1.7.4.4.4.4.4.m3.1a"><mrow id="A1.SS5.p1.7.4.4.4.4.4.m3.1.1" xref="A1.SS5.p1.7.4.4.4.4.4.m3.1.1.cmml"><mi id="A1.SS5.p1.7.4.4.4.4.4.m3.1.1.2" xref="A1.SS5.p1.7.4.4.4.4.4.m3.1.1.2.cmml"></mi><mo id="A1.SS5.p1.7.4.4.4.4.4.m3.1.1.1" lspace="0.222em" rspace="0.222em" xref="A1.SS5.p1.7.4.4.4.4.4.m3.1.1.1.cmml">\</mo><mrow id="A1.SS5.p1.7.4.4.4.4.4.m3.1.1.3" xref="A1.SS5.p1.7.4.4.4.4.4.m3.1.1.3.cmml"><mi id="A1.SS5.p1.7.4.4.4.4.4.m3.1.1.3.2" xref="A1.SS5.p1.7.4.4.4.4.4.m3.1.1.3.2.cmml">n</mi><mo id="A1.SS5.p1.7.4.4.4.4.4.m3.1.1.3.1" lspace="0.222em" rspace="0.222em" xref="A1.SS5.p1.7.4.4.4.4.4.m3.1.1.3.1.cmml">\</mo><mi id="A1.SS5.p1.7.4.4.4.4.4.m3.1.1.3.3" xref="A1.SS5.p1.7.4.4.4.4.4.m3.1.1.3.3.cmml">n</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="A1.SS5.p1.7.4.4.4.4.4.m3.1b"><apply id="A1.SS5.p1.7.4.4.4.4.4.m3.1.1.cmml" xref="A1.SS5.p1.7.4.4.4.4.4.m3.1.1"><ci id="A1.SS5.p1.7.4.4.4.4.4.m3.1.1.1.cmml" xref="A1.SS5.p1.7.4.4.4.4.4.m3.1.1.1">\</ci><csymbol cd="latexml" id="A1.SS5.p1.7.4.4.4.4.4.m3.1.1.2.cmml" xref="A1.SS5.p1.7.4.4.4.4.4.m3.1.1.2">absent</csymbol><apply id="A1.SS5.p1.7.4.4.4.4.4.m3.1.1.3.cmml" xref="A1.SS5.p1.7.4.4.4.4.4.m3.1.1.3"><ci id="A1.SS5.p1.7.4.4.4.4.4.m3.1.1.3.1.cmml" xref="A1.SS5.p1.7.4.4.4.4.4.m3.1.1.3.1">\</ci><ci id="A1.SS5.p1.7.4.4.4.4.4.m3.1.1.3.2.cmml" xref="A1.SS5.p1.7.4.4.4.4.4.m3.1.1.3.2">𝑛</ci><ci id="A1.SS5.p1.7.4.4.4.4.4.m3.1.1.3.3.cmml" xref="A1.SS5.p1.7.4.4.4.4.4.m3.1.1.3.3">𝑛</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS5.p1.7.4.4.4.4.4.m3.1c">\backslash n\backslash n</annotation><annotation encoding="application/x-llamapun" id="A1.SS5.p1.7.4.4.4.4.4.m3.1d">\ italic_n \ italic_n</annotation></semantics></math>:<span class="ltx_ERROR undefined" id="A1.SS5.p1.7.4.4.4.4.4.5">\&lt;</span>قرا هاد النص&gt;</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.SS5.p1.7.4.5.1">
<td class="ltx_td ltx_align_justify ltx_border_bb" id="A1.SS5.p1.7.4.5.1.1">
<span class="ltx_inline-block ltx_align_top" id="A1.SS5.p1.7.4.5.1.1.1">
<span class="ltx_p" id="A1.SS5.p1.7.4.5.1.1.1.1"><span class="ltx_text ltx_font_bold" id="A1.SS5.p1.7.4.5.1.1.1.1.1">assistant:</span> <span class="ltx_text ltx_font_italic" id="A1.SS5.p1.7.4.5.1.1.1.1.2">[answer]</span></span>
</span>
</td>
</tr>
</tbody>
</table>
<p class="ltx_p" id="A1.SS5.p1.13">Template 3:</p>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="A1.SS5.p1.10.3">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A1.SS5.p1.9.2.2">
<td class="ltx_td ltx_align_justify ltx_border_tt" id="A1.SS5.p1.9.2.2.2">
<span class="ltx_inline-block ltx_align_top" id="A1.SS5.p1.9.2.2.2.2"><span class="ltx_ERROR undefined" id="A1.SS5.p1.9.2.2.2.2.3">\setcode</span>
<span class="ltx_p" id="A1.SS5.p1.9.2.2.2.2.2">utf8
<span class="ltx_text ltx_font_bold" id="A1.SS5.p1.9.2.2.2.2.2.1">user</span>: <math alttext="\backslash n\backslash n" class="ltx_Math" display="inline" id="A1.SS5.p1.8.1.1.1.1.1.m1.1"><semantics id="A1.SS5.p1.8.1.1.1.1.1.m1.1a"><mrow id="A1.SS5.p1.8.1.1.1.1.1.m1.1.1" xref="A1.SS5.p1.8.1.1.1.1.1.m1.1.1.cmml"><mi id="A1.SS5.p1.8.1.1.1.1.1.m1.1.1.2" xref="A1.SS5.p1.8.1.1.1.1.1.m1.1.1.2.cmml"></mi><mo id="A1.SS5.p1.8.1.1.1.1.1.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="A1.SS5.p1.8.1.1.1.1.1.m1.1.1.1.cmml">\</mo><mrow id="A1.SS5.p1.8.1.1.1.1.1.m1.1.1.3" xref="A1.SS5.p1.8.1.1.1.1.1.m1.1.1.3.cmml"><mi id="A1.SS5.p1.8.1.1.1.1.1.m1.1.1.3.2" xref="A1.SS5.p1.8.1.1.1.1.1.m1.1.1.3.2.cmml">n</mi><mo id="A1.SS5.p1.8.1.1.1.1.1.m1.1.1.3.1" lspace="0.222em" rspace="0.222em" xref="A1.SS5.p1.8.1.1.1.1.1.m1.1.1.3.1.cmml">\</mo><mi id="A1.SS5.p1.8.1.1.1.1.1.m1.1.1.3.3" xref="A1.SS5.p1.8.1.1.1.1.1.m1.1.1.3.3.cmml">n</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="A1.SS5.p1.8.1.1.1.1.1.m1.1b"><apply id="A1.SS5.p1.8.1.1.1.1.1.m1.1.1.cmml" xref="A1.SS5.p1.8.1.1.1.1.1.m1.1.1"><ci id="A1.SS5.p1.8.1.1.1.1.1.m1.1.1.1.cmml" xref="A1.SS5.p1.8.1.1.1.1.1.m1.1.1.1">\</ci><csymbol cd="latexml" id="A1.SS5.p1.8.1.1.1.1.1.m1.1.1.2.cmml" xref="A1.SS5.p1.8.1.1.1.1.1.m1.1.1.2">absent</csymbol><apply id="A1.SS5.p1.8.1.1.1.1.1.m1.1.1.3.cmml" xref="A1.SS5.p1.8.1.1.1.1.1.m1.1.1.3"><ci id="A1.SS5.p1.8.1.1.1.1.1.m1.1.1.3.1.cmml" xref="A1.SS5.p1.8.1.1.1.1.1.m1.1.1.3.1">\</ci><ci id="A1.SS5.p1.8.1.1.1.1.1.m1.1.1.3.2.cmml" xref="A1.SS5.p1.8.1.1.1.1.1.m1.1.1.3.2">𝑛</ci><ci id="A1.SS5.p1.8.1.1.1.1.1.m1.1.1.3.3.cmml" xref="A1.SS5.p1.8.1.1.1.1.1.m1.1.1.3.3">𝑛</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS5.p1.8.1.1.1.1.1.m1.1c">\backslash n\backslash n</annotation><annotation encoding="application/x-llamapun" id="A1.SS5.p1.8.1.1.1.1.1.m1.1d">\ italic_n \ italic_n</annotation></semantics></math><span class="ltx_text ltx_font_italic" id="A1.SS5.p1.9.2.2.2.2.2.2">[passage]</span> <math alttext="\backslash n\backslash n" class="ltx_Math" display="inline" id="A1.SS5.p1.9.2.2.2.2.2.m2.1"><semantics id="A1.SS5.p1.9.2.2.2.2.2.m2.1a"><mrow id="A1.SS5.p1.9.2.2.2.2.2.m2.1.1" xref="A1.SS5.p1.9.2.2.2.2.2.m2.1.1.cmml"><mi id="A1.SS5.p1.9.2.2.2.2.2.m2.1.1.2" xref="A1.SS5.p1.9.2.2.2.2.2.m2.1.1.2.cmml"></mi><mo id="A1.SS5.p1.9.2.2.2.2.2.m2.1.1.1" lspace="0.222em" rspace="0.222em" xref="A1.SS5.p1.9.2.2.2.2.2.m2.1.1.1.cmml">\</mo><mrow id="A1.SS5.p1.9.2.2.2.2.2.m2.1.1.3" xref="A1.SS5.p1.9.2.2.2.2.2.m2.1.1.3.cmml"><mi id="A1.SS5.p1.9.2.2.2.2.2.m2.1.1.3.2" xref="A1.SS5.p1.9.2.2.2.2.2.m2.1.1.3.2.cmml">n</mi><mo id="A1.SS5.p1.9.2.2.2.2.2.m2.1.1.3.1" lspace="0.222em" rspace="0.222em" xref="A1.SS5.p1.9.2.2.2.2.2.m2.1.1.3.1.cmml">\</mo><mi id="A1.SS5.p1.9.2.2.2.2.2.m2.1.1.3.3" xref="A1.SS5.p1.9.2.2.2.2.2.m2.1.1.3.3.cmml">n</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="A1.SS5.p1.9.2.2.2.2.2.m2.1b"><apply id="A1.SS5.p1.9.2.2.2.2.2.m2.1.1.cmml" xref="A1.SS5.p1.9.2.2.2.2.2.m2.1.1"><ci id="A1.SS5.p1.9.2.2.2.2.2.m2.1.1.1.cmml" xref="A1.SS5.p1.9.2.2.2.2.2.m2.1.1.1">\</ci><csymbol cd="latexml" id="A1.SS5.p1.9.2.2.2.2.2.m2.1.1.2.cmml" xref="A1.SS5.p1.9.2.2.2.2.2.m2.1.1.2">absent</csymbol><apply id="A1.SS5.p1.9.2.2.2.2.2.m2.1.1.3.cmml" xref="A1.SS5.p1.9.2.2.2.2.2.m2.1.1.3"><ci id="A1.SS5.p1.9.2.2.2.2.2.m2.1.1.3.1.cmml" xref="A1.SS5.p1.9.2.2.2.2.2.m2.1.1.3.1">\</ci><ci id="A1.SS5.p1.9.2.2.2.2.2.m2.1.1.3.2.cmml" xref="A1.SS5.p1.9.2.2.2.2.2.m2.1.1.3.2">𝑛</ci><ci id="A1.SS5.p1.9.2.2.2.2.2.m2.1.1.3.3.cmml" xref="A1.SS5.p1.9.2.2.2.2.2.m2.1.1.3.3">𝑛</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS5.p1.9.2.2.2.2.2.m2.1c">\backslash n\backslash n</annotation><annotation encoding="application/x-llamapun" id="A1.SS5.p1.9.2.2.2.2.2.m2.1d">\ italic_n \ italic_n</annotation></semantics></math><span class="ltx_ERROR undefined" id="A1.SS5.p1.9.2.2.2.2.2.3">\&lt;</span>جاوب على هاد السؤال انطلاقا من داكشي لي فالنص&gt;</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.SS5.p1.10.3.3">
<td class="ltx_td ltx_align_justify" id="A1.SS5.p1.10.3.3.1">
<span class="ltx_inline-block ltx_align_top" id="A1.SS5.p1.10.3.3.1.1">
<span class="ltx_p" id="A1.SS5.p1.10.3.3.1.1.1"><math alttext="\backslash n\backslash n" class="ltx_Math" display="inline" id="A1.SS5.p1.10.3.3.1.1.1.m1.1"><semantics id="A1.SS5.p1.10.3.3.1.1.1.m1.1a"><mrow id="A1.SS5.p1.10.3.3.1.1.1.m1.1.1" xref="A1.SS5.p1.10.3.3.1.1.1.m1.1.1.cmml"><mi id="A1.SS5.p1.10.3.3.1.1.1.m1.1.1.2" xref="A1.SS5.p1.10.3.3.1.1.1.m1.1.1.2.cmml"></mi><mo id="A1.SS5.p1.10.3.3.1.1.1.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="A1.SS5.p1.10.3.3.1.1.1.m1.1.1.1.cmml">\</mo><mrow id="A1.SS5.p1.10.3.3.1.1.1.m1.1.1.3" xref="A1.SS5.p1.10.3.3.1.1.1.m1.1.1.3.cmml"><mi id="A1.SS5.p1.10.3.3.1.1.1.m1.1.1.3.2" xref="A1.SS5.p1.10.3.3.1.1.1.m1.1.1.3.2.cmml">n</mi><mo id="A1.SS5.p1.10.3.3.1.1.1.m1.1.1.3.1" lspace="0.222em" rspace="0.222em" xref="A1.SS5.p1.10.3.3.1.1.1.m1.1.1.3.1.cmml">\</mo><mi id="A1.SS5.p1.10.3.3.1.1.1.m1.1.1.3.3" xref="A1.SS5.p1.10.3.3.1.1.1.m1.1.1.3.3.cmml">n</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="A1.SS5.p1.10.3.3.1.1.1.m1.1b"><apply id="A1.SS5.p1.10.3.3.1.1.1.m1.1.1.cmml" xref="A1.SS5.p1.10.3.3.1.1.1.m1.1.1"><ci id="A1.SS5.p1.10.3.3.1.1.1.m1.1.1.1.cmml" xref="A1.SS5.p1.10.3.3.1.1.1.m1.1.1.1">\</ci><csymbol cd="latexml" id="A1.SS5.p1.10.3.3.1.1.1.m1.1.1.2.cmml" xref="A1.SS5.p1.10.3.3.1.1.1.m1.1.1.2">absent</csymbol><apply id="A1.SS5.p1.10.3.3.1.1.1.m1.1.1.3.cmml" xref="A1.SS5.p1.10.3.3.1.1.1.m1.1.1.3"><ci id="A1.SS5.p1.10.3.3.1.1.1.m1.1.1.3.1.cmml" xref="A1.SS5.p1.10.3.3.1.1.1.m1.1.1.3.1">\</ci><ci id="A1.SS5.p1.10.3.3.1.1.1.m1.1.1.3.2.cmml" xref="A1.SS5.p1.10.3.3.1.1.1.m1.1.1.3.2">𝑛</ci><ci id="A1.SS5.p1.10.3.3.1.1.1.m1.1.1.3.3.cmml" xref="A1.SS5.p1.10.3.3.1.1.1.m1.1.1.3.3">𝑛</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS5.p1.10.3.3.1.1.1.m1.1c">\backslash n\backslash n</annotation><annotation encoding="application/x-llamapun" id="A1.SS5.p1.10.3.3.1.1.1.m1.1d">\ italic_n \ italic_n</annotation></semantics></math> <span class="ltx_text ltx_font_italic" id="A1.SS5.p1.10.3.3.1.1.1.1">[question]</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.SS5.p1.10.3.4.1">
<td class="ltx_td ltx_align_justify ltx_border_bb" id="A1.SS5.p1.10.3.4.1.1">
<span class="ltx_inline-block ltx_align_top" id="A1.SS5.p1.10.3.4.1.1.1">
<span class="ltx_p" id="A1.SS5.p1.10.3.4.1.1.1.1"><span class="ltx_text ltx_font_bold" id="A1.SS5.p1.10.3.4.1.1.1.1.1">assistant:</span> <span class="ltx_text ltx_font_italic" id="A1.SS5.p1.10.3.4.1.1.1.1.2">[answer]</span></span>
</span>
</td>
</tr>
</tbody>
</table>
</div>
</section>
<section class="ltx_subsection" id="A1.SS6">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.6 </span>MoroccanSocialMedia-MultiGen</h3>
<div class="ltx_para ltx_noindent" id="A1.SS6.p1">
<p class="ltx_p" id="A1.SS6.p1.13">Continuation</p>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="A1.SS6.p1.2.2">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A1.SS6.p1.2.2.2">
<td class="ltx_td ltx_align_justify ltx_border_tt" id="A1.SS6.p1.2.2.2.2">
<span class="ltx_inline-block ltx_align_top" id="A1.SS6.p1.2.2.2.2.2"><span class="ltx_ERROR undefined" id="A1.SS6.p1.2.2.2.2.2.3">\setcode</span>
<span class="ltx_p" id="A1.SS6.p1.2.2.2.2.2.2">utf8
<span class="ltx_text ltx_font_bold" id="A1.SS6.p1.2.2.2.2.2.2.1">user</span>:  <math alttext="\backslash n" class="ltx_Math" display="inline" id="A1.SS6.p1.1.1.1.1.1.1.m1.1"><semantics id="A1.SS6.p1.1.1.1.1.1.1.m1.1a"><mrow id="A1.SS6.p1.1.1.1.1.1.1.m1.1.1" xref="A1.SS6.p1.1.1.1.1.1.1.m1.1.1.cmml"><mi id="A1.SS6.p1.1.1.1.1.1.1.m1.1.1.2" xref="A1.SS6.p1.1.1.1.1.1.1.m1.1.1.2.cmml"></mi><mo id="A1.SS6.p1.1.1.1.1.1.1.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="A1.SS6.p1.1.1.1.1.1.1.m1.1.1.1.cmml">\</mo><mi id="A1.SS6.p1.1.1.1.1.1.1.m1.1.1.3" xref="A1.SS6.p1.1.1.1.1.1.1.m1.1.1.3.cmml">n</mi></mrow><annotation-xml encoding="MathML-Content" id="A1.SS6.p1.1.1.1.1.1.1.m1.1b"><apply id="A1.SS6.p1.1.1.1.1.1.1.m1.1.1.cmml" xref="A1.SS6.p1.1.1.1.1.1.1.m1.1.1"><ci id="A1.SS6.p1.1.1.1.1.1.1.m1.1.1.1.cmml" xref="A1.SS6.p1.1.1.1.1.1.1.m1.1.1.1">\</ci><csymbol cd="latexml" id="A1.SS6.p1.1.1.1.1.1.1.m1.1.1.2.cmml" xref="A1.SS6.p1.1.1.1.1.1.1.m1.1.1.2">absent</csymbol><ci id="A1.SS6.p1.1.1.1.1.1.1.m1.1.1.3.cmml" xref="A1.SS6.p1.1.1.1.1.1.1.m1.1.1.3">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS6.p1.1.1.1.1.1.1.m1.1c">\backslash n</annotation><annotation encoding="application/x-llamapun" id="A1.SS6.p1.1.1.1.1.1.1.m1.1d">\ italic_n</annotation></semantics></math> <span class="ltx_text ltx_font_italic" id="A1.SS6.p1.2.2.2.2.2.2.2">[source sentence]</span> <math alttext="\backslash n" class="ltx_Math" display="inline" id="A1.SS6.p1.2.2.2.2.2.2.m2.1"><semantics id="A1.SS6.p1.2.2.2.2.2.2.m2.1a"><mrow id="A1.SS6.p1.2.2.2.2.2.2.m2.1.1" xref="A1.SS6.p1.2.2.2.2.2.2.m2.1.1.cmml"><mi id="A1.SS6.p1.2.2.2.2.2.2.m2.1.1.2" xref="A1.SS6.p1.2.2.2.2.2.2.m2.1.1.2.cmml"></mi><mo id="A1.SS6.p1.2.2.2.2.2.2.m2.1.1.1" lspace="0.222em" rspace="0.222em" xref="A1.SS6.p1.2.2.2.2.2.2.m2.1.1.1.cmml">\</mo><mi id="A1.SS6.p1.2.2.2.2.2.2.m2.1.1.3" xref="A1.SS6.p1.2.2.2.2.2.2.m2.1.1.3.cmml">n</mi></mrow><annotation-xml encoding="MathML-Content" id="A1.SS6.p1.2.2.2.2.2.2.m2.1b"><apply id="A1.SS6.p1.2.2.2.2.2.2.m2.1.1.cmml" xref="A1.SS6.p1.2.2.2.2.2.2.m2.1.1"><ci id="A1.SS6.p1.2.2.2.2.2.2.m2.1.1.1.cmml" xref="A1.SS6.p1.2.2.2.2.2.2.m2.1.1.1">\</ci><csymbol cd="latexml" id="A1.SS6.p1.2.2.2.2.2.2.m2.1.1.2.cmml" xref="A1.SS6.p1.2.2.2.2.2.2.m2.1.1.2">absent</csymbol><ci id="A1.SS6.p1.2.2.2.2.2.2.m2.1.1.3.cmml" xref="A1.SS6.p1.2.2.2.2.2.2.m2.1.1.3">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS6.p1.2.2.2.2.2.2.m2.1c">\backslash n</annotation><annotation encoding="application/x-llamapun" id="A1.SS6.p1.2.2.2.2.2.2.m2.1d">\ italic_n</annotation></semantics></math> <span class="ltx_ERROR undefined" id="A1.SS6.p1.2.2.2.2.2.2.3">\&lt;</span>:كمل هاد الجملة&gt;</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.SS6.p1.2.2.3.1">
<td class="ltx_td ltx_align_justify ltx_border_bb" id="A1.SS6.p1.2.2.3.1.1">
<span class="ltx_inline-block ltx_align_top" id="A1.SS6.p1.2.2.3.1.1.1">
<span class="ltx_p" id="A1.SS6.p1.2.2.3.1.1.1.1"><span class="ltx_text ltx_font_bold" id="A1.SS6.p1.2.2.3.1.1.1.1.1">assistant:</span> <span class="ltx_text ltx_font_italic" id="A1.SS6.p1.2.2.3.1.1.1.1.2">[completion]</span></span>
</span>
</td>
</tr>
</tbody>
</table>
<div class="ltx_pagination ltx_role_newpage"></div>
<p class="ltx_p" id="A1.SS6.p1.14">Reply</p>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="A1.SS6.p1.4.2">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A1.SS6.p1.4.2.2">
<td class="ltx_td ltx_align_justify ltx_border_tt" id="A1.SS6.p1.4.2.2.2">
<span class="ltx_inline-block ltx_align_top" id="A1.SS6.p1.4.2.2.2.2"><span class="ltx_ERROR undefined" id="A1.SS6.p1.4.2.2.2.2.3">\setcode</span>
<span class="ltx_p" id="A1.SS6.p1.4.2.2.2.2.2">utf8
<span class="ltx_text ltx_font_bold" id="A1.SS6.p1.4.2.2.2.2.2.2">user</span>:  <math alttext="\backslash n" class="ltx_Math" display="inline" id="A1.SS6.p1.3.1.1.1.1.1.m1.1"><semantics id="A1.SS6.p1.3.1.1.1.1.1.m1.1a"><mrow id="A1.SS6.p1.3.1.1.1.1.1.m1.1.1" xref="A1.SS6.p1.3.1.1.1.1.1.m1.1.1.cmml"><mi id="A1.SS6.p1.3.1.1.1.1.1.m1.1.1.2" xref="A1.SS6.p1.3.1.1.1.1.1.m1.1.1.2.cmml"></mi><mo id="A1.SS6.p1.3.1.1.1.1.1.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="A1.SS6.p1.3.1.1.1.1.1.m1.1.1.1.cmml">\</mo><mi id="A1.SS6.p1.3.1.1.1.1.1.m1.1.1.3" xref="A1.SS6.p1.3.1.1.1.1.1.m1.1.1.3.cmml">n</mi></mrow><annotation-xml encoding="MathML-Content" id="A1.SS6.p1.3.1.1.1.1.1.m1.1b"><apply id="A1.SS6.p1.3.1.1.1.1.1.m1.1.1.cmml" xref="A1.SS6.p1.3.1.1.1.1.1.m1.1.1"><ci id="A1.SS6.p1.3.1.1.1.1.1.m1.1.1.1.cmml" xref="A1.SS6.p1.3.1.1.1.1.1.m1.1.1.1">\</ci><csymbol cd="latexml" id="A1.SS6.p1.3.1.1.1.1.1.m1.1.1.2.cmml" xref="A1.SS6.p1.3.1.1.1.1.1.m1.1.1.2">absent</csymbol><ci id="A1.SS6.p1.3.1.1.1.1.1.m1.1.1.3.cmml" xref="A1.SS6.p1.3.1.1.1.1.1.m1.1.1.3">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS6.p1.3.1.1.1.1.1.m1.1c">\backslash n</annotation><annotation encoding="application/x-llamapun" id="A1.SS6.p1.3.1.1.1.1.1.m1.1d">\ italic_n</annotation></semantics></math> <span class="ltx_text ltx_font_italic" id="A1.SS6.p1.4.2.2.2.2.2.1">[message]<math alttext="\backslash n" class="ltx_Math" display="inline" id="A1.SS6.p1.4.2.2.2.2.2.1.m1.1"><semantics id="A1.SS6.p1.4.2.2.2.2.2.1.m1.1a"><mrow id="A1.SS6.p1.4.2.2.2.2.2.1.m1.1.1" xref="A1.SS6.p1.4.2.2.2.2.2.1.m1.1.1.cmml"><mi id="A1.SS6.p1.4.2.2.2.2.2.1.m1.1.1.2" xref="A1.SS6.p1.4.2.2.2.2.2.1.m1.1.1.2.cmml"></mi><mo id="A1.SS6.p1.4.2.2.2.2.2.1.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="A1.SS6.p1.4.2.2.2.2.2.1.m1.1.1.1.cmml">\</mo><mi id="A1.SS6.p1.4.2.2.2.2.2.1.m1.1.1.3" xref="A1.SS6.p1.4.2.2.2.2.2.1.m1.1.1.3.cmml">n</mi></mrow><annotation-xml encoding="MathML-Content" id="A1.SS6.p1.4.2.2.2.2.2.1.m1.1b"><apply id="A1.SS6.p1.4.2.2.2.2.2.1.m1.1.1.cmml" xref="A1.SS6.p1.4.2.2.2.2.2.1.m1.1.1"><ci id="A1.SS6.p1.4.2.2.2.2.2.1.m1.1.1.1.cmml" xref="A1.SS6.p1.4.2.2.2.2.2.1.m1.1.1.1">\</ci><csymbol cd="latexml" id="A1.SS6.p1.4.2.2.2.2.2.1.m1.1.1.2.cmml" xref="A1.SS6.p1.4.2.2.2.2.2.1.m1.1.1.2">absent</csymbol><ci id="A1.SS6.p1.4.2.2.2.2.2.1.m1.1.1.3.cmml" xref="A1.SS6.p1.4.2.2.2.2.2.1.m1.1.1.3">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS6.p1.4.2.2.2.2.2.1.m1.1c">\backslash n</annotation><annotation encoding="application/x-llamapun" id="A1.SS6.p1.4.2.2.2.2.2.1.m1.1d">\ italic_n</annotation></semantics></math></span> :<span class="ltx_ERROR undefined" id="A1.SS6.p1.4.2.2.2.2.2.3">\&lt;</span>جاوب على هاد الميساج&gt;</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.SS6.p1.4.2.3.1">
<td class="ltx_td ltx_align_justify ltx_border_bb" id="A1.SS6.p1.4.2.3.1.1">
<span class="ltx_inline-block ltx_align_top" id="A1.SS6.p1.4.2.3.1.1.1">
<span class="ltx_p" id="A1.SS6.p1.4.2.3.1.1.1.1"><span class="ltx_text ltx_font_bold" id="A1.SS6.p1.4.2.3.1.1.1.1.1">assistant:</span> <span class="ltx_text ltx_font_italic" id="A1.SS6.p1.4.2.3.1.1.1.1.2">[reply]</span></span>
</span>
</td>
</tr>
</tbody>
</table>
<p class="ltx_p" id="A1.SS6.p1.15">Summarization</p>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="A1.SS6.p1.6.2">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A1.SS6.p1.6.2.2">
<td class="ltx_td ltx_align_justify ltx_border_tt" id="A1.SS6.p1.6.2.2.2">
<span class="ltx_inline-block ltx_align_top" id="A1.SS6.p1.6.2.2.2.2"><span class="ltx_ERROR undefined" id="A1.SS6.p1.6.2.2.2.2.3">\setcode</span>
<span class="ltx_p" id="A1.SS6.p1.6.2.2.2.2.2">utf8
<span class="ltx_text ltx_font_bold" id="A1.SS6.p1.6.2.2.2.2.2.2">user</span>:  <math alttext="\backslash n" class="ltx_Math" display="inline" id="A1.SS6.p1.5.1.1.1.1.1.m1.1"><semantics id="A1.SS6.p1.5.1.1.1.1.1.m1.1a"><mrow id="A1.SS6.p1.5.1.1.1.1.1.m1.1.1" xref="A1.SS6.p1.5.1.1.1.1.1.m1.1.1.cmml"><mi id="A1.SS6.p1.5.1.1.1.1.1.m1.1.1.2" xref="A1.SS6.p1.5.1.1.1.1.1.m1.1.1.2.cmml"></mi><mo id="A1.SS6.p1.5.1.1.1.1.1.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="A1.SS6.p1.5.1.1.1.1.1.m1.1.1.1.cmml">\</mo><mi id="A1.SS6.p1.5.1.1.1.1.1.m1.1.1.3" xref="A1.SS6.p1.5.1.1.1.1.1.m1.1.1.3.cmml">n</mi></mrow><annotation-xml encoding="MathML-Content" id="A1.SS6.p1.5.1.1.1.1.1.m1.1b"><apply id="A1.SS6.p1.5.1.1.1.1.1.m1.1.1.cmml" xref="A1.SS6.p1.5.1.1.1.1.1.m1.1.1"><ci id="A1.SS6.p1.5.1.1.1.1.1.m1.1.1.1.cmml" xref="A1.SS6.p1.5.1.1.1.1.1.m1.1.1.1">\</ci><csymbol cd="latexml" id="A1.SS6.p1.5.1.1.1.1.1.m1.1.1.2.cmml" xref="A1.SS6.p1.5.1.1.1.1.1.m1.1.1.2">absent</csymbol><ci id="A1.SS6.p1.5.1.1.1.1.1.m1.1.1.3.cmml" xref="A1.SS6.p1.5.1.1.1.1.1.m1.1.1.3">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS6.p1.5.1.1.1.1.1.m1.1c">\backslash n</annotation><annotation encoding="application/x-llamapun" id="A1.SS6.p1.5.1.1.1.1.1.m1.1d">\ italic_n</annotation></semantics></math> <span class="ltx_text ltx_font_italic" id="A1.SS6.p1.6.2.2.2.2.2.1">[passage]<math alttext="\backslash n" class="ltx_Math" display="inline" id="A1.SS6.p1.6.2.2.2.2.2.1.m1.1"><semantics id="A1.SS6.p1.6.2.2.2.2.2.1.m1.1a"><mrow id="A1.SS6.p1.6.2.2.2.2.2.1.m1.1.1" xref="A1.SS6.p1.6.2.2.2.2.2.1.m1.1.1.cmml"><mi id="A1.SS6.p1.6.2.2.2.2.2.1.m1.1.1.2" xref="A1.SS6.p1.6.2.2.2.2.2.1.m1.1.1.2.cmml"></mi><mo id="A1.SS6.p1.6.2.2.2.2.2.1.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="A1.SS6.p1.6.2.2.2.2.2.1.m1.1.1.1.cmml">\</mo><mi id="A1.SS6.p1.6.2.2.2.2.2.1.m1.1.1.3" xref="A1.SS6.p1.6.2.2.2.2.2.1.m1.1.1.3.cmml">n</mi></mrow><annotation-xml encoding="MathML-Content" id="A1.SS6.p1.6.2.2.2.2.2.1.m1.1b"><apply id="A1.SS6.p1.6.2.2.2.2.2.1.m1.1.1.cmml" xref="A1.SS6.p1.6.2.2.2.2.2.1.m1.1.1"><ci id="A1.SS6.p1.6.2.2.2.2.2.1.m1.1.1.1.cmml" xref="A1.SS6.p1.6.2.2.2.2.2.1.m1.1.1.1">\</ci><csymbol cd="latexml" id="A1.SS6.p1.6.2.2.2.2.2.1.m1.1.1.2.cmml" xref="A1.SS6.p1.6.2.2.2.2.2.1.m1.1.1.2">absent</csymbol><ci id="A1.SS6.p1.6.2.2.2.2.2.1.m1.1.1.3.cmml" xref="A1.SS6.p1.6.2.2.2.2.2.1.m1.1.1.3">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS6.p1.6.2.2.2.2.2.1.m1.1c">\backslash n</annotation><annotation encoding="application/x-llamapun" id="A1.SS6.p1.6.2.2.2.2.2.1.m1.1d">\ italic_n</annotation></semantics></math></span> :<span class="ltx_ERROR undefined" id="A1.SS6.p1.6.2.2.2.2.2.3">\&lt;</span>لخص هاد النص&gt;</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.SS6.p1.6.2.3.1">
<td class="ltx_td ltx_align_justify ltx_border_bb" id="A1.SS6.p1.6.2.3.1.1">
<span class="ltx_inline-block ltx_align_top" id="A1.SS6.p1.6.2.3.1.1.1">
<span class="ltx_p" id="A1.SS6.p1.6.2.3.1.1.1.1"><span class="ltx_text ltx_font_bold" id="A1.SS6.p1.6.2.3.1.1.1.1.1">assistant:</span> <span class="ltx_text ltx_font_italic" id="A1.SS6.p1.6.2.3.1.1.1.1.2">[summary]</span></span>
</span>
</td>
</tr>
</tbody>
</table>
<p class="ltx_p" id="A1.SS6.p1.16">Rephrasing</p>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="A1.SS6.p1.8.2">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A1.SS6.p1.8.2.2">
<td class="ltx_td ltx_align_justify ltx_border_tt" id="A1.SS6.p1.8.2.2.2">
<span class="ltx_inline-block ltx_align_top" id="A1.SS6.p1.8.2.2.2.2"><span class="ltx_ERROR undefined" id="A1.SS6.p1.8.2.2.2.2.3">\setcode</span>
<span class="ltx_p" id="A1.SS6.p1.8.2.2.2.2.2">utf8
<span class="ltx_text ltx_font_bold" id="A1.SS6.p1.8.2.2.2.2.2.2">user</span>:  <math alttext="\backslash n" class="ltx_Math" display="inline" id="A1.SS6.p1.7.1.1.1.1.1.m1.1"><semantics id="A1.SS6.p1.7.1.1.1.1.1.m1.1a"><mrow id="A1.SS6.p1.7.1.1.1.1.1.m1.1.1" xref="A1.SS6.p1.7.1.1.1.1.1.m1.1.1.cmml"><mi id="A1.SS6.p1.7.1.1.1.1.1.m1.1.1.2" xref="A1.SS6.p1.7.1.1.1.1.1.m1.1.1.2.cmml"></mi><mo id="A1.SS6.p1.7.1.1.1.1.1.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="A1.SS6.p1.7.1.1.1.1.1.m1.1.1.1.cmml">\</mo><mi id="A1.SS6.p1.7.1.1.1.1.1.m1.1.1.3" xref="A1.SS6.p1.7.1.1.1.1.1.m1.1.1.3.cmml">n</mi></mrow><annotation-xml encoding="MathML-Content" id="A1.SS6.p1.7.1.1.1.1.1.m1.1b"><apply id="A1.SS6.p1.7.1.1.1.1.1.m1.1.1.cmml" xref="A1.SS6.p1.7.1.1.1.1.1.m1.1.1"><ci id="A1.SS6.p1.7.1.1.1.1.1.m1.1.1.1.cmml" xref="A1.SS6.p1.7.1.1.1.1.1.m1.1.1.1">\</ci><csymbol cd="latexml" id="A1.SS6.p1.7.1.1.1.1.1.m1.1.1.2.cmml" xref="A1.SS6.p1.7.1.1.1.1.1.m1.1.1.2">absent</csymbol><ci id="A1.SS6.p1.7.1.1.1.1.1.m1.1.1.3.cmml" xref="A1.SS6.p1.7.1.1.1.1.1.m1.1.1.3">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS6.p1.7.1.1.1.1.1.m1.1c">\backslash n</annotation><annotation encoding="application/x-llamapun" id="A1.SS6.p1.7.1.1.1.1.1.m1.1d">\ italic_n</annotation></semantics></math> <span class="ltx_text ltx_font_italic" id="A1.SS6.p1.8.2.2.2.2.2.1">[source sentence]<math alttext="\backslash n" class="ltx_Math" display="inline" id="A1.SS6.p1.8.2.2.2.2.2.1.m1.1"><semantics id="A1.SS6.p1.8.2.2.2.2.2.1.m1.1a"><mrow id="A1.SS6.p1.8.2.2.2.2.2.1.m1.1.1" xref="A1.SS6.p1.8.2.2.2.2.2.1.m1.1.1.cmml"><mi id="A1.SS6.p1.8.2.2.2.2.2.1.m1.1.1.2" xref="A1.SS6.p1.8.2.2.2.2.2.1.m1.1.1.2.cmml"></mi><mo id="A1.SS6.p1.8.2.2.2.2.2.1.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="A1.SS6.p1.8.2.2.2.2.2.1.m1.1.1.1.cmml">\</mo><mi id="A1.SS6.p1.8.2.2.2.2.2.1.m1.1.1.3" xref="A1.SS6.p1.8.2.2.2.2.2.1.m1.1.1.3.cmml">n</mi></mrow><annotation-xml encoding="MathML-Content" id="A1.SS6.p1.8.2.2.2.2.2.1.m1.1b"><apply id="A1.SS6.p1.8.2.2.2.2.2.1.m1.1.1.cmml" xref="A1.SS6.p1.8.2.2.2.2.2.1.m1.1.1"><ci id="A1.SS6.p1.8.2.2.2.2.2.1.m1.1.1.1.cmml" xref="A1.SS6.p1.8.2.2.2.2.2.1.m1.1.1.1">\</ci><csymbol cd="latexml" id="A1.SS6.p1.8.2.2.2.2.2.1.m1.1.1.2.cmml" xref="A1.SS6.p1.8.2.2.2.2.2.1.m1.1.1.2">absent</csymbol><ci id="A1.SS6.p1.8.2.2.2.2.2.1.m1.1.1.3.cmml" xref="A1.SS6.p1.8.2.2.2.2.2.1.m1.1.1.3">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS6.p1.8.2.2.2.2.2.1.m1.1c">\backslash n</annotation><annotation encoding="application/x-llamapun" id="A1.SS6.p1.8.2.2.2.2.2.1.m1.1d">\ italic_n</annotation></semantics></math></span> :<span class="ltx_ERROR undefined" id="A1.SS6.p1.8.2.2.2.2.2.3">\&lt;</span>كتب هاد الجملة بشي طريقة اخرى&gt;</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.SS6.p1.8.2.3.1">
<td class="ltx_td ltx_align_justify ltx_border_bb" id="A1.SS6.p1.8.2.3.1.1">
<span class="ltx_inline-block ltx_align_top" id="A1.SS6.p1.8.2.3.1.1.1">
<span class="ltx_p" id="A1.SS6.p1.8.2.3.1.1.1.1"><span class="ltx_text ltx_font_bold" id="A1.SS6.p1.8.2.3.1.1.1.1.1">assistant:</span> <span class="ltx_text ltx_font_italic" id="A1.SS6.p1.8.2.3.1.1.1.1.2">[resphrased sentence]</span></span>
</span>
</td>
</tr>
</tbody>
</table>
<p class="ltx_p" id="A1.SS6.p1.17">Explanation</p>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="A1.SS6.p1.10.2">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A1.SS6.p1.10.2.2">
<td class="ltx_td ltx_align_justify ltx_border_tt" id="A1.SS6.p1.10.2.2.2">
<span class="ltx_inline-block ltx_align_top" id="A1.SS6.p1.10.2.2.2.2"><span class="ltx_ERROR undefined" id="A1.SS6.p1.10.2.2.2.2.3">\setcode</span>
<span class="ltx_p" id="A1.SS6.p1.10.2.2.2.2.2">utf8
<span class="ltx_text ltx_font_bold" id="A1.SS6.p1.10.2.2.2.2.2.2">user</span>:  <math alttext="\backslash n" class="ltx_Math" display="inline" id="A1.SS6.p1.9.1.1.1.1.1.m1.1"><semantics id="A1.SS6.p1.9.1.1.1.1.1.m1.1a"><mrow id="A1.SS6.p1.9.1.1.1.1.1.m1.1.1" xref="A1.SS6.p1.9.1.1.1.1.1.m1.1.1.cmml"><mi id="A1.SS6.p1.9.1.1.1.1.1.m1.1.1.2" xref="A1.SS6.p1.9.1.1.1.1.1.m1.1.1.2.cmml"></mi><mo id="A1.SS6.p1.9.1.1.1.1.1.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="A1.SS6.p1.9.1.1.1.1.1.m1.1.1.1.cmml">\</mo><mi id="A1.SS6.p1.9.1.1.1.1.1.m1.1.1.3" xref="A1.SS6.p1.9.1.1.1.1.1.m1.1.1.3.cmml">n</mi></mrow><annotation-xml encoding="MathML-Content" id="A1.SS6.p1.9.1.1.1.1.1.m1.1b"><apply id="A1.SS6.p1.9.1.1.1.1.1.m1.1.1.cmml" xref="A1.SS6.p1.9.1.1.1.1.1.m1.1.1"><ci id="A1.SS6.p1.9.1.1.1.1.1.m1.1.1.1.cmml" xref="A1.SS6.p1.9.1.1.1.1.1.m1.1.1.1">\</ci><csymbol cd="latexml" id="A1.SS6.p1.9.1.1.1.1.1.m1.1.1.2.cmml" xref="A1.SS6.p1.9.1.1.1.1.1.m1.1.1.2">absent</csymbol><ci id="A1.SS6.p1.9.1.1.1.1.1.m1.1.1.3.cmml" xref="A1.SS6.p1.9.1.1.1.1.1.m1.1.1.3">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS6.p1.9.1.1.1.1.1.m1.1c">\backslash n</annotation><annotation encoding="application/x-llamapun" id="A1.SS6.p1.9.1.1.1.1.1.m1.1d">\ italic_n</annotation></semantics></math> <span class="ltx_text ltx_font_italic" id="A1.SS6.p1.10.2.2.2.2.2.1">[source sentence]<math alttext="\backslash n" class="ltx_Math" display="inline" id="A1.SS6.p1.10.2.2.2.2.2.1.m1.1"><semantics id="A1.SS6.p1.10.2.2.2.2.2.1.m1.1a"><mrow id="A1.SS6.p1.10.2.2.2.2.2.1.m1.1.1" xref="A1.SS6.p1.10.2.2.2.2.2.1.m1.1.1.cmml"><mi id="A1.SS6.p1.10.2.2.2.2.2.1.m1.1.1.2" xref="A1.SS6.p1.10.2.2.2.2.2.1.m1.1.1.2.cmml"></mi><mo id="A1.SS6.p1.10.2.2.2.2.2.1.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="A1.SS6.p1.10.2.2.2.2.2.1.m1.1.1.1.cmml">\</mo><mi id="A1.SS6.p1.10.2.2.2.2.2.1.m1.1.1.3" xref="A1.SS6.p1.10.2.2.2.2.2.1.m1.1.1.3.cmml">n</mi></mrow><annotation-xml encoding="MathML-Content" id="A1.SS6.p1.10.2.2.2.2.2.1.m1.1b"><apply id="A1.SS6.p1.10.2.2.2.2.2.1.m1.1.1.cmml" xref="A1.SS6.p1.10.2.2.2.2.2.1.m1.1.1"><ci id="A1.SS6.p1.10.2.2.2.2.2.1.m1.1.1.1.cmml" xref="A1.SS6.p1.10.2.2.2.2.2.1.m1.1.1.1">\</ci><csymbol cd="latexml" id="A1.SS6.p1.10.2.2.2.2.2.1.m1.1.1.2.cmml" xref="A1.SS6.p1.10.2.2.2.2.2.1.m1.1.1.2">absent</csymbol><ci id="A1.SS6.p1.10.2.2.2.2.2.1.m1.1.1.3.cmml" xref="A1.SS6.p1.10.2.2.2.2.2.1.m1.1.1.3">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS6.p1.10.2.2.2.2.2.1.m1.1c">\backslash n</annotation><annotation encoding="application/x-llamapun" id="A1.SS6.p1.10.2.2.2.2.2.1.m1.1d">\ italic_n</annotation></semantics></math></span> :<span class="ltx_ERROR undefined" id="A1.SS6.p1.10.2.2.2.2.2.3">\&lt;</span>شرح ليا هاد الجملة&gt;</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.SS6.p1.10.2.3.1">
<td class="ltx_td ltx_align_justify ltx_border_bb" id="A1.SS6.p1.10.2.3.1.1">
<span class="ltx_inline-block ltx_align_top" id="A1.SS6.p1.10.2.3.1.1.1">
<span class="ltx_p" id="A1.SS6.p1.10.2.3.1.1.1.1"><span class="ltx_text ltx_font_bold" id="A1.SS6.p1.10.2.3.1.1.1.1.1">assistant:</span> <span class="ltx_text ltx_font_italic" id="A1.SS6.p1.10.2.3.1.1.1.1.2">[explanation]</span></span>
</span>
</td>
</tr>
</tbody>
</table>
<p class="ltx_p" id="A1.SS6.p1.18">Safe Response</p>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="A1.SS6.p1.12.2">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A1.SS6.p1.12.2.2">
<td class="ltx_td ltx_align_justify ltx_border_tt" id="A1.SS6.p1.12.2.2.2">
<span class="ltx_inline-block ltx_align_top" id="A1.SS6.p1.12.2.2.2.2"><span class="ltx_ERROR undefined" id="A1.SS6.p1.12.2.2.2.2.3">\setcode</span>
<span class="ltx_p" id="A1.SS6.p1.12.2.2.2.2.2">utf8
<span class="ltx_text ltx_font_bold" id="A1.SS6.p1.12.2.2.2.2.2.2">user</span>:  <math alttext="\backslash n" class="ltx_Math" display="inline" id="A1.SS6.p1.11.1.1.1.1.1.m1.1"><semantics id="A1.SS6.p1.11.1.1.1.1.1.m1.1a"><mrow id="A1.SS6.p1.11.1.1.1.1.1.m1.1.1" xref="A1.SS6.p1.11.1.1.1.1.1.m1.1.1.cmml"><mi id="A1.SS6.p1.11.1.1.1.1.1.m1.1.1.2" xref="A1.SS6.p1.11.1.1.1.1.1.m1.1.1.2.cmml"></mi><mo id="A1.SS6.p1.11.1.1.1.1.1.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="A1.SS6.p1.11.1.1.1.1.1.m1.1.1.1.cmml">\</mo><mi id="A1.SS6.p1.11.1.1.1.1.1.m1.1.1.3" xref="A1.SS6.p1.11.1.1.1.1.1.m1.1.1.3.cmml">n</mi></mrow><annotation-xml encoding="MathML-Content" id="A1.SS6.p1.11.1.1.1.1.1.m1.1b"><apply id="A1.SS6.p1.11.1.1.1.1.1.m1.1.1.cmml" xref="A1.SS6.p1.11.1.1.1.1.1.m1.1.1"><ci id="A1.SS6.p1.11.1.1.1.1.1.m1.1.1.1.cmml" xref="A1.SS6.p1.11.1.1.1.1.1.m1.1.1.1">\</ci><csymbol cd="latexml" id="A1.SS6.p1.11.1.1.1.1.1.m1.1.1.2.cmml" xref="A1.SS6.p1.11.1.1.1.1.1.m1.1.1.2">absent</csymbol><ci id="A1.SS6.p1.11.1.1.1.1.1.m1.1.1.3.cmml" xref="A1.SS6.p1.11.1.1.1.1.1.m1.1.1.3">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS6.p1.11.1.1.1.1.1.m1.1c">\backslash n</annotation><annotation encoding="application/x-llamapun" id="A1.SS6.p1.11.1.1.1.1.1.m1.1d">\ italic_n</annotation></semantics></math> <span class="ltx_text ltx_font_italic" id="A1.SS6.p1.12.2.2.2.2.2.1">[source sentence]<math alttext="\backslash n" class="ltx_Math" display="inline" id="A1.SS6.p1.12.2.2.2.2.2.1.m1.1"><semantics id="A1.SS6.p1.12.2.2.2.2.2.1.m1.1a"><mrow id="A1.SS6.p1.12.2.2.2.2.2.1.m1.1.1" xref="A1.SS6.p1.12.2.2.2.2.2.1.m1.1.1.cmml"><mi id="A1.SS6.p1.12.2.2.2.2.2.1.m1.1.1.2" xref="A1.SS6.p1.12.2.2.2.2.2.1.m1.1.1.2.cmml"></mi><mo id="A1.SS6.p1.12.2.2.2.2.2.1.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="A1.SS6.p1.12.2.2.2.2.2.1.m1.1.1.1.cmml">\</mo><mi id="A1.SS6.p1.12.2.2.2.2.2.1.m1.1.1.3" xref="A1.SS6.p1.12.2.2.2.2.2.1.m1.1.1.3.cmml">n</mi></mrow><annotation-xml encoding="MathML-Content" id="A1.SS6.p1.12.2.2.2.2.2.1.m1.1b"><apply id="A1.SS6.p1.12.2.2.2.2.2.1.m1.1.1.cmml" xref="A1.SS6.p1.12.2.2.2.2.2.1.m1.1.1"><ci id="A1.SS6.p1.12.2.2.2.2.2.1.m1.1.1.1.cmml" xref="A1.SS6.p1.12.2.2.2.2.2.1.m1.1.1.1">\</ci><csymbol cd="latexml" id="A1.SS6.p1.12.2.2.2.2.2.1.m1.1.1.2.cmml" xref="A1.SS6.p1.12.2.2.2.2.2.1.m1.1.1.2">absent</csymbol><ci id="A1.SS6.p1.12.2.2.2.2.2.1.m1.1.1.3.cmml" xref="A1.SS6.p1.12.2.2.2.2.2.1.m1.1.1.3">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS6.p1.12.2.2.2.2.2.1.m1.1c">\backslash n</annotation><annotation encoding="application/x-llamapun" id="A1.SS6.p1.12.2.2.2.2.2.1.m1.1d">\ italic_n</annotation></semantics></math></span> :<span class="ltx_ERROR undefined" id="A1.SS6.p1.12.2.2.2.2.2.3">\&lt;</span>جاوب على هادشي بطريقة مأدبة&gt;</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.SS6.p1.12.2.3.1">
<td class="ltx_td ltx_align_justify ltx_border_bb" id="A1.SS6.p1.12.2.3.1.1">
<span class="ltx_inline-block ltx_align_top" id="A1.SS6.p1.12.2.3.1.1.1">
<span class="ltx_p" id="A1.SS6.p1.12.2.3.1.1.1.1"><span class="ltx_text ltx_font_bold" id="A1.SS6.p1.12.2.3.1.1.1.1.1">assistant:</span> <span class="ltx_text ltx_font_italic" id="A1.SS6.p1.12.2.3.1.1.1.1.2">[safe response]</span></span>
</span>
</td>
</tr>
</tbody>
</table>
</div>
</section>
<section class="ltx_subsection" id="A1.SS7">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.7 </span>DarijaStory-Completion</h3>
<div class="ltx_para" id="A1.SS7.2">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="A1.SS7.2.2">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A1.SS7.2.2.2">
<td class="ltx_td ltx_align_justify ltx_border_tt" id="A1.SS7.2.2.2.2">
<span class="ltx_inline-block ltx_align_top" id="A1.SS7.2.2.2.2.2"><span class="ltx_ERROR undefined" id="A1.SS7.2.2.2.2.2.3">\setcode</span>
<span class="ltx_p" id="A1.SS7.2.2.2.2.2.2">utf8
<span class="ltx_text ltx_font_bold" id="A1.SS7.2.2.2.2.2.2.2">user</span>:  <math alttext="\backslash n" class="ltx_Math" display="inline" id="A1.SS7.1.1.1.1.1.1.m1.1"><semantics id="A1.SS7.1.1.1.1.1.1.m1.1a"><mrow id="A1.SS7.1.1.1.1.1.1.m1.1.1" xref="A1.SS7.1.1.1.1.1.1.m1.1.1.cmml"><mi id="A1.SS7.1.1.1.1.1.1.m1.1.1.2" xref="A1.SS7.1.1.1.1.1.1.m1.1.1.2.cmml"></mi><mo id="A1.SS7.1.1.1.1.1.1.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="A1.SS7.1.1.1.1.1.1.m1.1.1.1.cmml">\</mo><mi id="A1.SS7.1.1.1.1.1.1.m1.1.1.3" xref="A1.SS7.1.1.1.1.1.1.m1.1.1.3.cmml">n</mi></mrow><annotation-xml encoding="MathML-Content" id="A1.SS7.1.1.1.1.1.1.m1.1b"><apply id="A1.SS7.1.1.1.1.1.1.m1.1.1.cmml" xref="A1.SS7.1.1.1.1.1.1.m1.1.1"><ci id="A1.SS7.1.1.1.1.1.1.m1.1.1.1.cmml" xref="A1.SS7.1.1.1.1.1.1.m1.1.1.1">\</ci><csymbol cd="latexml" id="A1.SS7.1.1.1.1.1.1.m1.1.1.2.cmml" xref="A1.SS7.1.1.1.1.1.1.m1.1.1.2">absent</csymbol><ci id="A1.SS7.1.1.1.1.1.1.m1.1.1.3.cmml" xref="A1.SS7.1.1.1.1.1.1.m1.1.1.3">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS7.1.1.1.1.1.1.m1.1c">\backslash n</annotation><annotation encoding="application/x-llamapun" id="A1.SS7.1.1.1.1.1.1.m1.1d">\ italic_n</annotation></semantics></math> <span class="ltx_text ltx_font_italic" id="A1.SS7.2.2.2.2.2.2.1">[story]<math alttext="\backslash n" class="ltx_Math" display="inline" id="A1.SS7.2.2.2.2.2.2.1.m1.1"><semantics id="A1.SS7.2.2.2.2.2.2.1.m1.1a"><mrow id="A1.SS7.2.2.2.2.2.2.1.m1.1.1" xref="A1.SS7.2.2.2.2.2.2.1.m1.1.1.cmml"><mi id="A1.SS7.2.2.2.2.2.2.1.m1.1.1.2" xref="A1.SS7.2.2.2.2.2.2.1.m1.1.1.2.cmml"></mi><mo id="A1.SS7.2.2.2.2.2.2.1.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="A1.SS7.2.2.2.2.2.2.1.m1.1.1.1.cmml">\</mo><mi id="A1.SS7.2.2.2.2.2.2.1.m1.1.1.3" xref="A1.SS7.2.2.2.2.2.2.1.m1.1.1.3.cmml">n</mi></mrow><annotation-xml encoding="MathML-Content" id="A1.SS7.2.2.2.2.2.2.1.m1.1b"><apply id="A1.SS7.2.2.2.2.2.2.1.m1.1.1.cmml" xref="A1.SS7.2.2.2.2.2.2.1.m1.1.1"><ci id="A1.SS7.2.2.2.2.2.2.1.m1.1.1.1.cmml" xref="A1.SS7.2.2.2.2.2.2.1.m1.1.1.1">\</ci><csymbol cd="latexml" id="A1.SS7.2.2.2.2.2.2.1.m1.1.1.2.cmml" xref="A1.SS7.2.2.2.2.2.2.1.m1.1.1.2">absent</csymbol><ci id="A1.SS7.2.2.2.2.2.2.1.m1.1.1.3.cmml" xref="A1.SS7.2.2.2.2.2.2.1.m1.1.1.3">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS7.2.2.2.2.2.2.1.m1.1c">\backslash n</annotation><annotation encoding="application/x-llamapun" id="A1.SS7.2.2.2.2.2.2.1.m1.1d">\ italic_n</annotation></semantics></math></span> :<span class="ltx_ERROR undefined" id="A1.SS7.2.2.2.2.2.2.3">\&lt;</span>كمل هاد لقصة&gt;</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.SS7.2.2.3.1">
<td class="ltx_td ltx_align_justify ltx_border_bb" id="A1.SS7.2.2.3.1.1">
<span class="ltx_inline-block ltx_align_top" id="A1.SS7.2.2.3.1.1.1">
<span class="ltx_p" id="A1.SS7.2.2.3.1.1.1.1"><span class="ltx_text ltx_font_bold" id="A1.SS7.2.2.3.1.1.1.1.1">assistant:</span> <span class="ltx_text ltx_font_italic" id="A1.SS7.2.2.3.1.1.1.1.2">[completion]</span></span>
</span>
</td>
</tr>
</tbody>
</table>
</div>
<div class="ltx_para" id="A1.SS7.p1">
<br class="ltx_break"/>
</div>
</section>
</section>
<section class="ltx_appendix" id="A2">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>TÜLU-V2-mix and its translation</h2>
<div class="ltx_para" id="A2.p1">
<p class="ltx_p" id="A2.p1.1">In this section, we provide a detailed overview of the TÜLU-V2-mix dataset and its translation process into Darija, including the datasets it incorporates and the sampling strategies employed. We also describe the dataset’s format and the steps involved in translating the dataset to Moroccan Darija.</p>
</div>
<section class="ltx_subsection" id="A2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.1 </span>Composition of TÜLU-V2-mix</h3>
<div class="ltx_para" id="A2.SS1.p1">
<p class="ltx_p" id="A2.SS1.p1.1">TÜLU-V2-mix incorporates subsets from the following datasets: FLAN <cite class="ltx_cite ltx_citemacro_citep">(Wei et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#bib.bib51" title="">2021</a>)</cite><span class="ltx_note ltx_role_footnote" id="footnote38"><sup class="ltx_note_mark">38</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">38</sup><span class="ltx_tag ltx_tag_note">38</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/google-research/FLAN/tree/main" title="">https://github.com/google-research/FLAN/tree/main</a></span></span></span>, Open Assistant 1 <cite class="ltx_cite ltx_citemacro_citep">(Köpf et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#bib.bib30" title="">2024</a>)</cite><span class="ltx_note ltx_role_footnote" id="footnote39"><sup class="ltx_note_mark">39</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">39</sup><span class="ltx_tag ltx_tag_note">39</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://hf.co/datasets/OpenAssistant/oasst1" title="">https://hf.co/datasets/OpenAssistant/oasst1</a></span></span></span>, ShareGPT <cite class="ltx_cite ltx_citemacro_citep">(Chen et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#bib.bib8" title="">2023</a>)</cite><span class="ltx_note ltx_role_footnote" id="footnote40"><sup class="ltx_note_mark">40</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">40</sup><span class="ltx_tag ltx_tag_note">40</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://hf.co/datasets/anon8231489123/ShareGPT_Vicuna_unfiltered" title="">https://hf.co/datasets/anon8231489123/ShareGPT_Vicuna_unfiltered</a></span></span></span>, GPT4-Alpaca <cite class="ltx_cite ltx_citemacro_citep">(Peng et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#bib.bib42" title="">2023</a>)</cite><span class="ltx_note ltx_role_footnote" id="footnote41"><sup class="ltx_note_mark">41</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">41</sup><span class="ltx_tag ltx_tag_note">41</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM#data-release" title="">https://github.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM#data-release</a></span></span></span>, Code-Alpaca<span class="ltx_note ltx_role_footnote" id="footnote42"><sup class="ltx_note_mark">42</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">42</sup><span class="ltx_tag ltx_tag_note">42</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/sahil280114/codealpaca" title="">https://github.com/sahil280114/codealpaca</a></span></span></span>, LIMA <cite class="ltx_cite ltx_citemacro_citep">(Zhou et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#bib.bib59" title="">2024</a>)</cite><span class="ltx_note ltx_role_footnote" id="footnote43"><sup class="ltx_note_mark">43</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">43</sup><span class="ltx_tag ltx_tag_note">43</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://hf.co/datasets/GAIR/lima" title="">https://hf.co/datasets/GAIR/lima</a></span></span></span>, WizardLM Evol Instruct <cite class="ltx_cite ltx_citemacro_citep">(Xu et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#bib.bib52" title="">2023</a>)</cite><span class="ltx_note ltx_role_footnote" id="footnote44"><sup class="ltx_note_mark">44</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">44</sup><span class="ltx_tag ltx_tag_note">44</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://hf.co/datasets/WizardLM/WizardLM_evol_instruct_V2_196k" title="">https://hf.co/datasets/WizardLM/WizardLM_evol_instruct_V2_196k</a></span></span></span>, and Open-Orca <cite class="ltx_cite ltx_citemacro_citep">(Mukherjee et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#bib.bib36" title="">2023</a>)</cite><span class="ltx_note ltx_role_footnote" id="footnote45"><sup class="ltx_note_mark">45</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">45</sup><span class="ltx_tag ltx_tag_note">45</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://hf.co/datasets/Open-Orca/OpenOrca" title="">https://hf.co/datasets/Open-Orca/OpenOrca</a></span></span></span>. The mixture also incorporates hard-coded instructions and a set of science-related questions derived from scientific documents. Table <a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#A2.T3" title="Table 3 ‣ B.1 Composition of TÜLU-V2-mix ‣ Appendix B TÜLU-V2-mix and its translation ‣ Atlas-Chat: Adapting Large Language Models for Low-Resource Moroccan Arabic Dialect"><span class="ltx_text ltx_ref_tag">3</span></a> presents descriptions of each of these datasets and describes how the subset in TÜLU-V2-mix was sampled.</p>
</div>
<figure class="ltx_table" id="A2.T3">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="A2.T3.1" style="width:433.6pt;height:444pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(50.1pt,-51.3pt) scale(1.30014670601398,1.30014670601398) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="A2.T3.1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A2.T3.1.1.1.1">
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_t" id="A2.T3.1.1.1.1.1" style="padding:2pt 2.0pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.T3.1.1.1.1.1.1">
<span class="ltx_p" id="A2.T3.1.1.1.1.1.1.1" style="width:51.2pt;"><span class="ltx_text ltx_font_bold" id="A2.T3.1.1.1.1.1.1.1.1">Dataset</span></span>
</span>
</th>
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_t" id="A2.T3.1.1.1.1.2" style="padding:2pt 2.0pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.T3.1.1.1.1.2.1">
<span class="ltx_p" id="A2.T3.1.1.1.1.2.1.1" style="width:156.5pt;"><span class="ltx_text ltx_font_bold" id="A2.T3.1.1.1.1.2.1.1.1">Description</span></span>
</span>
</th>
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_t" id="A2.T3.1.1.1.1.3" style="padding:2pt 2.0pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.T3.1.1.1.1.3.1">
<span class="ltx_p" id="A2.T3.1.1.1.1.3.1.1" style="width:113.8pt;"><span class="ltx_text ltx_font_bold" id="A2.T3.1.1.1.1.3.1.1.1">Sampling Strategy</span></span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A2.T3.1.1.2.1">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A2.T3.1.1.2.1.1" style="padding:2pt 2.0pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.T3.1.1.2.1.1.1">
<span class="ltx_p" id="A2.T3.1.1.2.1.1.1.1" style="width:51.2pt;"><span class="ltx_text ltx_font_bold" id="A2.T3.1.1.2.1.1.1.1.1">FLAN</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A2.T3.1.1.2.1.2" style="padding:2pt 2.0pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.T3.1.1.2.1.2.1">
<span class="ltx_p" id="A2.T3.1.1.2.1.2.1.1" style="width:156.5pt;">A collection of datasets with tasks such as question answering, summarization, translation, and more.</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A2.T3.1.1.2.1.3" style="padding:2pt 2.0pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.T3.1.1.2.1.3.1">
<span class="ltx_p" id="A2.T3.1.1.2.1.3.1.1" style="width:113.8pt;">100,000 examples from FLAN v2, split equally between general tasks and the CoT subset.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A2.T3.1.1.3.2">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A2.T3.1.1.3.2.1" style="padding:2pt 2.0pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.T3.1.1.3.2.1.1">
<span class="ltx_p" id="A2.T3.1.1.3.2.1.1.1" style="width:51.2pt;"><span class="ltx_text ltx_font_bold" id="A2.T3.1.1.3.2.1.1.1.1">Open Assistant 1</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A2.T3.1.1.3.2.2" style="padding:2pt 2.0pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.T3.1.1.3.2.2.1">
<span class="ltx_p" id="A2.T3.1.1.3.2.2.1.1" style="width:156.5pt;">A human-annotated assistant-style conversation corpus.</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A2.T3.1.1.3.2.3" style="padding:2pt 2.0pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.T3.1.1.3.2.3.1">
<span class="ltx_p" id="A2.T3.1.1.3.2.3.1.1" style="width:113.8pt;">Top-ranked paths in conversation trees. 7,708 examples.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A2.T3.1.1.4.3">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A2.T3.1.1.4.3.1" style="padding:2pt 2.0pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.T3.1.1.4.3.1.1">
<span class="ltx_p" id="A2.T3.1.1.4.3.1.1.1" style="width:51.2pt;"><span class="ltx_text ltx_font_bold" id="A2.T3.1.1.4.3.1.1.1.1">ShareGPT</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A2.T3.1.1.4.3.2" style="padding:2pt 2.0pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.T3.1.1.4.3.2.1">
<span class="ltx_p" id="A2.T3.1.1.4.3.2.1.1" style="width:156.5pt;">User-shared conversations with ChatGPT and GPT-4.</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A2.T3.1.1.4.3.3" style="padding:2pt 2.0pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.T3.1.1.4.3.3.1">
<span class="ltx_p" id="A2.T3.1.1.4.3.3.1.1" style="width:113.8pt;">114,046 samples from a processed ShareGPT dataset.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A2.T3.1.1.5.4">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A2.T3.1.1.5.4.1" style="padding:2pt 2.0pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.T3.1.1.5.4.1.1">
<span class="ltx_p" id="A2.T3.1.1.5.4.1.1.1" style="width:51.2pt;"><span class="ltx_text ltx_font_bold" id="A2.T3.1.1.5.4.1.1.1.1">GPT4-Alpaca</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A2.T3.1.1.5.4.2" style="padding:2pt 2.0pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.T3.1.1.5.4.2.1">
<span class="ltx_p" id="A2.T3.1.1.5.4.2.1.1" style="width:156.5pt;">GPT-4 generated responses to prompts from Alpaca.</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A2.T3.1.1.5.4.3" style="padding:2pt 2.0pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.T3.1.1.5.4.3.1">
<span class="ltx_p" id="A2.T3.1.1.5.4.3.1.1" style="width:113.8pt;">20,000 samples.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A2.T3.1.1.6.5">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A2.T3.1.1.6.5.1" style="padding:2pt 2.0pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.T3.1.1.6.5.1.1">
<span class="ltx_p" id="A2.T3.1.1.6.5.1.1.1" style="width:51.2pt;"><span class="ltx_text ltx_font_bold" id="A2.T3.1.1.6.5.1.1.1.1">Code-Alpaca</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A2.T3.1.1.6.5.2" style="padding:2pt 2.0pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.T3.1.1.6.5.2.1">
<span class="ltx_p" id="A2.T3.1.1.6.5.2.1.1" style="width:156.5pt;">Coding instruction-tuning data generated by text-davinci-003.</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A2.T3.1.1.6.5.3" style="padding:2pt 2.0pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.T3.1.1.6.5.3.1">
<span class="ltx_p" id="A2.T3.1.1.6.5.3.1.1" style="width:113.8pt;">All 20,022 examples.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A2.T3.1.1.7.6">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A2.T3.1.1.7.6.1" style="padding:2pt 2.0pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.T3.1.1.7.6.1.1">
<span class="ltx_p" id="A2.T3.1.1.7.6.1.1.1" style="width:51.2pt;"><span class="ltx_text ltx_font_bold" id="A2.T3.1.1.7.6.1.1.1.1">LIMA</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A2.T3.1.1.7.6.2" style="padding:2pt 2.0pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.T3.1.1.7.6.2.1">
<span class="ltx_p" id="A2.T3.1.1.7.6.2.1.1" style="width:156.5pt;">Carefully selected data with a special focus on quality.</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A2.T3.1.1.7.6.3" style="padding:2pt 2.0pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.T3.1.1.7.6.3.1">
<span class="ltx_p" id="A2.T3.1.1.7.6.3.1.1" style="width:113.8pt;">All 1,030 examples.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A2.T3.1.1.8.7">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A2.T3.1.1.8.7.1" style="padding:2pt 2.0pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.T3.1.1.8.7.1.1">
<span class="ltx_p" id="A2.T3.1.1.8.7.1.1.1" style="width:51.2pt;"><span class="ltx_text ltx_font_bold" id="A2.T3.1.1.8.7.1.1.1.1">WizardLM Evol Instruct</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A2.T3.1.1.8.7.2" style="padding:2pt 2.0pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.T3.1.1.8.7.2.1">
<span class="ltx_p" id="A2.T3.1.1.8.7.2.1.1" style="width:156.5pt;">Automatic evolution of instruction datasets, enhancing the complexity and diversity of instructions.</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A2.T3.1.1.8.7.3" style="padding:2pt 2.0pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.T3.1.1.8.7.3.1">
<span class="ltx_p" id="A2.T3.1.1.8.7.3.1.1" style="width:113.8pt;">30,000 examples.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A2.T3.1.1.9.8">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A2.T3.1.1.9.8.1" style="padding:2pt 2.0pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.T3.1.1.9.8.1.1">
<span class="ltx_p" id="A2.T3.1.1.9.8.1.1.1" style="width:51.2pt;"><span class="ltx_text ltx_font_bold" id="A2.T3.1.1.9.8.1.1.1.1">Open-Orca</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A2.T3.1.1.9.8.2" style="padding:2pt 2.0pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.T3.1.1.9.8.2.1">
<span class="ltx_p" id="A2.T3.1.1.9.8.2.1.1" style="width:156.5pt;">Augmented FLAN data with additional generated explanations.</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A2.T3.1.1.9.8.3" style="padding:2pt 2.0pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.T3.1.1.9.8.3.1">
<span class="ltx_p" id="A2.T3.1.1.9.8.3.1.1" style="width:113.8pt;">30,000 samples generated by GPT-4.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A2.T3.1.1.10.9">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A2.T3.1.1.10.9.1" style="padding:2pt 2.0pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.T3.1.1.10.9.1.1">
<span class="ltx_p" id="A2.T3.1.1.10.9.1.1.1" style="width:51.2pt;"><span class="ltx_text ltx_font_bold" id="A2.T3.1.1.10.9.1.1.1.1">Hardcoded</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A2.T3.1.1.10.9.2" style="padding:2pt 2.0pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.T3.1.1.10.9.2.1">
<span class="ltx_p" id="A2.T3.1.1.10.9.2.1.1" style="width:156.5pt;">Prompts ensuring the model correctly answers questions about its identity or creators.</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A2.T3.1.1.10.9.3" style="padding:2pt 2.0pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.T3.1.1.10.9.3.1">
<span class="ltx_p" id="A2.T3.1.1.10.9.3.1.1" style="width:113.8pt;">14 samples each repeated 10 times = 140 total samples.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A2.T3.1.1.11.10">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_b" id="A2.T3.1.1.11.10.1" style="padding:2pt 2.0pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.T3.1.1.11.10.1.1">
<span class="ltx_p" id="A2.T3.1.1.11.10.1.1.1" style="width:51.2pt;"><span class="ltx_text ltx_font_bold" id="A2.T3.1.1.11.10.1.1.1.1">Science</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_b" id="A2.T3.1.1.11.10.2" style="padding:2pt 2.0pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.T3.1.1.11.10.2.1">
<span class="ltx_p" id="A2.T3.1.1.11.10.2.1.1" style="width:156.5pt;">Scientific documents understanding tasks.</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_b" id="A2.T3.1.1.11.10.3" style="padding:2pt 2.0pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.T3.1.1.11.10.3.1">
<span class="ltx_p" id="A2.T3.1.1.11.10.3.1.1" style="width:113.8pt;">7,544 examples.</span>
</span>
</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>Subsets of TÜLU-V2-mix.</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="A2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.2 </span>Dataset Format</h3>
<div class="ltx_para ltx_noindent" id="A2.SS2.p1">
<p class="ltx_p" id="A2.SS2.p1.1">TÜLU-V2-mix is structured in a "messages" format commonly used for conversational datasets. Each interaction consists of a sequence of messages, where each message is represented as a JSON object with at least two key-value pairs:</p>
<ul class="ltx_itemize" id="A2.I1">
<li class="ltx_item" id="A2.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A2.I1.i1.p1">
<p class="ltx_p" id="A2.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="A2.I1.i1.p1.1.1">"role"</span>: Specifies the role of the participant in the conversation. Typically, this is either "user" (the person asking questions or giving prompts) or "assistant" (the model’s response).</p>
</div>
</li>
<li class="ltx_item" id="A2.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A2.I1.i2.p1">
<p class="ltx_p" id="A2.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="A2.I1.i2.p1.1.1">"content"</span>: Contains the actual text of the message. This is where the question, instruction, or response is written.</p>
</div>
</li>
</ul>
<p class="ltx_p" id="A2.SS2.p1.2">Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#A2.F2" title="Figure 2 ‣ B.2 Dataset Format ‣ Appendix B TÜLU-V2-mix and its translation ‣ Atlas-Chat: Adapting Large Language Models for Low-Resource Moroccan Arabic Dialect"><span class="ltx_text ltx_ref_tag">2</span></a> shows how samples from TÜLU-V2-mix are formatted.</p>
</div>
<figure class="ltx_figure" id="A2.F2">
<div class="ltx_listing ltx_lstlisting ltx_framed ltx_framed_rectangle ltx_listing" id="A2.F2.1" style="background-color:#F2F2F2;">
<div class="ltx_listing_data"><a download="" href="data:text/plain;base64,WwogICAgewogICAgICAgICJyb2xlIjogInVzZXIiLAogICAgICAgICJjb250ZW50IjogIldoYXQgaXMgdGhlIGxhdGVzdCByZWxlYXNlIHZlcnNpb24gb2YgdGhlIEx1YSBwcm9ncmFtbWluZyBsYW5ndWFnZT8iCiAgICB9LAogICAgewogICAgICAgICJyb2xlIjogImFzc2lzdGFudCIsCiAgICAgICAgImNvbnRlbnQiOiAiVGhlIGxhdGVzdCByZWxlYXNlIG9mIHRoZSBMdWEgcHJvZ3JhbW1pbmcgbGFuZ3VhZ2UgaXMgTHVhIDUuNC40LCByZWxlYXNlZCBpbiBKYW51YXJ5IDIwMjIuIFRoZSBsYXRlc3QgbWFqb3IgdmVyc2lvbiwgTHVhIDUuNCwgd2FzIHJlbGVhc2VkIGluIEp1bmUgIDIwMjAgYW5kIGludHJvZHVjZWQgbmV3IGZlYXR1cmVzIHN1Y2ggYXMgYSBuZXcgZ2VuZXJhdGlvbmFsIG1vZGUgZm9yIGdhcmJhZ2UgY29sbGVjdGlvbiwgY29uc3QgdmFyaWFibGVzLCBhbmQgdG8tYmUtY2xvc2VkIHZhcmlhYmxlcy4iCiAgICB9Cl0=">⬇</a></div>
<div class="ltx_listingline" id="lstnumberx1">
<span class="ltx_text ltx_font_typewriter" id="lstnumberx1.1">[</span>
</div>
<div class="ltx_listingline" id="lstnumberx2">
<span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx2.1"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx2.2">{</span>
</div>
<div class="ltx_listingline" id="lstnumberx3">
<span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx3.1"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx3.2">"</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx3.3">role</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx3.4">":</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx3.5"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx3.6">"</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx3.7">user</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx3.8">",</span>
</div>
<div class="ltx_listingline" id="lstnumberx4">
<span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx4.1"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx4.2">"</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx4.3">content</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx4.4">":</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx4.5"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx4.6">"</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx4.7">What</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx4.8"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx4.9">is</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx4.10"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx4.11">the</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx4.12"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx4.13">latest</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx4.14"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx4.15">release</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx4.16"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx4.17">version</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx4.18"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx4.19">of</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx4.20"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx4.21">the</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx4.22"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx4.23">Lua</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx4.24"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx4.25">programming</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx4.26"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx4.27">language</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx4.28">?"</span>
</div>
<div class="ltx_listingline" id="lstnumberx5">
<span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx5.1"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx5.2">},</span>
</div>
<div class="ltx_listingline" id="lstnumberx6">
<span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx6.1"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx6.2">{</span>
</div>
<div class="ltx_listingline" id="lstnumberx7">
<span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx7.1"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx7.2">"</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx7.3">role</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx7.4">":</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx7.5"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx7.6">"</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx7.7">assistant</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx7.8">",</span>
</div>
<div class="ltx_listingline" id="lstnumberx8">
<span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx8.1"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx8.2">"</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx8.3">content</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx8.4">":</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx8.5"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx8.6">"</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx8.7">The</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx8.8"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx8.9">latest</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx8.10"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx8.11">release</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx8.12"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx8.13">of</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx8.14"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx8.15">the</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx8.16"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx8.17">Lua</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx8.18"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx8.19">programming</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx8.20"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx8.21">language</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx8.22"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx8.23">is</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx8.24"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx8.25">Lua</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx8.26"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx8.27">5.4.4,</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx8.28"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx8.29">released</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx8.30"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx8.31">in</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx8.32"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx8.33">January</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx8.34"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx8.35">2022.</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx8.36"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx8.37">The</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx8.38"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx8.39">latest</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx8.40"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx8.41">major</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx8.42"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx8.43">version</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx8.44">,</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx8.45"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx8.46">Lua</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx8.47"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx8.48">5.4,</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx8.49"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx8.50">was</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx8.51"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx8.52">released</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx8.53"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx8.54">in</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx8.55"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx8.56">June</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx8.57"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx8.58">2020</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx8.59"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx8.60">and</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx8.61"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx8.62">introduced</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx8.63"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx8.64">new</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx8.65"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx8.66">features</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx8.67"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx8.68">such</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx8.69"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx8.70">as</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx8.71"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx8.72">a</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx8.73"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx8.74">new</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx8.75"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx8.76">generational</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx8.77"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx8.78">mode</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx8.79"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx8.80">for</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx8.81"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx8.82">garbage</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx8.83"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx8.84">collection</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx8.85">,</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx8.86"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx8.87">const</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx8.88"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx8.89">variables</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx8.90">,</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx8.91"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx8.92">and</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx8.93"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx8.94">to</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx8.95">-</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx8.96">be</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx8.97">-</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx8.98">closed</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx8.99"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx8.100">variables</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx8.101">."</span>
</div>
<div class="ltx_listingline" id="lstnumberx9">
<span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx9.1"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx9.2">}</span>
</div>
<div class="ltx_listingline" id="lstnumberx10">
<span class="ltx_text ltx_font_typewriter" id="lstnumberx10.1">]</span>
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>A Sample from TÜLU-V2-mix.</figcaption>
</figure>
<div class="ltx_para" id="A2.SS2.p2">
<p class="ltx_p" id="A2.SS2.p2.1">The "messages" format is particularly useful for training conversational models as it simulates multi-turn conversations by incorporating alternating roles between user and assistant messages. This format ensures a clear distinction between user inputs and the model’s responses. Additionally, during fine-tuning, the loss function is applied specifically to messages with the role "assistant," to focus optimization on improving response generation. We applied this format to structure the whole training dataset.</p>
</div>
</section>
<section class="ltx_subsection" id="A2.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.3 </span>Translation to Darija</h3>
<section class="ltx_subsubsection" id="A2.SS3.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">B.3.1 </span>Preprocessing</h4>
<div class="ltx_para" id="A2.SS3.SSS1.p1">
<p class="ltx_p" id="A2.SS3.SSS1.p1.1">Before translating the dataset into Darija, we applied several filters to ensure that the translation meets our quality requirements:</p>
<ul class="ltx_itemize" id="A2.I2">
<li class="ltx_item" id="A2.I2.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A2.I2.i1.p1">
<p class="ltx_p" id="A2.I2.i1.p1.1"><span class="ltx_text ltx_font_bold" id="A2.I2.i1.p1.1.1">Excluding the Science subset:</span> We removed this part because the questions often involved parts or entire sections from research articles, which could lose meaning or coherence when translated, particularly into Darija. Additionally, we considered that a typical Darija-speaking user is unlikely to ask the model about research papers in Darija, as they would more commonly use English for such inquiries.</p>
</div>
</li>
<li class="ltx_item" id="A2.I2.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A2.I2.i2.p1">
<p class="ltx_p" id="A2.I2.i2.p1.1"><span class="ltx_text ltx_font_bold" id="A2.I2.i2.p1.1.1">Filtering out empty messages:</span> Based on a reported issue<span class="ltx_note ltx_role_footnote" id="footnote46"><sup class="ltx_note_mark">46</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">46</sup><span class="ltx_tag ltx_tag_note">46</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/allenai/open-instruct/issues/161" title="">https://github.com/allenai/open-instruct/issues/161</a></span></span></span>, we discovered that some examples contained turns where the message role was defined, but the content was empty. To ensure data quality, we removed all such samples from the dataset.</p>
</div>
</li>
<li class="ltx_item" id="A2.I2.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A2.I2.i3.p1">
<p class="ltx_p" id="A2.I2.i3.p1.1"><span class="ltx_text ltx_font_bold" id="A2.I2.i3.p1.1.1">Removing translation tasks:</span> We decided to omit translation instructions because translating both the source and target sentences into Darija would result in redundant outputs. Even if we specify that only the target sentence should be translated, it would be challenging to consistently ensure that the model performing the Darija translation adheres to the instruction across all examples. Additionally, verifying the quality of the translations would be challenging, particularly when the original meaning could be distorted. Furthermore, we already possess high-quality translation datasets, so including lower-quality translations would only degrade the overall dataset quality.
<br class="ltx_break"/>To filter out translation tasks, we removed all samples containing either the strings "translate " or " translation ". We recognize that this method might exclude some instances where translation is mentioned without being the core task, for example, the user might be asking about the definition of the word "translation". However, given the large size of TÜLU-V2-mix, we believe such cases are rare, and the potential loss of a few samples would not impact the dataset’s overall quality.</p>
</div>
</li>
<li class="ltx_item" id="A2.I2.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A2.I2.i4.p1">
<p class="ltx_p" id="A2.I2.i4.p1.1"><span class="ltx_text ltx_font_bold" id="A2.I2.i4.p1.1.1">Excluding non-English samples:</span> We filtered out non-English examples to ensure higher translation quality, as translating from English to Darija tends to yield more accurate results compared to translations from other languages, especially those with low resources.
<br class="ltx_break"/>To implement this filter, we used one of the best language identification tools: the fastText Language Identification model<span class="ltx_note ltx_role_footnote" id="footnote47"><sup class="ltx_note_mark">47</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">47</sup><span class="ltx_tag ltx_tag_note">47</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://hf.co/facebook/fasttext-language-identification" title="">https://hf.co/facebook/fasttext-language-identification</a></span></span></span>. We set <span class="ltx_text ltx_font_typewriter" id="A2.I2.i4.p1.1.2">k=2</span>, meaning the model predicts the two most likely languages for each input text and provides a probability score for each. We excluded any samples where the most likely language was not English, as well as those labeled as English with a confidence score below 80%. Through multiple experiments, we found that purely English texts typically score close to 100%, while lower scores often indicate the presence of other languages mixed with English.</p>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_subsubsection" id="A2.SS3.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">B.3.2 </span>Translation</h4>
<div class="ltx_para" id="A2.SS3.SSS2.p1">
<p class="ltx_p" id="A2.SS3.SSS2.p1.1">We experimented with several open-source and closed-source Darija translation models, including NLLB-200-3.3B<span class="ltx_note ltx_role_footnote" id="footnote48"><sup class="ltx_note_mark">48</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">48</sup><span class="ltx_tag ltx_tag_note">48</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://hf.co/facebook/nllb-200-3.3B" title="">https://hf.co/facebook/nllb-200-3.3B</a></span></span></span> (No Language Left Behind<span class="ltx_note ltx_role_footnote" id="footnote49"><sup class="ltx_note_mark">49</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">49</sup><span class="ltx_tag ltx_tag_note">49</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://ai.meta.com/research/no-language-left-behind" title="">https://ai.meta.com/research/no-language-left-behind</a></span></span></span>), Terjman-Ultra<span class="ltx_note ltx_role_footnote" id="footnote50"><sup class="ltx_note_mark">50</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">50</sup><span class="ltx_tag ltx_tag_note">50</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://hf.co/atlasia/Terjman-Ultra" title="">https://hf.co/atlasia/Terjman-Ultra</a></span></span></span>, GPT-4o<span class="ltx_note ltx_role_footnote" id="footnote51"><sup class="ltx_note_mark">51</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">51</sup><span class="ltx_tag ltx_tag_note">51</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://openai.com/index/hello-gpt-4o" title="">https://openai.com/index/hello-gpt-4o</a></span></span></span>, Claude 3 Opus<span class="ltx_note ltx_role_footnote" id="footnote52"><sup class="ltx_note_mark">52</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">52</sup><span class="ltx_tag ltx_tag_note">52</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.anthropic.com/news/claude-3-family" title="">https://www.anthropic.com/news/claude-3-family</a></span></span></span>, and Claude 3.5 Sonnet<span class="ltx_note ltx_role_footnote" id="footnote53"><sup class="ltx_note_mark">53</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">53</sup><span class="ltx_tag ltx_tag_note">53</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.anthropic.com/news/claude-3-5-sonnet" title="">https://www.anthropic.com/news/claude-3-5-sonnet</a></span></span></span>. Our results showed that closed-source models consistently outperformed open-source alternatives, with GPT-4o and Claude 3.5 Sonnet taking the lead. We ultimately chose <span class="ltx_text ltx_font_bold" id="A2.SS3.SSS2.p1.1.1">Claude 3.5 Sonnet</span>, as it slightly outperformed GPT-4o and offered compatibility with Amazon Bedrock.
Table <a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#A2.T4" title="Table 4 ‣ B.3.2 Translation ‣ B.3 Translation to Darija ‣ Appendix B TÜLU-V2-mix and its translation ‣ Atlas-Chat: Adapting Large Language Models for Low-Resource Moroccan Arabic Dialect"><span class="ltx_text ltx_ref_tag">4</span></a> shows a comparison of an instruction translated to Darija using each of the models we tested. We observed that open-source models, namely NLLB-200-3.3B and Terjman-Ultra, tend to use more MSA, while closed-source models produce translations closer to Moroccan Darija. They also retain key formatting elements like line breaks (\n) and tags (###), which are crucial for preserving the structure of the instructions.</p>
</div>
<figure class="ltx_table" id="A2.T4">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="A2.T4.15">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A2.T4.15.16.1">
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_t" id="A2.T4.15.16.1.1" style="padding-top:2pt;padding-bottom:2pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.T4.15.16.1.1.1">
<span class="ltx_p" id="A2.T4.15.16.1.1.1.1" style="width:45.5pt;"><span class="ltx_text ltx_font_bold" id="A2.T4.15.16.1.1.1.1.1">Original Sentence</span></span>
</span>
</th>
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_t" id="A2.T4.15.16.1.2" style="padding-top:2pt;padding-bottom:2pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.T4.15.16.1.2.1">
<span class="ltx_p" id="A2.T4.15.16.1.2.1.1" style="width:352.8pt;"><span class="ltx_text ltx_font_typewriter" id="A2.T4.15.16.1.2.1.1.1">Write a response that appropriately completes the request.\n\n### Instruction:\nIdentify four positive impacts that artificial intelligence can have on the healthcare industry\n\n### Response:</span></span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A2.T4.15.17.1">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A2.T4.15.17.1.1" style="padding-top:2pt;padding-bottom:2pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.T4.15.17.1.1.1">
<span class="ltx_p" id="A2.T4.15.17.1.1.1.1" style="width:45.5pt;"><span class="ltx_text ltx_font_bold" id="A2.T4.15.17.1.1.1.1.1">NLLB-200-3.3B</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A2.T4.15.17.1.2" style="padding-top:2pt;padding-bottom:2pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.T4.15.17.1.2.1">
<span class="ltx_p" id="A2.T4.15.17.1.2.1.1" style="width:352.8pt;"><span class="ltx_ERROR undefined" id="A2.T4.15.17.1.2.1.1.1">\setcode</span>utf8<span class="ltx_ERROR undefined" id="A2.T4.15.17.1.2.1.1.2">{arabtext}</span>
كتب رد يكمل الطلب بشكل مناسب. ### التعليمات: حدد أربعة من التأثيرات الإيجابية التي يمكن لذكاء اصطناعي أن يكون لها على صناعة الرعاية الصحية ### الرد:</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A2.T4.15.18.2">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A2.T4.15.18.2.1" style="padding-top:2pt;padding-bottom:2pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.T4.15.18.2.1.1">
<span class="ltx_p" id="A2.T4.15.18.2.1.1.1" style="width:45.5pt;"><span class="ltx_text ltx_font_bold" id="A2.T4.15.18.2.1.1.1.1">Terjman-Ultra</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A2.T4.15.18.2.2" style="padding-top:2pt;padding-bottom:2pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.T4.15.18.2.2.1">
<span class="ltx_p" id="A2.T4.15.18.2.2.1.1" style="width:352.8pt;"><span class="ltx_ERROR undefined" id="A2.T4.15.18.2.2.1.1.1">\setcode</span>utf8<span class="ltx_ERROR undefined" id="A2.T4.15.18.2.2.1.1.2">{arabtext}</span>
كتبي رد ياكمل الطلب بشكل مناسب. ### تعليمات: حدد أربعة تأثيرات إيجابية يمكن لذكاء اصطناعي أن يكون لها على صناعة الرعاية الصحية ### رد:</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A2.T4.5.5">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A2.T4.5.5.6" style="padding-top:2pt;padding-bottom:2pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.T4.5.5.6.1">
<span class="ltx_p" id="A2.T4.5.5.6.1.1" style="width:45.5pt;"><span class="ltx_text ltx_font_bold" id="A2.T4.5.5.6.1.1.1">GPT-4o</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A2.T4.5.5.5" style="padding-top:2pt;padding-bottom:2pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.T4.5.5.5.5">
<span class="ltx_p" id="A2.T4.5.5.5.5.5" style="width:352.8pt;"><span class="ltx_ERROR undefined" id="A2.T4.5.5.5.5.5.1">\setcode</span>utf8<span class="ltx_ERROR undefined" id="A2.T4.5.5.5.5.5.2">{arabtext}</span>
كتب رد كيكمّل الطّلب بشكل مناسب.<math alttext="\backslash n" class="ltx_Math" display="inline" id="A2.T4.1.1.1.1.1.m1.1"><semantics id="A2.T4.1.1.1.1.1.m1.1a"><mrow id="A2.T4.1.1.1.1.1.m1.1.1" xref="A2.T4.1.1.1.1.1.m1.1.1.cmml"><mi id="A2.T4.1.1.1.1.1.m1.1.1.2" xref="A2.T4.1.1.1.1.1.m1.1.1.2.cmml"></mi><mo id="A2.T4.1.1.1.1.1.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="A2.T4.1.1.1.1.1.m1.1.1.1.cmml">\</mo><mi id="A2.T4.1.1.1.1.1.m1.1.1.3" xref="A2.T4.1.1.1.1.1.m1.1.1.3.cmml">n</mi></mrow><annotation-xml encoding="MathML-Content" id="A2.T4.1.1.1.1.1.m1.1b"><apply id="A2.T4.1.1.1.1.1.m1.1.1.cmml" xref="A2.T4.1.1.1.1.1.m1.1.1"><ci id="A2.T4.1.1.1.1.1.m1.1.1.1.cmml" xref="A2.T4.1.1.1.1.1.m1.1.1.1">\</ci><csymbol cd="latexml" id="A2.T4.1.1.1.1.1.m1.1.1.2.cmml" xref="A2.T4.1.1.1.1.1.m1.1.1.2">absent</csymbol><ci id="A2.T4.1.1.1.1.1.m1.1.1.3.cmml" xref="A2.T4.1.1.1.1.1.m1.1.1.3">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.T4.1.1.1.1.1.m1.1c">\backslash n</annotation><annotation encoding="application/x-llamapun" id="A2.T4.1.1.1.1.1.m1.1d">\ italic_n</annotation></semantics></math><math alttext="\backslash n" class="ltx_Math" display="inline" id="A2.T4.2.2.2.2.2.m2.1"><semantics id="A2.T4.2.2.2.2.2.m2.1a"><mrow id="A2.T4.2.2.2.2.2.m2.1.1" xref="A2.T4.2.2.2.2.2.m2.1.1.cmml"><mi id="A2.T4.2.2.2.2.2.m2.1.1.2" xref="A2.T4.2.2.2.2.2.m2.1.1.2.cmml"></mi><mo id="A2.T4.2.2.2.2.2.m2.1.1.1" lspace="0.222em" rspace="0.222em" xref="A2.T4.2.2.2.2.2.m2.1.1.1.cmml">\</mo><mi id="A2.T4.2.2.2.2.2.m2.1.1.3" xref="A2.T4.2.2.2.2.2.m2.1.1.3.cmml">n</mi></mrow><annotation-xml encoding="MathML-Content" id="A2.T4.2.2.2.2.2.m2.1b"><apply id="A2.T4.2.2.2.2.2.m2.1.1.cmml" xref="A2.T4.2.2.2.2.2.m2.1.1"><ci id="A2.T4.2.2.2.2.2.m2.1.1.1.cmml" xref="A2.T4.2.2.2.2.2.m2.1.1.1">\</ci><csymbol cd="latexml" id="A2.T4.2.2.2.2.2.m2.1.1.2.cmml" xref="A2.T4.2.2.2.2.2.m2.1.1.2">absent</csymbol><ci id="A2.T4.2.2.2.2.2.m2.1.1.3.cmml" xref="A2.T4.2.2.2.2.2.m2.1.1.3">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.T4.2.2.2.2.2.m2.1c">\backslash n</annotation><annotation encoding="application/x-llamapun" id="A2.T4.2.2.2.2.2.m2.1d">\ italic_n</annotation></semantics></math>### التعليمات:<math alttext="\backslash n" class="ltx_Math" display="inline" id="A2.T4.3.3.3.3.3.m3.1"><semantics id="A2.T4.3.3.3.3.3.m3.1a"><mrow id="A2.T4.3.3.3.3.3.m3.1.1" xref="A2.T4.3.3.3.3.3.m3.1.1.cmml"><mi id="A2.T4.3.3.3.3.3.m3.1.1.2" xref="A2.T4.3.3.3.3.3.m3.1.1.2.cmml"></mi><mo id="A2.T4.3.3.3.3.3.m3.1.1.1" lspace="0.222em" rspace="0.222em" xref="A2.T4.3.3.3.3.3.m3.1.1.1.cmml">\</mo><mi id="A2.T4.3.3.3.3.3.m3.1.1.3" xref="A2.T4.3.3.3.3.3.m3.1.1.3.cmml">n</mi></mrow><annotation-xml encoding="MathML-Content" id="A2.T4.3.3.3.3.3.m3.1b"><apply id="A2.T4.3.3.3.3.3.m3.1.1.cmml" xref="A2.T4.3.3.3.3.3.m3.1.1"><ci id="A2.T4.3.3.3.3.3.m3.1.1.1.cmml" xref="A2.T4.3.3.3.3.3.m3.1.1.1">\</ci><csymbol cd="latexml" id="A2.T4.3.3.3.3.3.m3.1.1.2.cmml" xref="A2.T4.3.3.3.3.3.m3.1.1.2">absent</csymbol><ci id="A2.T4.3.3.3.3.3.m3.1.1.3.cmml" xref="A2.T4.3.3.3.3.3.m3.1.1.3">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.T4.3.3.3.3.3.m3.1c">\backslash n</annotation><annotation encoding="application/x-llamapun" id="A2.T4.3.3.3.3.3.m3.1d">\ italic_n</annotation></semantics></math>حدّد أربع تأثيرات إيجابية اللي الذكاء الاصطناعي يمكن يكون عندو على قطاع الرعاية الصحية<math alttext="\backslash n" class="ltx_Math" display="inline" id="A2.T4.4.4.4.4.4.m4.1"><semantics id="A2.T4.4.4.4.4.4.m4.1a"><mrow id="A2.T4.4.4.4.4.4.m4.1.1" xref="A2.T4.4.4.4.4.4.m4.1.1.cmml"><mi id="A2.T4.4.4.4.4.4.m4.1.1.2" xref="A2.T4.4.4.4.4.4.m4.1.1.2.cmml"></mi><mo id="A2.T4.4.4.4.4.4.m4.1.1.1" lspace="0.222em" rspace="0.222em" xref="A2.T4.4.4.4.4.4.m4.1.1.1.cmml">\</mo><mi id="A2.T4.4.4.4.4.4.m4.1.1.3" xref="A2.T4.4.4.4.4.4.m4.1.1.3.cmml">n</mi></mrow><annotation-xml encoding="MathML-Content" id="A2.T4.4.4.4.4.4.m4.1b"><apply id="A2.T4.4.4.4.4.4.m4.1.1.cmml" xref="A2.T4.4.4.4.4.4.m4.1.1"><ci id="A2.T4.4.4.4.4.4.m4.1.1.1.cmml" xref="A2.T4.4.4.4.4.4.m4.1.1.1">\</ci><csymbol cd="latexml" id="A2.T4.4.4.4.4.4.m4.1.1.2.cmml" xref="A2.T4.4.4.4.4.4.m4.1.1.2">absent</csymbol><ci id="A2.T4.4.4.4.4.4.m4.1.1.3.cmml" xref="A2.T4.4.4.4.4.4.m4.1.1.3">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.T4.4.4.4.4.4.m4.1c">\backslash n</annotation><annotation encoding="application/x-llamapun" id="A2.T4.4.4.4.4.4.m4.1d">\ italic_n</annotation></semantics></math><math alttext="\backslash n" class="ltx_Math" display="inline" id="A2.T4.5.5.5.5.5.m5.1"><semantics id="A2.T4.5.5.5.5.5.m5.1a"><mrow id="A2.T4.5.5.5.5.5.m5.1.1" xref="A2.T4.5.5.5.5.5.m5.1.1.cmml"><mi id="A2.T4.5.5.5.5.5.m5.1.1.2" xref="A2.T4.5.5.5.5.5.m5.1.1.2.cmml"></mi><mo id="A2.T4.5.5.5.5.5.m5.1.1.1" lspace="0.222em" rspace="0.222em" xref="A2.T4.5.5.5.5.5.m5.1.1.1.cmml">\</mo><mi id="A2.T4.5.5.5.5.5.m5.1.1.3" xref="A2.T4.5.5.5.5.5.m5.1.1.3.cmml">n</mi></mrow><annotation-xml encoding="MathML-Content" id="A2.T4.5.5.5.5.5.m5.1b"><apply id="A2.T4.5.5.5.5.5.m5.1.1.cmml" xref="A2.T4.5.5.5.5.5.m5.1.1"><ci id="A2.T4.5.5.5.5.5.m5.1.1.1.cmml" xref="A2.T4.5.5.5.5.5.m5.1.1.1">\</ci><csymbol cd="latexml" id="A2.T4.5.5.5.5.5.m5.1.1.2.cmml" xref="A2.T4.5.5.5.5.5.m5.1.1.2">absent</csymbol><ci id="A2.T4.5.5.5.5.5.m5.1.1.3.cmml" xref="A2.T4.5.5.5.5.5.m5.1.1.3">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.T4.5.5.5.5.5.m5.1c">\backslash n</annotation><annotation encoding="application/x-llamapun" id="A2.T4.5.5.5.5.5.m5.1d">\ italic_n</annotation></semantics></math>### الرد:</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A2.T4.10.10">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A2.T4.10.10.6" style="padding-top:2pt;padding-bottom:2pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.T4.10.10.6.1">
<span class="ltx_p" id="A2.T4.10.10.6.1.1" style="width:45.5pt;"><span class="ltx_text ltx_font_bold" id="A2.T4.10.10.6.1.1.1">Claude 3 Opus</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A2.T4.10.10.5" style="padding-top:2pt;padding-bottom:2pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.T4.10.10.5.5">
<span class="ltx_p" id="A2.T4.10.10.5.5.5" style="width:352.8pt;"><span class="ltx_ERROR undefined" id="A2.T4.10.10.5.5.5.1">\setcode</span>utf8<span class="ltx_ERROR undefined" id="A2.T4.10.10.5.5.5.2">{arabtext}</span>
أكتب جواب لي يكمل الطلب بشكل مناسب.<math alttext="\backslash n" class="ltx_Math" display="inline" id="A2.T4.6.6.1.1.1.m1.1"><semantics id="A2.T4.6.6.1.1.1.m1.1a"><mrow id="A2.T4.6.6.1.1.1.m1.1.1" xref="A2.T4.6.6.1.1.1.m1.1.1.cmml"><mi id="A2.T4.6.6.1.1.1.m1.1.1.2" xref="A2.T4.6.6.1.1.1.m1.1.1.2.cmml"></mi><mo id="A2.T4.6.6.1.1.1.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="A2.T4.6.6.1.1.1.m1.1.1.1.cmml">\</mo><mi id="A2.T4.6.6.1.1.1.m1.1.1.3" xref="A2.T4.6.6.1.1.1.m1.1.1.3.cmml">n</mi></mrow><annotation-xml encoding="MathML-Content" id="A2.T4.6.6.1.1.1.m1.1b"><apply id="A2.T4.6.6.1.1.1.m1.1.1.cmml" xref="A2.T4.6.6.1.1.1.m1.1.1"><ci id="A2.T4.6.6.1.1.1.m1.1.1.1.cmml" xref="A2.T4.6.6.1.1.1.m1.1.1.1">\</ci><csymbol cd="latexml" id="A2.T4.6.6.1.1.1.m1.1.1.2.cmml" xref="A2.T4.6.6.1.1.1.m1.1.1.2">absent</csymbol><ci id="A2.T4.6.6.1.1.1.m1.1.1.3.cmml" xref="A2.T4.6.6.1.1.1.m1.1.1.3">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.T4.6.6.1.1.1.m1.1c">\backslash n</annotation><annotation encoding="application/x-llamapun" id="A2.T4.6.6.1.1.1.m1.1d">\ italic_n</annotation></semantics></math><math alttext="\backslash n" class="ltx_Math" display="inline" id="A2.T4.7.7.2.2.2.m2.1"><semantics id="A2.T4.7.7.2.2.2.m2.1a"><mrow id="A2.T4.7.7.2.2.2.m2.1.1" xref="A2.T4.7.7.2.2.2.m2.1.1.cmml"><mi id="A2.T4.7.7.2.2.2.m2.1.1.2" xref="A2.T4.7.7.2.2.2.m2.1.1.2.cmml"></mi><mo id="A2.T4.7.7.2.2.2.m2.1.1.1" lspace="0.222em" rspace="0.222em" xref="A2.T4.7.7.2.2.2.m2.1.1.1.cmml">\</mo><mi id="A2.T4.7.7.2.2.2.m2.1.1.3" xref="A2.T4.7.7.2.2.2.m2.1.1.3.cmml">n</mi></mrow><annotation-xml encoding="MathML-Content" id="A2.T4.7.7.2.2.2.m2.1b"><apply id="A2.T4.7.7.2.2.2.m2.1.1.cmml" xref="A2.T4.7.7.2.2.2.m2.1.1"><ci id="A2.T4.7.7.2.2.2.m2.1.1.1.cmml" xref="A2.T4.7.7.2.2.2.m2.1.1.1">\</ci><csymbol cd="latexml" id="A2.T4.7.7.2.2.2.m2.1.1.2.cmml" xref="A2.T4.7.7.2.2.2.m2.1.1.2">absent</csymbol><ci id="A2.T4.7.7.2.2.2.m2.1.1.3.cmml" xref="A2.T4.7.7.2.2.2.m2.1.1.3">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.T4.7.7.2.2.2.m2.1c">\backslash n</annotation><annotation encoding="application/x-llamapun" id="A2.T4.7.7.2.2.2.m2.1d">\ italic_n</annotation></semantics></math>### التعليمات:<math alttext="\backslash n" class="ltx_Math" display="inline" id="A2.T4.8.8.3.3.3.m3.1"><semantics id="A2.T4.8.8.3.3.3.m3.1a"><mrow id="A2.T4.8.8.3.3.3.m3.1.1" xref="A2.T4.8.8.3.3.3.m3.1.1.cmml"><mi id="A2.T4.8.8.3.3.3.m3.1.1.2" xref="A2.T4.8.8.3.3.3.m3.1.1.2.cmml"></mi><mo id="A2.T4.8.8.3.3.3.m3.1.1.1" lspace="0.222em" rspace="0.222em" xref="A2.T4.8.8.3.3.3.m3.1.1.1.cmml">\</mo><mi id="A2.T4.8.8.3.3.3.m3.1.1.3" xref="A2.T4.8.8.3.3.3.m3.1.1.3.cmml">n</mi></mrow><annotation-xml encoding="MathML-Content" id="A2.T4.8.8.3.3.3.m3.1b"><apply id="A2.T4.8.8.3.3.3.m3.1.1.cmml" xref="A2.T4.8.8.3.3.3.m3.1.1"><ci id="A2.T4.8.8.3.3.3.m3.1.1.1.cmml" xref="A2.T4.8.8.3.3.3.m3.1.1.1">\</ci><csymbol cd="latexml" id="A2.T4.8.8.3.3.3.m3.1.1.2.cmml" xref="A2.T4.8.8.3.3.3.m3.1.1.2">absent</csymbol><ci id="A2.T4.8.8.3.3.3.m3.1.1.3.cmml" xref="A2.T4.8.8.3.3.3.m3.1.1.3">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.T4.8.8.3.3.3.m3.1c">\backslash n</annotation><annotation encoding="application/x-llamapun" id="A2.T4.8.8.3.3.3.m3.1d">\ italic_n</annotation></semantics></math>عرف أربع تأثيرات إيجابية لي يمكن للذكاء الاصطناعي يكون عندو على قطاع الصحة<math alttext="\backslash n" class="ltx_Math" display="inline" id="A2.T4.9.9.4.4.4.m4.1"><semantics id="A2.T4.9.9.4.4.4.m4.1a"><mrow id="A2.T4.9.9.4.4.4.m4.1.1" xref="A2.T4.9.9.4.4.4.m4.1.1.cmml"><mi id="A2.T4.9.9.4.4.4.m4.1.1.2" xref="A2.T4.9.9.4.4.4.m4.1.1.2.cmml"></mi><mo id="A2.T4.9.9.4.4.4.m4.1.1.1" lspace="0.222em" rspace="0.222em" xref="A2.T4.9.9.4.4.4.m4.1.1.1.cmml">\</mo><mi id="A2.T4.9.9.4.4.4.m4.1.1.3" xref="A2.T4.9.9.4.4.4.m4.1.1.3.cmml">n</mi></mrow><annotation-xml encoding="MathML-Content" id="A2.T4.9.9.4.4.4.m4.1b"><apply id="A2.T4.9.9.4.4.4.m4.1.1.cmml" xref="A2.T4.9.9.4.4.4.m4.1.1"><ci id="A2.T4.9.9.4.4.4.m4.1.1.1.cmml" xref="A2.T4.9.9.4.4.4.m4.1.1.1">\</ci><csymbol cd="latexml" id="A2.T4.9.9.4.4.4.m4.1.1.2.cmml" xref="A2.T4.9.9.4.4.4.m4.1.1.2">absent</csymbol><ci id="A2.T4.9.9.4.4.4.m4.1.1.3.cmml" xref="A2.T4.9.9.4.4.4.m4.1.1.3">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.T4.9.9.4.4.4.m4.1c">\backslash n</annotation><annotation encoding="application/x-llamapun" id="A2.T4.9.9.4.4.4.m4.1d">\ italic_n</annotation></semantics></math><math alttext="\backslash n" class="ltx_Math" display="inline" id="A2.T4.10.10.5.5.5.m5.1"><semantics id="A2.T4.10.10.5.5.5.m5.1a"><mrow id="A2.T4.10.10.5.5.5.m5.1.1" xref="A2.T4.10.10.5.5.5.m5.1.1.cmml"><mi id="A2.T4.10.10.5.5.5.m5.1.1.2" xref="A2.T4.10.10.5.5.5.m5.1.1.2.cmml"></mi><mo id="A2.T4.10.10.5.5.5.m5.1.1.1" lspace="0.222em" rspace="0.222em" xref="A2.T4.10.10.5.5.5.m5.1.1.1.cmml">\</mo><mi id="A2.T4.10.10.5.5.5.m5.1.1.3" xref="A2.T4.10.10.5.5.5.m5.1.1.3.cmml">n</mi></mrow><annotation-xml encoding="MathML-Content" id="A2.T4.10.10.5.5.5.m5.1b"><apply id="A2.T4.10.10.5.5.5.m5.1.1.cmml" xref="A2.T4.10.10.5.5.5.m5.1.1"><ci id="A2.T4.10.10.5.5.5.m5.1.1.1.cmml" xref="A2.T4.10.10.5.5.5.m5.1.1.1">\</ci><csymbol cd="latexml" id="A2.T4.10.10.5.5.5.m5.1.1.2.cmml" xref="A2.T4.10.10.5.5.5.m5.1.1.2">absent</csymbol><ci id="A2.T4.10.10.5.5.5.m5.1.1.3.cmml" xref="A2.T4.10.10.5.5.5.m5.1.1.3">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.T4.10.10.5.5.5.m5.1c">\backslash n</annotation><annotation encoding="application/x-llamapun" id="A2.T4.10.10.5.5.5.m5.1d">\ italic_n</annotation></semantics></math>### الجواب:</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A2.T4.15.15">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_b" id="A2.T4.15.15.6" style="padding-top:2pt;padding-bottom:2pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.T4.15.15.6.1">
<span class="ltx_p" id="A2.T4.15.15.6.1.1" style="width:45.5pt;"><span class="ltx_text ltx_font_bold" id="A2.T4.15.15.6.1.1.1">Claude 3.5</span>
<span class="ltx_text ltx_font_bold" id="A2.T4.15.15.6.1.1.2">Sonnet</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_b" id="A2.T4.15.15.5" style="padding-top:2pt;padding-bottom:2pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.T4.15.15.5.5">
<span class="ltx_p" id="A2.T4.15.15.5.5.5" style="width:352.8pt;"><span class="ltx_ERROR undefined" id="A2.T4.15.15.5.5.5.1">\setcode</span>utf8<span class="ltx_ERROR undefined" id="A2.T4.15.15.5.5.5.2">{arabtext}</span>
اكتب جواب اللي يكمل الطلب بشكل مناسب.<math alttext="\backslash n" class="ltx_Math" display="inline" id="A2.T4.11.11.1.1.1.m1.1"><semantics id="A2.T4.11.11.1.1.1.m1.1a"><mrow id="A2.T4.11.11.1.1.1.m1.1.1" xref="A2.T4.11.11.1.1.1.m1.1.1.cmml"><mi id="A2.T4.11.11.1.1.1.m1.1.1.2" xref="A2.T4.11.11.1.1.1.m1.1.1.2.cmml"></mi><mo id="A2.T4.11.11.1.1.1.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="A2.T4.11.11.1.1.1.m1.1.1.1.cmml">\</mo><mi id="A2.T4.11.11.1.1.1.m1.1.1.3" xref="A2.T4.11.11.1.1.1.m1.1.1.3.cmml">n</mi></mrow><annotation-xml encoding="MathML-Content" id="A2.T4.11.11.1.1.1.m1.1b"><apply id="A2.T4.11.11.1.1.1.m1.1.1.cmml" xref="A2.T4.11.11.1.1.1.m1.1.1"><ci id="A2.T4.11.11.1.1.1.m1.1.1.1.cmml" xref="A2.T4.11.11.1.1.1.m1.1.1.1">\</ci><csymbol cd="latexml" id="A2.T4.11.11.1.1.1.m1.1.1.2.cmml" xref="A2.T4.11.11.1.1.1.m1.1.1.2">absent</csymbol><ci id="A2.T4.11.11.1.1.1.m1.1.1.3.cmml" xref="A2.T4.11.11.1.1.1.m1.1.1.3">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.T4.11.11.1.1.1.m1.1c">\backslash n</annotation><annotation encoding="application/x-llamapun" id="A2.T4.11.11.1.1.1.m1.1d">\ italic_n</annotation></semantics></math><math alttext="\backslash n" class="ltx_Math" display="inline" id="A2.T4.12.12.2.2.2.m2.1"><semantics id="A2.T4.12.12.2.2.2.m2.1a"><mrow id="A2.T4.12.12.2.2.2.m2.1.1" xref="A2.T4.12.12.2.2.2.m2.1.1.cmml"><mi id="A2.T4.12.12.2.2.2.m2.1.1.2" xref="A2.T4.12.12.2.2.2.m2.1.1.2.cmml"></mi><mo id="A2.T4.12.12.2.2.2.m2.1.1.1" lspace="0.222em" rspace="0.222em" xref="A2.T4.12.12.2.2.2.m2.1.1.1.cmml">\</mo><mi id="A2.T4.12.12.2.2.2.m2.1.1.3" xref="A2.T4.12.12.2.2.2.m2.1.1.3.cmml">n</mi></mrow><annotation-xml encoding="MathML-Content" id="A2.T4.12.12.2.2.2.m2.1b"><apply id="A2.T4.12.12.2.2.2.m2.1.1.cmml" xref="A2.T4.12.12.2.2.2.m2.1.1"><ci id="A2.T4.12.12.2.2.2.m2.1.1.1.cmml" xref="A2.T4.12.12.2.2.2.m2.1.1.1">\</ci><csymbol cd="latexml" id="A2.T4.12.12.2.2.2.m2.1.1.2.cmml" xref="A2.T4.12.12.2.2.2.m2.1.1.2">absent</csymbol><ci id="A2.T4.12.12.2.2.2.m2.1.1.3.cmml" xref="A2.T4.12.12.2.2.2.m2.1.1.3">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.T4.12.12.2.2.2.m2.1c">\backslash n</annotation><annotation encoding="application/x-llamapun" id="A2.T4.12.12.2.2.2.m2.1d">\ italic_n</annotation></semantics></math>### التعليمات:<math alttext="\backslash n" class="ltx_Math" display="inline" id="A2.T4.13.13.3.3.3.m3.1"><semantics id="A2.T4.13.13.3.3.3.m3.1a"><mrow id="A2.T4.13.13.3.3.3.m3.1.1" xref="A2.T4.13.13.3.3.3.m3.1.1.cmml"><mi id="A2.T4.13.13.3.3.3.m3.1.1.2" xref="A2.T4.13.13.3.3.3.m3.1.1.2.cmml"></mi><mo id="A2.T4.13.13.3.3.3.m3.1.1.1" lspace="0.222em" rspace="0.222em" xref="A2.T4.13.13.3.3.3.m3.1.1.1.cmml">\</mo><mi id="A2.T4.13.13.3.3.3.m3.1.1.3" xref="A2.T4.13.13.3.3.3.m3.1.1.3.cmml">n</mi></mrow><annotation-xml encoding="MathML-Content" id="A2.T4.13.13.3.3.3.m3.1b"><apply id="A2.T4.13.13.3.3.3.m3.1.1.cmml" xref="A2.T4.13.13.3.3.3.m3.1.1"><ci id="A2.T4.13.13.3.3.3.m3.1.1.1.cmml" xref="A2.T4.13.13.3.3.3.m3.1.1.1">\</ci><csymbol cd="latexml" id="A2.T4.13.13.3.3.3.m3.1.1.2.cmml" xref="A2.T4.13.13.3.3.3.m3.1.1.2">absent</csymbol><ci id="A2.T4.13.13.3.3.3.m3.1.1.3.cmml" xref="A2.T4.13.13.3.3.3.m3.1.1.3">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.T4.13.13.3.3.3.m3.1c">\backslash n</annotation><annotation encoding="application/x-llamapun" id="A2.T4.13.13.3.3.3.m3.1d">\ italic_n</annotation></semantics></math>حدد أربعة تأثيرات إيجابية اللي يمكن للذكاء الاصطناعي يديرها على قطاع الصحة<math alttext="\backslash n" class="ltx_Math" display="inline" id="A2.T4.14.14.4.4.4.m4.1"><semantics id="A2.T4.14.14.4.4.4.m4.1a"><mrow id="A2.T4.14.14.4.4.4.m4.1.1" xref="A2.T4.14.14.4.4.4.m4.1.1.cmml"><mi id="A2.T4.14.14.4.4.4.m4.1.1.2" xref="A2.T4.14.14.4.4.4.m4.1.1.2.cmml"></mi><mo id="A2.T4.14.14.4.4.4.m4.1.1.1" lspace="0.222em" rspace="0.222em" xref="A2.T4.14.14.4.4.4.m4.1.1.1.cmml">\</mo><mi id="A2.T4.14.14.4.4.4.m4.1.1.3" xref="A2.T4.14.14.4.4.4.m4.1.1.3.cmml">n</mi></mrow><annotation-xml encoding="MathML-Content" id="A2.T4.14.14.4.4.4.m4.1b"><apply id="A2.T4.14.14.4.4.4.m4.1.1.cmml" xref="A2.T4.14.14.4.4.4.m4.1.1"><ci id="A2.T4.14.14.4.4.4.m4.1.1.1.cmml" xref="A2.T4.14.14.4.4.4.m4.1.1.1">\</ci><csymbol cd="latexml" id="A2.T4.14.14.4.4.4.m4.1.1.2.cmml" xref="A2.T4.14.14.4.4.4.m4.1.1.2">absent</csymbol><ci id="A2.T4.14.14.4.4.4.m4.1.1.3.cmml" xref="A2.T4.14.14.4.4.4.m4.1.1.3">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.T4.14.14.4.4.4.m4.1c">\backslash n</annotation><annotation encoding="application/x-llamapun" id="A2.T4.14.14.4.4.4.m4.1d">\ italic_n</annotation></semantics></math><math alttext="\backslash n" class="ltx_Math" display="inline" id="A2.T4.15.15.5.5.5.m5.1"><semantics id="A2.T4.15.15.5.5.5.m5.1a"><mrow id="A2.T4.15.15.5.5.5.m5.1.1" xref="A2.T4.15.15.5.5.5.m5.1.1.cmml"><mi id="A2.T4.15.15.5.5.5.m5.1.1.2" xref="A2.T4.15.15.5.5.5.m5.1.1.2.cmml"></mi><mo id="A2.T4.15.15.5.5.5.m5.1.1.1" lspace="0.222em" rspace="0.222em" xref="A2.T4.15.15.5.5.5.m5.1.1.1.cmml">\</mo><mi id="A2.T4.15.15.5.5.5.m5.1.1.3" xref="A2.T4.15.15.5.5.5.m5.1.1.3.cmml">n</mi></mrow><annotation-xml encoding="MathML-Content" id="A2.T4.15.15.5.5.5.m5.1b"><apply id="A2.T4.15.15.5.5.5.m5.1.1.cmml" xref="A2.T4.15.15.5.5.5.m5.1.1"><ci id="A2.T4.15.15.5.5.5.m5.1.1.1.cmml" xref="A2.T4.15.15.5.5.5.m5.1.1.1">\</ci><csymbol cd="latexml" id="A2.T4.15.15.5.5.5.m5.1.1.2.cmml" xref="A2.T4.15.15.5.5.5.m5.1.1.2">absent</csymbol><ci id="A2.T4.15.15.5.5.5.m5.1.1.3.cmml" xref="A2.T4.15.15.5.5.5.m5.1.1.3">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.T4.15.15.5.5.5.m5.1c">\backslash n</annotation><annotation encoding="application/x-llamapun" id="A2.T4.15.15.5.5.5.m5.1d">\ italic_n</annotation></semantics></math>### الجواب:</span>
</span>
</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 4: </span>Translation example for model comparison.</figcaption>
</figure>
<div class="ltx_para" id="A2.SS3.SSS2.p2">
<p class="ltx_p" id="A2.SS3.SSS2.p2.1">We used Amazon Bedrock<span class="ltx_note ltx_role_footnote" id="footnote54"><sup class="ltx_note_mark">54</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">54</sup><span class="ltx_tag ltx_tag_note">54</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aws.amazon.com/bedrock" title="">https://aws.amazon.com/bedrock</a></span></span></span>, a cloud-based machine learning service from AWS, to translate the dataset into Darija. We provided specific instructions to Claude 3.5 Sonnet for handling the translations, refining the prompt after several rounds of experimentation. The final version of the prompt that produced the best results is shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#A2.F3" title="Figure 3 ‣ B.3.2 Translation ‣ B.3 Translation to Darija ‣ Appendix B TÜLU-V2-mix and its translation ‣ Atlas-Chat: Adapting Large Language Models for Low-Resource Moroccan Arabic Dialect"><span class="ltx_text ltx_ref_tag">3</span></a>. We altered this prompt slightly as needed for each subset of the dataset, ensuring that the translation remained consistent with the context and structure of each specific subset.</p>
</div>
<figure class="ltx_figure" id="A2.F3">
<div class="ltx_listing ltx_align_right ltx_lstlisting ltx_framed ltx_framed_rectangle ltx_listing" id="A2.F3.1" style="background-color:#F2F2F2;">
<div class="ltx_listing_data"><a download="" href="data:text/plain;base64,VHJhbnNsYXRlIHRoZSAnY29udGVudCcgZmllbGQgaW4gdGhlIHBhcmFncmFwaCBhZnRlciBbU291cmNlIFRleHRdIHRvIE1vcm9jY2FuIGRpYWxlY3QgKERhcmlqYSAtIEFyYWJpYyBhbHBoYWJldCkgd2hpbGUgZm9sbG93aW5nIHRoZXNlIGd1aWRlbGluZXM6CgotIEtlZXAgdGhlIGZvcm1hdCBvZiB0aGUgb3JpZ2luYWwgdGV4dCAobGlzdCBvZiBqc29uKS4KLSBJZiBhIHdvcmQgaXMgdXN1YWxseSBub3QgdXNlZCBpbiBBcmFiaWMsIHVzZSBpdHMgRnJlbmNoIGVxdWl2YWxlbnQuCi0gRG8gbm90IGluY2x1ZGUgYW55IGludHJvZHVjdGlvbiBvciBleHBsYW5hdGlvbiBhZnRlciB0aGUgdHJhbnNsYXRpb24sIG9ubHkgdGhlIHRyYW5zbGF0aW9uLgotIElmIHRoZXJlIGlzIGEgZ2l2ZW4gY29udGV4dCwgZXhhbXBsZSBvciBxdWVzdGlvbiB0cmFuc2xhdGUgaXQgYXMgd2VsbC4KLSBXaGVuZXZlciB5b3UgY29tZSBhY3Jvc3MgY29kZSBjb250ZXh0cyBvciB0ZWNobmljYWwgd29yZHMsIGtlZXAgdGhlbSBpbiBFbmdsaXNoLgotIFdoZW5ldmVyIHlvdSBjb21lIGFjcm9zcyBsaXRlcmF0dXJlLCBvciBleGFtcGxlIG9yIHF1ZXN0aW9uLCB0cmFuc2xhdGUgaXQgdG8gTW9yb2NjYW4uCi0gSWYgdGhlIHRleHQgaXMgY3VsdHVyYWx5IG5vdCBhY2NlcHRlZCBmb3IgTW9ycm9jYW5zLCBjaGFuZ2UgaXQgdG8gYSBtb3JlIGFjY2VwdGFibGUgb25lLgotIERvIG5vdCBhbnN3ZXIgdGhlIHJlcXVlc3QgaW4gdGhlIHNvdXJjZSB0ZXh0LgotIFdyaXRlIGZpcnN0IHRoZSBvcmlnaW5hbCB0ZXh0IGFmdGVyIHRoZSB0YWcgW1tPcmlnaW5hbF1dIGFuZCB0aGVuIHRoZSB0cmFuc2xhdGlvbiBhZnRlciB0aGUgdGFnIFtbVHJhbnNsYXRpb25dXS4KCltTb3VyY2UgVGV4dF0K">⬇</a></div>
<div class="ltx_listingline" id="lstnumberx11">
<span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx11.1">Translate</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx11.2"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx11.3">the</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx11.4"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx11.5">’</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx11.6">content</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx11.7">’</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx11.8"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx11.9">field</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx11.10"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx11.11">in</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx11.12"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx11.13">the</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx11.14"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx11.15">paragraph</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx11.16"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx11.17">after</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx11.18"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx11.19">[</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx11.20">Source</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx11.21"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx11.22">Text</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx11.23">]</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx11.24"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx11.25">to</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx11.26"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx11.27">Moroccan</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx11.28"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx11.29">dialect</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx11.30"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx11.31">(</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx11.32">Darija</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx11.33"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx11.34">-</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx11.35"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx11.36">Arabic</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx11.37"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx11.38">alphabet</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx11.39">)</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx11.40"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx11.41">while</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx11.42"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx11.43">following</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx11.44"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx11.45">these</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx11.46"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx11.47">guidelines</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx11.48">:</span>
</div>
<div class="ltx_listingline" id="lstnumberx12">
</div>
<div class="ltx_listingline" id="lstnumberx13">
<span class="ltx_text ltx_font_typewriter" id="lstnumberx13.1">-</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx13.2"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx13.3">Keep</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx13.4"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx13.5">the</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx13.6"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx13.7">format</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx13.8"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx13.9">of</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx13.10"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx13.11">the</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx13.12"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx13.13">original</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx13.14"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx13.15">text</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx13.16"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx13.17">(</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx13.18">list</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx13.19"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx13.20">of</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx13.21"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx13.22">json</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx13.23">).</span>
</div>
<div class="ltx_listingline" id="lstnumberx14">
<span class="ltx_text ltx_font_typewriter" id="lstnumberx14.1">-</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx14.2"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx14.3">If</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx14.4"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx14.5">a</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx14.6"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx14.7">word</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx14.8"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx14.9">is</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx14.10"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx14.11">usually</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx14.12"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx14.13">not</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx14.14"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx14.15">used</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx14.16"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx14.17">in</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx14.18"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx14.19">Arabic</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx14.20">,</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx14.21"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx14.22">use</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx14.23"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx14.24">its</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx14.25"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx14.26">French</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx14.27"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx14.28">equivalent</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx14.29">.</span>
</div>
<div class="ltx_listingline" id="lstnumberx15">
<span class="ltx_text ltx_font_typewriter" id="lstnumberx15.1">-</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx15.2"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx15.3">Do</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx15.4"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx15.5">not</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx15.6"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx15.7">include</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx15.8"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx15.9">any</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx15.10"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx15.11">introduction</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx15.12"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx15.13">or</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx15.14"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx15.15">explanation</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx15.16"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx15.17">after</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx15.18"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx15.19">the</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx15.20"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx15.21">translation</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx15.22">,</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx15.23"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx15.24">only</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx15.25"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx15.26">the</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx15.27"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx15.28">translation</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx15.29">.</span>
</div>
<div class="ltx_listingline" id="lstnumberx16">
<span class="ltx_text ltx_font_typewriter" id="lstnumberx16.1">-</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx16.2"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx16.3">If</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx16.4"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx16.5">there</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx16.6"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx16.7">is</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx16.8"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx16.9">a</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx16.10"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx16.11">given</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx16.12"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx16.13">context</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx16.14">,</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx16.15"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx16.16">example</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx16.17"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx16.18">or</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx16.19"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx16.20">question</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx16.21"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx16.22">translate</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx16.23"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx16.24">it</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx16.25"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx16.26">as</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx16.27"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx16.28">well</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx16.29">.</span>
</div>
<div class="ltx_listingline" id="lstnumberx17">
<span class="ltx_text ltx_font_typewriter" id="lstnumberx17.1">-</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx17.2"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx17.3">Whenever</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx17.4"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx17.5">you</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx17.6"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx17.7">come</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx17.8"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx17.9">across</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx17.10"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx17.11">code</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx17.12"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx17.13">contexts</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx17.14"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx17.15">or</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx17.16"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx17.17">technical</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx17.18"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx17.19">words</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx17.20">,</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx17.21"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx17.22">keep</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx17.23"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx17.24">them</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx17.25"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx17.26">in</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx17.27"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx17.28">English</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx17.29">.</span>
</div>
<div class="ltx_listingline" id="lstnumberx18">
<span class="ltx_text ltx_font_typewriter" id="lstnumberx18.1">-</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx18.2"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx18.3">Whenever</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx18.4"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx18.5">you</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx18.6"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx18.7">come</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx18.8"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx18.9">across</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx18.10"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx18.11">literature</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx18.12">,</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx18.13"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx18.14">or</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx18.15"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx18.16">example</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx18.17"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx18.18">or</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx18.19"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx18.20">question</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx18.21">,</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx18.22"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx18.23">translate</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx18.24"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx18.25">it</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx18.26"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx18.27">to</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx18.28"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx18.29">Moroccan</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx18.30">.</span>
</div>
<div class="ltx_listingline" id="lstnumberx19">
<span class="ltx_text ltx_font_typewriter" id="lstnumberx19.1">-</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx19.2"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx19.3">If</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx19.4"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx19.5">the</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx19.6"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx19.7">text</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx19.8"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx19.9">is</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx19.10"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx19.11">culturaly</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx19.12"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx19.13">not</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx19.14"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx19.15">accepted</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx19.16"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx19.17">for</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx19.18"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx19.19">Morrocans</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx19.20">,</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx19.21"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx19.22">change</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx19.23"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx19.24">it</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx19.25"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx19.26">to</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx19.27"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx19.28">a</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx19.29"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx19.30">more</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx19.31"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx19.32">acceptable</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx19.33"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx19.34">one</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx19.35">.</span>
</div>
<div class="ltx_listingline" id="lstnumberx20">
<span class="ltx_text ltx_font_typewriter" id="lstnumberx20.1">-</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx20.2"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx20.3">Do</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx20.4"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx20.5">not</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx20.6"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx20.7">answer</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx20.8"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx20.9">the</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx20.10"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx20.11">request</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx20.12"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx20.13">in</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx20.14"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx20.15">the</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx20.16"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx20.17">source</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx20.18"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx20.19">text</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx20.20">.</span>
</div>
<div class="ltx_listingline" id="lstnumberx21">
<span class="ltx_text ltx_font_typewriter" id="lstnumberx21.1">-</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx21.2"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx21.3">Write</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx21.4"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx21.5">first</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx21.6"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx21.7">the</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx21.8"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx21.9">original</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx21.10"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx21.11">text</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx21.12"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx21.13">after</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx21.14"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx21.15">the</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx21.16"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx21.17">tag</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx21.18"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx21.19">[[</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx21.20">Original</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx21.21">]]</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx21.22"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx21.23">and</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx21.24"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx21.25">then</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx21.26"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx21.27">the</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx21.28"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx21.29">translation</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx21.30"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx21.31">after</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx21.32"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx21.33">the</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx21.34"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx21.35">tag</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx21.36"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx21.37">[[</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx21.38">Translation</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx21.39">]].</span>
</div>
<div class="ltx_listingline" id="lstnumberx22">
</div>
<div class="ltx_listingline" id="lstnumberx23">
<span class="ltx_text ltx_font_typewriter" id="lstnumberx23.1">[</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx23.2">Source</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx23.3"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx23.4">Text</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx23.5">]</span>
</div>
</div>
<figcaption class="ltx_caption ltx_align_right"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>The prompt given to Clause Sonnet 3.5 for translation.</figcaption>
</figure>
<div class="ltx_para" id="A2.SS3.SSS2.p3">
<p class="ltx_p" id="A2.SS3.SSS2.p3.1">We used asynchronous programming techniques with Python’s asyncio library to make multiple concurrent requests (often 25 at a time) to the Bedrock translation service. This parallel approach significantly sped up the overall translation process by allowing us to handle many requests simultaneously instead of sequentially.</p>
</div>
</section>
<section class="ltx_subsubsection" id="A2.SS3.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">B.3.3 </span>Postprocessing</h4>
<div class="ltx_para" id="A2.SS3.SSS3.p1">
<p class="ltx_p" id="A2.SS3.SSS3.p1.1">After finishing the translation and cleaning the errors, we post-processed the translations by:</p>
<ul class="ltx_itemize" id="A2.I3">
<li class="ltx_item" id="A2.I3.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A2.I3.i1.p1">
<p class="ltx_p" id="A2.I3.i1.p1.1"><span class="ltx_text ltx_font_bold" id="A2.I3.i1.p1.1.1">Replacing non-translated keywords:</span> Some keywords such as "Input", "Output", "Response", "Answer", "Instructions", "Hypothesis" and "Additional Context" were not translated. We replaced these keywords with their Darija equivalents: <span class="ltx_ERROR undefined" id="A2.I3.i1.p1.1.2">\&lt;</span> المعطيات, النتيجة, الجواب, الجواب, تعليمات, الفرضية, سياق إضافي.&gt;</p>
</div>
</li>
<li class="ltx_item" id="A2.I3.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A2.I3.i2.p1">
<p class="ltx_p" id="A2.I3.i2.p1.1"><span class="ltx_text ltx_font_bold" id="A2.I3.i2.p1.1.1">Removing samples with excessive English content:</span> We utilized the fastText Language Identification model to detect samples where the predicted language was not Arabic. Since the model does not differentiate dialects, Darija is recognized as Arabic due to its use of Arabic script. We removed samples where the predicted language was not Arabic or where Arabic was predicted with a confidence level below 80%.</p>
</div>
</li>
</ul>
</div>
</section>
</section>
</section>
<section class="ltx_appendix" id="A3">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix C </span>Additional details</h2>
<section class="ltx_subsection" id="A3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">C.1 </span>Hard coded instruction samples</h3>
<div class="ltx_para" id="A3.SS1.p1">
<p class="ltx_p" id="A3.SS1.p1.1">We manually created 13 instruction samples to ensure that the model responds correctly to identity and creator-related questions, such as “Who created you?” and “What is your name?”. Each instruction is repeated 10 times to reinforce the memorization of the answers. Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#A3.F4" title="Figure 4 ‣ C.1 Hard coded instruction samples ‣ Appendix C Additional details ‣ Atlas-Chat: Adapting Large Language Models for Low-Resource Moroccan Arabic Dialect"><span class="ltx_text ltx_ref_tag">4</span></a> presents the full list of hard-coded instruction-answer pairs.</p>
</div>
<figure class="ltx_figure" id="A3.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="638" id="A3.F4.g1" src="x2.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Hard coded instruction-answer pairs.</figcaption>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section class="ltx_subsection" id="A3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">C.2 </span>Selected keywords for tweet searching</h3>
<div class="ltx_para" id="A3.SS2.p1">
<p class="ltx_p" id="A3.SS2.p1.1">We provide the 26 Darija-specific keywords used for tweet collection through the Twitter API, as referenced in Section <a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#S5.SS2" title="5.2 MoroccanSocialMedia-MultiGen (MSM-MG) ‣ 5 Synthetic Darija instruction datasets ‣ Atlas-Chat: Adapting Large Language Models for Low-Resource Moroccan Arabic Dialect"><span class="ltx_text ltx_ref_tag">5.2</span></a>.
<span class="ltx_ERROR undefined" id="A3.SS2.p1.1.1">{arabtext}</span>كاتشوف, كيضحك, كتبكي, داكشي, كيشوف, كتشوف, كيزيدو, دابا, ديال, تبوڭيصة, مكلخ, حشومة, منبقاوش, شلاهبية, تخربيق, كايدوي, كاندوي, يسيفطوه, يصيفطوه, السماسرية, ماكينش, مزيانين, الفقصة, زوينين, سيمانة, الدراري.</p>
</div>
</section>
<section class="ltx_subsection" id="A3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">C.3 </span>Selected topics from MMLU and ArabicMMLU</h3>
<div class="ltx_para" id="A3.SS3.p1">
<p class="ltx_p" id="A3.SS3.p1.1">The <span class="ltx_text ltx_font_bold" id="A3.SS3.p1.1.1">MMLU</span> subjects included in DarijaMMLU are: Global Facts, High School European History, High School Geography, High School Government and Politics, High School Psychology, High School Statistics, High School World History, Human Aging, International Law, Jurisprudence, Logical Fallacies, Management, Marketing, Moral Disputes, Moral Scenarios, Nutrition, Philosophy, Professional Law, Professional Psychology, Public Relations, Security Studies, Sociology, and World Religions.
From <span class="ltx_text ltx_font_bold" id="A3.SS3.p1.1.2">ArabicMMLU</span>, the subjects adopted into DarijaMMLU are: Islamic Studies, Driving Test, Natural Science, History, General Knowledge, Law, Physics, Social Science, Management, Arabic Language, Political Science, Philosophy, Accounting, Computer Science, Geography, Mathematics, Biology, Economics, Arabic Language (General), Arabic Language (Grammar), and Civics.</p>
</div>
</section>
<section class="ltx_subsection" id="A3.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">C.4 </span>LLM-as-Judge prompt for summarization evaluation</h3>
<div class="ltx_para" id="A3.SS4.p1">
<p class="ltx_p" id="A3.SS4.p1.1">Following the work of <cite class="ltx_cite ltx_citemacro_citet">Zheng et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#bib.bib58" title="">2023</a>)</cite> and <cite class="ltx_cite ltx_citemacro_citet">Fabbri et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#bib.bib13" title="">2021</a>)</cite>, which used advanced LLMs to evaluate responses from other LLMs, we employed Claude 3.5 Sonnet to assess the models’ summarization capabilities.
Summarization is subjective, and traditional text overlap-based methods often struggle to provide accurate evaluations. As shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#A3.F5" title="Figure 5 ‣ C.4 LLM-as-Judge prompt for summarization evaluation ‣ Appendix C Additional details ‣ Atlas-Chat: Adapting Large Language Models for Low-Resource Moroccan Arabic Dialect"><span class="ltx_text ltx_ref_tag">5</span></a>, we instructed Claude to evaluate model-generated summaries based on three main criteria: wordness, conciseness, and relevance.
The objective of the Darija summarization task is to produce a concise summary in native Darija using the fewest words possible, without introducing external information.
At each evaluation step, two summaries were presented to Claude: one generated by an LLM and the corresponding ground truth summary. To mitigate biases such as verbosity and position bias, identified by <cite class="ltx_cite ltx_citemacro_citet">Zheng et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#bib.bib58" title="">2023</a>)</cite>, all models were instructed to generate summaries of no more than 30 words (the average length of title summaries).
Additionally, each pair of generated and ground truth summaries was presented to Claude twice, with their positions swapped. Pairs in which position swapping influenced Claude’s decision were discarded.
The win rate of a model’s summary was calculated based on how often Claude preferred the model’s summary over the ground truth.</p>
</div>
<figure class="ltx_figure" id="A3.F5">
<div class="ltx_listing ltx_align_right ltx_lstlisting ltx_framed ltx_framed_rectangle ltx_listing" id="A3.F5.1" style="background-color:#F2F2F2;">
<div class="ltx_listing_data"><a download="" href="data:text/plain;base64,WW91IGFyZSBhbiBleHBlcnQgZXZhbHVhdG9yIHRhc2tlZCB3aXRoIGp1ZGdpbmcgdGhlIHF1YWxpdHkgb2YgdHdvIHN1bW1hcmllcyB3cml0dGVuIGluIE1vcm9jY2FuIERhcmlqYSBmb3IgYSBnaXZlbiBwYXNzYWdlLCBhbHNvIGluIE1vcm9jY2FuIERhcmlqYS4gWW91IGFyZSBzdHJpY3QgcmVnYXJkaW5nIGFueSBsYW5ndWFnZSBvciBkaWFsZWN0IHRoYXQgaXMgbm90IE1vcnJvY2FuIERhcmlqYSwgc3VjaCBhcyBNb2Rlcm4gU3RhbmRhcmQgQXJhYmljIChNU0EpIGFuZCBFbmdsaXNoLgoKIyMjIENyaXRlcmlhOgpDaG9vc2UgdGhlIGJldHRlciBzdW1tYXJ5IGJhc2VkIG9uIHRoZXNlIGNyaXRlcmlhOgoxLiAqKldvcmRuZXNzKio6IENsZWFyIGFuZCBwcmVjaXNlIGxhbmd1YWdlIGluIE1vcm9jY2FuIERhcmlqYSB0aGF0IGNvbnZleXMgdGhlIHBhc3NhZ2UncyBvcmlnaW5hbCBtZWFuaW5nIGFuZCBkb2Vzbid0IHVzZSBhbnkgb3RoZXIgbGFuZ3VhZ2Ugb3IgRGlhbGVjdC4KMi4gKipDb25jaXNlbmVzcyoqOiBTdHJhaWdodCB0byB0aGUgcG9pbnQsIGNhcHR1cmluZyBlc3NlbnRpYWwgaW5mb3JtYXRpb24gd2l0aG91dCB1bm5lY2Vzc2FyeSBkZXRhaWxzLgozLiAqKlJlbGV2YW5jZSoqOiBEaXJlY3RseSByZWxhdGVkIHRvIHRoZSBwYXNzYWdlIHdpdGhvdXQgYWRkaW5nIG5ldyBpbmZvcm1hdGlvbi4KCiMjIyBJbnN0cnVjdGlvbnM6CkZvciBlYWNoIHBhc3NhZ2UsIHlvdSB3aWxsIHJlY2VpdmUgdHdvIHN1bW1hcmllcywgKipBKiogYW5kICoqQioqLiBFdmFsdWF0ZSB0aGVtIGJhc2VkIG9uIHRoZSBjcml0ZXJpYSBhYm92ZSBhbmQgZGVjaWRlIHdoaWNoIG9uZSBpcyBiZXR0ZXIuIFByb3ZpZGUgb25seSB0aGUgbGV0dGVyICoqQSoqIG9yICoqQioqIGFzIHRoZSBhbnN3ZXIuCkl0IGlzIHN0cmljdGx5IGZvcmJpZGRlbiB0aGF0IGEgc3VtbWFyeSBpcyB3cml0dGVuIGluIE1vZGVybiBTdGFuZGFyZCBBcmFiaWMgKE1TQSkuCkEgc3VtbWFyeSBzaG91bGQgbm90IGJlIGNob3NlbiBpZiBpdCBpcyB3cml0dGVuIGluIE1TQS5zCgojIyNPdXRwdXQgZm9ybWF0OgpCZXR0ZXIgU3VtbWFyeTogW0Egb3IgQl0KCiMjIyBFdmFsdWF0ZToKKipQYXNzYWdlKio6CltTdGFydCBvZiB0aGUgcGFzc2FnZV0Ke3Bhc3NhZ2V9CltUZXh0IG9mIHRoZSBwYXNzYWdlXQoKKipTdW1tYXJ5IEEqKjoKW1N0YXJ0IG9mIFN1bW1hcnkgQV0Ke3N1bW1hcnlfYX0KW1RleHQgb2YgU3VtbWFyeSBBXQoKKipTdW1tYXJ5IEIqKjoKW1N0YXJ0IG9mIFN1bW1hcnkgQl0Ke3N1bW1hcnlfYn0KW1RleHQgb2YgU3VtbWFyeSBCXQoKWW91ciBSZXNwb25zZSAoT25seSBBIG9yIEIgd2l0aCBubyBhZGRpdGlvbmFsIHRleHQpOg==">⬇</a></div>
<div class="ltx_listingline" id="lstnumberx24">
<span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx24.1">You</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx24.2"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx24.3">are</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx24.4"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx24.5">an</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx24.6"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx24.7">expert</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx24.8"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx24.9">evaluator</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx24.10"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx24.11">tasked</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx24.12"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx24.13">with</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx24.14"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx24.15">judging</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx24.16"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx24.17">the</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx24.18"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx24.19">quality</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx24.20"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx24.21">of</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx24.22"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx24.23">two</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx24.24"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx24.25">summaries</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx24.26"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx24.27">written</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx24.28"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx24.29">in</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx24.30"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx24.31">Moroccan</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx24.32"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx24.33">Darija</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx24.34"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx24.35">for</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx24.36"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx24.37">a</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx24.38"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx24.39">given</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx24.40"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx24.41">passage</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx24.42">,</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx24.43"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx24.44">also</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx24.45"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx24.46">in</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx24.47"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx24.48">Moroccan</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx24.49"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx24.50">Darija</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx24.51">.</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx24.52"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx24.53">You</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx24.54"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx24.55">are</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx24.56"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx24.57">strict</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx24.58"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx24.59">regarding</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx24.60"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx24.61">any</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx24.62"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx24.63">language</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx24.64"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx24.65">or</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx24.66"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx24.67">dialect</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx24.68"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx24.69">that</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx24.70"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx24.71">is</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx24.72"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx24.73">not</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx24.74"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx24.75">Morrocan</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx24.76"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx24.77">Darija</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx24.78">,</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx24.79"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx24.80">such</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx24.81"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx24.82">as</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx24.83"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx24.84">Modern</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx24.85"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx24.86">Standard</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx24.87"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx24.88">Arabic</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx24.89"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx24.90">(</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx24.91">MSA</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx24.92">)</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx24.93"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx24.94">and</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx24.95"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx24.96">English</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx24.97">.</span>
</div>
<div class="ltx_listingline" id="lstnumberx25">
</div>
<div class="ltx_listingline" id="lstnumberx26">
<span class="ltx_text ltx_font_typewriter" id="lstnumberx26.1">###</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx26.2"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx26.3">Criteria</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx26.4">:</span>
</div>
<div class="ltx_listingline" id="lstnumberx27">
<span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx27.1">Choose</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx27.2"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx27.3">the</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx27.4"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx27.5">better</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx27.6"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx27.7">summary</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx27.8"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx27.9">based</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx27.10"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx27.11">on</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx27.12"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx27.13">these</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx27.14"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx27.15">criteria</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx27.16">:</span>
</div>
<div class="ltx_listingline" id="lstnumberx28">
<span class="ltx_text ltx_font_typewriter" id="lstnumberx28.1">1.</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx28.2"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx28.3">**</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx28.4">Wordness</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx28.5">**:</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx28.6"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx28.7">Clear</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx28.8"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx28.9">and</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx28.10"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx28.11">precise</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx28.12"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx28.13">language</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx28.14"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx28.15">in</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx28.16"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx28.17">Moroccan</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx28.18"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx28.19">Darija</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx28.20"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx28.21">that</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx28.22"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx28.23">conveys</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx28.24"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx28.25">the</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx28.26"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx28.27">passage</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx28.28">’</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx28.29">s</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx28.30"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx28.31">original</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx28.32"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx28.33">meaning</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx28.34"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx28.35">and</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx28.36"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx28.37">doesn</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx28.38">’</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx28.39">t</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx28.40"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx28.41">use</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx28.42"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx28.43">any</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx28.44"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx28.45">other</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx28.46"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx28.47">language</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx28.48"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx28.49">or</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx28.50"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx28.51">Dialect</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx28.52">.</span>
</div>
<div class="ltx_listingline" id="lstnumberx29">
<span class="ltx_text ltx_font_typewriter" id="lstnumberx29.1">2.</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx29.2"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx29.3">**</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx29.4">Conciseness</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx29.5">**:</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx29.6"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx29.7">Straight</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx29.8"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx29.9">to</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx29.10"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx29.11">the</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx29.12"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx29.13">point</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx29.14">,</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx29.15"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx29.16">capturing</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx29.17"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx29.18">essential</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx29.19"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx29.20">information</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx29.21"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx29.22">without</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx29.23"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx29.24">unnecessary</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx29.25"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx29.26">details</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx29.27">.</span>
</div>
<div class="ltx_listingline" id="lstnumberx30">
<span class="ltx_text ltx_font_typewriter" id="lstnumberx30.1">3.</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx30.2"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx30.3">**</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx30.4">Relevance</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx30.5">**:</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx30.6"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx30.7">Directly</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx30.8"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx30.9">related</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx30.10"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx30.11">to</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx30.12"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx30.13">the</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx30.14"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx30.15">passage</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx30.16"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx30.17">without</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx30.18"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx30.19">adding</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx30.20"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx30.21">new</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx30.22"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx30.23">information</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx30.24">.</span>
</div>
<div class="ltx_listingline" id="lstnumberx31">
</div>
<div class="ltx_listingline" id="lstnumberx32">
<span class="ltx_text ltx_font_typewriter" id="lstnumberx32.1">###</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx32.2"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx32.3">Instructions</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx32.4">:</span>
</div>
<div class="ltx_listingline" id="lstnumberx33">
<span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx33.1">For</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx33.2"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx33.3">each</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx33.4"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx33.5">passage</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx33.6">,</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx33.7"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx33.8">you</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx33.9"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx33.10">will</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx33.11"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx33.12">receive</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx33.13"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx33.14">two</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx33.15"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx33.16">summaries</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx33.17">,</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx33.18"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx33.19">**</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx33.20">A</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx33.21">**</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx33.22"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx33.23">and</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx33.24"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx33.25">**</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx33.26">B</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx33.27">**.</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx33.28"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx33.29">Evaluate</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx33.30"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx33.31">them</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx33.32"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx33.33">based</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx33.34"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx33.35">on</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx33.36"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx33.37">the</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx33.38"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx33.39">criteria</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx33.40"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx33.41">above</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx33.42"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx33.43">and</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx33.44"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx33.45">decide</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx33.46"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx33.47">which</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx33.48"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx33.49">one</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx33.50"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx33.51">is</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx33.52"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx33.53">better</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx33.54">.</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx33.55"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx33.56">Provide</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx33.57"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx33.58">only</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx33.59"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx33.60">the</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx33.61"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx33.62">letter</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx33.63"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx33.64">**</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx33.65">A</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx33.66">**</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx33.67"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx33.68">or</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx33.69"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx33.70">**</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx33.71">B</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx33.72">**</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx33.73"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx33.74">as</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx33.75"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx33.76">the</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx33.77"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx33.78">answer</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx33.79">.</span>
</div>
<div class="ltx_listingline" id="lstnumberx34">
<span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx34.1">It</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx34.2"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx34.3">is</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx34.4"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx34.5">strictly</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx34.6"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx34.7">forbidden</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx34.8"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx34.9">that</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx34.10"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx34.11">a</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx34.12"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx34.13">summary</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx34.14"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx34.15">is</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx34.16"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx34.17">written</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx34.18"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx34.19">in</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx34.20"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx34.21">Modern</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx34.22"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx34.23">Standard</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx34.24"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx34.25">Arabic</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx34.26"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx34.27">(</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx34.28">MSA</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx34.29">).</span>
</div>
<div class="ltx_listingline" id="lstnumberx35">
<span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx35.1">A</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx35.2"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx35.3">summary</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx35.4"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx35.5">should</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx35.6"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx35.7">not</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx35.8"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx35.9">be</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx35.10"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx35.11">chosen</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx35.12"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx35.13">if</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx35.14"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx35.15">it</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx35.16"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx35.17">is</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx35.18"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx35.19">written</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx35.20"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx35.21">in</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx35.22"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx35.23">MSA</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx35.24">.</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx35.25">s</span>
</div>
<div class="ltx_listingline" id="lstnumberx36">
</div>
<div class="ltx_listingline" id="lstnumberx37">
<span class="ltx_text ltx_font_typewriter" id="lstnumberx37.1">###</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx37.2">Output</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx37.3"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx37.4">format</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx37.5">:</span>
</div>
<div class="ltx_listingline" id="lstnumberx38">
<span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx38.1">Better</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx38.2"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx38.3">Summary</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx38.4">:</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx38.5"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx38.6">[</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx38.7">A</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx38.8"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx38.9">or</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx38.10"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx38.11">B</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx38.12">]</span>
</div>
<div class="ltx_listingline" id="lstnumberx39">
</div>
<div class="ltx_listingline" id="lstnumberx40">
<span class="ltx_text ltx_font_typewriter" id="lstnumberx40.1">###</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx40.2"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx40.3">Evaluate</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx40.4">:</span>
</div>
<div class="ltx_listingline" id="lstnumberx41">
<span class="ltx_text ltx_font_typewriter" id="lstnumberx41.1">**</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx41.2">Passage</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx41.3">**:</span>
</div>
<div class="ltx_listingline" id="lstnumberx42">
<span class="ltx_text ltx_font_typewriter" id="lstnumberx42.1">[</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx42.2">Start</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx42.3"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx42.4">of</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx42.5"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx42.6">the</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx42.7"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx42.8">passage</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx42.9">]</span>
</div>
<div class="ltx_listingline" id="lstnumberx43">
<span class="ltx_text ltx_font_typewriter" id="lstnumberx43.1">{</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx43.2">passage</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx43.3">}</span>
</div>
<div class="ltx_listingline" id="lstnumberx44">
<span class="ltx_text ltx_font_typewriter" id="lstnumberx44.1">[</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx44.2">Text</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx44.3"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx44.4">of</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx44.5"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx44.6">the</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx44.7"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx44.8">passage</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx44.9">]</span>
</div>
<div class="ltx_listingline" id="lstnumberx45">
</div>
<div class="ltx_listingline" id="lstnumberx46">
<span class="ltx_text ltx_font_typewriter" id="lstnumberx46.1">**</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx46.2">Summary</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx46.3"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx46.4">A</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx46.5">**:</span>
</div>
<div class="ltx_listingline" id="lstnumberx47">
<span class="ltx_text ltx_font_typewriter" id="lstnumberx47.1">[</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx47.2">Start</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx47.3"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx47.4">of</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx47.5"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx47.6">Summary</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx47.7"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx47.8">A</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx47.9">]</span>
</div>
<div class="ltx_listingline" id="lstnumberx48">
<span class="ltx_text ltx_font_typewriter" id="lstnumberx48.1">{</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx48.2">summary_a</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx48.3">}</span>
</div>
<div class="ltx_listingline" id="lstnumberx49">
<span class="ltx_text ltx_font_typewriter" id="lstnumberx49.1">[</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx49.2">Text</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx49.3"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx49.4">of</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx49.5"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx49.6">Summary</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx49.7"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx49.8">A</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx49.9">]</span>
</div>
<div class="ltx_listingline" id="lstnumberx50">
</div>
<div class="ltx_listingline" id="lstnumberx51">
<span class="ltx_text ltx_font_typewriter" id="lstnumberx51.1">**</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx51.2">Summary</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx51.3"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx51.4">B</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx51.5">**:</span>
</div>
<div class="ltx_listingline" id="lstnumberx52">
<span class="ltx_text ltx_font_typewriter" id="lstnumberx52.1">[</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx52.2">Start</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx52.3"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx52.4">of</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx52.5"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx52.6">Summary</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx52.7"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx52.8">B</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx52.9">]</span>
</div>
<div class="ltx_listingline" id="lstnumberx53">
<span class="ltx_text ltx_font_typewriter" id="lstnumberx53.1">{</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx53.2">summary_b</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx53.3">}</span>
</div>
<div class="ltx_listingline" id="lstnumberx54">
<span class="ltx_text ltx_font_typewriter" id="lstnumberx54.1">[</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx54.2">Text</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx54.3"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx54.4">of</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx54.5"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx54.6">Summary</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx54.7"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx54.8">B</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx54.9">]</span>
</div>
<div class="ltx_listingline" id="lstnumberx55">
</div>
<div class="ltx_listingline" id="lstnumberx56">
<span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx56.1">Your</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx56.2"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx56.3">Response</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx56.4"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx56.5">(</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx56.6">Only</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx56.7"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx56.8">A</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx56.9"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx56.10">or</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx56.11"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx56.12">B</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx56.13"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx56.14">with</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx56.15"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx56.16">no</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx56.17"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx56.18">additional</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx56.19"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx56.20">text</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx56.21">):</span>
</div>
</div>
<figcaption class="ltx_caption ltx_align_right"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>The prompt Given to Clause Sonnet 3.5 for choosing the best summary between the baseline and LLM-generated summaries.</figcaption>
</figure>
<div class="ltx_para" id="A3.SS4.p2">
<br class="ltx_break"/>
<div class="ltx_pagination ltx_role_newpage"></div>
</div>
</section>
</section>
<section class="ltx_appendix" id="A4">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix D </span>Examples of Atlas-Chat-9B responses</h2>
<div class="ltx_para" id="A4.p1">
<p class="ltx_p" id="A4.p1.1">Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#A4.F6" title="Figure 6 ‣ Appendix D Examples of Atlas-Chat-9B responses ‣ Atlas-Chat: Adapting Large Language Models for Low-Resource Moroccan Arabic Dialect"><span class="ltx_text ltx_ref_tag">6</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2409.17912v1#A4.F7" title="Figure 7 ‣ Appendix D Examples of Atlas-Chat-9B responses ‣ Atlas-Chat: Adapting Large Language Models for Low-Resource Moroccan Arabic Dialect"><span class="ltx_text ltx_ref_tag">7</span></a> present some samples of Atlas-Chat responses on a variety of questions.</p>
</div>
<figure class="ltx_figure" id="A4.F6">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" height="302" id="A4.F6.g1" src="extracted/5882150/figures/Atlas-Chat_Example1.png" width="479"/></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" height="130" id="A4.F6.g2" src="extracted/5882150/figures/Atlas-Chat_Example2.png" width="479"/></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" height="230" id="A4.F6.g3" src="extracted/5882150/figures/Atlas-Chat_Example3.png" width="479"/></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>Atlas-Chat-9B response example 1.</figcaption>
</figure>
<figure class="ltx_figure" id="A4.F7"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="139" id="A4.F7.g1" src="extracted/5882150/figures/Atlas-Chat_Example4.png" width="479"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 7: </span>Atlas-Chat-9B response example 2 (The model can understand English instructions but only responds in Darija).</figcaption>
</figure>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Thu Sep 26 14:34:55 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
