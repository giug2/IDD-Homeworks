<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Probing Causality Manipulation of Large Language Models</title>
<!--Generated on Mon Aug 26 15:57:28 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2408.14380v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#S1" title="In Probing Causality Manipulation of Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#S2" title="In Probing Causality Manipulation of Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Related Work</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#S2.SS1" title="In 2 Related Work ‣ Probing Causality Manipulation of Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>Probing LLMs</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#S2.SS2" title="In 2 Related Work ‣ Probing Causality Manipulation of Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>Evaluation of Causality for LLMs</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#S3" title="In Probing Causality Manipulation of Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Dataset Construction</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#S3.SS0.SSS0.Px1" title="In 3 Dataset Construction ‣ Probing Causality Manipulation of Large Language Models"><span class="ltx_text ltx_ref_title">Base Dataset</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#S3.SS0.SSS0.Px2" title="In 3 Dataset Construction ‣ Probing Causality Manipulation of Large Language Models"><span class="ltx_text ltx_ref_title">Classification Dataset Construction</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#S4" title="In Probing Causality Manipulation of Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Probing Design</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#S4.SS1" title="In 4 Probing Design ‣ Probing Causality Manipulation of Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Hierarchical Retrieval Augmented Generation</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#S4.SS1.SSS0.Px1" title="In 4.1 Hierarchical Retrieval Augmented Generation ‣ 4 Probing Design ‣ Probing Causality Manipulation of Large Language Models"><span class="ltx_text ltx_ref_title">Layer 1: No Augmentation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#S4.SS1.SSS0.Px2" title="In 4.1 Hierarchical Retrieval Augmented Generation ‣ 4 Probing Design ‣ Probing Causality Manipulation of Large Language Models"><span class="ltx_text ltx_ref_title">Layer 2: Original CMedCausal</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#S4.SS1.SSS0.Px3" title="In 4.1 Hierarchical Retrieval Augmented Generation ‣ 4 Probing Design ‣ Probing Causality Manipulation of Large Language Models"><span class="ltx_text ltx_ref_title">Layer 3: Universal Medical-KG</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#S4.SS1.SSS0.Px4" title="In 4.1 Hierarchical Retrieval Augmented Generation ‣ 4 Probing Design ‣ Probing Causality Manipulation of Large Language Models"><span class="ltx_text ltx_ref_title">Retrieval Augmented Generation</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#S4.SS2" title="In 4 Probing Design ‣ Probing Causality Manipulation of Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>In Context Learning Design</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#S5" title="In Probing Causality Manipulation of Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Experiments</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#S5.SS1" title="In 5 Experiments ‣ Probing Causality Manipulation of Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1 </span>Experiment Settings</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#S5.SS1.SSS0.Px1" title="In 5.1 Experiment Settings ‣ 5 Experiments ‣ Probing Causality Manipulation of Large Language Models"><span class="ltx_text ltx_ref_title">Model Selection</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#S5.SS1.SSS0.Px2" title="In 5.1 Experiment Settings ‣ 5 Experiments ‣ Probing Causality Manipulation of Large Language Models"><span class="ltx_text ltx_ref_title">Evaluations</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#S5.SS2" title="In 5 Experiments ‣ Probing Causality Manipulation of Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2 </span>Results</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#S5.SS2.SSS0.Px1" title="In 5.2 Results ‣ 5 Experiments ‣ Probing Causality Manipulation of Large Language Models"><span class="ltx_text ltx_ref_title">Probing native manipulation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#S5.SS2.SSS0.Px2" title="In 5.2 Results ‣ 5 Experiments ‣ Probing Causality Manipulation of Large Language Models"><span class="ltx_text ltx_ref_title">Probing manipulation on advanced prompt</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#S5.SS3" title="In 5 Experiments ‣ Probing Causality Manipulation of Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.3 </span>Analysis</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#S5.SS3.SSS0.Px1" title="In 5.3 Analysis ‣ 5 Experiments ‣ Probing Causality Manipulation of Large Language Models"><span class="ltx_text ltx_ref_title">Overall Analysis</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#S5.SS3.SSS0.Px2" title="In 5.3 Analysis ‣ 5 Experiments ‣ Probing Causality Manipulation of Large Language Models"><span class="ltx_text ltx_ref_title">Global Semantics</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#S5.SS3.SSS0.Px3" title="In 5.3 Analysis ‣ 5 Experiments ‣ Probing Causality Manipulation of Large Language Models"><span class="ltx_text ltx_ref_title">Entities In Causality</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#S5.SS3.SSS0.Px4" title="In 5.3 Analysis ‣ 5 Experiments ‣ Probing Causality Manipulation of Large Language Models"><span class="ltx_text ltx_ref_title">Causality Cognition</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#S5.SS3.SSS0.Px5" title="In 5.3 Analysis ‣ 5 Experiments ‣ Probing Causality Manipulation of Large Language Models"><span class="ltx_text ltx_ref_title">Knowledge</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#S6" title="In Probing Causality Manipulation of Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Conclusion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#A1" title="In Probing Causality Manipulation of Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A </span>Datasets Details And Statistics</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#A2" title="In Probing Causality Manipulation of Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B </span>Back Translation Implementation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#A3" title="In Probing Causality Manipulation of Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">C </span>Discussion of External Knowledge in Layer 3</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#A4" title="In Probing Causality Manipulation of Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">D </span>Retrieval Augmentation Design</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#A5" title="In Probing Causality Manipulation of Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">E </span>Prompts</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#A5.SS1" title="In Appendix E Prompts ‣ Probing Causality Manipulation of Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">E.1 </span>Structure of Prompts</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#A5.SS2" title="In E.1 Structure of Prompts ‣ Appendix E Prompts ‣ Probing Causality Manipulation of Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">E.2 </span>Examples of Prompts</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#A6" title="In E.2 Examples of Prompts ‣ E.1 Structure of Prompts ‣ Appendix E Prompts ‣ Probing Causality Manipulation of Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">F </span>Details of Models</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#A6.SS0.SSS0.Px1" title="In Appendix F Details of Models ‣ E.2 Examples of Prompts ‣ E.1 Structure of Prompts ‣ Appendix E Prompts ‣ Probing Causality Manipulation of Large Language Models"><span class="ltx_text ltx_ref_title">GPT-4</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#A6.SS0.SSS0.Px2" title="In Appendix F Details of Models ‣ E.2 Examples of Prompts ‣ E.1 Structure of Prompts ‣ Appendix E Prompts ‣ Probing Causality Manipulation of Large Language Models"><span class="ltx_text ltx_ref_title">GPT-3.5</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#A6.SS0.SSS0.Px3" title="In Appendix F Details of Models ‣ E.2 Examples of Prompts ‣ E.1 Structure of Prompts ‣ Appendix E Prompts ‣ Probing Causality Manipulation of Large Language Models"><span class="ltx_text ltx_ref_title">ChatGLM</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#A6.SS0.SSS0.Px4" title="In Appendix F Details of Models ‣ E.2 Examples of Prompts ‣ E.1 Structure of Prompts ‣ Appendix E Prompts ‣ Probing Causality Manipulation of Large Language Models"><span class="ltx_text ltx_ref_title">MedChatGLM</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#A6.SS0.SSS0.Px5" title="In Appendix F Details of Models ‣ E.2 Examples of Prompts ‣ E.1 Structure of Prompts ‣ Appendix E Prompts ‣ Probing Causality Manipulation of Large Language Models"><span class="ltx_text ltx_ref_title">BERT</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#A7" title="In E.2 Examples of Prompts ‣ E.1 Structure of Prompts ‣ Appendix E Prompts ‣ Probing Causality Manipulation of Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">G </span>Performance Difference of LLMs</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#A7.SS0.SSS0.Px1" title="In Appendix G Performance Difference of LLMs ‣ E.2 Examples of Prompts ‣ E.1 Structure of Prompts ‣ Appendix E Prompts ‣ Probing Causality Manipulation of Large Language Models"><span class="ltx_text ltx_ref_title">Training Strategies</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#A7.SS0.SSS0.Px2" title="In Appendix G Performance Difference of LLMs ‣ E.2 Examples of Prompts ‣ E.1 Structure of Prompts ‣ Appendix E Prompts ‣ Probing Causality Manipulation of Large Language Models"><span class="ltx_text ltx_ref_title">The Number of Model Parameters</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#A8" title="In E.2 Examples of Prompts ‣ E.1 Structure of Prompts ‣ Appendix E Prompts ‣ Probing Causality Manipulation of Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">H </span>PPL of Positive and Negative Instances</span></a></li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document">
<h1 class="ltx_title ltx_title_document">Probing Causality Manipulation of Large Language Models</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Chenyang Zhang , Haibo Tong <span class="ltx_note ltx_role_footnotemark" id="footnotex1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">footnotemark: </span><span class="ltx_tag ltx_tag_note">1</span></span></span></span>, Bin Zhang, Dongyu Zhang 
<br class="ltx_break"/>
<br class="ltx_break"/>Tongji University 
<br class="ltx_break"/>
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id1.1.id1">{inkzhangcy,2151130,2233009,yidu}@tongji.edu.cn</span>
<br class="ltx_break"/>
<br class="ltx_break"/>
</span><span class="ltx_author_notes">Equally Contribution.</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id2.id1">Large language models (LLMs) have shown various ability on natural language processing, including problems about causality. It is not intuitive for LLMs to command causality, since pretrained models usually work on statistical associations, and do not focus on causes and effects in sentences. So that probing internal manipulation of causality is necessary for LLMs. This paper proposes a novel approach to probe causality manipulation hierarchically, by providing different shortcuts to models and observe behaviors. We exploit retrieval augmented generation (RAG) and in-context learning (ICL) for models on a designed causality classification task. We conduct experiments on mainstream LLMs, including GPT-4 and some smaller and domain-specific models. Our results suggest that LLMs can detect entities related to causality and recognize direct causal relationships. However, LLMs lack specialized cognition for causality, merely treating them as part of the global semantic of the sentence. <span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>Our code and implementation are available at <a class="ltx_ref ltx_href" href="https://github.com/TongjiNLP/llm-causality-probing" title="">https://github.com/TongjiNLP/llm-causality-probing</a>.</span></span></span></p>
</div>
<div class="ltx_para ltx_noindent" id="p1">
<div class="ltx_block ltx_align_bottom" id="p1.1">
<p class="ltx_p" id="p1.1.1"><span class="ltx_text ltx_font_bold" id="p1.1.1.1">Probing Causality Manipulation of Large Language Models</span></p>
<br class="ltx_break ltx_centering"/>
<p class="ltx_p ltx_align_center" id="p1.1.2" style="width:433.6pt;"><span class="ltx_text ltx_inline-block" id="p1.1.2.1" style="width:0.0pt;">
<span class="ltx_tabular ltx_align_top" id="p1.1.2.1.1">
<span class="ltx_tbody">
<span class="ltx_tr" id="p1.1.2.1.1.1.1">
<span class="ltx_td ltx_align_center" id="p1.1.2.1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="p1.1.2.1.1.1.1.1.1">Chenyang Zhang <span class="ltx_note ltx_role_thanks" id="p1.1.2.1.1.1.1.1.1.1"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">thanks: </span>Equally Contribution.</span></span></span>, Haibo Tong <span class="ltx_note ltx_role_footnotemark" id="footnotex2"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">footnotemark: </span><span class="ltx_tag ltx_tag_note"><span class="ltx_text ltx_font_medium" id="footnotex2.1.1.1">1</span></span></span></span></span>, Bin Zhang, Dongyu Zhang</span></span></span>
<span class="ltx_tr" id="p1.1.2.1.1.2.2">
<span class="ltx_td ltx_align_center" id="p1.1.2.1.1.2.2.1">Tongji University</span></span>
<span class="ltx_tr" id="p1.1.2.1.1.3.3">
<span class="ltx_td ltx_align_center" id="p1.1.2.1.1.3.3.1"><span class="ltx_text ltx_font_typewriter" id="p1.1.2.1.1.3.3.1.1">{inkzhangcy,2151130,2233009,yidu}@tongji.edu.cn</span></span></span>
</span>
</span></span></p>
<br class="ltx_break ltx_centering"/>
</div>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Large language models (LLMs) exhibit a diverse range of capabilities in Natural Language Processing (NLP) <cite class="ltx_cite ltx_citemacro_citep">(Wei et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#bib.bib31" title="">2022a</a>; Ganguli et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#bib.bib10" title="">2022</a>)</cite>.
Though LLMs are still based on statistical machine learning <cite class="ltx_cite ltx_citemacro_citep">(Bareinboim et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#bib.bib1" title="">2022</a>; Chen et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#bib.bib5" title="">2023</a>)</cite>, they behave well in some inference and reasoning tasks <cite class="ltx_cite ltx_citemacro_citep">(Bhagavatula et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#bib.bib2" title="">2020</a>)</cite>, showing ability for manipulation of <span class="ltx_text ltx_font_bold" id="S1.p1.1.1">causality</span>.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">However, intrinsic manipulation of causality remains unclear for researchers.
Unfortunately, investigating intrinsic manipulation is not straightforward for LLMs due to complex model structure.
They have enormous parameters, magnifying the cost of refactoring models.
And more advanced architectures like Mixture-of-Experts (MoE) <cite class="ltx_cite ltx_citemacro_citep">(DeepSeek-AI et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#bib.bib6" title="">2024</a>; Jiang et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#bib.bib15" title="">2023</a>)</cite> proposes challenge for detailed probing, because behaviors of models are hard to guide.
Moreover, some existing models do not share technical details.
Intuitive research like ablation study is hard to work under such circumstances.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">To address this challenge, our work proposes an innovative approach of probing intrinsic manipulation of causality for LLMs.
As shown in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ Probing Causality Manipulation of Large Language Models"><span class="ltx_text ltx_ref_tag">1</span></a>, firstly we construct a classification dataset for detecting entities and relationships of causality in sentences.
Then we guide behaviors of LLMs by hierarchically add <span class="ltx_text ltx_font_italic" id="S1.p3.1.1">shortcuts</span> on this classification task.
We integrate retrieval augmented generation (RAG) and in context learning (ICL) for providing shortcuts.
This takes into account the effects of prompts and pretrained knowledge into consideration while probing.
Finally, we observe performance variance under different RAG and ICL, to probe intrinsic manipulation of causality.
We conduct experiments on LLMs in various parameters sizes and domain knowledge.
The experimental results show that LLMs are sensitive to global semantics in classification, and show a certain ability to identify causal entities with guidance. But they do not have direct cognition of causal relationships, lacking a fixed processing route for causality. This leads to sub-optimal performance in more complex problem scenarios for causality, indicating necessity for further attention in LLMs’ training.</p>
</div>
<figure class="ltx_figure" id="S1.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="272" id="S1.F1.1.g1" src="x1.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Main stricture of our probing works. We construct a causal dataset, then guide models by providing shortcuts. Finally, we probe intrinsic manipulation of causality by comparing performances of different shortcuts.</figcaption>
</figure>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Probing LLMs</h3>
<div class="ltx_para" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.1">The working mechanisms of LLMs remain unclear, raising concerns about the reliability and effectiveness of their generated content.
Probing <cite class="ltx_cite ltx_citemacro_citep">(Hewitt and Manning, <a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#bib.bib13" title="">2019</a>)</cite> aims to discern the internal behaviors of models.
Probing researches on LLMs have offered valuable insights into various topics,
like mathematical <cite class="ltx_cite ltx_citemacro_citep">(Stolfo et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#bib.bib28" title="">2023</a>)</cite>, sociology <cite class="ltx_cite ltx_citemacro_citep">(Ramezani and Xu, <a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#bib.bib26" title="">2023</a>; Hossain et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#bib.bib14" title="">2023</a>)</cite>, and pretrained knowledge <cite class="ltx_cite ltx_citemacro_citep">(Chen et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#bib.bib5" title="">2023</a>)</cite>.
In context learning <cite class="ltx_cite ltx_citemacro_citep">(Brown et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#bib.bib3" title="">2020</a>)</cite> is common approach in probing LLMs, since it enables guidance of LLMs without additional training.
Furthermore, furnishing models with specific knowledge has been proven to be an effective probing strategy <cite class="ltx_cite ltx_citemacro_citep">(Lin et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#bib.bib20" title="">2020</a>; Chen et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#bib.bib5" title="">2023</a>)</cite>.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Evaluation of Causality for LLMs</h3>
<div class="ltx_para" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.1">Causality in LLMs has been explored through tasks like commonsense inference <cite class="ltx_cite ltx_citemacro_citep">(Bhagavatula et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#bib.bib2" title="">2020</a>; Talmor et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#bib.bib29" title="">2019</a>)</cite>, event causal identification <cite class="ltx_cite ltx_citemacro_citep">(Gao et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#bib.bib12" title="">2019</a>; Mu and Li, <a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#bib.bib22" title="">2023</a>)</cite>, and explanation generation <cite class="ltx_cite ltx_citemacro_citep">(Du et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#bib.bib8" title="">2022a</a>)</cite>, with ChatGPT’s abilities evaluated <cite class="ltx_cite ltx_citemacro_citep">(Gao et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#bib.bib11" title="">2023</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S2.SS2.p2">
<p class="ltx_p" id="S2.SS2.p2.1">However, the integration of causality in real-world domains <cite class="ltx_cite ltx_citemacro_citep">(Kiciman et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#bib.bib18" title="">2023</a>)</cite> contrasts with LLMs’ reliance on statistical associations <cite class="ltx_cite ltx_citemacro_citep">(Zečević et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#bib.bib33" title="">2023</a>)</cite>. Furthermore, <cite class="ltx_cite ltx_citemacro_citep">(Jin et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#bib.bib16" title="">2024</a>)</cite> confirms LLMs’ lack of causal reasoning, pointing towards a gap in theoretical discussion despite practical applications.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Dataset Construction</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">In this section, we introduce an innovative approach to construct a classification dataset for probing.
Our approach focuses on entities and their causal relationships in sentence, and diminishes interference of pretrained knowledge for probing.
Moreover, our approach preserve gold standard for the classification tasks, which is feasible for providing "shortcuts" and to guide behaviours of models.</p>
</div>
<figure class="ltx_figure" id="S3.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="694" id="S3.F2.1.g1" src="x2.png" width="831"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>An instance of our constructed datasets. Causes in sentences are bold and effects are underlined. The corresponding causes and effects are marked with the same color.</figcaption>
</figure>
<section class="ltx_paragraph" id="S3.SS0.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Base Dataset</h4>
<div class="ltx_para" id="S3.SS0.SSS0.Px1.p1">
<p class="ltx_p" id="S3.SS0.SSS0.Px1.p1.1">We construct our dataset based on the CMedCausal dataset <cite class="ltx_cite ltx_citemacro_citep">(Zhang et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#bib.bib35" title="">2022</a>)</cite>.
CMedCausal provides medical expressions and annotates all causal relationships and entities (causes and effects) in sentences.
More details and cases about base dataset can be found in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#A1" title="Appendix A Datasets Details And Statistics ‣ Probing Causality Manipulation of Large Language Models"><span class="ltx_text ltx_ref_tag">A</span></a>.</p>
</div>
</section>
<section class="ltx_paragraph" id="S3.SS0.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Classification Dataset Construction</h4>
<div class="ltx_para" id="S3.SS0.SSS0.Px2.p1">
<p class="ltx_p" id="S3.SS0.SSS0.Px2.p1.1">For classification, we sample original sentences from CMedCausal as <span class="ltx_text ltx_font_bold" id="S3.SS0.SSS0.Px2.p1.1.1">positive instances</span>, as they contain correct causation.
And we produce <span class="ltx_text ltx_font_bold" id="S3.SS0.SSS0.Px2.p1.1.2">negative instances</span> with certain manners (notated as <span class="ltx_text ltx_font_italic" id="S3.SS0.SSS0.Px2.p1.1.3">Actions</span> or <span class="ltx_text ltx_font_italic" id="S3.SS0.SSS0.Px2.p1.1.4">Act.</span>).
Trough different actions, causation between entities are disturbed, but other parts of sentences are preserved in the best effort.
Fig. <a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#S3.F2" title="Figure 2 ‣ 3 Dataset Construction ‣ Probing Causality Manipulation of Large Language Models"><span class="ltx_text ltx_ref_tag">2</span></a> gives instance of three actions.</p>
</div>
<div class="ltx_para" id="S3.SS0.SSS0.Px2.p2">
<p class="ltx_p" id="S3.SS0.SSS0.Px2.p2.1"><span class="ltx_text ltx_font_bold" id="S3.SS0.SSS0.Px2.p2.1.1">Action 1: Local Causation Disturbing</span>
We swap the order of cause and effect <span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>Cause and effect of CMedCausal usally contains medical named entities.</span></span></span> in positive instance, to probe model manipulation of single causation in sentences.
We filter the corresponding original texts with a limited length.
Passages are segmented using a Chinese full stop character, and we select minimum continuous sentence sequence <span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>The sequence starts with first sentence contains causal mentions and ends with the last sentence contains causal mentions.</span></span></span> containing modified parts.</p>
</div>
<div class="ltx_para" id="S3.SS0.SSS0.Px2.p3">
<p class="ltx_p" id="S3.SS0.SSS0.Px2.p3.1"><span class="ltx_text ltx_font_bold" id="S3.SS0.SSS0.Px2.p3.1.1">Action 2: Global Causation Disturbing</span>
This action introduces a stronger disturbance for global semantics.
We shuffle all entities mentioned in any causation (no matter they are causes or effects), and put entities in shuffled order to produce a negative instance.</p>
</div>
<div class="ltx_para" id="S3.SS0.SSS0.Px2.p4">
<p class="ltx_p" id="S3.SS0.SSS0.Px2.p4.6"><span class="ltx_text ltx_font_bold" id="S3.SS0.SSS0.Px2.p4.6.2">Action 3: Mutual Causation Disturbing</span>
This action delves into the model’s further understanding of causation, specifically focusing on interactions between causation, which is based on cognition of causation.
We select two sentences with causation, pinpoint one causation in each sentence and swap another. For example, <math alttext="A\to B" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px2.p4.1.m1.1"><semantics id="S3.SS0.SSS0.Px2.p4.1.m1.1a"><mrow id="S3.SS0.SSS0.Px2.p4.1.m1.1.1" xref="S3.SS0.SSS0.Px2.p4.1.m1.1.1.cmml"><mi id="S3.SS0.SSS0.Px2.p4.1.m1.1.1.2" xref="S3.SS0.SSS0.Px2.p4.1.m1.1.1.2.cmml">A</mi><mo id="S3.SS0.SSS0.Px2.p4.1.m1.1.1.1" stretchy="false" xref="S3.SS0.SSS0.Px2.p4.1.m1.1.1.1.cmml">→</mo><mi id="S3.SS0.SSS0.Px2.p4.1.m1.1.1.3" xref="S3.SS0.SSS0.Px2.p4.1.m1.1.1.3.cmml">B</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px2.p4.1.m1.1b"><apply id="S3.SS0.SSS0.Px2.p4.1.m1.1.1.cmml" xref="S3.SS0.SSS0.Px2.p4.1.m1.1.1"><ci id="S3.SS0.SSS0.Px2.p4.1.m1.1.1.1.cmml" xref="S3.SS0.SSS0.Px2.p4.1.m1.1.1.1">→</ci><ci id="S3.SS0.SSS0.Px2.p4.1.m1.1.1.2.cmml" xref="S3.SS0.SSS0.Px2.p4.1.m1.1.1.2">𝐴</ci><ci id="S3.SS0.SSS0.Px2.p4.1.m1.1.1.3.cmml" xref="S3.SS0.SSS0.Px2.p4.1.m1.1.1.3">𝐵</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px2.p4.1.m1.1c">A\to B</annotation><annotation encoding="application/x-llamapun" id="S3.SS0.SSS0.Px2.p4.1.m1.1d">italic_A → italic_B</annotation></semantics></math> (represents <math alttext="A" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px2.p4.2.m2.1"><semantics id="S3.SS0.SSS0.Px2.p4.2.m2.1a"><mi id="S3.SS0.SSS0.Px2.p4.2.m2.1.1" xref="S3.SS0.SSS0.Px2.p4.2.m2.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px2.p4.2.m2.1b"><ci id="S3.SS0.SSS0.Px2.p4.2.m2.1.1.cmml" xref="S3.SS0.SSS0.Px2.p4.2.m2.1.1">𝐴</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px2.p4.2.m2.1c">A</annotation><annotation encoding="application/x-llamapun" id="S3.SS0.SSS0.Px2.p4.2.m2.1d">italic_A</annotation></semantics></math><span class="ltx_text ltx_font_italic" id="S3.SS0.SSS0.Px2.p4.3.1"> causes <math alttext="B" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px2.p4.3.1.m1.1"><semantics id="S3.SS0.SSS0.Px2.p4.3.1.m1.1a"><mi id="S3.SS0.SSS0.Px2.p4.3.1.m1.1.1" xref="S3.SS0.SSS0.Px2.p4.3.1.m1.1.1.cmml">B</mi><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px2.p4.3.1.m1.1b"><ci id="S3.SS0.SSS0.Px2.p4.3.1.m1.1.1.cmml" xref="S3.SS0.SSS0.Px2.p4.3.1.m1.1.1">𝐵</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px2.p4.3.1.m1.1c">B</annotation><annotation encoding="application/x-llamapun" id="S3.SS0.SSS0.Px2.p4.3.1.m1.1d">italic_B</annotation></semantics></math></span>) and <math alttext="C\to D" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px2.p4.4.m3.1"><semantics id="S3.SS0.SSS0.Px2.p4.4.m3.1a"><mrow id="S3.SS0.SSS0.Px2.p4.4.m3.1.1" xref="S3.SS0.SSS0.Px2.p4.4.m3.1.1.cmml"><mi id="S3.SS0.SSS0.Px2.p4.4.m3.1.1.2" xref="S3.SS0.SSS0.Px2.p4.4.m3.1.1.2.cmml">C</mi><mo id="S3.SS0.SSS0.Px2.p4.4.m3.1.1.1" stretchy="false" xref="S3.SS0.SSS0.Px2.p4.4.m3.1.1.1.cmml">→</mo><mi id="S3.SS0.SSS0.Px2.p4.4.m3.1.1.3" xref="S3.SS0.SSS0.Px2.p4.4.m3.1.1.3.cmml">D</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px2.p4.4.m3.1b"><apply id="S3.SS0.SSS0.Px2.p4.4.m3.1.1.cmml" xref="S3.SS0.SSS0.Px2.p4.4.m3.1.1"><ci id="S3.SS0.SSS0.Px2.p4.4.m3.1.1.1.cmml" xref="S3.SS0.SSS0.Px2.p4.4.m3.1.1.1">→</ci><ci id="S3.SS0.SSS0.Px2.p4.4.m3.1.1.2.cmml" xref="S3.SS0.SSS0.Px2.p4.4.m3.1.1.2">𝐶</ci><ci id="S3.SS0.SSS0.Px2.p4.4.m3.1.1.3.cmml" xref="S3.SS0.SSS0.Px2.p4.4.m3.1.1.3">𝐷</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px2.p4.4.m3.1c">C\to D</annotation><annotation encoding="application/x-llamapun" id="S3.SS0.SSS0.Px2.p4.4.m3.1d">italic_C → italic_D</annotation></semantics></math> are swapped to yield <math alttext="A\to D" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px2.p4.5.m4.1"><semantics id="S3.SS0.SSS0.Px2.p4.5.m4.1a"><mrow id="S3.SS0.SSS0.Px2.p4.5.m4.1.1" xref="S3.SS0.SSS0.Px2.p4.5.m4.1.1.cmml"><mi id="S3.SS0.SSS0.Px2.p4.5.m4.1.1.2" xref="S3.SS0.SSS0.Px2.p4.5.m4.1.1.2.cmml">A</mi><mo id="S3.SS0.SSS0.Px2.p4.5.m4.1.1.1" stretchy="false" xref="S3.SS0.SSS0.Px2.p4.5.m4.1.1.1.cmml">→</mo><mi id="S3.SS0.SSS0.Px2.p4.5.m4.1.1.3" xref="S3.SS0.SSS0.Px2.p4.5.m4.1.1.3.cmml">D</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px2.p4.5.m4.1b"><apply id="S3.SS0.SSS0.Px2.p4.5.m4.1.1.cmml" xref="S3.SS0.SSS0.Px2.p4.5.m4.1.1"><ci id="S3.SS0.SSS0.Px2.p4.5.m4.1.1.1.cmml" xref="S3.SS0.SSS0.Px2.p4.5.m4.1.1.1">→</ci><ci id="S3.SS0.SSS0.Px2.p4.5.m4.1.1.2.cmml" xref="S3.SS0.SSS0.Px2.p4.5.m4.1.1.2">𝐴</ci><ci id="S3.SS0.SSS0.Px2.p4.5.m4.1.1.3.cmml" xref="S3.SS0.SSS0.Px2.p4.5.m4.1.1.3">𝐷</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px2.p4.5.m4.1c">A\to D</annotation><annotation encoding="application/x-llamapun" id="S3.SS0.SSS0.Px2.p4.5.m4.1d">italic_A → italic_D</annotation></semantics></math> and <math alttext="C\to B" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px2.p4.6.m5.1"><semantics id="S3.SS0.SSS0.Px2.p4.6.m5.1a"><mrow id="S3.SS0.SSS0.Px2.p4.6.m5.1.1" xref="S3.SS0.SSS0.Px2.p4.6.m5.1.1.cmml"><mi id="S3.SS0.SSS0.Px2.p4.6.m5.1.1.2" xref="S3.SS0.SSS0.Px2.p4.6.m5.1.1.2.cmml">C</mi><mo id="S3.SS0.SSS0.Px2.p4.6.m5.1.1.1" stretchy="false" xref="S3.SS0.SSS0.Px2.p4.6.m5.1.1.1.cmml">→</mo><mi id="S3.SS0.SSS0.Px2.p4.6.m5.1.1.3" xref="S3.SS0.SSS0.Px2.p4.6.m5.1.1.3.cmml">B</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px2.p4.6.m5.1b"><apply id="S3.SS0.SSS0.Px2.p4.6.m5.1.1.cmml" xref="S3.SS0.SSS0.Px2.p4.6.m5.1.1"><ci id="S3.SS0.SSS0.Px2.p4.6.m5.1.1.1.cmml" xref="S3.SS0.SSS0.Px2.p4.6.m5.1.1.1">→</ci><ci id="S3.SS0.SSS0.Px2.p4.6.m5.1.1.2.cmml" xref="S3.SS0.SSS0.Px2.p4.6.m5.1.1.2">𝐶</ci><ci id="S3.SS0.SSS0.Px2.p4.6.m5.1.1.3.cmml" xref="S3.SS0.SSS0.Px2.p4.6.m5.1.1.3">𝐵</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px2.p4.6.m5.1c">C\to B</annotation><annotation encoding="application/x-llamapun" id="S3.SS0.SSS0.Px2.p4.6.m5.1d">italic_C → italic_B</annotation></semantics></math>.
And then altered causation is placed into original sentences to produce negative instances.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Probing Design</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">In this section, we propose a hierarchical probing approach.
As shown in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ Probing Causality Manipulation of Large Language Models"><span class="ltx_text ltx_ref_tag">1</span></a>, our method provides "shortcuts" hierarchically to LLMs in classification tasks.
These shortcuts include necessary steps for causality manipulation, like entities recognition and alignment, causal relation cognition.
By comparing whether these shortcuts are beneficial to tasks performance, intrinsic manipulation of causality is probed.
We exploit a combination of RAG and ICL for providing shortcuts to guide LLMs.
For evaluation, we rewrite classification tasks in Sec. <a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#S3" title="3 Dataset Construction ‣ Probing Causality Manipulation of Large Language Models"><span class="ltx_text ltx_ref_tag">3</span></a> into a question and answer form, requesting LLMs to judge whether causality of the sentence is right.</p>
</div>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Hierarchical Retrieval Augmented Generation</h3>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">We add different augmentation for LLMs, forming a hierarchical structure in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ Probing Causality Manipulation of Large Language Models"><span class="ltx_text ltx_ref_tag">1</span></a>, notated as <span class="ltx_text ltx_font_italic" id="S4.SS1.p1.1.1">layers</span>.
For each layer, we retrieve most relevant sentences and attach them in questions for LLMs.
From layer 1 to layer 3, we provide more complex guidance from shortcuts, representing a more ideal and detailed manipulation of causality. And we aim to probe whether models show identical manipulation as guided, which can be observed from performance changes.</p>
</div>
<section class="ltx_paragraph" id="S4.SS1.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Layer 1: No Augmentation</h4>
<div class="ltx_para" id="S4.SS1.SSS0.Px1.p1">
<p class="ltx_p" id="S4.SS1.SSS0.Px1.p1.1">This layer offers no augmentation for LLMs, to demonstrate models native manipulation.</p>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS1.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Layer 2: Original CMedCausal</h4>
<div class="ltx_para" id="S4.SS1.SSS0.Px2.p1">
<p class="ltx_p" id="S4.SS1.SSS0.Px2.p1.1">This layer provides the most efficient shortcuts, that is, the original passages used in dataset construction.
These shortcuts are derived from the original CMedCausal, serving as gold standard for classification. Consequently, this layer guides models to infer about basic causality, probing causal entities recognition and causality understanding.</p>
</div>
<div class="ltx_para" id="S4.SS1.SSS0.Px2.p2">
<p class="ltx_p" id="S4.SS1.SSS0.Px2.p2.1">Additionally, we exploit back-translation for this layer, notated as <span class="ltx_text ltx_font_bold" id="S4.SS1.SSS0.Px2.p2.1.1">Layer 2.5: Original CMedCausal (back-translated)</span>, implementation details can be found in Appendix. <a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#A2" title="Appendix B Back Translation Implementation ‣ Probing Causality Manipulation of Large Language Models"><span class="ltx_text ltx_ref_tag">B</span></a>.</p>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS1.SSS0.Px3">
<h4 class="ltx_title ltx_title_paragraph">Layer 3: Universal Medical-KG</h4>
<div class="ltx_para" id="S4.SS1.SSS0.Px3.p1">
<p class="ltx_p" id="S4.SS1.SSS0.Px3.p1.1">This classification dataset is in medical domain w common diseases in Chinese.
And we supplement the necessary medical knowledge, aiming to guide models to infer latent causality in sentences. LLMs are required to recognize entities and derive causality in knowledge.
To provide proper medical knowledge, we use a Chinese common disease knowledge graph, DiseaseKG<span class="ltx_note ltx_role_footnote" id="footnote4"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span><a class="ltx_ref ltx_href" href="https://github.com/nuolade/disease-kb" title="">https://github.com/nuolade/disease-kb</a></span></span></span>. We discuss about effectiveness of augmented knowledge in Appendix. <a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#A3" title="Appendix C Discussion of External Knowledge in Layer 3 ‣ Probing Causality Manipulation of Large Language Models"><span class="ltx_text ltx_ref_tag">C</span></a>.</p>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS1.SSS0.Px4">
<h4 class="ltx_title ltx_title_paragraph">Retrieval Augmented Generation</h4>
<div class="ltx_para" id="S4.SS1.SSS0.Px4.p1">
<p class="ltx_p" id="S4.SS1.SSS0.Px4.p1.1">To extract medical information from a large corpus, we adopt a retriever-reader pipeline <cite class="ltx_cite ltx_citemacro_citep">(Chen et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#bib.bib4" title="">2017</a>)</cite>. By integrating the retrieved knowledge with the questions, the model can gain more medical expertise, enhancing the accuracy of its answers. Additionally, efforts should be made to minimize the influence of specialized knowledge on the model’s ability to discern causality. The specific method of retrieval can be referred to in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#A4" title="Appendix D Retrieval Augmentation Design ‣ Probing Causality Manipulation of Large Language Models"><span class="ltx_text ltx_ref_tag">D</span></a>.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>In Context Learning Design</h3>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">In this section, we mainly exploit ICL for guidance of LLMs.
In detail, our main approach include prompt engineering.
Moreover, we integrate chain of thought <cite class="ltx_cite ltx_citemacro_citep">(Kojima et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#bib.bib19" title="">2022</a>; Zhou et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#bib.bib36" title="">2023</a>; Wei et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#bib.bib32" title="">2022b</a>)</cite> in prompts as further shortcuts.</p>
</div>
<div class="ltx_para" id="S4.SS2.p2">
<p class="ltx_p" id="S4.SS2.p2.1">We provide prompts with necessary information, following a prompt framework in community <span class="ltx_note ltx_role_footnote" id="footnote5"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span><a class="ltx_ref ltx_href" href="https://www.promptingguide.ai/" title="">https://www.promptingguide.ai/</a></span></span></span>.
We do not conduct further prompt engineering, since we believe that LLMs should comprehends natural prompts.
Prompt includes instructions, contexts, input data and output indicator, introduction of these components can be found in Appendix. <a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#A5.SS1" title="E.1 Structure of Prompts ‣ Appendix E Prompts ‣ Probing Causality Manipulation of Large Language Models"><span class="ltx_text ltx_ref_tag">E.1</span></a>.</p>
</div>
<div class="ltx_para" id="S4.SS2.p3">
<p class="ltx_p" id="S4.SS2.p3.1">The <span class="ltx_text ltx_font_bold" id="S4.SS2.p3.1.1">simple prompt</span> provides components mentioned above, but no additional guidance. It is used to probe native thinking process directly.
In order to better exploit causality ability of LLMs, we use <span class="ltx_text ltx_font_bold" id="S4.SS2.p3.1.2">advanced prompt</span> for additional experiments, indicating an upper bound.
Advanced prompt integrates chain of thoughts similar to <cite class="ltx_cite ltx_citemacro_citep">(Wei et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#bib.bib32" title="">2022b</a>)</cite>, which prompts models with types of mistakes (e.g. wrong orders of entities in causality), and instruct models to give an explanation and then conduct classification.
Since final sentences concatenated will be very long, we append some part of sentence (i.e. knowledge provided) into history with a multiple rounds dialog.
Examples of simple prompt and advanced prompt can be found in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#A5.SS2" title="E.2 Examples of Prompts ‣ E.1 Structure of Prompts ‣ Appendix E Prompts ‣ Probing Causality Manipulation of Large Language Models"><span class="ltx_text ltx_ref_tag">E.2</span></a>.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Experiments</h2>
<section class="ltx_subsection" id="S5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Experiment Settings</h3>
<section class="ltx_paragraph" id="S5.SS1.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Model Selection</h4>
<div class="ltx_para" id="S5.SS1.SSS0.Px1.p1">
<p class="ltx_p" id="S5.SS1.SSS0.Px1.p1.1">During models selection, language preference, domains preference, parameters size and feasibility of probing are considered during models selection.
So we select following models:</p>
</div>
<div class="ltx_para" id="S5.SS1.SSS0.Px1.p2">
<p class="ltx_p" id="S5.SS1.SSS0.Px1.p2.1"><span class="ltx_text ltx_font_bold" id="S5.SS1.SSS0.Px1.p2.1.1">GPT-4</span> <cite class="ltx_cite ltx_citemacro_citep">(OpenAI, <a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#bib.bib23" title="">2023</a>)</cite>,
<span class="ltx_text ltx_font_bold" id="S5.SS1.SSS0.Px1.p2.1.2">GPT-3.5</span> <cite class="ltx_cite ltx_citemacro_citep">(Ouyang et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#bib.bib24" title="">2022</a>)</cite>,
<span class="ltx_text ltx_font_bold" id="S5.SS1.SSS0.Px1.p2.1.3">ChatGLM</span> <cite class="ltx_cite ltx_citemacro_citep">(Zeng et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#bib.bib34" title="">2023</a>; Du et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#bib.bib9" title="">2022b</a>)</cite> and
<span class="ltx_text ltx_font_bold" id="S5.SS1.SSS0.Px1.p2.1.4">MedChatGLM</span> <span class="ltx_note ltx_role_footnote" id="footnote6"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_tag ltx_tag_note">6</span><a class="ltx_ref ltx_href" href="https://github.com/SCIR-HI/Med-ChatGLM" title="">https://github.com/SCIR-HI/Med-ChatGLM</a></span></span></span>.
For comparison, we use <span class="ltx_text ltx_font_bold" id="S5.SS1.SSS0.Px1.p2.1.5">BERT</span> <cite class="ltx_cite ltx_citemacro_citep">(Devlin et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#bib.bib7" title="">2019</a>)</cite> with surpervised learning. Appendix <a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#A6" title="Appendix F Details of Models ‣ E.2 Examples of Prompts ‣ E.1 Structure of Prompts ‣ Appendix E Prompts ‣ Probing Causality Manipulation of Large Language Models"><span class="ltx_text ltx_ref_tag">F</span></a> provides detailed settings.</p>
</div>
</section>
<section class="ltx_paragraph" id="S5.SS1.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Evaluations</h4>
<div class="ltx_para" id="S5.SS1.SSS0.Px2.p1">
<p class="ltx_p" id="S5.SS1.SSS0.Px2.p1.1">We extract responses from LLMs with an automatic program, and manually check unmatched responses.
Only decisions of models (<span class="ltx_text ltx_font_italic" id="S5.SS1.SSS0.Px2.p1.1.1">right</span> or <span class="ltx_text ltx_font_italic" id="S5.SS1.SSS0.Px2.p1.1.2">wrong</span>) are regarded as classification results.
Unclear answers like <span class="ltx_text ltx_font_italic" id="S5.SS1.SSS0.Px2.p1.1.3">I don’t know</span> are neglected in summary.</p>
</div>
<div class="ltx_para" id="S5.SS1.SSS0.Px2.p2">
<p class="ltx_p" id="S5.SS1.SSS0.Px2.p2.1">For binary classification, we evaluate performance with F1-score (F1). Additionally, we exploit Matthews correlation coefficient (MCC) <cite class="ltx_cite ltx_citemacro_citep">(Matthews, <a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#bib.bib21" title="">1975</a>)</cite> to measure coefficient of predictions and labels, in order to distinguish random classifications.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S5.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Results</h3>
<section class="ltx_paragraph" id="S5.SS2.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Probing native manipulation</h4>
<div class="ltx_para" id="S5.SS2.SSS0.Px1.p1">
<p class="ltx_p" id="S5.SS2.SSS0.Px1.p1.1">We probe LLMs with different parameters size (GPT-3.5 and ChatGLM) on simple prompts, and conduct parallel experiments on supervised BERT for comparison.
Results are shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#S5.T1" title="Table 1 ‣ Probing manipulation on advanced prompt ‣ 5.2 Results ‣ 5 Experiments ‣ Probing Causality Manipulation of Large Language Models"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
</section>
<section class="ltx_paragraph" id="S5.SS2.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Probing manipulation on advanced prompt</h4>
<div class="ltx_para" id="S5.SS2.SSS0.Px2.p1">
<p class="ltx_p" id="S5.SS2.SSS0.Px2.p1.1">We integrate advanced prompt to better exploit ability of LLMs, results are shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#S5.T2" title="Table 2 ‣ Probing manipulation on advanced prompt ‣ 5.2 Results ‣ 5 Experiments ‣ Probing Causality Manipulation of Large Language Models"><span class="ltx_text ltx_ref_tag">2</span></a>.
This is main evidence for subsequent probing.</p>
</div>
<figure class="ltx_table" id="S5.T1">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S5.T1.1" style="width:433.6pt;height:267.4pt;vertical-align:-261.1pt;"><span class="ltx_transformed_inner" style="transform:translate(-22.2pt,0.3pt) scale(0.907047668317443,0.907047668317443) ;"><span class="ltx_ERROR undefined" id="S5.T1.1.1">{tblr}</span>
<p class="ltx_p" id="S5.T1.1.2">cells = c,
row2 = TitanWhite,
cell11 = c=2,r=2,
cell13 = c=2,
cell15 = c=2,
cell17 = c=2,
cell23 = SnowyMint,
cell25 = SnowyMint,
cell27 = SnowyMint,
cell31 = r=3,
cell33 = SnowyMint,
cell34 = TitanWhite,
cell35 = SnowyMint,
cell36 = TitanWhite,
cell37 = SnowyMint,
cell38 = TitanWhite,
cell43 = SnowyMint,
cell44 = TitanWhite,
cell45 = SnowyMint,
cell46 = TitanWhite,
cell47 = SnowyMint,
cell48 = TitanWhite,
cell53 = SnowyMint,
cell54 = TitanWhite,
cell55 = SnowyMint,
cell56 = TitanWhite,
cell57 = SnowyMint,
cell58 = TitanWhite,
cell61 = r=3,
cell63 = SnowyMint,
cell64 = TitanWhite,
cell65 = SnowyMint,
cell66 = TitanWhite,
cell67 = SnowyMint,
cell68 = TitanWhite,
cell73 = SnowyMint,
cell74 = TitanWhite,
cell75 = SnowyMint,
cell76 = TitanWhite,
cell77 = SnowyMint,
cell78 = TitanWhite,
cell83 = SnowyMint,
cell84 = TitanWhite,
cell85 = SnowyMint,
cell86 = TitanWhite,
cell87 = SnowyMint,
cell88 = TitanWhite,
cell91 = r=3,
cell93 = SnowyMint,
cell94 = TitanWhite,
cell95 = SnowyMint,
cell96 = TitanWhite,
cell97 = SnowyMint,
cell98 = TitanWhite,
cell103 = SnowyMint,
cell104 = TitanWhite,
cell105 = SnowyMint,
cell106 = TitanWhite,
cell107 = SnowyMint,
cell108 = TitanWhite,
cell113 = SnowyMint,
cell114 = TitanWhite,
cell115 = SnowyMint,
cell116 = TitanWhite,
cell117 = SnowyMint,
cell118 = TitanWhite,
hline1,3,6,9,12 = -,
hline4-5,7-8,10-11 = 2-8dashed,

Models &amp;  ChatGLM   GPT-3.5   BERT  
<br class="ltx_break"/>  F1  MCC  F1  MCC  F1  MCC 
<br class="ltx_break"/>Act 1  L1  0.63  0.27  0.67  0.26  0.79  0.56 
<br class="ltx_break"/> L2  0.53  0.14  0.68  0.25  0.84  0.67 
<br class="ltx_break"/> L3  0.21  0.06  0.65  0.11  0.78  0.52 
<br class="ltx_break"/>Act 2  L1  0.57  0.33  0.74  0.50  0.77  0.48 
<br class="ltx_break"/> L2  0.52  0.24  0.73  0.38  0.80  0.56 
<br class="ltx_break"/> L3  0.15  0.11  0.67  0.22  0.68  0.22 
<br class="ltx_break"/>Act 3  L1  0.13  0.04  0.62  0.24  0.89  0.76 
<br class="ltx_break"/> L2  0.02  0.02  0.53  0.11  0.88  0.76 
<br class="ltx_break"/> L3  0.16  0.09  0.52  0.18  0.81  0.62</p>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Overall F1 and MCC results on simple prompts, <span class="ltx_text ltx_font_italic" id="S5.T1.3.1">Ln</span> stands for knowledge enhancement in layer n.</figcaption>
</figure>
<figure class="ltx_table" id="S5.T2">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S5.T2.1" style="width:433.6pt;height:404.7pt;vertical-align:-398.5pt;"><span class="ltx_transformed_inner" style="transform:translate(-24.7pt,0.4pt) scale(0.897659009977039,0.897659009977039) ;"><span class="ltx_ERROR undefined" id="S5.T2.1.1">{tblr}</span>
<p class="ltx_p" id="S5.T2.1.2">cells = c,
row2 = TitanWhite,
cell11 = c=2,r=2,
cell13 = c=2,
cell15 = c=2,
cell17 = c=2,
cell19 = c=2,
cell23 = SnowyMint,
cell25 = SnowyMint,
cell27 = SnowyMint,
cell29 = SnowyMint,
cell31 = r=4,
cell33 = SnowyMint,
cell34 = TitanWhite,
cell35 = SnowyMint,
cell36 = TitanWhite,
cell37 = SnowyMint,
cell38 = TitanWhite,
cell39 = SnowyMint,
cell310 = TitanWhite,
cell43 = SnowyMint,
cell44 = TitanWhite,
cell45 = SnowyMint,
cell46 = TitanWhite,
cell47 = SnowyMint,
cell48 = TitanWhite,
cell49 = SnowyMint,
cell410 = TitanWhite,
cell53 = SnowyMint,
cell54 = TitanWhite,
cell55 = SnowyMint,
cell56 = TitanWhite,
cell57 = SnowyMint,
cell58 = TitanWhite,
cell59 = SnowyMint,
cell510 = TitanWhite,
cell63 = SnowyMint,
cell64 = TitanWhite,
cell65 = SnowyMint,
cell66 = TitanWhite,
cell67 = SnowyMint,
cell68 = TitanWhite,
cell69 = SnowyMint,
cell610 = TitanWhite,
cell71 = r=4,
cell73 = SnowyMint,
cell74 = TitanWhite,
cell75 = SnowyMint,
cell76 = TitanWhite,
cell77 = SnowyMint,
cell78 = TitanWhite,
cell79 = SnowyMint,
cell710 = TitanWhite,
cell83 = SnowyMint,
cell84 = TitanWhite,
cell85 = SnowyMint,
cell86 = TitanWhite,
cell87 = SnowyMint,
cell88 = TitanWhite,
cell89 = SnowyMint,
cell810 = TitanWhite,
cell93 = SnowyMint,
cell94 = TitanWhite,
cell95 = SnowyMint,
cell96 = TitanWhite,
cell97 = SnowyMint,
cell98 = TitanWhite,
cell99 = SnowyMint,
cell910 = TitanWhite,
cell103 = SnowyMint,
cell104 = TitanWhite,
cell105 = SnowyMint,
cell106 = TitanWhite,
cell107 = SnowyMint,
cell108 = TitanWhite,
cell109 = SnowyMint,
cell1010 = TitanWhite,
cell111 = r=4,
cell113 = SnowyMint,
cell114 = TitanWhite,
cell115 = SnowyMint,
cell116 = TitanWhite,
cell117 = SnowyMint,
cell118 = TitanWhite,
cell119 = SnowyMint,
cell1110 = TitanWhite,
cell123 = SnowyMint,
cell124 = TitanWhite,
cell125 = SnowyMint,
cell126 = TitanWhite,
cell127 = SnowyMint,
cell128 = TitanWhite,
cell129 = SnowyMint,
cell1210 = TitanWhite,
cell133 = SnowyMint,
cell134 = TitanWhite,
cell135 = SnowyMint,
cell136 = TitanWhite,
cell137 = SnowyMint,
cell138 = TitanWhite,
cell139 = SnowyMint,
cell1310 = TitanWhite,
cell143 = SnowyMint,
cell144 = TitanWhite,
cell145 = SnowyMint,
cell146 = TitanWhite,
cell147 = SnowyMint,
cell148 = TitanWhite,
cell149 = SnowyMint,
cell1410 = TitanWhite,
hline1,3,11,15 = -,
hline4-6,8-10,12-14 = 2-10dashed,
hline7 = 1dashed,
hline7 = 2-10,

Models &amp;  GPT 4   GPT-3.5   ChatGLM   MedChatGLM  
<br class="ltx_break"/>  F1  MCC  F1  MCC  F1  MCC  F1  MCC 
<br class="ltx_break"/>Act 1  L1  0.71  0.33  0.68  0.27  0.63  0.14  0.52  0.06 
<br class="ltx_break"/> L2  0.86  0.71  0.75  0.42  0.53  0.21  0.57  0.08 
<br class="ltx_break"/> L2.5  0.81  0.60  0.16  0.13  0.47  0.13  0.55  0.14 
<br class="ltx_break"/> L3  0.76  0.46  0.68  0.20  0.26  0.10  0.41  -0.10 
<br class="ltx_break"/>Act 2  L1  0.75  0.45  0.70  0.37  0.63  0.20  0.57  0.14 
<br class="ltx_break"/> L2  0.84  0.66  0.80  0.56  0.50  0.30  0.55  -0.02 
<br class="ltx_break"/> L2.5  0.79  0.55  0.76  0.46  0.63  0.40  0.58  0.08 
<br class="ltx_break"/> L3  0.75  0.46  0.73  0.36  0.21  0.12  0.52  -0.04 
<br class="ltx_break"/>Act 3  L1  0.41  0.39  0.50  0.21  0.26  0.07  0.41  -0.04 
<br class="ltx_break"/> L2  0.39  0.37  0.34  0.12  0.06  0.00  0.51  -0.04 
<br class="ltx_break"/> L2.5  0.60  0.50  0.36  0.17  0.07  0.01  0.30  -0.23 
<br class="ltx_break"/> L3  0.58  0.48  0.42  0.19  0.04  0.03  0.50  0.04</p>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Overall results for advanced prompts, <span class="ltx_text ltx_font_italic" id="S5.T2.3.1">Ln</span> stands for knowledge enhancement in layer n.</figcaption>
</figure>
</section>
</section>
<section class="ltx_subsection" id="S5.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3 </span>Analysis</h3>
<section class="ltx_paragraph" id="S5.SS3.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Overall Analysis</h4>
<div class="ltx_para" id="S5.SS3.SSS0.Px1.p1">
<p class="ltx_p" id="S5.SS3.SSS0.Px1.p1.1">(1) Experimental results of MCC show that LLMs have weak causality ability on given classification task.
But it is not comparable with supervised models like BERT.
(2) Performance of LLMs varies. Reasons may include parameters, training strategies and domain knowledge. We discuss this in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#A7" title="Appendix G Performance Difference of LLMs ‣ E.2 Examples of Prompts ‣ E.1 Structure of Prompts ‣ Appendix E Prompts ‣ Probing Causality Manipulation of Large Language Models"><span class="ltx_text ltx_ref_tag">G</span></a>.
(3) Additionally, models show preferences for different actions in dataset, as shown in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#S5.F3" title="Figure 3 ‣ Global Semantics ‣ 5.3 Analysis ‣ 5 Experiments ‣ Probing Causality Manipulation of Large Language Models"><span class="ltx_text ltx_ref_tag">3</span></a>.</p>
</div>
</section>
<section class="ltx_paragraph" id="S5.SS3.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Global Semantics</h4>
<div class="ltx_para" id="S5.SS3.SSS0.Px2.p1">
<p class="ltx_p" id="S5.SS3.SSS0.Px2.p1.1">Global semantic is the key for classification, we derive this from actions preferences of models.
Action 2 integrates more modification from statistical perspective, which is easy for models to distinguish.
We evaluate perplexity of sentences in Appendix. <a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#A8" title="Appendix H PPL of Positive and Negative Instances ‣ E.2 Examples of Prompts ‣ E.1 Structure of Prompts ‣ Appendix E Prompts ‣ Probing Causality Manipulation of Large Language Models"><span class="ltx_text ltx_ref_tag">H</span></a> to prove this.
GPT-4 performs better in action 1 when knowledge is given, since it gains more instruction ability.
This tendency excludes MedChatGLM, as its MCC approaches to 0 and not indicative for analysis.
This tendency persists regardless of the prompts used.</p>
</div>
<figure class="ltx_figure" id="S5.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="796" id="S5.F3.1.g1" src="x3.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Trend of MCC with three actions in different models and different layers (Using Advanced Prompt).</figcaption>
</figure>
</section>
<section class="ltx_paragraph" id="S5.SS3.SSS0.Px3">
<h4 class="ltx_title ltx_title_paragraph">Entities In Causality</h4>
<div class="ltx_para" id="S5.SS3.SSS0.Px3.p1">
<p class="ltx_p" id="S5.SS3.SSS0.Px3.p1.1">(1) Discovering entities in causality is less important in manipulation than global semantics.
This is derived from action preferences as mentioned above. Moreover, we conduct back-translation experiments for augmented knowledge in layer 2 and observe a performance drop for most cases.
Back-translation tends to preserve entities in sentences, since expressions of medical entities are usually standard in Chinese and English.
(2) LLMs lack ability of aligning entities and their establishing systematical relations.
Entities in sentence are focused as a result of attention mechanism, but LLMs except for GPT-4 can not exploit augmentation of layer 3.
Layer 3 should be beneficial in Appendix. <a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#A3" title="Appendix C Discussion of External Knowledge in Layer 3 ‣ Probing Causality Manipulation of Large Language Models"><span class="ltx_text ltx_ref_tag">C</span></a>. Comparing with layer 2.5, layer 3 provides entities in other form, and this indicates LLMs fail to recognize causes and effects in heterogeneous form.</p>
</div>
</section>
<section class="ltx_paragraph" id="S5.SS3.SSS0.Px4">
<h4 class="ltx_title ltx_title_paragraph">Causality Cognition</h4>
<div class="ltx_para" id="S5.SS3.SSS0.Px4.p1">
<p class="ltx_p" id="S5.SS3.SSS0.Px4.p1.1">LLMs do not show much specific cognition for causality, relying more on linguistic order and positions to demonstrate causality.
The performance of action 3 is the worst of the three and has even approached random categorization for some models (ChatGLM and MedChatGLM).
Augmentation of layer 1 even causes a performance drop, regardless prompt used for all models including GPT-4.
In contrast, the introduction of layer 2 in action 1 improves performance.
This is because action 3 disturbs mutual causation. To realize mutual disturbance (especially when gold standard is given in layer 1), models needs to recognize causation specifically first.</p>
</div>
</section>
<section class="ltx_paragraph" id="S5.SS3.SSS0.Px5">
<h4 class="ltx_title ltx_title_paragraph">Knowledge</h4>
<div class="ltx_para" id="S5.SS3.SSS0.Px5.p1">
<p class="ltx_p" id="S5.SS3.SSS0.Px5.p1.1">Background knowledge has little contributions, and only augmentation of layer 2 assist for classifications after guidance of advanced prompt.
(1) LLMs are native to believe its pretrained knowledge for classification.
(2) Background knowledge about causality confuses LLMs for classification, and intervene normal manipulation by internal knowledge.
(3) LLMs manipulation of causality relies on abstract principles summarized from internal knowledge, which is in an abstract level. Since MedChatGLM diminishes classification abilities of ChatGLM, and approaches to random classification.</p>
</div>
</section>
</section>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusion</h2>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">In this paper, we introduce an innovative structure tailored to investigate intrinsic manipulations of causality for LLMs.
We construct a classification dataset focusing on causal relations and entities in sentences.
Then we probe models’ performance on this classification dataset.
We provide "shortcuts" through RAG and ICL, and observe performance change in datasets.
Probing conclusion is derived by judging whether such shortcuts are beneficial.
Our result indicates that LLMs show certain ability of causal recognition, mainly as a result of global semantic. Causal entities and their relations lack for detailed and specific manipulation, especially for LLMs with smaller parameters.
Our probing work still has limitations. (1) Our conclusion is derived as a summary for various LLMs. Relation of causality and LLMs’ training strategies should be discussed.
(2) Our experiment lacks the ability for detailed discussion about supervised learning and zero-shot cases for causality.

</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bareinboim et al. (2022)</span>
<span class="ltx_bibblock">
Elias Bareinboim, Juan D. Correa, Duligur Ibeling, and Thomas Icard. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1145/3501714.3501743" title="">On pearl’s hierarchy and the foundations of causal inference</a>.

</span>
<span class="ltx_bibblock">In Hector Geffner, Rina Dechter, and Joseph Y. Halpern, editors, <em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">Probabilistic and Causal Inference: The Works of Judea Pearl</em>, volume 36 of <em class="ltx_emph ltx_font_italic" id="bib.bib1.2.2">ACM Books</em>, pages 507–556. ACM.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bhagavatula et al. (2020)</span>
<span class="ltx_bibblock">
Chandra Bhagavatula, Ronan Le Bras, Chaitanya Malaviya, Keisuke Sakaguchi, Ari Holtzman, Hannah Rashkin, Doug Downey, Wen-tau Yih, and Yejin Choi. 2020.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://openreview.net/forum?id=Byg1v1HKDB" title="">Abductive commonsense reasoning</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">8th International Conference on Learning Representations, ICLR 2020, Addis Ababa, Ethiopia, April 26-30, 2020</em>. OpenReview.net.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brown et al. (2020)</span>
<span class="ltx_bibblock">
Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. 2020.

</span>
<span class="ltx_bibblock">Language models are few-shot learners.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">Proceedings of the 34th International Conference on Neural Information Processing Systems</em>, NIPS’20, Red Hook, NY, USA. Curran Associates Inc.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. (2017)</span>
<span class="ltx_bibblock">
Danqi Chen, Adam Fisch, Jason Weston, and Antoine Bordes. 2017.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/P17-1171" title="">Reading Wikipedia to answer open-domain questions</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em>, pages 1870–1879, Vancouver, Canada. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. (2023)</span>
<span class="ltx_bibblock">
Jiangjie Chen, Wei Shi, Ziquan Fu, Sijie Cheng, Lei Li, and Yanghua Xiao. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2023.acl-long.550" title="">Say what you mean! large language models speak too positively about negative commonsense knowledge</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em>, pages 9890–9908, Toronto, Canada. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">DeepSeek-AI et al. (2024)</span>
<span class="ltx_bibblock">
DeepSeek-AI, :, Xiao Bi, Deli Chen, Guanting Chen, Shanhuang Chen, Damai Dai, Chengqi Deng, Honghui Ding, Kai Dong, Qiushi Du, Zhe Fu, Huazuo Gao, Kaige Gao, Wenjun Gao, Ruiqi Ge, Kang Guan, Daya Guo, Jianzhong Guo, Guangbo Hao, Zhewen Hao, Ying He, Wenjie Hu, Panpan Huang, Erhang Li, Guowei Li, Jiashi Li, Yao Li, Y. K. Li, Wenfeng Liang, Fangyun Lin, A. X. Liu, Bo Liu, Wen Liu, Xiaodong Liu, Xin Liu, Yiyuan Liu, Haoyu Lu, Shanghao Lu, Fuli Luo, Shirong Ma, Xiaotao Nie, Tian Pei, Yishi Piao, Junjie Qiu, Hui Qu, Tongzheng Ren, Zehui Ren, Chong Ruan, Zhangli Sha, Zhihong Shao, Junxiao Song, Xuecheng Su, Jingxiang Sun, Yaofeng Sun, Minghui Tang, Bingxuan Wang, Peiyi Wang, Shiyu Wang, Yaohui Wang, Yongji Wang, Tong Wu, Y. Wu, Xin Xie, Zhenda Xie, Ziwei Xie, Yiliang Xiong, Hanwei Xu, R. X. Xu, Yanhong Xu, Dejian Yang, Yuxiang You, Shuiping Yu, Xingkai Yu, B. Zhang, Haowei Zhang, Lecong Zhang, Liyue Zhang, Mingchuan Zhang, Minghua Zhang, Wentao Zhang, Yichao Zhang, Chenggang Zhao, Yao Zhao, Shangyan Zhou, Shunfeng Zhou, Qihao Zhu, and Yuheng Zou. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2401.02954" title="">Deepseek llm: Scaling open-source language models with longtermism</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">Preprint</em>, arXiv:2401.02954.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Devlin et al. (2019)</span>
<span class="ltx_bibblock">
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/N19-1423" title="">BERT: Pre-training of deep bidirectional transformers for language understanding</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)</em>, pages 4171–4186, Minneapolis, Minnesota. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Du et al. (2022a)</span>
<span class="ltx_bibblock">
Li Du, Xiao Ding, Kai Xiong, Ting Liu, and Bing Qin. 2022a.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2022.acl-long.33" title="">e-CARE: a new dataset for exploring explainable causal reasoning</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em>, pages 432–446, Dublin, Ireland. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Du et al. (2022b)</span>
<span class="ltx_bibblock">
Zhengxiao Du, Yujie Qian, Xiao Liu, Ming Ding, Jiezhong Qiu, Zhilin Yang, and Jie Tang. 2022b.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2022.acl-long.26" title="">GLM: General language model pretraining with autoregressive blank infilling</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em>, pages 320–335, Dublin, Ireland. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ganguli et al. (2022)</span>
<span class="ltx_bibblock">
Deep Ganguli, Danny Hernandez, Liane Lovitt, Amanda Askell, Yuntao Bai, Anna Chen, Tom Conerly, Nova DasSarma, Dawn Drain, Nelson Elhage, Sheer El Showk, Stanislav Fort, Zac Hatfield-Dodds, Tom Henighan, Scott Johnston, Andy Jones, Nicholas Joseph, Jackson Kernian, Shauna Kravec, Ben Mann, Neel Nanda, Kamal Ndousse, Catherine Olsson, Daniela Amodei, Tom Brown, Jared Kaplan, Sam McCandlish, Christopher Olah, Dario Amodei, and Jack Clark. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1145/3531146.3533229" title="">Predictability and surprise in large generative models</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">FAccT ’22: 2022 ACM Conference on Fairness, Accountability, and Transparency, Seoul, Republic of Korea, June 21 - 24, 2022</em>, pages 1747–1764. ACM.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gao et al. (2023)</span>
<span class="ltx_bibblock">
Jinglong Gao, Xiao Ding, Bing Qin, and Ting Liu. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2023.findings-emnlp.743" title="">Is ChatGPT a good causal reasoner? a comprehensive evaluation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">Findings of the Association for Computational Linguistics: EMNLP 2023</em>, pages 11111–11126, Singapore. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gao et al. (2019)</span>
<span class="ltx_bibblock">
Lei Gao, Prafulla Kumar Choubey, and Ruihong Huang. 2019.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/N19-1179" title="">Modeling document-level causal structures for event causal relation identification</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)</em>, pages 1808–1817, Minneapolis, Minnesota. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hewitt and Manning (2019)</span>
<span class="ltx_bibblock">
John Hewitt and Christopher D. Manning. 2019.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/N19-1419" title="">A structural probe for finding syntax in word representations</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)</em>, pages 4129–4138, Minneapolis, Minnesota. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hossain et al. (2023)</span>
<span class="ltx_bibblock">
Tamanna Hossain, Sunipa Dev, and Sameer Singh. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2023.acl-long.293" title="">MISGENDERED: Limits of large language models in understanding pronouns</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em>, pages 5352–5367, Toronto, Canada. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jiang et al. (2023)</span>
<span class="ltx_bibblock">
Albert Q. Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford, Devendra Singh Chaplot, Diego de las Casas, Florian Bressand, Gianna Lengyel, Guillaume Lample, Lucile Saulnier, Lélio Renard Lavaud, Marie-Anne Lachaux, Pierre Stock, Teven Le Scao, Thibaut Lavril, Thomas Wang, Timothée Lacroix, and William El Sayed. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2310.06825" title="">Mistral 7b</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">Preprint</em>, arXiv:2310.06825.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jin et al. (2024)</span>
<span class="ltx_bibblock">
Zhijing Jin, Jiarui Liu, Zhiheng LYU, Spencer Poff, Mrinmaya Sachan, Rada Mihalcea, Mona T. Diab, and Bernhard Schölkopf. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://openreview.net/forum?id=vqIH0ObdqL" title="">Can large language models infer causation from correlation?</a>
</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">The Twelfth International Conference on Learning Representations</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Johnson et al. (2021)</span>
<span class="ltx_bibblock">
Jeff Johnson, Matthijs Douze, and Hervé Jégou. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1109/TBDATA.2019.2921572" title="">Billion-scale similarity search with gpus</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">IEEE Transactions on Big Data</em>, 7(3):535–547.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kiciman et al. (2023)</span>
<span class="ltx_bibblock">
Emre Kiciman, Robert Ness, Amit Sharma, and Chenhao Tan. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.48550/ARXIV.2305.00050" title="">Causal reasoning and large language models: Opening a new frontier for causality</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">CoRR</em>, abs/2305.00050.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kojima et al. (2022)</span>
<span class="ltx_bibblock">
Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://papers.nips.cc/paper_files/paper/2022/hash/8bb0d291acd4acf06ef112099c16f326-Abstract-Conference.html" title="">Large language models are zero-shot reasoners</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">NeurIPS</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin et al. (2020)</span>
<span class="ltx_bibblock">
Bill Yuchen Lin, Wangchunshu Zhou, Ming Shen, Pei Zhou, Chandra Bhagavatula, Yejin Choi, and Xiang Ren. 2020.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2020.findings-emnlp.165" title="">CommonGen: A constrained text generation challenge for generative commonsense reasoning</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">Findings of the Association for Computational Linguistics: EMNLP 2020</em>, pages 1823–1840, Online. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Matthews (1975)</span>
<span class="ltx_bibblock">
B.W. Matthews. 1975.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1016/0005-2795(75)90109-9" title="">Comparison of the predicted and observed secondary structure of t4 phage lysozyme</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">Biochimica et Biophysica Acta (BBA) - Protein Structure</em>, 405(2):442–451.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mu and Li (2023)</span>
<span class="ltx_bibblock">
Feiteng Mu and Wenjie Li. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2023.acl-short.83" title="">Enhancing event causality identification with counterfactual reasoning</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)</em>, pages 967–975, Toronto, Canada. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">OpenAI (2023)</span>
<span class="ltx_bibblock">
OpenAI. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.48550/arXiv.2303.08774" title="">GPT-4 technical report</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">CoRR</em>, abs/2303.08774.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ouyang et al. (2022)</span>
<span class="ltx_bibblock">
Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, John Schulman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda Askell, Peter Welinder, Paul F Christiano, Jan Leike, and Ryan Lowe. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://proceedings.neurips.cc/paper_files/paper/2022/file/b1efde53be364a73914f58805a001731-Paper-Conference.pdf" title="">Training language models to follow instructions with human feedback</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">Advances in Neural Information Processing Systems</em>, volume 35, pages 27730–27744. Curran Associates, Inc.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Radford et al. (2019)</span>
<span class="ltx_bibblock">
Alec Radford, Jeff Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever. 2019.

</span>
<span class="ltx_bibblock">Language models are unsupervised multitask learners.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ramezani and Xu (2023)</span>
<span class="ltx_bibblock">
Aida Ramezani and Yang Xu. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2023.acl-long.26" title="">Knowledge of cultural moral norms in large language models</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib26.1.1">Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em>, pages 428–446, Toronto, Canada. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Reimers and Gurevych (2019)</span>
<span class="ltx_bibblock">
Nils Reimers and Iryna Gurevych. 2019.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/D19-1410" title="">Sentence-BERT: Sentence embeddings using Siamese BERT-networks</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</em>, pages 3982–3992, Hong Kong, China. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Stolfo et al. (2023)</span>
<span class="ltx_bibblock">
Alessandro Stolfo, Zhijing Jin, Kumar Shridhar, Bernhard Schoelkopf, and Mrinmaya Sachan. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2023.acl-long.32" title="">A causal framework to quantify the robustness of mathematical reasoning with language models</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib28.1.1">Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em>, pages 545–561, Toronto, Canada. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Talmor et al. (2019)</span>
<span class="ltx_bibblock">
Alon Talmor, Jonathan Herzig, Nicholas Lourie, and Jonathan Berant. 2019.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/N19-1421" title="">CommonsenseQA: A question answering challenge targeting commonsense knowledge</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib29.1.1">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)</em>, pages 4149–4158, Minneapolis, Minnesota. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tan et al. (2019)</span>
<span class="ltx_bibblock">
Hao Tan, Licheng Yu, and Mohit Bansal. 2019.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/N19-1268" title="">Learning to navigate unseen environments: Back translation with environmental dropout</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib30.1.1">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)</em>, pages 2610–2621, Minneapolis, Minnesota. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wei et al. (2022a)</span>
<span class="ltx_bibblock">
Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler, Ed H. Chi, Tatsunori Hashimoto, Oriol Vinyals, Percy Liang, Jeff Dean, and William Fedus. 2022a.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://openreview.net/forum?id=yzkSU5zdwD" title="">Emergent abilities of large language models</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib31.1.1">Trans. Mach. Learn. Res.</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wei et al. (2022b)</span>
<span class="ltx_bibblock">
Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed H. Chi, Quoc V. Le, and Denny Zhou. 2022b.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://papers.nips.cc/paper_files/paper/2022/hash/9d5609613524ecf4f15af0f7b31abca4-Abstract-Conference.html" title="">Chain-of-thought prompting elicits reasoning in large language models</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib32.1.1">NeurIPS</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zečević et al. (2023)</span>
<span class="ltx_bibblock">
Matej Zečević, Moritz Willig, Devendra Singh Dhami, and Kristian Kersting. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://openreview.net/forum?id=tv46tCzs83" title="">Causal parrots: Large language models may talk causality but are not causal</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib33.1.1">Transactions on Machine Learning Research</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zeng et al. (2023)</span>
<span class="ltx_bibblock">
Aohan Zeng, Xiao Liu, Zhengxiao Du, Zihan Wang, Hanyu Lai, Ming Ding, Zhuoyi Yang, Yifan Xu, Wendi Zheng, Xiao Xia, Weng Lam Tam, Zixuan Ma, Yufei Xue, Jidong Zhai, Wenguang Chen, Zhiyuan Liu, Peng Zhang, Yuxiao Dong, and Jie Tang. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://openreview.net/pdf?id=-Aw0rrrPUF" title="">GLM-130B: an open bilingual pre-trained model</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib34.1.1">The Eleventh International Conference on Learning Representations, ICLR 2023, Kigali, Rwanda, May 1-5, 2023</em>. OpenReview.net.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. (2022)</span>
<span class="ltx_bibblock">
Ningyu Zhang, Mosha Chen, Zhen Bi, Xiaozhuan Liang, Lei Li, Xin Shang, Kangping Yin, Chuanqi Tan, Jian Xu, Fei Huang, Luo Si, Yuan Ni, Guotong Xie, Zhifang Sui, Baobao Chang, Hui Zong, Zheng Yuan, Linfeng Li, Jun Yan, Hongying Zan, Kunli Zhang, Buzhou Tang, and Qingcai Chen. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2022.acl-long.544" title="">CBLUE: A Chinese biomedical language understanding evaluation benchmark</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib35.1.1">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em>, pages 7888–7915, Dublin, Ireland. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou et al. (2023)</span>
<span class="ltx_bibblock">
Denny Zhou, Nathanael Schärli, Le Hou, Jason Wei, Nathan Scales, Xuezhi Wang, Dale Schuurmans, Claire Cui, Olivier Bousquet, Quoc V. Le, and Ed H. Chi. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://openreview.net/pdf?id=WZH7099tgfM" title="">Least-to-most prompting enables complex reasoning in large language models</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib36.1.1">The Eleventh International Conference on Learning Representations, ICLR 2023, Kigali, Rwanda, May 1-5, 2023</em>. OpenReview.net.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<section class="ltx_appendix" id="A1">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Datasets Details And Statistics</h2>
<div class="ltx_para" id="A1.p1">
<p class="ltx_p" id="A1.p1.1">The CMedCausal dataset <cite class="ltx_cite ltx_citemacro_citep">(Zhang et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#bib.bib35" title="">2022</a>)</cite> defines three key types of medical causal reasoning relationships: <span class="ltx_text ltx_font_bold" id="A1.p1.1.1">causation</span>, <span class="ltx_text ltx_font_bold" id="A1.p1.1.2">conditionality</span>, and <span class="ltx_text ltx_font_bold" id="A1.p1.1.3">hierarchical relationships</span>, consisting of 9,153 segments of medical text and 79,244 pairs of entity relationships. Our work primarily discusses relationships related to causality, hence, we have discarded hierarchical relationships. Medical concept fragments in the dataset refer to continuous character segments that can act as independent semantic units. These segments may represent medical entities, clinical findings, or specific disease symptoms. From the perspective of expressing causal predicates, these fragments fulfill semantic roles of conditions, causes, or consequences.</p>
</div>
<div class="ltx_para" id="A1.p2">
<p class="ltx_p" id="A1.p2.1">We translated part of the content from the Chinese dataset into English as an example. For instance, <span class="ltx_text ltx_font_italic" id="A1.p2.1.1">"Gastrointestinal dysfunction in the human body leads to a decrease in the patient’s absorption capacity."</span> In this case, <span class="ltx_text ltx_font_italic" id="A1.p2.1.2">"gastrointestinal dysfunction"</span> is a medical concept fragment. <span class="ltx_text ltx_font_italic" id="A1.p2.1.3">"gastrointestinal dysfunction"</span> is a direct cause of <span class="ltx_text ltx_font_italic" id="A1.p2.1.4">"decreased absorption capacity"</span>, and <span class="ltx_text ltx_font_italic" id="A1.p2.1.5">"decreased absorption capacity"</span> is a direct result of <span class="ltx_text ltx_font_italic" id="A1.p2.1.6">"gastrointestinal dysfunction"</span>. We can label this data as &lt;<span class="ltx_text ltx_font_italic" id="A1.p2.1.7">"gastrointestinal dysfunction"</span>, <span class="ltx_text ltx_font_italic" id="A1.p2.1.8">"decreased absorption capacity"</span>, <span class="ltx_text ltx_font_italic" id="A1.p2.1.9">"causation"</span>&gt;. Here, <span class="ltx_text ltx_font_italic" id="A1.p2.1.10">"gastrointestinal dysfunction"</span> serves as the subject (<span class="ltx_text ltx_font_bold" id="A1.p2.1.11">Head</span>) of the relationship, <span class="ltx_text ltx_font_italic" id="A1.p2.1.12">"decreased absorption capacity"</span> as the object (<span class="ltx_text ltx_font_bold" id="A1.p2.1.13">Tail</span>), and <span class="ltx_text ltx_font_italic" id="A1.p2.1.14">"causation"</span> as the specific type of relation (<span class="ltx_text ltx_font_bold" id="A1.p2.1.15">Relation</span>).</p>
</div>
<div class="ltx_para" id="A1.p3">
<p class="ltx_p" id="A1.p3.1">In the dataset, all data can be annotated in the triplet form of &lt;Head, Tail, Relation&gt;. We have conducted statistical analysis on the average length of data and the number of triplets corresponding to each relation in the dataset. The specific statistical results can be found in Table <a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#A1.T3" title="Table 3 ‣ Appendix A Datasets Details And Statistics ‣ Probing Causality Manipulation of Large Language Models"><span class="ltx_text ltx_ref_tag">3</span></a>.</p>
</div>
<div class="ltx_para" id="A1.p4">
<p class="ltx_p" id="A1.p4.1">Moreover, CMedCausal is in Chinese, and Chinese phrases contain fewer variations.
So that it is feasible to modify original dataset with text substitution, and preserve sentences fluency.</p>
</div>
<figure class="ltx_table" id="A1.T3">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="A1.T3.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A1.T3.1.1.1">
<td class="ltx_td ltx_align_left ltx_border_rr ltx_border_t" id="A1.T3.1.1.1.1">Items</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T3.1.1.1.2">Sum</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T3.1.1.1.3">Avg</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T3.1.1.1.4">Max</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T3.1.1.1.5">Min</td>
</tr>
<tr class="ltx_tr" id="A1.T3.1.2.2">
<td class="ltx_td ltx_align_left ltx_border_rr ltx_border_t" id="A1.T3.1.2.2.1">Passages</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T3.1.2.2.2">999</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T3.1.2.2.3">-</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T3.1.2.2.4">-</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T3.1.2.2.5">-</td>
</tr>
<tr class="ltx_tr" id="A1.T3.1.3.3">
<td class="ltx_td ltx_align_left ltx_border_rr" id="A1.T3.1.3.3.1">Length of each passage</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T3.1.3.3.2">-</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T3.1.3.3.3">267</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T3.1.3.3.4">544</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T3.1.3.3.5">29</td>
</tr>
<tr class="ltx_tr" id="A1.T3.1.4.4">
<td class="ltx_td ltx_align_left ltx_border_rr" id="A1.T3.1.4.4.1">Relations per instance</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T3.1.4.4.2">8804</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T3.1.4.4.3">8</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T3.1.4.4.4">44</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T3.1.4.4.5">0</td>
</tr>
<tr class="ltx_tr" id="A1.T3.1.5.5">
<td class="ltx_td ltx_align_left ltx_border_rr" id="A1.T3.1.5.5.1">Passages containing no relation</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T3.1.5.5.2">35</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T3.1.5.5.3">-</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T3.1.5.5.4">-</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T3.1.5.5.5">-</td>
</tr>
<tr class="ltx_tr" id="A1.T3.1.6.6">
<td class="ltx_td ltx_align_left ltx_border_rr" id="A1.T3.1.6.6.1">Causation</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T3.1.6.6.2">7056</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T3.1.6.6.3">-</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T3.1.6.6.4">-</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T3.1.6.6.5">-</td>
</tr>
<tr class="ltx_tr" id="A1.T3.1.7.7">
<td class="ltx_td ltx_align_left ltx_border_rr" id="A1.T3.1.7.7.1">Conditionality</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T3.1.7.7.2">659</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T3.1.7.7.3">-</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T3.1.7.7.4">-</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T3.1.7.7.5">-</td>
</tr>
<tr class="ltx_tr" id="A1.T3.1.8.8">
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_rr" id="A1.T3.1.8.8.1">Hierarchical Relationships</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r" id="A1.T3.1.8.8.2">1089</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r" id="A1.T3.1.8.8.3">-</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r" id="A1.T3.1.8.8.4">-</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r" id="A1.T3.1.8.8.5">-</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>The statistical results of the dataset include the sentence length, the number of relations contained in each sentence, and the specific quantity of each relation.</figcaption>
</figure>
</section>
<section class="ltx_appendix" id="A2">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>Back Translation Implementation</h2>
<div class="ltx_para" id="A2.p1">
<p class="ltx_p" id="A2.p1.1">Layer 2 provides essential knowledge for classification but may simplify the task, as models may compare two sentences straightforward to judge.
This sublayer transforms representations of knowledge in Layer 2, preserving its inherent meaning.
We exploit <span class="ltx_text ltx_font_italic" id="A2.p1.1.1">back-translation</span> <cite class="ltx_cite ltx_citemacro_citep">(Tan et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#bib.bib30" title="">2019</a>)</cite>, additionally necessitating the capability to identify mentions, as original dataset is in Chinese.
Because causal mentions in medical typically follow standard terminologies, receiving fewer modifications during back-translation compared to non-causal contexts.
In practice, we utilize the DeepL API <span class="ltx_note ltx_role_footnote" id="footnote7"><sup class="ltx_note_mark">7</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">7</sup><span class="ltx_tag ltx_tag_note">7</span><a class="ltx_ref ltx_href" href="https://www.deepl.com/translator" title="">https://www.deepl.com/translator</a></span></span></span> to translate texts retrieved from Langchain (consistent with Layer 2) into English and then directly translate them back.</p>
</div>
</section>
<section class="ltx_appendix" id="A3">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix C </span>Discussion of External Knowledge in Layer 3</h2>
<figure class="ltx_table" id="A3.T4">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="A3.T4.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A3.T4.1.1.1">
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t" id="A3.T4.1.1.1.1">
<span class="ltx_inline-block ltx_align_top" id="A3.T4.1.1.1.1.1">
<span class="ltx_p" id="A3.T4.1.1.1.1.1.1" style="width:173.4pt;"><span class="ltx_text ltx_font_bold" id="A3.T4.1.1.1.1.1.1.1">Sentence</span></span>
</span>
</th>
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_r ltx_border_t" id="A3.T4.1.1.1.2">
<span class="ltx_inline-block ltx_align_top" id="A3.T4.1.1.1.2.1">
<span class="ltx_p" id="A3.T4.1.1.1.2.1.1" style="width:216.8pt;"><span class="ltx_text ltx_font_bold" id="A3.T4.1.1.1.2.1.1.1">Knowledge</span></span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A3.T4.1.2.1">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" id="A3.T4.1.2.1.1">
<span class="ltx_inline-block ltx_align_top" id="A3.T4.1.2.1.1.1">
<span class="ltx_p" id="A3.T4.1.2.1.1.1.1" style="width:173.4pt;"><span class="ltx_ERROR undefined" id="A3.T4.1.2.1.1.1.1.1">{CJK*}</span>UTF8gbsn全身症状表现为精神不振、食欲减退、烦躁不安、轻度腹泻或呕吐</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A3.T4.1.2.1.2">
<span class="ltx_inline-block ltx_align_top" id="A3.T4.1.2.1.2.1">
<span class="ltx_p" id="A3.T4.1.2.1.2.1.1" style="width:216.8pt;"><span class="ltx_ERROR undefined" id="A3.T4.1.2.1.2.1.1.1">{CJK*}</span>UTF8gbsn小儿时期常见的呕吐是婴幼儿和儿童时期常见的临床症状之一，几乎任何感染或情绪紧张都可引起呕吐</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A3.T4.1.3.2">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r" id="A3.T4.1.3.2.1">
<span class="ltx_inline-block ltx_align_top" id="A3.T4.1.3.2.1.1">
<span class="ltx_p" id="A3.T4.1.3.2.1.1.1" style="width:173.4pt;"><span class="ltx_text ltx_font_italic" id="A3.T4.1.3.2.1.1.1.1">General symptoms manifest as malaise, decreased appetite, irritability, mild diarrhea, or vomiting.</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="A3.T4.1.3.2.2">
<span class="ltx_inline-block ltx_align_top" id="A3.T4.1.3.2.2.1">
<span class="ltx_p" id="A3.T4.1.3.2.2.1.1" style="width:216.8pt;"><span class="ltx_text ltx_font_italic" id="A3.T4.1.3.2.2.1.1.1">Vomiting during childhood is a common clinical symptom in infants and children, and can be caused by nearly any infection or emotional stress.</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A3.T4.1.4.3">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" id="A3.T4.1.4.3.1">
<span class="ltx_inline-block ltx_align_top" id="A3.T4.1.4.3.1.1">
<span class="ltx_p" id="A3.T4.1.4.3.1.1.1" style="width:173.4pt;"><span class="ltx_ERROR undefined" id="A3.T4.1.4.3.1.1.1.1">{CJK*}</span>UTF8gbsn一旦玻璃体当中水分越来越多,就会造成玻璃体和视网膜发生分离,这就是玻璃体后脱离</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A3.T4.1.4.3.2">
<span class="ltx_inline-block ltx_align_top" id="A3.T4.1.4.3.2.1">
<span class="ltx_p" id="A3.T4.1.4.3.2.1.1" style="width:216.8pt;"><span class="ltx_ERROR undefined" id="A3.T4.1.4.3.2.1.1.1">{CJK*}</span>UTF8gbsn近视尤其高度近视患者，玻璃体发生液化，纤维化以至后脱离</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A3.T4.1.5.4">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r" id="A3.T4.1.5.4.1">
<span class="ltx_inline-block ltx_align_top" id="A3.T4.1.5.4.1.1">
<span class="ltx_p" id="A3.T4.1.5.4.1.1.1" style="width:173.4pt;"><span class="ltx_text ltx_font_italic" id="A3.T4.1.5.4.1.1.1.1">Once the vitreous body accumulates more water, it can lead to a separation between the vitreous body and the retina, known as posterior vitreous detachment.</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="A3.T4.1.5.4.2">
<span class="ltx_inline-block ltx_align_top" id="A3.T4.1.5.4.2.1">
<span class="ltx_p" id="A3.T4.1.5.4.2.1.1" style="width:216.8pt;"><span class="ltx_text ltx_font_italic" id="A3.T4.1.5.4.2.1.1.1">In patients with myopia, especially high myopia, the vitreous body can undergo liquefaction and fibrosis, leading to detachment.</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A3.T4.1.6.5">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" id="A3.T4.1.6.5.1">
<span class="ltx_inline-block ltx_align_top" id="A3.T4.1.6.5.1.1">
<span class="ltx_p" id="A3.T4.1.6.5.1.1.1" style="width:173.4pt;"><span class="ltx_ERROR undefined" id="A3.T4.1.6.5.1.1.1.1">{CJK*}</span>UTF8gbsn过度的饮酒,会导致颈部的血管收缩加快,出现其他的一些不必要的并发症</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A3.T4.1.6.5.2">
<span class="ltx_inline-block ltx_align_top" id="A3.T4.1.6.5.2.1">
<span class="ltx_p" id="A3.T4.1.6.5.2.1.1" style="width:216.8pt;"><span class="ltx_ERROR undefined" id="A3.T4.1.6.5.2.1.1.1">{CJK*}</span>UTF8gbsn长期酗酒每天达100g容易导致向颈段脊髓供血的根动脉缺血</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A3.T4.1.7.6">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_l ltx_border_r" id="A3.T4.1.7.6.1">
<span class="ltx_inline-block ltx_align_top" id="A3.T4.1.7.6.1.1">
<span class="ltx_p" id="A3.T4.1.7.6.1.1.1" style="width:173.4pt;"><span class="ltx_text ltx_font_italic" id="A3.T4.1.7.6.1.1.1.1">Excessive drinking can lead to accelerated constriction of the blood vessels in the neck, resulting in other unnecessary complications.</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r" id="A3.T4.1.7.6.2">
<span class="ltx_inline-block ltx_align_top" id="A3.T4.1.7.6.2.1">
<span class="ltx_p" id="A3.T4.1.7.6.2.1.1" style="width:216.8pt;"><span class="ltx_text ltx_font_italic" id="A3.T4.1.7.6.2.1.1.1">Long-term heavy drinking, reaching 100g per day, can easily cause ischemia in the radicular arteries that supply blood to the cervical spine.</span></span>
</span>
</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 4: </span>Examples of Sentences and Corresponding Knowledge</figcaption>
</figure>
<div class="ltx_para" id="A3.p1">
<p class="ltx_p" id="A3.p1.1">Table <a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#A3.T4" title="Table 4 ‣ Appendix C Discussion of External Knowledge in Layer 3 ‣ Probing Causality Manipulation of Large Language Models"><span class="ltx_text ltx_ref_tag">4</span></a> provides examples of the corresponding knowledge provided to the model in Layer 3 when answering questions. To ensure the reliability of the knowledge provided in Layer 3, we randomly selected 50 samples to check whether the additional medical knowledge provided is related to the content of the question or the entities mentioned in the question. In the 50 samples examined, 43 of them had medical entities in the knowledge section that were related to the question statement, while the rest were unrelated. There were 31 samples that provided clear descriptive help for the causal relationship judgment of the question statement, whereas 19 did not offer significant useful information.</p>
</div>
</section>
<section class="ltx_appendix" id="A4">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix D </span>Retrieval Augmentation Design</h2>
<figure class="ltx_figure" id="A4.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="358" id="A4.F4.1.g1" src="x4.png" width="664"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Flowchart of secondary retrieval using langchain, where "encoding" means encoding the input text using the Sentence Transformer, "Calculate Similarity" means calculate the similarity score using the cosine similarity, "Search Description" Indicates the description of the corresponding medical text in the knowledge graph, "Spliting and Encoding" means that the description text is chunked and encoded and "Decoding" means decoding the encoded vector into a sentence.</figcaption>
</figure>
<div class="ltx_para" id="A4.p1">
<p class="ltx_p" id="A4.p1.1">To engage retrieval pipeline, we divide each sentence into chunks, allowing for overlap between them, and then encode each chunk using Sentence Transformer <cite class="ltx_cite ltx_citemacro_citep">(Reimers and Gurevych, <a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#bib.bib27" title="">2019</a>)</cite>.
We treat input of LLMs as a query and utilize FAISS (Facebook AI Similarity Search) <cite class="ltx_cite ltx_citemacro_citep">(Johnson et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#bib.bib17" title="">2021</a>)</cite> to efficiently match the encoded query with locally stored sentence vectors, retrieving the top <math alttext="k" class="ltx_Math" display="inline" id="A4.p1.1.m1.1"><semantics id="A4.p1.1.m1.1a"><mi id="A4.p1.1.m1.1.1" xref="A4.p1.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="A4.p1.1.m1.1b"><ci id="A4.p1.1.m1.1.1.cmml" xref="A4.p1.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.p1.1.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="A4.p1.1.m1.1d">italic_k</annotation></semantics></math> (set to 2 practically) most relevant chunks.
Since the retrieved sentence fragments may be incomplete, directly providing this knowledge to models would result in receiving inadequate information or incoherent statements.
To address this issue, we control locations of retrieved text fragments in the original text and individually expand the head and tail of the fragment until it forms a complete sentence.
Specifically, due to the large volume of textual data in the medical knowledge graph at Layer 3, directly using Langchain for item-by-item matching is highly inefficient. Therefore, we have adopted a hierarchical retrieval strategy. As shown in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#A4.F4" title="Figure 4 ‣ Appendix D Retrieval Augmentation Design ‣ Probing Causality Manipulation of Large Language Models"><span class="ltx_text ltx_ref_tag">4</span></a>, we first match the input text with disease names in the knowledge graph to select the most relevant diseases. Then, we match the input text with the textual descriptions corresponding to the selected diseases to identify the medical knowledge most relevant to the input text. This selected medical knowledge is ultimately integrated into the external medical knowledge required at Layer 3.</p>
</div>
</section>
<section class="ltx_appendix" id="A5">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix E </span>Prompts</h2>
<section class="ltx_subsection" id="A5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">E.1 </span>Structure of Prompts</h3>
<figure class="ltx_table" id="A5.T5">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="A5.T5.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A5.T5.1.1.1">
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t" id="A5.T5.1.1.1.1">
<span class="ltx_inline-block ltx_align_top" id="A5.T5.1.1.1.1.1">
<span class="ltx_p" id="A5.T5.1.1.1.1.1.1" style="width:65.0pt;">Type</span>
</span>
</th>
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_r ltx_border_t" id="A5.T5.1.1.1.2">
<span class="ltx_inline-block ltx_align_top" id="A5.T5.1.1.1.2.1">
<span class="ltx_p" id="A5.T5.1.1.1.2.1.1" style="width:143.1pt;">Chinese</span>
</span>
</th>
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_r ltx_border_t" id="A5.T5.1.1.1.3">
<span class="ltx_inline-block ltx_align_top" id="A5.T5.1.1.1.3.1">
<span class="ltx_p" id="A5.T5.1.1.1.3.1.1" style="width:143.1pt;">English</span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A5.T5.1.2.1">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" id="A5.T5.1.2.1.1">
<span class="ltx_inline-block ltx_align_top" id="A5.T5.1.2.1.1.1">
<span class="ltx_p" id="A5.T5.1.2.1.1.1.1" style="width:65.0pt;">Text</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A5.T5.1.2.1.2">
<span class="ltx_inline-block ltx_align_top" id="A5.T5.1.2.1.2.1">
<span class="ltx_p" id="A5.T5.1.2.1.2.1.1" style="width:143.1pt;"><span class="ltx_ERROR undefined" id="A5.T5.1.2.1.2.1.1.1">{CJK*}</span>UTF8gbsn全身症状表现为精神不振、食欲减退、烦躁不安、轻度腹泻或呕吐,全身症状在小宝宝身上可能相对来说比较突出。</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A5.T5.1.2.1.3">
<span class="ltx_inline-block ltx_align_top" id="A5.T5.1.2.1.3.1">
<span class="ltx_p" id="A5.T5.1.2.1.3.1.1" style="width:143.1pt;"><span class="ltx_text ltx_font_bold" id="A5.T5.1.2.1.3.1.1.1">General symptoms include lethargy, decreased appetite, irritability, mild diarrhea, or vomiting. These symptoms may be relatively prominent in babies.</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A5.T5.1.3.2">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" id="A5.T5.1.3.2.1">
<span class="ltx_inline-block ltx_align_top" id="A5.T5.1.3.2.1.1">
<span class="ltx_p" id="A5.T5.1.3.2.1.1.1" style="width:65.0pt;">Retrieved Knowledge</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A5.T5.1.3.2.2">
<span class="ltx_inline-block ltx_align_top" id="A5.T5.1.3.2.2.1">
<span class="ltx_p" id="A5.T5.1.3.2.2.1.1" style="width:143.1pt;"><span class="ltx_ERROR undefined" id="A5.T5.1.3.2.2.1.1.1">{CJK*}</span>UTF8gbsn小儿时期常见的呕吐是婴幼儿和儿童时期常见的临床症状之一，几乎任何感染或情绪紧张都可引起呕吐。</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A5.T5.1.3.2.3">
<span class="ltx_inline-block ltx_align_top" id="A5.T5.1.3.2.3.1">
<span class="ltx_p" id="A5.T5.1.3.2.3.1.1" style="width:143.1pt;"><span class="ltx_text ltx_font_italic" id="A5.T5.1.3.2.3.1.1.1">Vomiting in childhood is a common clinical symptom in infants and children, which can be caused by almost any infection or emotional stress.</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A5.T5.1.4.3">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_l ltx_border_r ltx_border_t" id="A5.T5.1.4.3.1">
<span class="ltx_inline-block ltx_align_top" id="A5.T5.1.4.3.1.1">
<span class="ltx_p" id="A5.T5.1.4.3.1.1.1" style="width:65.0pt;">Simple Prompt</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r ltx_border_t" id="A5.T5.1.4.3.2">
<span class="ltx_inline-block ltx_align_top" id="A5.T5.1.4.3.2.1">
<span class="ltx_p" id="A5.T5.1.4.3.2.1.1" style="width:143.1pt;"><span class="ltx_ERROR undefined" id="A5.T5.1.4.3.2.1.1.1">{CJK*}</span>UTF8gbsn额外医疗为：小儿时期常见的呕吐是婴幼儿和儿童时期常见的临床症状之一，几乎任何感染或情绪紧张都可引起呕吐。根据以上辅助知识和你已知的知识，回答：语句"全身症状表现为精神不振、食欲减退、烦躁不安、轻度腹泻或呕吐,全身症状在小宝宝身上可能相对来说比较突出"因果逻辑正确还是错误。</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r ltx_border_t" id="A5.T5.1.4.3.3">
<span class="ltx_inline-block ltx_align_top" id="A5.T5.1.4.3.3.1">
<span class="ltx_p" id="A5.T5.1.4.3.3.1.1" style="width:143.1pt;">Additional medical knowledge: <span class="ltx_text ltx_font_italic" id="A5.T5.1.4.3.3.1.1.1">Vomiting in childhood is a common clinical symptom in infants and children, which can be caused by almost any infection or emotional stress.</span> Given the above knowledge and what you know, answer: Is the statement "<span class="ltx_text ltx_font_bold" id="A5.T5.1.4.3.3.1.1.2">General symptoms include lethargy, decreased appetite, irritability, mild diarrhea, or vomiting, and these symptoms may be relatively prominent in babies</span>" logically correct or incorrect?</span>
</span>
</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 5: </span>Example of simple prompt</figcaption>
</figure>
<figure class="ltx_table" id="A5.SS1.tab1">
<div class="ltx_flex_figure ltx_flex_table">
<div class="ltx_flex_cell ltx_flex_size_2">
<table class="ltx_tabular ltx_figure_panel ltx_guessed_headers ltx_align_middle" id="A5.SS1.tab1.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A5.SS1.tab1.1.1.1">
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="A5.SS1.tab1.1.1.1.1">
<span class="ltx_inline-block ltx_align_top" id="A5.SS1.tab1.1.1.1.1.1">
<span class="ltx_p" id="A5.SS1.tab1.1.1.1.1.1.1" style="width:65.0pt;">Type</span>
</span>
</th>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A5.SS1.tab1.1.1.1.2">
<span class="ltx_inline-block ltx_align_top" id="A5.SS1.tab1.1.1.1.2.1">
<span class="ltx_p" id="A5.SS1.tab1.1.1.1.2.1.1" style="width:143.1pt;">Chinese</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A5.SS1.tab1.1.1.1.3">
<span class="ltx_inline-block ltx_align_top" id="A5.SS1.tab1.1.1.1.3.1">
<span class="ltx_p" id="A5.SS1.tab1.1.1.1.3.1.1" style="width:143.1pt;">English</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A5.SS1.tab1.1.2.2">
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="A5.SS1.tab1.1.2.2.1">
<span class="ltx_inline-block ltx_align_top" id="A5.SS1.tab1.1.2.2.1.1">
<span class="ltx_p" id="A5.SS1.tab1.1.2.2.1.1.1" style="width:65.0pt;">Text</span>
</span>
</th>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A5.SS1.tab1.1.2.2.2">
<span class="ltx_inline-block ltx_align_top" id="A5.SS1.tab1.1.2.2.2.1">
<span class="ltx_p" id="A5.SS1.tab1.1.2.2.2.1.1" style="width:143.1pt;"><span class="ltx_ERROR undefined" id="A5.SS1.tab1.1.2.2.2.1.1.1">{CJK*}</span>UTF8gbsn全身症状表现为精神不振、食欲减退、烦躁不安、轻度腹泻或呕吐,全身症状在小宝宝身上可能相对来说比较突出。</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A5.SS1.tab1.1.2.2.3">
<span class="ltx_inline-block ltx_align_top" id="A5.SS1.tab1.1.2.2.3.1">
<span class="ltx_p" id="A5.SS1.tab1.1.2.2.3.1.1" style="width:143.1pt;"><span class="ltx_text ltx_font_bold" id="A5.SS1.tab1.1.2.2.3.1.1.1">General symptoms include lethargy, decreased appetite, irritability, mild diarrhea, or vomiting. These symptoms may be relatively prominent in babies.</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A5.SS1.tab1.1.3.3">
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="A5.SS1.tab1.1.3.3.1">
<span class="ltx_inline-block ltx_align_top" id="A5.SS1.tab1.1.3.3.1.1">
<span class="ltx_p" id="A5.SS1.tab1.1.3.3.1.1.1" style="width:65.0pt;">Retrieved Knowledge</span>
</span>
</th>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A5.SS1.tab1.1.3.3.2">
<span class="ltx_inline-block ltx_align_top" id="A5.SS1.tab1.1.3.3.2.1">
<span class="ltx_p" id="A5.SS1.tab1.1.3.3.2.1.1" style="width:143.1pt;"><span class="ltx_ERROR undefined" id="A5.SS1.tab1.1.3.3.2.1.1.1">{CJK*}</span>UTF8gbsn小儿时期常见的呕吐是婴幼儿和儿童时期常见的临床症状之一，几乎任何感染或情绪紧张都可引起呕吐。</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A5.SS1.tab1.1.3.3.3">
<span class="ltx_inline-block ltx_align_top" id="A5.SS1.tab1.1.3.3.3.1">
<span class="ltx_p" id="A5.SS1.tab1.1.3.3.3.1.1" style="width:143.1pt;"><span class="ltx_text ltx_font_italic" id="A5.SS1.tab1.1.3.3.3.1.1.1">Vomiting in childhood is a common clinical symptom in infants and children, which can be caused by almost any infection or emotional stress.</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A5.SS1.tab1.1.4.4">
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r ltx_border_t" id="A5.SS1.tab1.1.4.4.1">
<span class="ltx_inline-block ltx_align_top" id="A5.SS1.tab1.1.4.4.1.1">
<span class="ltx_p" id="A5.SS1.tab1.1.4.4.1.1.1" style="width:65.0pt;">Advanced Prompt</span>
</span>
</th>
<td class="ltx_td ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_b ltx_border_t" id="A5.SS1.tab1.1.4.4.2">
<span class="ltx_inline-block ltx_align_top" id="A5.SS1.tab1.1.4.4.2.1">
<span class="ltx_p" id="A5.SS1.tab1.1.4.4.2.1.1" style="width:143.1pt;">[Round 0] \n <span class="ltx_ERROR undefined" id="A5.SS1.tab1.1.4.4.2.1.1.1">{CJK*}</span>UTF8gbsn问：你现在在进行句子因果逻辑关系分析的任务\n<span class="ltx_ERROR undefined" id="A5.SS1.tab1.1.4.4.2.1.1.2">{CJK*}</span>UTF8gbsn答：好的\n[Round 1]\n <span class="ltx_ERROR undefined" id="A5.SS1.tab1.1.4.4.2.1.1.3">{CJK*}</span>UTF8gbsn问：可能会出现因果倒置，涉及到因果关系的对象对应关系错误等错误。 \n <span class="ltx_ERROR undefined" id="A5.SS1.tab1.1.4.4.2.1.1.4">{CJK*}</span>UTF8gbsn答：好的\n[Round 2]\n<span class="ltx_ERROR undefined" id="A5.SS1.tab1.1.4.4.2.1.1.5">{CJK*}</span>UTF8gbsn问：你现在在进行句子因果逻辑关系分析的任务。\n <span class="ltx_ERROR undefined" id="A5.SS1.tab1.1.4.4.2.1.1.6">{CJK*}</span>UTF8gbsn答：好的\n[Round 3]\n <span class="ltx_ERROR undefined" id="A5.SS1.tab1.1.4.4.2.1.1.7">{CJK*}</span>UTF8gbsn问：这部分是为你提供的额外医疗知识：小儿时期常见的呕吐是婴幼儿和儿童时期常见的临床症状之一，几乎任何感染或情绪紧张都可引起呕吐\n <span class="ltx_ERROR undefined" id="A5.SS1.tab1.1.4.4.2.1.1.8">{CJK*}</span>UTF8gbsn答：好的\nquestion: <span class="ltx_ERROR undefined" id="A5.SS1.tab1.1.4.4.2.1.1.9">{CJK*}</span>UTF8gbsn语句："全身症状表现为精神不振、食欲减退、烦躁不安、轻度腹泻或呕吐,全身症状在小宝宝身上可能相对来说比较突出"这个语句是否逻辑正确？先回答是或者否，再给出对应的理由。</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r ltx_border_t" id="A5.SS1.tab1.1.4.4.3">
<span class="ltx_inline-block ltx_align_top" id="A5.SS1.tab1.1.4.4.3.1">
<span class="ltx_p" id="A5.SS1.tab1.1.4.4.3.1.1" style="width:143.1pt;">[Round 0]\n Q: You are now performing a task of analyzing the causal logical relationship of sentences.\n A: Okay.\n[Round 1]\n Q: There may be errors such as reversal of cause and effect, involving incorrect object correspondence of causal relationships.\n A: Okay.\n [Round 2]\n Q: You are now performing a task of analyzing the causal logical relationship of sentences.\n A: Okay.\n [Round 3]\n Q: This part is to provide you with additional medical knowledge: <span class="ltx_text ltx_font_italic" id="A5.SS1.tab1.1.4.4.3.1.1.1">Vomiting in childhood is a common clinical symptom in infants and children, which can be caused by almost any infection or emotional stress.</span>\n A: Okay.\n Question: Is the statement "<span class="ltx_text ltx_font_bold" id="A5.SS1.tab1.1.4.4.3.1.1.2">General symptoms include lethargy, decreased appetite, irritability, mild diarrhea, or vomiting, and these symptoms may be relatively prominent in babies</span>" logically correct? Answer yes or no, then provide the corresponding reason.</span>
</span>
</td>
</tr>
</tbody>
</table>
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 6: </span>Example of advanced prompt</figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<p class="ltx_p ltx_figure_panel" id="A5.SS1.tab1.2">Prompts for probing were designed according to <span class="ltx_text ltx_font_italic" id="A5.SS1.tab1.2.1">Base Prompt Framework</span> by Elvis Saravia<span class="ltx_note ltx_role_footnote" id="footnote8"><sup class="ltx_note_mark">8</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">8</sup><span class="ltx_tag ltx_tag_note">8</span><a class="ltx_ref ltx_href" href="https://www.promptingguide.ai/" title="">https://www.promptingguide.ai/</a></span></span></span>.
All prompts have the following elements: <span class="ltx_text ltx_font_bold" id="A5.SS1.tab1.2.2">Instructions</span>, we instruct LLMs with a binary classification tasks.
<span class="ltx_text ltx_font_bold" id="A5.SS1.tab1.2.3">Contexts</span>, we place supplementary knowledge and contexts in this section for problems contexts. In the layer of bare asking, this part is excluded.
<span class="ltx_text ltx_font_bold" id="A5.SS1.tab1.2.4">Input Data</span>, we place sentence to be classified in this slot, separated with Chinese quotation mark.
<span class="ltx_text ltx_font_bold" id="A5.SS1.tab1.2.5">Output Indicator</span>, we instruct models about output format and order, the best indicator is to make classification first and then explain why.
Extensive search for other prompts is neglected, since we consider understanding of reasonable prompts to be part of models capabilities.</p>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<section class="ltx_subsection ltx_figure_panel" id="A5.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">E.2 </span>Examples of Prompts</h3>
<div class="ltx_para" id="A5.SS2.p1">
<p class="ltx_p" id="A5.SS2.p1.1">When using a simple prompt, we directly connect the additional knowledge with the question content in a straightforward manner, as illustrated by the example in Table <a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#A5.T5" title="Table 5 ‣ E.1 Structure of Prompts ‣ Appendix E Prompts ‣ Probing Causality Manipulation of Large Language Models"><span class="ltx_text ltx_ref_tag">5</span></a>. In contrast, when using an advanced prompt, we employ multi-turn dialogues to emphasize the task content and separate the parts that provide knowledge from those that pose questions. This approach allows the model to understand the task content, and the boundaries between knowledge and questions more clearly. Examples of this can be found in Table <a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#A5.SS1" title="E.1 Structure of Prompts ‣ Appendix E Prompts ‣ Probing Causality Manipulation of Large Language Models"><span class="ltx_text ltx_ref_tag">E.1</span></a>.</p>
</div>
<section class="ltx_appendix" id="A6">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix F </span>Details of Models</h2>
<section class="ltx_paragraph" id="A6.SS0.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">GPT-4</h4>
<div class="ltx_para" id="A6.SS0.SSS0.Px1.p1">
<p class="ltx_p" id="A6.SS0.SSS0.Px1.p1.1"><cite class="ltx_cite ltx_citemacro_citep">(OpenAI, <a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#bib.bib23" title="">2023</a>)</cite>.
We use a static version of <span class="ltx_text ltx_font_italic" id="A6.SS0.SSS0.Px1.p1.1.1">GPT-4-0613</span> <span class="ltx_note ltx_role_footnote" id="footnote9"><sup class="ltx_note_mark">9</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">9</sup><span class="ltx_tag ltx_tag_note">9</span><a class="ltx_ref ltx_href" href="https://platform.openai.com/docs/models/gpt-4" title="">https://platform.openai.com/docs/models/gpt-4</a></span></span></span> for experiment.</p>
</div>
</section>
<section class="ltx_paragraph" id="A6.SS0.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">GPT-3.5</h4>
<div class="ltx_para" id="A6.SS0.SSS0.Px2.p1">
<p class="ltx_p" id="A6.SS0.SSS0.Px2.p1.1"><cite class="ltx_cite ltx_citemacro_citep">(Ouyang et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#bib.bib24" title="">2022</a>)</cite>. We use <span class="ltx_text ltx_font_italic" id="A6.SS0.SSS0.Px2.p1.1.1">GPT-3.5-Turbo<span class="ltx_note ltx_role_footnote" id="footnote10"><sup class="ltx_note_mark">10</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">10</sup><span class="ltx_tag ltx_tag_note"><span class="ltx_text ltx_font_upright" id="footnote10.1.1.1">10</span></span><a class="ltx_ref ltx_href ltx_font_upright" href="https://platform.openai.com/docs/models/gpt-3-5" title="">https://platform.openai.com/docs/models/gpt-3-5</a></span></span></span></span> static version of ChatGPT.</p>
</div>
</section>
<section class="ltx_paragraph" id="A6.SS0.SSS0.Px3">
<h4 class="ltx_title ltx_title_paragraph">ChatGLM</h4>
<div class="ltx_para" id="A6.SS0.SSS0.Px3.p1">
<p class="ltx_p" id="A6.SS0.SSS0.Px3.p1.1"><cite class="ltx_cite ltx_citemacro_citep">(Zeng et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#bib.bib34" title="">2023</a>; Du et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#bib.bib9" title="">2022b</a>)</cite>. It is pretrained mainly on Chinese and English corpus, and can recognize Chinese expressions better.</p>
</div>
</section>
<section class="ltx_paragraph" id="A6.SS0.SSS0.Px4">
<h4 class="ltx_title ltx_title_paragraph">MedChatGLM</h4>
<div class="ltx_para" id="A6.SS0.SSS0.Px4.p1">
<p class="ltx_p" id="A6.SS0.SSS0.Px4.p1.1">is a model under fine-tuning on ChatGLM in Chinese medical corpus.</p>
</div>
</section>
<section class="ltx_paragraph" id="A6.SS0.SSS0.Px5">
<h4 class="ltx_title ltx_title_paragraph">BERT</h4>
<div class="ltx_para" id="A6.SS0.SSS0.Px5.p1">
<p class="ltx_p" id="A6.SS0.SSS0.Px5.p1.1"><cite class="ltx_cite ltx_citemacro_citep">(Devlin et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#bib.bib7" title="">2019</a>)</cite> <span class="ltx_note ltx_role_footnote" id="footnote11"><sup class="ltx_note_mark">11</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">11</sup><span class="ltx_tag ltx_tag_note">11</span><a class="ltx_ref ltx_href" href="https://huggingface.co/bert-base-chinese" title="">https://huggingface.co/bert-base-chinese</a></span></span></span> is trained on supervised datasets, classification is extracted using masked language model (MLM), in which BERT is trained to fill certain slot with <span class="ltx_text ltx_font_italic" id="A6.SS0.SSS0.Px5.p1.1.1">right</span> or <span class="ltx_text ltx_font_italic" id="A6.SS0.SSS0.Px5.p1.1.2">wrong</span>.</p>
</div>
</section>
</section>
<section class="ltx_appendix" id="A7">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix G </span>Performance Difference of LLMs</h2>
<div class="ltx_para" id="A7.p1">
<p class="ltx_p" id="A7.p1.1">The performance of action 3 is the worst of the three and has even approached random categorization for some models (ChatGLM <cite class="ltx_cite ltx_citemacro_citep">(Zeng et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#bib.bib34" title="">2023</a>; Du et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#bib.bib9" title="">2022b</a>)</cite> and MedChatGLM).
The assistance of original passage causes a performance drop, regardless prompt used for all models including GPT-4 <cite class="ltx_cite ltx_citemacro_citep">(OpenAI, <a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#bib.bib23" title="">2023</a>)</cite>.
In contrast, the introduction of layer 2 in action 1 improves performance.
This means that model lacks understanding of causation between mentions, relying more on linguistic order and positions. We believe that the ability to judge causal relevance problems is mainly related to the number of model parameters and the training method.</p>
</div>
<section class="ltx_paragraph" id="A7.SS0.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Training Strategies</h4>
<div class="ltx_para" id="A7.SS0.SSS0.Px1.p1">
<p class="ltx_p" id="A7.SS0.SSS0.Px1.p1.1">GPT-4 and GPT-3.5 uses the RLHF <cite class="ltx_cite ltx_citemacro_citep">(Ouyang et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#bib.bib24" title="">2022</a>)</cite> training strategy, which makes its answer results more similar to human beings. This can improve the logic of its dialogue and improve its ability to discuss causal problems to a certain extent.</p>
</div>
</section>
<section class="ltx_paragraph" id="A7.SS0.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">The Number of Model Parameters</h4>
<div class="ltx_para" id="A7.SS0.SSS0.Px2.p1">
<p class="ltx_p" id="A7.SS0.SSS0.Px2.p1.1">Compared with GPT-3.5 and ChatGLM, GPT-4 has a larger number of parameters and a larger knowledge reserve, and it has a stronger ability to understand complex logic.</p>
</div>
</section>
</section>
<section class="ltx_appendix" id="A8">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix H </span>PPL of Positive and Negative Instances</h2>
<div class="ltx_para" id="A8.p1">
<p class="ltx_p" id="A8.p1.1">This section presents the specific experimental results of testing various actions using GPT-2 Chinese<span class="ltx_note ltx_role_footnote" id="footnote12"><sup class="ltx_note_mark">12</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">12</sup><span class="ltx_tag ltx_tag_note">12</span><a class="ltx_ref ltx_href" href="https://huggingface.co/uer/gpt2-chinese-cluecorpussmall" title="">https://huggingface.co/uer/gpt2-chinese-cluecorpussmall</a></span></span></span> <cite class="ltx_cite ltx_citemacro_citep">(Radford et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#bib.bib25" title="">2019</a>)</cite> to determine the confidence of sentences based on PPL.
We test PPL on all actions of datasets, and compare difference of positive and negative instances.
When difference is big, dataset are more easier for classification from statistical association.</p>
</div>
<div class="ltx_para" id="A8.p2">
<p class="ltx_p" id="A8.p2.1">As shown in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2408.14380v1#A8.F5" title="Figure 5 ‣ Appendix H PPL of Positive and Negative Instances ‣ E.2 Examples of Prompts ‣ E.1 Structure of Prompts ‣ Appendix E Prompts ‣ Probing Causality Manipulation of Large Language Models"><span class="ltx_text ltx_ref_tag">5</span></a>.
PPL is correlated with the model’s confidence in a given sentence using statistical associations.
Results show that action 2 is more easily distinguishable statistically, with a higher base PPL and a more pronounced increase in negative instances.</p>
</div>
<figure class="ltx_figure" id="A8.F5"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="168" id="A8.F5.1.g1" src="x5.png" width="224"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>PPL of positive and negative instances in different actions calculated by GPT-2</figcaption>
</figure>
</section>
</section>
</div>
</div>
</figure>
</section>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Mon Aug 26 15:57:28 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
