<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2310.11927] UNav-Sim: A Visually Realistic Underwater Robotics Simulator and Synthetic Data-generation Framework</title><meta property="og:description" content="Underwater robotic surveys can be costly due to the complex working environment and the need for various sensor modalities. While underwater simulators are essential, many existing simulators lack sufficient rendering ‚Ä¶">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="UNav-Sim: A Visually Realistic Underwater Robotics Simulator and Synthetic Data-generation Framework">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="UNav-Sim: A Visually Realistic Underwater Robotics Simulator and Synthetic Data-generation Framework">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2310.11927">

<!--Generated on Tue Feb 27 23:10:02 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<section id="id19" class="ltx_glossary ltx_acronym ltx_list_acronym">
<dl id="id19.19" class="ltx_glossarylist">
<dt id="id1.1.id1" class="ltx_glossaryentry">ROV</dt>
<dd>remotely operated vehicle</dd>
<dt id="id2.2.id2" class="ltx_glossaryentry">AUV</dt>
<dd>autonomous underwater vehicle</dd>
<dt id="id3.3.id3" class="ltx_glossaryentry">UWRS</dt>
<dd>underwater robotics simulator</dd>
<dt id="id4.4.id4" class="ltx_glossaryentry">NMPC</dt>
<dd>nonlinear model predictive control</dd>
<dt id="id5.5.id5" class="ltx_glossaryentry">MPC</dt>
<dd>model predictive control</dd>
<dt id="id6.6.id6" class="ltx_glossaryentry">SLAM</dt>
<dd>simultaneous localisation and mapping</dd>
<dt id="id7.7.id7" class="ltx_glossaryentry">vSLAM</dt>
<dd>visual SLAM</dd>
<dt id="id8.8.id8" class="ltx_glossaryentry">RL</dt>
<dd>reinforcement learning</dd>
<dt id="id9.9.id9" class="ltx_glossaryentry">DRL</dt>
<dd>deep reinforcement learning</dd>
<dt id="id10.10.id10" class="ltx_glossaryentry">UE</dt>
<dd>unreal engine</dd>
<dt id="id11.11.id11" class="ltx_glossaryentry">NED</dt>
<dd>North-East-Down</dd>
<dt id="id12.12.id12" class="ltx_glossaryentry">UE5</dt>
<dd>unreal engine 5</dd>
<dt id="id13.13.id13" class="ltx_glossaryentry">UE4</dt>
<dd>unreal engine 4</dd>
<dt id="id14.14.id14" class="ltx_glossaryentry">ROS</dt>
<dd>robot operating system</dd>
<dt id="id15.15.id15" class="ltx_glossaryentry">AI</dt>
<dd>artificial intelligence</dd>
<dt id="id16.16.id16" class="ltx_glossaryentry">APE</dt>
<dd>absolute positioning error</dd>
<dt id="id17.17.id17" class="ltx_glossaryentry">RPE</dt>
<dd>relative positioning error</dd>
<dt id="id18.18.id18" class="ltx_glossaryentry">PWM</dt>
<dd>pulse width modulation</dd>
<dt id="id19.19.id19" class="ltx_glossaryentry">DFKI</dt>
<dd>Deutsches Forschungszentrum f√ºr K√ºnstliche Intelligenz</dd>
</dl>
</section>
<h1 class="ltx_title ltx_font_bold ltx_title_document" style="font-size:173%;">UNav-Sim: A Visually Realistic Underwater Robotics Simulator and Synthetic Data-generation Framework
</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Abdelhakim Amer, Olaya √Ålvarez-Tu√±√≥n, Halil ƒ∞brahim Uƒüurlu, Jonas le Fevre Sejersen, 
<br class="ltx_break">Yury Brodskiy and
Erdal Kayacan
</span><span class="ltx_author_notes">A. Amer, O. Tunon, H. Uƒüurlu, J. Sejersen are with the Department of Electrical Engineering and Computer Engineering, Aarhus University, 8200 Aarhus, Denmark <span id="id20.1.id1" class="ltx_text ltx_font_typewriter" style="font-size:90%;">{abdelhakim, olaya, halil, jonas} at ece.au.dk</span>.
Y. Brodskiy is with EIVA a/s, 8660 Skanderborg, Denmark. <span id="id21.2.id2" class="ltx_text ltx_font_typewriter" style="font-size:90%;">{ybr} at eiva.com</span>.
E. Kayacan is with the Automatic Control Group, Department of Electrical Engineering and Information Technology, Paderborn University, Paderborn, Germany. <span id="id22.3.id3" class="ltx_text ltx_font_typewriter" style="font-size:90%;">{erdal.kayacan} at uni-paderborn.de</span></span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id23.id1" class="ltx_p">Underwater robotic surveys can be costly due to the complex working environment and the need for various sensor modalities. While underwater simulators are essential, many existing simulators lack sufficient rendering quality, restricting their ability to transfer algorithms from simulation to real-world applications. To address this limitation, we introduce UNav-Sim, which, to the best of our knowledge, is the first simulator to incorporate the efficient, high-detail rendering of Unreal Engine 5 (UE5). UNav-Sim is open-source<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a target="_blank" href="https://github.com/open-airlab/UNav-Sim" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/open-airlab/UNav-Sim</a></span></span></span> and includes an autonomous vision-based navigation stack. By supporting standard robotics tools like ROS, UNav-Sim enables researchers to develop and test algorithms for underwater environments efficiently.</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">I </span><span id="S1.1.1" class="ltx_text ltx_font_smallcaps">Introduction</span>
</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Marine robotics is an expanding field with numerous applications, including exploring underwater ecosystems and inspecting underwater infrastructure <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>. Recent developments in robotics and autonomy have demonstrated the superior capabilities of  <a href="#id15.15.id15"><span href="#id15.15.id15" title="artificial intelligence" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long">artificial intelligence</span></span></a> (<a href="#id15.15.id15"><abbr href="#id15.15.id15" title="artificial intelligence" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">AI</span></abbr></a>) and vision-based algorithms in solving complex tasks, such as drone racing <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>, <a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite> and inspection <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>. These achievements have shown promise in developing <a href="#id15.15.id15"><abbr href="#id15.15.id15" title="artificial intelligence" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">AI</span></abbr></a> and autonomy for marine applications as well <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>. To mitigate the high costs involved in developing and testing such algorithms, photorealistic simulation environments are needed that can accurately model the complexity of underwater scenarios <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>.</p>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/2310.11927/assets/x1.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="257" height="154" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>UNav-Sim is an underwater robotics simulator utilizing Unreal Engine 5 (UE5) highly realistic environments. The simulator includes many features useful for roboticists, such as ROS 2, and a wide range of sensors and cameras. The bottom right displays the feed from a front-facing RGB camera, while the bottom left shows a corresponding depth image.</figcaption>
</figure>
<figure id="S1.F2" class="ltx_figure"><img src="/html/2310.11927/assets/x2.png" id="S1.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="447" height="292" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>UNav-Sim system architecture is designed to be modular, allowing flexibility in adapting the simulator to various underwater autonomy tasks. The system utilizes Unreal Engine 5 (UE5) to provide a high-fidelity rendering environment for increased photo-realism. A model predictive controller (MPC), combined with a deep reinforcement learning (DRL) planner and Visual <a href="#id6.6.id6"><abbr href="#id6.6.id6" title="simultaneous localisation and mapping" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">SLAM</span></abbr></a> are utilized for vision-based underwater navigation. </figcaption>
</figure>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">In this context, this paper presents UNav-Sim, the first open-source underwater simulator based on  <a href="#id12.12.id12"><span href="#id12.12.id12" title="unreal engine 5" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long">unreal engine 5</span></span></a> (<a href="#id12.12.id12"><abbr href="#id12.12.id12" title="unreal engine 5" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">UE5</span></abbr></a>) to create photorealistic environments (see Fig. <a href="#S1.F1" title="Figure 1 ‚Ä£ I Introduction ‚Ä£ UNav-Sim: A Visually Realistic Underwater Robotics Simulator and Synthetic Data-generation Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>). Compared to existing underwater robotics simulators, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a>, <a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>, UNav-Sim provides superior rendering quality, essential for the development of <a href="#id15.15.id15"><abbr href="#id15.15.id15" title="artificial intelligence" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">AI</span></abbr></a> and vision-based navigation algorithms for underwater vehicles. It supports robotics tools such as ROS 2 and autopilot firmwares making it suitable for robotics research and development. The simulator uses the following open-source AirSim <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite> extensions: <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> to add custom vehicle models to AirSim, and <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite> for integration of AirSim to <a href="#id12.12.id12"><abbr href="#id12.12.id12" title="unreal engine 5" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">UE5</span></abbr></a>. UNav-Sim can be used to simulate a wide range of underwater scenarios and models. The paper also demonstrates its effectiveness for the development of vision-based localization and navigation methods for underwater robots.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">The rest of the paper is structured as follows: Section <a href="#S2" title="II State-of-the-art ‚Ä£ UNav-Sim: A Visually Realistic Underwater Robotics Simulator and Synthetic Data-generation Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag">II</span></a> presents an overview of the state-of-the-art simulators and their respective capabilities. Section <a href="#S3" title="III UNav-Sim software architecture ‚Ä£ UNav-Sim: A Visually Realistic Underwater Robotics Simulator and Synthetic Data-generation Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag">III</span></a> describes the software architecture, physics, and models that comprise UNav-Sim. In Section <a href="#S4" title="IV Vision-based underwater navigation stack ‚Ä£ UNav-Sim: A Visually Realistic Underwater Robotics Simulator and Synthetic Data-generation Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag">IV</span></a>, we describe a vision-based underwater navigation stack that was developed as a component of UNav-Sim. Then, we present a test case in Section <a href="#S5" title="V Example use-cases ‚Ä£ UNav-Sim: A Visually Realistic Underwater Robotics Simulator and Synthetic Data-generation Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag">V</span></a>, where we showcase the abilities and features of our simulator in a vision-based pipe inspection scenario. Lastly, conclusions are drawn from this work in Section <a href="#S6" title="VI Conclusion &amp; future work ‚Ä£ UNav-Sim: A Visually Realistic Underwater Robotics Simulator and Synthetic Data-generation Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag">VI</span></a>.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">II </span><span id="S2.1.1" class="ltx_text ltx_font_smallcaps">State-of-the-art</span>
</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">Robotics simulation tools have significantly advanced in recent years, with a focus on providing high-fidelity and photorealistic visual rendering. IsaacSim <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>, developed by Nvidia, is a recent example that includes both high-fidelity contact simulation and high-quality image rendering provided by Omniverse, making it suitable for simulating robotic grippers and walking robots. Another example is Microsoft‚Äôs AirSim <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>, yet another popular robotics simulator, specifically designed for aerial vehicles. AirSim utilizes its Fastphysics engine for physics simulation and  <a href="#id13.13.id13"><span href="#id13.13.id13" title="unreal engine 4" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long">unreal engine 4</span></span></a> (<a href="#id13.13.id13"><abbr href="#id13.13.id13" title="unreal engine 4" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">UE4</span></abbr></a>) for visualization.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p">While progress in robotics simulation tools has been rapid, underwater robotics simulation tools have lagged behind. UWSim <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite> and UUV Simulator <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite> are the two most commonly used underwater simulators <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>; however, they are now discontinued. A more recent simulator, DAVE <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>, was developed as a more modern version of the UUV simulator that supports more  <a href="#id1.1.id1"><span href="#id1.1.id1" title="remotely operated vehicle" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long">remotely operated vehicle</span></span></a> (<a href="#id1.1.id1"><abbr href="#id1.1.id1" title="remotely operated vehicle" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">ROV</span></abbr></a>) models and underwater sensors. However, the aforementioned simulators are based on Gazebo, which has the disadvantage of unrealistic rendering. This limits their usefulness for training and testing <a href="#id15.15.id15"><abbr href="#id15.15.id15" title="artificial intelligence" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">AI</span></abbr></a> algorithms that often rely on image inputs. To address this issue, HoloOcean <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite> was developed using <a href="#id13.13.id13"><abbr href="#id13.13.id13" title="unreal engine 4" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">UE4</span></abbr></a> for rendering and written in Python, but it lacks support for  <a href="#id14.14.id14"><span href="#id14.14.id14" title="robot operating system" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long">robot operating system</span></span></a> (<a href="#id14.14.id14"><abbr href="#id14.14.id14" title="robot operating system" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">ROS</span></abbr></a>) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>. Another example is MARUS <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>, which has not yet released its open-source implementation. The simulator uses Unity3D for visualization and integrates with <a href="#id14.14.id14"><abbr href="#id14.14.id14" title="robot operating system" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">ROS</span></abbr></a>. However, it lacks support for essential robotics and <a href="#id15.15.id15"><abbr href="#id15.15.id15" title="artificial intelligence" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">AI</span></abbr></a> tools, such as commercial autopilots <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>, or OpenAI‚Äôs Gym environments <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>, which are important tools for developing <a href="#id15.15.id15"><abbr href="#id15.15.id15" title="artificial intelligence" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">AI</span></abbr></a> and control algorithms for autonomous vehicles.</p>
</div>
<figure id="S2.T1" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">TABLE I: </span>Marine robotics simulators comparison showing UNav-Sim‚Äôs superior rendering quality and versatility.</figcaption>
<table id="S2.T1.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S2.T1.1.1.1" class="ltx_tr">
<th id="S2.T1.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt">Simulator</th>
<th id="S2.T1.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt">Year</th>
<th id="S2.T1.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Rendering quality</th>
<th id="S2.T1.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">ROS Support</th>
<th id="S2.T1.1.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Autopilot</th>
<th id="S2.T1.1.1.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">OS</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S2.T1.1.2.1" class="ltx_tr">
<th id="S2.T1.1.2.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">UWSim <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>
</th>
<th id="S2.T1.1.2.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">2012</th>
<td id="S2.T1.1.2.1.3" class="ltx_td ltx_align_center ltx_border_t">Low</td>
<td id="S2.T1.1.2.1.4" class="ltx_td ltx_align_center ltx_border_t">ROS 1</td>
<td id="S2.T1.1.2.1.5" class="ltx_td ltx_align_center ltx_border_t">None</td>
<td id="S2.T1.1.2.1.6" class="ltx_td ltx_align_center ltx_border_t">Linux</td>
</tr>
<tr id="S2.T1.1.3.2" class="ltx_tr">
<th id="S2.T1.1.3.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">UUV <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>
</th>
<th id="S2.T1.1.3.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_row">2016</th>
<td id="S2.T1.1.3.2.3" class="ltx_td ltx_align_center">Low</td>
<td id="S2.T1.1.3.2.4" class="ltx_td ltx_align_center">ROS 1</td>
<td id="S2.T1.1.3.2.5" class="ltx_td ltx_align_center">Ardupilot</td>
<td id="S2.T1.1.3.2.6" class="ltx_td ltx_align_center">Linux</td>
</tr>
<tr id="S2.T1.1.4.3" class="ltx_tr">
<th id="S2.T1.1.4.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">URSim <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>
</th>
<th id="S2.T1.1.4.3.2" class="ltx_td ltx_align_center ltx_th ltx_th_row">2019</th>
<td id="S2.T1.1.4.3.3" class="ltx_td ltx_align_center">Moderate</td>
<td id="S2.T1.1.4.3.4" class="ltx_td ltx_align_center">ROS 1</td>
<td id="S2.T1.1.4.3.5" class="ltx_td ltx_align_center">N/A</td>
<td id="S2.T1.1.4.3.6" class="ltx_td ltx_align_center">Linux</td>
</tr>
<tr id="S2.T1.1.5.4" class="ltx_tr">
<th id="S2.T1.1.5.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">HoloOcean <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>
</th>
<th id="S2.T1.1.5.4.2" class="ltx_td ltx_align_center ltx_th ltx_th_row">2022</th>
<td id="S2.T1.1.5.4.3" class="ltx_td ltx_align_center">High</td>
<td id="S2.T1.1.5.4.4" class="ltx_td ltx_align_center">N/A</td>
<td id="S2.T1.1.5.4.5" class="ltx_td ltx_align_center">N/A</td>
<td id="S2.T1.1.5.4.6" class="ltx_td ltx_align_center">Linux/Windows</td>
</tr>
<tr id="S2.T1.1.6.5" class="ltx_tr">
<th id="S2.T1.1.6.5.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">DAVE <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>
</th>
<th id="S2.T1.1.6.5.2" class="ltx_td ltx_align_center ltx_th ltx_th_row">2022</th>
<td id="S2.T1.1.6.5.3" class="ltx_td ltx_align_center">Low</td>
<td id="S2.T1.1.6.5.4" class="ltx_td ltx_align_center">ROS 1</td>
<td id="S2.T1.1.6.5.5" class="ltx_td ltx_align_center">PX4/Ardupilot</td>
<td id="S2.T1.1.6.5.6" class="ltx_td ltx_align_center">Linux</td>
</tr>
<tr id="S2.T1.1.7.6" class="ltx_tr">
<th id="S2.T1.1.7.6.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">MARUS <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>
</th>
<th id="S2.T1.1.7.6.2" class="ltx_td ltx_align_center ltx_th ltx_th_row">2022</th>
<td id="S2.T1.1.7.6.3" class="ltx_td ltx_align_center">Moderate</td>
<td id="S2.T1.1.7.6.4" class="ltx_td ltx_align_center">ROS 1,2</td>
<td id="S2.T1.1.7.6.5" class="ltx_td ltx_align_center">N/A</td>
<td id="S2.T1.1.7.6.6" class="ltx_td ltx_align_center">Linux/Windows</td>
</tr>
<tr id="S2.T1.1.8.7" class="ltx_tr">
<th id="S2.T1.1.8.7.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_t"><span id="S2.T1.1.8.7.1.1" class="ltx_text ltx_font_bold">UNav-Sim (Ours)</span></th>
<th id="S2.T1.1.8.7.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_t">2023</th>
<td id="S2.T1.1.8.7.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">Highest</td>
<td id="S2.T1.1.8.7.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">ROS 1,2</td>
<td id="S2.T1.1.8.7.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">PX4/Ardupilot</td>
<td id="S2.T1.1.8.7.6" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">Linux/Windows</td>
</tr>
</tbody>
</table>
</figure>
<div id="S2.p3" class="ltx_para">
<p id="S2.p3.1" class="ltx_p">A comparison of the capabilities of various open-source underwater robotics simulators, including the proposed simulator, is presented in Table <span class="ltx_ref ltx_missing_label ltx_ref_self">LABEL:Tab:comparision</span>. Amongst all simulators evaluated, the present work, UNav-Sim, stands out for its superior rendering quality, achieved through the utilization of the  <a href="#id10.10.id10"><span href="#id10.10.id10" title="unreal engine" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long">unreal engine</span></span></a> (<a href="#id10.10.id10"><abbr href="#id10.10.id10" title="unreal engine" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">UE</span></abbr></a>)5 graphics engine. Additionally, UNav-Sim supports a range of tools commonly used in developing robotics solutions, such as <a href="#id14.14.id14"><abbr href="#id14.14.id14" title="robot operating system" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">ROS</span></abbr></a>, gym environments, and autopilot systems. Furthermore, UNav-Sim is compatible with both Windows and Linux operating systems.</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">III </span><span id="S3.1.1" class="ltx_text ltx_font_smallcaps">UNav-Sim software architecture</span>
</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">UNav-Sim is composed of three main components, as illustrated in Fig.¬†<a href="#S1.F2" title="Figure 2 ‚Ä£ I Introduction ‚Ä£ UNav-Sim: A Visually Realistic Underwater Robotics Simulator and Synthetic Data-generation Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>: an underwater physics simulator, a state-of-the-art rendering engine, i.e. <a href="#id12.12.id12"><abbr href="#id12.12.id12" title="unreal engine 5" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">UE5</span></abbr></a>, and an autonomy stack. The underwater physics simulator, which contains the lumped parameter <a href="#id1.1.id1"><abbr href="#id1.1.id1" title="remotely operated vehicle" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">ROV</span></abbr></a> model and underwater dynamics equations, is modular and allows underwater vehicle motion simulation. It leverages the capabilities of AirSim, including the Fastphysics solver and a range of sensor models, such as GPS, IMU, cameras, and distance sensor. An API allows communication between the navigation stack and the physics simulator, with the former receiving essential sensor data and sending control commands. A <a href="#id14.14.id14"><abbr href="#id14.14.id14" title="robot operating system" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">ROS</span></abbr></a> wrapper is also available, which enables <a href="#id14.14.id14"><abbr href="#id14.14.id14" title="robot operating system" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">ROS</span></abbr></a>-based development and communication between different modules.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS1.5.1.1" class="ltx_text">III-A</span> </span><span id="S3.SS1.6.2" class="ltx_text ltx_font_italic">Underwater environment rendering</span>
</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.3" class="ltx_p">Underwater image formation can be modelled as a superposition of absorption, forward scattering, and backscattering effects at each pixel <math id="S3.SS1.p1.1.m1.2" class="ltx_Math" alttext="\textbf{x}=(u,v)" display="inline"><semantics id="S3.SS1.p1.1.m1.2a"><mrow id="S3.SS1.p1.1.m1.2.3" xref="S3.SS1.p1.1.m1.2.3.cmml"><mtext class="ltx_mathvariant_bold" id="S3.SS1.p1.1.m1.2.3.2" xref="S3.SS1.p1.1.m1.2.3.2a.cmml">x</mtext><mo id="S3.SS1.p1.1.m1.2.3.1" xref="S3.SS1.p1.1.m1.2.3.1.cmml">=</mo><mrow id="S3.SS1.p1.1.m1.2.3.3.2" xref="S3.SS1.p1.1.m1.2.3.3.1.cmml"><mo stretchy="false" id="S3.SS1.p1.1.m1.2.3.3.2.1" xref="S3.SS1.p1.1.m1.2.3.3.1.cmml">(</mo><mi id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml">u</mi><mo id="S3.SS1.p1.1.m1.2.3.3.2.2" xref="S3.SS1.p1.1.m1.2.3.3.1.cmml">,</mo><mi id="S3.SS1.p1.1.m1.2.2" xref="S3.SS1.p1.1.m1.2.2.cmml">v</mi><mo stretchy="false" id="S3.SS1.p1.1.m1.2.3.3.2.3" xref="S3.SS1.p1.1.m1.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.2b"><apply id="S3.SS1.p1.1.m1.2.3.cmml" xref="S3.SS1.p1.1.m1.2.3"><eq id="S3.SS1.p1.1.m1.2.3.1.cmml" xref="S3.SS1.p1.1.m1.2.3.1"></eq><ci id="S3.SS1.p1.1.m1.2.3.2a.cmml" xref="S3.SS1.p1.1.m1.2.3.2"><mtext class="ltx_mathvariant_bold" id="S3.SS1.p1.1.m1.2.3.2.cmml" xref="S3.SS1.p1.1.m1.2.3.2">x</mtext></ci><interval closure="open" id="S3.SS1.p1.1.m1.2.3.3.1.cmml" xref="S3.SS1.p1.1.m1.2.3.3.2"><ci id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1">ùë¢</ci><ci id="S3.SS1.p1.1.m1.2.2.cmml" xref="S3.SS1.p1.1.m1.2.2">ùë£</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.2c">\textbf{x}=(u,v)</annotation></semantics></math>. The image intensity <math id="S3.SS1.p1.2.m2.1" class="ltx_Math" alttext="I_{c}(x)" display="inline"><semantics id="S3.SS1.p1.2.m2.1a"><mrow id="S3.SS1.p1.2.m2.1.2" xref="S3.SS1.p1.2.m2.1.2.cmml"><msub id="S3.SS1.p1.2.m2.1.2.2" xref="S3.SS1.p1.2.m2.1.2.2.cmml"><mi id="S3.SS1.p1.2.m2.1.2.2.2" xref="S3.SS1.p1.2.m2.1.2.2.2.cmml">I</mi><mi id="S3.SS1.p1.2.m2.1.2.2.3" xref="S3.SS1.p1.2.m2.1.2.2.3.cmml">c</mi></msub><mo lspace="0em" rspace="0em" id="S3.SS1.p1.2.m2.1.2.1" xref="S3.SS1.p1.2.m2.1.2.1.cmml">‚Äã</mo><mrow id="S3.SS1.p1.2.m2.1.2.3.2" xref="S3.SS1.p1.2.m2.1.2.cmml"><mo stretchy="false" id="S3.SS1.p1.2.m2.1.2.3.2.1" xref="S3.SS1.p1.2.m2.1.2.cmml">(</mo><mi id="S3.SS1.p1.2.m2.1.1" xref="S3.SS1.p1.2.m2.1.1.cmml">x</mi><mo stretchy="false" id="S3.SS1.p1.2.m2.1.2.3.2.2" xref="S3.SS1.p1.2.m2.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.2.m2.1b"><apply id="S3.SS1.p1.2.m2.1.2.cmml" xref="S3.SS1.p1.2.m2.1.2"><times id="S3.SS1.p1.2.m2.1.2.1.cmml" xref="S3.SS1.p1.2.m2.1.2.1"></times><apply id="S3.SS1.p1.2.m2.1.2.2.cmml" xref="S3.SS1.p1.2.m2.1.2.2"><csymbol cd="ambiguous" id="S3.SS1.p1.2.m2.1.2.2.1.cmml" xref="S3.SS1.p1.2.m2.1.2.2">subscript</csymbol><ci id="S3.SS1.p1.2.m2.1.2.2.2.cmml" xref="S3.SS1.p1.2.m2.1.2.2.2">ùêº</ci><ci id="S3.SS1.p1.2.m2.1.2.2.3.cmml" xref="S3.SS1.p1.2.m2.1.2.2.3">ùëê</ci></apply><ci id="S3.SS1.p1.2.m2.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1">ùë•</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.2.m2.1c">I_{c}(x)</annotation></semantics></math> in each color channel <math id="S3.SS1.p1.3.m3.1" class="ltx_Math" alttext="c" display="inline"><semantics id="S3.SS1.p1.3.m3.1a"><mi id="S3.SS1.p1.3.m3.1.1" xref="S3.SS1.p1.3.m3.1.1.cmml">c</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.3.m3.1b"><ci id="S3.SS1.p1.3.m3.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1">ùëê</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.3.m3.1c">c</annotation></semantics></math> can be expressed as <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>:</p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<table id="S3.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E1.m1.4" class="ltx_Math" alttext="I_{c}(x)=D_{c}(x)+F_{c}(x)+B_{c}(x)" display="block"><semantics id="S3.E1.m1.4a"><mrow id="S3.E1.m1.4.5" xref="S3.E1.m1.4.5.cmml"><mrow id="S3.E1.m1.4.5.2" xref="S3.E1.m1.4.5.2.cmml"><msub id="S3.E1.m1.4.5.2.2" xref="S3.E1.m1.4.5.2.2.cmml"><mi id="S3.E1.m1.4.5.2.2.2" xref="S3.E1.m1.4.5.2.2.2.cmml">I</mi><mi id="S3.E1.m1.4.5.2.2.3" xref="S3.E1.m1.4.5.2.2.3.cmml">c</mi></msub><mo lspace="0em" rspace="0em" id="S3.E1.m1.4.5.2.1" xref="S3.E1.m1.4.5.2.1.cmml">‚Äã</mo><mrow id="S3.E1.m1.4.5.2.3.2" xref="S3.E1.m1.4.5.2.cmml"><mo stretchy="false" id="S3.E1.m1.4.5.2.3.2.1" xref="S3.E1.m1.4.5.2.cmml">(</mo><mi id="S3.E1.m1.1.1" xref="S3.E1.m1.1.1.cmml">x</mi><mo stretchy="false" id="S3.E1.m1.4.5.2.3.2.2" xref="S3.E1.m1.4.5.2.cmml">)</mo></mrow></mrow><mo id="S3.E1.m1.4.5.1" xref="S3.E1.m1.4.5.1.cmml">=</mo><mrow id="S3.E1.m1.4.5.3" xref="S3.E1.m1.4.5.3.cmml"><mrow id="S3.E1.m1.4.5.3.2" xref="S3.E1.m1.4.5.3.2.cmml"><msub id="S3.E1.m1.4.5.3.2.2" xref="S3.E1.m1.4.5.3.2.2.cmml"><mi id="S3.E1.m1.4.5.3.2.2.2" xref="S3.E1.m1.4.5.3.2.2.2.cmml">D</mi><mi id="S3.E1.m1.4.5.3.2.2.3" xref="S3.E1.m1.4.5.3.2.2.3.cmml">c</mi></msub><mo lspace="0em" rspace="0em" id="S3.E1.m1.4.5.3.2.1" xref="S3.E1.m1.4.5.3.2.1.cmml">‚Äã</mo><mrow id="S3.E1.m1.4.5.3.2.3.2" xref="S3.E1.m1.4.5.3.2.cmml"><mo stretchy="false" id="S3.E1.m1.4.5.3.2.3.2.1" xref="S3.E1.m1.4.5.3.2.cmml">(</mo><mi id="S3.E1.m1.2.2" xref="S3.E1.m1.2.2.cmml">x</mi><mo stretchy="false" id="S3.E1.m1.4.5.3.2.3.2.2" xref="S3.E1.m1.4.5.3.2.cmml">)</mo></mrow></mrow><mo id="S3.E1.m1.4.5.3.1" xref="S3.E1.m1.4.5.3.1.cmml">+</mo><mrow id="S3.E1.m1.4.5.3.3" xref="S3.E1.m1.4.5.3.3.cmml"><msub id="S3.E1.m1.4.5.3.3.2" xref="S3.E1.m1.4.5.3.3.2.cmml"><mi id="S3.E1.m1.4.5.3.3.2.2" xref="S3.E1.m1.4.5.3.3.2.2.cmml">F</mi><mi id="S3.E1.m1.4.5.3.3.2.3" xref="S3.E1.m1.4.5.3.3.2.3.cmml">c</mi></msub><mo lspace="0em" rspace="0em" id="S3.E1.m1.4.5.3.3.1" xref="S3.E1.m1.4.5.3.3.1.cmml">‚Äã</mo><mrow id="S3.E1.m1.4.5.3.3.3.2" xref="S3.E1.m1.4.5.3.3.cmml"><mo stretchy="false" id="S3.E1.m1.4.5.3.3.3.2.1" xref="S3.E1.m1.4.5.3.3.cmml">(</mo><mi id="S3.E1.m1.3.3" xref="S3.E1.m1.3.3.cmml">x</mi><mo stretchy="false" id="S3.E1.m1.4.5.3.3.3.2.2" xref="S3.E1.m1.4.5.3.3.cmml">)</mo></mrow></mrow><mo id="S3.E1.m1.4.5.3.1a" xref="S3.E1.m1.4.5.3.1.cmml">+</mo><mrow id="S3.E1.m1.4.5.3.4" xref="S3.E1.m1.4.5.3.4.cmml"><msub id="S3.E1.m1.4.5.3.4.2" xref="S3.E1.m1.4.5.3.4.2.cmml"><mi id="S3.E1.m1.4.5.3.4.2.2" xref="S3.E1.m1.4.5.3.4.2.2.cmml">B</mi><mi id="S3.E1.m1.4.5.3.4.2.3" xref="S3.E1.m1.4.5.3.4.2.3.cmml">c</mi></msub><mo lspace="0em" rspace="0em" id="S3.E1.m1.4.5.3.4.1" xref="S3.E1.m1.4.5.3.4.1.cmml">‚Äã</mo><mrow id="S3.E1.m1.4.5.3.4.3.2" xref="S3.E1.m1.4.5.3.4.cmml"><mo stretchy="false" id="S3.E1.m1.4.5.3.4.3.2.1" xref="S3.E1.m1.4.5.3.4.cmml">(</mo><mi id="S3.E1.m1.4.4" xref="S3.E1.m1.4.4.cmml">x</mi><mo stretchy="false" id="S3.E1.m1.4.5.3.4.3.2.2" xref="S3.E1.m1.4.5.3.4.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.4b"><apply id="S3.E1.m1.4.5.cmml" xref="S3.E1.m1.4.5"><eq id="S3.E1.m1.4.5.1.cmml" xref="S3.E1.m1.4.5.1"></eq><apply id="S3.E1.m1.4.5.2.cmml" xref="S3.E1.m1.4.5.2"><times id="S3.E1.m1.4.5.2.1.cmml" xref="S3.E1.m1.4.5.2.1"></times><apply id="S3.E1.m1.4.5.2.2.cmml" xref="S3.E1.m1.4.5.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.4.5.2.2.1.cmml" xref="S3.E1.m1.4.5.2.2">subscript</csymbol><ci id="S3.E1.m1.4.5.2.2.2.cmml" xref="S3.E1.m1.4.5.2.2.2">ùêº</ci><ci id="S3.E1.m1.4.5.2.2.3.cmml" xref="S3.E1.m1.4.5.2.2.3">ùëê</ci></apply><ci id="S3.E1.m1.1.1.cmml" xref="S3.E1.m1.1.1">ùë•</ci></apply><apply id="S3.E1.m1.4.5.3.cmml" xref="S3.E1.m1.4.5.3"><plus id="S3.E1.m1.4.5.3.1.cmml" xref="S3.E1.m1.4.5.3.1"></plus><apply id="S3.E1.m1.4.5.3.2.cmml" xref="S3.E1.m1.4.5.3.2"><times id="S3.E1.m1.4.5.3.2.1.cmml" xref="S3.E1.m1.4.5.3.2.1"></times><apply id="S3.E1.m1.4.5.3.2.2.cmml" xref="S3.E1.m1.4.5.3.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.4.5.3.2.2.1.cmml" xref="S3.E1.m1.4.5.3.2.2">subscript</csymbol><ci id="S3.E1.m1.4.5.3.2.2.2.cmml" xref="S3.E1.m1.4.5.3.2.2.2">ùê∑</ci><ci id="S3.E1.m1.4.5.3.2.2.3.cmml" xref="S3.E1.m1.4.5.3.2.2.3">ùëê</ci></apply><ci id="S3.E1.m1.2.2.cmml" xref="S3.E1.m1.2.2">ùë•</ci></apply><apply id="S3.E1.m1.4.5.3.3.cmml" xref="S3.E1.m1.4.5.3.3"><times id="S3.E1.m1.4.5.3.3.1.cmml" xref="S3.E1.m1.4.5.3.3.1"></times><apply id="S3.E1.m1.4.5.3.3.2.cmml" xref="S3.E1.m1.4.5.3.3.2"><csymbol cd="ambiguous" id="S3.E1.m1.4.5.3.3.2.1.cmml" xref="S3.E1.m1.4.5.3.3.2">subscript</csymbol><ci id="S3.E1.m1.4.5.3.3.2.2.cmml" xref="S3.E1.m1.4.5.3.3.2.2">ùêπ</ci><ci id="S3.E1.m1.4.5.3.3.2.3.cmml" xref="S3.E1.m1.4.5.3.3.2.3">ùëê</ci></apply><ci id="S3.E1.m1.3.3.cmml" xref="S3.E1.m1.3.3">ùë•</ci></apply><apply id="S3.E1.m1.4.5.3.4.cmml" xref="S3.E1.m1.4.5.3.4"><times id="S3.E1.m1.4.5.3.4.1.cmml" xref="S3.E1.m1.4.5.3.4.1"></times><apply id="S3.E1.m1.4.5.3.4.2.cmml" xref="S3.E1.m1.4.5.3.4.2"><csymbol cd="ambiguous" id="S3.E1.m1.4.5.3.4.2.1.cmml" xref="S3.E1.m1.4.5.3.4.2">subscript</csymbol><ci id="S3.E1.m1.4.5.3.4.2.2.cmml" xref="S3.E1.m1.4.5.3.4.2.2">ùêµ</ci><ci id="S3.E1.m1.4.5.3.4.2.3.cmml" xref="S3.E1.m1.4.5.3.4.2.3">ùëê</ci></apply><ci id="S3.E1.m1.4.4.cmml" xref="S3.E1.m1.4.4">ùë•</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.4c">I_{c}(x)=D_{c}(x)+F_{c}(x)+B_{c}(x)</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
</div>
<div id="S3.SS1.p3" class="ltx_para">
<p id="S3.SS1.p3.3" class="ltx_p">In this equation, <math id="S3.SS1.p3.1.m1.1" class="ltx_Math" alttext="D_{c}" display="inline"><semantics id="S3.SS1.p3.1.m1.1a"><msub id="S3.SS1.p3.1.m1.1.1" xref="S3.SS1.p3.1.m1.1.1.cmml"><mi id="S3.SS1.p3.1.m1.1.1.2" xref="S3.SS1.p3.1.m1.1.1.2.cmml">D</mi><mi id="S3.SS1.p3.1.m1.1.1.3" xref="S3.SS1.p3.1.m1.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.1.m1.1b"><apply id="S3.SS1.p3.1.m1.1.1.cmml" xref="S3.SS1.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.1.m1.1.1.1.cmml" xref="S3.SS1.p3.1.m1.1.1">subscript</csymbol><ci id="S3.SS1.p3.1.m1.1.1.2.cmml" xref="S3.SS1.p3.1.m1.1.1.2">ùê∑</ci><ci id="S3.SS1.p3.1.m1.1.1.3.cmml" xref="S3.SS1.p3.1.m1.1.1.3">ùëê</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.1.m1.1c">D_{c}</annotation></semantics></math> represents the attenuated signal from the object due to absorption. The forward scattering component <math id="S3.SS1.p3.2.m2.1" class="ltx_Math" alttext="F_{c}" display="inline"><semantics id="S3.SS1.p3.2.m2.1a"><msub id="S3.SS1.p3.2.m2.1.1" xref="S3.SS1.p3.2.m2.1.1.cmml"><mi id="S3.SS1.p3.2.m2.1.1.2" xref="S3.SS1.p3.2.m2.1.1.2.cmml">F</mi><mi id="S3.SS1.p3.2.m2.1.1.3" xref="S3.SS1.p3.2.m2.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.2.m2.1b"><apply id="S3.SS1.p3.2.m2.1.1.cmml" xref="S3.SS1.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.2.m2.1.1.1.cmml" xref="S3.SS1.p3.2.m2.1.1">subscript</csymbol><ci id="S3.SS1.p3.2.m2.1.1.2.cmml" xref="S3.SS1.p3.2.m2.1.1.2">ùêπ</ci><ci id="S3.SS1.p3.2.m2.1.1.3.cmml" xref="S3.SS1.p3.2.m2.1.1.3">ùëê</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.2.m2.1c">F_{c}</annotation></semantics></math> captures the light from the object that reaches the camera with small-angle scattering. Lastly, the backscattering component <math id="S3.SS1.p3.3.m3.1" class="ltx_Math" alttext="B_{c}" display="inline"><semantics id="S3.SS1.p3.3.m3.1a"><msub id="S3.SS1.p3.3.m3.1.1" xref="S3.SS1.p3.3.m3.1.1.cmml"><mi id="S3.SS1.p3.3.m3.1.1.2" xref="S3.SS1.p3.3.m3.1.1.2.cmml">B</mi><mi id="S3.SS1.p3.3.m3.1.1.3" xref="S3.SS1.p3.3.m3.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.3.m3.1b"><apply id="S3.SS1.p3.3.m3.1.1.cmml" xref="S3.SS1.p3.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.3.m3.1.1.1.cmml" xref="S3.SS1.p3.3.m3.1.1">subscript</csymbol><ci id="S3.SS1.p3.3.m3.1.1.2.cmml" xref="S3.SS1.p3.3.m3.1.1.2">ùêµ</ci><ci id="S3.SS1.p3.3.m3.1.1.3.cmml" xref="S3.SS1.p3.3.m3.1.1.3">ùëê</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.3.m3.1c">B_{c}</annotation></semantics></math> accounts for the degradation in color and contrast caused by the water scattering effect, where the light does not originate directly from the object. These effects can be modelled using different techniques and can vary based on the implementation within the rendering engine.</p>
</div>
<div id="S3.SS1.p4" class="ltx_para">
<p id="S3.SS1.p4.1" class="ltx_p">UNav-Sim utilizes <a href="#id12.12.id12"><abbr href="#id12.12.id12" title="unreal engine 5" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">UE5</span></abbr></a> as the rendering engine, which offers significant improvements over its predecessor, <a href="#id13.13.id13"><abbr href="#id13.13.id13" title="unreal engine 4" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">UE4</span></abbr></a>. <a href="#id12.12.id12"><abbr href="#id12.12.id12" title="unreal engine 5" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">UE5</span></abbr></a> significantly boosts polygon handling to 10 billion, introduces real-time ray-based lighting with Lumen, and incorporates Temporal Super Resolution for high-quality textures with minimal performance impact, enhancing visual fidelity and efficiency.</p>
</div>
<div id="S3.SS1.p5" class="ltx_para">
<p id="S3.SS1.p5.1" class="ltx_p"><a href="#id12.12.id12"><abbr href="#id12.12.id12" title="unreal engine 5" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">UE5</span></abbr></a> underwater rendering module models scattering effects in underwater images (<a href="#S3.E1" title="In III-A Underwater environment rendering ‚Ä£ III UNav-Sim software architecture ‚Ä£ UNav-Sim: A Visually Realistic Underwater Robotics Simulator and Synthetic Data-generation Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>), with Schlick Phase Functions <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>, taking into account the Opaque or Masked water surface.
The transparency of the water is implicitly handled within the volume shading model, and refraction is managed by reading the depth and color beneath the water surface to distort the samples.
One of the main challenges in generating underwater renderings is the variety of imaging conditions that drastically change the environment‚Äôs appearance <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>. <a href="#id12.12.id12"><abbr href="#id12.12.id12" title="unreal engine 5" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">UE5</span></abbr></a> allows users to define the scattering coefficients, absorption coefficients, phase function, and color scale behind the water, providing control over the water‚Äôs appearance and thus allowing users to simulate their preferred environment‚Äôs conditions.</p>
</div>
<div id="S3.SS1.p6" class="ltx_para">
<p id="S3.SS1.p6.1" class="ltx_p">Consequently, using <a href="#id12.12.id12"><abbr href="#id12.12.id12" title="unreal engine 5" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">UE5</span></abbr></a> within UNav-Sim, underwater environments that appear realistic can be created, where <a href="#id10.10.id10"><abbr href="#id10.10.id10" title="unreal engine" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">UE</span></abbr></a> allows designers to place and manipulate assets in a 3D space.
These assets can include terrain, static meshes, and lighting. They can be customized to create underwater virtual worlds, as shown in Fig. <a href="#S1.F2" title="Figure 2 ‚Ä£ I Introduction ‚Ä£ UNav-Sim: A Visually Realistic Underwater Robotics Simulator and Synthetic Data-generation Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
<div id="S3.SS1.p7" class="ltx_para">
<p id="S3.SS1.p7.1" class="ltx_p">UE uses blueprints to define the physical representation and behaviour of an <a href="#id1.1.id1"><abbr href="#id1.1.id1" title="remotely operated vehicle" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">ROV</span></abbr></a>. In UNav-Sim, the blueprint is linked to an external underwater physics engine to obtain kinematic information. The blueprint also defines cameras that gather visual information from the underwater environment, such as RGB and depth images.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS2.5.1.1" class="ltx_text">III-B</span> </span><span id="S3.SS2.6.2" class="ltx_text ltx_font_italic">Underwater physics</span>
</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">The core of the physics underlying underwater vehicles consists of the equations of motion that describe the different forces and moments acting on the vehicle‚Äôs body. These forces and moments can be classified into three categories: hydrostatics, hydrodynamics, and externally applied forces.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.16" class="ltx_p">The equation of motion in the body-fixed frame, originally presented in Fossen <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>, can be expressed in SNAME notation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite> as,</p>
<table id="S3.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E2.m1.22" class="ltx_Math" alttext="\begin{multlined}\mathbf{M}_{RB}\dot{\mathbf{\nu}}=\tau-\underbrace{\mathbf{C}_{RB}(\mathbf{\nu})\mathbf{\nu}}_{\text{Coriolis \hskip 1.0pt term}}-\underbrace{\mathbf{M}_{A}\dot{\mathbf{\nu}}-\mathbf{C}_{A}(\mathbf{\nu})\mathbf{\nu}}_{\text{Added\hskip 2.0ptmass}}\\
-\underbrace{\mathbf{D}(\mathbf{\nu})\mathbf{{\mathbf{\nu}}}}_{\text{Drag }}-\mathbf{g}(\mathbf{\eta}).\end{multlined}\mathbf{M}_{RB}\dot{\mathbf{\nu}}=\tau-\underbrace{\mathbf{C}_{RB}(\mathbf{\nu})\mathbf{\nu}}_{\text{Coriolis \hskip 1.0pt term}}-\underbrace{\mathbf{M}_{A}\dot{\mathbf{\nu}}-\mathbf{C}_{A}(\mathbf{\nu})\mathbf{\nu}}_{\text{Added\hskip 2.0ptmass}}\\
-\underbrace{\mathbf{D}(\mathbf{\nu})\mathbf{{\mathbf{\nu}}}}_{\text{Drag }}-\mathbf{g}(\mathbf{\eta})." display="block"><semantics id="S3.E2.m1.22a"><mtable displaystyle="true" rowspacing="0pt" id="S3.E2.m1.22.22.2"><mtr id="S3.E2.m1.22.22.2a"><mtd class="ltx_align_left" columnalign="left" id="S3.E2.m1.22.22.2b"><mrow id="S3.E2.m1.11.11.11.11.11"><mrow id="S3.E2.m1.11.11.11.11.11.12"><msub id="S3.E2.m1.11.11.11.11.11.12.2"><mi id="S3.E2.m1.1.1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.1.1.cmml">ùêå</mi><mrow id="S3.E2.m1.2.2.2.2.2.2.1" xref="S3.E2.m1.2.2.2.2.2.2.1.cmml"><mi id="S3.E2.m1.2.2.2.2.2.2.1.2" xref="S3.E2.m1.2.2.2.2.2.2.1.2.cmml">R</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.2.2.2.2.1.1" xref="S3.E2.m1.2.2.2.2.2.2.1.1.cmml">‚Äã</mo><mi id="S3.E2.m1.2.2.2.2.2.2.1.3" xref="S3.E2.m1.2.2.2.2.2.2.1.3.cmml">B</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S3.E2.m1.11.11.11.11.11.12.1" xref="S3.E2.m1.21.21.1.1.1.cmml">‚Äã</mo><mover accent="true" id="S3.E2.m1.3.3.3.3.3.3" xref="S3.E2.m1.3.3.3.3.3.3.cmml"><mi id="S3.E2.m1.3.3.3.3.3.3.2" xref="S3.E2.m1.3.3.3.3.3.3.2.cmml">ŒΩ</mi><mo id="S3.E2.m1.3.3.3.3.3.3.1" xref="S3.E2.m1.3.3.3.3.3.3.1.cmml">Àô</mo></mover></mrow><mo id="S3.E2.m1.4.4.4.4.4.4" xref="S3.E2.m1.4.4.4.4.4.4.cmml">=</mo><mrow id="S3.E2.m1.11.11.11.11.11.13"><mi id="S3.E2.m1.5.5.5.5.5.5" xref="S3.E2.m1.5.5.5.5.5.5.cmml">œÑ</mi><mo id="S3.E2.m1.6.6.6.6.6.6" xref="S3.E2.m1.6.6.6.6.6.6.cmml">‚àí</mo><munder id="S3.E2.m1.11.11.11.11.11.13.1"><munder accentunder="true" id="S3.E2.m1.7.7.7.7.7.7" xref="S3.E2.m1.7.7.7.7.7.7.cmml"><mrow id="S3.E2.m1.7.7.7.7.7.7.1" xref="S3.E2.m1.7.7.7.7.7.7.1.cmml"><msub id="S3.E2.m1.7.7.7.7.7.7.1.3" xref="S3.E2.m1.7.7.7.7.7.7.1.3.cmml"><mi id="S3.E2.m1.7.7.7.7.7.7.1.3.2" xref="S3.E2.m1.7.7.7.7.7.7.1.3.2.cmml">ùêÇ</mi><mrow id="S3.E2.m1.7.7.7.7.7.7.1.3.3" xref="S3.E2.m1.7.7.7.7.7.7.1.3.3.cmml"><mi id="S3.E2.m1.7.7.7.7.7.7.1.3.3.2" xref="S3.E2.m1.7.7.7.7.7.7.1.3.3.2.cmml">R</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.7.7.7.7.7.7.1.3.3.1" xref="S3.E2.m1.7.7.7.7.7.7.1.3.3.1.cmml">‚Äã</mo><mi id="S3.E2.m1.7.7.7.7.7.7.1.3.3.3" xref="S3.E2.m1.7.7.7.7.7.7.1.3.3.3.cmml">B</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S3.E2.m1.7.7.7.7.7.7.1.2" xref="S3.E2.m1.7.7.7.7.7.7.1.2.cmml">‚Äã</mo><mrow id="S3.E2.m1.7.7.7.7.7.7.1.4.2" xref="S3.E2.m1.7.7.7.7.7.7.1.cmml"><mo stretchy="false" id="S3.E2.m1.7.7.7.7.7.7.1.4.2.1" xref="S3.E2.m1.7.7.7.7.7.7.1.cmml">(</mo><mi id="S3.E2.m1.7.7.7.7.7.7.1.1" xref="S3.E2.m1.7.7.7.7.7.7.1.1.cmml">ŒΩ</mi><mo stretchy="false" id="S3.E2.m1.7.7.7.7.7.7.1.4.2.2" xref="S3.E2.m1.7.7.7.7.7.7.1.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S3.E2.m1.7.7.7.7.7.7.1.2a" xref="S3.E2.m1.7.7.7.7.7.7.1.2.cmml">‚Äã</mo><mi id="S3.E2.m1.7.7.7.7.7.7.1.5" xref="S3.E2.m1.7.7.7.7.7.7.1.5.cmml">ŒΩ</mi></mrow><mo id="S3.E2.m1.7.7.7.7.7.7.2" xref="S3.E2.m1.7.7.7.7.7.7.2.cmml">‚èü</mo></munder><mtext id="S3.E2.m1.8.8.8.8.8.8.1" xref="S3.E2.m1.8.8.8.8.8.8.1a.cmml">Coriolis ‚ÄÜ term</mtext></munder><mo id="S3.E2.m1.6.6.6.6.6.6a" xref="S3.E2.m1.6.6.6.6.6.6.cmml">‚àí</mo><munder id="S3.E2.m1.11.11.11.11.11.13.2"><munder accentunder="true" id="S3.E2.m1.10.10.10.10.10.10" xref="S3.E2.m1.10.10.10.10.10.10.cmml"><mrow id="S3.E2.m1.10.10.10.10.10.10.1" xref="S3.E2.m1.10.10.10.10.10.10.1.cmml"><mrow id="S3.E2.m1.10.10.10.10.10.10.1.3" xref="S3.E2.m1.10.10.10.10.10.10.1.3.cmml"><msub id="S3.E2.m1.10.10.10.10.10.10.1.3.2" xref="S3.E2.m1.10.10.10.10.10.10.1.3.2.cmml"><mi id="S3.E2.m1.10.10.10.10.10.10.1.3.2.2" xref="S3.E2.m1.10.10.10.10.10.10.1.3.2.2.cmml">ùêå</mi><mi id="S3.E2.m1.10.10.10.10.10.10.1.3.2.3" xref="S3.E2.m1.10.10.10.10.10.10.1.3.2.3.cmml">A</mi></msub><mo lspace="0em" rspace="0em" id="S3.E2.m1.10.10.10.10.10.10.1.3.1" xref="S3.E2.m1.10.10.10.10.10.10.1.3.1.cmml">‚Äã</mo><mover accent="true" id="S3.E2.m1.10.10.10.10.10.10.1.3.3" xref="S3.E2.m1.10.10.10.10.10.10.1.3.3.cmml"><mi id="S3.E2.m1.10.10.10.10.10.10.1.3.3.2" xref="S3.E2.m1.10.10.10.10.10.10.1.3.3.2.cmml">ŒΩ</mi><mo id="S3.E2.m1.10.10.10.10.10.10.1.3.3.1" xref="S3.E2.m1.10.10.10.10.10.10.1.3.3.1.cmml">Àô</mo></mover></mrow><mo id="S3.E2.m1.10.10.10.10.10.10.1.2" xref="S3.E2.m1.10.10.10.10.10.10.1.2.cmml">‚àí</mo><mrow id="S3.E2.m1.10.10.10.10.10.10.1.4" xref="S3.E2.m1.10.10.10.10.10.10.1.4.cmml"><msub id="S3.E2.m1.10.10.10.10.10.10.1.4.2" xref="S3.E2.m1.10.10.10.10.10.10.1.4.2.cmml"><mi id="S3.E2.m1.10.10.10.10.10.10.1.4.2.2" xref="S3.E2.m1.10.10.10.10.10.10.1.4.2.2.cmml">ùêÇ</mi><mi id="S3.E2.m1.10.10.10.10.10.10.1.4.2.3" xref="S3.E2.m1.10.10.10.10.10.10.1.4.2.3.cmml">A</mi></msub><mo lspace="0em" rspace="0em" id="S3.E2.m1.10.10.10.10.10.10.1.4.1" xref="S3.E2.m1.10.10.10.10.10.10.1.4.1.cmml">‚Äã</mo><mrow id="S3.E2.m1.10.10.10.10.10.10.1.4.3.2" xref="S3.E2.m1.10.10.10.10.10.10.1.4.cmml"><mo stretchy="false" id="S3.E2.m1.10.10.10.10.10.10.1.4.3.2.1" xref="S3.E2.m1.10.10.10.10.10.10.1.4.cmml">(</mo><mi id="S3.E2.m1.10.10.10.10.10.10.1.1" xref="S3.E2.m1.10.10.10.10.10.10.1.1.cmml">ŒΩ</mi><mo stretchy="false" id="S3.E2.m1.10.10.10.10.10.10.1.4.3.2.2" xref="S3.E2.m1.10.10.10.10.10.10.1.4.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S3.E2.m1.10.10.10.10.10.10.1.4.1a" xref="S3.E2.m1.10.10.10.10.10.10.1.4.1.cmml">‚Äã</mo><mi id="S3.E2.m1.10.10.10.10.10.10.1.4.4" xref="S3.E2.m1.10.10.10.10.10.10.1.4.4.cmml">ŒΩ</mi></mrow></mrow><mo id="S3.E2.m1.10.10.10.10.10.10.2" xref="S3.E2.m1.10.10.10.10.10.10.2.cmml">‚èü</mo></munder><mtext id="S3.E2.m1.11.11.11.11.11.11.1" xref="S3.E2.m1.11.11.11.11.11.11.1a.cmml">Added‚ÄÖmass</mtext></munder></mrow></mrow></mtd></mtr><mtr id="S3.E2.m1.22.22.2c"><mtd class="ltx_align_right" columnalign="right" id="S3.E2.m1.22.22.2d"><mrow id="S3.E2.m1.22.22.2.21.10.10.10"><mrow id="S3.E2.m1.22.22.2.21.10.10.10.1"><mrow id="S3.E2.m1.22.22.2.21.10.10.10.1.1"><mo id="S3.E2.m1.22.22.2.21.10.10.10.1.1a" xref="S3.E2.m1.21.21.1.1.1.cmml">‚àí</mo><munder id="S3.E2.m1.22.22.2.21.10.10.10.1.1.1"><munder accentunder="true" id="S3.E2.m1.13.13.13.2.2.2" xref="S3.E2.m1.13.13.13.2.2.2.cmml"><mrow id="S3.E2.m1.13.13.13.2.2.2.1" xref="S3.E2.m1.13.13.13.2.2.2.1.cmml"><mi id="S3.E2.m1.13.13.13.2.2.2.1.3" xref="S3.E2.m1.13.13.13.2.2.2.1.3.cmml">ùêÉ</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.13.13.13.2.2.2.1.2" xref="S3.E2.m1.13.13.13.2.2.2.1.2.cmml">‚Äã</mo><mrow id="S3.E2.m1.13.13.13.2.2.2.1.4.2" xref="S3.E2.m1.13.13.13.2.2.2.1.cmml"><mo stretchy="false" id="S3.E2.m1.13.13.13.2.2.2.1.4.2.1" xref="S3.E2.m1.13.13.13.2.2.2.1.cmml">(</mo><mi id="S3.E2.m1.13.13.13.2.2.2.1.1" xref="S3.E2.m1.13.13.13.2.2.2.1.1.cmml">ŒΩ</mi><mo stretchy="false" id="S3.E2.m1.13.13.13.2.2.2.1.4.2.2" xref="S3.E2.m1.13.13.13.2.2.2.1.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S3.E2.m1.13.13.13.2.2.2.1.2a" xref="S3.E2.m1.13.13.13.2.2.2.1.2.cmml">‚Äã</mo><mi id="S3.E2.m1.13.13.13.2.2.2.1.5" xref="S3.E2.m1.13.13.13.2.2.2.1.5.cmml">ŒΩ</mi></mrow><mo id="S3.E2.m1.13.13.13.2.2.2.2" xref="S3.E2.m1.13.13.13.2.2.2.2.cmml">‚èü</mo></munder><mtext id="S3.E2.m1.14.14.14.3.3.3.1" xref="S3.E2.m1.14.14.14.3.3.3.1a.cmml">Drag¬†</mtext></munder></mrow><mo id="S3.E2.m1.15.15.15.4.4.4" xref="S3.E2.m1.21.21.1.1.1.cmml">‚àí</mo><mrow id="S3.E2.m1.22.22.2.21.10.10.10.1.2"><mi id="S3.E2.m1.16.16.16.5.5.5" xref="S3.E2.m1.16.16.16.5.5.5.cmml">ùê†</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.22.22.2.21.10.10.10.1.2.1" xref="S3.E2.m1.21.21.1.1.1.cmml">‚Äã</mo><mrow id="S3.E2.m1.22.22.2.21.10.10.10.1.2.2"><mo stretchy="false" id="S3.E2.m1.17.17.17.6.6.6" xref="S3.E2.m1.21.21.1.1.1.cmml">(</mo><mi id="S3.E2.m1.18.18.18.7.7.7" xref="S3.E2.m1.18.18.18.7.7.7.cmml">Œ∑</mi><mo stretchy="false" id="S3.E2.m1.19.19.19.8.8.8" xref="S3.E2.m1.21.21.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo lspace="0em" id="S3.E2.m1.20.20.20.9.9.9" xref="S3.E2.m1.21.21.1.1.1.cmml">.</mo></mrow></mtd></mtr></mtable><annotation-xml encoding="MathML-Content" id="S3.E2.m1.22b"><apply id="S3.E2.m1.21.21.1.1.1.cmml" xref="S3.E2.m1.11.11.11.11.11.12.1"><eq id="S3.E2.m1.4.4.4.4.4.4.cmml" xref="S3.E2.m1.4.4.4.4.4.4"></eq><apply id="S3.E2.m1.21.21.1.1.1.2.cmml" xref="S3.E2.m1.11.11.11.11.11.12.1"><times id="S3.E2.m1.21.21.1.1.1.2.1.cmml" xref="S3.E2.m1.11.11.11.11.11.12.1"></times><apply id="S3.E2.m1.21.21.1.1.1.2.2.cmml" xref="S3.E2.m1.11.11.11.11.11.12.1"><csymbol cd="ambiguous" id="S3.E2.m1.21.21.1.1.1.2.2.1.cmml" xref="S3.E2.m1.11.11.11.11.11.12.1">subscript</csymbol><ci id="S3.E2.m1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1">ùêå</ci><apply id="S3.E2.m1.2.2.2.2.2.2.1.cmml" xref="S3.E2.m1.2.2.2.2.2.2.1"><times id="S3.E2.m1.2.2.2.2.2.2.1.1.cmml" xref="S3.E2.m1.2.2.2.2.2.2.1.1"></times><ci id="S3.E2.m1.2.2.2.2.2.2.1.2.cmml" xref="S3.E2.m1.2.2.2.2.2.2.1.2">ùëÖ</ci><ci id="S3.E2.m1.2.2.2.2.2.2.1.3.cmml" xref="S3.E2.m1.2.2.2.2.2.2.1.3">ùêµ</ci></apply></apply><apply id="S3.E2.m1.3.3.3.3.3.3.cmml" xref="S3.E2.m1.3.3.3.3.3.3"><ci id="S3.E2.m1.3.3.3.3.3.3.1.cmml" xref="S3.E2.m1.3.3.3.3.3.3.1">Àô</ci><ci id="S3.E2.m1.3.3.3.3.3.3.2.cmml" xref="S3.E2.m1.3.3.3.3.3.3.2">ùúà</ci></apply></apply><apply id="S3.E2.m1.21.21.1.1.1.3.cmml" xref="S3.E2.m1.11.11.11.11.11.12.1"><minus id="S3.E2.m1.6.6.6.6.6.6.cmml" xref="S3.E2.m1.6.6.6.6.6.6"></minus><ci id="S3.E2.m1.5.5.5.5.5.5.cmml" xref="S3.E2.m1.5.5.5.5.5.5">ùúè</ci><apply id="S3.E2.m1.21.21.1.1.1.3.3.cmml" xref="S3.E2.m1.11.11.11.11.11.12.1"><csymbol cd="ambiguous" id="S3.E2.m1.21.21.1.1.1.3.3.1.cmml" xref="S3.E2.m1.11.11.11.11.11.12.1">subscript</csymbol><apply id="S3.E2.m1.7.7.7.7.7.7.cmml" xref="S3.E2.m1.7.7.7.7.7.7"><ci id="S3.E2.m1.7.7.7.7.7.7.2.cmml" xref="S3.E2.m1.7.7.7.7.7.7.2">‚èü</ci><apply id="S3.E2.m1.7.7.7.7.7.7.1.cmml" xref="S3.E2.m1.7.7.7.7.7.7.1"><times id="S3.E2.m1.7.7.7.7.7.7.1.2.cmml" xref="S3.E2.m1.7.7.7.7.7.7.1.2"></times><apply id="S3.E2.m1.7.7.7.7.7.7.1.3.cmml" xref="S3.E2.m1.7.7.7.7.7.7.1.3"><csymbol cd="ambiguous" id="S3.E2.m1.7.7.7.7.7.7.1.3.1.cmml" xref="S3.E2.m1.7.7.7.7.7.7.1.3">subscript</csymbol><ci id="S3.E2.m1.7.7.7.7.7.7.1.3.2.cmml" xref="S3.E2.m1.7.7.7.7.7.7.1.3.2">ùêÇ</ci><apply id="S3.E2.m1.7.7.7.7.7.7.1.3.3.cmml" xref="S3.E2.m1.7.7.7.7.7.7.1.3.3"><times id="S3.E2.m1.7.7.7.7.7.7.1.3.3.1.cmml" xref="S3.E2.m1.7.7.7.7.7.7.1.3.3.1"></times><ci id="S3.E2.m1.7.7.7.7.7.7.1.3.3.2.cmml" xref="S3.E2.m1.7.7.7.7.7.7.1.3.3.2">ùëÖ</ci><ci id="S3.E2.m1.7.7.7.7.7.7.1.3.3.3.cmml" xref="S3.E2.m1.7.7.7.7.7.7.1.3.3.3">ùêµ</ci></apply></apply><ci id="S3.E2.m1.7.7.7.7.7.7.1.1.cmml" xref="S3.E2.m1.7.7.7.7.7.7.1.1">ùúà</ci><ci id="S3.E2.m1.7.7.7.7.7.7.1.5.cmml" xref="S3.E2.m1.7.7.7.7.7.7.1.5">ùúà</ci></apply></apply><ci id="S3.E2.m1.8.8.8.8.8.8.1a.cmml" xref="S3.E2.m1.8.8.8.8.8.8.1"><mtext mathsize="70%" id="S3.E2.m1.8.8.8.8.8.8.1.cmml" xref="S3.E2.m1.8.8.8.8.8.8.1">Coriolis ‚ÄÜ term</mtext></ci></apply><apply id="S3.E2.m1.21.21.1.1.1.3.4.cmml" xref="S3.E2.m1.11.11.11.11.11.12.1"><csymbol cd="ambiguous" id="S3.E2.m1.21.21.1.1.1.3.4.1.cmml" xref="S3.E2.m1.11.11.11.11.11.12.1">subscript</csymbol><apply id="S3.E2.m1.10.10.10.10.10.10.cmml" xref="S3.E2.m1.10.10.10.10.10.10"><ci id="S3.E2.m1.10.10.10.10.10.10.2.cmml" xref="S3.E2.m1.10.10.10.10.10.10.2">‚èü</ci><apply id="S3.E2.m1.10.10.10.10.10.10.1.cmml" xref="S3.E2.m1.10.10.10.10.10.10.1"><minus id="S3.E2.m1.10.10.10.10.10.10.1.2.cmml" xref="S3.E2.m1.10.10.10.10.10.10.1.2"></minus><apply id="S3.E2.m1.10.10.10.10.10.10.1.3.cmml" xref="S3.E2.m1.10.10.10.10.10.10.1.3"><times id="S3.E2.m1.10.10.10.10.10.10.1.3.1.cmml" xref="S3.E2.m1.10.10.10.10.10.10.1.3.1"></times><apply id="S3.E2.m1.10.10.10.10.10.10.1.3.2.cmml" xref="S3.E2.m1.10.10.10.10.10.10.1.3.2"><csymbol cd="ambiguous" id="S3.E2.m1.10.10.10.10.10.10.1.3.2.1.cmml" xref="S3.E2.m1.10.10.10.10.10.10.1.3.2">subscript</csymbol><ci id="S3.E2.m1.10.10.10.10.10.10.1.3.2.2.cmml" xref="S3.E2.m1.10.10.10.10.10.10.1.3.2.2">ùêå</ci><ci id="S3.E2.m1.10.10.10.10.10.10.1.3.2.3.cmml" xref="S3.E2.m1.10.10.10.10.10.10.1.3.2.3">ùê¥</ci></apply><apply id="S3.E2.m1.10.10.10.10.10.10.1.3.3.cmml" xref="S3.E2.m1.10.10.10.10.10.10.1.3.3"><ci id="S3.E2.m1.10.10.10.10.10.10.1.3.3.1.cmml" xref="S3.E2.m1.10.10.10.10.10.10.1.3.3.1">Àô</ci><ci id="S3.E2.m1.10.10.10.10.10.10.1.3.3.2.cmml" xref="S3.E2.m1.10.10.10.10.10.10.1.3.3.2">ùúà</ci></apply></apply><apply id="S3.E2.m1.10.10.10.10.10.10.1.4.cmml" xref="S3.E2.m1.10.10.10.10.10.10.1.4"><times id="S3.E2.m1.10.10.10.10.10.10.1.4.1.cmml" xref="S3.E2.m1.10.10.10.10.10.10.1.4.1"></times><apply id="S3.E2.m1.10.10.10.10.10.10.1.4.2.cmml" xref="S3.E2.m1.10.10.10.10.10.10.1.4.2"><csymbol cd="ambiguous" id="S3.E2.m1.10.10.10.10.10.10.1.4.2.1.cmml" xref="S3.E2.m1.10.10.10.10.10.10.1.4.2">subscript</csymbol><ci id="S3.E2.m1.10.10.10.10.10.10.1.4.2.2.cmml" xref="S3.E2.m1.10.10.10.10.10.10.1.4.2.2">ùêÇ</ci><ci id="S3.E2.m1.10.10.10.10.10.10.1.4.2.3.cmml" xref="S3.E2.m1.10.10.10.10.10.10.1.4.2.3">ùê¥</ci></apply><ci id="S3.E2.m1.10.10.10.10.10.10.1.1.cmml" xref="S3.E2.m1.10.10.10.10.10.10.1.1">ùúà</ci><ci id="S3.E2.m1.10.10.10.10.10.10.1.4.4.cmml" xref="S3.E2.m1.10.10.10.10.10.10.1.4.4">ùúà</ci></apply></apply></apply><ci id="S3.E2.m1.11.11.11.11.11.11.1a.cmml" xref="S3.E2.m1.11.11.11.11.11.11.1"><mtext mathsize="70%" id="S3.E2.m1.11.11.11.11.11.11.1.cmml" xref="S3.E2.m1.11.11.11.11.11.11.1">Added‚ÄÖmass</mtext></ci></apply><apply id="S3.E2.m1.21.21.1.1.1.3.5.cmml" xref="S3.E2.m1.11.11.11.11.11.12.1"><csymbol cd="ambiguous" id="S3.E2.m1.21.21.1.1.1.3.5.1.cmml" xref="S3.E2.m1.11.11.11.11.11.12.1">subscript</csymbol><apply id="S3.E2.m1.13.13.13.2.2.2.cmml" xref="S3.E2.m1.13.13.13.2.2.2"><ci id="S3.E2.m1.13.13.13.2.2.2.2.cmml" xref="S3.E2.m1.13.13.13.2.2.2.2">‚èü</ci><apply id="S3.E2.m1.13.13.13.2.2.2.1.cmml" xref="S3.E2.m1.13.13.13.2.2.2.1"><times id="S3.E2.m1.13.13.13.2.2.2.1.2.cmml" xref="S3.E2.m1.13.13.13.2.2.2.1.2"></times><ci id="S3.E2.m1.13.13.13.2.2.2.1.3.cmml" xref="S3.E2.m1.13.13.13.2.2.2.1.3">ùêÉ</ci><ci id="S3.E2.m1.13.13.13.2.2.2.1.1.cmml" xref="S3.E2.m1.13.13.13.2.2.2.1.1">ùúà</ci><ci id="S3.E2.m1.13.13.13.2.2.2.1.5.cmml" xref="S3.E2.m1.13.13.13.2.2.2.1.5">ùúà</ci></apply></apply><ci id="S3.E2.m1.14.14.14.3.3.3.1a.cmml" xref="S3.E2.m1.14.14.14.3.3.3.1"><mtext mathsize="70%" id="S3.E2.m1.14.14.14.3.3.3.1.cmml" xref="S3.E2.m1.14.14.14.3.3.3.1">Drag¬†</mtext></ci></apply><apply id="S3.E2.m1.21.21.1.1.1.3.6.cmml" xref="S3.E2.m1.11.11.11.11.11.12.1"><times id="S3.E2.m1.21.21.1.1.1.3.6.1.cmml" xref="S3.E2.m1.11.11.11.11.11.12.1"></times><ci id="S3.E2.m1.16.16.16.5.5.5.cmml" xref="S3.E2.m1.16.16.16.5.5.5">ùê†</ci><ci id="S3.E2.m1.18.18.18.7.7.7.cmml" xref="S3.E2.m1.18.18.18.7.7.7">ùúÇ</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.22c">\begin{multlined}\mathbf{M}_{RB}\dot{\mathbf{\nu}}=\tau-\underbrace{\mathbf{C}_{RB}(\mathbf{\nu})\mathbf{\nu}}_{\text{Coriolis \hskip 1.0pt term}}-\underbrace{\mathbf{M}_{A}\dot{\mathbf{\nu}}-\mathbf{C}_{A}(\mathbf{\nu})\mathbf{\nu}}_{\text{Added\hskip 2.0ptmass}}\\
-\underbrace{\mathbf{D}(\mathbf{\nu})\mathbf{{\mathbf{\nu}}}}_{\text{Drag }}-\mathbf{g}(\mathbf{\eta}).\end{multlined}\mathbf{M}_{RB}\dot{\mathbf{\nu}}=\tau-\underbrace{\mathbf{C}_{RB}(\mathbf{\nu})\mathbf{\nu}}_{\text{Coriolis \hskip 1.0pt term}}-\underbrace{\mathbf{M}_{A}\dot{\mathbf{\nu}}-\mathbf{C}_{A}(\mathbf{\nu})\mathbf{\nu}}_{\text{Added\hskip 2.0ptmass}}\\
-\underbrace{\mathbf{D}(\mathbf{\nu})\mathbf{{\mathbf{\nu}}}}_{\text{Drag }}-\mathbf{g}(\mathbf{\eta}).</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p id="S3.SS2.p2.15" class="ltx_p">The vehicle‚Äôs pose, <math id="S3.SS2.p2.1.m1.6" class="ltx_Math" alttext="\mathbf{\eta}=[x,y,z,\phi,\theta,\psi]^{T}" display="inline"><semantics id="S3.SS2.p2.1.m1.6a"><mrow id="S3.SS2.p2.1.m1.6.7" xref="S3.SS2.p2.1.m1.6.7.cmml"><mi id="S3.SS2.p2.1.m1.6.7.2" xref="S3.SS2.p2.1.m1.6.7.2.cmml">Œ∑</mi><mo id="S3.SS2.p2.1.m1.6.7.1" xref="S3.SS2.p2.1.m1.6.7.1.cmml">=</mo><msup id="S3.SS2.p2.1.m1.6.7.3" xref="S3.SS2.p2.1.m1.6.7.3.cmml"><mrow id="S3.SS2.p2.1.m1.6.7.3.2.2" xref="S3.SS2.p2.1.m1.6.7.3.2.1.cmml"><mo stretchy="false" id="S3.SS2.p2.1.m1.6.7.3.2.2.1" xref="S3.SS2.p2.1.m1.6.7.3.2.1.cmml">[</mo><mi id="S3.SS2.p2.1.m1.1.1" xref="S3.SS2.p2.1.m1.1.1.cmml">x</mi><mo id="S3.SS2.p2.1.m1.6.7.3.2.2.2" xref="S3.SS2.p2.1.m1.6.7.3.2.1.cmml">,</mo><mi id="S3.SS2.p2.1.m1.2.2" xref="S3.SS2.p2.1.m1.2.2.cmml">y</mi><mo id="S3.SS2.p2.1.m1.6.7.3.2.2.3" xref="S3.SS2.p2.1.m1.6.7.3.2.1.cmml">,</mo><mi id="S3.SS2.p2.1.m1.3.3" xref="S3.SS2.p2.1.m1.3.3.cmml">z</mi><mo id="S3.SS2.p2.1.m1.6.7.3.2.2.4" xref="S3.SS2.p2.1.m1.6.7.3.2.1.cmml">,</mo><mi id="S3.SS2.p2.1.m1.4.4" xref="S3.SS2.p2.1.m1.4.4.cmml">œï</mi><mo id="S3.SS2.p2.1.m1.6.7.3.2.2.5" xref="S3.SS2.p2.1.m1.6.7.3.2.1.cmml">,</mo><mi id="S3.SS2.p2.1.m1.5.5" xref="S3.SS2.p2.1.m1.5.5.cmml">Œ∏</mi><mo id="S3.SS2.p2.1.m1.6.7.3.2.2.6" xref="S3.SS2.p2.1.m1.6.7.3.2.1.cmml">,</mo><mi id="S3.SS2.p2.1.m1.6.6" xref="S3.SS2.p2.1.m1.6.6.cmml">œà</mi><mo stretchy="false" id="S3.SS2.p2.1.m1.6.7.3.2.2.7" xref="S3.SS2.p2.1.m1.6.7.3.2.1.cmml">]</mo></mrow><mi id="S3.SS2.p2.1.m1.6.7.3.3" xref="S3.SS2.p2.1.m1.6.7.3.3.cmml">T</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.1.m1.6b"><apply id="S3.SS2.p2.1.m1.6.7.cmml" xref="S3.SS2.p2.1.m1.6.7"><eq id="S3.SS2.p2.1.m1.6.7.1.cmml" xref="S3.SS2.p2.1.m1.6.7.1"></eq><ci id="S3.SS2.p2.1.m1.6.7.2.cmml" xref="S3.SS2.p2.1.m1.6.7.2">ùúÇ</ci><apply id="S3.SS2.p2.1.m1.6.7.3.cmml" xref="S3.SS2.p2.1.m1.6.7.3"><csymbol cd="ambiguous" id="S3.SS2.p2.1.m1.6.7.3.1.cmml" xref="S3.SS2.p2.1.m1.6.7.3">superscript</csymbol><list id="S3.SS2.p2.1.m1.6.7.3.2.1.cmml" xref="S3.SS2.p2.1.m1.6.7.3.2.2"><ci id="S3.SS2.p2.1.m1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1">ùë•</ci><ci id="S3.SS2.p2.1.m1.2.2.cmml" xref="S3.SS2.p2.1.m1.2.2">ùë¶</ci><ci id="S3.SS2.p2.1.m1.3.3.cmml" xref="S3.SS2.p2.1.m1.3.3">ùëß</ci><ci id="S3.SS2.p2.1.m1.4.4.cmml" xref="S3.SS2.p2.1.m1.4.4">italic-œï</ci><ci id="S3.SS2.p2.1.m1.5.5.cmml" xref="S3.SS2.p2.1.m1.5.5">ùúÉ</ci><ci id="S3.SS2.p2.1.m1.6.6.cmml" xref="S3.SS2.p2.1.m1.6.6">ùúì</ci></list><ci id="S3.SS2.p2.1.m1.6.7.3.3.cmml" xref="S3.SS2.p2.1.m1.6.7.3.3">ùëá</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.1.m1.6c">\mathbf{\eta}=[x,y,z,\phi,\theta,\psi]^{T}</annotation></semantics></math>, is described by a six-dimensional column vector where <math id="S3.SS2.p2.2.m2.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S3.SS2.p2.2.m2.1a"><mi id="S3.SS2.p2.2.m2.1.1" xref="S3.SS2.p2.2.m2.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.2.m2.1b"><ci id="S3.SS2.p2.2.m2.1.1.cmml" xref="S3.SS2.p2.2.m2.1.1">ùë•</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.2.m2.1c">x</annotation></semantics></math>, <math id="S3.SS2.p2.3.m3.1" class="ltx_Math" alttext="y" display="inline"><semantics id="S3.SS2.p2.3.m3.1a"><mi id="S3.SS2.p2.3.m3.1.1" xref="S3.SS2.p2.3.m3.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.3.m3.1b"><ci id="S3.SS2.p2.3.m3.1.1.cmml" xref="S3.SS2.p2.3.m3.1.1">ùë¶</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.3.m3.1c">y</annotation></semantics></math>, and <math id="S3.SS2.p2.4.m4.1" class="ltx_Math" alttext="z" display="inline"><semantics id="S3.SS2.p2.4.m4.1a"><mi id="S3.SS2.p2.4.m4.1.1" xref="S3.SS2.p2.4.m4.1.1.cmml">z</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.4.m4.1b"><ci id="S3.SS2.p2.4.m4.1.1.cmml" xref="S3.SS2.p2.4.m4.1.1">ùëß</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.4.m4.1c">z</annotation></semantics></math> denote the vehicle‚Äôs position in the  <a href="#id11.11.id11"><span href="#id11.11.id11" title="North-East-Down" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long">North-East-Down</span></span></a> (<a href="#id11.11.id11"><abbr href="#id11.11.id11" title="North-East-Down" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">NED</span></abbr></a>) frame, while <math id="S3.SS2.p2.5.m5.1" class="ltx_Math" alttext="\phi" display="inline"><semantics id="S3.SS2.p2.5.m5.1a"><mi id="S3.SS2.p2.5.m5.1.1" xref="S3.SS2.p2.5.m5.1.1.cmml">œï</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.5.m5.1b"><ci id="S3.SS2.p2.5.m5.1.1.cmml" xref="S3.SS2.p2.5.m5.1.1">italic-œï</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.5.m5.1c">\phi</annotation></semantics></math>, <math id="S3.SS2.p2.6.m6.1" class="ltx_Math" alttext="\theta" display="inline"><semantics id="S3.SS2.p2.6.m6.1a"><mi id="S3.SS2.p2.6.m6.1.1" xref="S3.SS2.p2.6.m6.1.1.cmml">Œ∏</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.6.m6.1b"><ci id="S3.SS2.p2.6.m6.1.1.cmml" xref="S3.SS2.p2.6.m6.1.1">ùúÉ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.6.m6.1c">\theta</annotation></semantics></math>, and <math id="S3.SS2.p2.7.m7.1" class="ltx_Math" alttext="\psi" display="inline"><semantics id="S3.SS2.p2.7.m7.1a"><mi id="S3.SS2.p2.7.m7.1.1" xref="S3.SS2.p2.7.m7.1.1.cmml">œà</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.7.m7.1b"><ci id="S3.SS2.p2.7.m7.1.1.cmml" xref="S3.SS2.p2.7.m7.1.1">ùúì</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.7.m7.1c">\psi</annotation></semantics></math> represent its roll, pitch, and yaw angles, respectively (see Fig. <a href="#S3.F3" title="Figure 3 ‚Ä£ III-B Underwater physics ‚Ä£ III UNav-Sim software architecture ‚Ä£ UNav-Sim: A Visually Realistic Underwater Robotics Simulator and Synthetic Data-generation Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>).
The linear and angular velocity vector in the body-fixed frame is denoted as <math id="S3.SS2.p2.8.m8.6" class="ltx_Math" alttext="\mathbf{\nu}=[u,v,w,p,q,r]^{T}" display="inline"><semantics id="S3.SS2.p2.8.m8.6a"><mrow id="S3.SS2.p2.8.m8.6.7" xref="S3.SS2.p2.8.m8.6.7.cmml"><mi id="S3.SS2.p2.8.m8.6.7.2" xref="S3.SS2.p2.8.m8.6.7.2.cmml">ŒΩ</mi><mo id="S3.SS2.p2.8.m8.6.7.1" xref="S3.SS2.p2.8.m8.6.7.1.cmml">=</mo><msup id="S3.SS2.p2.8.m8.6.7.3" xref="S3.SS2.p2.8.m8.6.7.3.cmml"><mrow id="S3.SS2.p2.8.m8.6.7.3.2.2" xref="S3.SS2.p2.8.m8.6.7.3.2.1.cmml"><mo stretchy="false" id="S3.SS2.p2.8.m8.6.7.3.2.2.1" xref="S3.SS2.p2.8.m8.6.7.3.2.1.cmml">[</mo><mi id="S3.SS2.p2.8.m8.1.1" xref="S3.SS2.p2.8.m8.1.1.cmml">u</mi><mo id="S3.SS2.p2.8.m8.6.7.3.2.2.2" xref="S3.SS2.p2.8.m8.6.7.3.2.1.cmml">,</mo><mi id="S3.SS2.p2.8.m8.2.2" xref="S3.SS2.p2.8.m8.2.2.cmml">v</mi><mo id="S3.SS2.p2.8.m8.6.7.3.2.2.3" xref="S3.SS2.p2.8.m8.6.7.3.2.1.cmml">,</mo><mi id="S3.SS2.p2.8.m8.3.3" xref="S3.SS2.p2.8.m8.3.3.cmml">w</mi><mo id="S3.SS2.p2.8.m8.6.7.3.2.2.4" xref="S3.SS2.p2.8.m8.6.7.3.2.1.cmml">,</mo><mi id="S3.SS2.p2.8.m8.4.4" xref="S3.SS2.p2.8.m8.4.4.cmml">p</mi><mo id="S3.SS2.p2.8.m8.6.7.3.2.2.5" xref="S3.SS2.p2.8.m8.6.7.3.2.1.cmml">,</mo><mi id="S3.SS2.p2.8.m8.5.5" xref="S3.SS2.p2.8.m8.5.5.cmml">q</mi><mo id="S3.SS2.p2.8.m8.6.7.3.2.2.6" xref="S3.SS2.p2.8.m8.6.7.3.2.1.cmml">,</mo><mi id="S3.SS2.p2.8.m8.6.6" xref="S3.SS2.p2.8.m8.6.6.cmml">r</mi><mo stretchy="false" id="S3.SS2.p2.8.m8.6.7.3.2.2.7" xref="S3.SS2.p2.8.m8.6.7.3.2.1.cmml">]</mo></mrow><mi id="S3.SS2.p2.8.m8.6.7.3.3" xref="S3.SS2.p2.8.m8.6.7.3.3.cmml">T</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.8.m8.6b"><apply id="S3.SS2.p2.8.m8.6.7.cmml" xref="S3.SS2.p2.8.m8.6.7"><eq id="S3.SS2.p2.8.m8.6.7.1.cmml" xref="S3.SS2.p2.8.m8.6.7.1"></eq><ci id="S3.SS2.p2.8.m8.6.7.2.cmml" xref="S3.SS2.p2.8.m8.6.7.2">ùúà</ci><apply id="S3.SS2.p2.8.m8.6.7.3.cmml" xref="S3.SS2.p2.8.m8.6.7.3"><csymbol cd="ambiguous" id="S3.SS2.p2.8.m8.6.7.3.1.cmml" xref="S3.SS2.p2.8.m8.6.7.3">superscript</csymbol><list id="S3.SS2.p2.8.m8.6.7.3.2.1.cmml" xref="S3.SS2.p2.8.m8.6.7.3.2.2"><ci id="S3.SS2.p2.8.m8.1.1.cmml" xref="S3.SS2.p2.8.m8.1.1">ùë¢</ci><ci id="S3.SS2.p2.8.m8.2.2.cmml" xref="S3.SS2.p2.8.m8.2.2">ùë£</ci><ci id="S3.SS2.p2.8.m8.3.3.cmml" xref="S3.SS2.p2.8.m8.3.3">ùë§</ci><ci id="S3.SS2.p2.8.m8.4.4.cmml" xref="S3.SS2.p2.8.m8.4.4">ùëù</ci><ci id="S3.SS2.p2.8.m8.5.5.cmml" xref="S3.SS2.p2.8.m8.5.5">ùëû</ci><ci id="S3.SS2.p2.8.m8.6.6.cmml" xref="S3.SS2.p2.8.m8.6.6">ùëü</ci></list><ci id="S3.SS2.p2.8.m8.6.7.3.3.cmml" xref="S3.SS2.p2.8.m8.6.7.3.3">ùëá</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.8.m8.6c">\mathbf{\nu}=[u,v,w,p,q,r]^{T}</annotation></semantics></math>. The inertia matrix of the vehicle‚Äôs body is represented by <math id="S3.SS2.p2.9.m9.1" class="ltx_Math" alttext="\mathbf{M}_{RB}" display="inline"><semantics id="S3.SS2.p2.9.m9.1a"><msub id="S3.SS2.p2.9.m9.1.1" xref="S3.SS2.p2.9.m9.1.1.cmml"><mi id="S3.SS2.p2.9.m9.1.1.2" xref="S3.SS2.p2.9.m9.1.1.2.cmml">ùêå</mi><mrow id="S3.SS2.p2.9.m9.1.1.3" xref="S3.SS2.p2.9.m9.1.1.3.cmml"><mi id="S3.SS2.p2.9.m9.1.1.3.2" xref="S3.SS2.p2.9.m9.1.1.3.2.cmml">R</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p2.9.m9.1.1.3.1" xref="S3.SS2.p2.9.m9.1.1.3.1.cmml">‚Äã</mo><mi id="S3.SS2.p2.9.m9.1.1.3.3" xref="S3.SS2.p2.9.m9.1.1.3.3.cmml">B</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.9.m9.1b"><apply id="S3.SS2.p2.9.m9.1.1.cmml" xref="S3.SS2.p2.9.m9.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.9.m9.1.1.1.cmml" xref="S3.SS2.p2.9.m9.1.1">subscript</csymbol><ci id="S3.SS2.p2.9.m9.1.1.2.cmml" xref="S3.SS2.p2.9.m9.1.1.2">ùêå</ci><apply id="S3.SS2.p2.9.m9.1.1.3.cmml" xref="S3.SS2.p2.9.m9.1.1.3"><times id="S3.SS2.p2.9.m9.1.1.3.1.cmml" xref="S3.SS2.p2.9.m9.1.1.3.1"></times><ci id="S3.SS2.p2.9.m9.1.1.3.2.cmml" xref="S3.SS2.p2.9.m9.1.1.3.2">ùëÖ</ci><ci id="S3.SS2.p2.9.m9.1.1.3.3.cmml" xref="S3.SS2.p2.9.m9.1.1.3.3">ùêµ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.9.m9.1c">\mathbf{M}_{RB}</annotation></semantics></math>.
Hydrostatic forces, <math id="S3.SS2.p2.10.m10.1" class="ltx_Math" alttext="g(\eta)" display="inline"><semantics id="S3.SS2.p2.10.m10.1a"><mrow id="S3.SS2.p2.10.m10.1.2" xref="S3.SS2.p2.10.m10.1.2.cmml"><mi id="S3.SS2.p2.10.m10.1.2.2" xref="S3.SS2.p2.10.m10.1.2.2.cmml">g</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p2.10.m10.1.2.1" xref="S3.SS2.p2.10.m10.1.2.1.cmml">‚Äã</mo><mrow id="S3.SS2.p2.10.m10.1.2.3.2" xref="S3.SS2.p2.10.m10.1.2.cmml"><mo stretchy="false" id="S3.SS2.p2.10.m10.1.2.3.2.1" xref="S3.SS2.p2.10.m10.1.2.cmml">(</mo><mi id="S3.SS2.p2.10.m10.1.1" xref="S3.SS2.p2.10.m10.1.1.cmml">Œ∑</mi><mo stretchy="false" id="S3.SS2.p2.10.m10.1.2.3.2.2" xref="S3.SS2.p2.10.m10.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.10.m10.1b"><apply id="S3.SS2.p2.10.m10.1.2.cmml" xref="S3.SS2.p2.10.m10.1.2"><times id="S3.SS2.p2.10.m10.1.2.1.cmml" xref="S3.SS2.p2.10.m10.1.2.1"></times><ci id="S3.SS2.p2.10.m10.1.2.2.cmml" xref="S3.SS2.p2.10.m10.1.2.2">ùëî</ci><ci id="S3.SS2.p2.10.m10.1.1.cmml" xref="S3.SS2.p2.10.m10.1.1">ùúÇ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.10.m10.1c">g(\eta)</annotation></semantics></math>, arise from gravity and buoyancy, along with associated moments and torques.
Hydrodynamic forces arise from the interaction between the vehicle and the surrounding water and can significantly impact the vehicle‚Äôs behavior. These forces include the Coriolis and centripetal forces caused by the rigid body‚Äôs mass, <math id="S3.SS2.p2.11.m11.1" class="ltx_Math" alttext="\mathbf{C}_{RB}(\mathbf{\nu})\mathbf{\nu}" display="inline"><semantics id="S3.SS2.p2.11.m11.1a"><mrow id="S3.SS2.p2.11.m11.1.2" xref="S3.SS2.p2.11.m11.1.2.cmml"><msub id="S3.SS2.p2.11.m11.1.2.2" xref="S3.SS2.p2.11.m11.1.2.2.cmml"><mi id="S3.SS2.p2.11.m11.1.2.2.2" xref="S3.SS2.p2.11.m11.1.2.2.2.cmml">ùêÇ</mi><mrow id="S3.SS2.p2.11.m11.1.2.2.3" xref="S3.SS2.p2.11.m11.1.2.2.3.cmml"><mi id="S3.SS2.p2.11.m11.1.2.2.3.2" xref="S3.SS2.p2.11.m11.1.2.2.3.2.cmml">R</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p2.11.m11.1.2.2.3.1" xref="S3.SS2.p2.11.m11.1.2.2.3.1.cmml">‚Äã</mo><mi id="S3.SS2.p2.11.m11.1.2.2.3.3" xref="S3.SS2.p2.11.m11.1.2.2.3.3.cmml">B</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S3.SS2.p2.11.m11.1.2.1" xref="S3.SS2.p2.11.m11.1.2.1.cmml">‚Äã</mo><mrow id="S3.SS2.p2.11.m11.1.2.3.2" xref="S3.SS2.p2.11.m11.1.2.cmml"><mo stretchy="false" id="S3.SS2.p2.11.m11.1.2.3.2.1" xref="S3.SS2.p2.11.m11.1.2.cmml">(</mo><mi id="S3.SS2.p2.11.m11.1.1" xref="S3.SS2.p2.11.m11.1.1.cmml">ŒΩ</mi><mo stretchy="false" id="S3.SS2.p2.11.m11.1.2.3.2.2" xref="S3.SS2.p2.11.m11.1.2.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S3.SS2.p2.11.m11.1.2.1a" xref="S3.SS2.p2.11.m11.1.2.1.cmml">‚Äã</mo><mi id="S3.SS2.p2.11.m11.1.2.4" xref="S3.SS2.p2.11.m11.1.2.4.cmml">ŒΩ</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.11.m11.1b"><apply id="S3.SS2.p2.11.m11.1.2.cmml" xref="S3.SS2.p2.11.m11.1.2"><times id="S3.SS2.p2.11.m11.1.2.1.cmml" xref="S3.SS2.p2.11.m11.1.2.1"></times><apply id="S3.SS2.p2.11.m11.1.2.2.cmml" xref="S3.SS2.p2.11.m11.1.2.2"><csymbol cd="ambiguous" id="S3.SS2.p2.11.m11.1.2.2.1.cmml" xref="S3.SS2.p2.11.m11.1.2.2">subscript</csymbol><ci id="S3.SS2.p2.11.m11.1.2.2.2.cmml" xref="S3.SS2.p2.11.m11.1.2.2.2">ùêÇ</ci><apply id="S3.SS2.p2.11.m11.1.2.2.3.cmml" xref="S3.SS2.p2.11.m11.1.2.2.3"><times id="S3.SS2.p2.11.m11.1.2.2.3.1.cmml" xref="S3.SS2.p2.11.m11.1.2.2.3.1"></times><ci id="S3.SS2.p2.11.m11.1.2.2.3.2.cmml" xref="S3.SS2.p2.11.m11.1.2.2.3.2">ùëÖ</ci><ci id="S3.SS2.p2.11.m11.1.2.2.3.3.cmml" xref="S3.SS2.p2.11.m11.1.2.2.3.3">ùêµ</ci></apply></apply><ci id="S3.SS2.p2.11.m11.1.1.cmml" xref="S3.SS2.p2.11.m11.1.1">ùúà</ci><ci id="S3.SS2.p2.11.m11.1.2.4.cmml" xref="S3.SS2.p2.11.m11.1.2.4">ùúà</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.11.m11.1c">\mathbf{C}_{RB}(\mathbf{\nu})\mathbf{\nu}</annotation></semantics></math>, the Coriolis forces, <math id="S3.SS2.p2.12.m12.1" class="ltx_Math" alttext="\mathbf{C}_{A}(\mathbf{\nu})" display="inline"><semantics id="S3.SS2.p2.12.m12.1a"><mrow id="S3.SS2.p2.12.m12.1.2" xref="S3.SS2.p2.12.m12.1.2.cmml"><msub id="S3.SS2.p2.12.m12.1.2.2" xref="S3.SS2.p2.12.m12.1.2.2.cmml"><mi id="S3.SS2.p2.12.m12.1.2.2.2" xref="S3.SS2.p2.12.m12.1.2.2.2.cmml">ùêÇ</mi><mi id="S3.SS2.p2.12.m12.1.2.2.3" xref="S3.SS2.p2.12.m12.1.2.2.3.cmml">A</mi></msub><mo lspace="0em" rspace="0em" id="S3.SS2.p2.12.m12.1.2.1" xref="S3.SS2.p2.12.m12.1.2.1.cmml">‚Äã</mo><mrow id="S3.SS2.p2.12.m12.1.2.3.2" xref="S3.SS2.p2.12.m12.1.2.cmml"><mo stretchy="false" id="S3.SS2.p2.12.m12.1.2.3.2.1" xref="S3.SS2.p2.12.m12.1.2.cmml">(</mo><mi id="S3.SS2.p2.12.m12.1.1" xref="S3.SS2.p2.12.m12.1.1.cmml">ŒΩ</mi><mo stretchy="false" id="S3.SS2.p2.12.m12.1.2.3.2.2" xref="S3.SS2.p2.12.m12.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.12.m12.1b"><apply id="S3.SS2.p2.12.m12.1.2.cmml" xref="S3.SS2.p2.12.m12.1.2"><times id="S3.SS2.p2.12.m12.1.2.1.cmml" xref="S3.SS2.p2.12.m12.1.2.1"></times><apply id="S3.SS2.p2.12.m12.1.2.2.cmml" xref="S3.SS2.p2.12.m12.1.2.2"><csymbol cd="ambiguous" id="S3.SS2.p2.12.m12.1.2.2.1.cmml" xref="S3.SS2.p2.12.m12.1.2.2">subscript</csymbol><ci id="S3.SS2.p2.12.m12.1.2.2.2.cmml" xref="S3.SS2.p2.12.m12.1.2.2.2">ùêÇ</ci><ci id="S3.SS2.p2.12.m12.1.2.2.3.cmml" xref="S3.SS2.p2.12.m12.1.2.2.3">ùê¥</ci></apply><ci id="S3.SS2.p2.12.m12.1.1.cmml" xref="S3.SS2.p2.12.m12.1.1">ùúà</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.12.m12.1c">\mathbf{C}_{A}(\mathbf{\nu})</annotation></semantics></math>, and moment of inertia, <math id="S3.SS2.p2.13.m13.1" class="ltx_Math" alttext="\mathbf{M}_{A}" display="inline"><semantics id="S3.SS2.p2.13.m13.1a"><msub id="S3.SS2.p2.13.m13.1.1" xref="S3.SS2.p2.13.m13.1.1.cmml"><mi id="S3.SS2.p2.13.m13.1.1.2" xref="S3.SS2.p2.13.m13.1.1.2.cmml">ùêå</mi><mi id="S3.SS2.p2.13.m13.1.1.3" xref="S3.SS2.p2.13.m13.1.1.3.cmml">A</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.13.m13.1b"><apply id="S3.SS2.p2.13.m13.1.1.cmml" xref="S3.SS2.p2.13.m13.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.13.m13.1.1.1.cmml" xref="S3.SS2.p2.13.m13.1.1">subscript</csymbol><ci id="S3.SS2.p2.13.m13.1.1.2.cmml" xref="S3.SS2.p2.13.m13.1.1.2">ùêå</ci><ci id="S3.SS2.p2.13.m13.1.1.3.cmml" xref="S3.SS2.p2.13.m13.1.1.3">ùê¥</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.13.m13.1c">\mathbf{M}_{A}</annotation></semantics></math>, arising from the added mass, and linear and quadratic damping effects, <math id="S3.SS2.p2.14.m14.1" class="ltx_Math" alttext="\mathbf{D}(\mathbf{\nu})\mathbf{{\nu}}" display="inline"><semantics id="S3.SS2.p2.14.m14.1a"><mrow id="S3.SS2.p2.14.m14.1.2" xref="S3.SS2.p2.14.m14.1.2.cmml"><mi id="S3.SS2.p2.14.m14.1.2.2" xref="S3.SS2.p2.14.m14.1.2.2.cmml">ùêÉ</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p2.14.m14.1.2.1" xref="S3.SS2.p2.14.m14.1.2.1.cmml">‚Äã</mo><mrow id="S3.SS2.p2.14.m14.1.2.3.2" xref="S3.SS2.p2.14.m14.1.2.cmml"><mo stretchy="false" id="S3.SS2.p2.14.m14.1.2.3.2.1" xref="S3.SS2.p2.14.m14.1.2.cmml">(</mo><mi id="S3.SS2.p2.14.m14.1.1" xref="S3.SS2.p2.14.m14.1.1.cmml">ŒΩ</mi><mo stretchy="false" id="S3.SS2.p2.14.m14.1.2.3.2.2" xref="S3.SS2.p2.14.m14.1.2.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S3.SS2.p2.14.m14.1.2.1a" xref="S3.SS2.p2.14.m14.1.2.1.cmml">‚Äã</mo><mi id="S3.SS2.p2.14.m14.1.2.4" xref="S3.SS2.p2.14.m14.1.2.4.cmml">ŒΩ</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.14.m14.1b"><apply id="S3.SS2.p2.14.m14.1.2.cmml" xref="S3.SS2.p2.14.m14.1.2"><times id="S3.SS2.p2.14.m14.1.2.1.cmml" xref="S3.SS2.p2.14.m14.1.2.1"></times><ci id="S3.SS2.p2.14.m14.1.2.2.cmml" xref="S3.SS2.p2.14.m14.1.2.2">ùêÉ</ci><ci id="S3.SS2.p2.14.m14.1.1.cmml" xref="S3.SS2.p2.14.m14.1.1">ùúà</ci><ci id="S3.SS2.p2.14.m14.1.2.4.cmml" xref="S3.SS2.p2.14.m14.1.2.4">ùúà</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.14.m14.1c">\mathbf{D}(\mathbf{\nu})\mathbf{{\nu}}</annotation></semantics></math>.
External forces, <math id="S3.SS2.p2.15.m15.1" class="ltx_Math" alttext="\tau" display="inline"><semantics id="S3.SS2.p2.15.m15.1a"><mi id="S3.SS2.p2.15.m15.1.1" xref="S3.SS2.p2.15.m15.1.1.cmml">œÑ</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.15.m15.1b"><ci id="S3.SS2.p2.15.m15.1.1.cmml" xref="S3.SS2.p2.15.m15.1.1">ùúè</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.15.m15.1c">\tau</annotation></semantics></math>, include the forces exerted on the <a href="#id1.1.id1"><abbr href="#id1.1.id1" title="remotely operated vehicle" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">ROV</span></abbr></a> by its thrusters, as well as the disturbances, caused by the surrounding water flow. Multiple disturbance models, such as constant value, sinusoidal, and a combination of sine waves are implemented.</p>
</div>
<div id="S3.SS2.p3" class="ltx_para">
<p id="S3.SS2.p3.1" class="ltx_p">To efficiently solve the equations of motion presented above, AirSim‚Äôs high-frequency physics engine is utilized with a computational frequency of <math id="S3.SS2.p3.1.m1.1" class="ltx_Math" alttext="1000\textrm{Hz}" display="inline"><semantics id="S3.SS2.p3.1.m1.1a"><mrow id="S3.SS2.p3.1.m1.1.1" xref="S3.SS2.p3.1.m1.1.1.cmml"><mn id="S3.SS2.p3.1.m1.1.1.2" xref="S3.SS2.p3.1.m1.1.1.2.cmml">1000</mn><mo lspace="0em" rspace="0em" id="S3.SS2.p3.1.m1.1.1.1" xref="S3.SS2.p3.1.m1.1.1.1.cmml">‚Äã</mo><mtext id="S3.SS2.p3.1.m1.1.1.3" xref="S3.SS2.p3.1.m1.1.1.3a.cmml">Hz</mtext></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.1.m1.1b"><apply id="S3.SS2.p3.1.m1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1"><times id="S3.SS2.p3.1.m1.1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1.1"></times><cn type="integer" id="S3.SS2.p3.1.m1.1.1.2.cmml" xref="S3.SS2.p3.1.m1.1.1.2">1000</cn><ci id="S3.SS2.p3.1.m1.1.1.3a.cmml" xref="S3.SS2.p3.1.m1.1.1.3"><mtext id="S3.SS2.p3.1.m1.1.1.3.cmml" xref="S3.SS2.p3.1.m1.1.1.3">Hz</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.1.m1.1c">1000\textrm{Hz}</annotation></semantics></math>. The engine uses the velocity verlet algorithm for numerical integration due to its computational benefits.</p>
</div>
<figure id="S3.F3" class="ltx_figure"><img src="/html/2310.11927/assets/x3.png" id="S3.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="330" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>ROV model defined in UNav-Sim: A force <math id="S3.F3.4.m1.1" class="ltx_Math" alttext="\tau_{i}" display="inline"><semantics id="S3.F3.4.m1.1b"><msub id="S3.F3.4.m1.1.1" xref="S3.F3.4.m1.1.1.cmml"><mi id="S3.F3.4.m1.1.1.2" xref="S3.F3.4.m1.1.1.2.cmml">œÑ</mi><mi id="S3.F3.4.m1.1.1.3" xref="S3.F3.4.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.F3.4.m1.1c"><apply id="S3.F3.4.m1.1.1.cmml" xref="S3.F3.4.m1.1.1"><csymbol cd="ambiguous" id="S3.F3.4.m1.1.1.1.cmml" xref="S3.F3.4.m1.1.1">subscript</csymbol><ci id="S3.F3.4.m1.1.1.2.cmml" xref="S3.F3.4.m1.1.1.2">ùúè</ci><ci id="S3.F3.4.m1.1.1.3.cmml" xref="S3.F3.4.m1.1.1.3">ùëñ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.4.m1.1d">\tau_{i}</annotation></semantics></math> is applied at each thruster location <math id="S3.F3.5.m2.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S3.F3.5.m2.1b"><mi id="S3.F3.5.m2.1.1" xref="S3.F3.5.m2.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.F3.5.m2.1c"><ci id="S3.F3.5.m2.1.1.cmml" xref="S3.F3.5.m2.1.1">ùëñ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.5.m2.1d">i</annotation></semantics></math>, where the thruster orientation is defined by a vector <math id="S3.F3.6.m3.1" class="ltx_Math" alttext="\textbf{n}_{i}" display="inline"><semantics id="S3.F3.6.m3.1b"><msub id="S3.F3.6.m3.1.1" xref="S3.F3.6.m3.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S3.F3.6.m3.1.1.2" xref="S3.F3.6.m3.1.1.2a.cmml">n</mtext><mi id="S3.F3.6.m3.1.1.3" xref="S3.F3.6.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.F3.6.m3.1c"><apply id="S3.F3.6.m3.1.1.cmml" xref="S3.F3.6.m3.1.1"><csymbol cd="ambiguous" id="S3.F3.6.m3.1.1.1.cmml" xref="S3.F3.6.m3.1.1">subscript</csymbol><ci id="S3.F3.6.m3.1.1.2a.cmml" xref="S3.F3.6.m3.1.1.2"><mtext class="ltx_mathvariant_bold" id="S3.F3.6.m3.1.1.2.cmml" xref="S3.F3.6.m3.1.1.2">n</mtext></ci><ci id="S3.F3.6.m3.1.1.3.cmml" xref="S3.F3.6.m3.1.1.3">ùëñ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.6.m3.1d">\textbf{n}_{i}</annotation></semantics></math>.</figcaption>
</figure>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS3.5.1.1" class="ltx_text">III-C</span> </span><span id="S3.SS3.6.2" class="ltx_text ltx_font_italic">ROV model </span>
</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.7" class="ltx_p">The <a href="#id1.1.id1"><abbr href="#id1.1.id1" title="remotely operated vehicle" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">ROV</span></abbr></a> is represented as a rigid body that is manipulated by an arbitrary number of actuators, <math id="S3.SS3.p1.1.m1.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S3.SS3.p1.1.m1.1a"><mi id="S3.SS3.p1.1.m1.1.1" xref="S3.SS3.p1.1.m1.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.1.m1.1b"><ci id="S3.SS3.p1.1.m1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1">ùëÅ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.1.m1.1c">N</annotation></semantics></math>. These actuators are located at user-defined vertices of the vehicle, with corresponding normals and positions denoted by <math id="S3.SS3.p1.2.m2.1" class="ltx_Math" alttext="n_{i}" display="inline"><semantics id="S3.SS3.p1.2.m2.1a"><msub id="S3.SS3.p1.2.m2.1.1" xref="S3.SS3.p1.2.m2.1.1.cmml"><mi id="S3.SS3.p1.2.m2.1.1.2" xref="S3.SS3.p1.2.m2.1.1.2.cmml">n</mi><mi id="S3.SS3.p1.2.m2.1.1.3" xref="S3.SS3.p1.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.2.m2.1b"><apply id="S3.SS3.p1.2.m2.1.1.cmml" xref="S3.SS3.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.2.m2.1.1.1.cmml" xref="S3.SS3.p1.2.m2.1.1">subscript</csymbol><ci id="S3.SS3.p1.2.m2.1.1.2.cmml" xref="S3.SS3.p1.2.m2.1.1.2">ùëõ</ci><ci id="S3.SS3.p1.2.m2.1.1.3.cmml" xref="S3.SS3.p1.2.m2.1.1.3">ùëñ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.2.m2.1c">n_{i}</annotation></semantics></math> and <math id="S3.SS3.p1.3.m3.1" class="ltx_Math" alttext="r_{i}" display="inline"><semantics id="S3.SS3.p1.3.m3.1a"><msub id="S3.SS3.p1.3.m3.1.1" xref="S3.SS3.p1.3.m3.1.1.cmml"><mi id="S3.SS3.p1.3.m3.1.1.2" xref="S3.SS3.p1.3.m3.1.1.2.cmml">r</mi><mi id="S3.SS3.p1.3.m3.1.1.3" xref="S3.SS3.p1.3.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.3.m3.1b"><apply id="S3.SS3.p1.3.m3.1.1.cmml" xref="S3.SS3.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.3.m3.1.1.1.cmml" xref="S3.SS3.p1.3.m3.1.1">subscript</csymbol><ci id="S3.SS3.p1.3.m3.1.1.2.cmml" xref="S3.SS3.p1.3.m3.1.1.2">ùëü</ci><ci id="S3.SS3.p1.3.m3.1.1.3.cmml" xref="S3.SS3.p1.3.m3.1.1.3">ùëñ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.3.m3.1c">r_{i}</annotation></semantics></math>, respectively, where <math id="S3.SS3.p1.4.m4.3" class="ltx_Math" alttext="i\in\{1,\dots,N\}" display="inline"><semantics id="S3.SS3.p1.4.m4.3a"><mrow id="S3.SS3.p1.4.m4.3.4" xref="S3.SS3.p1.4.m4.3.4.cmml"><mi id="S3.SS3.p1.4.m4.3.4.2" xref="S3.SS3.p1.4.m4.3.4.2.cmml">i</mi><mo id="S3.SS3.p1.4.m4.3.4.1" xref="S3.SS3.p1.4.m4.3.4.1.cmml">‚àà</mo><mrow id="S3.SS3.p1.4.m4.3.4.3.2" xref="S3.SS3.p1.4.m4.3.4.3.1.cmml"><mo stretchy="false" id="S3.SS3.p1.4.m4.3.4.3.2.1" xref="S3.SS3.p1.4.m4.3.4.3.1.cmml">{</mo><mn id="S3.SS3.p1.4.m4.1.1" xref="S3.SS3.p1.4.m4.1.1.cmml">1</mn><mo id="S3.SS3.p1.4.m4.3.4.3.2.2" xref="S3.SS3.p1.4.m4.3.4.3.1.cmml">,</mo><mi mathvariant="normal" id="S3.SS3.p1.4.m4.2.2" xref="S3.SS3.p1.4.m4.2.2.cmml">‚Ä¶</mi><mo id="S3.SS3.p1.4.m4.3.4.3.2.3" xref="S3.SS3.p1.4.m4.3.4.3.1.cmml">,</mo><mi id="S3.SS3.p1.4.m4.3.3" xref="S3.SS3.p1.4.m4.3.3.cmml">N</mi><mo stretchy="false" id="S3.SS3.p1.4.m4.3.4.3.2.4" xref="S3.SS3.p1.4.m4.3.4.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.4.m4.3b"><apply id="S3.SS3.p1.4.m4.3.4.cmml" xref="S3.SS3.p1.4.m4.3.4"><in id="S3.SS3.p1.4.m4.3.4.1.cmml" xref="S3.SS3.p1.4.m4.3.4.1"></in><ci id="S3.SS3.p1.4.m4.3.4.2.cmml" xref="S3.SS3.p1.4.m4.3.4.2">ùëñ</ci><set id="S3.SS3.p1.4.m4.3.4.3.1.cmml" xref="S3.SS3.p1.4.m4.3.4.3.2"><cn type="integer" id="S3.SS3.p1.4.m4.1.1.cmml" xref="S3.SS3.p1.4.m4.1.1">1</cn><ci id="S3.SS3.p1.4.m4.2.2.cmml" xref="S3.SS3.p1.4.m4.2.2">‚Ä¶</ci><ci id="S3.SS3.p1.4.m4.3.3.cmml" xref="S3.SS3.p1.4.m4.3.3">ùëÅ</ci></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.4.m4.3c">i\in\{1,\dots,N\}</annotation></semantics></math> is the actuator number. At each vertex, the vehicle receives a unitless control input, <math id="S3.SS3.p1.5.m5.2" class="ltx_Math" alttext="u_{i}\in(-1,1)" display="inline"><semantics id="S3.SS3.p1.5.m5.2a"><mrow id="S3.SS3.p1.5.m5.2.2" xref="S3.SS3.p1.5.m5.2.2.cmml"><msub id="S3.SS3.p1.5.m5.2.2.3" xref="S3.SS3.p1.5.m5.2.2.3.cmml"><mi id="S3.SS3.p1.5.m5.2.2.3.2" xref="S3.SS3.p1.5.m5.2.2.3.2.cmml">u</mi><mi id="S3.SS3.p1.5.m5.2.2.3.3" xref="S3.SS3.p1.5.m5.2.2.3.3.cmml">i</mi></msub><mo id="S3.SS3.p1.5.m5.2.2.2" xref="S3.SS3.p1.5.m5.2.2.2.cmml">‚àà</mo><mrow id="S3.SS3.p1.5.m5.2.2.1.1" xref="S3.SS3.p1.5.m5.2.2.1.2.cmml"><mo stretchy="false" id="S3.SS3.p1.5.m5.2.2.1.1.2" xref="S3.SS3.p1.5.m5.2.2.1.2.cmml">(</mo><mrow id="S3.SS3.p1.5.m5.2.2.1.1.1" xref="S3.SS3.p1.5.m5.2.2.1.1.1.cmml"><mo id="S3.SS3.p1.5.m5.2.2.1.1.1a" xref="S3.SS3.p1.5.m5.2.2.1.1.1.cmml">‚àí</mo><mn id="S3.SS3.p1.5.m5.2.2.1.1.1.2" xref="S3.SS3.p1.5.m5.2.2.1.1.1.2.cmml">1</mn></mrow><mo id="S3.SS3.p1.5.m5.2.2.1.1.3" xref="S3.SS3.p1.5.m5.2.2.1.2.cmml">,</mo><mn id="S3.SS3.p1.5.m5.1.1" xref="S3.SS3.p1.5.m5.1.1.cmml">1</mn><mo stretchy="false" id="S3.SS3.p1.5.m5.2.2.1.1.4" xref="S3.SS3.p1.5.m5.2.2.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.5.m5.2b"><apply id="S3.SS3.p1.5.m5.2.2.cmml" xref="S3.SS3.p1.5.m5.2.2"><in id="S3.SS3.p1.5.m5.2.2.2.cmml" xref="S3.SS3.p1.5.m5.2.2.2"></in><apply id="S3.SS3.p1.5.m5.2.2.3.cmml" xref="S3.SS3.p1.5.m5.2.2.3"><csymbol cd="ambiguous" id="S3.SS3.p1.5.m5.2.2.3.1.cmml" xref="S3.SS3.p1.5.m5.2.2.3">subscript</csymbol><ci id="S3.SS3.p1.5.m5.2.2.3.2.cmml" xref="S3.SS3.p1.5.m5.2.2.3.2">ùë¢</ci><ci id="S3.SS3.p1.5.m5.2.2.3.3.cmml" xref="S3.SS3.p1.5.m5.2.2.3.3">ùëñ</ci></apply><interval closure="open" id="S3.SS3.p1.5.m5.2.2.1.2.cmml" xref="S3.SS3.p1.5.m5.2.2.1.1"><apply id="S3.SS3.p1.5.m5.2.2.1.1.1.cmml" xref="S3.SS3.p1.5.m5.2.2.1.1.1"><minus id="S3.SS3.p1.5.m5.2.2.1.1.1.1.cmml" xref="S3.SS3.p1.5.m5.2.2.1.1.1"></minus><cn type="integer" id="S3.SS3.p1.5.m5.2.2.1.1.1.2.cmml" xref="S3.SS3.p1.5.m5.2.2.1.1.1.2">1</cn></apply><cn type="integer" id="S3.SS3.p1.5.m5.1.1.cmml" xref="S3.SS3.p1.5.m5.1.1">1</cn></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.5.m5.2c">u_{i}\in(-1,1)</annotation></semantics></math>. To account for actuator dynamics, a discrete low-pass filter with a time constant of <math id="S3.SS3.p1.6.m6.1" class="ltx_Math" alttext="t_{c}" display="inline"><semantics id="S3.SS3.p1.6.m6.1a"><msub id="S3.SS3.p1.6.m6.1.1" xref="S3.SS3.p1.6.m6.1.1.cmml"><mi id="S3.SS3.p1.6.m6.1.1.2" xref="S3.SS3.p1.6.m6.1.1.2.cmml">t</mi><mi id="S3.SS3.p1.6.m6.1.1.3" xref="S3.SS3.p1.6.m6.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.6.m6.1b"><apply id="S3.SS3.p1.6.m6.1.1.cmml" xref="S3.SS3.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.6.m6.1.1.1.cmml" xref="S3.SS3.p1.6.m6.1.1">subscript</csymbol><ci id="S3.SS3.p1.6.m6.1.1.2.cmml" xref="S3.SS3.p1.6.m6.1.1.2">ùë°</ci><ci id="S3.SS3.p1.6.m6.1.1.3.cmml" xref="S3.SS3.p1.6.m6.1.1.3">ùëê</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.6.m6.1c">t_{c}</annotation></semantics></math> is applied to the control input. The filtered input, denoted as <math id="S3.SS3.p1.7.m7.1" class="ltx_Math" alttext="u_{fi}" display="inline"><semantics id="S3.SS3.p1.7.m7.1a"><msub id="S3.SS3.p1.7.m7.1.1" xref="S3.SS3.p1.7.m7.1.1.cmml"><mi id="S3.SS3.p1.7.m7.1.1.2" xref="S3.SS3.p1.7.m7.1.1.2.cmml">u</mi><mrow id="S3.SS3.p1.7.m7.1.1.3" xref="S3.SS3.p1.7.m7.1.1.3.cmml"><mi id="S3.SS3.p1.7.m7.1.1.3.2" xref="S3.SS3.p1.7.m7.1.1.3.2.cmml">f</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p1.7.m7.1.1.3.1" xref="S3.SS3.p1.7.m7.1.1.3.1.cmml">‚Äã</mo><mi id="S3.SS3.p1.7.m7.1.1.3.3" xref="S3.SS3.p1.7.m7.1.1.3.3.cmml">i</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.7.m7.1b"><apply id="S3.SS3.p1.7.m7.1.1.cmml" xref="S3.SS3.p1.7.m7.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.7.m7.1.1.1.cmml" xref="S3.SS3.p1.7.m7.1.1">subscript</csymbol><ci id="S3.SS3.p1.7.m7.1.1.2.cmml" xref="S3.SS3.p1.7.m7.1.1.2">ùë¢</ci><apply id="S3.SS3.p1.7.m7.1.1.3.cmml" xref="S3.SS3.p1.7.m7.1.1.3"><times id="S3.SS3.p1.7.m7.1.1.3.1.cmml" xref="S3.SS3.p1.7.m7.1.1.3.1"></times><ci id="S3.SS3.p1.7.m7.1.1.3.2.cmml" xref="S3.SS3.p1.7.m7.1.1.3.2">ùëì</ci><ci id="S3.SS3.p1.7.m7.1.1.3.3.cmml" xref="S3.SS3.p1.7.m7.1.1.3.3">ùëñ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.7.m7.1c">u_{fi}</annotation></semantics></math>, is then used to calculate the thrust force using the relationship given as <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>,</p>
<table id="S3.E3" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E3.m1.1" class="ltx_Math" alttext="\tau_{i}=C_{T}\rho\omega^{2}_{max}D^{4}u_{fi}," display="block"><semantics id="S3.E3.m1.1a"><mrow id="S3.E3.m1.1.1.1" xref="S3.E3.m1.1.1.1.1.cmml"><mrow id="S3.E3.m1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.cmml"><msub id="S3.E3.m1.1.1.1.1.2" xref="S3.E3.m1.1.1.1.1.2.cmml"><mi id="S3.E3.m1.1.1.1.1.2.2" xref="S3.E3.m1.1.1.1.1.2.2.cmml">œÑ</mi><mi id="S3.E3.m1.1.1.1.1.2.3" xref="S3.E3.m1.1.1.1.1.2.3.cmml">i</mi></msub><mo id="S3.E3.m1.1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.1.cmml">=</mo><mrow id="S3.E3.m1.1.1.1.1.3" xref="S3.E3.m1.1.1.1.1.3.cmml"><msub id="S3.E3.m1.1.1.1.1.3.2" xref="S3.E3.m1.1.1.1.1.3.2.cmml"><mi id="S3.E3.m1.1.1.1.1.3.2.2" xref="S3.E3.m1.1.1.1.1.3.2.2.cmml">C</mi><mi id="S3.E3.m1.1.1.1.1.3.2.3" xref="S3.E3.m1.1.1.1.1.3.2.3.cmml">T</mi></msub><mo lspace="0em" rspace="0em" id="S3.E3.m1.1.1.1.1.3.1" xref="S3.E3.m1.1.1.1.1.3.1.cmml">‚Äã</mo><mi id="S3.E3.m1.1.1.1.1.3.3" xref="S3.E3.m1.1.1.1.1.3.3.cmml">œÅ</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.1.1.1.1.3.1a" xref="S3.E3.m1.1.1.1.1.3.1.cmml">‚Äã</mo><msubsup id="S3.E3.m1.1.1.1.1.3.4" xref="S3.E3.m1.1.1.1.1.3.4.cmml"><mi id="S3.E3.m1.1.1.1.1.3.4.2.2" xref="S3.E3.m1.1.1.1.1.3.4.2.2.cmml">œâ</mi><mrow id="S3.E3.m1.1.1.1.1.3.4.3" xref="S3.E3.m1.1.1.1.1.3.4.3.cmml"><mi id="S3.E3.m1.1.1.1.1.3.4.3.2" xref="S3.E3.m1.1.1.1.1.3.4.3.2.cmml">m</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.1.1.1.1.3.4.3.1" xref="S3.E3.m1.1.1.1.1.3.4.3.1.cmml">‚Äã</mo><mi id="S3.E3.m1.1.1.1.1.3.4.3.3" xref="S3.E3.m1.1.1.1.1.3.4.3.3.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.1.1.1.1.3.4.3.1a" xref="S3.E3.m1.1.1.1.1.3.4.3.1.cmml">‚Äã</mo><mi id="S3.E3.m1.1.1.1.1.3.4.3.4" xref="S3.E3.m1.1.1.1.1.3.4.3.4.cmml">x</mi></mrow><mn id="S3.E3.m1.1.1.1.1.3.4.2.3" xref="S3.E3.m1.1.1.1.1.3.4.2.3.cmml">2</mn></msubsup><mo lspace="0em" rspace="0em" id="S3.E3.m1.1.1.1.1.3.1b" xref="S3.E3.m1.1.1.1.1.3.1.cmml">‚Äã</mo><msup id="S3.E3.m1.1.1.1.1.3.5" xref="S3.E3.m1.1.1.1.1.3.5.cmml"><mi id="S3.E3.m1.1.1.1.1.3.5.2" xref="S3.E3.m1.1.1.1.1.3.5.2.cmml">D</mi><mn id="S3.E3.m1.1.1.1.1.3.5.3" xref="S3.E3.m1.1.1.1.1.3.5.3.cmml">4</mn></msup><mo lspace="0em" rspace="0em" id="S3.E3.m1.1.1.1.1.3.1c" xref="S3.E3.m1.1.1.1.1.3.1.cmml">‚Äã</mo><msub id="S3.E3.m1.1.1.1.1.3.6" xref="S3.E3.m1.1.1.1.1.3.6.cmml"><mi id="S3.E3.m1.1.1.1.1.3.6.2" xref="S3.E3.m1.1.1.1.1.3.6.2.cmml">u</mi><mrow id="S3.E3.m1.1.1.1.1.3.6.3" xref="S3.E3.m1.1.1.1.1.3.6.3.cmml"><mi id="S3.E3.m1.1.1.1.1.3.6.3.2" xref="S3.E3.m1.1.1.1.1.3.6.3.2.cmml">f</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.1.1.1.1.3.6.3.1" xref="S3.E3.m1.1.1.1.1.3.6.3.1.cmml">‚Äã</mo><mi id="S3.E3.m1.1.1.1.1.3.6.3.3" xref="S3.E3.m1.1.1.1.1.3.6.3.3.cmml">i</mi></mrow></msub></mrow></mrow><mo id="S3.E3.m1.1.1.1.2" xref="S3.E3.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E3.m1.1b"><apply id="S3.E3.m1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1"><eq id="S3.E3.m1.1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.1"></eq><apply id="S3.E3.m1.1.1.1.1.2.cmml" xref="S3.E3.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.1.1.2.1.cmml" xref="S3.E3.m1.1.1.1.1.2">subscript</csymbol><ci id="S3.E3.m1.1.1.1.1.2.2.cmml" xref="S3.E3.m1.1.1.1.1.2.2">ùúè</ci><ci id="S3.E3.m1.1.1.1.1.2.3.cmml" xref="S3.E3.m1.1.1.1.1.2.3">ùëñ</ci></apply><apply id="S3.E3.m1.1.1.1.1.3.cmml" xref="S3.E3.m1.1.1.1.1.3"><times id="S3.E3.m1.1.1.1.1.3.1.cmml" xref="S3.E3.m1.1.1.1.1.3.1"></times><apply id="S3.E3.m1.1.1.1.1.3.2.cmml" xref="S3.E3.m1.1.1.1.1.3.2"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.1.1.3.2.1.cmml" xref="S3.E3.m1.1.1.1.1.3.2">subscript</csymbol><ci id="S3.E3.m1.1.1.1.1.3.2.2.cmml" xref="S3.E3.m1.1.1.1.1.3.2.2">ùê∂</ci><ci id="S3.E3.m1.1.1.1.1.3.2.3.cmml" xref="S3.E3.m1.1.1.1.1.3.2.3">ùëá</ci></apply><ci id="S3.E3.m1.1.1.1.1.3.3.cmml" xref="S3.E3.m1.1.1.1.1.3.3">ùúå</ci><apply id="S3.E3.m1.1.1.1.1.3.4.cmml" xref="S3.E3.m1.1.1.1.1.3.4"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.1.1.3.4.1.cmml" xref="S3.E3.m1.1.1.1.1.3.4">subscript</csymbol><apply id="S3.E3.m1.1.1.1.1.3.4.2.cmml" xref="S3.E3.m1.1.1.1.1.3.4"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.1.1.3.4.2.1.cmml" xref="S3.E3.m1.1.1.1.1.3.4">superscript</csymbol><ci id="S3.E3.m1.1.1.1.1.3.4.2.2.cmml" xref="S3.E3.m1.1.1.1.1.3.4.2.2">ùúî</ci><cn type="integer" id="S3.E3.m1.1.1.1.1.3.4.2.3.cmml" xref="S3.E3.m1.1.1.1.1.3.4.2.3">2</cn></apply><apply id="S3.E3.m1.1.1.1.1.3.4.3.cmml" xref="S3.E3.m1.1.1.1.1.3.4.3"><times id="S3.E3.m1.1.1.1.1.3.4.3.1.cmml" xref="S3.E3.m1.1.1.1.1.3.4.3.1"></times><ci id="S3.E3.m1.1.1.1.1.3.4.3.2.cmml" xref="S3.E3.m1.1.1.1.1.3.4.3.2">ùëö</ci><ci id="S3.E3.m1.1.1.1.1.3.4.3.3.cmml" xref="S3.E3.m1.1.1.1.1.3.4.3.3">ùëé</ci><ci id="S3.E3.m1.1.1.1.1.3.4.3.4.cmml" xref="S3.E3.m1.1.1.1.1.3.4.3.4">ùë•</ci></apply></apply><apply id="S3.E3.m1.1.1.1.1.3.5.cmml" xref="S3.E3.m1.1.1.1.1.3.5"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.1.1.3.5.1.cmml" xref="S3.E3.m1.1.1.1.1.3.5">superscript</csymbol><ci id="S3.E3.m1.1.1.1.1.3.5.2.cmml" xref="S3.E3.m1.1.1.1.1.3.5.2">ùê∑</ci><cn type="integer" id="S3.E3.m1.1.1.1.1.3.5.3.cmml" xref="S3.E3.m1.1.1.1.1.3.5.3">4</cn></apply><apply id="S3.E3.m1.1.1.1.1.3.6.cmml" xref="S3.E3.m1.1.1.1.1.3.6"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.1.1.3.6.1.cmml" xref="S3.E3.m1.1.1.1.1.3.6">subscript</csymbol><ci id="S3.E3.m1.1.1.1.1.3.6.2.cmml" xref="S3.E3.m1.1.1.1.1.3.6.2">ùë¢</ci><apply id="S3.E3.m1.1.1.1.1.3.6.3.cmml" xref="S3.E3.m1.1.1.1.1.3.6.3"><times id="S3.E3.m1.1.1.1.1.3.6.3.1.cmml" xref="S3.E3.m1.1.1.1.1.3.6.3.1"></times><ci id="S3.E3.m1.1.1.1.1.3.6.3.2.cmml" xref="S3.E3.m1.1.1.1.1.3.6.3.2">ùëì</ci><ci id="S3.E3.m1.1.1.1.1.3.6.3.3.cmml" xref="S3.E3.m1.1.1.1.1.3.6.3.3">ùëñ</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E3.m1.1c">\tau_{i}=C_{T}\rho\omega^{2}_{max}D^{4}u_{fi},</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<p id="S3.SS3.p1.13" class="ltx_p">where <math id="S3.SS3.p1.8.m1.1" class="ltx_Math" alttext="\tau_{i}" display="inline"><semantics id="S3.SS3.p1.8.m1.1a"><msub id="S3.SS3.p1.8.m1.1.1" xref="S3.SS3.p1.8.m1.1.1.cmml"><mi id="S3.SS3.p1.8.m1.1.1.2" xref="S3.SS3.p1.8.m1.1.1.2.cmml">œÑ</mi><mi id="S3.SS3.p1.8.m1.1.1.3" xref="S3.SS3.p1.8.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.8.m1.1b"><apply id="S3.SS3.p1.8.m1.1.1.cmml" xref="S3.SS3.p1.8.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.8.m1.1.1.1.cmml" xref="S3.SS3.p1.8.m1.1.1">subscript</csymbol><ci id="S3.SS3.p1.8.m1.1.1.2.cmml" xref="S3.SS3.p1.8.m1.1.1.2">ùúè</ci><ci id="S3.SS3.p1.8.m1.1.1.3.cmml" xref="S3.SS3.p1.8.m1.1.1.3">ùëñ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.8.m1.1c">\tau_{i}</annotation></semantics></math> is the thrust force on the <math id="S3.SS3.p1.9.m2.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S3.SS3.p1.9.m2.1a"><mi id="S3.SS3.p1.9.m2.1.1" xref="S3.SS3.p1.9.m2.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.9.m2.1b"><ci id="S3.SS3.p1.9.m2.1.1.cmml" xref="S3.SS3.p1.9.m2.1.1">ùëñ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.9.m2.1c">i</annotation></semantics></math>-th thruster, <math id="S3.SS3.p1.10.m3.1" class="ltx_Math" alttext="C_{T}" display="inline"><semantics id="S3.SS3.p1.10.m3.1a"><msub id="S3.SS3.p1.10.m3.1.1" xref="S3.SS3.p1.10.m3.1.1.cmml"><mi id="S3.SS3.p1.10.m3.1.1.2" xref="S3.SS3.p1.10.m3.1.1.2.cmml">C</mi><mi id="S3.SS3.p1.10.m3.1.1.3" xref="S3.SS3.p1.10.m3.1.1.3.cmml">T</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.10.m3.1b"><apply id="S3.SS3.p1.10.m3.1.1.cmml" xref="S3.SS3.p1.10.m3.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.10.m3.1.1.1.cmml" xref="S3.SS3.p1.10.m3.1.1">subscript</csymbol><ci id="S3.SS3.p1.10.m3.1.1.2.cmml" xref="S3.SS3.p1.10.m3.1.1.2">ùê∂</ci><ci id="S3.SS3.p1.10.m3.1.1.3.cmml" xref="S3.SS3.p1.10.m3.1.1.3">ùëá</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.10.m3.1c">C_{T}</annotation></semantics></math> is the thrust coefficient, <math id="S3.SS3.p1.11.m4.1" class="ltx_Math" alttext="\rho" display="inline"><semantics id="S3.SS3.p1.11.m4.1a"><mi id="S3.SS3.p1.11.m4.1.1" xref="S3.SS3.p1.11.m4.1.1.cmml">œÅ</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.11.m4.1b"><ci id="S3.SS3.p1.11.m4.1.1.cmml" xref="S3.SS3.p1.11.m4.1.1">ùúå</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.11.m4.1c">\rho</annotation></semantics></math> is the density of water, <math id="S3.SS3.p1.12.m5.1" class="ltx_Math" alttext="\omega_{max}" display="inline"><semantics id="S3.SS3.p1.12.m5.1a"><msub id="S3.SS3.p1.12.m5.1.1" xref="S3.SS3.p1.12.m5.1.1.cmml"><mi id="S3.SS3.p1.12.m5.1.1.2" xref="S3.SS3.p1.12.m5.1.1.2.cmml">œâ</mi><mrow id="S3.SS3.p1.12.m5.1.1.3" xref="S3.SS3.p1.12.m5.1.1.3.cmml"><mi id="S3.SS3.p1.12.m5.1.1.3.2" xref="S3.SS3.p1.12.m5.1.1.3.2.cmml">m</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p1.12.m5.1.1.3.1" xref="S3.SS3.p1.12.m5.1.1.3.1.cmml">‚Äã</mo><mi id="S3.SS3.p1.12.m5.1.1.3.3" xref="S3.SS3.p1.12.m5.1.1.3.3.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p1.12.m5.1.1.3.1a" xref="S3.SS3.p1.12.m5.1.1.3.1.cmml">‚Äã</mo><mi id="S3.SS3.p1.12.m5.1.1.3.4" xref="S3.SS3.p1.12.m5.1.1.3.4.cmml">x</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.12.m5.1b"><apply id="S3.SS3.p1.12.m5.1.1.cmml" xref="S3.SS3.p1.12.m5.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.12.m5.1.1.1.cmml" xref="S3.SS3.p1.12.m5.1.1">subscript</csymbol><ci id="S3.SS3.p1.12.m5.1.1.2.cmml" xref="S3.SS3.p1.12.m5.1.1.2">ùúî</ci><apply id="S3.SS3.p1.12.m5.1.1.3.cmml" xref="S3.SS3.p1.12.m5.1.1.3"><times id="S3.SS3.p1.12.m5.1.1.3.1.cmml" xref="S3.SS3.p1.12.m5.1.1.3.1"></times><ci id="S3.SS3.p1.12.m5.1.1.3.2.cmml" xref="S3.SS3.p1.12.m5.1.1.3.2">ùëö</ci><ci id="S3.SS3.p1.12.m5.1.1.3.3.cmml" xref="S3.SS3.p1.12.m5.1.1.3.3">ùëé</ci><ci id="S3.SS3.p1.12.m5.1.1.3.4.cmml" xref="S3.SS3.p1.12.m5.1.1.3.4">ùë•</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.12.m5.1c">\omega_{max}</annotation></semantics></math> is the maximum thruster rotation speed, and <math id="S3.SS3.p1.13.m6.1" class="ltx_Math" alttext="D" display="inline"><semantics id="S3.SS3.p1.13.m6.1a"><mi id="S3.SS3.p1.13.m6.1.1" xref="S3.SS3.p1.13.m6.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.13.m6.1b"><ci id="S3.SS3.p1.13.m6.1.1.cmml" xref="S3.SS3.p1.13.m6.1.1">ùê∑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.13.m6.1c">D</annotation></semantics></math> is the propeller diameter.
In order to accurately compute the specific rigid motion of the <a href="#id1.1.id1"><abbr href="#id1.1.id1" title="remotely operated vehicle" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">ROV</span></abbr></a>, as described by equations (<a href="#S3.E2" title="In III-B Underwater physics ‚Ä£ III UNav-Sim software architecture ‚Ä£ UNav-Sim: A Visually Realistic Underwater Robotics Simulator and Synthetic Data-generation Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>) and (<a href="#S3.E3" title="In III-C ROV model ‚Ä£ III UNav-Sim software architecture ‚Ä£ UNav-Sim: A Visually Realistic Underwater Robotics Simulator and Synthetic Data-generation Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>), several vehicle-specific parameters such as its inertia, hydrodynamic coefficients, and the maximum thruster rotation speed, must be configured by the user.</p>
</div>
<div id="S3.SS3.p2" class="ltx_para">
<p id="S3.SS3.p2.1" class="ltx_p">The model chosen to be implemented, the Blue Robotics BlueROV2 Heavy, is an over-actuated <a href="#id1.1.id1"><abbr href="#id1.1.id1" title="remotely operated vehicle" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">ROV</span></abbr></a> with four vertical thrusters and four horizontal thrusters as shown in Fig. <a href="#S3.F3" title="Figure 3 ‚Ä£ III-B Underwater physics ‚Ä£ III UNav-Sim software architecture ‚Ä£ UNav-Sim: A Visually Realistic Underwater Robotics Simulator and Synthetic Data-generation Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>. The horizontal thrusters are oriented at 45 degrees and are responsible for the control of three degrees of freedom, namely, surge, sway, and yaw, while the vertical thrusters control heave, pitch, and roll. The model parameters are obtained from <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite>.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">IV </span><span id="S4.1.1" class="ltx_text ltx_font_smallcaps">Vision-based underwater navigation stack</span>
</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">The vision-based underwater navigation stack of UNav-Sim includes planning, control, and <a href="#id6.6.id6"><abbr href="#id6.6.id6" title="simultaneous localisation and mapping" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">SLAM</span></abbr></a>. Many state-of-the-art <a href="#id15.15.id15"><abbr href="#id15.15.id15" title="artificial intelligence" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">AI</span></abbr></a> algorithms in robotics, for example, as implemented in OpenDR toolkit <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite> or PyPose library <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>, primarily rely on vision for localization, planning, and control¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>. Therefore, in this study, we have chosen to utilize visual SLAM (VSLAM) and end-to-end  <a href="#id9.9.id9"><span href="#id9.9.id9" title="deep reinforcement learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long">deep reinforcement learning</span></span></a> (<a href="#id9.9.id9"><abbr href="#id9.9.id9" title="deep reinforcement learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">DRL</span></abbr></a>) algorithms to demonstrate the capabilities of the proposed simulator. To facilitate ease of integration with various autonomy algorithms and deployment on actual hardware, all algorithms have been developed using <a href="#id14.14.id14"><abbr href="#id14.14.id14" title="robot operating system" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">ROS</span></abbr></a> framework.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS1.5.1.1" class="ltx_text">IV-A</span> </span><span id="S4.SS1.6.2" class="ltx_text ltx_font_italic">Vision-based planning</span>
</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">The recent developments in machine learning methods enable intelligent agents to learn navigation tasks end-to-end. Generally, a deep neural network policy takes sensory input, such as high-dimensional visual data, and generates feasible actions without explicitly mapping the environment. These learning-based methods require large amounts of data for training, which is impractical for real-world robotics systems. Hence, simulation environments are very substantial for enriching the required data in many cases <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite>.
Furthermore, <a href="#id9.9.id9"><abbr href="#id9.9.id9" title="deep reinforcement learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">DRL</span></abbr></a> methods require demonstrations for exploration of the environment to learn a policy, which increases safety concerns for real-world learning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite>.
Consequently, simulation environments with high-fidelity visual sensors and accurate physical dynamics are crucial for DRL research. OpenAI‚Äôs gym¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite> is a general standard for experimenting with learning-based sequential decision-making tasks.
Therefore, we have provided a gym environment along with our simulator to augment its capabilities for benchmarking learning-based navigation algorithms.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS2.5.1.1" class="ltx_text">IV-B</span> </span><span id="S4.SS2.6.2" class="ltx_text ltx_font_italic">Control</span>
</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">A  <a href="#id5.5.id5"><span href="#id5.5.id5" title="model predictive control" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long">model predictive control</span></span></a> (<a href="#id5.5.id5"><abbr href="#id5.5.id5" title="model predictive control" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">MPC</span></abbr></a>) strategy was utilized to control the <a href="#id1.1.id1"><abbr href="#id1.1.id1" title="remotely operated vehicle" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">ROV</span></abbr></a> model, which consists of a two-step process involving an <a href="#id5.5.id5"><abbr href="#id5.5.id5" title="model predictive control" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">MPC</span></abbr></a> followed by a control allocation algorithm. The motivation for the use of MPC is based on its ability to handle both input and state constraints explicitly, and intuitive tuning parameters <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite>.
The <a href="#id5.5.id5"><abbr href="#id5.5.id5" title="model predictive control" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">MPC</span></abbr></a> is designed to solve an online optimization problem, aiming to determine the optimal body wrench forces and moments, given a particular robot pose and a desired reference pose.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.1" class="ltx_p">The control allocation algorithm is then employed to obtain the individual control signal for each thruster by using a pseudo-inverse of an allocation matrix, which is vehicle-specific and depends on the thruster configuration of the <a href="#id1.1.id1"><abbr href="#id1.1.id1" title="remotely operated vehicle" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">ROV</span></abbr></a>. ACADO toolkit <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref">33</a>]</cite> is utilized to implement the <a href="#id5.5.id5"><abbr href="#id5.5.id5" title="model predictive control" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">MPC</span></abbr></a> as a <a href="#id14.14.id14"><abbr href="#id14.14.id14" title="robot operating system" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">ROS</span></abbr></a> package, which is integrated into the <a href="#id14.14.id14"><abbr href="#id14.14.id14" title="robot operating system" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">ROS</span></abbr></a> navigation stack.</p>
</div>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS3.5.1.1" class="ltx_text">IV-C</span> </span><span id="S4.SS3.6.2" class="ltx_text ltx_font_italic">Visual localization</span>
</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">Visual localization algorithms rely on cameras to retrieve the robot‚Äôs state, which are widely used in the underwater robotics community <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite>. Long-standing ROS packages for SLAM include <span id="S4.SS3.p1.1.1" class="ltx_text ltx_font_typewriter">robot_localization</span>, which presents a classical filtering approach for sensor fusion <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite>, <span id="S4.SS3.p1.1.2" class="ltx_text ltx_font_typewriter">hector_slam</span>, which implements occupancy grid maps for laser and IMU data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite>, and <span id="S4.SS3.p1.1.3" class="ltx_text ltx_font_typewriter">gmapping</span>, which leverages a Rao-Blackwellized particle filter for laser-based SLAM <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite>.
The availability of these state-of-the-art and ready-to-use algorithms has allowed outstanding progress in the robotics community <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib38" title="" class="ltx_ref">38</a>, <a href="#bib.bib39" title="" class="ltx_ref">39</a>, <a href="#bib.bib40" title="" class="ltx_ref">40</a>, <a href="#bib.bib41" title="" class="ltx_ref">41</a>, <a href="#bib.bib42" title="" class="ltx_ref">42</a>]</cite>, as they ease the implementation of future advances for SLAM and the benchmarking of their performance. However, the availability of off-the-shelf packages for visual SLAM remains an open problem.
Therefore, we propose <span id="S4.SS3.p1.1.4" class="ltx_text ltx_font_typewriter">robot_visual_localization</span>, a ROS metapackage for deploying and benchmarking visual localization algorithms. We chose to implement the state-of-art methods ORB-SLAM3 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib43" title="" class="ltx_ref">43</a>]</cite> and TartanVO <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib44" title="" class="ltx_ref">44</a>]</cite>. Each algorithm is implemented as a standalone ROS package within the <span id="S4.SS3.p1.1.5" class="ltx_text ltx_font_typewriter">robot_visual_localization</span> metapackage, which takes as input the image stream, and outputs the camera trajectory and the map points for ORB-SLAM3, and the camera trajectory for TartanVO.</p>
</div>
<div id="S4.SS3.p2" class="ltx_para">
<p id="S4.SS3.p2.1" class="ltx_p">ORB-SLAM3 encompasses a geometry-based approach for SLAM. The ORB-SLAM3‚Äôs front end tracks ORB features across consecutive frames. The features are selected to be uniformly distributed across the image, and the matches search is performed according to a constant velocity model. The ORB-SLAM3‚Äôs back end builds a map with the sparse points tracked from the front end. Under tracking loss, the map is stored in memory as inactive, creating a new active map. The loop closure thread finds revisited areas under the active and inactive maps, merging them and propagating the accumulated drift.</p>
</div>
<div id="S4.SS3.p3" class="ltx_para">
<p id="S4.SS3.p3.1" class="ltx_p">Geometry-based algorithms such as ORB-SLAM3 still present the de-facto state-of-art for SLAM, due to their high precision and efficiency. However, they are highly dependent on feature detection and matching, and therefore sensitive to visual degradations such as repetitive patterns, textureless environments, and non-Lambertian surfaces. On the other hand, learning-based algorithms can be more robust against those challenging imaging conditions, but are highly dependent on the training data, and usually lack generalization ability.</p>
</div>
<div id="S4.SS3.p4" class="ltx_para">
<p id="S4.SS3.p4.1" class="ltx_p">The proposed ROS metapackage serves then as an accessible tool for the easy comparison of two of the main taxonomies in the SLAM‚Äôs state-of-art, which in the present work serves as a comparison of their performance under challenging underwater imaging conditions.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">V </span><span id="S5.1.1" class="ltx_text ltx_font_smallcaps">Example use-cases</span>
</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">As a case study for UNav-Sim, we present an autonomous pipe inspection scenario.
Pipe inspection, being the most common use case for <a href="#id1.1.id1"><abbr href="#id1.1.id1" title="remotely operated vehicle" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">ROV</span></abbr></a>s, presents a relevant and challenging use case, where vision-based navigation is essential to achieve the required task. Furthermore, we assess the efficacy of our underwater autonomy stack and report its performance in executing the designated autonomous pipe inspection task. A video showing the pipe inspection demonstration can be found here<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span><a target="_blank" href="https://youtu.be/unZS33lCqpU" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://youtu.be/unZS33lCqpU</a></span></span></span>.</p>
</div>
<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S5.SS1.5.1.1" class="ltx_text">V-A</span> </span><span id="S5.SS1.6.2" class="ltx_text ltx_font_italic">Vision-based pipe following with DRL</span>
</h3>

<div id="S5.SS1.p1" class="ltx_para">
<p id="S5.SS1.p1.8" class="ltx_p">In this experiment, the performance of UNav-Sim is evaluated in a pipe-following task. An agent utilizing <a href="#id9.9.id9"><abbr href="#id9.9.id9" title="deep reinforcement learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">DRL</span></abbr></a> is trained with the gym interface provided by the simulator to generate position commands based on RGB image observations. An <a href="#id5.5.id5"><abbr href="#id5.5.id5" title="model predictive control" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">MPC</span></abbr></a> controller subsequently executes the position commands. The convolutional neural network policy inputs <math id="S5.SS1.p1.1.m1.1" class="ltx_Math" alttext="180\times 320" display="inline"><semantics id="S5.SS1.p1.1.m1.1a"><mrow id="S5.SS1.p1.1.m1.1.1" xref="S5.SS1.p1.1.m1.1.1.cmml"><mn id="S5.SS1.p1.1.m1.1.1.2" xref="S5.SS1.p1.1.m1.1.1.2.cmml">180</mn><mo lspace="0.222em" rspace="0.222em" id="S5.SS1.p1.1.m1.1.1.1" xref="S5.SS1.p1.1.m1.1.1.1.cmml">√ó</mo><mn id="S5.SS1.p1.1.m1.1.1.3" xref="S5.SS1.p1.1.m1.1.1.3.cmml">320</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.1.m1.1b"><apply id="S5.SS1.p1.1.m1.1.1.cmml" xref="S5.SS1.p1.1.m1.1.1"><times id="S5.SS1.p1.1.m1.1.1.1.cmml" xref="S5.SS1.p1.1.m1.1.1.1"></times><cn type="integer" id="S5.SS1.p1.1.m1.1.1.2.cmml" xref="S5.SS1.p1.1.m1.1.1.2">180</cn><cn type="integer" id="S5.SS1.p1.1.m1.1.1.3.cmml" xref="S5.SS1.p1.1.m1.1.1.3">320</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.1.m1.1c">180\times 320</annotation></semantics></math> pixel RGB image observation, <math id="S5.SS1.p1.2.m2.1" class="ltx_Math" alttext="o_{t}" display="inline"><semantics id="S5.SS1.p1.2.m2.1a"><msub id="S5.SS1.p1.2.m2.1.1" xref="S5.SS1.p1.2.m2.1.1.cmml"><mi id="S5.SS1.p1.2.m2.1.1.2" xref="S5.SS1.p1.2.m2.1.1.2.cmml">o</mi><mi id="S5.SS1.p1.2.m2.1.1.3" xref="S5.SS1.p1.2.m2.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.2.m2.1b"><apply id="S5.SS1.p1.2.m2.1.1.cmml" xref="S5.SS1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S5.SS1.p1.2.m2.1.1.1.cmml" xref="S5.SS1.p1.2.m2.1.1">subscript</csymbol><ci id="S5.SS1.p1.2.m2.1.1.2.cmml" xref="S5.SS1.p1.2.m2.1.1.2">ùëú</ci><ci id="S5.SS1.p1.2.m2.1.1.3.cmml" xref="S5.SS1.p1.2.m2.1.1.3">ùë°</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.2.m2.1c">o_{t}</annotation></semantics></math>, from a downward-looking camera on <a href="#id1.1.id1"><abbr href="#id1.1.id1" title="remotely operated vehicle" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">ROV</span></abbr></a> and outputs an action, <math id="S5.SS1.p1.3.m3.1" class="ltx_Math" alttext="a_{t}" display="inline"><semantics id="S5.SS1.p1.3.m3.1a"><msub id="S5.SS1.p1.3.m3.1.1" xref="S5.SS1.p1.3.m3.1.1.cmml"><mi id="S5.SS1.p1.3.m3.1.1.2" xref="S5.SS1.p1.3.m3.1.1.2.cmml">a</mi><mi id="S5.SS1.p1.3.m3.1.1.3" xref="S5.SS1.p1.3.m3.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.3.m3.1b"><apply id="S5.SS1.p1.3.m3.1.1.cmml" xref="S5.SS1.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S5.SS1.p1.3.m3.1.1.1.cmml" xref="S5.SS1.p1.3.m3.1.1">subscript</csymbol><ci id="S5.SS1.p1.3.m3.1.1.2.cmml" xref="S5.SS1.p1.3.m3.1.1.2">ùëé</ci><ci id="S5.SS1.p1.3.m3.1.1.3.cmml" xref="S5.SS1.p1.3.m3.1.1.3">ùë°</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.3.m3.1c">a_{t}</annotation></semantics></math>, describing one meter away waypoint consisting of two values, <math id="S5.SS1.p1.4.m4.4" class="ltx_Math" alttext="a_{1},a_{2}\in[-1,1]" display="inline"><semantics id="S5.SS1.p1.4.m4.4a"><mrow id="S5.SS1.p1.4.m4.4.4" xref="S5.SS1.p1.4.m4.4.4.cmml"><mrow id="S5.SS1.p1.4.m4.3.3.2.2" xref="S5.SS1.p1.4.m4.3.3.2.3.cmml"><msub id="S5.SS1.p1.4.m4.2.2.1.1.1" xref="S5.SS1.p1.4.m4.2.2.1.1.1.cmml"><mi id="S5.SS1.p1.4.m4.2.2.1.1.1.2" xref="S5.SS1.p1.4.m4.2.2.1.1.1.2.cmml">a</mi><mn id="S5.SS1.p1.4.m4.2.2.1.1.1.3" xref="S5.SS1.p1.4.m4.2.2.1.1.1.3.cmml">1</mn></msub><mo id="S5.SS1.p1.4.m4.3.3.2.2.3" xref="S5.SS1.p1.4.m4.3.3.2.3.cmml">,</mo><msub id="S5.SS1.p1.4.m4.3.3.2.2.2" xref="S5.SS1.p1.4.m4.3.3.2.2.2.cmml"><mi id="S5.SS1.p1.4.m4.3.3.2.2.2.2" xref="S5.SS1.p1.4.m4.3.3.2.2.2.2.cmml">a</mi><mn id="S5.SS1.p1.4.m4.3.3.2.2.2.3" xref="S5.SS1.p1.4.m4.3.3.2.2.2.3.cmml">2</mn></msub></mrow><mo id="S5.SS1.p1.4.m4.4.4.4" xref="S5.SS1.p1.4.m4.4.4.4.cmml">‚àà</mo><mrow id="S5.SS1.p1.4.m4.4.4.3.1" xref="S5.SS1.p1.4.m4.4.4.3.2.cmml"><mo stretchy="false" id="S5.SS1.p1.4.m4.4.4.3.1.2" xref="S5.SS1.p1.4.m4.4.4.3.2.cmml">[</mo><mrow id="S5.SS1.p1.4.m4.4.4.3.1.1" xref="S5.SS1.p1.4.m4.4.4.3.1.1.cmml"><mo id="S5.SS1.p1.4.m4.4.4.3.1.1a" xref="S5.SS1.p1.4.m4.4.4.3.1.1.cmml">‚àí</mo><mn id="S5.SS1.p1.4.m4.4.4.3.1.1.2" xref="S5.SS1.p1.4.m4.4.4.3.1.1.2.cmml">1</mn></mrow><mo id="S5.SS1.p1.4.m4.4.4.3.1.3" xref="S5.SS1.p1.4.m4.4.4.3.2.cmml">,</mo><mn id="S5.SS1.p1.4.m4.1.1" xref="S5.SS1.p1.4.m4.1.1.cmml">1</mn><mo stretchy="false" id="S5.SS1.p1.4.m4.4.4.3.1.4" xref="S5.SS1.p1.4.m4.4.4.3.2.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.4.m4.4b"><apply id="S5.SS1.p1.4.m4.4.4.cmml" xref="S5.SS1.p1.4.m4.4.4"><in id="S5.SS1.p1.4.m4.4.4.4.cmml" xref="S5.SS1.p1.4.m4.4.4.4"></in><list id="S5.SS1.p1.4.m4.3.3.2.3.cmml" xref="S5.SS1.p1.4.m4.3.3.2.2"><apply id="S5.SS1.p1.4.m4.2.2.1.1.1.cmml" xref="S5.SS1.p1.4.m4.2.2.1.1.1"><csymbol cd="ambiguous" id="S5.SS1.p1.4.m4.2.2.1.1.1.1.cmml" xref="S5.SS1.p1.4.m4.2.2.1.1.1">subscript</csymbol><ci id="S5.SS1.p1.4.m4.2.2.1.1.1.2.cmml" xref="S5.SS1.p1.4.m4.2.2.1.1.1.2">ùëé</ci><cn type="integer" id="S5.SS1.p1.4.m4.2.2.1.1.1.3.cmml" xref="S5.SS1.p1.4.m4.2.2.1.1.1.3">1</cn></apply><apply id="S5.SS1.p1.4.m4.3.3.2.2.2.cmml" xref="S5.SS1.p1.4.m4.3.3.2.2.2"><csymbol cd="ambiguous" id="S5.SS1.p1.4.m4.3.3.2.2.2.1.cmml" xref="S5.SS1.p1.4.m4.3.3.2.2.2">subscript</csymbol><ci id="S5.SS1.p1.4.m4.3.3.2.2.2.2.cmml" xref="S5.SS1.p1.4.m4.3.3.2.2.2.2">ùëé</ci><cn type="integer" id="S5.SS1.p1.4.m4.3.3.2.2.2.3.cmml" xref="S5.SS1.p1.4.m4.3.3.2.2.2.3">2</cn></apply></list><interval closure="closed" id="S5.SS1.p1.4.m4.4.4.3.2.cmml" xref="S5.SS1.p1.4.m4.4.4.3.1"><apply id="S5.SS1.p1.4.m4.4.4.3.1.1.cmml" xref="S5.SS1.p1.4.m4.4.4.3.1.1"><minus id="S5.SS1.p1.4.m4.4.4.3.1.1.1.cmml" xref="S5.SS1.p1.4.m4.4.4.3.1.1"></minus><cn type="integer" id="S5.SS1.p1.4.m4.4.4.3.1.1.2.cmml" xref="S5.SS1.p1.4.m4.4.4.3.1.1.2">1</cn></apply><cn type="integer" id="S5.SS1.p1.4.m4.1.1.cmml" xref="S5.SS1.p1.4.m4.1.1">1</cn></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.4.m4.4c">a_{1},a_{2}\in[-1,1]</annotation></semantics></math>. The actions represent the direction of the position step and turn in the heading angle, respectively, similar to our previous work <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite>. The reward is defined with respect to vertical divergence from the pipe unless the termination of episodes; <math id="S5.SS1.p1.5.m5.1" class="ltx_Math" alttext="r_{t}=10-2e_{p}^{2}-2e_{\psi}" display="inline"><semantics id="S5.SS1.p1.5.m5.1a"><mrow id="S5.SS1.p1.5.m5.1.1" xref="S5.SS1.p1.5.m5.1.1.cmml"><msub id="S5.SS1.p1.5.m5.1.1.2" xref="S5.SS1.p1.5.m5.1.1.2.cmml"><mi id="S5.SS1.p1.5.m5.1.1.2.2" xref="S5.SS1.p1.5.m5.1.1.2.2.cmml">r</mi><mi id="S5.SS1.p1.5.m5.1.1.2.3" xref="S5.SS1.p1.5.m5.1.1.2.3.cmml">t</mi></msub><mo id="S5.SS1.p1.5.m5.1.1.1" xref="S5.SS1.p1.5.m5.1.1.1.cmml">=</mo><mrow id="S5.SS1.p1.5.m5.1.1.3" xref="S5.SS1.p1.5.m5.1.1.3.cmml"><mn id="S5.SS1.p1.5.m5.1.1.3.2" xref="S5.SS1.p1.5.m5.1.1.3.2.cmml">10</mn><mo id="S5.SS1.p1.5.m5.1.1.3.1" xref="S5.SS1.p1.5.m5.1.1.3.1.cmml">‚àí</mo><mrow id="S5.SS1.p1.5.m5.1.1.3.3" xref="S5.SS1.p1.5.m5.1.1.3.3.cmml"><mn id="S5.SS1.p1.5.m5.1.1.3.3.2" xref="S5.SS1.p1.5.m5.1.1.3.3.2.cmml">2</mn><mo lspace="0em" rspace="0em" id="S5.SS1.p1.5.m5.1.1.3.3.1" xref="S5.SS1.p1.5.m5.1.1.3.3.1.cmml">‚Äã</mo><msubsup id="S5.SS1.p1.5.m5.1.1.3.3.3" xref="S5.SS1.p1.5.m5.1.1.3.3.3.cmml"><mi id="S5.SS1.p1.5.m5.1.1.3.3.3.2.2" xref="S5.SS1.p1.5.m5.1.1.3.3.3.2.2.cmml">e</mi><mi id="S5.SS1.p1.5.m5.1.1.3.3.3.2.3" xref="S5.SS1.p1.5.m5.1.1.3.3.3.2.3.cmml">p</mi><mn id="S5.SS1.p1.5.m5.1.1.3.3.3.3" xref="S5.SS1.p1.5.m5.1.1.3.3.3.3.cmml">2</mn></msubsup></mrow><mo id="S5.SS1.p1.5.m5.1.1.3.1a" xref="S5.SS1.p1.5.m5.1.1.3.1.cmml">‚àí</mo><mrow id="S5.SS1.p1.5.m5.1.1.3.4" xref="S5.SS1.p1.5.m5.1.1.3.4.cmml"><mn id="S5.SS1.p1.5.m5.1.1.3.4.2" xref="S5.SS1.p1.5.m5.1.1.3.4.2.cmml">2</mn><mo lspace="0em" rspace="0em" id="S5.SS1.p1.5.m5.1.1.3.4.1" xref="S5.SS1.p1.5.m5.1.1.3.4.1.cmml">‚Äã</mo><msub id="S5.SS1.p1.5.m5.1.1.3.4.3" xref="S5.SS1.p1.5.m5.1.1.3.4.3.cmml"><mi id="S5.SS1.p1.5.m5.1.1.3.4.3.2" xref="S5.SS1.p1.5.m5.1.1.3.4.3.2.cmml">e</mi><mi id="S5.SS1.p1.5.m5.1.1.3.4.3.3" xref="S5.SS1.p1.5.m5.1.1.3.4.3.3.cmml">œà</mi></msub></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.5.m5.1b"><apply id="S5.SS1.p1.5.m5.1.1.cmml" xref="S5.SS1.p1.5.m5.1.1"><eq id="S5.SS1.p1.5.m5.1.1.1.cmml" xref="S5.SS1.p1.5.m5.1.1.1"></eq><apply id="S5.SS1.p1.5.m5.1.1.2.cmml" xref="S5.SS1.p1.5.m5.1.1.2"><csymbol cd="ambiguous" id="S5.SS1.p1.5.m5.1.1.2.1.cmml" xref="S5.SS1.p1.5.m5.1.1.2">subscript</csymbol><ci id="S5.SS1.p1.5.m5.1.1.2.2.cmml" xref="S5.SS1.p1.5.m5.1.1.2.2">ùëü</ci><ci id="S5.SS1.p1.5.m5.1.1.2.3.cmml" xref="S5.SS1.p1.5.m5.1.1.2.3">ùë°</ci></apply><apply id="S5.SS1.p1.5.m5.1.1.3.cmml" xref="S5.SS1.p1.5.m5.1.1.3"><minus id="S5.SS1.p1.5.m5.1.1.3.1.cmml" xref="S5.SS1.p1.5.m5.1.1.3.1"></minus><cn type="integer" id="S5.SS1.p1.5.m5.1.1.3.2.cmml" xref="S5.SS1.p1.5.m5.1.1.3.2">10</cn><apply id="S5.SS1.p1.5.m5.1.1.3.3.cmml" xref="S5.SS1.p1.5.m5.1.1.3.3"><times id="S5.SS1.p1.5.m5.1.1.3.3.1.cmml" xref="S5.SS1.p1.5.m5.1.1.3.3.1"></times><cn type="integer" id="S5.SS1.p1.5.m5.1.1.3.3.2.cmml" xref="S5.SS1.p1.5.m5.1.1.3.3.2">2</cn><apply id="S5.SS1.p1.5.m5.1.1.3.3.3.cmml" xref="S5.SS1.p1.5.m5.1.1.3.3.3"><csymbol cd="ambiguous" id="S5.SS1.p1.5.m5.1.1.3.3.3.1.cmml" xref="S5.SS1.p1.5.m5.1.1.3.3.3">superscript</csymbol><apply id="S5.SS1.p1.5.m5.1.1.3.3.3.2.cmml" xref="S5.SS1.p1.5.m5.1.1.3.3.3"><csymbol cd="ambiguous" id="S5.SS1.p1.5.m5.1.1.3.3.3.2.1.cmml" xref="S5.SS1.p1.5.m5.1.1.3.3.3">subscript</csymbol><ci id="S5.SS1.p1.5.m5.1.1.3.3.3.2.2.cmml" xref="S5.SS1.p1.5.m5.1.1.3.3.3.2.2">ùëí</ci><ci id="S5.SS1.p1.5.m5.1.1.3.3.3.2.3.cmml" xref="S5.SS1.p1.5.m5.1.1.3.3.3.2.3">ùëù</ci></apply><cn type="integer" id="S5.SS1.p1.5.m5.1.1.3.3.3.3.cmml" xref="S5.SS1.p1.5.m5.1.1.3.3.3.3">2</cn></apply></apply><apply id="S5.SS1.p1.5.m5.1.1.3.4.cmml" xref="S5.SS1.p1.5.m5.1.1.3.4"><times id="S5.SS1.p1.5.m5.1.1.3.4.1.cmml" xref="S5.SS1.p1.5.m5.1.1.3.4.1"></times><cn type="integer" id="S5.SS1.p1.5.m5.1.1.3.4.2.cmml" xref="S5.SS1.p1.5.m5.1.1.3.4.2">2</cn><apply id="S5.SS1.p1.5.m5.1.1.3.4.3.cmml" xref="S5.SS1.p1.5.m5.1.1.3.4.3"><csymbol cd="ambiguous" id="S5.SS1.p1.5.m5.1.1.3.4.3.1.cmml" xref="S5.SS1.p1.5.m5.1.1.3.4.3">subscript</csymbol><ci id="S5.SS1.p1.5.m5.1.1.3.4.3.2.cmml" xref="S5.SS1.p1.5.m5.1.1.3.4.3.2">ùëí</ci><ci id="S5.SS1.p1.5.m5.1.1.3.4.3.3.cmml" xref="S5.SS1.p1.5.m5.1.1.3.4.3.3">ùúì</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.5.m5.1c">r_{t}=10-2e_{p}^{2}-2e_{\psi}</annotation></semantics></math> where <math id="S5.SS1.p1.6.m6.1" class="ltx_Math" alttext="e_{p}" display="inline"><semantics id="S5.SS1.p1.6.m6.1a"><msub id="S5.SS1.p1.6.m6.1.1" xref="S5.SS1.p1.6.m6.1.1.cmml"><mi id="S5.SS1.p1.6.m6.1.1.2" xref="S5.SS1.p1.6.m6.1.1.2.cmml">e</mi><mi id="S5.SS1.p1.6.m6.1.1.3" xref="S5.SS1.p1.6.m6.1.1.3.cmml">p</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.6.m6.1b"><apply id="S5.SS1.p1.6.m6.1.1.cmml" xref="S5.SS1.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S5.SS1.p1.6.m6.1.1.1.cmml" xref="S5.SS1.p1.6.m6.1.1">subscript</csymbol><ci id="S5.SS1.p1.6.m6.1.1.2.cmml" xref="S5.SS1.p1.6.m6.1.1.2">ùëí</ci><ci id="S5.SS1.p1.6.m6.1.1.3.cmml" xref="S5.SS1.p1.6.m6.1.1.3">ùëù</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.6.m6.1c">e_{p}</annotation></semantics></math> is the closest distance to the pipe in the horizontal plane and <math id="S5.SS1.p1.7.m7.1" class="ltx_Math" alttext="e_{\psi}" display="inline"><semantics id="S5.SS1.p1.7.m7.1a"><msub id="S5.SS1.p1.7.m7.1.1" xref="S5.SS1.p1.7.m7.1.1.cmml"><mi id="S5.SS1.p1.7.m7.1.1.2" xref="S5.SS1.p1.7.m7.1.1.2.cmml">e</mi><mi id="S5.SS1.p1.7.m7.1.1.3" xref="S5.SS1.p1.7.m7.1.1.3.cmml">œà</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.7.m7.1b"><apply id="S5.SS1.p1.7.m7.1.1.cmml" xref="S5.SS1.p1.7.m7.1.1"><csymbol cd="ambiguous" id="S5.SS1.p1.7.m7.1.1.1.cmml" xref="S5.SS1.p1.7.m7.1.1">subscript</csymbol><ci id="S5.SS1.p1.7.m7.1.1.2.cmml" xref="S5.SS1.p1.7.m7.1.1.2">ùëí</ci><ci id="S5.SS1.p1.7.m7.1.1.3.cmml" xref="S5.SS1.p1.7.m7.1.1.3">ùúì</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.7.m7.1c">e_{\psi}</annotation></semantics></math> is the error in heading with respect to pipe direction. An episode is terminated where the pipes are not in the camera‚Äôs field of view, which is <math id="S5.SS1.p1.8.m8.1" class="ltx_Math" alttext="e_{p}&gt;2.5m" display="inline"><semantics id="S5.SS1.p1.8.m8.1a"><mrow id="S5.SS1.p1.8.m8.1.1" xref="S5.SS1.p1.8.m8.1.1.cmml"><msub id="S5.SS1.p1.8.m8.1.1.2" xref="S5.SS1.p1.8.m8.1.1.2.cmml"><mi id="S5.SS1.p1.8.m8.1.1.2.2" xref="S5.SS1.p1.8.m8.1.1.2.2.cmml">e</mi><mi id="S5.SS1.p1.8.m8.1.1.2.3" xref="S5.SS1.p1.8.m8.1.1.2.3.cmml">p</mi></msub><mo id="S5.SS1.p1.8.m8.1.1.1" xref="S5.SS1.p1.8.m8.1.1.1.cmml">&gt;</mo><mrow id="S5.SS1.p1.8.m8.1.1.3" xref="S5.SS1.p1.8.m8.1.1.3.cmml"><mn id="S5.SS1.p1.8.m8.1.1.3.2" xref="S5.SS1.p1.8.m8.1.1.3.2.cmml">2.5</mn><mo lspace="0em" rspace="0em" id="S5.SS1.p1.8.m8.1.1.3.1" xref="S5.SS1.p1.8.m8.1.1.3.1.cmml">‚Äã</mo><mi id="S5.SS1.p1.8.m8.1.1.3.3" xref="S5.SS1.p1.8.m8.1.1.3.3.cmml">m</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.8.m8.1b"><apply id="S5.SS1.p1.8.m8.1.1.cmml" xref="S5.SS1.p1.8.m8.1.1"><gt id="S5.SS1.p1.8.m8.1.1.1.cmml" xref="S5.SS1.p1.8.m8.1.1.1"></gt><apply id="S5.SS1.p1.8.m8.1.1.2.cmml" xref="S5.SS1.p1.8.m8.1.1.2"><csymbol cd="ambiguous" id="S5.SS1.p1.8.m8.1.1.2.1.cmml" xref="S5.SS1.p1.8.m8.1.1.2">subscript</csymbol><ci id="S5.SS1.p1.8.m8.1.1.2.2.cmml" xref="S5.SS1.p1.8.m8.1.1.2.2">ùëí</ci><ci id="S5.SS1.p1.8.m8.1.1.2.3.cmml" xref="S5.SS1.p1.8.m8.1.1.2.3">ùëù</ci></apply><apply id="S5.SS1.p1.8.m8.1.1.3.cmml" xref="S5.SS1.p1.8.m8.1.1.3"><times id="S5.SS1.p1.8.m8.1.1.3.1.cmml" xref="S5.SS1.p1.8.m8.1.1.3.1"></times><cn type="float" id="S5.SS1.p1.8.m8.1.1.3.2.cmml" xref="S5.SS1.p1.8.m8.1.1.3.2">2.5</cn><ci id="S5.SS1.p1.8.m8.1.1.3.3.cmml" xref="S5.SS1.p1.8.m8.1.1.3.3">ùëö</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.8.m8.1c">e_{p}&gt;2.5m</annotation></semantics></math>. The <a href="#id9.9.id9"><abbr href="#id9.9.id9" title="deep reinforcement learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">DRL</span></abbr></a> agent is trained with proximal policy optimization¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib45" title="" class="ltx_ref">45</a>]</cite> algorithm using <span id="S5.SS1.p1.8.1" class="ltx_text ltx_font_typewriter">stable-baselines3</span>¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib46" title="" class="ltx_ref">46</a>]</cite> package.</p>
</div>
<div id="S5.SS1.p2" class="ltx_para">
<p id="S5.SS1.p2.1" class="ltx_p">The trained policy is deployed on a pipe <math id="S5.SS1.p2.1.m1.1" class="ltx_Math" alttext="\sim 20" display="inline"><semantics id="S5.SS1.p2.1.m1.1a"><mrow id="S5.SS1.p2.1.m1.1.1" xref="S5.SS1.p2.1.m1.1.1.cmml"><mi id="S5.SS1.p2.1.m1.1.1.2" xref="S5.SS1.p2.1.m1.1.1.2.cmml"></mi><mo id="S5.SS1.p2.1.m1.1.1.1" xref="S5.SS1.p2.1.m1.1.1.1.cmml">‚àº</mo><mn id="S5.SS1.p2.1.m1.1.1.3" xref="S5.SS1.p2.1.m1.1.1.3.cmml">20</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p2.1.m1.1b"><apply id="S5.SS1.p2.1.m1.1.1.cmml" xref="S5.SS1.p2.1.m1.1.1"><csymbol cd="latexml" id="S5.SS1.p2.1.m1.1.1.1.cmml" xref="S5.SS1.p2.1.m1.1.1.1">similar-to</csymbol><csymbol cd="latexml" id="S5.SS1.p2.1.m1.1.1.2.cmml" xref="S5.SS1.p2.1.m1.1.1.2">absent</csymbol><cn type="integer" id="S5.SS1.p2.1.m1.1.1.3.cmml" xref="S5.SS1.p2.1.m1.1.1.3">20</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p2.1.m1.1c">\sim 20</annotation></semantics></math> meters long with right and left turns. The trajectory of the agent along with the pipes is visualized in Fig. <a href="#S5.F4" title="Figure 4 ‚Ä£ V-A Vision-based pipe following with DRL ‚Ä£ V Example use-cases ‚Ä£ UNav-Sim: A Visually Realistic Underwater Robotics Simulator and Synthetic Data-generation Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>.
While the agent is not accurately tracking the pipes due to the exploratory behavior of the <a href="#id9.9.id9"><abbr href="#id9.9.id9" title="deep reinforcement learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">DRL</span></abbr></a> policy, it learns to make reasoning from image observations and successfully follows the pipe.
This experiment demonstrates the utilization of high-fidelity image observations and accurate dynamics provided by UNav-Sim in a particular application.</p>
</div>
<figure id="S5.F4" class="ltx_figure"><img src="/html/2310.11927/assets/x4.png" id="S5.F4.g1" class="ltx_graphics ltx_centering ltx_img_portrait" width="254" height="320" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Trajectory followed by the <a href="#id9.9.id9"><abbr href="#id9.9.id9" title="deep reinforcement learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">DRL</span></abbr></a> agent (dark blue) along with the pipes from the top view. Starting point is the origin of the coordinate frame and is indicated with the <a href="#id1.1.id1"><abbr href="#id1.1.id1" title="remotely operated vehicle" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">ROV</span></abbr></a>.
</figcaption>
</figure>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S5.SS2.5.1.1" class="ltx_text">V-B</span> </span><span id="S5.SS2.6.2" class="ltx_text ltx_font_italic">Visual localization benchmarking</span>
</h3>

<div id="S5.SS2.p1" class="ltx_para">
<p id="S5.SS2.p1.1" class="ltx_p">The vision-based trajectory generated in Section <a href="#S5.SS1" title="V-A Vision-based pipe following with DRL ‚Ä£ V Example use-cases ‚Ä£ UNav-Sim: A Visually Realistic Underwater Robotics Simulator and Synthetic Data-generation Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">V-A</span></span></a>, being carried out by the robot with the controller showcased in Section <a href="#S4.SS2" title="IV-B Control ‚Ä£ IV Vision-based underwater navigation stack ‚Ä£ UNav-Sim: A Visually Realistic Underwater Robotics Simulator and Synthetic Data-generation Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">IV-B</span></span></a>, has served as a test setup for the visual localization experiment.
Two trajectories are carried out: a linear trajectory where no area in the map is revisited (see Fig. <a href="#S5.F4" title="Figure 4 ‚Ä£ V-A Vision-based pipe following with DRL ‚Ä£ V Example use-cases ‚Ä£ UNav-Sim: A Visually Realistic Underwater Robotics Simulator and Synthetic Data-generation Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>), and a trajectory with a loop, where the robot navigates back to the starting point.
The benchmarking is automatically performed by the <span id="S5.SS2.p1.1.1" class="ltx_text ltx_font_typewriter">robot_visual_localization</span> metapackage using <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib47" title="" class="ltx_ref">47</a>]</cite>.</p>
</div>
<div id="S5.SS2.p2" class="ltx_para">
<p id="S5.SS2.p2.5" class="ltx_p">During runtime, the estimated trajectory <math id="S5.SS2.p2.1.m1.1" class="ltx_Math" alttext="P_{i}" display="inline"><semantics id="S5.SS2.p2.1.m1.1a"><msub id="S5.SS2.p2.1.m1.1.1" xref="S5.SS2.p2.1.m1.1.1.cmml"><mi id="S5.SS2.p2.1.m1.1.1.2" xref="S5.SS2.p2.1.m1.1.1.2.cmml">P</mi><mi id="S5.SS2.p2.1.m1.1.1.3" xref="S5.SS2.p2.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS2.p2.1.m1.1b"><apply id="S5.SS2.p2.1.m1.1.1.cmml" xref="S5.SS2.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S5.SS2.p2.1.m1.1.1.1.cmml" xref="S5.SS2.p2.1.m1.1.1">subscript</csymbol><ci id="S5.SS2.p2.1.m1.1.1.2.cmml" xref="S5.SS2.p2.1.m1.1.1.2">ùëÉ</ci><ci id="S5.SS2.p2.1.m1.1.1.3.cmml" xref="S5.SS2.p2.1.m1.1.1.3">ùëñ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p2.1.m1.1c">P_{i}</annotation></semantics></math> and the ground truth trajectory <math id="S5.SS2.p2.2.m2.1" class="ltx_Math" alttext="Q_{i}" display="inline"><semantics id="S5.SS2.p2.2.m2.1a"><msub id="S5.SS2.p2.2.m2.1.1" xref="S5.SS2.p2.2.m2.1.1.cmml"><mi id="S5.SS2.p2.2.m2.1.1.2" xref="S5.SS2.p2.2.m2.1.1.2.cmml">Q</mi><mi id="S5.SS2.p2.2.m2.1.1.3" xref="S5.SS2.p2.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS2.p2.2.m2.1b"><apply id="S5.SS2.p2.2.m2.1.1.cmml" xref="S5.SS2.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S5.SS2.p2.2.m2.1.1.1.cmml" xref="S5.SS2.p2.2.m2.1.1">subscript</csymbol><ci id="S5.SS2.p2.2.m2.1.1.2.cmml" xref="S5.SS2.p2.2.m2.1.1.2">ùëÑ</ci><ci id="S5.SS2.p2.2.m2.1.1.3.cmml" xref="S5.SS2.p2.2.m2.1.1.3">ùëñ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p2.2.m2.1c">Q_{i}</annotation></semantics></math> are recorded into separate files composing a sequence of time-synchronized spatial poses. The pose format is the one proposed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib48" title="" class="ltx_ref">48</a>]</cite>, composed of the three spatial coordinates with the orientation in quaternions.
The metrics implemented are the  <a href="#id16.16.id16"><span href="#id16.16.id16" title="absolute positioning error" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long">absolute positioning error</span></span></a> (<a href="#id16.16.id16"><abbr href="#id16.16.id16" title="absolute positioning error" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">APE</span></abbr></a>) and the  <a href="#id17.17.id17"><span href="#id17.17.id17" title="relative positioning error" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long">relative positioning error</span></span></a> (<a href="#id17.17.id17"><abbr href="#id17.17.id17" title="relative positioning error" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">RPE</span></abbr></a>), which are automatically deployed over the recorded trajectories before shutdown. TartanVO presents a monocular visual odometry algorithm. Therefore, for a fair comparison, the ORB-SLAM3 experiment is executed under a monocular setup.
The deployment of monocular algorithms implies that the orientation of the algorithm‚Äôs world frame and the trajectory‚Äôs scale is arbitrary. Therefore, the estimated trajectories are aligned with the ground truth by obtaining the transform <math id="S5.SS2.p2.3.m3.1" class="ltx_Math" alttext="S\in Sim_{3}" display="inline"><semantics id="S5.SS2.p2.3.m3.1a"><mrow id="S5.SS2.p2.3.m3.1.1" xref="S5.SS2.p2.3.m3.1.1.cmml"><mi id="S5.SS2.p2.3.m3.1.1.2" xref="S5.SS2.p2.3.m3.1.1.2.cmml">S</mi><mo id="S5.SS2.p2.3.m3.1.1.1" xref="S5.SS2.p2.3.m3.1.1.1.cmml">‚àà</mo><mrow id="S5.SS2.p2.3.m3.1.1.3" xref="S5.SS2.p2.3.m3.1.1.3.cmml"><mi id="S5.SS2.p2.3.m3.1.1.3.2" xref="S5.SS2.p2.3.m3.1.1.3.2.cmml">S</mi><mo lspace="0em" rspace="0em" id="S5.SS2.p2.3.m3.1.1.3.1" xref="S5.SS2.p2.3.m3.1.1.3.1.cmml">‚Äã</mo><mi id="S5.SS2.p2.3.m3.1.1.3.3" xref="S5.SS2.p2.3.m3.1.1.3.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="S5.SS2.p2.3.m3.1.1.3.1a" xref="S5.SS2.p2.3.m3.1.1.3.1.cmml">‚Äã</mo><msub id="S5.SS2.p2.3.m3.1.1.3.4" xref="S5.SS2.p2.3.m3.1.1.3.4.cmml"><mi id="S5.SS2.p2.3.m3.1.1.3.4.2" xref="S5.SS2.p2.3.m3.1.1.3.4.2.cmml">m</mi><mn id="S5.SS2.p2.3.m3.1.1.3.4.3" xref="S5.SS2.p2.3.m3.1.1.3.4.3.cmml">3</mn></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.p2.3.m3.1b"><apply id="S5.SS2.p2.3.m3.1.1.cmml" xref="S5.SS2.p2.3.m3.1.1"><in id="S5.SS2.p2.3.m3.1.1.1.cmml" xref="S5.SS2.p2.3.m3.1.1.1"></in><ci id="S5.SS2.p2.3.m3.1.1.2.cmml" xref="S5.SS2.p2.3.m3.1.1.2">ùëÜ</ci><apply id="S5.SS2.p2.3.m3.1.1.3.cmml" xref="S5.SS2.p2.3.m3.1.1.3"><times id="S5.SS2.p2.3.m3.1.1.3.1.cmml" xref="S5.SS2.p2.3.m3.1.1.3.1"></times><ci id="S5.SS2.p2.3.m3.1.1.3.2.cmml" xref="S5.SS2.p2.3.m3.1.1.3.2">ùëÜ</ci><ci id="S5.SS2.p2.3.m3.1.1.3.3.cmml" xref="S5.SS2.p2.3.m3.1.1.3.3">ùëñ</ci><apply id="S5.SS2.p2.3.m3.1.1.3.4.cmml" xref="S5.SS2.p2.3.m3.1.1.3.4"><csymbol cd="ambiguous" id="S5.SS2.p2.3.m3.1.1.3.4.1.cmml" xref="S5.SS2.p2.3.m3.1.1.3.4">subscript</csymbol><ci id="S5.SS2.p2.3.m3.1.1.3.4.2.cmml" xref="S5.SS2.p2.3.m3.1.1.3.4.2">ùëö</ci><cn type="integer" id="S5.SS2.p2.3.m3.1.1.3.4.3.cmml" xref="S5.SS2.p2.3.m3.1.1.3.4.3">3</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p2.3.m3.1c">S\in Sim_{3}</annotation></semantics></math> that best aligns <math id="S5.SS2.p2.4.m4.1" class="ltx_Math" alttext="P_{i}" display="inline"><semantics id="S5.SS2.p2.4.m4.1a"><msub id="S5.SS2.p2.4.m4.1.1" xref="S5.SS2.p2.4.m4.1.1.cmml"><mi id="S5.SS2.p2.4.m4.1.1.2" xref="S5.SS2.p2.4.m4.1.1.2.cmml">P</mi><mi id="S5.SS2.p2.4.m4.1.1.3" xref="S5.SS2.p2.4.m4.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS2.p2.4.m4.1b"><apply id="S5.SS2.p2.4.m4.1.1.cmml" xref="S5.SS2.p2.4.m4.1.1"><csymbol cd="ambiguous" id="S5.SS2.p2.4.m4.1.1.1.cmml" xref="S5.SS2.p2.4.m4.1.1">subscript</csymbol><ci id="S5.SS2.p2.4.m4.1.1.2.cmml" xref="S5.SS2.p2.4.m4.1.1.2">ùëÉ</ci><ci id="S5.SS2.p2.4.m4.1.1.3.cmml" xref="S5.SS2.p2.4.m4.1.1.3">ùëñ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p2.4.m4.1c">P_{i}</annotation></semantics></math> with <math id="S5.SS2.p2.5.m5.1" class="ltx_Math" alttext="Q_{i}" display="inline"><semantics id="S5.SS2.p2.5.m5.1a"><msub id="S5.SS2.p2.5.m5.1.1" xref="S5.SS2.p2.5.m5.1.1.cmml"><mi id="S5.SS2.p2.5.m5.1.1.2" xref="S5.SS2.p2.5.m5.1.1.2.cmml">Q</mi><mi id="S5.SS2.p2.5.m5.1.1.3" xref="S5.SS2.p2.5.m5.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS2.p2.5.m5.1b"><apply id="S5.SS2.p2.5.m5.1.1.cmml" xref="S5.SS2.p2.5.m5.1.1"><csymbol cd="ambiguous" id="S5.SS2.p2.5.m5.1.1.1.cmml" xref="S5.SS2.p2.5.m5.1.1">subscript</csymbol><ci id="S5.SS2.p2.5.m5.1.1.2.cmml" xref="S5.SS2.p2.5.m5.1.1.2">ùëÑ</ci><ci id="S5.SS2.p2.5.m5.1.1.3.cmml" xref="S5.SS2.p2.5.m5.1.1.3">ùëñ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p2.5.m5.1c">Q_{i}</annotation></semantics></math>.</p>
</div>
<div id="S5.SS2.p3" class="ltx_para">
<p id="S5.SS2.p3.1" class="ltx_p">With the deployment of the automatic stack for visual inspection proposed by UNav-Sim, benchmarking of visual localization algorithms becomes a straightforward task: the robot follows the pipeline autonomously under the planned trajectory, with the visual localization algorithms being automatically executed by the <span id="S5.SS2.p3.1.1" class="ltx_text ltx_font_typewriter">robot_visual_localization</span> package, which on shutdown generates the results as depicted in Table <a href="#S5.T2" title="TABLE II ‚Ä£ V-B Visual localization benchmarking ‚Ä£ V Example use-cases ‚Ä£ UNav-Sim: A Visually Realistic Underwater Robotics Simulator and Synthetic Data-generation Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag">II</span></a>. It can be seen from the generated results that the two proposed algorithms depict a similar performance in the linear trajectory, but ORB-SLAM outperforms TartanVO under the presence of a closed loop.
Despite ORB-SLAM‚Äôs high efficiency in state-of-the-art datasets, the realistic underwater conditions confront one of the main challenges for feature-based approaches: the lack of texture. Moreover, the pipes are the main source of features, which avoids their uniform distribution across the image. Without enough evenly-distributed features, the ORB-SLAM‚Äôs front end drifts. Nevertheless, the closed trajectory shows the convenience of the back-end‚Äôs loop closure algorithm: the absolute errors are significantly reduced for translation and rotation.
On the other hand, TartanVO presents a drift similar to ORB-SLAM‚Äôs in the translations, but slightly higher for rotations. These results show the great potential of learning-based algorithms under imaging conditions that challenge geometry-based methods. Although the lack of generalization ability is the main source of drift in this case, TartanVO has been trained with high amounts of diversified data that explain its good performance in the proposed setup.</p>
</div>
<div id="S5.SS2.p4" class="ltx_para">
<p id="S5.SS2.p4.1" class="ltx_p">In conclusion, the framework proposed in UNav-Sim has enabled the automatic benchmarking of state-of-the-art visual localisation algorithms in a realistic underwater scenario. This has allowed the challenges and opportunities of these algorithms to be easily demonstrated in a geometry-based and learning-based manner.</p>
</div>
<figure id="S5.T2" class="ltx_table">
<figcaption class="ltx_caption ltx_centering" style="font-size:70%;"><span class="ltx_tag ltx_tag_table">TABLE II: </span>visual localization results in the pipeline tracking scenario.</figcaption>
<table id="S5.T2.3" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S5.T2.3.1.1" class="ltx_tr">
<th id="S5.T2.3.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S5.T2.3.1.1.1.1" class="ltx_text" style="font-size:70%;">Trajectory</span></th>
<th id="S5.T2.3.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S5.T2.3.1.1.2.1" class="ltx_text" style="font-size:70%;">Algorithm</span></th>
<th id="S5.T2.3.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S5.T2.3.1.1.3.1" class="ltx_text" style="font-size:70%;">APE[m]</span></th>
<th id="S5.T2.3.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S5.T2.3.1.1.4.1" class="ltx_text" style="font-size:70%;">RPE[m]</span></th>
<th id="S5.T2.3.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S5.T2.3.1.1.5.1" class="ltx_text" style="font-size:70%;">APE[rad]</span></th>
<th id="S5.T2.3.1.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S5.T2.3.1.1.6.1" class="ltx_text" style="font-size:70%;">RPE[rad]</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S5.T2.3.2.1" class="ltx_tr">
<td id="S5.T2.3.2.1.1" class="ltx_td ltx_align_center ltx_border_t" rowspan="2"><span id="S5.T2.3.2.1.1.1" class="ltx_text" style="font-size:70%;">Linear</span></td>
<td id="S5.T2.3.2.1.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T2.3.2.1.2.1" class="ltx_text" style="font-size:70%;">ORB-SLAM3</span></td>
<td id="S5.T2.3.2.1.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T2.3.2.1.3.1" class="ltx_text" style="font-size:70%;">1.75</span></td>
<td id="S5.T2.3.2.1.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T2.3.2.1.4.1" class="ltx_text ltx_font_bold" style="font-size:70%;">0.412</span></td>
<td id="S5.T2.3.2.1.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T2.3.2.1.5.1" class="ltx_text ltx_font_bold" style="font-size:70%;">1.53</span></td>
<td id="S5.T2.3.2.1.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T2.3.2.1.6.1" class="ltx_text ltx_font_bold" style="font-size:70%;">0.036</span></td>
</tr>
<tr id="S5.T2.3.3.2" class="ltx_tr">
<td id="S5.T2.3.3.2.1" class="ltx_td ltx_align_center"><span id="S5.T2.3.3.2.1.1" class="ltx_text" style="font-size:70%;">TartanVO</span></td>
<td id="S5.T2.3.3.2.2" class="ltx_td ltx_align_center"><span id="S5.T2.3.3.2.2.1" class="ltx_text ltx_font_bold" style="font-size:70%;">1.67</span></td>
<td id="S5.T2.3.3.2.3" class="ltx_td ltx_align_center"><span id="S5.T2.3.3.2.3.1" class="ltx_text" style="font-size:70%;">0.489</span></td>
<td id="S5.T2.3.3.2.4" class="ltx_td ltx_align_center"><span id="S5.T2.3.3.2.4.1" class="ltx_text" style="font-size:70%;">1.95</span></td>
<td id="S5.T2.3.3.2.5" class="ltx_td ltx_align_center"><span id="S5.T2.3.3.2.5.1" class="ltx_text" style="font-size:70%;">0.108</span></td>
</tr>
<tr id="S5.T2.3.4.3" class="ltx_tr">
<td id="S5.T2.3.4.3.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" rowspan="2"><span id="S5.T2.3.4.3.1.1" class="ltx_text" style="font-size:70%;">With loop</span></td>
<td id="S5.T2.3.4.3.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T2.3.4.3.2.1" class="ltx_text" style="font-size:70%;">ORB-SLAM3</span></td>
<td id="S5.T2.3.4.3.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T2.3.4.3.3.1" class="ltx_text ltx_font_bold" style="font-size:70%;">0.078</span></td>
<td id="S5.T2.3.4.3.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T2.3.4.3.4.1" class="ltx_text" style="font-size:70%;">0.372</span></td>
<td id="S5.T2.3.4.3.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T2.3.4.3.5.1" class="ltx_text ltx_font_bold" style="font-size:70%;">1.62</span></td>
<td id="S5.T2.3.4.3.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T2.3.4.3.6.1" class="ltx_text ltx_font_bold" style="font-size:70%;">0.006</span></td>
</tr>
<tr id="S5.T2.3.5.4" class="ltx_tr">
<td id="S5.T2.3.5.4.1" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T2.3.5.4.1.1" class="ltx_text" style="font-size:70%;">TartanVO</span></td>
<td id="S5.T2.3.5.4.2" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T2.3.5.4.2.1" class="ltx_text" style="font-size:70%;">0.961</span></td>
<td id="S5.T2.3.5.4.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T2.3.5.4.3.1" class="ltx_text ltx_font_bold" style="font-size:70%;">0.322</span></td>
<td id="S5.T2.3.5.4.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T2.3.5.4.4.1" class="ltx_text" style="font-size:70%;">2.10</span></td>
<td id="S5.T2.3.5.4.5" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T2.3.5.4.5.1" class="ltx_text" style="font-size:70%;">0.068</span></td>
</tr>
</tbody>
</table>
</figure>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VI </span><span id="S6.1.1" class="ltx_text ltx_font_smallcaps">Conclusion &amp; future work</span>
</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">We have developed UNav-Sim, a novel open-source underwater simulator, which builds upon AirSim and <a href="#id12.12.id12"><abbr href="#id12.12.id12" title="unreal engine 5" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">UE5</span></abbr></a> and incorporates state-of-the-art robotics algorithms. UNav-Sim also supports <a href="#id14.14.id14"><abbr href="#id14.14.id14" title="robot operating system" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">ROS</span></abbr></a> and multiple operating systems, facilitating a streamlined and efficient development process for robotics applications. Future work will include the incorporation of additional underwater sensors, vehicle models, and more custom environments.</p>
</div>
</section>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_font_smallcaps ltx_title_section">Acknowledgement</h2>

<div id="Sx1.p1" class="ltx_para">
<p id="Sx1.p1.1" class="ltx_p">This work is supported by EIVA a/s and Innovation Fund Denmark under grants 2040-00032B and 1044-00007B, the European Union‚Äôs Horizon 2020 Research and Innovation Program (OpenDR) under Grant 871449 and the Marie Sk≈Çodowska-Curie (REMARO) under Grant 956200. This publication reflects the authors‚Äô views only. The European Commission is not responsible for any use that may be made of the information it contains.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
Robert Bogue.

</span>
<span class="ltx_bibblock">Underwater robots: a review of technologies and applications.

</span>
<span class="ltx_bibblock"><span id="bib.bib1.1.1" class="ltx_text ltx_font_italic">Industrial Robot: An International Journal</span>, 2015.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
Efe Camci, Domenico Campolo, and Erdal Kayacan.

</span>
<span class="ltx_bibblock">Deep reinforcement learning for motion planning of quadrotors using raw depth images.

</span>
<span class="ltx_bibblock">In <span id="bib.bib2.1.1" class="ltx_text ltx_font_italic">2020 International Joint Conference on Neural Networks (IJCNN)</span>, pages 1‚Äì7. IEEE, 2020.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
Huy¬†Xuan Pham, Ilker Bozcan, Andriy Sarabakha, Sami Haddadin, and Erdal Kayacan.

</span>
<span class="ltx_bibblock">Gatenet: An efficient deep neural network architecture for gate perception using fish-eye camera in autonomous drone racing.

</span>
<span class="ltx_bibblock">In <span id="bib.bib3.1.1" class="ltx_text ltx_font_italic">2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</span>, pages 4176‚Äì4183. IEEE, 2021.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
Mohit Mehndiratta and Erdal Kayacan.

</span>
<span class="ltx_bibblock">Gaussian process-based learning control of aerial robots for precise visualization of geological outcrops.

</span>
<span class="ltx_bibblock">In <span id="bib.bib4.1.1" class="ltx_text ltx_font_italic">2020 European Control Conference (ECC)</span>, pages 10‚Äì16. IEEE, 2020.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
Leif Christensen, Jos√© de¬†Gea¬†Fern√°ndez, Marc Hildebrandt, Christian Ernst¬†Siegfried Koch, and Bilal Wehbe.

</span>
<span class="ltx_bibblock">Recent advances in ai for navigation and control of underwater robots.

</span>
<span class="ltx_bibblock"><span id="bib.bib5.1.1" class="ltx_text ltx_font_italic">Current Robotics Reports</span>, pages 1‚Äì11, 2022.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
Olaya √Ålvarez Tu√±√≥n, Hemanth Kanner, Luiza Ribeiro¬†Marnet, Huy Xuy¬†Pham, Jonas le¬†Fevre¬†Sejersen, Yury Brodskiy, and Erdal Kayacan.

</span>
<span class="ltx_bibblock">Mimir-uw: A multipurpose synthetic dataset for underwater navigation and inspection.

</span>
<span class="ltx_bibblock"><span id="bib.bib6.1.1" class="ltx_text ltx_font_italic">2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</span>, 2023.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
Easton Potokar, Spencer Ashford, Michael Kaess, and Joshua¬†G Mangelson.

</span>
<span class="ltx_bibblock">Holoocean: An underwater robotics simulator.

</span>
<span class="ltx_bibblock">In <span id="bib.bib7.1.1" class="ltx_text ltx_font_italic">2022 International Conference on Robotics and Automation (ICRA)</span>, pages 3040‚Äì3046. IEEE, 2022.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
Musa Morena¬†Marcusso Manh√£es, Sebastian¬†A Scherer, Martin Voss, Luiz¬†Ricardo Douat, and Thomas Rauschenbach.

</span>
<span class="ltx_bibblock">Uuv simulator: A gazebo-based package for underwater intervention and multi-robot simulation.

</span>
<span class="ltx_bibblock">In <span id="bib.bib8.1.1" class="ltx_text ltx_font_italic">OCEANS 2016 MTS/IEEE Monterey</span>, pages 1‚Äì8. IEEE, 2016.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
Mabel¬†M Zhang, Woen-Sug Choi, Jessica Herman, Duane Davis, Carson Vogt, Michael McCarrin, Yadunund Vijay, Dharini Dutia, William Lew, Steven Peters, et¬†al.

</span>
<span class="ltx_bibblock">Dave aquatic virtual environment: Toward a general underwater robotics simulator.

</span>
<span class="ltx_bibblock">In <span id="bib.bib9.1.1" class="ltx_text ltx_font_italic">2022 IEEE/OES Autonomous Underwater Vehicles Symposium (AUV)</span>, pages 1‚Äì8. IEEE, 2022.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
Ivan Lonƒçar, Juraj Obradoviƒá, Natko Kra≈°evac, Luka Mandiƒá, Igor Kvasiƒá, Fausto Ferreira, Vladimir Slo≈°iƒá, ƒêula Naƒë, and Nikola Mi≈°koviƒá.

</span>
<span class="ltx_bibblock">Marus-a marine robotics simulator.

</span>
<span class="ltx_bibblock">In <span id="bib.bib10.1.1" class="ltx_text ltx_font_italic">OCEANS 2022, Hampton Roads</span>, pages 1‚Äì7. IEEE, 2022.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
Shital Shah, Debadeepta Dey, Chris Lovett, and Ashish Kapoor.

</span>
<span class="ltx_bibblock">Airsim: High-fidelity visual and physical simulation for autonomous vehicles.

</span>
<span class="ltx_bibblock">In <span id="bib.bib11.1.1" class="ltx_text ltx_font_italic">Field and service robotics</span>, pages 621‚Äì635. Springer, 2018.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
BYU.

</span>
<span class="ltx_bibblock">byu vtol.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://github.com/byu-magicc/vtol-AirSim" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/byu-magicc/vtol-AirSim</a>, 2013.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
CodexLabsLLC.

</span>
<span class="ltx_bibblock">Colosseum.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://github.com/CodexLabsLLC/Colosseum" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/CodexLabsLLC/Colosseum</a>, 2013.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
Jacky Liang, Viktor Makoviychuk, Ankur Handa, Nuttapong Chentanez, Miles Macklin, and Dieter Fox.

</span>
<span class="ltx_bibblock">Gpu-accelerated robotic simulation for distributed reinforcement learning.

</span>
<span class="ltx_bibblock">In <span id="bib.bib14.1.1" class="ltx_text ltx_font_italic">Conference on Robot Learning</span>, pages 270‚Äì282. PMLR, 2018.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
Mario Prats, Javier Perez, J¬†Javier Fernandez, and Pedro¬†J Sanz.

</span>
<span class="ltx_bibblock">An open source tool for simulation and supervision of underwater intervention missions.

</span>
<span class="ltx_bibblock">In <span id="bib.bib15.1.1" class="ltx_text ltx_font_italic">2012 IEEE/RSJ international conference on Intelligent Robots and Systems</span>, pages 2577‚Äì2582. IEEE, 2012.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
Jack Collins, Shelvin Chand, Anthony Vanderkop, and David Howard.

</span>
<span class="ltx_bibblock">A review of physics simulators for robotic applications.

</span>
<span class="ltx_bibblock"><span id="bib.bib16.1.1" class="ltx_text ltx_font_italic">IEEE Access</span>, 9:51416‚Äì51431, 2021.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
Morgan Quigley, Ken Conley, Brian Gerkey, Josh Faust, Tully Foote, Jeremy Leibs, Rob Wheeler, Andrew¬†Y Ng, et¬†al.

</span>
<span class="ltx_bibblock">Ros: an open-source robot operating system.

</span>
<span class="ltx_bibblock">In <span id="bib.bib17.1.1" class="ltx_text ltx_font_italic">ICRA workshop on open source software</span>, volume¬†3, page¬†5. Kobe, Japan, 2009.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
Lorenz Meier, Dominik Honegger, and Marc Pollefeys.

</span>
<span class="ltx_bibblock">Px4: A node-based multithreaded open source robotics framework for deeply embedded platforms.

</span>
<span class="ltx_bibblock">In <span id="bib.bib18.1.1" class="ltx_text ltx_font_italic">2015 IEEE international conference on robotics and automation (ICRA)</span>, pages 6235‚Äì6240. IEEE, 2015.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
Greg Brockman, Vicki Cheung, Ludwig Pettersson, Jonas Schneider, John Schulman, Jie Tang, and Wojciech Zaremba.

</span>
<span class="ltx_bibblock">Openai gym.

</span>
<span class="ltx_bibblock"><span id="bib.bib19.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1606.01540</span>, 2016.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
Pushkal Katara, Mukul Khanna, Harshit Nagar, and Annapurani Panaiyappan.

</span>
<span class="ltx_bibblock">Open source simulator for unmanned underwater vehicles using ros and unity3d.

</span>
<span class="ltx_bibblock">In <span id="bib.bib20.1.1" class="ltx_text ltx_font_italic">2019 IEEE Underwater Technology (UT)</span>, pages 1‚Äì7. IEEE, 2019.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
Olaya √Ålvarez-Tu√±√≥n, Alberto Jard√≥n, and Carlos Balaguer.

</span>
<span class="ltx_bibblock">Generation and processing of simulated underwater images for infrastructure visual inspection with uuvs.

</span>
<span class="ltx_bibblock"><span id="bib.bib21.1.1" class="ltx_text ltx_font_italic">Sensors</span>, 19(24):5497, 2019.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
Philippe Blasi, Bertrand Le¬†Saec, and Christophe Schlick.

</span>
<span class="ltx_bibblock">A rendering algorithm for discrete volume density objects.

</span>
<span class="ltx_bibblock">In <span id="bib.bib22.1.1" class="ltx_text ltx_font_italic">Computer Graphics Forum</span>, volume¬†12, pages 201‚Äì210. Wiley Online Library, 1993.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
Derya Akkaynak, Tali Treibitz, Tom Shlesinger, Yossi Loya, Raz Tamir, and David Iluz.

</span>
<span class="ltx_bibblock">What is the space of attenuation coefficients in underwater computer vision?

</span>
<span class="ltx_bibblock">In <span id="bib.bib23.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</span>, pages 4931‚Äì4940, 2017.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
Thor¬†I Fossen.

</span>
<span class="ltx_bibblock"><span id="bib.bib24.1.1" class="ltx_text ltx_font_italic">Handbook of marine craft hydrodynamics and motion control</span>.

</span>
<span class="ltx_bibblock">John Wiley &amp; Sons, 2011.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
TheSocietyofNavalArchitectureandMarineEngineers SNAME.

</span>
<span class="ltx_bibblock">Nomenclature for treating the motion of a submerged body through a fluid.

</span>
<span class="ltx_bibblock"><span id="bib.bib25.1.1" class="ltx_text ltx_font_italic">The Society of Naval Architects and Marine Engineers, Technical and Research Bulletin</span>, pages 1‚Äì5, 1950.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
Chu-Jou Wu.

</span>
<span class="ltx_bibblock"><span id="bib.bib26.1.1" class="ltx_text ltx_font_italic">6-dof modelling and control of a remotely operated vehicle</span>.

</span>
<span class="ltx_bibblock">PhD thesis, Flinders University, College of Science and Engineering., 2018.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
S¬†Pedrazzi, D¬†Dias, F¬†Ferro, O¬†Green, E¬†Kayacan, et¬†al.

</span>
<span class="ltx_bibblock">Opendr: An open toolkit for enabling high performance, low footprint deep learning for robotics.

</span>
<span class="ltx_bibblock">In <span id="bib.bib27.1.1" class="ltx_text ltx_font_italic">2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</span>, pages 12479‚Äì12484. IEEE, 2022.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
Chen Wang, Dasong Gao, Kuan Xu, Junyi Geng, Yaoyu Hu, Yuheng Qiu, Bowen Li, Fan Yang, Brady Moon, Abhinav Pandey, et¬†al.

</span>
<span class="ltx_bibblock">Pypose: A library for robot learning with physics-based optimization.

</span>
<span class="ltx_bibblock"><span id="bib.bib28.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2209.15428</span>, 2022.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
Huy¬†Xuan Pham, Halil¬†Ibrahim Ugurlu, Jonas Le¬†Fevre, Deniz Bardakci, and Erdal Kayacan.

</span>
<span class="ltx_bibblock">Deep learning for vision-based navigation in autonomous drone racing.

</span>
<span class="ltx_bibblock">In <span id="bib.bib29.1.1" class="ltx_text ltx_font_italic">Deep learning for robot perception and cognition</span>, pages 371‚Äì406. Elsevier, 2022.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
Antonio Loquercio, Elia Kaufmann, Ren√© Ranftl, Matthias M√ºller, Vladlen Koltun, and Davide Scaramuzza.

</span>
<span class="ltx_bibblock">Learning high-speed flight in the wild.

</span>
<span class="ltx_bibblock"><span id="bib.bib30.1.1" class="ltx_text ltx_font_italic">Science Robotics</span>, 6(59):eabg5810, 2021.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
Halil¬†Ibrahim Ugurlu, Xuan¬†Huy Pham, and Erdal Kayacan.

</span>
<span class="ltx_bibblock">Sim-to-real deep reinforcement learning for safe end-to-end planning of aerial robots.

</span>
<span class="ltx_bibblock"><span id="bib.bib31.1.1" class="ltx_text ltx_font_italic">Robotics</span>, 11(5):109, 2022.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
Utku Eren, Anna Prach, Ba≈üaran¬†Bahadƒ±r Ko√ßer, Sa≈°a¬†V Rakoviƒá, Erdal Kayacan, and Beh√ßet A√ßƒ±kme≈üe.

</span>
<span class="ltx_bibblock">Model predictive control in aerospace systems: Current state and opportunities.

</span>
<span class="ltx_bibblock"><span id="bib.bib32.1.1" class="ltx_text ltx_font_italic">Journal of Guidance, Control, and Dynamics</span>, 40(7):1541‚Äì1566, 2017.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
Boris Houska, Hans¬†Joachim Ferreau, and Moritz Diehl.

</span>
<span class="ltx_bibblock">Acado toolkit‚Äîan open-source framework for automatic control and dynamic optimization.

</span>
<span class="ltx_bibblock"><span id="bib.bib33.1.1" class="ltx_text ltx_font_italic">Optimal Control Applications and Methods</span>, 32(3):298‚Äì312, 2011.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
Olaya √Ålvarez-Tu√±√≥n, Yury Brodskiy, and Erdal Kayacan.

</span>
<span class="ltx_bibblock">Monocular visual simultaneous localization and mapping:(r) evolution from geometry to deep learning-based pipelines.

</span>
<span class="ltx_bibblock"><span id="bib.bib34.1.1" class="ltx_text ltx_font_italic">IEEE Transactions on Artificial Intelligence</span>, 2023.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
Thomas Moore and Daniel Stouch.

</span>
<span class="ltx_bibblock">A generalized extended kalman filter implementation for the robot operating system.

</span>
<span class="ltx_bibblock">In <span id="bib.bib35.1.1" class="ltx_text ltx_font_italic">Intelligent Autonomous Systems 13: Proceedings of the 13th International Conference IAS-13</span>, pages 335‚Äì348. Springer, 2016.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock">
Stefan Kohlbrecher, Oskar Von¬†Stryk, Johannes Meyer, and Uwe Klingauf.

</span>
<span class="ltx_bibblock">A flexible and scalable slam system with full 3d motion estimation.

</span>
<span class="ltx_bibblock">In <span id="bib.bib36.1.1" class="ltx_text ltx_font_italic">2011 IEEE international symposium on safety, security, and rescue robotics</span>, pages 155‚Äì160. IEEE, 2011.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock">
Giorgio Grisetti, Cyrill Stachniss, and Wolfram Burgard.

</span>
<span class="ltx_bibblock">Improving grid-based slam with rao-blackwellized particle filters by adaptive proposals and selective resampling.

</span>
<span class="ltx_bibblock">In <span id="bib.bib37.1.1" class="ltx_text ltx_font_italic">Proceedings of the 2005 IEEE international conference on robotics and automation</span>, pages 2432‚Äì2437. IEEE, 2005.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock">
Leyao Huang.

</span>
<span class="ltx_bibblock">Review on lidar-based slam techniques.

</span>
<span class="ltx_bibblock">In <span id="bib.bib38.1.1" class="ltx_text ltx_font_italic">2021 International Conference on Signal Processing and Machine Learning (CONF-SPML)</span>, pages 163‚Äì168. IEEE, 2021.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock">
Naigong Yu and Bo¬†Zhang.

</span>
<span class="ltx_bibblock">An improved hector slam algorithm based on information fusion for mobile robot.

</span>
<span class="ltx_bibblock">In <span id="bib.bib39.1.1" class="ltx_text ltx_font_italic">2018 5th IEEE International conference on cloud computing and intelligence systems (CCIS)</span>, pages 279‚Äì284. IEEE, 2018.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock">
Weichen Wei, Bijan Shirinzadeh, Shunmugasundar Esakkiappan, Mohammadali Ghafarian, and Ammar Al-Jodah.

</span>
<span class="ltx_bibblock">Orientation correction for hector slam at starting stage.

</span>
<span class="ltx_bibblock">In <span id="bib.bib40.1.1" class="ltx_text ltx_font_italic">2019 7th International Conference on Robot Intelligence Technology and Applications (RiTA)</span>, pages 125‚Äì129. IEEE, 2019.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock">
Yassin Abdelrasoul, Abu Bakar Sayuti¬†HM Saman, and Patrick Sebastian.

</span>
<span class="ltx_bibblock">A quantitative study of tuning ros gmapping parameters and their effect on performing indoor 2d slam.

</span>
<span class="ltx_bibblock">In <span id="bib.bib41.1.1" class="ltx_text ltx_font_italic">2016 2nd IEEE international symposium on robotics and manufacturing automation (ROMA)</span>, pages 1‚Äì6. IEEE, 2016.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock">
BLEA Balasuriya, BAH Chathuranga, BHMD Jayasundara, NRAC Napagoda, SP¬†Kumarawadu, DP¬†Chandima, and AGBP Jayasekara.

</span>
<span class="ltx_bibblock">Outdoor robot navigation using gmapping based slam algorithm.

</span>
<span class="ltx_bibblock">In <span id="bib.bib42.1.1" class="ltx_text ltx_font_italic">2016 moratuwa engineering research conference (mercon)</span>, pages 403‚Äì408. IEEE, 2016.

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock">
Carlos Campos, Richard Elvira, Juan J¬†G√≥mez Rodr√≠guez, Jos√©¬†MM Montiel, and Juan¬†D Tard√≥s.

</span>
<span class="ltx_bibblock">Orb-slam3: An accurate open-source library for visual, visual‚Äìinertial, and multimap slam.

</span>
<span class="ltx_bibblock"><span id="bib.bib43.1.1" class="ltx_text ltx_font_italic">IEEE Transactions on Robotics</span>, 37(6):1874‚Äì1890, 2021.

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[44]</span>
<span class="ltx_bibblock">
Wenshan Wang, Yaoyu Hu, and Sebastian Scherer.

</span>
<span class="ltx_bibblock">Tartanvo: A generalizable learning-based vo.

</span>
<span class="ltx_bibblock">In <span id="bib.bib44.1.1" class="ltx_text ltx_font_italic">Conference on Robot Learning</span>, pages 1761‚Äì1772. PMLR, 2021.

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[45]</span>
<span class="ltx_bibblock">
John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, and Oleg Klimov.

</span>
<span class="ltx_bibblock">Proximal policy optimization algorithms.

</span>
<span class="ltx_bibblock"><span id="bib.bib45.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1707.06347</span>, 2017.

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[46]</span>
<span class="ltx_bibblock">
Antonin Raffin, Ashley Hill, Adam Gleave, Anssi Kanervisto, Maximilian Ernestus, and Noah Dormann.

</span>
<span class="ltx_bibblock">Stable-baselines3: Reliable reinforcement learning implementations.

</span>
<span class="ltx_bibblock"><span id="bib.bib46.1.1" class="ltx_text ltx_font_italic">Journal of Machine Learning Research</span>, 22(268):1‚Äì8, 2021.

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[47]</span>
<span class="ltx_bibblock">
Michael Grupp.

</span>
<span class="ltx_bibblock">evo: Python package for the evaluation of odometry and slam.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://github.com/MichaelGrupp/evo" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/MichaelGrupp/evo</a>, 2017.

</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[48]</span>
<span class="ltx_bibblock">
J√ºrgen Sturm, Nikolas Engelhard, Felix Endres, Wolfram Burgard, and Daniel Cremers.

</span>
<span class="ltx_bibblock">A benchmark for the evaluation of rgb-d slam systems.

</span>
<span class="ltx_bibblock">In <span id="bib.bib48.1.1" class="ltx_text ltx_font_italic">2012 IEEE/RSJ international conference on intelligent robots and systems</span>, pages 573‚Äì580. IEEE, 2012.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2310.11926" class="ar5iv-nav-button ar5iv-nav-button-prev">‚óÑ</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2310.11927" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2310.11927">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2310.11927" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2310.11928" class="ar5iv-nav-button ar5iv-nav-button-next">‚ñ∫</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Tue Feb 27 23:10:02 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "√ó";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
