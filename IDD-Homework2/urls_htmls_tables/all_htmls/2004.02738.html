<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2004.02738] IEEE BIBTEX style</title><meta property="og:description" content="In the era of advanced technologies, mobile devices are equipped with computing and sensing capabilities that gather excessive amounts of data. These amounts of data are suitable for training different learning models.…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="IEEE BIBTEX style">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="IEEE BIBTEX style">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2004.02738">

<!--Generated on Thu Mar  7 09:19:47 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<!--Document created on January 2014.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content="
Federated Learning,  Collaborative Learning,  Communication Cost,  Decentralised Data, 
">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">IEEE BIBT<span id="id4.id1" class="ltx_text" style="position:relative; bottom:-2.2pt;">E</span>X style</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">ShareLaTeX Templates
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"> Muhammad Asad, Ahmed Moustafa, Takayuki Ito, Muhammad Aslam<sup id="id5.3.id1" class="ltx_sup"><span id="id5.3.id1.1" class="ltx_text ltx_font_italic">†</span></sup>
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">Department of Computer Science, Nagoya Institute of Technology, Nagoya - Japan 
<br class="ltx_break"><math id="id3.2.m1.1" class="ltx_Math" alttext="{}^{{}^{\dagger}}" display="inline"><semantics id="id3.2.m1.1a"><msup id="id3.2.m1.1.1" xref="id3.2.m1.1.1.cmml"><mi id="id3.2.m1.1.1a" xref="id3.2.m1.1.1.cmml"></mi><msup id="id3.2.m1.1.1.1" xref="id3.2.m1.1.1.1.cmml"><mi id="id3.2.m1.1.1.1a" xref="id3.2.m1.1.1.1.cmml"></mi><mo id="id3.2.m1.1.1.1.1" xref="id3.2.m1.1.1.1.1.cmml">†</mo></msup></msup><annotation-xml encoding="MathML-Content" id="id3.2.m1.1b"><apply id="id3.2.m1.1.1.cmml" xref="id3.2.m1.1.1"><apply id="id3.2.m1.1.1.1.cmml" xref="id3.2.m1.1.1.1"><ci id="id3.2.m1.1.1.1.1.cmml" xref="id3.2.m1.1.1.1.1">†</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="id3.2.m1.1c">{}^{{}^{\dagger}}</annotation></semantics></math>School of Cyber Science and Engineering, Wuhan University, Wuhan - China 
<br class="ltx_break">e:mail: m.asad@itolab.nitech.ac.jp

</span></span></span>
</div>
<div class="ltx_dates">(January 2014)</div>

<h1 class="ltx_title ltx_title_document">Evaluating the Communication Efficiency in Federated Learning Algorithms</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">ShareLaTeX Templates
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"> Muhammad Asad, Ahmed Moustafa, Takayuki Ito, Muhammad Aslam<sup id="id5.3.id1" class="ltx_sup"><span id="id5.3.id1.1" class="ltx_text ltx_font_italic">†</span></sup>
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">Department of Computer Science, Nagoya Institute of Technology, Nagoya - Japan 
<br class="ltx_break"><math id="id3.2.m1.1" class="ltx_Math" alttext="{}^{{}^{\dagger}}" display="inline"><semantics id="id3.2.m1.1a"><msup id="id3.2.m1.1.1" xref="id3.2.m1.1.1.cmml"><mi id="id3.2.m1.1.1a" xref="id3.2.m1.1.1.cmml"></mi><msup id="id3.2.m1.1.1.1" xref="id3.2.m1.1.1.1.cmml"><mi id="id3.2.m1.1.1.1a" xref="id3.2.m1.1.1.1.cmml"></mi><mo id="id3.2.m1.1.1.1.1" xref="id3.2.m1.1.1.1.1.cmml">†</mo></msup></msup><annotation-xml encoding="MathML-Content" id="id3.2.m1.1b"><apply id="id3.2.m1.1.1.cmml" xref="id3.2.m1.1.1"><apply id="id3.2.m1.1.1.1.cmml" xref="id3.2.m1.1.1.1"><ci id="id3.2.m1.1.1.1.1.cmml" xref="id3.2.m1.1.1.1.1">†</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="id3.2.m1.1c">{}^{{}^{\dagger}}</annotation></semantics></math>School of Cyber Science and Engineering, Wuhan University, Wuhan - China 
<br class="ltx_break">e:mail: m.asad@itolab.nitech.ac.jp

</span></span></span>
</div>
<div class="ltx_dates">(January 2014)</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id6.id1" class="ltx_p">In the era of advanced technologies, mobile devices are equipped with computing and sensing capabilities that gather excessive amounts of data. These amounts of data are suitable for training different learning models. Cooperated with advancements in Deep Learning (DL), these learning models empower numerous useful applications, e.g., image processing, speech recognition, healthcare, vehicular network and many more. Traditionally, Machine Learning (ML) approaches require data to be centralised in cloud-based data-centres. However, this data is often large in quantity and privacy-sensitive which prevents logging into these data-centres for training the learning models. In turn, this results in critical issues of high latency and communication inefficiency. Recently, in light of new privacy legislations in many countries, the concept of Federated Learning (FL) has been introduced. In FL, mobile users are empowered to learn a global model by aggregating their local models, without sharing the privacy-sensitive data. Usually, these mobile users have slow network connections to the data-centre where the global model is maintained. Moreover, in a complex and large scale network, heterogeneous devices that have various energy constraints are involved. This raises the challenge of communication cost when implementing FL at large scale. To this end, in this research, we begin with the fundamentals of FL, and then, we highlight the recent FL algorithms and evaluate their communication efficiency with detailed comparisons. Furthermore, we propose a set of solutions to alleviate the existing FL problems both from communication perspective and privacy perspective.</p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Index Terms: </h6>
Federated Learning, Collaborative Learning, Communication Cost, Decentralised Data,

</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">I </span><span id="S1.1.1" class="ltx_text ltx_font_smallcaps">Introduction</span>
</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">In the past few years, the number of intelligent devices has grown rapidly with the advent of Internet of Things (IoT) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>. These devices are able to collect and process data at exceptional scale because of their embedded sensors and potent hardwares. On the other hand, Deep Learning (DL) has transformed the ways of information extraction from the data sources with radical successes in many applications such as image processing, speech recognition, health care, and natural language processing (NLP). The astonishing success of DL in processing large amounts of data can be credited to the availability of sufficient datasets for training <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>. In this regard, IoT has enabled a significant improvement in the training of DL models by exploiting the huge amounts of recorded data. Meanwhile, privacy has emerged as a major concern for each mobile user and it grows rapidly with the advent of social media networks. In this context, multiple misuse and data leakage cases in recent times has demonstrated that users’ privacy is at high risk during the centralised processing of data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Usually, IoT devices collect data in private environments where each device is explicitly decoupled from users due to various reasons. Therefore, sharing this data with a centralised server is not a good option, and hence, the possibility of training a DL model becomes challenging. To address this dilemma, a decentralised Machine Learning (ML) approach has been introduced, namely Federated Learning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">Federated Learning (FL) allows each participant device to jointly train a global DL model by using their combined data without revealing the personal data of each device to the centralised server. This privacy-preserving collaborative learning technique is achieved by following a three-step process as illustrated in Figure <a href="#S1.F1" title="Figure 1 ‣ 1st item ‣ I Introduction ‣ IEEE BIBTEX style" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
<div id="S1.p4" class="ltx_para">
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p"><span id="S1.I1.i1.p1.1.1" class="ltx_text ltx_font_bold">Task Initialization:</span> From the thousands of available devices in a certain time, the centralised server selects a certain number of devices and decides the training of specific FL task i.e., according to the corresponding data and the target application. Then, the centralised server specifies the training process and the hyper-parameters, e.g., learning rate. After specifying the devices and other task requirements, the centralised server broadcast the global model and the FL task to the selected participants.</p>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/2004.02738/assets/x1.png" id="S1.F1.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="246" height="138" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S1.F1.3.1.1" class="ltx_text" style="font-size:90%;">Figure 1</span>: </span><span id="S1.F1.4.2" class="ltx_text" style="font-size:90%;">FL general process with server and participants in single communication round where participants synchronise with the server and update the server for new updated global model.</span></figcaption>
</figure>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p"><span id="S1.I1.i2.p1.1.1" class="ltx_text ltx_font_bold">Local Model Training:</span> After receiving the global model, all the participants perform local computation based on the global model to update thier local parameters. The purpose is to find the optimal parameters that help in reducing the loss function. The updated parameters of each local model is sent back to the centralised server.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p"><span id="S1.I1.i3.p1.1.1" class="ltx_text ltx_font_bold">Global Model Aggregation:</span> The centralised server receives the local parameters from each participant and updates the global model parameters and then send back the updated global model parameters to all the participants in order to reduce the global loss function.</p>
</div>
</li>
</ul>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">The process of training in Steps 2 and 3 is continuously repeated until the desirable training accuracy is achieved or the global loss function meets the minimum requirements <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>.</p>
</div>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.1" class="ltx_p">On the other hand, in conventional centralised ML models, the implementation of federated training approaches on mobile networks features the following advantages. Firstly, <span id="S1.p6.1.1" class="ltx_text ltx_font_italic">efficient use of network bandwidth:</span> data owners only send the updated model parameters instead of sending the raw data for aggregation, which reduces the significant cost of data communication <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>. Secondly, <span id="S1.p6.1.2" class="ltx_text ltx_font_italic">latency:</span> in time critical applications such as Intelligent Transport Systems (ITS) where minimum network delay can create threatening situations, the implementation of FL can minimise this delay as the ML models will be consistently trained and updated. Moreover, real-time decisions, e.g., event detection, can be made locally at end devices <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>. Consequently, the latency in FL systems are much less than centralised systems. Thirdly, <span id="S1.p6.1.3" class="ltx_text ltx_font_italic">privacy:</span> the participants are not sending their raw data to the centralised server which ultimately guarantees each user privacy, and with this guaranteed privacy, the maximum number of users is able to participate in collaborative model training, and hence, the built model becomes better <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>.</p>
</div>
<div id="S1.p7" class="ltx_para">
<p id="S1.p7.1" class="ltx_p">Up to date, many attempts have been made for the implementation of FL at scale but still there are several challenges that need to be considered. Firstly, from the perspective of resource allocation, the heterogeneity of participating devices in terms of computation power, data quality and participation rate, needs to be managed in large scale networks. Secondly, due to the limited communication bandwidth and high dimensional model updates in mobile devices, communication cost remains an issue. Thirdly, malicious participants may exist in FL and can share the parameters of other participants, therefore, the security and privacy issues need to be considered in depth.</p>
</div>
<div id="S1.p8" class="ltx_para">
<p id="S1.p8.1" class="ltx_p">In the existing approaches of FL, neither the communication issues are properly addressed, nor the challenges of FL implementation are deeply discussed. This motivates us for conducting this study that covers, 1) implementation of FL 2) communication cost, and 3) a statistical and experimental comparison of the existing state-of-the-art algorithms. For the reader’s convenience, a list of the common abbreviations is shown in Table I.</p>
</div>
<div id="S1.p9" class="ltx_para">
<p id="S1.p9.1" class="ltx_p">The rest of this paper is organised as follows. Section II, highlights the fundamentals of FL and provides an overview of the existing FL frameworks and algorithms. Communication efficiency in FL algorithms is discussed in Section III. Evaluation of these algorithms are given in Section IV. The future work is proposed in Section V. Section VI concludes this paper.</p>
</div>
<figure id="S1.T1" class="ltx_table">
<table id="S1.T1.2" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S1.T1.2.1.1" class="ltx_tr">
<th id="S1.T1.2.1.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t">
<span id="S1.T1.2.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.1.1.1.1.1" class="ltx_p" style="width:51.2pt;"><span id="S1.T1.2.1.1.1.1.1.1" class="ltx_text" style="font-size:90%;">Abbreviation</span></span>
</span>
</th>
<th id="S1.T1.2.1.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_r ltx_border_t">
<span id="S1.T1.2.1.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.1.1.2.1.1" class="ltx_p" style="width:148.0pt;"><span id="S1.T1.2.1.1.2.1.1.1" class="ltx_text" style="font-size:90%;">Description</span></span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S1.T1.2.2.1" class="ltx_tr">
<td id="S1.T1.2.2.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_tt">
<span id="S1.T1.2.2.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.1.1.1.1" class="ltx_p" style="width:51.2pt;"><span id="S1.T1.2.2.1.1.1.1.1" class="ltx_text" style="font-size:90%;">CNN</span></span>
</span>
</td>
<td id="S1.T1.2.2.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt">
<span id="S1.T1.2.2.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.1.2.1.1" class="ltx_p" style="width:148.0pt;"><span id="S1.T1.2.2.1.2.1.1.1" class="ltx_text" style="font-size:90%;">Convolution Neural Network</span></span>
</span>
</td>
</tr>
<tr id="S1.T1.2.3.2" class="ltx_tr">
<td id="S1.T1.2.3.2.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t">
<span id="S1.T1.2.3.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.3.2.1.1.1" class="ltx_p" style="width:51.2pt;"><span id="S1.T1.2.3.2.1.1.1.1" class="ltx_text" style="font-size:90%;">DNN</span></span>
</span>
</td>
<td id="S1.T1.2.3.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S1.T1.2.3.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.3.2.2.1.1" class="ltx_p" style="width:148.0pt;"><span id="S1.T1.2.3.2.2.1.1.1" class="ltx_text" style="font-size:90%;">Deep Neural Network</span></span>
</span>
</td>
</tr>
<tr id="S1.T1.2.4.3" class="ltx_tr">
<td id="S1.T1.2.4.3.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t">
<span id="S1.T1.2.4.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.4.3.1.1.1" class="ltx_p" style="width:51.2pt;"><span id="S1.T1.2.4.3.1.1.1.1" class="ltx_text" style="font-size:90%;">DL</span></span>
</span>
</td>
<td id="S1.T1.2.4.3.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S1.T1.2.4.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.4.3.2.1.1" class="ltx_p" style="width:148.0pt;"><span id="S1.T1.2.4.3.2.1.1.1" class="ltx_text" style="font-size:90%;">Deep Learning</span></span>
</span>
</td>
</tr>
<tr id="S1.T1.2.5.4" class="ltx_tr">
<td id="S1.T1.2.5.4.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t">
<span id="S1.T1.2.5.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.5.4.1.1.1" class="ltx_p" style="width:51.2pt;"><span id="S1.T1.2.5.4.1.1.1.1" class="ltx_text" style="font-size:90%;">ML</span></span>
</span>
</td>
<td id="S1.T1.2.5.4.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S1.T1.2.5.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.5.4.2.1.1" class="ltx_p" style="width:148.0pt;"><span id="S1.T1.2.5.4.2.1.1.1" class="ltx_text" style="font-size:90%;">Machine Learning</span></span>
</span>
</td>
</tr>
<tr id="S1.T1.2.6.5" class="ltx_tr">
<td id="S1.T1.2.6.5.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t">
<span id="S1.T1.2.6.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.6.5.1.1.1" class="ltx_p" style="width:51.2pt;"><span id="S1.T1.2.6.5.1.1.1.1" class="ltx_text" style="font-size:90%;">DRL</span></span>
</span>
</td>
<td id="S1.T1.2.6.5.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S1.T1.2.6.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.6.5.2.1.1" class="ltx_p" style="width:148.0pt;"><span id="S1.T1.2.6.5.2.1.1.1" class="ltx_text" style="font-size:90%;">Deep Reinforcement Learning</span></span>
</span>
</td>
</tr>
<tr id="S1.T1.2.7.6" class="ltx_tr">
<td id="S1.T1.2.7.6.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t">
<span id="S1.T1.2.7.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.7.6.1.1.1" class="ltx_p" style="width:51.2pt;"><span id="S1.T1.2.7.6.1.1.1.1" class="ltx_text" style="font-size:90%;">FL</span></span>
</span>
</td>
<td id="S1.T1.2.7.6.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S1.T1.2.7.6.2.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.7.6.2.1.1" class="ltx_p" style="width:148.0pt;"><span id="S1.T1.2.7.6.2.1.1.1" class="ltx_text" style="font-size:90%;">Federated Learning</span></span>
</span>
</td>
</tr>
<tr id="S1.T1.2.8.7" class="ltx_tr">
<td id="S1.T1.2.8.7.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t">
<span id="S1.T1.2.8.7.1.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.8.7.1.1.1" class="ltx_p" style="width:51.2pt;"><span id="S1.T1.2.8.7.1.1.1.1" class="ltx_text" style="font-size:90%;">FedAvg</span></span>
</span>
</td>
<td id="S1.T1.2.8.7.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S1.T1.2.8.7.2.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.8.7.2.1.1" class="ltx_p" style="width:148.0pt;"><span id="S1.T1.2.8.7.2.1.1.1" class="ltx_text" style="font-size:90%;">Federated Averaging</span></span>
</span>
</td>
</tr>
<tr id="S1.T1.2.9.8" class="ltx_tr">
<td id="S1.T1.2.9.8.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t">
<span id="S1.T1.2.9.8.1.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.9.8.1.1.1" class="ltx_p" style="width:51.2pt;"><span id="S1.T1.2.9.8.1.1.1.1" class="ltx_text" style="font-size:90%;">IID</span></span>
</span>
</td>
<td id="S1.T1.2.9.8.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S1.T1.2.9.8.2.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.9.8.2.1.1" class="ltx_p" style="width:148.0pt;"><span id="S1.T1.2.9.8.2.1.1.1" class="ltx_text" style="font-size:90%;">Independent and Identically Distributed</span></span>
</span>
</td>
</tr>
<tr id="S1.T1.2.10.9" class="ltx_tr">
<td id="S1.T1.2.10.9.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t">
<span id="S1.T1.2.10.9.1.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.10.9.1.1.1" class="ltx_p" style="width:51.2pt;"><span id="S1.T1.2.10.9.1.1.1.1" class="ltx_text" style="font-size:90%;">NLP</span></span>
</span>
</td>
<td id="S1.T1.2.10.9.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S1.T1.2.10.9.2.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.10.9.2.1.1" class="ltx_p" style="width:148.0pt;"><span id="S1.T1.2.10.9.2.1.1.1" class="ltx_text" style="font-size:90%;">Natural Language Processing</span></span>
</span>
</td>
</tr>
<tr id="S1.T1.2.11.10" class="ltx_tr">
<td id="S1.T1.2.11.10.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t">
<span id="S1.T1.2.11.10.1.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.11.10.1.1.1" class="ltx_p" style="width:51.2pt;"><span id="S1.T1.2.11.10.1.1.1.1" class="ltx_text" style="font-size:90%;">MLP</span></span>
</span>
</td>
<td id="S1.T1.2.11.10.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S1.T1.2.11.10.2.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.11.10.2.1.1" class="ltx_p" style="width:148.0pt;"><span id="S1.T1.2.11.10.2.1.1.1" class="ltx_text" style="font-size:90%;">Multilayer Perceptron</span></span>
</span>
</td>
</tr>
<tr id="S1.T1.2.12.11" class="ltx_tr">
<td id="S1.T1.2.12.11.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t">
<span id="S1.T1.2.12.11.1.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.12.11.1.1.1" class="ltx_p" style="width:51.2pt;"><span id="S1.T1.2.12.11.1.1.1.1" class="ltx_text" style="font-size:90%;">ITS</span></span>
</span>
</td>
<td id="S1.T1.2.12.11.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S1.T1.2.12.11.2.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.12.11.2.1.1" class="ltx_p" style="width:148.0pt;"><span id="S1.T1.2.12.11.2.1.1.1" class="ltx_text" style="font-size:90%;">Intelligent Transport Systems</span></span>
</span>
</td>
</tr>
<tr id="S1.T1.2.13.12" class="ltx_tr">
<td id="S1.T1.2.13.12.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t">
<span id="S1.T1.2.13.12.1.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.13.12.1.1.1" class="ltx_p" style="width:51.2pt;"><span id="S1.T1.2.13.12.1.1.1.1" class="ltx_text" style="font-size:90%;">IoT</span></span>
</span>
</td>
<td id="S1.T1.2.13.12.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S1.T1.2.13.12.2.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.13.12.2.1.1" class="ltx_p" style="width:148.0pt;"><span id="S1.T1.2.13.12.2.1.1.1" class="ltx_text" style="font-size:90%;">Internet of Things</span></span>
</span>
</td>
</tr>
<tr id="S1.T1.2.14.13" class="ltx_tr">
<td id="S1.T1.2.14.13.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t">
<span id="S1.T1.2.14.13.1.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.14.13.1.1.1" class="ltx_p" style="width:51.2pt;"><span id="S1.T1.2.14.13.1.1.1.1" class="ltx_text" style="font-size:90%;">LSTM</span></span>
</span>
</td>
<td id="S1.T1.2.14.13.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S1.T1.2.14.13.2.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.14.13.2.1.1" class="ltx_p" style="width:148.0pt;"><span id="S1.T1.2.14.13.2.1.1.1" class="ltx_text" style="font-size:90%;">Long Short Term Memory</span></span>
</span>
</td>
</tr>
<tr id="S1.T1.2.15.14" class="ltx_tr">
<td id="S1.T1.2.15.14.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t">
<span id="S1.T1.2.15.14.1.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.15.14.1.1.1" class="ltx_p" style="width:51.2pt;"><span id="S1.T1.2.15.14.1.1.1.1" class="ltx_text" style="font-size:90%;">TFF</span></span>
</span>
</td>
<td id="S1.T1.2.15.14.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S1.T1.2.15.14.2.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.15.14.2.1.1" class="ltx_p" style="width:148.0pt;"><span id="S1.T1.2.15.14.2.1.1.1" class="ltx_text" style="font-size:90%;">TensorFlow Federated</span></span>
</span>
</td>
</tr>
<tr id="S1.T1.2.16.15" class="ltx_tr">
<td id="S1.T1.2.16.15.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_l ltx_border_r ltx_border_t">
<span id="S1.T1.2.16.15.1.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.16.15.1.1.1" class="ltx_p" style="width:51.2pt;"><span id="S1.T1.2.16.15.1.1.1.1" class="ltx_text" style="font-size:90%;">SGD</span></span>
</span>
</td>
<td id="S1.T1.2.16.15.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r ltx_border_t">
<span id="S1.T1.2.16.15.2.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.16.15.2.1.1" class="ltx_p" style="width:148.0pt;"><span id="S1.T1.2.16.15.2.1.1.1" class="ltx_text" style="font-size:90%;">Stochastic Gradient Descent</span></span>
</span>
</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S1.T1.3.1.1" class="ltx_text" style="font-size:90%;">TABLE I</span>: </span><span id="S1.T1.4.2" class="ltx_text" style="font-size:90%;">List of Notations and Common Abbreviations</span></figcaption>
</figure>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">II </span><span id="S2.1.1" class="ltx_text ltx_font_smallcaps">Fundamentals of Federated Learning</span>
</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">In this section, we highlight the characteristics, challenges, existing frameworks and the state-of-the art algorithms of FL.</p>
</div>
<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS1.4.1.1" class="ltx_text">II-A</span> </span><span id="S2.SS1.5.2" class="ltx_text ltx_font_italic">Federated Learning Challenges</span>
</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">In this subsection, we identify the unique and challenging characteristics of FL which distinguish it from the conventional distributed learning approaches. These characteristics are listed below:</p>
</div>
<div id="S2.SS1.p2" class="ltx_para">
<ul id="S2.I1" class="ltx_itemize">
<li id="S2.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i1.p1" class="ltx_para">
<p id="S2.I1.i1.p1.1" class="ltx_p"><span id="S2.I1.i1.p1.1.1" class="ltx_text ltx_font_bold">Non-IID Data:</span> data on the participant devices are collected by the devices themselves so there is a huge possibility of different data distributions among all the participants as each individual participant device collects the data based on its personal usage pattern and its local environment which might be different from other participants <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>.</p>
</div>
</li>
<li id="S2.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i2.p1" class="ltx_para">
<p id="S2.I1.i2.p1.1" class="ltx_p"><span id="S2.I1.i2.p1.1.1" class="ltx_text ltx_font_bold">Number of Clients:</span> collaborative learning models are evaluated based on the number of participants and the available data which are essential for FL. In this context, client participation is a big challenge as clients often denies to participate in the training due to various reasons, e.g., poor connection, limited battery, or no interest in collaborative training <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>. Therefore, guaranteeing the participation in FL needs to be solved.</p>
</div>
</li>
<li id="S2.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i3.p1" class="ltx_para">
<p id="S2.I1.i3.p1.1" class="ltx_p"><span id="S2.I1.i3.p1.1.1" class="ltx_text ltx_font_bold">Parameter Server:</span> after exceeding a certain threshold, the increasing number of clients becomes infeasible because of linear growth in the workload of communication and aggregation. Therefore, it is much needed to communicate via a parameter server in FL. Using this parameter server, communication rounds reduce to single round for participants and the server. Moreover, it reduces the communication cost per client. However, communication through parameter server remains a challenge for communication-efficient distributed training because the upload and download to/from the server require efficient compression in order to reduce communication-cost, time and energy consumption.</p>
</div>
</li>
<li id="S2.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i4.p1" class="ltx_para">
<p id="S2.I1.i4.p1.1" class="ltx_p"><span id="S2.I1.i4.p1.1.1" class="ltx_text ltx_font_bold">Limitations in Battery and Memory:</span> clients in the FL are usually the mobile devices which often have limited battery capacities. However, each single iteration of Stochastic Gradient Descent (SGD) in order to train Deep Neural Networks (DNN) is quite expensive in terms of battery cost. Therefore, it is necessary to use a small number of iterations during SGD evaluation. Moreover, the size of memory on mobile devices are so limited that it might be impossible to memorise all the processed samples during training because the footprint of SGD grows linearly with batch size <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>.</p>
</div>
</li>
</ul>
</div>
<div id="S2.SS1.p3" class="ltx_para">
<p id="S2.SS1.p3.1" class="ltx_p">In summary, the aforementioned characteristics of FL require consideration when designing communication-efficient distributed training algorithms.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS2.4.1.1" class="ltx_text">II-B</span> </span><span id="S2.SS2.5.2" class="ltx_text ltx_font_italic">Federated Learning Frameworks</span>
</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">Among the various FL frameworks, some of the open-source frameworks are developed for the implementation of FL algorithms as follows:</p>
</div>
<div id="S2.SS2.p2" class="ltx_para">
<ol id="S2.I2" class="ltx_enumerate">
<li id="S2.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S2.I2.i1.p1" class="ltx_para">
<p id="S2.I2.i1.p1.1" class="ltx_p"><span id="S2.I2.i1.p1.1.1" class="ltx_text ltx_font_bold">TensorFlow Federated (TFF):</span> TFF is an open-source framework for ML and similar computation on decentralised data. TFF is developed by Google to enable researchers to experiment in FL. The interface of TFF consists of the following two layers; Federated Learning (FL) and Federated Core (FC).</p>
</div>
<div id="S2.I2.i1.p2" class="ltx_para">
<p id="S2.I2.i1.p2.1" class="ltx_p">1) FL (API): in this layer, users are not required to apply their own FL algorithms instead it offers a high-level interface that allows users to implement FL using the existing models of TF.</p>
</div>
<div id="S2.I2.i1.p3" class="ltx_para">
<p id="S2.I2.i1.p3.1" class="ltx_p">2) FC (API): in this layer, users can implement their personal FL algorithms using a lower-level interface which combines TF with distributed communication operators.</p>
</div>
<div id="S2.I2.i1.p4" class="ltx_para">
<p id="S2.I2.i1.p4.1" class="ltx_p">In addition, developers are enabled to express federated-computation in TFF for diverse runtime-environments <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>.</p>
</div>
</li>
<li id="S2.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S2.I2.i2.p1" class="ltx_para">
<p id="S2.I2.i2.p1.1" class="ltx_p"><span id="S2.I2.i2.p1.1.1" class="ltx_text ltx_font_bold">PySyft:</span> PySyft is an open source library based on PyTorch for the implementation of FL algorithms which allows developers to train their models in untrusted environments with complete features of security. Retaining the native Torch interface, PySyft execute all the tensor operations in a similar fashion as in PyTorch. Apart from the FL, PySyft leverages other useful techniques in ML e.g., secure multi-party computation and differential privacy <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>.</p>
</div>
<figure id="alg1" class="ltx_float ltx_algorithm">
<div id="alg1.32" class="ltx_listing ltx_lst_numbers_left ltx_listing">
<div id="alg1.32.33" class="ltx_listingline">


</div>
<div id="alg1.1.1" class="ltx_listingline">
<span id="alg1.1.1.1" class="ltx_text ltx_font_bold">Input :</span> Mini-batch size (B), Participants (k), Participants per epoch (m), Total epochs (E) and Learning rate <math id="alg1.1.1.m1.1" class="ltx_Math" alttext="\eta" display="inline"><semantics id="alg1.1.1.m1.1a"><mi id="alg1.1.1.m1.1.1" xref="alg1.1.1.m1.1.1.cmml">η</mi><annotation-xml encoding="MathML-Content" id="alg1.1.1.m1.1b"><ci id="alg1.1.1.m1.1.1.cmml" xref="alg1.1.1.m1.1.1">𝜂</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.1.1.m1.1c">\eta</annotation></semantics></math>
</div>
<div id="alg1.2.2" class="ltx_listingline">
<span id="alg1.2.2.1" class="ltx_text ltx_font_bold">Output :</span> Global model <math id="alg1.2.2.m1.1" class="ltx_Math" alttext="W_{GM}" display="inline"><semantics id="alg1.2.2.m1.1a"><msub id="alg1.2.2.m1.1.1" xref="alg1.2.2.m1.1.1.cmml"><mi id="alg1.2.2.m1.1.1.2" xref="alg1.2.2.m1.1.1.2.cmml">W</mi><mrow id="alg1.2.2.m1.1.1.3" xref="alg1.2.2.m1.1.1.3.cmml"><mi id="alg1.2.2.m1.1.1.3.2" xref="alg1.2.2.m1.1.1.3.2.cmml">G</mi><mo lspace="0em" rspace="0em" id="alg1.2.2.m1.1.1.3.1" xref="alg1.2.2.m1.1.1.3.1.cmml">​</mo><mi id="alg1.2.2.m1.1.1.3.3" xref="alg1.2.2.m1.1.1.3.3.cmml">M</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="alg1.2.2.m1.1b"><apply id="alg1.2.2.m1.1.1.cmml" xref="alg1.2.2.m1.1.1"><csymbol cd="ambiguous" id="alg1.2.2.m1.1.1.1.cmml" xref="alg1.2.2.m1.1.1">subscript</csymbol><ci id="alg1.2.2.m1.1.1.2.cmml" xref="alg1.2.2.m1.1.1.2">𝑊</ci><apply id="alg1.2.2.m1.1.1.3.cmml" xref="alg1.2.2.m1.1.1.3"><times id="alg1.2.2.m1.1.1.3.1.cmml" xref="alg1.2.2.m1.1.1.3.1"></times><ci id="alg1.2.2.m1.1.1.3.2.cmml" xref="alg1.2.2.m1.1.1.3.2">𝐺</ci><ci id="alg1.2.2.m1.1.1.3.3.cmml" xref="alg1.2.2.m1.1.1.3.3">𝑀</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.2.2.m1.1c">W_{GM}</annotation></semantics></math>
</div>
<div id="alg1.32.34" class="ltx_listingline">
<span id="alg1.32.34.1" class="ltx_text ltx_font_bold">Server Execution:</span> 
</div>
<div id="alg1.3.3" class="ltx_listingline">
<span id="alg1.3.3.1" class="ltx_text ltx_font_bold">Initialize</span> <math id="alg1.3.3.m1.1" class="ltx_Math" alttext="W_{GM}" display="inline"><semantics id="alg1.3.3.m1.1a"><msub id="alg1.3.3.m1.1.1" xref="alg1.3.3.m1.1.1.cmml"><mi id="alg1.3.3.m1.1.1.2" xref="alg1.3.3.m1.1.1.2.cmml">W</mi><mrow id="alg1.3.3.m1.1.1.3" xref="alg1.3.3.m1.1.1.3.cmml"><mi id="alg1.3.3.m1.1.1.3.2" xref="alg1.3.3.m1.1.1.3.2.cmml">G</mi><mo lspace="0em" rspace="0em" id="alg1.3.3.m1.1.1.3.1" xref="alg1.3.3.m1.1.1.3.1.cmml">​</mo><mi id="alg1.3.3.m1.1.1.3.3" xref="alg1.3.3.m1.1.1.3.3.cmml">M</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="alg1.3.3.m1.1b"><apply id="alg1.3.3.m1.1.1.cmml" xref="alg1.3.3.m1.1.1"><csymbol cd="ambiguous" id="alg1.3.3.m1.1.1.1.cmml" xref="alg1.3.3.m1.1.1">subscript</csymbol><ci id="alg1.3.3.m1.1.1.2.cmml" xref="alg1.3.3.m1.1.1.2">𝑊</ci><apply id="alg1.3.3.m1.1.1.3.cmml" xref="alg1.3.3.m1.1.1.3"><times id="alg1.3.3.m1.1.1.3.1.cmml" xref="alg1.3.3.m1.1.1.3.1"></times><ci id="alg1.3.3.m1.1.1.3.2.cmml" xref="alg1.3.3.m1.1.1.3.2">𝐺</ci><ci id="alg1.3.3.m1.1.1.3.3.cmml" xref="alg1.3.3.m1.1.1.3.3">𝑀</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.3.3.m1.1c">W_{GM}</annotation></semantics></math>: 
</div>
<div id="alg1.32.35" class="ltx_listingline">

</div>
<div id="alg1.4.4" class="ltx_listingline">
<span id="alg1.4.4.2" class="ltx_text ltx_font_bold">for</span> <em id="alg1.4.4.1" class="ltx_emph ltx_font_italic">each epoch = <math id="alg1.4.4.1.m1.3" class="ltx_Math" alttext="1,2,3...N" display="inline"><semantics id="alg1.4.4.1.m1.3a"><mrow id="alg1.4.4.1.m1.3.3.1" xref="alg1.4.4.1.m1.3.3.2.cmml"><mn id="alg1.4.4.1.m1.1.1" xref="alg1.4.4.1.m1.1.1.cmml">1</mn><mo id="alg1.4.4.1.m1.3.3.1.2" xref="alg1.4.4.1.m1.3.3.2.cmml">,</mo><mn id="alg1.4.4.1.m1.2.2" xref="alg1.4.4.1.m1.2.2.cmml">2</mn><mo id="alg1.4.4.1.m1.3.3.1.3" xref="alg1.4.4.1.m1.3.3.2.cmml">,</mo><mrow id="alg1.4.4.1.m1.3.3.1.1" xref="alg1.4.4.1.m1.3.3.1.1.cmml"><mn id="alg1.4.4.1.m1.3.3.1.1.2" xref="alg1.4.4.1.m1.3.3.1.1.2.cmml">3</mn><mo lspace="0em" rspace="0em" id="alg1.4.4.1.m1.3.3.1.1.1" xref="alg1.4.4.1.m1.3.3.1.1.1.cmml">​</mo><mi mathvariant="normal" id="alg1.4.4.1.m1.3.3.1.1.3" xref="alg1.4.4.1.m1.3.3.1.1.3.cmml">…</mi><mo lspace="0em" rspace="0em" id="alg1.4.4.1.m1.3.3.1.1.1a" xref="alg1.4.4.1.m1.3.3.1.1.1.cmml">​</mo><mi id="alg1.4.4.1.m1.3.3.1.1.4" xref="alg1.4.4.1.m1.3.3.1.1.4.cmml">N</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.4.4.1.m1.3b"><list id="alg1.4.4.1.m1.3.3.2.cmml" xref="alg1.4.4.1.m1.3.3.1"><cn type="integer" id="alg1.4.4.1.m1.1.1.cmml" xref="alg1.4.4.1.m1.1.1">1</cn><cn type="integer" id="alg1.4.4.1.m1.2.2.cmml" xref="alg1.4.4.1.m1.2.2">2</cn><apply id="alg1.4.4.1.m1.3.3.1.1.cmml" xref="alg1.4.4.1.m1.3.3.1.1"><times id="alg1.4.4.1.m1.3.3.1.1.1.cmml" xref="alg1.4.4.1.m1.3.3.1.1.1"></times><cn type="integer" id="alg1.4.4.1.m1.3.3.1.1.2.cmml" xref="alg1.4.4.1.m1.3.3.1.1.2">3</cn><ci id="alg1.4.4.1.m1.3.3.1.1.3.cmml" xref="alg1.4.4.1.m1.3.3.1.1.3">…</ci><ci id="alg1.4.4.1.m1.3.3.1.1.4.cmml" xref="alg1.4.4.1.m1.3.3.1.1.4">𝑁</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="alg1.4.4.1.m1.3c">1,2,3...N</annotation></semantics></math> </em> <span id="alg1.4.4.3" class="ltx_text ltx_font_bold">do</span> 
</div>
<div id="alg1.7.7" class="ltx_listingline">  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   
Random subset <math id="alg1.5.5.m1.1" class="ltx_Math" alttext="S_{t}" display="inline"><semantics id="alg1.5.5.m1.1a"><msub id="alg1.5.5.m1.1.1" xref="alg1.5.5.m1.1.1.cmml"><mi id="alg1.5.5.m1.1.1.2" xref="alg1.5.5.m1.1.1.2.cmml">S</mi><mi id="alg1.5.5.m1.1.1.3" xref="alg1.5.5.m1.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="alg1.5.5.m1.1b"><apply id="alg1.5.5.m1.1.1.cmml" xref="alg1.5.5.m1.1.1"><csymbol cd="ambiguous" id="alg1.5.5.m1.1.1.1.cmml" xref="alg1.5.5.m1.1.1">subscript</csymbol><ci id="alg1.5.5.m1.1.1.2.cmml" xref="alg1.5.5.m1.1.1.2">𝑆</ci><ci id="alg1.5.5.m1.1.1.3.cmml" xref="alg1.5.5.m1.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.5.5.m1.1c">S_{t}</annotation></semantics></math> of <math id="alg1.6.6.m2.1" class="ltx_Math" alttext="m" display="inline"><semantics id="alg1.6.6.m2.1a"><mi id="alg1.6.6.m2.1.1" xref="alg1.6.6.m2.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="alg1.6.6.m2.1b"><ci id="alg1.6.6.m2.1.1.cmml" xref="alg1.6.6.m2.1.1">𝑚</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.6.6.m2.1c">m</annotation></semantics></math> participants from <math id="alg1.7.7.m3.1" class="ltx_Math" alttext="k" display="inline"><semantics id="alg1.7.7.m3.1a"><mi id="alg1.7.7.m3.1.1" xref="alg1.7.7.m3.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="alg1.7.7.m3.1b"><ci id="alg1.7.7.m3.1.1.cmml" xref="alg1.7.7.m3.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.7.7.m3.1c">k</annotation></semantics></math> participants 
</div>
<div id="alg1.32.36" class="ltx_listingline">  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   

</div>
<div id="alg1.32.37" class="ltx_listingline"> end for
</div>
<div id="alg1.10.10" class="ltx_listingline">
<span id="alg1.10.10.4" class="ltx_text ltx_font_bold">for</span> <em id="alg1.10.10.3" class="ltx_emph ltx_font_italic">every particpant <math id="alg1.8.8.1.m1.1" class="ltx_Math" alttext="w" display="inline"><semantics id="alg1.8.8.1.m1.1a"><mi id="alg1.8.8.1.m1.1.1" xref="alg1.8.8.1.m1.1.1.cmml">w</mi><annotation-xml encoding="MathML-Content" id="alg1.8.8.1.m1.1b"><ci id="alg1.8.8.1.m1.1.1.cmml" xref="alg1.8.8.1.m1.1.1">𝑤</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.8.8.1.m1.1c">w</annotation></semantics></math> <math id="alg1.9.9.2.m2.1" class="ltx_Math" alttext="\in" display="inline"><semantics id="alg1.9.9.2.m2.1a"><mo id="alg1.9.9.2.m2.1.1" xref="alg1.9.9.2.m2.1.1.cmml">∈</mo><annotation-xml encoding="MathML-Content" id="alg1.9.9.2.m2.1b"><in id="alg1.9.9.2.m2.1.1.cmml" xref="alg1.9.9.2.m2.1.1"></in></annotation-xml><annotation encoding="application/x-tex" id="alg1.9.9.2.m2.1c">\in</annotation></semantics></math> <math id="alg1.10.10.3.m3.1" class="ltx_Math" alttext="S_{t}" display="inline"><semantics id="alg1.10.10.3.m3.1a"><msub id="alg1.10.10.3.m3.1.1" xref="alg1.10.10.3.m3.1.1.cmml"><mi id="alg1.10.10.3.m3.1.1.2" xref="alg1.10.10.3.m3.1.1.2.cmml">S</mi><mi id="alg1.10.10.3.m3.1.1.3" xref="alg1.10.10.3.m3.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="alg1.10.10.3.m3.1b"><apply id="alg1.10.10.3.m3.1.1.cmml" xref="alg1.10.10.3.m3.1.1"><csymbol cd="ambiguous" id="alg1.10.10.3.m3.1.1.1.cmml" xref="alg1.10.10.3.m3.1.1">subscript</csymbol><ci id="alg1.10.10.3.m3.1.1.2.cmml" xref="alg1.10.10.3.m3.1.1.2">𝑆</ci><ci id="alg1.10.10.3.m3.1.1.3.cmml" xref="alg1.10.10.3.m3.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.10.10.3.m3.1c">S_{t}</annotation></semantics></math> <span id="alg1.10.10.3.1" class="ltx_text ltx_font_bold">parallely</span></em> <span id="alg1.10.10.5" class="ltx_text ltx_font_bold">do</span> 
</div>
<div id="alg1.13.13" class="ltx_listingline">  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   
<math id="alg1.11.11.m1.1" class="ltx_Math" alttext="{w_{GM}}^{t+1}_{k}" display="inline"><semantics id="alg1.11.11.m1.1a"><mmultiscripts id="alg1.11.11.m1.1.1" xref="alg1.11.11.m1.1.1.cmml"><mi id="alg1.11.11.m1.1.1.2.2.2" xref="alg1.11.11.m1.1.1.2.2.2.cmml">w</mi><mrow id="alg1.11.11.m1.1.1.2.2.3" xref="alg1.11.11.m1.1.1.2.2.3.cmml"><mi id="alg1.11.11.m1.1.1.2.2.3.2" xref="alg1.11.11.m1.1.1.2.2.3.2.cmml">G</mi><mo lspace="0em" rspace="0em" id="alg1.11.11.m1.1.1.2.2.3.1" xref="alg1.11.11.m1.1.1.2.2.3.1.cmml">​</mo><mi id="alg1.11.11.m1.1.1.2.2.3.3" xref="alg1.11.11.m1.1.1.2.2.3.3.cmml">M</mi></mrow><mrow id="alg1.11.11.m1.1.1a" xref="alg1.11.11.m1.1.1.cmml"></mrow><mi id="alg1.11.11.m1.1.1.3" xref="alg1.11.11.m1.1.1.3.cmml">k</mi><mrow id="alg1.11.11.m1.1.1.2.3" xref="alg1.11.11.m1.1.1.2.3.cmml"><mi id="alg1.11.11.m1.1.1.2.3.2" xref="alg1.11.11.m1.1.1.2.3.2.cmml">t</mi><mo id="alg1.11.11.m1.1.1.2.3.1" xref="alg1.11.11.m1.1.1.2.3.1.cmml">+</mo><mn id="alg1.11.11.m1.1.1.2.3.3" xref="alg1.11.11.m1.1.1.2.3.3.cmml">1</mn></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="alg1.11.11.m1.1b"><apply id="alg1.11.11.m1.1.1.cmml" xref="alg1.11.11.m1.1.1"><csymbol cd="ambiguous" id="alg1.11.11.m1.1.1.1.cmml" xref="alg1.11.11.m1.1.1">subscript</csymbol><apply id="alg1.11.11.m1.1.1.2.cmml" xref="alg1.11.11.m1.1.1"><csymbol cd="ambiguous" id="alg1.11.11.m1.1.1.2.1.cmml" xref="alg1.11.11.m1.1.1">superscript</csymbol><apply id="alg1.11.11.m1.1.1.2.2.cmml" xref="alg1.11.11.m1.1.1"><csymbol cd="ambiguous" id="alg1.11.11.m1.1.1.2.2.1.cmml" xref="alg1.11.11.m1.1.1">subscript</csymbol><ci id="alg1.11.11.m1.1.1.2.2.2.cmml" xref="alg1.11.11.m1.1.1.2.2.2">𝑤</ci><apply id="alg1.11.11.m1.1.1.2.2.3.cmml" xref="alg1.11.11.m1.1.1.2.2.3"><times id="alg1.11.11.m1.1.1.2.2.3.1.cmml" xref="alg1.11.11.m1.1.1.2.2.3.1"></times><ci id="alg1.11.11.m1.1.1.2.2.3.2.cmml" xref="alg1.11.11.m1.1.1.2.2.3.2">𝐺</ci><ci id="alg1.11.11.m1.1.1.2.2.3.3.cmml" xref="alg1.11.11.m1.1.1.2.2.3.3">𝑀</ci></apply></apply><apply id="alg1.11.11.m1.1.1.2.3.cmml" xref="alg1.11.11.m1.1.1.2.3"><plus id="alg1.11.11.m1.1.1.2.3.1.cmml" xref="alg1.11.11.m1.1.1.2.3.1"></plus><ci id="alg1.11.11.m1.1.1.2.3.2.cmml" xref="alg1.11.11.m1.1.1.2.3.2">𝑡</ci><cn type="integer" id="alg1.11.11.m1.1.1.2.3.3.cmml" xref="alg1.11.11.m1.1.1.2.3.3">1</cn></apply></apply><ci id="alg1.11.11.m1.1.1.3.cmml" xref="alg1.11.11.m1.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.11.11.m1.1c">{w_{GM}}^{t+1}_{k}</annotation></semantics></math> <math id="alg1.12.12.m2.1" class="ltx_Math" alttext="\leftarrow" display="inline"><semantics id="alg1.12.12.m2.1a"><mo stretchy="false" id="alg1.12.12.m2.1.1" xref="alg1.12.12.m2.1.1.cmml">←</mo><annotation-xml encoding="MathML-Content" id="alg1.12.12.m2.1b"><ci id="alg1.12.12.m2.1.1.cmml" xref="alg1.12.12.m2.1.1">←</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.12.12.m2.1c">\leftarrow</annotation></semantics></math> <span id="alg1.13.13.1" class="ltx_text ltx_font_bold">ClientTrainingUpdate</span>(<math id="alg1.13.13.m3.2" class="ltx_Math" alttext="k,w_{GM}" display="inline"><semantics id="alg1.13.13.m3.2a"><mrow id="alg1.13.13.m3.2.2.1" xref="alg1.13.13.m3.2.2.2.cmml"><mi id="alg1.13.13.m3.1.1" xref="alg1.13.13.m3.1.1.cmml">k</mi><mo id="alg1.13.13.m3.2.2.1.2" xref="alg1.13.13.m3.2.2.2.cmml">,</mo><msub id="alg1.13.13.m3.2.2.1.1" xref="alg1.13.13.m3.2.2.1.1.cmml"><mi id="alg1.13.13.m3.2.2.1.1.2" xref="alg1.13.13.m3.2.2.1.1.2.cmml">w</mi><mrow id="alg1.13.13.m3.2.2.1.1.3" xref="alg1.13.13.m3.2.2.1.1.3.cmml"><mi id="alg1.13.13.m3.2.2.1.1.3.2" xref="alg1.13.13.m3.2.2.1.1.3.2.cmml">G</mi><mo lspace="0em" rspace="0em" id="alg1.13.13.m3.2.2.1.1.3.1" xref="alg1.13.13.m3.2.2.1.1.3.1.cmml">​</mo><mi id="alg1.13.13.m3.2.2.1.1.3.3" xref="alg1.13.13.m3.2.2.1.1.3.3.cmml">M</mi></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="alg1.13.13.m3.2b"><list id="alg1.13.13.m3.2.2.2.cmml" xref="alg1.13.13.m3.2.2.1"><ci id="alg1.13.13.m3.1.1.cmml" xref="alg1.13.13.m3.1.1">𝑘</ci><apply id="alg1.13.13.m3.2.2.1.1.cmml" xref="alg1.13.13.m3.2.2.1.1"><csymbol cd="ambiguous" id="alg1.13.13.m3.2.2.1.1.1.cmml" xref="alg1.13.13.m3.2.2.1.1">subscript</csymbol><ci id="alg1.13.13.m3.2.2.1.1.2.cmml" xref="alg1.13.13.m3.2.2.1.1.2">𝑤</ci><apply id="alg1.13.13.m3.2.2.1.1.3.cmml" xref="alg1.13.13.m3.2.2.1.1.3"><times id="alg1.13.13.m3.2.2.1.1.3.1.cmml" xref="alg1.13.13.m3.2.2.1.1.3.1"></times><ci id="alg1.13.13.m3.2.2.1.1.3.2.cmml" xref="alg1.13.13.m3.2.2.1.1.3.2">𝐺</ci><ci id="alg1.13.13.m3.2.2.1.1.3.3.cmml" xref="alg1.13.13.m3.2.2.1.1.3.3">𝑀</ci></apply></apply></list></annotation-xml><annotation encoding="application/x-tex" id="alg1.13.13.m3.2c">k,w_{GM}</annotation></semantics></math>)

</div>
<div id="alg1.32.38" class="ltx_listingline"> end for
</div>
<div id="alg1.18.18" class="ltx_listingline">
<math id="alg1.14.14.m1.1" class="ltx_Math" alttext="w_{t+1}" display="inline"><semantics id="alg1.14.14.m1.1a"><msub id="alg1.14.14.m1.1.1" xref="alg1.14.14.m1.1.1.cmml"><mi id="alg1.14.14.m1.1.1.2" xref="alg1.14.14.m1.1.1.2.cmml">w</mi><mrow id="alg1.14.14.m1.1.1.3" xref="alg1.14.14.m1.1.1.3.cmml"><mi id="alg1.14.14.m1.1.1.3.2" xref="alg1.14.14.m1.1.1.3.2.cmml">t</mi><mo id="alg1.14.14.m1.1.1.3.1" xref="alg1.14.14.m1.1.1.3.1.cmml">+</mo><mn id="alg1.14.14.m1.1.1.3.3" xref="alg1.14.14.m1.1.1.3.3.cmml">1</mn></mrow></msub><annotation-xml encoding="MathML-Content" id="alg1.14.14.m1.1b"><apply id="alg1.14.14.m1.1.1.cmml" xref="alg1.14.14.m1.1.1"><csymbol cd="ambiguous" id="alg1.14.14.m1.1.1.1.cmml" xref="alg1.14.14.m1.1.1">subscript</csymbol><ci id="alg1.14.14.m1.1.1.2.cmml" xref="alg1.14.14.m1.1.1.2">𝑤</ci><apply id="alg1.14.14.m1.1.1.3.cmml" xref="alg1.14.14.m1.1.1.3"><plus id="alg1.14.14.m1.1.1.3.1.cmml" xref="alg1.14.14.m1.1.1.3.1"></plus><ci id="alg1.14.14.m1.1.1.3.2.cmml" xref="alg1.14.14.m1.1.1.3.2">𝑡</ci><cn type="integer" id="alg1.14.14.m1.1.1.3.3.cmml" xref="alg1.14.14.m1.1.1.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.14.14.m1.1c">w_{t+1}</annotation></semantics></math> <math id="alg1.15.15.m2.1" class="ltx_Math" alttext="\leftarrow" display="inline"><semantics id="alg1.15.15.m2.1a"><mo stretchy="false" id="alg1.15.15.m2.1.1" xref="alg1.15.15.m2.1.1.cmml">←</mo><annotation-xml encoding="MathML-Content" id="alg1.15.15.m2.1b"><ci id="alg1.15.15.m2.1.1.cmml" xref="alg1.15.15.m2.1.1">←</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.15.15.m2.1c">\leftarrow</annotation></semantics></math> <math id="alg1.16.16.m3.1" class="ltx_Math" alttext="\sum_{1}^{k}" display="inline"><semantics id="alg1.16.16.m3.1a"><msubsup id="alg1.16.16.m3.1.1" xref="alg1.16.16.m3.1.1.cmml"><mo id="alg1.16.16.m3.1.1.2.2" xref="alg1.16.16.m3.1.1.2.2.cmml">∑</mo><mn id="alg1.16.16.m3.1.1.2.3" xref="alg1.16.16.m3.1.1.2.3.cmml">1</mn><mi id="alg1.16.16.m3.1.1.3" xref="alg1.16.16.m3.1.1.3.cmml">k</mi></msubsup><annotation-xml encoding="MathML-Content" id="alg1.16.16.m3.1b"><apply id="alg1.16.16.m3.1.1.cmml" xref="alg1.16.16.m3.1.1"><csymbol cd="ambiguous" id="alg1.16.16.m3.1.1.1.cmml" xref="alg1.16.16.m3.1.1">superscript</csymbol><apply id="alg1.16.16.m3.1.1.2.cmml" xref="alg1.16.16.m3.1.1"><csymbol cd="ambiguous" id="alg1.16.16.m3.1.1.2.1.cmml" xref="alg1.16.16.m3.1.1">subscript</csymbol><sum id="alg1.16.16.m3.1.1.2.2.cmml" xref="alg1.16.16.m3.1.1.2.2"></sum><cn type="integer" id="alg1.16.16.m3.1.1.2.3.cmml" xref="alg1.16.16.m3.1.1.2.3">1</cn></apply><ci id="alg1.16.16.m3.1.1.3.cmml" xref="alg1.16.16.m3.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.16.16.m3.1c">\sum_{1}^{k}</annotation></semantics></math> <math id="alg1.17.17.m4.1" class="ltx_Math" alttext="\frac{m_{k}}{m}" display="inline"><semantics id="alg1.17.17.m4.1a"><mfrac id="alg1.17.17.m4.1.1" xref="alg1.17.17.m4.1.1.cmml"><msub id="alg1.17.17.m4.1.1.2" xref="alg1.17.17.m4.1.1.2.cmml"><mi id="alg1.17.17.m4.1.1.2.2" xref="alg1.17.17.m4.1.1.2.2.cmml">m</mi><mi id="alg1.17.17.m4.1.1.2.3" xref="alg1.17.17.m4.1.1.2.3.cmml">k</mi></msub><mi id="alg1.17.17.m4.1.1.3" xref="alg1.17.17.m4.1.1.3.cmml">m</mi></mfrac><annotation-xml encoding="MathML-Content" id="alg1.17.17.m4.1b"><apply id="alg1.17.17.m4.1.1.cmml" xref="alg1.17.17.m4.1.1"><divide id="alg1.17.17.m4.1.1.1.cmml" xref="alg1.17.17.m4.1.1"></divide><apply id="alg1.17.17.m4.1.1.2.cmml" xref="alg1.17.17.m4.1.1.2"><csymbol cd="ambiguous" id="alg1.17.17.m4.1.1.2.1.cmml" xref="alg1.17.17.m4.1.1.2">subscript</csymbol><ci id="alg1.17.17.m4.1.1.2.2.cmml" xref="alg1.17.17.m4.1.1.2.2">𝑚</ci><ci id="alg1.17.17.m4.1.1.2.3.cmml" xref="alg1.17.17.m4.1.1.2.3">𝑘</ci></apply><ci id="alg1.17.17.m4.1.1.3.cmml" xref="alg1.17.17.m4.1.1.3">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.17.17.m4.1c">\frac{m_{k}}{m}</annotation></semantics></math> <math id="alg1.18.18.m5.1" class="ltx_Math" alttext="{w_{GM}}^{t+1}_{k}" display="inline"><semantics id="alg1.18.18.m5.1a"><mmultiscripts id="alg1.18.18.m5.1.1" xref="alg1.18.18.m5.1.1.cmml"><mi id="alg1.18.18.m5.1.1.2.2.2" xref="alg1.18.18.m5.1.1.2.2.2.cmml">w</mi><mrow id="alg1.18.18.m5.1.1.2.2.3" xref="alg1.18.18.m5.1.1.2.2.3.cmml"><mi id="alg1.18.18.m5.1.1.2.2.3.2" xref="alg1.18.18.m5.1.1.2.2.3.2.cmml">G</mi><mo lspace="0em" rspace="0em" id="alg1.18.18.m5.1.1.2.2.3.1" xref="alg1.18.18.m5.1.1.2.2.3.1.cmml">​</mo><mi id="alg1.18.18.m5.1.1.2.2.3.3" xref="alg1.18.18.m5.1.1.2.2.3.3.cmml">M</mi></mrow><mrow id="alg1.18.18.m5.1.1a" xref="alg1.18.18.m5.1.1.cmml"></mrow><mi id="alg1.18.18.m5.1.1.3" xref="alg1.18.18.m5.1.1.3.cmml">k</mi><mrow id="alg1.18.18.m5.1.1.2.3" xref="alg1.18.18.m5.1.1.2.3.cmml"><mi id="alg1.18.18.m5.1.1.2.3.2" xref="alg1.18.18.m5.1.1.2.3.2.cmml">t</mi><mo id="alg1.18.18.m5.1.1.2.3.1" xref="alg1.18.18.m5.1.1.2.3.1.cmml">+</mo><mn id="alg1.18.18.m5.1.1.2.3.3" xref="alg1.18.18.m5.1.1.2.3.3.cmml">1</mn></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="alg1.18.18.m5.1b"><apply id="alg1.18.18.m5.1.1.cmml" xref="alg1.18.18.m5.1.1"><csymbol cd="ambiguous" id="alg1.18.18.m5.1.1.1.cmml" xref="alg1.18.18.m5.1.1">subscript</csymbol><apply id="alg1.18.18.m5.1.1.2.cmml" xref="alg1.18.18.m5.1.1"><csymbol cd="ambiguous" id="alg1.18.18.m5.1.1.2.1.cmml" xref="alg1.18.18.m5.1.1">superscript</csymbol><apply id="alg1.18.18.m5.1.1.2.2.cmml" xref="alg1.18.18.m5.1.1"><csymbol cd="ambiguous" id="alg1.18.18.m5.1.1.2.2.1.cmml" xref="alg1.18.18.m5.1.1">subscript</csymbol><ci id="alg1.18.18.m5.1.1.2.2.2.cmml" xref="alg1.18.18.m5.1.1.2.2.2">𝑤</ci><apply id="alg1.18.18.m5.1.1.2.2.3.cmml" xref="alg1.18.18.m5.1.1.2.2.3"><times id="alg1.18.18.m5.1.1.2.2.3.1.cmml" xref="alg1.18.18.m5.1.1.2.2.3.1"></times><ci id="alg1.18.18.m5.1.1.2.2.3.2.cmml" xref="alg1.18.18.m5.1.1.2.2.3.2">𝐺</ci><ci id="alg1.18.18.m5.1.1.2.2.3.3.cmml" xref="alg1.18.18.m5.1.1.2.2.3.3">𝑀</ci></apply></apply><apply id="alg1.18.18.m5.1.1.2.3.cmml" xref="alg1.18.18.m5.1.1.2.3"><plus id="alg1.18.18.m5.1.1.2.3.1.cmml" xref="alg1.18.18.m5.1.1.2.3.1"></plus><ci id="alg1.18.18.m5.1.1.2.3.2.cmml" xref="alg1.18.18.m5.1.1.2.3.2">𝑡</ci><cn type="integer" id="alg1.18.18.m5.1.1.2.3.3.cmml" xref="alg1.18.18.m5.1.1.2.3.3">1</cn></apply></apply><ci id="alg1.18.18.m5.1.1.3.cmml" xref="alg1.18.18.m5.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.18.18.m5.1c">{w_{GM}}^{t+1}_{k}</annotation></semantics></math> (Averaging Aggregation) 
</div>
<div id="alg1.32.39" class="ltx_listingline">
<span id="alg1.32.39.1" class="ltx_text ltx_font_bold">Client Update:</span> 
</div>
<div id="alg1.21.21" class="ltx_listingline">
<math id="alg1.19.19.m1.1" class="ltx_Math" alttext="\beta" display="inline"><semantics id="alg1.19.19.m1.1a"><mi id="alg1.19.19.m1.1.1" xref="alg1.19.19.m1.1.1.cmml">β</mi><annotation-xml encoding="MathML-Content" id="alg1.19.19.m1.1b"><ci id="alg1.19.19.m1.1.1.cmml" xref="alg1.19.19.m1.1.1">𝛽</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.19.19.m1.1c">\beta</annotation></semantics></math> <math id="alg1.20.20.m2.1" class="ltx_Math" alttext="\leftarrow" display="inline"><semantics id="alg1.20.20.m2.1a"><mo stretchy="false" id="alg1.20.20.m2.1.1" xref="alg1.20.20.m2.1.1.cmml">←</mo><annotation-xml encoding="MathML-Content" id="alg1.20.20.m2.1b"><ci id="alg1.20.20.m2.1.1.cmml" xref="alg1.20.20.m2.1.1">←</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.20.20.m2.1c">\leftarrow</annotation></semantics></math> mini-batches creates through splitting local datasets <math id="alg1.21.21.m3.1" class="ltx_Math" alttext="D_{L}" display="inline"><semantics id="alg1.21.21.m3.1a"><msub id="alg1.21.21.m3.1.1" xref="alg1.21.21.m3.1.1.cmml"><mi id="alg1.21.21.m3.1.1.2" xref="alg1.21.21.m3.1.1.2.cmml">D</mi><mi id="alg1.21.21.m3.1.1.3" xref="alg1.21.21.m3.1.1.3.cmml">L</mi></msub><annotation-xml encoding="MathML-Content" id="alg1.21.21.m3.1b"><apply id="alg1.21.21.m3.1.1.cmml" xref="alg1.21.21.m3.1.1"><csymbol cd="ambiguous" id="alg1.21.21.m3.1.1.1.cmml" xref="alg1.21.21.m3.1.1">subscript</csymbol><ci id="alg1.21.21.m3.1.1.2.cmml" xref="alg1.21.21.m3.1.1.2">𝐷</ci><ci id="alg1.21.21.m3.1.1.3.cmml" xref="alg1.21.21.m3.1.1.3">𝐿</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.21.21.m3.1c">D_{L}</annotation></semantics></math> 
</div>
<div id="alg1.24.24" class="ltx_listingline">
<span id="alg1.24.24.4" class="ltx_text ltx_font_bold">for</span> <em id="alg1.24.24.3" class="ltx_emph ltx_font_italic">each local epoch <math id="alg1.22.22.1.m1.1" class="ltx_Math" alttext="k" display="inline"><semantics id="alg1.22.22.1.m1.1a"><mi id="alg1.22.22.1.m1.1.1" xref="alg1.22.22.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="alg1.22.22.1.m1.1b"><ci id="alg1.22.22.1.m1.1.1.cmml" xref="alg1.22.22.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.22.22.1.m1.1c">k</annotation></semantics></math> from <math id="alg1.23.23.2.m2.1" class="ltx_Math" alttext="1" display="inline"><semantics id="alg1.23.23.2.m2.1a"><mn id="alg1.23.23.2.m2.1.1" xref="alg1.23.23.2.m2.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="alg1.23.23.2.m2.1b"><cn type="integer" id="alg1.23.23.2.m2.1.1.cmml" xref="alg1.23.23.2.m2.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="alg1.23.23.2.m2.1c">1</annotation></semantics></math> to <math id="alg1.24.24.3.m3.1" class="ltx_Math" alttext="E" display="inline"><semantics id="alg1.24.24.3.m3.1a"><mi id="alg1.24.24.3.m3.1.1" xref="alg1.24.24.3.m3.1.1.cmml">E</mi><annotation-xml encoding="MathML-Content" id="alg1.24.24.3.m3.1b"><ci id="alg1.24.24.3.m3.1.1.cmml" xref="alg1.24.24.3.m3.1.1">𝐸</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.24.24.3.m3.1c">E</annotation></semantics></math> </em> <span id="alg1.24.24.5" class="ltx_text ltx_font_bold">do</span> 
</div>
<div id="alg1.32.40" class="ltx_listingline">  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   

</div>
<div id="alg1.32.41" class="ltx_listingline"> end for
</div>
<div id="alg1.26.26" class="ltx_listingline">
<span id="alg1.26.26.3" class="ltx_text ltx_font_bold">for</span> <em id="alg1.26.26.2" class="ltx_emph ltx_font_italic">local mini-batch b <math id="alg1.25.25.1.m1.1" class="ltx_Math" alttext="\in" display="inline"><semantics id="alg1.25.25.1.m1.1a"><mo id="alg1.25.25.1.m1.1.1" xref="alg1.25.25.1.m1.1.1.cmml">∈</mo><annotation-xml encoding="MathML-Content" id="alg1.25.25.1.m1.1b"><in id="alg1.25.25.1.m1.1.1.cmml" xref="alg1.25.25.1.m1.1.1"></in></annotation-xml><annotation encoding="application/x-tex" id="alg1.25.25.1.m1.1c">\in</annotation></semantics></math> <math id="alg1.26.26.2.m2.1" class="ltx_Math" alttext="\beta" display="inline"><semantics id="alg1.26.26.2.m2.1a"><mi id="alg1.26.26.2.m2.1.1" xref="alg1.26.26.2.m2.1.1.cmml">β</mi><annotation-xml encoding="MathML-Content" id="alg1.26.26.2.m2.1b"><ci id="alg1.26.26.2.m2.1.1.cmml" xref="alg1.26.26.2.m2.1.1">𝛽</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.26.26.2.m2.1c">\beta</annotation></semantics></math></em> <span id="alg1.26.26.4" class="ltx_text ltx_font_bold">do</span> 
</div>
<div id="alg1.30.30" class="ltx_listingline">  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   
<math id="alg1.27.27.m1.1" class="ltx_Math" alttext="w_{GM}" display="inline"><semantics id="alg1.27.27.m1.1a"><msub id="alg1.27.27.m1.1.1" xref="alg1.27.27.m1.1.1.cmml"><mi id="alg1.27.27.m1.1.1.2" xref="alg1.27.27.m1.1.1.2.cmml">w</mi><mrow id="alg1.27.27.m1.1.1.3" xref="alg1.27.27.m1.1.1.3.cmml"><mi id="alg1.27.27.m1.1.1.3.2" xref="alg1.27.27.m1.1.1.3.2.cmml">G</mi><mo lspace="0em" rspace="0em" id="alg1.27.27.m1.1.1.3.1" xref="alg1.27.27.m1.1.1.3.1.cmml">​</mo><mi id="alg1.27.27.m1.1.1.3.3" xref="alg1.27.27.m1.1.1.3.3.cmml">M</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="alg1.27.27.m1.1b"><apply id="alg1.27.27.m1.1.1.cmml" xref="alg1.27.27.m1.1.1"><csymbol cd="ambiguous" id="alg1.27.27.m1.1.1.1.cmml" xref="alg1.27.27.m1.1.1">subscript</csymbol><ci id="alg1.27.27.m1.1.1.2.cmml" xref="alg1.27.27.m1.1.1.2">𝑤</ci><apply id="alg1.27.27.m1.1.1.3.cmml" xref="alg1.27.27.m1.1.1.3"><times id="alg1.27.27.m1.1.1.3.1.cmml" xref="alg1.27.27.m1.1.1.3.1"></times><ci id="alg1.27.27.m1.1.1.3.2.cmml" xref="alg1.27.27.m1.1.1.3.2">𝐺</ci><ci id="alg1.27.27.m1.1.1.3.3.cmml" xref="alg1.27.27.m1.1.1.3.3">𝑀</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.27.27.m1.1c">w_{GM}</annotation></semantics></math> <math id="alg1.28.28.m2.1" class="ltx_Math" alttext="\leftarrow" display="inline"><semantics id="alg1.28.28.m2.1a"><mo stretchy="false" id="alg1.28.28.m2.1.1" xref="alg1.28.28.m2.1.1.cmml">←</mo><annotation-xml encoding="MathML-Content" id="alg1.28.28.m2.1b"><ci id="alg1.28.28.m2.1.1.cmml" xref="alg1.28.28.m2.1.1">←</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.28.28.m2.1c">\leftarrow</annotation></semantics></math> <span id="alg1.30.30.1" class="ltx_text ltx_font_italic">w</span> – <math id="alg1.29.29.m3.1" class="ltx_Math" alttext="\eta" display="inline"><semantics id="alg1.29.29.m3.1a"><mi id="alg1.29.29.m3.1.1" xref="alg1.29.29.m3.1.1.cmml">η</mi><annotation-xml encoding="MathML-Content" id="alg1.29.29.m3.1b"><ci id="alg1.29.29.m3.1.1.cmml" xref="alg1.29.29.m3.1.1">𝜂</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.29.29.m3.1c">\eta</annotation></semantics></math><math id="alg1.30.30.m4.1" class="ltx_Math" alttext="\bigtriangleup" display="inline"><semantics id="alg1.30.30.m4.1a"><mo id="alg1.30.30.m4.1.1" xref="alg1.30.30.m4.1.1.cmml">△</mo><annotation-xml encoding="MathML-Content" id="alg1.30.30.m4.1b"><ci id="alg1.30.30.m4.1.1.cmml" xref="alg1.30.30.m4.1.1">△</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.30.30.m4.1c">\bigtriangleup</annotation></semantics></math><span id="alg1.30.30.2" class="ltx_text ltx_font_italic">l(w, b)</span> 
</div>
<div id="alg1.32.32" class="ltx_listingline">  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>    <span id="alg1.32.32.2" class="ltx_text ltx_font_bold ltx_font_italic">(<math id="alg1.31.31.1.m1.1" class="ltx_Math" alttext="\bigtriangleup" display="inline"><semantics id="alg1.31.31.1.m1.1a"><mo id="alg1.31.31.1.m1.1.1" xref="alg1.31.31.1.m1.1.1.cmml">△</mo><annotation-xml encoding="MathML-Content" id="alg1.31.31.1.m1.1b"><ci id="alg1.31.31.1.m1.1.1.cmml" xref="alg1.31.31.1.m1.1.1">△</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.31.31.1.m1.1c">\bigtriangleup</annotation></semantics></math>l is the gradient of l on b and <math id="alg1.32.32.2.m2.1" class="ltx_Math" alttext="\eta" display="inline"><semantics id="alg1.32.32.2.m2.1a"><mi mathvariant="normal" id="alg1.32.32.2.m2.1.1" xref="alg1.32.32.2.m2.1.1.cmml">η</mi><annotation-xml encoding="MathML-Content" id="alg1.32.32.2.m2.1b"><ci id="alg1.32.32.2.m2.1.1.cmml" xref="alg1.32.32.2.m2.1.1">η</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.32.32.2.m2.1c">\eta</annotation></semantics></math> is the learning rate)</span>

</div>
<div id="alg1.32.42" class="ltx_listingline"> end for
</div>
<div id="alg1.32.43" class="ltx_listingline">
</div>
<div id="alg1.32.44" class="ltx_listingline">
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_float"><span id="alg1.34.1.1" class="ltx_text ltx_font_bold">Algorithm 1</span> </span>Federated Averaging Algorithm <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite></figcaption>
</figure>
</li>
<li id="S2.I2.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="S2.I2.i3.p1" class="ltx_para">
<p id="S2.I2.i3.p1.1" class="ltx_p"><span id="S2.I2.i3.p1.1.1" class="ltx_text ltx_font_bold">LEAF:</span> LEAF is an open-source benchmark framework for FL that includes numerous datasets, e.g., FEMNIST, Sentiment140, Shakespeare, Celeba and Synthetic. In Federated Extended MNIST (FEMNIST) and Sentiment140 datasets, partitions are based on writer-of-each-character and different-users, respectively. The participants on these datasets in FL are assumed to be a writer or a user and the corresponding data will remain on each participant’s devices <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>.</p>
</div>
</li>
</ol>
</div>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS3.4.1.1" class="ltx_text">II-C</span> </span><span id="S2.SS3.5.2" class="ltx_text ltx_font_italic">Federated Learning Approaches</span>
</h3>

<div id="S2.SS3.p1" class="ltx_para">
<p id="S2.SS3.p1.1" class="ltx_p">In a typical ML system, optimisation algorithms like SGD require large datasets for efficient training over the cloud. Such iterative algorithms demand high-throughput and low latency connection for training. In case of FL, data is distributed over millions of devices in a heterogeneous manner. Moreover, those devices have significantly lower-throughput and higher-latency connections and intermittently ready for training. Motivated by latency and bandwidth limitations, Federated Averaging Algorithm (FedAvg) is proposed <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite> to overcome these issues. Pseudocode of FedAvg algorithm is shown in Algorithm 1.</p>
</div>
<div id="S2.SS3.p2" class="ltx_para">
<p id="S2.SS3.p2.1" class="ltx_p">FedAvg algorithm works as follows, firstly, the server initialises the task (server execution: <span id="S2.SS3.p2.1.1" class="ltx_text ltx_font_bold">Algorithm 1</span>) and then the implementation of local training begins by participants using the mini-batches of local datasets. Secondly, participants optimises the task in client update (client update: <span id="S2.SS3.p2.1.2" class="ltx_text ltx_font_bold">Algorithm 1</span>). Lastly, in the final iteration of <span id="S2.SS3.p2.1.3" class="ltx_text ltx_font_bold">client update</span>, the global loss is minimised by the server using averaging aggregation which is generally defined as:</p>
</div>
<div id="S2.SS3.p3" class="ltx_para">
<table id="S2.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E1.m1.1" class="ltx_Math" alttext="w_{t+1}=\sum_{1}^{k}\frac{m_{k}}{m}{w_{GM}}^{t+1}_{k}" display="block"><semantics id="S2.E1.m1.1a"><mrow id="S2.E1.m1.1.1" xref="S2.E1.m1.1.1.cmml"><msub id="S2.E1.m1.1.1.2" xref="S2.E1.m1.1.1.2.cmml"><mi id="S2.E1.m1.1.1.2.2" xref="S2.E1.m1.1.1.2.2.cmml">w</mi><mrow id="S2.E1.m1.1.1.2.3" xref="S2.E1.m1.1.1.2.3.cmml"><mi id="S2.E1.m1.1.1.2.3.2" xref="S2.E1.m1.1.1.2.3.2.cmml">t</mi><mo id="S2.E1.m1.1.1.2.3.1" xref="S2.E1.m1.1.1.2.3.1.cmml">+</mo><mn id="S2.E1.m1.1.1.2.3.3" xref="S2.E1.m1.1.1.2.3.3.cmml">1</mn></mrow></msub><mo rspace="0.111em" id="S2.E1.m1.1.1.1" xref="S2.E1.m1.1.1.1.cmml">=</mo><mrow id="S2.E1.m1.1.1.3" xref="S2.E1.m1.1.1.3.cmml"><munderover id="S2.E1.m1.1.1.3.1" xref="S2.E1.m1.1.1.3.1.cmml"><mo movablelimits="false" id="S2.E1.m1.1.1.3.1.2.2" xref="S2.E1.m1.1.1.3.1.2.2.cmml">∑</mo><mn id="S2.E1.m1.1.1.3.1.2.3" xref="S2.E1.m1.1.1.3.1.2.3.cmml">1</mn><mi id="S2.E1.m1.1.1.3.1.3" xref="S2.E1.m1.1.1.3.1.3.cmml">k</mi></munderover><mrow id="S2.E1.m1.1.1.3.2" xref="S2.E1.m1.1.1.3.2.cmml"><mfrac id="S2.E1.m1.1.1.3.2.2" xref="S2.E1.m1.1.1.3.2.2.cmml"><msub id="S2.E1.m1.1.1.3.2.2.2" xref="S2.E1.m1.1.1.3.2.2.2.cmml"><mi id="S2.E1.m1.1.1.3.2.2.2.2" xref="S2.E1.m1.1.1.3.2.2.2.2.cmml">m</mi><mi id="S2.E1.m1.1.1.3.2.2.2.3" xref="S2.E1.m1.1.1.3.2.2.2.3.cmml">k</mi></msub><mi id="S2.E1.m1.1.1.3.2.2.3" xref="S2.E1.m1.1.1.3.2.2.3.cmml">m</mi></mfrac><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.3.2.1" xref="S2.E1.m1.1.1.3.2.1.cmml">​</mo><mmultiscripts id="S2.E1.m1.1.1.3.2.3" xref="S2.E1.m1.1.1.3.2.3.cmml"><mi id="S2.E1.m1.1.1.3.2.3.2.2.2" xref="S2.E1.m1.1.1.3.2.3.2.2.2.cmml">w</mi><mrow id="S2.E1.m1.1.1.3.2.3.2.2.3" xref="S2.E1.m1.1.1.3.2.3.2.2.3.cmml"><mi id="S2.E1.m1.1.1.3.2.3.2.2.3.2" xref="S2.E1.m1.1.1.3.2.3.2.2.3.2.cmml">G</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.3.2.3.2.2.3.1" xref="S2.E1.m1.1.1.3.2.3.2.2.3.1.cmml">​</mo><mi id="S2.E1.m1.1.1.3.2.3.2.2.3.3" xref="S2.E1.m1.1.1.3.2.3.2.2.3.3.cmml">M</mi></mrow><mrow id="S2.E1.m1.1.1.3.2.3a" xref="S2.E1.m1.1.1.3.2.3.cmml"></mrow><mi id="S2.E1.m1.1.1.3.2.3.3" xref="S2.E1.m1.1.1.3.2.3.3.cmml">k</mi><mrow id="S2.E1.m1.1.1.3.2.3.2.3" xref="S2.E1.m1.1.1.3.2.3.2.3.cmml"><mi id="S2.E1.m1.1.1.3.2.3.2.3.2" xref="S2.E1.m1.1.1.3.2.3.2.3.2.cmml">t</mi><mo id="S2.E1.m1.1.1.3.2.3.2.3.1" xref="S2.E1.m1.1.1.3.2.3.2.3.1.cmml">+</mo><mn id="S2.E1.m1.1.1.3.2.3.2.3.3" xref="S2.E1.m1.1.1.3.2.3.2.3.3.cmml">1</mn></mrow></mmultiscripts></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E1.m1.1b"><apply id="S2.E1.m1.1.1.cmml" xref="S2.E1.m1.1.1"><eq id="S2.E1.m1.1.1.1.cmml" xref="S2.E1.m1.1.1.1"></eq><apply id="S2.E1.m1.1.1.2.cmml" xref="S2.E1.m1.1.1.2"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.2.1.cmml" xref="S2.E1.m1.1.1.2">subscript</csymbol><ci id="S2.E1.m1.1.1.2.2.cmml" xref="S2.E1.m1.1.1.2.2">𝑤</ci><apply id="S2.E1.m1.1.1.2.3.cmml" xref="S2.E1.m1.1.1.2.3"><plus id="S2.E1.m1.1.1.2.3.1.cmml" xref="S2.E1.m1.1.1.2.3.1"></plus><ci id="S2.E1.m1.1.1.2.3.2.cmml" xref="S2.E1.m1.1.1.2.3.2">𝑡</ci><cn type="integer" id="S2.E1.m1.1.1.2.3.3.cmml" xref="S2.E1.m1.1.1.2.3.3">1</cn></apply></apply><apply id="S2.E1.m1.1.1.3.cmml" xref="S2.E1.m1.1.1.3"><apply id="S2.E1.m1.1.1.3.1.cmml" xref="S2.E1.m1.1.1.3.1"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.3.1.1.cmml" xref="S2.E1.m1.1.1.3.1">superscript</csymbol><apply id="S2.E1.m1.1.1.3.1.2.cmml" xref="S2.E1.m1.1.1.3.1"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.3.1.2.1.cmml" xref="S2.E1.m1.1.1.3.1">subscript</csymbol><sum id="S2.E1.m1.1.1.3.1.2.2.cmml" xref="S2.E1.m1.1.1.3.1.2.2"></sum><cn type="integer" id="S2.E1.m1.1.1.3.1.2.3.cmml" xref="S2.E1.m1.1.1.3.1.2.3">1</cn></apply><ci id="S2.E1.m1.1.1.3.1.3.cmml" xref="S2.E1.m1.1.1.3.1.3">𝑘</ci></apply><apply id="S2.E1.m1.1.1.3.2.cmml" xref="S2.E1.m1.1.1.3.2"><times id="S2.E1.m1.1.1.3.2.1.cmml" xref="S2.E1.m1.1.1.3.2.1"></times><apply id="S2.E1.m1.1.1.3.2.2.cmml" xref="S2.E1.m1.1.1.3.2.2"><divide id="S2.E1.m1.1.1.3.2.2.1.cmml" xref="S2.E1.m1.1.1.3.2.2"></divide><apply id="S2.E1.m1.1.1.3.2.2.2.cmml" xref="S2.E1.m1.1.1.3.2.2.2"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.3.2.2.2.1.cmml" xref="S2.E1.m1.1.1.3.2.2.2">subscript</csymbol><ci id="S2.E1.m1.1.1.3.2.2.2.2.cmml" xref="S2.E1.m1.1.1.3.2.2.2.2">𝑚</ci><ci id="S2.E1.m1.1.1.3.2.2.2.3.cmml" xref="S2.E1.m1.1.1.3.2.2.2.3">𝑘</ci></apply><ci id="S2.E1.m1.1.1.3.2.2.3.cmml" xref="S2.E1.m1.1.1.3.2.2.3">𝑚</ci></apply><apply id="S2.E1.m1.1.1.3.2.3.cmml" xref="S2.E1.m1.1.1.3.2.3"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.3.2.3.1.cmml" xref="S2.E1.m1.1.1.3.2.3">subscript</csymbol><apply id="S2.E1.m1.1.1.3.2.3.2.cmml" xref="S2.E1.m1.1.1.3.2.3"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.3.2.3.2.1.cmml" xref="S2.E1.m1.1.1.3.2.3">superscript</csymbol><apply id="S2.E1.m1.1.1.3.2.3.2.2.cmml" xref="S2.E1.m1.1.1.3.2.3"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.3.2.3.2.2.1.cmml" xref="S2.E1.m1.1.1.3.2.3">subscript</csymbol><ci id="S2.E1.m1.1.1.3.2.3.2.2.2.cmml" xref="S2.E1.m1.1.1.3.2.3.2.2.2">𝑤</ci><apply id="S2.E1.m1.1.1.3.2.3.2.2.3.cmml" xref="S2.E1.m1.1.1.3.2.3.2.2.3"><times id="S2.E1.m1.1.1.3.2.3.2.2.3.1.cmml" xref="S2.E1.m1.1.1.3.2.3.2.2.3.1"></times><ci id="S2.E1.m1.1.1.3.2.3.2.2.3.2.cmml" xref="S2.E1.m1.1.1.3.2.3.2.2.3.2">𝐺</ci><ci id="S2.E1.m1.1.1.3.2.3.2.2.3.3.cmml" xref="S2.E1.m1.1.1.3.2.3.2.2.3.3">𝑀</ci></apply></apply><apply id="S2.E1.m1.1.1.3.2.3.2.3.cmml" xref="S2.E1.m1.1.1.3.2.3.2.3"><plus id="S2.E1.m1.1.1.3.2.3.2.3.1.cmml" xref="S2.E1.m1.1.1.3.2.3.2.3.1"></plus><ci id="S2.E1.m1.1.1.3.2.3.2.3.2.cmml" xref="S2.E1.m1.1.1.3.2.3.2.3.2">𝑡</ci><cn type="integer" id="S2.E1.m1.1.1.3.2.3.2.3.3.cmml" xref="S2.E1.m1.1.1.3.2.3.2.3.3">1</cn></apply></apply><ci id="S2.E1.m1.1.1.3.2.3.3.cmml" xref="S2.E1.m1.1.1.3.2.3.3">𝑘</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E1.m1.1c">w_{t+1}=\sum_{1}^{k}\frac{m_{k}}{m}{w_{GM}}^{t+1}_{k}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
</div>
<div id="S2.SS3.p4" class="ltx_para">
<p id="S2.SS3.p4.1" class="ltx_p">As described in Section 1, the training process of FL will continuously repeat until the desired accuracy is achieved or the global loss converges.
Although FedAvg is specifically proposed for FL settings, it suffers with large amounts of non-iid data as observed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite> such that its accuracy drops by 55% in non-iid environments as compared to iid environments. This can be more severe in highly distributed environments because of the different data distribution of each client <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>. Based on these analysis, we believe that the FedAvg algorithm faces a convergence issue on non-iid data.</p>
</div>
<div id="S2.SS3.p5" class="ltx_para">
<p id="S2.SS3.p5.1" class="ltx_p">To reach the SGD level convergence rate, <span id="S2.SS3.p5.1.1" class="ltx_text ltx_font_bold ltx_font_italic">SignSGD</span> is proposed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite> which transmits only the sign of each mini-batch in CNN and MLP. Compared with FedAvg, this method suffers even worse stability in non-iid environments <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>. As demonstrated in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>, SignSGD completely fails in the accuracy test of CIFAR-10 dataset and the convex logistic regression test. To understand this convergence issue, we need to investigate how a single mini-batch can have a correct sign. We consider</p>
</div>
<div id="S2.SS3.p6" class="ltx_para">
<table id="S2.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E2.m1.2" class="ltx_Math" alttext="BG_{p}^{s}=\frac{1}{s}\sum_{i=1}^{s}\bigtriangledown_{p}l(x_{i},\textit{Z})" display="block"><semantics id="S2.E2.m1.2a"><mrow id="S2.E2.m1.2.2" xref="S2.E2.m1.2.2.cmml"><mrow id="S2.E2.m1.2.2.3" xref="S2.E2.m1.2.2.3.cmml"><mi id="S2.E2.m1.2.2.3.2" xref="S2.E2.m1.2.2.3.2.cmml">B</mi><mo lspace="0em" rspace="0em" id="S2.E2.m1.2.2.3.1" xref="S2.E2.m1.2.2.3.1.cmml">​</mo><msubsup id="S2.E2.m1.2.2.3.3" xref="S2.E2.m1.2.2.3.3.cmml"><mi id="S2.E2.m1.2.2.3.3.2.2" xref="S2.E2.m1.2.2.3.3.2.2.cmml">G</mi><mi id="S2.E2.m1.2.2.3.3.2.3" xref="S2.E2.m1.2.2.3.3.2.3.cmml">p</mi><mi id="S2.E2.m1.2.2.3.3.3" xref="S2.E2.m1.2.2.3.3.3.cmml">s</mi></msubsup></mrow><mo id="S2.E2.m1.2.2.2" xref="S2.E2.m1.2.2.2.cmml">=</mo><mrow id="S2.E2.m1.2.2.1" xref="S2.E2.m1.2.2.1.cmml"><mrow id="S2.E2.m1.2.2.1.3" xref="S2.E2.m1.2.2.1.3.cmml"><mfrac id="S2.E2.m1.2.2.1.3.2" xref="S2.E2.m1.2.2.1.3.2.cmml"><mn id="S2.E2.m1.2.2.1.3.2.2" xref="S2.E2.m1.2.2.1.3.2.2.cmml">1</mn><mi id="S2.E2.m1.2.2.1.3.2.3" xref="S2.E2.m1.2.2.1.3.2.3.cmml">s</mi></mfrac><mo lspace="0em" rspace="0em" id="S2.E2.m1.2.2.1.3.1" xref="S2.E2.m1.2.2.1.3.1.cmml">​</mo><munderover id="S2.E2.m1.2.2.1.3.3" xref="S2.E2.m1.2.2.1.3.3.cmml"><mo movablelimits="false" rspace="0em" id="S2.E2.m1.2.2.1.3.3.2.2" xref="S2.E2.m1.2.2.1.3.3.2.2.cmml">∑</mo><mrow id="S2.E2.m1.2.2.1.3.3.2.3" xref="S2.E2.m1.2.2.1.3.3.2.3.cmml"><mi id="S2.E2.m1.2.2.1.3.3.2.3.2" xref="S2.E2.m1.2.2.1.3.3.2.3.2.cmml">i</mi><mo id="S2.E2.m1.2.2.1.3.3.2.3.1" xref="S2.E2.m1.2.2.1.3.3.2.3.1.cmml">=</mo><mn id="S2.E2.m1.2.2.1.3.3.2.3.3" xref="S2.E2.m1.2.2.1.3.3.2.3.3.cmml">1</mn></mrow><mi id="S2.E2.m1.2.2.1.3.3.3" xref="S2.E2.m1.2.2.1.3.3.3.cmml">s</mi></munderover></mrow><msub id="S2.E2.m1.2.2.1.2" xref="S2.E2.m1.2.2.1.2.cmml"><mo lspace="0em" rspace="0.222em" id="S2.E2.m1.2.2.1.2.2" xref="S2.E2.m1.2.2.1.2.2.cmml">▽</mo><mi id="S2.E2.m1.2.2.1.2.3" xref="S2.E2.m1.2.2.1.2.3.cmml">p</mi></msub><mrow id="S2.E2.m1.2.2.1.1" xref="S2.E2.m1.2.2.1.1.cmml"><mi id="S2.E2.m1.2.2.1.1.3" xref="S2.E2.m1.2.2.1.1.3.cmml">l</mi><mo lspace="0em" rspace="0em" id="S2.E2.m1.2.2.1.1.2" xref="S2.E2.m1.2.2.1.1.2.cmml">​</mo><mrow id="S2.E2.m1.2.2.1.1.1.1" xref="S2.E2.m1.2.2.1.1.1.2.cmml"><mo stretchy="false" id="S2.E2.m1.2.2.1.1.1.1.2" xref="S2.E2.m1.2.2.1.1.1.2.cmml">(</mo><msub id="S2.E2.m1.2.2.1.1.1.1.1" xref="S2.E2.m1.2.2.1.1.1.1.1.cmml"><mi id="S2.E2.m1.2.2.1.1.1.1.1.2" xref="S2.E2.m1.2.2.1.1.1.1.1.2.cmml">x</mi><mi id="S2.E2.m1.2.2.1.1.1.1.1.3" xref="S2.E2.m1.2.2.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S2.E2.m1.2.2.1.1.1.1.3" xref="S2.E2.m1.2.2.1.1.1.2.cmml">,</mo><mtext class="ltx_mathvariant_italic" id="S2.E2.m1.1.1" xref="S2.E2.m1.1.1a.cmml">Z</mtext><mo stretchy="false" id="S2.E2.m1.2.2.1.1.1.1.4" xref="S2.E2.m1.2.2.1.1.1.2.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E2.m1.2b"><apply id="S2.E2.m1.2.2.cmml" xref="S2.E2.m1.2.2"><eq id="S2.E2.m1.2.2.2.cmml" xref="S2.E2.m1.2.2.2"></eq><apply id="S2.E2.m1.2.2.3.cmml" xref="S2.E2.m1.2.2.3"><times id="S2.E2.m1.2.2.3.1.cmml" xref="S2.E2.m1.2.2.3.1"></times><ci id="S2.E2.m1.2.2.3.2.cmml" xref="S2.E2.m1.2.2.3.2">𝐵</ci><apply id="S2.E2.m1.2.2.3.3.cmml" xref="S2.E2.m1.2.2.3.3"><csymbol cd="ambiguous" id="S2.E2.m1.2.2.3.3.1.cmml" xref="S2.E2.m1.2.2.3.3">superscript</csymbol><apply id="S2.E2.m1.2.2.3.3.2.cmml" xref="S2.E2.m1.2.2.3.3"><csymbol cd="ambiguous" id="S2.E2.m1.2.2.3.3.2.1.cmml" xref="S2.E2.m1.2.2.3.3">subscript</csymbol><ci id="S2.E2.m1.2.2.3.3.2.2.cmml" xref="S2.E2.m1.2.2.3.3.2.2">𝐺</ci><ci id="S2.E2.m1.2.2.3.3.2.3.cmml" xref="S2.E2.m1.2.2.3.3.2.3">𝑝</ci></apply><ci id="S2.E2.m1.2.2.3.3.3.cmml" xref="S2.E2.m1.2.2.3.3.3">𝑠</ci></apply></apply><apply id="S2.E2.m1.2.2.1.cmml" xref="S2.E2.m1.2.2.1"><apply id="S2.E2.m1.2.2.1.2.cmml" xref="S2.E2.m1.2.2.1.2"><csymbol cd="ambiguous" id="S2.E2.m1.2.2.1.2.1.cmml" xref="S2.E2.m1.2.2.1.2">subscript</csymbol><ci id="S2.E2.m1.2.2.1.2.2.cmml" xref="S2.E2.m1.2.2.1.2.2">▽</ci><ci id="S2.E2.m1.2.2.1.2.3.cmml" xref="S2.E2.m1.2.2.1.2.3">𝑝</ci></apply><apply id="S2.E2.m1.2.2.1.3.cmml" xref="S2.E2.m1.2.2.1.3"><times id="S2.E2.m1.2.2.1.3.1.cmml" xref="S2.E2.m1.2.2.1.3.1"></times><apply id="S2.E2.m1.2.2.1.3.2.cmml" xref="S2.E2.m1.2.2.1.3.2"><divide id="S2.E2.m1.2.2.1.3.2.1.cmml" xref="S2.E2.m1.2.2.1.3.2"></divide><cn type="integer" id="S2.E2.m1.2.2.1.3.2.2.cmml" xref="S2.E2.m1.2.2.1.3.2.2">1</cn><ci id="S2.E2.m1.2.2.1.3.2.3.cmml" xref="S2.E2.m1.2.2.1.3.2.3">𝑠</ci></apply><apply id="S2.E2.m1.2.2.1.3.3.cmml" xref="S2.E2.m1.2.2.1.3.3"><csymbol cd="ambiguous" id="S2.E2.m1.2.2.1.3.3.1.cmml" xref="S2.E2.m1.2.2.1.3.3">superscript</csymbol><apply id="S2.E2.m1.2.2.1.3.3.2.cmml" xref="S2.E2.m1.2.2.1.3.3"><csymbol cd="ambiguous" id="S2.E2.m1.2.2.1.3.3.2.1.cmml" xref="S2.E2.m1.2.2.1.3.3">subscript</csymbol><sum id="S2.E2.m1.2.2.1.3.3.2.2.cmml" xref="S2.E2.m1.2.2.1.3.3.2.2"></sum><apply id="S2.E2.m1.2.2.1.3.3.2.3.cmml" xref="S2.E2.m1.2.2.1.3.3.2.3"><eq id="S2.E2.m1.2.2.1.3.3.2.3.1.cmml" xref="S2.E2.m1.2.2.1.3.3.2.3.1"></eq><ci id="S2.E2.m1.2.2.1.3.3.2.3.2.cmml" xref="S2.E2.m1.2.2.1.3.3.2.3.2">𝑖</ci><cn type="integer" id="S2.E2.m1.2.2.1.3.3.2.3.3.cmml" xref="S2.E2.m1.2.2.1.3.3.2.3.3">1</cn></apply></apply><ci id="S2.E2.m1.2.2.1.3.3.3.cmml" xref="S2.E2.m1.2.2.1.3.3.3">𝑠</ci></apply></apply><apply id="S2.E2.m1.2.2.1.1.cmml" xref="S2.E2.m1.2.2.1.1"><times id="S2.E2.m1.2.2.1.1.2.cmml" xref="S2.E2.m1.2.2.1.1.2"></times><ci id="S2.E2.m1.2.2.1.1.3.cmml" xref="S2.E2.m1.2.2.1.1.3">𝑙</ci><interval closure="open" id="S2.E2.m1.2.2.1.1.1.2.cmml" xref="S2.E2.m1.2.2.1.1.1.1"><apply id="S2.E2.m1.2.2.1.1.1.1.1.cmml" xref="S2.E2.m1.2.2.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E2.m1.2.2.1.1.1.1.1.1.cmml" xref="S2.E2.m1.2.2.1.1.1.1.1">subscript</csymbol><ci id="S2.E2.m1.2.2.1.1.1.1.1.2.cmml" xref="S2.E2.m1.2.2.1.1.1.1.1.2">𝑥</ci><ci id="S2.E2.m1.2.2.1.1.1.1.1.3.cmml" xref="S2.E2.m1.2.2.1.1.1.1.1.3">𝑖</ci></apply><ci id="S2.E2.m1.1.1a.cmml" xref="S2.E2.m1.1.1"><mtext class="ltx_mathvariant_italic" id="S2.E2.m1.1.1.cmml" xref="S2.E2.m1.1.1">Z</mtext></ci></interval></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E2.m1.2c">BG_{p}^{s}=\frac{1}{s}\sum_{i=1}^{s}\bigtriangledown_{p}l(x_{i},\textit{Z})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
</div>
<div id="S2.SS3.p7" class="ltx_para">
<p id="S2.SS3.p7.9" class="ltx_p">a batch gradient <math id="S2.SS3.p7.1.m1.1" class="ltx_Math" alttext="BG" display="inline"><semantics id="S2.SS3.p7.1.m1.1a"><mrow id="S2.SS3.p7.1.m1.1.1" xref="S2.SS3.p7.1.m1.1.1.cmml"><mi id="S2.SS3.p7.1.m1.1.1.2" xref="S2.SS3.p7.1.m1.1.1.2.cmml">B</mi><mo lspace="0em" rspace="0em" id="S2.SS3.p7.1.m1.1.1.1" xref="S2.SS3.p7.1.m1.1.1.1.cmml">​</mo><mi id="S2.SS3.p7.1.m1.1.1.3" xref="S2.SS3.p7.1.m1.1.1.3.cmml">G</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p7.1.m1.1b"><apply id="S2.SS3.p7.1.m1.1.1.cmml" xref="S2.SS3.p7.1.m1.1.1"><times id="S2.SS3.p7.1.m1.1.1.1.cmml" xref="S2.SS3.p7.1.m1.1.1.1"></times><ci id="S2.SS3.p7.1.m1.1.1.2.cmml" xref="S2.SS3.p7.1.m1.1.1.2">𝐵</ci><ci id="S2.SS3.p7.1.m1.1.1.3.cmml" xref="S2.SS3.p7.1.m1.1.1.3">𝐺</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p7.1.m1.1c">BG</annotation></semantics></math> on data <math id="S2.SS3.p7.2.m2.1" class="ltx_Math" alttext="d^{s}" display="inline"><semantics id="S2.SS3.p7.2.m2.1a"><msup id="S2.SS3.p7.2.m2.1.1" xref="S2.SS3.p7.2.m2.1.1.cmml"><mi id="S2.SS3.p7.2.m2.1.1.2" xref="S2.SS3.p7.2.m2.1.1.2.cmml">d</mi><mi id="S2.SS3.p7.2.m2.1.1.3" xref="S2.SS3.p7.2.m2.1.1.3.cmml">s</mi></msup><annotation-xml encoding="MathML-Content" id="S2.SS3.p7.2.m2.1b"><apply id="S2.SS3.p7.2.m2.1.1.cmml" xref="S2.SS3.p7.2.m2.1.1"><csymbol cd="ambiguous" id="S2.SS3.p7.2.m2.1.1.1.cmml" xref="S2.SS3.p7.2.m2.1.1">superscript</csymbol><ci id="S2.SS3.p7.2.m2.1.1.2.cmml" xref="S2.SS3.p7.2.m2.1.1.2">𝑑</ci><ci id="S2.SS3.p7.2.m2.1.1.3.cmml" xref="S2.SS3.p7.2.m2.1.1.3">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p7.2.m2.1c">d^{s}</annotation></semantics></math> from a specific mini-batch <math id="S2.SS3.p7.3.m3.1" class="ltx_Math" alttext="mb" display="inline"><semantics id="S2.SS3.p7.3.m3.1a"><mrow id="S2.SS3.p7.3.m3.1.1" xref="S2.SS3.p7.3.m3.1.1.cmml"><mi id="S2.SS3.p7.3.m3.1.1.2" xref="S2.SS3.p7.3.m3.1.1.2.cmml">m</mi><mo lspace="0em" rspace="0em" id="S2.SS3.p7.3.m3.1.1.1" xref="S2.SS3.p7.3.m3.1.1.1.cmml">​</mo><mi id="S2.SS3.p7.3.m3.1.1.3" xref="S2.SS3.p7.3.m3.1.1.3.cmml">b</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p7.3.m3.1b"><apply id="S2.SS3.p7.3.m3.1.1.cmml" xref="S2.SS3.p7.3.m3.1.1"><times id="S2.SS3.p7.3.m3.1.1.1.cmml" xref="S2.SS3.p7.3.m3.1.1.1"></times><ci id="S2.SS3.p7.3.m3.1.1.2.cmml" xref="S2.SS3.p7.3.m3.1.1.2">𝑚</ci><ci id="S2.SS3.p7.3.m3.1.1.3.cmml" xref="S2.SS3.p7.3.m3.1.1.3">𝑏</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p7.3.m3.1c">mb</annotation></semantics></math> <math id="S2.SS3.p7.4.m4.1" class="ltx_Math" alttext="\subset" display="inline"><semantics id="S2.SS3.p7.4.m4.1a"><mo id="S2.SS3.p7.4.m4.1.1" xref="S2.SS3.p7.4.m4.1.1.cmml">⊂</mo><annotation-xml encoding="MathML-Content" id="S2.SS3.p7.4.m4.1b"><subset id="S2.SS3.p7.4.m4.1.1.cmml" xref="S2.SS3.p7.4.m4.1.1"></subset></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p7.4.m4.1c">\subset</annotation></semantics></math> <math id="S2.SS3.p7.5.m5.1" class="ltx_Math" alttext="d" display="inline"><semantics id="S2.SS3.p7.5.m5.1a"><mi id="S2.SS3.p7.5.m5.1.1" xref="S2.SS3.p7.5.m5.1.1.cmml">d</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.p7.5.m5.1b"><ci id="S2.SS3.p7.5.m5.1.1.cmml" xref="S2.SS3.p7.5.m5.1.1">𝑑</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p7.5.m5.1c">d</annotation></semantics></math> of size <math id="S2.SS3.p7.6.m6.1" class="ltx_Math" alttext="s" display="inline"><semantics id="S2.SS3.p7.6.m6.1a"><mi id="S2.SS3.p7.6.m6.1.1" xref="S2.SS3.p7.6.m6.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.p7.6.m6.1b"><ci id="S2.SS3.p7.6.m6.1.1.cmml" xref="S2.SS3.p7.6.m6.1.1">𝑠</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p7.6.m6.1c">s</annotation></semantics></math> with parameter <math id="S2.SS3.p7.7.m7.1" class="ltx_Math" alttext="p" display="inline"><semantics id="S2.SS3.p7.7.m7.1a"><mi id="S2.SS3.p7.7.m7.1.1" xref="S2.SS3.p7.7.m7.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.p7.7.m7.1b"><ci id="S2.SS3.p7.7.m7.1.1.cmml" xref="S2.SS3.p7.7.m7.1.1">𝑝</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p7.7.m7.1c">p</annotation></semantics></math>. If we consider this gradient <math id="S2.SS3.p7.8.m8.1" class="ltx_Math" alttext="BG_{p}^{s}" display="inline"><semantics id="S2.SS3.p7.8.m8.1a"><mrow id="S2.SS3.p7.8.m8.1.1" xref="S2.SS3.p7.8.m8.1.1.cmml"><mi id="S2.SS3.p7.8.m8.1.1.2" xref="S2.SS3.p7.8.m8.1.1.2.cmml">B</mi><mo lspace="0em" rspace="0em" id="S2.SS3.p7.8.m8.1.1.1" xref="S2.SS3.p7.8.m8.1.1.1.cmml">​</mo><msubsup id="S2.SS3.p7.8.m8.1.1.3" xref="S2.SS3.p7.8.m8.1.1.3.cmml"><mi id="S2.SS3.p7.8.m8.1.1.3.2.2" xref="S2.SS3.p7.8.m8.1.1.3.2.2.cmml">G</mi><mi id="S2.SS3.p7.8.m8.1.1.3.2.3" xref="S2.SS3.p7.8.m8.1.1.3.2.3.cmml">p</mi><mi id="S2.SS3.p7.8.m8.1.1.3.3" xref="S2.SS3.p7.8.m8.1.1.3.3.cmml">s</mi></msubsup></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p7.8.m8.1b"><apply id="S2.SS3.p7.8.m8.1.1.cmml" xref="S2.SS3.p7.8.m8.1.1"><times id="S2.SS3.p7.8.m8.1.1.1.cmml" xref="S2.SS3.p7.8.m8.1.1.1"></times><ci id="S2.SS3.p7.8.m8.1.1.2.cmml" xref="S2.SS3.p7.8.m8.1.1.2">𝐵</ci><apply id="S2.SS3.p7.8.m8.1.1.3.cmml" xref="S2.SS3.p7.8.m8.1.1.3"><csymbol cd="ambiguous" id="S2.SS3.p7.8.m8.1.1.3.1.cmml" xref="S2.SS3.p7.8.m8.1.1.3">superscript</csymbol><apply id="S2.SS3.p7.8.m8.1.1.3.2.cmml" xref="S2.SS3.p7.8.m8.1.1.3"><csymbol cd="ambiguous" id="S2.SS3.p7.8.m8.1.1.3.2.1.cmml" xref="S2.SS3.p7.8.m8.1.1.3">subscript</csymbol><ci id="S2.SS3.p7.8.m8.1.1.3.2.2.cmml" xref="S2.SS3.p7.8.m8.1.1.3.2.2">𝐺</ci><ci id="S2.SS3.p7.8.m8.1.1.3.2.3.cmml" xref="S2.SS3.p7.8.m8.1.1.3.2.3">𝑝</ci></apply><ci id="S2.SS3.p7.8.m8.1.1.3.3.cmml" xref="S2.SS3.p7.8.m8.1.1.3.3">𝑠</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p7.8.m8.1c">BG_{p}^{s}</annotation></semantics></math> over the complete training data <math id="S2.SS3.p7.9.m9.1" class="ltx_Math" alttext="d" display="inline"><semantics id="S2.SS3.p7.9.m9.1a"><mi id="S2.SS3.p7.9.m9.1.1" xref="S2.SS3.p7.9.m9.1.1.cmml">d</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.p7.9.m9.1b"><ci id="S2.SS3.p7.9.m9.1.1.cmml" xref="S2.SS3.p7.9.m9.1.1">𝑑</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p7.9.m9.1c">d</annotation></semantics></math>. Then, the probability of the gradient can be defined by:</p>
</div>
<div id="S2.SS3.p8" class="ltx_para">
<table id="S2.E3" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E3.m1.2" class="ltx_Math" alttext="\gamma_{p}(s)=\mathcal{P}[sign(BG_{p}^{s})=sign(BG)]." display="block"><semantics id="S2.E3.m1.2a"><mrow id="S2.E3.m1.2.2.1" xref="S2.E3.m1.2.2.1.1.cmml"><mrow id="S2.E3.m1.2.2.1.1" xref="S2.E3.m1.2.2.1.1.cmml"><mrow id="S2.E3.m1.2.2.1.1.3" xref="S2.E3.m1.2.2.1.1.3.cmml"><msub id="S2.E3.m1.2.2.1.1.3.2" xref="S2.E3.m1.2.2.1.1.3.2.cmml"><mi id="S2.E3.m1.2.2.1.1.3.2.2" xref="S2.E3.m1.2.2.1.1.3.2.2.cmml">γ</mi><mi id="S2.E3.m1.2.2.1.1.3.2.3" xref="S2.E3.m1.2.2.1.1.3.2.3.cmml">p</mi></msub><mo lspace="0em" rspace="0em" id="S2.E3.m1.2.2.1.1.3.1" xref="S2.E3.m1.2.2.1.1.3.1.cmml">​</mo><mrow id="S2.E3.m1.2.2.1.1.3.3.2" xref="S2.E3.m1.2.2.1.1.3.cmml"><mo stretchy="false" id="S2.E3.m1.2.2.1.1.3.3.2.1" xref="S2.E3.m1.2.2.1.1.3.cmml">(</mo><mi id="S2.E3.m1.1.1" xref="S2.E3.m1.1.1.cmml">s</mi><mo stretchy="false" id="S2.E3.m1.2.2.1.1.3.3.2.2" xref="S2.E3.m1.2.2.1.1.3.cmml">)</mo></mrow></mrow><mo id="S2.E3.m1.2.2.1.1.2" xref="S2.E3.m1.2.2.1.1.2.cmml">=</mo><mrow id="S2.E3.m1.2.2.1.1.1" xref="S2.E3.m1.2.2.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E3.m1.2.2.1.1.1.3" xref="S2.E3.m1.2.2.1.1.1.3.cmml">𝒫</mi><mo lspace="0em" rspace="0em" id="S2.E3.m1.2.2.1.1.1.2" xref="S2.E3.m1.2.2.1.1.1.2.cmml">​</mo><mrow id="S2.E3.m1.2.2.1.1.1.1.1" xref="S2.E3.m1.2.2.1.1.1.1.2.cmml"><mo stretchy="false" id="S2.E3.m1.2.2.1.1.1.1.1.2" xref="S2.E3.m1.2.2.1.1.1.1.2.1.cmml">[</mo><mrow id="S2.E3.m1.2.2.1.1.1.1.1.1" xref="S2.E3.m1.2.2.1.1.1.1.1.1.cmml"><mrow id="S2.E3.m1.2.2.1.1.1.1.1.1.1" xref="S2.E3.m1.2.2.1.1.1.1.1.1.1.cmml"><mi id="S2.E3.m1.2.2.1.1.1.1.1.1.1.3" xref="S2.E3.m1.2.2.1.1.1.1.1.1.1.3.cmml">s</mi><mo lspace="0em" rspace="0em" id="S2.E3.m1.2.2.1.1.1.1.1.1.1.2" xref="S2.E3.m1.2.2.1.1.1.1.1.1.1.2.cmml">​</mo><mi id="S2.E3.m1.2.2.1.1.1.1.1.1.1.4" xref="S2.E3.m1.2.2.1.1.1.1.1.1.1.4.cmml">i</mi><mo lspace="0em" rspace="0em" id="S2.E3.m1.2.2.1.1.1.1.1.1.1.2a" xref="S2.E3.m1.2.2.1.1.1.1.1.1.1.2.cmml">​</mo><mi id="S2.E3.m1.2.2.1.1.1.1.1.1.1.5" xref="S2.E3.m1.2.2.1.1.1.1.1.1.1.5.cmml">g</mi><mo lspace="0em" rspace="0em" id="S2.E3.m1.2.2.1.1.1.1.1.1.1.2b" xref="S2.E3.m1.2.2.1.1.1.1.1.1.1.2.cmml">​</mo><mi id="S2.E3.m1.2.2.1.1.1.1.1.1.1.6" xref="S2.E3.m1.2.2.1.1.1.1.1.1.1.6.cmml">n</mi><mo lspace="0em" rspace="0em" id="S2.E3.m1.2.2.1.1.1.1.1.1.1.2c" xref="S2.E3.m1.2.2.1.1.1.1.1.1.1.2.cmml">​</mo><mrow id="S2.E3.m1.2.2.1.1.1.1.1.1.1.1.1" xref="S2.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.E3.m1.2.2.1.1.1.1.1.1.1.1.1.2" xref="S2.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S2.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1" xref="S2.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S2.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.2" xref="S2.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.2.cmml">B</mi><mo lspace="0em" rspace="0em" id="S2.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.1" xref="S2.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.cmml">​</mo><msubsup id="S2.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.3" xref="S2.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.cmml"><mi id="S2.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2.2" xref="S2.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2.2.cmml">G</mi><mi id="S2.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2.3" xref="S2.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2.3.cmml">p</mi><mi id="S2.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.3" xref="S2.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.3.cmml">s</mi></msubsup></mrow><mo stretchy="false" id="S2.E3.m1.2.2.1.1.1.1.1.1.1.1.1.3" xref="S2.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S2.E3.m1.2.2.1.1.1.1.1.1.3" xref="S2.E3.m1.2.2.1.1.1.1.1.1.3.cmml">=</mo><mrow id="S2.E3.m1.2.2.1.1.1.1.1.1.2" xref="S2.E3.m1.2.2.1.1.1.1.1.1.2.cmml"><mi id="S2.E3.m1.2.2.1.1.1.1.1.1.2.3" xref="S2.E3.m1.2.2.1.1.1.1.1.1.2.3.cmml">s</mi><mo lspace="0em" rspace="0em" id="S2.E3.m1.2.2.1.1.1.1.1.1.2.2" xref="S2.E3.m1.2.2.1.1.1.1.1.1.2.2.cmml">​</mo><mi id="S2.E3.m1.2.2.1.1.1.1.1.1.2.4" xref="S2.E3.m1.2.2.1.1.1.1.1.1.2.4.cmml">i</mi><mo lspace="0em" rspace="0em" id="S2.E3.m1.2.2.1.1.1.1.1.1.2.2a" xref="S2.E3.m1.2.2.1.1.1.1.1.1.2.2.cmml">​</mo><mi id="S2.E3.m1.2.2.1.1.1.1.1.1.2.5" xref="S2.E3.m1.2.2.1.1.1.1.1.1.2.5.cmml">g</mi><mo lspace="0em" rspace="0em" id="S2.E3.m1.2.2.1.1.1.1.1.1.2.2b" xref="S2.E3.m1.2.2.1.1.1.1.1.1.2.2.cmml">​</mo><mi id="S2.E3.m1.2.2.1.1.1.1.1.1.2.6" xref="S2.E3.m1.2.2.1.1.1.1.1.1.2.6.cmml">n</mi><mo lspace="0em" rspace="0em" id="S2.E3.m1.2.2.1.1.1.1.1.1.2.2c" xref="S2.E3.m1.2.2.1.1.1.1.1.1.2.2.cmml">​</mo><mrow id="S2.E3.m1.2.2.1.1.1.1.1.1.2.1.1" xref="S2.E3.m1.2.2.1.1.1.1.1.1.2.1.1.1.cmml"><mo stretchy="false" id="S2.E3.m1.2.2.1.1.1.1.1.1.2.1.1.2" xref="S2.E3.m1.2.2.1.1.1.1.1.1.2.1.1.1.cmml">(</mo><mrow id="S2.E3.m1.2.2.1.1.1.1.1.1.2.1.1.1" xref="S2.E3.m1.2.2.1.1.1.1.1.1.2.1.1.1.cmml"><mi id="S2.E3.m1.2.2.1.1.1.1.1.1.2.1.1.1.2" xref="S2.E3.m1.2.2.1.1.1.1.1.1.2.1.1.1.2.cmml">B</mi><mo lspace="0em" rspace="0em" id="S2.E3.m1.2.2.1.1.1.1.1.1.2.1.1.1.1" xref="S2.E3.m1.2.2.1.1.1.1.1.1.2.1.1.1.1.cmml">​</mo><mi id="S2.E3.m1.2.2.1.1.1.1.1.1.2.1.1.1.3" xref="S2.E3.m1.2.2.1.1.1.1.1.1.2.1.1.1.3.cmml">G</mi></mrow><mo stretchy="false" id="S2.E3.m1.2.2.1.1.1.1.1.1.2.1.1.3" xref="S2.E3.m1.2.2.1.1.1.1.1.1.2.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo stretchy="false" id="S2.E3.m1.2.2.1.1.1.1.1.3" xref="S2.E3.m1.2.2.1.1.1.1.2.1.cmml">]</mo></mrow></mrow></mrow><mo lspace="0em" id="S2.E3.m1.2.2.1.2" xref="S2.E3.m1.2.2.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.E3.m1.2b"><apply id="S2.E3.m1.2.2.1.1.cmml" xref="S2.E3.m1.2.2.1"><eq id="S2.E3.m1.2.2.1.1.2.cmml" xref="S2.E3.m1.2.2.1.1.2"></eq><apply id="S2.E3.m1.2.2.1.1.3.cmml" xref="S2.E3.m1.2.2.1.1.3"><times id="S2.E3.m1.2.2.1.1.3.1.cmml" xref="S2.E3.m1.2.2.1.1.3.1"></times><apply id="S2.E3.m1.2.2.1.1.3.2.cmml" xref="S2.E3.m1.2.2.1.1.3.2"><csymbol cd="ambiguous" id="S2.E3.m1.2.2.1.1.3.2.1.cmml" xref="S2.E3.m1.2.2.1.1.3.2">subscript</csymbol><ci id="S2.E3.m1.2.2.1.1.3.2.2.cmml" xref="S2.E3.m1.2.2.1.1.3.2.2">𝛾</ci><ci id="S2.E3.m1.2.2.1.1.3.2.3.cmml" xref="S2.E3.m1.2.2.1.1.3.2.3">𝑝</ci></apply><ci id="S2.E3.m1.1.1.cmml" xref="S2.E3.m1.1.1">𝑠</ci></apply><apply id="S2.E3.m1.2.2.1.1.1.cmml" xref="S2.E3.m1.2.2.1.1.1"><times id="S2.E3.m1.2.2.1.1.1.2.cmml" xref="S2.E3.m1.2.2.1.1.1.2"></times><ci id="S2.E3.m1.2.2.1.1.1.3.cmml" xref="S2.E3.m1.2.2.1.1.1.3">𝒫</ci><apply id="S2.E3.m1.2.2.1.1.1.1.2.cmml" xref="S2.E3.m1.2.2.1.1.1.1.1"><csymbol cd="latexml" id="S2.E3.m1.2.2.1.1.1.1.2.1.cmml" xref="S2.E3.m1.2.2.1.1.1.1.1.2">delimited-[]</csymbol><apply id="S2.E3.m1.2.2.1.1.1.1.1.1.cmml" xref="S2.E3.m1.2.2.1.1.1.1.1.1"><eq id="S2.E3.m1.2.2.1.1.1.1.1.1.3.cmml" xref="S2.E3.m1.2.2.1.1.1.1.1.1.3"></eq><apply id="S2.E3.m1.2.2.1.1.1.1.1.1.1.cmml" xref="S2.E3.m1.2.2.1.1.1.1.1.1.1"><times id="S2.E3.m1.2.2.1.1.1.1.1.1.1.2.cmml" xref="S2.E3.m1.2.2.1.1.1.1.1.1.1.2"></times><ci id="S2.E3.m1.2.2.1.1.1.1.1.1.1.3.cmml" xref="S2.E3.m1.2.2.1.1.1.1.1.1.1.3">𝑠</ci><ci id="S2.E3.m1.2.2.1.1.1.1.1.1.1.4.cmml" xref="S2.E3.m1.2.2.1.1.1.1.1.1.1.4">𝑖</ci><ci id="S2.E3.m1.2.2.1.1.1.1.1.1.1.5.cmml" xref="S2.E3.m1.2.2.1.1.1.1.1.1.1.5">𝑔</ci><ci id="S2.E3.m1.2.2.1.1.1.1.1.1.1.6.cmml" xref="S2.E3.m1.2.2.1.1.1.1.1.1.1.6">𝑛</ci><apply id="S2.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E3.m1.2.2.1.1.1.1.1.1.1.1.1"><times id="S2.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.1"></times><ci id="S2.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.2">𝐵</ci><apply id="S2.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S2.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S2.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.3">superscript</csymbol><apply id="S2.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S2.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2.1.cmml" xref="S2.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S2.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2.2.cmml" xref="S2.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2.2">𝐺</ci><ci id="S2.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2.3.cmml" xref="S2.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2.3">𝑝</ci></apply><ci id="S2.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S2.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.3">𝑠</ci></apply></apply></apply><apply id="S2.E3.m1.2.2.1.1.1.1.1.1.2.cmml" xref="S2.E3.m1.2.2.1.1.1.1.1.1.2"><times id="S2.E3.m1.2.2.1.1.1.1.1.1.2.2.cmml" xref="S2.E3.m1.2.2.1.1.1.1.1.1.2.2"></times><ci id="S2.E3.m1.2.2.1.1.1.1.1.1.2.3.cmml" xref="S2.E3.m1.2.2.1.1.1.1.1.1.2.3">𝑠</ci><ci id="S2.E3.m1.2.2.1.1.1.1.1.1.2.4.cmml" xref="S2.E3.m1.2.2.1.1.1.1.1.1.2.4">𝑖</ci><ci id="S2.E3.m1.2.2.1.1.1.1.1.1.2.5.cmml" xref="S2.E3.m1.2.2.1.1.1.1.1.1.2.5">𝑔</ci><ci id="S2.E3.m1.2.2.1.1.1.1.1.1.2.6.cmml" xref="S2.E3.m1.2.2.1.1.1.1.1.1.2.6">𝑛</ci><apply id="S2.E3.m1.2.2.1.1.1.1.1.1.2.1.1.1.cmml" xref="S2.E3.m1.2.2.1.1.1.1.1.1.2.1.1"><times id="S2.E3.m1.2.2.1.1.1.1.1.1.2.1.1.1.1.cmml" xref="S2.E3.m1.2.2.1.1.1.1.1.1.2.1.1.1.1"></times><ci id="S2.E3.m1.2.2.1.1.1.1.1.1.2.1.1.1.2.cmml" xref="S2.E3.m1.2.2.1.1.1.1.1.1.2.1.1.1.2">𝐵</ci><ci id="S2.E3.m1.2.2.1.1.1.1.1.1.2.1.1.1.3.cmml" xref="S2.E3.m1.2.2.1.1.1.1.1.1.2.1.1.1.3">𝐺</ci></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E3.m1.2c">\gamma_{p}(s)=\mathcal{P}[sign(BG_{p}^{s})=sign(BG)].</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
</div>
<div id="S2.SS3.p9" class="ltx_para">
<p id="S2.SS3.p9.3" class="ltx_p">Apparently from Equation (3), size of the first mini-batch, <math id="S2.SS3.p9.1.m1.1" class="ltx_Math" alttext="BD^{1}" display="inline"><semantics id="S2.SS3.p9.1.m1.1a"><mrow id="S2.SS3.p9.1.m1.1.1" xref="S2.SS3.p9.1.m1.1.1.cmml"><mi id="S2.SS3.p9.1.m1.1.1.2" xref="S2.SS3.p9.1.m1.1.1.2.cmml">B</mi><mo lspace="0em" rspace="0em" id="S2.SS3.p9.1.m1.1.1.1" xref="S2.SS3.p9.1.m1.1.1.1.cmml">​</mo><msup id="S2.SS3.p9.1.m1.1.1.3" xref="S2.SS3.p9.1.m1.1.1.3.cmml"><mi id="S2.SS3.p9.1.m1.1.1.3.2" xref="S2.SS3.p9.1.m1.1.1.3.2.cmml">D</mi><mn id="S2.SS3.p9.1.m1.1.1.3.3" xref="S2.SS3.p9.1.m1.1.1.3.3.cmml">1</mn></msup></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p9.1.m1.1b"><apply id="S2.SS3.p9.1.m1.1.1.cmml" xref="S2.SS3.p9.1.m1.1.1"><times id="S2.SS3.p9.1.m1.1.1.1.cmml" xref="S2.SS3.p9.1.m1.1.1.1"></times><ci id="S2.SS3.p9.1.m1.1.1.2.cmml" xref="S2.SS3.p9.1.m1.1.1.2">𝐵</ci><apply id="S2.SS3.p9.1.m1.1.1.3.cmml" xref="S2.SS3.p9.1.m1.1.1.3"><csymbol cd="ambiguous" id="S2.SS3.p9.1.m1.1.1.3.1.cmml" xref="S2.SS3.p9.1.m1.1.1.3">superscript</csymbol><ci id="S2.SS3.p9.1.m1.1.1.3.2.cmml" xref="S2.SS3.p9.1.m1.1.1.3.2">𝐷</ci><cn type="integer" id="S2.SS3.p9.1.m1.1.1.3.3.cmml" xref="S2.SS3.p9.1.m1.1.1.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p9.1.m1.1c">BD^{1}</annotation></semantics></math> is considered a bad predictor for the sign of true gradient because of high variance and average convergence of <math id="S2.SS3.p9.2.m2.1" class="ltx_Math" alttext="\gamma(1)=0.53" display="inline"><semantics id="S2.SS3.p9.2.m2.1a"><mrow id="S2.SS3.p9.2.m2.1.2" xref="S2.SS3.p9.2.m2.1.2.cmml"><mrow id="S2.SS3.p9.2.m2.1.2.2" xref="S2.SS3.p9.2.m2.1.2.2.cmml"><mi id="S2.SS3.p9.2.m2.1.2.2.2" xref="S2.SS3.p9.2.m2.1.2.2.2.cmml">γ</mi><mo lspace="0em" rspace="0em" id="S2.SS3.p9.2.m2.1.2.2.1" xref="S2.SS3.p9.2.m2.1.2.2.1.cmml">​</mo><mrow id="S2.SS3.p9.2.m2.1.2.2.3.2" xref="S2.SS3.p9.2.m2.1.2.2.cmml"><mo stretchy="false" id="S2.SS3.p9.2.m2.1.2.2.3.2.1" xref="S2.SS3.p9.2.m2.1.2.2.cmml">(</mo><mn id="S2.SS3.p9.2.m2.1.1" xref="S2.SS3.p9.2.m2.1.1.cmml">1</mn><mo stretchy="false" id="S2.SS3.p9.2.m2.1.2.2.3.2.2" xref="S2.SS3.p9.2.m2.1.2.2.cmml">)</mo></mrow></mrow><mo id="S2.SS3.p9.2.m2.1.2.1" xref="S2.SS3.p9.2.m2.1.2.1.cmml">=</mo><mn id="S2.SS3.p9.2.m2.1.2.3" xref="S2.SS3.p9.2.m2.1.2.3.cmml">0.53</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p9.2.m2.1b"><apply id="S2.SS3.p9.2.m2.1.2.cmml" xref="S2.SS3.p9.2.m2.1.2"><eq id="S2.SS3.p9.2.m2.1.2.1.cmml" xref="S2.SS3.p9.2.m2.1.2.1"></eq><apply id="S2.SS3.p9.2.m2.1.2.2.cmml" xref="S2.SS3.p9.2.m2.1.2.2"><times id="S2.SS3.p9.2.m2.1.2.2.1.cmml" xref="S2.SS3.p9.2.m2.1.2.2.1"></times><ci id="S2.SS3.p9.2.m2.1.2.2.2.cmml" xref="S2.SS3.p9.2.m2.1.2.2.2">𝛾</ci><cn type="integer" id="S2.SS3.p9.2.m2.1.1.cmml" xref="S2.SS3.p9.2.m2.1.1">1</cn></apply><cn type="float" id="S2.SS3.p9.2.m2.1.2.3.cmml" xref="S2.SS3.p9.2.m2.1.2.3">0.53</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p9.2.m2.1c">\gamma(1)=0.53</annotation></semantics></math>. It means for non-iid data, the convergence stays low with any size of mini-batch. However, for iid data, <math id="S2.SS3.p9.3.m3.1" class="ltx_Math" alttext="\gamma" display="inline"><semantics id="S2.SS3.p9.3.m3.1a"><mi id="S2.SS3.p9.3.m3.1.1" xref="S2.SS3.p9.3.m3.1.1.cmml">γ</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.p9.3.m3.1b"><ci id="S2.SS3.p9.3.m3.1.1.cmml" xref="S2.SS3.p9.3.m3.1.1">𝛾</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p9.3.m3.1c">\gamma</annotation></semantics></math> grows quickly with the increasing batch size which ultimately increases the number of accurate updates. Therefore, signSGD can work on any batch size for training but becomes inefficient in non-iid environments.</p>
</div>
<div id="S2.SS3.p10" class="ltx_para">
<p id="S2.SS3.p10.1" class="ltx_p">Based on the above <span id="S2.SS3.p10.1.1" class="ltx_text ltx_font_italic">characteristics</span> and <span id="S2.SS3.p10.1.2" class="ltx_text ltx_font_italic">limitations</span> of FL environments, we conclude that any communication-efficient FL algorithm needs to attain the following requirements; 1) robust for non-iid environments, 2) scalable for dense networks, vigorous for partial participants and 3) communication compression in both directions; upstream and downstream.
The detailed comparison of FL algorithms based on these requirements is given in Table II. (<span id="S2.SS3.p10.1.3" class="ltx_text ltx_font_bold">Note:</span> In Table II, we call "Feasibility for Non-IID Environment" if the FL training converges in non-iid data. We call a "Upstream and Downstream Compression" if the algorithm supports compression in either direction. We call "scalability and partial participation" if the algorithm achieves the desired accuracy in a highly dense distributed network).</p>
</div>
<figure id="S2.T2" class="ltx_table">
<table id="S2.T2.2" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S2.T2.2.1.1" class="ltx_tr">
<th id="S2.T2.2.1.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t">
<span id="S2.T2.2.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T2.2.1.1.1.1.1" class="ltx_p" style="width:79.7pt;">FL Algorithms</span>
</span>
</th>
<th id="S2.T2.2.1.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_r ltx_border_t">
<span id="S2.T2.2.1.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T2.2.1.1.2.1.1" class="ltx_p" style="width:48.4pt;">Upstream and Downstream Compression</span>
</span>
</th>
<th id="S2.T2.2.1.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_r ltx_border_t">
<span id="S2.T2.2.1.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T2.2.1.1.3.1.1" class="ltx_p" style="width:42.7pt;">Scalability and Partial Participation</span>
</span>
</th>
<th id="S2.T2.2.1.1.4" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_r ltx_border_t">
<span id="S2.T2.2.1.1.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T2.2.1.1.4.1.1" class="ltx_p" style="width:42.7pt;">Feasibility for Non-IID Environment</span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S2.T2.2.2.1" class="ltx_tr">
<td id="S2.T2.2.2.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_tt">
<span id="S2.T2.2.2.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T2.2.2.1.1.1.1" class="ltx_p" style="width:79.7pt;">DGC <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>, Gradient Dropping <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>, Storm, Variance based <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite></span>
</span>
</td>
<td id="S2.T2.2.2.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt">
<span id="S2.T2.2.2.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T2.2.2.1.2.1.1" class="ltx_p" style="width:48.4pt;">Upstream</span>
</span>
</td>
<td id="S2.T2.2.2.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt">
<span id="S2.T2.2.2.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T2.2.2.1.3.1.1" class="ltx_p" style="width:42.7pt;">Weak</span>
</span>
</td>
<td id="S2.T2.2.2.1.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt">
<span id="S2.T2.2.2.1.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T2.2.2.1.4.1.1" class="ltx_p" style="width:42.7pt;">Yes</span>
</span>
</td>
</tr>
<tr id="S2.T2.2.3.2" class="ltx_tr">
<td id="S2.T2.2.3.2.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t">
<span id="S2.T2.2.3.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T2.2.3.2.1.1.1" class="ltx_p" style="width:79.7pt;">TrenGrad <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>, ATOMO <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>, QSGD <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite></span>
</span>
</td>
<td id="S2.T2.2.3.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S2.T2.2.3.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T2.2.3.2.2.1.1" class="ltx_p" style="width:48.4pt;">Upstream</span>
</span>
</td>
<td id="S2.T2.2.3.2.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S2.T2.2.3.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T2.2.3.2.3.1.1" class="ltx_p" style="width:42.7pt;">Weak</span>
</span>
</td>
<td id="S2.T2.2.3.2.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S2.T2.2.3.2.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T2.2.3.2.4.1.1" class="ltx_p" style="width:42.7pt;">No</span>
</span>
</td>
</tr>
<tr id="S2.T2.2.4.3" class="ltx_tr">
<td id="S2.T2.2.4.3.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t">
<span id="S2.T2.2.4.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T2.2.4.3.1.1.1" class="ltx_p" style="width:79.7pt;">SignSGD <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite></span>
</span>
</td>
<td id="S2.T2.2.4.3.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S2.T2.2.4.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T2.2.4.3.2.1.1" class="ltx_p" style="width:48.4pt;">Both</span>
</span>
</td>
<td id="S2.T2.2.4.3.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S2.T2.2.4.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T2.2.4.3.3.1.1" class="ltx_p" style="width:42.7pt;">Strong</span>
</span>
</td>
<td id="S2.T2.2.4.3.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S2.T2.2.4.3.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T2.2.4.3.4.1.1" class="ltx_p" style="width:42.7pt;">No</span>
</span>
</td>
</tr>
<tr id="S2.T2.2.5.4" class="ltx_tr">
<td id="S2.T2.2.5.4.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_l ltx_border_r ltx_border_t">
<span id="S2.T2.2.5.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T2.2.5.4.1.1.1" class="ltx_p" style="width:79.7pt;">Federated Averaging <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite></span>
</span>
</td>
<td id="S2.T2.2.5.4.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r ltx_border_t">
<span id="S2.T2.2.5.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T2.2.5.4.2.1.1" class="ltx_p" style="width:48.4pt;">Both</span>
</span>
</td>
<td id="S2.T2.2.5.4.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r ltx_border_t">
<span id="S2.T2.2.5.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T2.2.5.4.3.1.1" class="ltx_p" style="width:42.7pt;">Strong</span>
</span>
</td>
<td id="S2.T2.2.5.4.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r ltx_border_t">
<span id="S2.T2.2.5.4.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T2.2.5.4.4.1.1" class="ltx_p" style="width:42.7pt;">No</span>
</span>
</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S2.T2.3.1.1" class="ltx_text" style="font-size:90%;">TABLE II</span>: </span><span id="S2.T2.4.2" class="ltx_text" style="font-size:90%;">Comparison of various state-of-the-art algorithms for communication-efficient DL.</span></figcaption>
</figure>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">III </span><span id="S3.1.1" class="ltx_text ltx_font_smallcaps">Communication-Efficient Algorithms</span>
</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">In FL settings, the communication rounds between the server and participant devices are repeated till achieving desired accuracy. However, in the DL models of CNN and MLP training involves millions of parameters that results in high communication-cost. Moreover, the above mentioned limitations cause the delay in uploading the updates by participants. Therefore, the following approaches are proposed to minimise this delay and are considered for evaluation.</p>
</div>
<div id="S3.p2" class="ltx_para">
<ul id="S3.I1" class="ltx_itemize">
<li id="S3.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i1.p1" class="ltx_para">
<p id="S3.I1.i1.p1.1" class="ltx_p"><span id="S3.I1.i1.p1.1.1" class="ltx_text ltx_font_bold ltx_font_italic">FedAvg:</span> Federated Averaging (FedAvg) algorithm proposed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite> is evaluated on CIFAR-10 and MNIST datasets. The authors considered two different methods for on-device computation: (i) <span id="S3.I1.i1.p1.1.2" class="ltx_text ltx_font_italic">parallelism</span> that enables maximum device participations, (ii) <span id="S3.I1.i1.p1.1.3" class="ltx_text ltx_font_italic">computation per participant</span> that enhances local updates to achieve global aggregation. Based on the simulation results, parallelism shows no significant improvement after a certain threshold whereas computation per participant increases the accuracy by keeping a constant fraction of selected participant devices.</p>
</div>
</li>
<li id="S3.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i2.p1" class="ltx_para">
<p id="S3.I1.i2.p1.1" class="ltx_p"><span id="S3.I1.i2.p1.1.1" class="ltx_text ltx_font_bold ltx_font_italic">STC:</span> Sparse Ternary Compression (STC) proposed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite> to meet the general requirement of FL. The authors extend the top-k gradient technique with downstream compression. Considering IID and non-IID environments, results are evaluated compared to the FedAvg algorithm. The simulation results are taken using the CIFAR-10 and MNIST datasets for better comparison and show that STC enables a significant improvement in non-IID environments than FedAvg algorithm.</p>
</div>
</li>
<li id="S3.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i3.p1" class="ltx_para">
<p id="S3.I1.i3.p1.1" class="ltx_p"><span id="S3.I1.i3.p1.1.1" class="ltx_text ltx_font_bold ltx_font_italic">CMFL:</span> Communication-Mitigating Federated Learning (CMFL) proposed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite> to guarantee the global convergence by reducing the communication cost through uploading only relevant local update. To identify the relevancy of each update, participant devices are required to compare the local update with the global update in each iteration. Finally, global update will be done based on the computed relevance score, this global update is considered irrelevant when the relevant score is less than a certain threshold. Simulations experiments conducted on LSTM and MNIST datasets which shows that CMFL requires 13.97 and 3.47 times fewer iterations to achieve 80% accuracy as compared to FedAvg algorithm. Comparing with Gaia <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>, CMFL achieves better accuracy in fewer communication iterations.</p>
</div>
</li>
<li id="S3.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i4.p1" class="ltx_para">
<p id="S3.I1.i4.p1.1" class="ltx_p"><span id="S3.I1.i4.p1.1.1" class="ltx_text ltx_font_bold ltx_font_italic">FedMMD:</span> To alleviate the communication problem in non-IID environments, Federated Maximum and Mean Discrepancy (FedMMD) is proposed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>. During training, each participant learns from the other participants to fix the global model by incorporation of MMD into the loss function. Using MMD loss function, the participants are eligible to get more generalised features from global model which accelerates the convergence while reducing communication iterations. The simulation results are taken using CIFAR-10 and MNIST datasets which shows that accuracy is achieved in 20% fewer communication rounds as compared FedAvg in non-IID environments.</p>
</div>
</li>
<li id="S3.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i5.p1" class="ltx_para">
<p id="S3.I1.i5.p1.1" class="ltx_p"><span id="S3.I1.i5.p1.1.1" class="ltx_text ltx_font_bold ltx_font_italic">Fed-Dropout:</span> To reduce the server-to-participant costs, a lossy compression and federated dropout (Fed-Dropout) approach is proposed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite>. The Fed-Dropout approach uses activation functions for pre-defined number of iterations at fully connected layer to derive a sub-model which is received by the participants for training. Then, the updated sub-model is sent back towards the global model for obtaining a complete DNN model. Fed-Dropout succeeds not only in reducing the communication cost from server-to-participant but also reduces the size of update from participant-to-server. The simulation experiments are conducted on CIFAR-10 and MNIST datasets. Their results show that Fed-Dropout achieves 25% dropout rate for weight matrices on fully-connected layer and 43% size reduction in model communication.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">IV </span><span id="S4.1.1" class="ltx_text ltx_font_smallcaps">Algorithm Evaluations</span>
</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">Based on the aforementioned analysis, none of these algorithms proves the best possible solution. Therefore, they are considered for evaluation in order to find the gaps, issues and limitations which help us to propose a better FL algorithm.</p>
</div>
<div id="S4.p2" class="ltx_para">
<p id="S4.p2.1" class="ltx_p">For evaluations, we considered the following settings which are shared among all the algorithms mentioned in Section III.</p>
</div>
<figure id="S4.F2" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2"><img src="/html/2004.02738/assets/x2.png" id="S4.F2.g1" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_portrait" width="230" height="298" alt="Refer to caption"></div>
<div class="ltx_flex_cell ltx_flex_size_2"><img src="/html/2004.02738/assets/x3.png" id="S4.F2.g2" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_portrait" width="230" height="298" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F2.2.1.1" class="ltx_text" style="font-size:90%;">Figure 2</span>: </span><span id="S4.F2.3.2" class="ltx_text" style="font-size:90%;">Test-accuracy comparison w.r.t number of iterations on CIFAR-10 and MNIST datasets for IID environment.</span></figcaption>
</figure>
<figure id="S4.T3" class="ltx_table">
<table id="S4.T3.2" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T3.2.1.1" class="ltx_tr">
<th id="S4.T3.2.1.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t">
<span id="S4.T3.2.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.2.1.1.1.1.1" class="ltx_p" style="width:31.3pt;">Parameters</span>
</span>
</th>
<th id="S4.T3.2.1.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_r ltx_border_t">
<span id="S4.T3.2.1.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.2.1.1.2.1.1" class="ltx_p" style="width:28.5pt;">Clients</span>
</span>
</th>
<th id="S4.T3.2.1.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_r ltx_border_t">
<span id="S4.T3.2.1.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.2.1.1.3.1.1" class="ltx_p" style="width:42.7pt;">Participation</span>
</span>
</th>
<th id="S4.T3.2.1.1.4" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_r ltx_border_t">
<span id="S4.T3.2.1.1.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.2.1.1.4.1.1" class="ltx_p" style="width:31.3pt;">Classes</span>
</span>
</th>
<th id="S4.T3.2.1.1.5" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_r ltx_border_t">
<span id="S4.T3.2.1.1.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.2.1.1.5.1.1" class="ltx_p" style="width:42.7pt;">Batch Size</span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T3.2.2.1" class="ltx_tr">
<td id="S4.T3.2.2.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_l ltx_border_r ltx_border_tt">
<span id="S4.T3.2.2.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.2.2.1.1.1.1" class="ltx_p" style="width:31.3pt;">Value</span>
</span>
</td>
<td id="S4.T3.2.2.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r ltx_border_tt">
<span id="S4.T3.2.2.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.2.2.1.2.1.1" class="ltx_p" style="width:28.5pt;">i = 100</span>
</span>
</td>
<td id="S4.T3.2.2.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r ltx_border_tt">
<span id="S4.T3.2.2.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.2.2.1.3.1.1" class="ltx_p" style="width:42.7pt;">P = 10%</span>
</span>
</td>
<td id="S4.T3.2.2.1.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r ltx_border_tt">
<span id="S4.T3.2.2.1.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.2.2.1.4.1.1" class="ltx_p" style="width:31.3pt;">C = 10</span>
</span>
</td>
<td id="S4.T3.2.2.1.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r ltx_border_tt">
<span id="S4.T3.2.2.1.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.2.2.1.5.1.1" class="ltx_p" style="width:42.7pt;">S = 20</span>
</span>
</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S4.T3.3.1.1" class="ltx_text" style="font-size:90%;">TABLE III</span>: </span><span id="S4.T3.4.2" class="ltx_text" style="font-size:90%;">Federated baseline configuration considered in each of the aforementioned algorithms and we utilise these configuration for experimental evaluation.</span></figcaption>
</figure>
<figure id="S4.F3" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2"><img src="/html/2004.02738/assets/x4.png" id="S4.F3.g1" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_portrait" width="230" height="298" alt="Refer to caption"></div>
<div class="ltx_flex_cell ltx_flex_size_2"><img src="/html/2004.02738/assets/x5.png" id="S4.F3.g2" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_portrait" width="230" height="298" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F3.2.1.1" class="ltx_text" style="font-size:90%;">Figure 3</span>: </span><span id="S4.F3.3.2" class="ltx_text" style="font-size:90%;">Test-accuracy comparison w.r.t number of iterations on CIFAR-10 and MNIST datasets for non-IID environment.</span></figcaption>
</figure>
<figure id="S4.T4" class="ltx_table">
<table id="S4.T4.2" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T4.2.1.1" class="ltx_tr">
<th id="S4.T4.2.1.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t">
<span id="S4.T4.2.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T4.2.1.1.1.1.1" class="ltx_p" style="width:42.7pt;">Algorithms</span>
</span>
</th>
<th id="S4.T4.2.1.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_r ltx_border_t">
<span id="S4.T4.2.1.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T4.2.1.1.2.1.1" class="ltx_p" style="width:54.1pt;">Model</span>
</span>
</th>
<th id="S4.T4.2.1.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_r ltx_border_t">
<span id="S4.T4.2.1.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T4.2.1.1.3.1.1" class="ltx_p" style="width:59.8pt;">Datasets</span>
</span>
</th>
<th id="S4.T4.2.1.1.4" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_r ltx_border_t">
<span id="S4.T4.2.1.1.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T4.2.1.1.4.1.1" class="ltx_p" style="width:48.4pt;">Task</span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T4.2.2.1" class="ltx_tr">
<td id="S4.T4.2.2.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_tt">
<span id="S4.T4.2.2.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T4.2.2.1.1.1.1" class="ltx_p" style="width:42.7pt;">FedAvg</span>
</span>
</td>
<td id="S4.T4.2.2.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt">
<span id="S4.T4.2.2.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T4.2.2.1.2.1.1" class="ltx_p" style="width:54.1pt;">CNN</span>
</span>
</td>
<td id="S4.T4.2.2.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt">
<span id="S4.T4.2.2.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T4.2.2.1.3.1.1" class="ltx_p" style="width:59.8pt;">CIFAR &amp; MNIST</span>
</span>
</td>
<td id="S4.T4.2.2.1.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt">
<span id="S4.T4.2.2.1.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T4.2.2.1.4.1.1" class="ltx_p" style="width:48.4pt;">Learning Rate,</span>
</span>
</td>
</tr>
<tr id="S4.T4.2.3.2" class="ltx_tr">
<td id="S4.T4.2.3.2.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t">
<span id="S4.T4.2.3.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T4.2.3.2.1.1.1" class="ltx_p" style="width:42.7pt;">STC</span>
</span>
</td>
<td id="S4.T4.2.3.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S4.T4.2.3.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T4.2.3.2.2.1.1" class="ltx_p" style="width:54.1pt;">VGG11 &amp; CNN</span>
</span>
</td>
<td id="S4.T4.2.3.2.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S4.T4.2.3.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T4.2.3.2.3.1.1" class="ltx_p" style="width:59.8pt;">CIFAR &amp; MNIST</span>
</span>
</td>
<td id="S4.T4.2.3.2.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="S4.T4.2.3.2.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T4.2.3.2.4.1.1" class="ltx_p" style="width:48.4pt;">Iterations,</span>
</span>
</td>
</tr>
<tr id="S4.T4.2.4.3" class="ltx_tr">
<td id="S4.T4.2.4.3.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t">
<span id="S4.T4.2.4.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T4.2.4.3.1.1.1" class="ltx_p" style="width:42.7pt;">CMFL</span>
</span>
</td>
<td id="S4.T4.2.4.3.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S4.T4.2.4.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T4.2.4.3.2.1.1" class="ltx_p" style="width:54.1pt;">CNN</span>
</span>
</td>
<td id="S4.T4.2.4.3.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S4.T4.2.4.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T4.2.4.3.3.1.1" class="ltx_p" style="width:59.8pt;">CIFAR &amp; MNIST</span>
</span>
</td>
<td id="S4.T4.2.4.3.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="S4.T4.2.4.3.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T4.2.4.3.4.1.1" class="ltx_p" style="width:48.4pt;">Momentum,</span>
</span>
</td>
</tr>
<tr id="S4.T4.2.5.4" class="ltx_tr">
<td id="S4.T4.2.5.4.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t">
<span id="S4.T4.2.5.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T4.2.5.4.1.1.1" class="ltx_p" style="width:42.7pt;">FedMMD</span>
</span>
</td>
<td id="S4.T4.2.5.4.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S4.T4.2.5.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T4.2.5.4.2.1.1" class="ltx_p" style="width:54.1pt;">CNN &amp; MLP</span>
</span>
</td>
<td id="S4.T4.2.5.4.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S4.T4.2.5.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T4.2.5.4.3.1.1" class="ltx_p" style="width:59.8pt;">CIFAR &amp; MNIST</span>
</span>
</td>
<td id="S4.T4.2.5.4.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="S4.T4.2.5.4.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T4.2.5.4.4.1.1" class="ltx_p" style="width:48.4pt;">Accuracy &amp;</span>
</span>
</td>
</tr>
<tr id="S4.T4.2.6.5" class="ltx_tr">
<td id="S4.T4.2.6.5.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_l ltx_border_r ltx_border_t">
<span id="S4.T4.2.6.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T4.2.6.5.1.1.1" class="ltx_p" style="width:42.7pt;">Fed-Dropout</span>
</span>
</td>
<td id="S4.T4.2.6.5.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r ltx_border_t">
<span id="S4.T4.2.6.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T4.2.6.5.2.1.1" class="ltx_p" style="width:54.1pt;">CNN</span>
</span>
</td>
<td id="S4.T4.2.6.5.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r ltx_border_t">
<span id="S4.T4.2.6.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T4.2.6.5.3.1.1" class="ltx_p" style="width:59.8pt;">CIFAR &amp; MNIST</span>
</span>
</td>
<td id="S4.T4.2.6.5.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r">
<span id="S4.T4.2.6.5.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T4.2.6.5.4.1.1" class="ltx_p" style="width:48.4pt;">Parameters</span>
</span>
</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S4.T4.3.1.1" class="ltx_text" style="font-size:90%;">TABLE IV</span>: </span><span id="S4.T4.4.2" class="ltx_text" style="font-size:90%;">Hyper-Parameters and Models on Non-IID Data :-learning rate kept constant throughout training process</span></figcaption>
</figure>
<div id="S4.p3" class="ltx_para">
<p id="S4.p3.1" class="ltx_p">The baseline of FL environment is determined by four parameters. In specific, we set the base number of participant clients to 100 with 10% of participation ratio. Each client is assigned the same number of 10 different classes for training data. In Figures 2 and 3, all hyper-parameters are set to these baseline values as shown in Table III. In addition, the learning tasks and model classification for each algorithm is summarised in Table IV.</p>
</div>
<div id="S4.p4" class="ltx_para">
<p id="S4.p4.1" class="ltx_p">On the other hand, we have considered two ways of dividing the CIFAR-10 and MNIST datasets over the clients: 1) <span id="S4.p4.1.1" class="ltx_text ltx_font_bold">IID</span>, where the data is first shuffled and then divided among 100 clients, and 2) <span id="S4.p4.1.2" class="ltx_text ltx_font_bold">non-IID</span>, where the data is first sorted according to their labels and then evenly divided among 100 clients. Figures 2 and 3 show the comparison result of the accuracy of these algorithms <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>, <a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib23" title="" class="ltx_ref">23</a>, <a href="#bib.bib25" title="" class="ltx_ref">25</a>, <a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite> both in IID and non-IID environments, respectively.</p>
</div>
<div id="S4.p5" class="ltx_para">
<p id="S4.p5.1" class="ltx_p">In specific, Figure 2, shows the results of test-accuracy in IID environment. Due to the shuffling the data among clients, the accuracy of all four algorithms increases gradually but decay in amount of computation in later stages of convergence. This result shows that Fed-Dropout achieves higher accuracy in CIFAR-10 dataset and comparatively significant accuracy in MNIST dataset. Meanwhile, STC provides the same level of accuracy as Fed-Dropout at later stages of convergence in both CIFAR-10 and MNIST datasets. FedAvg is only considered in CIFAR-10 dataset and achieves better accuracy than FedMMD. Similarly, CMFL is considered only in MNIST dataset and achieves the highest level of accuracy whereas, FedDMMD achieves the lowest level of accuracy in both CIFAR-10 and MNIST datasets. The reason behind this is that in FedMMD each participant is required to learn from other participants which creates higher latency and results in minimum accuracy.</p>
</div>
<div id="S4.p6" class="ltx_para">
<p id="S4.p6.1" class="ltx_p">On the other hand, Figure 3 shows the test-accuracy of the aforementioned algorithms in non-IID environments. In specific, the results show that, in CIFAR-10 dataset Fed-Dropout achieves highest accuracy. Because Fed-Dropout utilises the fully connected layer and obtain a complete DNN model which helps in reducing the cost for both participants and server. Although performing good in CIFAR-10 dataset, Fed-Dropout couldn’t get higher accuracy in MNIST dataset. Afterwards, STC performs much better than FedMMD and Fed-Dropout in CIFAR-10 dataset. Meanwhile, FedMMD achieves the lowest accuracy in CIFAR-10 dataset but works far better in MNIST dataset. CMFL achieves the highest accuracy in MNIST dataset by utilising the only relevant update feature.</p>
</div>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">V </span><span id="S5.1.1" class="ltx_text ltx_font_smallcaps">Proposed Future Work</span>
</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.4" class="ltx_p">Based on the evaluation and analysis presented in this paper, it has been shown that training DL models using FL enhances the security, privacy, and reduces the communication costs. In the future work, we will mainly focus on non-IID environments, not only to reduce the communication costs, but also to provide the enhanced security features. Considering training <span id="S5.p1.4.1" class="ltx_text ltx_font_italic">MLP</span> and <span id="S5.p1.4.2" class="ltx_text ltx_font_italic">CNN</span> on <span id="S5.p1.4.3" class="ltx_text ltx_font_italic">CIFAR-10</span>, <span id="S5.p1.4.4" class="ltx_text ltx_font_italic">MNIST</span> and <span id="S5.p1.4.5" class="ltx_text ltx_font_italic">FEMNIST</span> datasets, we are hopeful to achieve better accuracy on the aforementioned datasets. Towards this end, we propose a data sharing strategy where the global data model aggregates from uniformly distributed stores. In specific, in the initialisation phase, the global model is trained on the global shared data where a small amount <math id="S5.p1.1.m1.1" class="ltx_Math" alttext="\Gamma" display="inline"><semantics id="S5.p1.1.m1.1a"><mi mathvariant="normal" id="S5.p1.1.m1.1.1" xref="S5.p1.1.m1.1.1.cmml">Γ</mi><annotation-xml encoding="MathML-Content" id="S5.p1.1.m1.1b"><ci id="S5.p1.1.m1.1.1.cmml" xref="S5.p1.1.m1.1.1">Γ</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.p1.1.m1.1c">\Gamma</annotation></semantics></math> of this shared data is distributed among all the participants from <math id="S5.p1.2.m2.1" class="ltx_Math" alttext="x_{1}" display="inline"><semantics id="S5.p1.2.m2.1a"><msub id="S5.p1.2.m2.1.1" xref="S5.p1.2.m2.1.1.cmml"><mi id="S5.p1.2.m2.1.1.2" xref="S5.p1.2.m2.1.1.2.cmml">x</mi><mn id="S5.p1.2.m2.1.1.3" xref="S5.p1.2.m2.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S5.p1.2.m2.1b"><apply id="S5.p1.2.m2.1.1.cmml" xref="S5.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S5.p1.2.m2.1.1.1.cmml" xref="S5.p1.2.m2.1.1">subscript</csymbol><ci id="S5.p1.2.m2.1.1.2.cmml" xref="S5.p1.2.m2.1.1.2">𝑥</ci><cn type="integer" id="S5.p1.2.m2.1.1.3.cmml" xref="S5.p1.2.m2.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p1.2.m2.1c">x_{1}</annotation></semantics></math> to <math id="S5.p1.3.m3.1" class="ltx_Math" alttext="x_{N}" display="inline"><semantics id="S5.p1.3.m3.1a"><msub id="S5.p1.3.m3.1.1" xref="S5.p1.3.m3.1.1.cmml"><mi id="S5.p1.3.m3.1.1.2" xref="S5.p1.3.m3.1.1.2.cmml">x</mi><mi id="S5.p1.3.m3.1.1.3" xref="S5.p1.3.m3.1.1.3.cmml">N</mi></msub><annotation-xml encoding="MathML-Content" id="S5.p1.3.m3.1b"><apply id="S5.p1.3.m3.1.1.cmml" xref="S5.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S5.p1.3.m3.1.1.1.cmml" xref="S5.p1.3.m3.1.1">subscript</csymbol><ci id="S5.p1.3.m3.1.1.2.cmml" xref="S5.p1.3.m3.1.1.2">𝑥</ci><ci id="S5.p1.3.m3.1.1.3.cmml" xref="S5.p1.3.m3.1.1.3">𝑁</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p1.3.m3.1c">x_{N}</annotation></semantics></math>. Once all the participants update their shared data portion, then the server aggregates the local model to train the global model. In general, we will consider two tradeoffs; (i) the tradeoff between the size of global model and test accuracy, (ii) the tradeoff between test accuracy and the amount of shared data <math id="S5.p1.4.m4.1" class="ltx_Math" alttext="\Gamma" display="inline"><semantics id="S5.p1.4.m4.1a"><mi mathvariant="normal" id="S5.p1.4.m4.1.1" xref="S5.p1.4.m4.1.1.cmml">Γ</mi><annotation-xml encoding="MathML-Content" id="S5.p1.4.m4.1b"><ci id="S5.p1.4.m4.1.1.cmml" xref="S5.p1.4.m4.1.1">Γ</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.p1.4.m4.1c">\Gamma</annotation></semantics></math>. For improving the security, we plan to combine the secure multiparty computation (SMC) and differential privacy (which are proposed separately in all the existing literature). Since the number of participants is high in FL, we utilise this combined technique to increase the trust-rate among participants. Therefore, we assume that the proposed model will be scalable and able to provide the highest security against threats with the maximum accuracy in communication.</p>
</div>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VI </span><span id="S6.1.1" class="ltx_text ltx_font_smallcaps">Conclusion</span>
</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">In this paper, we present an evaluation of the communication efficiency in FL. We begin with introduction to FL and the need for communication efficient algorithms and explains that FL can play a vital role in promoting the security features while reducing communication cost of mobile devices. Then, we describe the fundamentals of FL by revealing the challenging characteristics of the available FL frameworks. Afterwards, we provide a detailed review of the state-of-the-art FL models, datasets and algorithms. Furthermore, we provide a detailed statistical and experimental evaluation of the existing FL algorithms. This motivates us to propose a novel FL strategy as our future work to improve both security and communication aspects.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
S. Wiedemann, K.-R. Müller, and W. Samek, “Compact and computationally
efficient representation of deep neural networks,” <em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">IEEE transactions
on neural networks and learning systems</em>, 2019.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
H. B. McMahan, E. Moore, D. Ramage, S. Hampson <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">et al.</em>,
“Communication-efficient learning of deep networks from decentralized
data,” <em id="bib.bib2.2.2" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1602.05629</em>, 2016.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
H. B. McMahan, E. Moore, D. Ramage, and B. A. y Arcas, “Federated learning of
deep networks using model averaging,” 2016.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
W. Y. B. Lim, N. C. Luong, D. T. Hoang, Y. Jiao, Y.-C. Liang, Q. Yang,
D. Niyato, and C. Miao, “Federated learning in mobile edge networks: A
comprehensive survey,” <em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1909.11875</em>, 2019.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
A. Reisizadeh, A. Mokhtari, H. Hassani, A. Jadbabaie, and R. Pedarsani,
“Fedpaq: A communication-efficient federated learning method with periodic
averaging and quantization,” <em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1909.13014</em>, 2019.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
F. Ang, L. Chen, N. Zhao, Y. Chen, W. Wang, and F. R. Yu, “Robust federated
learning with noisy communication,” <em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1911.00251</em>,
2019.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
M. Nasr, R. Shokri, and A. Houmansadr, “Comprehensive privacy analysis of deep
learning: Passive and active white-box inference attacks against centralized
and federated learning,” in <em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">2019 IEEE Symposium on Security and
Privacy (SP)</em>.   IEEE, 2019, pp.
739–753.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
Y. Zhao, M. Li, L. Lai, N. Suda, D. Civin, and V. Chandra, “Federated learning
with non-iid data,” <em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1806.00582</em>, 2018.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
T. Nishio and R. Yonetani, “Client selection for federated learning with
heterogeneous resources in mobile edge,” in <em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">ICC 2019-2019 IEEE
International Conference on Communications (ICC)</em>.   IEEE, 2019, pp. 1–7.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
F. Sattler, S. Wiedemann, K.-R. Müller, and W. Samek, “Robust and
communication-efficient federated learning from non-iid data,” <em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">arXiv
preprint arXiv:1903.02891</em>, 2019.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
“Google, “tensorflow federated: Machine learning on decentralized data.”

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
T. Ryffel, A. Trask, M. Dahl, B. Wagner, J. Mancuso, D. Rueckert, and
J. Passerat-Palmbach, “A generic framework for privacy preserving deep
learning,” <em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1811.04017</em>, 2018.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
S. Caldas, P. Wu, T. Li, J. Konečnỳ, H. B. McMahan, V. Smith, and
A. Talwalkar, “Leaf: A benchmark for federated settings,” <em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">arXiv
preprint arXiv:1812.01097</em>, 2018.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
X. Li, K. Huang, W. Yang, S. Wang, and Z. Zhang, “On the convergence of fedavg
on non-iid data,” <em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1907.02189</em>, 2019.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
J. Bernstein, Y.-X. Wang, K. Azizzadenesheli, and A. Anandkumar, “signsgd:
Compressed optimisation for non-convex problems,” <em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">arXiv preprint
arXiv:1802.04434</em>, 2018.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
J. Bernstein, J. Zhao, K. Azizzadenesheli, and A. Anandkumar, “signsgd with
majority vote is communication efficient and fault tolerant,” <em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">arXiv</em>,
2018.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
Y. Lin, S. Han, H. Mao, Y. Wang, and W. J. Dally, “Deep gradient compression:
Reducing the communication bandwidth for distributed training,” <em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">arXiv
preprint arXiv:1712.01887</em>, 2017.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
A. F. Aji and K. Heafield, “Sparse communication for distributed gradient
descent,” <em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1704.05021</em>, 2017.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
N. Strom, “Scalable distributed dnn training using commodity gpu cloud
computing,” in <em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">Sixteenth Annual Conference of the International Speech
Communication Association</em>, 2015.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
W. Wen, C. Xu, F. Yan, C. Wu, Y. Wang, Y. Chen, and H. Li, “Terngrad: Ternary
gradients to reduce communication in distributed deep learning,” in
<em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">Advances in neural information processing systems</em>, 2017, pp.
1509–1519.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
H. Wang, S. Sievert, S. Liu, Z. Charles, D. Papailiopoulos, and S. Wright,
“Atomo: Communication-efficient learning via atomic sparsification,” in
<em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>, 2018, pp.
9850–9861.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
D. Alistarh, D. Grubic, J. Li, R. Tomioka, and M. Vojnovic, “Qsgd:
Communication-efficient sgd via gradient quantization and encoding,” in
<em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>, 2017, pp.
1709–1720.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
L. Wang, W. Wang, and B. Li, “Cmfl: Mitigating communication overhead for
federated learning.”

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
K. Hsieh, A. Harlap, N. Vijaykumar, D. Konomis, G. R. Ganger, P. B. Gibbons,
and O. Mutlu, “Gaia: Geo-distributed machine learning approaching
<math id="bib.bib24.1.m1.1" class="ltx_Math" alttext="\{" display="inline"><semantics id="bib.bib24.1.m1.1a"><mo stretchy="false" id="bib.bib24.1.m1.1.1" xref="bib.bib24.1.m1.1.1.cmml">{</mo><annotation-xml encoding="MathML-Content" id="bib.bib24.1.m1.1b"><ci id="bib.bib24.1.m1.1.1.cmml" xref="bib.bib24.1.m1.1.1">{</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib24.1.m1.1c">\{</annotation></semantics></math>LAN<math id="bib.bib24.2.m2.1" class="ltx_Math" alttext="\}" display="inline"><semantics id="bib.bib24.2.m2.1a"><mo stretchy="false" id="bib.bib24.2.m2.1.1" xref="bib.bib24.2.m2.1.1.cmml">}</mo><annotation-xml encoding="MathML-Content" id="bib.bib24.2.m2.1b"><ci id="bib.bib24.2.m2.1.1.cmml" xref="bib.bib24.2.m2.1.1">}</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib24.2.m2.1c">\}</annotation></semantics></math> speeds,” in <em id="bib.bib24.6.4" class="ltx_emph ltx_font_italic">14th <math id="bib.bib24.3.1.m1.1" class="ltx_Math" alttext="\{" display="inline"><semantics id="bib.bib24.3.1.m1.1a"><mo stretchy="false" id="bib.bib24.3.1.m1.1.1" xref="bib.bib24.3.1.m1.1.1.cmml">{</mo><annotation-xml encoding="MathML-Content" id="bib.bib24.3.1.m1.1b"><ci id="bib.bib24.3.1.m1.1.1.cmml" xref="bib.bib24.3.1.m1.1.1">{</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib24.3.1.m1.1c">\{</annotation></semantics></math>USENIX<math id="bib.bib24.4.2.m2.1" class="ltx_Math" alttext="\}" display="inline"><semantics id="bib.bib24.4.2.m2.1a"><mo stretchy="false" id="bib.bib24.4.2.m2.1.1" xref="bib.bib24.4.2.m2.1.1.cmml">}</mo><annotation-xml encoding="MathML-Content" id="bib.bib24.4.2.m2.1b"><ci id="bib.bib24.4.2.m2.1.1.cmml" xref="bib.bib24.4.2.m2.1.1">}</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib24.4.2.m2.1c">\}</annotation></semantics></math> Symposium on Networked
Systems Design and Implementation (<math id="bib.bib24.5.3.m3.1" class="ltx_Math" alttext="\{" display="inline"><semantics id="bib.bib24.5.3.m3.1a"><mo stretchy="false" id="bib.bib24.5.3.m3.1.1" xref="bib.bib24.5.3.m3.1.1.cmml">{</mo><annotation-xml encoding="MathML-Content" id="bib.bib24.5.3.m3.1b"><ci id="bib.bib24.5.3.m3.1.1.cmml" xref="bib.bib24.5.3.m3.1.1">{</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib24.5.3.m3.1c">\{</annotation></semantics></math>NSDI<math id="bib.bib24.6.4.m4.1" class="ltx_Math" alttext="\}" display="inline"><semantics id="bib.bib24.6.4.m4.1a"><mo stretchy="false" id="bib.bib24.6.4.m4.1.1" xref="bib.bib24.6.4.m4.1.1.cmml">}</mo><annotation-xml encoding="MathML-Content" id="bib.bib24.6.4.m4.1b"><ci id="bib.bib24.6.4.m4.1.1.cmml" xref="bib.bib24.6.4.m4.1.1">}</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib24.6.4.m4.1c">\}</annotation></semantics></math> 17)</em>, 2017, pp. 629–647.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
X. Yao, T. Huang, C. Wu, R.-x. Zhang, and L. Sun, “Federated learning with
additional mechanisms on clients to reduce communication costs,” <em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">arXiv
preprint arXiv:1908.05891</em>, 2019.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
S. Caldas, J. Konečny, H. B. McMahan, and A. Talwalkar, “Expanding the
reach of federated learning by reducing client resource requirements,”
<em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1812.07210</em>, 2018.


</span>
</li>
</ul>
</section>
<div id="p1" class="ltx_para">
<p id="p1.1" class="ltx_p"></p>
</div>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2004.02737" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2004.02738" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2004.02738">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2004.02738" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2004.02740" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Thu Mar  7 09:19:47 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
