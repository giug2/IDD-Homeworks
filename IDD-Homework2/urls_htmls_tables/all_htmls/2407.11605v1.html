<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Interactions with Generative Information Retrieval Systems</title>
<!--Generated on Tue Jul 16 11:06:04 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2407.11605v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#S1" title="In Interactions with Generative Information Retrieval Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#S2" title="In Interactions with Generative Information Retrieval Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Expressing Information Needs</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#S3" title="In Interactions with Generative Information Retrieval Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Proactive Feedback</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#S4" title="In Interactions with Generative Information Retrieval Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Result Refinement</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#S4.SS1" title="In 4 Result Refinement ‣ Interactions with Generative Information Retrieval Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>An Overview of Result Refinement</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#S4.SS2" title="In 4 Result Refinement ‣ Interactions with Generative Information Retrieval Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Technical Challenges</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#S5" title="In Interactions with Generative Information Retrieval Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Clarification</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#S5.SS1" title="In 5 Clarification ‣ Interactions with Generative Information Retrieval Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1 </span>An Overview of Search Clarification</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#S5.SS2" title="In 5 Clarification ‣ Interactions with Generative Information Retrieval Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2 </span>Technical Challenges</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#S6" title="In Interactions with Generative Information Retrieval Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Proactive Interactions</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#S6.SS1" title="In 6 Proactive Interactions ‣ Interactions with Generative Information Retrieval Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.1 </span>An Overview of Proactive Generative Retrieval Systems</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#S6.SS2" title="In 6 Proactive Interactions ‣ Interactions with Generative Information Retrieval Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.2 </span>User Responses to Proactive Interactions</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#S6.SS3" title="In 6 Proactive Interactions ‣ Interactions with Generative Information Retrieval Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.3 </span>Technical Challenges</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#S6.SS4" title="In 6 Proactive Interactions ‣ Interactions with Generative Information Retrieval Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.4 </span>Evaluation of Proactive Systems</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#S7" title="In Interactions with Generative Information Retrieval Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7 </span>Explanation</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#S7.SS1" title="In 7 Explanation ‣ Interactions with Generative Information Retrieval Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7.1 </span>An Overview of Explanation in IR</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#S7.SS2" title="In 7 Explanation ‣ Interactions with Generative Information Retrieval Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7.2 </span>Modes of Explanation in Generative IR</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#S8" title="In Interactions with Generative Information Retrieval Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">8 </span>Multi-Modal Interactions</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#S9" title="In Interactions with Generative Information Retrieval Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">9 </span>User Interfaces</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#S10" title="In Interactions with Generative Information Retrieval Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">10 </span>Conclusions</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<div class="ltx_para" id="p1">
<p class="ltx_p" id="p1.1">*[inlinelist,1]label=(),










<span class="ltx_note ltx_role_institutetext" id="p1.1.1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">institutetext: </span>University of Amsterdam, The Netherlands
<br class="ltx_break"/><span class="ltx_note ltx_role_email" id="p1.1.1.1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">email: </span>m.aliannejadi@uva.nl</span></span></span> </span></span></span><span class="ltx_note ltx_role_institutetext" id="p1.1.2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_note_type">institutetext: </span>University of Texas at Austin, United States
<br class="ltx_break"/><span class="ltx_note ltx_role_email" id="p1.1.2.1"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_note_type">email: </span>jacekg@utexas.edu</span></span></span> </span></span></span><span class="ltx_note ltx_role_institutetext" id="p1.1.3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_note_type">institutetext: </span>University of Massachusetts Amherst
<br class="ltx_break"/><span class="ltx_note ltx_role_email" id="p1.1.3.1"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_note_type">email: </span>zamani@cs.umass.edu</span></span></span>
<br class="ltx_break"/> 
<br class="ltx_break"/> 
<br class="ltx_break"/>Draft of a chapter intended to appear in a forthcoming book on generative information retrieval, co-edited by Chirag Shah and Ryen White.
</span></span></span>
</p>
</div>
<h1 class="ltx_title ltx_title_document">Interactions with Generative Information Retrieval Systems</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Mohammad Aliannejadi
</span><span class="ltx_author_notes">11</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Jacek Gwizdka
</span><span class="ltx_author_notes">22</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Hamed Zamani
</span><span class="ltx_author_notes">33</span></span>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">At its core, information access and seeking is an interactive process. In existing search engines, interactions are limited to a few pre-defined actions, such as “requery”, “click on a document”, “scrolling up/down”, “going to the next result page”, “leaving the search engine”, etc. A major benefit of moving towards generative IR systems is enabling users with a richer expression of information need and feedback and free-form interactions in natural language and beyond. In other words, the actions users take are no longer limited by the clickable links and buttons available on the search engine result page and users can express themselves freely through natural language. This can go even beyond natural language, through images, videos, gestures, and sensors using multi-modal generative IR systems. This chapter briefly discusses the role of <em class="ltx_emph ltx_font_italic" id="S1.p1.1.1">interaction</em> in generative IR systems. We will first discuss different ways users can express their information needs by interacting with generative IR systems (Section <a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#S2" title="2 Expressing Information Needs ‣ Interactions with Generative Information Retrieval Systems"><span class="ltx_text ltx_ref_tag">2</span></a>). We then explain how users can provide explicit or implicit feedback to generative IR systems and how they can consume such feedback (Section <a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#S3" title="3 Proactive Feedback ‣ Interactions with Generative Information Retrieval Systems"><span class="ltx_text ltx_ref_tag">3</span></a>). Next, we will cover how users interactively can refine retrieval results (Section <a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#S4" title="4 Result Refinement ‣ Interactions with Generative Information Retrieval Systems"><span class="ltx_text ltx_ref_tag">4</span></a>). We will expand upon mixed-initiative interactions and discuss clarification and preference elicitation in more detail (Section <a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#S5" title="5 Clarification ‣ Interactions with Generative Information Retrieval Systems"><span class="ltx_text ltx_ref_tag">5</span></a>). We then discuss proactive generative IR systems, including context-aware recommendation, following up past conversations, contributing to multi-party conversations, and feedback requests (Section <a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#S6" title="6 Proactive Interactions ‣ Interactions with Generative Information Retrieval Systems"><span class="ltx_text ltx_ref_tag">6</span></a>). Providing explanation is another interaction type that we briefly discuss in this chapter (Section <a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#S7" title="7 Explanation ‣ Interactions with Generative Information Retrieval Systems"><span class="ltx_text ltx_ref_tag">7</span></a>). We will also briefly describe multi-modal interactions in generative information retrieval (Section <a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#S8" title="8 Multi-Modal Interactions ‣ Interactions with Generative Information Retrieval Systems"><span class="ltx_text ltx_ref_tag">8</span></a>). Finally, we describe emerging frameworks and solutions for user interfaces with generative AI systems (Section <a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#S9" title="9 User Interfaces ‣ Interactions with Generative Information Retrieval Systems"><span class="ltx_text ltx_ref_tag">9</span></a>). We conclude with a question: Will the myriad interaction possibilities afforded by generative AI systems be embraced by a broad user base, or will they remain merely a research curiosity?</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Expressing Information Needs</h2>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">An information need is what prompts users to seek information through various means, such as asking others, consulting printed resources, other media, or searching online. It arises from the awareness of a gap in a user’s knowledge or understanding, necessitating the acquisition of information to bridge that gap
 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib12" title="">12</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib25" title="">25</a>]</cite>. Bridging the gap helps to fulfill a specific purpose or goal, which is typically driven by a work task  <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib13" title="">13</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S2.p2">
<p class="ltx_p" id="S2.p2.1">Prompt-based interactions with <span class="ltx_glossaryref" title="large language models"><span class="ltx_text ltx_glossary_long-plural">large language modelss</span></span>, and more broadly, multi-modal interactions with <abbr class="ltx_glossaryref" title="large language models"><span class="ltx_text ltx_glossary_short-plural">LLMs</span></abbr>-based systems, provide an opportunity to fundamentally rethink the processes of searching for, finding, and using information, and how to support these activities. This fresh perspective has the potential to significantly transform user experience by enhancing how users express their information needs and achieve their goals.</p>
</div>
<div class="ltx_para" id="S2.p3">
<p class="ltx_p" id="S2.p3.1">We will frame our considerations using the information need model proposed by Robert Taylor in the 1960s <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib69" title="">69</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib70" title="">70</a>]</cite>. Taylor identified four levels of information need, each helping us to understand how users formulate questions in their minds, how they articulate them, and how they interact with information systems. The four levels of information need are: (1) <span class="ltx_text ltx_font_bold" id="S2.p3.1.1">Visceral Need</span>: An inexpressible, unformulated need, felt as a vague sense of dissatisfaction, (2) <span class="ltx_text ltx_font_bold" id="S2.p3.1.2">Conscious Need</span>: The user is aware of the need but cannot fully articulate it, (3) <span class="ltx_text ltx_font_bold" id="S2.p3.1.3">Formalized Need</span>: The need can be clearly expressed and defined, (4) <span class="ltx_text ltx_font_bold" id="S2.p3.1.4">Compromised Need</span>: The articulated need, as presented to an information system, often simplified or altered to fit the system’s capabilities.</p>
</div>
<div class="ltx_para" id="S2.p4">
<p class="ltx_p" id="S2.p4.1">Traditional search systems typically support levels 3 and 4, but not 1 and 2. We believe that <abbr class="ltx_glossaryref" title="large language models"><span class="ltx_text ltx_glossary_short-plural">LLMs</span></abbr>-based information access systems have the potential to support all four levels. Therefore, we use these four levels to structure our speculative list of ways users could be assisted in their interactions with generative AI. We will draw, in part, on well-known information seeking models
<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib45" title="">45</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib40" title="">40</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S2.p5">
<p class="ltx_p" id="S2.p5.1">Support for <span class="ltx_text ltx_font_bold" id="S2.p5.1.1">Visceral Need</span>:
(1) <span class="ltx_text ltx_font_italic" id="S2.p5.1.2">exploratory interactions</span>: provide users with broad, exploratory dialogue that might help users <span class="ltx_text ltx_font_italic" id="S2.p5.1.3">clarify</span> their thoughts; suggest related topics to help users better understand and articulate their needs. This is an example of <a class="ltx_ref ltx_refmacro_nameref" href="https://arxiv.org/html/2407.11605v1#S5" title="In Interactions with Generative Information Retrieval Systems"><span class="ltx_text ltx_ref_title">Clarification</span></a> which we describe in Section <a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#S5" title="5 Clarification ‣ Interactions with Generative Information Retrieval Systems"><span class="ltx_text ltx_ref_tag">5</span></a>.
(2) <span class="ltx_text ltx_font_italic" id="S2.p5.1.4">prompt suggestions</span>: offer prompt suggestions or follow-up questions to guide users towards more specific questions. This is an example of <a class="ltx_ref ltx_refmacro_nameref" href="https://arxiv.org/html/2407.11605v1#S6" title="In Interactions with Generative Information Retrieval Systems"><span class="ltx_text ltx_ref_title">Proactive Interactions</span></a> which we describe in Section <a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#S6" title="6 Proactive Interactions ‣ Interactions with Generative Information Retrieval Systems"><span class="ltx_text ltx_ref_tag">6</span></a>.</p>
</div>
<div class="ltx_para" id="S2.p6">
<p class="ltx_p" id="S2.p6.1">Support for <span class="ltx_text ltx_font_bold" id="S2.p6.1.1">Conscious Need</span>:
(1) <span class="ltx_text ltx_font_italic" id="S2.p6.1.2">partial expression of needs</span>: accept partially formed questions or statements of need;
(2) <span class="ltx_text ltx_font_italic" id="S2.p6.1.3">proactive support for refinement</span>: generate relevant information that helps users <span class="ltx_text ltx_font_italic" id="S2.p6.1.4">refine</span> their understanding of what they’re looking for;
(3) <span class="ltx_text ltx_font_italic" id="S2.p6.1.5">guided conversations</span>: engage in a dialogue to help users articulate their needs more precisely. We describe such approaches in more detail in <a class="ltx_ref ltx_refmacro_nameref" href="https://arxiv.org/html/2407.11605v1#S4" title="In Interactions with Generative Information Retrieval Systems"><span class="ltx_text ltx_ref_title">Result Refinement</span></a> (Section <a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#S4" title="4 Result Refinement ‣ Interactions with Generative Information Retrieval Systems"><span class="ltx_text ltx_ref_tag">4</span></a>) and <a class="ltx_ref ltx_refmacro_nameref" href="https://arxiv.org/html/2407.11605v1#S6" title="In Interactions with Generative Information Retrieval Systems"><span class="ltx_text ltx_ref_title">Proactive Interactions</span></a> (Section <a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#S6" title="6 Proactive Interactions ‣ Interactions with Generative Information Retrieval Systems"><span class="ltx_text ltx_ref_tag">6</span></a>).</p>
</div>
<div class="ltx_para" id="S2.p7">
<p class="ltx_p" id="S2.p7.1">Support for <span class="ltx_text ltx_font_bold" id="S2.p7.1.1">Formalized Need</span>:
(1) <span class="ltx_text ltx_font_italic" id="S2.p7.1.2">direct queries</span>: respond directly to well-formulated questions with relevant information;
(2) <span class="ltx_text ltx_font_italic" id="S2.p7.1.3">structured responses</span>: provide detailed, structured responses that address specific aspects of the user’s need;
(3) <span class="ltx_text ltx_font_italic" id="S2.p7.1.4">advanced features</span>: offer options (e.g., filters) for further exploration or <span class="ltx_text ltx_font_italic" id="S2.p7.1.5">clarification</span> based on the formalized need.</p>
</div>
<div class="ltx_para" id="S2.p8">
<p class="ltx_p" id="S2.p8.1">Finally, support for <span class="ltx_text ltx_font_bold" id="S2.p8.1.1">Compromised Need</span>:
(1) <span class="ltx_text ltx_font_italic" id="S2.p8.1.2">flexibility of syntax</span>: offer flexibility to allow for iterative refinement of queries without strict syntax requirements;
(2) <span class="ltx_text ltx_font_italic" id="S2.p8.1.3">flexibility of language</span>: interpret and respond to a wide range of query formats, reducing the need for users to adapt their language significantly;
(3) <span class="ltx_text ltx_font_italic" id="S2.p8.1.4">feedback loop</span>: offer feedback on questions, suggesting modifications or alternative phrasings to better match the user’s needs and system’s capabilities. We describe such approaches in more detail in <a class="ltx_ref ltx_refmacro_nameref" href="https://arxiv.org/html/2407.11605v1#S3" title="In Interactions with Generative Information Retrieval Systems"><span class="ltx_text ltx_ref_title">Proactive Feedback</span></a> (Section <a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#S3" title="3 Proactive Feedback ‣ Interactions with Generative Information Retrieval Systems"><span class="ltx_text ltx_ref_tag">3</span></a>).</p>
</div>
<div class="ltx_para" id="S2.p9">
<p class="ltx_p" id="S2.p9.1">Overall, the key advantages of <abbr class="ltx_glossaryref" title="large language models"><span class="ltx_text ltx_glossary_short-plural">LLMs</span></abbr> in assisting users at all four levels of information need are:</p>
<ul class="ltx_itemize" id="S2.I1">
<li class="ltx_item" id="S2.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S2.I1.i1.p1">
<p class="ltx_p" id="S2.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S2.I1.i1.p1.1.1">Natural Language Processing</span>: <abbr class="ltx_glossaryref" title="large language models"><span class="ltx_text ltx_glossary_short-plural">LLMs</span></abbr> can understand and respond to queries expressed in natural language, making them accessible even at the visceral and conscious need levels.</p>
</div>
</li>
<li class="ltx_item" id="S2.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S2.I1.i2.p1">
<p class="ltx_p" id="S2.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S2.I1.i2.p1.1.1">Contextual Understanding</span>: Advanced <abbr class="ltx_glossaryref" title="large language models"><span class="ltx_text ltx_glossary_short-plural">LLMs</span></abbr> can maintain context over multiple interactions, allowing for a more nuanced exploration of information needs.</p>
</div>
</li>
<li class="ltx_item" id="S2.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S2.I1.i3.p1">
<p class="ltx_p" id="S2.I1.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S2.I1.i3.p1.1.1">Broad Knowledge Base</span>: <abbr class="ltx_glossaryref" title="large language models"><span class="ltx_text ltx_glossary_short-plural">LLMs</span></abbr> draw upon a vast range of information, potentially addressing needs across various domains and levels of specificity.</p>
</div>
</li>
<li class="ltx_item" id="S2.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S2.I1.i4.p1">
<p class="ltx_p" id="S2.I1.i4.p1.1"><span class="ltx_text ltx_font_bold" id="S2.I1.i4.p1.1.1">Adaptive Responses</span>: <abbr class="ltx_glossaryref" title="large language models"><span class="ltx_text ltx_glossary_short-plural">LLMs</span></abbr> can tailor their responses based on the perceived level of the user’s information need, understanding and responding to both simple and complex questions and providing more or less detail as appropriate.</p>
</div>
</li>
<li class="ltx_item" id="S2.I1.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S2.I1.i5.p1">
<p class="ltx_p" id="S2.I1.i5.p1.1"><span class="ltx_text ltx_font_bold" id="S2.I1.i5.p1.1.1">Iterative Refinement</span>: The conversational nature of <abbr class="ltx_glossaryref" title="large language models"><span class="ltx_text ltx_glossary_short-plural">LLMs</span></abbr> interactions allows users to refine their queries progressively, moving from visceral to formalized needs through dialogue</p>
</div>
</li>
<li class="ltx_item" id="S2.I1.i6" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S2.I1.i6.p1">
<p class="ltx_p" id="S2.I1.i6.p1.1"><span class="ltx_text ltx_font_bold" id="S2.I1.i6.p1.1.1">Enhanced Expressiveness</span>: Prompt-based interactions allow users to express their needs in more nuanced and detailed ways. Users can specify the format, tone, and depth of the information they seek, which can lead to more tailored and useful outputs. For instance, users can request summaries, detailed explanations, comparisons, or creative content, depending on their needs.</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="S2.p10">
<p class="ltx_p" id="S2.p10.1">However, it’s important to note that while <abbr class="ltx_glossaryref" title="large language models"><span class="ltx_text ltx_glossary_short-plural">LLMs</span></abbr> offer powerful capabilities in addressing information needs across Taylor’s levels, they also have limitations. They may sometimes provide plausible-sounding but incorrect information, lack true understanding of context beyond the immediate conversation, and cannot replace the critical thinking and expertise of human information professionals in complex scenarios.</p>
</div>
<div class="ltx_para" id="S2.p11">
<p class="ltx_p" id="S2.p11.1">While <abbr class="ltx_glossaryref" title="large language models"><span class="ltx_text ltx_glossary_short-plural">LLMs</span></abbr> can offer enhanced capabilities for expressing information needs, they also introduce new challenges. Such as <span class="ltx_text ltx_font_italic" id="S2.p11.1.1">Capability Gap</span>: users may struggle to formulate their intentions clearly and effectively, leading to a gap between what they want and what the <abbr class="ltx_glossaryref" title="large language models"><span class="ltx_text ltx_glossary_short-plural">LLMs</span></abbr> provides.
<span class="ltx_text ltx_font_italic" id="S2.p11.1.2">Instruction Gap</span>: users need to learn how to craft effective prompts, which can involve understanding the <abbr class="ltx_glossaryref" title="large language models"><span class="ltx_text ltx_glossary_short-plural">LLMs</span></abbr>’s capabilities and limitations.
<span class="ltx_text ltx_font_italic" id="S2.p11.1.3">Evaluation of Outputs</span>: users must critically evaluate the <abbr class="ltx_glossaryref" title="large language models"><span class="ltx_text ltx_glossary_short-plural">LLMs</span></abbr>’s responses for accuracy and relevance, as <abbr class="ltx_glossaryref" title="large language models"><span class="ltx_text ltx_glossary_short-plural">LLMs</span></abbr> can sometimes generate incorrect or misleading information.
A recent paper introduced these three gaps and termed them collectively the <span class="ltx_text ltx_font_italic" id="S2.p11.1.4">”Gulf of Envisioning”</span>  <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib64" title="">64</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S2.p12">
<p class="ltx_p" id="S2.p12.1">In the following sections we address selected aspects of user-<abbr class="ltx_glossaryref" title="large language models"><span class="ltx_text ltx_glossary_short-plural">LLMs</span></abbr>-based-system-interactions, <a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#S3" title="3 Proactive Feedback ‣ Interactions with Generative Information Retrieval Systems"><span class="ltx_text ltx_ref_tag">3</span></a> <a class="ltx_ref ltx_refmacro_nameref" href="https://arxiv.org/html/2407.11605v1#S3" title="In Interactions with Generative Information Retrieval Systems"><span class="ltx_text ltx_ref_title">Proactive Feedback</span></a> <a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#S4" title="4 Result Refinement ‣ Interactions with Generative Information Retrieval Systems"><span class="ltx_text ltx_ref_tag">4</span></a>, <a class="ltx_ref ltx_refmacro_nameref" href="https://arxiv.org/html/2407.11605v1#S4" title="In Interactions with Generative Information Retrieval Systems"><span class="ltx_text ltx_ref_title">Result Refinement</span></a> <a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#S5" title="5 Clarification ‣ Interactions with Generative Information Retrieval Systems"><span class="ltx_text ltx_ref_tag">5</span></a> <a class="ltx_ref ltx_refmacro_nameref" href="https://arxiv.org/html/2407.11605v1#S5" title="In Interactions with Generative Information Retrieval Systems"><span class="ltx_text ltx_ref_title">Clarification</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#S6" title="6 Proactive Interactions ‣ Interactions with Generative Information Retrieval Systems"><span class="ltx_text ltx_ref_tag">6</span></a> <a class="ltx_ref ltx_refmacro_nameref" href="https://arxiv.org/html/2407.11605v1#S6" title="In Interactions with Generative Information Retrieval Systems"><span class="ltx_text ltx_ref_title">Proactive Interactions</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#S7" title="7 Explanation ‣ Interactions with Generative Information Retrieval Systems"><span class="ltx_text ltx_ref_tag">7</span></a> <a class="ltx_ref ltx_refmacro_nameref" href="https://arxiv.org/html/2407.11605v1#S7" title="In Interactions with Generative Information Retrieval Systems"><span class="ltx_text ltx_ref_title">Explanation</span></a>, and <a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#S8" title="8 Multi-Modal Interactions ‣ Interactions with Generative Information Retrieval Systems"><span class="ltx_text ltx_ref_tag">8</span></a> <a class="ltx_ref ltx_refmacro_nameref" href="https://arxiv.org/html/2407.11605v1#S8" title="In Interactions with Generative Information Retrieval Systems"><span class="ltx_text ltx_ref_title">Multi-Modal Interactions</span></a>. In Section <a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#S9" title="9 User Interfaces ‣ Interactions with Generative Information Retrieval Systems"><span class="ltx_text ltx_ref_tag">9</span></a>, <a class="ltx_ref ltx_refmacro_nameref" href="https://arxiv.org/html/2407.11605v1#S9" title="In Interactions with Generative Information Retrieval Systems"><span class="ltx_text ltx_ref_title">User Interfaces</span></a>, we discuss recent user interface frameworks and solutions.</p>
</div>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Proactive Feedback</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">Recent developments in large language models have paved the path towards complex interactions between the user and the system. Generative IR models are able to satisfy user’s information needs in multiple interaction turns. Among many possibilities, this enables users to provide feedback to the system. Feedback can be provided when is explicitly requested by the system, for example in the form of clarifying questions or preference elicitation <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib5" title="">5</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib82" title="">82</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib52" title="">52</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib49" title="">49</a>]</cite>. Section <a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#S5" title="5 Clarification ‣ Interactions with Generative Information Retrieval Systems"><span class="ltx_text ltx_ref_tag">5</span></a> discusses these aspects in more detail. Feedback can be also requested for assessing the quality of the system at the end or in the middle of a conversation. For instance, Amazon’s Alexa Prize Challenge <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib51" title="">51</a>]</cite> has sought explicit rating feedback from users upon the completion of the conversation. Zamani et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib85" title="">85</a>]</cite> introduce the possibility of improving this simple approach by asking context-aware questions for feedback and making natural language interactions within the conversation.</p>
</div>
<div class="ltx_para" id="S3.p2">
<p class="ltx_p" id="S3.p2.1">Feedback can be provided proactively by the user, which is the focus of this section. Perhaps the simplest type of feedback that users provide can be in the form of <em class="ltx_emph ltx_font_italic" id="S3.p2.1.1">repeating or reformulating the user’s need in the same search session</em>. If detected, this often means that the user’s need has not been addressed yet. Besides such simple scenarios, users may provide <em class="ltx_emph ltx_font_italic" id="S3.p2.1.2">explicit positive or negative feedback</em>. Explicit positive feedback are often easier to identify and interpret. They are often in the form of appreciation and hold a positive sentiment. Explicit negative feedback, on the other hand, is more challenging, more diverse, and perhaps more important for system designers as they help the system to improve and identify its limitations. Pointing out what parts of the system’s response is inaccurate, why it is does not satisfy the user’s needs, or expressing frustration and disappointment are examples of explicit negative feedback. Current state-of-the-art technologies often cannot successfully take advantage of explicit negative feedback and often limit themselves to acknowledging the system’s limitations and apologizing from the users. There are huge potentials in successfully comprehending negative feedback from users.</p>
</div>
<div class="ltx_para" id="S3.p3">
<p class="ltx_p" id="S3.p3.1">In generative IR systems, grounding as relevance feedback is also relevant to the concept of explicit feedback. Trippas et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib71" title="">71</a>]</cite> define grounding as discourse for the creation of mutual knowledge and beliefs. Examples include providing indirect feedback by reciting their interpretation of the results. This process can potentially enable CIS systems to better understand a user’s awareness of the results, background knowledge, or information need.</p>
</div>
<div class="ltx_para" id="S3.p4">
<p class="ltx_p" id="S3.p4.1">We would like to highlight the potentials in providing implicit feedback as well. Progress in commercial (web) search engines is in debt to large-scale implicit feedback collected from user interactions, such as clicks, skipped results, dwell time, and cursor (mouse) movement. Implicit feedback in generative IR systems is more challenging, because it is more likely to deal with abandonment in each session. This means that users may leave the system as they receive the answer they want without providing any positive feedback. Alternatively, they may leave the system as they lose hope in getting the right answer from the system. Besides abandonment, changing topics and asking follow-up questions can be interpreted as an implicit feedback signal in generative IR. Interpreting these user behaviors is essential in improving generative IR systems.</p>
</div>
<div class="ltx_para" id="S3.p5">
<p class="ltx_p" id="S3.p5.1">Research in understanding and modeling implicit (negative) feedback is relatively sparse and future technologies can greatly benefit from further research in this space.</p>
</div>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Result Refinement</h2>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>An Overview of Result Refinement</h3>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">Result refinement is relatively understudied, compared to other modes of interaction in generative IR. Search result refinement has a long history of research in IR, especially in areas such as information filtering (e.g., recommender systems) where users access semi-structured information <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib16" title="">16</a>]</cite>. Figure <a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#S4.F1" title="Figure 1 ‣ 4.2 Technical Challenges ‣ 4 Result Refinement ‣ Interactions with Generative Information Retrieval Systems"><span class="ltx_text ltx_ref_tag">1</span></a> shows an example search result page from Amazon.com, where users are able to select certain attributes of the items (e.g., size) in the catalog to narrow down the results being presented to them. Search result refinement for semi-structured data is a relatively trivial task, as the refinement pane usually concerns the most important attributes of the items, given the query and the top item list. In the preference-based search literature, example-critiquing approaches have been explored <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib73" title="">73</a>]</cite>, where the model suggests examples to the user, and with the user’s feedback, it then models the user’s preference. In conversational recommender systems, a similar approach is taken as part of the preference elicitation process <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib37" title="">37</a>]</cite>. In this process, the conversational system starts the conversation by asking the user’s opinion about movies, aiming to optimize the decision space. A similar approach is taken in conversational product recommendation <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib97" title="">97</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib96" title="">96</a>]</cite>. In these works, the high-level idea is to extract important attributes from user reviews of products and model a probabilistic decision space. Then the conversational system takes a greedy approach in which, at every step, it aims to ask about an item attribute that minimizes the uncertainty of the decision space.
Search result refinement is more challenging in web search, where the system deals with unstructured data. One of the earliest, simplest, and yet most effective ways is using vertical in the search result page <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib8" title="">8</a>]</cite>. Search result verticals divide the search results based on very high-level categories, such as images, videos, and news. Even though, very high level, it still can be considered as a naïve approach to refinement, as it approaches the user information from the result type. In most cases, the same user query can be satisfied with different modalities, which turns out to be one of the most important aspects of search, hence major commercial search engines still employ this approach.
Finally, some early approaches tried to diversify, but also refine search results based on automatically extracted information facets. Faceted search <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib72" title="">72</a>]</cite> provides a means of navigation through topic facets for the users, enabling them to narrow down their information needs, as well as the search space. These early systems mainly relied on automatic facet extractors <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib36" title="">36</a>]</cite>.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Technical Challenges</h3>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">In the generative era, result refinement faces both algorithmic and interactive challenges.</p>
</div>
<div class="ltx_para" id="S4.SS2.p2">
<p class="ltx_p" id="S4.SS2.p2.1"><span class="ltx_text ltx_font_bold" id="S4.SS2.p2.1.1">Algorithmic challenges.</span>
As the items or documents are being represented using model parameters, refining the results based on a single attribute of the item is less trivial. To address this challenge, several works study controllable recommendation via disentanglement <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib17" title="">17</a>]</cite>, where the goal is to represent items as separated attribute vectors instead of a single latent vector. Some of these attributes would be mapped to actual attributes in the catalog (e.g., color, style), or some latent attributes. <span class="ltx_ERROR undefined" id="S4.SS2.p2.1.2">\Acp</span>LLM have shown to be capable of extracting query facets, relying solely on their intrinsic knowledge <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib41" title="">41</a>]</cite>. However, as shown in the literature, <abbr class="ltx_glossaryref" title="large language models"><span class="ltx_text ltx_glossary_short-plural">LLMs</span></abbr> are not yet capable of effectively grounding <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib63" title="">63</a>]</cite>, which leads to suboptimal planning of <abbr class="ltx_glossaryref" title="large language models"><span class="ltx_text ltx_glossary_short-plural">LLMs</span></abbr> utilizing their intrinsic knowledge to take the best next action. For example, for cases where humans would
As the items or documents are being represented using model parameters, refining the results based on a single attribute of the item is less trivial. To address this challenge, several works study controllable recommendation via disentanglement <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib17" title="">17</a>]</cite>, where the goal is to represent items as separated attribute vectors instead of a single latent vector. Some of these attributes would be mapped to actual attributes in the catalog (e.g., color, style), or some latent attributes. <span class="ltx_ERROR undefined" id="S4.SS2.p2.1.3">\Acp</span>LLM have shown to be capable of extracting query facets, relying solely on their intrinsic knowledge <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib41" title="">41</a>]</cite>. However, as shown in the literature, <abbr class="ltx_glossaryref" title="large language models"><span class="ltx_text ltx_glossary_short-plural">LLMs</span></abbr> are not yet capable of effectively grounding <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib63" title="">63</a>]</cite>, which leads to suboptimal planning of <abbr class="ltx_glossaryref" title="large language models"><span class="ltx_text ltx_glossary_short-plural">LLMs</span></abbr> utilizing their intrinsic knowledge to take the best next action. For example, in conversations where most humans would ask for refinement, <abbr class="ltx_glossaryref" title="large language models"><span class="ltx_text ltx_glossary_short-plural">LLMs</span></abbr> fail to take the same action.</p>
</div>
<div class="ltx_para" id="S4.SS2.p3">
<p class="ltx_p" id="S4.SS2.p3.1"><span class="ltx_text ltx_font_bold" id="S4.SS2.p3.1.1">Interactive challenges.</span>
As mentioned above, there has been research on various modes of refinement, i.e., search verticals, item attributes, faceted search, and example critique. While each of these modes has been utilized for a specific interaction medium (e.g., web search vs. conversational search), generative systems could potentially mix them. For example, prompting the user about their preferred search result modality, rather than making an assumption.
Moreover, Chen et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib14" title="">14</a>]</cite> review the interactive challenges of <abbr class="ltx_glossaryref" title="large language models"><span class="ltx_text ltx_glossary_short-plural">LLMs</span></abbr> in the light of personalization, highlighting the importance of user–system interactions in result presentation, specifically refinement. Among other challenges, they refer to laborious data collection for training <abbr class="ltx_glossaryref" title="large language models"><span class="ltx_text ltx_glossary_short-plural">LLMs</span></abbr> to be effective interactive systems, which can hinder the learning process.</p>
</div>
<figure class="ltx_figure" id="S4.F1">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S4.F1.1"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="310" id="S4.F1.1.g1" src="extracted/5734863/img/refinement1.png" width="269"/>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S4.F1.2"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="282" id="S4.F1.2.g1" src="extracted/5734863/img/refinement2.png" width="269"/>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Examples of search result refinement from Amazon.com. The refinement panes on the left help users browse through the search results.</figcaption>
</figure>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Clarification</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">In a generative retrieval setting where the system aims to provide a comprehensive response to the user, whether in a conversational or web search setting, it is of utmost importance to ensure that the user’s intent is predicted with high confidence. This is particularly critical, as in traditional web search scenarios, the system would diversify the list of results to ensure that various facets or interpretations of the query are covered in the top results <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib57" title="">57</a>]</cite>. However, in a generative scenario, usually, a single answer is provided to the user, limiting the information that can be exchanged between the user and the system.</p>
</div>
<section class="ltx_subsection" id="S5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>An Overview of Search Clarification</h3>
<div class="ltx_para" id="S5.SS1.p1">
<p class="ltx_p" id="S5.SS1.p1.1">Clarifying questions have been studied extensively <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib34" title="">34</a>]</cite> in the context of conversational question-answering <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib52" title="">52</a>]</cite>, information-seeking conversations <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib5" title="">5</a>]</cite>, and web search <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib82" title="">82</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S5.SS1.p2">
<p class="ltx_p" id="S5.SS1.p2.1">Another line of research studies the role of mixed-initiative interactions for user preference elicitation <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib49" title="">49</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib37" title="">37</a>]</cite>. The goal here is to understand the user preference when multiple documents (items) can be deemed relevant to their information need. Radlinski et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib49" title="">49</a>]</cite> study this problem for movie recommendation, where the user information need is typically generic (e.g., “romantic movies”) with multiple potentially relevant items. The dialogue system’s goal in this setting is to engage in a conversation to elicit user preference in a more fine-grained way.</p>
</div>
<div class="ltx_para" id="S5.SS1.p3">
<p class="ltx_p" id="S5.SS1.p3.1">There has been a body of research studying the effect of mixed-initiative interventions such as clarifying questions on user experience <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib35" title="">35</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib84" title="">84</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib95" title="">95</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib98" title="">98</a>]</cite>. Kiesel et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib35" title="">35</a>]</cite> study the effect of voice query clarification on user experience and find even in cases where the system performance is not improved, users have better experience.
In web search, Zamani et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib84" title="">84</a>]</cite> study the effect of incorporating a clarification pane on the search result page, implemented in Bing.com. Analyzing the click logs, they find that the clarification pane improves user experience. More specifically, among the seven templates they use to generate the clarifying questions, they find clear preference towards certain question templates in terms of user engagement.
Zou et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib95" title="">95</a>]</cite> study the effect of the clarification pane in the same setting in a controlled experimental setup where they introduce three quality levels and measure user satisfaction and performance. They find that asking a low-quality question in a search session risks lower user engagement with questions of higher quality in the same session. This finding was confirmed in a follow-up work <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib98" title="">98</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S5.SS1.p4">
<p class="ltx_p" id="S5.SS1.p4.1">User engagement (i.e., click-through rate) can be considered as a user-oriented quality measure of clarifying questions.
Sekulic et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib58" title="">58</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib60" title="">60</a>]</cite> extract various SERP- and document-based features to predict user engagement while interacting with clarifying questions in a web-based interface <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib83" title="">83</a>]</cite>. Rahmani et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib50" title="">50</a>]</cite> study the effect of various query- and question-based features to predict user satisfaction in the MIMICS dataset <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib83" title="">83</a>]</cite> where they find, among others, a positive sentiment in the clarifying question leads to higher user satisfaction. Sekulic et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib61" title="">61</a>]</cite> instead predicts the usefulness of clarifying questions in the retrieval pipeline. Following an early study on the effect of different types of clarifying questions on retrieval performance <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib38" title="">38</a>]</cite>, they train a classifier to predict the usefulness of a clarifying question and its answer in the retrieval pipeline and incorporate it in the retrieval pipeline if only it is predicted to be useful.</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Technical Challenges</h3>
<div class="ltx_para" id="S5.SS2.p1">
<p class="ltx_p" id="S5.SS2.p1.1"><span class="ltx_text ltx_font_bold" id="S5.SS2.p1.1.1">Planning.</span>
While the early works in this area focused mainly on ranking clarifying questions from a pre-collected question bank <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib3" title="">3</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib4" title="">4</a>]</cite>, more recent studies aim towards leveraging the generation power of <abbr class="ltx_glossaryref" title="large language models"><span class="ltx_text ltx_glossary_short-plural">LLMs</span></abbr> to generate clarifying questions <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib88" title="">88</a>]</cite>. However, generative systems based entirely on <abbr class="ltx_glossaryref" title="large language models"><span class="ltx_text ltx_glossary_short-plural">LLMs</span></abbr> are not effective in proactive interactions, especially in generating clarifying questions when necessary <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib23" title="">23</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib63" title="">63</a>]</cite>. Initial experiments reveal the power of <abbr class="ltx_glossaryref" title="large language models"><span class="ltx_text ltx_glossary_short-plural">LLMs</span></abbr> in understanding the context of a query or a search session <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib1" title="">1</a>]</cite> and generate potential questions based on the context when prompted <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib21" title="">21</a>]</cite>; however, they fail at planning when to ask and which question to ask <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib21" title="">21</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib63" title="">63</a>]</cite>.
Shaikh et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib63" title="">63</a>]</cite> conduct a study where they compare human–human conversations with system–human conversations and find that <abbr class="ltx_glossaryref" title="large language models"><span class="ltx_text ltx_glossary_short-plural">LLMs</span></abbr> fail at effectively planning when to ask clarifying questions in a conversation, even though they can generate high-quality questions if they are explicitly prompted to do so.
Deng et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib22" title="">22</a>]</cite> propose a proactive chain-of-thought approach to enhance the planning capability of <abbr class="ltx_glossaryref" title="large language models"><span class="ltx_text ltx_glossary_short-plural">LLMs</span></abbr> such as ChatGPT and show that it has a considerable effect on their interaction capabilities.</p>
</div>
<div class="ltx_para" id="S5.SS2.p2">
<p class="ltx_p" id="S5.SS2.p2.1"><span class="ltx_text ltx_font_bold" id="S5.SS2.p2.1.1">Evaluation.</span>
Evaluating generative systems comes with various challenges. On top of that, evaluating interactive generative systems involves even more challenges as the user response to a system output is required.
A line of research looks at simulating and modeling the user–system interactions in a mixed-initiative setting <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib90" title="">90</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib11" title="">11</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib55" title="">55</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib2" title="">2</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib10" title="">10</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib48" title="">48</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib59" title="">59</a>]</cite>. User simulation can be beneficial to generative IR models in two ways: (i) they provide a means for evaluating generated content, and (ii) they can be used for training. Zhang and Balog <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib90" title="">90</a>]</cite> propose a user simulator for conversational recommendation to evaluate the system performance. This is followed by the work done by Sekulic et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib59" title="">59</a>]</cite> and Owoicho et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib48" title="">48</a>]</cite> in using GPT-based models to simulate users in a mixed-initiative information-seeking conversational system where the main goal of the simulator is to provide an answer to a generated clarifying question. They show that such simulators can lead to reliable evaluation of conversational systems.</p>
</div>
<div class="ltx_para" id="S5.SS2.p3">
<p class="ltx_p" id="S5.SS2.p3.1">There are various considerations to take into account in simulating and evaluating interactive generative systems:</p>
<ul class="ltx_itemize" id="S5.I1">
<li class="ltx_item" id="S5.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S5.I1.i1.p1">
<p class="ltx_p" id="S5.I1.i1.p1.1">User effort: In interacting with the system, users bear different levels of cognitive load, which can lead to user fatigue as the number of interactions increases.</p>
</div>
</li>
<li class="ltx_item" id="S5.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S5.I1.i2.p1">
<p class="ltx_p" id="S5.I1.i2.p1.1">User information gain: To model the true value of a clarifying question in a conversation, we need to model both the gain and effort a clarifying question brings to the conversation <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib2" title="">2</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib10" title="">10</a>]</cite>.</p>
</div>
</li>
<li class="ltx_item" id="S5.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S5.I1.i3.p1">
<p class="ltx_p" id="S5.I1.i3.p1.1">Information nuggets: Information gain can be modeled by breaking the user’s information need into information nuggets and measuring how much asking a certain clarifying question would help us provide further information nuggets to the user.</p>
</div>
</li>
<li class="ltx_item" id="S5.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S5.I1.i4.p1">
<p class="ltx_p" id="S5.I1.i4.p1.1">User model: As proposed by Balog <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib11" title="">11</a>]</cite>, an effective user simulator should have various components, including a user mental model. Realistically, a single user simulator does not cover the needs and behavior of the wide range of users interacting with the system.</p>
</div>
</li>
</ul>
</div>
</section>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Proactive Interactions</h2>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">Typically, users initiate the interaction with a generative retrieval system, for example by submitting a chit-chat utterance, asking a question, or submitting an action request. In mixed-initiative conversational systems, the agent is also able to initiate the conversation. This is also called a <em class="ltx_emph ltx_font_italic" id="S6.p1.1.1">proactive</em>, system-initiative, or agent-initiative conversation. Existing generative AI systems are relatively under-developed when it comes to proactive interactions <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib43" title="">43</a>]</cite>. A major reason is that initiating a conversation by the system is not only challenging, but can also be risky; frequent and non-relevant proactive interactions may annoy users and hurt user satisfaction and trust <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib85" title="">85</a>]</cite>. Therefore, whether and when to initiate a proactive interaction are the key decisions a proactive CIS system should make.</p>
</div>
<figure class="ltx_figure" id="S6.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="467" id="S6.F2.g1" src="x1.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>A generic pipeline for conversation initiation in CIS systems by Wadhwa and Zamani <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib74" title="">74</a>]</cite>.</figcaption>
</figure>
<section class="ltx_subsection" id="S6.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.1 </span>An Overview of Proactive Generative Retrieval Systems</h3>
<div class="ltx_para" id="S6.SS1.p1">
<p class="ltx_p" id="S6.SS1.p1.1">Wadhwa and Zamani <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib74" title="">74</a>]</cite> explored proactive conversational information access systems, discussing their challenges and opportunities. The authors introduced a taxonomy of proactive interactions, delineating three dimensions: (1) initiation moment (<em class="ltx_emph ltx_font_italic" id="S6.SS1.p1.1.1">when</em> to initiate a conversation), (2) initiation purpose (<em class="ltx_emph ltx_font_italic" id="S6.SS1.p1.1.2">why</em> to initiate a conversation), and (3) initiation means (<em class="ltx_emph ltx_font_italic" id="S6.SS1.p1.1.3">how</em> to initiative a conversation). They identified five purposes for initiating interactions: (1) filtering streaming information, (2) context-aware recommendation, (3) following up a past user-system conversation, (4) contributing to a multi-party human conversation, and (5) requesting feedback from users. A generic pipeline for these systems is depicted in Figure <a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#S6.F2" title="Figure 2 ‣ 6 Proactive Interactions ‣ Interactions with Generative Information Retrieval Systems"><span class="ltx_text ltx_ref_tag">2</span></a>. In this pipeline, several algorithms constantly monitor the user’s context and information streams to produce conversation initiation instances, which are stored in a database. A conversation initiator component then selects an appropriate instance based on the situation, initiating a fluent and accurate utterance. Figure <a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#S6.F2" title="Figure 2 ‣ 6 Proactive Interactions ‣ Interactions with Generative Information Retrieval Systems"><span class="ltx_text ltx_ref_tag">2</span></a> is sufficiently generic for illustrating proactive interactions in generative retrieval models and we use it to describe research and open questions in proactive retrieval in more detail.</p>
</div>
<div class="ltx_para" id="S6.SS1.p2">
<p class="ltx_p" id="S6.SS1.p2.1">Initiating a conversation through recommendation stands as one of the most common scenarios for proactive interaction. For instance, a conversational information access system might suggest an item based on the user’s situational context, such as their location, time, and preferences. It is worth noting the distinction from traditional conversational recommendation setups, where users typically initiate the conversation by requesting specific items <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib66" title="">66</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib92" title="">92</a>]</cite>. Recent efforts in joint modeling of search and recommendation and developing unified information access systems <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib80" title="">80</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib81" title="">81</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib87" title="">87</a>]</cite> represent a step towards developing proactive, and thus mixed-initiative, systems in search and recommendation. However, proactive conversations extend beyond mere recommendations.</p>
</div>
<div class="ltx_para" id="S6.SS1.p3">
<p class="ltx_p" id="S6.SS1.p3.1">For example, Avula and Arguello <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib9" title="">9</a>]</cite> devised a system for conducting wizard-of-oz experiments, investigating proactive interactions during conversational collaborative search. This system could seamlessly integrate into collaborative platforms like Slack,<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://slack.com/" title="">https://slack.com/</a></span></span></span> where during a collaborative search task, an external u ser (acting as a wizard) provides information. Though advancements in this area are nascent, there exists considerable potential for systems to initiate context-based conversations, engaging users and eliciting feedback.</p>
</div>
<div class="ltx_para" id="S6.SS1.p4">
<p class="ltx_p" id="S6.SS1.p4.1">Consider a scenario where a user employs a mapping application to navigate to a restaurant. Leveraging contextual cues, a proactive generative retrieval system could subsequently initiate a conversation upon the user’s return journey, inquiring about their dining experience. Such interactions not only enhance user engagement but also facilitate feedback collection, aiding in profile refinement. Similarly, in situations where a user encounters difficulty in task completion, a conversational system could autonomously engage in conversation, offering assistance <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib85" title="">85</a>]</cite>.</p>
</div>
</section>
<section class="ltx_subsection" id="S6.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.2 </span>User Responses to Proactive Interactions</h3>
<div class="ltx_para" id="S6.SS2.p1">
<p class="ltx_p" id="S6.SS2.p1.1">While in generative retrieval systems, users have the freedom to provide a natural language response in any form, they can be categorized as follows <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib74" title="">74</a>]</cite>:</p>
<ul class="ltx_itemize" id="S6.I1">
<li class="ltx_item" id="S6.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S6.I1.i1.p1">
<p class="ltx_p" id="S6.I1.i1.p1.1">Null action: Users provide no response to the initiated conversation. It is important to note that null action should not necessarily be construed as negative feedback, as users may find the initiation useful but may not desire further engagement.</p>
</div>
</li>
<li class="ltx_item" id="S6.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S6.I1.i2.p1">
<p class="ltx_p" id="S6.I1.i2.p1.1">Interruption or negation: Users respond in a manner consistent with terminating any further engagement by the generative retrieval system. It is perhaps safe to interpret such responses as negative feedback.</p>
</div>
</li>
<li class="ltx_item" id="S6.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S6.I1.i3.p1">
<p class="ltx_p" id="S6.I1.i3.p1.1">Relevant response: Users provide a pertinent response to the initiated interaction, typically occurring when the interaction involves a question or solicits feedback.</p>
</div>
</li>
<li class="ltx_item" id="S6.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S6.I1.i4.p1">
<p class="ltx_p" id="S6.I1.i4.p1.1">Postpone: Users respond to the initiated conversation and request the system to remind them at a later time.</p>
</div>
</li>
<li class="ltx_item" id="S6.I1.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S6.I1.i5.p1">
<p class="ltx_p" id="S6.I1.i5.p1.1">Critique or clarification-seeking response: Users engage further with the generative retrieval system, either seeking more information or critiquing existing engagement.</p>
</div>
</li>
<li class="ltx_item" id="S6.I1.i6" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S6.I1.i6.p1">
<p class="ltx_p" id="S6.I1.i6.p1.1">Follow-up: Users provide a follow-up response to obtain additional information or perform actions related to the initiated conversation.</p>
</div>
</li>
<li class="ltx_item" id="S6.I1.i7" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S6.I1.i7.p1">
<p class="ltx_p" id="S6.I1.i7.p1.1">Topic drift: Users respond but shift the topic of the initiated conversation.</p>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_subsection" id="S6.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.3 </span>Technical Challenges</h3>
<div class="ltx_para" id="S6.SS3.p1">
<p class="ltx_p" id="S6.SS3.p1.1">Here, we outline key technical hurdles in implementing the pipeline shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#S6.F2" title="Figure 2 ‣ 6 Proactive Interactions ‣ Interactions with Generative Information Retrieval Systems"><span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
<div class="ltx_para" id="S6.SS3.p2">
<p class="ltx_p" id="S6.SS3.p2.1"><span class="ltx_text ltx_font_bold" id="S6.SS3.p2.1.1">Producing System-Initiative Instances.</span>
The initial step in the system-initiation pipeline involves identifying reasons for initiating a conversation and generating a proactive instance. Proactive instances encapsulate all relevant information about a conversation, including its purpose, content, and context. This process entails addressing each initiation purpose component outlined in Figure <a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#S6.F2" title="Figure 2 ‣ 6 Proactive Interactions ‣ Interactions with Generative Information Retrieval Systems"><span class="ltx_text ltx_ref_tag">2</span></a>. While some purposes, such as filtering streaming information and recommendation, have received attention in the literature, others like following up a past conversation or contributing to a multi-party conversation remain relatively unexplored. Thus, a major technical challenge lies in developing models capable of identifying the reasons for conversation initiation across various goals, including filtering information, recommendation, conversation follow-up, contributing to multi-party conversations, or requesting feedback.</p>
</div>
<div class="ltx_para" id="S6.SS3.p3">
<p class="ltx_p" id="S6.SS3.p3.1"><span class="ltx_text ltx_font_bold" id="S6.SS3.p3.1.1">Developing an Initiator Model.</span>
The subsequent step involves selecting a proactive instance from the instance collection using an initiator component. The primary challenge in this component stems from our limited understanding of the optimal moment to initiate a conversation. Consequently, future research should emphasize conducting user studies to explore the ideal timing for conversation initiation. Weak signals gleaned from user interactions with existing conversational systems, even those lacking proactive capabilities, could provide valuable insights. For instance, instances, where users initiate trivial conversations (e.g., out of boredom), could serve as noisy but potentially useful signals for predicting optimal conversation initiation moments. Machine learning models trained on situational context and user profiles could leverage such signals. Furthermore, interactive systems that log user interactions offer the opportunity to iteratively refine prediction accuracy based on user feedback.</p>
</div>
<div class="ltx_para" id="S6.SS3.p4">
<p class="ltx_p" id="S6.SS3.p4.1"><span class="ltx_text ltx_font_bold" id="S6.SS3.p4.1.1">Generating System-Initiative Utterances.</span>
The final step entails generating a (natural language) interaction based on a proactive instance and presenting it to the user. Techniques from dialogue systems and text generation research can be leveraged for this purpose. Since users typically do not anticipate proactive utterances, a notable technical challenge lies in providing context within the generated utterance to ensure user comprehension. This context could reference previous interactions with the system, user experiences, or explanations regarding the rationale behind initiating the conversation. Given that each instance is a structured data object, neural models designed for unstructured text generation from structured data, such as tables, could be potentially useful.</p>
</div>
</section>
<section class="ltx_subsection" id="S6.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.4 </span>Evaluation of Proactive Systems</h3>
<div class="ltx_para" id="S6.SS4.p1">
<p class="ltx_p" id="S6.SS4.p1.1">Assessing proactive generative IR systems poses significant challenges. While IR research has traditionally focused on creating collections for specific information-seeking tasks, these collections are typically based on predefined needs (e.g., TREC<span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://trec.nist.gov/" title="">https://trec.nist.gov/</a></span></span></span> tracks) or observations (e.g., clickthrough data). However, these evaluation methods do not readily apply to scenarios involving proactive interactions. Although evaluating proactive generative IR systems remains largely unexplored in the literature, we can envision two classes of evaluation methodologies: (1) modular evaluation, and (2) end-to-end evaluation.</p>
</div>
<div class="ltx_para" id="S6.SS4.p2">
<p class="ltx_p" id="S6.SS4.p2.1">In modular evaluation, the quality of each component in Figure <a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#S6.F2" title="Figure 2 ‣ 6 Proactive Interactions ‣ Interactions with Generative Information Retrieval Systems"><span class="ltx_text ltx_ref_tag">2</span></a> is evaluated in isolation? For example, how accurate is the initiator component in identifying opportune moments for proactive interactions? This methodology simplifies evaluation in proactive systems, but does not provide a complete picture of the overall performance of the system from the user’s perspective, and does not reflect real-world complexities.</p>
</div>
<div class="ltx_para" id="S6.SS4.p3">
<p class="ltx_p" id="S6.SS4.p3.1">In end-to-end evaluation, one can explore both offline and online evaluation strategies. For offline evaluation, each instance would encompass all necessary information for the system at a given timestamp, including past user-system interactions, user profiles, situational contexts, and streams of new information. The model’s performance would then be assessed based on the generated proactive interactions, if applicable. Crafting a single evaluation metric capable of capturing all facets of conversation initiation evaluation presents a challenge, necessitating further investigation. Recently, Samarinas and Zamani <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib56" title="">56</a>]</cite> introduced a large-scale benchmark for proactive interactions to ongoing multi-party human conversations and proposed normalized proactive discounted cumulative gain (npDCG) for end-to-end evaluation of such systems. In a separate investigation, Sen et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib62" title="">62</a>]</cite> suggested evaluating proactive recommendation within search sessions by aggregating a correlation measure over the session. This measure assesses the relationship between the expected outcome—comprising the list of documents retrieved with a true user query—and the predicted outcome, representing the list of documents recommended by a proactive search system.</p>
</div>
<div class="ltx_para" id="S6.SS4.p4">
<p class="ltx_p" id="S6.SS4.p4.1">In the realm of online evaluation, conventional A/B tests can serve as a valuable tool for assessing the system’s efficacy. Additionally, interpreting user feedback—both positive and negative—can provide valuable insights into system performance.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S7">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Explanation</h2>
<div class="ltx_para" id="S7.p1">
<p class="ltx_p" id="S7.p1.1">Explanation can be seen as a critical tool in search result presentation in generative systems, as users are interested in comprehensive justification and explanation of the presented results <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib28" title="">28</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib14" title="">14</a>]</cite>. Also, it can lead to more user trust in the results, potentially aiding the user to distinguish between a low-quality and a high-quality response.</p>
</div>
<section class="ltx_subsection" id="S7.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">7.1 </span>An Overview of Explanation in IR</h3>
<div class="ltx_para" id="S7.SS1.p1">
<p class="ltx_p" id="S7.SS1.p1.1">Zhao et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib94" title="">94</a>]</cite> provide a survey on the explainability of <abbr class="ltx_glossaryref" title="large language models"><span class="ltx_text ltx_glossary_short-plural">LLMs</span></abbr> where they provide a taxonomy of explanations, together with methods for explaining Transformer-based <abbr class="ltx_glossaryref" title="large language models"><span class="ltx_text ltx_glossary_short-plural">LLMs</span></abbr>. Also, they discuss various methods for evaluating explanations for both local and global explanations.
Krishna et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib39" title="">39</a>]</cite> show that not only are explanations useful in user–system interactions, but they also improve the performance of <abbr class="ltx_glossaryref" title="large language models"><span class="ltx_text ltx_glossary_short-plural">LLMs</span></abbr>. They study automatic rationale generation in a  <span class="ltx_glossaryref" title="chain of thought"><span class="ltx_text ltx_glossary_long">chain of thought</span></span> (<abbr class="ltx_glossaryref" title="chain of thought"><span class="ltx_text ltx_glossary_short">CoT</span></abbr>) manner.
Deng et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib24" title="">24</a>]</cite> show that rephrasing the user input leads to a better understanding of the user request which in turn results in better performance of the LLM, which is complementary to <abbr class="ltx_glossaryref" title="chain of thought"><span class="ltx_text ltx_glossary_short">CoT</span></abbr> reasoning.
In their tutorial, Anand et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib6" title="">6</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib7" title="">7</a>]</cite> review Transformer-based explanation generation.
Zhang et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib89" title="">89</a>]</cite> addresses search explainability via the lens of query understanding, where the system’s task is to predict the user intent considering their query as input.
LiEGe <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib79" title="">79</a>]</cite> explains all the documents in the ranking jointly using a listwise explanation generator.</p>
</div>
<div class="ltx_para" id="S7.SS1.p2">
<p class="ltx_p" id="S7.SS1.p2.1">Evaluating explanations is challenging. For free-text generations, human evaluation is employed. In other cases, because of a lack of explanation, proxy explanations such as clicks, query descriptions, query aspect annotation, and topic annotation can be used. For feature-based models, explanations are evaluated based on the effectiveness of predicted features. As for counterfactual explanations, model-based evaluation is employed.</p>
</div>
</section>
<section class="ltx_subsection" id="S7.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">7.2 </span>Modes of Explanation in Generative IR</h3>
<div class="ltx_para" id="S7.SS2.p1">
<p class="ltx_p" id="S7.SS2.p1.1">The main mode of explanation used in generative models is free-form text, where the model would further elaborate why the provided answer is relevant to the user’s input. The explanation often consists of two major parts: (i) a further description of user information need, and (ii) an explanation of the reasons why the generated response is relevant to the user’s input.
The system has a limited information bandwidth and cannot present the users with multiple intents of their query. Therefore, describing what the system “thinks” the user wants helps the user understand whether the system understands their intent or not <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib89" title="">89</a>]</cite>.
This type of explanation aims to ensure the user that their information need is properly understood by the system and can lead to increased trust in the system. Also, in case of misunderstanding the user’s information need, it provides the opportunity for the user to realize what is missing in their input. This can be seen as similar to scanning the SERP by the user, through which the user would have an idea if the system understands their information need correctly.</p>
</div>
<div class="ltx_para" id="S7.SS2.p2">
<p class="ltx_p" id="S7.SS2.p2.1">Another form of explanation is to provide citations. This has been studied more extensively in the NLP community where the generated text attribution <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib29" title="">29</a>]</cite>. The URL citations are supposed to provide evidence of the source of information from the web. However, there are concerns regarding the quality of the citations, as there is no clear way of controlling the <abbr class="ltx_glossaryref" title="large language models"><span class="ltx_text ltx_glossary_short">LLM</span></abbr> to ground its responses on the cited page <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib91" title="">91</a>]</cite>. Citing source documents, while being useful as a form of explanation, still does not provide a comprehensive idea of the relevance of the source. Comparing it to a typical SERP where the users are exposed to the URLs of the results, users already have a quality perception by scanning through the page title, summary, and URL. Even though the <abbr class="ltx_glossaryref" title="large language models"><span class="ltx_text ltx_glossary_short">LLM</span></abbr>-based search interfaces aim to mimic this experience, it is not yet clear which parts of the generated response are extracted from the cited document. Moreover, it is not clear how much the system depends on its intrinsic knowledge (i.e., model parameters) vs. the retrieved document. Therefore, more research in this area is required to understand how much different techniques and modes of explanation affect the users’ perception of quality and trust. One potential alternative is to treat the system as an information-gathering tool <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib53" title="">53</a>]</cite>, rather than an information system. In such cases, the responses would look like “After searching the web, I found numerous sources of information about your query. Two of more trustworthy sources mention that ….” With such a response, not only does the user learn about the search space of the given query, but also they learn about the most important information extracted from the topic documents.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S8">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">8 </span>Multi-Modal Interactions</h2>
<div class="ltx_para" id="S8.p1">
<p class="ltx_p" id="S8.p1.1">Research has demonstrated the advantageous role of multimodal signals in both keyword-based and recommendation-driven searches, spanning from contextual item recommendations <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib33" title="">33</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib76" title="">76</a>]</cite> to visual and multimedia recommendations <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib46" title="">46</a>]</cite>. These signals also address challenges like cold-start issues <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib18" title="">18</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib47" title="">47</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib15" title="">15</a>]</cite> and aiding in explaining and visualizing recommendation outcomes <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib68" title="">68</a>]</cite>. A recent survey by Deldjoo et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib19" title="">19</a>]</cite> offers insights into the role of multimedia content in recommendation systems, delineating how such content—comprising audio, visual, and textual elements—enriches real-world recommendation challenges.</p>
</div>
<div class="ltx_para" id="S8.p2">
<p class="ltx_p" id="S8.p2.1">A significant challenge in Multimedia Information Systems lies in fusing multiple modalities to derive meaningful representations. Recent advancements in multi-modal large language models employ joint representation techniques to establish a latent space where multiple modality information can be compared. However, aligning content data like text and images is relatively straightforward compared to aligning content with user preferences such as ratings or social media data.</p>
</div>
<div class="ltx_para" id="S8.p3">
<p class="ltx_p" id="S8.p3.1">Deldjoo et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib20" title="">20</a>]</cite> explored multi-modal conversational information-seeking tasks from multiple perspectives. They investigated (1) <span class="ltx_text ltx_font_italic" id="S8.p3.1.1">Why</span> using multi-modal interactions, (2) <span class="ltx_text ltx_font_italic" id="S8.p3.1.2">Which</span> tasks to support in multi-modal conversational systems, (3) <span class="ltx_text ltx_font_italic" id="S8.p3.1.3">When</span> to integrate multiple modalities in conversations, and (4) <span class="ltx_text ltx_font_italic" id="S8.p3.1.4">How</span> to research multiple modalities and conversations to enable multi-modal conversational information seeking. Deldjoo et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib20" title="">20</a>]</cite> highlight the importance of each of these perspectives through a real-world example:</p>
</div>
<div class="ltx_para" id="S8.p4">
<blockquote class="ltx_quote" id="S8.p4.1">
<p class="ltx_p" id="S8.p4.1.1">Imagine a person is cycling along the road on their way to work. She is planning her day, including tasks from presenting a budget, hosting a new client, picking up their children after school, and making dinner. The cyclist passes a flower on the sideroad, which caught her eye and wanted to know what this plant is. Since she is cycling on a busy road, she quickly stops, takes a photo, and keeps riding. Meanwhile, she asks her earbuds to tell her which plant that was by a spoken query such as “what was that plant and is it edible?”</p>
</blockquote>
</div>
<div class="ltx_para" id="S8.p5">
<p class="ltx_p" id="S8.p5.1">The authors argue that generative IR systems with multi-modal interactions and multi-modal sensors can accomplish the user’s need in this and even more complex scenarios.
Dealing with multi-modal interactions is a multidisciplinary topic, spanning across research areas from information retrieval, recommender systems, multi-media, human-computer interactions, computer vision, and even psychological and cognitive sciences. The intersection of the research areas that enable people to search for information through multi-modal conversations has not received the attention it deserves and it might partially be due to the complexity of the topic in terms of both modeling and evaluation. Prior work are mostly limited to two modalities (image and text), e.g., <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib67" title="">67</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib78" title="">78</a>]</cite>, and further development in multi-modal foundation models <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib42" title="">42</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib26" title="">26</a>]</cite> and multi-modal retrieval-augmented generation models <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib54" title="">54</a>]</cite>, is expected to speed up progress in this area.</p>
</div>
</section>
<section class="ltx_section" id="S9">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">9 </span>User Interfaces</h2>
<div class="ltx_para" id="S9.p1">
<p class="ltx_p" id="S9.p1.1">While in Section <a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#S2" title="2 Expressing Information Needs ‣ Interactions with Generative Information Retrieval Systems"><span class="ltx_text ltx_ref_tag">2</span></a> we focused on general interaction methods to assist users in expressing their information needs when interacting with generative AI, in this section we review recent work on interaction techniques and user interfaces for information access with <abbr class="ltx_glossaryref" title="large language models"><span class="ltx_text ltx_glossary_short-plural">LLMs</span></abbr>. The design space is huge, and it is still under-researched and poorly understood. For example, out of approximately 750 pre-prints related to <abbr class="ltx_glossaryref" title="large language models"><span class="ltx_text ltx_glossary_short-plural">LLMs</span></abbr> published on arXiv in the field of Information Retrieval between 2020-2024, only 22 mentioned ”user interface” in their abstracts.</p>
</div>
<div class="ltx_para" id="S9.p2">
<p class="ltx_p" id="S9.p2.1">New human-LLM interaction frameworks are only starting to emerge. For example, recent work <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib27" title="">27</a>]</cite> reviewed 73 papers published in HCI conferences since 2021 to investigate the dynamics of human-LLM interaction. Authors identified four key phases in the interaction flow and developed a taxonomy of four primary interaction modes. The four phases are: <span class="ltx_text ltx_font_italic" id="S9.p2.1.1">planning</span> - before an interaction, <span class="ltx_text ltx_font_italic" id="S9.p2.1.2">facilitating</span> - during an interaction, <span class="ltx_text ltx_font_italic" id="S9.p2.1.3">iterating</span> - refining an interaction, and <span class="ltx_text ltx_font_italic" id="S9.p2.1.4">testing</span> - testing an interaction. The interaction modes include: <span class="ltx_text ltx_font_italic" id="S9.p2.1.5">Standard Prompting, User Interface, Context-based and Agent Facilitator</span>. The <span class="ltx_text ltx_font_italic" id="S9.p2.1.6">User Interface</span> mode is of most interest to us as it enhances user interactions with <abbr class="ltx_glossaryref" title="large language models"><span class="ltx_text ltx_glossary_short-plural">LLMs</span></abbr> beyond the conversational interface by improving input, output, iteration, and reasoning processes. This mode contains five approaches, which could be used separately or in combination.
(1) <span class="ltx_text ltx_font_italic" id="S9.p2.1.7">Structured prompt</span> approaches assist users in creating multi-component prompts, which could range from zero-shot to few-shot, and support specification of constraints. Tools like PromptMaker <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib30" title="">30</a>]</cite> combine prefixes, settings, and examples in prompt creation.
(2) <span class="ltx_text ltx_font_italic" id="S9.p2.1.8">Varying output</span> approaches allow users to specify output formats. Early examples like GenLine and GenForm <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib31" title="">31</a>]</cite> facilitate generation of user specified mixed outputs, such as HTML, JavaScript, and CSS code. User’s control over output format allows for high level of personalization and, potentially, enhances consumption of information.
(3) <span class="ltx_text ltx_font_italic" id="S9.p2.1.9">Iteration of interaction</span> approaches include features such as debugging, error labeling, regenerating, and self-repairing, enabling users to refine their original prompts and workflows. BotDesigner <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib86" title="">86</a>]</cite>, for instance, helps users identify and label errors within conversations and offers a ”retry” button to regenerate outputs.
(4) <span class="ltx_text ltx_font_italic" id="S9.p2.1.10">Testing of interaction</span> facilitates the testing of various prompt variations, useful for quick testing of complex solutions. Tools like VISAR <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib93" title="">93</a>]</cite> use visual programming to enable rapid prototyping and testing of writing organization.
(5) <span class="ltx_text ltx_font_italic" id="S9.p2.1.11">UI to support reasoning</span> incorporates direct manipulation in the Chain-of-Thought process, allowing users to actively participate in and reorganize reasoning sequences. Other approaches in this area offer visual programming techniques, such as chain designs and mind maps and enable a more interactive and user-defined reasoning framework <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib32" title="">32</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib65" title="">65</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib93" title="">93</a>]</cite>. For example, Graphologue <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib32" title="">32</a>]</cite> introduced: (1) graphical diagrams which convert text-based responses from <abbr class="ltx_glossaryref" title="large language models"><span class="ltx_text ltx_glossary_short-plural">LLMs</span></abbr> into diagrams; (2) graphical dialogues which enable graphical, non-linear dialogues between humans and <abbr class="ltx_glossaryref" title="large language models"><span class="ltx_text ltx_glossary_short-plural">LLMs</span></abbr>; and (3) interactive diagrams which allow users to adjust graphical presentation, its complexity and submit context-specific prompts.</p>
</div>
<div class="ltx_para" id="S9.p3">
<p class="ltx_p" id="S9.p3.1">MacNeil et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib44" title="">44</a>]</cite> explores three methods for integrating <abbr class="ltx_glossaryref" title="large language models"><span class="ltx_text ltx_glossary_short-plural">LLMs</span></abbr> into user interfaces through a framework called Prompt Middleware. The three methods are: (1) <span class="ltx_text ltx_font_italic" id="S9.p3.1.1">Static Prompts</span> are predefined prompts generated by experts through prompt engineering. They can be invoked by using UI elements (e.g., buttons), allowing users to send high-quality prompts to with minimal effort. This method leverages best practices but limits user control over prompt generation. (2) <span class="ltx_text ltx_font_italic" id="S9.p3.1.2">Template-Based Prompts</span> involve generating prompts by filling in a template with options selected from the UI. The template integrates expertise and best practices, giving users more control through UI options. This method is exemplified by the FeedbackBuffet prototype, a writing assistant that uses template-based prompts to generate feedback on writing samples <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib44" title="">44</a>]</cite>. (3) <span class="ltx_text ltx_font_italic" id="S9.p3.1.3">Free-Form Prompts</span>: This method grants users full control over the prompting process. Although challenging, it is beneficial in scenarios where complete control is desired.</p>
</div>
<div class="ltx_para" id="S9.p4">
<p class="ltx_p" id="S9.p4.1">Wang et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib75" title="">75</a>]</cite>
present a proactive interface design that addresses challenges users face in initializing and refining prompts, providing feedback to the system, and managing cognitive load. They describe three interaction techniques (<span class="ltx_text ltx_font_italic" id="S9.p4.1.1">Perception Articulation, Prompt Suggestions, Conversation Explanation</span>) and how they can be supported by user interface elements. Perception articulation is supported by a pre-task questionnaire and main prompt template - the first supports information need at the visceral level, while the latter at the formalized level. Prompt suggestions are provided through supportive function tabs, which support conscious need. Conversation explanations are also delivered through supportive function tabs, with a feedback mechanism allowing users to rate the usefulness of these explanations. This feature supports compromised needs.
Evaluation with participants demonstrated the effectiveness of these supportive functions in reducing cognitive load, guiding prompt refinement, and increasing user engagement. In interviews, participants appreciated the perception articulation functions for setting expectations and the conversation explanations for balancing expectations and satisfaction.</p>
</div>
<div class="ltx_para" id="S9.p5">
<p class="ltx_p" id="S9.p5.1">On one hand, the design space of user interfaces for <abbr class="ltx_glossaryref" title="large language models"><span class="ltx_text ltx_glossary_short-plural">LLMs</span></abbr> offers a myriad of new interaction possibilities. On the other, taking advantage of the new possibilities can lead to complexity, which can make interfaces harder to comprehend and can overwhelm users. From the history of search interface evolution, we know that more complex search interfaces have not been widely accepted. For example, faceted search UIs led to a sharp learning curve and increased cognitive load <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.11605v1#bib.bib77" title="">77</a>]</cite>. History likes to repeat itself. Will it be the case with user interfaces for <abbr class="ltx_glossaryref" title="large language models"><span class="ltx_text ltx_glossary_short-plural">LLMs</span></abbr>? Will the more complex interfaces for <abbr class="ltx_glossaryref" title="large language models"><span class="ltx_text ltx_glossary_short-plural">LLMs</span></abbr> become only niche products?</p>
</div>
</section>
<section class="ltx_section" id="S10">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">10 </span>Conclusions</h2>
<div class="ltx_para" id="S10.p1">
<p class="ltx_p" id="S10.p1.1">As mentioned multiple times throughout this chapter, handling complex interaction types and modalities has been relatively under-explored and the authors find it a rich area of investment for the further development of generative information retrieval systems. This chapter pointed out prior work on various interaction types, from expressing information need to result refinement and mixed-initiative interactions, including clarification, feedback, and proactive interactions. Recent developments in (multi-modal) foundation models, including large language models, have paved the path towards better understanding complex user interactions, but we are still far from ideal generative information retrieval systems that can satisfy user needs efficiently, effectively, fairly, and robustly.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
Abbasiantaeb, Z., Yuan, Y., Kanoulas, E., Aliannejadi, M.: Let the LLMs Talk: Simulating Human-to-Human Conversational QA via Zero-Shot LLM-to-LLM Interactions. In: WSDM. pp. 8–17. ACM (2024)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
Aliannejadi, M., Azzopardi, L., Zamani, H., Kanoulas, E., Thomas, P., Craswell, N.: Analysing mixed initiatives and search strategies during conversational search. In: CIKM. pp. 16–26. ACM (2021)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
Aliannejadi, M., Kiseleva, J., Chuklin, A., Dalton, J., Burtsev, M.: Convai3: Generating clarifying questions for open-domain dialogue systems (clariq). CoRR <span class="ltx_text ltx_font_bold" id="bib.bib3.1.1">abs/2009.11352</span> (2020)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
Aliannejadi, M., Kiseleva, J., Chuklin, A., Dalton, J., Burtsev, M.: Building and evaluating open-domain dialogue corpora with clarifying questions. In: EMNLP (1). pp. 4473–4484. Association for Computational Linguistics (2021)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
Aliannejadi, M., Zamani, H., Crestani, F., Croft, W.B.: Asking clarifying questions in open-domain information-seeking conversations. In: SIGIR. pp. 475–484. ACM (2019)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
Anand, A., Lyu, L., Idahl, M., Wang, Y., Wallat, J., Zhang, Z.: Explainable information retrieval: A survey. CoRR <span class="ltx_text ltx_font_bold" id="bib.bib6.1.1">abs/2211.02405</span> (2022)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
Anand, A., Sen, P., Saha, S., Verma, M., Mitra, M.: Explainable information retrieval. In: Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval. pp. 3448–3451. ACM (2023)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
Arguello, J., Diaz, F., Callan, J.: Learning to aggregate vertical results into web search results. In: CIKM. pp. 201–210. ACM (2011)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
Avula, S., Arguello, J.: Wizard of oz interface to study system initiative for conversational search. In: Proceedings of the 2020 Conference on Human Information Interaction and Retrieval. p. 447–451. CHIIR ’20, Association for Computing Machinery, New York, NY, USA (2020). https://doi.org/10.1145/3343413.3377941, <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi-org.ezp.lib.unimelb.edu.au/10.1145/3343413.3377941" title="">https://doi-org.ezp.lib.unimelb.edu.au/10.1145/3343413.3377941</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
Azzopardi, L., Aliannejadi, M., Kanoulas, E.: Towards building economic models of conversational search. In: ECIR (2). Lecture Notes in Computer Science, vol. 13186, pp. 31–38. Springer (2022)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
Balog, K.: Conversational AI from an information retrieval perspective: Remaining challenges and a case for user simulation. In: DESIRES. CEUR Workshop Proceedings, vol. 2950, pp. 80–90. CEUR-WS.org (2021)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
Belkin, N.J.: Anomalous states of knowledge as a basis for information retrieval. Canadian Journal of Information Science <span class="ltx_text ltx_font_bold" id="bib.bib12.1.1">5</span>, 133–143 (1980)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
Byström, K., Hansen, P.: Conceptual framework for tasks in information studies. Journal of the American Society for Information Science and Technology <span class="ltx_text ltx_font_bold" id="bib.bib13.1.1">56</span>(10), 1050–1061 (2005). https://doi.org/10.1002/asi.20197

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
Chen, J., Liu, Z., Huang, X., Wu, C., Liu, Q., Jiang, G., Pu, Y., Lei, Y., Chen, X., Wang, X., Lian, D., Chen, E.: When large language models meet personalization: Perspectives of challenges and opportunities. CoRR <span class="ltx_text ltx_font_bold" id="bib.bib14.1.1">abs/2307.16376</span> (2023)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
Cui, P., Wang, Z., Su, Z.: What videos are similar with you?: Learning a common attributed representation for video recommendation. In: Hua, K.A., Rui, Y., Steinmetz, R., Hanjalic, A., Natsev, A., Zhu, W. (eds.) Proceedings of the ACM International Conference on Multimedia, MM ’14,. pp. 597–606. ACM (2014)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
Cui, Z., Yu, F., Wu, S., Liu, Q., Wang, L.: Disentangled item representation for recommender systems. ACM Trans. Intell. Syst. Technol. <span class="ltx_text ltx_font_bold" id="bib.bib16.1.1">12</span>(2), 20:1–20:20 (2021)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
Cui, Z., Yu, F., Wu, S., Liu, Q., Wang, L.: Disentangled item representation for recommender systems. ACM Trans. Intell. Syst. Technol. <span class="ltx_text ltx_font_bold" id="bib.bib17.1.1">12</span>(2), 20:1–20:20 (2021)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
Deldjoo, Y., Dacrema, M.F., Constantin, M.G., Eghbal-zadeh, H., Cereda, S., Schedl, M., Ionescu, B., Cremonesi, P.: Movie genome: alleviating new item cold start in movie recommendation. User Model. User Adapt. Interact. <span class="ltx_text ltx_font_bold" id="bib.bib18.1.1">29</span>(2), 291–343 (2019)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
Deldjoo, Y., Schedl, M., Cremonesi, P., Pasi, G.: Recommender systems leveraging multimedia content. ACM Comput. Surv. <span class="ltx_text ltx_font_bold" id="bib.bib19.1.1">53</span>(5), 106:1–106:38 (2020)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
Deldjoo, Y., Trippas, J.R., Zamani, H.: Towards multi-modal conversational information seeking. In: Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval. p. 1577–1587. SIGIR ’21, Association for Computing Machinery, New York, NY, USA (2021). https://doi.org/10.1145/3404835.3462806, <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3404835.3462806" title="">https://doi.org/10.1145/3404835.3462806</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
Deng, Y., Lei, W., Lam, W., Chua, T.: A survey on proactive dialogue systems: Problems, methods, and prospects. In: IJCAI. pp. 6583–6591. ijcai.org (2023)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
Deng, Y., Liao, L., Chen, L., Wang, H., Lei, W., Chua, T.: Prompting and evaluating large language models for proactive dialogues: Clarification, target-guided, and non-collaboration. In: EMNLP (Findings). pp. 10602–10621. Association for Computational Linguistics (2023)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
Deng, Y., Zhang, A., Lin, Y., Chen, X., Wen, J., Chua, T.: Large language model powered agents in the web. In: WWW (Companion Volume). pp. 1242–1245. ACM (2024)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
Deng, Y., Zhang, W., Chen, Z., Gu, Q.: Rephrase and respond: Let large language models ask better questions for themselves. CoRR <span class="ltx_text ltx_font_bold" id="bib.bib24.1.1">abs/2311.04205</span> (2023)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
DERVIN, B., NILAN, M.: Information needs and uses. Annual review of information science and technology <span class="ltx_text ltx_font_bold" id="bib.bib25.1.1">21</span>, 3–33 (1986)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
Fei, N., Lu, Z., Gao, Y., Yang, G., Huo, Y., Wen, J., Lu, H., Song, R., Gao, X., Xiang, T., Sun, H., Wen, J.: Wenlan 2.0: Make AI imagine via a multimodal foundation model. Nat. Commun. <span class="ltx_text ltx_font_bold" id="bib.bib26.1.1">13</span>(1) (2022)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
Gao, J., Gebreegziabher, S.A., Choo, K.T.W., Li, T.J.J., Perrault, S.T., Malone, T.W.: A Taxonomy for Human-LLM Interaction Modes: An Initial Exploration. In: Extended Abstracts of the CHI Conference on Human Factors in Computing Systems. pp. 1–11 (2024). https://doi.org/10.1145/3613905.3650786

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
Gao, J., Wang, X., Wang, Y., Xie, X.: Explainable recommendation through attentive multi-view learning. In: AAAI. pp. 3622–3629. AAAI Press (2019)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
Huang, J., Chang, K.C.: Citation: A key to building responsible and accountable large language models. CoRR <span class="ltx_text ltx_font_bold" id="bib.bib29.1.1">abs/2307.02185</span> (2023)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
Jiang, E., Olson, K., Toh, E., Molina, A., Donsbach, A., Terry, M., Cai, C.J.: PromptMaker: Prompt-based Prototyping with Large Language Models. In: Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems. pp. 1–8. CHI EA ’22, ACM (2022). https://doi.org/10.1145/3491101.3503564

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
Jiang, E., Toh, E., Molina, A., Donsbach, A., Cai, C.J., Terry, M.: GenLine and GenForm: Two Tools for Interacting with Generative Language Models in a Code Editor. In: Adjunct Proceedings of the 34th Annual ACM Symposium on User Interface Software and Technology. pp. 145–147. ACM (2021). https://doi.org/10.1145/3474349.3480209

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
Jiang, P., Rayan, J., Dow, S.P., Xia, H.: Graphologue: Exploring Large Language Model Responses with Interactive Diagrams. In: Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology. pp. 1–20. ACM (2023). https://doi.org/10.1145/3586183.3606737

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
Kaminskas, M., Ricci, F., Schedl, M.: Location-aware music recommendation using auto-tagging and hybrid matching. In: Seventh ACM Conference on Recommender Systems, RecSys ’13, Hong Kong, China, October 12-16, 2013. pp. 17–24. ACM (2013)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
Keyvan, K., Huang, J.X.: How to approach ambiguous queries in conversational search: A survey of techniques, approaches, tools, and challenges. ACM Comput. Surv. <span class="ltx_text ltx_font_bold" id="bib.bib34.1.1">55</span>(6), 129:1–129:40 (2023)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
Kiesel, J., Bahrami, A., Stein, B., Anand, A., Hagen, M.: Toward voice query clarification. In: SIGIR. pp. 1257–1260. ACM (2018)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock">
Kong, W., Allan, J.: Extracting query facets from search results. In: SIGIR. pp. 93–102. ACM (2013)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock">
Kostric, I., Balog, K., Radlinski, F.: Generating usage-related questions for preference elicitation in conversational recommender systems. Trans. Recomm. Syst. <span class="ltx_text ltx_font_bold" id="bib.bib37.1.1">2</span>(2), 12:1–12:24 (2024)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock">
Krasakis, A.M., Aliannejadi, M., Voskarides, N., Kanoulas, E.: Analysing the effect of clarifying questions on document ranking in conversational search. In: ICTIR. pp. 129–132. ACM (2020)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock">
Krishna, S., Ma, J., Slack, D., Ghandeharioun, A., Singh, S., Lakkaraju, H.: Post hoc explanations of language models can improve language models. In: Advances in Neural Information Processing Systems 36 (2023)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock">
Kuhlthau, C.C.: Inside the search process: Information seeking from the user’s perspective. Journal of the American Society for Information Science <span class="ltx_text ltx_font_bold" id="bib.bib40.1.1">42</span>(5), 361–371 (1991-06)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock">
Lee, J., Kim, J.: Enhanced facet generation with LLM editing. In: LREC/COLING. pp. 5856–5865. ELRA and ICCL (2024)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock">
Li, C., Gan, Z., Yang, Z., Yang, J., Li, L., Wang, L., Gao, J.: Multimodal foundation models: From specialists to general-purpose assistants. Foundations and Trends® in Computer Graphics and Vision <span class="ltx_text ltx_font_bold" id="bib.bib42.1.1">16</span>(1-2), 1–214 (2024). https://doi.org/10.1561/0600000110, <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://dx.doi.org/10.1561/0600000110" title="">http://dx.doi.org/10.1561/0600000110</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock">
Liao, L., Yang, G.H., Shah, C.: Proactive conversational agents in the post-chatgpt world. In: Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval. p. 3452–3455. SIGIR ’23, Association for Computing Machinery, New York, NY, USA (2023). https://doi.org/10.1145/3539618.3594250, <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3539618.3594250" title="">https://doi.org/10.1145/3539618.3594250</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[44]</span>
<span class="ltx_bibblock">
MacNeil, S., Tran, A., Kim, J., Huang, Z., Bernstein, S., Mogil, D.: Prompt Middleware: Mapping Prompts for Large Language Models to UI Affordances (2023). https://doi.org/10.48550/arXiv.2307.01142

</span>
</li>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[45]</span>
<span class="ltx_bibblock">
Marchionini, G.: Information Seeking in Electronic Environments. Cambridge University Press (1995)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib46">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[46]</span>
<span class="ltx_bibblock">
McAuley, J.J., Targett, C., Shi, Q., van den Hengel, A.: Image-based recommendations on styles and substitutes. In: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval, Santiago, Chile, August 9-13, 2015. pp. 43–52. ACM (2015)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib47">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[47]</span>
<span class="ltx_bibblock">
Oramas, S., Nieto, O., Sordo, M., Serra, X.: A deep multimodal approach for cold-start music recommendation. In: Proceedings of the 2nd Workshop on Deep Learning for Recommender Systems, DLRS@RecSys 2017, Como, Italy, August 27, 2017. pp. 32–37. ACM (2017)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib48">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[48]</span>
<span class="ltx_bibblock">
Owoicho, P., Sekulic, I., Aliannejadi, M., Dalton, J., Crestani, F.: Exploiting simulated user feedback for conversational search: Ranking, rewriting, and beyond. In: SIGIR. pp. 632–642. ACM (2023)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib49">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[49]</span>
<span class="ltx_bibblock">
Radlinski, F., Balog, K., Byrne, B., Krishnamoorthi, K.: Coached conversational preference elicitation: A case study in understanding movie preferences. In: SIGdial. pp. 353–360. Association for Computational Linguistics (2019)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib50">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[50]</span>
<span class="ltx_bibblock">
Rahmani, H.A., Wang, X., Aliannejadi, M., Naghiaei, M., Yilmaz, E.: Clarifying the path to user satisfaction: An investigation into clarification usefulness. In: EACL (Findings). pp. 1266–1277. Association for Computational Linguistics (2024)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib51">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[51]</span>
<span class="ltx_bibblock">
Ram, A., Prasad, R., Khatri, C., Venkatesh, A., Gabriel, R., Liu, Q., Nunn, J., Hedayatnia, B., Cheng, M., Nagar, A., King, E., Bland, K., Wartick, A., Pan, Y., Song, H., Jayadevan, S., Hwang, G., Pettigrue, A.: Conversational AI: the science behind the alexa prize. arXiv preprint 1801.03604 (2018)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib52">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[52]</span>
<span class="ltx_bibblock">
Rao, S., III, H.D.: Learning to ask good questions: Ranking clarification questions using neural expected value of perfect information. In: ACL (1). pp. 2737–2746. Association for Computational Linguistics (2018)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib53">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[53]</span>
<span class="ltx_bibblock">
Ren, P., Liu, Z., Song, X., Tian, H., Chen, Z., Ren, Z., de Rijke, M.: Wizard of search engine: Access to information through conversations with search engines. In: SIGIR. pp. 533–543. ACM (2021)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib54">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[54]</span>
<span class="ltx_bibblock">
Salemi, A., Altmayer Pizzorno, J., Zamani, H.: A symmetric dual encoding dense retrieval framework for knowledge-intensive visual question answering. In: Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval. p. 110–120. SIGIR ’23, Association for Computing Machinery, New York, NY, USA (2023). https://doi.org/10.1145/3539618.3591629, <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3539618.3591629" title="">https://doi.org/10.1145/3539618.3591629</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib55">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[55]</span>
<span class="ltx_bibblock">
Salle, A., Malmasi, S., Rokhlenko, O., Agichtein, E.: Cosearcher: studying the effectiveness of conversational search refinement and clarification through user simulation. Inf. Retr. J. <span class="ltx_text ltx_font_bold" id="bib.bib55.1.1">25</span>(2), 209–238 (2022)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib56">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[56]</span>
<span class="ltx_bibblock">
Samarinas, C., Zamani, H.: Procis: A benchmark for proactive retrieval in conversations. In: Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval. SIGIR ’24, Association for Computing Machinery, New York, NY, USA (2024), (to)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib57">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[57]</span>
<span class="ltx_bibblock">
Santos, R.L.T., MacDonald, C., Ounis, I.: Search result diversification. Found. Trends Inf. Retr. <span class="ltx_text ltx_font_bold" id="bib.bib57.1.1">9</span>(1), 1–90 (2015)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib58">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[58]</span>
<span class="ltx_bibblock">
Sekulic, I., Aliannejadi, M., Crestani, F.: User engagement prediction for clarification in search. In: ECIR (1). Lecture Notes in Computer Science, vol. 12656, pp. 619–633. Springer (2021)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib59">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[59]</span>
<span class="ltx_bibblock">
Sekulic, I., Aliannejadi, M., Crestani, F.: Evaluating mixed-initiative conversational search systems via user simulation. In: WSDM. pp. 888–896. ACM (2022)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib60">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[60]</span>
<span class="ltx_bibblock">
Sekulic, I., Aliannejadi, M., Crestani, F.: Exploiting document-based features for clarification in conversational search. In: ECIR (1). Lecture Notes in Computer Science, vol. 13185, pp. 413–427. Springer (2022)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib61">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[61]</span>
<span class="ltx_bibblock">
Sekulic, I., Lajewska, W., Balog, K., Crestani, F.: Estimating the usefulness of clarifying questions and answers for conversational search. In: ECIR (3). Lecture Notes in Computer Science, vol. 14610, pp. 384–392. Springer (2024)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib62">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[62]</span>
<span class="ltx_bibblock">
Sen, P., Ganguly, D., Jones, G.: Procrastination is the thief of time: Evaluating the effectiveness of proactive search systems. In: The 41st International ACM SIGIR Conference on Research &amp; Development in Information Retrieval. p. 1157–1160. SIGIR ’18, Association for Computing Machinery, New York, NY, USA (2018). https://doi.org/10.1145/3209978.3210114, <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3209978.3210114" title="">https://doi.org/10.1145/3209978.3210114</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib63">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[63]</span>
<span class="ltx_bibblock">
Shaikh, O., Gligoric, K., Khetan, A., Gerstgrasser, M., Yang, D., Jurafsky, D.: Grounding gaps in language model generations. In: Duh, K., Gomez, H., Bethard, S. (eds.) Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers). pp. 6279–6296. Association for Computational Linguistics, Mexico City, Mexico (Jun 2024), <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/2024.naacl-long.348" title="">https://aclanthology.org/2024.naacl-long.348</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib64">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[64]</span>
<span class="ltx_bibblock">
Subramonyam, H., Pea, R., Pondoc, C., Agrawala, M., Seifert, C.: Bridging the Gulf of Envisioning: Cognitive Challenges in Prompt Based Interactions with LLMs. In: Proceedings of the CHI Conference on Human Factors in Computing Systems. pp. 1–19. ACM (2024). https://doi.org/10.1145/3613904.3642754

</span>
</li>
<li class="ltx_bibitem" id="bib.bib65">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[65]</span>
<span class="ltx_bibblock">
Suh, S., Min, B., Palani, S., Xia, H.: Sensecape: Enabling Multilevel Exploration and Sensemaking with Large Language Models. In: Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology. pp. 1–18. ACM (2023). https://doi.org/10.1145/3586183.3606756

</span>
</li>
<li class="ltx_bibitem" id="bib.bib66">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[66]</span>
<span class="ltx_bibblock">
Sun, Y., Zhang, Y.: Conversational recommender system. In: The 41st International ACM SIGIR Conference on Research &amp; Development in Information Retrieval. p. 235–244. SIGIR ’18, Association for Computing Machinery, New York, NY, USA (2018). https://doi.org/10.1145/3209978.3210002, <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3209978.3210002" title="">https://doi.org/10.1145/3209978.3210002</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib67">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[67]</span>
<span class="ltx_bibblock">
Sundar, A., Heck, L.: Multimodal conversational AI: A survey of datasets and approaches. In: Liu, B., Papangelis, A., Ultes, S., Rastogi, A., Chen, Y.N., Spithourakis, G., Nouri, E., Shi, W. (eds.) Proceedings of the 4th Workshop on NLP for Conversational AI. pp. 131–147. Association for Computational Linguistics, Dublin, Ireland (May 2022). https://doi.org/10.18653/v1/2022.nlp4convai-1.12, <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/2022.nlp4convai-1.12" title="">https://aclanthology.org/2022.nlp4convai-1.12</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib68">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[68]</span>
<span class="ltx_bibblock">
Tangseng, P., Okatani, T.: Toward explainable fashion recommendation. In: IEEE Winter Conference on Applications of Computer Vision, WACV 2020, Snowmass Village, CO, USA, March 1-5, 2020. pp. 2142–2151. IEEE (2020)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib69">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[69]</span>
<span class="ltx_bibblock">
Taylor, R.S.: The process of asking questions. American Documentation <span class="ltx_text ltx_font_bold" id="bib.bib69.1.1">13</span>(4), 391–396 (1962). https://doi.org/10.1002/asi.5090130405

</span>
</li>
<li class="ltx_bibitem" id="bib.bib70">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[70]</span>
<span class="ltx_bibblock">
Taylor, R.S.: Question-negotiation and information seeking in libraries. College &amp; Research Libraries <span class="ltx_text ltx_font_bold" id="bib.bib70.1.1">29</span>(3), 178–194 (1968). https://doi.org/10.5860/crl_29_03_178

</span>
</li>
<li class="ltx_bibitem" id="bib.bib71">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[71]</span>
<span class="ltx_bibblock">
Trippas, J.R., Spina, D., Thomas, P., Sanderson, M., Joho, H., Cavedon, L.: Towards a model for spoken conversational search. Inf. Process. Manage. <span class="ltx_text ltx_font_bold" id="bib.bib71.1.1">57</span>(2) (mar 2020). https://doi.org/10.1016/j.ipm.2019.102162, <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1016/j.ipm.2019.102162" title="">https://doi.org/10.1016/j.ipm.2019.102162</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib72">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[72]</span>
<span class="ltx_bibblock">
Tunkelang, D.: Faceted Search. Synthesis Lectures on Information Concepts, Retrieval, and Services, Morgan &amp; Claypool Publishers (2009)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib73">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[73]</span>
<span class="ltx_bibblock">
Viappiani, P., Faltings, B., Pu, P.: Preference-based search using example-critiquing with suggestions. J. Artif. Intell. Res. <span class="ltx_text ltx_font_bold" id="bib.bib73.1.1">27</span>, 465–503 (2006)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib74">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[74]</span>
<span class="ltx_bibblock">
Wadhwa, S., Zamani, H.: Towards system-initiative conversational information seeking. In: Proceedings of the Second International Conference on Design of Experimental Search and Information Retrieval Systems. pp. 102–116. DESIRES ’21, CSUR (2021)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib75">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[75]</span>
<span class="ltx_bibblock">
Wang, B., Liu, J., Karimnazarov, J., Thompson, N.: Task Supportive and Personalized Human-Large Language Model Interaction: A User Study. In: Proceedings of the 2024 ACM SIGIR Conference on Human Information Interaction and Retrieval. pp. 370–375 (2024). https://doi.org/10.1145/3627508.3638344

</span>
</li>
<li class="ltx_bibitem" id="bib.bib76">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[76]</span>
<span class="ltx_bibblock">
Wang, S., Wang, Y., Tang, J., Shu, K., Ranganath, S., Liu, H.: What your images reveal: Exploiting visual contents for point-of-interest recommendation. In: Proceedings of the 26th International Conference on World Wide Web, WWW 2017. pp. 391–400. ACM (2017)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib77">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[77]</span>
<span class="ltx_bibblock">
Wilson, M.: Evaluating the Cognitive Impact of Search User Interface Design Decisions. In: Proceedings of the 1st European Workshop on Human-Computer Interaction and Information Retrieval. pp. 27–30 (2011), <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://ceur-ws.org/Vol-763/" title="">http://ceur-ws.org/Vol-763/</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib78">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[78]</span>
<span class="ltx_bibblock">
Wu, Y., Macdonald, C., Ounis, I.: Multimodal conversational fashion recommendation with positive and negative natural-language feedback. In: Proceedings of the 4th Conference on Conversational User Interfaces. CUI ’22, Association for Computing Machinery, New York, NY, USA (2022). https://doi.org/10.1145/3543829.3543837, <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3543829.3543837" title="">https://doi.org/10.1145/3543829.3543837</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib79">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[79]</span>
<span class="ltx_bibblock">
Yu, P., Rahimi, R., Allan, J.: Towards explainable search results: A listwise explanation generator. In: SIGIR. pp. 669–680. ACM (2022)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib80">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[80]</span>
<span class="ltx_bibblock">
Zamani, H., Croft, W.B.: Joint modeling and optimization of search and recommendation. In: Proceedings of the First International Conference on Design of Experimental Search and Information Retrieval Systems. pp. 36–41. DESIRES ’18, CSUR (2020)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib81">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[81]</span>
<span class="ltx_bibblock">
Zamani, H., Croft, W.B.: Learning a joint search and recommendation model from user-item interactions. In: Proceedings of the 13th International Conference on Web Search and Data Mining. pp. 717–725. WSDM ’20, Association for Computing Machinery, New York, NY, USA (2020). https://doi.org/10.1145/3336191.3371818, <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3336191.3371818" title="">https://doi.org/10.1145/3336191.3371818</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib82">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[82]</span>
<span class="ltx_bibblock">
Zamani, H., Dumais, S.T., Craswell, N., Bennett, P.N., Lueck, G.: Generating clarifying questions for information retrieval. In: WWW. pp. 418–428. ACM / IW3C2 (2020)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib83">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[83]</span>
<span class="ltx_bibblock">
Zamani, H., Lueck, G., Chen, E., Quispe, R., Luu, F., Craswell, N.: MIMICS: A large-scale data collection for search clarification. In: CIKM. pp. 3189–3196. ACM (2020)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib84">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[84]</span>
<span class="ltx_bibblock">
Zamani, H., Mitra, B., Chen, E., Lueck, G., Diaz, F., Bennett, P.N., Craswell, N., Dumais, S.T.: Analyzing and learning from user interactions for search clarification. In: Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval. p. 1181–1190. SIGIR ’20, Association for Computing Machinery, New York, NY, USA (2020). https://doi.org/10.1145/3397271.3401160, <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3397271.3401160" title="">https://doi.org/10.1145/3397271.3401160</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib85">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[85]</span>
<span class="ltx_bibblock">
Zamani, H., Trippas, J.R., Dalton, J., Radlinski, F.: Conversational information seeking. Foundations and Trends® in Information Retrieval <span class="ltx_text ltx_font_bold" id="bib.bib85.1.1">17</span>(3-4), 244–456 (2023). https://doi.org/10.1561/1500000081, <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://dx.doi.org/10.1561/1500000081" title="">http://dx.doi.org/10.1561/1500000081</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib86">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[86]</span>
<span class="ltx_bibblock">
Zamfirescu-Pereira, J., Wong, R.Y., Hartmann, B., Yang, Q.: Why Johnny Can’t Prompt: How Non-AI Experts Try (and Fail) to Design LLM Prompts. In: Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems. pp. 1–21. CHI ’23, Association for Computing Machinery (2023). https://doi.org/10.1145/3544548.3581388

</span>
</li>
<li class="ltx_bibitem" id="bib.bib87">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[87]</span>
<span class="ltx_bibblock">
Zeng, H., Kallumadi, S., Alibadi, Z., Nogueira, R., Zamani, H.: A personalized dense retrieval framework for unified information access. In: Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval. p. 121–130. SIGIR ’23, Association for Computing Machinery, New York, NY, USA (2023). https://doi.org/10.1145/3539618.3591626, <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3539618.3591626" title="">https://doi.org/10.1145/3539618.3591626</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib88">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[88]</span>
<span class="ltx_bibblock">
Zhang, Q., Naradowsky, J., Miyao, Y.: Ask an expert: Leveraging language models to improve strategic reasoning in goal-oriented dialogue models. In: ACL (Findings). pp. 6665–6694. Association for Computational Linguistics (2023)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib89">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[89]</span>
<span class="ltx_bibblock">
Zhang, R., Guo, J., Fan, Y., Lan, Y., Cheng, X.: Query understanding via intent description generation. In: CIKM. pp. 1823–1832. ACM (2020)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib90">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[90]</span>
<span class="ltx_bibblock">
Zhang, S., Balog, K.: Evaluating conversational recommender systems via user simulation. In: KDD. pp. 1512–1520. ACM (2020)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib91">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[91]</span>
<span class="ltx_bibblock">
Zhang, W., Aliannejadi, M., Yuan, Y., Pei, J., Huang, J.H., Kanoulas, E.: Towards fine-grained citation evaluation in generated text: A comparative analysis of faithfulness metrics (2024), <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2406.15264" title="">https://arxiv.org/abs/2406.15264</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib92">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[92]</span>
<span class="ltx_bibblock">
Zhang, Y., Chen, X., Ai, Q., Yang, L., Croft, W.B.: Towards conversational search and recommendation: System ask, user respond. In: Proceedings of the 27th ACM International Conference on Information and Knowledge Management. pp. 177–186. CIKM ’18, ACM, New York, NY, USA (2018). https://doi.org/10.1145/3269206.3271776, <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://doi.acm.org/10.1145/3269206.3271776" title="">http://doi.acm.org/10.1145/3269206.3271776</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib93">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[93]</span>
<span class="ltx_bibblock">
Zhang, Z., Gao, J., Dhaliwal, R.S., Li, T.J.J.: VISAR: A Human-AI Argumentative Writing Assistant with Visual Programming and Rapid Draft Prototyping. In: Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology. pp. 1–30 (2023). https://doi.org/10.1145/3586183.3606800

</span>
</li>
<li class="ltx_bibitem" id="bib.bib94">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[94]</span>
<span class="ltx_bibblock">
Zhao, H., Chen, H., Yang, F., Liu, N., Deng, H., Cai, H., Wang, S., Yin, D., Du, M.: Explainability for large language models: A survey. CoRR <span class="ltx_text ltx_font_bold" id="bib.bib94.1.1">abs/2309.01029</span> (2023)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib95">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[95]</span>
<span class="ltx_bibblock">
Zou, J., Aliannejadi, M., Kanoulas, E., Pera, M.S., Liu, Y.: Users meet clarifying questions: Toward a better understanding of user interactions for search clarification. ACM Trans. Inf. Syst. <span class="ltx_text ltx_font_bold" id="bib.bib95.1.1">41</span>(1), 16:1–16:25 (2023)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib96">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[96]</span>
<span class="ltx_bibblock">
Zou, J., Chen, Y., Kanoulas, E.: Towards question-based recommender systems. In: SIGIR. pp. 881–890. ACM (2020)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib97">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[97]</span>
<span class="ltx_bibblock">
Zou, J., Kanoulas, E.: Learning to ask: Question-based sequential bayesian product search. In: CIKM. pp. 369–378. ACM (2019)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib98">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[98]</span>
<span class="ltx_bibblock">
Zou, J., Sun, A., Long, C., Aliannejadi, M., Kanoulas, E.: Asking clarifying questions: To benefit or to disturb users in web search? Inf. Process. Manag. <span class="ltx_text ltx_font_bold" id="bib.bib98.1.1">60</span>(2), 103176 (2023)

</span>
</li>
</ul>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Tue Jul 16 11:06:04 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
