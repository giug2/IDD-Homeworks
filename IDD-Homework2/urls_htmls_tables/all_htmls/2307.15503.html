<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2307.15503] The Applicability of Federated Learning to Official Statistics</title><meta property="og:description" content="This work investigates the potential of Federated Learning (FL) for official statistics and shows how well the performance of FL models can keep up with centralized learning methods.
FL is particularly interesting for …">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="The Applicability of Federated Learning to Official Statistics">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="The Applicability of Federated Learning to Official Statistics">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2307.15503">

<!--Generated on Wed Feb 28 16:19:53 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line"><span id="id1" class="ltx_note ltx_role_institutetext"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">institutetext: </span>Universität Hamburg, Hamburg, Germany </span></span></span><span id="id2" class="ltx_note ltx_role_institutetext"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_note_type">institutetext: </span>Federal Statistical Office (Destatis), Wiesbaden, Germany
</span></span></span>
<h1 class="ltx_title ltx_title_document">The Applicability of Federated Learning to Official Statistics</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Joshua Stock
</span><span class="ltx_author_notes">11</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Oliver Hauke
</span><span class="ltx_author_notes">22</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Julius Weißmann
</span><span class="ltx_author_notes">22</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Hannes Federrath
</span><span class="ltx_author_notes">11</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id1.id1" class="ltx_p">This work investigates the potential of Federated Learning (FL) for official statistics and shows how well the performance of FL models can keep up with centralized learning methods.
FL is particularly interesting for official statistics because its utilization can safeguard the privacy of data holders, thus facilitating access to a broader range of data.
By simulating three different use cases, important insights on the applicability of the technology are gained.
The use cases are based on a medical insurance data set, a fine dust pollution data set and a mobile radio coverage data set – all of which are from domains close to official statistics.
We provide a detailed analysis of the results, including a comparison of centralized and FL algorithm performances for each simulation.
In all three use cases, we were able to train models via FL which reach a performance very close to the centralized model benchmarks.
Our key observations and their implications for transferring the simulations into practice are summarized.
We arrive at the conclusion that FL has the potential to emerge as a pivotal technology in future use cases of official statistics.</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">The aim of national statistical offices (NSOs) is to develop, produce and disseminate high-quality official statistics that can be considered a reliable portrayal of reality <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx19" title="" class="ltx_ref">Yun+22</a>]</cite>.
In order to effectively capture our rapidly changing world, NSOs are currently undergoing a process of modernization, leveraging new data sources, methodologies and technologies.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">NSOs have effectively extracted information from new data sources,
such as scanner data<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>Scanner data in consumer price statistics and for determining regional price differences <a target="_blank" href="https://www.destatis.de/EN/Service/EXSTAT/Datensaetze/scanner-data.html" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.destatis.de/EN/Service/EXSTAT/Datensaetze/scanner-data.html</a>, accessed on July 17, 2023</span></span></span>
or Mobile Network Operator (MNO) data<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>Use of MNO data <a target="_blank" href="https://cros-legacy.ec.europa.eu/content/12-use-mno-data_en" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://cros-legacy.ec.europa.eu/content/12-use-mno-data_en</a>, accessed on July 17, 2023</span></span></span>.
However, the potential of numerous other data sources, including privately held data<span id="footnote3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>Guidance on private sector data sharing
<a target="_blank" href="https://digital-strategy.ec.europa.eu/en/policies/private-sector-data-sharing" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://digital-strategy.ec.europa.eu/en/policies/private-sector-data-sharing</a>, accessed on July 17, 2023</span></span></span> or data from certain official entities, remains largely untapped.
Legal frameworks, which are fundamental to official statistics, only adapt slowly to changing data needs and currently hinder access to valuable new data sources.
Cooperation with potential data donors faces restrictions due to concerns about privacy, confidentiality, or disclosing individual business interests.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">In the meantime, the methodology employed by NSOs is evolving, with machine learning (ML) gaining substantial popularity and, as a result, undergoing a process of establishment.
ML has been applied in various areas of official statistics (e.g. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx4" title="" class="ltx_ref">DB17</a>, <a href="#bib.bibx2" title="" class="ltx_ref">BDF18</a>, <a href="#bib.bibx5" title="" class="ltx_ref">Eur22</a>]</cite>),
and new frameworks such as <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx19" title="" class="ltx_ref">Yun+22</a>]</cite> address the need to measure the quality of ML.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">Within official statistics, ML tools have proven effective in processing new data sources, such as text and images, or enabling the automation of statistical production tasks, including classifying information or predicting not (yet) available data.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p"><span id="S1.p5.1.1" class="ltx_text ltx_font_bold">Federated learning (FL)</span> is an emerging approach within ML that provides immense unexplored potential for official statistics. It addresses the challenge of extracting and exchanging valuable global information from new data sources without compromising the privacy of individual data owners.
Introduced in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx10" title="" class="ltx_ref">McM+17</a>]</cite>, FL enables collaborative model training across distributed data sources while preserving data privacy by keeping the data localized.
In scenarios where external partners are unwilling to share individual-level information due
to regulatory or strategic
considerations, but still aim to analyze or disseminate global insights in their field of application, NSOs can offer trustworthy solutions by utilizing FL.
In return, FL empowers contributing NSOs to
integrate new data sources into statistical production.</p>
</div>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.1" class="ltx_p">Although FL has been successfully applied to many domains, to the best of our knowledge, besides our work only one currently presented study investigates the applicability of FL to the field of official statistics.
In a proof of concept (PoC) by the United Nations (UN), FL is applied to estimate human activity based on data collected from smart and wearable devices <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx17" title="" class="ltx_ref">Tem22</a>, <a href="#bib.bibx3" title="" class="ltx_ref">Buc23</a>]</cite>.
The PoC emphasizes operative aspects of FL coordinating multiple NSOs and benefits of additional privacy enhancing technologies.</p>
</div>
<div id="S1.p7" class="ltx_para">
<p id="S1.p7.1" class="ltx_p">The main contribution of this paper lies in presenting three additional applications of FL that address current data need representative for official statistics.
Complementary, we emphasize measuring the numerical predictive performance and reproducibility by openly sharing our code, which, in two instances, is applied to publicly available data.
In the first simulation related to health, individual healthcare costs are predicted utilizing tools for regression.
In the second simulation related to <span id="S1.p7.1.1" class="ltx_text ltx_font_bold">sustainability</span>, current fine dust pollution levels are classified based on meteorological data.
In the third simulation related to <span id="S1.p7.1.2" class="ltx_text ltx_font_bold">mobility</span>, the daily range of movement of mobile phone users are classified by MNO data.
The first two simulations focus on assessing the estimation performance achieved by FL in comparison to centralized models that have complete access to all available data.
The third application presents valuable insights and lessons learned from the implementation of FL, involving the active participation of a real external partner.
We draw conclusions on the applicability of FL in NSOs in <a href="#S5" title="5 Implications for Official Statistics ‣ The Applicability of Federated Learning to Official Statistics" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">section 5</span></a>, which are summarized in <a href="#S6" title="6 Conclusion ‣ The Applicability of Federated Learning to Official Statistics" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">section 6</span></a>.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Background</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">Before presenting the simulated use cases in <a href="#S3" title="3 Simulations ‣ The Applicability of Federated Learning to Official Statistics" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">section 3</span></a>, this section provides an overview of FL and privacy challenges with ML.</p>
</div>
<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Federated Learning</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">In FL, a centralized server (or aggregator, in our case a NSO) coordinates the process of training a ML model (mainly deep neural networks) by initializing a global model and forwarding it to the data owners (clients).
In each training round, each client trains the model with their private data and sends the resulting model back to the central server.
The central server uses a FL method to aggregate the updates of the participants into the next iteration of the global model and starts the next round by distributing the updated model to the clients.
This process is repeated to improve the performance of the model.</p>
</div>
<div id="S2.SS1.p2" class="ltx_para">
<p id="S2.SS1.p2.1" class="ltx_p">NSOs primarily strive to generate global models that accurately represent the available data, which, in our setting, is distributed among multiple clients. Thus, we compare the performance of FL to models with access to the combined data of all clients.
Alternatively, if upcoming applications seek to supply each client with an optimized individual model by leveraging information from the other clients, <em id="S2.SS1.p2.1.1" class="ltx_emph ltx_font_italic">personalized</em> FL can be used. This approach is not covered in this paper but can be found in  <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx8" title="" class="ltx_ref">KKP20</a>, <a href="#bib.bibx7" title="" class="ltx_ref">Hu+18</a>]</cite>.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Privacy Challenges with Machine Learning</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">When training data for a ML model is distributed among multiple parties, the data traditionally needs to be combined on a central server prior to training an ML model.
FL has become a popular alternative to this approach, as it allows to train a model in a distributed way from the start, without the need to aggregate training data first.
Thus, using FL has the privacy advantage that there is no need to exchange private training data.
Instead, data holders can train a global model collaboratively in a distributed fashion, without transferring any data record.</p>
</div>
<div id="S2.SS2.p2" class="ltx_para">
<p id="S2.SS2.p2.1" class="ltx_p">But although FL makes sharing private training data obsolete,
there are other privacy challenges inherent to ML which have also been observed for FL.
While ML models are always trained to fulfill a dedicated task, often more information than strictly necessary for fulfilling the task is extracted into the model weights during training <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx16" title="" class="ltx_ref">SRS17</a>]</cite>.
This excessive, and potentially private, information in the model weights is called privacy leakage.
In general, this leakage can be leveraged by any party who has full access to a model and its trained weights.</p>
</div>
<div id="S2.SS2.p3" class="ltx_para">
<p id="S2.SS2.p3.1" class="ltx_p">One concrete example of such a privacy attack is <em id="S2.SS2.p3.1.1" class="ltx_emph ltx_font_italic">training data extraction</em> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx22" title="" class="ltx_ref">ZLH19</a>]</cite>, which allows extracting data records from a trained model.
Another known attack is <em id="S2.SS2.p3.1.2" class="ltx_emph ltx_font_italic">model inversion</em> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx6" title="" class="ltx_ref">HAP17</a>]</cite>, where repeated requests to the model are used to reconstruct class representatives.
<em id="S2.SS2.p3.1.3" class="ltx_emph ltx_font_italic">Membership inference</em> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx15" title="" class="ltx_ref">Sho+17</a>]</cite>
aims at individual training data records: the attack’s target is to decide whether a specific data record was part of the training data.
Building on the original proposal, other works have transferred membership inference attacks to the FL scenario <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx12" title="" class="ltx_ref">NSH19</a>]</cite>.
Last but not least, <em id="S2.SS2.p3.1.4" class="ltx_emph ltx_font_italic">property inference</em> attacks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx11" title="" class="ltx_ref">Mel+19</a>]</cite> allow to deduce statistical properties of the target model’s training data.
This is especially relevant in FL scenarios, where the characteristics of each client’s local data set can be highly sensitive, e.g., in medical domains.</p>
</div>
<div id="S2.SS2.p4" class="ltx_para">
<p id="S2.SS2.p4.1" class="ltx_p">The applicability of these attacks depends on the concrete use case, the type of model and other factors.
Concerning attacker models, i.e., the scenario in which an attack is executed, some FL-specific attacks rely on a malicious aggregator.
Nonetheless, all attacks mentioned above also work in an environment where not the aggregator, but one of the FL clients is the attacker.
Hence, even if the aggregator can be trusted, e.g., because the aggregator’s role is assumed by a NSO, these attacks can still be executed by other FL clients.
Analyzing the individual privacy leakage of the simulated use cases in this paper are out of scope.
Nonetheless, raising awareness to these issues, e.g., by communicating potential risks to clients in an FL scenario, should not be neglected.
Beyond this, strategies under the umbrella term <em id="S2.SS2.p4.1.1" class="ltx_emph ltx_font_italic">privay-preserving machine learning</em> (PPML) can help to mitigate these risks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx20" title="" class="ltx_ref">YZH21</a>]</cite>.</p>
</div>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Frameworks</h3>

<div id="S2.SS3.p1" class="ltx_para">
<p id="S2.SS3.p1.1" class="ltx_p">In our simulations, we use the frameworks TensorFlow<span id="footnote4" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span>TensorFlow <a target="_blank" href="https://www.tensorflow.org/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.tensorflow.org/</a>, accessed on July 17, 2023</span></span></span> for neural networks
and TensorFlow Federated<span id="footnote5" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span>TensorFlow Federated: Machine learning on decentralized data <a target="_blank" href="https://www.tensorflow.org/federated" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.tensorflow.org/federated</a>, accessed on July 17, 2023</span></span></span> for FL.
We use PyCaret<span id="footnote6" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_tag ltx_tag_note">6</span>PyCaret <a target="_blank" href="https://pycaret.org/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://pycaret.org/</a>, accessed on July 17, 2023</span></span></span> for automizing benchmark experiments in the centralized settings and scikit-learn<span id="footnote7" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">7</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">7</sup><span class="ltx_tag ltx_tag_note">7</span>scikit-learn, Machine Learning in Python <a target="_blank" href="https://scikit-learn.org/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://scikit-learn.org/</a>, accessed on July 17, 2023</span></span></span> for data processing.</p>
</div>
<div id="S2.SS3.p2" class="ltx_para">
<p id="S2.SS3.p2.1" class="ltx_p">The code we have written for this work is openly available on GitHub<span id="footnote8" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">8</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">8</sup><span class="ltx_tag ltx_tag_note">8</span>Code repository for this paper: <a target="_blank" href="https://www.github.com/joshua-stock/fl-official-statistics" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.github.com/joshua-stock/fl-official-statistics</a>, accessed on July 17, 2023. Note that for the mobile radio coverage simulation, the code has only been executed locally on the private data set, hence it is not included in the repository.</span></span></span>.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Simulations</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">Most relevant for NSOs is <em id="S3.p1.1.1" class="ltx_emph ltx_font_italic">cross-silo</em> FL, where a few reliable clients train a model, e.g. official authorities.
In contrast, <em id="S3.p1.1.2" class="ltx_emph ltx_font_italic">cross-device</em> FL uses numerous clients, e.g. smartphones, to train a model.
To analyze the potential of cross-silo FL for official statistics, we run simulations with three different data sets.
For each use case, we first compute benchmarks by evaluating centralized ML models, i.e., models which are trained on the whole data set.
Afterwards, we split the data set and assign the parts to (simulated) FL clients for the FL simulation.
This way, we have a basis for interpreting the performance of the model resulting from the FL training simulation.
The performance metrics of the trained ML models (including coefficient of determination <math id="S3.p1.1.m1.1" class="ltx_Math" alttext="\text{R}^{2}" display="inline"><semantics id="S3.p1.1.m1.1a"><msup id="S3.p1.1.m1.1.1" xref="S3.p1.1.m1.1.1.cmml"><mtext id="S3.p1.1.m1.1.1.2" xref="S3.p1.1.m1.1.1.2a.cmml">R</mtext><mn id="S3.p1.1.m1.1.1.3" xref="S3.p1.1.m1.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="S3.p1.1.m1.1b"><apply id="S3.p1.1.m1.1.1.cmml" xref="S3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.p1.1.m1.1.1.1.cmml" xref="S3.p1.1.m1.1.1">superscript</csymbol><ci id="S3.p1.1.m1.1.1.2a.cmml" xref="S3.p1.1.m1.1.1.2"><mtext id="S3.p1.1.m1.1.1.2.cmml" xref="S3.p1.1.m1.1.1.2">R</mtext></ci><cn type="integer" id="S3.p1.1.m1.1.1.3.cmml" xref="S3.p1.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.1.m1.1c">\text{R}^{2}</annotation></semantics></math> or accuracy) are computed on test sets of each data set.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Medical insurance data</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">The demand for timely and reliable information on public health is steadily increasing.
The COVID-19 pandemic has significantly accelerated this trend, raising questions about the financial feasibility of our healthcare system and the availability of medical supplies.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.1" class="ltx_p">Thus, our first experiment focuses on modeling a regression problem related to healthcare by considering the following question:
Given an individual’s health status characteristics, what is the magnitude of their insurance <em id="S3.SS1.p2.1.1" class="ltx_emph ltx_font_italic">charges</em>?
We aim to address two primary questions.
Firstly, we explore the suitability of neural networks in comparison to other models for the regression task.
Secondly, we assess the feasibility of utilizing a simulated decentralized data set in an FL setting to tackle the problem.</p>
</div>
<section id="S3.SS1.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Data set</h4>

<div id="S3.SS1.SSS0.Px1.p1" class="ltx_para">
<p id="S3.SS1.SSS0.Px1.p1.1" class="ltx_p">The given data set links medical insurance premium <em id="S3.SS1.SSS0.Px1.p1.1.1" class="ltx_emph ltx_font_italic">charges</em>
to related individual attributes<span id="footnote9" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">9</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">9</sup><span class="ltx_tag ltx_tag_note">9</span>US health insurance dataset <a target="_blank" href="https://www.kaggle.com/datasets/teertha/ushealthinsurancedataset" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.kaggle.com/datasets/teertha/ushealthinsurancedataset</a>, accessed on July 17, 2023</span></span></span>.
Considered are the six features <em id="S3.SS1.SSS0.Px1.p1.1.2" class="ltx_emph ltx_font_italic">age</em>, <em id="S3.SS1.SSS0.Px1.p1.1.3" class="ltx_emph ltx_font_italic">sex</em>, <em id="S3.SS1.SSS0.Px1.p1.1.4" class="ltx_emph ltx_font_italic">bmi</em> (body mass index), <em id="S3.SS1.SSS0.Px1.p1.1.5" class="ltx_emph ltx_font_italic">children</em> (count), <em id="S3.SS1.SSS0.Px1.p1.1.6" class="ltx_emph ltx_font_italic">smoker</em> (yes/no) and four <em id="S3.SS1.SSS0.Px1.p1.1.7" class="ltx_emph ltx_font_italic">regions</em>.
In our studies, the feature <em id="S3.SS1.SSS0.Px1.p1.1.8" class="ltx_emph ltx_font_italic">region</em> was excluded during FL training and solely utilized for partitioning the data within the FL setting.
In total, the data set consists of <math id="S3.SS1.SSS0.Px1.p1.1.m1.1" class="ltx_Math" alttext="1338" display="inline"><semantics id="S3.SS1.SSS0.Px1.p1.1.m1.1a"><mn id="S3.SS1.SSS0.Px1.p1.1.m1.1.1" xref="S3.SS1.SSS0.Px1.p1.1.m1.1.1.cmml">1338</mn><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px1.p1.1.m1.1b"><cn type="integer" id="S3.SS1.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.1.m1.1.1">1338</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px1.p1.1.m1.1c">1338</annotation></semantics></math> complete records, i.e. there are no missing or undefined values.
Also, the data set is highly balanced: The values in <em id="S3.SS1.SSS0.Px1.p1.1.9" class="ltx_emph ltx_font_italic">age</em> are evenly dispersed, just as the distribution of male and female records is about 50/50 (attribute <em id="S3.SS1.SSS0.Px1.p1.1.10" class="ltx_emph ltx_font_italic">gender</em>) and each <em id="S3.SS1.SSS0.Px1.p1.1.11" class="ltx_emph ltx_font_italic">region</em> is represented nearly equally often.
The origin of the data is unknown, however its homogeneity and integrity suggest that it has been created artificially.</p>
</div>
</section>
<section id="S3.SS1.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Data preprocessing</h4>

<div id="S3.SS1.SSS0.Px2.p1" class="ltx_para">
<p id="S3.SS1.SSS0.Px2.p1.1" class="ltx_p">We encode the binary attributes <em id="S3.SS1.SSS0.Px2.p1.1.1" class="ltx_emph ltx_font_italic">sex</em> and <em id="S3.SS1.SSS0.Px2.p1.1.2" class="ltx_emph ltx_font_italic">smoker</em> into a numeric form (0 or 1).
The attributes <em id="S3.SS1.SSS0.Px2.p1.1.3" class="ltx_emph ltx_font_italic">age</em>, <em id="S3.SS1.SSS0.Px2.p1.1.4" class="ltx_emph ltx_font_italic">bmi</em> and <em id="S3.SS1.SSS0.Px2.p1.1.5" class="ltx_emph ltx_font_italic">children</em> are scaled to a range from 0 to 1.
In the centralized benchmarks, the attribute <em id="S3.SS1.SSS0.Px2.p1.1.6" class="ltx_emph ltx_font_italic">region</em> is one-hot-encoded.</p>
</div>
</section>
<section id="S3.SS1.SSS0.Px3" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Setup</h4>

<div id="S3.SS1.SSS0.Px3.p1" class="ltx_para">
<p id="S3.SS1.SSS0.Px3.p1.1" class="ltx_p">We aim to investigate the suitability of neural networks for estimating insurance <em id="S3.SS1.SSS0.Px3.p1.1.1" class="ltx_emph ltx_font_italic">charges</em> and explore the extent to which this problem can be addressed using a FL approach. To achieve this, we compare different models and evaluate their performance.</p>
</div>
<div id="S3.SS1.SSS0.Px3.p2" class="ltx_para">
<p id="S3.SS1.SSS0.Px3.p2.1" class="ltx_p">A basic fully connected neural network architecture, that takes five input features, is utilized. The network consists of three hidden layers with 40, 40, and 20 units in each respective layer.
Following each layer, a Rectified Linear Unit (ReLU) activation function is applied.
The final output layer comprises a single neuron.
To optimize the network, the Adam optimizer with a learning rate of 0.05 is employed.
In the federated setting, we utilize the same initial model but integrate FedAdam for server updates.
This decision is based on previous research <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx13" title="" class="ltx_ref">Red+20</a>]</cite>, which emphasizes the benefits of adaptive server optimization techniques for achieving improved convergence.</p>
</div>
<div id="S3.SS1.SSS0.Px3.p3" class="ltx_para">
<p id="S3.SS1.SSS0.Px3.p3.2" class="ltx_p">In the centralized approach, we allocate a training budget of 100 epochs.
In contrast, the federated approach incorporates 50 rounds of communication between the client and server during training.
Each round involves clients individually training the model for 50 epochs.
To track the running training, <math id="S3.SS1.SSS0.Px3.p3.1.m1.1" class="ltx_Math" alttext="10\%" display="inline"><semantics id="S3.SS1.SSS0.Px3.p3.1.m1.1a"><mrow id="S3.SS1.SSS0.Px3.p3.1.m1.1.1" xref="S3.SS1.SSS0.Px3.p3.1.m1.1.1.cmml"><mn id="S3.SS1.SSS0.Px3.p3.1.m1.1.1.2" xref="S3.SS1.SSS0.Px3.p3.1.m1.1.1.2.cmml">10</mn><mo id="S3.SS1.SSS0.Px3.p3.1.m1.1.1.1" xref="S3.SS1.SSS0.Px3.p3.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px3.p3.1.m1.1b"><apply id="S3.SS1.SSS0.Px3.p3.1.m1.1.1.cmml" xref="S3.SS1.SSS0.Px3.p3.1.m1.1.1"><csymbol cd="latexml" id="S3.SS1.SSS0.Px3.p3.1.m1.1.1.1.cmml" xref="S3.SS1.SSS0.Px3.p3.1.m1.1.1.1">percent</csymbol><cn type="integer" id="S3.SS1.SSS0.Px3.p3.1.m1.1.1.2.cmml" xref="S3.SS1.SSS0.Px3.p3.1.m1.1.1.2">10</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px3.p3.1.m1.1c">10\%</annotation></semantics></math> evaluation data is used by each client in the FL setting and <math id="S3.SS1.SSS0.Px3.p3.2.m2.1" class="ltx_Math" alttext="20\%" display="inline"><semantics id="S3.SS1.SSS0.Px3.p3.2.m2.1a"><mrow id="S3.SS1.SSS0.Px3.p3.2.m2.1.1" xref="S3.SS1.SSS0.Px3.p3.2.m2.1.1.cmml"><mn id="S3.SS1.SSS0.Px3.p3.2.m2.1.1.2" xref="S3.SS1.SSS0.Px3.p3.2.m2.1.1.2.cmml">20</mn><mo id="S3.SS1.SSS0.Px3.p3.2.m2.1.1.1" xref="S3.SS1.SSS0.Px3.p3.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px3.p3.2.m2.1b"><apply id="S3.SS1.SSS0.Px3.p3.2.m2.1.1.cmml" xref="S3.SS1.SSS0.Px3.p3.2.m2.1.1"><csymbol cd="latexml" id="S3.SS1.SSS0.Px3.p3.2.m2.1.1.1.cmml" xref="S3.SS1.SSS0.Px3.p3.2.m2.1.1.1">percent</csymbol><cn type="integer" id="S3.SS1.SSS0.Px3.p3.2.m2.1.1.2.cmml" xref="S3.SS1.SSS0.Px3.p3.2.m2.1.1.2">20</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px3.p3.2.m2.1c">20\%</annotation></semantics></math> is used in the centralized scenario.
It is neglected in calculating the final test performance.
The remaining shallow learning models undergo hyperparameter optimization using a random search approach with a budget of 100 iterations.
We evaluate all models using 5-fold cross validation.</p>
</div>
<figure id="S3.T1" class="ltx_table">
<table id="S3.T1.12" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S3.T1.2.2" class="ltx_tr">
<th id="S3.T1.2.2.3" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt" style="padding:2.5pt 4.3pt;"><span id="S3.T1.2.2.3.1" class="ltx_text ltx_font_bold">Model</span></th>
<td id="S3.T1.2.2.2" class="ltx_td ltx_align_center ltx_border_tt" style="padding:2.5pt 4.3pt;"><span id="S3.T1.2.2.2.2" class="ltx_text"><math id="S3.T1.1.1.1.1.m1.1" class="ltx_Math" alttext="\text{R}^{2}" display="inline"><semantics id="S3.T1.1.1.1.1.m1.1a"><msup id="S3.T1.1.1.1.1.m1.1.1" xref="S3.T1.1.1.1.1.m1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S3.T1.1.1.1.1.m1.1.1.2" xref="S3.T1.1.1.1.1.m1.1.1.2a.cmml">R</mtext><mn id="S3.T1.1.1.1.1.m1.1.1.3" xref="S3.T1.1.1.1.1.m1.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="S3.T1.1.1.1.1.m1.1b"><apply id="S3.T1.1.1.1.1.m1.1.1.cmml" xref="S3.T1.1.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.T1.1.1.1.1.m1.1.1.1.cmml" xref="S3.T1.1.1.1.1.m1.1.1">superscript</csymbol><ci id="S3.T1.1.1.1.1.m1.1.1.2a.cmml" xref="S3.T1.1.1.1.1.m1.1.1.2"><mtext class="ltx_mathvariant_bold" id="S3.T1.1.1.1.1.m1.1.1.2.cmml" xref="S3.T1.1.1.1.1.m1.1.1.2">R</mtext></ci><cn type="integer" id="S3.T1.1.1.1.1.m1.1.1.3.cmml" xref="S3.T1.1.1.1.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.1.1.1.1.m1.1c">\text{R}^{2}</annotation></semantics></math><span id="S3.T1.2.2.2.2.1" class="ltx_text ltx_font_bold ltx_align_center">(<math id="S3.T1.2.2.2.2.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.T1.2.2.2.2.1.m1.1a"><mo id="S3.T1.2.2.2.2.1.m1.1.1" xref="S3.T1.2.2.2.2.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S3.T1.2.2.2.2.1.m1.1b"><csymbol cd="latexml" id="S3.T1.2.2.2.2.1.m1.1.1.cmml" xref="S3.T1.2.2.2.2.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.2.2.2.2.1.m1.1c">\pm</annotation></semantics></math> std)</span></span></td>
<td id="S3.T1.2.2.4" class="ltx_td ltx_align_center ltx_border_tt" style="padding:2.5pt 4.3pt;"><span id="S3.T1.2.2.4.1" class="ltx_text ltx_font_bold">Rel. loss (%)</span></td>
</tr>
<tr id="S3.T1.3.3" class="ltx_tr">
<th id="S3.T1.3.3.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" style="padding:2.5pt 4.3pt;">neural network</th>
<td id="S3.T1.3.3.1" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 4.3pt;"><math id="S3.T1.3.3.1.m1.1" class="ltx_Math" alttext="81.5(4.01)" display="inline"><semantics id="S3.T1.3.3.1.m1.1a"><mrow id="S3.T1.3.3.1.m1.1.2" xref="S3.T1.3.3.1.m1.1.2.cmml"><mn id="S3.T1.3.3.1.m1.1.2.2" xref="S3.T1.3.3.1.m1.1.2.2.cmml">81.5</mn><mo lspace="0em" rspace="0em" id="S3.T1.3.3.1.m1.1.2.1" xref="S3.T1.3.3.1.m1.1.2.1.cmml">​</mo><mrow id="S3.T1.3.3.1.m1.1.2.3.2" xref="S3.T1.3.3.1.m1.1.2.cmml"><mo stretchy="false" id="S3.T1.3.3.1.m1.1.2.3.2.1" xref="S3.T1.3.3.1.m1.1.2.cmml">(</mo><mn id="S3.T1.3.3.1.m1.1.1" xref="S3.T1.3.3.1.m1.1.1.cmml">4.01</mn><mo stretchy="false" id="S3.T1.3.3.1.m1.1.2.3.2.2" xref="S3.T1.3.3.1.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.T1.3.3.1.m1.1b"><apply id="S3.T1.3.3.1.m1.1.2.cmml" xref="S3.T1.3.3.1.m1.1.2"><times id="S3.T1.3.3.1.m1.1.2.1.cmml" xref="S3.T1.3.3.1.m1.1.2.1"></times><cn type="float" id="S3.T1.3.3.1.m1.1.2.2.cmml" xref="S3.T1.3.3.1.m1.1.2.2">81.5</cn><cn type="float" id="S3.T1.3.3.1.m1.1.1.cmml" xref="S3.T1.3.3.1.m1.1.1">4.01</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.3.3.1.m1.1c">81.5(4.01)</annotation></semantics></math></td>
<td id="S3.T1.3.3.3" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 4.3pt;">3.5</td>
</tr>
<tr id="S3.T1.4.4" class="ltx_tr">
<th id="S3.T1.4.4.2" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding:2.5pt 4.3pt;">neural network (federated)</th>
<td id="S3.T1.4.4.1" class="ltx_td ltx_align_center" style="padding:2.5pt 4.3pt;"><math id="S3.T1.4.4.1.m1.1" class="ltx_Math" alttext="78.4(3.13)" display="inline"><semantics id="S3.T1.4.4.1.m1.1a"><mrow id="S3.T1.4.4.1.m1.1.2" xref="S3.T1.4.4.1.m1.1.2.cmml"><mn id="S3.T1.4.4.1.m1.1.2.2" xref="S3.T1.4.4.1.m1.1.2.2.cmml">78.4</mn><mo lspace="0em" rspace="0em" id="S3.T1.4.4.1.m1.1.2.1" xref="S3.T1.4.4.1.m1.1.2.1.cmml">​</mo><mrow id="S3.T1.4.4.1.m1.1.2.3.2" xref="S3.T1.4.4.1.m1.1.2.cmml"><mo stretchy="false" id="S3.T1.4.4.1.m1.1.2.3.2.1" xref="S3.T1.4.4.1.m1.1.2.cmml">(</mo><mn id="S3.T1.4.4.1.m1.1.1" xref="S3.T1.4.4.1.m1.1.1.cmml">3.13</mn><mo stretchy="false" id="S3.T1.4.4.1.m1.1.2.3.2.2" xref="S3.T1.4.4.1.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.T1.4.4.1.m1.1b"><apply id="S3.T1.4.4.1.m1.1.2.cmml" xref="S3.T1.4.4.1.m1.1.2"><times id="S3.T1.4.4.1.m1.1.2.1.cmml" xref="S3.T1.4.4.1.m1.1.2.1"></times><cn type="float" id="S3.T1.4.4.1.m1.1.2.2.cmml" xref="S3.T1.4.4.1.m1.1.2.2">78.4</cn><cn type="float" id="S3.T1.4.4.1.m1.1.1.cmml" xref="S3.T1.4.4.1.m1.1.1">3.13</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.4.4.1.m1.1c">78.4(3.13)</annotation></semantics></math></td>
<td id="S3.T1.4.4.3" class="ltx_td ltx_align_center" style="padding:2.5pt 4.3pt;">7.2</td>
</tr>
<tr id="S3.T1.5.5" class="ltx_tr">
<th id="S3.T1.5.5.2" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding:2.5pt 4.3pt;">random forest</th>
<td id="S3.T1.5.5.1" class="ltx_td ltx_align_center" style="padding:2.5pt 4.3pt;"><math id="S3.T1.5.5.1.m1.1" class="ltx_Math" alttext="84.5(4.73)" display="inline"><semantics id="S3.T1.5.5.1.m1.1a"><mrow id="S3.T1.5.5.1.m1.1.2" xref="S3.T1.5.5.1.m1.1.2.cmml"><mn id="S3.T1.5.5.1.m1.1.2.2" xref="S3.T1.5.5.1.m1.1.2.2.cmml">84.5</mn><mo lspace="0em" rspace="0em" id="S3.T1.5.5.1.m1.1.2.1" xref="S3.T1.5.5.1.m1.1.2.1.cmml">​</mo><mrow id="S3.T1.5.5.1.m1.1.2.3.2" xref="S3.T1.5.5.1.m1.1.2.cmml"><mo stretchy="false" id="S3.T1.5.5.1.m1.1.2.3.2.1" xref="S3.T1.5.5.1.m1.1.2.cmml">(</mo><mn id="S3.T1.5.5.1.m1.1.1" xref="S3.T1.5.5.1.m1.1.1.cmml">4.73</mn><mo stretchy="false" id="S3.T1.5.5.1.m1.1.2.3.2.2" xref="S3.T1.5.5.1.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.T1.5.5.1.m1.1b"><apply id="S3.T1.5.5.1.m1.1.2.cmml" xref="S3.T1.5.5.1.m1.1.2"><times id="S3.T1.5.5.1.m1.1.2.1.cmml" xref="S3.T1.5.5.1.m1.1.2.1"></times><cn type="float" id="S3.T1.5.5.1.m1.1.2.2.cmml" xref="S3.T1.5.5.1.m1.1.2.2">84.5</cn><cn type="float" id="S3.T1.5.5.1.m1.1.1.cmml" xref="S3.T1.5.5.1.m1.1.1">4.73</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.5.5.1.m1.1c">84.5(4.73)</annotation></semantics></math></td>
<td id="S3.T1.5.5.3" class="ltx_td ltx_align_center" style="padding:2.5pt 4.3pt;">0.0</td>
</tr>
<tr id="S3.T1.6.6" class="ltx_tr">
<th id="S3.T1.6.6.2" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding:2.5pt 4.3pt;">XGBoost</th>
<td id="S3.T1.6.6.3" class="ltx_td ltx_align_center" style="padding:2.5pt 4.3pt;">84.3 (3.96)</td>
<td id="S3.T1.6.6.1" class="ltx_td ltx_align_center" style="padding:2.5pt 4.3pt;"><math id="S3.T1.6.6.1.m1.1" class="ltx_Math" alttext="0.2" display="inline"><semantics id="S3.T1.6.6.1.m1.1a"><mn id="S3.T1.6.6.1.m1.1.1" xref="S3.T1.6.6.1.m1.1.1.cmml">0.2</mn><annotation-xml encoding="MathML-Content" id="S3.T1.6.6.1.m1.1b"><cn type="float" id="S3.T1.6.6.1.m1.1.1.cmml" xref="S3.T1.6.6.1.m1.1.1">0.2</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.6.6.1.m1.1c">0.2</annotation></semantics></math></td>
</tr>
<tr id="S3.T1.8.8" class="ltx_tr">
<th id="S3.T1.8.8.3" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding:2.5pt 4.3pt;">decision tree</th>
<td id="S3.T1.7.7.1" class="ltx_td ltx_align_center" style="padding:2.5pt 4.3pt;">
<math id="S3.T1.7.7.1.m1.1" class="ltx_Math" alttext="84.1" display="inline"><semantics id="S3.T1.7.7.1.m1.1a"><mn id="S3.T1.7.7.1.m1.1.1" xref="S3.T1.7.7.1.m1.1.1.cmml">84.1</mn><annotation-xml encoding="MathML-Content" id="S3.T1.7.7.1.m1.1b"><cn type="float" id="S3.T1.7.7.1.m1.1.1.cmml" xref="S3.T1.7.7.1.m1.1.1">84.1</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.7.7.1.m1.1c">84.1</annotation></semantics></math> (4.23)</td>
<td id="S3.T1.8.8.2" class="ltx_td ltx_align_center" style="padding:2.5pt 4.3pt;"><math id="S3.T1.8.8.2.m1.1" class="ltx_Math" alttext="0.5" display="inline"><semantics id="S3.T1.8.8.2.m1.1a"><mn id="S3.T1.8.8.2.m1.1.1" xref="S3.T1.8.8.2.m1.1.1.cmml">0.5</mn><annotation-xml encoding="MathML-Content" id="S3.T1.8.8.2.m1.1b"><cn type="float" id="S3.T1.8.8.2.m1.1.1.cmml" xref="S3.T1.8.8.2.m1.1.1">0.5</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.8.8.2.m1.1c">0.5</annotation></semantics></math></td>
</tr>
<tr id="S3.T1.10.10" class="ltx_tr">
<th id="S3.T1.10.10.3" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding:2.5pt 4.3pt;">k-nearest neighbors</th>
<td id="S3.T1.9.9.1" class="ltx_td ltx_align_center" style="padding:2.5pt 4.3pt;">
<math id="S3.T1.9.9.1.m1.1" class="ltx_Math" alttext="74.4" display="inline"><semantics id="S3.T1.9.9.1.m1.1a"><mn id="S3.T1.9.9.1.m1.1.1" xref="S3.T1.9.9.1.m1.1.1.cmml">74.4</mn><annotation-xml encoding="MathML-Content" id="S3.T1.9.9.1.m1.1b"><cn type="float" id="S3.T1.9.9.1.m1.1.1.cmml" xref="S3.T1.9.9.1.m1.1.1">74.4</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.9.9.1.m1.1c">74.4</annotation></semantics></math> (5.53)</td>
<td id="S3.T1.10.10.2" class="ltx_td ltx_align_center" style="padding:2.5pt 4.3pt;"><math id="S3.T1.10.10.2.m1.1" class="ltx_Math" alttext="12.0" display="inline"><semantics id="S3.T1.10.10.2.m1.1a"><mn id="S3.T1.10.10.2.m1.1.1" xref="S3.T1.10.10.2.m1.1.1.cmml">12.0</mn><annotation-xml encoding="MathML-Content" id="S3.T1.10.10.2.m1.1b"><cn type="float" id="S3.T1.10.10.2.m1.1.1.cmml" xref="S3.T1.10.10.2.m1.1.1">12.0</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.10.10.2.m1.1c">12.0</annotation></semantics></math></td>
</tr>
<tr id="S3.T1.12.12" class="ltx_tr">
<th id="S3.T1.12.12.3" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" style="padding:2.5pt 4.3pt;">linear regression</th>
<td id="S3.T1.11.11.1" class="ltx_td ltx_align_center ltx_border_bb" style="padding:2.5pt 4.3pt;">
<math id="S3.T1.11.11.1.m1.1" class="ltx_Math" alttext="72.8" display="inline"><semantics id="S3.T1.11.11.1.m1.1a"><mn id="S3.T1.11.11.1.m1.1.1" xref="S3.T1.11.11.1.m1.1.1.cmml">72.8</mn><annotation-xml encoding="MathML-Content" id="S3.T1.11.11.1.m1.1b"><cn type="float" id="S3.T1.11.11.1.m1.1.1.cmml" xref="S3.T1.11.11.1.m1.1.1">72.8</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.11.11.1.m1.1c">72.8</annotation></semantics></math> (6.07)</td>
<td id="S3.T1.12.12.2" class="ltx_td ltx_align_center ltx_border_bb" style="padding:2.5pt 4.3pt;"><math id="S3.T1.12.12.2.m1.1" class="ltx_Math" alttext="13.8" display="inline"><semantics id="S3.T1.12.12.2.m1.1a"><mn id="S3.T1.12.12.2.m1.1.1" xref="S3.T1.12.12.2.m1.1.1.cmml">13.8</mn><annotation-xml encoding="MathML-Content" id="S3.T1.12.12.2.m1.1b"><cn type="float" id="S3.T1.12.12.2.m1.1.1.cmml" xref="S3.T1.12.12.2.m1.1.1">13.8</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.12.12.2.m1.1c">13.8</annotation></semantics></math></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 1: </span>Performance comparison of different prediction models for the medical insurance use case.
The performance is quantified using <math id="S3.T1.13.m1.1" class="ltx_Math" alttext="\text{R}^{2}" display="inline"><semantics id="S3.T1.13.m1.1b"><msup id="S3.T1.13.m1.1.1" xref="S3.T1.13.m1.1.1.cmml"><mtext id="S3.T1.13.m1.1.1.2" xref="S3.T1.13.m1.1.1.2a.cmml">R</mtext><mn id="S3.T1.13.m1.1.1.3" xref="S3.T1.13.m1.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="S3.T1.13.m1.1c"><apply id="S3.T1.13.m1.1.1.cmml" xref="S3.T1.13.m1.1.1"><csymbol cd="ambiguous" id="S3.T1.13.m1.1.1.1.cmml" xref="S3.T1.13.m1.1.1">superscript</csymbol><ci id="S3.T1.13.m1.1.1.2a.cmml" xref="S3.T1.13.m1.1.1.2"><mtext id="S3.T1.13.m1.1.1.2.cmml" xref="S3.T1.13.m1.1.1.2">R</mtext></ci><cn type="integer" id="S3.T1.13.m1.1.1.3.cmml" xref="S3.T1.13.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.13.m1.1d">\text{R}^{2}</annotation></semantics></math> in %, along with the corresponding standard deviation (std).
Additionally, the relative loss to the best centralized model (rel. loss) is reported.</figcaption>
</figure>
</section>
<section id="S3.SS1.SSS0.Px4" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Results</h4>

<div id="S3.SS1.SSS0.Px4.p1" class="ltx_para">
<p id="S3.SS1.SSS0.Px4.p1.2" class="ltx_p">We conduct a performance comparison of the models based on their 5-fold cross-validation <math id="S3.SS1.SSS0.Px4.p1.1.m1.1" class="ltx_Math" alttext="\text{R}^{2}" display="inline"><semantics id="S3.SS1.SSS0.Px4.p1.1.m1.1a"><msup id="S3.SS1.SSS0.Px4.p1.1.m1.1.1" xref="S3.SS1.SSS0.Px4.p1.1.m1.1.1.cmml"><mtext id="S3.SS1.SSS0.Px4.p1.1.m1.1.1.2" xref="S3.SS1.SSS0.Px4.p1.1.m1.1.1.2a.cmml">R</mtext><mn id="S3.SS1.SSS0.Px4.p1.1.m1.1.1.3" xref="S3.SS1.SSS0.Px4.p1.1.m1.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px4.p1.1.m1.1b"><apply id="S3.SS1.SSS0.Px4.p1.1.m1.1.1.cmml" xref="S3.SS1.SSS0.Px4.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px4.p1.1.m1.1.1.1.cmml" xref="S3.SS1.SSS0.Px4.p1.1.m1.1.1">superscript</csymbol><ci id="S3.SS1.SSS0.Px4.p1.1.m1.1.1.2a.cmml" xref="S3.SS1.SSS0.Px4.p1.1.m1.1.1.2"><mtext id="S3.SS1.SSS0.Px4.p1.1.m1.1.1.2.cmml" xref="S3.SS1.SSS0.Px4.p1.1.m1.1.1.2">R</mtext></ci><cn type="integer" id="S3.SS1.SSS0.Px4.p1.1.m1.1.1.3.cmml" xref="S3.SS1.SSS0.Px4.p1.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px4.p1.1.m1.1c">\text{R}^{2}</annotation></semantics></math> scores and consider their standard deviation (see <a href="#S3.T1" title="Table 1 ‣ Setup ‣ 3.1 Medical insurance data ‣ 3 Simulations ‣ The Applicability of Federated Learning to Official Statistics" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Table 1</span></a>).
The random forest model achieves the highest performance with an <math id="S3.SS1.SSS0.Px4.p1.2.m2.1" class="ltx_Math" alttext="\text{R}^{2}" display="inline"><semantics id="S3.SS1.SSS0.Px4.p1.2.m2.1a"><msup id="S3.SS1.SSS0.Px4.p1.2.m2.1.1" xref="S3.SS1.SSS0.Px4.p1.2.m2.1.1.cmml"><mtext id="S3.SS1.SSS0.Px4.p1.2.m2.1.1.2" xref="S3.SS1.SSS0.Px4.p1.2.m2.1.1.2a.cmml">R</mtext><mn id="S3.SS1.SSS0.Px4.p1.2.m2.1.1.3" xref="S3.SS1.SSS0.Px4.p1.2.m2.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px4.p1.2.m2.1b"><apply id="S3.SS1.SSS0.Px4.p1.2.m2.1.1.cmml" xref="S3.SS1.SSS0.Px4.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px4.p1.2.m2.1.1.1.cmml" xref="S3.SS1.SSS0.Px4.p1.2.m2.1.1">superscript</csymbol><ci id="S3.SS1.SSS0.Px4.p1.2.m2.1.1.2a.cmml" xref="S3.SS1.SSS0.Px4.p1.2.m2.1.1.2"><mtext id="S3.SS1.SSS0.Px4.p1.2.m2.1.1.2.cmml" xref="S3.SS1.SSS0.Px4.p1.2.m2.1.1.2">R</mtext></ci><cn type="integer" id="S3.SS1.SSS0.Px4.p1.2.m2.1.1.3.cmml" xref="S3.SS1.SSS0.Px4.p1.2.m2.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px4.p1.2.m2.1c">\text{R}^{2}</annotation></semantics></math> of 84.5 %, closely followed by XGBoost and Decision Tree, which scores 0.2 and 0.5 percentage points lower, respectively.</p>
</div>
<div id="S3.SS1.SSS0.Px4.p2" class="ltx_para">
<p id="S3.SS1.SSS0.Px4.p2.2" class="ltx_p">The neural network model achieves an <math id="S3.SS1.SSS0.Px4.p2.1.m1.1" class="ltx_Math" alttext="\text{R}^{2}" display="inline"><semantics id="S3.SS1.SSS0.Px4.p2.1.m1.1a"><msup id="S3.SS1.SSS0.Px4.p2.1.m1.1.1" xref="S3.SS1.SSS0.Px4.p2.1.m1.1.1.cmml"><mtext id="S3.SS1.SSS0.Px4.p2.1.m1.1.1.2" xref="S3.SS1.SSS0.Px4.p2.1.m1.1.1.2a.cmml">R</mtext><mn id="S3.SS1.SSS0.Px4.p2.1.m1.1.1.3" xref="S3.SS1.SSS0.Px4.p2.1.m1.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px4.p2.1.m1.1b"><apply id="S3.SS1.SSS0.Px4.p2.1.m1.1.1.cmml" xref="S3.SS1.SSS0.Px4.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px4.p2.1.m1.1.1.1.cmml" xref="S3.SS1.SSS0.Px4.p2.1.m1.1.1">superscript</csymbol><ci id="S3.SS1.SSS0.Px4.p2.1.m1.1.1.2a.cmml" xref="S3.SS1.SSS0.Px4.p2.1.m1.1.1.2"><mtext id="S3.SS1.SSS0.Px4.p2.1.m1.1.1.2.cmml" xref="S3.SS1.SSS0.Px4.p2.1.m1.1.1.2">R</mtext></ci><cn type="integer" id="S3.SS1.SSS0.Px4.p2.1.m1.1.1.3.cmml" xref="S3.SS1.SSS0.Px4.p2.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px4.p2.1.m1.1c">\text{R}^{2}</annotation></semantics></math> of 81.5 %, indicating a performance 3.5 % worse than the best model.
However, it still provides a reasonable result compared to K-Nearest Neighbors (KNN) and Linear Regression, which obtain significantly lower <math id="S3.SS1.SSS0.Px4.p2.2.m2.1" class="ltx_Math" alttext="\text{R}^{2}" display="inline"><semantics id="S3.SS1.SSS0.Px4.p2.2.m2.1a"><msup id="S3.SS1.SSS0.Px4.p2.2.m2.1.1" xref="S3.SS1.SSS0.Px4.p2.2.m2.1.1.cmml"><mtext id="S3.SS1.SSS0.Px4.p2.2.m2.1.1.2" xref="S3.SS1.SSS0.Px4.p2.2.m2.1.1.2a.cmml">R</mtext><mn id="S3.SS1.SSS0.Px4.p2.2.m2.1.1.3" xref="S3.SS1.SSS0.Px4.p2.2.m2.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px4.p2.2.m2.1b"><apply id="S3.SS1.SSS0.Px4.p2.2.m2.1.1.cmml" xref="S3.SS1.SSS0.Px4.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px4.p2.2.m2.1.1.1.cmml" xref="S3.SS1.SSS0.Px4.p2.2.m2.1.1">superscript</csymbol><ci id="S3.SS1.SSS0.Px4.p2.2.m2.1.1.2a.cmml" xref="S3.SS1.SSS0.Px4.p2.2.m2.1.1.2"><mtext id="S3.SS1.SSS0.Px4.p2.2.m2.1.1.2.cmml" xref="S3.SS1.SSS0.Px4.p2.2.m2.1.1.2">R</mtext></ci><cn type="integer" id="S3.SS1.SSS0.Px4.p2.2.m2.1.1.3.cmml" xref="S3.SS1.SSS0.Px4.p2.2.m2.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px4.p2.2.m2.1c">\text{R}^{2}</annotation></semantics></math> scores of 12 % and 13.8 %, respectively.</p>
</div>
<div id="S3.SS1.SSS0.Px4.p3" class="ltx_para">
<p id="S3.SS1.SSS0.Px4.p3.1" class="ltx_p">The Federated neural network demonstrates an <math id="S3.SS1.SSS0.Px4.p3.1.m1.1" class="ltx_Math" alttext="\text{R}^{2}" display="inline"><semantics id="S3.SS1.SSS0.Px4.p3.1.m1.1a"><msup id="S3.SS1.SSS0.Px4.p3.1.m1.1.1" xref="S3.SS1.SSS0.Px4.p3.1.m1.1.1.cmml"><mtext id="S3.SS1.SSS0.Px4.p3.1.m1.1.1.2" xref="S3.SS1.SSS0.Px4.p3.1.m1.1.1.2a.cmml">R</mtext><mn id="S3.SS1.SSS0.Px4.p3.1.m1.1.1.3" xref="S3.SS1.SSS0.Px4.p3.1.m1.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px4.p3.1.m1.1b"><apply id="S3.SS1.SSS0.Px4.p3.1.m1.1.1.cmml" xref="S3.SS1.SSS0.Px4.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px4.p3.1.m1.1.1.1.cmml" xref="S3.SS1.SSS0.Px4.p3.1.m1.1.1">superscript</csymbol><ci id="S3.SS1.SSS0.Px4.p3.1.m1.1.1.2a.cmml" xref="S3.SS1.SSS0.Px4.p3.1.m1.1.1.2"><mtext id="S3.SS1.SSS0.Px4.p3.1.m1.1.1.2.cmml" xref="S3.SS1.SSS0.Px4.p3.1.m1.1.1.2">R</mtext></ci><cn type="integer" id="S3.SS1.SSS0.Px4.p3.1.m1.1.1.3.cmml" xref="S3.SS1.SSS0.Px4.p3.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px4.p3.1.m1.1c">\text{R}^{2}</annotation></semantics></math> of 78.4 %, slightly lower than the centralized neural network but 7.2 % worse than the random forest model.
Notably, the Federated neural network exhibits a lower standard deviation of 3.99 compared to the centralized neural network (4.92) and also outperforms the random forest model (4.73) in this regard.</p>
</div>
</section>
<section id="S3.SS1.SSS0.Px5" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Discussion</h4>

<div id="S3.SS1.SSS0.Px5.p1" class="ltx_para">
<p id="S3.SS1.SSS0.Px5.p1.1" class="ltx_p">Based on the research questions, we can draw clear conclusions from the findings presented in <a href="#S3.T1" title="Table 1 ‣ Setup ‣ 3.1 Medical insurance data ‣ 3 Simulations ‣ The Applicability of Federated Learning to Official Statistics" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Table 1</span></a>.
Initially, we compared the performance of different models, including a simple neural network. Although the random forest model outperformed others, its performance was only 3.5 % higher, distinguishing it significantly from models such as KNN and linear regression, which performed 12 % and 13.8 % worse than the random forest, respectively.</p>
</div>
<div id="S3.SS1.SSS0.Px5.p2" class="ltx_para">
<p id="S3.SS1.SSS0.Px5.p2.1" class="ltx_p">The observed performance decrease from 81.5 % to 78.4 % in the FL approach can be attributed to the training process and falls within a reasonable range.
Considering the privacy advantages of FL, the 7.2 % accuracy loss compared to the best model is acceptable, particularly when taking into account the reduction in standard deviation from 4.92 to 3.99.</p>
</div>
<div id="S3.SS1.SSS0.Px5.p3" class="ltx_para">
<p id="S3.SS1.SSS0.Px5.p3.1" class="ltx_p">Although this example is hypothetical, it highlights the potential benefits and importance of FL in official statistics. It showcases how FL provides access to crucial data sets for ML while maintaining nearly negligible loss in accuracy compared to a centralized data set.</p>
</div>
</section>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Fine dust pollution</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.2" class="ltx_p">Reducing air pollution is a significant part of the Sustainable Development Goals (SDGs) established by the United Nations<span id="footnote10" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">10</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">10</sup><span class="ltx_tag ltx_tag_note">10</span>Air quality and health <a target="_blank" href="https://www.who.int/teams/environment-climate-change-and-health/air-quality-and-health/policy-progress/sustainable-development-goals-air-pollution" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.who.int/teams/environment-climate-change-and-health/air-quality-and-health/policy-progress/sustainable-development-goals-air-pollution</a>, accessed on July 17, 2023</span></span></span>. To measure progress toward achieving SDGs, NGOs and other data producing organizations developed a set of 231 internationally comparable indicators, including <em id="S3.SS2.p1.2.2" class="ltx_emph ltx_font_italic">annual mean levels of fine particulate matter (e.g. PM<sub id="S3.SS2.p1.2.2.1" class="ltx_sub">2.5</sub> and PM<sub id="S3.SS2.p1.2.2.2" class="ltx_sub">10</sub>)</em>.
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx7" title="" class="ltx_ref">Hu+18</a>]</cite> showed that personalized FL can be used to extract timely high frequent information on air pollution more accurately than models using centralized data.</p>
</div>
<figure id="S3.F1" class="ltx_figure"><img src="/html/2307.15503/assets/pic/pm-beijing.png" id="S3.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="299" height="224" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Location of meteorological stations for the fine dust pollution simulation on a map of Beijing, China.
12 of the 13 stations are included in the public data set which we have used for our simulations.
The dashed lines mark <em id="S3.F1.3.1" class="ltx_emph ltx_font_italic">regions</em> of the <span id="S3.F1.4.2" class="ltx_text ltx_inline-quote ltx_outerquote">“Region-Learning”</span> approach in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx7" title="" class="ltx_ref">Hu+18</a>]</cite>.
Image source: <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx7" title="" class="ltx_ref">Hu+18</a>]</cite>.</figcaption>
</figure>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.3" class="ltx_p">In our second use case, we provide a comparison between centralized and FL models (without personalization) and make the developed code and methods accessible.
It should be noted that we utilize a slightly different data set and methodology compared to <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx7" title="" class="ltx_ref">Hu+18</a>]</cite>, which we explain at the end of this section.
We model a classification task in which the current fine dust pollution is inferred based on meteorological input data.
More precisely, 48 consecutive hourly measurements are used to make a prediction for the current PM<sub id="S3.SS2.p2.3.1" class="ltx_sub"><span id="S3.SS2.p2.3.1.1" class="ltx_text ltx_font_italic">2.5</span></sub> pollution (the total weight of particles smaller than <math id="S3.SS2.p2.2.m2.3" class="ltx_Math" alttext="2.5\text{\,}\mathrm{\SIUnitSymbolMicro m}" display="inline"><semantics id="S3.SS2.p2.2.m2.3a"><mrow id="S3.SS2.p2.2.m2.3.3" xref="S3.SS2.p2.2.m2.3.3.cmml"><mn id="S3.SS2.p2.2.m2.1.1.1.1.1.1" xref="S3.SS2.p2.2.m2.1.1.1.1.1.1.cmml">2.5</mn><mtext id="S3.SS2.p2.2.m2.2.2.2.2.2.2" xref="S3.SS2.p2.2.m2.2.2.2.2.2.2.cmml"> </mtext><mrow class="ltx_unit" id="S3.SS2.p2.2.m2.3.3.3.3.3.3" xref="S3.SS2.p2.2.m2.3.3.3.3.3.3.cmml"><mi mathvariant="normal" id="S3.SS2.p2.2.m2.3.3.3.3.3.3.2" xref="S3.SS2.p2.2.m2.3.3.3.3.3.3.cmml">µ</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p2.2.m2.3.3.3.3.3.3.1" xref="S3.SS2.p2.2.m2.3.3.3.3.3.3.cmml">​</mo><mi mathvariant="normal" id="S3.SS2.p2.2.m2.3.3.3.3.3.3.3" xref="S3.SS2.p2.2.m2.3.3.3.3.3.3.cmml">m</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.2.m2.3b"><apply id="S3.SS2.p2.2.m2.3.3.cmml" xref="S3.SS2.p2.2.m2.3.3"><csymbol cd="latexml" id="S3.SS2.p2.2.m2.2.2.2.2.2.2.cmml" xref="S3.SS2.p2.2.m2.2.2.2.2.2.2">times</csymbol><cn type="float" id="S3.SS2.p2.2.m2.1.1.1.1.1.1.cmml" xref="S3.SS2.p2.2.m2.1.1.1.1.1.1">2.5</cn><csymbol cd="latexml" id="S3.SS2.p2.2.m2.3.3.3.3.3.3.cmml" xref="S3.SS2.p2.2.m2.3.3.3.3.3.3">micrometer</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.2.m2.3c">2.5\text{\,}\mathrm{\SIUnitSymbolMicro m}</annotation></semantics></math> in one <math id="S3.SS2.p2.3.m3.3" class="ltx_Math" alttext="\text{\,}{\mathrm{m}}^{3}" display="inline"><semantics id="S3.SS2.p2.3.m3.3a"><mrow id="S3.SS2.p2.3.m3.3.3" xref="S3.SS2.p2.3.m3.3.3.cmml"><mi id="S3.SS2.p2.3.m3.1.1.1.1.1.1" xref="S3.SS2.p2.3.m3.1.1.1.1.1.1.cmml"></mi><mtext id="S3.SS2.p2.3.m3.2.2.2.2.2.2" xref="S3.SS2.p2.3.m3.2.2.2.2.2.2.cmml"> </mtext><msup id="S3.SS2.p2.3.m3.3.3.3.3.3.3" xref="S3.SS2.p2.3.m3.3.3.3.3.3.3.cmml"><mi class="ltx_unit" mathvariant="normal" id="S3.SS2.p2.3.m3.3.3.3.3.3.3.2" xref="S3.SS2.p2.3.m3.3.3.3.3.3.3.2.cmml">m</mi><mn id="S3.SS2.p2.3.m3.3.3.3.3.3.3.3" xref="S3.SS2.p2.3.m3.3.3.3.3.3.3.3.cmml">3</mn></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.3.m3.3b"><apply id="S3.SS2.p2.3.m3.3.3.cmml" xref="S3.SS2.p2.3.m3.3.3"><csymbol cd="latexml" id="S3.SS2.p2.3.m3.2.2.2.2.2.2.cmml" xref="S3.SS2.p2.3.m3.2.2.2.2.2.2">times</csymbol><csymbol cd="latexml" id="S3.SS2.p2.3.m3.1.1.1.1.1.1.cmml" xref="S3.SS2.p2.3.m3.1.1.1.1.1.1">absent</csymbol><apply id="S3.SS2.p2.3.m3.3.3.3.3.3.3.cmml" xref="S3.SS2.p2.3.m3.3.3.3.3.3.3"><power id="S3.SS2.p2.3.m3.3.3.3.3.3.3.1.cmml" xref="S3.SS2.p2.3.m3.3.3.3.3.3.3"></power><csymbol cd="latexml" id="S3.SS2.p2.3.m3.3.3.3.3.3.3.2.cmml" xref="S3.SS2.p2.3.m3.3.3.3.3.3.3.2">meter</csymbol><cn type="integer" id="S3.SS2.p2.3.m3.3.3.3.3.3.3.3.cmml" xref="S3.SS2.p2.3.m3.3.3.3.3.3.3.3">3</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.3.m3.3c">\text{\,}{\mathrm{m}}^{3}</annotation></semantics></math>).
The output of the predictor is one of the three classes <em id="S3.SS2.p2.3.2" class="ltx_emph ltx_font_italic">low</em>, <em id="S3.SS2.p2.3.3" class="ltx_emph ltx_font_italic">medium</em> or <em id="S3.SS2.p2.3.4" class="ltx_emph ltx_font_italic">high</em>.
The thresholds for each class are chosen in a way such that the samples of the whole data set are distributed evenly among the three classes.</p>
</div>
<section id="S3.SS2.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Data set</h4>

<div id="S3.SS2.SSS0.Px1.p1" class="ltx_para">
<p id="S3.SS2.SSS0.Px1.p1.2" class="ltx_p">The data set we use is a multi-feature air quality and weather data set <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx21" title="" class="ltx_ref">Zha+17</a>]</cite> which is publicly available online<span id="footnote11" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">11</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">11</sup><span class="ltx_tag ltx_tag_note">11</span>Beijing multi-site air-quality data set <a target="_blank" href="https://www.kaggle.com/datasets/sid321axn/beijing-multisite-airquality-data-set" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.kaggle.com/datasets/sid321axn/beijing-multisite-airquality-data-set</a>, accessed on July 17, 2023</span></span></span>.
It consists of hourly measurements of 12 meteorological stations in Beijing, recorded over a time span of 4 years (2013–2017).
<a href="#S3.F1" title="Figure 1 ‣ 3.2 Fine dust pollution ‣ 3 Simulations ‣ The Applicability of Federated Learning to Official Statistics" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Figure 1</span></a> depicts the locations of the 12 stations in Beijing.
In total, more than <math id="S3.SS2.SSS0.Px1.p1.1.m1.1" class="ltx_Math" alttext="420\,000" display="inline"><semantics id="S3.SS2.SSS0.Px1.p1.1.m1.1a"><mn id="S3.SS2.SSS0.Px1.p1.1.m1.1.1" xref="S3.SS2.SSS0.Px1.p1.1.m1.1.1.cmml">420 000</mn><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px1.p1.1.m1.1b"><cn type="integer" id="S3.SS2.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S3.SS2.SSS0.Px1.p1.1.m1.1.1">420000</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px1.p1.1.m1.1c">420\,000</annotation></semantics></math> data records are included in the data set.
Although some attributes are missing for some data records, most records have data for all the 17 attributes.
An example plot for the two attributes PM<sub id="S3.SS2.SSS0.Px1.p1.2.1" class="ltx_sub"><span id="S3.SS2.SSS0.Px1.p1.2.1.1" class="ltx_text ltx_font_italic">2.5</span></sub> and temperature is shown in <a href="#S3.F2" title="Figure 2 ‣ Data set ‣ 3.2 Fine dust pollution ‣ 3 Simulations ‣ The Applicability of Federated Learning to Official Statistics" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Figure 2</span></a>.</p>
</div>
<figure id="S3.F2" class="ltx_figure"><img src="/html/2307.15503/assets/pic/pm-data-overview.png" id="S3.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="538" height="290" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Example plot for the data of one meteorological station and the two features PM<sub id="S3.F2.4.1" class="ltx_sub"><span id="S3.F2.4.1.1" class="ltx_text ltx_font_italic">2.5</span></sub> and temperature. The four-year time span is clearly visible by the temperature wave, due to hot summers and cold winters.</figcaption>
</figure>
</section>
<section id="S3.SS2.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Data preprocessing</h4>

<div id="S3.SS2.SSS0.Px2.p1" class="ltx_para">
<p id="S3.SS2.SSS0.Px2.p1.4" class="ltx_p">To complete the missing data records, we use linear interpolation.
We apply one-hot encoding to the wind direction attribute.
All other features are scaled to a range from 0 to 1.
For the attributes PM<sub id="S3.SS2.SSS0.Px2.p1.4.1" class="ltx_sub"><span id="S3.SS2.SSS0.Px2.p1.4.1.1" class="ltx_text ltx_font_italic">10</span></sub>, SO<sub id="S3.SS2.SSS0.Px2.p1.4.2" class="ltx_sub">2</sub>, NO<sub id="S3.SS2.SSS0.Px2.p1.4.3" class="ltx_sub">2</sub>, CO and O<sub id="S3.SS2.SSS0.Px2.p1.4.4" class="ltx_sub">3</sub>,
we observe a high correlation with the target attribute and thus exclude them from training.
80% of the data are used as training data, the rest is used as test data.</p>
</div>
</section>
<section id="S3.SS2.SSS0.Px3" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Setup</h4>

<div id="S3.SS2.SSS0.Px3.p1" class="ltx_para">
<p id="S3.SS2.SSS0.Px3.p1.1" class="ltx_p">As in the first use case, we implement a centralized learning benchmark and compare it with a FL approach.
We model one FL client per meteorological station and split the data accordingly, while the benchmark model is trained with data from all 12 stations.
In both settings, we use neural networks with LSTM (long-short term memory) layers and apply 5-fold cross validation.
The architecture of the neural networks is similar across both settings and has been manually tuned to reach a good performance:
The input layer is followed by a 10-neuron LSTM layer, a dropout layer with a dropout rate of 25%,
a 5-neuron LSTM layer, another dropout layer with a dropout rate of 35% and a 3-neuron dense
layer for the classification output.
For the same reasons as in the first use case, we use the Adam optimizer and apply a learning rate of 0.05 on the server and 0.005 on the client.
The client learning rate is decreased every 64 epochs by a factor of 10 to facilitate fine-tuning in later stages of the training.
The total training budget we have allocated is 10 epochs for centralized learning and 200 epochs for FL (with a single round of local training per epoch).</p>
</div>
</section>
<section id="S3.SS2.SSS0.Px4" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Results</h4>

<div id="S3.SS2.SSS0.Px4.p1" class="ltx_para">
<p id="S3.SS2.SSS0.Px4.p1.1" class="ltx_p">A summary of our results for the fine dust pollution use case is provided in <a href="#S3.T2" title="Table 2 ‣ Results ‣ 3.2 Fine dust pollution ‣ 3 Simulations ‣ The Applicability of Federated Learning to Official Statistics" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Table 2</span></a>.
Depicted are the means of our 5-fold cross validation experiments.</p>
</div>
<div id="S3.SS2.SSS0.Px4.p2" class="ltx_para">
<p id="S3.SS2.SSS0.Px4.p2.1" class="ltx_p">The centralized learning benchmark reaches a mean classification accuracy of 72.4%, with similarly high numbers for precision and recall (72.8%, respectively 72.3%).
In comparison, the FL classifier reaches a performance of both an accuracy and a recall of 68.0% and a precision of 67.9%.
The relative standard deviation is higher in the FL scenario for all three metrics, reaching from +2.67 percentage points (accuracy) to +2.9 percentage points (both precision and recall).</p>
</div>
<div id="S3.SS2.SSS0.Px4.p3" class="ltx_para">
<p id="S3.SS2.SSS0.Px4.p3.1" class="ltx_p">An exemplary confusion matrix for one of the five resulting models of the centralized learning is depicted in <a href="#S3.T3" title="Table 3 ‣ Results ‣ 3.2 Fine dust pollution ‣ 3 Simulations ‣ The Applicability of Federated Learning to Official Statistics" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Table 3</span></a>.
Most misclassifications are made for the <em id="S3.SS2.SSS0.Px4.p3.1.1" class="ltx_emph ltx_font_italic">medium</em> class.
The same could be observed for the other models (both in centralized and federated learning).</p>
</div>
<figure id="S3.T2" class="ltx_table">
<table id="S3.T2.3" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T2.3.3" class="ltx_tr">
<th id="S3.T2.3.3.4" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" style="padding:1pt 4.3pt;"><span id="S3.T2.3.3.4.1" class="ltx_text ltx_font_bold">Model</span></th>
<th id="S3.T2.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding:1pt 4.3pt;"><span id="S3.T2.1.1.1.1" class="ltx_text ltx_font_bold">Accuracy (<math id="S3.T2.1.1.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.T2.1.1.1.1.m1.1a"><mo id="S3.T2.1.1.1.1.m1.1.1" xref="S3.T2.1.1.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S3.T2.1.1.1.1.m1.1b"><csymbol cd="latexml" id="S3.T2.1.1.1.1.m1.1.1.cmml" xref="S3.T2.1.1.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.1.1.1.1.m1.1c">\pm</annotation></semantics></math> std)</span></th>
<th id="S3.T2.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding:1pt 4.3pt;"><span id="S3.T2.2.2.2.1" class="ltx_text ltx_font_bold">Precision (<math id="S3.T2.2.2.2.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.T2.2.2.2.1.m1.1a"><mo id="S3.T2.2.2.2.1.m1.1.1" xref="S3.T2.2.2.2.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S3.T2.2.2.2.1.m1.1b"><csymbol cd="latexml" id="S3.T2.2.2.2.1.m1.1.1.cmml" xref="S3.T2.2.2.2.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.2.2.2.1.m1.1c">\pm</annotation></semantics></math> std)</span></th>
<th id="S3.T2.3.3.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding:1pt 4.3pt;"><span id="S3.T2.3.3.3.1" class="ltx_text ltx_font_bold">Recall (<math id="S3.T2.3.3.3.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.T2.3.3.3.1.m1.1a"><mo id="S3.T2.3.3.3.1.m1.1.1" xref="S3.T2.3.3.3.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S3.T2.3.3.3.1.m1.1b"><csymbol cd="latexml" id="S3.T2.3.3.3.1.m1.1.1.cmml" xref="S3.T2.3.3.3.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.3.3.3.1.m1.1c">\pm</annotation></semantics></math> std)</span></th>
<th id="S3.T2.3.3.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding:1pt 4.3pt;"><span id="S3.T2.3.3.5.1" class="ltx_text ltx_font_bold">Rel. loss (%)</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T2.3.4.1" class="ltx_tr">
<th id="S3.T2.3.4.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" style="padding:1pt 4.3pt;">neural network</th>
<td id="S3.T2.3.4.1.2" class="ltx_td ltx_align_center ltx_border_t" style="padding:1pt 4.3pt;">72.4% (4.92)</td>
<td id="S3.T2.3.4.1.3" class="ltx_td ltx_align_center ltx_border_t" style="padding:1pt 4.3pt;">72.8% (8.66)</td>
<td id="S3.T2.3.4.1.4" class="ltx_td ltx_align_center ltx_border_t" style="padding:1pt 4.3pt;">72.3% (8.10)</td>
<td id="S3.T2.3.4.1.5" class="ltx_td ltx_align_center ltx_border_t" style="padding:1pt 4.3pt;">0.0</td>
</tr>
<tr id="S3.T2.3.5.2" class="ltx_tr">
<th id="S3.T2.3.5.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" style="padding:1pt 4.3pt;">neural network (fed.)</th>
<td id="S3.T2.3.5.2.2" class="ltx_td ltx_align_center ltx_border_bb" style="padding:1pt 4.3pt;">68.0% (7.59)</td>
<td id="S3.T2.3.5.2.3" class="ltx_td ltx_align_center ltx_border_bb" style="padding:1pt 4.3pt;">67.9% (10.05)</td>
<td id="S3.T2.3.5.2.4" class="ltx_td ltx_align_center ltx_border_bb" style="padding:1pt 4.3pt;">68.0% (9.59)</td>
<td id="S3.T2.3.5.2.5" class="ltx_td ltx_align_center ltx_border_bb" style="padding:1pt 4.3pt;">5.9-6.7</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Performance in the fine dust pollution simulation. The span of the relative loss refers to all three metrics.</figcaption>
</figure>
<figure id="S3.T3" class="ltx_table">
<table id="S3.T3.9" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T3.9.10.1" class="ltx_tr">
<th id="S3.T3.9.10.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" style="padding:0.9pt 4.3pt;">
<span id="S3.T3.9.10.1.1.1" class="ltx_text" style="font-size:90%;">true class / </span><span id="S3.T3.9.10.1.1.2" class="ltx_text ltx_font_bold" style="font-size:90%;">predicted class</span>
</th>
<th id="S3.T3.9.10.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding:0.9pt 4.3pt;"><span id="S3.T3.9.10.1.2.1" class="ltx_text ltx_font_bold" style="font-size:90%;">low</span></th>
<th id="S3.T3.9.10.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding:0.9pt 4.3pt;"><span id="S3.T3.9.10.1.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">medium</span></th>
<th id="S3.T3.9.10.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding:0.9pt 4.3pt;"><span id="S3.T3.9.10.1.4.1" class="ltx_text ltx_font_bold" style="font-size:90%;">high</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T3.3.3" class="ltx_tr">
<th id="S3.T3.3.3.4" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" style="padding:0.9pt 4.3pt;"><span id="S3.T3.3.3.4.1" class="ltx_text" style="font-size:90%;">low</span></th>
<td id="S3.T3.1.1.1" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.9pt 4.3pt;"><math id="S3.T3.1.1.1.m1.1" class="ltx_Math" alttext="114\,450" display="inline"><semantics id="S3.T3.1.1.1.m1.1a"><mn mathsize="90%" id="S3.T3.1.1.1.m1.1.1" xref="S3.T3.1.1.1.m1.1.1.cmml">114 450</mn><annotation-xml encoding="MathML-Content" id="S3.T3.1.1.1.m1.1b"><cn type="integer" id="S3.T3.1.1.1.m1.1.1.cmml" xref="S3.T3.1.1.1.m1.1.1">114450</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.1.1.1.m1.1c">114\,450</annotation></semantics></math></td>
<td id="S3.T3.2.2.2" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.9pt 4.3pt;"><math id="S3.T3.2.2.2.m1.1" class="ltx_Math" alttext="23\,712" display="inline"><semantics id="S3.T3.2.2.2.m1.1a"><mn mathsize="90%" id="S3.T3.2.2.2.m1.1.1" xref="S3.T3.2.2.2.m1.1.1.cmml">23 712</mn><annotation-xml encoding="MathML-Content" id="S3.T3.2.2.2.m1.1b"><cn type="integer" id="S3.T3.2.2.2.m1.1.1.cmml" xref="S3.T3.2.2.2.m1.1.1">23712</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.2.2.2.m1.1c">23\,712</annotation></semantics></math></td>
<td id="S3.T3.3.3.3" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.9pt 4.3pt;"><math id="S3.T3.3.3.3.m1.1" class="ltx_Math" alttext="5769" display="inline"><semantics id="S3.T3.3.3.3.m1.1a"><mn mathsize="90%" id="S3.T3.3.3.3.m1.1.1" xref="S3.T3.3.3.3.m1.1.1.cmml">5769</mn><annotation-xml encoding="MathML-Content" id="S3.T3.3.3.3.m1.1b"><cn type="integer" id="S3.T3.3.3.3.m1.1.1.cmml" xref="S3.T3.3.3.3.m1.1.1">5769</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.3.3.3.m1.1c">5769</annotation></semantics></math></td>
</tr>
<tr id="S3.T3.6.6" class="ltx_tr">
<th id="S3.T3.6.6.4" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding:0.9pt 4.3pt;"><span id="S3.T3.6.6.4.1" class="ltx_text" style="font-size:90%;">medium</span></th>
<td id="S3.T3.4.4.1" class="ltx_td ltx_align_center" style="padding:0.9pt 4.3pt;"><math id="S3.T3.4.4.1.m1.1" class="ltx_Math" alttext="23\,635" display="inline"><semantics id="S3.T3.4.4.1.m1.1a"><mn mathsize="90%" id="S3.T3.4.4.1.m1.1.1" xref="S3.T3.4.4.1.m1.1.1.cmml">23 635</mn><annotation-xml encoding="MathML-Content" id="S3.T3.4.4.1.m1.1b"><cn type="integer" id="S3.T3.4.4.1.m1.1.1.cmml" xref="S3.T3.4.4.1.m1.1.1">23635</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.4.4.1.m1.1c">23\,635</annotation></semantics></math></td>
<td id="S3.T3.5.5.2" class="ltx_td ltx_align_center" style="padding:0.9pt 4.3pt;"><math id="S3.T3.5.5.2.m1.1" class="ltx_Math" alttext="80\,718" display="inline"><semantics id="S3.T3.5.5.2.m1.1a"><mn mathsize="90%" id="S3.T3.5.5.2.m1.1.1" xref="S3.T3.5.5.2.m1.1.1.cmml">80 718</mn><annotation-xml encoding="MathML-Content" id="S3.T3.5.5.2.m1.1b"><cn type="integer" id="S3.T3.5.5.2.m1.1.1.cmml" xref="S3.T3.5.5.2.m1.1.1">80718</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.5.5.2.m1.1c">80\,718</annotation></semantics></math></td>
<td id="S3.T3.6.6.3" class="ltx_td ltx_align_center" style="padding:0.9pt 4.3pt;"><math id="S3.T3.6.6.3.m1.1" class="ltx_Math" alttext="33\,754" display="inline"><semantics id="S3.T3.6.6.3.m1.1a"><mn mathsize="90%" id="S3.T3.6.6.3.m1.1.1" xref="S3.T3.6.6.3.m1.1.1.cmml">33 754</mn><annotation-xml encoding="MathML-Content" id="S3.T3.6.6.3.m1.1b"><cn type="integer" id="S3.T3.6.6.3.m1.1.1.cmml" xref="S3.T3.6.6.3.m1.1.1">33754</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.6.6.3.m1.1c">33\,754</annotation></semantics></math></td>
</tr>
<tr id="S3.T3.9.9" class="ltx_tr">
<th id="S3.T3.9.9.4" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" style="padding:0.9pt 4.3pt;"><span id="S3.T3.9.9.4.1" class="ltx_text" style="font-size:90%;">high</span></th>
<td id="S3.T3.7.7.1" class="ltx_td ltx_align_center ltx_border_bb" style="padding:0.9pt 4.3pt;"><math id="S3.T3.7.7.1.m1.1" class="ltx_Math" alttext="1944" display="inline"><semantics id="S3.T3.7.7.1.m1.1a"><mn mathsize="90%" id="S3.T3.7.7.1.m1.1.1" xref="S3.T3.7.7.1.m1.1.1.cmml">1944</mn><annotation-xml encoding="MathML-Content" id="S3.T3.7.7.1.m1.1b"><cn type="integer" id="S3.T3.7.7.1.m1.1.1.cmml" xref="S3.T3.7.7.1.m1.1.1">1944</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.7.7.1.m1.1c">1944</annotation></semantics></math></td>
<td id="S3.T3.8.8.2" class="ltx_td ltx_align_center ltx_border_bb" style="padding:0.9pt 4.3pt;"><math id="S3.T3.8.8.2.m1.1" class="ltx_Math" alttext="24\,629" display="inline"><semantics id="S3.T3.8.8.2.m1.1a"><mn mathsize="90%" id="S3.T3.8.8.2.m1.1.1" xref="S3.T3.8.8.2.m1.1.1.cmml">24 629</mn><annotation-xml encoding="MathML-Content" id="S3.T3.8.8.2.m1.1b"><cn type="integer" id="S3.T3.8.8.2.m1.1.1.cmml" xref="S3.T3.8.8.2.m1.1.1">24629</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.8.8.2.m1.1c">24\,629</annotation></semantics></math></td>
<td id="S3.T3.9.9.3" class="ltx_td ltx_align_center ltx_border_bb" style="padding:0.9pt 4.3pt;"><math id="S3.T3.9.9.3.m1.1" class="ltx_Math" alttext="111\,581" display="inline"><semantics id="S3.T3.9.9.3.m1.1a"><mn mathsize="90%" id="S3.T3.9.9.3.m1.1.1" xref="S3.T3.9.9.3.m1.1.1.cmml">111 581</mn><annotation-xml encoding="MathML-Content" id="S3.T3.9.9.3.m1.1b"><cn type="integer" id="S3.T3.9.9.3.m1.1.1.cmml" xref="S3.T3.9.9.3.m1.1.1">111581</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.9.9.3.m1.1c">111\,581</annotation></semantics></math></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 3: </span>Exemplary confusion matrix for one of the five models in the cross-validation training of the centralized model for the fine dust pollution use case.</figcaption>
</figure>
</section>
<section id="S3.SS2.SSS0.Px5" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Discussion</h4>

<div id="S3.SS2.SSS0.Px5.p1" class="ltx_para">
<p id="S3.SS2.SSS0.Px5.p1.1" class="ltx_p">Compared to the first use case, the training database is significantly larger.
With 12 clients, there are also four times as many participants in the FL scenario as in the first use case.
Still, the performance decrease is small, with an accuracy of 68.0% (FL) compared to 72.4% in the centralized training scenario.</p>
</div>
<div id="S3.SS2.SSS0.Px5.p2" class="ltx_para">
<p id="S3.SS2.SSS0.Px5.p2.1" class="ltx_p">Apart from preprocessing the data set,
another time-consuming part of the engineering was tuning the hyperparameters of the FL training.
Tools for automatic FL hyperparameter optimization were out of scope for this work, thus it was necessary to manually trigger different trial runs with varying hyperparameters.</p>
</div>
</section>
<section id="S3.SS2.SSS0.Px6" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Comparison with literature</h4>

<div id="S3.SS2.SSS0.Px6.p1" class="ltx_para">
<p id="S3.SS2.SSS0.Px6.p1.1" class="ltx_p">The authors of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx7" title="" class="ltx_ref">Hu+18</a>]</cite> compare the results of their personalized FL strategy <span id="S3.SS2.SSS0.Px6.p1.1.1" class="ltx_text ltx_inline-quote ltx_outerquote">“Region-Learning”</span> to a centralized learning baseline and standard FL.
Although according to the authors, their personalized FL approach outperforms the other two approaches (averaged over the regions by 5 percentage points compared to standard FL),
we want to stress that Region-Learning has another goal than standard FL – namely multiple specialized models, and not one global model as in standard FL and most use cases for official statistics (also see <a href="#S2.SS1" title="2.1 Federated Learning ‣ 2 Background ‣ The Applicability of Federated Learning to Official Statistics" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">subsection 2.1</span></a>).</p>
</div>
<div id="S3.SS2.SSS0.Px6.p2" class="ltx_para">
<p id="S3.SS2.SSS0.Px6.p2.5" class="ltx_p">Furthermore, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx7" title="" class="ltx_ref">Hu+18</a>]</cite> have not provided sufficient information to retrace their experiments.
Especially the number of classes for PM<sub id="S3.SS2.SSS0.Px6.p2.5.2" class="ltx_sub"><span id="S3.SS2.SSS0.Px6.p2.5.2.1" class="ltx_text ltx_font_italic">2.5</span></sub> classification and information on the features used for training the classifiers are missing, so that their results are hard to compare to ours.
For example, setting the number of classes to 2 and using all features of the data set (including the other pollution attributes PM<sub id="S3.SS2.SSS0.Px6.p2.5.3" class="ltx_sub"><span id="S3.SS2.SSS0.Px6.p2.5.3.1" class="ltx_text ltx_font_italic">10</span></sub>, SO<sub id="S3.SS2.SSS0.Px6.p2.5.4" class="ltx_sub">2</sub> etc.) would significantly ease the estimation task.
Also, we have no information on whether cross validation was applied in the work of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx7" title="" class="ltx_ref">Hu+18</a>]</cite>.
Two more hints in the paper <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx7" title="" class="ltx_ref">Hu+18</a>]</cite> suggest that they have used a slightly different data set than we have: The data set they describe includes <span id="S3.SS2.SSS0.Px6.p2.4.1" class="ltx_text ltx_inline-quote ltx_outerquote">“more than <math id="S3.SS2.SSS0.Px6.p2.4.1.m1.1" class="ltx_Math" alttext="100\,000" display="inline"><semantics id="S3.SS2.SSS0.Px6.p2.4.1.m1.1a"><mn id="S3.SS2.SSS0.Px6.p2.4.1.m1.1.1" xref="S3.SS2.SSS0.Px6.p2.4.1.m1.1.1.cmml">100 000</mn><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px6.p2.4.1.m1.1b"><cn type="integer" id="S3.SS2.SSS0.Px6.p2.4.1.m1.1.1.cmml" xref="S3.SS2.SSS0.Px6.p2.4.1.m1.1.1">100000</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px6.p2.4.1.m1.1c">100\,000</annotation></semantics></math>”</span> data records from 13 meteorological stations in Beijing, while our data set contains more than <math id="S3.SS2.SSS0.Px6.p2.5.m4.1" class="ltx_Math" alttext="420\,000" display="inline"><semantics id="S3.SS2.SSS0.Px6.p2.5.m4.1a"><mn id="S3.SS2.SSS0.Px6.p2.5.m4.1.1" xref="S3.SS2.SSS0.Px6.p2.5.m4.1.1.cmml">420 000</mn><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px6.p2.5.m4.1b"><cn type="integer" id="S3.SS2.SSS0.Px6.p2.5.m4.1.1.cmml" xref="S3.SS2.SSS0.Px6.p2.5.m4.1.1">420000</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px6.p2.5.m4.1c">420\,000</annotation></semantics></math> records from 12 stations.</p>
</div>
<div id="S3.SS2.SSS0.Px6.p3" class="ltx_para">
<p id="S3.SS2.SSS0.Px6.p3.1" class="ltx_p">One consistency across both their work and ours is the accuracy drop from centralized learning to FL, with 4 percentage points in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx7" title="" class="ltx_ref">Hu+18</a>]</cite> and 4.4 percentage points in our work.</p>
</div>
</section>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Mobile radio (LTE)</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">Mobile Network Operator (MNO) data is a valuable source for obtaining high-frequency and spacial insights in various fields, including population structure, mobility and the socio-economic impact of policy interventions. However, a lack of legal frameworks permitting access to data of all providers, as seen in cases like Germany, constrain the quality of analysis <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx14" title="" class="ltx_ref">SBH22</a>]</cite>.
Accessing only data of selected providers introduces biases, making FL an attractive solution to enhance the representativeness by enabling the aggregation of insights from multiple major MNOs.</p>
</div>
<div id="S3.SS3.p2" class="ltx_para">
<p id="S3.SS3.p2.1" class="ltx_p">Thus, our third use case is based on private MNO data owned by the company umlaut SE<span id="footnote12" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">12</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">12</sup><span class="ltx_tag ltx_tag_note">12</span>umlaut website <a target="_blank" href="https://www.umlaut.com/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.umlaut.com/</a>, accessed on July 17, 2023</span></span></span>. Different from the first two use cases, we had no direct access to the data, just as the aggregation party in realistic FL settings.
While this allows for practical insights, it also comes with constricted resources in the private sector.
Hence, the focus of this use case is more on practical engineering issues of FL and less on optimal results.</p>
</div>
<div id="S3.SS3.p3" class="ltx_para">
<p id="S3.SS3.p3.1" class="ltx_p">The data set contains mobile communication network coverage data, including latency and speed tests, each linked to the mobile LTE devices of individual users and a specific timestamp.
The data records are also associated with GPS coordinates, such that a daily <span id="S3.SS3.p3.1.1" class="ltx_text ltx_inline-quote ltx_outerquote">“radius of action”</span> can be computed for each user.
This radius describes how far a user has moved from their home base within one day.
The user home bases have also been computed on the available data – a home base is defined as the place where most data records have been recorded.
The ML task we model in this use case is to estimate the daily radius of action for a user, given different LTE metrics of one particular day (see below).</p>
</div>
<section id="S3.SS3.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Data set</h4>

<div id="S3.SS3.SSS0.Px1.p1" class="ltx_para">
<p id="S3.SS3.SSS0.Px1.p1.1" class="ltx_p">The whole data set originally contains <math id="S3.SS3.SSS0.Px1.p1.1.m1.1" class="ltx_Math" alttext="286\,329\,137" display="inline"><semantics id="S3.SS3.SSS0.Px1.p1.1.m1.1a"><mn id="S3.SS3.SSS0.Px1.p1.1.m1.1.1" xref="S3.SS3.SSS0.Px1.p1.1.m1.1.1.cmml">286 329 137</mn><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS0.Px1.p1.1.m1.1b"><cn type="integer" id="S3.SS3.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S3.SS3.SSS0.Px1.p1.1.m1.1.1">286329137</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS0.Px1.p1.1.m1.1c">286\,329\,137</annotation></semantics></math> data records.
The following features of the data set have been aggregated for each day and user: <em id="S3.SS3.SSS0.Px1.p1.1.1" class="ltx_emph ltx_font_italic">radius of action</em> in meters, <em id="S3.SS3.SSS0.Px1.p1.1.2" class="ltx_emph ltx_font_italic">share of data records with Wi-Fi connection</em> and the variance and mean values for each of the following LTE metrics: <em id="S3.SS3.SSS0.Px1.p1.1.3" class="ltx_emph ltx_font_italic">RSRQ</em>, <em id="S3.SS3.SSS0.Px1.p1.1.4" class="ltx_emph ltx_font_italic">RSRP</em>, <em id="S3.SS3.SSS0.Px1.p1.1.5" class="ltx_emph ltx_font_italic">RSSNR</em> and <em id="S3.SS3.SSS0.Px1.p1.1.6" class="ltx_emph ltx_font_italic">RSSI</em>.
The date has been encoded into three numeric features (<em id="S3.SS3.SSS0.Px1.p1.1.7" class="ltx_emph ltx_font_italic">calendar week</em>, <em id="S3.SS3.SSS0.Px1.p1.1.8" class="ltx_emph ltx_font_italic">day of the week</em> and <em id="S3.SS3.SSS0.Px1.p1.1.9" class="ltx_emph ltx_font_italic">month</em>) and the boolean feature <em id="S3.SS3.SSS0.Px1.p1.1.10" class="ltx_emph ltx_font_italic">weekend</em>.</p>
</div>
</section>
<section id="S3.SS3.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Data preprocessing</h4>

<div id="S3.SS3.SSS0.Px2.p1" class="ltx_para">
<p id="S3.SS3.SSS0.Px2.p1.2" class="ltx_p">We set a specific time frame of six months and a geofence around the German state of North Rhine-Westphalia.
All other records are excluded – leaving <math id="S3.SS3.SSS0.Px2.p1.1.m1.1" class="ltx_Math" alttext="2\,718\,416" display="inline"><semantics id="S3.SS3.SSS0.Px2.p1.1.m1.1a"><mn id="S3.SS3.SSS0.Px2.p1.1.m1.1.1" xref="S3.SS3.SSS0.Px2.p1.1.m1.1.1.cmml">2 718 416</mn><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS0.Px2.p1.1.m1.1b"><cn type="integer" id="S3.SS3.SSS0.Px2.p1.1.m1.1.1.cmml" xref="S3.SS3.SSS0.Px2.p1.1.m1.1.1">2718416</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS0.Px2.p1.1.m1.1c">2\,718\,416</annotation></semantics></math> records in the data set.
Additionally, we apply a filtering strategy to clean our data: each user in the database needs to have data for at least 20 different days (within the time span of six months) and 10 records on each of these days.
Otherwise, all records of this user are discarded.
After the second filtering step, there are <math id="S3.SS3.SSS0.Px2.p1.2.m2.1" class="ltx_Math" alttext="1\,508\,102" display="inline"><semantics id="S3.SS3.SSS0.Px2.p1.2.m2.1a"><mn id="S3.SS3.SSS0.Px2.p1.2.m2.1.1" xref="S3.SS3.SSS0.Px2.p1.2.m2.1.1.cmml">1 508 102</mn><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS0.Px2.p1.2.m2.1b"><cn type="integer" id="S3.SS3.SSS0.Px2.p1.2.m2.1.1.cmml" xref="S3.SS3.SSS0.Px2.p1.2.m2.1.1">1508102</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS0.Px2.p1.2.m2.1c">1\,508\,102</annotation></semantics></math> data records in the data set.
We scale each feature to a range from 0 to 1 and then use for training, validating and testing our models.</p>
</div>
<div id="S3.SS3.SSS0.Px2.p2" class="ltx_para">
<p id="S3.SS3.SSS0.Px2.p2.1" class="ltx_p">60% of the data are used as training data, 20% are used as validation data and the remaining 20% as test data.
For FL, we have divided the data set according to the mobile network operators (MNOs) of the users.
Since more than 99.6% of the data records are associated with three major providers, the other 0.4% of the data records (belonging to 29 other MNOs) are eliminated from the data set.</p>
</div>
</section>
<section id="S3.SS3.SSS0.Px3" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Setup</h4>

<div id="S3.SS3.SSS0.Px3.p1" class="ltx_para">
<p id="S3.SS3.SSS0.Px3.p1.1" class="ltx_p">We use two centralized learning benchmarks: a random forest regressor and a neural network, which have both been subject to a hyperparameter search prior to their training.
The network architecture for both the centralized benchmark neural network and the FL training process is the same:
The first layer consists of 28 dense-neurons and the second layer consists of 14 dense-neurons, which lead to the single-neuron output layer.
All dense layers except for the output layer use the ReLU activation function.
For FL, we use the SGD optimizer with a server learning rate of 3.0, a client learning rate of 0.8 and a batch size of 2.</p>
</div>
</section>
<section id="S3.SS3.SSS0.Px4" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Results</h4>

<div id="S3.SS3.SSS0.Px4.p1" class="ltx_para">
<p id="S3.SS3.SSS0.Px4.p1.2" class="ltx_p">The benchmarks of the centralized learning regressors are <math id="S3.SS3.SSS0.Px4.p1.1.m1.1" class="ltx_Math" alttext="\text{R}^{2}" display="inline"><semantics id="S3.SS3.SSS0.Px4.p1.1.m1.1a"><msup id="S3.SS3.SSS0.Px4.p1.1.m1.1.1" xref="S3.SS3.SSS0.Px4.p1.1.m1.1.1.cmml"><mtext id="S3.SS3.SSS0.Px4.p1.1.m1.1.1.2" xref="S3.SS3.SSS0.Px4.p1.1.m1.1.1.2a.cmml">R</mtext><mn id="S3.SS3.SSS0.Px4.p1.1.m1.1.1.3" xref="S3.SS3.SSS0.Px4.p1.1.m1.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS0.Px4.p1.1.m1.1b"><apply id="S3.SS3.SSS0.Px4.p1.1.m1.1.1.cmml" xref="S3.SS3.SSS0.Px4.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS0.Px4.p1.1.m1.1.1.1.cmml" xref="S3.SS3.SSS0.Px4.p1.1.m1.1.1">superscript</csymbol><ci id="S3.SS3.SSS0.Px4.p1.1.m1.1.1.2a.cmml" xref="S3.SS3.SSS0.Px4.p1.1.m1.1.1.2"><mtext id="S3.SS3.SSS0.Px4.p1.1.m1.1.1.2.cmml" xref="S3.SS3.SSS0.Px4.p1.1.m1.1.1.2">R</mtext></ci><cn type="integer" id="S3.SS3.SSS0.Px4.p1.1.m1.1.1.3.cmml" xref="S3.SS3.SSS0.Px4.p1.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS0.Px4.p1.1.m1.1c">\text{R}^{2}</annotation></semantics></math> values of 0.158 (random forest), 0.13 (neural network) and 0.13 (linear regression).
For the neural network trained in the FL scenario, we achieve a slightly lower <math id="S3.SS3.SSS0.Px4.p1.2.m2.1" class="ltx_Math" alttext="\text{R}^{2}" display="inline"><semantics id="S3.SS3.SSS0.Px4.p1.2.m2.1a"><msup id="S3.SS3.SSS0.Px4.p1.2.m2.1.1" xref="S3.SS3.SSS0.Px4.p1.2.m2.1.1.cmml"><mtext id="S3.SS3.SSS0.Px4.p1.2.m2.1.1.2" xref="S3.SS3.SSS0.Px4.p1.2.m2.1.1.2a.cmml">R</mtext><mn id="S3.SS3.SSS0.Px4.p1.2.m2.1.1.3" xref="S3.SS3.SSS0.Px4.p1.2.m2.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS0.Px4.p1.2.m2.1b"><apply id="S3.SS3.SSS0.Px4.p1.2.m2.1.1.cmml" xref="S3.SS3.SSS0.Px4.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS0.Px4.p1.2.m2.1.1.1.cmml" xref="S3.SS3.SSS0.Px4.p1.2.m2.1.1">superscript</csymbol><ci id="S3.SS3.SSS0.Px4.p1.2.m2.1.1.2a.cmml" xref="S3.SS3.SSS0.Px4.p1.2.m2.1.1.2"><mtext id="S3.SS3.SSS0.Px4.p1.2.m2.1.1.2.cmml" xref="S3.SS3.SSS0.Px4.p1.2.m2.1.1.2">R</mtext></ci><cn type="integer" id="S3.SS3.SSS0.Px4.p1.2.m2.1.1.3.cmml" xref="S3.SS3.SSS0.Px4.p1.2.m2.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS0.Px4.p1.2.m2.1c">\text{R}^{2}</annotation></semantics></math> value of 0.114 (see <a href="#S3.T4" title="Table 4 ‣ Results ‣ 3.3 Mobile radio (LTE) ‣ 3 Simulations ‣ The Applicability of Federated Learning to Official Statistics" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Table 4</span></a>).</p>
</div>
<figure id="S3.T4" class="ltx_table">
<table id="S3.T4.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T4.1.1" class="ltx_tr">
<th id="S3.T4.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" style="padding:0.9pt 4.3pt;"><span id="S3.T4.1.1.2.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Model</span></th>
<th id="S3.T4.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding:0.9pt 4.3pt;"><math id="S3.T4.1.1.1.m1.1" class="ltx_Math" alttext="\text{R}^{2}" display="inline"><semantics id="S3.T4.1.1.1.m1.1a"><msup id="S3.T4.1.1.1.m1.1.1" xref="S3.T4.1.1.1.m1.1.1.cmml"><mtext class="ltx_mathvariant_bold" mathsize="90%" id="S3.T4.1.1.1.m1.1.1.2" xref="S3.T4.1.1.1.m1.1.1.2a.cmml">R</mtext><mn mathsize="90%" id="S3.T4.1.1.1.m1.1.1.3" xref="S3.T4.1.1.1.m1.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="S3.T4.1.1.1.m1.1b"><apply id="S3.T4.1.1.1.m1.1.1.cmml" xref="S3.T4.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.T4.1.1.1.m1.1.1.1.cmml" xref="S3.T4.1.1.1.m1.1.1">superscript</csymbol><ci id="S3.T4.1.1.1.m1.1.1.2a.cmml" xref="S3.T4.1.1.1.m1.1.1.2"><mtext class="ltx_mathvariant_bold" mathsize="90%" id="S3.T4.1.1.1.m1.1.1.2.cmml" xref="S3.T4.1.1.1.m1.1.1.2">R</mtext></ci><cn type="integer" id="S3.T4.1.1.1.m1.1.1.3.cmml" xref="S3.T4.1.1.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T4.1.1.1.m1.1c">\text{R}^{2}</annotation></semantics></math></th>
<th id="S3.T4.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding:0.9pt 4.3pt;"><span id="S3.T4.1.1.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Rel. loss (%)</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T4.1.2.1" class="ltx_tr">
<th id="S3.T4.1.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" style="padding:0.9pt 4.3pt;"><span id="S3.T4.1.2.1.1.1" class="ltx_text" style="font-size:90%;">neural network</span></th>
<td id="S3.T4.1.2.1.2" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.9pt 4.3pt;"><span id="S3.T4.1.2.1.2.1" class="ltx_text" style="font-size:90%;">0.130</span></td>
<td id="S3.T4.1.2.1.3" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.9pt 4.3pt;"><span id="S3.T4.1.2.1.3.1" class="ltx_text" style="font-size:90%;">17.7</span></td>
</tr>
<tr id="S3.T4.1.3.2" class="ltx_tr">
<th id="S3.T4.1.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding:0.9pt 4.3pt;"><span id="S3.T4.1.3.2.1.1" class="ltx_text" style="font-size:90%;">neural network (federated)</span></th>
<td id="S3.T4.1.3.2.2" class="ltx_td ltx_align_center" style="padding:0.9pt 4.3pt;"><span id="S3.T4.1.3.2.2.1" class="ltx_text" style="font-size:90%;">0.114</span></td>
<td id="S3.T4.1.3.2.3" class="ltx_td ltx_align_center" style="padding:0.9pt 4.3pt;"><span id="S3.T4.1.3.2.3.1" class="ltx_text" style="font-size:90%;">27.8</span></td>
</tr>
<tr id="S3.T4.1.4.3" class="ltx_tr">
<th id="S3.T4.1.4.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" style="padding:0.9pt 4.3pt;"><span id="S3.T4.1.4.3.1.1" class="ltx_text" style="font-size:90%;">random forest</span></th>
<td id="S3.T4.1.4.3.2" class="ltx_td ltx_align_center ltx_border_bb" style="padding:0.9pt 4.3pt;"><span id="S3.T4.1.4.3.2.1" class="ltx_text" style="font-size:90%;">0.158</span></td>
<td id="S3.T4.1.4.3.3" class="ltx_td ltx_align_center ltx_border_bb" style="padding:0.9pt 4.3pt;"><span id="S3.T4.1.4.3.3.1" class="ltx_text" style="font-size:90%;">0.0</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 4: </span>Performance in the mobile radio simulation.</figcaption>
</figure>
</section>
<section id="S3.SS3.SSS0.Px5" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Discussion</h4>

<div id="S3.SS3.SSS0.Px5.p1" class="ltx_para">
<p id="S3.SS3.SSS0.Px5.p1.2" class="ltx_p">The reasons behind the weak performance of the benchmark models (<math id="S3.SS3.SSS0.Px5.p1.1.m1.1" class="ltx_Math" alttext="\text{R}^{2}" display="inline"><semantics id="S3.SS3.SSS0.Px5.p1.1.m1.1a"><msup id="S3.SS3.SSS0.Px5.p1.1.m1.1.1" xref="S3.SS3.SSS0.Px5.p1.1.m1.1.1.cmml"><mtext id="S3.SS3.SSS0.Px5.p1.1.m1.1.1.2" xref="S3.SS3.SSS0.Px5.p1.1.m1.1.1.2a.cmml">R</mtext><mn id="S3.SS3.SSS0.Px5.p1.1.m1.1.1.3" xref="S3.SS3.SSS0.Px5.p1.1.m1.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS0.Px5.p1.1.m1.1b"><apply id="S3.SS3.SSS0.Px5.p1.1.m1.1.1.cmml" xref="S3.SS3.SSS0.Px5.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS0.Px5.p1.1.m1.1.1.1.cmml" xref="S3.SS3.SSS0.Px5.p1.1.m1.1.1">superscript</csymbol><ci id="S3.SS3.SSS0.Px5.p1.1.m1.1.1.2a.cmml" xref="S3.SS3.SSS0.Px5.p1.1.m1.1.1.2"><mtext id="S3.SS3.SSS0.Px5.p1.1.m1.1.1.2.cmml" xref="S3.SS3.SSS0.Px5.p1.1.m1.1.1.2">R</mtext></ci><cn type="integer" id="S3.SS3.SSS0.Px5.p1.1.m1.1.1.3.cmml" xref="S3.SS3.SSS0.Px5.p1.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS0.Px5.p1.1.m1.1c">\text{R}^{2}</annotation></semantics></math> of 0.158 and 0.13) are not clear.
The hyperparameters might not be optimal, since we were not able to spend many resources on hyperparameter tuning due to time constraints of the data owner.
Another reason might be the that the modeled task (estimating the radius of action based on LTE connection data) is inherently hard to learn.
With an <math id="S3.SS3.SSS0.Px5.p1.2.m2.1" class="ltx_Math" alttext="\text{R}^{2}" display="inline"><semantics id="S3.SS3.SSS0.Px5.p1.2.m2.1a"><msup id="S3.SS3.SSS0.Px5.p1.2.m2.1.1" xref="S3.SS3.SSS0.Px5.p1.2.m2.1.1.cmml"><mtext id="S3.SS3.SSS0.Px5.p1.2.m2.1.1.2" xref="S3.SS3.SSS0.Px5.p1.2.m2.1.1.2a.cmml">R</mtext><mn id="S3.SS3.SSS0.Px5.p1.2.m2.1.1.3" xref="S3.SS3.SSS0.Px5.p1.2.m2.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS0.Px5.p1.2.m2.1b"><apply id="S3.SS3.SSS0.Px5.p1.2.m2.1.1.cmml" xref="S3.SS3.SSS0.Px5.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS0.Px5.p1.2.m2.1.1.1.cmml" xref="S3.SS3.SSS0.Px5.p1.2.m2.1.1">superscript</csymbol><ci id="S3.SS3.SSS0.Px5.p1.2.m2.1.1.2a.cmml" xref="S3.SS3.SSS0.Px5.p1.2.m2.1.1.2"><mtext id="S3.SS3.SSS0.Px5.p1.2.m2.1.1.2.cmml" xref="S3.SS3.SSS0.Px5.p1.2.m2.1.1.2">R</mtext></ci><cn type="integer" id="S3.SS3.SSS0.Px5.p1.2.m2.1.1.3.cmml" xref="S3.SS3.SSS0.Px5.p1.2.m2.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS0.Px5.p1.2.m2.1c">\text{R}^{2}</annotation></semantics></math> of 0.114, we were able to reproduce this performance in the FL setting.</p>
</div>
<div id="S3.SS3.SSS0.Px5.p2" class="ltx_para">
<p id="S3.SS3.SSS0.Px5.p2.1" class="ltx_p">Since the private data set in this use case has not left company premises, there are important lessons to be learned from a practical perspective:</p>
<ol id="S3.I1" class="ltx_enumerate">
<li id="S3.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S3.I1.i1.p1" class="ltx_para">
<p id="S3.I1.i1.p1.1" class="ltx_p">Even if the data set is not directly available during the model engineering process, it is crucial to get basic insights on the features and statistical properties before starting the training.
Essential decisions, such as the type of model to be trained, can be made based on this.</p>
</div>
</li>
<li id="S3.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S3.I1.i2.p1" class="ltx_para">
<p id="S3.I1.i2.p1.1" class="ltx_p">A thorough hyperparameter optimization is needed to obtain useful results.
It might take a lot of time and computational resources to find hyperparameters which are suited for the task.</p>
</div>
</li>
<li id="S3.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="S3.I1.i3.p1" class="ltx_para">
<p id="S3.I1.i3.p1.1" class="ltx_p">Technical difficulties while creating the necessary APIs and setting up the chosen ML framework at the FL clients can slow down the process even more.
Without access to the database, it might be hard to reproduce technical errors.</p>
</div>
</li>
</ol>
</div>
<div id="S3.SS3.SSS0.Px5.p3" class="ltx_para">
<p id="S3.SS3.SSS0.Px5.p3.1" class="ltx_p">While all points mentioned above were encountered in the third simulation, there was only <em id="S3.SS3.SSS0.Px5.p3.1.1" class="ltx_emph ltx_font_italic">one</em> party who held all data.
In real FL scenarios with multiple data holders, the process might get much more complicated.</p>
</div>
</section>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Key Observations</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">Our simulations lead to the following key observations:</p>
</div>
<div id="S4.p2" class="ltx_para">
<p id="S4.p2.1" class="ltx_p">Models trained via FL can reach a performance very close to models trained with centralized ML approaches, as we have shown in all three use cases.
While the performance gap itself is not surprising (since the FL model has been exposed to the complete data set only indirectly), we want to stress that without FL, many ML scenarios might not be possible due to privacy concerns, trade secrets, or similar reasons.
This is especially true for health care data, i.e., the domain of our first simulation.</p>
</div>
<div id="S4.p3" class="ltx_para">
<p id="S4.p3.1" class="ltx_p">While the random forest regressor has demonstrated superior performance compared to other centralized learning benchmarks in all three simulations, exploring the potential of tree-based models within a FL context <span id="S4.p3.1.1" class="ltx_ERROR undefined">\cites</span>alquraan2022fedtrees, eflboost, FedGBDT could be a promising avenue for further investigation.
The improved interpretability and explainability over many other models, e.g., neural networks, is another advantage of tree-based models.</p>
</div>
<div id="S4.p4" class="ltx_para">
<p id="S4.p4.1" class="ltx_p">On the other hand, random forest regressors are not suitable if tasks get more complicated.
Also, their architecture, i.e., many decision trees which may be individually overfitted to parts of the training data, can facilitate the extraction of sensitive information of the training data and thus pose an additional privacy risk.</p>
</div>
<div id="S4.p5" class="ltx_para">
<p id="S4.p5.1" class="ltx_p">Choosing the right hyperparameters is crucial for any ML model.
Since automatic HPO is still an open problem for FL algorithms, (manually) finding the right settings can be a time-consuming process.
Developing a suitable framework for automated HPO for FL would be important future work – although for official statistics, other issues might be more pressing at the moment (see <a href="#S5" title="5 Implications for Official Statistics ‣ The Applicability of Federated Learning to Official Statistics" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">section 5</span></a>).</p>
</div>
<div id="S4.p6" class="ltx_para">
<p id="S4.p6.1" class="ltx_p">In our third simulation (mobile radio data), we did not have access to the training and test data set, just like in a real-world scenario.
This means both HPO and technical debugging needed to be performed remotely, without access to the data.
Although this was already challenging,
we believe that in scenarios with multiple data holders and possibly heterogeneous data sets, these tasks will be even harder.</p>
</div>
<div id="S4.p7" class="ltx_para">
<p id="S4.p7.1" class="ltx_p">All FL simulations were performed on the machine which also had access to the complete data set.
In a real-world application, where each client runs on a distinct machine, other settings and other frameworks might be more practical than TensorFlow Federated.</p>
</div>
<div id="S4.p8" class="ltx_para">
<p id="S4.p8.1" class="ltx_p">Last but not least, we want to emphasize that FL, despite its privacy-enhancing character,
may still be vulnerable to some ML privacy issues (see <a href="#S2.SS2" title="2.2 Privacy Challenges with Machine Learning ‣ 2 Background ‣ The Applicability of Federated Learning to Official Statistics" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">subsection 2.2</span></a>).
Hence, analyzing and communicating these risks is an important step before an application is rolled out in practice.</p>
</div>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Implications for Official Statistics</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">In this work, we have demonstrated how FL can enable NSOs to address pressing data needs in fields that are relevant to policymakers and society.
Official statistics are characterized by high accuracy while underlying strict standards in confidentiality and privacy.
Accuracy, explainability, reproducibility, timeliness, and cost-effectiveness are essential quality dimensions for statistical algorithms <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx19" title="" class="ltx_ref">Yun+22</a>]</cite>.
In this setting, our findings indicate that FL bears significant potential to support statistical production and improve data quality.</p>
</div>
<div id="S5.p2" class="ltx_para">
<p id="S5.p2.1" class="ltx_p">We have shown that FL can empower NSOs to generate reliable models that accurately capture global relations.
In each of our use cases, the FL-generated models exhibited nearly identical predictive performance compared to a model created by combining all available data.
Each model architecture that performed well on centralized or local data could be easily adapted to a FL training process with a similar level of predictive performance only using distributed data.</p>
</div>
<div id="S5.p3" class="ltx_para">
<p id="S5.p3.1" class="ltx_p">If upcoming applications require to optimize an individual model for each participating party, personalized FL can be used to generate potentially improved models tailored to individual clients.
This increases the interest to cooperate for each participating party, as it offers
to enhance the analytic potential for each client and the server.
However, it is important to note that this customization may come at the cost of global predictive performance.</p>
</div>
<div id="S5.p4" class="ltx_para">
<p id="S5.p4.1" class="ltx_p">FL provides the main advantage of not needing to exchange sensitive data (see <a href="#S2.SS2" title="2.2 Privacy Challenges with Machine Learning ‣ 2 Background ‣ The Applicability of Federated Learning to Official Statistics" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">subsection 2.2</span></a>).
Additionally, there is no need to store or process the complete data set centralized in the NSOs.</p>
</div>
<div id="S5.p5" class="ltx_para">
<p id="S5.p5.1" class="ltx_p">NSOs can be empowered to appraise novel data sources sans the need for new legislation. In cases where legislative changes prove impractical, FL provides a crucial pathway to assess and prepare for regulations’ modernization.
By showcasing the advantages and implications of accessing new data sources before legal frameworks permit, FL not only significantly accelerates and relieves statistics production but also occasionally enables it.</p>
</div>
<div id="S5.p6" class="ltx_para">
<p id="S5.p6.1" class="ltx_p">To ensure successful future implementations of FL in NSOs, it is essential to focus on further advancements. Specifically, improvements in communication frequency are crucial to enable high-speed and efficient exchanges. Our observations indicate that FL generally requires a greater number of epochs (distributed across communication rounds) compared to centralized training to achieve similar performance levels. In our use cases, even with small datasets, we found that at least 50 rounds of communication were necessary. In real-world applications, this would result in high delay and cost. Therefore, the development of infrastructure for seamless sending and receiving ML models is necessary. Addressing this challenge, we discovered that the implementation of adaptive server optimization techniques reduced the training rounds and contributed to training stability. As a result, we recommend the use of adaptive optimizers to help minimize communication costs and enhance the efficiency of FL processes. By incorporating such adaptive optimization methods, NSOs can optimize the performance and effectiveness of FL while reducing the burden of communication overhead.</p>
</div>
<div id="S5.p7" class="ltx_para">
<p id="S5.p7.1" class="ltx_p">Additionally, it is crucial to provide partners with the necessary tools to update models effectively.
This requires coordination of the server and expertise from all participating parties. In practice, real-world applications of FL often involve the challenge of harmonizing client data without directly accessing it. Achieving an optimized model architecture uniformly across all clients also necessitates the knowledge and collaborative efforts of the clients themselves.
Providing comprehensive tools and resources to partners enables them to actively contribute to the model updating process while maintaining data privacy and security.
</p>
</div>
<div id="S5.p8" class="ltx_para">
<p id="S5.p8.1" class="ltx_p">FL is evolving rapidly and both industry and research will continue to improve the field in the coming years. The performance and efficiency of practical FL frameworks is expected to be further optimized. Similarly, we expect the development of more usable PPML algorithms including the ones based on Secure Multi-Party Computation (SMPC) and Homomorphic Encryption (HE) – allowing for provably secure collaborative ML. Although such PPML methods have been proposed and frameworks exist, their performance today is often far from acceptable for many practical applications. With more standardization and simpler, respectively more efficient, applications, FL will become even more beneficial to official statistics.</p>
</div>
<div id="S5.p9" class="ltx_para">
<p id="S5.p9.1" class="ltx_p">In summary, FL should indeed be recognized as an important technology that can facilitate the modernization of legal frameworks for official statistics.
It enables NSOs to safely use publicly relevant information that is not expected to be accessed by future legal frameworks, ultimately enhancing the quality and relevance of official statistics.
However, further development is still required to fully realize the potential of FL in this context.</p>
</div>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusion</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">In scenarios where external partners are unwilling to share individual-level information but still aim to analyze or disseminate global insights in their field of application, FL can help to overcome these issues.
We have shown across a range of three simulated use cases that FL can reach a very similar performance to centralized learning algorithms.
Hence, our results indicate that if classic (centralized) ML techniques work sufficiently well, FL can possibly produce models with a similar performance.</p>
</div>
<div id="S6.p2" class="ltx_para">
<p id="S6.p2.1" class="ltx_p">One of the next steps to transfer FL into the practice of official statistics could be to conduct practical pilot studies.
These could further showcase both the applicability and challenges of FL beyond a simulated context.
Another focus of future work in this area could be the analysis of privacy risks in FL scenarios of official statistics and potential mitigation strategies.
This would be an important stepping stone in ensuring the privacy protection of involved parties, on top of the privacy enhancement by using FL.
Just as in countless other domains, we expect FL to become a relevant technology for official statistics in the near future.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bibx1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[Al-+23]</span>
<span class="ltx_bibblock">Mohammad Al-Quraan et al.
</span>
<span class="ltx_bibblock">“FedTrees: A Novel Computation-Communication Efficient Federated Learning Framework Investigated in Smart Grids”
</span>
<span class="ltx_bibblock">In <em id="bib.bibx1.1.1" class="ltx_emph ltx_font_italic">Engineering Applications of Artificial Intelligence</em> <span id="bib.bibx1.2.2" class="ltx_text ltx_font_bold">124</span>
</span>
<span class="ltx_bibblock">Elsevier, 2023
</span>
<span class="ltx_bibblock">DOI: <a target="_blank" href="https://dx.doi.org/10.1016/j.engappai.2023.106654" title="" class="ltx_ref ltx_href">10.1016/j.engappai.2023.106654</a>
</span>
</li>
<li id="bib.bibx2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[BDF18]</span>
<span class="ltx_bibblock">Martin Beck, Florian Dumpert and Joerg Feuerhake
</span>
<span class="ltx_bibblock">“Machine learning in official statistics”
</span>
<span class="ltx_bibblock">In <em id="bib.bibx2.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1812.10422</em>, 2018
</span>
<span class="ltx_bibblock">URL: <a target="_blank" href="https://arxiv.org/abs/1812.10422" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/abs/1812.10422</a>
</span>
</li>
<li id="bib.bibx3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[Buc23]</span>
<span class="ltx_bibblock">David Buckley
</span>
<span class="ltx_bibblock">“15. United Nations Economic Commission for Europe: Trialling approaches to privacy-preserving federated machine learning”
</span>
<span class="ltx_bibblock">UN Statistics Wiki, 2023
</span>
<span class="ltx_bibblock">URL: <a target="_blank" href="https://unstats.un.org/wiki/display/UGTTOPPT/15.+United+Nations+Economic+Commission+for+Europe%3A+Trialling+approaches+to+privacy-preserving+federated+machine+learning" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://unstats.un.org/wiki/display/UGTTOPPT/15.+United+Nations+Economic+Commission+for+Europe%3A+Trialling+approaches+to+privacy-preserving+federated+machine+learning</a>
</span>
</li>
<li id="bib.bibx4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[DB17]</span>
<span class="ltx_bibblock">Florian Dumpert and Martin Beck
</span>
<span class="ltx_bibblock">“Einsatz von Machine-Learning-Verfahren in amtlichen Unternehmensstatistiken”
</span>
<span class="ltx_bibblock">In <em id="bib.bibx4.1.1" class="ltx_emph ltx_font_italic">AStA Wirtschafts-und Sozialstatistisches Archiv</em> <span id="bib.bibx4.2.2" class="ltx_text ltx_font_bold">2.11</span>, 2017, pp. 83–106
</span>
</li>
<li id="bib.bibx5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[Eur22]</span>
<span class="ltx_bibblock">United Nations Economic Commission Europe
</span>
<span class="ltx_bibblock">“Machine Learning for Official Statistics”
</span>
<span class="ltx_bibblock">In <em id="bib.bibx5.1.1" class="ltx_emph ltx_font_italic">UNECE Machine Learning Group</em>, 2022
</span>
<span class="ltx_bibblock">URL: <a target="_blank" href="https://unece.org/statistics/publications/machine-learning-official-statistics" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://unece.org/statistics/publications/machine-learning-official-statistics</a>
</span>
</li>
<li id="bib.bibx6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[HAP17]</span>
<span class="ltx_bibblock">Briland Hitaj, Giuseppe Ateniese and Fernando Perez-Cruz
</span>
<span class="ltx_bibblock">“Deep models under the GAN: information leakage from collaborative deep learning”
</span>
<span class="ltx_bibblock">In <em id="bib.bibx6.1.1" class="ltx_emph ltx_font_italic">ACM CCS</em>, 2017, pp. 603–618
</span>
</li>
<li id="bib.bibx7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[Hu+18]</span>
<span class="ltx_bibblock">Binxuan Hu, Yujia Gao, Liang Liu and Huadong Ma
</span>
<span class="ltx_bibblock">“Federated region-learning: An edge computing based framework for urban environment sensing”
</span>
<span class="ltx_bibblock">In <em id="bib.bibx7.1.1" class="ltx_emph ltx_font_italic">IEEE GLOBECOM</em>, 2018, pp. 1–7
</span>
<span class="ltx_bibblock">IEEE
</span>
</li>
<li id="bib.bibx8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[KKP20]</span>
<span class="ltx_bibblock">Viraj Kulkarni, Milind Kulkarni and Aniruddha Pant
</span>
<span class="ltx_bibblock">“Survey of personalization techniques for federated learning”
</span>
<span class="ltx_bibblock">In <em id="bib.bibx8.1.1" class="ltx_emph ltx_font_italic">2020 Fourth World Conference on Smart Trends in Systems, Security and Sustainability (WorldS4)</em>, 2020, pp. 794–797
</span>
<span class="ltx_bibblock">IEEE
</span>
</li>
<li id="bib.bibx9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[LWH20]</span>
<span class="ltx_bibblock">Qinbin Li, Zeyi Wen and Bingsheng He
</span>
<span class="ltx_bibblock">“Practical Federated Gradient Boosting Decision Trees”
</span>
<span class="ltx_bibblock">In <em id="bib.bibx9.1.1" class="ltx_emph ltx_font_italic">Proceedings of the AAAI Conference on Artificial Intelligence</em> <span id="bib.bibx9.2.2" class="ltx_text ltx_font_bold">34.04</span>, 2020, pp. 4642–4649
</span>
<span class="ltx_bibblock">URL: <a target="_blank" href="https://doi.org/10.1609/aaai.v34i04.5895" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1609/aaai.v34i04.5895</a>
</span>
</li>
<li id="bib.bibx10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[McM+17]</span>
<span class="ltx_bibblock">Brendan McMahan et al.
</span>
<span class="ltx_bibblock">“Communication-efficient learning of deep networks from decentralized data”
</span>
<span class="ltx_bibblock">In <em id="bib.bibx10.1.1" class="ltx_emph ltx_font_italic">Artificial intelligence and statistics</em>, 2017, pp. 1273–1282
</span>
<span class="ltx_bibblock">PMLR
</span>
</li>
<li id="bib.bibx11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[Mel+19]</span>
<span class="ltx_bibblock">Luca Melis, Congzheng Song, Emiliano De Cristofaro and Vitaly Shmatikov
</span>
<span class="ltx_bibblock">“Exploiting unintended feature leakage in collaborative learning”
</span>
<span class="ltx_bibblock">In <em id="bib.bibx11.1.1" class="ltx_emph ltx_font_italic">2019 IEEE symposium on security and privacy (SP)</em>, 2019, pp. 691–706
</span>
<span class="ltx_bibblock">IEEE
</span>
</li>
<li id="bib.bibx12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[NSH19]</span>
<span class="ltx_bibblock">Milad Nasr, Reza Shokri and Amir Houmansadr
</span>
<span class="ltx_bibblock">“Comprehensive privacy analysis of deep learning: Passive and active white-box inference attacks against centralized and federated learning”
</span>
<span class="ltx_bibblock">In <em id="bib.bibx12.1.1" class="ltx_emph ltx_font_italic">IEEE SP</em>, 2019, pp. 739–753
</span>
<span class="ltx_bibblock">IEEE
</span>
</li>
<li id="bib.bibx13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[Red+20]</span>
<span class="ltx_bibblock">Sashank Reddi et al.
</span>
<span class="ltx_bibblock">“Adaptive federated optimization”, 2020
</span>
<span class="ltx_bibblock">DOI: <a target="_blank" href="https://dx.doi.org/ARXIV.2003.00295" title="" class="ltx_ref ltx_href">ARXIV.2003.00295</a>
</span>
</li>
<li id="bib.bibx14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[SBH22]</span>
<span class="ltx_bibblock">Younes Saidani, Sarah Bohnensteffen and Sandra Hadam
</span>
<span class="ltx_bibblock">“Qualität von Mobilfunkdaten – Projekterfahrungen und Anwendungsfälle aus der amtlichen Statistik”
</span>
<span class="ltx_bibblock">In <em id="bib.bibx14.1.1" class="ltx_emph ltx_font_italic">WISTA - Wirtschaft und Statistik</em>, 2022, pp. 55–67
</span>
<span class="ltx_bibblock">URL: <a target="_blank" href="https://www.destatis.de/DE/Methoden/WISTA-Wirtschaft-und-Statistik/2022/05/qualitaet-mobilfunkdaten-052022.html" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.destatis.de/DE/Methoden/WISTA-Wirtschaft-und-Statistik/2022/05/qualitaet-mobilfunkdaten-052022.html</a>
</span>
</li>
<li id="bib.bibx15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[Sho+17]</span>
<span class="ltx_bibblock">Reza Shokri, Marco Stronati, Congzheng Song and Vitaly Shmatikov
</span>
<span class="ltx_bibblock">“Membership inference attacks against machine learning models”
</span>
<span class="ltx_bibblock">In <em id="bib.bibx15.1.1" class="ltx_emph ltx_font_italic">2017 IEEE symposium on security and privacy (SP)</em>, 2017, pp. 3–18
</span>
<span class="ltx_bibblock">IEEE
</span>
</li>
<li id="bib.bibx16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[SRS17]</span>
<span class="ltx_bibblock">Congzheng Song, Thomas Ristenpart and Vitaly Shmatikov
</span>
<span class="ltx_bibblock">“Machine learning models that remember too much”
</span>
<span class="ltx_bibblock">In <em id="bib.bibx16.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2017 ACM SIGSAC Conference on computer and communications security</em>, 2017, pp. 587–601
</span>
</li>
<li id="bib.bibx17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[Tem22]</span>
<span class="ltx_bibblock">Julian Templeton
</span>
<span class="ltx_bibblock">“Privacy enhancing technologies: An overview of federated learning”
</span>
<span class="ltx_bibblock">Statistics Canada, 2022
</span>
<span class="ltx_bibblock">URL: <a target="_blank" href="https://www.statcan.gc.ca/en/data-science/network/privacy-enhancing-techniques" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.statcan.gc.ca/en/data-science/network/privacy-enhancing-techniques</a>
</span>
</li>
<li id="bib.bibx18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[YOW22]</span>
<span class="ltx_bibblock">Fuki Yamamoto, Seiichi Ozawa and Lihua Wang
</span>
<span class="ltx_bibblock">“eFL-Boost: Efficient Federated Learning for Gradient Boosting Decision Trees”
</span>
<span class="ltx_bibblock">In <em id="bib.bibx18.1.1" class="ltx_emph ltx_font_italic">IEEE Access</em> <span id="bib.bibx18.2.2" class="ltx_text ltx_font_bold">10</span>, 2022, pp. 43954–43963
</span>
<span class="ltx_bibblock">DOI: <a target="_blank" href="https://dx.doi.org/10.1109/ACCESS.2022.3169502" title="" class="ltx_ref ltx_href">10.1109/ACCESS.2022.3169502</a>
</span>
</li>
<li id="bib.bibx19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[Yun+22]</span>
<span class="ltx_bibblock">Wesley Yung et al.
</span>
<span class="ltx_bibblock">“A quality framework for statistical algorithms”
</span>
<span class="ltx_bibblock">In <em id="bib.bibx19.1.1" class="ltx_emph ltx_font_italic">Statistical Journal of the IAOS</em> <span id="bib.bibx19.2.2" class="ltx_text ltx_font_bold">38.1</span>
</span>
<span class="ltx_bibblock">IOS Press, 2022, pp. 291–308
</span>
</li>
<li id="bib.bibx20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[YZH21]</span>
<span class="ltx_bibblock">Xuefei Yin, Yanming Zhu and Jiankun Hu
</span>
<span class="ltx_bibblock">“A comprehensive survey of privacy-preserving federated learning: A taxonomy, review, and future directions”
</span>
<span class="ltx_bibblock">In <em id="bib.bibx20.1.1" class="ltx_emph ltx_font_italic">ACM Computing Surveys (CSUR)</em> <span id="bib.bibx20.2.2" class="ltx_text ltx_font_bold">54.6</span>
</span>
<span class="ltx_bibblock">ACM New York, NY, USA, 2021, pp. 1–36
</span>
</li>
<li id="bib.bibx21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[Zha+17]</span>
<span class="ltx_bibblock">Shuyi Zhang et al.
</span>
<span class="ltx_bibblock">“Cautionary tales on air-quality improvement in Beijing”
</span>
<span class="ltx_bibblock">In <em id="bib.bibx21.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Royal Society A: Mathematical, Physical and Engineering Sciences</em> <span id="bib.bibx21.2.2" class="ltx_text ltx_font_bold">473.2205</span>
</span>
<span class="ltx_bibblock">The Royal Society Publishing, 2017, pp. 20170457
</span>
</li>
<li id="bib.bibx22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[ZLH19]</span>
<span class="ltx_bibblock">Ligeng Zhu, Zhijian Liu and Song Han
</span>
<span class="ltx_bibblock">“Deep leakage from gradients”
</span>
<span class="ltx_bibblock">In <em id="bib.bibx22.1.1" class="ltx_emph ltx_font_italic">Advances in neural information processing systems</em> <span id="bib.bibx22.2.2" class="ltx_text ltx_font_bold">32</span>, 2019
</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2307.15502" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2307.15503" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2307.15503">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2307.15503" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2307.15504" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Wed Feb 28 16:19:53 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
