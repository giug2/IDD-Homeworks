<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2007.13300] Evaluation of Federated Learning in Phishing Email Detection</title><meta property="og:description" content="The use of Artificial Intelligence (AI) to detect phishing emails is primarily dependent on large-scale centralized datasets, which opens it up to a myriad of privacy, trust, and legal issues.
Moreover, organizations a…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Evaluation of Federated Learning in Phishing Email Detection">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Evaluation of Federated Learning in Phishing Email Detection">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2007.13300">

<!--Generated on Thu Mar 14 12:47:56 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_font_bold ltx_title_document" style="font-size:173%;">Evaluation of Federated Learning in Phishing Email Detection
</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Chandra Thapa,
Jun Wen Tang,
Alsharif Abuadbba,
Yansong Gao,
Seyit Camtepe,
Surya Nepal,
Mahathir Almashor,
and Yifeng Zheng
</span><span class="ltx_author_notes">C. Thapa, and S. Camtepe are with Data61, CSIRO, Sydney, Australia. E-mail: {chandra.thapa; seyit.camtepe}@data61.csiro.au.A. Abuadbba, S. Nepal, and M. Almashor are with Data61, CSIRO, Sydney, Australia, and Cyber Security Cooperative Research Centre, Australia. E-mail: {sharif.abuadbba; surya.nepal; mahathir.almashor}@data61.csiro.au.J.W. Tang, Y. Gao, and Y. Zheng were with Data61, CSIRO, Sydney, Australia during this work. E-mail: jun.tang@student.unsw.edu.au, yansong.gao@njust.edu.cn, and yifeng.zheng@hit.edu.cn</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id1.id1" class="ltx_p">The use of Artificial Intelligence (AI) to detect phishing emails is primarily dependent on large-scale centralized datasets, which opens it up to a myriad of privacy, trust, and legal issues.
Moreover, organizations are loathed to share emails, given the risk of leakage of commercially sensitive information. Consequently, it is uncommon to obtain sufficient emails to train a global AI model efficiently. Accordingly, privacy-preserving distributed and collaborative machine learning, particularly Federated Learning (FL), is a desideratum.
Already prevalent in the healthcare sector, questions remain regarding the effectiveness and efficacy of FL-based phishing detection within the context of multi-organization collaborations. To the best of our knowledge, the work herein is the first to investigate the use of FL in email anti-phishing.
This paper builds upon a deep neural network model, particularly Recurrent Convolutional Neural Network (RNN) and Bidirectional Encoder Representations from Transformers (BERT) for phishing email detection. It analyzes the FL-entangled learning performance under various settings, including (i) balanced and asymmetrical data distribution among organizations and (ii) scalability.
Our results corroborate comparable performance statistics of FL in phishing email detection to centralized learning for balanced datasets, and low organization counts.
Moreover, we observe a variation in performance when increasing organizational counts. For a fixed total email dataset, the global RNN based model suffers by a 1.8% accuracy drop when increasing organizational counts from 2 to 10. In contrast, BERT accuracy rises by 0.6% when going from 2 to 5 organizations.
However, if we allow increasing the overall email dataset with the
introduction of new organizations in the FL framework, the organizational level performance is improved by achieving a faster convergence speed. Besides, FL suffers in its overall global model performance due to highly unstable outputs if the email dataset distribution is highly asymmetric.
</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span><span id="S1.1.1" class="ltx_text ltx_font_smallcaps">Introduction</span>
</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Email is the most usual means of formal communication. At the same time, it is exploited as a common attack vector for phishing attacks, where attackers disguise as a trustworthy entity and try to install malware or obtain sensitive information such as login credentials and bank details of the recipient. Based on the 2019 phishing and email fraud statistics <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>, phishing accounts for 90% of data breaches, which leads to an average financial loss of $3.86M. Moreover, phishing attacks cost American businesses half a billion dollars a year <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>, and it is increasing. Recently, COVID-19 drives phishing emails up to an unprecedented level by over 600% <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">To protect users from phishing attacks, various techniques have been devised. These techniques can generally be divided into two categories: traditional methods and artificial intelligence (AI) based methods. Traditional methods rely on known email formats, and they are inefficient because the email formats can be easily manipulated with time by the attackers. In comparison, the AI-based method is context-aware. It can continuously learn from the newly available emails and adapt to handle the new attack formats/cases efficiently on time.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">Among AI-based methods, deep learning (DL) feeds the email data directly to the system without requiring delicate feature engineering. Moreover, feature engineering is usually a time-consuming and laborious domain-specific task necessary for the conventional ML-based methods such as decision tree <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>. This makes DL a suitable method to learn against evolving threats with time. Convolutional Neural Network <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>, Recurrent Convolutional Neural Network (RCNN) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>, and transformers <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite> are typical examples of the DL-based method. Although DL-based methods are preferable over other methods considering its performance and automated feature engineering, it requires a considerable amount of email data as a trade-off.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">Unfortunately, emails are sensitive to organizations<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>Organizations are commonly referred to as clients in the remainder of this paper.</span></span></span>, and disclosure to third parties is often avoided <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>.
Even anonymization of the email is problematic because it can be easily circumvented — attackers can exploit various characteristics, e.g., social graphs, to re-identify the victim’s entity <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>. As such, it is non-trivial to aggregate emails for centralized analysis. Besides, a recent work <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite> emphasizes the strict ethical concerns when accessing and analyzing the emails of 92 organizations, even with access permission.
For any purpose, improperly centralized data management could violate specific rules, such as reusing the data indiscriminately and risk-agnostic data processing <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>, required by General Data Protection Regulation (GDPR) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> and HIPAA <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>. Therefore, even with the users’ permission to use their data for agreed tasks (e.g., DL), handling the email data under a centralized cloud is still risky under the set of privacy regulations.
Thus there is an urgent need for methods that preserve data privacy in DL and break the email data silos. As such, DL can access abundant email datasets and improve its performance (e.g., detection accuracy).
</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">In this regard, federated learning (FL) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>, <a href="#bib.bib15" title="" class="ltx_ref">15</a>, <a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>, the most popular collaborative learning, is a suitable candidate method. It trains a joint DL model by harvesting the rich distributed data held by each client in a default privacy mode. The privacy of the raw data is enabled by two means; firstly, data never shared with other clients/participants. Secondly, data is always within the control of data custodians (i.e., clients). Consequently, the data custodians have an assurance of some level of privacy and control to their data, motivating them to participate in distributed machine learning for overall social good (e.g., an anti-phishing DL model with high detection).</p>
</div>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.1" class="ltx_p">FL has been explored in various applications such as finance <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>, health ,<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>, <a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite> and natural language processing (NLP) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>. However, it is still unclear how efficient and effective it would be in phishing email detection with regard to the relevant deep models such as (i) THEMIS <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>, which is the best performing RCNN based centralized model on phishing emails, and (ii) BERT <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>, which is the best performing transformer-based centralized model on text data.
FL over email data is similar to FL in NLP, but the challenge here is that the phishing emails are highly subjective, e.g., spear phishing, and its dataset size is smaller than the NLP corpus.
To the best of our knowledge, the applicability of FL for detecting phishing emails has not been explicitly investigated. Thus in this paper, we take the first studies of FL entangled phishing email detection and investigate its performance using the DL models.</p>
</div>
<section id="S1.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">1.1 </span><span id="S1.SS1.1.1" class="ltx_text ltx_font_italic">Our contributions</span>
</h3>

<div id="S1.SS1.p1" class="ltx_para">
<p id="S1.SS1.p1.1" class="ltx_p">This work considers both the balanced and asymmetrical data distribution among clients. The evaluations are carried out with the following six research questions in mind:</p>
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.ix1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span id="S1.I1.ix1.1.1.1" class="ltx_text ltx_font_bold">RQ1</span></span> 
<div id="S1.I1.ix1.p1" class="ltx_para">
<p id="S1.I1.ix1.p1.1" class="ltx_p"><span id="S1.I1.ix1.p1.1.1" class="ltx_text ltx_font_bold">(Balanced data distribution) Can FL be applied to learn from distributed email repositories to achieve comparable performance to centralized learning (CL)?</span>
We develop deep-learning anti-phishing models based on FL and CL under balanced data distribution. Their performances show that FL achieves a comparable performance to CL. For example, (i) THEMIS model’s performance at 45 epoch is 99.3% test accuracy, and 97.9% global test accuracy for the CL and FL with 5 clients, respectively, and (ii) BERT model’s performance at 15 epoch is 96.2% test accuracy and 96.1% global test accuracy for the CL and FL with 5 clients, respectively. Details are provided in Section <a href="#S4.SS1" title="4.1 Distributed email learning under balanced data distribution ‣ 4 Results ‣ Evaluation of Federated Learning in Phishing Email Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.1</span></a>.</p>
</div>
</li>
<li id="S1.I1.ix2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span id="S1.I1.ix2.1.1.1" class="ltx_text ltx_font_bold">RQ2</span></span> 
<div id="S1.I1.ix2.p1" class="ltx_para">
<p id="S1.I1.ix2.p1.1" class="ltx_p"><span id="S1.I1.ix2.p1.1.1" class="ltx_text ltx_font_bold">(Scalability) How would the number of clients affect FL performance and convergence?</span>
Our experiments under balanced data distribution suggest that while keeping the same total email dataset, the convergence of the accuracy curve and its maximum value is model dependent.
We observe THEMIS model dropping by around 0.5% in global test accuracy at 45 epoch going from 2 to 5 clients, but the BERT model improved by around 0.6% in global test accuracy at 15 epoch going from 2 to 5 clients.
<span id="S1.I1.ix2.p1.1.2" class="ltx_text ltx_font_bold">RQ4</span> addresses some FL’s benefits to the THEMIS model. Details are provided in Section <a href="#S4.SS1" title="4.1 Distributed email learning under balanced data distribution ‣ 4 Results ‣ Evaluation of Federated Learning in Phishing Email Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.1</span></a>.</p>
</div>
</li>
<li id="S1.I1.ix3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span id="S1.I1.ix3.1.1.1" class="ltx_text ltx_font_bold">RQ3</span></span> 
<div id="S1.I1.ix3.p1" class="ltx_para">
<p id="S1.I1.ix3.p1.1" class="ltx_p"><span id="S1.I1.ix3.p1.1.1" class="ltx_text ltx_font_bold">(Communication overhead) What is the communication overhead resulting from FL?</span>
FL has a communication overhead as a trade-off to privacy, and it is only dependent on the model size. For example, we quantify the overhead per global epoch per client for THEMIS around 0.192 GB and BERT around 0.438 GB for all cases under our setting. We regard such overheads as not of particular concern for organizational level participants. Details are provided in Section <a href="#S4.SS1" title="4.1 Distributed email learning under balanced data distribution ‣ 4 Results ‣ Evaluation of Federated Learning in Phishing Email Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.1</span></a>.</p>
</div>
</li>
<li id="S1.I1.ix4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span id="S1.I1.ix4.1.1.1" class="ltx_text ltx_font_bold">RQ4</span></span> 
<div id="S1.I1.ix4.p1" class="ltx_para">
<p id="S1.I1.ix4.p1.1" class="ltx_p"><span id="S1.I1.ix4.p1.1.1" class="ltx_text ltx_font_bold">(Client-level perspectives in FL) Can a client leverage FL to improve its performance?</span>
We investigate client-level performances under both balanced and asymmetric data distribution in FL, considering the cases where clients are available with time in the training process, and the total email dataset increases with the addition of the new client. A fast convergence in the accuracy curve is observed with the THEMIS model. Details are in Section <a href="#S4.SS2" title="4.2 Client-level perspectives in FL ‣ 4 Results ‣ Evaluation of Federated Learning in Phishing Email Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.2</span></a>.</p>
</div>
</li>
<li id="S1.I1.ix5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span id="S1.I1.ix5.1.1.1" class="ltx_text ltx_font_bold">RQ5</span></span> 
<div id="S1.I1.ix5.p1" class="ltx_para">
<p id="S1.I1.ix5.p1.1" class="ltx_p"><span id="S1.I1.ix5.p1.1.1" class="ltx_text ltx_font_bold">(Asymmetric data distribution) How would FL perform under asymmetric data distribution among clients due to the variations in the local dataset’s size and the local phishing to legitimate sample ratio?</span></p>
</div>
<div id="S1.I1.ix5.p2" class="ltx_para">
<p id="S1.I1.ix5.p2.1" class="ltx_p">Our studies with the THEMIS model under 2, 5, and 10 clients suggest that FL performs well and similar over the asymmetric data distribution that is due to different local dataset sizes and the local phishing to legitimate sample ratio. Thus FL is resilient in these scenarios. Details are in Section <a href="#S4.SS3" title="4.3 Distributed email learning under asymmetric data distribution ‣ 4 Results ‣ Evaluation of Federated Learning in Phishing Email Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.3</span></a>.</p>
</div>
</li>
<li id="S1.I1.ix6" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span id="S1.I1.ix6.1.1.1" class="ltx_text ltx_font_bold">RQ6</span></span> 
<div id="S1.I1.ix6.p1" class="ltx_para">
<p id="S1.I1.ix6.p1.1" class="ltx_p"><span id="S1.I1.ix6.p1.1.1" class="ltx_text ltx_font_bold">(Asymmetric data distribution) How would FL perform under extreme dataset diversity among clients?</span>
Data asymmetry, in this case, is due to the class skewness and different dataset size (small to large) across the clients.
Our studies suggest that forming a best performing global model for all clients under FL is not straightforward. In addition, the local and global performances are model depended. Details are in Section <a href="#S4.SS4" title="4.4 Distributed email learning under an extreme asymmetric data distribution ‣ 4 Results ‣ Evaluation of Federated Learning in Phishing Email Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.4</span></a>.</p>
</div>
</li>
</ul>
</div>
</section>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span><span id="S2.1.1" class="ltx_text ltx_font_smallcaps">Background</span>
</h2>

<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span><span id="S2.SS1.1.1" class="ltx_text ltx_font_italic">Centralized learning</span>
</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">Centralized learning (CL) is normally performed by aggregating all available datasets (e.g., phishing and legitimate emails) at one central repository. Then it performs centralized machine learning on the aggregated dataset.
During the learning process, a modeler can access the raw data shared by one or more clients, thus making it unsuitable if the data is private such as emails. Besides, in the era of big data and deep learning, it is non-trivial to maintain the required resources, including storage and computation, in CL. Thus there is a rise in distributed learning, in particular, FL.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span><span id="S2.SS2.1.1" class="ltx_text ltx_font_italic">Federated learning</span>
</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.6" class="ltx_p">Federated learning (FL) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite> allows parallel deep learning training across distributed clients and pushes the computation to the edge devices (i.e., clients). Fig. <a href="#S2.F1" title="Figure 1 ‣ 2.2 Federated learning ‣ 2 Background ‣ Evaluation of Federated Learning in Phishing Email Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> illustrates an overview of FL. There are four exemplified clients with their local email datasets and one coordinating server.
Firstly, each client <math id="S2.SS2.p1.1.m1.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S2.SS2.p1.1.m1.1a"><mi id="S2.SS2.p1.1.m1.1.1" xref="S2.SS2.p1.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.1.m1.1b"><ci id="S2.SS2.p1.1.m1.1.1.cmml" xref="S2.SS2.p1.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.1.m1.1c">k</annotation></semantics></math>, <math id="S2.SS2.p1.2.m2.4" class="ltx_Math" alttext="k\in\{1,2,3,4\}" display="inline"><semantics id="S2.SS2.p1.2.m2.4a"><mrow id="S2.SS2.p1.2.m2.4.5" xref="S2.SS2.p1.2.m2.4.5.cmml"><mi id="S2.SS2.p1.2.m2.4.5.2" xref="S2.SS2.p1.2.m2.4.5.2.cmml">k</mi><mo id="S2.SS2.p1.2.m2.4.5.1" xref="S2.SS2.p1.2.m2.4.5.1.cmml">∈</mo><mrow id="S2.SS2.p1.2.m2.4.5.3.2" xref="S2.SS2.p1.2.m2.4.5.3.1.cmml"><mo stretchy="false" id="S2.SS2.p1.2.m2.4.5.3.2.1" xref="S2.SS2.p1.2.m2.4.5.3.1.cmml">{</mo><mn id="S2.SS2.p1.2.m2.1.1" xref="S2.SS2.p1.2.m2.1.1.cmml">1</mn><mo id="S2.SS2.p1.2.m2.4.5.3.2.2" xref="S2.SS2.p1.2.m2.4.5.3.1.cmml">,</mo><mn id="S2.SS2.p1.2.m2.2.2" xref="S2.SS2.p1.2.m2.2.2.cmml">2</mn><mo id="S2.SS2.p1.2.m2.4.5.3.2.3" xref="S2.SS2.p1.2.m2.4.5.3.1.cmml">,</mo><mn id="S2.SS2.p1.2.m2.3.3" xref="S2.SS2.p1.2.m2.3.3.cmml">3</mn><mo id="S2.SS2.p1.2.m2.4.5.3.2.4" xref="S2.SS2.p1.2.m2.4.5.3.1.cmml">,</mo><mn id="S2.SS2.p1.2.m2.4.4" xref="S2.SS2.p1.2.m2.4.4.cmml">4</mn><mo stretchy="false" id="S2.SS2.p1.2.m2.4.5.3.2.5" xref="S2.SS2.p1.2.m2.4.5.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.2.m2.4b"><apply id="S2.SS2.p1.2.m2.4.5.cmml" xref="S2.SS2.p1.2.m2.4.5"><in id="S2.SS2.p1.2.m2.4.5.1.cmml" xref="S2.SS2.p1.2.m2.4.5.1"></in><ci id="S2.SS2.p1.2.m2.4.5.2.cmml" xref="S2.SS2.p1.2.m2.4.5.2">𝑘</ci><set id="S2.SS2.p1.2.m2.4.5.3.1.cmml" xref="S2.SS2.p1.2.m2.4.5.3.2"><cn type="integer" id="S2.SS2.p1.2.m2.1.1.cmml" xref="S2.SS2.p1.2.m2.1.1">1</cn><cn type="integer" id="S2.SS2.p1.2.m2.2.2.cmml" xref="S2.SS2.p1.2.m2.2.2">2</cn><cn type="integer" id="S2.SS2.p1.2.m2.3.3.cmml" xref="S2.SS2.p1.2.m2.3.3">3</cn><cn type="integer" id="S2.SS2.p1.2.m2.4.4.cmml" xref="S2.SS2.p1.2.m2.4.4">4</cn></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.2.m2.4c">k\in\{1,2,3,4\}</annotation></semantics></math>, trains the model on their local email dataset <math id="S2.SS2.p1.3.m3.1" class="ltx_Math" alttext="D_{k}" display="inline"><semantics id="S2.SS2.p1.3.m3.1a"><msub id="S2.SS2.p1.3.m3.1.1" xref="S2.SS2.p1.3.m3.1.1.cmml"><mi id="S2.SS2.p1.3.m3.1.1.2" xref="S2.SS2.p1.3.m3.1.1.2.cmml">D</mi><mi id="S2.SS2.p1.3.m3.1.1.3" xref="S2.SS2.p1.3.m3.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.3.m3.1b"><apply id="S2.SS2.p1.3.m3.1.1.cmml" xref="S2.SS2.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S2.SS2.p1.3.m3.1.1.1.cmml" xref="S2.SS2.p1.3.m3.1.1">subscript</csymbol><ci id="S2.SS2.p1.3.m3.1.1.2.cmml" xref="S2.SS2.p1.3.m3.1.1.2">𝐷</ci><ci id="S2.SS2.p1.3.m3.1.1.3.cmml" xref="S2.SS2.p1.3.m3.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.3.m3.1c">D_{k}</annotation></semantics></math> and produce the local model <math id="S2.SS2.p1.4.m4.1" class="ltx_Math" alttext="W^{k}_{t}" display="inline"><semantics id="S2.SS2.p1.4.m4.1a"><msubsup id="S2.SS2.p1.4.m4.1.1" xref="S2.SS2.p1.4.m4.1.1.cmml"><mi id="S2.SS2.p1.4.m4.1.1.2.2" xref="S2.SS2.p1.4.m4.1.1.2.2.cmml">W</mi><mi id="S2.SS2.p1.4.m4.1.1.3" xref="S2.SS2.p1.4.m4.1.1.3.cmml">t</mi><mi id="S2.SS2.p1.4.m4.1.1.2.3" xref="S2.SS2.p1.4.m4.1.1.2.3.cmml">k</mi></msubsup><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.4.m4.1b"><apply id="S2.SS2.p1.4.m4.1.1.cmml" xref="S2.SS2.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S2.SS2.p1.4.m4.1.1.1.cmml" xref="S2.SS2.p1.4.m4.1.1">subscript</csymbol><apply id="S2.SS2.p1.4.m4.1.1.2.cmml" xref="S2.SS2.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S2.SS2.p1.4.m4.1.1.2.1.cmml" xref="S2.SS2.p1.4.m4.1.1">superscript</csymbol><ci id="S2.SS2.p1.4.m4.1.1.2.2.cmml" xref="S2.SS2.p1.4.m4.1.1.2.2">𝑊</ci><ci id="S2.SS2.p1.4.m4.1.1.2.3.cmml" xref="S2.SS2.p1.4.m4.1.1.2.3">𝑘</ci></apply><ci id="S2.SS2.p1.4.m4.1.1.3.cmml" xref="S2.SS2.p1.4.m4.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.4.m4.1c">W^{k}_{t}</annotation></semantics></math> at time instance <math id="S2.SS2.p1.5.m5.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S2.SS2.p1.5.m5.1a"><mi id="S2.SS2.p1.5.m5.1.1" xref="S2.SS2.p1.5.m5.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.5.m5.1b"><ci id="S2.SS2.p1.5.m5.1.1.cmml" xref="S2.SS2.p1.5.m5.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.5.m5.1c">t</annotation></semantics></math>. Secondly, all clients upload their local models to the server. Then the server performs the weighted averaging (i.e., aggregation) of the local models and updates the global model <math id="S2.SS2.p1.6.m6.1" class="ltx_Math" alttext="W_{t+1}" display="inline"><semantics id="S2.SS2.p1.6.m6.1a"><msub id="S2.SS2.p1.6.m6.1.1" xref="S2.SS2.p1.6.m6.1.1.cmml"><mi id="S2.SS2.p1.6.m6.1.1.2" xref="S2.SS2.p1.6.m6.1.1.2.cmml">W</mi><mrow id="S2.SS2.p1.6.m6.1.1.3" xref="S2.SS2.p1.6.m6.1.1.3.cmml"><mi id="S2.SS2.p1.6.m6.1.1.3.2" xref="S2.SS2.p1.6.m6.1.1.3.2.cmml">t</mi><mo id="S2.SS2.p1.6.m6.1.1.3.1" xref="S2.SS2.p1.6.m6.1.1.3.1.cmml">+</mo><mn id="S2.SS2.p1.6.m6.1.1.3.3" xref="S2.SS2.p1.6.m6.1.1.3.3.cmml">1</mn></mrow></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.6.m6.1b"><apply id="S2.SS2.p1.6.m6.1.1.cmml" xref="S2.SS2.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S2.SS2.p1.6.m6.1.1.1.cmml" xref="S2.SS2.p1.6.m6.1.1">subscript</csymbol><ci id="S2.SS2.p1.6.m6.1.1.2.cmml" xref="S2.SS2.p1.6.m6.1.1.2">𝑊</ci><apply id="S2.SS2.p1.6.m6.1.1.3.cmml" xref="S2.SS2.p1.6.m6.1.1.3"><plus id="S2.SS2.p1.6.m6.1.1.3.1.cmml" xref="S2.SS2.p1.6.m6.1.1.3.1"></plus><ci id="S2.SS2.p1.6.m6.1.1.3.2.cmml" xref="S2.SS2.p1.6.m6.1.1.3.2">𝑡</ci><cn type="integer" id="S2.SS2.p1.6.m6.1.1.3.3.cmml" xref="S2.SS2.p1.6.m6.1.1.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.6.m6.1c">W_{t+1}</annotation></semantics></math>. Finally, the global model is broadcast to all clients (model synchronization), and this completes the one round, known as one global epoch, of the FL process. This process continues until the model converges (see Algorithm <a href="#alg1" title="In 3.1 Datasets ‣ 3 Experimental setup ‣ Evaluation of Federated Learning in Phishing Email Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>). In FL, the server synchronizes the training process across the clients. Over the entire training process, only the models (i.e., model parameters) are transmitted between the clients and the server. Thus a client (e.g., financial institution) does not require to share their raw email data to the server (e.g., coordinated by an email analyzer) or any other clients during the training process. Thus the data are always local and kept confidential in FL.</p>
</div>
<figure id="S2.F1" class="ltx_figure"><img src="/html/2007.13300/assets/x1.png" id="S2.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="266" height="133" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>An overview of federated learning.</figcaption>
</figure>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span><span id="S3.1.1" class="ltx_text ltx_font_smallcaps">Experimental setup</span>
</h2>

<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span><span id="S3.SS1.1.1" class="ltx_text ltx_font_italic">Datasets</span>
</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">In this work, primarily, phishing and legitimate email samples are collected from three popular sources, namely First Security and Privacy Analytics Anti-Phishing Shared Task (IWSPA-AP) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>, Nazario’s phishing corpora (Nazario) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>, and Enron Email Dataset (Enron) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>. Besides, we consider phishing emails from CSIRO<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>https://www.csiro.au/</span></span></span> (private emails) and Phishbowl <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>.
The dataset contains email samples with both header<span id="footnote3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>Email header precedes the email body and contains information of the header fields, including <em id="footnote3.1" class="ltx_emph ltx_font_italic">To, Subject, Received, Content-Type, Return-Path,</em> and <em id="footnote3.2" class="ltx_emph ltx_font_italic">Authentication-Results.</em></span></span></span> and without header: IWSPA-AP has both types, whereas all email samples in Nazario and Enron have the header accompanied by the body, no header for CSIRO and Phishbowl emails. Overall, the data sources include Wikileaks archives, SpamAssassin, IT departments of different universities, synthetic emails created by Data engine <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>, Enron (emails generated by employees of Enron corporation), Nazario (personal collection), and private emails (CSIRO).
CSIRO emails are phishing emails reported by CSIRO staff between 2017 to 2020, and we manually labeled them to remove the spam.
Phishbowl emails are published by Cornell University, and we collected emails reported from April 2019 to January 2021. The emails on the website have a header but with partial fields or body only, so we consider the body only of these emails for our dataset.
To provide more insight into the email samples, we present some frequently appearing words in them as follows:</p>
<ul id="S3.I1" class="ltx_itemize">
<li id="S3.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i1.p1" class="ltx_para">
<p id="S3.I1.i1.p1.1" class="ltx_p">IWSPA-AP phishing email (a) with header includes <em id="S3.I1.i1.p1.1.1" class="ltx_emph ltx_font_italic">account, PayPal, please, eBay, link, security, update,bank, online,</em> and <em id="S3.I1.i1.p1.1.2" class="ltx_emph ltx_font_italic">information</em>, and (b) without header includes <em id="S3.I1.i1.p1.1.3" class="ltx_emph ltx_font_italic">text, account, email, please, information, click, team, online,</em> and <em id="S3.I1.i1.p1.1.4" class="ltx_emph ltx_font_italic">security</em>. IWSPA-AP legitimate email (a) with header includes <em id="S3.I1.i1.p1.1.5" class="ltx_emph ltx_font_italic">email, please, new, sent, party, people, Donald, state,</em> and <em id="S3.I1.i1.p1.1.6" class="ltx_emph ltx_font_italic">president</em>, and (b) without header includes <em id="S3.I1.i1.p1.1.7" class="ltx_emph ltx_font_italic">text, link, national, US, Trump,</em> and <em id="S3.I1.i1.p1.1.8" class="ltx_emph ltx_font_italic">democratic</em>.</p>
</div>
</li>
<li id="S3.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i2.p1" class="ltx_para">
<p id="S3.I1.i2.p1.1" class="ltx_p">Nazario includes <em id="S3.I1.i2.p1.1.1" class="ltx_emph ltx_font_italic">important, account, update, please, email, security, PayPal, eBay, bank, access, information, item, click, confirm,</em> and <em id="S3.I1.i2.p1.1.2" class="ltx_emph ltx_font_italic">service.</em></p>
</div>
</li>
<li id="S3.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i3.p1" class="ltx_para">
<p id="S3.I1.i3.p1.1" class="ltx_p">Enron includes <em id="S3.I1.i3.p1.1.1" class="ltx_emph ltx_font_italic">text, plain, subject, please, email, power, image, time, know, this, message, information,</em> and <em id="S3.I1.i3.p1.1.2" class="ltx_emph ltx_font_italic">energy.</em></p>
</div>
</li>
<li id="S3.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i4.p1" class="ltx_para">
<p id="S3.I1.i4.p1.1" class="ltx_p">CSIRO includes <em id="S3.I1.i4.p1.1.1" class="ltx_emph ltx_font_italic">shopping, parcel, invitation, payment, employee, webinar, survey, newsletter, program</em> and <em id="S3.I1.i4.p1.1.2" class="ltx_emph ltx_font_italic">workshop</em>.</p>
</div>
</li>
<li id="S3.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i5.p1" class="ltx_para">
<p id="S3.I1.i5.p1.1" class="ltx_p">Phishbowl includes <em id="S3.I1.i5.p1.1.1" class="ltx_emph ltx_font_italic">account, id, password, Cornell, upgrade, notice, administrator, message, job, server,</em> and <em id="S3.I1.i5.p1.1.2" class="ltx_emph ltx_font_italic">verify</em>.</p>
</div>
</li>
</ul>
</div>
<figure id="alg1" class="ltx_float ltx_algorithm">
<div id="alg1.19" class="ltx_listing ltx_lst_numbers_left ltx_listing">
<div id="alg1.19.20" class="ltx_listingline">
<span id="alg1.19.20.1" class="ltx_text" style="font-size:80%;"><span id="alg1.19.20.1.1" class="ltx_text ltx_font_bold">Input:</span> </span><span id="alg1.19.20.2" class="ltx_text" style="font-size:80%;">Email dataset</span>
</div>
<div id="alg1.19.21" class="ltx_listingline">
<span id="alg1.19.21.1" class="ltx_text" style="font-size:80%;">
</span><span id="alg1.19.21.2" class="ltx_text" style="font-size:80%;"><span id="alg1.19.21.2.1" class="ltx_text ltx_font_bold">Output:</span> </span><span id="alg1.19.21.3" class="ltx_text" style="font-size:80%;">Model performance (e.g., Accuracy, F1-score, and Precision)</span>
</div>
<div id="alg1.19.22" class="ltx_listingline">
<span id="alg1.19.22.1" class="ltx_text" style="font-size:80%;">
</span><span id="alg1.19.22.2" class="ltx_text ltx_font_typewriter" style="font-size:80%;">/* </span><span id="alg1.19.22.3" class="ltx_text ltx_font_typewriter" style="font-size:80%;">Server-side  */</span>
</div>
<div id="alg1.19.23" class="ltx_listingline">
<span id="alg1.19.23.1" class="ltx_text" style="font-size:80%;">

</span><span id="alg1.19.23.2" class="ltx_text ltx_font_bold" style="font-size:80%;">Server:</span><span id="alg1.19.23.3" class="ltx_text" style="font-size:80%;"> </span><em id="alg1.19.23.4" class="ltx_emph ltx_font_italic" style="font-size:80%;"></em>
</div>
<div id="alg1.2.2" class="ltx_listingline">
<span id="alg1.2.2.1" class="ltx_text" style="font-size:80%;">  </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span id="alg1.2.2.2" class="ltx_text" style="font-size:80%;">   </span><span id="alg1.2.2.3" class="ltx_text" style="font-size:80%;">
Initialize and send global model </span><math id="alg1.1.1.m1.1" class="ltx_Math" alttext="W_{t}" display="inline"><semantics id="alg1.1.1.m1.1a"><msub id="alg1.1.1.m1.1.1" xref="alg1.1.1.m1.1.1.cmml"><mi mathsize="80%" id="alg1.1.1.m1.1.1.2" xref="alg1.1.1.m1.1.1.2.cmml">W</mi><mi mathsize="80%" id="alg1.1.1.m1.1.1.3" xref="alg1.1.1.m1.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="alg1.1.1.m1.1b"><apply id="alg1.1.1.m1.1.1.cmml" xref="alg1.1.1.m1.1.1"><csymbol cd="ambiguous" id="alg1.1.1.m1.1.1.1.cmml" xref="alg1.1.1.m1.1.1">subscript</csymbol><ci id="alg1.1.1.m1.1.1.2.cmml" xref="alg1.1.1.m1.1.1.2">𝑊</ci><ci id="alg1.1.1.m1.1.1.3.cmml" xref="alg1.1.1.m1.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.1.1.m1.1c">W_{t}</annotation></semantics></math><span id="alg1.2.2.4" class="ltx_text" style="font-size:80%;"> to all </span><math id="alg1.2.2.m2.1" class="ltx_Math" alttext="K" display="inline"><semantics id="alg1.2.2.m2.1a"><mi mathsize="80%" id="alg1.2.2.m2.1.1" xref="alg1.2.2.m2.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="alg1.2.2.m2.1b"><ci id="alg1.2.2.m2.1.1.cmml" xref="alg1.2.2.m2.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.2.2.m2.1c">K</annotation></semantics></math><span id="alg1.2.2.5" class="ltx_text" style="font-size:80%;"> clients;</span>
</div>
<div id="alg1.19.24" class="ltx_listingline">
<span id="alg1.19.24.1" class="ltx_text" style="font-size:80%;">  </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span id="alg1.19.24.2" class="ltx_text" style="font-size:80%;">   </span><span id="alg1.19.24.3" class="ltx_text" style="font-size:80%;">
</span>
</div>
<div id="alg1.3.3" class="ltx_listingline">
<span id="alg1.3.3.2" class="ltx_text" style="font-size:80%;">  </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span id="alg1.3.3.3" class="ltx_text" style="font-size:80%;">   </span><span id="alg1.3.3.4" class="ltx_text ltx_font_bold" style="font-size:80%;">for</span><span id="alg1.3.3.5" class="ltx_text" style="font-size:80%;"> </span><em id="alg1.3.3.1" class="ltx_emph ltx_font_italic" style="font-size:80%;"><span id="alg1.3.3.1.1" class="ltx_text ltx_font_upright">epoch</span> <math id="alg1.3.3.1.m1.1" class="ltx_Math" alttext="e\in E" display="inline"><semantics id="alg1.3.3.1.m1.1a"><mrow id="alg1.3.3.1.m1.1.1" xref="alg1.3.3.1.m1.1.1.cmml"><mi id="alg1.3.3.1.m1.1.1.2" xref="alg1.3.3.1.m1.1.1.2.cmml">e</mi><mo id="alg1.3.3.1.m1.1.1.1" xref="alg1.3.3.1.m1.1.1.1.cmml">∈</mo><mi id="alg1.3.3.1.m1.1.1.3" xref="alg1.3.3.1.m1.1.1.3.cmml">E</mi></mrow><annotation-xml encoding="MathML-Content" id="alg1.3.3.1.m1.1b"><apply id="alg1.3.3.1.m1.1.1.cmml" xref="alg1.3.3.1.m1.1.1"><in id="alg1.3.3.1.m1.1.1.1.cmml" xref="alg1.3.3.1.m1.1.1.1"></in><ci id="alg1.3.3.1.m1.1.1.2.cmml" xref="alg1.3.3.1.m1.1.1.2">𝑒</ci><ci id="alg1.3.3.1.m1.1.1.3.cmml" xref="alg1.3.3.1.m1.1.1.3">𝐸</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.3.3.1.m1.1c">e\in E</annotation></semantics></math></em><span id="alg1.3.3.6" class="ltx_text" style="font-size:80%;"> </span><span id="alg1.3.3.7" class="ltx_text ltx_font_bold" style="font-size:80%;">do</span>
</div>
<div id="alg1.4.4" class="ltx_listingline">
<span id="alg1.4.4.2" class="ltx_text" style="font-size:80%;">  </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span id="alg1.4.4.3" class="ltx_text" style="font-size:80%;">     </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span id="alg1.4.4.4" class="ltx_text" style="font-size:80%;">   </span><span id="alg1.4.4.5" class="ltx_text" style="font-size:80%;">
</span><span id="alg1.4.4.6" class="ltx_text ltx_font_bold" style="font-size:80%;">for</span><span id="alg1.4.4.7" class="ltx_text" style="font-size:80%;"> </span><em id="alg1.4.4.1" class="ltx_emph" style="font-size:80%;">each client <math id="alg1.4.4.1.1.m1.4" class="ltx_Math" alttext="k\in\{1,2,\dots,K\}" display="inline"><semantics id="alg1.4.4.1.1.m1.4a"><mrow id="alg1.4.4.1.1.m1.4.5" xref="alg1.4.4.1.1.m1.4.5.cmml"><mi id="alg1.4.4.1.1.m1.4.5.2" xref="alg1.4.4.1.1.m1.4.5.2.cmml">k</mi><mo id="alg1.4.4.1.1.m1.4.5.1" xref="alg1.4.4.1.1.m1.4.5.1.cmml">∈</mo><mrow id="alg1.4.4.1.1.m1.4.5.3.2" xref="alg1.4.4.1.1.m1.4.5.3.1.cmml"><mo stretchy="false" id="alg1.4.4.1.1.m1.4.5.3.2.1" xref="alg1.4.4.1.1.m1.4.5.3.1.cmml">{</mo><mn id="alg1.4.4.1.1.m1.1.1" xref="alg1.4.4.1.1.m1.1.1.cmml">1</mn><mo id="alg1.4.4.1.1.m1.4.5.3.2.2" xref="alg1.4.4.1.1.m1.4.5.3.1.cmml">,</mo><mn id="alg1.4.4.1.1.m1.2.2" xref="alg1.4.4.1.1.m1.2.2.cmml">2</mn><mo id="alg1.4.4.1.1.m1.4.5.3.2.3" xref="alg1.4.4.1.1.m1.4.5.3.1.cmml">,</mo><mi mathvariant="normal" id="alg1.4.4.1.1.m1.3.3" xref="alg1.4.4.1.1.m1.3.3.cmml">…</mi><mo id="alg1.4.4.1.1.m1.4.5.3.2.4" xref="alg1.4.4.1.1.m1.4.5.3.1.cmml">,</mo><mi id="alg1.4.4.1.1.m1.4.4" xref="alg1.4.4.1.1.m1.4.4.cmml">K</mi><mo stretchy="false" id="alg1.4.4.1.1.m1.4.5.3.2.5" xref="alg1.4.4.1.1.m1.4.5.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.4.4.1.1.m1.4b"><apply id="alg1.4.4.1.1.m1.4.5.cmml" xref="alg1.4.4.1.1.m1.4.5"><in id="alg1.4.4.1.1.m1.4.5.1.cmml" xref="alg1.4.4.1.1.m1.4.5.1"></in><ci id="alg1.4.4.1.1.m1.4.5.2.cmml" xref="alg1.4.4.1.1.m1.4.5.2">𝑘</ci><set id="alg1.4.4.1.1.m1.4.5.3.1.cmml" xref="alg1.4.4.1.1.m1.4.5.3.2"><cn type="integer" id="alg1.4.4.1.1.m1.1.1.cmml" xref="alg1.4.4.1.1.m1.1.1">1</cn><cn type="integer" id="alg1.4.4.1.1.m1.2.2.cmml" xref="alg1.4.4.1.1.m1.2.2">2</cn><ci id="alg1.4.4.1.1.m1.3.3.cmml" xref="alg1.4.4.1.1.m1.3.3">…</ci><ci id="alg1.4.4.1.1.m1.4.4.cmml" xref="alg1.4.4.1.1.m1.4.4">𝐾</ci></set></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.4.4.1.1.m1.4c">k\in\{1,2,\dots,K\}</annotation></semantics></math> in parallel</em><span id="alg1.4.4.8" class="ltx_text" style="font-size:80%;"> </span><span id="alg1.4.4.9" class="ltx_text ltx_font_bold" style="font-size:80%;">do</span>
</div>
<div id="alg1.5.5" class="ltx_listingline">
<span id="alg1.5.5.1" class="ltx_text" style="font-size:80%;">  </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span id="alg1.5.5.2" class="ltx_text" style="font-size:80%;">     </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span id="alg1.5.5.3" class="ltx_text" style="font-size:80%;">     </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span id="alg1.5.5.4" class="ltx_text" style="font-size:80%;">   </span><span id="alg1.5.5.5" class="ltx_text" style="font-size:80%;">
</span><math id="alg1.5.5.m1.1" class="ltx_Math" alttext="W_{t}^{k}\leftarrow\textup{ClientUpdate}(W_{t}^{k})" display="inline"><semantics id="alg1.5.5.m1.1a"><mrow id="alg1.5.5.m1.1.1" xref="alg1.5.5.m1.1.1.cmml"><msubsup id="alg1.5.5.m1.1.1.3" xref="alg1.5.5.m1.1.1.3.cmml"><mi mathsize="80%" id="alg1.5.5.m1.1.1.3.2.2" xref="alg1.5.5.m1.1.1.3.2.2.cmml">W</mi><mi mathsize="80%" id="alg1.5.5.m1.1.1.3.2.3" xref="alg1.5.5.m1.1.1.3.2.3.cmml">t</mi><mi mathsize="80%" id="alg1.5.5.m1.1.1.3.3" xref="alg1.5.5.m1.1.1.3.3.cmml">k</mi></msubsup><mo mathsize="80%" stretchy="false" id="alg1.5.5.m1.1.1.2" xref="alg1.5.5.m1.1.1.2.cmml">←</mo><mrow id="alg1.5.5.m1.1.1.1" xref="alg1.5.5.m1.1.1.1.cmml"><mtext mathsize="80%" id="alg1.5.5.m1.1.1.1.3" xref="alg1.5.5.m1.1.1.1.3a.cmml">ClientUpdate</mtext><mo lspace="0em" rspace="0em" id="alg1.5.5.m1.1.1.1.2" xref="alg1.5.5.m1.1.1.1.2.cmml">​</mo><mrow id="alg1.5.5.m1.1.1.1.1.1" xref="alg1.5.5.m1.1.1.1.1.1.1.cmml"><mo maxsize="80%" minsize="80%" id="alg1.5.5.m1.1.1.1.1.1.2" xref="alg1.5.5.m1.1.1.1.1.1.1.cmml">(</mo><msubsup id="alg1.5.5.m1.1.1.1.1.1.1" xref="alg1.5.5.m1.1.1.1.1.1.1.cmml"><mi mathsize="80%" id="alg1.5.5.m1.1.1.1.1.1.1.2.2" xref="alg1.5.5.m1.1.1.1.1.1.1.2.2.cmml">W</mi><mi mathsize="80%" id="alg1.5.5.m1.1.1.1.1.1.1.2.3" xref="alg1.5.5.m1.1.1.1.1.1.1.2.3.cmml">t</mi><mi mathsize="80%" id="alg1.5.5.m1.1.1.1.1.1.1.3" xref="alg1.5.5.m1.1.1.1.1.1.1.3.cmml">k</mi></msubsup><mo maxsize="80%" minsize="80%" id="alg1.5.5.m1.1.1.1.1.1.3" xref="alg1.5.5.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.5.5.m1.1b"><apply id="alg1.5.5.m1.1.1.cmml" xref="alg1.5.5.m1.1.1"><ci id="alg1.5.5.m1.1.1.2.cmml" xref="alg1.5.5.m1.1.1.2">←</ci><apply id="alg1.5.5.m1.1.1.3.cmml" xref="alg1.5.5.m1.1.1.3"><csymbol cd="ambiguous" id="alg1.5.5.m1.1.1.3.1.cmml" xref="alg1.5.5.m1.1.1.3">superscript</csymbol><apply id="alg1.5.5.m1.1.1.3.2.cmml" xref="alg1.5.5.m1.1.1.3"><csymbol cd="ambiguous" id="alg1.5.5.m1.1.1.3.2.1.cmml" xref="alg1.5.5.m1.1.1.3">subscript</csymbol><ci id="alg1.5.5.m1.1.1.3.2.2.cmml" xref="alg1.5.5.m1.1.1.3.2.2">𝑊</ci><ci id="alg1.5.5.m1.1.1.3.2.3.cmml" xref="alg1.5.5.m1.1.1.3.2.3">𝑡</ci></apply><ci id="alg1.5.5.m1.1.1.3.3.cmml" xref="alg1.5.5.m1.1.1.3.3">𝑘</ci></apply><apply id="alg1.5.5.m1.1.1.1.cmml" xref="alg1.5.5.m1.1.1.1"><times id="alg1.5.5.m1.1.1.1.2.cmml" xref="alg1.5.5.m1.1.1.1.2"></times><ci id="alg1.5.5.m1.1.1.1.3a.cmml" xref="alg1.5.5.m1.1.1.1.3"><mtext mathsize="80%" id="alg1.5.5.m1.1.1.1.3.cmml" xref="alg1.5.5.m1.1.1.1.3">ClientUpdate</mtext></ci><apply id="alg1.5.5.m1.1.1.1.1.1.1.cmml" xref="alg1.5.5.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="alg1.5.5.m1.1.1.1.1.1.1.1.cmml" xref="alg1.5.5.m1.1.1.1.1.1">superscript</csymbol><apply id="alg1.5.5.m1.1.1.1.1.1.1.2.cmml" xref="alg1.5.5.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="alg1.5.5.m1.1.1.1.1.1.1.2.1.cmml" xref="alg1.5.5.m1.1.1.1.1.1">subscript</csymbol><ci id="alg1.5.5.m1.1.1.1.1.1.1.2.2.cmml" xref="alg1.5.5.m1.1.1.1.1.1.1.2.2">𝑊</ci><ci id="alg1.5.5.m1.1.1.1.1.1.1.2.3.cmml" xref="alg1.5.5.m1.1.1.1.1.1.1.2.3">𝑡</ci></apply><ci id="alg1.5.5.m1.1.1.1.1.1.1.3.cmml" xref="alg1.5.5.m1.1.1.1.1.1.1.3">𝑘</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.5.5.m1.1c">W_{t}^{k}\leftarrow\textup{ClientUpdate}(W_{t}^{k})</annotation></semantics></math><span id="alg1.5.5.6" class="ltx_text" style="font-size:80%;"> ;</span>
</div>
<div id="alg1.19.25" class="ltx_listingline">
<span id="alg1.19.25.1" class="ltx_text" style="font-size:80%;">  </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span id="alg1.19.25.2" class="ltx_text" style="font-size:80%;">     </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span id="alg1.19.25.3" class="ltx_text" style="font-size:80%;">     </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span id="alg1.19.25.4" class="ltx_text" style="font-size:80%;">   </span><span id="alg1.19.25.5" class="ltx_text" style="font-size:80%;">  </span><span id="alg1.19.25.6" class="ltx_text ltx_font_typewriter" style="font-size:80%;">// </span><span id="alg1.19.25.7" class="ltx_text ltx_font_typewriter" style="font-size:80%;">local updates</span>
</div>
<div id="alg1.19.26" class="ltx_listingline">
<span id="alg1.19.26.1" class="ltx_text" style="font-size:80%;">  </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span id="alg1.19.26.2" class="ltx_text" style="font-size:80%;">     </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span id="alg1.19.26.3" class="ltx_text" style="font-size:80%;">     </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span id="alg1.19.26.4" class="ltx_text" style="font-size:80%;">   </span><span id="alg1.19.26.5" class="ltx_text" style="font-size:80%;">
</span>
</div>
<div id="alg1.6.6" class="ltx_listingline">
<span id="alg1.6.6.1" class="ltx_text" style="font-size:80%;">  </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span id="alg1.6.6.2" class="ltx_text" style="font-size:80%;">     </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span id="alg1.6.6.3" class="ltx_text" style="font-size:80%;">   </span><span id="alg1.6.6.4" class="ltx_text" style="font-size:80%;">Perform weighted averaging and update the global model: </span><math id="alg1.6.6.m1.2" class="ltx_Math" alttext="W_{t+1}\leftarrow\sum_{k=1}^{K}\frac{n_{k}}{n}W_{t}^{k},\quad n=\sum_{k}n_{k}" display="inline"><semantics id="alg1.6.6.m1.2a"><mrow id="alg1.6.6.m1.2.2.2" xref="alg1.6.6.m1.2.2.3.cmml"><mrow id="alg1.6.6.m1.1.1.1.1" xref="alg1.6.6.m1.1.1.1.1.cmml"><msub id="alg1.6.6.m1.1.1.1.1.2" xref="alg1.6.6.m1.1.1.1.1.2.cmml"><mi mathsize="80%" id="alg1.6.6.m1.1.1.1.1.2.2" xref="alg1.6.6.m1.1.1.1.1.2.2.cmml">W</mi><mrow id="alg1.6.6.m1.1.1.1.1.2.3" xref="alg1.6.6.m1.1.1.1.1.2.3.cmml"><mi mathsize="80%" id="alg1.6.6.m1.1.1.1.1.2.3.2" xref="alg1.6.6.m1.1.1.1.1.2.3.2.cmml">t</mi><mo mathsize="80%" id="alg1.6.6.m1.1.1.1.1.2.3.1" xref="alg1.6.6.m1.1.1.1.1.2.3.1.cmml">+</mo><mn mathsize="80%" id="alg1.6.6.m1.1.1.1.1.2.3.3" xref="alg1.6.6.m1.1.1.1.1.2.3.3.cmml">1</mn></mrow></msub><mo mathsize="80%" rspace="0.111em" stretchy="false" id="alg1.6.6.m1.1.1.1.1.1" xref="alg1.6.6.m1.1.1.1.1.1.cmml">←</mo><mrow id="alg1.6.6.m1.1.1.1.1.3" xref="alg1.6.6.m1.1.1.1.1.3.cmml"><msubsup id="alg1.6.6.m1.1.1.1.1.3.1" xref="alg1.6.6.m1.1.1.1.1.3.1.cmml"><mo maxsize="80%" minsize="80%" stretchy="true" id="alg1.6.6.m1.1.1.1.1.3.1.2.2" xref="alg1.6.6.m1.1.1.1.1.3.1.2.2.cmml">∑</mo><mrow id="alg1.6.6.m1.1.1.1.1.3.1.2.3" xref="alg1.6.6.m1.1.1.1.1.3.1.2.3.cmml"><mi mathsize="80%" id="alg1.6.6.m1.1.1.1.1.3.1.2.3.2" xref="alg1.6.6.m1.1.1.1.1.3.1.2.3.2.cmml">k</mi><mo mathsize="80%" id="alg1.6.6.m1.1.1.1.1.3.1.2.3.1" xref="alg1.6.6.m1.1.1.1.1.3.1.2.3.1.cmml">=</mo><mn mathsize="80%" id="alg1.6.6.m1.1.1.1.1.3.1.2.3.3" xref="alg1.6.6.m1.1.1.1.1.3.1.2.3.3.cmml">1</mn></mrow><mi mathsize="80%" id="alg1.6.6.m1.1.1.1.1.3.1.3" xref="alg1.6.6.m1.1.1.1.1.3.1.3.cmml">K</mi></msubsup><mrow id="alg1.6.6.m1.1.1.1.1.3.2" xref="alg1.6.6.m1.1.1.1.1.3.2.cmml"><mfrac id="alg1.6.6.m1.1.1.1.1.3.2.2" xref="alg1.6.6.m1.1.1.1.1.3.2.2.cmml"><msub id="alg1.6.6.m1.1.1.1.1.3.2.2.2" xref="alg1.6.6.m1.1.1.1.1.3.2.2.2.cmml"><mi mathsize="80%" id="alg1.6.6.m1.1.1.1.1.3.2.2.2.2" xref="alg1.6.6.m1.1.1.1.1.3.2.2.2.2.cmml">n</mi><mi mathsize="80%" id="alg1.6.6.m1.1.1.1.1.3.2.2.2.3" xref="alg1.6.6.m1.1.1.1.1.3.2.2.2.3.cmml">k</mi></msub><mi mathsize="80%" id="alg1.6.6.m1.1.1.1.1.3.2.2.3" xref="alg1.6.6.m1.1.1.1.1.3.2.2.3.cmml">n</mi></mfrac><mo lspace="0em" rspace="0em" id="alg1.6.6.m1.1.1.1.1.3.2.1" xref="alg1.6.6.m1.1.1.1.1.3.2.1.cmml">​</mo><msubsup id="alg1.6.6.m1.1.1.1.1.3.2.3" xref="alg1.6.6.m1.1.1.1.1.3.2.3.cmml"><mi mathsize="80%" id="alg1.6.6.m1.1.1.1.1.3.2.3.2.2" xref="alg1.6.6.m1.1.1.1.1.3.2.3.2.2.cmml">W</mi><mi mathsize="80%" id="alg1.6.6.m1.1.1.1.1.3.2.3.2.3" xref="alg1.6.6.m1.1.1.1.1.3.2.3.2.3.cmml">t</mi><mi mathsize="80%" id="alg1.6.6.m1.1.1.1.1.3.2.3.3" xref="alg1.6.6.m1.1.1.1.1.3.2.3.3.cmml">k</mi></msubsup></mrow></mrow></mrow><mo mathsize="80%" rspace="0.967em" id="alg1.6.6.m1.2.2.2.3" xref="alg1.6.6.m1.2.2.3a.cmml">,</mo><mrow id="alg1.6.6.m1.2.2.2.2" xref="alg1.6.6.m1.2.2.2.2.cmml"><mi mathsize="80%" id="alg1.6.6.m1.2.2.2.2.2" xref="alg1.6.6.m1.2.2.2.2.2.cmml">n</mi><mo mathsize="80%" rspace="0.111em" id="alg1.6.6.m1.2.2.2.2.1" xref="alg1.6.6.m1.2.2.2.2.1.cmml">=</mo><mrow id="alg1.6.6.m1.2.2.2.2.3" xref="alg1.6.6.m1.2.2.2.2.3.cmml"><msub id="alg1.6.6.m1.2.2.2.2.3.1" xref="alg1.6.6.m1.2.2.2.2.3.1.cmml"><mo maxsize="80%" minsize="80%" stretchy="true" id="alg1.6.6.m1.2.2.2.2.3.1.2" xref="alg1.6.6.m1.2.2.2.2.3.1.2.cmml">∑</mo><mi mathsize="80%" id="alg1.6.6.m1.2.2.2.2.3.1.3" xref="alg1.6.6.m1.2.2.2.2.3.1.3.cmml">k</mi></msub><msub id="alg1.6.6.m1.2.2.2.2.3.2" xref="alg1.6.6.m1.2.2.2.2.3.2.cmml"><mi mathsize="80%" id="alg1.6.6.m1.2.2.2.2.3.2.2" xref="alg1.6.6.m1.2.2.2.2.3.2.2.cmml">n</mi><mi mathsize="80%" id="alg1.6.6.m1.2.2.2.2.3.2.3" xref="alg1.6.6.m1.2.2.2.2.3.2.3.cmml">k</mi></msub></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.6.6.m1.2b"><apply id="alg1.6.6.m1.2.2.3.cmml" xref="alg1.6.6.m1.2.2.2"><csymbol cd="ambiguous" id="alg1.6.6.m1.2.2.3a.cmml" xref="alg1.6.6.m1.2.2.2.3">formulae-sequence</csymbol><apply id="alg1.6.6.m1.1.1.1.1.cmml" xref="alg1.6.6.m1.1.1.1.1"><ci id="alg1.6.6.m1.1.1.1.1.1.cmml" xref="alg1.6.6.m1.1.1.1.1.1">←</ci><apply id="alg1.6.6.m1.1.1.1.1.2.cmml" xref="alg1.6.6.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="alg1.6.6.m1.1.1.1.1.2.1.cmml" xref="alg1.6.6.m1.1.1.1.1.2">subscript</csymbol><ci id="alg1.6.6.m1.1.1.1.1.2.2.cmml" xref="alg1.6.6.m1.1.1.1.1.2.2">𝑊</ci><apply id="alg1.6.6.m1.1.1.1.1.2.3.cmml" xref="alg1.6.6.m1.1.1.1.1.2.3"><plus id="alg1.6.6.m1.1.1.1.1.2.3.1.cmml" xref="alg1.6.6.m1.1.1.1.1.2.3.1"></plus><ci id="alg1.6.6.m1.1.1.1.1.2.3.2.cmml" xref="alg1.6.6.m1.1.1.1.1.2.3.2">𝑡</ci><cn type="integer" id="alg1.6.6.m1.1.1.1.1.2.3.3.cmml" xref="alg1.6.6.m1.1.1.1.1.2.3.3">1</cn></apply></apply><apply id="alg1.6.6.m1.1.1.1.1.3.cmml" xref="alg1.6.6.m1.1.1.1.1.3"><apply id="alg1.6.6.m1.1.1.1.1.3.1.cmml" xref="alg1.6.6.m1.1.1.1.1.3.1"><csymbol cd="ambiguous" id="alg1.6.6.m1.1.1.1.1.3.1.1.cmml" xref="alg1.6.6.m1.1.1.1.1.3.1">superscript</csymbol><apply id="alg1.6.6.m1.1.1.1.1.3.1.2.cmml" xref="alg1.6.6.m1.1.1.1.1.3.1"><csymbol cd="ambiguous" id="alg1.6.6.m1.1.1.1.1.3.1.2.1.cmml" xref="alg1.6.6.m1.1.1.1.1.3.1">subscript</csymbol><sum id="alg1.6.6.m1.1.1.1.1.3.1.2.2.cmml" xref="alg1.6.6.m1.1.1.1.1.3.1.2.2"></sum><apply id="alg1.6.6.m1.1.1.1.1.3.1.2.3.cmml" xref="alg1.6.6.m1.1.1.1.1.3.1.2.3"><eq id="alg1.6.6.m1.1.1.1.1.3.1.2.3.1.cmml" xref="alg1.6.6.m1.1.1.1.1.3.1.2.3.1"></eq><ci id="alg1.6.6.m1.1.1.1.1.3.1.2.3.2.cmml" xref="alg1.6.6.m1.1.1.1.1.3.1.2.3.2">𝑘</ci><cn type="integer" id="alg1.6.6.m1.1.1.1.1.3.1.2.3.3.cmml" xref="alg1.6.6.m1.1.1.1.1.3.1.2.3.3">1</cn></apply></apply><ci id="alg1.6.6.m1.1.1.1.1.3.1.3.cmml" xref="alg1.6.6.m1.1.1.1.1.3.1.3">𝐾</ci></apply><apply id="alg1.6.6.m1.1.1.1.1.3.2.cmml" xref="alg1.6.6.m1.1.1.1.1.3.2"><times id="alg1.6.6.m1.1.1.1.1.3.2.1.cmml" xref="alg1.6.6.m1.1.1.1.1.3.2.1"></times><apply id="alg1.6.6.m1.1.1.1.1.3.2.2.cmml" xref="alg1.6.6.m1.1.1.1.1.3.2.2"><divide id="alg1.6.6.m1.1.1.1.1.3.2.2.1.cmml" xref="alg1.6.6.m1.1.1.1.1.3.2.2"></divide><apply id="alg1.6.6.m1.1.1.1.1.3.2.2.2.cmml" xref="alg1.6.6.m1.1.1.1.1.3.2.2.2"><csymbol cd="ambiguous" id="alg1.6.6.m1.1.1.1.1.3.2.2.2.1.cmml" xref="alg1.6.6.m1.1.1.1.1.3.2.2.2">subscript</csymbol><ci id="alg1.6.6.m1.1.1.1.1.3.2.2.2.2.cmml" xref="alg1.6.6.m1.1.1.1.1.3.2.2.2.2">𝑛</ci><ci id="alg1.6.6.m1.1.1.1.1.3.2.2.2.3.cmml" xref="alg1.6.6.m1.1.1.1.1.3.2.2.2.3">𝑘</ci></apply><ci id="alg1.6.6.m1.1.1.1.1.3.2.2.3.cmml" xref="alg1.6.6.m1.1.1.1.1.3.2.2.3">𝑛</ci></apply><apply id="alg1.6.6.m1.1.1.1.1.3.2.3.cmml" xref="alg1.6.6.m1.1.1.1.1.3.2.3"><csymbol cd="ambiguous" id="alg1.6.6.m1.1.1.1.1.3.2.3.1.cmml" xref="alg1.6.6.m1.1.1.1.1.3.2.3">superscript</csymbol><apply id="alg1.6.6.m1.1.1.1.1.3.2.3.2.cmml" xref="alg1.6.6.m1.1.1.1.1.3.2.3"><csymbol cd="ambiguous" id="alg1.6.6.m1.1.1.1.1.3.2.3.2.1.cmml" xref="alg1.6.6.m1.1.1.1.1.3.2.3">subscript</csymbol><ci id="alg1.6.6.m1.1.1.1.1.3.2.3.2.2.cmml" xref="alg1.6.6.m1.1.1.1.1.3.2.3.2.2">𝑊</ci><ci id="alg1.6.6.m1.1.1.1.1.3.2.3.2.3.cmml" xref="alg1.6.6.m1.1.1.1.1.3.2.3.2.3">𝑡</ci></apply><ci id="alg1.6.6.m1.1.1.1.1.3.2.3.3.cmml" xref="alg1.6.6.m1.1.1.1.1.3.2.3.3">𝑘</ci></apply></apply></apply></apply><apply id="alg1.6.6.m1.2.2.2.2.cmml" xref="alg1.6.6.m1.2.2.2.2"><eq id="alg1.6.6.m1.2.2.2.2.1.cmml" xref="alg1.6.6.m1.2.2.2.2.1"></eq><ci id="alg1.6.6.m1.2.2.2.2.2.cmml" xref="alg1.6.6.m1.2.2.2.2.2">𝑛</ci><apply id="alg1.6.6.m1.2.2.2.2.3.cmml" xref="alg1.6.6.m1.2.2.2.2.3"><apply id="alg1.6.6.m1.2.2.2.2.3.1.cmml" xref="alg1.6.6.m1.2.2.2.2.3.1"><csymbol cd="ambiguous" id="alg1.6.6.m1.2.2.2.2.3.1.1.cmml" xref="alg1.6.6.m1.2.2.2.2.3.1">subscript</csymbol><sum id="alg1.6.6.m1.2.2.2.2.3.1.2.cmml" xref="alg1.6.6.m1.2.2.2.2.3.1.2"></sum><ci id="alg1.6.6.m1.2.2.2.2.3.1.3.cmml" xref="alg1.6.6.m1.2.2.2.2.3.1.3">𝑘</ci></apply><apply id="alg1.6.6.m1.2.2.2.2.3.2.cmml" xref="alg1.6.6.m1.2.2.2.2.3.2"><csymbol cd="ambiguous" id="alg1.6.6.m1.2.2.2.2.3.2.1.cmml" xref="alg1.6.6.m1.2.2.2.2.3.2">subscript</csymbol><ci id="alg1.6.6.m1.2.2.2.2.3.2.2.cmml" xref="alg1.6.6.m1.2.2.2.2.3.2.2">𝑛</ci><ci id="alg1.6.6.m1.2.2.2.2.3.2.3.cmml" xref="alg1.6.6.m1.2.2.2.2.3.2.3">𝑘</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.6.6.m1.2c">W_{t+1}\leftarrow\sum_{k=1}^{K}\frac{n_{k}}{n}W_{t}^{k},\quad n=\sum_{k}n_{k}</annotation></semantics></math><span id="alg1.6.6.5" class="ltx_text" style="font-size:80%;">;</span>
</div>
<div id="alg1.19.27" class="ltx_listingline">
<span id="alg1.19.27.1" class="ltx_text" style="font-size:80%;">  </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span id="alg1.19.27.2" class="ltx_text" style="font-size:80%;">     </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span id="alg1.19.27.3" class="ltx_text" style="font-size:80%;">   </span><span id="alg1.19.27.4" class="ltx_text" style="font-size:80%;">
</span>
</div>
<div id="alg1.7.7" class="ltx_listingline">
<span id="alg1.7.7.1" class="ltx_text" style="font-size:80%;">  </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span id="alg1.7.7.2" class="ltx_text" style="font-size:80%;">     </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span id="alg1.7.7.3" class="ltx_text" style="font-size:80%;">   </span><span id="alg1.7.7.4" class="ltx_text" style="font-size:80%;">Send the updated global model </span><math id="alg1.7.7.m1.1" class="ltx_Math" alttext="W_{t+1}" display="inline"><semantics id="alg1.7.7.m1.1a"><msub id="alg1.7.7.m1.1.1" xref="alg1.7.7.m1.1.1.cmml"><mi mathsize="80%" id="alg1.7.7.m1.1.1.2" xref="alg1.7.7.m1.1.1.2.cmml">W</mi><mrow id="alg1.7.7.m1.1.1.3" xref="alg1.7.7.m1.1.1.3.cmml"><mi mathsize="80%" id="alg1.7.7.m1.1.1.3.2" xref="alg1.7.7.m1.1.1.3.2.cmml">t</mi><mo mathsize="80%" id="alg1.7.7.m1.1.1.3.1" xref="alg1.7.7.m1.1.1.3.1.cmml">+</mo><mn mathsize="80%" id="alg1.7.7.m1.1.1.3.3" xref="alg1.7.7.m1.1.1.3.3.cmml">1</mn></mrow></msub><annotation-xml encoding="MathML-Content" id="alg1.7.7.m1.1b"><apply id="alg1.7.7.m1.1.1.cmml" xref="alg1.7.7.m1.1.1"><csymbol cd="ambiguous" id="alg1.7.7.m1.1.1.1.cmml" xref="alg1.7.7.m1.1.1">subscript</csymbol><ci id="alg1.7.7.m1.1.1.2.cmml" xref="alg1.7.7.m1.1.1.2">𝑊</ci><apply id="alg1.7.7.m1.1.1.3.cmml" xref="alg1.7.7.m1.1.1.3"><plus id="alg1.7.7.m1.1.1.3.1.cmml" xref="alg1.7.7.m1.1.1.3.1"></plus><ci id="alg1.7.7.m1.1.1.3.2.cmml" xref="alg1.7.7.m1.1.1.3.2">𝑡</ci><cn type="integer" id="alg1.7.7.m1.1.1.3.3.cmml" xref="alg1.7.7.m1.1.1.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.7.7.m1.1c">W_{t+1}</annotation></semantics></math><span id="alg1.7.7.5" class="ltx_text" style="font-size:80%;"> to all clients;</span>
</div>
<div id="alg1.19.28" class="ltx_listingline">
<span id="alg1.19.28.1" class="ltx_text" style="font-size:80%;">  </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span id="alg1.19.28.2" class="ltx_text" style="font-size:80%;">     </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span id="alg1.19.28.3" class="ltx_text" style="font-size:80%;">   </span><span id="alg1.19.28.4" class="ltx_text" style="font-size:80%;">
</span>
</div>
<div id="alg1.19.29" class="ltx_listingline">
<span id="alg1.19.29.1" class="ltx_text" style="font-size:80%;">  </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span id="alg1.19.29.2" class="ltx_text" style="font-size:80%;">   </span>
</div>
<div id="alg1.8.8" class="ltx_listingline">
<span id="alg1.8.8.2" class="ltx_text" style="font-size:80%;">
</span><span id="alg1.8.8.3" class="ltx_text ltx_font_typewriter" style="font-size:80%;">/* </span><span id="alg1.8.8.1" class="ltx_text ltx_font_typewriter" style="font-size:80%;">Client-side at each client <math id="alg1.8.8.1.m1.1" class="ltx_Math" alttext="k" display="inline"><semantics id="alg1.8.8.1.m1.1a"><mi id="alg1.8.8.1.m1.1.1" xref="alg1.8.8.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="alg1.8.8.1.m1.1b"><ci id="alg1.8.8.1.m1.1.1.cmml" xref="alg1.8.8.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.8.8.1.m1.1c">k</annotation></semantics></math>  */</span>
</div>
<div id="alg1.9.9" class="ltx_listingline">
<span id="alg1.9.9.2" class="ltx_text" style="font-size:80%;">

</span><span id="alg1.9.9.1" class="ltx_text ltx_font_bold" style="font-size:80%;">ClientUpdate<math id="alg1.9.9.1.m1.1" class="ltx_Math" alttext="(W_{t}^{k})" display="inline"><semantics id="alg1.9.9.1.m1.1a"><mrow id="alg1.9.9.1.m1.1.1.1" xref="alg1.9.9.1.m1.1.1.1.1.cmml"><mo stretchy="false" id="alg1.9.9.1.m1.1.1.1.2" xref="alg1.9.9.1.m1.1.1.1.1.cmml">(</mo><msubsup id="alg1.9.9.1.m1.1.1.1.1" xref="alg1.9.9.1.m1.1.1.1.1.cmml"><mi id="alg1.9.9.1.m1.1.1.1.1.2.2" xref="alg1.9.9.1.m1.1.1.1.1.2.2.cmml">W</mi><mi id="alg1.9.9.1.m1.1.1.1.1.2.3" xref="alg1.9.9.1.m1.1.1.1.1.2.3.cmml">t</mi><mi id="alg1.9.9.1.m1.1.1.1.1.3" xref="alg1.9.9.1.m1.1.1.1.1.3.cmml">k</mi></msubsup><mo stretchy="false" id="alg1.9.9.1.m1.1.1.1.3" xref="alg1.9.9.1.m1.1.1.1.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="alg1.9.9.1.m1.1b"><apply id="alg1.9.9.1.m1.1.1.1.1.cmml" xref="alg1.9.9.1.m1.1.1.1"><csymbol cd="ambiguous" id="alg1.9.9.1.m1.1.1.1.1.1.cmml" xref="alg1.9.9.1.m1.1.1.1">superscript</csymbol><apply id="alg1.9.9.1.m1.1.1.1.1.2.cmml" xref="alg1.9.9.1.m1.1.1.1"><csymbol cd="ambiguous" id="alg1.9.9.1.m1.1.1.1.1.2.1.cmml" xref="alg1.9.9.1.m1.1.1.1">subscript</csymbol><ci id="alg1.9.9.1.m1.1.1.1.1.2.2.cmml" xref="alg1.9.9.1.m1.1.1.1.1.2.2">𝑊</ci><ci id="alg1.9.9.1.m1.1.1.1.1.2.3.cmml" xref="alg1.9.9.1.m1.1.1.1.1.2.3">𝑡</ci></apply><ci id="alg1.9.9.1.m1.1.1.1.1.3.cmml" xref="alg1.9.9.1.m1.1.1.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.9.9.1.m1.1c">(W_{t}^{k})</annotation></semantics></math>:</span><span id="alg1.9.9.3" class="ltx_text" style="font-size:80%;"> </span><em id="alg1.9.9.4" class="ltx_emph ltx_font_italic" style="font-size:80%;"></em>
</div>
<div id="alg1.19.30" class="ltx_listingline">
<span id="alg1.19.30.1" class="ltx_text" style="font-size:80%;">  </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span id="alg1.19.30.2" class="ltx_text" style="font-size:80%;">   </span><span id="alg1.19.30.3" class="ltx_text" style="font-size:80%;">
</span>
</div>
<div id="alg1.19.31" class="ltx_listingline">
<span id="alg1.19.31.1" class="ltx_text" style="font-size:80%;">  </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span id="alg1.19.31.2" class="ltx_text" style="font-size:80%;">   </span><span id="alg1.19.31.3" class="ltx_text ltx_font_typewriter" style="font-size:80%;">/* </span><span id="alg1.19.31.4" class="ltx_text ltx_font_typewriter" style="font-size:80%;">Runs once at the beginning  */</span>
</div>
<div id="alg1.19.32" class="ltx_listingline">
<span id="alg1.19.32.1" class="ltx_text" style="font-size:80%;">  </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span id="alg1.19.32.2" class="ltx_text" style="font-size:80%;">   </span><span id="alg1.19.32.3" class="ltx_text" style="font-size:80%;">

</span><span id="alg1.19.32.4" class="ltx_text ltx_font_bold" style="font-size:80%;">Email dataset preparation:</span><span id="alg1.19.32.5" class="ltx_text" style="font-size:80%;"> </span><em id="alg1.19.32.6" class="ltx_emph ltx_font_italic" style="font-size:80%;"></em>
</div>
<div id="alg1.19.33" class="ltx_listingline">
<span id="alg1.19.33.1" class="ltx_text" style="font-size:80%;">  </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span id="alg1.19.33.2" class="ltx_text" style="font-size:80%;">     </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span id="alg1.19.33.3" class="ltx_text" style="font-size:80%;">   </span><span id="alg1.19.33.4" class="ltx_text" style="font-size:80%;">
Data extraction, setting up phishing to legit email ratios, 80:20 train-test split, and Tokenization (details in Section </span><a href="#S3.SS3" title="3.3 Data preparation ‣ 3 Experimental setup ‣ Evaluation of Federated Learning in Phishing Email Detection" class="ltx_ref" style="font-size:80%;"><span class="ltx_text ltx_ref_tag">3.3</span></a><span id="alg1.19.33.5" class="ltx_text" style="font-size:80%;">);</span>
</div>
<div id="alg1.19.34" class="ltx_listingline">
<span id="alg1.19.34.1" class="ltx_text" style="font-size:80%;">  </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span id="alg1.19.34.2" class="ltx_text" style="font-size:80%;">     </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span id="alg1.19.34.3" class="ltx_text" style="font-size:80%;">   </span><span id="alg1.19.34.4" class="ltx_text" style="font-size:80%;">
</span>
</div>
<div id="alg1.19.35" class="ltx_listingline">
<span id="alg1.19.35.1" class="ltx_text" style="font-size:80%;">  </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span id="alg1.19.35.2" class="ltx_text" style="font-size:80%;">   </span>
</div>
<div id="alg1.19.36" class="ltx_listingline">
<span id="alg1.19.36.1" class="ltx_text" style="font-size:80%;">  </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span id="alg1.19.36.2" class="ltx_text" style="font-size:80%;">   </span><span id="alg1.19.36.3" class="ltx_text ltx_font_typewriter" style="font-size:80%;">/* </span><span id="alg1.19.36.4" class="ltx_text ltx_font_typewriter" style="font-size:80%;">Runs repetitively during the training/testing  */</span>
</div>
<div id="alg1.10.10" class="ltx_listingline">
<span id="alg1.10.10.2" class="ltx_text" style="font-size:80%;">  </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span id="alg1.10.10.3" class="ltx_text" style="font-size:80%;">   </span><span id="alg1.10.10.4" class="ltx_text" style="font-size:80%;">
</span><span id="alg1.10.10.5" class="ltx_text ltx_font_bold" style="font-size:80%;">while</span><span id="alg1.10.10.6" class="ltx_text" style="font-size:80%;"> </span><em id="alg1.10.10.1" class="ltx_emph" style="font-size:80%;">global model <math id="alg1.10.10.1.1.m1.1" class="ltx_Math" alttext="W_{t}" display="inline"><semantics id="alg1.10.10.1.1.m1.1a"><msub id="alg1.10.10.1.1.m1.1.1" xref="alg1.10.10.1.1.m1.1.1.cmml"><mi id="alg1.10.10.1.1.m1.1.1.2" xref="alg1.10.10.1.1.m1.1.1.2.cmml">W</mi><mi id="alg1.10.10.1.1.m1.1.1.3" xref="alg1.10.10.1.1.m1.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="alg1.10.10.1.1.m1.1b"><apply id="alg1.10.10.1.1.m1.1.1.cmml" xref="alg1.10.10.1.1.m1.1.1"><csymbol cd="ambiguous" id="alg1.10.10.1.1.m1.1.1.1.cmml" xref="alg1.10.10.1.1.m1.1.1">subscript</csymbol><ci id="alg1.10.10.1.1.m1.1.1.2.cmml" xref="alg1.10.10.1.1.m1.1.1.2">𝑊</ci><ci id="alg1.10.10.1.1.m1.1.1.3.cmml" xref="alg1.10.10.1.1.m1.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.10.10.1.1.m1.1c">W_{t}</annotation></semantics></math> is received from the server</em><span id="alg1.10.10.7" class="ltx_text" style="font-size:80%;"> </span><span id="alg1.10.10.8" class="ltx_text ltx_font_bold" style="font-size:80%;">do</span>
</div>
<div id="alg1.11.11" class="ltx_listingline">
<span id="alg1.11.11.1" class="ltx_text" style="font-size:80%;">  </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span id="alg1.11.11.2" class="ltx_text" style="font-size:80%;">     </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span id="alg1.11.11.3" class="ltx_text" style="font-size:80%;">   </span><span id="alg1.11.11.4" class="ltx_text" style="font-size:80%;">
Set </span><math id="alg1.11.11.m1.1" class="ltx_Math" alttext="W_{t}^{k}=W_{t}" display="inline"><semantics id="alg1.11.11.m1.1a"><mrow id="alg1.11.11.m1.1.1" xref="alg1.11.11.m1.1.1.cmml"><msubsup id="alg1.11.11.m1.1.1.2" xref="alg1.11.11.m1.1.1.2.cmml"><mi mathsize="80%" id="alg1.11.11.m1.1.1.2.2.2" xref="alg1.11.11.m1.1.1.2.2.2.cmml">W</mi><mi mathsize="80%" id="alg1.11.11.m1.1.1.2.2.3" xref="alg1.11.11.m1.1.1.2.2.3.cmml">t</mi><mi mathsize="80%" id="alg1.11.11.m1.1.1.2.3" xref="alg1.11.11.m1.1.1.2.3.cmml">k</mi></msubsup><mo mathsize="80%" id="alg1.11.11.m1.1.1.1" xref="alg1.11.11.m1.1.1.1.cmml">=</mo><msub id="alg1.11.11.m1.1.1.3" xref="alg1.11.11.m1.1.1.3.cmml"><mi mathsize="80%" id="alg1.11.11.m1.1.1.3.2" xref="alg1.11.11.m1.1.1.3.2.cmml">W</mi><mi mathsize="80%" id="alg1.11.11.m1.1.1.3.3" xref="alg1.11.11.m1.1.1.3.3.cmml">t</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="alg1.11.11.m1.1b"><apply id="alg1.11.11.m1.1.1.cmml" xref="alg1.11.11.m1.1.1"><eq id="alg1.11.11.m1.1.1.1.cmml" xref="alg1.11.11.m1.1.1.1"></eq><apply id="alg1.11.11.m1.1.1.2.cmml" xref="alg1.11.11.m1.1.1.2"><csymbol cd="ambiguous" id="alg1.11.11.m1.1.1.2.1.cmml" xref="alg1.11.11.m1.1.1.2">superscript</csymbol><apply id="alg1.11.11.m1.1.1.2.2.cmml" xref="alg1.11.11.m1.1.1.2"><csymbol cd="ambiguous" id="alg1.11.11.m1.1.1.2.2.1.cmml" xref="alg1.11.11.m1.1.1.2">subscript</csymbol><ci id="alg1.11.11.m1.1.1.2.2.2.cmml" xref="alg1.11.11.m1.1.1.2.2.2">𝑊</ci><ci id="alg1.11.11.m1.1.1.2.2.3.cmml" xref="alg1.11.11.m1.1.1.2.2.3">𝑡</ci></apply><ci id="alg1.11.11.m1.1.1.2.3.cmml" xref="alg1.11.11.m1.1.1.2.3">𝑘</ci></apply><apply id="alg1.11.11.m1.1.1.3.cmml" xref="alg1.11.11.m1.1.1.3"><csymbol cd="ambiguous" id="alg1.11.11.m1.1.1.3.1.cmml" xref="alg1.11.11.m1.1.1.3">subscript</csymbol><ci id="alg1.11.11.m1.1.1.3.2.cmml" xref="alg1.11.11.m1.1.1.3.2">𝑊</ci><ci id="alg1.11.11.m1.1.1.3.3.cmml" xref="alg1.11.11.m1.1.1.3.3">𝑡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.11.11.m1.1c">W_{t}^{k}=W_{t}</annotation></semantics></math><span id="alg1.11.11.5" class="ltx_text" style="font-size:80%;">;</span>
</div>
<div id="alg1.13.13" class="ltx_listingline">
<span id="alg1.13.13.3" class="ltx_text" style="font-size:80%;">  </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span id="alg1.13.13.4" class="ltx_text" style="font-size:80%;">     </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span id="alg1.13.13.5" class="ltx_text" style="font-size:80%;">   </span><span id="alg1.13.13.6" class="ltx_text" style="font-size:80%;">
</span><span id="alg1.13.13.7" class="ltx_text ltx_font_typewriter" style="font-size:80%;">/* </span><span id="alg1.13.13.2" class="ltx_text ltx_font_typewriter" style="font-size:80%;">Training/testing on the local email dataset <math id="alg1.12.12.1.m1.1" class="ltx_Math" alttext="X" display="inline"><semantics id="alg1.12.12.1.m1.1a"><mi id="alg1.12.12.1.m1.1.1" xref="alg1.12.12.1.m1.1.1.cmml">X</mi><annotation-xml encoding="MathML-Content" id="alg1.12.12.1.m1.1b"><ci id="alg1.12.12.1.m1.1.1.cmml" xref="alg1.12.12.1.m1.1.1">𝑋</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.12.12.1.m1.1c">X</annotation></semantics></math> having <math id="alg1.13.13.2.m2.1" class="ltx_Math" alttext="n_{k}" display="inline"><semantics id="alg1.13.13.2.m2.1a"><msub id="alg1.13.13.2.m2.1.1" xref="alg1.13.13.2.m2.1.1.cmml"><mi id="alg1.13.13.2.m2.1.1.2" xref="alg1.13.13.2.m2.1.1.2.cmml">n</mi><mi id="alg1.13.13.2.m2.1.1.3" xref="alg1.13.13.2.m2.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="alg1.13.13.2.m2.1b"><apply id="alg1.13.13.2.m2.1.1.cmml" xref="alg1.13.13.2.m2.1.1"><csymbol cd="ambiguous" id="alg1.13.13.2.m2.1.1.1.cmml" xref="alg1.13.13.2.m2.1.1">subscript</csymbol><ci id="alg1.13.13.2.m2.1.1.2.cmml" xref="alg1.13.13.2.m2.1.1.2">𝑛</ci><ci id="alg1.13.13.2.m2.1.1.3.cmml" xref="alg1.13.13.2.m2.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.13.13.2.m2.1c">n_{k}</annotation></semantics></math> samples  */</span>
</div>
<div id="alg1.14.14" class="ltx_listingline">
<span id="alg1.14.14.2" class="ltx_text" style="font-size:80%;">  </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span id="alg1.14.14.3" class="ltx_text" style="font-size:80%;">     </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span id="alg1.14.14.4" class="ltx_text" style="font-size:80%;">   </span><span id="alg1.14.14.5" class="ltx_text" style="font-size:80%;">
</span><span id="alg1.14.14.6" class="ltx_text ltx_font_bold" style="font-size:80%;">for</span><span id="alg1.14.14.7" class="ltx_text" style="font-size:80%;"> </span><em id="alg1.14.14.1" class="ltx_emph ltx_font_italic" style="font-size:80%;"><span id="alg1.14.14.1.1" class="ltx_text ltx_font_upright">batch</span> <math id="alg1.14.14.1.m1.1" class="ltx_Math" alttext="b\in\mathcal{B}" display="inline"><semantics id="alg1.14.14.1.m1.1a"><mrow id="alg1.14.14.1.m1.1.1" xref="alg1.14.14.1.m1.1.1.cmml"><mi id="alg1.14.14.1.m1.1.1.2" xref="alg1.14.14.1.m1.1.1.2.cmml">b</mi><mo id="alg1.14.14.1.m1.1.1.1" xref="alg1.14.14.1.m1.1.1.1.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="alg1.14.14.1.m1.1.1.3" xref="alg1.14.14.1.m1.1.1.3.cmml">ℬ</mi></mrow><annotation-xml encoding="MathML-Content" id="alg1.14.14.1.m1.1b"><apply id="alg1.14.14.1.m1.1.1.cmml" xref="alg1.14.14.1.m1.1.1"><in id="alg1.14.14.1.m1.1.1.1.cmml" xref="alg1.14.14.1.m1.1.1.1"></in><ci id="alg1.14.14.1.m1.1.1.2.cmml" xref="alg1.14.14.1.m1.1.1.2">𝑏</ci><ci id="alg1.14.14.1.m1.1.1.3.cmml" xref="alg1.14.14.1.m1.1.1.3">ℬ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.14.14.1.m1.1c">b\in\mathcal{B}</annotation></semantics></math></em><span id="alg1.14.14.8" class="ltx_text" style="font-size:80%;"> </span><span id="alg1.14.14.9" class="ltx_text ltx_font_bold" style="font-size:80%;">do</span>
</div>
<div id="alg1.19.37" class="ltx_listingline">
<span id="alg1.19.37.1" class="ltx_text" style="font-size:80%;">  </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span id="alg1.19.37.2" class="ltx_text" style="font-size:80%;">     </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span id="alg1.19.37.3" class="ltx_text" style="font-size:80%;">     </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span id="alg1.19.37.4" class="ltx_text" style="font-size:80%;">   </span><span id="alg1.19.37.5" class="ltx_text" style="font-size:80%;">
</span>
</div>
<div id="alg1.15.15" class="ltx_listingline">
<span id="alg1.15.15.1" class="ltx_text" style="font-size:80%;">  </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span id="alg1.15.15.2" class="ltx_text" style="font-size:80%;">     </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span id="alg1.15.15.3" class="ltx_text" style="font-size:80%;">     </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span id="alg1.15.15.4" class="ltx_text" style="font-size:80%;">   </span><math id="alg1.15.15.m1.2" class="ltx_Math" alttext="W^{k}_{t}\leftarrow W^{k}_{t}-\eta\triangledown f(W^{k}_{t};X)\ \textup{for}\ X\sim\mathcal{P}_{k}" display="inline"><semantics id="alg1.15.15.m1.2a"><mrow id="alg1.15.15.m1.2.2" xref="alg1.15.15.m1.2.2.cmml"><msubsup id="alg1.15.15.m1.2.2.3" xref="alg1.15.15.m1.2.2.3.cmml"><mi mathsize="80%" id="alg1.15.15.m1.2.2.3.2.2" xref="alg1.15.15.m1.2.2.3.2.2.cmml">W</mi><mi mathsize="80%" id="alg1.15.15.m1.2.2.3.3" xref="alg1.15.15.m1.2.2.3.3.cmml">t</mi><mi mathsize="80%" id="alg1.15.15.m1.2.2.3.2.3" xref="alg1.15.15.m1.2.2.3.2.3.cmml">k</mi></msubsup><mo mathsize="80%" stretchy="false" id="alg1.15.15.m1.2.2.4" xref="alg1.15.15.m1.2.2.4.cmml">←</mo><mrow id="alg1.15.15.m1.2.2.1" xref="alg1.15.15.m1.2.2.1.cmml"><msubsup id="alg1.15.15.m1.2.2.1.3" xref="alg1.15.15.m1.2.2.1.3.cmml"><mi mathsize="80%" id="alg1.15.15.m1.2.2.1.3.2.2" xref="alg1.15.15.m1.2.2.1.3.2.2.cmml">W</mi><mi mathsize="80%" id="alg1.15.15.m1.2.2.1.3.3" xref="alg1.15.15.m1.2.2.1.3.3.cmml">t</mi><mi mathsize="80%" id="alg1.15.15.m1.2.2.1.3.2.3" xref="alg1.15.15.m1.2.2.1.3.2.3.cmml">k</mi></msubsup><mo mathsize="80%" id="alg1.15.15.m1.2.2.1.2" xref="alg1.15.15.m1.2.2.1.2.cmml">−</mo><mrow id="alg1.15.15.m1.2.2.1.1" xref="alg1.15.15.m1.2.2.1.1.cmml"><mi mathsize="80%" id="alg1.15.15.m1.2.2.1.1.3" xref="alg1.15.15.m1.2.2.1.1.3.cmml">η</mi><mo lspace="0em" rspace="0em" id="alg1.15.15.m1.2.2.1.1.2" xref="alg1.15.15.m1.2.2.1.1.2.cmml">​</mo><mi mathsize="80%" mathvariant="normal" id="alg1.15.15.m1.2.2.1.1.4" xref="alg1.15.15.m1.2.2.1.1.4.cmml">▽</mi><mo lspace="0em" rspace="0em" id="alg1.15.15.m1.2.2.1.1.2a" xref="alg1.15.15.m1.2.2.1.1.2.cmml">​</mo><mi mathsize="80%" id="alg1.15.15.m1.2.2.1.1.5" xref="alg1.15.15.m1.2.2.1.1.5.cmml">f</mi><mo lspace="0em" rspace="0em" id="alg1.15.15.m1.2.2.1.1.2b" xref="alg1.15.15.m1.2.2.1.1.2.cmml">​</mo><mrow id="alg1.15.15.m1.2.2.1.1.1.1" xref="alg1.15.15.m1.2.2.1.1.1.2.cmml"><mo maxsize="80%" minsize="80%" id="alg1.15.15.m1.2.2.1.1.1.1.2" xref="alg1.15.15.m1.2.2.1.1.1.2.cmml">(</mo><msubsup id="alg1.15.15.m1.2.2.1.1.1.1.1" xref="alg1.15.15.m1.2.2.1.1.1.1.1.cmml"><mi mathsize="80%" id="alg1.15.15.m1.2.2.1.1.1.1.1.2.2" xref="alg1.15.15.m1.2.2.1.1.1.1.1.2.2.cmml">W</mi><mi mathsize="80%" id="alg1.15.15.m1.2.2.1.1.1.1.1.3" xref="alg1.15.15.m1.2.2.1.1.1.1.1.3.cmml">t</mi><mi mathsize="80%" id="alg1.15.15.m1.2.2.1.1.1.1.1.2.3" xref="alg1.15.15.m1.2.2.1.1.1.1.1.2.3.cmml">k</mi></msubsup><mo mathsize="80%" id="alg1.15.15.m1.2.2.1.1.1.1.3" xref="alg1.15.15.m1.2.2.1.1.1.2.cmml">;</mo><mi mathsize="80%" id="alg1.15.15.m1.1.1" xref="alg1.15.15.m1.1.1.cmml">X</mi><mo maxsize="80%" minsize="80%" id="alg1.15.15.m1.2.2.1.1.1.1.4" xref="alg1.15.15.m1.2.2.1.1.1.2.cmml">)</mo></mrow><mo lspace="0.400em" rspace="0em" id="alg1.15.15.m1.2.2.1.1.2c" xref="alg1.15.15.m1.2.2.1.1.2.cmml">​</mo><mtext mathsize="80%" id="alg1.15.15.m1.2.2.1.1.6" xref="alg1.15.15.m1.2.2.1.1.6a.cmml">for</mtext><mo lspace="0.400em" rspace="0em" id="alg1.15.15.m1.2.2.1.1.2d" xref="alg1.15.15.m1.2.2.1.1.2.cmml">​</mo><mi mathsize="80%" id="alg1.15.15.m1.2.2.1.1.7" xref="alg1.15.15.m1.2.2.1.1.7.cmml">X</mi></mrow></mrow><mo mathsize="80%" id="alg1.15.15.m1.2.2.5" xref="alg1.15.15.m1.2.2.5.cmml">∼</mo><msub id="alg1.15.15.m1.2.2.6" xref="alg1.15.15.m1.2.2.6.cmml"><mi class="ltx_font_mathcaligraphic" mathsize="80%" id="alg1.15.15.m1.2.2.6.2" xref="alg1.15.15.m1.2.2.6.2.cmml">𝒫</mi><mi mathsize="80%" id="alg1.15.15.m1.2.2.6.3" xref="alg1.15.15.m1.2.2.6.3.cmml">k</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="alg1.15.15.m1.2b"><apply id="alg1.15.15.m1.2.2.cmml" xref="alg1.15.15.m1.2.2"><and id="alg1.15.15.m1.2.2a.cmml" xref="alg1.15.15.m1.2.2"></and><apply id="alg1.15.15.m1.2.2b.cmml" xref="alg1.15.15.m1.2.2"><ci id="alg1.15.15.m1.2.2.4.cmml" xref="alg1.15.15.m1.2.2.4">←</ci><apply id="alg1.15.15.m1.2.2.3.cmml" xref="alg1.15.15.m1.2.2.3"><csymbol cd="ambiguous" id="alg1.15.15.m1.2.2.3.1.cmml" xref="alg1.15.15.m1.2.2.3">subscript</csymbol><apply id="alg1.15.15.m1.2.2.3.2.cmml" xref="alg1.15.15.m1.2.2.3"><csymbol cd="ambiguous" id="alg1.15.15.m1.2.2.3.2.1.cmml" xref="alg1.15.15.m1.2.2.3">superscript</csymbol><ci id="alg1.15.15.m1.2.2.3.2.2.cmml" xref="alg1.15.15.m1.2.2.3.2.2">𝑊</ci><ci id="alg1.15.15.m1.2.2.3.2.3.cmml" xref="alg1.15.15.m1.2.2.3.2.3">𝑘</ci></apply><ci id="alg1.15.15.m1.2.2.3.3.cmml" xref="alg1.15.15.m1.2.2.3.3">𝑡</ci></apply><apply id="alg1.15.15.m1.2.2.1.cmml" xref="alg1.15.15.m1.2.2.1"><minus id="alg1.15.15.m1.2.2.1.2.cmml" xref="alg1.15.15.m1.2.2.1.2"></minus><apply id="alg1.15.15.m1.2.2.1.3.cmml" xref="alg1.15.15.m1.2.2.1.3"><csymbol cd="ambiguous" id="alg1.15.15.m1.2.2.1.3.1.cmml" xref="alg1.15.15.m1.2.2.1.3">subscript</csymbol><apply id="alg1.15.15.m1.2.2.1.3.2.cmml" xref="alg1.15.15.m1.2.2.1.3"><csymbol cd="ambiguous" id="alg1.15.15.m1.2.2.1.3.2.1.cmml" xref="alg1.15.15.m1.2.2.1.3">superscript</csymbol><ci id="alg1.15.15.m1.2.2.1.3.2.2.cmml" xref="alg1.15.15.m1.2.2.1.3.2.2">𝑊</ci><ci id="alg1.15.15.m1.2.2.1.3.2.3.cmml" xref="alg1.15.15.m1.2.2.1.3.2.3">𝑘</ci></apply><ci id="alg1.15.15.m1.2.2.1.3.3.cmml" xref="alg1.15.15.m1.2.2.1.3.3">𝑡</ci></apply><apply id="alg1.15.15.m1.2.2.1.1.cmml" xref="alg1.15.15.m1.2.2.1.1"><times id="alg1.15.15.m1.2.2.1.1.2.cmml" xref="alg1.15.15.m1.2.2.1.1.2"></times><ci id="alg1.15.15.m1.2.2.1.1.3.cmml" xref="alg1.15.15.m1.2.2.1.1.3">𝜂</ci><ci id="alg1.15.15.m1.2.2.1.1.4.cmml" xref="alg1.15.15.m1.2.2.1.1.4">▽</ci><ci id="alg1.15.15.m1.2.2.1.1.5.cmml" xref="alg1.15.15.m1.2.2.1.1.5">𝑓</ci><list id="alg1.15.15.m1.2.2.1.1.1.2.cmml" xref="alg1.15.15.m1.2.2.1.1.1.1"><apply id="alg1.15.15.m1.2.2.1.1.1.1.1.cmml" xref="alg1.15.15.m1.2.2.1.1.1.1.1"><csymbol cd="ambiguous" id="alg1.15.15.m1.2.2.1.1.1.1.1.1.cmml" xref="alg1.15.15.m1.2.2.1.1.1.1.1">subscript</csymbol><apply id="alg1.15.15.m1.2.2.1.1.1.1.1.2.cmml" xref="alg1.15.15.m1.2.2.1.1.1.1.1"><csymbol cd="ambiguous" id="alg1.15.15.m1.2.2.1.1.1.1.1.2.1.cmml" xref="alg1.15.15.m1.2.2.1.1.1.1.1">superscript</csymbol><ci id="alg1.15.15.m1.2.2.1.1.1.1.1.2.2.cmml" xref="alg1.15.15.m1.2.2.1.1.1.1.1.2.2">𝑊</ci><ci id="alg1.15.15.m1.2.2.1.1.1.1.1.2.3.cmml" xref="alg1.15.15.m1.2.2.1.1.1.1.1.2.3">𝑘</ci></apply><ci id="alg1.15.15.m1.2.2.1.1.1.1.1.3.cmml" xref="alg1.15.15.m1.2.2.1.1.1.1.1.3">𝑡</ci></apply><ci id="alg1.15.15.m1.1.1.cmml" xref="alg1.15.15.m1.1.1">𝑋</ci></list><ci id="alg1.15.15.m1.2.2.1.1.6a.cmml" xref="alg1.15.15.m1.2.2.1.1.6"><mtext mathsize="80%" id="alg1.15.15.m1.2.2.1.1.6.cmml" xref="alg1.15.15.m1.2.2.1.1.6">for</mtext></ci><ci id="alg1.15.15.m1.2.2.1.1.7.cmml" xref="alg1.15.15.m1.2.2.1.1.7">𝑋</ci></apply></apply></apply><apply id="alg1.15.15.m1.2.2c.cmml" xref="alg1.15.15.m1.2.2"><csymbol cd="latexml" id="alg1.15.15.m1.2.2.5.cmml" xref="alg1.15.15.m1.2.2.5">similar-to</csymbol><share href="#alg1.15.15.m1.2.2.1.cmml" id="alg1.15.15.m1.2.2d.cmml" xref="alg1.15.15.m1.2.2"></share><apply id="alg1.15.15.m1.2.2.6.cmml" xref="alg1.15.15.m1.2.2.6"><csymbol cd="ambiguous" id="alg1.15.15.m1.2.2.6.1.cmml" xref="alg1.15.15.m1.2.2.6">subscript</csymbol><ci id="alg1.15.15.m1.2.2.6.2.cmml" xref="alg1.15.15.m1.2.2.6.2">𝒫</ci><ci id="alg1.15.15.m1.2.2.6.3.cmml" xref="alg1.15.15.m1.2.2.6.3">𝑘</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.15.15.m1.2c">W^{k}_{t}\leftarrow W^{k}_{t}-\eta\triangledown f(W^{k}_{t};X)\ \textup{for}\ X\sim\mathcal{P}_{k}</annotation></semantics></math><span id="alg1.15.15.5" class="ltx_text" style="font-size:80%;">
;</span>
</div>
<div id="alg1.18.18" class="ltx_listingline">
<span id="alg1.18.18.3" class="ltx_text" style="font-size:80%;">  </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span id="alg1.18.18.4" class="ltx_text" style="font-size:80%;">     </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span id="alg1.18.18.5" class="ltx_text" style="font-size:80%;">     </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span id="alg1.18.18.6" class="ltx_text" style="font-size:80%;">   </span><span id="alg1.18.18.7" class="ltx_text" style="font-size:80%;">  </span><span id="alg1.18.18.8" class="ltx_text ltx_font_typewriter" style="font-size:80%;">// </span><math id="alg1.16.16.m1.1" class="ltx_Math" alttext="\mathcal{B}" display="inline"><semantics id="alg1.16.16.m1.1a"><mi class="ltx_font_mathcaligraphic" mathsize="80%" id="alg1.16.16.m1.1.1" xref="alg1.16.16.m1.1.1.cmml">ℬ</mi><annotation-xml encoding="MathML-Content" id="alg1.16.16.m1.1b"><ci id="alg1.16.16.m1.1.1.cmml" xref="alg1.16.16.m1.1.1">ℬ</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.16.16.m1.1c">\mathcal{B}</annotation></semantics></math><span id="alg1.18.18.2" class="ltx_text ltx_font_typewriter" style="font-size:80%;"> is batch size, <math id="alg1.17.17.1.m1.1" class="ltx_Math" alttext="\eta" display="inline"><semantics id="alg1.17.17.1.m1.1a"><mi id="alg1.17.17.1.m1.1.1" xref="alg1.17.17.1.m1.1.1.cmml">η</mi><annotation-xml encoding="MathML-Content" id="alg1.17.17.1.m1.1b"><ci id="alg1.17.17.1.m1.1.1.cmml" xref="alg1.17.17.1.m1.1.1">𝜂</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.17.17.1.m1.1c">\eta</annotation></semantics></math> is learning rate, and <math id="alg1.18.18.2.m2.2" class="ltx_Math" alttext="\triangledown f(W^{k}_{t};X)" display="inline"><semantics id="alg1.18.18.2.m2.2a"><mrow id="alg1.18.18.2.m2.2.2" xref="alg1.18.18.2.m2.2.2.cmml"><mi mathvariant="normal" id="alg1.18.18.2.m2.2.2.3" xref="alg1.18.18.2.m2.2.2.3.cmml">▽</mi><mo lspace="0em" rspace="0em" id="alg1.18.18.2.m2.2.2.2" xref="alg1.18.18.2.m2.2.2.2.cmml">​</mo><mi id="alg1.18.18.2.m2.2.2.4" xref="alg1.18.18.2.m2.2.2.4.cmml">f</mi><mo lspace="0em" rspace="0em" id="alg1.18.18.2.m2.2.2.2a" xref="alg1.18.18.2.m2.2.2.2.cmml">​</mo><mrow id="alg1.18.18.2.m2.2.2.1.1" xref="alg1.18.18.2.m2.2.2.1.2.cmml"><mo stretchy="false" id="alg1.18.18.2.m2.2.2.1.1.2" xref="alg1.18.18.2.m2.2.2.1.2.cmml">(</mo><msubsup id="alg1.18.18.2.m2.2.2.1.1.1" xref="alg1.18.18.2.m2.2.2.1.1.1.cmml"><mi id="alg1.18.18.2.m2.2.2.1.1.1.2.2" xref="alg1.18.18.2.m2.2.2.1.1.1.2.2.cmml">W</mi><mi id="alg1.18.18.2.m2.2.2.1.1.1.3" xref="alg1.18.18.2.m2.2.2.1.1.1.3.cmml">t</mi><mi id="alg1.18.18.2.m2.2.2.1.1.1.2.3" xref="alg1.18.18.2.m2.2.2.1.1.1.2.3.cmml">k</mi></msubsup><mo id="alg1.18.18.2.m2.2.2.1.1.3" xref="alg1.18.18.2.m2.2.2.1.2.cmml">;</mo><mi id="alg1.18.18.2.m2.1.1" xref="alg1.18.18.2.m2.1.1.cmml">X</mi><mo stretchy="false" id="alg1.18.18.2.m2.2.2.1.1.4" xref="alg1.18.18.2.m2.2.2.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.18.18.2.m2.2b"><apply id="alg1.18.18.2.m2.2.2.cmml" xref="alg1.18.18.2.m2.2.2"><times id="alg1.18.18.2.m2.2.2.2.cmml" xref="alg1.18.18.2.m2.2.2.2"></times><ci id="alg1.18.18.2.m2.2.2.3.cmml" xref="alg1.18.18.2.m2.2.2.3">▽</ci><ci id="alg1.18.18.2.m2.2.2.4.cmml" xref="alg1.18.18.2.m2.2.2.4">𝑓</ci><list id="alg1.18.18.2.m2.2.2.1.2.cmml" xref="alg1.18.18.2.m2.2.2.1.1"><apply id="alg1.18.18.2.m2.2.2.1.1.1.cmml" xref="alg1.18.18.2.m2.2.2.1.1.1"><csymbol cd="ambiguous" id="alg1.18.18.2.m2.2.2.1.1.1.1.cmml" xref="alg1.18.18.2.m2.2.2.1.1.1">subscript</csymbol><apply id="alg1.18.18.2.m2.2.2.1.1.1.2.cmml" xref="alg1.18.18.2.m2.2.2.1.1.1"><csymbol cd="ambiguous" id="alg1.18.18.2.m2.2.2.1.1.1.2.1.cmml" xref="alg1.18.18.2.m2.2.2.1.1.1">superscript</csymbol><ci id="alg1.18.18.2.m2.2.2.1.1.1.2.2.cmml" xref="alg1.18.18.2.m2.2.2.1.1.1.2.2">𝑊</ci><ci id="alg1.18.18.2.m2.2.2.1.1.1.2.3.cmml" xref="alg1.18.18.2.m2.2.2.1.1.1.2.3">𝑘</ci></apply><ci id="alg1.18.18.2.m2.2.2.1.1.1.3.cmml" xref="alg1.18.18.2.m2.2.2.1.1.1.3">𝑡</ci></apply><ci id="alg1.18.18.2.m2.1.1.cmml" xref="alg1.18.18.2.m2.1.1">𝑋</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.18.18.2.m2.2c">\triangledown f(W^{k}_{t};X)</annotation></semantics></math> is gradients with respect to the cost function</span>
</div>
<div id="alg1.19.38" class="ltx_listingline">
<span id="alg1.19.38.1" class="ltx_text" style="font-size:80%;">  </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span id="alg1.19.38.2" class="ltx_text" style="font-size:80%;">     </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span id="alg1.19.38.3" class="ltx_text" style="font-size:80%;">     </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span id="alg1.19.38.4" class="ltx_text" style="font-size:80%;">   </span><span id="alg1.19.38.5" class="ltx_text" style="font-size:80%;">
</span>
</div>
<div id="alg1.19.19" class="ltx_listingline">
<span id="alg1.19.19.1" class="ltx_text" style="font-size:80%;">  </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span id="alg1.19.19.2" class="ltx_text" style="font-size:80%;">     </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span id="alg1.19.19.3" class="ltx_text" style="font-size:80%;">   </span><span id="alg1.19.19.4" class="ltx_text" style="font-size:80%;">Send locally trained </span><math id="alg1.19.19.m1.1" class="ltx_Math" alttext="W_{t}^{k}" display="inline"><semantics id="alg1.19.19.m1.1a"><msubsup id="alg1.19.19.m1.1.1" xref="alg1.19.19.m1.1.1.cmml"><mi mathsize="80%" id="alg1.19.19.m1.1.1.2.2" xref="alg1.19.19.m1.1.1.2.2.cmml">W</mi><mi mathsize="80%" id="alg1.19.19.m1.1.1.2.3" xref="alg1.19.19.m1.1.1.2.3.cmml">t</mi><mi mathsize="80%" id="alg1.19.19.m1.1.1.3" xref="alg1.19.19.m1.1.1.3.cmml">k</mi></msubsup><annotation-xml encoding="MathML-Content" id="alg1.19.19.m1.1b"><apply id="alg1.19.19.m1.1.1.cmml" xref="alg1.19.19.m1.1.1"><csymbol cd="ambiguous" id="alg1.19.19.m1.1.1.1.cmml" xref="alg1.19.19.m1.1.1">superscript</csymbol><apply id="alg1.19.19.m1.1.1.2.cmml" xref="alg1.19.19.m1.1.1"><csymbol cd="ambiguous" id="alg1.19.19.m1.1.1.2.1.cmml" xref="alg1.19.19.m1.1.1">subscript</csymbol><ci id="alg1.19.19.m1.1.1.2.2.cmml" xref="alg1.19.19.m1.1.1.2.2">𝑊</ci><ci id="alg1.19.19.m1.1.1.2.3.cmml" xref="alg1.19.19.m1.1.1.2.3">𝑡</ci></apply><ci id="alg1.19.19.m1.1.1.3.cmml" xref="alg1.19.19.m1.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.19.19.m1.1c">W_{t}^{k}</annotation></semantics></math><span id="alg1.19.19.5" class="ltx_text" style="font-size:80%;"> to Server;</span>
</div>
<div id="alg1.19.39" class="ltx_listingline">
<span id="alg1.19.39.1" class="ltx_text" style="font-size:80%;">  </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span id="alg1.19.39.2" class="ltx_text" style="font-size:80%;">     </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span id="alg1.19.39.3" class="ltx_text" style="font-size:80%;">   </span><span id="alg1.19.39.4" class="ltx_text" style="font-size:80%;">
</span>
</div>
<div id="alg1.19.40" class="ltx_listingline">
<span id="alg1.19.40.1" class="ltx_text" style="font-size:80%;">  </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span id="alg1.19.40.2" class="ltx_text" style="font-size:80%;">   </span>
</div>
<div id="alg1.19.41" class="ltx_listingline">
<span id="alg1.19.41.1" class="ltx_text" style="font-size:80%;">
</span>
</div>
</div>
<figcaption class="ltx_caption" style="font-size:80%;"><span class="ltx_tag ltx_tag_float"><span id="alg1.23.1.1" class="ltx_text ltx_font_bold">Algorithm 1</span> </span>Federated learning</figcaption>
</figure>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.1" class="ltx_p">We have considered the <span id="S3.SS1.p2.1.1" class="ltx_text ltx_font_italic">updated email dataset</span> from the sources, e.g., Nazario’s phishing corpus 2019. In total, the experimental dataset has <math id="S3.SS1.p2.1.m1.1" class="ltx_Math" alttext="23916" display="inline"><semantics id="S3.SS1.p2.1.m1.1a"><mn id="S3.SS1.p2.1.m1.1.1" xref="S3.SS1.p2.1.m1.1.1.cmml">23916</mn><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.1.m1.1b"><cn type="integer" id="S3.SS1.p2.1.m1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1">23916</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.1.m1.1c">23916</annotation></semantics></math> email samples, and Table <a href="#S3.T1" title="TABLE I ‣ 3.1 Datasets ‣ 3 Experimental setup ‣ Evaluation of Federated Learning in Phishing Email Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">I</span></a> shows the number of emails extracted from each source.</p>
</div>
<figure id="S3.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering" style="font-size:80%;"><span class="ltx_tag ltx_tag_table">TABLE I: </span>The number of email samples.</figcaption>
<table id="S3.T1.3" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T1.3.1.1" class="ltx_tr">
<th id="S3.T1.3.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t"><span id="S3.T1.3.1.1.1.1" class="ltx_text" style="font-size:80%;">Source</span></th>
<th id="S3.T1.3.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S3.T1.3.1.1.2.1" class="ltx_text" style="font-size:80%;">Phishing (P)</span></th>
<th id="S3.T1.3.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S3.T1.3.1.1.3.1" class="ltx_text" style="font-size:80%;">Legitimate (L)</span></th>
<th id="S3.T1.3.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S3.T1.3.1.1.4.1" class="ltx_text" style="font-size:80%;">P+L</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T1.3.2.1" class="ltx_tr">
<th id="S3.T1.3.2.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t"><span id="S3.T1.3.2.1.1.1" class="ltx_text" style="font-size:80%;">IWSPA-AP</span></th>
<td id="S3.T1.3.2.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T1.3.2.1.2.1" class="ltx_text" style="font-size:80%;">1132</span></td>
<td id="S3.T1.3.2.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T1.3.2.1.3.1" class="ltx_text" style="font-size:80%;">9174</span></td>
<td id="S3.T1.3.2.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T1.3.2.1.4.1" class="ltx_text" style="font-size:80%;">10306</span></td>
</tr>
<tr id="S3.T1.3.3.2" class="ltx_tr">
<th id="S3.T1.3.3.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t"><span id="S3.T1.3.3.2.1.1" class="ltx_text" style="font-size:80%;">Nazario</span></th>
<td id="S3.T1.3.3.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T1.3.3.2.2.1" class="ltx_text" style="font-size:80%;">8890</span></td>
<td id="S3.T1.3.3.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T1.3.3.2.3.1" class="ltx_text" style="font-size:80%;">0</span></td>
<td id="S3.T1.3.3.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T1.3.3.2.4.1" class="ltx_text" style="font-size:80%;">8890</span></td>
</tr>
<tr id="S3.T1.3.4.3" class="ltx_tr">
<th id="S3.T1.3.4.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t"><span id="S3.T1.3.4.3.1.1" class="ltx_text" style="font-size:80%;">Enron</span></th>
<td id="S3.T1.3.4.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T1.3.4.3.2.1" class="ltx_text" style="font-size:80%;">0</span></td>
<td id="S3.T1.3.4.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T1.3.4.3.3.1" class="ltx_text" style="font-size:80%;">4279</span></td>
<td id="S3.T1.3.4.3.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T1.3.4.3.4.1" class="ltx_text" style="font-size:80%;">4279</span></td>
</tr>
<tr id="S3.T1.3.5.4" class="ltx_tr">
<th id="S3.T1.3.5.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t"><span id="S3.T1.3.5.4.1.1" class="ltx_text" style="font-size:80%;">CSIRO</span></th>
<td id="S3.T1.3.5.4.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T1.3.5.4.2.1" class="ltx_text" style="font-size:80%;">309</span></td>
<td id="S3.T1.3.5.4.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T1.3.5.4.3.1" class="ltx_text" style="font-size:80%;">0</span></td>
<td id="S3.T1.3.5.4.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T1.3.5.4.4.1" class="ltx_text" style="font-size:80%;">309</span></td>
</tr>
<tr id="S3.T1.3.6.5" class="ltx_tr">
<th id="S3.T1.3.6.5.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t"><span id="S3.T1.3.6.5.1.1" class="ltx_text" style="font-size:80%;">Phisbowl</span></th>
<td id="S3.T1.3.6.5.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T1.3.6.5.2.1" class="ltx_text" style="font-size:80%;">132</span></td>
<td id="S3.T1.3.6.5.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T1.3.6.5.3.1" class="ltx_text" style="font-size:80%;">0</span></td>
<td id="S3.T1.3.6.5.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T1.3.6.5.4.1" class="ltx_text" style="font-size:80%;">132</span></td>
</tr>
<tr id="S3.T1.3.7.6" class="ltx_tr">
<th id="S3.T1.3.7.6.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r ltx_border_t"><em id="S3.T1.3.7.6.1.1" class="ltx_emph ltx_font_italic" style="font-size:80%;">Total</em></th>
<td id="S3.T1.3.7.6.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S3.T1.3.7.6.2.1" class="ltx_text" style="font-size:80%;">10463</span></td>
<td id="S3.T1.3.7.6.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S3.T1.3.7.6.3.1" class="ltx_text" style="font-size:80%;">13453</span></td>
<td id="S3.T1.3.7.6.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S3.T1.3.7.6.4.1" class="ltx_text" style="font-size:80%;">23916</span></td>
</tr>
</tbody>
</table>
</figure>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span><span id="S3.SS2.1.1" class="ltx_text ltx_font_italic">Deep learning model selection:</span>
</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">The selected models are described in the following:</p>
</div>
<section id="S3.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.1 </span>THEMIS model</h4>

<div id="S3.SS2.SSS1.p1" class="ltx_para">
<p id="S3.SS2.SSS1.p1.1" class="ltx_p">THEMIS is one of the recent models, which has been demonstrated to be highly effective for phishing email detection. It employs Recurrent Convolutional Neural Network (RCNNs) and models emails at multiple levels, including char-level email header, word-level email header, char-level email body, and word-level email body <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>. This way, it captures the deep underlying semantics of the phishing emails efficiently and consequently making THEMIS better than existing DL-based methods that are limited to natural language processing and deep learning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>.</p>
</div>
<figure id="S3.F2" class="ltx_figure"><img src="/html/2007.13300/assets/x2.png" id="S3.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="177" height="62" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>An overview of THEMIS model.</figcaption>
</figure>
<div id="S3.SS2.SSS1.p2" class="ltx_para">
<p id="S3.SS2.SSS1.p2.1" class="ltx_p"><span id="S3.SS2.SSS1.p2.1.1" class="ltx_text ltx_font_bold">Overview of THEMIS model</span>: Fig. <a href="#S3.F2" title="Figure 2 ‣ 3.2.1 THEMIS model ‣ 3.2 Deep learning model selection: ‣ 3 Experimental setup ‣ Evaluation of Federated Learning in Phishing Email Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> illustrates a system overview of the THEMIS model. Firstly, THEMIS extracts the char-level and word-level of the email header and body, and then an embedding layer converts all these levels to the respective vector representation. Afterward, it feeds each vector representation into the RCNN model <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite> and learns a representation for the email header and email body, respectively.
THEMIS RCNN consists of four Bidirectional-Long Short-Term Memory (Bi-LSTM) that obtain the left and right semantic information of a specific location with its embedding information from the above four vectors, thus forming something called a triple. Next, these triples are mapped into specified dimensions using a <span id="S3.SS2.SSS1.p2.1.2" class="ltx_text ltx_font_typewriter">tanh</span> activation function. The longitudinal max polling is then applied to obtain four different representations, which will be paired to form only two representations for the header and the body.
As the email header representation and body representation have varying degrees of impact on phishing detection, an attention mechanism is applied to compute a weighted sum of the two representations. This produces an ultimate representation of the whole email, which is further processed to produce the classification result. For more details of the THEMIS model, we refer readers to <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>.</p>
</div>
<div id="S3.SS2.SSS1.p3" class="ltx_para">
<p id="S3.SS2.SSS1.p3.1" class="ltx_p">The THEMIS original paper considered only emails with headers (8780 samples) and the THEMIS model was trained on those data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>. In contrast, this paper considers (i) around 2.7x more email samples, (ii) emails with header and without header information, (ii) THEMIS under emails with both headers and without headers (body only), and we analyze their performances with CL and FL.</p>
</div>
</section>
<section id="S3.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.2 </span>Bidirectional Encoder Representations from Transformers</h4>

<div id="S3.SS2.SSS2.p1" class="ltx_para">
<p id="S3.SS2.SSS2.p1.1" class="ltx_p">Bidirectional Encoder Representations from Transformers (BERT) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite> is a language model initially developed by Google. Transformer encoders are basic blocks of BERT. Transformers learn the contextual information in the input sequence by an attention mechanism that enables them to relate different parts of the input sequence to find their relationship, for example, the contextual information of the words/sub-words in a sentence. BERT reads the entire input sequence to get bidirectionally trained. This enables BERT to learn the contextual information better than the techniques looking at the sequence from one direction (e.g., each word conditioned on its previous or next words).</p>
</div>
<figure id="S3.F3" class="ltx_figure"><img src="/html/2007.13300/assets/x3.png" id="S3.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="266" height="157" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>An overview of BERT model for phishing detection, where <span id="S3.F3.11.1" class="ltx_text ltx_markedasmath">E</span> is input embeddings, <span id="S3.F3.12.2" class="ltx_text ltx_markedasmath">C</span> and <math id="S3.F3.7.m3.1" class="ltx_Math" alttext="\textup{T}_{i}" display="inline"><semantics id="S3.F3.7.m3.1b"><msub id="S3.F3.7.m3.1.1" xref="S3.F3.7.m3.1.1.cmml"><mtext id="S3.F3.7.m3.1.1.2" xref="S3.F3.7.m3.1.1.2a.cmml">T</mtext><mi id="S3.F3.7.m3.1.1.3" xref="S3.F3.7.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.F3.7.m3.1c"><apply id="S3.F3.7.m3.1.1.cmml" xref="S3.F3.7.m3.1.1"><csymbol cd="ambiguous" id="S3.F3.7.m3.1.1.1.cmml" xref="S3.F3.7.m3.1.1">subscript</csymbol><ci id="S3.F3.7.m3.1.1.2a.cmml" xref="S3.F3.7.m3.1.1.2"><mtext id="S3.F3.7.m3.1.1.2.cmml" xref="S3.F3.7.m3.1.1.2">T</mtext></ci><ci id="S3.F3.7.m3.1.1.3.cmml" xref="S3.F3.7.m3.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.7.m3.1d">\textup{T}_{i}</annotation></semantics></math> are the final hidden vectors of token [CLS] and <math id="S3.F3.8.m4.1" class="ltx_Math" alttext="i^{\textup{th}}" display="inline"><semantics id="S3.F3.8.m4.1b"><msup id="S3.F3.8.m4.1.1" xref="S3.F3.8.m4.1.1.cmml"><mi id="S3.F3.8.m4.1.1.2" xref="S3.F3.8.m4.1.1.2.cmml">i</mi><mtext id="S3.F3.8.m4.1.1.3" xref="S3.F3.8.m4.1.1.3a.cmml">th</mtext></msup><annotation-xml encoding="MathML-Content" id="S3.F3.8.m4.1c"><apply id="S3.F3.8.m4.1.1.cmml" xref="S3.F3.8.m4.1.1"><csymbol cd="ambiguous" id="S3.F3.8.m4.1.1.1.cmml" xref="S3.F3.8.m4.1.1">superscript</csymbol><ci id="S3.F3.8.m4.1.1.2.cmml" xref="S3.F3.8.m4.1.1.2">𝑖</ci><ci id="S3.F3.8.m4.1.1.3a.cmml" xref="S3.F3.8.m4.1.1.3"><mtext mathsize="70%" id="S3.F3.8.m4.1.1.3.cmml" xref="S3.F3.8.m4.1.1.3">th</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.8.m4.1d">i^{\textup{th}}</annotation></semantics></math> token, respectively.</figcaption>
</figure>
<div id="S3.SS2.SSS2.p2" class="ltx_para">
<p id="S3.SS2.SSS2.p2.1" class="ltx_p"><span id="S3.SS2.SSS2.p2.1.1" class="ltx_text ltx_font_bold">Overview of BERT model</span>:
In this paper, we use Huggingface’s library called <em id="S3.SS2.SSS2.p2.1.2" class="ltx_emph ltx_font_italic">transformers</em> to use the bert-base-uncased pretrained on a large corpus of English texts <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite> such as English Wikipedia and BookCorpus. The model has 12 layers of transformers, 768 hidden sizes, 12 self-attention heads, and altogether 110 million parameters.
BERT model is used for various tasks other than natural language processing by performing its fine-tuning. In this process, few layers are added to the end of the model (e.g., classification layer) and train/test the whole model with a small learning rate over the available dataset.
The model is pre-trained for two tasks: masked language modeling (MLM) and next sentence prediction (NSP). MLM predicts the masked words in a sentence whose 15% words are randomly masked by the model at the beginning. NSP predicts whether two sentences, which have their words masked to some percentage, follow each other or not. Thus the embedding has special tokens [CLS] at the beginning of each sentence, [SEP] to separate two sentences in a sequence and the end of the sentence, and [MASK] to mask any word in the sentence. An overview of the BERT model for a classification task is depicted in Fig. <a href="#S3.F3" title="Figure 3 ‣ 3.2.2 Bidirectional Encoder Representations from Transformers ‣ 3.2 Deep learning model selection: ‣ 3 Experimental setup ‣ Evaluation of Federated Learning in Phishing Email Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>.</p>
</div>
<div id="S3.SS2.SSS2.p3" class="ltx_para">
<p id="S3.SS2.SSS2.p3.1" class="ltx_p">BERT has been used in phishing email detection <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>. The authors designed a smaller BERT, called CatBERT, by pruning odd-numbered transformers from it and replacing those with adapters. CatBERT is reported to achieve 87% of detection rate on their own data collected at Sophos, and it is best compared to the DistilBERT (compressed BERT model) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite> and LSTM based models on their dataset.
Our focus in this paper is to demonstrate the feasibility of FL on the detection side. We proceed by exploring the standard BERT rather than distilled BERT models (which only benefit computation). To our best knowledge, only CL has been observed and analyzed for the BERT in phishing email detection.
Moreover, in centralized learning, the performance of the standard BERT in phishing email detection is still not clear.</p>
</div>
<div id="S3.SS2.SSS2.p4" class="ltx_para">
<p id="S3.SS2.SSS2.p4.1" class="ltx_p">In our experiments, BERT considers only the body of email samples as its input because, unlike THEMIS, it has no dedicated architectural part to get all header fields separately. However, we can concatenate the header information to the body and feed it to the BERT model.</p>
</div>
</section>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span><span id="S3.SS3.1.1" class="ltx_text ltx_font_italic">Data preparation</span>
</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">We have different data sources and data distribution among the clients in our FL setups. For <span id="S3.SS3.p1.1.1" class="ltx_text ltx_font_bold">RQ1</span> to <span id="S3.SS3.p1.1.2" class="ltx_text ltx_font_bold">RQ5</span>, we consider three email sources, namely IWSPA-AP, Nazario, and Enron, with a total of 23,475 email samples. We consider the other two sources, CSIRO and Phishbowl emails, for <span id="S3.SS3.p1.1.3" class="ltx_text ltx_font_bold">RQ6</span>. We did this division as there are only 441 phishing email samples from CSIRO and Phishbowl emails, and they should be analyzed only in the extreme dataset diversity under <span id="S3.SS3.p1.1.4" class="ltx_text ltx_font_bold">RQ6</span>.</p>
</div>
<div id="S3.SS3.p2" class="ltx_para">
<p id="S3.SS3.p2.1" class="ltx_p">Under our balanced dataset setup for <span id="S3.SS3.p2.1.1" class="ltx_text ltx_font_bold">RQ1</span> to <span id="S3.SS3.p2.1.2" class="ltx_text ltx_font_bold">RQ4</span>, including the asymmetric dataset for <span id="S3.SS3.p2.1.3" class="ltx_text ltx_font_bold">RQ4</span>, we consider equal phishing and legitimate email samples out of 23,475 data samples. So, we prepare the experimental dataset of size 20,044 (i.e., <math id="S3.SS3.p2.1.m1.2" class="ltx_Math" alttext="2\times 10,022" display="inline"><semantics id="S3.SS3.p2.1.m1.2a"><mrow id="S3.SS3.p2.1.m1.2.2.1" xref="S3.SS3.p2.1.m1.2.2.2.cmml"><mrow id="S3.SS3.p2.1.m1.2.2.1.1" xref="S3.SS3.p2.1.m1.2.2.1.1.cmml"><mn id="S3.SS3.p2.1.m1.2.2.1.1.2" xref="S3.SS3.p2.1.m1.2.2.1.1.2.cmml">2</mn><mo lspace="0.222em" rspace="0.222em" id="S3.SS3.p2.1.m1.2.2.1.1.1" xref="S3.SS3.p2.1.m1.2.2.1.1.1.cmml">×</mo><mn id="S3.SS3.p2.1.m1.2.2.1.1.3" xref="S3.SS3.p2.1.m1.2.2.1.1.3.cmml">10</mn></mrow><mo id="S3.SS3.p2.1.m1.2.2.1.2" xref="S3.SS3.p2.1.m1.2.2.2.cmml">,</mo><mn id="S3.SS3.p2.1.m1.1.1" xref="S3.SS3.p2.1.m1.1.1.cmml">022</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.1.m1.2b"><list id="S3.SS3.p2.1.m1.2.2.2.cmml" xref="S3.SS3.p2.1.m1.2.2.1"><apply id="S3.SS3.p2.1.m1.2.2.1.1.cmml" xref="S3.SS3.p2.1.m1.2.2.1.1"><times id="S3.SS3.p2.1.m1.2.2.1.1.1.cmml" xref="S3.SS3.p2.1.m1.2.2.1.1.1"></times><cn type="integer" id="S3.SS3.p2.1.m1.2.2.1.1.2.cmml" xref="S3.SS3.p2.1.m1.2.2.1.1.2">2</cn><cn type="integer" id="S3.SS3.p2.1.m1.2.2.1.1.3.cmml" xref="S3.SS3.p2.1.m1.2.2.1.1.3">10</cn></apply><cn type="integer" id="S3.SS3.p2.1.m1.1.1.cmml" xref="S3.SS3.p2.1.m1.1.1">022</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.1.m1.2c">2\times 10,022</annotation></semantics></math>) — to be precise, 10,022 is aligned with the number of phishing emails while the number of legitimate emails is 13,453. Moreover, the new dataset has four parts - phishing header, phishing body, legitimate header, and legitimate body - each part with 10,022 samples.
The experimental dataset is equally and uniformly distributed in all our distributed setups with multiple clients except for the cases with the asymmetric dataset (<span id="S3.SS3.p2.1.4" class="ltx_text ltx_font_bold">RQ4</span>, <span id="S3.SS3.p2.1.5" class="ltx_text ltx_font_bold">RQ5</span>, and <span id="S3.SS3.p2.1.6" class="ltx_text ltx_font_bold">RQ6</span>). For example, cases with five clients have a dataset of size 4008 (i.e., around 20044 divided by 5) in each client.
Under the distributed setup for <span id="S3.SS3.p2.1.7" class="ltx_text ltx_font_bold">RQ5</span>, we perform two experiments (i) each client has different sizes of email samples with 50:50 phishing to legitimate email ratio, and (ii) each client has the same sizes of email samples but with different phishing to legitimate email ratio.
Under <span id="S3.SS3.p2.1.8" class="ltx_text ltx_font_bold">RQ6</span>, we consider five clients, each uniquely corresponding to one of our five data sources.</p>
</div>
<div id="S3.SS3.p3" class="ltx_para">
<p id="S3.SS3.p3.1" class="ltx_p">We perform all the above data distributions for experimental setups, which simulate cases with multiple organizations having their own local data (distributed data) in different geo-locations and remaining in silos.
For all experiments, the training-to-testing data split ratio is 80:20.</p>
</div>
<div id="S3.SS3.p4" class="ltx_para">
<p id="S3.SS3.p4.1" class="ltx_p">Our email data sources have two types of file formats, viz., text file (.txt) and mbox file (.mbox). Each email is a single text file if the email sample is in text format. In the mbox format, all messages are concatenated and stored as plain text in a single file. Moreover, each message starts with the four characters "From" followed by a space. Both types of email files are firstly parsed into two parts, namely email header and email body, and then subjected to further processing, including cleaning and tokenization.</p>
</div>
<section id="S3.SS3.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.3.1 </span>Extraction of Header and Body</h4>

<div id="S3.SS3.SSS1.p1" class="ltx_para">
<p id="S3.SS3.SSS1.p1.1" class="ltx_p">The class <span id="S3.SS3.SSS1.p1.1.1" class="ltx_text ltx_font_typewriter">Header</span> of the python module, called <span id="S3.SS3.SSS1.p1.1.2" class="ltx_text ltx_font_typewriter">email.header</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite>, is used to extract the email header, and this separates the header and body part of the email samples. In the header section, we consider only the <em id="S3.SS3.SSS1.p1.1.3" class="ltx_emph ltx_font_italic">Subject</em> and the <em id="S3.SS3.SSS1.p1.1.4" class="ltx_emph ltx_font_italic">Content-Type</em> field, which are deemed essential for phishing detection. This separation is done by using the python library called the regular expression (RE) module <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite>.</p>
</div>
</section>
<section id="S3.SS3.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.3.2 </span>Cleaning of the Extracted Header and Body</h4>

<div id="S3.SS3.SSS2.p1" class="ltx_para">
<p id="S3.SS3.SSS2.p1.1" class="ltx_p">The python library <span id="S3.SS3.SSS2.p1.1.1" class="ltx_text ltx_font_typewriter">Beautiful Soup 4</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite> and <span id="S3.SS3.SSS2.p1.1.2" class="ltx_text ltx_font_typewriter">HTML parser</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref">33</a>]</cite> are used to clean the text information in HTML format. Besides, we use RE for the plain text (both in header and body) cleaning by removing punctuation and non-alphabetic characters. To filter out the stop words from the header and body, we use <span id="S3.SS3.SSS2.p1.1.3" class="ltx_text ltx_font_typewriter">stopwords</span> of the nltk packages (<span id="S3.SS3.SSS2.p1.1.4" class="ltx_text ltx_font_typewriter">nltk.corpus</span>) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite> of python.</p>
</div>
</section>
<section id="S3.SS3.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.3.3 </span>Tokenization</h4>

<div id="S3.SS3.SSS3.p1" class="ltx_para">
<p id="S3.SS3.SSS3.p1.1" class="ltx_p">Our two models under investigation require different tokenization methods.</p>
</div>
<div id="S3.SS3.SSS3.p2" class="ltx_para">
<p id="S3.SS3.SSS3.p2.1" class="ltx_p">For THEMIS, we performed tokenization in the following way:
To get the char-level and word-level sequences of the tokens for both header and body parts, the Tokenizer class provided by <span id="S3.SS3.SSS3.p2.1.1" class="ltx_text ltx_font_typewriter">Keras</span> library <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite> is used.
Basically, this is to encode each character/word as a unique integer as required by the input format of the embedding layer.
Two main functions are used for tokenization; these are ‘fit_on_texts,’ which updates internal vocabulary based on a list of texts, and ‘texts_to_sequences,’ which transforms each text in texts to a sequence of integers by considering only words known by the tokenizer. In all our measurements, we keep 50, 100, 150, and 300 as the length of the four sequences of tokens, which are word-level header, char-level header, word-level body, and char-level body, respectively.</p>
</div>
<div id="S3.SS3.SSS3.p3" class="ltx_para">
<p id="S3.SS3.SSS3.p3.1" class="ltx_p">For BERT, we consider only the email body and performed its tokenization in the following way: We used BertTokenizer <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite> provided by Huggingface library to encode the email’s body to tokens. Besides, the tokenizer inserts additional special tokens such as [CLS] and [SEP] in the process. BERT allows only 512 tokens to be inputted at a time, and it is considered during tokenization. Also, the tokenizer returns original input ids, attention masks, and token type ids required during learning.</p>
</div>
</section>
</section>
<section id="S3.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4 </span><span id="S3.SS4.1.1" class="ltx_text ltx_font_italic">Experimental steps</span>
</h3>

<div id="S3.SS4.p1" class="ltx_para">
<p id="S3.SS4.p1.1" class="ltx_p">For performance analysis, we use a High-performance Computing (HPC) platform that is built on <em id="S3.SS4.p1.1.1" class="ltx_emph ltx_font_italic">Dell EMC’s PowerEdge</em> platform. It has the <em id="S3.SS4.p1.1.2" class="ltx_emph ltx_font_italic">Tesla P100-SXM2-16GB</em> GPU model. All code is written in Python 3.6.1. The THEMIS model, which has an RCNN, is implemented by using TensorFlow 2.2.5 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite> and Keras 2.2.5 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib38" title="" class="ltx_ref">38</a>]</cite> framework, and the BERT model, a pretrained transformer model, is downloaded from the Huggingface library. In all measurements, we keep the same random seed, i.e., <span id="S3.SS4.p1.1.3" class="ltx_text ltx_font_typewriter">random.seed(123)</span>. We run centralized model training and federated model training under various settings in our experiments, but with the same (i) learning rate of 0.0001 and batch size of 256 for THEMIS model, and (ii) learning rate of 0.00001 and batch size of 4 for BERT model. The specific batch size is chosen based on the available resources (e.g., GPU has 16GB internal memory).</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span><span id="S4.1.1" class="ltx_text ltx_font_smallcaps">Results</span>
</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">To ease the presentation, we divide this section into four parts under which the six research questions are analyzed with the empirical results. We perform experiments with the THEMIS model in this work, considering both with and without email header information. For convenience, we refer to <em id="S4.p1.1.1" class="ltx_emph ltx_font_italic">THEMIS</em> model if it considers both email’s header and body information, and <em id="S4.p1.1.2" class="ltx_emph ltx_font_italic">THEMISb</em> model if it considers only email’s body information in the remainder of this paper.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span><span id="S4.SS1.1.1" class="ltx_text ltx_font_italic">Distributed email learning under balanced data distribution</span>
</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.6" class="ltx_p">Considering the CL’s accuracy as the baseline, for <span id="S4.SS1.p1.6.1" class="ltx_text ltx_font_bold">RQ1</span>, <span id="S4.SS1.p1.6.2" class="ltx_text ltx_font_bold">RQ2</span>, and <span id="S4.SS1.p1.6.3" class="ltx_text ltx_font_bold">RQ3</span>, we perform experiments under a balanced data distribution among the clients where the total dataset remains the same. In other words, for the total dataset <math id="S4.SS1.p1.1.m1.1" class="ltx_Math" alttext="D" display="inline"><semantics id="S4.SS1.p1.1.m1.1a"><mi id="S4.SS1.p1.1.m1.1.1" xref="S4.SS1.p1.1.m1.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.1.m1.1b"><ci id="S4.SS1.p1.1.m1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1">𝐷</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.1.m1.1c">D</annotation></semantics></math>, and for any number of clients <math id="S4.SS1.p1.2.m2.1" class="ltx_Math" alttext="K\geq 1" display="inline"><semantics id="S4.SS1.p1.2.m2.1a"><mrow id="S4.SS1.p1.2.m2.1.1" xref="S4.SS1.p1.2.m2.1.1.cmml"><mi id="S4.SS1.p1.2.m2.1.1.2" xref="S4.SS1.p1.2.m2.1.1.2.cmml">K</mi><mo id="S4.SS1.p1.2.m2.1.1.1" xref="S4.SS1.p1.2.m2.1.1.1.cmml">≥</mo><mn id="S4.SS1.p1.2.m2.1.1.3" xref="S4.SS1.p1.2.m2.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.2.m2.1b"><apply id="S4.SS1.p1.2.m2.1.1.cmml" xref="S4.SS1.p1.2.m2.1.1"><geq id="S4.SS1.p1.2.m2.1.1.1.cmml" xref="S4.SS1.p1.2.m2.1.1.1"></geq><ci id="S4.SS1.p1.2.m2.1.1.2.cmml" xref="S4.SS1.p1.2.m2.1.1.2">𝐾</ci><cn type="integer" id="S4.SS1.p1.2.m2.1.1.3.cmml" xref="S4.SS1.p1.2.m2.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.2.m2.1c">K\geq 1</annotation></semantics></math>, <math id="S4.SS1.p1.3.m3.1" class="ltx_Math" alttext="\bigcup_{k}D_{k}=D" display="inline"><semantics id="S4.SS1.p1.3.m3.1a"><mrow id="S4.SS1.p1.3.m3.1.1" xref="S4.SS1.p1.3.m3.1.1.cmml"><mrow id="S4.SS1.p1.3.m3.1.1.2" xref="S4.SS1.p1.3.m3.1.1.2.cmml"><msub id="S4.SS1.p1.3.m3.1.1.2.1" xref="S4.SS1.p1.3.m3.1.1.2.1.cmml"><mo id="S4.SS1.p1.3.m3.1.1.2.1.2" xref="S4.SS1.p1.3.m3.1.1.2.1.2.cmml">⋃</mo><mi id="S4.SS1.p1.3.m3.1.1.2.1.3" xref="S4.SS1.p1.3.m3.1.1.2.1.3.cmml">k</mi></msub><msub id="S4.SS1.p1.3.m3.1.1.2.2" xref="S4.SS1.p1.3.m3.1.1.2.2.cmml"><mi id="S4.SS1.p1.3.m3.1.1.2.2.2" xref="S4.SS1.p1.3.m3.1.1.2.2.2.cmml">D</mi><mi id="S4.SS1.p1.3.m3.1.1.2.2.3" xref="S4.SS1.p1.3.m3.1.1.2.2.3.cmml">k</mi></msub></mrow><mo id="S4.SS1.p1.3.m3.1.1.1" xref="S4.SS1.p1.3.m3.1.1.1.cmml">=</mo><mi id="S4.SS1.p1.3.m3.1.1.3" xref="S4.SS1.p1.3.m3.1.1.3.cmml">D</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.3.m3.1b"><apply id="S4.SS1.p1.3.m3.1.1.cmml" xref="S4.SS1.p1.3.m3.1.1"><eq id="S4.SS1.p1.3.m3.1.1.1.cmml" xref="S4.SS1.p1.3.m3.1.1.1"></eq><apply id="S4.SS1.p1.3.m3.1.1.2.cmml" xref="S4.SS1.p1.3.m3.1.1.2"><apply id="S4.SS1.p1.3.m3.1.1.2.1.cmml" xref="S4.SS1.p1.3.m3.1.1.2.1"><csymbol cd="ambiguous" id="S4.SS1.p1.3.m3.1.1.2.1.1.cmml" xref="S4.SS1.p1.3.m3.1.1.2.1">subscript</csymbol><union id="S4.SS1.p1.3.m3.1.1.2.1.2.cmml" xref="S4.SS1.p1.3.m3.1.1.2.1.2"></union><ci id="S4.SS1.p1.3.m3.1.1.2.1.3.cmml" xref="S4.SS1.p1.3.m3.1.1.2.1.3">𝑘</ci></apply><apply id="S4.SS1.p1.3.m3.1.1.2.2.cmml" xref="S4.SS1.p1.3.m3.1.1.2.2"><csymbol cd="ambiguous" id="S4.SS1.p1.3.m3.1.1.2.2.1.cmml" xref="S4.SS1.p1.3.m3.1.1.2.2">subscript</csymbol><ci id="S4.SS1.p1.3.m3.1.1.2.2.2.cmml" xref="S4.SS1.p1.3.m3.1.1.2.2.2">𝐷</ci><ci id="S4.SS1.p1.3.m3.1.1.2.2.3.cmml" xref="S4.SS1.p1.3.m3.1.1.2.2.3">𝑘</ci></apply></apply><ci id="S4.SS1.p1.3.m3.1.1.3.cmml" xref="S4.SS1.p1.3.m3.1.1.3">𝐷</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.3.m3.1c">\bigcup_{k}D_{k}=D</annotation></semantics></math>, where <math id="S4.SS1.p1.4.m4.1" class="ltx_Math" alttext="D_{k}" display="inline"><semantics id="S4.SS1.p1.4.m4.1a"><msub id="S4.SS1.p1.4.m4.1.1" xref="S4.SS1.p1.4.m4.1.1.cmml"><mi id="S4.SS1.p1.4.m4.1.1.2" xref="S4.SS1.p1.4.m4.1.1.2.cmml">D</mi><mi id="S4.SS1.p1.4.m4.1.1.3" xref="S4.SS1.p1.4.m4.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.4.m4.1b"><apply id="S4.SS1.p1.4.m4.1.1.cmml" xref="S4.SS1.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S4.SS1.p1.4.m4.1.1.1.cmml" xref="S4.SS1.p1.4.m4.1.1">subscript</csymbol><ci id="S4.SS1.p1.4.m4.1.1.2.cmml" xref="S4.SS1.p1.4.m4.1.1.2">𝐷</ci><ci id="S4.SS1.p1.4.m4.1.1.3.cmml" xref="S4.SS1.p1.4.m4.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.4.m4.1c">D_{k}</annotation></semantics></math> is the dataset of the client <math id="S4.SS1.p1.5.m5.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S4.SS1.p1.5.m5.1a"><mi id="S4.SS1.p1.5.m5.1.1" xref="S4.SS1.p1.5.m5.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.5.m5.1b"><ci id="S4.SS1.p1.5.m5.1.1.cmml" xref="S4.SS1.p1.5.m5.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.5.m5.1c">k</annotation></semantics></math>, <math id="S4.SS1.p1.6.m6.4" class="ltx_Math" alttext="k\in\{1,2,\dots,K\}" display="inline"><semantics id="S4.SS1.p1.6.m6.4a"><mrow id="S4.SS1.p1.6.m6.4.5" xref="S4.SS1.p1.6.m6.4.5.cmml"><mi id="S4.SS1.p1.6.m6.4.5.2" xref="S4.SS1.p1.6.m6.4.5.2.cmml">k</mi><mo id="S4.SS1.p1.6.m6.4.5.1" xref="S4.SS1.p1.6.m6.4.5.1.cmml">∈</mo><mrow id="S4.SS1.p1.6.m6.4.5.3.2" xref="S4.SS1.p1.6.m6.4.5.3.1.cmml"><mo stretchy="false" id="S4.SS1.p1.6.m6.4.5.3.2.1" xref="S4.SS1.p1.6.m6.4.5.3.1.cmml">{</mo><mn id="S4.SS1.p1.6.m6.1.1" xref="S4.SS1.p1.6.m6.1.1.cmml">1</mn><mo id="S4.SS1.p1.6.m6.4.5.3.2.2" xref="S4.SS1.p1.6.m6.4.5.3.1.cmml">,</mo><mn id="S4.SS1.p1.6.m6.2.2" xref="S4.SS1.p1.6.m6.2.2.cmml">2</mn><mo id="S4.SS1.p1.6.m6.4.5.3.2.3" xref="S4.SS1.p1.6.m6.4.5.3.1.cmml">,</mo><mi mathvariant="normal" id="S4.SS1.p1.6.m6.3.3" xref="S4.SS1.p1.6.m6.3.3.cmml">…</mi><mo id="S4.SS1.p1.6.m6.4.5.3.2.4" xref="S4.SS1.p1.6.m6.4.5.3.1.cmml">,</mo><mi id="S4.SS1.p1.6.m6.4.4" xref="S4.SS1.p1.6.m6.4.4.cmml">K</mi><mo stretchy="false" id="S4.SS1.p1.6.m6.4.5.3.2.5" xref="S4.SS1.p1.6.m6.4.5.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.6.m6.4b"><apply id="S4.SS1.p1.6.m6.4.5.cmml" xref="S4.SS1.p1.6.m6.4.5"><in id="S4.SS1.p1.6.m6.4.5.1.cmml" xref="S4.SS1.p1.6.m6.4.5.1"></in><ci id="S4.SS1.p1.6.m6.4.5.2.cmml" xref="S4.SS1.p1.6.m6.4.5.2">𝑘</ci><set id="S4.SS1.p1.6.m6.4.5.3.1.cmml" xref="S4.SS1.p1.6.m6.4.5.3.2"><cn type="integer" id="S4.SS1.p1.6.m6.1.1.cmml" xref="S4.SS1.p1.6.m6.1.1">1</cn><cn type="integer" id="S4.SS1.p1.6.m6.2.2.cmml" xref="S4.SS1.p1.6.m6.2.2">2</cn><ci id="S4.SS1.p1.6.m6.3.3.cmml" xref="S4.SS1.p1.6.m6.3.3">…</ci><ci id="S4.SS1.p1.6.m6.4.4.cmml" xref="S4.SS1.p1.6.m6.4.4">𝐾</ci></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.6.m6.4c">k\in\{1,2,\dots,K\}</annotation></semantics></math>.
We keep the same size of the total dataset despite the change in the number of clients. This is done to see the effect of the change in the number of clients (datasets distribution) within the same total dataset.
In our setups, we reasonably assume that the clients are with resourceful computation to jointly training the FL model to preserve the privacy of emails. 
<br class="ltx_break"><span id="S4.SS1.p1.6.4" class="ltx_text ltx_font_bold">How THEMIS and THEMISb perform?
<br class="ltx_break"></span>THEMIS outperforms THEMISb in our experiments. In CL at the 45 global epoch, for THEMIS, we observe an accuracy of 99.301%, FPR of 0.0035, and FNR of 0.0105 (see Fig. <a href="#S4.F4" title="Figure 4 ‣ 4.1 Distributed email learning under balanced data distribution ‣ 4 Results ‣ Evaluation of Federated Learning in Phishing Email Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>), whereas THEMISb only provides an accuracy of 95.085% (drop by around 4%), FPR of 0.022 and FNR of 0.0778 (see Fig. <a href="#A1.F13" title="Figure 13 ‣ A.1 Performance of THEMISb (considering email’s body only) in the centralized and federated learning with two, five, and ten clients. ‣ Appendix A Supplemental results ‣ Evaluation of Federated Learning in Phishing Email Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">13</span></a>). This indicates that header information is critical for the THEMIS model, and it is leveraging them well for phishing detection.
The accuracy and FPR stated in the THEMIS paper <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite> are 99.848% and 0.043%, respectively. These values are nominally different than our case. This can be due to various reasons, including email data samples, sample size (see Section <a href="#S3.SS2.SSS1" title="3.2.1 THEMIS model ‣ 3.2 Deep learning model selection: ‣ 3 Experimental setup ‣ Evaluation of Federated Learning in Phishing Email Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.2.1</span></a>), and model hyper-parameters.</p>
</div>
<div id="Thmresearchq1" class="ltx_theorem ltx_theorem_researchq">
<h6 class="ltx_title ltx_runin ltx_title_theorem"><span class="ltx_tag ltx_tag_theorem"><span id="Thmresearchq1.1.1.1" class="ltx_text ltx_font_bold">RQ 1</span></span></h6>
<div id="Thmresearchq1.p1" class="ltx_para">
<p id="Thmresearchq1.p1.1" class="ltx_p"><span id="Thmresearchq1.p1.1.1" class="ltx_text ltx_font_bold ltx_font_italic">Can FL be applied to learn from distributed email repositories to achieve comparable performance to centralized learning?<span id="Thmresearchq1.p1.1.1.1" class="ltx_text ltx_font_medium"></span></span></p>
</div>
</div>
<figure id="S4.F4" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S4.F4.1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2007.13300/assets/x4.png" id="S4.F4.1.g1" class="ltx_graphics ltx_img_landscape" width="432" height="299" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S4.F4.2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2007.13300/assets/x5.png" id="S4.F4.2.g1" class="ltx_graphics ltx_img_landscape" width="432" height="298" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S4.F4.3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2007.13300/assets/x6.png" id="S4.F4.3.g1" class="ltx_graphics ltx_img_landscape" width="597" height="127" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S4.F4.4" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2007.13300/assets/x7.png" id="S4.F4.4.g1" class="ltx_graphics ltx_img_landscape" width="597" height="142" alt="Refer to caption">
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Results for the THEMIS model: Convergence curves of average testing accuracy for the (a) local models and (b) global model. Performance metrics of the testing results at the 45 global epoch in centralized and federated learning (FL) with two, five, and ten clients are depicted in (c) and (d).
</figcaption>
</figure>
<figure id="S4.F5" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S4.F5.1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2007.13300/assets/x8.png" id="S4.F5.1.g1" class="ltx_graphics ltx_img_landscape" width="432" height="299" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S4.F5.2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2007.13300/assets/x9.png" id="S4.F5.2.g1" class="ltx_graphics ltx_img_landscape" width="432" height="298" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S4.F5.3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2007.13300/assets/x10.png" id="S4.F5.3.g1" class="ltx_graphics ltx_img_landscape" width="597" height="126" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S4.F5.4" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2007.13300/assets/x11.png" id="S4.F5.4.g1" class="ltx_graphics ltx_img_landscape" width="597" height="105" alt="Refer to caption">
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Results for the BERT model: Convergence curves of average testing accuracy for the (a) local models and (b) global model. Corresponding performance metrics of the testing results at the global epoch of 15 in centralized and federated learning (FL) with two and five clients are depicted in (c) and (d).
</figcaption>
</figure>
<div id="S4.SS1.p2" class="ltx_para">
<p id="S4.SS1.p2.1" class="ltx_p">Under FL with 2, 5, and 10 clients, the THEMIS model converges to get local and global model test accuracy greater than around 96% in the observation window of 45 global epochs. However, none of them achieves the CL performance of 99.3% accuracy within our observation window. Similar performance is observed with the THEMISb model.
For the BERT model (which only considers emails without header information while training/testing), at 15 global epoch, we have (i) in CL, testing accuracy of 96.183%, FPR of 0.0091 and FNR of 0.0576, (ii) in FL with two clients, global testing accuracy of 95.559%, FPR 0.017 of and FNR of 0.0719, and (iii) in FL with five clients, global testing accuracy of 96.11%, FPR 0.0091 of and FNR of 0.0610 (see Fig. <a href="#S4.F5" title="Figure 5 ‣ 4.1 Distributed email learning under balanced data distribution ‣ 4 Results ‣ Evaluation of Federated Learning in Phishing Email Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>).
We find that BERT performance is not good as THEMIS, but it is better than THEMISb in our observations.</p>
</div>
<div id="S4.SS1.p3" class="ltx_para">
<span id="S4.SS1.p3.1" class="ltx_inline-block ltx_framed ltx_framed_rectangle" style="border-color: #000000;">
<span id="S4.SS1.p3.1.1" class="ltx_p"><span id="S4.SS1.p3.1.1.1" class="ltx_text ltx_font_bold">Summary:</span> FL is feasible with comparable performance to the CL for phishing email detection. It enables privacy benefits to the system, but it could not achieve the CL performance as a trade-off in our experiments.</span>
</span>
</div>
<div id="Thmresearchq2" class="ltx_theorem ltx_theorem_researchq">
<h6 class="ltx_title ltx_runin ltx_title_theorem"><span class="ltx_tag ltx_tag_theorem"><span id="Thmresearchq2.1.1.1" class="ltx_text ltx_font_bold">RQ 2</span></span></h6>
<div id="Thmresearchq2.p1" class="ltx_para">
<p id="Thmresearchq2.p1.1" class="ltx_p"><span id="Thmresearchq2.p1.1.1" class="ltx_text ltx_font_bold ltx_font_italic">How would the number of clients affect FL performance and convergence?<span id="Thmresearchq2.p1.1.1.1" class="ltx_text ltx_font_medium"></span></span></p>
</div>
</div>
<div id="S4.SS1.p4" class="ltx_para">
<p id="S4.SS1.p4.1" class="ltx_p">For FL with THEMIS model, the convergence patterns for both local and global models are similar. However, in both cases, the average performances degraded with the increase in the number of clients. For example, we observe the global testing accuracy at the 45 global epoch drops by 1.8% going from two clients setup to ten clients setup with the THEMIS model (see Fig. <a href="#S4.F4" title="Figure 4 ‣ 4.1 Distributed email learning under balanced data distribution ‣ 4 Results ‣ Evaluation of Federated Learning in Phishing Email Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>). The potential reason for this drop might be the effect on convergence rate due to local shuffling in distributed setup; the convergence rate is dominated by local training size and more the better <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref">39</a>]</cite>. For THEMISb, the drop is about 6% going from two clients to ten clients. This drop in THEMISb is significant in comparison to THEMIS.</p>
</div>
<div id="S4.SS1.p5" class="ltx_para">
<p id="S4.SS1.p5.1" class="ltx_p">For FL with BERT, the local and global BERT model performance drop is negligible compared with the BERT in CL, e.g., only 0.6% for 2 clients (see Fig. <a href="#S4.F5" title="Figure 5 ‣ 4.1 Distributed email learning under balanced data distribution ‣ 4 Results ‣ Evaluation of Federated Learning in Phishing Email Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>). In contrast to THEMIS/THEMISb performance, the BERT performance does not degrade with the increase in clients, as the BERT with 5 clients is showing better performance than BERT with 2 clients by 0.6% in accuracy at the 15 global epoch.</p>
</div>
<div id="S4.SS1.p6" class="ltx_para">
<span id="S4.SS1.p6.1" class="ltx_inline-block ltx_framed ltx_framed_rectangle" style="border-color: #000000;">
<span id="S4.SS1.p6.1.1" class="ltx_p"><span id="S4.SS1.p6.1.1.1" class="ltx_text ltx_font_bold">Summary:</span> The convergence and performance with the increase in the number of clients in FL are model-dependent. For THEMIS, there are slower convergences and performance degradation with the increase in clients, whereas BERT has the opposite in our experiments.</span>
</span>
</div>
<div id="Thmresearchq3" class="ltx_theorem ltx_theorem_researchq">
<h6 class="ltx_title ltx_runin ltx_title_theorem"><span class="ltx_tag ltx_tag_theorem"><span id="Thmresearchq3.1.1.1" class="ltx_text ltx_font_bold">RQ 3</span></span></h6>
<div id="Thmresearchq3.p1" class="ltx_para">
<p id="Thmresearchq3.p1.1" class="ltx_p"><span id="Thmresearchq3.p1.1.1" class="ltx_text ltx_font_bold ltx_font_italic">What is communication overhead resulting from FL?<span id="Thmresearchq3.p1.1.1.1" class="ltx_text ltx_font_medium"></span></span></p>
</div>
</div>
<div id="S4.SS1.p7" class="ltx_para">
<p id="S4.SS1.p7.3" class="ltx_p">As the main server is assumed to have sufficient resources to handle any communication overhead, our concern is with clients who have relatively low resources than the server. Thus the quantification of communication overhead in FL is limited to the client-side.
We measure the data uploaded (i.e., a sum of the data packet size of <math id="S4.SS1.p7.1.m1.1" class="ltx_Math" alttext="W_{t}^{k}" display="inline"><semantics id="S4.SS1.p7.1.m1.1a"><msubsup id="S4.SS1.p7.1.m1.1.1" xref="S4.SS1.p7.1.m1.1.1.cmml"><mi id="S4.SS1.p7.1.m1.1.1.2.2" xref="S4.SS1.p7.1.m1.1.1.2.2.cmml">W</mi><mi id="S4.SS1.p7.1.m1.1.1.2.3" xref="S4.SS1.p7.1.m1.1.1.2.3.cmml">t</mi><mi id="S4.SS1.p7.1.m1.1.1.3" xref="S4.SS1.p7.1.m1.1.1.3.cmml">k</mi></msubsup><annotation-xml encoding="MathML-Content" id="S4.SS1.p7.1.m1.1b"><apply id="S4.SS1.p7.1.m1.1.1.cmml" xref="S4.SS1.p7.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS1.p7.1.m1.1.1.1.cmml" xref="S4.SS1.p7.1.m1.1.1">superscript</csymbol><apply id="S4.SS1.p7.1.m1.1.1.2.cmml" xref="S4.SS1.p7.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS1.p7.1.m1.1.1.2.1.cmml" xref="S4.SS1.p7.1.m1.1.1">subscript</csymbol><ci id="S4.SS1.p7.1.m1.1.1.2.2.cmml" xref="S4.SS1.p7.1.m1.1.1.2.2">𝑊</ci><ci id="S4.SS1.p7.1.m1.1.1.2.3.cmml" xref="S4.SS1.p7.1.m1.1.1.2.3">𝑡</ci></apply><ci id="S4.SS1.p7.1.m1.1.1.3.cmml" xref="S4.SS1.p7.1.m1.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p7.1.m1.1c">W_{t}^{k}</annotation></semantics></math> and <math id="S4.SS1.p7.2.m2.1" class="ltx_Math" alttext="n_{k}" display="inline"><semantics id="S4.SS1.p7.2.m2.1a"><msub id="S4.SS1.p7.2.m2.1.1" xref="S4.SS1.p7.2.m2.1.1.cmml"><mi id="S4.SS1.p7.2.m2.1.1.2" xref="S4.SS1.p7.2.m2.1.1.2.cmml">n</mi><mi id="S4.SS1.p7.2.m2.1.1.3" xref="S4.SS1.p7.2.m2.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p7.2.m2.1b"><apply id="S4.SS1.p7.2.m2.1.1.cmml" xref="S4.SS1.p7.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS1.p7.2.m2.1.1.1.cmml" xref="S4.SS1.p7.2.m2.1.1">subscript</csymbol><ci id="S4.SS1.p7.2.m2.1.1.2.cmml" xref="S4.SS1.p7.2.m2.1.1.2">𝑛</ci><ci id="S4.SS1.p7.2.m2.1.1.3.cmml" xref="S4.SS1.p7.2.m2.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p7.2.m2.1c">n_{k}</annotation></semantics></math>) and download (i.e., data packet size of <math id="S4.SS1.p7.3.m3.1" class="ltx_Math" alttext="W_{t+1}" display="inline"><semantics id="S4.SS1.p7.3.m3.1a"><msub id="S4.SS1.p7.3.m3.1.1" xref="S4.SS1.p7.3.m3.1.1.cmml"><mi id="S4.SS1.p7.3.m3.1.1.2" xref="S4.SS1.p7.3.m3.1.1.2.cmml">W</mi><mrow id="S4.SS1.p7.3.m3.1.1.3" xref="S4.SS1.p7.3.m3.1.1.3.cmml"><mi id="S4.SS1.p7.3.m3.1.1.3.2" xref="S4.SS1.p7.3.m3.1.1.3.2.cmml">t</mi><mo id="S4.SS1.p7.3.m3.1.1.3.1" xref="S4.SS1.p7.3.m3.1.1.3.1.cmml">+</mo><mn id="S4.SS1.p7.3.m3.1.1.3.3" xref="S4.SS1.p7.3.m3.1.1.3.3.cmml">1</mn></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p7.3.m3.1b"><apply id="S4.SS1.p7.3.m3.1.1.cmml" xref="S4.SS1.p7.3.m3.1.1"><csymbol cd="ambiguous" id="S4.SS1.p7.3.m3.1.1.1.cmml" xref="S4.SS1.p7.3.m3.1.1">subscript</csymbol><ci id="S4.SS1.p7.3.m3.1.1.2.cmml" xref="S4.SS1.p7.3.m3.1.1.2">𝑊</ci><apply id="S4.SS1.p7.3.m3.1.1.3.cmml" xref="S4.SS1.p7.3.m3.1.1.3"><plus id="S4.SS1.p7.3.m3.1.1.3.1.cmml" xref="S4.SS1.p7.3.m3.1.1.3.1"></plus><ci id="S4.SS1.p7.3.m3.1.1.3.2.cmml" xref="S4.SS1.p7.3.m3.1.1.3.2">𝑡</ci><cn type="integer" id="S4.SS1.p7.3.m3.1.1.3.3.cmml" xref="S4.SS1.p7.3.m3.1.1.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p7.3.m3.1c">W_{t+1}</annotation></semantics></math>) to and from the server, respectively, and it is averaged by the total number of the clients. In CL, we do not consider a client-server setup; thus, the communication overhead is zero.</p>
</div>
<div id="S4.SS1.p8" class="ltx_para">
<p id="S4.SS1.p8.1" class="ltx_p">As the sample size information is negligible comparing the model size, the download and upload are almost the size of the global model and the local model, respectively while training, at each client in FL.
Thus the communication overhead solely depends on the model size and thus not on the number of clients or epochs. This is verified from our experiments with the various number of clients. For THEMIS and BERT models, we observe a consistent average communication overhead of around 0.192GB and 0.438GB per global epoch per client, respectively, for all cases.
The overhead can be easily addressed by a well-connected setup with wired or wireless connections between the server and clients who participated in the anti-phishing framework. Thus this is not a concern for organizational-level participation in distributed email learning as these organizations are usually resourceful clients.</p>
</div>
<div id="S4.SS1.p9" class="ltx_para">
<span id="S4.SS1.p9.1" class="ltx_inline-block ltx_framed ltx_framed_rectangle" style="border-color: #000000;">
<span id="S4.SS1.p9.1.1" class="ltx_p"><span id="S4.SS1.p9.1.1.1" class="ltx_text ltx_font_bold">Summary:</span> Communication overhead per client per global epoch is the model’s size-dependent.</span>
</span>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span><span id="S4.SS2.1.1" class="ltx_text ltx_font_italic">Client-level perspectives in FL</span>
</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.8" class="ltx_p">To demonstrate the client-level performance in phishing email detection in distributed setups, we perform three experiments under a balanced and asymmetric data distribution among the clients, where the total dataset changes with the number of clients. In other words, for any number of clients <math id="S4.SS2.p1.1.m1.1" class="ltx_Math" alttext="K\geq 1" display="inline"><semantics id="S4.SS2.p1.1.m1.1a"><mrow id="S4.SS2.p1.1.m1.1.1" xref="S4.SS2.p1.1.m1.1.1.cmml"><mi id="S4.SS2.p1.1.m1.1.1.2" xref="S4.SS2.p1.1.m1.1.1.2.cmml">K</mi><mo id="S4.SS2.p1.1.m1.1.1.1" xref="S4.SS2.p1.1.m1.1.1.1.cmml">≥</mo><mn id="S4.SS2.p1.1.m1.1.1.3" xref="S4.SS2.p1.1.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.1.m1.1b"><apply id="S4.SS2.p1.1.m1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1"><geq id="S4.SS2.p1.1.m1.1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1.1"></geq><ci id="S4.SS2.p1.1.m1.1.1.2.cmml" xref="S4.SS2.p1.1.m1.1.1.2">𝐾</ci><cn type="integer" id="S4.SS2.p1.1.m1.1.1.3.cmml" xref="S4.SS2.p1.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.1.m1.1c">K\geq 1</annotation></semantics></math>, if <math id="S4.SS2.p1.2.m2.1" class="ltx_Math" alttext="\bigcup_{k}D_{k}=D^{\prime}" display="inline"><semantics id="S4.SS2.p1.2.m2.1a"><mrow id="S4.SS2.p1.2.m2.1.1" xref="S4.SS2.p1.2.m2.1.1.cmml"><mrow id="S4.SS2.p1.2.m2.1.1.2" xref="S4.SS2.p1.2.m2.1.1.2.cmml"><msub id="S4.SS2.p1.2.m2.1.1.2.1" xref="S4.SS2.p1.2.m2.1.1.2.1.cmml"><mo id="S4.SS2.p1.2.m2.1.1.2.1.2" xref="S4.SS2.p1.2.m2.1.1.2.1.2.cmml">⋃</mo><mi id="S4.SS2.p1.2.m2.1.1.2.1.3" xref="S4.SS2.p1.2.m2.1.1.2.1.3.cmml">k</mi></msub><msub id="S4.SS2.p1.2.m2.1.1.2.2" xref="S4.SS2.p1.2.m2.1.1.2.2.cmml"><mi id="S4.SS2.p1.2.m2.1.1.2.2.2" xref="S4.SS2.p1.2.m2.1.1.2.2.2.cmml">D</mi><mi id="S4.SS2.p1.2.m2.1.1.2.2.3" xref="S4.SS2.p1.2.m2.1.1.2.2.3.cmml">k</mi></msub></mrow><mo id="S4.SS2.p1.2.m2.1.1.1" xref="S4.SS2.p1.2.m2.1.1.1.cmml">=</mo><msup id="S4.SS2.p1.2.m2.1.1.3" xref="S4.SS2.p1.2.m2.1.1.3.cmml"><mi id="S4.SS2.p1.2.m2.1.1.3.2" xref="S4.SS2.p1.2.m2.1.1.3.2.cmml">D</mi><mo id="S4.SS2.p1.2.m2.1.1.3.3" xref="S4.SS2.p1.2.m2.1.1.3.3.cmml">′</mo></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.2.m2.1b"><apply id="S4.SS2.p1.2.m2.1.1.cmml" xref="S4.SS2.p1.2.m2.1.1"><eq id="S4.SS2.p1.2.m2.1.1.1.cmml" xref="S4.SS2.p1.2.m2.1.1.1"></eq><apply id="S4.SS2.p1.2.m2.1.1.2.cmml" xref="S4.SS2.p1.2.m2.1.1.2"><apply id="S4.SS2.p1.2.m2.1.1.2.1.cmml" xref="S4.SS2.p1.2.m2.1.1.2.1"><csymbol cd="ambiguous" id="S4.SS2.p1.2.m2.1.1.2.1.1.cmml" xref="S4.SS2.p1.2.m2.1.1.2.1">subscript</csymbol><union id="S4.SS2.p1.2.m2.1.1.2.1.2.cmml" xref="S4.SS2.p1.2.m2.1.1.2.1.2"></union><ci id="S4.SS2.p1.2.m2.1.1.2.1.3.cmml" xref="S4.SS2.p1.2.m2.1.1.2.1.3">𝑘</ci></apply><apply id="S4.SS2.p1.2.m2.1.1.2.2.cmml" xref="S4.SS2.p1.2.m2.1.1.2.2"><csymbol cd="ambiguous" id="S4.SS2.p1.2.m2.1.1.2.2.1.cmml" xref="S4.SS2.p1.2.m2.1.1.2.2">subscript</csymbol><ci id="S4.SS2.p1.2.m2.1.1.2.2.2.cmml" xref="S4.SS2.p1.2.m2.1.1.2.2.2">𝐷</ci><ci id="S4.SS2.p1.2.m2.1.1.2.2.3.cmml" xref="S4.SS2.p1.2.m2.1.1.2.2.3">𝑘</ci></apply></apply><apply id="S4.SS2.p1.2.m2.1.1.3.cmml" xref="S4.SS2.p1.2.m2.1.1.3"><csymbol cd="ambiguous" id="S4.SS2.p1.2.m2.1.1.3.1.cmml" xref="S4.SS2.p1.2.m2.1.1.3">superscript</csymbol><ci id="S4.SS2.p1.2.m2.1.1.3.2.cmml" xref="S4.SS2.p1.2.m2.1.1.3.2">𝐷</ci><ci id="S4.SS2.p1.2.m2.1.1.3.3.cmml" xref="S4.SS2.p1.2.m2.1.1.3.3">′</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.2.m2.1c">\bigcup_{k}D_{k}=D^{\prime}</annotation></semantics></math>, where <math id="S4.SS2.p1.3.m3.1" class="ltx_Math" alttext="D_{k}" display="inline"><semantics id="S4.SS2.p1.3.m3.1a"><msub id="S4.SS2.p1.3.m3.1.1" xref="S4.SS2.p1.3.m3.1.1.cmml"><mi id="S4.SS2.p1.3.m3.1.1.2" xref="S4.SS2.p1.3.m3.1.1.2.cmml">D</mi><mi id="S4.SS2.p1.3.m3.1.1.3" xref="S4.SS2.p1.3.m3.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.3.m3.1b"><apply id="S4.SS2.p1.3.m3.1.1.cmml" xref="S4.SS2.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S4.SS2.p1.3.m3.1.1.1.cmml" xref="S4.SS2.p1.3.m3.1.1">subscript</csymbol><ci id="S4.SS2.p1.3.m3.1.1.2.cmml" xref="S4.SS2.p1.3.m3.1.1.2">𝐷</ci><ci id="S4.SS2.p1.3.m3.1.1.3.cmml" xref="S4.SS2.p1.3.m3.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.3.m3.1c">D_{k}</annotation></semantics></math> is the dataset of the client <math id="S4.SS2.p1.4.m4.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S4.SS2.p1.4.m4.1a"><mi id="S4.SS2.p1.4.m4.1.1" xref="S4.SS2.p1.4.m4.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.4.m4.1b"><ci id="S4.SS2.p1.4.m4.1.1.cmml" xref="S4.SS2.p1.4.m4.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.4.m4.1c">k</annotation></semantics></math>, <math id="S4.SS2.p1.5.m5.4" class="ltx_Math" alttext="k\in\{1,2,\dots,K\}" display="inline"><semantics id="S4.SS2.p1.5.m5.4a"><mrow id="S4.SS2.p1.5.m5.4.5" xref="S4.SS2.p1.5.m5.4.5.cmml"><mi id="S4.SS2.p1.5.m5.4.5.2" xref="S4.SS2.p1.5.m5.4.5.2.cmml">k</mi><mo id="S4.SS2.p1.5.m5.4.5.1" xref="S4.SS2.p1.5.m5.4.5.1.cmml">∈</mo><mrow id="S4.SS2.p1.5.m5.4.5.3.2" xref="S4.SS2.p1.5.m5.4.5.3.1.cmml"><mo stretchy="false" id="S4.SS2.p1.5.m5.4.5.3.2.1" xref="S4.SS2.p1.5.m5.4.5.3.1.cmml">{</mo><mn id="S4.SS2.p1.5.m5.1.1" xref="S4.SS2.p1.5.m5.1.1.cmml">1</mn><mo id="S4.SS2.p1.5.m5.4.5.3.2.2" xref="S4.SS2.p1.5.m5.4.5.3.1.cmml">,</mo><mn id="S4.SS2.p1.5.m5.2.2" xref="S4.SS2.p1.5.m5.2.2.cmml">2</mn><mo id="S4.SS2.p1.5.m5.4.5.3.2.3" xref="S4.SS2.p1.5.m5.4.5.3.1.cmml">,</mo><mi mathvariant="normal" id="S4.SS2.p1.5.m5.3.3" xref="S4.SS2.p1.5.m5.3.3.cmml">…</mi><mo id="S4.SS2.p1.5.m5.4.5.3.2.4" xref="S4.SS2.p1.5.m5.4.5.3.1.cmml">,</mo><mi id="S4.SS2.p1.5.m5.4.4" xref="S4.SS2.p1.5.m5.4.4.cmml">K</mi><mo stretchy="false" id="S4.SS2.p1.5.m5.4.5.3.2.5" xref="S4.SS2.p1.5.m5.4.5.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.5.m5.4b"><apply id="S4.SS2.p1.5.m5.4.5.cmml" xref="S4.SS2.p1.5.m5.4.5"><in id="S4.SS2.p1.5.m5.4.5.1.cmml" xref="S4.SS2.p1.5.m5.4.5.1"></in><ci id="S4.SS2.p1.5.m5.4.5.2.cmml" xref="S4.SS2.p1.5.m5.4.5.2">𝑘</ci><set id="S4.SS2.p1.5.m5.4.5.3.1.cmml" xref="S4.SS2.p1.5.m5.4.5.3.2"><cn type="integer" id="S4.SS2.p1.5.m5.1.1.cmml" xref="S4.SS2.p1.5.m5.1.1">1</cn><cn type="integer" id="S4.SS2.p1.5.m5.2.2.cmml" xref="S4.SS2.p1.5.m5.2.2">2</cn><ci id="S4.SS2.p1.5.m5.3.3.cmml" xref="S4.SS2.p1.5.m5.3.3">…</ci><ci id="S4.SS2.p1.5.m5.4.4.cmml" xref="S4.SS2.p1.5.m5.4.4">𝐾</ci></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.5.m5.4c">k\in\{1,2,\dots,K\}</annotation></semantics></math>, then for <math id="S4.SS2.p1.6.m6.1" class="ltx_Math" alttext="K+1" display="inline"><semantics id="S4.SS2.p1.6.m6.1a"><mrow id="S4.SS2.p1.6.m6.1.1" xref="S4.SS2.p1.6.m6.1.1.cmml"><mi id="S4.SS2.p1.6.m6.1.1.2" xref="S4.SS2.p1.6.m6.1.1.2.cmml">K</mi><mo id="S4.SS2.p1.6.m6.1.1.1" xref="S4.SS2.p1.6.m6.1.1.1.cmml">+</mo><mn id="S4.SS2.p1.6.m6.1.1.3" xref="S4.SS2.p1.6.m6.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.6.m6.1b"><apply id="S4.SS2.p1.6.m6.1.1.cmml" xref="S4.SS2.p1.6.m6.1.1"><plus id="S4.SS2.p1.6.m6.1.1.1.cmml" xref="S4.SS2.p1.6.m6.1.1.1"></plus><ci id="S4.SS2.p1.6.m6.1.1.2.cmml" xref="S4.SS2.p1.6.m6.1.1.2">𝐾</ci><cn type="integer" id="S4.SS2.p1.6.m6.1.1.3.cmml" xref="S4.SS2.p1.6.m6.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.6.m6.1c">K+1</annotation></semantics></math> clients, <math id="S4.SS2.p1.7.m7.1" class="ltx_Math" alttext="\bigcup_{k}D_{k}=D" display="inline"><semantics id="S4.SS2.p1.7.m7.1a"><mrow id="S4.SS2.p1.7.m7.1.1" xref="S4.SS2.p1.7.m7.1.1.cmml"><mrow id="S4.SS2.p1.7.m7.1.1.2" xref="S4.SS2.p1.7.m7.1.1.2.cmml"><msub id="S4.SS2.p1.7.m7.1.1.2.1" xref="S4.SS2.p1.7.m7.1.1.2.1.cmml"><mo id="S4.SS2.p1.7.m7.1.1.2.1.2" xref="S4.SS2.p1.7.m7.1.1.2.1.2.cmml">⋃</mo><mi id="S4.SS2.p1.7.m7.1.1.2.1.3" xref="S4.SS2.p1.7.m7.1.1.2.1.3.cmml">k</mi></msub><msub id="S4.SS2.p1.7.m7.1.1.2.2" xref="S4.SS2.p1.7.m7.1.1.2.2.cmml"><mi id="S4.SS2.p1.7.m7.1.1.2.2.2" xref="S4.SS2.p1.7.m7.1.1.2.2.2.cmml">D</mi><mi id="S4.SS2.p1.7.m7.1.1.2.2.3" xref="S4.SS2.p1.7.m7.1.1.2.2.3.cmml">k</mi></msub></mrow><mo id="S4.SS2.p1.7.m7.1.1.1" xref="S4.SS2.p1.7.m7.1.1.1.cmml">=</mo><mi id="S4.SS2.p1.7.m7.1.1.3" xref="S4.SS2.p1.7.m7.1.1.3.cmml">D</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.7.m7.1b"><apply id="S4.SS2.p1.7.m7.1.1.cmml" xref="S4.SS2.p1.7.m7.1.1"><eq id="S4.SS2.p1.7.m7.1.1.1.cmml" xref="S4.SS2.p1.7.m7.1.1.1"></eq><apply id="S4.SS2.p1.7.m7.1.1.2.cmml" xref="S4.SS2.p1.7.m7.1.1.2"><apply id="S4.SS2.p1.7.m7.1.1.2.1.cmml" xref="S4.SS2.p1.7.m7.1.1.2.1"><csymbol cd="ambiguous" id="S4.SS2.p1.7.m7.1.1.2.1.1.cmml" xref="S4.SS2.p1.7.m7.1.1.2.1">subscript</csymbol><union id="S4.SS2.p1.7.m7.1.1.2.1.2.cmml" xref="S4.SS2.p1.7.m7.1.1.2.1.2"></union><ci id="S4.SS2.p1.7.m7.1.1.2.1.3.cmml" xref="S4.SS2.p1.7.m7.1.1.2.1.3">𝑘</ci></apply><apply id="S4.SS2.p1.7.m7.1.1.2.2.cmml" xref="S4.SS2.p1.7.m7.1.1.2.2"><csymbol cd="ambiguous" id="S4.SS2.p1.7.m7.1.1.2.2.1.cmml" xref="S4.SS2.p1.7.m7.1.1.2.2">subscript</csymbol><ci id="S4.SS2.p1.7.m7.1.1.2.2.2.cmml" xref="S4.SS2.p1.7.m7.1.1.2.2.2">𝐷</ci><ci id="S4.SS2.p1.7.m7.1.1.2.2.3.cmml" xref="S4.SS2.p1.7.m7.1.1.2.2.3">𝑘</ci></apply></apply><ci id="S4.SS2.p1.7.m7.1.1.3.cmml" xref="S4.SS2.p1.7.m7.1.1.3">𝐷</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.7.m7.1c">\bigcup_{k}D_{k}=D</annotation></semantics></math> such that <math id="S4.SS2.p1.8.m8.1" class="ltx_Math" alttext="D^{\prime}\subset D" display="inline"><semantics id="S4.SS2.p1.8.m8.1a"><mrow id="S4.SS2.p1.8.m8.1.1" xref="S4.SS2.p1.8.m8.1.1.cmml"><msup id="S4.SS2.p1.8.m8.1.1.2" xref="S4.SS2.p1.8.m8.1.1.2.cmml"><mi id="S4.SS2.p1.8.m8.1.1.2.2" xref="S4.SS2.p1.8.m8.1.1.2.2.cmml">D</mi><mo id="S4.SS2.p1.8.m8.1.1.2.3" xref="S4.SS2.p1.8.m8.1.1.2.3.cmml">′</mo></msup><mo id="S4.SS2.p1.8.m8.1.1.1" xref="S4.SS2.p1.8.m8.1.1.1.cmml">⊂</mo><mi id="S4.SS2.p1.8.m8.1.1.3" xref="S4.SS2.p1.8.m8.1.1.3.cmml">D</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.8.m8.1b"><apply id="S4.SS2.p1.8.m8.1.1.cmml" xref="S4.SS2.p1.8.m8.1.1"><subset id="S4.SS2.p1.8.m8.1.1.1.cmml" xref="S4.SS2.p1.8.m8.1.1.1"></subset><apply id="S4.SS2.p1.8.m8.1.1.2.cmml" xref="S4.SS2.p1.8.m8.1.1.2"><csymbol cd="ambiguous" id="S4.SS2.p1.8.m8.1.1.2.1.cmml" xref="S4.SS2.p1.8.m8.1.1.2">superscript</csymbol><ci id="S4.SS2.p1.8.m8.1.1.2.2.cmml" xref="S4.SS2.p1.8.m8.1.1.2.2">𝐷</ci><ci id="S4.SS2.p1.8.m8.1.1.2.3.cmml" xref="S4.SS2.p1.8.m8.1.1.2.3">′</ci></apply><ci id="S4.SS2.p1.8.m8.1.1.3.cmml" xref="S4.SS2.p1.8.m8.1.1.3">𝐷</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.8.m8.1c">D^{\prime}\subset D</annotation></semantics></math>.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.5" class="ltx_p">For this section, asymmetric data distribution is only due to the different sample sizes among clients but with the equal number of phishing and legitimate emails. The variation in the local data sizes is based on the maximum percentage of the variation provided by the term “<math id="S4.SS2.p2.1.m1.1" class="ltx_Math" alttext="\mathsf{var}" display="inline"><semantics id="S4.SS2.p2.1.m1.1a"><mi id="S4.SS2.p2.1.m1.1.1" xref="S4.SS2.p2.1.m1.1.1.cmml">𝗏𝖺𝗋</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.1.m1.1b"><ci id="S4.SS2.p2.1.m1.1.1.cmml" xref="S4.SS2.p2.1.m1.1.1">𝗏𝖺𝗋</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.1.m1.1c">\mathsf{var}</annotation></semantics></math>.” For example, if <math id="S4.SS2.p2.2.m2.1" class="ltx_Math" alttext="\mathsf{var}=10\%" display="inline"><semantics id="S4.SS2.p2.2.m2.1a"><mrow id="S4.SS2.p2.2.m2.1.1" xref="S4.SS2.p2.2.m2.1.1.cmml"><mi id="S4.SS2.p2.2.m2.1.1.2" xref="S4.SS2.p2.2.m2.1.1.2.cmml">𝗏𝖺𝗋</mi><mo id="S4.SS2.p2.2.m2.1.1.1" xref="S4.SS2.p2.2.m2.1.1.1.cmml">=</mo><mrow id="S4.SS2.p2.2.m2.1.1.3" xref="S4.SS2.p2.2.m2.1.1.3.cmml"><mn id="S4.SS2.p2.2.m2.1.1.3.2" xref="S4.SS2.p2.2.m2.1.1.3.2.cmml">10</mn><mo id="S4.SS2.p2.2.m2.1.1.3.1" xref="S4.SS2.p2.2.m2.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.2.m2.1b"><apply id="S4.SS2.p2.2.m2.1.1.cmml" xref="S4.SS2.p2.2.m2.1.1"><eq id="S4.SS2.p2.2.m2.1.1.1.cmml" xref="S4.SS2.p2.2.m2.1.1.1"></eq><ci id="S4.SS2.p2.2.m2.1.1.2.cmml" xref="S4.SS2.p2.2.m2.1.1.2">𝗏𝖺𝗋</ci><apply id="S4.SS2.p2.2.m2.1.1.3.cmml" xref="S4.SS2.p2.2.m2.1.1.3"><csymbol cd="latexml" id="S4.SS2.p2.2.m2.1.1.3.1.cmml" xref="S4.SS2.p2.2.m2.1.1.3.1">percent</csymbol><cn type="integer" id="S4.SS2.p2.2.m2.1.1.3.2.cmml" xref="S4.SS2.p2.2.m2.1.1.3.2">10</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.2.m2.1c">\mathsf{var}=10\%</annotation></semantics></math>, then the variation of the data across the five clients is given by <math id="S4.SS2.p2.3.m3.5" class="ltx_Math" alttext="[-10\%,-5\%,0\%,+5\%,+10\%]" display="inline"><semantics id="S4.SS2.p2.3.m3.5a"><mrow id="S4.SS2.p2.3.m3.5.5.5" xref="S4.SS2.p2.3.m3.5.5.6.cmml"><mo stretchy="false" id="S4.SS2.p2.3.m3.5.5.5.6" xref="S4.SS2.p2.3.m3.5.5.6.cmml">[</mo><mrow id="S4.SS2.p2.3.m3.1.1.1.1" xref="S4.SS2.p2.3.m3.1.1.1.1.cmml"><mo id="S4.SS2.p2.3.m3.1.1.1.1a" xref="S4.SS2.p2.3.m3.1.1.1.1.cmml">−</mo><mrow id="S4.SS2.p2.3.m3.1.1.1.1.2" xref="S4.SS2.p2.3.m3.1.1.1.1.2.cmml"><mn id="S4.SS2.p2.3.m3.1.1.1.1.2.2" xref="S4.SS2.p2.3.m3.1.1.1.1.2.2.cmml">10</mn><mo id="S4.SS2.p2.3.m3.1.1.1.1.2.1" xref="S4.SS2.p2.3.m3.1.1.1.1.2.1.cmml">%</mo></mrow></mrow><mo id="S4.SS2.p2.3.m3.5.5.5.7" xref="S4.SS2.p2.3.m3.5.5.6.cmml">,</mo><mrow id="S4.SS2.p2.3.m3.2.2.2.2" xref="S4.SS2.p2.3.m3.2.2.2.2.cmml"><mo id="S4.SS2.p2.3.m3.2.2.2.2a" xref="S4.SS2.p2.3.m3.2.2.2.2.cmml">−</mo><mrow id="S4.SS2.p2.3.m3.2.2.2.2.2" xref="S4.SS2.p2.3.m3.2.2.2.2.2.cmml"><mn id="S4.SS2.p2.3.m3.2.2.2.2.2.2" xref="S4.SS2.p2.3.m3.2.2.2.2.2.2.cmml">5</mn><mo id="S4.SS2.p2.3.m3.2.2.2.2.2.1" xref="S4.SS2.p2.3.m3.2.2.2.2.2.1.cmml">%</mo></mrow></mrow><mo id="S4.SS2.p2.3.m3.5.5.5.8" xref="S4.SS2.p2.3.m3.5.5.6.cmml">,</mo><mrow id="S4.SS2.p2.3.m3.3.3.3.3" xref="S4.SS2.p2.3.m3.3.3.3.3.cmml"><mn id="S4.SS2.p2.3.m3.3.3.3.3.2" xref="S4.SS2.p2.3.m3.3.3.3.3.2.cmml">0</mn><mo id="S4.SS2.p2.3.m3.3.3.3.3.1" xref="S4.SS2.p2.3.m3.3.3.3.3.1.cmml">%</mo></mrow><mo id="S4.SS2.p2.3.m3.5.5.5.9" xref="S4.SS2.p2.3.m3.5.5.6.cmml">,</mo><mrow id="S4.SS2.p2.3.m3.4.4.4.4" xref="S4.SS2.p2.3.m3.4.4.4.4.cmml"><mo id="S4.SS2.p2.3.m3.4.4.4.4a" xref="S4.SS2.p2.3.m3.4.4.4.4.cmml">+</mo><mrow id="S4.SS2.p2.3.m3.4.4.4.4.2" xref="S4.SS2.p2.3.m3.4.4.4.4.2.cmml"><mn id="S4.SS2.p2.3.m3.4.4.4.4.2.2" xref="S4.SS2.p2.3.m3.4.4.4.4.2.2.cmml">5</mn><mo id="S4.SS2.p2.3.m3.4.4.4.4.2.1" xref="S4.SS2.p2.3.m3.4.4.4.4.2.1.cmml">%</mo></mrow></mrow><mo id="S4.SS2.p2.3.m3.5.5.5.10" xref="S4.SS2.p2.3.m3.5.5.6.cmml">,</mo><mrow id="S4.SS2.p2.3.m3.5.5.5.5" xref="S4.SS2.p2.3.m3.5.5.5.5.cmml"><mo id="S4.SS2.p2.3.m3.5.5.5.5a" xref="S4.SS2.p2.3.m3.5.5.5.5.cmml">+</mo><mrow id="S4.SS2.p2.3.m3.5.5.5.5.2" xref="S4.SS2.p2.3.m3.5.5.5.5.2.cmml"><mn id="S4.SS2.p2.3.m3.5.5.5.5.2.2" xref="S4.SS2.p2.3.m3.5.5.5.5.2.2.cmml">10</mn><mo id="S4.SS2.p2.3.m3.5.5.5.5.2.1" xref="S4.SS2.p2.3.m3.5.5.5.5.2.1.cmml">%</mo></mrow></mrow><mo stretchy="false" id="S4.SS2.p2.3.m3.5.5.5.11" xref="S4.SS2.p2.3.m3.5.5.6.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.3.m3.5b"><list id="S4.SS2.p2.3.m3.5.5.6.cmml" xref="S4.SS2.p2.3.m3.5.5.5"><apply id="S4.SS2.p2.3.m3.1.1.1.1.cmml" xref="S4.SS2.p2.3.m3.1.1.1.1"><minus id="S4.SS2.p2.3.m3.1.1.1.1.1.cmml" xref="S4.SS2.p2.3.m3.1.1.1.1"></minus><apply id="S4.SS2.p2.3.m3.1.1.1.1.2.cmml" xref="S4.SS2.p2.3.m3.1.1.1.1.2"><csymbol cd="latexml" id="S4.SS2.p2.3.m3.1.1.1.1.2.1.cmml" xref="S4.SS2.p2.3.m3.1.1.1.1.2.1">percent</csymbol><cn type="integer" id="S4.SS2.p2.3.m3.1.1.1.1.2.2.cmml" xref="S4.SS2.p2.3.m3.1.1.1.1.2.2">10</cn></apply></apply><apply id="S4.SS2.p2.3.m3.2.2.2.2.cmml" xref="S4.SS2.p2.3.m3.2.2.2.2"><minus id="S4.SS2.p2.3.m3.2.2.2.2.1.cmml" xref="S4.SS2.p2.3.m3.2.2.2.2"></minus><apply id="S4.SS2.p2.3.m3.2.2.2.2.2.cmml" xref="S4.SS2.p2.3.m3.2.2.2.2.2"><csymbol cd="latexml" id="S4.SS2.p2.3.m3.2.2.2.2.2.1.cmml" xref="S4.SS2.p2.3.m3.2.2.2.2.2.1">percent</csymbol><cn type="integer" id="S4.SS2.p2.3.m3.2.2.2.2.2.2.cmml" xref="S4.SS2.p2.3.m3.2.2.2.2.2.2">5</cn></apply></apply><apply id="S4.SS2.p2.3.m3.3.3.3.3.cmml" xref="S4.SS2.p2.3.m3.3.3.3.3"><csymbol cd="latexml" id="S4.SS2.p2.3.m3.3.3.3.3.1.cmml" xref="S4.SS2.p2.3.m3.3.3.3.3.1">percent</csymbol><cn type="integer" id="S4.SS2.p2.3.m3.3.3.3.3.2.cmml" xref="S4.SS2.p2.3.m3.3.3.3.3.2">0</cn></apply><apply id="S4.SS2.p2.3.m3.4.4.4.4.cmml" xref="S4.SS2.p2.3.m3.4.4.4.4"><plus id="S4.SS2.p2.3.m3.4.4.4.4.1.cmml" xref="S4.SS2.p2.3.m3.4.4.4.4"></plus><apply id="S4.SS2.p2.3.m3.4.4.4.4.2.cmml" xref="S4.SS2.p2.3.m3.4.4.4.4.2"><csymbol cd="latexml" id="S4.SS2.p2.3.m3.4.4.4.4.2.1.cmml" xref="S4.SS2.p2.3.m3.4.4.4.4.2.1">percent</csymbol><cn type="integer" id="S4.SS2.p2.3.m3.4.4.4.4.2.2.cmml" xref="S4.SS2.p2.3.m3.4.4.4.4.2.2">5</cn></apply></apply><apply id="S4.SS2.p2.3.m3.5.5.5.5.cmml" xref="S4.SS2.p2.3.m3.5.5.5.5"><plus id="S4.SS2.p2.3.m3.5.5.5.5.1.cmml" xref="S4.SS2.p2.3.m3.5.5.5.5"></plus><apply id="S4.SS2.p2.3.m3.5.5.5.5.2.cmml" xref="S4.SS2.p2.3.m3.5.5.5.5.2"><csymbol cd="latexml" id="S4.SS2.p2.3.m3.5.5.5.5.2.1.cmml" xref="S4.SS2.p2.3.m3.5.5.5.5.2.1">percent</csymbol><cn type="integer" id="S4.SS2.p2.3.m3.5.5.5.5.2.2.cmml" xref="S4.SS2.p2.3.m3.5.5.5.5.2.2">10</cn></apply></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.3.m3.5c">[-10\%,-5\%,0\%,+5\%,+10\%]</annotation></semantics></math>, where -10% referred to the 10% less local data, and +10% referred to the 10% more data in the respective clients. This means, 3606, 3806, 4008, 4208, and 4408 local data samples are resided in clients 1, 2, 3, 4 and 5, respectively, if <math id="S4.SS2.p2.4.m4.1" class="ltx_Math" alttext="\mathsf{var}=10\%" display="inline"><semantics id="S4.SS2.p2.4.m4.1a"><mrow id="S4.SS2.p2.4.m4.1.1" xref="S4.SS2.p2.4.m4.1.1.cmml"><mi id="S4.SS2.p2.4.m4.1.1.2" xref="S4.SS2.p2.4.m4.1.1.2.cmml">𝗏𝖺𝗋</mi><mo id="S4.SS2.p2.4.m4.1.1.1" xref="S4.SS2.p2.4.m4.1.1.1.cmml">=</mo><mrow id="S4.SS2.p2.4.m4.1.1.3" xref="S4.SS2.p2.4.m4.1.1.3.cmml"><mn id="S4.SS2.p2.4.m4.1.1.3.2" xref="S4.SS2.p2.4.m4.1.1.3.2.cmml">10</mn><mo id="S4.SS2.p2.4.m4.1.1.3.1" xref="S4.SS2.p2.4.m4.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.4.m4.1b"><apply id="S4.SS2.p2.4.m4.1.1.cmml" xref="S4.SS2.p2.4.m4.1.1"><eq id="S4.SS2.p2.4.m4.1.1.1.cmml" xref="S4.SS2.p2.4.m4.1.1.1"></eq><ci id="S4.SS2.p2.4.m4.1.1.2.cmml" xref="S4.SS2.p2.4.m4.1.1.2">𝗏𝖺𝗋</ci><apply id="S4.SS2.p2.4.m4.1.1.3.cmml" xref="S4.SS2.p2.4.m4.1.1.3"><csymbol cd="latexml" id="S4.SS2.p2.4.m4.1.1.3.1.cmml" xref="S4.SS2.p2.4.m4.1.1.3.1">percent</csymbol><cn type="integer" id="S4.SS2.p2.4.m4.1.1.3.2.cmml" xref="S4.SS2.p2.4.m4.1.1.3.2">10</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.4.m4.1c">\mathsf{var}=10\%</annotation></semantics></math>. This way, we create a variation of the sizes of the local data by maintaining the total size of the datasets. Besides, the balanced data distribution is the case where <math id="S4.SS2.p2.5.m5.1" class="ltx_Math" alttext="\mathsf{var}=0" display="inline"><semantics id="S4.SS2.p2.5.m5.1a"><mrow id="S4.SS2.p2.5.m5.1.1" xref="S4.SS2.p2.5.m5.1.1.cmml"><mi id="S4.SS2.p2.5.m5.1.1.2" xref="S4.SS2.p2.5.m5.1.1.2.cmml">𝗏𝖺𝗋</mi><mo id="S4.SS2.p2.5.m5.1.1.1" xref="S4.SS2.p2.5.m5.1.1.1.cmml">=</mo><mn id="S4.SS2.p2.5.m5.1.1.3" xref="S4.SS2.p2.5.m5.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.5.m5.1b"><apply id="S4.SS2.p2.5.m5.1.1.cmml" xref="S4.SS2.p2.5.m5.1.1"><eq id="S4.SS2.p2.5.m5.1.1.1.cmml" xref="S4.SS2.p2.5.m5.1.1.1"></eq><ci id="S4.SS2.p2.5.m5.1.1.2.cmml" xref="S4.SS2.p2.5.m5.1.1.2">𝗏𝖺𝗋</ci><cn type="integer" id="S4.SS2.p2.5.m5.1.1.3.cmml" xref="S4.SS2.p2.5.m5.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.5.m5.1c">\mathsf{var}=0</annotation></semantics></math>.</p>
</div>
<div id="Thmresearchq4" class="ltx_theorem ltx_theorem_researchq">
<h6 class="ltx_title ltx_runin ltx_title_theorem"><span class="ltx_tag ltx_tag_theorem"><span id="Thmresearchq4.1.1.1" class="ltx_text ltx_font_bold">RQ 4</span></span></h6>
<div id="Thmresearchq4.p1" class="ltx_para">
<p id="Thmresearchq4.p1.1" class="ltx_p"><span id="Thmresearchq4.p1.1.1" class="ltx_text ltx_font_bold ltx_font_italic">Can a client leverage FL to improve its performance?<span id="Thmresearchq4.p1.1.1.1" class="ltx_text ltx_font_medium"></span></span></p>
</div>
</div>
<div id="S4.SS2.p3" class="ltx_para">
<p id="S4.SS2.p3.1" class="ltx_p">For this research question, we limit our experiments to the THEMIS model (considering both email’s header and body information) because BERT has high training/testing overhead if we go up to 50 global epochs.</p>
</div>
<section id="S4.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.1 </span>Experiment 1: A client-level and overall effects of adding one new client in FL</h4>

<div id="S4.SS2.SSS1.p1" class="ltx_para">
<p id="S4.SS2.SSS1.p1.1" class="ltx_p">In this experiment, we consider five clients in total, where the first four clients (C1–C4) participate in the FL until 15 global epochs and train the model collaboratively. Afterward, the learning is carried out only with the fifth client, and the training proceeds for the next 15 global epochs (i.e., until 30 global epochs).
Besides, the testing results are computed for all five clients throughout the process for the performance evaluation. This experiment examines how a newly joining client member is benefited in FL by improving its performance in phishing detection.</p>
</div>
<figure id="S4.F6" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F6.1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2007.13300/assets/x12.png" id="S4.F6.1.g1" class="ltx_graphics ltx_img_landscape" width="332" height="182" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F6.2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2007.13300/assets/x13.png" id="S4.F6.2.g1" class="ltx_graphics ltx_img_landscape" width="312" height="175" alt="Refer to caption">
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>Convergence curves of (a) global testing accuracy and (b) local testing accuracy from the Experiment 1 with five clients and <math id="S4.F6.4.m1.1" class="ltx_Math" alttext="\mathsf{var}=80" display="inline"><semantics id="S4.F6.4.m1.1b"><mrow id="S4.F6.4.m1.1.1" xref="S4.F6.4.m1.1.1.cmml"><mi id="S4.F6.4.m1.1.1.2" xref="S4.F6.4.m1.1.1.2.cmml">𝗏𝖺𝗋</mi><mo id="S4.F6.4.m1.1.1.1" xref="S4.F6.4.m1.1.1.1.cmml">=</mo><mn id="S4.F6.4.m1.1.1.3" xref="S4.F6.4.m1.1.1.3.cmml">80</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.F6.4.m1.1c"><apply id="S4.F6.4.m1.1.1.cmml" xref="S4.F6.4.m1.1.1"><eq id="S4.F6.4.m1.1.1.1.cmml" xref="S4.F6.4.m1.1.1.1"></eq><ci id="S4.F6.4.m1.1.1.2.cmml" xref="S4.F6.4.m1.1.1.2">𝗏𝖺𝗋</ci><cn type="integer" id="S4.F6.4.m1.1.1.3.cmml" xref="S4.F6.4.m1.1.1.3">80</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F6.4.m1.1d">\mathsf{var}=80</annotation></semantics></math>. The first four clients train the model until 15 global epochs, and then (only) the fifth client trains the model.</figcaption>
</figure>
<div id="S4.SS2.SSS1.p2" class="ltx_para">
<p id="S4.SS2.SSS1.p2.3" class="ltx_p">The experimental result depicted in Fig. <a href="#S4.F6" title="Figure 6 ‣ 4.2.1 Experiment 1: A client-level and overall effects of adding one new client in FL ‣ 4.2 Client-level perspectives in FL ‣ 4 Results ‣ Evaluation of Federated Learning in Phishing Email Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> is for the case with <math id="S4.SS2.SSS1.p2.1.m1.1" class="ltx_Math" alttext="\mathsf{var}=80" display="inline"><semantics id="S4.SS2.SSS1.p2.1.m1.1a"><mrow id="S4.SS2.SSS1.p2.1.m1.1.1" xref="S4.SS2.SSS1.p2.1.m1.1.1.cmml"><mi id="S4.SS2.SSS1.p2.1.m1.1.1.2" xref="S4.SS2.SSS1.p2.1.m1.1.1.2.cmml">𝗏𝖺𝗋</mi><mo id="S4.SS2.SSS1.p2.1.m1.1.1.1" xref="S4.SS2.SSS1.p2.1.m1.1.1.1.cmml">=</mo><mn id="S4.SS2.SSS1.p2.1.m1.1.1.3" xref="S4.SS2.SSS1.p2.1.m1.1.1.3.cmml">80</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS1.p2.1.m1.1b"><apply id="S4.SS2.SSS1.p2.1.m1.1.1.cmml" xref="S4.SS2.SSS1.p2.1.m1.1.1"><eq id="S4.SS2.SSS1.p2.1.m1.1.1.1.cmml" xref="S4.SS2.SSS1.p2.1.m1.1.1.1"></eq><ci id="S4.SS2.SSS1.p2.1.m1.1.1.2.cmml" xref="S4.SS2.SSS1.p2.1.m1.1.1.2">𝗏𝖺𝗋</ci><cn type="integer" id="S4.SS2.SSS1.p2.1.m1.1.1.3.cmml" xref="S4.SS2.SSS1.p2.1.m1.1.1.3">80</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS1.p2.1.m1.1c">\mathsf{var}=80</annotation></semantics></math>, which provides the variations in the sizes of the local dataset (i.e., [-80%, -40%, 0%, +40%, +80%]) to capture a practical setting among the five clients. The figure shows that the average global test accuracy of the first four clients is slightly higher than the fifth client (not participated in the learning process) until 15 global epochs. Afterward, the fifth client trains the model, so its average global testing accuracy improves by 2.98%, and FPR and FNR improve by 3.5% and 2.2%, respectively. This performance decreases with the lesser variation in the sizes of the local dataset; the improvements in average global test accuracy are 2.91%, 2.87%, and 2.24% with <math id="S4.SS2.SSS1.p2.2.m2.1" class="ltx_Math" alttext="\mathsf{var}" display="inline"><semantics id="S4.SS2.SSS1.p2.2.m2.1a"><mi id="S4.SS2.SSS1.p2.2.m2.1.1" xref="S4.SS2.SSS1.p2.2.m2.1.1.cmml">𝗏𝖺𝗋</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS1.p2.2.m2.1b"><ci id="S4.SS2.SSS1.p2.2.m2.1.1.cmml" xref="S4.SS2.SSS1.p2.2.m2.1.1">𝗏𝖺𝗋</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS1.p2.2.m2.1c">\mathsf{var}</annotation></semantics></math> equal to 50, 30, and 0, respectively. Refer to Fig. <a href="#A1.F14" title="Figure 14 ‣ A.2 Client-level performance of the THEMIS model ‣ Appendix A Supplemental results ‣ Evaluation of Federated Learning in Phishing Email Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">14</span></a> in Appendix for the results with the balanced email distribution, i.e., <math id="S4.SS2.SSS1.p2.3.m3.1" class="ltx_Math" alttext="\mathsf{var}=0" display="inline"><semantics id="S4.SS2.SSS1.p2.3.m3.1a"><mrow id="S4.SS2.SSS1.p2.3.m3.1.1" xref="S4.SS2.SSS1.p2.3.m3.1.1.cmml"><mi id="S4.SS2.SSS1.p2.3.m3.1.1.2" xref="S4.SS2.SSS1.p2.3.m3.1.1.2.cmml">𝗏𝖺𝗋</mi><mo id="S4.SS2.SSS1.p2.3.m3.1.1.1" xref="S4.SS2.SSS1.p2.3.m3.1.1.1.cmml">=</mo><mn id="S4.SS2.SSS1.p2.3.m3.1.1.3" xref="S4.SS2.SSS1.p2.3.m3.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS1.p2.3.m3.1b"><apply id="S4.SS2.SSS1.p2.3.m3.1.1.cmml" xref="S4.SS2.SSS1.p2.3.m3.1.1"><eq id="S4.SS2.SSS1.p2.3.m3.1.1.1.cmml" xref="S4.SS2.SSS1.p2.3.m3.1.1.1"></eq><ci id="S4.SS2.SSS1.p2.3.m3.1.1.2.cmml" xref="S4.SS2.SSS1.p2.3.m3.1.1.2">𝗏𝖺𝗋</ci><cn type="integer" id="S4.SS2.SSS1.p2.3.m3.1.1.3.cmml" xref="S4.SS2.SSS1.p2.3.m3.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS1.p2.3.m3.1c">\mathsf{var}=0</annotation></semantics></math>.
Overall results show that the evolved model (after training by client 5) is still relevant to the first four clients (C1–C4) as their average testing results with and without client 5 differ only nominally. Nonetheless, the fifth client boosts the accuracy of phishing detection in its local dataset under the FL setup.</p>
</div>
</section>
<section id="S4.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.2 </span>Experiment 2: A client-level and overall effects of continuously adding new clients in FL</h4>

<div id="S4.SS2.SSS2.p1" class="ltx_para">
<p id="S4.SS2.SSS2.p1.1" class="ltx_p">In this experiment, the learning process is started with the first client, and then one new client is joined continuously at an interval of 10 global epochs as the training proceeds. Refer to Table  <a href="#S4.T2" title="TABLE II ‣ 4.2.2 Experiment 2: A client-level and overall effects of continuously adding new clients in FL ‣ 4.2 Client-level perspectives in FL ‣ 4 Results ‣ Evaluation of Federated Learning in Phishing Email Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">II</span></a> for details. This experiment simulates the practical cases where more than one client (different than the Experiment 1) is available with time during model training and demonstrates how the newly available clients can continue to perform FL to contribute accuracy improvements for phishing detection.</p>
</div>
<figure id="S4.F7" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S4.F7.1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2007.13300/assets/x14.png" id="S4.F7.1.g1" class="ltx_graphics ltx_img_landscape" width="432" height="228" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S4.F7.2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2007.13300/assets/x15.png" id="S4.F7.2.g1" class="ltx_graphics ltx_img_landscape" width="432" height="229" alt="Refer to caption">
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7: </span>Convergence curves of (a) global testing accuracy and (b) local testing accuracy from the Experiment 2 with five clients and <math id="S4.F7.4.m1.1" class="ltx_Math" alttext="\mathsf{var}=0" display="inline"><semantics id="S4.F7.4.m1.1b"><mrow id="S4.F7.4.m1.1.1" xref="S4.F7.4.m1.1.1.cmml"><mi id="S4.F7.4.m1.1.1.2" xref="S4.F7.4.m1.1.1.2.cmml">𝗏𝖺𝗋</mi><mo id="S4.F7.4.m1.1.1.1" xref="S4.F7.4.m1.1.1.1.cmml">=</mo><mn id="S4.F7.4.m1.1.1.3" xref="S4.F7.4.m1.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.F7.4.m1.1c"><apply id="S4.F7.4.m1.1.1.cmml" xref="S4.F7.4.m1.1.1"><eq id="S4.F7.4.m1.1.1.1.cmml" xref="S4.F7.4.m1.1.1.1"></eq><ci id="S4.F7.4.m1.1.1.2.cmml" xref="S4.F7.4.m1.1.1.2">𝗏𝖺𝗋</ci><cn type="integer" id="S4.F7.4.m1.1.1.3.cmml" xref="S4.F7.4.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F7.4.m1.1d">\mathsf{var}=0</annotation></semantics></math>. The FL training starts with one client, i.e., client 1, and a new client joins the training at every 10-th global epochs in a sequence from client 2 to client 5.</figcaption>
</figure>
<figure id="S4.T2" class="ltx_table">
<figcaption class="ltx_caption ltx_centering" style="font-size:80%;"><span class="ltx_tag ltx_tag_table">TABLE II: </span>Experimental steps for the Experiment 2</figcaption>
<table id="S4.T2.3" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T2.3.1.1" class="ltx_tr">
<td id="S4.T2.3.1.1.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t"><span id="S4.T2.3.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Round</span></td>
<td id="S4.T2.3.1.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.3.1.1.2.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Involvement of clients</span></td>
</tr>
<tr id="S4.T2.3.2.2" class="ltx_tr">
<td id="S4.T2.3.2.2.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t"><span id="S4.T2.3.2.2.1.1" class="ltx_text" style="font-size:80%;">0 to 9</span></td>
<td id="S4.T2.3.2.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.3.2.2.2.1" class="ltx_text" style="font-size:80%;">Only the first client.</span></td>
</tr>
<tr id="S4.T2.3.3.3" class="ltx_tr">
<td id="S4.T2.3.3.3.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t"><span id="S4.T2.3.3.3.1.1" class="ltx_text" style="font-size:80%;">10 to 19</span></td>
<td id="S4.T2.3.3.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.3.3.3.2.1" class="ltx_text" style="font-size:80%;">Only the first and second client.</span></td>
</tr>
<tr id="S4.T2.3.4.4" class="ltx_tr">
<td id="S4.T2.3.4.4.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t"><span id="S4.T2.3.4.4.1.1" class="ltx_text" style="font-size:80%;">20 to 29</span></td>
<td id="S4.T2.3.4.4.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.3.4.4.2.1" class="ltx_text" style="font-size:80%;">Only the first, second, and third client.</span></td>
</tr>
<tr id="S4.T2.3.5.5" class="ltx_tr">
<td id="S4.T2.3.5.5.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t"><span id="S4.T2.3.5.5.1.1" class="ltx_text" style="font-size:80%;">30 to 39</span></td>
<td id="S4.T2.3.5.5.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.3.5.5.2.1" class="ltx_text" style="font-size:80%;">First, second, third, and fourth client.</span></td>
</tr>
<tr id="S4.T2.3.6.6" class="ltx_tr">
<td id="S4.T2.3.6.6.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t"><span id="S4.T2.3.6.6.1.1" class="ltx_text" style="font-size:80%;">40 to 50</span></td>
<td id="S4.T2.3.6.6.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.3.6.6.2.1" class="ltx_text" style="font-size:80%;">All five clients.</span></td>
</tr>
<tr id="S4.T2.3.7.7" class="ltx_tr">
<td id="S4.T2.3.7.7.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t" colspan="2">
<table id="S4.T2.3.7.7.1.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T2.3.7.7.1.1.1" class="ltx_tr">
<td id="S4.T2.3.7.7.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T2.3.7.7.1.1.1.1.1" class="ltx_text" style="font-size:80%;">The local and global test accuracy are measured</span></td>
</tr>
<tr id="S4.T2.3.7.7.1.1.2" class="ltx_tr">
<td id="S4.T2.3.7.7.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T2.3.7.7.1.1.2.1.1" class="ltx_text" style="font-size:80%;">for all clients throughout the process.</span></td>
</tr>
</table>
</td>
</tr>
</tbody>
</table>
</figure>
<div id="S4.SS2.SSS2.p2" class="ltx_para">
<p id="S4.SS2.SSS2.p2.4" class="ltx_p">The result depicted in Fig. <a href="#S4.F7" title="Figure 7 ‣ 4.2.2 Experiment 2: A client-level and overall effects of continuously adding new clients in FL ‣ 4.2 Client-level perspectives in FL ‣ 4 Results ‣ Evaluation of Federated Learning in Phishing Email Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> is for the case with the same size of the local dataset among the five clients (i.e., <math id="S4.SS2.SSS2.p2.1.m1.1" class="ltx_Math" alttext="\mathsf{var}=0" display="inline"><semantics id="S4.SS2.SSS2.p2.1.m1.1a"><mrow id="S4.SS2.SSS2.p2.1.m1.1.1" xref="S4.SS2.SSS2.p2.1.m1.1.1.cmml"><mi id="S4.SS2.SSS2.p2.1.m1.1.1.2" xref="S4.SS2.SSS2.p2.1.m1.1.1.2.cmml">𝗏𝖺𝗋</mi><mo id="S4.SS2.SSS2.p2.1.m1.1.1.1" xref="S4.SS2.SSS2.p2.1.m1.1.1.1.cmml">=</mo><mn id="S4.SS2.SSS2.p2.1.m1.1.1.3" xref="S4.SS2.SSS2.p2.1.m1.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS2.p2.1.m1.1b"><apply id="S4.SS2.SSS2.p2.1.m1.1.1.cmml" xref="S4.SS2.SSS2.p2.1.m1.1.1"><eq id="S4.SS2.SSS2.p2.1.m1.1.1.1.cmml" xref="S4.SS2.SSS2.p2.1.m1.1.1.1"></eq><ci id="S4.SS2.SSS2.p2.1.m1.1.1.2.cmml" xref="S4.SS2.SSS2.p2.1.m1.1.1.2">𝗏𝖺𝗋</ci><cn type="integer" id="S4.SS2.SSS2.p2.1.m1.1.1.3.cmml" xref="S4.SS2.SSS2.p2.1.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS2.p2.1.m1.1c">\mathsf{var}=0</annotation></semantics></math>), which are gradually added to the learning process, as stated in Table <a href="#S4.T2" title="TABLE II ‣ 4.2.2 Experiment 2: A client-level and overall effects of continuously adding new clients in FL ‣ 4.2 Client-level perspectives in FL ‣ 4 Results ‣ Evaluation of Federated Learning in Phishing Email Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">II</span></a>. As per expectation, it shows that the global testing accuracy improves for each client when it is added to FL. For example, the average global testing accuracy jumps by around 4.9% (corresponding to the accuracy at the 10 and 19 global epoch) for client 2 when it joins client 1 in training the model at global epoch 10.
The local testing results are carried only when the client is involved in the model training. Thus the local testing accuracy before a client joins the training is zero in Fig. <a href="#S4.F7" title="Figure 7 ‣ 4.2.2 Experiment 2: A client-level and overall effects of continuously adding new clients in FL ‣ 4.2 Client-level perspectives in FL ‣ 4 Results ‣ Evaluation of Federated Learning in Phishing Email Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>.
The overall performance pattern for the case with <math id="S4.SS2.SSS2.p2.2.m2.3" class="ltx_Math" alttext="\mathsf{var}\in\{30,50,80\}" display="inline"><semantics id="S4.SS2.SSS2.p2.2.m2.3a"><mrow id="S4.SS2.SSS2.p2.2.m2.3.4" xref="S4.SS2.SSS2.p2.2.m2.3.4.cmml"><mi id="S4.SS2.SSS2.p2.2.m2.3.4.2" xref="S4.SS2.SSS2.p2.2.m2.3.4.2.cmml">𝗏𝖺𝗋</mi><mo id="S4.SS2.SSS2.p2.2.m2.3.4.1" xref="S4.SS2.SSS2.p2.2.m2.3.4.1.cmml">∈</mo><mrow id="S4.SS2.SSS2.p2.2.m2.3.4.3.2" xref="S4.SS2.SSS2.p2.2.m2.3.4.3.1.cmml"><mo stretchy="false" id="S4.SS2.SSS2.p2.2.m2.3.4.3.2.1" xref="S4.SS2.SSS2.p2.2.m2.3.4.3.1.cmml">{</mo><mn id="S4.SS2.SSS2.p2.2.m2.1.1" xref="S4.SS2.SSS2.p2.2.m2.1.1.cmml">30</mn><mo id="S4.SS2.SSS2.p2.2.m2.3.4.3.2.2" xref="S4.SS2.SSS2.p2.2.m2.3.4.3.1.cmml">,</mo><mn id="S4.SS2.SSS2.p2.2.m2.2.2" xref="S4.SS2.SSS2.p2.2.m2.2.2.cmml">50</mn><mo id="S4.SS2.SSS2.p2.2.m2.3.4.3.2.3" xref="S4.SS2.SSS2.p2.2.m2.3.4.3.1.cmml">,</mo><mn id="S4.SS2.SSS2.p2.2.m2.3.3" xref="S4.SS2.SSS2.p2.2.m2.3.3.cmml">80</mn><mo stretchy="false" id="S4.SS2.SSS2.p2.2.m2.3.4.3.2.4" xref="S4.SS2.SSS2.p2.2.m2.3.4.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS2.p2.2.m2.3b"><apply id="S4.SS2.SSS2.p2.2.m2.3.4.cmml" xref="S4.SS2.SSS2.p2.2.m2.3.4"><in id="S4.SS2.SSS2.p2.2.m2.3.4.1.cmml" xref="S4.SS2.SSS2.p2.2.m2.3.4.1"></in><ci id="S4.SS2.SSS2.p2.2.m2.3.4.2.cmml" xref="S4.SS2.SSS2.p2.2.m2.3.4.2">𝗏𝖺𝗋</ci><set id="S4.SS2.SSS2.p2.2.m2.3.4.3.1.cmml" xref="S4.SS2.SSS2.p2.2.m2.3.4.3.2"><cn type="integer" id="S4.SS2.SSS2.p2.2.m2.1.1.cmml" xref="S4.SS2.SSS2.p2.2.m2.1.1">30</cn><cn type="integer" id="S4.SS2.SSS2.p2.2.m2.2.2.cmml" xref="S4.SS2.SSS2.p2.2.m2.2.2">50</cn><cn type="integer" id="S4.SS2.SSS2.p2.2.m2.3.3.cmml" xref="S4.SS2.SSS2.p2.2.m2.3.3">80</cn></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS2.p2.2.m2.3c">\mathsf{var}\in\{30,50,80\}</annotation></semantics></math> is similar to the case with <math id="S4.SS2.SSS2.p2.3.m3.1" class="ltx_Math" alttext="\mathsf{var}=0" display="inline"><semantics id="S4.SS2.SSS2.p2.3.m3.1a"><mrow id="S4.SS2.SSS2.p2.3.m3.1.1" xref="S4.SS2.SSS2.p2.3.m3.1.1.cmml"><mi id="S4.SS2.SSS2.p2.3.m3.1.1.2" xref="S4.SS2.SSS2.p2.3.m3.1.1.2.cmml">𝗏𝖺𝗋</mi><mo id="S4.SS2.SSS2.p2.3.m3.1.1.1" xref="S4.SS2.SSS2.p2.3.m3.1.1.1.cmml">=</mo><mn id="S4.SS2.SSS2.p2.3.m3.1.1.3" xref="S4.SS2.SSS2.p2.3.m3.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS2.p2.3.m3.1b"><apply id="S4.SS2.SSS2.p2.3.m3.1.1.cmml" xref="S4.SS2.SSS2.p2.3.m3.1.1"><eq id="S4.SS2.SSS2.p2.3.m3.1.1.1.cmml" xref="S4.SS2.SSS2.p2.3.m3.1.1.1"></eq><ci id="S4.SS2.SSS2.p2.3.m3.1.1.2.cmml" xref="S4.SS2.SSS2.p2.3.m3.1.1.2">𝗏𝖺𝗋</ci><cn type="integer" id="S4.SS2.SSS2.p2.3.m3.1.1.3.cmml" xref="S4.SS2.SSS2.p2.3.m3.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS2.p2.3.m3.1c">\mathsf{var}=0</annotation></semantics></math>. However, we observe the dominance of late joining clients (e.g., client 4 and 5) in their performance since the initial clients (e.g., client 1) have a fewer number of samples than the late joining clients if <math id="S4.SS2.SSS2.p2.4.m4.1" class="ltx_Math" alttext="\mathsf{var}\neq 0" display="inline"><semantics id="S4.SS2.SSS2.p2.4.m4.1a"><mrow id="S4.SS2.SSS2.p2.4.m4.1.1" xref="S4.SS2.SSS2.p2.4.m4.1.1.cmml"><mi id="S4.SS2.SSS2.p2.4.m4.1.1.2" xref="S4.SS2.SSS2.p2.4.m4.1.1.2.cmml">𝗏𝖺𝗋</mi><mo id="S4.SS2.SSS2.p2.4.m4.1.1.1" xref="S4.SS2.SSS2.p2.4.m4.1.1.1.cmml">≠</mo><mn id="S4.SS2.SSS2.p2.4.m4.1.1.3" xref="S4.SS2.SSS2.p2.4.m4.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS2.p2.4.m4.1b"><apply id="S4.SS2.SSS2.p2.4.m4.1.1.cmml" xref="S4.SS2.SSS2.p2.4.m4.1.1"><neq id="S4.SS2.SSS2.p2.4.m4.1.1.1.cmml" xref="S4.SS2.SSS2.p2.4.m4.1.1.1"></neq><ci id="S4.SS2.SSS2.p2.4.m4.1.1.2.cmml" xref="S4.SS2.SSS2.p2.4.m4.1.1.2">𝗏𝖺𝗋</ci><cn type="integer" id="S4.SS2.SSS2.p2.4.m4.1.1.3.cmml" xref="S4.SS2.SSS2.p2.4.m4.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS2.p2.4.m4.1c">\mathsf{var}\neq 0</annotation></semantics></math>. Moreover, the initial client, such as client 1, could not catch up with the performance of the late joining client, such as client 5 (for details, refer to Fig. <a href="#A1.F15" title="Figure 15 ‣ A.2 Client-level performance of the THEMIS model ‣ Appendix A Supplemental results ‣ Evaluation of Federated Learning in Phishing Email Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">15</span></a> in Appendix).</p>
</div>
</section>
<section id="S4.SS2.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.3 </span>Experiment 3: Benefits to the newly participated client in the FL learning process</h4>

<div id="S4.SS2.SSS3.p1" class="ltx_para">
<p id="S4.SS2.SSS3.p1.1" class="ltx_p">In this experiment, we analyze the performance of client 1, which we assume a newly participating client, with and without leveraging FL. In the FL setup, the model is first trained by the four clients (client 2 to client 5) for 20 global epochs, and then the resulting model (pre-trained model) is further trained by client 1 on its local email data samples. The dataset distribution of the clients is defined by <math id="S4.SS2.SSS3.p1.1.m1.1" class="ltx_Math" alttext="\mathsf{var}" display="inline"><semantics id="S4.SS2.SSS3.p1.1.m1.1a"><mi id="S4.SS2.SSS3.p1.1.m1.1.1" xref="S4.SS2.SSS3.p1.1.m1.1.1.cmml">𝗏𝖺𝗋</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS3.p1.1.m1.1b"><ci id="S4.SS2.SSS3.p1.1.m1.1.1.cmml" xref="S4.SS2.SSS3.p1.1.m1.1.1">𝗏𝖺𝗋</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS3.p1.1.m1.1c">\mathsf{var}</annotation></semantics></math>. On the other hand, for the case without FL, client 1 performs CL only on its local email dataset.</p>
</div>
<figure id="S4.F8" class="ltx_figure"><img src="/html/2007.13300/assets/x16.png" id="S4.F8.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="432" height="229" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 8: </span>Convergence curves of (local) testing accuracy for the client 1 with and without leveraging FL. The dataset of client 1 is based on <math id="S4.F8.2.m1.1" class="ltx_Math" alttext="\mathsf{var}=80" display="inline"><semantics id="S4.F8.2.m1.1b"><mrow id="S4.F8.2.m1.1.1" xref="S4.F8.2.m1.1.1.cmml"><mi id="S4.F8.2.m1.1.1.2" xref="S4.F8.2.m1.1.1.2.cmml">𝗏𝖺𝗋</mi><mo id="S4.F8.2.m1.1.1.1" xref="S4.F8.2.m1.1.1.1.cmml">=</mo><mn id="S4.F8.2.m1.1.1.3" xref="S4.F8.2.m1.1.1.3.cmml">80</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.F8.2.m1.1c"><apply id="S4.F8.2.m1.1.1.cmml" xref="S4.F8.2.m1.1.1"><eq id="S4.F8.2.m1.1.1.1.cmml" xref="S4.F8.2.m1.1.1.1"></eq><ci id="S4.F8.2.m1.1.1.2.cmml" xref="S4.F8.2.m1.1.1.2">𝗏𝖺𝗋</ci><cn type="integer" id="S4.F8.2.m1.1.1.3.cmml" xref="S4.F8.2.m1.1.1.3">80</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F8.2.m1.1d">\mathsf{var}=80</annotation></semantics></math> among five clients.</figcaption>
</figure>
<div id="S4.SS2.SSS3.p2" class="ltx_para">
<p id="S4.SS2.SSS3.p2.2" class="ltx_p">The result depicted in Fig. <a href="#S4.F8" title="Figure 8 ‣ 4.2.3 Experiment 3: Benefits to the newly participated client in the FL learning process ‣ 4.2 Client-level perspectives in FL ‣ 4 Results ‣ Evaluation of Federated Learning in Phishing Email Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a> is for the client 1, and its dataset is defined under five clients setup with <math id="S4.SS2.SSS3.p2.1.m1.1" class="ltx_Math" alttext="\mathsf{var}=80" display="inline"><semantics id="S4.SS2.SSS3.p2.1.m1.1a"><mrow id="S4.SS2.SSS3.p2.1.m1.1.1" xref="S4.SS2.SSS3.p2.1.m1.1.1.cmml"><mi id="S4.SS2.SSS3.p2.1.m1.1.1.2" xref="S4.SS2.SSS3.p2.1.m1.1.1.2.cmml">𝗏𝖺𝗋</mi><mo id="S4.SS2.SSS3.p2.1.m1.1.1.1" xref="S4.SS2.SSS3.p2.1.m1.1.1.1.cmml">=</mo><mn id="S4.SS2.SSS3.p2.1.m1.1.1.3" xref="S4.SS2.SSS3.p2.1.m1.1.1.3.cmml">80</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS3.p2.1.m1.1b"><apply id="S4.SS2.SSS3.p2.1.m1.1.1.cmml" xref="S4.SS2.SSS3.p2.1.m1.1.1"><eq id="S4.SS2.SSS3.p2.1.m1.1.1.1.cmml" xref="S4.SS2.SSS3.p2.1.m1.1.1.1"></eq><ci id="S4.SS2.SSS3.p2.1.m1.1.1.2.cmml" xref="S4.SS2.SSS3.p2.1.m1.1.1.2">𝗏𝖺𝗋</ci><cn type="integer" id="S4.SS2.SSS3.p2.1.m1.1.1.3.cmml" xref="S4.SS2.SSS3.p2.1.m1.1.1.3">80</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS3.p2.1.m1.1c">\mathsf{var}=80</annotation></semantics></math> (this means that client 1 has 80% fewer data samples than client 3). It shows that the client 1 achieves a fast convergence and stable output by leveraging FL compared to its training under CL over its local dataset. However, the same final accuracy of around 98% is observed for both cases at the 50 global epoch.
If the client 1’s dataset is assigned based on <math id="S4.SS2.SSS3.p2.2.m2.1" class="ltx_Math" alttext="\mathsf{var}=0" display="inline"><semantics id="S4.SS2.SSS3.p2.2.m2.1a"><mrow id="S4.SS2.SSS3.p2.2.m2.1.1" xref="S4.SS2.SSS3.p2.2.m2.1.1.cmml"><mi id="S4.SS2.SSS3.p2.2.m2.1.1.2" xref="S4.SS2.SSS3.p2.2.m2.1.1.2.cmml">𝗏𝖺𝗋</mi><mo id="S4.SS2.SSS3.p2.2.m2.1.1.1" xref="S4.SS2.SSS3.p2.2.m2.1.1.1.cmml">=</mo><mn id="S4.SS2.SSS3.p2.2.m2.1.1.3" xref="S4.SS2.SSS3.p2.2.m2.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS3.p2.2.m2.1b"><apply id="S4.SS2.SSS3.p2.2.m2.1.1.cmml" xref="S4.SS2.SSS3.p2.2.m2.1.1"><eq id="S4.SS2.SSS3.p2.2.m2.1.1.1.cmml" xref="S4.SS2.SSS3.p2.2.m2.1.1.1"></eq><ci id="S4.SS2.SSS3.p2.2.m2.1.1.2.cmml" xref="S4.SS2.SSS3.p2.2.m2.1.1.2">𝗏𝖺𝗋</ci><cn type="integer" id="S4.SS2.SSS3.p2.2.m2.1.1.3.cmml" xref="S4.SS2.SSS3.p2.2.m2.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS3.p2.2.m2.1c">\mathsf{var}=0</annotation></semantics></math> (balanced case) with five clients, then the convergence curves for the client 1 are more stable and flat after 10 global epoch; however, a fast convergence is consistently observed for this case when leveraging FL as well. Refer to Fig. <a href="#A1.F14" title="Figure 14 ‣ A.2 Client-level performance of the THEMIS model ‣ Appendix A Supplemental results ‣ Evaluation of Federated Learning in Phishing Email Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">14</span></a> in the Appendix for the results.</p>
</div>
<div id="S4.SS2.SSS3.p3" class="ltx_para">
<span id="S4.SS2.SSS3.p3.1" class="ltx_inline-block ltx_framed ltx_framed_rectangle" style="border-color: #000000;">
<span id="S4.SS2.SSS3.p3.1.1" class="ltx_p"><span id="S4.SS2.SSS3.p3.1.1.1" class="ltx_text ltx_font_bold">Summary:</span> Based on the results in this section, the answer to the <span id="S4.SS2.SSS3.p3.1.1.2" class="ltx_text ltx_font_bold">RQ4</span> is affirmative. The results demonstrate that FL is useful for performance-boosting, including fast convergence, in phishing detection training at the client level under the distributed setups.</span>
</span>
</div>
</section>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span><span id="S4.SS3.1.1" class="ltx_text ltx_font_italic">Distributed email learning under asymmetric data distribution</span>
</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">We examine the performance of FL under an asymmetric dataset distribution mainly in two forms; (1) different sample size among clients (defined by <math id="S4.SS3.p1.1.m1.1" class="ltx_Math" alttext="\mathsf{var}" display="inline"><semantics id="S4.SS3.p1.1.m1.1a"><mi id="S4.SS3.p1.1.m1.1.1" xref="S4.SS3.p1.1.m1.1.1.cmml">𝗏𝖺𝗋</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.1.m1.1b"><ci id="S4.SS3.p1.1.m1.1.1.cmml" xref="S4.SS3.p1.1.m1.1.1">𝗏𝖺𝗋</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.1.m1.1c">\mathsf{var}</annotation></semantics></math>) but with an equal number of phishing and legitimate emails, and (2) same sample size but the different number of phishing and legitimate emails. This setup is not precisely a non-IID distribution, which is due to the high skewness both in the number of samples and their classes present in each client’s dataset.</p>
</div>
<div id="Thmresearchq5" class="ltx_theorem ltx_theorem_researchq">
<h6 class="ltx_title ltx_runin ltx_title_theorem"><span class="ltx_tag ltx_tag_theorem"><span id="Thmresearchq5.1.1.1" class="ltx_text ltx_font_bold">RQ 5</span></span></h6>
<div id="Thmresearchq5.p1" class="ltx_para">
<p id="Thmresearchq5.p1.1" class="ltx_p"><span id="Thmresearchq5.p1.1.1" class="ltx_text ltx_font_bold ltx_font_italic">How would FL perform under asymmetric data distribution among clients due to the variations in the local dataset’s size and the local phishing to legitimate sample ratio?<span id="Thmresearchq5.p1.1.1.1" class="ltx_text ltx_font_medium"></span></span></p>
</div>
</div>
<div id="S4.SS3.p2" class="ltx_para">
<p id="S4.SS3.p2.1" class="ltx_p">We perform two experiments based on the phishing to legitimate email samples (P/L) ratio among clients.</p>
</div>
<figure id="S4.F9" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S4.F9.1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2007.13300/assets/x17.png" id="S4.F9.1.g1" class="ltx_graphics ltx_img_landscape" width="432" height="281" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S4.F9.2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2007.13300/assets/x18.png" id="S4.F9.2.g1" class="ltx_graphics ltx_img_landscape" width="432" height="281" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S4.F9.3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2007.13300/assets/x19.png" id="S4.F9.3.g1" class="ltx_graphics ltx_img_landscape" width="631" height="135" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S4.F9.4" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2007.13300/assets/x20.png" id="S4.F9.4.g1" class="ltx_graphics ltx_img_landscape" width="631" height="117" alt="Refer to caption">
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 9: </span>Showing the impact of different local data sizes provided by different <math id="S4.F9.6.m1.1" class="ltx_Math" alttext="\mathsf{var}" display="inline"><semantics id="S4.F9.6.m1.1b"><mi id="S4.F9.6.m1.1.1" xref="S4.F9.6.m1.1.1.cmml">𝗏𝖺𝗋</mi><annotation-xml encoding="MathML-Content" id="S4.F9.6.m1.1c"><ci id="S4.F9.6.m1.1.1.cmml" xref="S4.F9.6.m1.1.1">𝗏𝖺𝗋</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.F9.6.m1.1d">\mathsf{var}</annotation></semantics></math> among clients to their convergence in FL with five clients on testing accuracy curves of (a) local model, and (b) global model. Corresponding performance metrics of the testing results at 45 global epoch in centralized and federated learning (FL) with five clients are depicted in (c) and (d).</figcaption>
</figure>
<section id="S4.SS3.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.3.1 </span>Same P/L ratio across clients but having different sizes of the local dataset</h4>

<div id="S4.SS3.SSS1.p1" class="ltx_para">
<p id="S4.SS3.SSS1.p1.4" class="ltx_p">The result for 0% (balanced), 10%, 20%, 50%, and 80% variations in the sizes of the local dataset in FL among 5 clients is depicted in Fig. <a href="#S4.F9" title="Figure 9 ‣ 4.3 Distributed email learning under asymmetric data distribution ‣ 4 Results ‣ Evaluation of Federated Learning in Phishing Email Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a>. The result shows that the convergence of the test accuracy curves rises until the global epoch of 10, then remains almost flat afterward.
All cases with different <math id="S4.SS3.SSS1.p1.1.m1.1" class="ltx_Math" alttext="\mathsf{var}" display="inline"><semantics id="S4.SS3.SSS1.p1.1.m1.1a"><mi id="S4.SS3.SSS1.p1.1.m1.1.1" xref="S4.SS3.SSS1.p1.1.m1.1.1.cmml">𝗏𝖺𝗋</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS1.p1.1.m1.1b"><ci id="S4.SS3.SSS1.p1.1.m1.1.1.cmml" xref="S4.SS3.SSS1.p1.1.m1.1.1">𝗏𝖺𝗋</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS1.p1.1.m1.1c">\mathsf{var}</annotation></semantics></math> maintain an overall testing accuracy of around 97% and similar FPR and FNR at the 45 global epoch (Fig. <a href="#S4.F9" title="Figure 9 ‣ 4.3 Distributed email learning under asymmetric data distribution ‣ 4 Results ‣ Evaluation of Federated Learning in Phishing Email Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a>). We observe similar performance patterns for 10 clients. However, for 2 clients, the test performances are improved relative to 5 or 10 clients for all cases except with <math id="S4.SS3.SSS1.p1.2.m2.1" class="ltx_Math" alttext="\mathsf{var}=50" display="inline"><semantics id="S4.SS3.SSS1.p1.2.m2.1a"><mrow id="S4.SS3.SSS1.p1.2.m2.1.1" xref="S4.SS3.SSS1.p1.2.m2.1.1.cmml"><mi id="S4.SS3.SSS1.p1.2.m2.1.1.2" xref="S4.SS3.SSS1.p1.2.m2.1.1.2.cmml">𝗏𝖺𝗋</mi><mo id="S4.SS3.SSS1.p1.2.m2.1.1.1" xref="S4.SS3.SSS1.p1.2.m2.1.1.1.cmml">=</mo><mn id="S4.SS3.SSS1.p1.2.m2.1.1.3" xref="S4.SS3.SSS1.p1.2.m2.1.1.3.cmml">50</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS1.p1.2.m2.1b"><apply id="S4.SS3.SSS1.p1.2.m2.1.1.cmml" xref="S4.SS3.SSS1.p1.2.m2.1.1"><eq id="S4.SS3.SSS1.p1.2.m2.1.1.1.cmml" xref="S4.SS3.SSS1.p1.2.m2.1.1.1"></eq><ci id="S4.SS3.SSS1.p1.2.m2.1.1.2.cmml" xref="S4.SS3.SSS1.p1.2.m2.1.1.2">𝗏𝖺𝗋</ci><cn type="integer" id="S4.SS3.SSS1.p1.2.m2.1.1.3.cmml" xref="S4.SS3.SSS1.p1.2.m2.1.1.3">50</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS1.p1.2.m2.1c">\mathsf{var}=50</annotation></semantics></math> (refer to Fig.<a href="#A1.F17" title="Figure 17 ‣ A.3 THEMIS performance over two clients with a data size variations in the dataset ‣ Appendix A Supplemental results ‣ Evaluation of Federated Learning in Phishing Email Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">17</span></a> for details).
The results show that the closeness of the performance for <math id="S4.SS3.SSS1.p1.3.m3.1" class="ltx_Math" alttext="\mathsf{var}=50" display="inline"><semantics id="S4.SS3.SSS1.p1.3.m3.1a"><mrow id="S4.SS3.SSS1.p1.3.m3.1.1" xref="S4.SS3.SSS1.p1.3.m3.1.1.cmml"><mi id="S4.SS3.SSS1.p1.3.m3.1.1.2" xref="S4.SS3.SSS1.p1.3.m3.1.1.2.cmml">𝗏𝖺𝗋</mi><mo id="S4.SS3.SSS1.p1.3.m3.1.1.1" xref="S4.SS3.SSS1.p1.3.m3.1.1.1.cmml">=</mo><mn id="S4.SS3.SSS1.p1.3.m3.1.1.3" xref="S4.SS3.SSS1.p1.3.m3.1.1.3.cmml">50</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS1.p1.3.m3.1b"><apply id="S4.SS3.SSS1.p1.3.m3.1.1.cmml" xref="S4.SS3.SSS1.p1.3.m3.1.1"><eq id="S4.SS3.SSS1.p1.3.m3.1.1.1.cmml" xref="S4.SS3.SSS1.p1.3.m3.1.1.1"></eq><ci id="S4.SS3.SSS1.p1.3.m3.1.1.2.cmml" xref="S4.SS3.SSS1.p1.3.m3.1.1.2">𝗏𝖺𝗋</ci><cn type="integer" id="S4.SS3.SSS1.p1.3.m3.1.1.3.cmml" xref="S4.SS3.SSS1.p1.3.m3.1.1.3">50</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS1.p1.3.m3.1c">\mathsf{var}=50</annotation></semantics></math> to other cases of <math id="S4.SS3.SSS1.p1.4.m4.1" class="ltx_Math" alttext="\mathsf{var}" display="inline"><semantics id="S4.SS3.SSS1.p1.4.m4.1a"><mi id="S4.SS3.SSS1.p1.4.m4.1.1" xref="S4.SS3.SSS1.p1.4.m4.1.1.cmml">𝗏𝖺𝗋</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS1.p1.4.m4.1b"><ci id="S4.SS3.SSS1.p1.4.m4.1.1.cmml" xref="S4.SS3.SSS1.p1.4.m4.1.1">𝗏𝖺𝗋</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS1.p1.4.m4.1c">\mathsf{var}</annotation></semantics></math> increases with the increase in the number of clients; it achieves the same performance as others for ten clients.</p>
</div>
<div id="S4.SS3.SSS1.p2" class="ltx_para">
<p id="S4.SS3.SSS1.p2.1" class="ltx_p">For most cases, the similarity in performance despite variations in the local data sizes amongst clients indicates the FL’s resilience (mostly enabled by weighted averaging) to the data size variations.</p>
</div>
</section>
<section id="S4.SS3.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.3.2 </span>Different legit email to phishing email sample ratio across clients but having the same sizes of the local dataset</h4>

<figure id="S4.F10" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S4.F10.1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2007.13300/assets/x21.png" id="S4.F10.1.g1" class="ltx_graphics ltx_img_landscape" width="432" height="317" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S4.F10.2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2007.13300/assets/x22.png" id="S4.F10.2.g1" class="ltx_graphics ltx_img_landscape" width="432" height="316" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S4.F10.3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2007.13300/assets/x23.png" id="S4.F10.3.g1" class="ltx_graphics ltx_img_landscape" width="631" height="103" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S4.F10.4" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2007.13300/assets/x24.png" id="S4.F10.4.g1" class="ltx_graphics ltx_img_landscape" width="631" height="96" alt="Refer to caption">
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 10: </span>Showing the impact of different legit email to phishing email sample ratios in the local dataset to their convergence in FL with five clients on testing accuracy curves of (a) local model and (b) global model. Corresponding performance metrics of the testing results at the global epoch of 45 in centralized and federated learning (FL) with five clients are depicted in (c) and (d).</figcaption>
</figure>
<div id="S4.SS3.SSS2.p1" class="ltx_para">
<p id="S4.SS3.SSS2.p1.1" class="ltx_p">Fig. <a href="#S4.F10" title="Figure 10 ‣ 4.3.2 Different legit email to phishing email sample ratio across clients but having the same sizes of the local dataset ‣ 4.3 Distributed email learning under asymmetric data distribution ‣ 4 Results ‣ Evaluation of Federated Learning in Phishing Email Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10</span></a> depicts the results for FL among 5 clients having the same size of the local dataset but all with P/L ratios of (i) 10:90 (first case), (ii) 30:70 (second case), (iii) 50:50 (third case), and (iv) 70:30 (fourth case). We choose the specific ratios for the test purpose so that the P/L ratio remains distinct. This setup is more practical than the setup with the same P/L ratio, as this has a bias in the samples. The experiments for this section have <math id="S4.SS3.SSS2.p1.1.m1.1" class="ltx_Math" alttext="\mathsf{var}=0" display="inline"><semantics id="S4.SS3.SSS2.p1.1.m1.1a"><mrow id="S4.SS3.SSS2.p1.1.m1.1.1" xref="S4.SS3.SSS2.p1.1.m1.1.1.cmml"><mi id="S4.SS3.SSS2.p1.1.m1.1.1.2" xref="S4.SS3.SSS2.p1.1.m1.1.1.2.cmml">𝗏𝖺𝗋</mi><mo id="S4.SS3.SSS2.p1.1.m1.1.1.1" xref="S4.SS3.SSS2.p1.1.m1.1.1.1.cmml">=</mo><mn id="S4.SS3.SSS2.p1.1.m1.1.1.3" xref="S4.SS3.SSS2.p1.1.m1.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS2.p1.1.m1.1b"><apply id="S4.SS3.SSS2.p1.1.m1.1.1.cmml" xref="S4.SS3.SSS2.p1.1.m1.1.1"><eq id="S4.SS3.SSS2.p1.1.m1.1.1.1.cmml" xref="S4.SS3.SSS2.p1.1.m1.1.1.1"></eq><ci id="S4.SS3.SSS2.p1.1.m1.1.1.2.cmml" xref="S4.SS3.SSS2.p1.1.m1.1.1.2">𝗏𝖺𝗋</ci><cn type="integer" id="S4.SS3.SSS2.p1.1.m1.1.1.3.cmml" xref="S4.SS3.SSS2.p1.1.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS2.p1.1.m1.1c">\mathsf{var}=0</annotation></semantics></math>. The figure shows that until the global epoch of 15, there is a difference in the performance, where the first case (i.e., 10:90 P/L ratio) with the lower phishing email samples was not performing well compared with other cases with higher phishing email samples. However, after the 15 epoch, all cases converge similarly to provide an overall testing accuracy of around 97% except for the second (30:70 P/L ratio) case, where the testing accuracy is around 93%. Other performance metrics are provided in Fig. <a href="#S4.F10" title="Figure 10 ‣ 4.3.2 Different legit email to phishing email sample ratio across clients but having the same sizes of the local dataset ‣ 4.3 Distributed email learning under asymmetric data distribution ‣ 4 Results ‣ Evaluation of Federated Learning in Phishing Email Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10</span></a> and <a href="#S4.F10" title="Figure 10 ‣ 4.3.2 Different legit email to phishing email sample ratio across clients but having the same sizes of the local dataset ‣ 4.3 Distributed email learning under asymmetric data distribution ‣ 4 Results ‣ Evaluation of Federated Learning in Phishing Email Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10</span></a>.</p>
</div>
<div id="S4.SS3.SSS2.p2" class="ltx_para">
<p id="S4.SS3.SSS2.p2.1" class="ltx_p">Comparing the results for two, five, and ten clients (see Fig. <a href="#A1.F18" title="Figure 18 ‣ A.4 THEMIS performance over ten clients with the phishing to legitimate email samples ratio variations in the dataset ‣ Appendix A Supplemental results ‣ Evaluation of Federated Learning in Phishing Email Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">18</span></a> in Appendix for the results with ten clients), they show a jump in the testing accuracy for the first case (10:90 P/L ratio) at different global epoch; jumps at 5, 15, and 30 global epochs for two, five and ten clients, respectively. The reasons behind these jumps are unclear.
Overall, observing at the 45 global epoch for the setups with two, five, and ten clients, the global performance for various P/L ratios slightly decreases with the increase in phishing samples (going from 10% to 70%). In practice, organizations have fewer phishing emails than legitimate; thus, this concern can be contained.</p>
</div>
<div id="S4.SS3.SSS2.p3" class="ltx_para">
<span id="S4.SS3.SSS2.p3.1" class="ltx_inline-block ltx_framed ltx_framed_rectangle" style="border-color: #000000;">
<span id="S4.SS3.SSS2.p3.1.1" class="ltx_p"><span id="S4.SS3.SSS2.p3.1.1.1" class="ltx_text ltx_font_bold">Summary:</span> Based on the empirical results in this section, in most cases, FL demonstrates highly resilient performances against the asymmetric data distribution due to the size and P/L ratio.</span>
</span>
</div>
</section>
</section>
<section id="S4.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4 </span><span id="S4.SS4.1.1" class="ltx_text ltx_font_italic">Distributed email learning under an extreme asymmetric data distribution</span>
</h3>

<div id="S4.SS4.p1" class="ltx_para">
<p id="S4.SS4.p1.1" class="ltx_p">In this section, we consider an extreme dataset diversity among the clients. We keep our different email sources as different clients; Client 1 has IWSPA dataset, Client 2 has Enron dataset, Client 3 has Nazario dataset, Client 4 has CSIRO emails, and Client 5 has Phishbowl emails (refer to Table <a href="#S3.T1" title="TABLE I ‣ 3.1 Datasets ‣ 3 Experimental setup ‣ Evaluation of Federated Learning in Phishing Email Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">I</span></a> for the size of local datasets). This setup captures both the variations in the sample sizes and class type across clients.</p>
</div>
<div id="Thmresearchq6" class="ltx_theorem ltx_theorem_researchq">
<h6 class="ltx_title ltx_runin ltx_title_theorem"><span class="ltx_tag ltx_tag_theorem"><span id="Thmresearchq6.1.1.1" class="ltx_text ltx_font_bold">RQ 6</span></span></h6>
<div id="Thmresearchq6.p1" class="ltx_para">
<p id="Thmresearchq6.p1.1" class="ltx_p"><span id="Thmresearchq6.p1.1.1" class="ltx_text ltx_font_bold ltx_font_italic">How would FL perform under extreme dataset diversity among clients?<span id="Thmresearchq6.p1.1.1.1" class="ltx_text ltx_font_medium"></span></span></p>
</div>
</div>
<figure id="S4.F11" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S4.F11.1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2007.13300/assets/x25.png" id="S4.F11.1.g1" class="ltx_graphics ltx_img_landscape" width="465" height="252" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S4.F11.2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2007.13300/assets/x26.png" id="S4.F11.2.g1" class="ltx_graphics ltx_img_landscape" width="465" height="252" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S4.F11.3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2007.13300/assets/x27.png" id="S4.F11.3.g1" class="ltx_graphics ltx_img_landscape" width="465" height="248" alt="Refer to caption">
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 11: </span>THEMISb model with five clients: Client-level convergence curves of (a) testing accuracy of the local model, (b) testing accuracy of the global model, and (c) training accuracy.</figcaption>
</figure>
<figure id="S4.F12" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S4.F12.1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2007.13300/assets/x28.png" id="S4.F12.1.g1" class="ltx_graphics ltx_img_landscape" width="465" height="252" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S4.F12.2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2007.13300/assets/x29.png" id="S4.F12.2.g1" class="ltx_graphics ltx_img_landscape" width="465" height="252" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S4.F12.3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2007.13300/assets/x30.png" id="S4.F12.3.g1" class="ltx_graphics ltx_img_landscape" width="465" height="248" alt="Refer to caption">
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 12: </span>BERT model with five clients: Client-level convergence curves of (a) testing accuracy of the local model, (b) testing accuracy of the global model, and (c) training accuracy.</figcaption>
</figure>
<div id="S4.SS4.p2" class="ltx_para">
<p id="S4.SS4.p2.1" class="ltx_p">The results for THEMISb and BERT, both considering only the body of emails while learning, are depicted in Fig. <a href="#S4.F11" title="Figure 11 ‣ 4.4 Distributed email learning under an extreme asymmetric data distribution ‣ 4 Results ‣ Evaluation of Federated Learning in Phishing Email Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">11</span></a>, and  <a href="#S4.F12" title="Figure 12 ‣ 4.4 Distributed email learning under an extreme asymmetric data distribution ‣ 4 Results ‣ Evaluation of Federated Learning in Phishing Email Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">12</span></a>, respectively.
For the THEMIS and THEMISb model, clients having few samples and the latest phishing samples, such as client 4 and client 5, could not collaborate effectively while training and testing and suffer from high fluctuations in its results. Moreover, client 3, which has only phishing emails but in large numbers, also shows similar performance to client 4 and 5 in the global model testing. However, its local model testing result is excellent (around 99.99% accuracy). Both the THEMIS models (THEMIS and THEMISb) show similar results. Refer to Fig. <a href="#A1.F19" title="Figure 19 ‣ A.5 Distributed email learning under an extreme asymmetric data distribution with THEMIS (considering both email’s header and body information) ‣ Appendix A Supplemental results ‣ Evaluation of Federated Learning in Phishing Email Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">19</span></a> in the Appendix for the results of the THEMIS model (considering the email headers).</p>
</div>
<div id="S4.SS4.p3" class="ltx_para">
<p id="S4.SS4.p3.1" class="ltx_p">Unlike the results of THEMISb and THEMIS, all clients converge well during training with the BERT model and perform well in the local model testing. Moreover, client 1 is under-performing among all with 97% accuracy in the local model testing; others maintain accuracy of 99.99%.
However, the global testing results show high fluctuations, specifically for clients 1, 2, and 4. Clients 4 and 5 have relatively stable results in global model testing than other clients. This result is in sharp contrast to that with the THEMIS/THEMISb model.
The problem with the THEMIS/THEMISb model in FL can be contained by allowing the clients to train their local models for a longer time and keep either the local or global model based on their performance for the deployment.</p>
</div>
<div id="S4.SS4.p4" class="ltx_para">
<span id="S4.SS4.p4.1" class="ltx_inline-block ltx_framed ltx_framed_rectangle" style="border-color: #000000;">
<span id="S4.SS4.p4.1.1" class="ltx_p"><span id="S4.SS4.p4.1.1.1" class="ltx_text ltx_font_bold">Summary: Under extreme dataset diversity among clients, models suffer high fluctuation in their performances. However, BERT produces relatively stable results even for clients with few samples. This indicates the FL performance is model-dependent.</span></span>
</span>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span><span id="S5.1.1" class="ltx_text ltx_font_smallcaps">Related Works</span>
</h2>

<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span><span id="S5.SS1.1.1" class="ltx_text ltx_font_italic">Centralized learning in phishing detection</span>
</h3>

<div id="S5.SS1.p1" class="ltx_para">
<p id="S5.SS1.p1.1" class="ltx_p">A centralized email analysis based on AI-based methods for phishing detection has been explored for a long time. Conventional ML-based techniques such as decision trees, logistic regression, random forests, AdaBoost, and support vector machines are analyzed in phishing detection <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>, <a href="#bib.bib41" title="" class="ltx_ref">41</a>, <a href="#bib.bib42" title="" class="ltx_ref">42</a>, <a href="#bib.bib43" title="" class="ltx_ref">43</a>, <a href="#bib.bib44" title="" class="ltx_ref">44</a>, <a href="#bib.bib45" title="" class="ltx_ref">45</a>, <a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>. These techniques are based on feature engineering, which requires in-depth domain knowledge and trials.
On the other hand, DL-based methods include deep neural networks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib46" title="" class="ltx_ref">46</a>]</cite>, convolutional neural networks (CNNs) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>, deep belief networks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib47" title="" class="ltx_ref">47</a>]</cite>, bidirectional LSTM with supervised attention <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib48" title="" class="ltx_ref">48</a>]</cite>, and recurrent convolutional neural networks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>. These works are mostly based on natural language processing techniques for phishing detection.
While most existing works have focused on the effective detection of general phishing emails, few works consider specialized phishing attacks, including spear phishing attacks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib49" title="" class="ltx_ref">49</a>]</cite> and business email compromise attacks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib50" title="" class="ltx_ref">50</a>]</cite> in specific contexts.
Despite the usefulness, all the above works operate under a setting where emails must be centralized for analysis and thus do not provide privacy protection of email datasets.</p>
</div>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span><span id="S5.SS2.1.1" class="ltx_text ltx_font_italic">Cryptographic Deep Learning Training</span>
</h3>

<div id="S5.SS2.p1" class="ltx_para">
<p id="S5.SS2.p1.1" class="ltx_p">There have been attempts on cryptographic approaches for supporting DL model training over encrypted data, which can be applicable for phishing email detection while preserving privacy.
For privacy-preserving neural network training, the first system design is SecureML <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib51" title="" class="ltx_ref">51</a>]</cite>.
In this system, multiple data providers can secretly share their data among two cloud servers, which will then conduct the training procedure over the secret-shared data.
This work relies on the secure computation techniques, e.g., secret sharing and garbled circuits, to design a secure two-party computation protocol, allowing two cloud servers to compute in the ciphertext domain the linear operations (addition and multiplication) as well as the non-linear activation functions.
Later, a design that works in the three-server model was proposed <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib52" title="" class="ltx_ref">52</a>]</cite>. It is based on the lightweight secret sharing technique with better performance than SecureML.
This work assumes an adversary model where none of the three cloud servers will deviate from the protocol.
The work in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib53" title="" class="ltx_ref">53</a>]</cite> also operates under a similar three-server setting yet achieves more robust security against malicious adversaries who deviate arbitrarily.
This line of work presents valuable research endeavors in enabling deep neural network training over encrypted data. Yet, it has to rely on additional architectural assumptions (i.e., non-colluding cloud servers) and incur substantial performance overheads (up to orders of magnitude slower) compared to the plain text baseline.</p>
</div>
</section>
<section id="S5.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3 </span><span id="S5.SS3.1.1" class="ltx_text ltx_font_italic">Federated Learning</span>
</h3>

<div id="S5.SS3.p1" class="ltx_para">
<p id="S5.SS3.p1.1" class="ltx_p">FL is attractive, especially when the data is sensitive, like in the financial sector (banks) and the medical sector (hospitals) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>. There have been several works in FL though none of them specifically address phishing email detection. Some works include the following: Google has used FL for next-word prediction in
a virtual keyboard for smartphones words <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib54" title="" class="ltx_ref">54</a>]</cite>, Leroy <span id="S5.SS3.p1.1.1" class="ltx_text ltx_font_italic">et al.</span> applied FL for speech keyword spotting  <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib55" title="" class="ltx_ref">55</a>]</cite>, Gao <span id="S5.SS3.p1.1.2" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib56" title="" class="ltx_ref">56</a>]</cite> propose to use FL to train a joint model over heterogeneous ECG medical data to preserve the data privacy of each party, and
Yang <span id="S5.SS3.p1.1.3" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite> applied FL to detect credit card fraud.</p>
</div>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span><span id="S6.1.1" class="ltx_text ltx_font_smallcaps">Discussion and future work</span>
</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">This paper is the first step in federated email learning for phishing detection. Though our results demonstrated its benefits and performances, FL needs more studies, specifically for its robustness under aspects such as security attacks.</p>
</div>
<section id="S6.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.1 </span><span id="S6.SS1.1.1" class="ltx_text ltx_font_italic">Improving federated learning performance in phishing email detection</span>
</h3>

<div id="S6.SS1.p1" class="ltx_para">
<p id="S6.SS1.p1.1" class="ltx_p">This paper considered the federated averaging (FedAvg) algorithm for the model aggregation in FL.
But in literature, it is reported that FedAvg can have a hugely detrimental effect on the model’s performance because there can be many variants of the model weights that only differ in the ordering of parameters, such as in neural networks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib57" title="" class="ltx_ref">57</a>]</cite>. Besides, the personalization of the model may cause the deterioration of the model performance due to the FedAvg  <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib58" title="" class="ltx_ref">58</a>]</cite>. Personalization means that the local model may fit well for some but not all devices. This means some devices will have outstanding performance and otherwise for other devices (the case for clients 4 and 5 with THEMIS model under an extreme asymmetric data distribution). With more users, the effect of personalization is more significant and resulting a low-performance global model. This effect can be mitigated using model agnostic meta learning  <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib58" title="" class="ltx_ref">58</a>]</cite> to improve the global model so that it can fit well for the majority of the users and has a faster convergence. As a side effect, the local test accuracy, due to the less personalized effect, it is less likely for some devices to have excellent local model performance. Thus to improve the results further, studying other aggregating methods such as FedCurv and FedProx <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib59" title="" class="ltx_ref">59</a>]</cite> may be required in phishing detection.
Besides, studies with more models, a large corpus of email data, and their comparative analysis in FL are left as the next work.</p>
</div>
</section>
<section id="S6.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.2 </span><span id="S6.SS2.1.1" class="ltx_text ltx_font_italic">Federated learning, privacy, and security attacks</span>
</h3>

<div id="S6.SS2.p1" class="ltx_para">
<p id="S6.SS2.p1.1" class="ltx_p">The main challenge to deploy FL in phishing detection would be the possibility of security and privacy attacks in FL, which is observed under different datasets other than phishing emails. Moreover, privacy could be leaked due to the inference attack <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib60" title="" class="ltx_ref">60</a>]</cite>, while security attacks can occur due to backdoor attacks via data poisoning or parameter tampering <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib61" title="" class="ltx_ref">61</a>]</cite>. Corresponding countermeasures, such as input filters, unlearning, strong intentional perturbation-based Trojan attack detection, and dynamic client allocation mechanism <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib62" title="" class="ltx_ref">62</a>, <a href="#bib.bib63" title="" class="ltx_ref">63</a>, <a href="#bib.bib16" title="" class="ltx_ref">16</a>, <a href="#bib.bib64" title="" class="ltx_ref">64</a>]</cite>, can be deployed to mitigate such attacks. However, future works are required to analyze their implications in phishing detection.</p>
</div>
</section>
<section id="S6.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.3 </span><span id="S6.SS3.1.1" class="ltx_text ltx_font_italic">Federated learning and data privacy</span>
</h3>

<div id="S6.SS3.p1" class="ltx_para">
<p id="S6.SS3.p1.1" class="ltx_p">FL is a privacy-by-design approach, however, FL alone can not guarantee data privacy. So, there are various other techniques such as homomorphic encryption <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib65" title="" class="ltx_ref">65</a>]</cite> (a cryptographic approach) and differential privacy <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib66" title="" class="ltx_ref">66</a>]</cite> used <span id="S6.SS3.p1.1.1" class="ltx_text ltx_font_italic">along with</span> FL for guaranteed and provable privacy, respectively. However, homomorphic encryption increases computational overhead, and differential privacy degrades the performance as a trade-off. The integration of these techniques to FL in phishing detection remains as other research avenues.</p>
</div>
</section>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span><span id="S7.1.1" class="ltx_text ltx_font_smallcaps">Conclusion</span>
</h2>

<div id="S7.p1" class="ltx_para">
<p id="S7.p1.1" class="ltx_p">This work took the first step to implement federated learning (FL) for email phishing detection in collaborative distributed frameworks. FL enables multiple organizations to collaborate to train a deep anti-phishing model without sharing their email data. Deep anti-phishing models usually have high detection but require huge data. Thus more organizations can contribute to improving the model performance, including the client-level performance, by harnessing data integration in FL, as illustrated in this paper.
Built upon the best deep learning model relevant to email phishing detection, namely BERT and THEMIS/THEMISb, our analysis under FL demonstrated promising results while preserving email privacy. More specifically, the deep learning model’s performance under FL was comparable to centralized learning, and for most of the cases, it performed well under various scenarios, including asymmetric data distribution among clients. However, for an extreme asymmetry in data distribution, the performance is subjective to the model and dataset, where BERT was relatively stable than THEMIS/THEMISb.</p>
</div>
</section>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_font_smallcaps ltx_title_section">Acknowledgements</h2>

<div id="Sx1.p1" class="ltx_para">
<p id="Sx1.p1.1" class="ltx_p">The work is partially supported by the Cyber Security Cooperative Research Centre, Australia.
The authors acknowledge Professor Rakesh Verma from the University of Houston, USA, for the IWSPA-AP corpus.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
Retruster Ltd., “2019 phishing statistics and email fraud statistics,”
2020. [Online]. Available:
<span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://retruster.com/blog/2019-phishing-and-email-fraud-statistics.html</span>

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
L. Mathews, “Phishing scams cost american businesses half a billion dollars a
year,” 2017. [Online]. Available:
<span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://www.forbes.com/sites/leemathews/2017/05/05/phishing-scams-cost-american-businesses-half-a-billion-dollars-a-year/#133f645b3fa1</span>

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
P. Muncaster, “Covid19 drives phishing emails up 667% in under a month,”
2020. [Online]. Available:
<span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://www.infosecurity-magazine.com/news/covid19-drive-phishing-emails-667?utm_source=twitterfeed&amp;utm_medium=twitter</span>

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
E. G. Dada, J. S. Bassi, H. Chiroma, S. M. Abdulhamid, A. O. Adetunmbi, and
O. E. Ajibuwa, “Machine learning for email spam filtering: review,
approaches and open research problems,” <em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">Heliyon</em>, vol. 5, no. 6, pp.
e01 802 (1–23), 2019.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
H. M, N. Unnithan, V. Ravi, and S. Kp, “Deep learning based phishing e-mail
detection cen-deepspam,” in <em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">Proc. 1st AntiPhishing Shared Pilot at 4th
ACM IWSPA</em>, 03 2018.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
Y. Fang, C. Zhang, C. Huang, L. Liu, and Y. Yang, “Phishing email detection
using improved rcnn model with multilevel vectors and attention mechanism,”
<em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">IEEE Access</em>, vol. 7, pp. 56 329–56 340, 2019.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova, “Bert: Pre-training of deep
bidirectional transformers for language understanding,” 2019. [Online].
Available: <span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://arxiv.org/pdf/1810.04805.pdf</span>

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
A. Das, S. Baki, A. El Aassal, R. Verma, and A. Dunbar, “Sok: A comprehensive
reexamination of phishing research from the security perspective,”
<em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">Commun. Surveys Tuts.</em>, vol. 22, no. 1, p. 671–708, Jan. 2020.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
J. Gao, Q. Ping, and J. Wang, “Resisting re-identification mining on social
graph data,” <em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">World Wide Web</em>, vol. 21, no. 6, pp. 1759–1771, 2018.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
G. Ho, A. Cidon, L. Gavish, M. Schweighauser, V. Paxson, S. Savage, G. M.
Voelker, and D. Wagner, “Detecting and characterizing lateral phishing at
scale,” in <em id="bib.bib10.4.4" class="ltx_emph ltx_font_italic">28th <math id="bib.bib10.1.1.m1.1" class="ltx_Math" alttext="\{" display="inline"><semantics id="bib.bib10.1.1.m1.1a"><mo stretchy="false" id="bib.bib10.1.1.m1.1.1" xref="bib.bib10.1.1.m1.1.1.cmml">{</mo><annotation-xml encoding="MathML-Content" id="bib.bib10.1.1.m1.1b"><ci id="bib.bib10.1.1.m1.1.1.cmml" xref="bib.bib10.1.1.m1.1.1">{</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib10.1.1.m1.1c">\{</annotation></semantics></math>USENIX<math id="bib.bib10.2.2.m2.1" class="ltx_Math" alttext="\}" display="inline"><semantics id="bib.bib10.2.2.m2.1a"><mo stretchy="false" id="bib.bib10.2.2.m2.1.1" xref="bib.bib10.2.2.m2.1.1.cmml">}</mo><annotation-xml encoding="MathML-Content" id="bib.bib10.2.2.m2.1b"><ci id="bib.bib10.2.2.m2.1.1.cmml" xref="bib.bib10.2.2.m2.1.1">}</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib10.2.2.m2.1c">\}</annotation></semantics></math> Security Symposium (<math id="bib.bib10.3.3.m3.1" class="ltx_Math" alttext="\{" display="inline"><semantics id="bib.bib10.3.3.m3.1a"><mo stretchy="false" id="bib.bib10.3.3.m3.1.1" xref="bib.bib10.3.3.m3.1.1.cmml">{</mo><annotation-xml encoding="MathML-Content" id="bib.bib10.3.3.m3.1b"><ci id="bib.bib10.3.3.m3.1.1.cmml" xref="bib.bib10.3.3.m3.1.1">{</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib10.3.3.m3.1c">\{</annotation></semantics></math>USENIX<math id="bib.bib10.4.4.m4.1" class="ltx_Math" alttext="\}" display="inline"><semantics id="bib.bib10.4.4.m4.1a"><mo stretchy="false" id="bib.bib10.4.4.m4.1.1" xref="bib.bib10.4.4.m4.1.1.cmml">}</mo><annotation-xml encoding="MathML-Content" id="bib.bib10.4.4.m4.1b"><ci id="bib.bib10.4.4.m4.1.1.cmml" xref="bib.bib10.4.4.m4.1.1">}</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib10.4.4.m4.1c">\}</annotation></semantics></math>
Security 19)</em>, 2019, pp. 1273–1290.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
S. Shastri, M. Wasserman, and V. Chidambaram, “The seven sins of personal-data
processing systems under gdpr,” in <em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">Proc. of the 11th USENIX Conference
on Hot Topics in Cloud Computing</em>, ser. HotCloud’19.   Berkeley, CA, USA: USENIX Association, 2019, pp. 1–1.
[Online]. Available: <span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">http://dl.acm.org/citation.cfm?id=3357034.3357036</span>

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
EU GDPR, “General data protection regulation (gdpr),”
<span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://www.eugdpr.org/</span>, accessed: Nov 10, 2019.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
H. C. Assistance, “Summary of the hipaa privacy rule,” <em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">Office for Civil
Rights</em>, 2003.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
H. B. McMahan, “A survey of algorithms and analysis for adaptive online
learning,” <em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">Journal of Machine Learning Research</em>, vol. 18, pp.
90:1–90:50, 2017. [Online]. Available:
<span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">http://jmlr.org/papers/v18/14-428.html</span>

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
K. Bonawitz, H. Eichner, W. Grieskamp, D. Huba, A. Ingerman, V. Ivanov,
C. Kiddon, J. Konecný, S. Mazzocchi, H. B. McMahan, T. V. Overveldt,
D. Petrou, D. Ramage, and J. Roselander, “Towards federated learning at
scale: System design,” <em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/1902.01046, 2019. [Online].
Available: <span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">http://arxiv.org/abs/1902.01046</span>

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
P. Kairouz, H. B. McMahan, B. Avent, A. Bellet, M. Bennis, A. N. Bhagoji,
K. Bonawitz, Z. Charles, G. Cormode, R. Cummings <em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Advances
and open problems in federated learning,” 2019. [Online]. Available:
<span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://arxiv.org/abs/1912.04977</span>

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
W. Yang, Y. Zhang, K. Ye, L. Li, and C.-Z. Xu, “Ffd: A federated learning
based method for credit card fraud detection,” in <em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">International
Conference on Big Data</em>.   Springer,
2019, pp. 18–32.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
N. Rieke, J. Hancox, W. Li, F. Milletari, and H. e. a. Roth, “The future of
digital health with federated learning,” <em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">npj Digit. Med.</em>, vol. 3, no.
119, 2020.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
B. Y. Lin, C. He, Z. Zeng, H. Wang, Y. Huang, M. Soltanolkotabi, X. Ren, and
S. Avestimehr, “Fednlp: A research platform for federated learning in
natural language processing,” 2021.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
R. Lab@UH, “First security and privacy analytics anti-phishing shared task
(iwspa-ap 2018),” accessed: Jan 16, 2020. [Online]. Available:
<span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://dasavisha.github.io/IWSPA-sharedtask/</span>

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
J. Nazario, “Nazario’s phishing corpora,” accessed: Jan 16, 2020. [Online].
Available: <span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://monkey.org/~jose/phishing/</span>

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
C. project, “Enron email dataset,” accessed: Jan 16, 2020. [Online].
Available: <span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">http://www.cs.cmu.edu/~enron/</span>

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
C. University, “Phis bowl,” accessed: Jan 3, 2021. [Online]. Available:
<span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://it.cornell.edu/phish-bowl</span>

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
“The dada engine,” accessed: Jan 16, 2020. [Online]. Available:
<span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">http://dev.null.org/dadaengine/</span>

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
H. M, N. A. Unnithan, V. R, and S. KP, “Deep learning based phishing e-mail
detection,” in <em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">Proc. 1st AntiPhishing Shared Pilot at 4th ACM IWSPA</em>,
2018.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
S. Lai, L. Xu, K. Liu, and J. Zhao, “Recurrent convolutional neural networks
for text classification,” in <em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">Twenty-ninth AAAI conference on
artificial intelligence</em>, 2015.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
HuggingFace, “bert-base-uncased,” accessed: April 9, 2020. [Online].
Available: <span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://huggingface.co/bert-base-uncased</span>

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
Y. Lee, J. Saxe, and R. Harang, “Catbert: Context-aware tiny bert for
detecting social engineering emails,” 2020. [Online]. Available:
<span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://arxiv.org/pdf/2010.03484.pdf</span>

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
V. Sanh, L. Debut, J. Chaumond, and T. Wolf, “Distilbert, a distilled version
of bert: smaller, faster, cheaper and lighter,” 2020. [Online]. Available:
<span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://arxiv.org/pdf/1910.01108.pdf</span>

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
P. S. Foundation, “email.header: Internationalized headers,” accessed: Jan
18, 2020. [Online]. Available:
<span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://docs.python.org/3/library/email.header.html</span>

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
S. Labs, “re — regular expression operations,” accessed: Jan 18, 2020.
[Online]. Available: <span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://docs.python.org/3/library/re.html</span>

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
B. group, “Beautiful soup,” accessed: Jan 19, 2020. [Online]. Available:
<span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://www.crummy.com/software/BeautifulSoup/</span>

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
Online, “html.parser — simple html and xhtml parser,” accessed: Jan 19,
2020. [Online]. Available:
<span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://docs.python.org/3/library/html.parser.html</span>

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
S. Bird, E. Klein, and E. Loper, “Natural language processing with python:
Analyzing text with the natural language toolkit,” accessed: Jan 19, 2020.
[Online]. Available: <span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://www.nltk.org/book/ch02.html</span>

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
Online, “tf.keras.preprocessing.text.tokenizer,” accessed: Jan 20, 2020.
[Online]. Available:
<span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text/Tokenizer</span>

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock">
——, “Bert,” accessed: Jan 21, 2021. [Online]. Available:
<span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://huggingface.co/transformers/model_doc/bert.html</span>

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock">
M. Abadi, P. Barham, J. Chen, Z. Chen, and A. D. . X. Zheng, “Tensorflow: A
system for large-scale machine learning,” in <em id="bib.bib37.1.1" class="ltx_emph ltx_font_italic">12th USENIX Symposium
on Operating Systems Design and Implementation</em>, K. Keeton and T. Roscoe,
Eds.   USENIX Association, 2016, pp.
265–283.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock">
K. team, “Keras: The python deep learning library,” accessed: Jan 18, 2020.
[Online]. Available: <span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://keras.io/</span>

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock">
Q. Meng, W. Chen, Y. Wang, Z.-M. Ma, and T.-Y. Liu, “Convergence analysis of
distributed stochastic gradient descent with shuffling,”
<em id="bib.bib39.1.1" class="ltx_emph ltx_font_italic">Neurocomputing</em>, vol. 337, pp. 46–57, 2019.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock">
S. Abu-Nimeh, D. Nappa, X. Wang, and S. Nair, “A comparison of machine
learning techniques for phishing detection,” in <em id="bib.bib40.1.1" class="ltx_emph ltx_font_italic">Proc. of the
Anti-Phishing Working Groups 2nd Annual eCrime Researchers Summit</em>, vol.
269.   ACM, 2007, pp. 60–69.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock">
A. Bergholz, J. D. Beer, S. Glahn, M. Moens, G. Paaß, and S. Strobel, “New
filtering approaches for phishing email,” <em id="bib.bib41.1.1" class="ltx_emph ltx_font_italic">Journal of Computer
Security</em>, vol. 18, no. 1, pp. 7–35, 2010.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock">
R. M. Verma, N. Shashidhar, and N. Hossain, “Detecting phishing emails the
natural language way,” in <em id="bib.bib42.1.1" class="ltx_emph ltx_font_italic">Proc. of ESORICS</em>, vol. 7459, 2012, pp.
824–841.

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock">
A. Vazhayil, N. Harikrishnan, R. Vinayakumar, K. Soman, and A. Verma, “Ped-ml:
Phishing email detection using classical machine learning techniques,” in
<em id="bib.bib43.1.1" class="ltx_emph ltx_font_italic">Proc. 1st AntiPhishing Shared Pilot at 4th ACM IWSPA</em>, 2018, pp. 1–8.

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[44]</span>
<span class="ltx_bibblock">
C. N. Gutierrez, T. Kim, R. D. Corte, J. Avery, D. Goldwasser, M. Cinque, and
S. Bagchi, “Learning from the ones that got away: Detecting new forms of
phishing attacks,” <em id="bib.bib44.1.1" class="ltx_emph ltx_font_italic">IEEE Trans. Dependable Secur. Comput.</em>, vol. 15,
no. 6, pp. 988–1001, 2018.

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[45]</span>
<span class="ltx_bibblock">
N. Unnithan, H. NB, V. R, S. Kp, and S. Sundarakrishna, “Detecting phishing
e-mail using machine learning techniques cen-securenlp,” in <em id="bib.bib45.1.1" class="ltx_emph ltx_font_italic">Proc. 1st
AntiPhishing Shared Pilot at 4th ACM IWSPA</em>, 03 2018.

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[46]</span>
<span class="ltx_bibblock">
S. Smadi, N. Aslam, and L. Zhang, “Detection of online phishing email using
dynamic evolving neural network based on reinforcement learning,”
<em id="bib.bib46.1.1" class="ltx_emph ltx_font_italic">Decis. Support Syst.</em>, vol. 107, pp. 88–102, 2018.

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[47]</span>
<span class="ltx_bibblock">
J. Zhang and X. Li, “Phishing detection method based on borderline-smote deep
belief network,” in <em id="bib.bib47.1.1" class="ltx_emph ltx_font_italic">Proc. of International Conference on Security,
Privacy and Anonymity in Computation, Communication and Storage</em>, 2017, pp.
45–53.

</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[48]</span>
<span class="ltx_bibblock">
M. Nguyen, T. Nguyen, and T. H. Nguyen, “A deep learning model with
hierarchical lstms and supervised attention for anti-phishing,” in
<em id="bib.bib48.1.1" class="ltx_emph ltx_font_italic">Proc. 1st AntiPhishing Shared Pilot at 4th ACM IWSPA</em>, 03 2018.

</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[49]</span>
<span class="ltx_bibblock">
H. Gascon, S. Ullrich, B. Stritter, and K. Rieck, “Reading between the lines:
Content-agnostic detection of spear-phishing emails,” in <em id="bib.bib49.1.1" class="ltx_emph ltx_font_italic">Proc. of
RAID</em>, M. Bailey, T. Holz, M. Stamatogiannakis, and S. Ioannidis, Eds., 2018,
pp. 69–91.

</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[50]</span>
<span class="ltx_bibblock">
A. Cidon, L. Gavish, I. Bleier, N. Korshun, M. Schweighauser, and A. Tsitkin,
“High precision detection of business email compromise,” in <em id="bib.bib50.1.1" class="ltx_emph ltx_font_italic">Proc.
28th USENIX Security Symposium</em>, 2019, pp. 1291–1307.

</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[51]</span>
<span class="ltx_bibblock">
P. Mohassel and Y. Zhang, “Secureml: A system for scalable
privacy-preserving machine learning,” in <em id="bib.bib51.1.1" class="ltx_emph ltx_font_italic">Proc. of IEEE S&amp;P</em>, 2017,
pp. 19–38.

</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[52]</span>
<span class="ltx_bibblock">
S. Wagh, D. Gupta, and N. Chandran, “Securenn: 3-party secure computation for
neural network training,” <em id="bib.bib52.1.1" class="ltx_emph ltx_font_italic">PoPETs</em>, vol. 2019, no. 3, pp. 26–49, 2019.

</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[53]</span>
<span class="ltx_bibblock">
P. Mohassel and P. Rindal, “Aby<math id="bib.bib53.1.m1.1" class="ltx_Math" alttext="{}^{\mbox{3}}" display="inline"><semantics id="bib.bib53.1.m1.1a"><msup id="bib.bib53.1.m1.1.1" xref="bib.bib53.1.m1.1.1.cmml"><mi id="bib.bib53.1.m1.1.1a" xref="bib.bib53.1.m1.1.1.cmml"></mi><mtext id="bib.bib53.1.m1.1.1.1" xref="bib.bib53.1.m1.1.1.1a.cmml">3</mtext></msup><annotation-xml encoding="MathML-Content" id="bib.bib53.1.m1.1b"><apply id="bib.bib53.1.m1.1.1.cmml" xref="bib.bib53.1.m1.1.1"><ci id="bib.bib53.1.m1.1.1.1a.cmml" xref="bib.bib53.1.m1.1.1.1"><mtext mathsize="70%" id="bib.bib53.1.m1.1.1.1.cmml" xref="bib.bib53.1.m1.1.1.1">3</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="bib.bib53.1.m1.1c">{}^{\mbox{3}}</annotation></semantics></math>: A mixed protocol framework
for machine learning,” in <em id="bib.bib53.2.1" class="ltx_emph ltx_font_italic">Proc. of the 2018 ACM SIGSAC Conf. on
Computer and Commn. Security, CCS</em>, 2018, pp. 35–52.

</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[54]</span>
<span class="ltx_bibblock">
A. Hard, K. Rao, R. Mathews, S. Ramaswamy, F. Beaufays, S. Augenstein,
H. Eichner, C. Kiddon, and D. Ramage, “Federated learning for mobile
keyboard prediction,” <em id="bib.bib54.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1811.03604</em>, 2018.

</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[55]</span>
<span class="ltx_bibblock">
D. Leroy, A. Coucke, T. Lavril, T. Gisselbrecht, and J. Dureau, “Federated
learning for keyword spotting,” in <em id="bib.bib55.1.1" class="ltx_emph ltx_font_italic">ICASSP 2019-2019 IEEE International
Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>.   IEEE, 2019, pp. 6341–6345.

</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[56]</span>
<span class="ltx_bibblock">
D. Gao, C. Ju, X. Wei, Y. Liu, T. Chen, and Q. Yang, “Hhhfl: Hierarchical
heterogeneous horizontal federated learning for electroencephalography,”
<em id="bib.bib56.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1909.05784v3</em>, 2019.

</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[57]</span>
<span class="ltx_bibblock">
H. Wang, M. Yurochkin, Y. Sun, D. Papailiopoulos, and Y. Khazaeni, “Federated
learning with matched averaging,” in <em id="bib.bib57.1.1" class="ltx_emph ltx_font_italic">ICLR</em>, 2020, pp. 1–16.

</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[58]</span>
<span class="ltx_bibblock">
Y. Jiang, J. Konečný, K. Rush, and S. Kannan, “Improving federated learning
personalization via model agnostic meta learning,” 2019. [Online].
Available: <span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://arxiv.org/abs/1909.12488</span>

</span>
</li>
<li id="bib.bib59" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[59]</span>
<span class="ltx_bibblock">
N. Shoham, T. Avidor, A. Keren, N. Israel, D. Benditkis, L. Mor-Yosef, and
I. Zeitak, “Overcoming forgetting in federated learning on non-iid data,”
2019.

</span>
</li>
<li id="bib.bib60" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[60]</span>
<span class="ltx_bibblock">
M. Nasr, R. Shokri, and A. Houmansadr, “Comprehensive privacy analysis of deep
learning: Passive and active white-box inference attacks against centralized
and federated learning,” in <em id="bib.bib60.1.1" class="ltx_emph ltx_font_italic">2019 IEEE Symposium on Security and
Privacy (SP)</em>.   IEEE, 2019, pp.
739–753.

</span>
</li>
<li id="bib.bib61" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[61]</span>
<span class="ltx_bibblock">
E. Bagdasaryan, A. Veit, Y. Hua, D. Estrin, and V. Shmatikov, “How to backdoor
federated learning,” 2018. [Online]. Available:
<span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://arxiv.org/abs/1807.00459</span>

</span>
</li>
<li id="bib.bib62" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[62]</span>
<span class="ltx_bibblock">
B. Wang, Y. Yao, S. Shan, H. Li, B. Viswanath, H. Zheng, and B. Y. Zhao,
“Neural cleanse: Identifying and mitigating backdoor attacks in neural
networks,” in <em id="bib.bib62.1.1" class="ltx_emph ltx_font_italic">2019 IEEE Symposium on Security and Privacy (SP)</em>.   IEEE, 2019, pp. 707–723.

</span>
</li>
<li id="bib.bib63" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[63]</span>
<span class="ltx_bibblock">
Y. Gao, C. Xu, D. Wang, S. Chen, D. C. Ranasinghe, and S. Nepal, “Strip: A
defence against trojan attacks on deep neural networks,” in <em id="bib.bib63.1.1" class="ltx_emph ltx_font_italic">Proc. of
the 35th Annual Computer Security Applications Conference</em>, 2019, pp.
113–125.

</span>
</li>
<li id="bib.bib64" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[64]</span>
<span class="ltx_bibblock">
L. Zhao, S. Hu, Q. Wang, J. Jiang, S. Chao, X. Luo, and P. Hu, “Shielding
collaborative learning: Mitigating poisoning attacks through client-side
detection,” <em id="bib.bib64.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Dependable and Secure Computing</em>,
2020.

</span>
</li>
<li id="bib.bib65" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[65]</span>
<span class="ltx_bibblock">
C. Gentry, “A fully homomorphic encryption scheme,” Ph.D. dissertation,
Stanford University, Stanford, California, Sept. 2009.

</span>
</li>
<li id="bib.bib66" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[66]</span>
<span class="ltx_bibblock">
C. Dwork and A. Roth, “The algorithmic foundations of differential privacy,”
<em id="bib.bib66.1.1" class="ltx_emph ltx_font_italic">Foundations and Trends in Theoretical Computer Science</em>, vol. 9, no.
3-4, pp. 211–407, 2014.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<section id="A1" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Supplemental results</h2>

<section id="A1.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.1 </span><span id="A1.SS1.1.1" class="ltx_text ltx_font_italic">Performance of THEMISb (considering email’s body only) in the centralized and federated learning with two, five, and ten clients.</span>
</h3>

<figure id="A1.F13" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="A1.F13.1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2007.13300/assets/x31.png" id="A1.F13.1.g1" class="ltx_graphics ltx_img_landscape" width="465" height="322" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="A1.F13.2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2007.13300/assets/x32.png" id="A1.F13.2.g1" class="ltx_graphics ltx_img_landscape" width="465" height="322" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="A1.F13.3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2007.13300/assets/x33.png" id="A1.F13.3.g1" class="ltx_graphics ltx_img_landscape" width="597" height="140" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="A1.F13.4" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2007.13300/assets/x34.png" id="A1.F13.4.g1" class="ltx_graphics ltx_img_landscape" width="597" height="120" alt="Refer to caption">
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 13: </span>Results of the THEMISb model: Convergence curves of average testing accuracy for the (a) local models and (b) global model considering body only of email samples. Corresponding performance metrics of the testing results at the global epoch of 45 in centralized and federated learning (FL) with two, five, and ten clients are depicted in (c) and (d).
</figcaption>
</figure>
</section>
<section id="A1.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.2 </span><span id="A1.SS2.1.1" class="ltx_text ltx_font_italic">Client-level performance of the THEMIS model</span>
</h3>

<figure id="A1.F14" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="A1.F14.1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2007.13300/assets/x35.png" id="A1.F14.1.g1" class="ltx_graphics ltx_img_landscape" width="465" height="261" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="A1.F14.2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2007.13300/assets/x36.png" id="A1.F14.2.g1" class="ltx_graphics ltx_img_landscape" width="465" height="260" alt="Refer to caption">
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 14: </span>Experiment 1: Convergence curves of (a) global testing accuracy and (b) local testing accuracy from the Experiment 1 with five clients and <math id="A1.F14.4.m1.1" class="ltx_Math" alttext="\mathsf{var}=0" display="inline"><semantics id="A1.F14.4.m1.1b"><mrow id="A1.F14.4.m1.1.1" xref="A1.F14.4.m1.1.1.cmml"><mi id="A1.F14.4.m1.1.1.2" xref="A1.F14.4.m1.1.1.2.cmml">𝗏𝖺𝗋</mi><mo id="A1.F14.4.m1.1.1.1" xref="A1.F14.4.m1.1.1.1.cmml">=</mo><mn id="A1.F14.4.m1.1.1.3" xref="A1.F14.4.m1.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.F14.4.m1.1c"><apply id="A1.F14.4.m1.1.1.cmml" xref="A1.F14.4.m1.1.1"><eq id="A1.F14.4.m1.1.1.1.cmml" xref="A1.F14.4.m1.1.1.1"></eq><ci id="A1.F14.4.m1.1.1.2.cmml" xref="A1.F14.4.m1.1.1.2">𝗏𝖺𝗋</ci><cn type="integer" id="A1.F14.4.m1.1.1.3.cmml" xref="A1.F14.4.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.F14.4.m1.1d">\mathsf{var}=0</annotation></semantics></math>. The first four clients train the model until 15 global epochs, and then (only) the fifth client trains the model.</figcaption>
</figure>
<figure id="A1.F15" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="A1.F15.1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2007.13300/assets/x37.png" id="A1.F15.1.g1" class="ltx_graphics ltx_img_landscape" width="465" height="245" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="A1.F15.2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2007.13300/assets/x38.png" id="A1.F15.2.g1" class="ltx_graphics ltx_img_landscape" width="465" height="247" alt="Refer to caption">
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 15: </span>Experiment 2: Convergence curves of (a) global testing accuracy and (b) local testing accuracy from the Experiment 2 with five clients and <math id="A1.F15.4.m1.1" class="ltx_Math" alttext="\mathsf{var}=80" display="inline"><semantics id="A1.F15.4.m1.1b"><mrow id="A1.F15.4.m1.1.1" xref="A1.F15.4.m1.1.1.cmml"><mi id="A1.F15.4.m1.1.1.2" xref="A1.F15.4.m1.1.1.2.cmml">𝗏𝖺𝗋</mi><mo id="A1.F15.4.m1.1.1.1" xref="A1.F15.4.m1.1.1.1.cmml">=</mo><mn id="A1.F15.4.m1.1.1.3" xref="A1.F15.4.m1.1.1.3.cmml">80</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.F15.4.m1.1c"><apply id="A1.F15.4.m1.1.1.cmml" xref="A1.F15.4.m1.1.1"><eq id="A1.F15.4.m1.1.1.1.cmml" xref="A1.F15.4.m1.1.1.1"></eq><ci id="A1.F15.4.m1.1.1.2.cmml" xref="A1.F15.4.m1.1.1.2">𝗏𝖺𝗋</ci><cn type="integer" id="A1.F15.4.m1.1.1.3.cmml" xref="A1.F15.4.m1.1.1.3">80</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.F15.4.m1.1d">\mathsf{var}=80</annotation></semantics></math>. The FL training starts with one client, i.e., client 1, and a new client joins the training at every 10-th global epochs in a sequence from client 2 to client 5.</figcaption>
</figure>
<figure id="A1.F16" class="ltx_figure"><img src="/html/2007.13300/assets/x39.png" id="A1.F16.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="465" height="247" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 16: </span>Experiment 3: Convergence curves of the (local) testing accuracy for the client 1 with and without leveraging FL. The dataset of client 1 is based on <math id="A1.F16.2.m1.1" class="ltx_Math" alttext="\mathsf{var}=0" display="inline"><semantics id="A1.F16.2.m1.1b"><mrow id="A1.F16.2.m1.1.1" xref="A1.F16.2.m1.1.1.cmml"><mi id="A1.F16.2.m1.1.1.2" xref="A1.F16.2.m1.1.1.2.cmml">𝗏𝖺𝗋</mi><mo id="A1.F16.2.m1.1.1.1" xref="A1.F16.2.m1.1.1.1.cmml">=</mo><mn id="A1.F16.2.m1.1.1.3" xref="A1.F16.2.m1.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.F16.2.m1.1c"><apply id="A1.F16.2.m1.1.1.cmml" xref="A1.F16.2.m1.1.1"><eq id="A1.F16.2.m1.1.1.1.cmml" xref="A1.F16.2.m1.1.1.1"></eq><ci id="A1.F16.2.m1.1.1.2.cmml" xref="A1.F16.2.m1.1.1.2">𝗏𝖺𝗋</ci><cn type="integer" id="A1.F16.2.m1.1.1.3.cmml" xref="A1.F16.2.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.F16.2.m1.1d">\mathsf{var}=0</annotation></semantics></math> among five clients.</figcaption>
</figure>
</section>
<section id="A1.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.3 </span><span id="A1.SS3.1.1" class="ltx_text ltx_font_italic">THEMIS performance over two clients with a data size variations in the dataset</span>
</h3>

<figure id="A1.F17" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="A1.F17.1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2007.13300/assets/x40.png" id="A1.F17.1.g1" class="ltx_graphics ltx_img_landscape" width="465" height="302" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="A1.F17.2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2007.13300/assets/x41.png" id="A1.F17.2.g1" class="ltx_graphics ltx_img_landscape" width="465" height="303" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="A1.F17.3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2007.13300/assets/x42.png" id="A1.F17.3.g1" class="ltx_graphics ltx_img_landscape" width="597" height="127" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="A1.F17.4" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2007.13300/assets/x43.png" id="A1.F17.4.g1" class="ltx_graphics ltx_img_landscape" width="597" height="111" alt="Refer to caption">
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 17: </span>Showing the impact of different local data sizes provided by different <math id="A1.F17.6.m1.1" class="ltx_Math" alttext="\mathsf{var}" display="inline"><semantics id="A1.F17.6.m1.1b"><mi id="A1.F17.6.m1.1.1" xref="A1.F17.6.m1.1.1.cmml">𝗏𝖺𝗋</mi><annotation-xml encoding="MathML-Content" id="A1.F17.6.m1.1c"><ci id="A1.F17.6.m1.1.1.cmml" xref="A1.F17.6.m1.1.1">𝗏𝖺𝗋</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.F17.6.m1.1d">\mathsf{var}</annotation></semantics></math> among clients to their convergence in FL with two clients on testing accuracy curves of the (a) local model, and (b) global model. Corresponding performance metrics of the testing results at the global epoch of 45 in centralized and federated learning (FL) with ten clients are depicted in (c) and (d).</figcaption>
</figure>
</section>
<section id="A1.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.4 </span><span id="A1.SS4.1.1" class="ltx_text ltx_font_italic">THEMIS performance over ten clients with the phishing to legitimate email samples ratio variations in the dataset</span>
</h3>

<figure id="A1.F18" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="A1.F18.1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2007.13300/assets/x44.png" id="A1.F18.1.g1" class="ltx_graphics ltx_img_landscape" width="465" height="341" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="A1.F18.2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2007.13300/assets/x45.png" id="A1.F18.2.g1" class="ltx_graphics ltx_img_landscape" width="465" height="341" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="A1.F18.3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2007.13300/assets/x46.png" id="A1.F18.3.g1" class="ltx_graphics ltx_img_landscape" width="631" height="112" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="A1.F18.4" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2007.13300/assets/x47.png" id="A1.F18.4.g1" class="ltx_graphics ltx_img_landscape" width="631" height="94" alt="Refer to caption">
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 18: </span>Showing the impact of different legit email to phishing email samples ratios in the local dataset to their convergence in FL with ten clients on testing accuracy curves of the (a) local model and (b) global model. Corresponding performance metrics of the testing results at the global epoch of 45 in centralized and federated learning (FL) with ten clients are depicted in (c) and (d).</figcaption>
</figure>
</section>
<section id="A1.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.5 </span><span id="A1.SS5.1.1" class="ltx_text ltx_font_italic">Distributed email learning under an extreme asymmetric data distribution with THEMIS (considering both email’s header and body information)</span>
</h3>

<figure id="A1.F19" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="A1.F19.1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2007.13300/assets/x48.png" id="A1.F19.1.g1" class="ltx_graphics ltx_img_landscape" width="465" height="252" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="A1.F19.2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2007.13300/assets/x49.png" id="A1.F19.2.g1" class="ltx_graphics ltx_img_landscape" width="465" height="252" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="A1.F19.3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2007.13300/assets/x50.png" id="A1.F19.3.g1" class="ltx_graphics ltx_img_landscape" width="465" height="248" alt="Refer to caption">
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 19: </span>THEMIS model with five clients: Client-level convergence curves of (a) testing accuracy of the local model, (b) testing accuracy of the global model, and (c) training accuracy.</figcaption>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2007.13299" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2007.13300" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2007.13300">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2007.13300" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2007.13302" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Thu Mar 14 12:47:56 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
