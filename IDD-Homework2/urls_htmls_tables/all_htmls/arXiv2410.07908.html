<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>ONCOPILOT: A Promptable CT Foundation Model For Solid Tumor Evaluation</title>
<!--Generated on Fri Oct 11 07:15:16 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2410.07908v2/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.07908v2#S1" title="In ONCOPILOT: A Promptable CT Foundation Model For Solid Tumor Evaluation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.07908v2#S2" title="In ONCOPILOT: A Promptable CT Foundation Model For Solid Tumor Evaluation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Materials and Methods</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.07908v2#S2.SS1" title="In 2 Materials and Methods ‚Ä£ ONCOPILOT: A Promptable CT Foundation Model For Solid Tumor Evaluation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>Foundation Model</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.07908v2#S2.SS2" title="In 2 Materials and Methods ‚Ä£ ONCOPILOT: A Promptable CT Foundation Model For Solid Tumor Evaluation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>Evaluation criteria of ONCOPILOT‚Äôs performances</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.07908v2#S2.SS3" title="In 2 Materials and Methods ‚Ä£ ONCOPILOT: A Promptable CT Foundation Model For Solid Tumor Evaluation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.3 </span>Baseline</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.07908v2#S2.SS4" title="In 2 Materials and Methods ‚Ä£ ONCOPILOT: A Promptable CT Foundation Model For Solid Tumor Evaluation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.4 </span>Datasets</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.07908v2#S2.SS5" title="In 2 Materials and Methods ‚Ä£ ONCOPILOT: A Promptable CT Foundation Model For Solid Tumor Evaluation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.5 </span>Segmentation Process</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.07908v2#S2.SS6" title="In 2 Materials and Methods ‚Ä£ ONCOPILOT: A Promptable CT Foundation Model For Solid Tumor Evaluation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.6 </span>Morphology Analysis</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.07908v2#S2.SS7" title="In 2 Materials and Methods ‚Ä£ ONCOPILOT: A Promptable CT Foundation Model For Solid Tumor Evaluation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.7 </span>RECIST Measurement</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.07908v2#S2.SS8" title="In 2 Materials and Methods ‚Ä£ ONCOPILOT: A Promptable CT Foundation Model For Solid Tumor Evaluation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.8 </span>ONCOPILOT integration into radiologist‚Äôs workflow</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.07908v2#S3" title="In ONCOPILOT: A Promptable CT Foundation Model For Solid Tumor Evaluation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Results</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.07908v2#S3.SS1" title="In 3 Results ‚Ä£ ONCOPILOT: A Promptable CT Foundation Model For Solid Tumor Evaluation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Foundation Model</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.07908v2#S3.SS2" title="In 3 Results ‚Ä£ ONCOPILOT: A Promptable CT Foundation Model For Solid Tumor Evaluation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Segmentation Performance</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.07908v2#S3.SS3" title="In 3 Results ‚Ä£ ONCOPILOT: A Promptable CT Foundation Model For Solid Tumor Evaluation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>Morphology Analysis</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.07908v2#S3.SS4" title="In 3 Results ‚Ä£ ONCOPILOT: A Promptable CT Foundation Model For Solid Tumor Evaluation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.4 </span>ONCOPILOT Evaluation Against Radiologists</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.07908v2#S3.SS5" title="In 3 Results ‚Ä£ ONCOPILOT: A Promptable CT Foundation Model For Solid Tumor Evaluation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.5 </span>ONCOPILOT Integration into Radiologist‚Äôs Workflow</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.07908v2#S4" title="In ONCOPILOT: A Promptable CT Foundation Model For Solid Tumor Evaluation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Discussion</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">ONCOPILOT: A Promptable CT Foundation Model For Solid Tumor Evaluation</h1>
<div class="ltx_logical-block" id="id1">
<div class="ltx_para" id="id1.p1">
<p class="ltx_p ltx_align_center" id="id1.p1.1"><span class="ltx_text ltx_font_bold" id="id1.p1.1.1">Author Contributions</span></p>
<p class="ltx_p ltx_align_center" id="id1.p1.2"><span class="ltx_text ltx_font_bold" id="id1.p1.2.1">Direct contribution</span>: L. Machado<sup class="ltx_sup" id="id1.p1.2.2">1</sup>, H. Philippe<sup class="ltx_sup" id="id1.p1.2.3">1,2</sup>, E. Ferreres<sup class="ltx_sup" id="id1.p1.2.4">1</sup>, J. Khlaut<sup class="ltx_sup" id="id1.p1.2.5">1</sup>, J. Dupuis<sup class="ltx_sup" id="id1.p1.2.6">1</sup>, K. Le Floch<sup class="ltx_sup" id="id1.p1.2.7">1</sup>, D. Habip Gatenyo<sup class="ltx_sup" id="id1.p1.2.8">1</sup></p>
<p class="ltx_p ltx_align_center" id="id1.p1.3"><span class="ltx_text ltx_font_bold" id="id1.p1.3.1">Senior contribution</span>: P. Roux<sup class="ltx_sup" id="id1.p1.3.2">3</sup>, J. Gr√©gory<sup class="ltx_sup" id="id1.p1.3.3">2</sup>, M. Ronot<sup class="ltx_sup" id="id1.p1.3.4">2</sup>, C. Dancette<sup class="ltx_sup" id="id1.p1.3.5">1</sup>, D. Tordjman<sup class="ltx_sup" id="id1.p1.3.6">1</sup>, P. Manceron<sup class="ltx_sup" id="id1.p1.3.7">1</sup>, P. H√©rent<sup class="ltx_sup" id="id1.p1.3.8">1,3</sup></p>
<p class="ltx_p ltx_align_center" id="id1.p1.4"><sup class="ltx_sup" id="id1.p1.4.1"><span class="ltx_text" id="id1.p1.4.1.1" style="font-size:90%;">1</span></sup><span class="ltx_text" id="id1.p1.4.2" style="font-size:90%;">Raidium, Paris Biotech Sant√©, Paris, France 
<br class="ltx_break"/><sup class="ltx_sup" id="id1.p1.4.2.1">2</sup>H√¥pital Beaujon, APHP.Nord, Clichy, France 
<br class="ltx_break"/><sup class="ltx_sup" id="id1.p1.4.2.2">3</sup>Centre d‚ÄôImagerie du Nord, Saint-Denis, France
</span></p>
</div>
</div>
<div class="ltx_para ltx_noindent ltx_align_center" id="id2.p1">
<p class="ltx_p" id="id2.p1.1"><span class="ltx_rule" style="width:346.9pt;height:0.4pt;background:black;display:inline-block;">¬†</span></p>
</div>
<div class="ltx_para" id="p1">
<p class="ltx_p ltx_align_center" id="p1.1"><span class="ltx_text ltx_font_bold" id="p1.1.1" style="font-size:144%;">Abstract</span></p>
</div>
<div class="ltx_para" id="p2">
<p class="ltx_p" id="p2.1">Carcinogenesis is a proteiform phenomenon that can lead to metastatic spread, with tumors emerging in various locations and displaying complex, diverse shapes. As a crucial focus at the intersection of research and clinical practice, it demands precise and flexible assessment. However, current biomarkers, such as RECIST 1.1‚Äôs long and short axis measurements, fall short of capturing this complexity, offering an only approximate estimate of tumor burden and an overly simplistic representation of a far more intricate process.</p>
</div>
<div class="ltx_para" id="p3">
<p class="ltx_p" id="p3.1">Additionally, existing supervised AI models face challenges in adequately addressing the variability in tumor presentations, which limits their clinical utility. These limitations arise from the scarcity of annotations and the models‚Äô focus on narrowly defined tasks.</p>
</div>
<div class="ltx_para" id="p4">
<p class="ltx_p" id="p4.1">To address these challenges, we developed <span class="ltx_text ltx_font_bold" id="p4.1.1">ONCOPILOT</span>, an interactive radiological foundation model trained on approximately 7,500 CT scans covering the whole body, from both normal anatomy and a wide range of oncological cases. ONCOPILOT performs 3D tumor segmentation using visual prompts like point-click and bounding boxes, outperforming state-of-the-art models (e.g., nnUnet-based) and achieving radiologist-level accuracy in RECIST 1.1 measurements. The key advantage of this foundation model is its ability to surpass state-of-the-art performance while keeping the radiologist in the loop, a capability that previous models could not achieve. When radiologists interactively refine the segmentations, accuracy improves even further. ONCOPILOT also accelerates measurement processes and reduces inter-reader variability. Moreover, it facilitates volumetric analysis, unlocking new biomarkers for deeper insights.</p>
</div>
<div class="ltx_para" id="p5">
<p class="ltx_p" id="p5.1">This AI assistant is expected to enhance the precision of RECIST 1.1 measurements, unlock the potential of volumetric biomarkers, and improve patient stratification and clinical care, while seamlessly integrating into the radiological workflow.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">The wide variability in tumor appearance and location makes precise monitoring of oncological disease a critical challenge for both clinical care and research. Effective evaluation of oncological disease is essential for accurately assessing tumor aggressiveness, predicting prognosis, and guiding treatment decisions.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">The Response Evaluation Criteria in Solid Tumors (RECIST v1.1) has long been regarded as the gold standard for radiologically assessing solid tumors over time <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.07908v2#bib.bib1" title="">1</a>]</cite>, allowing for patient stratification based on disease response or progression. However, this method has significant limitations: the low information yield from linear long axis measurement in comparison to total tumor burden <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.07908v2#bib.bib2" title="">2</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.07908v2#bib.bib3" title="">3</a>]</cite>, the arbitrary and non-reproducible selection of target lesions, which can result in the misclassification of disease status <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.07908v2#bib.bib4" title="">4</a>]</cite> and significant inaccuracies in measuring the long axis, with inter-reader variability exceeding 20% <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.07908v2#bib.bib5" title="">5</a>]</cite>, further contributing to classification errors.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">Traditionally, the long and short axes of the tumor are used as widely accepted proxies for estimating tumor size on CT scans. However, in the era of quantitative imaging, these linear measurements are increasingly considered inadequate as the field shifts toward more informative quantitative markers, such as volumetry <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.07908v2#bib.bib6" title="">6</a>]</cite> and shape assessments, including tumor eccentricity and irregularity <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.07908v2#bib.bib7" title="">7</a>]</cite>. Volumetric analysis, more sensitive to change than diameter due to its proportionality to the cube of the radius, is proving advantageous in detecting tumor burden changes, especially for tumors with irregular shapes, where linear measurements fail to capture their complexity <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.07908v2#bib.bib8" title="">8</a>]</cite>. Recently, novel radiomics biomarkers derived from volumetric analysis have shown significant promise in oncological evaluation, notably in colon and lung cancers <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.07908v2#bib.bib9" title="">9</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.07908v2#bib.bib10" title="">10</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">Despite its promise, volumetric measurement is time-consuming <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.07908v2#bib.bib11" title="">11</a>]</cite> and impractical to perform manually. While efforts have been made to automate the volumetric delineation of oncological lesions, from early models relying on manual feature extraction to approaches using deep learning with convolutional neural networks <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.07908v2#bib.bib12" title="">12</a>]</cite>, these models remain limited. Most are organ-specific, and the solutions currently employed in clinical practice are effective primarily in straightforward cases, such as lung nodules, but struggle with the diverse appearances of metastatic lesions. Furthermore, these methods often lack interactivity and adaptability to varying inputs, which restricts their integration into the radiological workflow.</p>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">The emergence of foundation models, a paradigm shift in deep learning, could alleviate these issues. Powered by transformer architecture and self-attention mechanisms <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.07908v2#bib.bib13" title="">13</a>]</cite>, foundation models, when trained on extensive datasets, can significantly outperform traditional deep-learning systems <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.07908v2#bib.bib14" title="">14</a>]</cite>. Their key strengths lie in transfer learning and zero-shot classification, enabling them to handle tasks not encountered during initial training‚Äîcapabilities that traditional deep-learning models lack.</p>
</div>
<div class="ltx_para" id="S1.p6">
<p class="ltx_p" id="S1.p6.1">Recently, these models have been positioned as the future of medical imaging, offering potential solutions to critical challenges such as poor generalization and the need for large quantities of labeled training data <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.07908v2#bib.bib15" title="">15</a>]</cite>. Notably, they can generate reliable segmentation masks using text or visual prompts (e.g., actions taken on the images by the user), such as bounding boxes or point-click inputs on regions of interest <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.07908v2#bib.bib16" title="">16</a>]</cite>. The ability to dynamically refine segmentation masks and generate varying outcomes from different visual prompts is a crucial step toward explainable AI, addressing the opaque nature of traditional models, and making it usable for radiologists.</p>
</div>
<div class="ltx_para" id="S1.p7">
<p class="ltx_p" id="S1.p7.1">In response to these advancements, we developed ONCOPILOT, an interactive foundation model trained using publicly available CT scans of normal anatomy and more than 7,500 tumors from diverse organs. Our model aims to deliver precise and reproducible RECIST measurements and to facilitate the volumetric analysis of oncologic lesions within an interactive viewer. We evaluated ONCOPILOT against a panel of radiologists and investigated the potential for integrating this AI assistant into the radiologist‚Äôs workflow.</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Materials and Methods</h2>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Foundation Model</h3>
<div class="ltx_para" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.1">ONCOPILOT is a foundation model adapted from SAM <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.07908v2#bib.bib16" title="">16</a>]</cite>, specifically aiming to segment biomedical images. Such an approach has been concomitantly adopted in the literature in the form of MedSAM <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.07908v2#bib.bib17" title="">17</a>]</cite>, SegVol <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.07908v2#bib.bib18" title="">18</a>]</cite>, and SAM-Med3D <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.07908v2#bib.bib19" title="">19</a>]</cite>. This model is trained to perform image segmentation tasks. It processes 2D images and prompts, such as a bounding box, a point, or a mask. The model aims to generate a 3D prediction of the volume of a specific anatomical structure based on the input image and visual prompt. From the initial slice 2D segmentation masks are propagated sequentially across the z-axis until they encounter the boundaries of the object. Alternatively, the propagation can be halted based on predefined stopping criteria once specific conditions are met. The result of this propagation is a 3D segmentation mask.</p>
</div>
<div class="ltx_para" id="S2.SS1.p2">
<p class="ltx_p" id="S2.SS1.p2.1">The model is initialized with the released weights of the SAM model <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.07908v2#bib.bib16" title="">16</a>]</cite> and trained in a supervised manner with an initial general pre-training on normal anatomy and oncological lesions followed by a specialization on oncological lesions with a focused fine-tuning on tumors only. The initial training took 40 hours on 32 V100 Nvidia GPUs (totaling 1280 GPU hours) with a learning rate of <math alttext="10^{-5}" class="ltx_Math" display="inline" id="S2.SS1.p2.1.m1.1"><semantics id="S2.SS1.p2.1.m1.1a"><msup id="S2.SS1.p2.1.m1.1.1" xref="S2.SS1.p2.1.m1.1.1.cmml"><mn id="S2.SS1.p2.1.m1.1.1.2" xref="S2.SS1.p2.1.m1.1.1.2.cmml">10</mn><mrow id="S2.SS1.p2.1.m1.1.1.3" xref="S2.SS1.p2.1.m1.1.1.3.cmml"><mo id="S2.SS1.p2.1.m1.1.1.3a" xref="S2.SS1.p2.1.m1.1.1.3.cmml">‚àí</mo><mn id="S2.SS1.p2.1.m1.1.1.3.2" xref="S2.SS1.p2.1.m1.1.1.3.2.cmml">5</mn></mrow></msup><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.1.m1.1b"><apply id="S2.SS1.p2.1.m1.1.1.cmml" xref="S2.SS1.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S2.SS1.p2.1.m1.1.1.1.cmml" xref="S2.SS1.p2.1.m1.1.1">superscript</csymbol><cn id="S2.SS1.p2.1.m1.1.1.2.cmml" type="integer" xref="S2.SS1.p2.1.m1.1.1.2">10</cn><apply id="S2.SS1.p2.1.m1.1.1.3.cmml" xref="S2.SS1.p2.1.m1.1.1.3"><minus id="S2.SS1.p2.1.m1.1.1.3.1.cmml" xref="S2.SS1.p2.1.m1.1.1.3"></minus><cn id="S2.SS1.p2.1.m1.1.1.3.2.cmml" type="integer" xref="S2.SS1.p2.1.m1.1.1.3.2">5</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.1.m1.1c">10^{-5}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p2.1.m1.1d">10 start_POSTSUPERSCRIPT - 5 end_POSTSUPERSCRIPT</annotation></semantics></math>. The fine-tuning took 10 hours on a Nvidia 4090 GPU.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Evaluation criteria of ONCOPILOT‚Äôs performances</h3>
<div class="ltx_para" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.1">To assess the effectiveness of our model, three parameters are taken into account:</p>
</div>
<div class="ltx_para" id="S2.SS2.p2">
<p class="ltx_p" id="S2.SS2.p2.1"><span class="ltx_text ltx_font_bold" id="S2.SS2.p2.1.1">Segmentation performance</span>: Measured using the DICE score, a standard metric for evaluating segmentation quality. The performance of ONCOPILOT is compared to that of a state-of-the-art model, see section <span class="ltx_text ltx_font_italic" id="S2.SS2.p2.1.2">Baseline</span>.</p>
</div>
<div class="ltx_para" id="S2.SS2.p3">
<p class="ltx_p" id="S2.SS2.p3.1"><span class="ltx_text ltx_font_bold" id="S2.SS2.p3.1.1">Long axis measurement performance</span>: Evaluated using the absolute error and inter-operator variability as metrics. For more details, see section <span class="ltx_text ltx_font_italic" id="S2.SS2.p3.1.2">RECIST measurement and ONCOPILOT evaluation against radiologists</span>.</p>
</div>
<div class="ltx_para" id="S2.SS2.p4">
<p class="ltx_p" id="S2.SS2.p4.1"><span class="ltx_text ltx_font_bold" id="S2.SS2.p4.1.1">Radiologist‚Äôs time efficiency and precision</span>: The average time a radiologist takes to complete one measurement and the inter-reader variability serve as metrics for evaluating the integration of the model into a radiologist‚Äôs workflow. For further information, see section <span class="ltx_text ltx_font_italic" id="S2.SS2.p4.1.2">ONCOPILOT integration into radiologist‚Äôs workflow</span>.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Baseline</h3>
<div class="ltx_para" id="S2.SS3.p1">
<p class="ltx_p" id="S2.SS3.p1.1">To compare the performance of our foundation model to state-of-the-art segmentation models we used the model provided by the ULS23 oncological lesion segmentation challenge as a baseline <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.07908v2#bib.bib20" title="">20</a>]</cite>. We used the result of their full model (nnUnet-ResEnc+SS) on the 10% held-out test set originating from their fully-labeled dataset. This model is based on the nnUnet architecture <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.07908v2#bib.bib21" title="">21</a>]</cite> and has been trained and fine-tuned on a dataset of 38,693 lesions including fully-labeled and partially-labeled tumor masks.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.4 </span>Datasets</h3>
<div class="ltx_para" id="S2.SS4.p1">
<p class="ltx_p" id="S2.SS4.p1.3">ONCOPILOT was pre-trained on publicly available datasets containing medical images and segmentation masks for general anatomy and oncological lesions:</p>
<ul class="ltx_itemize" id="S2.I1">
<li class="ltx_item" id="S2.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span>
<div class="ltx_para" id="S2.I1.i1.p1">
<p class="ltx_p" id="S2.I1.i1.p1.1">1204 CT scans from TotalSegmentator v1 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.07908v2#bib.bib22" title="">22</a>]</cite>, with 104 labeled anatomical structures (27 organs, 59 bones, 10 muscles, 8 vessels).</p>
</div>
</li>
<li class="ltx_item" id="S2.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span>
<div class="ltx_para" id="S2.I1.i2.p1">
<p class="ltx_p" id="S2.I1.i2.p1.1">743 diverse tumors from the DeepLesion dataset <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.07908v2#bib.bib23" title="">23</a>]</cite>, curated and segmented for the ULS23 challenge <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.07908v2#bib.bib20" title="">20</a>]</cite>, referred to as ULS23 DeepLesion.</p>
</div>
</li>
<li class="ltx_item" id="S2.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span>
<div class="ltx_para" id="S2.I1.i3.p1">
<p class="ltx_p" id="S2.I1.i3.p1.1">697 bone oncological lesions and 120 pancreatic tumors from the Radboudumc hospital, available through the ULS23 dataset <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.07908v2#bib.bib20" title="">20</a>]</cite>.</p>
</div>
</li>
<li class="ltx_item" id="S2.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span>
<div class="ltx_para" id="S2.I1.i4.p1">
<p class="ltx_p" id="S2.I1.i4.p1.1">470 volumes from the multimodal MSD challenge <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.07908v2#bib.bib24" title="">24</a>]</cite>, using only the Lung, Colon, Pancreas datasets.</p>
</div>
</li>
<li class="ltx_item" id="S2.I1.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span>
<div class="ltx_para" id="S2.I1.i5.p1">
<p class="ltx_p" id="S2.I1.i5.p1.1">700 lung nodules from the LNDb dataset <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.07908v2#bib.bib25" title="">25</a>]</cite>.</p>
</div>
</li>
<li class="ltx_item" id="S2.I1.i6" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span>
<div class="ltx_para" id="S2.I1.i6.p1">
<p class="ltx_p" id="S2.I1.i6.p1.1">300 kidney tumors from the KITS23 dataset <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.07908v2#bib.bib26" title="">26</a>]</cite>.</p>
</div>
</li>
<li class="ltx_item" id="S2.I1.i7" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span>
<div class="ltx_para" id="S2.I1.i7.p1">
<p class="ltx_p" id="S2.I1.i7.p1.1">832 liver tumors from the LiTS dataset <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.07908v2#bib.bib27" title="">27</a>]</cite>, also part of the MSD challenge.</p>
</div>
</li>
<li class="ltx_item" id="S2.I1.i8" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span>
<div class="ltx_para" id="S2.I1.i8.p1">
<p class="ltx_p" id="S2.I1.i8.p1.1">932 mediastinal and abdominal lymph nodes from the NIH-LN dataset <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.07908v2#bib.bib28" title="">28</a>]</cite>.</p>
</div>
</li>
<li class="ltx_item" id="S2.I1.i9" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span>
<div class="ltx_para" id="S2.I1.i9.p1">
<p class="ltx_p" id="S2.I1.i9.p1.1">2236 lung oncological lesions from the LIDC-IDRI dataset <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.07908v2#bib.bib29" title="">29</a>]</cite>.</p>
</div>
</li>
</ul>
<p class="ltx_p" id="S2.SS4.p1.2">A random 90% training set was selected, with a 10% held-out test dataset, by analogy with the ULS23 challenge. A randomly selected set of 67 tumors <math alttext="\geq" class="ltx_Math" display="inline" id="S2.SS4.p1.1.m1.1"><semantics id="S2.SS4.p1.1.m1.1a"><mo id="S2.SS4.p1.1.m1.1.1" xref="S2.SS4.p1.1.m1.1.1.cmml">‚â•</mo><annotation-xml encoding="MathML-Content" id="S2.SS4.p1.1.m1.1b"><geq id="S2.SS4.p1.1.m1.1.1.cmml" xref="S2.SS4.p1.1.m1.1.1"></geq></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p1.1.m1.1c">\geq</annotation><annotation encoding="application/x-llamapun" id="S2.SS4.p1.1.m1.1d">‚â•</annotation></semantics></math> 10 mm in size ( <math alttext="\geq" class="ltx_Math" display="inline" id="S2.SS4.p1.2.m2.1"><semantics id="S2.SS4.p1.2.m2.1a"><mo id="S2.SS4.p1.2.m2.1.1" xref="S2.SS4.p1.2.m2.1.1.cmml">‚â•</mo><annotation-xml encoding="MathML-Content" id="S2.SS4.p1.2.m2.1b"><geq id="S2.SS4.p1.2.m2.1.1.cmml" xref="S2.SS4.p1.2.m2.1.1"></geq></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p1.2.m2.1c">\geq</annotation><annotation encoding="application/x-llamapun" id="S2.SS4.p1.2.m2.1d">‚â•</annotation></semantics></math> 15 mm for lymph nodes) from the ULS23 DeepLesion training set was kept out for validation against radiologists.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.5 </span>Segmentation Process</h3>
<div class="ltx_para" id="S2.SS5.p1">
<p class="ltx_p" id="S2.SS5.p1.1">The model had access to the entire volume and to the visual prompt. The image thresholding was fixed at -500 ; +1000 UH, an unrestricted window akin to bone windowing, which empirically led to the best overall results (data not shown). The model outputs then an initial segmentation mask in 2D. The segmentation masks for the remaining 2D axial slices are then calculated autoregressively, using the mask from the adjacent slice as the prompt for the next slice. This process propagates the segmentation masks from the middle slice, resulting in a 3D segmentation mask.</p>
</div>
<figure class="ltx_figure" id="S2.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="324" id="S2.F1.g1" src="extracted/5918755/fig1.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span><span class="ltx_text ltx_font_bold" id="S2.F1.2.1">ONCOPILOT Foundation Model Training and Evaluation</span> (A) Overview of the datasets used for training the ONCOPILOT segmentation model, including the distribution across train, test, and validation sets. (B) Diagram illustrating the ONCOPILOT segmentation model‚Äôs workflow. The model accepts visual prompts (either point-clicks or bounding boxes) of 3D tumor volumes and outputs corresponding 3D segmentation masks. Optional editing allows for real or simulated radiologist interaction, where positive and negative edit-points can be set manually in a viewer environment or automatically during evaluation.</figcaption>
</figure>
<div class="ltx_para" id="S2.SS5.p2">
<p class="ltx_p" id="S2.SS5.p2.1">The ONCOPILOT model is evaluated in three experimental settings using visual prompts that simulate real-life usage:</p>
<ul class="ltx_itemize" id="S2.I2">
<li class="ltx_item" id="S2.I2.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span>
<div class="ltx_para" id="S2.I2.i1.p1">
<p class="ltx_p" id="S2.I2.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S2.I2.i1.p1.1.1">Bounding box</span>: the model is prompted with a 2D bounding box outlining the lesion from the middle slice of the ground-truth mask, expanded with an offset of 15 pixels.</p>
</div>
</li>
<li class="ltx_item" id="S2.I2.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span>
<div class="ltx_para" id="S2.I2.i2.p1">
<p class="ltx_p" id="S2.I2.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S2.I2.i2.p1.1.1">Point-click</span>: the model is prompted by a single point, which is determined as the barycenter of the ground-truth mask or the closest point that falls within the segmentation mask.</p>
</div>
</li>
<li class="ltx_item" id="S2.I2.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span>
<div class="ltx_para" id="S2.I2.i3.p1">
<p class="ltx_p" id="S2.I2.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S2.I2.i3.p1.1.1">Point-edit</span>: to simulate interactions with radiologists, the 3D segmentation mask proposed in point-click mode is refined using up to 4 edit point-clicks chosen as the barycenter of the prediction error that can be negative (i.e., reduce an over-segmented mask) or positive (i.e., expand an under-segmented mask).</p>
</div>
</li>
</ul>
</div>
<figure class="ltx_figure" id="S2.F2">
<p class="ltx_p ltx_align_center" id="S2.F2.1"><span class="ltx_text ltx_inline-block" id="S2.F2.1.1" style="width:433.6pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="333" id="S2.F2.1.1.g1" src="extracted/5918755/fig2.png" width="598"/></span></p>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span><span class="ltx_text ltx_font_bold" id="S2.F2.3.1">ONCOPILOT Performance Against Baseline</span> (A) Radar plot (top) and table (bottom) displaying segmentation DICE scores across 7 lesion types for 3 different ONCOPILOT models (point, point-edit, bbox) compared to the best-performing baseline from the ULS23 segmentation challenge on the 10% held-out test set. (B) Examples of successful segmentations from the test set, comparing point mode (left columns) and bbox mode (right columns). The top row shows the visual prompt provided to the model, the middle row displays the ground truth mask for that slice, and the bottom row presents the ONCOPILOT model‚Äôs predicted segmentation.</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S2.SS6">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.6 </span>Morphology Analysis</h3>
<div class="ltx_para" id="S2.SS6.p1">
<p class="ltx_p" id="S2.SS6.p1.4">Sphericity index is calculated as the ratio of the surface area of a sphere to the surface area of the ground truth segmentation mask, given equal volumes, with a perfect sphere having a sphericity index of 1 while irregular structures being closer to 0. The following formula was used:</p>
<table class="ltx_equation ltx_eqn_table" id="S2.Ex1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="S=\frac{\pi^{1/3}\cdot(6V)^{2/3}}{A}" class="ltx_Math" display="block" id="S2.Ex1.m1.1"><semantics id="S2.Ex1.m1.1a"><mrow id="S2.Ex1.m1.1.2" xref="S2.Ex1.m1.1.2.cmml"><mi id="S2.Ex1.m1.1.2.2" xref="S2.Ex1.m1.1.2.2.cmml">S</mi><mo id="S2.Ex1.m1.1.2.1" xref="S2.Ex1.m1.1.2.1.cmml">=</mo><mfrac id="S2.Ex1.m1.1.1" xref="S2.Ex1.m1.1.1.cmml"><mrow id="S2.Ex1.m1.1.1.1" xref="S2.Ex1.m1.1.1.1.cmml"><msup id="S2.Ex1.m1.1.1.1.3" xref="S2.Ex1.m1.1.1.1.3.cmml"><mi id="S2.Ex1.m1.1.1.1.3.2" xref="S2.Ex1.m1.1.1.1.3.2.cmml">œÄ</mi><mrow id="S2.Ex1.m1.1.1.1.3.3" xref="S2.Ex1.m1.1.1.1.3.3.cmml"><mn id="S2.Ex1.m1.1.1.1.3.3.2" xref="S2.Ex1.m1.1.1.1.3.3.2.cmml">1</mn><mo id="S2.Ex1.m1.1.1.1.3.3.1" xref="S2.Ex1.m1.1.1.1.3.3.1.cmml">/</mo><mn id="S2.Ex1.m1.1.1.1.3.3.3" xref="S2.Ex1.m1.1.1.1.3.3.3.cmml">3</mn></mrow></msup><mo id="S2.Ex1.m1.1.1.1.2" lspace="0.222em" rspace="0.222em" xref="S2.Ex1.m1.1.1.1.2.cmml">‚ãÖ</mo><msup id="S2.Ex1.m1.1.1.1.1" xref="S2.Ex1.m1.1.1.1.1.cmml"><mrow id="S2.Ex1.m1.1.1.1.1.1.1" xref="S2.Ex1.m1.1.1.1.1.1.1.1.cmml"><mo id="S2.Ex1.m1.1.1.1.1.1.1.2" stretchy="false" xref="S2.Ex1.m1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S2.Ex1.m1.1.1.1.1.1.1.1" xref="S2.Ex1.m1.1.1.1.1.1.1.1.cmml"><mn id="S2.Ex1.m1.1.1.1.1.1.1.1.2" xref="S2.Ex1.m1.1.1.1.1.1.1.1.2.cmml">6</mn><mo id="S2.Ex1.m1.1.1.1.1.1.1.1.1" xref="S2.Ex1.m1.1.1.1.1.1.1.1.1.cmml">‚Å¢</mo><mi id="S2.Ex1.m1.1.1.1.1.1.1.1.3" xref="S2.Ex1.m1.1.1.1.1.1.1.1.3.cmml">V</mi></mrow><mo id="S2.Ex1.m1.1.1.1.1.1.1.3" stretchy="false" xref="S2.Ex1.m1.1.1.1.1.1.1.1.cmml">)</mo></mrow><mrow id="S2.Ex1.m1.1.1.1.1.3" xref="S2.Ex1.m1.1.1.1.1.3.cmml"><mn id="S2.Ex1.m1.1.1.1.1.3.2" xref="S2.Ex1.m1.1.1.1.1.3.2.cmml">2</mn><mo id="S2.Ex1.m1.1.1.1.1.3.1" xref="S2.Ex1.m1.1.1.1.1.3.1.cmml">/</mo><mn id="S2.Ex1.m1.1.1.1.1.3.3" xref="S2.Ex1.m1.1.1.1.1.3.3.cmml">3</mn></mrow></msup></mrow><mi id="S2.Ex1.m1.1.1.3" xref="S2.Ex1.m1.1.1.3.cmml">A</mi></mfrac></mrow><annotation-xml encoding="MathML-Content" id="S2.Ex1.m1.1b"><apply id="S2.Ex1.m1.1.2.cmml" xref="S2.Ex1.m1.1.2"><eq id="S2.Ex1.m1.1.2.1.cmml" xref="S2.Ex1.m1.1.2.1"></eq><ci id="S2.Ex1.m1.1.2.2.cmml" xref="S2.Ex1.m1.1.2.2">ùëÜ</ci><apply id="S2.Ex1.m1.1.1.cmml" xref="S2.Ex1.m1.1.1"><divide id="S2.Ex1.m1.1.1.2.cmml" xref="S2.Ex1.m1.1.1"></divide><apply id="S2.Ex1.m1.1.1.1.cmml" xref="S2.Ex1.m1.1.1.1"><ci id="S2.Ex1.m1.1.1.1.2.cmml" xref="S2.Ex1.m1.1.1.1.2">‚ãÖ</ci><apply id="S2.Ex1.m1.1.1.1.3.cmml" xref="S2.Ex1.m1.1.1.1.3"><csymbol cd="ambiguous" id="S2.Ex1.m1.1.1.1.3.1.cmml" xref="S2.Ex1.m1.1.1.1.3">superscript</csymbol><ci id="S2.Ex1.m1.1.1.1.3.2.cmml" xref="S2.Ex1.m1.1.1.1.3.2">ùúã</ci><apply id="S2.Ex1.m1.1.1.1.3.3.cmml" xref="S2.Ex1.m1.1.1.1.3.3"><divide id="S2.Ex1.m1.1.1.1.3.3.1.cmml" xref="S2.Ex1.m1.1.1.1.3.3.1"></divide><cn id="S2.Ex1.m1.1.1.1.3.3.2.cmml" type="integer" xref="S2.Ex1.m1.1.1.1.3.3.2">1</cn><cn id="S2.Ex1.m1.1.1.1.3.3.3.cmml" type="integer" xref="S2.Ex1.m1.1.1.1.3.3.3">3</cn></apply></apply><apply id="S2.Ex1.m1.1.1.1.1.cmml" xref="S2.Ex1.m1.1.1.1.1"><csymbol cd="ambiguous" id="S2.Ex1.m1.1.1.1.1.2.cmml" xref="S2.Ex1.m1.1.1.1.1">superscript</csymbol><apply id="S2.Ex1.m1.1.1.1.1.1.1.1.cmml" xref="S2.Ex1.m1.1.1.1.1.1.1"><times id="S2.Ex1.m1.1.1.1.1.1.1.1.1.cmml" xref="S2.Ex1.m1.1.1.1.1.1.1.1.1"></times><cn id="S2.Ex1.m1.1.1.1.1.1.1.1.2.cmml" type="integer" xref="S2.Ex1.m1.1.1.1.1.1.1.1.2">6</cn><ci id="S2.Ex1.m1.1.1.1.1.1.1.1.3.cmml" xref="S2.Ex1.m1.1.1.1.1.1.1.1.3">ùëâ</ci></apply><apply id="S2.Ex1.m1.1.1.1.1.3.cmml" xref="S2.Ex1.m1.1.1.1.1.3"><divide id="S2.Ex1.m1.1.1.1.1.3.1.cmml" xref="S2.Ex1.m1.1.1.1.1.3.1"></divide><cn id="S2.Ex1.m1.1.1.1.1.3.2.cmml" type="integer" xref="S2.Ex1.m1.1.1.1.1.3.2">2</cn><cn id="S2.Ex1.m1.1.1.1.1.3.3.cmml" type="integer" xref="S2.Ex1.m1.1.1.1.1.3.3">3</cn></apply></apply></apply><ci id="S2.Ex1.m1.1.1.3.cmml" xref="S2.Ex1.m1.1.1.3">ùê¥</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.Ex1.m1.1c">S=\frac{\pi^{1/3}\cdot(6V)^{2/3}}{A}</annotation><annotation encoding="application/x-llamapun" id="S2.Ex1.m1.1d">italic_S = divide start_ARG italic_œÄ start_POSTSUPERSCRIPT 1 / 3 end_POSTSUPERSCRIPT ‚ãÖ ( 6 italic_V ) start_POSTSUPERSCRIPT 2 / 3 end_POSTSUPERSCRIPT end_ARG start_ARG italic_A end_ARG</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S2.SS6.p1.3">where <math alttext="S" class="ltx_Math" display="inline" id="S2.SS6.p1.1.m1.1"><semantics id="S2.SS6.p1.1.m1.1a"><mi id="S2.SS6.p1.1.m1.1.1" xref="S2.SS6.p1.1.m1.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="S2.SS6.p1.1.m1.1b"><ci id="S2.SS6.p1.1.m1.1.1.cmml" xref="S2.SS6.p1.1.m1.1.1">ùëÜ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS6.p1.1.m1.1c">S</annotation><annotation encoding="application/x-llamapun" id="S2.SS6.p1.1.m1.1d">italic_S</annotation></semantics></math> is the sphericity, <math alttext="V" class="ltx_Math" display="inline" id="S2.SS6.p1.2.m2.1"><semantics id="S2.SS6.p1.2.m2.1a"><mi id="S2.SS6.p1.2.m2.1.1" xref="S2.SS6.p1.2.m2.1.1.cmml">V</mi><annotation-xml encoding="MathML-Content" id="S2.SS6.p1.2.m2.1b"><ci id="S2.SS6.p1.2.m2.1.1.cmml" xref="S2.SS6.p1.2.m2.1.1">ùëâ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS6.p1.2.m2.1c">V</annotation><annotation encoding="application/x-llamapun" id="S2.SS6.p1.2.m2.1d">italic_V</annotation></semantics></math> is the volume of the object, and <math alttext="A" class="ltx_Math" display="inline" id="S2.SS6.p1.3.m3.1"><semantics id="S2.SS6.p1.3.m3.1a"><mi id="S2.SS6.p1.3.m3.1.1" xref="S2.SS6.p1.3.m3.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S2.SS6.p1.3.m3.1b"><ci id="S2.SS6.p1.3.m3.1.1.cmml" xref="S2.SS6.p1.3.m3.1.1">ùê¥</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS6.p1.3.m3.1c">A</annotation><annotation encoding="application/x-llamapun" id="S2.SS6.p1.3.m3.1d">italic_A</annotation></semantics></math> is the surface area of the object.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS7">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.7 </span>RECIST Measurement</h3>
<div class="ltx_para" id="S2.SS7.p1">
<p class="ltx_p" id="S2.SS7.p1.1">RECIST measurements from ONCOPILOT were inferred from the segmentation masks in bounding box, point and point-edit modes. The primary measurement evaluated was the long axis of the oncological lesion, with the following amendments for simplicity and consistency: it was applied even to lymph nodes and restricted to the axial plane.</p>
</div>
<div class="ltx_para" id="S2.SS7.p2">
<p class="ltx_p" id="S2.SS7.p2.2">To further understand ONCOPILOT‚Äôs performance in real oncological evaluations, we compared it against a panel of radiologists for RECIST v1.1 measurements. Using a validation set of 67 tumors from diverse organs kept out from the ULS23 DeepLesion dataset, we compared the long axis in the axial plane inferred from ONCOPILOT predicted segmentation masks to manual annotations made by the radiologist panel composed of three radiologists with a minimum of 18 months of experience. These 67 tumors are selected for their inclusivity as potential target lesions according to the RECIST v1.1 guidelines (i.e., solid lesions with a long axis <math alttext="\geq" class="ltx_Math" display="inline" id="S2.SS7.p2.1.m1.1"><semantics id="S2.SS7.p2.1.m1.1a"><mo id="S2.SS7.p2.1.m1.1.1" xref="S2.SS7.p2.1.m1.1.1.cmml">‚â•</mo><annotation-xml encoding="MathML-Content" id="S2.SS7.p2.1.m1.1b"><geq id="S2.SS7.p2.1.m1.1.1.cmml" xref="S2.SS7.p2.1.m1.1.1"></geq></annotation-xml><annotation encoding="application/x-tex" id="S2.SS7.p2.1.m1.1c">\geq</annotation><annotation encoding="application/x-llamapun" id="S2.SS7.p2.1.m1.1d">‚â•</annotation></semantics></math> 10 mm, lymph nodes with a short axis <math alttext="\geq" class="ltx_Math" display="inline" id="S2.SS7.p2.2.m2.1"><semantics id="S2.SS7.p2.2.m2.1a"><mo id="S2.SS7.p2.2.m2.1.1" xref="S2.SS7.p2.2.m2.1.1.cmml">‚â•</mo><annotation-xml encoding="MathML-Content" id="S2.SS7.p2.2.m2.1b"><geq id="S2.SS7.p2.2.m2.1.1.cmml" xref="S2.SS7.p2.2.m2.1.1"></geq></annotation-xml><annotation encoding="application/x-tex" id="S2.SS7.p2.2.m2.1c">\geq</annotation><annotation encoding="application/x-llamapun" id="S2.SS7.p2.2.m2.1d">‚â•</annotation></semantics></math> 15 mm) and filtered for their segmentation quality. The measures proposed by ONCOPILOT and the radiologists were compared to those inferred from the ground-truth segmentation masks to extract the measurement error.</p>
</div>
<div class="ltx_para" id="S2.SS7.p3">
<p class="ltx_p" id="S2.SS7.p3.1">Radiologists used our in-house viewer for manual and ONCOPILOT-assisted measurement of the lesion‚Äôs long axis. They could zoom at will, modify the image‚Äôs windowing, and navigate the volume freely, without the help of multi-planar reconstruction. The barycenter of the lesion was superimposed on the initial volume to indicate the lesion of interest without biasing the radiologist by showing the ground-truth mask. For ONCOPILOT-assisted measurements, the radiologists used the measures inferred by the model after automatic segmentation of the target lesion by ONCOPILOT using bounding box visual prompts only for simplicity.</p>
</div>
<div class="ltx_para" id="S2.SS7.p4">
<p class="ltx_p" id="S2.SS7.p4.1">Inter-operator variability was defined as the deviation of each radiologist‚Äôs measurement from the overall average of all measurements for a given lesion, whether those measurements are aided by the segmentation model or done manually. Essentially, it represents the mean error of each radiologist compared to the collective average. Measurement duration was recorded for each assessment. It is defined as the time from the CT‚Äôs initial display to getting the object‚Äôs final measurement.</p>
</div>
<figure class="ltx_figure" id="S2.F3">
<p class="ltx_p ltx_align_center" id="S2.F3.1"><span class="ltx_text ltx_inline-block" id="S2.F3.1.1" style="width:433.6pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="177" id="S2.F3.1.1.g1" src="extracted/5918755/fig3.png" width="658"/></span></p>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span><span class="ltx_text ltx_font_bold" id="S2.F3.11.1">ONCOPILOT Performance on Different Lesion Types</span> Bar plot showing the mean DICE scores from ONCOPILOT segmentation masks in point mode (red) and point-edit mode (blue) for: (A) spherical lesions (sphericity <math alttext="&gt;0.6" class="ltx_Math" display="inline" id="S2.F3.6.m1.1"><semantics id="S2.F3.6.m1.1b"><mrow id="S2.F3.6.m1.1.1" xref="S2.F3.6.m1.1.1.cmml"><mi id="S2.F3.6.m1.1.1.2" xref="S2.F3.6.m1.1.1.2.cmml"></mi><mo id="S2.F3.6.m1.1.1.1" xref="S2.F3.6.m1.1.1.1.cmml">&gt;</mo><mn id="S2.F3.6.m1.1.1.3" xref="S2.F3.6.m1.1.1.3.cmml">0.6</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.F3.6.m1.1c"><apply id="S2.F3.6.m1.1.1.cmml" xref="S2.F3.6.m1.1.1"><gt id="S2.F3.6.m1.1.1.1.cmml" xref="S2.F3.6.m1.1.1.1"></gt><csymbol cd="latexml" id="S2.F3.6.m1.1.1.2.cmml" xref="S2.F3.6.m1.1.1.2">absent</csymbol><cn id="S2.F3.6.m1.1.1.3.cmml" type="float" xref="S2.F3.6.m1.1.1.3">0.6</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F3.6.m1.1d">&gt;0.6</annotation><annotation encoding="application/x-llamapun" id="S2.F3.6.m1.1e">&gt; 0.6</annotation></semantics></math>) versus irregular lesions (see Methods for the sphericity formula), (B) large lesions (long axis <math alttext="&gt;15" class="ltx_Math" display="inline" id="S2.F3.7.m2.1"><semantics id="S2.F3.7.m2.1b"><mrow id="S2.F3.7.m2.1.1" xref="S2.F3.7.m2.1.1.cmml"><mi id="S2.F3.7.m2.1.1.2" xref="S2.F3.7.m2.1.1.2.cmml"></mi><mo id="S2.F3.7.m2.1.1.1" xref="S2.F3.7.m2.1.1.1.cmml">&gt;</mo><mn id="S2.F3.7.m2.1.1.3" xref="S2.F3.7.m2.1.1.3.cmml">15</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.F3.7.m2.1c"><apply id="S2.F3.7.m2.1.1.cmml" xref="S2.F3.7.m2.1.1"><gt id="S2.F3.7.m2.1.1.1.cmml" xref="S2.F3.7.m2.1.1.1"></gt><csymbol cd="latexml" id="S2.F3.7.m2.1.1.2.cmml" xref="S2.F3.7.m2.1.1.2">absent</csymbol><cn id="S2.F3.7.m2.1.1.3.cmml" type="integer" xref="S2.F3.7.m2.1.1.3">15</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F3.7.m2.1d">&gt;15</annotation><annotation encoding="application/x-llamapun" id="S2.F3.7.m2.1e">&gt; 15</annotation></semantics></math> mm) versus smaller lesions, (C) voluminous lesions (volume <math alttext="&gt;1" class="ltx_Math" display="inline" id="S2.F3.8.m3.1"><semantics id="S2.F3.8.m3.1b"><mrow id="S2.F3.8.m3.1.1" xref="S2.F3.8.m3.1.1.cmml"><mi id="S2.F3.8.m3.1.1.2" xref="S2.F3.8.m3.1.1.2.cmml"></mi><mo id="S2.F3.8.m3.1.1.1" xref="S2.F3.8.m3.1.1.1.cmml">&gt;</mo><mn id="S2.F3.8.m3.1.1.3" xref="S2.F3.8.m3.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.F3.8.m3.1c"><apply id="S2.F3.8.m3.1.1.cmml" xref="S2.F3.8.m3.1.1"><gt id="S2.F3.8.m3.1.1.1.cmml" xref="S2.F3.8.m3.1.1.1"></gt><csymbol cd="latexml" id="S2.F3.8.m3.1.1.2.cmml" xref="S2.F3.8.m3.1.1.2">absent</csymbol><cn id="S2.F3.8.m3.1.1.3.cmml" type="integer" xref="S2.F3.8.m3.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F3.8.m3.1d">&gt;1</annotation><annotation encoding="application/x-llamapun" id="S2.F3.8.m3.1e">&gt; 1</annotation></semantics></math> mL) versus smaller lesions. (D) Boxplot displaying the distribution of DICE scores produced by ONCOPILOT in point mode (red) and point-edit mode (blue) across various lesion types in the 10% held-out test set, with median values and interquartile ranges highlighted. (E) Boxplot showing RECIST measurements derived from ONCOPILOT‚Äôs predicted masks in point mode (red) and point-edit mode (blue) across different lesion types in the 10% held-out test set, highlighting median values and interquartile ranges. The long axis is defined as the longest possible line in the axial plane across the predicted 3D mask. ***: p-value <math alttext="&lt;0.001" class="ltx_Math" display="inline" id="S2.F3.9.m4.1"><semantics id="S2.F3.9.m4.1b"><mrow id="S2.F3.9.m4.1.1" xref="S2.F3.9.m4.1.1.cmml"><mi id="S2.F3.9.m4.1.1.2" xref="S2.F3.9.m4.1.1.2.cmml"></mi><mo id="S2.F3.9.m4.1.1.1" xref="S2.F3.9.m4.1.1.1.cmml">&lt;</mo><mn id="S2.F3.9.m4.1.1.3" xref="S2.F3.9.m4.1.1.3.cmml">0.001</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.F3.9.m4.1c"><apply id="S2.F3.9.m4.1.1.cmml" xref="S2.F3.9.m4.1.1"><lt id="S2.F3.9.m4.1.1.1.cmml" xref="S2.F3.9.m4.1.1.1"></lt><csymbol cd="latexml" id="S2.F3.9.m4.1.1.2.cmml" xref="S2.F3.9.m4.1.1.2">absent</csymbol><cn id="S2.F3.9.m4.1.1.3.cmml" type="float" xref="S2.F3.9.m4.1.1.3">0.001</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F3.9.m4.1d">&lt;0.001</annotation><annotation encoding="application/x-llamapun" id="S2.F3.9.m4.1e">&lt; 0.001</annotation></semantics></math>; n.s.: non-significant.</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S2.SS8">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.8 </span>ONCOPILOT integration into radiologist‚Äôs workflow</h3>
<div class="ltx_para" id="S2.SS8.p1">
<p class="ltx_p" id="S2.SS8.p1.1">Finally, to determine whether ONCOPILOT could serve as an AI companion, we evaluated its integration and improvement of the oncological evaluation workflow within our in-house environment. We measured inter-reader variability as the mean deviation from the average between radiologists performing RECIST measurements manually and radiologists performing these measures semi-automatically using the segmentation model by drawing a bounding box around the lesion. We also timed the duration required to obtain measurements in each scenario.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Results</h2>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Foundation Model</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">Our foundation model, ONCOPILOT, was pre-trained on a diverse dataset comprising normal anatomy and oncological lesions, totaling 2,374 CT scans including 104 anatomical structures (e.g., organs, bones) and 4 oncological lesions regardless of histology and malignity (i.e., lung, liver, pancreas and colon tumors) from the MSD dataset (Figure 1A), without distinction regarding their histological type or malignancy.</p>
</div>
<div class="ltx_para" id="S3.SS1.p2">
<p class="ltx_p" id="S3.SS1.p2.1">To become specialized for oncology the model was subsequently fine-tuned on a comprehensive dataset of 6,229 tumors from various organs (e.g., pancreas, bone, liver, kidney, lung, lymph nodes). ONCOPILOT is designed to interactively segment oncological lesions in 3D, utilizing visual prompts such as a bounding box (referred to as bbox) around the lesion of interest or a point-click (referred to as point) inside it (Figure 1B). To simulate the dynamic refinement of the predicted segmentation masks by radiologists we developed an editing mechanism (referred to as point-edit, see Material &amp; Methods).</p>
</div>
<figure class="ltx_figure" id="S3.F4">
<p class="ltx_p ltx_align_center" id="S3.F4.1"><span class="ltx_text ltx_inline-block" id="S3.F4.1.1" style="width:433.6pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="284" id="S3.F4.1.1.g1" src="extracted/5918755/fig4.png" width="658"/></span></p>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span><span class="ltx_text ltx_font_bold" id="S3.F4.5.1">ONCOPILOT Integration Into Radiologist‚Äôs Workflow</span> (A) Diagram and results comparing ONCOPILOT in point, point-edit, and bbox modes against three radiologists for the long-axis measurement of diverse oncological lesions. Median absolute error (mm) and median relative error (% of lesion size) are shown. P-values from t-tests compare ONCOPILOT models to radiologists for long-axis measurement error, without statistical significance p <math alttext="\geq" class="ltx_Math" display="inline" id="S3.F4.3.m1.1"><semantics id="S3.F4.3.m1.1b"><mo id="S3.F4.3.m1.1.1" xref="S3.F4.3.m1.1.1.cmml">‚â•</mo><annotation-xml encoding="MathML-Content" id="S3.F4.3.m1.1c"><geq id="S3.F4.3.m1.1.1.cmml" xref="S3.F4.3.m1.1.1"></geq></annotation-xml><annotation encoding="application/x-tex" id="S3.F4.3.m1.1d">\geq</annotation><annotation encoding="application/x-llamapun" id="S3.F4.3.m1.1e">‚â•</annotation></semantics></math> 0.05. The long axis is the longest line in the axial plane across the predicted 3D mask. (B) Boxplot (bottom) of ONCOPILOT‚Äôs tumors long-axis measurement performance against radiologists. Left: median absolute error (mm) vs. ground truth. Right: median relative error (% of lesion size). Median and interquartile ranges are shown. (C) Diagram of an experiment evaluating radiologists‚Äô inter-operator variability and measurement time while measuring tumors‚Äô long-axis using a digital viewer for manual vs. ONCOPILOT-assisted (bbox mode) long-axis assessments. (D) Boxplots show radiologists‚Äô inter-operator variability in measurement error (left) and measurement time (right) using manual vs. ONCOPILOT-assisted annotations across diverse tumors, with t-test p-values; n=3.</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Segmentation Performance</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">ONCOPILOT surpassed the baseline model in all evaluation metrics‚Äîpoint, point-edit, and bbox‚Äîacross all lesion types, with the exception of lung tumors, where only the point-edit model demonstrated superior performance (Figure 2A, with examples of successful segmentations in Figure 2B).</p>
</div>
<div class="ltx_para" id="S3.SS2.p2">
<p class="ltx_p" id="S3.SS2.p2.1">The test dataset was imbalanced, with over 40% of the lesions being lung tumors, which biased the overall DICE score in favor of the baseline model (further adressed in the Discussion section). ONCOPILOT achieved mean DICE scores of 0.70 for point mode, 0.70 for bbox mode, and 0.78 for point-edit mode, compared to 0.70 for the baseline. The distribution of lesion sizes by organ and examples of failed segmentations are provided in Supplementary Figures S1A and S1B. Additionally, it is worth mentioning that nnUNet models are often restricted to specific tasks, tends to underperform on complex datasets, and require longer training and inference times while ONCOPILOT offers an all-in-one solution.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Morphology Analysis</h3>
<div class="ltx_para" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.1">The segmentation masks outputted by the model in point mode were influenced by the lesion morphology and size. Indeed, ONCOPILOT exhibited lower DICE scores for lesions with irregular, non-spherical shapes, with a mean DICE of 0.66 for tumors with a sphericity index below 0.6, compared to 0.71 for more spherical tumors in point mode (<math alttext="p&lt;0.001" class="ltx_Math" display="inline" id="S3.SS3.p1.1.m1.1"><semantics id="S3.SS3.p1.1.m1.1a"><mrow id="S3.SS3.p1.1.m1.1.1" xref="S3.SS3.p1.1.m1.1.1.cmml"><mi id="S3.SS3.p1.1.m1.1.1.2" xref="S3.SS3.p1.1.m1.1.1.2.cmml">p</mi><mo id="S3.SS3.p1.1.m1.1.1.1" xref="S3.SS3.p1.1.m1.1.1.1.cmml">&lt;</mo><mn id="S3.SS3.p1.1.m1.1.1.3" xref="S3.SS3.p1.1.m1.1.1.3.cmml">0.001</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.1.m1.1b"><apply id="S3.SS3.p1.1.m1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1"><lt id="S3.SS3.p1.1.m1.1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1.1"></lt><ci id="S3.SS3.p1.1.m1.1.1.2.cmml" xref="S3.SS3.p1.1.m1.1.1.2">ùëù</ci><cn id="S3.SS3.p1.1.m1.1.1.3.cmml" type="float" xref="S3.SS3.p1.1.m1.1.1.3">0.001</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.1.m1.1c">p&lt;0.001</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.1.m1.1d">italic_p &lt; 0.001</annotation></semantics></math>, Figure 3A, Supplementary Figure S2A).</p>
</div>
<div class="ltx_para" id="S3.SS3.p2">
<p class="ltx_p" id="S3.SS3.p2.4">Similarly, smaller lesions yielded lower DICE scores, with a mean of 0.67 for lesions with a long axis <math alttext="&lt;15mm" class="ltx_Math" display="inline" id="S3.SS3.p2.1.m1.1"><semantics id="S3.SS3.p2.1.m1.1a"><mrow id="S3.SS3.p2.1.m1.1.1" xref="S3.SS3.p2.1.m1.1.1.cmml"><mi id="S3.SS3.p2.1.m1.1.1.2" xref="S3.SS3.p2.1.m1.1.1.2.cmml"></mi><mo id="S3.SS3.p2.1.m1.1.1.1" xref="S3.SS3.p2.1.m1.1.1.1.cmml">&lt;</mo><mrow id="S3.SS3.p2.1.m1.1.1.3" xref="S3.SS3.p2.1.m1.1.1.3.cmml"><mn id="S3.SS3.p2.1.m1.1.1.3.2" xref="S3.SS3.p2.1.m1.1.1.3.2.cmml">15</mn><mo id="S3.SS3.p2.1.m1.1.1.3.1" xref="S3.SS3.p2.1.m1.1.1.3.1.cmml">‚Å¢</mo><mi id="S3.SS3.p2.1.m1.1.1.3.3" xref="S3.SS3.p2.1.m1.1.1.3.3.cmml">m</mi><mo id="S3.SS3.p2.1.m1.1.1.3.1a" xref="S3.SS3.p2.1.m1.1.1.3.1.cmml">‚Å¢</mo><mi id="S3.SS3.p2.1.m1.1.1.3.4" xref="S3.SS3.p2.1.m1.1.1.3.4.cmml">m</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.1.m1.1b"><apply id="S3.SS3.p2.1.m1.1.1.cmml" xref="S3.SS3.p2.1.m1.1.1"><lt id="S3.SS3.p2.1.m1.1.1.1.cmml" xref="S3.SS3.p2.1.m1.1.1.1"></lt><csymbol cd="latexml" id="S3.SS3.p2.1.m1.1.1.2.cmml" xref="S3.SS3.p2.1.m1.1.1.2">absent</csymbol><apply id="S3.SS3.p2.1.m1.1.1.3.cmml" xref="S3.SS3.p2.1.m1.1.1.3"><times id="S3.SS3.p2.1.m1.1.1.3.1.cmml" xref="S3.SS3.p2.1.m1.1.1.3.1"></times><cn id="S3.SS3.p2.1.m1.1.1.3.2.cmml" type="integer" xref="S3.SS3.p2.1.m1.1.1.3.2">15</cn><ci id="S3.SS3.p2.1.m1.1.1.3.3.cmml" xref="S3.SS3.p2.1.m1.1.1.3.3">ùëö</ci><ci id="S3.SS3.p2.1.m1.1.1.3.4.cmml" xref="S3.SS3.p2.1.m1.1.1.3.4">ùëö</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.1.m1.1c">&lt;15mm</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p2.1.m1.1d">&lt; 15 italic_m italic_m</annotation></semantics></math> versus 0.73 for larger lesions (<math alttext="p&lt;0.001" class="ltx_Math" display="inline" id="S3.SS3.p2.2.m2.1"><semantics id="S3.SS3.p2.2.m2.1a"><mrow id="S3.SS3.p2.2.m2.1.1" xref="S3.SS3.p2.2.m2.1.1.cmml"><mi id="S3.SS3.p2.2.m2.1.1.2" xref="S3.SS3.p2.2.m2.1.1.2.cmml">p</mi><mo id="S3.SS3.p2.2.m2.1.1.1" xref="S3.SS3.p2.2.m2.1.1.1.cmml">&lt;</mo><mn id="S3.SS3.p2.2.m2.1.1.3" xref="S3.SS3.p2.2.m2.1.1.3.cmml">0.001</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.2.m2.1b"><apply id="S3.SS3.p2.2.m2.1.1.cmml" xref="S3.SS3.p2.2.m2.1.1"><lt id="S3.SS3.p2.2.m2.1.1.1.cmml" xref="S3.SS3.p2.2.m2.1.1.1"></lt><ci id="S3.SS3.p2.2.m2.1.1.2.cmml" xref="S3.SS3.p2.2.m2.1.1.2">ùëù</ci><cn id="S3.SS3.p2.2.m2.1.1.3.cmml" type="float" xref="S3.SS3.p2.2.m2.1.1.3">0.001</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.2.m2.1c">p&lt;0.001</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p2.2.m2.1d">italic_p &lt; 0.001</annotation></semantics></math>, Figure 3B, Supplementary Figure S2B). This trend persisted when using volume as a metric: lesions under 1 mL had a mean DICE of 0.67, compared to 0.74 for larger lesions (<math alttext="p&lt;0.001" class="ltx_Math" display="inline" id="S3.SS3.p2.3.m3.1"><semantics id="S3.SS3.p2.3.m3.1a"><mrow id="S3.SS3.p2.3.m3.1.1" xref="S3.SS3.p2.3.m3.1.1.cmml"><mi id="S3.SS3.p2.3.m3.1.1.2" xref="S3.SS3.p2.3.m3.1.1.2.cmml">p</mi><mo id="S3.SS3.p2.3.m3.1.1.1" xref="S3.SS3.p2.3.m3.1.1.1.cmml">&lt;</mo><mn id="S3.SS3.p2.3.m3.1.1.3" xref="S3.SS3.p2.3.m3.1.1.3.cmml">0.001</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.3.m3.1b"><apply id="S3.SS3.p2.3.m3.1.1.cmml" xref="S3.SS3.p2.3.m3.1.1"><lt id="S3.SS3.p2.3.m3.1.1.1.cmml" xref="S3.SS3.p2.3.m3.1.1.1"></lt><ci id="S3.SS3.p2.3.m3.1.1.2.cmml" xref="S3.SS3.p2.3.m3.1.1.2">ùëù</ci><cn id="S3.SS3.p2.3.m3.1.1.3.cmml" type="float" xref="S3.SS3.p2.3.m3.1.1.3">0.001</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.3.m3.1c">p&lt;0.001</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p2.3.m3.1d">italic_p &lt; 0.001</annotation></semantics></math>, Figure 3C, Supplementary Figure S2C). Crucially, interactive editing mitigated these biases, eliminating significant differences in DICE scores between lesions of varying sphericity, long axis, or volume in point-edit mode. This approach also reduced disparities in DICE between lesion types (Figure 3D). Additionally, when using RECIST measurements for the long axis instead of DICE scores, interactive editing significantly reduced measurement errors, with the median error decreasing from 14.1% in point mode to 9.6% in point-edit mode (<math alttext="p&lt;0.001" class="ltx_Math" display="inline" id="S3.SS3.p2.4.m4.1"><semantics id="S3.SS3.p2.4.m4.1a"><mrow id="S3.SS3.p2.4.m4.1.1" xref="S3.SS3.p2.4.m4.1.1.cmml"><mi id="S3.SS3.p2.4.m4.1.1.2" xref="S3.SS3.p2.4.m4.1.1.2.cmml">p</mi><mo id="S3.SS3.p2.4.m4.1.1.1" xref="S3.SS3.p2.4.m4.1.1.1.cmml">&lt;</mo><mn id="S3.SS3.p2.4.m4.1.1.3" xref="S3.SS3.p2.4.m4.1.1.3.cmml">0.001</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.4.m4.1b"><apply id="S3.SS3.p2.4.m4.1.1.cmml" xref="S3.SS3.p2.4.m4.1.1"><lt id="S3.SS3.p2.4.m4.1.1.1.cmml" xref="S3.SS3.p2.4.m4.1.1.1"></lt><ci id="S3.SS3.p2.4.m4.1.1.2.cmml" xref="S3.SS3.p2.4.m4.1.1.2">ùëù</ci><cn id="S3.SS3.p2.4.m4.1.1.3.cmml" type="float" xref="S3.SS3.p2.4.m4.1.1.3">0.001</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.4.m4.1c">p&lt;0.001</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p2.4.m4.1d">italic_p &lt; 0.001</annotation></semantics></math>). This level of accuracy is consistent with the reported inter-reader variability among radiologists for single-lesion measurements (<cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2410.07908v2#bib.bib5" title="">5</a>]</cite>, Figure 3E).</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4 </span>ONCOPILOT Evaluation Against Radiologists</h3>
<div class="ltx_para" id="S3.SS4.p1">
<p class="ltx_p" id="S3.SS4.p1.1">ONCOPILOT demonstrated radiologist-level performance in point, point-edit, and bbox modes (Figure 4A, 4B). There was no statistically significant difference between the different ONCOPILOT models when evaluated against radiologists, with a median absolute error in long axis measurement of 1.3 mm for radiologists (8.6% of the median lesion size) versus 1.1 mm for ONCOPILOT in point-edit mode (7.4%), 1.6 mm in point mode (10.8%), and 1.5 mm in bbox mode (10.4%).</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.5 </span>ONCOPILOT Integration into Radiologist‚Äôs Workflow</h3>
<div class="ltx_para" id="S3.SS5.p1">
<p class="ltx_p" id="S3.SS5.p1.2">ONCOPILOT enhanced the reproducibility and efficiency of radiologist measurements, with an inter-reader deviation of 1.7 mm when assisted by ONCOPILOT versus 2.4 mm manually (Figure 4C, 4D, <math alttext="p&lt;0.05" class="ltx_Math" display="inline" id="S3.SS5.p1.1.m1.1"><semantics id="S3.SS5.p1.1.m1.1a"><mrow id="S3.SS5.p1.1.m1.1.1" xref="S3.SS5.p1.1.m1.1.1.cmml"><mi id="S3.SS5.p1.1.m1.1.1.2" xref="S3.SS5.p1.1.m1.1.1.2.cmml">p</mi><mo id="S3.SS5.p1.1.m1.1.1.1" xref="S3.SS5.p1.1.m1.1.1.1.cmml">&lt;</mo><mn id="S3.SS5.p1.1.m1.1.1.3" xref="S3.SS5.p1.1.m1.1.1.3.cmml">0.05</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS5.p1.1.m1.1b"><apply id="S3.SS5.p1.1.m1.1.1.cmml" xref="S3.SS5.p1.1.m1.1.1"><lt id="S3.SS5.p1.1.m1.1.1.1.cmml" xref="S3.SS5.p1.1.m1.1.1.1"></lt><ci id="S3.SS5.p1.1.m1.1.1.2.cmml" xref="S3.SS5.p1.1.m1.1.1.2">ùëù</ci><cn id="S3.SS5.p1.1.m1.1.1.3.cmml" type="float" xref="S3.SS5.p1.1.m1.1.1.3">0.05</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p1.1.m1.1c">p&lt;0.05</annotation><annotation encoding="application/x-llamapun" id="S3.SS5.p1.1.m1.1d">italic_p &lt; 0.05</annotation></semantics></math>). Additionally, radiologists demonstrated a faster measurement speed using ONCOPILOT, with an average time of 17.2 seconds per measurement compared to 20.6 seconds with manual annotations (<math alttext="p&lt;0.05" class="ltx_Math" display="inline" id="S3.SS5.p1.2.m2.1"><semantics id="S3.SS5.p1.2.m2.1a"><mrow id="S3.SS5.p1.2.m2.1.1" xref="S3.SS5.p1.2.m2.1.1.cmml"><mi id="S3.SS5.p1.2.m2.1.1.2" xref="S3.SS5.p1.2.m2.1.1.2.cmml">p</mi><mo id="S3.SS5.p1.2.m2.1.1.1" xref="S3.SS5.p1.2.m2.1.1.1.cmml">&lt;</mo><mn id="S3.SS5.p1.2.m2.1.1.3" xref="S3.SS5.p1.2.m2.1.1.3.cmml">0.05</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS5.p1.2.m2.1b"><apply id="S3.SS5.p1.2.m2.1.1.cmml" xref="S3.SS5.p1.2.m2.1.1"><lt id="S3.SS5.p1.2.m2.1.1.1.cmml" xref="S3.SS5.p1.2.m2.1.1.1"></lt><ci id="S3.SS5.p1.2.m2.1.1.2.cmml" xref="S3.SS5.p1.2.m2.1.1.2">ùëù</ci><cn id="S3.SS5.p1.2.m2.1.1.3.cmml" type="float" xref="S3.SS5.p1.2.m2.1.1.3">0.05</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p1.2.m2.1c">p&lt;0.05</annotation><annotation encoding="application/x-llamapun" id="S3.SS5.p1.2.m2.1d">italic_p &lt; 0.05</annotation></semantics></math>). Notably, this improvement in speed was achieved without focusing on speed optimization, as it operated on a non-optimized web-based platform (showcased in Supplementary Figure S3A to S3E). Most of the measurement time was spent locating the lesion within the exam, suggesting that ONCOPILOT could be further accelerated with targeted improvements.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Discussion</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">In summary, ONCOPILOT demonstrated state-of-the-art performance in tumor segmentation across a diverse set of oncological lesions, achieving radiologist-level accuracy in RECIST 1.1 measurements. The model‚Äôs flexibility, enabled by interactive visual prompts and refinement capabilities in our in-house viewer, marks a significant advancement in integrating an explainable AI copilot into the imaging workflow while keeping the radiologist in the loop. This approach not only reduces inter-reader variability and measurement time but also offers a more adaptable solution compared to rigid, traditional segmentation models. Nonetheless, further research is needed to establish how these gains in efficiency and precision translate into meaningful improvements in longitudinal oncological evaluation and influence disease status assessment.</p>
</div>
<div class="ltx_para" id="S4.p2">
<p class="ltx_p" id="S4.p2.1">ONCOPILOT not only enhances the precision and consistency of RECIST-based oncological assessments but also goes beyond traditional RECIST measurements by enabling volumetric analysis and uncovering previously unexplored radiomic features. Volumetric biomarkers, such as tumor growth rate and total tumor burden, combined with morphology-based markers, offer more comprehensive and accurate indicators of tumor mass and aggressiveness compared to conventional long and short axis measurements. These novel radiomic biomarkers will better accommodate the variability in tumor presentations, providing a more precise characterization of oncological disease.</p>
</div>
<div class="ltx_para" id="S4.p3">
<p class="ltx_p" id="S4.p3.1">It is important to note that ONCOPILOT‚Äôs suboptimal performance on lung tumors appears to be related to lesion size, highlighting a limitation of our model. Lung tumors in the test set were predominantly small nodules of uncertain oncological relevance, with a median size of 9 mm compared to 20 mm for non-lung tumors. This disproportionate representation (more than 40%) of lung lesions in the test dataset skewed the overall results, disadvantaging our model‚Äôs performance. Future versions of the model, along with a more balanced test dataset, should address this limitation.</p>
</div>
<div class="ltx_para" id="S4.p4">
<p class="ltx_p" id="S4.p4.1">ONCOPILOT leveraged publicly available data <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2410.07908v2#bib.bib20" title="">20</a>]</cite> and model architecture <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2410.07908v2#bib.bib20" title="">20</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.07908v2#bib.bib16" title="">16</a>]</cite>, demonstrating that foundation models are already capable of delivering impactful results in the biomedical field without significant technical hurdles. Although ONCOPILOT can be considered a small foundation model in terms of training set size, it already showcases the promising potential of this technology, with future iterations expected to be significantly more advanced and effective. These results reinforce our belief that foundation models are a pivotal step toward the next generation of AI-assisted radiology.</p>
</div>
<div class="ltx_para" id="S4.p5">
<p class="ltx_p" id="S4.p5.1">Through this work, we aim to demonstrate oncological evaluation as the first use case for the native integration of foundation-model-based AI assistants into the radiologist‚Äôs workflow, paving the way for improved patient stratification, optimized clinical trial monitoring, more informed treatment decisions, and ultimately enhanced patient care.</p>
</div>
</section>
<section class="ltx_section" id="Sx1">
<h2 class="ltx_title ltx_title_section">Acknowledgments</h2>
<div class="ltx_para" id="Sx1.p1">
<p class="ltx_p" id="Sx1.p1.1">This work was granted access to the HPC resources of IDRIS under the allocation 2024-AD011013489R2 made by GENCI.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
E.¬†A. Eisenhauer, P.¬†Therasse, J.¬†Bogaerts, et¬†al.

</span>
<span class="ltx_bibblock">New response evaluation criteria in solid tumours: Revised recist guideline (version 1.1).

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib1.1.1">European Journal of Cancer</span>, 45(2):228‚Äì247, 2009.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
Michel Meignan, Anne¬†S√©gol√®ne Cottereau, Annibale Versari, Lo√Øc Chartier, Jehan Dupuis, Sami Boussetta, Ilaria Grassi, et¬†al.

</span>
<span class="ltx_bibblock">Baseline metabolic tumor volume predicts outcome in high-tumor-burden follicular lymphoma: A pooled analysis of three multicenter studies.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib2.1.1">Journal of Clinical Oncology</span>, 34(30):3618‚Äì3626, 2016.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
Hyun¬†Woo Chung, Kye¬†Young Lee, Hee¬†Joung Kim, et¬†al.

</span>
<span class="ltx_bibblock">Fdg pet/ct metabolic tumor volume and total lesion glycolysis predict prognosis in patients with advanced lung adenocarcinoma.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib3.1.1">Journal of Cancer Research and Clinical Oncology</span>, 140(1):89‚Äì98, 2014.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
Christiane¬†K. Kuhl, Yunus Alparslan, Jonas Schmoee, Bruno Sequeira, Annika Keulers, Tim¬†H. Br√ºmmendorf, and Sebastian Keil.

</span>
<span class="ltx_bibblock">Validity of recist version 1.1 for response assessment in metastatic cancer: A prospective, multireader study.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib4.1.1">Radiology</span>, 290(2):349‚Äì356, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
Soon¬†Ho Yoon, Kyung¬†Won Kim, Jin¬†Mo Goo, et¬†al.

</span>
<span class="ltx_bibblock">Observer variability in recist-based tumour burden measurements: A meta-analysis.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib5.1.1">European Journal of Cancer</span>, 53:5‚Äì15, 2016.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
Virginia¬†B. Planz, Meghan¬†G. Lubner, and Perry¬†J. Pickhardt.

</span>
<span class="ltx_bibblock">Volumetric analysis at abdominal ct: Oncologic and non-oncologic applications.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib6.1.1">The British Journal of Radiology</span>, 92(1095):20180631, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
Shidan Wang, Alyssa Chen, Lin Yang, et¬†al.

</span>
<span class="ltx_bibblock">Comprehensive analysis of lung cancer pathology images to discover tumor shape and boundary features that predict survival outcome.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib7.1.1">Scientific Reports</span>, 8(1):10393, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
S.¬†A. Hayes, M.¬†C. Pietanza, D.¬†O‚ÄôDriscoll, et¬†al.

</span>
<span class="ltx_bibblock">Comparison of ct volumetric measurement with recist response in patients with lung cancer.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib8.1.1">European Journal of Radiology</span>, 85(3):524‚Äì533, 2016.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
Laurent Dercle, Binsheng Zhao, Mithat G√∂nen, et¬†al.

</span>
<span class="ltx_bibblock">An imaging signature to predict outcome in metastatic colorectal cancer using routine computed tomography scans.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib9.1.1">European Journal of Cancer</span>, 161:138‚Äì147, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
Laurent Dercle, Matthew Fronheiser, Naiyer¬†A Rizvi, et¬†al.

</span>
<span class="ltx_bibblock">Baseline radiomic signature to estimate overall survival in patients with nsclc.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib10.1.1">Journal of Thoracic Oncology</span>, 18(5):587‚Äì598, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
Markus Zimmermann, Christiane¬†K. Kuhl, Hanna Engelke, Gerhard Bettermann, and Sebastian Keil.

</span>
<span class="ltx_bibblock">Ct-based whole-body tumor volumetry versus recist 1.1: Feasibility and implications for inter-reader variability.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib11.1.1">European Journal of Radiology</span>, 135:109514, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
Ritu Tandon, Shweta Agrawal, Narendra Pal¬†Singh Rathore, Abhinava¬†K. Mishra, and Sanjiv¬†Kumar Jain.

</span>
<span class="ltx_bibblock">A systematic review on deep learning-based automated cancer diagnosis models.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib12.1.1">Journal of Cellular and Molecular Medicine</span>, 28(6):e18144, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
Ashish Vaswani, Noam¬†M. Shazeer, Niki Parmar, et¬†al.

</span>
<span class="ltx_bibblock">Attention is all you need.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib13.1.1">Advances in Neural Information Processing Systems</span>, pages 5998‚Äì6008, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
Rishi Bommasani, Drew¬†A Hudson, Ehsan Adeli, et¬†al.

</span>
<span class="ltx_bibblock">On the opportunities and risks of foundation models.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib14.1.1">arXiv preprint arXiv:2108.07258</span>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
Bobby Azad, Reza Azad, Sania Eskandari, et¬†al.

</span>
<span class="ltx_bibblock">Foundational models in medical imaging: A comprehensive survey and future vision.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib15.1.1">arXiv preprint arXiv:2310.18689</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
Alexander Kirillov, Eric Mintun, Nikhila Ravi, et¬†al.

</span>
<span class="ltx_bibblock">Segment anything.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib16.1.1">arXiv preprint arXiv:2304.02643</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
Jun Ma, Yuting He, Feifei Li, Lin Han, Chenyu You, and Bo¬†Wang.

</span>
<span class="ltx_bibblock">Segment anything in medical images.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib17.1.1">Nature Communications</span>, 15(1):654, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
Yuxin Du, Fan Bai, Tiejun Huang, et¬†al.

</span>
<span class="ltx_bibblock">Segvol: Universal and interactive volumetric medical image segmentation.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib18.1.1">arXiv preprint arXiv:2311.13385</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
Haoyu Wang, Sizheng Guo, Jin Ye, et¬†al.

</span>
<span class="ltx_bibblock">Sam-med3d.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib19.1.1">arXiv preprint arXiv:2310.15161</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
M.¬†J. J.¬†de Grauw, E.¬†Th Scholten, E.¬†J. Smit, et¬†al.

</span>
<span class="ltx_bibblock">The uls23 challenge: A baseline model and benchmark dataset for 3d universal lesion segmentation in computed tomography.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib20.1.1">arXiv preprint arXiv:2406.05231</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
Fabian Isensee, Paul¬†F. Jaeger, Simon A.¬†A. Kohl, et¬†al.

</span>
<span class="ltx_bibblock">nnu-net: A self-configuring method for deep learning-based biomedical image segmentation.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib21.1.1">Nature Methods</span>, 18(2):203‚Äì211, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
Jakob Wasserthal, Hanns-Christian Breit, Manfred¬†T. Meyer, et¬†al.

</span>
<span class="ltx_bibblock">Totalsegmentator: Robust segmentation of 104 anatomical structures in ct images.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib22.1.1">arXiv preprint arXiv:2208.05868</span>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
Ke¬†Yan, Xiaosong Wang, Le¬†Lu, and Ronald¬†M. Summers.

</span>
<span class="ltx_bibblock">Deeplesion: Automated mining of large-scale lesion annotations and universal lesion detection with deep learning.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib23.1.1">Journal of Medical Imaging (Bellingham, Wash.)</span>, 5(3):036501, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
Michela Antonelli, Annika Reinke, Spyridon Bakas, et¬†al.

</span>
<span class="ltx_bibblock">The medical segmentation decathlon.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib24.1.1">Nature Communications</span>, 13(1):4128, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
Jo√£o Pedrosa, Guilherme Aresta, Carlos Ferreira, Gurraj Atwal, Hady Ahmady¬†Phoulady, Xiaoyu Chen, Rongzhen Chen, et¬†al.

</span>
<span class="ltx_bibblock">Lndb challenge on automatic lung cancer patient management.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib25.1.1">Medical Image Analysis</span>, 70:102027, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
Nicholas Heller, Fabian Isensee, Darya Trofimova, et¬†al.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib26.1.1">Kidney and Kidney Tumor Segmentation: MICCAI 2021 Challenge, KiTS 2021, Held in Conjunction with MICCAI 2021, Strasbourg, France, September 27, 2021, Proceedings</span>.

</span>
<span class="ltx_bibblock">Springer Nature, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
Patrick Bilic, Patrick Christ, Hongwei¬†Bran Li, et¬†al.

</span>
<span class="ltx_bibblock">The liver tumor segmentation benchmark (lits).

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib27.1.1">Medical Image Analysis</span>, 84:102680, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
Holger Roth, Amal Farag, Le¬†Lu, et¬†al.

</span>
<span class="ltx_bibblock">A new 2.5 d representation for lymph node detection in ct (ct lymph nodes).

</span>
<span class="ltx_bibblock">The Cancer Imaging Archive, 2015.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
Samuel¬†G Armato, Geoffrey McLennan, Luc Bidaut, et¬†al.

</span>
<span class="ltx_bibblock">The lung image database consortium (lidc) and image database resource initiative (idri): A completed reference database of lung nodules on ct scans.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib29.1.1">Medical Physics</span>, 38(2):915‚Äì931, 2011.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<section class="ltx_section" id="Sx2">
<h2 class="ltx_title ltx_title_section">Supplementary Figures</h2>
<figure class="ltx_figure" id="Sx2.F6">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="Sx2.F6.1" style="width:433.6pt;">
<p class="ltx_p" id="Sx2.F6.1.1"><span class="ltx_text ltx_inline-block" id="Sx2.F6.1.1.1" style="width:433.6pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="158" id="Sx2.F6.1.1.1.g1" src="extracted/5918755/figs1.png" width="598"/></span></p>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure S1: </span><span class="ltx_text ltx_font_bold" id="Sx2.F6.1.3.1">ONCOPILOT Long Axis Performance Across Different Organs</span> (A) Table showing the mean and median long-axis measurements (in mm) for the various organ types in the test set. (B) Example of a suboptimal segmentation by ONCOPILOT on a small lung nodule from the LIDC-IDRI dataset with magnification of the overlay on the rightmost panel, with a DICE of 0.66 in point mode.</figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="Sx2.F6.8" style="width:433.6pt;">
<p class="ltx_p" id="Sx2.F6.2.1"><span class="ltx_text ltx_inline-block" id="Sx2.F6.2.1.1" style="width:433.6pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="239" id="Sx2.F6.2.1.1.g1" src="extracted/5918755/figs2.png" width="598"/></span></p>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure S2: </span><span class="ltx_text ltx_font_bold" id="Sx2.F6.8.9.1">ONCOPILOT Morphology Evaluation</span> (A) Density plot showing the distribution of DICE scores from ONCOPILOT segmentation masks in point mode (red) and point-edit mode (blue) for spherical lesions (sphericity <math alttext="&gt;0.6" class="ltx_Math" display="inline" id="Sx2.F6.6.5.m1.1"><semantics id="Sx2.F6.6.5.m1.1b"><mrow id="Sx2.F6.6.5.m1.1.1" xref="Sx2.F6.6.5.m1.1.1.cmml"><mi id="Sx2.F6.6.5.m1.1.1.2" xref="Sx2.F6.6.5.m1.1.1.2.cmml"></mi><mo id="Sx2.F6.6.5.m1.1.1.1" xref="Sx2.F6.6.5.m1.1.1.1.cmml">&gt;</mo><mn id="Sx2.F6.6.5.m1.1.1.3" xref="Sx2.F6.6.5.m1.1.1.3.cmml">0.6</mn></mrow><annotation-xml encoding="MathML-Content" id="Sx2.F6.6.5.m1.1c"><apply id="Sx2.F6.6.5.m1.1.1.cmml" xref="Sx2.F6.6.5.m1.1.1"><gt id="Sx2.F6.6.5.m1.1.1.1.cmml" xref="Sx2.F6.6.5.m1.1.1.1"></gt><csymbol cd="latexml" id="Sx2.F6.6.5.m1.1.1.2.cmml" xref="Sx2.F6.6.5.m1.1.1.2">absent</csymbol><cn id="Sx2.F6.6.5.m1.1.1.3.cmml" type="float" xref="Sx2.F6.6.5.m1.1.1.3">0.6</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx2.F6.6.5.m1.1d">&gt;0.6</annotation><annotation encoding="application/x-llamapun" id="Sx2.F6.6.5.m1.1e">&gt; 0.6</annotation></semantics></math>) versus irregular lesions (see Methods for the sphericity formula). (B) Density plot showing the distribution of DICE scores from ONCOPILOT segmentation masks in point mode (red) and point-edit mode (blue) for large lesions (long axis <math alttext="&gt;15" class="ltx_Math" display="inline" id="Sx2.F6.7.6.m2.1"><semantics id="Sx2.F6.7.6.m2.1b"><mrow id="Sx2.F6.7.6.m2.1.1" xref="Sx2.F6.7.6.m2.1.1.cmml"><mi id="Sx2.F6.7.6.m2.1.1.2" xref="Sx2.F6.7.6.m2.1.1.2.cmml"></mi><mo id="Sx2.F6.7.6.m2.1.1.1" xref="Sx2.F6.7.6.m2.1.1.1.cmml">&gt;</mo><mn id="Sx2.F6.7.6.m2.1.1.3" xref="Sx2.F6.7.6.m2.1.1.3.cmml">15</mn></mrow><annotation-xml encoding="MathML-Content" id="Sx2.F6.7.6.m2.1c"><apply id="Sx2.F6.7.6.m2.1.1.cmml" xref="Sx2.F6.7.6.m2.1.1"><gt id="Sx2.F6.7.6.m2.1.1.1.cmml" xref="Sx2.F6.7.6.m2.1.1.1"></gt><csymbol cd="latexml" id="Sx2.F6.7.6.m2.1.1.2.cmml" xref="Sx2.F6.7.6.m2.1.1.2">absent</csymbol><cn id="Sx2.F6.7.6.m2.1.1.3.cmml" type="integer" xref="Sx2.F6.7.6.m2.1.1.3">15</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx2.F6.7.6.m2.1d">&gt;15</annotation><annotation encoding="application/x-llamapun" id="Sx2.F6.7.6.m2.1e">&gt; 15</annotation></semantics></math> mm) versus smaller lesions. (C) Density plot showing the distribution of DICE scores from ONCOPILOT segmentation masks in point mode (red) and point-edit mode (blue) for voluminous lesions (volume <math alttext="&gt;1" class="ltx_Math" display="inline" id="Sx2.F6.8.7.m3.1"><semantics id="Sx2.F6.8.7.m3.1b"><mrow id="Sx2.F6.8.7.m3.1.1" xref="Sx2.F6.8.7.m3.1.1.cmml"><mi id="Sx2.F6.8.7.m3.1.1.2" xref="Sx2.F6.8.7.m3.1.1.2.cmml"></mi><mo id="Sx2.F6.8.7.m3.1.1.1" xref="Sx2.F6.8.7.m3.1.1.1.cmml">&gt;</mo><mn id="Sx2.F6.8.7.m3.1.1.3" xref="Sx2.F6.8.7.m3.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="Sx2.F6.8.7.m3.1c"><apply id="Sx2.F6.8.7.m3.1.1.cmml" xref="Sx2.F6.8.7.m3.1.1"><gt id="Sx2.F6.8.7.m3.1.1.1.cmml" xref="Sx2.F6.8.7.m3.1.1.1"></gt><csymbol cd="latexml" id="Sx2.F6.8.7.m3.1.1.2.cmml" xref="Sx2.F6.8.7.m3.1.1.2">absent</csymbol><cn id="Sx2.F6.8.7.m3.1.1.3.cmml" type="integer" xref="Sx2.F6.8.7.m3.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx2.F6.8.7.m3.1d">&gt;1</annotation><annotation encoding="application/x-llamapun" id="Sx2.F6.8.7.m3.1e">&gt; 1</annotation></semantics></math> mL) versus smaller lesions.</figcaption>
</figure>
</div>
</div>
</figure>
<figure class="ltx_figure" id="Sx2.F7">
<p class="ltx_p ltx_align_center" id="Sx2.F7.1"><span class="ltx_text ltx_inline-block" id="Sx2.F7.1.1" style="width:433.6pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="343" id="Sx2.F7.1.1.g1" src="extracted/5918755/figs3.png" width="598"/></span></p>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure S3: </span><span class="ltx_text ltx_font_bold" id="Sx2.F7.3.1">ONCOPILOT Integration into a DICOM Viewer</span> (A) Overview of our in-house viewer featuring ONCOPILOT segmentation options and an interactive chat window for queries. A hypoattenuating liver lesion to be measured is depicted. (B) Depiction of different measurement modes: left panel : manual long-axis measurement; middle panel : bounding-box segmentation; right panel : point-click segmentation. (C) A proposed segmentation mask following bounding-box segmentation, showing slight over-segmentation at the anterior part of the lesion. (D) A proposed segmentation mask after interactive editing with the user to correct over-segmentation. (E) Interactive retrieval of measurements through a chat window.</figcaption>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Fri Oct 11 07:15:16 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
