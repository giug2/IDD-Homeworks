<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>SkillMatch: Evaluating Self-supervised Learning of Skill Relatedness</title>
<!--Generated on Mon Oct  7 13:00:53 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<meta content="Skill Relatedness Semantic Text Similarity Information Extraction." lang="en" name="keywords"/>
<base href="/html/2410.05006v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.05006v1#S1" title="In SkillMatch: Evaluating Self-supervised Learning of Skill Relatedness"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Motivation and Related Work</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.05006v1#S2" title="In SkillMatch: Evaluating Self-supervised Learning of Skill Relatedness"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Construction of <span class="ltx_text ltx_font_smallcaps">SkillMatch</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.05006v1#S3" title="In SkillMatch: Evaluating Self-supervised Learning of Skill Relatedness"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Methodology</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05006v1#S3.SS0.SSS1" title="In 3 Methodology ‚Ä£ SkillMatch: Evaluating Self-supervised Learning of Skill Relatedness"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.0.1 </span>Static vector baselines</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05006v1#S3.SS0.SSS2" title="In 3 Methodology ‚Ä£ SkillMatch: Evaluating Self-supervised Learning of Skill Relatedness"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.0.2 </span>Contextual models</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.05006v1#S4" title="In SkillMatch: Evaluating Self-supervised Learning of Skill Relatedness"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Experiments and Results</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05006v1#S4.SS1" title="In 4 Experiments and Results ‚Ä£ SkillMatch: Evaluating Self-supervised Learning of Skill Relatedness"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Results</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.05006v1#S5" title="In SkillMatch: Evaluating Self-supervised Learning of Skill Relatedness"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Conclusion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2410.05006v1#Pt0.A1" title="In SkillMatch: Evaluating Self-supervised Learning of Skill Relatedness"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A </span>Prompts</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2410.05006v1#Pt0.A2" title="In SkillMatch: Evaluating Self-supervised Learning of Skill Relatedness"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B </span>Training details</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05006v1#Pt0.A2.SS1" title="In Appendix B Training details ‚Ä£ SkillMatch: Evaluating Self-supervised Learning of Skill Relatedness"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B.1 </span>Word2Vec</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05006v1#Pt0.A2.SS2" title="In Appendix B Training details ‚Ä£ SkillMatch: Evaluating Self-supervised Learning of Skill Relatedness"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B.2 </span>fastText</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05006v1#Pt0.A2.SS3" title="In Appendix B Training details ‚Ä£ SkillMatch: Evaluating Self-supervised Learning of Skill Relatedness"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B.3 </span>Sentence-BERT fine-tuning</span></a></li>
</ol>
</li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line"><span class="ltx_note ltx_role_institutetext" id="id1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">institutetext: </span>Ghent University ‚Äì imec, 9052 Gent, Belgium 
<br class="ltx_break"/>
<span class="ltx_note ltx_role_email" id="id1.1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">email: </span>{jensjoris.decorte, thomas.demeester, chris.develder}@ugent.be</span></span></span>
<br class="ltx_break"/><a class="ltx_ref ltx_url" href="https://ugentt2k.github.io/" title="">https://ugentt2k.github.io/</a>
</span></span></span><span class="ltx_note ltx_role_institutetext" id="id2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_note_type">institutetext: </span>TechWolf, 9000 Gent, Belgium
<br class="ltx_break"/><span class="ltx_note ltx_role_email" id="id2.1"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_note_type">email: </span>{jensjoris, jeroen}@techwolf.ai</span></span></span>
<br class="ltx_break"/><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://techwolf.ai/" title="">https://techwolf.ai/</a></span></span></span>
<h1 class="ltx_title ltx_title_document">
<span class="ltx_text ltx_font_smallcaps" id="id1.id1">SkillMatch</span>: Evaluating Self-supervised Learning of Skill Relatedness</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Jens-Joris¬†Decorte
</span><span class="ltx_author_notes">1122</span></span>
<span class="ltx_author_before">‚ÄÉ‚ÄÉ</span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Jeroen¬†Van¬†Hautte
</span><span class="ltx_author_notes">22</span></span>
<span class="ltx_author_before">‚ÄÉ‚ÄÉ</span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
<br class="ltx_break"/>Thomas¬†Demeester
</span><span class="ltx_author_notes">11</span></span>
<span class="ltx_author_before">‚ÄÉ‚ÄÉ</span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Chris¬†Develder
</span><span class="ltx_author_notes">11</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id2.id1">Accurately modeling the relationships between skills is a crucial part of human resources processes such as recruitment and employee development.
Yet, no benchmarks exist to evaluate such methods directly.
We construct and release <span class="ltx_text ltx_font_smallcaps" id="id2.id1.1">SkillMatch</span>, a benchmark for the task of skill relatedness, based on expert knowledge mining from millions of job ads.
Additionally, we propose a scalable self-supervised learning technique to adapt a Sentence-BERT model based on skill co-occurrence in job ads.
This new method greatly surpasses traditional models for skill relatedness as measured on <span class="ltx_text ltx_font_smallcaps" id="id2.id1.2">SkillMatch</span>.
By releasing <span class="ltx_text ltx_font_smallcaps" id="id2.id1.3">SkillMatch</span> publicly, we aim to contribute a foundation for research towards increased accuracy and transparency of skill-based recommendation systems.</p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Keywords: </h6>Skill Relatedness Semantic Text Similarity Information Extraction.
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Motivation and Related Work</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Skills play a central role in human resources (HR) processes such as recruitment or learning and development.
Recommendation systems are often used in these processes to suggest actions based on skills.
Examples are ranking candidates for a job, or suggesting learning content to employees.
However, relying solely on the explicit presence of a given skill would neglect the complex relations between skills in the real world.
In recruitment, taking related skills into account will increase the relevant candidate pool and ensure that all relevant candidates are considered.
Similarly, considering these related skills helps to more accurately identify skill gaps within an organization and effectively recommend appropriate courses to employees.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">Several works study the usage of these skill relations as part of a job recommendation.
Static word vector methods have been used to compare resume and job ads content, including skills, in the context of job recommendation¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05006v1#bib.bib7" title="">7</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.05006v1#bib.bib14" title="">14</a>]</cite>.
More recent approaches use a joint representation learning framework to represent jobs and skills based on graphs of job and skill relations¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05006v1#bib.bib2" title="">2</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.05006v1#bib.bib9" title="">9</a>]</cite>.
In these works, evaluation solely focuses on downstream task performance.
However, it is unclear whether the obtained skill representations accurately reflect the relatedness between skills, given the absence of direct, intrinsic evaluation thereof.
Furthermore, evaluation on downstream tasks like job recommendation can hide task-specific biases in these representations, and does not ensure their validity for other uses.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">Preliminary work on the intrinsic evaluation of skill representation methods relies on manual annotation by domain experts, and is therefore limited in scale.
An early method relies on semantic role features extracted from parse trees to capture skill similarity¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05006v1#bib.bib11" title="">11</a>]</cite>.
However, the corresponding human evaluation data, which comprises a limited set of 75 skill pairs with similarity rated on a five point scale, is not publicly available.
Similarly, Gandhi et al.¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05006v1#bib.bib3" title="">3</a>]</cite> use a set of 600 pairs of skills annotated on a three point scale for the evaluation of their method.
In another instance, qualitative feedback from subject matter experts is used to evaluate a learned model of skill relatedness in a large IT organization¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05006v1#bib.bib15" title="">15</a>]</cite>.
Le et al.¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05006v1#bib.bib8" title="">8</a>]</cite> propose Skill2Vec, a method based on the popular Word2Vec method that learns static vectors for a vocabulary of skills, based on their presence in job ads.
They ask domain experts to manually select the relevant skills out of the five nearest neighbors, for 200 different samples.
For all the aforementioned works, the annotation effort required for their intrinsic evaluation is not scalable, and their data is not released.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">With our work, we aim to tackle this lack of intrinsic evaluation, by constructing and releasing <span class="ltx_text ltx_font_smallcaps" id="S1.p4.1.1">SkillMatch</span>, a first-of-its-kind comprehensive benchmark for the skill relatedness task.
The dataset is available at <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://huggingface.co/datasets/jensjorisdecorte/SkillMatch-1K" title="">https://huggingface.co/datasets/jensjorisdecorte/SkillMatch-1K</a>.
It is based on a robust distillation of expert knowledge drawn from millions of job ads.
We start by describing the construction of the <span class="ltx_text ltx_font_smallcaps" id="S1.p4.1.2">SkillMatch</span> benchmark in ¬ß<a class="ltx_ref" href="https://arxiv.org/html/2410.05006v1#S2" title="2 Construction of SkillMatch ‚Ä£ SkillMatch: Evaluating Self-supervised Learning of Skill Relatedness"><span class="ltx_text ltx_ref_tag">2</span></a>.
We set out to evaluate commonly used representation methods for skill relatedness, listed in ¬ß<a class="ltx_ref" href="https://arxiv.org/html/2410.05006v1#S3" title="3 Methodology ‚Ä£ SkillMatch: Evaluating Self-supervised Learning of Skill Relatedness"><span class="ltx_text ltx_ref_tag">3</span></a>, including a proposed new self-supervised objective to adapt a Sentence-BERT model¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05006v1#bib.bib13" title="">13</a>]</cite>.
This objective is specifically designed to enhance skill-skill relations based on co-occurrence in job ads.
Finally, we evaluate its performance of the new <span class="ltx_text ltx_font_smallcaps" id="S1.p4.1.3">SkillMatch</span> benchmark, and show the superior performance of our proposed self-supervised Sentence-BERT adaptation method in ¬ß<a class="ltx_ref" href="https://arxiv.org/html/2410.05006v1#S4" title="4 Experiments and Results ‚Ä£ SkillMatch: Evaluating Self-supervised Learning of Skill Relatedness"><span class="ltx_text ltx_ref_tag">4</span></a>.</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Construction of <span class="ltx_text ltx_font_smallcaps" id="S2.1.1">SkillMatch</span>
</h2>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">We create <span class="ltx_text ltx_font_smallcaps" id="S2.p1.1.1">SkillMatch</span>, a first-of-its-kind benchmark for the task of skill relatedness in the labor market.
The creation of <span class="ltx_text ltx_font_smallcaps" id="S2.p1.1.2">SkillMatch</span> relies on expert knowledge embedded across millions of job ads.
More specifically, we observe that hiring managers explicitly mention their equivalent preference toward two or more related skills.
One example of such an expression in a job ad is the following: <span class="ltx_text ltx_font_italic" id="S2.p1.1.3">‚ÄúExperience with platforms such as <span class="ltx_text ltx_framed ltx_framed_underline" id="S2.p1.1.3.1">Kubernetes</span>, <span class="ltx_text ltx_framed ltx_framed_underline" id="S2.p1.1.3.2">KafKa</span>, or <span class="ltx_text ltx_framed ltx_framed_underline" id="S2.p1.1.3.3">EKS</span>‚Äù</span>.
This lexical pattern, characterized by phrases like ‚Äúsuch as‚Äù, indicates that the underlined skills are considered equally relevant to the job requirements by the hiring manager.
When two skills are repeatedly mentioned together in this manner, it indicates that they are strongly related, and we base the creation of <span class="ltx_text ltx_font_smallcaps" id="S2.p1.1.4">SkillMatch</span> on this insight.
Through manual inspection, we construct two groups of lexical patterns, for a total of 15 patterns, that indicate these skill relations:</p>
</div>
<div class="ltx_para" id="S2.p2">
<ol class="ltx_enumerate" id="S2.I1">
<li class="ltx_item" id="S2.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="S2.I1.i1.p1">
<p class="ltx_p" id="S2.I1.i1.p1.1"><span class="ltx_text" id="S2.I1.i1.p1.1.1"><span class="ltx_text ltx_font_bold" id="S2.I1.i1.p1.1.1.1">X</span> {and/or} {other/related/similar/equivalent} ‚Ä¶ <span class="ltx_text ltx_font_bold" id="S2.I1.i1.p1.1.1.2">KW</span></span> (8 patterns)</p>
</div>
</li>
<li class="ltx_item" id="S2.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="S2.I1.i2.p1">
<p class="ltx_p" id="S2.I1.i2.p1.1"><span class="ltx_text" id="S2.I1.i2.p1.1.1"><span class="ltx_text ltx_font_bold" id="S2.I1.i2.p1.1.1.1">KW</span> ‚Ä¶ {such as/including/especially/for example/e.g./i.e.} <span class="ltx_text ltx_font_bold" id="S2.I1.i2.p1.1.1.2">X</span></span> (7 patterns)</p>
</div>
</li>
</ol>
</div>
<div class="ltx_para" id="S2.p3">
<p class="ltx_p" id="S2.p3.1">Here, <span class="ltx_text ltx_font_bold" id="S2.p3.1.1">X</span> refers to the location in which related skills are expected to be enumerated.
Furthermore, to ensure relevancy of the sentence, the other side of the sentence should contain one keyword out of <span class="ltx_text ltx_font_italic" id="S2.p3.1.2">skill, technique, knowledge, experience, background</span>, at least within a 30 character range, as indicated by <span class="ltx_text ltx_font_bold" id="S2.p3.1.3">KW</span>.
Stemming is used to increase the recall of this filter.
We note that the patterns are strongly inspired by the more commonly known Hearst patterns¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05006v1#bib.bib5" title="">5</a>]</cite>.
Nearly 32 million job ads were scanned for these patterns.
All ads are written in English and posted in the United States in 2024.
A total of 360,449 unique sentences were found to adhere to these patterns.</p>
</div>
<div class="ltx_para" id="S2.p4">
<p class="ltx_p" id="S2.p4.1">The related skills are extracted from the sentence using a simple few-shot learning strategy, constructing a prompt with examples.
We use the recently introduced Gemini 1.5 Flash<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://deepmind.google/technologies/gemini/flash/" title="">https://deepmind.google/technologies/gemini/flash/</a></span></span></span> model for its strong performance and cost efficiency.
We refer to Appendix¬†<a class="ltx_ref" href="https://arxiv.org/html/2410.05006v1#Pt0.A1" title="Appendix A Prompts ‚Ä£ SkillMatch: Evaluating Self-supervised Learning of Skill Relatedness"><span class="ltx_text ltx_ref_tag">A</span></a> for details on the prompt.
Afterwards, the casing of all extracted skills is normalized towards its most frequent form, such that for example both ‚Äúcss‚Äù and ‚ÄúCSS‚Äù are represented by their most common variant ‚ÄúCSS‚Äù.
Finally, related skill pairs are defined as those that co-occur at least 3 times, and have a conditional probability of 25% or above, in each direction.
This dual criterion ensures that only closely related skills are considered as positive examples.
Negative pairs were generated by randomly selecting skills that never appeared together in the lexical patterns, maintaining an equal number of negative and positive pairs to balance the benchmark.
The complete benchmark contains 1,000 positive pairs and an equal amount of negative pairs.
Some examples of related skill pairs in <span class="ltx_text ltx_font_smallcaps" id="S2.p4.1.1">SkillMatch</span> are shown in Table¬†<a class="ltx_ref" href="https://arxiv.org/html/2410.05006v1#S2.T1" title="Table 1 ‚Ä£ 2 Construction of SkillMatch ‚Ä£ SkillMatch: Evaluating Self-supervised Learning of Skill Relatedness"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
<figure class="ltx_table" id="S2.T1">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S2.T1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S2.T1.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S2.T1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S2.T1.1.1.1.1.1">Skill 1</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S2.T1.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S2.T1.1.1.1.2.1">Skill 2</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S2.T1.1.1.1.3"><span class="ltx_text ltx_font_bold" id="S2.T1.1.1.1.3.1">Frequency</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S2.T1.1.2.1">
<td class="ltx_td ltx_align_left ltx_border_t" id="S2.T1.1.2.1.1">HTML</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S2.T1.1.2.1.2">CSS</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T1.1.2.1.3">705</td>
</tr>
<tr class="ltx_tr" id="S2.T1.1.3.2">
<td class="ltx_td ltx_align_left" id="S2.T1.1.3.2.1">grammar</td>
<td class="ltx_td ltx_align_left" id="S2.T1.1.3.2.2">spelling</td>
<td class="ltx_td ltx_align_center" id="S2.T1.1.3.2.3">137</td>
</tr>
<tr class="ltx_tr" id="S2.T1.1.4.3">
<td class="ltx_td ltx_align_left" id="S2.T1.1.4.3.1">deep learning</td>
<td class="ltx_td ltx_align_left" id="S2.T1.1.4.3.2">natural language processing</td>
<td class="ltx_td ltx_align_center" id="S2.T1.1.4.3.3">66</td>
</tr>
<tr class="ltx_tr" id="S2.T1.1.5.4">
<td class="ltx_td ltx_align_left" id="S2.T1.1.5.4.1">GDPR</td>
<td class="ltx_td ltx_align_left" id="S2.T1.1.5.4.2">CCPA</td>
<td class="ltx_td ltx_align_center" id="S2.T1.1.5.4.3">41</td>
</tr>
<tr class="ltx_tr" id="S2.T1.1.6.5">
<td class="ltx_td ltx_align_left" id="S2.T1.1.6.5.1">AS9100</td>
<td class="ltx_td ltx_align_left" id="S2.T1.1.6.5.2">ISO 9001</td>
<td class="ltx_td ltx_align_center" id="S2.T1.1.6.5.3">14</td>
</tr>
<tr class="ltx_tr" id="S2.T1.1.7.6">
<td class="ltx_td ltx_align_left" id="S2.T1.1.7.6.1">paid search</td>
<td class="ltx_td ltx_align_left" id="S2.T1.1.7.6.2">paid social</td>
<td class="ltx_td ltx_align_center" id="S2.T1.1.7.6.3">7</td>
</tr>
<tr class="ltx_tr" id="S2.T1.1.8.7">
<td class="ltx_td ltx_align_left" id="S2.T1.1.8.7.1">Single Sign-On (SSO)</td>
<td class="ltx_td ltx_align_left" id="S2.T1.1.8.7.2">Multi-Factor Authentication (MFA)</td>
<td class="ltx_td ltx_align_center" id="S2.T1.1.8.7.3">6</td>
</tr>
<tr class="ltx_tr" id="S2.T1.1.9.8">
<td class="ltx_td ltx_align_left ltx_border_bb" id="S2.T1.1.9.8.1">payroll software</td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="S2.T1.1.9.8.2">benefits software</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S2.T1.1.9.8.3">5</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Examples of related skill pairs in <span class="ltx_text ltx_font_smallcaps" id="S2.T1.3.1">SkillMatch</span>.</figcaption>
</figure>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Methodology</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">We use representation learning as the basis for expressing skill relatedness.
In this setup, a model takes a skill phrase as input and transforms it into a multidimensional vector.
The relatedness of a pair of skills is then indicated by the cosine similarity of their respective vectors.</p>
</div>
<section class="ltx_subsubsection" id="S3.SS0.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.0.1 </span>Static vector baselines</h4>
<div class="ltx_para" id="S3.SS0.SSS1.p1">
<p class="ltx_p" id="S3.SS0.SSS1.p1.1">We implement static vector methods to represent and compare skills, as they have traditionally been used a lot to represent skills.
We implement both the Word2Vec Skip-gram¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05006v1#bib.bib10" title="">10</a>]</cite> and the fastText¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05006v1#bib.bib1" title="">1</a>]</cite> algorithms.
For both algorithms, we use an off-the-shelf model trained on generic text, and we train a domain-specific model on a large corpus of job ads.
When a skill consists of multiple words in the Word2Vec models, the weighted sum of their constituent words‚Äô vectors is used to represent a phrase, where the inverse frequency of the words in the training corpus are used as weights.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S3.SS0.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.0.2 </span>Contextual models</h4>
<div class="ltx_para" id="S3.SS0.SSS2.p1">
<p class="ltx_p" id="S3.SS0.SSS2.p1.2">Static word vectors fail to represent the different meanings of words based on the context.
In contrast, transformer-based models such as Sentence-BERT produce contextual representations that capture the semantic meaning of the full input¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05006v1#bib.bib13" title="">13</a>]</cite>.
We propose a new method to adapt a pre-trained Sentence-BERT model for the task of skill relatedness, based on the co-occurrence of skills in a large corpus of job ads.
It requires a preprocessing step of extracting all skill spans from a job ad, which can be achieved through dedicated models as in <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05006v1#bib.bib16" title="">16</a>]</cite> or through the use of an LLM.
This results in a corpus where each job ad is represented by a list of skill spans, in order of appearance.
A job ad with <math alttext="N" class="ltx_Math" display="inline" id="S3.SS0.SSS2.p1.1.m1.1"><semantics id="S3.SS0.SSS2.p1.1.m1.1a"><mi id="S3.SS0.SSS2.p1.1.m1.1.1" xref="S3.SS0.SSS2.p1.1.m1.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS2.p1.1.m1.1b"><ci id="S3.SS0.SSS2.p1.1.m1.1.1.cmml" xref="S3.SS0.SSS2.p1.1.m1.1.1">ùëÅ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS2.p1.1.m1.1c">N</annotation><annotation encoding="application/x-llamapun" id="S3.SS0.SSS2.p1.1.m1.1d">italic_N</annotation></semantics></math> skill spans is then converted into <math alttext="N-1" class="ltx_Math" display="inline" id="S3.SS0.SSS2.p1.2.m2.1"><semantics id="S3.SS0.SSS2.p1.2.m2.1a"><mrow id="S3.SS0.SSS2.p1.2.m2.1.1" xref="S3.SS0.SSS2.p1.2.m2.1.1.cmml"><mi id="S3.SS0.SSS2.p1.2.m2.1.1.2" xref="S3.SS0.SSS2.p1.2.m2.1.1.2.cmml">N</mi><mo id="S3.SS0.SSS2.p1.2.m2.1.1.1" xref="S3.SS0.SSS2.p1.2.m2.1.1.1.cmml">‚àí</mo><mn id="S3.SS0.SSS2.p1.2.m2.1.1.3" xref="S3.SS0.SSS2.p1.2.m2.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS2.p1.2.m2.1b"><apply id="S3.SS0.SSS2.p1.2.m2.1.1.cmml" xref="S3.SS0.SSS2.p1.2.m2.1.1"><minus id="S3.SS0.SSS2.p1.2.m2.1.1.1.cmml" xref="S3.SS0.SSS2.p1.2.m2.1.1.1"></minus><ci id="S3.SS0.SSS2.p1.2.m2.1.1.2.cmml" xref="S3.SS0.SSS2.p1.2.m2.1.1.2">ùëÅ</ci><cn id="S3.SS0.SSS2.p1.2.m2.1.1.3.cmml" type="integer" xref="S3.SS0.SSS2.p1.2.m2.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS2.p1.2.m2.1c">N-1</annotation><annotation encoding="application/x-llamapun" id="S3.SS0.SSS2.p1.2.m2.1d">italic_N - 1</annotation></semantics></math> positive training pairs, each consisting of two adjacent skills in the list.
These positive pairs are used to adapt the Sentence-BERT model with a contrastive learning objective, employing in-batch negatives through the InfoNCE loss function, as proposed by <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05006v1#bib.bib6" title="">6</a>]</cite>.
This optimization leads the model to produce similar vector representations for skills that frequently occur in succession, thus encoding the nuanced relationships between skills more effectively.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experiments and Results</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">For the generic Word2Vec model, we use <span class="ltx_text ltx_font_italic" id="S4.p1.1.1">word2vec-google-news-300<span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note"><span class="ltx_text ltx_font_upright" id="footnote2.1.1.1">2</span></span><a class="ltx_ref ltx_url ltx_font_typewriter ltx_font_upright" href="https://code.google.com/archive/p/word2vec/" title="">https://code.google.com/archive/p/word2vec/</a></span></span></span></span>, which has 300-dimensional vectors, trained on the Google News dataset.
For the generic fastText vectors, we use <span class="ltx_text ltx_font_italic" id="S4.p1.1.2">cc.en.300.bin</span>, a 300-dimensional vector model trained on Common Crawl and Wikipedia¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05006v1#bib.bib4" title="">4</a>]</cite>.
To train their domain-specific versions, we use a dataset of 755k job ads, also from 2024.
Note that these are not included in the dataset used to construct <span class="ltx_text ltx_font_smallcaps" id="S4.p1.1.3">SkillMatch</span>.
For the general domain Sentence-BERT model we use a model that is pre-trained on over 1B pairs of semantically similar sentences¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05006v1#bib.bib13" title="">13</a>]</cite>.<span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://huggingface.co/sentence-transformers/all-distilroberta-v1" title="">https://huggingface.co/sentence-transformers/all-distilroberta-v1</a></span></span></span>
We fine-tune this base model through contrastive learning on the adjacent skill phrase pairs.
The model is trained on a total of over 8.2 million skill phrase pairs.
We refer to Appendix¬†<a class="ltx_ref" href="https://arxiv.org/html/2410.05006v1#Pt0.A2" title="Appendix B Training details ‚Ä£ SkillMatch: Evaluating Self-supervised Learning of Skill Relatedness"><span class="ltx_text ltx_ref_tag">B</span></a> for details on training hyperparameters.
Performance on <span class="ltx_text ltx_font_smallcaps" id="S4.p1.1.4">SkillMatch</span> is measured by the area under the precision-recall curve (AUC-PR) for the pooled positive and negative pairs in the benchmark, where the cosine similarity between the skill embeddings represents the extent to which two skills are related according to the learned representation model.
Additionally, for each skill in a given positive pair, the reciprocal rank of the matching skill is calculated, among the ranking of all other skills in the benchmark (from both positive and negative pairs). We report the mean reciprocal rank (MRR).</p>
</div>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Results</h3>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">The performance on <span class="ltx_text ltx_font_smallcaps" id="S4.SS1.p1.1.1">SkillMatch</span> for each method is shown in Table¬†<a class="ltx_ref" href="https://arxiv.org/html/2410.05006v1#S4.T2" title="Table 2 ‚Ä£ 4.1 Results ‚Ä£ 4 Experiments and Results ‚Ä£ SkillMatch: Evaluating Self-supervised Learning of Skill Relatedness"><span class="ltx_text ltx_ref_tag">2</span></a>.
Our contrastive learning objective for the Sentence-BERT model significantly outperforms all other models.
This shows the effectiveness of modeling skill relatedness based on skill co-occurrence in job ads.
The domain-specific static vectors outperform their generic versions, despite being trained on fewer data.
Notably, the generic Word2Vec model performs much worse compared to the fastText model.
Further analysis reveals that this is due to words not being modeled in the generic Word2Vec model.
The number of skill phrases in <span class="ltx_text ltx_font_smallcaps" id="S4.SS1.p1.1.2">SkillMatch</span> without a Word2Vec representation drops from 193 to 36 when using the domain-specific model.
fastText does not suffer from this out-of-vocabulary issue by design.</p>
</div>
<figure class="ltx_table" id="S4.T2">
<div class="ltx_flex_figure ltx_flex_table">
<div class="ltx_flex_cell ltx_flex_size_1">
<table class="ltx_tabular ltx_centering ltx_figure_panel ltx_guessed_headers ltx_align_middle" id="S4.T2.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T2.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt" id="S4.T2.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.1.1.1">Method</span></th>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T2.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.1.2.1">AUC-PR</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T2.1.1.1.3"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.1.3.1">MRR</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.2.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T2.1.2.2.1">Word2Vec</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.2.2.2">0.844</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.2.2.3">0.187</td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.3.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T2.1.3.3.1">Word2Vec<sup class="ltx_sup" id="S4.T2.1.3.3.1.1"><span class="ltx_text ltx_font_smallcaps" id="S4.T2.1.3.3.1.1.1">ds</span></sup>
</th>
<td class="ltx_td ltx_align_center" id="S4.T2.1.3.3.2">0.922</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.3.3.3">0.300</td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.4.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T2.1.4.4.1">fastText</th>
<td class="ltx_td ltx_align_center" id="S4.T2.1.4.4.2">0.913</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.4.4.3">0.262</td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.5.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T2.1.5.5.1">fastText<sup class="ltx_sup" id="S4.T2.1.5.5.1.1"><span class="ltx_text ltx_font_smallcaps" id="S4.T2.1.5.5.1.1.1">ds</span></sup>
</th>
<td class="ltx_td ltx_align_center" id="S4.T2.1.5.5.2">0.941</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.5.5.3">0.325</td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.6.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T2.1.6.6.1">Sentence-BERT</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.6.6.2">0.876</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.6.6.3">0.145</td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.7.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S4.T2.1.7.7.1">Sentence-BERT<sup class="ltx_sup" id="S4.T2.1.7.7.1.1"><span class="ltx_text ltx_font_smallcaps" id="S4.T2.1.7.7.1.1.1">ds</span></sup><span class="ltx_text ltx_phantom" id="S4.T2.1.7.7.1.2"><span style="visibility:hidden">x</span></span>
</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.1.7.7.2"><span class="ltx_text ltx_font_bold" id="S4.T2.1.7.7.2.1">0.969</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.1.7.7.3"><span class="ltx_text ltx_font_bold" id="S4.T2.1.7.7.3.1">0.357</span></td>
</tr>
</tbody>
</table>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<ul class="ltx_itemize ltx_centering ltx_figure_panel" id="S4.I1">
<li class="ltx_item" id="S4.I1.ix1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span class="ltx_text ltx_font_smallcaps" id="S4.I1.ix1.1.1.1">ds</span></span>
<div class="ltx_para" id="S4.I1.ix1.p1">
<p class="ltx_p" id="S4.I1.ix1.p1.1"><span class="ltx_text" id="S4.I1.ix1.p1.1.1" style="font-size:90%;">= domain-specific versions.</span></p>
</div>
</li>
</ul>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Comparison of model performance for the skill relatedness task. For the static vector models, the domain-specific versions refer to the models trained from scratch on job ads. For Sentence-BERT, the domain-specific model refers to its fine-tuned variant based on the proposed self-supervised skill co-occurrence objective.</figcaption>
</figure>
<div class="ltx_para" id="S4.SS1.p2">
<p class="ltx_p" id="S4.SS1.p2.1">Despite its popularity, the pretrained Sentence-BERT model is outperformed by generic fastText vectors.
We assume this is partly because Sentence-BERT models are trained to represent full sentences, which might harm their ability to meaningfully represent shorter phrases.
As such, our fine-tuning strategy for Sentence-BERT effectively serves both purposes of learning domain-specific skill relations, as well as learning to effectively represent shorter phrases instead of full sentences.</p>
</div>
<div class="ltx_para" id="S4.SS1.p3">
<p class="ltx_p" id="S4.SS1.p3.1">Finally, qualitative analysis of the skill relatedness scores allows inspecting the effect of our proposed Sentence-BERT fine-tuning approach.
Fig.¬†<a class="ltx_ref" href="https://arxiv.org/html/2410.05006v1#S4.F1" title="Figure 1 ‚Ä£ 4.1 Results ‚Ä£ 4 Experiments and Results ‚Ä£ SkillMatch: Evaluating Self-supervised Learning of Skill Relatedness"><span class="ltx_text ltx_ref_tag">1</span></a> displays one such example: a heatmap of similarity scores between two clusters of IT skills, being three web development related (<span class="ltx_text ltx_font_italic" id="S4.SS1.p3.1.1">HTML, CSS, JavaScript</span>) and three machine learning related skills (<span class="ltx_text ltx_font_italic" id="S4.SS1.p3.1.2">ML, Deep Learning, NLP</span>).</p>
</div>
<figure class="ltx_figure" id="S4.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="262" id="S4.F1.g1" src="extracted/5907151/images/IT-skills-heatmap.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>A visualization of similarity scores between two clusters of skills (web development and machine learning), obtained through the pre-trained Sentence-BERT (left) and its fine-tuned counterpart (right). Clusters become clearly visible after fine-tuning.</figcaption>
</figure>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusion</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">We introduce <span class="ltx_text ltx_font_smallcaps" id="S5.p1.1.1">SkillMatch</span>, a benchmark for evaluating skill relatedness, based on expert knowledge mined from millions of job ads.
We propose a new self-supervised technique to adapt a Sentence-BERT model for the task of skill relatedness, and show its effectiveness on <span class="ltx_text ltx_font_smallcaps" id="S5.p1.1.2">SkillMatch</span>.
With this contribution we hope to enable more research on the intrinsic evaluation of skill representation models, eventually to increase the accuracy and transparency of skill-based recommendation systems.</p>
</div>
</section>
<section class="ltx_section" id="Sx1">
<h2 class="ltx_title ltx_title_section">Limitations</h2>
<div class="ltx_para" id="Sx1.p1">
<p class="ltx_p" id="Sx1.p1.1"><span class="ltx_text ltx_font_smallcaps" id="Sx1.p1.1.1">SkillMatch</span> consists of binary annotations, while in reality, skill relatedness is a continuous spectrum, as some pairs of skills are more related than others.
It is not obvious how continuous values for relatedness could be accurately deduced from expert knowledge in job ads.
Secondly, applications that operate on a broader scale require an extension towards more languages and regions to ensure robust and accurate modeling of skill relations in different languages and cultures.
Finally, there are other interesting relations between skills, such as <span class="ltx_text ltx_font_italic" id="Sx1.p1.1.2">part-of</span> relations, that are not in the scope of this work.</p>
</div>
</section>
<section class="ltx_section" id="Sx2">
<h2 class="ltx_title ltx_title_section">Acknowledgments</h2>
<div class="ltx_para" id="Sx2.p1">
<p class="ltx_p" id="Sx2.p1.1">This project was funded by the Flemish Government, through Flanders Innovation &amp; Entrepreneurship (VLAIO, project HBC.2020.2893).</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
Bojanowski, P., Grave, E., Joulin, A., Mikolov, T.: Enriching word vectors with subword information. Transactions of the Association for Computational Linguistics <span class="ltx_text ltx_font_bold" id="bib.bib1.1.1">5</span>, 135‚Äì146 (2017). https://doi.org/10.1162/tacl_a_00051, <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/Q17-1010" title="">https://aclanthology.org/Q17-1010</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
Dave, V.S., Zhang, B., Al¬†Hasan, M., AlJadda, K., Korayem, M.: A combined representation learning approach for better job and skill recommendation. In: Proceedings of the 27th ACM International Conference on Information and Knowledge Management. p. 1997‚Äì2005. CIKM ‚Äô18, Association for Computing Machinery, New York, NY, USA (2018). https://doi.org/10.1145/3269206.3272023, <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3269206.3272023" title="">https://doi.org/10.1145/3269206.3272023</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
Gandhi, S., Nagesh, R., Das, S.: Learning skills adjacency representations for optimized reskilling recommendations. In: 2022 IEEE International Conference on Big Data (Big Data). pp. 2253‚Äì2258. IEEE (2022)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
Grave, E., Bojanowski, P., Gupta, P., Joulin, A., Mikolov, T.: Learning word vectors for 157 languages. In: Proceedings of the International Conference on Language Resources and Evaluation (LREC 2018) (2018)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
Hearst, M.A.: Automatic acquisition of hyponyms from large text corpora. In: COLING 1992 volume 2: The 14th international conference on computational linguistics (1992)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
Henderson, M., Al-Rfou, R., Strope, B., Sung, Y.H., Luk√°cs, L., Guo, R., Kumar, S., Miklos, B., Kurzweil, R.: Efficient natural language response suggestion for smart reply. ArXiv <span class="ltx_text ltx_font_bold" id="bib.bib6.1.1">abs/1705.00652</span> (2017)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
Kara, A., Dani≈ü, F.S., Orman, G.K., Turhan, S.N., √ñzl√º, √ñ.A.: Job recommendation based on extracted skill embeddings. In: Arai, K. (ed.) Intelligent Systems and Applications. pp. 497‚Äì507. Springer International Publishing, Cham (2023)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
Le, V.D., Quan, V.M., An, D.Q.: Skill2vec: Machine learning approaches for determining the relevant skill from job description. ArXiv <span class="ltx_text ltx_font_bold" id="bib.bib8.1.1">abs/1707.09751</span> (2017), <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://api.semanticscholar.org/CorpusID:4376242" title="">https://api.semanticscholar.org/CorpusID:4376242</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
Liu, M., Wang, J., Abdelfatah, K., Korayem, M.: Tripartite vector representations for better job recommendation (2019)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
Mikolov, T., Chen, K., Corrado, G., Dean, J.: Efficient estimation of word representations in vector space. Proceedings of Workshop at ICLR <span class="ltx_text ltx_font_bold" id="bib.bib10.1.1">2013</span> (01 2013)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
Pan, F., Farrell, R.: Computing semantic similarity between skill statements for approximate matching. In: Sidner, C., Schultz, T., Stone, M., Zhai, C. (eds.) Human Language Technologies 2007: The Conference of the North American Chapter of the Association for Computational Linguistics; Proceedings of the Main Conference. pp. 572‚Äì579. Association for Computational Linguistics, Rochester, New York (Apr 2007), <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/N07-1072" title="">https://aclanthology.org/N07-1072</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
≈òeh≈Ø≈ôek, R., Sojka, P.: Software Framework for Topic Modelling with Large Corpora. In: Proceedings of the LREC 2010 Workshop on New Challenges for NLP Frameworks. pp. 45‚Äì50. ELRA, Valletta, Malta (May 2010), <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://is.muni.cz/publication/884893/en" title="">http://is.muni.cz/publication/884893/en</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
Reimers, N., Gurevych, I.: Sentence-BERT: Sentence embeddings using Siamese BERT-networks. In: Inui, K., Jiang, J., Ng, V., Wan, X. (eds.) Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP). pp. 3982‚Äì3992. Association for Computational Linguistics, Hong Kong, China (Nov 2019). https://doi.org/10.18653/v1/D19-1410

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
Valverde-Rebaza, J., Puma, R., Bustios, P., Silva, N.C.: Job Recommendation based on Job Seeker Skills: An Empirical Study. In: Proceedings of the First Workshop on Narrative Extraction From Text (Text2Story 2018) co-located with The 40th European Conference on Information Retrieval (ECIR 2018). pp. 47‚Äì51 (2018)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
Vasudevan, S., Singh, M., Mondal, J., Peran, M., Zweig, B., Johnston, B., Rosenfeld, R.: Estimating fungibility between skills by combining skill similarities obtained from multiple data sources. Data Science and Engineering <span class="ltx_text ltx_font_bold" id="bib.bib15.1.1">3</span>, 248‚Äì262 (2018)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
Zhang, M., Jensen, K., Sonniks, S., Plank, B.: SkillSpan: Hard and soft skill extraction from English job postings. In: Carpuat, M., de¬†Marneffe, M.C., Meza¬†Ruiz, I.V. (eds.) Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. pp. 4962‚Äì4984. Association for Computational Linguistics, Seattle, United States (Jul 2022). https://doi.org/10.18653/v1/2022.naacl-main.366, <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/2022.naacl-main.366" title="">https://aclanthology.org/2022.naacl-main.366</a>
</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<section class="ltx_appendix" id="Pt0.A1">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Prompts</h2>
<div class="ltx_para" id="Pt0.A1.p1">
<p class="ltx_p" id="Pt0.A1.p1.1">The following prompt is used to extract skill spans from job ads, as a preprocessing step for the Sentence-BERT fine-tuning procedure.
Note the placeholder <span class="ltx_text" id="Pt0.A1.p1.1.1">[Job Ad]</span>, which is replaced by the job ad from which skill spans need to be extracted.</p>
</div>
<div class="ltx_para ltx_noindent" id="Pt0.A1.p2">
<svg class="ltx_picture" height="448.47" id="Pt0.A1.p2.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,448.47) matrix(1 0 0 -1 0 0)"><g fill="#000000" fill-opacity="1.0"><path d="M 0 0 L 0 448.47 L 600 448.47 L 600 0 Z" style="stroke:none"></path></g><g fill="#F2F2F2" fill-opacity="1.0"><path d="M 0.69 0.69 L 0.69 447.78 L 599.31 447.78 L 599.31 0.69 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 6.23 3.46)"><foreignobject color="#000000" height="441.55" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="587.55">
<span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="Pt0.A1.p2.pic1.1.1.1.1.1" style="width:424.6pt;">
<span class="ltx_p" id="Pt0.A1.p2.pic1.1.1.1.1.1.1"><span class="ltx_text ltx_font_typewriter ltx_framed ltx_framed_underline" id="Pt0.A1.p2.pic1.1.1.1.1.1.1.1" style="font-size:80%;">System instruction</span></span>
<span class="ltx_p" id="Pt0.A1.p2.pic1.1.1.1.1.1.2"><span class="ltx_text ltx_font_typewriter" id="Pt0.A1.p2.pic1.1.1.1.1.1.2.1" style="font-size:80%;">You are a helpful HR expert. Your mission is to list all relevant skills mentioned in job ad responsibilities and qualifications, as a comma-separated list. Don‚Äôt mention vague terms like ‚Äòrelevant experience‚Äô.

<br class="ltx_break"/>
<br class="ltx_break"/><span class="ltx_text ltx_framed ltx_framed_underline" id="Pt0.A1.p2.pic1.1.1.1.1.1.2.1.1">Prompt</span>
<br class="ltx_break"/># Vacancy 1
<br class="ltx_break"/>As a Senior Software Engineer, you‚Äôll be a cornerstone of our Integrations team, developing and maintaining powerful APIs that enable seamless integrations. You‚Äôll be surrounded by brilliant minds eager to learn from your experience and insights. Your expertise will help scale our existing foundation and ensure we remain lean, smart and fun. If you‚Äôre a collaborative communicator who thrives in dynamic environments and finds joy in mentoring colleagues, we want you on our team!
<br class="ltx_break"/>Job requirements
<br class="ltx_break"/>You have 5+ years of practical experience in a software engineering role, preferably at different company stages
<br class="ltx_break"/>You‚Äôve gained deep expertise in Python, Django and/or Typescript backends
<br class="ltx_break"/>You‚Äôve system design experience with a focus on scalability and performance
<br class="ltx_break"/>You‚Äôre proficient in software development methodologies
<br class="ltx_break"/>You‚Äôve demonstrated excellent mentorship and communication skills
<br class="ltx_break"/>Apply now!
<br class="ltx_break"/>
<br class="ltx_break"/># Skills 1
<br class="ltx_break"/>Software engineering, Python, Django, Typescript backends, system design, scalability, system performance, software development methodologies, mentorship, communication skills.

<br class="ltx_break"/>
<br class="ltx_break"/># Vacancy 2

<br class="ltx_break"/><span class="ltx_text" id="Pt0.A1.p2.pic1.1.1.1.1.1.2.1.2">[Job Ad]</span>
<br class="ltx_break"/>
<br class="ltx_break"/># Skills 2<span class="ltx_text ltx_font_serif" id="Pt0.A1.p2.pic1.1.1.1.1.1.2.1.3"></span></span></span>
</span></foreignobject></g></g></svg>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
<div class="ltx_para" id="Pt0.A1.p3">
<p class="ltx_p" id="Pt0.A1.p3.1">The following prompt was used to extract the related skills from the sentences detected by the lexical patterns. Placeholder <span class="ltx_text" id="Pt0.A1.p3.1.1">[sentence]</span> is replaced by the sentence from which the related skills should be extracted.</p>
</div>
<div class="ltx_para ltx_noindent" id="Pt0.A1.p4">
<svg class="ltx_picture" height="282.43" id="Pt0.A1.p4.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,282.43) matrix(1 0 0 -1 0 0)"><g fill="#000000" fill-opacity="1.0"><path d="M 0 0 L 0 282.43 L 600 282.43 L 600 0 Z" style="stroke:none"></path></g><g fill="#F2F2F2" fill-opacity="1.0"><path d="M 0.69 0.69 L 0.69 281.74 L 599.31 281.74 L 599.31 0.69 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 6.23 3.46)"><foreignobject color="#000000" height="275.51" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="587.55">
<span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="Pt0.A1.p4.pic1.1.1.1.1.1" style="width:424.6pt;">
<span class="ltx_p" id="Pt0.A1.p4.pic1.1.1.1.1.1.1"><span class="ltx_text ltx_font_typewriter ltx_framed ltx_framed_underline" id="Pt0.A1.p4.pic1.1.1.1.1.1.1.1" style="font-size:80%;">System instruction</span></span>
<span class="ltx_p" id="Pt0.A1.p4.pic1.1.1.1.1.1.2"><span class="ltx_text ltx_font_typewriter" id="Pt0.A1.p4.pic1.1.1.1.1.1.2.1" style="font-size:80%;">Given a sentence from a job ad, deduct whether it contains a list of equivalently desired skills. Do not include vague terms like ‚Äôexperience‚Äô or ‚Äôknowledge‚Äô.

<br class="ltx_break"/>
<br class="ltx_break"/><span class="ltx_text ltx_framed ltx_framed_underline" id="Pt0.A1.p4.pic1.1.1.1.1.1.2.1.1">Prompt</span>
<br class="ltx_break"/>Sentence: Knowledge of supply chain management concepts such as product purchasing, pricing structures, and inventory control.
<br class="ltx_break"/>Equivalent skills list: product purchasing, pricing structures, inventory control
<br class="ltx_break"/>
<br class="ltx_break"/>Sentence: Comprehensive writing skills, including proper punctuation and grammar, organization, and formatting.
<br class="ltx_break"/>Equivalent skills list: punctuation, grammar, organization of texts, formatting documents
<br class="ltx_break"/>
<br class="ltx_break"/>Sentence: Knowledge of accounting operations to include all aspects such as accounts receivable accounts payable, etc.
<br class="ltx_break"/>Equivalent skills list: accounts receivable, accounts payable<span class="ltx_text ltx_font_serif" id="Pt0.A1.p4.pic1.1.1.1.1.1.2.1.2">
<br class="ltx_break"/>
<br class="ltx_break"/>Sentence: <span class="ltx_text" id="Pt0.A1.p4.pic1.1.1.1.1.1.2.1.2.1">[sentence]</span>
<br class="ltx_break"/>Equivalent skills list:</span></span></span>
</span></foreignobject></g></g></svg>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section class="ltx_appendix" id="Pt0.A2">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>Training details</h2>
<section class="ltx_subsection" id="Pt0.A2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.1 </span>Word2Vec</h3>
<div class="ltx_para" id="Pt0.A2.SS1.p1">
<p class="ltx_p" id="Pt0.A2.SS1.p1.1">For the domain-specific Word2Vec model, we use the skip-gram algorithm.
We use the popular gensim library to train the model¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05006v1#bib.bib12" title="">12</a>]</cite>.
We set the vector size to 300, which is the same as for the generic Word2Vec model.
Negative sampling is used with 5 negatives.
A minimum of 5 occurrences is set for words to be represented in the model.
The window size is set to 5.</p>
</div>
</section>
<section class="ltx_subsection" id="Pt0.A2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.2 </span>fastText</h3>
<div class="ltx_para" id="Pt0.A2.SS2.p1">
<p class="ltx_p" id="Pt0.A2.SS2.p1.1">For the domain-specific fastText model, we also use the skip-gram algorithm.
We use the fastText library in Python to train the model.<span class="ltx_note ltx_role_footnote" id="footnote4"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://fasttext.cc/" title="">https://fasttext.cc/</a></span></span></span>
We set the vector size to 300, which is the same as for the generic fastText model.
Negative sampling is used with 5 negatives.
A minimum of 5 occurrences is set for words to be represented in the model.
The window size is set to 5.</p>
</div>
</section>
<section class="ltx_subsection" id="Pt0.A2.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.3 </span>Sentence-BERT fine-tuning</h3>
<div class="ltx_para" id="Pt0.A2.SS3.p1">
<p class="ltx_p" id="Pt0.A2.SS3.p1.1">The contrastive training is implemented using the popular SBERT implementation in Python¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05006v1#bib.bib13" title="">13</a>]</cite>.<span class="ltx_note ltx_role_footnote" id="footnote5"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.sbert.net/" title="">https://www.sbert.net/</a></span></span></span>
We keep the default value of 20 for the ‚Äúscale‚Äù hyperparameter <span class="ltx_text ltx_font_italic" id="Pt0.A2.SS3.p1.1.1">alpha</span>.
We train for 1 epoch.
The positive pairs are randomly shuffled into batches of 128 pairs.
We use the AdamW optimizer with a learning rate of 2e-5 and a ‚ÄúWarmupLinear‚Äù learning rate schedule with a warmup period of 5% of the training data.
Automatic mixed precision (AMP) was used to speed up training.
Training was accelerated using an Nvidia V100 GPU.</p>
</div>
</section>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Mon Oct  7 13:00:53 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
