<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2105.03938] Passage Retrieval for Outside-Knowledge Visual Question Answering</title><meta property="og:description" content="In this work, we address multi-modal information needs that contain text questions and images by focusing on passage retrieval for outside-knowledge visual question answering. This task requires access to outside knowlâ€¦">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Passage Retrieval for Outside-Knowledge Visual Question Answering">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Passage Retrieval for Outside-Knowledge Visual Question Answering">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2105.03938">

<!--Generated on Fri Mar  8 00:11:28 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content="Dense Retrieval; Multi-Modal; Visual Question Answering">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line ltx_leqno">
<div id="p1" class="ltx_para">
<span id="p1.1" class="ltx_ERROR undefined">\useunder</span>
<p id="p1.2" class="ltx_p"><span id="p1.2.1" class="ltx_text ltx_ulem_uline"></span><span id="p1.2.2" class="ltx_ERROR undefined">\ul</span>
</p>
</div>
<h1 class="ltx_title ltx_title_document">Passage Retrieval for Outside-Knowledge <span id="id1.id1" class="ltx_text">Visual Question Answering</span>
</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Chen Qu, Hamed Zamani, Liu Yang, W. Bruce Croft, Erik Learned-Miller
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id2.1.id1" class="ltx_text ltx_affiliation_institution">
University of Massachusetts Amherst</span><span id="id3.2.id2" class="ltx_text ltx_affiliation_streetaddress">140 Governors Dr.</span><span id="id4.3.id3" class="ltx_text ltx_affiliation_city">Amherst</span><span id="id5.4.id4" class="ltx_text ltx_affiliation_state">MA</span><span id="id6.5.id5" class="ltx_text ltx_affiliation_postcode">01003</span><span id="id7.6.id6" class="ltx_text ltx_affiliation_country">United States</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:chenqu,%20zamani,%20lyang,%20croft,%20elm@cs.umass.edu">chenqu, zamani, lyang, croft, elm@cs.umass.edu</a>
</span></span></span>
</div>
<div class="ltx_dates">(2021)</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract.</h6>
<p id="id8.id1" class="ltx_p">In this work, we address multi-modal information needs that contain text questions and images by focusing on passage retrieval for outside-knowledge visual question answering. This task requires access to outside knowledge, which in our case we define to be a large unstructured passage collection. We first conduct sparse retrieval with BM25 and study expanding the question with object names and image captions. We verify that visual clues play an important role and captions tend to be more informative than object names in sparse retrieval. We then construct a dual-encoder dense retriever, with the query encoder being LXMERTÂ <cite class="ltx_cite ltx_citemacro_citep">(Tan and Bansal, <a href="#bib.bib35" title="" class="ltx_ref">2019</a>)</cite>, a multi-modal pre-trained transformer. We further show that dense retrieval significantly outperforms sparse retrieval that uses object expansion. Moreover, dense retrieval matches the performance of sparse retrieval that leverages human-generated captions.</p>
</div>
<div class="ltx_keywords">Dense Retrieval; Multi-Modal; Visual Question Answering
</div>
<span id="id1" class="ltx_note ltx_note_frontmatter ltx_role_journalyear"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_type">journalyear: </span>2021</span></span></span><span id="id2" class="ltx_note ltx_note_frontmatter ltx_role_copyright"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_type">copyright: </span>acmcopyright</span></span></span><span id="id3" class="ltx_note ltx_note_frontmatter ltx_role_conference"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_type">conference: </span>Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval; July 11â€“15, 2021; Virtual Event, Canada</span></span></span><span id="id4" class="ltx_note ltx_note_frontmatter ltx_role_booktitle"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_type">booktitle: </span>Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR â€™21), July 11â€“15, 2021, Virtual Event, Canada</span></span></span><span id="id5" class="ltx_note ltx_note_frontmatter ltx_role_price"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_type">price: </span>15.00</span></span></span><span id="id6" class="ltx_note ltx_note_frontmatter ltx_role_doi"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_type">doi: </span>10.1145/3404835.3462987</span></span></span><span id="id7" class="ltx_note ltx_note_frontmatter ltx_role_isbn"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_type">isbn: </span>978-1-4503-8037-9/21/07</span></span></span><span id="id8" class="ltx_note ltx_note_frontmatter ltx_role_ccs"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_type">ccs: </span>Information systemsÂ Question answering</span></span></span><span id="id9" class="ltx_note ltx_note_frontmatter ltx_role_ccs"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_type">ccs: </span>Information systemsÂ Multimedia and multimodal retrieval</span></span></span>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1. </span>Introduction</h2>

<figure id="S1.F1" class="ltx_figure"><img src="/html/2105.03938/assets/x1.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="216" height="58" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S1.F1.2.1.1" class="ltx_text" style="font-size:90%;">Figure 1</span>. </span><span id="S1.F1.3.2" class="ltx_text" style="font-size:90%;">An example of passage retrieval for OK-VQA. Boldface denotes a potential answer. Image Â©gsloan, <a target="_blank" href="https://www.flickr.com/photos/gsloan/8137199999/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.flickr.com/photos/gsloan/8137199999/</a></span></figcaption>
</figure>
<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Recent work on Question Answering (QA)Â <cite class="ltx_cite ltx_citemacro_citep">(Rajpurkar etÂ al., <a href="#bib.bib33" title="" class="ltx_ref">2016</a>; Yang etÂ al., <a href="#bib.bib44" title="" class="ltx_ref">2020</a>; Qu etÂ al., <a href="#bib.bib30" title="" class="ltx_ref">2020a</a>)</cite> mostly focuses on uni-modal information needs, i.e., text- or voice-based questions (voice input can be considered as text after automatic transcription).
However, many information needs, such as the one in Fig.Â <a href="#S1.F1" title="Figure 1 â€£ 1. Introduction â€£ Passage Retrieval for Outside-Knowledge Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, would be inconvenient or hard to explain without a picture.
This motivates the study of methods that can handle multi-modal information needs containing both text questions and imagesÂ <cite class="ltx_cite ltx_citemacro_citep">(Deldjoo etÂ al., <a href="#bib.bib7" title="" class="ltx_ref">2021</a>; Lien etÂ al., <a href="#bib.bib22" title="" class="ltx_ref">2020</a>)</cite>.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Specifically, we focus on a Visual QA (VQA) task referred to as Outside-Knowledge VQA (OK-VQA). Classic VQA benchmarksÂ <cite class="ltx_cite ltx_citemacro_citep">(Malinowski and Fritz, <a href="#bib.bib25" title="" class="ltx_ref">2014</a>; Yu etÂ al., <a href="#bib.bib46" title="" class="ltx_ref">2015</a>; Zhu etÂ al., <a href="#bib.bib47" title="" class="ltx_ref">2016</a>; Goyal etÂ al., <a href="#bib.bib12" title="" class="ltx_ref">2017</a>; Agrawal etÂ al., <a href="#bib.bib1" title="" class="ltx_ref">2015</a>)</cite> and modelsÂ <cite class="ltx_cite ltx_citemacro_citep">(Ben-younes etÂ al., <a href="#bib.bib3" title="" class="ltx_ref">2017</a>; Kim etÂ al., <a href="#bib.bib17" title="" class="ltx_ref">2018</a>; Malinowski etÂ al., <a href="#bib.bib26" title="" class="ltx_ref">2015</a>; Xiong etÂ al., <a href="#bib.bib41" title="" class="ltx_ref">2016</a>; Lu etÂ al., <a href="#bib.bib23" title="" class="ltx_ref">2016</a>; Fukui etÂ al., <a href="#bib.bib10" title="" class="ltx_ref">2016</a>)</cite> mainly focus on questions about counting, visual attributes, or other visual detection tasks, whose answers can be found in the given image. In contrast, images in our task help to define the information need, instead of simply being the knowledge source by which the question is answered. OK-VQA resembles open-domain QAÂ <cite class="ltx_cite ltx_citemacro_citep">(Voorhees and Tice, <a href="#bib.bib37" title="" class="ltx_ref">1999</a>)</cite> in the sense that both tasks require access to an outside and open knowledge resource, e.g., a large collection of passages, to answer the questions. Open-domain QA systems typically follow a retrieve-and-read paradigmÂ <cite class="ltx_cite ltx_citemacro_citep">(Karpukhin etÂ al., <a href="#bib.bib16" title="" class="ltx_ref">2020</a>; Lee etÂ al., <a href="#bib.bib20" title="" class="ltx_ref">2019</a>; Qu etÂ al., <a href="#bib.bib30" title="" class="ltx_ref">2020a</a>; Chen etÂ al., <a href="#bib.bib5" title="" class="ltx_ref">2017</a>; Qu etÂ al., <a href="#bib.bib32" title="" class="ltx_ref">2020b</a>; Xiong etÂ al., <a href="#bib.bib43" title="" class="ltx_ref">2020b</a>; Qu etÂ al., <a href="#bib.bib31" title="" class="ltx_ref">2021</a>)</cite>, where the system first retrieves a number of documents (passages) from a collection and then extracts answers from them. This paradigm is less studied for multi-modal information needs, which is the focus of this paper. In this work, we focus on the retrieval phase for OK-VQA as illustrated in Fig.Â <a href="#S1.F1" title="Figure 1 â€£ 1. Introduction â€£ Passage Retrieval for Outside-Knowledge Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">Unlike previous knowledge-based VQA work that retrieves knowledge from a knowledge baseÂ  <cite class="ltx_cite ltx_citemacro_citep">(GardÃ¨res etÂ al., <a href="#bib.bib11" title="" class="ltx_ref">2020</a>; Narasimhan etÂ al., <a href="#bib.bib29" title="" class="ltx_ref">2018</a>; Narasimhan and Schwing, <a href="#bib.bib28" title="" class="ltx_ref">2018</a>; Wang etÂ al., <a href="#bib.bib38" title="" class="ltx_ref">2017</a>, <a href="#bib.bib39" title="" class="ltx_ref">2018</a>; Wu etÂ al., <a href="#bib.bib40" title="" class="ltx_ref">2016</a>; Li etÂ al., <a href="#bib.bib21" title="" class="ltx_ref">2017</a>; Yu etÂ al., <a href="#bib.bib45" title="" class="ltx_ref">2020</a>; Zhu etÂ al., <a href="#bib.bib48" title="" class="ltx_ref">2020</a>)</cite> or using a Wikipedia Search APIÂ <cite class="ltx_cite ltx_citemacro_citep">(Marino etÂ al., <a href="#bib.bib27" title="" class="ltx_ref">2019</a>)</cite>, we systematically study passage retrieval for OK-VQA with <span id="S1.p3.1.1" class="ltx_text ltx_font_italic">generic</span> information retrieval approaches
so that our methods can be applied to a wider range of <em id="S1.p3.1.2" class="ltx_emph ltx_font_italic">unstructured</em> knowledge resources.
In particular, we seek answers to the following research questions: (<span id="S1.p3.1.3" class="ltx_text ltx_font_bold">RQ1</span>) How helpful are the visual signals in OK-VQA? (<span id="S1.p3.1.4" class="ltx_text ltx_font_bold">RQ2</span>) What is the most effective way to incorporate visual signals into sparse retrieval models that are based on term matching? (<span id="S1.p3.1.5" class="ltx_text ltx_font_bold">RQ3</span>) How well does dense retrievalÂ <cite class="ltx_cite ltx_citemacro_citep">(Luan etÂ al., <a href="#bib.bib24" title="" class="ltx_ref">2020</a>; Karpukhin etÂ al., <a href="#bib.bib16" title="" class="ltx_ref">2020</a>; Xiong etÂ al., <a href="#bib.bib42" title="" class="ltx_ref">2020a</a>; Lee etÂ al., <a href="#bib.bib20" title="" class="ltx_ref">2019</a>; Guu etÂ al., <a href="#bib.bib13" title="" class="ltx_ref">2020</a>)</cite> work with multi-modal information needs?</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">To answer these important research questions, we study passage retrieval for OK-VQA queries with a large Wikipedia passage collection. We first conduct sparse retrieval with BM25. We investigate the performance of expanding the original question with different human-annotated object names and image captions. We further study the impact of using different rank fusion methods for different expansion types. We verify that visual clues play an important role in our task. In particular, captions tend to be more informative than object names in sparse retrieval. We further reveal that it is desirable to exploit the most salient matching signal (CombMAXÂ <cite class="ltx_cite ltx_citemacro_citep">(Lee, <a href="#bib.bib19" title="" class="ltx_ref">1997</a>; Fox and Shaw, <a href="#bib.bib9" title="" class="ltx_ref">1993</a>)</cite>) when using object expansion
while it is better to consider the matching signals for all captions with CombSUMÂ <cite class="ltx_cite ltx_citemacro_citep">(Lee, <a href="#bib.bib19" title="" class="ltx_ref">1997</a>; Fox and Shaw, <a href="#bib.bib9" title="" class="ltx_ref">1993</a>)</cite> or Reciprocal Rank FusionÂ <cite class="ltx_cite ltx_citemacro_citep">(Hu etÂ al., <a href="#bib.bib14" title="" class="ltx_ref">2018</a>)</cite> when we expand with human-generated captions.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">We then adopt a dual-encoder architecture to construct a learnable dense retriever following previous workÂ <cite class="ltx_cite ltx_citemacro_citep">(Luan etÂ al., <a href="#bib.bib24" title="" class="ltx_ref">2020</a>; Karpukhin etÂ al., <a href="#bib.bib16" title="" class="ltx_ref">2020</a>; Xiong etÂ al., <a href="#bib.bib42" title="" class="ltx_ref">2020a</a>; Qu etÂ al., <a href="#bib.bib30" title="" class="ltx_ref">2020a</a>; Lee etÂ al., <a href="#bib.bib20" title="" class="ltx_ref">2019</a>)</cite>. We employ LXMERTÂ <cite class="ltx_cite ltx_citemacro_citep">(Tan and Bansal, <a href="#bib.bib35" title="" class="ltx_ref">2019</a>)</cite>, a pre-trained Transformer modelÂ <cite class="ltx_cite ltx_citemacro_citep">(Vaswani etÂ al., <a href="#bib.bib36" title="" class="ltx_ref">2017</a>)</cite>, as our multi-modal query encoder to encode both the text question and the image as an information need. We observe that our dense retriever achieves a statistically significant performance improvement over sparse retrieval that leverages object expansion, demonstrating the effectiveness of dense retrieval with a multi-modal query encoder. Furthermore, our dense retriever manages to match the performance of sparse retrieval with caption expansion, even though the latter leverages human-generated captions that are often highly informative.
Our research is one of fundamental steps for future studies on retrieval-based OK-VQA.
Our code is released for research purposes.<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a target="_blank" href="https://github.com/prdwb/okvqa-release" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/prdwb/okvqa-release</a></span></span></span></p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2. </span>Passage Retrieval for OK-VQA</h2>

<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1. </span>Task Definition</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.5" class="ltx_p">We are given an information need (query) denoted as <math id="S2.SS1.p1.1.m1.2" class="ltx_Math" alttext="Q_{i}=\langle q_{i},v_{i}\rangle" display="inline"><semantics id="S2.SS1.p1.1.m1.2a"><mrow id="S2.SS1.p1.1.m1.2.2" xref="S2.SS1.p1.1.m1.2.2.cmml"><msub id="S2.SS1.p1.1.m1.2.2.4" xref="S2.SS1.p1.1.m1.2.2.4.cmml"><mi id="S2.SS1.p1.1.m1.2.2.4.2" xref="S2.SS1.p1.1.m1.2.2.4.2.cmml">Q</mi><mi id="S2.SS1.p1.1.m1.2.2.4.3" xref="S2.SS1.p1.1.m1.2.2.4.3.cmml">i</mi></msub><mo id="S2.SS1.p1.1.m1.2.2.3" xref="S2.SS1.p1.1.m1.2.2.3.cmml">=</mo><mrow id="S2.SS1.p1.1.m1.2.2.2.2" xref="S2.SS1.p1.1.m1.2.2.2.3.cmml"><mo stretchy="false" id="S2.SS1.p1.1.m1.2.2.2.2.3" xref="S2.SS1.p1.1.m1.2.2.2.3.cmml">âŸ¨</mo><msub id="S2.SS1.p1.1.m1.1.1.1.1.1" xref="S2.SS1.p1.1.m1.1.1.1.1.1.cmml"><mi id="S2.SS1.p1.1.m1.1.1.1.1.1.2" xref="S2.SS1.p1.1.m1.1.1.1.1.1.2.cmml">q</mi><mi id="S2.SS1.p1.1.m1.1.1.1.1.1.3" xref="S2.SS1.p1.1.m1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S2.SS1.p1.1.m1.2.2.2.2.4" xref="S2.SS1.p1.1.m1.2.2.2.3.cmml">,</mo><msub id="S2.SS1.p1.1.m1.2.2.2.2.2" xref="S2.SS1.p1.1.m1.2.2.2.2.2.cmml"><mi id="S2.SS1.p1.1.m1.2.2.2.2.2.2" xref="S2.SS1.p1.1.m1.2.2.2.2.2.2.cmml">v</mi><mi id="S2.SS1.p1.1.m1.2.2.2.2.2.3" xref="S2.SS1.p1.1.m1.2.2.2.2.2.3.cmml">i</mi></msub><mo stretchy="false" id="S2.SS1.p1.1.m1.2.2.2.2.5" xref="S2.SS1.p1.1.m1.2.2.2.3.cmml">âŸ©</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.1.m1.2b"><apply id="S2.SS1.p1.1.m1.2.2.cmml" xref="S2.SS1.p1.1.m1.2.2"><eq id="S2.SS1.p1.1.m1.2.2.3.cmml" xref="S2.SS1.p1.1.m1.2.2.3"></eq><apply id="S2.SS1.p1.1.m1.2.2.4.cmml" xref="S2.SS1.p1.1.m1.2.2.4"><csymbol cd="ambiguous" id="S2.SS1.p1.1.m1.2.2.4.1.cmml" xref="S2.SS1.p1.1.m1.2.2.4">subscript</csymbol><ci id="S2.SS1.p1.1.m1.2.2.4.2.cmml" xref="S2.SS1.p1.1.m1.2.2.4.2">ğ‘„</ci><ci id="S2.SS1.p1.1.m1.2.2.4.3.cmml" xref="S2.SS1.p1.1.m1.2.2.4.3">ğ‘–</ci></apply><list id="S2.SS1.p1.1.m1.2.2.2.3.cmml" xref="S2.SS1.p1.1.m1.2.2.2.2"><apply id="S2.SS1.p1.1.m1.1.1.1.1.1.cmml" xref="S2.SS1.p1.1.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.SS1.p1.1.m1.1.1.1.1.1.1.cmml" xref="S2.SS1.p1.1.m1.1.1.1.1.1">subscript</csymbol><ci id="S2.SS1.p1.1.m1.1.1.1.1.1.2.cmml" xref="S2.SS1.p1.1.m1.1.1.1.1.1.2">ğ‘</ci><ci id="S2.SS1.p1.1.m1.1.1.1.1.1.3.cmml" xref="S2.SS1.p1.1.m1.1.1.1.1.1.3">ğ‘–</ci></apply><apply id="S2.SS1.p1.1.m1.2.2.2.2.2.cmml" xref="S2.SS1.p1.1.m1.2.2.2.2.2"><csymbol cd="ambiguous" id="S2.SS1.p1.1.m1.2.2.2.2.2.1.cmml" xref="S2.SS1.p1.1.m1.2.2.2.2.2">subscript</csymbol><ci id="S2.SS1.p1.1.m1.2.2.2.2.2.2.cmml" xref="S2.SS1.p1.1.m1.2.2.2.2.2.2">ğ‘£</ci><ci id="S2.SS1.p1.1.m1.2.2.2.2.2.3.cmml" xref="S2.SS1.p1.1.m1.2.2.2.2.2.3">ğ‘–</ci></apply></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.1.m1.2c">Q_{i}=\langle q_{i},v_{i}\rangle</annotation></semantics></math>. It consists of a text question <math id="S2.SS1.p1.2.m2.1" class="ltx_Math" alttext="q_{i}" display="inline"><semantics id="S2.SS1.p1.2.m2.1a"><msub id="S2.SS1.p1.2.m2.1.1" xref="S2.SS1.p1.2.m2.1.1.cmml"><mi id="S2.SS1.p1.2.m2.1.1.2" xref="S2.SS1.p1.2.m2.1.1.2.cmml">q</mi><mi id="S2.SS1.p1.2.m2.1.1.3" xref="S2.SS1.p1.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.2.m2.1b"><apply id="S2.SS1.p1.2.m2.1.1.cmml" xref="S2.SS1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S2.SS1.p1.2.m2.1.1.1.cmml" xref="S2.SS1.p1.2.m2.1.1">subscript</csymbol><ci id="S2.SS1.p1.2.m2.1.1.2.cmml" xref="S2.SS1.p1.2.m2.1.1.2">ğ‘</ci><ci id="S2.SS1.p1.2.m2.1.1.3.cmml" xref="S2.SS1.p1.2.m2.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.2.m2.1c">q_{i}</annotation></semantics></math> and an image <math id="S2.SS1.p1.3.m3.1" class="ltx_Math" alttext="v_{i}" display="inline"><semantics id="S2.SS1.p1.3.m3.1a"><msub id="S2.SS1.p1.3.m3.1.1" xref="S2.SS1.p1.3.m3.1.1.cmml"><mi id="S2.SS1.p1.3.m3.1.1.2" xref="S2.SS1.p1.3.m3.1.1.2.cmml">v</mi><mi id="S2.SS1.p1.3.m3.1.1.3" xref="S2.SS1.p1.3.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.3.m3.1b"><apply id="S2.SS1.p1.3.m3.1.1.cmml" xref="S2.SS1.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S2.SS1.p1.3.m3.1.1.1.cmml" xref="S2.SS1.p1.3.m3.1.1">subscript</csymbol><ci id="S2.SS1.p1.3.m3.1.1.2.cmml" xref="S2.SS1.p1.3.m3.1.1.2">ğ‘£</ci><ci id="S2.SS1.p1.3.m3.1.1.3.cmml" xref="S2.SS1.p1.3.m3.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.3.m3.1c">v_{i}</annotation></semantics></math>. The task is to retrieve <math id="S2.SS1.p1.4.m4.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S2.SS1.p1.4.m4.1a"><mi id="S2.SS1.p1.4.m4.1.1" xref="S2.SS1.p1.4.m4.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.4.m4.1b"><ci id="S2.SS1.p1.4.m4.1.1.cmml" xref="S2.SS1.p1.4.m4.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.4.m4.1c">k</annotation></semantics></math> passages
that can be used to fulfill <math id="S2.SS1.p1.5.m5.1" class="ltx_Math" alttext="Q_{i}" display="inline"><semantics id="S2.SS1.p1.5.m5.1a"><msub id="S2.SS1.p1.5.m5.1.1" xref="S2.SS1.p1.5.m5.1.1.cmml"><mi id="S2.SS1.p1.5.m5.1.1.2" xref="S2.SS1.p1.5.m5.1.1.2.cmml">Q</mi><mi id="S2.SS1.p1.5.m5.1.1.3" xref="S2.SS1.p1.5.m5.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.5.m5.1b"><apply id="S2.SS1.p1.5.m5.1.1.cmml" xref="S2.SS1.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S2.SS1.p1.5.m5.1.1.1.cmml" xref="S2.SS1.p1.5.m5.1.1">subscript</csymbol><ci id="S2.SS1.p1.5.m5.1.1.2.cmml" xref="S2.SS1.p1.5.m5.1.1.2">ğ‘„</ci><ci id="S2.SS1.p1.5.m5.1.1.3.cmml" xref="S2.SS1.p1.5.m5.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.5.m5.1c">Q_{i}</annotation></semantics></math>, from a large passage collection. Following the work on open-domain QAÂ <cite class="ltx_cite ltx_citemacro_citep">(Lee etÂ al., <a href="#bib.bib20" title="" class="ltx_ref">2019</a>; Qu etÂ al., <a href="#bib.bib30" title="" class="ltx_ref">2020a</a>; Karpukhin etÂ al., <a href="#bib.bib16" title="" class="ltx_ref">2020</a>)</cite>, a passage is deemed as relevant if it contains the ground truth answer.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2. </span>Sparse Retrieval</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.3" class="ltx_p">The backbone of our sparse retrieval approach is BM25,
which works with text queries. Therefore, we expand <math id="S2.SS2.p1.1.m1.1" class="ltx_Math" alttext="q_{i}" display="inline"><semantics id="S2.SS2.p1.1.m1.1a"><msub id="S2.SS2.p1.1.m1.1.1" xref="S2.SS2.p1.1.m1.1.1.cmml"><mi id="S2.SS2.p1.1.m1.1.1.2" xref="S2.SS2.p1.1.m1.1.1.2.cmml">q</mi><mi id="S2.SS2.p1.1.m1.1.1.3" xref="S2.SS2.p1.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.1.m1.1b"><apply id="S2.SS2.p1.1.m1.1.1.cmml" xref="S2.SS2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S2.SS2.p1.1.m1.1.1.1.cmml" xref="S2.SS2.p1.1.m1.1.1">subscript</csymbol><ci id="S2.SS2.p1.1.m1.1.1.2.cmml" xref="S2.SS2.p1.1.m1.1.1.2">ğ‘</ci><ci id="S2.SS2.p1.1.m1.1.1.3.cmml" xref="S2.SS2.p1.1.m1.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.1.m1.1c">q_{i}</annotation></semantics></math> with different textual descriptions of visual clues to construct the BM25 queries. Visual signals in an image are typically expressed in two forms. The first form is a set of object names <math id="S2.SS2.p1.2.m2.3" class="ltx_Math" alttext="\{o_{i}^{1},o_{i}^{2},\cdots\}" display="inline"><semantics id="S2.SS2.p1.2.m2.3a"><mrow id="S2.SS2.p1.2.m2.3.3.2" xref="S2.SS2.p1.2.m2.3.3.3.cmml"><mo stretchy="false" id="S2.SS2.p1.2.m2.3.3.2.3" xref="S2.SS2.p1.2.m2.3.3.3.cmml">{</mo><msubsup id="S2.SS2.p1.2.m2.2.2.1.1" xref="S2.SS2.p1.2.m2.2.2.1.1.cmml"><mi id="S2.SS2.p1.2.m2.2.2.1.1.2.2" xref="S2.SS2.p1.2.m2.2.2.1.1.2.2.cmml">o</mi><mi id="S2.SS2.p1.2.m2.2.2.1.1.2.3" xref="S2.SS2.p1.2.m2.2.2.1.1.2.3.cmml">i</mi><mn id="S2.SS2.p1.2.m2.2.2.1.1.3" xref="S2.SS2.p1.2.m2.2.2.1.1.3.cmml">1</mn></msubsup><mo id="S2.SS2.p1.2.m2.3.3.2.4" xref="S2.SS2.p1.2.m2.3.3.3.cmml">,</mo><msubsup id="S2.SS2.p1.2.m2.3.3.2.2" xref="S2.SS2.p1.2.m2.3.3.2.2.cmml"><mi id="S2.SS2.p1.2.m2.3.3.2.2.2.2" xref="S2.SS2.p1.2.m2.3.3.2.2.2.2.cmml">o</mi><mi id="S2.SS2.p1.2.m2.3.3.2.2.2.3" xref="S2.SS2.p1.2.m2.3.3.2.2.2.3.cmml">i</mi><mn id="S2.SS2.p1.2.m2.3.3.2.2.3" xref="S2.SS2.p1.2.m2.3.3.2.2.3.cmml">2</mn></msubsup><mo id="S2.SS2.p1.2.m2.3.3.2.5" xref="S2.SS2.p1.2.m2.3.3.3.cmml">,</mo><mi mathvariant="normal" id="S2.SS2.p1.2.m2.1.1" xref="S2.SS2.p1.2.m2.1.1.cmml">â‹¯</mi><mo stretchy="false" id="S2.SS2.p1.2.m2.3.3.2.6" xref="S2.SS2.p1.2.m2.3.3.3.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.2.m2.3b"><set id="S2.SS2.p1.2.m2.3.3.3.cmml" xref="S2.SS2.p1.2.m2.3.3.2"><apply id="S2.SS2.p1.2.m2.2.2.1.1.cmml" xref="S2.SS2.p1.2.m2.2.2.1.1"><csymbol cd="ambiguous" id="S2.SS2.p1.2.m2.2.2.1.1.1.cmml" xref="S2.SS2.p1.2.m2.2.2.1.1">superscript</csymbol><apply id="S2.SS2.p1.2.m2.2.2.1.1.2.cmml" xref="S2.SS2.p1.2.m2.2.2.1.1"><csymbol cd="ambiguous" id="S2.SS2.p1.2.m2.2.2.1.1.2.1.cmml" xref="S2.SS2.p1.2.m2.2.2.1.1">subscript</csymbol><ci id="S2.SS2.p1.2.m2.2.2.1.1.2.2.cmml" xref="S2.SS2.p1.2.m2.2.2.1.1.2.2">ğ‘œ</ci><ci id="S2.SS2.p1.2.m2.2.2.1.1.2.3.cmml" xref="S2.SS2.p1.2.m2.2.2.1.1.2.3">ğ‘–</ci></apply><cn type="integer" id="S2.SS2.p1.2.m2.2.2.1.1.3.cmml" xref="S2.SS2.p1.2.m2.2.2.1.1.3">1</cn></apply><apply id="S2.SS2.p1.2.m2.3.3.2.2.cmml" xref="S2.SS2.p1.2.m2.3.3.2.2"><csymbol cd="ambiguous" id="S2.SS2.p1.2.m2.3.3.2.2.1.cmml" xref="S2.SS2.p1.2.m2.3.3.2.2">superscript</csymbol><apply id="S2.SS2.p1.2.m2.3.3.2.2.2.cmml" xref="S2.SS2.p1.2.m2.3.3.2.2"><csymbol cd="ambiguous" id="S2.SS2.p1.2.m2.3.3.2.2.2.1.cmml" xref="S2.SS2.p1.2.m2.3.3.2.2">subscript</csymbol><ci id="S2.SS2.p1.2.m2.3.3.2.2.2.2.cmml" xref="S2.SS2.p1.2.m2.3.3.2.2.2.2">ğ‘œ</ci><ci id="S2.SS2.p1.2.m2.3.3.2.2.2.3.cmml" xref="S2.SS2.p1.2.m2.3.3.2.2.2.3">ğ‘–</ci></apply><cn type="integer" id="S2.SS2.p1.2.m2.3.3.2.2.3.cmml" xref="S2.SS2.p1.2.m2.3.3.2.2.3">2</cn></apply><ci id="S2.SS2.p1.2.m2.1.1.cmml" xref="S2.SS2.p1.2.m2.1.1">â‹¯</ci></set></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.2.m2.3c">\{o_{i}^{1},o_{i}^{2},\cdots\}</annotation></semantics></math> produced by an object detector. Each object is a Region of Interest (RoI) that reveals a meaningful component of the image.
The second form is a set of captions <math id="S2.SS2.p1.3.m3.3" class="ltx_Math" alttext="\{c_{i}^{1},c_{i}^{2},\cdots\}" display="inline"><semantics id="S2.SS2.p1.3.m3.3a"><mrow id="S2.SS2.p1.3.m3.3.3.2" xref="S2.SS2.p1.3.m3.3.3.3.cmml"><mo stretchy="false" id="S2.SS2.p1.3.m3.3.3.2.3" xref="S2.SS2.p1.3.m3.3.3.3.cmml">{</mo><msubsup id="S2.SS2.p1.3.m3.2.2.1.1" xref="S2.SS2.p1.3.m3.2.2.1.1.cmml"><mi id="S2.SS2.p1.3.m3.2.2.1.1.2.2" xref="S2.SS2.p1.3.m3.2.2.1.1.2.2.cmml">c</mi><mi id="S2.SS2.p1.3.m3.2.2.1.1.2.3" xref="S2.SS2.p1.3.m3.2.2.1.1.2.3.cmml">i</mi><mn id="S2.SS2.p1.3.m3.2.2.1.1.3" xref="S2.SS2.p1.3.m3.2.2.1.1.3.cmml">1</mn></msubsup><mo id="S2.SS2.p1.3.m3.3.3.2.4" xref="S2.SS2.p1.3.m3.3.3.3.cmml">,</mo><msubsup id="S2.SS2.p1.3.m3.3.3.2.2" xref="S2.SS2.p1.3.m3.3.3.2.2.cmml"><mi id="S2.SS2.p1.3.m3.3.3.2.2.2.2" xref="S2.SS2.p1.3.m3.3.3.2.2.2.2.cmml">c</mi><mi id="S2.SS2.p1.3.m3.3.3.2.2.2.3" xref="S2.SS2.p1.3.m3.3.3.2.2.2.3.cmml">i</mi><mn id="S2.SS2.p1.3.m3.3.3.2.2.3" xref="S2.SS2.p1.3.m3.3.3.2.2.3.cmml">2</mn></msubsup><mo id="S2.SS2.p1.3.m3.3.3.2.5" xref="S2.SS2.p1.3.m3.3.3.3.cmml">,</mo><mi mathvariant="normal" id="S2.SS2.p1.3.m3.1.1" xref="S2.SS2.p1.3.m3.1.1.cmml">â‹¯</mi><mo stretchy="false" id="S2.SS2.p1.3.m3.3.3.2.6" xref="S2.SS2.p1.3.m3.3.3.3.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.3.m3.3b"><set id="S2.SS2.p1.3.m3.3.3.3.cmml" xref="S2.SS2.p1.3.m3.3.3.2"><apply id="S2.SS2.p1.3.m3.2.2.1.1.cmml" xref="S2.SS2.p1.3.m3.2.2.1.1"><csymbol cd="ambiguous" id="S2.SS2.p1.3.m3.2.2.1.1.1.cmml" xref="S2.SS2.p1.3.m3.2.2.1.1">superscript</csymbol><apply id="S2.SS2.p1.3.m3.2.2.1.1.2.cmml" xref="S2.SS2.p1.3.m3.2.2.1.1"><csymbol cd="ambiguous" id="S2.SS2.p1.3.m3.2.2.1.1.2.1.cmml" xref="S2.SS2.p1.3.m3.2.2.1.1">subscript</csymbol><ci id="S2.SS2.p1.3.m3.2.2.1.1.2.2.cmml" xref="S2.SS2.p1.3.m3.2.2.1.1.2.2">ğ‘</ci><ci id="S2.SS2.p1.3.m3.2.2.1.1.2.3.cmml" xref="S2.SS2.p1.3.m3.2.2.1.1.2.3">ğ‘–</ci></apply><cn type="integer" id="S2.SS2.p1.3.m3.2.2.1.1.3.cmml" xref="S2.SS2.p1.3.m3.2.2.1.1.3">1</cn></apply><apply id="S2.SS2.p1.3.m3.3.3.2.2.cmml" xref="S2.SS2.p1.3.m3.3.3.2.2"><csymbol cd="ambiguous" id="S2.SS2.p1.3.m3.3.3.2.2.1.cmml" xref="S2.SS2.p1.3.m3.3.3.2.2">superscript</csymbol><apply id="S2.SS2.p1.3.m3.3.3.2.2.2.cmml" xref="S2.SS2.p1.3.m3.3.3.2.2"><csymbol cd="ambiguous" id="S2.SS2.p1.3.m3.3.3.2.2.2.1.cmml" xref="S2.SS2.p1.3.m3.3.3.2.2">subscript</csymbol><ci id="S2.SS2.p1.3.m3.3.3.2.2.2.2.cmml" xref="S2.SS2.p1.3.m3.3.3.2.2.2.2">ğ‘</ci><ci id="S2.SS2.p1.3.m3.3.3.2.2.2.3.cmml" xref="S2.SS2.p1.3.m3.3.3.2.2.2.3">ğ‘–</ci></apply><cn type="integer" id="S2.SS2.p1.3.m3.3.3.2.2.3.cmml" xref="S2.SS2.p1.3.m3.3.3.2.2.3">2</cn></apply><ci id="S2.SS2.p1.3.m3.1.1.cmml" xref="S2.SS2.p1.3.m3.1.1">â‹¯</ci></set></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.3.m3.3c">\{c_{i}^{1},c_{i}^{2},\cdots\}</annotation></semantics></math> produced by an image descriptor to describe the image.
We adopt human-annotated object names and captions for sparse retrieval. Although the human annotations do not necessarily give the performance upper bound, they would be strong baselines for dense retrieval and make sure that our analysis will not be affected by the quality of automatic annotations produced by object detectors and image descriptors.
We study different expansion of visual signals as follows:
</p>
<ul id="S2.I1" class="ltx_itemize">
<li id="S2.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S2.I1.i1.p1" class="ltx_para">
<p id="S2.I1.i1.p1.2" class="ltx_p"><span id="S2.I1.i1.p1.2.1" class="ltx_text ltx_font_bold">BM25-Orig</span>: taking the original <math id="S2.I1.i1.p1.1.m1.1" class="ltx_Math" alttext="q_{i}" display="inline"><semantics id="S2.I1.i1.p1.1.m1.1a"><msub id="S2.I1.i1.p1.1.m1.1.1" xref="S2.I1.i1.p1.1.m1.1.1.cmml"><mi id="S2.I1.i1.p1.1.m1.1.1.2" xref="S2.I1.i1.p1.1.m1.1.1.2.cmml">q</mi><mi id="S2.I1.i1.p1.1.m1.1.1.3" xref="S2.I1.i1.p1.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.I1.i1.p1.1.m1.1b"><apply id="S2.I1.i1.p1.1.m1.1.1.cmml" xref="S2.I1.i1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S2.I1.i1.p1.1.m1.1.1.1.cmml" xref="S2.I1.i1.p1.1.m1.1.1">subscript</csymbol><ci id="S2.I1.i1.p1.1.m1.1.1.2.cmml" xref="S2.I1.i1.p1.1.m1.1.1.2">ğ‘</ci><ci id="S2.I1.i1.p1.1.m1.1.1.3.cmml" xref="S2.I1.i1.p1.1.m1.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i1.p1.1.m1.1c">q_{i}</annotation></semantics></math> only, i.e., <math id="S2.I1.i1.p1.2.m2.1" class="ltx_Math" alttext="Q_{i}^{\text{orig}}=\{q_{i}\}" display="inline"><semantics id="S2.I1.i1.p1.2.m2.1a"><mrow id="S2.I1.i1.p1.2.m2.1.1" xref="S2.I1.i1.p1.2.m2.1.1.cmml"><msubsup id="S2.I1.i1.p1.2.m2.1.1.3" xref="S2.I1.i1.p1.2.m2.1.1.3.cmml"><mi id="S2.I1.i1.p1.2.m2.1.1.3.2.2" xref="S2.I1.i1.p1.2.m2.1.1.3.2.2.cmml">Q</mi><mi id="S2.I1.i1.p1.2.m2.1.1.3.2.3" xref="S2.I1.i1.p1.2.m2.1.1.3.2.3.cmml">i</mi><mtext id="S2.I1.i1.p1.2.m2.1.1.3.3" xref="S2.I1.i1.p1.2.m2.1.1.3.3a.cmml">orig</mtext></msubsup><mo id="S2.I1.i1.p1.2.m2.1.1.2" xref="S2.I1.i1.p1.2.m2.1.1.2.cmml">=</mo><mrow id="S2.I1.i1.p1.2.m2.1.1.1.1" xref="S2.I1.i1.p1.2.m2.1.1.1.2.cmml"><mo stretchy="false" id="S2.I1.i1.p1.2.m2.1.1.1.1.2" xref="S2.I1.i1.p1.2.m2.1.1.1.2.cmml">{</mo><msub id="S2.I1.i1.p1.2.m2.1.1.1.1.1" xref="S2.I1.i1.p1.2.m2.1.1.1.1.1.cmml"><mi id="S2.I1.i1.p1.2.m2.1.1.1.1.1.2" xref="S2.I1.i1.p1.2.m2.1.1.1.1.1.2.cmml">q</mi><mi id="S2.I1.i1.p1.2.m2.1.1.1.1.1.3" xref="S2.I1.i1.p1.2.m2.1.1.1.1.1.3.cmml">i</mi></msub><mo stretchy="false" id="S2.I1.i1.p1.2.m2.1.1.1.1.3" xref="S2.I1.i1.p1.2.m2.1.1.1.2.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.I1.i1.p1.2.m2.1b"><apply id="S2.I1.i1.p1.2.m2.1.1.cmml" xref="S2.I1.i1.p1.2.m2.1.1"><eq id="S2.I1.i1.p1.2.m2.1.1.2.cmml" xref="S2.I1.i1.p1.2.m2.1.1.2"></eq><apply id="S2.I1.i1.p1.2.m2.1.1.3.cmml" xref="S2.I1.i1.p1.2.m2.1.1.3"><csymbol cd="ambiguous" id="S2.I1.i1.p1.2.m2.1.1.3.1.cmml" xref="S2.I1.i1.p1.2.m2.1.1.3">superscript</csymbol><apply id="S2.I1.i1.p1.2.m2.1.1.3.2.cmml" xref="S2.I1.i1.p1.2.m2.1.1.3"><csymbol cd="ambiguous" id="S2.I1.i1.p1.2.m2.1.1.3.2.1.cmml" xref="S2.I1.i1.p1.2.m2.1.1.3">subscript</csymbol><ci id="S2.I1.i1.p1.2.m2.1.1.3.2.2.cmml" xref="S2.I1.i1.p1.2.m2.1.1.3.2.2">ğ‘„</ci><ci id="S2.I1.i1.p1.2.m2.1.1.3.2.3.cmml" xref="S2.I1.i1.p1.2.m2.1.1.3.2.3">ğ‘–</ci></apply><ci id="S2.I1.i1.p1.2.m2.1.1.3.3a.cmml" xref="S2.I1.i1.p1.2.m2.1.1.3.3"><mtext mathsize="70%" id="S2.I1.i1.p1.2.m2.1.1.3.3.cmml" xref="S2.I1.i1.p1.2.m2.1.1.3.3">orig</mtext></ci></apply><set id="S2.I1.i1.p1.2.m2.1.1.1.2.cmml" xref="S2.I1.i1.p1.2.m2.1.1.1.1"><apply id="S2.I1.i1.p1.2.m2.1.1.1.1.1.cmml" xref="S2.I1.i1.p1.2.m2.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.I1.i1.p1.2.m2.1.1.1.1.1.1.cmml" xref="S2.I1.i1.p1.2.m2.1.1.1.1.1">subscript</csymbol><ci id="S2.I1.i1.p1.2.m2.1.1.1.1.1.2.cmml" xref="S2.I1.i1.p1.2.m2.1.1.1.1.1.2">ğ‘</ci><ci id="S2.I1.i1.p1.2.m2.1.1.1.1.1.3.cmml" xref="S2.I1.i1.p1.2.m2.1.1.1.1.1.3">ğ‘–</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i1.p1.2.m2.1c">Q_{i}^{\text{orig}}=\{q_{i}\}</annotation></semantics></math>.</p>
</div>
</li>
<li id="S2.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S2.I1.i2.p1" class="ltx_para">
<p id="S2.I1.i2.p1.2" class="ltx_p"><span id="S2.I1.i2.p1.2.1" class="ltx_text ltx_font_bold">BM25-Obj</span> (object expansion): appending each one of the object names to <math id="S2.I1.i2.p1.1.m1.1" class="ltx_Math" alttext="q_{i}" display="inline"><semantics id="S2.I1.i2.p1.1.m1.1a"><msub id="S2.I1.i2.p1.1.m1.1.1" xref="S2.I1.i2.p1.1.m1.1.1.cmml"><mi id="S2.I1.i2.p1.1.m1.1.1.2" xref="S2.I1.i2.p1.1.m1.1.1.2.cmml">q</mi><mi id="S2.I1.i2.p1.1.m1.1.1.3" xref="S2.I1.i2.p1.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.I1.i2.p1.1.m1.1b"><apply id="S2.I1.i2.p1.1.m1.1.1.cmml" xref="S2.I1.i2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S2.I1.i2.p1.1.m1.1.1.1.cmml" xref="S2.I1.i2.p1.1.m1.1.1">subscript</csymbol><ci id="S2.I1.i2.p1.1.m1.1.1.2.cmml" xref="S2.I1.i2.p1.1.m1.1.1.2">ğ‘</ci><ci id="S2.I1.i2.p1.1.m1.1.1.3.cmml" xref="S2.I1.i2.p1.1.m1.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i2.p1.1.m1.1c">q_{i}</annotation></semantics></math>, i.e., <math id="S2.I1.i2.p1.2.m2.3" class="ltx_Math" alttext="Q_{i}^{\text{obj}}=\{q_{i}+o_{i}^{1},q_{i}+o_{i}^{2},\cdots\}" display="inline"><semantics id="S2.I1.i2.p1.2.m2.3a"><mrow id="S2.I1.i2.p1.2.m2.3.3" xref="S2.I1.i2.p1.2.m2.3.3.cmml"><msubsup id="S2.I1.i2.p1.2.m2.3.3.4" xref="S2.I1.i2.p1.2.m2.3.3.4.cmml"><mi id="S2.I1.i2.p1.2.m2.3.3.4.2.2" xref="S2.I1.i2.p1.2.m2.3.3.4.2.2.cmml">Q</mi><mi id="S2.I1.i2.p1.2.m2.3.3.4.2.3" xref="S2.I1.i2.p1.2.m2.3.3.4.2.3.cmml">i</mi><mtext id="S2.I1.i2.p1.2.m2.3.3.4.3" xref="S2.I1.i2.p1.2.m2.3.3.4.3a.cmml">obj</mtext></msubsup><mo id="S2.I1.i2.p1.2.m2.3.3.3" xref="S2.I1.i2.p1.2.m2.3.3.3.cmml">=</mo><mrow id="S2.I1.i2.p1.2.m2.3.3.2.2" xref="S2.I1.i2.p1.2.m2.3.3.2.3.cmml"><mo stretchy="false" id="S2.I1.i2.p1.2.m2.3.3.2.2.3" xref="S2.I1.i2.p1.2.m2.3.3.2.3.cmml">{</mo><mrow id="S2.I1.i2.p1.2.m2.2.2.1.1.1" xref="S2.I1.i2.p1.2.m2.2.2.1.1.1.cmml"><msub id="S2.I1.i2.p1.2.m2.2.2.1.1.1.2" xref="S2.I1.i2.p1.2.m2.2.2.1.1.1.2.cmml"><mi id="S2.I1.i2.p1.2.m2.2.2.1.1.1.2.2" xref="S2.I1.i2.p1.2.m2.2.2.1.1.1.2.2.cmml">q</mi><mi id="S2.I1.i2.p1.2.m2.2.2.1.1.1.2.3" xref="S2.I1.i2.p1.2.m2.2.2.1.1.1.2.3.cmml">i</mi></msub><mo id="S2.I1.i2.p1.2.m2.2.2.1.1.1.1" xref="S2.I1.i2.p1.2.m2.2.2.1.1.1.1.cmml">+</mo><msubsup id="S2.I1.i2.p1.2.m2.2.2.1.1.1.3" xref="S2.I1.i2.p1.2.m2.2.2.1.1.1.3.cmml"><mi id="S2.I1.i2.p1.2.m2.2.2.1.1.1.3.2.2" xref="S2.I1.i2.p1.2.m2.2.2.1.1.1.3.2.2.cmml">o</mi><mi id="S2.I1.i2.p1.2.m2.2.2.1.1.1.3.2.3" xref="S2.I1.i2.p1.2.m2.2.2.1.1.1.3.2.3.cmml">i</mi><mn id="S2.I1.i2.p1.2.m2.2.2.1.1.1.3.3" xref="S2.I1.i2.p1.2.m2.2.2.1.1.1.3.3.cmml">1</mn></msubsup></mrow><mo id="S2.I1.i2.p1.2.m2.3.3.2.2.4" xref="S2.I1.i2.p1.2.m2.3.3.2.3.cmml">,</mo><mrow id="S2.I1.i2.p1.2.m2.3.3.2.2.2" xref="S2.I1.i2.p1.2.m2.3.3.2.2.2.cmml"><msub id="S2.I1.i2.p1.2.m2.3.3.2.2.2.2" xref="S2.I1.i2.p1.2.m2.3.3.2.2.2.2.cmml"><mi id="S2.I1.i2.p1.2.m2.3.3.2.2.2.2.2" xref="S2.I1.i2.p1.2.m2.3.3.2.2.2.2.2.cmml">q</mi><mi id="S2.I1.i2.p1.2.m2.3.3.2.2.2.2.3" xref="S2.I1.i2.p1.2.m2.3.3.2.2.2.2.3.cmml">i</mi></msub><mo id="S2.I1.i2.p1.2.m2.3.3.2.2.2.1" xref="S2.I1.i2.p1.2.m2.3.3.2.2.2.1.cmml">+</mo><msubsup id="S2.I1.i2.p1.2.m2.3.3.2.2.2.3" xref="S2.I1.i2.p1.2.m2.3.3.2.2.2.3.cmml"><mi id="S2.I1.i2.p1.2.m2.3.3.2.2.2.3.2.2" xref="S2.I1.i2.p1.2.m2.3.3.2.2.2.3.2.2.cmml">o</mi><mi id="S2.I1.i2.p1.2.m2.3.3.2.2.2.3.2.3" xref="S2.I1.i2.p1.2.m2.3.3.2.2.2.3.2.3.cmml">i</mi><mn id="S2.I1.i2.p1.2.m2.3.3.2.2.2.3.3" xref="S2.I1.i2.p1.2.m2.3.3.2.2.2.3.3.cmml">2</mn></msubsup></mrow><mo id="S2.I1.i2.p1.2.m2.3.3.2.2.5" xref="S2.I1.i2.p1.2.m2.3.3.2.3.cmml">,</mo><mi mathvariant="normal" id="S2.I1.i2.p1.2.m2.1.1" xref="S2.I1.i2.p1.2.m2.1.1.cmml">â‹¯</mi><mo stretchy="false" id="S2.I1.i2.p1.2.m2.3.3.2.2.6" xref="S2.I1.i2.p1.2.m2.3.3.2.3.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.I1.i2.p1.2.m2.3b"><apply id="S2.I1.i2.p1.2.m2.3.3.cmml" xref="S2.I1.i2.p1.2.m2.3.3"><eq id="S2.I1.i2.p1.2.m2.3.3.3.cmml" xref="S2.I1.i2.p1.2.m2.3.3.3"></eq><apply id="S2.I1.i2.p1.2.m2.3.3.4.cmml" xref="S2.I1.i2.p1.2.m2.3.3.4"><csymbol cd="ambiguous" id="S2.I1.i2.p1.2.m2.3.3.4.1.cmml" xref="S2.I1.i2.p1.2.m2.3.3.4">superscript</csymbol><apply id="S2.I1.i2.p1.2.m2.3.3.4.2.cmml" xref="S2.I1.i2.p1.2.m2.3.3.4"><csymbol cd="ambiguous" id="S2.I1.i2.p1.2.m2.3.3.4.2.1.cmml" xref="S2.I1.i2.p1.2.m2.3.3.4">subscript</csymbol><ci id="S2.I1.i2.p1.2.m2.3.3.4.2.2.cmml" xref="S2.I1.i2.p1.2.m2.3.3.4.2.2">ğ‘„</ci><ci id="S2.I1.i2.p1.2.m2.3.3.4.2.3.cmml" xref="S2.I1.i2.p1.2.m2.3.3.4.2.3">ğ‘–</ci></apply><ci id="S2.I1.i2.p1.2.m2.3.3.4.3a.cmml" xref="S2.I1.i2.p1.2.m2.3.3.4.3"><mtext mathsize="70%" id="S2.I1.i2.p1.2.m2.3.3.4.3.cmml" xref="S2.I1.i2.p1.2.m2.3.3.4.3">obj</mtext></ci></apply><set id="S2.I1.i2.p1.2.m2.3.3.2.3.cmml" xref="S2.I1.i2.p1.2.m2.3.3.2.2"><apply id="S2.I1.i2.p1.2.m2.2.2.1.1.1.cmml" xref="S2.I1.i2.p1.2.m2.2.2.1.1.1"><plus id="S2.I1.i2.p1.2.m2.2.2.1.1.1.1.cmml" xref="S2.I1.i2.p1.2.m2.2.2.1.1.1.1"></plus><apply id="S2.I1.i2.p1.2.m2.2.2.1.1.1.2.cmml" xref="S2.I1.i2.p1.2.m2.2.2.1.1.1.2"><csymbol cd="ambiguous" id="S2.I1.i2.p1.2.m2.2.2.1.1.1.2.1.cmml" xref="S2.I1.i2.p1.2.m2.2.2.1.1.1.2">subscript</csymbol><ci id="S2.I1.i2.p1.2.m2.2.2.1.1.1.2.2.cmml" xref="S2.I1.i2.p1.2.m2.2.2.1.1.1.2.2">ğ‘</ci><ci id="S2.I1.i2.p1.2.m2.2.2.1.1.1.2.3.cmml" xref="S2.I1.i2.p1.2.m2.2.2.1.1.1.2.3">ğ‘–</ci></apply><apply id="S2.I1.i2.p1.2.m2.2.2.1.1.1.3.cmml" xref="S2.I1.i2.p1.2.m2.2.2.1.1.1.3"><csymbol cd="ambiguous" id="S2.I1.i2.p1.2.m2.2.2.1.1.1.3.1.cmml" xref="S2.I1.i2.p1.2.m2.2.2.1.1.1.3">superscript</csymbol><apply id="S2.I1.i2.p1.2.m2.2.2.1.1.1.3.2.cmml" xref="S2.I1.i2.p1.2.m2.2.2.1.1.1.3"><csymbol cd="ambiguous" id="S2.I1.i2.p1.2.m2.2.2.1.1.1.3.2.1.cmml" xref="S2.I1.i2.p1.2.m2.2.2.1.1.1.3">subscript</csymbol><ci id="S2.I1.i2.p1.2.m2.2.2.1.1.1.3.2.2.cmml" xref="S2.I1.i2.p1.2.m2.2.2.1.1.1.3.2.2">ğ‘œ</ci><ci id="S2.I1.i2.p1.2.m2.2.2.1.1.1.3.2.3.cmml" xref="S2.I1.i2.p1.2.m2.2.2.1.1.1.3.2.3">ğ‘–</ci></apply><cn type="integer" id="S2.I1.i2.p1.2.m2.2.2.1.1.1.3.3.cmml" xref="S2.I1.i2.p1.2.m2.2.2.1.1.1.3.3">1</cn></apply></apply><apply id="S2.I1.i2.p1.2.m2.3.3.2.2.2.cmml" xref="S2.I1.i2.p1.2.m2.3.3.2.2.2"><plus id="S2.I1.i2.p1.2.m2.3.3.2.2.2.1.cmml" xref="S2.I1.i2.p1.2.m2.3.3.2.2.2.1"></plus><apply id="S2.I1.i2.p1.2.m2.3.3.2.2.2.2.cmml" xref="S2.I1.i2.p1.2.m2.3.3.2.2.2.2"><csymbol cd="ambiguous" id="S2.I1.i2.p1.2.m2.3.3.2.2.2.2.1.cmml" xref="S2.I1.i2.p1.2.m2.3.3.2.2.2.2">subscript</csymbol><ci id="S2.I1.i2.p1.2.m2.3.3.2.2.2.2.2.cmml" xref="S2.I1.i2.p1.2.m2.3.3.2.2.2.2.2">ğ‘</ci><ci id="S2.I1.i2.p1.2.m2.3.3.2.2.2.2.3.cmml" xref="S2.I1.i2.p1.2.m2.3.3.2.2.2.2.3">ğ‘–</ci></apply><apply id="S2.I1.i2.p1.2.m2.3.3.2.2.2.3.cmml" xref="S2.I1.i2.p1.2.m2.3.3.2.2.2.3"><csymbol cd="ambiguous" id="S2.I1.i2.p1.2.m2.3.3.2.2.2.3.1.cmml" xref="S2.I1.i2.p1.2.m2.3.3.2.2.2.3">superscript</csymbol><apply id="S2.I1.i2.p1.2.m2.3.3.2.2.2.3.2.cmml" xref="S2.I1.i2.p1.2.m2.3.3.2.2.2.3"><csymbol cd="ambiguous" id="S2.I1.i2.p1.2.m2.3.3.2.2.2.3.2.1.cmml" xref="S2.I1.i2.p1.2.m2.3.3.2.2.2.3">subscript</csymbol><ci id="S2.I1.i2.p1.2.m2.3.3.2.2.2.3.2.2.cmml" xref="S2.I1.i2.p1.2.m2.3.3.2.2.2.3.2.2">ğ‘œ</ci><ci id="S2.I1.i2.p1.2.m2.3.3.2.2.2.3.2.3.cmml" xref="S2.I1.i2.p1.2.m2.3.3.2.2.2.3.2.3">ğ‘–</ci></apply><cn type="integer" id="S2.I1.i2.p1.2.m2.3.3.2.2.2.3.3.cmml" xref="S2.I1.i2.p1.2.m2.3.3.2.2.2.3.3">2</cn></apply></apply><ci id="S2.I1.i2.p1.2.m2.1.1.cmml" xref="S2.I1.i2.p1.2.m2.1.1">â‹¯</ci></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i2.p1.2.m2.3c">Q_{i}^{\text{obj}}=\{q_{i}+o_{i}^{1},q_{i}+o_{i}^{2},\cdots\}</annotation></semantics></math>.</p>
</div>
</li>
<li id="S2.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S2.I1.i3.p1" class="ltx_para">
<p id="S2.I1.i3.p1.2" class="ltx_p"><span id="S2.I1.i3.p1.2.1" class="ltx_text ltx_font_bold">BM25-Cap</span> (caption expansion): appending each one of the captions to <math id="S2.I1.i3.p1.1.m1.1" class="ltx_Math" alttext="q_{i}" display="inline"><semantics id="S2.I1.i3.p1.1.m1.1a"><msub id="S2.I1.i3.p1.1.m1.1.1" xref="S2.I1.i3.p1.1.m1.1.1.cmml"><mi id="S2.I1.i3.p1.1.m1.1.1.2" xref="S2.I1.i3.p1.1.m1.1.1.2.cmml">q</mi><mi id="S2.I1.i3.p1.1.m1.1.1.3" xref="S2.I1.i3.p1.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.I1.i3.p1.1.m1.1b"><apply id="S2.I1.i3.p1.1.m1.1.1.cmml" xref="S2.I1.i3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S2.I1.i3.p1.1.m1.1.1.1.cmml" xref="S2.I1.i3.p1.1.m1.1.1">subscript</csymbol><ci id="S2.I1.i3.p1.1.m1.1.1.2.cmml" xref="S2.I1.i3.p1.1.m1.1.1.2">ğ‘</ci><ci id="S2.I1.i3.p1.1.m1.1.1.3.cmml" xref="S2.I1.i3.p1.1.m1.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i3.p1.1.m1.1c">q_{i}</annotation></semantics></math>, i.e., <math id="S2.I1.i3.p1.2.m2.3" class="ltx_Math" alttext="Q_{i}^{\text{cap}}=\{q_{i}+c_{i}^{1},q_{i}+c_{i}^{2},\cdots\}" display="inline"><semantics id="S2.I1.i3.p1.2.m2.3a"><mrow id="S2.I1.i3.p1.2.m2.3.3" xref="S2.I1.i3.p1.2.m2.3.3.cmml"><msubsup id="S2.I1.i3.p1.2.m2.3.3.4" xref="S2.I1.i3.p1.2.m2.3.3.4.cmml"><mi id="S2.I1.i3.p1.2.m2.3.3.4.2.2" xref="S2.I1.i3.p1.2.m2.3.3.4.2.2.cmml">Q</mi><mi id="S2.I1.i3.p1.2.m2.3.3.4.2.3" xref="S2.I1.i3.p1.2.m2.3.3.4.2.3.cmml">i</mi><mtext id="S2.I1.i3.p1.2.m2.3.3.4.3" xref="S2.I1.i3.p1.2.m2.3.3.4.3a.cmml">cap</mtext></msubsup><mo id="S2.I1.i3.p1.2.m2.3.3.3" xref="S2.I1.i3.p1.2.m2.3.3.3.cmml">=</mo><mrow id="S2.I1.i3.p1.2.m2.3.3.2.2" xref="S2.I1.i3.p1.2.m2.3.3.2.3.cmml"><mo stretchy="false" id="S2.I1.i3.p1.2.m2.3.3.2.2.3" xref="S2.I1.i3.p1.2.m2.3.3.2.3.cmml">{</mo><mrow id="S2.I1.i3.p1.2.m2.2.2.1.1.1" xref="S2.I1.i3.p1.2.m2.2.2.1.1.1.cmml"><msub id="S2.I1.i3.p1.2.m2.2.2.1.1.1.2" xref="S2.I1.i3.p1.2.m2.2.2.1.1.1.2.cmml"><mi id="S2.I1.i3.p1.2.m2.2.2.1.1.1.2.2" xref="S2.I1.i3.p1.2.m2.2.2.1.1.1.2.2.cmml">q</mi><mi id="S2.I1.i3.p1.2.m2.2.2.1.1.1.2.3" xref="S2.I1.i3.p1.2.m2.2.2.1.1.1.2.3.cmml">i</mi></msub><mo id="S2.I1.i3.p1.2.m2.2.2.1.1.1.1" xref="S2.I1.i3.p1.2.m2.2.2.1.1.1.1.cmml">+</mo><msubsup id="S2.I1.i3.p1.2.m2.2.2.1.1.1.3" xref="S2.I1.i3.p1.2.m2.2.2.1.1.1.3.cmml"><mi id="S2.I1.i3.p1.2.m2.2.2.1.1.1.3.2.2" xref="S2.I1.i3.p1.2.m2.2.2.1.1.1.3.2.2.cmml">c</mi><mi id="S2.I1.i3.p1.2.m2.2.2.1.1.1.3.2.3" xref="S2.I1.i3.p1.2.m2.2.2.1.1.1.3.2.3.cmml">i</mi><mn id="S2.I1.i3.p1.2.m2.2.2.1.1.1.3.3" xref="S2.I1.i3.p1.2.m2.2.2.1.1.1.3.3.cmml">1</mn></msubsup></mrow><mo id="S2.I1.i3.p1.2.m2.3.3.2.2.4" xref="S2.I1.i3.p1.2.m2.3.3.2.3.cmml">,</mo><mrow id="S2.I1.i3.p1.2.m2.3.3.2.2.2" xref="S2.I1.i3.p1.2.m2.3.3.2.2.2.cmml"><msub id="S2.I1.i3.p1.2.m2.3.3.2.2.2.2" xref="S2.I1.i3.p1.2.m2.3.3.2.2.2.2.cmml"><mi id="S2.I1.i3.p1.2.m2.3.3.2.2.2.2.2" xref="S2.I1.i3.p1.2.m2.3.3.2.2.2.2.2.cmml">q</mi><mi id="S2.I1.i3.p1.2.m2.3.3.2.2.2.2.3" xref="S2.I1.i3.p1.2.m2.3.3.2.2.2.2.3.cmml">i</mi></msub><mo id="S2.I1.i3.p1.2.m2.3.3.2.2.2.1" xref="S2.I1.i3.p1.2.m2.3.3.2.2.2.1.cmml">+</mo><msubsup id="S2.I1.i3.p1.2.m2.3.3.2.2.2.3" xref="S2.I1.i3.p1.2.m2.3.3.2.2.2.3.cmml"><mi id="S2.I1.i3.p1.2.m2.3.3.2.2.2.3.2.2" xref="S2.I1.i3.p1.2.m2.3.3.2.2.2.3.2.2.cmml">c</mi><mi id="S2.I1.i3.p1.2.m2.3.3.2.2.2.3.2.3" xref="S2.I1.i3.p1.2.m2.3.3.2.2.2.3.2.3.cmml">i</mi><mn id="S2.I1.i3.p1.2.m2.3.3.2.2.2.3.3" xref="S2.I1.i3.p1.2.m2.3.3.2.2.2.3.3.cmml">2</mn></msubsup></mrow><mo id="S2.I1.i3.p1.2.m2.3.3.2.2.5" xref="S2.I1.i3.p1.2.m2.3.3.2.3.cmml">,</mo><mi mathvariant="normal" id="S2.I1.i3.p1.2.m2.1.1" xref="S2.I1.i3.p1.2.m2.1.1.cmml">â‹¯</mi><mo stretchy="false" id="S2.I1.i3.p1.2.m2.3.3.2.2.6" xref="S2.I1.i3.p1.2.m2.3.3.2.3.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.I1.i3.p1.2.m2.3b"><apply id="S2.I1.i3.p1.2.m2.3.3.cmml" xref="S2.I1.i3.p1.2.m2.3.3"><eq id="S2.I1.i3.p1.2.m2.3.3.3.cmml" xref="S2.I1.i3.p1.2.m2.3.3.3"></eq><apply id="S2.I1.i3.p1.2.m2.3.3.4.cmml" xref="S2.I1.i3.p1.2.m2.3.3.4"><csymbol cd="ambiguous" id="S2.I1.i3.p1.2.m2.3.3.4.1.cmml" xref="S2.I1.i3.p1.2.m2.3.3.4">superscript</csymbol><apply id="S2.I1.i3.p1.2.m2.3.3.4.2.cmml" xref="S2.I1.i3.p1.2.m2.3.3.4"><csymbol cd="ambiguous" id="S2.I1.i3.p1.2.m2.3.3.4.2.1.cmml" xref="S2.I1.i3.p1.2.m2.3.3.4">subscript</csymbol><ci id="S2.I1.i3.p1.2.m2.3.3.4.2.2.cmml" xref="S2.I1.i3.p1.2.m2.3.3.4.2.2">ğ‘„</ci><ci id="S2.I1.i3.p1.2.m2.3.3.4.2.3.cmml" xref="S2.I1.i3.p1.2.m2.3.3.4.2.3">ğ‘–</ci></apply><ci id="S2.I1.i3.p1.2.m2.3.3.4.3a.cmml" xref="S2.I1.i3.p1.2.m2.3.3.4.3"><mtext mathsize="70%" id="S2.I1.i3.p1.2.m2.3.3.4.3.cmml" xref="S2.I1.i3.p1.2.m2.3.3.4.3">cap</mtext></ci></apply><set id="S2.I1.i3.p1.2.m2.3.3.2.3.cmml" xref="S2.I1.i3.p1.2.m2.3.3.2.2"><apply id="S2.I1.i3.p1.2.m2.2.2.1.1.1.cmml" xref="S2.I1.i3.p1.2.m2.2.2.1.1.1"><plus id="S2.I1.i3.p1.2.m2.2.2.1.1.1.1.cmml" xref="S2.I1.i3.p1.2.m2.2.2.1.1.1.1"></plus><apply id="S2.I1.i3.p1.2.m2.2.2.1.1.1.2.cmml" xref="S2.I1.i3.p1.2.m2.2.2.1.1.1.2"><csymbol cd="ambiguous" id="S2.I1.i3.p1.2.m2.2.2.1.1.1.2.1.cmml" xref="S2.I1.i3.p1.2.m2.2.2.1.1.1.2">subscript</csymbol><ci id="S2.I1.i3.p1.2.m2.2.2.1.1.1.2.2.cmml" xref="S2.I1.i3.p1.2.m2.2.2.1.1.1.2.2">ğ‘</ci><ci id="S2.I1.i3.p1.2.m2.2.2.1.1.1.2.3.cmml" xref="S2.I1.i3.p1.2.m2.2.2.1.1.1.2.3">ğ‘–</ci></apply><apply id="S2.I1.i3.p1.2.m2.2.2.1.1.1.3.cmml" xref="S2.I1.i3.p1.2.m2.2.2.1.1.1.3"><csymbol cd="ambiguous" id="S2.I1.i3.p1.2.m2.2.2.1.1.1.3.1.cmml" xref="S2.I1.i3.p1.2.m2.2.2.1.1.1.3">superscript</csymbol><apply id="S2.I1.i3.p1.2.m2.2.2.1.1.1.3.2.cmml" xref="S2.I1.i3.p1.2.m2.2.2.1.1.1.3"><csymbol cd="ambiguous" id="S2.I1.i3.p1.2.m2.2.2.1.1.1.3.2.1.cmml" xref="S2.I1.i3.p1.2.m2.2.2.1.1.1.3">subscript</csymbol><ci id="S2.I1.i3.p1.2.m2.2.2.1.1.1.3.2.2.cmml" xref="S2.I1.i3.p1.2.m2.2.2.1.1.1.3.2.2">ğ‘</ci><ci id="S2.I1.i3.p1.2.m2.2.2.1.1.1.3.2.3.cmml" xref="S2.I1.i3.p1.2.m2.2.2.1.1.1.3.2.3">ğ‘–</ci></apply><cn type="integer" id="S2.I1.i3.p1.2.m2.2.2.1.1.1.3.3.cmml" xref="S2.I1.i3.p1.2.m2.2.2.1.1.1.3.3">1</cn></apply></apply><apply id="S2.I1.i3.p1.2.m2.3.3.2.2.2.cmml" xref="S2.I1.i3.p1.2.m2.3.3.2.2.2"><plus id="S2.I1.i3.p1.2.m2.3.3.2.2.2.1.cmml" xref="S2.I1.i3.p1.2.m2.3.3.2.2.2.1"></plus><apply id="S2.I1.i3.p1.2.m2.3.3.2.2.2.2.cmml" xref="S2.I1.i3.p1.2.m2.3.3.2.2.2.2"><csymbol cd="ambiguous" id="S2.I1.i3.p1.2.m2.3.3.2.2.2.2.1.cmml" xref="S2.I1.i3.p1.2.m2.3.3.2.2.2.2">subscript</csymbol><ci id="S2.I1.i3.p1.2.m2.3.3.2.2.2.2.2.cmml" xref="S2.I1.i3.p1.2.m2.3.3.2.2.2.2.2">ğ‘</ci><ci id="S2.I1.i3.p1.2.m2.3.3.2.2.2.2.3.cmml" xref="S2.I1.i3.p1.2.m2.3.3.2.2.2.2.3">ğ‘–</ci></apply><apply id="S2.I1.i3.p1.2.m2.3.3.2.2.2.3.cmml" xref="S2.I1.i3.p1.2.m2.3.3.2.2.2.3"><csymbol cd="ambiguous" id="S2.I1.i3.p1.2.m2.3.3.2.2.2.3.1.cmml" xref="S2.I1.i3.p1.2.m2.3.3.2.2.2.3">superscript</csymbol><apply id="S2.I1.i3.p1.2.m2.3.3.2.2.2.3.2.cmml" xref="S2.I1.i3.p1.2.m2.3.3.2.2.2.3"><csymbol cd="ambiguous" id="S2.I1.i3.p1.2.m2.3.3.2.2.2.3.2.1.cmml" xref="S2.I1.i3.p1.2.m2.3.3.2.2.2.3">subscript</csymbol><ci id="S2.I1.i3.p1.2.m2.3.3.2.2.2.3.2.2.cmml" xref="S2.I1.i3.p1.2.m2.3.3.2.2.2.3.2.2">ğ‘</ci><ci id="S2.I1.i3.p1.2.m2.3.3.2.2.2.3.2.3.cmml" xref="S2.I1.i3.p1.2.m2.3.3.2.2.2.3.2.3">ğ‘–</ci></apply><cn type="integer" id="S2.I1.i3.p1.2.m2.3.3.2.2.2.3.3.cmml" xref="S2.I1.i3.p1.2.m2.3.3.2.2.2.3.3">2</cn></apply></apply><ci id="S2.I1.i3.p1.2.m2.1.1.cmml" xref="S2.I1.i3.p1.2.m2.1.1">â‹¯</ci></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i3.p1.2.m2.3c">Q_{i}^{\text{cap}}=\{q_{i}+c_{i}^{1},q_{i}+c_{i}^{2},\cdots\}</annotation></semantics></math>.</p>
</div>
</li>
<li id="S2.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S2.I1.i4.p1" class="ltx_para">
<p id="S2.I1.i4.p1.1" class="ltx_p"><span id="S2.I1.i4.p1.1.1" class="ltx_text ltx_font_bold">BM25-All</span>: taking the union of the above queries
, i.e., <math id="S2.I1.i4.p1.1.m1.1" class="ltx_Math" alttext="Q_{i}^{\text{all}}=Q_{i}^{\text{orig}}\cup Q_{i}^{\text{obj}}\cup Q_{i}^{\text{cap}}" display="inline"><semantics id="S2.I1.i4.p1.1.m1.1a"><mrow id="S2.I1.i4.p1.1.m1.1.1" xref="S2.I1.i4.p1.1.m1.1.1.cmml"><msubsup id="S2.I1.i4.p1.1.m1.1.1.2" xref="S2.I1.i4.p1.1.m1.1.1.2.cmml"><mi id="S2.I1.i4.p1.1.m1.1.1.2.2.2" xref="S2.I1.i4.p1.1.m1.1.1.2.2.2.cmml">Q</mi><mi id="S2.I1.i4.p1.1.m1.1.1.2.2.3" xref="S2.I1.i4.p1.1.m1.1.1.2.2.3.cmml">i</mi><mtext id="S2.I1.i4.p1.1.m1.1.1.2.3" xref="S2.I1.i4.p1.1.m1.1.1.2.3a.cmml">all</mtext></msubsup><mo id="S2.I1.i4.p1.1.m1.1.1.1" xref="S2.I1.i4.p1.1.m1.1.1.1.cmml">=</mo><mrow id="S2.I1.i4.p1.1.m1.1.1.3" xref="S2.I1.i4.p1.1.m1.1.1.3.cmml"><msubsup id="S2.I1.i4.p1.1.m1.1.1.3.2" xref="S2.I1.i4.p1.1.m1.1.1.3.2.cmml"><mi id="S2.I1.i4.p1.1.m1.1.1.3.2.2.2" xref="S2.I1.i4.p1.1.m1.1.1.3.2.2.2.cmml">Q</mi><mi id="S2.I1.i4.p1.1.m1.1.1.3.2.2.3" xref="S2.I1.i4.p1.1.m1.1.1.3.2.2.3.cmml">i</mi><mtext id="S2.I1.i4.p1.1.m1.1.1.3.2.3" xref="S2.I1.i4.p1.1.m1.1.1.3.2.3a.cmml">orig</mtext></msubsup><mo id="S2.I1.i4.p1.1.m1.1.1.3.1" xref="S2.I1.i4.p1.1.m1.1.1.3.1.cmml">âˆª</mo><msubsup id="S2.I1.i4.p1.1.m1.1.1.3.3" xref="S2.I1.i4.p1.1.m1.1.1.3.3.cmml"><mi id="S2.I1.i4.p1.1.m1.1.1.3.3.2.2" xref="S2.I1.i4.p1.1.m1.1.1.3.3.2.2.cmml">Q</mi><mi id="S2.I1.i4.p1.1.m1.1.1.3.3.2.3" xref="S2.I1.i4.p1.1.m1.1.1.3.3.2.3.cmml">i</mi><mtext id="S2.I1.i4.p1.1.m1.1.1.3.3.3" xref="S2.I1.i4.p1.1.m1.1.1.3.3.3a.cmml">obj</mtext></msubsup><mo id="S2.I1.i4.p1.1.m1.1.1.3.1a" xref="S2.I1.i4.p1.1.m1.1.1.3.1.cmml">âˆª</mo><msubsup id="S2.I1.i4.p1.1.m1.1.1.3.4" xref="S2.I1.i4.p1.1.m1.1.1.3.4.cmml"><mi id="S2.I1.i4.p1.1.m1.1.1.3.4.2.2" xref="S2.I1.i4.p1.1.m1.1.1.3.4.2.2.cmml">Q</mi><mi id="S2.I1.i4.p1.1.m1.1.1.3.4.2.3" xref="S2.I1.i4.p1.1.m1.1.1.3.4.2.3.cmml">i</mi><mtext id="S2.I1.i4.p1.1.m1.1.1.3.4.3" xref="S2.I1.i4.p1.1.m1.1.1.3.4.3a.cmml">cap</mtext></msubsup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.I1.i4.p1.1.m1.1b"><apply id="S2.I1.i4.p1.1.m1.1.1.cmml" xref="S2.I1.i4.p1.1.m1.1.1"><eq id="S2.I1.i4.p1.1.m1.1.1.1.cmml" xref="S2.I1.i4.p1.1.m1.1.1.1"></eq><apply id="S2.I1.i4.p1.1.m1.1.1.2.cmml" xref="S2.I1.i4.p1.1.m1.1.1.2"><csymbol cd="ambiguous" id="S2.I1.i4.p1.1.m1.1.1.2.1.cmml" xref="S2.I1.i4.p1.1.m1.1.1.2">superscript</csymbol><apply id="S2.I1.i4.p1.1.m1.1.1.2.2.cmml" xref="S2.I1.i4.p1.1.m1.1.1.2"><csymbol cd="ambiguous" id="S2.I1.i4.p1.1.m1.1.1.2.2.1.cmml" xref="S2.I1.i4.p1.1.m1.1.1.2">subscript</csymbol><ci id="S2.I1.i4.p1.1.m1.1.1.2.2.2.cmml" xref="S2.I1.i4.p1.1.m1.1.1.2.2.2">ğ‘„</ci><ci id="S2.I1.i4.p1.1.m1.1.1.2.2.3.cmml" xref="S2.I1.i4.p1.1.m1.1.1.2.2.3">ğ‘–</ci></apply><ci id="S2.I1.i4.p1.1.m1.1.1.2.3a.cmml" xref="S2.I1.i4.p1.1.m1.1.1.2.3"><mtext mathsize="70%" id="S2.I1.i4.p1.1.m1.1.1.2.3.cmml" xref="S2.I1.i4.p1.1.m1.1.1.2.3">all</mtext></ci></apply><apply id="S2.I1.i4.p1.1.m1.1.1.3.cmml" xref="S2.I1.i4.p1.1.m1.1.1.3"><union id="S2.I1.i4.p1.1.m1.1.1.3.1.cmml" xref="S2.I1.i4.p1.1.m1.1.1.3.1"></union><apply id="S2.I1.i4.p1.1.m1.1.1.3.2.cmml" xref="S2.I1.i4.p1.1.m1.1.1.3.2"><csymbol cd="ambiguous" id="S2.I1.i4.p1.1.m1.1.1.3.2.1.cmml" xref="S2.I1.i4.p1.1.m1.1.1.3.2">superscript</csymbol><apply id="S2.I1.i4.p1.1.m1.1.1.3.2.2.cmml" xref="S2.I1.i4.p1.1.m1.1.1.3.2"><csymbol cd="ambiguous" id="S2.I1.i4.p1.1.m1.1.1.3.2.2.1.cmml" xref="S2.I1.i4.p1.1.m1.1.1.3.2">subscript</csymbol><ci id="S2.I1.i4.p1.1.m1.1.1.3.2.2.2.cmml" xref="S2.I1.i4.p1.1.m1.1.1.3.2.2.2">ğ‘„</ci><ci id="S2.I1.i4.p1.1.m1.1.1.3.2.2.3.cmml" xref="S2.I1.i4.p1.1.m1.1.1.3.2.2.3">ğ‘–</ci></apply><ci id="S2.I1.i4.p1.1.m1.1.1.3.2.3a.cmml" xref="S2.I1.i4.p1.1.m1.1.1.3.2.3"><mtext mathsize="70%" id="S2.I1.i4.p1.1.m1.1.1.3.2.3.cmml" xref="S2.I1.i4.p1.1.m1.1.1.3.2.3">orig</mtext></ci></apply><apply id="S2.I1.i4.p1.1.m1.1.1.3.3.cmml" xref="S2.I1.i4.p1.1.m1.1.1.3.3"><csymbol cd="ambiguous" id="S2.I1.i4.p1.1.m1.1.1.3.3.1.cmml" xref="S2.I1.i4.p1.1.m1.1.1.3.3">superscript</csymbol><apply id="S2.I1.i4.p1.1.m1.1.1.3.3.2.cmml" xref="S2.I1.i4.p1.1.m1.1.1.3.3"><csymbol cd="ambiguous" id="S2.I1.i4.p1.1.m1.1.1.3.3.2.1.cmml" xref="S2.I1.i4.p1.1.m1.1.1.3.3">subscript</csymbol><ci id="S2.I1.i4.p1.1.m1.1.1.3.3.2.2.cmml" xref="S2.I1.i4.p1.1.m1.1.1.3.3.2.2">ğ‘„</ci><ci id="S2.I1.i4.p1.1.m1.1.1.3.3.2.3.cmml" xref="S2.I1.i4.p1.1.m1.1.1.3.3.2.3">ğ‘–</ci></apply><ci id="S2.I1.i4.p1.1.m1.1.1.3.3.3a.cmml" xref="S2.I1.i4.p1.1.m1.1.1.3.3.3"><mtext mathsize="70%" id="S2.I1.i4.p1.1.m1.1.1.3.3.3.cmml" xref="S2.I1.i4.p1.1.m1.1.1.3.3.3">obj</mtext></ci></apply><apply id="S2.I1.i4.p1.1.m1.1.1.3.4.cmml" xref="S2.I1.i4.p1.1.m1.1.1.3.4"><csymbol cd="ambiguous" id="S2.I1.i4.p1.1.m1.1.1.3.4.1.cmml" xref="S2.I1.i4.p1.1.m1.1.1.3.4">superscript</csymbol><apply id="S2.I1.i4.p1.1.m1.1.1.3.4.2.cmml" xref="S2.I1.i4.p1.1.m1.1.1.3.4"><csymbol cd="ambiguous" id="S2.I1.i4.p1.1.m1.1.1.3.4.2.1.cmml" xref="S2.I1.i4.p1.1.m1.1.1.3.4">subscript</csymbol><ci id="S2.I1.i4.p1.1.m1.1.1.3.4.2.2.cmml" xref="S2.I1.i4.p1.1.m1.1.1.3.4.2.2">ğ‘„</ci><ci id="S2.I1.i4.p1.1.m1.1.1.3.4.2.3.cmml" xref="S2.I1.i4.p1.1.m1.1.1.3.4.2.3">ğ‘–</ci></apply><ci id="S2.I1.i4.p1.1.m1.1.1.3.4.3a.cmml" xref="S2.I1.i4.p1.1.m1.1.1.3.4.3"><mtext mathsize="70%" id="S2.I1.i4.p1.1.m1.1.1.3.4.3.cmml" xref="S2.I1.i4.p1.1.m1.1.1.3.4.3">cap</mtext></ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i4.p1.1.m1.1c">Q_{i}^{\text{all}}=Q_{i}^{\text{orig}}\cup Q_{i}^{\text{obj}}\cup Q_{i}^{\text{cap}}</annotation></semantics></math>.</p>
</div>
</li>
</ul>
<p id="S2.SS2.p1.10" class="ltx_p">Since <math id="S2.SS2.p1.4.m1.1" class="ltx_Math" alttext="Q_{i}^{\text{obj/cap/all}}" display="inline"><semantics id="S2.SS2.p1.4.m1.1a"><msubsup id="S2.SS2.p1.4.m1.1.1" xref="S2.SS2.p1.4.m1.1.1.cmml"><mi id="S2.SS2.p1.4.m1.1.1.2.2" xref="S2.SS2.p1.4.m1.1.1.2.2.cmml">Q</mi><mi id="S2.SS2.p1.4.m1.1.1.2.3" xref="S2.SS2.p1.4.m1.1.1.2.3.cmml">i</mi><mtext id="S2.SS2.p1.4.m1.1.1.3" xref="S2.SS2.p1.4.m1.1.1.3a.cmml">obj/cap/all</mtext></msubsup><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.4.m1.1b"><apply id="S2.SS2.p1.4.m1.1.1.cmml" xref="S2.SS2.p1.4.m1.1.1"><csymbol cd="ambiguous" id="S2.SS2.p1.4.m1.1.1.1.cmml" xref="S2.SS2.p1.4.m1.1.1">superscript</csymbol><apply id="S2.SS2.p1.4.m1.1.1.2.cmml" xref="S2.SS2.p1.4.m1.1.1"><csymbol cd="ambiguous" id="S2.SS2.p1.4.m1.1.1.2.1.cmml" xref="S2.SS2.p1.4.m1.1.1">subscript</csymbol><ci id="S2.SS2.p1.4.m1.1.1.2.2.cmml" xref="S2.SS2.p1.4.m1.1.1.2.2">ğ‘„</ci><ci id="S2.SS2.p1.4.m1.1.1.2.3.cmml" xref="S2.SS2.p1.4.m1.1.1.2.3">ğ‘–</ci></apply><ci id="S2.SS2.p1.4.m1.1.1.3a.cmml" xref="S2.SS2.p1.4.m1.1.1.3"><mtext mathsize="70%" id="S2.SS2.p1.4.m1.1.1.3.cmml" xref="S2.SS2.p1.4.m1.1.1.3">obj/cap/all</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.4.m1.1c">Q_{i}^{\text{obj/cap/all}}</annotation></semantics></math> contains multiple BM25 queries for the same information need <math id="S2.SS2.p1.5.m2.1" class="ltx_Math" alttext="Q_{i}" display="inline"><semantics id="S2.SS2.p1.5.m2.1a"><msub id="S2.SS2.p1.5.m2.1.1" xref="S2.SS2.p1.5.m2.1.1.cmml"><mi id="S2.SS2.p1.5.m2.1.1.2" xref="S2.SS2.p1.5.m2.1.1.2.cmml">Q</mi><mi id="S2.SS2.p1.5.m2.1.1.3" xref="S2.SS2.p1.5.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.5.m2.1b"><apply id="S2.SS2.p1.5.m2.1.1.cmml" xref="S2.SS2.p1.5.m2.1.1"><csymbol cd="ambiguous" id="S2.SS2.p1.5.m2.1.1.1.cmml" xref="S2.SS2.p1.5.m2.1.1">subscript</csymbol><ci id="S2.SS2.p1.5.m2.1.1.2.cmml" xref="S2.SS2.p1.5.m2.1.1.2">ğ‘„</ci><ci id="S2.SS2.p1.5.m2.1.1.3.cmml" xref="S2.SS2.p1.5.m2.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.5.m2.1c">Q_{i}</annotation></semantics></math>, we need rank fusion methods to consolidate the ranked lists <math id="S2.SS2.p1.6.m3.1" class="ltx_Math" alttext="R" display="inline"><semantics id="S2.SS2.p1.6.m3.1a"><mi id="S2.SS2.p1.6.m3.1.1" xref="S2.SS2.p1.6.m3.1.1.cmml">R</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.6.m3.1b"><ci id="S2.SS2.p1.6.m3.1.1.cmml" xref="S2.SS2.p1.6.m3.1.1">ğ‘…</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.6.m3.1c">R</annotation></semantics></math> generated by queries within each query set.
This resembles an ensemble process to combine results obtained with different visual signals.
We consider <span id="S2.SS2.p1.10.1" class="ltx_text ltx_font_bold">CombMAX</span>Â <cite class="ltx_cite ltx_citemacro_citep">(Lee, <a href="#bib.bib19" title="" class="ltx_ref">1997</a>; Fox and Shaw, <a href="#bib.bib9" title="" class="ltx_ref">1993</a>)</cite> (taking the maximum score of a passage in different ranked lists), <span id="S2.SS2.p1.10.2" class="ltx_text ltx_font_bold">CombSUM</span>Â <cite class="ltx_cite ltx_citemacro_citep">(Lee, <a href="#bib.bib19" title="" class="ltx_ref">1997</a>; Fox and Shaw, <a href="#bib.bib9" title="" class="ltx_ref">1993</a>)</cite> (taking the sum of scores of a passage in different ranked lists), and <span id="S2.SS2.p1.10.3" class="ltx_text ltx_font_bold">RRF</span> (Reciprocal Rank Fusion)Â <cite class="ltx_cite ltx_citemacro_citep">(Cormack etÂ al., <a href="#bib.bib6" title="" class="ltx_ref">2009</a>)</cite> (the fusion score for a passage <math id="S2.SS2.p1.7.m4.1" class="ltx_Math" alttext="p" display="inline"><semantics id="S2.SS2.p1.7.m4.1a"><mi id="S2.SS2.p1.7.m4.1.1" xref="S2.SS2.p1.7.m4.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.7.m4.1b"><ci id="S2.SS2.p1.7.m4.1.1.cmml" xref="S2.SS2.p1.7.m4.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.7.m4.1c">p</annotation></semantics></math> is defined as <math id="S2.SS2.p1.8.m5.1" class="ltx_Math" alttext="\sum_{r\in R}\frac{1}{const+r(p)}" display="inline"><semantics id="S2.SS2.p1.8.m5.1a"><mrow id="S2.SS2.p1.8.m5.1.2" xref="S2.SS2.p1.8.m5.1.2.cmml"><msub id="S2.SS2.p1.8.m5.1.2.1" xref="S2.SS2.p1.8.m5.1.2.1.cmml"><mo id="S2.SS2.p1.8.m5.1.2.1.2" xref="S2.SS2.p1.8.m5.1.2.1.2.cmml">âˆ‘</mo><mrow id="S2.SS2.p1.8.m5.1.2.1.3" xref="S2.SS2.p1.8.m5.1.2.1.3.cmml"><mi id="S2.SS2.p1.8.m5.1.2.1.3.2" xref="S2.SS2.p1.8.m5.1.2.1.3.2.cmml">r</mi><mo id="S2.SS2.p1.8.m5.1.2.1.3.1" xref="S2.SS2.p1.8.m5.1.2.1.3.1.cmml">âˆˆ</mo><mi id="S2.SS2.p1.8.m5.1.2.1.3.3" xref="S2.SS2.p1.8.m5.1.2.1.3.3.cmml">R</mi></mrow></msub><mfrac id="S2.SS2.p1.8.m5.1.1" xref="S2.SS2.p1.8.m5.1.1.cmml"><mn id="S2.SS2.p1.8.m5.1.1.3" xref="S2.SS2.p1.8.m5.1.1.3.cmml">1</mn><mrow id="S2.SS2.p1.8.m5.1.1.1" xref="S2.SS2.p1.8.m5.1.1.1.cmml"><mrow id="S2.SS2.p1.8.m5.1.1.1.3" xref="S2.SS2.p1.8.m5.1.1.1.3.cmml"><mi id="S2.SS2.p1.8.m5.1.1.1.3.2" xref="S2.SS2.p1.8.m5.1.1.1.3.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S2.SS2.p1.8.m5.1.1.1.3.1" xref="S2.SS2.p1.8.m5.1.1.1.3.1.cmml">â€‹</mo><mi id="S2.SS2.p1.8.m5.1.1.1.3.3" xref="S2.SS2.p1.8.m5.1.1.1.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S2.SS2.p1.8.m5.1.1.1.3.1a" xref="S2.SS2.p1.8.m5.1.1.1.3.1.cmml">â€‹</mo><mi id="S2.SS2.p1.8.m5.1.1.1.3.4" xref="S2.SS2.p1.8.m5.1.1.1.3.4.cmml">n</mi><mo lspace="0em" rspace="0em" id="S2.SS2.p1.8.m5.1.1.1.3.1b" xref="S2.SS2.p1.8.m5.1.1.1.3.1.cmml">â€‹</mo><mi id="S2.SS2.p1.8.m5.1.1.1.3.5" xref="S2.SS2.p1.8.m5.1.1.1.3.5.cmml">s</mi><mo lspace="0em" rspace="0em" id="S2.SS2.p1.8.m5.1.1.1.3.1c" xref="S2.SS2.p1.8.m5.1.1.1.3.1.cmml">â€‹</mo><mi id="S2.SS2.p1.8.m5.1.1.1.3.6" xref="S2.SS2.p1.8.m5.1.1.1.3.6.cmml">t</mi></mrow><mo id="S2.SS2.p1.8.m5.1.1.1.2" xref="S2.SS2.p1.8.m5.1.1.1.2.cmml">+</mo><mrow id="S2.SS2.p1.8.m5.1.1.1.4" xref="S2.SS2.p1.8.m5.1.1.1.4.cmml"><mi id="S2.SS2.p1.8.m5.1.1.1.4.2" xref="S2.SS2.p1.8.m5.1.1.1.4.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S2.SS2.p1.8.m5.1.1.1.4.1" xref="S2.SS2.p1.8.m5.1.1.1.4.1.cmml">â€‹</mo><mrow id="S2.SS2.p1.8.m5.1.1.1.4.3.2" xref="S2.SS2.p1.8.m5.1.1.1.4.cmml"><mo stretchy="false" id="S2.SS2.p1.8.m5.1.1.1.4.3.2.1" xref="S2.SS2.p1.8.m5.1.1.1.4.cmml">(</mo><mi id="S2.SS2.p1.8.m5.1.1.1.1" xref="S2.SS2.p1.8.m5.1.1.1.1.cmml">p</mi><mo stretchy="false" id="S2.SS2.p1.8.m5.1.1.1.4.3.2.2" xref="S2.SS2.p1.8.m5.1.1.1.4.cmml">)</mo></mrow></mrow></mrow></mfrac></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.8.m5.1b"><apply id="S2.SS2.p1.8.m5.1.2.cmml" xref="S2.SS2.p1.8.m5.1.2"><apply id="S2.SS2.p1.8.m5.1.2.1.cmml" xref="S2.SS2.p1.8.m5.1.2.1"><csymbol cd="ambiguous" id="S2.SS2.p1.8.m5.1.2.1.1.cmml" xref="S2.SS2.p1.8.m5.1.2.1">subscript</csymbol><sum id="S2.SS2.p1.8.m5.1.2.1.2.cmml" xref="S2.SS2.p1.8.m5.1.2.1.2"></sum><apply id="S2.SS2.p1.8.m5.1.2.1.3.cmml" xref="S2.SS2.p1.8.m5.1.2.1.3"><in id="S2.SS2.p1.8.m5.1.2.1.3.1.cmml" xref="S2.SS2.p1.8.m5.1.2.1.3.1"></in><ci id="S2.SS2.p1.8.m5.1.2.1.3.2.cmml" xref="S2.SS2.p1.8.m5.1.2.1.3.2">ğ‘Ÿ</ci><ci id="S2.SS2.p1.8.m5.1.2.1.3.3.cmml" xref="S2.SS2.p1.8.m5.1.2.1.3.3">ğ‘…</ci></apply></apply><apply id="S2.SS2.p1.8.m5.1.1.cmml" xref="S2.SS2.p1.8.m5.1.1"><divide id="S2.SS2.p1.8.m5.1.1.2.cmml" xref="S2.SS2.p1.8.m5.1.1"></divide><cn type="integer" id="S2.SS2.p1.8.m5.1.1.3.cmml" xref="S2.SS2.p1.8.m5.1.1.3">1</cn><apply id="S2.SS2.p1.8.m5.1.1.1.cmml" xref="S2.SS2.p1.8.m5.1.1.1"><plus id="S2.SS2.p1.8.m5.1.1.1.2.cmml" xref="S2.SS2.p1.8.m5.1.1.1.2"></plus><apply id="S2.SS2.p1.8.m5.1.1.1.3.cmml" xref="S2.SS2.p1.8.m5.1.1.1.3"><times id="S2.SS2.p1.8.m5.1.1.1.3.1.cmml" xref="S2.SS2.p1.8.m5.1.1.1.3.1"></times><ci id="S2.SS2.p1.8.m5.1.1.1.3.2.cmml" xref="S2.SS2.p1.8.m5.1.1.1.3.2">ğ‘</ci><ci id="S2.SS2.p1.8.m5.1.1.1.3.3.cmml" xref="S2.SS2.p1.8.m5.1.1.1.3.3">ğ‘œ</ci><ci id="S2.SS2.p1.8.m5.1.1.1.3.4.cmml" xref="S2.SS2.p1.8.m5.1.1.1.3.4">ğ‘›</ci><ci id="S2.SS2.p1.8.m5.1.1.1.3.5.cmml" xref="S2.SS2.p1.8.m5.1.1.1.3.5">ğ‘ </ci><ci id="S2.SS2.p1.8.m5.1.1.1.3.6.cmml" xref="S2.SS2.p1.8.m5.1.1.1.3.6">ğ‘¡</ci></apply><apply id="S2.SS2.p1.8.m5.1.1.1.4.cmml" xref="S2.SS2.p1.8.m5.1.1.1.4"><times id="S2.SS2.p1.8.m5.1.1.1.4.1.cmml" xref="S2.SS2.p1.8.m5.1.1.1.4.1"></times><ci id="S2.SS2.p1.8.m5.1.1.1.4.2.cmml" xref="S2.SS2.p1.8.m5.1.1.1.4.2">ğ‘Ÿ</ci><ci id="S2.SS2.p1.8.m5.1.1.1.1.cmml" xref="S2.SS2.p1.8.m5.1.1.1.1">ğ‘</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.8.m5.1c">\sum_{r\in R}\frac{1}{const+r(p)}</annotation></semantics></math>, where <math id="S2.SS2.p1.9.m6.1" class="ltx_Math" alttext="r(\cdot)" display="inline"><semantics id="S2.SS2.p1.9.m6.1a"><mrow id="S2.SS2.p1.9.m6.1.2" xref="S2.SS2.p1.9.m6.1.2.cmml"><mi id="S2.SS2.p1.9.m6.1.2.2" xref="S2.SS2.p1.9.m6.1.2.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S2.SS2.p1.9.m6.1.2.1" xref="S2.SS2.p1.9.m6.1.2.1.cmml">â€‹</mo><mrow id="S2.SS2.p1.9.m6.1.2.3.2" xref="S2.SS2.p1.9.m6.1.2.cmml"><mo stretchy="false" id="S2.SS2.p1.9.m6.1.2.3.2.1" xref="S2.SS2.p1.9.m6.1.2.cmml">(</mo><mo lspace="0em" rspace="0em" id="S2.SS2.p1.9.m6.1.1" xref="S2.SS2.p1.9.m6.1.1.cmml">â‹…</mo><mo stretchy="false" id="S2.SS2.p1.9.m6.1.2.3.2.2" xref="S2.SS2.p1.9.m6.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.9.m6.1b"><apply id="S2.SS2.p1.9.m6.1.2.cmml" xref="S2.SS2.p1.9.m6.1.2"><times id="S2.SS2.p1.9.m6.1.2.1.cmml" xref="S2.SS2.p1.9.m6.1.2.1"></times><ci id="S2.SS2.p1.9.m6.1.2.2.cmml" xref="S2.SS2.p1.9.m6.1.2.2">ğ‘Ÿ</ci><ci id="S2.SS2.p1.9.m6.1.1.cmml" xref="S2.SS2.p1.9.m6.1.1">â‹…</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.9.m6.1c">r(\cdot)</annotation></semantics></math> is the rank of <math id="S2.SS2.p1.10.m7.1" class="ltx_Math" alttext="p" display="inline"><semantics id="S2.SS2.p1.10.m7.1a"><mi id="S2.SS2.p1.10.m7.1.1" xref="S2.SS2.p1.10.m7.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.10.m7.1b"><ci id="S2.SS2.p1.10.m7.1.1.cmml" xref="S2.SS2.p1.10.m7.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.10.m7.1c">p</annotation></semantics></math>).
CombMAX could help the model be more robust to distracting visual signals while the other two fusion approaches make sure that the impacts of lower-ranked passages do not vanish.</p>
</div>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3. </span>Dense Retrieval</h3>

<figure id="S2.F2" class="ltx_figure"><img src="/html/2105.03938/assets/x2.png" id="S2.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="217" height="58" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S2.F2.2.1.1" class="ltx_text" style="font-size:90%;">Figure 2</span>. </span><span id="S2.F2.3.2" class="ltx_text" style="font-size:90%;">Dense retrieval with neural dual encoders.</span></figcaption>
</figure>
<div id="S2.SS3.p1" class="ltx_para">
<p id="S2.SS3.p1.1" class="ltx_p">Following previous workÂ <cite class="ltx_cite ltx_citemacro_citep">(Karpukhin etÂ al., <a href="#bib.bib16" title="" class="ltx_ref">2020</a>; Xiong etÂ al., <a href="#bib.bib42" title="" class="ltx_ref">2020a</a>; Qu etÂ al., <a href="#bib.bib30" title="" class="ltx_ref">2020a</a>; Lee etÂ al., <a href="#bib.bib20" title="" class="ltx_ref">2019</a>)</cite>, we adopt a dual-encoder architecture to construct a learnable retriever. The retrieval process is â€œdenseâ€ in the sense that the queries and passages are encoded to low-dimensional dense vectors, as opposed to the high-dimensional sparse vectors used in sparse retrieval. As shown in Fig.Â <a href="#S2.F2" title="Figure 2 â€£ 2.3. Dense Retrieval â€£ 2. Passage Retrieval for OK-VQA â€£ Passage Retrieval for Outside-Knowledge Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, the retriever consists of a query encoder and a passage encoder.</p>
</div>
<section id="S2.SS3.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.3.1. </span><span id="S2.SS3.SSS1.1.1" class="ltx_text ltx_font_bold">Query Encoder</span>
</h4>

<div id="S2.SS3.SSS1.p1" class="ltx_para">
<p id="S2.SS3.SSS1.p1.2" class="ltx_p">We adopt the LXMERT modelÂ <cite class="ltx_cite ltx_citemacro_citep">(Tan and Bansal, <a href="#bib.bib35" title="" class="ltx_ref">2019</a>)</cite> as the query encoder since it can encode both the question and image components of <math id="S2.SS3.SSS1.p1.1.m1.1" class="ltx_Math" alttext="Q_{i}" display="inline"><semantics id="S2.SS3.SSS1.p1.1.m1.1a"><msub id="S2.SS3.SSS1.p1.1.m1.1.1" xref="S2.SS3.SSS1.p1.1.m1.1.1.cmml"><mi id="S2.SS3.SSS1.p1.1.m1.1.1.2" xref="S2.SS3.SSS1.p1.1.m1.1.1.2.cmml">Q</mi><mi id="S2.SS3.SSS1.p1.1.m1.1.1.3" xref="S2.SS3.SSS1.p1.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS3.SSS1.p1.1.m1.1b"><apply id="S2.SS3.SSS1.p1.1.m1.1.1.cmml" xref="S2.SS3.SSS1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S2.SS3.SSS1.p1.1.m1.1.1.1.cmml" xref="S2.SS3.SSS1.p1.1.m1.1.1">subscript</csymbol><ci id="S2.SS3.SSS1.p1.1.m1.1.1.2.cmml" xref="S2.SS3.SSS1.p1.1.m1.1.1.2">ğ‘„</ci><ci id="S2.SS3.SSS1.p1.1.m1.1.1.3.cmml" xref="S2.SS3.SSS1.p1.1.m1.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.SSS1.p1.1.m1.1c">Q_{i}</annotation></semantics></math>. LXMERT is a pre-trained Transformer modelÂ <cite class="ltx_cite ltx_citemacro_citep">(Vaswani etÂ al., <a href="#bib.bib36" title="" class="ltx_ref">2017</a>)</cite> designed to learn vision and language connections. It consists of three encoders, an object relationship encoder, a language encoder, and a cross-modality encoder. The first two single-modality encoders function in a similar way to BERTÂ <cite class="ltx_cite ltx_citemacro_citep">(Devlin etÂ al., <a href="#bib.bib8" title="" class="ltx_ref">2019</a>)</cite> except that the object relationship encoder works with a set of object detections produced by a Faster R-CNNÂ <cite class="ltx_cite ltx_citemacro_citep">(Ren etÂ al., <a href="#bib.bib34" title="" class="ltx_ref">2015</a>)</cite> model pre-trained on Visual GenomeÂ <cite class="ltx_cite ltx_citemacro_citep">(Anderson etÂ al., <a href="#bib.bib2" title="" class="ltx_ref">2018</a>; Krishna etÂ al., <a href="#bib.bib18" title="" class="ltx_ref">2016</a>)</cite>. Each detection representation can be considered as an â€œimage token embeddingâ€ that consists of its RoI features (fixed) and position features (trainable). The cross-modality encoder conducts bi-directional cross attention between vision and language representations.
We refer our readers to the LXMERT paperÂ <cite class="ltx_cite ltx_citemacro_citep">(Tan and Bansal, <a href="#bib.bib35" title="" class="ltx_ref">2019</a>)</cite> for further details. We project the cross-modality output of LXMERT to an <math id="S2.SS3.SSS1.p1.2.m2.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S2.SS3.SSS1.p1.2.m2.1a"><mi id="S2.SS3.SSS1.p1.2.m2.1.1" xref="S2.SS3.SSS1.p1.2.m2.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.SSS1.p1.2.m2.1b"><ci id="S2.SS3.SSS1.p1.2.m2.1.1.cmml" xref="S2.SS3.SSS1.p1.2.m2.1.1">ğ‘›</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.SSS1.p1.2.m2.1c">n</annotation></semantics></math>-dimensional query representation. The dense retriever with a LXMERT query encoder is referred to as <span id="S2.SS3.SSS1.p1.2.1" class="ltx_text ltx_font_bold">Dense-LXMERT</span>. To adopt a deeper analytical view, we also consider BERT as the query encoder, which only works with the question component of the query, resulting in the <span id="S2.SS3.SSS1.p1.2.2" class="ltx_text ltx_font_bold">Dense-BERT</span> model.</p>
</div>
</section>
<section id="S2.SS3.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.3.2. </span><span id="S2.SS3.SSS2.1.1" class="ltx_text ltx_font_bold">Passage Encoder</span>
</h4>

<div id="S2.SS3.SSS2.p1" class="ltx_para">
<p id="S2.SS3.SSS2.p1.1" class="ltx_p">We use BERT as the passage encoder and project the <span id="S2.SS3.SSS2.p1.1.1" class="ltx_text ltx_font_typewriter">[CLS]</span> representation to an <math id="S2.SS3.SSS2.p1.1.m1.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S2.SS3.SSS2.p1.1.m1.1a"><mi id="S2.SS3.SSS2.p1.1.m1.1.1" xref="S2.SS3.SSS2.p1.1.m1.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.SSS2.p1.1.m1.1b"><ci id="S2.SS3.SSS2.p1.1.m1.1.1.cmml" xref="S2.SS3.SSS2.p1.1.m1.1.1">ğ‘›</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.SSS2.p1.1.m1.1c">n</annotation></semantics></math>-dimensional passage representation. The retrieval score is defined as the dot product of the query and passage representations.
After training, we encode all passages in the collection during an offline process. At inference time, we use FaissÂ <cite class="ltx_cite ltx_citemacro_citep">(Johnson etÂ al., <a href="#bib.bib15" title="" class="ltx_ref">2017</a>)</cite>
for maximum inner product search.</p>
</div>
</section>
<section id="S2.SS3.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.3.3. </span><span id="S2.SS3.SSS3.1.1" class="ltx_text ltx_font_bold">Training</span>
</h4>

<div id="S2.SS3.SSS3.p1" class="ltx_para">
<p id="S2.SS3.SSS3.p1.5" class="ltx_p">We train the dual-encoder retriever with a set of training instances. Each instance is denoted as <math id="S2.SS3.SSS3.p1.1.m1.3" class="ltx_Math" alttext="\langle Q_{i},p_{i}^{+},p_{i}^{-}\rangle" display="inline"><semantics id="S2.SS3.SSS3.p1.1.m1.3a"><mrow id="S2.SS3.SSS3.p1.1.m1.3.3.3" xref="S2.SS3.SSS3.p1.1.m1.3.3.4.cmml"><mo stretchy="false" id="S2.SS3.SSS3.p1.1.m1.3.3.3.4" xref="S2.SS3.SSS3.p1.1.m1.3.3.4.cmml">âŸ¨</mo><msub id="S2.SS3.SSS3.p1.1.m1.1.1.1.1" xref="S2.SS3.SSS3.p1.1.m1.1.1.1.1.cmml"><mi id="S2.SS3.SSS3.p1.1.m1.1.1.1.1.2" xref="S2.SS3.SSS3.p1.1.m1.1.1.1.1.2.cmml">Q</mi><mi id="S2.SS3.SSS3.p1.1.m1.1.1.1.1.3" xref="S2.SS3.SSS3.p1.1.m1.1.1.1.1.3.cmml">i</mi></msub><mo id="S2.SS3.SSS3.p1.1.m1.3.3.3.5" xref="S2.SS3.SSS3.p1.1.m1.3.3.4.cmml">,</mo><msubsup id="S2.SS3.SSS3.p1.1.m1.2.2.2.2" xref="S2.SS3.SSS3.p1.1.m1.2.2.2.2.cmml"><mi id="S2.SS3.SSS3.p1.1.m1.2.2.2.2.2.2" xref="S2.SS3.SSS3.p1.1.m1.2.2.2.2.2.2.cmml">p</mi><mi id="S2.SS3.SSS3.p1.1.m1.2.2.2.2.2.3" xref="S2.SS3.SSS3.p1.1.m1.2.2.2.2.2.3.cmml">i</mi><mo id="S2.SS3.SSS3.p1.1.m1.2.2.2.2.3" xref="S2.SS3.SSS3.p1.1.m1.2.2.2.2.3.cmml">+</mo></msubsup><mo id="S2.SS3.SSS3.p1.1.m1.3.3.3.6" xref="S2.SS3.SSS3.p1.1.m1.3.3.4.cmml">,</mo><msubsup id="S2.SS3.SSS3.p1.1.m1.3.3.3.3" xref="S2.SS3.SSS3.p1.1.m1.3.3.3.3.cmml"><mi id="S2.SS3.SSS3.p1.1.m1.3.3.3.3.2.2" xref="S2.SS3.SSS3.p1.1.m1.3.3.3.3.2.2.cmml">p</mi><mi id="S2.SS3.SSS3.p1.1.m1.3.3.3.3.2.3" xref="S2.SS3.SSS3.p1.1.m1.3.3.3.3.2.3.cmml">i</mi><mo id="S2.SS3.SSS3.p1.1.m1.3.3.3.3.3" xref="S2.SS3.SSS3.p1.1.m1.3.3.3.3.3.cmml">âˆ’</mo></msubsup><mo stretchy="false" id="S2.SS3.SSS3.p1.1.m1.3.3.3.7" xref="S2.SS3.SSS3.p1.1.m1.3.3.4.cmml">âŸ©</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.SSS3.p1.1.m1.3b"><list id="S2.SS3.SSS3.p1.1.m1.3.3.4.cmml" xref="S2.SS3.SSS3.p1.1.m1.3.3.3"><apply id="S2.SS3.SSS3.p1.1.m1.1.1.1.1.cmml" xref="S2.SS3.SSS3.p1.1.m1.1.1.1.1"><csymbol cd="ambiguous" id="S2.SS3.SSS3.p1.1.m1.1.1.1.1.1.cmml" xref="S2.SS3.SSS3.p1.1.m1.1.1.1.1">subscript</csymbol><ci id="S2.SS3.SSS3.p1.1.m1.1.1.1.1.2.cmml" xref="S2.SS3.SSS3.p1.1.m1.1.1.1.1.2">ğ‘„</ci><ci id="S2.SS3.SSS3.p1.1.m1.1.1.1.1.3.cmml" xref="S2.SS3.SSS3.p1.1.m1.1.1.1.1.3">ğ‘–</ci></apply><apply id="S2.SS3.SSS3.p1.1.m1.2.2.2.2.cmml" xref="S2.SS3.SSS3.p1.1.m1.2.2.2.2"><csymbol cd="ambiguous" id="S2.SS3.SSS3.p1.1.m1.2.2.2.2.1.cmml" xref="S2.SS3.SSS3.p1.1.m1.2.2.2.2">superscript</csymbol><apply id="S2.SS3.SSS3.p1.1.m1.2.2.2.2.2.cmml" xref="S2.SS3.SSS3.p1.1.m1.2.2.2.2"><csymbol cd="ambiguous" id="S2.SS3.SSS3.p1.1.m1.2.2.2.2.2.1.cmml" xref="S2.SS3.SSS3.p1.1.m1.2.2.2.2">subscript</csymbol><ci id="S2.SS3.SSS3.p1.1.m1.2.2.2.2.2.2.cmml" xref="S2.SS3.SSS3.p1.1.m1.2.2.2.2.2.2">ğ‘</ci><ci id="S2.SS3.SSS3.p1.1.m1.2.2.2.2.2.3.cmml" xref="S2.SS3.SSS3.p1.1.m1.2.2.2.2.2.3">ğ‘–</ci></apply><plus id="S2.SS3.SSS3.p1.1.m1.2.2.2.2.3.cmml" xref="S2.SS3.SSS3.p1.1.m1.2.2.2.2.3"></plus></apply><apply id="S2.SS3.SSS3.p1.1.m1.3.3.3.3.cmml" xref="S2.SS3.SSS3.p1.1.m1.3.3.3.3"><csymbol cd="ambiguous" id="S2.SS3.SSS3.p1.1.m1.3.3.3.3.1.cmml" xref="S2.SS3.SSS3.p1.1.m1.3.3.3.3">superscript</csymbol><apply id="S2.SS3.SSS3.p1.1.m1.3.3.3.3.2.cmml" xref="S2.SS3.SSS3.p1.1.m1.3.3.3.3"><csymbol cd="ambiguous" id="S2.SS3.SSS3.p1.1.m1.3.3.3.3.2.1.cmml" xref="S2.SS3.SSS3.p1.1.m1.3.3.3.3">subscript</csymbol><ci id="S2.SS3.SSS3.p1.1.m1.3.3.3.3.2.2.cmml" xref="S2.SS3.SSS3.p1.1.m1.3.3.3.3.2.2">ğ‘</ci><ci id="S2.SS3.SSS3.p1.1.m1.3.3.3.3.2.3.cmml" xref="S2.SS3.SSS3.p1.1.m1.3.3.3.3.2.3">ğ‘–</ci></apply><minus id="S2.SS3.SSS3.p1.1.m1.3.3.3.3.3.cmml" xref="S2.SS3.SSS3.p1.1.m1.3.3.3.3.3"></minus></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.SSS3.p1.1.m1.3c">\langle Q_{i},p_{i}^{+},p_{i}^{-}\rangle</annotation></semantics></math>, where <math id="S2.SS3.SSS3.p1.2.m2.1" class="ltx_Math" alttext="p_{i}^{+}" display="inline"><semantics id="S2.SS3.SSS3.p1.2.m2.1a"><msubsup id="S2.SS3.SSS3.p1.2.m2.1.1" xref="S2.SS3.SSS3.p1.2.m2.1.1.cmml"><mi id="S2.SS3.SSS3.p1.2.m2.1.1.2.2" xref="S2.SS3.SSS3.p1.2.m2.1.1.2.2.cmml">p</mi><mi id="S2.SS3.SSS3.p1.2.m2.1.1.2.3" xref="S2.SS3.SSS3.p1.2.m2.1.1.2.3.cmml">i</mi><mo id="S2.SS3.SSS3.p1.2.m2.1.1.3" xref="S2.SS3.SSS3.p1.2.m2.1.1.3.cmml">+</mo></msubsup><annotation-xml encoding="MathML-Content" id="S2.SS3.SSS3.p1.2.m2.1b"><apply id="S2.SS3.SSS3.p1.2.m2.1.1.cmml" xref="S2.SS3.SSS3.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S2.SS3.SSS3.p1.2.m2.1.1.1.cmml" xref="S2.SS3.SSS3.p1.2.m2.1.1">superscript</csymbol><apply id="S2.SS3.SSS3.p1.2.m2.1.1.2.cmml" xref="S2.SS3.SSS3.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S2.SS3.SSS3.p1.2.m2.1.1.2.1.cmml" xref="S2.SS3.SSS3.p1.2.m2.1.1">subscript</csymbol><ci id="S2.SS3.SSS3.p1.2.m2.1.1.2.2.cmml" xref="S2.SS3.SSS3.p1.2.m2.1.1.2.2">ğ‘</ci><ci id="S2.SS3.SSS3.p1.2.m2.1.1.2.3.cmml" xref="S2.SS3.SSS3.p1.2.m2.1.1.2.3">ğ‘–</ci></apply><plus id="S2.SS3.SSS3.p1.2.m2.1.1.3.cmml" xref="S2.SS3.SSS3.p1.2.m2.1.1.3"></plus></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.SSS3.p1.2.m2.1c">p_{i}^{+}</annotation></semantics></math> is a positive passage that contains the answer while <math id="S2.SS3.SSS3.p1.3.m3.1" class="ltx_Math" alttext="p_{i}^{-}" display="inline"><semantics id="S2.SS3.SSS3.p1.3.m3.1a"><msubsup id="S2.SS3.SSS3.p1.3.m3.1.1" xref="S2.SS3.SSS3.p1.3.m3.1.1.cmml"><mi id="S2.SS3.SSS3.p1.3.m3.1.1.2.2" xref="S2.SS3.SSS3.p1.3.m3.1.1.2.2.cmml">p</mi><mi id="S2.SS3.SSS3.p1.3.m3.1.1.2.3" xref="S2.SS3.SSS3.p1.3.m3.1.1.2.3.cmml">i</mi><mo id="S2.SS3.SSS3.p1.3.m3.1.1.3" xref="S2.SS3.SSS3.p1.3.m3.1.1.3.cmml">âˆ’</mo></msubsup><annotation-xml encoding="MathML-Content" id="S2.SS3.SSS3.p1.3.m3.1b"><apply id="S2.SS3.SSS3.p1.3.m3.1.1.cmml" xref="S2.SS3.SSS3.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S2.SS3.SSS3.p1.3.m3.1.1.1.cmml" xref="S2.SS3.SSS3.p1.3.m3.1.1">superscript</csymbol><apply id="S2.SS3.SSS3.p1.3.m3.1.1.2.cmml" xref="S2.SS3.SSS3.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S2.SS3.SSS3.p1.3.m3.1.1.2.1.cmml" xref="S2.SS3.SSS3.p1.3.m3.1.1">subscript</csymbol><ci id="S2.SS3.SSS3.p1.3.m3.1.1.2.2.cmml" xref="S2.SS3.SSS3.p1.3.m3.1.1.2.2">ğ‘</ci><ci id="S2.SS3.SSS3.p1.3.m3.1.1.2.3.cmml" xref="S2.SS3.SSS3.p1.3.m3.1.1.2.3">ğ‘–</ci></apply><minus id="S2.SS3.SSS3.p1.3.m3.1.1.3.cmml" xref="S2.SS3.SSS3.p1.3.m3.1.1.3"></minus></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.SSS3.p1.3.m3.1c">p_{i}^{-}</annotation></semantics></math> is a negative passage that does not contain the answer. In our case, we select <math id="S2.SS3.SSS3.p1.4.m4.1" class="ltx_Math" alttext="p_{i}^{-}" display="inline"><semantics id="S2.SS3.SSS3.p1.4.m4.1a"><msubsup id="S2.SS3.SSS3.p1.4.m4.1.1" xref="S2.SS3.SSS3.p1.4.m4.1.1.cmml"><mi id="S2.SS3.SSS3.p1.4.m4.1.1.2.2" xref="S2.SS3.SSS3.p1.4.m4.1.1.2.2.cmml">p</mi><mi id="S2.SS3.SSS3.p1.4.m4.1.1.2.3" xref="S2.SS3.SSS3.p1.4.m4.1.1.2.3.cmml">i</mi><mo id="S2.SS3.SSS3.p1.4.m4.1.1.3" xref="S2.SS3.SSS3.p1.4.m4.1.1.3.cmml">âˆ’</mo></msubsup><annotation-xml encoding="MathML-Content" id="S2.SS3.SSS3.p1.4.m4.1b"><apply id="S2.SS3.SSS3.p1.4.m4.1.1.cmml" xref="S2.SS3.SSS3.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S2.SS3.SSS3.p1.4.m4.1.1.1.cmml" xref="S2.SS3.SSS3.p1.4.m4.1.1">superscript</csymbol><apply id="S2.SS3.SSS3.p1.4.m4.1.1.2.cmml" xref="S2.SS3.SSS3.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S2.SS3.SSS3.p1.4.m4.1.1.2.1.cmml" xref="S2.SS3.SSS3.p1.4.m4.1.1">subscript</csymbol><ci id="S2.SS3.SSS3.p1.4.m4.1.1.2.2.cmml" xref="S2.SS3.SSS3.p1.4.m4.1.1.2.2">ğ‘</ci><ci id="S2.SS3.SSS3.p1.4.m4.1.1.2.3.cmml" xref="S2.SS3.SSS3.p1.4.m4.1.1.2.3">ğ‘–</ci></apply><minus id="S2.SS3.SSS3.p1.4.m4.1.1.3.cmml" xref="S2.SS3.SSS3.p1.4.m4.1.1.3"></minus></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.SSS3.p1.4.m4.1c">p_{i}^{-}</annotation></semantics></math> from the top passages retrieved by a sparse retrieval method. Thus, <math id="S2.SS3.SSS3.p1.5.m5.1" class="ltx_Math" alttext="p_{i}^{-}" display="inline"><semantics id="S2.SS3.SSS3.p1.5.m5.1a"><msubsup id="S2.SS3.SSS3.p1.5.m5.1.1" xref="S2.SS3.SSS3.p1.5.m5.1.1.cmml"><mi id="S2.SS3.SSS3.p1.5.m5.1.1.2.2" xref="S2.SS3.SSS3.p1.5.m5.1.1.2.2.cmml">p</mi><mi id="S2.SS3.SSS3.p1.5.m5.1.1.2.3" xref="S2.SS3.SSS3.p1.5.m5.1.1.2.3.cmml">i</mi><mo id="S2.SS3.SSS3.p1.5.m5.1.1.3" xref="S2.SS3.SSS3.p1.5.m5.1.1.3.cmml">âˆ’</mo></msubsup><annotation-xml encoding="MathML-Content" id="S2.SS3.SSS3.p1.5.m5.1b"><apply id="S2.SS3.SSS3.p1.5.m5.1.1.cmml" xref="S2.SS3.SSS3.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S2.SS3.SSS3.p1.5.m5.1.1.1.cmml" xref="S2.SS3.SSS3.p1.5.m5.1.1">superscript</csymbol><apply id="S2.SS3.SSS3.p1.5.m5.1.1.2.cmml" xref="S2.SS3.SSS3.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S2.SS3.SSS3.p1.5.m5.1.1.2.1.cmml" xref="S2.SS3.SSS3.p1.5.m5.1.1">subscript</csymbol><ci id="S2.SS3.SSS3.p1.5.m5.1.1.2.2.cmml" xref="S2.SS3.SSS3.p1.5.m5.1.1.2.2">ğ‘</ci><ci id="S2.SS3.SSS3.p1.5.m5.1.1.2.3.cmml" xref="S2.SS3.SSS3.p1.5.m5.1.1.2.3">ğ‘–</ci></apply><minus id="S2.SS3.SSS3.p1.5.m5.1.1.3.cmml" xref="S2.SS3.SSS3.p1.5.m5.1.1.3"></minus></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.SSS3.p1.5.m5.1c">p_{i}^{-}</annotation></semantics></math> can be referred to as a <span id="S2.SS3.SSS3.p1.5.1" class="ltx_text ltx_font_italic">retrieved negative</span>. We present more details on constructing the training data in Sec.Â <a href="#S3.SS1.SSS2" title="3.1.2. Data Construction for Dense Retrieval â€£ 3.1. Experimental Setup â€£ 3. Experiments â€£ Passage Retrieval for Outside-Knowledge Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.1.2</span></a>.
In addition to the retrieved negatives, one might want to take advantage of the other passages in the batch as in-batch negatives. Although in-batch negatives resemble randomly sampled negatives that can be less effectiveÂ <cite class="ltx_cite ltx_citemacro_citep">(Karpukhin etÂ al., <a href="#bib.bib16" title="" class="ltx_ref">2020</a>)</cite>, it is extremely efficient since passage representations can be reused within the batch. <cite class="ltx_cite ltx_citemacro_citet">Karpukhin etÂ al. (<a href="#bib.bib16" title="" class="ltx_ref">2020</a>)</cite> studied
combining in-batch negatives with retrieved negatives for uni-modal queries.
We further dig into this topic for multi-modal queries. We consider the following negative sampling strategies:
</p>
<ul id="S2.I2" class="ltx_itemize">
<li id="S2.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S2.I2.i1.p1" class="ltx_para">
<p id="S2.I2.i1.p1.1" class="ltx_p"><span id="S2.I2.i1.p1.1.1" class="ltx_text ltx_font_bold">R-Neg</span>: using the <span id="S2.I2.i1.p1.1.2" class="ltx_text ltx_font_bold">r</span>etrieved <span id="S2.I2.i1.p1.1.3" class="ltx_text ltx_font_bold">neg</span>ative passage only.</p>
</div>
</li>
<li id="S2.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S2.I2.i2.p1" class="ltx_para">
<p id="S2.I2.i2.p1.1" class="ltx_p"><span id="S2.I2.i2.p1.1.1" class="ltx_text ltx_font_bold">R-Neg+IB-Neg</span>: using the <span id="S2.I2.i2.p1.1.2" class="ltx_text ltx_font_bold">r</span>etrieved <span id="S2.I2.i2.p1.1.3" class="ltx_text ltx_font_bold">neg</span>ative, along with all other <span id="S2.I2.i2.p1.1.4" class="ltx_text ltx_font_bold">i</span>n-<span id="S2.I2.i2.p1.1.5" class="ltx_text ltx_font_bold">b</span>atch <span id="S2.I2.i2.p1.1.6" class="ltx_text ltx_font_bold">neg</span>ative passages of other instances.</p>
</div>
</li>
<li id="S2.I2.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S2.I2.i3.p1" class="ltx_para">
<p id="S2.I2.i3.p1.1" class="ltx_p"><span id="S2.I2.i3.p1.1.1" class="ltx_text ltx_font_bold">R-Neg+IB-Pos</span>: using the <span id="S2.I2.i3.p1.1.2" class="ltx_text ltx_font_bold">r</span>etrieved <span id="S2.I2.i3.p1.1.3" class="ltx_text ltx_font_bold">neg</span>ative, along with all other <span id="S2.I2.i3.p1.1.4" class="ltx_text ltx_font_bold">i</span>n-<span id="S2.I2.i3.p1.1.5" class="ltx_text ltx_font_bold">b</span>atch <span id="S2.I2.i3.p1.1.6" class="ltx_text ltx_font_bold">pos</span>itive passages of other instances.</p>
</div>
</li>
<li id="S2.I2.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S2.I2.i4.p1" class="ltx_para">
<p id="S2.I2.i4.p1.1" class="ltx_p"><span id="S2.I2.i4.p1.1.1" class="ltx_text ltx_font_bold">R-Neg+IB-All</span>: using the <span id="S2.I2.i4.p1.1.2" class="ltx_text ltx_font_bold">r</span>etrieved <span id="S2.I2.i4.p1.1.3" class="ltx_text ltx_font_bold">neg</span>ative, along with <span id="S2.I2.i4.p1.1.4" class="ltx_text ltx_font_bold">all</span> other <span id="S2.I2.i4.p1.1.5" class="ltx_text ltx_font_bold">i</span>n-<span id="S2.I2.i4.p1.1.6" class="ltx_text ltx_font_bold">b</span>atch passages, except for <math id="S2.I2.i4.p1.1.m1.1" class="ltx_Math" alttext="p_{i}^{+}" display="inline"><semantics id="S2.I2.i4.p1.1.m1.1a"><msubsup id="S2.I2.i4.p1.1.m1.1.1" xref="S2.I2.i4.p1.1.m1.1.1.cmml"><mi id="S2.I2.i4.p1.1.m1.1.1.2.2" xref="S2.I2.i4.p1.1.m1.1.1.2.2.cmml">p</mi><mi id="S2.I2.i4.p1.1.m1.1.1.2.3" xref="S2.I2.i4.p1.1.m1.1.1.2.3.cmml">i</mi><mo id="S2.I2.i4.p1.1.m1.1.1.3" xref="S2.I2.i4.p1.1.m1.1.1.3.cmml">+</mo></msubsup><annotation-xml encoding="MathML-Content" id="S2.I2.i4.p1.1.m1.1b"><apply id="S2.I2.i4.p1.1.m1.1.1.cmml" xref="S2.I2.i4.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S2.I2.i4.p1.1.m1.1.1.1.cmml" xref="S2.I2.i4.p1.1.m1.1.1">superscript</csymbol><apply id="S2.I2.i4.p1.1.m1.1.1.2.cmml" xref="S2.I2.i4.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S2.I2.i4.p1.1.m1.1.1.2.1.cmml" xref="S2.I2.i4.p1.1.m1.1.1">subscript</csymbol><ci id="S2.I2.i4.p1.1.m1.1.1.2.2.cmml" xref="S2.I2.i4.p1.1.m1.1.1.2.2">ğ‘</ci><ci id="S2.I2.i4.p1.1.m1.1.1.2.3.cmml" xref="S2.I2.i4.p1.1.m1.1.1.2.3">ğ‘–</ci></apply><plus id="S2.I2.i4.p1.1.m1.1.1.3.cmml" xref="S2.I2.i4.p1.1.m1.1.1.3"></plus></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I2.i4.p1.1.m1.1c">p_{i}^{+}</annotation></semantics></math>.
The same query can be paired with different positive and negative passages to augment the training data as suggested in Sec.Â <a href="#S3.SS1.SSS2" title="3.1.2. Data Construction for Dense Retrieval â€£ 3.1. Experimental Setup â€£ 3. Experiments â€£ Passage Retrieval for Outside-Knowledge Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.1.2</span></a>. Therefore, the queries within a batch can coincide even with random batching. In this case, the misuse of a positive passage as negative may hinder the learning process. We empirically examine whether this concern holds by comparing R-Neg+IB-All/Pos to R-Neg+IB-Neg.</p>
</div>
</li>
</ul>
</div>
<div id="S2.SS3.SSS3.p2" class="ltx_para">
<p id="S2.SS3.SSS3.p2.1" class="ltx_p">Following previous workÂ <cite class="ltx_cite ltx_citemacro_citep">(Qu etÂ al., <a href="#bib.bib30" title="" class="ltx_ref">2020a</a>; Karpukhin etÂ al., <a href="#bib.bib16" title="" class="ltx_ref">2020</a>)</cite>, we use cross entropy loss to maximize the probability of the positive passage given the negatives identified above. We then average the losses for queries in the batch.</p>
</div>
</section>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3. </span>Experiments</h2>

<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1. </span>Experimental Setup</h3>

<section id="S3.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.1. </span><span id="S3.SS1.SSS1.1.1" class="ltx_text ltx_font_bold">Dataset</span>
</h4>

<div id="S3.SS1.SSS1.p1" class="ltx_para">
<p id="S3.SS1.SSS1.p1.1" class="ltx_p">Our retrieval dataset is based on the OK-VQA datasetÂ <cite class="ltx_cite ltx_citemacro_citep">(Marino etÂ al., <a href="#bib.bib27" title="" class="ltx_ref">2019</a>)</cite>, where all questions require outside knowledge.<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span><a target="_blank" href="https://okvqa.allenai.org/index.html" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://okvqa.allenai.org/index.html</a></span></span></span>
The images in the OK-VQA dataset are from the COCO datasetÂ <cite class="ltx_cite ltx_citemacro_citep">(Goyal etÂ al., <a href="#bib.bib12" title="" class="ltx_ref">2017</a>)</cite>.
We take the original training queries as our training queries and split the original validation queries into our validation and testing queries. In terms of the collection, we take the Wikipedia passage collection with 11 million passages created by previous work <cite class="ltx_cite ltx_citemacro_citep">(Qu etÂ al., <a href="#bib.bib30" title="" class="ltx_ref">2020a</a>)</cite>.<span id="footnote3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span><a target="_blank" href="https://ciir.cs.umass.edu/downloads/ORConvQA/all_blocks.txt.gz" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://ciir.cs.umass.edu/downloads/ORConvQA/all_blocks.txt.gz</a></span></span></span>
Each passage contains at most 384 â€œwordpiecesâ€Â <cite class="ltx_cite ltx_citemacro_citep">(Devlin etÂ al., <a href="#bib.bib8" title="" class="ltx_ref">2019</a>)</cite> with intact sentence boundaries. Data statistics are presented in Tab.Â <a href="#S3.T1" title="Table 1 â€£ 3.1.2. Data Construction for Dense Retrieval â€£ 3.1. Experimental Setup â€£ 3. Experiments â€£ Passage Retrieval for Outside-Knowledge Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
</section>
<section id="S3.SS1.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.2. </span><span id="S3.SS1.SSS2.1.1" class="ltx_text ltx_font_bold">Data Construction for Dense Retrieval</span>
</h4>

<div id="S3.SS1.SSS2.p1" class="ltx_para">
<p id="S3.SS1.SSS2.p1.1" class="ltx_p">We create the training instances described in Sec.Â <a href="#S2.SS3.SSS3" title="2.3.3. Training â€£ 2.3. Dense Retrieval â€£ 2. Passage Retrieval for OK-VQA â€£ Passage Retrieval for Outside-Knowledge Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.3.3</span></a> using retrieved passages of sparse retrieval (see configuration details in Sec.Â <a href="#S3.SS1.SSS4" title="3.1.4. Implementation Details â€£ 3.1. Experimental Setup â€£ 3. Experiments â€£ Passage Retrieval for Outside-Knowledge Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.1.4</span></a>).
A passage is identified to be positive if it contains an exact match (case-insensitive) of a ground truth answer. The other retrieved passages are considered as negatives. We take the top 5 positive passages, each repeated 5 times (for augmentation), to construct training instances with random retrieved negatives.
In addition, we put together a small validation collection by taking the top 20 passages for each question. Data statistics are presented in Tab.Â <a href="#S3.T1" title="Table 1 â€£ 3.1.2. Data Construction for Dense Retrieval â€£ 3.1. Experimental Setup â€£ 3. Experiments â€£ Passage Retrieval for Outside-Knowledge Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
<figure id="S3.T1" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S3.T1.2.1.1" class="ltx_text" style="font-size:90%;">Table 1</span>. </span><span id="S3.T1.3.2" class="ltx_text" style="font-size:90%;">Data statistics.</span></figcaption>
<table id="S3.T1.4" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T1.4.1.1" class="ltx_tr">
<th id="S3.T1.4.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:2.5pt;padding-right:2.5pt;"><span id="S3.T1.4.1.1.1.1" class="ltx_text" style="font-size:80%;">Split</span></th>
<th id="S3.T1.4.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:2.5pt;padding-right:2.5pt;"><span id="S3.T1.4.1.1.2.1" class="ltx_text" style="font-size:80%;">#. questions</span></th>
<th id="S3.T1.4.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:2.5pt;padding-right:2.5pt;"><span id="S3.T1.4.1.1.3.1" class="ltx_text" style="font-size:80%;">#. BM25 queries</span></th>
<th id="S3.T1.4.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:2.5pt;padding-right:2.5pt;"><span id="S3.T1.4.1.1.4.1" class="ltx_text" style="font-size:80%;">#. training instances</span></th>
<th id="S3.T1.4.1.1.5" class="ltx_td ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:2.5pt;padding-right:2.5pt;"><span id="S3.T1.4.1.1.5.1" class="ltx_text" style="font-size:80%;">#. passages in collection</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T1.4.2.1" class="ltx_tr">
<td id="S3.T1.4.2.1.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;"><span id="S3.T1.4.2.1.1.1" class="ltx_text" style="font-size:80%;">Train</span></td>
<td id="S3.T1.4.2.1.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;"><span id="S3.T1.4.2.1.2.1" class="ltx_text" style="font-size:80%;">9,009</span></td>
<td id="S3.T1.4.2.1.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;"><span id="S3.T1.4.2.1.3.1" class="ltx_text" style="font-size:80%;">81,100</span></td>
<td id="S3.T1.4.2.1.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;"><span id="S3.T1.4.2.1.4.1" class="ltx_text" style="font-size:80%;">211,200</span></td>
<td id="S3.T1.4.2.1.5" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;"><span id="S3.T1.4.2.1.5.1" class="ltx_text" style="font-size:80%;">N/A</span></td>
</tr>
<tr id="S3.T1.4.3.2" class="ltx_tr">
<td id="S3.T1.4.3.2.1" class="ltx_td ltx_align_center" style="padding-left:2.5pt;padding-right:2.5pt;"><span id="S3.T1.4.3.2.1.1" class="ltx_text" style="font-size:80%;">Val</span></td>
<td id="S3.T1.4.3.2.2" class="ltx_td ltx_align_center" style="padding-left:2.5pt;padding-right:2.5pt;"><span id="S3.T1.4.3.2.2.1" class="ltx_text" style="font-size:80%;">2,523</span></td>
<td id="S3.T1.4.3.2.3" class="ltx_td ltx_align_center" style="padding-left:2.5pt;padding-right:2.5pt;"><span id="S3.T1.4.3.2.3.1" class="ltx_text" style="font-size:80%;">22,352</span></td>
<td id="S3.T1.4.3.2.4" class="ltx_td ltx_align_center" style="padding-left:2.5pt;padding-right:2.5pt;"><span id="S3.T1.4.3.2.4.1" class="ltx_text" style="font-size:80%;">N/A</span></td>
<td id="S3.T1.4.3.2.5" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.5pt;padding-right:2.5pt;"><span id="S3.T1.4.3.2.5.1" class="ltx_text" style="font-size:80%;">34,059</span></td>
</tr>
<tr id="S3.T1.4.4.3" class="ltx_tr">
<td id="S3.T1.4.4.3.1" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:2.5pt;padding-right:2.5pt;"><span id="S3.T1.4.4.3.1.1" class="ltx_text" style="font-size:80%;">Test</span></td>
<td id="S3.T1.4.4.3.2" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:2.5pt;padding-right:2.5pt;"><span id="S3.T1.4.4.3.2.1" class="ltx_text" style="font-size:80%;">2,523</span></td>
<td id="S3.T1.4.4.3.3" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:2.5pt;padding-right:2.5pt;"><span id="S3.T1.4.4.3.3.1" class="ltx_text" style="font-size:80%;">22,573</span></td>
<td id="S3.T1.4.4.3.4" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:2.5pt;padding-right:2.5pt;"><span id="S3.T1.4.4.3.4.1" class="ltx_text" style="font-size:80%;">N/A</span></td>
<td id="S3.T1.4.4.3.5" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:2.5pt;padding-right:2.5pt;"><span id="S3.T1.4.4.3.5.1" class="ltx_text" style="font-size:80%;">11,000,000</span></td>
</tr>
</tbody>
</table>
</figure>
</section>
<section id="S3.SS1.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.3. </span><span id="S3.SS1.SSS3.1.1" class="ltx_text ltx_font_bold">Evaluation Metrics</span>
</h4>

<div id="S3.SS1.SSS3.p1" class="ltx_para">
<p id="S3.SS1.SSS3.p1.1" class="ltx_p">We focus on passage retrieval for multi-modal information needs as the first step in the OK-VQA pipeline. The output of the retrieval process will be used by a reader model to extract the answer. Therefore, following previous workÂ <cite class="ltx_cite ltx_citemacro_citep">(Karpukhin etÂ al., <a href="#bib.bib16" title="" class="ltx_ref">2020</a>; Chen etÂ al., <a href="#bib.bib5" title="" class="ltx_ref">2017</a>)</cite>, we use precision-oriented metrics to evaluate the performance of our models. Precisely, we use Mean Reciprocal Rank and Precision with the ranking cut-off of 5 (MRR@5 and P@5) as our metrics.</p>
</div>
</section>
<section id="S3.SS1.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.4. </span><span id="S3.SS1.SSS4.1.1" class="ltx_text ltx_font_bold">Implementation Details</span>
</h4>

<div id="S3.SS1.SSS4.p1" class="ltx_para">
<p id="S3.SS1.SSS4.p1.5" class="ltx_p">For sparse retrieval, we use BM25 in Anserini (v0.5.1).<span id="footnote4" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span><a target="_blank" href="https://github.com/castorini/anserini" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/castorini/anserini</a></span></span></span> We tune <math id="S3.SS1.SSS4.p1.1.m1.2" class="ltx_Math" alttext="k_{1}\in[0.5,1.5]" display="inline"><semantics id="S3.SS1.SSS4.p1.1.m1.2a"><mrow id="S3.SS1.SSS4.p1.1.m1.2.3" xref="S3.SS1.SSS4.p1.1.m1.2.3.cmml"><msub id="S3.SS1.SSS4.p1.1.m1.2.3.2" xref="S3.SS1.SSS4.p1.1.m1.2.3.2.cmml"><mi id="S3.SS1.SSS4.p1.1.m1.2.3.2.2" xref="S3.SS1.SSS4.p1.1.m1.2.3.2.2.cmml">k</mi><mn id="S3.SS1.SSS4.p1.1.m1.2.3.2.3" xref="S3.SS1.SSS4.p1.1.m1.2.3.2.3.cmml">1</mn></msub><mo id="S3.SS1.SSS4.p1.1.m1.2.3.1" xref="S3.SS1.SSS4.p1.1.m1.2.3.1.cmml">âˆˆ</mo><mrow id="S3.SS1.SSS4.p1.1.m1.2.3.3.2" xref="S3.SS1.SSS4.p1.1.m1.2.3.3.1.cmml"><mo stretchy="false" id="S3.SS1.SSS4.p1.1.m1.2.3.3.2.1" xref="S3.SS1.SSS4.p1.1.m1.2.3.3.1.cmml">[</mo><mn id="S3.SS1.SSS4.p1.1.m1.1.1" xref="S3.SS1.SSS4.p1.1.m1.1.1.cmml">0.5</mn><mo id="S3.SS1.SSS4.p1.1.m1.2.3.3.2.2" xref="S3.SS1.SSS4.p1.1.m1.2.3.3.1.cmml">,</mo><mn id="S3.SS1.SSS4.p1.1.m1.2.2" xref="S3.SS1.SSS4.p1.1.m1.2.2.cmml">1.5</mn><mo stretchy="false" id="S3.SS1.SSS4.p1.1.m1.2.3.3.2.3" xref="S3.SS1.SSS4.p1.1.m1.2.3.3.1.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS4.p1.1.m1.2b"><apply id="S3.SS1.SSS4.p1.1.m1.2.3.cmml" xref="S3.SS1.SSS4.p1.1.m1.2.3"><in id="S3.SS1.SSS4.p1.1.m1.2.3.1.cmml" xref="S3.SS1.SSS4.p1.1.m1.2.3.1"></in><apply id="S3.SS1.SSS4.p1.1.m1.2.3.2.cmml" xref="S3.SS1.SSS4.p1.1.m1.2.3.2"><csymbol cd="ambiguous" id="S3.SS1.SSS4.p1.1.m1.2.3.2.1.cmml" xref="S3.SS1.SSS4.p1.1.m1.2.3.2">subscript</csymbol><ci id="S3.SS1.SSS4.p1.1.m1.2.3.2.2.cmml" xref="S3.SS1.SSS4.p1.1.m1.2.3.2.2">ğ‘˜</ci><cn type="integer" id="S3.SS1.SSS4.p1.1.m1.2.3.2.3.cmml" xref="S3.SS1.SSS4.p1.1.m1.2.3.2.3">1</cn></apply><interval closure="closed" id="S3.SS1.SSS4.p1.1.m1.2.3.3.1.cmml" xref="S3.SS1.SSS4.p1.1.m1.2.3.3.2"><cn type="float" id="S3.SS1.SSS4.p1.1.m1.1.1.cmml" xref="S3.SS1.SSS4.p1.1.m1.1.1">0.5</cn><cn type="float" id="S3.SS1.SSS4.p1.1.m1.2.2.cmml" xref="S3.SS1.SSS4.p1.1.m1.2.2">1.5</cn></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS4.p1.1.m1.2c">k_{1}\in[0.5,1.5]</annotation></semantics></math> and <math id="S3.SS1.SSS4.p1.2.m2.2" class="ltx_Math" alttext="b\in[0.2,0.8]" display="inline"><semantics id="S3.SS1.SSS4.p1.2.m2.2a"><mrow id="S3.SS1.SSS4.p1.2.m2.2.3" xref="S3.SS1.SSS4.p1.2.m2.2.3.cmml"><mi id="S3.SS1.SSS4.p1.2.m2.2.3.2" xref="S3.SS1.SSS4.p1.2.m2.2.3.2.cmml">b</mi><mo id="S3.SS1.SSS4.p1.2.m2.2.3.1" xref="S3.SS1.SSS4.p1.2.m2.2.3.1.cmml">âˆˆ</mo><mrow id="S3.SS1.SSS4.p1.2.m2.2.3.3.2" xref="S3.SS1.SSS4.p1.2.m2.2.3.3.1.cmml"><mo stretchy="false" id="S3.SS1.SSS4.p1.2.m2.2.3.3.2.1" xref="S3.SS1.SSS4.p1.2.m2.2.3.3.1.cmml">[</mo><mn id="S3.SS1.SSS4.p1.2.m2.1.1" xref="S3.SS1.SSS4.p1.2.m2.1.1.cmml">0.2</mn><mo id="S3.SS1.SSS4.p1.2.m2.2.3.3.2.2" xref="S3.SS1.SSS4.p1.2.m2.2.3.3.1.cmml">,</mo><mn id="S3.SS1.SSS4.p1.2.m2.2.2" xref="S3.SS1.SSS4.p1.2.m2.2.2.cmml">0.8</mn><mo stretchy="false" id="S3.SS1.SSS4.p1.2.m2.2.3.3.2.3" xref="S3.SS1.SSS4.p1.2.m2.2.3.3.1.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS4.p1.2.m2.2b"><apply id="S3.SS1.SSS4.p1.2.m2.2.3.cmml" xref="S3.SS1.SSS4.p1.2.m2.2.3"><in id="S3.SS1.SSS4.p1.2.m2.2.3.1.cmml" xref="S3.SS1.SSS4.p1.2.m2.2.3.1"></in><ci id="S3.SS1.SSS4.p1.2.m2.2.3.2.cmml" xref="S3.SS1.SSS4.p1.2.m2.2.3.2">ğ‘</ci><interval closure="closed" id="S3.SS1.SSS4.p1.2.m2.2.3.3.1.cmml" xref="S3.SS1.SSS4.p1.2.m2.2.3.3.2"><cn type="float" id="S3.SS1.SSS4.p1.2.m2.1.1.cmml" xref="S3.SS1.SSS4.p1.2.m2.1.1">0.2</cn><cn type="float" id="S3.SS1.SSS4.p1.2.m2.2.2.cmml" xref="S3.SS1.SSS4.p1.2.m2.2.2">0.8</cn></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS4.p1.2.m2.2c">b\in[0.2,0.8]</annotation></semantics></math> with steps of 0.2 based on validation MRR. The best setting is <math id="S3.SS1.SSS4.p1.3.m3.2" class="ltx_Math" alttext="k_{1}=1.1,b=0.4" display="inline"><semantics id="S3.SS1.SSS4.p1.3.m3.2a"><mrow id="S3.SS1.SSS4.p1.3.m3.2.2.2" xref="S3.SS1.SSS4.p1.3.m3.2.2.3.cmml"><mrow id="S3.SS1.SSS4.p1.3.m3.1.1.1.1" xref="S3.SS1.SSS4.p1.3.m3.1.1.1.1.cmml"><msub id="S3.SS1.SSS4.p1.3.m3.1.1.1.1.2" xref="S3.SS1.SSS4.p1.3.m3.1.1.1.1.2.cmml"><mi id="S3.SS1.SSS4.p1.3.m3.1.1.1.1.2.2" xref="S3.SS1.SSS4.p1.3.m3.1.1.1.1.2.2.cmml">k</mi><mn id="S3.SS1.SSS4.p1.3.m3.1.1.1.1.2.3" xref="S3.SS1.SSS4.p1.3.m3.1.1.1.1.2.3.cmml">1</mn></msub><mo id="S3.SS1.SSS4.p1.3.m3.1.1.1.1.1" xref="S3.SS1.SSS4.p1.3.m3.1.1.1.1.1.cmml">=</mo><mn id="S3.SS1.SSS4.p1.3.m3.1.1.1.1.3" xref="S3.SS1.SSS4.p1.3.m3.1.1.1.1.3.cmml">1.1</mn></mrow><mo id="S3.SS1.SSS4.p1.3.m3.2.2.2.3" xref="S3.SS1.SSS4.p1.3.m3.2.2.3a.cmml">,</mo><mrow id="S3.SS1.SSS4.p1.3.m3.2.2.2.2" xref="S3.SS1.SSS4.p1.3.m3.2.2.2.2.cmml"><mi id="S3.SS1.SSS4.p1.3.m3.2.2.2.2.2" xref="S3.SS1.SSS4.p1.3.m3.2.2.2.2.2.cmml">b</mi><mo id="S3.SS1.SSS4.p1.3.m3.2.2.2.2.1" xref="S3.SS1.SSS4.p1.3.m3.2.2.2.2.1.cmml">=</mo><mn id="S3.SS1.SSS4.p1.3.m3.2.2.2.2.3" xref="S3.SS1.SSS4.p1.3.m3.2.2.2.2.3.cmml">0.4</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS4.p1.3.m3.2b"><apply id="S3.SS1.SSS4.p1.3.m3.2.2.3.cmml" xref="S3.SS1.SSS4.p1.3.m3.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.SSS4.p1.3.m3.2.2.3a.cmml" xref="S3.SS1.SSS4.p1.3.m3.2.2.2.3">formulae-sequence</csymbol><apply id="S3.SS1.SSS4.p1.3.m3.1.1.1.1.cmml" xref="S3.SS1.SSS4.p1.3.m3.1.1.1.1"><eq id="S3.SS1.SSS4.p1.3.m3.1.1.1.1.1.cmml" xref="S3.SS1.SSS4.p1.3.m3.1.1.1.1.1"></eq><apply id="S3.SS1.SSS4.p1.3.m3.1.1.1.1.2.cmml" xref="S3.SS1.SSS4.p1.3.m3.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.SSS4.p1.3.m3.1.1.1.1.2.1.cmml" xref="S3.SS1.SSS4.p1.3.m3.1.1.1.1.2">subscript</csymbol><ci id="S3.SS1.SSS4.p1.3.m3.1.1.1.1.2.2.cmml" xref="S3.SS1.SSS4.p1.3.m3.1.1.1.1.2.2">ğ‘˜</ci><cn type="integer" id="S3.SS1.SSS4.p1.3.m3.1.1.1.1.2.3.cmml" xref="S3.SS1.SSS4.p1.3.m3.1.1.1.1.2.3">1</cn></apply><cn type="float" id="S3.SS1.SSS4.p1.3.m3.1.1.1.1.3.cmml" xref="S3.SS1.SSS4.p1.3.m3.1.1.1.1.3">1.1</cn></apply><apply id="S3.SS1.SSS4.p1.3.m3.2.2.2.2.cmml" xref="S3.SS1.SSS4.p1.3.m3.2.2.2.2"><eq id="S3.SS1.SSS4.p1.3.m3.2.2.2.2.1.cmml" xref="S3.SS1.SSS4.p1.3.m3.2.2.2.2.1"></eq><ci id="S3.SS1.SSS4.p1.3.m3.2.2.2.2.2.cmml" xref="S3.SS1.SSS4.p1.3.m3.2.2.2.2.2">ğ‘</ci><cn type="float" id="S3.SS1.SSS4.p1.3.m3.2.2.2.2.3.cmml" xref="S3.SS1.SSS4.p1.3.m3.2.2.2.2.3">0.4</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS4.p1.3.m3.2c">k_{1}=1.1,b=0.4</annotation></semantics></math>. The constant in RRF is set to 60 <cite class="ltx_cite ltx_citemacro_citep">(Cormack etÂ al., <a href="#bib.bib6" title="" class="ltx_ref">2009</a>; Benham and Culpepper, <a href="#bib.bib4" title="" class="ltx_ref">2017</a>)</cite>. Human-annotated object names and captions are from the COCO datasetÂ <cite class="ltx_cite ltx_citemacro_citep">(Goyal etÂ al., <a href="#bib.bib12" title="" class="ltx_ref">2017</a>)</cite>.
For dense retrieval, we use the HuggingFace transformers library<span id="footnote5" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span><a target="_blank" href="https://github.com/huggingface/transformers" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/huggingface/transformers</a></span></span></span> for the implementations of LXMERT and BERT. We set the maximum sequence length of the query encoder to 20Â <cite class="ltx_cite ltx_citemacro_citep">(Tan and Bansal, <a href="#bib.bib35" title="" class="ltx_ref">2019</a>)</cite>, that of the passage encoder to 384, the projection size (<math id="S3.SS1.SSS4.p1.4.m4.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S3.SS1.SSS4.p1.4.m4.1a"><mi id="S3.SS1.SSS4.p1.4.m4.1.1" xref="S3.SS1.SSS4.p1.4.m4.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS4.p1.4.m4.1b"><ci id="S3.SS1.SSS4.p1.4.m4.1.1.cmml" xref="S3.SS1.SSS4.p1.4.m4.1.1">ğ‘›</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS4.p1.4.m4.1c">n</annotation></semantics></math>) for the query/passage representations to 768, the learning rate to 1e-5, the batch size to 4 per GPU, and the number of fine-tuning epochs to 2. We adopt R-Neg+IB-All as the negative sampling strategy. We save checkpoints every 5,000 steps and evaluate on the validation set to select the best model for the test set. The training time is 10 hours for Dense-BERT and 12 hours for Dense-LXMERT. All models are trained with 4 GPUs with mixed-precision training. Warm-up takes 10% of the total steps. The training instances are constructed with the top 100 retrieved passages for each question using BM25-Cap (CombSUM) with the default BM25 configuration in Anserini (<math id="S3.SS1.SSS4.p1.5.m5.2" class="ltx_Math" alttext="k_{1}=0.9,b=0.4" display="inline"><semantics id="S3.SS1.SSS4.p1.5.m5.2a"><mrow id="S3.SS1.SSS4.p1.5.m5.2.2.2" xref="S3.SS1.SSS4.p1.5.m5.2.2.3.cmml"><mrow id="S3.SS1.SSS4.p1.5.m5.1.1.1.1" xref="S3.SS1.SSS4.p1.5.m5.1.1.1.1.cmml"><msub id="S3.SS1.SSS4.p1.5.m5.1.1.1.1.2" xref="S3.SS1.SSS4.p1.5.m5.1.1.1.1.2.cmml"><mi id="S3.SS1.SSS4.p1.5.m5.1.1.1.1.2.2" xref="S3.SS1.SSS4.p1.5.m5.1.1.1.1.2.2.cmml">k</mi><mn id="S3.SS1.SSS4.p1.5.m5.1.1.1.1.2.3" xref="S3.SS1.SSS4.p1.5.m5.1.1.1.1.2.3.cmml">1</mn></msub><mo id="S3.SS1.SSS4.p1.5.m5.1.1.1.1.1" xref="S3.SS1.SSS4.p1.5.m5.1.1.1.1.1.cmml">=</mo><mn id="S3.SS1.SSS4.p1.5.m5.1.1.1.1.3" xref="S3.SS1.SSS4.p1.5.m5.1.1.1.1.3.cmml">0.9</mn></mrow><mo id="S3.SS1.SSS4.p1.5.m5.2.2.2.3" xref="S3.SS1.SSS4.p1.5.m5.2.2.3a.cmml">,</mo><mrow id="S3.SS1.SSS4.p1.5.m5.2.2.2.2" xref="S3.SS1.SSS4.p1.5.m5.2.2.2.2.cmml"><mi id="S3.SS1.SSS4.p1.5.m5.2.2.2.2.2" xref="S3.SS1.SSS4.p1.5.m5.2.2.2.2.2.cmml">b</mi><mo id="S3.SS1.SSS4.p1.5.m5.2.2.2.2.1" xref="S3.SS1.SSS4.p1.5.m5.2.2.2.2.1.cmml">=</mo><mn id="S3.SS1.SSS4.p1.5.m5.2.2.2.2.3" xref="S3.SS1.SSS4.p1.5.m5.2.2.2.2.3.cmml">0.4</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS4.p1.5.m5.2b"><apply id="S3.SS1.SSS4.p1.5.m5.2.2.3.cmml" xref="S3.SS1.SSS4.p1.5.m5.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.SSS4.p1.5.m5.2.2.3a.cmml" xref="S3.SS1.SSS4.p1.5.m5.2.2.2.3">formulae-sequence</csymbol><apply id="S3.SS1.SSS4.p1.5.m5.1.1.1.1.cmml" xref="S3.SS1.SSS4.p1.5.m5.1.1.1.1"><eq id="S3.SS1.SSS4.p1.5.m5.1.1.1.1.1.cmml" xref="S3.SS1.SSS4.p1.5.m5.1.1.1.1.1"></eq><apply id="S3.SS1.SSS4.p1.5.m5.1.1.1.1.2.cmml" xref="S3.SS1.SSS4.p1.5.m5.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.SSS4.p1.5.m5.1.1.1.1.2.1.cmml" xref="S3.SS1.SSS4.p1.5.m5.1.1.1.1.2">subscript</csymbol><ci id="S3.SS1.SSS4.p1.5.m5.1.1.1.1.2.2.cmml" xref="S3.SS1.SSS4.p1.5.m5.1.1.1.1.2.2">ğ‘˜</ci><cn type="integer" id="S3.SS1.SSS4.p1.5.m5.1.1.1.1.2.3.cmml" xref="S3.SS1.SSS4.p1.5.m5.1.1.1.1.2.3">1</cn></apply><cn type="float" id="S3.SS1.SSS4.p1.5.m5.1.1.1.1.3.cmml" xref="S3.SS1.SSS4.p1.5.m5.1.1.1.1.3">0.9</cn></apply><apply id="S3.SS1.SSS4.p1.5.m5.2.2.2.2.cmml" xref="S3.SS1.SSS4.p1.5.m5.2.2.2.2"><eq id="S3.SS1.SSS4.p1.5.m5.2.2.2.2.1.cmml" xref="S3.SS1.SSS4.p1.5.m5.2.2.2.2.1"></eq><ci id="S3.SS1.SSS4.p1.5.m5.2.2.2.2.2.cmml" xref="S3.SS1.SSS4.p1.5.m5.2.2.2.2.2">ğ‘</ci><cn type="float" id="S3.SS1.SSS4.p1.5.m5.2.2.2.2.3.cmml" xref="S3.SS1.SSS4.p1.5.m5.2.2.2.2.3">0.4</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS4.p1.5.m5.2c">k_{1}=0.9,b=0.4</annotation></semantics></math>).</p>
</div>
</section>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2. </span>Main Results</h3>

<section id="S3.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.1. </span><span id="S3.SS2.SSS1.1.1" class="ltx_text ltx_font_bold">Sparse Retrieval</span>
</h4>

<div id="S3.SS2.SSS1.p1" class="ltx_para">
<p id="S3.SS2.SSS1.p1.1" class="ltx_p">We present the results for sparse retrieval in Tab.Â <a href="#S3.T2" title="Table 2 â€£ 3.2.1. Sparse Retrieval â€£ 3.2. Main Results â€£ 3. Experiments â€£ Passage Retrieval for Outside-Knowledge Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> to answer <span id="S3.SS2.SSS1.p1.1.1" class="ltx_text ltx_font_bold">RQ1</span> and <span id="S3.SS2.SSS1.p1.1.2" class="ltx_text ltx_font_bold">RQ2</span> raised in Sec.Â <a href="#S1" title="1. Introduction â€£ Passage Retrieval for Outside-Knowledge Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. First, we observe that approaches that consider visual signals outperform BM25-Orig by a large margin, verifying that visual clues are helpful in our task. We then compare BM25 with different forms of visual clues. Methods with captions (BM25-Cap/All) outperform object expansion, indicating that captions are more informative than object names. This makes sense since captions typically cover important objects descriptively. BM25-All does not benefit from incorporating both objects and captions. On the contrary, objects can be distracting and hurt the performance gain from captions. Finally, we compare different rank fusion methods. When objects are being considered (BM25-Obj/All), CombMAX yields the best performance since it is robust to potentially misleading objects by only considering objects with the best matching score. On the other hand, CombSUM and RRF work well with caption expansion. Their ability to consider the impact of all captions is desirable since captions are closely connected to the image and can be diverse and complementary. The best performing approach is BM25-Cap with CombSUM.</p>
</div>
<figure id="S3.T2" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S3.T2.20.4.1" class="ltx_text" style="font-size:90%;">Table 2</span>. </span><span id="S3.T2.6.3" class="ltx_text" style="font-size:90%;">Sparse retrieval results. Boldface denotes the best performance within each group and underscores denote the best overall results. <math id="S3.T2.4.1.m1.1" class="ltx_Math" alttext="\blacktriangle i" display="inline"><semantics id="S3.T2.4.1.m1.1b"><mrow id="S3.T2.4.1.m1.1.1" xref="S3.T2.4.1.m1.1.1.cmml"><mi mathvariant="normal" id="S3.T2.4.1.m1.1.1.2" xref="S3.T2.4.1.m1.1.1.2.cmml">â–²</mi><mo lspace="0em" rspace="0em" id="S3.T2.4.1.m1.1.1.1" xref="S3.T2.4.1.m1.1.1.1.cmml">â€‹</mo><mi id="S3.T2.4.1.m1.1.1.3" xref="S3.T2.4.1.m1.1.1.3.cmml">i</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.T2.4.1.m1.1c"><apply id="S3.T2.4.1.m1.1.1.cmml" xref="S3.T2.4.1.m1.1.1"><times id="S3.T2.4.1.m1.1.1.1.cmml" xref="S3.T2.4.1.m1.1.1.1"></times><ci id="S3.T2.4.1.m1.1.1.2.cmml" xref="S3.T2.4.1.m1.1.1.2">â–²</ci><ci id="S3.T2.4.1.m1.1.1.3.cmml" xref="S3.T2.4.1.m1.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.4.1.m1.1d">\blacktriangle i</annotation></semantics></math> denotes that the gain with respect to the best method in group <math id="S3.T2.5.2.m2.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S3.T2.5.2.m2.1b"><mi id="S3.T2.5.2.m2.1.1" xref="S3.T2.5.2.m2.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.T2.5.2.m2.1c"><ci id="S3.T2.5.2.m2.1.1.cmml" xref="S3.T2.5.2.m2.1.1">ğ‘–</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.5.2.m2.1d">i</annotation></semantics></math> has statistically significance with <math id="S3.T2.6.3.m3.1" class="ltx_Math" alttext="p&lt;0.05" display="inline"><semantics id="S3.T2.6.3.m3.1b"><mrow id="S3.T2.6.3.m3.1.1" xref="S3.T2.6.3.m3.1.1.cmml"><mi id="S3.T2.6.3.m3.1.1.2" xref="S3.T2.6.3.m3.1.1.2.cmml">p</mi><mo id="S3.T2.6.3.m3.1.1.1" xref="S3.T2.6.3.m3.1.1.1.cmml">&lt;</mo><mn id="S3.T2.6.3.m3.1.1.3" xref="S3.T2.6.3.m3.1.1.3.cmml">0.05</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.T2.6.3.m3.1c"><apply id="S3.T2.6.3.m3.1.1.cmml" xref="S3.T2.6.3.m3.1.1"><lt id="S3.T2.6.3.m3.1.1.1.cmml" xref="S3.T2.6.3.m3.1.1.1"></lt><ci id="S3.T2.6.3.m3.1.1.2.cmml" xref="S3.T2.6.3.m3.1.1.2">ğ‘</ci><cn type="float" id="S3.T2.6.3.m3.1.1.3.cmml" xref="S3.T2.6.3.m3.1.1.3">0.05</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.6.3.m3.1d">p&lt;0.05</annotation></semantics></math> tested by the Studentâ€™s paired t-test.</span></figcaption>
<table id="S3.T2.18" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S3.T2.18.13.1" class="ltx_tr">
<th id="S3.T2.18.13.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;" colspan="2"><span id="S3.T2.18.13.1.1.1" class="ltx_text" style="font-size:80%;">Methods</span></th>
<td id="S3.T2.18.13.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;" colspan="2"><span id="S3.T2.18.13.1.2.1" class="ltx_text" style="font-size:80%;">Val</span></td>
<td id="S3.T2.18.13.1.3" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;" colspan="2"><span id="S3.T2.18.13.1.3.1" class="ltx_text" style="font-size:80%;">Test</span></td>
</tr>
<tr id="S3.T2.18.14.2" class="ltx_tr">
<th id="S3.T2.18.14.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S3.T2.18.14.2.1.1" class="ltx_text" style="font-size:80%;">Expansion</span></th>
<th id="S3.T2.18.14.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S3.T2.18.14.2.2.1" class="ltx_text" style="font-size:80%;">Fusion</span></th>
<td id="S3.T2.18.14.2.3" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S3.T2.18.14.2.3.1" class="ltx_text" style="font-size:80%;">MRR@5</span></td>
<td id="S3.T2.18.14.2.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S3.T2.18.14.2.4.1" class="ltx_text" style="font-size:80%;">P@5</span></td>
<td id="S3.T2.18.14.2.5" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S3.T2.18.14.2.5.1" class="ltx_text" style="font-size:80%;">MRR@5</span></td>
<td id="S3.T2.18.14.2.6" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S3.T2.18.14.2.6.1" class="ltx_text" style="font-size:80%;">P@5</span></td>
</tr>
<tr id="S3.T2.18.15.3" class="ltx_tr">
<th id="S3.T2.18.15.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S3.T2.18.15.3.1.1" class="ltx_text" style="font-size:80%;">1. BM25-Orig</span></th>
<th id="S3.T2.18.15.3.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S3.T2.18.15.3.2.1" class="ltx_text" style="font-size:80%;">N/A</span></th>
<td id="S3.T2.18.15.3.3" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S3.T2.18.15.3.3.1" class="ltx_text" style="font-size:80%;">0.2565</span></td>
<td id="S3.T2.18.15.3.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S3.T2.18.15.3.4.1" class="ltx_text" style="font-size:80%;">0.1772</span></td>
<td id="S3.T2.18.15.3.5" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S3.T2.18.15.3.5.1" class="ltx_text" style="font-size:80%;">0.2637</span></td>
<td id="S3.T2.18.15.3.6" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S3.T2.18.15.3.6.1" class="ltx_text" style="font-size:80%;">0.1755</span></td>
</tr>
<tr id="S3.T2.10.4" class="ltx_tr">
<th id="S3.T2.10.4.5" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;" rowspan="3"><span id="S3.T2.10.4.5.1" class="ltx_text" style="font-size:80%;">2. BM25-Obj</span></th>
<th id="S3.T2.10.4.6" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S3.T2.10.4.6.1" class="ltx_text" style="font-size:80%;">CombMAX</span></th>
<td id="S3.T2.7.1.1" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S3.T2.7.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">0.3772<sup id="S3.T2.7.1.1.1.1" class="ltx_sup"><span id="S3.T2.7.1.1.1.1.1" class="ltx_text ltx_font_medium ltx_font_italic">â–²1</span></sup></span></td>
<td id="S3.T2.8.2.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S3.T2.8.2.2.1" class="ltx_text ltx_font_bold" style="font-size:80%;">0.2667<sup id="S3.T2.8.2.2.1.1" class="ltx_sup"><span id="S3.T2.8.2.2.1.1.1" class="ltx_text ltx_font_medium ltx_font_italic">â–²1</span></sup></span></td>
<td id="S3.T2.9.3.3" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S3.T2.9.3.3.1" class="ltx_text ltx_font_bold" style="font-size:80%;">0.3686<sup id="S3.T2.9.3.3.1.1" class="ltx_sup"><span id="S3.T2.9.3.3.1.1.1" class="ltx_text ltx_font_medium ltx_font_italic">â–²1</span></sup></span></td>
<td id="S3.T2.10.4.4" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S3.T2.10.4.4.1" class="ltx_text ltx_font_bold" style="font-size:80%;">0.2541<sup id="S3.T2.10.4.4.1.1" class="ltx_sup"><span id="S3.T2.10.4.4.1.1.1" class="ltx_text ltx_font_medium ltx_font_italic">â–²1</span></sup></span></td>
</tr>
<tr id="S3.T2.18.16.4" class="ltx_tr">
<th id="S3.T2.18.16.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S3.T2.18.16.4.1.1" class="ltx_text" style="font-size:80%;">CombSUM</span></th>
<td id="S3.T2.18.16.4.2" class="ltx_td ltx_align_left" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S3.T2.18.16.4.2.1" class="ltx_text" style="font-size:80%;">0.3493</span></td>
<td id="S3.T2.18.16.4.3" class="ltx_td ltx_align_left ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S3.T2.18.16.4.3.1" class="ltx_text" style="font-size:80%;">0.2395</span></td>
<td id="S3.T2.18.16.4.4" class="ltx_td ltx_align_left" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S3.T2.18.16.4.4.1" class="ltx_text" style="font-size:80%;">0.3406</span></td>
<td id="S3.T2.18.16.4.5" class="ltx_td ltx_align_left" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S3.T2.18.16.4.5.1" class="ltx_text" style="font-size:80%;">0.2322</span></td>
</tr>
<tr id="S3.T2.18.17.5" class="ltx_tr">
<th id="S3.T2.18.17.5.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S3.T2.18.17.5.1.1" class="ltx_text" style="font-size:80%;">RRF</span></th>
<td id="S3.T2.18.17.5.2" class="ltx_td ltx_align_left" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S3.T2.18.17.5.2.1" class="ltx_text" style="font-size:80%;">0.3389</span></td>
<td id="S3.T2.18.17.5.3" class="ltx_td ltx_align_left ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S3.T2.18.17.5.3.1" class="ltx_text" style="font-size:80%;">0.2291</span></td>
<td id="S3.T2.18.17.5.4" class="ltx_td ltx_align_left" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S3.T2.18.17.5.4.1" class="ltx_text" style="font-size:80%;">0.3292</span></td>
<td id="S3.T2.18.17.5.5" class="ltx_td ltx_align_left" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S3.T2.18.17.5.5.1" class="ltx_text" style="font-size:80%;">0.2213</span></td>
</tr>
<tr id="S3.T2.18.18.6" class="ltx_tr">
<th id="S3.T2.18.18.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;" rowspan="3"><span id="S3.T2.18.18.6.1.1" class="ltx_text" style="font-size:80%;">3. BM25-Cap</span></th>
<th id="S3.T2.18.18.6.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S3.T2.18.18.6.2.1" class="ltx_text" style="font-size:80%;">CombMAX</span></th>
<td id="S3.T2.18.18.6.3" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S3.T2.18.18.6.3.1" class="ltx_text" style="font-size:80%;">0.4547</span></td>
<td id="S3.T2.18.18.6.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S3.T2.18.18.6.4.1" class="ltx_text" style="font-size:80%;">0.3294</span></td>
<td id="S3.T2.18.18.6.5" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S3.T2.18.18.6.5.1" class="ltx_text" style="font-size:80%;">0.4534</span></td>
<td id="S3.T2.18.18.6.6" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S3.T2.18.18.6.6.1" class="ltx_text" style="font-size:80%;">0.3230</span></td>
</tr>
<tr id="S3.T2.14.8" class="ltx_tr">
<th id="S3.T2.14.8.5" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S3.T2.14.8.5.1" class="ltx_text" style="font-size:80%;">CombSUM</span></th>
<td id="S3.T2.11.5.1" class="ltx_td ltx_align_left" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S3.T2.11.5.1.2" class="ltx_ERROR undefined">\ul</span><span id="S3.T2.11.5.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">0.4727<sup id="S3.T2.11.5.1.1.1" class="ltx_sup"><span id="S3.T2.11.5.1.1.1.1" class="ltx_text ltx_font_medium ltx_font_italic">â–²1,2,4</span></sup></span>
</td>
<td id="S3.T2.12.6.2" class="ltx_td ltx_align_left ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S3.T2.12.6.2.2" class="ltx_ERROR undefined">\ul</span><span id="S3.T2.12.6.2.1" class="ltx_text ltx_font_bold" style="font-size:80%;">0.3483<sup id="S3.T2.12.6.2.1.1" class="ltx_sup"><span id="S3.T2.12.6.2.1.1.1" class="ltx_text ltx_font_medium ltx_font_italic">â–²1,2,4</span></sup></span>
</td>
<td id="S3.T2.13.7.3" class="ltx_td ltx_align_left" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S3.T2.13.7.3.2" class="ltx_ERROR undefined">\ul</span><span id="S3.T2.13.7.3.1" class="ltx_text ltx_font_bold" style="font-size:80%;">0.4622<sup id="S3.T2.13.7.3.1.1" class="ltx_sup"><span id="S3.T2.13.7.3.1.1.1" class="ltx_text ltx_font_medium ltx_font_italic">â–²1,2</span></sup></span>
</td>
<td id="S3.T2.14.8.4" class="ltx_td ltx_align_left" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S3.T2.14.8.4.2" class="ltx_ERROR undefined">\ul</span><span id="S3.T2.14.8.4.1" class="ltx_text ltx_font_bold" style="font-size:80%;">0.3367<sup id="S3.T2.14.8.4.1.1" class="ltx_sup"><span id="S3.T2.14.8.4.1.1.1" class="ltx_text ltx_font_medium ltx_font_italic">â–²1,2,4</span></sup></span>
</td>
</tr>
<tr id="S3.T2.18.19.7" class="ltx_tr">
<th id="S3.T2.18.19.7.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S3.T2.18.19.7.1.1" class="ltx_text" style="font-size:80%;">RRF</span></th>
<td id="S3.T2.18.19.7.2" class="ltx_td ltx_align_left" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S3.T2.18.19.7.2.1" class="ltx_text" style="font-size:80%;">0.4689</span></td>
<td id="S3.T2.18.19.7.3" class="ltx_td ltx_align_left ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S3.T2.18.19.7.3.1" class="ltx_text" style="font-size:80%;">0.3440</span></td>
<td id="S3.T2.18.19.7.4" class="ltx_td ltx_align_left" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S3.T2.18.19.7.4.1" class="ltx_text" style="font-size:80%;">0.4585</span></td>
<td id="S3.T2.18.19.7.5" class="ltx_td ltx_align_left" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S3.T2.18.19.7.5.1" class="ltx_text" style="font-size:80%;">0.3346</span></td>
</tr>
<tr id="S3.T2.18.12" class="ltx_tr">
<th id="S3.T2.18.12.5" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;" rowspan="3"><span id="S3.T2.18.12.5.1" class="ltx_text" style="font-size:80%;">4. BM25-All</span></th>
<th id="S3.T2.18.12.6" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S3.T2.18.12.6.1" class="ltx_text" style="font-size:80%;">CombMAX</span></th>
<td id="S3.T2.15.9.1" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S3.T2.15.9.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">0.4550<sup id="S3.T2.15.9.1.1.1" class="ltx_sup"><span id="S3.T2.15.9.1.1.1.1" class="ltx_text ltx_font_medium ltx_font_italic">â–²1,2</span></sup></span></td>
<td id="S3.T2.16.10.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S3.T2.16.10.2.1" class="ltx_text ltx_font_bold" style="font-size:80%;">0.3293<sup id="S3.T2.16.10.2.1.1" class="ltx_sup"><span id="S3.T2.16.10.2.1.1.1" class="ltx_text ltx_font_medium ltx_font_italic">â–²1,2</span></sup></span></td>
<td id="S3.T2.17.11.3" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S3.T2.17.11.3.1" class="ltx_text ltx_font_bold" style="font-size:80%;">0.4533<sup id="S3.T2.17.11.3.1.1" class="ltx_sup"><span id="S3.T2.17.11.3.1.1.1" class="ltx_text ltx_font_medium ltx_font_italic">â–²1,2</span></sup></span></td>
<td id="S3.T2.18.12.4" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S3.T2.18.12.4.1" class="ltx_text ltx_font_bold" style="font-size:80%;">0.3233<sup id="S3.T2.18.12.4.1.1" class="ltx_sup"><span id="S3.T2.18.12.4.1.1.1" class="ltx_text ltx_font_medium ltx_font_italic">â–²1,2</span></sup></span></td>
</tr>
<tr id="S3.T2.18.20.8" class="ltx_tr">
<th id="S3.T2.18.20.8.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S3.T2.18.20.8.1.1" class="ltx_text" style="font-size:80%;">CombSUM</span></th>
<td id="S3.T2.18.20.8.2" class="ltx_td ltx_align_left" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S3.T2.18.20.8.2.1" class="ltx_text" style="font-size:80%;">0.4490</span></td>
<td id="S3.T2.18.20.8.3" class="ltx_td ltx_align_left ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S3.T2.18.20.8.3.1" class="ltx_text" style="font-size:80%;">0.3241</span></td>
<td id="S3.T2.18.20.8.4" class="ltx_td ltx_align_left" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S3.T2.18.20.8.4.1" class="ltx_text" style="font-size:80%;">0.4396</span></td>
<td id="S3.T2.18.20.8.5" class="ltx_td ltx_align_left" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S3.T2.18.20.8.5.1" class="ltx_text" style="font-size:80%;">0.3126</span></td>
</tr>
<tr id="S3.T2.18.21.9" class="ltx_tr">
<th id="S3.T2.18.21.9.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S3.T2.18.21.9.1.1" class="ltx_text" style="font-size:80%;">RRF</span></th>
<td id="S3.T2.18.21.9.2" class="ltx_td ltx_align_left ltx_border_bb" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S3.T2.18.21.9.2.1" class="ltx_text" style="font-size:80%;">0.4322</span></td>
<td id="S3.T2.18.21.9.3" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S3.T2.18.21.9.3.1" class="ltx_text" style="font-size:80%;">0.3069</span></td>
<td id="S3.T2.18.21.9.4" class="ltx_td ltx_align_left ltx_border_bb" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S3.T2.18.21.9.4.1" class="ltx_text" style="font-size:80%;">0.4260</span></td>
<td id="S3.T2.18.21.9.5" class="ltx_td ltx_align_left ltx_border_bb" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S3.T2.18.21.9.5.1" class="ltx_text" style="font-size:80%;">0.2956</span></td>
</tr>
</tbody>
</table>
</figure>
</section>
<section id="S3.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.2. </span><span id="S3.SS2.SSS2.1.1" class="ltx_text ltx_font_bold">Dense Retrieval</span>
</h4>

<div id="S3.SS2.SSS2.p1" class="ltx_para">
<p id="S3.SS2.SSS2.p1.1" class="ltx_p">We present the dense retrieval results, along with the best sparse retrieval results in Tab.Â <a href="#S3.T3" title="Table 3 â€£ 3.2.2. Dense Retrieval â€£ 3.2. Main Results â€£ 3. Experiments â€£ Passage Retrieval for Outside-Knowledge Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> to answer <span id="S3.SS2.SSS2.p1.1.1" class="ltx_text ltx_font_bold">RQ3</span>. We first compare retrieval without visual clues: we observe that Dense-BERT outperforms BM25-Orig by a large margin, verifying the capability of dense retrieval. We further explain that this capability is contingent upon the negative sampling strategy used during training in Sec.Â <a href="#S3.SS3.SSS2" title="3.3.2. Impact of negative sampling â€£ 3.3. Additional Results â€£ 3. Experiments â€£ Passage Retrieval for Outside-Knowledge Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.3.2</span></a>. Moreover, Dense-BERT even surpasses BM25-Obj that considers visual signals.
This could be due to the tendency of Dense-BERT to retrieve passages containing frequent answers.
We speculate this kind of overfitting is caused by the lack of visual signals. Further analysis can be found in Sec.Â <a href="#S3.SS3" title="3.3. Additional Results â€£ 3. Experiments â€£ Passage Retrieval for Outside-Knowledge Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.3</span></a>.</p>
</div>
<div id="S3.SS2.SSS2.p2" class="ltx_para">
<p id="S3.SS2.SSS2.p2.1" class="ltx_p">We further observe that Dense-LXMERT significantly outperforms BM25-Obj.
Dense-LXMERT leverages both the RoI features and position features in object detection to learn object relations, which can be more effective than using ground truth object names in sparse retrieval.
We then compare Dense-LXMERT with BM25-Cap/All. These sparse retrieval methods consider human-annotated image captions that are highly informative and descriptive. On the contrary, Dense-LXMERT has to learn the importance of the objects and the relation among them with object-level features. In this unfavorable situation, Dense-LXMERT still manages to match the performance of BM25-Cap/All. Although BM25-Cap is slightly better, the margins are statistically <span id="S3.SS2.SSS2.p2.1.1" class="ltx_text ltx_font_italic">insignificant</span>.
Finally, we observe that Dense-LXMERT significantly outperforms Dense-BERT, further validating the use of a multi-modal query encoder.</p>
</div>
<figure id="S3.T3" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S3.T3.27.3.1" class="ltx_text" style="font-size:90%;">Table 3</span>. </span><span id="S3.T3.4.2" class="ltx_text" style="font-size:90%;">Dense retrieval results.
Refer to Tab.Â <a href="#S3.T2" title="Table 2 â€£ 3.2.1. Sparse Retrieval â€£ 3.2. Main Results â€£ 3. Experiments â€£ Passage Retrieval for Outside-Knowledge Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> for notations. <math id="S3.T3.3.1.m1.1" class="ltx_Math" alttext="\triangle i" display="inline"><semantics id="S3.T3.3.1.m1.1b"><mrow id="S3.T3.3.1.m1.1.1" xref="S3.T3.3.1.m1.1.1.cmml"><mi mathvariant="normal" id="S3.T3.3.1.m1.1.1.2" xref="S3.T3.3.1.m1.1.1.2.cmml">â–³</mi><mo lspace="0em" rspace="0em" id="S3.T3.3.1.m1.1.1.1" xref="S3.T3.3.1.m1.1.1.1.cmml">â€‹</mo><mi id="S3.T3.3.1.m1.1.1.3" xref="S3.T3.3.1.m1.1.1.3.cmml">i</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.T3.3.1.m1.1c"><apply id="S3.T3.3.1.m1.1.1.cmml" xref="S3.T3.3.1.m1.1.1"><times id="S3.T3.3.1.m1.1.1.1.cmml" xref="S3.T3.3.1.m1.1.1.1"></times><ci id="S3.T3.3.1.m1.1.1.2.cmml" xref="S3.T3.3.1.m1.1.1.2">â–³</ci><ci id="S3.T3.3.1.m1.1.1.3.cmml" xref="S3.T3.3.1.m1.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.3.1.m1.1d">\triangle i</annotation></semantics></math> denotes the statistical significance is obtained with <math id="S3.T3.4.2.m2.1" class="ltx_Math" alttext="0.05&lt;p&lt;0.1" display="inline"><semantics id="S3.T3.4.2.m2.1b"><mrow id="S3.T3.4.2.m2.1.1" xref="S3.T3.4.2.m2.1.1.cmml"><mn id="S3.T3.4.2.m2.1.1.2" xref="S3.T3.4.2.m2.1.1.2.cmml">0.05</mn><mo id="S3.T3.4.2.m2.1.1.3" xref="S3.T3.4.2.m2.1.1.3.cmml">&lt;</mo><mi id="S3.T3.4.2.m2.1.1.4" xref="S3.T3.4.2.m2.1.1.4.cmml">p</mi><mo id="S3.T3.4.2.m2.1.1.5" xref="S3.T3.4.2.m2.1.1.5.cmml">&lt;</mo><mn id="S3.T3.4.2.m2.1.1.6" xref="S3.T3.4.2.m2.1.1.6.cmml">0.1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.T3.4.2.m2.1c"><apply id="S3.T3.4.2.m2.1.1.cmml" xref="S3.T3.4.2.m2.1.1"><and id="S3.T3.4.2.m2.1.1a.cmml" xref="S3.T3.4.2.m2.1.1"></and><apply id="S3.T3.4.2.m2.1.1b.cmml" xref="S3.T3.4.2.m2.1.1"><lt id="S3.T3.4.2.m2.1.1.3.cmml" xref="S3.T3.4.2.m2.1.1.3"></lt><cn type="float" id="S3.T3.4.2.m2.1.1.2.cmml" xref="S3.T3.4.2.m2.1.1.2">0.05</cn><ci id="S3.T3.4.2.m2.1.1.4.cmml" xref="S3.T3.4.2.m2.1.1.4">ğ‘</ci></apply><apply id="S3.T3.4.2.m2.1.1c.cmml" xref="S3.T3.4.2.m2.1.1"><lt id="S3.T3.4.2.m2.1.1.5.cmml" xref="S3.T3.4.2.m2.1.1.5"></lt><share href="#S3.T3.4.2.m2.1.1.4.cmml" id="S3.T3.4.2.m2.1.1d.cmml" xref="S3.T3.4.2.m2.1.1"></share><cn type="float" id="S3.T3.4.2.m2.1.1.6.cmml" xref="S3.T3.4.2.m2.1.1.6">0.1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.4.2.m2.1d">0.05&lt;p&lt;0.1</annotation></semantics></math>.
Note that <span id="S3.T3.4.2.1" class="ltx_text ltx_font_italic">BM25-Obj/Cap/All has access to the ground truth object names and captions.
</span></span></figcaption>
<table id="S3.T3.24" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S3.T3.24.21.1" class="ltx_tr">
<th id="S3.T3.24.21.1.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_tt" style="padding-left:1.0pt;padding-right:1.0pt;" colspan="2" rowspan="2"><span id="S3.T3.24.21.1.1.1" class="ltx_text" style="font-size:80%;">Methods</span></th>
<td id="S3.T3.24.21.1.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_tt" style="padding-left:1.0pt;padding-right:1.0pt;" colspan="2"><span id="S3.T3.24.21.1.2.1" class="ltx_text" style="font-size:80%;">Val</span></td>
<td id="S3.T3.24.21.1.3" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_tt" style="padding-left:1.0pt;padding-right:1.0pt;" colspan="2"><span id="S3.T3.24.21.1.3.1" class="ltx_text" style="font-size:80%;">Test</span></td>
</tr>
<tr id="S3.T3.24.22.2" class="ltx_tr">
<td id="S3.T3.24.22.2.1" class="ltx_td ltx_nopad_l ltx_align_left ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S3.T3.24.22.2.1.1" class="ltx_text" style="font-size:80%;">MRR@5</span></td>
<td id="S3.T3.24.22.2.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S3.T3.24.22.2.2.1" class="ltx_text" style="font-size:80%;">P@5</span></td>
<td id="S3.T3.24.22.2.3" class="ltx_td ltx_nopad_l ltx_align_left ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S3.T3.24.22.2.3.1" class="ltx_text" style="font-size:80%;">MRR@5</span></td>
<td id="S3.T3.24.22.2.4" class="ltx_td ltx_nopad_l ltx_align_left ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S3.T3.24.22.2.4.1" class="ltx_text" style="font-size:80%;">P@5</span></td>
</tr>
<tr id="S3.T3.24.23.3" class="ltx_tr">
<th id="S3.T3.24.23.3.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;" rowspan="4"><span id="S3.T3.24.23.3.1.1" class="ltx_text" style="font-size:80%;">
<span id="S3.T3.24.23.3.1.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:7.0pt;height:22.7pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="width:22.7pt;transform:translate(-7.86pt,-7.08pt) rotate(-90deg) ;">
<span id="S3.T3.24.23.3.1.1.1.1" class="ltx_p">Sparse</span>
</span></span></span></th>
<th id="S3.T3.24.23.3.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S3.T3.24.23.3.2.1" class="ltx_text" style="font-size:80%;">1. BM25-Orig</span></th>
<td id="S3.T3.24.23.3.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S3.T3.24.23.3.3.1" class="ltx_text" style="font-size:80%;">0.2565</span></td>
<td id="S3.T3.24.23.3.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S3.T3.24.23.3.4.1" class="ltx_text" style="font-size:80%;">0.1772</span></td>
<td id="S3.T3.24.23.3.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S3.T3.24.23.3.5.1" class="ltx_text" style="font-size:80%;">0.2637</span></td>
<td id="S3.T3.24.23.3.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S3.T3.24.23.3.6.1" class="ltx_text" style="font-size:80%;">0.1755</span></td>
</tr>
<tr id="S3.T3.8.4" class="ltx_tr">
<th id="S3.T3.8.4.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S3.T3.8.4.5.1" class="ltx_text" style="font-size:80%;">2. BM25-Obj (CombMAX)</span></th>
<td id="S3.T3.5.1.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="S3.T3.5.1.1.1" class="ltx_text" style="font-size:80%;">0.3772</span><sup id="S3.T3.5.1.1.2" class="ltx_sup"><span id="S3.T3.5.1.1.2.1" class="ltx_text ltx_font_italic" style="font-size:80%;">â–²1</span></sup>
</td>
<td id="S3.T3.6.2.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="S3.T3.6.2.2.1" class="ltx_text" style="font-size:80%;">0.2667</span><sup id="S3.T3.6.2.2.2" class="ltx_sup"><span id="S3.T3.6.2.2.2.1" class="ltx_text ltx_font_italic" style="font-size:80%;">â–²1</span></sup>
</td>
<td id="S3.T3.7.3.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="S3.T3.7.3.3.1" class="ltx_text" style="font-size:80%;">0.3686</span><sup id="S3.T3.7.3.3.2" class="ltx_sup"><span id="S3.T3.7.3.3.2.1" class="ltx_text ltx_font_italic" style="font-size:80%;">â–²1</span></sup>
</td>
<td id="S3.T3.8.4.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="S3.T3.8.4.4.1" class="ltx_text" style="font-size:80%;">0.2541</span><sup id="S3.T3.8.4.4.2" class="ltx_sup"><span id="S3.T3.8.4.4.2.1" class="ltx_text ltx_font_italic" style="font-size:80%;">â–²1</span></sup>
</td>
</tr>
<tr id="S3.T3.12.8" class="ltx_tr">
<th id="S3.T3.12.8.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S3.T3.12.8.5.1" class="ltx_text" style="font-size:80%;">3. BM25-Cap (CombSUM)</span></th>
<td id="S3.T3.9.5.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="S3.T3.9.5.1.2" class="ltx_ERROR undefined">\ul</span><span id="S3.T3.9.5.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">0.4727<math id="S3.T3.9.5.1.1.m1.3" class="ltx_Math" alttext="{}^{\blacktriangle 1,2,4\ \triangle 5}" display="inline"><semantics id="S3.T3.9.5.1.1.m1.3a"><msup id="S3.T3.9.5.1.1.m1.3.3" xref="S3.T3.9.5.1.1.m1.3.3.cmml"><mi id="S3.T3.9.5.1.1.m1.3.3a" xref="S3.T3.9.5.1.1.m1.3.3.cmml"></mi><mrow id="S3.T3.9.5.1.1.m1.3.3.3.3" xref="S3.T3.9.5.1.1.m1.3.3.3.4.cmml"><mrow id="S3.T3.9.5.1.1.m1.2.2.2.2.1" xref="S3.T3.9.5.1.1.m1.2.2.2.2.1.cmml"><mi mathvariant="normal" id="S3.T3.9.5.1.1.m1.2.2.2.2.1.2" xref="S3.T3.9.5.1.1.m1.2.2.2.2.1.2.cmml">â–²</mi><mo lspace="0em" rspace="0em" id="S3.T3.9.5.1.1.m1.2.2.2.2.1.1" xref="S3.T3.9.5.1.1.m1.2.2.2.2.1.1.cmml">â€‹</mo><mn id="S3.T3.9.5.1.1.m1.2.2.2.2.1.3" xref="S3.T3.9.5.1.1.m1.2.2.2.2.1.3.cmml">1</mn></mrow><mo id="S3.T3.9.5.1.1.m1.3.3.3.3.3" xref="S3.T3.9.5.1.1.m1.3.3.3.4.cmml">,</mo><mn id="S3.T3.9.5.1.1.m1.1.1.1.1" xref="S3.T3.9.5.1.1.m1.1.1.1.1.cmml">2</mn><mo id="S3.T3.9.5.1.1.m1.3.3.3.3.4" xref="S3.T3.9.5.1.1.m1.3.3.3.4.cmml">,</mo><mrow id="S3.T3.9.5.1.1.m1.3.3.3.3.2" xref="S3.T3.9.5.1.1.m1.3.3.3.3.2.cmml"><mn id="S3.T3.9.5.1.1.m1.3.3.3.3.2.2" xref="S3.T3.9.5.1.1.m1.3.3.3.3.2.2.cmml">4</mn><mo lspace="0.280em" rspace="0em" id="S3.T3.9.5.1.1.m1.3.3.3.3.2.1" xref="S3.T3.9.5.1.1.m1.3.3.3.3.2.1.cmml">â€‹</mo><mi mathvariant="normal" id="S3.T3.9.5.1.1.m1.3.3.3.3.2.3" xref="S3.T3.9.5.1.1.m1.3.3.3.3.2.3.cmml">â–³</mi><mo lspace="0em" rspace="0em" id="S3.T3.9.5.1.1.m1.3.3.3.3.2.1a" xref="S3.T3.9.5.1.1.m1.3.3.3.3.2.1.cmml">â€‹</mo><mn id="S3.T3.9.5.1.1.m1.3.3.3.3.2.4" xref="S3.T3.9.5.1.1.m1.3.3.3.3.2.4.cmml">5</mn></mrow></mrow></msup><annotation-xml encoding="MathML-Content" id="S3.T3.9.5.1.1.m1.3b"><apply id="S3.T3.9.5.1.1.m1.3.3.cmml" xref="S3.T3.9.5.1.1.m1.3.3"><list id="S3.T3.9.5.1.1.m1.3.3.3.4.cmml" xref="S3.T3.9.5.1.1.m1.3.3.3.3"><apply id="S3.T3.9.5.1.1.m1.2.2.2.2.1.cmml" xref="S3.T3.9.5.1.1.m1.2.2.2.2.1"><times id="S3.T3.9.5.1.1.m1.2.2.2.2.1.1.cmml" xref="S3.T3.9.5.1.1.m1.2.2.2.2.1.1"></times><ci id="S3.T3.9.5.1.1.m1.2.2.2.2.1.2.cmml" xref="S3.T3.9.5.1.1.m1.2.2.2.2.1.2">â–²</ci><cn type="integer" id="S3.T3.9.5.1.1.m1.2.2.2.2.1.3.cmml" xref="S3.T3.9.5.1.1.m1.2.2.2.2.1.3">1</cn></apply><cn type="integer" id="S3.T3.9.5.1.1.m1.1.1.1.1.cmml" xref="S3.T3.9.5.1.1.m1.1.1.1.1">2</cn><apply id="S3.T3.9.5.1.1.m1.3.3.3.3.2.cmml" xref="S3.T3.9.5.1.1.m1.3.3.3.3.2"><times id="S3.T3.9.5.1.1.m1.3.3.3.3.2.1.cmml" xref="S3.T3.9.5.1.1.m1.3.3.3.3.2.1"></times><cn type="integer" id="S3.T3.9.5.1.1.m1.3.3.3.3.2.2.cmml" xref="S3.T3.9.5.1.1.m1.3.3.3.3.2.2">4</cn><ci id="S3.T3.9.5.1.1.m1.3.3.3.3.2.3.cmml" xref="S3.T3.9.5.1.1.m1.3.3.3.3.2.3">â–³</ci><cn type="integer" id="S3.T3.9.5.1.1.m1.3.3.3.3.2.4.cmml" xref="S3.T3.9.5.1.1.m1.3.3.3.3.2.4">5</cn></apply></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.9.5.1.1.m1.3c">{}^{\blacktriangle 1,2,4\ \triangle 5}</annotation></semantics></math></span>
</td>
<td id="S3.T3.10.6.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="S3.T3.10.6.2.2" class="ltx_ERROR undefined">\ul</span><span id="S3.T3.10.6.2.1" class="ltx_text ltx_font_bold" style="font-size:80%;">0.3483<sup id="S3.T3.10.6.2.1.1" class="ltx_sup"><span id="S3.T3.10.6.2.1.1.1" class="ltx_text ltx_font_medium ltx_font_italic">â–²1,2,4,5</span></sup></span>
</td>
<td id="S3.T3.11.7.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="S3.T3.11.7.3.2" class="ltx_ERROR undefined">\ul</span><span id="S3.T3.11.7.3.1" class="ltx_text ltx_font_bold" style="font-size:80%;">0.4622<sup id="S3.T3.11.7.3.1.1" class="ltx_sup"><span id="S3.T3.11.7.3.1.1.1" class="ltx_text ltx_font_medium ltx_font_italic">â–²1,2,5</span></sup></span>
</td>
<td id="S3.T3.12.8.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="S3.T3.12.8.4.2" class="ltx_ERROR undefined">\ul</span><span id="S3.T3.12.8.4.1" class="ltx_text ltx_font_bold" style="font-size:80%;">0.3367<sup id="S3.T3.12.8.4.1.1" class="ltx_sup"><span id="S3.T3.12.8.4.1.1.1" class="ltx_text ltx_font_medium ltx_font_italic">â–²1,2,4,5</span></sup></span>
</td>
</tr>
<tr id="S3.T3.16.12" class="ltx_tr">
<th id="S3.T3.16.12.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S3.T3.16.12.5.1" class="ltx_text" style="font-size:80%;">4. BM25-All (CombMAX)</span></th>
<td id="S3.T3.13.9.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="S3.T3.13.9.1.1" class="ltx_text" style="font-size:80%;">0.4550</span><sup id="S3.T3.13.9.1.2" class="ltx_sup"><span id="S3.T3.13.9.1.2.1" class="ltx_text ltx_font_italic" style="font-size:80%;">â–²1,2</span></sup>
</td>
<td id="S3.T3.14.10.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="S3.T3.14.10.2.1" class="ltx_text" style="font-size:80%;">0.3293</span><math id="S3.T3.14.10.2.m1.2" class="ltx_Math" alttext="{}^{\blacktriangle 1,2\ \triangle 5}" display="inline"><semantics id="S3.T3.14.10.2.m1.2a"><msup id="S3.T3.14.10.2.m1.2.2" xref="S3.T3.14.10.2.m1.2.2.cmml"><mi id="S3.T3.14.10.2.m1.2.2a" xref="S3.T3.14.10.2.m1.2.2.cmml"></mi><mrow id="S3.T3.14.10.2.m1.2.2.2.2" xref="S3.T3.14.10.2.m1.2.2.2.3.cmml"><mrow id="S3.T3.14.10.2.m1.1.1.1.1.1" xref="S3.T3.14.10.2.m1.1.1.1.1.1.cmml"><mi mathsize="80%" mathvariant="normal" id="S3.T3.14.10.2.m1.1.1.1.1.1.2" xref="S3.T3.14.10.2.m1.1.1.1.1.1.2.cmml">â–²</mi><mo lspace="0em" rspace="0em" id="S3.T3.14.10.2.m1.1.1.1.1.1.1" xref="S3.T3.14.10.2.m1.1.1.1.1.1.1.cmml">â€‹</mo><mn mathsize="80%" id="S3.T3.14.10.2.m1.1.1.1.1.1.3" xref="S3.T3.14.10.2.m1.1.1.1.1.1.3.cmml">1</mn></mrow><mo mathsize="80%" id="S3.T3.14.10.2.m1.2.2.2.2.3" xref="S3.T3.14.10.2.m1.2.2.2.3.cmml">,</mo><mrow id="S3.T3.14.10.2.m1.2.2.2.2.2" xref="S3.T3.14.10.2.m1.2.2.2.2.2.cmml"><mn mathsize="80%" id="S3.T3.14.10.2.m1.2.2.2.2.2.2" xref="S3.T3.14.10.2.m1.2.2.2.2.2.2.cmml">2</mn><mo lspace="0.280em" rspace="0em" id="S3.T3.14.10.2.m1.2.2.2.2.2.1" xref="S3.T3.14.10.2.m1.2.2.2.2.2.1.cmml">â€‹</mo><mi mathsize="80%" mathvariant="normal" id="S3.T3.14.10.2.m1.2.2.2.2.2.3" xref="S3.T3.14.10.2.m1.2.2.2.2.2.3.cmml">â–³</mi><mo lspace="0em" rspace="0em" id="S3.T3.14.10.2.m1.2.2.2.2.2.1a" xref="S3.T3.14.10.2.m1.2.2.2.2.2.1.cmml">â€‹</mo><mn mathsize="80%" id="S3.T3.14.10.2.m1.2.2.2.2.2.4" xref="S3.T3.14.10.2.m1.2.2.2.2.2.4.cmml">5</mn></mrow></mrow></msup><annotation-xml encoding="MathML-Content" id="S3.T3.14.10.2.m1.2b"><apply id="S3.T3.14.10.2.m1.2.2.cmml" xref="S3.T3.14.10.2.m1.2.2"><list id="S3.T3.14.10.2.m1.2.2.2.3.cmml" xref="S3.T3.14.10.2.m1.2.2.2.2"><apply id="S3.T3.14.10.2.m1.1.1.1.1.1.cmml" xref="S3.T3.14.10.2.m1.1.1.1.1.1"><times id="S3.T3.14.10.2.m1.1.1.1.1.1.1.cmml" xref="S3.T3.14.10.2.m1.1.1.1.1.1.1"></times><ci id="S3.T3.14.10.2.m1.1.1.1.1.1.2.cmml" xref="S3.T3.14.10.2.m1.1.1.1.1.1.2">â–²</ci><cn type="integer" id="S3.T3.14.10.2.m1.1.1.1.1.1.3.cmml" xref="S3.T3.14.10.2.m1.1.1.1.1.1.3">1</cn></apply><apply id="S3.T3.14.10.2.m1.2.2.2.2.2.cmml" xref="S3.T3.14.10.2.m1.2.2.2.2.2"><times id="S3.T3.14.10.2.m1.2.2.2.2.2.1.cmml" xref="S3.T3.14.10.2.m1.2.2.2.2.2.1"></times><cn type="integer" id="S3.T3.14.10.2.m1.2.2.2.2.2.2.cmml" xref="S3.T3.14.10.2.m1.2.2.2.2.2.2">2</cn><ci id="S3.T3.14.10.2.m1.2.2.2.2.2.3.cmml" xref="S3.T3.14.10.2.m1.2.2.2.2.2.3">â–³</ci><cn type="integer" id="S3.T3.14.10.2.m1.2.2.2.2.2.4.cmml" xref="S3.T3.14.10.2.m1.2.2.2.2.2.4">5</cn></apply></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.14.10.2.m1.2c">{}^{\blacktriangle 1,2\ \triangle 5}</annotation></semantics></math>
</td>
<td id="S3.T3.15.11.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="S3.T3.15.11.3.1" class="ltx_text" style="font-size:80%;">0.4533</span><math id="S3.T3.15.11.3.m1.2" class="ltx_Math" alttext="{}^{\blacktriangle 1,2\ \triangle 5}" display="inline"><semantics id="S3.T3.15.11.3.m1.2a"><msup id="S3.T3.15.11.3.m1.2.2" xref="S3.T3.15.11.3.m1.2.2.cmml"><mi id="S3.T3.15.11.3.m1.2.2a" xref="S3.T3.15.11.3.m1.2.2.cmml"></mi><mrow id="S3.T3.15.11.3.m1.2.2.2.2" xref="S3.T3.15.11.3.m1.2.2.2.3.cmml"><mrow id="S3.T3.15.11.3.m1.1.1.1.1.1" xref="S3.T3.15.11.3.m1.1.1.1.1.1.cmml"><mi mathsize="80%" mathvariant="normal" id="S3.T3.15.11.3.m1.1.1.1.1.1.2" xref="S3.T3.15.11.3.m1.1.1.1.1.1.2.cmml">â–²</mi><mo lspace="0em" rspace="0em" id="S3.T3.15.11.3.m1.1.1.1.1.1.1" xref="S3.T3.15.11.3.m1.1.1.1.1.1.1.cmml">â€‹</mo><mn mathsize="80%" id="S3.T3.15.11.3.m1.1.1.1.1.1.3" xref="S3.T3.15.11.3.m1.1.1.1.1.1.3.cmml">1</mn></mrow><mo mathsize="80%" id="S3.T3.15.11.3.m1.2.2.2.2.3" xref="S3.T3.15.11.3.m1.2.2.2.3.cmml">,</mo><mrow id="S3.T3.15.11.3.m1.2.2.2.2.2" xref="S3.T3.15.11.3.m1.2.2.2.2.2.cmml"><mn mathsize="80%" id="S3.T3.15.11.3.m1.2.2.2.2.2.2" xref="S3.T3.15.11.3.m1.2.2.2.2.2.2.cmml">2</mn><mo lspace="0.280em" rspace="0em" id="S3.T3.15.11.3.m1.2.2.2.2.2.1" xref="S3.T3.15.11.3.m1.2.2.2.2.2.1.cmml">â€‹</mo><mi mathsize="80%" mathvariant="normal" id="S3.T3.15.11.3.m1.2.2.2.2.2.3" xref="S3.T3.15.11.3.m1.2.2.2.2.2.3.cmml">â–³</mi><mo lspace="0em" rspace="0em" id="S3.T3.15.11.3.m1.2.2.2.2.2.1a" xref="S3.T3.15.11.3.m1.2.2.2.2.2.1.cmml">â€‹</mo><mn mathsize="80%" id="S3.T3.15.11.3.m1.2.2.2.2.2.4" xref="S3.T3.15.11.3.m1.2.2.2.2.2.4.cmml">5</mn></mrow></mrow></msup><annotation-xml encoding="MathML-Content" id="S3.T3.15.11.3.m1.2b"><apply id="S3.T3.15.11.3.m1.2.2.cmml" xref="S3.T3.15.11.3.m1.2.2"><list id="S3.T3.15.11.3.m1.2.2.2.3.cmml" xref="S3.T3.15.11.3.m1.2.2.2.2"><apply id="S3.T3.15.11.3.m1.1.1.1.1.1.cmml" xref="S3.T3.15.11.3.m1.1.1.1.1.1"><times id="S3.T3.15.11.3.m1.1.1.1.1.1.1.cmml" xref="S3.T3.15.11.3.m1.1.1.1.1.1.1"></times><ci id="S3.T3.15.11.3.m1.1.1.1.1.1.2.cmml" xref="S3.T3.15.11.3.m1.1.1.1.1.1.2">â–²</ci><cn type="integer" id="S3.T3.15.11.3.m1.1.1.1.1.1.3.cmml" xref="S3.T3.15.11.3.m1.1.1.1.1.1.3">1</cn></apply><apply id="S3.T3.15.11.3.m1.2.2.2.2.2.cmml" xref="S3.T3.15.11.3.m1.2.2.2.2.2"><times id="S3.T3.15.11.3.m1.2.2.2.2.2.1.cmml" xref="S3.T3.15.11.3.m1.2.2.2.2.2.1"></times><cn type="integer" id="S3.T3.15.11.3.m1.2.2.2.2.2.2.cmml" xref="S3.T3.15.11.3.m1.2.2.2.2.2.2">2</cn><ci id="S3.T3.15.11.3.m1.2.2.2.2.2.3.cmml" xref="S3.T3.15.11.3.m1.2.2.2.2.2.3">â–³</ci><cn type="integer" id="S3.T3.15.11.3.m1.2.2.2.2.2.4.cmml" xref="S3.T3.15.11.3.m1.2.2.2.2.2.4">5</cn></apply></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.15.11.3.m1.2c">{}^{\blacktriangle 1,2\ \triangle 5}</annotation></semantics></math>
</td>
<td id="S3.T3.16.12.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="S3.T3.16.12.4.1" class="ltx_text" style="font-size:80%;">0.3233</span><sup id="S3.T3.16.12.4.2" class="ltx_sup"><span id="S3.T3.16.12.4.2.1" class="ltx_text ltx_font_italic" style="font-size:80%;">â–²1,2,5</span></sup>
</td>
</tr>
<tr id="S3.T3.20.16" class="ltx_tr">
<th id="S3.T3.20.16.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;" rowspan="2"><span id="S3.T3.20.16.5.1" class="ltx_text" style="font-size:80%;">
<span id="S3.T3.20.16.5.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:5.5pt;height:20.8pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="width:20.8pt;transform:translate(-7.68pt,-7.68pt) rotate(-90deg) ;">
<span id="S3.T3.20.16.5.1.1.1" class="ltx_p">Dense</span>
</span></span></span></th>
<th id="S3.T3.20.16.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S3.T3.20.16.6.1" class="ltx_text" style="font-size:80%;">5. Dense-BERT</span></th>
<td id="S3.T3.17.13.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="S3.T3.17.13.1.1" class="ltx_text" style="font-size:80%;">0.4555</span><sup id="S3.T3.17.13.1.2" class="ltx_sup"><span id="S3.T3.17.13.1.2.1" class="ltx_text ltx_font_italic" style="font-size:80%;">â–²1,2</span></sup>
</td>
<td id="S3.T3.18.14.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="S3.T3.18.14.2.1" class="ltx_text" style="font-size:80%;">0.3155</span><sup id="S3.T3.18.14.2.2" class="ltx_sup"><span id="S3.T3.18.14.2.2.1" class="ltx_text ltx_font_italic" style="font-size:80%;">â–²1,2</span></sup>
</td>
<td id="S3.T3.19.15.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="S3.T3.19.15.3.1" class="ltx_text" style="font-size:80%;">0.4325</span><sup id="S3.T3.19.15.3.2" class="ltx_sup"><span id="S3.T3.19.15.3.2.1" class="ltx_text ltx_font_italic" style="font-size:80%;">â–²1,2</span></sup>
</td>
<td id="S3.T3.20.16.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="S3.T3.20.16.4.1" class="ltx_text" style="font-size:80%;">0.3058</span><sup id="S3.T3.20.16.4.2" class="ltx_sup"><span id="S3.T3.20.16.4.2.1" class="ltx_text ltx_font_italic" style="font-size:80%;">â–²1,2</span></sup>
</td>
</tr>
<tr id="S3.T3.24.20" class="ltx_tr">
<th id="S3.T3.24.20.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S3.T3.24.20.5.1" class="ltx_text" style="font-size:80%;">6. Dense-LXMERT</span></th>
<td id="S3.T3.21.17.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_bb" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S3.T3.21.17.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">0.4704<math id="S3.T3.21.17.1.1.m1.2" class="ltx_Math" alttext="{}^{\blacktriangle 1,2\ \triangle 5}" display="inline"><semantics id="S3.T3.21.17.1.1.m1.2a"><msup id="S3.T3.21.17.1.1.m1.2.2" xref="S3.T3.21.17.1.1.m1.2.2.cmml"><mi id="S3.T3.21.17.1.1.m1.2.2a" xref="S3.T3.21.17.1.1.m1.2.2.cmml"></mi><mrow id="S3.T3.21.17.1.1.m1.2.2.2.2" xref="S3.T3.21.17.1.1.m1.2.2.2.3.cmml"><mrow id="S3.T3.21.17.1.1.m1.1.1.1.1.1" xref="S3.T3.21.17.1.1.m1.1.1.1.1.1.cmml"><mi mathvariant="normal" id="S3.T3.21.17.1.1.m1.1.1.1.1.1.2" xref="S3.T3.21.17.1.1.m1.1.1.1.1.1.2.cmml">â–²</mi><mo lspace="0em" rspace="0em" id="S3.T3.21.17.1.1.m1.1.1.1.1.1.1" xref="S3.T3.21.17.1.1.m1.1.1.1.1.1.1.cmml">â€‹</mo><mn id="S3.T3.21.17.1.1.m1.1.1.1.1.1.3" xref="S3.T3.21.17.1.1.m1.1.1.1.1.1.3.cmml">1</mn></mrow><mo id="S3.T3.21.17.1.1.m1.2.2.2.2.3" xref="S3.T3.21.17.1.1.m1.2.2.2.3.cmml">,</mo><mrow id="S3.T3.21.17.1.1.m1.2.2.2.2.2" xref="S3.T3.21.17.1.1.m1.2.2.2.2.2.cmml"><mn id="S3.T3.21.17.1.1.m1.2.2.2.2.2.2" xref="S3.T3.21.17.1.1.m1.2.2.2.2.2.2.cmml">2</mn><mo lspace="0.280em" rspace="0em" id="S3.T3.21.17.1.1.m1.2.2.2.2.2.1" xref="S3.T3.21.17.1.1.m1.2.2.2.2.2.1.cmml">â€‹</mo><mi mathvariant="normal" id="S3.T3.21.17.1.1.m1.2.2.2.2.2.3" xref="S3.T3.21.17.1.1.m1.2.2.2.2.2.3.cmml">â–³</mi><mo lspace="0em" rspace="0em" id="S3.T3.21.17.1.1.m1.2.2.2.2.2.1a" xref="S3.T3.21.17.1.1.m1.2.2.2.2.2.1.cmml">â€‹</mo><mn id="S3.T3.21.17.1.1.m1.2.2.2.2.2.4" xref="S3.T3.21.17.1.1.m1.2.2.2.2.2.4.cmml">5</mn></mrow></mrow></msup><annotation-xml encoding="MathML-Content" id="S3.T3.21.17.1.1.m1.2b"><apply id="S3.T3.21.17.1.1.m1.2.2.cmml" xref="S3.T3.21.17.1.1.m1.2.2"><list id="S3.T3.21.17.1.1.m1.2.2.2.3.cmml" xref="S3.T3.21.17.1.1.m1.2.2.2.2"><apply id="S3.T3.21.17.1.1.m1.1.1.1.1.1.cmml" xref="S3.T3.21.17.1.1.m1.1.1.1.1.1"><times id="S3.T3.21.17.1.1.m1.1.1.1.1.1.1.cmml" xref="S3.T3.21.17.1.1.m1.1.1.1.1.1.1"></times><ci id="S3.T3.21.17.1.1.m1.1.1.1.1.1.2.cmml" xref="S3.T3.21.17.1.1.m1.1.1.1.1.1.2">â–²</ci><cn type="integer" id="S3.T3.21.17.1.1.m1.1.1.1.1.1.3.cmml" xref="S3.T3.21.17.1.1.m1.1.1.1.1.1.3">1</cn></apply><apply id="S3.T3.21.17.1.1.m1.2.2.2.2.2.cmml" xref="S3.T3.21.17.1.1.m1.2.2.2.2.2"><times id="S3.T3.21.17.1.1.m1.2.2.2.2.2.1.cmml" xref="S3.T3.21.17.1.1.m1.2.2.2.2.2.1"></times><cn type="integer" id="S3.T3.21.17.1.1.m1.2.2.2.2.2.2.cmml" xref="S3.T3.21.17.1.1.m1.2.2.2.2.2.2">2</cn><ci id="S3.T3.21.17.1.1.m1.2.2.2.2.2.3.cmml" xref="S3.T3.21.17.1.1.m1.2.2.2.2.2.3">â–³</ci><cn type="integer" id="S3.T3.21.17.1.1.m1.2.2.2.2.2.4.cmml" xref="S3.T3.21.17.1.1.m1.2.2.2.2.2.4">5</cn></apply></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.21.17.1.1.m1.2c">{}^{\blacktriangle 1,2\ \triangle 5}</annotation></semantics></math></span></td>
<td id="S3.T3.22.18.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_bb ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S3.T3.22.18.2.1" class="ltx_text ltx_font_bold" style="font-size:80%;">0.3364<sup id="S3.T3.22.18.2.1.1" class="ltx_sup"><span id="S3.T3.22.18.2.1.1.1" class="ltx_text ltx_font_medium ltx_font_italic">â–²1,2,5</span></sup></span></td>
<td id="S3.T3.23.19.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_bb" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S3.T3.23.19.3.1" class="ltx_text ltx_font_bold" style="font-size:80%;">0.4526<sup id="S3.T3.23.19.3.1.1" class="ltx_sup"><span id="S3.T3.23.19.3.1.1.1" class="ltx_text ltx_font_medium ltx_font_italic">â–²1,2,5</span></sup></span></td>
<td id="S3.T3.24.20.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_bb" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S3.T3.24.20.4.1" class="ltx_text ltx_font_bold" style="font-size:80%;">0.3329<sup id="S3.T3.24.20.4.1.1" class="ltx_sup"><span id="S3.T3.24.20.4.1.1.1" class="ltx_text ltx_font_medium ltx_font_italic">â–²1,2,5</span></sup></span></td>
</tr>
</tbody>
</table>
</figure>
</section>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3. </span>Additional Results</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">We provide additional analysis to study the impact of the projection size and negative sampling strategies with validation performance.</p>
</div>
<section id="S3.SS3.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.3.1. </span><span id="S3.SS3.SSS1.1.1" class="ltx_text ltx_font_bold">Impact of projection size</span>
</h4>

<div id="S3.SS3.SSS1.p1" class="ltx_para">
<p id="S3.SS3.SSS1.p1.4" class="ltx_p">We present the impact of the dimensionality <math id="S3.SS3.SSS1.p1.1.m1.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S3.SS3.SSS1.p1.1.m1.1a"><mi id="S3.SS3.SSS1.p1.1.m1.1.1" xref="S3.SS3.SSS1.p1.1.m1.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p1.1.m1.1b"><ci id="S3.SS3.SSS1.p1.1.m1.1.1.cmml" xref="S3.SS3.SSS1.p1.1.m1.1.1">ğ‘›</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.p1.1.m1.1c">n</annotation></semantics></math> of query/passage representations in Fig.Â <a href="#S3.F3.sf1" title="In Figure 3 â€£ 3.3.2. Impact of negative sampling â€£ 3.3. Additional Results â€£ 3. Experiments â€£ Passage Retrieval for Outside-Knowledge Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3(a)</span></a>. We observe that a larger projection size always leads to better performance, although the performance gain seems to be insignificant for LXMERT after <math id="S3.SS3.SSS1.p1.2.m2.1" class="ltx_Math" alttext="n=256" display="inline"><semantics id="S3.SS3.SSS1.p1.2.m2.1a"><mrow id="S3.SS3.SSS1.p1.2.m2.1.1" xref="S3.SS3.SSS1.p1.2.m2.1.1.cmml"><mi id="S3.SS3.SSS1.p1.2.m2.1.1.2" xref="S3.SS3.SSS1.p1.2.m2.1.1.2.cmml">n</mi><mo id="S3.SS3.SSS1.p1.2.m2.1.1.1" xref="S3.SS3.SSS1.p1.2.m2.1.1.1.cmml">=</mo><mn id="S3.SS3.SSS1.p1.2.m2.1.1.3" xref="S3.SS3.SSS1.p1.2.m2.1.1.3.cmml">256</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p1.2.m2.1b"><apply id="S3.SS3.SSS1.p1.2.m2.1.1.cmml" xref="S3.SS3.SSS1.p1.2.m2.1.1"><eq id="S3.SS3.SSS1.p1.2.m2.1.1.1.cmml" xref="S3.SS3.SSS1.p1.2.m2.1.1.1"></eq><ci id="S3.SS3.SSS1.p1.2.m2.1.1.2.cmml" xref="S3.SS3.SSS1.p1.2.m2.1.1.2">ğ‘›</ci><cn type="integer" id="S3.SS3.SSS1.p1.2.m2.1.1.3.cmml" xref="S3.SS3.SSS1.p1.2.m2.1.1.3">256</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.p1.2.m2.1c">n=256</annotation></semantics></math>. We set <math id="S3.SS3.SSS1.p1.3.m3.1" class="ltx_Math" alttext="n=768" display="inline"><semantics id="S3.SS3.SSS1.p1.3.m3.1a"><mrow id="S3.SS3.SSS1.p1.3.m3.1.1" xref="S3.SS3.SSS1.p1.3.m3.1.1.cmml"><mi id="S3.SS3.SSS1.p1.3.m3.1.1.2" xref="S3.SS3.SSS1.p1.3.m3.1.1.2.cmml">n</mi><mo id="S3.SS3.SSS1.p1.3.m3.1.1.1" xref="S3.SS3.SSS1.p1.3.m3.1.1.1.cmml">=</mo><mn id="S3.SS3.SSS1.p1.3.m3.1.1.3" xref="S3.SS3.SSS1.p1.3.m3.1.1.3.cmml">768</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p1.3.m3.1b"><apply id="S3.SS3.SSS1.p1.3.m3.1.1.cmml" xref="S3.SS3.SSS1.p1.3.m3.1.1"><eq id="S3.SS3.SSS1.p1.3.m3.1.1.1.cmml" xref="S3.SS3.SSS1.p1.3.m3.1.1.1"></eq><ci id="S3.SS3.SSS1.p1.3.m3.1.1.2.cmml" xref="S3.SS3.SSS1.p1.3.m3.1.1.2">ğ‘›</ci><cn type="integer" id="S3.SS3.SSS1.p1.3.m3.1.1.3.cmml" xref="S3.SS3.SSS1.p1.3.m3.1.1.3">768</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.p1.3.m3.1c">n=768</annotation></semantics></math> as reported in Sec.<a href="#S3.SS1.SSS4" title="3.1.4. Implementation Details â€£ 3.1. Experimental Setup â€£ 3. Experiments â€£ Passage Retrieval for Outside-Knowledge Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.1.4</span></a> since it gives the best performance for both Dense-LXMERT and Dense-BERT. When working with a much larger collection than ours (ours has 11 million passages), one might want to use <math id="S3.SS3.SSS1.p1.4.m4.1" class="ltx_Math" alttext="n=256" display="inline"><semantics id="S3.SS3.SSS1.p1.4.m4.1a"><mrow id="S3.SS3.SSS1.p1.4.m4.1.1" xref="S3.SS3.SSS1.p1.4.m4.1.1.cmml"><mi id="S3.SS3.SSS1.p1.4.m4.1.1.2" xref="S3.SS3.SSS1.p1.4.m4.1.1.2.cmml">n</mi><mo id="S3.SS3.SSS1.p1.4.m4.1.1.1" xref="S3.SS3.SSS1.p1.4.m4.1.1.1.cmml">=</mo><mn id="S3.SS3.SSS1.p1.4.m4.1.1.3" xref="S3.SS3.SSS1.p1.4.m4.1.1.3.cmml">256</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p1.4.m4.1b"><apply id="S3.SS3.SSS1.p1.4.m4.1.1.cmml" xref="S3.SS3.SSS1.p1.4.m4.1.1"><eq id="S3.SS3.SSS1.p1.4.m4.1.1.1.cmml" xref="S3.SS3.SSS1.p1.4.m4.1.1.1"></eq><ci id="S3.SS3.SSS1.p1.4.m4.1.1.2.cmml" xref="S3.SS3.SSS1.p1.4.m4.1.1.2">ğ‘›</ci><cn type="integer" id="S3.SS3.SSS1.p1.4.m4.1.1.3.cmml" xref="S3.SS3.SSS1.p1.4.m4.1.1.3">256</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.p1.4.m4.1c">n=256</annotation></semantics></math> since it offers similar performance with less memory consumption.</p>
</div>
</section>
<section id="S3.SS3.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.3.2. </span><span id="S3.SS3.SSS2.1.1" class="ltx_text ltx_font_bold">Impact of negative sampling</span>
</h4>

<div id="S3.SS3.SSS2.p1" class="ltx_para">
<p id="S3.SS3.SSS2.p1.1" class="ltx_p">The desirable performance of dense retrieval is contingent upon the negative sampling strategy. We present the impact of different sampling methods described in Sec.Â <a href="#S2.SS3.SSS3" title="2.3.3. Training â€£ 2.3. Dense Retrieval â€£ 2. Passage Retrieval for OK-VQA â€£ Passage Retrieval for Outside-Knowledge Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.3.3</span></a> in Fig.Â <a href="#S3.F3.sf2" title="In Figure 3 â€£ 3.3.2. Impact of negative sampling â€£ 3.3. Additional Results â€£ 3. Experiments â€£ Passage Retrieval for Outside-Knowledge Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3(b)</span></a>. We observe that combining retrieved negatives with in-batch negatives dramatically improves the model performance, verifying the observations in <cite class="ltx_cite ltx_citemacro_citet">Karpukhin etÂ al. (<a href="#bib.bib16" title="" class="ltx_ref">2020</a>)</cite> for multi-modal queries.
Also, different choices of in-batch negatives (R-Neg+IB-Neg/Pos/All) give a similar performance for LXMERT, indicating that coinciding questions in the same batch should not be a concern for our batch size and data size reported in Sec.Â <a href="#S3.SS1" title="3.1. Experimental Setup â€£ 3. Experiments â€£ Passage Retrieval for Outside-Knowledge Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.1</span></a>.</p>
</div>
<div id="S3.SS3.SSS2.p2" class="ltx_para">
<p id="S3.SS3.SSS2.p2.1" class="ltx_p">Both analyses show that Dense-BERT is more demanding on larger model capacity (larger projection size) and more negative samples. We speculate that BERT is overfitting the patterns in the training data since it lacks important visual clues for matching. In comparison, Dense-LXMERT is less sensitive to reasonably-chosen projection sizes and negative sampling strategies because it can learn matching signals from both language and vision clues.</p>
</div>
<figure id="S3.F3" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S3.F3.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2105.03938/assets/x3.png" id="S3.F3.sf1.g1" class="ltx_graphics ltx_img_landscape" width="461" height="319" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S3.F3.sf1.4.2.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S3.F3.sf1.2.1" class="ltx_text" style="font-size:90%;">Impact of projection size <math id="S3.F3.sf1.2.1.m1.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S3.F3.sf1.2.1.m1.1b"><mi id="S3.F3.sf1.2.1.m1.1.1" xref="S3.F3.sf1.2.1.m1.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.F3.sf1.2.1.m1.1c"><ci id="S3.F3.sf1.2.1.m1.1.1.cmml" xref="S3.F3.sf1.2.1.m1.1.1">ğ‘›</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.sf1.2.1.m1.1d">n</annotation></semantics></math>.</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S3.F3.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2105.03938/assets/x4.png" id="S3.F3.sf2.g1" class="ltx_graphics ltx_img_landscape" width="461" height="322" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S3.F3.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S3.F3.sf2.3.2" class="ltx_text" style="font-size:90%;">Impact of negative sampling.</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F3.2.1.1" class="ltx_text" style="font-size:90%;">Figure 3</span>. </span><span id="S3.F3.3.2" class="ltx_text" style="font-size:90%;">Additional results.</span></figcaption>
</figure>
</section>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4. </span>Conclusions and Future Work</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">We study passage retrieval for OK-VQA with sparse and dense retrieval and verify visual clues play an important role. We discover that captions are more informative than object names in sparse retrieval and CombMAX works well with object expansion while CombSUM and RRF are better for caption expansion.
We further show a dense retriever with a multi-modal query encoder can significantly outperform sparse retrieval with object expansion and even matches the performance of that with human-generated captions.
In the future, we will consider using automatic captions for sparse retrieval and study answer extraction to complete the QA pipeline.

</p>
</div>
<div class="ltx_acknowledgements">
<h6 class="ltx_title ltx_title_acknowledgements">Acknowledgements.</h6>
This work was supported in part by the Center for Intelligent Information Retrieval. Any opinions, findings and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect those of the sponsors.

</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Agrawal etÂ al. [2015]</span>
<span class="ltx_bibblock">
A.Â Agrawal, J.Â Lu, S.Â Antol, M.Â Mitchell, C.Â L. Zitnick, D.Â Parikh, and
D.Â Batra.

</span>
<span class="ltx_bibblock">VQA: Visual Question Answering.

</span>
<span class="ltx_bibblock"><em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">International Journal of Computer Vision</em>, 123:4â€“31,
2015.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Anderson etÂ al. [2018]</span>
<span class="ltx_bibblock">
P.Â Anderson, X.Â He, C.Â Buehler, D.Â Teney, M.Â Johnson, S.Â Gould, and L.Â Zhang.

</span>
<span class="ltx_bibblock">Bottom-up and top-down attention for image captioning and visual
question answering.

</span>
<span class="ltx_bibblock"><em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">2018 IEEE/CVF Conference on Computer Vision and Pattern
Recognition</em>, pages 6077â€“6086, 2018.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ben-younes etÂ al. [2017]</span>
<span class="ltx_bibblock">
H.Â Ben-younes, R.Â CadÃ¨ne, M.Â Cord, and N.Â Thome.

</span>
<span class="ltx_bibblock">MUTAN: Multimodal Tucker Fusion for Visual Question Answering.

</span>
<span class="ltx_bibblock">In <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">ICCV</em>, 2017.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Benham and Culpepper [2017]</span>
<span class="ltx_bibblock">
R.Â Benham and J.Â S. Culpepper.

</span>
<span class="ltx_bibblock">Risk-Reward Trade-offs in Rank Fusion.

</span>
<span class="ltx_bibblock"><em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 22nd Australasian Document Computing
Symposium</em>, 2017.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen etÂ al. [2017]</span>
<span class="ltx_bibblock">
D.Â Chen, A.Â Fisch, J.Â Weston, and A.Â Bordes.

</span>
<span class="ltx_bibblock">Reading Wikipedia to Answer Open-Domain Questions.

</span>
<span class="ltx_bibblock">In <em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">ACL</em>, 2017.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cormack etÂ al. [2009]</span>
<span class="ltx_bibblock">
G.Â V. Cormack, C.Â L.Â A. Clarke, and S.Â BÃ¼ttcher.

</span>
<span class="ltx_bibblock">Reciprocal rank fusion outperforms condorcet and individual rank
learning methods.

</span>
<span class="ltx_bibblock">In <em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">SIGIR</em>, 2009.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Deldjoo etÂ al. [2021]</span>
<span class="ltx_bibblock">
Y.Â Deldjoo, J.Â R. Trippas, and H.Â Zamani.

</span>
<span class="ltx_bibblock">Towards Multi-Modal Conversational Information Seeking.

</span>
<span class="ltx_bibblock">In <em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">SIGIR</em>, 2021.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Devlin etÂ al. [2019]</span>
<span class="ltx_bibblock">
J.Â Devlin, M.-W. Chang, K.Â Lee, and K.Â Toutanova.

</span>
<span class="ltx_bibblock">BERT: Pre-training of Deep Bidirectional Transformers for Language
Understanding.

</span>
<span class="ltx_bibblock">In <em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">NAACL-HLT</em>, 2019.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fox and Shaw [1993]</span>
<span class="ltx_bibblock">
E.Â A. Fox and J.Â A. Shaw.

</span>
<span class="ltx_bibblock">Combination of Multiple Searches.

</span>
<span class="ltx_bibblock">In <em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">TREC</em>, 1993.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fukui etÂ al. [2016]</span>
<span class="ltx_bibblock">
A.Â Fukui, D.Â H. Park, D.Â Yang, A.Â Rohrbach, T.Â Darrell, and M.Â Rohrbach.

</span>
<span class="ltx_bibblock">Multimodal Compact Bilinear Pooling for Visual Question Answering
and Visual Grounding.

</span>
<span class="ltx_bibblock">In <em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">EMNLP</em>, 2016.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">GardÃ¨res etÂ al. [2020]</span>
<span class="ltx_bibblock">
F.Â GardÃ¨res, M.Â Ziaeefard, B.Â Abeloos, and F.Â LÃ©cuÃ©.

</span>
<span class="ltx_bibblock">ConceptBert: Concept-Aware Representation for Visual Question
Answering.

</span>
<span class="ltx_bibblock">In <em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">EMNLP</em>, 2020.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Goyal etÂ al. [2017]</span>
<span class="ltx_bibblock">
Y.Â Goyal, T.Â Khot, D.Â Summers-Stay, D.Â Batra, and D.Â Parikh.

</span>
<span class="ltx_bibblock">Making the V in VQA Matter: Elevating the Role of Image
Understanding in Visual Question Answering.

</span>
<span class="ltx_bibblock">In <em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">CVPR</em>, 2017.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Guu etÂ al. [2020]</span>
<span class="ltx_bibblock">
K.Â Guu, K.Â Lee, Z.Â Tung, P.Â Pasupat, and M.-W. Chang.

</span>
<span class="ltx_bibblock">REALM: Retrieval-Augmented Language Model Pre-Training.

</span>
<span class="ltx_bibblock"><em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">ArXiv</em>, abs/2002.08909, 2020.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hu etÂ al. [2018]</span>
<span class="ltx_bibblock">
M.Â Hu, Y.Â Peng, Z.Â Huang, X.Â Qiu, F.Â Wei, and M.Â Zhou.

</span>
<span class="ltx_bibblock">Reinforced Mnemonic Reader for Machine Reading Comprehension.

</span>
<span class="ltx_bibblock">In <em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">IJCAI</em>, 2018.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Johnson etÂ al. [2017]</span>
<span class="ltx_bibblock">
J.Â Johnson, M.Â Douze, and H.Â JÃ©gou.

</span>
<span class="ltx_bibblock">Billion-scale similarity search with GPUs.

</span>
<span class="ltx_bibblock"><em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">ArXiv</em>, 2017.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Karpukhin etÂ al. [2020]</span>
<span class="ltx_bibblock">
V.Â Karpukhin, B.Â OÄŸuz, S.Â Min, P.Â Lewis, L.Â Y. Wu, S.Â Edunov, D.Â Chen, and
W.Â tau Yih.

</span>
<span class="ltx_bibblock">Dense Passage Retrieval for Open-Domain Question Answering.

</span>
<span class="ltx_bibblock">In <em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">EMNLP</em>, 2020.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kim etÂ al. [2018]</span>
<span class="ltx_bibblock">
J.Â Kim, J.Â Jun, and B.Â Zhang.

</span>
<span class="ltx_bibblock">Bilinear Attention Networks.

</span>
<span class="ltx_bibblock">In <em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">NeurIPS</em>, 2018.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Krishna etÂ al. [2016]</span>
<span class="ltx_bibblock">
R.Â Krishna, Y.Â Zhu, O.Â Groth, J.Â Johnson, K.Â Hata, J.Â Kravitz, S.Â Chen,
Y.Â Kalantidis, L.Â Li, D.Â A. Shamma, M.Â S. Bernstein, and L.Â Fei-Fei.

</span>
<span class="ltx_bibblock">Visual genome: Connecting language and vision using crowdsourced
dense image annotations.

</span>
<span class="ltx_bibblock"><em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">International Journal of Computer Vision</em>, 123:32â€“73, 2016.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lee [1997]</span>
<span class="ltx_bibblock">
J.Â H. Lee.

</span>
<span class="ltx_bibblock">Analyses of Multiple Evidence Combination.

</span>
<span class="ltx_bibblock">In <em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">SIGIR</em>, 1997.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lee etÂ al. [2019]</span>
<span class="ltx_bibblock">
K.Â Lee, M.-W. Chang, and K.Â Toutanova.

</span>
<span class="ltx_bibblock">Latent Retrieval for Weakly Supervised Open Domain Question
Answering.

</span>
<span class="ltx_bibblock">In <em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">ACL</em>, 2019.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li etÂ al. [2017]</span>
<span class="ltx_bibblock">
G.Â Li, H.Â Su, and W.Â Zhu.

</span>
<span class="ltx_bibblock">Incorporating external knowledge to answer open-domain visual
questions with dynamic memory networks.

</span>
<span class="ltx_bibblock"><em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">ArXiv</em>, abs/1712.00733, 2017.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lien etÂ al. [2020]</span>
<span class="ltx_bibblock">
Y.-C. Lien, H.Â Zamani, and W.Â B. Croft.

</span>
<span class="ltx_bibblock">Recipe Retrieval with Visual Query of Ingredients.

</span>
<span class="ltx_bibblock">In <em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">SIGIR</em>, 2020.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lu etÂ al. [2016]</span>
<span class="ltx_bibblock">
J.Â Lu, J.Â Yang, D.Â Batra, and D.Â Parikh.

</span>
<span class="ltx_bibblock">Hierarchical Question-Image Co-Attention for Visual Question
Answering.

</span>
<span class="ltx_bibblock">In <em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">NIPS</em>, 2016.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Luan etÂ al. [2020]</span>
<span class="ltx_bibblock">
Y.Â Luan, J.Â Eisenstein, K.Â Toutanova, and M.Â Collins.

</span>
<span class="ltx_bibblock">Sparse, Dense, and Attentional Representations for Text Retrieval.

</span>
<span class="ltx_bibblock"><em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">ArXiv</em>, abs/2005.00181, 2020.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Malinowski and Fritz [2014]</span>
<span class="ltx_bibblock">
M.Â Malinowski and M.Â Fritz.

</span>
<span class="ltx_bibblock">A Multi-World Approach to Question Answering about Real-World Scenes
based on Uncertain Input.

</span>
<span class="ltx_bibblock">In <em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">NIPS</em>, 2014.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Malinowski etÂ al. [2015]</span>
<span class="ltx_bibblock">
M.Â Malinowski, M.Â Rohrbach, and M.Â Fritz.

</span>
<span class="ltx_bibblock">Ask Your Neurons: A Neural-Based Approach to Answering Questions
about Images.

</span>
<span class="ltx_bibblock">In <em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">ICCV</em>, pages 1â€“9, 2015.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Marino etÂ al. [2019]</span>
<span class="ltx_bibblock">
K.Â Marino, M.Â Rastegari, A.Â Farhadi, and R.Â Mottaghi.

</span>
<span class="ltx_bibblock">OK-VQA: A Visual Question Answering Benchmark Requiring External
Knowledge.

</span>
<span class="ltx_bibblock">In <em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">CVPR</em>, 2019.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Narasimhan and Schwing [2018]</span>
<span class="ltx_bibblock">
M.Â Narasimhan and A.Â G. Schwing.

</span>
<span class="ltx_bibblock">Straight to the Facts: Learning Knowledge Base Retrieval for Factual
Visual Question Answering.

</span>
<span class="ltx_bibblock">In <em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">ECCV</em>, 2018.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Narasimhan etÂ al. [2018]</span>
<span class="ltx_bibblock">
M.Â Narasimhan, S.Â Lazebnik, and A.Â G. Schwing.

</span>
<span class="ltx_bibblock">Out of the Box: Reasoning with Graph Convolution Nets for Factual
Visual Question Answering.

</span>
<span class="ltx_bibblock">In <em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">NeurIPS</em>, 2018.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Qu etÂ al. [2020a]</span>
<span class="ltx_bibblock">
C.Â Qu, L.Â Yang, C.Â Chen, M.Â Qiu, W.Â B. Croft, and M.Â Iyyer.

</span>
<span class="ltx_bibblock">Open-Retrieval Conversational Question Answering.

</span>
<span class="ltx_bibblock">In <em id="bib.bib30.1.1" class="ltx_emph ltx_font_italic">SIGIR</em>, 2020a.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Qu etÂ al. [2021]</span>
<span class="ltx_bibblock">
C.Â Qu, L.Â Yang, C.Â Chen, W.Â Croft, K.Â Krishna, and M.Â Iyyer.

</span>
<span class="ltx_bibblock">Weakly-Supervised Open-Retrieval Conversational Question Answering.

</span>
<span class="ltx_bibblock">In <em id="bib.bib31.1.1" class="ltx_emph ltx_font_italic">ECIR</em>, 2021.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Qu etÂ al. [2020b]</span>
<span class="ltx_bibblock">
Y.Â Qu, Y.Â Ding, J.Â Liu, K.Â Liu, R.Â Ren, X.Â Zhao, D.Â Dong, H.Â Wu, and H.Â Wang.

</span>
<span class="ltx_bibblock">RocketQA: An Optimized Training Approach to Dense Passage Retrieval
for Open-Domain Question Answering.

</span>
<span class="ltx_bibblock"><em id="bib.bib32.1.1" class="ltx_emph ltx_font_italic">ArXiv</em>, abs/2010.08191, 2020b.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rajpurkar etÂ al. [2016]</span>
<span class="ltx_bibblock">
P.Â Rajpurkar, J.Â Zhang, K.Â Lopyrev, and P.Â Liang.

</span>
<span class="ltx_bibblock">SQuAD: 100, 000+ Questions for Machine Comprehension of Text.

</span>
<span class="ltx_bibblock">In <em id="bib.bib33.1.1" class="ltx_emph ltx_font_italic">EMNLP</em>, 2016.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ren etÂ al. [2015]</span>
<span class="ltx_bibblock">
S.Â Ren, K.Â He, R.Â B. Girshick, and J.Â Sun.

</span>
<span class="ltx_bibblock">Faster R-CNN: Towards Real-Time Object Detection with Region
Proposal Networks.

</span>
<span class="ltx_bibblock"><em id="bib.bib34.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Pattern Analysis and Machine
Intelligence</em>, 39:1137â€“1149, 2015.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tan and Bansal [2019]</span>
<span class="ltx_bibblock">
H.Â H. Tan and M.Â Bansal.

</span>
<span class="ltx_bibblock">LXMERT: Learning Cross-Modality Encoder Representations from
Transformers.

</span>
<span class="ltx_bibblock">In <em id="bib.bib35.1.1" class="ltx_emph ltx_font_italic">EMNLP/IJCNLP</em>, 2019.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vaswani etÂ al. [2017]</span>
<span class="ltx_bibblock">
A.Â Vaswani, N.Â Shazeer, N.Â Parmar, J.Â Uszkoreit, L.Â Jones, A.Â N. Gomez,
L.Â Kaiser, and I.Â Polosukhin.

</span>
<span class="ltx_bibblock">Attention Is All You Need.

</span>
<span class="ltx_bibblock">In <em id="bib.bib36.1.1" class="ltx_emph ltx_font_italic">NIPS</em>, 2017.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Voorhees and Tice [1999]</span>
<span class="ltx_bibblock">
E.Â M. Voorhees and D.Â M. Tice.

</span>
<span class="ltx_bibblock">The TREC-8 Question Answering Track Evaluation.

</span>
<span class="ltx_bibblock">In <em id="bib.bib37.1.1" class="ltx_emph ltx_font_italic">TREC</em>, 1999.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang etÂ al. [2017]</span>
<span class="ltx_bibblock">
P.Â Wang, Q.Â Wu, C.Â Shen, A.Â Dick, and A.Â V.Â D. Hengel.

</span>
<span class="ltx_bibblock">Explicit Knowledge-based Reasoning for Visual Question Answering.

</span>
<span class="ltx_bibblock">In <em id="bib.bib38.1.1" class="ltx_emph ltx_font_italic">IJCAI</em>, 2017.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang etÂ al. [2018]</span>
<span class="ltx_bibblock">
P.Â Wang, Q.Â Wu, C.Â Shen, A.Â Dick, and A.Â vanÂ den Hengel.

</span>
<span class="ltx_bibblock">FVQA: Fact-Based Visual Question Answering.

</span>
<span class="ltx_bibblock"><em id="bib.bib39.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Pattern Analysis and Machine
Intelligence</em>, 40:2413â€“2427, 2018.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu etÂ al. [2016]</span>
<span class="ltx_bibblock">
Q.Â Wu, P.Â Wang, C.Â Shen, A.Â Dick, and A.Â V.Â D. Hengel.

</span>
<span class="ltx_bibblock">Ask Me Anything: Free-Form Visual Question Answering Based on
Knowledge from External Sources.

</span>
<span class="ltx_bibblock">In <em id="bib.bib40.1.1" class="ltx_emph ltx_font_italic">CVPR</em>, 2016.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xiong etÂ al. [2016]</span>
<span class="ltx_bibblock">
C.Â Xiong, S.Â Merity, and R.Â Socher.

</span>
<span class="ltx_bibblock">Dynamic Memory Networks for Visual and Textual Question Answering.

</span>
<span class="ltx_bibblock">In <em id="bib.bib41.1.1" class="ltx_emph ltx_font_italic">ICML</em>, 2016.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xiong etÂ al. [2020a]</span>
<span class="ltx_bibblock">
L.Â Xiong, C.Â Xiong, Y.Â Li, K.-F. Tang, J.Â Liu, P.Â Bennett, J.Â Ahmed, and
A.Â Overwijk.

</span>
<span class="ltx_bibblock">Approximate Nearest Neighbor Negative Contrastive Learning for Dense
Text Retrieval.

</span>
<span class="ltx_bibblock"><em id="bib.bib42.1.1" class="ltx_emph ltx_font_italic">ArXiv</em>, abs/2007.00808, 2020a.

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xiong etÂ al. [2020b]</span>
<span class="ltx_bibblock">
W.Â Xiong, X.Â Li, S.Â Iyer, J.Â Du, P.Â Lewis, W.Â Y. Wang, Y.Â Mehdad, W.Â tau Yih,
S.Â Riedel, D.Â Kiela, and B.Â Ouguz.

</span>
<span class="ltx_bibblock">Answering Complex Open-Domain Questions with Multi-Hop Dense
Retrieval.

</span>
<span class="ltx_bibblock"><em id="bib.bib43.1.1" class="ltx_emph ltx_font_italic">ArXiv</em>, abs/2009.12756, 2020b.

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang etÂ al. [2020]</span>
<span class="ltx_bibblock">
L.Â Yang, M.Â Qiu, C.Â Qu, C.Â Chen, J.Â Guo, Y.Â Zhang, W.Â B. Croft, and H.Â Chen.

</span>
<span class="ltx_bibblock">IART: Intent-Aware Response Ranking with Transformers in
Information-Seeking Conversation Systems.

</span>
<span class="ltx_bibblock">In <em id="bib.bib44.1.1" class="ltx_emph ltx_font_italic">WWW</em>, 2020.

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu etÂ al. [2020]</span>
<span class="ltx_bibblock">
J.Â Yu, Z.Â Zhu, Y.Â Wang, W.Â Zhang, Y.Â Hu, and J.Â Tan.

</span>
<span class="ltx_bibblock">Cross-modal Knowledge Reasoning for Knowledge-based Visual Question
Answering.

</span>
<span class="ltx_bibblock"><em id="bib.bib45.1.1" class="ltx_emph ltx_font_italic">Pattern Recognition</em>, 108:107563, 2020.

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu etÂ al. [2015]</span>
<span class="ltx_bibblock">
L.Â Yu, E.Â Park, A.Â Berg, and T.Â Berg.

</span>
<span class="ltx_bibblock">Visual Madlibs: Fill in the Blank Description Generation and
Question Answering.

</span>
<span class="ltx_bibblock">In <em id="bib.bib46.1.1" class="ltx_emph ltx_font_italic">ICCV</em>, 2015.

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhu etÂ al. [2016]</span>
<span class="ltx_bibblock">
Y.Â Zhu, O.Â Groth, M.Â S. Bernstein, and L.Â Fei-Fei.

</span>
<span class="ltx_bibblock">Visual7W: Grounded Question Answering in Images.

</span>
<span class="ltx_bibblock">In <em id="bib.bib47.1.1" class="ltx_emph ltx_font_italic">CVPR</em>, 2016.

</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhu etÂ al. [2020]</span>
<span class="ltx_bibblock">
Z.Â Zhu, J.Â Yu, Y.Â Wang, Y.Â Sun, Y.Â Hu, and Q.Â Wu.

</span>
<span class="ltx_bibblock">Mucko: Multi-Layer Cross-Modal Knowledge Reasoning for Fact-based
Visual Question Answering.

</span>
<span class="ltx_bibblock">In <em id="bib.bib48.1.1" class="ltx_emph ltx_font_italic">IJCAI</em>, 2020.

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2105.03937" class="ar5iv-nav-button ar5iv-nav-button-prev">â—„</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2105.03938" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2105.03938">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2105.03938" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2105.03939" class="ar5iv-nav-button ar5iv-nav-button-next">â–º</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Fri Mar  8 00:11:28 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "Ã—";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
