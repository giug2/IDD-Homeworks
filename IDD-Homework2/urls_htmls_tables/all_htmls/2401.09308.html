<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2401.09308] Can Synthetic Data Boost the Training of Deep Acoustic Vehicle Counting Networks?</title><meta property="og:description" content="In the design of traffic monitoring solutions for optimizing the urban mobility infrastructure, acoustic vehicle counting models have received attention due to their cost effectiveness and energy efficiency.
Although d…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Can Synthetic Data Boost the Training of Deep Acoustic Vehicle Counting Networks?">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Can Synthetic Data Boost the Training of Deep Acoustic Vehicle Counting Networks?">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2401.09308">

<!--Generated on Tue Feb 27 08:58:16 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Can Synthetic Data Boost the Training of Deep Acoustic Vehicle Counting Networks?</h1>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id4.4" class="ltx_p">In the design of traffic monitoring solutions for optimizing the urban mobility infrastructure, acoustic vehicle counting models have received attention due to their cost effectiveness and energy efficiency.
Although deep learning has proven effective for visual traffic monitoring, its use has not been thoroughly investigated in the audio domain, likely due to real-world data scarcity.
In this work, we propose a novel approach to acoustic vehicle counting by developing: i) a traffic noise simulation framework to synthesize realistic vehicle pass-by events; ii) a strategy to mix synthetic and real data to train a deep-learning model for traffic counting. The proposed system is capable of simultaneously counting cars and commercial vehicles driving on a two-lane road, and identifying their direction of travel under moderate traffic density conditions.
With only 24 hours of labeled real-world traffic noise, we are able to improve counting accuracy on real-world data from <math id="id1.1.m1.1" class="ltx_Math" alttext="63\%" display="inline"><semantics id="id1.1.m1.1a"><mrow id="id1.1.m1.1.1" xref="id1.1.m1.1.1.cmml"><mn id="id1.1.m1.1.1.2" xref="id1.1.m1.1.1.2.cmml">63</mn><mo id="id1.1.m1.1.1.1" xref="id1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="id1.1.m1.1b"><apply id="id1.1.m1.1.1.cmml" xref="id1.1.m1.1.1"><csymbol cd="latexml" id="id1.1.m1.1.1.1.cmml" xref="id1.1.m1.1.1.1">percent</csymbol><cn type="integer" id="id1.1.m1.1.1.2.cmml" xref="id1.1.m1.1.1.2">63</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="id1.1.m1.1c">63\%</annotation></semantics></math> to <math id="id2.2.m2.1" class="ltx_Math" alttext="88\%" display="inline"><semantics id="id2.2.m2.1a"><mrow id="id2.2.m2.1.1" xref="id2.2.m2.1.1.cmml"><mn id="id2.2.m2.1.1.2" xref="id2.2.m2.1.1.2.cmml">88</mn><mo id="id2.2.m2.1.1.1" xref="id2.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="id2.2.m2.1b"><apply id="id2.2.m2.1.1.cmml" xref="id2.2.m2.1.1"><csymbol cd="latexml" id="id2.2.m2.1.1.1.cmml" xref="id2.2.m2.1.1.1">percent</csymbol><cn type="integer" id="id2.2.m2.1.1.2.cmml" xref="id2.2.m2.1.1.2">88</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="id2.2.m2.1c">88\%</annotation></semantics></math> for cars and from <math id="id3.3.m3.1" class="ltx_Math" alttext="86\%" display="inline"><semantics id="id3.3.m3.1a"><mrow id="id3.3.m3.1.1" xref="id3.3.m3.1.1.cmml"><mn id="id3.3.m3.1.1.2" xref="id3.3.m3.1.1.2.cmml">86</mn><mo id="id3.3.m3.1.1.1" xref="id3.3.m3.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="id3.3.m3.1b"><apply id="id3.3.m3.1.1.cmml" xref="id3.3.m3.1.1"><csymbol cd="latexml" id="id3.3.m3.1.1.1.cmml" xref="id3.3.m3.1.1.1">percent</csymbol><cn type="integer" id="id3.3.m3.1.1.2.cmml" xref="id3.3.m3.1.1.2">86</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="id3.3.m3.1c">86\%</annotation></semantics></math> to <math id="id4.4.m4.1" class="ltx_Math" alttext="94\%" display="inline"><semantics id="id4.4.m4.1a"><mrow id="id4.4.m4.1.1" xref="id4.4.m4.1.1.cmml"><mn id="id4.4.m4.1.1.2" xref="id4.4.m4.1.1.2.cmml">94</mn><mo id="id4.4.m4.1.1.1" xref="id4.4.m4.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="id4.4.m4.1b"><apply id="id4.4.m4.1.1.cmml" xref="id4.4.m4.1.1"><csymbol cd="latexml" id="id4.4.m4.1.1.1.cmml" xref="id4.4.m4.1.1.1">percent</csymbol><cn type="integer" id="id4.4.m4.1.1.2.cmml" xref="id4.4.m4.1.1.2">94</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="id4.4.m4.1c">94\%</annotation></semantics></math> for commercial vehicles.</p>
</div>
<div id="p1" class="ltx_para">
<p id="p1.1" class="ltx_p"><span id="p1.1.1" class="ltx_text ltx_font_bold ltx_font_italic">Index Terms<span id="p1.1.1.1" class="ltx_text ltx_font_upright">— </span></span>
acoustic vehicle counting, synthetic data generation, urban audio analysis</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">The development of smart cities relies on the deployment of sensors and devices in urban areas to collect data and efficiently monitor and manage public infrastructures <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>. Traffic monitoring systems are used to gather information on the usage of roadways, including estimates on the number, speed and type of vehicles passing by, to control the traffic volume or to detect anomalous conditions. Several different sensors are available for traffic monitoring, including intrusive systems embedded in the road, e.g. induction loops, vibration or magnetic sensors, non-intrusive systems mounted over or on the side of the road, e.g. radar, cameras, infrared or acoustic sensors, and off-road mobile devices, e.g. aircraft or satellites <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>, <a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>. Acoustic sensors, though not being the most common solution, provide several advantages compared to other devices: microphones are in fact low-cost and power efficient devices, not affected by low-visibility conditions.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Although the literature is still relatively limited, several approaches for acoustic vehicle detection <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>, <a href="#bib.bib5" title="" class="ltx_ref">5</a>, <a href="#bib.bib6" title="" class="ltx_ref">6</a>, <a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite> and counting <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a>, <a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite> have been proposed. These methods are mostly based on the analysis of audio signals captured using either a single microphone or a microphone array, rely either on traditional signal processing <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>, deep learning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite> or a combination of both <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>, and target multiple tasks. While the basic goal is the detection of passing vehicles, more advanced methods also aim at discriminating the type of vehicle (e.g. car, truck, motorbike, etc.), the direction of motion (e.g. left-to-right or right-to-left), and, eventually, its speed.
Even though data-driven approaches prove effective in sound detection tasks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>, their potential has not yet been thoroughly investigated in the context of acoustic vehicle counting (AVC). One reason can be identified in the scarcity of available datasets for this purpose: a few existing datasets <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>, <a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite> are of limited size, insufficient for training an end-to-end deep learning model, and usually contain single-channel recordings.
Collecting data is in fact a complex and expensive task that entails not only recording audio, but also collecting ground truth data using other sensor modalities, usually difficult to deploy, and developing synchronization strategies to align the collected audio and ground truth sensor(s) data.</p>
</div>
<figure id="S1.F1" class="ltx_figure">
<div id="S1.F1.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:411.9pt;height:78.3pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-20.3pt,3.9pt) scale(0.91021353991152,0.91021353991152) ;"><img src="/html/2401.09308/assets/x1.png" id="S1.F1.1.g1" class="ltx_graphics ltx_img_landscape" width="476" height="92" alt="Refer to caption">
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S1.F1.3.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Fig. 1</span>: </span><span id="S1.F1.4.2" class="ltx_text" style="font-size:90%;">The proposed CRNN architecture takes as input the raw signal from a 4-channel linear microphone array and computes in parallel: i) the Generalized Cross-Correlation with Phase Transform (GCC-Phat) between pairs of channels; ii) a Learnable Filterbank with Gabor filters. Two convolutional encoders followed by Time-Distributed Multi-Layer Perceptrons (TD-MLP) compute spatial and semantic features, respectively. The concatenated features are processed by a further TD-MLP layer, followed by a Gated Recurrent Unit (GRU) and a fully connected (FC) layer to regress the number of vehicles per type (car, CV) and per direction (left-to-right, right-to-left).</span></figcaption>
</figure>
<figure id="S1.F2" class="ltx_figure"><img src="/html/2401.09308/assets/x2.png" id="S1.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="348" height="88" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S1.F2.4.2.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Fig. 2</span>: </span><span id="S1.F2.2.1" class="ltx_text" style="font-size:90%;">Distribution of recorded events in four target categories averaged over <math id="S1.F2.2.1.m1.1.1.m1.3" class="ltx_markedasmath" alttext="60\text{\,}\mathrm{s}\text{/}" display="inline"><semantics id="S1.F2.2.1.m1.1.1.m1.3b"><mrow id="S1.F2.2.1.m1.1.1.m1.3.3" xref="S1.F2.2.1.m1.1.1.m1.3.3.cmml"><mn id="S1.F2.2.1.m1.1.1.m1.1.1.1.1.1.1" xref="S1.F2.2.1.m1.1.1.m1.1.1.1.1.1.1.cmml">60</mn><mtext id="S1.F2.2.1.m1.1.1.m1.2.2.2.2.2.2" xref="S1.F2.2.1.m1.1.1.m1.2.2.2.2.2.2.cmml"> </mtext><mrow id="S1.F2.2.1.m1.1.1.m1.3.3.3.3.3.3" xref="S1.F2.2.1.m1.1.1.m1.3.3.3.3.3.3.cmml"><mi class="ltx_unit" mathvariant="normal" id="S1.F2.2.1.m1.1.1.m1.3.3.3.3.3.3.1.1.1.1.1.1" xref="S1.F2.2.1.m1.1.1.m1.3.3.3.3.3.3.1.1.1.1.1.1.cmml">s</mi><mtext id="S1.F2.2.1.m1.1.1.m1.3.3.3.3.3.3.2.2.2.2.2.2" xref="S1.F2.2.1.m1.1.1.m1.3.3.3.3.3.3.2.2.2.2.2.2.cmml">/</mtext><mi id="S1.F2.2.1.m1.1.1.m1.3.3.3.3.3.3.3.3.3.3.3.3" xref="S1.F2.2.1.m1.1.1.m1.3.3.3.3.3.3.3.3.3.3.3.3.cmml"></mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S1.F2.2.1.m1.1.1.m1.3c"><apply id="S1.F2.2.1.m1.1.1.m1.3.3.cmml" xref="S1.F2.2.1.m1.1.1.m1.3.3"><csymbol cd="latexml" id="S1.F2.2.1.m1.1.1.m1.2.2.2.2.2.2.cmml" xref="S1.F2.2.1.m1.1.1.m1.2.2.2.2.2.2">times</csymbol><cn type="integer" id="S1.F2.2.1.m1.1.1.m1.1.1.1.1.1.1.cmml" xref="S1.F2.2.1.m1.1.1.m1.1.1.1.1.1.1">60</cn><apply id="S1.F2.2.1.m1.1.1.m1.3.3.3.3.3.3.cmml" xref="S1.F2.2.1.m1.1.1.m1.3.3.3.3.3.3"><csymbol cd="latexml" id="S1.F2.2.1.m1.1.1.m1.3.3.3.3.3.3.2.2.2.2.2.2.cmml" xref="S1.F2.2.1.m1.1.1.m1.3.3.3.3.3.3.2.2.2.2.2.2">divide</csymbol><csymbol cd="latexml" id="S1.F2.2.1.m1.1.1.m1.3.3.3.3.3.3.1.1.1.1.1.1.cmml" xref="S1.F2.2.1.m1.1.1.m1.3.3.3.3.3.3.1.1.1.1.1.1">second</csymbol><csymbol cd="latexml" id="S1.F2.2.1.m1.1.1.m1.3.3.3.3.3.3.3.3.3.3.3.3.cmml" xref="S1.F2.2.1.m1.1.1.m1.3.3.3.3.3.3.3.3.3.3.3.3">absent</csymbol></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.F2.2.1.m1.1.1.m1.3d">60\text{\,}\mathrm{s}\text{/}</annotation></semantics></math> audio segments.</span></figcaption>
</figure>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">In this paper we address AVC using a 4-channel linear microphone array deployed on the side of a two-lane road. Our goal is to identify pass-by events in moderate traffic density conditions - i.e. up to 1000 vehicles per hour, per lane - with vehicles driving from left to right in the close lane and in the opposite direction in the far lane. For each detected event, the vehicle must be classified as <em id="S1.p3.1.1" class="ltx_emph ltx_font_italic">car</em> or <em id="S1.p3.1.2" class="ltx_emph ltx_font_italic">commercial vehicle</em> (CV) - heavy vehicles such as trucks and buses - and the direction of transit must be identified.
In this work, we introduce a convolutional recurrent neural network (CRNN) for traffic counting, with a training procedure based on the usage of synthetic data generated using the <em id="S1.p3.1.3" class="ltx_emph ltx_font_italic">pyroadacoustics</em> simulator <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>. This method drastically reduces the amount of required real-world data to achieve high traffic counting accuracy. In summary, we first define a strategy to synthesize acoustic traffic noise, then pre-train the model based on the synthetically generated dataset, and finally perform fine-tuning on a limited amount of real-world data. Evaluation on a separate dataset collected by Bosch on a German municipal road shows that the proposed system is capable of learning to count traffic effectively with as little as <math id="S1.p3.1.m1.1.1.m1.3" class="ltx_markedasmath" alttext="24\text{\,}\mathrm{h}\text{/}" display="inline"><semantics id="S1.p3.1.m1.1.1.m1.3a"><mrow id="S1.p3.1.m1.1.1.m1.3.3" xref="S1.p3.1.m1.1.1.m1.3.3.cmml"><mn id="S1.p3.1.m1.1.1.m1.1.1.1.1.1.1" xref="S1.p3.1.m1.1.1.m1.1.1.1.1.1.1.cmml">24</mn><mtext id="S1.p3.1.m1.1.1.m1.2.2.2.2.2.2" xref="S1.p3.1.m1.1.1.m1.2.2.2.2.2.2.cmml"> </mtext><mrow id="S1.p3.1.m1.1.1.m1.3.3.3.3.3.3" xref="S1.p3.1.m1.1.1.m1.3.3.3.3.3.3.cmml"><mi class="ltx_unit" mathvariant="normal" id="S1.p3.1.m1.1.1.m1.3.3.3.3.3.3.1.1.1.1.1.1" xref="S1.p3.1.m1.1.1.m1.3.3.3.3.3.3.1.1.1.1.1.1.cmml">h</mi><mtext id="S1.p3.1.m1.1.1.m1.3.3.3.3.3.3.2.2.2.2.2.2" xref="S1.p3.1.m1.1.1.m1.3.3.3.3.3.3.2.2.2.2.2.2.cmml">/</mtext><mi id="S1.p3.1.m1.1.1.m1.3.3.3.3.3.3.3.3.3.3.3.3" xref="S1.p3.1.m1.1.1.m1.3.3.3.3.3.3.3.3.3.3.3.3.cmml"></mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S1.p3.1.m1.1.1.m1.3b"><apply id="S1.p3.1.m1.1.1.m1.3.3.cmml" xref="S1.p3.1.m1.1.1.m1.3.3"><csymbol cd="latexml" id="S1.p3.1.m1.1.1.m1.2.2.2.2.2.2.cmml" xref="S1.p3.1.m1.1.1.m1.2.2.2.2.2.2">times</csymbol><cn type="integer" id="S1.p3.1.m1.1.1.m1.1.1.1.1.1.1.cmml" xref="S1.p3.1.m1.1.1.m1.1.1.1.1.1.1">24</cn><apply id="S1.p3.1.m1.1.1.m1.3.3.3.3.3.3.cmml" xref="S1.p3.1.m1.1.1.m1.3.3.3.3.3.3"><csymbol cd="latexml" id="S1.p3.1.m1.1.1.m1.3.3.3.3.3.3.2.2.2.2.2.2.cmml" xref="S1.p3.1.m1.1.1.m1.3.3.3.3.3.3.2.2.2.2.2.2">divide</csymbol><csymbol cd="latexml" id="S1.p3.1.m1.1.1.m1.3.3.3.3.3.3.1.1.1.1.1.1.cmml" xref="S1.p3.1.m1.1.1.m1.3.3.3.3.3.3.1.1.1.1.1.1">hour</csymbol><csymbol cd="latexml" id="S1.p3.1.m1.1.1.m1.3.3.3.3.3.3.3.3.3.3.3.3.cmml" xref="S1.p3.1.m1.1.1.m1.3.3.3.3.3.3.3.3.3.3.3.3">absent</csymbol></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.p3.1.m1.1.1.m1.3c">24\text{\,}\mathrm{h}\text{/}</annotation></semantics></math> of labeled real-world data. <span id="S1.p3.1.4" class="ltx_text" style="color:#000000;">Source code for this paper is available online<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note"><span id="footnote1.1.1.1" class="ltx_text" style="color:#000000;">1</span></span><span id="footnote1.4" class="ltx_text" style="color:#000000;">[Coming soon] </span><span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self" style="color:#000000;">https://github.com/boschresearch/acoustic-traffic-simulation-counting</span></span></span></span></span>.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Methodology</h2>

<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Data Description</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.4" class="ltx_p">A traffic noise dataset is provided by Bosch for the design and assessment of the AVC model. Data was recorded in the span of 11 days (264 total hours of recording) over few months, on a two-lane municipal road with a fixed recording setup of a 4-channel linear microphone array. The array is located at the side of the road, with parallel orientation with respect to the traffic direction, at a lateral distance of <math id="S2.SS1.p1.1.m1.1.1.m1.3" class="ltx_markedasmath" alttext="4\text{\,}\mathrm{m}\text{/}" display="inline"><semantics id="S2.SS1.p1.1.m1.1.1.m1.3a"><mrow id="S2.SS1.p1.1.m1.1.1.m1.3.3" xref="S2.SS1.p1.1.m1.1.1.m1.3.3.cmml"><mn id="S2.SS1.p1.1.m1.1.1.m1.1.1.1.1.1.1" xref="S2.SS1.p1.1.m1.1.1.m1.1.1.1.1.1.1.cmml">4</mn><mtext id="S2.SS1.p1.1.m1.1.1.m1.2.2.2.2.2.2" xref="S2.SS1.p1.1.m1.1.1.m1.2.2.2.2.2.2.cmml"> </mtext><mrow id="S2.SS1.p1.1.m1.1.1.m1.3.3.3.3.3.3" xref="S2.SS1.p1.1.m1.1.1.m1.3.3.3.3.3.3.cmml"><mi class="ltx_unit" mathvariant="normal" id="S2.SS1.p1.1.m1.1.1.m1.3.3.3.3.3.3.1.1.1.1.1.1" xref="S2.SS1.p1.1.m1.1.1.m1.3.3.3.3.3.3.1.1.1.1.1.1.cmml">m</mi><mtext id="S2.SS1.p1.1.m1.1.1.m1.3.3.3.3.3.3.2.2.2.2.2.2" xref="S2.SS1.p1.1.m1.1.1.m1.3.3.3.3.3.3.2.2.2.2.2.2.cmml">/</mtext><mi id="S2.SS1.p1.1.m1.1.1.m1.3.3.3.3.3.3.3.3.3.3.3.3" xref="S2.SS1.p1.1.m1.1.1.m1.3.3.3.3.3.3.3.3.3.3.3.3.cmml"></mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.1.m1.1.1.m1.3b"><apply id="S2.SS1.p1.1.m1.1.1.m1.3.3.cmml" xref="S2.SS1.p1.1.m1.1.1.m1.3.3"><csymbol cd="latexml" id="S2.SS1.p1.1.m1.1.1.m1.2.2.2.2.2.2.cmml" xref="S2.SS1.p1.1.m1.1.1.m1.2.2.2.2.2.2">times</csymbol><cn type="integer" id="S2.SS1.p1.1.m1.1.1.m1.1.1.1.1.1.1.cmml" xref="S2.SS1.p1.1.m1.1.1.m1.1.1.1.1.1.1">4</cn><apply id="S2.SS1.p1.1.m1.1.1.m1.3.3.3.3.3.3.cmml" xref="S2.SS1.p1.1.m1.1.1.m1.3.3.3.3.3.3"><csymbol cd="latexml" id="S2.SS1.p1.1.m1.1.1.m1.3.3.3.3.3.3.2.2.2.2.2.2.cmml" xref="S2.SS1.p1.1.m1.1.1.m1.3.3.3.3.3.3.2.2.2.2.2.2">divide</csymbol><csymbol cd="latexml" id="S2.SS1.p1.1.m1.1.1.m1.3.3.3.3.3.3.1.1.1.1.1.1.cmml" xref="S2.SS1.p1.1.m1.1.1.m1.3.3.3.3.3.3.1.1.1.1.1.1">meter</csymbol><csymbol cd="latexml" id="S2.SS1.p1.1.m1.1.1.m1.3.3.3.3.3.3.3.3.3.3.3.3.cmml" xref="S2.SS1.p1.1.m1.1.1.m1.3.3.3.3.3.3.3.3.3.3.3.3">absent</csymbol></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.1.m1.1.1.m1.3c">4\text{\,}\mathrm{m}\text{/}</annotation></semantics></math> and a height of <math id="S2.SS1.p1.2.m2.1.1.m1.3" class="ltx_markedasmath" alttext="2.7\text{\,}\mathrm{m}\text{/}" display="inline"><semantics id="S2.SS1.p1.2.m2.1.1.m1.3a"><mrow id="S2.SS1.p1.2.m2.1.1.m1.3.3" xref="S2.SS1.p1.2.m2.1.1.m1.3.3.cmml"><mn id="S2.SS1.p1.2.m2.1.1.m1.1.1.1.1.1.1" xref="S2.SS1.p1.2.m2.1.1.m1.1.1.1.1.1.1.cmml">2.7</mn><mtext id="S2.SS1.p1.2.m2.1.1.m1.2.2.2.2.2.2" xref="S2.SS1.p1.2.m2.1.1.m1.2.2.2.2.2.2.cmml"> </mtext><mrow id="S2.SS1.p1.2.m2.1.1.m1.3.3.3.3.3.3" xref="S2.SS1.p1.2.m2.1.1.m1.3.3.3.3.3.3.cmml"><mi class="ltx_unit" mathvariant="normal" id="S2.SS1.p1.2.m2.1.1.m1.3.3.3.3.3.3.1.1.1.1.1.1" xref="S2.SS1.p1.2.m2.1.1.m1.3.3.3.3.3.3.1.1.1.1.1.1.cmml">m</mi><mtext id="S2.SS1.p1.2.m2.1.1.m1.3.3.3.3.3.3.2.2.2.2.2.2" xref="S2.SS1.p1.2.m2.1.1.m1.3.3.3.3.3.3.2.2.2.2.2.2.cmml">/</mtext><mi id="S2.SS1.p1.2.m2.1.1.m1.3.3.3.3.3.3.3.3.3.3.3.3" xref="S2.SS1.p1.2.m2.1.1.m1.3.3.3.3.3.3.3.3.3.3.3.3.cmml"></mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.2.m2.1.1.m1.3b"><apply id="S2.SS1.p1.2.m2.1.1.m1.3.3.cmml" xref="S2.SS1.p1.2.m2.1.1.m1.3.3"><csymbol cd="latexml" id="S2.SS1.p1.2.m2.1.1.m1.2.2.2.2.2.2.cmml" xref="S2.SS1.p1.2.m2.1.1.m1.2.2.2.2.2.2">times</csymbol><cn type="float" id="S2.SS1.p1.2.m2.1.1.m1.1.1.1.1.1.1.cmml" xref="S2.SS1.p1.2.m2.1.1.m1.1.1.1.1.1.1">2.7</cn><apply id="S2.SS1.p1.2.m2.1.1.m1.3.3.3.3.3.3.cmml" xref="S2.SS1.p1.2.m2.1.1.m1.3.3.3.3.3.3"><csymbol cd="latexml" id="S2.SS1.p1.2.m2.1.1.m1.3.3.3.3.3.3.2.2.2.2.2.2.cmml" xref="S2.SS1.p1.2.m2.1.1.m1.3.3.3.3.3.3.2.2.2.2.2.2">divide</csymbol><csymbol cd="latexml" id="S2.SS1.p1.2.m2.1.1.m1.3.3.3.3.3.3.1.1.1.1.1.1.cmml" xref="S2.SS1.p1.2.m2.1.1.m1.3.3.3.3.3.3.1.1.1.1.1.1">meter</csymbol><csymbol cd="latexml" id="S2.SS1.p1.2.m2.1.1.m1.3.3.3.3.3.3.3.3.3.3.3.3.cmml" xref="S2.SS1.p1.2.m2.1.1.m1.3.3.3.3.3.3.3.3.3.3.3.3">absent</csymbol></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.2.m2.1.1.m1.3c">2.7\text{\,}\mathrm{m}\text{/}</annotation></semantics></math>. The microphones are uniformly spaced, with an array aperture of <math id="S2.SS1.p1.3.m3.1.1.m1.3" class="ltx_markedasmath" alttext="24\text{\,}\mathrm{cm}\text{/}" display="inline"><semantics id="S2.SS1.p1.3.m3.1.1.m1.3a"><mrow id="S2.SS1.p1.3.m3.1.1.m1.3.3" xref="S2.SS1.p1.3.m3.1.1.m1.3.3.cmml"><mn id="S2.SS1.p1.3.m3.1.1.m1.1.1.1.1.1.1" xref="S2.SS1.p1.3.m3.1.1.m1.1.1.1.1.1.1.cmml">24</mn><mtext id="S2.SS1.p1.3.m3.1.1.m1.2.2.2.2.2.2" xref="S2.SS1.p1.3.m3.1.1.m1.2.2.2.2.2.2.cmml"> </mtext><mrow id="S2.SS1.p1.3.m3.1.1.m1.3.3.3.3.3.3" xref="S2.SS1.p1.3.m3.1.1.m1.3.3.3.3.3.3.cmml"><mi class="ltx_unit" id="S2.SS1.p1.3.m3.1.1.m1.3.3.3.3.3.3.1.1.1.1.1.1" xref="S2.SS1.p1.3.m3.1.1.m1.3.3.3.3.3.3.1.1.1.1.1.1.cmml">cm</mi><mtext id="S2.SS1.p1.3.m3.1.1.m1.3.3.3.3.3.3.2.2.2.2.2.2" xref="S2.SS1.p1.3.m3.1.1.m1.3.3.3.3.3.3.2.2.2.2.2.2.cmml">/</mtext><mi id="S2.SS1.p1.3.m3.1.1.m1.3.3.3.3.3.3.3.3.3.3.3.3" xref="S2.SS1.p1.3.m3.1.1.m1.3.3.3.3.3.3.3.3.3.3.3.3.cmml"></mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.3.m3.1.1.m1.3b"><apply id="S2.SS1.p1.3.m3.1.1.m1.3.3.cmml" xref="S2.SS1.p1.3.m3.1.1.m1.3.3"><csymbol cd="latexml" id="S2.SS1.p1.3.m3.1.1.m1.2.2.2.2.2.2.cmml" xref="S2.SS1.p1.3.m3.1.1.m1.2.2.2.2.2.2">times</csymbol><cn type="integer" id="S2.SS1.p1.3.m3.1.1.m1.1.1.1.1.1.1.cmml" xref="S2.SS1.p1.3.m3.1.1.m1.1.1.1.1.1.1">24</cn><apply id="S2.SS1.p1.3.m3.1.1.m1.3.3.3.3.3.3.cmml" xref="S2.SS1.p1.3.m3.1.1.m1.3.3.3.3.3.3"><csymbol cd="latexml" id="S2.SS1.p1.3.m3.1.1.m1.3.3.3.3.3.3.2.2.2.2.2.2.cmml" xref="S2.SS1.p1.3.m3.1.1.m1.3.3.3.3.3.3.2.2.2.2.2.2">divide</csymbol><csymbol cd="latexml" id="S2.SS1.p1.3.m3.1.1.m1.3.3.3.3.3.3.1.1.1.1.1.1.cmml" xref="S2.SS1.p1.3.m3.1.1.m1.3.3.3.3.3.3.1.1.1.1.1.1">centimeter</csymbol><csymbol cd="latexml" id="S2.SS1.p1.3.m3.1.1.m1.3.3.3.3.3.3.3.3.3.3.3.3.cmml" xref="S2.SS1.p1.3.m3.1.1.m1.3.3.3.3.3.3.3.3.3.3.3.3">absent</csymbol></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.3.m3.1.1.m1.3c">24\text{\,}\mathrm{cm}\text{/}</annotation></semantics></math>. The road has two lanes in which vehicles travel in opposite directions, passing from left to right (l2r) in the closest lane, and from right to left (r2l) in the farthest. The traffic flow has a maximum density of 1000 vehicles per hour, per lane, and includes various vehicle types such as: cars, commercial vehicles (i.e. buses and trucks), motorbikes and bicycles; with a maximum speed of <math id="S2.SS1.p1.4.m4.1.1.m1.3" class="ltx_markedasmath" alttext="100\text{\,}\mathrm{km}\text{/}\mathrm{h}" display="inline"><semantics id="S2.SS1.p1.4.m4.1.1.m1.3a"><mrow id="S2.SS1.p1.4.m4.1.1.m1.3.3" xref="S2.SS1.p1.4.m4.1.1.m1.3.3.cmml"><mn id="S2.SS1.p1.4.m4.1.1.m1.1.1.1.1.1.1" xref="S2.SS1.p1.4.m4.1.1.m1.1.1.1.1.1.1.cmml">100</mn><mtext id="S2.SS1.p1.4.m4.1.1.m1.2.2.2.2.2.2" xref="S2.SS1.p1.4.m4.1.1.m1.2.2.2.2.2.2.cmml"> </mtext><mrow id="S2.SS1.p1.4.m4.1.1.m1.3.3.3.3.3.3" xref="S2.SS1.p1.4.m4.1.1.m1.3.3.3.3.3.3.cmml"><mi class="ltx_unit" id="S2.SS1.p1.4.m4.1.1.m1.3.3.3.3.3.3.1.1.1.1.1.1" xref="S2.SS1.p1.4.m4.1.1.m1.3.3.3.3.3.3.1.1.1.1.1.1.cmml">km</mi><mtext id="S2.SS1.p1.4.m4.1.1.m1.3.3.3.3.3.3.2.2.2.2.2.2" xref="S2.SS1.p1.4.m4.1.1.m1.3.3.3.3.3.3.2.2.2.2.2.2.cmml">/</mtext><mi class="ltx_unit" mathvariant="normal" id="S2.SS1.p1.4.m4.1.1.m1.3.3.3.3.3.3.3.3.3.3.3.3" xref="S2.SS1.p1.4.m4.1.1.m1.3.3.3.3.3.3.3.3.3.3.3.3.cmml">h</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.4.m4.1.1.m1.3b"><apply id="S2.SS1.p1.4.m4.1.1.m1.3.3.cmml" xref="S2.SS1.p1.4.m4.1.1.m1.3.3"><csymbol cd="latexml" id="S2.SS1.p1.4.m4.1.1.m1.2.2.2.2.2.2.cmml" xref="S2.SS1.p1.4.m4.1.1.m1.2.2.2.2.2.2">times</csymbol><cn type="integer" id="S2.SS1.p1.4.m4.1.1.m1.1.1.1.1.1.1.cmml" xref="S2.SS1.p1.4.m4.1.1.m1.1.1.1.1.1.1">100</cn><apply id="S2.SS1.p1.4.m4.1.1.m1.3.3.3.3.3.3.cmml" xref="S2.SS1.p1.4.m4.1.1.m1.3.3.3.3.3.3"><csymbol cd="latexml" id="S2.SS1.p1.4.m4.1.1.m1.3.3.3.3.3.3.2.2.2.2.2.2.cmml" xref="S2.SS1.p1.4.m4.1.1.m1.3.3.3.3.3.3.2.2.2.2.2.2">divide</csymbol><csymbol cd="latexml" id="S2.SS1.p1.4.m4.1.1.m1.3.3.3.3.3.3.1.1.1.1.1.1.cmml" xref="S2.SS1.p1.4.m4.1.1.m1.3.3.3.3.3.3.1.1.1.1.1.1">kilometer</csymbol><csymbol cd="latexml" id="S2.SS1.p1.4.m4.1.1.m1.3.3.3.3.3.3.3.3.3.3.3.3.cmml" xref="S2.SS1.p1.4.m4.1.1.m1.3.3.3.3.3.3.3.3.3.3.3.3">hour</csymbol></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.4.m4.1.1.m1.3c">100\text{\,}\mathrm{km}\text{/}\mathrm{h}</annotation></semantics></math>. <span id="S2.SS1.p1.4.1" class="ltx_text" style="color:#000000;">Overlapping pass-bys (in different lanes) occur in the dataset</span>.
Ground truth data containing pass-by instant, vehicle type and direction of motion, are gathered via induction coils for cars and CVs, that together represent the majority of road agents and thus have the strongest impact on the traffic distribution.
Fig. <a href="#S1.F2" title="Figure 2 ‣ 1 Introduction ‣ Can Synthetic Data Boost the Training of Deep Acoustic Vehicle Counting Networks?" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> shows the data distribution across the dataset for each of the four categories of interest (car-l2r, car-r2l, CV-l2r, CV-r2l).</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>CRNN Architecture</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">To identify the number of passing vehicles in these four categories, we use the convolutional recurrent neural network (CRNN) depicted in Fig. <a href="#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ Can Synthetic Data Boost the Training of Deep Acoustic Vehicle Counting Networks?" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. In the upper network branch, Generalized Cross-Correlation with Phase transform (GCC-Phat) features, <span id="S2.SS2.p1.1.1" class="ltx_text" style="color:#000000;">helpful to identify the direction of movement of the detected vehicles</span>, are provided as input to a convolutional encoder, that consists of two Conv2D layers with 32 filters each, followed by a Conv2D layer with 64 filters, each with kernel size (3,3) and a stride of 2 in both dimensions.</p>
</div>
<figure id="S2.F3" class="ltx_figure"><img src="/html/2401.09308/assets/x3.png" id="S2.F3.g1" class="ltx_graphics ltx_img_landscape" width="187" height="93" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S2.F3.5.2.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Fig. 3</span>: </span><span id="S2.F3.2.1" class="ltx_text" style="font-size:90%;">Test accuracy of models trained on an increasing amount of real-world data (<span id="S2.F3.2.1.1" class="ltx_text ltx_markedasmath">RW</span>).</span></figcaption>
</figure>
<figure id="S2.F4" class="ltx_figure"><img src="/html/2401.09308/assets/x4.png" id="S2.F4.g1" class="ltx_graphics ltx_img_landscape" width="187" height="93" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S2.F4.5.2.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Fig. 4</span>: </span><span id="S2.F4.2.1" class="ltx_text" style="font-size:90%;">Test accuracy of models pre-trained on synthetic data and then fine-tuned (<span id="S2.F4.2.1.1" class="ltx_text ltx_markedasmath">FT</span>) on an increasing amount of real-world data.</span></figcaption>
</figure>
<figure id="S2.F5" class="ltx_figure"><img src="/html/2401.09308/assets/x5.png" id="S2.F5.g1" class="ltx_graphics ltx_img_square" width="180" height="181" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S2.F5.2.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Fig. 5</span>: </span><span id="S2.F5.3.2" class="ltx_text" style="font-size:90%;">Average accuracy (marks) and accuracy ranges (whiskers) obtained using a model pre-trained on synthetic data and fine-tuned (FT) on an increasing amount of real-world data, and a model trained from scratch using same amount of real-world data (RW).</span></figcaption>
</figure>
<div id="S2.SS2.p2" class="ltx_para">
<p id="S2.SS2.p2.1" class="ltx_p">The output of the encoder is then passed through two time-distributed fully connected (FC) layers with 128 neurons each. Time-distributed layers are independently applied to each time frame of their input. In the lower branch, the spectrogram of the 4-channel audio signal<span id="S2.SS2.p2.1.1" class="ltx_text" style="color:#000000;">, useful to identify the type of vehicle (car or CV),</span> is filtered via a learnable Gabor filterbank <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite> with 96 channels, and then passed through a convolutional encoder and a time-distributed block similar to the upper branch. The output of the two branches is then concatenated and passed to another time-distributed block with three layers of 128 neurons each. Finally, a gated recurrent unit (GRU) with two layers of 128 neurons is used to model temporal dependencies. A FC layer with four neurons is then used as a regression output, providing the count of vehicles of the four categories of car-l2r, car-r2l, CV-l2r, CV-r2l. The model has a total of <math id="S2.SS2.p2.1.m1.1.1.m1.3" class="ltx_markedasmath" alttext="506\text{\,}\mathrm{K}\text{/}" display="inline"><semantics id="S2.SS2.p2.1.m1.1.1.m1.3a"><mrow id="S2.SS2.p2.1.m1.1.1.m1.3.3" xref="S2.SS2.p2.1.m1.1.1.m1.3.3.cmml"><mn id="S2.SS2.p2.1.m1.1.1.m1.1.1.1.1.1.1" xref="S2.SS2.p2.1.m1.1.1.m1.1.1.1.1.1.1.cmml">506</mn><mtext id="S2.SS2.p2.1.m1.1.1.m1.2.2.2.2.2.2" xref="S2.SS2.p2.1.m1.1.1.m1.2.2.2.2.2.2.cmml"> </mtext><mrow id="S2.SS2.p2.1.m1.1.1.m1.3.3.3.3.3.3" xref="S2.SS2.p2.1.m1.1.1.m1.3.3.3.3.3.3.cmml"><mi class="ltx_unit" mathvariant="normal" id="S2.SS2.p2.1.m1.1.1.m1.3.3.3.3.3.3.1.1.1.1.1.1" xref="S2.SS2.p2.1.m1.1.1.m1.3.3.3.3.3.3.1.1.1.1.1.1.cmml">K</mi><mtext id="S2.SS2.p2.1.m1.1.1.m1.3.3.3.3.3.3.2.2.2.2.2.2" xref="S2.SS2.p2.1.m1.1.1.m1.3.3.3.3.3.3.2.2.2.2.2.2.cmml">/</mtext><mi id="S2.SS2.p2.1.m1.1.1.m1.3.3.3.3.3.3.3.3.3.3.3.3" xref="S2.SS2.p2.1.m1.1.1.m1.3.3.3.3.3.3.3.3.3.3.3.3.cmml"></mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p2.1.m1.1.1.m1.3b"><apply id="S2.SS2.p2.1.m1.1.1.m1.3.3.cmml" xref="S2.SS2.p2.1.m1.1.1.m1.3.3"><csymbol cd="latexml" id="S2.SS2.p2.1.m1.1.1.m1.2.2.2.2.2.2.cmml" xref="S2.SS2.p2.1.m1.1.1.m1.2.2.2.2.2.2">times</csymbol><cn type="integer" id="S2.SS2.p2.1.m1.1.1.m1.1.1.1.1.1.1.cmml" xref="S2.SS2.p2.1.m1.1.1.m1.1.1.1.1.1.1">506</cn><apply id="S2.SS2.p2.1.m1.1.1.m1.3.3.3.3.3.3.cmml" xref="S2.SS2.p2.1.m1.1.1.m1.3.3.3.3.3.3"><csymbol cd="latexml" id="S2.SS2.p2.1.m1.1.1.m1.3.3.3.3.3.3.2.2.2.2.2.2.cmml" xref="S2.SS2.p2.1.m1.1.1.m1.3.3.3.3.3.3.2.2.2.2.2.2">divide</csymbol><csymbol cd="latexml" id="S2.SS2.p2.1.m1.1.1.m1.3.3.3.3.3.3.1.1.1.1.1.1.cmml" xref="S2.SS2.p2.1.m1.1.1.m1.3.3.3.3.3.3.1.1.1.1.1.1">kelvin</csymbol><csymbol cd="latexml" id="S2.SS2.p2.1.m1.1.1.m1.3.3.3.3.3.3.3.3.3.3.3.3.cmml" xref="S2.SS2.p2.1.m1.1.1.m1.3.3.3.3.3.3.3.3.3.3.3.3">absent</csymbol></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p2.1.m1.1.1.m1.3c">506\text{\,}\mathrm{K}\text{/}</annotation></semantics></math> trainable parameters.</p>
</div>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Synthetic Data Generation</h3>

<div id="S2.SS3.p1" class="ltx_para">
<p id="S2.SS3.p1.9" class="ltx_p">The main challenge of deep learning models is the large amount of data required to train them. To ease this requirement, we propose a training strategy based on the use of synthetic data. The data generation system relies on the open source<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span><span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://github.com/steDamiano/pyroadacoustics</span> </span></span></span> <em id="S2.SS3.p1.9.1" class="ltx_emph ltx_font_italic">pyroadacoustics</em> simulator <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>, designed to simulate the audio produced by a source moving on a road - including direct sound, reflection from the asphalt, air absorption and Doppler effect - and received by a set of static omnidirectional microphones with arbitrary array geometry. First, we simulate individual pass-bys defining a rectilinear source trajectory, based on speed and direction of travel, to obtain a <math id="S2.SS3.p1.1.m1.1.1.m1.3" class="ltx_markedasmath" alttext="30\text{\,}\mathrm{s}\text{/}" display="inline"><semantics id="S2.SS3.p1.1.m1.1.1.m1.3a"><mrow id="S2.SS3.p1.1.m1.1.1.m1.3.3" xref="S2.SS3.p1.1.m1.1.1.m1.3.3.cmml"><mn id="S2.SS3.p1.1.m1.1.1.m1.1.1.1.1.1.1" xref="S2.SS3.p1.1.m1.1.1.m1.1.1.1.1.1.1.cmml">30</mn><mtext id="S2.SS3.p1.1.m1.1.1.m1.2.2.2.2.2.2" xref="S2.SS3.p1.1.m1.1.1.m1.2.2.2.2.2.2.cmml"> </mtext><mrow id="S2.SS3.p1.1.m1.1.1.m1.3.3.3.3.3.3" xref="S2.SS3.p1.1.m1.1.1.m1.3.3.3.3.3.3.cmml"><mi class="ltx_unit" mathvariant="normal" id="S2.SS3.p1.1.m1.1.1.m1.3.3.3.3.3.3.1.1.1.1.1.1" xref="S2.SS3.p1.1.m1.1.1.m1.3.3.3.3.3.3.1.1.1.1.1.1.cmml">s</mi><mtext id="S2.SS3.p1.1.m1.1.1.m1.3.3.3.3.3.3.2.2.2.2.2.2" xref="S2.SS3.p1.1.m1.1.1.m1.3.3.3.3.3.3.2.2.2.2.2.2.cmml">/</mtext><mi id="S2.SS3.p1.1.m1.1.1.m1.3.3.3.3.3.3.3.3.3.3.3.3" xref="S2.SS3.p1.1.m1.1.1.m1.3.3.3.3.3.3.3.3.3.3.3.3.cmml"></mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p1.1.m1.1.1.m1.3b"><apply id="S2.SS3.p1.1.m1.1.1.m1.3.3.cmml" xref="S2.SS3.p1.1.m1.1.1.m1.3.3"><csymbol cd="latexml" id="S2.SS3.p1.1.m1.1.1.m1.2.2.2.2.2.2.cmml" xref="S2.SS3.p1.1.m1.1.1.m1.2.2.2.2.2.2">times</csymbol><cn type="integer" id="S2.SS3.p1.1.m1.1.1.m1.1.1.1.1.1.1.cmml" xref="S2.SS3.p1.1.m1.1.1.m1.1.1.1.1.1.1">30</cn><apply id="S2.SS3.p1.1.m1.1.1.m1.3.3.3.3.3.3.cmml" xref="S2.SS3.p1.1.m1.1.1.m1.3.3.3.3.3.3"><csymbol cd="latexml" id="S2.SS3.p1.1.m1.1.1.m1.3.3.3.3.3.3.2.2.2.2.2.2.cmml" xref="S2.SS3.p1.1.m1.1.1.m1.3.3.3.3.3.3.2.2.2.2.2.2">divide</csymbol><csymbol cd="latexml" id="S2.SS3.p1.1.m1.1.1.m1.3.3.3.3.3.3.1.1.1.1.1.1.cmml" xref="S2.SS3.p1.1.m1.1.1.m1.3.3.3.3.3.3.1.1.1.1.1.1">second</csymbol><csymbol cd="latexml" id="S2.SS3.p1.1.m1.1.1.m1.3.3.3.3.3.3.3.3.3.3.3.3.cmml" xref="S2.SS3.p1.1.m1.1.1.m1.3.3.3.3.3.3.3.3.3.3.3.3">absent</csymbol></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p1.1.m1.1.1.m1.3c">30\text{\,}\mathrm{s}\text{/}</annotation></semantics></math>-long simulation.
Since the simulation emulates the real-world dataset, and there are no traffic lights, crossroads or turns close to the array location, the speed of the vehicles is assumed to be constant during the pass-by for simulation purpose.
Then, we synthetically generate source signals according to the Harmonoise model <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>, which models a passing vehicle by superimposing two vertically-stacked point sources, containing a mixture of road/tire interaction noise and engine noise.
The lower source (LS), located at a height of <math id="S2.SS3.p1.2.m2.1.1.m1.3" class="ltx_markedasmath" alttext="1\text{\,}\mathrm{cm}\text{/}" display="inline"><semantics id="S2.SS3.p1.2.m2.1.1.m1.3a"><mrow id="S2.SS3.p1.2.m2.1.1.m1.3.3" xref="S2.SS3.p1.2.m2.1.1.m1.3.3.cmml"><mn id="S2.SS3.p1.2.m2.1.1.m1.1.1.1.1.1.1" xref="S2.SS3.p1.2.m2.1.1.m1.1.1.1.1.1.1.cmml">1</mn><mtext id="S2.SS3.p1.2.m2.1.1.m1.2.2.2.2.2.2" xref="S2.SS3.p1.2.m2.1.1.m1.2.2.2.2.2.2.cmml"> </mtext><mrow id="S2.SS3.p1.2.m2.1.1.m1.3.3.3.3.3.3" xref="S2.SS3.p1.2.m2.1.1.m1.3.3.3.3.3.3.cmml"><mi class="ltx_unit" id="S2.SS3.p1.2.m2.1.1.m1.3.3.3.3.3.3.1.1.1.1.1.1" xref="S2.SS3.p1.2.m2.1.1.m1.3.3.3.3.3.3.1.1.1.1.1.1.cmml">cm</mi><mtext id="S2.SS3.p1.2.m2.1.1.m1.3.3.3.3.3.3.2.2.2.2.2.2" xref="S2.SS3.p1.2.m2.1.1.m1.3.3.3.3.3.3.2.2.2.2.2.2.cmml">/</mtext><mi id="S2.SS3.p1.2.m2.1.1.m1.3.3.3.3.3.3.3.3.3.3.3.3" xref="S2.SS3.p1.2.m2.1.1.m1.3.3.3.3.3.3.3.3.3.3.3.3.cmml"></mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p1.2.m2.1.1.m1.3b"><apply id="S2.SS3.p1.2.m2.1.1.m1.3.3.cmml" xref="S2.SS3.p1.2.m2.1.1.m1.3.3"><csymbol cd="latexml" id="S2.SS3.p1.2.m2.1.1.m1.2.2.2.2.2.2.cmml" xref="S2.SS3.p1.2.m2.1.1.m1.2.2.2.2.2.2">times</csymbol><cn type="integer" id="S2.SS3.p1.2.m2.1.1.m1.1.1.1.1.1.1.cmml" xref="S2.SS3.p1.2.m2.1.1.m1.1.1.1.1.1.1">1</cn><apply id="S2.SS3.p1.2.m2.1.1.m1.3.3.3.3.3.3.cmml" xref="S2.SS3.p1.2.m2.1.1.m1.3.3.3.3.3.3"><csymbol cd="latexml" id="S2.SS3.p1.2.m2.1.1.m1.3.3.3.3.3.3.2.2.2.2.2.2.cmml" xref="S2.SS3.p1.2.m2.1.1.m1.3.3.3.3.3.3.2.2.2.2.2.2">divide</csymbol><csymbol cd="latexml" id="S2.SS3.p1.2.m2.1.1.m1.3.3.3.3.3.3.1.1.1.1.1.1.cmml" xref="S2.SS3.p1.2.m2.1.1.m1.3.3.3.3.3.3.1.1.1.1.1.1">centimeter</csymbol><csymbol cd="latexml" id="S2.SS3.p1.2.m2.1.1.m1.3.3.3.3.3.3.3.3.3.3.3.3.cmml" xref="S2.SS3.p1.2.m2.1.1.m1.3.3.3.3.3.3.3.3.3.3.3.3">absent</csymbol></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p1.2.m2.1.1.m1.3c">1\text{\,}\mathrm{cm}\text{/}</annotation></semantics></math>, emits <math id="S2.SS3.p1.3.m3.1" class="ltx_Math" alttext="80\%" display="inline"><semantics id="S2.SS3.p1.3.m3.1a"><mrow id="S2.SS3.p1.3.m3.1.1" xref="S2.SS3.p1.3.m3.1.1.cmml"><mn id="S2.SS3.p1.3.m3.1.1.2" xref="S2.SS3.p1.3.m3.1.1.2.cmml">80</mn><mo id="S2.SS3.p1.3.m3.1.1.1" xref="S2.SS3.p1.3.m3.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p1.3.m3.1b"><apply id="S2.SS3.p1.3.m3.1.1.cmml" xref="S2.SS3.p1.3.m3.1.1"><csymbol cd="latexml" id="S2.SS3.p1.3.m3.1.1.1.cmml" xref="S2.SS3.p1.3.m3.1.1.1">percent</csymbol><cn type="integer" id="S2.SS3.p1.3.m3.1.1.2.cmml" xref="S2.SS3.p1.3.m3.1.1.2">80</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p1.3.m3.1c">80\%</annotation></semantics></math> of the total power of the road/tire interaction noise, and <math id="S2.SS3.p1.4.m4.1" class="ltx_Math" alttext="20\%" display="inline"><semantics id="S2.SS3.p1.4.m4.1a"><mrow id="S2.SS3.p1.4.m4.1.1" xref="S2.SS3.p1.4.m4.1.1.cmml"><mn id="S2.SS3.p1.4.m4.1.1.2" xref="S2.SS3.p1.4.m4.1.1.2.cmml">20</mn><mo id="S2.SS3.p1.4.m4.1.1.1" xref="S2.SS3.p1.4.m4.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p1.4.m4.1b"><apply id="S2.SS3.p1.4.m4.1.1.cmml" xref="S2.SS3.p1.4.m4.1.1"><csymbol cd="latexml" id="S2.SS3.p1.4.m4.1.1.1.cmml" xref="S2.SS3.p1.4.m4.1.1.1">percent</csymbol><cn type="integer" id="S2.SS3.p1.4.m4.1.1.2.cmml" xref="S2.SS3.p1.4.m4.1.1.2">20</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p1.4.m4.1c">20\%</annotation></semantics></math> of the total power of engine noise. The higher source (HS), located at a height of <math id="S2.SS3.p1.5.m5.1.1.m1.3" class="ltx_markedasmath" alttext="30\text{\,}\mathrm{cm}\text{/}" display="inline"><semantics id="S2.SS3.p1.5.m5.1.1.m1.3a"><mrow id="S2.SS3.p1.5.m5.1.1.m1.3.3" xref="S2.SS3.p1.5.m5.1.1.m1.3.3.cmml"><mn id="S2.SS3.p1.5.m5.1.1.m1.1.1.1.1.1.1" xref="S2.SS3.p1.5.m5.1.1.m1.1.1.1.1.1.1.cmml">30</mn><mtext id="S2.SS3.p1.5.m5.1.1.m1.2.2.2.2.2.2" xref="S2.SS3.p1.5.m5.1.1.m1.2.2.2.2.2.2.cmml"> </mtext><mrow id="S2.SS3.p1.5.m5.1.1.m1.3.3.3.3.3.3" xref="S2.SS3.p1.5.m5.1.1.m1.3.3.3.3.3.3.cmml"><mi class="ltx_unit" id="S2.SS3.p1.5.m5.1.1.m1.3.3.3.3.3.3.1.1.1.1.1.1" xref="S2.SS3.p1.5.m5.1.1.m1.3.3.3.3.3.3.1.1.1.1.1.1.cmml">cm</mi><mtext id="S2.SS3.p1.5.m5.1.1.m1.3.3.3.3.3.3.2.2.2.2.2.2" xref="S2.SS3.p1.5.m5.1.1.m1.3.3.3.3.3.3.2.2.2.2.2.2.cmml">/</mtext><mi id="S2.SS3.p1.5.m5.1.1.m1.3.3.3.3.3.3.3.3.3.3.3.3" xref="S2.SS3.p1.5.m5.1.1.m1.3.3.3.3.3.3.3.3.3.3.3.3.cmml"></mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p1.5.m5.1.1.m1.3b"><apply id="S2.SS3.p1.5.m5.1.1.m1.3.3.cmml" xref="S2.SS3.p1.5.m5.1.1.m1.3.3"><csymbol cd="latexml" id="S2.SS3.p1.5.m5.1.1.m1.2.2.2.2.2.2.cmml" xref="S2.SS3.p1.5.m5.1.1.m1.2.2.2.2.2.2">times</csymbol><cn type="integer" id="S2.SS3.p1.5.m5.1.1.m1.1.1.1.1.1.1.cmml" xref="S2.SS3.p1.5.m5.1.1.m1.1.1.1.1.1.1">30</cn><apply id="S2.SS3.p1.5.m5.1.1.m1.3.3.3.3.3.3.cmml" xref="S2.SS3.p1.5.m5.1.1.m1.3.3.3.3.3.3"><csymbol cd="latexml" id="S2.SS3.p1.5.m5.1.1.m1.3.3.3.3.3.3.2.2.2.2.2.2.cmml" xref="S2.SS3.p1.5.m5.1.1.m1.3.3.3.3.3.3.2.2.2.2.2.2">divide</csymbol><csymbol cd="latexml" id="S2.SS3.p1.5.m5.1.1.m1.3.3.3.3.3.3.1.1.1.1.1.1.cmml" xref="S2.SS3.p1.5.m5.1.1.m1.3.3.3.3.3.3.1.1.1.1.1.1">centimeter</csymbol><csymbol cd="latexml" id="S2.SS3.p1.5.m5.1.1.m1.3.3.3.3.3.3.3.3.3.3.3.3.cmml" xref="S2.SS3.p1.5.m5.1.1.m1.3.3.3.3.3.3.3.3.3.3.3.3">absent</csymbol></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p1.5.m5.1.1.m1.3c">30\text{\,}\mathrm{cm}\text{/}</annotation></semantics></math> for cars, and <math id="S2.SS3.p1.6.m6.1.1.m1.3" class="ltx_markedasmath" alttext="75\text{\,}\mathrm{cm}\text{/}" display="inline"><semantics id="S2.SS3.p1.6.m6.1.1.m1.3a"><mrow id="S2.SS3.p1.6.m6.1.1.m1.3.3" xref="S2.SS3.p1.6.m6.1.1.m1.3.3.cmml"><mn id="S2.SS3.p1.6.m6.1.1.m1.1.1.1.1.1.1" xref="S2.SS3.p1.6.m6.1.1.m1.1.1.1.1.1.1.cmml">75</mn><mtext id="S2.SS3.p1.6.m6.1.1.m1.2.2.2.2.2.2" xref="S2.SS3.p1.6.m6.1.1.m1.2.2.2.2.2.2.cmml"> </mtext><mrow id="S2.SS3.p1.6.m6.1.1.m1.3.3.3.3.3.3" xref="S2.SS3.p1.6.m6.1.1.m1.3.3.3.3.3.3.cmml"><mi class="ltx_unit" id="S2.SS3.p1.6.m6.1.1.m1.3.3.3.3.3.3.1.1.1.1.1.1" xref="S2.SS3.p1.6.m6.1.1.m1.3.3.3.3.3.3.1.1.1.1.1.1.cmml">cm</mi><mtext id="S2.SS3.p1.6.m6.1.1.m1.3.3.3.3.3.3.2.2.2.2.2.2" xref="S2.SS3.p1.6.m6.1.1.m1.3.3.3.3.3.3.2.2.2.2.2.2.cmml">/</mtext><mi id="S2.SS3.p1.6.m6.1.1.m1.3.3.3.3.3.3.3.3.3.3.3.3" xref="S2.SS3.p1.6.m6.1.1.m1.3.3.3.3.3.3.3.3.3.3.3.3.cmml"></mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p1.6.m6.1.1.m1.3b"><apply id="S2.SS3.p1.6.m6.1.1.m1.3.3.cmml" xref="S2.SS3.p1.6.m6.1.1.m1.3.3"><csymbol cd="latexml" id="S2.SS3.p1.6.m6.1.1.m1.2.2.2.2.2.2.cmml" xref="S2.SS3.p1.6.m6.1.1.m1.2.2.2.2.2.2">times</csymbol><cn type="integer" id="S2.SS3.p1.6.m6.1.1.m1.1.1.1.1.1.1.cmml" xref="S2.SS3.p1.6.m6.1.1.m1.1.1.1.1.1.1">75</cn><apply id="S2.SS3.p1.6.m6.1.1.m1.3.3.3.3.3.3.cmml" xref="S2.SS3.p1.6.m6.1.1.m1.3.3.3.3.3.3"><csymbol cd="latexml" id="S2.SS3.p1.6.m6.1.1.m1.3.3.3.3.3.3.2.2.2.2.2.2.cmml" xref="S2.SS3.p1.6.m6.1.1.m1.3.3.3.3.3.3.2.2.2.2.2.2">divide</csymbol><csymbol cd="latexml" id="S2.SS3.p1.6.m6.1.1.m1.3.3.3.3.3.3.1.1.1.1.1.1.cmml" xref="S2.SS3.p1.6.m6.1.1.m1.3.3.3.3.3.3.1.1.1.1.1.1">centimeter</csymbol><csymbol cd="latexml" id="S2.SS3.p1.6.m6.1.1.m1.3.3.3.3.3.3.3.3.3.3.3.3.cmml" xref="S2.SS3.p1.6.m6.1.1.m1.3.3.3.3.3.3.3.3.3.3.3.3">absent</csymbol></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p1.6.m6.1.1.m1.3c">75\text{\,}\mathrm{cm}\text{/}</annotation></semantics></math> for commercial vehicles, emits <math id="S2.SS3.p1.7.m7.1" class="ltx_Math" alttext="20\%" display="inline"><semantics id="S2.SS3.p1.7.m7.1a"><mrow id="S2.SS3.p1.7.m7.1.1" xref="S2.SS3.p1.7.m7.1.1.cmml"><mn id="S2.SS3.p1.7.m7.1.1.2" xref="S2.SS3.p1.7.m7.1.1.2.cmml">20</mn><mo id="S2.SS3.p1.7.m7.1.1.1" xref="S2.SS3.p1.7.m7.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p1.7.m7.1b"><apply id="S2.SS3.p1.7.m7.1.1.cmml" xref="S2.SS3.p1.7.m7.1.1"><csymbol cd="latexml" id="S2.SS3.p1.7.m7.1.1.1.cmml" xref="S2.SS3.p1.7.m7.1.1.1">percent</csymbol><cn type="integer" id="S2.SS3.p1.7.m7.1.1.2.cmml" xref="S2.SS3.p1.7.m7.1.1.2">20</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p1.7.m7.1c">20\%</annotation></semantics></math> of the total power of the road/tire interaction noise, and <math id="S2.SS3.p1.8.m8.1" class="ltx_Math" alttext="80\%" display="inline"><semantics id="S2.SS3.p1.8.m8.1a"><mrow id="S2.SS3.p1.8.m8.1.1" xref="S2.SS3.p1.8.m8.1.1.cmml"><mn id="S2.SS3.p1.8.m8.1.1.2" xref="S2.SS3.p1.8.m8.1.1.2.cmml">80</mn><mo id="S2.SS3.p1.8.m8.1.1.1" xref="S2.SS3.p1.8.m8.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p1.8.m8.1b"><apply id="S2.SS3.p1.8.m8.1.1.cmml" xref="S2.SS3.p1.8.m8.1.1"><csymbol cd="latexml" id="S2.SS3.p1.8.m8.1.1.1.cmml" xref="S2.SS3.p1.8.m8.1.1.1">percent</csymbol><cn type="integer" id="S2.SS3.p1.8.m8.1.1.2.cmml" xref="S2.SS3.p1.8.m8.1.1.2">80</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p1.8.m8.1c">80\%</annotation></semantics></math> of the total power of engine noise.
The road/tire interaction noise signal is generated according to the Harmonoise model <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>, while the engine noise is produced using the Baldan model <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>, and normalized to match the Harmonoise signal power as described in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>. After creating the signal mixtures of the HS and LS, we use them as input to <em id="S2.SS3.p1.9.2" class="ltx_emph ltx_font_italic">pyroadacoustics</em> to simulate the pass-by events.
Finally, the simulated individual events are combined based on the traffic distribution of the real-world data to re-create the traffic flow, and the resulting signal is split into <math id="S2.SS3.p1.9.m9.1.1.m1.3" class="ltx_markedasmath" alttext="60\text{\,}\mathrm{s}\text{/}" display="inline"><semantics id="S2.SS3.p1.9.m9.1.1.m1.3a"><mrow id="S2.SS3.p1.9.m9.1.1.m1.3.3" xref="S2.SS3.p1.9.m9.1.1.m1.3.3.cmml"><mn id="S2.SS3.p1.9.m9.1.1.m1.1.1.1.1.1.1" xref="S2.SS3.p1.9.m9.1.1.m1.1.1.1.1.1.1.cmml">60</mn><mtext id="S2.SS3.p1.9.m9.1.1.m1.2.2.2.2.2.2" xref="S2.SS3.p1.9.m9.1.1.m1.2.2.2.2.2.2.cmml"> </mtext><mrow id="S2.SS3.p1.9.m9.1.1.m1.3.3.3.3.3.3" xref="S2.SS3.p1.9.m9.1.1.m1.3.3.3.3.3.3.cmml"><mi class="ltx_unit" mathvariant="normal" id="S2.SS3.p1.9.m9.1.1.m1.3.3.3.3.3.3.1.1.1.1.1.1" xref="S2.SS3.p1.9.m9.1.1.m1.3.3.3.3.3.3.1.1.1.1.1.1.cmml">s</mi><mtext id="S2.SS3.p1.9.m9.1.1.m1.3.3.3.3.3.3.2.2.2.2.2.2" xref="S2.SS3.p1.9.m9.1.1.m1.3.3.3.3.3.3.2.2.2.2.2.2.cmml">/</mtext><mi id="S2.SS3.p1.9.m9.1.1.m1.3.3.3.3.3.3.3.3.3.3.3.3" xref="S2.SS3.p1.9.m9.1.1.m1.3.3.3.3.3.3.3.3.3.3.3.3.cmml"></mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p1.9.m9.1.1.m1.3b"><apply id="S2.SS3.p1.9.m9.1.1.m1.3.3.cmml" xref="S2.SS3.p1.9.m9.1.1.m1.3.3"><csymbol cd="latexml" id="S2.SS3.p1.9.m9.1.1.m1.2.2.2.2.2.2.cmml" xref="S2.SS3.p1.9.m9.1.1.m1.2.2.2.2.2.2">times</csymbol><cn type="integer" id="S2.SS3.p1.9.m9.1.1.m1.1.1.1.1.1.1.cmml" xref="S2.SS3.p1.9.m9.1.1.m1.1.1.1.1.1.1">60</cn><apply id="S2.SS3.p1.9.m9.1.1.m1.3.3.3.3.3.3.cmml" xref="S2.SS3.p1.9.m9.1.1.m1.3.3.3.3.3.3"><csymbol cd="latexml" id="S2.SS3.p1.9.m9.1.1.m1.3.3.3.3.3.3.2.2.2.2.2.2.cmml" xref="S2.SS3.p1.9.m9.1.1.m1.3.3.3.3.3.3.2.2.2.2.2.2">divide</csymbol><csymbol cd="latexml" id="S2.SS3.p1.9.m9.1.1.m1.3.3.3.3.3.3.1.1.1.1.1.1.cmml" xref="S2.SS3.p1.9.m9.1.1.m1.3.3.3.3.3.3.1.1.1.1.1.1">second</csymbol><csymbol cd="latexml" id="S2.SS3.p1.9.m9.1.1.m1.3.3.3.3.3.3.3.3.3.3.3.3.cmml" xref="S2.SS3.p1.9.m9.1.1.m1.3.3.3.3.3.3.3.3.3.3.3.3">absent</csymbol></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p1.9.m9.1.1.m1.3c">60\text{\,}\mathrm{s}\text{/}</annotation></semantics></math>-long audio segments.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Experimental Evaluation</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.2" class="ltx_p">In this section, we analyze the performance of the proposed model and the effectiveness of synthetic data for pre-training purpose.
We resample all the data to <math id="S3.p1.1.m1.1.1.m1.3" class="ltx_markedasmath" alttext="16\text{\,}\mathrm{kHz}\text{/}" display="inline"><semantics id="S3.p1.1.m1.1.1.m1.3a"><mrow id="S3.p1.1.m1.1.1.m1.3.3" xref="S3.p1.1.m1.1.1.m1.3.3.cmml"><mn id="S3.p1.1.m1.1.1.m1.1.1.1.1.1.1" xref="S3.p1.1.m1.1.1.m1.1.1.1.1.1.1.cmml">16</mn><mtext id="S3.p1.1.m1.1.1.m1.2.2.2.2.2.2" xref="S3.p1.1.m1.1.1.m1.2.2.2.2.2.2.cmml"> </mtext><mrow id="S3.p1.1.m1.1.1.m1.3.3.3.3.3.3" xref="S3.p1.1.m1.1.1.m1.3.3.3.3.3.3.cmml"><mi class="ltx_unit" id="S3.p1.1.m1.1.1.m1.3.3.3.3.3.3.1.1.1.1.1.1" xref="S3.p1.1.m1.1.1.m1.3.3.3.3.3.3.1.1.1.1.1.1.cmml">kHz</mi><mtext id="S3.p1.1.m1.1.1.m1.3.3.3.3.3.3.2.2.2.2.2.2" xref="S3.p1.1.m1.1.1.m1.3.3.3.3.3.3.2.2.2.2.2.2.cmml">/</mtext><mi id="S3.p1.1.m1.1.1.m1.3.3.3.3.3.3.3.3.3.3.3.3" xref="S3.p1.1.m1.1.1.m1.3.3.3.3.3.3.3.3.3.3.3.3.cmml"></mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.p1.1.m1.1.1.m1.3b"><apply id="S3.p1.1.m1.1.1.m1.3.3.cmml" xref="S3.p1.1.m1.1.1.m1.3.3"><csymbol cd="latexml" id="S3.p1.1.m1.1.1.m1.2.2.2.2.2.2.cmml" xref="S3.p1.1.m1.1.1.m1.2.2.2.2.2.2">times</csymbol><cn type="integer" id="S3.p1.1.m1.1.1.m1.1.1.1.1.1.1.cmml" xref="S3.p1.1.m1.1.1.m1.1.1.1.1.1.1">16</cn><apply id="S3.p1.1.m1.1.1.m1.3.3.3.3.3.3.cmml" xref="S3.p1.1.m1.1.1.m1.3.3.3.3.3.3"><csymbol cd="latexml" id="S3.p1.1.m1.1.1.m1.3.3.3.3.3.3.2.2.2.2.2.2.cmml" xref="S3.p1.1.m1.1.1.m1.3.3.3.3.3.3.2.2.2.2.2.2">divide</csymbol><csymbol cd="latexml" id="S3.p1.1.m1.1.1.m1.3.3.3.3.3.3.1.1.1.1.1.1.cmml" xref="S3.p1.1.m1.1.1.m1.3.3.3.3.3.3.1.1.1.1.1.1">kilohertz</csymbol><csymbol cd="latexml" id="S3.p1.1.m1.1.1.m1.3.3.3.3.3.3.3.3.3.3.3.3.cmml" xref="S3.p1.1.m1.1.1.m1.3.3.3.3.3.3.3.3.3.3.3.3">absent</csymbol></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.1.m1.1.1.m1.3c">16\text{\,}\mathrm{kHz}\text{/}</annotation></semantics></math> and apply peak normalization to each audio segment. During training, we introduce spectrogram augmentation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>, use a mean squared error loss, Adam optimizer <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite> with learning rate <math id="S3.p1.2.m2.1" class="ltx_Math" alttext="\mathrm{lr}=10^{-4}" display="inline"><semantics id="S3.p1.2.m2.1a"><mrow id="S3.p1.2.m2.1.1" xref="S3.p1.2.m2.1.1.cmml"><mi id="S3.p1.2.m2.1.1.2" xref="S3.p1.2.m2.1.1.2.cmml">lr</mi><mo id="S3.p1.2.m2.1.1.1" xref="S3.p1.2.m2.1.1.1.cmml">=</mo><msup id="S3.p1.2.m2.1.1.3" xref="S3.p1.2.m2.1.1.3.cmml"><mn id="S3.p1.2.m2.1.1.3.2" xref="S3.p1.2.m2.1.1.3.2.cmml">10</mn><mrow id="S3.p1.2.m2.1.1.3.3" xref="S3.p1.2.m2.1.1.3.3.cmml"><mo id="S3.p1.2.m2.1.1.3.3a" xref="S3.p1.2.m2.1.1.3.3.cmml">−</mo><mn id="S3.p1.2.m2.1.1.3.3.2" xref="S3.p1.2.m2.1.1.3.3.2.cmml">4</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.p1.2.m2.1b"><apply id="S3.p1.2.m2.1.1.cmml" xref="S3.p1.2.m2.1.1"><eq id="S3.p1.2.m2.1.1.1.cmml" xref="S3.p1.2.m2.1.1.1"></eq><ci id="S3.p1.2.m2.1.1.2.cmml" xref="S3.p1.2.m2.1.1.2">lr</ci><apply id="S3.p1.2.m2.1.1.3.cmml" xref="S3.p1.2.m2.1.1.3"><csymbol cd="ambiguous" id="S3.p1.2.m2.1.1.3.1.cmml" xref="S3.p1.2.m2.1.1.3">superscript</csymbol><cn type="integer" id="S3.p1.2.m2.1.1.3.2.cmml" xref="S3.p1.2.m2.1.1.3.2">10</cn><apply id="S3.p1.2.m2.1.1.3.3.cmml" xref="S3.p1.2.m2.1.1.3.3"><minus id="S3.p1.2.m2.1.1.3.3.1.cmml" xref="S3.p1.2.m2.1.1.3.3"></minus><cn type="integer" id="S3.p1.2.m2.1.1.3.3.2.cmml" xref="S3.p1.2.m2.1.1.3.3.2">4</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.2.m2.1c">\mathrm{lr}=10^{-4}</annotation></semantics></math>, batch size of 128. We train the model for 150 epochs, selecting the best checkpoint based on validation loss. We implement the proposed architecture in Keras<span id="footnote3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span><span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://github.com/keras-team/keras</span></span></span></span> and train on a single V100-32GB GPU. To compare and evaluate different training strategies, we first round the output of the CRNN to the nearest integer, then compute the classification accuracy, i.e. the number of segments where the predicted number of vehicles matches exactly the ground truth versus the total number of segments.
We split the available real-world data into a training set - 6 consecutive days of recordings; a validation set - 2 days; and a test set - 3 days recorded in a different month than training and validation data. The synthetic dataset replicates the distribution of events of the training set, and has therefore no statistical overlap with validation and test sets. As we are interested in evaluating the model performance on real-world data, we do not generate any synthetic data for testing.</p>
</div>
<div id="S3.p2" class="ltx_para">
<p id="S3.p2.11" class="ltx_p">We first train several models using only real-world (<span id="S3.p2.11.1" class="ltx_text ltx_markedasmath">RW</span>) data, increasing the training set size from <math id="S3.p2.2.m2.1.1.m1.3" class="ltx_markedasmath" alttext="1\text{\,}\mathrm{h}\text{/}" display="inline"><semantics id="S3.p2.2.m2.1.1.m1.3a"><mrow id="S3.p2.2.m2.1.1.m1.3.3" xref="S3.p2.2.m2.1.1.m1.3.3.cmml"><mn id="S3.p2.2.m2.1.1.m1.1.1.1.1.1.1" xref="S3.p2.2.m2.1.1.m1.1.1.1.1.1.1.cmml">1</mn><mtext id="S3.p2.2.m2.1.1.m1.2.2.2.2.2.2" xref="S3.p2.2.m2.1.1.m1.2.2.2.2.2.2.cmml"> </mtext><mrow id="S3.p2.2.m2.1.1.m1.3.3.3.3.3.3" xref="S3.p2.2.m2.1.1.m1.3.3.3.3.3.3.cmml"><mi class="ltx_unit" mathvariant="normal" id="S3.p2.2.m2.1.1.m1.3.3.3.3.3.3.1.1.1.1.1.1" xref="S3.p2.2.m2.1.1.m1.3.3.3.3.3.3.1.1.1.1.1.1.cmml">h</mi><mtext id="S3.p2.2.m2.1.1.m1.3.3.3.3.3.3.2.2.2.2.2.2" xref="S3.p2.2.m2.1.1.m1.3.3.3.3.3.3.2.2.2.2.2.2.cmml">/</mtext><mi id="S3.p2.2.m2.1.1.m1.3.3.3.3.3.3.3.3.3.3.3.3" xref="S3.p2.2.m2.1.1.m1.3.3.3.3.3.3.3.3.3.3.3.3.cmml"></mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.p2.2.m2.1.1.m1.3b"><apply id="S3.p2.2.m2.1.1.m1.3.3.cmml" xref="S3.p2.2.m2.1.1.m1.3.3"><csymbol cd="latexml" id="S3.p2.2.m2.1.1.m1.2.2.2.2.2.2.cmml" xref="S3.p2.2.m2.1.1.m1.2.2.2.2.2.2">times</csymbol><cn type="integer" id="S3.p2.2.m2.1.1.m1.1.1.1.1.1.1.cmml" xref="S3.p2.2.m2.1.1.m1.1.1.1.1.1.1">1</cn><apply id="S3.p2.2.m2.1.1.m1.3.3.3.3.3.3.cmml" xref="S3.p2.2.m2.1.1.m1.3.3.3.3.3.3"><csymbol cd="latexml" id="S3.p2.2.m2.1.1.m1.3.3.3.3.3.3.2.2.2.2.2.2.cmml" xref="S3.p2.2.m2.1.1.m1.3.3.3.3.3.3.2.2.2.2.2.2">divide</csymbol><csymbol cd="latexml" id="S3.p2.2.m2.1.1.m1.3.3.3.3.3.3.1.1.1.1.1.1.cmml" xref="S3.p2.2.m2.1.1.m1.3.3.3.3.3.3.1.1.1.1.1.1">hour</csymbol><csymbol cd="latexml" id="S3.p2.2.m2.1.1.m1.3.3.3.3.3.3.3.3.3.3.3.3.cmml" xref="S3.p2.2.m2.1.1.m1.3.3.3.3.3.3.3.3.3.3.3.3">absent</csymbol></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.2.m2.1.1.m1.3c">1\text{\,}\mathrm{h}\text{/}</annotation></semantics></math> to <math id="S3.p2.3.m3.1.1.m1.3" class="ltx_markedasmath" alttext="144\text{\,}\mathrm{h}\text{/}" display="inline"><semantics id="S3.p2.3.m3.1.1.m1.3a"><mrow id="S3.p2.3.m3.1.1.m1.3.3" xref="S3.p2.3.m3.1.1.m1.3.3.cmml"><mn id="S3.p2.3.m3.1.1.m1.1.1.1.1.1.1" xref="S3.p2.3.m3.1.1.m1.1.1.1.1.1.1.cmml">144</mn><mtext id="S3.p2.3.m3.1.1.m1.2.2.2.2.2.2" xref="S3.p2.3.m3.1.1.m1.2.2.2.2.2.2.cmml"> </mtext><mrow id="S3.p2.3.m3.1.1.m1.3.3.3.3.3.3" xref="S3.p2.3.m3.1.1.m1.3.3.3.3.3.3.cmml"><mi class="ltx_unit" mathvariant="normal" id="S3.p2.3.m3.1.1.m1.3.3.3.3.3.3.1.1.1.1.1.1" xref="S3.p2.3.m3.1.1.m1.3.3.3.3.3.3.1.1.1.1.1.1.cmml">h</mi><mtext id="S3.p2.3.m3.1.1.m1.3.3.3.3.3.3.2.2.2.2.2.2" xref="S3.p2.3.m3.1.1.m1.3.3.3.3.3.3.2.2.2.2.2.2.cmml">/</mtext><mi id="S3.p2.3.m3.1.1.m1.3.3.3.3.3.3.3.3.3.3.3.3" xref="S3.p2.3.m3.1.1.m1.3.3.3.3.3.3.3.3.3.3.3.3.cmml"></mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.p2.3.m3.1.1.m1.3b"><apply id="S3.p2.3.m3.1.1.m1.3.3.cmml" xref="S3.p2.3.m3.1.1.m1.3.3"><csymbol cd="latexml" id="S3.p2.3.m3.1.1.m1.2.2.2.2.2.2.cmml" xref="S3.p2.3.m3.1.1.m1.2.2.2.2.2.2">times</csymbol><cn type="integer" id="S3.p2.3.m3.1.1.m1.1.1.1.1.1.1.cmml" xref="S3.p2.3.m3.1.1.m1.1.1.1.1.1.1">144</cn><apply id="S3.p2.3.m3.1.1.m1.3.3.3.3.3.3.cmml" xref="S3.p2.3.m3.1.1.m1.3.3.3.3.3.3"><csymbol cd="latexml" id="S3.p2.3.m3.1.1.m1.3.3.3.3.3.3.2.2.2.2.2.2.cmml" xref="S3.p2.3.m3.1.1.m1.3.3.3.3.3.3.2.2.2.2.2.2">divide</csymbol><csymbol cd="latexml" id="S3.p2.3.m3.1.1.m1.3.3.3.3.3.3.1.1.1.1.1.1.cmml" xref="S3.p2.3.m3.1.1.m1.3.3.3.3.3.3.1.1.1.1.1.1">hour</csymbol><csymbol cd="latexml" id="S3.p2.3.m3.1.1.m1.3.3.3.3.3.3.3.3.3.3.3.3.cmml" xref="S3.p2.3.m3.1.1.m1.3.3.3.3.3.3.3.3.3.3.3.3">absent</csymbol></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.3.m3.1.1.m1.3c">144\text{\,}\mathrm{h}\text{/}</annotation></semantics></math> and training each model 4 times on randomly-chosen <span id="S3.p2.11.2" class="ltx_text" style="color:#000000;">folds</span> within the available training data. Results, reported in Fig. <a href="#S2.F3" title="Figure 3 ‣ 2.2 CRNN Architecture ‣ 2 Methodology ‣ Can Synthetic Data Boost the Training of Deep Acoustic Vehicle Counting Networks?" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, show the expected increasing trend in test accuracy when more training data is used. This confirms that the proposed model has the capacity to learn effectively from an increasing amount of data.
We then pre-train a model using <math id="S3.p2.4.m4.1.1.m1.3" class="ltx_markedasmath" alttext="144\text{\,}\mathrm{h}\text{/}" display="inline"><semantics id="S3.p2.4.m4.1.1.m1.3a"><mrow id="S3.p2.4.m4.1.1.m1.3.3" xref="S3.p2.4.m4.1.1.m1.3.3.cmml"><mn id="S3.p2.4.m4.1.1.m1.1.1.1.1.1.1" xref="S3.p2.4.m4.1.1.m1.1.1.1.1.1.1.cmml">144</mn><mtext id="S3.p2.4.m4.1.1.m1.2.2.2.2.2.2" xref="S3.p2.4.m4.1.1.m1.2.2.2.2.2.2.cmml"> </mtext><mrow id="S3.p2.4.m4.1.1.m1.3.3.3.3.3.3" xref="S3.p2.4.m4.1.1.m1.3.3.3.3.3.3.cmml"><mi class="ltx_unit" mathvariant="normal" id="S3.p2.4.m4.1.1.m1.3.3.3.3.3.3.1.1.1.1.1.1" xref="S3.p2.4.m4.1.1.m1.3.3.3.3.3.3.1.1.1.1.1.1.cmml">h</mi><mtext id="S3.p2.4.m4.1.1.m1.3.3.3.3.3.3.2.2.2.2.2.2" xref="S3.p2.4.m4.1.1.m1.3.3.3.3.3.3.2.2.2.2.2.2.cmml">/</mtext><mi id="S3.p2.4.m4.1.1.m1.3.3.3.3.3.3.3.3.3.3.3.3" xref="S3.p2.4.m4.1.1.m1.3.3.3.3.3.3.3.3.3.3.3.3.cmml"></mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.p2.4.m4.1.1.m1.3b"><apply id="S3.p2.4.m4.1.1.m1.3.3.cmml" xref="S3.p2.4.m4.1.1.m1.3.3"><csymbol cd="latexml" id="S3.p2.4.m4.1.1.m1.2.2.2.2.2.2.cmml" xref="S3.p2.4.m4.1.1.m1.2.2.2.2.2.2">times</csymbol><cn type="integer" id="S3.p2.4.m4.1.1.m1.1.1.1.1.1.1.cmml" xref="S3.p2.4.m4.1.1.m1.1.1.1.1.1.1">144</cn><apply id="S3.p2.4.m4.1.1.m1.3.3.3.3.3.3.cmml" xref="S3.p2.4.m4.1.1.m1.3.3.3.3.3.3"><csymbol cd="latexml" id="S3.p2.4.m4.1.1.m1.3.3.3.3.3.3.2.2.2.2.2.2.cmml" xref="S3.p2.4.m4.1.1.m1.3.3.3.3.3.3.2.2.2.2.2.2">divide</csymbol><csymbol cd="latexml" id="S3.p2.4.m4.1.1.m1.3.3.3.3.3.3.1.1.1.1.1.1.cmml" xref="S3.p2.4.m4.1.1.m1.3.3.3.3.3.3.1.1.1.1.1.1">hour</csymbol><csymbol cd="latexml" id="S3.p2.4.m4.1.1.m1.3.3.3.3.3.3.3.3.3.3.3.3.cmml" xref="S3.p2.4.m4.1.1.m1.3.3.3.3.3.3.3.3.3.3.3.3">absent</csymbol></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.4.m4.1.1.m1.3c">144\text{\,}\mathrm{h}\text{/}</annotation></semantics></math> of synthetic data generated as described in Sec. <a href="#S2.SS3" title="2.3 Synthetic Data Generation ‣ 2 Methodology ‣ Can Synthetic Data Boost the Training of Deep Acoustic Vehicle Counting Networks?" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.3</span></a> and fine-tune it with an increasing amount of real-world data ranging from <math id="S3.p2.5.m5.1.1.m1.3" class="ltx_markedasmath" alttext="1\text{\,}\mathrm{h}\text{/}" display="inline"><semantics id="S3.p2.5.m5.1.1.m1.3a"><mrow id="S3.p2.5.m5.1.1.m1.3.3" xref="S3.p2.5.m5.1.1.m1.3.3.cmml"><mn id="S3.p2.5.m5.1.1.m1.1.1.1.1.1.1" xref="S3.p2.5.m5.1.1.m1.1.1.1.1.1.1.cmml">1</mn><mtext id="S3.p2.5.m5.1.1.m1.2.2.2.2.2.2" xref="S3.p2.5.m5.1.1.m1.2.2.2.2.2.2.cmml"> </mtext><mrow id="S3.p2.5.m5.1.1.m1.3.3.3.3.3.3" xref="S3.p2.5.m5.1.1.m1.3.3.3.3.3.3.cmml"><mi class="ltx_unit" mathvariant="normal" id="S3.p2.5.m5.1.1.m1.3.3.3.3.3.3.1.1.1.1.1.1" xref="S3.p2.5.m5.1.1.m1.3.3.3.3.3.3.1.1.1.1.1.1.cmml">h</mi><mtext id="S3.p2.5.m5.1.1.m1.3.3.3.3.3.3.2.2.2.2.2.2" xref="S3.p2.5.m5.1.1.m1.3.3.3.3.3.3.2.2.2.2.2.2.cmml">/</mtext><mi id="S3.p2.5.m5.1.1.m1.3.3.3.3.3.3.3.3.3.3.3.3" xref="S3.p2.5.m5.1.1.m1.3.3.3.3.3.3.3.3.3.3.3.3.cmml"></mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.p2.5.m5.1.1.m1.3b"><apply id="S3.p2.5.m5.1.1.m1.3.3.cmml" xref="S3.p2.5.m5.1.1.m1.3.3"><csymbol cd="latexml" id="S3.p2.5.m5.1.1.m1.2.2.2.2.2.2.cmml" xref="S3.p2.5.m5.1.1.m1.2.2.2.2.2.2">times</csymbol><cn type="integer" id="S3.p2.5.m5.1.1.m1.1.1.1.1.1.1.cmml" xref="S3.p2.5.m5.1.1.m1.1.1.1.1.1.1">1</cn><apply id="S3.p2.5.m5.1.1.m1.3.3.3.3.3.3.cmml" xref="S3.p2.5.m5.1.1.m1.3.3.3.3.3.3"><csymbol cd="latexml" id="S3.p2.5.m5.1.1.m1.3.3.3.3.3.3.2.2.2.2.2.2.cmml" xref="S3.p2.5.m5.1.1.m1.3.3.3.3.3.3.2.2.2.2.2.2">divide</csymbol><csymbol cd="latexml" id="S3.p2.5.m5.1.1.m1.3.3.3.3.3.3.1.1.1.1.1.1.cmml" xref="S3.p2.5.m5.1.1.m1.3.3.3.3.3.3.1.1.1.1.1.1">hour</csymbol><csymbol cd="latexml" id="S3.p2.5.m5.1.1.m1.3.3.3.3.3.3.3.3.3.3.3.3.cmml" xref="S3.p2.5.m5.1.1.m1.3.3.3.3.3.3.3.3.3.3.3.3">absent</csymbol></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.5.m5.1.1.m1.3c">1\text{\,}\mathrm{h}\text{/}</annotation></semantics></math> to <math id="S3.p2.6.m6.1.1.m1.3" class="ltx_markedasmath" alttext="144\text{\,}\mathrm{h}\text{/}" display="inline"><semantics id="S3.p2.6.m6.1.1.m1.3a"><mrow id="S3.p2.6.m6.1.1.m1.3.3" xref="S3.p2.6.m6.1.1.m1.3.3.cmml"><mn id="S3.p2.6.m6.1.1.m1.1.1.1.1.1.1" xref="S3.p2.6.m6.1.1.m1.1.1.1.1.1.1.cmml">144</mn><mtext id="S3.p2.6.m6.1.1.m1.2.2.2.2.2.2" xref="S3.p2.6.m6.1.1.m1.2.2.2.2.2.2.cmml"> </mtext><mrow id="S3.p2.6.m6.1.1.m1.3.3.3.3.3.3" xref="S3.p2.6.m6.1.1.m1.3.3.3.3.3.3.cmml"><mi class="ltx_unit" mathvariant="normal" id="S3.p2.6.m6.1.1.m1.3.3.3.3.3.3.1.1.1.1.1.1" xref="S3.p2.6.m6.1.1.m1.3.3.3.3.3.3.1.1.1.1.1.1.cmml">h</mi><mtext id="S3.p2.6.m6.1.1.m1.3.3.3.3.3.3.2.2.2.2.2.2" xref="S3.p2.6.m6.1.1.m1.3.3.3.3.3.3.2.2.2.2.2.2.cmml">/</mtext><mi id="S3.p2.6.m6.1.1.m1.3.3.3.3.3.3.3.3.3.3.3.3" xref="S3.p2.6.m6.1.1.m1.3.3.3.3.3.3.3.3.3.3.3.3.cmml"></mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.p2.6.m6.1.1.m1.3b"><apply id="S3.p2.6.m6.1.1.m1.3.3.cmml" xref="S3.p2.6.m6.1.1.m1.3.3"><csymbol cd="latexml" id="S3.p2.6.m6.1.1.m1.2.2.2.2.2.2.cmml" xref="S3.p2.6.m6.1.1.m1.2.2.2.2.2.2">times</csymbol><cn type="integer" id="S3.p2.6.m6.1.1.m1.1.1.1.1.1.1.cmml" xref="S3.p2.6.m6.1.1.m1.1.1.1.1.1.1">144</cn><apply id="S3.p2.6.m6.1.1.m1.3.3.3.3.3.3.cmml" xref="S3.p2.6.m6.1.1.m1.3.3.3.3.3.3"><csymbol cd="latexml" id="S3.p2.6.m6.1.1.m1.3.3.3.3.3.3.2.2.2.2.2.2.cmml" xref="S3.p2.6.m6.1.1.m1.3.3.3.3.3.3.2.2.2.2.2.2">divide</csymbol><csymbol cd="latexml" id="S3.p2.6.m6.1.1.m1.3.3.3.3.3.3.1.1.1.1.1.1.cmml" xref="S3.p2.6.m6.1.1.m1.3.3.3.3.3.3.1.1.1.1.1.1">hour</csymbol><csymbol cd="latexml" id="S3.p2.6.m6.1.1.m1.3.3.3.3.3.3.3.3.3.3.3.3.cmml" xref="S3.p2.6.m6.1.1.m1.3.3.3.3.3.3.3.3.3.3.3.3">absent</csymbol></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.6.m6.1.1.m1.3c">144\text{\,}\mathrm{h}\text{/}</annotation></semantics></math>. Real-world data for fine-tuning is randomly selected from the available real-world training data, repeating each training 4 times on different data subsets. Fig. <a href="#S2.F4" title="Figure 4 ‣ 2.2 CRNN Architecture ‣ 2 Methodology ‣ Can Synthetic Data Boost the Training of Deep Acoustic Vehicle Counting Networks?" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> shows the classification accuracy on the test set for the fine-tuned models. With no fine-tuning on real-world data (<math id="S3.p2.7.m7.1.1.m1.3" class="ltx_markedasmath" alttext="0\text{\,}\mathrm{h}\text{/}" display="inline"><semantics id="S3.p2.7.m7.1.1.m1.3a"><mrow id="S3.p2.7.m7.1.1.m1.3.3" xref="S3.p2.7.m7.1.1.m1.3.3.cmml"><mn id="S3.p2.7.m7.1.1.m1.1.1.1.1.1.1" xref="S3.p2.7.m7.1.1.m1.1.1.1.1.1.1.cmml">0</mn><mtext id="S3.p2.7.m7.1.1.m1.2.2.2.2.2.2" xref="S3.p2.7.m7.1.1.m1.2.2.2.2.2.2.cmml"> </mtext><mrow id="S3.p2.7.m7.1.1.m1.3.3.3.3.3.3" xref="S3.p2.7.m7.1.1.m1.3.3.3.3.3.3.cmml"><mi class="ltx_unit" mathvariant="normal" id="S3.p2.7.m7.1.1.m1.3.3.3.3.3.3.1.1.1.1.1.1" xref="S3.p2.7.m7.1.1.m1.3.3.3.3.3.3.1.1.1.1.1.1.cmml">h</mi><mtext id="S3.p2.7.m7.1.1.m1.3.3.3.3.3.3.2.2.2.2.2.2" xref="S3.p2.7.m7.1.1.m1.3.3.3.3.3.3.2.2.2.2.2.2.cmml">/</mtext><mi id="S3.p2.7.m7.1.1.m1.3.3.3.3.3.3.3.3.3.3.3.3" xref="S3.p2.7.m7.1.1.m1.3.3.3.3.3.3.3.3.3.3.3.3.cmml"></mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.p2.7.m7.1.1.m1.3b"><apply id="S3.p2.7.m7.1.1.m1.3.3.cmml" xref="S3.p2.7.m7.1.1.m1.3.3"><csymbol cd="latexml" id="S3.p2.7.m7.1.1.m1.2.2.2.2.2.2.cmml" xref="S3.p2.7.m7.1.1.m1.2.2.2.2.2.2">times</csymbol><cn type="integer" id="S3.p2.7.m7.1.1.m1.1.1.1.1.1.1.cmml" xref="S3.p2.7.m7.1.1.m1.1.1.1.1.1.1">0</cn><apply id="S3.p2.7.m7.1.1.m1.3.3.3.3.3.3.cmml" xref="S3.p2.7.m7.1.1.m1.3.3.3.3.3.3"><csymbol cd="latexml" id="S3.p2.7.m7.1.1.m1.3.3.3.3.3.3.2.2.2.2.2.2.cmml" xref="S3.p2.7.m7.1.1.m1.3.3.3.3.3.3.2.2.2.2.2.2">divide</csymbol><csymbol cd="latexml" id="S3.p2.7.m7.1.1.m1.3.3.3.3.3.3.1.1.1.1.1.1.cmml" xref="S3.p2.7.m7.1.1.m1.3.3.3.3.3.3.1.1.1.1.1.1">hour</csymbol><csymbol cd="latexml" id="S3.p2.7.m7.1.1.m1.3.3.3.3.3.3.3.3.3.3.3.3.cmml" xref="S3.p2.7.m7.1.1.m1.3.3.3.3.3.3.3.3.3.3.3.3">absent</csymbol></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.7.m7.1.1.m1.3c">0\text{\,}\mathrm{h}\text{/}</annotation></semantics></math>) the model pre-trained only on synthetic data performs poorly, highlighting the need for a fine-tuning strategy that allows the model to adapt to the real data distribution. With as little as <math id="S3.p2.8.m8.1.1.m1.3" class="ltx_markedasmath" alttext="6\text{\,}\mathrm{h}\text{/}" display="inline"><semantics id="S3.p2.8.m8.1.1.m1.3a"><mrow id="S3.p2.8.m8.1.1.m1.3.3" xref="S3.p2.8.m8.1.1.m1.3.3.cmml"><mn id="S3.p2.8.m8.1.1.m1.1.1.1.1.1.1" xref="S3.p2.8.m8.1.1.m1.1.1.1.1.1.1.cmml">6</mn><mtext id="S3.p2.8.m8.1.1.m1.2.2.2.2.2.2" xref="S3.p2.8.m8.1.1.m1.2.2.2.2.2.2.cmml"> </mtext><mrow id="S3.p2.8.m8.1.1.m1.3.3.3.3.3.3" xref="S3.p2.8.m8.1.1.m1.3.3.3.3.3.3.cmml"><mi class="ltx_unit" mathvariant="normal" id="S3.p2.8.m8.1.1.m1.3.3.3.3.3.3.1.1.1.1.1.1" xref="S3.p2.8.m8.1.1.m1.3.3.3.3.3.3.1.1.1.1.1.1.cmml">h</mi><mtext id="S3.p2.8.m8.1.1.m1.3.3.3.3.3.3.2.2.2.2.2.2" xref="S3.p2.8.m8.1.1.m1.3.3.3.3.3.3.2.2.2.2.2.2.cmml">/</mtext><mi id="S3.p2.8.m8.1.1.m1.3.3.3.3.3.3.3.3.3.3.3.3" xref="S3.p2.8.m8.1.1.m1.3.3.3.3.3.3.3.3.3.3.3.3.cmml"></mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.p2.8.m8.1.1.m1.3b"><apply id="S3.p2.8.m8.1.1.m1.3.3.cmml" xref="S3.p2.8.m8.1.1.m1.3.3"><csymbol cd="latexml" id="S3.p2.8.m8.1.1.m1.2.2.2.2.2.2.cmml" xref="S3.p2.8.m8.1.1.m1.2.2.2.2.2.2">times</csymbol><cn type="integer" id="S3.p2.8.m8.1.1.m1.1.1.1.1.1.1.cmml" xref="S3.p2.8.m8.1.1.m1.1.1.1.1.1.1">6</cn><apply id="S3.p2.8.m8.1.1.m1.3.3.3.3.3.3.cmml" xref="S3.p2.8.m8.1.1.m1.3.3.3.3.3.3"><csymbol cd="latexml" id="S3.p2.8.m8.1.1.m1.3.3.3.3.3.3.2.2.2.2.2.2.cmml" xref="S3.p2.8.m8.1.1.m1.3.3.3.3.3.3.2.2.2.2.2.2">divide</csymbol><csymbol cd="latexml" id="S3.p2.8.m8.1.1.m1.3.3.3.3.3.3.1.1.1.1.1.1.cmml" xref="S3.p2.8.m8.1.1.m1.3.3.3.3.3.3.1.1.1.1.1.1">hour</csymbol><csymbol cd="latexml" id="S3.p2.8.m8.1.1.m1.3.3.3.3.3.3.3.3.3.3.3.3.cmml" xref="S3.p2.8.m8.1.1.m1.3.3.3.3.3.3.3.3.3.3.3.3">absent</csymbol></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.8.m8.1.1.m1.3c">6\text{\,}\mathrm{h}\text{/}</annotation></semantics></math> of real data for fine-tuning, however, the model is already capable of counting with an accuracy between <math id="S3.p2.9.m9.1" class="ltx_Math" alttext="0.77" display="inline"><semantics id="S3.p2.9.m9.1a"><mn id="S3.p2.9.m9.1.1" xref="S3.p2.9.m9.1.1.cmml">0.77</mn><annotation-xml encoding="MathML-Content" id="S3.p2.9.m9.1b"><cn type="float" id="S3.p2.9.m9.1.1.cmml" xref="S3.p2.9.m9.1.1">0.77</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.9.m9.1c">0.77</annotation></semantics></math> and <math id="S3.p2.10.m10.1" class="ltx_Math" alttext="0.87" display="inline"><semantics id="S3.p2.10.m10.1a"><mn id="S3.p2.10.m10.1.1" xref="S3.p2.10.m10.1.1.cmml">0.87</mn><annotation-xml encoding="MathML-Content" id="S3.p2.10.m10.1b"><cn type="float" id="S3.p2.10.m10.1.1.cmml" xref="S3.p2.10.m10.1.1">0.87</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.10.m10.1c">0.87</annotation></semantics></math> for all categories. The accuracy saturates when more than <math id="S3.p2.11.m11.1.1.m1.3" class="ltx_markedasmath" alttext="24\text{\,}\mathrm{h}\text{/}" display="inline"><semantics id="S3.p2.11.m11.1.1.m1.3a"><mrow id="S3.p2.11.m11.1.1.m1.3.3" xref="S3.p2.11.m11.1.1.m1.3.3.cmml"><mn id="S3.p2.11.m11.1.1.m1.1.1.1.1.1.1" xref="S3.p2.11.m11.1.1.m1.1.1.1.1.1.1.cmml">24</mn><mtext id="S3.p2.11.m11.1.1.m1.2.2.2.2.2.2" xref="S3.p2.11.m11.1.1.m1.2.2.2.2.2.2.cmml"> </mtext><mrow id="S3.p2.11.m11.1.1.m1.3.3.3.3.3.3" xref="S3.p2.11.m11.1.1.m1.3.3.3.3.3.3.cmml"><mi class="ltx_unit" mathvariant="normal" id="S3.p2.11.m11.1.1.m1.3.3.3.3.3.3.1.1.1.1.1.1" xref="S3.p2.11.m11.1.1.m1.3.3.3.3.3.3.1.1.1.1.1.1.cmml">h</mi><mtext id="S3.p2.11.m11.1.1.m1.3.3.3.3.3.3.2.2.2.2.2.2" xref="S3.p2.11.m11.1.1.m1.3.3.3.3.3.3.2.2.2.2.2.2.cmml">/</mtext><mi id="S3.p2.11.m11.1.1.m1.3.3.3.3.3.3.3.3.3.3.3.3" xref="S3.p2.11.m11.1.1.m1.3.3.3.3.3.3.3.3.3.3.3.3.cmml"></mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.p2.11.m11.1.1.m1.3b"><apply id="S3.p2.11.m11.1.1.m1.3.3.cmml" xref="S3.p2.11.m11.1.1.m1.3.3"><csymbol cd="latexml" id="S3.p2.11.m11.1.1.m1.2.2.2.2.2.2.cmml" xref="S3.p2.11.m11.1.1.m1.2.2.2.2.2.2">times</csymbol><cn type="integer" id="S3.p2.11.m11.1.1.m1.1.1.1.1.1.1.cmml" xref="S3.p2.11.m11.1.1.m1.1.1.1.1.1.1">24</cn><apply id="S3.p2.11.m11.1.1.m1.3.3.3.3.3.3.cmml" xref="S3.p2.11.m11.1.1.m1.3.3.3.3.3.3"><csymbol cd="latexml" id="S3.p2.11.m11.1.1.m1.3.3.3.3.3.3.2.2.2.2.2.2.cmml" xref="S3.p2.11.m11.1.1.m1.3.3.3.3.3.3.2.2.2.2.2.2">divide</csymbol><csymbol cd="latexml" id="S3.p2.11.m11.1.1.m1.3.3.3.3.3.3.1.1.1.1.1.1.cmml" xref="S3.p2.11.m11.1.1.m1.3.3.3.3.3.3.1.1.1.1.1.1">hour</csymbol><csymbol cd="latexml" id="S3.p2.11.m11.1.1.m1.3.3.3.3.3.3.3.3.3.3.3.3.cmml" xref="S3.p2.11.m11.1.1.m1.3.3.3.3.3.3.3.3.3.3.3.3">absent</csymbol></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.11.m11.1.1.m1.3c">24\text{\,}\mathrm{h}\text{/}</annotation></semantics></math> of real-world data are used for fine-tuning.</p>
</div>
<div id="S3.p3" class="ltx_para">
<p id="S3.p3.11" class="ltx_p">Fig. <a href="#S2.F5" title="Figure 5 ‣ 2.2 CRNN Architecture ‣ 2 Methodology ‣ Can Synthetic Data Boost the Training of Deep Acoustic Vehicle Counting Networks?" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> compares accuracy between fine-tuned models with up to <math id="S3.p3.1.m1.1.1.m1.3" class="ltx_markedasmath" alttext="144\text{\,}\mathrm{h}\text{/}" display="inline"><semantics id="S3.p3.1.m1.1.1.m1.3a"><mrow id="S3.p3.1.m1.1.1.m1.3.3" xref="S3.p3.1.m1.1.1.m1.3.3.cmml"><mn id="S3.p3.1.m1.1.1.m1.1.1.1.1.1.1" xref="S3.p3.1.m1.1.1.m1.1.1.1.1.1.1.cmml">144</mn><mtext id="S3.p3.1.m1.1.1.m1.2.2.2.2.2.2" xref="S3.p3.1.m1.1.1.m1.2.2.2.2.2.2.cmml"> </mtext><mrow id="S3.p3.1.m1.1.1.m1.3.3.3.3.3.3" xref="S3.p3.1.m1.1.1.m1.3.3.3.3.3.3.cmml"><mi class="ltx_unit" mathvariant="normal" id="S3.p3.1.m1.1.1.m1.3.3.3.3.3.3.1.1.1.1.1.1" xref="S3.p3.1.m1.1.1.m1.3.3.3.3.3.3.1.1.1.1.1.1.cmml">h</mi><mtext id="S3.p3.1.m1.1.1.m1.3.3.3.3.3.3.2.2.2.2.2.2" xref="S3.p3.1.m1.1.1.m1.3.3.3.3.3.3.2.2.2.2.2.2.cmml">/</mtext><mi id="S3.p3.1.m1.1.1.m1.3.3.3.3.3.3.3.3.3.3.3.3" xref="S3.p3.1.m1.1.1.m1.3.3.3.3.3.3.3.3.3.3.3.3.cmml"></mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.p3.1.m1.1.1.m1.3b"><apply id="S3.p3.1.m1.1.1.m1.3.3.cmml" xref="S3.p3.1.m1.1.1.m1.3.3"><csymbol cd="latexml" id="S3.p3.1.m1.1.1.m1.2.2.2.2.2.2.cmml" xref="S3.p3.1.m1.1.1.m1.2.2.2.2.2.2">times</csymbol><cn type="integer" id="S3.p3.1.m1.1.1.m1.1.1.1.1.1.1.cmml" xref="S3.p3.1.m1.1.1.m1.1.1.1.1.1.1">144</cn><apply id="S3.p3.1.m1.1.1.m1.3.3.3.3.3.3.cmml" xref="S3.p3.1.m1.1.1.m1.3.3.3.3.3.3"><csymbol cd="latexml" id="S3.p3.1.m1.1.1.m1.3.3.3.3.3.3.2.2.2.2.2.2.cmml" xref="S3.p3.1.m1.1.1.m1.3.3.3.3.3.3.2.2.2.2.2.2">divide</csymbol><csymbol cd="latexml" id="S3.p3.1.m1.1.1.m1.3.3.3.3.3.3.1.1.1.1.1.1.cmml" xref="S3.p3.1.m1.1.1.m1.3.3.3.3.3.3.1.1.1.1.1.1">hour</csymbol><csymbol cd="latexml" id="S3.p3.1.m1.1.1.m1.3.3.3.3.3.3.3.3.3.3.3.3.cmml" xref="S3.p3.1.m1.1.1.m1.3.3.3.3.3.3.3.3.3.3.3.3">absent</csymbol></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p3.1.m1.1.1.m1.3c">144\text{\,}\mathrm{h}\text{/}</annotation></semantics></math> of real-world data and models trained from scratch on the same amount of real-world data. We hereby merge the directions of car and CV events and report, for each model, the average accuracy obtained in the 4 folds, together with accuracy ranges. The average accuracy per category obtained by fine-tuning on <math id="S3.p3.2.m2.1.1.m1.3" class="ltx_markedasmath" alttext="24\text{\,}\mathrm{h}\text{/}" display="inline"><semantics id="S3.p3.2.m2.1.1.m1.3a"><mrow id="S3.p3.2.m2.1.1.m1.3.3" xref="S3.p3.2.m2.1.1.m1.3.3.cmml"><mn id="S3.p3.2.m2.1.1.m1.1.1.1.1.1.1" xref="S3.p3.2.m2.1.1.m1.1.1.1.1.1.1.cmml">24</mn><mtext id="S3.p3.2.m2.1.1.m1.2.2.2.2.2.2" xref="S3.p3.2.m2.1.1.m1.2.2.2.2.2.2.cmml"> </mtext><mrow id="S3.p3.2.m2.1.1.m1.3.3.3.3.3.3" xref="S3.p3.2.m2.1.1.m1.3.3.3.3.3.3.cmml"><mi class="ltx_unit" mathvariant="normal" id="S3.p3.2.m2.1.1.m1.3.3.3.3.3.3.1.1.1.1.1.1" xref="S3.p3.2.m2.1.1.m1.3.3.3.3.3.3.1.1.1.1.1.1.cmml">h</mi><mtext id="S3.p3.2.m2.1.1.m1.3.3.3.3.3.3.2.2.2.2.2.2" xref="S3.p3.2.m2.1.1.m1.3.3.3.3.3.3.2.2.2.2.2.2.cmml">/</mtext><mi id="S3.p3.2.m2.1.1.m1.3.3.3.3.3.3.3.3.3.3.3.3" xref="S3.p3.2.m2.1.1.m1.3.3.3.3.3.3.3.3.3.3.3.3.cmml"></mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.p3.2.m2.1.1.m1.3b"><apply id="S3.p3.2.m2.1.1.m1.3.3.cmml" xref="S3.p3.2.m2.1.1.m1.3.3"><csymbol cd="latexml" id="S3.p3.2.m2.1.1.m1.2.2.2.2.2.2.cmml" xref="S3.p3.2.m2.1.1.m1.2.2.2.2.2.2">times</csymbol><cn type="integer" id="S3.p3.2.m2.1.1.m1.1.1.1.1.1.1.cmml" xref="S3.p3.2.m2.1.1.m1.1.1.1.1.1.1">24</cn><apply id="S3.p3.2.m2.1.1.m1.3.3.3.3.3.3.cmml" xref="S3.p3.2.m2.1.1.m1.3.3.3.3.3.3"><csymbol cd="latexml" id="S3.p3.2.m2.1.1.m1.3.3.3.3.3.3.2.2.2.2.2.2.cmml" xref="S3.p3.2.m2.1.1.m1.3.3.3.3.3.3.2.2.2.2.2.2">divide</csymbol><csymbol cd="latexml" id="S3.p3.2.m2.1.1.m1.3.3.3.3.3.3.1.1.1.1.1.1.cmml" xref="S3.p3.2.m2.1.1.m1.3.3.3.3.3.3.1.1.1.1.1.1">hour</csymbol><csymbol cd="latexml" id="S3.p3.2.m2.1.1.m1.3.3.3.3.3.3.3.3.3.3.3.3.cmml" xref="S3.p3.2.m2.1.1.m1.3.3.3.3.3.3.3.3.3.3.3.3">absent</csymbol></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p3.2.m2.1.1.m1.3c">24\text{\,}\mathrm{h}\text{/}</annotation></semantics></math> of real-world data (<math id="S3.p3.3.m3.1" class="ltx_Math" alttext="\text{FT}_{\text{24h}}" display="inline"><semantics id="S3.p3.3.m3.1a"><msub id="S3.p3.3.m3.1.1" xref="S3.p3.3.m3.1.1.cmml"><mtext id="S3.p3.3.m3.1.1.2" xref="S3.p3.3.m3.1.1.2a.cmml">FT</mtext><mtext id="S3.p3.3.m3.1.1.3" xref="S3.p3.3.m3.1.1.3a.cmml">24h</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.p3.3.m3.1b"><apply id="S3.p3.3.m3.1.1.cmml" xref="S3.p3.3.m3.1.1"><csymbol cd="ambiguous" id="S3.p3.3.m3.1.1.1.cmml" xref="S3.p3.3.m3.1.1">subscript</csymbol><ci id="S3.p3.3.m3.1.1.2a.cmml" xref="S3.p3.3.m3.1.1.2"><mtext id="S3.p3.3.m3.1.1.2.cmml" xref="S3.p3.3.m3.1.1.2">FT</mtext></ci><ci id="S3.p3.3.m3.1.1.3a.cmml" xref="S3.p3.3.m3.1.1.3"><mtext mathsize="70%" id="S3.p3.3.m3.1.1.3.cmml" xref="S3.p3.3.m3.1.1.3">24h</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p3.3.m3.1c">\text{FT}_{\text{24h}}</annotation></semantics></math>) reaches <math id="S3.p3.4.m4.4" class="ltx_Math" alttext="(0.88,0.89,0.95,0.94)" display="inline"><semantics id="S3.p3.4.m4.4a"><mrow id="S3.p3.4.m4.4.5.2" xref="S3.p3.4.m4.4.5.1.cmml"><mo stretchy="false" id="S3.p3.4.m4.4.5.2.1" xref="S3.p3.4.m4.4.5.1.cmml">(</mo><mn id="S3.p3.4.m4.1.1" xref="S3.p3.4.m4.1.1.cmml">0.88</mn><mo id="S3.p3.4.m4.4.5.2.2" xref="S3.p3.4.m4.4.5.1.cmml">,</mo><mn id="S3.p3.4.m4.2.2" xref="S3.p3.4.m4.2.2.cmml">0.89</mn><mo id="S3.p3.4.m4.4.5.2.3" xref="S3.p3.4.m4.4.5.1.cmml">,</mo><mn id="S3.p3.4.m4.3.3" xref="S3.p3.4.m4.3.3.cmml">0.95</mn><mo id="S3.p3.4.m4.4.5.2.4" xref="S3.p3.4.m4.4.5.1.cmml">,</mo><mn id="S3.p3.4.m4.4.4" xref="S3.p3.4.m4.4.4.cmml">0.94</mn><mo stretchy="false" id="S3.p3.4.m4.4.5.2.5" xref="S3.p3.4.m4.4.5.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.p3.4.m4.4b"><vector id="S3.p3.4.m4.4.5.1.cmml" xref="S3.p3.4.m4.4.5.2"><cn type="float" id="S3.p3.4.m4.1.1.cmml" xref="S3.p3.4.m4.1.1">0.88</cn><cn type="float" id="S3.p3.4.m4.2.2.cmml" xref="S3.p3.4.m4.2.2">0.89</cn><cn type="float" id="S3.p3.4.m4.3.3.cmml" xref="S3.p3.4.m4.3.3">0.95</cn><cn type="float" id="S3.p3.4.m4.4.4.cmml" xref="S3.p3.4.m4.4.4">0.94</cn></vector></annotation-xml><annotation encoding="application/x-tex" id="S3.p3.4.m4.4c">(0.88,0.89,0.95,0.94)</annotation></semantics></math> for (car-l2r, car-r2l, CV-l2r, CV-r2l) respectively, compared to <math id="S3.p3.5.m5.4" class="ltx_Math" alttext="(0.63,0.63,0.86,0.87)" display="inline"><semantics id="S3.p3.5.m5.4a"><mrow id="S3.p3.5.m5.4.5.2" xref="S3.p3.5.m5.4.5.1.cmml"><mo stretchy="false" id="S3.p3.5.m5.4.5.2.1" xref="S3.p3.5.m5.4.5.1.cmml">(</mo><mn id="S3.p3.5.m5.1.1" xref="S3.p3.5.m5.1.1.cmml">0.63</mn><mo id="S3.p3.5.m5.4.5.2.2" xref="S3.p3.5.m5.4.5.1.cmml">,</mo><mn id="S3.p3.5.m5.2.2" xref="S3.p3.5.m5.2.2.cmml">0.63</mn><mo id="S3.p3.5.m5.4.5.2.3" xref="S3.p3.5.m5.4.5.1.cmml">,</mo><mn id="S3.p3.5.m5.3.3" xref="S3.p3.5.m5.3.3.cmml">0.86</mn><mo id="S3.p3.5.m5.4.5.2.4" xref="S3.p3.5.m5.4.5.1.cmml">,</mo><mn id="S3.p3.5.m5.4.4" xref="S3.p3.5.m5.4.4.cmml">0.87</mn><mo stretchy="false" id="S3.p3.5.m5.4.5.2.5" xref="S3.p3.5.m5.4.5.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.p3.5.m5.4b"><vector id="S3.p3.5.m5.4.5.1.cmml" xref="S3.p3.5.m5.4.5.2"><cn type="float" id="S3.p3.5.m5.1.1.cmml" xref="S3.p3.5.m5.1.1">0.63</cn><cn type="float" id="S3.p3.5.m5.2.2.cmml" xref="S3.p3.5.m5.2.2">0.63</cn><cn type="float" id="S3.p3.5.m5.3.3.cmml" xref="S3.p3.5.m5.3.3">0.86</cn><cn type="float" id="S3.p3.5.m5.4.4.cmml" xref="S3.p3.5.m5.4.4">0.87</cn></vector></annotation-xml><annotation encoding="application/x-tex" id="S3.p3.5.m5.4c">(0.63,0.63,0.86,0.87)</annotation></semantics></math> obtained by training from scratch on real-world data only (<math id="S3.p3.6.m6.1" class="ltx_Math" alttext="\text{RW}_{\text{24h}}" display="inline"><semantics id="S3.p3.6.m6.1a"><msub id="S3.p3.6.m6.1.1" xref="S3.p3.6.m6.1.1.cmml"><mtext id="S3.p3.6.m6.1.1.2" xref="S3.p3.6.m6.1.1.2a.cmml">RW</mtext><mtext id="S3.p3.6.m6.1.1.3" xref="S3.p3.6.m6.1.1.3a.cmml">24h</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.p3.6.m6.1b"><apply id="S3.p3.6.m6.1.1.cmml" xref="S3.p3.6.m6.1.1"><csymbol cd="ambiguous" id="S3.p3.6.m6.1.1.1.cmml" xref="S3.p3.6.m6.1.1">subscript</csymbol><ci id="S3.p3.6.m6.1.1.2a.cmml" xref="S3.p3.6.m6.1.1.2"><mtext id="S3.p3.6.m6.1.1.2.cmml" xref="S3.p3.6.m6.1.1.2">RW</mtext></ci><ci id="S3.p3.6.m6.1.1.3a.cmml" xref="S3.p3.6.m6.1.1.3"><mtext mathsize="70%" id="S3.p3.6.m6.1.1.3.cmml" xref="S3.p3.6.m6.1.1.3">24h</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p3.6.m6.1c">\text{RW}_{\text{24h}}</annotation></semantics></math>), with an average increase in accuracy of <math id="S3.p3.7.m7.1" class="ltx_Math" alttext="0.25" display="inline"><semantics id="S3.p3.7.m7.1a"><mn id="S3.p3.7.m7.1.1" xref="S3.p3.7.m7.1.1.cmml">0.25</mn><annotation-xml encoding="MathML-Content" id="S3.p3.7.m7.1b"><cn type="float" id="S3.p3.7.m7.1.1.cmml" xref="S3.p3.7.m7.1.1">0.25</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.p3.7.m7.1c">0.25</annotation></semantics></math> for cars and <math id="S3.p3.8.m8.1" class="ltx_Math" alttext="0.08" display="inline"><semantics id="S3.p3.8.m8.1a"><mn id="S3.p3.8.m8.1.1" xref="S3.p3.8.m8.1.1.cmml">0.08</mn><annotation-xml encoding="MathML-Content" id="S3.p3.8.m8.1b"><cn type="float" id="S3.p3.8.m8.1.1.cmml" xref="S3.p3.8.m8.1.1">0.08</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.p3.8.m8.1c">0.08</annotation></semantics></math> for CVs. A comparable accuracy requires <span id="S3.p3.9.1" class="ltx_text" style="color:#000000;">between <math id="S3.p3.9.1.m1.1.1.m1.3" class="ltx_markedasmath" alttext="72\text{\,}\mathrm{h}\text{/}" display="inline"><semantics id="S3.p3.9.1.m1.1.1.m1.3a"><mrow id="S3.p3.9.1.m1.1.1.m1.3.3" xref="S3.p3.9.1.m1.1.1.m1.3.3.cmml"><mn mathcolor="#000000" id="S3.p3.9.1.m1.1.1.m1.1.1.1.1.1.1" xref="S3.p3.9.1.m1.1.1.m1.1.1.1.1.1.1.cmml">72</mn><mtext mathcolor="#000000" id="S3.p3.9.1.m1.1.1.m1.2.2.2.2.2.2" xref="S3.p3.9.1.m1.1.1.m1.2.2.2.2.2.2.cmml"> </mtext><mrow id="S3.p3.9.1.m1.1.1.m1.3.3.3.3.3.3" xref="S3.p3.9.1.m1.1.1.m1.3.3.3.3.3.3.cmml"><mi class="ltx_unit" mathcolor="#000000" mathvariant="normal" id="S3.p3.9.1.m1.1.1.m1.3.3.3.3.3.3.1.1.1.1.1.1" xref="S3.p3.9.1.m1.1.1.m1.3.3.3.3.3.3.1.1.1.1.1.1.cmml">h</mi><mtext mathcolor="#000000" id="S3.p3.9.1.m1.1.1.m1.3.3.3.3.3.3.2.2.2.2.2.2" xref="S3.p3.9.1.m1.1.1.m1.3.3.3.3.3.3.2.2.2.2.2.2.cmml">/</mtext><mi id="S3.p3.9.1.m1.1.1.m1.3.3.3.3.3.3.3.3.3.3.3.3" xref="S3.p3.9.1.m1.1.1.m1.3.3.3.3.3.3.3.3.3.3.3.3.cmml"></mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.p3.9.1.m1.1.1.m1.3b"><apply id="S3.p3.9.1.m1.1.1.m1.3.3.cmml" xref="S3.p3.9.1.m1.1.1.m1.3.3"><csymbol cd="latexml" id="S3.p3.9.1.m1.1.1.m1.2.2.2.2.2.2.cmml" xref="S3.p3.9.1.m1.1.1.m1.2.2.2.2.2.2">times</csymbol><cn type="integer" id="S3.p3.9.1.m1.1.1.m1.1.1.1.1.1.1.cmml" xref="S3.p3.9.1.m1.1.1.m1.1.1.1.1.1.1">72</cn><apply id="S3.p3.9.1.m1.1.1.m1.3.3.3.3.3.3.cmml" xref="S3.p3.9.1.m1.1.1.m1.3.3.3.3.3.3"><csymbol cd="latexml" id="S3.p3.9.1.m1.1.1.m1.3.3.3.3.3.3.2.2.2.2.2.2.cmml" xref="S3.p3.9.1.m1.1.1.m1.3.3.3.3.3.3.2.2.2.2.2.2">divide</csymbol><csymbol cd="latexml" id="S3.p3.9.1.m1.1.1.m1.3.3.3.3.3.3.1.1.1.1.1.1.cmml" xref="S3.p3.9.1.m1.1.1.m1.3.3.3.3.3.3.1.1.1.1.1.1">hour</csymbol><csymbol cd="latexml" id="S3.p3.9.1.m1.1.1.m1.3.3.3.3.3.3.3.3.3.3.3.3.cmml" xref="S3.p3.9.1.m1.1.1.m1.3.3.3.3.3.3.3.3.3.3.3.3">absent</csymbol></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p3.9.1.m1.1.1.m1.3c">72\text{\,}\mathrm{h}\text{/}</annotation></semantics></math> and</span> <math id="S3.p3.10.m9.1.1.m1.3" class="ltx_markedasmath" alttext="144\text{\,}\mathrm{h}\text{/}" display="inline"><semantics id="S3.p3.10.m9.1.1.m1.3a"><mrow id="S3.p3.10.m9.1.1.m1.3.3" xref="S3.p3.10.m9.1.1.m1.3.3.cmml"><mn id="S3.p3.10.m9.1.1.m1.1.1.1.1.1.1" xref="S3.p3.10.m9.1.1.m1.1.1.1.1.1.1.cmml">144</mn><mtext id="S3.p3.10.m9.1.1.m1.2.2.2.2.2.2" xref="S3.p3.10.m9.1.1.m1.2.2.2.2.2.2.cmml"> </mtext><mrow id="S3.p3.10.m9.1.1.m1.3.3.3.3.3.3" xref="S3.p3.10.m9.1.1.m1.3.3.3.3.3.3.cmml"><mi class="ltx_unit" mathvariant="normal" id="S3.p3.10.m9.1.1.m1.3.3.3.3.3.3.1.1.1.1.1.1" xref="S3.p3.10.m9.1.1.m1.3.3.3.3.3.3.1.1.1.1.1.1.cmml">h</mi><mtext id="S3.p3.10.m9.1.1.m1.3.3.3.3.3.3.2.2.2.2.2.2" xref="S3.p3.10.m9.1.1.m1.3.3.3.3.3.3.2.2.2.2.2.2.cmml">/</mtext><mi id="S3.p3.10.m9.1.1.m1.3.3.3.3.3.3.3.3.3.3.3.3" xref="S3.p3.10.m9.1.1.m1.3.3.3.3.3.3.3.3.3.3.3.3.cmml"></mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.p3.10.m9.1.1.m1.3b"><apply id="S3.p3.10.m9.1.1.m1.3.3.cmml" xref="S3.p3.10.m9.1.1.m1.3.3"><csymbol cd="latexml" id="S3.p3.10.m9.1.1.m1.2.2.2.2.2.2.cmml" xref="S3.p3.10.m9.1.1.m1.2.2.2.2.2.2">times</csymbol><cn type="integer" id="S3.p3.10.m9.1.1.m1.1.1.1.1.1.1.cmml" xref="S3.p3.10.m9.1.1.m1.1.1.1.1.1.1">144</cn><apply id="S3.p3.10.m9.1.1.m1.3.3.3.3.3.3.cmml" xref="S3.p3.10.m9.1.1.m1.3.3.3.3.3.3"><csymbol cd="latexml" id="S3.p3.10.m9.1.1.m1.3.3.3.3.3.3.2.2.2.2.2.2.cmml" xref="S3.p3.10.m9.1.1.m1.3.3.3.3.3.3.2.2.2.2.2.2">divide</csymbol><csymbol cd="latexml" id="S3.p3.10.m9.1.1.m1.3.3.3.3.3.3.1.1.1.1.1.1.cmml" xref="S3.p3.10.m9.1.1.m1.3.3.3.3.3.3.1.1.1.1.1.1">hour</csymbol><csymbol cd="latexml" id="S3.p3.10.m9.1.1.m1.3.3.3.3.3.3.3.3.3.3.3.3.cmml" xref="S3.p3.10.m9.1.1.m1.3.3.3.3.3.3.3.3.3.3.3.3">absent</csymbol></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p3.10.m9.1.1.m1.3c">144\text{\,}\mathrm{h}\text{/}</annotation></semantics></math> of real-world data.
Fig. <a href="#S2.F5" title="Figure 5 ‣ 2.2 CRNN Architecture ‣ 2 Methodology ‣ Can Synthetic Data Boost the Training of Deep Acoustic Vehicle Counting Networks?" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> also shows that fine-tuning with <math id="S3.p3.11.m10.1.1.m1.3" class="ltx_markedasmath" alttext="12\text{\,}\mathrm{h}\text{/}" display="inline"><semantics id="S3.p3.11.m10.1.1.m1.3a"><mrow id="S3.p3.11.m10.1.1.m1.3.3" xref="S3.p3.11.m10.1.1.m1.3.3.cmml"><mn mathcolor="#000000" id="S3.p3.11.m10.1.1.m1.1.1.1.1.1.1" xref="S3.p3.11.m10.1.1.m1.1.1.1.1.1.1.cmml">12</mn><mtext mathcolor="#000000" id="S3.p3.11.m10.1.1.m1.2.2.2.2.2.2" xref="S3.p3.11.m10.1.1.m1.2.2.2.2.2.2.cmml"> </mtext><mrow id="S3.p3.11.m10.1.1.m1.3.3.3.3.3.3" xref="S3.p3.11.m10.1.1.m1.3.3.3.3.3.3.cmml"><mi class="ltx_unit" mathcolor="#000000" mathvariant="normal" id="S3.p3.11.m10.1.1.m1.3.3.3.3.3.3.1.1.1.1.1.1" xref="S3.p3.11.m10.1.1.m1.3.3.3.3.3.3.1.1.1.1.1.1.cmml">h</mi><mtext mathcolor="#000000" id="S3.p3.11.m10.1.1.m1.3.3.3.3.3.3.2.2.2.2.2.2" xref="S3.p3.11.m10.1.1.m1.3.3.3.3.3.3.2.2.2.2.2.2.cmml">/</mtext><mi id="S3.p3.11.m10.1.1.m1.3.3.3.3.3.3.3.3.3.3.3.3" xref="S3.p3.11.m10.1.1.m1.3.3.3.3.3.3.3.3.3.3.3.3.cmml"></mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.p3.11.m10.1.1.m1.3b"><apply id="S3.p3.11.m10.1.1.m1.3.3.cmml" xref="S3.p3.11.m10.1.1.m1.3.3"><csymbol cd="latexml" id="S3.p3.11.m10.1.1.m1.2.2.2.2.2.2.cmml" xref="S3.p3.11.m10.1.1.m1.2.2.2.2.2.2">times</csymbol><cn type="integer" id="S3.p3.11.m10.1.1.m1.1.1.1.1.1.1.cmml" xref="S3.p3.11.m10.1.1.m1.1.1.1.1.1.1">12</cn><apply id="S3.p3.11.m10.1.1.m1.3.3.3.3.3.3.cmml" xref="S3.p3.11.m10.1.1.m1.3.3.3.3.3.3"><csymbol cd="latexml" id="S3.p3.11.m10.1.1.m1.3.3.3.3.3.3.2.2.2.2.2.2.cmml" xref="S3.p3.11.m10.1.1.m1.3.3.3.3.3.3.2.2.2.2.2.2">divide</csymbol><csymbol cd="latexml" id="S3.p3.11.m10.1.1.m1.3.3.3.3.3.3.1.1.1.1.1.1.cmml" xref="S3.p3.11.m10.1.1.m1.3.3.3.3.3.3.1.1.1.1.1.1">hour</csymbol><csymbol cd="latexml" id="S3.p3.11.m10.1.1.m1.3.3.3.3.3.3.3.3.3.3.3.3.cmml" xref="S3.p3.11.m10.1.1.m1.3.3.3.3.3.3.3.3.3.3.3.3">absent</csymbol></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p3.11.m10.1.1.m1.3c">12\text{\,}\mathrm{h}\text{/}</annotation></semantics></math><span id="S3.p3.11.2" class="ltx_text" style="color:#000000;"> or more leads to a significant reduction in accuracy variation across folds, indicating that fine-tuning a model pre-conditioned to understand traffic is more stable than training from scratch on the same amount of data.</span></p>
</div>
<div id="S3.p4" class="ltx_para">
<p id="S3.p4.13" class="ltx_p">We finally evaluate the average miscount when the model predicts a wrong count. Here, we compute the mean absolute error on the misclassified samples only (<math id="S3.p4.1.m1.1" class="ltx_Math" alttext="\text{MAE}_{\text{mis}}" display="inline"><semantics id="S3.p4.1.m1.1a"><msub id="S3.p4.1.m1.1.1" xref="S3.p4.1.m1.1.1.cmml"><mtext id="S3.p4.1.m1.1.1.2" xref="S3.p4.1.m1.1.1.2a.cmml">MAE</mtext><mtext id="S3.p4.1.m1.1.1.3" xref="S3.p4.1.m1.1.1.3a.cmml">mis</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.p4.1.m1.1b"><apply id="S3.p4.1.m1.1.1.cmml" xref="S3.p4.1.m1.1.1"><csymbol cd="ambiguous" id="S3.p4.1.m1.1.1.1.cmml" xref="S3.p4.1.m1.1.1">subscript</csymbol><ci id="S3.p4.1.m1.1.1.2a.cmml" xref="S3.p4.1.m1.1.1.2"><mtext id="S3.p4.1.m1.1.1.2.cmml" xref="S3.p4.1.m1.1.1.2">MAE</mtext></ci><ci id="S3.p4.1.m1.1.1.3a.cmml" xref="S3.p4.1.m1.1.1.3"><mtext mathsize="70%" id="S3.p4.1.m1.1.1.3.cmml" xref="S3.p4.1.m1.1.1.3">mis</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p4.1.m1.1c">\text{MAE}_{\text{mis}}</annotation></semantics></math>), measuring by how much the prediction differs from the ground truth. It is worth noting that the lower bound for <math id="S3.p4.2.m2.1" class="ltx_Math" alttext="\text{MAE}_{\text{mis}}" display="inline"><semantics id="S3.p4.2.m2.1a"><msub id="S3.p4.2.m2.1.1" xref="S3.p4.2.m2.1.1.cmml"><mtext id="S3.p4.2.m2.1.1.2" xref="S3.p4.2.m2.1.1.2a.cmml">MAE</mtext><mtext id="S3.p4.2.m2.1.1.3" xref="S3.p4.2.m2.1.1.3a.cmml">mis</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.p4.2.m2.1b"><apply id="S3.p4.2.m2.1.1.cmml" xref="S3.p4.2.m2.1.1"><csymbol cd="ambiguous" id="S3.p4.2.m2.1.1.1.cmml" xref="S3.p4.2.m2.1.1">subscript</csymbol><ci id="S3.p4.2.m2.1.1.2a.cmml" xref="S3.p4.2.m2.1.1.2"><mtext id="S3.p4.2.m2.1.1.2.cmml" xref="S3.p4.2.m2.1.1.2">MAE</mtext></ci><ci id="S3.p4.2.m2.1.1.3a.cmml" xref="S3.p4.2.m2.1.1.3"><mtext mathsize="70%" id="S3.p4.2.m2.1.1.3.cmml" xref="S3.p4.2.m2.1.1.3">mis</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p4.2.m2.1c">\text{MAE}_{\text{mis}}</annotation></semantics></math> is <math id="S3.p4.3.m3.1" class="ltx_Math" alttext="1" display="inline"><semantics id="S3.p4.3.m3.1a"><mn id="S3.p4.3.m3.1.1" xref="S3.p4.3.m3.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="S3.p4.3.m3.1b"><cn type="integer" id="S3.p4.3.m3.1.1.cmml" xref="S3.p4.3.m3.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.p4.3.m3.1c">1</annotation></semantics></math>.
In Tab. <a href="#S3.T1" title="Table 1 ‣ 3 Experimental Evaluation ‣ Can Synthetic Data Boost the Training of Deep Acoustic Vehicle Counting Networks?" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> we report both accuracy and <math id="S3.p4.4.m4.1" class="ltx_Math" alttext="\text{MAE}_{\text{mis}}" display="inline"><semantics id="S3.p4.4.m4.1a"><msub id="S3.p4.4.m4.1.1" xref="S3.p4.4.m4.1.1.cmml"><mtext id="S3.p4.4.m4.1.1.2" xref="S3.p4.4.m4.1.1.2a.cmml">MAE</mtext><mtext id="S3.p4.4.m4.1.1.3" xref="S3.p4.4.m4.1.1.3a.cmml">mis</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.p4.4.m4.1b"><apply id="S3.p4.4.m4.1.1.cmml" xref="S3.p4.4.m4.1.1"><csymbol cd="ambiguous" id="S3.p4.4.m4.1.1.1.cmml" xref="S3.p4.4.m4.1.1">subscript</csymbol><ci id="S3.p4.4.m4.1.1.2a.cmml" xref="S3.p4.4.m4.1.1.2"><mtext id="S3.p4.4.m4.1.1.2.cmml" xref="S3.p4.4.m4.1.1.2">MAE</mtext></ci><ci id="S3.p4.4.m4.1.1.3a.cmml" xref="S3.p4.4.m4.1.1.3"><mtext mathsize="70%" id="S3.p4.4.m4.1.1.3.cmml" xref="S3.p4.4.m4.1.1.3">mis</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p4.4.m4.1c">\text{MAE}_{\text{mis}}</annotation></semantics></math> for each model trained from scratch (<span id="S3.p4.13.1" class="ltx_text ltx_markedasmath">RW</span>) and fine-tuned (<span id="S3.p4.13.2" class="ltx_text ltx_markedasmath">FT</span>). By comparing <math id="S3.p4.7.m7.1" class="ltx_Math" alttext="\text{RW}_{\text{24h}}" display="inline"><semantics id="S3.p4.7.m7.1a"><msub id="S3.p4.7.m7.1.1" xref="S3.p4.7.m7.1.1.cmml"><mtext id="S3.p4.7.m7.1.1.2" xref="S3.p4.7.m7.1.1.2a.cmml">RW</mtext><mtext id="S3.p4.7.m7.1.1.3" xref="S3.p4.7.m7.1.1.3a.cmml">24h</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.p4.7.m7.1b"><apply id="S3.p4.7.m7.1.1.cmml" xref="S3.p4.7.m7.1.1"><csymbol cd="ambiguous" id="S3.p4.7.m7.1.1.1.cmml" xref="S3.p4.7.m7.1.1">subscript</csymbol><ci id="S3.p4.7.m7.1.1.2a.cmml" xref="S3.p4.7.m7.1.1.2"><mtext id="S3.p4.7.m7.1.1.2.cmml" xref="S3.p4.7.m7.1.1.2">RW</mtext></ci><ci id="S3.p4.7.m7.1.1.3a.cmml" xref="S3.p4.7.m7.1.1.3"><mtext mathsize="70%" id="S3.p4.7.m7.1.1.3.cmml" xref="S3.p4.7.m7.1.1.3">24h</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p4.7.m7.1c">\text{RW}_{\text{24h}}</annotation></semantics></math> with <math id="S3.p4.8.m8.1" class="ltx_Math" alttext="\text{FT}_{\text{24h}}" display="inline"><semantics id="S3.p4.8.m8.1a"><msub id="S3.p4.8.m8.1.1" xref="S3.p4.8.m8.1.1.cmml"><mtext id="S3.p4.8.m8.1.1.2" xref="S3.p4.8.m8.1.1.2a.cmml">FT</mtext><mtext id="S3.p4.8.m8.1.1.3" xref="S3.p4.8.m8.1.1.3a.cmml">24h</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.p4.8.m8.1b"><apply id="S3.p4.8.m8.1.1.cmml" xref="S3.p4.8.m8.1.1"><csymbol cd="ambiguous" id="S3.p4.8.m8.1.1.1.cmml" xref="S3.p4.8.m8.1.1">subscript</csymbol><ci id="S3.p4.8.m8.1.1.2a.cmml" xref="S3.p4.8.m8.1.1.2"><mtext id="S3.p4.8.m8.1.1.2.cmml" xref="S3.p4.8.m8.1.1.2">FT</mtext></ci><ci id="S3.p4.8.m8.1.1.3a.cmml" xref="S3.p4.8.m8.1.1.3"><mtext mathsize="70%" id="S3.p4.8.m8.1.1.3.cmml" xref="S3.p4.8.m8.1.1.3">24h</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p4.8.m8.1c">\text{FT}_{\text{24h}}</annotation></semantics></math>, we see that the increase in accuracy (<math id="S3.p4.9.m9.1" class="ltx_Math" alttext="+0.25" display="inline"><semantics id="S3.p4.9.m9.1a"><mrow id="S3.p4.9.m9.1.1" xref="S3.p4.9.m9.1.1.cmml"><mo id="S3.p4.9.m9.1.1a" xref="S3.p4.9.m9.1.1.cmml">+</mo><mn id="S3.p4.9.m9.1.1.2" xref="S3.p4.9.m9.1.1.2.cmml">0.25</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.p4.9.m9.1b"><apply id="S3.p4.9.m9.1.1.cmml" xref="S3.p4.9.m9.1.1"><plus id="S3.p4.9.m9.1.1.1.cmml" xref="S3.p4.9.m9.1.1"></plus><cn type="float" id="S3.p4.9.m9.1.1.2.cmml" xref="S3.p4.9.m9.1.1.2">0.25</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p4.9.m9.1c">+0.25</annotation></semantics></math> for cars, <math id="S3.p4.10.m10.1" class="ltx_Math" alttext="+0.08" display="inline"><semantics id="S3.p4.10.m10.1a"><mrow id="S3.p4.10.m10.1.1" xref="S3.p4.10.m10.1.1.cmml"><mo id="S3.p4.10.m10.1.1a" xref="S3.p4.10.m10.1.1.cmml">+</mo><mn id="S3.p4.10.m10.1.1.2" xref="S3.p4.10.m10.1.1.2.cmml">0.08</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.p4.10.m10.1b"><apply id="S3.p4.10.m10.1.1.cmml" xref="S3.p4.10.m10.1.1"><plus id="S3.p4.10.m10.1.1.1.cmml" xref="S3.p4.10.m10.1.1"></plus><cn type="float" id="S3.p4.10.m10.1.1.2.cmml" xref="S3.p4.10.m10.1.1.2">0.08</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p4.10.m10.1c">+0.08</annotation></semantics></math> for commercial vehicles) is accompanied by a significant reduction in <math id="S3.p4.11.m11.1" class="ltx_Math" alttext="\text{MAE}_{\text{mis}}" display="inline"><semantics id="S3.p4.11.m11.1a"><msub id="S3.p4.11.m11.1.1" xref="S3.p4.11.m11.1.1.cmml"><mtext id="S3.p4.11.m11.1.1.2" xref="S3.p4.11.m11.1.1.2a.cmml">MAE</mtext><mtext id="S3.p4.11.m11.1.1.3" xref="S3.p4.11.m11.1.1.3a.cmml">mis</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.p4.11.m11.1b"><apply id="S3.p4.11.m11.1.1.cmml" xref="S3.p4.11.m11.1.1"><csymbol cd="ambiguous" id="S3.p4.11.m11.1.1.1.cmml" xref="S3.p4.11.m11.1.1">subscript</csymbol><ci id="S3.p4.11.m11.1.1.2a.cmml" xref="S3.p4.11.m11.1.1.2"><mtext id="S3.p4.11.m11.1.1.2.cmml" xref="S3.p4.11.m11.1.1.2">MAE</mtext></ci><ci id="S3.p4.11.m11.1.1.3a.cmml" xref="S3.p4.11.m11.1.1.3"><mtext mathsize="70%" id="S3.p4.11.m11.1.1.3.cmml" xref="S3.p4.11.m11.1.1.3">mis</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p4.11.m11.1c">\text{MAE}_{\text{mis}}</annotation></semantics></math> (<math id="S3.p4.12.m12.1" class="ltx_Math" alttext="-0.10" display="inline"><semantics id="S3.p4.12.m12.1a"><mrow id="S3.p4.12.m12.1.1" xref="S3.p4.12.m12.1.1.cmml"><mo id="S3.p4.12.m12.1.1a" xref="S3.p4.12.m12.1.1.cmml">−</mo><mn id="S3.p4.12.m12.1.1.2" xref="S3.p4.12.m12.1.1.2.cmml">0.10</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.p4.12.m12.1b"><apply id="S3.p4.12.m12.1.1.cmml" xref="S3.p4.12.m12.1.1"><minus id="S3.p4.12.m12.1.1.1.cmml" xref="S3.p4.12.m12.1.1"></minus><cn type="float" id="S3.p4.12.m12.1.1.2.cmml" xref="S3.p4.12.m12.1.1.2">0.10</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p4.12.m12.1c">-0.10</annotation></semantics></math> for both cars and commercial vehicles). This clearly shows the effectiveness of synthetic pre-training, allowing the <math id="S3.p4.13.m13.1" class="ltx_Math" alttext="\text{FT}_{\text{24h}}" display="inline"><semantics id="S3.p4.13.m13.1a"><msub id="S3.p4.13.m13.1.1" xref="S3.p4.13.m13.1.1.cmml"><mtext id="S3.p4.13.m13.1.1.2" xref="S3.p4.13.m13.1.1.2a.cmml">FT</mtext><mtext id="S3.p4.13.m13.1.1.3" xref="S3.p4.13.m13.1.1.3a.cmml">24h</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.p4.13.m13.1b"><apply id="S3.p4.13.m13.1.1.cmml" xref="S3.p4.13.m13.1.1"><csymbol cd="ambiguous" id="S3.p4.13.m13.1.1.1.cmml" xref="S3.p4.13.m13.1.1">subscript</csymbol><ci id="S3.p4.13.m13.1.1.2a.cmml" xref="S3.p4.13.m13.1.1.2"><mtext id="S3.p4.13.m13.1.1.2.cmml" xref="S3.p4.13.m13.1.1.2">FT</mtext></ci><ci id="S3.p4.13.m13.1.1.3a.cmml" xref="S3.p4.13.m13.1.1.3"><mtext mathsize="70%" id="S3.p4.13.m13.1.1.3.cmml" xref="S3.p4.13.m13.1.1.3">24h</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p4.13.m13.1c">\text{FT}_{\text{24h}}</annotation></semantics></math> to perform with high accuracy and low deviation in traffic counting.</p>
</div>
<figure id="S3.T1" class="ltx_table">
<table id="S3.T1.11" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S3.T1.1.1" class="ltx_tr">
<td id="S3.T1.1.1.2" class="ltx_td ltx_border_tt" style="padding-top:-0.5pt;padding-bottom:-0.5pt;" rowspan="2"></td>
<td id="S3.T1.1.1.3" class="ltx_td ltx_align_center ltx_border_tt" style="padding-top:-0.5pt;padding-bottom:-0.5pt;" colspan="2">Accuracy</td>
<td id="S3.T1.1.1.1" class="ltx_td ltx_align_center ltx_border_tt" style="padding-top:-0.5pt;padding-bottom:-0.5pt;" colspan="2"><math id="S3.T1.1.1.1.m1.1" class="ltx_Math" alttext="\text{MAE}_{\text{mis}}" display="inline"><semantics id="S3.T1.1.1.1.m1.1a"><msub id="S3.T1.1.1.1.m1.1.1" xref="S3.T1.1.1.1.m1.1.1.cmml"><mtext id="S3.T1.1.1.1.m1.1.1.2" xref="S3.T1.1.1.1.m1.1.1.2a.cmml">MAE</mtext><mtext id="S3.T1.1.1.1.m1.1.1.3" xref="S3.T1.1.1.1.m1.1.1.3a.cmml">mis</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.T1.1.1.1.m1.1b"><apply id="S3.T1.1.1.1.m1.1.1.cmml" xref="S3.T1.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.T1.1.1.1.m1.1.1.1.cmml" xref="S3.T1.1.1.1.m1.1.1">subscript</csymbol><ci id="S3.T1.1.1.1.m1.1.1.2a.cmml" xref="S3.T1.1.1.1.m1.1.1.2"><mtext id="S3.T1.1.1.1.m1.1.1.2.cmml" xref="S3.T1.1.1.1.m1.1.1.2">MAE</mtext></ci><ci id="S3.T1.1.1.1.m1.1.1.3a.cmml" xref="S3.T1.1.1.1.m1.1.1.3"><mtext mathsize="70%" id="S3.T1.1.1.1.m1.1.1.3.cmml" xref="S3.T1.1.1.1.m1.1.1.3">mis</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.1.1.1.m1.1c">\text{MAE}_{\text{mis}}</annotation></semantics></math></td>
<td id="S3.T1.1.1.4" class="ltx_td ltx_align_center ltx_border_tt" style="padding-top:-0.5pt;padding-bottom:-0.5pt;">Real-world data</td>
</tr>
<tr id="S3.T1.11.12.1" class="ltx_tr">
<td id="S3.T1.11.12.1.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:-0.5pt;padding-bottom:-0.5pt;">car</td>
<td id="S3.T1.11.12.1.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:-0.5pt;padding-bottom:-0.5pt;">CV</td>
<td id="S3.T1.11.12.1.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:-0.5pt;padding-bottom:-0.5pt;">car</td>
<td id="S3.T1.11.12.1.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:-0.5pt;padding-bottom:-0.5pt;">CV</td>
<td id="S3.T1.11.12.1.5" class="ltx_td" style="padding-top:-0.5pt;padding-bottom:-0.5pt;"></td>
</tr>
<tr id="S3.T1.3.3" class="ltx_tr">
<td id="S3.T1.2.2.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:-0.5pt;padding-bottom:-0.5pt;"><math id="S3.T1.2.2.1.m1.1" class="ltx_Math" alttext="\text{RW}_{\text{144h}}" display="inline"><semantics id="S3.T1.2.2.1.m1.1a"><msub id="S3.T1.2.2.1.m1.1.1" xref="S3.T1.2.2.1.m1.1.1.cmml"><mtext id="S3.T1.2.2.1.m1.1.1.2" xref="S3.T1.2.2.1.m1.1.1.2a.cmml">RW</mtext><mtext id="S3.T1.2.2.1.m1.1.1.3" xref="S3.T1.2.2.1.m1.1.1.3a.cmml">144h</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.T1.2.2.1.m1.1b"><apply id="S3.T1.2.2.1.m1.1.1.cmml" xref="S3.T1.2.2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.T1.2.2.1.m1.1.1.1.cmml" xref="S3.T1.2.2.1.m1.1.1">subscript</csymbol><ci id="S3.T1.2.2.1.m1.1.1.2a.cmml" xref="S3.T1.2.2.1.m1.1.1.2"><mtext id="S3.T1.2.2.1.m1.1.1.2.cmml" xref="S3.T1.2.2.1.m1.1.1.2">RW</mtext></ci><ci id="S3.T1.2.2.1.m1.1.1.3a.cmml" xref="S3.T1.2.2.1.m1.1.1.3"><mtext mathsize="70%" id="S3.T1.2.2.1.m1.1.1.3.cmml" xref="S3.T1.2.2.1.m1.1.1.3">144h</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.2.2.1.m1.1c">\text{RW}_{\text{144h}}</annotation></semantics></math></td>
<td id="S3.T1.3.3.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:-0.5pt;padding-bottom:-0.5pt;">0.91</td>
<td id="S3.T1.3.3.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:-0.5pt;padding-bottom:-0.5pt;">0.96</td>
<td id="S3.T1.3.3.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:-0.5pt;padding-bottom:-0.5pt;">1.04</td>
<td id="S3.T1.3.3.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:-0.5pt;padding-bottom:-0.5pt;">1.04</td>
<td id="S3.T1.3.3.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:-0.5pt;padding-bottom:-0.5pt;"><math id="S3.T1.3.3.2.m1.1.1.m1.3" class="ltx_markedasmath" alttext="144\text{\,}\mathrm{h}" display="inline"><semantics id="S3.T1.3.3.2.m1.1.1.m1.3a"><mrow id="S3.T1.3.3.2.m1.1.1.m1.3.3" xref="S3.T1.3.3.2.m1.1.1.m1.3.3.cmml"><mn id="S3.T1.3.3.2.m1.1.1.m1.1.1.1.1.1.1" xref="S3.T1.3.3.2.m1.1.1.m1.1.1.1.1.1.1.cmml">144</mn><mtext id="S3.T1.3.3.2.m1.1.1.m1.2.2.2.2.2.2" xref="S3.T1.3.3.2.m1.1.1.m1.2.2.2.2.2.2.cmml"> </mtext><mi mathvariant="normal" id="S3.T1.3.3.2.m1.1.1.m1.3.3.3.3.3.3" xref="S3.T1.3.3.2.m1.1.1.m1.3.3.3.3.3.3.cmml">h</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.T1.3.3.2.m1.1.1.m1.3b"><apply id="S3.T1.3.3.2.m1.1.1.m1.3.3.cmml" xref="S3.T1.3.3.2.m1.1.1.m1.3.3"><csymbol cd="latexml" id="S3.T1.3.3.2.m1.1.1.m1.2.2.2.2.2.2.cmml" xref="S3.T1.3.3.2.m1.1.1.m1.2.2.2.2.2.2">times</csymbol><cn type="integer" id="S3.T1.3.3.2.m1.1.1.m1.1.1.1.1.1.1.cmml" xref="S3.T1.3.3.2.m1.1.1.m1.1.1.1.1.1.1">144</cn><ci id="S3.T1.3.3.2.m1.1.1.m1.3.3.3.3.3.3.cmml" xref="S3.T1.3.3.2.m1.1.1.m1.3.3.3.3.3.3">h</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.3.3.2.m1.1.1.m1.3c">144\text{\,}\mathrm{h}</annotation></semantics></math></td>
</tr>
<tr id="S3.T1.5.5" class="ltx_tr">
<td id="S3.T1.4.4.1" class="ltx_td ltx_align_center" style="padding-top:-0.5pt;padding-bottom:-0.5pt;"><math id="S3.T1.4.4.1.m1.1" class="ltx_Math" alttext="\text{RW}_{\text{24h}}" display="inline"><semantics id="S3.T1.4.4.1.m1.1a"><msub id="S3.T1.4.4.1.m1.1.1" xref="S3.T1.4.4.1.m1.1.1.cmml"><mtext id="S3.T1.4.4.1.m1.1.1.2" xref="S3.T1.4.4.1.m1.1.1.2a.cmml">RW</mtext><mtext id="S3.T1.4.4.1.m1.1.1.3" xref="S3.T1.4.4.1.m1.1.1.3a.cmml">24h</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.T1.4.4.1.m1.1b"><apply id="S3.T1.4.4.1.m1.1.1.cmml" xref="S3.T1.4.4.1.m1.1.1"><csymbol cd="ambiguous" id="S3.T1.4.4.1.m1.1.1.1.cmml" xref="S3.T1.4.4.1.m1.1.1">subscript</csymbol><ci id="S3.T1.4.4.1.m1.1.1.2a.cmml" xref="S3.T1.4.4.1.m1.1.1.2"><mtext id="S3.T1.4.4.1.m1.1.1.2.cmml" xref="S3.T1.4.4.1.m1.1.1.2">RW</mtext></ci><ci id="S3.T1.4.4.1.m1.1.1.3a.cmml" xref="S3.T1.4.4.1.m1.1.1.3"><mtext mathsize="70%" id="S3.T1.4.4.1.m1.1.1.3.cmml" xref="S3.T1.4.4.1.m1.1.1.3">24h</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.4.4.1.m1.1c">\text{RW}_{\text{24h}}</annotation></semantics></math></td>
<td id="S3.T1.5.5.3" class="ltx_td ltx_align_center" style="padding-top:-0.5pt;padding-bottom:-0.5pt;">0.63</td>
<td id="S3.T1.5.5.4" class="ltx_td ltx_align_center" style="padding-top:-0.5pt;padding-bottom:-0.5pt;">0.86</td>
<td id="S3.T1.5.5.5" class="ltx_td ltx_align_center" style="padding-top:-0.5pt;padding-bottom:-0.5pt;">1.16</td>
<td id="S3.T1.5.5.6" class="ltx_td ltx_align_center" style="padding-top:-0.5pt;padding-bottom:-0.5pt;">1.13</td>
<td id="S3.T1.5.5.2" class="ltx_td ltx_align_center" style="padding-top:-0.5pt;padding-bottom:-0.5pt;"><math id="S3.T1.5.5.2.m1.1.1.m1.3" class="ltx_markedasmath" alttext="24\text{\,}\mathrm{h}" display="inline"><semantics id="S3.T1.5.5.2.m1.1.1.m1.3a"><mrow id="S3.T1.5.5.2.m1.1.1.m1.3.3" xref="S3.T1.5.5.2.m1.1.1.m1.3.3.cmml"><mn id="S3.T1.5.5.2.m1.1.1.m1.1.1.1.1.1.1" xref="S3.T1.5.5.2.m1.1.1.m1.1.1.1.1.1.1.cmml">24</mn><mtext id="S3.T1.5.5.2.m1.1.1.m1.2.2.2.2.2.2" xref="S3.T1.5.5.2.m1.1.1.m1.2.2.2.2.2.2.cmml"> </mtext><mi mathvariant="normal" id="S3.T1.5.5.2.m1.1.1.m1.3.3.3.3.3.3" xref="S3.T1.5.5.2.m1.1.1.m1.3.3.3.3.3.3.cmml">h</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.T1.5.5.2.m1.1.1.m1.3b"><apply id="S3.T1.5.5.2.m1.1.1.m1.3.3.cmml" xref="S3.T1.5.5.2.m1.1.1.m1.3.3"><csymbol cd="latexml" id="S3.T1.5.5.2.m1.1.1.m1.2.2.2.2.2.2.cmml" xref="S3.T1.5.5.2.m1.1.1.m1.2.2.2.2.2.2">times</csymbol><cn type="integer" id="S3.T1.5.5.2.m1.1.1.m1.1.1.1.1.1.1.cmml" xref="S3.T1.5.5.2.m1.1.1.m1.1.1.1.1.1.1">24</cn><ci id="S3.T1.5.5.2.m1.1.1.m1.3.3.3.3.3.3.cmml" xref="S3.T1.5.5.2.m1.1.1.m1.3.3.3.3.3.3">h</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.5.5.2.m1.1.1.m1.3c">24\text{\,}\mathrm{h}</annotation></semantics></math></td>
</tr>
<tr id="S3.T1.7.7" class="ltx_tr">
<td id="S3.T1.6.6.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:-0.5pt;padding-bottom:-0.5pt;"><math id="S3.T1.6.6.1.m1.1" class="ltx_Math" alttext="\text{FT}_{\text{24h}}" display="inline"><semantics id="S3.T1.6.6.1.m1.1a"><msub id="S3.T1.6.6.1.m1.1.1" xref="S3.T1.6.6.1.m1.1.1.cmml"><mtext id="S3.T1.6.6.1.m1.1.1.2" xref="S3.T1.6.6.1.m1.1.1.2a.cmml">FT</mtext><mtext id="S3.T1.6.6.1.m1.1.1.3" xref="S3.T1.6.6.1.m1.1.1.3a.cmml">24h</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.T1.6.6.1.m1.1b"><apply id="S3.T1.6.6.1.m1.1.1.cmml" xref="S3.T1.6.6.1.m1.1.1"><csymbol cd="ambiguous" id="S3.T1.6.6.1.m1.1.1.1.cmml" xref="S3.T1.6.6.1.m1.1.1">subscript</csymbol><ci id="S3.T1.6.6.1.m1.1.1.2a.cmml" xref="S3.T1.6.6.1.m1.1.1.2"><mtext id="S3.T1.6.6.1.m1.1.1.2.cmml" xref="S3.T1.6.6.1.m1.1.1.2">FT</mtext></ci><ci id="S3.T1.6.6.1.m1.1.1.3a.cmml" xref="S3.T1.6.6.1.m1.1.1.3"><mtext mathsize="70%" id="S3.T1.6.6.1.m1.1.1.3.cmml" xref="S3.T1.6.6.1.m1.1.1.3">24h</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.6.6.1.m1.1c">\text{FT}_{\text{24h}}</annotation></semantics></math></td>
<td id="S3.T1.7.7.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:-0.5pt;padding-bottom:-0.5pt;">0.88</td>
<td id="S3.T1.7.7.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:-0.5pt;padding-bottom:-0.5pt;">0.94</td>
<td id="S3.T1.7.7.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:-0.5pt;padding-bottom:-0.5pt;">1.06</td>
<td id="S3.T1.7.7.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:-0.5pt;padding-bottom:-0.5pt;">1.03</td>
<td id="S3.T1.7.7.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:-0.5pt;padding-bottom:-0.5pt;"><math id="S3.T1.7.7.2.m1.1.1.m1.3" class="ltx_markedasmath" alttext="24\text{\,}\mathrm{h}" display="inline"><semantics id="S3.T1.7.7.2.m1.1.1.m1.3a"><mrow id="S3.T1.7.7.2.m1.1.1.m1.3.3" xref="S3.T1.7.7.2.m1.1.1.m1.3.3.cmml"><mn id="S3.T1.7.7.2.m1.1.1.m1.1.1.1.1.1.1" xref="S3.T1.7.7.2.m1.1.1.m1.1.1.1.1.1.1.cmml">24</mn><mtext id="S3.T1.7.7.2.m1.1.1.m1.2.2.2.2.2.2" xref="S3.T1.7.7.2.m1.1.1.m1.2.2.2.2.2.2.cmml"> </mtext><mi mathvariant="normal" id="S3.T1.7.7.2.m1.1.1.m1.3.3.3.3.3.3" xref="S3.T1.7.7.2.m1.1.1.m1.3.3.3.3.3.3.cmml">h</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.T1.7.7.2.m1.1.1.m1.3b"><apply id="S3.T1.7.7.2.m1.1.1.m1.3.3.cmml" xref="S3.T1.7.7.2.m1.1.1.m1.3.3"><csymbol cd="latexml" id="S3.T1.7.7.2.m1.1.1.m1.2.2.2.2.2.2.cmml" xref="S3.T1.7.7.2.m1.1.1.m1.2.2.2.2.2.2">times</csymbol><cn type="integer" id="S3.T1.7.7.2.m1.1.1.m1.1.1.1.1.1.1.cmml" xref="S3.T1.7.7.2.m1.1.1.m1.1.1.1.1.1.1">24</cn><ci id="S3.T1.7.7.2.m1.1.1.m1.3.3.3.3.3.3.cmml" xref="S3.T1.7.7.2.m1.1.1.m1.3.3.3.3.3.3">h</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.7.7.2.m1.1.1.m1.3c">24\text{\,}\mathrm{h}</annotation></semantics></math></td>
</tr>
<tr id="S3.T1.9.9" class="ltx_tr">
<td id="S3.T1.8.8.1" class="ltx_td ltx_align_center" style="padding-top:-0.5pt;padding-bottom:-0.5pt;"><math id="S3.T1.8.8.1.m1.1" class="ltx_Math" alttext="\text{FT}_{\text{12h}}" display="inline"><semantics id="S3.T1.8.8.1.m1.1a"><msub id="S3.T1.8.8.1.m1.1.1" xref="S3.T1.8.8.1.m1.1.1.cmml"><mtext id="S3.T1.8.8.1.m1.1.1.2" xref="S3.T1.8.8.1.m1.1.1.2a.cmml">FT</mtext><mtext id="S3.T1.8.8.1.m1.1.1.3" xref="S3.T1.8.8.1.m1.1.1.3a.cmml">12h</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.T1.8.8.1.m1.1b"><apply id="S3.T1.8.8.1.m1.1.1.cmml" xref="S3.T1.8.8.1.m1.1.1"><csymbol cd="ambiguous" id="S3.T1.8.8.1.m1.1.1.1.cmml" xref="S3.T1.8.8.1.m1.1.1">subscript</csymbol><ci id="S3.T1.8.8.1.m1.1.1.2a.cmml" xref="S3.T1.8.8.1.m1.1.1.2"><mtext id="S3.T1.8.8.1.m1.1.1.2.cmml" xref="S3.T1.8.8.1.m1.1.1.2">FT</mtext></ci><ci id="S3.T1.8.8.1.m1.1.1.3a.cmml" xref="S3.T1.8.8.1.m1.1.1.3"><mtext mathsize="70%" id="S3.T1.8.8.1.m1.1.1.3.cmml" xref="S3.T1.8.8.1.m1.1.1.3">12h</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.8.8.1.m1.1c">\text{FT}_{\text{12h}}</annotation></semantics></math></td>
<td id="S3.T1.9.9.3" class="ltx_td ltx_align_center" style="padding-top:-0.5pt;padding-bottom:-0.5pt;">0.81</td>
<td id="S3.T1.9.9.4" class="ltx_td ltx_align_center" style="padding-top:-0.5pt;padding-bottom:-0.5pt;">0.90</td>
<td id="S3.T1.9.9.5" class="ltx_td ltx_align_center" style="padding-top:-0.5pt;padding-bottom:-0.5pt;">1.10</td>
<td id="S3.T1.9.9.6" class="ltx_td ltx_align_center" style="padding-top:-0.5pt;padding-bottom:-0.5pt;">1.08</td>
<td id="S3.T1.9.9.2" class="ltx_td ltx_align_center" style="padding-top:-0.5pt;padding-bottom:-0.5pt;"><math id="S3.T1.9.9.2.m1.1.1.m1.3" class="ltx_markedasmath" alttext="12\text{\,}\mathrm{h}" display="inline"><semantics id="S3.T1.9.9.2.m1.1.1.m1.3a"><mrow id="S3.T1.9.9.2.m1.1.1.m1.3.3" xref="S3.T1.9.9.2.m1.1.1.m1.3.3.cmml"><mn id="S3.T1.9.9.2.m1.1.1.m1.1.1.1.1.1.1" xref="S3.T1.9.9.2.m1.1.1.m1.1.1.1.1.1.1.cmml">12</mn><mtext id="S3.T1.9.9.2.m1.1.1.m1.2.2.2.2.2.2" xref="S3.T1.9.9.2.m1.1.1.m1.2.2.2.2.2.2.cmml"> </mtext><mi mathvariant="normal" id="S3.T1.9.9.2.m1.1.1.m1.3.3.3.3.3.3" xref="S3.T1.9.9.2.m1.1.1.m1.3.3.3.3.3.3.cmml">h</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.T1.9.9.2.m1.1.1.m1.3b"><apply id="S3.T1.9.9.2.m1.1.1.m1.3.3.cmml" xref="S3.T1.9.9.2.m1.1.1.m1.3.3"><csymbol cd="latexml" id="S3.T1.9.9.2.m1.1.1.m1.2.2.2.2.2.2.cmml" xref="S3.T1.9.9.2.m1.1.1.m1.2.2.2.2.2.2">times</csymbol><cn type="integer" id="S3.T1.9.9.2.m1.1.1.m1.1.1.1.1.1.1.cmml" xref="S3.T1.9.9.2.m1.1.1.m1.1.1.1.1.1.1">12</cn><ci id="S3.T1.9.9.2.m1.1.1.m1.3.3.3.3.3.3.cmml" xref="S3.T1.9.9.2.m1.1.1.m1.3.3.3.3.3.3">h</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.9.9.2.m1.1.1.m1.3c">12\text{\,}\mathrm{h}</annotation></semantics></math></td>
</tr>
<tr id="S3.T1.11.11" class="ltx_tr">
<td id="S3.T1.10.10.1" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:-0.5pt;padding-bottom:-0.5pt;"><math id="S3.T1.10.10.1.m1.1" class="ltx_Math" alttext="\text{FT}_{\text{6h}}" display="inline"><semantics id="S3.T1.10.10.1.m1.1a"><msub id="S3.T1.10.10.1.m1.1.1" xref="S3.T1.10.10.1.m1.1.1.cmml"><mtext id="S3.T1.10.10.1.m1.1.1.2" xref="S3.T1.10.10.1.m1.1.1.2a.cmml">FT</mtext><mtext id="S3.T1.10.10.1.m1.1.1.3" xref="S3.T1.10.10.1.m1.1.1.3a.cmml">6h</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.T1.10.10.1.m1.1b"><apply id="S3.T1.10.10.1.m1.1.1.cmml" xref="S3.T1.10.10.1.m1.1.1"><csymbol cd="ambiguous" id="S3.T1.10.10.1.m1.1.1.1.cmml" xref="S3.T1.10.10.1.m1.1.1">subscript</csymbol><ci id="S3.T1.10.10.1.m1.1.1.2a.cmml" xref="S3.T1.10.10.1.m1.1.1.2"><mtext id="S3.T1.10.10.1.m1.1.1.2.cmml" xref="S3.T1.10.10.1.m1.1.1.2">FT</mtext></ci><ci id="S3.T1.10.10.1.m1.1.1.3a.cmml" xref="S3.T1.10.10.1.m1.1.1.3"><mtext mathsize="70%" id="S3.T1.10.10.1.m1.1.1.3.cmml" xref="S3.T1.10.10.1.m1.1.1.3">6h</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.10.10.1.m1.1c">\text{FT}_{\text{6h}}</annotation></semantics></math></td>
<td id="S3.T1.11.11.3" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:-0.5pt;padding-bottom:-0.5pt;">0.77</td>
<td id="S3.T1.11.11.4" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:-0.5pt;padding-bottom:-0.5pt;">0.87</td>
<td id="S3.T1.11.11.5" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:-0.5pt;padding-bottom:-0.5pt;">1.13</td>
<td id="S3.T1.11.11.6" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:-0.5pt;padding-bottom:-0.5pt;">1.12</td>
<td id="S3.T1.11.11.2" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:-0.5pt;padding-bottom:-0.5pt;"><math id="S3.T1.11.11.2.m1.1.1.m1.3" class="ltx_markedasmath" alttext="6\text{\,}\mathrm{h}" display="inline"><semantics id="S3.T1.11.11.2.m1.1.1.m1.3a"><mrow id="S3.T1.11.11.2.m1.1.1.m1.3.3" xref="S3.T1.11.11.2.m1.1.1.m1.3.3.cmml"><mn id="S3.T1.11.11.2.m1.1.1.m1.1.1.1.1.1.1" xref="S3.T1.11.11.2.m1.1.1.m1.1.1.1.1.1.1.cmml">6</mn><mtext id="S3.T1.11.11.2.m1.1.1.m1.2.2.2.2.2.2" xref="S3.T1.11.11.2.m1.1.1.m1.2.2.2.2.2.2.cmml"> </mtext><mi mathvariant="normal" id="S3.T1.11.11.2.m1.1.1.m1.3.3.3.3.3.3" xref="S3.T1.11.11.2.m1.1.1.m1.3.3.3.3.3.3.cmml">h</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.T1.11.11.2.m1.1.1.m1.3b"><apply id="S3.T1.11.11.2.m1.1.1.m1.3.3.cmml" xref="S3.T1.11.11.2.m1.1.1.m1.3.3"><csymbol cd="latexml" id="S3.T1.11.11.2.m1.1.1.m1.2.2.2.2.2.2.cmml" xref="S3.T1.11.11.2.m1.1.1.m1.2.2.2.2.2.2">times</csymbol><cn type="integer" id="S3.T1.11.11.2.m1.1.1.m1.1.1.1.1.1.1.cmml" xref="S3.T1.11.11.2.m1.1.1.m1.1.1.1.1.1.1">6</cn><ci id="S3.T1.11.11.2.m1.1.1.m1.3.3.3.3.3.3.cmml" xref="S3.T1.11.11.2.m1.1.1.m1.3.3.3.3.3.3">h</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.11.11.2.m1.1.1.m1.3c">6\text{\,}\mathrm{h}</annotation></semantics></math></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S3.T1.21.4.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Table 1</span>: </span><span id="S3.T1.17.3" class="ltx_text" style="font-size:90%;">Accuracy and mean absolute error on misclassified segments (<math id="S3.T1.15.1.m1.1" class="ltx_Math" alttext="\text{MAE}_{\text{mis}}" display="inline"><semantics id="S3.T1.15.1.m1.1b"><msub id="S3.T1.15.1.m1.1.1" xref="S3.T1.15.1.m1.1.1.cmml"><mtext id="S3.T1.15.1.m1.1.1.2" xref="S3.T1.15.1.m1.1.1.2a.cmml">MAE</mtext><mtext id="S3.T1.15.1.m1.1.1.3" xref="S3.T1.15.1.m1.1.1.3a.cmml">mis</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.T1.15.1.m1.1c"><apply id="S3.T1.15.1.m1.1.1.cmml" xref="S3.T1.15.1.m1.1.1"><csymbol cd="ambiguous" id="S3.T1.15.1.m1.1.1.1.cmml" xref="S3.T1.15.1.m1.1.1">subscript</csymbol><ci id="S3.T1.15.1.m1.1.1.2a.cmml" xref="S3.T1.15.1.m1.1.1.2"><mtext id="S3.T1.15.1.m1.1.1.2.cmml" xref="S3.T1.15.1.m1.1.1.2">MAE</mtext></ci><ci id="S3.T1.15.1.m1.1.1.3a.cmml" xref="S3.T1.15.1.m1.1.1.3"><mtext mathsize="70%" id="S3.T1.15.1.m1.1.1.3.cmml" xref="S3.T1.15.1.m1.1.1.3">mis</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.15.1.m1.1d">\text{MAE}_{\text{mis}}</annotation></semantics></math>) for models trained on real-world (<span id="S3.T1.17.3.1" class="ltx_text ltx_markedasmath">RW</span>) data only, or pre-trained on synthetic data and then fine-tuned (<span id="S3.T1.17.3.2" class="ltx_text ltx_markedasmath">FT</span>) on increasing amount of real-world data.</span></figcaption>
</figure>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Conclusion and Future Work</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">In this work we propose an AVC system based on a CRNN architecture trained on a mixture of synthetic and real-world data. The model relies on audio data captured by a 4-channel linear microphone array located at the side of the road. It is designed to count traffic for different vehicle types and direction of transit, and it is tested on real data from a two-lane road in moderate traffic density conditions. The proposed synthetic data generation procedure enables the model pre-training on simulated samples, with great benefit to reduce the amount of real-world data necessary to reach a high counting accuracy.</p>
</div>
<div id="S4.p2" class="ltx_para">
<p id="S4.p2.1" class="ltx_p">Future works will evaluate different data generation procedures to separately analyze the impact of the road/tire interaction and engine noises on the counting performance, as well as the generalization capabilities to different deployments.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
Rong Du, Paolo Santi, Ming Xiao, Athanasios V. Vasilakos, and Carlo Fischione,

</span>
<span class="ltx_bibblock">“The Sensable City: A Survey on the Deployment and
Management for Smart City Monitoring,”

</span>
<span class="ltx_bibblock"><span id="bib.bib1.1.1" class="ltx_text ltx_font_italic">IEEE Comm. Surveys &amp; Tutorials</span>, vol. 21, no. 2, pp.
1533–1560, 2019.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
Myounggyu Won,

</span>
<span class="ltx_bibblock">“Intelligent Traffic Monitoring Systems for Vehicle
Classification: A Survey,”

</span>
<span class="ltx_bibblock"><span id="bib.bib2.1.1" class="ltx_text ltx_font_italic">IEEE Access</span>, vol. 8, pp. 73340–73358, 2020.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
Slobodan Djukanović, Jiří Matas, and Tuomas Virtanen,

</span>
<span class="ltx_bibblock">“Robust audio-based vehicle counting in low-to-moderate traffic
flow,”

</span>
<span class="ltx_bibblock">in <span id="bib.bib3.1.1" class="ltx_text ltx_font_italic">Proc. 2020 IEEE Intelligent Vehicles Symp. (IV)</span>,
2020, pp. 1608–1614.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
Shigemi Ishida, Jumpei Kajimura, Masato Uchino, Shigeaki Tagashira, and Akira
Fukuda,

</span>
<span class="ltx_bibblock">“SAVeD: Acoustic vehicle detector with speed estimation capable
of sequential vehicle detection,”

</span>
<span class="ltx_bibblock">in <span id="bib.bib4.1.1" class="ltx_text ltx_font_italic">Proc. 2018 21st Int. Conf. Intelligent Transportation
Syst. (ITSC)</span>, Nov. 2018, pp. 906–912.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
Chaoyi Wang, Yaozhe Song, Haolong Liu, Huawei Liu, Jianpo Liu, Baoqing Li, and
Xiaobing Yuan,

</span>
<span class="ltx_bibblock">“Real-Time Vehicle Sound Detection System Based on
Depthwise Separable Convolution Neural Network and Spectrogram
Augmentation,”

</span>
<span class="ltx_bibblock"><span id="bib.bib5.1.1" class="ltx_text ltx_font_italic">Remote Sensing</span>, vol. 14, no. 19, pp. 4848, Sept. 2022.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
Grzegorz Szwoch and Józef Kotus,

</span>
<span class="ltx_bibblock">“Acoustic Detector of Road Vehicles Based on Sound
Intensity,”

</span>
<span class="ltx_bibblock"><span id="bib.bib6.1.1" class="ltx_text ltx_font_italic">Sensors</span>, vol. 21, no. 23, pp. 7781, Nov. 2021.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
Kazuo Kubo, Chengyu Li, Shigemi Ishida, Shigeaki Tagashira, and Akira Fukuda,

</span>
<span class="ltx_bibblock">“Design of ultra low power vehicle detector utilizing discrete
wavelet transform,”

</span>
<span class="ltx_bibblock">in <span id="bib.bib7.1.1" class="ltx_text ltx_font_italic">Proc. ITS AP Forum</span>, May 2018, pp. 1052–1063.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
Nikola Bulatovic and Slobodan Djukanovic,

</span>
<span class="ltx_bibblock">“Mel-spectrogram features for acoustic vehicle detection and speed
estimation,”

</span>
<span class="ltx_bibblock">in <span id="bib.bib8.1.1" class="ltx_text ltx_font_italic">Proc. 26th International Conference on Information Technology
(IT)</span>, Zabljak, Montenegro, Feb. 2022.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
Slobodan Djukanović, Yash Patel, Jiří Matas, and Tuomas Virtanen,

</span>
<span class="ltx_bibblock">“Neural network-based acoustic vehicle counting,”

</span>
<span class="ltx_bibblock">in <span id="bib.bib9.1.1" class="ltx_text ltx_font_italic">Proc. 2021 29th European Signal Processing Conference
(EUSIPCO)</span>, Aug. 2021, pp. 561–565.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
Xingshui Zu, Shaojie Zhang, Feng Guo, Qin Zhao, Xin Zhang, Xing You, Huawei
Liu, Baoqing Li, and Xiaobing Yuan,

</span>
<span class="ltx_bibblock">“Vehicle Counting and Moving Direction Identification
Based on Small-Aperture Microphone Array,”

</span>
<span class="ltx_bibblock"><span id="bib.bib10.1.1" class="ltx_text ltx_font_italic">Sensors</span>, vol. 17, no. 5, pp. 1089, May 2017.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
A. Severdaks and M. Liepins,

</span>
<span class="ltx_bibblock">“Vehicle Counting and Motion Direction Detection Using
Microphone Array,”

</span>
<span class="ltx_bibblock"><span id="bib.bib11.1.1" class="ltx_text ltx_font_italic">Electronics and Electrical Engineering</span>, vol. 19, no. 8, Oct.
2013.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
Annamaria Mesaros, Toni Heittola, Tuomas Virtanen, and Mark D. Plumbley,

</span>
<span class="ltx_bibblock">“Sound Event Detection: A tutorial,”

</span>
<span class="ltx_bibblock"><span id="bib.bib12.1.1" class="ltx_text ltx_font_italic">IEEE Signal Process. Mag.</span>, vol. 38, no. 5, pp. 67–83, Sept.
2021.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
Jakob Abesser, Saichand Gourishetti, András Kátai, Tobias Clauss, Prachi
Sharma, and Judith Liebetrau,

</span>
<span class="ltx_bibblock">“IDMT-traffic: an open benchmark dataset for acoustic traffic
monitoring research,”

</span>
<span class="ltx_bibblock">in <span id="bib.bib13.1.1" class="ltx_text ltx_font_italic">Proc. 2021 29th European Signal Process. Conf.
(EUSIPCO)</span>, Aug. 2021, pp. 551–555.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
Stefano Damiano and Toon van Waterschoot,

</span>
<span class="ltx_bibblock">“Pyroadacoustics: a Road Acoustics Simulator Based on
Variable Length Delay Lines,”

</span>
<span class="ltx_bibblock">in <span id="bib.bib14.1.1" class="ltx_text ltx_font_italic">Proc. 25th Int. Conf. on Digital Audio Effects
(DAFx20in22)</span>, Vienna, Austria, Sept. 2022, pp. 216–223.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
Neil Zeghidour, Olivier Teboul, Félix de Chaumont Quitry, and Marco
Tagliasacchi,

</span>
<span class="ltx_bibblock">“LEAF: A learnable frontend for audio classification,”

</span>
<span class="ltx_bibblock">in <span id="bib.bib15.1.1" class="ltx_text ltx_font_italic">Proc. 9th Int. Conf. Learning Representations
(ICLR)</span>, Virtual Event, Austria, May 2021.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
Hans G. Jonasson,

</span>
<span class="ltx_bibblock">“Acoustical source modelling of road vehicles,”

</span>
<span class="ltx_bibblock"><span id="bib.bib16.1.1" class="ltx_text ltx_font_italic">Acta Acustica united with Acustica</span>, vol. 93, no. 2, pp.
173–184, 2007.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
Stefano Baldan, Helene Lachambre, Stefano Delle Monache, and Patrick Boussard,

</span>
<span class="ltx_bibblock">“Physically informed car engine sound synthesis for virtual and
augmented environments,”

</span>
<span class="ltx_bibblock">in <span id="bib.bib17.1.1" class="ltx_text ltx_font_italic">Proc. 2015 IEEE 2nd VR Workshop Sonic Interactions
Virtual Environments (SIVE)</span>, Arles, France, Mar. 2015, pp. 1–6.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
Yang Fu,

</span>
<span class="ltx_bibblock"><span id="bib.bib18.1.1" class="ltx_text ltx_font_italic">Auralisation of Traffic Flow using Procedural Audio
Methods</span>,

</span>
<span class="ltx_bibblock">PhD Thesis, University of York, York, UK, Jan. 2021.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
Daniel S. Park, William Chan, Yu Zhang, Chung-Cheng Chiu, Barret Zoph, Ekin D.
Cubuk, and Quoc V. Le,

</span>
<span class="ltx_bibblock">“SpecAugment: A Simple Data Augmentation Method for
Automatic Speech Recognition,”

</span>
<span class="ltx_bibblock">in <span id="bib.bib19.1.1" class="ltx_text ltx_font_italic">Proc. Interspeech 2019</span>, Graz, Austria, Sept. 2019, pp.
2613–2617.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
Diederik P. Kingma and Jimmy Ba,

</span>
<span class="ltx_bibblock">“Adam: A method for stochastic optimization,”

</span>
<span class="ltx_bibblock">in <span id="bib.bib20.1.1" class="ltx_text ltx_font_italic">Proc. 3rd Int. Conf. Learning Representations
(ICLR)</span>, San Diego, USA, May 2015.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2401.09307" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2401.09308" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2401.09308">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2401.09308" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2401.09309" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Tue Feb 27 08:58:16 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
