<article class="ltx_document ltx_authors_1line">
 <h1 class="ltx_title ltx_title_document">
  On the Prospects of Incorporating Large Language Models (LLMs) in Automated Planning and Scheduling (APS)
 </h1>
 <div class="ltx_authors">
  <span class="ltx_creator ltx_role_author">
   <span class="ltx_personname">
    Vishal Pallagani
    <sup class="ltx_sup" id="id1.1.id1">
     1
    </sup>
    ,
Kaushik Roy
    <sup class="ltx_sup" id="id2.2.id2">
     1
    </sup>
    ,
Bharath Muppasani
    <sup class="ltx_sup" id="id3.3.id3">
     1
    </sup>
    ,
Francesco Fabiano
    <sup class="ltx_sup" id="id4.4.id4">
     2
    </sup>
    ,
Andrea Loreggia
    <sup class="ltx_sup" id="id5.5.id5">
     3
    </sup>
    ,
Keerthiram Murugesan
    <sup class="ltx_sup" id="id6.6.id6">
     4
    </sup>
    ,
Biplav Srivastava
    <sup class="ltx_sup" id="id7.7.id7">
     1
    </sup>
    ,
Francesca Rossi
    <sup class="ltx_sup" id="id8.8.id8">
     4
    </sup>
    ,
Lior Horesh
    <sup class="ltx_sup" id="id9.9.id9">
     4
    </sup>
    ,
Amit Sheth
    <sup class="ltx_sup" id="id10.10.id10">
     1
    </sup>
   </span>
  </span>
 </div>
 <div class="ltx_abstract">
  <h6 class="ltx_title ltx_title_abstract">
   Abstract
  </h6>
  <p class="ltx_p" id="id11.id1">
   Automated Planning and Scheduling is among the growing areas in Artificial Intelligence (AI) where mention of LLMs has gained popularity. Based on a comprehensive review of 126 papers, this paper investigates eight categories based on the unique applications of LLMs in addressing various aspects of planning problems: language translation, plan generation, model construction, multi-agent planning, interactive planning, heuristics optimization, tool integration, and brain-inspired planning. For each category, we articulate the issues considered and existing gaps. A critical insight resulting from our review is that the true potential of LLMs unfolds when they are integrated with traditional symbolic planners, pointing towards a promising neuro-symbolic approach. This approach effectively combines the generative aspects of LLMs with the precision of classical planning methods. By synthesizing insights from existing literature, we underline the potential of this integration to address complex planning challenges. Our goal is to encourage the ICAPS community to recognize the complementary strengths of LLMs and symbolic planners, advocating for a direction in automated planning that leverages these synergistic capabilities to develop more advanced and intelligent planning systems.
  </p>
 </div>
 <section class="ltx_section" id="Sx1">
  <h2 class="ltx_title ltx_title_section">
   Introduction
  </h2>
  <figure class="ltx_table" id="Sx1.T1">
   <table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="Sx1.T1.1">
    <thead class="ltx_thead">
     <tr class="ltx_tr" id="Sx1.T1.1.1.1">
      <th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="Sx1.T1.1.1.1.1">
       <span class="ltx_text ltx_font_bold" id="Sx1.T1.1.1.1.1.1">
        Category
       </span>
      </th>
      <th class="ltx_td ltx_nopad_r ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt" id="Sx1.T1.1.1.1.2">
       <span class="ltx_inline-block ltx_align_top" id="Sx1.T1.1.1.1.2.1">
        <span class="ltx_p" id="Sx1.T1.1.1.1.2.1.1" style="width:398.3pt;">
         <span class="ltx_text ltx_font_bold" id="Sx1.T1.1.1.1.2.1.1.1">
          Description
         </span>
        </span>
       </span>
      </th>
     </tr>
    </thead>
    <tbody class="ltx_tbody">
     <tr class="ltx_tr" id="Sx1.T1.1.2.1">
      <th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="Sx1.T1.1.2.1.1">
       Language Translation
      </th>
      <td class="ltx_td ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_t" id="Sx1.T1.1.2.1.2">
       <span class="ltx_inline-block ltx_align_top" id="Sx1.T1.1.2.1.2.1">
        <span class="ltx_p" id="Sx1.T1.1.2.1.2.1.1" style="width:398.3pt;">
         Involves converting natural language into structured planning languages or formats like PDDL and vice-versa, enhancing the interface between human linguistic input and machine-understandable planning directives.
        </span>
       </span>
      </td>
     </tr>
     <tr class="ltx_tr" id="Sx1.T1.1.3.2">
      <th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Sx1.T1.1.3.2.1">
       Plan Generation
      </th>
      <td class="ltx_td ltx_nopad_r ltx_align_justify ltx_align_top" id="Sx1.T1.1.3.2.2">
       <span class="ltx_inline-block ltx_align_top" id="Sx1.T1.1.3.2.2.1">
        <span class="ltx_p" id="Sx1.T1.1.3.2.2.1.1" style="width:398.3pt;">
         Entails the creation of plans or strategies directly by LLMs, focusing on generating actionable sequences or decision-making processes.
        </span>
       </span>
      </td>
     </tr>
     <tr class="ltx_tr" id="Sx1.T1.1.4.3">
      <th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Sx1.T1.1.4.3.1">
       Model Construction
      </th>
      <td class="ltx_td ltx_nopad_r ltx_align_justify ltx_align_top" id="Sx1.T1.1.4.3.2">
       <span class="ltx_inline-block ltx_align_top" id="Sx1.T1.1.4.3.2.1">
        <span class="ltx_p" id="Sx1.T1.1.4.3.2.1.1" style="width:398.3pt;">
         Utilizes LLMs to construct or refine world and domain models essential for accurate and effective planning.
        </span>
       </span>
      </td>
     </tr>
     <tr class="ltx_tr" id="Sx1.T1.1.5.4">
      <th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Sx1.T1.1.5.4.1">
       Multi-agent Planning
      </th>
      <td class="ltx_td ltx_nopad_r ltx_align_justify ltx_align_top" id="Sx1.T1.1.5.4.2">
       <span class="ltx_inline-block ltx_align_top" id="Sx1.T1.1.5.4.2.1">
        <span class="ltx_p" id="Sx1.T1.1.5.4.2.1.1" style="width:398.3pt;">
         Focuses on scenarios involving multiple agents, where LLMs contribute to coordination and cooperative strategy development.
        </span>
       </span>
      </td>
     </tr>
     <tr class="ltx_tr" id="Sx1.T1.1.6.5">
      <th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Sx1.T1.1.6.5.1">
       Interactive Planning
      </th>
      <td class="ltx_td ltx_nopad_r ltx_align_justify ltx_align_top" id="Sx1.T1.1.6.5.2">
       <span class="ltx_inline-block ltx_align_top" id="Sx1.T1.1.6.5.2.1">
        <span class="ltx_p" id="Sx1.T1.1.6.5.2.1.1" style="width:398.3pt;">
         Centers on scenarios requiring iterative feedback or interactive planning with users, external verifiers, or environment, emphasizing the adaptability of LLMs to dynamic inputs.
        </span>
       </span>
      </td>
     </tr>
     <tr class="ltx_tr" id="Sx1.T1.1.7.6">
      <th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Sx1.T1.1.7.6.1">
       Heuristics Optimization
      </th>
      <td class="ltx_td ltx_nopad_r ltx_align_justify ltx_align_top" id="Sx1.T1.1.7.6.2">
       <span class="ltx_inline-block ltx_align_top" id="Sx1.T1.1.7.6.2.1">
        <span class="ltx_p" id="Sx1.T1.1.7.6.2.1.1" style="width:398.3pt;">
         Applies LLMs in optimizing planning processes through refining existing plans or providing heuristic assistance to symbolic planners.
        </span>
       </span>
      </td>
     </tr>
     <tr class="ltx_tr" id="Sx1.T1.1.8.7">
      <th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Sx1.T1.1.8.7.1">
       Tool Integration
      </th>
      <td class="ltx_td ltx_nopad_r ltx_align_justify ltx_align_top" id="Sx1.T1.1.8.7.2">
       <span class="ltx_inline-block ltx_align_top" id="Sx1.T1.1.8.7.2.1">
        <span class="ltx_p" id="Sx1.T1.1.8.7.2.1.1" style="width:398.3pt;">
         Encompasses studies where LLMs act as central orchestrators or coordinators in a tool ecosystem, interfacing with planners, theorem provers, and other systems.
        </span>
       </span>
      </td>
     </tr>
     <tr class="ltx_tr" id="Sx1.T1.1.9.8">
      <th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="Sx1.T1.1.9.8.1">
       Brain-Inspired Planning
      </th>
      <td class="ltx_td ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_bb" id="Sx1.T1.1.9.8.2">
       <span class="ltx_inline-block ltx_align_top" id="Sx1.T1.1.9.8.2.1">
        <span class="ltx_p" id="Sx1.T1.1.9.8.2.1.1" style="width:398.3pt;">
         Covers research focusing on LLM architectures inspired by neurological or cognitive processes, particularly to enhance planning capabilities.
        </span>
       </span>
      </td>
     </tr>
    </tbody>
   </table>
   <figcaption class="ltx_caption ltx_centering">
    <span class="ltx_tag ltx_tag_table">
     Table 1:
    </span>
    Comprehensive description of the eight categories utilizing LLMs in APS
   </figcaption>
  </figure>
  <div class="ltx_para" id="Sx1.p1">
   <p class="ltx_p" id="Sx1.p1.1">
    As a sub-field of Artificial Intelligence
    <cite class="ltx_cite ltx_citemacro_citep">
     (Russell and Norvig
     <a class="ltx_ref" href="#bib.bib87" title="">
      2003
     </a>
     )
    </cite>
    , Automated Planning and Scheduling
    <cite class="ltx_cite ltx_citemacro_citep">
     (Ghallab, Nau, and Traverso
     <a class="ltx_ref" href="#bib.bib29" title="">
      2004
     </a>
     )
    </cite>
    refers to developing algorithms and systems to generate plans or sequences of actions to achieve specific goals in a given environment or problem domain. APS is a valuable tool in domains where there is a need for intelligent decision-making, goal achievement, and efficient resource utilization. It enables the automation of complex tasks, making systems more capable and adaptable in dynamic environments. Over time, APS has evolved from the early development of robust theoretical foundations to practical applications in diverse sectors like manufacturing, space exploration, and personal scheduling. This evolution underscores the versatility and critical significance of APS.
   </p>
  </div>
  <div class="ltx_para" id="Sx1.p2">
   <p class="ltx_p" id="Sx1.p2.1">
    In parallel with advancements in APS, the development and proliferation of LLMs have marked a substantial leap in AI, particularly within computational linguistics. Evolving from early efforts in natural language processing (NLP), LLMs have undergone significant transformation. Initially focused on basic tasks like word prediction and syntax analysis, newer models are characterized by their ability to generate coherent, contextually relevant text and perform diverse, complex linguistic tasks. Trained on extensive text corpora, LLMs have mastered human-like language patterns. Their recent success in various NLP tasks has prompted efforts to apply these models in APS. There is a notable shift towards using language constructs to specify aspects of planning, such as preconditions, effects, and goals, rather than relying solely on traditional planning domain languages like PDDL.
   </p>
  </div>
  <div class="ltx_para" id="Sx1.p3">
   <p class="ltx_p" id="Sx1.p3.1">
    This paper presents an exhaustive literature review exploring the integration of LLMs in APS across eight categories: Language Translation, Plan Generation, Model Construction, Multi-agent Planning, Interactive Planning, Heuristics Optimization, Brain-Inspired Planning, and Tool Integration. Table
    <a class="ltx_ref" href="#Sx1.T1" title="Table 1 ‣ Introduction ‣ On the Prospects of Incorporating Large Language Models (LLMs) in Automated Planning and Scheduling (APS)">
     <span class="ltx_text ltx_ref_tag">
      1
     </span>
    </a>
    provides the description for the eight categories. Our comprehensive analysis of 126 papers not only categorizes LLMs’ diverse contributions but also identifies significant gaps in each domain. Through our review, we put forward the following position:
   </p>
  </div>
  <div class="ltx_para ltx_noindent" id="Sx1.p4">
   <svg class="ltx_picture" height="175.39" id="Sx1.p4.pic1" overflow="visible" version="1.1" width="600">
    <g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,175.39) matrix(1 0 0 -1 0 0)">
     <g fill="#0000BF" fill-opacity="1.0">
      <path d="M 0 5.91 L 0 169.48 C 0 172.74 2.64 175.39 5.91 175.39 L 594.09 175.39 C 597.36 175.39 600 172.74 600 169.48 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none">
      </path>
     </g>
     <g fill="#F7F7FF" fill-opacity="1.0">
      <path d="M 1.97 5.91 L 1.97 154.12 L 598.03 154.12 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none">
      </path>
     </g>
     <g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 13.78 160.03)">
      <foreignobject color="#FFFFFF" height="9.46" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="572.44">
       <span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="Sx1.p4.pic1.1.1.1.1.1" style="width:413.7pt;">
        <span class="ltx_p" id="Sx1.p4.pic1.1.1.1.1.1.1">
         Position Statement
        </span>
       </span>
      </foreignobject>
     </g>
     <g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 13.78 13.78)">
      <foreignobject color="#000000" height="128.53" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="572.44">
       <span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="Sx1.p4.pic1.2.2.2.1.1" style="width:413.7pt;">
        <span class="ltx_p" id="Sx1.p4.pic1.2.2.2.1.1.1">
         Integrating LLMs into APS marks a pivotal advancement, bridging the gap between the advanced reasoning of traditional APS and the nuanced language understanding of LLMs. Traditional APS systems excel in structured, logical planning but often lack flexibility and contextual adaptability, a gap readily filled by LLMs. Conversely, while LLMs offer unparalleled natural language processing and a vast knowledge base, they fail to generate precise, actionable plans where APS systems thrive. This integration surpasses the limitations of each standalone method, offering a dynamic and context-aware planning approach, while also scaling up the traditional use of data and past experiences in the planning process.
        </span>
       </span>
      </foreignobject>
     </g>
    </g>
   </svg>
  </div>
  <div class="ltx_para" id="Sx1.p5">
   <p class="ltx_p" id="Sx1.p5.1">
    In the forthcoming sections, we delve into the background of LLMs and classical planning problem, accompanied by the identification of literature. This sets the stage for an in-depth exploration of the application of LLMs in APS, where we critically examine the strengths and limitations of LLMs. Our position on the emerging neuro-symbolic AI paradigm is central to our discussion, highlighting its unique advantages over purely neural network-based (i.e., statistical AI) or symbolic AI approaches. Finally, we will discuss prospective developments, address potential challenges, and identify promising opportunities in the field.
   </p>
  </div>
 </section>
 <section class="ltx_section" id="Sx2">
  <h2 class="ltx_title ltx_title_section">
   Background
  </h2>
  <section class="ltx_subsection" id="Sx2.SSx1">
   <h3 class="ltx_title ltx_title_subsection">
    Large Language Models
   </h3>
   <div class="ltx_para" id="Sx2.SSx1.p1">
    <p class="ltx_p" id="Sx2.SSx1.p1.1">
     Large language models are neural network models with upwards of
     <math alttext="\sim" class="ltx_Math" display="inline" id="Sx2.SSx1.p1.1.m1.1">
      <semantics id="Sx2.SSx1.p1.1.m1.1a">
       <mo id="Sx2.SSx1.p1.1.m1.1.1" xref="Sx2.SSx1.p1.1.m1.1.1.cmml">
        ∼
       </mo>
       <annotation-xml encoding="MathML-Content" id="Sx2.SSx1.p1.1.m1.1b">
        <csymbol cd="latexml" id="Sx2.SSx1.p1.1.m1.1.1.cmml" xref="Sx2.SSx1.p1.1.m1.1.1">
         similar-to
        </csymbol>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="Sx2.SSx1.p1.1.m1.1c">
        \sim
       </annotation>
      </semantics>
     </math>
     3 billion parameters that are trained on extremely large corpora of natural language data (trillions of tokens/words). These models are proficient in interpreting, generating, and contextualizing human language, leading to applications ranging from text generation to language-driven reasoning tasks. The evolution of LLMs in NLP began with rule-based models, progressed through statistical models, and achieved a significant breakthrough with the introduction of neural network-based models. The shift to sequence-based neural networks, with Recurrent Neural Networks (RNNs) and Long Short-Term Memory (LSTM) networks, marked a notable advancement due to their capability to process information and context over long sequences. Shortcomings in RNNs and LSTMs due to vanishing gradients and, consequently, loss of
     <span class="ltx_text ltx_font_italic" id="Sx2.SSx1.p1.1.1">
      very long
     </span>
     sequence contexts lead to the transformer model, which introduced self-attention (SA) mechanisms. The SA mechanism enabled focus on different parts of a long input sequence in parallel, which enhanced understanding of contextual nuances in language patterns over extremely long sequences. The SA mechanism is also complemented with positional encodings in transformers to enable the model to maintain an awareness of word/token order, which is required to understand accurate grammar and syntax. The self-attention mechanism, central to transformers, uses a query, key, and value system to contextualize dependencies in the input sequence. Informally, the SA concept is inspired by classical information retrieval systems where the query is the input sequence context, the key refers to a “database” contained within the parametric memory, and the value is the actual value present at that reference. The operation is mathematically expressed in Equation
     <a class="ltx_ref" href="#Sx2.E1" title="In Large Language Models ‣ Background ‣ On the Prospects of Incorporating Large Language Models (LLMs) in Automated Planning and Scheduling (APS)">
      <span class="ltx_text ltx_ref_tag">
       1
      </span>
     </a>
     .
    </p>
   </div>
   <div class="ltx_para" id="Sx2.SSx1.p2">
    <table class="ltx_equation ltx_eqn_table" id="Sx2.E1">
     <tbody>
      <tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
       <td class="ltx_eqn_cell ltx_eqn_center_padleft">
       </td>
       <td class="ltx_eqn_cell ltx_align_center">
        <math alttext="\text{Attention}(Q,K,V)=\text{softmax}\left(\frac{QK^{T}}{\sqrt{d_{k}}}\right)V" class="ltx_Math" display="block" id="Sx2.E1.m1.4">
         <semantics id="Sx2.E1.m1.4a">
          <mrow id="Sx2.E1.m1.4.5" xref="Sx2.E1.m1.4.5.cmml">
           <mrow id="Sx2.E1.m1.4.5.2" xref="Sx2.E1.m1.4.5.2.cmml">
            <mtext id="Sx2.E1.m1.4.5.2.2" xref="Sx2.E1.m1.4.5.2.2a.cmml">
             Attention
            </mtext>
            <mo id="Sx2.E1.m1.4.5.2.1" lspace="0em" rspace="0em" xref="Sx2.E1.m1.4.5.2.1.cmml">
             ​
            </mo>
            <mrow id="Sx2.E1.m1.4.5.2.3.2" xref="Sx2.E1.m1.4.5.2.3.1.cmml">
             <mo id="Sx2.E1.m1.4.5.2.3.2.1" stretchy="false" xref="Sx2.E1.m1.4.5.2.3.1.cmml">
              (
             </mo>
             <mi id="Sx2.E1.m1.1.1" xref="Sx2.E1.m1.1.1.cmml">
              Q
             </mi>
             <mo id="Sx2.E1.m1.4.5.2.3.2.2" xref="Sx2.E1.m1.4.5.2.3.1.cmml">
              ,
             </mo>
             <mi id="Sx2.E1.m1.2.2" xref="Sx2.E1.m1.2.2.cmml">
              K
             </mi>
             <mo id="Sx2.E1.m1.4.5.2.3.2.3" xref="Sx2.E1.m1.4.5.2.3.1.cmml">
              ,
             </mo>
             <mi id="Sx2.E1.m1.3.3" xref="Sx2.E1.m1.3.3.cmml">
              V
             </mi>
             <mo id="Sx2.E1.m1.4.5.2.3.2.4" stretchy="false" xref="Sx2.E1.m1.4.5.2.3.1.cmml">
              )
             </mo>
            </mrow>
           </mrow>
           <mo id="Sx2.E1.m1.4.5.1" xref="Sx2.E1.m1.4.5.1.cmml">
            =
           </mo>
           <mrow id="Sx2.E1.m1.4.5.3" xref="Sx2.E1.m1.4.5.3.cmml">
            <mtext id="Sx2.E1.m1.4.5.3.2" xref="Sx2.E1.m1.4.5.3.2a.cmml">
             softmax
            </mtext>
            <mo id="Sx2.E1.m1.4.5.3.1" lspace="0em" rspace="0em" xref="Sx2.E1.m1.4.5.3.1.cmml">
             ​
            </mo>
            <mrow id="Sx2.E1.m1.4.5.3.3.2" xref="Sx2.E1.m1.4.4.cmml">
             <mo id="Sx2.E1.m1.4.5.3.3.2.1" xref="Sx2.E1.m1.4.4.cmml">
              (
             </mo>
             <mfrac id="Sx2.E1.m1.4.4" xref="Sx2.E1.m1.4.4.cmml">
              <mrow id="Sx2.E1.m1.4.4.2" xref="Sx2.E1.m1.4.4.2.cmml">
               <mi id="Sx2.E1.m1.4.4.2.2" xref="Sx2.E1.m1.4.4.2.2.cmml">
                Q
               </mi>
               <mo id="Sx2.E1.m1.4.4.2.1" lspace="0em" rspace="0em" xref="Sx2.E1.m1.4.4.2.1.cmml">
                ​
               </mo>
               <msup id="Sx2.E1.m1.4.4.2.3" xref="Sx2.E1.m1.4.4.2.3.cmml">
                <mi id="Sx2.E1.m1.4.4.2.3.2" xref="Sx2.E1.m1.4.4.2.3.2.cmml">
                 K
                </mi>
                <mi id="Sx2.E1.m1.4.4.2.3.3" xref="Sx2.E1.m1.4.4.2.3.3.cmml">
                 T
                </mi>
               </msup>
              </mrow>
              <msqrt id="Sx2.E1.m1.4.4.3" xref="Sx2.E1.m1.4.4.3.cmml">
               <msub id="Sx2.E1.m1.4.4.3.2" xref="Sx2.E1.m1.4.4.3.2.cmml">
                <mi id="Sx2.E1.m1.4.4.3.2.2" xref="Sx2.E1.m1.4.4.3.2.2.cmml">
                 d
                </mi>
                <mi id="Sx2.E1.m1.4.4.3.2.3" xref="Sx2.E1.m1.4.4.3.2.3.cmml">
                 k
                </mi>
               </msub>
              </msqrt>
             </mfrac>
             <mo id="Sx2.E1.m1.4.5.3.3.2.2" xref="Sx2.E1.m1.4.4.cmml">
              )
             </mo>
            </mrow>
            <mo id="Sx2.E1.m1.4.5.3.1a" lspace="0em" rspace="0em" xref="Sx2.E1.m1.4.5.3.1.cmml">
             ​
            </mo>
            <mi id="Sx2.E1.m1.4.5.3.4" xref="Sx2.E1.m1.4.5.3.4.cmml">
             V
            </mi>
           </mrow>
          </mrow>
          <annotation-xml encoding="MathML-Content" id="Sx2.E1.m1.4b">
           <apply id="Sx2.E1.m1.4.5.cmml" xref="Sx2.E1.m1.4.5">
            <eq id="Sx2.E1.m1.4.5.1.cmml" xref="Sx2.E1.m1.4.5.1">
            </eq>
            <apply id="Sx2.E1.m1.4.5.2.cmml" xref="Sx2.E1.m1.4.5.2">
             <times id="Sx2.E1.m1.4.5.2.1.cmml" xref="Sx2.E1.m1.4.5.2.1">
             </times>
             <ci id="Sx2.E1.m1.4.5.2.2a.cmml" xref="Sx2.E1.m1.4.5.2.2">
              <mtext id="Sx2.E1.m1.4.5.2.2.cmml" xref="Sx2.E1.m1.4.5.2.2">
               Attention
              </mtext>
             </ci>
             <vector id="Sx2.E1.m1.4.5.2.3.1.cmml" xref="Sx2.E1.m1.4.5.2.3.2">
              <ci id="Sx2.E1.m1.1.1.cmml" xref="Sx2.E1.m1.1.1">
               𝑄
              </ci>
              <ci id="Sx2.E1.m1.2.2.cmml" xref="Sx2.E1.m1.2.2">
               𝐾
              </ci>
              <ci id="Sx2.E1.m1.3.3.cmml" xref="Sx2.E1.m1.3.3">
               𝑉
              </ci>
             </vector>
            </apply>
            <apply id="Sx2.E1.m1.4.5.3.cmml" xref="Sx2.E1.m1.4.5.3">
             <times id="Sx2.E1.m1.4.5.3.1.cmml" xref="Sx2.E1.m1.4.5.3.1">
             </times>
             <ci id="Sx2.E1.m1.4.5.3.2a.cmml" xref="Sx2.E1.m1.4.5.3.2">
              <mtext id="Sx2.E1.m1.4.5.3.2.cmml" xref="Sx2.E1.m1.4.5.3.2">
               softmax
              </mtext>
             </ci>
             <apply id="Sx2.E1.m1.4.4.cmml" xref="Sx2.E1.m1.4.5.3.3.2">
              <divide id="Sx2.E1.m1.4.4.1.cmml" xref="Sx2.E1.m1.4.5.3.3.2">
              </divide>
              <apply id="Sx2.E1.m1.4.4.2.cmml" xref="Sx2.E1.m1.4.4.2">
               <times id="Sx2.E1.m1.4.4.2.1.cmml" xref="Sx2.E1.m1.4.4.2.1">
               </times>
               <ci id="Sx2.E1.m1.4.4.2.2.cmml" xref="Sx2.E1.m1.4.4.2.2">
                𝑄
               </ci>
               <apply id="Sx2.E1.m1.4.4.2.3.cmml" xref="Sx2.E1.m1.4.4.2.3">
                <csymbol cd="ambiguous" id="Sx2.E1.m1.4.4.2.3.1.cmml" xref="Sx2.E1.m1.4.4.2.3">
                 superscript
                </csymbol>
                <ci id="Sx2.E1.m1.4.4.2.3.2.cmml" xref="Sx2.E1.m1.4.4.2.3.2">
                 𝐾
                </ci>
                <ci id="Sx2.E1.m1.4.4.2.3.3.cmml" xref="Sx2.E1.m1.4.4.2.3.3">
                 𝑇
                </ci>
               </apply>
              </apply>
              <apply id="Sx2.E1.m1.4.4.3.cmml" xref="Sx2.E1.m1.4.4.3">
               <root id="Sx2.E1.m1.4.4.3a.cmml" xref="Sx2.E1.m1.4.4.3">
               </root>
               <apply id="Sx2.E1.m1.4.4.3.2.cmml" xref="Sx2.E1.m1.4.4.3.2">
                <csymbol cd="ambiguous" id="Sx2.E1.m1.4.4.3.2.1.cmml" xref="Sx2.E1.m1.4.4.3.2">
                 subscript
                </csymbol>
                <ci id="Sx2.E1.m1.4.4.3.2.2.cmml" xref="Sx2.E1.m1.4.4.3.2.2">
                 𝑑
                </ci>
                <ci id="Sx2.E1.m1.4.4.3.2.3.cmml" xref="Sx2.E1.m1.4.4.3.2.3">
                 𝑘
                </ci>
               </apply>
              </apply>
             </apply>
             <ci id="Sx2.E1.m1.4.5.3.4.cmml" xref="Sx2.E1.m1.4.5.3.4">
              𝑉
             </ci>
            </apply>
           </apply>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="Sx2.E1.m1.4c">
           \text{Attention}(Q,K,V)=\text{softmax}\left(\frac{QK^{T}}{\sqrt{d_{k}}}\right)V
          </annotation>
         </semantics>
        </math>
       </td>
       <td class="ltx_eqn_cell ltx_eqn_center_padright">
       </td>
       <td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1">
        <span class="ltx_tag ltx_tag_equation ltx_align_right">
         (1)
        </span>
       </td>
      </tr>
     </tbody>
    </table>
   </div>
   <div class="ltx_para" id="Sx2.SSx1.p3">
    <p class="ltx_p" id="Sx2.SSx1.p3.5">
     In this equation,
     <math alttext="Q" class="ltx_Math" display="inline" id="Sx2.SSx1.p3.1.m1.1">
      <semantics id="Sx2.SSx1.p3.1.m1.1a">
       <mi id="Sx2.SSx1.p3.1.m1.1.1" xref="Sx2.SSx1.p3.1.m1.1.1.cmml">
        Q
       </mi>
       <annotation-xml encoding="MathML-Content" id="Sx2.SSx1.p3.1.m1.1b">
        <ci id="Sx2.SSx1.p3.1.m1.1.1.cmml" xref="Sx2.SSx1.p3.1.m1.1.1">
         𝑄
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="Sx2.SSx1.p3.1.m1.1c">
        Q
       </annotation>
      </semantics>
     </math>
     ,
     <math alttext="K" class="ltx_Math" display="inline" id="Sx2.SSx1.p3.2.m2.1">
      <semantics id="Sx2.SSx1.p3.2.m2.1a">
       <mi id="Sx2.SSx1.p3.2.m2.1.1" xref="Sx2.SSx1.p3.2.m2.1.1.cmml">
        K
       </mi>
       <annotation-xml encoding="MathML-Content" id="Sx2.SSx1.p3.2.m2.1b">
        <ci id="Sx2.SSx1.p3.2.m2.1.1.cmml" xref="Sx2.SSx1.p3.2.m2.1.1">
         𝐾
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="Sx2.SSx1.p3.2.m2.1c">
        K
       </annotation>
      </semantics>
     </math>
     , and
     <math alttext="V" class="ltx_Math" display="inline" id="Sx2.SSx1.p3.3.m3.1">
      <semantics id="Sx2.SSx1.p3.3.m3.1a">
       <mi id="Sx2.SSx1.p3.3.m3.1.1" xref="Sx2.SSx1.p3.3.m3.1.1.cmml">
        V
       </mi>
       <annotation-xml encoding="MathML-Content" id="Sx2.SSx1.p3.3.m3.1b">
        <ci id="Sx2.SSx1.p3.3.m3.1.1.cmml" xref="Sx2.SSx1.p3.3.m3.1.1">
         𝑉
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="Sx2.SSx1.p3.3.m3.1c">
        V
       </annotation>
      </semantics>
     </math>
     denote the query, key, and value matrices. The scaling factor
     <math alttext="\sqrt{d_{k}}" class="ltx_Math" display="inline" id="Sx2.SSx1.p3.4.m4.1">
      <semantics id="Sx2.SSx1.p3.4.m4.1a">
       <msqrt id="Sx2.SSx1.p3.4.m4.1.1" xref="Sx2.SSx1.p3.4.m4.1.1.cmml">
        <msub id="Sx2.SSx1.p3.4.m4.1.1.2" xref="Sx2.SSx1.p3.4.m4.1.1.2.cmml">
         <mi id="Sx2.SSx1.p3.4.m4.1.1.2.2" xref="Sx2.SSx1.p3.4.m4.1.1.2.2.cmml">
          d
         </mi>
         <mi id="Sx2.SSx1.p3.4.m4.1.1.2.3" xref="Sx2.SSx1.p3.4.m4.1.1.2.3.cmml">
          k
         </mi>
        </msub>
       </msqrt>
       <annotation-xml encoding="MathML-Content" id="Sx2.SSx1.p3.4.m4.1b">
        <apply id="Sx2.SSx1.p3.4.m4.1.1.cmml" xref="Sx2.SSx1.p3.4.m4.1.1">
         <root id="Sx2.SSx1.p3.4.m4.1.1a.cmml" xref="Sx2.SSx1.p3.4.m4.1.1">
         </root>
         <apply id="Sx2.SSx1.p3.4.m4.1.1.2.cmml" xref="Sx2.SSx1.p3.4.m4.1.1.2">
          <csymbol cd="ambiguous" id="Sx2.SSx1.p3.4.m4.1.1.2.1.cmml" xref="Sx2.SSx1.p3.4.m4.1.1.2">
           subscript
          </csymbol>
          <ci id="Sx2.SSx1.p3.4.m4.1.1.2.2.cmml" xref="Sx2.SSx1.p3.4.m4.1.1.2.2">
           𝑑
          </ci>
          <ci id="Sx2.SSx1.p3.4.m4.1.1.2.3.cmml" xref="Sx2.SSx1.p3.4.m4.1.1.2.3">
           𝑘
          </ci>
         </apply>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="Sx2.SSx1.p3.4.m4.1c">
        \sqrt{d_{k}}
       </annotation>
      </semantics>
     </math>
     , where
     <math alttext="d_{k}" class="ltx_Math" display="inline" id="Sx2.SSx1.p3.5.m5.1">
      <semantics id="Sx2.SSx1.p3.5.m5.1a">
       <msub id="Sx2.SSx1.p3.5.m5.1.1" xref="Sx2.SSx1.p3.5.m5.1.1.cmml">
        <mi id="Sx2.SSx1.p3.5.m5.1.1.2" xref="Sx2.SSx1.p3.5.m5.1.1.2.cmml">
         d
        </mi>
        <mi id="Sx2.SSx1.p3.5.m5.1.1.3" xref="Sx2.SSx1.p3.5.m5.1.1.3.cmml">
         k
        </mi>
       </msub>
       <annotation-xml encoding="MathML-Content" id="Sx2.SSx1.p3.5.m5.1b">
        <apply id="Sx2.SSx1.p3.5.m5.1.1.cmml" xref="Sx2.SSx1.p3.5.m5.1.1">
         <csymbol cd="ambiguous" id="Sx2.SSx1.p3.5.m5.1.1.1.cmml" xref="Sx2.SSx1.p3.5.m5.1.1">
          subscript
         </csymbol>
         <ci id="Sx2.SSx1.p3.5.m5.1.1.2.cmml" xref="Sx2.SSx1.p3.5.m5.1.1.2">
          𝑑
         </ci>
         <ci id="Sx2.SSx1.p3.5.m5.1.1.3.cmml" xref="Sx2.SSx1.p3.5.m5.1.1.3">
          𝑘
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="Sx2.SSx1.p3.5.m5.1c">
        d_{k}
       </annotation>
      </semantics>
     </math>
     is the dimension of the keys, is employed to standardize the vectors to unit variance for ensuring stable softmax gradients during training. Since the introduction of LLMs with self-attention, there have been several architectural variants depending on the downstream tasks.
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="Sx2.SSx1.p4">
    <p class="ltx_p" id="Sx2.SSx1.p4.1">
     <span class="ltx_text ltx_font_bold" id="Sx2.SSx1.p4.1.1">
      Causal Language Modeling (CLMs)
     </span>
     : CLMs, such as GPT-4, are designed for tasks where text generation is sequential and dependent on the preceding context. They predict each subsequent word based on the preceding words, modeling the probability of a word sequence in a forward direction. This process is mathematically formulated as shown in Equation
     <a class="ltx_ref" href="#Sx2.E2" title="In Large Language Models ‣ Background ‣ On the Prospects of Incorporating Large Language Models (LLMs) in Automated Planning and Scheduling (APS)">
      <span class="ltx_text ltx_ref_tag">
       2
      </span>
     </a>
     .
    </p>
   </div>
   <div class="ltx_para" id="Sx2.SSx1.p5">
    <table class="ltx_equation ltx_eqn_table" id="Sx2.E2">
     <tbody>
      <tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
       <td class="ltx_eqn_cell ltx_eqn_center_padleft">
       </td>
       <td class="ltx_eqn_cell ltx_align_center">
        <math alttext="P(T)=\prod_{i=1}^{n}P(t_{i}|t_{&lt;i})" class="ltx_Math" display="block" id="Sx2.E2.m1.2">
         <semantics id="Sx2.E2.m1.2a">
          <mrow id="Sx2.E2.m1.2.2" xref="Sx2.E2.m1.2.2.cmml">
           <mrow id="Sx2.E2.m1.2.2.3" xref="Sx2.E2.m1.2.2.3.cmml">
            <mi id="Sx2.E2.m1.2.2.3.2" xref="Sx2.E2.m1.2.2.3.2.cmml">
             P
            </mi>
            <mo id="Sx2.E2.m1.2.2.3.1" lspace="0em" rspace="0em" xref="Sx2.E2.m1.2.2.3.1.cmml">
             ​
            </mo>
            <mrow id="Sx2.E2.m1.2.2.3.3.2" xref="Sx2.E2.m1.2.2.3.cmml">
             <mo id="Sx2.E2.m1.2.2.3.3.2.1" stretchy="false" xref="Sx2.E2.m1.2.2.3.cmml">
              (
             </mo>
             <mi id="Sx2.E2.m1.1.1" xref="Sx2.E2.m1.1.1.cmml">
              T
             </mi>
             <mo id="Sx2.E2.m1.2.2.3.3.2.2" stretchy="false" xref="Sx2.E2.m1.2.2.3.cmml">
              )
             </mo>
            </mrow>
           </mrow>
           <mo id="Sx2.E2.m1.2.2.2" rspace="0.111em" xref="Sx2.E2.m1.2.2.2.cmml">
            =
           </mo>
           <mrow id="Sx2.E2.m1.2.2.1" xref="Sx2.E2.m1.2.2.1.cmml">
            <munderover id="Sx2.E2.m1.2.2.1.2" xref="Sx2.E2.m1.2.2.1.2.cmml">
             <mo id="Sx2.E2.m1.2.2.1.2.2.2" movablelimits="false" xref="Sx2.E2.m1.2.2.1.2.2.2.cmml">
              ∏
             </mo>
             <mrow id="Sx2.E2.m1.2.2.1.2.2.3" xref="Sx2.E2.m1.2.2.1.2.2.3.cmml">
              <mi id="Sx2.E2.m1.2.2.1.2.2.3.2" xref="Sx2.E2.m1.2.2.1.2.2.3.2.cmml">
               i
              </mi>
              <mo id="Sx2.E2.m1.2.2.1.2.2.3.1" xref="Sx2.E2.m1.2.2.1.2.2.3.1.cmml">
               =
              </mo>
              <mn id="Sx2.E2.m1.2.2.1.2.2.3.3" xref="Sx2.E2.m1.2.2.1.2.2.3.3.cmml">
               1
              </mn>
             </mrow>
             <mi id="Sx2.E2.m1.2.2.1.2.3" xref="Sx2.E2.m1.2.2.1.2.3.cmml">
              n
             </mi>
            </munderover>
            <mrow id="Sx2.E2.m1.2.2.1.1" xref="Sx2.E2.m1.2.2.1.1.cmml">
             <mi id="Sx2.E2.m1.2.2.1.1.3" xref="Sx2.E2.m1.2.2.1.1.3.cmml">
              P
             </mi>
             <mo id="Sx2.E2.m1.2.2.1.1.2" lspace="0em" rspace="0em" xref="Sx2.E2.m1.2.2.1.1.2.cmml">
              ​
             </mo>
             <mrow id="Sx2.E2.m1.2.2.1.1.1.1" xref="Sx2.E2.m1.2.2.1.1.1.1.1.cmml">
              <mo id="Sx2.E2.m1.2.2.1.1.1.1.2" stretchy="false" xref="Sx2.E2.m1.2.2.1.1.1.1.1.cmml">
               (
              </mo>
              <mrow id="Sx2.E2.m1.2.2.1.1.1.1.1" xref="Sx2.E2.m1.2.2.1.1.1.1.1.cmml">
               <msub id="Sx2.E2.m1.2.2.1.1.1.1.1.2" xref="Sx2.E2.m1.2.2.1.1.1.1.1.2.cmml">
                <mi id="Sx2.E2.m1.2.2.1.1.1.1.1.2.2" xref="Sx2.E2.m1.2.2.1.1.1.1.1.2.2.cmml">
                 t
                </mi>
                <mi id="Sx2.E2.m1.2.2.1.1.1.1.1.2.3" xref="Sx2.E2.m1.2.2.1.1.1.1.1.2.3.cmml">
                 i
                </mi>
               </msub>
               <mo fence="false" id="Sx2.E2.m1.2.2.1.1.1.1.1.1" xref="Sx2.E2.m1.2.2.1.1.1.1.1.1.cmml">
                |
               </mo>
               <msub id="Sx2.E2.m1.2.2.1.1.1.1.1.3" xref="Sx2.E2.m1.2.2.1.1.1.1.1.3.cmml">
                <mi id="Sx2.E2.m1.2.2.1.1.1.1.1.3.2" xref="Sx2.E2.m1.2.2.1.1.1.1.1.3.2.cmml">
                 t
                </mi>
                <mrow id="Sx2.E2.m1.2.2.1.1.1.1.1.3.3" xref="Sx2.E2.m1.2.2.1.1.1.1.1.3.3.cmml">
                 <mi id="Sx2.E2.m1.2.2.1.1.1.1.1.3.3.2" xref="Sx2.E2.m1.2.2.1.1.1.1.1.3.3.2.cmml">
                 </mi>
                 <mo id="Sx2.E2.m1.2.2.1.1.1.1.1.3.3.1" xref="Sx2.E2.m1.2.2.1.1.1.1.1.3.3.1.cmml">
                  &lt;
                 </mo>
                 <mi id="Sx2.E2.m1.2.2.1.1.1.1.1.3.3.3" xref="Sx2.E2.m1.2.2.1.1.1.1.1.3.3.3.cmml">
                  i
                 </mi>
                </mrow>
               </msub>
              </mrow>
              <mo id="Sx2.E2.m1.2.2.1.1.1.1.3" stretchy="false" xref="Sx2.E2.m1.2.2.1.1.1.1.1.cmml">
               )
              </mo>
             </mrow>
            </mrow>
           </mrow>
          </mrow>
          <annotation-xml encoding="MathML-Content" id="Sx2.E2.m1.2b">
           <apply id="Sx2.E2.m1.2.2.cmml" xref="Sx2.E2.m1.2.2">
            <eq id="Sx2.E2.m1.2.2.2.cmml" xref="Sx2.E2.m1.2.2.2">
            </eq>
            <apply id="Sx2.E2.m1.2.2.3.cmml" xref="Sx2.E2.m1.2.2.3">
             <times id="Sx2.E2.m1.2.2.3.1.cmml" xref="Sx2.E2.m1.2.2.3.1">
             </times>
             <ci id="Sx2.E2.m1.2.2.3.2.cmml" xref="Sx2.E2.m1.2.2.3.2">
              𝑃
             </ci>
             <ci id="Sx2.E2.m1.1.1.cmml" xref="Sx2.E2.m1.1.1">
              𝑇
             </ci>
            </apply>
            <apply id="Sx2.E2.m1.2.2.1.cmml" xref="Sx2.E2.m1.2.2.1">
             <apply id="Sx2.E2.m1.2.2.1.2.cmml" xref="Sx2.E2.m1.2.2.1.2">
              <csymbol cd="ambiguous" id="Sx2.E2.m1.2.2.1.2.1.cmml" xref="Sx2.E2.m1.2.2.1.2">
               superscript
              </csymbol>
              <apply id="Sx2.E2.m1.2.2.1.2.2.cmml" xref="Sx2.E2.m1.2.2.1.2">
               <csymbol cd="ambiguous" id="Sx2.E2.m1.2.2.1.2.2.1.cmml" xref="Sx2.E2.m1.2.2.1.2">
                subscript
               </csymbol>
               <csymbol cd="latexml" id="Sx2.E2.m1.2.2.1.2.2.2.cmml" xref="Sx2.E2.m1.2.2.1.2.2.2">
                product
               </csymbol>
               <apply id="Sx2.E2.m1.2.2.1.2.2.3.cmml" xref="Sx2.E2.m1.2.2.1.2.2.3">
                <eq id="Sx2.E2.m1.2.2.1.2.2.3.1.cmml" xref="Sx2.E2.m1.2.2.1.2.2.3.1">
                </eq>
                <ci id="Sx2.E2.m1.2.2.1.2.2.3.2.cmml" xref="Sx2.E2.m1.2.2.1.2.2.3.2">
                 𝑖
                </ci>
                <cn id="Sx2.E2.m1.2.2.1.2.2.3.3.cmml" type="integer" xref="Sx2.E2.m1.2.2.1.2.2.3.3">
                 1
                </cn>
               </apply>
              </apply>
              <ci id="Sx2.E2.m1.2.2.1.2.3.cmml" xref="Sx2.E2.m1.2.2.1.2.3">
               𝑛
              </ci>
             </apply>
             <apply id="Sx2.E2.m1.2.2.1.1.cmml" xref="Sx2.E2.m1.2.2.1.1">
              <times id="Sx2.E2.m1.2.2.1.1.2.cmml" xref="Sx2.E2.m1.2.2.1.1.2">
              </times>
              <ci id="Sx2.E2.m1.2.2.1.1.3.cmml" xref="Sx2.E2.m1.2.2.1.1.3">
               𝑃
              </ci>
              <apply id="Sx2.E2.m1.2.2.1.1.1.1.1.cmml" xref="Sx2.E2.m1.2.2.1.1.1.1">
               <csymbol cd="latexml" id="Sx2.E2.m1.2.2.1.1.1.1.1.1.cmml" xref="Sx2.E2.m1.2.2.1.1.1.1.1.1">
                conditional
               </csymbol>
               <apply id="Sx2.E2.m1.2.2.1.1.1.1.1.2.cmml" xref="Sx2.E2.m1.2.2.1.1.1.1.1.2">
                <csymbol cd="ambiguous" id="Sx2.E2.m1.2.2.1.1.1.1.1.2.1.cmml" xref="Sx2.E2.m1.2.2.1.1.1.1.1.2">
                 subscript
                </csymbol>
                <ci id="Sx2.E2.m1.2.2.1.1.1.1.1.2.2.cmml" xref="Sx2.E2.m1.2.2.1.1.1.1.1.2.2">
                 𝑡
                </ci>
                <ci id="Sx2.E2.m1.2.2.1.1.1.1.1.2.3.cmml" xref="Sx2.E2.m1.2.2.1.1.1.1.1.2.3">
                 𝑖
                </ci>
               </apply>
               <apply id="Sx2.E2.m1.2.2.1.1.1.1.1.3.cmml" xref="Sx2.E2.m1.2.2.1.1.1.1.1.3">
                <csymbol cd="ambiguous" id="Sx2.E2.m1.2.2.1.1.1.1.1.3.1.cmml" xref="Sx2.E2.m1.2.2.1.1.1.1.1.3">
                 subscript
                </csymbol>
                <ci id="Sx2.E2.m1.2.2.1.1.1.1.1.3.2.cmml" xref="Sx2.E2.m1.2.2.1.1.1.1.1.3.2">
                 𝑡
                </ci>
                <apply id="Sx2.E2.m1.2.2.1.1.1.1.1.3.3.cmml" xref="Sx2.E2.m1.2.2.1.1.1.1.1.3.3">
                 <lt id="Sx2.E2.m1.2.2.1.1.1.1.1.3.3.1.cmml" xref="Sx2.E2.m1.2.2.1.1.1.1.1.3.3.1">
                 </lt>
                 <csymbol cd="latexml" id="Sx2.E2.m1.2.2.1.1.1.1.1.3.3.2.cmml" xref="Sx2.E2.m1.2.2.1.1.1.1.1.3.3.2">
                  absent
                 </csymbol>
                 <ci id="Sx2.E2.m1.2.2.1.1.1.1.1.3.3.3.cmml" xref="Sx2.E2.m1.2.2.1.1.1.1.1.3.3.3">
                  𝑖
                 </ci>
                </apply>
               </apply>
              </apply>
             </apply>
            </apply>
           </apply>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="Sx2.E2.m1.2c">
           P(T)=\prod_{i=1}^{n}P(t_{i}|t_{&lt;i})
          </annotation>
         </semantics>
        </math>
       </td>
       <td class="ltx_eqn_cell ltx_eqn_center_padright">
       </td>
       <td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1">
        <span class="ltx_tag ltx_tag_equation ltx_align_right">
         (2)
        </span>
       </td>
      </tr>
     </tbody>
    </table>
   </div>
   <div class="ltx_para" id="Sx2.SSx1.p6">
    <p class="ltx_p" id="Sx2.SSx1.p6.3">
     In this formulation,
     <math alttext="P(t_{i}|t_{&lt;i})" class="ltx_Math" display="inline" id="Sx2.SSx1.p6.1.m1.1">
      <semantics id="Sx2.SSx1.p6.1.m1.1a">
       <mrow id="Sx2.SSx1.p6.1.m1.1.1" xref="Sx2.SSx1.p6.1.m1.1.1.cmml">
        <mi id="Sx2.SSx1.p6.1.m1.1.1.3" xref="Sx2.SSx1.p6.1.m1.1.1.3.cmml">
         P
        </mi>
        <mo id="Sx2.SSx1.p6.1.m1.1.1.2" lspace="0em" rspace="0em" xref="Sx2.SSx1.p6.1.m1.1.1.2.cmml">
         ​
        </mo>
        <mrow id="Sx2.SSx1.p6.1.m1.1.1.1.1" xref="Sx2.SSx1.p6.1.m1.1.1.1.1.1.cmml">
         <mo id="Sx2.SSx1.p6.1.m1.1.1.1.1.2" stretchy="false" xref="Sx2.SSx1.p6.1.m1.1.1.1.1.1.cmml">
          (
         </mo>
         <mrow id="Sx2.SSx1.p6.1.m1.1.1.1.1.1" xref="Sx2.SSx1.p6.1.m1.1.1.1.1.1.cmml">
          <msub id="Sx2.SSx1.p6.1.m1.1.1.1.1.1.2" xref="Sx2.SSx1.p6.1.m1.1.1.1.1.1.2.cmml">
           <mi id="Sx2.SSx1.p6.1.m1.1.1.1.1.1.2.2" xref="Sx2.SSx1.p6.1.m1.1.1.1.1.1.2.2.cmml">
            t
           </mi>
           <mi id="Sx2.SSx1.p6.1.m1.1.1.1.1.1.2.3" xref="Sx2.SSx1.p6.1.m1.1.1.1.1.1.2.3.cmml">
            i
           </mi>
          </msub>
          <mo fence="false" id="Sx2.SSx1.p6.1.m1.1.1.1.1.1.1" xref="Sx2.SSx1.p6.1.m1.1.1.1.1.1.1.cmml">
           |
          </mo>
          <msub id="Sx2.SSx1.p6.1.m1.1.1.1.1.1.3" xref="Sx2.SSx1.p6.1.m1.1.1.1.1.1.3.cmml">
           <mi id="Sx2.SSx1.p6.1.m1.1.1.1.1.1.3.2" xref="Sx2.SSx1.p6.1.m1.1.1.1.1.1.3.2.cmml">
            t
           </mi>
           <mrow id="Sx2.SSx1.p6.1.m1.1.1.1.1.1.3.3" xref="Sx2.SSx1.p6.1.m1.1.1.1.1.1.3.3.cmml">
            <mi id="Sx2.SSx1.p6.1.m1.1.1.1.1.1.3.3.2" xref="Sx2.SSx1.p6.1.m1.1.1.1.1.1.3.3.2.cmml">
            </mi>
            <mo id="Sx2.SSx1.p6.1.m1.1.1.1.1.1.3.3.1" xref="Sx2.SSx1.p6.1.m1.1.1.1.1.1.3.3.1.cmml">
             &lt;
            </mo>
            <mi id="Sx2.SSx1.p6.1.m1.1.1.1.1.1.3.3.3" xref="Sx2.SSx1.p6.1.m1.1.1.1.1.1.3.3.3.cmml">
             i
            </mi>
           </mrow>
          </msub>
         </mrow>
         <mo id="Sx2.SSx1.p6.1.m1.1.1.1.1.3" stretchy="false" xref="Sx2.SSx1.p6.1.m1.1.1.1.1.1.cmml">
          )
         </mo>
        </mrow>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="Sx2.SSx1.p6.1.m1.1b">
        <apply id="Sx2.SSx1.p6.1.m1.1.1.cmml" xref="Sx2.SSx1.p6.1.m1.1.1">
         <times id="Sx2.SSx1.p6.1.m1.1.1.2.cmml" xref="Sx2.SSx1.p6.1.m1.1.1.2">
         </times>
         <ci id="Sx2.SSx1.p6.1.m1.1.1.3.cmml" xref="Sx2.SSx1.p6.1.m1.1.1.3">
          𝑃
         </ci>
         <apply id="Sx2.SSx1.p6.1.m1.1.1.1.1.1.cmml" xref="Sx2.SSx1.p6.1.m1.1.1.1.1">
          <csymbol cd="latexml" id="Sx2.SSx1.p6.1.m1.1.1.1.1.1.1.cmml" xref="Sx2.SSx1.p6.1.m1.1.1.1.1.1.1">
           conditional
          </csymbol>
          <apply id="Sx2.SSx1.p6.1.m1.1.1.1.1.1.2.cmml" xref="Sx2.SSx1.p6.1.m1.1.1.1.1.1.2">
           <csymbol cd="ambiguous" id="Sx2.SSx1.p6.1.m1.1.1.1.1.1.2.1.cmml" xref="Sx2.SSx1.p6.1.m1.1.1.1.1.1.2">
            subscript
           </csymbol>
           <ci id="Sx2.SSx1.p6.1.m1.1.1.1.1.1.2.2.cmml" xref="Sx2.SSx1.p6.1.m1.1.1.1.1.1.2.2">
            𝑡
           </ci>
           <ci id="Sx2.SSx1.p6.1.m1.1.1.1.1.1.2.3.cmml" xref="Sx2.SSx1.p6.1.m1.1.1.1.1.1.2.3">
            𝑖
           </ci>
          </apply>
          <apply id="Sx2.SSx1.p6.1.m1.1.1.1.1.1.3.cmml" xref="Sx2.SSx1.p6.1.m1.1.1.1.1.1.3">
           <csymbol cd="ambiguous" id="Sx2.SSx1.p6.1.m1.1.1.1.1.1.3.1.cmml" xref="Sx2.SSx1.p6.1.m1.1.1.1.1.1.3">
            subscript
           </csymbol>
           <ci id="Sx2.SSx1.p6.1.m1.1.1.1.1.1.3.2.cmml" xref="Sx2.SSx1.p6.1.m1.1.1.1.1.1.3.2">
            𝑡
           </ci>
           <apply id="Sx2.SSx1.p6.1.m1.1.1.1.1.1.3.3.cmml" xref="Sx2.SSx1.p6.1.m1.1.1.1.1.1.3.3">
            <lt id="Sx2.SSx1.p6.1.m1.1.1.1.1.1.3.3.1.cmml" xref="Sx2.SSx1.p6.1.m1.1.1.1.1.1.3.3.1">
            </lt>
            <csymbol cd="latexml" id="Sx2.SSx1.p6.1.m1.1.1.1.1.1.3.3.2.cmml" xref="Sx2.SSx1.p6.1.m1.1.1.1.1.1.3.3.2">
             absent
            </csymbol>
            <ci id="Sx2.SSx1.p6.1.m1.1.1.1.1.1.3.3.3.cmml" xref="Sx2.SSx1.p6.1.m1.1.1.1.1.1.3.3.3">
             𝑖
            </ci>
           </apply>
          </apply>
         </apply>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="Sx2.SSx1.p6.1.m1.1c">
        P(t_{i}|t_{&lt;i})
       </annotation>
      </semantics>
     </math>
     represents the probability of the
     <math alttext="i" class="ltx_Math" display="inline" id="Sx2.SSx1.p6.2.m2.1">
      <semantics id="Sx2.SSx1.p6.2.m2.1a">
       <mi id="Sx2.SSx1.p6.2.m2.1.1" xref="Sx2.SSx1.p6.2.m2.1.1.cmml">
        i
       </mi>
       <annotation-xml encoding="MathML-Content" id="Sx2.SSx1.p6.2.m2.1b">
        <ci id="Sx2.SSx1.p6.2.m2.1.1.cmml" xref="Sx2.SSx1.p6.2.m2.1.1">
         𝑖
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="Sx2.SSx1.p6.2.m2.1c">
        i
       </annotation>
      </semantics>
     </math>
     -th token given all preceding tokens,
     <math alttext="t_{&lt;i}" class="ltx_Math" display="inline" id="Sx2.SSx1.p6.3.m3.1">
      <semantics id="Sx2.SSx1.p6.3.m3.1a">
       <msub id="Sx2.SSx1.p6.3.m3.1.1" xref="Sx2.SSx1.p6.3.m3.1.1.cmml">
        <mi id="Sx2.SSx1.p6.3.m3.1.1.2" xref="Sx2.SSx1.p6.3.m3.1.1.2.cmml">
         t
        </mi>
        <mrow id="Sx2.SSx1.p6.3.m3.1.1.3" xref="Sx2.SSx1.p6.3.m3.1.1.3.cmml">
         <mi id="Sx2.SSx1.p6.3.m3.1.1.3.2" xref="Sx2.SSx1.p6.3.m3.1.1.3.2.cmml">
         </mi>
         <mo id="Sx2.SSx1.p6.3.m3.1.1.3.1" xref="Sx2.SSx1.p6.3.m3.1.1.3.1.cmml">
          &lt;
         </mo>
         <mi id="Sx2.SSx1.p6.3.m3.1.1.3.3" xref="Sx2.SSx1.p6.3.m3.1.1.3.3.cmml">
          i
         </mi>
        </mrow>
       </msub>
       <annotation-xml encoding="MathML-Content" id="Sx2.SSx1.p6.3.m3.1b">
        <apply id="Sx2.SSx1.p6.3.m3.1.1.cmml" xref="Sx2.SSx1.p6.3.m3.1.1">
         <csymbol cd="ambiguous" id="Sx2.SSx1.p6.3.m3.1.1.1.cmml" xref="Sx2.SSx1.p6.3.m3.1.1">
          subscript
         </csymbol>
         <ci id="Sx2.SSx1.p6.3.m3.1.1.2.cmml" xref="Sx2.SSx1.p6.3.m3.1.1.2">
          𝑡
         </ci>
         <apply id="Sx2.SSx1.p6.3.m3.1.1.3.cmml" xref="Sx2.SSx1.p6.3.m3.1.1.3">
          <lt id="Sx2.SSx1.p6.3.m3.1.1.3.1.cmml" xref="Sx2.SSx1.p6.3.m3.1.1.3.1">
          </lt>
          <csymbol cd="latexml" id="Sx2.SSx1.p6.3.m3.1.1.3.2.cmml" xref="Sx2.SSx1.p6.3.m3.1.1.3.2">
           absent
          </csymbol>
          <ci id="Sx2.SSx1.p6.3.m3.1.1.3.3.cmml" xref="Sx2.SSx1.p6.3.m3.1.1.3.3">
           𝑖
          </ci>
         </apply>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="Sx2.SSx1.p6.3.m3.1c">
        t_{&lt;i}
       </annotation>
      </semantics>
     </math>
     . This characteristic makes CLMs particularly suitable for applications like content generation, where the flow and coherence of the text in the forward direction are crucial.
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="Sx2.SSx1.p7">
    <p class="ltx_p" id="Sx2.SSx1.p7.1">
     <span class="ltx_text ltx_font_bold" id="Sx2.SSx1.p7.1.1">
      Masked Language Modeling (MLMs)
     </span>
     : Unlike CLMs, MLMs like BERT are trained to understand the bidirectional context by predicting words randomly masked in a sentence. This approach allows the model to learn both forward and backward dependencies in language structure. The MLM prediction process can be represented as Equation
     <a class="ltx_ref" href="#Sx2.E3" title="In Large Language Models ‣ Background ‣ On the Prospects of Incorporating Large Language Models (LLMs) in Automated Planning and Scheduling (APS)">
      <span class="ltx_text ltx_ref_tag">
       3
      </span>
     </a>
     .
    </p>
   </div>
   <div class="ltx_para" id="Sx2.SSx1.p8">
    <table class="ltx_equation ltx_eqn_table" id="Sx2.E3">
     <tbody>
      <tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
       <td class="ltx_eqn_cell ltx_eqn_center_padleft">
       </td>
       <td class="ltx_eqn_cell ltx_align_center">
        <math alttext="P(T_{\text{masked}}|T_{\text{context}})=\prod_{i\in M}P(t_{i}|T_{\text{context}})" class="ltx_Math" display="block" id="Sx2.E3.m1.2">
         <semantics id="Sx2.E3.m1.2a">
          <mrow id="Sx2.E3.m1.2.2" xref="Sx2.E3.m1.2.2.cmml">
           <mrow id="Sx2.E3.m1.1.1.1" xref="Sx2.E3.m1.1.1.1.cmml">
            <mi id="Sx2.E3.m1.1.1.1.3" xref="Sx2.E3.m1.1.1.1.3.cmml">
             P
            </mi>
            <mo id="Sx2.E3.m1.1.1.1.2" lspace="0em" rspace="0em" xref="Sx2.E3.m1.1.1.1.2.cmml">
             ​
            </mo>
            <mrow id="Sx2.E3.m1.1.1.1.1.1" xref="Sx2.E3.m1.1.1.1.1.1.1.cmml">
             <mo id="Sx2.E3.m1.1.1.1.1.1.2" stretchy="false" xref="Sx2.E3.m1.1.1.1.1.1.1.cmml">
              (
             </mo>
             <mrow id="Sx2.E3.m1.1.1.1.1.1.1" xref="Sx2.E3.m1.1.1.1.1.1.1.cmml">
              <msub id="Sx2.E3.m1.1.1.1.1.1.1.2" xref="Sx2.E3.m1.1.1.1.1.1.1.2.cmml">
               <mi id="Sx2.E3.m1.1.1.1.1.1.1.2.2" xref="Sx2.E3.m1.1.1.1.1.1.1.2.2.cmml">
                T
               </mi>
               <mtext id="Sx2.E3.m1.1.1.1.1.1.1.2.3" xref="Sx2.E3.m1.1.1.1.1.1.1.2.3a.cmml">
                masked
               </mtext>
              </msub>
              <mo fence="false" id="Sx2.E3.m1.1.1.1.1.1.1.1" xref="Sx2.E3.m1.1.1.1.1.1.1.1.cmml">
               |
              </mo>
              <msub id="Sx2.E3.m1.1.1.1.1.1.1.3" xref="Sx2.E3.m1.1.1.1.1.1.1.3.cmml">
               <mi id="Sx2.E3.m1.1.1.1.1.1.1.3.2" xref="Sx2.E3.m1.1.1.1.1.1.1.3.2.cmml">
                T
               </mi>
               <mtext id="Sx2.E3.m1.1.1.1.1.1.1.3.3" xref="Sx2.E3.m1.1.1.1.1.1.1.3.3a.cmml">
                context
               </mtext>
              </msub>
             </mrow>
             <mo id="Sx2.E3.m1.1.1.1.1.1.3" stretchy="false" xref="Sx2.E3.m1.1.1.1.1.1.1.cmml">
              )
             </mo>
            </mrow>
           </mrow>
           <mo id="Sx2.E3.m1.2.2.3" rspace="0.111em" xref="Sx2.E3.m1.2.2.3.cmml">
            =
           </mo>
           <mrow id="Sx2.E3.m1.2.2.2" xref="Sx2.E3.m1.2.2.2.cmml">
            <munder id="Sx2.E3.m1.2.2.2.2" xref="Sx2.E3.m1.2.2.2.2.cmml">
             <mo id="Sx2.E3.m1.2.2.2.2.2" movablelimits="false" xref="Sx2.E3.m1.2.2.2.2.2.cmml">
              ∏
             </mo>
             <mrow id="Sx2.E3.m1.2.2.2.2.3" xref="Sx2.E3.m1.2.2.2.2.3.cmml">
              <mi id="Sx2.E3.m1.2.2.2.2.3.2" xref="Sx2.E3.m1.2.2.2.2.3.2.cmml">
               i
              </mi>
              <mo id="Sx2.E3.m1.2.2.2.2.3.1" xref="Sx2.E3.m1.2.2.2.2.3.1.cmml">
               ∈
              </mo>
              <mi id="Sx2.E3.m1.2.2.2.2.3.3" xref="Sx2.E3.m1.2.2.2.2.3.3.cmml">
               M
              </mi>
             </mrow>
            </munder>
            <mrow id="Sx2.E3.m1.2.2.2.1" xref="Sx2.E3.m1.2.2.2.1.cmml">
             <mi id="Sx2.E3.m1.2.2.2.1.3" xref="Sx2.E3.m1.2.2.2.1.3.cmml">
              P
             </mi>
             <mo id="Sx2.E3.m1.2.2.2.1.2" lspace="0em" rspace="0em" xref="Sx2.E3.m1.2.2.2.1.2.cmml">
              ​
             </mo>
             <mrow id="Sx2.E3.m1.2.2.2.1.1.1" xref="Sx2.E3.m1.2.2.2.1.1.1.1.cmml">
              <mo id="Sx2.E3.m1.2.2.2.1.1.1.2" stretchy="false" xref="Sx2.E3.m1.2.2.2.1.1.1.1.cmml">
               (
              </mo>
              <mrow id="Sx2.E3.m1.2.2.2.1.1.1.1" xref="Sx2.E3.m1.2.2.2.1.1.1.1.cmml">
               <msub id="Sx2.E3.m1.2.2.2.1.1.1.1.2" xref="Sx2.E3.m1.2.2.2.1.1.1.1.2.cmml">
                <mi id="Sx2.E3.m1.2.2.2.1.1.1.1.2.2" xref="Sx2.E3.m1.2.2.2.1.1.1.1.2.2.cmml">
                 t
                </mi>
                <mi id="Sx2.E3.m1.2.2.2.1.1.1.1.2.3" xref="Sx2.E3.m1.2.2.2.1.1.1.1.2.3.cmml">
                 i
                </mi>
               </msub>
               <mo fence="false" id="Sx2.E3.m1.2.2.2.1.1.1.1.1" xref="Sx2.E3.m1.2.2.2.1.1.1.1.1.cmml">
                |
               </mo>
               <msub id="Sx2.E3.m1.2.2.2.1.1.1.1.3" xref="Sx2.E3.m1.2.2.2.1.1.1.1.3.cmml">
                <mi id="Sx2.E3.m1.2.2.2.1.1.1.1.3.2" xref="Sx2.E3.m1.2.2.2.1.1.1.1.3.2.cmml">
                 T
                </mi>
                <mtext id="Sx2.E3.m1.2.2.2.1.1.1.1.3.3" xref="Sx2.E3.m1.2.2.2.1.1.1.1.3.3a.cmml">
                 context
                </mtext>
               </msub>
              </mrow>
              <mo id="Sx2.E3.m1.2.2.2.1.1.1.3" stretchy="false" xref="Sx2.E3.m1.2.2.2.1.1.1.1.cmml">
               )
              </mo>
             </mrow>
            </mrow>
           </mrow>
          </mrow>
          <annotation-xml encoding="MathML-Content" id="Sx2.E3.m1.2b">
           <apply id="Sx2.E3.m1.2.2.cmml" xref="Sx2.E3.m1.2.2">
            <eq id="Sx2.E3.m1.2.2.3.cmml" xref="Sx2.E3.m1.2.2.3">
            </eq>
            <apply id="Sx2.E3.m1.1.1.1.cmml" xref="Sx2.E3.m1.1.1.1">
             <times id="Sx2.E3.m1.1.1.1.2.cmml" xref="Sx2.E3.m1.1.1.1.2">
             </times>
             <ci id="Sx2.E3.m1.1.1.1.3.cmml" xref="Sx2.E3.m1.1.1.1.3">
              𝑃
             </ci>
             <apply id="Sx2.E3.m1.1.1.1.1.1.1.cmml" xref="Sx2.E3.m1.1.1.1.1.1">
              <csymbol cd="latexml" id="Sx2.E3.m1.1.1.1.1.1.1.1.cmml" xref="Sx2.E3.m1.1.1.1.1.1.1.1">
               conditional
              </csymbol>
              <apply id="Sx2.E3.m1.1.1.1.1.1.1.2.cmml" xref="Sx2.E3.m1.1.1.1.1.1.1.2">
               <csymbol cd="ambiguous" id="Sx2.E3.m1.1.1.1.1.1.1.2.1.cmml" xref="Sx2.E3.m1.1.1.1.1.1.1.2">
                subscript
               </csymbol>
               <ci id="Sx2.E3.m1.1.1.1.1.1.1.2.2.cmml" xref="Sx2.E3.m1.1.1.1.1.1.1.2.2">
                𝑇
               </ci>
               <ci id="Sx2.E3.m1.1.1.1.1.1.1.2.3a.cmml" xref="Sx2.E3.m1.1.1.1.1.1.1.2.3">
                <mtext id="Sx2.E3.m1.1.1.1.1.1.1.2.3.cmml" mathsize="70%" xref="Sx2.E3.m1.1.1.1.1.1.1.2.3">
                 masked
                </mtext>
               </ci>
              </apply>
              <apply id="Sx2.E3.m1.1.1.1.1.1.1.3.cmml" xref="Sx2.E3.m1.1.1.1.1.1.1.3">
               <csymbol cd="ambiguous" id="Sx2.E3.m1.1.1.1.1.1.1.3.1.cmml" xref="Sx2.E3.m1.1.1.1.1.1.1.3">
                subscript
               </csymbol>
               <ci id="Sx2.E3.m1.1.1.1.1.1.1.3.2.cmml" xref="Sx2.E3.m1.1.1.1.1.1.1.3.2">
                𝑇
               </ci>
               <ci id="Sx2.E3.m1.1.1.1.1.1.1.3.3a.cmml" xref="Sx2.E3.m1.1.1.1.1.1.1.3.3">
                <mtext id="Sx2.E3.m1.1.1.1.1.1.1.3.3.cmml" mathsize="70%" xref="Sx2.E3.m1.1.1.1.1.1.1.3.3">
                 context
                </mtext>
               </ci>
              </apply>
             </apply>
            </apply>
            <apply id="Sx2.E3.m1.2.2.2.cmml" xref="Sx2.E3.m1.2.2.2">
             <apply id="Sx2.E3.m1.2.2.2.2.cmml" xref="Sx2.E3.m1.2.2.2.2">
              <csymbol cd="ambiguous" id="Sx2.E3.m1.2.2.2.2.1.cmml" xref="Sx2.E3.m1.2.2.2.2">
               subscript
              </csymbol>
              <csymbol cd="latexml" id="Sx2.E3.m1.2.2.2.2.2.cmml" xref="Sx2.E3.m1.2.2.2.2.2">
               product
              </csymbol>
              <apply id="Sx2.E3.m1.2.2.2.2.3.cmml" xref="Sx2.E3.m1.2.2.2.2.3">
               <in id="Sx2.E3.m1.2.2.2.2.3.1.cmml" xref="Sx2.E3.m1.2.2.2.2.3.1">
               </in>
               <ci id="Sx2.E3.m1.2.2.2.2.3.2.cmml" xref="Sx2.E3.m1.2.2.2.2.3.2">
                𝑖
               </ci>
               <ci id="Sx2.E3.m1.2.2.2.2.3.3.cmml" xref="Sx2.E3.m1.2.2.2.2.3.3">
                𝑀
               </ci>
              </apply>
             </apply>
             <apply id="Sx2.E3.m1.2.2.2.1.cmml" xref="Sx2.E3.m1.2.2.2.1">
              <times id="Sx2.E3.m1.2.2.2.1.2.cmml" xref="Sx2.E3.m1.2.2.2.1.2">
              </times>
              <ci id="Sx2.E3.m1.2.2.2.1.3.cmml" xref="Sx2.E3.m1.2.2.2.1.3">
               𝑃
              </ci>
              <apply id="Sx2.E3.m1.2.2.2.1.1.1.1.cmml" xref="Sx2.E3.m1.2.2.2.1.1.1">
               <csymbol cd="latexml" id="Sx2.E3.m1.2.2.2.1.1.1.1.1.cmml" xref="Sx2.E3.m1.2.2.2.1.1.1.1.1">
                conditional
               </csymbol>
               <apply id="Sx2.E3.m1.2.2.2.1.1.1.1.2.cmml" xref="Sx2.E3.m1.2.2.2.1.1.1.1.2">
                <csymbol cd="ambiguous" id="Sx2.E3.m1.2.2.2.1.1.1.1.2.1.cmml" xref="Sx2.E3.m1.2.2.2.1.1.1.1.2">
                 subscript
                </csymbol>
                <ci id="Sx2.E3.m1.2.2.2.1.1.1.1.2.2.cmml" xref="Sx2.E3.m1.2.2.2.1.1.1.1.2.2">
                 𝑡
                </ci>
                <ci id="Sx2.E3.m1.2.2.2.1.1.1.1.2.3.cmml" xref="Sx2.E3.m1.2.2.2.1.1.1.1.2.3">
                 𝑖
                </ci>
               </apply>
               <apply id="Sx2.E3.m1.2.2.2.1.1.1.1.3.cmml" xref="Sx2.E3.m1.2.2.2.1.1.1.1.3">
                <csymbol cd="ambiguous" id="Sx2.E3.m1.2.2.2.1.1.1.1.3.1.cmml" xref="Sx2.E3.m1.2.2.2.1.1.1.1.3">
                 subscript
                </csymbol>
                <ci id="Sx2.E3.m1.2.2.2.1.1.1.1.3.2.cmml" xref="Sx2.E3.m1.2.2.2.1.1.1.1.3.2">
                 𝑇
                </ci>
                <ci id="Sx2.E3.m1.2.2.2.1.1.1.1.3.3a.cmml" xref="Sx2.E3.m1.2.2.2.1.1.1.1.3.3">
                 <mtext id="Sx2.E3.m1.2.2.2.1.1.1.1.3.3.cmml" mathsize="70%" xref="Sx2.E3.m1.2.2.2.1.1.1.1.3.3">
                  context
                 </mtext>
                </ci>
               </apply>
              </apply>
             </apply>
            </apply>
           </apply>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="Sx2.E3.m1.2c">
           P(T_{\text{masked}}|T_{\text{context}})=\prod_{i\in M}P(t_{i}|T_{\text{context}})
          </annotation>
         </semantics>
        </math>
       </td>
       <td class="ltx_eqn_cell ltx_eqn_center_padright">
       </td>
       <td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1">
        <span class="ltx_tag ltx_tag_equation ltx_align_right">
         (3)
        </span>
       </td>
      </tr>
     </tbody>
    </table>
   </div>
   <div class="ltx_para" id="Sx2.SSx1.p9">
    <p class="ltx_p" id="Sx2.SSx1.p9.3">
     Here,
     <math alttext="T_{\text{masked}}" class="ltx_Math" display="inline" id="Sx2.SSx1.p9.1.m1.1">
      <semantics id="Sx2.SSx1.p9.1.m1.1a">
       <msub id="Sx2.SSx1.p9.1.m1.1.1" xref="Sx2.SSx1.p9.1.m1.1.1.cmml">
        <mi id="Sx2.SSx1.p9.1.m1.1.1.2" xref="Sx2.SSx1.p9.1.m1.1.1.2.cmml">
         T
        </mi>
        <mtext id="Sx2.SSx1.p9.1.m1.1.1.3" xref="Sx2.SSx1.p9.1.m1.1.1.3a.cmml">
         masked
        </mtext>
       </msub>
       <annotation-xml encoding="MathML-Content" id="Sx2.SSx1.p9.1.m1.1b">
        <apply id="Sx2.SSx1.p9.1.m1.1.1.cmml" xref="Sx2.SSx1.p9.1.m1.1.1">
         <csymbol cd="ambiguous" id="Sx2.SSx1.p9.1.m1.1.1.1.cmml" xref="Sx2.SSx1.p9.1.m1.1.1">
          subscript
         </csymbol>
         <ci id="Sx2.SSx1.p9.1.m1.1.1.2.cmml" xref="Sx2.SSx1.p9.1.m1.1.1.2">
          𝑇
         </ci>
         <ci id="Sx2.SSx1.p9.1.m1.1.1.3a.cmml" xref="Sx2.SSx1.p9.1.m1.1.1.3">
          <mtext id="Sx2.SSx1.p9.1.m1.1.1.3.cmml" mathsize="70%" xref="Sx2.SSx1.p9.1.m1.1.1.3">
           masked
          </mtext>
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="Sx2.SSx1.p9.1.m1.1c">
        T_{\text{masked}}
       </annotation>
      </semantics>
     </math>
     is the set of masked tokens in the sentence,
     <math alttext="T_{\text{context}}" class="ltx_Math" display="inline" id="Sx2.SSx1.p9.2.m2.1">
      <semantics id="Sx2.SSx1.p9.2.m2.1a">
       <msub id="Sx2.SSx1.p9.2.m2.1.1" xref="Sx2.SSx1.p9.2.m2.1.1.cmml">
        <mi id="Sx2.SSx1.p9.2.m2.1.1.2" xref="Sx2.SSx1.p9.2.m2.1.1.2.cmml">
         T
        </mi>
        <mtext id="Sx2.SSx1.p9.2.m2.1.1.3" xref="Sx2.SSx1.p9.2.m2.1.1.3a.cmml">
         context
        </mtext>
       </msub>
       <annotation-xml encoding="MathML-Content" id="Sx2.SSx1.p9.2.m2.1b">
        <apply id="Sx2.SSx1.p9.2.m2.1.1.cmml" xref="Sx2.SSx1.p9.2.m2.1.1">
         <csymbol cd="ambiguous" id="Sx2.SSx1.p9.2.m2.1.1.1.cmml" xref="Sx2.SSx1.p9.2.m2.1.1">
          subscript
         </csymbol>
         <ci id="Sx2.SSx1.p9.2.m2.1.1.2.cmml" xref="Sx2.SSx1.p9.2.m2.1.1.2">
          𝑇
         </ci>
         <ci id="Sx2.SSx1.p9.2.m2.1.1.3a.cmml" xref="Sx2.SSx1.p9.2.m2.1.1.3">
          <mtext id="Sx2.SSx1.p9.2.m2.1.1.3.cmml" mathsize="70%" xref="Sx2.SSx1.p9.2.m2.1.1.3">
           context
          </mtext>
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="Sx2.SSx1.p9.2.m2.1c">
        T_{\text{context}}
       </annotation>
      </semantics>
     </math>
     represents the unmasked part of the sentence, and
     <math alttext="M" class="ltx_Math" display="inline" id="Sx2.SSx1.p9.3.m3.1">
      <semantics id="Sx2.SSx1.p9.3.m3.1a">
       <mi id="Sx2.SSx1.p9.3.m3.1.1" xref="Sx2.SSx1.p9.3.m3.1.1.cmml">
        M
       </mi>
       <annotation-xml encoding="MathML-Content" id="Sx2.SSx1.p9.3.m3.1b">
        <ci id="Sx2.SSx1.p9.3.m3.1.1.cmml" xref="Sx2.SSx1.p9.3.m3.1.1">
         𝑀
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="Sx2.SSx1.p9.3.m3.1c">
        M
       </annotation>
      </semantics>
     </math>
     is the set of masked positions. MLMs have proven effective in NLP tasks such as sentiment analysis or question answering.
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="Sx2.SSx1.p10">
    <p class="ltx_p" id="Sx2.SSx1.p10.1">
     <span class="ltx_text ltx_font_bold" id="Sx2.SSx1.p10.1.1">
      Sequence-to-Sequence (Seq2Seq) Modeling
     </span>
     : Seq2Seq models, like T5, are designed to transform an input sequence into a related output sequence. They are often employed in tasks that require a mapping between different types of sequences, such as language translation or summarization. The Seq2Seq process is formulated as Equation
     <a class="ltx_ref" href="#Sx2.E4" title="In Large Language Models ‣ Background ‣ On the Prospects of Incorporating Large Language Models (LLMs) in Automated Planning and Scheduling (APS)">
      <span class="ltx_text ltx_ref_tag">
       4
      </span>
     </a>
     .
    </p>
   </div>
   <div class="ltx_para" id="Sx2.SSx1.p11">
    <table class="ltx_equation ltx_eqn_table" id="Sx2.E4">
     <tbody>
      <tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
       <td class="ltx_eqn_cell ltx_eqn_center_padleft">
       </td>
       <td class="ltx_eqn_cell ltx_align_center">
        <math alttext="P(T_{\text{output}}|T_{\text{input}})=\prod_{i=1}^{m}P(t_{\text{output}_{i}}|T_{\text{input}},t_{\text{output}_{&lt;i}})" class="ltx_Math" display="block" id="Sx2.E4.m1.2">
         <semantics id="Sx2.E4.m1.2a">
          <mrow id="Sx2.E4.m1.2.2" xref="Sx2.E4.m1.2.2.cmml">
           <mrow id="Sx2.E4.m1.1.1.1" xref="Sx2.E4.m1.1.1.1.cmml">
            <mi id="Sx2.E4.m1.1.1.1.3" xref="Sx2.E4.m1.1.1.1.3.cmml">
             P
            </mi>
            <mo id="Sx2.E4.m1.1.1.1.2" lspace="0em" rspace="0em" xref="Sx2.E4.m1.1.1.1.2.cmml">
             ​
            </mo>
            <mrow id="Sx2.E4.m1.1.1.1.1.1" xref="Sx2.E4.m1.1.1.1.1.1.1.cmml">
             <mo id="Sx2.E4.m1.1.1.1.1.1.2" stretchy="false" xref="Sx2.E4.m1.1.1.1.1.1.1.cmml">
              (
             </mo>
             <mrow id="Sx2.E4.m1.1.1.1.1.1.1" xref="Sx2.E4.m1.1.1.1.1.1.1.cmml">
              <msub id="Sx2.E4.m1.1.1.1.1.1.1.2" xref="Sx2.E4.m1.1.1.1.1.1.1.2.cmml">
               <mi id="Sx2.E4.m1.1.1.1.1.1.1.2.2" xref="Sx2.E4.m1.1.1.1.1.1.1.2.2.cmml">
                T
               </mi>
               <mtext id="Sx2.E4.m1.1.1.1.1.1.1.2.3" xref="Sx2.E4.m1.1.1.1.1.1.1.2.3a.cmml">
                output
               </mtext>
              </msub>
              <mo fence="false" id="Sx2.E4.m1.1.1.1.1.1.1.1" xref="Sx2.E4.m1.1.1.1.1.1.1.1.cmml">
               |
              </mo>
              <msub id="Sx2.E4.m1.1.1.1.1.1.1.3" xref="Sx2.E4.m1.1.1.1.1.1.1.3.cmml">
               <mi id="Sx2.E4.m1.1.1.1.1.1.1.3.2" xref="Sx2.E4.m1.1.1.1.1.1.1.3.2.cmml">
                T
               </mi>
               <mtext id="Sx2.E4.m1.1.1.1.1.1.1.3.3" xref="Sx2.E4.m1.1.1.1.1.1.1.3.3a.cmml">
                input
               </mtext>
              </msub>
             </mrow>
             <mo id="Sx2.E4.m1.1.1.1.1.1.3" stretchy="false" xref="Sx2.E4.m1.1.1.1.1.1.1.cmml">
              )
             </mo>
            </mrow>
           </mrow>
           <mo id="Sx2.E4.m1.2.2.3" rspace="0.111em" xref="Sx2.E4.m1.2.2.3.cmml">
            =
           </mo>
           <mrow id="Sx2.E4.m1.2.2.2" xref="Sx2.E4.m1.2.2.2.cmml">
            <munderover id="Sx2.E4.m1.2.2.2.2" xref="Sx2.E4.m1.2.2.2.2.cmml">
             <mo id="Sx2.E4.m1.2.2.2.2.2.2" movablelimits="false" xref="Sx2.E4.m1.2.2.2.2.2.2.cmml">
              ∏
             </mo>
             <mrow id="Sx2.E4.m1.2.2.2.2.2.3" xref="Sx2.E4.m1.2.2.2.2.2.3.cmml">
              <mi id="Sx2.E4.m1.2.2.2.2.2.3.2" xref="Sx2.E4.m1.2.2.2.2.2.3.2.cmml">
               i
              </mi>
              <mo id="Sx2.E4.m1.2.2.2.2.2.3.1" xref="Sx2.E4.m1.2.2.2.2.2.3.1.cmml">
               =
              </mo>
              <mn id="Sx2.E4.m1.2.2.2.2.2.3.3" xref="Sx2.E4.m1.2.2.2.2.2.3.3.cmml">
               1
              </mn>
             </mrow>
             <mi id="Sx2.E4.m1.2.2.2.2.3" xref="Sx2.E4.m1.2.2.2.2.3.cmml">
              m
             </mi>
            </munderover>
            <mrow id="Sx2.E4.m1.2.2.2.1" xref="Sx2.E4.m1.2.2.2.1.cmml">
             <mi id="Sx2.E4.m1.2.2.2.1.3" xref="Sx2.E4.m1.2.2.2.1.3.cmml">
              P
             </mi>
             <mo id="Sx2.E4.m1.2.2.2.1.2" lspace="0em" rspace="0em" xref="Sx2.E4.m1.2.2.2.1.2.cmml">
              ​
             </mo>
             <mrow id="Sx2.E4.m1.2.2.2.1.1.1" xref="Sx2.E4.m1.2.2.2.1.1.1.1.cmml">
              <mo id="Sx2.E4.m1.2.2.2.1.1.1.2" stretchy="false" xref="Sx2.E4.m1.2.2.2.1.1.1.1.cmml">
               (
              </mo>
              <mrow id="Sx2.E4.m1.2.2.2.1.1.1.1" xref="Sx2.E4.m1.2.2.2.1.1.1.1.cmml">
               <msub id="Sx2.E4.m1.2.2.2.1.1.1.1.4" xref="Sx2.E4.m1.2.2.2.1.1.1.1.4.cmml">
                <mi id="Sx2.E4.m1.2.2.2.1.1.1.1.4.2" xref="Sx2.E4.m1.2.2.2.1.1.1.1.4.2.cmml">
                 t
                </mi>
                <msub id="Sx2.E4.m1.2.2.2.1.1.1.1.4.3" xref="Sx2.E4.m1.2.2.2.1.1.1.1.4.3.cmml">
                 <mtext id="Sx2.E4.m1.2.2.2.1.1.1.1.4.3.2" xref="Sx2.E4.m1.2.2.2.1.1.1.1.4.3.2a.cmml">
                  output
                 </mtext>
                 <mi id="Sx2.E4.m1.2.2.2.1.1.1.1.4.3.3" xref="Sx2.E4.m1.2.2.2.1.1.1.1.4.3.3.cmml">
                  i
                 </mi>
                </msub>
               </msub>
               <mo fence="false" id="Sx2.E4.m1.2.2.2.1.1.1.1.3" xref="Sx2.E4.m1.2.2.2.1.1.1.1.3.cmml">
                |
               </mo>
               <mrow id="Sx2.E4.m1.2.2.2.1.1.1.1.2.2" xref="Sx2.E4.m1.2.2.2.1.1.1.1.2.3.cmml">
                <msub id="Sx2.E4.m1.2.2.2.1.1.1.1.1.1.1" xref="Sx2.E4.m1.2.2.2.1.1.1.1.1.1.1.cmml">
                 <mi id="Sx2.E4.m1.2.2.2.1.1.1.1.1.1.1.2" xref="Sx2.E4.m1.2.2.2.1.1.1.1.1.1.1.2.cmml">
                  T
                 </mi>
                 <mtext id="Sx2.E4.m1.2.2.2.1.1.1.1.1.1.1.3" xref="Sx2.E4.m1.2.2.2.1.1.1.1.1.1.1.3a.cmml">
                  input
                 </mtext>
                </msub>
                <mo id="Sx2.E4.m1.2.2.2.1.1.1.1.2.2.3" xref="Sx2.E4.m1.2.2.2.1.1.1.1.2.3.cmml">
                 ,
                </mo>
                <msub id="Sx2.E4.m1.2.2.2.1.1.1.1.2.2.2" xref="Sx2.E4.m1.2.2.2.1.1.1.1.2.2.2.cmml">
                 <mi id="Sx2.E4.m1.2.2.2.1.1.1.1.2.2.2.2" xref="Sx2.E4.m1.2.2.2.1.1.1.1.2.2.2.2.cmml">
                  t
                 </mi>
                 <msub id="Sx2.E4.m1.2.2.2.1.1.1.1.2.2.2.3" xref="Sx2.E4.m1.2.2.2.1.1.1.1.2.2.2.3.cmml">
                  <mtext id="Sx2.E4.m1.2.2.2.1.1.1.1.2.2.2.3.2" xref="Sx2.E4.m1.2.2.2.1.1.1.1.2.2.2.3.2a.cmml">
                   output
                  </mtext>
                  <mrow id="Sx2.E4.m1.2.2.2.1.1.1.1.2.2.2.3.3" xref="Sx2.E4.m1.2.2.2.1.1.1.1.2.2.2.3.3.cmml">
                   <mi id="Sx2.E4.m1.2.2.2.1.1.1.1.2.2.2.3.3.2" xref="Sx2.E4.m1.2.2.2.1.1.1.1.2.2.2.3.3.2.cmml">
                   </mi>
                   <mo id="Sx2.E4.m1.2.2.2.1.1.1.1.2.2.2.3.3.1" xref="Sx2.E4.m1.2.2.2.1.1.1.1.2.2.2.3.3.1.cmml">
                    &lt;
                   </mo>
                   <mi id="Sx2.E4.m1.2.2.2.1.1.1.1.2.2.2.3.3.3" xref="Sx2.E4.m1.2.2.2.1.1.1.1.2.2.2.3.3.3.cmml">
                    i
                   </mi>
                  </mrow>
                 </msub>
                </msub>
               </mrow>
              </mrow>
              <mo id="Sx2.E4.m1.2.2.2.1.1.1.3" stretchy="false" xref="Sx2.E4.m1.2.2.2.1.1.1.1.cmml">
               )
              </mo>
             </mrow>
            </mrow>
           </mrow>
          </mrow>
          <annotation-xml encoding="MathML-Content" id="Sx2.E4.m1.2b">
           <apply id="Sx2.E4.m1.2.2.cmml" xref="Sx2.E4.m1.2.2">
            <eq id="Sx2.E4.m1.2.2.3.cmml" xref="Sx2.E4.m1.2.2.3">
            </eq>
            <apply id="Sx2.E4.m1.1.1.1.cmml" xref="Sx2.E4.m1.1.1.1">
             <times id="Sx2.E4.m1.1.1.1.2.cmml" xref="Sx2.E4.m1.1.1.1.2">
             </times>
             <ci id="Sx2.E4.m1.1.1.1.3.cmml" xref="Sx2.E4.m1.1.1.1.3">
              𝑃
             </ci>
             <apply id="Sx2.E4.m1.1.1.1.1.1.1.cmml" xref="Sx2.E4.m1.1.1.1.1.1">
              <csymbol cd="latexml" id="Sx2.E4.m1.1.1.1.1.1.1.1.cmml" xref="Sx2.E4.m1.1.1.1.1.1.1.1">
               conditional
              </csymbol>
              <apply id="Sx2.E4.m1.1.1.1.1.1.1.2.cmml" xref="Sx2.E4.m1.1.1.1.1.1.1.2">
               <csymbol cd="ambiguous" id="Sx2.E4.m1.1.1.1.1.1.1.2.1.cmml" xref="Sx2.E4.m1.1.1.1.1.1.1.2">
                subscript
               </csymbol>
               <ci id="Sx2.E4.m1.1.1.1.1.1.1.2.2.cmml" xref="Sx2.E4.m1.1.1.1.1.1.1.2.2">
                𝑇
               </ci>
               <ci id="Sx2.E4.m1.1.1.1.1.1.1.2.3a.cmml" xref="Sx2.E4.m1.1.1.1.1.1.1.2.3">
                <mtext id="Sx2.E4.m1.1.1.1.1.1.1.2.3.cmml" mathsize="70%" xref="Sx2.E4.m1.1.1.1.1.1.1.2.3">
                 output
                </mtext>
               </ci>
              </apply>
              <apply id="Sx2.E4.m1.1.1.1.1.1.1.3.cmml" xref="Sx2.E4.m1.1.1.1.1.1.1.3">
               <csymbol cd="ambiguous" id="Sx2.E4.m1.1.1.1.1.1.1.3.1.cmml" xref="Sx2.E4.m1.1.1.1.1.1.1.3">
                subscript
               </csymbol>
               <ci id="Sx2.E4.m1.1.1.1.1.1.1.3.2.cmml" xref="Sx2.E4.m1.1.1.1.1.1.1.3.2">
                𝑇
               </ci>
               <ci id="Sx2.E4.m1.1.1.1.1.1.1.3.3a.cmml" xref="Sx2.E4.m1.1.1.1.1.1.1.3.3">
                <mtext id="Sx2.E4.m1.1.1.1.1.1.1.3.3.cmml" mathsize="70%" xref="Sx2.E4.m1.1.1.1.1.1.1.3.3">
                 input
                </mtext>
               </ci>
              </apply>
             </apply>
            </apply>
            <apply id="Sx2.E4.m1.2.2.2.cmml" xref="Sx2.E4.m1.2.2.2">
             <apply id="Sx2.E4.m1.2.2.2.2.cmml" xref="Sx2.E4.m1.2.2.2.2">
              <csymbol cd="ambiguous" id="Sx2.E4.m1.2.2.2.2.1.cmml" xref="Sx2.E4.m1.2.2.2.2">
               superscript
              </csymbol>
              <apply id="Sx2.E4.m1.2.2.2.2.2.cmml" xref="Sx2.E4.m1.2.2.2.2">
               <csymbol cd="ambiguous" id="Sx2.E4.m1.2.2.2.2.2.1.cmml" xref="Sx2.E4.m1.2.2.2.2">
                subscript
               </csymbol>
               <csymbol cd="latexml" id="Sx2.E4.m1.2.2.2.2.2.2.cmml" xref="Sx2.E4.m1.2.2.2.2.2.2">
                product
               </csymbol>
               <apply id="Sx2.E4.m1.2.2.2.2.2.3.cmml" xref="Sx2.E4.m1.2.2.2.2.2.3">
                <eq id="Sx2.E4.m1.2.2.2.2.2.3.1.cmml" xref="Sx2.E4.m1.2.2.2.2.2.3.1">
                </eq>
                <ci id="Sx2.E4.m1.2.2.2.2.2.3.2.cmml" xref="Sx2.E4.m1.2.2.2.2.2.3.2">
                 𝑖
                </ci>
                <cn id="Sx2.E4.m1.2.2.2.2.2.3.3.cmml" type="integer" xref="Sx2.E4.m1.2.2.2.2.2.3.3">
                 1
                </cn>
               </apply>
              </apply>
              <ci id="Sx2.E4.m1.2.2.2.2.3.cmml" xref="Sx2.E4.m1.2.2.2.2.3">
               𝑚
              </ci>
             </apply>
             <apply id="Sx2.E4.m1.2.2.2.1.cmml" xref="Sx2.E4.m1.2.2.2.1">
              <times id="Sx2.E4.m1.2.2.2.1.2.cmml" xref="Sx2.E4.m1.2.2.2.1.2">
              </times>
              <ci id="Sx2.E4.m1.2.2.2.1.3.cmml" xref="Sx2.E4.m1.2.2.2.1.3">
               𝑃
              </ci>
              <apply id="Sx2.E4.m1.2.2.2.1.1.1.1.cmml" xref="Sx2.E4.m1.2.2.2.1.1.1">
               <csymbol cd="latexml" id="Sx2.E4.m1.2.2.2.1.1.1.1.3.cmml" xref="Sx2.E4.m1.2.2.2.1.1.1.1.3">
                conditional
               </csymbol>
               <apply id="Sx2.E4.m1.2.2.2.1.1.1.1.4.cmml" xref="Sx2.E4.m1.2.2.2.1.1.1.1.4">
                <csymbol cd="ambiguous" id="Sx2.E4.m1.2.2.2.1.1.1.1.4.1.cmml" xref="Sx2.E4.m1.2.2.2.1.1.1.1.4">
                 subscript
                </csymbol>
                <ci id="Sx2.E4.m1.2.2.2.1.1.1.1.4.2.cmml" xref="Sx2.E4.m1.2.2.2.1.1.1.1.4.2">
                 𝑡
                </ci>
                <apply id="Sx2.E4.m1.2.2.2.1.1.1.1.4.3.cmml" xref="Sx2.E4.m1.2.2.2.1.1.1.1.4.3">
                 <csymbol cd="ambiguous" id="Sx2.E4.m1.2.2.2.1.1.1.1.4.3.1.cmml" xref="Sx2.E4.m1.2.2.2.1.1.1.1.4.3">
                  subscript
                 </csymbol>
                 <ci id="Sx2.E4.m1.2.2.2.1.1.1.1.4.3.2a.cmml" xref="Sx2.E4.m1.2.2.2.1.1.1.1.4.3.2">
                  <mtext id="Sx2.E4.m1.2.2.2.1.1.1.1.4.3.2.cmml" mathsize="70%" xref="Sx2.E4.m1.2.2.2.1.1.1.1.4.3.2">
                   output
                  </mtext>
                 </ci>
                 <ci id="Sx2.E4.m1.2.2.2.1.1.1.1.4.3.3.cmml" xref="Sx2.E4.m1.2.2.2.1.1.1.1.4.3.3">
                  𝑖
                 </ci>
                </apply>
               </apply>
               <list id="Sx2.E4.m1.2.2.2.1.1.1.1.2.3.cmml" xref="Sx2.E4.m1.2.2.2.1.1.1.1.2.2">
                <apply id="Sx2.E4.m1.2.2.2.1.1.1.1.1.1.1.cmml" xref="Sx2.E4.m1.2.2.2.1.1.1.1.1.1.1">
                 <csymbol cd="ambiguous" id="Sx2.E4.m1.2.2.2.1.1.1.1.1.1.1.1.cmml" xref="Sx2.E4.m1.2.2.2.1.1.1.1.1.1.1">
                  subscript
                 </csymbol>
                 <ci id="Sx2.E4.m1.2.2.2.1.1.1.1.1.1.1.2.cmml" xref="Sx2.E4.m1.2.2.2.1.1.1.1.1.1.1.2">
                  𝑇
                 </ci>
                 <ci id="Sx2.E4.m1.2.2.2.1.1.1.1.1.1.1.3a.cmml" xref="Sx2.E4.m1.2.2.2.1.1.1.1.1.1.1.3">
                  <mtext id="Sx2.E4.m1.2.2.2.1.1.1.1.1.1.1.3.cmml" mathsize="70%" xref="Sx2.E4.m1.2.2.2.1.1.1.1.1.1.1.3">
                   input
                  </mtext>
                 </ci>
                </apply>
                <apply id="Sx2.E4.m1.2.2.2.1.1.1.1.2.2.2.cmml" xref="Sx2.E4.m1.2.2.2.1.1.1.1.2.2.2">
                 <csymbol cd="ambiguous" id="Sx2.E4.m1.2.2.2.1.1.1.1.2.2.2.1.cmml" xref="Sx2.E4.m1.2.2.2.1.1.1.1.2.2.2">
                  subscript
                 </csymbol>
                 <ci id="Sx2.E4.m1.2.2.2.1.1.1.1.2.2.2.2.cmml" xref="Sx2.E4.m1.2.2.2.1.1.1.1.2.2.2.2">
                  𝑡
                 </ci>
                 <apply id="Sx2.E4.m1.2.2.2.1.1.1.1.2.2.2.3.cmml" xref="Sx2.E4.m1.2.2.2.1.1.1.1.2.2.2.3">
                  <csymbol cd="ambiguous" id="Sx2.E4.m1.2.2.2.1.1.1.1.2.2.2.3.1.cmml" xref="Sx2.E4.m1.2.2.2.1.1.1.1.2.2.2.3">
                   subscript
                  </csymbol>
                  <ci id="Sx2.E4.m1.2.2.2.1.1.1.1.2.2.2.3.2a.cmml" xref="Sx2.E4.m1.2.2.2.1.1.1.1.2.2.2.3.2">
                   <mtext id="Sx2.E4.m1.2.2.2.1.1.1.1.2.2.2.3.2.cmml" mathsize="70%" xref="Sx2.E4.m1.2.2.2.1.1.1.1.2.2.2.3.2">
                    output
                   </mtext>
                  </ci>
                  <apply id="Sx2.E4.m1.2.2.2.1.1.1.1.2.2.2.3.3.cmml" xref="Sx2.E4.m1.2.2.2.1.1.1.1.2.2.2.3.3">
                   <lt id="Sx2.E4.m1.2.2.2.1.1.1.1.2.2.2.3.3.1.cmml" xref="Sx2.E4.m1.2.2.2.1.1.1.1.2.2.2.3.3.1">
                   </lt>
                   <csymbol cd="latexml" id="Sx2.E4.m1.2.2.2.1.1.1.1.2.2.2.3.3.2.cmml" xref="Sx2.E4.m1.2.2.2.1.1.1.1.2.2.2.3.3.2">
                    absent
                   </csymbol>
                   <ci id="Sx2.E4.m1.2.2.2.1.1.1.1.2.2.2.3.3.3.cmml" xref="Sx2.E4.m1.2.2.2.1.1.1.1.2.2.2.3.3.3">
                    𝑖
                   </ci>
                  </apply>
                 </apply>
                </apply>
               </list>
              </apply>
             </apply>
            </apply>
           </apply>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="Sx2.E4.m1.2c">
           P(T_{\text{output}}|T_{\text{input}})=\prod_{i=1}^{m}P(t_{\text{output}_{i}}|T_{\text{input}},t_{\text{output}_{&lt;i}})
          </annotation>
         </semantics>
        </math>
       </td>
       <td class="ltx_eqn_cell ltx_eqn_center_padright">
       </td>
       <td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1">
        <span class="ltx_tag ltx_tag_equation ltx_align_right">
         (4)
        </span>
       </td>
      </tr>
     </tbody>
    </table>
   </div>
   <div class="ltx_para" id="Sx2.SSx1.p12">
    <p class="ltx_p" id="Sx2.SSx1.p12.3">
     In Equation
     <a class="ltx_ref" href="#Sx2.E4" title="In Large Language Models ‣ Background ‣ On the Prospects of Incorporating Large Language Models (LLMs) in Automated Planning and Scheduling (APS)">
      <span class="ltx_text ltx_ref_tag">
       4
      </span>
     </a>
     ,
     <math alttext="T_{\text{input}}" class="ltx_Math" display="inline" id="Sx2.SSx1.p12.1.m1.1">
      <semantics id="Sx2.SSx1.p12.1.m1.1a">
       <msub id="Sx2.SSx1.p12.1.m1.1.1" xref="Sx2.SSx1.p12.1.m1.1.1.cmml">
        <mi id="Sx2.SSx1.p12.1.m1.1.1.2" xref="Sx2.SSx1.p12.1.m1.1.1.2.cmml">
         T
        </mi>
        <mtext id="Sx2.SSx1.p12.1.m1.1.1.3" xref="Sx2.SSx1.p12.1.m1.1.1.3a.cmml">
         input
        </mtext>
       </msub>
       <annotation-xml encoding="MathML-Content" id="Sx2.SSx1.p12.1.m1.1b">
        <apply id="Sx2.SSx1.p12.1.m1.1.1.cmml" xref="Sx2.SSx1.p12.1.m1.1.1">
         <csymbol cd="ambiguous" id="Sx2.SSx1.p12.1.m1.1.1.1.cmml" xref="Sx2.SSx1.p12.1.m1.1.1">
          subscript
         </csymbol>
         <ci id="Sx2.SSx1.p12.1.m1.1.1.2.cmml" xref="Sx2.SSx1.p12.1.m1.1.1.2">
          𝑇
         </ci>
         <ci id="Sx2.SSx1.p12.1.m1.1.1.3a.cmml" xref="Sx2.SSx1.p12.1.m1.1.1.3">
          <mtext id="Sx2.SSx1.p12.1.m1.1.1.3.cmml" mathsize="70%" xref="Sx2.SSx1.p12.1.m1.1.1.3">
           input
          </mtext>
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="Sx2.SSx1.p12.1.m1.1c">
        T_{\text{input}}
       </annotation>
      </semantics>
     </math>
     is the input sequence,
     <math alttext="T_{\text{output}}" class="ltx_Math" display="inline" id="Sx2.SSx1.p12.2.m2.1">
      <semantics id="Sx2.SSx1.p12.2.m2.1a">
       <msub id="Sx2.SSx1.p12.2.m2.1.1" xref="Sx2.SSx1.p12.2.m2.1.1.cmml">
        <mi id="Sx2.SSx1.p12.2.m2.1.1.2" xref="Sx2.SSx1.p12.2.m2.1.1.2.cmml">
         T
        </mi>
        <mtext id="Sx2.SSx1.p12.2.m2.1.1.3" xref="Sx2.SSx1.p12.2.m2.1.1.3a.cmml">
         output
        </mtext>
       </msub>
       <annotation-xml encoding="MathML-Content" id="Sx2.SSx1.p12.2.m2.1b">
        <apply id="Sx2.SSx1.p12.2.m2.1.1.cmml" xref="Sx2.SSx1.p12.2.m2.1.1">
         <csymbol cd="ambiguous" id="Sx2.SSx1.p12.2.m2.1.1.1.cmml" xref="Sx2.SSx1.p12.2.m2.1.1">
          subscript
         </csymbol>
         <ci id="Sx2.SSx1.p12.2.m2.1.1.2.cmml" xref="Sx2.SSx1.p12.2.m2.1.1.2">
          𝑇
         </ci>
         <ci id="Sx2.SSx1.p12.2.m2.1.1.3a.cmml" xref="Sx2.SSx1.p12.2.m2.1.1.3">
          <mtext id="Sx2.SSx1.p12.2.m2.1.1.3.cmml" mathsize="70%" xref="Sx2.SSx1.p12.2.m2.1.1.3">
           output
          </mtext>
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="Sx2.SSx1.p12.2.m2.1c">
        T_{\text{output}}
       </annotation>
      </semantics>
     </math>
     is the output sequence, and
     <math alttext="P(t_{\text{output}_{i}}|T_{\text{input}},t_{\text{output}_{&lt;i}})" class="ltx_Math" display="inline" id="Sx2.SSx1.p12.3.m3.1">
      <semantics id="Sx2.SSx1.p12.3.m3.1a">
       <mrow id="Sx2.SSx1.p12.3.m3.1.1" xref="Sx2.SSx1.p12.3.m3.1.1.cmml">
        <mi id="Sx2.SSx1.p12.3.m3.1.1.3" xref="Sx2.SSx1.p12.3.m3.1.1.3.cmml">
         P
        </mi>
        <mo id="Sx2.SSx1.p12.3.m3.1.1.2" lspace="0em" rspace="0em" xref="Sx2.SSx1.p12.3.m3.1.1.2.cmml">
         ​
        </mo>
        <mrow id="Sx2.SSx1.p12.3.m3.1.1.1.1" xref="Sx2.SSx1.p12.3.m3.1.1.1.1.1.cmml">
         <mo id="Sx2.SSx1.p12.3.m3.1.1.1.1.2" stretchy="false" xref="Sx2.SSx1.p12.3.m3.1.1.1.1.1.cmml">
          (
         </mo>
         <mrow id="Sx2.SSx1.p12.3.m3.1.1.1.1.1" xref="Sx2.SSx1.p12.3.m3.1.1.1.1.1.cmml">
          <msub id="Sx2.SSx1.p12.3.m3.1.1.1.1.1.4" xref="Sx2.SSx1.p12.3.m3.1.1.1.1.1.4.cmml">
           <mi id="Sx2.SSx1.p12.3.m3.1.1.1.1.1.4.2" xref="Sx2.SSx1.p12.3.m3.1.1.1.1.1.4.2.cmml">
            t
           </mi>
           <msub id="Sx2.SSx1.p12.3.m3.1.1.1.1.1.4.3" xref="Sx2.SSx1.p12.3.m3.1.1.1.1.1.4.3.cmml">
            <mtext id="Sx2.SSx1.p12.3.m3.1.1.1.1.1.4.3.2" xref="Sx2.SSx1.p12.3.m3.1.1.1.1.1.4.3.2a.cmml">
             output
            </mtext>
            <mi id="Sx2.SSx1.p12.3.m3.1.1.1.1.1.4.3.3" xref="Sx2.SSx1.p12.3.m3.1.1.1.1.1.4.3.3.cmml">
             i
            </mi>
           </msub>
          </msub>
          <mo fence="false" id="Sx2.SSx1.p12.3.m3.1.1.1.1.1.3" xref="Sx2.SSx1.p12.3.m3.1.1.1.1.1.3.cmml">
           |
          </mo>
          <mrow id="Sx2.SSx1.p12.3.m3.1.1.1.1.1.2.2" xref="Sx2.SSx1.p12.3.m3.1.1.1.1.1.2.3.cmml">
           <msub id="Sx2.SSx1.p12.3.m3.1.1.1.1.1.1.1.1" xref="Sx2.SSx1.p12.3.m3.1.1.1.1.1.1.1.1.cmml">
            <mi id="Sx2.SSx1.p12.3.m3.1.1.1.1.1.1.1.1.2" xref="Sx2.SSx1.p12.3.m3.1.1.1.1.1.1.1.1.2.cmml">
             T
            </mi>
            <mtext id="Sx2.SSx1.p12.3.m3.1.1.1.1.1.1.1.1.3" xref="Sx2.SSx1.p12.3.m3.1.1.1.1.1.1.1.1.3a.cmml">
             input
            </mtext>
           </msub>
           <mo id="Sx2.SSx1.p12.3.m3.1.1.1.1.1.2.2.3" xref="Sx2.SSx1.p12.3.m3.1.1.1.1.1.2.3.cmml">
            ,
           </mo>
           <msub id="Sx2.SSx1.p12.3.m3.1.1.1.1.1.2.2.2" xref="Sx2.SSx1.p12.3.m3.1.1.1.1.1.2.2.2.cmml">
            <mi id="Sx2.SSx1.p12.3.m3.1.1.1.1.1.2.2.2.2" xref="Sx2.SSx1.p12.3.m3.1.1.1.1.1.2.2.2.2.cmml">
             t
            </mi>
            <msub id="Sx2.SSx1.p12.3.m3.1.1.1.1.1.2.2.2.3" xref="Sx2.SSx1.p12.3.m3.1.1.1.1.1.2.2.2.3.cmml">
             <mtext id="Sx2.SSx1.p12.3.m3.1.1.1.1.1.2.2.2.3.2" xref="Sx2.SSx1.p12.3.m3.1.1.1.1.1.2.2.2.3.2a.cmml">
              output
             </mtext>
             <mrow id="Sx2.SSx1.p12.3.m3.1.1.1.1.1.2.2.2.3.3" xref="Sx2.SSx1.p12.3.m3.1.1.1.1.1.2.2.2.3.3.cmml">
              <mi id="Sx2.SSx1.p12.3.m3.1.1.1.1.1.2.2.2.3.3.2" xref="Sx2.SSx1.p12.3.m3.1.1.1.1.1.2.2.2.3.3.2.cmml">
              </mi>
              <mo id="Sx2.SSx1.p12.3.m3.1.1.1.1.1.2.2.2.3.3.1" xref="Sx2.SSx1.p12.3.m3.1.1.1.1.1.2.2.2.3.3.1.cmml">
               &lt;
              </mo>
              <mi id="Sx2.SSx1.p12.3.m3.1.1.1.1.1.2.2.2.3.3.3" xref="Sx2.SSx1.p12.3.m3.1.1.1.1.1.2.2.2.3.3.3.cmml">
               i
              </mi>
             </mrow>
            </msub>
           </msub>
          </mrow>
         </mrow>
         <mo id="Sx2.SSx1.p12.3.m3.1.1.1.1.3" stretchy="false" xref="Sx2.SSx1.p12.3.m3.1.1.1.1.1.cmml">
          )
         </mo>
        </mrow>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="Sx2.SSx1.p12.3.m3.1b">
        <apply id="Sx2.SSx1.p12.3.m3.1.1.cmml" xref="Sx2.SSx1.p12.3.m3.1.1">
         <times id="Sx2.SSx1.p12.3.m3.1.1.2.cmml" xref="Sx2.SSx1.p12.3.m3.1.1.2">
         </times>
         <ci id="Sx2.SSx1.p12.3.m3.1.1.3.cmml" xref="Sx2.SSx1.p12.3.m3.1.1.3">
          𝑃
         </ci>
         <apply id="Sx2.SSx1.p12.3.m3.1.1.1.1.1.cmml" xref="Sx2.SSx1.p12.3.m3.1.1.1.1">
          <csymbol cd="latexml" id="Sx2.SSx1.p12.3.m3.1.1.1.1.1.3.cmml" xref="Sx2.SSx1.p12.3.m3.1.1.1.1.1.3">
           conditional
          </csymbol>
          <apply id="Sx2.SSx1.p12.3.m3.1.1.1.1.1.4.cmml" xref="Sx2.SSx1.p12.3.m3.1.1.1.1.1.4">
           <csymbol cd="ambiguous" id="Sx2.SSx1.p12.3.m3.1.1.1.1.1.4.1.cmml" xref="Sx2.SSx1.p12.3.m3.1.1.1.1.1.4">
            subscript
           </csymbol>
           <ci id="Sx2.SSx1.p12.3.m3.1.1.1.1.1.4.2.cmml" xref="Sx2.SSx1.p12.3.m3.1.1.1.1.1.4.2">
            𝑡
           </ci>
           <apply id="Sx2.SSx1.p12.3.m3.1.1.1.1.1.4.3.cmml" xref="Sx2.SSx1.p12.3.m3.1.1.1.1.1.4.3">
            <csymbol cd="ambiguous" id="Sx2.SSx1.p12.3.m3.1.1.1.1.1.4.3.1.cmml" xref="Sx2.SSx1.p12.3.m3.1.1.1.1.1.4.3">
             subscript
            </csymbol>
            <ci id="Sx2.SSx1.p12.3.m3.1.1.1.1.1.4.3.2a.cmml" xref="Sx2.SSx1.p12.3.m3.1.1.1.1.1.4.3.2">
             <mtext id="Sx2.SSx1.p12.3.m3.1.1.1.1.1.4.3.2.cmml" mathsize="70%" xref="Sx2.SSx1.p12.3.m3.1.1.1.1.1.4.3.2">
              output
             </mtext>
            </ci>
            <ci id="Sx2.SSx1.p12.3.m3.1.1.1.1.1.4.3.3.cmml" xref="Sx2.SSx1.p12.3.m3.1.1.1.1.1.4.3.3">
             𝑖
            </ci>
           </apply>
          </apply>
          <list id="Sx2.SSx1.p12.3.m3.1.1.1.1.1.2.3.cmml" xref="Sx2.SSx1.p12.3.m3.1.1.1.1.1.2.2">
           <apply id="Sx2.SSx1.p12.3.m3.1.1.1.1.1.1.1.1.cmml" xref="Sx2.SSx1.p12.3.m3.1.1.1.1.1.1.1.1">
            <csymbol cd="ambiguous" id="Sx2.SSx1.p12.3.m3.1.1.1.1.1.1.1.1.1.cmml" xref="Sx2.SSx1.p12.3.m3.1.1.1.1.1.1.1.1">
             subscript
            </csymbol>
            <ci id="Sx2.SSx1.p12.3.m3.1.1.1.1.1.1.1.1.2.cmml" xref="Sx2.SSx1.p12.3.m3.1.1.1.1.1.1.1.1.2">
             𝑇
            </ci>
            <ci id="Sx2.SSx1.p12.3.m3.1.1.1.1.1.1.1.1.3a.cmml" xref="Sx2.SSx1.p12.3.m3.1.1.1.1.1.1.1.1.3">
             <mtext id="Sx2.SSx1.p12.3.m3.1.1.1.1.1.1.1.1.3.cmml" mathsize="70%" xref="Sx2.SSx1.p12.3.m3.1.1.1.1.1.1.1.1.3">
              input
             </mtext>
            </ci>
           </apply>
           <apply id="Sx2.SSx1.p12.3.m3.1.1.1.1.1.2.2.2.cmml" xref="Sx2.SSx1.p12.3.m3.1.1.1.1.1.2.2.2">
            <csymbol cd="ambiguous" id="Sx2.SSx1.p12.3.m3.1.1.1.1.1.2.2.2.1.cmml" xref="Sx2.SSx1.p12.3.m3.1.1.1.1.1.2.2.2">
             subscript
            </csymbol>
            <ci id="Sx2.SSx1.p12.3.m3.1.1.1.1.1.2.2.2.2.cmml" xref="Sx2.SSx1.p12.3.m3.1.1.1.1.1.2.2.2.2">
             𝑡
            </ci>
            <apply id="Sx2.SSx1.p12.3.m3.1.1.1.1.1.2.2.2.3.cmml" xref="Sx2.SSx1.p12.3.m3.1.1.1.1.1.2.2.2.3">
             <csymbol cd="ambiguous" id="Sx2.SSx1.p12.3.m3.1.1.1.1.1.2.2.2.3.1.cmml" xref="Sx2.SSx1.p12.3.m3.1.1.1.1.1.2.2.2.3">
              subscript
             </csymbol>
             <ci id="Sx2.SSx1.p12.3.m3.1.1.1.1.1.2.2.2.3.2a.cmml" xref="Sx2.SSx1.p12.3.m3.1.1.1.1.1.2.2.2.3.2">
              <mtext id="Sx2.SSx1.p12.3.m3.1.1.1.1.1.2.2.2.3.2.cmml" mathsize="70%" xref="Sx2.SSx1.p12.3.m3.1.1.1.1.1.2.2.2.3.2">
               output
              </mtext>
             </ci>
             <apply id="Sx2.SSx1.p12.3.m3.1.1.1.1.1.2.2.2.3.3.cmml" xref="Sx2.SSx1.p12.3.m3.1.1.1.1.1.2.2.2.3.3">
              <lt id="Sx2.SSx1.p12.3.m3.1.1.1.1.1.2.2.2.3.3.1.cmml" xref="Sx2.SSx1.p12.3.m3.1.1.1.1.1.2.2.2.3.3.1">
              </lt>
              <csymbol cd="latexml" id="Sx2.SSx1.p12.3.m3.1.1.1.1.1.2.2.2.3.3.2.cmml" xref="Sx2.SSx1.p12.3.m3.1.1.1.1.1.2.2.2.3.3.2">
               absent
              </csymbol>
              <ci id="Sx2.SSx1.p12.3.m3.1.1.1.1.1.2.2.2.3.3.3.cmml" xref="Sx2.SSx1.p12.3.m3.1.1.1.1.1.2.2.2.3.3.3">
               𝑖
              </ci>
             </apply>
            </apply>
           </apply>
          </list>
         </apply>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="Sx2.SSx1.p12.3.m3.1c">
        P(t_{\text{output}_{i}}|T_{\text{input}},t_{\text{output}_{&lt;i}})
       </annotation>
      </semantics>
     </math>
     calculates the probability of generating each token in the output sequence, considering both the input sequence and the preceding tokens in the output sequence.
    </p>
   </div>
   <div class="ltx_para" id="Sx2.SSx1.p13">
    <p class="ltx_p" id="Sx2.SSx1.p13.1">
     In addition to their architectural variants, the utility of LLMs is further enhanced by specific model utilization strategies, enabling their effective adaptation to various domains at scale. One key strategy is fine-tuning, which applies to pre-trained LLMs. Pre-trained LLMs are models already trained on large datasets to understand and generate language, acquiring a broad linguistic knowledge base. Fine-tuning involves further training pre-trained LLMs on a smaller, task-specific dataset, thereby adjusting the neural network weights for particular applications. This process is mathematically represented in Equation
     <a class="ltx_ref" href="#Sx2.E5" title="In Large Language Models ‣ Background ‣ On the Prospects of Incorporating Large Language Models (LLMs) in Automated Planning and Scheduling (APS)">
      <span class="ltx_text ltx_ref_tag">
       5
      </span>
     </a>
     .
    </p>
   </div>
   <div class="ltx_para" id="Sx2.SSx1.p14">
    <table class="ltx_equation ltx_eqn_table" id="Sx2.E5">
     <tbody>
      <tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
       <td class="ltx_eqn_cell ltx_eqn_center_padleft">
       </td>
       <td class="ltx_eqn_cell ltx_align_center">
        <math alttext="\theta_{\text{fine-tuned}}=\theta_{\text{pre-trained}}-\eta\cdot\nabla_{\theta}L(\theta,D_{\text{task}})" class="ltx_Math" display="block" id="Sx2.E5.m1.2">
         <semantics id="Sx2.E5.m1.2a">
          <mrow id="Sx2.E5.m1.2.2" xref="Sx2.E5.m1.2.2.cmml">
           <msub id="Sx2.E5.m1.2.2.3" xref="Sx2.E5.m1.2.2.3.cmml">
            <mi id="Sx2.E5.m1.2.2.3.2" xref="Sx2.E5.m1.2.2.3.2.cmml">
             θ
            </mi>
            <mtext id="Sx2.E5.m1.2.2.3.3" xref="Sx2.E5.m1.2.2.3.3a.cmml">
             fine-tuned
            </mtext>
           </msub>
           <mo id="Sx2.E5.m1.2.2.2" xref="Sx2.E5.m1.2.2.2.cmml">
            =
           </mo>
           <mrow id="Sx2.E5.m1.2.2.1" xref="Sx2.E5.m1.2.2.1.cmml">
            <msub id="Sx2.E5.m1.2.2.1.3" xref="Sx2.E5.m1.2.2.1.3.cmml">
             <mi id="Sx2.E5.m1.2.2.1.3.2" xref="Sx2.E5.m1.2.2.1.3.2.cmml">
              θ
             </mi>
             <mtext id="Sx2.E5.m1.2.2.1.3.3" xref="Sx2.E5.m1.2.2.1.3.3a.cmml">
              pre-trained
             </mtext>
            </msub>
            <mo id="Sx2.E5.m1.2.2.1.2" xref="Sx2.E5.m1.2.2.1.2.cmml">
             −
            </mo>
            <mrow id="Sx2.E5.m1.2.2.1.1" xref="Sx2.E5.m1.2.2.1.1.cmml">
             <mrow id="Sx2.E5.m1.2.2.1.1.3" xref="Sx2.E5.m1.2.2.1.1.3.cmml">
              <mi id="Sx2.E5.m1.2.2.1.1.3.2" xref="Sx2.E5.m1.2.2.1.1.3.2.cmml">
               η
              </mi>
              <mo id="Sx2.E5.m1.2.2.1.1.3.1" lspace="0.222em" rspace="0.222em" xref="Sx2.E5.m1.2.2.1.1.3.1.cmml">
               ⋅
              </mo>
              <mrow id="Sx2.E5.m1.2.2.1.1.3.3" xref="Sx2.E5.m1.2.2.1.1.3.3.cmml">
               <msub id="Sx2.E5.m1.2.2.1.1.3.3.1" xref="Sx2.E5.m1.2.2.1.1.3.3.1.cmml">
                <mo id="Sx2.E5.m1.2.2.1.1.3.3.1.2" rspace="0.167em" xref="Sx2.E5.m1.2.2.1.1.3.3.1.2.cmml">
                 ∇
                </mo>
                <mi id="Sx2.E5.m1.2.2.1.1.3.3.1.3" xref="Sx2.E5.m1.2.2.1.1.3.3.1.3.cmml">
                 θ
                </mi>
               </msub>
               <mi id="Sx2.E5.m1.2.2.1.1.3.3.2" xref="Sx2.E5.m1.2.2.1.1.3.3.2.cmml">
                L
               </mi>
              </mrow>
             </mrow>
             <mo id="Sx2.E5.m1.2.2.1.1.2" lspace="0em" rspace="0em" xref="Sx2.E5.m1.2.2.1.1.2.cmml">
              ​
             </mo>
             <mrow id="Sx2.E5.m1.2.2.1.1.1.1" xref="Sx2.E5.m1.2.2.1.1.1.2.cmml">
              <mo id="Sx2.E5.m1.2.2.1.1.1.1.2" stretchy="false" xref="Sx2.E5.m1.2.2.1.1.1.2.cmml">
               (
              </mo>
              <mi id="Sx2.E5.m1.1.1" xref="Sx2.E5.m1.1.1.cmml">
               θ
              </mi>
              <mo id="Sx2.E5.m1.2.2.1.1.1.1.3" xref="Sx2.E5.m1.2.2.1.1.1.2.cmml">
               ,
              </mo>
              <msub id="Sx2.E5.m1.2.2.1.1.1.1.1" xref="Sx2.E5.m1.2.2.1.1.1.1.1.cmml">
               <mi id="Sx2.E5.m1.2.2.1.1.1.1.1.2" xref="Sx2.E5.m1.2.2.1.1.1.1.1.2.cmml">
                D
               </mi>
               <mtext id="Sx2.E5.m1.2.2.1.1.1.1.1.3" xref="Sx2.E5.m1.2.2.1.1.1.1.1.3a.cmml">
                task
               </mtext>
              </msub>
              <mo id="Sx2.E5.m1.2.2.1.1.1.1.4" stretchy="false" xref="Sx2.E5.m1.2.2.1.1.1.2.cmml">
               )
              </mo>
             </mrow>
            </mrow>
           </mrow>
          </mrow>
          <annotation-xml encoding="MathML-Content" id="Sx2.E5.m1.2b">
           <apply id="Sx2.E5.m1.2.2.cmml" xref="Sx2.E5.m1.2.2">
            <eq id="Sx2.E5.m1.2.2.2.cmml" xref="Sx2.E5.m1.2.2.2">
            </eq>
            <apply id="Sx2.E5.m1.2.2.3.cmml" xref="Sx2.E5.m1.2.2.3">
             <csymbol cd="ambiguous" id="Sx2.E5.m1.2.2.3.1.cmml" xref="Sx2.E5.m1.2.2.3">
              subscript
             </csymbol>
             <ci id="Sx2.E5.m1.2.2.3.2.cmml" xref="Sx2.E5.m1.2.2.3.2">
              𝜃
             </ci>
             <ci id="Sx2.E5.m1.2.2.3.3a.cmml" xref="Sx2.E5.m1.2.2.3.3">
              <mtext id="Sx2.E5.m1.2.2.3.3.cmml" mathsize="70%" xref="Sx2.E5.m1.2.2.3.3">
               fine-tuned
              </mtext>
             </ci>
            </apply>
            <apply id="Sx2.E5.m1.2.2.1.cmml" xref="Sx2.E5.m1.2.2.1">
             <minus id="Sx2.E5.m1.2.2.1.2.cmml" xref="Sx2.E5.m1.2.2.1.2">
             </minus>
             <apply id="Sx2.E5.m1.2.2.1.3.cmml" xref="Sx2.E5.m1.2.2.1.3">
              <csymbol cd="ambiguous" id="Sx2.E5.m1.2.2.1.3.1.cmml" xref="Sx2.E5.m1.2.2.1.3">
               subscript
              </csymbol>
              <ci id="Sx2.E5.m1.2.2.1.3.2.cmml" xref="Sx2.E5.m1.2.2.1.3.2">
               𝜃
              </ci>
              <ci id="Sx2.E5.m1.2.2.1.3.3a.cmml" xref="Sx2.E5.m1.2.2.1.3.3">
               <mtext id="Sx2.E5.m1.2.2.1.3.3.cmml" mathsize="70%" xref="Sx2.E5.m1.2.2.1.3.3">
                pre-trained
               </mtext>
              </ci>
             </apply>
             <apply id="Sx2.E5.m1.2.2.1.1.cmml" xref="Sx2.E5.m1.2.2.1.1">
              <times id="Sx2.E5.m1.2.2.1.1.2.cmml" xref="Sx2.E5.m1.2.2.1.1.2">
              </times>
              <apply id="Sx2.E5.m1.2.2.1.1.3.cmml" xref="Sx2.E5.m1.2.2.1.1.3">
               <ci id="Sx2.E5.m1.2.2.1.1.3.1.cmml" xref="Sx2.E5.m1.2.2.1.1.3.1">
                ⋅
               </ci>
               <ci id="Sx2.E5.m1.2.2.1.1.3.2.cmml" xref="Sx2.E5.m1.2.2.1.1.3.2">
                𝜂
               </ci>
               <apply id="Sx2.E5.m1.2.2.1.1.3.3.cmml" xref="Sx2.E5.m1.2.2.1.1.3.3">
                <apply id="Sx2.E5.m1.2.2.1.1.3.3.1.cmml" xref="Sx2.E5.m1.2.2.1.1.3.3.1">
                 <csymbol cd="ambiguous" id="Sx2.E5.m1.2.2.1.1.3.3.1.1.cmml" xref="Sx2.E5.m1.2.2.1.1.3.3.1">
                  subscript
                 </csymbol>
                 <ci id="Sx2.E5.m1.2.2.1.1.3.3.1.2.cmml" xref="Sx2.E5.m1.2.2.1.1.3.3.1.2">
                  ∇
                 </ci>
                 <ci id="Sx2.E5.m1.2.2.1.1.3.3.1.3.cmml" xref="Sx2.E5.m1.2.2.1.1.3.3.1.3">
                  𝜃
                 </ci>
                </apply>
                <ci id="Sx2.E5.m1.2.2.1.1.3.3.2.cmml" xref="Sx2.E5.m1.2.2.1.1.3.3.2">
                 𝐿
                </ci>
               </apply>
              </apply>
              <interval closure="open" id="Sx2.E5.m1.2.2.1.1.1.2.cmml" xref="Sx2.E5.m1.2.2.1.1.1.1">
               <ci id="Sx2.E5.m1.1.1.cmml" xref="Sx2.E5.m1.1.1">
                𝜃
               </ci>
               <apply id="Sx2.E5.m1.2.2.1.1.1.1.1.cmml" xref="Sx2.E5.m1.2.2.1.1.1.1.1">
                <csymbol cd="ambiguous" id="Sx2.E5.m1.2.2.1.1.1.1.1.1.cmml" xref="Sx2.E5.m1.2.2.1.1.1.1.1">
                 subscript
                </csymbol>
                <ci id="Sx2.E5.m1.2.2.1.1.1.1.1.2.cmml" xref="Sx2.E5.m1.2.2.1.1.1.1.1.2">
                 𝐷
                </ci>
                <ci id="Sx2.E5.m1.2.2.1.1.1.1.1.3a.cmml" xref="Sx2.E5.m1.2.2.1.1.1.1.1.3">
                 <mtext id="Sx2.E5.m1.2.2.1.1.1.1.1.3.cmml" mathsize="70%" xref="Sx2.E5.m1.2.2.1.1.1.1.1.3">
                  task
                 </mtext>
                </ci>
               </apply>
              </interval>
             </apply>
            </apply>
           </apply>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="Sx2.E5.m1.2c">
           \theta_{\text{fine-tuned}}=\theta_{\text{pre-trained}}-\eta\cdot\nabla_{\theta}L(\theta,D_{\text{task}})
          </annotation>
         </semantics>
        </math>
       </td>
       <td class="ltx_eqn_cell ltx_eqn_center_padright">
       </td>
       <td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1">
        <span class="ltx_tag ltx_tag_equation ltx_align_right">
         (5)
        </span>
       </td>
      </tr>
     </tbody>
    </table>
   </div>
   <div class="ltx_para" id="Sx2.SSx1.p15">
    <p class="ltx_p" id="Sx2.SSx1.p15.7">
     Here,
     <math alttext="\theta_{\text{fine-tuned}}" class="ltx_Math" display="inline" id="Sx2.SSx1.p15.1.m1.1">
      <semantics id="Sx2.SSx1.p15.1.m1.1a">
       <msub id="Sx2.SSx1.p15.1.m1.1.1" xref="Sx2.SSx1.p15.1.m1.1.1.cmml">
        <mi id="Sx2.SSx1.p15.1.m1.1.1.2" xref="Sx2.SSx1.p15.1.m1.1.1.2.cmml">
         θ
        </mi>
        <mtext id="Sx2.SSx1.p15.1.m1.1.1.3" xref="Sx2.SSx1.p15.1.m1.1.1.3a.cmml">
         fine-tuned
        </mtext>
       </msub>
       <annotation-xml encoding="MathML-Content" id="Sx2.SSx1.p15.1.m1.1b">
        <apply id="Sx2.SSx1.p15.1.m1.1.1.cmml" xref="Sx2.SSx1.p15.1.m1.1.1">
         <csymbol cd="ambiguous" id="Sx2.SSx1.p15.1.m1.1.1.1.cmml" xref="Sx2.SSx1.p15.1.m1.1.1">
          subscript
         </csymbol>
         <ci id="Sx2.SSx1.p15.1.m1.1.1.2.cmml" xref="Sx2.SSx1.p15.1.m1.1.1.2">
          𝜃
         </ci>
         <ci id="Sx2.SSx1.p15.1.m1.1.1.3a.cmml" xref="Sx2.SSx1.p15.1.m1.1.1.3">
          <mtext id="Sx2.SSx1.p15.1.m1.1.1.3.cmml" mathsize="70%" xref="Sx2.SSx1.p15.1.m1.1.1.3">
           fine-tuned
          </mtext>
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="Sx2.SSx1.p15.1.m1.1c">
        \theta_{\text{fine-tuned}}
       </annotation>
      </semantics>
     </math>
     are the model parameters after fine-tuning,
     <math alttext="\theta_{\text{pre-trained}}" class="ltx_Math" display="inline" id="Sx2.SSx1.p15.2.m2.1">
      <semantics id="Sx2.SSx1.p15.2.m2.1a">
       <msub id="Sx2.SSx1.p15.2.m2.1.1" xref="Sx2.SSx1.p15.2.m2.1.1.cmml">
        <mi id="Sx2.SSx1.p15.2.m2.1.1.2" xref="Sx2.SSx1.p15.2.m2.1.1.2.cmml">
         θ
        </mi>
        <mtext id="Sx2.SSx1.p15.2.m2.1.1.3" xref="Sx2.SSx1.p15.2.m2.1.1.3a.cmml">
         pre-trained
        </mtext>
       </msub>
       <annotation-xml encoding="MathML-Content" id="Sx2.SSx1.p15.2.m2.1b">
        <apply id="Sx2.SSx1.p15.2.m2.1.1.cmml" xref="Sx2.SSx1.p15.2.m2.1.1">
         <csymbol cd="ambiguous" id="Sx2.SSx1.p15.2.m2.1.1.1.cmml" xref="Sx2.SSx1.p15.2.m2.1.1">
          subscript
         </csymbol>
         <ci id="Sx2.SSx1.p15.2.m2.1.1.2.cmml" xref="Sx2.SSx1.p15.2.m2.1.1.2">
          𝜃
         </ci>
         <ci id="Sx2.SSx1.p15.2.m2.1.1.3a.cmml" xref="Sx2.SSx1.p15.2.m2.1.1.3">
          <mtext id="Sx2.SSx1.p15.2.m2.1.1.3.cmml" mathsize="70%" xref="Sx2.SSx1.p15.2.m2.1.1.3">
           pre-trained
          </mtext>
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="Sx2.SSx1.p15.2.m2.1c">
        \theta_{\text{pre-trained}}
       </annotation>
      </semantics>
     </math>
     are the parameters obtained from pre-training,
     <math alttext="\eta" class="ltx_Math" display="inline" id="Sx2.SSx1.p15.3.m3.1">
      <semantics id="Sx2.SSx1.p15.3.m3.1a">
       <mi id="Sx2.SSx1.p15.3.m3.1.1" xref="Sx2.SSx1.p15.3.m3.1.1.cmml">
        η
       </mi>
       <annotation-xml encoding="MathML-Content" id="Sx2.SSx1.p15.3.m3.1b">
        <ci id="Sx2.SSx1.p15.3.m3.1.1.cmml" xref="Sx2.SSx1.p15.3.m3.1.1">
         𝜂
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="Sx2.SSx1.p15.3.m3.1c">
        \eta
       </annotation>
      </semantics>
     </math>
     is the learning rate, and
     <math alttext="\nabla_{\theta}L(\theta,D_{\text{task}})" class="ltx_Math" display="inline" id="Sx2.SSx1.p15.4.m4.2">
      <semantics id="Sx2.SSx1.p15.4.m4.2a">
       <mrow id="Sx2.SSx1.p15.4.m4.2.2" xref="Sx2.SSx1.p15.4.m4.2.2.cmml">
        <mrow id="Sx2.SSx1.p15.4.m4.2.2.3" xref="Sx2.SSx1.p15.4.m4.2.2.3.cmml">
         <msub id="Sx2.SSx1.p15.4.m4.2.2.3.1" xref="Sx2.SSx1.p15.4.m4.2.2.3.1.cmml">
          <mo id="Sx2.SSx1.p15.4.m4.2.2.3.1.2" xref="Sx2.SSx1.p15.4.m4.2.2.3.1.2.cmml">
           ∇
          </mo>
          <mi id="Sx2.SSx1.p15.4.m4.2.2.3.1.3" xref="Sx2.SSx1.p15.4.m4.2.2.3.1.3.cmml">
           θ
          </mi>
         </msub>
         <mi id="Sx2.SSx1.p15.4.m4.2.2.3.2" xref="Sx2.SSx1.p15.4.m4.2.2.3.2.cmml">
          L
         </mi>
        </mrow>
        <mo id="Sx2.SSx1.p15.4.m4.2.2.2" lspace="0em" rspace="0em" xref="Sx2.SSx1.p15.4.m4.2.2.2.cmml">
         ​
        </mo>
        <mrow id="Sx2.SSx1.p15.4.m4.2.2.1.1" xref="Sx2.SSx1.p15.4.m4.2.2.1.2.cmml">
         <mo id="Sx2.SSx1.p15.4.m4.2.2.1.1.2" stretchy="false" xref="Sx2.SSx1.p15.4.m4.2.2.1.2.cmml">
          (
         </mo>
         <mi id="Sx2.SSx1.p15.4.m4.1.1" xref="Sx2.SSx1.p15.4.m4.1.1.cmml">
          θ
         </mi>
         <mo id="Sx2.SSx1.p15.4.m4.2.2.1.1.3" xref="Sx2.SSx1.p15.4.m4.2.2.1.2.cmml">
          ,
         </mo>
         <msub id="Sx2.SSx1.p15.4.m4.2.2.1.1.1" xref="Sx2.SSx1.p15.4.m4.2.2.1.1.1.cmml">
          <mi id="Sx2.SSx1.p15.4.m4.2.2.1.1.1.2" xref="Sx2.SSx1.p15.4.m4.2.2.1.1.1.2.cmml">
           D
          </mi>
          <mtext id="Sx2.SSx1.p15.4.m4.2.2.1.1.1.3" xref="Sx2.SSx1.p15.4.m4.2.2.1.1.1.3a.cmml">
           task
          </mtext>
         </msub>
         <mo id="Sx2.SSx1.p15.4.m4.2.2.1.1.4" stretchy="false" xref="Sx2.SSx1.p15.4.m4.2.2.1.2.cmml">
          )
         </mo>
        </mrow>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="Sx2.SSx1.p15.4.m4.2b">
        <apply id="Sx2.SSx1.p15.4.m4.2.2.cmml" xref="Sx2.SSx1.p15.4.m4.2.2">
         <times id="Sx2.SSx1.p15.4.m4.2.2.2.cmml" xref="Sx2.SSx1.p15.4.m4.2.2.2">
         </times>
         <apply id="Sx2.SSx1.p15.4.m4.2.2.3.cmml" xref="Sx2.SSx1.p15.4.m4.2.2.3">
          <apply id="Sx2.SSx1.p15.4.m4.2.2.3.1.cmml" xref="Sx2.SSx1.p15.4.m4.2.2.3.1">
           <csymbol cd="ambiguous" id="Sx2.SSx1.p15.4.m4.2.2.3.1.1.cmml" xref="Sx2.SSx1.p15.4.m4.2.2.3.1">
            subscript
           </csymbol>
           <ci id="Sx2.SSx1.p15.4.m4.2.2.3.1.2.cmml" xref="Sx2.SSx1.p15.4.m4.2.2.3.1.2">
            ∇
           </ci>
           <ci id="Sx2.SSx1.p15.4.m4.2.2.3.1.3.cmml" xref="Sx2.SSx1.p15.4.m4.2.2.3.1.3">
            𝜃
           </ci>
          </apply>
          <ci id="Sx2.SSx1.p15.4.m4.2.2.3.2.cmml" xref="Sx2.SSx1.p15.4.m4.2.2.3.2">
           𝐿
          </ci>
         </apply>
         <interval closure="open" id="Sx2.SSx1.p15.4.m4.2.2.1.2.cmml" xref="Sx2.SSx1.p15.4.m4.2.2.1.1">
          <ci id="Sx2.SSx1.p15.4.m4.1.1.cmml" xref="Sx2.SSx1.p15.4.m4.1.1">
           𝜃
          </ci>
          <apply id="Sx2.SSx1.p15.4.m4.2.2.1.1.1.cmml" xref="Sx2.SSx1.p15.4.m4.2.2.1.1.1">
           <csymbol cd="ambiguous" id="Sx2.SSx1.p15.4.m4.2.2.1.1.1.1.cmml" xref="Sx2.SSx1.p15.4.m4.2.2.1.1.1">
            subscript
           </csymbol>
           <ci id="Sx2.SSx1.p15.4.m4.2.2.1.1.1.2.cmml" xref="Sx2.SSx1.p15.4.m4.2.2.1.1.1.2">
            𝐷
           </ci>
           <ci id="Sx2.SSx1.p15.4.m4.2.2.1.1.1.3a.cmml" xref="Sx2.SSx1.p15.4.m4.2.2.1.1.1.3">
            <mtext id="Sx2.SSx1.p15.4.m4.2.2.1.1.1.3.cmml" mathsize="70%" xref="Sx2.SSx1.p15.4.m4.2.2.1.1.1.3">
             task
            </mtext>
           </ci>
          </apply>
         </interval>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="Sx2.SSx1.p15.4.m4.2c">
        \nabla_{\theta}L(\theta,D_{\text{task}})
       </annotation>
      </semantics>
     </math>
     denotes the gradient of the loss function
     <math alttext="L" class="ltx_Math" display="inline" id="Sx2.SSx1.p15.5.m5.1">
      <semantics id="Sx2.SSx1.p15.5.m5.1a">
       <mi id="Sx2.SSx1.p15.5.m5.1.1" xref="Sx2.SSx1.p15.5.m5.1.1.cmml">
        L
       </mi>
       <annotation-xml encoding="MathML-Content" id="Sx2.SSx1.p15.5.m5.1b">
        <ci id="Sx2.SSx1.p15.5.m5.1.1.cmml" xref="Sx2.SSx1.p15.5.m5.1.1">
         𝐿
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="Sx2.SSx1.p15.5.m5.1c">
        L
       </annotation>
      </semantics>
     </math>
     with respect to the parameters
     <math alttext="\theta" class="ltx_Math" display="inline" id="Sx2.SSx1.p15.6.m6.1">
      <semantics id="Sx2.SSx1.p15.6.m6.1a">
       <mi id="Sx2.SSx1.p15.6.m6.1.1" xref="Sx2.SSx1.p15.6.m6.1.1.cmml">
        θ
       </mi>
       <annotation-xml encoding="MathML-Content" id="Sx2.SSx1.p15.6.m6.1b">
        <ci id="Sx2.SSx1.p15.6.m6.1.1.cmml" xref="Sx2.SSx1.p15.6.m6.1.1">
         𝜃
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="Sx2.SSx1.p15.6.m6.1c">
        \theta
       </annotation>
      </semantics>
     </math>
     on the task-specific dataset
     <math alttext="D_{\text{task}}" class="ltx_Math" display="inline" id="Sx2.SSx1.p15.7.m7.1">
      <semantics id="Sx2.SSx1.p15.7.m7.1a">
       <msub id="Sx2.SSx1.p15.7.m7.1.1" xref="Sx2.SSx1.p15.7.m7.1.1.cmml">
        <mi id="Sx2.SSx1.p15.7.m7.1.1.2" xref="Sx2.SSx1.p15.7.m7.1.1.2.cmml">
         D
        </mi>
        <mtext id="Sx2.SSx1.p15.7.m7.1.1.3" xref="Sx2.SSx1.p15.7.m7.1.1.3a.cmml">
         task
        </mtext>
       </msub>
       <annotation-xml encoding="MathML-Content" id="Sx2.SSx1.p15.7.m7.1b">
        <apply id="Sx2.SSx1.p15.7.m7.1.1.cmml" xref="Sx2.SSx1.p15.7.m7.1.1">
         <csymbol cd="ambiguous" id="Sx2.SSx1.p15.7.m7.1.1.1.cmml" xref="Sx2.SSx1.p15.7.m7.1.1">
          subscript
         </csymbol>
         <ci id="Sx2.SSx1.p15.7.m7.1.1.2.cmml" xref="Sx2.SSx1.p15.7.m7.1.1.2">
          𝐷
         </ci>
         <ci id="Sx2.SSx1.p15.7.m7.1.1.3a.cmml" xref="Sx2.SSx1.p15.7.m7.1.1.3">
          <mtext id="Sx2.SSx1.p15.7.m7.1.1.3.cmml" mathsize="70%" xref="Sx2.SSx1.p15.7.m7.1.1.3">
           task
          </mtext>
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="Sx2.SSx1.p15.7.m7.1c">
        D_{\text{task}}
       </annotation>
      </semantics>
     </math>
     .
    </p>
   </div>
   <div class="ltx_para" id="Sx2.SSx1.p16">
    <table class="ltx_equation ltx_eqn_table" id="Sx2.E6">
     <tbody>
      <tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
       <td class="ltx_eqn_cell ltx_eqn_center_padleft">
       </td>
       <td class="ltx_eqn_cell ltx_align_center">
        <math alttext="P(T|C)=\prod_{i=1}^{n}P(t_{i}|t_{&lt;i},C)" class="ltx_Math" display="block" id="Sx2.E6.m1.3">
         <semantics id="Sx2.E6.m1.3a">
          <mrow id="Sx2.E6.m1.3.3" xref="Sx2.E6.m1.3.3.cmml">
           <mrow id="Sx2.E6.m1.2.2.1" xref="Sx2.E6.m1.2.2.1.cmml">
            <mi id="Sx2.E6.m1.2.2.1.3" xref="Sx2.E6.m1.2.2.1.3.cmml">
             P
            </mi>
            <mo id="Sx2.E6.m1.2.2.1.2" lspace="0em" rspace="0em" xref="Sx2.E6.m1.2.2.1.2.cmml">
             ​
            </mo>
            <mrow id="Sx2.E6.m1.2.2.1.1.1" xref="Sx2.E6.m1.2.2.1.1.1.1.cmml">
             <mo id="Sx2.E6.m1.2.2.1.1.1.2" stretchy="false" xref="Sx2.E6.m1.2.2.1.1.1.1.cmml">
              (
             </mo>
             <mrow id="Sx2.E6.m1.2.2.1.1.1.1" xref="Sx2.E6.m1.2.2.1.1.1.1.cmml">
              <mi id="Sx2.E6.m1.2.2.1.1.1.1.2" xref="Sx2.E6.m1.2.2.1.1.1.1.2.cmml">
               T
              </mi>
              <mo fence="false" id="Sx2.E6.m1.2.2.1.1.1.1.1" xref="Sx2.E6.m1.2.2.1.1.1.1.1.cmml">
               |
              </mo>
              <mi id="Sx2.E6.m1.2.2.1.1.1.1.3" xref="Sx2.E6.m1.2.2.1.1.1.1.3.cmml">
               C
              </mi>
             </mrow>
             <mo id="Sx2.E6.m1.2.2.1.1.1.3" stretchy="false" xref="Sx2.E6.m1.2.2.1.1.1.1.cmml">
              )
             </mo>
            </mrow>
           </mrow>
           <mo id="Sx2.E6.m1.3.3.3" rspace="0.111em" xref="Sx2.E6.m1.3.3.3.cmml">
            =
           </mo>
           <mrow id="Sx2.E6.m1.3.3.2" xref="Sx2.E6.m1.3.3.2.cmml">
            <munderover id="Sx2.E6.m1.3.3.2.2" xref="Sx2.E6.m1.3.3.2.2.cmml">
             <mo id="Sx2.E6.m1.3.3.2.2.2.2" movablelimits="false" xref="Sx2.E6.m1.3.3.2.2.2.2.cmml">
              ∏
             </mo>
             <mrow id="Sx2.E6.m1.3.3.2.2.2.3" xref="Sx2.E6.m1.3.3.2.2.2.3.cmml">
              <mi id="Sx2.E6.m1.3.3.2.2.2.3.2" xref="Sx2.E6.m1.3.3.2.2.2.3.2.cmml">
               i
              </mi>
              <mo id="Sx2.E6.m1.3.3.2.2.2.3.1" xref="Sx2.E6.m1.3.3.2.2.2.3.1.cmml">
               =
              </mo>
              <mn id="Sx2.E6.m1.3.3.2.2.2.3.3" xref="Sx2.E6.m1.3.3.2.2.2.3.3.cmml">
               1
              </mn>
             </mrow>
             <mi id="Sx2.E6.m1.3.3.2.2.3" xref="Sx2.E6.m1.3.3.2.2.3.cmml">
              n
             </mi>
            </munderover>
            <mrow id="Sx2.E6.m1.3.3.2.1" xref="Sx2.E6.m1.3.3.2.1.cmml">
             <mi id="Sx2.E6.m1.3.3.2.1.3" xref="Sx2.E6.m1.3.3.2.1.3.cmml">
              P
             </mi>
             <mo id="Sx2.E6.m1.3.3.2.1.2" lspace="0em" rspace="0em" xref="Sx2.E6.m1.3.3.2.1.2.cmml">
              ​
             </mo>
             <mrow id="Sx2.E6.m1.3.3.2.1.1.1" xref="Sx2.E6.m1.3.3.2.1.1.1.1.cmml">
              <mo id="Sx2.E6.m1.3.3.2.1.1.1.2" stretchy="false" xref="Sx2.E6.m1.3.3.2.1.1.1.1.cmml">
               (
              </mo>
              <mrow id="Sx2.E6.m1.3.3.2.1.1.1.1" xref="Sx2.E6.m1.3.3.2.1.1.1.1.cmml">
               <msub id="Sx2.E6.m1.3.3.2.1.1.1.1.3" xref="Sx2.E6.m1.3.3.2.1.1.1.1.3.cmml">
                <mi id="Sx2.E6.m1.3.3.2.1.1.1.1.3.2" xref="Sx2.E6.m1.3.3.2.1.1.1.1.3.2.cmml">
                 t
                </mi>
                <mi id="Sx2.E6.m1.3.3.2.1.1.1.1.3.3" xref="Sx2.E6.m1.3.3.2.1.1.1.1.3.3.cmml">
                 i
                </mi>
               </msub>
               <mo fence="false" id="Sx2.E6.m1.3.3.2.1.1.1.1.2" xref="Sx2.E6.m1.3.3.2.1.1.1.1.2.cmml">
                |
               </mo>
               <mrow id="Sx2.E6.m1.3.3.2.1.1.1.1.1.1" xref="Sx2.E6.m1.3.3.2.1.1.1.1.1.2.cmml">
                <msub id="Sx2.E6.m1.3.3.2.1.1.1.1.1.1.1" xref="Sx2.E6.m1.3.3.2.1.1.1.1.1.1.1.cmml">
                 <mi id="Sx2.E6.m1.3.3.2.1.1.1.1.1.1.1.2" xref="Sx2.E6.m1.3.3.2.1.1.1.1.1.1.1.2.cmml">
                  t
                 </mi>
                 <mrow id="Sx2.E6.m1.3.3.2.1.1.1.1.1.1.1.3" xref="Sx2.E6.m1.3.3.2.1.1.1.1.1.1.1.3.cmml">
                  <mi id="Sx2.E6.m1.3.3.2.1.1.1.1.1.1.1.3.2" xref="Sx2.E6.m1.3.3.2.1.1.1.1.1.1.1.3.2.cmml">
                  </mi>
                  <mo id="Sx2.E6.m1.3.3.2.1.1.1.1.1.1.1.3.1" xref="Sx2.E6.m1.3.3.2.1.1.1.1.1.1.1.3.1.cmml">
                   &lt;
                  </mo>
                  <mi id="Sx2.E6.m1.3.3.2.1.1.1.1.1.1.1.3.3" xref="Sx2.E6.m1.3.3.2.1.1.1.1.1.1.1.3.3.cmml">
                   i
                  </mi>
                 </mrow>
                </msub>
                <mo id="Sx2.E6.m1.3.3.2.1.1.1.1.1.1.2" xref="Sx2.E6.m1.3.3.2.1.1.1.1.1.2.cmml">
                 ,
                </mo>
                <mi id="Sx2.E6.m1.1.1" xref="Sx2.E6.m1.1.1.cmml">
                 C
                </mi>
               </mrow>
              </mrow>
              <mo id="Sx2.E6.m1.3.3.2.1.1.1.3" stretchy="false" xref="Sx2.E6.m1.3.3.2.1.1.1.1.cmml">
               )
              </mo>
             </mrow>
            </mrow>
           </mrow>
          </mrow>
          <annotation-xml encoding="MathML-Content" id="Sx2.E6.m1.3b">
           <apply id="Sx2.E6.m1.3.3.cmml" xref="Sx2.E6.m1.3.3">
            <eq id="Sx2.E6.m1.3.3.3.cmml" xref="Sx2.E6.m1.3.3.3">
            </eq>
            <apply id="Sx2.E6.m1.2.2.1.cmml" xref="Sx2.E6.m1.2.2.1">
             <times id="Sx2.E6.m1.2.2.1.2.cmml" xref="Sx2.E6.m1.2.2.1.2">
             </times>
             <ci id="Sx2.E6.m1.2.2.1.3.cmml" xref="Sx2.E6.m1.2.2.1.3">
              𝑃
             </ci>
             <apply id="Sx2.E6.m1.2.2.1.1.1.1.cmml" xref="Sx2.E6.m1.2.2.1.1.1">
              <csymbol cd="latexml" id="Sx2.E6.m1.2.2.1.1.1.1.1.cmml" xref="Sx2.E6.m1.2.2.1.1.1.1.1">
               conditional
              </csymbol>
              <ci id="Sx2.E6.m1.2.2.1.1.1.1.2.cmml" xref="Sx2.E6.m1.2.2.1.1.1.1.2">
               𝑇
              </ci>
              <ci id="Sx2.E6.m1.2.2.1.1.1.1.3.cmml" xref="Sx2.E6.m1.2.2.1.1.1.1.3">
               𝐶
              </ci>
             </apply>
            </apply>
            <apply id="Sx2.E6.m1.3.3.2.cmml" xref="Sx2.E6.m1.3.3.2">
             <apply id="Sx2.E6.m1.3.3.2.2.cmml" xref="Sx2.E6.m1.3.3.2.2">
              <csymbol cd="ambiguous" id="Sx2.E6.m1.3.3.2.2.1.cmml" xref="Sx2.E6.m1.3.3.2.2">
               superscript
              </csymbol>
              <apply id="Sx2.E6.m1.3.3.2.2.2.cmml" xref="Sx2.E6.m1.3.3.2.2">
               <csymbol cd="ambiguous" id="Sx2.E6.m1.3.3.2.2.2.1.cmml" xref="Sx2.E6.m1.3.3.2.2">
                subscript
               </csymbol>
               <csymbol cd="latexml" id="Sx2.E6.m1.3.3.2.2.2.2.cmml" xref="Sx2.E6.m1.3.3.2.2.2.2">
                product
               </csymbol>
               <apply id="Sx2.E6.m1.3.3.2.2.2.3.cmml" xref="Sx2.E6.m1.3.3.2.2.2.3">
                <eq id="Sx2.E6.m1.3.3.2.2.2.3.1.cmml" xref="Sx2.E6.m1.3.3.2.2.2.3.1">
                </eq>
                <ci id="Sx2.E6.m1.3.3.2.2.2.3.2.cmml" xref="Sx2.E6.m1.3.3.2.2.2.3.2">
                 𝑖
                </ci>
                <cn id="Sx2.E6.m1.3.3.2.2.2.3.3.cmml" type="integer" xref="Sx2.E6.m1.3.3.2.2.2.3.3">
                 1
                </cn>
               </apply>
              </apply>
              <ci id="Sx2.E6.m1.3.3.2.2.3.cmml" xref="Sx2.E6.m1.3.3.2.2.3">
               𝑛
              </ci>
             </apply>
             <apply id="Sx2.E6.m1.3.3.2.1.cmml" xref="Sx2.E6.m1.3.3.2.1">
              <times id="Sx2.E6.m1.3.3.2.1.2.cmml" xref="Sx2.E6.m1.3.3.2.1.2">
              </times>
              <ci id="Sx2.E6.m1.3.3.2.1.3.cmml" xref="Sx2.E6.m1.3.3.2.1.3">
               𝑃
              </ci>
              <apply id="Sx2.E6.m1.3.3.2.1.1.1.1.cmml" xref="Sx2.E6.m1.3.3.2.1.1.1">
               <csymbol cd="latexml" id="Sx2.E6.m1.3.3.2.1.1.1.1.2.cmml" xref="Sx2.E6.m1.3.3.2.1.1.1.1.2">
                conditional
               </csymbol>
               <apply id="Sx2.E6.m1.3.3.2.1.1.1.1.3.cmml" xref="Sx2.E6.m1.3.3.2.1.1.1.1.3">
                <csymbol cd="ambiguous" id="Sx2.E6.m1.3.3.2.1.1.1.1.3.1.cmml" xref="Sx2.E6.m1.3.3.2.1.1.1.1.3">
                 subscript
                </csymbol>
                <ci id="Sx2.E6.m1.3.3.2.1.1.1.1.3.2.cmml" xref="Sx2.E6.m1.3.3.2.1.1.1.1.3.2">
                 𝑡
                </ci>
                <ci id="Sx2.E6.m1.3.3.2.1.1.1.1.3.3.cmml" xref="Sx2.E6.m1.3.3.2.1.1.1.1.3.3">
                 𝑖
                </ci>
               </apply>
               <list id="Sx2.E6.m1.3.3.2.1.1.1.1.1.2.cmml" xref="Sx2.E6.m1.3.3.2.1.1.1.1.1.1">
                <apply id="Sx2.E6.m1.3.3.2.1.1.1.1.1.1.1.cmml" xref="Sx2.E6.m1.3.3.2.1.1.1.1.1.1.1">
                 <csymbol cd="ambiguous" id="Sx2.E6.m1.3.3.2.1.1.1.1.1.1.1.1.cmml" xref="Sx2.E6.m1.3.3.2.1.1.1.1.1.1.1">
                  subscript
                 </csymbol>
                 <ci id="Sx2.E6.m1.3.3.2.1.1.1.1.1.1.1.2.cmml" xref="Sx2.E6.m1.3.3.2.1.1.1.1.1.1.1.2">
                  𝑡
                 </ci>
                 <apply id="Sx2.E6.m1.3.3.2.1.1.1.1.1.1.1.3.cmml" xref="Sx2.E6.m1.3.3.2.1.1.1.1.1.1.1.3">
                  <lt id="Sx2.E6.m1.3.3.2.1.1.1.1.1.1.1.3.1.cmml" xref="Sx2.E6.m1.3.3.2.1.1.1.1.1.1.1.3.1">
                  </lt>
                  <csymbol cd="latexml" id="Sx2.E6.m1.3.3.2.1.1.1.1.1.1.1.3.2.cmml" xref="Sx2.E6.m1.3.3.2.1.1.1.1.1.1.1.3.2">
                   absent
                  </csymbol>
                  <ci id="Sx2.E6.m1.3.3.2.1.1.1.1.1.1.1.3.3.cmml" xref="Sx2.E6.m1.3.3.2.1.1.1.1.1.1.1.3.3">
                   𝑖
                  </ci>
                 </apply>
                </apply>
                <ci id="Sx2.E6.m1.1.1.cmml" xref="Sx2.E6.m1.1.1">
                 𝐶
                </ci>
               </list>
              </apply>
             </apply>
            </apply>
           </apply>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="Sx2.E6.m1.3c">
           P(T|C)=\prod_{i=1}^{n}P(t_{i}|t_{&lt;i},C)
          </annotation>
         </semantics>
        </math>
       </td>
       <td class="ltx_eqn_cell ltx_eqn_center_padright">
       </td>
       <td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1">
        <span class="ltx_tag ltx_tag_equation ltx_align_right">
         (6)
        </span>
       </td>
      </tr>
     </tbody>
    </table>
   </div>
   <div class="ltx_para" id="Sx2.SSx1.p17">
    <p class="ltx_p" id="Sx2.SSx1.p17.10">
     Complementing the fine-tuning approach is in-context learning, an alternative strategy that is particularly characteristic of models like the GPT series. This method diverges from fine-tuning by enabling the model to adapt its responses based on immediate context or prompts without necessitating further training. The efficacy of in-context learning is a direct consequence of the comprehensive pre-training phase, where models are exposed to diverse textual datasets, thereby acquiring a nuanced understanding of language and context. Given a context
     <math alttext="C" class="ltx_Math" display="inline" id="Sx2.SSx1.p17.1.m1.1">
      <semantics id="Sx2.SSx1.p17.1.m1.1a">
       <mi id="Sx2.SSx1.p17.1.m1.1.1" xref="Sx2.SSx1.p17.1.m1.1.1.cmml">
        C
       </mi>
       <annotation-xml encoding="MathML-Content" id="Sx2.SSx1.p17.1.m1.1b">
        <ci id="Sx2.SSx1.p17.1.m1.1.1.cmml" xref="Sx2.SSx1.p17.1.m1.1.1">
         𝐶
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="Sx2.SSx1.p17.1.m1.1c">
        C
       </annotation>
      </semantics>
     </math>
     , the model generates text
     <math alttext="T" class="ltx_Math" display="inline" id="Sx2.SSx1.p17.2.m2.1">
      <semantics id="Sx2.SSx1.p17.2.m2.1a">
       <mi id="Sx2.SSx1.p17.2.m2.1.1" xref="Sx2.SSx1.p17.2.m2.1.1.cmml">
        T
       </mi>
       <annotation-xml encoding="MathML-Content" id="Sx2.SSx1.p17.2.m2.1b">
        <ci id="Sx2.SSx1.p17.2.m2.1.1.cmml" xref="Sx2.SSx1.p17.2.m2.1.1">
         𝑇
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="Sx2.SSx1.p17.2.m2.1c">
        T
       </annotation>
      </semantics>
     </math>
     that is contextually relevant, as shown in Equation
     <a class="ltx_ref" href="#Sx2.E6" title="In Large Language Models ‣ Background ‣ On the Prospects of Incorporating Large Language Models (LLMs) in Automated Planning and Scheduling (APS)">
      <span class="ltx_text ltx_ref_tag">
       6
      </span>
     </a>
     . Here,
     <math alttext="P(T|C)" class="ltx_Math" display="inline" id="Sx2.SSx1.p17.3.m3.1">
      <semantics id="Sx2.SSx1.p17.3.m3.1a">
       <mrow id="Sx2.SSx1.p17.3.m3.1.1" xref="Sx2.SSx1.p17.3.m3.1.1.cmml">
        <mi id="Sx2.SSx1.p17.3.m3.1.1.3" xref="Sx2.SSx1.p17.3.m3.1.1.3.cmml">
         P
        </mi>
        <mo id="Sx2.SSx1.p17.3.m3.1.1.2" lspace="0em" rspace="0em" xref="Sx2.SSx1.p17.3.m3.1.1.2.cmml">
         ​
        </mo>
        <mrow id="Sx2.SSx1.p17.3.m3.1.1.1.1" xref="Sx2.SSx1.p17.3.m3.1.1.1.1.1.cmml">
         <mo id="Sx2.SSx1.p17.3.m3.1.1.1.1.2" stretchy="false" xref="Sx2.SSx1.p17.3.m3.1.1.1.1.1.cmml">
          (
         </mo>
         <mrow id="Sx2.SSx1.p17.3.m3.1.1.1.1.1" xref="Sx2.SSx1.p17.3.m3.1.1.1.1.1.cmml">
          <mi id="Sx2.SSx1.p17.3.m3.1.1.1.1.1.2" xref="Sx2.SSx1.p17.3.m3.1.1.1.1.1.2.cmml">
           T
          </mi>
          <mo fence="false" id="Sx2.SSx1.p17.3.m3.1.1.1.1.1.1" xref="Sx2.SSx1.p17.3.m3.1.1.1.1.1.1.cmml">
           |
          </mo>
          <mi id="Sx2.SSx1.p17.3.m3.1.1.1.1.1.3" xref="Sx2.SSx1.p17.3.m3.1.1.1.1.1.3.cmml">
           C
          </mi>
         </mrow>
         <mo id="Sx2.SSx1.p17.3.m3.1.1.1.1.3" stretchy="false" xref="Sx2.SSx1.p17.3.m3.1.1.1.1.1.cmml">
          )
         </mo>
        </mrow>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="Sx2.SSx1.p17.3.m3.1b">
        <apply id="Sx2.SSx1.p17.3.m3.1.1.cmml" xref="Sx2.SSx1.p17.3.m3.1.1">
         <times id="Sx2.SSx1.p17.3.m3.1.1.2.cmml" xref="Sx2.SSx1.p17.3.m3.1.1.2">
         </times>
         <ci id="Sx2.SSx1.p17.3.m3.1.1.3.cmml" xref="Sx2.SSx1.p17.3.m3.1.1.3">
          𝑃
         </ci>
         <apply id="Sx2.SSx1.p17.3.m3.1.1.1.1.1.cmml" xref="Sx2.SSx1.p17.3.m3.1.1.1.1">
          <csymbol cd="latexml" id="Sx2.SSx1.p17.3.m3.1.1.1.1.1.1.cmml" xref="Sx2.SSx1.p17.3.m3.1.1.1.1.1.1">
           conditional
          </csymbol>
          <ci id="Sx2.SSx1.p17.3.m3.1.1.1.1.1.2.cmml" xref="Sx2.SSx1.p17.3.m3.1.1.1.1.1.2">
           𝑇
          </ci>
          <ci id="Sx2.SSx1.p17.3.m3.1.1.1.1.1.3.cmml" xref="Sx2.SSx1.p17.3.m3.1.1.1.1.1.3">
           𝐶
          </ci>
         </apply>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="Sx2.SSx1.p17.3.m3.1c">
        P(T|C)
       </annotation>
      </semantics>
     </math>
     is the probability of generating text
     <math alttext="T" class="ltx_Math" display="inline" id="Sx2.SSx1.p17.4.m4.1">
      <semantics id="Sx2.SSx1.p17.4.m4.1a">
       <mi id="Sx2.SSx1.p17.4.m4.1.1" xref="Sx2.SSx1.p17.4.m4.1.1.cmml">
        T
       </mi>
       <annotation-xml encoding="MathML-Content" id="Sx2.SSx1.p17.4.m4.1b">
        <ci id="Sx2.SSx1.p17.4.m4.1.1.cmml" xref="Sx2.SSx1.p17.4.m4.1.1">
         𝑇
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="Sx2.SSx1.p17.4.m4.1c">
        T
       </annotation>
      </semantics>
     </math>
     given the context
     <math alttext="C" class="ltx_Math" display="inline" id="Sx2.SSx1.p17.5.m5.1">
      <semantics id="Sx2.SSx1.p17.5.m5.1a">
       <mi id="Sx2.SSx1.p17.5.m5.1.1" xref="Sx2.SSx1.p17.5.m5.1.1.cmml">
        C
       </mi>
       <annotation-xml encoding="MathML-Content" id="Sx2.SSx1.p17.5.m5.1b">
        <ci id="Sx2.SSx1.p17.5.m5.1.1.cmml" xref="Sx2.SSx1.p17.5.m5.1.1">
         𝐶
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="Sx2.SSx1.p17.5.m5.1c">
        C
       </annotation>
      </semantics>
     </math>
     , and
     <math alttext="P(t_{i}|t_{&lt;i},C)" class="ltx_Math" display="inline" id="Sx2.SSx1.p17.6.m6.2">
      <semantics id="Sx2.SSx1.p17.6.m6.2a">
       <mrow id="Sx2.SSx1.p17.6.m6.2.2" xref="Sx2.SSx1.p17.6.m6.2.2.cmml">
        <mi id="Sx2.SSx1.p17.6.m6.2.2.3" xref="Sx2.SSx1.p17.6.m6.2.2.3.cmml">
         P
        </mi>
        <mo id="Sx2.SSx1.p17.6.m6.2.2.2" lspace="0em" rspace="0em" xref="Sx2.SSx1.p17.6.m6.2.2.2.cmml">
         ​
        </mo>
        <mrow id="Sx2.SSx1.p17.6.m6.2.2.1.1" xref="Sx2.SSx1.p17.6.m6.2.2.1.1.1.cmml">
         <mo id="Sx2.SSx1.p17.6.m6.2.2.1.1.2" stretchy="false" xref="Sx2.SSx1.p17.6.m6.2.2.1.1.1.cmml">
          (
         </mo>
         <mrow id="Sx2.SSx1.p17.6.m6.2.2.1.1.1" xref="Sx2.SSx1.p17.6.m6.2.2.1.1.1.cmml">
          <msub id="Sx2.SSx1.p17.6.m6.2.2.1.1.1.3" xref="Sx2.SSx1.p17.6.m6.2.2.1.1.1.3.cmml">
           <mi id="Sx2.SSx1.p17.6.m6.2.2.1.1.1.3.2" xref="Sx2.SSx1.p17.6.m6.2.2.1.1.1.3.2.cmml">
            t
           </mi>
           <mi id="Sx2.SSx1.p17.6.m6.2.2.1.1.1.3.3" xref="Sx2.SSx1.p17.6.m6.2.2.1.1.1.3.3.cmml">
            i
           </mi>
          </msub>
          <mo fence="false" id="Sx2.SSx1.p17.6.m6.2.2.1.1.1.2" xref="Sx2.SSx1.p17.6.m6.2.2.1.1.1.2.cmml">
           |
          </mo>
          <mrow id="Sx2.SSx1.p17.6.m6.2.2.1.1.1.1.1" xref="Sx2.SSx1.p17.6.m6.2.2.1.1.1.1.2.cmml">
           <msub id="Sx2.SSx1.p17.6.m6.2.2.1.1.1.1.1.1" xref="Sx2.SSx1.p17.6.m6.2.2.1.1.1.1.1.1.cmml">
            <mi id="Sx2.SSx1.p17.6.m6.2.2.1.1.1.1.1.1.2" xref="Sx2.SSx1.p17.6.m6.2.2.1.1.1.1.1.1.2.cmml">
             t
            </mi>
            <mrow id="Sx2.SSx1.p17.6.m6.2.2.1.1.1.1.1.1.3" xref="Sx2.SSx1.p17.6.m6.2.2.1.1.1.1.1.1.3.cmml">
             <mi id="Sx2.SSx1.p17.6.m6.2.2.1.1.1.1.1.1.3.2" xref="Sx2.SSx1.p17.6.m6.2.2.1.1.1.1.1.1.3.2.cmml">
             </mi>
             <mo id="Sx2.SSx1.p17.6.m6.2.2.1.1.1.1.1.1.3.1" xref="Sx2.SSx1.p17.6.m6.2.2.1.1.1.1.1.1.3.1.cmml">
              &lt;
             </mo>
             <mi id="Sx2.SSx1.p17.6.m6.2.2.1.1.1.1.1.1.3.3" xref="Sx2.SSx1.p17.6.m6.2.2.1.1.1.1.1.1.3.3.cmml">
              i
             </mi>
            </mrow>
           </msub>
           <mo id="Sx2.SSx1.p17.6.m6.2.2.1.1.1.1.1.2" xref="Sx2.SSx1.p17.6.m6.2.2.1.1.1.1.2.cmml">
            ,
           </mo>
           <mi id="Sx2.SSx1.p17.6.m6.1.1" xref="Sx2.SSx1.p17.6.m6.1.1.cmml">
            C
           </mi>
          </mrow>
         </mrow>
         <mo id="Sx2.SSx1.p17.6.m6.2.2.1.1.3" stretchy="false" xref="Sx2.SSx1.p17.6.m6.2.2.1.1.1.cmml">
          )
         </mo>
        </mrow>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="Sx2.SSx1.p17.6.m6.2b">
        <apply id="Sx2.SSx1.p17.6.m6.2.2.cmml" xref="Sx2.SSx1.p17.6.m6.2.2">
         <times id="Sx2.SSx1.p17.6.m6.2.2.2.cmml" xref="Sx2.SSx1.p17.6.m6.2.2.2">
         </times>
         <ci id="Sx2.SSx1.p17.6.m6.2.2.3.cmml" xref="Sx2.SSx1.p17.6.m6.2.2.3">
          𝑃
         </ci>
         <apply id="Sx2.SSx1.p17.6.m6.2.2.1.1.1.cmml" xref="Sx2.SSx1.p17.6.m6.2.2.1.1">
          <csymbol cd="latexml" id="Sx2.SSx1.p17.6.m6.2.2.1.1.1.2.cmml" xref="Sx2.SSx1.p17.6.m6.2.2.1.1.1.2">
           conditional
          </csymbol>
          <apply id="Sx2.SSx1.p17.6.m6.2.2.1.1.1.3.cmml" xref="Sx2.SSx1.p17.6.m6.2.2.1.1.1.3">
           <csymbol cd="ambiguous" id="Sx2.SSx1.p17.6.m6.2.2.1.1.1.3.1.cmml" xref="Sx2.SSx1.p17.6.m6.2.2.1.1.1.3">
            subscript
           </csymbol>
           <ci id="Sx2.SSx1.p17.6.m6.2.2.1.1.1.3.2.cmml" xref="Sx2.SSx1.p17.6.m6.2.2.1.1.1.3.2">
            𝑡
           </ci>
           <ci id="Sx2.SSx1.p17.6.m6.2.2.1.1.1.3.3.cmml" xref="Sx2.SSx1.p17.6.m6.2.2.1.1.1.3.3">
            𝑖
           </ci>
          </apply>
          <list id="Sx2.SSx1.p17.6.m6.2.2.1.1.1.1.2.cmml" xref="Sx2.SSx1.p17.6.m6.2.2.1.1.1.1.1">
           <apply id="Sx2.SSx1.p17.6.m6.2.2.1.1.1.1.1.1.cmml" xref="Sx2.SSx1.p17.6.m6.2.2.1.1.1.1.1.1">
            <csymbol cd="ambiguous" id="Sx2.SSx1.p17.6.m6.2.2.1.1.1.1.1.1.1.cmml" xref="Sx2.SSx1.p17.6.m6.2.2.1.1.1.1.1.1">
             subscript
            </csymbol>
            <ci id="Sx2.SSx1.p17.6.m6.2.2.1.1.1.1.1.1.2.cmml" xref="Sx2.SSx1.p17.6.m6.2.2.1.1.1.1.1.1.2">
             𝑡
            </ci>
            <apply id="Sx2.SSx1.p17.6.m6.2.2.1.1.1.1.1.1.3.cmml" xref="Sx2.SSx1.p17.6.m6.2.2.1.1.1.1.1.1.3">
             <lt id="Sx2.SSx1.p17.6.m6.2.2.1.1.1.1.1.1.3.1.cmml" xref="Sx2.SSx1.p17.6.m6.2.2.1.1.1.1.1.1.3.1">
             </lt>
             <csymbol cd="latexml" id="Sx2.SSx1.p17.6.m6.2.2.1.1.1.1.1.1.3.2.cmml" xref="Sx2.SSx1.p17.6.m6.2.2.1.1.1.1.1.1.3.2">
              absent
             </csymbol>
             <ci id="Sx2.SSx1.p17.6.m6.2.2.1.1.1.1.1.1.3.3.cmml" xref="Sx2.SSx1.p17.6.m6.2.2.1.1.1.1.1.1.3.3">
              𝑖
             </ci>
            </apply>
           </apply>
           <ci id="Sx2.SSx1.p17.6.m6.1.1.cmml" xref="Sx2.SSx1.p17.6.m6.1.1">
            𝐶
           </ci>
          </list>
         </apply>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="Sx2.SSx1.p17.6.m6.2c">
        P(t_{i}|t_{&lt;i},C)
       </annotation>
      </semantics>
     </math>
     is the probability of generating the
     <math alttext="i" class="ltx_Math" display="inline" id="Sx2.SSx1.p17.7.m7.1">
      <semantics id="Sx2.SSx1.p17.7.m7.1a">
       <mi id="Sx2.SSx1.p17.7.m7.1.1" xref="Sx2.SSx1.p17.7.m7.1.1.cmml">
        i
       </mi>
       <annotation-xml encoding="MathML-Content" id="Sx2.SSx1.p17.7.m7.1b">
        <ci id="Sx2.SSx1.p17.7.m7.1.1.cmml" xref="Sx2.SSx1.p17.7.m7.1.1">
         𝑖
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="Sx2.SSx1.p17.7.m7.1c">
        i
       </annotation>
      </semantics>
     </math>
     -th token
     <math alttext="t_{i}" class="ltx_Math" display="inline" id="Sx2.SSx1.p17.8.m8.1">
      <semantics id="Sx2.SSx1.p17.8.m8.1a">
       <msub id="Sx2.SSx1.p17.8.m8.1.1" xref="Sx2.SSx1.p17.8.m8.1.1.cmml">
        <mi id="Sx2.SSx1.p17.8.m8.1.1.2" xref="Sx2.SSx1.p17.8.m8.1.1.2.cmml">
         t
        </mi>
        <mi id="Sx2.SSx1.p17.8.m8.1.1.3" xref="Sx2.SSx1.p17.8.m8.1.1.3.cmml">
         i
        </mi>
       </msub>
       <annotation-xml encoding="MathML-Content" id="Sx2.SSx1.p17.8.m8.1b">
        <apply id="Sx2.SSx1.p17.8.m8.1.1.cmml" xref="Sx2.SSx1.p17.8.m8.1.1">
         <csymbol cd="ambiguous" id="Sx2.SSx1.p17.8.m8.1.1.1.cmml" xref="Sx2.SSx1.p17.8.m8.1.1">
          subscript
         </csymbol>
         <ci id="Sx2.SSx1.p17.8.m8.1.1.2.cmml" xref="Sx2.SSx1.p17.8.m8.1.1.2">
          𝑡
         </ci>
         <ci id="Sx2.SSx1.p17.8.m8.1.1.3.cmml" xref="Sx2.SSx1.p17.8.m8.1.1.3">
          𝑖
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="Sx2.SSx1.p17.8.m8.1c">
        t_{i}
       </annotation>
      </semantics>
     </math>
     given the preceding tokens
     <math alttext="t_{&lt;i}" class="ltx_Math" display="inline" id="Sx2.SSx1.p17.9.m9.1">
      <semantics id="Sx2.SSx1.p17.9.m9.1a">
       <msub id="Sx2.SSx1.p17.9.m9.1.1" xref="Sx2.SSx1.p17.9.m9.1.1.cmml">
        <mi id="Sx2.SSx1.p17.9.m9.1.1.2" xref="Sx2.SSx1.p17.9.m9.1.1.2.cmml">
         t
        </mi>
        <mrow id="Sx2.SSx1.p17.9.m9.1.1.3" xref="Sx2.SSx1.p17.9.m9.1.1.3.cmml">
         <mi id="Sx2.SSx1.p17.9.m9.1.1.3.2" xref="Sx2.SSx1.p17.9.m9.1.1.3.2.cmml">
         </mi>
         <mo id="Sx2.SSx1.p17.9.m9.1.1.3.1" xref="Sx2.SSx1.p17.9.m9.1.1.3.1.cmml">
          &lt;
         </mo>
         <mi id="Sx2.SSx1.p17.9.m9.1.1.3.3" xref="Sx2.SSx1.p17.9.m9.1.1.3.3.cmml">
          i
         </mi>
        </mrow>
       </msub>
       <annotation-xml encoding="MathML-Content" id="Sx2.SSx1.p17.9.m9.1b">
        <apply id="Sx2.SSx1.p17.9.m9.1.1.cmml" xref="Sx2.SSx1.p17.9.m9.1.1">
         <csymbol cd="ambiguous" id="Sx2.SSx1.p17.9.m9.1.1.1.cmml" xref="Sx2.SSx1.p17.9.m9.1.1">
          subscript
         </csymbol>
         <ci id="Sx2.SSx1.p17.9.m9.1.1.2.cmml" xref="Sx2.SSx1.p17.9.m9.1.1.2">
          𝑡
         </ci>
         <apply id="Sx2.SSx1.p17.9.m9.1.1.3.cmml" xref="Sx2.SSx1.p17.9.m9.1.1.3">
          <lt id="Sx2.SSx1.p17.9.m9.1.1.3.1.cmml" xref="Sx2.SSx1.p17.9.m9.1.1.3.1">
          </lt>
          <csymbol cd="latexml" id="Sx2.SSx1.p17.9.m9.1.1.3.2.cmml" xref="Sx2.SSx1.p17.9.m9.1.1.3.2">
           absent
          </csymbol>
          <ci id="Sx2.SSx1.p17.9.m9.1.1.3.3.cmml" xref="Sx2.SSx1.p17.9.m9.1.1.3.3">
           𝑖
          </ci>
         </apply>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="Sx2.SSx1.p17.9.m9.1c">
        t_{&lt;i}
       </annotation>
      </semantics>
     </math>
     and the context
     <math alttext="C" class="ltx_Math" display="inline" id="Sx2.SSx1.p17.10.m10.1">
      <semantics id="Sx2.SSx1.p17.10.m10.1a">
       <mi id="Sx2.SSx1.p17.10.m10.1.1" xref="Sx2.SSx1.p17.10.m10.1.1.cmml">
        C
       </mi>
       <annotation-xml encoding="MathML-Content" id="Sx2.SSx1.p17.10.m10.1b">
        <ci id="Sx2.SSx1.p17.10.m10.1.1.cmml" xref="Sx2.SSx1.p17.10.m10.1.1">
         𝐶
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="Sx2.SSx1.p17.10.m10.1c">
        C
       </annotation>
      </semantics>
     </math>
     .
    </p>
   </div>
   <figure class="ltx_figure" id="Sx2.F1">
    <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="291" id="Sx2.F1.g1" src="/html/2401.02500/assets/figures/llm_benchmarks.png" width="479"/>
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_figure">
      Figure 1:
     </span>
     Radar chart showcasing the relative performance of six language models (GPT-4, Claude-v1, GPT-3.5-turbo, Vicuna-13B, Alpaca-13B, LLama-13B) across key domains: Writing, Roleplay, Reasoning, Math, Coding, Extraction, STEM, and Humanities from
     <cite class="ltx_cite ltx_citemacro_citet">
      Zheng et al. (
      <a class="ltx_ref" href="#bib.bib137" title="">
       2023a
      </a>
      )
     </cite>
     .
    </figcaption>
   </figure>
   <figure class="ltx_figure" id="Sx2.F2">
    <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="216" id="Sx2.F2.g1" src="/html/2401.02500/assets/figures/papers_per_conferences.png" width="558"/>
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_figure">
      Figure 2:
     </span>
     Of the 126 papers surveyed in this study, 55 were accepted by peer-reviewed conferences. This chart illustrates the distribution of these papers across various conferences in the fields of LLMs and APS, highlighting the primary forums for scholarly contributions in these areas.
    </figcaption>
   </figure>
   <div class="ltx_para" id="Sx2.SSx1.p18">
    <p class="ltx_p" id="Sx2.SSx1.p18.1">
     These diverse model types and training methodologies under the umbrella of LLMs showcase the flexibility and adaptability of language models in handling a wide range of complex tasks. Figure
     <a class="ltx_ref" href="#Sx2.F1" title="Figure 1 ‣ Large Language Models ‣ Background ‣ On the Prospects of Incorporating Large Language Models (LLMs) in Automated Planning and Scheduling (APS)">
      <span class="ltx_text ltx_ref_tag">
       1
      </span>
     </a>
     illustrates the comparative capabilities of different LLMs across various competency domains, such as Writing (evaluating text generation quality), Roleplay (assessing conversational interaction), Reasoning (logical problem-solving), Math (numerical problem-solving), Coding (programming language understanding and generation), Extraction (information retrieval from text), STEM (proficiency in scientific and technical contexts), and Humanities (engagement with arts, history, and social sciences content). Across these domains, GPT-4 exhibits the strongest performance in the benchmark dataset evaluated by
     <cite class="ltx_cite ltx_citemacro_citet">
      Zheng et al. (
      <a class="ltx_ref" href="#bib.bib137" title="">
       2023a
      </a>
      )
     </cite>
     , indicative of its superior training and extensive knowledge base. Expanding LLMs into applications such as code generation signifies their adaptability and potential for cross-disciplinary innovation. However, fine-tuning and in-context learning methodologies also bring challenges, such as potential data overfitting and reliance on the quality of input context. LLMs’ continuous development and refinement promise to open new frontiers in various domains, including automated planning and scheduling, by bridging AI with human-like language understanding.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="Sx2.SSx2">
   <h3 class="ltx_title ltx_title_subsection">
    Automated Planning and Scheduling
   </h3>
   <div class="ltx_para" id="Sx2.SSx2.p1">
    <p class="ltx_p" id="Sx2.SSx2.p1.19">
     APS is a branch of AI that focuses on the creation of strategies or action sequences, typically for execution by intelligent agents, autonomous robots, and unmanned vehicles. A basic category in APS is a Classical Planning Problem (CPP)
     <cite class="ltx_cite ltx_citemacro_citep">
      (Russell and Norvig
      <a class="ltx_ref" href="#bib.bib87" title="">
       2003
      </a>
      )
     </cite>
     which is a tuple
     <math alttext="\mathcal{M}=\langle\mathcal{D},\mathcal{I},\mathcal{G}\rangle" class="ltx_Math" display="inline" id="Sx2.SSx2.p1.1.m1.3">
      <semantics id="Sx2.SSx2.p1.1.m1.3a">
       <mrow id="Sx2.SSx2.p1.1.m1.3.4" xref="Sx2.SSx2.p1.1.m1.3.4.cmml">
        <mi class="ltx_font_mathcaligraphic" id="Sx2.SSx2.p1.1.m1.3.4.2" xref="Sx2.SSx2.p1.1.m1.3.4.2.cmml">
         ℳ
        </mi>
        <mo id="Sx2.SSx2.p1.1.m1.3.4.1" xref="Sx2.SSx2.p1.1.m1.3.4.1.cmml">
         =
        </mo>
        <mrow id="Sx2.SSx2.p1.1.m1.3.4.3.2" xref="Sx2.SSx2.p1.1.m1.3.4.3.1.cmml">
         <mo id="Sx2.SSx2.p1.1.m1.3.4.3.2.1" stretchy="false" xref="Sx2.SSx2.p1.1.m1.3.4.3.1.cmml">
          ⟨
         </mo>
         <mi class="ltx_font_mathcaligraphic" id="Sx2.SSx2.p1.1.m1.1.1" xref="Sx2.SSx2.p1.1.m1.1.1.cmml">
          𝒟
         </mi>
         <mo id="Sx2.SSx2.p1.1.m1.3.4.3.2.2" xref="Sx2.SSx2.p1.1.m1.3.4.3.1.cmml">
          ,
         </mo>
         <mi class="ltx_font_mathcaligraphic" id="Sx2.SSx2.p1.1.m1.2.2" xref="Sx2.SSx2.p1.1.m1.2.2.cmml">
          ℐ
         </mi>
         <mo id="Sx2.SSx2.p1.1.m1.3.4.3.2.3" xref="Sx2.SSx2.p1.1.m1.3.4.3.1.cmml">
          ,
         </mo>
         <mi class="ltx_font_mathcaligraphic" id="Sx2.SSx2.p1.1.m1.3.3" xref="Sx2.SSx2.p1.1.m1.3.3.cmml">
          𝒢
         </mi>
         <mo id="Sx2.SSx2.p1.1.m1.3.4.3.2.4" stretchy="false" xref="Sx2.SSx2.p1.1.m1.3.4.3.1.cmml">
          ⟩
         </mo>
        </mrow>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="Sx2.SSx2.p1.1.m1.3b">
        <apply id="Sx2.SSx2.p1.1.m1.3.4.cmml" xref="Sx2.SSx2.p1.1.m1.3.4">
         <eq id="Sx2.SSx2.p1.1.m1.3.4.1.cmml" xref="Sx2.SSx2.p1.1.m1.3.4.1">
         </eq>
         <ci id="Sx2.SSx2.p1.1.m1.3.4.2.cmml" xref="Sx2.SSx2.p1.1.m1.3.4.2">
          ℳ
         </ci>
         <list id="Sx2.SSx2.p1.1.m1.3.4.3.1.cmml" xref="Sx2.SSx2.p1.1.m1.3.4.3.2">
          <ci id="Sx2.SSx2.p1.1.m1.1.1.cmml" xref="Sx2.SSx2.p1.1.m1.1.1">
           𝒟
          </ci>
          <ci id="Sx2.SSx2.p1.1.m1.2.2.cmml" xref="Sx2.SSx2.p1.1.m1.2.2">
           ℐ
          </ci>
          <ci id="Sx2.SSx2.p1.1.m1.3.3.cmml" xref="Sx2.SSx2.p1.1.m1.3.3">
           𝒢
          </ci>
         </list>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="Sx2.SSx2.p1.1.m1.3c">
        \mathcal{M}=\langle\mathcal{D},\mathcal{I},\mathcal{G}\rangle
       </annotation>
      </semantics>
     </math>
     with domain
     <math alttext="\mathcal{D}=\langle F,A\rangle" class="ltx_Math" display="inline" id="Sx2.SSx2.p1.2.m2.2">
      <semantics id="Sx2.SSx2.p1.2.m2.2a">
       <mrow id="Sx2.SSx2.p1.2.m2.2.3" xref="Sx2.SSx2.p1.2.m2.2.3.cmml">
        <mi class="ltx_font_mathcaligraphic" id="Sx2.SSx2.p1.2.m2.2.3.2" xref="Sx2.SSx2.p1.2.m2.2.3.2.cmml">
         𝒟
        </mi>
        <mo id="Sx2.SSx2.p1.2.m2.2.3.1" xref="Sx2.SSx2.p1.2.m2.2.3.1.cmml">
         =
        </mo>
        <mrow id="Sx2.SSx2.p1.2.m2.2.3.3.2" xref="Sx2.SSx2.p1.2.m2.2.3.3.1.cmml">
         <mo id="Sx2.SSx2.p1.2.m2.2.3.3.2.1" stretchy="false" xref="Sx2.SSx2.p1.2.m2.2.3.3.1.cmml">
          ⟨
         </mo>
         <mi id="Sx2.SSx2.p1.2.m2.1.1" xref="Sx2.SSx2.p1.2.m2.1.1.cmml">
          F
         </mi>
         <mo id="Sx2.SSx2.p1.2.m2.2.3.3.2.2" xref="Sx2.SSx2.p1.2.m2.2.3.3.1.cmml">
          ,
         </mo>
         <mi id="Sx2.SSx2.p1.2.m2.2.2" xref="Sx2.SSx2.p1.2.m2.2.2.cmml">
          A
         </mi>
         <mo id="Sx2.SSx2.p1.2.m2.2.3.3.2.3" stretchy="false" xref="Sx2.SSx2.p1.2.m2.2.3.3.1.cmml">
          ⟩
         </mo>
        </mrow>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="Sx2.SSx2.p1.2.m2.2b">
        <apply id="Sx2.SSx2.p1.2.m2.2.3.cmml" xref="Sx2.SSx2.p1.2.m2.2.3">
         <eq id="Sx2.SSx2.p1.2.m2.2.3.1.cmml" xref="Sx2.SSx2.p1.2.m2.2.3.1">
         </eq>
         <ci id="Sx2.SSx2.p1.2.m2.2.3.2.cmml" xref="Sx2.SSx2.p1.2.m2.2.3.2">
          𝒟
         </ci>
         <list id="Sx2.SSx2.p1.2.m2.2.3.3.1.cmml" xref="Sx2.SSx2.p1.2.m2.2.3.3.2">
          <ci id="Sx2.SSx2.p1.2.m2.1.1.cmml" xref="Sx2.SSx2.p1.2.m2.1.1">
           𝐹
          </ci>
          <ci id="Sx2.SSx2.p1.2.m2.2.2.cmml" xref="Sx2.SSx2.p1.2.m2.2.2">
           𝐴
          </ci>
         </list>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="Sx2.SSx2.p1.2.m2.2c">
        \mathcal{D}=\langle F,A\rangle
       </annotation>
      </semantics>
     </math>
     - where
     <math alttext="F" class="ltx_Math" display="inline" id="Sx2.SSx2.p1.3.m3.1">
      <semantics id="Sx2.SSx2.p1.3.m3.1a">
       <mi id="Sx2.SSx2.p1.3.m3.1.1" xref="Sx2.SSx2.p1.3.m3.1.1.cmml">
        F
       </mi>
       <annotation-xml encoding="MathML-Content" id="Sx2.SSx2.p1.3.m3.1b">
        <ci id="Sx2.SSx2.p1.3.m3.1.1.cmml" xref="Sx2.SSx2.p1.3.m3.1.1">
         𝐹
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="Sx2.SSx2.p1.3.m3.1c">
        F
       </annotation>
      </semantics>
     </math>
     is a set of fluents that define a state
     <math alttext="s\subseteq F" class="ltx_Math" display="inline" id="Sx2.SSx2.p1.4.m4.1">
      <semantics id="Sx2.SSx2.p1.4.m4.1a">
       <mrow id="Sx2.SSx2.p1.4.m4.1.1" xref="Sx2.SSx2.p1.4.m4.1.1.cmml">
        <mi id="Sx2.SSx2.p1.4.m4.1.1.2" xref="Sx2.SSx2.p1.4.m4.1.1.2.cmml">
         s
        </mi>
        <mo id="Sx2.SSx2.p1.4.m4.1.1.1" xref="Sx2.SSx2.p1.4.m4.1.1.1.cmml">
         ⊆
        </mo>
        <mi id="Sx2.SSx2.p1.4.m4.1.1.3" xref="Sx2.SSx2.p1.4.m4.1.1.3.cmml">
         F
        </mi>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="Sx2.SSx2.p1.4.m4.1b">
        <apply id="Sx2.SSx2.p1.4.m4.1.1.cmml" xref="Sx2.SSx2.p1.4.m4.1.1">
         <subset id="Sx2.SSx2.p1.4.m4.1.1.1.cmml" xref="Sx2.SSx2.p1.4.m4.1.1.1">
         </subset>
         <ci id="Sx2.SSx2.p1.4.m4.1.1.2.cmml" xref="Sx2.SSx2.p1.4.m4.1.1.2">
          𝑠
         </ci>
         <ci id="Sx2.SSx2.p1.4.m4.1.1.3.cmml" xref="Sx2.SSx2.p1.4.m4.1.1.3">
          𝐹
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="Sx2.SSx2.p1.4.m4.1c">
        s\subseteq F
       </annotation>
      </semantics>
     </math>
     , and
     <math alttext="A" class="ltx_Math" display="inline" id="Sx2.SSx2.p1.5.m5.1">
      <semantics id="Sx2.SSx2.p1.5.m5.1a">
       <mi id="Sx2.SSx2.p1.5.m5.1.1" xref="Sx2.SSx2.p1.5.m5.1.1.cmml">
        A
       </mi>
       <annotation-xml encoding="MathML-Content" id="Sx2.SSx2.p1.5.m5.1b">
        <ci id="Sx2.SSx2.p1.5.m5.1.1.cmml" xref="Sx2.SSx2.p1.5.m5.1.1">
         𝐴
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="Sx2.SSx2.p1.5.m5.1c">
        A
       </annotation>
      </semantics>
     </math>
     is a set of actions - and initial and goal states
     <math alttext="\mathcal{I},\mathcal{G}\subseteq F" class="ltx_Math" display="inline" id="Sx2.SSx2.p1.6.m6.2">
      <semantics id="Sx2.SSx2.p1.6.m6.2a">
       <mrow id="Sx2.SSx2.p1.6.m6.2.3" xref="Sx2.SSx2.p1.6.m6.2.3.cmml">
        <mrow id="Sx2.SSx2.p1.6.m6.2.3.2.2" xref="Sx2.SSx2.p1.6.m6.2.3.2.1.cmml">
         <mi class="ltx_font_mathcaligraphic" id="Sx2.SSx2.p1.6.m6.1.1" xref="Sx2.SSx2.p1.6.m6.1.1.cmml">
          ℐ
         </mi>
         <mo id="Sx2.SSx2.p1.6.m6.2.3.2.2.1" xref="Sx2.SSx2.p1.6.m6.2.3.2.1.cmml">
          ,
         </mo>
         <mi class="ltx_font_mathcaligraphic" id="Sx2.SSx2.p1.6.m6.2.2" xref="Sx2.SSx2.p1.6.m6.2.2.cmml">
          𝒢
         </mi>
        </mrow>
        <mo id="Sx2.SSx2.p1.6.m6.2.3.1" xref="Sx2.SSx2.p1.6.m6.2.3.1.cmml">
         ⊆
        </mo>
        <mi id="Sx2.SSx2.p1.6.m6.2.3.3" xref="Sx2.SSx2.p1.6.m6.2.3.3.cmml">
         F
        </mi>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="Sx2.SSx2.p1.6.m6.2b">
        <apply id="Sx2.SSx2.p1.6.m6.2.3.cmml" xref="Sx2.SSx2.p1.6.m6.2.3">
         <subset id="Sx2.SSx2.p1.6.m6.2.3.1.cmml" xref="Sx2.SSx2.p1.6.m6.2.3.1">
         </subset>
         <list id="Sx2.SSx2.p1.6.m6.2.3.2.1.cmml" xref="Sx2.SSx2.p1.6.m6.2.3.2.2">
          <ci id="Sx2.SSx2.p1.6.m6.1.1.cmml" xref="Sx2.SSx2.p1.6.m6.1.1">
           ℐ
          </ci>
          <ci id="Sx2.SSx2.p1.6.m6.2.2.cmml" xref="Sx2.SSx2.p1.6.m6.2.2">
           𝒢
          </ci>
         </list>
         <ci id="Sx2.SSx2.p1.6.m6.2.3.3.cmml" xref="Sx2.SSx2.p1.6.m6.2.3.3">
          𝐹
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="Sx2.SSx2.p1.6.m6.2c">
        \mathcal{I},\mathcal{G}\subseteq F
       </annotation>
      </semantics>
     </math>
     . Action
     <math alttext="a\in A" class="ltx_Math" display="inline" id="Sx2.SSx2.p1.7.m7.1">
      <semantics id="Sx2.SSx2.p1.7.m7.1a">
       <mrow id="Sx2.SSx2.p1.7.m7.1.1" xref="Sx2.SSx2.p1.7.m7.1.1.cmml">
        <mi id="Sx2.SSx2.p1.7.m7.1.1.2" xref="Sx2.SSx2.p1.7.m7.1.1.2.cmml">
         a
        </mi>
        <mo id="Sx2.SSx2.p1.7.m7.1.1.1" xref="Sx2.SSx2.p1.7.m7.1.1.1.cmml">
         ∈
        </mo>
        <mi id="Sx2.SSx2.p1.7.m7.1.1.3" xref="Sx2.SSx2.p1.7.m7.1.1.3.cmml">
         A
        </mi>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="Sx2.SSx2.p1.7.m7.1b">
        <apply id="Sx2.SSx2.p1.7.m7.1.1.cmml" xref="Sx2.SSx2.p1.7.m7.1.1">
         <in id="Sx2.SSx2.p1.7.m7.1.1.1.cmml" xref="Sx2.SSx2.p1.7.m7.1.1.1">
         </in>
         <ci id="Sx2.SSx2.p1.7.m7.1.1.2.cmml" xref="Sx2.SSx2.p1.7.m7.1.1.2">
          𝑎
         </ci>
         <ci id="Sx2.SSx2.p1.7.m7.1.1.3.cmml" xref="Sx2.SSx2.p1.7.m7.1.1.3">
          𝐴
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="Sx2.SSx2.p1.7.m7.1c">
        a\in A
       </annotation>
      </semantics>
     </math>
     is a tuple
     <math alttext="(c_{a},\textit{pre}(a),\textit{eff}^{\pm}(a))" class="ltx_Math" display="inline" id="Sx2.SSx2.p1.8.m8.5">
      <semantics id="Sx2.SSx2.p1.8.m8.5a">
       <mrow id="Sx2.SSx2.p1.8.m8.5.5.3" xref="Sx2.SSx2.p1.8.m8.5.5.4.cmml">
        <mo id="Sx2.SSx2.p1.8.m8.5.5.3.4" stretchy="false" xref="Sx2.SSx2.p1.8.m8.5.5.4.cmml">
         (
        </mo>
        <msub id="Sx2.SSx2.p1.8.m8.3.3.1.1" xref="Sx2.SSx2.p1.8.m8.3.3.1.1.cmml">
         <mi id="Sx2.SSx2.p1.8.m8.3.3.1.1.2" xref="Sx2.SSx2.p1.8.m8.3.3.1.1.2.cmml">
          c
         </mi>
         <mi id="Sx2.SSx2.p1.8.m8.3.3.1.1.3" xref="Sx2.SSx2.p1.8.m8.3.3.1.1.3.cmml">
          a
         </mi>
        </msub>
        <mo id="Sx2.SSx2.p1.8.m8.5.5.3.5" xref="Sx2.SSx2.p1.8.m8.5.5.4.cmml">
         ,
        </mo>
        <mrow id="Sx2.SSx2.p1.8.m8.4.4.2.2" xref="Sx2.SSx2.p1.8.m8.4.4.2.2.cmml">
         <mtext class="ltx_mathvariant_italic" id="Sx2.SSx2.p1.8.m8.4.4.2.2.2" xref="Sx2.SSx2.p1.8.m8.4.4.2.2.2a.cmml">
          pre
         </mtext>
         <mo id="Sx2.SSx2.p1.8.m8.4.4.2.2.1" lspace="0em" rspace="0em" xref="Sx2.SSx2.p1.8.m8.4.4.2.2.1.cmml">
          ​
         </mo>
         <mrow id="Sx2.SSx2.p1.8.m8.4.4.2.2.3.2" xref="Sx2.SSx2.p1.8.m8.4.4.2.2.cmml">
          <mo id="Sx2.SSx2.p1.8.m8.4.4.2.2.3.2.1" stretchy="false" xref="Sx2.SSx2.p1.8.m8.4.4.2.2.cmml">
           (
          </mo>
          <mi id="Sx2.SSx2.p1.8.m8.1.1" xref="Sx2.SSx2.p1.8.m8.1.1.cmml">
           a
          </mi>
          <mo id="Sx2.SSx2.p1.8.m8.4.4.2.2.3.2.2" stretchy="false" xref="Sx2.SSx2.p1.8.m8.4.4.2.2.cmml">
           )
          </mo>
         </mrow>
        </mrow>
        <mo id="Sx2.SSx2.p1.8.m8.5.5.3.6" xref="Sx2.SSx2.p1.8.m8.5.5.4.cmml">
         ,
        </mo>
        <mrow id="Sx2.SSx2.p1.8.m8.5.5.3.3" xref="Sx2.SSx2.p1.8.m8.5.5.3.3.cmml">
         <msup id="Sx2.SSx2.p1.8.m8.5.5.3.3.2" xref="Sx2.SSx2.p1.8.m8.5.5.3.3.2.cmml">
          <mtext class="ltx_mathvariant_italic" id="Sx2.SSx2.p1.8.m8.5.5.3.3.2.2" xref="Sx2.SSx2.p1.8.m8.5.5.3.3.2.2a.cmml">
           eff
          </mtext>
          <mo id="Sx2.SSx2.p1.8.m8.5.5.3.3.2.3" xref="Sx2.SSx2.p1.8.m8.5.5.3.3.2.3.cmml">
           ±
          </mo>
         </msup>
         <mo id="Sx2.SSx2.p1.8.m8.5.5.3.3.1" lspace="0em" rspace="0em" xref="Sx2.SSx2.p1.8.m8.5.5.3.3.1.cmml">
          ​
         </mo>
         <mrow id="Sx2.SSx2.p1.8.m8.5.5.3.3.3.2" xref="Sx2.SSx2.p1.8.m8.5.5.3.3.cmml">
          <mo id="Sx2.SSx2.p1.8.m8.5.5.3.3.3.2.1" stretchy="false" xref="Sx2.SSx2.p1.8.m8.5.5.3.3.cmml">
           (
          </mo>
          <mi id="Sx2.SSx2.p1.8.m8.2.2" xref="Sx2.SSx2.p1.8.m8.2.2.cmml">
           a
          </mi>
          <mo id="Sx2.SSx2.p1.8.m8.5.5.3.3.3.2.2" stretchy="false" xref="Sx2.SSx2.p1.8.m8.5.5.3.3.cmml">
           )
          </mo>
         </mrow>
        </mrow>
        <mo id="Sx2.SSx2.p1.8.m8.5.5.3.7" stretchy="false" xref="Sx2.SSx2.p1.8.m8.5.5.4.cmml">
         )
        </mo>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="Sx2.SSx2.p1.8.m8.5b">
        <vector id="Sx2.SSx2.p1.8.m8.5.5.4.cmml" xref="Sx2.SSx2.p1.8.m8.5.5.3">
         <apply id="Sx2.SSx2.p1.8.m8.3.3.1.1.cmml" xref="Sx2.SSx2.p1.8.m8.3.3.1.1">
          <csymbol cd="ambiguous" id="Sx2.SSx2.p1.8.m8.3.3.1.1.1.cmml" xref="Sx2.SSx2.p1.8.m8.3.3.1.1">
           subscript
          </csymbol>
          <ci id="Sx2.SSx2.p1.8.m8.3.3.1.1.2.cmml" xref="Sx2.SSx2.p1.8.m8.3.3.1.1.2">
           𝑐
          </ci>
          <ci id="Sx2.SSx2.p1.8.m8.3.3.1.1.3.cmml" xref="Sx2.SSx2.p1.8.m8.3.3.1.1.3">
           𝑎
          </ci>
         </apply>
         <apply id="Sx2.SSx2.p1.8.m8.4.4.2.2.cmml" xref="Sx2.SSx2.p1.8.m8.4.4.2.2">
          <times id="Sx2.SSx2.p1.8.m8.4.4.2.2.1.cmml" xref="Sx2.SSx2.p1.8.m8.4.4.2.2.1">
          </times>
          <ci id="Sx2.SSx2.p1.8.m8.4.4.2.2.2a.cmml" xref="Sx2.SSx2.p1.8.m8.4.4.2.2.2">
           <mtext class="ltx_mathvariant_italic" id="Sx2.SSx2.p1.8.m8.4.4.2.2.2.cmml" xref="Sx2.SSx2.p1.8.m8.4.4.2.2.2">
            pre
           </mtext>
          </ci>
          <ci id="Sx2.SSx2.p1.8.m8.1.1.cmml" xref="Sx2.SSx2.p1.8.m8.1.1">
           𝑎
          </ci>
         </apply>
         <apply id="Sx2.SSx2.p1.8.m8.5.5.3.3.cmml" xref="Sx2.SSx2.p1.8.m8.5.5.3.3">
          <times id="Sx2.SSx2.p1.8.m8.5.5.3.3.1.cmml" xref="Sx2.SSx2.p1.8.m8.5.5.3.3.1">
          </times>
          <apply id="Sx2.SSx2.p1.8.m8.5.5.3.3.2.cmml" xref="Sx2.SSx2.p1.8.m8.5.5.3.3.2">
           <csymbol cd="ambiguous" id="Sx2.SSx2.p1.8.m8.5.5.3.3.2.1.cmml" xref="Sx2.SSx2.p1.8.m8.5.5.3.3.2">
            superscript
           </csymbol>
           <ci id="Sx2.SSx2.p1.8.m8.5.5.3.3.2.2a.cmml" xref="Sx2.SSx2.p1.8.m8.5.5.3.3.2.2">
            <mtext class="ltx_mathvariant_italic" id="Sx2.SSx2.p1.8.m8.5.5.3.3.2.2.cmml" xref="Sx2.SSx2.p1.8.m8.5.5.3.3.2.2">
             eff
            </mtext>
           </ci>
           <csymbol cd="latexml" id="Sx2.SSx2.p1.8.m8.5.5.3.3.2.3.cmml" xref="Sx2.SSx2.p1.8.m8.5.5.3.3.2.3">
            plus-or-minus
           </csymbol>
          </apply>
          <ci id="Sx2.SSx2.p1.8.m8.2.2.cmml" xref="Sx2.SSx2.p1.8.m8.2.2">
           𝑎
          </ci>
         </apply>
        </vector>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="Sx2.SSx2.p1.8.m8.5c">
        (c_{a},\textit{pre}(a),\textit{eff}^{\pm}(a))
       </annotation>
      </semantics>
     </math>
     where
     <math alttext="c_{a}" class="ltx_Math" display="inline" id="Sx2.SSx2.p1.9.m9.1">
      <semantics id="Sx2.SSx2.p1.9.m9.1a">
       <msub id="Sx2.SSx2.p1.9.m9.1.1" xref="Sx2.SSx2.p1.9.m9.1.1.cmml">
        <mi id="Sx2.SSx2.p1.9.m9.1.1.2" xref="Sx2.SSx2.p1.9.m9.1.1.2.cmml">
         c
        </mi>
        <mi id="Sx2.SSx2.p1.9.m9.1.1.3" xref="Sx2.SSx2.p1.9.m9.1.1.3.cmml">
         a
        </mi>
       </msub>
       <annotation-xml encoding="MathML-Content" id="Sx2.SSx2.p1.9.m9.1b">
        <apply id="Sx2.SSx2.p1.9.m9.1.1.cmml" xref="Sx2.SSx2.p1.9.m9.1.1">
         <csymbol cd="ambiguous" id="Sx2.SSx2.p1.9.m9.1.1.1.cmml" xref="Sx2.SSx2.p1.9.m9.1.1">
          subscript
         </csymbol>
         <ci id="Sx2.SSx2.p1.9.m9.1.1.2.cmml" xref="Sx2.SSx2.p1.9.m9.1.1.2">
          𝑐
         </ci>
         <ci id="Sx2.SSx2.p1.9.m9.1.1.3.cmml" xref="Sx2.SSx2.p1.9.m9.1.1.3">
          𝑎
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="Sx2.SSx2.p1.9.m9.1c">
        c_{a}
       </annotation>
      </semantics>
     </math>
     is the cost, and
     <math alttext="\textit{pre}(a),\textit{eff}^{\pm}(a)\subseteq F" class="ltx_Math" display="inline" id="Sx2.SSx2.p1.10.m10.4">
      <semantics id="Sx2.SSx2.p1.10.m10.4a">
       <mrow id="Sx2.SSx2.p1.10.m10.4.4" xref="Sx2.SSx2.p1.10.m10.4.4.cmml">
        <mrow id="Sx2.SSx2.p1.10.m10.4.4.2.2" xref="Sx2.SSx2.p1.10.m10.4.4.2.3.cmml">
         <mrow id="Sx2.SSx2.p1.10.m10.3.3.1.1.1" xref="Sx2.SSx2.p1.10.m10.3.3.1.1.1.cmml">
          <mtext class="ltx_mathvariant_italic" id="Sx2.SSx2.p1.10.m10.3.3.1.1.1.2" xref="Sx2.SSx2.p1.10.m10.3.3.1.1.1.2a.cmml">
           pre
          </mtext>
          <mo id="Sx2.SSx2.p1.10.m10.3.3.1.1.1.1" lspace="0em" rspace="0em" xref="Sx2.SSx2.p1.10.m10.3.3.1.1.1.1.cmml">
           ​
          </mo>
          <mrow id="Sx2.SSx2.p1.10.m10.3.3.1.1.1.3.2" xref="Sx2.SSx2.p1.10.m10.3.3.1.1.1.cmml">
           <mo id="Sx2.SSx2.p1.10.m10.3.3.1.1.1.3.2.1" stretchy="false" xref="Sx2.SSx2.p1.10.m10.3.3.1.1.1.cmml">
            (
           </mo>
           <mi id="Sx2.SSx2.p1.10.m10.1.1" xref="Sx2.SSx2.p1.10.m10.1.1.cmml">
            a
           </mi>
           <mo id="Sx2.SSx2.p1.10.m10.3.3.1.1.1.3.2.2" stretchy="false" xref="Sx2.SSx2.p1.10.m10.3.3.1.1.1.cmml">
            )
           </mo>
          </mrow>
         </mrow>
         <mo id="Sx2.SSx2.p1.10.m10.4.4.2.2.3" xref="Sx2.SSx2.p1.10.m10.4.4.2.3.cmml">
          ,
         </mo>
         <mrow id="Sx2.SSx2.p1.10.m10.4.4.2.2.2" xref="Sx2.SSx2.p1.10.m10.4.4.2.2.2.cmml">
          <msup id="Sx2.SSx2.p1.10.m10.4.4.2.2.2.2" xref="Sx2.SSx2.p1.10.m10.4.4.2.2.2.2.cmml">
           <mtext class="ltx_mathvariant_italic" id="Sx2.SSx2.p1.10.m10.4.4.2.2.2.2.2" xref="Sx2.SSx2.p1.10.m10.4.4.2.2.2.2.2a.cmml">
            eff
           </mtext>
           <mo id="Sx2.SSx2.p1.10.m10.4.4.2.2.2.2.3" xref="Sx2.SSx2.p1.10.m10.4.4.2.2.2.2.3.cmml">
            ±
           </mo>
          </msup>
          <mo id="Sx2.SSx2.p1.10.m10.4.4.2.2.2.1" lspace="0em" rspace="0em" xref="Sx2.SSx2.p1.10.m10.4.4.2.2.2.1.cmml">
           ​
          </mo>
          <mrow id="Sx2.SSx2.p1.10.m10.4.4.2.2.2.3.2" xref="Sx2.SSx2.p1.10.m10.4.4.2.2.2.cmml">
           <mo id="Sx2.SSx2.p1.10.m10.4.4.2.2.2.3.2.1" stretchy="false" xref="Sx2.SSx2.p1.10.m10.4.4.2.2.2.cmml">
            (
           </mo>
           <mi id="Sx2.SSx2.p1.10.m10.2.2" xref="Sx2.SSx2.p1.10.m10.2.2.cmml">
            a
           </mi>
           <mo id="Sx2.SSx2.p1.10.m10.4.4.2.2.2.3.2.2" stretchy="false" xref="Sx2.SSx2.p1.10.m10.4.4.2.2.2.cmml">
            )
           </mo>
          </mrow>
         </mrow>
        </mrow>
        <mo id="Sx2.SSx2.p1.10.m10.4.4.3" xref="Sx2.SSx2.p1.10.m10.4.4.3.cmml">
         ⊆
        </mo>
        <mi id="Sx2.SSx2.p1.10.m10.4.4.4" xref="Sx2.SSx2.p1.10.m10.4.4.4.cmml">
         F
        </mi>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="Sx2.SSx2.p1.10.m10.4b">
        <apply id="Sx2.SSx2.p1.10.m10.4.4.cmml" xref="Sx2.SSx2.p1.10.m10.4.4">
         <subset id="Sx2.SSx2.p1.10.m10.4.4.3.cmml" xref="Sx2.SSx2.p1.10.m10.4.4.3">
         </subset>
         <list id="Sx2.SSx2.p1.10.m10.4.4.2.3.cmml" xref="Sx2.SSx2.p1.10.m10.4.4.2.2">
          <apply id="Sx2.SSx2.p1.10.m10.3.3.1.1.1.cmml" xref="Sx2.SSx2.p1.10.m10.3.3.1.1.1">
           <times id="Sx2.SSx2.p1.10.m10.3.3.1.1.1.1.cmml" xref="Sx2.SSx2.p1.10.m10.3.3.1.1.1.1">
           </times>
           <ci id="Sx2.SSx2.p1.10.m10.3.3.1.1.1.2a.cmml" xref="Sx2.SSx2.p1.10.m10.3.3.1.1.1.2">
            <mtext class="ltx_mathvariant_italic" id="Sx2.SSx2.p1.10.m10.3.3.1.1.1.2.cmml" xref="Sx2.SSx2.p1.10.m10.3.3.1.1.1.2">
             pre
            </mtext>
           </ci>
           <ci id="Sx2.SSx2.p1.10.m10.1.1.cmml" xref="Sx2.SSx2.p1.10.m10.1.1">
            𝑎
           </ci>
          </apply>
          <apply id="Sx2.SSx2.p1.10.m10.4.4.2.2.2.cmml" xref="Sx2.SSx2.p1.10.m10.4.4.2.2.2">
           <times id="Sx2.SSx2.p1.10.m10.4.4.2.2.2.1.cmml" xref="Sx2.SSx2.p1.10.m10.4.4.2.2.2.1">
           </times>
           <apply id="Sx2.SSx2.p1.10.m10.4.4.2.2.2.2.cmml" xref="Sx2.SSx2.p1.10.m10.4.4.2.2.2.2">
            <csymbol cd="ambiguous" id="Sx2.SSx2.p1.10.m10.4.4.2.2.2.2.1.cmml" xref="Sx2.SSx2.p1.10.m10.4.4.2.2.2.2">
             superscript
            </csymbol>
            <ci id="Sx2.SSx2.p1.10.m10.4.4.2.2.2.2.2a.cmml" xref="Sx2.SSx2.p1.10.m10.4.4.2.2.2.2.2">
             <mtext class="ltx_mathvariant_italic" id="Sx2.SSx2.p1.10.m10.4.4.2.2.2.2.2.cmml" xref="Sx2.SSx2.p1.10.m10.4.4.2.2.2.2.2">
              eff
             </mtext>
            </ci>
            <csymbol cd="latexml" id="Sx2.SSx2.p1.10.m10.4.4.2.2.2.2.3.cmml" xref="Sx2.SSx2.p1.10.m10.4.4.2.2.2.2.3">
             plus-or-minus
            </csymbol>
           </apply>
           <ci id="Sx2.SSx2.p1.10.m10.2.2.cmml" xref="Sx2.SSx2.p1.10.m10.2.2">
            𝑎
           </ci>
          </apply>
         </list>
         <ci id="Sx2.SSx2.p1.10.m10.4.4.4.cmml" xref="Sx2.SSx2.p1.10.m10.4.4.4">
          𝐹
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="Sx2.SSx2.p1.10.m10.4c">
        \textit{pre}(a),\textit{eff}^{\pm}(a)\subseteq F
       </annotation>
      </semantics>
     </math>
     are the preconditions and add/delete effects, i.e.,
     <math alttext="\delta_{\mathcal{M}}(s,a)\models\bot s" class="ltx_Math" display="inline" id="Sx2.SSx2.p1.11.m11.2">
      <semantics id="Sx2.SSx2.p1.11.m11.2a">
       <mrow id="Sx2.SSx2.p1.11.m11.2.3" xref="Sx2.SSx2.p1.11.m11.2.3.cmml">
        <mrow id="Sx2.SSx2.p1.11.m11.2.3.2" xref="Sx2.SSx2.p1.11.m11.2.3.2.cmml">
         <msub id="Sx2.SSx2.p1.11.m11.2.3.2.2" xref="Sx2.SSx2.p1.11.m11.2.3.2.2.cmml">
          <mi id="Sx2.SSx2.p1.11.m11.2.3.2.2.2" xref="Sx2.SSx2.p1.11.m11.2.3.2.2.2.cmml">
           δ
          </mi>
          <mi class="ltx_font_mathcaligraphic" id="Sx2.SSx2.p1.11.m11.2.3.2.2.3" xref="Sx2.SSx2.p1.11.m11.2.3.2.2.3.cmml">
           ℳ
          </mi>
         </msub>
         <mo id="Sx2.SSx2.p1.11.m11.2.3.2.1" lspace="0em" rspace="0em" xref="Sx2.SSx2.p1.11.m11.2.3.2.1.cmml">
          ​
         </mo>
         <mrow id="Sx2.SSx2.p1.11.m11.2.3.2.3.2" xref="Sx2.SSx2.p1.11.m11.2.3.2.3.1.cmml">
          <mo id="Sx2.SSx2.p1.11.m11.2.3.2.3.2.1" stretchy="false" xref="Sx2.SSx2.p1.11.m11.2.3.2.3.1.cmml">
           (
          </mo>
          <mi id="Sx2.SSx2.p1.11.m11.1.1" xref="Sx2.SSx2.p1.11.m11.1.1.cmml">
           s
          </mi>
          <mo id="Sx2.SSx2.p1.11.m11.2.3.2.3.2.2" xref="Sx2.SSx2.p1.11.m11.2.3.2.3.1.cmml">
           ,
          </mo>
          <mi id="Sx2.SSx2.p1.11.m11.2.2" xref="Sx2.SSx2.p1.11.m11.2.2.cmml">
           a
          </mi>
          <mo id="Sx2.SSx2.p1.11.m11.2.3.2.3.2.3" stretchy="false" xref="Sx2.SSx2.p1.11.m11.2.3.2.3.1.cmml">
           )
          </mo>
         </mrow>
        </mrow>
        <mo id="Sx2.SSx2.p1.11.m11.2.3.1" rspace="0.1389em" xref="Sx2.SSx2.p1.11.m11.2.3.1.cmml">
         ⊧
        </mo>
        <mrow id="Sx2.SSx2.p1.11.m11.2.3.3" xref="Sx2.SSx2.p1.11.m11.2.3.3.cmml">
         <mo id="Sx2.SSx2.p1.11.m11.2.3.3a" lspace="0.1389em" rspace="0em" xref="Sx2.SSx2.p1.11.m11.2.3.3.cmml">
          ⊥
         </mo>
         <mi id="Sx2.SSx2.p1.11.m11.2.3.3.2" xref="Sx2.SSx2.p1.11.m11.2.3.3.2.cmml">
          s
         </mi>
        </mrow>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="Sx2.SSx2.p1.11.m11.2b">
        <apply id="Sx2.SSx2.p1.11.m11.2.3.cmml" xref="Sx2.SSx2.p1.11.m11.2.3">
         <csymbol cd="latexml" id="Sx2.SSx2.p1.11.m11.2.3.1.cmml" xref="Sx2.SSx2.p1.11.m11.2.3.1">
          models
         </csymbol>
         <apply id="Sx2.SSx2.p1.11.m11.2.3.2.cmml" xref="Sx2.SSx2.p1.11.m11.2.3.2">
          <times id="Sx2.SSx2.p1.11.m11.2.3.2.1.cmml" xref="Sx2.SSx2.p1.11.m11.2.3.2.1">
          </times>
          <apply id="Sx2.SSx2.p1.11.m11.2.3.2.2.cmml" xref="Sx2.SSx2.p1.11.m11.2.3.2.2">
           <csymbol cd="ambiguous" id="Sx2.SSx2.p1.11.m11.2.3.2.2.1.cmml" xref="Sx2.SSx2.p1.11.m11.2.3.2.2">
            subscript
           </csymbol>
           <ci id="Sx2.SSx2.p1.11.m11.2.3.2.2.2.cmml" xref="Sx2.SSx2.p1.11.m11.2.3.2.2.2">
            𝛿
           </ci>
           <ci id="Sx2.SSx2.p1.11.m11.2.3.2.2.3.cmml" xref="Sx2.SSx2.p1.11.m11.2.3.2.2.3">
            ℳ
           </ci>
          </apply>
          <interval closure="open" id="Sx2.SSx2.p1.11.m11.2.3.2.3.1.cmml" xref="Sx2.SSx2.p1.11.m11.2.3.2.3.2">
           <ci id="Sx2.SSx2.p1.11.m11.1.1.cmml" xref="Sx2.SSx2.p1.11.m11.1.1">
            𝑠
           </ci>
           <ci id="Sx2.SSx2.p1.11.m11.2.2.cmml" xref="Sx2.SSx2.p1.11.m11.2.2">
            𝑎
           </ci>
          </interval>
         </apply>
         <apply id="Sx2.SSx2.p1.11.m11.2.3.3.cmml" xref="Sx2.SSx2.p1.11.m11.2.3.3">
          <csymbol cd="latexml" id="Sx2.SSx2.p1.11.m11.2.3.3.1.cmml" xref="Sx2.SSx2.p1.11.m11.2.3.3">
           bottom
          </csymbol>
          <ci id="Sx2.SSx2.p1.11.m11.2.3.3.2.cmml" xref="Sx2.SSx2.p1.11.m11.2.3.3.2">
           𝑠
          </ci>
         </apply>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="Sx2.SSx2.p1.11.m11.2c">
        \delta_{\mathcal{M}}(s,a)\models\bot s
       </annotation>
      </semantics>
     </math>
     <span class="ltx_text ltx_font_italic" id="Sx2.SSx2.p1.19.1">
      if
     </span>
     <math alttext="s\not\models\textit{pre}(a);" class="ltx_Math" display="inline" id="Sx2.SSx2.p1.12.m12.2">
      <semantics id="Sx2.SSx2.p1.12.m12.2a">
       <mrow id="Sx2.SSx2.p1.12.m12.2.2.1" xref="Sx2.SSx2.p1.12.m12.2.2.1.1.cmml">
        <mrow id="Sx2.SSx2.p1.12.m12.2.2.1.1" xref="Sx2.SSx2.p1.12.m12.2.2.1.1.cmml">
         <mi id="Sx2.SSx2.p1.12.m12.2.2.1.1.2" xref="Sx2.SSx2.p1.12.m12.2.2.1.1.2.cmml">
          s
         </mi>
         <mo id="Sx2.SSx2.p1.12.m12.2.2.1.1.1" xref="Sx2.SSx2.p1.12.m12.2.2.1.1.1.cmml">
          ⊧̸
         </mo>
         <mrow id="Sx2.SSx2.p1.12.m12.2.2.1.1.3" xref="Sx2.SSx2.p1.12.m12.2.2.1.1.3.cmml">
          <mtext class="ltx_mathvariant_italic" id="Sx2.SSx2.p1.12.m12.2.2.1.1.3.2" xref="Sx2.SSx2.p1.12.m12.2.2.1.1.3.2a.cmml">
           pre
          </mtext>
          <mo id="Sx2.SSx2.p1.12.m12.2.2.1.1.3.1" lspace="0em" rspace="0em" xref="Sx2.SSx2.p1.12.m12.2.2.1.1.3.1.cmml">
           ​
          </mo>
          <mrow id="Sx2.SSx2.p1.12.m12.2.2.1.1.3.3.2" xref="Sx2.SSx2.p1.12.m12.2.2.1.1.3.cmml">
           <mo id="Sx2.SSx2.p1.12.m12.2.2.1.1.3.3.2.1" stretchy="false" xref="Sx2.SSx2.p1.12.m12.2.2.1.1.3.cmml">
            (
           </mo>
           <mi id="Sx2.SSx2.p1.12.m12.1.1" xref="Sx2.SSx2.p1.12.m12.1.1.cmml">
            a
           </mi>
           <mo id="Sx2.SSx2.p1.12.m12.2.2.1.1.3.3.2.2" stretchy="false" xref="Sx2.SSx2.p1.12.m12.2.2.1.1.3.cmml">
            )
           </mo>
          </mrow>
         </mrow>
        </mrow>
        <mo id="Sx2.SSx2.p1.12.m12.2.2.1.2" xref="Sx2.SSx2.p1.12.m12.2.2.1.1.cmml">
         ;
        </mo>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="Sx2.SSx2.p1.12.m12.2b">
        <apply id="Sx2.SSx2.p1.12.m12.2.2.1.1.cmml" xref="Sx2.SSx2.p1.12.m12.2.2.1">
         <csymbol cd="latexml" id="Sx2.SSx2.p1.12.m12.2.2.1.1.1.cmml" xref="Sx2.SSx2.p1.12.m12.2.2.1.1.1">
          not-models
         </csymbol>
         <ci id="Sx2.SSx2.p1.12.m12.2.2.1.1.2.cmml" xref="Sx2.SSx2.p1.12.m12.2.2.1.1.2">
          𝑠
         </ci>
         <apply id="Sx2.SSx2.p1.12.m12.2.2.1.1.3.cmml" xref="Sx2.SSx2.p1.12.m12.2.2.1.1.3">
          <times id="Sx2.SSx2.p1.12.m12.2.2.1.1.3.1.cmml" xref="Sx2.SSx2.p1.12.m12.2.2.1.1.3.1">
          </times>
          <ci id="Sx2.SSx2.p1.12.m12.2.2.1.1.3.2a.cmml" xref="Sx2.SSx2.p1.12.m12.2.2.1.1.3.2">
           <mtext class="ltx_mathvariant_italic" id="Sx2.SSx2.p1.12.m12.2.2.1.1.3.2.cmml" xref="Sx2.SSx2.p1.12.m12.2.2.1.1.3.2">
            pre
           </mtext>
          </ci>
          <ci id="Sx2.SSx2.p1.12.m12.1.1.cmml" xref="Sx2.SSx2.p1.12.m12.1.1">
           𝑎
          </ci>
         </apply>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="Sx2.SSx2.p1.12.m12.2c">
        s\not\models\textit{pre}(a);
       </annotation>
      </semantics>
     </math>
     <span class="ltx_text ltx_font_italic" id="Sx2.SSx2.p1.19.2">
      else
     </span>
     <math alttext="\delta_{\mathcal{M}}(s,a)\models s\cup\text{eff}^{+}(a)\setminus\text{eff}^{-}(a)" class="ltx_Math" display="inline" id="Sx2.SSx2.p1.13.m13.4">
      <semantics id="Sx2.SSx2.p1.13.m13.4a">
       <mrow id="Sx2.SSx2.p1.13.m13.4.5" xref="Sx2.SSx2.p1.13.m13.4.5.cmml">
        <mrow id="Sx2.SSx2.p1.13.m13.4.5.2" xref="Sx2.SSx2.p1.13.m13.4.5.2.cmml">
         <msub id="Sx2.SSx2.p1.13.m13.4.5.2.2" xref="Sx2.SSx2.p1.13.m13.4.5.2.2.cmml">
          <mi id="Sx2.SSx2.p1.13.m13.4.5.2.2.2" xref="Sx2.SSx2.p1.13.m13.4.5.2.2.2.cmml">
           δ
          </mi>
          <mi class="ltx_font_mathcaligraphic" id="Sx2.SSx2.p1.13.m13.4.5.2.2.3" xref="Sx2.SSx2.p1.13.m13.4.5.2.2.3.cmml">
           ℳ
          </mi>
         </msub>
         <mo id="Sx2.SSx2.p1.13.m13.4.5.2.1" lspace="0em" rspace="0em" xref="Sx2.SSx2.p1.13.m13.4.5.2.1.cmml">
          ​
         </mo>
         <mrow id="Sx2.SSx2.p1.13.m13.4.5.2.3.2" xref="Sx2.SSx2.p1.13.m13.4.5.2.3.1.cmml">
          <mo id="Sx2.SSx2.p1.13.m13.4.5.2.3.2.1" stretchy="false" xref="Sx2.SSx2.p1.13.m13.4.5.2.3.1.cmml">
           (
          </mo>
          <mi id="Sx2.SSx2.p1.13.m13.1.1" xref="Sx2.SSx2.p1.13.m13.1.1.cmml">
           s
          </mi>
          <mo id="Sx2.SSx2.p1.13.m13.4.5.2.3.2.2" xref="Sx2.SSx2.p1.13.m13.4.5.2.3.1.cmml">
           ,
          </mo>
          <mi id="Sx2.SSx2.p1.13.m13.2.2" xref="Sx2.SSx2.p1.13.m13.2.2.cmml">
           a
          </mi>
          <mo id="Sx2.SSx2.p1.13.m13.4.5.2.3.2.3" stretchy="false" xref="Sx2.SSx2.p1.13.m13.4.5.2.3.1.cmml">
           )
          </mo>
         </mrow>
        </mrow>
        <mo id="Sx2.SSx2.p1.13.m13.4.5.1" xref="Sx2.SSx2.p1.13.m13.4.5.1.cmml">
         ⊧
        </mo>
        <mrow id="Sx2.SSx2.p1.13.m13.4.5.3" xref="Sx2.SSx2.p1.13.m13.4.5.3.cmml">
         <mrow id="Sx2.SSx2.p1.13.m13.4.5.3.2" xref="Sx2.SSx2.p1.13.m13.4.5.3.2.cmml">
          <mi id="Sx2.SSx2.p1.13.m13.4.5.3.2.2" xref="Sx2.SSx2.p1.13.m13.4.5.3.2.2.cmml">
           s
          </mi>
          <mo id="Sx2.SSx2.p1.13.m13.4.5.3.2.1" xref="Sx2.SSx2.p1.13.m13.4.5.3.2.1.cmml">
           ∪
          </mo>
          <mrow id="Sx2.SSx2.p1.13.m13.4.5.3.2.3" xref="Sx2.SSx2.p1.13.m13.4.5.3.2.3.cmml">
           <msup id="Sx2.SSx2.p1.13.m13.4.5.3.2.3.2" xref="Sx2.SSx2.p1.13.m13.4.5.3.2.3.2.cmml">
            <mtext id="Sx2.SSx2.p1.13.m13.4.5.3.2.3.2.2" xref="Sx2.SSx2.p1.13.m13.4.5.3.2.3.2.2a.cmml">
             eff
            </mtext>
            <mo id="Sx2.SSx2.p1.13.m13.4.5.3.2.3.2.3" xref="Sx2.SSx2.p1.13.m13.4.5.3.2.3.2.3.cmml">
             +
            </mo>
           </msup>
           <mo id="Sx2.SSx2.p1.13.m13.4.5.3.2.3.1" lspace="0em" rspace="0em" xref="Sx2.SSx2.p1.13.m13.4.5.3.2.3.1.cmml">
            ​
           </mo>
           <mrow id="Sx2.SSx2.p1.13.m13.4.5.3.2.3.3.2" xref="Sx2.SSx2.p1.13.m13.4.5.3.2.3.cmml">
            <mo id="Sx2.SSx2.p1.13.m13.4.5.3.2.3.3.2.1" stretchy="false" xref="Sx2.SSx2.p1.13.m13.4.5.3.2.3.cmml">
             (
            </mo>
            <mi id="Sx2.SSx2.p1.13.m13.3.3" xref="Sx2.SSx2.p1.13.m13.3.3.cmml">
             a
            </mi>
            <mo id="Sx2.SSx2.p1.13.m13.4.5.3.2.3.3.2.2" stretchy="false" xref="Sx2.SSx2.p1.13.m13.4.5.3.2.3.cmml">
             )
            </mo>
           </mrow>
          </mrow>
         </mrow>
         <mo id="Sx2.SSx2.p1.13.m13.4.5.3.1" xref="Sx2.SSx2.p1.13.m13.4.5.3.1.cmml">
          ∖
         </mo>
         <mrow id="Sx2.SSx2.p1.13.m13.4.5.3.3" xref="Sx2.SSx2.p1.13.m13.4.5.3.3.cmml">
          <msup id="Sx2.SSx2.p1.13.m13.4.5.3.3.2" xref="Sx2.SSx2.p1.13.m13.4.5.3.3.2.cmml">
           <mtext id="Sx2.SSx2.p1.13.m13.4.5.3.3.2.2" xref="Sx2.SSx2.p1.13.m13.4.5.3.3.2.2a.cmml">
            eff
           </mtext>
           <mo id="Sx2.SSx2.p1.13.m13.4.5.3.3.2.3" xref="Sx2.SSx2.p1.13.m13.4.5.3.3.2.3.cmml">
            −
           </mo>
          </msup>
          <mo id="Sx2.SSx2.p1.13.m13.4.5.3.3.1" lspace="0em" rspace="0em" xref="Sx2.SSx2.p1.13.m13.4.5.3.3.1.cmml">
           ​
          </mo>
          <mrow id="Sx2.SSx2.p1.13.m13.4.5.3.3.3.2" xref="Sx2.SSx2.p1.13.m13.4.5.3.3.cmml">
           <mo id="Sx2.SSx2.p1.13.m13.4.5.3.3.3.2.1" stretchy="false" xref="Sx2.SSx2.p1.13.m13.4.5.3.3.cmml">
            (
           </mo>
           <mi id="Sx2.SSx2.p1.13.m13.4.4" xref="Sx2.SSx2.p1.13.m13.4.4.cmml">
            a
           </mi>
           <mo id="Sx2.SSx2.p1.13.m13.4.5.3.3.3.2.2" stretchy="false" xref="Sx2.SSx2.p1.13.m13.4.5.3.3.cmml">
            )
           </mo>
          </mrow>
         </mrow>
        </mrow>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="Sx2.SSx2.p1.13.m13.4b">
        <apply id="Sx2.SSx2.p1.13.m13.4.5.cmml" xref="Sx2.SSx2.p1.13.m13.4.5">
         <csymbol cd="latexml" id="Sx2.SSx2.p1.13.m13.4.5.1.cmml" xref="Sx2.SSx2.p1.13.m13.4.5.1">
          models
         </csymbol>
         <apply id="Sx2.SSx2.p1.13.m13.4.5.2.cmml" xref="Sx2.SSx2.p1.13.m13.4.5.2">
          <times id="Sx2.SSx2.p1.13.m13.4.5.2.1.cmml" xref="Sx2.SSx2.p1.13.m13.4.5.2.1">
          </times>
          <apply id="Sx2.SSx2.p1.13.m13.4.5.2.2.cmml" xref="Sx2.SSx2.p1.13.m13.4.5.2.2">
           <csymbol cd="ambiguous" id="Sx2.SSx2.p1.13.m13.4.5.2.2.1.cmml" xref="Sx2.SSx2.p1.13.m13.4.5.2.2">
            subscript
           </csymbol>
           <ci id="Sx2.SSx2.p1.13.m13.4.5.2.2.2.cmml" xref="Sx2.SSx2.p1.13.m13.4.5.2.2.2">
            𝛿
           </ci>
           <ci id="Sx2.SSx2.p1.13.m13.4.5.2.2.3.cmml" xref="Sx2.SSx2.p1.13.m13.4.5.2.2.3">
            ℳ
           </ci>
          </apply>
          <interval closure="open" id="Sx2.SSx2.p1.13.m13.4.5.2.3.1.cmml" xref="Sx2.SSx2.p1.13.m13.4.5.2.3.2">
           <ci id="Sx2.SSx2.p1.13.m13.1.1.cmml" xref="Sx2.SSx2.p1.13.m13.1.1">
            𝑠
           </ci>
           <ci id="Sx2.SSx2.p1.13.m13.2.2.cmml" xref="Sx2.SSx2.p1.13.m13.2.2">
            𝑎
           </ci>
          </interval>
         </apply>
         <apply id="Sx2.SSx2.p1.13.m13.4.5.3.cmml" xref="Sx2.SSx2.p1.13.m13.4.5.3">
          <setdiff id="Sx2.SSx2.p1.13.m13.4.5.3.1.cmml" xref="Sx2.SSx2.p1.13.m13.4.5.3.1">
          </setdiff>
          <apply id="Sx2.SSx2.p1.13.m13.4.5.3.2.cmml" xref="Sx2.SSx2.p1.13.m13.4.5.3.2">
           <union id="Sx2.SSx2.p1.13.m13.4.5.3.2.1.cmml" xref="Sx2.SSx2.p1.13.m13.4.5.3.2.1">
           </union>
           <ci id="Sx2.SSx2.p1.13.m13.4.5.3.2.2.cmml" xref="Sx2.SSx2.p1.13.m13.4.5.3.2.2">
            𝑠
           </ci>
           <apply id="Sx2.SSx2.p1.13.m13.4.5.3.2.3.cmml" xref="Sx2.SSx2.p1.13.m13.4.5.3.2.3">
            <times id="Sx2.SSx2.p1.13.m13.4.5.3.2.3.1.cmml" xref="Sx2.SSx2.p1.13.m13.4.5.3.2.3.1">
            </times>
            <apply id="Sx2.SSx2.p1.13.m13.4.5.3.2.3.2.cmml" xref="Sx2.SSx2.p1.13.m13.4.5.3.2.3.2">
             <csymbol cd="ambiguous" id="Sx2.SSx2.p1.13.m13.4.5.3.2.3.2.1.cmml" xref="Sx2.SSx2.p1.13.m13.4.5.3.2.3.2">
              superscript
             </csymbol>
             <ci id="Sx2.SSx2.p1.13.m13.4.5.3.2.3.2.2a.cmml" xref="Sx2.SSx2.p1.13.m13.4.5.3.2.3.2.2">
              <mtext id="Sx2.SSx2.p1.13.m13.4.5.3.2.3.2.2.cmml" xref="Sx2.SSx2.p1.13.m13.4.5.3.2.3.2.2">
               eff
              </mtext>
             </ci>
             <plus id="Sx2.SSx2.p1.13.m13.4.5.3.2.3.2.3.cmml" xref="Sx2.SSx2.p1.13.m13.4.5.3.2.3.2.3">
             </plus>
            </apply>
            <ci id="Sx2.SSx2.p1.13.m13.3.3.cmml" xref="Sx2.SSx2.p1.13.m13.3.3">
             𝑎
            </ci>
           </apply>
          </apply>
          <apply id="Sx2.SSx2.p1.13.m13.4.5.3.3.cmml" xref="Sx2.SSx2.p1.13.m13.4.5.3.3">
           <times id="Sx2.SSx2.p1.13.m13.4.5.3.3.1.cmml" xref="Sx2.SSx2.p1.13.m13.4.5.3.3.1">
           </times>
           <apply id="Sx2.SSx2.p1.13.m13.4.5.3.3.2.cmml" xref="Sx2.SSx2.p1.13.m13.4.5.3.3.2">
            <csymbol cd="ambiguous" id="Sx2.SSx2.p1.13.m13.4.5.3.3.2.1.cmml" xref="Sx2.SSx2.p1.13.m13.4.5.3.3.2">
             superscript
            </csymbol>
            <ci id="Sx2.SSx2.p1.13.m13.4.5.3.3.2.2a.cmml" xref="Sx2.SSx2.p1.13.m13.4.5.3.3.2.2">
             <mtext id="Sx2.SSx2.p1.13.m13.4.5.3.3.2.2.cmml" xref="Sx2.SSx2.p1.13.m13.4.5.3.3.2.2">
              eff
             </mtext>
            </ci>
            <minus id="Sx2.SSx2.p1.13.m13.4.5.3.3.2.3.cmml" xref="Sx2.SSx2.p1.13.m13.4.5.3.3.2.3">
            </minus>
           </apply>
           <ci id="Sx2.SSx2.p1.13.m13.4.4.cmml" xref="Sx2.SSx2.p1.13.m13.4.4">
            𝑎
           </ci>
          </apply>
         </apply>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="Sx2.SSx2.p1.13.m13.4c">
        \delta_{\mathcal{M}}(s,a)\models s\cup\text{eff}^{+}(a)\setminus\text{eff}^{-}(a)
       </annotation>
      </semantics>
     </math>
     where
     <math alttext="\delta_{\mathcal{M}}(\cdot)" class="ltx_Math" display="inline" id="Sx2.SSx2.p1.14.m14.1">
      <semantics id="Sx2.SSx2.p1.14.m14.1a">
       <mrow id="Sx2.SSx2.p1.14.m14.1.2" xref="Sx2.SSx2.p1.14.m14.1.2.cmml">
        <msub id="Sx2.SSx2.p1.14.m14.1.2.2" xref="Sx2.SSx2.p1.14.m14.1.2.2.cmml">
         <mi id="Sx2.SSx2.p1.14.m14.1.2.2.2" xref="Sx2.SSx2.p1.14.m14.1.2.2.2.cmml">
          δ
         </mi>
         <mi class="ltx_font_mathcaligraphic" id="Sx2.SSx2.p1.14.m14.1.2.2.3" xref="Sx2.SSx2.p1.14.m14.1.2.2.3.cmml">
          ℳ
         </mi>
        </msub>
        <mo id="Sx2.SSx2.p1.14.m14.1.2.1" lspace="0em" rspace="0em" xref="Sx2.SSx2.p1.14.m14.1.2.1.cmml">
         ​
        </mo>
        <mrow id="Sx2.SSx2.p1.14.m14.1.2.3.2" xref="Sx2.SSx2.p1.14.m14.1.2.cmml">
         <mo id="Sx2.SSx2.p1.14.m14.1.2.3.2.1" stretchy="false" xref="Sx2.SSx2.p1.14.m14.1.2.cmml">
          (
         </mo>
         <mo id="Sx2.SSx2.p1.14.m14.1.1" lspace="0em" rspace="0em" xref="Sx2.SSx2.p1.14.m14.1.1.cmml">
          ⋅
         </mo>
         <mo id="Sx2.SSx2.p1.14.m14.1.2.3.2.2" stretchy="false" xref="Sx2.SSx2.p1.14.m14.1.2.cmml">
          )
         </mo>
        </mrow>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="Sx2.SSx2.p1.14.m14.1b">
        <apply id="Sx2.SSx2.p1.14.m14.1.2.cmml" xref="Sx2.SSx2.p1.14.m14.1.2">
         <times id="Sx2.SSx2.p1.14.m14.1.2.1.cmml" xref="Sx2.SSx2.p1.14.m14.1.2.1">
         </times>
         <apply id="Sx2.SSx2.p1.14.m14.1.2.2.cmml" xref="Sx2.SSx2.p1.14.m14.1.2.2">
          <csymbol cd="ambiguous" id="Sx2.SSx2.p1.14.m14.1.2.2.1.cmml" xref="Sx2.SSx2.p1.14.m14.1.2.2">
           subscript
          </csymbol>
          <ci id="Sx2.SSx2.p1.14.m14.1.2.2.2.cmml" xref="Sx2.SSx2.p1.14.m14.1.2.2.2">
           𝛿
          </ci>
          <ci id="Sx2.SSx2.p1.14.m14.1.2.2.3.cmml" xref="Sx2.SSx2.p1.14.m14.1.2.2.3">
           ℳ
          </ci>
         </apply>
         <ci id="Sx2.SSx2.p1.14.m14.1.1.cmml" xref="Sx2.SSx2.p1.14.m14.1.1">
          ⋅
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="Sx2.SSx2.p1.14.m14.1c">
        \delta_{\mathcal{M}}(\cdot)
       </annotation>
      </semantics>
     </math>
     is the transition function. The cumulative transition function is
     <math alttext="\delta_{\mathcal{M}}(s,(a_{1},a_{2},\ldots,a_{n}))=\delta_{\mathcal{M}}(\delta_{\mathcal{M}}(s,a_{1}),(a_{2},\ldots,a_{n}))" class="ltx_Math" display="inline" id="Sx2.SSx2.p1.15.m15.7">
      <semantics id="Sx2.SSx2.p1.15.m15.7a">
       <mrow id="Sx2.SSx2.p1.15.m15.7.7" xref="Sx2.SSx2.p1.15.m15.7.7.cmml">
        <mrow id="Sx2.SSx2.p1.15.m15.5.5.1" xref="Sx2.SSx2.p1.15.m15.5.5.1.cmml">
         <msub id="Sx2.SSx2.p1.15.m15.5.5.1.3" xref="Sx2.SSx2.p1.15.m15.5.5.1.3.cmml">
          <mi id="Sx2.SSx2.p1.15.m15.5.5.1.3.2" xref="Sx2.SSx2.p1.15.m15.5.5.1.3.2.cmml">
           δ
          </mi>
          <mi class="ltx_font_mathcaligraphic" id="Sx2.SSx2.p1.15.m15.5.5.1.3.3" xref="Sx2.SSx2.p1.15.m15.5.5.1.3.3.cmml">
           ℳ
          </mi>
         </msub>
         <mo id="Sx2.SSx2.p1.15.m15.5.5.1.2" lspace="0em" rspace="0em" xref="Sx2.SSx2.p1.15.m15.5.5.1.2.cmml">
          ​
         </mo>
         <mrow id="Sx2.SSx2.p1.15.m15.5.5.1.1.1" xref="Sx2.SSx2.p1.15.m15.5.5.1.1.2.cmml">
          <mo id="Sx2.SSx2.p1.15.m15.5.5.1.1.1.2" stretchy="false" xref="Sx2.SSx2.p1.15.m15.5.5.1.1.2.cmml">
           (
          </mo>
          <mi id="Sx2.SSx2.p1.15.m15.2.2" xref="Sx2.SSx2.p1.15.m15.2.2.cmml">
           s
          </mi>
          <mo id="Sx2.SSx2.p1.15.m15.5.5.1.1.1.3" xref="Sx2.SSx2.p1.15.m15.5.5.1.1.2.cmml">
           ,
          </mo>
          <mrow id="Sx2.SSx2.p1.15.m15.5.5.1.1.1.1.3" xref="Sx2.SSx2.p1.15.m15.5.5.1.1.1.1.4.cmml">
           <mo id="Sx2.SSx2.p1.15.m15.5.5.1.1.1.1.3.4" stretchy="false" xref="Sx2.SSx2.p1.15.m15.5.5.1.1.1.1.4.cmml">
            (
           </mo>
           <msub id="Sx2.SSx2.p1.15.m15.5.5.1.1.1.1.1.1" xref="Sx2.SSx2.p1.15.m15.5.5.1.1.1.1.1.1.cmml">
            <mi id="Sx2.SSx2.p1.15.m15.5.5.1.1.1.1.1.1.2" xref="Sx2.SSx2.p1.15.m15.5.5.1.1.1.1.1.1.2.cmml">
             a
            </mi>
            <mn id="Sx2.SSx2.p1.15.m15.5.5.1.1.1.1.1.1.3" xref="Sx2.SSx2.p1.15.m15.5.5.1.1.1.1.1.1.3.cmml">
             1
            </mn>
           </msub>
           <mo id="Sx2.SSx2.p1.15.m15.5.5.1.1.1.1.3.5" xref="Sx2.SSx2.p1.15.m15.5.5.1.1.1.1.4.cmml">
            ,
           </mo>
           <msub id="Sx2.SSx2.p1.15.m15.5.5.1.1.1.1.2.2" xref="Sx2.SSx2.p1.15.m15.5.5.1.1.1.1.2.2.cmml">
            <mi id="Sx2.SSx2.p1.15.m15.5.5.1.1.1.1.2.2.2" xref="Sx2.SSx2.p1.15.m15.5.5.1.1.1.1.2.2.2.cmml">
             a
            </mi>
            <mn id="Sx2.SSx2.p1.15.m15.5.5.1.1.1.1.2.2.3" xref="Sx2.SSx2.p1.15.m15.5.5.1.1.1.1.2.2.3.cmml">
             2
            </mn>
           </msub>
           <mo id="Sx2.SSx2.p1.15.m15.5.5.1.1.1.1.3.6" xref="Sx2.SSx2.p1.15.m15.5.5.1.1.1.1.4.cmml">
            ,
           </mo>
           <mi id="Sx2.SSx2.p1.15.m15.1.1" mathvariant="normal" xref="Sx2.SSx2.p1.15.m15.1.1.cmml">
            …
           </mi>
           <mo id="Sx2.SSx2.p1.15.m15.5.5.1.1.1.1.3.7" xref="Sx2.SSx2.p1.15.m15.5.5.1.1.1.1.4.cmml">
            ,
           </mo>
           <msub id="Sx2.SSx2.p1.15.m15.5.5.1.1.1.1.3.3" xref="Sx2.SSx2.p1.15.m15.5.5.1.1.1.1.3.3.cmml">
            <mi id="Sx2.SSx2.p1.15.m15.5.5.1.1.1.1.3.3.2" xref="Sx2.SSx2.p1.15.m15.5.5.1.1.1.1.3.3.2.cmml">
             a
            </mi>
            <mi id="Sx2.SSx2.p1.15.m15.5.5.1.1.1.1.3.3.3" xref="Sx2.SSx2.p1.15.m15.5.5.1.1.1.1.3.3.3.cmml">
             n
            </mi>
           </msub>
           <mo id="Sx2.SSx2.p1.15.m15.5.5.1.1.1.1.3.8" stretchy="false" xref="Sx2.SSx2.p1.15.m15.5.5.1.1.1.1.4.cmml">
            )
           </mo>
          </mrow>
          <mo id="Sx2.SSx2.p1.15.m15.5.5.1.1.1.4" stretchy="false" xref="Sx2.SSx2.p1.15.m15.5.5.1.1.2.cmml">
           )
          </mo>
         </mrow>
        </mrow>
        <mo id="Sx2.SSx2.p1.15.m15.7.7.4" xref="Sx2.SSx2.p1.15.m15.7.7.4.cmml">
         =
        </mo>
        <mrow id="Sx2.SSx2.p1.15.m15.7.7.3" xref="Sx2.SSx2.p1.15.m15.7.7.3.cmml">
         <msub id="Sx2.SSx2.p1.15.m15.7.7.3.4" xref="Sx2.SSx2.p1.15.m15.7.7.3.4.cmml">
          <mi id="Sx2.SSx2.p1.15.m15.7.7.3.4.2" xref="Sx2.SSx2.p1.15.m15.7.7.3.4.2.cmml">
           δ
          </mi>
          <mi class="ltx_font_mathcaligraphic" id="Sx2.SSx2.p1.15.m15.7.7.3.4.3" xref="Sx2.SSx2.p1.15.m15.7.7.3.4.3.cmml">
           ℳ
          </mi>
         </msub>
         <mo id="Sx2.SSx2.p1.15.m15.7.7.3.3" lspace="0em" rspace="0em" xref="Sx2.SSx2.p1.15.m15.7.7.3.3.cmml">
          ​
         </mo>
         <mrow id="Sx2.SSx2.p1.15.m15.7.7.3.2.2" xref="Sx2.SSx2.p1.15.m15.7.7.3.2.3.cmml">
          <mo id="Sx2.SSx2.p1.15.m15.7.7.3.2.2.3" stretchy="false" xref="Sx2.SSx2.p1.15.m15.7.7.3.2.3.cmml">
           (
          </mo>
          <mrow id="Sx2.SSx2.p1.15.m15.6.6.2.1.1.1" xref="Sx2.SSx2.p1.15.m15.6.6.2.1.1.1.cmml">
           <msub id="Sx2.SSx2.p1.15.m15.6.6.2.1.1.1.3" xref="Sx2.SSx2.p1.15.m15.6.6.2.1.1.1.3.cmml">
            <mi id="Sx2.SSx2.p1.15.m15.6.6.2.1.1.1.3.2" xref="Sx2.SSx2.p1.15.m15.6.6.2.1.1.1.3.2.cmml">
             δ
            </mi>
            <mi class="ltx_font_mathcaligraphic" id="Sx2.SSx2.p1.15.m15.6.6.2.1.1.1.3.3" xref="Sx2.SSx2.p1.15.m15.6.6.2.1.1.1.3.3.cmml">
             ℳ
            </mi>
           </msub>
           <mo id="Sx2.SSx2.p1.15.m15.6.6.2.1.1.1.2" lspace="0em" rspace="0em" xref="Sx2.SSx2.p1.15.m15.6.6.2.1.1.1.2.cmml">
            ​
           </mo>
           <mrow id="Sx2.SSx2.p1.15.m15.6.6.2.1.1.1.1.1" xref="Sx2.SSx2.p1.15.m15.6.6.2.1.1.1.1.2.cmml">
            <mo id="Sx2.SSx2.p1.15.m15.6.6.2.1.1.1.1.1.2" stretchy="false" xref="Sx2.SSx2.p1.15.m15.6.6.2.1.1.1.1.2.cmml">
             (
            </mo>
            <mi id="Sx2.SSx2.p1.15.m15.3.3" xref="Sx2.SSx2.p1.15.m15.3.3.cmml">
             s
            </mi>
            <mo id="Sx2.SSx2.p1.15.m15.6.6.2.1.1.1.1.1.3" xref="Sx2.SSx2.p1.15.m15.6.6.2.1.1.1.1.2.cmml">
             ,
            </mo>
            <msub id="Sx2.SSx2.p1.15.m15.6.6.2.1.1.1.1.1.1" xref="Sx2.SSx2.p1.15.m15.6.6.2.1.1.1.1.1.1.cmml">
             <mi id="Sx2.SSx2.p1.15.m15.6.6.2.1.1.1.1.1.1.2" xref="Sx2.SSx2.p1.15.m15.6.6.2.1.1.1.1.1.1.2.cmml">
              a
             </mi>
             <mn id="Sx2.SSx2.p1.15.m15.6.6.2.1.1.1.1.1.1.3" xref="Sx2.SSx2.p1.15.m15.6.6.2.1.1.1.1.1.1.3.cmml">
              1
             </mn>
            </msub>
            <mo id="Sx2.SSx2.p1.15.m15.6.6.2.1.1.1.1.1.4" stretchy="false" xref="Sx2.SSx2.p1.15.m15.6.6.2.1.1.1.1.2.cmml">
             )
            </mo>
           </mrow>
          </mrow>
          <mo id="Sx2.SSx2.p1.15.m15.7.7.3.2.2.4" xref="Sx2.SSx2.p1.15.m15.7.7.3.2.3.cmml">
           ,
          </mo>
          <mrow id="Sx2.SSx2.p1.15.m15.7.7.3.2.2.2.2" xref="Sx2.SSx2.p1.15.m15.7.7.3.2.2.2.3.cmml">
           <mo id="Sx2.SSx2.p1.15.m15.7.7.3.2.2.2.2.3" stretchy="false" xref="Sx2.SSx2.p1.15.m15.7.7.3.2.2.2.3.cmml">
            (
           </mo>
           <msub id="Sx2.SSx2.p1.15.m15.7.7.3.2.2.2.1.1" xref="Sx2.SSx2.p1.15.m15.7.7.3.2.2.2.1.1.cmml">
            <mi id="Sx2.SSx2.p1.15.m15.7.7.3.2.2.2.1.1.2" xref="Sx2.SSx2.p1.15.m15.7.7.3.2.2.2.1.1.2.cmml">
             a
            </mi>
            <mn id="Sx2.SSx2.p1.15.m15.7.7.3.2.2.2.1.1.3" xref="Sx2.SSx2.p1.15.m15.7.7.3.2.2.2.1.1.3.cmml">
             2
            </mn>
           </msub>
           <mo id="Sx2.SSx2.p1.15.m15.7.7.3.2.2.2.2.4" xref="Sx2.SSx2.p1.15.m15.7.7.3.2.2.2.3.cmml">
            ,
           </mo>
           <mi id="Sx2.SSx2.p1.15.m15.4.4" mathvariant="normal" xref="Sx2.SSx2.p1.15.m15.4.4.cmml">
            …
           </mi>
           <mo id="Sx2.SSx2.p1.15.m15.7.7.3.2.2.2.2.5" xref="Sx2.SSx2.p1.15.m15.7.7.3.2.2.2.3.cmml">
            ,
           </mo>
           <msub id="Sx2.SSx2.p1.15.m15.7.7.3.2.2.2.2.2" xref="Sx2.SSx2.p1.15.m15.7.7.3.2.2.2.2.2.cmml">
            <mi id="Sx2.SSx2.p1.15.m15.7.7.3.2.2.2.2.2.2" xref="Sx2.SSx2.p1.15.m15.7.7.3.2.2.2.2.2.2.cmml">
             a
            </mi>
            <mi id="Sx2.SSx2.p1.15.m15.7.7.3.2.2.2.2.2.3" xref="Sx2.SSx2.p1.15.m15.7.7.3.2.2.2.2.2.3.cmml">
             n
            </mi>
           </msub>
           <mo id="Sx2.SSx2.p1.15.m15.7.7.3.2.2.2.2.6" stretchy="false" xref="Sx2.SSx2.p1.15.m15.7.7.3.2.2.2.3.cmml">
            )
           </mo>
          </mrow>
          <mo id="Sx2.SSx2.p1.15.m15.7.7.3.2.2.5" stretchy="false" xref="Sx2.SSx2.p1.15.m15.7.7.3.2.3.cmml">
           )
          </mo>
         </mrow>
        </mrow>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="Sx2.SSx2.p1.15.m15.7b">
        <apply id="Sx2.SSx2.p1.15.m15.7.7.cmml" xref="Sx2.SSx2.p1.15.m15.7.7">
         <eq id="Sx2.SSx2.p1.15.m15.7.7.4.cmml" xref="Sx2.SSx2.p1.15.m15.7.7.4">
         </eq>
         <apply id="Sx2.SSx2.p1.15.m15.5.5.1.cmml" xref="Sx2.SSx2.p1.15.m15.5.5.1">
          <times id="Sx2.SSx2.p1.15.m15.5.5.1.2.cmml" xref="Sx2.SSx2.p1.15.m15.5.5.1.2">
          </times>
          <apply id="Sx2.SSx2.p1.15.m15.5.5.1.3.cmml" xref="Sx2.SSx2.p1.15.m15.5.5.1.3">
           <csymbol cd="ambiguous" id="Sx2.SSx2.p1.15.m15.5.5.1.3.1.cmml" xref="Sx2.SSx2.p1.15.m15.5.5.1.3">
            subscript
           </csymbol>
           <ci id="Sx2.SSx2.p1.15.m15.5.5.1.3.2.cmml" xref="Sx2.SSx2.p1.15.m15.5.5.1.3.2">
            𝛿
           </ci>
           <ci id="Sx2.SSx2.p1.15.m15.5.5.1.3.3.cmml" xref="Sx2.SSx2.p1.15.m15.5.5.1.3.3">
            ℳ
           </ci>
          </apply>
          <interval closure="open" id="Sx2.SSx2.p1.15.m15.5.5.1.1.2.cmml" xref="Sx2.SSx2.p1.15.m15.5.5.1.1.1">
           <ci id="Sx2.SSx2.p1.15.m15.2.2.cmml" xref="Sx2.SSx2.p1.15.m15.2.2">
            𝑠
           </ci>
           <vector id="Sx2.SSx2.p1.15.m15.5.5.1.1.1.1.4.cmml" xref="Sx2.SSx2.p1.15.m15.5.5.1.1.1.1.3">
            <apply id="Sx2.SSx2.p1.15.m15.5.5.1.1.1.1.1.1.cmml" xref="Sx2.SSx2.p1.15.m15.5.5.1.1.1.1.1.1">
             <csymbol cd="ambiguous" id="Sx2.SSx2.p1.15.m15.5.5.1.1.1.1.1.1.1.cmml" xref="Sx2.SSx2.p1.15.m15.5.5.1.1.1.1.1.1">
              subscript
             </csymbol>
             <ci id="Sx2.SSx2.p1.15.m15.5.5.1.1.1.1.1.1.2.cmml" xref="Sx2.SSx2.p1.15.m15.5.5.1.1.1.1.1.1.2">
              𝑎
             </ci>
             <cn id="Sx2.SSx2.p1.15.m15.5.5.1.1.1.1.1.1.3.cmml" type="integer" xref="Sx2.SSx2.p1.15.m15.5.5.1.1.1.1.1.1.3">
              1
             </cn>
            </apply>
            <apply id="Sx2.SSx2.p1.15.m15.5.5.1.1.1.1.2.2.cmml" xref="Sx2.SSx2.p1.15.m15.5.5.1.1.1.1.2.2">
             <csymbol cd="ambiguous" id="Sx2.SSx2.p1.15.m15.5.5.1.1.1.1.2.2.1.cmml" xref="Sx2.SSx2.p1.15.m15.5.5.1.1.1.1.2.2">
              subscript
             </csymbol>
             <ci id="Sx2.SSx2.p1.15.m15.5.5.1.1.1.1.2.2.2.cmml" xref="Sx2.SSx2.p1.15.m15.5.5.1.1.1.1.2.2.2">
              𝑎
             </ci>
             <cn id="Sx2.SSx2.p1.15.m15.5.5.1.1.1.1.2.2.3.cmml" type="integer" xref="Sx2.SSx2.p1.15.m15.5.5.1.1.1.1.2.2.3">
              2
             </cn>
            </apply>
            <ci id="Sx2.SSx2.p1.15.m15.1.1.cmml" xref="Sx2.SSx2.p1.15.m15.1.1">
             …
            </ci>
            <apply id="Sx2.SSx2.p1.15.m15.5.5.1.1.1.1.3.3.cmml" xref="Sx2.SSx2.p1.15.m15.5.5.1.1.1.1.3.3">
             <csymbol cd="ambiguous" id="Sx2.SSx2.p1.15.m15.5.5.1.1.1.1.3.3.1.cmml" xref="Sx2.SSx2.p1.15.m15.5.5.1.1.1.1.3.3">
              subscript
             </csymbol>
             <ci id="Sx2.SSx2.p1.15.m15.5.5.1.1.1.1.3.3.2.cmml" xref="Sx2.SSx2.p1.15.m15.5.5.1.1.1.1.3.3.2">
              𝑎
             </ci>
             <ci id="Sx2.SSx2.p1.15.m15.5.5.1.1.1.1.3.3.3.cmml" xref="Sx2.SSx2.p1.15.m15.5.5.1.1.1.1.3.3.3">
              𝑛
             </ci>
            </apply>
           </vector>
          </interval>
         </apply>
         <apply id="Sx2.SSx2.p1.15.m15.7.7.3.cmml" xref="Sx2.SSx2.p1.15.m15.7.7.3">
          <times id="Sx2.SSx2.p1.15.m15.7.7.3.3.cmml" xref="Sx2.SSx2.p1.15.m15.7.7.3.3">
          </times>
          <apply id="Sx2.SSx2.p1.15.m15.7.7.3.4.cmml" xref="Sx2.SSx2.p1.15.m15.7.7.3.4">
           <csymbol cd="ambiguous" id="Sx2.SSx2.p1.15.m15.7.7.3.4.1.cmml" xref="Sx2.SSx2.p1.15.m15.7.7.3.4">
            subscript
           </csymbol>
           <ci id="Sx2.SSx2.p1.15.m15.7.7.3.4.2.cmml" xref="Sx2.SSx2.p1.15.m15.7.7.3.4.2">
            𝛿
           </ci>
           <ci id="Sx2.SSx2.p1.15.m15.7.7.3.4.3.cmml" xref="Sx2.SSx2.p1.15.m15.7.7.3.4.3">
            ℳ
           </ci>
          </apply>
          <interval closure="open" id="Sx2.SSx2.p1.15.m15.7.7.3.2.3.cmml" xref="Sx2.SSx2.p1.15.m15.7.7.3.2.2">
           <apply id="Sx2.SSx2.p1.15.m15.6.6.2.1.1.1.cmml" xref="Sx2.SSx2.p1.15.m15.6.6.2.1.1.1">
            <times id="Sx2.SSx2.p1.15.m15.6.6.2.1.1.1.2.cmml" xref="Sx2.SSx2.p1.15.m15.6.6.2.1.1.1.2">
            </times>
            <apply id="Sx2.SSx2.p1.15.m15.6.6.2.1.1.1.3.cmml" xref="Sx2.SSx2.p1.15.m15.6.6.2.1.1.1.3">
             <csymbol cd="ambiguous" id="Sx2.SSx2.p1.15.m15.6.6.2.1.1.1.3.1.cmml" xref="Sx2.SSx2.p1.15.m15.6.6.2.1.1.1.3">
              subscript
             </csymbol>
             <ci id="Sx2.SSx2.p1.15.m15.6.6.2.1.1.1.3.2.cmml" xref="Sx2.SSx2.p1.15.m15.6.6.2.1.1.1.3.2">
              𝛿
             </ci>
             <ci id="Sx2.SSx2.p1.15.m15.6.6.2.1.1.1.3.3.cmml" xref="Sx2.SSx2.p1.15.m15.6.6.2.1.1.1.3.3">
              ℳ
             </ci>
            </apply>
            <interval closure="open" id="Sx2.SSx2.p1.15.m15.6.6.2.1.1.1.1.2.cmml" xref="Sx2.SSx2.p1.15.m15.6.6.2.1.1.1.1.1">
             <ci id="Sx2.SSx2.p1.15.m15.3.3.cmml" xref="Sx2.SSx2.p1.15.m15.3.3">
              𝑠
             </ci>
             <apply id="Sx2.SSx2.p1.15.m15.6.6.2.1.1.1.1.1.1.cmml" xref="Sx2.SSx2.p1.15.m15.6.6.2.1.1.1.1.1.1">
              <csymbol cd="ambiguous" id="Sx2.SSx2.p1.15.m15.6.6.2.1.1.1.1.1.1.1.cmml" xref="Sx2.SSx2.p1.15.m15.6.6.2.1.1.1.1.1.1">
               subscript
              </csymbol>
              <ci id="Sx2.SSx2.p1.15.m15.6.6.2.1.1.1.1.1.1.2.cmml" xref="Sx2.SSx2.p1.15.m15.6.6.2.1.1.1.1.1.1.2">
               𝑎
              </ci>
              <cn id="Sx2.SSx2.p1.15.m15.6.6.2.1.1.1.1.1.1.3.cmml" type="integer" xref="Sx2.SSx2.p1.15.m15.6.6.2.1.1.1.1.1.1.3">
               1
              </cn>
             </apply>
            </interval>
           </apply>
           <vector id="Sx2.SSx2.p1.15.m15.7.7.3.2.2.2.3.cmml" xref="Sx2.SSx2.p1.15.m15.7.7.3.2.2.2.2">
            <apply id="Sx2.SSx2.p1.15.m15.7.7.3.2.2.2.1.1.cmml" xref="Sx2.SSx2.p1.15.m15.7.7.3.2.2.2.1.1">
             <csymbol cd="ambiguous" id="Sx2.SSx2.p1.15.m15.7.7.3.2.2.2.1.1.1.cmml" xref="Sx2.SSx2.p1.15.m15.7.7.3.2.2.2.1.1">
              subscript
             </csymbol>
             <ci id="Sx2.SSx2.p1.15.m15.7.7.3.2.2.2.1.1.2.cmml" xref="Sx2.SSx2.p1.15.m15.7.7.3.2.2.2.1.1.2">
              𝑎
             </ci>
             <cn id="Sx2.SSx2.p1.15.m15.7.7.3.2.2.2.1.1.3.cmml" type="integer" xref="Sx2.SSx2.p1.15.m15.7.7.3.2.2.2.1.1.3">
              2
             </cn>
            </apply>
            <ci id="Sx2.SSx2.p1.15.m15.4.4.cmml" xref="Sx2.SSx2.p1.15.m15.4.4">
             …
            </ci>
            <apply id="Sx2.SSx2.p1.15.m15.7.7.3.2.2.2.2.2.cmml" xref="Sx2.SSx2.p1.15.m15.7.7.3.2.2.2.2.2">
             <csymbol cd="ambiguous" id="Sx2.SSx2.p1.15.m15.7.7.3.2.2.2.2.2.1.cmml" xref="Sx2.SSx2.p1.15.m15.7.7.3.2.2.2.2.2">
              subscript
             </csymbol>
             <ci id="Sx2.SSx2.p1.15.m15.7.7.3.2.2.2.2.2.2.cmml" xref="Sx2.SSx2.p1.15.m15.7.7.3.2.2.2.2.2.2">
              𝑎
             </ci>
             <ci id="Sx2.SSx2.p1.15.m15.7.7.3.2.2.2.2.2.3.cmml" xref="Sx2.SSx2.p1.15.m15.7.7.3.2.2.2.2.2.3">
              𝑛
             </ci>
            </apply>
           </vector>
          </interval>
         </apply>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="Sx2.SSx2.p1.15.m15.7c">
        \delta_{\mathcal{M}}(s,(a_{1},a_{2},\ldots,a_{n}))=\delta_{\mathcal{M}}(\delta_{\mathcal{M}}(s,a_{1}),(a_{2},\ldots,a_{n}))
       </annotation>
      </semantics>
     </math>
     . A plan for a CPP is a sequence of actions
     <math alttext="\langle a_{1},a_{2},\ldots,a_{n}\rangle" class="ltx_Math" display="inline" id="Sx2.SSx2.p1.16.m16.4">
      <semantics id="Sx2.SSx2.p1.16.m16.4a">
       <mrow id="Sx2.SSx2.p1.16.m16.4.4.3" xref="Sx2.SSx2.p1.16.m16.4.4.4.cmml">
        <mo id="Sx2.SSx2.p1.16.m16.4.4.3.4" stretchy="false" xref="Sx2.SSx2.p1.16.m16.4.4.4.cmml">
         ⟨
        </mo>
        <msub id="Sx2.SSx2.p1.16.m16.2.2.1.1" xref="Sx2.SSx2.p1.16.m16.2.2.1.1.cmml">
         <mi id="Sx2.SSx2.p1.16.m16.2.2.1.1.2" xref="Sx2.SSx2.p1.16.m16.2.2.1.1.2.cmml">
          a
         </mi>
         <mn id="Sx2.SSx2.p1.16.m16.2.2.1.1.3" xref="Sx2.SSx2.p1.16.m16.2.2.1.1.3.cmml">
          1
         </mn>
        </msub>
        <mo id="Sx2.SSx2.p1.16.m16.4.4.3.5" xref="Sx2.SSx2.p1.16.m16.4.4.4.cmml">
         ,
        </mo>
        <msub id="Sx2.SSx2.p1.16.m16.3.3.2.2" xref="Sx2.SSx2.p1.16.m16.3.3.2.2.cmml">
         <mi id="Sx2.SSx2.p1.16.m16.3.3.2.2.2" xref="Sx2.SSx2.p1.16.m16.3.3.2.2.2.cmml">
          a
         </mi>
         <mn id="Sx2.SSx2.p1.16.m16.3.3.2.2.3" xref="Sx2.SSx2.p1.16.m16.3.3.2.2.3.cmml">
          2
         </mn>
        </msub>
        <mo id="Sx2.SSx2.p1.16.m16.4.4.3.6" xref="Sx2.SSx2.p1.16.m16.4.4.4.cmml">
         ,
        </mo>
        <mi id="Sx2.SSx2.p1.16.m16.1.1" mathvariant="normal" xref="Sx2.SSx2.p1.16.m16.1.1.cmml">
         …
        </mi>
        <mo id="Sx2.SSx2.p1.16.m16.4.4.3.7" xref="Sx2.SSx2.p1.16.m16.4.4.4.cmml">
         ,
        </mo>
        <msub id="Sx2.SSx2.p1.16.m16.4.4.3.3" xref="Sx2.SSx2.p1.16.m16.4.4.3.3.cmml">
         <mi id="Sx2.SSx2.p1.16.m16.4.4.3.3.2" xref="Sx2.SSx2.p1.16.m16.4.4.3.3.2.cmml">
          a
         </mi>
         <mi id="Sx2.SSx2.p1.16.m16.4.4.3.3.3" xref="Sx2.SSx2.p1.16.m16.4.4.3.3.3.cmml">
          n
         </mi>
        </msub>
        <mo id="Sx2.SSx2.p1.16.m16.4.4.3.8" stretchy="false" xref="Sx2.SSx2.p1.16.m16.4.4.4.cmml">
         ⟩
        </mo>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="Sx2.SSx2.p1.16.m16.4b">
        <list id="Sx2.SSx2.p1.16.m16.4.4.4.cmml" xref="Sx2.SSx2.p1.16.m16.4.4.3">
         <apply id="Sx2.SSx2.p1.16.m16.2.2.1.1.cmml" xref="Sx2.SSx2.p1.16.m16.2.2.1.1">
          <csymbol cd="ambiguous" id="Sx2.SSx2.p1.16.m16.2.2.1.1.1.cmml" xref="Sx2.SSx2.p1.16.m16.2.2.1.1">
           subscript
          </csymbol>
          <ci id="Sx2.SSx2.p1.16.m16.2.2.1.1.2.cmml" xref="Sx2.SSx2.p1.16.m16.2.2.1.1.2">
           𝑎
          </ci>
          <cn id="Sx2.SSx2.p1.16.m16.2.2.1.1.3.cmml" type="integer" xref="Sx2.SSx2.p1.16.m16.2.2.1.1.3">
           1
          </cn>
         </apply>
         <apply id="Sx2.SSx2.p1.16.m16.3.3.2.2.cmml" xref="Sx2.SSx2.p1.16.m16.3.3.2.2">
          <csymbol cd="ambiguous" id="Sx2.SSx2.p1.16.m16.3.3.2.2.1.cmml" xref="Sx2.SSx2.p1.16.m16.3.3.2.2">
           subscript
          </csymbol>
          <ci id="Sx2.SSx2.p1.16.m16.3.3.2.2.2.cmml" xref="Sx2.SSx2.p1.16.m16.3.3.2.2.2">
           𝑎
          </ci>
          <cn id="Sx2.SSx2.p1.16.m16.3.3.2.2.3.cmml" type="integer" xref="Sx2.SSx2.p1.16.m16.3.3.2.2.3">
           2
          </cn>
         </apply>
         <ci id="Sx2.SSx2.p1.16.m16.1.1.cmml" xref="Sx2.SSx2.p1.16.m16.1.1">
          …
         </ci>
         <apply id="Sx2.SSx2.p1.16.m16.4.4.3.3.cmml" xref="Sx2.SSx2.p1.16.m16.4.4.3.3">
          <csymbol cd="ambiguous" id="Sx2.SSx2.p1.16.m16.4.4.3.3.1.cmml" xref="Sx2.SSx2.p1.16.m16.4.4.3.3">
           subscript
          </csymbol>
          <ci id="Sx2.SSx2.p1.16.m16.4.4.3.3.2.cmml" xref="Sx2.SSx2.p1.16.m16.4.4.3.3.2">
           𝑎
          </ci>
          <ci id="Sx2.SSx2.p1.16.m16.4.4.3.3.3.cmml" xref="Sx2.SSx2.p1.16.m16.4.4.3.3.3">
           𝑛
          </ci>
         </apply>
        </list>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="Sx2.SSx2.p1.16.m16.4c">
        \langle a_{1},a_{2},\ldots,a_{n}\rangle
       </annotation>
      </semantics>
     </math>
     that transforms the initial state
     <math alttext="\mathcal{I}" class="ltx_Math" display="inline" id="Sx2.SSx2.p1.17.m17.1">
      <semantics id="Sx2.SSx2.p1.17.m17.1a">
       <mi class="ltx_font_mathcaligraphic" id="Sx2.SSx2.p1.17.m17.1.1" xref="Sx2.SSx2.p1.17.m17.1.1.cmml">
        ℐ
       </mi>
       <annotation-xml encoding="MathML-Content" id="Sx2.SSx2.p1.17.m17.1b">
        <ci id="Sx2.SSx2.p1.17.m17.1.1.cmml" xref="Sx2.SSx2.p1.17.m17.1.1">
         ℐ
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="Sx2.SSx2.p1.17.m17.1c">
        \mathcal{I}
       </annotation>
      </semantics>
     </math>
     into the goal state
     <math alttext="\mathcal{G}" class="ltx_Math" display="inline" id="Sx2.SSx2.p1.18.m18.1">
      <semantics id="Sx2.SSx2.p1.18.m18.1a">
       <mi class="ltx_font_mathcaligraphic" id="Sx2.SSx2.p1.18.m18.1.1" xref="Sx2.SSx2.p1.18.m18.1.1.cmml">
        𝒢
       </mi>
       <annotation-xml encoding="MathML-Content" id="Sx2.SSx2.p1.18.m18.1b">
        <ci id="Sx2.SSx2.p1.18.m18.1.1.cmml" xref="Sx2.SSx2.p1.18.m18.1.1">
         𝒢
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="Sx2.SSx2.p1.18.m18.1c">
        \mathcal{G}
       </annotation>
      </semantics>
     </math>
     using the transition function
     <math alttext="\delta_{\mathcal{M}}" class="ltx_Math" display="inline" id="Sx2.SSx2.p1.19.m19.1">
      <semantics id="Sx2.SSx2.p1.19.m19.1a">
       <msub id="Sx2.SSx2.p1.19.m19.1.1" xref="Sx2.SSx2.p1.19.m19.1.1.cmml">
        <mi id="Sx2.SSx2.p1.19.m19.1.1.2" xref="Sx2.SSx2.p1.19.m19.1.1.2.cmml">
         δ
        </mi>
        <mi class="ltx_font_mathcaligraphic" id="Sx2.SSx2.p1.19.m19.1.1.3" xref="Sx2.SSx2.p1.19.m19.1.1.3.cmml">
         ℳ
        </mi>
       </msub>
       <annotation-xml encoding="MathML-Content" id="Sx2.SSx2.p1.19.m19.1b">
        <apply id="Sx2.SSx2.p1.19.m19.1.1.cmml" xref="Sx2.SSx2.p1.19.m19.1.1">
         <csymbol cd="ambiguous" id="Sx2.SSx2.p1.19.m19.1.1.1.cmml" xref="Sx2.SSx2.p1.19.m19.1.1">
          subscript
         </csymbol>
         <ci id="Sx2.SSx2.p1.19.m19.1.1.2.cmml" xref="Sx2.SSx2.p1.19.m19.1.1.2">
          𝛿
         </ci>
         <ci id="Sx2.SSx2.p1.19.m19.1.1.3.cmml" xref="Sx2.SSx2.p1.19.m19.1.1.3">
          ℳ
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="Sx2.SSx2.p1.19.m19.1c">
        \delta_{\mathcal{M}}
       </annotation>
      </semantics>
     </math>
     . Traditionally, a CPP is encoded using a symbolic representation, where states, actions, and transitions are explicitly enumerated. This symbolic approach, often implemented using Planning Domain Definition Language or PDDL
     <cite class="ltx_cite ltx_citemacro_citep">
      (McDermott et al.
      <a class="ltx_ref" href="#bib.bib72" title="">
       1998
      </a>
      )
     </cite>
     , ensures precise and unambiguous descriptions of planning problems. This formalism allows for applying search algorithms and heuristic methods to find a sequence of actions that lead to the goal state, which is the essence of the plan.
    </p>
   </div>
   <div class="ltx_para" id="Sx2.SSx2.p2">
    <p class="ltx_p" id="Sx2.SSx2.p2.1">
     The advent of LLMs has sparked a significant evolution in representation methods for CPPs, moving towards leveraging the expressive power of natural language
     <cite class="ltx_cite ltx_citemacro_citep">
      (Valmeekam et al.
      <a class="ltx_ref" href="#bib.bib102" title="">
       2023a
      </a>
      )
     </cite>
     and the perceptual capabilities of vision
     <cite class="ltx_cite ltx_citemacro_citep">
      (Asai
      <a class="ltx_ref" href="#bib.bib3" title="">
       2018
      </a>
      )
     </cite>
     . These novel approaches, inherently more suited for LLM processing, use text and vision-based representations, allowing researchers to utilize the pre-existing knowledge within LLMs. This shift enables a more humanistic comprehension and reasoning about planning tasks, enhancing the flexibility and applicability of planning algorithms in complex, dynamic environments. LLMs, while distinct in being trained on vast datasets outside the traditional scope of planning, loosely connect to previous data-driven methodologies, such as case-based reasoning
     <cite class="ltx_cite ltx_citemacro_citep">
      (Xu
      <a class="ltx_ref" href="#bib.bib117" title="">
       1995
      </a>
      )
     </cite>
     applied to planning and Hierarchical Task Network (HTN)
     <cite class="ltx_cite ltx_citemacro_citep">
      (Georgievski and Aiello
      <a class="ltx_ref" href="#bib.bib27" title="">
       2015
      </a>
      )
     </cite>
     which make use of task knowledge. It is an open area how LLMs may be used synergestically with prior methods.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="Sx2.SSx3">
   <h3 class="ltx_title ltx_title_subsection">
    LLMs in APS – Literature selection
   </h3>
   <div class="ltx_para" id="Sx2.SSx3.p1">
    <p class="ltx_p" id="Sx2.SSx3.p1.1">
     A comprehensive survey of existing literature was conducted to explore the application of LLMs for automated planning. This endeavor led to identifying 126 pertinent research papers showcasing various methodologies, applications, and theoretical insights into utilizing LLMs within this domain.
    </p>
   </div>
   <div class="ltx_para" id="Sx2.SSx3.p2">
    <p class="ltx_p" id="Sx2.SSx3.p2.1">
     The selection of these papers was guided by stringent criteria, focusing primarily on their relevance to the core theme of LLMs in automated planning. The search, conducted across multiple academic databases and journals, was steered by keywords such as “Large Language Models”, “Automated Planning”, “LLMs in Planning”, and “LLMs + Robotics”. Figure
     <a class="ltx_ref" href="#Sx2.F2" title="Figure 2 ‣ Large Language Models ‣ Background ‣ On the Prospects of Incorporating Large Language Models (LLMs) in Automated Planning and Scheduling (APS)">
      <span class="ltx_text ltx_ref_tag">
       2
      </span>
     </a>
     presents the distribution of these selected papers across various peer-reviewed conferences, underlining the breadth and diversity of forums addressing the intersection of LLMs and APS. Even if a paper originated from a workshop within a conference, only the conference name is listed. Out of 126 papers, 71 are under review or available on arXiv. The inclusion criteria prioritized the relevance and contribution of papers to automated planning with LLMs over the publication date. Nonetheless, all surveyed papers emerged from either 2022 or 2023, a trend depicted in Figure
     <a class="ltx_ref" href="#Sx2.F3" title="Figure 3 ‣ LLMs in APS – Literature selection ‣ Background ‣ On the Prospects of Incorporating Large Language Models (LLMs) in Automated Planning and Scheduling (APS)">
      <span class="ltx_text ltx_ref_tag">
       3
      </span>
     </a>
     , underscoring the recent surge in LLM research. A word cloud was generated to visually capture the prevalent research themes reflected in these papers’ titles, illustrated in Figure
     <a class="ltx_ref" href="#Sx2.F4" title="Figure 4 ‣ LLMs in APS – Literature selection ‣ Background ‣ On the Prospects of Incorporating Large Language Models (LLMs) in Automated Planning and Scheduling (APS)">
      <span class="ltx_text ltx_ref_tag">
       4
      </span>
     </a>
     . This cloud highlights the frequent use of terms such as “Language Model” and “Planning”, which dominate the current discourse. In contrast, the emergence of “Neuro-Symbolic” reflects a nascent yet growing interest in integrating neural and symbolic approaches within the field. This systematic approach ensured a comprehensive inclusion of seminal works and recent advancements.
    </p>
   </div>
   <figure class="ltx_figure" id="Sx2.F3">
    <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="318" id="Sx2.F3.g1" src="/html/2401.02500/assets/figures/papers_per_year.png" width="491"/>
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_figure">
      Figure 3:
     </span>
     Annual distribution of the 126 surveyed papers, indicating a significant increase in publications from 12 in 2022 to 114 in 2023, highlighting the rapid growth of LLM research within a single year.
    </figcaption>
   </figure>
   <div class="ltx_para" id="Sx2.SSx3.p3">
    <p class="ltx_p" id="Sx2.SSx3.p3.1">
     Upon the accumulation of these papers, a meticulous manual categorization was undertaken. The papers were divided into four piles, each containing approximately 30 papers. Each pile was manually categorized by one author, with the final categorization being reviewed by all authors. During this process, each paper could belong to multiple categories out of the eight established. The maximum number of categories assigned to a single paper was three, although the median was typically one category per paper. This process was pivotal in distilling the vast information into coherent, thematic groups. The categorization was conducted based on the specific application of LLMs in planning. This formed eight distinct categories, each representing a unique facet of LLM application in automated planning. These categories facilitate a structured analysis and highlight LLMs’ diverse applications and theoretical underpinnings in this field.
    </p>
   </div>
   <figure class="ltx_figure" id="Sx2.F4">
    <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="306" id="Sx2.F4.g1" src="/html/2401.02500/assets/figures/wordcloud.png" width="598"/>
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_figure">
      Figure 4:
     </span>
     Word cloud of terms from the titles of papers surveyed in this study, displaying the prevalence of “Language Model” and “Planning” as central themes. The presence of “Neuro-Symbolic” indicates an emergent trend toward the fusion of neural and symbolic methodologies in the domain.
    </figcaption>
   </figure>
   <figure class="ltx_figure" id="Sx2.F5">
    <div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="Sx2.F5.1" style="width:505.9pt;height:317.4pt;vertical-align:-312.9pt;">
     <span class="ltx_transformed_inner" style="transform:translate(-141.7pt,1.2pt) scale(0.640951618660585,0.640951618660585) ;">
      <span class="ltx_ERROR undefined" id="Sx2.F5.1.1">
       {forest}
      </span>
      <p class="ltx_p" id="Sx2.F5.1.2">
       for tree=my node,
l sep+=5pt,
grow’=east,
edge=gray, thick,
parent anchor=east,
child anchor=west,
if n children=0tier=last,
edge path=
[draw,
       <span class="ltx_ERROR undefined" id="Sx2.F5.1.2.1">
        \forestoption
       </span>
       edge] (!u.parent anchor) – +(10pt,0) —- (.child anchor)
       <span class="ltx_ERROR undefined" id="Sx2.F5.1.2.2">
        \forestoption
       </span>
       edge label;
,

[Application of LLMs in Planning, my node
[Language Translation
       <br class="ltx_break"/>
       (23), translation
[
       <cite class="ltx_cite ltx_citemacro_citep">
        (Liu et al.
        <a class="ltx_ref" href="#bib.bib64" title="">
         2023
        </a>
        ; Xie et al.
        <a class="ltx_ref" href="#bib.bib115" title="">
         2023
        </a>
        ; Guan et al.
        <a class="ltx_ref" href="#bib.bib34" title="">
         2023
        </a>
        ; Chalvatzaki et al.
        <a class="ltx_ref" href="#bib.bib8" title="">
         2023
        </a>
        ; Yang, Ishay, and Lee
        <a class="ltx_ref" href="#bib.bib124" title="">
         2023
        </a>
        ; Wong et al.
        <a class="ltx_ref" href="#bib.bib111" title="">
         2023
        </a>
        ; Kelly et al.
        <a class="ltx_ref" href="#bib.bib55" title="">
         2023
        </a>
        ; Yang
        <a class="ltx_ref" href="#bib.bib123" title="">
         2023
        </a>
        ; Lin et al.
        <a class="ltx_ref" href="#bib.bib63" title="">
         2023c
        </a>
        ; Sakib and Sun
        <a class="ltx_ref" href="#bib.bib88" title="">
         2023
        </a>
        ; Yang et al.
        <a class="ltx_ref" href="#bib.bib120" title="">
         2023b
        </a>
        ; Parakh et al.
        <a class="ltx_ref" href="#bib.bib80" title="">
         2023
        </a>
        ; Dai et al.
        <a class="ltx_ref" href="#bib.bib14" title="">
         2023
        </a>
        ; Yang et al.
        <a class="ltx_ref" href="#bib.bib119" title="">
         2023a
        </a>
        ; Shirai et al.
        <a class="ltx_ref" href="#bib.bib93" title="">
         2023
        </a>
        ; Ding et al.
        <a class="ltx_ref" href="#bib.bib18" title="">
         2023b
        </a>
        ; Zelikman et al.
        <a class="ltx_ref" href="#bib.bib130" title="">
         2023
        </a>
        ; Pan et al.
        <a class="ltx_ref" href="#bib.bib79" title="">
         2023
        </a>
        ; Xu et al.
        <a class="ltx_ref" href="#bib.bib118" title="">
         2023b
        </a>
        ; Brohan et al.
        <a class="ltx_ref" href="#bib.bib5" title="">
         2023
        </a>
        ; Yang, Gaglione, and Topcu
        <a class="ltx_ref" href="#bib.bib121" title="">
         2022
        </a>
        ; Chen et al.
        <a class="ltx_ref" href="#bib.bib9" title="">
         2023a
        </a>
        ; You et al.
        <a class="ltx_ref" href="#bib.bib127" title="">
         2023
        </a>
        )
       </cite>
       , level 2=blue]]
[Plan Generation
       <br class="ltx_break"/>
       (53), plan gen
[
       <cite class="ltx_cite ltx_citemacro_citep">
        (Sermanet et al.
        <a class="ltx_ref" href="#bib.bib90" title="">
         2023
        </a>
        ; Li et al.
        <a class="ltx_ref" href="#bib.bib60" title="">
         2023b
        </a>
        ; Pallagani et al.
        <a class="ltx_ref" href="#bib.bib76" title="">
         2022
        </a>
        ; Silver et al.
        <a class="ltx_ref" href="#bib.bib94" title="">
         2023
        </a>
        ; Pallagani et al.
        <a class="ltx_ref" href="#bib.bib78" title="">
         2023b
        </a>
        ; Arora and Kambhampati
        <a class="ltx_ref" href="#bib.bib2" title="">
         2023
        </a>
        ; Fabiano et al.
        <a class="ltx_ref" href="#bib.bib23" title="">
         2023
        </a>
        ; Chalvatzaki et al.
        <a class="ltx_ref" href="#bib.bib8" title="">
         2023
        </a>
        ; Gu et al.
        <a class="ltx_ref" href="#bib.bib33" title="">
         2023
        </a>
        ; Silver et al.
        <a class="ltx_ref" href="#bib.bib95" title="">
         2022
        </a>
        ; Hao et al.
        <a class="ltx_ref" href="#bib.bib35" title="">
         2023a
        </a>
        ; Lin et al.
        <a class="ltx_ref" href="#bib.bib62" title="">
         2023b
        </a>
        ; Yuan et al.
        <a class="ltx_ref" href="#bib.bib129" title="">
         2023b
        </a>
        ; Gandhi, Sadigh, and Goodman
        <a class="ltx_ref" href="#bib.bib25" title="">
         2023
        </a>
        ; Joublin et al.
        <a class="ltx_ref" href="#bib.bib51" title="">
         2023
        </a>
        ; Chen et al.
        <a class="ltx_ref" href="#bib.bib11" title="">
         2023c
        </a>
        ; Zhang, Jin, and Zhuo
        <a class="ltx_ref" href="#bib.bib133" title="">
         2023
        </a>
        ; Capitanelli and Mastrogiovanni
        <a class="ltx_ref" href="#bib.bib6" title="">
         2023
        </a>
        ; Yang and Tomar
        <a class="ltx_ref" href="#bib.bib122" title="">
         2023
        </a>
        ; Song et al.
        <a class="ltx_ref" href="#bib.bib97" title="">
         2023
        </a>
        ; Dagan, Keller, and Lascarides
        <a class="ltx_ref" href="#bib.bib13" title="">
         2023
        </a>
        ; Kannan, Venkatesh, and Min
        <a class="ltx_ref" href="#bib.bib52" title="">
         2023
        </a>
        ; Valmeekam et al.
        <a class="ltx_ref" href="#bib.bib104" title="">
         2023b
        </a>
        ; Rana et al.
        <a class="ltx_ref" href="#bib.bib84" title="">
         2023
        </a>
        ; Tang et al.
        <a class="ltx_ref" href="#bib.bib100" title="">
         2023
        </a>
        ; Singh et al.
        <a class="ltx_ref" href="#bib.bib96" title="">
         2023
        </a>
        ; Wang et al.
        <a class="ltx_ref" href="#bib.bib108" title="">
         2023d
        </a>
        ; Huang et al.
        <a class="ltx_ref" href="#bib.bib46" title="">
         2022a
        </a>
        ; Rajvanshi et al.
        <a class="ltx_ref" href="#bib.bib82" title="">
         2023
        </a>
        ; Ding et al.
        <a class="ltx_ref" href="#bib.bib19" title="">
         2023c
        </a>
        ; Lu et al.
        <a class="ltx_ref" href="#bib.bib69" title="">
         2023b
        </a>
        ; Wu et al.
        <a class="ltx_ref" href="#bib.bib112" title="">
         2023a
        </a>
        ; Wang et al.
        <a class="ltx_ref" href="#bib.bib105" title="">
         2023a
        </a>
        ,
        <a class="ltx_ref" href="#bib.bib107" title="">
         c
        </a>
        ; Kim et al.
        <a class="ltx_ref" href="#bib.bib56" title="">
         2023
        </a>
        ; Hu et al.
        <a class="ltx_ref" href="#bib.bib41" title="">
         2023b
        </a>
        ; Zhang et al.
        <a class="ltx_ref" href="#bib.bib135" title="">
         2023c
        </a>
        ; Kant et al.
        <a class="ltx_ref" href="#bib.bib53" title="">
         2022
        </a>
        ; Luo et al.
        <a class="ltx_ref" href="#bib.bib70" title="">
         2023
        </a>
        ; Pallagani et al.
        <a class="ltx_ref" href="#bib.bib77" title="">
         2023a
        </a>
        ; Huang et al.
        <a class="ltx_ref" href="#bib.bib48" title="">
         2023b
        </a>
        ; Sarkisyan et al.
        <a class="ltx_ref" href="#bib.bib89" title="">
         2023
        </a>
        ; Lu et al.
        <a class="ltx_ref" href="#bib.bib68" title="">
         2022
        </a>
        ; Parakh et al.
        <a class="ltx_ref" href="#bib.bib80" title="">
         2023
        </a>
        ; Zelikman et al.
        <a class="ltx_ref" href="#bib.bib130" title="">
         2023
        </a>
        ; Besta et al.
        <a class="ltx_ref" href="#bib.bib4" title="">
         2023
        </a>
        ; Huang et al.
        <a class="ltx_ref" href="#bib.bib47" title="">
         2023a
        </a>
        ; Dalal et al.
        <a class="ltx_ref" href="#bib.bib15" title="">
         2023
        </a>
        ; Wang et al.
        <a class="ltx_ref" href="#bib.bib106" title="">
         2023b
        </a>
        ; Yao et al.
        <a class="ltx_ref" href="#bib.bib125" title="">
         2023
        </a>
        ; Valmeekam et al.
        <a class="ltx_ref" href="#bib.bib103" title="">
         2022
        </a>
        ; Valmeekam, Marquez, and Kambhampati
        <a class="ltx_ref" href="#bib.bib101" title="">
         2023
        </a>
        ; Gramopadhye and Szafir
        <a class="ltx_ref" href="#bib.bib31" title="">
         2022
        </a>
        )
       </cite>
       , level 2=green]]
[Model
       <br class="ltx_break"/>
       Construction (17), model cons
[
       <cite class="ltx_cite ltx_citemacro_citep">
        (Nottingham et al.
        <a class="ltx_ref" href="#bib.bib75" title="">
         2023
        </a>
        ; Hao et al.
        <a class="ltx_ref" href="#bib.bib35" title="">
         2023a
        </a>
        ; Zhang and Soh
        <a class="ltx_ref" href="#bib.bib131" title="">
         2023
        </a>
        ; Wong et al.
        <a class="ltx_ref" href="#bib.bib111" title="">
         2023
        </a>
        ; Kelly et al.
        <a class="ltx_ref" href="#bib.bib55" title="">
         2023
        </a>
        ; Mandi, Jain, and Song
        <a class="ltx_ref" href="#bib.bib71" title="">
         2023
        </a>
        ; Hu et al.
        <a class="ltx_ref" href="#bib.bib40" title="">
         2023a
        </a>
        ; Zhao, Lee, and Hsu
        <a class="ltx_ref" href="#bib.bib136" title="">
         2023
        </a>
        ; Yoneda et al.
        <a class="ltx_ref" href="#bib.bib126" title="">
         2023
        </a>
        ; Wu et al.
        <a class="ltx_ref" href="#bib.bib114" title="">
         2023b
        </a>
        ; Ding et al.
        <a class="ltx_ref" href="#bib.bib18" title="">
         2023b
        </a>
        ; Huang et al.
        <a class="ltx_ref" href="#bib.bib47" title="">
         2023a
        </a>
        ; Yuan et al.
        <a class="ltx_ref" href="#bib.bib128" title="">
         2023a
        </a>
        ; Xu et al.
        <a class="ltx_ref" href="#bib.bib118" title="">
         2023b
        </a>
        ; Kirk, Wray, and Laird
        <a class="ltx_ref" href="#bib.bib57" title="">
         2023
        </a>
        ; Brohan et al.
        <a class="ltx_ref" href="#bib.bib5" title="">
         2023
        </a>
        ; Gragera and Pozanco
        <a class="ltx_ref" href="#bib.bib30" title="">
         2023
        </a>
        )
       </cite>
       , level 2=red]]
[Multi-agent Planning (4), multi agent
[
       <cite class="ltx_cite ltx_citemacro_citep">
        (Zhang et al.
        <a class="ltx_ref" href="#bib.bib134" title="">
         2023b
        </a>
        ; Wei et al.
        <a class="ltx_ref" href="#bib.bib110" title="">
         2023
        </a>
        ; Chen et al.
        <a class="ltx_ref" href="#bib.bib12" title="">
         2023d
        </a>
        ; Abdelnabi et al.
        <a class="ltx_ref" href="#bib.bib1" title="">
         2023
        </a>
        ; Hua et al.
        <a class="ltx_ref" href="#bib.bib45" title="">
         2023
        </a>
        )
       </cite>
       , level 2=orange]]
[Interactive Planning (21), interactive
[
       <cite class="ltx_cite ltx_citemacro_citep">
        (Guan et al.
        <a class="ltx_ref" href="#bib.bib34" title="">
         2023
        </a>
        ; Arora and Kambhampati
        <a class="ltx_ref" href="#bib.bib2" title="">
         2023
        </a>
        ; Carta et al.
        <a class="ltx_ref" href="#bib.bib7" title="">
         2023
        </a>
        ; Zhou et al.
        <a class="ltx_ref" href="#bib.bib139" title="">
         2023
        </a>
        ; Jha et al.
        <a class="ltx_ref" href="#bib.bib50" title="">
         2023
        </a>
        ; Chen et al.
        <a class="ltx_ref" href="#bib.bib10" title="">
         2023b
        </a>
        ; Huang et al.
        <a class="ltx_ref" href="#bib.bib49" title="">
         2022b
        </a>
        ; Rana et al.
        <a class="ltx_ref" href="#bib.bib84" title="">
         2023
        </a>
        ; Ren et al.
        <a class="ltx_ref" href="#bib.bib85" title="">
         2023
        </a>
        ; Hu et al.
        <a class="ltx_ref" href="#bib.bib42" title="">
         2023c
        </a>
        ; Wang et al.
        <a class="ltx_ref" href="#bib.bib107" title="">
         2023c
        </a>
        ; Kim et al.
        <a class="ltx_ref" href="#bib.bib56" title="">
         2023
        </a>
        ; Hu et al.
        <a class="ltx_ref" href="#bib.bib41" title="">
         2023b
        </a>
        ; Raman et al.
        <a class="ltx_ref" href="#bib.bib83" title="">
         2022
        </a>
        ; Wu, Ai, and Hsu
        <a class="ltx_ref" href="#bib.bib113" title="">
         2023
        </a>
        ; Graule and Isler
        <a class="ltx_ref" href="#bib.bib32" title="">
         2023
        </a>
        ; Liu, Bahety, and Song
        <a class="ltx_ref" href="#bib.bib65" title="">
         2023
        </a>
        ; Driess et al.
        <a class="ltx_ref" href="#bib.bib20" title="">
         2023
        </a>
        ; Naik et al.
        <a class="ltx_ref" href="#bib.bib74" title="">
         2023
        </a>
        ; Sun et al.
        <a class="ltx_ref" href="#bib.bib99" title="">
         2023
        </a>
        ; Zheng et al.
        <a class="ltx_ref" href="#bib.bib138" title="">
         2023b
        </a>
        )
       </cite>
       , level 2=purple]]
[Heuristics Optimization (8), heuristics
[
       <cite class="ltx_cite ltx_citemacro_citep">
        (Hazra, Martires, and De Raedt
        <a class="ltx_ref" href="#bib.bib37" title="">
         2023
        </a>
        ; Silver et al.
        <a class="ltx_ref" href="#bib.bib95" title="">
         2022
        </a>
        ; Hao et al.
        <a class="ltx_ref" href="#bib.bib35" title="">
         2023a
        </a>
        ; Raimondo et al.
        <a class="ltx_ref" href="#bib.bib81" title="">
         2023
        </a>
        ; Valmeekam et al.
        <a class="ltx_ref" href="#bib.bib104" title="">
         2023b
        </a>
        ; Shah et al.
        <a class="ltx_ref" href="#bib.bib91" title="">
         2023
        </a>
        ; Dai et al.
        <a class="ltx_ref" href="#bib.bib14" title="">
         2023
        </a>
        ; Feng et al.
        <a class="ltx_ref" href="#bib.bib24" title="">
         2023
        </a>
        )
       </cite>
       , level 2=pink]]
[Tool Integration
       <br class="ltx_break"/>
       (8), tool integ
[
       <cite class="ltx_cite ltx_citemacro_citep">
        (Xu et al.
        <a class="ltx_ref" href="#bib.bib116" title="">
         2023a
        </a>
        ; Ruan et al.
        <a class="ltx_ref" href="#bib.bib86" title="">
         2023
        </a>
        ; Li et al.
        <a class="ltx_ref" href="#bib.bib59" title="">
         2023a
        </a>
        ; Lu et al.
        <a class="ltx_ref" href="#bib.bib67" title="">
         2023a
        </a>
        ; Hsieh et al.
        <a class="ltx_ref" href="#bib.bib39" title="">
         2023
        </a>
        ; Shen et al.
        <a class="ltx_ref" href="#bib.bib92" title="">
         2023
        </a>
        ; Hao et al.
        <a class="ltx_ref" href="#bib.bib36" title="">
         2023b
        </a>
        ; Ge et al.
        <a class="ltx_ref" href="#bib.bib26" title="">
         2023
        </a>
        )
       </cite>
       , level 2=lime]]
[Brain-inspired Planning (5), brain insp
[
       <cite class="ltx_cite ltx_citemacro_citep">
        (Webb et al.
        <a class="ltx_ref" href="#bib.bib109" title="">
         2023
        </a>
        ; Sumers et al.
        <a class="ltx_ref" href="#bib.bib98" title="">
         2023
        </a>
        ; Momennejad et al.
        <a class="ltx_ref" href="#bib.bib73" title="">
         2023
        </a>
        ; Hu et al.
        <a class="ltx_ref" href="#bib.bib43" title="">
         2023d
        </a>
        ; Lin et al.
        <a class="ltx_ref" href="#bib.bib61" title="">
         2023a
        </a>
        )
       </cite>
       , level 2=cyan]]
]
]
      </p>
     </span>
    </div>
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_figure">
      Figure 5:
     </span>
     Taxonomy of recent research in the intersection of LLMs and Planning into categories (#).
Each has scholarly papers based on their unique application or customization of LLMs in addressing various aspects of planning problems.
    </figcaption>
   </figure>
  </section>
 </section>
 <section class="ltx_section" id="Sx3">
  <h2 class="ltx_title ltx_title_section">
   LLMs in APS – Literature Discussion
  </h2>
  <div class="ltx_para" id="Sx3.p1">
   <p class="ltx_p" id="Sx3.p1.1">
    This section dwelves into the diverse applications of LLMs in planning tasks. We have identified eight distinct categories based on the utility and application of LLMs in planning, which are concisely summarized in Table
    <a class="ltx_ref" href="#Sx1.T1" title="Table 1 ‣ Introduction ‣ On the Prospects of Incorporating Large Language Models (LLMs) in Automated Planning and Scheduling (APS)">
     <span class="ltx_text ltx_ref_tag">
      1
     </span>
    </a>
    . Figure
    <a class="ltx_ref" href="#Sx2.F5" title="Figure 5 ‣ LLMs in APS – Literature selection ‣ Background ‣ On the Prospects of Incorporating Large Language Models (LLMs) in Automated Planning and Scheduling (APS)">
     <span class="ltx_text ltx_ref_tag">
      5
     </span>
    </a>
    provides a detailed taxonomy, illustrating the categorization of the identified research papers.
   </p>
  </div>
  <section class="ltx_subsection" id="Sx3.SSx1">
   <h3 class="ltx_title ltx_title_subsection">
    Language Translation
   </h3>
   <div class="ltx_para" id="Sx3.SSx1.p1">
    <p class="ltx_p" id="Sx3.SSx1.p1.1">
     Language translation in the context of LLMs and planning involves transforming natural language instructions into structured planning languages
     <cite class="ltx_cite ltx_citemacro_citep">
      (Wong et al.
      <a class="ltx_ref" href="#bib.bib111" title="">
       2023
      </a>
      ; Kelly et al.
      <a class="ltx_ref" href="#bib.bib55" title="">
       2023
      </a>
      ; Yang
      <a class="ltx_ref" href="#bib.bib123" title="">
       2023
      </a>
      ; Pan et al.
      <a class="ltx_ref" href="#bib.bib79" title="">
       2023
      </a>
      ; Xie et al.
      <a class="ltx_ref" href="#bib.bib115" title="">
       2023
      </a>
      ; Yang, Ishay, and Lee
      <a class="ltx_ref" href="#bib.bib124" title="">
       2023
      </a>
      ; Lin et al.
      <a class="ltx_ref" href="#bib.bib63" title="">
       2023c
      </a>
      ; Sakib and Sun
      <a class="ltx_ref" href="#bib.bib88" title="">
       2023
      </a>
      ; Yang et al.
      <a class="ltx_ref" href="#bib.bib120" title="">
       2023b
      </a>
      ; Parakh et al.
      <a class="ltx_ref" href="#bib.bib80" title="">
       2023
      </a>
      ; Yang et al.
      <a class="ltx_ref" href="#bib.bib119" title="">
       2023a
      </a>
      ; Dai et al.
      <a class="ltx_ref" href="#bib.bib14" title="">
       2023
      </a>
      ; Ding et al.
      <a class="ltx_ref" href="#bib.bib18" title="">
       2023b
      </a>
      ; Zelikman et al.
      <a class="ltx_ref" href="#bib.bib130" title="">
       2023
      </a>
      ; Xu et al.
      <a class="ltx_ref" href="#bib.bib118" title="">
       2023b
      </a>
      ; Chen et al.
      <a class="ltx_ref" href="#bib.bib9" title="">
       2023a
      </a>
      ; You et al.
      <a class="ltx_ref" href="#bib.bib127" title="">
       2023
      </a>
      )
     </cite>
     such as PDDL, and vice versa, utilizing in-context learning techniques
     <cite class="ltx_cite ltx_citemacro_citep">
      (Guan et al.
      <a class="ltx_ref" href="#bib.bib34" title="">
       2023
      </a>
      )
     </cite>
     . This capability effectively bridges the gap between human linguistic expression and machine-understandable formats, enhancing intuitive and efficient planning processes. The LLM+P framework
     <cite class="ltx_cite ltx_citemacro_citep">
      (Liu et al.
      <a class="ltx_ref" href="#bib.bib64" title="">
       2023
      </a>
      )
     </cite>
     exemplifies this by converting natural language descriptions of planning problems into PDDL using GPT-4, leveraging classical planners for solution finding, and then translating these solutions back into natural language, with a specific focus on robot planning scenarios. Additionally, Graph2NL
     <cite class="ltx_cite ltx_citemacro_citep">
      (Chalvatzaki et al.
      <a class="ltx_ref" href="#bib.bib8" title="">
       2023
      </a>
      )
     </cite>
     generates natural language text from scene graphs for long-horizon robot reasoning tasks, while
     <cite class="ltx_cite ltx_citemacro_citep">
      (Shirai et al.
      <a class="ltx_ref" href="#bib.bib93" title="">
       2023
      </a>
      )
     </cite>
     introduces a vision-to-language interpreter for robot task planning. Further,
     <cite class="ltx_cite ltx_citemacro_citep">
      (Brohan et al.
      <a class="ltx_ref" href="#bib.bib5" title="">
       2023
      </a>
      )
     </cite>
     examines the grounding of LLM-generated natural language utterances in actionable robot tasks, and
     <cite class="ltx_cite ltx_citemacro_citep">
      (Yang, Gaglione, and Topcu
      <a class="ltx_ref" href="#bib.bib121" title="">
       2022
      </a>
      )
     </cite>
     utilizes LLMs for creating finite-state automatons for sequential decision-making problems. Despite these advancements, a critical research gap emerges in the autonomous translation capabilities of LLMs, particularly in converting natural language to PDDL without external expert intervention.
    </p>
   </div>
   <div class="ltx_para" id="Sx3.SSx1.p2">
    <span class="ltx_inline-block ltx_framed ltx_framed_rectangle" id="Sx3.SSx1.p2.1" style="border-color: #000000;">
     <span class="ltx_p" id="Sx3.SSx1.p2.1.1">
      While LLMs effectively translate PDDL to natural language,
      <span class="ltx_text ltx_font_bold" id="Sx3.SSx1.p2.1.1.1">
       a notable gap is evident in their limited understanding of real-world objects and the problem of grounding affordances
      </span>
      , mainly when translating natural language to structured languages like PDDL. Addressing this gap calls for integrating neuro-symbolic approaches in LLMs, where the fusion of perceptual experience for concrete concept understanding from knowledge graphs complements LLMs’ proficiency in distributional statistics
      <cite class="ltx_cite ltx_citemacro_citep">
       (Lenat and Marcus
       <a class="ltx_ref" href="#bib.bib58" title="">
        2023
       </a>
       )
      </cite>
      .
     </span>
    </span>
   </div>
  </section>
  <section class="ltx_subsection" id="Sx3.SSx2">
   <h3 class="ltx_title ltx_title_subsection">
    Plan Generation
   </h3>
   <div class="ltx_para" id="Sx3.SSx2.p1">
    <p class="ltx_p" id="Sx3.SSx2.p1.1">
     This category focuses on directly generating plans using LLMs. The research, primarily utilizing causal language models through in-context learning
     <cite class="ltx_cite ltx_citemacro_citep">
      (Sermanet et al.
      <a class="ltx_ref" href="#bib.bib90" title="">
       2023
      </a>
      ; Li et al.
      <a class="ltx_ref" href="#bib.bib60" title="">
       2023b
      </a>
      ; Silver et al.
      <a class="ltx_ref" href="#bib.bib94" title="">
       2023
      </a>
      ; Parakh et al.
      <a class="ltx_ref" href="#bib.bib80" title="">
       2023
      </a>
      ; Zelikman et al.
      <a class="ltx_ref" href="#bib.bib130" title="">
       2023
      </a>
      ; Besta et al.
      <a class="ltx_ref" href="#bib.bib4" title="">
       2023
      </a>
      ; Huang et al.
      <a class="ltx_ref" href="#bib.bib47" title="">
       2023a
      </a>
      ; Dalal et al.
      <a class="ltx_ref" href="#bib.bib15" title="">
       2023
      </a>
      ; Wang et al.
      <a class="ltx_ref" href="#bib.bib106" title="">
       2023b
      </a>
      ; Valmeekam et al.
      <a class="ltx_ref" href="#bib.bib103" title="">
       2022
      </a>
      ; Valmeekam, Marquez, and Kambhampati
      <a class="ltx_ref" href="#bib.bib101" title="">
       2023
      </a>
      ; Gramopadhye and Szafir
      <a class="ltx_ref" href="#bib.bib31" title="">
       2022
      </a>
      ; Singh et al.
      <a class="ltx_ref" href="#bib.bib96" title="">
       2023
      </a>
      )
     </cite>
     <span class="ltx_note ltx_role_footnote" id="footnote1">
      <sup class="ltx_note_mark">
       1
      </sup>
      <span class="ltx_note_outer">
       <span class="ltx_note_content">
        <sup class="ltx_note_mark">
         1
        </sup>
        <span class="ltx_tag ltx_tag_note">
         1
        </span>
        Due to space constraints, only a select number of papers are cited in this section.
       </span>
      </span>
     </span>
     , demonstrates modest performance, indicating notable challenges in employing LLMs for effective plan generation. Novel in-context learning strategies, such as the Chain-of-Symbol and Tree of Thoughts, have been introduced to enhance LLMs’ reasoning capabilities
     <cite class="ltx_cite ltx_citemacro_citep">
      (Hu et al.
      <a class="ltx_ref" href="#bib.bib41" title="">
       2023b
      </a>
      ; Yao et al.
      <a class="ltx_ref" href="#bib.bib125" title="">
       2023
      </a>
      )
     </cite>
     . Efforts to generate multimodal, text, and image-based goal-conditioned plans are exemplified by
     <cite class="ltx_cite ltx_citemacro_citep">
      (Lu et al.
      <a class="ltx_ref" href="#bib.bib69" title="">
       2023b
      </a>
      )
     </cite>
     . Additionally, a subset of studies in this survey investigates the fine-tuning of seq2seq, code-based language models
     <cite class="ltx_cite ltx_citemacro_citep">
      (Pallagani et al.
      <a class="ltx_ref" href="#bib.bib76" title="">
       2022
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib78" title="">
       2023b
      </a>
      )
     </cite>
     , which are noted for their advanced syntactic encoding. These models show promise in improving plan generation within the confines of their training datasets
     <cite class="ltx_cite ltx_citemacro_citep">
      (Logeswaran et al.
      <a class="ltx_ref" href="#bib.bib66" title="">
       2023
      </a>
      )
     </cite>
     , yet exhibit limitations in generalizing to out-of-distribution domains
     <cite class="ltx_cite ltx_citemacro_citep">
      (Pallagani et al.
      <a class="ltx_ref" href="#bib.bib77" title="">
       2023a
      </a>
      )
     </cite>
     , highlighting a gap in their adaptability across diverse planning contexts.
    </p>
   </div>
   <div class="ltx_para" id="Sx3.SSx2.p2">
    <span class="ltx_inline-block ltx_framed ltx_framed_rectangle" id="Sx3.SSx2.p2.1" style="border-color: #000000;">
     <span class="ltx_p" id="Sx3.SSx2.p2.1.1">
      Causal LLMs are predominantly used for plan generation, but their performance is often
      <span class="ltx_text ltx_font_bold" id="Sx3.SSx2.p2.1.1.1">
       limited due to their design, which is focused on generating text based on preceding input.
      </span>
      On the other hand, seq2seq LLMs can generate valid plans but
      <span class="ltx_text ltx_font_bold" id="Sx3.SSx2.p2.1.1.2">
       struggle with generalization across diverse domains.
      </span>
      This limitation highlights an opportunity for a synergistic approach: integrating even imperfect LLM outputs with symbolic planners can expedite heuristic searches, thereby enhancing efficiency and reducing search times
      <cite class="ltx_cite ltx_citemacro_citep">
       (Fabiano et al.
       <a class="ltx_ref" href="#bib.bib23" title="">
        2023
       </a>
       )
      </cite>
      .
     </span>
    </span>
   </div>
  </section>
  <section class="ltx_subsection" id="Sx3.SSx3">
   <h3 class="ltx_title ltx_title_subsection">
    Model Construction
   </h3>
   <div class="ltx_para" id="Sx3.SSx3.p1">
    <p class="ltx_p" id="Sx3.SSx3.p1.1">
     This category employs LLMs to build or refine world and domain models essential for accurate planning.
     <cite class="ltx_cite ltx_citemacro_citet">
      Nottingham et al. (
      <a class="ltx_ref" href="#bib.bib75" title="">
       2023
      </a>
      ); Yuan et al. (
      <a class="ltx_ref" href="#bib.bib128" title="">
       2023a
      </a>
      )
     </cite>
     leverage in-context learning with LLMs to develop an abstract world model in the Minecraft domain, highlighting the challenge of semantic grounding in LLMs. Similarly,
     <cite class="ltx_cite ltx_citemacro_citet">
      Gragera and Pozanco (
      <a class="ltx_ref" href="#bib.bib30" title="">
       2023
      </a>
      )
     </cite>
     explore the capability of LLMs in completing ill-defined PDDL domains. Efforts such as
     <cite class="ltx_cite ltx_citemacro_citep">
      (Huang et al.
      <a class="ltx_ref" href="#bib.bib47" title="">
       2023a
      </a>
      ; Brohan et al.
      <a class="ltx_ref" href="#bib.bib5" title="">
       2023
      </a>
      )
     </cite>
     delve into LLMs’ grounding capabilities, with SayCan
     <cite class="ltx_cite ltx_citemacro_citep">
      (Brohan et al.
      <a class="ltx_ref" href="#bib.bib5" title="">
       2023
      </a>
      )
     </cite>
     notably achieving 74% executable plans.
     <cite class="ltx_cite ltx_citemacro_citet">
      Hao et al. (
      <a class="ltx_ref" href="#bib.bib35" title="">
       2023a
      </a>
      ); Yoneda et al. (
      <a class="ltx_ref" href="#bib.bib126" title="">
       2023
      </a>
      )
     </cite>
     innovatively positions LLMs as both world models and reasoning agents, enabling the simulation of world states and prediction of action outcomes. Research by
     <cite class="ltx_cite ltx_citemacro_citep">
      (Zhang and Soh
      <a class="ltx_ref" href="#bib.bib131" title="">
       2023
      </a>
      ; Wong et al.
      <a class="ltx_ref" href="#bib.bib111" title="">
       2023
      </a>
      ; Mandi, Jain, and Song
      <a class="ltx_ref" href="#bib.bib71" title="">
       2023
      </a>
      ; Hu et al.
      <a class="ltx_ref" href="#bib.bib40" title="">
       2023a
      </a>
      ; Zhao, Lee, and Hsu
      <a class="ltx_ref" href="#bib.bib136" title="">
       2023
      </a>
      ; Ding et al.
      <a class="ltx_ref" href="#bib.bib18" title="">
       2023b
      </a>
      ; Huang et al.
      <a class="ltx_ref" href="#bib.bib47" title="">
       2023a
      </a>
      ; Wu et al.
      <a class="ltx_ref" href="#bib.bib114" title="">
       2023b
      </a>
      ; Xu et al.
      <a class="ltx_ref" href="#bib.bib118" title="">
       2023b
      </a>
      ; Brohan et al.
      <a class="ltx_ref" href="#bib.bib5" title="">
       2023
      </a>
      )
     </cite>
     shows that LLMs can effectively model high-level human states and behaviors using their commonsense knowledge. Yet, they face difficulties accurately processing low-level geometrical or shape features due to spatial and numerical reasoning constraints. Additionally,
     <cite class="ltx_cite ltx_citemacro_citet">
      Kelly et al. (
      <a class="ltx_ref" href="#bib.bib55" title="">
       2023
      </a>
      )
     </cite>
     investigates the potential of LLMs in conjunction with planners to craft narratives and logical story models, integrating human-in-the-loop for iterative edits.
    </p>
   </div>
   <div class="ltx_para" id="Sx3.SSx3.p2">
    <span class="ltx_inline-block ltx_framed ltx_framed_rectangle" id="Sx3.SSx3.p2.1" style="border-color: #000000;">
     <span class="ltx_p" id="Sx3.SSx3.p2.1.1">
      LLMs often
      <span class="ltx_text ltx_font_bold" id="Sx3.SSx3.p2.1.1.1">
       struggle with detailed spatial reasoning and processing low-level environmental features, limiting their effectiveness in model construction.
      </span>
      Integrating world models presents a viable solution, offering advanced abstractions for reasoning that encompass human-like cognitive elements and interactions, thereby enhancing LLMs’ capabilities in model construction
      <cite class="ltx_cite ltx_citemacro_citep">
       (Hu and Shu
       <a class="ltx_ref" href="#bib.bib44" title="">
        2023
       </a>
       )
      </cite>
      .
     </span>
    </span>
   </div>
  </section>
  <section class="ltx_subsection" id="Sx3.SSx4">
   <h3 class="ltx_title ltx_title_subsection">
    Multi-agent Planning
   </h3>
   <div class="ltx_para" id="Sx3.SSx4.p1">
    <p class="ltx_p" id="Sx3.SSx4.p1.1">
     In multi-agent planning, LLMs play a vital role in scenarios involving interaction among multiple agents, typically modeled using distinct LLMs. These models enhance coordination and cooperation, leading to more complex and effective multi-agent strategies.
     <cite class="ltx_cite ltx_citemacro_citep">
      (Zhang et al.
      <a class="ltx_ref" href="#bib.bib134" title="">
       2023b
      </a>
      )
     </cite>
     introduces an innovative framework that employs LLMs to develop cooperative embodied agents. AutoGraph
     <cite class="ltx_cite ltx_citemacro_citep">
      (Wei et al.
      <a class="ltx_ref" href="#bib.bib110" title="">
       2023
      </a>
      )
     </cite>
     leverages LLMs to generate autonomous agents adept at devising solutions for varied graph-structured data problems. Addressing scalability in multi-robot task planning,
     <cite class="ltx_cite ltx_citemacro_citep">
      (Chen et al.
      <a class="ltx_ref" href="#bib.bib12" title="">
       2023d
      </a>
      )
     </cite>
     proposes frameworks for the collaborative function of different LLM-based agents. Furthermore,
     <cite class="ltx_cite ltx_citemacro_citep">
      (Abdelnabi et al.
      <a class="ltx_ref" href="#bib.bib1" title="">
       2023
      </a>
      )
     </cite>
     and
     <cite class="ltx_cite ltx_citemacro_citep">
      (Hua et al.
      <a class="ltx_ref" href="#bib.bib45" title="">
       2023
      </a>
      )
     </cite>
     collectively demonstrate the effectiveness of LLM agents in complex negotiation and decision-making environments.
    </p>
   </div>
   <div class="ltx_para" id="Sx3.SSx4.p2">
    <span class="ltx_inline-block ltx_framed ltx_framed_rectangle" id="Sx3.SSx4.p2.1" style="border-color: #000000;">
     <span class="ltx_p" id="Sx3.SSx4.p2.1.1">
      A key gap in multi-agent planning with LLMs lies in
      <span class="ltx_text ltx_font_bold" id="Sx3.SSx4.p2.1.1.1">
       standardizing inter-agent communication and maintaining distinct belief states, including human aspects.
      </span>
      Overcoming this requires advanced LLM algorithms for dynamic alignment of communication and belief states, drawing on epistemic reasoning and knowledge representation
      <cite class="ltx_cite ltx_citemacro_citep">
       (de Zarzà et al.
       <a class="ltx_ref" href="#bib.bib16" title="">
        2023
       </a>
       )
      </cite>
      .
     </span>
    </span>
   </div>
  </section>
  <section class="ltx_subsection" id="Sx3.SSx5">
   <h3 class="ltx_title ltx_title_subsection">
    Interactive Planning
   </h3>
   <div class="ltx_para" id="Sx3.SSx5.p1">
    <p class="ltx_p" id="Sx3.SSx5.p1.1">
     In this category, LLMs are utilized in dynamic scenarios where real-time adaptability to user feedback or iterative planning is essential. The refinement of LLM outputs is typically achieved through four primary feedback variants:
     <span class="ltx_inline-enumerate" id="Sx3.I1">
      <span class="ltx_inline-item" id="Sx3.I1.i1">
       <span class="ltx_tag ltx_tag_inline-item">
        <span class="ltx_text ltx_font_bold" id="Sx3.I1.i1.1.1.1">
         (a)
        </span>
       </span>
       <span class="ltx_text" id="Sx3.I1.i1.4">
        External verifiers, such as VAL
        <cite class="ltx_cite ltx_citemacro_citep">
         (Howey, Long, and Fox
         <a class="ltx_ref" href="#bib.bib38" title="">
          2004
         </a>
         )
        </cite>
        for PDDL or scene descriptors and success detectors in robotics
        <cite class="ltx_cite ltx_citemacro_citep">
         (Guan et al.
         <a class="ltx_ref" href="#bib.bib34" title="">
          2023
         </a>
         ; Arora and Kambhampati
         <a class="ltx_ref" href="#bib.bib2" title="">
          2023
         </a>
         ; Jha et al.
         <a class="ltx_ref" href="#bib.bib50" title="">
          2023
         </a>
         ; Huang et al.
         <a class="ltx_ref" href="#bib.bib49" title="">
          2022b
         </a>
         ; Liu, Bahety, and Song
         <a class="ltx_ref" href="#bib.bib65" title="">
          2023
         </a>
         ; Rana et al.
         <a class="ltx_ref" href="#bib.bib84" title="">
          2023
         </a>
         ; Ren et al.
         <a class="ltx_ref" href="#bib.bib85" title="">
          2023
         </a>
         ; Kim et al.
         <a class="ltx_ref" href="#bib.bib56" title="">
          2023
         </a>
         ; Graule and Isler
         <a class="ltx_ref" href="#bib.bib32" title="">
          2023
         </a>
         ; Driess et al.
         <a class="ltx_ref" href="#bib.bib20" title="">
          2023
         </a>
         ; Zheng et al.
         <a class="ltx_ref" href="#bib.bib138" title="">
          2023b
         </a>
         )
        </cite>
        ;
       </span>
      </span>
      <span class="ltx_inline-item" id="Sx3.I1.i2">
       <span class="ltx_tag ltx_tag_inline-item">
        <span class="ltx_text ltx_font_bold" id="Sx3.I1.i2.1.1.1">
         (b)
        </span>
       </span>
       <span class="ltx_text" id="Sx3.I1.i2.4">
        Online reinforcement learning, which progressively updates the LLM about environmental changes
        <cite class="ltx_cite ltx_citemacro_citep">
         (Carta et al.
         <a class="ltx_ref" href="#bib.bib7" title="">
          2023
         </a>
         )
        </cite>
        ;
       </span>
      </span>
      <span class="ltx_inline-item" id="Sx3.I1.i3">
       <span class="ltx_tag ltx_tag_inline-item">
        <span class="ltx_text ltx_font_bold" id="Sx3.I1.i3.1.1.1">
         (c)
        </span>
       </span>
       <span class="ltx_text" id="Sx3.I1.i3.4">
        Self-refinement by LLMs, where they provide feedback on their own outputs
        <cite class="ltx_cite ltx_citemacro_citep">
         (Zhou et al.
         <a class="ltx_ref" href="#bib.bib139" title="">
          2023
         </a>
         ; Hu et al.
         <a class="ltx_ref" href="#bib.bib42" title="">
          2023c
         </a>
         ,
         <a class="ltx_ref" href="#bib.bib41" title="">
          b
         </a>
         ; Ding et al.
         <a class="ltx_ref" href="#bib.bib17" title="">
          2023a
         </a>
         ; Sun et al.
         <a class="ltx_ref" href="#bib.bib99" title="">
          2023
         </a>
         ; Naik et al.
         <a class="ltx_ref" href="#bib.bib74" title="">
          2023
         </a>
         )
        </cite>
        ;
       </span>
      </span>
      <span class="ltx_inline-item" id="Sx3.I1.i4">
       <span class="ltx_tag ltx_tag_inline-item">
        <span class="ltx_text ltx_font_bold" id="Sx3.I1.i4.1.1.1">
         (d)
        </span>
       </span>
       <span class="ltx_text" id="Sx3.I1.i4.4">
        Input from human experts
        <cite class="ltx_cite ltx_citemacro_citep">
         (Raman et al.
         <a class="ltx_ref" href="#bib.bib83" title="">
          2022
         </a>
         ; Wu, Ai, and Hsu
         <a class="ltx_ref" href="#bib.bib113" title="">
          2023
         </a>
         )
        </cite>
        .
       </span>
      </span>
     </span>
     Furthermore,
     <cite class="ltx_cite ltx_citemacro_citep">
      (Chen et al.
      <a class="ltx_ref" href="#bib.bib10" title="">
       2023b
      </a>
      )
     </cite>
     introduces the “Action Before Action” method, enabling LLMs to proactively seek relevant information from external sources in natural language, thereby improving embodied decision-making in LLMs by 40%.
    </p>
   </div>
   <div class="ltx_para" id="Sx3.SSx5.p2">
    <span class="ltx_inline-block ltx_framed ltx_framed_rectangle" id="Sx3.SSx5.p2.1" style="border-color: #000000;">
     <span class="ltx_p" id="Sx3.SSx5.p2.1.1">
      A key gap in interactive planning with LLMs lies in harmonizing the “fast” neural processing of LLMs with “slow” symbolic reasoning, as manifested in feedback mechanisms. This integration is key to
      <span class="ltx_text ltx_font_bold" id="Sx3.SSx5.p2.1.1.1">
       maintaining the neural speed of LLMs while effectively embedding the depth and precision of feedback
      </span>
      , which is vital for accuracy in dynamic planning scenarios
      <cite class="ltx_cite ltx_citemacro_citep">
       (Zhang et al.
       <a class="ltx_ref" href="#bib.bib132" title="">
        2023a
       </a>
       )
      </cite>
      .
     </span>
    </span>
   </div>
  </section>
  <section class="ltx_subsection" id="Sx3.SSx6">
   <h3 class="ltx_title ltx_title_subsection">
    Heuristics Optimization
   </h3>
   <div class="ltx_para" id="Sx3.SSx6.p1">
    <p class="ltx_p" id="Sx3.SSx6.p1.1">
     In the realm of Heuristics Optimization, LLMs are leveraged to enhance planning processes, either by refining existing plans or aiding symbolic planners with heuristic guidance. Studies like
     <cite class="ltx_cite ltx_citemacro_citep">
      (Hazra, Martires, and De Raedt
      <a class="ltx_ref" href="#bib.bib37" title="">
       2023
      </a>
      ; Hao et al.
      <a class="ltx_ref" href="#bib.bib35" title="">
       2023a
      </a>
      ; Dai et al.
      <a class="ltx_ref" href="#bib.bib14" title="">
       2023
      </a>
      ; Feng et al.
      <a class="ltx_ref" href="#bib.bib24" title="">
       2023
      </a>
      )
     </cite>
     have effectively coupled LLMs with heuristic searches to identify optimal action sequences. Research by
     <cite class="ltx_cite ltx_citemacro_citep">
      (Silver et al.
      <a class="ltx_ref" href="#bib.bib95" title="">
       2022
      </a>
      ; Shah et al.
      <a class="ltx_ref" href="#bib.bib91" title="">
       2023
      </a>
      ; Valmeekam et al.
      <a class="ltx_ref" href="#bib.bib104" title="">
       2023b
      </a>
      )
     </cite>
     reveals that LLMs’ outputs, even if partially correct, can provide valuable direction for symbolic planners such as LPG
     <cite class="ltx_cite ltx_citemacro_citep">
      (Gerevini and Serina
      <a class="ltx_ref" href="#bib.bib28" title="">
       2002
      </a>
      )
     </cite>
     , especially in problems beyond the LLMs’ solvable scope. Furthermore,
     <cite class="ltx_cite ltx_citemacro_citep">
      (Raimondo et al.
      <a class="ltx_ref" href="#bib.bib81" title="">
       2023
      </a>
      )
     </cite>
     makes an intriguing observation that including workflows and action plans in LLM input prompts can notably enhance task-oriented dialogue generalization.
    </p>
   </div>
   <div class="ltx_para" id="Sx3.SSx6.p2">
    <span class="ltx_inline-block ltx_framed ltx_framed_rectangle" id="Sx3.SSx6.p2.1" style="border-color: #000000;">
     <span class="ltx_p" id="Sx3.SSx6.p2.1.1">
      This category marks significant progress towards realizing neuro-symbolic approaches in APS.
      <span class="ltx_text ltx_font_bold" id="Sx3.SSx6.p2.1.1.1">
       Current methods emphasize plan validity, often at the expense of time efficiency.
      </span>
      Future research should look at how to continually evolve LLMs for better plan generation, with its experience from complimenting symbolic planners
      <cite class="ltx_cite ltx_citemacro_citep">
       (Du et al.
       <a class="ltx_ref" href="#bib.bib21" title="">
        2023
       </a>
       )
      </cite>
      .
     </span>
    </span>
   </div>
  </section>
  <section class="ltx_subsection" id="Sx3.SSx7">
   <h3 class="ltx_title ltx_title_subsection">
    Tool Integration
   </h3>
   <div class="ltx_para" id="Sx3.SSx7.p1">
    <p class="ltx_p" id="Sx3.SSx7.p1.1">
     In tool integration, LLMs serve as coordinators within a diverse array of planning tools, enhancing functionality in complex scenarios. Studies like
     <cite class="ltx_cite ltx_citemacro_citep">
      (Xu et al.
      <a class="ltx_ref" href="#bib.bib116" title="">
       2023a
      </a>
      ; Lu et al.
      <a class="ltx_ref" href="#bib.bib67" title="">
       2023a
      </a>
      ; Shen et al.
      <a class="ltx_ref" href="#bib.bib92" title="">
       2023
      </a>
      ; Hao et al.
      <a class="ltx_ref" href="#bib.bib36" title="">
       2023b
      </a>
      ; Ge et al.
      <a class="ltx_ref" href="#bib.bib26" title="">
       2023
      </a>
      )
     </cite>
     demonstrate that incorporating tools such as web search engines, Python functions, and API endpoints enhances LLM reasoning abilities. However,
     <cite class="ltx_cite ltx_citemacro_citep">
      (Ruan et al.
      <a class="ltx_ref" href="#bib.bib86" title="">
       2023
      </a>
      )
     </cite>
     notes a tendency for LLMs to over-rely on specific tools, potentially prolonging the planning process.
     <cite class="ltx_cite ltx_citemacro_citep">
      (Li et al.
      <a class="ltx_ref" href="#bib.bib59" title="">
       2023a
      </a>
      )
     </cite>
     introduces a benchmark for tool-augmented LLMs. While typical approaches involve teaching LLMs tool usage via multiple prompts,
     <cite class="ltx_cite ltx_citemacro_citep">
      (Hsieh et al.
      <a class="ltx_ref" href="#bib.bib39" title="">
       2023
      </a>
      )
     </cite>
     suggests that leveraging tool documentation offers improved planning capabilities, circumventing the need for extensive demonstrations.
    </p>
   </div>
   <div class="ltx_para" id="Sx3.SSx7.p2">
    <span class="ltx_inline-block ltx_framed ltx_framed_rectangle" id="Sx3.SSx7.p2.1" style="border-color: #000000;">
     <span class="ltx_p" id="Sx3.SSx7.p2.1.1">
      LLMs often
      <span class="ltx_text ltx_font_bold" id="Sx3.SSx7.p2.1.1.1">
       hallucinate non-existent tools, overuse a single tool, and face scaling challenges with multiple tools.
      </span>
      Overcoming these issues is key to enabling LLMs to effectively select and utilize various tools in complex planning scenarios
      <cite class="ltx_cite ltx_citemacro_citep">
       (Elaraby et al.
       <a class="ltx_ref" href="#bib.bib22" title="">
        2023
       </a>
       )
      </cite>
      .
     </span>
    </span>
   </div>
  </section>
  <section class="ltx_subsection" id="Sx3.SSx8">
   <h3 class="ltx_title ltx_title_subsection">
    Brain-Inspired Planning
   </h3>
   <div class="ltx_para" id="Sx3.SSx8.p1">
    <p class="ltx_p" id="Sx3.SSx8.p1.1">
     This area explores neurologically and cognitively inspired architectures in LLMs
     <cite class="ltx_cite ltx_citemacro_citep">
      (Webb et al.
      <a class="ltx_ref" href="#bib.bib109" title="">
       2023
      </a>
      ; Sumers et al.
      <a class="ltx_ref" href="#bib.bib98" title="">
       2023
      </a>
      ; Momennejad et al.
      <a class="ltx_ref" href="#bib.bib73" title="">
       2023
      </a>
      ; Hu et al.
      <a class="ltx_ref" href="#bib.bib43" title="">
       2023d
      </a>
      ; Lin et al.
      <a class="ltx_ref" href="#bib.bib61" title="">
       2023a
      </a>
      )
     </cite>
     , aiming to replicate human-like planning in enhancing problem-solving. However, while these methods rely on in-context learning, they frequently encounter challenges such as hallucination and grounding, as previously discussed, and tend to be more computationally intensive than in-context learning alone.
    </p>
   </div>
   <div class="ltx_para" id="Sx3.SSx8.p2">
    <span class="ltx_inline-block ltx_framed ltx_framed_rectangle" id="Sx3.SSx8.p2.1" style="border-color: #000000;">
     <span class="ltx_p" id="Sx3.SSx8.p2.1.1">
      While LLMs attempt to mimic symbolic solvers through in-context learning for brain-inspired modules, this approach
      <span class="ltx_text ltx_font_bold" id="Sx3.SSx8.p2.1.1.1">
       lacks adaptability and is a superficial understanding of complex cognitive processes.
      </span>
      To overcome these issues, developing systems where neural and symbolic components are intrinsically intertwined is critical as it would accurately mirror human cognitive capabilities in planning
      <cite class="ltx_cite ltx_citemacro_citep">
       (Fabiano et al.
       <a class="ltx_ref" href="#bib.bib23" title="">
        2023
       </a>
       )
      </cite>
      .
     </span>
    </span>
   </div>
  </section>
 </section>
 <section class="ltx_section" id="Sx4">
  <h2 class="ltx_title ltx_title_section">
   Discussion and Conclusion
  </h2>
  <div class="ltx_para" id="Sx4.p1">
   <p class="ltx_p" id="Sx4.p1.1">
    In this position paper, we comprehensively investigate the role of LLMs within the domain of APS, analyzing 126 scholarly articles across eight distinct categories. This extensive survey not only provides a detailed landscape of current LLM applications and their limitations but also highlights the volume of research in each category: Language Translation with 23 papers demonstrates LLMs’ proficiency, whereas Plan Generation, the most researched category with 53 papers, reveals their shortcomings in optimality, completeness, and correctness compared to traditional combinatorial planners. Our exploration extends to Model Construction (17 papers), which examines LLMs in developing planning models, and the relatively unexplored area of Multi-agent Planning (4 papers). Interactive Planning is well represented with 21 papers, illustrating LLMs’ adaptability in feedback-centric scenarios. Despite being less researched, Heuristics Optimization and Tool Integration, each with 8 papers, provide valuable insights into efficiency enhancement and integration of LLMs with symbolic solvers. Lastly, Brain-inspired Planning, although least represented with 5 papers, opens innovative avenues for human-like planning processes in LLMs. By identifying the research distribution and gaps in these categories, our paper proposes how neuro-symbolic approaches can address these voids, thereby underscoring the varying degrees of LLM applications in APS and guiding future research towards enhancing their capabilities in complex planning tasks.
   </p>
  </div>
  <div class="ltx_para" id="Sx4.p2">
   <p class="ltx_p" id="Sx4.p2.1">
    It is important to acknowledge that while LLMs have shown promise, they are not a panacea for the inherent complexities of automated planning. The expectation that LLMs, operating within polynomial run-time bounds, could supplant the nuanced and often non-polynomial complexities of symbolic planners is not yet realizable. Indeed, the strengths of LLMs do not currently include generating sequences of actions akin to those devised by symbolic planners, which are essential for creating a coherent and practical plan for complex problems. However, this does not diminish the potential utility of LLMs within this space. When considering average-case scenarios, which are typically less complex than worst-case scenarios, LLMs could offer substantial efficiencies. They can be seen as akin to meta-heuristic approaches, capable of accelerating plan generation in a variety of settings. As such, their application, governed by cognitive-inspired frameworks like SOFAI
    <cite class="ltx_cite ltx_citemacro_citep">
     (Fabiano et al.
     <a class="ltx_ref" href="#bib.bib23" title="">
      2023
     </a>
     )
    </cite>
    , could delineate when and where their use is most advantageous.
   </p>
  </div>
  <div class="ltx_para" id="Sx4.p3">
   <p class="ltx_p" id="Sx4.p3.1">
    Future research should prioritize three areas: developing new LLM training paradigms that ensure coherence and goal alignment in outputs; delving into Henry Kautz’s neuro-symbolic taxonomies
    <cite class="ltx_cite ltx_citemacro_citep">
     (Kautz
     <a class="ltx_ref" href="#bib.bib54" title="">
      2022
     </a>
     )
    </cite>
    to better integrate neural and symbolic methods; and establishing clear performance metrics for LLM-assisted planners. In conclusion, integrating LLMs into automated planning, while challenging, opens avenues for innovation. Embracing a symbiotic approach that combines the creative strengths of LLMs with the precision of symbolic planners can lead to more effective, sophisticated AI applications in planning.
   </p>
  </div>
 </section>
 <section class="ltx_bibliography" id="bib">
  <h2 class="ltx_title ltx_title_bibliography">
   References
  </h2>
  <ul class="ltx_biblist">
   <li class="ltx_bibitem" id="bib.bib1">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Abdelnabi et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Abdelnabi, S.; Gomaa, A.; Sivaprasad, S.; Schönherr, L.; and Fritz, M. 2023.
    </span>
    <span class="ltx_bibblock">
     Llm-deliberation: Evaluating llms with interactive multi-agent negotiation games.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">
      arXiv preprint arXiv:2309.17234
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib2">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Arora and Kambhampati (2023)
    </span>
    <span class="ltx_bibblock">
     Arora, D.; and Kambhampati, S. 2023.
    </span>
    <span class="ltx_bibblock">
     Learning and Leveraging Verifiers to Improve Planning Capabilities of Pre-trained Language Models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">
      arXiv preprint arXiv:2305.17077
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib3">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Asai (2018)
    </span>
    <span class="ltx_bibblock">
     Asai, M. 2018.
    </span>
    <span class="ltx_bibblock">
     Photo-Realistic Blocksworld Dataset.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">
      arXiv preprint arXiv:1812.01818
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib4">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Besta et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Besta, M.; Blach, N.; Kubicek, A.; Gerstenberger, R.; Gianinazzi, L.; Gajda, J.; Lehmann, T.; Podstawski, M.; Niewiadomski, H.; Nyczyk, P.; et al. 2023.
    </span>
    <span class="ltx_bibblock">
     Graph of thoughts: Solving elaborate problems with large language models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">
      arXiv preprint arXiv:2308.09687
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib5">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Brohan et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Brohan, A.; Chebotar, Y.; Finn, C.; Hausman, K.; Herzog, A.; Ho, D.; Ibarz, J.; Irpan, A.; Jang, E.; Julian, R.; et al. 2023.
    </span>
    <span class="ltx_bibblock">
     Do as i can, not as i say: Grounding language in robotic affordances.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">
      Conference on Robot Learning
     </em>
     , 287–318. PMLR.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib6">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Capitanelli and Mastrogiovanni (2023)
    </span>
    <span class="ltx_bibblock">
     Capitanelli, A.; and Mastrogiovanni, F. 2023.
    </span>
    <span class="ltx_bibblock">
     A Framework to Generate Neurosymbolic PDDL-compliant Planners.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">
      arXiv preprint arXiv:2303.00438
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib7">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Carta et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Carta, T.; Romac, C.; Wolf, T.; Lamprier, S.; Sigaud, O.; and Oudeyer, P.-Y. 2023.
    </span>
    <span class="ltx_bibblock">
     Grounding large language models in interactive environments with online reinforcement learning.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">
      arXiv preprint arXiv:2302.02662
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib8">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Chalvatzaki et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Chalvatzaki, G.; Younes, A.; Nandha, D.; Le, A. T.; Ribeiro, L. F.; and Gurevych, I. 2023.
    </span>
    <span class="ltx_bibblock">
     Learning to reason over scene graphs: a case study of finetuning GPT-2 into a robot language model for grounded task planning.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">
      Frontiers in Robotics and AI
     </em>
     , 10.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib9">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Chen et al. (2023a)
    </span>
    <span class="ltx_bibblock">
     Chen, B.; Xia, F.; Ichter, B.; Rao, K.; Gopalakrishnan, K.; Ryoo, M. S.; Stone, A.; and Kappler, D. 2023a.
    </span>
    <span class="ltx_bibblock">
     Open-vocabulary queryable scene representations for real world planning.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">
      2023 IEEE International Conference on Robotics and Automation (ICRA)
     </em>
     , 11509–11522. IEEE.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib10">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Chen et al. (2023b)
    </span>
    <span class="ltx_bibblock">
     Chen, X.; Zhang, S.; Zhang, P.; Zhao, L.; and Chen, J. 2023b.
    </span>
    <span class="ltx_bibblock">
     Asking Before Action: Gather Information in Embodied Decision Making with Language Models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">
      arXiv preprint arXiv:2305.15695
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib11">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Chen et al. (2023c)
    </span>
    <span class="ltx_bibblock">
     Chen, Y.; Arkin, J.; Zhang, Y.; Roy, N.; and Fan, C. 2023c.
    </span>
    <span class="ltx_bibblock">
     AutoTAMP: Autoregressive Task and Motion Planning with LLMs as Translators and Checkers.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">
      arXiv preprint arXiv:2306.06531
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib12">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Chen et al. (2023d)
    </span>
    <span class="ltx_bibblock">
     Chen, Y.; Arkin, J.; Zhang, Y.; Roy, N.; and Fan, C. 2023d.
    </span>
    <span class="ltx_bibblock">
     Scalable Multi-Robot Collaboration with Large Language Models: Centralized or Decentralized Systems?
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">
      arXiv preprint arXiv:2309.15943
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib13">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Dagan, Keller, and Lascarides (2023)
    </span>
    <span class="ltx_bibblock">
     Dagan, G.; Keller, F.; and Lascarides, A. 2023.
    </span>
    <span class="ltx_bibblock">
     Dynamic Planning with a LLM.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">
      arXiv preprint arXiv:2308.06391
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib14">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Dai et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Dai, Z.; Asgharivaskasi, A.; Duong, T.; Lin, S.; Tzes, M.-E.; Pappas, G.; and Atanasov, N. 2023.
    </span>
    <span class="ltx_bibblock">
     Optimal Scene Graph Planning with Large Language Model Guidance.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">
      arXiv preprint arXiv:2309.09182
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib15">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Dalal et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Dalal, M.; Chiruvolu, T.; Chaplot, D. S.; and Salakhutdinov, R. 2023.
    </span>
    <span class="ltx_bibblock">
     Plan-Seq-Learn: Language Model Guided RL for Solving Long Horizon Robotics Tasks.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">
      2nd Workshop on Language and Robot Learning: Language as Grounding
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib16">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     de Zarzà et al. (2023)
    </span>
    <span class="ltx_bibblock">
     de Zarzà, I.; de Curtò, J.; Roig, G.; Manzoni, P.; and Calafate, C. T. 2023.
    </span>
    <span class="ltx_bibblock">
     Emergent Cooperation and Strategy Adaptation in Multi-Agent Systems: An Extended Coevolutionary Theory with LLMs.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">
      Electronics
     </em>
     , 12(12): 2722.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib17">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Ding et al. (2023a)
    </span>
    <span class="ltx_bibblock">
     Ding, Y.; Zhang, X.; Amiri, S.; Cao, N.; Yang, H.; Kaminski, A.; Esselink, C.; and Zhang, S. 2023a.
    </span>
    <span class="ltx_bibblock">
     Integrating Action Knowledge and LLMs for Task Planning and Situation Handling in Open Worlds.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">
      arXiv preprint arXiv:2305.17590
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib18">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Ding et al. (2023b)
    </span>
    <span class="ltx_bibblock">
     Ding, Y.; Zhang, X.; Paxton, C.; and Zhang, S. 2023b.
    </span>
    <span class="ltx_bibblock">
     Leveraging Commonsense Knowledge from Large Language Models for Task and Motion Planning.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">
      RSS 2023 Workshop on Learning for Task and Motion Planning
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib19">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Ding et al. (2023c)
    </span>
    <span class="ltx_bibblock">
     Ding, Y.; Zhang, X.; Paxton, C.; and Zhang, S. 2023c.
    </span>
    <span class="ltx_bibblock">
     Task and motion planning with large language models for object rearrangement.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">
      arXiv preprint arXiv:2303.06247
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib20">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Driess et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Driess, D.; Xia, F.; Sajjadi, M. S.; Lynch, C.; Chowdhery, A.; Ichter, B.; Wahid, A.; Tompson, J.; Vuong, Q.; Yu, T.; et al. 2023.
    </span>
    <span class="ltx_bibblock">
     Palm-e: An embodied multimodal language model.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">
      arXiv preprint arXiv:2303.03378
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib21">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Du et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Du, M.; Luu, A. T.; Ji, B.; and Ng, S.-k. 2023.
    </span>
    <span class="ltx_bibblock">
     From Static to Dynamic: A Continual Learning Framework for Large Language Models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">
      arXiv preprint arXiv:2310.14248
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib22">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Elaraby et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Elaraby, M.; Lu, M.; Dunn, J.; Zhang, X.; Wang, Y.; and Liu, S. 2023.
    </span>
    <span class="ltx_bibblock">
     Halo: Estimation and reduction of hallucinations in open-source weak large language models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">
      arXiv preprint arXiv:2308.11764
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib23">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Fabiano et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Fabiano, F.; Pallagani, V.; Ganapini, M. B.; Horesh, L.; Loreggia, A.; Murugesan, K.; Rossi, F.; and Srivastava, B. 2023.
    </span>
    <span class="ltx_bibblock">
     Fast and Slow Planning.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">
      arXiv preprint arXiv:2303.04283
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib24">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Feng et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Feng, X.; Wan, Z.; Wen, M.; Wen, Y.; Zhang, W.; and Wang, J. 2023.
    </span>
    <span class="ltx_bibblock">
     Alphazero-like tree-search can guide large language model decoding and training.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">
      arXiv preprint arXiv:2309.17179
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib25">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Gandhi, Sadigh, and Goodman (2023)
    </span>
    <span class="ltx_bibblock">
     Gandhi, K.; Sadigh, D.; and Goodman, N. D. 2023.
    </span>
    <span class="ltx_bibblock">
     Strategic Reasoning with Language Models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib25.1.1">
      arXiv preprint arXiv:2305.19165
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib26">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Ge et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Ge, Y.; Hua, W.; Ji, J.; Tan, J.; Xu, S.; and Zhang, Y. 2023.
    </span>
    <span class="ltx_bibblock">
     Openagi: When llm meets domain experts.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib26.1.1">
      arXiv preprint arXiv:2304.04370
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib27">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Georgievski and Aiello (2015)
    </span>
    <span class="ltx_bibblock">
     Georgievski, I.; and Aiello, M. 2015.
    </span>
    <span class="ltx_bibblock">
     HTN planning: Overview, comparison, and beyond.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">
      Artif. Intell.
     </em>
     , 222: 124–156.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib28">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Gerevini and Serina (2002)
    </span>
    <span class="ltx_bibblock">
     Gerevini, A.; and Serina, I. 2002.
    </span>
    <span class="ltx_bibblock">
     LPG: A Planner Based on Local Search for Planning Graphs with Action Costs.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib28.1.1">
      Aips
     </em>
     , volume 2, 281–290.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib29">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Ghallab, Nau, and Traverso (2004)
    </span>
    <span class="ltx_bibblock">
     Ghallab, M.; Nau, D.; and Traverso, P. 2004.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib29.1.1">
      Automated Planning: Theory and Practice
     </em>
     .
    </span>
    <span class="ltx_bibblock">
     The Morgan Kaufmann Series in Artificial Intelligence. Amsterdam: Morgan Kaufmann.
    </span>
    <span class="ltx_bibblock">
     ISBN 978-1-55860-856-6.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib30">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Gragera and Pozanco (2023)
    </span>
    <span class="ltx_bibblock">
     Gragera, A.; and Pozanco, A. 2023.
    </span>
    <span class="ltx_bibblock">
     Exploring the Limitations of using Large Language Models to Fix Planning Tasks.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib31">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Gramopadhye and Szafir (2022)
    </span>
    <span class="ltx_bibblock">
     Gramopadhye, M.; and Szafir, D. 2022.
    </span>
    <span class="ltx_bibblock">
     Generating executable action plans with environmentally-aware language models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib31.1.1">
      arXiv preprint arXiv:2210.04964
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib32">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Graule and Isler (2023)
    </span>
    <span class="ltx_bibblock">
     Graule, M. A.; and Isler, V. 2023.
    </span>
    <span class="ltx_bibblock">
     GG-LLM: Geometrically Grounding Large Language Models for Zero-shot Human Activity Forecasting in Human-Aware Task Planning.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib32.1.1">
      arXiv preprint arXiv:2310.20034
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib33">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Gu et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Gu, Q.; Kuwajerwala, A.; Morin, S.; Jatavallabhula, K. M.; Sen, B.; Agarwal, A.; Rivera, C.; Paul, W.; Ellis, K.; Chellappa, R.; et al. 2023.
    </span>
    <span class="ltx_bibblock">
     Conceptgraphs: Open-vocabulary 3d scene graphs for perception and planning.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib33.1.1">
      arXiv preprint arXiv:2309.16650
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib34">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Guan et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Guan, L.; Valmeekam, K.; Sreedharan, S.; and Kambhampati, S. 2023.
    </span>
    <span class="ltx_bibblock">
     Leveraging Pre-trained Large Language Models to Construct and Utilize World Models for Model-based Task Planning.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib34.1.1">
      arXiv preprint arXiv:2305.14909
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib35">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Hao et al. (2023a)
    </span>
    <span class="ltx_bibblock">
     Hao, S.; Gu, Y.; Ma, H.; Hong, J. J.; Wang, Z.; Wang, D. Z.; and Hu, Z. 2023a.
    </span>
    <span class="ltx_bibblock">
     Reasoning with language model is planning with world model.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib35.1.1">
      arXiv preprint arXiv:2305.14992
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib36">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Hao et al. (2023b)
    </span>
    <span class="ltx_bibblock">
     Hao, S.; Liu, T.; Wang, Z.; and Hu, Z. 2023b.
    </span>
    <span class="ltx_bibblock">
     ToolkenGPT: Augmenting Frozen Language Models with Massive Tools via Tool Embeddings.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib36.1.1">
      arXiv preprint arXiv:2305.11554
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib37">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Hazra, Martires, and De Raedt (2023)
    </span>
    <span class="ltx_bibblock">
     Hazra, R.; Martires, P. Z. D.; and De Raedt, L. 2023.
    </span>
    <span class="ltx_bibblock">
     SayCanPay: Heuristic Planning with Large Language Models using Learnable Domain Knowledge.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib37.1.1">
      arXiv preprint arXiv:2308.12682
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib38">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Howey, Long, and Fox (2004)
    </span>
    <span class="ltx_bibblock">
     Howey, R.; Long, D.; and Fox, M. 2004.
    </span>
    <span class="ltx_bibblock">
     VAL: automatic plan validation, continuous effects and mixed initiative planning using PDDL.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib38.1.1">
      16th IEEE International Conference on Tools with Artificial Intelligence
     </em>
     , 294–301.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib39">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Hsieh et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Hsieh, C.-Y.; Chen, S.-A.; Li, C.-L.; Fujii, Y.; Ratner, A.; Lee, C.-Y.; Krishna, R.; and Pfister, T. 2023.
    </span>
    <span class="ltx_bibblock">
     Tool documentation enables zero-shot tool-usage with large language models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib39.1.1">
      arXiv preprint arXiv:2308.00675
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib40">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Hu et al. (2023a)
    </span>
    <span class="ltx_bibblock">
     Hu, B.; Zhao, C.; Zhang, P.; Zhou, Z.; Yang, Y.; Xu, Z.; and Liu, B. 2023a.
    </span>
    <span class="ltx_bibblock">
     Enabling Efficient Interaction between an Algorithm Agent and an LLM: A Reinforcement Learning Approach.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib40.1.1">
      arXiv preprint arXiv:2306.03604
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib41">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Hu et al. (2023b)
    </span>
    <span class="ltx_bibblock">
     Hu, H.; Lu, H.; Zhang, H.; Lam, W.; and Zhang, Y. 2023b.
    </span>
    <span class="ltx_bibblock">
     Chain-of-Symbol Prompting Elicits Planning in Large Langauge Models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib41.1.1">
      arXiv preprint arXiv:2305.10276
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib42">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Hu et al. (2023c)
    </span>
    <span class="ltx_bibblock">
     Hu, M.; Mu, Y.; Yu, X.; Ding, M.; Wu, S.; Shao, W.; Chen, Q.; Wang, B.; Qiao, Y.; and Luo, P. 2023c.
    </span>
    <span class="ltx_bibblock">
     Tree-Planner: Efficient Close-loop Task Planning with Large Language Models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib42.1.1">
      arXiv preprint arXiv:2310.08582
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib43">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Hu et al. (2023d)
    </span>
    <span class="ltx_bibblock">
     Hu, P.; Qi, J.; Li, X.; Li, H.; Wang, X.; Quan, B.; Wang, R.; and Zhou, Y. 2023d.
    </span>
    <span class="ltx_bibblock">
     Tree-of-mixed-thought: Combining fast and slow thinking for multi-hop visual reasoning.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib43.1.1">
      arXiv preprint arXiv:2308.09658
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib44">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Hu and Shu (2023)
    </span>
    <span class="ltx_bibblock">
     Hu, Z.; and Shu, T. 2023.
    </span>
    <span class="ltx_bibblock">
     Language Models, Agent Models, and World Models: The LAW for Machine Reasoning and Planning.
    </span>
    <span class="ltx_bibblock">
     arXiv:2312.05230.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib45">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Hua et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Hua, W.; Fan, L.; Li, L.; Mei, K.; Ji, J.; Ge, Y.; Hemphill, L.; and Zhang, Y. 2023.
    </span>
    <span class="ltx_bibblock">
     War and peace (waragent): Large language model-based multi-agent simulation of world wars.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib45.1.1">
      arXiv preprint arXiv:2311.17227
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib46">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Huang et al. (2022a)
    </span>
    <span class="ltx_bibblock">
     Huang, W.; Abbeel, P.; Pathak, D.; and Mordatch, I. 2022a.
    </span>
    <span class="ltx_bibblock">
     Language models as zero-shot planners: Extracting actionable knowledge for embodied agents.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib46.1.1">
      International Conference on Machine Learning
     </em>
     , 9118–9147. PMLR.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib47">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Huang et al. (2023a)
    </span>
    <span class="ltx_bibblock">
     Huang, W.; Wang, C.; Zhang, R.; Li, Y.; Wu, J.; and Fei-Fei, L. 2023a.
    </span>
    <span class="ltx_bibblock">
     Voxposer: Composable 3d value maps for robotic manipulation with language models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib47.1.1">
      arXiv preprint arXiv:2307.05973
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib48">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Huang et al. (2023b)
    </span>
    <span class="ltx_bibblock">
     Huang, W.; Xia, F.; Shah, D.; Driess, D.; Zeng, A.; Lu, Y.; Florence, P.; Mordatch, I.; Levine, S.; Hausman, K.; et al. 2023b.
    </span>
    <span class="ltx_bibblock">
     Grounded decoding: Guiding text generation with grounded models for robot control.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib48.1.1">
      arXiv preprint arXiv:2303.00855
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib49">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Huang et al. (2022b)
    </span>
    <span class="ltx_bibblock">
     Huang, W.; Xia, F.; Xiao, T.; Chan, H.; Liang, J.; Florence, P.; Zeng, A.; Tompson, J.; Mordatch, I.; Chebotar, Y.; et al. 2022b.
    </span>
    <span class="ltx_bibblock">
     Inner monologue: Embodied reasoning through planning with language models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib49.1.1">
      arXiv preprint arXiv:2207.05608
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib50">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Jha et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Jha, S. K.; Jha, S.; Lincoln, P.; Bastian, N. D.; Velasquez, A.; Ewetz, R.; and Neema, S. 2023.
    </span>
    <span class="ltx_bibblock">
     Neuro Symbolic Reasoning for Planning: Counterexample Guided Inductive Synthesis using Large Language Models and Satisfiability Solving.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib50.1.1">
      arXiv preprint arXiv:2309.16436
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib51">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Joublin et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Joublin, F.; Ceravola, A.; Smirnov, P.; Ocker, F.; Deigmoeller, J.; Belardinelli, A.; Wang, C.; Hasler, S.; Tanneberg, D.; and Gienger, M. 2023.
    </span>
    <span class="ltx_bibblock">
     CoPAL: Corrective Planning of Robot Actions with Large Language Models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib51.1.1">
      arXiv preprint arXiv:2310.07263
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib52">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Kannan, Venkatesh, and Min (2023)
    </span>
    <span class="ltx_bibblock">
     Kannan, S. S.; Venkatesh, V. L.; and Min, B.-C. 2023.
    </span>
    <span class="ltx_bibblock">
     SMART-LLM: Smart Multi-Agent Robot Task Planning using Large Language Models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib52.1.1">
      arXiv preprint arXiv:2309.10062
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib53">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Kant et al. (2022)
    </span>
    <span class="ltx_bibblock">
     Kant, Y.; Ramachandran, A.; Yenamandra, S.; Gilitschenski, I.; Batra, D.; Szot, A.; and Agrawal, H. 2022.
    </span>
    <span class="ltx_bibblock">
     Housekeep: Tidying virtual households using commonsense reasoning.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib53.1.1">
      European Conference on Computer Vision
     </em>
     , 355–373. Springer.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib54">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Kautz (2022)
    </span>
    <span class="ltx_bibblock">
     Kautz, H. A. 2022.
    </span>
    <span class="ltx_bibblock">
     The third AI summer: AAAI Robert S. Engelmore Memorial Lecture.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib54.1.1">
      AI Magazine
     </em>
     , 43(1): 105–125.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib55">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Kelly et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Kelly, J.; Calderwood, A.; Wardrip-Fruin, N.; and Mateas, M. 2023.
    </span>
    <span class="ltx_bibblock">
     There and back again: extracting formal domains for controllable neurosymbolic story authoring.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib55.1.1">
      Proceedings of the AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment
     </em>
     , volume 19, 64–74.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib56">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Kim et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Kim, G.; Kim, T.; Kannan, S. S.; Venkatesh, V. L.; Kim, D.; and Min, B.-C. 2023.
    </span>
    <span class="ltx_bibblock">
     DynaCon: Dynamic Robot Planner with Contextual Awareness via LLMs.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib56.1.1">
      arXiv preprint arXiv:2309.16031
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib57">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Kirk, Wray, and Laird (2023)
    </span>
    <span class="ltx_bibblock">
     Kirk, J. R.; Wray, R. E.; and Laird, J. E. 2023.
    </span>
    <span class="ltx_bibblock">
     Exploiting Language Models as a Source of Knowledge for Cognitive Agents.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib57.1.1">
      arXiv preprint arXiv:2310.06846
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib58">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Lenat and Marcus (2023)
    </span>
    <span class="ltx_bibblock">
     Lenat, D.; and Marcus, G. 2023.
    </span>
    <span class="ltx_bibblock">
     Getting from generative ai to trustworthy ai: What llms might learn from cyc.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib58.1.1">
      arXiv preprint arXiv:2308.04445
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib59">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Li et al. (2023a)
    </span>
    <span class="ltx_bibblock">
     Li, M.; Song, F.; Yu, B.; Yu, H.; Li, Z.; Huang, F.; and Li, Y. 2023a.
    </span>
    <span class="ltx_bibblock">
     Api-bank: A benchmark for tool-augmented llms.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib59.1.1">
      arXiv preprint arXiv:2304.08244
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib60">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Li et al. (2023b)
    </span>
    <span class="ltx_bibblock">
     Li, Y.; Kamra, N.; Desai, R.; and Halevy, A. 2023b.
    </span>
    <span class="ltx_bibblock">
     Human-Centered Planning.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib60.1.1">
      arXiv preprint arXiv:2311.04403
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib61">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Lin et al. (2023a)
    </span>
    <span class="ltx_bibblock">
     Lin, B. Y.; Fu, Y.; Yang, K.; Ammanabrolu, P.; Brahman, F.; Huang, S.; Bhagavatula, C.; Choi, Y.; and Ren, X. 2023a.
    </span>
    <span class="ltx_bibblock">
     SwiftSage: A Generative Agent with Fast and Slow Thinking for Complex Interactive Tasks.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib61.1.1">
      arXiv preprint arXiv:2305.17390
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib62">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Lin et al. (2023b)
    </span>
    <span class="ltx_bibblock">
     Lin, H.; Zala, A.; Cho, J.; and Bansal, M. 2023b.
    </span>
    <span class="ltx_bibblock">
     Videodirectorgpt: Consistent multi-scene video generation via llm-guided planning.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib62.1.1">
      arXiv preprint arXiv:2309.15091
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib63">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Lin et al. (2023c)
    </span>
    <span class="ltx_bibblock">
     Lin, K.; Agia, C.; Migimatsu, T.; Pavone, M.; and Bohg, J. 2023c.
    </span>
    <span class="ltx_bibblock">
     Text2motion: From natural language instructions to feasible plans.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib63.1.1">
      arXiv preprint arXiv:2303.12153
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib64">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Liu et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Liu, B.; Jiang, Y.; Zhang, X.; Liu, Q.; Zhang, S.; Biswas, J.; and Stone, P. 2023.
    </span>
    <span class="ltx_bibblock">
     Llm+ p: Empowering large language models with optimal planning proficiency.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib64.1.1">
      arXiv preprint arXiv:2304.11477
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib65">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Liu, Bahety, and Song (2023)
    </span>
    <span class="ltx_bibblock">
     Liu, Z.; Bahety, A.; and Song, S. 2023.
    </span>
    <span class="ltx_bibblock">
     Reflect: Summarizing robot experiences for failure explanation and correction.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib65.1.1">
      arXiv preprint arXiv:2306.15724
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib66">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Logeswaran et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Logeswaran, L.; Sohn, S.; Lyu, Y.; Liu, A. Z.; Kim, D.-K.; Shim, D.; Lee, M.; and Lee, H. 2023.
    </span>
    <span class="ltx_bibblock">
     Code Models are Zero-shot Precondition Reasoners.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib66.1.1">
      arXiv preprint arXiv:2311.09601
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib67">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Lu et al. (2023a)
    </span>
    <span class="ltx_bibblock">
     Lu, P.; Peng, B.; Cheng, H.; Galley, M.; Chang, K.-W.; Wu, Y. N.; Zhu, S.-C.; and Gao, J. 2023a.
    </span>
    <span class="ltx_bibblock">
     Chameleon: Plug-and-play compositional reasoning with large language models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib67.1.1">
      arXiv preprint arXiv:2304.09842
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib68">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Lu et al. (2022)
    </span>
    <span class="ltx_bibblock">
     Lu, Y.; Feng, W.; Zhu, W.; Xu, W.; Wang, X. E.; Eckstein, M.; and Wang, W. Y. 2022.
    </span>
    <span class="ltx_bibblock">
     Neuro-symbolic causal language planning with commonsense prompting.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib68.1.1">
      arXiv e-prints
     </em>
     , arXiv–2206.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib69">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Lu et al. (2023b)
    </span>
    <span class="ltx_bibblock">
     Lu, Y.; Lu, P.; Chen, Z.; Zhu, W.; Wang, X. E.; and Wang, W. Y. 2023b.
    </span>
    <span class="ltx_bibblock">
     Multimodal Procedural Planning via Dual Text-Image Prompting.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib69.1.1">
      arXiv preprint arXiv:2305.01795
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib70">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Luo et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Luo, L.; Li, Y.-F.; Haffari, G.; and Pan, S. 2023.
    </span>
    <span class="ltx_bibblock">
     Reasoning on graphs: Faithful and interpretable large language model reasoning.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib70.1.1">
      arXiv preprint arXiv:2310.01061
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib71">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Mandi, Jain, and Song (2023)
    </span>
    <span class="ltx_bibblock">
     Mandi, Z.; Jain, S.; and Song, S. 2023.
    </span>
    <span class="ltx_bibblock">
     Roco: Dialectic multi-robot collaboration with large language models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib71.1.1">
      arXiv preprint arXiv:2307.04738
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib72">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     McDermott et al. (1998)
    </span>
    <span class="ltx_bibblock">
     McDermott, D.; Ghallab, M.; Howe, A.; Knoblock, C.; Ram, A.; Veloso, M.; Weld, D.; and Wilkins, D. 1998.
    </span>
    <span class="ltx_bibblock">
     PDDL-the planning domain definition language.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib73">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Momennejad et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Momennejad, I.; Hasanbeig, H.; Vieira, F.; Sharma, H.; Ness, R. O.; Jojic, N.; Palangi, H.; and Larson, J. 2023.
    </span>
    <span class="ltx_bibblock">
     Evaluating Cognitive Maps and Planning in Large Language Models with CogEval.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib73.1.1">
      arXiv preprint arXiv:2309.15129
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib74">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Naik et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Naik, R.; Chandrasekaran, V.; Yuksekgonul, M.; Palangi, H.; and Nushi, B. 2023.
    </span>
    <span class="ltx_bibblock">
     Diversity of Thought Improves Reasoning Abilities of Large Language Models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib74.1.1">
      arXiv preprint arXiv:2310.07088
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib75">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Nottingham et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Nottingham, K.; Ammanabrolu, P.; Suhr, A.; Choi, Y.; Hajishirzi, H.; Singh, S.; and Fox, R. 2023.
    </span>
    <span class="ltx_bibblock">
     Do embodied agents dream of pixelated sheep?: Embodied decision making using language guided world modelling.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib75.1.1">
      arXiv preprint arXiv:2301.12050
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib76">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Pallagani et al. (2022)
    </span>
    <span class="ltx_bibblock">
     Pallagani, V.; Muppasani, B.; Murugesan, K.; Rossi, F.; Horesh, L.; Srivastava, B.; Fabiano, F.; and Loreggia, A. 2022.
    </span>
    <span class="ltx_bibblock">
     Plansformer: Generating symbolic plans using transformers.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib76.1.1">
      arXiv preprint arXiv:2212.08681
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib77">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Pallagani et al. (2023a)
    </span>
    <span class="ltx_bibblock">
     Pallagani, V.; Muppasani, B.; Murugesan, K.; Rossi, F.; Srivastava, B.; Horesh, L.; Fabiano, F.; and Loreggia, A. 2023a.
    </span>
    <span class="ltx_bibblock">
     Understanding the Capabilities of Large Language Models for Automated Planning.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib77.1.1">
      arXiv preprint arXiv:2305.16151
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib78">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Pallagani et al. (2023b)
    </span>
    <span class="ltx_bibblock">
     Pallagani, V.; Muppasani, B.; Srivastava, B.; Rossi, F.; Horesh, L.; Murugesan, K.; Loreggia, A.; Fabiano, F.; Joseph, R.; Kethepalli, Y.; et al. 2023b.
    </span>
    <span class="ltx_bibblock">
     Plansformer Tool: Demonstrating Generation of Symbolic Plans Using Transformers.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib78.1.1">
      IJCAI
     </em>
     , volume 2023, 7158–7162. International Joint Conferences on Artificial Intelligence.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib79">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Pan et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Pan, L.; Albalak, A.; Wang, X.; and Wang, W. Y. 2023.
    </span>
    <span class="ltx_bibblock">
     Logic-lm: Empowering large language models with symbolic solvers for faithful logical reasoning.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib79.1.1">
      arXiv preprint arXiv:2305.12295
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib80">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Parakh et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Parakh, M.; Fong, A.; Simeonov, A.; Gupta, A.; Chen, T.; and Agrawal, P. 2023.
    </span>
    <span class="ltx_bibblock">
     Human-Assisted Continual Robot Learning with Foundation Models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib80.1.1">
      arXiv preprint arXiv:2309.14321
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib81">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Raimondo et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Raimondo, S.; Pal, C.; Liu, X.; Vazquez, D.; and Palacios, H. 2023.
    </span>
    <span class="ltx_bibblock">
     Improving Generalization in Task-oriented Dialogues with Workflows and Action Plans.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib81.1.1">
      arXiv preprint arXiv:2306.01729
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib82">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Rajvanshi et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Rajvanshi, A.; Sikka, K.; Lin, X.; Lee, B.; Chiu, H.-P.; and Velasquez, A. 2023.
    </span>
    <span class="ltx_bibblock">
     Saynav: Grounding large language models for dynamic planning to navigation in new environments.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib82.1.1">
      arXiv preprint arXiv:2309.04077
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib83">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Raman et al. (2022)
    </span>
    <span class="ltx_bibblock">
     Raman, S. S.; Cohen, V.; Rosen, E.; Idrees, I.; Paulius, D.; and Tellex, S. 2022.
    </span>
    <span class="ltx_bibblock">
     Planning with large language models via corrective re-prompting.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib83.1.1">
      NeurIPS 2022 Foundation Models for Decision Making Workshop
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib84">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Rana et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Rana, K.; Haviland, J.; Garg, S.; Abou-Chakra, J.; Reid, I.; and Suenderhauf, N. 2023.
    </span>
    <span class="ltx_bibblock">
     Sayplan: Grounding large language models using 3d scene graphs for scalable task planning.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib84.1.1">
      arXiv preprint arXiv:2307.06135
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib85">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Ren et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Ren, A. Z.; Dixit, A.; Bodrova, A.; Singh, S.; Tu, S.; Brown, N.; Xu, P.; Takayama, L.; Xia, F.; Varley, J.; et al. 2023.
    </span>
    <span class="ltx_bibblock">
     Robots that ask for help: Uncertainty alignment for large language model planners.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib85.1.1">
      arXiv preprint arXiv:2307.01928
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib86">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Ruan et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Ruan, J.; Chen, Y.; Zhang, B.; Xu, Z.; Bao, T.; Du, G.; Shi, S.; Mao, H.; Zeng, X.; and Zhao, R. 2023.
    </span>
    <span class="ltx_bibblock">
     Tptu: Task planning and tool usage of large language model-based ai agents.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib86.1.1">
      arXiv preprint arXiv:2308.03427
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib87">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Russell and Norvig (2003)
    </span>
    <span class="ltx_bibblock">
     Russell, S.; and Norvig, P. 2003.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib87.1.1">
      Artificial Intelligence, A Modern Approach. Second Edition
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib88">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Sakib and Sun (2023)
    </span>
    <span class="ltx_bibblock">
     Sakib, M. S.; and Sun, Y. 2023.
    </span>
    <span class="ltx_bibblock">
     From Cooking Recipes to Robot Task Trees–Improving Planning Correctness and Task Efficiency by Leveraging LLMs with a Knowledge Network.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib88.1.1">
      arXiv preprint arXiv:2309.09181
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib89">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Sarkisyan et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Sarkisyan, C.; Korchemnyi, A.; Kovalev, A. K.; and Panov, A. I. 2023.
    </span>
    <span class="ltx_bibblock">
     Evaluation of Pretrained Large Language Models in Embodied Planning Tasks.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib89.1.1">
      International Conference on Artificial General Intelligence
     </em>
     , 222–232. Springer.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib90">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Sermanet et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Sermanet, P.; Ding, T.; Zhao, J.; Xia, F.; Dwibedi, D.; Gopalakrishnan, K.; Chan, C.; Dulac-Arnold, G.; Maddineni, S.; Joshi, N. J.; et al. 2023.
    </span>
    <span class="ltx_bibblock">
     RoboVQA: Multimodal Long-Horizon Reasoning for Robotics.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib90.1.1">
      arXiv preprint arXiv:2311.00899
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib91">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Shah et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Shah, D.; Equi, M.; Osinski, B.; Xia, F.; Ichter, B.; and Levine, S. 2023.
    </span>
    <span class="ltx_bibblock">
     Navigation with large language models: Semantic guesswork as a heuristic for planning.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib91.1.1">
      arXiv preprint arXiv:2310.10103
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib92">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Shen et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Shen, Y.; Song, K.; Tan, X.; Li, D.; Lu, W.; and Zhuang, Y. 2023.
    </span>
    <span class="ltx_bibblock">
     Hugginggpt: Solving ai tasks with chatgpt and its friends in huggingface.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib92.1.1">
      arXiv preprint arXiv:2303.17580
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib93">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Shirai et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Shirai, K.; Beltran-Hernandez, C. C.; Hamaya, M.; Hashimoto, A.; Tanaka, S.; Kawaharazuka, K.; Tanaka, K.; Ushiku, Y.; and Mori, S. 2023.
    </span>
    <span class="ltx_bibblock">
     Vision-Language Interpreter for Robot Task Planning.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib93.1.1">
      arXiv preprint arXiv:2311.00967
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib94">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Silver et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Silver, T.; Dan, S.; Srinivas, K.; Tenenbaum, J. B.; Kaelbling, L. P.; and Katz, M. 2023.
    </span>
    <span class="ltx_bibblock">
     Generalized Planning in PDDL Domains with Pretrained Large Language Models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib94.1.1">
      arXiv preprint arXiv:2305.11014
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib95">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Silver et al. (2022)
    </span>
    <span class="ltx_bibblock">
     Silver, T.; Hariprasad, V.; Shuttleworth, R. S.; Kumar, N.; Lozano-Pérez, T.; and Kaelbling, L. P. 2022.
    </span>
    <span class="ltx_bibblock">
     PDDL planning with pretrained large language models.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib95.1.1">
      NeurIPS 2022 Foundation Models for Decision Making Workshop
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib96">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Singh et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Singh, I.; Blukis, V.; Mousavian, A.; Goyal, A.; Xu, D.; Tremblay, J.; Fox, D.; Thomason, J.; and Garg, A. 2023.
    </span>
    <span class="ltx_bibblock">
     ProgPrompt: program generation for situated robot task planning using large language models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib96.1.1">
      Autonomous Robots
     </em>
     , 1–14.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib97">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Song et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Song, C. H.; Wu, J.; Washington, C.; Sadler, B. M.; Chao, W.-L.; and Su, Y. 2023.
    </span>
    <span class="ltx_bibblock">
     Llm-planner: Few-shot grounded planning for embodied agents with large language models.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib97.1.1">
      Proceedings of the IEEE/CVF International Conference on Computer Vision
     </em>
     , 2998–3009.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib98">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Sumers et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Sumers, T.; Yao, S.; Narasimhan, K.; and Griffiths, T. L. 2023.
    </span>
    <span class="ltx_bibblock">
     Cognitive architectures for language agents.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib98.1.1">
      arXiv preprint arXiv:2309.02427
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib99">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Sun et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Sun, H.; Zhuang, Y.; Kong, L.; Dai, B.; and Zhang, C. 2023.
    </span>
    <span class="ltx_bibblock">
     AdaPlanner: Adaptive Planning from Feedback with Language Models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib99.1.1">
      arXiv preprint arXiv:2305.16653
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib100">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Tang et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Tang, X.; Zheng, Z.; Li, J.; Meng, F.; Zhu, S.-C.; Liang, Y.; and Zhang, M. 2023.
    </span>
    <span class="ltx_bibblock">
     Large Language Models are In-Context Semantic Reasoners rather than Symbolic Reasoners.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib100.1.1">
      arXiv preprint arXiv:2305.14825
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib101">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Valmeekam, Marquez, and Kambhampati (2023)
    </span>
    <span class="ltx_bibblock">
     Valmeekam, K.; Marquez, M.; and Kambhampati, S. 2023.
    </span>
    <span class="ltx_bibblock">
     Can Large Language Models Really Improve by Self-critiquing Their Own Plans?
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib101.1.1">
      arXiv preprint arXiv:2310.08118
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib102">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Valmeekam et al. (2023a)
    </span>
    <span class="ltx_bibblock">
     Valmeekam, K.; Marquez, M.; Olmo, A.; Sreedharan, S.; and Kambhampati, S. 2023a.
    </span>
    <span class="ltx_bibblock">
     PlanBench: An Extensible Benchmark for Evaluating Large Language Models on Planning and Reasoning about Change.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib102.1.1">
      Thirty-seventh Conference on Neural Information Processing Systems Datasets and Benchmarks Track
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib103">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Valmeekam et al. (2022)
    </span>
    <span class="ltx_bibblock">
     Valmeekam, K.; Olmo, A.; Sreedharan, S.; and Kambhampati, S. 2022.
    </span>
    <span class="ltx_bibblock">
     Large Language Models Still Can’t Plan (A Benchmark for LLMs on Planning and Reasoning about Change).
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib103.1.1">
      arXiv preprint arXiv:2206.10498
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib104">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Valmeekam et al. (2023b)
    </span>
    <span class="ltx_bibblock">
     Valmeekam, K.; Sreedharan, S.; Marquez, M.; Olmo, A.; and Kambhampati, S. 2023b.
    </span>
    <span class="ltx_bibblock">
     On the planning abilities of large language models (a critical investigation with a proposed benchmark).
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib104.1.1">
      arXiv preprint arXiv:2302.06706
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib105">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wang et al. (2023a)
    </span>
    <span class="ltx_bibblock">
     Wang, J.; Tong, J.; Tan, K.; Vorobeychik, Y.; and Kantaros, Y. 2023a.
    </span>
    <span class="ltx_bibblock">
     Conformal Temporal Logic Planning using Large Language Models: Knowing When to Do What and When to Ask for Help.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib105.1.1">
      arXiv preprint arXiv:2309.10092
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib106">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wang et al. (2023b)
    </span>
    <span class="ltx_bibblock">
     Wang, L.; Xu, W.; Lan, Y.; Hu, Z.; Lan, Y.; Lee, R. K.-W.; and Lim, E.-P. 2023b.
    </span>
    <span class="ltx_bibblock">
     Plan-and-solve prompting: Improving zero-shot chain-of-thought reasoning by large language models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib106.1.1">
      arXiv preprint arXiv:2305.04091
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib107">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wang et al. (2023c)
    </span>
    <span class="ltx_bibblock">
     Wang, X.; Caccia, L.; Ostapenko, O.; Yuan, X.; and Sordoni, A. 2023c.
    </span>
    <span class="ltx_bibblock">
     Guiding language model reasoning with planning tokens.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib107.1.1">
      arXiv preprint arXiv:2310.05707
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib108">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wang et al. (2023d)
    </span>
    <span class="ltx_bibblock">
     Wang, Z.; Cai, S.; Liu, A.; Ma, X.; and Liang, Y. 2023d.
    </span>
    <span class="ltx_bibblock">
     Describe, explain, plan and select: Interactive planning with large language models enables open-world multi-task agents.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib108.1.1">
      arXiv preprint arXiv:2302.01560
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib109">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Webb et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Webb, T.; Mondal, S. S.; Wang, C.; Krabach, B.; and Momennejad, I. 2023.
    </span>
    <span class="ltx_bibblock">
     A Prefrontal Cortex-inspired Architecture for Planning in Large Language Models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib109.1.1">
      arXiv preprint arXiv:2310.00194
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib110">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wei et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Wei, L.; He, Z.; Zhao, H.; and Yao, Q. 2023.
    </span>
    <span class="ltx_bibblock">
     Unleashing the Power of Graph Learning through LLM-based Autonomous Agents.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib110.1.1">
      arXiv preprint arXiv:2309.04565
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib111">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wong et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Wong, L.; Grand, G.; Lew, A. K.; Goodman, N. D.; Mansinghka, V. K.; Andreas, J.; and Tenenbaum, J. B. 2023.
    </span>
    <span class="ltx_bibblock">
     From Word Models to World Models: Translating from Natural Language to the Probabilistic Language of Thought.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib111.1.1">
      arXiv preprint arXiv:2306.12672
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib112">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wu et al. (2023a)
    </span>
    <span class="ltx_bibblock">
     Wu, Y.; Min, S. Y.; Bisk, Y.; Salakhutdinov, R.; Azaria, A.; Li, Y.; Mitchell, T.; and Prabhumoye, S. 2023a.
    </span>
    <span class="ltx_bibblock">
     Plan, Eliminate, and Track–Language Models are Good Teachers for Embodied Agents.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib112.1.1">
      arXiv preprint arXiv:2305.02412
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib113">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wu, Ai, and Hsu (2023)
    </span>
    <span class="ltx_bibblock">
     Wu, Z.; Ai, B.; and Hsu, D. 2023.
    </span>
    <span class="ltx_bibblock">
     Integrating Common Sense and Planning with Large Language Models for Room Tidying.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib113.1.1">
      RSS 2023 Workshop on Learning for Task and Motion Planning
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib114">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wu et al. (2023b)
    </span>
    <span class="ltx_bibblock">
     Wu, Z.; Wang, Z.; Xu, X.; Lu, J.; and Yan, H. 2023b.
    </span>
    <span class="ltx_bibblock">
     Embodied task planning with large language models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib114.1.1">
      arXiv preprint arXiv:2307.01848
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib115">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Xie et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Xie, Y.; Yu, C.; Zhu, T.; Bai, J.; Gong, Z.; and Soh, H. 2023.
    </span>
    <span class="ltx_bibblock">
     Translating natural language to planning goals with large-language models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib115.1.1">
      arXiv preprint arXiv:2302.05128
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib116">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Xu et al. (2023a)
    </span>
    <span class="ltx_bibblock">
     Xu, B.; Liu, X.; Shen, H.; Han, Z.; Li, Y.; Yue, M.; Peng, Z.; Liu, Y.; Yao, Z.; and Xu, D. 2023a.
    </span>
    <span class="ltx_bibblock">
     Gentopia: A collaborative platform for tool-augmented llms.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib116.1.1">
      arXiv preprint arXiv:2308.04030
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib117">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Xu (1995)
    </span>
    <span class="ltx_bibblock">
     Xu, L. 1995.
    </span>
    <span class="ltx_bibblock">
     Case based reasoning.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib117.1.1">
      IEEE Potentials
     </em>
     , 13(5): 10–13.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib118">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Xu et al. (2023b)
    </span>
    <span class="ltx_bibblock">
     Xu, M.; Huang, P.; Yu, W.; Liu, S.; Zhang, X.; Niu, Y.; Zhang, T.; Xia, F.; Tan, J.; and Zhao, D. 2023b.
    </span>
    <span class="ltx_bibblock">
     Creative Robot Tool Use with Large Language Models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib118.1.1">
      arXiv preprint arXiv:2310.13065
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib119">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Yang et al. (2023a)
    </span>
    <span class="ltx_bibblock">
     Yang, J.; Chen, X.; Qian, S.; Madaan, N.; Iyengar, M.; Fouhey, D. F.; and Chai, J. 2023a.
    </span>
    <span class="ltx_bibblock">
     LLM-Grounder: Open-Vocabulary 3D Visual Grounding with Large Language Model as an Agent.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib119.1.1">
      arXiv preprint arXiv:2309.12311
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib120">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Yang et al. (2023b)
    </span>
    <span class="ltx_bibblock">
     Yang, R.; Hou, M.; Wang, J.; and Zhang, F. 2023b.
    </span>
    <span class="ltx_bibblock">
     OceanChat: Piloting Autonomous Underwater Vehicles in Natural Language.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib120.1.1">
      arXiv preprint arXiv:2309.16052
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib121">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Yang, Gaglione, and Topcu (2022)
    </span>
    <span class="ltx_bibblock">
     Yang, Y.; Gaglione, J.-R.; and Topcu, U. 2022.
    </span>
    <span class="ltx_bibblock">
     Learning Automata-Based Task Knowledge Representation from Large-Scale Generative Language Models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib121.1.1">
      arXiv preprint arXiv:2212.01944
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib122">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Yang and Tomar (2023)
    </span>
    <span class="ltx_bibblock">
     Yang, Y.; and Tomar, A. 2023.
    </span>
    <span class="ltx_bibblock">
     On the Planning, Search, and Memorization Capabilities of Large Language Models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib122.1.1">
      arXiv preprint arXiv:2309.01868
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib123">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Yang (2023)
    </span>
    <span class="ltx_bibblock">
     Yang, Z. 2023.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib123.1.1">
      Neuro-Symbolic AI Approaches to Enhance Deep Neural Networks with Logical Reasoning and Knowledge Integration
     </em>
     .
    </span>
    <span class="ltx_bibblock">
     Ph.D. thesis, Arizona State University.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib124">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Yang, Ishay, and Lee (2023)
    </span>
    <span class="ltx_bibblock">
     Yang, Z.; Ishay, A.; and Lee, J. 2023.
    </span>
    <span class="ltx_bibblock">
     Coupling Large Language Models with Logic Programming for Robust and General Reasoning from Text.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib124.1.1">
      arXiv preprint arXiv:2307.07696
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib125">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Yao et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Yao, S.; Yu, D.; Zhao, J.; Shafran, I.; Griffiths, T. L.; Cao, Y.; and Narasimhan, K. 2023.
    </span>
    <span class="ltx_bibblock">
     Tree of thoughts: Deliberate problem solving with large language models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib125.1.1">
      arXiv preprint arXiv:2305.10601
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib126">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Yoneda et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Yoneda, T.; Fang, J.; Li, P.; Zhang, H.; Jiang, T.; Lin, S.; Picker, B.; Yunis, D.; Mei, H.; and Walter, M. R. 2023.
    </span>
    <span class="ltx_bibblock">
     Statler: State-maintaining language models for embodied reasoning.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib126.1.1">
      arXiv preprint arXiv:2306.17840
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib127">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     You et al. (2023)
    </span>
    <span class="ltx_bibblock">
     You, W.; Wu, W.; Liang, Y.; Mao, S.; Wu, C.; Cao, M.; Cai, Y.; Guo, Y.; Xia, Y.; Wei, F.; et al. 2023.
    </span>
    <span class="ltx_bibblock">
     EIPE-text: Evaluation-Guided Iterative Plan Extraction for Long-Form Narrative Text Generation.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib127.1.1">
      arXiv preprint arXiv:2310.08185
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib128">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Yuan et al. (2023a)
    </span>
    <span class="ltx_bibblock">
     Yuan, H.; Zhang, C.; Wang, H.; Xie, F.; Cai, P.; Dong, H.; and Lu, Z. 2023a.
    </span>
    <span class="ltx_bibblock">
     Plan4mc: Skill reinforcement learning and planning for open-world minecraft tasks.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib128.1.1">
      arXiv preprint arXiv:2303.16563
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib129">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Yuan et al. (2023b)
    </span>
    <span class="ltx_bibblock">
     Yuan, S.; Chen, J.; Fu, Z.; Ge, X.; Shah, S.; Jankowski, C. R.; Yang, D.; and Xiao, Y. 2023b.
    </span>
    <span class="ltx_bibblock">
     Distilling Script Knowledge from Large Language Models for Constrained Language Planning.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib129.1.1">
      arXiv preprint arXiv:2305.05252
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib130">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Zelikman et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Zelikman, E.; Huang, Q.; Poesia, G.; Goodman, N.; and Haber, N. 2023.
    </span>
    <span class="ltx_bibblock">
     Parsel: Algorithmic Reasoning with Language Models by Composing Decompositions.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib130.1.1">
      Thirty-seventh Conference on Neural Information Processing Systems
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib131">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Zhang and Soh (2023)
    </span>
    <span class="ltx_bibblock">
     Zhang, B.; and Soh, H. 2023.
    </span>
    <span class="ltx_bibblock">
     Large language models as zero-shot human models for human-robot interaction.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib131.1.1">
      arXiv preprint arXiv:2303.03548
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib132">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Zhang et al. (2023a)
    </span>
    <span class="ltx_bibblock">
     Zhang, C.; Liu, L.; Wang, J.; Wang, C.; Sun, X.; Wang, H.; and Cai, M. 2023a.
    </span>
    <span class="ltx_bibblock">
     Prefer: Prompt ensemble learning via feedback-reflect-refine.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib132.1.1">
      arXiv preprint arXiv:2308.12033
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib133">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Zhang, Jin, and Zhuo (2023)
    </span>
    <span class="ltx_bibblock">
     Zhang, F.; Jin, K.; and Zhuo, H. H. 2023.
    </span>
    <span class="ltx_bibblock">
     Planning with Logical Graph-based Language Model for Instruction Generation.
    </span>
    <span class="ltx_bibblock">
     arXiv:2308.13782.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib134">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Zhang et al. (2023b)
    </span>
    <span class="ltx_bibblock">
     Zhang, H.; Du, W.; Shan, J.; Zhou, Q.; Du, Y.; Tenenbaum, J. B.; Shu, T.; and Gan, C. 2023b.
    </span>
    <span class="ltx_bibblock">
     Building cooperative embodied agents modularly with large language models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib134.1.1">
      arXiv preprint arXiv:2307.02485
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib135">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Zhang et al. (2023c)
    </span>
    <span class="ltx_bibblock">
     Zhang, J.; Zhang, J.; Pertsch, K.; Liu, Z.; Ren, X.; Chang, M.; Sun, S.-H.; and Lim, J. J. 2023c.
    </span>
    <span class="ltx_bibblock">
     Bootstrap your own skills: Learning to solve new tasks with large language model guidance.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib135.1.1">
      arXiv preprint arXiv:2310.10021
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib136">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Zhao, Lee, and Hsu (2023)
    </span>
    <span class="ltx_bibblock">
     Zhao, Z.; Lee, W. S.; and Hsu, D. 2023.
    </span>
    <span class="ltx_bibblock">
     Large Language Models as Commonsense Knowledge for Large-Scale Task Planning.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib136.1.1">
      arXiv preprint arXiv:2305.14078
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib137">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Zheng et al. (2023a)
    </span>
    <span class="ltx_bibblock">
     Zheng, L.; Chiang, W.-L.; Sheng, Y.; Zhuang, S.; Wu, Z.; Zhuang, Y.; Lin, Z.; Li, Z.; Li, D.; Xing, E. P.; Zhang, H.; Gonzalez, J. E.; and Stoica, I. 2023a.
    </span>
    <span class="ltx_bibblock">
     Judging LLM-as-a-judge with MT-Bench and Chatbot Arena.
    </span>
    <span class="ltx_bibblock">
     arXiv:2306.05685.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib138">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Zheng et al. (2023b)
    </span>
    <span class="ltx_bibblock">
     Zheng, S.; Liu, J.; Feng, Y.; and Lu, Z. 2023b.
    </span>
    <span class="ltx_bibblock">
     Steve-Eye: Equipping LLM-based Embodied Agents with Visual Perception in Open Worlds.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib138.1.1">
      arXiv preprint arXiv:2310.13255
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib139">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Zhou et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Zhou, Z.; Song, J.; Yao, K.; Shu, Z.; and Ma, L. 2023.
    </span>
    <span class="ltx_bibblock">
     ISR-LLM: Iterative Self-Refined Large Language Model for Long-Horizon Sequential Task Planning.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib139.1.1">
      arXiv preprint arXiv:2308.13724
     </em>
     .
    </span>
   </li>
  </ul>
 </section>
 <div class="ltx_pagination ltx_role_newpage">
 </div>
</article>
