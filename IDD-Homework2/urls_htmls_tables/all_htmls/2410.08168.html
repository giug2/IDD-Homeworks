<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>ZeroComp: Zero-shot Object Compositing from Image Intrinsics via Diffusion</title>
<!--Generated on Thu Oct 10 15:57:31 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2410.08168v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#S1" title="In ZeroComp: Zero-shot Object Compositing from Image Intrinsics via Diffusion"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#S2" title="In ZeroComp: Zero-shot Object Compositing from Image Intrinsics via Diffusion"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Related work</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#S3" title="In ZeroComp: Zero-shot Object Compositing from Image Intrinsics via Diffusion"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span><span class="ltx_text ltx_font_smallcaps">ZeroComp</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#S3.SS1" title="In 3 ZeroComp ‣ ZeroComp: Zero-shot Object Compositing from Image Intrinsics via Diffusion"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Training <span class="ltx_text ltx_font_smallcaps">ZeroComp</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#S3.SS2" title="In 3 ZeroComp ‣ ZeroComp: Zero-shot Object Compositing from Image Intrinsics via Diffusion"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Zero-shot object compositing using <span class="ltx_text ltx_font_smallcaps">ZeroComp</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#S3.SS3" title="In 3 ZeroComp ‣ ZeroComp: Zero-shot Object Compositing from Image Intrinsics via Diffusion"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>Preserving background fidelity</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#S4" title="In ZeroComp: Zero-shot Object Compositing from Image Intrinsics via Diffusion"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Test dataset for 3D object compositing</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#S5" title="In ZeroComp: Zero-shot Object Compositing from Image Intrinsics via Diffusion"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Evaluation</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#S5.SS1" title="In 5 Evaluation ‣ ZeroComp: Zero-shot Object Compositing from Image Intrinsics via Diffusion"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1 </span>Lighting estimation method comparison</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#S5.SS2" title="In 5 Evaluation ‣ ZeroComp: Zero-shot Object Compositing from Image Intrinsics via Diffusion"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2 </span>Image-based compositing method comparison</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#S5.SS3" title="In 5 Evaluation ‣ ZeroComp: Zero-shot Object Compositing from Image Intrinsics via Diffusion"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.3 </span>Human perceptual study</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#S5.SS4" title="In 5 Evaluation ‣ ZeroComp: Zero-shot Object Compositing from Image Intrinsics via Diffusion"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.4 </span>Ablations</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#S5.SS5" title="In 5 Evaluation ‣ ZeroComp: Zero-shot Object Compositing from Image Intrinsics via Diffusion"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.5 </span>Extensions</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#S6" title="In ZeroComp: Zero-shot Object Compositing from Image Intrinsics via Diffusion"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Discussion</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line ltx_pruned_first">
<h1 class="ltx_title ltx_title_document">
<span class="ltx_text ltx_font_smallcaps" id="id13.id1">ZeroComp</span>: Zero-shot Object Compositing from Image Intrinsics via Diffusion</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Zitian Zhang<sup class="ltx_sup" id="id14.9.id1">1</sup>  Frédéric Fortier-Chouinard<sup class="ltx_sup" id="id15.10.id2">1</sup>  Mathieu Garon<sup class="ltx_sup" id="id16.11.id3">2</sup>
<br class="ltx_break"/>Anand Bhattad<sup class="ltx_sup" id="id17.12.id4">3</sup>  Jean-François Lalonde<sup class="ltx_sup" id="id18.13.id5">1</sup>
<br class="ltx_break"/><sup class="ltx_sup" id="id19.14.id6">1</sup>Université Laval, <sup class="ltx_sup" id="id20.15.id7">2</sup>Depix Technologies, <sup class="ltx_sup" id="id21.16.id8">3</sup>Toyota Technological Institute at Chicago
</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id22.id1">We present <span class="ltx_text ltx_font_smallcaps" id="id22.id1.1">ZeroComp</span>, an effective zero-shot 3D object compositing approach that does not require paired composite-scene images during training. Our method leverages ControlNet to condition from intrinsic images and combines it with a Stable Diffusion model to utilize its scene priors, together operating as an effective rendering engine. During training, <span class="ltx_text ltx_font_smallcaps" id="id22.id1.2">ZeroComp</span> uses intrinsic images based on geometry, albedo, and masked shading, all without the need for paired images of scenes with and without composite objects. Once trained, it seamlessly integrates virtual 3D objects into scenes, adjusting shading to create realistic composites. We developed a high-quality evaluation dataset and demonstrate that <span class="ltx_text ltx_font_smallcaps" id="id22.id1.3">ZeroComp</span> outperforms methods using explicit lighting estimations and generative techniques in quantitative and human perception benchmarks. Additionally, <span class="ltx_text ltx_font_smallcaps" id="id22.id1.4">ZeroComp</span> extends to real and outdoor image compositing, even when trained solely on synthetic indoor data, showcasing its effectiveness in image compositing.</p>
</div>
<div class="ltx_logical-block" id="id12">
<div class="ltx_para" id="id12.p1">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="id11.3">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="id11.3.3">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="id9.1.1.1" style="padding-left:1.0pt;padding-right:1.0pt;"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="172" id="id9.1.1.1.g1" src="extracted/5908513/figures/teaser/bg.jpg" width="172"/></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="id10.2.2.2" style="padding-left:1.0pt;padding-right:1.0pt;"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="172" id="id10.2.2.2.g1" src="extracted/5908513/figures/teaser/teaser_hd3.png" width="172"/></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="id11.3.3.3" style="padding-left:1.0pt;padding-right:1.0pt;"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="172" id="id11.3.3.3.g1" src="extracted/5908513/figures/teaser/9C4A0370-2d21311d85_02_crop_B07QHYD995_pred_seed_1_comp.png" width="172"/></td>
</tr>
<tr class="ltx_tr" id="id11.3.4.1">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="id11.3.4.1.1" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text" id="id11.3.4.1.1.1" style="font-size:80%;">(a) Target image</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="id11.3.4.1.2" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text" id="id11.3.4.1.2.1" style="font-size:80%;">(b) Intrinsic maps</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="id11.3.4.1.3" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text" id="id11.3.4.1.3.1" style="font-size:80%;">(c) Predicted composite</span></td>
</tr>
</tbody>
</table>
</div>
<figure class="ltx_figure ltx_align_center" id="S0.F1">
<figcaption class="ltx_caption" style="font-size:80%;"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S0.F1.8.1.1" style="font-size:113%;">Figure 1</span>: </span><span class="ltx_text" id="S0.F1.9.2" style="font-size:113%;">From (a) a target background image and (b) available intrinsic maps (depth, normals, albedo) rendered from a 3D model, our method <span class="ltx_text ltx_font_smallcaps" id="S0.F1.9.2.1">ZeroComp</span> generates (c) a realistic composite, without access to the scene geometry or lighting, and without being trained specifically for object compositing. <span class="ltx_text ltx_font_smallcaps" id="S0.F1.9.2.2">ZeroComp</span> realistically shades the object and adds a compelling shadow.</span></figcaption>
</figure>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Compositing 3D objects into real photographs has become an essential task in diverse fields such as image editing and visual effects.
To achieve high realism, the virtual object—defined as a 3D asset with geometry, texture, etc.—must interact with the lighting and elements from the real target scene. To this end, Debevec <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib18" title="">18</a>]</cite> introduced “image-based lighting” (IBL), a three-step approach for compositing of 3D objects into real images: 1) capture the high dynamic range (HDR) lighting properties of the target scene to use as a virtual light source; 2) approximate the surrounding target scene geometry to catch virtual shadows; and 3) render and composite the virtual object into the scene. Since then, several methods have been proposed to improve upon each of these steps, but the overall approach has remained the same. For example, lighting estimation methods <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib22" title="">22</a>]</cite> have replaced the need for capturing light probes; depth estimation <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib4" title="">4</a>]</cite> and camera auto-calibration <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib32" title="">32</a>]</cite> can approximate the target scene geometry.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">Recent works <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib12" title="">12</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib85" title="">85</a>]</cite> has departed from this three-step procedure and leveraged pre-trained diffusion models such as Stable Diffusion <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib58" title="">58</a>]</cite> (SD). This creates a simpler, single-pass approach that creates highly realistic images. However, the object is often adjusted, rotated, or even deformed by the SD model, which leads to unpredictable results.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">Addressing the limitations of current IBL- and SD-based compositing methods, we propose <span class="ltx_text ltx_font_smallcaps" id="S1.p3.1.1">ZeroComp</span>, which merges the generative power of SD models with the precision of the IBL framework to enable realistic compositing of virtual 3D objects into images. Central to <span class="ltx_text ltx_font_smallcaps" id="S1.p3.1.2">ZeroComp</span> is training a ControlNet <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib86" title="">86</a>]</cite> that leverages a pre-trained SD backbone to render images from an intrinsic decomposition of a given scene. This training results in zero-shot compositing, allowing object insertion into diverse scenes without specific prior training. Consequently, <span class="ltx_text ltx_font_smallcaps" id="S1.p3.1.3">ZeroComp</span> ensures realistic compositing of virtual objects, preserving their shape, pose, and texture, without requiring paired training dataset. This zero-shot capability stems from our rendering-focused training strategy, offering a compositing solution within a single framework.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">To achieve this, our key idea is to train <span class="ltx_text ltx_font_smallcaps" id="S1.p4.1.1">ZeroComp</span> on a simpler proxy task: given a decomposition of an image into its intrinsic components—depth, normals, albedo, and partial input shading—generate a fully relit image. This network is trained using synthetic datasets like OpenRooms <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib44" title="">44</a>]</cite> or InteriorVerse <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib91" title="">91</a>]</cite>. At inference, new 3D objects are inserted into the depth, normals, and albedo layers as naive composites. The trained model then generates a fully-shaded version of the object, faithful to the scene lighting while retaining object identity. In short, <span class="ltx_text ltx_font_smallcaps" id="S1.p4.1.2">ZeroComp</span> acts as a neural renderer, specifically trained to generate illumination effects such as shading and cast shadows (<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#S0.F1" title="In ZeroComp: Zero-shot Object Compositing from Image Intrinsics via Diffusion"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">1</span></a>).</p>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">To rigorously assess our approach, we compile a meticulously curated dataset for evaluating image compositing, utilizing 3D object assets from the Amazon Berkeley Object dataset <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib15" title="">15</a>]</cite> and background scenes from the Laval HDR Indoor dataset <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib22" title="">22</a>]</cite>. Extensive evaluation shows that our method competes well with traditional methods relying on explicit lighting estimation and surpasses other SD-based strategies in realism and faithfulness to the object. Given that quantitative metrics often do not correlate well with human perception <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib27" title="">27</a>]</cite>, we conducted a user study that demonstrated our approach significantly outshines all other methods.
In summary our contributions are: 1) we present <span class="ltx_text ltx_font_smallcaps" id="S1.p5.1.1">ZeroComp</span> for zero-shot object compositing, where a ControlNet is trained as a neural renderer, conditioned on intrinsic layers; 2) a novel test dataset for evaluating 3D object compositing methods; 3) a thorough evaluation unifying several methods from the recent literature, including lighting estimation, shadow generation, diffusion models and harmonization approaches; and 4) a user study demonstrating the performance of <span class="ltx_text ltx_font_smallcaps" id="S1.p5.1.2">ZeroComp</span> at generating renders more perceptually pleasing than state-of-the-art methods.</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related work</h2>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">Image compositing has a long history in vision and graphics. Of note, Reinhard et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib55" title="">55</a>]</cite> studied color-based harmonization, later revisited in <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib52" title="">52</a>]</cite>. Issuing from the pioneering work by Burt and Adelson <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib9" title="">9</a>]</cite>, seamless object blending has been studied in <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib49" title="">49</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib59" title="">59</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib67" title="">67</a>]</cite>. Lalonde et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib41" title="">41</a>]</cite> inserted compatible objects from a large database into a target scene. Karsch et al.<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib33" title="">33</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib34" title="">34</a>]</cite> inserted synthetic 3D objects through the estimation of geometry and lighting annotations. Since then, image compositing techniques have approached the problem along different dimensions.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.p2">
<p class="ltx_p" id="S2.p2.1"><span class="ltx_text ltx_font_bold" id="S2.p2.1.1">Using light estimators.</span>
This body of work achieves compositing by using HDR lighting for scenes and relighting virtual 3D objects within them. Learning-based methods estimate illumination through both non-parametric models <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib22" title="">22</a>]</cite> and parametric models <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib21" title="">21</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib30" title="">30</a>]</cite>. Recent advancements enable editable illumination by merging parametric and non-parametric approaches for lighting adjustments <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib72" title="">72</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib43" title="">43</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib70" title="">70</a>]</cite>.
Efforts to tackle complex scene lighting have led to methods for estimating spatially-varying illumination <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib23" title="">23</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib42" title="">42</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib92" title="">92</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib65" title="">65</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib13" title="">13</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib24" title="">24</a>]</cite>. Unlike these methods, <span class="ltx_text ltx_font_smallcaps" id="S2.p2.1.2">ZeroComp</span> does not rely on explicit lighting estimation and rendering; instead, it jointly learns these tasks.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.p3">
<p class="ltx_p" id="S2.p3.1"><span class="ltx_text ltx_font_bold" id="S2.p3.1.1">Intrinsic images,</span>
or the process of factorizing an image into albedo and shading, has long been studied <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib3" title="">3</a>]</cite>. More recent approaches also recover other intrinsic maps such as depth and surface normals <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib20" title="">20</a>]</cite>.
Several approaches try to achieve better decomposition through incorporating human annotations <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib90" title="">90</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib39" title="">39</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib73" title="">73</a>]</cite>, ordinal information <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib94" title="">94</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib10" title="">10</a>]</cite>, physical insights <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib79" title="">79</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib54" title="">54</a>]</cite>, shade tree structure <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib25" title="">25</a>]</cite>, or multi-view information <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib50" title="">50</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib78" title="">78</a>]</cite>. Other methods  <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib42" title="">42</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib92" title="">92</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib13" title="">13</a>]</cite> estimate shape, spatially-varying lighting, and non-Lambertian surface reflectance for improved compositing. Recent methods have utilized pretrained StyleGAN or SD for the extraction of intrinsic images, either via latent search <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib6" title="">6</a>]</cite>, low-rank adaptations <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib19" title="">19</a>]</cite>, through a probabilistic formulation <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib38" title="">38</a>]</cite>, or though ControlNet <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib47" title="">47</a>]</cite>. Concurrently, RGB<math alttext="\leftrightarrow" class="ltx_Math" display="inline" id="S2.p3.1.m1.1"><semantics id="S2.p3.1.m1.1a"><mo id="S2.p3.1.m1.1.1" stretchy="false" xref="S2.p3.1.m1.1.1.cmml">↔</mo><annotation-xml encoding="MathML-Content" id="S2.p3.1.m1.1b"><ci id="S2.p3.1.m1.1.1.cmml" xref="S2.p3.1.m1.1.1">↔</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p3.1.m1.1c">\leftrightarrow</annotation><annotation encoding="application/x-llamapun" id="S2.p3.1.m1.1d">↔</annotation></semantics></math>X <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib83" title="">83</a>]</cite> decomposes images into intrinsic maps and synthesizes them using material and lighting-aware diffusion models.
Intrinsic images can be used to reshade inserted objects <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib5" title="">5</a>]</cite>. This can be extended by adjusting the shading in the foreground and background separately for compatible composites <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib11" title="">11</a>]</cite>. StyLitGAN <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib8" title="">8</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib7" title="">7</a>]</cite> relits real images by manipulating StyleGAN latent space. LightIt <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib36" title="">36</a>]</cite> controls lighting using intrinsics in diffusion models.
Similarly, we use intrinsic images for compositing and leverage scene priors through pretrained diffusion models.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.p4">
<p class="ltx_p" id="S2.p4.1"><span class="ltx_text ltx_font_bold" id="S2.p4.1.1">Shadows.</span> Compositing accurate shadows is crucial for photorealism <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib14" title="">14</a>]</cite>. Recent advances include shadow generation <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib46" title="">46</a>]</cite> and harmonization <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib69" title="">69</a>]</cite> models. Techniques by Sheng et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib61" title="">61</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib62" title="">62</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib63" title="">63</a>]</cite> use pixel height information to generate various light effects, including shadows. In contrast, our approach implicitly learns to generate realistic shadows without shadow-specific supervision, eliminating the need for a separate shadow generation or correction pipeline.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.p5">
<p class="ltx_p" id="S2.p5.1"><span class="ltx_text ltx_font_bold" id="S2.p5.1.1">Image harmonization.</span> Methods aiming to harmonize the color distribution of inserted objects for coherence with the background include <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib55" title="">55</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib52" title="">52</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib40" title="">40</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib66" title="">66</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib68" title="">68</a>]</cite>. Relevant methods also exploit intrinsic images for harmonization <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib29" title="">29</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib11" title="">11</a>]</cite>. These approaches typically focus on adjusting object colors and, unlike our work, cannot synthesize shadows.</p>
</div>
<figure class="ltx_figure" id="S2.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="441" id="S2.F2.g1" src="x1.png" width="789"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S2.F2.13.6.1" style="font-size:90%;">Figure 2</span>: </span><span class="ltx_text" id="S2.F2.10.5" style="font-size:90%;">Overview of our zero-shot intrinsic compositing pipeline. The input background image <math alttext="x_{\mathrm{bg}}" class="ltx_Math" display="inline" id="S2.F2.6.1.m1.1"><semantics id="S2.F2.6.1.m1.1b"><msub id="S2.F2.6.1.m1.1.1" xref="S2.F2.6.1.m1.1.1.cmml"><mi id="S2.F2.6.1.m1.1.1.2" xref="S2.F2.6.1.m1.1.1.2.cmml">x</mi><mi id="S2.F2.6.1.m1.1.1.3" xref="S2.F2.6.1.m1.1.1.3.cmml">bg</mi></msub><annotation-xml encoding="MathML-Content" id="S2.F2.6.1.m1.1c"><apply id="S2.F2.6.1.m1.1.1.cmml" xref="S2.F2.6.1.m1.1.1"><csymbol cd="ambiguous" id="S2.F2.6.1.m1.1.1.1.cmml" xref="S2.F2.6.1.m1.1.1">subscript</csymbol><ci id="S2.F2.6.1.m1.1.1.2.cmml" xref="S2.F2.6.1.m1.1.1.2">𝑥</ci><ci id="S2.F2.6.1.m1.1.1.3.cmml" xref="S2.F2.6.1.m1.1.1.3">bg</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F2.6.1.m1.1d">x_{\mathrm{bg}}</annotation><annotation encoding="application/x-llamapun" id="S2.F2.6.1.m1.1e">italic_x start_POSTSUBSCRIPT roman_bg end_POSTSUBSCRIPT</annotation></semantics></math> (top-left) is first converted to intrinsic layers <math alttext="\mathbf{i}_{\mathrm{bg}}" class="ltx_Math" display="inline" id="S2.F2.7.2.m2.1"><semantics id="S2.F2.7.2.m2.1b"><msub id="S2.F2.7.2.m2.1.1" xref="S2.F2.7.2.m2.1.1.cmml"><mi id="S2.F2.7.2.m2.1.1.2" xref="S2.F2.7.2.m2.1.1.2.cmml">𝐢</mi><mi id="S2.F2.7.2.m2.1.1.3" xref="S2.F2.7.2.m2.1.1.3.cmml">bg</mi></msub><annotation-xml encoding="MathML-Content" id="S2.F2.7.2.m2.1c"><apply id="S2.F2.7.2.m2.1.1.cmml" xref="S2.F2.7.2.m2.1.1"><csymbol cd="ambiguous" id="S2.F2.7.2.m2.1.1.1.cmml" xref="S2.F2.7.2.m2.1.1">subscript</csymbol><ci id="S2.F2.7.2.m2.1.1.2.cmml" xref="S2.F2.7.2.m2.1.1.2">𝐢</ci><ci id="S2.F2.7.2.m2.1.1.3.cmml" xref="S2.F2.7.2.m2.1.1.3">bg</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F2.7.2.m2.1d">\mathbf{i}_{\mathrm{bg}}</annotation><annotation encoding="application/x-llamapun" id="S2.F2.7.2.m2.1e">bold_i start_POSTSUBSCRIPT roman_bg end_POSTSUBSCRIPT</annotation></semantics></math> using specialized networks (top, in yellow). In parallel, the corresponding intrinsic layers of the 3D object <math alttext="\mathbf{i}_{\mathrm{obj}}" class="ltx_Math" display="inline" id="S2.F2.8.3.m3.1"><semantics id="S2.F2.8.3.m3.1b"><msub id="S2.F2.8.3.m3.1.1" xref="S2.F2.8.3.m3.1.1.cmml"><mi id="S2.F2.8.3.m3.1.1.2" xref="S2.F2.8.3.m3.1.1.2.cmml">𝐢</mi><mi id="S2.F2.8.3.m3.1.1.3" xref="S2.F2.8.3.m3.1.1.3.cmml">obj</mi></msub><annotation-xml encoding="MathML-Content" id="S2.F2.8.3.m3.1c"><apply id="S2.F2.8.3.m3.1.1.cmml" xref="S2.F2.8.3.m3.1.1"><csymbol cd="ambiguous" id="S2.F2.8.3.m3.1.1.1.cmml" xref="S2.F2.8.3.m3.1.1">subscript</csymbol><ci id="S2.F2.8.3.m3.1.1.2.cmml" xref="S2.F2.8.3.m3.1.1.2">𝐢</ci><ci id="S2.F2.8.3.m3.1.1.3.cmml" xref="S2.F2.8.3.m3.1.1.3">obj</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F2.8.3.m3.1d">\mathbf{i}_{\mathrm{obj}}</annotation><annotation encoding="application/x-llamapun" id="S2.F2.8.3.m3.1e">bold_i start_POSTSUBSCRIPT roman_obj end_POSTSUBSCRIPT</annotation></semantics></math>—except the shading—are rendered using a graphics engine (middle, in blue). Layers are then composited together to obtain the composited intrinsics <math alttext="\mathbf{i}_{\mathrm{comp}}" class="ltx_Math" display="inline" id="S2.F2.9.4.m4.1"><semantics id="S2.F2.9.4.m4.1b"><msub id="S2.F2.9.4.m4.1.1" xref="S2.F2.9.4.m4.1.1.cmml"><mi id="S2.F2.9.4.m4.1.1.2" xref="S2.F2.9.4.m4.1.1.2.cmml">𝐢</mi><mi id="S2.F2.9.4.m4.1.1.3" xref="S2.F2.9.4.m4.1.1.3.cmml">comp</mi></msub><annotation-xml encoding="MathML-Content" id="S2.F2.9.4.m4.1c"><apply id="S2.F2.9.4.m4.1.1.cmml" xref="S2.F2.9.4.m4.1.1"><csymbol cd="ambiguous" id="S2.F2.9.4.m4.1.1.1.cmml" xref="S2.F2.9.4.m4.1.1">subscript</csymbol><ci id="S2.F2.9.4.m4.1.1.2.cmml" xref="S2.F2.9.4.m4.1.1.2">𝐢</ci><ci id="S2.F2.9.4.m4.1.1.3.cmml" xref="S2.F2.9.4.m4.1.1.3">comp</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F2.9.4.m4.1d">\mathbf{i}_{\mathrm{comp}}</annotation><annotation encoding="application/x-llamapun" id="S2.F2.9.4.m4.1e">bold_i start_POSTSUBSCRIPT roman_comp end_POSTSUBSCRIPT</annotation></semantics></math> (bottom, in green). From this, our trained <span class="ltx_text ltx_font_smallcaps" id="S2.F2.10.5.1">ZeroComp</span> renders the final composite <math alttext="x" class="ltx_Math" display="inline" id="S2.F2.10.5.m5.1"><semantics id="S2.F2.10.5.m5.1b"><mi id="S2.F2.10.5.m5.1.1" xref="S2.F2.10.5.m5.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S2.F2.10.5.m5.1c"><ci id="S2.F2.10.5.m5.1.1.cmml" xref="S2.F2.10.5.m5.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.F2.10.5.m5.1d">x</annotation><annotation encoding="application/x-llamapun" id="S2.F2.10.5.m5.1e">italic_x</annotation></semantics></math> (top-right).</span></figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S2.p6">
<p class="ltx_p" id="S2.p6.1"><span class="ltx_text ltx_font_bold" id="S2.p6.1.1">Using generative models.</span> Large generative models like Stable Diffusion (SD) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib58" title="">58</a>]</cite> have led to the development of image editing applications by adapting pretrained models through fine-tuning <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib31" title="">31</a>]</cite>, or by learning adapters <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib77" title="">77</a>]</cite>. We employ ControlNet <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib86" title="">86</a>]</cite> to train a model that accepts intrinsic images and learns to render the final image.</p>
</div>
<div class="ltx_para" id="S2.p7">
<p class="ltx_p" id="S2.p7.1">Recent methods in object compositing have largely leveraged SD. 3DIT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib48" title="">48</a>]</cite> uses language instructions for object insertion but requires paired images for training. CustomNet <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib80" title="">80</a>]</cite> manipulates viewpoint, location, and background, while PhD <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib88" title="">88</a>]</cite> employs a two-step harmonization process. ControlCom <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib85" title="">85</a>]</cite> and ObjectStitch <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib64" title="">64</a>]</cite> focus on embedding manipulation. Paint by Example <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib75" title="">75</a>]</cite> uses exemplar-guided compositing, and AnyDoor <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib12" title="">12</a>]</cite> uses identity tokens and a frequency-aware feature extractor for detailed object representation. More recent works such as DiffusionLight <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib51" title="">51</a>]</cite> (lighting estimation), Alchemist <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib60" title="">60</a>]</cite> (material control), DiLightNet <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib82" title="">82</a>]</cite> (object rendering), and others <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib89" title="">89</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib53" title="">53</a>]</cite> (multi-view relighting) rely on specifically-designed training sets. In contrast, our method uniquely integrates intrinsic image handling with ControlNet <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib86" title="">86</a>]</cite>, enabling zero-shot 3D object compositing without explicit feature manipulation or multi-step processes.</p>
</div>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span><span class="ltx_text ltx_font_smallcaps" id="S3.1.1">ZeroComp</span>
</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1"><span class="ltx_text ltx_font_smallcaps" id="S3.p1.1.1">ZeroComp</span> is a neural renderer that leverages the power of Stable Diffusion <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib58" title="">58</a>]</cite> and ControlNet <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib86" title="">86</a>]</cite>, which is trained to render images from their intrinsic maps, namely depth, normals, albedo and shading. The distinctive aspect of our model is its ability to integrate 3D objects into 2D images without requiring training on paired images of scenes both with and without the objects. We refer to this capability as zero-shot compositing, allowing the model to perform compositing tasks it hasn’t been explicitly trained for.</p>
</div>
<div class="ltx_para" id="S3.p2">
<p class="ltx_p" id="S3.p2.1">A crucial element of <span class="ltx_text ltx_font_smallcaps" id="S3.p2.1.1">ZeroComp</span> involves training it to develop an implicit understanding of the lighting and geometry from the intrinsic maps, enabling it to correct the appearance of the shading where it is missing. During inference, objects can be inserted into scenes using their albedo, normals, and depth maps. For the shading component, regions corresponding to the inserted objects are masked, and our trained <span class="ltx_text ltx_font_smallcaps" id="S3.p2.1.2">ZeroComp</span> adjusts this shading to align with the scene’s original lighting. An overview of our zero-shot intrinsic compositing approach is illustrated in <a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#S2.F2" title="In 2 Related work ‣ ZeroComp: Zero-shot Object Compositing from Image Intrinsics via Diffusion"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Training <span class="ltx_text ltx_font_smallcaps" id="S3.SS1.1.1">ZeroComp</span>
</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">The training process is meticulously designed to handle the intrinsic components of images where shading is partially available. The model learns to reconstruct scenes from provided intrinsic maps while being conditioned on randomly masked regions within the shading channels. This approach encourages the model to reason about the scene’s lighting and geometry autonomously.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p2">
<p class="ltx_p" id="S3.SS1.p2.1"><span class="ltx_text ltx_font_bold" id="S3.SS1.p2.1.1">Training data.</span>
The synthetic OpenRooms <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib44" title="">44</a>]</cite> is used as sole training data. This dataset provides depth, normals, albedo, and partial shading information (division between the image and albedo) necessary to understand and recreate complex scenes. Our method can be easily extended to additional intrinsic maps if available, such as roughness and metallic maps in InteriorVerse <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib91" title="">91</a>]</cite>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p3">
<p class="ltx_p" id="S3.SS1.p3.1"><span class="ltx_text ltx_font_bold" id="S3.SS1.p3.1.1">Shading masks.</span>
During training, random masks <math alttext="s" class="ltx_Math" display="inline" id="S3.SS1.p3.1.m1.1"><semantics id="S3.SS1.p3.1.m1.1a"><mi id="S3.SS1.p3.1.m1.1.1" xref="S3.SS1.p3.1.m1.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.1.m1.1b"><ci id="S3.SS1.p3.1.m1.1.1.cmml" xref="S3.SS1.p3.1.m1.1.1">𝑠</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.1.m1.1c">s</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p3.1.m1.1d">italic_s</annotation></semantics></math> are generated using a mix of random rectangles/circles (60% probability) and by removing or keeping the entire shading maps (30% and 10% probability resp., see supp.).</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p4">
<p class="ltx_p" id="S3.SS1.p4.11"><span class="ltx_text ltx_font_bold" id="S3.SS1.p4.11.1">Learning objectives and losses.</span>

The primary training objective is to accurately render images based on intrinsic maps while effectively inpainting missing shading information. This is formalized through a loss function that conditions the rendering process on intrinsic maps and a mask indicating regions for shading inpainting. To improve the fidelity of the hue in the background, we follow <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib45" title="">45</a>]</cite> and use zero terminal SNR, v prediction, DDIM scheduling and trailing timestep selection. The loss function is defined as:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathcal{L}=\mathbb{E}_{t,x_{0},\epsilon,s}\left\|v_{t}-\tilde{v}_{t}(x_{t},%
\mathbf{i},s,t)\right\|_{2}^{2}\,," class="ltx_Math" display="block" id="S3.E1.m1.8"><semantics id="S3.E1.m1.8a"><mrow id="S3.E1.m1.8.8.1" xref="S3.E1.m1.8.8.1.1.cmml"><mrow id="S3.E1.m1.8.8.1.1" xref="S3.E1.m1.8.8.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E1.m1.8.8.1.1.3" xref="S3.E1.m1.8.8.1.1.3.cmml">ℒ</mi><mo id="S3.E1.m1.8.8.1.1.2" xref="S3.E1.m1.8.8.1.1.2.cmml">=</mo><mrow id="S3.E1.m1.8.8.1.1.1" xref="S3.E1.m1.8.8.1.1.1.cmml"><msub id="S3.E1.m1.8.8.1.1.1.3" xref="S3.E1.m1.8.8.1.1.1.3.cmml"><mi id="S3.E1.m1.8.8.1.1.1.3.2" xref="S3.E1.m1.8.8.1.1.1.3.2.cmml">𝔼</mi><mrow id="S3.E1.m1.4.4.4.4" xref="S3.E1.m1.4.4.4.5.cmml"><mi id="S3.E1.m1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.cmml">t</mi><mo id="S3.E1.m1.4.4.4.4.2" xref="S3.E1.m1.4.4.4.5.cmml">,</mo><msub id="S3.E1.m1.4.4.4.4.1" xref="S3.E1.m1.4.4.4.4.1.cmml"><mi id="S3.E1.m1.4.4.4.4.1.2" xref="S3.E1.m1.4.4.4.4.1.2.cmml">x</mi><mn id="S3.E1.m1.4.4.4.4.1.3" xref="S3.E1.m1.4.4.4.4.1.3.cmml">0</mn></msub><mo id="S3.E1.m1.4.4.4.4.3" xref="S3.E1.m1.4.4.4.5.cmml">,</mo><mi id="S3.E1.m1.2.2.2.2" xref="S3.E1.m1.2.2.2.2.cmml">ϵ</mi><mo id="S3.E1.m1.4.4.4.4.4" xref="S3.E1.m1.4.4.4.5.cmml">,</mo><mi id="S3.E1.m1.3.3.3.3" xref="S3.E1.m1.3.3.3.3.cmml">s</mi></mrow></msub><mo id="S3.E1.m1.8.8.1.1.1.2" xref="S3.E1.m1.8.8.1.1.1.2.cmml">⁢</mo><msubsup id="S3.E1.m1.8.8.1.1.1.1" xref="S3.E1.m1.8.8.1.1.1.1.cmml"><mrow id="S3.E1.m1.8.8.1.1.1.1.1.1.1" xref="S3.E1.m1.8.8.1.1.1.1.1.1.2.cmml"><mo id="S3.E1.m1.8.8.1.1.1.1.1.1.1.2" xref="S3.E1.m1.8.8.1.1.1.1.1.1.2.1.cmml">‖</mo><mrow id="S3.E1.m1.8.8.1.1.1.1.1.1.1.1" xref="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.cmml"><msub id="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.3" xref="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.3.cmml"><mi id="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.3.2" xref="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.3.2.cmml">v</mi><mi id="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.3.3" xref="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.3.3.cmml">t</mi></msub><mo id="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.2" xref="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.2.cmml">−</mo><mrow id="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.1" xref="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.1.cmml"><msub id="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.1.3" xref="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.1.3.cmml"><mover accent="true" id="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.1.3.2" xref="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.1.3.2.cmml"><mi id="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.1.3.2.2" xref="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.1.3.2.2.cmml">v</mi><mo id="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.1.3.2.1" xref="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.1.3.2.1.cmml">~</mo></mover><mi id="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.1.3.3" xref="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.1.3.3.cmml">t</mi></msub><mo id="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.1.2" xref="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.1.2.cmml">⁢</mo><mrow id="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.1.1.2.cmml"><mo id="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.1.1.1.2" stretchy="false" xref="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.1.1.2.cmml">(</mo><msub id="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml">x</mi><mi id="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml">t</mi></msub><mo id="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.1.1.2.cmml">,</mo><mi id="S3.E1.m1.5.5" xref="S3.E1.m1.5.5.cmml">𝐢</mi><mo id="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.1.1.1.4" xref="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.1.1.2.cmml">,</mo><mi id="S3.E1.m1.6.6" xref="S3.E1.m1.6.6.cmml">s</mi><mo id="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.1.1.1.5" xref="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.1.1.2.cmml">,</mo><mi id="S3.E1.m1.7.7" xref="S3.E1.m1.7.7.cmml">t</mi><mo id="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.1.1.1.6" stretchy="false" xref="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.1.1.2.cmml">)</mo></mrow></mrow></mrow><mo id="S3.E1.m1.8.8.1.1.1.1.1.1.1.3" xref="S3.E1.m1.8.8.1.1.1.1.1.1.2.1.cmml">‖</mo></mrow><mn id="S3.E1.m1.8.8.1.1.1.1.1.3" xref="S3.E1.m1.8.8.1.1.1.1.1.3.cmml">2</mn><mn id="S3.E1.m1.8.8.1.1.1.1.3" xref="S3.E1.m1.8.8.1.1.1.1.3.cmml">2</mn></msubsup></mrow></mrow><mo id="S3.E1.m1.8.8.1.2" xref="S3.E1.m1.8.8.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.8b"><apply id="S3.E1.m1.8.8.1.1.cmml" xref="S3.E1.m1.8.8.1"><eq id="S3.E1.m1.8.8.1.1.2.cmml" xref="S3.E1.m1.8.8.1.1.2"></eq><ci id="S3.E1.m1.8.8.1.1.3.cmml" xref="S3.E1.m1.8.8.1.1.3">ℒ</ci><apply id="S3.E1.m1.8.8.1.1.1.cmml" xref="S3.E1.m1.8.8.1.1.1"><times id="S3.E1.m1.8.8.1.1.1.2.cmml" xref="S3.E1.m1.8.8.1.1.1.2"></times><apply id="S3.E1.m1.8.8.1.1.1.3.cmml" xref="S3.E1.m1.8.8.1.1.1.3"><csymbol cd="ambiguous" id="S3.E1.m1.8.8.1.1.1.3.1.cmml" xref="S3.E1.m1.8.8.1.1.1.3">subscript</csymbol><ci id="S3.E1.m1.8.8.1.1.1.3.2.cmml" xref="S3.E1.m1.8.8.1.1.1.3.2">𝔼</ci><list id="S3.E1.m1.4.4.4.5.cmml" xref="S3.E1.m1.4.4.4.4"><ci id="S3.E1.m1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1">𝑡</ci><apply id="S3.E1.m1.4.4.4.4.1.cmml" xref="S3.E1.m1.4.4.4.4.1"><csymbol cd="ambiguous" id="S3.E1.m1.4.4.4.4.1.1.cmml" xref="S3.E1.m1.4.4.4.4.1">subscript</csymbol><ci id="S3.E1.m1.4.4.4.4.1.2.cmml" xref="S3.E1.m1.4.4.4.4.1.2">𝑥</ci><cn id="S3.E1.m1.4.4.4.4.1.3.cmml" type="integer" xref="S3.E1.m1.4.4.4.4.1.3">0</cn></apply><ci id="S3.E1.m1.2.2.2.2.cmml" xref="S3.E1.m1.2.2.2.2">italic-ϵ</ci><ci id="S3.E1.m1.3.3.3.3.cmml" xref="S3.E1.m1.3.3.3.3">𝑠</ci></list></apply><apply id="S3.E1.m1.8.8.1.1.1.1.cmml" xref="S3.E1.m1.8.8.1.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.8.8.1.1.1.1.2.cmml" xref="S3.E1.m1.8.8.1.1.1.1">superscript</csymbol><apply id="S3.E1.m1.8.8.1.1.1.1.1.cmml" xref="S3.E1.m1.8.8.1.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.8.8.1.1.1.1.1.2.cmml" xref="S3.E1.m1.8.8.1.1.1.1">subscript</csymbol><apply id="S3.E1.m1.8.8.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.8.8.1.1.1.1.1.1.1"><csymbol cd="latexml" id="S3.E1.m1.8.8.1.1.1.1.1.1.2.1.cmml" xref="S3.E1.m1.8.8.1.1.1.1.1.1.1.2">norm</csymbol><apply id="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.8.8.1.1.1.1.1.1.1.1"><minus id="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.2"></minus><apply id="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.3.2">𝑣</ci><ci id="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.3.3.cmml" xref="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.3.3">𝑡</ci></apply><apply id="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.1"><times id="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.1.2"></times><apply id="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.1.3">subscript</csymbol><apply id="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.1.3.2"><ci id="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.1.3.2.1.cmml" xref="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.1.3.2.1">~</ci><ci id="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.1.3.2.2.cmml" xref="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.1.3.2.2">𝑣</ci></apply><ci id="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.1.3.3">𝑡</ci></apply><vector id="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.1.1.1"><apply id="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.1.1.1.1.2">𝑥</ci><ci id="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.1.1.1.1.3">𝑡</ci></apply><ci id="S3.E1.m1.5.5.cmml" xref="S3.E1.m1.5.5">𝐢</ci><ci id="S3.E1.m1.6.6.cmml" xref="S3.E1.m1.6.6">𝑠</ci><ci id="S3.E1.m1.7.7.cmml" xref="S3.E1.m1.7.7">𝑡</ci></vector></apply></apply></apply><cn id="S3.E1.m1.8.8.1.1.1.1.1.3.cmml" type="integer" xref="S3.E1.m1.8.8.1.1.1.1.1.3">2</cn></apply><cn id="S3.E1.m1.8.8.1.1.1.1.3.cmml" type="integer" xref="S3.E1.m1.8.8.1.1.1.1.3">2</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.8c">\mathcal{L}=\mathbb{E}_{t,x_{0},\epsilon,s}\left\|v_{t}-\tilde{v}_{t}(x_{t},%
\mathbf{i},s,t)\right\|_{2}^{2}\,,</annotation><annotation encoding="application/x-llamapun" id="S3.E1.m1.8d">caligraphic_L = blackboard_E start_POSTSUBSCRIPT italic_t , italic_x start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_ϵ , italic_s end_POSTSUBSCRIPT ∥ italic_v start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT - over~ start_ARG italic_v end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , bold_i , italic_s , italic_t ) ∥ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS1.p4.10">where <math alttext="v_{t}" class="ltx_Math" display="inline" id="S3.SS1.p4.1.m1.1"><semantics id="S3.SS1.p4.1.m1.1a"><msub id="S3.SS1.p4.1.m1.1.1" xref="S3.SS1.p4.1.m1.1.1.cmml"><mi id="S3.SS1.p4.1.m1.1.1.2" xref="S3.SS1.p4.1.m1.1.1.2.cmml">v</mi><mi id="S3.SS1.p4.1.m1.1.1.3" xref="S3.SS1.p4.1.m1.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.1.m1.1b"><apply id="S3.SS1.p4.1.m1.1.1.cmml" xref="S3.SS1.p4.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p4.1.m1.1.1.1.cmml" xref="S3.SS1.p4.1.m1.1.1">subscript</csymbol><ci id="S3.SS1.p4.1.m1.1.1.2.cmml" xref="S3.SS1.p4.1.m1.1.1.2">𝑣</ci><ci id="S3.SS1.p4.1.m1.1.1.3.cmml" xref="S3.SS1.p4.1.m1.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.1.m1.1c">v_{t}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p4.1.m1.1d">italic_v start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> progressively evolves from image to noise over the denoising time steps (see <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib45" title="">45</a>]</cite>). <math alttext="x_{t}" class="ltx_Math" display="inline" id="S3.SS1.p4.2.m2.1"><semantics id="S3.SS1.p4.2.m2.1a"><msub id="S3.SS1.p4.2.m2.1.1" xref="S3.SS1.p4.2.m2.1.1.cmml"><mi id="S3.SS1.p4.2.m2.1.1.2" xref="S3.SS1.p4.2.m2.1.1.2.cmml">x</mi><mi id="S3.SS1.p4.2.m2.1.1.3" xref="S3.SS1.p4.2.m2.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.2.m2.1b"><apply id="S3.SS1.p4.2.m2.1.1.cmml" xref="S3.SS1.p4.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p4.2.m2.1.1.1.cmml" xref="S3.SS1.p4.2.m2.1.1">subscript</csymbol><ci id="S3.SS1.p4.2.m2.1.1.2.cmml" xref="S3.SS1.p4.2.m2.1.1.2">𝑥</ci><ci id="S3.SS1.p4.2.m2.1.1.3.cmml" xref="S3.SS1.p4.2.m2.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.2.m2.1c">x_{t}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p4.2.m2.1d">italic_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> is the generated image at time step <math alttext="t" class="ltx_Math" display="inline" id="S3.SS1.p4.3.m3.1"><semantics id="S3.SS1.p4.3.m3.1a"><mi id="S3.SS1.p4.3.m3.1.1" xref="S3.SS1.p4.3.m3.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.3.m3.1b"><ci id="S3.SS1.p4.3.m3.1.1.cmml" xref="S3.SS1.p4.3.m3.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.3.m3.1c">t</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p4.3.m3.1d">italic_t</annotation></semantics></math>, <math alttext="\mathbf{i}=\{i_{d},i_{n},i_{a},i_{s}\}" class="ltx_Math" display="inline" id="S3.SS1.p4.4.m4.4"><semantics id="S3.SS1.p4.4.m4.4a"><mrow id="S3.SS1.p4.4.m4.4.4" xref="S3.SS1.p4.4.m4.4.4.cmml"><mi id="S3.SS1.p4.4.m4.4.4.6" xref="S3.SS1.p4.4.m4.4.4.6.cmml">𝐢</mi><mo id="S3.SS1.p4.4.m4.4.4.5" xref="S3.SS1.p4.4.m4.4.4.5.cmml">=</mo><mrow id="S3.SS1.p4.4.m4.4.4.4.4" xref="S3.SS1.p4.4.m4.4.4.4.5.cmml"><mo id="S3.SS1.p4.4.m4.4.4.4.4.5" stretchy="false" xref="S3.SS1.p4.4.m4.4.4.4.5.cmml">{</mo><msub id="S3.SS1.p4.4.m4.1.1.1.1.1" xref="S3.SS1.p4.4.m4.1.1.1.1.1.cmml"><mi id="S3.SS1.p4.4.m4.1.1.1.1.1.2" xref="S3.SS1.p4.4.m4.1.1.1.1.1.2.cmml">i</mi><mi id="S3.SS1.p4.4.m4.1.1.1.1.1.3" xref="S3.SS1.p4.4.m4.1.1.1.1.1.3.cmml">d</mi></msub><mo id="S3.SS1.p4.4.m4.4.4.4.4.6" xref="S3.SS1.p4.4.m4.4.4.4.5.cmml">,</mo><msub id="S3.SS1.p4.4.m4.2.2.2.2.2" xref="S3.SS1.p4.4.m4.2.2.2.2.2.cmml"><mi id="S3.SS1.p4.4.m4.2.2.2.2.2.2" xref="S3.SS1.p4.4.m4.2.2.2.2.2.2.cmml">i</mi><mi id="S3.SS1.p4.4.m4.2.2.2.2.2.3" xref="S3.SS1.p4.4.m4.2.2.2.2.2.3.cmml">n</mi></msub><mo id="S3.SS1.p4.4.m4.4.4.4.4.7" xref="S3.SS1.p4.4.m4.4.4.4.5.cmml">,</mo><msub id="S3.SS1.p4.4.m4.3.3.3.3.3" xref="S3.SS1.p4.4.m4.3.3.3.3.3.cmml"><mi id="S3.SS1.p4.4.m4.3.3.3.3.3.2" xref="S3.SS1.p4.4.m4.3.3.3.3.3.2.cmml">i</mi><mi id="S3.SS1.p4.4.m4.3.3.3.3.3.3" xref="S3.SS1.p4.4.m4.3.3.3.3.3.3.cmml">a</mi></msub><mo id="S3.SS1.p4.4.m4.4.4.4.4.8" xref="S3.SS1.p4.4.m4.4.4.4.5.cmml">,</mo><msub id="S3.SS1.p4.4.m4.4.4.4.4.4" xref="S3.SS1.p4.4.m4.4.4.4.4.4.cmml"><mi id="S3.SS1.p4.4.m4.4.4.4.4.4.2" xref="S3.SS1.p4.4.m4.4.4.4.4.4.2.cmml">i</mi><mi id="S3.SS1.p4.4.m4.4.4.4.4.4.3" xref="S3.SS1.p4.4.m4.4.4.4.4.4.3.cmml">s</mi></msub><mo id="S3.SS1.p4.4.m4.4.4.4.4.9" stretchy="false" xref="S3.SS1.p4.4.m4.4.4.4.5.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.4.m4.4b"><apply id="S3.SS1.p4.4.m4.4.4.cmml" xref="S3.SS1.p4.4.m4.4.4"><eq id="S3.SS1.p4.4.m4.4.4.5.cmml" xref="S3.SS1.p4.4.m4.4.4.5"></eq><ci id="S3.SS1.p4.4.m4.4.4.6.cmml" xref="S3.SS1.p4.4.m4.4.4.6">𝐢</ci><set id="S3.SS1.p4.4.m4.4.4.4.5.cmml" xref="S3.SS1.p4.4.m4.4.4.4.4"><apply id="S3.SS1.p4.4.m4.1.1.1.1.1.cmml" xref="S3.SS1.p4.4.m4.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p4.4.m4.1.1.1.1.1.1.cmml" xref="S3.SS1.p4.4.m4.1.1.1.1.1">subscript</csymbol><ci id="S3.SS1.p4.4.m4.1.1.1.1.1.2.cmml" xref="S3.SS1.p4.4.m4.1.1.1.1.1.2">𝑖</ci><ci id="S3.SS1.p4.4.m4.1.1.1.1.1.3.cmml" xref="S3.SS1.p4.4.m4.1.1.1.1.1.3">𝑑</ci></apply><apply id="S3.SS1.p4.4.m4.2.2.2.2.2.cmml" xref="S3.SS1.p4.4.m4.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p4.4.m4.2.2.2.2.2.1.cmml" xref="S3.SS1.p4.4.m4.2.2.2.2.2">subscript</csymbol><ci id="S3.SS1.p4.4.m4.2.2.2.2.2.2.cmml" xref="S3.SS1.p4.4.m4.2.2.2.2.2.2">𝑖</ci><ci id="S3.SS1.p4.4.m4.2.2.2.2.2.3.cmml" xref="S3.SS1.p4.4.m4.2.2.2.2.2.3">𝑛</ci></apply><apply id="S3.SS1.p4.4.m4.3.3.3.3.3.cmml" xref="S3.SS1.p4.4.m4.3.3.3.3.3"><csymbol cd="ambiguous" id="S3.SS1.p4.4.m4.3.3.3.3.3.1.cmml" xref="S3.SS1.p4.4.m4.3.3.3.3.3">subscript</csymbol><ci id="S3.SS1.p4.4.m4.3.3.3.3.3.2.cmml" xref="S3.SS1.p4.4.m4.3.3.3.3.3.2">𝑖</ci><ci id="S3.SS1.p4.4.m4.3.3.3.3.3.3.cmml" xref="S3.SS1.p4.4.m4.3.3.3.3.3.3">𝑎</ci></apply><apply id="S3.SS1.p4.4.m4.4.4.4.4.4.cmml" xref="S3.SS1.p4.4.m4.4.4.4.4.4"><csymbol cd="ambiguous" id="S3.SS1.p4.4.m4.4.4.4.4.4.1.cmml" xref="S3.SS1.p4.4.m4.4.4.4.4.4">subscript</csymbol><ci id="S3.SS1.p4.4.m4.4.4.4.4.4.2.cmml" xref="S3.SS1.p4.4.m4.4.4.4.4.4.2">𝑖</ci><ci id="S3.SS1.p4.4.m4.4.4.4.4.4.3.cmml" xref="S3.SS1.p4.4.m4.4.4.4.4.4.3">𝑠</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.4.m4.4c">\mathbf{i}=\{i_{d},i_{n},i_{a},i_{s}\}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p4.4.m4.4d">bold_i = { italic_i start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT , italic_i start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT , italic_i start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT , italic_i start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT }</annotation></semantics></math> is the intrinsic conditions provided to the model, containing depth, normals, albedo and shading resp., and <math alttext="\tilde{v}_{t}(\cdot)" class="ltx_Math" display="inline" id="S3.SS1.p4.5.m5.1"><semantics id="S3.SS1.p4.5.m5.1a"><mrow id="S3.SS1.p4.5.m5.1.2" xref="S3.SS1.p4.5.m5.1.2.cmml"><msub id="S3.SS1.p4.5.m5.1.2.2" xref="S3.SS1.p4.5.m5.1.2.2.cmml"><mover accent="true" id="S3.SS1.p4.5.m5.1.2.2.2" xref="S3.SS1.p4.5.m5.1.2.2.2.cmml"><mi id="S3.SS1.p4.5.m5.1.2.2.2.2" xref="S3.SS1.p4.5.m5.1.2.2.2.2.cmml">v</mi><mo id="S3.SS1.p4.5.m5.1.2.2.2.1" xref="S3.SS1.p4.5.m5.1.2.2.2.1.cmml">~</mo></mover><mi id="S3.SS1.p4.5.m5.1.2.2.3" xref="S3.SS1.p4.5.m5.1.2.2.3.cmml">t</mi></msub><mo id="S3.SS1.p4.5.m5.1.2.1" xref="S3.SS1.p4.5.m5.1.2.1.cmml">⁢</mo><mrow id="S3.SS1.p4.5.m5.1.2.3.2" xref="S3.SS1.p4.5.m5.1.2.cmml"><mo id="S3.SS1.p4.5.m5.1.2.3.2.1" stretchy="false" xref="S3.SS1.p4.5.m5.1.2.cmml">(</mo><mo id="S3.SS1.p4.5.m5.1.1" lspace="0em" rspace="0em" xref="S3.SS1.p4.5.m5.1.1.cmml">⋅</mo><mo id="S3.SS1.p4.5.m5.1.2.3.2.2" stretchy="false" xref="S3.SS1.p4.5.m5.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.5.m5.1b"><apply id="S3.SS1.p4.5.m5.1.2.cmml" xref="S3.SS1.p4.5.m5.1.2"><times id="S3.SS1.p4.5.m5.1.2.1.cmml" xref="S3.SS1.p4.5.m5.1.2.1"></times><apply id="S3.SS1.p4.5.m5.1.2.2.cmml" xref="S3.SS1.p4.5.m5.1.2.2"><csymbol cd="ambiguous" id="S3.SS1.p4.5.m5.1.2.2.1.cmml" xref="S3.SS1.p4.5.m5.1.2.2">subscript</csymbol><apply id="S3.SS1.p4.5.m5.1.2.2.2.cmml" xref="S3.SS1.p4.5.m5.1.2.2.2"><ci id="S3.SS1.p4.5.m5.1.2.2.2.1.cmml" xref="S3.SS1.p4.5.m5.1.2.2.2.1">~</ci><ci id="S3.SS1.p4.5.m5.1.2.2.2.2.cmml" xref="S3.SS1.p4.5.m5.1.2.2.2.2">𝑣</ci></apply><ci id="S3.SS1.p4.5.m5.1.2.2.3.cmml" xref="S3.SS1.p4.5.m5.1.2.2.3">𝑡</ci></apply><ci id="S3.SS1.p4.5.m5.1.1.cmml" xref="S3.SS1.p4.5.m5.1.1">⋅</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.5.m5.1c">\tilde{v}_{t}(\cdot)</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p4.5.m5.1d">over~ start_ARG italic_v end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( ⋅ )</annotation></semantics></math> the model prediction. <math alttext="\mathbb{E}_{t,x_{0},\epsilon,s}" class="ltx_Math" display="inline" id="S3.SS1.p4.6.m6.4"><semantics id="S3.SS1.p4.6.m6.4a"><msub id="S3.SS1.p4.6.m6.4.5" xref="S3.SS1.p4.6.m6.4.5.cmml"><mi id="S3.SS1.p4.6.m6.4.5.2" xref="S3.SS1.p4.6.m6.4.5.2.cmml">𝔼</mi><mrow id="S3.SS1.p4.6.m6.4.4.4.4" xref="S3.SS1.p4.6.m6.4.4.4.5.cmml"><mi id="S3.SS1.p4.6.m6.1.1.1.1" xref="S3.SS1.p4.6.m6.1.1.1.1.cmml">t</mi><mo id="S3.SS1.p4.6.m6.4.4.4.4.2" xref="S3.SS1.p4.6.m6.4.4.4.5.cmml">,</mo><msub id="S3.SS1.p4.6.m6.4.4.4.4.1" xref="S3.SS1.p4.6.m6.4.4.4.4.1.cmml"><mi id="S3.SS1.p4.6.m6.4.4.4.4.1.2" xref="S3.SS1.p4.6.m6.4.4.4.4.1.2.cmml">x</mi><mn id="S3.SS1.p4.6.m6.4.4.4.4.1.3" xref="S3.SS1.p4.6.m6.4.4.4.4.1.3.cmml">0</mn></msub><mo id="S3.SS1.p4.6.m6.4.4.4.4.3" xref="S3.SS1.p4.6.m6.4.4.4.5.cmml">,</mo><mi id="S3.SS1.p4.6.m6.2.2.2.2" xref="S3.SS1.p4.6.m6.2.2.2.2.cmml">ϵ</mi><mo id="S3.SS1.p4.6.m6.4.4.4.4.4" xref="S3.SS1.p4.6.m6.4.4.4.5.cmml">,</mo><mi id="S3.SS1.p4.6.m6.3.3.3.3" xref="S3.SS1.p4.6.m6.3.3.3.3.cmml">s</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.6.m6.4b"><apply id="S3.SS1.p4.6.m6.4.5.cmml" xref="S3.SS1.p4.6.m6.4.5"><csymbol cd="ambiguous" id="S3.SS1.p4.6.m6.4.5.1.cmml" xref="S3.SS1.p4.6.m6.4.5">subscript</csymbol><ci id="S3.SS1.p4.6.m6.4.5.2.cmml" xref="S3.SS1.p4.6.m6.4.5.2">𝔼</ci><list id="S3.SS1.p4.6.m6.4.4.4.5.cmml" xref="S3.SS1.p4.6.m6.4.4.4.4"><ci id="S3.SS1.p4.6.m6.1.1.1.1.cmml" xref="S3.SS1.p4.6.m6.1.1.1.1">𝑡</ci><apply id="S3.SS1.p4.6.m6.4.4.4.4.1.cmml" xref="S3.SS1.p4.6.m6.4.4.4.4.1"><csymbol cd="ambiguous" id="S3.SS1.p4.6.m6.4.4.4.4.1.1.cmml" xref="S3.SS1.p4.6.m6.4.4.4.4.1">subscript</csymbol><ci id="S3.SS1.p4.6.m6.4.4.4.4.1.2.cmml" xref="S3.SS1.p4.6.m6.4.4.4.4.1.2">𝑥</ci><cn id="S3.SS1.p4.6.m6.4.4.4.4.1.3.cmml" type="integer" xref="S3.SS1.p4.6.m6.4.4.4.4.1.3">0</cn></apply><ci id="S3.SS1.p4.6.m6.2.2.2.2.cmml" xref="S3.SS1.p4.6.m6.2.2.2.2">italic-ϵ</ci><ci id="S3.SS1.p4.6.m6.3.3.3.3.cmml" xref="S3.SS1.p4.6.m6.3.3.3.3">𝑠</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.6.m6.4c">\mathbb{E}_{t,x_{0},\epsilon,s}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p4.6.m6.4d">blackboard_E start_POSTSUBSCRIPT italic_t , italic_x start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_ϵ , italic_s end_POSTSUBSCRIPT</annotation></semantics></math> denotes the expectation over: denoising time steps <math alttext="t" class="ltx_Math" display="inline" id="S3.SS1.p4.7.m7.1"><semantics id="S3.SS1.p4.7.m7.1a"><mi id="S3.SS1.p4.7.m7.1.1" xref="S3.SS1.p4.7.m7.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.7.m7.1b"><ci id="S3.SS1.p4.7.m7.1.1.cmml" xref="S3.SS1.p4.7.m7.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.7.m7.1c">t</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p4.7.m7.1d">italic_t</annotation></semantics></math>, initial image <math alttext="x_{0}" class="ltx_Math" display="inline" id="S3.SS1.p4.8.m8.1"><semantics id="S3.SS1.p4.8.m8.1a"><msub id="S3.SS1.p4.8.m8.1.1" xref="S3.SS1.p4.8.m8.1.1.cmml"><mi id="S3.SS1.p4.8.m8.1.1.2" xref="S3.SS1.p4.8.m8.1.1.2.cmml">x</mi><mn id="S3.SS1.p4.8.m8.1.1.3" xref="S3.SS1.p4.8.m8.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.8.m8.1b"><apply id="S3.SS1.p4.8.m8.1.1.cmml" xref="S3.SS1.p4.8.m8.1.1"><csymbol cd="ambiguous" id="S3.SS1.p4.8.m8.1.1.1.cmml" xref="S3.SS1.p4.8.m8.1.1">subscript</csymbol><ci id="S3.SS1.p4.8.m8.1.1.2.cmml" xref="S3.SS1.p4.8.m8.1.1.2">𝑥</ci><cn id="S3.SS1.p4.8.m8.1.1.3.cmml" type="integer" xref="S3.SS1.p4.8.m8.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.8.m8.1c">x_{0}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p4.8.m8.1d">italic_x start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT</annotation></semantics></math>, noise <math alttext="\epsilon" class="ltx_Math" display="inline" id="S3.SS1.p4.9.m9.1"><semantics id="S3.SS1.p4.9.m9.1a"><mi id="S3.SS1.p4.9.m9.1.1" xref="S3.SS1.p4.9.m9.1.1.cmml">ϵ</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.9.m9.1b"><ci id="S3.SS1.p4.9.m9.1.1.cmml" xref="S3.SS1.p4.9.m9.1.1">italic-ϵ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.9.m9.1c">\epsilon</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p4.9.m9.1d">italic_ϵ</annotation></semantics></math>, and shading mask <math alttext="s" class="ltx_Math" display="inline" id="S3.SS1.p4.10.m10.1"><semantics id="S3.SS1.p4.10.m10.1a"><mi id="S3.SS1.p4.10.m10.1.1" xref="S3.SS1.p4.10.m10.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.10.m10.1b"><ci id="S3.SS1.p4.10.m10.1.1.cmml" xref="S3.SS1.p4.10.m10.1.1">𝑠</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.10.m10.1c">s</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p4.10.m10.1d">italic_s</annotation></semantics></math>.</p>
</div>
<div class="ltx_para" id="S3.SS1.p5">
<p class="ltx_p" id="S3.SS1.p5.3">By iteratively minimizing <math alttext="\mathcal{L}" class="ltx_Math" display="inline" id="S3.SS1.p5.1.m1.1"><semantics id="S3.SS1.p5.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p5.1.m1.1.1" xref="S3.SS1.p5.1.m1.1.1.cmml">ℒ</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p5.1.m1.1b"><ci id="S3.SS1.p5.1.m1.1.1.cmml" xref="S3.SS1.p5.1.m1.1.1">ℒ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p5.1.m1.1c">\mathcal{L}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p5.1.m1.1d">caligraphic_L</annotation></semantics></math> across various training steps, <span class="ltx_text ltx_font_smallcaps" id="S3.SS1.p5.3.1">ZeroComp</span> progressively refines its ability to render realistic images given image intrinsics. We use a pretrained Stable Diffusion 2.1 as the backbone model and condition it on intrinsic inputs <math alttext="\mathbf{i}" class="ltx_Math" display="inline" id="S3.SS1.p5.2.m2.1"><semantics id="S3.SS1.p5.2.m2.1a"><mi id="S3.SS1.p5.2.m2.1.1" xref="S3.SS1.p5.2.m2.1.1.cmml">𝐢</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p5.2.m2.1b"><ci id="S3.SS1.p5.2.m2.1.1.cmml" xref="S3.SS1.p5.2.m2.1.1">𝐢</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p5.2.m2.1c">\mathbf{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p5.2.m2.1d">bold_i</annotation></semantics></math> using ControlNet. The model is trained for 808k steps with a batch size of 32 at a resolution of <math alttext="512\times 512" class="ltx_Math" display="inline" id="S3.SS1.p5.3.m3.1"><semantics id="S3.SS1.p5.3.m3.1a"><mrow id="S3.SS1.p5.3.m3.1.1" xref="S3.SS1.p5.3.m3.1.1.cmml"><mn id="S3.SS1.p5.3.m3.1.1.2" xref="S3.SS1.p5.3.m3.1.1.2.cmml">512</mn><mo id="S3.SS1.p5.3.m3.1.1.1" lspace="0.222em" rspace="0.222em" xref="S3.SS1.p5.3.m3.1.1.1.cmml">×</mo><mn id="S3.SS1.p5.3.m3.1.1.3" xref="S3.SS1.p5.3.m3.1.1.3.cmml">512</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p5.3.m3.1b"><apply id="S3.SS1.p5.3.m3.1.1.cmml" xref="S3.SS1.p5.3.m3.1.1"><times id="S3.SS1.p5.3.m3.1.1.1.cmml" xref="S3.SS1.p5.3.m3.1.1.1"></times><cn id="S3.SS1.p5.3.m3.1.1.2.cmml" type="integer" xref="S3.SS1.p5.3.m3.1.1.2">512</cn><cn id="S3.SS1.p5.3.m3.1.1.3.cmml" type="integer" xref="S3.SS1.p5.3.m3.1.1.3">512</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p5.3.m3.1c">512\times 512</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p5.3.m3.1d">512 × 512</annotation></semantics></math> using 19,709 training samples.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Zero-shot object compositing using <span class="ltx_text ltx_font_smallcaps" id="S3.SS2.1.1">ZeroComp</span>
</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">Our goal is to place objects into photographs to achieve a seamless blend without prior access to intrinsic scene information. To accomplish this, we utilize available pretrained, off-the-shelf models that infer the intrinsic properties of the background <math alttext="\mathbf{i}_{\mathrm{bg}}" class="ltx_Math" display="inline" id="S3.SS2.p1.1.m1.1"><semantics id="S3.SS2.p1.1.m1.1a"><msub id="S3.SS2.p1.1.m1.1.1" xref="S3.SS2.p1.1.m1.1.1.cmml"><mi id="S3.SS2.p1.1.m1.1.1.2" xref="S3.SS2.p1.1.m1.1.1.2.cmml">𝐢</mi><mi id="S3.SS2.p1.1.m1.1.1.3" xref="S3.SS2.p1.1.m1.1.1.3.cmml">bg</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.m1.1b"><apply id="S3.SS2.p1.1.m1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.1.m1.1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1">subscript</csymbol><ci id="S3.SS2.p1.1.m1.1.1.2.cmml" xref="S3.SS2.p1.1.m1.1.1.2">𝐢</ci><ci id="S3.SS2.p1.1.m1.1.1.3.cmml" xref="S3.SS2.p1.1.m1.1.1.3">bg</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.1.m1.1c">\mathbf{i}_{\mathrm{bg}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.1.m1.1d">bold_i start_POSTSUBSCRIPT roman_bg end_POSTSUBSCRIPT</annotation></semantics></math> from the given photograph (<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#S2.F2" title="In 2 Related work ‣ ZeroComp: Zero-shot Object Compositing from Image Intrinsics via Diffusion"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">2</span></a>, top).
Specifically, we employ ZoeDepth <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib4" title="">4</a>]</cite> to extract depth maps from the input images. For normals, we leverage StableNormal <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib76" title="">76</a>]</cite>. Albedo is estimated using Intrinsic Image Diffusion (IID) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib37" title="">37</a>]</cite>. The shading information is derived by dividing the original image with its albedo.</p>
</div>
<div class="ltx_para" id="S3.SS2.p2">
<p class="ltx_p" id="S3.SS2.p2.1">For the objects we intend to insert (<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#S2.F2" title="In 2 Related work ‣ ZeroComp: Zero-shot Object Compositing from Image Intrinsics via Diffusion"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">2</span></a>, middle), we use the Blender <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib16" title="">16</a>]</cite> graphics engine to render its intrinsic layers <math alttext="\mathbf{i}_{\mathrm{obj}}" class="ltx_Math" display="inline" id="S3.SS2.p2.1.m1.1"><semantics id="S3.SS2.p2.1.m1.1a"><msub id="S3.SS2.p2.1.m1.1.1" xref="S3.SS2.p2.1.m1.1.1.cmml"><mi id="S3.SS2.p2.1.m1.1.1.2" xref="S3.SS2.p2.1.m1.1.1.2.cmml">𝐢</mi><mi id="S3.SS2.p2.1.m1.1.1.3" xref="S3.SS2.p2.1.m1.1.1.3.cmml">obj</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.1.m1.1b"><apply id="S3.SS2.p2.1.m1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.1.m1.1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1">subscript</csymbol><ci id="S3.SS2.p2.1.m1.1.1.2.cmml" xref="S3.SS2.p2.1.m1.1.1.2">𝐢</ci><ci id="S3.SS2.p2.1.m1.1.1.3.cmml" xref="S3.SS2.p2.1.m1.1.1.3">obj</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.1.m1.1c">\mathbf{i}_{\mathrm{obj}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.1.m1.1d">bold_i start_POSTSUBSCRIPT roman_obj end_POSTSUBSCRIPT</annotation></semantics></math>, except shading which is unknown. As with traditional IBL, this allows the user full control over the object pose and location in the target image. Each intrinsic map from the background and object are then composited together through simple compositing</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E2">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="i_{c,\mathrm{comp}}=m\,i_{c,\mathrm{obj}}+(1-m)\,i_{c,\mathrm{bg}}\,," class="ltx_Math" display="block" id="S3.E2.m1.7"><semantics id="S3.E2.m1.7a"><mrow id="S3.E2.m1.7.7.1" xref="S3.E2.m1.7.7.1.1.cmml"><mrow id="S3.E2.m1.7.7.1.1" xref="S3.E2.m1.7.7.1.1.cmml"><msub id="S3.E2.m1.7.7.1.1.3" xref="S3.E2.m1.7.7.1.1.3.cmml"><mi id="S3.E2.m1.7.7.1.1.3.2" xref="S3.E2.m1.7.7.1.1.3.2.cmml">i</mi><mrow id="S3.E2.m1.2.2.2.4" xref="S3.E2.m1.2.2.2.3.cmml"><mi id="S3.E2.m1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.cmml">c</mi><mo id="S3.E2.m1.2.2.2.4.1" xref="S3.E2.m1.2.2.2.3.cmml">,</mo><mi id="S3.E2.m1.2.2.2.2" xref="S3.E2.m1.2.2.2.2.cmml">comp</mi></mrow></msub><mo id="S3.E2.m1.7.7.1.1.2" xref="S3.E2.m1.7.7.1.1.2.cmml">=</mo><mrow id="S3.E2.m1.7.7.1.1.1" xref="S3.E2.m1.7.7.1.1.1.cmml"><mrow id="S3.E2.m1.7.7.1.1.1.3" xref="S3.E2.m1.7.7.1.1.1.3.cmml"><mi id="S3.E2.m1.7.7.1.1.1.3.2" xref="S3.E2.m1.7.7.1.1.1.3.2.cmml">m</mi><mo id="S3.E2.m1.7.7.1.1.1.3.1" lspace="0.170em" xref="S3.E2.m1.7.7.1.1.1.3.1.cmml">⁢</mo><msub id="S3.E2.m1.7.7.1.1.1.3.3" xref="S3.E2.m1.7.7.1.1.1.3.3.cmml"><mi id="S3.E2.m1.7.7.1.1.1.3.3.2" xref="S3.E2.m1.7.7.1.1.1.3.3.2.cmml">i</mi><mrow id="S3.E2.m1.4.4.2.4" xref="S3.E2.m1.4.4.2.3.cmml"><mi id="S3.E2.m1.3.3.1.1" xref="S3.E2.m1.3.3.1.1.cmml">c</mi><mo id="S3.E2.m1.4.4.2.4.1" xref="S3.E2.m1.4.4.2.3.cmml">,</mo><mi id="S3.E2.m1.4.4.2.2" xref="S3.E2.m1.4.4.2.2.cmml">obj</mi></mrow></msub></mrow><mo id="S3.E2.m1.7.7.1.1.1.2" xref="S3.E2.m1.7.7.1.1.1.2.cmml">+</mo><mrow id="S3.E2.m1.7.7.1.1.1.1" xref="S3.E2.m1.7.7.1.1.1.1.cmml"><mrow id="S3.E2.m1.7.7.1.1.1.1.1.1" xref="S3.E2.m1.7.7.1.1.1.1.1.1.1.cmml"><mo id="S3.E2.m1.7.7.1.1.1.1.1.1.2" stretchy="false" xref="S3.E2.m1.7.7.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E2.m1.7.7.1.1.1.1.1.1.1" xref="S3.E2.m1.7.7.1.1.1.1.1.1.1.cmml"><mn id="S3.E2.m1.7.7.1.1.1.1.1.1.1.2" xref="S3.E2.m1.7.7.1.1.1.1.1.1.1.2.cmml">1</mn><mo id="S3.E2.m1.7.7.1.1.1.1.1.1.1.1" xref="S3.E2.m1.7.7.1.1.1.1.1.1.1.1.cmml">−</mo><mi id="S3.E2.m1.7.7.1.1.1.1.1.1.1.3" xref="S3.E2.m1.7.7.1.1.1.1.1.1.1.3.cmml">m</mi></mrow><mo id="S3.E2.m1.7.7.1.1.1.1.1.1.3" stretchy="false" xref="S3.E2.m1.7.7.1.1.1.1.1.1.1.cmml">)</mo></mrow><mo id="S3.E2.m1.7.7.1.1.1.1.2" lspace="0.170em" xref="S3.E2.m1.7.7.1.1.1.1.2.cmml">⁢</mo><msub id="S3.E2.m1.7.7.1.1.1.1.3" xref="S3.E2.m1.7.7.1.1.1.1.3.cmml"><mi id="S3.E2.m1.7.7.1.1.1.1.3.2" xref="S3.E2.m1.7.7.1.1.1.1.3.2.cmml">i</mi><mrow id="S3.E2.m1.6.6.2.4" xref="S3.E2.m1.6.6.2.3.cmml"><mi id="S3.E2.m1.5.5.1.1" xref="S3.E2.m1.5.5.1.1.cmml">c</mi><mo id="S3.E2.m1.6.6.2.4.1" xref="S3.E2.m1.6.6.2.3.cmml">,</mo><mi id="S3.E2.m1.6.6.2.2" xref="S3.E2.m1.6.6.2.2.cmml">bg</mi></mrow></msub></mrow></mrow></mrow><mo id="S3.E2.m1.7.7.1.2" xref="S3.E2.m1.7.7.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.7b"><apply id="S3.E2.m1.7.7.1.1.cmml" xref="S3.E2.m1.7.7.1"><eq id="S3.E2.m1.7.7.1.1.2.cmml" xref="S3.E2.m1.7.7.1.1.2"></eq><apply id="S3.E2.m1.7.7.1.1.3.cmml" xref="S3.E2.m1.7.7.1.1.3"><csymbol cd="ambiguous" id="S3.E2.m1.7.7.1.1.3.1.cmml" xref="S3.E2.m1.7.7.1.1.3">subscript</csymbol><ci id="S3.E2.m1.7.7.1.1.3.2.cmml" xref="S3.E2.m1.7.7.1.1.3.2">𝑖</ci><list id="S3.E2.m1.2.2.2.3.cmml" xref="S3.E2.m1.2.2.2.4"><ci id="S3.E2.m1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1">𝑐</ci><ci id="S3.E2.m1.2.2.2.2.cmml" xref="S3.E2.m1.2.2.2.2">comp</ci></list></apply><apply id="S3.E2.m1.7.7.1.1.1.cmml" xref="S3.E2.m1.7.7.1.1.1"><plus id="S3.E2.m1.7.7.1.1.1.2.cmml" xref="S3.E2.m1.7.7.1.1.1.2"></plus><apply id="S3.E2.m1.7.7.1.1.1.3.cmml" xref="S3.E2.m1.7.7.1.1.1.3"><times id="S3.E2.m1.7.7.1.1.1.3.1.cmml" xref="S3.E2.m1.7.7.1.1.1.3.1"></times><ci id="S3.E2.m1.7.7.1.1.1.3.2.cmml" xref="S3.E2.m1.7.7.1.1.1.3.2">𝑚</ci><apply id="S3.E2.m1.7.7.1.1.1.3.3.cmml" xref="S3.E2.m1.7.7.1.1.1.3.3"><csymbol cd="ambiguous" id="S3.E2.m1.7.7.1.1.1.3.3.1.cmml" xref="S3.E2.m1.7.7.1.1.1.3.3">subscript</csymbol><ci id="S3.E2.m1.7.7.1.1.1.3.3.2.cmml" xref="S3.E2.m1.7.7.1.1.1.3.3.2">𝑖</ci><list id="S3.E2.m1.4.4.2.3.cmml" xref="S3.E2.m1.4.4.2.4"><ci id="S3.E2.m1.3.3.1.1.cmml" xref="S3.E2.m1.3.3.1.1">𝑐</ci><ci id="S3.E2.m1.4.4.2.2.cmml" xref="S3.E2.m1.4.4.2.2">obj</ci></list></apply></apply><apply id="S3.E2.m1.7.7.1.1.1.1.cmml" xref="S3.E2.m1.7.7.1.1.1.1"><times id="S3.E2.m1.7.7.1.1.1.1.2.cmml" xref="S3.E2.m1.7.7.1.1.1.1.2"></times><apply id="S3.E2.m1.7.7.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.7.7.1.1.1.1.1.1"><minus id="S3.E2.m1.7.7.1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.7.7.1.1.1.1.1.1.1.1"></minus><cn id="S3.E2.m1.7.7.1.1.1.1.1.1.1.2.cmml" type="integer" xref="S3.E2.m1.7.7.1.1.1.1.1.1.1.2">1</cn><ci id="S3.E2.m1.7.7.1.1.1.1.1.1.1.3.cmml" xref="S3.E2.m1.7.7.1.1.1.1.1.1.1.3">𝑚</ci></apply><apply id="S3.E2.m1.7.7.1.1.1.1.3.cmml" xref="S3.E2.m1.7.7.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E2.m1.7.7.1.1.1.1.3.1.cmml" xref="S3.E2.m1.7.7.1.1.1.1.3">subscript</csymbol><ci id="S3.E2.m1.7.7.1.1.1.1.3.2.cmml" xref="S3.E2.m1.7.7.1.1.1.1.3.2">𝑖</ci><list id="S3.E2.m1.6.6.2.3.cmml" xref="S3.E2.m1.6.6.2.4"><ci id="S3.E2.m1.5.5.1.1.cmml" xref="S3.E2.m1.5.5.1.1">𝑐</ci><ci id="S3.E2.m1.6.6.2.2.cmml" xref="S3.E2.m1.6.6.2.2">bg</ci></list></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.7c">i_{c,\mathrm{comp}}=m\,i_{c,\mathrm{obj}}+(1-m)\,i_{c,\mathrm{bg}}\,,</annotation><annotation encoding="application/x-llamapun" id="S3.E2.m1.7d">italic_i start_POSTSUBSCRIPT italic_c , roman_comp end_POSTSUBSCRIPT = italic_m italic_i start_POSTSUBSCRIPT italic_c , roman_obj end_POSTSUBSCRIPT + ( 1 - italic_m ) italic_i start_POSTSUBSCRIPT italic_c , roman_bg end_POSTSUBSCRIPT ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS2.p2.4">where <math alttext="i_{c}\in\{i_{d},i_{n},i_{a},i_{s}\}" class="ltx_Math" display="inline" id="S3.SS2.p2.2.m1.4"><semantics id="S3.SS2.p2.2.m1.4a"><mrow id="S3.SS2.p2.2.m1.4.4" xref="S3.SS2.p2.2.m1.4.4.cmml"><msub id="S3.SS2.p2.2.m1.4.4.6" xref="S3.SS2.p2.2.m1.4.4.6.cmml"><mi id="S3.SS2.p2.2.m1.4.4.6.2" xref="S3.SS2.p2.2.m1.4.4.6.2.cmml">i</mi><mi id="S3.SS2.p2.2.m1.4.4.6.3" xref="S3.SS2.p2.2.m1.4.4.6.3.cmml">c</mi></msub><mo id="S3.SS2.p2.2.m1.4.4.5" xref="S3.SS2.p2.2.m1.4.4.5.cmml">∈</mo><mrow id="S3.SS2.p2.2.m1.4.4.4.4" xref="S3.SS2.p2.2.m1.4.4.4.5.cmml"><mo id="S3.SS2.p2.2.m1.4.4.4.4.5" stretchy="false" xref="S3.SS2.p2.2.m1.4.4.4.5.cmml">{</mo><msub id="S3.SS2.p2.2.m1.1.1.1.1.1" xref="S3.SS2.p2.2.m1.1.1.1.1.1.cmml"><mi id="S3.SS2.p2.2.m1.1.1.1.1.1.2" xref="S3.SS2.p2.2.m1.1.1.1.1.1.2.cmml">i</mi><mi id="S3.SS2.p2.2.m1.1.1.1.1.1.3" xref="S3.SS2.p2.2.m1.1.1.1.1.1.3.cmml">d</mi></msub><mo id="S3.SS2.p2.2.m1.4.4.4.4.6" xref="S3.SS2.p2.2.m1.4.4.4.5.cmml">,</mo><msub id="S3.SS2.p2.2.m1.2.2.2.2.2" xref="S3.SS2.p2.2.m1.2.2.2.2.2.cmml"><mi id="S3.SS2.p2.2.m1.2.2.2.2.2.2" xref="S3.SS2.p2.2.m1.2.2.2.2.2.2.cmml">i</mi><mi id="S3.SS2.p2.2.m1.2.2.2.2.2.3" xref="S3.SS2.p2.2.m1.2.2.2.2.2.3.cmml">n</mi></msub><mo id="S3.SS2.p2.2.m1.4.4.4.4.7" xref="S3.SS2.p2.2.m1.4.4.4.5.cmml">,</mo><msub id="S3.SS2.p2.2.m1.3.3.3.3.3" xref="S3.SS2.p2.2.m1.3.3.3.3.3.cmml"><mi id="S3.SS2.p2.2.m1.3.3.3.3.3.2" xref="S3.SS2.p2.2.m1.3.3.3.3.3.2.cmml">i</mi><mi id="S3.SS2.p2.2.m1.3.3.3.3.3.3" xref="S3.SS2.p2.2.m1.3.3.3.3.3.3.cmml">a</mi></msub><mo id="S3.SS2.p2.2.m1.4.4.4.4.8" xref="S3.SS2.p2.2.m1.4.4.4.5.cmml">,</mo><msub id="S3.SS2.p2.2.m1.4.4.4.4.4" xref="S3.SS2.p2.2.m1.4.4.4.4.4.cmml"><mi id="S3.SS2.p2.2.m1.4.4.4.4.4.2" xref="S3.SS2.p2.2.m1.4.4.4.4.4.2.cmml">i</mi><mi id="S3.SS2.p2.2.m1.4.4.4.4.4.3" xref="S3.SS2.p2.2.m1.4.4.4.4.4.3.cmml">s</mi></msub><mo id="S3.SS2.p2.2.m1.4.4.4.4.9" stretchy="false" xref="S3.SS2.p2.2.m1.4.4.4.5.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.2.m1.4b"><apply id="S3.SS2.p2.2.m1.4.4.cmml" xref="S3.SS2.p2.2.m1.4.4"><in id="S3.SS2.p2.2.m1.4.4.5.cmml" xref="S3.SS2.p2.2.m1.4.4.5"></in><apply id="S3.SS2.p2.2.m1.4.4.6.cmml" xref="S3.SS2.p2.2.m1.4.4.6"><csymbol cd="ambiguous" id="S3.SS2.p2.2.m1.4.4.6.1.cmml" xref="S3.SS2.p2.2.m1.4.4.6">subscript</csymbol><ci id="S3.SS2.p2.2.m1.4.4.6.2.cmml" xref="S3.SS2.p2.2.m1.4.4.6.2">𝑖</ci><ci id="S3.SS2.p2.2.m1.4.4.6.3.cmml" xref="S3.SS2.p2.2.m1.4.4.6.3">𝑐</ci></apply><set id="S3.SS2.p2.2.m1.4.4.4.5.cmml" xref="S3.SS2.p2.2.m1.4.4.4.4"><apply id="S3.SS2.p2.2.m1.1.1.1.1.1.cmml" xref="S3.SS2.p2.2.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.2.m1.1.1.1.1.1.1.cmml" xref="S3.SS2.p2.2.m1.1.1.1.1.1">subscript</csymbol><ci id="S3.SS2.p2.2.m1.1.1.1.1.1.2.cmml" xref="S3.SS2.p2.2.m1.1.1.1.1.1.2">𝑖</ci><ci id="S3.SS2.p2.2.m1.1.1.1.1.1.3.cmml" xref="S3.SS2.p2.2.m1.1.1.1.1.1.3">𝑑</ci></apply><apply id="S3.SS2.p2.2.m1.2.2.2.2.2.cmml" xref="S3.SS2.p2.2.m1.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.p2.2.m1.2.2.2.2.2.1.cmml" xref="S3.SS2.p2.2.m1.2.2.2.2.2">subscript</csymbol><ci id="S3.SS2.p2.2.m1.2.2.2.2.2.2.cmml" xref="S3.SS2.p2.2.m1.2.2.2.2.2.2">𝑖</ci><ci id="S3.SS2.p2.2.m1.2.2.2.2.2.3.cmml" xref="S3.SS2.p2.2.m1.2.2.2.2.2.3">𝑛</ci></apply><apply id="S3.SS2.p2.2.m1.3.3.3.3.3.cmml" xref="S3.SS2.p2.2.m1.3.3.3.3.3"><csymbol cd="ambiguous" id="S3.SS2.p2.2.m1.3.3.3.3.3.1.cmml" xref="S3.SS2.p2.2.m1.3.3.3.3.3">subscript</csymbol><ci id="S3.SS2.p2.2.m1.3.3.3.3.3.2.cmml" xref="S3.SS2.p2.2.m1.3.3.3.3.3.2">𝑖</ci><ci id="S3.SS2.p2.2.m1.3.3.3.3.3.3.cmml" xref="S3.SS2.p2.2.m1.3.3.3.3.3.3">𝑎</ci></apply><apply id="S3.SS2.p2.2.m1.4.4.4.4.4.cmml" xref="S3.SS2.p2.2.m1.4.4.4.4.4"><csymbol cd="ambiguous" id="S3.SS2.p2.2.m1.4.4.4.4.4.1.cmml" xref="S3.SS2.p2.2.m1.4.4.4.4.4">subscript</csymbol><ci id="S3.SS2.p2.2.m1.4.4.4.4.4.2.cmml" xref="S3.SS2.p2.2.m1.4.4.4.4.4.2">𝑖</ci><ci id="S3.SS2.p2.2.m1.4.4.4.4.4.3.cmml" xref="S3.SS2.p2.2.m1.4.4.4.4.4.3">𝑠</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.2.m1.4c">i_{c}\in\{i_{d},i_{n},i_{a},i_{s}\}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.2.m1.4d">italic_i start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT ∈ { italic_i start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT , italic_i start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT , italic_i start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT , italic_i start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT }</annotation></semantics></math> denotes one of the intrinsic maps and <math alttext="m" class="ltx_Math" display="inline" id="S3.SS2.p2.3.m2.1"><semantics id="S3.SS2.p2.3.m2.1a"><mi id="S3.SS2.p2.3.m2.1.1" xref="S3.SS2.p2.3.m2.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.3.m2.1b"><ci id="S3.SS2.p2.3.m2.1.1.cmml" xref="S3.SS2.p2.3.m2.1.1">𝑚</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.3.m2.1c">m</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.3.m2.1d">italic_m</annotation></semantics></math> the object mask obtained from the graphics engine, resulting in a set of composite intrinsics (<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#S2.F2" title="In 2 Related work ‣ ZeroComp: Zero-shot Object Compositing from Image Intrinsics via Diffusion"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">2</span></a>, bottom). Since the depth scale of the object and the background may not match, we align the object footprint depth (planar projection on the vertical axis) with the background depth by fitting an affine transform to the footprint and applying it to <math alttext="i_{d,\mathrm{obj}}" class="ltx_Math" display="inline" id="S3.SS2.p2.4.m3.2"><semantics id="S3.SS2.p2.4.m3.2a"><msub id="S3.SS2.p2.4.m3.2.3" xref="S3.SS2.p2.4.m3.2.3.cmml"><mi id="S3.SS2.p2.4.m3.2.3.2" xref="S3.SS2.p2.4.m3.2.3.2.cmml">i</mi><mrow id="S3.SS2.p2.4.m3.2.2.2.4" xref="S3.SS2.p2.4.m3.2.2.2.3.cmml"><mi id="S3.SS2.p2.4.m3.1.1.1.1" xref="S3.SS2.p2.4.m3.1.1.1.1.cmml">d</mi><mo id="S3.SS2.p2.4.m3.2.2.2.4.1" xref="S3.SS2.p2.4.m3.2.2.2.3.cmml">,</mo><mi id="S3.SS2.p2.4.m3.2.2.2.2" xref="S3.SS2.p2.4.m3.2.2.2.2.cmml">obj</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.4.m3.2b"><apply id="S3.SS2.p2.4.m3.2.3.cmml" xref="S3.SS2.p2.4.m3.2.3"><csymbol cd="ambiguous" id="S3.SS2.p2.4.m3.2.3.1.cmml" xref="S3.SS2.p2.4.m3.2.3">subscript</csymbol><ci id="S3.SS2.p2.4.m3.2.3.2.cmml" xref="S3.SS2.p2.4.m3.2.3.2">𝑖</ci><list id="S3.SS2.p2.4.m3.2.2.2.3.cmml" xref="S3.SS2.p2.4.m3.2.2.2.4"><ci id="S3.SS2.p2.4.m3.1.1.1.1.cmml" xref="S3.SS2.p2.4.m3.1.1.1.1">𝑑</ci><ci id="S3.SS2.p2.4.m3.2.2.2.2.cmml" xref="S3.SS2.p2.4.m3.2.2.2.2">obj</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.4.m3.2c">i_{d,\mathrm{obj}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.4.m3.2d">italic_i start_POSTSUBSCRIPT italic_d , roman_obj end_POSTSUBSCRIPT</annotation></semantics></math>. An object also affects surroundings (e.g., by casting shadows), so we mask any pixel from the shading map if the pixel estimated 3D position is within a distance threshold</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E3">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="d=\lambda(\max_{y}m_{y,\mathrm{obj}}-\min_{y}m_{y,\mathrm{obj}})\,," class="ltx_Math" display="block" id="S3.E3.m1.5"><semantics id="S3.E3.m1.5a"><mrow id="S3.E3.m1.5.5.1" xref="S3.E3.m1.5.5.1.1.cmml"><mrow id="S3.E3.m1.5.5.1.1" xref="S3.E3.m1.5.5.1.1.cmml"><mi id="S3.E3.m1.5.5.1.1.3" xref="S3.E3.m1.5.5.1.1.3.cmml">d</mi><mo id="S3.E3.m1.5.5.1.1.2" xref="S3.E3.m1.5.5.1.1.2.cmml">=</mo><mrow id="S3.E3.m1.5.5.1.1.1" xref="S3.E3.m1.5.5.1.1.1.cmml"><mi id="S3.E3.m1.5.5.1.1.1.3" xref="S3.E3.m1.5.5.1.1.1.3.cmml">λ</mi><mo id="S3.E3.m1.5.5.1.1.1.2" xref="S3.E3.m1.5.5.1.1.1.2.cmml">⁢</mo><mrow id="S3.E3.m1.5.5.1.1.1.1.1" xref="S3.E3.m1.5.5.1.1.1.1.1.1.cmml"><mo id="S3.E3.m1.5.5.1.1.1.1.1.2" stretchy="false" xref="S3.E3.m1.5.5.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E3.m1.5.5.1.1.1.1.1.1" xref="S3.E3.m1.5.5.1.1.1.1.1.1.cmml"><mrow id="S3.E3.m1.5.5.1.1.1.1.1.1.2" xref="S3.E3.m1.5.5.1.1.1.1.1.1.2.cmml"><munder id="S3.E3.m1.5.5.1.1.1.1.1.1.2.1" xref="S3.E3.m1.5.5.1.1.1.1.1.1.2.1.cmml"><mi id="S3.E3.m1.5.5.1.1.1.1.1.1.2.1.2" xref="S3.E3.m1.5.5.1.1.1.1.1.1.2.1.2.cmml">max</mi><mi id="S3.E3.m1.5.5.1.1.1.1.1.1.2.1.3" xref="S3.E3.m1.5.5.1.1.1.1.1.1.2.1.3.cmml">y</mi></munder><mo id="S3.E3.m1.5.5.1.1.1.1.1.1.2a" lspace="0.167em" xref="S3.E3.m1.5.5.1.1.1.1.1.1.2.cmml">⁡</mo><msub id="S3.E3.m1.5.5.1.1.1.1.1.1.2.2" xref="S3.E3.m1.5.5.1.1.1.1.1.1.2.2.cmml"><mi id="S3.E3.m1.5.5.1.1.1.1.1.1.2.2.2" xref="S3.E3.m1.5.5.1.1.1.1.1.1.2.2.2.cmml">m</mi><mrow id="S3.E3.m1.2.2.2.4" xref="S3.E3.m1.2.2.2.3.cmml"><mi id="S3.E3.m1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.cmml">y</mi><mo id="S3.E3.m1.2.2.2.4.1" xref="S3.E3.m1.2.2.2.3.cmml">,</mo><mi id="S3.E3.m1.2.2.2.2" xref="S3.E3.m1.2.2.2.2.cmml">obj</mi></mrow></msub></mrow><mo id="S3.E3.m1.5.5.1.1.1.1.1.1.1" xref="S3.E3.m1.5.5.1.1.1.1.1.1.1.cmml">−</mo><mrow id="S3.E3.m1.5.5.1.1.1.1.1.1.3" xref="S3.E3.m1.5.5.1.1.1.1.1.1.3.cmml"><munder id="S3.E3.m1.5.5.1.1.1.1.1.1.3.1" xref="S3.E3.m1.5.5.1.1.1.1.1.1.3.1.cmml"><mi id="S3.E3.m1.5.5.1.1.1.1.1.1.3.1.2" xref="S3.E3.m1.5.5.1.1.1.1.1.1.3.1.2.cmml">min</mi><mi id="S3.E3.m1.5.5.1.1.1.1.1.1.3.1.3" xref="S3.E3.m1.5.5.1.1.1.1.1.1.3.1.3.cmml">y</mi></munder><mo id="S3.E3.m1.5.5.1.1.1.1.1.1.3a" lspace="0.167em" xref="S3.E3.m1.5.5.1.1.1.1.1.1.3.cmml">⁡</mo><msub id="S3.E3.m1.5.5.1.1.1.1.1.1.3.2" xref="S3.E3.m1.5.5.1.1.1.1.1.1.3.2.cmml"><mi id="S3.E3.m1.5.5.1.1.1.1.1.1.3.2.2" xref="S3.E3.m1.5.5.1.1.1.1.1.1.3.2.2.cmml">m</mi><mrow id="S3.E3.m1.4.4.2.4" xref="S3.E3.m1.4.4.2.3.cmml"><mi id="S3.E3.m1.3.3.1.1" xref="S3.E3.m1.3.3.1.1.cmml">y</mi><mo id="S3.E3.m1.4.4.2.4.1" xref="S3.E3.m1.4.4.2.3.cmml">,</mo><mi id="S3.E3.m1.4.4.2.2" xref="S3.E3.m1.4.4.2.2.cmml">obj</mi></mrow></msub></mrow></mrow><mo id="S3.E3.m1.5.5.1.1.1.1.1.3" rspace="0.170em" stretchy="false" xref="S3.E3.m1.5.5.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo id="S3.E3.m1.5.5.1.2" xref="S3.E3.m1.5.5.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E3.m1.5b"><apply id="S3.E3.m1.5.5.1.1.cmml" xref="S3.E3.m1.5.5.1"><eq id="S3.E3.m1.5.5.1.1.2.cmml" xref="S3.E3.m1.5.5.1.1.2"></eq><ci id="S3.E3.m1.5.5.1.1.3.cmml" xref="S3.E3.m1.5.5.1.1.3">𝑑</ci><apply id="S3.E3.m1.5.5.1.1.1.cmml" xref="S3.E3.m1.5.5.1.1.1"><times id="S3.E3.m1.5.5.1.1.1.2.cmml" xref="S3.E3.m1.5.5.1.1.1.2"></times><ci id="S3.E3.m1.5.5.1.1.1.3.cmml" xref="S3.E3.m1.5.5.1.1.1.3">𝜆</ci><apply id="S3.E3.m1.5.5.1.1.1.1.1.1.cmml" xref="S3.E3.m1.5.5.1.1.1.1.1"><minus id="S3.E3.m1.5.5.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.5.5.1.1.1.1.1.1.1"></minus><apply id="S3.E3.m1.5.5.1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.5.5.1.1.1.1.1.1.2"><apply id="S3.E3.m1.5.5.1.1.1.1.1.1.2.1.cmml" xref="S3.E3.m1.5.5.1.1.1.1.1.1.2.1"><csymbol cd="ambiguous" id="S3.E3.m1.5.5.1.1.1.1.1.1.2.1.1.cmml" xref="S3.E3.m1.5.5.1.1.1.1.1.1.2.1">subscript</csymbol><max id="S3.E3.m1.5.5.1.1.1.1.1.1.2.1.2.cmml" xref="S3.E3.m1.5.5.1.1.1.1.1.1.2.1.2"></max><ci id="S3.E3.m1.5.5.1.1.1.1.1.1.2.1.3.cmml" xref="S3.E3.m1.5.5.1.1.1.1.1.1.2.1.3">𝑦</ci></apply><apply id="S3.E3.m1.5.5.1.1.1.1.1.1.2.2.cmml" xref="S3.E3.m1.5.5.1.1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S3.E3.m1.5.5.1.1.1.1.1.1.2.2.1.cmml" xref="S3.E3.m1.5.5.1.1.1.1.1.1.2.2">subscript</csymbol><ci id="S3.E3.m1.5.5.1.1.1.1.1.1.2.2.2.cmml" xref="S3.E3.m1.5.5.1.1.1.1.1.1.2.2.2">𝑚</ci><list id="S3.E3.m1.2.2.2.3.cmml" xref="S3.E3.m1.2.2.2.4"><ci id="S3.E3.m1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1">𝑦</ci><ci id="S3.E3.m1.2.2.2.2.cmml" xref="S3.E3.m1.2.2.2.2">obj</ci></list></apply></apply><apply id="S3.E3.m1.5.5.1.1.1.1.1.1.3.cmml" xref="S3.E3.m1.5.5.1.1.1.1.1.1.3"><apply id="S3.E3.m1.5.5.1.1.1.1.1.1.3.1.cmml" xref="S3.E3.m1.5.5.1.1.1.1.1.1.3.1"><csymbol cd="ambiguous" id="S3.E3.m1.5.5.1.1.1.1.1.1.3.1.1.cmml" xref="S3.E3.m1.5.5.1.1.1.1.1.1.3.1">subscript</csymbol><min id="S3.E3.m1.5.5.1.1.1.1.1.1.3.1.2.cmml" xref="S3.E3.m1.5.5.1.1.1.1.1.1.3.1.2"></min><ci id="S3.E3.m1.5.5.1.1.1.1.1.1.3.1.3.cmml" xref="S3.E3.m1.5.5.1.1.1.1.1.1.3.1.3">𝑦</ci></apply><apply id="S3.E3.m1.5.5.1.1.1.1.1.1.3.2.cmml" xref="S3.E3.m1.5.5.1.1.1.1.1.1.3.2"><csymbol cd="ambiguous" id="S3.E3.m1.5.5.1.1.1.1.1.1.3.2.1.cmml" xref="S3.E3.m1.5.5.1.1.1.1.1.1.3.2">subscript</csymbol><ci id="S3.E3.m1.5.5.1.1.1.1.1.1.3.2.2.cmml" xref="S3.E3.m1.5.5.1.1.1.1.1.1.3.2.2">𝑚</ci><list id="S3.E3.m1.4.4.2.3.cmml" xref="S3.E3.m1.4.4.2.4"><ci id="S3.E3.m1.3.3.1.1.cmml" xref="S3.E3.m1.3.3.1.1">𝑦</ci><ci id="S3.E3.m1.4.4.2.2.cmml" xref="S3.E3.m1.4.4.2.2">obj</ci></list></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E3.m1.5c">d=\lambda(\max_{y}m_{y,\mathrm{obj}}-\min_{y}m_{y,\mathrm{obj}})\,,</annotation><annotation encoding="application/x-llamapun" id="S3.E3.m1.5d">italic_d = italic_λ ( roman_max start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT italic_m start_POSTSUBSCRIPT italic_y , roman_obj end_POSTSUBSCRIPT - roman_min start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT italic_m start_POSTSUBSCRIPT italic_y , roman_obj end_POSTSUBSCRIPT ) ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS2.p2.9">where <math alttext="m_{y,\mathrm{obj}}" class="ltx_Math" display="inline" id="S3.SS2.p2.5.m1.2"><semantics id="S3.SS2.p2.5.m1.2a"><msub id="S3.SS2.p2.5.m1.2.3" xref="S3.SS2.p2.5.m1.2.3.cmml"><mi id="S3.SS2.p2.5.m1.2.3.2" xref="S3.SS2.p2.5.m1.2.3.2.cmml">m</mi><mrow id="S3.SS2.p2.5.m1.2.2.2.4" xref="S3.SS2.p2.5.m1.2.2.2.3.cmml"><mi id="S3.SS2.p2.5.m1.1.1.1.1" xref="S3.SS2.p2.5.m1.1.1.1.1.cmml">y</mi><mo id="S3.SS2.p2.5.m1.2.2.2.4.1" xref="S3.SS2.p2.5.m1.2.2.2.3.cmml">,</mo><mi id="S3.SS2.p2.5.m1.2.2.2.2" xref="S3.SS2.p2.5.m1.2.2.2.2.cmml">obj</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.5.m1.2b"><apply id="S3.SS2.p2.5.m1.2.3.cmml" xref="S3.SS2.p2.5.m1.2.3"><csymbol cd="ambiguous" id="S3.SS2.p2.5.m1.2.3.1.cmml" xref="S3.SS2.p2.5.m1.2.3">subscript</csymbol><ci id="S3.SS2.p2.5.m1.2.3.2.cmml" xref="S3.SS2.p2.5.m1.2.3.2">𝑚</ci><list id="S3.SS2.p2.5.m1.2.2.2.3.cmml" xref="S3.SS2.p2.5.m1.2.2.2.4"><ci id="S3.SS2.p2.5.m1.1.1.1.1.cmml" xref="S3.SS2.p2.5.m1.1.1.1.1">𝑦</ci><ci id="S3.SS2.p2.5.m1.2.2.2.2.cmml" xref="S3.SS2.p2.5.m1.2.2.2.2">obj</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.5.m1.2c">m_{y,\mathrm{obj}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.5.m1.2d">italic_m start_POSTSUBSCRIPT italic_y , roman_obj end_POSTSUBSCRIPT</annotation></semantics></math> represents the (3D) <math alttext="y" class="ltx_Math" display="inline" id="S3.SS2.p2.6.m2.1"><semantics id="S3.SS2.p2.6.m2.1a"><mi id="S3.SS2.p2.6.m2.1.1" xref="S3.SS2.p2.6.m2.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.6.m2.1b"><ci id="S3.SS2.p2.6.m2.1.1.cmml" xref="S3.SS2.p2.6.m2.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.6.m2.1c">y</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.6.m2.1d">italic_y</annotation></semantics></math> coordinate of a pixel in the object mask <math alttext="m" class="ltx_Math" display="inline" id="S3.SS2.p2.7.m3.1"><semantics id="S3.SS2.p2.7.m3.1a"><mi id="S3.SS2.p2.7.m3.1.1" xref="S3.SS2.p2.7.m3.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.7.m3.1b"><ci id="S3.SS2.p2.7.m3.1.1.cmml" xref="S3.SS2.p2.7.m3.1.1">𝑚</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.7.m3.1c">m</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.7.m3.1d">italic_m</annotation></semantics></math> (obtained from the depth map <math alttext="i_{d,\mathrm{obj}}" class="ltx_Math" display="inline" id="S3.SS2.p2.8.m4.2"><semantics id="S3.SS2.p2.8.m4.2a"><msub id="S3.SS2.p2.8.m4.2.3" xref="S3.SS2.p2.8.m4.2.3.cmml"><mi id="S3.SS2.p2.8.m4.2.3.2" xref="S3.SS2.p2.8.m4.2.3.2.cmml">i</mi><mrow id="S3.SS2.p2.8.m4.2.2.2.4" xref="S3.SS2.p2.8.m4.2.2.2.3.cmml"><mi id="S3.SS2.p2.8.m4.1.1.1.1" xref="S3.SS2.p2.8.m4.1.1.1.1.cmml">d</mi><mo id="S3.SS2.p2.8.m4.2.2.2.4.1" xref="S3.SS2.p2.8.m4.2.2.2.3.cmml">,</mo><mi id="S3.SS2.p2.8.m4.2.2.2.2" xref="S3.SS2.p2.8.m4.2.2.2.2.cmml">obj</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.8.m4.2b"><apply id="S3.SS2.p2.8.m4.2.3.cmml" xref="S3.SS2.p2.8.m4.2.3"><csymbol cd="ambiguous" id="S3.SS2.p2.8.m4.2.3.1.cmml" xref="S3.SS2.p2.8.m4.2.3">subscript</csymbol><ci id="S3.SS2.p2.8.m4.2.3.2.cmml" xref="S3.SS2.p2.8.m4.2.3.2">𝑖</ci><list id="S3.SS2.p2.8.m4.2.2.2.3.cmml" xref="S3.SS2.p2.8.m4.2.2.2.4"><ci id="S3.SS2.p2.8.m4.1.1.1.1.cmml" xref="S3.SS2.p2.8.m4.1.1.1.1">𝑑</ci><ci id="S3.SS2.p2.8.m4.2.2.2.2.cmml" xref="S3.SS2.p2.8.m4.2.2.2.2">obj</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.8.m4.2c">i_{d,\mathrm{obj}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.8.m4.2d">italic_i start_POSTSUBSCRIPT italic_d , roman_obj end_POSTSUBSCRIPT</annotation></semantics></math>). This threshold is motivated by the fact that the length of a shadow is typically proportional to the object height. In practice, we set the relative shading radius <math alttext="\lambda=1.0" class="ltx_Math" display="inline" id="S3.SS2.p2.9.m5.1"><semantics id="S3.SS2.p2.9.m5.1a"><mrow id="S3.SS2.p2.9.m5.1.1" xref="S3.SS2.p2.9.m5.1.1.cmml"><mi id="S3.SS2.p2.9.m5.1.1.2" xref="S3.SS2.p2.9.m5.1.1.2.cmml">λ</mi><mo id="S3.SS2.p2.9.m5.1.1.1" xref="S3.SS2.p2.9.m5.1.1.1.cmml">=</mo><mn id="S3.SS2.p2.9.m5.1.1.3" xref="S3.SS2.p2.9.m5.1.1.3.cmml">1.0</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.9.m5.1b"><apply id="S3.SS2.p2.9.m5.1.1.cmml" xref="S3.SS2.p2.9.m5.1.1"><eq id="S3.SS2.p2.9.m5.1.1.1.cmml" xref="S3.SS2.p2.9.m5.1.1.1"></eq><ci id="S3.SS2.p2.9.m5.1.1.2.cmml" xref="S3.SS2.p2.9.m5.1.1.2">𝜆</ci><cn id="S3.SS2.p2.9.m5.1.1.3.cmml" type="float" xref="S3.SS2.p2.9.m5.1.1.3">1.0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.9.m5.1c">\lambda=1.0</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.9.m5.1d">italic_λ = 1.0</annotation></semantics></math>, and explore different values in <a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#S5" title="5 Evaluation ‣ ZeroComp: Zero-shot Object Compositing from Image Intrinsics via Diffusion"><span class="ltx_text ltx_ref_tag">Sec.</span> <span class="ltx_text ltx_ref_tag">5</span></a>. Pixels in the shading map directly above the object are never masked, to avoid unnecessary shadows (on the ceiling, for instance).</p>
</div>
<div class="ltx_para" id="S3.SS2.p3">
<p class="ltx_p" id="S3.SS2.p3.1">Finally, our trained <span class="ltx_text ltx_font_smallcaps" id="S3.SS2.p3.1.1">ZeroComp</span> is run on the composite intrinsics to obtain the final output (<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#S2.F2" title="In 2 Related work ‣ ZeroComp: Zero-shot Object Compositing from Image Intrinsics via Diffusion"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">2</span></a>, right), where the newly added object appears as a natural part of the original scene. This approach enables the insertion of objects into various scenes with realistic lighting interactions including reshading and casting shadows, achieving zero-shot compositing. For all our experiments, we use seed 469, which was shown in <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib74" title="">74</a>]</cite> to produce the highest-quality generations in SD among 1000 seeds.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Preserving background fidelity</h3>
<div class="ltx_para" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.2">The ControlNet framework does not guarantee a perfect reconstruction of the background image. As demonstrated in previous studies, small details are susceptible to loss <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib93" title="">93</a>]</cite>. To mitigate this, we take inspiration from the differential compositing framework of Debevec <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib18" title="">18</a>]</cite> and generate a shadow opacity ratio from two predictions of <span class="ltx_text ltx_font_smallcaps" id="S3.SS3.p1.2.1">ZeroComp</span>. Denoting <math alttext="f_{\theta}(\mathbf{i})" class="ltx_Math" display="inline" id="S3.SS3.p1.1.m1.1"><semantics id="S3.SS3.p1.1.m1.1a"><mrow id="S3.SS3.p1.1.m1.1.2" xref="S3.SS3.p1.1.m1.1.2.cmml"><msub id="S3.SS3.p1.1.m1.1.2.2" xref="S3.SS3.p1.1.m1.1.2.2.cmml"><mi id="S3.SS3.p1.1.m1.1.2.2.2" xref="S3.SS3.p1.1.m1.1.2.2.2.cmml">f</mi><mi id="S3.SS3.p1.1.m1.1.2.2.3" xref="S3.SS3.p1.1.m1.1.2.2.3.cmml">θ</mi></msub><mo id="S3.SS3.p1.1.m1.1.2.1" xref="S3.SS3.p1.1.m1.1.2.1.cmml">⁢</mo><mrow id="S3.SS3.p1.1.m1.1.2.3.2" xref="S3.SS3.p1.1.m1.1.2.cmml"><mo id="S3.SS3.p1.1.m1.1.2.3.2.1" stretchy="false" xref="S3.SS3.p1.1.m1.1.2.cmml">(</mo><mi id="S3.SS3.p1.1.m1.1.1" xref="S3.SS3.p1.1.m1.1.1.cmml">𝐢</mi><mo id="S3.SS3.p1.1.m1.1.2.3.2.2" stretchy="false" xref="S3.SS3.p1.1.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.1.m1.1b"><apply id="S3.SS3.p1.1.m1.1.2.cmml" xref="S3.SS3.p1.1.m1.1.2"><times id="S3.SS3.p1.1.m1.1.2.1.cmml" xref="S3.SS3.p1.1.m1.1.2.1"></times><apply id="S3.SS3.p1.1.m1.1.2.2.cmml" xref="S3.SS3.p1.1.m1.1.2.2"><csymbol cd="ambiguous" id="S3.SS3.p1.1.m1.1.2.2.1.cmml" xref="S3.SS3.p1.1.m1.1.2.2">subscript</csymbol><ci id="S3.SS3.p1.1.m1.1.2.2.2.cmml" xref="S3.SS3.p1.1.m1.1.2.2.2">𝑓</ci><ci id="S3.SS3.p1.1.m1.1.2.2.3.cmml" xref="S3.SS3.p1.1.m1.1.2.2.3">𝜃</ci></apply><ci id="S3.SS3.p1.1.m1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1">𝐢</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.1.m1.1c">f_{\theta}(\mathbf{i})</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.1.m1.1d">italic_f start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT ( bold_i )</annotation></semantics></math> as a full inference pass of the model on input intrinsic maps <math alttext="\mathbf{i}=\{i_{d},i_{n},i_{a},i_{s}\}" class="ltx_Math" display="inline" id="S3.SS3.p1.2.m2.4"><semantics id="S3.SS3.p1.2.m2.4a"><mrow id="S3.SS3.p1.2.m2.4.4" xref="S3.SS3.p1.2.m2.4.4.cmml"><mi id="S3.SS3.p1.2.m2.4.4.6" xref="S3.SS3.p1.2.m2.4.4.6.cmml">𝐢</mi><mo id="S3.SS3.p1.2.m2.4.4.5" xref="S3.SS3.p1.2.m2.4.4.5.cmml">=</mo><mrow id="S3.SS3.p1.2.m2.4.4.4.4" xref="S3.SS3.p1.2.m2.4.4.4.5.cmml"><mo id="S3.SS3.p1.2.m2.4.4.4.4.5" stretchy="false" xref="S3.SS3.p1.2.m2.4.4.4.5.cmml">{</mo><msub id="S3.SS3.p1.2.m2.1.1.1.1.1" xref="S3.SS3.p1.2.m2.1.1.1.1.1.cmml"><mi id="S3.SS3.p1.2.m2.1.1.1.1.1.2" xref="S3.SS3.p1.2.m2.1.1.1.1.1.2.cmml">i</mi><mi id="S3.SS3.p1.2.m2.1.1.1.1.1.3" xref="S3.SS3.p1.2.m2.1.1.1.1.1.3.cmml">d</mi></msub><mo id="S3.SS3.p1.2.m2.4.4.4.4.6" xref="S3.SS3.p1.2.m2.4.4.4.5.cmml">,</mo><msub id="S3.SS3.p1.2.m2.2.2.2.2.2" xref="S3.SS3.p1.2.m2.2.2.2.2.2.cmml"><mi id="S3.SS3.p1.2.m2.2.2.2.2.2.2" xref="S3.SS3.p1.2.m2.2.2.2.2.2.2.cmml">i</mi><mi id="S3.SS3.p1.2.m2.2.2.2.2.2.3" xref="S3.SS3.p1.2.m2.2.2.2.2.2.3.cmml">n</mi></msub><mo id="S3.SS3.p1.2.m2.4.4.4.4.7" xref="S3.SS3.p1.2.m2.4.4.4.5.cmml">,</mo><msub id="S3.SS3.p1.2.m2.3.3.3.3.3" xref="S3.SS3.p1.2.m2.3.3.3.3.3.cmml"><mi id="S3.SS3.p1.2.m2.3.3.3.3.3.2" xref="S3.SS3.p1.2.m2.3.3.3.3.3.2.cmml">i</mi><mi id="S3.SS3.p1.2.m2.3.3.3.3.3.3" xref="S3.SS3.p1.2.m2.3.3.3.3.3.3.cmml">a</mi></msub><mo id="S3.SS3.p1.2.m2.4.4.4.4.8" xref="S3.SS3.p1.2.m2.4.4.4.5.cmml">,</mo><msub id="S3.SS3.p1.2.m2.4.4.4.4.4" xref="S3.SS3.p1.2.m2.4.4.4.4.4.cmml"><mi id="S3.SS3.p1.2.m2.4.4.4.4.4.2" xref="S3.SS3.p1.2.m2.4.4.4.4.4.2.cmml">i</mi><mi id="S3.SS3.p1.2.m2.4.4.4.4.4.3" xref="S3.SS3.p1.2.m2.4.4.4.4.4.3.cmml">s</mi></msub><mo id="S3.SS3.p1.2.m2.4.4.4.4.9" stretchy="false" xref="S3.SS3.p1.2.m2.4.4.4.5.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.2.m2.4b"><apply id="S3.SS3.p1.2.m2.4.4.cmml" xref="S3.SS3.p1.2.m2.4.4"><eq id="S3.SS3.p1.2.m2.4.4.5.cmml" xref="S3.SS3.p1.2.m2.4.4.5"></eq><ci id="S3.SS3.p1.2.m2.4.4.6.cmml" xref="S3.SS3.p1.2.m2.4.4.6">𝐢</ci><set id="S3.SS3.p1.2.m2.4.4.4.5.cmml" xref="S3.SS3.p1.2.m2.4.4.4.4"><apply id="S3.SS3.p1.2.m2.1.1.1.1.1.cmml" xref="S3.SS3.p1.2.m2.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.2.m2.1.1.1.1.1.1.cmml" xref="S3.SS3.p1.2.m2.1.1.1.1.1">subscript</csymbol><ci id="S3.SS3.p1.2.m2.1.1.1.1.1.2.cmml" xref="S3.SS3.p1.2.m2.1.1.1.1.1.2">𝑖</ci><ci id="S3.SS3.p1.2.m2.1.1.1.1.1.3.cmml" xref="S3.SS3.p1.2.m2.1.1.1.1.1.3">𝑑</ci></apply><apply id="S3.SS3.p1.2.m2.2.2.2.2.2.cmml" xref="S3.SS3.p1.2.m2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS3.p1.2.m2.2.2.2.2.2.1.cmml" xref="S3.SS3.p1.2.m2.2.2.2.2.2">subscript</csymbol><ci id="S3.SS3.p1.2.m2.2.2.2.2.2.2.cmml" xref="S3.SS3.p1.2.m2.2.2.2.2.2.2">𝑖</ci><ci id="S3.SS3.p1.2.m2.2.2.2.2.2.3.cmml" xref="S3.SS3.p1.2.m2.2.2.2.2.2.3">𝑛</ci></apply><apply id="S3.SS3.p1.2.m2.3.3.3.3.3.cmml" xref="S3.SS3.p1.2.m2.3.3.3.3.3"><csymbol cd="ambiguous" id="S3.SS3.p1.2.m2.3.3.3.3.3.1.cmml" xref="S3.SS3.p1.2.m2.3.3.3.3.3">subscript</csymbol><ci id="S3.SS3.p1.2.m2.3.3.3.3.3.2.cmml" xref="S3.SS3.p1.2.m2.3.3.3.3.3.2">𝑖</ci><ci id="S3.SS3.p1.2.m2.3.3.3.3.3.3.cmml" xref="S3.SS3.p1.2.m2.3.3.3.3.3.3">𝑎</ci></apply><apply id="S3.SS3.p1.2.m2.4.4.4.4.4.cmml" xref="S3.SS3.p1.2.m2.4.4.4.4.4"><csymbol cd="ambiguous" id="S3.SS3.p1.2.m2.4.4.4.4.4.1.cmml" xref="S3.SS3.p1.2.m2.4.4.4.4.4">subscript</csymbol><ci id="S3.SS3.p1.2.m2.4.4.4.4.4.2.cmml" xref="S3.SS3.p1.2.m2.4.4.4.4.4.2">𝑖</ci><ci id="S3.SS3.p1.2.m2.4.4.4.4.4.3.cmml" xref="S3.SS3.p1.2.m2.4.4.4.4.4.3">𝑠</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.2.m2.4c">\mathbf{i}=\{i_{d},i_{n},i_{a},i_{s}\}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.2.m2.4d">bold_i = { italic_i start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT , italic_i start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT , italic_i start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT , italic_i start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT }</annotation></semantics></math> (containing depth, normals, albedo and shading resp., c.f. <a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#S3.SS1" title="3.1 Training ZeroComp ‣ 3 ZeroComp ‣ ZeroComp: Zero-shot Object Compositing from Image Intrinsics via Diffusion"><span class="ltx_text ltx_ref_tag">Sec.</span> <span class="ltx_text ltx_ref_tag">3.1</span></a>), we compute the shadow opacity ratio:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E4">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="R=\frac{f_{\theta}(\mathbf{i}_{\mathrm{comp}})}{f_{\theta}(\mathbf{i}_{\mathrm%
{bg}})}\,," class="ltx_Math" display="block" id="S3.E4.m1.3"><semantics id="S3.E4.m1.3a"><mrow id="S3.E4.m1.3.3.1" xref="S3.E4.m1.3.3.1.1.cmml"><mrow id="S3.E4.m1.3.3.1.1" xref="S3.E4.m1.3.3.1.1.cmml"><mi id="S3.E4.m1.3.3.1.1.2" xref="S3.E4.m1.3.3.1.1.2.cmml">R</mi><mo id="S3.E4.m1.3.3.1.1.1" xref="S3.E4.m1.3.3.1.1.1.cmml">=</mo><mfrac id="S3.E4.m1.2.2" xref="S3.E4.m1.2.2.cmml"><mrow id="S3.E4.m1.1.1.1" xref="S3.E4.m1.1.1.1.cmml"><msub id="S3.E4.m1.1.1.1.3" xref="S3.E4.m1.1.1.1.3.cmml"><mi id="S3.E4.m1.1.1.1.3.2" xref="S3.E4.m1.1.1.1.3.2.cmml">f</mi><mi id="S3.E4.m1.1.1.1.3.3" xref="S3.E4.m1.1.1.1.3.3.cmml">θ</mi></msub><mo id="S3.E4.m1.1.1.1.2" xref="S3.E4.m1.1.1.1.2.cmml">⁢</mo><mrow id="S3.E4.m1.1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.1.1.cmml"><mo id="S3.E4.m1.1.1.1.1.1.2" stretchy="false" xref="S3.E4.m1.1.1.1.1.1.1.cmml">(</mo><msub id="S3.E4.m1.1.1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.1.1.cmml"><mi id="S3.E4.m1.1.1.1.1.1.1.2" xref="S3.E4.m1.1.1.1.1.1.1.2.cmml">𝐢</mi><mi id="S3.E4.m1.1.1.1.1.1.1.3" xref="S3.E4.m1.1.1.1.1.1.1.3.cmml">comp</mi></msub><mo id="S3.E4.m1.1.1.1.1.1.3" stretchy="false" xref="S3.E4.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mrow id="S3.E4.m1.2.2.2" xref="S3.E4.m1.2.2.2.cmml"><msub id="S3.E4.m1.2.2.2.3" xref="S3.E4.m1.2.2.2.3.cmml"><mi id="S3.E4.m1.2.2.2.3.2" xref="S3.E4.m1.2.2.2.3.2.cmml">f</mi><mi id="S3.E4.m1.2.2.2.3.3" xref="S3.E4.m1.2.2.2.3.3.cmml">θ</mi></msub><mo id="S3.E4.m1.2.2.2.2" xref="S3.E4.m1.2.2.2.2.cmml">⁢</mo><mrow id="S3.E4.m1.2.2.2.1.1" xref="S3.E4.m1.2.2.2.1.1.1.cmml"><mo id="S3.E4.m1.2.2.2.1.1.2" stretchy="false" xref="S3.E4.m1.2.2.2.1.1.1.cmml">(</mo><msub id="S3.E4.m1.2.2.2.1.1.1" xref="S3.E4.m1.2.2.2.1.1.1.cmml"><mi id="S3.E4.m1.2.2.2.1.1.1.2" xref="S3.E4.m1.2.2.2.1.1.1.2.cmml">𝐢</mi><mi id="S3.E4.m1.2.2.2.1.1.1.3" xref="S3.E4.m1.2.2.2.1.1.1.3.cmml">bg</mi></msub><mo id="S3.E4.m1.2.2.2.1.1.3" stretchy="false" xref="S3.E4.m1.2.2.2.1.1.1.cmml">)</mo></mrow></mrow></mfrac></mrow><mo id="S3.E4.m1.3.3.1.2" lspace="0.170em" xref="S3.E4.m1.3.3.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E4.m1.3b"><apply id="S3.E4.m1.3.3.1.1.cmml" xref="S3.E4.m1.3.3.1"><eq id="S3.E4.m1.3.3.1.1.1.cmml" xref="S3.E4.m1.3.3.1.1.1"></eq><ci id="S3.E4.m1.3.3.1.1.2.cmml" xref="S3.E4.m1.3.3.1.1.2">𝑅</ci><apply id="S3.E4.m1.2.2.cmml" xref="S3.E4.m1.2.2"><divide id="S3.E4.m1.2.2.3.cmml" xref="S3.E4.m1.2.2"></divide><apply id="S3.E4.m1.1.1.1.cmml" xref="S3.E4.m1.1.1.1"><times id="S3.E4.m1.1.1.1.2.cmml" xref="S3.E4.m1.1.1.1.2"></times><apply id="S3.E4.m1.1.1.1.3.cmml" xref="S3.E4.m1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.3.1.cmml" xref="S3.E4.m1.1.1.1.3">subscript</csymbol><ci id="S3.E4.m1.1.1.1.3.2.cmml" xref="S3.E4.m1.1.1.1.3.2">𝑓</ci><ci id="S3.E4.m1.1.1.1.3.3.cmml" xref="S3.E4.m1.1.1.1.3.3">𝜃</ci></apply><apply id="S3.E4.m1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.1">subscript</csymbol><ci id="S3.E4.m1.1.1.1.1.1.1.2.cmml" xref="S3.E4.m1.1.1.1.1.1.1.2">𝐢</ci><ci id="S3.E4.m1.1.1.1.1.1.1.3.cmml" xref="S3.E4.m1.1.1.1.1.1.1.3">comp</ci></apply></apply><apply id="S3.E4.m1.2.2.2.cmml" xref="S3.E4.m1.2.2.2"><times id="S3.E4.m1.2.2.2.2.cmml" xref="S3.E4.m1.2.2.2.2"></times><apply id="S3.E4.m1.2.2.2.3.cmml" xref="S3.E4.m1.2.2.2.3"><csymbol cd="ambiguous" id="S3.E4.m1.2.2.2.3.1.cmml" xref="S3.E4.m1.2.2.2.3">subscript</csymbol><ci id="S3.E4.m1.2.2.2.3.2.cmml" xref="S3.E4.m1.2.2.2.3.2">𝑓</ci><ci id="S3.E4.m1.2.2.2.3.3.cmml" xref="S3.E4.m1.2.2.2.3.3">𝜃</ci></apply><apply id="S3.E4.m1.2.2.2.1.1.1.cmml" xref="S3.E4.m1.2.2.2.1.1"><csymbol cd="ambiguous" id="S3.E4.m1.2.2.2.1.1.1.1.cmml" xref="S3.E4.m1.2.2.2.1.1">subscript</csymbol><ci id="S3.E4.m1.2.2.2.1.1.1.2.cmml" xref="S3.E4.m1.2.2.2.1.1.1.2">𝐢</ci><ci id="S3.E4.m1.2.2.2.1.1.1.3.cmml" xref="S3.E4.m1.2.2.2.1.1.1.3">bg</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E4.m1.3c">R=\frac{f_{\theta}(\mathbf{i}_{\mathrm{comp}})}{f_{\theta}(\mathbf{i}_{\mathrm%
{bg}})}\,,</annotation><annotation encoding="application/x-llamapun" id="S3.E4.m1.3d">italic_R = divide start_ARG italic_f start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT ( bold_i start_POSTSUBSCRIPT roman_comp end_POSTSUBSCRIPT ) end_ARG start_ARG italic_f start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT ( bold_i start_POSTSUBSCRIPT roman_bg end_POSTSUBSCRIPT ) end_ARG ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS3.p1.10">where <math alttext="\mathbf{i}_{\mathrm{comp}}" class="ltx_Math" display="inline" id="S3.SS3.p1.3.m1.1"><semantics id="S3.SS3.p1.3.m1.1a"><msub id="S3.SS3.p1.3.m1.1.1" xref="S3.SS3.p1.3.m1.1.1.cmml"><mi id="S3.SS3.p1.3.m1.1.1.2" xref="S3.SS3.p1.3.m1.1.1.2.cmml">𝐢</mi><mi id="S3.SS3.p1.3.m1.1.1.3" xref="S3.SS3.p1.3.m1.1.1.3.cmml">comp</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.3.m1.1b"><apply id="S3.SS3.p1.3.m1.1.1.cmml" xref="S3.SS3.p1.3.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.3.m1.1.1.1.cmml" xref="S3.SS3.p1.3.m1.1.1">subscript</csymbol><ci id="S3.SS3.p1.3.m1.1.1.2.cmml" xref="S3.SS3.p1.3.m1.1.1.2">𝐢</ci><ci id="S3.SS3.p1.3.m1.1.1.3.cmml" xref="S3.SS3.p1.3.m1.1.1.3">comp</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.3.m1.1c">\mathbf{i}_{\mathrm{comp}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.3.m1.1d">bold_i start_POSTSUBSCRIPT roman_comp end_POSTSUBSCRIPT</annotation></semantics></math> and <math alttext="\mathbf{i}_{\mathrm{bg}}" class="ltx_Math" display="inline" id="S3.SS3.p1.4.m2.1"><semantics id="S3.SS3.p1.4.m2.1a"><msub id="S3.SS3.p1.4.m2.1.1" xref="S3.SS3.p1.4.m2.1.1.cmml"><mi id="S3.SS3.p1.4.m2.1.1.2" xref="S3.SS3.p1.4.m2.1.1.2.cmml">𝐢</mi><mi id="S3.SS3.p1.4.m2.1.1.3" xref="S3.SS3.p1.4.m2.1.1.3.cmml">bg</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.4.m2.1b"><apply id="S3.SS3.p1.4.m2.1.1.cmml" xref="S3.SS3.p1.4.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.4.m2.1.1.1.cmml" xref="S3.SS3.p1.4.m2.1.1">subscript</csymbol><ci id="S3.SS3.p1.4.m2.1.1.2.cmml" xref="S3.SS3.p1.4.m2.1.1.2">𝐢</ci><ci id="S3.SS3.p1.4.m2.1.1.3.cmml" xref="S3.SS3.p1.4.m2.1.1.3">bg</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.4.m2.1c">\mathbf{i}_{\mathrm{bg}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.4.m2.1d">bold_i start_POSTSUBSCRIPT roman_bg end_POSTSUBSCRIPT</annotation></semantics></math> are the intrinsic maps of the composite and background resp., see <a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#S3.E2" title="In 3.2 Zero-shot object compositing using ZeroComp ‣ 3 ZeroComp ‣ ZeroComp: Zero-shot Object Compositing from Image Intrinsics via Diffusion"><span class="ltx_text ltx_ref_tag">Eq.</span> <span class="ltx_text ltx_ref_tag">2</span></a>. Note that <a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#S3.E4" title="In 3.3 Preserving background fidelity ‣ 3 ZeroComp ‣ ZeroComp: Zero-shot Object Compositing from Image Intrinsics via Diffusion"><span class="ltx_text ltx_ref_tag">Eq.</span> <span class="ltx_text ltx_ref_tag">4</span></a> is computed on grayscale and the result is clamped to <math alttext="[0,1]" class="ltx_Math" display="inline" id="S3.SS3.p1.5.m3.2"><semantics id="S3.SS3.p1.5.m3.2a"><mrow id="S3.SS3.p1.5.m3.2.3.2" xref="S3.SS3.p1.5.m3.2.3.1.cmml"><mo id="S3.SS3.p1.5.m3.2.3.2.1" stretchy="false" xref="S3.SS3.p1.5.m3.2.3.1.cmml">[</mo><mn id="S3.SS3.p1.5.m3.1.1" xref="S3.SS3.p1.5.m3.1.1.cmml">0</mn><mo id="S3.SS3.p1.5.m3.2.3.2.2" xref="S3.SS3.p1.5.m3.2.3.1.cmml">,</mo><mn id="S3.SS3.p1.5.m3.2.2" xref="S3.SS3.p1.5.m3.2.2.cmml">1</mn><mo id="S3.SS3.p1.5.m3.2.3.2.3" stretchy="false" xref="S3.SS3.p1.5.m3.2.3.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.5.m3.2b"><interval closure="closed" id="S3.SS3.p1.5.m3.2.3.1.cmml" xref="S3.SS3.p1.5.m3.2.3.2"><cn id="S3.SS3.p1.5.m3.1.1.cmml" type="integer" xref="S3.SS3.p1.5.m3.1.1">0</cn><cn id="S3.SS3.p1.5.m3.2.2.cmml" type="integer" xref="S3.SS3.p1.5.m3.2.2">1</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.5.m3.2c">[0,1]</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.5.m3.2d">[ 0 , 1 ]</annotation></semantics></math>.
We fix the diffusion with the same seed and use the same shading mask on the background <math alttext="i_{s}" class="ltx_Math" display="inline" id="S3.SS3.p1.6.m4.1"><semantics id="S3.SS3.p1.6.m4.1a"><msub id="S3.SS3.p1.6.m4.1.1" xref="S3.SS3.p1.6.m4.1.1.cmml"><mi id="S3.SS3.p1.6.m4.1.1.2" xref="S3.SS3.p1.6.m4.1.1.2.cmml">i</mi><mi id="S3.SS3.p1.6.m4.1.1.3" xref="S3.SS3.p1.6.m4.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.6.m4.1b"><apply id="S3.SS3.p1.6.m4.1.1.cmml" xref="S3.SS3.p1.6.m4.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.6.m4.1.1.1.cmml" xref="S3.SS3.p1.6.m4.1.1">subscript</csymbol><ci id="S3.SS3.p1.6.m4.1.1.2.cmml" xref="S3.SS3.p1.6.m4.1.1.2">𝑖</ci><ci id="S3.SS3.p1.6.m4.1.1.3.cmml" xref="S3.SS3.p1.6.m4.1.1.3">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.6.m4.1c">i_{s}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.6.m4.1d">italic_i start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT</annotation></semantics></math> to minimize discrepancies between both predictions.
To further avoid unnecessary opacity unrelated to the object, we set the opacity to 1 if they are outside of the shading mask <math alttext="m" class="ltx_Math" display="inline" id="S3.SS3.p1.7.m5.1"><semantics id="S3.SS3.p1.7.m5.1a"><mi id="S3.SS3.p1.7.m5.1.1" xref="S3.SS3.p1.7.m5.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.7.m5.1b"><ci id="S3.SS3.p1.7.m5.1.1.cmml" xref="S3.SS3.p1.7.m5.1.1">𝑚</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.7.m5.1c">m</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.7.m5.1d">italic_m</annotation></semantics></math> computed earlier (c.f. <a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#S3.SS2" title="3.2 Zero-shot object compositing using ZeroComp ‣ 3 ZeroComp ‣ ZeroComp: Zero-shot Object Compositing from Image Intrinsics via Diffusion"><span class="ltx_text ltx_ref_tag">Sec.</span> <span class="ltx_text ltx_ref_tag">3.2</span></a>). A Gaussian blur with kernel <math alttext="15\times 15" class="ltx_Math" display="inline" id="S3.SS3.p1.8.m6.1"><semantics id="S3.SS3.p1.8.m6.1a"><mrow id="S3.SS3.p1.8.m6.1.1" xref="S3.SS3.p1.8.m6.1.1.cmml"><mn id="S3.SS3.p1.8.m6.1.1.2" xref="S3.SS3.p1.8.m6.1.1.2.cmml">15</mn><mo id="S3.SS3.p1.8.m6.1.1.1" lspace="0.222em" rspace="0.222em" xref="S3.SS3.p1.8.m6.1.1.1.cmml">×</mo><mn id="S3.SS3.p1.8.m6.1.1.3" xref="S3.SS3.p1.8.m6.1.1.3.cmml">15</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.8.m6.1b"><apply id="S3.SS3.p1.8.m6.1.1.cmml" xref="S3.SS3.p1.8.m6.1.1"><times id="S3.SS3.p1.8.m6.1.1.1.cmml" xref="S3.SS3.p1.8.m6.1.1.1"></times><cn id="S3.SS3.p1.8.m6.1.1.2.cmml" type="integer" xref="S3.SS3.p1.8.m6.1.1.2">15</cn><cn id="S3.SS3.p1.8.m6.1.1.3.cmml" type="integer" xref="S3.SS3.p1.8.m6.1.1.3">15</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.8.m6.1c">15\times 15</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.8.m6.1d">15 × 15</annotation></semantics></math> and <math alttext="\sigma=1.5" class="ltx_Math" display="inline" id="S3.SS3.p1.9.m7.1"><semantics id="S3.SS3.p1.9.m7.1a"><mrow id="S3.SS3.p1.9.m7.1.1" xref="S3.SS3.p1.9.m7.1.1.cmml"><mi id="S3.SS3.p1.9.m7.1.1.2" xref="S3.SS3.p1.9.m7.1.1.2.cmml">σ</mi><mo id="S3.SS3.p1.9.m7.1.1.1" xref="S3.SS3.p1.9.m7.1.1.1.cmml">=</mo><mn id="S3.SS3.p1.9.m7.1.1.3" xref="S3.SS3.p1.9.m7.1.1.3.cmml">1.5</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.9.m7.1b"><apply id="S3.SS3.p1.9.m7.1.1.cmml" xref="S3.SS3.p1.9.m7.1.1"><eq id="S3.SS3.p1.9.m7.1.1.1.cmml" xref="S3.SS3.p1.9.m7.1.1.1"></eq><ci id="S3.SS3.p1.9.m7.1.1.2.cmml" xref="S3.SS3.p1.9.m7.1.1.2">𝜎</ci><cn id="S3.SS3.p1.9.m7.1.1.3.cmml" type="float" xref="S3.SS3.p1.9.m7.1.1.3">1.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.9.m7.1c">\sigma=1.5</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.9.m7.1d">italic_σ = 1.5</annotation></semantics></math> is applied to <math alttext="m" class="ltx_Math" display="inline" id="S3.SS3.p1.10.m8.1"><semantics id="S3.SS3.p1.10.m8.1a"><mi id="S3.SS3.p1.10.m8.1.1" xref="S3.SS3.p1.10.m8.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.10.m8.1b"><ci id="S3.SS3.p1.10.m8.1.1.cmml" xref="S3.SS3.p1.10.m8.1.1">𝑚</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.10.m8.1c">m</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.10.m8.1d">italic_m</annotation></semantics></math> to avoid blending artifacts.
The final compositing equation is</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E5">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="x=(1-m)\,R\,x_{\mathrm{bg}}+m\,C\,f(\mathbf{i}_{\mathrm{comp}})\,," class="ltx_Math" display="block" id="S3.E5.m1.1"><semantics id="S3.E5.m1.1a"><mrow id="S3.E5.m1.1.1.1" xref="S3.E5.m1.1.1.1.1.cmml"><mrow id="S3.E5.m1.1.1.1.1" xref="S3.E5.m1.1.1.1.1.cmml"><mi id="S3.E5.m1.1.1.1.1.4" xref="S3.E5.m1.1.1.1.1.4.cmml">x</mi><mo id="S3.E5.m1.1.1.1.1.3" xref="S3.E5.m1.1.1.1.1.3.cmml">=</mo><mrow id="S3.E5.m1.1.1.1.1.2" xref="S3.E5.m1.1.1.1.1.2.cmml"><mrow id="S3.E5.m1.1.1.1.1.1.1" xref="S3.E5.m1.1.1.1.1.1.1.cmml"><mrow id="S3.E5.m1.1.1.1.1.1.1.1.1" xref="S3.E5.m1.1.1.1.1.1.1.1.1.1.cmml"><mo id="S3.E5.m1.1.1.1.1.1.1.1.1.2" stretchy="false" xref="S3.E5.m1.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E5.m1.1.1.1.1.1.1.1.1.1" xref="S3.E5.m1.1.1.1.1.1.1.1.1.1.cmml"><mn id="S3.E5.m1.1.1.1.1.1.1.1.1.1.2" xref="S3.E5.m1.1.1.1.1.1.1.1.1.1.2.cmml">1</mn><mo id="S3.E5.m1.1.1.1.1.1.1.1.1.1.1" xref="S3.E5.m1.1.1.1.1.1.1.1.1.1.1.cmml">−</mo><mi id="S3.E5.m1.1.1.1.1.1.1.1.1.1.3" xref="S3.E5.m1.1.1.1.1.1.1.1.1.1.3.cmml">m</mi></mrow><mo id="S3.E5.m1.1.1.1.1.1.1.1.1.3" stretchy="false" xref="S3.E5.m1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow><mo id="S3.E5.m1.1.1.1.1.1.1.2" lspace="0.170em" xref="S3.E5.m1.1.1.1.1.1.1.2.cmml">⁢</mo><mi id="S3.E5.m1.1.1.1.1.1.1.3" xref="S3.E5.m1.1.1.1.1.1.1.3.cmml">R</mi><mo id="S3.E5.m1.1.1.1.1.1.1.2a" lspace="0.170em" xref="S3.E5.m1.1.1.1.1.1.1.2.cmml">⁢</mo><msub id="S3.E5.m1.1.1.1.1.1.1.4" xref="S3.E5.m1.1.1.1.1.1.1.4.cmml"><mi id="S3.E5.m1.1.1.1.1.1.1.4.2" xref="S3.E5.m1.1.1.1.1.1.1.4.2.cmml">x</mi><mi id="S3.E5.m1.1.1.1.1.1.1.4.3" xref="S3.E5.m1.1.1.1.1.1.1.4.3.cmml">bg</mi></msub></mrow><mo id="S3.E5.m1.1.1.1.1.2.3" xref="S3.E5.m1.1.1.1.1.2.3.cmml">+</mo><mrow id="S3.E5.m1.1.1.1.1.2.2" xref="S3.E5.m1.1.1.1.1.2.2.cmml"><mi id="S3.E5.m1.1.1.1.1.2.2.3" xref="S3.E5.m1.1.1.1.1.2.2.3.cmml">m</mi><mo id="S3.E5.m1.1.1.1.1.2.2.2" lspace="0.170em" xref="S3.E5.m1.1.1.1.1.2.2.2.cmml">⁢</mo><mi id="S3.E5.m1.1.1.1.1.2.2.4" xref="S3.E5.m1.1.1.1.1.2.2.4.cmml">C</mi><mo id="S3.E5.m1.1.1.1.1.2.2.2a" lspace="0.170em" xref="S3.E5.m1.1.1.1.1.2.2.2.cmml">⁢</mo><mi id="S3.E5.m1.1.1.1.1.2.2.5" xref="S3.E5.m1.1.1.1.1.2.2.5.cmml">f</mi><mo id="S3.E5.m1.1.1.1.1.2.2.2b" xref="S3.E5.m1.1.1.1.1.2.2.2.cmml">⁢</mo><mrow id="S3.E5.m1.1.1.1.1.2.2.1.1" xref="S3.E5.m1.1.1.1.1.2.2.1.1.1.cmml"><mo id="S3.E5.m1.1.1.1.1.2.2.1.1.2" stretchy="false" xref="S3.E5.m1.1.1.1.1.2.2.1.1.1.cmml">(</mo><msub id="S3.E5.m1.1.1.1.1.2.2.1.1.1" xref="S3.E5.m1.1.1.1.1.2.2.1.1.1.cmml"><mi id="S3.E5.m1.1.1.1.1.2.2.1.1.1.2" xref="S3.E5.m1.1.1.1.1.2.2.1.1.1.2.cmml">𝐢</mi><mi id="S3.E5.m1.1.1.1.1.2.2.1.1.1.3" xref="S3.E5.m1.1.1.1.1.2.2.1.1.1.3.cmml">comp</mi></msub><mo id="S3.E5.m1.1.1.1.1.2.2.1.1.3" rspace="0.170em" stretchy="false" xref="S3.E5.m1.1.1.1.1.2.2.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow><mo id="S3.E5.m1.1.1.1.2" xref="S3.E5.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E5.m1.1b"><apply id="S3.E5.m1.1.1.1.1.cmml" xref="S3.E5.m1.1.1.1"><eq id="S3.E5.m1.1.1.1.1.3.cmml" xref="S3.E5.m1.1.1.1.1.3"></eq><ci id="S3.E5.m1.1.1.1.1.4.cmml" xref="S3.E5.m1.1.1.1.1.4">𝑥</ci><apply id="S3.E5.m1.1.1.1.1.2.cmml" xref="S3.E5.m1.1.1.1.1.2"><plus id="S3.E5.m1.1.1.1.1.2.3.cmml" xref="S3.E5.m1.1.1.1.1.2.3"></plus><apply id="S3.E5.m1.1.1.1.1.1.1.cmml" xref="S3.E5.m1.1.1.1.1.1.1"><times id="S3.E5.m1.1.1.1.1.1.1.2.cmml" xref="S3.E5.m1.1.1.1.1.1.1.2"></times><apply id="S3.E5.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E5.m1.1.1.1.1.1.1.1.1"><minus id="S3.E5.m1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E5.m1.1.1.1.1.1.1.1.1.1.1"></minus><cn id="S3.E5.m1.1.1.1.1.1.1.1.1.1.2.cmml" type="integer" xref="S3.E5.m1.1.1.1.1.1.1.1.1.1.2">1</cn><ci id="S3.E5.m1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E5.m1.1.1.1.1.1.1.1.1.1.3">𝑚</ci></apply><ci id="S3.E5.m1.1.1.1.1.1.1.3.cmml" xref="S3.E5.m1.1.1.1.1.1.1.3">𝑅</ci><apply id="S3.E5.m1.1.1.1.1.1.1.4.cmml" xref="S3.E5.m1.1.1.1.1.1.1.4"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.1.1.1.1.4.1.cmml" xref="S3.E5.m1.1.1.1.1.1.1.4">subscript</csymbol><ci id="S3.E5.m1.1.1.1.1.1.1.4.2.cmml" xref="S3.E5.m1.1.1.1.1.1.1.4.2">𝑥</ci><ci id="S3.E5.m1.1.1.1.1.1.1.4.3.cmml" xref="S3.E5.m1.1.1.1.1.1.1.4.3">bg</ci></apply></apply><apply id="S3.E5.m1.1.1.1.1.2.2.cmml" xref="S3.E5.m1.1.1.1.1.2.2"><times id="S3.E5.m1.1.1.1.1.2.2.2.cmml" xref="S3.E5.m1.1.1.1.1.2.2.2"></times><ci id="S3.E5.m1.1.1.1.1.2.2.3.cmml" xref="S3.E5.m1.1.1.1.1.2.2.3">𝑚</ci><ci id="S3.E5.m1.1.1.1.1.2.2.4.cmml" xref="S3.E5.m1.1.1.1.1.2.2.4">𝐶</ci><ci id="S3.E5.m1.1.1.1.1.2.2.5.cmml" xref="S3.E5.m1.1.1.1.1.2.2.5">𝑓</ci><apply id="S3.E5.m1.1.1.1.1.2.2.1.1.1.cmml" xref="S3.E5.m1.1.1.1.1.2.2.1.1"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.1.1.2.2.1.1.1.1.cmml" xref="S3.E5.m1.1.1.1.1.2.2.1.1">subscript</csymbol><ci id="S3.E5.m1.1.1.1.1.2.2.1.1.1.2.cmml" xref="S3.E5.m1.1.1.1.1.2.2.1.1.1.2">𝐢</ci><ci id="S3.E5.m1.1.1.1.1.2.2.1.1.1.3.cmml" xref="S3.E5.m1.1.1.1.1.2.2.1.1.1.3">comp</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E5.m1.1c">x=(1-m)\,R\,x_{\mathrm{bg}}+m\,C\,f(\mathbf{i}_{\mathrm{comp}})\,,</annotation><annotation encoding="application/x-llamapun" id="S3.E5.m1.1d">italic_x = ( 1 - italic_m ) italic_R italic_x start_POSTSUBSCRIPT roman_bg end_POSTSUBSCRIPT + italic_m italic_C italic_f ( bold_i start_POSTSUBSCRIPT roman_comp end_POSTSUBSCRIPT ) ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS3.p1.13">where <math alttext="C" class="ltx_Math" display="inline" id="S3.SS3.p1.11.m1.1"><semantics id="S3.SS3.p1.11.m1.1a"><mi id="S3.SS3.p1.11.m1.1.1" xref="S3.SS3.p1.11.m1.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.11.m1.1b"><ci id="S3.SS3.p1.11.m1.1.1.cmml" xref="S3.SS3.p1.11.m1.1.1">𝐶</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.11.m1.1c">C</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.11.m1.1d">italic_C</annotation></semantics></math> is a color balance factor computed as the average color ratio of background <math alttext="x_{\mathrm{bg}}" class="ltx_Math" display="inline" id="S3.SS3.p1.12.m2.1"><semantics id="S3.SS3.p1.12.m2.1a"><msub id="S3.SS3.p1.12.m2.1.1" xref="S3.SS3.p1.12.m2.1.1.cmml"><mi id="S3.SS3.p1.12.m2.1.1.2" xref="S3.SS3.p1.12.m2.1.1.2.cmml">x</mi><mi id="S3.SS3.p1.12.m2.1.1.3" xref="S3.SS3.p1.12.m2.1.1.3.cmml">bg</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.12.m2.1b"><apply id="S3.SS3.p1.12.m2.1.1.cmml" xref="S3.SS3.p1.12.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.12.m2.1.1.1.cmml" xref="S3.SS3.p1.12.m2.1.1">subscript</csymbol><ci id="S3.SS3.p1.12.m2.1.1.2.cmml" xref="S3.SS3.p1.12.m2.1.1.2">𝑥</ci><ci id="S3.SS3.p1.12.m2.1.1.3.cmml" xref="S3.SS3.p1.12.m2.1.1.3">bg</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.12.m2.1c">x_{\mathrm{bg}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.12.m2.1d">italic_x start_POSTSUBSCRIPT roman_bg end_POSTSUBSCRIPT</annotation></semantics></math> and the network output <math alttext="f(\mathbf{i}_{\mathrm{comp}})" class="ltx_Math" display="inline" id="S3.SS3.p1.13.m3.1"><semantics id="S3.SS3.p1.13.m3.1a"><mrow id="S3.SS3.p1.13.m3.1.1" xref="S3.SS3.p1.13.m3.1.1.cmml"><mi id="S3.SS3.p1.13.m3.1.1.3" xref="S3.SS3.p1.13.m3.1.1.3.cmml">f</mi><mo id="S3.SS3.p1.13.m3.1.1.2" xref="S3.SS3.p1.13.m3.1.1.2.cmml">⁢</mo><mrow id="S3.SS3.p1.13.m3.1.1.1.1" xref="S3.SS3.p1.13.m3.1.1.1.1.1.cmml"><mo id="S3.SS3.p1.13.m3.1.1.1.1.2" stretchy="false" xref="S3.SS3.p1.13.m3.1.1.1.1.1.cmml">(</mo><msub id="S3.SS3.p1.13.m3.1.1.1.1.1" xref="S3.SS3.p1.13.m3.1.1.1.1.1.cmml"><mi id="S3.SS3.p1.13.m3.1.1.1.1.1.2" xref="S3.SS3.p1.13.m3.1.1.1.1.1.2.cmml">𝐢</mi><mi id="S3.SS3.p1.13.m3.1.1.1.1.1.3" xref="S3.SS3.p1.13.m3.1.1.1.1.1.3.cmml">comp</mi></msub><mo id="S3.SS3.p1.13.m3.1.1.1.1.3" stretchy="false" xref="S3.SS3.p1.13.m3.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.13.m3.1b"><apply id="S3.SS3.p1.13.m3.1.1.cmml" xref="S3.SS3.p1.13.m3.1.1"><times id="S3.SS3.p1.13.m3.1.1.2.cmml" xref="S3.SS3.p1.13.m3.1.1.2"></times><ci id="S3.SS3.p1.13.m3.1.1.3.cmml" xref="S3.SS3.p1.13.m3.1.1.3">𝑓</ci><apply id="S3.SS3.p1.13.m3.1.1.1.1.1.cmml" xref="S3.SS3.p1.13.m3.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.13.m3.1.1.1.1.1.1.cmml" xref="S3.SS3.p1.13.m3.1.1.1.1">subscript</csymbol><ci id="S3.SS3.p1.13.m3.1.1.1.1.1.2.cmml" xref="S3.SS3.p1.13.m3.1.1.1.1.1.2">𝐢</ci><ci id="S3.SS3.p1.13.m3.1.1.1.1.1.3.cmml" xref="S3.SS3.p1.13.m3.1.1.1.1.1.3">comp</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.13.m3.1c">f(\mathbf{i}_{\mathrm{comp}})</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.13.m3.1d">italic_f ( bold_i start_POSTSUBSCRIPT roman_comp end_POSTSUBSCRIPT )</annotation></semantics></math> to account for global color shifts. In <a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#S3.F3" title="In 3.3 Preserving background fidelity ‣ 3 ZeroComp ‣ ZeroComp: Zero-shot Object Compositing from Image Intrinsics via Diffusion"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">3</span></a>, we compare our composition and direct output of the network.</p>
</div>
<figure class="ltx_figure" id="S3.F3">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S3.F3.16">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.F3.10.10">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S3.F3.2.2.2" style="padding-left:1.0pt;padding-right:1.0pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="87" id="S3.F3.1.1.1.g1" src="extracted/5908513/figures/visibility/9C4A8928-2fbd3aa74a_05_crop_B07HZ782D9_vis2/bg.jpg" width="87"/><span class="ltx_text" id="S3.F3.2.2.2.2" style="font-size:70%;">
</span><span class="ltx_text ltx_inline-block" id="S3.F3.2.2.2.1" style="font-size:70%;width:0.0pt;position:relative; bottom:22.8pt;"><svg height="-54619" overflow="visible" version="1.1" width="1383699"><g transform="translate(0,-54619) scale(1,-1)"><rect fill="none" height="-39473.2pt" stroke="#000000" stroke-width="0.4" width="999999.3pt" x="0" y="0"></rect><g class="makebox" transform="translate(0,0)"><g transform="translate(0,-54619.0673861907) scale(1, -1)"><foreignobject height="-54619.0673861907" overflow="visible" width="1383699.04524699"><img alt="Refer to caption" class="ltx_graphics ltx_missing ltx_missing_image" id="S3.F3.2.2.2.1.1.pic1.1.g1" src=""/></foreignobject></g></g></g></svg></span>
</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S3.F3.4.4.4" style="padding-left:1.0pt;padding-right:1.0pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="87" id="S3.F3.3.3.3.g1" src="extracted/5908513/figures/visibility/9C4A8928-2fbd3aa74a_05_crop_B07HZ782D9_vis2/pred_bg.jpg" width="87"/><span class="ltx_text" id="S3.F3.4.4.4.2" style="font-size:70%;">
</span><span class="ltx_text ltx_inline-block" id="S3.F3.4.4.4.1" style="font-size:70%;width:0.0pt;position:relative; bottom:22.8pt;"><svg height="-54619" overflow="visible" version="1.1" width="1383699"><g transform="translate(0,-54619) scale(1,-1)"><rect fill="none" height="-39473.2pt" stroke="#000000" stroke-width="0.4" width="999999.3pt" x="0" y="0"></rect><g class="makebox" transform="translate(0,0)"><g transform="translate(0,-54619.0673861907) scale(1, -1)"><foreignobject height="-54619.0673861907" overflow="visible" width="1383699.04524699"><img alt="Refer to caption" class="ltx_graphics ltx_missing ltx_missing_image" id="S3.F3.4.4.4.1.1.pic1.1.g1" src=""/></foreignobject></g></g></g></svg></span>
</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S3.F3.6.6.6" style="padding-left:1.0pt;padding-right:1.0pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="87" id="S3.F3.5.5.5.g1" src="extracted/5908513/figures/visibility/9C4A8928-2fbd3aa74a_05_crop_B07HZ782D9_vis2/pred.jpg" width="87"/><span class="ltx_text" id="S3.F3.6.6.6.2" style="font-size:70%;">
</span><span class="ltx_text ltx_inline-block" id="S3.F3.6.6.6.1" style="font-size:70%;width:0.0pt;position:relative; bottom:22.8pt;"><svg height="-54619" overflow="visible" version="1.1" width="1383699"><g transform="translate(0,-54619) scale(1,-1)"><rect fill="none" height="-39473.2pt" stroke="#000000" stroke-width="0.4" width="999999.3pt" x="0" y="0"></rect><g class="makebox" transform="translate(0,0)"><g transform="translate(0,-54619.0673861907) scale(1, -1)"><foreignobject height="-54619.0673861907" overflow="visible" width="1383699.04524699"><img alt="Refer to caption" class="ltx_graphics ltx_missing ltx_missing_image" id="S3.F3.6.6.6.1.1.pic1.1.g1" src=""/></foreignobject></g></g></g></svg></span>
</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S3.F3.7.7.7" style="padding-left:1.0pt;padding-right:1.0pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="87" id="S3.F3.7.7.7.g1" src="extracted/5908513/figures/visibility/9C4A8928-2fbd3aa74a_05_crop_B07HZ782D9_vis2/visibility.jpg" width="87"/></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S3.F3.8.8.8" style="padding-left:1.0pt;padding-right:1.0pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="87" id="S3.F3.8.8.8.g1" src="extracted/5908513/figures/visibility/9C4A8928-2fbd3aa74a_05_crop_B07HZ782D9_vis2/mask.jpg" width="87"/></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S3.F3.10.10.10" style="padding-left:1.0pt;padding-right:1.0pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="87" id="S3.F3.9.9.9.g1" src="extracted/5908513/figures/visibility/9C4A8928-2fbd3aa74a_05_crop_B07HZ782D9_vis2/pred_vis.jpg" width="87"/><span class="ltx_text" id="S3.F3.10.10.10.2" style="font-size:70%;">
</span><span class="ltx_text ltx_inline-block" id="S3.F3.10.10.10.1" style="font-size:70%;width:0.0pt;position:relative; bottom:22.8pt;"><svg height="-54619" overflow="visible" version="1.1" width="1383699"><g transform="translate(0,-54619) scale(1,-1)"><rect fill="none" height="-39473.2pt" stroke="#000000" stroke-width="0.4" width="999999.3pt" x="0" y="0"></rect><g class="makebox" transform="translate(0,0)"><g transform="translate(0,-54619.0673861907) scale(1, -1)"><foreignobject height="-54619.0673861907" overflow="visible" width="1383699.04524699"><img alt="Refer to caption" class="ltx_graphics ltx_missing ltx_missing_image" id="S3.F3.10.10.10.1.1.pic1.1.g1" src=""/></foreignobject></g></g></g></svg></span>
</td>
</tr>
<tr class="ltx_tr" id="S3.F3.16.16">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S3.F3.11.11.1" style="padding-left:1.0pt;padding-right:1.0pt;">
<span class="ltx_text" id="S3.F3.11.11.1.1" style="font-size:70%;">(a) </span><math alttext="x_{\mathrm{bg}}" class="ltx_Math" display="inline" id="S3.F3.11.11.1.m1.1"><semantics id="S3.F3.11.11.1.m1.1a"><msub id="S3.F3.11.11.1.m1.1.1" xref="S3.F3.11.11.1.m1.1.1.cmml"><mi id="S3.F3.11.11.1.m1.1.1.2" mathsize="70%" xref="S3.F3.11.11.1.m1.1.1.2.cmml">x</mi><mi id="S3.F3.11.11.1.m1.1.1.3" mathsize="70%" xref="S3.F3.11.11.1.m1.1.1.3.cmml">bg</mi></msub><annotation-xml encoding="MathML-Content" id="S3.F3.11.11.1.m1.1b"><apply id="S3.F3.11.11.1.m1.1.1.cmml" xref="S3.F3.11.11.1.m1.1.1"><csymbol cd="ambiguous" id="S3.F3.11.11.1.m1.1.1.1.cmml" xref="S3.F3.11.11.1.m1.1.1">subscript</csymbol><ci id="S3.F3.11.11.1.m1.1.1.2.cmml" xref="S3.F3.11.11.1.m1.1.1.2">𝑥</ci><ci id="S3.F3.11.11.1.m1.1.1.3.cmml" xref="S3.F3.11.11.1.m1.1.1.3">bg</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.11.11.1.m1.1c">x_{\mathrm{bg}}</annotation><annotation encoding="application/x-llamapun" id="S3.F3.11.11.1.m1.1d">italic_x start_POSTSUBSCRIPT roman_bg end_POSTSUBSCRIPT</annotation></semantics></math>
</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S3.F3.12.12.2" style="padding-left:1.0pt;padding-right:1.0pt;">
<span class="ltx_text" id="S3.F3.12.12.2.1" style="font-size:70%;">(b) </span><math alttext="f_{\theta}(\mathbf{i}_{\mathrm{bg}})" class="ltx_Math" display="inline" id="S3.F3.12.12.2.m1.1"><semantics id="S3.F3.12.12.2.m1.1a"><mrow id="S3.F3.12.12.2.m1.1.1" xref="S3.F3.12.12.2.m1.1.1.cmml"><msub id="S3.F3.12.12.2.m1.1.1.3" xref="S3.F3.12.12.2.m1.1.1.3.cmml"><mi id="S3.F3.12.12.2.m1.1.1.3.2" mathsize="70%" xref="S3.F3.12.12.2.m1.1.1.3.2.cmml">f</mi><mi id="S3.F3.12.12.2.m1.1.1.3.3" mathsize="70%" xref="S3.F3.12.12.2.m1.1.1.3.3.cmml">θ</mi></msub><mo id="S3.F3.12.12.2.m1.1.1.2" xref="S3.F3.12.12.2.m1.1.1.2.cmml">⁢</mo><mrow id="S3.F3.12.12.2.m1.1.1.1.1" xref="S3.F3.12.12.2.m1.1.1.1.1.1.cmml"><mo id="S3.F3.12.12.2.m1.1.1.1.1.2" maxsize="70%" minsize="70%" xref="S3.F3.12.12.2.m1.1.1.1.1.1.cmml">(</mo><msub id="S3.F3.12.12.2.m1.1.1.1.1.1" xref="S3.F3.12.12.2.m1.1.1.1.1.1.cmml"><mi id="S3.F3.12.12.2.m1.1.1.1.1.1.2" mathsize="70%" xref="S3.F3.12.12.2.m1.1.1.1.1.1.2.cmml">𝐢</mi><mi id="S3.F3.12.12.2.m1.1.1.1.1.1.3" mathsize="70%" xref="S3.F3.12.12.2.m1.1.1.1.1.1.3.cmml">bg</mi></msub><mo id="S3.F3.12.12.2.m1.1.1.1.1.3" maxsize="70%" minsize="70%" xref="S3.F3.12.12.2.m1.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.F3.12.12.2.m1.1b"><apply id="S3.F3.12.12.2.m1.1.1.cmml" xref="S3.F3.12.12.2.m1.1.1"><times id="S3.F3.12.12.2.m1.1.1.2.cmml" xref="S3.F3.12.12.2.m1.1.1.2"></times><apply id="S3.F3.12.12.2.m1.1.1.3.cmml" xref="S3.F3.12.12.2.m1.1.1.3"><csymbol cd="ambiguous" id="S3.F3.12.12.2.m1.1.1.3.1.cmml" xref="S3.F3.12.12.2.m1.1.1.3">subscript</csymbol><ci id="S3.F3.12.12.2.m1.1.1.3.2.cmml" xref="S3.F3.12.12.2.m1.1.1.3.2">𝑓</ci><ci id="S3.F3.12.12.2.m1.1.1.3.3.cmml" xref="S3.F3.12.12.2.m1.1.1.3.3">𝜃</ci></apply><apply id="S3.F3.12.12.2.m1.1.1.1.1.1.cmml" xref="S3.F3.12.12.2.m1.1.1.1.1"><csymbol cd="ambiguous" id="S3.F3.12.12.2.m1.1.1.1.1.1.1.cmml" xref="S3.F3.12.12.2.m1.1.1.1.1">subscript</csymbol><ci id="S3.F3.12.12.2.m1.1.1.1.1.1.2.cmml" xref="S3.F3.12.12.2.m1.1.1.1.1.1.2">𝐢</ci><ci id="S3.F3.12.12.2.m1.1.1.1.1.1.3.cmml" xref="S3.F3.12.12.2.m1.1.1.1.1.1.3">bg</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.12.12.2.m1.1c">f_{\theta}(\mathbf{i}_{\mathrm{bg}})</annotation><annotation encoding="application/x-llamapun" id="S3.F3.12.12.2.m1.1d">italic_f start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT ( bold_i start_POSTSUBSCRIPT roman_bg end_POSTSUBSCRIPT )</annotation></semantics></math>
</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S3.F3.13.13.3" style="padding-left:1.0pt;padding-right:1.0pt;">
<span class="ltx_text" id="S3.F3.13.13.3.1" style="font-size:70%;">(c) </span><math alttext="f_{\theta}(\mathbf{i}_{\mathrm{comp}})" class="ltx_Math" display="inline" id="S3.F3.13.13.3.m1.1"><semantics id="S3.F3.13.13.3.m1.1a"><mrow id="S3.F3.13.13.3.m1.1.1" xref="S3.F3.13.13.3.m1.1.1.cmml"><msub id="S3.F3.13.13.3.m1.1.1.3" xref="S3.F3.13.13.3.m1.1.1.3.cmml"><mi id="S3.F3.13.13.3.m1.1.1.3.2" mathsize="70%" xref="S3.F3.13.13.3.m1.1.1.3.2.cmml">f</mi><mi id="S3.F3.13.13.3.m1.1.1.3.3" mathsize="70%" xref="S3.F3.13.13.3.m1.1.1.3.3.cmml">θ</mi></msub><mo id="S3.F3.13.13.3.m1.1.1.2" xref="S3.F3.13.13.3.m1.1.1.2.cmml">⁢</mo><mrow id="S3.F3.13.13.3.m1.1.1.1.1" xref="S3.F3.13.13.3.m1.1.1.1.1.1.cmml"><mo id="S3.F3.13.13.3.m1.1.1.1.1.2" maxsize="70%" minsize="70%" xref="S3.F3.13.13.3.m1.1.1.1.1.1.cmml">(</mo><msub id="S3.F3.13.13.3.m1.1.1.1.1.1" xref="S3.F3.13.13.3.m1.1.1.1.1.1.cmml"><mi id="S3.F3.13.13.3.m1.1.1.1.1.1.2" mathsize="70%" xref="S3.F3.13.13.3.m1.1.1.1.1.1.2.cmml">𝐢</mi><mi id="S3.F3.13.13.3.m1.1.1.1.1.1.3" mathsize="70%" xref="S3.F3.13.13.3.m1.1.1.1.1.1.3.cmml">comp</mi></msub><mo id="S3.F3.13.13.3.m1.1.1.1.1.3" maxsize="70%" minsize="70%" xref="S3.F3.13.13.3.m1.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.F3.13.13.3.m1.1b"><apply id="S3.F3.13.13.3.m1.1.1.cmml" xref="S3.F3.13.13.3.m1.1.1"><times id="S3.F3.13.13.3.m1.1.1.2.cmml" xref="S3.F3.13.13.3.m1.1.1.2"></times><apply id="S3.F3.13.13.3.m1.1.1.3.cmml" xref="S3.F3.13.13.3.m1.1.1.3"><csymbol cd="ambiguous" id="S3.F3.13.13.3.m1.1.1.3.1.cmml" xref="S3.F3.13.13.3.m1.1.1.3">subscript</csymbol><ci id="S3.F3.13.13.3.m1.1.1.3.2.cmml" xref="S3.F3.13.13.3.m1.1.1.3.2">𝑓</ci><ci id="S3.F3.13.13.3.m1.1.1.3.3.cmml" xref="S3.F3.13.13.3.m1.1.1.3.3">𝜃</ci></apply><apply id="S3.F3.13.13.3.m1.1.1.1.1.1.cmml" xref="S3.F3.13.13.3.m1.1.1.1.1"><csymbol cd="ambiguous" id="S3.F3.13.13.3.m1.1.1.1.1.1.1.cmml" xref="S3.F3.13.13.3.m1.1.1.1.1">subscript</csymbol><ci id="S3.F3.13.13.3.m1.1.1.1.1.1.2.cmml" xref="S3.F3.13.13.3.m1.1.1.1.1.1.2">𝐢</ci><ci id="S3.F3.13.13.3.m1.1.1.1.1.1.3.cmml" xref="S3.F3.13.13.3.m1.1.1.1.1.1.3">comp</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.13.13.3.m1.1c">f_{\theta}(\mathbf{i}_{\mathrm{comp}})</annotation><annotation encoding="application/x-llamapun" id="S3.F3.13.13.3.m1.1d">italic_f start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT ( bold_i start_POSTSUBSCRIPT roman_comp end_POSTSUBSCRIPT )</annotation></semantics></math>
</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S3.F3.14.14.4" style="padding-left:1.0pt;padding-right:1.0pt;">
<span class="ltx_text" id="S3.F3.14.14.4.1" style="font-size:70%;">(d) </span><math alttext="R" class="ltx_Math" display="inline" id="S3.F3.14.14.4.m1.1"><semantics id="S3.F3.14.14.4.m1.1a"><mi id="S3.F3.14.14.4.m1.1.1" mathsize="70%" xref="S3.F3.14.14.4.m1.1.1.cmml">R</mi><annotation-xml encoding="MathML-Content" id="S3.F3.14.14.4.m1.1b"><ci id="S3.F3.14.14.4.m1.1.1.cmml" xref="S3.F3.14.14.4.m1.1.1">𝑅</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.14.14.4.m1.1c">R</annotation><annotation encoding="application/x-llamapun" id="S3.F3.14.14.4.m1.1d">italic_R</annotation></semantics></math>
</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S3.F3.15.15.5" style="padding-left:1.0pt;padding-right:1.0pt;">
<span class="ltx_text" id="S3.F3.15.15.5.1" style="font-size:70%;">(e) </span><math alttext="m" class="ltx_Math" display="inline" id="S3.F3.15.15.5.m1.1"><semantics id="S3.F3.15.15.5.m1.1a"><mi id="S3.F3.15.15.5.m1.1.1" mathsize="70%" xref="S3.F3.15.15.5.m1.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="S3.F3.15.15.5.m1.1b"><ci id="S3.F3.15.15.5.m1.1.1.cmml" xref="S3.F3.15.15.5.m1.1.1">𝑚</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.15.15.5.m1.1c">m</annotation><annotation encoding="application/x-llamapun" id="S3.F3.15.15.5.m1.1d">italic_m</annotation></semantics></math>
</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S3.F3.16.16.6" style="padding-left:1.0pt;padding-right:1.0pt;">
<span class="ltx_text" id="S3.F3.16.16.6.1" style="font-size:70%;">(f) Comp </span><math alttext="x" class="ltx_Math" display="inline" id="S3.F3.16.16.6.m1.1"><semantics id="S3.F3.16.16.6.m1.1a"><mi id="S3.F3.16.16.6.m1.1.1" mathsize="70%" xref="S3.F3.16.16.6.m1.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S3.F3.16.16.6.m1.1b"><ci id="S3.F3.16.16.6.m1.1.1.cmml" xref="S3.F3.16.16.6.m1.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.16.16.6.m1.1c">x</annotation><annotation encoding="application/x-llamapun" id="S3.F3.16.16.6.m1.1d">italic_x</annotation></semantics></math>
</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:70%;"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S3.F3.39.7.1" style="font-size:129%;">Figure 3</span>: </span><span class="ltx_text" id="S3.F3.28.6" style="font-size:129%;">Overview of different components from our full compositing equation in <a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#S3.E5" title="In 3.3 Preserving background fidelity ‣ 3 ZeroComp ‣ ZeroComp: Zero-shot Object Compositing from Image Intrinsics via Diffusion"><span class="ltx_text ltx_ref_tag">eq.</span> <span class="ltx_text ltx_ref_tag">5</span></a>. For (a) a given target background image <math alttext="x_{\mathrm{bg}}" class="ltx_Math" display="inline" id="S3.F3.23.1.m1.1"><semantics id="S3.F3.23.1.m1.1b"><msub id="S3.F3.23.1.m1.1.1" xref="S3.F3.23.1.m1.1.1.cmml"><mi id="S3.F3.23.1.m1.1.1.2" xref="S3.F3.23.1.m1.1.1.2.cmml">x</mi><mi id="S3.F3.23.1.m1.1.1.3" xref="S3.F3.23.1.m1.1.1.3.cmml">bg</mi></msub><annotation-xml encoding="MathML-Content" id="S3.F3.23.1.m1.1c"><apply id="S3.F3.23.1.m1.1.1.cmml" xref="S3.F3.23.1.m1.1.1"><csymbol cd="ambiguous" id="S3.F3.23.1.m1.1.1.1.cmml" xref="S3.F3.23.1.m1.1.1">subscript</csymbol><ci id="S3.F3.23.1.m1.1.1.2.cmml" xref="S3.F3.23.1.m1.1.1.2">𝑥</ci><ci id="S3.F3.23.1.m1.1.1.3.cmml" xref="S3.F3.23.1.m1.1.1.3">bg</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.23.1.m1.1d">x_{\mathrm{bg}}</annotation><annotation encoding="application/x-llamapun" id="S3.F3.23.1.m1.1e">italic_x start_POSTSUBSCRIPT roman_bg end_POSTSUBSCRIPT</annotation></semantics></math>, diffusion models can create artifacts when rendering (b) background <math alttext="f_{\theta}(\mathbf{i}_{\mathrm{bg}})" class="ltx_Math" display="inline" id="S3.F3.24.2.m2.1"><semantics id="S3.F3.24.2.m2.1b"><mrow id="S3.F3.24.2.m2.1.1" xref="S3.F3.24.2.m2.1.1.cmml"><msub id="S3.F3.24.2.m2.1.1.3" xref="S3.F3.24.2.m2.1.1.3.cmml"><mi id="S3.F3.24.2.m2.1.1.3.2" xref="S3.F3.24.2.m2.1.1.3.2.cmml">f</mi><mi id="S3.F3.24.2.m2.1.1.3.3" xref="S3.F3.24.2.m2.1.1.3.3.cmml">θ</mi></msub><mo id="S3.F3.24.2.m2.1.1.2" xref="S3.F3.24.2.m2.1.1.2.cmml">⁢</mo><mrow id="S3.F3.24.2.m2.1.1.1.1" xref="S3.F3.24.2.m2.1.1.1.1.1.cmml"><mo id="S3.F3.24.2.m2.1.1.1.1.2" stretchy="false" xref="S3.F3.24.2.m2.1.1.1.1.1.cmml">(</mo><msub id="S3.F3.24.2.m2.1.1.1.1.1" xref="S3.F3.24.2.m2.1.1.1.1.1.cmml"><mi id="S3.F3.24.2.m2.1.1.1.1.1.2" xref="S3.F3.24.2.m2.1.1.1.1.1.2.cmml">𝐢</mi><mi id="S3.F3.24.2.m2.1.1.1.1.1.3" xref="S3.F3.24.2.m2.1.1.1.1.1.3.cmml">bg</mi></msub><mo id="S3.F3.24.2.m2.1.1.1.1.3" stretchy="false" xref="S3.F3.24.2.m2.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.F3.24.2.m2.1c"><apply id="S3.F3.24.2.m2.1.1.cmml" xref="S3.F3.24.2.m2.1.1"><times id="S3.F3.24.2.m2.1.1.2.cmml" xref="S3.F3.24.2.m2.1.1.2"></times><apply id="S3.F3.24.2.m2.1.1.3.cmml" xref="S3.F3.24.2.m2.1.1.3"><csymbol cd="ambiguous" id="S3.F3.24.2.m2.1.1.3.1.cmml" xref="S3.F3.24.2.m2.1.1.3">subscript</csymbol><ci id="S3.F3.24.2.m2.1.1.3.2.cmml" xref="S3.F3.24.2.m2.1.1.3.2">𝑓</ci><ci id="S3.F3.24.2.m2.1.1.3.3.cmml" xref="S3.F3.24.2.m2.1.1.3.3">𝜃</ci></apply><apply id="S3.F3.24.2.m2.1.1.1.1.1.cmml" xref="S3.F3.24.2.m2.1.1.1.1"><csymbol cd="ambiguous" id="S3.F3.24.2.m2.1.1.1.1.1.1.cmml" xref="S3.F3.24.2.m2.1.1.1.1">subscript</csymbol><ci id="S3.F3.24.2.m2.1.1.1.1.1.2.cmml" xref="S3.F3.24.2.m2.1.1.1.1.1.2">𝐢</ci><ci id="S3.F3.24.2.m2.1.1.1.1.1.3.cmml" xref="S3.F3.24.2.m2.1.1.1.1.1.3">bg</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.24.2.m2.1d">f_{\theta}(\mathbf{i}_{\mathrm{bg}})</annotation><annotation encoding="application/x-llamapun" id="S3.F3.24.2.m2.1e">italic_f start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT ( bold_i start_POSTSUBSCRIPT roman_bg end_POSTSUBSCRIPT )</annotation></semantics></math> and (c) composite <math alttext="f_{\theta}(\mathbf{i}_{\mathrm{comp}})" class="ltx_Math" display="inline" id="S3.F3.25.3.m3.1"><semantics id="S3.F3.25.3.m3.1b"><mrow id="S3.F3.25.3.m3.1.1" xref="S3.F3.25.3.m3.1.1.cmml"><msub id="S3.F3.25.3.m3.1.1.3" xref="S3.F3.25.3.m3.1.1.3.cmml"><mi id="S3.F3.25.3.m3.1.1.3.2" xref="S3.F3.25.3.m3.1.1.3.2.cmml">f</mi><mi id="S3.F3.25.3.m3.1.1.3.3" xref="S3.F3.25.3.m3.1.1.3.3.cmml">θ</mi></msub><mo id="S3.F3.25.3.m3.1.1.2" xref="S3.F3.25.3.m3.1.1.2.cmml">⁢</mo><mrow id="S3.F3.25.3.m3.1.1.1.1" xref="S3.F3.25.3.m3.1.1.1.1.1.cmml"><mo id="S3.F3.25.3.m3.1.1.1.1.2" stretchy="false" xref="S3.F3.25.3.m3.1.1.1.1.1.cmml">(</mo><msub id="S3.F3.25.3.m3.1.1.1.1.1" xref="S3.F3.25.3.m3.1.1.1.1.1.cmml"><mi id="S3.F3.25.3.m3.1.1.1.1.1.2" xref="S3.F3.25.3.m3.1.1.1.1.1.2.cmml">𝐢</mi><mi id="S3.F3.25.3.m3.1.1.1.1.1.3" xref="S3.F3.25.3.m3.1.1.1.1.1.3.cmml">comp</mi></msub><mo id="S3.F3.25.3.m3.1.1.1.1.3" stretchy="false" xref="S3.F3.25.3.m3.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.F3.25.3.m3.1c"><apply id="S3.F3.25.3.m3.1.1.cmml" xref="S3.F3.25.3.m3.1.1"><times id="S3.F3.25.3.m3.1.1.2.cmml" xref="S3.F3.25.3.m3.1.1.2"></times><apply id="S3.F3.25.3.m3.1.1.3.cmml" xref="S3.F3.25.3.m3.1.1.3"><csymbol cd="ambiguous" id="S3.F3.25.3.m3.1.1.3.1.cmml" xref="S3.F3.25.3.m3.1.1.3">subscript</csymbol><ci id="S3.F3.25.3.m3.1.1.3.2.cmml" xref="S3.F3.25.3.m3.1.1.3.2">𝑓</ci><ci id="S3.F3.25.3.m3.1.1.3.3.cmml" xref="S3.F3.25.3.m3.1.1.3.3">𝜃</ci></apply><apply id="S3.F3.25.3.m3.1.1.1.1.1.cmml" xref="S3.F3.25.3.m3.1.1.1.1"><csymbol cd="ambiguous" id="S3.F3.25.3.m3.1.1.1.1.1.1.cmml" xref="S3.F3.25.3.m3.1.1.1.1">subscript</csymbol><ci id="S3.F3.25.3.m3.1.1.1.1.1.2.cmml" xref="S3.F3.25.3.m3.1.1.1.1.1.2">𝐢</ci><ci id="S3.F3.25.3.m3.1.1.1.1.1.3.cmml" xref="S3.F3.25.3.m3.1.1.1.1.1.3">comp</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.25.3.m3.1d">f_{\theta}(\mathbf{i}_{\mathrm{comp}})</annotation><annotation encoding="application/x-llamapun" id="S3.F3.25.3.m3.1e">italic_f start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT ( bold_i start_POSTSUBSCRIPT roman_comp end_POSTSUBSCRIPT )</annotation></semantics></math> intrinsics. To alleviate this, we compute (d) the shadow opacity ratio of predictions <math alttext="R" class="ltx_Math" display="inline" id="S3.F3.26.4.m4.1"><semantics id="S3.F3.26.4.m4.1b"><mi id="S3.F3.26.4.m4.1.1" xref="S3.F3.26.4.m4.1.1.cmml">R</mi><annotation-xml encoding="MathML-Content" id="S3.F3.26.4.m4.1c"><ci id="S3.F3.26.4.m4.1.1.cmml" xref="S3.F3.26.4.m4.1.1">𝑅</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.26.4.m4.1d">R</annotation><annotation encoding="application/x-llamapun" id="S3.F3.26.4.m4.1e">italic_R</annotation></semantics></math> and, together with (e) the object mask <math alttext="m" class="ltx_Math" display="inline" id="S3.F3.27.5.m5.1"><semantics id="S3.F3.27.5.m5.1b"><mi id="S3.F3.27.5.m5.1.1" xref="S3.F3.27.5.m5.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="S3.F3.27.5.m5.1c"><ci id="S3.F3.27.5.m5.1.1.cmml" xref="S3.F3.27.5.m5.1.1">𝑚</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.27.5.m5.1d">m</annotation><annotation encoding="application/x-llamapun" id="S3.F3.27.5.m5.1e">italic_m</annotation></semantics></math>, we can create (f) the final artifacts-free composite <math alttext="x" class="ltx_Math" display="inline" id="S3.F3.28.6.m6.1"><semantics id="S3.F3.28.6.m6.1b"><mi id="S3.F3.28.6.m6.1.1" xref="S3.F3.28.6.m6.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S3.F3.28.6.m6.1c"><ci id="S3.F3.28.6.m6.1.1.cmml" xref="S3.F3.28.6.m6.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.28.6.m6.1d">x</annotation><annotation encoding="application/x-llamapun" id="S3.F3.28.6.m6.1e">italic_x</annotation></semantics></math>. Please see the insets (top-right of each column) for a zoomed-in view of the artifacts created.</span></figcaption>
</figure>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Test dataset for 3D object compositing</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">Evaluating the quality of 3D object composites can be cumbersome, and performing a uniform evaluation of various methods such as lighting estimation, harmonization, or generative techniques is challenging. We require scenes where 1) the background is a real image with known HDR lighting, 2) the scene geometry is defined, 3) a virtual object is correctly positioned, and 4) a realistic rendering exists. Current evaluation datasets often lack some of these requirements: <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib12" title="">12</a>]</cite> lack object geometry, <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib23" title="">23</a>]</cite> does not include objects, <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib57" title="">57</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib44" title="">44</a>]</cite> use synthetic imagery, and 3D Copy-Paste <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib24" title="">24</a>]</cite> lacks ground truth HDR lighting. Inspired by <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib24" title="">24</a>]</cite>, we propose a simple method for automatically generating a dataset for evaluating 3D object compositing approaches.</p>
</div>
<div class="ltx_para" id="S4.p2">
<p class="ltx_p" id="S4.p2.2">Specifically, we leverage the test dataset provided by <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib72" title="">72</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib17" title="">17</a>]</cite>, which contains 2,240 images of <math alttext="50^{\circ}" class="ltx_Math" display="inline" id="S4.p2.1.m1.1"><semantics id="S4.p2.1.m1.1a"><msup id="S4.p2.1.m1.1.1" xref="S4.p2.1.m1.1.1.cmml"><mn id="S4.p2.1.m1.1.1.2" xref="S4.p2.1.m1.1.1.2.cmml">50</mn><mo id="S4.p2.1.m1.1.1.3" xref="S4.p2.1.m1.1.1.3.cmml">∘</mo></msup><annotation-xml encoding="MathML-Content" id="S4.p2.1.m1.1b"><apply id="S4.p2.1.m1.1.1.cmml" xref="S4.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S4.p2.1.m1.1.1.1.cmml" xref="S4.p2.1.m1.1.1">superscript</csymbol><cn id="S4.p2.1.m1.1.1.2.cmml" type="integer" xref="S4.p2.1.m1.1.1.2">50</cn><compose id="S4.p2.1.m1.1.1.3.cmml" xref="S4.p2.1.m1.1.1.3"></compose></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.1.m1.1c">50^{\circ}</annotation><annotation encoding="application/x-llamapun" id="S4.p2.1.m1.1d">50 start_POSTSUPERSCRIPT ∘ end_POSTSUPERSCRIPT</annotation></semantics></math> field of view, extracted from HDR environment maps in the Laval Indoor HDR Dataset <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib22" title="">22</a>]</cite>, and the result from several lighting estimation methods. For each image, we first find a suitable location to insert a virtual object by computing normals using DSINE <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib2" title="">2</a>]</cite> on each crop. We detect a support region by selecting normals with an angle less than <math alttext="15^{\circ}" class="ltx_Math" display="inline" id="S4.p2.2.m2.1"><semantics id="S4.p2.2.m2.1a"><msup id="S4.p2.2.m2.1.1" xref="S4.p2.2.m2.1.1.cmml"><mn id="S4.p2.2.m2.1.1.2" xref="S4.p2.2.m2.1.1.2.cmml">15</mn><mo id="S4.p2.2.m2.1.1.3" xref="S4.p2.2.m2.1.1.3.cmml">∘</mo></msup><annotation-xml encoding="MathML-Content" id="S4.p2.2.m2.1b"><apply id="S4.p2.2.m2.1.1.cmml" xref="S4.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S4.p2.2.m2.1.1.1.cmml" xref="S4.p2.2.m2.1.1">superscript</csymbol><cn id="S4.p2.2.m2.1.1.2.cmml" type="integer" xref="S4.p2.2.m2.1.1.2">15</cn><compose id="S4.p2.2.m2.1.1.3.cmml" xref="S4.p2.2.m2.1.1.3"></compose></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.2.m2.1c">15^{\circ}</annotation><annotation encoding="application/x-llamapun" id="S4.p2.2.m2.1d">15 start_POSTSUPERSCRIPT ∘ end_POSTSUPERSCRIPT</annotation></semantics></math> with the up vector. Images with support regions too small (defined as not fitting a circle of 75 pixels radius) are discarded, resulting in 228 admissible background crops.
Next, a 3D object is chosen at random from the ABO dataset <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib15" title="">15</a>]</cite> and randomly rotated about its vertical axis. The object is scaled to fit its footprint in the support region, ensuring its bounding box is entirely within the camera frustum. Four random objects are rendered for each image, and those with inconsistent geometry, semantics, or unrealistic albedo are discarded, resulting in a total of 213 high-quality images.</p>
</div>
<div class="ltx_para" id="S4.p3">
<p class="ltx_p" id="S4.p3.1">Finally, we render the object using physically based rendering in Blender <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib16" title="">16</a>]</cite>. To account for spatially-varying indoor lighting, we warp the panorama by converting it to a 3D mesh according to its depth map from <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib56" title="">56</a>]</cite>, and reproject it at the center of the object’s bounding box. This approach provides high-quality simulated ground truth, enabling the generation of many more scenes than the 20 available in <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib23" title="">23</a>]</cite>. The last column of <a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#S4.F4" title="In 4 Test dataset for 3D object compositing ‣ ZeroComp: Zero-shot Object Compositing from Image Intrinsics via Diffusion"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">4</span></a> shows a representative subset of realistic image composites. This dataset will be released publicly upon publication of the paper.</p>
</div>
<figure class="ltx_figure" id="S4.F4">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S4.F4.35">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.F4.7.7">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.F4.1.1.1" style="padding:-3pt 0.3pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="96" id="S4.F4.1.1.1.g1" src="extracted/5908513/figures/images_sorted_by_op_v1_1.0_objdepth_PSNR/9C4A0370-2d21311d85_02_crop_B075QDTYGK_bg.jpg" width="96"/></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.F4.2.2.2" style="padding:-3pt 0.3pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="96" id="S4.F4.2.2.2.g1" src="extracted/5908513/figures/images_sorted_by_op_v1_1.0_objdepth_PSNR/garon2019fast/9C4A0370-2d21311d85_02_crop_B075QDTYGK.jpg" width="96"/></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.F4.3.3.3" style="padding:-3pt 0.3pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="96" id="S4.F4.3.3.3.g1" src="extracted/5908513/figures/images_sorted_by_op_v1_1.0_objdepth_PSNR/zhan2021emlight/9C4A0370-2d21311d85_02_crop_B075QDTYGK.jpg" width="96"/></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.F4.4.4.4" style="padding:-3pt 0.3pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="96" id="S4.F4.4.4.4.g1" src="extracted/5908513/figures/images_sorted_by_op_v1_1.0_objdepth_PSNR/arshadowgan20/9C4A0370-2d21311d85_02_crop_B075QDTYGK.jpg" width="96"/></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.F4.5.5.5" style="padding:-3pt 0.3pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="96" id="S4.F4.5.5.5.g1" src="extracted/5908513/figures/images_sorted_by_op_v1_1.0_objdepth_PSNR/controlcom23/9C4A0370-2d21311d85_02_crop_B075QDTYGK.jpg" width="96"/></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.F4.6.6.6" style="padding:-3pt 0.3pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="96" id="S4.F4.6.6.6.g1" src="extracted/5908513/figures/images_sorted_by_op_v1_1.0_objdepth_PSNR/op_v1_1.0_objdepth/9C4A0370-2d21311d85_02_crop_B075QDTYGK.jpg" width="96"/></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.F4.7.7.7" style="padding:-3pt 0.3pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="96" id="S4.F4.7.7.7.g1" src="extracted/5908513/figures/images_sorted_by_op_v1_1.0_objdepth_PSNR/GT_emission_envmap/9C4A0370-2d21311d85_02_crop_B075QDTYGK.jpg" width="96"/></td>
</tr>
<tr class="ltx_tr" id="S4.F4.14.14">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.F4.8.8.1" style="padding:-3pt 0.3pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="96" id="S4.F4.8.8.1.g1" src="extracted/5908513/figures/images_sorted_by_op_v1_1.0_objdepth_PSNR/AG8A4408-86aa88feb2_00_crop_B07Q2PGH2P_bg.jpg" width="96"/></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.F4.9.9.2" style="padding:-3pt 0.3pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="96" id="S4.F4.9.9.2.g1" src="extracted/5908513/figures/images_sorted_by_op_v1_1.0_objdepth_PSNR/garon2019fast/AG8A4408-86aa88feb2_00_crop_B07Q2PGH2P.jpg" width="96"/></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.F4.10.10.3" style="padding:-3pt 0.3pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="96" id="S4.F4.10.10.3.g1" src="extracted/5908513/figures/images_sorted_by_op_v1_1.0_objdepth_PSNR/zhan2021emlight/AG8A4408-86aa88feb2_00_crop_B07Q2PGH2P.jpg" width="96"/></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.F4.11.11.4" style="padding:-3pt 0.3pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="96" id="S4.F4.11.11.4.g1" src="extracted/5908513/figures/images_sorted_by_op_v1_1.0_objdepth_PSNR/arshadowgan20/AG8A4408-86aa88feb2_00_crop_B07Q2PGH2P.jpg" width="96"/></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.F4.12.12.5" style="padding:-3pt 0.3pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="96" id="S4.F4.12.12.5.g1" src="extracted/5908513/figures/images_sorted_by_op_v1_1.0_objdepth_PSNR/controlcom23/AG8A4408-86aa88feb2_00_crop_B07Q2PGH2P.jpg" width="96"/></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.F4.13.13.6" style="padding:-3pt 0.3pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="96" id="S4.F4.13.13.6.g1" src="extracted/5908513/figures/images_sorted_by_op_v1_1.0_objdepth_PSNR/op_v1_1.0_objdepth/AG8A4408-86aa88feb2_00_crop_B07Q2PGH2P.jpg" width="96"/></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.F4.14.14.7" style="padding:-3pt 0.3pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="96" id="S4.F4.14.14.7.g1" src="extracted/5908513/figures/images_sorted_by_op_v1_1.0_objdepth_PSNR/GT_emission_envmap/AG8A4408-86aa88feb2_00_crop_B07Q2PGH2P.jpg" width="96"/></td>
</tr>
<tr class="ltx_tr" id="S4.F4.21.21">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.F4.15.15.1" style="padding:-3pt 0.3pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="96" id="S4.F4.15.15.1.g1" src="extracted/5908513/figures/images_sorted_by_op_v1_1.0_objdepth_PSNR/9C4A8088-1bb62eeb83_04_crop_B082VLTCM4_bg.jpg" width="96"/></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.F4.16.16.2" style="padding:-3pt 0.3pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="96" id="S4.F4.16.16.2.g1" src="extracted/5908513/figures/images_sorted_by_op_v1_1.0_objdepth_PSNR/garon2019fast/9C4A8088-1bb62eeb83_04_crop_B082VLTCM4.jpg" width="96"/></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.F4.17.17.3" style="padding:-3pt 0.3pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="96" id="S4.F4.17.17.3.g1" src="extracted/5908513/figures/images_sorted_by_op_v1_1.0_objdepth_PSNR/zhan2021emlight/9C4A8088-1bb62eeb83_04_crop_B082VLTCM4.jpg" width="96"/></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.F4.18.18.4" style="padding:-3pt 0.3pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="96" id="S4.F4.18.18.4.g1" src="extracted/5908513/figures/images_sorted_by_op_v1_1.0_objdepth_PSNR/arshadowgan20/9C4A8088-1bb62eeb83_04_crop_B082VLTCM4.jpg" width="96"/></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.F4.19.19.5" style="padding:-3pt 0.3pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="96" id="S4.F4.19.19.5.g1" src="extracted/5908513/figures/images_sorted_by_op_v1_1.0_objdepth_PSNR/controlcom23/9C4A8088-1bb62eeb83_04_crop_B082VLTCM4.jpg" width="96"/></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.F4.20.20.6" style="padding:-3pt 0.3pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="96" id="S4.F4.20.20.6.g1" src="extracted/5908513/figures/images_sorted_by_op_v1_1.0_objdepth_PSNR/op_v1_1.0_objdepth/9C4A8088-1bb62eeb83_04_crop_B082VLTCM4.jpg" width="96"/></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.F4.21.21.7" style="padding:-3pt 0.3pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="96" id="S4.F4.21.21.7.g1" src="extracted/5908513/figures/images_sorted_by_op_v1_1.0_objdepth_PSNR/GT_emission_envmap/9C4A8088-1bb62eeb83_04_crop_B082VLTCM4.jpg" width="96"/></td>
</tr>
<tr class="ltx_tr" id="S4.F4.28.28">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.F4.22.22.1" style="padding:-3pt 0.3pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="96" id="S4.F4.22.22.1.g1" src="extracted/5908513/figures/images_sorted_by_op_v1_1.0_objdepth_PSNR/AG8A4702-1a77809d2c_01_crop_B07DBHFDSQ_bg.jpg" width="96"/></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.F4.23.23.2" style="padding:-3pt 0.3pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="96" id="S4.F4.23.23.2.g1" src="extracted/5908513/figures/images_sorted_by_op_v1_1.0_objdepth_PSNR/garon2019fast/AG8A4702-1a77809d2c_01_crop_B07DBHFDSQ.jpg" width="96"/></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.F4.24.24.3" style="padding:-3pt 0.3pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="96" id="S4.F4.24.24.3.g1" src="extracted/5908513/figures/images_sorted_by_op_v1_1.0_objdepth_PSNR/zhan2021emlight/AG8A4702-1a77809d2c_01_crop_B07DBHFDSQ.jpg" width="96"/></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.F4.25.25.4" style="padding:-3pt 0.3pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="96" id="S4.F4.25.25.4.g1" src="extracted/5908513/figures/images_sorted_by_op_v1_1.0_objdepth_PSNR/arshadowgan20/AG8A4702-1a77809d2c_01_crop_B07DBHFDSQ.jpg" width="96"/></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.F4.26.26.5" style="padding:-3pt 0.3pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="96" id="S4.F4.26.26.5.g1" src="extracted/5908513/figures/images_sorted_by_op_v1_1.0_objdepth_PSNR/controlcom23/AG8A4702-1a77809d2c_01_crop_B07DBHFDSQ.jpg" width="96"/></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.F4.27.27.6" style="padding:-3pt 0.3pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="96" id="S4.F4.27.27.6.g1" src="extracted/5908513/figures/images_sorted_by_op_v1_1.0_objdepth_PSNR/op_v1_1.0_objdepth/AG8A4702-1a77809d2c_01_crop_B07DBHFDSQ.jpg" width="96"/></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.F4.28.28.7" style="padding:-3pt 0.3pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="96" id="S4.F4.28.28.7.g1" src="extracted/5908513/figures/images_sorted_by_op_v1_1.0_objdepth_PSNR/GT_emission_envmap/AG8A4702-1a77809d2c_01_crop_B07DBHFDSQ.jpg" width="96"/></td>
</tr>
<tr class="ltx_tr" id="S4.F4.35.35">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.F4.29.29.1" style="padding:-3pt 0.3pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="96" id="S4.F4.29.29.1.g1" src="extracted/5908513/figures/images_sorted_by_op_v1_1.0_objdepth_PSNR/9C4A0608-306f35cf54_00_crop_B0871D4XPB_bg.jpg" width="96"/></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.F4.30.30.2" style="padding:-3pt 0.3pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="96" id="S4.F4.30.30.2.g1" src="extracted/5908513/figures/images_sorted_by_op_v1_1.0_objdepth_PSNR/garon2019fast/9C4A0608-306f35cf54_00_crop_B0871D4XPB.jpg" width="96"/></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.F4.31.31.3" style="padding:-3pt 0.3pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="96" id="S4.F4.31.31.3.g1" src="extracted/5908513/figures/images_sorted_by_op_v1_1.0_objdepth_PSNR/zhan2021emlight/9C4A0608-306f35cf54_00_crop_B0871D4XPB.jpg" width="96"/></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.F4.32.32.4" style="padding:-3pt 0.3pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="96" id="S4.F4.32.32.4.g1" src="extracted/5908513/figures/images_sorted_by_op_v1_1.0_objdepth_PSNR/arshadowgan20/9C4A0608-306f35cf54_00_crop_B0871D4XPB.jpg" width="96"/></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.F4.33.33.5" style="padding:-3pt 0.3pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="96" id="S4.F4.33.33.5.g1" src="extracted/5908513/figures/images_sorted_by_op_v1_1.0_objdepth_PSNR/controlcom23/9C4A0608-306f35cf54_00_crop_B0871D4XPB.jpg" width="96"/></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.F4.34.34.6" style="padding:-3pt 0.3pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="96" id="S4.F4.34.34.6.g1" src="extracted/5908513/figures/images_sorted_by_op_v1_1.0_objdepth_PSNR/op_v1_1.0_objdepth/9C4A0608-306f35cf54_00_crop_B0871D4XPB.jpg" width="96"/></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.F4.35.35.7" style="padding:-3pt 0.3pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="96" id="S4.F4.35.35.7.g1" src="extracted/5908513/figures/images_sorted_by_op_v1_1.0_objdepth_PSNR/GT_emission_envmap/9C4A0608-306f35cf54_00_crop_B0871D4XPB.jpg" width="96"/></td>
</tr>
<tr class="ltx_tr" id="S4.F4.35.36.1">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.F4.35.36.1.1" style="padding:-3pt 0.3pt;"><span class="ltx_text" id="S4.F4.35.36.1.1.1" style="font-size:80%;">Background</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.F4.35.36.1.2" style="padding:-3pt 0.3pt;">
<span class="ltx_text" id="S4.F4.35.36.1.2.1" style="font-size:80%;">Garon’19 </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S4.F4.35.36.1.2.2.1" style="font-size:80%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib23" title="">23</a><span class="ltx_text" id="S4.F4.35.36.1.2.3.2" style="font-size:80%;">]</span></cite>
</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.F4.35.36.1.3" style="padding:-3pt 0.3pt;">
<span class="ltx_text" id="S4.F4.35.36.1.3.1" style="font-size:80%;">EMLight </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S4.F4.35.36.1.3.2.1" style="font-size:80%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib84" title="">84</a><span class="ltx_text" id="S4.F4.35.36.1.3.3.2" style="font-size:80%;">]</span></cite>
</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.F4.35.36.1.4" style="padding:-3pt 0.3pt;">
<span class="ltx_text" id="S4.F4.35.36.1.4.1" style="font-size:80%;">ARShadowGAN </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S4.F4.35.36.1.4.2.1" style="font-size:80%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib46" title="">46</a><span class="ltx_text" id="S4.F4.35.36.1.4.3.2" style="font-size:80%;">]</span></cite>
</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.F4.35.36.1.5" style="padding:-3pt 0.3pt;">
<span class="ltx_text" id="S4.F4.35.36.1.5.1" style="font-size:80%;">ControlCom </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S4.F4.35.36.1.5.2.1" style="font-size:80%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib85" title="">85</a><span class="ltx_text" id="S4.F4.35.36.1.5.3.2" style="font-size:80%;">]</span></cite>
</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.F4.35.36.1.6" style="padding:-3pt 0.3pt;"><span class="ltx_text" id="S4.F4.35.36.1.6.1" style="font-size:80%;">Ours</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.F4.35.36.1.7" style="padding:-3pt 0.3pt;"><span class="ltx_text" id="S4.F4.35.36.1.7.1" style="font-size:80%;">Simulated GT</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:80%;"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F4.41.1.1" style="font-size:113%;">Figure 4</span>: </span><span class="ltx_text" id="S4.F4.42.2" style="font-size:113%;">Qualitative comparison with lighting estimation and image-based methods. Results are sorted from worst (top) to best (bottom) PSNR for “Ours”. Please zoom in and refer to the <span class="ltx_text ltx_font_bold" id="S4.F4.42.2.1">supplementary material</span> for additional images and methods.</span></figcaption>
</figure>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Evaluation</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">In this section, we conduct a comprehensive evaluation of <span class="ltx_text ltx_font_smallcaps" id="S5.p1.1.1">ZeroComp</span>’s performance as a neural renderer for zero-shot compositing. Leveraging the evaluation dataset introduced in <a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#S4" title="4 Test dataset for 3D object compositing ‣ ZeroComp: Zero-shot Object Compositing from Image Intrinsics via Diffusion"><span class="ltx_text ltx_ref_tag">Sec.</span> <span class="ltx_text ltx_ref_tag">4</span></a>, we quantitatively and qualitatively compare against state-of-the-art methods on a range of metrics to offer a multi-faceted assessment of image quality. We use standard metrics to compare composites with the simulated ground truth, including Peak Signal-to-Noise Ratio (PSNR), Root Mean Square Error (RMSE) and its scale-invariant version (si-RMSE), Mean Absolute Difference (MAE), Structural Similarity Index Measure (SSIM) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib71" title="">71</a>]</cite>, Learned Perceptual Image Patch Similarity (LPIPS) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib87" title="">87</a>]</cite>, and FLIP <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib1" title="">1</a>]</cite>. While we agree that perceptual metrics are better suited for our task, several researchers <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib28" title="">28</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib35" title="">35</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib26" title="">26</a>]</cite> highlight the vulnerability of neural network-based metrics like LPIPS to noise and adversarial attacks. To mitigate the influence of the rendering noise present in the training datasets <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib44" title="">44</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib91" title="">91</a>]</cite>, we resize both the test images and references to <math alttext="256\times 256" class="ltx_Math" display="inline" id="S5.p1.1.m1.1"><semantics id="S5.p1.1.m1.1a"><mrow id="S5.p1.1.m1.1.1" xref="S5.p1.1.m1.1.1.cmml"><mn id="S5.p1.1.m1.1.1.2" xref="S5.p1.1.m1.1.1.2.cmml">256</mn><mo id="S5.p1.1.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="S5.p1.1.m1.1.1.1.cmml">×</mo><mn id="S5.p1.1.m1.1.1.3" xref="S5.p1.1.m1.1.1.3.cmml">256</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.p1.1.m1.1b"><apply id="S5.p1.1.m1.1.1.cmml" xref="S5.p1.1.m1.1.1"><times id="S5.p1.1.m1.1.1.1.cmml" xref="S5.p1.1.m1.1.1.1"></times><cn id="S5.p1.1.m1.1.1.2.cmml" type="integer" xref="S5.p1.1.m1.1.1.2">256</cn><cn id="S5.p1.1.m1.1.1.3.cmml" type="integer" xref="S5.p1.1.m1.1.1.3">256</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p1.1.m1.1c">256\times 256</annotation><annotation encoding="application/x-llamapun" id="S5.p1.1.m1.1d">256 × 256</annotation></semantics></math> for all methods on LPIPS. Additionally, FLIP addresses this issue by applying a spatial filter removing high frequency details imperceptible to humans. During evaluation, we demonstrate that our approach achieves performance comparable to most lighting estimation methods, all without explicitly modeling lighting conditions. We also contrast our method with diffusion and intrinsic image-based baselines <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib12" title="">12</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib85" title="">85</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib11" title="">11</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib46" title="">46</a>]</cite>, showcasing superiority on most metrics.</p>
</div>
<div class="ltx_para" id="S5.p2">
<p class="ltx_p" id="S5.p2.1">Given that recent research shows that quantitative metrics do not correlate well with human perception <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib81" title="">81</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib27" title="">27</a>]</cite>, we also conduct a human perceptual study, revealing a clear improvement over all other methods. This highlights <span class="ltx_text ltx_font_smallcaps" id="S5.p2.1.1">ZeroComp</span>’s ability to produce perceptually plausible results. Finally, we showcase its extensions to material editing, outdoor scenes, and real-world 2D images.</p>
</div>
<section class="ltx_subsection" id="S5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Lighting estimation method comparison</h3>
<div class="ltx_para" id="S5.SS1.p1">
<p class="ltx_p" id="S5.SS1.p1.1">Traditional lighting-based compositing methods set the benchmark by estimating scene lighting for realistic 3D object insertion. These methods use a full 3D object, a delicately curated model for shadow casting, a physically-based rendering engine, and a suitable lighting representation (e.g., parametric lights<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib22" title="">22</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib21" title="">21</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib72" title="">72</a>]</cite>, spherical functions <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib23" title="">23</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib84" title="">84</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib17" title="">17</a>]</cite>, etc.). For optimal results, everything must be perfectly aligned.
In contrast, <span class="ltx_text ltx_font_smallcaps" id="S5.SS1.p1.1.1">ZeroComp</span> only requires placing the object in 2D, generating intrinsics using simple shaders (depth, normals, and albedo), and relies on the network understanding to infer missing information. Despite the task is more challenging, <span class="ltx_text ltx_font_smallcaps" id="S5.SS1.p1.1.2">ZeroComp</span> achieves competitive results, surpassing many explicit lighting-based techniques <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib22" title="">22</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib70" title="">70</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib72" title="">72</a>]</cite>, as shown in <a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#S5.T1" title="In 5.1 Lighting estimation method comparison ‣ 5 Evaluation ‣ ZeroComp: Zero-shot Object Compositing from Image Intrinsics via Diffusion"><span class="ltx_text ltx_ref_tag">Tab.</span> <span class="ltx_text ltx_ref_tag">1</span></a>. Qualitative comparisons in <a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#S4.F4" title="In 4 Test dataset for 3D object compositing ‣ ZeroComp: Zero-shot Object Compositing from Image Intrinsics via Diffusion"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">4</span></a> show that <span class="ltx_text ltx_font_smallcaps" id="S5.SS1.p1.1.3">ZeroComp</span> realistically shades these objects while maintaining their appearance, acting as a strong contender to traditional approaches.</p>
</div>
<figure class="ltx_table" id="S5.T1">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S5.T1.7" style="width:216.8pt;height:156pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-66.7pt,48.0pt) scale(0.619008510154819,0.619008510154819) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S5.T1.7.7">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T1.7.7.7">
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_th ltx_th_row ltx_border_tt" id="S5.T1.7.7.7.8" style="padding-left:1.0pt;padding-right:1.0pt;"></th>
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row ltx_border_tt" id="S5.T1.7.7.7.9" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text" id="S5.T1.7.7.7.9.1" style="font-size:80%;">Method</span></th>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_tt" id="S5.T1.1.1.1.1" style="padding-left:1.0pt;padding-right:1.0pt;">
<span class="ltx_text" id="S5.T1.1.1.1.1.1" style="font-size:80%;">PSNR</span><sub class="ltx_sub" id="S5.T1.1.1.1.1.2"><span class="ltx_text" id="S5.T1.1.1.1.1.2.1" style="font-size:80%;">↑</span></sub>
</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_tt" id="S5.T1.2.2.2.2" style="padding-left:1.0pt;padding-right:1.0pt;">
<span class="ltx_text" id="S5.T1.2.2.2.2.1" style="font-size:80%;">RMSE</span><sub class="ltx_sub" id="S5.T1.2.2.2.2.2"><span class="ltx_text" id="S5.T1.2.2.2.2.2.1" style="font-size:80%;">↓</span></sub>
</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_tt" id="S5.T1.3.3.3.3" style="padding-left:1.0pt;padding-right:1.0pt;">
<span class="ltx_text" id="S5.T1.3.3.3.3.1" style="font-size:80%;">si-RMSE</span><sub class="ltx_sub" id="S5.T1.3.3.3.3.2"><span class="ltx_text" id="S5.T1.3.3.3.3.2.1" style="font-size:80%;">↓</span></sub>
</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_tt" id="S5.T1.4.4.4.4" style="padding-left:1.0pt;padding-right:1.0pt;">
<span class="ltx_text" id="S5.T1.4.4.4.4.1" style="font-size:80%;">SSIM</span><sub class="ltx_sub" id="S5.T1.4.4.4.4.2"><span class="ltx_text" id="S5.T1.4.4.4.4.2.1" style="font-size:80%;">↑</span></sub>
</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_tt" id="S5.T1.5.5.5.5" style="padding-left:1.0pt;padding-right:1.0pt;">
<span class="ltx_text" id="S5.T1.5.5.5.5.1" style="font-size:80%;">MAE</span><sub class="ltx_sub" id="S5.T1.5.5.5.5.2"><span class="ltx_text" id="S5.T1.5.5.5.5.2.1" style="font-size:80%;">↓</span></sub>
</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_tt" id="S5.T1.6.6.6.6" style="padding-left:1.0pt;padding-right:1.0pt;">
<span class="ltx_text" id="S5.T1.6.6.6.6.1" style="font-size:80%;">LPIPS</span><sub class="ltx_sub" id="S5.T1.6.6.6.6.2"><span class="ltx_text" id="S5.T1.6.6.6.6.2.1" style="font-size:80%;">↓</span></sub>
</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_tt" id="S5.T1.7.7.7.7" style="padding-left:1.0pt;padding-right:1.0pt;">
<span class="ltx_text" id="S5.T1.7.7.7.7.1" style="font-size:80%;">FLIP</span><sub class="ltx_sub" id="S5.T1.7.7.7.7.2"><span class="ltx_text" id="S5.T1.7.7.7.7.2.1" style="font-size:80%;">↓</span></sub>
</td>
</tr>
<tr class="ltx_tr" id="S5.T1.7.7.8.1">
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S5.T1.7.7.8.1.1" rowspan="7" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text" id="S5.T1.7.7.8.1.1.1" style="font-size:80%;">
<span class="ltx_inline-block ltx_transformed_outer" id="S5.T1.7.7.8.1.1.1.1" style="width:6.2pt;height:45.1pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="width:45.1pt;transform:translate(-19.42pt,-18.73pt) rotate(-90deg) ;">
<span class="ltx_p" id="S5.T1.7.7.8.1.1.1.1.1"><span class="ltx_text" id="S5.T1.7.7.8.1.1.1.1.1.1" style="font-size:88%;">Lighting-based</span></span>
</span></span></span></th>
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S5.T1.7.7.8.1.2" style="padding-left:1.0pt;padding-right:1.0pt;">
<span class="ltx_text" id="S5.T1.7.7.8.1.2.1" style="font-size:80%;">Gardner’17 </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S5.T1.7.7.8.1.2.2.1" style="font-size:80%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib22" title="">22</a><span class="ltx_text" id="S5.T1.7.7.8.1.2.3.2" style="font-size:80%;">]</span></cite>
</th>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T1.7.7.8.1.3" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text" id="S5.T1.7.7.8.1.3.1" style="font-size:80%;">25.9</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T1.7.7.8.1.4" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text" id="S5.T1.7.7.8.1.4.1" style="font-size:80%;">0.0677</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T1.7.7.8.1.5" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text" id="S5.T1.7.7.8.1.5.1" style="font-size:80%;">0.0606</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T1.7.7.8.1.6" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text" id="S5.T1.7.7.8.1.6.1" style="font-size:80%;">0.967</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T1.7.7.8.1.7" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text" id="S5.T1.7.7.8.1.7.1" style="font-size:80%;">0.0211</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T1.7.7.8.1.8" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text" id="S5.T1.7.7.8.1.8.1" style="font-size:80%;">0.0331</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T1.7.7.8.1.9" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text" id="S5.T1.7.7.8.1.9.1" style="font-size:80%;">0.0664</span></td>
</tr>
<tr class="ltx_tr" id="S5.T1.7.7.9.2">
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row" id="S5.T1.7.7.9.2.1" style="padding-left:1.0pt;padding-right:1.0pt;">
<span class="ltx_text" id="S5.T1.7.7.9.2.1.1" style="font-size:80%;">Garon’19 </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S5.T1.7.7.9.2.1.2.1" style="font-size:80%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib23" title="">23</a><span class="ltx_text" id="S5.T1.7.7.9.2.1.3.2" style="font-size:80%;">]</span></cite>
</th>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T1.7.7.9.2.2" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text" id="S5.T1.7.7.9.2.2.1" style="font-size:80%;">34.2</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T1.7.7.9.2.3" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text" id="S5.T1.7.7.9.2.3.1" style="font-size:80%;">0.0256</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T1.7.7.9.2.4" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text" id="S5.T1.7.7.9.2.4.1" style="font-size:80%;">0.0251</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T1.7.7.9.2.5" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text" id="S5.T1.7.7.9.2.5.1" style="font-size:80%;">0.986</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T1.7.7.9.2.6" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text" id="S5.T1.7.7.9.2.6.1" style="font-size:80%;">0.0089</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T1.7.7.9.2.7" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text" id="S5.T1.7.7.9.2.7.1" style="font-size:80%;">0.0175</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T1.7.7.9.2.8" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text" id="S5.T1.7.7.9.2.8.1" style="font-size:80%;">0.0440</span></td>
</tr>
<tr class="ltx_tr" id="S5.T1.7.7.10.3">
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row" id="S5.T1.7.7.10.3.1" style="padding-left:1.0pt;padding-right:1.0pt;">
<span class="ltx_text" id="S5.T1.7.7.10.3.1.1" style="font-size:80%;">Gardner’19 </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S5.T1.7.7.10.3.1.2.1" style="font-size:80%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib21" title="">21</a><span class="ltx_text" id="S5.T1.7.7.10.3.1.3.2" style="font-size:80%;">]</span></cite>
</th>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T1.7.7.10.3.2" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text" id="S5.T1.7.7.10.3.2.1" style="font-size:80%;">32.3</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T1.7.7.10.3.3" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text" id="S5.T1.7.7.10.3.3.1" style="font-size:80%;">0.0293</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T1.7.7.10.3.4" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text" id="S5.T1.7.7.10.3.4.1" style="font-size:80%;">0.0281</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T1.7.7.10.3.5" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text" id="S5.T1.7.7.10.3.5.1" style="font-size:80%;">0.984</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T1.7.7.10.3.6" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text" id="S5.T1.7.7.10.3.6.1" style="font-size:80%;">0.0091</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T1.7.7.10.3.7" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text" id="S5.T1.7.7.10.3.7.1" style="font-size:80%;">0.0211</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T1.7.7.10.3.8" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text" id="S5.T1.7.7.10.3.8.1" style="font-size:80%;">0.0450</span></td>
</tr>
<tr class="ltx_tr" id="S5.T1.7.7.11.4">
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row" id="S5.T1.7.7.11.4.1" style="padding-left:1.0pt;padding-right:1.0pt;">
<span class="ltx_text" id="S5.T1.7.7.11.4.1.1" style="font-size:80%;">Everlight </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S5.T1.7.7.11.4.1.2.1" style="font-size:80%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib17" title="">17</a><span class="ltx_text" id="S5.T1.7.7.11.4.1.3.2" style="font-size:80%;">]</span></cite>
</th>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T1.7.7.11.4.2" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text" id="S5.T1.7.7.11.4.2.1" style="font-size:80%;">33.3</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T1.7.7.11.4.3" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text" id="S5.T1.7.7.11.4.3.1" style="font-size:80%;">0.0290</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T1.7.7.11.4.4" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text" id="S5.T1.7.7.11.4.4.1" style="font-size:80%;">0.0285</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T1.7.7.11.4.5" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text" id="S5.T1.7.7.11.4.5.1" style="font-size:80%;">0.982</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T1.7.7.11.4.6" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text" id="S5.T1.7.7.11.4.6.1" style="font-size:80%;">0.0102</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T1.7.7.11.4.7" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text" id="S5.T1.7.7.11.4.7.1" style="font-size:80%;">0.0184</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T1.7.7.11.4.8" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text" id="S5.T1.7.7.11.4.8.1" style="font-size:80%;">0.0462</span></td>
</tr>
<tr class="ltx_tr" id="S5.T1.7.7.12.5">
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row" id="S5.T1.7.7.12.5.1" style="padding-left:1.0pt;padding-right:1.0pt;">
<span class="ltx_text" id="S5.T1.7.7.12.5.1.1" style="font-size:80%;">StyleLight </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S5.T1.7.7.12.5.1.2.1" style="font-size:80%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib70" title="">70</a><span class="ltx_text" id="S5.T1.7.7.12.5.1.3.2" style="font-size:80%;">]</span></cite>
</th>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T1.7.7.12.5.2" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text" id="S5.T1.7.7.12.5.2.1" style="font-size:80%;">29.3</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T1.7.7.12.5.3" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text" id="S5.T1.7.7.12.5.3.1" style="font-size:80%;">0.0416</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T1.7.7.12.5.4" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text" id="S5.T1.7.7.12.5.4.1" style="font-size:80%;">0.0399</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T1.7.7.12.5.5" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text" id="S5.T1.7.7.12.5.5.1" style="font-size:80%;">0.976</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T1.7.7.12.5.6" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text" id="S5.T1.7.7.12.5.6.1" style="font-size:80%;">0.0139</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T1.7.7.12.5.7" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text" id="S5.T1.7.7.12.5.7.1" style="font-size:80%;">0.0287</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T1.7.7.12.5.8" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text" id="S5.T1.7.7.12.5.8.1" style="font-size:80%;">0.0580</span></td>
</tr>
<tr class="ltx_tr" id="S5.T1.7.7.13.6">
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row" id="S5.T1.7.7.13.6.1" style="padding-left:1.0pt;padding-right:1.0pt;">
<span class="ltx_text" id="S5.T1.7.7.13.6.1.1" style="font-size:80%;">Weber’22 </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S5.T1.7.7.13.6.1.2.1" style="font-size:80%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib72" title="">72</a><span class="ltx_text" id="S5.T1.7.7.13.6.1.3.2" style="font-size:80%;">]</span></cite>
</th>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T1.7.7.13.6.2" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text" id="S5.T1.7.7.13.6.2.1" style="font-size:80%;">29.6</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T1.7.7.13.6.3" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text" id="S5.T1.7.7.13.6.3.1" style="font-size:80%;">0.0403</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T1.7.7.13.6.4" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text" id="S5.T1.7.7.13.6.4.1" style="font-size:80%;">0.0380</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T1.7.7.13.6.5" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text" id="S5.T1.7.7.13.6.5.1" style="font-size:80%;">0.980</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T1.7.7.13.6.6" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text" id="S5.T1.7.7.13.6.6.1" style="font-size:80%;">0.0130</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T1.7.7.13.6.7" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text" id="S5.T1.7.7.13.6.7.1" style="font-size:80%;">0.0239</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T1.7.7.13.6.8" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text" id="S5.T1.7.7.13.6.8.1" style="font-size:80%;">0.0556</span></td>
</tr>
<tr class="ltx_tr" id="S5.T1.7.7.14.7">
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row" id="S5.T1.7.7.14.7.1" style="padding-left:1.0pt;padding-right:1.0pt;">
<span class="ltx_text" id="S5.T1.7.7.14.7.1.1" style="font-size:80%;">EMLight </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S5.T1.7.7.14.7.1.2.1" style="font-size:80%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib84" title="">84</a><span class="ltx_text" id="S5.T1.7.7.14.7.1.3.2" style="font-size:80%;">]</span></cite>
</th>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T1.7.7.14.7.2" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text" id="S5.T1.7.7.14.7.2.1" style="font-size:80%;">32.7</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T1.7.7.14.7.3" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text" id="S5.T1.7.7.14.7.3.1" style="font-size:80%;">0.0301</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T1.7.7.14.7.4" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text" id="S5.T1.7.7.14.7.4.1" style="font-size:80%;">0.0297</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T1.7.7.14.7.5" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text" id="S5.T1.7.7.14.7.5.1" style="font-size:80%;">0.981</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T1.7.7.14.7.6" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text" id="S5.T1.7.7.14.7.6.1" style="font-size:80%;">0.0104</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T1.7.7.14.7.7" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text" id="S5.T1.7.7.14.7.7.1" style="font-size:80%;">0.0218</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T1.7.7.14.7.8" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text" id="S5.T1.7.7.14.7.8.1" style="font-size:80%;">0.0471</span></td>
</tr>
<tr class="ltx_tr" id="S5.T1.7.7.15.8">
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S5.T1.7.7.15.8.1" rowspan="4" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text" id="S5.T1.7.7.15.8.1.1" style="font-size:80%;">
<span class="ltx_inline-block ltx_transformed_outer" id="S5.T1.7.7.15.8.1.1.1" style="width:6.2pt;height:38pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="width:38.0pt;transform:translate(-15.87pt,-15.19pt) rotate(-90deg) ;">
<span class="ltx_p" id="S5.T1.7.7.15.8.1.1.1.1"><span class="ltx_text" id="S5.T1.7.7.15.8.1.1.1.1.1" style="font-size:88%;">Image-based</span></span>
</span></span></span></th>
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S5.T1.7.7.15.8.2" style="padding-left:1.0pt;padding-right:1.0pt;">
<span class="ltx_text" id="S5.T1.7.7.15.8.2.1" style="font-size:80%;">AnyDoor </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S5.T1.7.7.15.8.2.2.1" style="font-size:80%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib12" title="">12</a><span class="ltx_text" id="S5.T1.7.7.15.8.2.3.2" style="font-size:80%;">]</span></cite>
</th>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T1.7.7.15.8.3" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text" id="S5.T1.7.7.15.8.3.1" style="font-size:80%;">24.5</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T1.7.7.15.8.4" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text" id="S5.T1.7.7.15.8.4.1" style="font-size:80%;">0.0666</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T1.7.7.15.8.5" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text" id="S5.T1.7.7.15.8.5.1" style="font-size:80%;">0.0657</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T1.7.7.15.8.6" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text" id="S5.T1.7.7.15.8.6.1" style="font-size:80%;">0.883</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T1.7.7.15.8.7" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text" id="S5.T1.7.7.15.8.7.1" style="font-size:80%;">0.0265</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T1.7.7.15.8.8" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text" id="S5.T1.7.7.15.8.8.1" style="font-size:80%;">0.0822</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T1.7.7.15.8.9" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text" id="S5.T1.7.7.15.8.9.1" style="font-size:80%;">0.1098</span></td>
</tr>
<tr class="ltx_tr" id="S5.T1.7.7.16.9">
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row" id="S5.T1.7.7.16.9.1" style="padding-left:1.0pt;padding-right:1.0pt;">
<span class="ltx_text" id="S5.T1.7.7.16.9.1.1" style="font-size:80%;">ControlCom </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S5.T1.7.7.16.9.1.2.1" style="font-size:80%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib85" title="">85</a><span class="ltx_text" id="S5.T1.7.7.16.9.1.3.2" style="font-size:80%;">]</span></cite>
</th>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T1.7.7.16.9.2" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text" id="S5.T1.7.7.16.9.2.1" style="font-size:80%;">25.5</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T1.7.7.16.9.3" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text" id="S5.T1.7.7.16.9.3.1" style="font-size:80%;">0.0566</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T1.7.7.16.9.4" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text" id="S5.T1.7.7.16.9.4.1" style="font-size:80%;">0.0554</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T1.7.7.16.9.5" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text" id="S5.T1.7.7.16.9.5.1" style="font-size:80%;">0.866</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T1.7.7.16.9.6" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text" id="S5.T1.7.7.16.9.6.1" style="font-size:80%;">0.0283</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T1.7.7.16.9.7" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text" id="S5.T1.7.7.16.9.7.1" style="font-size:80%;">0.0711</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T1.7.7.16.9.8" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text" id="S5.T1.7.7.16.9.8.1" style="font-size:80%;">0.1516</span></td>
</tr>
<tr class="ltx_tr" id="S5.T1.7.7.17.10">
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row" id="S5.T1.7.7.17.10.1" style="padding-left:1.0pt;padding-right:1.0pt;">
<span class="ltx_text" id="S5.T1.7.7.17.10.1.1" style="font-size:80%;">Careaga’23 </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S5.T1.7.7.17.10.1.2.1" style="font-size:80%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib11" title="">11</a><span class="ltx_text" id="S5.T1.7.7.17.10.1.3.2" style="font-size:80%;">]</span></cite>
</th>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T1.7.7.17.10.2" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text" id="S5.T1.7.7.17.10.2.1" style="font-size:80%;">26.6</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T1.7.7.17.10.3" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text" id="S5.T1.7.7.17.10.3.1" style="font-size:80%;">0.0527</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T1.7.7.17.10.4" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text" id="S5.T1.7.7.17.10.4.1" style="font-size:80%;">0.0498</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T1.7.7.17.10.5" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text" id="S5.T1.7.7.17.10.5.1" style="font-size:80%;">0.965</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T1.7.7.17.10.6" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text" id="S5.T1.7.7.17.10.6.1" style="font-size:80%;">0.0192</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T1.7.7.17.10.7" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text" id="S5.T1.7.7.17.10.7.1" style="font-size:80%;">0.0347</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T1.7.7.17.10.8" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text" id="S5.T1.7.7.17.10.8.1" style="font-size:80%;">0.0884</span></td>
</tr>
<tr class="ltx_tr" id="S5.T1.7.7.18.11">
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row" id="S5.T1.7.7.18.11.1" style="padding-left:1.0pt;padding-right:1.0pt;">
<span class="ltx_text" id="S5.T1.7.7.18.11.1.1" style="font-size:80%;">ARShadowGAN </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S5.T1.7.7.18.11.1.2.1" style="font-size:80%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib46" title="">46</a><span class="ltx_text" id="S5.T1.7.7.18.11.1.3.2" style="font-size:80%;">]</span></cite>
</th>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T1.7.7.18.11.2" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text" id="S5.T1.7.7.18.11.2.1" style="font-size:80%;">27.4</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T1.7.7.18.11.3" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text" id="S5.T1.7.7.18.11.3.1" style="font-size:80%;">0.0484</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T1.7.7.18.11.4" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text" id="S5.T1.7.7.18.11.4.1" style="font-size:80%;">0.0467</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T1.7.7.18.11.5" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text" id="S5.T1.7.7.18.11.5.1" style="font-size:80%;">0.907</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T1.7.7.18.11.6" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text" id="S5.T1.7.7.18.11.6.1" style="font-size:80%;">0.0213</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T1.7.7.18.11.7" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text" id="S5.T1.7.7.18.11.7.1" style="font-size:80%;">0.0584</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T1.7.7.18.11.8" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text" id="S5.T1.7.7.18.11.8.1" style="font-size:80%;">0.0994</span></td>
</tr>
<tr class="ltx_tr" id="S5.T1.7.7.19.12">
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_th ltx_th_row ltx_border_t" id="S5.T1.7.7.19.12.1" style="padding-left:1.0pt;padding-right:1.0pt;"></th>
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S5.T1.7.7.19.12.2" style="padding-left:1.0pt;padding-right:1.0pt;">
<span class="ltx_text ltx_font_smallcaps" id="S5.T1.7.7.19.12.2.1" style="font-size:80%;">ZeroComp</span><span class="ltx_text" id="S5.T1.7.7.19.12.2.2" style="font-size:80%;"> OR</span>
</th>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T1.7.7.19.12.3" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text" id="S5.T1.7.7.19.12.3.1" style="font-size:80%;">31.7</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T1.7.7.19.12.4" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text" id="S5.T1.7.7.19.12.4.1" style="font-size:80%;">0.0303</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T1.7.7.19.12.5" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text" id="S5.T1.7.7.19.12.5.1" style="font-size:80%;">0.0295</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T1.7.7.19.12.6" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text" id="S5.T1.7.7.19.12.6.1" style="font-size:80%;">0.970</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T1.7.7.19.12.7" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text" id="S5.T1.7.7.19.12.7.1" style="font-size:80%;">0.0109</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T1.7.7.19.12.8" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text" id="S5.T1.7.7.19.12.8.1" style="font-size:80%;">0.0269</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T1.7.7.19.12.9" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text" id="S5.T1.7.7.19.12.9.1" style="font-size:80%;">0.0538</span></td>
</tr>
<tr class="ltx_tr" id="S5.T1.7.7.20.13">
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_th ltx_th_row ltx_border_bb" id="S5.T1.7.7.20.13.1" style="padding-left:1.0pt;padding-right:1.0pt;"></th>
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S5.T1.7.7.20.13.2" style="padding-left:1.0pt;padding-right:1.0pt;">
<span class="ltx_text ltx_font_smallcaps" id="S5.T1.7.7.20.13.2.1" style="font-size:80%;">ZeroComp</span><span class="ltx_text" id="S5.T1.7.7.20.13.2.2" style="font-size:80%;"> IV</span>
</th>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" id="S5.T1.7.7.20.13.3" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text" id="S5.T1.7.7.20.13.3.1" style="font-size:80%;">33.0</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" id="S5.T1.7.7.20.13.4" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text" id="S5.T1.7.7.20.13.4.1" style="font-size:80%;">0.0259</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" id="S5.T1.7.7.20.13.5" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text" id="S5.T1.7.7.20.13.5.1" style="font-size:80%;">0.0254</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" id="S5.T1.7.7.20.13.6" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text" id="S5.T1.7.7.20.13.6.1" style="font-size:80%;">0.973</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" id="S5.T1.7.7.20.13.7" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text" id="S5.T1.7.7.20.13.7.1" style="font-size:80%;">0.0091</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" id="S5.T1.7.7.20.13.8" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text" id="S5.T1.7.7.20.13.8.1" style="font-size:80%;">0.0246</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" id="S5.T1.7.7.20.13.9" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text" id="S5.T1.7.7.20.13.9.1" style="font-size:80%;">0.0474</span></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering" style="font-size:80%;"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S5.T1.17.1.1" style="font-size:113%;">Table 1</span>: </span><span class="ltx_text" id="S5.T1.18.2" style="font-size:113%;">Quantitative evaluation. All metrics are computed on the whole image. Different sections indicate methods, from top to bottom: lighting estimation, image-based compositing and ours. OR and IV refer to OpenRooms <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib44" title="">44</a>]</cite> and InteriorVerse <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib91" title="">91</a>]</cite>.
</span></figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S5.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Image-based compositing method comparison</h3>
<div class="ltx_para" id="S5.SS2.p1">
<p class="ltx_p" id="S5.SS2.p1.1">Our evaluation extends to methods that employ intrinsic image decomposition and generative modeling for object compositing. Recent methods like AnyDoor <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib12" title="">12</a>]</cite> and ControlCom <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib85" title="">85</a>]</cite> similarly employ a generative framework with a Stable Diffusion backbone, whereas Careaga et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib11" title="">11</a>]</cite> also rely on intrinsic image decomposition for compositing. Finally, we include ARShadowGAN <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib46" title="">46</a>]</cite> as an example of shadow generation techniques. All of these methods expect as input an image of the object placed in a different scene. We simulate this setup by rendering the object with a randomly sampled environment map from our test set, and feeding it to the methods, letting them do the task of relighting appropriately based on the target background.</p>
</div>
<div class="ltx_para" id="S5.SS2.p2">
<p class="ltx_p" id="S5.SS2.p2.1">The quantitative results in <a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#S5.T1" title="In 5.1 Lighting estimation method comparison ‣ 5 Evaluation ‣ ZeroComp: Zero-shot Object Compositing from Image Intrinsics via Diffusion"><span class="ltx_text ltx_ref_tag">Tab.</span> <span class="ltx_text ltx_ref_tag">1</span></a> (middle bracket) show a superior score for <span class="ltx_text ltx_font_smallcaps" id="S5.SS2.p2.1.1">ZeroComp</span> in all metrics against image-based compositing methods. We identify two main issues with other approaches: they tend to 1) modify the object itself or its pose <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib12" title="">12</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib85" title="">85</a>]</cite>; or 2) generate shadows of limited quality <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib11" title="">11</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib46" title="">46</a>]</cite>.
In contrast, <span class="ltx_text ltx_font_smallcaps" id="S5.SS2.p2.1.2">ZeroComp</span> preserves the original appearance and pose of objects and generates complex and realistic shadows even without access to the full 3D model of the virtual object.</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3 </span>Human perceptual study</h3>
<div class="ltx_para" id="S5.SS3.p1">
<p class="ltx_p" id="S5.SS3.p1.1">While quantitative metrics provide a measure of image quality, recent evidence has shown they do not correlate with human perception when evaluating the realism of composited images <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib27" title="">27</a>]</cite>.
We therefore conduct two user studies to evaluate the perceived realism of the images produced by our method compared to other established approaches.</p>
</div>
<figure class="ltx_table" id="S5.T2">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S5.T2.8">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T2.8.9.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt" id="S5.T2.8.9.1.1"><span class="ltx_text" id="S5.T2.8.9.1.1.1" style="font-size:80%;">Method</span></th>
<td class="ltx_td ltx_align_right ltx_border_tt" id="S5.T2.8.9.1.2"><span class="ltx_text" id="S5.T2.8.9.1.2.1" style="font-size:80%;">Confusion (%)</span></td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S5.T2.1.1.2"><span class="ltx_text ltx_font_bold ltx_font_smallcaps" id="S5.T2.1.1.2.1" style="font-size:80%;">ZeroComp<span class="ltx_text ltx_font_upright" id="S5.T2.1.1.2.1.1"> OR (ours)</span></span></th>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T2.1.1.1"><span class="ltx_text ltx_font_bold" id="S5.T2.1.1.1.1" style="font-size:80%;">45.0 <math alttext="\pm" class="ltx_Math" display="inline" id="S5.T2.1.1.1.1.m1.1"><semantics id="S5.T2.1.1.1.1.m1.1a"><mo id="S5.T2.1.1.1.1.m1.1.1" xref="S5.T2.1.1.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S5.T2.1.1.1.1.m1.1b"><csymbol cd="latexml" id="S5.T2.1.1.1.1.m1.1.1.cmml" xref="S5.T2.1.1.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.1.1.1.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S5.T2.1.1.1.1.m1.1d">±</annotation></semantics></math> 3.9</span></td>
</tr>
<tr class="ltx_tr" id="S5.T2.2.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T2.2.2.2">
<span class="ltx_text" id="S5.T2.2.2.2.1" style="font-size:80%;">EMLight </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S5.T2.2.2.2.2.1" style="font-size:80%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib84" title="">84</a><span class="ltx_text" id="S5.T2.2.2.2.3.2" style="font-size:80%;">]</span></cite>
</th>
<td class="ltx_td ltx_align_right" id="S5.T2.2.2.1">
<span class="ltx_text" id="S5.T2.2.2.1.1" style="font-size:80%;">41.5 </span><math alttext="\pm" class="ltx_Math" display="inline" id="S5.T2.2.2.1.m1.1"><semantics id="S5.T2.2.2.1.m1.1a"><mo id="S5.T2.2.2.1.m1.1.1" mathsize="80%" xref="S5.T2.2.2.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S5.T2.2.2.1.m1.1b"><csymbol cd="latexml" id="S5.T2.2.2.1.m1.1.1.cmml" xref="S5.T2.2.2.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.2.2.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S5.T2.2.2.1.m1.1d">±</annotation></semantics></math><span class="ltx_text" id="S5.T2.2.2.1.2" style="font-size:80%;"> 3.9</span>
</td>
</tr>
<tr class="ltx_tr" id="S5.T2.3.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T2.3.3.2">
<span class="ltx_text ltx_font_smallcaps" id="S5.T2.3.3.2.1" style="font-size:80%;">ZeroComp</span><span class="ltx_text" id="S5.T2.3.3.2.2" style="font-size:80%;"> IV</span>
</th>
<td class="ltx_td ltx_align_right" id="S5.T2.3.3.1">
<span class="ltx_text" id="S5.T2.3.3.1.1" style="font-size:80%;">35.7 </span><math alttext="\pm" class="ltx_Math" display="inline" id="S5.T2.3.3.1.m1.1"><semantics id="S5.T2.3.3.1.m1.1a"><mo id="S5.T2.3.3.1.m1.1.1" mathsize="80%" xref="S5.T2.3.3.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S5.T2.3.3.1.m1.1b"><csymbol cd="latexml" id="S5.T2.3.3.1.m1.1.1.cmml" xref="S5.T2.3.3.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.3.3.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S5.T2.3.3.1.m1.1d">±</annotation></semantics></math><span class="ltx_text" id="S5.T2.3.3.1.2" style="font-size:80%;"> 3.7 *</span>
</td>
</tr>
<tr class="ltx_tr" id="S5.T2.4.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T2.4.4.2">
<span class="ltx_text" id="S5.T2.4.4.2.1" style="font-size:80%;">Garon’19 </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S5.T2.4.4.2.2.1" style="font-size:80%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib23" title="">23</a><span class="ltx_text" id="S5.T2.4.4.2.3.2" style="font-size:80%;">]</span></cite>
</th>
<td class="ltx_td ltx_align_right" id="S5.T2.4.4.1">
<span class="ltx_text" id="S5.T2.4.4.1.1" style="font-size:80%;">31.5 </span><math alttext="\pm" class="ltx_Math" display="inline" id="S5.T2.4.4.1.m1.1"><semantics id="S5.T2.4.4.1.m1.1a"><mo id="S5.T2.4.4.1.m1.1.1" mathsize="80%" xref="S5.T2.4.4.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S5.T2.4.4.1.m1.1b"><csymbol cd="latexml" id="S5.T2.4.4.1.m1.1.1.cmml" xref="S5.T2.4.4.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.4.4.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S5.T2.4.4.1.m1.1d">±</annotation></semantics></math><span class="ltx_text" id="S5.T2.4.4.1.2" style="font-size:80%;"> 3.6 *</span>
</td>
</tr>
<tr class="ltx_tr" id="S5.T2.5.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T2.5.5.2">
<span class="ltx_text" id="S5.T2.5.5.2.1" style="font-size:80%;">Everlight </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S5.T2.5.5.2.2.1" style="font-size:80%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib17" title="">17</a><span class="ltx_text" id="S5.T2.5.5.2.3.2" style="font-size:80%;">]</span></cite>
</th>
<td class="ltx_td ltx_align_right" id="S5.T2.5.5.1">
<span class="ltx_text" id="S5.T2.5.5.1.1" style="font-size:80%;">31.4 </span><math alttext="\pm" class="ltx_Math" display="inline" id="S5.T2.5.5.1.m1.1"><semantics id="S5.T2.5.5.1.m1.1a"><mo id="S5.T2.5.5.1.m1.1.1" mathsize="80%" xref="S5.T2.5.5.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S5.T2.5.5.1.m1.1b"><csymbol cd="latexml" id="S5.T2.5.5.1.m1.1.1.cmml" xref="S5.T2.5.5.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.5.5.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S5.T2.5.5.1.m1.1d">±</annotation></semantics></math><span class="ltx_text" id="S5.T2.5.5.1.2" style="font-size:80%;"> 3.6 *</span>
</td>
</tr>
<tr class="ltx_tr" id="S5.T2.6.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T2.6.6.2">
<span class="ltx_text" id="S5.T2.6.6.2.1" style="font-size:80%;">ControlCom </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S5.T2.6.6.2.2.1" style="font-size:80%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib85" title="">85</a><span class="ltx_text" id="S5.T2.6.6.2.3.2" style="font-size:80%;">]</span></cite>
</th>
<td class="ltx_td ltx_align_right" id="S5.T2.6.6.1">
<span class="ltx_text" id="S5.T2.6.6.1.1" style="font-size:80%;">19.9 </span><math alttext="\pm" class="ltx_Math" display="inline" id="S5.T2.6.6.1.m1.1"><semantics id="S5.T2.6.6.1.m1.1a"><mo id="S5.T2.6.6.1.m1.1.1" mathsize="80%" xref="S5.T2.6.6.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S5.T2.6.6.1.m1.1b"><csymbol cd="latexml" id="S5.T2.6.6.1.m1.1.1.cmml" xref="S5.T2.6.6.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.6.6.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S5.T2.6.6.1.m1.1d">±</annotation></semantics></math><span class="ltx_text" id="S5.T2.6.6.1.2" style="font-size:80%;"> 3.1 *</span>
</td>
</tr>
<tr class="ltx_tr" id="S5.T2.7.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T2.7.7.2">
<span class="ltx_text" id="S5.T2.7.7.2.1" style="font-size:80%;">Careaga’23 </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S5.T2.7.7.2.2.1" style="font-size:80%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib11" title="">11</a><span class="ltx_text" id="S5.T2.7.7.2.3.2" style="font-size:80%;">]</span></cite>
</th>
<td class="ltx_td ltx_align_right" id="S5.T2.7.7.1">
<span class="ltx_text" id="S5.T2.7.7.1.1" style="font-size:80%;">5.0 </span><math alttext="\pm" class="ltx_Math" display="inline" id="S5.T2.7.7.1.m1.1"><semantics id="S5.T2.7.7.1.m1.1a"><mo id="S5.T2.7.7.1.m1.1.1" mathsize="80%" xref="S5.T2.7.7.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S5.T2.7.7.1.m1.1b"><csymbol cd="latexml" id="S5.T2.7.7.1.m1.1.1.cmml" xref="S5.T2.7.7.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.7.7.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S5.T2.7.7.1.m1.1d">±</annotation></semantics></math><span class="ltx_text" id="S5.T2.7.7.1.2" style="font-size:80%;"> 1.7 *</span>
</td>
</tr>
<tr class="ltx_tr" id="S5.T2.8.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S5.T2.8.8.2">
<span class="ltx_text" id="S5.T2.8.8.2.1" style="font-size:80%;">ARShadowGAN </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S5.T2.8.8.2.2.1" style="font-size:80%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib46" title="">46</a><span class="ltx_text" id="S5.T2.8.8.2.3.2" style="font-size:80%;">]</span></cite>
</th>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S5.T2.8.8.1">
<span class="ltx_text" id="S5.T2.8.8.1.1" style="font-size:80%;">4.8 </span><math alttext="\pm" class="ltx_Math" display="inline" id="S5.T2.8.8.1.m1.1"><semantics id="S5.T2.8.8.1.m1.1a"><mo id="S5.T2.8.8.1.m1.1.1" mathsize="80%" xref="S5.T2.8.8.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S5.T2.8.8.1.m1.1b"><csymbol cd="latexml" id="S5.T2.8.8.1.m1.1.1.cmml" xref="S5.T2.8.8.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.8.8.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S5.T2.8.8.1.m1.1d">±</annotation></semantics></math><span class="ltx_text" id="S5.T2.8.8.1.2" style="font-size:80%;"> 1.7 *</span>
</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:80%;"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S5.T2.14.1.1" style="font-size:113%;">Table 2</span>: </span><span class="ltx_text" id="S5.T2.15.2" style="font-size:113%;">Results of our 2AFC user study indicates the perceived realism of the composites, sorted by decreasing confusion (perfect confusion is 50%), and 95% confidence intervals (where “*” indicate a statistically significant difference with <span class="ltx_text ltx_font_smallcaps" id="S5.T2.15.2.1">ZeroComp</span> OR).</span></figcaption>
</figure>
<div class="ltx_para" id="S5.SS3.p2">
<p class="ltx_p" id="S5.SS3.p2.1">We first designed a two-alternative forced choice (2AFC) task where participants viewed a series of image pairs. Each pair featured a ground truth composite and a prediction from one method, both showing the same object on the same background. We asked observers, “The same virtual object has been inserted in these two images. Click on the image that looks the most realistic” (see supp. for instructions). To reduce bias, we randomized the left/right placement of ground truth and predicted images. Each user evaluated 20 pairs per method, totaling 160 comparisons. We randomly sampled a non-overlapping subset of the test set for each method.
In this scenario, a confusion rate of 50% would indicate that users find the generated composites indistinguishable from the ground truth on average. We selected the three lighting estimation methods <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib23" title="">23</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib84" title="">84</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib17" title="">17</a>]</cite> and the three image-based methods <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib46" title="">46</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib85" title="">85</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib11" title="">11</a>]</cite> with the highest PSNR.
A total of <math alttext="N=47" class="ltx_Math" display="inline" id="S5.SS3.p2.1.m1.1"><semantics id="S5.SS3.p2.1.m1.1a"><mrow id="S5.SS3.p2.1.m1.1.1" xref="S5.SS3.p2.1.m1.1.1.cmml"><mi id="S5.SS3.p2.1.m1.1.1.2" xref="S5.SS3.p2.1.m1.1.1.2.cmml">N</mi><mo id="S5.SS3.p2.1.m1.1.1.1" xref="S5.SS3.p2.1.m1.1.1.1.cmml">=</mo><mn id="S5.SS3.p2.1.m1.1.1.3" xref="S5.SS3.p2.1.m1.1.1.3.cmml">47</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.p2.1.m1.1b"><apply id="S5.SS3.p2.1.m1.1.1.cmml" xref="S5.SS3.p2.1.m1.1.1"><eq id="S5.SS3.p2.1.m1.1.1.1.cmml" xref="S5.SS3.p2.1.m1.1.1.1"></eq><ci id="S5.SS3.p2.1.m1.1.1.2.cmml" xref="S5.SS3.p2.1.m1.1.1.2">𝑁</ci><cn id="S5.SS3.p2.1.m1.1.1.3.cmml" type="integer" xref="S5.SS3.p2.1.m1.1.1.3">47</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p2.1.m1.1c">N=47</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.p2.1.m1.1d">italic_N = 47</annotation></semantics></math> observers participated in our study.</p>
</div>
<div class="ltx_para" id="S5.SS3.p3">
<p class="ltx_p" id="S5.SS3.p3.2">As shown in <a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#S5.T2" title="In 5.3 Human perceptual study ‣ 5 Evaluation ‣ ZeroComp: Zero-shot Object Compositing from Image Intrinsics via Diffusion"><span class="ltx_text ltx_ref_tag">Tab.</span> <span class="ltx_text ltx_ref_tag">2</span></a>, our method trained on OpenRooms achieves a 45% confusion rate, indicating a strong preference for the realism of our composites. <span class="ltx_text ltx_font_smallcaps" id="S5.SS3.p3.2.1">ZeroComp</span> trained on InteriorVerse (IV) doesn’t perform as well, presumably due to weaker shadows. The method with the best quantitative score from <a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#S5.T1" title="In 5.1 Lighting estimation method comparison ‣ 5 Evaluation ‣ ZeroComp: Zero-shot Object Compositing from Image Intrinsics via Diffusion"><span class="ltx_text ltx_ref_tag">Tab.</span> <span class="ltx_text ltx_ref_tag">1</span></a>, Garon’19 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib23" title="">23</a>]</cite>, is ranked fourth with 31.5%, corroborating recent findings that image evaluation metrics do not correlate well with human perception <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib27" title="">27</a>]</cite>.
We achieve statistically significant better results against all methods, except with EMLight. We therefore conduct a second user study where <math alttext="N=19" class="ltx_Math" display="inline" id="S5.SS3.p3.1.m1.1"><semantics id="S5.SS3.p3.1.m1.1a"><mrow id="S5.SS3.p3.1.m1.1.1" xref="S5.SS3.p3.1.m1.1.1.cmml"><mi id="S5.SS3.p3.1.m1.1.1.2" xref="S5.SS3.p3.1.m1.1.1.2.cmml">N</mi><mo id="S5.SS3.p3.1.m1.1.1.1" xref="S5.SS3.p3.1.m1.1.1.1.cmml">=</mo><mn id="S5.SS3.p3.1.m1.1.1.3" xref="S5.SS3.p3.1.m1.1.1.3.cmml">19</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.p3.1.m1.1b"><apply id="S5.SS3.p3.1.m1.1.1.cmml" xref="S5.SS3.p3.1.m1.1.1"><eq id="S5.SS3.p3.1.m1.1.1.1.cmml" xref="S5.SS3.p3.1.m1.1.1.1"></eq><ci id="S5.SS3.p3.1.m1.1.1.2.cmml" xref="S5.SS3.p3.1.m1.1.1.2">𝑁</ci><cn id="S5.SS3.p3.1.m1.1.1.3.cmml" type="integer" xref="S5.SS3.p3.1.m1.1.1.3">19</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p3.1.m1.1c">N=19</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.p3.1.m1.1d">italic_N = 19</annotation></semantics></math> participants were shown 100 pairs of images, each pair containing one result from <span class="ltx_text ltx_font_smallcaps" id="S5.SS3.p3.2.2">ZeroComp</span> and the other from EMLight, in randomized order. Users selected our method 55.4 <math alttext="\pm" class="ltx_Math" display="inline" id="S5.SS3.p3.2.m2.1"><semantics id="S5.SS3.p3.2.m2.1a"><mo id="S5.SS3.p3.2.m2.1.1" xref="S5.SS3.p3.2.m2.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S5.SS3.p3.2.m2.1b"><csymbol cd="latexml" id="S5.SS3.p3.2.m2.1.1.cmml" xref="S5.SS3.p3.2.m2.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p3.2.m2.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.p3.2.m2.1d">±</annotation></semantics></math> 2.2% of the time, demonstrating preference for <span class="ltx_text ltx_font_smallcaps" id="S5.SS3.p3.2.3">ZeroComp</span>.</p>
</div>
<figure class="ltx_table" id="S5.T3">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S5.T3.5">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T3.2.2">
<th class="ltx_td ltx_th ltx_th_row ltx_border_tt" id="S5.T3.2.2.3"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt" id="S5.T3.2.2.4"><span class="ltx_text" id="S5.T3.2.2.4.1" style="font-size:80%;">Method</span></th>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T3.1.1.1">
<span class="ltx_text" id="S5.T3.1.1.1.1" style="font-size:80%;">PSNR</span><sub class="ltx_sub" id="S5.T3.1.1.1.2"><span class="ltx_text" id="S5.T3.1.1.1.2.1" style="font-size:80%;">↑</span></sub>
</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T3.2.2.2">
<span class="ltx_text" id="S5.T3.2.2.2.1" style="font-size:80%;">SSIM</span><sub class="ltx_sub" id="S5.T3.2.2.2.2"><span class="ltx_text" id="S5.T3.2.2.2.2.1" style="font-size:80%;">↑</span></sub>
</td>
</tr>
<tr class="ltx_tr" id="S5.T3.3.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S5.T3.3.3.2" rowspan="3"><span class="ltx_text" id="S5.T3.3.3.2.1" style="font-size:80%;">Radius</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S5.T3.3.3.1"><math alttext="\lambda=0.5" class="ltx_Math" display="inline" id="S5.T3.3.3.1.m1.1"><semantics id="S5.T3.3.3.1.m1.1a"><mrow id="S5.T3.3.3.1.m1.1.1" xref="S5.T3.3.3.1.m1.1.1.cmml"><mi id="S5.T3.3.3.1.m1.1.1.2" mathsize="80%" xref="S5.T3.3.3.1.m1.1.1.2.cmml">λ</mi><mo id="S5.T3.3.3.1.m1.1.1.1" mathsize="80%" xref="S5.T3.3.3.1.m1.1.1.1.cmml">=</mo><mn id="S5.T3.3.3.1.m1.1.1.3" mathsize="80%" xref="S5.T3.3.3.1.m1.1.1.3.cmml">0.5</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T3.3.3.1.m1.1b"><apply id="S5.T3.3.3.1.m1.1.1.cmml" xref="S5.T3.3.3.1.m1.1.1"><eq id="S5.T3.3.3.1.m1.1.1.1.cmml" xref="S5.T3.3.3.1.m1.1.1.1"></eq><ci id="S5.T3.3.3.1.m1.1.1.2.cmml" xref="S5.T3.3.3.1.m1.1.1.2">𝜆</ci><cn id="S5.T3.3.3.1.m1.1.1.3.cmml" type="float" xref="S5.T3.3.3.1.m1.1.1.3">0.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.3.3.1.m1.1c">\lambda=0.5</annotation><annotation encoding="application/x-llamapun" id="S5.T3.3.3.1.m1.1d">italic_λ = 0.5</annotation></semantics></math></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.3.3.3"><span class="ltx_text" id="S5.T3.3.3.3.1" style="font-size:80%;">32.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.3.3.4"><span class="ltx_text" id="S5.T3.3.3.4.1" style="font-size:80%;">0.973</span></td>
</tr>
<tr class="ltx_tr" id="S5.T3.4.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T3.4.4.1">
<math alttext="\lambda=1.0" class="ltx_Math" display="inline" id="S5.T3.4.4.1.m1.1"><semantics id="S5.T3.4.4.1.m1.1a"><mrow id="S5.T3.4.4.1.m1.1.1" xref="S5.T3.4.4.1.m1.1.1.cmml"><mi id="S5.T3.4.4.1.m1.1.1.2" mathsize="80%" xref="S5.T3.4.4.1.m1.1.1.2.cmml">λ</mi><mo id="S5.T3.4.4.1.m1.1.1.1" mathsize="80%" xref="S5.T3.4.4.1.m1.1.1.1.cmml">=</mo><mn id="S5.T3.4.4.1.m1.1.1.3" mathsize="80%" xref="S5.T3.4.4.1.m1.1.1.3.cmml">1.0</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T3.4.4.1.m1.1b"><apply id="S5.T3.4.4.1.m1.1.1.cmml" xref="S5.T3.4.4.1.m1.1.1"><eq id="S5.T3.4.4.1.m1.1.1.1.cmml" xref="S5.T3.4.4.1.m1.1.1.1"></eq><ci id="S5.T3.4.4.1.m1.1.1.2.cmml" xref="S5.T3.4.4.1.m1.1.1.2">𝜆</ci><cn id="S5.T3.4.4.1.m1.1.1.3.cmml" type="float" xref="S5.T3.4.4.1.m1.1.1.3">1.0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.4.4.1.m1.1c">\lambda=1.0</annotation><annotation encoding="application/x-llamapun" id="S5.T3.4.4.1.m1.1d">italic_λ = 1.0</annotation></semantics></math><span class="ltx_text" id="S5.T3.4.4.1.1" style="font-size:80%;"> (Ours)</span>
</th>
<td class="ltx_td ltx_align_center" id="S5.T3.4.4.2"><span class="ltx_text" id="S5.T3.4.4.2.1" style="font-size:80%;">31.7</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.4.4.3"><span class="ltx_text" id="S5.T3.4.4.3.1" style="font-size:80%;">0.970</span></td>
</tr>
<tr class="ltx_tr" id="S5.T3.5.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T3.5.5.1"><math alttext="\lambda=1.5" class="ltx_Math" display="inline" id="S5.T3.5.5.1.m1.1"><semantics id="S5.T3.5.5.1.m1.1a"><mrow id="S5.T3.5.5.1.m1.1.1" xref="S5.T3.5.5.1.m1.1.1.cmml"><mi id="S5.T3.5.5.1.m1.1.1.2" mathsize="80%" xref="S5.T3.5.5.1.m1.1.1.2.cmml">λ</mi><mo id="S5.T3.5.5.1.m1.1.1.1" mathsize="80%" xref="S5.T3.5.5.1.m1.1.1.1.cmml">=</mo><mn id="S5.T3.5.5.1.m1.1.1.3" mathsize="80%" xref="S5.T3.5.5.1.m1.1.1.3.cmml">1.5</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T3.5.5.1.m1.1b"><apply id="S5.T3.5.5.1.m1.1.1.cmml" xref="S5.T3.5.5.1.m1.1.1"><eq id="S5.T3.5.5.1.m1.1.1.1.cmml" xref="S5.T3.5.5.1.m1.1.1.1"></eq><ci id="S5.T3.5.5.1.m1.1.1.2.cmml" xref="S5.T3.5.5.1.m1.1.1.2">𝜆</ci><cn id="S5.T3.5.5.1.m1.1.1.3.cmml" type="float" xref="S5.T3.5.5.1.m1.1.1.3">1.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.5.5.1.m1.1c">\lambda=1.5</annotation><annotation encoding="application/x-llamapun" id="S5.T3.5.5.1.m1.1d">italic_λ = 1.5</annotation></semantics></math></th>
<td class="ltx_td ltx_align_center" id="S5.T3.5.5.2"><span class="ltx_text" id="S5.T3.5.5.2.1" style="font-size:80%;">30.8</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.5.5.3"><span class="ltx_text" id="S5.T3.5.5.3.1" style="font-size:80%;">0.967</span></td>
</tr>
<tr class="ltx_tr" id="S5.T3.5.6.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t" id="S5.T3.5.6.1.1" rowspan="4"><span class="ltx_text" id="S5.T3.5.6.1.1.1" style="font-size:80%;">Input</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S5.T3.5.6.1.2"><span class="ltx_text" id="S5.T3.5.6.1.2.1" style="font-size:80%;">w/o depth and normals</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.5.6.1.3"><span class="ltx_text" id="S5.T3.5.6.1.3.1" style="font-size:80%;">31.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.5.6.1.4"><span class="ltx_text" id="S5.T3.5.6.1.4.1" style="font-size:80%;">0.966</span></td>
</tr>
<tr class="ltx_tr" id="S5.T3.5.7.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T3.5.7.2.1"><span class="ltx_text" id="S5.T3.5.7.2.1.1" style="font-size:80%;">w/o normal</span></th>
<td class="ltx_td ltx_align_center" id="S5.T3.5.7.2.2"><span class="ltx_text" id="S5.T3.5.7.2.2.1" style="font-size:80%;">31.6</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.5.7.2.3"><span class="ltx_text" id="S5.T3.5.7.2.3.1" style="font-size:80%;">0.965</span></td>
</tr>
<tr class="ltx_tr" id="S5.T3.5.8.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T3.5.8.3.1"><span class="ltx_text" id="S5.T3.5.8.3.1.1" style="font-size:80%;">w/o depth</span></th>
<td class="ltx_td ltx_align_center" id="S5.T3.5.8.3.2"><span class="ltx_text" id="S5.T3.5.8.3.2.1" style="font-size:80%;">32.1</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.5.8.3.3"><span class="ltx_text" id="S5.T3.5.8.3.3.1" style="font-size:80%;">0.969</span></td>
</tr>
<tr class="ltx_tr" id="S5.T3.5.9.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S5.T3.5.9.4.1"><span class="ltx_text" id="S5.T3.5.9.4.1.1" style="font-size:80%;">baseline</span></th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T3.5.9.4.2"><span class="ltx_text" id="S5.T3.5.9.4.2.1" style="font-size:80%;">31.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T3.5.9.4.3"><span class="ltx_text" id="S5.T3.5.9.4.3.1" style="font-size:80%;">0.969</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:80%;"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S5.T3.9.1.1" style="font-size:113%;">Table 3</span>: </span><span class="ltx_text" id="S5.T3.10.2" style="font-size:113%;">Ablation study on the shading radius, different inputs. The baseline and input-ablated models are trained for 220k steps.</span></figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S5.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.4 </span>Ablations</h3>
<div class="ltx_para" id="S5.SS4.p1">
<p class="ltx_p" id="S5.SS4.p1.1">In <a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#S5.T3" title="In 5.3 Human perceptual study ‣ 5 Evaluation ‣ ZeroComp: Zero-shot Object Compositing from Image Intrinsics via Diffusion"><span class="ltx_text ltx_ref_tag">Tab.</span> <span class="ltx_text ltx_ref_tag">3</span></a>, we ablate shading radius (“Radius”),
various intrinsic maps as input (“Input”). The quantitative difference due to the shading radius is confirmed visually in <a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#S5.F5" title="In 5.4 Ablations ‣ 5 Evaluation ‣ ZeroComp: Zero-shot Object Compositing from Image Intrinsics via Diffusion"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">5</span></a>. However, metrics contradict visual observations when it comes to using different inputs. From <a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#S5.F6" title="In 5.4 Ablations ‣ 5 Evaluation ‣ ZeroComp: Zero-shot Object Compositing from Image Intrinsics via Diffusion"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">6</span></a>, not using the depth or normal maps results in a loss of realism.</p>
</div>
<figure class="ltx_figure" id="S5.F5">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S5.F5.9">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.F5.3.3">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.F5.1.1.1" style="padding-left:1.0pt;padding-right:1.0pt;">
<span class="ltx_text" id="S5.F5.1.1.1.1" style="font-size:80%;"> </span><svg class="ltx_picture" height="192" id="S5.F5.1.1.1.pic1" overflow="visible" version="1.1" width="192"><g transform="translate(0,192) matrix(1 0 0 -1 0 0) translate(-0.28,0) translate(0,-0.28)"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="matrix(1.0 0.0 0.0 1.0 0.28 0.28)"><foreignobject height="192" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="192"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="192" id="S5.F5.1.1.1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.g1" src="extracted/5908513/figures/effect_radius/radius_0.5/9C4A3359-3edd9ddf7d_08_crop_B07B4MH9DB.jpg" width="192"/></foreignobject></g><g color="#FF0000" fill="#FF0000" stroke="#FF0000" stroke-width="0.8pt"><path d="M 3.85 48.14 M 3.85 48.14 L 3.85 19.26 L 67.39 19.26 L 67.39 48.14 Z M 67.39 19.26" style="fill:none"></path></g></g></svg>
</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.F5.2.2.2" style="padding-left:1.0pt;padding-right:1.0pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="192" id="S5.F5.2.2.2.g1" src="extracted/5908513/figures/effect_radius/radius_1.0/9C4A3359-3edd9ddf7d_08_crop_B07B4MH9DB.jpg" width="192"/></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.F5.3.3.3" style="padding-left:1.0pt;padding-right:1.0pt;">
<span class="ltx_text" id="S5.F5.3.3.3.1" style="font-size:80%;"></span><svg class="ltx_picture" height="192" id="S5.F5.3.3.3.pic1" overflow="visible" version="1.1" width="192"><g transform="translate(0,192) matrix(1 0 0 -1 0 0) translate(-0.28,0) translate(0,-0.28)"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="matrix(1.0 0.0 0.0 1.0 0.28 0.28)"><foreignobject height="192" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="192"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="192" id="S5.F5.3.3.3.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.g1" src="extracted/5908513/figures/effect_radius/radius_2.0/9C4A3359-3edd9ddf7d_08_crop_B07B4MH9DB.jpg" width="192"/></foreignobject></g><g color="#FF0000" fill="#FF0000" stroke="#FF0000" stroke-width="0.8pt"><path d="M 67.39 96.28 M 67.39 96.28 L 67.39 38.51 L 96.28 38.51 L 96.28 96.28 Z M 96.28 38.51" style="fill:none"></path></g></g></svg>
</td>
</tr>
<tr class="ltx_tr" id="S5.F5.6.6">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.F5.4.4.1" style="padding-left:1.0pt;padding-right:1.0pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="192" id="S5.F5.4.4.1.g1" src="extracted/5908513/figures/effect_radius/radius_0.5/9C4A3359-3edd9ddf7d_08_crop_B07B4MH9DB_comp_shading-1.jpg" width="192"/></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.F5.5.5.2" style="padding-left:1.0pt;padding-right:1.0pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="192" id="S5.F5.5.5.2.g1" src="extracted/5908513/figures/effect_radius/radius_1.0/9C4A3359-3edd9ddf7d_08_crop_B07B4MH9DB_comp_shading.jpg" width="192"/></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.F5.6.6.3" style="padding-left:1.0pt;padding-right:1.0pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="192" id="S5.F5.6.6.3.g1" src="extracted/5908513/figures/effect_radius/radius_2.0/9C4A3359-3edd9ddf7d_08_crop_B07B4MH9DB_comp_shading-1-2.jpg" width="192"/></td>
</tr>
<tr class="ltx_tr" id="S5.F5.9.9">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.F5.7.7.1" style="padding-left:1.0pt;padding-right:1.0pt;"><math alttext="\lambda=0.5" class="ltx_Math" display="inline" id="S5.F5.7.7.1.m1.1"><semantics id="S5.F5.7.7.1.m1.1a"><mrow id="S5.F5.7.7.1.m1.1.1" xref="S5.F5.7.7.1.m1.1.1.cmml"><mi id="S5.F5.7.7.1.m1.1.1.2" mathsize="80%" xref="S5.F5.7.7.1.m1.1.1.2.cmml">λ</mi><mo id="S5.F5.7.7.1.m1.1.1.1" mathsize="80%" xref="S5.F5.7.7.1.m1.1.1.1.cmml">=</mo><mn id="S5.F5.7.7.1.m1.1.1.3" mathsize="80%" xref="S5.F5.7.7.1.m1.1.1.3.cmml">0.5</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.F5.7.7.1.m1.1b"><apply id="S5.F5.7.7.1.m1.1.1.cmml" xref="S5.F5.7.7.1.m1.1.1"><eq id="S5.F5.7.7.1.m1.1.1.1.cmml" xref="S5.F5.7.7.1.m1.1.1.1"></eq><ci id="S5.F5.7.7.1.m1.1.1.2.cmml" xref="S5.F5.7.7.1.m1.1.1.2">𝜆</ci><cn id="S5.F5.7.7.1.m1.1.1.3.cmml" type="float" xref="S5.F5.7.7.1.m1.1.1.3">0.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.F5.7.7.1.m1.1c">\lambda=0.5</annotation><annotation encoding="application/x-llamapun" id="S5.F5.7.7.1.m1.1d">italic_λ = 0.5</annotation></semantics></math></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.F5.8.8.2" style="padding-left:1.0pt;padding-right:1.0pt;"><math alttext="\lambda=1.0" class="ltx_Math" display="inline" id="S5.F5.8.8.2.m1.1"><semantics id="S5.F5.8.8.2.m1.1a"><mrow id="S5.F5.8.8.2.m1.1.1" xref="S5.F5.8.8.2.m1.1.1.cmml"><mi id="S5.F5.8.8.2.m1.1.1.2" mathsize="80%" xref="S5.F5.8.8.2.m1.1.1.2.cmml">λ</mi><mo id="S5.F5.8.8.2.m1.1.1.1" mathsize="80%" xref="S5.F5.8.8.2.m1.1.1.1.cmml">=</mo><mn id="S5.F5.8.8.2.m1.1.1.3" mathsize="80%" xref="S5.F5.8.8.2.m1.1.1.3.cmml">1.0</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.F5.8.8.2.m1.1b"><apply id="S5.F5.8.8.2.m1.1.1.cmml" xref="S5.F5.8.8.2.m1.1.1"><eq id="S5.F5.8.8.2.m1.1.1.1.cmml" xref="S5.F5.8.8.2.m1.1.1.1"></eq><ci id="S5.F5.8.8.2.m1.1.1.2.cmml" xref="S5.F5.8.8.2.m1.1.1.2">𝜆</ci><cn id="S5.F5.8.8.2.m1.1.1.3.cmml" type="float" xref="S5.F5.8.8.2.m1.1.1.3">1.0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.F5.8.8.2.m1.1c">\lambda=1.0</annotation><annotation encoding="application/x-llamapun" id="S5.F5.8.8.2.m1.1d">italic_λ = 1.0</annotation></semantics></math></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.F5.9.9.3" style="padding-left:1.0pt;padding-right:1.0pt;"><math alttext="\lambda=2.0" class="ltx_Math" display="inline" id="S5.F5.9.9.3.m1.1"><semantics id="S5.F5.9.9.3.m1.1a"><mrow id="S5.F5.9.9.3.m1.1.1" xref="S5.F5.9.9.3.m1.1.1.cmml"><mi id="S5.F5.9.9.3.m1.1.1.2" mathsize="80%" xref="S5.F5.9.9.3.m1.1.1.2.cmml">λ</mi><mo id="S5.F5.9.9.3.m1.1.1.1" mathsize="80%" xref="S5.F5.9.9.3.m1.1.1.1.cmml">=</mo><mn id="S5.F5.9.9.3.m1.1.1.3" mathsize="80%" xref="S5.F5.9.9.3.m1.1.1.3.cmml">2.0</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.F5.9.9.3.m1.1b"><apply id="S5.F5.9.9.3.m1.1.1.cmml" xref="S5.F5.9.9.3.m1.1.1"><eq id="S5.F5.9.9.3.m1.1.1.1.cmml" xref="S5.F5.9.9.3.m1.1.1.1"></eq><ci id="S5.F5.9.9.3.m1.1.1.2.cmml" xref="S5.F5.9.9.3.m1.1.1.2">𝜆</ci><cn id="S5.F5.9.9.3.m1.1.1.3.cmml" type="float" xref="S5.F5.9.9.3.m1.1.1.3">2.0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.F5.9.9.3.m1.1c">\lambda=2.0</annotation><annotation encoding="application/x-llamapun" id="S5.F5.9.9.3.m1.1d">italic_λ = 2.0</annotation></semantics></math></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:80%;"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S5.F5.22.4.1" style="font-size:113%;">Figure 5</span>: </span><span class="ltx_text" id="S5.F5.15.3" style="font-size:113%;">Effect of the shading mask radius <math alttext="\lambda" class="ltx_Math" display="inline" id="S5.F5.13.1.m1.1"><semantics id="S5.F5.13.1.m1.1b"><mi id="S5.F5.13.1.m1.1.1" xref="S5.F5.13.1.m1.1.1.cmml">λ</mi><annotation-xml encoding="MathML-Content" id="S5.F5.13.1.m1.1c"><ci id="S5.F5.13.1.m1.1.1.cmml" xref="S5.F5.13.1.m1.1.1">𝜆</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.F5.13.1.m1.1d">\lambda</annotation><annotation encoding="application/x-llamapun" id="S5.F5.13.1.m1.1e">italic_λ</annotation></semantics></math>. Generated images (top) and their associated masked shading maps (bottom) are shown. A small radius (<math alttext="\lambda=0.5" class="ltx_Math" display="inline" id="S5.F5.14.2.m2.1"><semantics id="S5.F5.14.2.m2.1b"><mrow id="S5.F5.14.2.m2.1.1" xref="S5.F5.14.2.m2.1.1.cmml"><mi id="S5.F5.14.2.m2.1.1.2" xref="S5.F5.14.2.m2.1.1.2.cmml">λ</mi><mo id="S5.F5.14.2.m2.1.1.1" xref="S5.F5.14.2.m2.1.1.1.cmml">=</mo><mn id="S5.F5.14.2.m2.1.1.3" xref="S5.F5.14.2.m2.1.1.3.cmml">0.5</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.F5.14.2.m2.1c"><apply id="S5.F5.14.2.m2.1.1.cmml" xref="S5.F5.14.2.m2.1.1"><eq id="S5.F5.14.2.m2.1.1.1.cmml" xref="S5.F5.14.2.m2.1.1.1"></eq><ci id="S5.F5.14.2.m2.1.1.2.cmml" xref="S5.F5.14.2.m2.1.1.2">𝜆</ci><cn id="S5.F5.14.2.m2.1.1.3.cmml" type="float" xref="S5.F5.14.2.m2.1.1.3">0.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.F5.14.2.m2.1d">\lambda=0.5</annotation><annotation encoding="application/x-llamapun" id="S5.F5.14.2.m2.1e">italic_λ = 0.5</annotation></semantics></math>) results in unrealistic shadow shapes, while a large radius (<math alttext="\lambda=2.0" class="ltx_Math" display="inline" id="S5.F5.15.3.m3.1"><semantics id="S5.F5.15.3.m3.1b"><mrow id="S5.F5.15.3.m3.1.1" xref="S5.F5.15.3.m3.1.1.cmml"><mi id="S5.F5.15.3.m3.1.1.2" xref="S5.F5.15.3.m3.1.1.2.cmml">λ</mi><mo id="S5.F5.15.3.m3.1.1.1" xref="S5.F5.15.3.m3.1.1.1.cmml">=</mo><mn id="S5.F5.15.3.m3.1.1.3" xref="S5.F5.15.3.m3.1.1.3.cmml">2.0</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.F5.15.3.m3.1c"><apply id="S5.F5.15.3.m3.1.1.cmml" xref="S5.F5.15.3.m3.1.1"><eq id="S5.F5.15.3.m3.1.1.1.cmml" xref="S5.F5.15.3.m3.1.1.1"></eq><ci id="S5.F5.15.3.m3.1.1.2.cmml" xref="S5.F5.15.3.m3.1.1.2">𝜆</ci><cn id="S5.F5.15.3.m3.1.1.3.cmml" type="float" xref="S5.F5.15.3.m3.1.1.3">2.0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.F5.15.3.m3.1d">\lambda=2.0</annotation><annotation encoding="application/x-llamapun" id="S5.F5.15.3.m3.1e">italic_λ = 2.0</annotation></semantics></math>) produces overly large shadows and a loss of shading detail in the scene.</span></figcaption>
</figure>
<figure class="ltx_figure" id="S5.F6">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S5.F6.12">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S5.F6.8.8">
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column" id="S5.F6.2.2.2" style="padding-left:1.0pt;padding-right:1.0pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="138" id="S5.F6.1.1.1.g1" src="extracted/5908513/figures/ablation_conditioning/df/9C4A4861-19626f89e9_04_crop_B07B4MSYPS.jpg" width="138"/><span class="ltx_text" id="S5.F6.2.2.2.2" style="font-size:80%;">
</span><span class="ltx_text ltx_inline-block" id="S5.F6.2.2.2.1" style="font-size:80%;width:0.0pt;position:relative; bottom:25.6pt;"><svg height="48" overflow="visible" version="1.1" width="135"><g transform="translate(0,48) scale(1,-1)"><rect fill="none" height="34.7pt" stroke="#000000" stroke-width="0.4" width="97.6pt" x="0" y="0"></rect><g class="makebox" transform="translate(0,0)"><g transform="translate(0,48.0143904801439) scale(1, -1)"><foreignobject height="48.0143904801439" overflow="visible" width="135.049121350491"><img alt="Refer to caption" class="ltx_graphics ltx_missing ltx_missing_image" id="S5.F6.2.2.2.1.1.pic1.1.g1" src=""/></foreignobject></g></g></g></svg></span>
</th>
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column" id="S5.F6.4.4.4" style="padding-left:1.0pt;padding-right:1.0pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="138" id="S5.F6.3.3.3.g1" src="extracted/5908513/figures/ablation_conditioning/df_nm/9C4A4861-19626f89e9_04_crop_B07B4MSYPS.jpg" width="138"/><span class="ltx_text" id="S5.F6.4.4.4.2" style="font-size:80%;">
</span><span class="ltx_text ltx_inline-block" id="S5.F6.4.4.4.1" style="font-size:80%;width:0.0pt;position:relative; bottom:25.6pt;"><svg height="48" overflow="visible" version="1.1" width="135"><g transform="translate(0,48) scale(1,-1)"><rect fill="none" height="34.7pt" stroke="#000000" stroke-width="0.4" width="97.6pt" x="0" y="0"></rect><g class="makebox" transform="translate(0,0)"><g transform="translate(0,48.0143904801439) scale(1, -1)"><foreignobject height="48.0143904801439" overflow="visible" width="135.049121350491"><img alt="Refer to caption" class="ltx_graphics ltx_missing ltx_missing_image" id="S5.F6.4.4.4.1.1.pic1.1.g1" src=""/></foreignobject></g></g></g></svg></span>
</th>
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column" id="S5.F6.6.6.6" style="padding-left:1.0pt;padding-right:1.0pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="138" id="S5.F6.5.5.5.g1" src="extracted/5908513/figures/ablation_conditioning/df_dp/9C4A4861-19626f89e9_04_crop_B07B4MSYPS.jpg" width="138"/><span class="ltx_text" id="S5.F6.6.6.6.2" style="font-size:80%;">
</span><span class="ltx_text ltx_inline-block" id="S5.F6.6.6.6.1" style="font-size:80%;width:0.0pt;position:relative; bottom:25.6pt;"><svg height="48" overflow="visible" version="1.1" width="135"><g transform="translate(0,48) scale(1,-1)"><rect fill="none" height="34.7pt" stroke="#000000" stroke-width="0.4" width="97.6pt" x="0" y="0"></rect><g class="makebox" transform="translate(0,0)"><g transform="translate(0,48.0143904801439) scale(1, -1)"><foreignobject height="48.0143904801439" overflow="visible" width="135.049121350491"><img alt="Refer to caption" class="ltx_graphics ltx_missing ltx_missing_image" id="S5.F6.6.6.6.1.1.pic1.1.g1" src=""/></foreignobject></g></g></g></svg></span>
</th>
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column" id="S5.F6.8.8.8" style="padding-left:1.0pt;padding-right:1.0pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="138" id="S5.F6.7.7.7.g1" src="extracted/5908513/figures/ablation_conditioning/df_dp_nm_2days/9C4A4861-19626f89e9_04_crop_B07B4MSYPS_pred_seed_1_comp.png" width="138"/><span class="ltx_text" id="S5.F6.8.8.8.2" style="font-size:80%;">
</span><span class="ltx_text ltx_inline-block" id="S5.F6.8.8.8.1" style="font-size:80%;width:0.0pt;position:relative; bottom:25.6pt;"><svg height="48" overflow="visible" version="1.1" width="135"><g transform="translate(0,48) scale(1,-1)"><rect fill="none" height="34.7pt" stroke="#000000" stroke-width="0.4" width="97.6pt" x="0" y="0"></rect><g class="makebox" transform="translate(0,0)"><g transform="translate(0,48.0143904801439) scale(1, -1)"><foreignobject height="48.0143904801439" overflow="visible" width="135.049121350491"><img alt="Refer to caption" class="ltx_graphics ltx_missing ltx_missing_image" id="S5.F6.8.8.8.1.1.pic1.1.g1" src=""/></foreignobject></g></g></g></svg></span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.F6.12.12">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.F6.9.9.1" style="padding-left:1.0pt;padding-right:1.0pt;"><math alttext="i_{a}" class="ltx_Math" display="inline" id="S5.F6.9.9.1.m1.1"><semantics id="S5.F6.9.9.1.m1.1a"><msub id="S5.F6.9.9.1.m1.1.1" xref="S5.F6.9.9.1.m1.1.1.cmml"><mi id="S5.F6.9.9.1.m1.1.1.2" mathsize="80%" xref="S5.F6.9.9.1.m1.1.1.2.cmml">i</mi><mi id="S5.F6.9.9.1.m1.1.1.3" mathsize="80%" xref="S5.F6.9.9.1.m1.1.1.3.cmml">a</mi></msub><annotation-xml encoding="MathML-Content" id="S5.F6.9.9.1.m1.1b"><apply id="S5.F6.9.9.1.m1.1.1.cmml" xref="S5.F6.9.9.1.m1.1.1"><csymbol cd="ambiguous" id="S5.F6.9.9.1.m1.1.1.1.cmml" xref="S5.F6.9.9.1.m1.1.1">subscript</csymbol><ci id="S5.F6.9.9.1.m1.1.1.2.cmml" xref="S5.F6.9.9.1.m1.1.1.2">𝑖</ci><ci id="S5.F6.9.9.1.m1.1.1.3.cmml" xref="S5.F6.9.9.1.m1.1.1.3">𝑎</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.F6.9.9.1.m1.1c">i_{a}</annotation><annotation encoding="application/x-llamapun" id="S5.F6.9.9.1.m1.1d">italic_i start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT</annotation></semantics></math></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.F6.10.10.2" style="padding-left:1.0pt;padding-right:1.0pt;"><math alttext="\{i_{a},i_{n}\}" class="ltx_Math" display="inline" id="S5.F6.10.10.2.m1.2"><semantics id="S5.F6.10.10.2.m1.2a"><mrow id="S5.F6.10.10.2.m1.2.2.2" xref="S5.F6.10.10.2.m1.2.2.3.cmml"><mo id="S5.F6.10.10.2.m1.2.2.2.3" maxsize="80%" minsize="80%" xref="S5.F6.10.10.2.m1.2.2.3.cmml">{</mo><msub id="S5.F6.10.10.2.m1.1.1.1.1" xref="S5.F6.10.10.2.m1.1.1.1.1.cmml"><mi id="S5.F6.10.10.2.m1.1.1.1.1.2" mathsize="80%" xref="S5.F6.10.10.2.m1.1.1.1.1.2.cmml">i</mi><mi id="S5.F6.10.10.2.m1.1.1.1.1.3" mathsize="80%" xref="S5.F6.10.10.2.m1.1.1.1.1.3.cmml">a</mi></msub><mo id="S5.F6.10.10.2.m1.2.2.2.4" mathsize="80%" xref="S5.F6.10.10.2.m1.2.2.3.cmml">,</mo><msub id="S5.F6.10.10.2.m1.2.2.2.2" xref="S5.F6.10.10.2.m1.2.2.2.2.cmml"><mi id="S5.F6.10.10.2.m1.2.2.2.2.2" mathsize="80%" xref="S5.F6.10.10.2.m1.2.2.2.2.2.cmml">i</mi><mi id="S5.F6.10.10.2.m1.2.2.2.2.3" mathsize="80%" xref="S5.F6.10.10.2.m1.2.2.2.2.3.cmml">n</mi></msub><mo id="S5.F6.10.10.2.m1.2.2.2.5" maxsize="80%" minsize="80%" xref="S5.F6.10.10.2.m1.2.2.3.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.F6.10.10.2.m1.2b"><set id="S5.F6.10.10.2.m1.2.2.3.cmml" xref="S5.F6.10.10.2.m1.2.2.2"><apply id="S5.F6.10.10.2.m1.1.1.1.1.cmml" xref="S5.F6.10.10.2.m1.1.1.1.1"><csymbol cd="ambiguous" id="S5.F6.10.10.2.m1.1.1.1.1.1.cmml" xref="S5.F6.10.10.2.m1.1.1.1.1">subscript</csymbol><ci id="S5.F6.10.10.2.m1.1.1.1.1.2.cmml" xref="S5.F6.10.10.2.m1.1.1.1.1.2">𝑖</ci><ci id="S5.F6.10.10.2.m1.1.1.1.1.3.cmml" xref="S5.F6.10.10.2.m1.1.1.1.1.3">𝑎</ci></apply><apply id="S5.F6.10.10.2.m1.2.2.2.2.cmml" xref="S5.F6.10.10.2.m1.2.2.2.2"><csymbol cd="ambiguous" id="S5.F6.10.10.2.m1.2.2.2.2.1.cmml" xref="S5.F6.10.10.2.m1.2.2.2.2">subscript</csymbol><ci id="S5.F6.10.10.2.m1.2.2.2.2.2.cmml" xref="S5.F6.10.10.2.m1.2.2.2.2.2">𝑖</ci><ci id="S5.F6.10.10.2.m1.2.2.2.2.3.cmml" xref="S5.F6.10.10.2.m1.2.2.2.2.3">𝑛</ci></apply></set></annotation-xml><annotation encoding="application/x-tex" id="S5.F6.10.10.2.m1.2c">\{i_{a},i_{n}\}</annotation><annotation encoding="application/x-llamapun" id="S5.F6.10.10.2.m1.2d">{ italic_i start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT , italic_i start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT }</annotation></semantics></math></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.F6.11.11.3" style="padding-left:1.0pt;padding-right:1.0pt;"><math alttext="\{i_{a},i_{d}\}" class="ltx_Math" display="inline" id="S5.F6.11.11.3.m1.2"><semantics id="S5.F6.11.11.3.m1.2a"><mrow id="S5.F6.11.11.3.m1.2.2.2" xref="S5.F6.11.11.3.m1.2.2.3.cmml"><mo id="S5.F6.11.11.3.m1.2.2.2.3" maxsize="80%" minsize="80%" xref="S5.F6.11.11.3.m1.2.2.3.cmml">{</mo><msub id="S5.F6.11.11.3.m1.1.1.1.1" xref="S5.F6.11.11.3.m1.1.1.1.1.cmml"><mi id="S5.F6.11.11.3.m1.1.1.1.1.2" mathsize="80%" xref="S5.F6.11.11.3.m1.1.1.1.1.2.cmml">i</mi><mi id="S5.F6.11.11.3.m1.1.1.1.1.3" mathsize="80%" xref="S5.F6.11.11.3.m1.1.1.1.1.3.cmml">a</mi></msub><mo id="S5.F6.11.11.3.m1.2.2.2.4" mathsize="80%" xref="S5.F6.11.11.3.m1.2.2.3.cmml">,</mo><msub id="S5.F6.11.11.3.m1.2.2.2.2" xref="S5.F6.11.11.3.m1.2.2.2.2.cmml"><mi id="S5.F6.11.11.3.m1.2.2.2.2.2" mathsize="80%" xref="S5.F6.11.11.3.m1.2.2.2.2.2.cmml">i</mi><mi id="S5.F6.11.11.3.m1.2.2.2.2.3" mathsize="80%" xref="S5.F6.11.11.3.m1.2.2.2.2.3.cmml">d</mi></msub><mo id="S5.F6.11.11.3.m1.2.2.2.5" maxsize="80%" minsize="80%" xref="S5.F6.11.11.3.m1.2.2.3.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.F6.11.11.3.m1.2b"><set id="S5.F6.11.11.3.m1.2.2.3.cmml" xref="S5.F6.11.11.3.m1.2.2.2"><apply id="S5.F6.11.11.3.m1.1.1.1.1.cmml" xref="S5.F6.11.11.3.m1.1.1.1.1"><csymbol cd="ambiguous" id="S5.F6.11.11.3.m1.1.1.1.1.1.cmml" xref="S5.F6.11.11.3.m1.1.1.1.1">subscript</csymbol><ci id="S5.F6.11.11.3.m1.1.1.1.1.2.cmml" xref="S5.F6.11.11.3.m1.1.1.1.1.2">𝑖</ci><ci id="S5.F6.11.11.3.m1.1.1.1.1.3.cmml" xref="S5.F6.11.11.3.m1.1.1.1.1.3">𝑎</ci></apply><apply id="S5.F6.11.11.3.m1.2.2.2.2.cmml" xref="S5.F6.11.11.3.m1.2.2.2.2"><csymbol cd="ambiguous" id="S5.F6.11.11.3.m1.2.2.2.2.1.cmml" xref="S5.F6.11.11.3.m1.2.2.2.2">subscript</csymbol><ci id="S5.F6.11.11.3.m1.2.2.2.2.2.cmml" xref="S5.F6.11.11.3.m1.2.2.2.2.2">𝑖</ci><ci id="S5.F6.11.11.3.m1.2.2.2.2.3.cmml" xref="S5.F6.11.11.3.m1.2.2.2.2.3">𝑑</ci></apply></set></annotation-xml><annotation encoding="application/x-tex" id="S5.F6.11.11.3.m1.2c">\{i_{a},i_{d}\}</annotation><annotation encoding="application/x-llamapun" id="S5.F6.11.11.3.m1.2d">{ italic_i start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT , italic_i start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT }</annotation></semantics></math></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.F6.12.12.4" style="padding-left:1.0pt;padding-right:1.0pt;"><math alttext="\{i_{a},i_{n},i_{d}\}" class="ltx_Math" display="inline" id="S5.F6.12.12.4.m1.3"><semantics id="S5.F6.12.12.4.m1.3a"><mrow id="S5.F6.12.12.4.m1.3.3.3" xref="S5.F6.12.12.4.m1.3.3.4.cmml"><mo id="S5.F6.12.12.4.m1.3.3.3.4" maxsize="80%" minsize="80%" xref="S5.F6.12.12.4.m1.3.3.4.cmml">{</mo><msub id="S5.F6.12.12.4.m1.1.1.1.1" xref="S5.F6.12.12.4.m1.1.1.1.1.cmml"><mi id="S5.F6.12.12.4.m1.1.1.1.1.2" mathsize="80%" xref="S5.F6.12.12.4.m1.1.1.1.1.2.cmml">i</mi><mi id="S5.F6.12.12.4.m1.1.1.1.1.3" mathsize="80%" xref="S5.F6.12.12.4.m1.1.1.1.1.3.cmml">a</mi></msub><mo id="S5.F6.12.12.4.m1.3.3.3.5" mathsize="80%" xref="S5.F6.12.12.4.m1.3.3.4.cmml">,</mo><msub id="S5.F6.12.12.4.m1.2.2.2.2" xref="S5.F6.12.12.4.m1.2.2.2.2.cmml"><mi id="S5.F6.12.12.4.m1.2.2.2.2.2" mathsize="80%" xref="S5.F6.12.12.4.m1.2.2.2.2.2.cmml">i</mi><mi id="S5.F6.12.12.4.m1.2.2.2.2.3" mathsize="80%" xref="S5.F6.12.12.4.m1.2.2.2.2.3.cmml">n</mi></msub><mo id="S5.F6.12.12.4.m1.3.3.3.6" mathsize="80%" xref="S5.F6.12.12.4.m1.3.3.4.cmml">,</mo><msub id="S5.F6.12.12.4.m1.3.3.3.3" xref="S5.F6.12.12.4.m1.3.3.3.3.cmml"><mi id="S5.F6.12.12.4.m1.3.3.3.3.2" mathsize="80%" xref="S5.F6.12.12.4.m1.3.3.3.3.2.cmml">i</mi><mi id="S5.F6.12.12.4.m1.3.3.3.3.3" mathsize="80%" xref="S5.F6.12.12.4.m1.3.3.3.3.3.cmml">d</mi></msub><mo id="S5.F6.12.12.4.m1.3.3.3.7" maxsize="80%" minsize="80%" xref="S5.F6.12.12.4.m1.3.3.4.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.F6.12.12.4.m1.3b"><set id="S5.F6.12.12.4.m1.3.3.4.cmml" xref="S5.F6.12.12.4.m1.3.3.3"><apply id="S5.F6.12.12.4.m1.1.1.1.1.cmml" xref="S5.F6.12.12.4.m1.1.1.1.1"><csymbol cd="ambiguous" id="S5.F6.12.12.4.m1.1.1.1.1.1.cmml" xref="S5.F6.12.12.4.m1.1.1.1.1">subscript</csymbol><ci id="S5.F6.12.12.4.m1.1.1.1.1.2.cmml" xref="S5.F6.12.12.4.m1.1.1.1.1.2">𝑖</ci><ci id="S5.F6.12.12.4.m1.1.1.1.1.3.cmml" xref="S5.F6.12.12.4.m1.1.1.1.1.3">𝑎</ci></apply><apply id="S5.F6.12.12.4.m1.2.2.2.2.cmml" xref="S5.F6.12.12.4.m1.2.2.2.2"><csymbol cd="ambiguous" id="S5.F6.12.12.4.m1.2.2.2.2.1.cmml" xref="S5.F6.12.12.4.m1.2.2.2.2">subscript</csymbol><ci id="S5.F6.12.12.4.m1.2.2.2.2.2.cmml" xref="S5.F6.12.12.4.m1.2.2.2.2.2">𝑖</ci><ci id="S5.F6.12.12.4.m1.2.2.2.2.3.cmml" xref="S5.F6.12.12.4.m1.2.2.2.2.3">𝑛</ci></apply><apply id="S5.F6.12.12.4.m1.3.3.3.3.cmml" xref="S5.F6.12.12.4.m1.3.3.3.3"><csymbol cd="ambiguous" id="S5.F6.12.12.4.m1.3.3.3.3.1.cmml" xref="S5.F6.12.12.4.m1.3.3.3.3">subscript</csymbol><ci id="S5.F6.12.12.4.m1.3.3.3.3.2.cmml" xref="S5.F6.12.12.4.m1.3.3.3.3.2">𝑖</ci><ci id="S5.F6.12.12.4.m1.3.3.3.3.3.cmml" xref="S5.F6.12.12.4.m1.3.3.3.3.3">𝑑</ci></apply></set></annotation-xml><annotation encoding="application/x-tex" id="S5.F6.12.12.4.m1.3c">\{i_{a},i_{n},i_{d}\}</annotation><annotation encoding="application/x-llamapun" id="S5.F6.12.12.4.m1.3d">{ italic_i start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT , italic_i start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT , italic_i start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT }</annotation></semantics></math></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:80%;"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S5.F6.25.4.1" style="font-size:113%;">Figure 6</span>: </span><span class="ltx_text" id="S5.F6.18.3" style="font-size:113%;">Ablation on intrinsic conditionings: Training using different combinations of depth (<math alttext="i_{d}" class="ltx_Math" display="inline" id="S5.F6.16.1.m1.1"><semantics id="S5.F6.16.1.m1.1b"><msub id="S5.F6.16.1.m1.1.1" xref="S5.F6.16.1.m1.1.1.cmml"><mi id="S5.F6.16.1.m1.1.1.2" xref="S5.F6.16.1.m1.1.1.2.cmml">i</mi><mi id="S5.F6.16.1.m1.1.1.3" xref="S5.F6.16.1.m1.1.1.3.cmml">d</mi></msub><annotation-xml encoding="MathML-Content" id="S5.F6.16.1.m1.1c"><apply id="S5.F6.16.1.m1.1.1.cmml" xref="S5.F6.16.1.m1.1.1"><csymbol cd="ambiguous" id="S5.F6.16.1.m1.1.1.1.cmml" xref="S5.F6.16.1.m1.1.1">subscript</csymbol><ci id="S5.F6.16.1.m1.1.1.2.cmml" xref="S5.F6.16.1.m1.1.1.2">𝑖</ci><ci id="S5.F6.16.1.m1.1.1.3.cmml" xref="S5.F6.16.1.m1.1.1.3">𝑑</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.F6.16.1.m1.1d">i_{d}</annotation><annotation encoding="application/x-llamapun" id="S5.F6.16.1.m1.1e">italic_i start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT</annotation></semantics></math>) and normals (<math alttext="i_{n}" class="ltx_Math" display="inline" id="S5.F6.17.2.m2.1"><semantics id="S5.F6.17.2.m2.1b"><msub id="S5.F6.17.2.m2.1.1" xref="S5.F6.17.2.m2.1.1.cmml"><mi id="S5.F6.17.2.m2.1.1.2" xref="S5.F6.17.2.m2.1.1.2.cmml">i</mi><mi id="S5.F6.17.2.m2.1.1.3" xref="S5.F6.17.2.m2.1.1.3.cmml">n</mi></msub><annotation-xml encoding="MathML-Content" id="S5.F6.17.2.m2.1c"><apply id="S5.F6.17.2.m2.1.1.cmml" xref="S5.F6.17.2.m2.1.1"><csymbol cd="ambiguous" id="S5.F6.17.2.m2.1.1.1.cmml" xref="S5.F6.17.2.m2.1.1">subscript</csymbol><ci id="S5.F6.17.2.m2.1.1.2.cmml" xref="S5.F6.17.2.m2.1.1.2">𝑖</ci><ci id="S5.F6.17.2.m2.1.1.3.cmml" xref="S5.F6.17.2.m2.1.1.3">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.F6.17.2.m2.1d">i_{n}</annotation><annotation encoding="application/x-llamapun" id="S5.F6.17.2.m2.1e">italic_i start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT</annotation></semantics></math>), while consistently retaining the albedo (<math alttext="i_{a}" class="ltx_Math" display="inline" id="S5.F6.18.3.m3.1"><semantics id="S5.F6.18.3.m3.1b"><msub id="S5.F6.18.3.m3.1.1" xref="S5.F6.18.3.m3.1.1.cmml"><mi id="S5.F6.18.3.m3.1.1.2" xref="S5.F6.18.3.m3.1.1.2.cmml">i</mi><mi id="S5.F6.18.3.m3.1.1.3" xref="S5.F6.18.3.m3.1.1.3.cmml">a</mi></msub><annotation-xml encoding="MathML-Content" id="S5.F6.18.3.m3.1c"><apply id="S5.F6.18.3.m3.1.1.cmml" xref="S5.F6.18.3.m3.1.1"><csymbol cd="ambiguous" id="S5.F6.18.3.m3.1.1.1.cmml" xref="S5.F6.18.3.m3.1.1">subscript</csymbol><ci id="S5.F6.18.3.m3.1.1.2.cmml" xref="S5.F6.18.3.m3.1.1.2">𝑖</ci><ci id="S5.F6.18.3.m3.1.1.3.cmml" xref="S5.F6.18.3.m3.1.1.3">𝑎</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.F6.18.3.m3.1d">i_{a}</annotation><annotation encoding="application/x-llamapun" id="S5.F6.18.3.m3.1e">italic_i start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT</annotation></semantics></math>). Normals aid the network in generating sharp object details, whereas depth enhances shadow strength. Using both conditionings provides optimal results.</span></figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S5.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.5 </span>Extensions</h3>
<figure class="ltx_figure" id="S5.F7">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S5.F7.6">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.F7.4.4">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.F7.1.1.1" style="padding-left:1.0pt;padding-right:1.0pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="138" id="S5.F7.1.1.1.g1" src="extracted/5908513/figures/iv_metallic_roughness/2days/7/9C4A4861-19626f89e9_03_crop_B07QBMQ4PZ_pred_seed_1_o.jpg" width="138"/></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.F7.2.2.2" style="padding-left:1.0pt;padding-right:1.0pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="138" id="S5.F7.2.2.2.g1" src="extracted/5908513/figures/iv_metallic_roughness/2days/7/9C4A4861-19626f89e9_03_crop_B07QBMQ4PZ_pred_seed_1_m.jpg" width="138"/></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.F7.3.3.3" style="padding-left:1.0pt;padding-right:1.0pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="138" id="S5.F7.3.3.3.g1" src="extracted/5908513/figures/iv_metallic_roughness/2days/6/9C4A6901-d0b46d02c4_01_crop_B07MF1NJ7Q_pred_seed_1_comp_o.jpg" width="138"/></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.F7.4.4.4" style="padding-left:1.0pt;padding-right:1.0pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="138" id="S5.F7.4.4.4.g1" src="extracted/5908513/figures/iv_metallic_roughness/2days/6/9C4A6901-d0b46d02c4_01_crop_B07MF1NJ7Q_pred_seed_1_comp_m.jpg" width="138"/></td>
</tr>
<tr class="ltx_tr" id="S5.F7.6.6">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.F7.6.6.3" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text" id="S5.F7.6.6.3.1" style="font-size:70%;">Original</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.F7.5.5.1" style="padding-left:1.0pt;padding-right:1.0pt;"><math alttext="RG=0,MT=1" class="ltx_Math" display="inline" id="S5.F7.5.5.1.m1.2"><semantics id="S5.F7.5.5.1.m1.2a"><mrow id="S5.F7.5.5.1.m1.2.2.2" xref="S5.F7.5.5.1.m1.2.2.3.cmml"><mrow id="S5.F7.5.5.1.m1.1.1.1.1" xref="S5.F7.5.5.1.m1.1.1.1.1.cmml"><mrow id="S5.F7.5.5.1.m1.1.1.1.1.2" xref="S5.F7.5.5.1.m1.1.1.1.1.2.cmml"><mi id="S5.F7.5.5.1.m1.1.1.1.1.2.2" mathsize="70%" xref="S5.F7.5.5.1.m1.1.1.1.1.2.2.cmml">R</mi><mo id="S5.F7.5.5.1.m1.1.1.1.1.2.1" xref="S5.F7.5.5.1.m1.1.1.1.1.2.1.cmml">⁢</mo><mi id="S5.F7.5.5.1.m1.1.1.1.1.2.3" mathsize="70%" xref="S5.F7.5.5.1.m1.1.1.1.1.2.3.cmml">G</mi></mrow><mo id="S5.F7.5.5.1.m1.1.1.1.1.1" mathsize="70%" xref="S5.F7.5.5.1.m1.1.1.1.1.1.cmml">=</mo><mn id="S5.F7.5.5.1.m1.1.1.1.1.3" mathsize="70%" xref="S5.F7.5.5.1.m1.1.1.1.1.3.cmml">0</mn></mrow><mo id="S5.F7.5.5.1.m1.2.2.2.3" mathsize="70%" xref="S5.F7.5.5.1.m1.2.2.3a.cmml">,</mo><mrow id="S5.F7.5.5.1.m1.2.2.2.2" xref="S5.F7.5.5.1.m1.2.2.2.2.cmml"><mrow id="S5.F7.5.5.1.m1.2.2.2.2.2" xref="S5.F7.5.5.1.m1.2.2.2.2.2.cmml"><mi id="S5.F7.5.5.1.m1.2.2.2.2.2.2" mathsize="70%" xref="S5.F7.5.5.1.m1.2.2.2.2.2.2.cmml">M</mi><mo id="S5.F7.5.5.1.m1.2.2.2.2.2.1" xref="S5.F7.5.5.1.m1.2.2.2.2.2.1.cmml">⁢</mo><mi id="S5.F7.5.5.1.m1.2.2.2.2.2.3" mathsize="70%" xref="S5.F7.5.5.1.m1.2.2.2.2.2.3.cmml">T</mi></mrow><mo id="S5.F7.5.5.1.m1.2.2.2.2.1" mathsize="70%" xref="S5.F7.5.5.1.m1.2.2.2.2.1.cmml">=</mo><mn id="S5.F7.5.5.1.m1.2.2.2.2.3" mathsize="70%" xref="S5.F7.5.5.1.m1.2.2.2.2.3.cmml">1</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.F7.5.5.1.m1.2b"><apply id="S5.F7.5.5.1.m1.2.2.3.cmml" xref="S5.F7.5.5.1.m1.2.2.2"><csymbol cd="ambiguous" id="S5.F7.5.5.1.m1.2.2.3a.cmml" xref="S5.F7.5.5.1.m1.2.2.2.3">formulae-sequence</csymbol><apply id="S5.F7.5.5.1.m1.1.1.1.1.cmml" xref="S5.F7.5.5.1.m1.1.1.1.1"><eq id="S5.F7.5.5.1.m1.1.1.1.1.1.cmml" xref="S5.F7.5.5.1.m1.1.1.1.1.1"></eq><apply id="S5.F7.5.5.1.m1.1.1.1.1.2.cmml" xref="S5.F7.5.5.1.m1.1.1.1.1.2"><times id="S5.F7.5.5.1.m1.1.1.1.1.2.1.cmml" xref="S5.F7.5.5.1.m1.1.1.1.1.2.1"></times><ci id="S5.F7.5.5.1.m1.1.1.1.1.2.2.cmml" xref="S5.F7.5.5.1.m1.1.1.1.1.2.2">𝑅</ci><ci id="S5.F7.5.5.1.m1.1.1.1.1.2.3.cmml" xref="S5.F7.5.5.1.m1.1.1.1.1.2.3">𝐺</ci></apply><cn id="S5.F7.5.5.1.m1.1.1.1.1.3.cmml" type="integer" xref="S5.F7.5.5.1.m1.1.1.1.1.3">0</cn></apply><apply id="S5.F7.5.5.1.m1.2.2.2.2.cmml" xref="S5.F7.5.5.1.m1.2.2.2.2"><eq id="S5.F7.5.5.1.m1.2.2.2.2.1.cmml" xref="S5.F7.5.5.1.m1.2.2.2.2.1"></eq><apply id="S5.F7.5.5.1.m1.2.2.2.2.2.cmml" xref="S5.F7.5.5.1.m1.2.2.2.2.2"><times id="S5.F7.5.5.1.m1.2.2.2.2.2.1.cmml" xref="S5.F7.5.5.1.m1.2.2.2.2.2.1"></times><ci id="S5.F7.5.5.1.m1.2.2.2.2.2.2.cmml" xref="S5.F7.5.5.1.m1.2.2.2.2.2.2">𝑀</ci><ci id="S5.F7.5.5.1.m1.2.2.2.2.2.3.cmml" xref="S5.F7.5.5.1.m1.2.2.2.2.2.3">𝑇</ci></apply><cn id="S5.F7.5.5.1.m1.2.2.2.2.3.cmml" type="integer" xref="S5.F7.5.5.1.m1.2.2.2.2.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.F7.5.5.1.m1.2c">RG=0,MT=1</annotation><annotation encoding="application/x-llamapun" id="S5.F7.5.5.1.m1.2d">italic_R italic_G = 0 , italic_M italic_T = 1</annotation></semantics></math></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.F7.6.6.4" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text" id="S5.F7.6.6.4.1" style="font-size:70%;">Original</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.F7.6.6.2" style="padding-left:1.0pt;padding-right:1.0pt;"><math alttext="RG=0,MT=1" class="ltx_Math" display="inline" id="S5.F7.6.6.2.m1.2"><semantics id="S5.F7.6.6.2.m1.2a"><mrow id="S5.F7.6.6.2.m1.2.2.2" xref="S5.F7.6.6.2.m1.2.2.3.cmml"><mrow id="S5.F7.6.6.2.m1.1.1.1.1" xref="S5.F7.6.6.2.m1.1.1.1.1.cmml"><mrow id="S5.F7.6.6.2.m1.1.1.1.1.2" xref="S5.F7.6.6.2.m1.1.1.1.1.2.cmml"><mi id="S5.F7.6.6.2.m1.1.1.1.1.2.2" mathsize="70%" xref="S5.F7.6.6.2.m1.1.1.1.1.2.2.cmml">R</mi><mo id="S5.F7.6.6.2.m1.1.1.1.1.2.1" xref="S5.F7.6.6.2.m1.1.1.1.1.2.1.cmml">⁢</mo><mi id="S5.F7.6.6.2.m1.1.1.1.1.2.3" mathsize="70%" xref="S5.F7.6.6.2.m1.1.1.1.1.2.3.cmml">G</mi></mrow><mo id="S5.F7.6.6.2.m1.1.1.1.1.1" mathsize="70%" xref="S5.F7.6.6.2.m1.1.1.1.1.1.cmml">=</mo><mn id="S5.F7.6.6.2.m1.1.1.1.1.3" mathsize="70%" xref="S5.F7.6.6.2.m1.1.1.1.1.3.cmml">0</mn></mrow><mo id="S5.F7.6.6.2.m1.2.2.2.3" mathsize="70%" xref="S5.F7.6.6.2.m1.2.2.3a.cmml">,</mo><mrow id="S5.F7.6.6.2.m1.2.2.2.2" xref="S5.F7.6.6.2.m1.2.2.2.2.cmml"><mrow id="S5.F7.6.6.2.m1.2.2.2.2.2" xref="S5.F7.6.6.2.m1.2.2.2.2.2.cmml"><mi id="S5.F7.6.6.2.m1.2.2.2.2.2.2" mathsize="70%" xref="S5.F7.6.6.2.m1.2.2.2.2.2.2.cmml">M</mi><mo id="S5.F7.6.6.2.m1.2.2.2.2.2.1" xref="S5.F7.6.6.2.m1.2.2.2.2.2.1.cmml">⁢</mo><mi id="S5.F7.6.6.2.m1.2.2.2.2.2.3" mathsize="70%" xref="S5.F7.6.6.2.m1.2.2.2.2.2.3.cmml">T</mi></mrow><mo id="S5.F7.6.6.2.m1.2.2.2.2.1" mathsize="70%" xref="S5.F7.6.6.2.m1.2.2.2.2.1.cmml">=</mo><mn id="S5.F7.6.6.2.m1.2.2.2.2.3" mathsize="70%" xref="S5.F7.6.6.2.m1.2.2.2.2.3.cmml">1</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.F7.6.6.2.m1.2b"><apply id="S5.F7.6.6.2.m1.2.2.3.cmml" xref="S5.F7.6.6.2.m1.2.2.2"><csymbol cd="ambiguous" id="S5.F7.6.6.2.m1.2.2.3a.cmml" xref="S5.F7.6.6.2.m1.2.2.2.3">formulae-sequence</csymbol><apply id="S5.F7.6.6.2.m1.1.1.1.1.cmml" xref="S5.F7.6.6.2.m1.1.1.1.1"><eq id="S5.F7.6.6.2.m1.1.1.1.1.1.cmml" xref="S5.F7.6.6.2.m1.1.1.1.1.1"></eq><apply id="S5.F7.6.6.2.m1.1.1.1.1.2.cmml" xref="S5.F7.6.6.2.m1.1.1.1.1.2"><times id="S5.F7.6.6.2.m1.1.1.1.1.2.1.cmml" xref="S5.F7.6.6.2.m1.1.1.1.1.2.1"></times><ci id="S5.F7.6.6.2.m1.1.1.1.1.2.2.cmml" xref="S5.F7.6.6.2.m1.1.1.1.1.2.2">𝑅</ci><ci id="S5.F7.6.6.2.m1.1.1.1.1.2.3.cmml" xref="S5.F7.6.6.2.m1.1.1.1.1.2.3">𝐺</ci></apply><cn id="S5.F7.6.6.2.m1.1.1.1.1.3.cmml" type="integer" xref="S5.F7.6.6.2.m1.1.1.1.1.3">0</cn></apply><apply id="S5.F7.6.6.2.m1.2.2.2.2.cmml" xref="S5.F7.6.6.2.m1.2.2.2.2"><eq id="S5.F7.6.6.2.m1.2.2.2.2.1.cmml" xref="S5.F7.6.6.2.m1.2.2.2.2.1"></eq><apply id="S5.F7.6.6.2.m1.2.2.2.2.2.cmml" xref="S5.F7.6.6.2.m1.2.2.2.2.2"><times id="S5.F7.6.6.2.m1.2.2.2.2.2.1.cmml" xref="S5.F7.6.6.2.m1.2.2.2.2.2.1"></times><ci id="S5.F7.6.6.2.m1.2.2.2.2.2.2.cmml" xref="S5.F7.6.6.2.m1.2.2.2.2.2.2">𝑀</ci><ci id="S5.F7.6.6.2.m1.2.2.2.2.2.3.cmml" xref="S5.F7.6.6.2.m1.2.2.2.2.2.3">𝑇</ci></apply><cn id="S5.F7.6.6.2.m1.2.2.2.2.3.cmml" type="integer" xref="S5.F7.6.6.2.m1.2.2.2.2.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.F7.6.6.2.m1.2c">RG=0,MT=1</annotation><annotation encoding="application/x-llamapun" id="S5.F7.6.6.2.m1.2d">italic_R italic_G = 0 , italic_M italic_T = 1</annotation></semantics></math></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:70%;"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S5.F7.15.1.1" style="font-size:129%;">Figure 7</span>: </span><span class="ltx_text" id="S5.F7.16.2" style="font-size:129%;">Training <span class="ltx_text ltx_font_smallcaps" id="S5.F7.16.2.1">ZeroComp</span> on InteriorVerse <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib91" title="">91</a>]</cite> significantly enhances its performance with shiny objects by allowing precise control over roughness and metallic properties.</span></figcaption>
</figure>
<figure class="ltx_figure" id="S5.F8">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S5.F8.3">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.F8.3.3">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.F8.1.1.1" style="padding-left:1.0pt;padding-right:1.0pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="192" id="S5.F8.1.1.1.g1" src="extracted/5908513/figures/dominant_light_source/outdoor/1.jpg" width="192"/></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.F8.2.2.2" style="padding-left:1.0pt;padding-right:1.0pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="192" id="S5.F8.2.2.2.g1" src="extracted/5908513/figures/dominant_light_source/outdoor/2.jpg" width="192"/></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.F8.3.3.3" style="padding-left:1.0pt;padding-right:1.0pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="192" id="S5.F8.3.3.3.g1" src="extracted/5908513/figures/dominant_light_source/outdoor/3.jpg" width="192"/></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:80%;"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S5.F8.8.1.1" style="font-size:113%;">Figure 8</span>: </span><span class="ltx_text ltx_font_smallcaps" id="S5.F8.9.2" style="font-size:113%;">ZeroComp<span class="ltx_text ltx_font_upright" id="S5.F8.9.2.1"> generalizes to outdoor scenes, despite being trained exclusively on indoor scenes. Note how the object shading and cast shadows seamlessly blend with the target background.</span></span></figcaption>
</figure>
<figure class="ltx_figure" id="S5.F9">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S5.F9.6">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.F9.3.3">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.F9.1.1.1" style="padding-left:1.0pt;padding-right:1.0pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="192" id="S5.F9.1.1.1.g1" src="extracted/5908513/figures/real_world/cylinder/obj.jpg" width="192"/></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.F9.2.2.2" style="padding-left:1.0pt;padding-right:1.0pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="192" id="S5.F9.2.2.2.g1" src="extracted/5908513/figures/real_world/cylinder/dst_pixel_values.jpg" width="192"/></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.F9.3.3.3" style="padding-left:1.0pt;padding-right:1.0pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="192" id="S5.F9.3.3.3.g1" src="extracted/5908513/figures/real_world/cylinder/post_comp.jpg" width="192"/></td>
</tr>
<tr class="ltx_tr" id="S5.F9.6.6">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.F9.4.4.1" style="padding-left:1.0pt;padding-right:1.0pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="192" id="S5.F9.4.4.1.g1" src="extracted/5908513/figures/real_world/dog/obj_src_obj.jpg" width="192"/></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.F9.5.5.2" style="padding-left:1.0pt;padding-right:1.0pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="192" id="S5.F9.5.5.2.g1" src="extracted/5908513/figures/real_world/dog/dst_pixel_values.jpg" width="192"/></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.F9.6.6.3" style="padding-left:1.0pt;padding-right:1.0pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="192" id="S5.F9.6.6.3.g1" src="extracted/5908513/figures/real_world/dog/post_comp.jpg" width="192"/></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S5.F9.9.1.1" style="font-size:90%;">Figure 9</span>: </span><span class="ltx_text" id="S5.F9.10.2" style="font-size:90%;">Using <span class="ltx_text ltx_font_smallcaps" id="S5.F9.10.2.1">ZeroComp</span> to composite real 2D objects without access to a 3D model. Intrinsic maps for both the object image and the target background are estimated separately, then composited together and fed to our pipeline. Examples are displayed left to right: object, target background, and predicted composite.</span></figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S5.SS5.p1">
<p class="ltx_p" id="S5.SS5.p1.1"><span class="ltx_text ltx_font_bold" id="S5.SS5.p1.1.1">Material editing.</span> By training on additional intrinsic maps such as roughness and metallic available in the InteriorVerse dataset <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#bib.bib91" title="">91</a>]</cite>, <span class="ltx_text ltx_font_smallcaps" id="S5.SS5.p1.1.2">ZeroComp</span> can also adjust the materials of the virtual object.
In <a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#S5.F7" title="In 5.5 Extensions ‣ 5 Evaluation ‣ ZeroComp: Zero-shot Object Compositing from Image Intrinsics via Diffusion"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">7</span></a>, we modify the roughness (RG) and metallicity (MT) to demonstrate the effectiveness of <span class="ltx_text ltx_font_smallcaps" id="S5.SS5.p1.1.3">ZeroComp</span> in handling more advanced materials.</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS5.p2">
<p class="ltx_p" id="S5.SS5.p2.1"><span class="ltx_text ltx_font_bold" id="S5.SS5.p2.1.1">Outdoor images.</span> Despite being trained only on indoor imagery, <span class="ltx_text ltx_font_smallcaps" id="S5.SS5.p2.1.2">ZeroComp</span> also generalizes to outdoor scenes and can generate realistic shadows, as demonstrated in <a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#S5.F8" title="In 5.5 Extensions ‣ 5 Evaluation ‣ ZeroComp: Zero-shot Object Compositing from Image Intrinsics via Diffusion"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">8</span></a>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS5.p3">
<p class="ltx_p" id="S5.SS5.p3.1"><span class="ltx_text ltx_font_bold" id="S5.SS5.p3.1.1">2D object compositing.</span> <span class="ltx_text ltx_font_smallcaps" id="S5.SS5.p3.1.2">ZeroComp</span> can also be applied to 2D objects segmented from real images, where a 3D model is not available. Here, we rely on intrinsic estimators (<a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#S3.SS2" title="3.2 Zero-shot object compositing using ZeroComp ‣ 3 ZeroComp ‣ ZeroComp: Zero-shot Object Compositing from Image Intrinsics via Diffusion"><span class="ltx_text ltx_ref_tag">Sec.</span> <span class="ltx_text ltx_ref_tag">3.2</span></a>) to estimate the object depth and normals. We use the RGB as the albedo to avoid detrimental noise in the image texture while keeping the rest of the pipeline unchanged. For demonstration purposes, the object was segmented and placed in the target image manually. <a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#S5.F9" title="In 5.5 Extensions ‣ 5 Evaluation ‣ ZeroComp: Zero-shot Object Compositing from Image Intrinsics via Diffusion"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">9</span></a> shows several such examples, showing our method can be easily extended to the case of 2D object compositing.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Discussion</h2>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">We present <span class="ltx_text ltx_font_smallcaps" id="S6.p1.1.1">ZeroComp</span>, a novel approach for creating realistic image composites with intricate lighting interactions between virtual objects and scenes. Our method achieves zero-shot compositing by training on the simpler proxy task of reconstructing an image from its intrinsic layers using readily available datasets, simplifying the training procedure. Moreover, we present a comprehensive evaluation dataset for 3D object composition in real images, where our method exhibits favorable performance compared to various light estimation and generative techniques. Through an extensive user study using the same dataset, we demonstrate that <span class="ltx_text ltx_font_smallcaps" id="S6.p1.1.2">ZeroComp</span> achieves the highest perceptual scores among recent methods. This also suggests the need for reliable quantitative metrics for lighting estimation.</p>
</div>
<div class="ltx_para ltx_noindent" id="S6.p2">
<p class="ltx_p" id="S6.p2.1"><span class="ltx_text ltx_font_bold" id="S6.p2.1.1">Limitations.</span>
<span class="ltx_text ltx_font_smallcaps" id="S6.p2.1.2">ZeroComp</span> depends on intrinsic estimators to decompose the background image. While the model shows robustness to these estimators (see supplement), even with synthetic training data, errors in their predictions can affect rendering quality. Nonetheless, <span class="ltx_text ltx_font_smallcaps" id="S6.p2.1.3">ZeroComp</span> has demonstrated impressive results when fully leveraging estimated albedo and shading for both the background and inserted objects (see <a class="ltx_ref" href="https://arxiv.org/html/2410.08168v1#S5.F9" title="In 5.5 Extensions ‣ 5 Evaluation ‣ ZeroComp: Zero-shot Object Compositing from Image Intrinsics via Diffusion"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">9</span></a>), suggesting that non-synthetic training data could enhance the model’s robustness.</p>
</div>
<section class="ltx_paragraph" id="S6.SS0.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Acknowledgements</h4>
<div class="ltx_para" id="S6.SS0.SSS0.Px1.p1">
<p class="ltx_p" id="S6.SS0.SSS0.Px1.p1.1">This research was supported by NSERC grants RGPIN 2020-04799 and ALLRP 586543-23, Mitacs and Depix. Computing resources were provided by the Digital Research Alliance of Canada. The authors thank Louis-Étienne Messier and Justine Giroux for their help as well as all members of the lab for discussions and proofreading help.</p>
</div>
</section>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography" style="font-size:90%;">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib1.1.1" style="font-size:90%;">
Pontus Andersson, Jim Nilsson, Tomas Akenine-Möller, Magnus Oskarsson, Kalle Åström, and Mark D Fairchild.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib1.2.1" style="font-size:90%;">Flip: A difference evaluator for alternating images.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib1.3.1" style="font-size:90%;">Proc. ACM Comput. Graph. Interact. Tech.</span><span class="ltx_text" id="bib.bib1.4.2" style="font-size:90%;">, 3(2):15–1, 2020.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib2.1.1" style="font-size:90%;">
Gwangbin Bae and Andrew J. Davison.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib2.2.1" style="font-size:90%;">Rethinking inductive biases for surface normal estimation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib2.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib2.4.2" style="font-size:90%;">IEEE Conf. Comput. Vis. Pattern Recog.</span><span class="ltx_text" id="bib.bib2.5.3" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib3.1.1" style="font-size:90%;">
Harry Barrow, J Tenenbaum, A Hanson, and E Riseman.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib3.2.1" style="font-size:90%;">Recovering intrinsic scene characteristics.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib3.3.1" style="font-size:90%;">Comput. vis. syst</span><span class="ltx_text" id="bib.bib3.4.2" style="font-size:90%;">, 2(3-26):2, 1978.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib4.1.1" style="font-size:90%;">
Shariq Farooq Bhat, Reiner Birkl, Diana Wofk, Peter Wonka, and Matthias Müller.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib4.2.1" style="font-size:90%;">Zoedepth: Zero-shot transfer by combining relative and metric depth.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib4.3.1" style="font-size:90%;">arXiv preprint arXiv:2302.12288</span><span class="ltx_text" id="bib.bib4.4.2" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib5.1.1" style="font-size:90%;">
Anand Bhattad and David A Forsyth.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib5.2.1" style="font-size:90%;">Cut-and-paste object insertion by enabling deep image prior for reshading.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib5.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib5.4.2" style="font-size:90%;">Int. Conf. 3D Vis.</span><span class="ltx_text" id="bib.bib5.5.3" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib6.1.1" style="font-size:90%;">
Anand Bhattad, Daniel McKee, Derek Hoiem, and David Forsyth.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib6.2.1" style="font-size:90%;">Stylegan knows normal, depth, albedo, and more.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib6.3.1" style="font-size:90%;">Advances in Neural Information Processing Systems</span><span class="ltx_text" id="bib.bib6.4.2" style="font-size:90%;">, 36, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib7.1.1" style="font-size:90%;">
Anand Bhattad, Viraj Shah, Derek Hoiem, and David A Forsyth.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib7.2.1" style="font-size:90%;">Make it so: Steering stylegan for any image inversion and editing.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib7.3.1" style="font-size:90%;">arXiv preprint arXiv:2304.14403</span><span class="ltx_text" id="bib.bib7.4.2" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib8.1.1" style="font-size:90%;">
Anand Bhattad, James Soole, and DA Forsyth.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib8.2.1" style="font-size:90%;">Stylitgan: Image-based relighting via latent control.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib8.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib8.4.2" style="font-size:90%;">IEEE Conf. Comput. Vis. Pattern Recog.</span><span class="ltx_text" id="bib.bib8.5.3" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib9.1.1" style="font-size:90%;">
Peter J Burt and Edward H Adelson.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib9.2.1" style="font-size:90%;">A multiresolution spline with application to image mosaics.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib9.3.1" style="font-size:90%;">ACM Trans. Graph.</span><span class="ltx_text" id="bib.bib9.4.2" style="font-size:90%;">, 2(4):217–236, 1983.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib10.1.1" style="font-size:90%;">
Chris Careaga and Yağız Aksoy.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib10.2.1" style="font-size:90%;">Intrinsic image decomposition via ordinal shading.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib10.3.1" style="font-size:90%;">ACM Trans. Graph.</span><span class="ltx_text" id="bib.bib10.4.2" style="font-size:90%;">, 43(1):1–24, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib11.1.1" style="font-size:90%;">
Chris Careaga, S Mahdi H Miangoleh, and Yağız Aksoy.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib11.2.1" style="font-size:90%;">Intrinsic harmonization for illumination-aware compositing.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib11.3.1" style="font-size:90%;">ACM Trans. Graph.</span><span class="ltx_text" id="bib.bib11.4.2" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib12.1.1" style="font-size:90%;">
Xi Chen, Lianghua Huang, Yu Liu, Yujun Shen, Deli Zhao, and Hengshuang Zhao.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib12.2.1" style="font-size:90%;">Anydoor: Zero-shot object-level image customization.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib12.3.1" style="font-size:90%;">arXiv preprint arXiv:2307.09481</span><span class="ltx_text" id="bib.bib12.4.2" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib13.1.1" style="font-size:90%;">
JunYong Choi, SeokYeong Lee, Haesol Park, Seung-Won Jung, Ig-Jae Kim, and Junghyun Cho.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib13.2.1" style="font-size:90%;">Mair: multi-view attention inverse rendering with 3d spatially-varying lighting estimation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib13.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib13.4.2" style="font-size:90%;">IEEE Conf. Comput. Vis. Pattern Recog.</span><span class="ltx_text" id="bib.bib13.5.3" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib14.1.1" style="font-size:90%;">
Yung-Yu Chuang, Dan B Goldman, Brian Curless, David H Salesin, and Richard Szeliski.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib14.2.1" style="font-size:90%;">Shadow matting and compositing.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib14.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib14.4.2" style="font-size:90%;">ACM SIGGRAPH Conf.</span><span class="ltx_text" id="bib.bib14.5.3" style="font-size:90%;">, 2003.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib15.1.1" style="font-size:90%;">
Jasmine Collins, Shubham Goel, Kenan Deng, Achleshwar Luthra, Leon Xu, Erhan Gundogdu, Xi Zhang, Tomas F Yago Vicente, Thomas Dideriksen, Himanshu Arora, Matthieu Guillaumin, and Jitendra Malik.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib15.2.1" style="font-size:90%;">ABO: Dataset and benchmarks for real-world 3d object understanding.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib15.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib15.4.2" style="font-size:90%;">IEEE Conf. Comput. Vis. Pattern Recog.</span><span class="ltx_text" id="bib.bib15.5.3" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib16.1.1" style="font-size:90%;">
Blender Online Community.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib16.2.1" style="font-size:90%;">Blender - a 3D modelling and rendering package</span><span class="ltx_text" id="bib.bib16.3.2" style="font-size:90%;">.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib16.4.1" style="font-size:90%;">Blender Foundation, Stichting Blender Foundation, Amsterdam, 2018.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib17.1.1" style="font-size:90%;">
Mohammad Reza Karimi Dastjerdi, Jonathan Eisenmann, Yannick Hold-Geoffroy, and Jean-François Lalonde.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib17.2.1" style="font-size:90%;">Everlight: Indoor-outdoor editable HDR lighting estimation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib17.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib17.4.2" style="font-size:90%;">Int. Conf. Comput. Vis.</span><span class="ltx_text" id="bib.bib17.5.3" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib18.1.1" style="font-size:90%;">
Paul Debevec.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib18.2.1" style="font-size:90%;">Rendering synthetic objects into real scenes: Bridging traditional and image-based graphics with global illumination and high dynamic range photography.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib18.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib18.4.2" style="font-size:90%;">Conf. Comp. Graph. Int. Tech.</span><span class="ltx_text" id="bib.bib18.5.3" style="font-size:90%;">, ACM SIGGRAPH Conf., pages 189–198, 1998.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib19.1.1" style="font-size:90%;">
Xiaodan Du, Nicholas Kolkin, Greg Shakhnarovich, and Anand Bhattad.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib19.2.1" style="font-size:90%;">Generative models: What do they know? do they know things? let’s find out!
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib19.3.1" style="font-size:90%;">arXiv preprint arXiv:2311.17137</span><span class="ltx_text" id="bib.bib19.4.2" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib20.1.1" style="font-size:90%;">
Elena Garces, Carlos Rodriguez-Pardo, Dan Casas, and Jorge Lopez-Moreno.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib20.2.1" style="font-size:90%;">A survey on intrinsic images: Delving deep into lambert and beyond.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib20.3.1" style="font-size:90%;">International Journal of Computer Vision</span><span class="ltx_text" id="bib.bib20.4.2" style="font-size:90%;">, 130(3):836–868, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib21.1.1" style="font-size:90%;">
Marc-André Gardner, Yannick Hold-Geoffroy, Kalyan Sunkavalli, Christian Gagné, and Jean-François Lalonde.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib21.2.1" style="font-size:90%;">Deep parametric indoor lighting estimation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib21.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib21.4.2" style="font-size:90%;">Int. Conf. Comput. Vis.</span><span class="ltx_text" id="bib.bib21.5.3" style="font-size:90%;">, 2019.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib22.1.1" style="font-size:90%;">
Marc-André Gardner, Kalyan Sunkavalli, Ersin Yumer, Xiaohui Shen, Emiliano Gambaretto, Christian Gagné, and Jean-François Lalonde.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib22.2.1" style="font-size:90%;">Learning to predict indoor illumination from a single image.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib22.3.1" style="font-size:90%;">ACM Trans. Graph.</span><span class="ltx_text" id="bib.bib22.4.2" style="font-size:90%;">, 9(4), 2017.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib23.1.1" style="font-size:90%;">
Mathieu Garon, Kalyan Sunkavalli, Sunil Hadap, Nathan Carr, and Jean-François Lalonde.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib23.2.1" style="font-size:90%;">Fast spatially-varying indoor lighting estimation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib23.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib23.4.2" style="font-size:90%;">IEEE Conf. Comput. Vis. Pattern Recog.</span><span class="ltx_text" id="bib.bib23.5.3" style="font-size:90%;">, 2019.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib24.1.1" style="font-size:90%;">
Yunhao Ge, Hong-Xing Yu, Cheng Zhao, Yuliang Guo, Xinyu Huang, Liu Ren, Laurent Itti, and Jiajun Wu.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib24.2.1" style="font-size:90%;">3d copy-paste: Physically plausible object insertion for monocular 3d detection.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib24.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib24.4.2" style="font-size:90%;">Adv. Neural Inform. Process. Syst.</span><span class="ltx_text" id="bib.bib24.5.3" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib25.1.1" style="font-size:90%;">
Chen Geng, Hong-Xing Yu, Sharon Zhang, Maneesh Agrawala, and Jiajun Wu.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib25.2.1" style="font-size:90%;">Tree-structured shading decomposition.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib25.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib25.4.2" style="font-size:90%;">Int. Conf. Comput. Vis.</span><span class="ltx_text" id="bib.bib25.5.3" style="font-size:90%;">, pages 488–498, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib26.1.1" style="font-size:90%;">
Sara Ghazanfari, Alexandre Araujo, Prashanth Krishnamurthy, Farshad Khorrami, and Siddharth Garg.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib26.2.1" style="font-size:90%;">Lipsim: A provably robust perceptual similarity metric.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib26.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib26.4.2" style="font-size:90%;">Int. Conf. Learn. Represent.</span><span class="ltx_text" id="bib.bib26.5.3" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib27.1.1" style="font-size:90%;">
Justine Giroux, Mohammad Reza Karimi Dastjerdi, Yannick Hold-Geoffroy, Javier Vazquez-Corral, and Jean-François Lalonde.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib27.2.1" style="font-size:90%;">Towards a perceptual evaluation framework for lighting estimation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib27.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib27.4.2" style="font-size:90%;">IEEE Conf. Comput. Vis. Pattern Recog.</span><span class="ltx_text" id="bib.bib27.5.3" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib28.1.1" style="font-size:90%;">
Ian J Goodfellow, Jonathon Shlens, and Christian Szegedy.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib28.2.1" style="font-size:90%;">Explaining and harnessing adversarial examples.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib28.3.1" style="font-size:90%;">arXiv preprint arXiv:1412.6572</span><span class="ltx_text" id="bib.bib28.4.2" style="font-size:90%;">, 2014.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib29.1.1" style="font-size:90%;">
Zonghui Guo, Haiyong Zheng, Yufeng Jiang, Zhaorui Gu, and Bing Zheng.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib29.2.1" style="font-size:90%;">Intrinsic image harmonization.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib29.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib29.4.2" style="font-size:90%;">IEEE Conf. Comput. Vis. Pattern Recog.</span><span class="ltx_text" id="bib.bib29.5.3" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib30.1.1" style="font-size:90%;">
Yannick Hold-Geoffroy, Kalyan Sunkavalli, Sunil Hadap, Emiliano Gambaretto, and Jean-François Lalonde.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib30.2.1" style="font-size:90%;">Deep outdoor illumination estimation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib30.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib30.4.2" style="font-size:90%;">IEEE Conf. Comput. Vis. Pattern Recog.</span><span class="ltx_text" id="bib.bib30.5.3" style="font-size:90%;">, 2017.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib31.1.1" style="font-size:90%;">
Edward J Hu, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, Weizhu Chen, et al.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib31.2.1" style="font-size:90%;">Lora: Low-rank adaptation of large language models.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib31.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib31.4.2" style="font-size:90%;">Int. Conf. Learn. Represent.</span><span class="ltx_text" id="bib.bib31.5.3" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib32.1.1" style="font-size:90%;">
Linyi Jin, Jianming Zhang, Yannick Hold-Geoffroy, Oliver Wang, Kevin Blackburn-Matzen, Matthew Sticha, and David F Fouhey.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib32.2.1" style="font-size:90%;">Perspective fields for single image camera calibration.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib32.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib32.4.2" style="font-size:90%;">IEEE Conf. Comput. Vis. Pattern Recog.</span><span class="ltx_text" id="bib.bib32.5.3" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib33.1.1" style="font-size:90%;">
Kevin Karsch, Varsha Hedau, David Forsyth, and Derek Hoiem.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib33.2.1" style="font-size:90%;">Rendering synthetic objects into legacy photographs.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib33.3.1" style="font-size:90%;">ACM Trans. Graph.</span><span class="ltx_text" id="bib.bib33.4.2" style="font-size:90%;">, 30(6):1–12, 2011.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib34.1.1" style="font-size:90%;">
Kevin Karsch, Kalyan Sunkavalli, Sunil Hadap, Nathan Carr, Hailin Jin, Rafael Fonte, Michael Sittig, and David Forsyth.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib34.2.1" style="font-size:90%;">Automatic scene inference for 3d object compositing.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib34.3.1" style="font-size:90%;">ACM Trans. Graph.</span><span class="ltx_text" id="bib.bib34.4.2" style="font-size:90%;">, 33(3):1–15, 2014.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib35.1.1" style="font-size:90%;">
Markus Kettunen, Erik Härkönen, and Jaakko Lehtinen.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib35.2.1" style="font-size:90%;">E-lpips: robust perceptual image similarity via random transformation ensembles.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib35.3.1" style="font-size:90%;">arXiv preprint arXiv:1906.03973</span><span class="ltx_text" id="bib.bib35.4.2" style="font-size:90%;">, 2019.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib36.1.1" style="font-size:90%;">
Peter Kocsis, Julien Philip, Kalyan Sunkavalli, Matthias Nießner, and Yannick Hold-Geoffroy.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib36.2.1" style="font-size:90%;">Lightit: Illumination modeling and control for diffusion models.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib36.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib36.4.2" style="font-size:90%;">IEEE Conf. Comput. Vis. Pattern Recog.</span><span class="ltx_text" id="bib.bib36.5.3" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib37.1.1" style="font-size:90%;">
Peter Kocsis, Vincent Sitzmann, and Matthias Nießner.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib37.2.1" style="font-size:90%;">Intrinsic image diffusion for indoor single-view material estimation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib37.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib37.4.2" style="font-size:90%;">IEEE Conf. Comput. Vis. Pattern Recog.</span><span class="ltx_text" id="bib.bib37.5.3" style="font-size:90%;">, pages 5198–5208, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib38.1.1" style="font-size:90%;">
Peter Kocsis, Vincent Sitzmann, and Matthias Nießner.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib38.2.1" style="font-size:90%;">Intrinsic image diffusion for single-view material estimation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib38.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib38.4.2" style="font-size:90%;">IEEE Conf. Comput. Vis. Pattern Recog.</span><span class="ltx_text" id="bib.bib38.5.3" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib39.1.1" style="font-size:90%;">
Balazs Kovacs, Sean Bell, Noah Snavely, and Kavita Bala.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib39.2.1" style="font-size:90%;">Shading annotations in the wild.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib39.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib39.4.2" style="font-size:90%;">IEEE Conf. Comput. Vis. Pattern Recog.</span><span class="ltx_text" id="bib.bib39.5.3" style="font-size:90%;">, pages 6998–7007, 2017.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib40.1.1" style="font-size:90%;">
Jean-Francois Lalonde and Alexei A Efros.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib40.2.1" style="font-size:90%;">Using color compatibility for assessing image realism.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib40.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib40.4.2" style="font-size:90%;">Int. Conf. Comput. Vis.</span><span class="ltx_text" id="bib.bib40.5.3" style="font-size:90%;">, 2007.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib41.1.1" style="font-size:90%;">
Jean-François Lalonde, Derek Hoiem, Alexei A Efros, Carsten Rother, John Winn, and Antonio Criminisi.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib41.2.1" style="font-size:90%;">Photo clip art.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib41.3.1" style="font-size:90%;">ACM Trans. Graph.</span><span class="ltx_text" id="bib.bib41.4.2" style="font-size:90%;">, 26(3), 2007.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib42.1.1" style="font-size:90%;">
Zhengqin Li, Mohammad Shafiei, Ravi Ramamoorthi, Kalyan Sunkavalli, and Manmohan Chandraker.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib42.2.1" style="font-size:90%;">Inverse rendering for complex indoor scenes: Shape, spatially-varying lighting and svbrdf from a single image.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib42.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib42.4.2" style="font-size:90%;">IEEE Conf. Comput. Vis. Pattern Recog.</span><span class="ltx_text" id="bib.bib42.5.3" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib43.1.1" style="font-size:90%;">
Zhengqin Li, Jia Shi, Sai Bi, Rui Zhu, Kalyan Sunkavalli, Miloš Hašan, Zexiang Xu, Ravi Ramamoorthi, and Manmohan Chandraker.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib43.2.1" style="font-size:90%;">Physically-based editing of indoor scene lighting from a single image.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib43.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib43.4.2" style="font-size:90%;">Eur. Conf. Comput. Vis.</span><span class="ltx_text" id="bib.bib43.5.3" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_tag_bibitem">[44]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib44.1.1" style="font-size:90%;">
Zhengqin Li, Ting-Wei Yu, Shen Sang, Sarah Wang, Meng Song, Yuhan Liu, Yu-Ying Yeh, Rui Zhu, Nitesh Gundavarapu, Jia Shi, et al.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib44.2.1" style="font-size:90%;">Openrooms: An end-to-end open framework for photorealistic indoor scene datasets.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib44.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib44.4.2" style="font-size:90%;">IEEE Conf. Comput. Vis. Pattern Recog.</span><span class="ltx_text" id="bib.bib44.5.3" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_tag_bibitem">[45]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib45.1.1" style="font-size:90%;">
Shanchuan Lin, Bingchen Liu, Jiashi Li, and Xiao Yang.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib45.2.1" style="font-size:90%;">Common diffusion noise schedules and sample steps are flawed.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib45.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib45.4.2" style="font-size:90%;">IEEE/CVF Winter Conf. App. Comp. Vis.</span><span class="ltx_text" id="bib.bib45.5.3" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib46">
<span class="ltx_tag ltx_tag_bibitem">[46]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib46.1.1" style="font-size:90%;">
Daquan Liu, Chengjiang Long, Hongpan Zhang, Hanning Yu, Xinzhi Dong, and Chunxia Xiao.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib46.2.1" style="font-size:90%;">Arshadowgan: Shadow generative adversarial network for augmented reality in single light scenes.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib46.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib46.4.2" style="font-size:90%;">IEEE Conf. Comput. Vis. Pattern Recog.</span><span class="ltx_text" id="bib.bib46.5.3" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib47">
<span class="ltx_tag ltx_tag_bibitem">[47]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib47.1.1" style="font-size:90%;">
Jundan Luo, Duygu Ceylan, Jae Shin Yoon, Nanxuan Zhao, Julien Philip, Anna Frühstück, Wenbin Li, Christian Richardt, and Tuanfeng Wang.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib47.2.1" style="font-size:90%;">Intrinsicdiffusion: Joint intrinsic layers from latent diffusion models.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib47.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib47.4.2" style="font-size:90%;">ACM SIGGRAPH Conf.</span><span class="ltx_text" id="bib.bib47.5.3" style="font-size:90%;">, pages 1–11, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib48">
<span class="ltx_tag ltx_tag_bibitem">[48]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib48.1.1" style="font-size:90%;">
Oscar Michel, Anand Bhattad, Eli VanderBilt, Ranjay Krishna, Aniruddha Kembhavi, and Tanmay Gupta.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib48.2.1" style="font-size:90%;">Object 3dit: Language-guided 3d-aware image editing.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib48.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib48.4.2" style="font-size:90%;">Adv. Neural Inform. Process. Syst.</span><span class="ltx_text" id="bib.bib48.5.3" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib49">
<span class="ltx_tag ltx_tag_bibitem">[49]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib49.1.1" style="font-size:90%;">
Patrick Pérez, Michel Gangnet, and Andrew Blake.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib49.2.1" style="font-size:90%;">Poisson image editing.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib49.3.1" style="font-size:90%;">ACM Trans. Graph.</span><span class="ltx_text" id="bib.bib49.4.2" style="font-size:90%;">, 22(3), 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib50">
<span class="ltx_tag ltx_tag_bibitem">[50]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib50.1.1" style="font-size:90%;">
Julien Philip, Michaël Gharbi, Tinghui Zhou, Alexei A Efros, and George Drettakis.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib50.2.1" style="font-size:90%;">Multi-view relighting using a geometry-aware network.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib50.3.1" style="font-size:90%;">ACM Trans. Graph.</span><span class="ltx_text" id="bib.bib50.4.2" style="font-size:90%;">, 38(4):78–1, 2019.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib51">
<span class="ltx_tag ltx_tag_bibitem">[51]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib51.1.1" style="font-size:90%;">
Pakkapon Phongthawee, Worameth Chinchuthakun, Nontaphat Sinsunthithet, Varun Jampani, Amit Raj, Pramook Khungurn, and Supasorn Suwajanakorn.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib51.2.1" style="font-size:90%;">Diffusionlight: Light probes for free by painting a chrome ball.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib51.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib51.4.2" style="font-size:90%;">IEEE Conf. Comput. Vis. Pattern Recog.</span><span class="ltx_text" id="bib.bib51.5.3" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib52">
<span class="ltx_tag ltx_tag_bibitem">[52]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib52.1.1" style="font-size:90%;">
Francois Pitie, Anil C Kokaram, and Rozenn Dahyot.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib52.2.1" style="font-size:90%;">N-dimensional probability density function transfer and its application to color transfer.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib52.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib52.4.2" style="font-size:90%;">Int. Conf. Comput. Vis.</span><span class="ltx_text" id="bib.bib52.5.3" style="font-size:90%;">, 2005.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib53">
<span class="ltx_tag ltx_tag_bibitem">[53]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib53.1.1" style="font-size:90%;">
Yohan Poirier-Ginter, Alban Gauthier, Julien Phillip, Jean-François Lalonde, and George Drettakis.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib53.2.1" style="font-size:90%;">A diffusion approach to radiance field relighting using multi-illumination synthesis.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib53.3.1" style="font-size:90%;">Comput. Graph. Forum</span><span class="ltx_text" id="bib.bib53.4.2" style="font-size:90%;">, 43(4), 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib54">
<span class="ltx_tag ltx_tag_bibitem">[54]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib54.1.1" style="font-size:90%;">
Mani Ramanagopal, Sriram Narayanan, Aswin C Sankaranarayanan, and Srinivasa G Narasimhan.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib54.2.1" style="font-size:90%;">A theory of joint light and heat transport for lambertian scenes.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib54.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib54.4.2" style="font-size:90%;">IEEE Conf. Comput. Vis. Pattern Recog.</span><span class="ltx_text" id="bib.bib54.5.3" style="font-size:90%;">, pages 11924–11933, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib55">
<span class="ltx_tag ltx_tag_bibitem">[55]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib55.1.1" style="font-size:90%;">
Erik Reinhard, Michael Adhikhmin, Bruce Gooch, and Peter Shirley.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib55.2.1" style="font-size:90%;">Color transfer between images.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib55.3.1" style="font-size:90%;">IEEE Comp. Graph. Appl.</span><span class="ltx_text" id="bib.bib55.4.2" style="font-size:90%;">, 21(5):34–41, 2001.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib56">
<span class="ltx_tag ltx_tag_bibitem">[56]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib56.2.1" style="font-size:90%;">
Manuel Rey-Area, Mingze Yuan, and Christian Richardt.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib56.3.1" style="font-size:90%;">360monodepth: High-resolution </span><math alttext="360^{\circ}" class="ltx_Math" display="inline" id="bib.bib56.1.m1.1"><semantics id="bib.bib56.1.m1.1a"><msup id="bib.bib56.1.m1.1.1" xref="bib.bib56.1.m1.1.1.cmml"><mn id="bib.bib56.1.m1.1.1.2" mathsize="90%" xref="bib.bib56.1.m1.1.1.2.cmml">360</mn><mo id="bib.bib56.1.m1.1.1.3" mathsize="90%" xref="bib.bib56.1.m1.1.1.3.cmml">∘</mo></msup><annotation-xml encoding="MathML-Content" id="bib.bib56.1.m1.1b"><apply id="bib.bib56.1.m1.1.1.cmml" xref="bib.bib56.1.m1.1.1"><csymbol cd="ambiguous" id="bib.bib56.1.m1.1.1.1.cmml" xref="bib.bib56.1.m1.1.1">superscript</csymbol><cn id="bib.bib56.1.m1.1.1.2.cmml" type="integer" xref="bib.bib56.1.m1.1.1.2">360</cn><compose id="bib.bib56.1.m1.1.1.3.cmml" xref="bib.bib56.1.m1.1.1.3"></compose></apply></annotation-xml><annotation encoding="application/x-tex" id="bib.bib56.1.m1.1c">360^{\circ}</annotation><annotation encoding="application/x-llamapun" id="bib.bib56.1.m1.1d">360 start_POSTSUPERSCRIPT ∘ end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text" id="bib.bib56.4.2" style="font-size:90%;"> monocular depth estimation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib56.5.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib56.6.2" style="font-size:90%;">IEEE Conf. Comput. Vis. Pattern Recog.</span><span class="ltx_text" id="bib.bib56.7.3" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib57">
<span class="ltx_tag ltx_tag_bibitem">[57]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib57.1.1" style="font-size:90%;">
Mike Roberts, Jason Ramapuram, Anurag Ranjan, Atulit Kumar, Miguel Angel Bautista, Nathan Paczan, Russ Webb, and Joshua M. Susskind.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib57.2.1" style="font-size:90%;">Hypersim: A photorealistic synthetic dataset for holistic indoor scene understanding.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib57.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib57.4.2" style="font-size:90%;">Int. Conf. Comput. Vis.</span><span class="ltx_text" id="bib.bib57.5.3" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib58">
<span class="ltx_tag ltx_tag_bibitem">[58]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib58.1.1" style="font-size:90%;">
Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Björn Ommer.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib58.2.1" style="font-size:90%;">High-resolution image synthesis with latent diffusion models.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib58.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib58.4.2" style="font-size:90%;">IEEE Conf. Comput. Vis. Pattern Recog.</span><span class="ltx_text" id="bib.bib58.5.3" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib59">
<span class="ltx_tag ltx_tag_bibitem">[59]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib59.1.1" style="font-size:90%;">
Carsten Rother, Vladimir Kolmogorov, and Andrew Blake.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib59.2.1" style="font-size:90%;">Grabcut interactive foreground extraction using iterated graph cuts.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib59.3.1" style="font-size:90%;">ACM Trans. Graph.</span><span class="ltx_text" id="bib.bib59.4.2" style="font-size:90%;">, 23(3):309–314, 2004.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib60">
<span class="ltx_tag ltx_tag_bibitem">[60]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib60.1.1" style="font-size:90%;">
Prafull Sharma, Varun Jampani, Yuanzhen Li, Xuhui Jia, Dmitry Lagun, Fredo Durand, Bill Freeman, and Mark Matthews.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib60.2.1" style="font-size:90%;">Alchemist: Parametric control of material properties with diffusion models.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib60.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib60.4.2" style="font-size:90%;">IEEE Conf. Comput. Vis. Pattern Recog.</span><span class="ltx_text" id="bib.bib60.5.3" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib61">
<span class="ltx_tag ltx_tag_bibitem">[61]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib61.1.1" style="font-size:90%;">
Yichen Sheng, Yifan Liu, Jianming Zhang, Wei Yin, A Cengiz Oztireli, He Zhang, Zhe Lin, Eli Shechtman, and Bedrich Benes.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib61.2.1" style="font-size:90%;">Controllable shadow generation using pixel height maps.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib61.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib61.4.2" style="font-size:90%;">Eur. Conf. Comput. Vis.</span><span class="ltx_text" id="bib.bib61.5.3" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib62">
<span class="ltx_tag ltx_tag_bibitem">[62]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib62.1.1" style="font-size:90%;">
Yichen Sheng, Jianming Zhang, and Bedrich Benes.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib62.2.1" style="font-size:90%;">Ssn: Soft shadow network for image compositing.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib62.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib62.4.2" style="font-size:90%;">IEEE Conf. Comput. Vis. Pattern Recog.</span><span class="ltx_text" id="bib.bib62.5.3" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib63">
<span class="ltx_tag ltx_tag_bibitem">[63]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib63.1.1" style="font-size:90%;">
Yichen Sheng, Jianming Zhang, Julien Philip, Yannick Hold-Geoffroy, Xin Sun, He Zhang, Lu Ling, and Bedrich Benes.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib63.2.1" style="font-size:90%;">Pixht-lab: Pixel height based light effect generation for image compositing.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib63.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib63.4.2" style="font-size:90%;">IEEE Conf. Comput. Vis. Pattern Recog.</span><span class="ltx_text" id="bib.bib63.5.3" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib64">
<span class="ltx_tag ltx_tag_bibitem">[64]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib64.1.1" style="font-size:90%;">
Yizhi Song, Zhifei Zhang, Zhe Lin, Scott Cohen, Brian Price, Jianming Zhang, Soo Ye Kim, and Daniel Aliaga.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib64.2.1" style="font-size:90%;">Objectstitch: Generative object compositing.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib64.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib64.4.2" style="font-size:90%;">IEEE Conf. Comput. Vis. Pattern Recog.</span><span class="ltx_text" id="bib.bib64.5.3" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib65">
<span class="ltx_tag ltx_tag_bibitem">[65]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib65.1.1" style="font-size:90%;">
Pratul P Srinivasan, Ben Mildenhall, Matthew Tancik, Jonathan T Barron, Richard Tucker, and Noah Snavely.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib65.2.1" style="font-size:90%;">Lighthouse: Predicting lighting volumes for spatially-coherent illumination.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib65.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib65.4.2" style="font-size:90%;">IEEE Conf. Comput. Vis. Pattern Recog.</span><span class="ltx_text" id="bib.bib65.5.3" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib66">
<span class="ltx_tag ltx_tag_bibitem">[66]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib66.1.1" style="font-size:90%;">
Kalyan Sunkavalli, Micah K Johnson, Wojciech Matusik, and Hanspeter Pfister.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib66.2.1" style="font-size:90%;">Multi-scale image harmonization.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib66.3.1" style="font-size:90%;">ACM Trans. Graph.</span><span class="ltx_text" id="bib.bib66.4.2" style="font-size:90%;">, 29(4), 2010.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib67">
<span class="ltx_tag ltx_tag_bibitem">[67]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib67.1.1" style="font-size:90%;">
Michael W Tao, Micah K Johnson, and Sylvain Paris.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib67.2.1" style="font-size:90%;">Error-tolerant image compositing.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib67.3.1" style="font-size:90%;">Int. J. Comput. Vis.</span><span class="ltx_text" id="bib.bib67.4.2" style="font-size:90%;">, 103:178–189, 2013.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib68">
<span class="ltx_tag ltx_tag_bibitem">[68]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib68.1.1" style="font-size:90%;">
Yi-Hsuan Tsai, Xiaohui Shen, Zhe Lin, Kalyan Sunkavalli, Xin Lu, and Ming-Hsuan Yang.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib68.2.1" style="font-size:90%;">Deep image harmonization.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib68.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib68.4.2" style="font-size:90%;">IEEE Conf. Comput. Vis. Pattern Recog.</span><span class="ltx_text" id="bib.bib68.5.3" style="font-size:90%;">, 2017.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib69">
<span class="ltx_tag ltx_tag_bibitem">[69]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib69.1.1" style="font-size:90%;">
Lucas Valença, Jinsong Zhang, Michaël Gharbi, Yannick Hold-Geoffroy, and Jean-François Lalonde.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib69.2.1" style="font-size:90%;">Shadow harmonization for realistic compositing.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib69.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib69.4.2" style="font-size:90%;">ACM SIGGRAPH Asia Conf.</span><span class="ltx_text" id="bib.bib69.5.3" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib70">
<span class="ltx_tag ltx_tag_bibitem">[70]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib70.1.1" style="font-size:90%;">
Guangcong Wang, Yinuo Yang, Chen Change Loy, and Ziwei Liu.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib70.2.1" style="font-size:90%;">Stylelight: HDR panorama generation for lighting estimation and editing.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib70.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib70.4.2" style="font-size:90%;">Eur. Conf. Comput. Vis.</span><span class="ltx_text" id="bib.bib70.5.3" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib71">
<span class="ltx_tag ltx_tag_bibitem">[71]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib71.1.1" style="font-size:90%;">
Zhou Wang, Alan C. Bovik, Hamid R. Sheikh, and Eero P. Simoncelli.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib71.2.1" style="font-size:90%;">Image quality assessment: from error visibility to structural similarity.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib71.3.1" style="font-size:90%;">IEEE Trans. Image Process.</span><span class="ltx_text" id="bib.bib71.4.2" style="font-size:90%;">, 13(4):600–612, 2004.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib72">
<span class="ltx_tag ltx_tag_bibitem">[72]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib72.1.1" style="font-size:90%;">
Henrique Weber, Mathieu Garon, and Jean-François Lalonde.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib72.2.1" style="font-size:90%;">Editable indoor lighting estimation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib72.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib72.4.2" style="font-size:90%;">Eur. Conf. Comput. Vis.</span><span class="ltx_text" id="bib.bib72.5.3" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib73">
<span class="ltx_tag ltx_tag_bibitem">[73]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib73.1.1" style="font-size:90%;">
Jiaye Wu, Sanjoy Chowdhury, Hariharmano Shanmugaraja, David Jacobs, and Soumyadip Sengupta.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib73.2.1" style="font-size:90%;">Measured albedo in the wild: Filling the gap in intrinsics evaluation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib73.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib73.4.2" style="font-size:90%;">2023 IEEE International Conference on Computational Photography (ICCP)</span><span class="ltx_text" id="bib.bib73.5.3" style="font-size:90%;">, pages 1–12. IEEE, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib74">
<span class="ltx_tag ltx_tag_bibitem">[74]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib74.1.1" style="font-size:90%;">
Katherine Xu, Lingzhi Zhang, and Jianbo Shi.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib74.2.1" style="font-size:90%;">Good seed makes a good crop: Discovering secret seeds in text-to-image diffusion models, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib75">
<span class="ltx_tag ltx_tag_bibitem">[75]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib75.1.1" style="font-size:90%;">
Binxin Yang, Shuyang Gu, Bo Zhang, Ting Zhang, Xuejin Chen, Xiaoyan Sun, Dong Chen, and Fang Wen.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib75.2.1" style="font-size:90%;">Paint by example: Exemplar-based image editing with diffusion models.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib75.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib75.4.2" style="font-size:90%;">IEEE Conf. Comput. Vis. Pattern Recog.</span><span class="ltx_text" id="bib.bib75.5.3" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib76">
<span class="ltx_tag ltx_tag_bibitem">[76]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib76.1.1" style="font-size:90%;">
Chongjie Ye, Lingteng Qiu, Xiaodong Gu, Qi Zuo, Yushuang Wu, Zilong Dong, Liefeng Bo, Yuliang Xiu, and Xiaoguang Han.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib76.2.1" style="font-size:90%;">Stablenormal: Reducing diffusion variance for stable and sharp normal.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib76.3.1" style="font-size:90%;">arXiv preprint arXiv:2406.16864</span><span class="ltx_text" id="bib.bib76.4.2" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib77">
<span class="ltx_tag ltx_tag_bibitem">[77]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib77.1.1" style="font-size:90%;">
Hu Ye, Jun Zhang, Sibo Liu, Xiao Han, and Wei Yang.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib77.2.1" style="font-size:90%;">Ip-adapter: Text compatible image prompt adapter for text-to-image diffusion models.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib77.3.1" style="font-size:90%;">arXiv preprint arXiv:2308.06721</span><span class="ltx_text" id="bib.bib77.4.2" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib78">
<span class="ltx_tag ltx_tag_bibitem">[78]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib78.1.1" style="font-size:90%;">
Weicai Ye, Shuo Chen, Chong Bao, Hujun Bao, Marc Pollefeys, Zhaopeng Cui, and Guofeng Zhang.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib78.2.1" style="font-size:90%;">Intrinsicnerf: Learning intrinsic neural radiance fields for editable novel view synthesis.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib78.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib78.4.2" style="font-size:90%;">Int. Conf. Comput. Vis.</span><span class="ltx_text" id="bib.bib78.5.3" style="font-size:90%;">, pages 339–351, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib79">
<span class="ltx_tag ltx_tag_bibitem">[79]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib79.1.1" style="font-size:90%;">
Yusaku Yoshida, Ryo Kawahara, and Takahiro Okabe.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib79.2.1" style="font-size:90%;">Light source separation and intrinsic image decomposition under ac illumination.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib79.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib79.4.2" style="font-size:90%;">IEEE Conf. Comput. Vis. Pattern Recog.</span><span class="ltx_text" id="bib.bib79.5.3" style="font-size:90%;">, pages 5735–5743, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib80">
<span class="ltx_tag ltx_tag_bibitem">[80]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib80.1.1" style="font-size:90%;">
Ziyang Yuan, Mingdeng Cao, Xintao Wang, Zhongang Qi, Chun Yuan, and Ying Shan.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib80.2.1" style="font-size:90%;">Customnet: Zero-shot object customization with variable-viewpoints in text-to-image diffusion models.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib80.3.1" style="font-size:90%;">arXiv preprint arXiv:2310.19784</span><span class="ltx_text" id="bib.bib80.4.2" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib81">
<span class="ltx_tag ltx_tag_bibitem">[81]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib81.1.1" style="font-size:90%;">
Syed Waqas Zamir, Javier Vazquez-Corral, and Marcelo Bertalmio.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib81.2.1" style="font-size:90%;">Vision models for wide color gamut imaging in cinema.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib81.3.1" style="font-size:90%;">IEEE Trans. Pattern Anal. Mach. Intell.</span><span class="ltx_text" id="bib.bib81.4.2" style="font-size:90%;">, 43(5):1777–1790, 2019.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib82">
<span class="ltx_tag ltx_tag_bibitem">[82]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib82.1.1" style="font-size:90%;">
Chong Zeng, Yue Dong, Pieter Peers, Youkang Kong, Hongzhi Wu, and Xin Tong.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib82.2.1" style="font-size:90%;">DiLightNet: Fine-grained lighting control for diffusion-based image generation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib82.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib82.4.2" style="font-size:90%;">ACM SIGGRAPH Conf.</span><span class="ltx_text" id="bib.bib82.5.3" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib83">
<span class="ltx_tag ltx_tag_bibitem">[83]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib83.2.1" style="font-size:90%;">
Zheng Zeng, Valentin Deschaintre, Iliyan Georgiev, Yannick Hold-Geoffroy, Yiwei Hu, Fujun Luan, Ling-Qi Yan, and Miloš Hašan.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib83.3.1" style="font-size:90%;">RGB </span><math alttext="\leftrightarrow" class="ltx_Math" display="inline" id="bib.bib83.1.m1.1"><semantics id="bib.bib83.1.m1.1a"><mo id="bib.bib83.1.m1.1.1" mathsize="90%" stretchy="false" xref="bib.bib83.1.m1.1.1.cmml">↔</mo><annotation-xml encoding="MathML-Content" id="bib.bib83.1.m1.1b"><ci id="bib.bib83.1.m1.1.1.cmml" xref="bib.bib83.1.m1.1.1">↔</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib83.1.m1.1c">\leftrightarrow</annotation><annotation encoding="application/x-llamapun" id="bib.bib83.1.m1.1d">↔</annotation></semantics></math><span class="ltx_text" id="bib.bib83.4.2" style="font-size:90%;"> X: Image decomposition and synthesis using material-and lighting-aware diffusion models.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib83.5.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib83.6.2" style="font-size:90%;">ACM SIGGRAPH Conf.</span><span class="ltx_text" id="bib.bib83.7.3" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib84">
<span class="ltx_tag ltx_tag_bibitem">[84]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib84.1.1" style="font-size:90%;">
Fangneng Zhan, Changgong Zhang, Yingchen Yu, Yuan Chang, Shijian Lu, Feiying Ma, and Xuansong Xie.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib84.2.1" style="font-size:90%;">EMLight: Lighting Estimation via Spherical Distribution Approximation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib84.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib84.4.2" style="font-size:90%;">AAAI</span><span class="ltx_text" id="bib.bib84.5.3" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib85">
<span class="ltx_tag ltx_tag_bibitem">[85]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib85.1.1" style="font-size:90%;">
Bo Zhang, Yuxuan Duan, Jun Lan, Yan Hong, Huijia Zhu, Weiqiang Wang, and Li Niu.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib85.2.1" style="font-size:90%;">Controlcom: Controllable image composition using diffusion model.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib85.3.1" style="font-size:90%;">arXiv preprint arXiv:2308.10040</span><span class="ltx_text" id="bib.bib85.4.2" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib86">
<span class="ltx_tag ltx_tag_bibitem">[86]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib86.1.1" style="font-size:90%;">
Lvmin Zhang, Anyi Rao, and Maneesh Agrawala.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib86.2.1" style="font-size:90%;">Adding conditional control to text-to-image diffusion models.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib86.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib86.4.2" style="font-size:90%;">Int. Conf. Comput. Vis.</span><span class="ltx_text" id="bib.bib86.5.3" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib87">
<span class="ltx_tag ltx_tag_bibitem">[87]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib87.1.1" style="font-size:90%;">
Richard Zhang, Phillip Isola, Alexei A Efros, Eli Shechtman, and Oliver Wang.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib87.2.1" style="font-size:90%;">The unreasonable effectiveness of deep features as a perceptual metric.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib87.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib87.4.2" style="font-size:90%;">IEEE Conf. Comput. Vis. Pattern Recog.</span><span class="ltx_text" id="bib.bib87.5.3" style="font-size:90%;">, 2018.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib88">
<span class="ltx_tag ltx_tag_bibitem">[88]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib88.1.1" style="font-size:90%;">
Xin Zhang, Jiaxian Guo, Paul Yoo, Yutaka Matsuo, and Yusuke Iwasawa.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib88.2.1" style="font-size:90%;">Paste, inpaint and harmonize via denoising: Subject-driven image editing with pre-trained diffusion model.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib88.3.1" style="font-size:90%;">arXiv preprint arXiv:2306.07596</span><span class="ltx_text" id="bib.bib88.4.2" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib89">
<span class="ltx_tag ltx_tag_bibitem">[89]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib89.1.1" style="font-size:90%;">
Xiaoming Zhao, Pratul P. Srinivasan, Dor Verbin, Keunhong Park, Ricardo Martin Brualla, and Philipp Henzler.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib89.2.1" style="font-size:90%;">IllumiNeRF: 3D relighting without inverse rendering.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib89.3.1" style="font-size:90%;">ArXiv</span><span class="ltx_text" id="bib.bib89.4.2" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib90">
<span class="ltx_tag ltx_tag_bibitem">[90]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib90.1.1" style="font-size:90%;">
Tinghui Zhou, Philipp Krahenbuhl, and Alexei A Efros.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib90.2.1" style="font-size:90%;">Learning data-driven reflectance priors for intrinsic image decomposition.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib90.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib90.4.2" style="font-size:90%;">Int. Conf. Comput. Vis.</span><span class="ltx_text" id="bib.bib90.5.3" style="font-size:90%;">, pages 3469–3477, 2015.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib91">
<span class="ltx_tag ltx_tag_bibitem">[91]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib91.1.1" style="font-size:90%;">
Jingsen Zhu, Fujun Luan, Yuchi Huo, Zihao Lin, Zhihua Zhong, Dianbing Xi, Rui Wang, Hujun Bao, Jiaxiang Zheng, and Rui Tang.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib91.2.1" style="font-size:90%;">Learning-based inverse rendering of complex indoor scenes with differentiable monte carlo raytracing.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib91.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib91.4.2" style="font-size:90%;">ACM SIGGRAPH Asia Conf.</span><span class="ltx_text" id="bib.bib91.5.3" style="font-size:90%;"> ACM, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib92">
<span class="ltx_tag ltx_tag_bibitem">[92]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib92.1.1" style="font-size:90%;">
Rui Zhu, Zhengqin Li, Janarbek Matai, Fatih Porikli, and Manmohan Chandraker.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib92.2.1" style="font-size:90%;">Irisformer: Dense vision transformers for single-image inverse rendering in indoor scenes.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib92.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib92.4.2" style="font-size:90%;">IEEE Conf. Comput. Vis. Pattern Recog.</span><span class="ltx_text" id="bib.bib92.5.3" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib93">
<span class="ltx_tag ltx_tag_bibitem">[93]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib93.1.1" style="font-size:90%;">
Zixin Zhu, Xuelu Feng, Dongdong Chen, Jianmin Bao, Le Wang, Yinpeng Chen, Lu Yuan, and Gang Hua.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib93.2.1" style="font-size:90%;">Designing a better asymmetric vqgan for stablediffusion.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib93.3.1" style="font-size:90%;">arXiv preprint arXiv:2306.04632</span><span class="ltx_text" id="bib.bib93.4.2" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib94">
<span class="ltx_tag ltx_tag_bibitem">[94]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib94.1.1" style="font-size:90%;">
Daniel Zoran, Phillip Isola, Dilip Krishnan, and William T Freeman.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib94.2.1" style="font-size:90%;">Learning ordinal relationships for mid-level vision.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib94.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib94.4.2" style="font-size:90%;">Int. Conf. Comput. Vis.</span><span class="ltx_text" id="bib.bib94.5.3" style="font-size:90%;">, pages 388–396, 2015.
</span>
</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Thu Oct 10 15:57:31 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
