<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2405.17495] Vertical Federated Learning for Effectiveness, Security, Applicability: A Survey</title><meta property="og:description" content="Vertical Federated Learning (VFL) is a privacy-preserving distributed learning paradigm where different parties collaboratively learn models using partitioned features of shared samples, without leaking private data. R…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Vertical Federated Learning for Effectiveness, Security, Applicability: A Survey">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Vertical Federated Learning for Effectiveness, Security, Applicability: A Survey">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2405.17495">

<!--Generated on Wed Jun  5 16:30:01 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content="Survey,  Vertical Federated Learning,  Trustworthy AI">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line ltx_leqno">
<h1 class="ltx_title ltx_title_document">Vertical Federated Learning for Effectiveness, Security, Applicability: A Survey</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Mang Ye
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:yemang@whu.edu.cn">yemang@whu.edu.cn</a>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Wei Shen
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:weishen@whu.edu.cn">weishen@whu.edu.cn</a>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Bo Du
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:dubo@whu.edu.cn">dubo@whu.edu.cn</a>
</span>
<span class="ltx_contact ltx_role_affiliation"><span id="id1.1.id1" class="ltx_text ltx_affiliation_institution">The National Engineering Research Center for Multimedia Software, School of Computer Science, Wuhan University</span><span id="id2.2.id2" class="ltx_text ltx_affiliation_city">Wuhan</span><span id="id3.3.id3" class="ltx_text ltx_affiliation_country">China</span>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Eduard Snezhko
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:eduard.snezhko@gmail.com">eduard.snezhko@gmail.com</a>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Vassili Kovalev
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:vassili.kovalev@gmail.com">vassili.kovalev@gmail.com</a>
</span>
<span class="ltx_contact ltx_role_affiliation"><span id="id4.1.id1" class="ltx_text ltx_affiliation_institution">United Institute of Informatics Problems of Belarus National Academy of Sciences, National Academy of Sciences of Belarus</span><span id="id5.2.id2" class="ltx_text ltx_affiliation_city">Minsk</span><span id="id6.3.id3" class="ltx_text ltx_affiliation_country">Belarus</span>
</span></span></span>
<span class="ltx_author_before"> and </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Pong C. Yuen
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:pcyuen@comp.hkbu.edu.hk">pcyuen@comp.hkbu.edu.hk</a>
</span>
<span class="ltx_contact ltx_role_affiliation"><span id="id7.1.id1" class="ltx_text ltx_affiliation_institution">Department of Computer Science, Hong Kong Baptist University</span><span id="id8.2.id2" class="ltx_text ltx_affiliation_city">Hong Kong</span><span id="id9.3.id3" class="ltx_text ltx_affiliation_country">China</span>
</span></span></span>
</div>
<div class="ltx_dates">(2024)</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract.</h6>
<p id="id10.id1" class="ltx_p">Vertical Federated Learning (VFL) is a privacy-preserving distributed learning paradigm where different parties collaboratively learn models using partitioned features of shared samples, without leaking private data. Recent research has shown promising results addressing various challenges in VFL, highlighting its potential for practical applications in cross-domain collaboration. However, the corresponding research is scattered and lacks organization. To advance VFL research, this survey offers a systematic overview of recent developments. First, we provide a history and background introduction, along with a summary of the general training protocol of VFL. We then revisit the taxonomy in recent reviews and analyze limitations in-depth. For a comprehensive and structured discussion, we synthesize recent research from three fundamental perspectives: effectiveness, security, and applicability. Finally, we discuss several critical future research directions in VFL, which will facilitate the developments in this field. We provide a collection of research lists and periodically update them at <a target="_blank" href="https://github.com/shentt67/VFL_Survey" title="" class="ltx_ref ltx_href">https://github.com/shentt67/VFL_Survey</a>.</p>
</div>
<div class="ltx_keywords">Survey, Vertical Federated Learning, Trustworthy AI
</div>
<span id="id1" class="ltx_note ltx_note_frontmatter ltx_role_copyright"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">copyright: </span>acmlicensed</span></span></span><span id="id2" class="ltx_note ltx_note_frontmatter ltx_role_journalyear"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">journalyear: </span>2024</span></span></span><span id="id3" class="ltx_note ltx_note_frontmatter ltx_role_doi"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">doi: </span>XXXXXXX.XXXXXXX</span></span></span><span id="id4" class="ltx_note ltx_note_frontmatter ltx_role_isbn"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">isbn: </span>978-1-4503-XXXX-X/18/06</span></span></span><span id="id5" class="ltx_note ltx_note_frontmatter ltx_role_ccs"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">ccs: </span>General and reference Surveys and overviews</span></span></span><span id="id6" class="ltx_note ltx_note_frontmatter ltx_role_ccs"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">ccs: </span>Security and privacy Privacy-preserving protocols</span></span></span><span id="id7" class="ltx_note ltx_note_frontmatter ltx_role_ccs"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">ccs: </span>Computing methodologies Artificial intelligence</span></span></span>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1. </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">The rapid development of deep learning has created a significant demand for high-quality and large-quantity data. However, collecting sufficient data for training within a single party is often challenging. An intuitive solution is to collaborate by sharing data among multiple associated participants, but this valuable data often involves personal privacy concerns <cite class="ltx_cite ltx_citemacro_citep">(Fung et al<span class="ltx_text">.</span>, <a href="#bib.bib52" title="" class="ltx_ref">2010</a>; Wagner and Eckhoff, <a href="#bib.bib161" title="" class="ltx_ref">2018</a>; Liu et al<span class="ltx_text">.</span>, <a href="#bib.bib107" title="" class="ltx_ref">2021a</a>; Salehzadeh Niksirat et al<span class="ltx_text">.</span>, <a href="#bib.bib146" title="" class="ltx_ref">2024</a>; Ye et al<span class="ltx_text">.</span>, <a href="#bib.bib187" title="" class="ltx_ref">2024</a>; Han et al<span class="ltx_text">.</span>, <a href="#bib.bib62" title="" class="ltx_ref">2023</a>)</cite> or confidentiality agreements <cite class="ltx_cite ltx_citemacro_citep">(May and Sell, <a href="#bib.bib124" title="" class="ltx_ref">2005</a>; of Investigators for Fairness in Trial Data Sharing, <a href="#bib.bib131" title="" class="ltx_ref">2016</a>; GDPR, <a href="#bib.bib53" title="" class="ltx_ref">2018</a>; ccp, <a href="#bib.bib2" title="" class="ltx_ref">2018</a>; cdp, <a href="#bib.bib3" title="" class="ltx_ref">2018</a>)</cite>, which hinders data sharing and leads to data silos. As an alternative solution, Federated Learning (FL) <cite class="ltx_cite ltx_citemacro_citep">(Yang et al<span class="ltx_text">.</span>, <a href="#bib.bib180" title="" class="ltx_ref">2019</a>; McMahan et al<span class="ltx_text">.</span>, <a href="#bib.bib125" title="" class="ltx_ref">2017</a>; Li et al<span class="ltx_text">.</span>, <a href="#bib.bib102" title="" class="ltx_ref">2020c</a>; Yin et al<span class="ltx_text">.</span>, <a href="#bib.bib189" title="" class="ltx_ref">2021</a>; Huang et al<span class="ltx_text">.</span>, <a href="#bib.bib72" title="" class="ltx_ref">2023a</a>; Ye et al<span class="ltx_text">.</span>, <a href="#bib.bib186" title="" class="ltx_ref">2023</a>)</cite> has garnered increasing attention in research and applications. FL aims to collaboratively train models across participants without exposing raw data. Based on the distributed way of data, Federated Learning can be primarily categorized into three scenarios:</p>
</div>
<div id="S1.p2" class="ltx_para">
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p"><span id="S1.I1.i1.p1.1.1" class="ltx_text ltx_font_bold">Horizontal Federated Learning (HFL)</span> <cite class="ltx_cite ltx_citemacro_citep">(Yang et al<span class="ltx_text">.</span>, <a href="#bib.bib180" title="" class="ltx_ref">2019</a>; McMahan et al<span class="ltx_text">.</span>, <a href="#bib.bib125" title="" class="ltx_ref">2017</a>; Li et al<span class="ltx_text">.</span>, <a href="#bib.bib102" title="" class="ltx_ref">2020c</a>; Yin et al<span class="ltx_text">.</span>, <a href="#bib.bib189" title="" class="ltx_ref">2021</a>; Nguyen et al<span class="ltx_text">.</span>, <a href="#bib.bib128" title="" class="ltx_ref">2022</a>; Pfeiffer et al<span class="ltx_text">.</span>, <a href="#bib.bib132" title="" class="ltx_ref">2023</a>; Wu et al<span class="ltx_text">.</span>, <a href="#bib.bib168" title="" class="ltx_ref">2023a</a>; Qu et al<span class="ltx_text">.</span>, <a href="#bib.bib140" title="" class="ltx_ref">2022</a>; Fang and Ye, <a href="#bib.bib43" title="" class="ltx_ref">2022</a>; Huang et al<span class="ltx_text">.</span>, <a href="#bib.bib73" title="" class="ltx_ref">2022b</a>, <a href="#bib.bib72" title="" class="ltx_ref">2023a</a>, <a href="#bib.bib76" title="" class="ltx_ref">2023e</a>; Ye et al<span class="ltx_text">.</span>, <a href="#bib.bib186" title="" class="ltx_ref">2023</a>; Huang et al<span class="ltx_text">.</span>, <a href="#bib.bib75" title="" class="ltx_ref">2023d</a>; Fang et al<span class="ltx_text">.</span>, <a href="#bib.bib44" title="" class="ltx_ref">2023</a>; Yang et al<span class="ltx_text">.</span>, <a href="#bib.bib182" title="" class="ltx_ref">2023b</a>; Huang et al<span class="ltx_text">.</span>, <a href="#bib.bib74" title="" class="ltx_ref">2023c</a>; Shang et al<span class="ltx_text">.</span>, <a href="#bib.bib147" title="" class="ltx_ref">2022</a>; Huang et al<span class="ltx_text">.</span>, <a href="#bib.bib71" title="" class="ltx_ref">2024</a>; Chen et al<span class="ltx_text">.</span>, <a href="#bib.bib29" title="" class="ltx_ref">2024b</a>)</cite>: Here, participants share the same feature space but have different local samples. The goal is to train a global model that can generalize across samples from different clients.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p"><span id="S1.I1.i2.p1.1.1" class="ltx_text ltx_font_bold">Vertical Federated Learning (VFL)</span> <cite class="ltx_cite ltx_citemacro_citep">(Hardy et al<span class="ltx_text">.</span>, <a href="#bib.bib63" title="" class="ltx_ref">2017</a>; Yang et al<span class="ltx_text">.</span>, <a href="#bib.bib180" title="" class="ltx_ref">2019</a>; Liu et al<span class="ltx_text">.</span>, <a href="#bib.bib113" title="" class="ltx_ref">2024</a>)</cite>: In this scenario, clients share the same samples (shared/aligned samples) but have different local features. The goal of VFL is to train a global model capable of making predictions using the distributed features of shared samples.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p"><span id="S1.I1.i3.p1.1.1" class="ltx_text ltx_font_bold">Federated Transfer Learning (FTL)</span> <cite class="ltx_cite ltx_citemacro_citep">(Yang et al<span class="ltx_text">.</span>, <a href="#bib.bib180" title="" class="ltx_ref">2019</a>; Saha and Ahmad, <a href="#bib.bib145" title="" class="ltx_ref">2021</a>; Liu et al<span class="ltx_text">.</span>, <a href="#bib.bib112" title="" class="ltx_ref">2020a</a>; Chen et al<span class="ltx_text">.</span>, <a href="#bib.bib30" title="" class="ltx_ref">2020b</a>)</cite>: Additionally, there is a scenario where clients share both common samples and parts of the feature spaces. The goal of FTL is to transfer knowledge from one client to others through shared samples.</p>
</div>
</li>
</ul>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">As a specific scenario of federated learning, VFL finds extensive application in cross-domain scenarios. For example, as illustrated in <a href="#S1.F1" title="In 1. Introduction ‣ Vertical Federated Learning for Effectiveness, Security, Applicability: A Survey" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">1</span></a>, a mall could collaborate with a video platform and a bank to train a global model that predicts shared users’ shopping intentions. Typically, participants in VFL include an active client and several passive clients. Each client transforms raw sample features into feature embeddings using local models. These are then sent to the active client and aggregated by a global model to make predictions. Additionally, a trustworthy coordinator is employed to ensure secure communication and sample alignment <cite class="ltx_cite ltx_citemacro_citep">(Hardy et al<span class="ltx_text">.</span>, <a href="#bib.bib63" title="" class="ltx_ref">2017</a>; Liang and Chawathe, <a href="#bib.bib105" title="" class="ltx_ref">2004</a>; Lu and Ding, <a href="#bib.bib119" title="" class="ltx_ref">2020</a>; Benny et al<span class="ltx_text">.</span>, <a href="#bib.bib9" title="" class="ltx_ref">2014</a>; Meadows, <a href="#bib.bib126" title="" class="ltx_ref">1986</a>; Pinkas et al<span class="ltx_text">.</span>, <a href="#bib.bib133" title="" class="ltx_ref">2015</a>; Chen et al<span class="ltx_text">.</span>, <a href="#bib.bib22" title="" class="ltx_ref">2017</a>; Pinkas et al<span class="ltx_text">.</span>, <a href="#bib.bib134" title="" class="ltx_ref">2018</a>)</cite>. This setup facilitates cross-domain collaboration without compromising data privacy. Recently, VFL has been widely explored and shown promising results in various domains, including finance <cite class="ltx_cite ltx_citemacro_citep">(Cheng et al<span class="ltx_text">.</span>, <a href="#bib.bib32" title="" class="ltx_ref">2020</a>; Zheng et al<span class="ltx_text">.</span>, <a href="#bib.bib206" title="" class="ltx_ref">2020</a>; Long et al<span class="ltx_text">.</span>, <a href="#bib.bib118" title="" class="ltx_ref">2020</a>)</cite>, recommendation systems <cite class="ltx_cite ltx_citemacro_citep">(Zhang and Jiang, <a href="#bib.bib194" title="" class="ltx_ref">2021</a>; Wei et al<span class="ltx_text">.</span>, <a href="#bib.bib167" title="" class="ltx_ref">2023</a>; Yuan et al<span class="ltx_text">.</span>, <a href="#bib.bib192" title="" class="ltx_ref">2022</a>; Cai, <a href="#bib.bib13" title="" class="ltx_ref">2020</a>; Lin, <a href="#bib.bib106" title="" class="ltx_ref">2021</a>; Wei et al<span class="ltx_text">.</span>, <a href="#bib.bib167" title="" class="ltx_ref">2023</a>)</cite>, and healthcare <cite class="ltx_cite ltx_citemacro_citep">(Yan et al<span class="ltx_text">.</span>, <a href="#bib.bib178" title="" class="ltx_ref">2024</a>; Huang et al<span class="ltx_text">.</span>, <a href="#bib.bib70" title="" class="ltx_ref">2023b</a>; Hu et al<span class="ltx_text">.</span>, <a href="#bib.bib69" title="" class="ltx_ref">2022</a>; Rooijakkers, <a href="#bib.bib144" title="" class="ltx_ref">2020</a>; Song et al<span class="ltx_text">.</span>, <a href="#bib.bib149" title="" class="ltx_ref">2021</a>)</cite>, among others <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a href="#bib.bib96" title="" class="ltx_ref">2020b</a>; Liu et al<span class="ltx_text">.</span>, <a href="#bib.bib111" title="" class="ltx_ref">2021b</a>; He et al<span class="ltx_text">.</span>, <a href="#bib.bib65" title="" class="ltx_ref">2020</a>; Teimoori et al<span class="ltx_text">.</span>, <a href="#bib.bib157" title="" class="ltx_ref">2022</a>; Niknam et al<span class="ltx_text">.</span>, <a href="#bib.bib130" title="" class="ltx_ref">2020</a>; Zhang et al<span class="ltx_text">.</span>, <a href="#bib.bib202" title="" class="ltx_ref">2020</a>; Hashemi et al<span class="ltx_text">.</span>, <a href="#bib.bib64" title="" class="ltx_ref">2021</a>; Liu et al<span class="ltx_text">.</span>, <a href="#bib.bib109" title="" class="ltx_ref">2021e</a>; Ge et al<span class="ltx_text">.</span>, <a href="#bib.bib54" title="" class="ltx_ref">2022</a>)</cite>.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">Despite the development and application of VFL, various challenges still hinder its progress. Researchers have explored these challenges, proposing feasible solutions across three main areas: effectiveness, security, and applicability. <span id="S1.p4.1.1" class="ltx_text ltx_font_italic">Effectiveness</span> focuses on improving VFL under typical conditions, including the development of superior models and the selection of optimal features and clients; <span id="S1.p4.1.2" class="ltx_text ltx_font_italic">Security</span> is vital, as VFL involves collaboration among multiple parties. Ensuring data safety and protecting against attacks is essential to maintaining trust among all participants; <span id="S1.p4.1.3" class="ltx_text ltx_font_italic">Applicability</span> assesses how VFL can operate effectively in real-world scenarios, which are often constrained. This exploration helps to broaden the practical utility of VFL across different sectors. Together, these themes construct a comprehensive research landscape:</p>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/2405.17495/assets/x1.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="392" height="217" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1. </span><span id="S1.F1.2.1" class="ltx_text ltx_font_bold">A Practical Application of Vertical Federated Learning.</span> We present a practical cross-domain collaboration with three participants: mall, video platform, and bank. The mall acts as the active client, collaborating with the video platform and the bank as passive clients. Each client holds the local features and models of the same users. The active client holds the task labels, e.g., whether to buy the tie. A global model is introduced to make the final prediction of the shared/aligned users by aggregating feature embeddings from all clients. With prediction results and labels, the gradients can be calculated for both global and local model updation. Besides, a third-party coordinator can be employed for secure communication and sample alignment. </figcaption>
</figure>
<div id="S1.p5" class="ltx_para">
<ul id="S1.I2" class="ltx_itemize">
<li id="S1.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I2.i1.p1" class="ltx_para">
<p id="S1.I2.i1.p1.1" class="ltx_p"><span id="S1.I2.i1.p1.1.1" class="ltx_text ltx_font_bold">Effectiveness.</span> In machine learning, it is significant to mine effective information from statistical data, which promotes the target learning tasks <cite class="ltx_cite ltx_citemacro_citep">(Mitchell, <a href="#bib.bib127" title="" class="ltx_ref">1999</a>; Al-Jarrah et al<span class="ltx_text">.</span>, <a href="#bib.bib6" title="" class="ltx_ref">2015</a>)</cite>. In VFL, when collaborating with splitting features across multiple participants, the similar and crucial challenge is to aggregate effective information from features in a distributed way. For the general setting in VFL, there are two research directions to achieve effective distributed feature aggregation and task learning: (1) <span id="S1.I2.i1.p1.1.2" class="ltx_text ltx_font_italic">Model Design.</span> These works aim to design basic architecture that adapts for distributed feature learning. Specifically, designing effective models for collaboration with distributed features is the foundation of constructing the VFL paradigm in practical cross-domain collaboration. The topics include extracting meaningful embeddings with split features, achieving effective global feature aggregation, privacy-preserving learning models, and so on. Generally, there are two different kinds of models: (i) Tree-based model. Tree-based model is light and highly efficient, which is suitable for simple data structures such as tabular data. (ii) Neural network-based model. Compared with the traditional machine learning paradigm, the Neural network-based model has enhanced expression ability, which is more suitable for complex multi-modal data, such as text, image, and audio. (2) <span id="S1.I2.i1.p1.1.3" class="ltx_text ltx_font_italic">Feature &amp; Client Selection.</span> In VFL, each client has a contribution to the prediction of shared/aligned samples. However, due to the client heterogeneity, the influences on the final prediction are different between clients. Concretely, the information contained in different features is various, and the local model architectures are different. which affects the results of the prediction task. In this case, recent research explores selecting critical features or clients to obtain effective information from raw data, promoting advanced collaboration performance. The core idea of feature &amp; client selection is to adjust the contribution of different features and clients, which eliminates interference from other redundant information.</p>
</div>
<figure id="S1.F2" class="ltx_figure"><img src="/html/2405.17495/assets/x2.png" id="S1.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="438" height="346" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2. </span><span id="S1.F2.2.1" class="ltx_text ltx_font_bold">Survey Outline.</span> It concludes four parts: Introduction, Preliminary, Basic Research Directions, and Future Directions.</figcaption>
</figure>
</li>
<li id="S1.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I2.i2.p1" class="ltx_para">
<p id="S1.I2.i2.p1.1" class="ltx_p"><span id="S1.I2.i2.p1.1.1" class="ltx_text ltx_font_bold">Security.</span> Vertical Federated Learning is proposed as a privacy-preserving paradigm for distributed features. Although primary privacy ensurance is achieved without leaking raw data, enhanced security is needed to handle the different security threats. In summary, there are two aspects of security concerns: (1) <span id="S1.I2.i2.p1.1.2" class="ltx_text ltx_font_italic">Privacy Leakage.</span> Firstly, privacy leakage problems exist in different stages of VFL, including leakage in sample alignment, embedding transportations, and gradient transportations. (2) <span id="S1.I2.i2.p1.1.3" class="ltx_text ltx_font_italic">Malicious Attack.</span> On the one hand, to obtain the raw data information, the attackers perform data inference attacks: Firstly, all clients can perform the feature inference attack to get the original features in other clients. Besides, the passive clients can perform label inference attacks to infer the labels of the samples from active clients. Moreover, the attackers can perform destructive attacks to affect the system: The attackers can implant specific backdoors to the target prediction, or inject data perturbation to perform poison attack for degrading the collaboration performance. It is also crucial to design corresponding defense strategies against different attacks.</p>
</div>
</li>
<li id="S1.I2.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I2.i3.p1" class="ltx_para">
<p id="S1.I2.i3.p1.1" class="ltx_p"><span id="S1.I2.i3.p1.1.1" class="ltx_text ltx_font_bold">Applicability.</span> When deploying vertical federated learning in various practical scenarios, different challenges hinder the performance of VFL. It is critical to promote practical application in different limited situations. When deploying VFL in practical scenarios, there exists the following challenges: (1) <span id="S1.I2.i3.p1.1.2" class="ltx_text ltx_font_italic">Limited Data.</span> In VFL, there are two aspects of limited data, that hinder the generalization in practical scenarios: (i) Limited Aligned Samples. The critical step to deploying VFL is to find the shared/aligned samples between clients. However, the shared clients are usually in few amounts, especially with a large number of clients. In the situation of limited aligned samples, the performance of VFL is trapped by the limited knowledge and poor generalization of the few aligned samples. (ii) Limited Labels. The labels of the active client are the crucial guidance for collaboration task learning. However, due to various reasons such as the difficulty in collecting large quantities or high-quality labels, the amount of accessible labels for collaboration is often limited, which hinders the performance. (2) <span id="S1.I2.i3.p1.1.3" class="ltx_text ltx_font_italic">Large Communication Burdens.</span> To achieve collaboration across clients, multiple communications are required, which brings large communication burdens to the practical systems. At the same time, the resources in the system are often limited. In this case, it is difficult to apply VFL in practical systems. It is critical to design a communication-effective framework to increase the applicability of VFL in practical scenarios. (3) <span id="S1.I2.i3.p1.1.4" class="ltx_text ltx_font_italic">Client Asynchrony.</span> For the differences in models, number of features, calculation ability, and so on, the clients will finish their calculation and communication asynchronously in a single training epoch, which causes a huge updation delay and training time costs.</p>
</div>
</li>
</ul>
</div>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.1" class="ltx_p">As Vertical Federated Learning (VFL) gains significance in practical applications and emerges as a critical research field, there are several recent surveys <cite class="ltx_cite ltx_citemacro_citep">(Yang et al<span class="ltx_text">.</span>, <a href="#bib.bib180" title="" class="ltx_ref">2019</a>; Xu et al<span class="ltx_text">.</span>, <a href="#bib.bib175" title="" class="ltx_ref">2022</a>; Khan et al<span class="ltx_text">.</span>, <a href="#bib.bib89" title="" class="ltx_ref">2022b</a>; Wei et al<span class="ltx_text">.</span>, <a href="#bib.bib166" title="" class="ltx_ref">2022</a>; Li et al<span class="ltx_text">.</span>, <a href="#bib.bib99" title="" class="ltx_ref">2023b</a>; Yang et al<span class="ltx_text">.</span>, <a href="#bib.bib179" title="" class="ltx_ref">2023a</a>; Liu et al<span class="ltx_text">.</span>, <a href="#bib.bib113" title="" class="ltx_ref">2024</a>; Yu et al<span class="ltx_text">.</span>, <a href="#bib.bib190" title="" class="ltx_ref">2024</a>)</cite> that explore general research topics within VFL. However, the landscape of existing research is fragmented and complex, with no comprehensive and rational taxonomy of research challenges in VFL that encompasses the most recent methods. Yang <span id="S1.p6.1.1" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_citep">(Yang et al<span class="ltx_text">.</span>, <a href="#bib.bib180" title="" class="ltx_ref">2019</a>)</cite> offer a pioneering systemic definition of Federated Learning categorized by data distribution, discussing potential applications. However, it is a general survey on federated learning (FL), lacking a specific and thorough investigation of vertical federated learning (VFL). Liu <span id="S1.p6.1.2" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_citep">(Liu et al<span class="ltx_text">.</span>, <a href="#bib.bib113" title="" class="ltx_ref">2024</a>)</cite> conduct a literature survey on the aspects of effectiveness, efficiency, and privacy, with a unified framework for VFL. However, with the rapid initiation and development of the field, some of the latest literature, including aspects of applicability and security, have not been included. Besides, our survey provides an additional discussion and summary of future research directions compared to this work. While other surveys <cite class="ltx_cite ltx_citemacro_citep">(Xu et al<span class="ltx_text">.</span>, <a href="#bib.bib175" title="" class="ltx_ref">2022</a>; Khan et al<span class="ltx_text">.</span>, <a href="#bib.bib89" title="" class="ltx_ref">2022b</a>; Wei et al<span class="ltx_text">.</span>, <a href="#bib.bib166" title="" class="ltx_ref">2022</a>; Li et al<span class="ltx_text">.</span>, <a href="#bib.bib99" title="" class="ltx_ref">2023b</a>; Yang et al<span class="ltx_text">.</span>, <a href="#bib.bib179" title="" class="ltx_ref">2023a</a>; Yu et al<span class="ltx_text">.</span>, <a href="#bib.bib190" title="" class="ltx_ref">2024</a>)</cite> summarize existing works focusing on scattered aspects such as privacy concerns <cite class="ltx_cite ltx_citemacro_citep">(Xu et al<span class="ltx_text">.</span>, <a href="#bib.bib175" title="" class="ltx_ref">2022</a>; Li et al<span class="ltx_text">.</span>, <a href="#bib.bib99" title="" class="ltx_ref">2023b</a>; Yu et al<span class="ltx_text">.</span>, <a href="#bib.bib190" title="" class="ltx_ref">2024</a>)</cite>, experimental settings <cite class="ltx_cite ltx_citemacro_citep">(Khan et al<span class="ltx_text">.</span>, <a href="#bib.bib89" title="" class="ltx_ref">2022b</a>; Wei et al<span class="ltx_text">.</span>, <a href="#bib.bib166" title="" class="ltx_ref">2022</a>; Li et al<span class="ltx_text">.</span>, <a href="#bib.bib99" title="" class="ltx_ref">2023b</a>)</cite>, database systems <cite class="ltx_cite ltx_citemacro_citep">(Yang et al<span class="ltx_text">.</span>, <a href="#bib.bib179" title="" class="ltx_ref">2023a</a>)</cite>, and theoretical analysis <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a href="#bib.bib99" title="" class="ltx_ref">2023b</a>; Yang et al<span class="ltx_text">.</span>, <a href="#bib.bib179" title="" class="ltx_ref">2023a</a>)</cite>, with fragmented summaries of existing works, we provide a summary from three fundamental perspectives: effectiveness, security, and applicability, which encompasses the most recent works and offers a comprehensive landscape.</p>
</div>
<div id="S1.p7" class="ltx_para">
<p id="S1.p7.1" class="ltx_p">In conclusion, we propose a novel taxonomy method aimed at providing an exhaustive survey that incorporates the latest advances. We categorize existing works into three aspects, which comprehensively summarize the most recent developments: Effectiveness, which ensures the performance of VFL in general settings; Security, which provides advanced guarantees against privacy concerns and malicious attackers; and Applicability, which explores solutions for developing VFL algorithms in various practical applications. Based on our summary, we propose a series of future research topics that are both unsolved and valuable. The outline of this survey is illustrated in <a href="#S1.F2" title="In 1st item ‣ 1. Introduction ‣ Vertical Federated Learning for Effectiveness, Security, Applicability: A Survey" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">2</span></a>. The principal contributions of this survey can be outlined as follows:</p>
</div>
<div id="S1.p8" class="ltx_para">
<ul id="S1.I3" class="ltx_itemize">
<li id="S1.I3.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I3.i1.p1" class="ltx_para">
<p id="S1.I3.i1.p1.1" class="ltx_p">We provide an in-depth analysis of vertical federated learning and present the state-of-the-art comprehensive survey on its effectiveness in general VFL scenarios, security concerning privacy issues and malicious attacks, and applicability in limited practical applications.</p>
</div>
</li>
<li id="S1.I3.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I3.i2.p1" class="ltx_para">
<p id="S1.I3.i2.p1.1" class="ltx_p">We collect updated and influential works from prominent conferences and journals, as well as recent literature on arXiv, and organize them into a novel taxonomy: Model Design and Feature &amp; Client Selection under Effectiveness, Privacy Leakage and Malicious Attacks under Security, and Limited Data, Large Communication Burden, and Client Asynchrony under Applicability. In-depth analyses and comparisons of these methods are also included.</p>
</div>
</li>
<li id="S1.I3.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I3.i3.p1" class="ltx_para">
<p id="S1.I3.i3.p1.1" class="ltx_p">We provide an extensive discussion of future directions, including the trade-offs and synergies between basic directions and other open issues, which will serve as references for potential research and applications in this field.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2. </span>Preliminary</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">In this section, we will describe the general setting of VFL, which is also illustrated in recent literature <cite class="ltx_cite ltx_citemacro_citep">(Yang et al<span class="ltx_text">.</span>, <a href="#bib.bib180" title="" class="ltx_ref">2019</a>; Liu et al<span class="ltx_text">.</span>, <a href="#bib.bib113" title="" class="ltx_ref">2024</a>; Xu et al<span class="ltx_text">.</span>, <a href="#bib.bib175" title="" class="ltx_ref">2022</a>; Khan et al<span class="ltx_text">.</span>, <a href="#bib.bib89" title="" class="ltx_ref">2022b</a>; Wei et al<span class="ltx_text">.</span>, <a href="#bib.bib166" title="" class="ltx_ref">2022</a>; Li et al<span class="ltx_text">.</span>, <a href="#bib.bib99" title="" class="ltx_ref">2023b</a>; Yang et al<span class="ltx_text">.</span>, <a href="#bib.bib179" title="" class="ltx_ref">2023a</a>)</cite>. Compared with existing works, we will provide a more comprehensive summary as follows:</p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.16" class="ltx_p"><span id="S2.p2.16.1" class="ltx_text ltx_font_bold">Distributed Data.</span> In VFL, the data is distributed across clients by feature spaces. Suppose there are <math id="S2.p2.1.m1.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S2.p2.1.m1.1a"><mi id="S2.p2.1.m1.1.1" xref="S2.p2.1.m1.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S2.p2.1.m1.1b"><ci id="S2.p2.1.m1.1.1.cmml" xref="S2.p2.1.m1.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.1.m1.1c">N</annotation></semantics></math> data samples in total, and the number of clients is <math id="S2.p2.2.m2.1" class="ltx_Math" alttext="M" display="inline"><semantics id="S2.p2.2.m2.1a"><mi id="S2.p2.2.m2.1.1" xref="S2.p2.2.m2.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S2.p2.2.m2.1b"><ci id="S2.p2.2.m2.1.1.cmml" xref="S2.p2.2.m2.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.2.m2.1c">M</annotation></semantics></math>. The sample set is defined as <math id="S2.p2.3.m3.2" class="ltx_Math" alttext="D=\left\{x_{i},y_{i}\right\}_{i=1}^{N}" display="inline"><semantics id="S2.p2.3.m3.2a"><mrow id="S2.p2.3.m3.2.2" xref="S2.p2.3.m3.2.2.cmml"><mi id="S2.p2.3.m3.2.2.4" xref="S2.p2.3.m3.2.2.4.cmml">D</mi><mo id="S2.p2.3.m3.2.2.3" xref="S2.p2.3.m3.2.2.3.cmml">=</mo><msubsup id="S2.p2.3.m3.2.2.2" xref="S2.p2.3.m3.2.2.2.cmml"><mrow id="S2.p2.3.m3.2.2.2.2.2.2" xref="S2.p2.3.m3.2.2.2.2.2.3.cmml"><mo id="S2.p2.3.m3.2.2.2.2.2.2.3" xref="S2.p2.3.m3.2.2.2.2.2.3.cmml">{</mo><msub id="S2.p2.3.m3.1.1.1.1.1.1.1" xref="S2.p2.3.m3.1.1.1.1.1.1.1.cmml"><mi id="S2.p2.3.m3.1.1.1.1.1.1.1.2" xref="S2.p2.3.m3.1.1.1.1.1.1.1.2.cmml">x</mi><mi id="S2.p2.3.m3.1.1.1.1.1.1.1.3" xref="S2.p2.3.m3.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S2.p2.3.m3.2.2.2.2.2.2.4" xref="S2.p2.3.m3.2.2.2.2.2.3.cmml">,</mo><msub id="S2.p2.3.m3.2.2.2.2.2.2.2" xref="S2.p2.3.m3.2.2.2.2.2.2.2.cmml"><mi id="S2.p2.3.m3.2.2.2.2.2.2.2.2" xref="S2.p2.3.m3.2.2.2.2.2.2.2.2.cmml">y</mi><mi id="S2.p2.3.m3.2.2.2.2.2.2.2.3" xref="S2.p2.3.m3.2.2.2.2.2.2.2.3.cmml">i</mi></msub><mo id="S2.p2.3.m3.2.2.2.2.2.2.5" xref="S2.p2.3.m3.2.2.2.2.2.3.cmml">}</mo></mrow><mrow id="S2.p2.3.m3.2.2.2.2.4" xref="S2.p2.3.m3.2.2.2.2.4.cmml"><mi id="S2.p2.3.m3.2.2.2.2.4.2" xref="S2.p2.3.m3.2.2.2.2.4.2.cmml">i</mi><mo id="S2.p2.3.m3.2.2.2.2.4.1" xref="S2.p2.3.m3.2.2.2.2.4.1.cmml">=</mo><mn id="S2.p2.3.m3.2.2.2.2.4.3" xref="S2.p2.3.m3.2.2.2.2.4.3.cmml">1</mn></mrow><mi id="S2.p2.3.m3.2.2.2.4" xref="S2.p2.3.m3.2.2.2.4.cmml">N</mi></msubsup></mrow><annotation-xml encoding="MathML-Content" id="S2.p2.3.m3.2b"><apply id="S2.p2.3.m3.2.2.cmml" xref="S2.p2.3.m3.2.2"><eq id="S2.p2.3.m3.2.2.3.cmml" xref="S2.p2.3.m3.2.2.3"></eq><ci id="S2.p2.3.m3.2.2.4.cmml" xref="S2.p2.3.m3.2.2.4">𝐷</ci><apply id="S2.p2.3.m3.2.2.2.cmml" xref="S2.p2.3.m3.2.2.2"><csymbol cd="ambiguous" id="S2.p2.3.m3.2.2.2.3.cmml" xref="S2.p2.3.m3.2.2.2">superscript</csymbol><apply id="S2.p2.3.m3.2.2.2.2.cmml" xref="S2.p2.3.m3.2.2.2"><csymbol cd="ambiguous" id="S2.p2.3.m3.2.2.2.2.3.cmml" xref="S2.p2.3.m3.2.2.2">subscript</csymbol><set id="S2.p2.3.m3.2.2.2.2.2.3.cmml" xref="S2.p2.3.m3.2.2.2.2.2.2"><apply id="S2.p2.3.m3.1.1.1.1.1.1.1.cmml" xref="S2.p2.3.m3.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.p2.3.m3.1.1.1.1.1.1.1.1.cmml" xref="S2.p2.3.m3.1.1.1.1.1.1.1">subscript</csymbol><ci id="S2.p2.3.m3.1.1.1.1.1.1.1.2.cmml" xref="S2.p2.3.m3.1.1.1.1.1.1.1.2">𝑥</ci><ci id="S2.p2.3.m3.1.1.1.1.1.1.1.3.cmml" xref="S2.p2.3.m3.1.1.1.1.1.1.1.3">𝑖</ci></apply><apply id="S2.p2.3.m3.2.2.2.2.2.2.2.cmml" xref="S2.p2.3.m3.2.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S2.p2.3.m3.2.2.2.2.2.2.2.1.cmml" xref="S2.p2.3.m3.2.2.2.2.2.2.2">subscript</csymbol><ci id="S2.p2.3.m3.2.2.2.2.2.2.2.2.cmml" xref="S2.p2.3.m3.2.2.2.2.2.2.2.2">𝑦</ci><ci id="S2.p2.3.m3.2.2.2.2.2.2.2.3.cmml" xref="S2.p2.3.m3.2.2.2.2.2.2.2.3">𝑖</ci></apply></set><apply id="S2.p2.3.m3.2.2.2.2.4.cmml" xref="S2.p2.3.m3.2.2.2.2.4"><eq id="S2.p2.3.m3.2.2.2.2.4.1.cmml" xref="S2.p2.3.m3.2.2.2.2.4.1"></eq><ci id="S2.p2.3.m3.2.2.2.2.4.2.cmml" xref="S2.p2.3.m3.2.2.2.2.4.2">𝑖</ci><cn type="integer" id="S2.p2.3.m3.2.2.2.2.4.3.cmml" xref="S2.p2.3.m3.2.2.2.2.4.3">1</cn></apply></apply><ci id="S2.p2.3.m3.2.2.2.4.cmml" xref="S2.p2.3.m3.2.2.2.4">𝑁</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.3.m3.2c">D=\left\{x_{i},y_{i}\right\}_{i=1}^{N}</annotation></semantics></math>, where <math id="S2.p2.4.m4.1" class="ltx_Math" alttext="x_{i}\in\mathbb{R}^{d}" display="inline"><semantics id="S2.p2.4.m4.1a"><mrow id="S2.p2.4.m4.1.1" xref="S2.p2.4.m4.1.1.cmml"><msub id="S2.p2.4.m4.1.1.2" xref="S2.p2.4.m4.1.1.2.cmml"><mi id="S2.p2.4.m4.1.1.2.2" xref="S2.p2.4.m4.1.1.2.2.cmml">x</mi><mi id="S2.p2.4.m4.1.1.2.3" xref="S2.p2.4.m4.1.1.2.3.cmml">i</mi></msub><mo id="S2.p2.4.m4.1.1.1" xref="S2.p2.4.m4.1.1.1.cmml">∈</mo><msup id="S2.p2.4.m4.1.1.3" xref="S2.p2.4.m4.1.1.3.cmml"><mi id="S2.p2.4.m4.1.1.3.2" xref="S2.p2.4.m4.1.1.3.2.cmml">ℝ</mi><mi id="S2.p2.4.m4.1.1.3.3" xref="S2.p2.4.m4.1.1.3.3.cmml">d</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="S2.p2.4.m4.1b"><apply id="S2.p2.4.m4.1.1.cmml" xref="S2.p2.4.m4.1.1"><in id="S2.p2.4.m4.1.1.1.cmml" xref="S2.p2.4.m4.1.1.1"></in><apply id="S2.p2.4.m4.1.1.2.cmml" xref="S2.p2.4.m4.1.1.2"><csymbol cd="ambiguous" id="S2.p2.4.m4.1.1.2.1.cmml" xref="S2.p2.4.m4.1.1.2">subscript</csymbol><ci id="S2.p2.4.m4.1.1.2.2.cmml" xref="S2.p2.4.m4.1.1.2.2">𝑥</ci><ci id="S2.p2.4.m4.1.1.2.3.cmml" xref="S2.p2.4.m4.1.1.2.3">𝑖</ci></apply><apply id="S2.p2.4.m4.1.1.3.cmml" xref="S2.p2.4.m4.1.1.3"><csymbol cd="ambiguous" id="S2.p2.4.m4.1.1.3.1.cmml" xref="S2.p2.4.m4.1.1.3">superscript</csymbol><ci id="S2.p2.4.m4.1.1.3.2.cmml" xref="S2.p2.4.m4.1.1.3.2">ℝ</ci><ci id="S2.p2.4.m4.1.1.3.3.cmml" xref="S2.p2.4.m4.1.1.3.3">𝑑</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.4.m4.1c">x_{i}\in\mathbb{R}^{d}</annotation></semantics></math> is the dimension number of raw features, <math id="S2.p2.5.m5.1" class="ltx_Math" alttext="y_{i}" display="inline"><semantics id="S2.p2.5.m5.1a"><msub id="S2.p2.5.m5.1.1" xref="S2.p2.5.m5.1.1.cmml"><mi id="S2.p2.5.m5.1.1.2" xref="S2.p2.5.m5.1.1.2.cmml">y</mi><mi id="S2.p2.5.m5.1.1.3" xref="S2.p2.5.m5.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.p2.5.m5.1b"><apply id="S2.p2.5.m5.1.1.cmml" xref="S2.p2.5.m5.1.1"><csymbol cd="ambiguous" id="S2.p2.5.m5.1.1.1.cmml" xref="S2.p2.5.m5.1.1">subscript</csymbol><ci id="S2.p2.5.m5.1.1.2.cmml" xref="S2.p2.5.m5.1.1.2">𝑦</ci><ci id="S2.p2.5.m5.1.1.3.cmml" xref="S2.p2.5.m5.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.5.m5.1c">y_{i}</annotation></semantics></math> is the corresponding label. The distributed data has two situations: if client <math id="S2.p2.6.m6.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S2.p2.6.m6.1a"><mi id="S2.p2.6.m6.1.1" xref="S2.p2.6.m6.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S2.p2.6.m6.1b"><ci id="S2.p2.6.m6.1.1.cmml" xref="S2.p2.6.m6.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.6.m6.1c">k</annotation></semantics></math> is the active client, then the data is defined as <math id="S2.p2.7.m7.2" class="ltx_Math" alttext="D^{k}=\left\{x_{i}^{k},y_{i}^{k}\right\}_{i=1}^{N^{k}},x_{i}\in\mathbb{R}^{d^{k}}" display="inline"><semantics id="S2.p2.7.m7.2a"><mrow id="S2.p2.7.m7.2.2.2" xref="S2.p2.7.m7.2.2.3.cmml"><mrow id="S2.p2.7.m7.1.1.1.1" xref="S2.p2.7.m7.1.1.1.1.cmml"><msup id="S2.p2.7.m7.1.1.1.1.4" xref="S2.p2.7.m7.1.1.1.1.4.cmml"><mi id="S2.p2.7.m7.1.1.1.1.4.2" xref="S2.p2.7.m7.1.1.1.1.4.2.cmml">D</mi><mi id="S2.p2.7.m7.1.1.1.1.4.3" xref="S2.p2.7.m7.1.1.1.1.4.3.cmml">k</mi></msup><mo id="S2.p2.7.m7.1.1.1.1.3" xref="S2.p2.7.m7.1.1.1.1.3.cmml">=</mo><msubsup id="S2.p2.7.m7.1.1.1.1.2" xref="S2.p2.7.m7.1.1.1.1.2.cmml"><mrow id="S2.p2.7.m7.1.1.1.1.2.2.2.2" xref="S2.p2.7.m7.1.1.1.1.2.2.2.3.cmml"><mo id="S2.p2.7.m7.1.1.1.1.2.2.2.2.3" xref="S2.p2.7.m7.1.1.1.1.2.2.2.3.cmml">{</mo><msubsup id="S2.p2.7.m7.1.1.1.1.1.1.1.1.1" xref="S2.p2.7.m7.1.1.1.1.1.1.1.1.1.cmml"><mi id="S2.p2.7.m7.1.1.1.1.1.1.1.1.1.2.2" xref="S2.p2.7.m7.1.1.1.1.1.1.1.1.1.2.2.cmml">x</mi><mi id="S2.p2.7.m7.1.1.1.1.1.1.1.1.1.2.3" xref="S2.p2.7.m7.1.1.1.1.1.1.1.1.1.2.3.cmml">i</mi><mi id="S2.p2.7.m7.1.1.1.1.1.1.1.1.1.3" xref="S2.p2.7.m7.1.1.1.1.1.1.1.1.1.3.cmml">k</mi></msubsup><mo id="S2.p2.7.m7.1.1.1.1.2.2.2.2.4" xref="S2.p2.7.m7.1.1.1.1.2.2.2.3.cmml">,</mo><msubsup id="S2.p2.7.m7.1.1.1.1.2.2.2.2.2" xref="S2.p2.7.m7.1.1.1.1.2.2.2.2.2.cmml"><mi id="S2.p2.7.m7.1.1.1.1.2.2.2.2.2.2.2" xref="S2.p2.7.m7.1.1.1.1.2.2.2.2.2.2.2.cmml">y</mi><mi id="S2.p2.7.m7.1.1.1.1.2.2.2.2.2.2.3" xref="S2.p2.7.m7.1.1.1.1.2.2.2.2.2.2.3.cmml">i</mi><mi id="S2.p2.7.m7.1.1.1.1.2.2.2.2.2.3" xref="S2.p2.7.m7.1.1.1.1.2.2.2.2.2.3.cmml">k</mi></msubsup><mo id="S2.p2.7.m7.1.1.1.1.2.2.2.2.5" xref="S2.p2.7.m7.1.1.1.1.2.2.2.3.cmml">}</mo></mrow><mrow id="S2.p2.7.m7.1.1.1.1.2.2.4" xref="S2.p2.7.m7.1.1.1.1.2.2.4.cmml"><mi id="S2.p2.7.m7.1.1.1.1.2.2.4.2" xref="S2.p2.7.m7.1.1.1.1.2.2.4.2.cmml">i</mi><mo id="S2.p2.7.m7.1.1.1.1.2.2.4.1" xref="S2.p2.7.m7.1.1.1.1.2.2.4.1.cmml">=</mo><mn id="S2.p2.7.m7.1.1.1.1.2.2.4.3" xref="S2.p2.7.m7.1.1.1.1.2.2.4.3.cmml">1</mn></mrow><msup id="S2.p2.7.m7.1.1.1.1.2.4" xref="S2.p2.7.m7.1.1.1.1.2.4.cmml"><mi id="S2.p2.7.m7.1.1.1.1.2.4.2" xref="S2.p2.7.m7.1.1.1.1.2.4.2.cmml">N</mi><mi id="S2.p2.7.m7.1.1.1.1.2.4.3" xref="S2.p2.7.m7.1.1.1.1.2.4.3.cmml">k</mi></msup></msubsup></mrow><mo id="S2.p2.7.m7.2.2.2.3" xref="S2.p2.7.m7.2.2.3a.cmml">,</mo><mrow id="S2.p2.7.m7.2.2.2.2" xref="S2.p2.7.m7.2.2.2.2.cmml"><msub id="S2.p2.7.m7.2.2.2.2.2" xref="S2.p2.7.m7.2.2.2.2.2.cmml"><mi id="S2.p2.7.m7.2.2.2.2.2.2" xref="S2.p2.7.m7.2.2.2.2.2.2.cmml">x</mi><mi id="S2.p2.7.m7.2.2.2.2.2.3" xref="S2.p2.7.m7.2.2.2.2.2.3.cmml">i</mi></msub><mo id="S2.p2.7.m7.2.2.2.2.1" xref="S2.p2.7.m7.2.2.2.2.1.cmml">∈</mo><msup id="S2.p2.7.m7.2.2.2.2.3" xref="S2.p2.7.m7.2.2.2.2.3.cmml"><mi id="S2.p2.7.m7.2.2.2.2.3.2" xref="S2.p2.7.m7.2.2.2.2.3.2.cmml">ℝ</mi><msup id="S2.p2.7.m7.2.2.2.2.3.3" xref="S2.p2.7.m7.2.2.2.2.3.3.cmml"><mi id="S2.p2.7.m7.2.2.2.2.3.3.2" xref="S2.p2.7.m7.2.2.2.2.3.3.2.cmml">d</mi><mi id="S2.p2.7.m7.2.2.2.2.3.3.3" xref="S2.p2.7.m7.2.2.2.2.3.3.3.cmml">k</mi></msup></msup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.p2.7.m7.2b"><apply id="S2.p2.7.m7.2.2.3.cmml" xref="S2.p2.7.m7.2.2.2"><csymbol cd="ambiguous" id="S2.p2.7.m7.2.2.3a.cmml" xref="S2.p2.7.m7.2.2.2.3">formulae-sequence</csymbol><apply id="S2.p2.7.m7.1.1.1.1.cmml" xref="S2.p2.7.m7.1.1.1.1"><eq id="S2.p2.7.m7.1.1.1.1.3.cmml" xref="S2.p2.7.m7.1.1.1.1.3"></eq><apply id="S2.p2.7.m7.1.1.1.1.4.cmml" xref="S2.p2.7.m7.1.1.1.1.4"><csymbol cd="ambiguous" id="S2.p2.7.m7.1.1.1.1.4.1.cmml" xref="S2.p2.7.m7.1.1.1.1.4">superscript</csymbol><ci id="S2.p2.7.m7.1.1.1.1.4.2.cmml" xref="S2.p2.7.m7.1.1.1.1.4.2">𝐷</ci><ci id="S2.p2.7.m7.1.1.1.1.4.3.cmml" xref="S2.p2.7.m7.1.1.1.1.4.3">𝑘</ci></apply><apply id="S2.p2.7.m7.1.1.1.1.2.cmml" xref="S2.p2.7.m7.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.p2.7.m7.1.1.1.1.2.3.cmml" xref="S2.p2.7.m7.1.1.1.1.2">superscript</csymbol><apply id="S2.p2.7.m7.1.1.1.1.2.2.cmml" xref="S2.p2.7.m7.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.p2.7.m7.1.1.1.1.2.2.3.cmml" xref="S2.p2.7.m7.1.1.1.1.2">subscript</csymbol><set id="S2.p2.7.m7.1.1.1.1.2.2.2.3.cmml" xref="S2.p2.7.m7.1.1.1.1.2.2.2.2"><apply id="S2.p2.7.m7.1.1.1.1.1.1.1.1.1.cmml" xref="S2.p2.7.m7.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.p2.7.m7.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.p2.7.m7.1.1.1.1.1.1.1.1.1">superscript</csymbol><apply id="S2.p2.7.m7.1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.p2.7.m7.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.p2.7.m7.1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S2.p2.7.m7.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S2.p2.7.m7.1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S2.p2.7.m7.1.1.1.1.1.1.1.1.1.2.2">𝑥</ci><ci id="S2.p2.7.m7.1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S2.p2.7.m7.1.1.1.1.1.1.1.1.1.2.3">𝑖</ci></apply><ci id="S2.p2.7.m7.1.1.1.1.1.1.1.1.1.3.cmml" xref="S2.p2.7.m7.1.1.1.1.1.1.1.1.1.3">𝑘</ci></apply><apply id="S2.p2.7.m7.1.1.1.1.2.2.2.2.2.cmml" xref="S2.p2.7.m7.1.1.1.1.2.2.2.2.2"><csymbol cd="ambiguous" id="S2.p2.7.m7.1.1.1.1.2.2.2.2.2.1.cmml" xref="S2.p2.7.m7.1.1.1.1.2.2.2.2.2">superscript</csymbol><apply id="S2.p2.7.m7.1.1.1.1.2.2.2.2.2.2.cmml" xref="S2.p2.7.m7.1.1.1.1.2.2.2.2.2"><csymbol cd="ambiguous" id="S2.p2.7.m7.1.1.1.1.2.2.2.2.2.2.1.cmml" xref="S2.p2.7.m7.1.1.1.1.2.2.2.2.2">subscript</csymbol><ci id="S2.p2.7.m7.1.1.1.1.2.2.2.2.2.2.2.cmml" xref="S2.p2.7.m7.1.1.1.1.2.2.2.2.2.2.2">𝑦</ci><ci id="S2.p2.7.m7.1.1.1.1.2.2.2.2.2.2.3.cmml" xref="S2.p2.7.m7.1.1.1.1.2.2.2.2.2.2.3">𝑖</ci></apply><ci id="S2.p2.7.m7.1.1.1.1.2.2.2.2.2.3.cmml" xref="S2.p2.7.m7.1.1.1.1.2.2.2.2.2.3">𝑘</ci></apply></set><apply id="S2.p2.7.m7.1.1.1.1.2.2.4.cmml" xref="S2.p2.7.m7.1.1.1.1.2.2.4"><eq id="S2.p2.7.m7.1.1.1.1.2.2.4.1.cmml" xref="S2.p2.7.m7.1.1.1.1.2.2.4.1"></eq><ci id="S2.p2.7.m7.1.1.1.1.2.2.4.2.cmml" xref="S2.p2.7.m7.1.1.1.1.2.2.4.2">𝑖</ci><cn type="integer" id="S2.p2.7.m7.1.1.1.1.2.2.4.3.cmml" xref="S2.p2.7.m7.1.1.1.1.2.2.4.3">1</cn></apply></apply><apply id="S2.p2.7.m7.1.1.1.1.2.4.cmml" xref="S2.p2.7.m7.1.1.1.1.2.4"><csymbol cd="ambiguous" id="S2.p2.7.m7.1.1.1.1.2.4.1.cmml" xref="S2.p2.7.m7.1.1.1.1.2.4">superscript</csymbol><ci id="S2.p2.7.m7.1.1.1.1.2.4.2.cmml" xref="S2.p2.7.m7.1.1.1.1.2.4.2">𝑁</ci><ci id="S2.p2.7.m7.1.1.1.1.2.4.3.cmml" xref="S2.p2.7.m7.1.1.1.1.2.4.3">𝑘</ci></apply></apply></apply><apply id="S2.p2.7.m7.2.2.2.2.cmml" xref="S2.p2.7.m7.2.2.2.2"><in id="S2.p2.7.m7.2.2.2.2.1.cmml" xref="S2.p2.7.m7.2.2.2.2.1"></in><apply id="S2.p2.7.m7.2.2.2.2.2.cmml" xref="S2.p2.7.m7.2.2.2.2.2"><csymbol cd="ambiguous" id="S2.p2.7.m7.2.2.2.2.2.1.cmml" xref="S2.p2.7.m7.2.2.2.2.2">subscript</csymbol><ci id="S2.p2.7.m7.2.2.2.2.2.2.cmml" xref="S2.p2.7.m7.2.2.2.2.2.2">𝑥</ci><ci id="S2.p2.7.m7.2.2.2.2.2.3.cmml" xref="S2.p2.7.m7.2.2.2.2.2.3">𝑖</ci></apply><apply id="S2.p2.7.m7.2.2.2.2.3.cmml" xref="S2.p2.7.m7.2.2.2.2.3"><csymbol cd="ambiguous" id="S2.p2.7.m7.2.2.2.2.3.1.cmml" xref="S2.p2.7.m7.2.2.2.2.3">superscript</csymbol><ci id="S2.p2.7.m7.2.2.2.2.3.2.cmml" xref="S2.p2.7.m7.2.2.2.2.3.2">ℝ</ci><apply id="S2.p2.7.m7.2.2.2.2.3.3.cmml" xref="S2.p2.7.m7.2.2.2.2.3.3"><csymbol cd="ambiguous" id="S2.p2.7.m7.2.2.2.2.3.3.1.cmml" xref="S2.p2.7.m7.2.2.2.2.3.3">superscript</csymbol><ci id="S2.p2.7.m7.2.2.2.2.3.3.2.cmml" xref="S2.p2.7.m7.2.2.2.2.3.3.2">𝑑</ci><ci id="S2.p2.7.m7.2.2.2.2.3.3.3.cmml" xref="S2.p2.7.m7.2.2.2.2.3.3.3">𝑘</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.7.m7.2c">D^{k}=\left\{x_{i}^{k},y_{i}^{k}\right\}_{i=1}^{N^{k}},x_{i}\in\mathbb{R}^{d^{k}}</annotation></semantics></math> where <math id="S2.p2.8.m8.1" class="ltx_Math" alttext="y_{i}^{k}" display="inline"><semantics id="S2.p2.8.m8.1a"><msubsup id="S2.p2.8.m8.1.1" xref="S2.p2.8.m8.1.1.cmml"><mi id="S2.p2.8.m8.1.1.2.2" xref="S2.p2.8.m8.1.1.2.2.cmml">y</mi><mi id="S2.p2.8.m8.1.1.2.3" xref="S2.p2.8.m8.1.1.2.3.cmml">i</mi><mi id="S2.p2.8.m8.1.1.3" xref="S2.p2.8.m8.1.1.3.cmml">k</mi></msubsup><annotation-xml encoding="MathML-Content" id="S2.p2.8.m8.1b"><apply id="S2.p2.8.m8.1.1.cmml" xref="S2.p2.8.m8.1.1"><csymbol cd="ambiguous" id="S2.p2.8.m8.1.1.1.cmml" xref="S2.p2.8.m8.1.1">superscript</csymbol><apply id="S2.p2.8.m8.1.1.2.cmml" xref="S2.p2.8.m8.1.1"><csymbol cd="ambiguous" id="S2.p2.8.m8.1.1.2.1.cmml" xref="S2.p2.8.m8.1.1">subscript</csymbol><ci id="S2.p2.8.m8.1.1.2.2.cmml" xref="S2.p2.8.m8.1.1.2.2">𝑦</ci><ci id="S2.p2.8.m8.1.1.2.3.cmml" xref="S2.p2.8.m8.1.1.2.3">𝑖</ci></apply><ci id="S2.p2.8.m8.1.1.3.cmml" xref="S2.p2.8.m8.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.8.m8.1c">y_{i}^{k}</annotation></semantics></math> is the corresponding labels of the sample <math id="S2.p2.9.m9.1" class="ltx_Math" alttext="x_{i}^{k}" display="inline"><semantics id="S2.p2.9.m9.1a"><msubsup id="S2.p2.9.m9.1.1" xref="S2.p2.9.m9.1.1.cmml"><mi id="S2.p2.9.m9.1.1.2.2" xref="S2.p2.9.m9.1.1.2.2.cmml">x</mi><mi id="S2.p2.9.m9.1.1.2.3" xref="S2.p2.9.m9.1.1.2.3.cmml">i</mi><mi id="S2.p2.9.m9.1.1.3" xref="S2.p2.9.m9.1.1.3.cmml">k</mi></msubsup><annotation-xml encoding="MathML-Content" id="S2.p2.9.m9.1b"><apply id="S2.p2.9.m9.1.1.cmml" xref="S2.p2.9.m9.1.1"><csymbol cd="ambiguous" id="S2.p2.9.m9.1.1.1.cmml" xref="S2.p2.9.m9.1.1">superscript</csymbol><apply id="S2.p2.9.m9.1.1.2.cmml" xref="S2.p2.9.m9.1.1"><csymbol cd="ambiguous" id="S2.p2.9.m9.1.1.2.1.cmml" xref="S2.p2.9.m9.1.1">subscript</csymbol><ci id="S2.p2.9.m9.1.1.2.2.cmml" xref="S2.p2.9.m9.1.1.2.2">𝑥</ci><ci id="S2.p2.9.m9.1.1.2.3.cmml" xref="S2.p2.9.m9.1.1.2.3">𝑖</ci></apply><ci id="S2.p2.9.m9.1.1.3.cmml" xref="S2.p2.9.m9.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.9.m9.1c">x_{i}^{k}</annotation></semantics></math>; if client <math id="S2.p2.10.m10.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S2.p2.10.m10.1a"><mi id="S2.p2.10.m10.1.1" xref="S2.p2.10.m10.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S2.p2.10.m10.1b"><ci id="S2.p2.10.m10.1.1.cmml" xref="S2.p2.10.m10.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.10.m10.1c">k</annotation></semantics></math> is the passive client, the data can be defined as <math id="S2.p2.11.m11.2" class="ltx_Math" alttext="D^{k}=\left\{x_{i}^{k}\right\}_{i=1}^{N^{k}},x_{i}\in\mathbb{R}^{d^{k}}" display="inline"><semantics id="S2.p2.11.m11.2a"><mrow id="S2.p2.11.m11.2.2.2" xref="S2.p2.11.m11.2.2.3.cmml"><mrow id="S2.p2.11.m11.1.1.1.1" xref="S2.p2.11.m11.1.1.1.1.cmml"><msup id="S2.p2.11.m11.1.1.1.1.3" xref="S2.p2.11.m11.1.1.1.1.3.cmml"><mi id="S2.p2.11.m11.1.1.1.1.3.2" xref="S2.p2.11.m11.1.1.1.1.3.2.cmml">D</mi><mi id="S2.p2.11.m11.1.1.1.1.3.3" xref="S2.p2.11.m11.1.1.1.1.3.3.cmml">k</mi></msup><mo id="S2.p2.11.m11.1.1.1.1.2" xref="S2.p2.11.m11.1.1.1.1.2.cmml">=</mo><msubsup id="S2.p2.11.m11.1.1.1.1.1" xref="S2.p2.11.m11.1.1.1.1.1.cmml"><mrow id="S2.p2.11.m11.1.1.1.1.1.1.1.1" xref="S2.p2.11.m11.1.1.1.1.1.1.1.2.cmml"><mo id="S2.p2.11.m11.1.1.1.1.1.1.1.1.2" xref="S2.p2.11.m11.1.1.1.1.1.1.1.2.cmml">{</mo><msubsup id="S2.p2.11.m11.1.1.1.1.1.1.1.1.1" xref="S2.p2.11.m11.1.1.1.1.1.1.1.1.1.cmml"><mi id="S2.p2.11.m11.1.1.1.1.1.1.1.1.1.2.2" xref="S2.p2.11.m11.1.1.1.1.1.1.1.1.1.2.2.cmml">x</mi><mi id="S2.p2.11.m11.1.1.1.1.1.1.1.1.1.2.3" xref="S2.p2.11.m11.1.1.1.1.1.1.1.1.1.2.3.cmml">i</mi><mi id="S2.p2.11.m11.1.1.1.1.1.1.1.1.1.3" xref="S2.p2.11.m11.1.1.1.1.1.1.1.1.1.3.cmml">k</mi></msubsup><mo id="S2.p2.11.m11.1.1.1.1.1.1.1.1.3" xref="S2.p2.11.m11.1.1.1.1.1.1.1.2.cmml">}</mo></mrow><mrow id="S2.p2.11.m11.1.1.1.1.1.1.3" xref="S2.p2.11.m11.1.1.1.1.1.1.3.cmml"><mi id="S2.p2.11.m11.1.1.1.1.1.1.3.2" xref="S2.p2.11.m11.1.1.1.1.1.1.3.2.cmml">i</mi><mo id="S2.p2.11.m11.1.1.1.1.1.1.3.1" xref="S2.p2.11.m11.1.1.1.1.1.1.3.1.cmml">=</mo><mn id="S2.p2.11.m11.1.1.1.1.1.1.3.3" xref="S2.p2.11.m11.1.1.1.1.1.1.3.3.cmml">1</mn></mrow><msup id="S2.p2.11.m11.1.1.1.1.1.3" xref="S2.p2.11.m11.1.1.1.1.1.3.cmml"><mi id="S2.p2.11.m11.1.1.1.1.1.3.2" xref="S2.p2.11.m11.1.1.1.1.1.3.2.cmml">N</mi><mi id="S2.p2.11.m11.1.1.1.1.1.3.3" xref="S2.p2.11.m11.1.1.1.1.1.3.3.cmml">k</mi></msup></msubsup></mrow><mo id="S2.p2.11.m11.2.2.2.3" xref="S2.p2.11.m11.2.2.3a.cmml">,</mo><mrow id="S2.p2.11.m11.2.2.2.2" xref="S2.p2.11.m11.2.2.2.2.cmml"><msub id="S2.p2.11.m11.2.2.2.2.2" xref="S2.p2.11.m11.2.2.2.2.2.cmml"><mi id="S2.p2.11.m11.2.2.2.2.2.2" xref="S2.p2.11.m11.2.2.2.2.2.2.cmml">x</mi><mi id="S2.p2.11.m11.2.2.2.2.2.3" xref="S2.p2.11.m11.2.2.2.2.2.3.cmml">i</mi></msub><mo id="S2.p2.11.m11.2.2.2.2.1" xref="S2.p2.11.m11.2.2.2.2.1.cmml">∈</mo><msup id="S2.p2.11.m11.2.2.2.2.3" xref="S2.p2.11.m11.2.2.2.2.3.cmml"><mi id="S2.p2.11.m11.2.2.2.2.3.2" xref="S2.p2.11.m11.2.2.2.2.3.2.cmml">ℝ</mi><msup id="S2.p2.11.m11.2.2.2.2.3.3" xref="S2.p2.11.m11.2.2.2.2.3.3.cmml"><mi id="S2.p2.11.m11.2.2.2.2.3.3.2" xref="S2.p2.11.m11.2.2.2.2.3.3.2.cmml">d</mi><mi id="S2.p2.11.m11.2.2.2.2.3.3.3" xref="S2.p2.11.m11.2.2.2.2.3.3.3.cmml">k</mi></msup></msup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.p2.11.m11.2b"><apply id="S2.p2.11.m11.2.2.3.cmml" xref="S2.p2.11.m11.2.2.2"><csymbol cd="ambiguous" id="S2.p2.11.m11.2.2.3a.cmml" xref="S2.p2.11.m11.2.2.2.3">formulae-sequence</csymbol><apply id="S2.p2.11.m11.1.1.1.1.cmml" xref="S2.p2.11.m11.1.1.1.1"><eq id="S2.p2.11.m11.1.1.1.1.2.cmml" xref="S2.p2.11.m11.1.1.1.1.2"></eq><apply id="S2.p2.11.m11.1.1.1.1.3.cmml" xref="S2.p2.11.m11.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.p2.11.m11.1.1.1.1.3.1.cmml" xref="S2.p2.11.m11.1.1.1.1.3">superscript</csymbol><ci id="S2.p2.11.m11.1.1.1.1.3.2.cmml" xref="S2.p2.11.m11.1.1.1.1.3.2">𝐷</ci><ci id="S2.p2.11.m11.1.1.1.1.3.3.cmml" xref="S2.p2.11.m11.1.1.1.1.3.3">𝑘</ci></apply><apply id="S2.p2.11.m11.1.1.1.1.1.cmml" xref="S2.p2.11.m11.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.p2.11.m11.1.1.1.1.1.2.cmml" xref="S2.p2.11.m11.1.1.1.1.1">superscript</csymbol><apply id="S2.p2.11.m11.1.1.1.1.1.1.cmml" xref="S2.p2.11.m11.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.p2.11.m11.1.1.1.1.1.1.2.cmml" xref="S2.p2.11.m11.1.1.1.1.1">subscript</csymbol><set id="S2.p2.11.m11.1.1.1.1.1.1.1.2.cmml" xref="S2.p2.11.m11.1.1.1.1.1.1.1.1"><apply id="S2.p2.11.m11.1.1.1.1.1.1.1.1.1.cmml" xref="S2.p2.11.m11.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.p2.11.m11.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.p2.11.m11.1.1.1.1.1.1.1.1.1">superscript</csymbol><apply id="S2.p2.11.m11.1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.p2.11.m11.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.p2.11.m11.1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S2.p2.11.m11.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S2.p2.11.m11.1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S2.p2.11.m11.1.1.1.1.1.1.1.1.1.2.2">𝑥</ci><ci id="S2.p2.11.m11.1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S2.p2.11.m11.1.1.1.1.1.1.1.1.1.2.3">𝑖</ci></apply><ci id="S2.p2.11.m11.1.1.1.1.1.1.1.1.1.3.cmml" xref="S2.p2.11.m11.1.1.1.1.1.1.1.1.1.3">𝑘</ci></apply></set><apply id="S2.p2.11.m11.1.1.1.1.1.1.3.cmml" xref="S2.p2.11.m11.1.1.1.1.1.1.3"><eq id="S2.p2.11.m11.1.1.1.1.1.1.3.1.cmml" xref="S2.p2.11.m11.1.1.1.1.1.1.3.1"></eq><ci id="S2.p2.11.m11.1.1.1.1.1.1.3.2.cmml" xref="S2.p2.11.m11.1.1.1.1.1.1.3.2">𝑖</ci><cn type="integer" id="S2.p2.11.m11.1.1.1.1.1.1.3.3.cmml" xref="S2.p2.11.m11.1.1.1.1.1.1.3.3">1</cn></apply></apply><apply id="S2.p2.11.m11.1.1.1.1.1.3.cmml" xref="S2.p2.11.m11.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.p2.11.m11.1.1.1.1.1.3.1.cmml" xref="S2.p2.11.m11.1.1.1.1.1.3">superscript</csymbol><ci id="S2.p2.11.m11.1.1.1.1.1.3.2.cmml" xref="S2.p2.11.m11.1.1.1.1.1.3.2">𝑁</ci><ci id="S2.p2.11.m11.1.1.1.1.1.3.3.cmml" xref="S2.p2.11.m11.1.1.1.1.1.3.3">𝑘</ci></apply></apply></apply><apply id="S2.p2.11.m11.2.2.2.2.cmml" xref="S2.p2.11.m11.2.2.2.2"><in id="S2.p2.11.m11.2.2.2.2.1.cmml" xref="S2.p2.11.m11.2.2.2.2.1"></in><apply id="S2.p2.11.m11.2.2.2.2.2.cmml" xref="S2.p2.11.m11.2.2.2.2.2"><csymbol cd="ambiguous" id="S2.p2.11.m11.2.2.2.2.2.1.cmml" xref="S2.p2.11.m11.2.2.2.2.2">subscript</csymbol><ci id="S2.p2.11.m11.2.2.2.2.2.2.cmml" xref="S2.p2.11.m11.2.2.2.2.2.2">𝑥</ci><ci id="S2.p2.11.m11.2.2.2.2.2.3.cmml" xref="S2.p2.11.m11.2.2.2.2.2.3">𝑖</ci></apply><apply id="S2.p2.11.m11.2.2.2.2.3.cmml" xref="S2.p2.11.m11.2.2.2.2.3"><csymbol cd="ambiguous" id="S2.p2.11.m11.2.2.2.2.3.1.cmml" xref="S2.p2.11.m11.2.2.2.2.3">superscript</csymbol><ci id="S2.p2.11.m11.2.2.2.2.3.2.cmml" xref="S2.p2.11.m11.2.2.2.2.3.2">ℝ</ci><apply id="S2.p2.11.m11.2.2.2.2.3.3.cmml" xref="S2.p2.11.m11.2.2.2.2.3.3"><csymbol cd="ambiguous" id="S2.p2.11.m11.2.2.2.2.3.3.1.cmml" xref="S2.p2.11.m11.2.2.2.2.3.3">superscript</csymbol><ci id="S2.p2.11.m11.2.2.2.2.3.3.2.cmml" xref="S2.p2.11.m11.2.2.2.2.3.3.2">𝑑</ci><ci id="S2.p2.11.m11.2.2.2.2.3.3.3.cmml" xref="S2.p2.11.m11.2.2.2.2.3.3.3">𝑘</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.11.m11.2c">D^{k}=\left\{x_{i}^{k}\right\}_{i=1}^{N^{k}},x_{i}\in\mathbb{R}^{d^{k}}</annotation></semantics></math>. In above definition, the <math id="S2.p2.12.m12.1" class="ltx_Math" alttext="N^{k}" display="inline"><semantics id="S2.p2.12.m12.1a"><msup id="S2.p2.12.m12.1.1" xref="S2.p2.12.m12.1.1.cmml"><mi id="S2.p2.12.m12.1.1.2" xref="S2.p2.12.m12.1.1.2.cmml">N</mi><mi id="S2.p2.12.m12.1.1.3" xref="S2.p2.12.m12.1.1.3.cmml">k</mi></msup><annotation-xml encoding="MathML-Content" id="S2.p2.12.m12.1b"><apply id="S2.p2.12.m12.1.1.cmml" xref="S2.p2.12.m12.1.1"><csymbol cd="ambiguous" id="S2.p2.12.m12.1.1.1.cmml" xref="S2.p2.12.m12.1.1">superscript</csymbol><ci id="S2.p2.12.m12.1.1.2.cmml" xref="S2.p2.12.m12.1.1.2">𝑁</ci><ci id="S2.p2.12.m12.1.1.3.cmml" xref="S2.p2.12.m12.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.12.m12.1c">N^{k}</annotation></semantics></math> represents the number of the samples in client <math id="S2.p2.13.m13.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S2.p2.13.m13.1a"><mi id="S2.p2.13.m13.1.1" xref="S2.p2.13.m13.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S2.p2.13.m13.1b"><ci id="S2.p2.13.m13.1.1.cmml" xref="S2.p2.13.m13.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.13.m13.1c">k</annotation></semantics></math>, and <math id="S2.p2.14.m14.1" class="ltx_Math" alttext="d^{k}" display="inline"><semantics id="S2.p2.14.m14.1a"><msup id="S2.p2.14.m14.1.1" xref="S2.p2.14.m14.1.1.cmml"><mi id="S2.p2.14.m14.1.1.2" xref="S2.p2.14.m14.1.1.2.cmml">d</mi><mi id="S2.p2.14.m14.1.1.3" xref="S2.p2.14.m14.1.1.3.cmml">k</mi></msup><annotation-xml encoding="MathML-Content" id="S2.p2.14.m14.1b"><apply id="S2.p2.14.m14.1.1.cmml" xref="S2.p2.14.m14.1.1"><csymbol cd="ambiguous" id="S2.p2.14.m14.1.1.1.cmml" xref="S2.p2.14.m14.1.1">superscript</csymbol><ci id="S2.p2.14.m14.1.1.2.cmml" xref="S2.p2.14.m14.1.1.2">𝑑</ci><ci id="S2.p2.14.m14.1.1.3.cmml" xref="S2.p2.14.m14.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.14.m14.1c">d^{k}</annotation></semantics></math> is the number of feature dimensions in client <math id="S2.p2.15.m15.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S2.p2.15.m15.1a"><mi id="S2.p2.15.m15.1.1" xref="S2.p2.15.m15.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S2.p2.15.m15.1b"><ci id="S2.p2.15.m15.1.1.cmml" xref="S2.p2.15.m15.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.15.m15.1c">k</annotation></semantics></math>, which satisfies <math id="S2.p2.16.m16.1" class="ltx_Math" alttext="d=\sum^{M-1}_{k=1}d^{k}" display="inline"><semantics id="S2.p2.16.m16.1a"><mrow id="S2.p2.16.m16.1.1" xref="S2.p2.16.m16.1.1.cmml"><mi id="S2.p2.16.m16.1.1.2" xref="S2.p2.16.m16.1.1.2.cmml">d</mi><mo rspace="0.111em" id="S2.p2.16.m16.1.1.1" xref="S2.p2.16.m16.1.1.1.cmml">=</mo><mrow id="S2.p2.16.m16.1.1.3" xref="S2.p2.16.m16.1.1.3.cmml"><msubsup id="S2.p2.16.m16.1.1.3.1" xref="S2.p2.16.m16.1.1.3.1.cmml"><mo id="S2.p2.16.m16.1.1.3.1.2.2" xref="S2.p2.16.m16.1.1.3.1.2.2.cmml">∑</mo><mrow id="S2.p2.16.m16.1.1.3.1.3" xref="S2.p2.16.m16.1.1.3.1.3.cmml"><mi id="S2.p2.16.m16.1.1.3.1.3.2" xref="S2.p2.16.m16.1.1.3.1.3.2.cmml">k</mi><mo id="S2.p2.16.m16.1.1.3.1.3.1" xref="S2.p2.16.m16.1.1.3.1.3.1.cmml">=</mo><mn id="S2.p2.16.m16.1.1.3.1.3.3" xref="S2.p2.16.m16.1.1.3.1.3.3.cmml">1</mn></mrow><mrow id="S2.p2.16.m16.1.1.3.1.2.3" xref="S2.p2.16.m16.1.1.3.1.2.3.cmml"><mi id="S2.p2.16.m16.1.1.3.1.2.3.2" xref="S2.p2.16.m16.1.1.3.1.2.3.2.cmml">M</mi><mo id="S2.p2.16.m16.1.1.3.1.2.3.1" xref="S2.p2.16.m16.1.1.3.1.2.3.1.cmml">−</mo><mn id="S2.p2.16.m16.1.1.3.1.2.3.3" xref="S2.p2.16.m16.1.1.3.1.2.3.3.cmml">1</mn></mrow></msubsup><msup id="S2.p2.16.m16.1.1.3.2" xref="S2.p2.16.m16.1.1.3.2.cmml"><mi id="S2.p2.16.m16.1.1.3.2.2" xref="S2.p2.16.m16.1.1.3.2.2.cmml">d</mi><mi id="S2.p2.16.m16.1.1.3.2.3" xref="S2.p2.16.m16.1.1.3.2.3.cmml">k</mi></msup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.p2.16.m16.1b"><apply id="S2.p2.16.m16.1.1.cmml" xref="S2.p2.16.m16.1.1"><eq id="S2.p2.16.m16.1.1.1.cmml" xref="S2.p2.16.m16.1.1.1"></eq><ci id="S2.p2.16.m16.1.1.2.cmml" xref="S2.p2.16.m16.1.1.2">𝑑</ci><apply id="S2.p2.16.m16.1.1.3.cmml" xref="S2.p2.16.m16.1.1.3"><apply id="S2.p2.16.m16.1.1.3.1.cmml" xref="S2.p2.16.m16.1.1.3.1"><csymbol cd="ambiguous" id="S2.p2.16.m16.1.1.3.1.1.cmml" xref="S2.p2.16.m16.1.1.3.1">subscript</csymbol><apply id="S2.p2.16.m16.1.1.3.1.2.cmml" xref="S2.p2.16.m16.1.1.3.1"><csymbol cd="ambiguous" id="S2.p2.16.m16.1.1.3.1.2.1.cmml" xref="S2.p2.16.m16.1.1.3.1">superscript</csymbol><sum id="S2.p2.16.m16.1.1.3.1.2.2.cmml" xref="S2.p2.16.m16.1.1.3.1.2.2"></sum><apply id="S2.p2.16.m16.1.1.3.1.2.3.cmml" xref="S2.p2.16.m16.1.1.3.1.2.3"><minus id="S2.p2.16.m16.1.1.3.1.2.3.1.cmml" xref="S2.p2.16.m16.1.1.3.1.2.3.1"></minus><ci id="S2.p2.16.m16.1.1.3.1.2.3.2.cmml" xref="S2.p2.16.m16.1.1.3.1.2.3.2">𝑀</ci><cn type="integer" id="S2.p2.16.m16.1.1.3.1.2.3.3.cmml" xref="S2.p2.16.m16.1.1.3.1.2.3.3">1</cn></apply></apply><apply id="S2.p2.16.m16.1.1.3.1.3.cmml" xref="S2.p2.16.m16.1.1.3.1.3"><eq id="S2.p2.16.m16.1.1.3.1.3.1.cmml" xref="S2.p2.16.m16.1.1.3.1.3.1"></eq><ci id="S2.p2.16.m16.1.1.3.1.3.2.cmml" xref="S2.p2.16.m16.1.1.3.1.3.2">𝑘</ci><cn type="integer" id="S2.p2.16.m16.1.1.3.1.3.3.cmml" xref="S2.p2.16.m16.1.1.3.1.3.3">1</cn></apply></apply><apply id="S2.p2.16.m16.1.1.3.2.cmml" xref="S2.p2.16.m16.1.1.3.2"><csymbol cd="ambiguous" id="S2.p2.16.m16.1.1.3.2.1.cmml" xref="S2.p2.16.m16.1.1.3.2">superscript</csymbol><ci id="S2.p2.16.m16.1.1.3.2.2.cmml" xref="S2.p2.16.m16.1.1.3.2.2">𝑑</ci><ci id="S2.p2.16.m16.1.1.3.2.3.cmml" xref="S2.p2.16.m16.1.1.3.2.3">𝑘</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.16.m16.1c">d=\sum^{M-1}_{k=1}d^{k}</annotation></semantics></math>.</p>
</div>
<div id="S2.p3" class="ltx_para">
<p id="S2.p3.2" class="ltx_p"><span id="S2.p3.2.1" class="ltx_text ltx_font_bold">Sample Alignment.</span> Denote the shared sample set as <math id="S2.p3.1.m1.2" class="ltx_Math" alttext="D^{S}=\left\{x_{i}^{S},y_{i}^{S}\right\}_{i=1}^{N^{S}},x_{i}\in\mathbb{R}^{d}" display="inline"><semantics id="S2.p3.1.m1.2a"><mrow id="S2.p3.1.m1.2.2.2" xref="S2.p3.1.m1.2.2.3.cmml"><mrow id="S2.p3.1.m1.1.1.1.1" xref="S2.p3.1.m1.1.1.1.1.cmml"><msup id="S2.p3.1.m1.1.1.1.1.4" xref="S2.p3.1.m1.1.1.1.1.4.cmml"><mi id="S2.p3.1.m1.1.1.1.1.4.2" xref="S2.p3.1.m1.1.1.1.1.4.2.cmml">D</mi><mi id="S2.p3.1.m1.1.1.1.1.4.3" xref="S2.p3.1.m1.1.1.1.1.4.3.cmml">S</mi></msup><mo id="S2.p3.1.m1.1.1.1.1.3" xref="S2.p3.1.m1.1.1.1.1.3.cmml">=</mo><msubsup id="S2.p3.1.m1.1.1.1.1.2" xref="S2.p3.1.m1.1.1.1.1.2.cmml"><mrow id="S2.p3.1.m1.1.1.1.1.2.2.2.2" xref="S2.p3.1.m1.1.1.1.1.2.2.2.3.cmml"><mo id="S2.p3.1.m1.1.1.1.1.2.2.2.2.3" xref="S2.p3.1.m1.1.1.1.1.2.2.2.3.cmml">{</mo><msubsup id="S2.p3.1.m1.1.1.1.1.1.1.1.1.1" xref="S2.p3.1.m1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S2.p3.1.m1.1.1.1.1.1.1.1.1.1.2.2" xref="S2.p3.1.m1.1.1.1.1.1.1.1.1.1.2.2.cmml">x</mi><mi id="S2.p3.1.m1.1.1.1.1.1.1.1.1.1.2.3" xref="S2.p3.1.m1.1.1.1.1.1.1.1.1.1.2.3.cmml">i</mi><mi id="S2.p3.1.m1.1.1.1.1.1.1.1.1.1.3" xref="S2.p3.1.m1.1.1.1.1.1.1.1.1.1.3.cmml">S</mi></msubsup><mo id="S2.p3.1.m1.1.1.1.1.2.2.2.2.4" xref="S2.p3.1.m1.1.1.1.1.2.2.2.3.cmml">,</mo><msubsup id="S2.p3.1.m1.1.1.1.1.2.2.2.2.2" xref="S2.p3.1.m1.1.1.1.1.2.2.2.2.2.cmml"><mi id="S2.p3.1.m1.1.1.1.1.2.2.2.2.2.2.2" xref="S2.p3.1.m1.1.1.1.1.2.2.2.2.2.2.2.cmml">y</mi><mi id="S2.p3.1.m1.1.1.1.1.2.2.2.2.2.2.3" xref="S2.p3.1.m1.1.1.1.1.2.2.2.2.2.2.3.cmml">i</mi><mi id="S2.p3.1.m1.1.1.1.1.2.2.2.2.2.3" xref="S2.p3.1.m1.1.1.1.1.2.2.2.2.2.3.cmml">S</mi></msubsup><mo id="S2.p3.1.m1.1.1.1.1.2.2.2.2.5" xref="S2.p3.1.m1.1.1.1.1.2.2.2.3.cmml">}</mo></mrow><mrow id="S2.p3.1.m1.1.1.1.1.2.2.4" xref="S2.p3.1.m1.1.1.1.1.2.2.4.cmml"><mi id="S2.p3.1.m1.1.1.1.1.2.2.4.2" xref="S2.p3.1.m1.1.1.1.1.2.2.4.2.cmml">i</mi><mo id="S2.p3.1.m1.1.1.1.1.2.2.4.1" xref="S2.p3.1.m1.1.1.1.1.2.2.4.1.cmml">=</mo><mn id="S2.p3.1.m1.1.1.1.1.2.2.4.3" xref="S2.p3.1.m1.1.1.1.1.2.2.4.3.cmml">1</mn></mrow><msup id="S2.p3.1.m1.1.1.1.1.2.4" xref="S2.p3.1.m1.1.1.1.1.2.4.cmml"><mi id="S2.p3.1.m1.1.1.1.1.2.4.2" xref="S2.p3.1.m1.1.1.1.1.2.4.2.cmml">N</mi><mi id="S2.p3.1.m1.1.1.1.1.2.4.3" xref="S2.p3.1.m1.1.1.1.1.2.4.3.cmml">S</mi></msup></msubsup></mrow><mo id="S2.p3.1.m1.2.2.2.3" xref="S2.p3.1.m1.2.2.3a.cmml">,</mo><mrow id="S2.p3.1.m1.2.2.2.2" xref="S2.p3.1.m1.2.2.2.2.cmml"><msub id="S2.p3.1.m1.2.2.2.2.2" xref="S2.p3.1.m1.2.2.2.2.2.cmml"><mi id="S2.p3.1.m1.2.2.2.2.2.2" xref="S2.p3.1.m1.2.2.2.2.2.2.cmml">x</mi><mi id="S2.p3.1.m1.2.2.2.2.2.3" xref="S2.p3.1.m1.2.2.2.2.2.3.cmml">i</mi></msub><mo id="S2.p3.1.m1.2.2.2.2.1" xref="S2.p3.1.m1.2.2.2.2.1.cmml">∈</mo><msup id="S2.p3.1.m1.2.2.2.2.3" xref="S2.p3.1.m1.2.2.2.2.3.cmml"><mi id="S2.p3.1.m1.2.2.2.2.3.2" xref="S2.p3.1.m1.2.2.2.2.3.2.cmml">ℝ</mi><mi id="S2.p3.1.m1.2.2.2.2.3.3" xref="S2.p3.1.m1.2.2.2.2.3.3.cmml">d</mi></msup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.p3.1.m1.2b"><apply id="S2.p3.1.m1.2.2.3.cmml" xref="S2.p3.1.m1.2.2.2"><csymbol cd="ambiguous" id="S2.p3.1.m1.2.2.3a.cmml" xref="S2.p3.1.m1.2.2.2.3">formulae-sequence</csymbol><apply id="S2.p3.1.m1.1.1.1.1.cmml" xref="S2.p3.1.m1.1.1.1.1"><eq id="S2.p3.1.m1.1.1.1.1.3.cmml" xref="S2.p3.1.m1.1.1.1.1.3"></eq><apply id="S2.p3.1.m1.1.1.1.1.4.cmml" xref="S2.p3.1.m1.1.1.1.1.4"><csymbol cd="ambiguous" id="S2.p3.1.m1.1.1.1.1.4.1.cmml" xref="S2.p3.1.m1.1.1.1.1.4">superscript</csymbol><ci id="S2.p3.1.m1.1.1.1.1.4.2.cmml" xref="S2.p3.1.m1.1.1.1.1.4.2">𝐷</ci><ci id="S2.p3.1.m1.1.1.1.1.4.3.cmml" xref="S2.p3.1.m1.1.1.1.1.4.3">𝑆</ci></apply><apply id="S2.p3.1.m1.1.1.1.1.2.cmml" xref="S2.p3.1.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.p3.1.m1.1.1.1.1.2.3.cmml" xref="S2.p3.1.m1.1.1.1.1.2">superscript</csymbol><apply id="S2.p3.1.m1.1.1.1.1.2.2.cmml" xref="S2.p3.1.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.p3.1.m1.1.1.1.1.2.2.3.cmml" xref="S2.p3.1.m1.1.1.1.1.2">subscript</csymbol><set id="S2.p3.1.m1.1.1.1.1.2.2.2.3.cmml" xref="S2.p3.1.m1.1.1.1.1.2.2.2.2"><apply id="S2.p3.1.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.p3.1.m1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.p3.1.m1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.p3.1.m1.1.1.1.1.1.1.1.1.1">superscript</csymbol><apply id="S2.p3.1.m1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.p3.1.m1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.p3.1.m1.1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S2.p3.1.m1.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S2.p3.1.m1.1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S2.p3.1.m1.1.1.1.1.1.1.1.1.1.2.2">𝑥</ci><ci id="S2.p3.1.m1.1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S2.p3.1.m1.1.1.1.1.1.1.1.1.1.2.3">𝑖</ci></apply><ci id="S2.p3.1.m1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S2.p3.1.m1.1.1.1.1.1.1.1.1.1.3">𝑆</ci></apply><apply id="S2.p3.1.m1.1.1.1.1.2.2.2.2.2.cmml" xref="S2.p3.1.m1.1.1.1.1.2.2.2.2.2"><csymbol cd="ambiguous" id="S2.p3.1.m1.1.1.1.1.2.2.2.2.2.1.cmml" xref="S2.p3.1.m1.1.1.1.1.2.2.2.2.2">superscript</csymbol><apply id="S2.p3.1.m1.1.1.1.1.2.2.2.2.2.2.cmml" xref="S2.p3.1.m1.1.1.1.1.2.2.2.2.2"><csymbol cd="ambiguous" id="S2.p3.1.m1.1.1.1.1.2.2.2.2.2.2.1.cmml" xref="S2.p3.1.m1.1.1.1.1.2.2.2.2.2">subscript</csymbol><ci id="S2.p3.1.m1.1.1.1.1.2.2.2.2.2.2.2.cmml" xref="S2.p3.1.m1.1.1.1.1.2.2.2.2.2.2.2">𝑦</ci><ci id="S2.p3.1.m1.1.1.1.1.2.2.2.2.2.2.3.cmml" xref="S2.p3.1.m1.1.1.1.1.2.2.2.2.2.2.3">𝑖</ci></apply><ci id="S2.p3.1.m1.1.1.1.1.2.2.2.2.2.3.cmml" xref="S2.p3.1.m1.1.1.1.1.2.2.2.2.2.3">𝑆</ci></apply></set><apply id="S2.p3.1.m1.1.1.1.1.2.2.4.cmml" xref="S2.p3.1.m1.1.1.1.1.2.2.4"><eq id="S2.p3.1.m1.1.1.1.1.2.2.4.1.cmml" xref="S2.p3.1.m1.1.1.1.1.2.2.4.1"></eq><ci id="S2.p3.1.m1.1.1.1.1.2.2.4.2.cmml" xref="S2.p3.1.m1.1.1.1.1.2.2.4.2">𝑖</ci><cn type="integer" id="S2.p3.1.m1.1.1.1.1.2.2.4.3.cmml" xref="S2.p3.1.m1.1.1.1.1.2.2.4.3">1</cn></apply></apply><apply id="S2.p3.1.m1.1.1.1.1.2.4.cmml" xref="S2.p3.1.m1.1.1.1.1.2.4"><csymbol cd="ambiguous" id="S2.p3.1.m1.1.1.1.1.2.4.1.cmml" xref="S2.p3.1.m1.1.1.1.1.2.4">superscript</csymbol><ci id="S2.p3.1.m1.1.1.1.1.2.4.2.cmml" xref="S2.p3.1.m1.1.1.1.1.2.4.2">𝑁</ci><ci id="S2.p3.1.m1.1.1.1.1.2.4.3.cmml" xref="S2.p3.1.m1.1.1.1.1.2.4.3">𝑆</ci></apply></apply></apply><apply id="S2.p3.1.m1.2.2.2.2.cmml" xref="S2.p3.1.m1.2.2.2.2"><in id="S2.p3.1.m1.2.2.2.2.1.cmml" xref="S2.p3.1.m1.2.2.2.2.1"></in><apply id="S2.p3.1.m1.2.2.2.2.2.cmml" xref="S2.p3.1.m1.2.2.2.2.2"><csymbol cd="ambiguous" id="S2.p3.1.m1.2.2.2.2.2.1.cmml" xref="S2.p3.1.m1.2.2.2.2.2">subscript</csymbol><ci id="S2.p3.1.m1.2.2.2.2.2.2.cmml" xref="S2.p3.1.m1.2.2.2.2.2.2">𝑥</ci><ci id="S2.p3.1.m1.2.2.2.2.2.3.cmml" xref="S2.p3.1.m1.2.2.2.2.2.3">𝑖</ci></apply><apply id="S2.p3.1.m1.2.2.2.2.3.cmml" xref="S2.p3.1.m1.2.2.2.2.3"><csymbol cd="ambiguous" id="S2.p3.1.m1.2.2.2.2.3.1.cmml" xref="S2.p3.1.m1.2.2.2.2.3">superscript</csymbol><ci id="S2.p3.1.m1.2.2.2.2.3.2.cmml" xref="S2.p3.1.m1.2.2.2.2.3.2">ℝ</ci><ci id="S2.p3.1.m1.2.2.2.2.3.3.cmml" xref="S2.p3.1.m1.2.2.2.2.3.3">𝑑</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p3.1.m1.2c">D^{S}=\left\{x_{i}^{S},y_{i}^{S}\right\}_{i=1}^{N^{S}},x_{i}\in\mathbb{R}^{d}</annotation></semantics></math>, where <math id="S2.p3.2.m2.1" class="ltx_Math" alttext="y_{i}^{S}" display="inline"><semantics id="S2.p3.2.m2.1a"><msubsup id="S2.p3.2.m2.1.1" xref="S2.p3.2.m2.1.1.cmml"><mi id="S2.p3.2.m2.1.1.2.2" xref="S2.p3.2.m2.1.1.2.2.cmml">y</mi><mi id="S2.p3.2.m2.1.1.2.3" xref="S2.p3.2.m2.1.1.2.3.cmml">i</mi><mi id="S2.p3.2.m2.1.1.3" xref="S2.p3.2.m2.1.1.3.cmml">S</mi></msubsup><annotation-xml encoding="MathML-Content" id="S2.p3.2.m2.1b"><apply id="S2.p3.2.m2.1.1.cmml" xref="S2.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S2.p3.2.m2.1.1.1.cmml" xref="S2.p3.2.m2.1.1">superscript</csymbol><apply id="S2.p3.2.m2.1.1.2.cmml" xref="S2.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S2.p3.2.m2.1.1.2.1.cmml" xref="S2.p3.2.m2.1.1">subscript</csymbol><ci id="S2.p3.2.m2.1.1.2.2.cmml" xref="S2.p3.2.m2.1.1.2.2">𝑦</ci><ci id="S2.p3.2.m2.1.1.2.3.cmml" xref="S2.p3.2.m2.1.1.2.3">𝑖</ci></apply><ci id="S2.p3.2.m2.1.1.3.cmml" xref="S2.p3.2.m2.1.1.3">𝑆</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p3.2.m2.1c">y_{i}^{S}</annotation></semantics></math> is the corresponding labels and origin from the active client. The clients in VFL share the same samples with distributed features, and the shared/aligned samples are discovered with the Sample Alignment process. There are two kinds of sample alignment methods explored in recent research <cite class="ltx_cite ltx_citemacro_citep">(Liang and Chawathe, <a href="#bib.bib105" title="" class="ltx_ref">2004</a>; Lu and Ding, <a href="#bib.bib119" title="" class="ltx_ref">2020</a>; Benny et al<span class="ltx_text">.</span>, <a href="#bib.bib9" title="" class="ltx_ref">2014</a>; Meadows, <a href="#bib.bib126" title="" class="ltx_ref">1986</a>; Pinkas et al<span class="ltx_text">.</span>, <a href="#bib.bib133" title="" class="ltx_ref">2015</a>; Chen et al<span class="ltx_text">.</span>, <a href="#bib.bib22" title="" class="ltx_ref">2017</a>; Pinkas et al<span class="ltx_text">.</span>, <a href="#bib.bib134" title="" class="ltx_ref">2018</a>; Sun et al<span class="ltx_text">.</span>, <a href="#bib.bib154" title="" class="ltx_ref">2021a</a>; Kissner and Song, <a href="#bib.bib90" title="" class="ltx_ref">2005</a>; Davidson and Cid, <a href="#bib.bib35" title="" class="ltx_ref">2017</a>; Jia et al<span class="ltx_text">.</span>, <a href="#bib.bib80" title="" class="ltx_ref">2022</a>; Inbar et al<span class="ltx_text">.</span>, <a href="#bib.bib78" title="" class="ltx_ref">2018</a>; Kolesnikov et al<span class="ltx_text">.</span>, <a href="#bib.bib91" title="" class="ltx_ref">2017</a>; Hardy et al<span class="ltx_text">.</span>, <a href="#bib.bib63" title="" class="ltx_ref">2017</a>)</cite>: One of the ideal solutions is joint the data across clients by the common unique IDs for samples; Besides, the raw data in different clients can be encrypted and sent to the trust-worthy third party, pairing by matching strategy on encrypted data.</p>
</div>
<div id="S2.p4" class="ltx_para">
<p id="S2.p4.3" class="ltx_p"><span id="S2.p4.3.1" class="ltx_text ltx_font_bold">Active/Passive Client.</span> There are two different kinds of clients in VFL, representing different statuses in the collaboration process. Generally, there is one active client in a single VFL process. The active client is the initiator of collaboration, where the labels of the collaboration task are stored. Denote the set of labels as <math id="S2.p4.1.m1.1" class="ltx_Math" alttext="Y=\left\{y_{i}\right\}_{i=1}^{N}" display="inline"><semantics id="S2.p4.1.m1.1a"><mrow id="S2.p4.1.m1.1.1" xref="S2.p4.1.m1.1.1.cmml"><mi id="S2.p4.1.m1.1.1.3" xref="S2.p4.1.m1.1.1.3.cmml">Y</mi><mo id="S2.p4.1.m1.1.1.2" xref="S2.p4.1.m1.1.1.2.cmml">=</mo><msubsup id="S2.p4.1.m1.1.1.1" xref="S2.p4.1.m1.1.1.1.cmml"><mrow id="S2.p4.1.m1.1.1.1.1.1.1" xref="S2.p4.1.m1.1.1.1.1.1.2.cmml"><mo id="S2.p4.1.m1.1.1.1.1.1.1.2" xref="S2.p4.1.m1.1.1.1.1.1.2.cmml">{</mo><msub id="S2.p4.1.m1.1.1.1.1.1.1.1" xref="S2.p4.1.m1.1.1.1.1.1.1.1.cmml"><mi id="S2.p4.1.m1.1.1.1.1.1.1.1.2" xref="S2.p4.1.m1.1.1.1.1.1.1.1.2.cmml">y</mi><mi id="S2.p4.1.m1.1.1.1.1.1.1.1.3" xref="S2.p4.1.m1.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S2.p4.1.m1.1.1.1.1.1.1.3" xref="S2.p4.1.m1.1.1.1.1.1.2.cmml">}</mo></mrow><mrow id="S2.p4.1.m1.1.1.1.1.3" xref="S2.p4.1.m1.1.1.1.1.3.cmml"><mi id="S2.p4.1.m1.1.1.1.1.3.2" xref="S2.p4.1.m1.1.1.1.1.3.2.cmml">i</mi><mo id="S2.p4.1.m1.1.1.1.1.3.1" xref="S2.p4.1.m1.1.1.1.1.3.1.cmml">=</mo><mn id="S2.p4.1.m1.1.1.1.1.3.3" xref="S2.p4.1.m1.1.1.1.1.3.3.cmml">1</mn></mrow><mi id="S2.p4.1.m1.1.1.1.3" xref="S2.p4.1.m1.1.1.1.3.cmml">N</mi></msubsup></mrow><annotation-xml encoding="MathML-Content" id="S2.p4.1.m1.1b"><apply id="S2.p4.1.m1.1.1.cmml" xref="S2.p4.1.m1.1.1"><eq id="S2.p4.1.m1.1.1.2.cmml" xref="S2.p4.1.m1.1.1.2"></eq><ci id="S2.p4.1.m1.1.1.3.cmml" xref="S2.p4.1.m1.1.1.3">𝑌</ci><apply id="S2.p4.1.m1.1.1.1.cmml" xref="S2.p4.1.m1.1.1.1"><csymbol cd="ambiguous" id="S2.p4.1.m1.1.1.1.2.cmml" xref="S2.p4.1.m1.1.1.1">superscript</csymbol><apply id="S2.p4.1.m1.1.1.1.1.cmml" xref="S2.p4.1.m1.1.1.1"><csymbol cd="ambiguous" id="S2.p4.1.m1.1.1.1.1.2.cmml" xref="S2.p4.1.m1.1.1.1">subscript</csymbol><set id="S2.p4.1.m1.1.1.1.1.1.2.cmml" xref="S2.p4.1.m1.1.1.1.1.1.1"><apply id="S2.p4.1.m1.1.1.1.1.1.1.1.cmml" xref="S2.p4.1.m1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.p4.1.m1.1.1.1.1.1.1.1.1.cmml" xref="S2.p4.1.m1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S2.p4.1.m1.1.1.1.1.1.1.1.2.cmml" xref="S2.p4.1.m1.1.1.1.1.1.1.1.2">𝑦</ci><ci id="S2.p4.1.m1.1.1.1.1.1.1.1.3.cmml" xref="S2.p4.1.m1.1.1.1.1.1.1.1.3">𝑖</ci></apply></set><apply id="S2.p4.1.m1.1.1.1.1.3.cmml" xref="S2.p4.1.m1.1.1.1.1.3"><eq id="S2.p4.1.m1.1.1.1.1.3.1.cmml" xref="S2.p4.1.m1.1.1.1.1.3.1"></eq><ci id="S2.p4.1.m1.1.1.1.1.3.2.cmml" xref="S2.p4.1.m1.1.1.1.1.3.2">𝑖</ci><cn type="integer" id="S2.p4.1.m1.1.1.1.1.3.3.cmml" xref="S2.p4.1.m1.1.1.1.1.3.3">1</cn></apply></apply><ci id="S2.p4.1.m1.1.1.1.3.cmml" xref="S2.p4.1.m1.1.1.1.3">𝑁</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p4.1.m1.1c">Y=\left\{y_{i}\right\}_{i=1}^{N}</annotation></semantics></math>, and <math id="S2.p4.2.m2.1" class="ltx_Math" alttext="y_{i}" display="inline"><semantics id="S2.p4.2.m2.1a"><msub id="S2.p4.2.m2.1.1" xref="S2.p4.2.m2.1.1.cmml"><mi id="S2.p4.2.m2.1.1.2" xref="S2.p4.2.m2.1.1.2.cmml">y</mi><mi id="S2.p4.2.m2.1.1.3" xref="S2.p4.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.p4.2.m2.1b"><apply id="S2.p4.2.m2.1.1.cmml" xref="S2.p4.2.m2.1.1"><csymbol cd="ambiguous" id="S2.p4.2.m2.1.1.1.cmml" xref="S2.p4.2.m2.1.1">subscript</csymbol><ci id="S2.p4.2.m2.1.1.2.cmml" xref="S2.p4.2.m2.1.1.2">𝑦</ci><ci id="S2.p4.2.m2.1.1.3.cmml" xref="S2.p4.2.m2.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p4.2.m2.1c">y_{i}</annotation></semantics></math> represents the corresponding labels of the sample <math id="S2.p4.3.m3.1" class="ltx_Math" alttext="x_{i}" display="inline"><semantics id="S2.p4.3.m3.1a"><msub id="S2.p4.3.m3.1.1" xref="S2.p4.3.m3.1.1.cmml"><mi id="S2.p4.3.m3.1.1.2" xref="S2.p4.3.m3.1.1.2.cmml">x</mi><mi id="S2.p4.3.m3.1.1.3" xref="S2.p4.3.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.p4.3.m3.1b"><apply id="S2.p4.3.m3.1.1.cmml" xref="S2.p4.3.m3.1.1"><csymbol cd="ambiguous" id="S2.p4.3.m3.1.1.1.cmml" xref="S2.p4.3.m3.1.1">subscript</csymbol><ci id="S2.p4.3.m3.1.1.2.cmml" xref="S2.p4.3.m3.1.1.2">𝑥</ci><ci id="S2.p4.3.m3.1.1.3.cmml" xref="S2.p4.3.m3.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p4.3.m3.1c">x_{i}</annotation></semantics></math>. Besides, the passive clients hold parts of sample features only, and all the features from both active and passive clients are unioned by sample alignment for model training, under the supervision of corresponding labels from the active client.</p>
</div>
<figure id="S2.F3" class="ltx_figure"><img src="/html/2405.17495/assets/x3.png" id="S2.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="178" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3. </span><span id="S2.F3.2.1" class="ltx_text ltx_font_bold">The general flow of training and testing in VFL.</span> (a) During training, aligned sample embeddings are sent to the active client, where gradients are calculated based on task labels. The overall objective is to optimize for collaborative prediction. These gradients are then sent back to each client for model updating. (b) During testing, predictions on aligned samples are made utilizing the trained global and local models.</figcaption>
</figure>
<div id="S2.p5" class="ltx_para">
<p id="S2.p5.6" class="ltx_p"><span id="S2.p5.6.1" class="ltx_text ltx_font_bold">Overall Objective.</span> The goal of VFL is to train a global model for accurate prediction on the shared samples <math id="S2.p5.1.m1.2" class="ltx_Math" alttext="D^{S}=\left\{x_{i}^{S},y_{i}^{S}\right\}_{i=1}^{N^{S}}" display="inline"><semantics id="S2.p5.1.m1.2a"><mrow id="S2.p5.1.m1.2.2" xref="S2.p5.1.m1.2.2.cmml"><msup id="S2.p5.1.m1.2.2.4" xref="S2.p5.1.m1.2.2.4.cmml"><mi id="S2.p5.1.m1.2.2.4.2" xref="S2.p5.1.m1.2.2.4.2.cmml">D</mi><mi id="S2.p5.1.m1.2.2.4.3" xref="S2.p5.1.m1.2.2.4.3.cmml">S</mi></msup><mo id="S2.p5.1.m1.2.2.3" xref="S2.p5.1.m1.2.2.3.cmml">=</mo><msubsup id="S2.p5.1.m1.2.2.2" xref="S2.p5.1.m1.2.2.2.cmml"><mrow id="S2.p5.1.m1.2.2.2.2.2.2" xref="S2.p5.1.m1.2.2.2.2.2.3.cmml"><mo id="S2.p5.1.m1.2.2.2.2.2.2.3" xref="S2.p5.1.m1.2.2.2.2.2.3.cmml">{</mo><msubsup id="S2.p5.1.m1.1.1.1.1.1.1.1" xref="S2.p5.1.m1.1.1.1.1.1.1.1.cmml"><mi id="S2.p5.1.m1.1.1.1.1.1.1.1.2.2" xref="S2.p5.1.m1.1.1.1.1.1.1.1.2.2.cmml">x</mi><mi id="S2.p5.1.m1.1.1.1.1.1.1.1.2.3" xref="S2.p5.1.m1.1.1.1.1.1.1.1.2.3.cmml">i</mi><mi id="S2.p5.1.m1.1.1.1.1.1.1.1.3" xref="S2.p5.1.m1.1.1.1.1.1.1.1.3.cmml">S</mi></msubsup><mo id="S2.p5.1.m1.2.2.2.2.2.2.4" xref="S2.p5.1.m1.2.2.2.2.2.3.cmml">,</mo><msubsup id="S2.p5.1.m1.2.2.2.2.2.2.2" xref="S2.p5.1.m1.2.2.2.2.2.2.2.cmml"><mi id="S2.p5.1.m1.2.2.2.2.2.2.2.2.2" xref="S2.p5.1.m1.2.2.2.2.2.2.2.2.2.cmml">y</mi><mi id="S2.p5.1.m1.2.2.2.2.2.2.2.2.3" xref="S2.p5.1.m1.2.2.2.2.2.2.2.2.3.cmml">i</mi><mi id="S2.p5.1.m1.2.2.2.2.2.2.2.3" xref="S2.p5.1.m1.2.2.2.2.2.2.2.3.cmml">S</mi></msubsup><mo id="S2.p5.1.m1.2.2.2.2.2.2.5" xref="S2.p5.1.m1.2.2.2.2.2.3.cmml">}</mo></mrow><mrow id="S2.p5.1.m1.2.2.2.2.4" xref="S2.p5.1.m1.2.2.2.2.4.cmml"><mi id="S2.p5.1.m1.2.2.2.2.4.2" xref="S2.p5.1.m1.2.2.2.2.4.2.cmml">i</mi><mo id="S2.p5.1.m1.2.2.2.2.4.1" xref="S2.p5.1.m1.2.2.2.2.4.1.cmml">=</mo><mn id="S2.p5.1.m1.2.2.2.2.4.3" xref="S2.p5.1.m1.2.2.2.2.4.3.cmml">1</mn></mrow><msup id="S2.p5.1.m1.2.2.2.4" xref="S2.p5.1.m1.2.2.2.4.cmml"><mi id="S2.p5.1.m1.2.2.2.4.2" xref="S2.p5.1.m1.2.2.2.4.2.cmml">N</mi><mi id="S2.p5.1.m1.2.2.2.4.3" xref="S2.p5.1.m1.2.2.2.4.3.cmml">S</mi></msup></msubsup></mrow><annotation-xml encoding="MathML-Content" id="S2.p5.1.m1.2b"><apply id="S2.p5.1.m1.2.2.cmml" xref="S2.p5.1.m1.2.2"><eq id="S2.p5.1.m1.2.2.3.cmml" xref="S2.p5.1.m1.2.2.3"></eq><apply id="S2.p5.1.m1.2.2.4.cmml" xref="S2.p5.1.m1.2.2.4"><csymbol cd="ambiguous" id="S2.p5.1.m1.2.2.4.1.cmml" xref="S2.p5.1.m1.2.2.4">superscript</csymbol><ci id="S2.p5.1.m1.2.2.4.2.cmml" xref="S2.p5.1.m1.2.2.4.2">𝐷</ci><ci id="S2.p5.1.m1.2.2.4.3.cmml" xref="S2.p5.1.m1.2.2.4.3">𝑆</ci></apply><apply id="S2.p5.1.m1.2.2.2.cmml" xref="S2.p5.1.m1.2.2.2"><csymbol cd="ambiguous" id="S2.p5.1.m1.2.2.2.3.cmml" xref="S2.p5.1.m1.2.2.2">superscript</csymbol><apply id="S2.p5.1.m1.2.2.2.2.cmml" xref="S2.p5.1.m1.2.2.2"><csymbol cd="ambiguous" id="S2.p5.1.m1.2.2.2.2.3.cmml" xref="S2.p5.1.m1.2.2.2">subscript</csymbol><set id="S2.p5.1.m1.2.2.2.2.2.3.cmml" xref="S2.p5.1.m1.2.2.2.2.2.2"><apply id="S2.p5.1.m1.1.1.1.1.1.1.1.cmml" xref="S2.p5.1.m1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.p5.1.m1.1.1.1.1.1.1.1.1.cmml" xref="S2.p5.1.m1.1.1.1.1.1.1.1">superscript</csymbol><apply id="S2.p5.1.m1.1.1.1.1.1.1.1.2.cmml" xref="S2.p5.1.m1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.p5.1.m1.1.1.1.1.1.1.1.2.1.cmml" xref="S2.p5.1.m1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S2.p5.1.m1.1.1.1.1.1.1.1.2.2.cmml" xref="S2.p5.1.m1.1.1.1.1.1.1.1.2.2">𝑥</ci><ci id="S2.p5.1.m1.1.1.1.1.1.1.1.2.3.cmml" xref="S2.p5.1.m1.1.1.1.1.1.1.1.2.3">𝑖</ci></apply><ci id="S2.p5.1.m1.1.1.1.1.1.1.1.3.cmml" xref="S2.p5.1.m1.1.1.1.1.1.1.1.3">𝑆</ci></apply><apply id="S2.p5.1.m1.2.2.2.2.2.2.2.cmml" xref="S2.p5.1.m1.2.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S2.p5.1.m1.2.2.2.2.2.2.2.1.cmml" xref="S2.p5.1.m1.2.2.2.2.2.2.2">superscript</csymbol><apply id="S2.p5.1.m1.2.2.2.2.2.2.2.2.cmml" xref="S2.p5.1.m1.2.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S2.p5.1.m1.2.2.2.2.2.2.2.2.1.cmml" xref="S2.p5.1.m1.2.2.2.2.2.2.2">subscript</csymbol><ci id="S2.p5.1.m1.2.2.2.2.2.2.2.2.2.cmml" xref="S2.p5.1.m1.2.2.2.2.2.2.2.2.2">𝑦</ci><ci id="S2.p5.1.m1.2.2.2.2.2.2.2.2.3.cmml" xref="S2.p5.1.m1.2.2.2.2.2.2.2.2.3">𝑖</ci></apply><ci id="S2.p5.1.m1.2.2.2.2.2.2.2.3.cmml" xref="S2.p5.1.m1.2.2.2.2.2.2.2.3">𝑆</ci></apply></set><apply id="S2.p5.1.m1.2.2.2.2.4.cmml" xref="S2.p5.1.m1.2.2.2.2.4"><eq id="S2.p5.1.m1.2.2.2.2.4.1.cmml" xref="S2.p5.1.m1.2.2.2.2.4.1"></eq><ci id="S2.p5.1.m1.2.2.2.2.4.2.cmml" xref="S2.p5.1.m1.2.2.2.2.4.2">𝑖</ci><cn type="integer" id="S2.p5.1.m1.2.2.2.2.4.3.cmml" xref="S2.p5.1.m1.2.2.2.2.4.3">1</cn></apply></apply><apply id="S2.p5.1.m1.2.2.2.4.cmml" xref="S2.p5.1.m1.2.2.2.4"><csymbol cd="ambiguous" id="S2.p5.1.m1.2.2.2.4.1.cmml" xref="S2.p5.1.m1.2.2.2.4">superscript</csymbol><ci id="S2.p5.1.m1.2.2.2.4.2.cmml" xref="S2.p5.1.m1.2.2.2.4.2">𝑁</ci><ci id="S2.p5.1.m1.2.2.2.4.3.cmml" xref="S2.p5.1.m1.2.2.2.4.3">𝑆</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p5.1.m1.2c">D^{S}=\left\{x_{i}^{S},y_{i}^{S}\right\}_{i=1}^{N^{S}}</annotation></semantics></math>. Denote the local model in client <math id="S2.p5.2.m2.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S2.p5.2.m2.1a"><mi id="S2.p5.2.m2.1.1" xref="S2.p5.2.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S2.p5.2.m2.1b"><ci id="S2.p5.2.m2.1.1.cmml" xref="S2.p5.2.m2.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p5.2.m2.1c">k</annotation></semantics></math> as <math id="S2.p5.3.m3.1" class="ltx_Math" alttext="F(\theta^{k})" display="inline"><semantics id="S2.p5.3.m3.1a"><mrow id="S2.p5.3.m3.1.1" xref="S2.p5.3.m3.1.1.cmml"><mi id="S2.p5.3.m3.1.1.3" xref="S2.p5.3.m3.1.1.3.cmml">F</mi><mo lspace="0em" rspace="0em" id="S2.p5.3.m3.1.1.2" xref="S2.p5.3.m3.1.1.2.cmml">​</mo><mrow id="S2.p5.3.m3.1.1.1.1" xref="S2.p5.3.m3.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.p5.3.m3.1.1.1.1.2" xref="S2.p5.3.m3.1.1.1.1.1.cmml">(</mo><msup id="S2.p5.3.m3.1.1.1.1.1" xref="S2.p5.3.m3.1.1.1.1.1.cmml"><mi id="S2.p5.3.m3.1.1.1.1.1.2" xref="S2.p5.3.m3.1.1.1.1.1.2.cmml">θ</mi><mi id="S2.p5.3.m3.1.1.1.1.1.3" xref="S2.p5.3.m3.1.1.1.1.1.3.cmml">k</mi></msup><mo stretchy="false" id="S2.p5.3.m3.1.1.1.1.3" xref="S2.p5.3.m3.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.p5.3.m3.1b"><apply id="S2.p5.3.m3.1.1.cmml" xref="S2.p5.3.m3.1.1"><times id="S2.p5.3.m3.1.1.2.cmml" xref="S2.p5.3.m3.1.1.2"></times><ci id="S2.p5.3.m3.1.1.3.cmml" xref="S2.p5.3.m3.1.1.3">𝐹</ci><apply id="S2.p5.3.m3.1.1.1.1.1.cmml" xref="S2.p5.3.m3.1.1.1.1"><csymbol cd="ambiguous" id="S2.p5.3.m3.1.1.1.1.1.1.cmml" xref="S2.p5.3.m3.1.1.1.1">superscript</csymbol><ci id="S2.p5.3.m3.1.1.1.1.1.2.cmml" xref="S2.p5.3.m3.1.1.1.1.1.2">𝜃</ci><ci id="S2.p5.3.m3.1.1.1.1.1.3.cmml" xref="S2.p5.3.m3.1.1.1.1.1.3">𝑘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p5.3.m3.1c">F(\theta^{k})</annotation></semantics></math>, which is employed for learning embeddings from the origin local data. Firstly, the local data <math id="S2.p5.4.m4.1" class="ltx_Math" alttext="x_{i}^{k}" display="inline"><semantics id="S2.p5.4.m4.1a"><msubsup id="S2.p5.4.m4.1.1" xref="S2.p5.4.m4.1.1.cmml"><mi id="S2.p5.4.m4.1.1.2.2" xref="S2.p5.4.m4.1.1.2.2.cmml">x</mi><mi id="S2.p5.4.m4.1.1.2.3" xref="S2.p5.4.m4.1.1.2.3.cmml">i</mi><mi id="S2.p5.4.m4.1.1.3" xref="S2.p5.4.m4.1.1.3.cmml">k</mi></msubsup><annotation-xml encoding="MathML-Content" id="S2.p5.4.m4.1b"><apply id="S2.p5.4.m4.1.1.cmml" xref="S2.p5.4.m4.1.1"><csymbol cd="ambiguous" id="S2.p5.4.m4.1.1.1.cmml" xref="S2.p5.4.m4.1.1">superscript</csymbol><apply id="S2.p5.4.m4.1.1.2.cmml" xref="S2.p5.4.m4.1.1"><csymbol cd="ambiguous" id="S2.p5.4.m4.1.1.2.1.cmml" xref="S2.p5.4.m4.1.1">subscript</csymbol><ci id="S2.p5.4.m4.1.1.2.2.cmml" xref="S2.p5.4.m4.1.1.2.2">𝑥</ci><ci id="S2.p5.4.m4.1.1.2.3.cmml" xref="S2.p5.4.m4.1.1.2.3">𝑖</ci></apply><ci id="S2.p5.4.m4.1.1.3.cmml" xref="S2.p5.4.m4.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p5.4.m4.1c">x_{i}^{k}</annotation></semantics></math> in client <math id="S2.p5.5.m5.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S2.p5.5.m5.1a"><mi id="S2.p5.5.m5.1.1" xref="S2.p5.5.m5.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S2.p5.5.m5.1b"><ci id="S2.p5.5.m5.1.1.cmml" xref="S2.p5.5.m5.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p5.5.m5.1c">k</annotation></semantics></math> is transformed into the feature embedding <math id="S2.p5.6.m6.1" class="ltx_Math" alttext="h_{i}^{k}" display="inline"><semantics id="S2.p5.6.m6.1a"><msubsup id="S2.p5.6.m6.1.1" xref="S2.p5.6.m6.1.1.cmml"><mi id="S2.p5.6.m6.1.1.2.2" xref="S2.p5.6.m6.1.1.2.2.cmml">h</mi><mi id="S2.p5.6.m6.1.1.2.3" xref="S2.p5.6.m6.1.1.2.3.cmml">i</mi><mi id="S2.p5.6.m6.1.1.3" xref="S2.p5.6.m6.1.1.3.cmml">k</mi></msubsup><annotation-xml encoding="MathML-Content" id="S2.p5.6.m6.1b"><apply id="S2.p5.6.m6.1.1.cmml" xref="S2.p5.6.m6.1.1"><csymbol cd="ambiguous" id="S2.p5.6.m6.1.1.1.cmml" xref="S2.p5.6.m6.1.1">superscript</csymbol><apply id="S2.p5.6.m6.1.1.2.cmml" xref="S2.p5.6.m6.1.1"><csymbol cd="ambiguous" id="S2.p5.6.m6.1.1.2.1.cmml" xref="S2.p5.6.m6.1.1">subscript</csymbol><ci id="S2.p5.6.m6.1.1.2.2.cmml" xref="S2.p5.6.m6.1.1.2.2">ℎ</ci><ci id="S2.p5.6.m6.1.1.2.3.cmml" xref="S2.p5.6.m6.1.1.2.3">𝑖</ci></apply><ci id="S2.p5.6.m6.1.1.3.cmml" xref="S2.p5.6.m6.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p5.6.m6.1c">h_{i}^{k}</annotation></semantics></math> by local model, which is defined as follows:</p>
</div>
<div id="S2.p6" class="ltx_para">
<table id="S2.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left"><span class="ltx_tag ltx_tag_equation ltx_align_left">(1)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E1.m1.1" class="ltx_Math" alttext="{{h}^{k}_{i}=F(x^{k}_{i};\theta^{k}).}" display="block"><semantics id="S2.E1.m1.1a"><mrow id="S2.E1.m1.1.1.1" xref="S2.E1.m1.1.1.1.1.cmml"><mrow id="S2.E1.m1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.cmml"><msubsup id="S2.E1.m1.1.1.1.1.4" xref="S2.E1.m1.1.1.1.1.4.cmml"><mi id="S2.E1.m1.1.1.1.1.4.2.2" xref="S2.E1.m1.1.1.1.1.4.2.2.cmml">h</mi><mi id="S2.E1.m1.1.1.1.1.4.3" xref="S2.E1.m1.1.1.1.1.4.3.cmml">i</mi><mi id="S2.E1.m1.1.1.1.1.4.2.3" xref="S2.E1.m1.1.1.1.1.4.2.3.cmml">k</mi></msubsup><mo id="S2.E1.m1.1.1.1.1.3" xref="S2.E1.m1.1.1.1.1.3.cmml">=</mo><mrow id="S2.E1.m1.1.1.1.1.2" xref="S2.E1.m1.1.1.1.1.2.cmml"><mi id="S2.E1.m1.1.1.1.1.2.4" xref="S2.E1.m1.1.1.1.1.2.4.cmml">F</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.1.1.2.3" xref="S2.E1.m1.1.1.1.1.2.3.cmml">​</mo><mrow id="S2.E1.m1.1.1.1.1.2.2.2" xref="S2.E1.m1.1.1.1.1.2.2.3.cmml"><mo stretchy="false" id="S2.E1.m1.1.1.1.1.2.2.2.3" xref="S2.E1.m1.1.1.1.1.2.2.3.cmml">(</mo><msubsup id="S2.E1.m1.1.1.1.1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.1.1.1.1.cmml"><mi id="S2.E1.m1.1.1.1.1.1.1.1.1.2.2" xref="S2.E1.m1.1.1.1.1.1.1.1.1.2.2.cmml">x</mi><mi id="S2.E1.m1.1.1.1.1.1.1.1.1.3" xref="S2.E1.m1.1.1.1.1.1.1.1.1.3.cmml">i</mi><mi id="S2.E1.m1.1.1.1.1.1.1.1.1.2.3" xref="S2.E1.m1.1.1.1.1.1.1.1.1.2.3.cmml">k</mi></msubsup><mo id="S2.E1.m1.1.1.1.1.2.2.2.4" xref="S2.E1.m1.1.1.1.1.2.2.3.cmml">;</mo><msup id="S2.E1.m1.1.1.1.1.2.2.2.2" xref="S2.E1.m1.1.1.1.1.2.2.2.2.cmml"><mi id="S2.E1.m1.1.1.1.1.2.2.2.2.2" xref="S2.E1.m1.1.1.1.1.2.2.2.2.2.cmml">θ</mi><mi id="S2.E1.m1.1.1.1.1.2.2.2.2.3" xref="S2.E1.m1.1.1.1.1.2.2.2.2.3.cmml">k</mi></msup><mo stretchy="false" id="S2.E1.m1.1.1.1.1.2.2.2.5" xref="S2.E1.m1.1.1.1.1.2.2.3.cmml">)</mo></mrow></mrow></mrow><mo lspace="0em" id="S2.E1.m1.1.1.1.2" xref="S2.E1.m1.1.1.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.E1.m1.1b"><apply id="S2.E1.m1.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1"><eq id="S2.E1.m1.1.1.1.1.3.cmml" xref="S2.E1.m1.1.1.1.1.3"></eq><apply id="S2.E1.m1.1.1.1.1.4.cmml" xref="S2.E1.m1.1.1.1.1.4"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.1.1.4.1.cmml" xref="S2.E1.m1.1.1.1.1.4">subscript</csymbol><apply id="S2.E1.m1.1.1.1.1.4.2.cmml" xref="S2.E1.m1.1.1.1.1.4"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.1.1.4.2.1.cmml" xref="S2.E1.m1.1.1.1.1.4">superscript</csymbol><ci id="S2.E1.m1.1.1.1.1.4.2.2.cmml" xref="S2.E1.m1.1.1.1.1.4.2.2">ℎ</ci><ci id="S2.E1.m1.1.1.1.1.4.2.3.cmml" xref="S2.E1.m1.1.1.1.1.4.2.3">𝑘</ci></apply><ci id="S2.E1.m1.1.1.1.1.4.3.cmml" xref="S2.E1.m1.1.1.1.1.4.3">𝑖</ci></apply><apply id="S2.E1.m1.1.1.1.1.2.cmml" xref="S2.E1.m1.1.1.1.1.2"><times id="S2.E1.m1.1.1.1.1.2.3.cmml" xref="S2.E1.m1.1.1.1.1.2.3"></times><ci id="S2.E1.m1.1.1.1.1.2.4.cmml" xref="S2.E1.m1.1.1.1.1.2.4">𝐹</ci><list id="S2.E1.m1.1.1.1.1.2.2.3.cmml" xref="S2.E1.m1.1.1.1.1.2.2.2"><apply id="S2.E1.m1.1.1.1.1.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1">subscript</csymbol><apply id="S2.E1.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1">superscript</csymbol><ci id="S2.E1.m1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.2.2">𝑥</ci><ci id="S2.E1.m1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.2.3">𝑘</ci></apply><ci id="S2.E1.m1.1.1.1.1.1.1.1.1.3.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.3">𝑖</ci></apply><apply id="S2.E1.m1.1.1.1.1.2.2.2.2.cmml" xref="S2.E1.m1.1.1.1.1.2.2.2.2"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.1.1.2.2.2.2.1.cmml" xref="S2.E1.m1.1.1.1.1.2.2.2.2">superscript</csymbol><ci id="S2.E1.m1.1.1.1.1.2.2.2.2.2.cmml" xref="S2.E1.m1.1.1.1.1.2.2.2.2.2">𝜃</ci><ci id="S2.E1.m1.1.1.1.1.2.2.2.2.3.cmml" xref="S2.E1.m1.1.1.1.1.2.2.2.2.3">𝑘</ci></apply></list></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E1.m1.1c">{{h}^{k}_{i}=F(x^{k}_{i};\theta^{k}).}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div id="S2.p7" class="ltx_para">
<p id="S2.p7.4" class="ltx_p">After that, the embedding concatenation of shared samples <math id="S2.p7.1.m1.4" class="ltx_Math" alttext="H^{S}=[h^{k}],k=1,...,M-1" display="inline"><semantics id="S2.p7.1.m1.4a"><mrow id="S2.p7.1.m1.4.4.2" xref="S2.p7.1.m1.4.4.3.cmml"><mrow id="S2.p7.1.m1.3.3.1.1" xref="S2.p7.1.m1.3.3.1.1.cmml"><msup id="S2.p7.1.m1.3.3.1.1.3" xref="S2.p7.1.m1.3.3.1.1.3.cmml"><mi id="S2.p7.1.m1.3.3.1.1.3.2" xref="S2.p7.1.m1.3.3.1.1.3.2.cmml">H</mi><mi id="S2.p7.1.m1.3.3.1.1.3.3" xref="S2.p7.1.m1.3.3.1.1.3.3.cmml">S</mi></msup><mo id="S2.p7.1.m1.3.3.1.1.2" xref="S2.p7.1.m1.3.3.1.1.2.cmml">=</mo><mrow id="S2.p7.1.m1.3.3.1.1.1.1" xref="S2.p7.1.m1.3.3.1.1.1.2.cmml"><mo stretchy="false" id="S2.p7.1.m1.3.3.1.1.1.1.2" xref="S2.p7.1.m1.3.3.1.1.1.2.1.cmml">[</mo><msup id="S2.p7.1.m1.3.3.1.1.1.1.1" xref="S2.p7.1.m1.3.3.1.1.1.1.1.cmml"><mi id="S2.p7.1.m1.3.3.1.1.1.1.1.2" xref="S2.p7.1.m1.3.3.1.1.1.1.1.2.cmml">h</mi><mi id="S2.p7.1.m1.3.3.1.1.1.1.1.3" xref="S2.p7.1.m1.3.3.1.1.1.1.1.3.cmml">k</mi></msup><mo stretchy="false" id="S2.p7.1.m1.3.3.1.1.1.1.3" xref="S2.p7.1.m1.3.3.1.1.1.2.1.cmml">]</mo></mrow></mrow><mo id="S2.p7.1.m1.4.4.2.3" xref="S2.p7.1.m1.4.4.3a.cmml">,</mo><mrow id="S2.p7.1.m1.4.4.2.2" xref="S2.p7.1.m1.4.4.2.2.cmml"><mi id="S2.p7.1.m1.4.4.2.2.3" xref="S2.p7.1.m1.4.4.2.2.3.cmml">k</mi><mo id="S2.p7.1.m1.4.4.2.2.2" xref="S2.p7.1.m1.4.4.2.2.2.cmml">=</mo><mrow id="S2.p7.1.m1.4.4.2.2.1.1" xref="S2.p7.1.m1.4.4.2.2.1.2.cmml"><mn id="S2.p7.1.m1.1.1" xref="S2.p7.1.m1.1.1.cmml">1</mn><mo id="S2.p7.1.m1.4.4.2.2.1.1.2" xref="S2.p7.1.m1.4.4.2.2.1.2.cmml">,</mo><mi mathvariant="normal" id="S2.p7.1.m1.2.2" xref="S2.p7.1.m1.2.2.cmml">…</mi><mo id="S2.p7.1.m1.4.4.2.2.1.1.3" xref="S2.p7.1.m1.4.4.2.2.1.2.cmml">,</mo><mrow id="S2.p7.1.m1.4.4.2.2.1.1.1" xref="S2.p7.1.m1.4.4.2.2.1.1.1.cmml"><mi id="S2.p7.1.m1.4.4.2.2.1.1.1.2" xref="S2.p7.1.m1.4.4.2.2.1.1.1.2.cmml">M</mi><mo id="S2.p7.1.m1.4.4.2.2.1.1.1.1" xref="S2.p7.1.m1.4.4.2.2.1.1.1.1.cmml">−</mo><mn id="S2.p7.1.m1.4.4.2.2.1.1.1.3" xref="S2.p7.1.m1.4.4.2.2.1.1.1.3.cmml">1</mn></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.p7.1.m1.4b"><apply id="S2.p7.1.m1.4.4.3.cmml" xref="S2.p7.1.m1.4.4.2"><csymbol cd="ambiguous" id="S2.p7.1.m1.4.4.3a.cmml" xref="S2.p7.1.m1.4.4.2.3">formulae-sequence</csymbol><apply id="S2.p7.1.m1.3.3.1.1.cmml" xref="S2.p7.1.m1.3.3.1.1"><eq id="S2.p7.1.m1.3.3.1.1.2.cmml" xref="S2.p7.1.m1.3.3.1.1.2"></eq><apply id="S2.p7.1.m1.3.3.1.1.3.cmml" xref="S2.p7.1.m1.3.3.1.1.3"><csymbol cd="ambiguous" id="S2.p7.1.m1.3.3.1.1.3.1.cmml" xref="S2.p7.1.m1.3.3.1.1.3">superscript</csymbol><ci id="S2.p7.1.m1.3.3.1.1.3.2.cmml" xref="S2.p7.1.m1.3.3.1.1.3.2">𝐻</ci><ci id="S2.p7.1.m1.3.3.1.1.3.3.cmml" xref="S2.p7.1.m1.3.3.1.1.3.3">𝑆</ci></apply><apply id="S2.p7.1.m1.3.3.1.1.1.2.cmml" xref="S2.p7.1.m1.3.3.1.1.1.1"><csymbol cd="latexml" id="S2.p7.1.m1.3.3.1.1.1.2.1.cmml" xref="S2.p7.1.m1.3.3.1.1.1.1.2">delimited-[]</csymbol><apply id="S2.p7.1.m1.3.3.1.1.1.1.1.cmml" xref="S2.p7.1.m1.3.3.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.p7.1.m1.3.3.1.1.1.1.1.1.cmml" xref="S2.p7.1.m1.3.3.1.1.1.1.1">superscript</csymbol><ci id="S2.p7.1.m1.3.3.1.1.1.1.1.2.cmml" xref="S2.p7.1.m1.3.3.1.1.1.1.1.2">ℎ</ci><ci id="S2.p7.1.m1.3.3.1.1.1.1.1.3.cmml" xref="S2.p7.1.m1.3.3.1.1.1.1.1.3">𝑘</ci></apply></apply></apply><apply id="S2.p7.1.m1.4.4.2.2.cmml" xref="S2.p7.1.m1.4.4.2.2"><eq id="S2.p7.1.m1.4.4.2.2.2.cmml" xref="S2.p7.1.m1.4.4.2.2.2"></eq><ci id="S2.p7.1.m1.4.4.2.2.3.cmml" xref="S2.p7.1.m1.4.4.2.2.3">𝑘</ci><list id="S2.p7.1.m1.4.4.2.2.1.2.cmml" xref="S2.p7.1.m1.4.4.2.2.1.1"><cn type="integer" id="S2.p7.1.m1.1.1.cmml" xref="S2.p7.1.m1.1.1">1</cn><ci id="S2.p7.1.m1.2.2.cmml" xref="S2.p7.1.m1.2.2">…</ci><apply id="S2.p7.1.m1.4.4.2.2.1.1.1.cmml" xref="S2.p7.1.m1.4.4.2.2.1.1.1"><minus id="S2.p7.1.m1.4.4.2.2.1.1.1.1.cmml" xref="S2.p7.1.m1.4.4.2.2.1.1.1.1"></minus><ci id="S2.p7.1.m1.4.4.2.2.1.1.1.2.cmml" xref="S2.p7.1.m1.4.4.2.2.1.1.1.2">𝑀</ci><cn type="integer" id="S2.p7.1.m1.4.4.2.2.1.1.1.3.cmml" xref="S2.p7.1.m1.4.4.2.2.1.1.1.3">1</cn></apply></list></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p7.1.m1.4c">H^{S}=[h^{k}],k=1,...,M-1</annotation></semantics></math> are transmitted to the side of the global model <math id="S2.p7.2.m2.1" class="ltx_Math" alttext="G(\theta^{S})" display="inline"><semantics id="S2.p7.2.m2.1a"><mrow id="S2.p7.2.m2.1.1" xref="S2.p7.2.m2.1.1.cmml"><mi id="S2.p7.2.m2.1.1.3" xref="S2.p7.2.m2.1.1.3.cmml">G</mi><mo lspace="0em" rspace="0em" id="S2.p7.2.m2.1.1.2" xref="S2.p7.2.m2.1.1.2.cmml">​</mo><mrow id="S2.p7.2.m2.1.1.1.1" xref="S2.p7.2.m2.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.p7.2.m2.1.1.1.1.2" xref="S2.p7.2.m2.1.1.1.1.1.cmml">(</mo><msup id="S2.p7.2.m2.1.1.1.1.1" xref="S2.p7.2.m2.1.1.1.1.1.cmml"><mi id="S2.p7.2.m2.1.1.1.1.1.2" xref="S2.p7.2.m2.1.1.1.1.1.2.cmml">θ</mi><mi id="S2.p7.2.m2.1.1.1.1.1.3" xref="S2.p7.2.m2.1.1.1.1.1.3.cmml">S</mi></msup><mo stretchy="false" id="S2.p7.2.m2.1.1.1.1.3" xref="S2.p7.2.m2.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.p7.2.m2.1b"><apply id="S2.p7.2.m2.1.1.cmml" xref="S2.p7.2.m2.1.1"><times id="S2.p7.2.m2.1.1.2.cmml" xref="S2.p7.2.m2.1.1.2"></times><ci id="S2.p7.2.m2.1.1.3.cmml" xref="S2.p7.2.m2.1.1.3">𝐺</ci><apply id="S2.p7.2.m2.1.1.1.1.1.cmml" xref="S2.p7.2.m2.1.1.1.1"><csymbol cd="ambiguous" id="S2.p7.2.m2.1.1.1.1.1.1.cmml" xref="S2.p7.2.m2.1.1.1.1">superscript</csymbol><ci id="S2.p7.2.m2.1.1.1.1.1.2.cmml" xref="S2.p7.2.m2.1.1.1.1.1.2">𝜃</ci><ci id="S2.p7.2.m2.1.1.1.1.1.3.cmml" xref="S2.p7.2.m2.1.1.1.1.1.3">𝑆</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p7.2.m2.1c">G(\theta^{S})</annotation></semantics></math>. The global model can be stored in the active client, or a trust-worthy server. Then, the embeddings are aggregated to predict labels of shared samples. The predicted labels <math id="S2.p7.3.m3.1" class="ltx_Math" alttext="\hat{y}^{S}" display="inline"><semantics id="S2.p7.3.m3.1a"><msup id="S2.p7.3.m3.1.1" xref="S2.p7.3.m3.1.1.cmml"><mover accent="true" id="S2.p7.3.m3.1.1.2" xref="S2.p7.3.m3.1.1.2.cmml"><mi id="S2.p7.3.m3.1.1.2.2" xref="S2.p7.3.m3.1.1.2.2.cmml">y</mi><mo id="S2.p7.3.m3.1.1.2.1" xref="S2.p7.3.m3.1.1.2.1.cmml">^</mo></mover><mi id="S2.p7.3.m3.1.1.3" xref="S2.p7.3.m3.1.1.3.cmml">S</mi></msup><annotation-xml encoding="MathML-Content" id="S2.p7.3.m3.1b"><apply id="S2.p7.3.m3.1.1.cmml" xref="S2.p7.3.m3.1.1"><csymbol cd="ambiguous" id="S2.p7.3.m3.1.1.1.cmml" xref="S2.p7.3.m3.1.1">superscript</csymbol><apply id="S2.p7.3.m3.1.1.2.cmml" xref="S2.p7.3.m3.1.1.2"><ci id="S2.p7.3.m3.1.1.2.1.cmml" xref="S2.p7.3.m3.1.1.2.1">^</ci><ci id="S2.p7.3.m3.1.1.2.2.cmml" xref="S2.p7.3.m3.1.1.2.2">𝑦</ci></apply><ci id="S2.p7.3.m3.1.1.3.cmml" xref="S2.p7.3.m3.1.1.3">𝑆</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p7.3.m3.1c">\hat{y}^{S}</annotation></semantics></math> for the samples <math id="S2.p7.4.m4.1" class="ltx_Math" alttext="x^{S}\in D^{S}" display="inline"><semantics id="S2.p7.4.m4.1a"><mrow id="S2.p7.4.m4.1.1" xref="S2.p7.4.m4.1.1.cmml"><msup id="S2.p7.4.m4.1.1.2" xref="S2.p7.4.m4.1.1.2.cmml"><mi id="S2.p7.4.m4.1.1.2.2" xref="S2.p7.4.m4.1.1.2.2.cmml">x</mi><mi id="S2.p7.4.m4.1.1.2.3" xref="S2.p7.4.m4.1.1.2.3.cmml">S</mi></msup><mo id="S2.p7.4.m4.1.1.1" xref="S2.p7.4.m4.1.1.1.cmml">∈</mo><msup id="S2.p7.4.m4.1.1.3" xref="S2.p7.4.m4.1.1.3.cmml"><mi id="S2.p7.4.m4.1.1.3.2" xref="S2.p7.4.m4.1.1.3.2.cmml">D</mi><mi id="S2.p7.4.m4.1.1.3.3" xref="S2.p7.4.m4.1.1.3.3.cmml">S</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="S2.p7.4.m4.1b"><apply id="S2.p7.4.m4.1.1.cmml" xref="S2.p7.4.m4.1.1"><in id="S2.p7.4.m4.1.1.1.cmml" xref="S2.p7.4.m4.1.1.1"></in><apply id="S2.p7.4.m4.1.1.2.cmml" xref="S2.p7.4.m4.1.1.2"><csymbol cd="ambiguous" id="S2.p7.4.m4.1.1.2.1.cmml" xref="S2.p7.4.m4.1.1.2">superscript</csymbol><ci id="S2.p7.4.m4.1.1.2.2.cmml" xref="S2.p7.4.m4.1.1.2.2">𝑥</ci><ci id="S2.p7.4.m4.1.1.2.3.cmml" xref="S2.p7.4.m4.1.1.2.3">𝑆</ci></apply><apply id="S2.p7.4.m4.1.1.3.cmml" xref="S2.p7.4.m4.1.1.3"><csymbol cd="ambiguous" id="S2.p7.4.m4.1.1.3.1.cmml" xref="S2.p7.4.m4.1.1.3">superscript</csymbol><ci id="S2.p7.4.m4.1.1.3.2.cmml" xref="S2.p7.4.m4.1.1.3.2">𝐷</ci><ci id="S2.p7.4.m4.1.1.3.3.cmml" xref="S2.p7.4.m4.1.1.3.3">𝑆</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p7.4.m4.1c">x^{S}\in D^{S}</annotation></semantics></math> are defined as:</p>
</div>
<div id="S2.p8" class="ltx_para">
<table id="S2.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left"><span class="ltx_tag ltx_tag_equation ltx_align_left">(2)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E2.m1.1" class="ltx_Math" alttext="{\hat{y}^{S}=G(H^{S};\theta^{S}).}" display="block"><semantics id="S2.E2.m1.1a"><mrow id="S2.E2.m1.1.1.1" xref="S2.E2.m1.1.1.1.1.cmml"><mrow id="S2.E2.m1.1.1.1.1" xref="S2.E2.m1.1.1.1.1.cmml"><msup id="S2.E2.m1.1.1.1.1.4" xref="S2.E2.m1.1.1.1.1.4.cmml"><mover accent="true" id="S2.E2.m1.1.1.1.1.4.2" xref="S2.E2.m1.1.1.1.1.4.2.cmml"><mi id="S2.E2.m1.1.1.1.1.4.2.2" xref="S2.E2.m1.1.1.1.1.4.2.2.cmml">y</mi><mo id="S2.E2.m1.1.1.1.1.4.2.1" xref="S2.E2.m1.1.1.1.1.4.2.1.cmml">^</mo></mover><mi id="S2.E2.m1.1.1.1.1.4.3" xref="S2.E2.m1.1.1.1.1.4.3.cmml">S</mi></msup><mo id="S2.E2.m1.1.1.1.1.3" xref="S2.E2.m1.1.1.1.1.3.cmml">=</mo><mrow id="S2.E2.m1.1.1.1.1.2" xref="S2.E2.m1.1.1.1.1.2.cmml"><mi id="S2.E2.m1.1.1.1.1.2.4" xref="S2.E2.m1.1.1.1.1.2.4.cmml">G</mi><mo lspace="0em" rspace="0em" id="S2.E2.m1.1.1.1.1.2.3" xref="S2.E2.m1.1.1.1.1.2.3.cmml">​</mo><mrow id="S2.E2.m1.1.1.1.1.2.2.2" xref="S2.E2.m1.1.1.1.1.2.2.3.cmml"><mo stretchy="false" id="S2.E2.m1.1.1.1.1.2.2.2.3" xref="S2.E2.m1.1.1.1.1.2.2.3.cmml">(</mo><msup id="S2.E2.m1.1.1.1.1.1.1.1.1" xref="S2.E2.m1.1.1.1.1.1.1.1.1.cmml"><mi id="S2.E2.m1.1.1.1.1.1.1.1.1.2" xref="S2.E2.m1.1.1.1.1.1.1.1.1.2.cmml">H</mi><mi id="S2.E2.m1.1.1.1.1.1.1.1.1.3" xref="S2.E2.m1.1.1.1.1.1.1.1.1.3.cmml">S</mi></msup><mo id="S2.E2.m1.1.1.1.1.2.2.2.4" xref="S2.E2.m1.1.1.1.1.2.2.3.cmml">;</mo><msup id="S2.E2.m1.1.1.1.1.2.2.2.2" xref="S2.E2.m1.1.1.1.1.2.2.2.2.cmml"><mi id="S2.E2.m1.1.1.1.1.2.2.2.2.2" xref="S2.E2.m1.1.1.1.1.2.2.2.2.2.cmml">θ</mi><mi id="S2.E2.m1.1.1.1.1.2.2.2.2.3" xref="S2.E2.m1.1.1.1.1.2.2.2.2.3.cmml">S</mi></msup><mo stretchy="false" id="S2.E2.m1.1.1.1.1.2.2.2.5" xref="S2.E2.m1.1.1.1.1.2.2.3.cmml">)</mo></mrow></mrow></mrow><mo lspace="0em" id="S2.E2.m1.1.1.1.2" xref="S2.E2.m1.1.1.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.E2.m1.1b"><apply id="S2.E2.m1.1.1.1.1.cmml" xref="S2.E2.m1.1.1.1"><eq id="S2.E2.m1.1.1.1.1.3.cmml" xref="S2.E2.m1.1.1.1.1.3"></eq><apply id="S2.E2.m1.1.1.1.1.4.cmml" xref="S2.E2.m1.1.1.1.1.4"><csymbol cd="ambiguous" id="S2.E2.m1.1.1.1.1.4.1.cmml" xref="S2.E2.m1.1.1.1.1.4">superscript</csymbol><apply id="S2.E2.m1.1.1.1.1.4.2.cmml" xref="S2.E2.m1.1.1.1.1.4.2"><ci id="S2.E2.m1.1.1.1.1.4.2.1.cmml" xref="S2.E2.m1.1.1.1.1.4.2.1">^</ci><ci id="S2.E2.m1.1.1.1.1.4.2.2.cmml" xref="S2.E2.m1.1.1.1.1.4.2.2">𝑦</ci></apply><ci id="S2.E2.m1.1.1.1.1.4.3.cmml" xref="S2.E2.m1.1.1.1.1.4.3">𝑆</ci></apply><apply id="S2.E2.m1.1.1.1.1.2.cmml" xref="S2.E2.m1.1.1.1.1.2"><times id="S2.E2.m1.1.1.1.1.2.3.cmml" xref="S2.E2.m1.1.1.1.1.2.3"></times><ci id="S2.E2.m1.1.1.1.1.2.4.cmml" xref="S2.E2.m1.1.1.1.1.2.4">𝐺</ci><list id="S2.E2.m1.1.1.1.1.2.2.3.cmml" xref="S2.E2.m1.1.1.1.1.2.2.2"><apply id="S2.E2.m1.1.1.1.1.1.1.1.1.cmml" xref="S2.E2.m1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E2.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E2.m1.1.1.1.1.1.1.1.1">superscript</csymbol><ci id="S2.E2.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E2.m1.1.1.1.1.1.1.1.1.2">𝐻</ci><ci id="S2.E2.m1.1.1.1.1.1.1.1.1.3.cmml" xref="S2.E2.m1.1.1.1.1.1.1.1.1.3">𝑆</ci></apply><apply id="S2.E2.m1.1.1.1.1.2.2.2.2.cmml" xref="S2.E2.m1.1.1.1.1.2.2.2.2"><csymbol cd="ambiguous" id="S2.E2.m1.1.1.1.1.2.2.2.2.1.cmml" xref="S2.E2.m1.1.1.1.1.2.2.2.2">superscript</csymbol><ci id="S2.E2.m1.1.1.1.1.2.2.2.2.2.cmml" xref="S2.E2.m1.1.1.1.1.2.2.2.2.2">𝜃</ci><ci id="S2.E2.m1.1.1.1.1.2.2.2.2.3.cmml" xref="S2.E2.m1.1.1.1.1.2.2.2.2.3">𝑆</ci></apply></list></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E2.m1.1c">{\hat{y}^{S}=G(H^{S};\theta^{S}).}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div id="S2.p9" class="ltx_para">
<p id="S2.p9.1" class="ltx_p">The objective of collaborative learning is defined as follows:</p>
</div>
<div id="S2.p10" class="ltx_para">
<table id="S2.E3" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left"><span class="ltx_tag ltx_tag_equation ltx_align_left">(3)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E3.m1.6" class="ltx_Math" alttext="{\theta^{1},...,\theta^{k},\theta^{S}=\arg\min_{\theta^{1},...,\theta^{k},\theta^{S}}\mathcal{L}(\hat{y}^{S},y^{S}),}" display="block"><semantics id="S2.E3.m1.6a"><mrow id="S2.E3.m1.6.6.1" xref="S2.E3.m1.6.6.1.1.cmml"><mrow id="S2.E3.m1.6.6.1.1" xref="S2.E3.m1.6.6.1.1.cmml"><mrow id="S2.E3.m1.6.6.1.1.3.3" xref="S2.E3.m1.6.6.1.1.3.4.cmml"><msup id="S2.E3.m1.6.6.1.1.1.1.1" xref="S2.E3.m1.6.6.1.1.1.1.1.cmml"><mi id="S2.E3.m1.6.6.1.1.1.1.1.2" xref="S2.E3.m1.6.6.1.1.1.1.1.2.cmml">θ</mi><mn id="S2.E3.m1.6.6.1.1.1.1.1.3" xref="S2.E3.m1.6.6.1.1.1.1.1.3.cmml">1</mn></msup><mo id="S2.E3.m1.6.6.1.1.3.3.4" xref="S2.E3.m1.6.6.1.1.3.4.cmml">,</mo><mi mathvariant="normal" id="S2.E3.m1.5.5" xref="S2.E3.m1.5.5.cmml">…</mi><mo id="S2.E3.m1.6.6.1.1.3.3.5" xref="S2.E3.m1.6.6.1.1.3.4.cmml">,</mo><msup id="S2.E3.m1.6.6.1.1.2.2.2" xref="S2.E3.m1.6.6.1.1.2.2.2.cmml"><mi id="S2.E3.m1.6.6.1.1.2.2.2.2" xref="S2.E3.m1.6.6.1.1.2.2.2.2.cmml">θ</mi><mi id="S2.E3.m1.6.6.1.1.2.2.2.3" xref="S2.E3.m1.6.6.1.1.2.2.2.3.cmml">k</mi></msup><mo id="S2.E3.m1.6.6.1.1.3.3.6" xref="S2.E3.m1.6.6.1.1.3.4.cmml">,</mo><msup id="S2.E3.m1.6.6.1.1.3.3.3" xref="S2.E3.m1.6.6.1.1.3.3.3.cmml"><mi id="S2.E3.m1.6.6.1.1.3.3.3.2" xref="S2.E3.m1.6.6.1.1.3.3.3.2.cmml">θ</mi><mi id="S2.E3.m1.6.6.1.1.3.3.3.3" xref="S2.E3.m1.6.6.1.1.3.3.3.3.cmml">S</mi></msup></mrow><mo id="S2.E3.m1.6.6.1.1.6" xref="S2.E3.m1.6.6.1.1.6.cmml">=</mo><mrow id="S2.E3.m1.6.6.1.1.5" xref="S2.E3.m1.6.6.1.1.5.cmml"><mrow id="S2.E3.m1.6.6.1.1.5.4" xref="S2.E3.m1.6.6.1.1.5.4.cmml"><mi id="S2.E3.m1.6.6.1.1.5.4.1" xref="S2.E3.m1.6.6.1.1.5.4.1.cmml">arg</mi><mo lspace="0.167em" id="S2.E3.m1.6.6.1.1.5.4a" xref="S2.E3.m1.6.6.1.1.5.4.cmml">⁡</mo><mrow id="S2.E3.m1.6.6.1.1.5.4.2" xref="S2.E3.m1.6.6.1.1.5.4.2.cmml"><munder id="S2.E3.m1.6.6.1.1.5.4.2.1" xref="S2.E3.m1.6.6.1.1.5.4.2.1.cmml"><mi id="S2.E3.m1.6.6.1.1.5.4.2.1.2" xref="S2.E3.m1.6.6.1.1.5.4.2.1.2.cmml">min</mi><mrow id="S2.E3.m1.4.4.4.4" xref="S2.E3.m1.4.4.4.5.cmml"><msup id="S2.E3.m1.2.2.2.2.1" xref="S2.E3.m1.2.2.2.2.1.cmml"><mi id="S2.E3.m1.2.2.2.2.1.2" xref="S2.E3.m1.2.2.2.2.1.2.cmml">θ</mi><mn id="S2.E3.m1.2.2.2.2.1.3" xref="S2.E3.m1.2.2.2.2.1.3.cmml">1</mn></msup><mo id="S2.E3.m1.4.4.4.4.4" xref="S2.E3.m1.4.4.4.5.cmml">,</mo><mi mathvariant="normal" id="S2.E3.m1.1.1.1.1" xref="S2.E3.m1.1.1.1.1.cmml">…</mi><mo id="S2.E3.m1.4.4.4.4.5" xref="S2.E3.m1.4.4.4.5.cmml">,</mo><msup id="S2.E3.m1.3.3.3.3.2" xref="S2.E3.m1.3.3.3.3.2.cmml"><mi id="S2.E3.m1.3.3.3.3.2.2" xref="S2.E3.m1.3.3.3.3.2.2.cmml">θ</mi><mi id="S2.E3.m1.3.3.3.3.2.3" xref="S2.E3.m1.3.3.3.3.2.3.cmml">k</mi></msup><mo id="S2.E3.m1.4.4.4.4.6" xref="S2.E3.m1.4.4.4.5.cmml">,</mo><msup id="S2.E3.m1.4.4.4.4.3" xref="S2.E3.m1.4.4.4.4.3.cmml"><mi id="S2.E3.m1.4.4.4.4.3.2" xref="S2.E3.m1.4.4.4.4.3.2.cmml">θ</mi><mi id="S2.E3.m1.4.4.4.4.3.3" xref="S2.E3.m1.4.4.4.4.3.3.cmml">S</mi></msup></mrow></munder><mo lspace="0.167em" id="S2.E3.m1.6.6.1.1.5.4.2a" xref="S2.E3.m1.6.6.1.1.5.4.2.cmml">⁡</mo><mi class="ltx_font_mathcaligraphic" id="S2.E3.m1.6.6.1.1.5.4.2.2" xref="S2.E3.m1.6.6.1.1.5.4.2.2.cmml">ℒ</mi></mrow></mrow><mo lspace="0em" rspace="0em" id="S2.E3.m1.6.6.1.1.5.3" xref="S2.E3.m1.6.6.1.1.5.3.cmml">​</mo><mrow id="S2.E3.m1.6.6.1.1.5.2.2" xref="S2.E3.m1.6.6.1.1.5.2.3.cmml"><mo stretchy="false" id="S2.E3.m1.6.6.1.1.5.2.2.3" xref="S2.E3.m1.6.6.1.1.5.2.3.cmml">(</mo><msup id="S2.E3.m1.6.6.1.1.4.1.1.1" xref="S2.E3.m1.6.6.1.1.4.1.1.1.cmml"><mover accent="true" id="S2.E3.m1.6.6.1.1.4.1.1.1.2" xref="S2.E3.m1.6.6.1.1.4.1.1.1.2.cmml"><mi id="S2.E3.m1.6.6.1.1.4.1.1.1.2.2" xref="S2.E3.m1.6.6.1.1.4.1.1.1.2.2.cmml">y</mi><mo id="S2.E3.m1.6.6.1.1.4.1.1.1.2.1" xref="S2.E3.m1.6.6.1.1.4.1.1.1.2.1.cmml">^</mo></mover><mi id="S2.E3.m1.6.6.1.1.4.1.1.1.3" xref="S2.E3.m1.6.6.1.1.4.1.1.1.3.cmml">S</mi></msup><mo id="S2.E3.m1.6.6.1.1.5.2.2.4" xref="S2.E3.m1.6.6.1.1.5.2.3.cmml">,</mo><msup id="S2.E3.m1.6.6.1.1.5.2.2.2" xref="S2.E3.m1.6.6.1.1.5.2.2.2.cmml"><mi id="S2.E3.m1.6.6.1.1.5.2.2.2.2" xref="S2.E3.m1.6.6.1.1.5.2.2.2.2.cmml">y</mi><mi id="S2.E3.m1.6.6.1.1.5.2.2.2.3" xref="S2.E3.m1.6.6.1.1.5.2.2.2.3.cmml">S</mi></msup><mo stretchy="false" id="S2.E3.m1.6.6.1.1.5.2.2.5" xref="S2.E3.m1.6.6.1.1.5.2.3.cmml">)</mo></mrow></mrow></mrow><mo id="S2.E3.m1.6.6.1.2" xref="S2.E3.m1.6.6.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.E3.m1.6b"><apply id="S2.E3.m1.6.6.1.1.cmml" xref="S2.E3.m1.6.6.1"><eq id="S2.E3.m1.6.6.1.1.6.cmml" xref="S2.E3.m1.6.6.1.1.6"></eq><list id="S2.E3.m1.6.6.1.1.3.4.cmml" xref="S2.E3.m1.6.6.1.1.3.3"><apply id="S2.E3.m1.6.6.1.1.1.1.1.cmml" xref="S2.E3.m1.6.6.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E3.m1.6.6.1.1.1.1.1.1.cmml" xref="S2.E3.m1.6.6.1.1.1.1.1">superscript</csymbol><ci id="S2.E3.m1.6.6.1.1.1.1.1.2.cmml" xref="S2.E3.m1.6.6.1.1.1.1.1.2">𝜃</ci><cn type="integer" id="S2.E3.m1.6.6.1.1.1.1.1.3.cmml" xref="S2.E3.m1.6.6.1.1.1.1.1.3">1</cn></apply><ci id="S2.E3.m1.5.5.cmml" xref="S2.E3.m1.5.5">…</ci><apply id="S2.E3.m1.6.6.1.1.2.2.2.cmml" xref="S2.E3.m1.6.6.1.1.2.2.2"><csymbol cd="ambiguous" id="S2.E3.m1.6.6.1.1.2.2.2.1.cmml" xref="S2.E3.m1.6.6.1.1.2.2.2">superscript</csymbol><ci id="S2.E3.m1.6.6.1.1.2.2.2.2.cmml" xref="S2.E3.m1.6.6.1.1.2.2.2.2">𝜃</ci><ci id="S2.E3.m1.6.6.1.1.2.2.2.3.cmml" xref="S2.E3.m1.6.6.1.1.2.2.2.3">𝑘</ci></apply><apply id="S2.E3.m1.6.6.1.1.3.3.3.cmml" xref="S2.E3.m1.6.6.1.1.3.3.3"><csymbol cd="ambiguous" id="S2.E3.m1.6.6.1.1.3.3.3.1.cmml" xref="S2.E3.m1.6.6.1.1.3.3.3">superscript</csymbol><ci id="S2.E3.m1.6.6.1.1.3.3.3.2.cmml" xref="S2.E3.m1.6.6.1.1.3.3.3.2">𝜃</ci><ci id="S2.E3.m1.6.6.1.1.3.3.3.3.cmml" xref="S2.E3.m1.6.6.1.1.3.3.3.3">𝑆</ci></apply></list><apply id="S2.E3.m1.6.6.1.1.5.cmml" xref="S2.E3.m1.6.6.1.1.5"><times id="S2.E3.m1.6.6.1.1.5.3.cmml" xref="S2.E3.m1.6.6.1.1.5.3"></times><apply id="S2.E3.m1.6.6.1.1.5.4.cmml" xref="S2.E3.m1.6.6.1.1.5.4"><arg id="S2.E3.m1.6.6.1.1.5.4.1.cmml" xref="S2.E3.m1.6.6.1.1.5.4.1"></arg><apply id="S2.E3.m1.6.6.1.1.5.4.2.cmml" xref="S2.E3.m1.6.6.1.1.5.4.2"><apply id="S2.E3.m1.6.6.1.1.5.4.2.1.cmml" xref="S2.E3.m1.6.6.1.1.5.4.2.1"><csymbol cd="ambiguous" id="S2.E3.m1.6.6.1.1.5.4.2.1.1.cmml" xref="S2.E3.m1.6.6.1.1.5.4.2.1">subscript</csymbol><min id="S2.E3.m1.6.6.1.1.5.4.2.1.2.cmml" xref="S2.E3.m1.6.6.1.1.5.4.2.1.2"></min><list id="S2.E3.m1.4.4.4.5.cmml" xref="S2.E3.m1.4.4.4.4"><apply id="S2.E3.m1.2.2.2.2.1.cmml" xref="S2.E3.m1.2.2.2.2.1"><csymbol cd="ambiguous" id="S2.E3.m1.2.2.2.2.1.1.cmml" xref="S2.E3.m1.2.2.2.2.1">superscript</csymbol><ci id="S2.E3.m1.2.2.2.2.1.2.cmml" xref="S2.E3.m1.2.2.2.2.1.2">𝜃</ci><cn type="integer" id="S2.E3.m1.2.2.2.2.1.3.cmml" xref="S2.E3.m1.2.2.2.2.1.3">1</cn></apply><ci id="S2.E3.m1.1.1.1.1.cmml" xref="S2.E3.m1.1.1.1.1">…</ci><apply id="S2.E3.m1.3.3.3.3.2.cmml" xref="S2.E3.m1.3.3.3.3.2"><csymbol cd="ambiguous" id="S2.E3.m1.3.3.3.3.2.1.cmml" xref="S2.E3.m1.3.3.3.3.2">superscript</csymbol><ci id="S2.E3.m1.3.3.3.3.2.2.cmml" xref="S2.E3.m1.3.3.3.3.2.2">𝜃</ci><ci id="S2.E3.m1.3.3.3.3.2.3.cmml" xref="S2.E3.m1.3.3.3.3.2.3">𝑘</ci></apply><apply id="S2.E3.m1.4.4.4.4.3.cmml" xref="S2.E3.m1.4.4.4.4.3"><csymbol cd="ambiguous" id="S2.E3.m1.4.4.4.4.3.1.cmml" xref="S2.E3.m1.4.4.4.4.3">superscript</csymbol><ci id="S2.E3.m1.4.4.4.4.3.2.cmml" xref="S2.E3.m1.4.4.4.4.3.2">𝜃</ci><ci id="S2.E3.m1.4.4.4.4.3.3.cmml" xref="S2.E3.m1.4.4.4.4.3.3">𝑆</ci></apply></list></apply><ci id="S2.E3.m1.6.6.1.1.5.4.2.2.cmml" xref="S2.E3.m1.6.6.1.1.5.4.2.2">ℒ</ci></apply></apply><interval closure="open" id="S2.E3.m1.6.6.1.1.5.2.3.cmml" xref="S2.E3.m1.6.6.1.1.5.2.2"><apply id="S2.E3.m1.6.6.1.1.4.1.1.1.cmml" xref="S2.E3.m1.6.6.1.1.4.1.1.1"><csymbol cd="ambiguous" id="S2.E3.m1.6.6.1.1.4.1.1.1.1.cmml" xref="S2.E3.m1.6.6.1.1.4.1.1.1">superscript</csymbol><apply id="S2.E3.m1.6.6.1.1.4.1.1.1.2.cmml" xref="S2.E3.m1.6.6.1.1.4.1.1.1.2"><ci id="S2.E3.m1.6.6.1.1.4.1.1.1.2.1.cmml" xref="S2.E3.m1.6.6.1.1.4.1.1.1.2.1">^</ci><ci id="S2.E3.m1.6.6.1.1.4.1.1.1.2.2.cmml" xref="S2.E3.m1.6.6.1.1.4.1.1.1.2.2">𝑦</ci></apply><ci id="S2.E3.m1.6.6.1.1.4.1.1.1.3.cmml" xref="S2.E3.m1.6.6.1.1.4.1.1.1.3">𝑆</ci></apply><apply id="S2.E3.m1.6.6.1.1.5.2.2.2.cmml" xref="S2.E3.m1.6.6.1.1.5.2.2.2"><csymbol cd="ambiguous" id="S2.E3.m1.6.6.1.1.5.2.2.2.1.cmml" xref="S2.E3.m1.6.6.1.1.5.2.2.2">superscript</csymbol><ci id="S2.E3.m1.6.6.1.1.5.2.2.2.2.cmml" xref="S2.E3.m1.6.6.1.1.5.2.2.2.2">𝑦</ci><ci id="S2.E3.m1.6.6.1.1.5.2.2.2.3.cmml" xref="S2.E3.m1.6.6.1.1.5.2.2.2.3">𝑆</ci></apply></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E3.m1.6c">{\theta^{1},...,\theta^{k},\theta^{S}=\arg\min_{\theta^{1},...,\theta^{k},\theta^{S}}\mathcal{L}(\hat{y}^{S},y^{S}),}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p id="S2.p10.1" class="ltx_p">where <math id="S2.p10.1.m1.1" class="ltx_Math" alttext="\mathcal{L}" display="inline"><semantics id="S2.p10.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S2.p10.1.m1.1.1" xref="S2.p10.1.m1.1.1.cmml">ℒ</mi><annotation-xml encoding="MathML-Content" id="S2.p10.1.m1.1b"><ci id="S2.p10.1.m1.1.1.cmml" xref="S2.p10.1.m1.1.1">ℒ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p10.1.m1.1c">\mathcal{L}</annotation></semantics></math> is the loss function of the collaboration learning task. For instance, an alternative loss function could be the cross-entropy loss for the classification task.</p>
</div>
<div id="S2.p11" class="ltx_para">
<p id="S2.p11.1" class="ltx_p"><span id="S2.p11.1.1" class="ltx_text ltx_font_bold">Coordinator.</span> To provide secure ensurance, a trust-worthy coordinator is introduced. It controls the privacy protocol of secure communication and the sample alignment process. In VFL, the coordinator can be the active client or a third-party server. The general flow of training and testing in VFL is illustrated in <a href="#S2.F3" title="In 2. Preliminary ‣ Vertical Federated Learning for Effectiveness, Security, Applicability: A Survey" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">3</span></a>. In the training stage, the local data is transformed into embeddings and aggregated by the global model, and then the gradients are backward to both the global model and local models for model updation. In the testing stage, the data of test samples is transformed and transmitted to the trained global model for prediction.</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3. </span>Effectiveness</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">In the typical setting of Vertical Federated Learning (VFL), data is distributed across different clients by feature, with the objective of training a global model within a privacy-preserving framework. The cornerstone of VFL lies in crafting a foundational paradigm for efficiently extracting information from these distributed features. To enhance effectiveness in the basic setup of VFL, efforts have concentrated on two main areas: Firstly, recent studies have focused on developing fundamental models for VFL that facilitate effective collaboration while ensuring privacy. Secondly, pioneering research has explored ways to extract more valuable information from all features or clients by assessing the importance of each feature or client. We will elaborate on these aspects in detail next.</p>
</div>
<figure id="S3.F4" class="ltx_figure"><img src="/html/2405.17495/assets/x4.png" id="S3.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="415" height="197" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4. </span><span id="S3.F4.2.1" class="ltx_text ltx_font_bold">The illustration of Tree-based/Neural Network-based model.</span> (a) For the tree-based model in VFL, each client trains a part of the tree model using partitioned features. These partial trees are then combined to construct the global tree model. (b) For the Neural Network-based model, each client trains its local model to extract embeddings. The global model is then trained in the active client using embeddings from all clients.</figcaption>
</figure>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1. </span>Model Design</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">In traditional machine learning, the raw data is centralized, and the whole model can be applied to learning the data in a single client. However, the traditional models are not applicable in VFL due to the decentralized features. The specific model designs are needed in VFL to ensure that decentralized features are aggregated in a privacy-preserving paradigm, which forms the foundation for effective collaboration. It can be categorized into two different types based on their basic architecture:</p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.1" class="ltx_p"><span id="S3.SS1.p2.1.1" class="ltx_text ltx_font_bold">Tree-based Model.</span> It is a lightweight design for distributed feature aggregation, suitable for making rapid predictions with modest accuracy. To maintain a basic privacy-preserving flow in VFL, several studies <cite class="ltx_cite ltx_citemacro_citep">(Wu et al<span class="ltx_text">.</span>, <a href="#bib.bib170" title="" class="ltx_ref">2020</a>; Cheng et al<span class="ltx_text">.</span>, <a href="#bib.bib31" title="" class="ltx_ref">2021</a>; Chen et al<span class="ltx_text">.</span>, <a href="#bib.bib27" title="" class="ltx_ref">2021</a>; Feng et al<span class="ltx_text">.</span>, <a href="#bib.bib47" title="" class="ltx_ref">2019</a>; Fang et al<span class="ltx_text">.</span>, <a href="#bib.bib42" title="" class="ltx_ref">2021</a>)</cite> propose utilizing encryption strategies with ID and feature embeddings to enable private alignment and aggregation, effectively training a split tree model. Other works <cite class="ltx_cite ltx_citemacro_citep">(Tian et al<span class="ltx_text">.</span>, <a href="#bib.bib158" title="" class="ltx_ref">2020</a>; Li et al<span class="ltx_text">.</span>, <a href="#bib.bib103" title="" class="ltx_ref">2022</a>)</cite> focus on constructing a privacy-preserving paradigm while achieving effective feature aggregation. Additionally, random forest-based approaches <cite class="ltx_cite ltx_citemacro_citep">(Liu et al<span class="ltx_text">.</span>, <a href="#bib.bib114" title="" class="ltx_ref">2020b</a>; Yao et al<span class="ltx_text">.</span>, <a href="#bib.bib185" title="" class="ltx_ref">2022</a>; Hou et al<span class="ltx_text">.</span>, <a href="#bib.bib68" title="" class="ltx_ref">2021</a>)</cite> have been introduced, employing bagging strategies to enhance training effectiveness. Liu <span id="S3.SS1.p2.1.2" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_citep">(Liu et al<span class="ltx_text">.</span>, <a href="#bib.bib114" title="" class="ltx_ref">2020b</a>)</cite> suggest using the CART tree combined with bagging and a trustworthy third party to develop a random forest algorithm specifically for vertical federated learning. Yao <span id="S3.SS1.p2.1.3" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_citep">(Yao et al<span class="ltx_text">.</span>, <a href="#bib.bib185" title="" class="ltx_ref">2022</a>)</cite> utilize a random affine code to facilitate privacy-preserving collaboration, suitable for large-scale data applications. Hou <span id="S3.SS1.p2.1.4" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_citep">(Hou et al<span class="ltx_text">.</span>, <a href="#bib.bib68" title="" class="ltx_ref">2021</a>)</cite> introduce a verifiable strategy for random forests in VFL to ensure effective collaboration among dynamically changing participants. Squirrel <cite class="ltx_cite ltx_citemacro_citep">(Lu et al<span class="ltx_text">.</span>, <a href="#bib.bib120" title="" class="ltx_ref">2023</a>)</cite> enables two data owners to train a GBDT model on vertically split datasets without revealing sensitive information, safeguarding privacy against semi-honest adversaries. This framework combines novel GBDT algorithm designs with advanced cryptography, featuring efficient mechanisms for hiding sample distribution and optimized methods for gradient aggregation. However, it acknowledges the challenges of designing a secure and computationally efficient GBDT training protocol that is also communication-efficient under practical constraints such as limited high-speed bandwidth for cross-enterprise collaborative learning. The complexity of maintaining privacy during training and potential risks associated with publishing decision trees are highlighted as areas for further research. HybridTree <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a href="#bib.bib100" title="" class="ltx_ref">2023c</a>)</cite> incorporates party-specific knowledge by adding layers to the tree structure, enabling significant speed improvements in training times and providing a scalable solution for practical federated learning scenarios. However, the method is particularly suited for tabular data and may not directly apply to other data types like images or text.</p>
</div>
<div id="S3.SS1.p3" class="ltx_para">
<p id="S3.SS1.p3.1" class="ltx_p"><span id="S3.SS1.p3.1.1" class="ltx_text ltx_font_bold">Neural Network-Based Model.</span> It leverages deep neural networks, well-suited for handling complex data types (such as images, text, and audio) and tasks (like detection and recognition) within the VFL framework. Romanini <span id="S3.SS1.p3.1.2" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_citep">(Romanini et al<span class="ltx_text">.</span>, <a href="#bib.bib143" title="" class="ltx_ref">2021</a>)</cite> introduce PyVertical, a foundational design for vertical federated learning that utilizes split neural networks. This allows participants to train on vertically partitioned data features across different clients while keeping their raw data private. Feng <span id="S3.SS1.p3.1.3" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_citep">(Feng and Yu, <a href="#bib.bib46" title="" class="ltx_ref">2020</a>)</cite> explore a privacy-preserving label-sharing strategy. The proposed framework, MMVFL, facilitates effective collaboration among multiple participants through sparse learning and optimization with a global pseudo-label matrix. However, the assumption that data from all participants share the same label space limits the applicability of MMVFL. Liu <span id="S3.SS1.p3.1.4" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_citep">(Liu et al<span class="ltx_text">.</span>, <a href="#bib.bib112" title="" class="ltx_ref">2020a</a>)</cite> propose the Federated Transfer Learning (FTL) framework, which facilitates knowledge transfer from the source domain using overlapped samples and features. Addressing the gap for sequential data, Abedi <span id="S3.SS1.p3.1.5" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_citep">(Abedi and Khan, <a href="#bib.bib4" title="" class="ltx_ref">2024</a>)</cite> introduce FedSL, a split Recurrent Neural Network tailored for distributed sequential data processing.</p>
</div>
<figure id="S3.F5" class="ltx_figure"><img src="/html/2405.17495/assets/x5.png" id="S3.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="175" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5. </span><span id="S3.F5.2.1" class="ltx_text ltx_font_bold">The illustration of Feature &amp; Client Selection.</span> (a) Feature selection aims to identify crucial features for collaborative training across all clients. (b) Client selection involves choosing essential clients for collaboration.</figcaption>
</figure>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2. </span>Feature &amp; Client Selection</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">In vertical federated learning, multiple participants contribute distinct features for common samples to perform prediction tasks. However, the high-dimensional raw features often contain irrelevant or noisy information that does not relate to the current prediction task. These redundant features, present in some clients, add unnecessary costs or introduce noise, hindering the effectiveness of vertical federated learning. Hence, selecting critical features and clients becomes crucial in vertical federated learning to ensure effectiveness. Traditional feature selection algorithms are designed for centralized data and may not directly adapt to vertical federated learning, where features are distributed across different clients. Additionally, while some works focus on client selection in federated learning, they are typically designed for shared feature spaces with different samples, rendering them unsuitable for vertical federated learning. To enhance effectiveness, recent research has proposed a variety of novel feature and client selection methods tailored specifically for vertical federated learning. These methods can be categorized based on the different selection criteria, which are detailed as follows:</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.1" class="ltx_p"><span id="S3.SS2.p2.1.1" class="ltx_text ltx_font_bold">Feature Selection.</span>
One strategy to enhance effectiveness is to select critical features for collaboration. Li <span id="S3.SS2.p2.1.2" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a href="#bib.bib95" title="" class="ltx_ref">2023a</a>)</cite> propose a dual gate-based feature selection method, efficiently approximating the probability of feature selection. They also introduce a local perturbation method for enhanced privacy. LESS-VFL <cite class="ltx_cite ltx_citemacro_citep">(Castiglia et al<span class="ltx_text">.</span>, <a href="#bib.bib15" title="" class="ltx_ref">2023</a>)</cite> explores and formalizes the feature selection problem for VFL, and achieves communication-effective feature selection using the group lasso algorithm. Feng <span id="S3.SS2.p2.1.3" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_citep">(Feng, <a href="#bib.bib45" title="" class="ltx_ref">2022</a>)</cite> propose feature selection without sample alignment through local weight regularizations. Zhang <span id="S3.SS2.p2.1.4" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_citep">(Zhang et al<span class="ltx_text">.</span>, <a href="#bib.bib197" title="" class="ltx_ref">2022b</a>)</cite> introduce a privacy-preserving feature selection method for electronic health, utilizing Gini impurity to measure feature importance and proposing customized protocols for different eHealth scenarios. Fu <span id="S3.SS2.p2.1.5" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_citep">(Fu et al<span class="ltx_text">.</span>, <a href="#bib.bib51" title="" class="ltx_ref">2023</a>)</cite> propose FEAST, leveraging conditional mutual information to select informative features with low redundancy. PSO-EVFFS <cite class="ltx_cite ltx_citemacro_citep">(Zhang et al<span class="ltx_text">.</span>, <a href="#bib.bib201" title="" class="ltx_ref">2023b</a>)</cite> integrates evolutionary feature selection into the SecureBoost framework, optimizing both hyperparameters of the XGBoost model and feature subsets to improve accuracy while ensuring data privacy. However, generalization to other backbones remains unexplored.</p>
</div>
<div id="S3.SS2.p3" class="ltx_para">
<p id="S3.SS2.p3.1" class="ltx_p"><span id="S3.SS2.p3.1.1" class="ltx_text ltx_font_bold">Client Selection.</span>
In addition to feature-level selection, several studies focus on client selection for effectiveness. FedSV <cite class="ltx_cite ltx_citemacro_citep">(Wang et al<span class="ltx_text">.</span>, <a href="#bib.bib163" title="" class="ltx_ref">2019</a>)</cite> proposes to measure client contributions in VFL using Shapley Values. It calculates the Shapley value for each client during training and aggregates these values for the final contribution assessment. However, FedSV fails to achieve fairness as clients not selected in certain iterations are not considered. To address fairness concerns in client contribution measurement, Fan <span id="S3.SS2.p3.1.2" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_citep">(Fan et al<span class="ltx_text">.</span>, <a href="#bib.bib41" title="" class="ltx_ref">2024</a>)</cite> propose VerFedVS, where client contributions are calculated across multiple time stamps, and embeddings from different timestamps are utilized to ensure fairness. Moreover, VerFedVS is communication-efficient and applicable in both synchronous and asynchronous settings. For efficient and secure client selection, Jiang <span id="S3.SS2.p3.1.3" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_citep">(Jiang et al<span class="ltx_text">.</span>, <a href="#bib.bib81" title="" class="ltx_ref">2022a</a>)</cite> propose VF-MINE, which utilizes mutual information (MI) to select a subset of clients that preserves maximum MI. Additionally, VF-MINE ensures privacy protection through homomorphic encryption and optimizes communication costs between participants.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4. </span>Security</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">Security is a paramount concern in vertical federated learning, encompassing two critical aspects. Firstly, the threat of privacy leakage looms large, particularly during sample alignment and communication phases. Secondly, VFL faces the challenge of malicious attacks performed by evil parties. The attacks aim to access the private information of raw data or are designed to disrupt the collaborative learning process. As VFL involves multiple parties collaborating without sharing raw data, addressing these security concerns is essential not only for protecting the privacy of participants but also for constructing trust and reliability of the collaboration learning. In the following section, we illustrate the security issues in VFL into two aspects: Privacy Leakage and Malicious Attacks.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1. </span>Privacy Leakage</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">Privacy leakage poses a significant challenge in vertical federated learning, manifesting across various stages of the collaborative process <cite class="ltx_cite ltx_citemacro_citep">(Xu et al<span class="ltx_text">.</span>, <a href="#bib.bib175" title="" class="ltx_ref">2022</a>; Yu et al<span class="ltx_text">.</span>, <a href="#bib.bib190" title="" class="ltx_ref">2024</a>; Jiang et al<span class="ltx_text">.</span>, <a href="#bib.bib82" title="" class="ltx_ref">2022b</a>)</cite>. The first concern is the information leakage during sample alignment, where shared samples between different clients become susceptible to unintentional exposure. Besides, the transportation of embeddings and gradients between clients introduces further vulnerabilities. Leakage in embedding transportation entails the risk of revealing sensitive information encoded in the intermediate representations, while leakage in gradient transportation raises the potential for malicious entities to infer private information during the collaborative model training. Addressing these concerns becomes imperative to ensure the security and confidentiality of the VFL systems.</p>
</div>
<div id="S4.SS1.p2" class="ltx_para">
<p id="S4.SS1.p2.1" class="ltx_p"><span id="S4.SS1.p2.1.1" class="ltx_text ltx_font_bold">Leakage in Sample Alignment.</span>
Sample Alignment is the critical step for VFL, which aims to discover the common samples shared by the clients. However, privacy leakage during sample alignment presents a significant concern, arising from the necessity to compare a common identity or perform calculations with raw data. Sharing identities and raw data inadvertently introduces vulnerabilities that could compromise individual privacy of raw data. The fundamental challenge lies in achieving sample alignment without revealing private information, necessitating robust mechanisms and protocols to secure this process. To achieve privacy-preserving sample alignment, Hardy <span id="S4.SS1.p2.1.2" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_citep">(Hardy et al<span class="ltx_text">.</span>, <a href="#bib.bib63" title="" class="ltx_ref">2017</a>)</cite> propose the Privacy-Preserving Entity Resolution, where the raw data in clients is encrypted into a cryptographic long-term key (CLK). Subsequently, these CLKs are transmitted to the coordinator for matching entities, and the alignment information is then returned to the clients. It ensures the identification of common entities between different data providers without exposing private data. Lu <span id="S4.SS1.p2.1.3" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_citep">(Lu and Ding, <a href="#bib.bib119" title="" class="ltx_ref">2020</a>)</cite> propose a multi-party private set intersection protocol that can handle cases where some parties drop out during the protocol execution. It relies on lightweight cryptographic primitives for efficient operation and can handle dropout scenarios without significant performance impacts. FLORIST <cite class="ltx_cite ltx_citemacro_citep">(Sun et al<span class="ltx_text">.</span>, <a href="#bib.bib154" title="" class="ltx_ref">2021a</a>)</cite> utilizes Private Set Union (PSU) <cite class="ltx_cite ltx_citemacro_citep">(Kissner and Song, <a href="#bib.bib90" title="" class="ltx_ref">2005</a>; Davidson and Cid, <a href="#bib.bib35" title="" class="ltx_ref">2017</a>; Jia et al<span class="ltx_text">.</span>, <a href="#bib.bib80" title="" class="ltx_ref">2022</a>)</cite> to align data without revealing intersection membership. Besides, it employs synthetic data generation for samples outside the intersection to maintain privacy and model utility. However, the PSU protocol may increase the training sample size due to the union set, leading to higher training costs.</p>
</div>
<div id="S4.SS1.p3" class="ltx_para">
<p id="S4.SS1.p3.1" class="ltx_p"><span id="S4.SS1.p3.1.1" class="ltx_text ltx_font_bold">Leakage in Embeddings Transportation.</span>
In VFL, the intermediate embeddings are transmitted to the active client for training the global model. Privacy leakage in embedding transportation poses a critical concern in vertical federated learning, stemming from intermediate feature embeddings from each client inherently containing privacy-sensitive information derived from raw data. This issue becomes especially pronounced when considering potential malicious attackers or participants in collaboration. To address this challenge, Hardy <span id="S4.SS1.p3.1.2" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_citep">(Hardy et al<span class="ltx_text">.</span>, <a href="#bib.bib63" title="" class="ltx_ref">2017</a>)</cite> propose to leverage homomorphic encryption for intermediate embeddings, to ensure data privacy without leaking information from raw data. HDP-VFL <cite class="ltx_cite ltx_citemacro_citep">(Wang et al<span class="ltx_text">.</span>, <a href="#bib.bib162" title="" class="ltx_ref">2020</a>)</cite> enables joint learning of a generalized linear model (GLM) from vertically partitioned data with minimal cost in terms of training time and accuracy. It leverages differential privacy (DP) to protect intermediate results (IR) during VFL, avoiding the need for Homomorphic Encryption (HE) or Secure Multi-Party Computation (MPC). However, under limited privacy budgets, the accuracy of the joint model may be constrained. Falcon <cite class="ltx_cite ltx_citemacro_citep">(Wu et al<span class="ltx_text">.</span>, <a href="#bib.bib171" title="" class="ltx_ref">2023c</a>)</cite> supports VFL training for various machine learning models with strong privacy protection. It utilizes a hybrid strategy of threshold partially homomorphic encryption (PHE) and additive secret sharing scheme (SSS). Nevertheless, the requirements for threshold decryption in PHE and conversion to SSS can be computationally demanding.</p>
</div>
<div id="S4.SS1.p4" class="ltx_para">
<p id="S4.SS1.p4.1" class="ltx_p"><span id="S4.SS1.p4.1.1" class="ltx_text ltx_font_bold">Leakage in Gradient Transportation.</span> During collaboration learning, the updated gradients are sent back to each client. Privacy leakage in gradient transportation represents a pivotal security challenge, wherein the gradients encompass sensitive information related to both the labels and the local models. These components, crucial for the collaborative learning process, are inherently private to each client. The transmission of gradients during collaboration introduces a potential avenue for privacy leakage, particularly when considering malicious attackers seeking to exploit the leakages. To address the privacy leakage with gradients, recent works utilize encryption or differential privacy paradigm to the VFL algorithm. FedV <cite class="ltx_cite ltx_citemacro_citep">(Xu et al<span class="ltx_text">.</span>, <a href="#bib.bib176" title="" class="ltx_ref">2021</a>)</cite> enables collaborative training of models without peer-to-peer communication among parties. It uses functional encryption to secure gradient computation for models like linear regression, logistic regression, and SVMs. However, the use of functional encryption may introduce computational complexity. CRDP-FL <cite class="ltx_cite ltx_citemacro_citep">(Zhao et al<span class="ltx_text">.</span>, <a href="#bib.bib203" title="" class="ltx_ref">2022</a>)</cite> integrates differential privacy into a VFL framework to protect privacy while maintaining utility. It ensures strong privacy guarantees by injecting differential privacy noise. AdaVFL <cite class="ltx_cite ltx_citemacro_citep">(Errounda and Liu, <a href="#bib.bib38" title="" class="ltx_ref">2023</a>)</cite> adapts privacy protection based on feature contributions and model convergence. It uses zero-Concentrated Differential Privacy (zCDP) for privacy accounting, aiming to balance privacy protection and utility. Nonetheless, the protocol assumes honest-but-curious adversaries and secure communication channels, which may not be valid in all real-world scenarios. Besides, the adaptive budgeting scheme relies on the model convergence dynamics, which may vary with different datasets and tasks.</p>
</div>
<figure id="S4.F6" class="ltx_figure"><img src="/html/2405.17495/assets/x6.png" id="S4.F6.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="392" height="211" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6. </span><span id="S4.F6.2.1" class="ltx_text ltx_font_bold">Inference Attack.</span> (a) The attacker can infer the raw features using gradients and intermediate embeddings. (b) The attacker can infer the task labels using the trained local model and the gradients.</figcaption>
</figure>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2. </span>Malicious Attack</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">The malicious attack poses a significant threat to the security of VFL systems. It manifests in two primary forms: Inference Attack and Destructive Attack. In the former, malicious attackers attempt to intrude into the private domains of participants by exploiting information communicated during the collaboration. The goal is to infer raw data, directly threatening the confidentiality of participant-specific information. Besides, Destructive Attack poses a risk to the function and robustness of the learned model. Attackers attempt to disrupt the effectiveness and reliability of the learned model. In the following sections, we will examine these two aspects of malicious attacks, highlight their potential consequences, and critically, explore the corresponding defense strategies designed to enhance the security of VFL against such threats.</p>
</div>
<section id="S4.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.1. </span>Inference Attack</h4>

<div id="S4.SS2.SSS1.p1" class="ltx_para">
<p id="S4.SS2.SSS1.p1.1" class="ltx_p">The Inference Attack poses a significant challenge to participant privacy in VFL, where attackers aim to recover private data by exploiting the information exchanged during collaboration. Through the analysis of exchanged information, attackers can reconstruct raw data from participants, representing a significant threat to system security. According to the obtained data, Inference Attack can be categorized into two types: Feature Inference Attack, where the goal is to uncover features using gradients or prediction outputs; Label Inference Attack, which aims to extract label information from the active client using gradient or model parameter information.</p>
</div>
<div id="S4.SS2.SSS1.p2" class="ltx_para">
<p id="S4.SS2.SSS1.p2.1" class="ltx_p"><span id="S4.SS2.SSS1.p2.1.1" class="ltx_text ltx_font_bold">Feature Inference Attack:</span> Luo <span id="S4.SS2.SSS1.p2.1.2" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_citep">(Luo et al<span class="ltx_text">.</span>, <a href="#bib.bib121" title="" class="ltx_ref">2021</a>)</cite> develop specific attacks that work with both single and multiple prediction outputs. They involve precise and generative inference and do not depend on any prior knowledge about the target data distribution, adaptable to various complex VFL models. However, the effectiveness of these attacks depends on the correlation between the features of the adversary and those of the passive parties. CAFE <cite class="ltx_cite ltx_citemacro_citep">(Jin et al<span class="ltx_text">.</span>, <a href="#bib.bib83" title="" class="ltx_ref">2021</a>)</cite> is designed to recover data in batches from shared aggregated gradients. It leverages data index and internal representation alignments to efficiently conduct large-batch data leakage attacks. Nevertheless, the effectiveness of CAFE is influenced by the model architecture and weight distribution initialization. Rassouli <span id="S4.SS2.SSS1.p2.1.3" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_citep">(Rassouli et al<span class="ltx_text">.</span>, <a href="#bib.bib142" title="" class="ltx_ref">2022</a>)</cite> propose several inference attack techniques to reconstruct sensitive features from the passive party in VFL. They utilize the Chebyshev center concept for these attacks and provide theoretical performance guarantees, but computing the Chebyshev center is complex and computationally intensive. Ye <span id="S4.SS2.SSS1.p2.1.4" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_citep">(Ye et al<span class="ltx_text">.</span>, <a href="#bib.bib188" title="" class="ltx_ref">2022</a>)</cite> introduces an attack that attempts to reconstruct binary features from passive parties in VFL. It proves that while reconstructing general features is NP-hard, binary feature reconstruction is feasible and presents a search-based attack algorithm. However, this attack primarily targets binary features and may not be directly applicable to other types of data or non-binary features. Yang <span id="S4.SS2.SSS1.p2.1.5" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_citep">(Yang et al<span class="ltx_text">.</span>, <a href="#bib.bib181" title="" class="ltx_ref">2023c</a>)</cite> propose to utilize an inference model to minimize the distance between predictions from inferred and target features. It employs zeroth-order gradient estimation to train the inference model due to the lack of direct access to the global model and other local model information. However, the effectiveness of the attack is influenced by the correlation between known features and target features. Higher correlations lead to better attack performance.</p>
</div>
<div id="S4.SS2.SSS1.p3" class="ltx_para">
<p id="S4.SS2.SSS1.p3.1" class="ltx_p"><span id="S4.SS2.SSS1.p3.1.1" class="ltx_text ltx_font_bold">Label Inference Attack:</span> Liu <span id="S4.SS2.SSS1.p3.1.2" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_citep">(Liu et al<span class="ltx_text">.</span>, <a href="#bib.bib117" title="" class="ltx_ref">2021f</a>)</cite> introduce a gradient inversion model that can reconstruct private labels with high accuracy by exploiting batch-averaged local gradients. They also present a gradient-replacement attack that facilitates label replacement in black-box VFL settings without altering the existing VFL protocols. However, the success of this attack depends on the batch size being smaller than the dimension of the embedded features in the final fully connected layer. Li <span id="S4.SS2.SSS1.p3.1.3" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a href="#bib.bib98" title="" class="ltx_ref">2021</a>)</cite> propose a norm-based scoring function, which exploits the observation that the norm of the gradient vector can be different for positive and negative examples, potentially revealing label information. The scoring function uses the gradient norm as a predictor of the unseen label. Nonetheless, it is tailored to a specific threat model within two-party split learning, which may not generalize to other models or settings. Fu <span id="S4.SS2.SSS1.p3.1.4" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_citep">(Fu et al<span class="ltx_text">.</span>, <a href="#bib.bib48" title="" class="ltx_ref">2022b</a>)</cite> propose passive attacks using model completion, active attacks with a malicious local optimizer, and direct attacks by utilizing the gradient signs. However, the direct label inference attack is limited to training examples and requires additional steps for inference on new samples. Sun <span id="S4.SS2.SSS1.p3.1.5" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_citep">(Sun et al<span class="ltx_text">.</span>, <a href="#bib.bib153" title="" class="ltx_ref">2022</a>)</cite> introduce a label inference attack method that exploits the correlation between intermediate embeddings and private labels to steal sensitive label information. However, the label party may need to increase computational resources to re-learn the correlation between embeddings and labels to maintain model utility. Exploit <cite class="ltx_cite ltx_citemacro_citep">(Kariyappa and Qureshi, <a href="#bib.bib87" title="" class="ltx_ref">2023</a>)</cite> frames the attack as a supervised learning task using gradient information obtained during split learning. Nevertheless, the efficacy of Exploit varies based on the chosen splitting layer. Further exploration could involve evaluating the attack performance across different splitting layers and examining its robustness to various defense mechanisms. Qiu <span id="S4.SS2.SSS1.p3.1.6" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_citep">(Qiu et al<span class="ltx_text">.</span>, <a href="#bib.bib136" title="" class="ltx_ref">2022</a>)</cite> propose a numerical approximation method, which is designed to approximate encrypted representations in VFL, enabling the inference of private label-related relations. However, the effectiveness of the attack is contingent on access to certain knowledge, such as prediction results and global model parameters.</p>
</div>
<figure id="S4.F7" class="ltx_figure"><img src="/html/2405.17495/assets/x7.png" id="S4.F7.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="171" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7. </span><span id="S4.F7.2.1" class="ltx_text ltx_font_bold">Destructive Attack.</span> (a) The attacker can add a backdoor trigger to the data for making the target prediction. (b) The attacker can poison the raw data by adding noise or mismatching the sample IDs.</figcaption>
</figure>
</section>
<section id="S4.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.2. </span>Destructive Attack</h4>

<div id="S4.SS2.SSS2.p1" class="ltx_para">
<p id="S4.SS2.SSS2.p1.1" class="ltx_p">In vertical federated learning, the destructive attack manifests when attackers attempt to compromise the prediction of the trained model. Attackers may employ various tactics, including injecting targeted modifications, introducing malicious data, manipulating model parameters, or disrupting the learning process. The Destructive Attack can be categorized into two types: <span id="S4.SS2.SSS2.p1.1.1" class="ltx_text ltx_font_italic">Backdoor Attack</span> and <span id="S4.SS2.SSS2.p1.1.2" class="ltx_text ltx_font_italic">Poison Attack</span>. The former involves surreptitiously injecting subtle modifications into the data, thereby causing the model to produce incorrect predictions for specific targets. Besides, the Poison Attack aims to corrupt the model or the underlying data directly, reducing the accuracy of model predictions and undermining the trustworthiness of the collaborative learning framework.</p>
</div>
<div id="S4.SS2.SSS2.p2" class="ltx_para">
<p id="S4.SS2.SSS2.p2.1" class="ltx_p"><span id="S4.SS2.SSS2.p2.1.1" class="ltx_text ltx_font_bold">Backdoor Attack:</span> Liu <span id="S4.SS2.SSS2.p2.1.2" class="ltx_text ltx_font_italic">et al</span> <cite class="ltx_cite ltx_citemacro_citep">(Liu et al<span class="ltx_text">.</span>, <a href="#bib.bib115" title="" class="ltx_ref">2020c</a>)</cite> propose to record the intermediate gradient of a clean sample with the targeted label and use this recorded gradient for poisoned samples. The goal is to make the model assign an attacker-chosen label to input data with a specific pattern or trigger. However, the modification of gradients will influence the performance on clean data. UAB <cite class="ltx_cite ltx_citemacro_citep">(Chen et al<span class="ltx_text">.</span>, <a href="#bib.bib25" title="" class="ltx_ref">2024a</a>)</cite> utilizes bi-level optimization to alternately optimize universal backdoor trigger generation and model parameters during VFL training, without requiring additional data or labels from other participants. However, the attack performance will be affected if the dataset is imbalanced. LR-BA <cite class="ltx_cite ltx_citemacro_citep">(Gu and Bai, <a href="#bib.bib60" title="" class="ltx_ref">2023</a>)</cite> involves an adversarial participant in VFL who fine-tunes their local model to produce specific latent representations for backdoor instances, thereby manipulating the federated model to predict an attacker-specified label. It can be executed even without access to labels, using only local latent representations, but its performance may vary with the dataset and number of classes. He <span id="S4.SS2.SSS2.p2.1.3" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_citep">(He et al<span class="ltx_text">.</span>, <a href="#bib.bib67" title="" class="ltx_ref">2023</a>)</cite> propose to utilize a malicious client injecting a stealthy backdoor into the global model during training. This is achieved by replacing the local embeddings of a small number of target-class samples with a carefully constructed trigger vector, without modifying any labels. However, the attack method is non-trivial and requires careful construction of the trigger vector. VILLAIN <cite class="ltx_cite ltx_citemacro_citep">(Bai et al<span class="ltx_text">.</span>, <a href="#bib.bib7" title="" class="ltx_ref">2023</a>)</cite> introduces a novel label inference algorithm to insert a backdoor into the global model. It intensifies the backdoor attack power by designing a stealthy additive trigger and introducing backdoor augmentation strategies to impose a larger influence on the global model. Nevertheless, its effectiveness relies on the sophisticated label inference algorithm, which introduces additional complexity. BadVFL <cite class="ltx_cite ltx_citemacro_citep">(Xuan et al<span class="ltx_text">.</span>, <a href="#bib.bib177" title="" class="ltx_ref">2023</a>)</cite> introduces a Source Data Detection (SDD) module to trace data categories based on gradients and a Source Data Perturbation (SDP) scheme to enhance the decision dependency between the trigger and attack target. Nonetheless, the effectiveness of the attack may vary with the complexity of the global model structure, affecting gradient-based calculations. Graph-Fraudster <cite class="ltx_cite ltx_citemacro_citep">(Chen et al<span class="ltx_text">.</span>, <a href="#bib.bib24" title="" class="ltx_ref">2022</a>)</cite> leverages noise-added global node embeddings and gradients of pairwise nodes to confuse the global model. However, the success of the attack relies on the leakage of global node embeddings.</p>
</div>
<div id="S4.SS2.SSS2.p3" class="ltx_para">
<p id="S4.SS2.SSS2.p3.1" class="ltx_p"><span id="S4.SS2.SSS2.p3.1.1" class="ltx_text ltx_font_bold">Poison Attack:</span> VFedAD <cite class="ltx_cite ltx_citemacro_citep">(Lai et al<span class="ltx_text">.</span>, <a href="#bib.bib93" title="" class="ltx_ref">2023</a>)</cite> proposes three data-level poison attack methods: Random Failure, which introduces noise to raw data; Random Mismatch, where IDs in some clients are shuffled to disrupt collaborative learning performance; and Targeted Tampering, where the attacker replaces some samples with target features. However, the attacks are easy to detect due to the conspicuous modification of raw data. Qiu <span id="S4.SS2.SSS2.p3.1.2" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_citep">(Qiu et al<span class="ltx_text">.</span>, <a href="#bib.bib138" title="" class="ltx_ref">2024b</a>)</cite> introduce two attacks, the replay attack and the generation attack, demonstrating the vulnerability of VFL systems to the Byzantine Generals Problem. It also explores a poisoning phase to enhance these attacks when the adversary has limited features. Yao <span id="S4.SS2.SSS2.p3.1.3" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_citep">(Duanyi et al<span class="ltx_text">.</span>, <a href="#bib.bib37" title="" class="ltx_ref">2023</a>)</cite> propose an attack that disrupts the VFL inference process by adaptively corrupting a subset of clients. It formulates finding optimal attack strategies as an online optimization problem, involving adversarial example generation and corruption pattern selection. However, the ability to adjust corruption patterns relies on the effectiveness of previous attacks, which may not always lead to the discovery of the optimal pattern. P-GAN <cite class="ltx_cite ltx_citemacro_citep">(Chen et al<span class="ltx_text">.</span>, <a href="#bib.bib28" title="" class="ltx_ref">2024c</a>)</cite> utilizes semi-supervised learning to create a surrogate target model, then employs a GAN-based method to generate adversarial perturbations that degrade the model performance. However, the effectiveness is influenced by various factors like the number of attacker features and the known labels.</p>
</div>
</section>
<section id="S4.SS2.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.3. </span>Defense</h4>

<div id="S4.SS2.SSS3.p1" class="ltx_para">
<p id="S4.SS2.SSS3.p1.1" class="ltx_p">Defending against malicious attacks is crucial for ensuring the security of VFL. Two primary defense strategies involve mitigating inference attacks and thwarting destructive attacks. Mitigating the risks posed by inference attacks, which seek to infer sensitive data from transmitted information, requires the implementation of sophisticated encryption and privacy-preserving protocols. Besides, countering destructive attacks demands measures to detect and neutralize malicious attempts aimed at undermining the integrity and functionality of learned models.</p>
</div>
<div id="S4.SS2.SSS3.p2" class="ltx_para">
<p id="S4.SS2.SSS3.p2.1" class="ltx_p"><span id="S4.SS2.SSS3.p2.1.1" class="ltx_text ltx_font_bold">Defense Against Inference Attacks.</span>
For <span id="S4.SS2.SSS3.p2.1.2" class="ltx_text ltx_font_italic">defending against feature inference attacks,</span> Sun <span id="S4.SS2.SSS3.p2.1.3" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_citep">(Sun et al<span class="ltx_text">.</span>, <a href="#bib.bib155" title="" class="ltx_ref">2021b</a>)</cite> propose an adversarial training framework with three modules: adversarial reconstruction, noise regularization, and distance correlation minimization, which work together to make the collaboration model robust against attacks that attempt to reconstruct sensitive input data from shared gradients. Nevertheless, the adversarial nature of the training process adds complexity and may require careful tuning to achieve the desired balance between privacy and performance. VFLDefender <cite class="ltx_cite ltx_citemacro_citep">(Zhu et al<span class="ltx_text">.</span>, <a href="#bib.bib207" title="" class="ltx_ref">2024</a>)</cite> employs gradient obfuscation to reduce the correlation between model updates and training data, effectively preventing reconstruction attacks and preserving data privacy. However, the defense mechanism impacts model utility and the balance between privacy and performance needs further exploration. Chang <span id="S4.SS2.SSS3.p2.1.4" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_citep">(Chang and Zhu, <a href="#bib.bib18" title="" class="ltx_ref">2024</a>)</cite> propose to selectively transmit only a portion of the gradient components, reducing the risk of data leakage while maintaining model training accuracy. Besides, they use cosine similarity to measure the angular difference between client-updated gradients and server-sent gradients. Clients can then disguise their uploaded gradient to protect privacy without compromising the global model accuracy. However, it requires additional processing of gradient components, which can be computationally intensive. Mao <span id="S4.SS2.SSS3.p2.1.5" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_citep">(Mao et al<span class="ltx_text">.</span>, <a href="#bib.bib123" title="" class="ltx_ref">2022</a>)</cite> implement a fine-grained privacy budget allocation scheme to efficiently perturb information exchange between the passive and the active client, effectively protecting from data reconstruction attacks. FedPass <cite class="ltx_cite ltx_citemacro_citep">(Gu et al<span class="ltx_text">.</span>, <a href="#bib.bib59" title="" class="ltx_ref">2023</a>)</cite> introduces an adaptive obfuscation mechanism that adjusts during the learning process to protect features and labels simultaneously. It embeds private passports in both passive and active party models, making it exponentially hard for attackers to infer features and nearly impossible to infer private labels. However, the randomness in passport generation is crucial for data privacy, but the process and its security implications require careful consideration.</p>
</div>
<div id="S4.SS2.SSS3.p3" class="ltx_para">
<p id="S4.SS2.SSS3.p3.1" class="ltx_p">For <span id="S4.SS2.SSS3.p3.1.1" class="ltx_text ltx_font_italic">defending against label inference attack,</span> Li <span id="S4.SS2.SSS3.p3.1.2" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a href="#bib.bib98" title="" class="ltx_ref">2021</a>)</cite> proposes minimizing label leakage in split learning by optimizing noise perturbation structures. It strategically adds random noise to gradients and prevents adversaries from recovering private labels. However, it assumes a gaussian distribution for unperturbed gradients and can be computationally intensive with multiple optimizations. DCAE <cite class="ltx_cite ltx_citemacro_citep">(Zou et al<span class="ltx_text">.</span>, <a href="#bib.bib210" title="" class="ltx_ref">2022</a>)</cite> proposes to defend against label inference and replacement attacks by disguising true labels using autoencoder and entropy regularization with prior label knowledge. However, the implementation of DCAE may add complexity to the VFL system. Sun <span id="S4.SS2.SSS3.p3.1.3" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_citep">(Sun et al<span class="ltx_text">.</span>, <a href="#bib.bib153" title="" class="ltx_ref">2022</a>)</cite> propose an additional optimization goal at the active client to minimize the distance correlation, making it difficult for an adversary to infer private labels from the shared intermediate embedding. However, the method is primarily evaluated in a binary classification setting, and its effectiveness in other scenarios or with different data distributions is not extensively discussed. Besides, the active client may need additional computational costs to re-learn the correlation between embeddings and labels. FLSG <cite class="ltx_cite ltx_citemacro_citep">(Fan et al<span class="ltx_text">.</span>, <a href="#bib.bib39" title="" class="ltx_ref">2023a</a>)</cite> defends against passive label inference attacks by generating gradients similar to the original ones using a Gaussian distribution. It measures the cosine distance between the generated and original gradients and selects the most similar ones to replace the original gradients during back-propagation. Despite being lower than other methods, implementing FLSG still increases the training time compared to the original VFL framework. Wang <span id="S4.SS2.SSS3.p3.1.4" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_citep">(Wang et al<span class="ltx_text">.</span>, <a href="#bib.bib165" title="" class="ltx_ref">2023</a>)</cite> introduce a shadow model to share gradients during training, disrupting the correlation between gradients and training data, which hinders attackers from inferring labels. However, the introduction of a new local model and the need for secret sharing during training add complexity and potential cost to the process. ProjPert <cite class="ltx_cite ltx_citemacro_citep">(Fu et al<span class="ltx_text">.</span>, <a href="#bib.bib50" title="" class="ltx_ref">2024</a>)</cite> addresses the issue of label leakage during training by formulating an optimization problem that minimizes the impact on model quality while satisfying a pre-set privacy guarantee. However, the heuristic variant may not always provide the optimal solution but is designed to be close to it. HashVFL <cite class="ltx_cite ltx_citemacro_citep">(Qiu et al<span class="ltx_text">.</span>, <a href="#bib.bib137" title="" class="ltx_ref">2024a</a>)</cite> addresses the challenges of learnability, bit balance, and consistency in VFL. It uses a sign function for binarization, batch normalization for bit balance, and predefined binary codes for consistency. However, the integration of hashing can cause vanishing gradients during model training. Zheng <span id="S4.SS2.SSS3.p3.1.5" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_citep">(Zheng et al<span class="ltx_text">.</span>, <a href="#bib.bib205" title="" class="ltx_ref">2022</a>)</cite> propose the use of potential energy loss (PELoss) to make the output distribution of the local model more complex, protecting against label leakage. It pushes outputs of the same class toward the decision boundary, making it difficult for an attacker to fine-tune the local model with a small number of leaked labeled samples. However, the method assumes the attacker uses supervised learning to fine-tune the local model and does not consider attacks based on unsupervised learning approaches. TPSL <cite class="ltx_cite ltx_citemacro_citep">(Yang et al<span class="ltx_text">.</span>, <a href="#bib.bib183" title="" class="ltx_ref">2022a</a>)</cite> adds noise to gradients and model updates during training to ensure differential privacy, focusing on protecting sensitive label information. Takahashi <span id="S4.SS2.SSS3.p3.1.6" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_citep">(Takahashi et al<span class="ltx_text">.</span>, <a href="#bib.bib156" title="" class="ltx_ref">2023</a>)</cite> propose defense mechanisms to mitigate label leakage in tree-based VFL, by utilizing label differential privacy with post-processing and mutual information regularization. Nevertheless, it requires additional training and communications.</p>
</div>
<div id="S4.SS2.SSS3.p4" class="ltx_para">
<p id="S4.SS2.SSS3.p4.1" class="ltx_p"><span id="S4.SS2.SSS3.p4.1.1" class="ltx_text ltx_font_bold">Defend Against Destructive Attacks.</span>
He <span id="S4.SS2.SSS3.p4.1.2" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_citep">(He et al<span class="ltx_text">.</span>, <a href="#bib.bib67" title="" class="ltx_ref">2023</a>)</cite> propose strategies from three aspects: Statistical Filtering, which filters out abnormal local embeddings that deviate from natural outputs, but may not detect stealthy attacks with well-crafted trigger vectors; Reverse Engineering Detection, identifies backdoored models by comparing reversed trigger vectors for different classes, but with low detection rates, indicating difficulty in identifying malicious models; Confusional Autoencoder, which maps original labels to fake labels to minimize classification probability differences, but does not significantly hinder the proposed attack, as it does not rely on gradients or label inference. Chen <span id="S4.SS2.SSS3.p4.1.3" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_citep">(Chen et al<span class="ltx_text">.</span>, <a href="#bib.bib28" title="" class="ltx_ref">2024c</a>)</cite> focus on a server-side anomaly detection algorithm based on a deep auto-encoder (DAE) to defense against data poisoning attacks. The DAE method is used to identify outliers in embedding vectors with reconstruction errors and filter out anomalous data, ensuring that only clean training data is used on the server. Nonetheless, the detection might struggle with high proportions of poisoned data; VFedAD <cite class="ltx_cite ltx_citemacro_citep">(Lai et al<span class="ltx_text">.</span>, <a href="#bib.bib93" title="" class="ltx_ref">2023</a>)</cite> uses information theory to detect anomalies in vertical federated learning. It employs contrastive learning and cross-client prediction tasks to learn data representations that help identify poisoned samples. Nonetheless, the success of anomaly detection hinges on the quality of learned data representations. Qiu <span id="S4.SS2.SSS3.p4.1.4" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_citep">(Qiu et al<span class="ltx_text">.</span>, <a href="#bib.bib138" title="" class="ltx_ref">2024b</a>)</cite> utilize two kinds of strategies to defend the destructive attack: Normalization, which is effective against black-box attacks like ZOO by transforming perturbed input, preventing gradient approximation. However, the impact is limited when the attacker has a significant feature ratio, as the threat persists; Dropout reduces model memorization of specific patterns, which can mitigate attacks, but high dropout probability can drastically reduce main task performance, making it impractical for collaborative learning. RVFR <cite class="ltx_cite ltx_citemacro_citep">(Liu et al<span class="ltx_text">.</span>, <a href="#bib.bib110" title="" class="ltx_ref">2021d</a>)</cite> operates by training individual feature extractors in quarantine, followed by a robust feature subspace recovery process, and feature purification based on the assumption that only a small fraction of agents are malicious. The framework is theoretically grounded, providing guarantees for the recovery of uncorrupted features and the robustness of the model against a range of attacks. However, the effectiveness of RVFR hinges on specific assumptions such as the existence of a low-rank feature subspace and the predominance of well-intentioned agents.</p>
</div>
</section>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5. </span>Applicability</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">Vertical Federated Learning (VFL) has emerged as a pivotal technology in a multitude of application domains <cite class="ltx_cite ltx_citemacro_citep">(Yang et al<span class="ltx_text">.</span>, <a href="#bib.bib180" title="" class="ltx_ref">2019</a>; Liu et al<span class="ltx_text">.</span>, <a href="#bib.bib113" title="" class="ltx_ref">2024</a>; Zhang and Jiang, <a href="#bib.bib194" title="" class="ltx_ref">2021</a>; Wei et al<span class="ltx_text">.</span>, <a href="#bib.bib167" title="" class="ltx_ref">2023</a>; Yan et al<span class="ltx_text">.</span>, <a href="#bib.bib178" title="" class="ltx_ref">2024</a>; Huang et al<span class="ltx_text">.</span>, <a href="#bib.bib70" title="" class="ltx_ref">2023b</a>; Li et al<span class="ltx_text">.</span>, <a href="#bib.bib96" title="" class="ltx_ref">2020b</a>; Liu et al<span class="ltx_text">.</span>, <a href="#bib.bib111" title="" class="ltx_ref">2021b</a>)</cite>. Despite its advances, the practical deployment of VFL systems frequently encounters several obstacles that can significantly hinder their applications. Recent research identifies challenges from three main aspects: (1) <span id="S5.p1.1.1" class="ltx_text ltx_font_italic">Limited Data.</span> Obtaining sufficient high-quality data for model generalization is crucial, but VFL faces limitations in data availability. This includes: (i) Limited Aligned Samples: VFL relies on all clients possessing parts of features from the same samples. However, the number of common samples is often limited, hampering model generalization. (ii) Limited Labels: In many cases, collecting high-quality labels is challenging, which reduces collaboration performance. (2) <span id="S5.p1.1.2" class="ltx_text ltx_font_italic">Large Communication Burden.</span> The communication cost in VFL is significant, as intermediate features and updated gradients are frequently exchanged. However, device resources are typically limited. Addressing this challenge is crucial for deploying VFL systems. (3) <span id="S5.p1.1.3" class="ltx_text ltx_font_italic">Client Asynchrony.</span> In practice, the device and computing power differences cause the calculation of intermediate results to be delayed in some clients, which affects the updation of collaborative learning. It shows the asynchrony in vertical federated learning and becomes a critical issue in achieving the applicability of the VFL system.</p>
</div>
<figure id="S5.F8" class="ltx_figure"><img src="/html/2405.17495/assets/x8.png" id="S5.F8.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="424" height="128" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 8. </span><span id="S5.F8.2.1" class="ltx_text ltx_font_bold">Limited Data.</span> (a) Aligned samples are often limited, especially as the number of clients increases. (b) The task labels in the active client are limited, leaving unlabeled samples underutilized.</figcaption>
</figure>
<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1. </span>Limited Data</h3>

<div id="S5.SS1.p1" class="ltx_para">
<p id="S5.SS1.p1.1" class="ltx_p">The amount of high-quality data is critical to improve the generalization of the trained models. However, a large amount of sufficient data is usually unavailable in VFL, which impedes the applicability of VFL. The challenges of limited data can be divided into two aspects:</p>
</div>
<div id="S5.SS1.p2" class="ltx_para">
<p id="S5.SS1.p2.1" class="ltx_p"><span id="S5.SS1.p2.1.1" class="ltx_text ltx_font_bold">Limited Aligned Samples.</span>
The performance of Vertical Federated Learning (VFL) heavily relies on the availability of common samples shared across different clients for collaborative training. However, in practice, the number of aligned samples is often restricted, particularly as the number of clients increases. This limitation in the size of aligned samples impedes collaboration performance and diminishes the applicability of VFL. Recent efforts have extensively explored solutions to enhance the applicability of VFL in the face of limited aligned samples. They strive to address this challenge by maximizing the utilization of unaligned samples through feature generation and pseudo-label estimation. For instance, FedCVT <cite class="ltx_cite ltx_citemacro_citep">(Kang et al<span class="ltx_text">.</span>, <a href="#bib.bib85" title="" class="ltx_ref">2022a</a>)</cite> proposes to complete missing features for unaligned samples and assign pseudo-labels, effectively expanding the sample size for collaborative training. Sun <span id="S5.SS1.p2.1.2" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_citep">(Sun et al<span class="ltx_text">.</span>, <a href="#bib.bib152" title="" class="ltx_ref">2023b</a>)</cite> introduced a semi-supervised paradigm in which each client updates with estimated labels to improve sample utilization. However, these methods face various limitations. Firstly, both label estimation and feature generation are prone to errors, introducing noisy information. Moreover, these methods exclusively leverage samples with high-confidence pseudo-labels for learning, leaving a significant number of samples underutilized. Furthermore, accurately generating pseudo-labels and features becomes even more challenging in scenarios with limited aligned samples due to the reliance on prior information about aligned samples. FedMC <cite class="ltx_cite ltx_citemacro_citep">(Yang et al<span class="ltx_text">.</span>, <a href="#bib.bib184" title="" class="ltx_ref">2022b</a>)</cite> expands the training data by matching non-overlapping samples based on similarity, thus improving the effectiveness of the jointly trained model. However, it aims to pair the unaligned samples upper the desired similarity for collaboration training, which cannot fully utilize the samples. Given these limitations, future research could explore more efficient frameworks to overcome the challenges posed by limited aligned samples.</p>
</div>
<div id="S5.SS1.p3" class="ltx_para">
<p id="S5.SS1.p3.1" class="ltx_p"><span id="S5.SS1.p3.1.1" class="ltx_text ltx_font_bold">Limited Labels.</span>
Limited labels pose a significant challenge to the applicability of VFL. In vertical federated learning, multiple clients collaborate to build a shared model for the collaboration task, with the labels from the active client. However, the availability of labeled data for training is often constrained due to various reasons, including privacy concerns and the difficulty of providing large amounts of high-quality labeled data. The scarcity of labeled data hampers collaborative training, impacting the performance of the global model. To improve applicability in situations with scarce labels in VFL, recent works propose a series of unsupervised and self-supervised methods to leverage unlabeled data. For instance, Cha <span id="S5.SS1.p3.1.2" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_citep">(Cha et al<span class="ltx_text">.</span>, <a href="#bib.bib17" title="" class="ltx_ref">2021</a>)</cite> present a simple and robust VFL paradigm based on auto-encoders, which does not require domain knowledge or labels to train the autoencoder models. However, the proposed method transforms data into a high-dimensional latent space, introducing redundant information and potential overfitting on short data sequences. FedOnce <cite class="ltx_cite ltx_citemacro_citep">(Wu et al<span class="ltx_text">.</span>, <a href="#bib.bib174" title="" class="ltx_ref">2022b</a>)</cite> proposes to enhance the intermediate features by unsupervised learning in each client without labels. However, labels for the collaboration task are still needed for training; Besides, additional computational costs are introduced with local updation. FedHSSL <cite class="ltx_cite ltx_citemacro_citep">(He et al<span class="ltx_text">.</span>, <a href="#bib.bib66" title="" class="ltx_ref">2024</a>)</cite> presents a pre-train method for VFL. The basic idea is to leverage cross-party views, local views, and invariant features of samples to improve the performance of VFL collaboration with limited labels. However, it relies on the assumption that participating parties have similar data distributions, and additional communication costs are introduced, which may affect scalability and efficiency. SS-VFL <cite class="ltx_cite ltx_citemacro_citep">(Castiglia et al<span class="ltx_text">.</span>, <a href="#bib.bib14" title="" class="ltx_ref">2022b</a>)</cite> leverages unlabeled data to train representation networks and labeled data for a downstream prediction network, aiming to achieve higher accuracy with reduced communication costs. However, the effectiveness may vary depending on the similarity between local and centralized class probability distributions. Additionally, there is a potential for model bias if the datasets used for training are biased.</p>
</div>
<figure id="S5.F9" class="ltx_figure"><img src="/html/2405.17495/assets/x9.png" id="S5.F9.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="405" height="172" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 9. </span><span id="S5.F9.2.1" class="ltx_text ltx_font_bold">Large Communication Burden and Client Asynchrony.</span> (a) The sample alignment process and multiple communication rounds introduce significant communication burdens. (b) Differences in computational power and bandwidth cause the asynchronous updates between clients.</figcaption>
</figure>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2. </span>Large Communication Burden</h3>

<div id="S5.SS2.p1" class="ltx_para">
<p id="S5.SS2.p1.1" class="ltx_p">The challenge of a large communication burden in Vertical Federated Learning arises from the need to exchange substantial amounts of information across different clients during the collaboration process. In VFL, each client retains its local dataset and models, then the global model is built with intermediate features and collaboration labels. During this process, the communication of intermediate information such as features, gradients, and sample alignment indices between clients can be resource-intensive, especially when dealing with large-scale datasets or models. The sheer volume of data that needs to be transmitted over networks introduces latency and consumes bandwidth. This challenge is particularly pronounced in scenarios where the participating clients are geographically dispersed or have limited communication resources, which hinders the application of VFL. To mitigate the large communication burden and improve the applicability of VFL, many innovative strategies have been proposed in recent works. AsySQN <cite class="ltx_cite ltx_citemacro_citep">(Zhang et al<span class="ltx_text">.</span>, <a href="#bib.bib195" title="" class="ltx_ref">2021b</a>)</cite> proposes to use asynchronous stochastic quasi-Newton methods to train VFL models. It leverages approximate second-order information to reduce the number of communication rounds and improve the convergence speed. However, it requires the collaboration labels to be held by all parties, which may not be realistic in some scenarios. Khan <span id="S5.SS2.p1.1.1" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_citep">(Khan et al<span class="ltx_text">.</span>, <a href="#bib.bib88" title="" class="ltx_ref">2022a</a>)</cite> propose utilizing feature compress methods to compress the local data of each party into latent representations and reduce the communication rounds into one, thus reducing the total communication overhead. However, it depends on the choice of the feature extraction technique, which may affect the quality of the latent representations and the final model. FedBCD <cite class="ltx_cite ltx_citemacro_citep">(Liu et al<span class="ltx_text">.</span>, <a href="#bib.bib116" title="" class="ltx_ref">2022</a>)</cite> utilizes a Federated Stochastic Block Coordinate Descent algorithm, enabling parties to perform multiple local updates before each communication, reducing communication overhead. However, the number of local-update rounds needs careful selection to avoid potential divergence. Besides, the performance can be sensitive to the choice of stepsize and batch size. C-VFL <cite class="ltx_cite ltx_citemacro_citep">(Castiglia et al<span class="ltx_text">.</span>, <a href="#bib.bib16" title="" class="ltx_ref">2022a</a>)</cite> leverages several local updations with compressed embedding sharing, which reduces the communication cost by over 90% compared to VFL without compression, without performance degradation. Nevertheless, it requires bounded embedding gradients and bounded Hessian of the objective function, which may not hold for some models or datasets. CELU-VFL <cite class="ltx_cite ltx_citemacro_citep">(Fu et al<span class="ltx_text">.</span>, <a href="#bib.bib49" title="" class="ltx_ref">2022a</a>)</cite> utilizes cached stale statistics to estimate model gradients for local updation, reducing the need for frequent cross-party communication. However, it involves approximation with stale statistics, which may introduce errors in gradient estimation. SparseVFL <cite class="ltx_cite ltx_citemacro_citep">(Inoue et al<span class="ltx_text">.</span>, <a href="#bib.bib79" title="" class="ltx_ref">2023</a>)</cite> reduces the data size exchanged between the server and clients by exploiting the sparsity of embeddings and gradients. However, the sparsity may vary depending on the data distribution, neural network architecture, and hyperparameters, making it less effective for dense embeddings/gradients or high-dimensional embeddings/gradients. VFL-CZOFO <cite class="ltx_cite ltx_citemacro_citep">(Wang et al<span class="ltx_text">.</span>, <a href="#bib.bib164" title="" class="ltx_ref">2024</a>)</cite> applies a cascaded hybrid optimization method that uses a zeroth-order (ZO) gradient on the most critical output layer of the clients, and a first-order (FO) gradient on the other parts of the model. It greatly alleviates the slow convergence problem of ZO-based VFL and significantly reduces communication costs compared with state-of-the-art communication-efficient VFL frameworks. However, it increases computational costs, requiring multiple forward propagations on its local model, and requires a trade-off between compression rate and test accuracy. Cheetah <cite class="ltx_cite ltx_citemacro_citep">(Huang et al<span class="ltx_text">.</span>, <a href="#bib.bib77" title="" class="ltx_ref">2022a</a>)</cite> introduces homomorphic encryption-based protocols for linear layers without expensive rotation operations and efficient primitives for non-linear functions, resulting in faster and more communication-efficient secure two-party neural network (2PC-NN) inference. However, the protocol involves multiple steps, including partitioning input shares, encoding to polynomials, homomorphic operations, and re-masking, which can be computationally intensive. FDSKL <cite class="ltx_cite ltx_citemacro_citep">(Gu et al<span class="ltx_text">.</span>, <a href="#bib.bib57" title="" class="ltx_ref">2020</a>)</cite> uses random features to approximate kernel mapping functions and doubly stochastic gradients for solution updates, all computed without revealing data. The algorithm is shown to be faster and more communication-efficient than existing federated learning methods when dealing with kernels while maintaining similar generalization performance. However, the model coefficients are stored separately across different workers to maintain privacy, which could complicate the model management and updating process.</p>
</div>
</section>
<section id="S5.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3. </span>Client Asynchrony</h3>

<div id="S5.SS3.p1" class="ltx_para">
<p id="S5.SS3.p1.2" class="ltx_p">Client asynchrony in VFL arises because participating clients operate on their local datasets and communicate intermediate results independently with different computational powers and bandwidth, potentially leading to temporal misalignment in the collaboration process. Unlike synchronous scenarios where all clients update their models simultaneously, asynchronous VFL involves clients uploading intermediate features and updating models at different times. This asynchrony introduces complexities in maintaining consistency and coordination among the models. Issues such as parameter staleness, where some models may use outdated information, can arise, impacting the convergence of the global model. Recent works have widely explored solutions to address this challenge. VAFL <cite class="ltx_cite ltx_citemacro_citep">(Chen et al<span class="ltx_text">.</span>, <a href="#bib.bib26" title="" class="ltx_ref">2020a</a>)</cite> allows clients to run stochastic gradient algorithms without coordination. Clients can participate intermittently or strategically, but it may become complex when dealing with nonlinear local embedding functions. Li <span id="S5.SS3.p1.2.1" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a href="#bib.bib97" title="" class="ltx_ref">2020a</a>)</cite> propose an efficient method for client asynchrony, introducing gradient prediction using second-order Taylor expansion and double-end sparse compression to reduce training time and network traffic without sacrificing accuracy. However, it requires synchronous warm-up training at the beginning, and the gradient prediction method may introduce estimation errors, although they are mitigated by adaptive hyper-parameters. Gu <span id="S5.SS3.p1.2.2" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_citep">(Gu et al<span class="ltx_text">.</span>, <a href="#bib.bib58" title="" class="ltx_ref">2021</a>)</cite> introduce an asynchronous federated stochastic gradient descent (AFSGD-VP) algorithm and its variants for vertically partitioned data. It improves efficiency by keeping all computational resources busy, avoiding idle time waiting for synchronization. Although it addresses the straggler problem well initially, as the number of workers grows, the communication overheads can limit the scalability and speedup of the algorithms. VFB<sup id="S5.SS3.p1.2.3" class="ltx_sup"><span id="S5.SS3.p1.2.3.1" class="ltx_text ltx_font_italic">2</span></sup> <cite class="ltx_cite ltx_citemacro_citep">(Zhang et al<span class="ltx_text">.</span>, <a href="#bib.bib196" title="" class="ltx_ref">2021a</a>)</cite> integrates a backward updating mechanism and bilevel asynchronous parallel architecture, enabling asynchronous model updates across parties. However, VFB<sup id="S5.SS3.p1.2.4" class="ltx_sup"><span id="S5.SS3.p1.2.4.1" class="ltx_text ltx_font_italic">2</span></sup> assumes that one or partial parties hold labels, which may not be the case in all real-world applications. Shi <span id="S5.SS3.p1.2.5" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_citep">(Shi et al<span class="ltx_text">.</span>, <a href="#bib.bib148" title="" class="ltx_ref">2022</a>)</cite> propose to leverage asynchronous training to reduce waiting time and use secret sharing instead of HE for privacy protection, eliminating the need for a trusted VFL coordinator. Nevertheless, the total computational complexity and communication cost can increase with the number of participants and the size of the data. vFedSec <cite class="ltx_cite ltx_citemacro_citep">(Qiu et al<span class="ltx_text">.</span>, <a href="#bib.bib139" title="" class="ltx_ref">2023</a>)</cite> employs a robust aggregation mechanism that can handle missing or temporarily disconnected clients. Instead of waiting for all clients to participate in each round, vFedSec allows partial model updates. Besides, vFedSec adjusts the learning rate dynamically based on the number of active clients. However, it might require significant computational resources, making it less practical for real-time applications. Sun <span id="S5.SS3.p1.2.6" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_citep">(Sun et al<span class="ltx_text">.</span>, <a href="#bib.bib151" title="" class="ltx_ref">2023a</a>)</cite> propose party-wise dropout to prevent the co-adaptation of feature extractors across parties, which is the root cause of performance drops. However, the method addresses the co-adaptation of feature extractors across parties, but it doesn’t eliminate it entirely. There’s still a chance that the model may rely on certain representation components from specific parties’ extractors. FedVS <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a href="#bib.bib101" title="" class="ltx_ref">2023d</a>)</cite> is designed to handle straggling clients during training without performance degradation. It uses secret sharing schemes for local data and models, ensuring that the aggregation of all client embeddings is reconstructed losslessly from non-straggling clients. However, the feature reconstruction may have limitations while the non-straggling clients are in limited numbers.</p>
</div>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6. </span>Future Research Directions</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">In this section, we discuss the potential research directions that remain unexplored and can promote advances in the future.</p>
</div>
<section id="S6.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.1. </span>Effectiveness/Applicability and Security Trade-off</h3>

<div id="S6.SS1.p1" class="ltx_para">
<p id="S6.SS1.p1.1" class="ltx_p">In the domain of vertical federated learning (VFL), there is a complex interplay between striving for effectiveness and applicability on one hand, and the imperative to enhance security on the other. This balance characterizes the Effectiveness/Applicability and Security Trade-off, where efforts to enhance the security of the system may impact its efficacy and usability. This trade-off issue has been widely discussed in horizontal federated learning (HFL) <cite class="ltx_cite ltx_citemacro_citep">(Zhang et al<span class="ltx_text">.</span>, <a href="#bib.bib198" title="" class="ltx_ref">2022a</a>; Li et al<span class="ltx_text">.</span>, <a href="#bib.bib104" title="" class="ltx_ref">2024</a>; Zhang et al<span class="ltx_text">.</span>, <a href="#bib.bib200" title="" class="ltx_ref">2023c</a>; Girgis et al<span class="ltx_text">.</span>, <a href="#bib.bib55" title="" class="ltx_ref">2021</a>; Chen et al<span class="ltx_text">.</span>, <a href="#bib.bib23" title="" class="ltx_ref">2023</a>)</cite>. As VFL endeavors to harness disparate data sources while ensuring privacy, trade-offs inevitably arise. Tran <span id="S6.SS1.p1.1.1" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_citep">(Tran et al<span class="ltx_text">.</span>, <a href="#bib.bib160" title="" class="ltx_ref">2023</a>)</cite> offer a theoretical characterization of the relationship between privacy, convergence error, and communication cost. Kang <span id="S6.SS1.p1.1.2" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_citep">(Kang et al<span class="ltx_text">.</span>, <a href="#bib.bib86" title="" class="ltx_ref">2022b</a>)</cite> propose an evaluation strategy to measure the trade-off performance between privacy and utility, which offers references for future works. Understanding and navigating the complex trade-offs in VFL is essential for fostering the advancement and adoption of a secure, resilient, and effective collaborative system.</p>
</div>
</section>
<section id="S6.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.2. </span>Effectiveness Facilitates Security and Applicability</h3>

<div id="S6.SS2.p1" class="ltx_para">
<p id="S6.SS2.p1.1" class="ltx_p">In VFL, effectiveness serves as the cornerstone for enhancing both security and applicability. An effectively designed model not only ensures improved computational efficiency but also broadens the scope of applicability by catering to diverse and complex data scenarios. Besides, through feature &amp; client selection, it will allow for the prioritization of significant features or critical clients, further streamlining the learning process, and reducing computational overhead for enhanced applicability. Concurrently, the feature &amp; client selection process plays a pivotal role in identifying and mitigating potential vulnerabilities, enabling the early detection of attack vectors. By intertwining effectiveness with model design and feature &amp; client selection, a harmonious balance is achieved for enhanced applicability and security.</p>
</div>
</section>
<section id="S6.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.3. </span>Open Issues</h3>

<div id="S6.SS3.p1" class="ltx_para">
<p id="S6.SS3.p1.1" class="ltx_p">In Vertical Federated Learning (VFL), several open issues remain that are crucial for advancing the field yet have not been fully addressed. One major challenge is the absence of large-scale practical datasets. While current studies often evaluate their approaches by dividing data by features, there is a lack of standardized datasets that match practical VFL scenarios, resulting in biased evaluations. Additionally, the robustness of VFL systems against data noise has not been thoroughly investigated. Data noise can significantly impact the accuracy of models, yet strategies to mitigate this effect in VFL are underexplored. Another critical issue is the potential for unfair prediction bias towards certain features, which can lead to unequal treatment of different data inputs and raise ethical concerns. Furthermore, the exploration of VFL in handling various data variants, such as multi-modal data and graph data, is still in its infancy. These data types are increasingly common in practical applications, and their integration into VFL systems poses unique challenges and opportunities. Finally, with the development of foundation models, how vertical federated learning can facilitate their advancements is also a significant topic. Addressing these open issues is vital for the development of more robust, fair, and versatile VFL systems.</p>
</div>
<section id="S6.SS3.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">6.3.1. </span>Practical Datasets</h4>

<div id="S6.SS3.SSS1.p1" class="ltx_para">
<p id="S6.SS3.SSS1.p1.1" class="ltx_p">In VFL, different clients possess subsets of features on aligned samples, and cross-domain collaboration is conducted without leaking private data. A dataset collected from practical cross-domain collaborations would significantly facilitate VFL research. However, due to privacy concerns, a large-scale practical dataset for VFL is lacking. Existing works evaluate with data partitioned on standard datasets, such as dividing images or tabular data into segments and distributing them to clients. The VFLAIR <cite class="ltx_cite ltx_citemacro_citep">(Zou et al<span class="ltx_text">.</span>, <a href="#bib.bib209" title="" class="ltx_ref">2024</a>)</cite> benchmark evaluates 11 attacks and 8 defenses across 9 datasets, including image datasets <cite class="ltx_cite ltx_citemacro_citep">(LeCun et al<span class="ltx_text">.</span>, <a href="#bib.bib94" title="" class="ltx_ref">1998</a>; Krizhevsky et al<span class="ltx_text">.</span>, <a href="#bib.bib92" title="" class="ltx_ref">2009</a>; Chua et al<span class="ltx_text">.</span>, <a href="#bib.bib34" title="" class="ltx_ref">2009</a>; Street et al<span class="ltx_text">.</span>, <a href="#bib.bib150" title="" class="ltx_ref">1993</a>)</cite> and tabular datasets <cite class="ltx_cite ltx_citemacro_citep">(Becker and Kohavi, <a href="#bib.bib8" title="" class="ltx_ref">1996</a>; Dua et al<span class="ltx_text">.</span>, <a href="#bib.bib36" title="" class="ltx_ref">2017</a>; Kahn, <a href="#bib.bib84" title="" class="ltx_ref">1994</a>)</cite>, with data equally partitioned among each client. However, feature partitioning compromises data integrity and deviates from practical scenarios. FedSim <cite class="ltx_cite ltx_citemacro_citep">(Wu et al<span class="ltx_text">.</span>, <a href="#bib.bib173" title="" class="ltx_ref">2022a</a>)</cite> proposes linking multiple datasets based on similarity measurements to simulate practical scenarios. However, the linkage method does not apply when each sample is uniquely identified. Vertibench <cite class="ltx_cite ltx_citemacro_citep">(Wu et al<span class="ltx_text">.</span>, <a href="#bib.bib172" title="" class="ltx_ref">2023b</a>)</cite> proposes to evaluate the distribution of data partitions based on party importance and correlation, and introduces a real-world image-to-image VFL dataset named Satellite, capturing satellite imagery of the same locations from 16 different visits. Despite its advancement, datasets where clients hold related but distinct data are lacking. The collection of practical datasets will be a critical focus for future research.</p>
</div>
</section>
<section id="S6.SS3.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">6.3.2. </span>Robustness and Generalization</h4>

<div id="S6.SS3.SSS2.p1" class="ltx_para">
<p id="S6.SS3.SSS2.p1.1" class="ltx_p"><span id="S6.SS3.SSS2.p1.1.1" class="ltx_text ltx_font_italic">Robustness</span> in Vertical Federated Learning (VFL) is crucial to ensure models can handle challenges such as data noise. Data noise, which encompasses inaccuracies or errors stemming from various sources, can lead to incorrect predictions by the model. A robust VFL system is designed to resist such disturbances, guaranteeing that the learned model remains reliable even with imperfect data. Besides, the <span id="S6.SS3.SSS2.p1.1.2" class="ltx_text ltx_font_italic">Generalization</span> with unfair biases in prediction is equally important. It involves ensuring that the model does not deviate to certain features, which could result in biased predictions and compromise fairness across all data points. To enhance prediction fairness, FairVFL <cite class="ltx_cite ltx_citemacro_citep">(Qi et al<span class="ltx_text">.</span>, <a href="#bib.bib135" title="" class="ltx_ref">2022</a>)</cite> proposes to improve fairness in VFL models by learning unified and fair representations of data in a privacy-preserving manner. It employs adversarial learning to eliminate bias in data representations and utilizes contrastive adversarial learning to ensure user privacy. By removing bias from data representations, FairVFL promotes fairness across different user groups. Liu <span id="S6.SS3.SSS2.p1.1.3" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_citep">(Liu et al<span class="ltx_text">.</span>, <a href="#bib.bib108" title="" class="ltx_ref">2021c</a>)</cite> propose to model the fair learning task as a nonconvex-constrained optimization problem, aiming to discover a model that minimizes the loss function while adhering to fairness constraints. Formulating the problem in this way explicitly incorporates fairness considerations into the learning process.</p>
</div>
</section>
<section id="S6.SS3.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">6.3.3. </span>VFL on Different Data Variants</h4>

<div id="S6.SS3.SSS3.p1" class="ltx_para">
<p id="S6.SS3.SSS3.p1.1" class="ltx_p">Extending vertical federated learning to different data variants such as multi-modal and graph data holds significant promise for practical applications, enabling more comprehensive information aggregation by leveraging diverse data sources. Multi-modal data amalgamates various types of information, including text, images, and audio, providing a holistic view of the data. Gong <span id="S6.SS3.SSS3.p1.1.1" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_citep">(Gong et al<span class="ltx_text">.</span>, <a href="#bib.bib56" title="" class="ltx_ref">2023</a>)</cite> develop a vertical federated learning framework to handle multi-modal data distribution challenges. Graph data, on the other hand, captures relationships and networks, providing deep insights into the interconnected nature of data points <cite class="ltx_cite ltx_citemacro_citep">(Chen et al<span class="ltx_text">.</span>, <a href="#bib.bib21" title="" class="ltx_ref">2020c</a>; Cheung et al<span class="ltx_text">.</span>, <a href="#bib.bib33" title="" class="ltx_ref">2021</a>; Ni et al<span class="ltx_text">.</span>, <a href="#bib.bib129" title="" class="ltx_ref">2021</a>; Chen et al<span class="ltx_text">.</span>, <a href="#bib.bib24" title="" class="ltx_ref">2022</a>; Zhang et al<span class="ltx_text">.</span>, <a href="#bib.bib199" title="" class="ltx_ref">2023a</a>; Mai and Pang, <a href="#bib.bib122" title="" class="ltx_ref">2023</a>; Wu et al<span class="ltx_text">.</span>, <a href="#bib.bib169" title="" class="ltx_ref">2023d</a>)</cite>. By integrating VFL with different data variants, we unlock new potentials for solving complex problems, such as understanding social networks and enhancing multimedia recommendations. It not only expands the applicability of VFL but also lays the groundwork for more sophisticated and inclusive data analysis techniques.</p>
</div>
</section>
<section id="S6.SS3.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">6.3.4. </span>VFL with Foundation Models</h4>

<div id="S6.SS3.SSS4.p1" class="ltx_para">
<p id="S6.SS3.SSS4.p1.1" class="ltx_p">Recently, foundation models <cite class="ltx_cite ltx_citemacro_citep">(Bommasani et al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2021</a>; Yuan et al<span class="ltx_text">.</span>, <a href="#bib.bib193" title="" class="ltx_ref">2021</a>; Chang et al<span class="ltx_text">.</span>, <a href="#bib.bib19" title="" class="ltx_ref">2024</a>)</cite> have shown promising results and applications in various scenarios, such as GPT models <cite class="ltx_cite ltx_citemacro_citep">(Radford et al<span class="ltx_text">.</span>, <a href="#bib.bib141" title="" class="ltx_ref">2019</a>; Brown et al<span class="ltx_text">.</span>, <a href="#bib.bib12" title="" class="ltx_ref">2020</a>; Achiam et al<span class="ltx_text">.</span>, <a href="#bib.bib5" title="" class="ltx_ref">2023</a>)</cite>, LLaMA <cite class="ltx_cite ltx_citemacro_citep">(Touvron et al<span class="ltx_text">.</span>, <a href="#bib.bib159" title="" class="ltx_ref">2023</a>)</cite>, and Sora <cite class="ltx_cite ltx_citemacro_citep">(Brooks et al<span class="ltx_text">.</span>, <a href="#bib.bib11" title="" class="ltx_ref">2024</a>)</cite>. While training foundation models requires a large amount of high-quality data, federated learning provides an alternative method to collaborate data from multiple clients without privacy leakage. Although several works have explored the combination of federated learning and foundation models <cite class="ltx_cite ltx_citemacro_citep">(Zhuang et al<span class="ltx_text">.</span>, <a href="#bib.bib208" title="" class="ltx_ref">2023</a>; Fan et al<span class="ltx_text">.</span>, <a href="#bib.bib40" title="" class="ltx_ref">2023b</a>; Charles et al<span class="ltx_text">.</span>, <a href="#bib.bib20" title="" class="ltx_ref">2024</a>; Yu et al<span class="ltx_text">.</span>, <a href="#bib.bib191" title="" class="ltx_ref">2023</a>; Guo et al<span class="ltx_text">.</span>, <a href="#bib.bib61" title="" class="ltx_ref">2023</a>)</cite>, there is a lack of comprehensive discussion about vertical federated learning with foundation models. When deploying foundation models, there are privacy leakages concerning both data and model parameters. With VFL, multiple clients collaborate to train a prediction model, where only intermediate embeddings are transmitted to protect data privacy. Additionally, the entire model can be split among different clients, thereby eliminating the risk of leaking the complete model parameters. Moreover, the data can be enhanced in the feature space, which complements the data utilization in sample spaces. To explore the utilization of VFL with foundation models, Zheng <cite class="ltx_cite ltx_citemacro_citep">(Zheng, <a href="#bib.bib204" title="" class="ltx_ref">2023</a>)</cite> proposes using vertical federated learning as a privacy protection method for training foundation models and constructs a basic flow for training foundation models in VFL settings, addressing concerns about reconstruction attacks. However, training foundation models requires multiple training epochs and large data scales, which introduces significant communication and computation burdens. In the future, it is significant to explore the efficient deployment of VFL with foundation models.</p>
</div>
</section>
</section>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7. </span>Conclusion</h2>

<div id="S7.p1" class="ltx_para">
<p id="S7.p1.1" class="ltx_p">In this survey, we provide a comprehensive and systematic review of recent progress in vertical federated learning. It is the first survey to summarize related works from the perspectives of effectiveness, security and applicability, presenting the most extensive and up-to-date literature. Initially, we provide a brief introduction to vertical federated learning, including the basic training protocols of VFL, equipping readers with essential background knowledge. Subsequently, we explore research topics from three perspectives: Effectiveness, focusing on developing effective learning paradigms for general settings in VFL; Applicability, which aims to explore solutions for various limited scenarios in VFL with potential applications; and Security, which ensures privacy and resistance to malicious attacks. The relevant works are summarized accordingly. Finally, we provide an outlook on valuable future research directions, which will facilitate advancements in vertical federated learning. In conclusion, vertical federated learning is attracting significant attention in related research fields and has made rapid progress recently. However, numerous research challenges remain unexplored.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(1)</span>
<span class="ltx_bibblock">        




</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">ccp (2018)</span>
<span class="ltx_bibblock">
2018.

</span>
<span class="ltx_bibblock">California consumer privacy act (ccpa).

</span>
<span class="ltx_bibblock">(2018).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">cdp (2018)</span>
<span class="ltx_bibblock">
2018.

</span>
<span class="ltx_bibblock">Virginia consumer data protection act (cdpa).

</span>
<span class="ltx_bibblock">(2018).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Abedi and Khan (2024)</span>
<span class="ltx_bibblock">
Ali Abedi and Shehroz S Khan. 2024.

</span>
<span class="ltx_bibblock">Fedsl: Federated split learning on distributed sequential data in recurrent neural networks.

</span>
<span class="ltx_bibblock"><em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">Multimedia Tools and Applications</em> 83, 10 (2024), 28891–28911.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Achiam et al<span id="bib.bib5.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, et al<span id="bib.bib5.3.1" class="ltx_text">.</span> 2023.

</span>
<span class="ltx_bibblock">Gpt-4 technical report.

</span>
<span class="ltx_bibblock"><em id="bib.bib5.4.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2303.08774</em> (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Al-Jarrah et al<span id="bib.bib6.2.2.1" class="ltx_text">.</span> (2015)</span>
<span class="ltx_bibblock">
Omar Y Al-Jarrah, Paul D Yoo, Sami Muhaidat, George K Karagiannidis, and Kamal Taha. 2015.

</span>
<span class="ltx_bibblock">Efficient machine learning for big data: A review.

</span>
<span class="ltx_bibblock"><em id="bib.bib6.3.1" class="ltx_emph ltx_font_italic">Big Data Research</em> 2, 3 (2015), 87–93.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bai et al<span id="bib.bib7.4.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Yijie Bai, Yanjiao Chen, Hanlei Zhang, Wenyuan Xu, Haiqin Weng, and Dou Goodman. 2023.

</span>
<span class="ltx_bibblock"><math id="bib.bib7.1.m1.1" class="ltx_Math" alttext="\{" display="inline"><semantics id="bib.bib7.1.m1.1a"><mo stretchy="false" id="bib.bib7.1.m1.1.1" xref="bib.bib7.1.m1.1.1.cmml">{</mo><annotation-xml encoding="MathML-Content" id="bib.bib7.1.m1.1b"><ci id="bib.bib7.1.m1.1.1.cmml" xref="bib.bib7.1.m1.1.1">{</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib7.1.m1.1c">\{</annotation></semantics></math>VILLAIN<math id="bib.bib7.2.m2.1" class="ltx_Math" alttext="\}" display="inline"><semantics id="bib.bib7.2.m2.1a"><mo stretchy="false" id="bib.bib7.2.m2.1.1" xref="bib.bib7.2.m2.1.1.cmml">}</mo><annotation-xml encoding="MathML-Content" id="bib.bib7.2.m2.1b"><ci id="bib.bib7.2.m2.1.1.cmml" xref="bib.bib7.2.m2.1.1">}</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib7.2.m2.1c">\}</annotation></semantics></math>: Backdoor Attacks Against Vertical Split Learning. In <em id="bib.bib7.5.1" class="ltx_emph ltx_font_italic">USENIX Security</em>. 2743–2760.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Becker and Kohavi (1996)</span>
<span class="ltx_bibblock">
Barry Becker and Ronny Kohavi. 1996.

</span>
<span class="ltx_bibblock">Adult.

</span>
<span class="ltx_bibblock">(1996).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Benny et al<span id="bib.bib9.2.2.1" class="ltx_text">.</span> (2014)</span>
<span class="ltx_bibblock">
Pinkas Benny, Schneider Thomas, and Zohner Michael. 2014.

</span>
<span class="ltx_bibblock">Faster private set intersection based on OT extension. In <em id="bib.bib9.3.1" class="ltx_emph ltx_font_italic">Usenix Security</em>. 797–812.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bommasani et al<span id="bib.bib10.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Rishi Bommasani, Drew A Hudson, Ehsan Adeli, Russ Altman, Simran Arora, Sydney von Arx, Michael S Bernstein, Jeannette Bohg, Antoine Bosselut, Emma Brunskill, et al<span id="bib.bib10.3.1" class="ltx_text">.</span> 2021.

</span>
<span class="ltx_bibblock">On the opportunities and risks of foundation models.

</span>
<span class="ltx_bibblock"><em id="bib.bib10.4.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2108.07258</em> (2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brooks et al<span id="bib.bib11.2.2.1" class="ltx_text">.</span> (2024)</span>
<span class="ltx_bibblock">
Tim Brooks, Bill Peebles, Connor Holmes, Will DePue, Yufei Guo, Li Jing, David Schnurr, Joe Taylor, Troy Luhman, Eric Luhman, Clarence Ng, Ricky Wang, and Aditya Ramesh. 2024.

</span>
<span class="ltx_bibblock">Video generation models as world simulators.

</span>
<span class="ltx_bibblock">(2024).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brown et al<span id="bib.bib12.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al<span id="bib.bib12.3.1" class="ltx_text">.</span> 2020.

</span>
<span class="ltx_bibblock">Language models are few-shot learners.

</span>
<span class="ltx_bibblock"><em id="bib.bib12.4.1" class="ltx_emph ltx_font_italic">NeurIPS</em> 33 (2020), 1877–1901.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cai (2020)</span>
<span class="ltx_bibblock">
Fangfang Cai. 2020.

</span>
<span class="ltx_bibblock">ByteDance breaks federal learning: open source fedlearner framework, 209% increase in advertising efficiency.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Castiglia et al<span id="bib.bib14.2.2.1" class="ltx_text">.</span> (2022b)</span>
<span class="ltx_bibblock">
Timothy Castiglia, Shiqiang Wang, and Stacy Patterson. 2022b.

</span>
<span class="ltx_bibblock">Self-supervised vertical federated learning. In <em id="bib.bib14.3.1" class="ltx_emph ltx_font_italic">Workshop on Federated Learning: Recent Advances and New Challenges</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Castiglia et al<span id="bib.bib15.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Timothy Castiglia, Yi Zhou, Shiqiang Wang, Swanand Kadhe, Nathalie Baracaldo, and Stacy Patterson. 2023.

</span>
<span class="ltx_bibblock">Less-vfl: Communication-efficient feature selection for vertical federated learning. In <em id="bib.bib15.3.1" class="ltx_emph ltx_font_italic">ICML</em>. 3757–3781.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Castiglia et al<span id="bib.bib16.2.2.1" class="ltx_text">.</span> (2022a)</span>
<span class="ltx_bibblock">
Timothy J Castiglia, Anirban Das, Shiqiang Wang, and Stacy Patterson. 2022a.

</span>
<span class="ltx_bibblock">Compressed-vfl: Communication-efficient learning with vertically partitioned data. In <em id="bib.bib16.3.1" class="ltx_emph ltx_font_italic">ICML</em>. 2738–2766.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cha et al<span id="bib.bib17.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Dongchul Cha, MinDong Sung, Yu-Rang Park, et al<span id="bib.bib17.3.1" class="ltx_text">.</span> 2021.

</span>
<span class="ltx_bibblock">Implementing vertical federated learning using autoencoders: Practical application, generalizability, and utility study.

</span>
<span class="ltx_bibblock"><em id="bib.bib17.4.1" class="ltx_emph ltx_font_italic">JMIR medical informatics</em> 9, 6 (2021), e26598.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chang and Zhu (2024)</span>
<span class="ltx_bibblock">
Wenhan Chang and Tianqing Zhu. 2024.

</span>
<span class="ltx_bibblock">Gradient-based defense methods for data leakage in vertical federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">Computers &amp; Security</em> 139 (2024), 103744.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chang et al<span id="bib.bib19.2.2.1" class="ltx_text">.</span> (2024)</span>
<span class="ltx_bibblock">
Yupeng Chang, Xu Wang, Jindong Wang, Yuan Wu, Linyi Yang, Kaijie Zhu, Hao Chen, Xiaoyuan Yi, Cunxiang Wang, Yidong Wang, et al<span id="bib.bib19.3.1" class="ltx_text">.</span> 2024.

</span>
<span class="ltx_bibblock">A survey on evaluation of large language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib19.4.1" class="ltx_emph ltx_font_italic">ACM Transactions on Intelligent Systems and Technology</em> 15, 3 (2024), 1–45.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Charles et al<span id="bib.bib20.2.2.1" class="ltx_text">.</span> (2024)</span>
<span class="ltx_bibblock">
Zachary Charles, Nicole Mitchell, Krishna Pillutla, Michael Reneer, and Zachary Garrett. 2024.

</span>
<span class="ltx_bibblock">Towards federated foundation models: Scalable dataset pipelines for group-structured learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib20.3.1" class="ltx_emph ltx_font_italic">NeurIPS</em> 36 (2024).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al<span id="bib.bib21.2.2.1" class="ltx_text">.</span> (2020c)</span>
<span class="ltx_bibblock">
Chaochao Chen, Jun Zhou, Longfei Zheng, Huiwen Wu, Lingjuan Lyu, Jia Wu, Bingzhe Wu, Ziqi Liu, Li Wang, and Xiaolin Zheng. 2020c.

</span>
<span class="ltx_bibblock">Vertically federated graph neural network for privacy-preserving node classification.

</span>
<span class="ltx_bibblock"><em id="bib.bib21.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2005.11903</em> (2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al<span id="bib.bib22.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Hao Chen, Kim Laine, and Peter Rindal. 2017.

</span>
<span class="ltx_bibblock">Fast private set intersection from homomorphic encryption. In <em id="bib.bib22.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security</em>. 1243–1255.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al<span id="bib.bib23.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Huiqiang Chen, Tianqing Zhu, Tao Zhang, Wanlei Zhou, and Philip S Yu. 2023.

</span>
<span class="ltx_bibblock">Privacy and fairness in Federated learning: on the perspective of Tradeoff.

</span>
<span class="ltx_bibblock"><em id="bib.bib23.3.1" class="ltx_emph ltx_font_italic">Comput. Surveys</em> 56, 2 (2023), 1–37.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al<span id="bib.bib24.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Jinyin Chen, Guohan Huang, Haibin Zheng, Shanqing Yu, Wenrong Jiang, and Chen Cui. 2022.

</span>
<span class="ltx_bibblock">Graph-fraudster: Adversarial attacks on graph neural network-based vertical federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib24.3.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Computational Social Systems</em> 10, 2 (2022), 492–506.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al<span id="bib.bib25.2.2.1" class="ltx_text">.</span> (2024a)</span>
<span class="ltx_bibblock">
Peng Chen, Xin Du, Zhihui Lu, and Hongfeng Chai. 2024a.

</span>
<span class="ltx_bibblock">Universal adversarial backdoor attacks to fool vertical federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib25.3.1" class="ltx_emph ltx_font_italic">Computers &amp; Security</em> 137 (2024), 103601.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al<span id="bib.bib26.2.2.1" class="ltx_text">.</span> (2020a)</span>
<span class="ltx_bibblock">
Tianyi Chen, Xiao Jin, Yuejiao Sun, and Wotao Yin. 2020a.

</span>
<span class="ltx_bibblock">Vafl: a method of vertical asynchronous federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib26.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2007.06081</em> (2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al<span id="bib.bib27.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Weijing Chen, Guoqiang Ma, Tao Fan, Yan Kang, Qian Xu, and Qiang Yang. 2021.

</span>
<span class="ltx_bibblock">Secureboost+: A high performance gradient boosting tree framework for large scale vertical federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib27.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2110.10927</em> (2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al<span id="bib.bib28.2.2.1" class="ltx_text">.</span> (2024c)</span>
<span class="ltx_bibblock">
Xiaolin Chen, Daoguang Zan, Wei Li, Bei Guan, and Yongji Wang. 2024c.

</span>
<span class="ltx_bibblock">A GAN-based data poisoning framework against anomaly detection in vertical federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib28.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2401.08984</em> (2024).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al<span id="bib.bib29.2.2.1" class="ltx_text">.</span> (2024b)</span>
<span class="ltx_bibblock">
Yuhang Chen, Wenke Huang, and Mang Ye. 2024b.

</span>
<span class="ltx_bibblock">Fair Federated Learning under Domain Skew with Local Consistency and Domain Diversity. In <em id="bib.bib29.3.1" class="ltx_emph ltx_font_italic">CVPR</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al<span id="bib.bib30.2.2.1" class="ltx_text">.</span> (2020b)</span>
<span class="ltx_bibblock">
Yiqiang Chen, Xin Qin, Jindong Wang, Chaohui Yu, and Wen Gao. 2020b.

</span>
<span class="ltx_bibblock">Fedhealth: A federated transfer learning framework for wearable healthcare.

</span>
<span class="ltx_bibblock"><em id="bib.bib30.3.1" class="ltx_emph ltx_font_italic">IEEE Intelligent Systems</em> 35, 4 (2020), 83–93.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cheng et al<span id="bib.bib31.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Kewei Cheng, Tao Fan, Yilun Jin, Yang Liu, Tianjian Chen, Dimitrios Papadopoulos, and Qiang Yang. 2021.

</span>
<span class="ltx_bibblock">Secureboost: A lossless federated learning framework.

</span>
<span class="ltx_bibblock"><em id="bib.bib31.3.1" class="ltx_emph ltx_font_italic">IEEE Intelligent Systems</em> 36, 6 (2021), 87–98.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cheng et al<span id="bib.bib32.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Yong Cheng, Yang Liu, Tianjian Chen, and Qiang Yang. 2020.

</span>
<span class="ltx_bibblock">Federated learning for privacy-preserving AI.

</span>
<span class="ltx_bibblock"><em id="bib.bib32.3.1" class="ltx_emph ltx_font_italic">Commun. ACM</em> 63, 12 (2020), 33–36.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cheung et al<span id="bib.bib33.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Tsz-Him Cheung, Weihang Dai, and Shuhan Li. 2021.

</span>
<span class="ltx_bibblock">Fedsgc: Federated simple graph convolution for node classification. In <em id="bib.bib33.3.1" class="ltx_emph ltx_font_italic">IJCAI Workshops</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chua et al<span id="bib.bib34.2.2.1" class="ltx_text">.</span> (2009)</span>
<span class="ltx_bibblock">
Tat-Seng Chua, Jinhui Tang, Richang Hong, Haojie Li, Zhiping Luo, and Yantao Zheng. 2009.

</span>
<span class="ltx_bibblock">Nus-wide: a real-world web image database from national university of singapore. In <em id="bib.bib34.3.1" class="ltx_emph ltx_font_italic">Proceedings of the ACM international conference on image and video retrieval</em>. 1–9.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Davidson and Cid (2017)</span>
<span class="ltx_bibblock">
Alex Davidson and Carlos Cid. 2017.

</span>
<span class="ltx_bibblock">An efficient toolkit for computing private set operations. In <em id="bib.bib35.1.1" class="ltx_emph ltx_font_italic">Information Security and Privacy</em>. 261–278.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dua et al<span id="bib.bib36.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Dheeru Dua, Casey Graff, et al<span id="bib.bib36.3.1" class="ltx_text">.</span> 2017.

</span>
<span class="ltx_bibblock">UCI machine learning repository.

</span>
<span class="ltx_bibblock">(2017).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Duanyi et al<span id="bib.bib37.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Yao Duanyi, Songze Li, Xue Ye, and Jin Liu. 2023.

</span>
<span class="ltx_bibblock">Constructing Adversarial Examples for Vertical Federated Learning: Optimal Client Corruption through Multi-Armed Bandit. In <em id="bib.bib37.3.1" class="ltx_emph ltx_font_italic">ICLR</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Errounda and Liu (2023)</span>
<span class="ltx_bibblock">
Fatima Zahra Errounda and Yan Liu. 2023.

</span>
<span class="ltx_bibblock">Adaptive differential privacy in vertical federated learning for mobility forecasting.

</span>
<span class="ltx_bibblock"><em id="bib.bib38.1.1" class="ltx_emph ltx_font_italic">Future Generation Computer Systems</em> 149 (2023), 531–546.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fan et al<span id="bib.bib39.2.2.1" class="ltx_text">.</span> (2023a)</span>
<span class="ltx_bibblock">
Kai Fan, Jingtao Hong, Wenjie Li, Xingwen Zhao, Hui Li, and Yintang Yang. 2023a.

</span>
<span class="ltx_bibblock">FLSG: A Novel Defense Strategy Against Inference Attacks in Vertical Federated Learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib39.3.1" class="ltx_emph ltx_font_italic">IEEE Internet of Things Journal</em> (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fan et al<span id="bib.bib40.2.2.1" class="ltx_text">.</span> (2023b)</span>
<span class="ltx_bibblock">
Tao Fan, Yan Kang, Guoqiang Ma, Weijing Chen, Wenbin Wei, Lixin Fan, and Qiang Yang. 2023b.

</span>
<span class="ltx_bibblock">Fate-llm: A industrial grade federated learning framework for large language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib40.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2310.10049</em> (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fan et al<span id="bib.bib41.2.2.1" class="ltx_text">.</span> (2024)</span>
<span class="ltx_bibblock">
Zhenan Fan, Huang Fang, Zirui Zhou, Jian Pei, Michael P Friedlander, and Yong Zhang. 2024.

</span>
<span class="ltx_bibblock">Fair and efficient contribution valuation for vertical federated learning. In <em id="bib.bib41.3.1" class="ltx_emph ltx_font_italic">ICLR</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fang et al<span id="bib.bib42.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Wenjing Fang, Derun Zhao, Jin Tan, Chaochao Chen, Chaofan Yu, Li Wang, Lei Wang, Jun Zhou, and Benyu Zhang. 2021.

</span>
<span class="ltx_bibblock">Large-scale secure XGB for vertical federated learning. In <em id="bib.bib42.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 30th ACM International Conference on Information &amp; Knowledge Management</em>. 443–452.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fang and Ye (2022)</span>
<span class="ltx_bibblock">
Xiuwen Fang and Mang Ye. 2022.

</span>
<span class="ltx_bibblock">Robust federated learning with noisy and heterogeneous clients. In <em id="bib.bib43.1.1" class="ltx_emph ltx_font_italic">CVPR</em>. 10072–10081.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fang et al<span id="bib.bib44.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Xiuwen Fang, Mang Ye, and Xiyuan Yang. 2023.

</span>
<span class="ltx_bibblock">Robust heterogeneous federated learning under data corruption. In <em id="bib.bib44.3.1" class="ltx_emph ltx_font_italic">CVPR</em>. 5020–5030.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Feng (2022)</span>
<span class="ltx_bibblock">
Siwei Feng. 2022.

</span>
<span class="ltx_bibblock">Vertical federated learning-based feature selection with non-overlapping sample utilization.

</span>
<span class="ltx_bibblock"><em id="bib.bib45.1.1" class="ltx_emph ltx_font_italic">Expert Systems with Applications</em> 208 (2022), 118097.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Feng and Yu (2020)</span>
<span class="ltx_bibblock">
Siwei Feng and Han Yu. 2020.

</span>
<span class="ltx_bibblock">Multi-participant multi-class vertical federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib46.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2001.11154</em> (2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Feng et al<span id="bib.bib47.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Zhi Feng, Haoyi Xiong, Chuanyuan Song, Sijia Yang, Baoxin Zhao, Licheng Wang, Zeyu Chen, Shengwen Yang, Liping Liu, and Jun Huan. 2019.

</span>
<span class="ltx_bibblock">Securegbm: Secure multi-party gradient boosting. In <em id="bib.bib47.3.1" class="ltx_emph ltx_font_italic">2019 IEEE international conference on big data (big data)</em>. 1312–1321.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fu et al<span id="bib.bib48.2.2.1" class="ltx_text">.</span> (2022b)</span>
<span class="ltx_bibblock">
Chong Fu, Xuhong Zhang, Shouling Ji, Jinyin Chen, Jingzheng Wu, Shanqing Guo, Jun Zhou, Alex X Liu, and Ting Wang. 2022b.

</span>
<span class="ltx_bibblock">Label inference attacks against vertical federated learning. In <em id="bib.bib48.3.1" class="ltx_emph ltx_font_italic">USENIX Security</em>. 1397–1414.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fu et al<span id="bib.bib49.2.2.1" class="ltx_text">.</span> (2022a)</span>
<span class="ltx_bibblock">
Fangcheng Fu, Xupeng Miao, Jiawei Jiang, Huanran Xue, and Bin Cui. 2022a.

</span>
<span class="ltx_bibblock">Towards communication-efficient vertical federated learning training via cache-enabled local updates.

</span>
<span class="ltx_bibblock"><em id="bib.bib49.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2207.14628</em> (2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fu et al<span id="bib.bib50.2.2.1" class="ltx_text">.</span> (2024)</span>
<span class="ltx_bibblock">
F. Fu, X. Wang, J. Jiang, H. Xue, and B. Cui. 2024.

</span>
<span class="ltx_bibblock">ProjPert: Projection-based Perturbation for Label Protection in Split Learning based Vertical Federated Learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib50.3.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Knowledge and Data Engineering</em> (2024).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fu et al<span id="bib.bib51.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Rui Fu, Yuncheng Wu, Quanqing Xu, and Meihui Zhang. 2023.

</span>
<span class="ltx_bibblock">FEAST: A communication-efficient federated feature selection framework for relational data.

</span>
<span class="ltx_bibblock"><em id="bib.bib51.3.1" class="ltx_emph ltx_font_italic">Proceedings of the ACM on Management of Data</em> 1, 1 (2023), 1–28.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fung et al<span id="bib.bib52.2.2.1" class="ltx_text">.</span> (2010)</span>
<span class="ltx_bibblock">
Benjamin CM Fung, Ke Wang, Rui Chen, and Philip S Yu. 2010.

</span>
<span class="ltx_bibblock">Privacy-preserving data publishing: A survey of recent developments.

</span>
<span class="ltx_bibblock"><em id="bib.bib52.3.1" class="ltx_emph ltx_font_italic">Comput. Surveys</em> 42, 4 (2010), 1–53.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">GDPR (2018)</span>
<span class="ltx_bibblock">
General Data Protection Regulation GDPR. 2018.

</span>
<span class="ltx_bibblock">General data protection regulation.

</span>
<span class="ltx_bibblock">(2018).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ge et al<span id="bib.bib54.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Ning Ge, Guanghao Li, Li Zhang, and Yi Liu. 2022.

</span>
<span class="ltx_bibblock">Failure prediction in production line based on federated learning: an empirical study.

</span>
<span class="ltx_bibblock"><em id="bib.bib54.3.1" class="ltx_emph ltx_font_italic">Journal of Intelligent Manufacturing</em> 33, 8 (2022), 2277–2294.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Girgis et al<span id="bib.bib55.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Antonious M Girgis, Deepesh Data, Suhas Diggavi, Peter Kairouz, and Ananda Theertha Suresh. 2021.

</span>
<span class="ltx_bibblock">Shuffled model of federated learning: Privacy, accuracy and communication trade-offs.

</span>
<span class="ltx_bibblock"><em id="bib.bib55.3.1" class="ltx_emph ltx_font_italic">IEEE Journal on Selected Areas in Information Theory</em> 2, 1 (2021), 464–478.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gong et al<span id="bib.bib56.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Maoguo Gong, Yuanqiao Zhang, Yuan Gao, AK Qin, Yue Wu, Shanfeng Wang, and Yihong Zhang. 2023.

</span>
<span class="ltx_bibblock">A Multi-Modal Vertical Federated Learning Framework Based on Homomorphic Encryption.

</span>
<span class="ltx_bibblock"><em id="bib.bib56.3.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Information Forensics and Security</em> (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gu et al<span id="bib.bib57.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Bin Gu, Zhiyuan Dang, Xiang Li, and Heng Huang. 2020.

</span>
<span class="ltx_bibblock">Federated doubly stochastic kernel learning for vertically partitioned data. In <em id="bib.bib57.3.1" class="ltx_emph ltx_font_italic">SIGKDD</em>. 2483–2493.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gu et al<span id="bib.bib58.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Bin Gu, An Xu, Zhouyuan Huo, Cheng Deng, and Heng Huang. 2021.

</span>
<span class="ltx_bibblock">Privacy-preserving asynchronous vertical federated learning algorithms for multiparty collaborative learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib58.3.1" class="ltx_emph ltx_font_italic">TNNLS</em> 33, 11 (2021), 6103–6115.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib59" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gu et al<span id="bib.bib59.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Hanlin Gu, Jiahuan Luo, Yan Kang, Lixin Fan, and Qiang Yang. 2023.

</span>
<span class="ltx_bibblock">FedPass: privacy-preserving vertical federated deep learning with adaptive obfuscation.

</span>
<span class="ltx_bibblock"><em id="bib.bib59.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2301.12623</em> (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib60" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gu and Bai (2023)</span>
<span class="ltx_bibblock">
Yuhao Gu and Yuebin Bai. 2023.

</span>
<span class="ltx_bibblock">LR-BA: Backdoor attack against vertical federated learning using local latent representations.

</span>
<span class="ltx_bibblock"><em id="bib.bib60.1.1" class="ltx_emph ltx_font_italic">Computers &amp; Security</em> 129 (2023), 103193.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib61" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Guo et al<span id="bib.bib61.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Tao Guo, Song Guo, Junxiao Wang, Xueyang Tang, and Wenchao Xu. 2023.

</span>
<span class="ltx_bibblock">Promptfl: Let federated participants cooperatively learn prompts instead of models-federated learning in age of foundation model.

</span>
<span class="ltx_bibblock"><em id="bib.bib61.3.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Mobile Computing</em> (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib62" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Han et al<span id="bib.bib62.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Xiao Han, Yuncong Yang, Leye Wang, and Junjie Wu. 2023.

</span>
<span class="ltx_bibblock">Privacy-Preserving Network Embedding against Private Link Inference Attacks.

</span>
<span class="ltx_bibblock"><em id="bib.bib62.3.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Dependable and Secure Computing</em> (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib63" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hardy et al<span id="bib.bib63.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Stephen Hardy, Wilko Henecka, Hamish Ivey-Law, Richard Nock, Giorgio Patrini, Guillaume Smith, and Brian Thorne. 2017.

</span>
<span class="ltx_bibblock">Private federated learning on vertically partitioned data via entity resolution and additively homomorphic encryption.

</span>
<span class="ltx_bibblock"><em id="bib.bib63.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1711.10677</em> (2017).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib64" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hashemi et al<span id="bib.bib64.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Nazila Hashemi, Pooyan Safari, Behnam Shariati, and Johannes Karl Fischer. 2021.

</span>
<span class="ltx_bibblock">Vertical federated learning for privacy-preserving ML model development in partially disaggregated networks. In <em id="bib.bib64.3.1" class="ltx_emph ltx_font_italic">2021 European Conference on Optical Communication</em>. 1–4.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib65" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He et al<span id="bib.bib65.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Chaoyang He, Songze Li, Jinhyun So, Xiao Zeng, Mi Zhang, Hongyi Wang, Xiaoyang Wang, Praneeth Vepakomma, Abhishek Singh, Hang Qiu, et al<span id="bib.bib65.3.1" class="ltx_text">.</span> 2020.

</span>
<span class="ltx_bibblock">Fedml: A research library and benchmark for federated machine learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib65.4.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2007.13518</em> (2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib66" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He et al<span id="bib.bib66.2.2.1" class="ltx_text">.</span> (2024)</span>
<span class="ltx_bibblock">
Yuanqin He, Yan Kang, Xinyuan Zhao, Jiahuan Luo, Lixin Fan, Yuxing Han, and Qiang Yang. 2024.

</span>
<span class="ltx_bibblock">A hybrid self-supervised learning framework for vertical federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib66.3.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Big Data</em> (2024).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib67" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He et al<span id="bib.bib67.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Ying He, Zhili Shen, Jingyu Hua, Qixuan Dong, Jiacheng Niu, Wei Tong, Xu Huang, Chen Li, and Sheng Zhong. 2023.

</span>
<span class="ltx_bibblock">Backdoor Attack Against Split Neural Network-Based Vertical Federated Learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib67.3.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Information Forensics and Security</em> (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib68" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hou et al<span id="bib.bib68.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Jinpeng Hou, Mang Su, Anmin Fu, and Yan Yu. 2021.

</span>
<span class="ltx_bibblock">Verifiable privacy-preserving scheme based on vertical federated random forest.

</span>
<span class="ltx_bibblock"><em id="bib.bib68.3.1" class="ltx_emph ltx_font_italic">IEEE Internet of Things Journal</em> 9, 22 (2021), 22158–22172.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib69" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hu et al<span id="bib.bib69.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Yuzheng Hu, Tianle Cai, Jinyong Shan, Shange Tang, Chaochao Cai, Ethan Song, Bo Li, and Dawn Song. 2022.

</span>
<span class="ltx_bibblock">Is vertical logistic regression privacy-preserving? a comprehensive privacy analysis and beyond.

</span>
<span class="ltx_bibblock"><em id="bib.bib69.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2207.09087</em> (2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib70" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang et al<span id="bib.bib70.2.2.1" class="ltx_text">.</span> (2023b)</span>
<span class="ltx_bibblock">
Chung-ju Huang, Leye Wang, and Xiao Han. 2023b.

</span>
<span class="ltx_bibblock">Vertical federated knowledge transfer via representation distillation for healthcare collaboration networks. In <em id="bib.bib70.3.1" class="ltx_emph ltx_font_italic">WWW</em>. 4188–4199.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib71" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang et al<span id="bib.bib71.2.2.1" class="ltx_text">.</span> (2024)</span>
<span class="ltx_bibblock">
Wenke Huang, Yuxia Liu, Mang Ye, Jun Chen, and Bo Du. 2024.

</span>
<span class="ltx_bibblock">Federated Learning with Long-Tailed Data via Representation Unification and Classifier Rectification.

</span>
<span class="ltx_bibblock"><em id="bib.bib71.3.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Information Forensics and Security</em> (2024).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib72" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang et al<span id="bib.bib72.2.2.1" class="ltx_text">.</span> (2023a)</span>
<span class="ltx_bibblock">
Wenke Huang, Guancheng Wan, Mang Ye, and Bo Du. 2023a.

</span>
<span class="ltx_bibblock">Federated graph semantic and structural learning. In <em id="bib.bib72.3.1" class="ltx_emph ltx_font_italic">IJCAI</em>. 3830–3838.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib73" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang et al<span id="bib.bib73.2.2.1" class="ltx_text">.</span> (2022b)</span>
<span class="ltx_bibblock">
Wenke Huang, Mang Ye, and Bo Du. 2022b.

</span>
<span class="ltx_bibblock">Learn from others and be yourself in heterogeneous federated learning. In <em id="bib.bib73.3.1" class="ltx_emph ltx_font_italic">CVPR</em>. 10143–10153.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib74" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang et al<span id="bib.bib74.2.2.1" class="ltx_text">.</span> (2023c)</span>
<span class="ltx_bibblock">
Wenke Huang, Mang Ye, Zekun Shi, and Bo Du. 2023c.

</span>
<span class="ltx_bibblock">Generalizable heterogeneous federated cross-correlation and instance similarity learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib74.3.1" class="ltx_emph ltx_font_italic">IEEE TPAMI</em> (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib75" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang et al<span id="bib.bib75.2.2.1" class="ltx_text">.</span> (2023d)</span>
<span class="ltx_bibblock">
Wenke Huang, Mang Ye, Zekun Shi, He Li, and Bo Du. 2023d.

</span>
<span class="ltx_bibblock">Rethinking federated learning with domain shift: A prototype view. In <em id="bib.bib75.3.1" class="ltx_emph ltx_font_italic">CVPR</em>. 16312–16322.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib76" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang et al<span id="bib.bib76.2.2.1" class="ltx_text">.</span> (2023e)</span>
<span class="ltx_bibblock">
Wenke Huang, Mang Ye, Zekun Shi, Guancheng Wan, He Li, Bo Du, and Qiang Yang. 2023e.

</span>
<span class="ltx_bibblock">Federated Learning for Generalization, Robustness, Fairness: A Survey and Benchmark.

</span>
<span class="ltx_bibblock"><em id="bib.bib76.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2311.06750</em> (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib77" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang et al<span id="bib.bib77.4.2.1" class="ltx_text">.</span> (2022a)</span>
<span class="ltx_bibblock">
Zhicong Huang, Wen-jie Lu, Cheng Hong, and Jiansheng Ding. 2022a.

</span>
<span class="ltx_bibblock">Cheetah: Lean and fast secure <math id="bib.bib77.1.m1.1" class="ltx_Math" alttext="\{" display="inline"><semantics id="bib.bib77.1.m1.1a"><mo stretchy="false" id="bib.bib77.1.m1.1.1" xref="bib.bib77.1.m1.1.1.cmml">{</mo><annotation-xml encoding="MathML-Content" id="bib.bib77.1.m1.1b"><ci id="bib.bib77.1.m1.1.1.cmml" xref="bib.bib77.1.m1.1.1">{</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib77.1.m1.1c">\{</annotation></semantics></math>Two-Party<math id="bib.bib77.2.m2.1" class="ltx_Math" alttext="\}" display="inline"><semantics id="bib.bib77.2.m2.1a"><mo stretchy="false" id="bib.bib77.2.m2.1.1" xref="bib.bib77.2.m2.1.1.cmml">}</mo><annotation-xml encoding="MathML-Content" id="bib.bib77.2.m2.1b"><ci id="bib.bib77.2.m2.1.1.cmml" xref="bib.bib77.2.m2.1.1">}</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib77.2.m2.1c">\}</annotation></semantics></math> deep neural network inference. In <em id="bib.bib77.5.1" class="ltx_emph ltx_font_italic">USENIX Security</em>. 809–826.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib78" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Inbar et al<span id="bib.bib78.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Roi Inbar, Eran Omri, and Benny Pinkas. 2018.

</span>
<span class="ltx_bibblock">Efficient scalable multiparty private set-intersection via garbled bloom filters. In <em id="bib.bib78.3.1" class="ltx_emph ltx_font_italic">International conference on security and cryptography for networks</em>. 235–252.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib79" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Inoue et al<span id="bib.bib79.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Yoshitaka Inoue, Hiroki Moriya, Qiong Zhang, and Kris Skrinak. 2023.

</span>
<span class="ltx_bibblock">SparseVFL: Communication-Efficient Vertical Federated Learning Based on Sparsification of Embeddings and Gradients. In <em id="bib.bib79.3.1" class="ltx_emph ltx_font_italic">International Workshop on Federated Learning for Distributed Data Mining</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib80" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jia et al<span id="bib.bib80.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Yanxue Jia, Shi-Feng Sun, Hong-Sheng Zhou, Jiajun Du, and Dawu Gu. 2022.

</span>
<span class="ltx_bibblock">Shuffle-based private set union: Faster and more secure. In <em id="bib.bib80.3.1" class="ltx_emph ltx_font_italic">USENIX Security</em>. 2947–2964.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib81" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jiang et al<span id="bib.bib81.2.2.1" class="ltx_text">.</span> (2022a)</span>
<span class="ltx_bibblock">
Jiawei Jiang, Lukas Burkhalter, Fangcheng Fu, Bolin Ding, Bo Du, Anwar Hithnawi, Bo Li, and Ce Zhang. 2022a.

</span>
<span class="ltx_bibblock">Vf-ps: How to select important participants in vertical federated learning, efficiently and securely?

</span>
<span class="ltx_bibblock"><em id="bib.bib81.3.1" class="ltx_emph ltx_font_italic">NeurIPS</em> 35 (2022), 2088–2101.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib82" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jiang et al<span id="bib.bib82.2.2.1" class="ltx_text">.</span> (2022b)</span>
<span class="ltx_bibblock">
Xue Jiang, Xuebing Zhou, and Jens Grossklags. 2022b.

</span>
<span class="ltx_bibblock">Comprehensive analysis of privacy leakage in vertical federated learning during prediction.

</span>
<span class="ltx_bibblock"><em id="bib.bib82.3.1" class="ltx_emph ltx_font_italic">Proceedings on Privacy Enhancing Technologies</em> (2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib83" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jin et al<span id="bib.bib83.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Xiao Jin, Pin-Yu Chen, Chia-Yi Hsu, Chia-Mu Yu, and Tianyi Chen. 2021.

</span>
<span class="ltx_bibblock">Cafe: Catastrophic data leakage in vertical federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib83.3.1" class="ltx_emph ltx_font_italic">NeurIPS</em> 34 (2021), 994–1006.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib84" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kahn (1994)</span>
<span class="ltx_bibblock">
Michael Kahn. 1994.

</span>
<span class="ltx_bibblock">Diabetes.

</span>
<span class="ltx_bibblock">(1994).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib85" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kang et al<span id="bib.bib85.2.2.1" class="ltx_text">.</span> (2022a)</span>
<span class="ltx_bibblock">
Yan Kang, Yang Liu, and Xinle Liang. 2022a.

</span>
<span class="ltx_bibblock">Fedcvt: Semi-supervised vertical federated learning with cross-view training.

</span>
<span class="ltx_bibblock"><em id="bib.bib85.3.1" class="ltx_emph ltx_font_italic">ACM Transactions on Intelligent Systems and Technology</em> 13, 4 (2022), 1–16.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib86" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kang et al<span id="bib.bib86.2.2.1" class="ltx_text">.</span> (2022b)</span>
<span class="ltx_bibblock">
Yan Kang, Jiahuan Luo, Yuanqin He, Xiaojin Zhang, Lixin Fan, and Qiang Yang. 2022b.

</span>
<span class="ltx_bibblock">A framework for evaluating privacy-utility trade-off in vertical federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib86.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2209.03885</em> (2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib87" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kariyappa and Qureshi (2023)</span>
<span class="ltx_bibblock">
Sanjay Kariyappa and Moinuddin K Qureshi. 2023.

</span>
<span class="ltx_bibblock">Exploit: Extracting private labels in split learning. In <em id="bib.bib87.1.1" class="ltx_emph ltx_font_italic">2023 IEEE Conference on Secure and Trustworthy Machine Learning</em>. 165–175.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib88" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Khan et al<span id="bib.bib88.2.2.1" class="ltx_text">.</span> (2022a)</span>
<span class="ltx_bibblock">
Afsana Khan, Marijn ten Thij, and Anna Wilbik. 2022a.

</span>
<span class="ltx_bibblock">Communication-efficient vertical federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib88.3.1" class="ltx_emph ltx_font_italic">Algorithms</em> 15, 8 (2022), 273.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib89" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Khan et al<span id="bib.bib89.2.2.1" class="ltx_text">.</span> (2022b)</span>
<span class="ltx_bibblock">
Afsana Khan, Marijn ten Thij, and Anna Wilbik. 2022b.

</span>
<span class="ltx_bibblock">Vertical federated learning: A structured literature review.

</span>
<span class="ltx_bibblock"><em id="bib.bib89.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2212.00622</em> (2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib90" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kissner and Song (2005)</span>
<span class="ltx_bibblock">
Lea Kissner and Dawn Song. 2005.

</span>
<span class="ltx_bibblock">Privacy-preserving set operations. In <em id="bib.bib90.1.1" class="ltx_emph ltx_font_italic">Annual International Cryptology Conference</em>. 241–257.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib91" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kolesnikov et al<span id="bib.bib91.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Vladimir Kolesnikov, Naor Matania, Benny Pinkas, Mike Rosulek, and Ni Trieu. 2017.

</span>
<span class="ltx_bibblock">Practical multi-party private set intersection from symmetric-key techniques. In <em id="bib.bib91.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security</em>. 1257–1272.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib92" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Krizhevsky et al<span id="bib.bib92.2.2.1" class="ltx_text">.</span> (2009)</span>
<span class="ltx_bibblock">
Alex Krizhevsky, Geoffrey Hinton, et al<span id="bib.bib92.3.1" class="ltx_text">.</span> 2009.

</span>
<span class="ltx_bibblock">Learning multiple layers of features from tiny images.

</span>
<span class="ltx_bibblock">(2009).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib93" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lai et al<span id="bib.bib93.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Jinrong Lai, Tong Wang, Chuan Chen, Yihao Li, and Zibin Zheng. 2023.

</span>
<span class="ltx_bibblock">VFedAD: A Defense Method Based on the Information Mechanism Behind the Vertical Federated Data Poisoning Attack. In <em id="bib.bib93.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 32nd ACM International Conference on Information and Knowledge Management</em>. 1148–1157.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib94" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">LeCun et al<span id="bib.bib94.2.2.1" class="ltx_text">.</span> (1998)</span>
<span class="ltx_bibblock">
Yann LeCun, Léon Bottou, Yoshua Bengio, and Patrick Haffner. 1998.

</span>
<span class="ltx_bibblock">Gradient-based learning applied to document recognition.

</span>
<span class="ltx_bibblock"><em id="bib.bib94.3.1" class="ltx_emph ltx_font_italic">Proc. IEEE</em> 86, 11 (1998), 2278–2324.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib95" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al<span id="bib.bib95.2.2.1" class="ltx_text">.</span> (2023a)</span>
<span class="ltx_bibblock">
Anran Li, Hongyi Peng, Lan Zhang, Jiahui Huang, Qing Guo, Han Yu, and Yang Liu. 2023a.

</span>
<span class="ltx_bibblock">Fedsdg-fs: Efficient and secure feature selection for vertical federated learning. In <em id="bib.bib95.3.1" class="ltx_emph ltx_font_italic">INFOCOM</em>. 1–10.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib96" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al<span id="bib.bib96.2.2.1" class="ltx_text">.</span> (2020b)</span>
<span class="ltx_bibblock">
Li Li, Yuxi Fan, Mike Tse, and Kuo-Yi Lin. 2020b.

</span>
<span class="ltx_bibblock">A review of applications in federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib96.3.1" class="ltx_emph ltx_font_italic">Computers &amp; Industrial Engineering</em> 149 (2020), 106854.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib97" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al<span id="bib.bib97.2.2.1" class="ltx_text">.</span> (2020a)</span>
<span class="ltx_bibblock">
Ming Li, Yiwei Chen, Yiqin Wang, and Yu Pan. 2020a.

</span>
<span class="ltx_bibblock">Efficient asynchronous vertical federated learning via gradient prediction and double-end sparse compression. In <em id="bib.bib97.3.1" class="ltx_emph ltx_font_italic">2020 16th international conference on control, automation, robotics and vision</em>. 291–296.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib98" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al<span id="bib.bib98.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Oscar Li, Jiankai Sun, Xin Yang, Weihao Gao, Hongyi Zhang, Junyuan Xie, Virginia Smith, and Chong Wang. 2021.

</span>
<span class="ltx_bibblock">Label leakage and protection in two-party split learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib98.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2102.08504</em> (2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib99" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al<span id="bib.bib99.2.2.1" class="ltx_text">.</span> (2023b)</span>
<span class="ltx_bibblock">
Qun Li, Chandra Thapa, Lawrence Ong, Yifeng Zheng, Hua Ma, Seyit A Camtepe, Anmin Fu, and Yansong Gao. 2023b.

</span>
<span class="ltx_bibblock">Vertical federated learning: Taxonomies, threats, and prospects.

</span>
<span class="ltx_bibblock"><em id="bib.bib99.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2302.01550</em> (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib100" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al<span id="bib.bib100.2.2.1" class="ltx_text">.</span> (2023c)</span>
<span class="ltx_bibblock">
Qinbin Li, Chulin Xie, Xiaojun Xu, Xiaoyuan Liu, Ce Zhang, Bo Li, Bingsheng He, and Dawn Song. 2023c.

</span>
<span class="ltx_bibblock">Effective and Efficient Federated Tree Learning on Hybrid Data.

</span>
<span class="ltx_bibblock"><em id="bib.bib100.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2310.11865</em> (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib101" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al<span id="bib.bib101.2.2.1" class="ltx_text">.</span> (2023d)</span>
<span class="ltx_bibblock">
Songze Li, Duanyi Yao, and Jin Liu. 2023d.

</span>
<span class="ltx_bibblock">Fedvs: Straggler-resilient and privacy-preserving vertical federated learning for split models. In <em id="bib.bib101.3.1" class="ltx_emph ltx_font_italic">ICML</em>. 20296–20311.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib102" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al<span id="bib.bib102.2.2.1" class="ltx_text">.</span> (2020c)</span>
<span class="ltx_bibblock">
Tian Li, Anit Kumar Sahu, Ameet Talwalkar, and Virginia Smith. 2020c.

</span>
<span class="ltx_bibblock">Federated learning: Challenges, methods, and future directions.

</span>
<span class="ltx_bibblock"><em id="bib.bib102.3.1" class="ltx_emph ltx_font_italic">IEEE signal processing magazine</em> 37, 3 (2020), 50–60.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib103" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al<span id="bib.bib103.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Xiaochen Li, Yuke Hu, Weiran Liu, Hanwen Feng, Li Peng, Yuan Hong, Kui Ren, and Zhan Qin. 2022.

</span>
<span class="ltx_bibblock">OpBoost: a vertical federated tree boosting framework based on order-preserving desensitization.

</span>
<span class="ltx_bibblock"><em id="bib.bib103.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2210.01318</em> (2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib104" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al<span id="bib.bib104.2.2.1" class="ltx_text">.</span> (2024)</span>
<span class="ltx_bibblock">
Yuecheng Li, Tong Wang, Chuan Chen, Jian Lou, Bin Chen, Lei Yang, and Zibin Zheng. 2024.

</span>
<span class="ltx_bibblock">Clients Collaborate: Flexible Differentially Private Federated Learning with Guaranteed Improvement of Utility-Privacy Trade-off.

</span>
<span class="ltx_bibblock"><em id="bib.bib104.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2402.07002</em> (2024).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib105" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liang and Chawathe (2004)</span>
<span class="ltx_bibblock">
Gang Liang and Sudarshan S Chawathe. 2004.

</span>
<span class="ltx_bibblock">Privacy-preserving inter-database operations. In <em id="bib.bib105.1.1" class="ltx_emph ltx_font_italic">International Conference on Intelligence and Security Informatics</em>. 66–82.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib106" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin (2021)</span>
<span class="ltx_bibblock">
Y Lin. 2021.

</span>
<span class="ltx_bibblock">The practice of federated learning in tencent wesee advertising.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib107" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al<span id="bib.bib107.2.2.1" class="ltx_text">.</span> (2021a)</span>
<span class="ltx_bibblock">
Bo Liu, Ming Ding, Sina Shaham, Wenny Rahayu, Farhad Farokhi, and Zihuai Lin. 2021a.

</span>
<span class="ltx_bibblock">When machine learning meets privacy: A survey and outlook.

</span>
<span class="ltx_bibblock"><em id="bib.bib107.3.1" class="ltx_emph ltx_font_italic">Comput. Surveys</em> 54, 2 (2021), 1–36.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib108" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al<span id="bib.bib108.2.2.1" class="ltx_text">.</span> (2021c)</span>
<span class="ltx_bibblock">
Changxin Liu, Zhenan Fan, Zirui Zhou, Yang Shi, Jian Pei, Lingyang Chu, and Yong Zhang. 2021c.

</span>
<span class="ltx_bibblock">Achieving model fairness in vertical federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib108.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2109.08344</em> (2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib109" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al<span id="bib.bib109.2.2.1" class="ltx_text">.</span> (2021e)</span>
<span class="ltx_bibblock">
Haizhou Liu, Xuan Zhang, Xinwei Shen, and Hongbin Sun. 2021e.

</span>
<span class="ltx_bibblock">A federated learning framework for smart grids: Securing power traces in collaborative learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib109.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2103.11870</em> (2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib110" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al<span id="bib.bib110.2.2.1" class="ltx_text">.</span> (2021d)</span>
<span class="ltx_bibblock">
Jing Liu, Chulin Xie, Krishnaram Kenthapadi, Sanmi Koyejo, and Bo Li. 2021d.

</span>
<span class="ltx_bibblock">Rvfr: Robust vertical federated learning via feature subspace recovery. In <em id="bib.bib110.3.1" class="ltx_emph ltx_font_italic">NeurIPS Workshop New Frontiers in Federated Learning: Privacy, Fairness, Robustness, Personalization and Data Ownership</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib111" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al<span id="bib.bib111.2.2.1" class="ltx_text">.</span> (2021b)</span>
<span class="ltx_bibblock">
Yang Liu, Tao Fan, Tianjian Chen, Qian Xu, and Qiang Yang. 2021b.

</span>
<span class="ltx_bibblock">Fate: An industrial grade platform for collaborative learning with data protection.

</span>
<span class="ltx_bibblock"><em id="bib.bib111.3.1" class="ltx_emph ltx_font_italic">JMLR</em> 22, 226 (2021), 1–6.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib112" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al<span id="bib.bib112.2.2.1" class="ltx_text">.</span> (2020a)</span>
<span class="ltx_bibblock">
Yang Liu, Yan Kang, Chaoping Xing, Tianjian Chen, and Qiang Yang. 2020a.

</span>
<span class="ltx_bibblock">A secure federated transfer learning framework.

</span>
<span class="ltx_bibblock"><em id="bib.bib112.3.1" class="ltx_emph ltx_font_italic">IEEE Intelligent Systems</em> 35, 4 (2020), 70–82.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib113" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al<span id="bib.bib113.2.2.1" class="ltx_text">.</span> (2024)</span>
<span class="ltx_bibblock">
Yang Liu, Yan Kang, Tianyuan Zou, Yanhong Pu, Yuanqin He, Xiaozhou Ye, Ye Ouyang, Ya-Qin Zhang, and Qiang Yang. 2024.

</span>
<span class="ltx_bibblock">Vertical Federated Learning: Concepts, Advances, and Challenges.

</span>
<span class="ltx_bibblock"><em id="bib.bib113.3.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Knowledge and Data Engineering</em> (2024).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib114" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al<span id="bib.bib114.2.2.1" class="ltx_text">.</span> (2020b)</span>
<span class="ltx_bibblock">
Yang Liu, Yingting Liu, Zhijie Liu, Yuxuan Liang, Chuishi Meng, Junbo Zhang, and Yu Zheng. 2020b.

</span>
<span class="ltx_bibblock">Federated forest.

</span>
<span class="ltx_bibblock"><em id="bib.bib114.3.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Big Data</em> 8, 3 (2020), 843–854.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib115" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al<span id="bib.bib115.2.2.1" class="ltx_text">.</span> (2020c)</span>
<span class="ltx_bibblock">
Yang Liu, Zhihao Yi, and Tianjian Chen. 2020c.

</span>
<span class="ltx_bibblock">Backdoor attacks and defenses in feature-partitioned collaborative learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib115.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2007.03608</em> (2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib116" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al<span id="bib.bib116.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Yang Liu, Xinwei Zhang, Yan Kang, Liping Li, Tianjian Chen, Mingyi Hong, and Qiang Yang. 2022.

</span>
<span class="ltx_bibblock">Fedbcd: A communication-efficient collaborative learning framework for distributed features.

</span>
<span class="ltx_bibblock"><em id="bib.bib116.3.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Signal Processing</em> 70 (2022), 4277–4290.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib117" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al<span id="bib.bib117.2.2.1" class="ltx_text">.</span> (2021f)</span>
<span class="ltx_bibblock">
Yang Liu, Tianyuan Zou, Yan Kang, Wenhan Liu, Yuanqin He, Zhihao Yi, and Qiang Yang. 2021f.

</span>
<span class="ltx_bibblock">Batch label inference and replacement attacks in black-boxed vertical federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib117.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2112.05409</em> (2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib118" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Long et al<span id="bib.bib118.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Guodong Long, Yue Tan, Jing Jiang, and Chengqi Zhang. 2020.

</span>
<span class="ltx_bibblock">Federated learning for open banking.

</span>
<span class="ltx_bibblock">In <em id="bib.bib118.3.1" class="ltx_emph ltx_font_italic">Federated Learning: Privacy and Incentive</em>. 240–254.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib119" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lu and Ding (2020)</span>
<span class="ltx_bibblock">
Linpeng Lu and Ning Ding. 2020.

</span>
<span class="ltx_bibblock">Multi-party private set intersection in vertical federated learning. In <em id="bib.bib119.1.1" class="ltx_emph ltx_font_italic">TrustCom</em>. 707–714.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib120" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lu et al<span id="bib.bib120.4.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Wen-jie Lu, Zhicong Huang, Qizhi Zhang, Yuchen Wang, and Cheng Hong. 2023.

</span>
<span class="ltx_bibblock">Squirrel: A Scalable Secure <math id="bib.bib120.1.m1.1" class="ltx_Math" alttext="\{" display="inline"><semantics id="bib.bib120.1.m1.1a"><mo stretchy="false" id="bib.bib120.1.m1.1.1" xref="bib.bib120.1.m1.1.1.cmml">{</mo><annotation-xml encoding="MathML-Content" id="bib.bib120.1.m1.1b"><ci id="bib.bib120.1.m1.1.1.cmml" xref="bib.bib120.1.m1.1.1">{</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib120.1.m1.1c">\{</annotation></semantics></math>Two-Party<math id="bib.bib120.2.m2.1" class="ltx_Math" alttext="\}" display="inline"><semantics id="bib.bib120.2.m2.1a"><mo stretchy="false" id="bib.bib120.2.m2.1.1" xref="bib.bib120.2.m2.1.1.cmml">}</mo><annotation-xml encoding="MathML-Content" id="bib.bib120.2.m2.1b"><ci id="bib.bib120.2.m2.1.1.cmml" xref="bib.bib120.2.m2.1.1">}</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib120.2.m2.1c">\}</annotation></semantics></math> Computation Framework for Training Gradient Boosting Decision Tree. In <em id="bib.bib120.5.1" class="ltx_emph ltx_font_italic">USENIX Security</em>. 6435–6451.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib121" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Luo et al<span id="bib.bib121.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Xinjian Luo, Yuncheng Wu, Xiaokui Xiao, and Beng Chin Ooi. 2021.

</span>
<span class="ltx_bibblock">Feature inference attack on model predictions in vertical federated learning. In <em id="bib.bib121.3.1" class="ltx_emph ltx_font_italic">ICDE</em>. 181–192.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib122" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mai and Pang (2023)</span>
<span class="ltx_bibblock">
Peihua Mai and Yan Pang. 2023.

</span>
<span class="ltx_bibblock">Vertical federated graph neural network for recommender system. In <em id="bib.bib122.1.1" class="ltx_emph ltx_font_italic">ICML</em>. 23516–23535.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib123" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mao et al<span id="bib.bib123.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Yunlong Mao, Zexi Xin, Zhenyu Li, Jue Hong, Yang Qingyou, and Sheng Zhong. 2022.

</span>
<span class="ltx_bibblock">Secure Split Learning against Property Inference and Data Reconstruction Attacks.

</span>
<span class="ltx_bibblock">(2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib124" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">May and Sell (2005)</span>
<span class="ltx_bibblock">
Christopher May and Susan K Sell. 2005.

</span>
<span class="ltx_bibblock"><em id="bib.bib124.1.1" class="ltx_emph ltx_font_italic">Intellectual property rights: A critical history</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib125" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">McMahan et al<span id="bib.bib125.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Aguera y Arcas. 2017.

</span>
<span class="ltx_bibblock">Communication-efficient learning of deep networks from decentralized data. In <em id="bib.bib125.3.1" class="ltx_emph ltx_font_italic">Artificial intelligence and statistics</em>. 1273–1282.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib126" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Meadows (1986)</span>
<span class="ltx_bibblock">
Catherine Meadows. 1986.

</span>
<span class="ltx_bibblock">A more efficient cryptographic matchmaking protocol for use in the absence of a continuously available third party. In <em id="bib.bib126.1.1" class="ltx_emph ltx_font_italic">1986 IEEE Symposium on Security and Privacy</em>. 134–134.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib127" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mitchell (1999)</span>
<span class="ltx_bibblock">
Tom M Mitchell. 1999.

</span>
<span class="ltx_bibblock">Machine learning and data mining.

</span>
<span class="ltx_bibblock"><em id="bib.bib127.1.1" class="ltx_emph ltx_font_italic">Commun. ACM</em> 42, 11 (1999), 30–36.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib128" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nguyen et al<span id="bib.bib128.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Dinh C Nguyen, Quoc-Viet Pham, Pubudu N Pathirana, Ming Ding, Aruna Seneviratne, Zihuai Lin, Octavia Dobre, and Won-Joo Hwang. 2022.

</span>
<span class="ltx_bibblock">Federated learning for smart healthcare: A survey.

</span>
<span class="ltx_bibblock"><em id="bib.bib128.3.1" class="ltx_emph ltx_font_italic">Comput. Surveys</em> 55, 3 (2022), 1–37.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib129" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ni et al<span id="bib.bib129.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Xiang Ni, Xiaolong Xu, Lingjuan Lyu, Changhua Meng, and Weiqiang Wang. 2021.

</span>
<span class="ltx_bibblock">A vertical federated learning framework for graph convolutional network.

</span>
<span class="ltx_bibblock"><em id="bib.bib129.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2106.11593</em> (2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib130" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Niknam et al<span id="bib.bib130.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Solmaz Niknam, Harpreet S Dhillon, and Jeffrey H Reed. 2020.

</span>
<span class="ltx_bibblock">Federated learning for wireless communications: Motivation, opportunities, and challenges.

</span>
<span class="ltx_bibblock"><em id="bib.bib130.3.1" class="ltx_emph ltx_font_italic">IEEE Communications Magazine</em> 58, 6 (2020), 46–51.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib131" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">of Investigators for Fairness in Trial Data Sharing (2016)</span>
<span class="ltx_bibblock">
International Consortium of Investigators for Fairness in Trial Data Sharing. 2016.

</span>
<span class="ltx_bibblock">Toward fairness in data sharing.

</span>
<span class="ltx_bibblock"><em id="bib.bib131.1.1" class="ltx_emph ltx_font_italic">New England Journal of Medicine</em> 375, 5 (2016), 405–407.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib132" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pfeiffer et al<span id="bib.bib132.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Kilian Pfeiffer, Martin Rapp, Ramin Khalili, and Jörg Henkel. 2023.

</span>
<span class="ltx_bibblock">Federated learning for computationally constrained heterogeneous devices: A survey.

</span>
<span class="ltx_bibblock"><em id="bib.bib132.3.1" class="ltx_emph ltx_font_italic">Comput. Surveys</em> 55, 14s (2023), 1–27.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib133" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pinkas et al<span id="bib.bib133.2.2.1" class="ltx_text">.</span> (2015)</span>
<span class="ltx_bibblock">
Benny Pinkas, Thomas Schneider, Gil Segev, and Michael Zohner. 2015.

</span>
<span class="ltx_bibblock">Phasing: Private set intersection using permutation-based hashing. In <em id="bib.bib133.3.1" class="ltx_emph ltx_font_italic">USENIX Security</em>. 515–530.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib134" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pinkas et al<span id="bib.bib134.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Benny Pinkas, Thomas Schneider, and Michael Zohner. 2018.

</span>
<span class="ltx_bibblock">Scalable private set intersection based on OT extension.

</span>
<span class="ltx_bibblock"><em id="bib.bib134.3.1" class="ltx_emph ltx_font_italic">ACM Transactions on Privacy and Security</em> 21, 2 (2018), 1–35.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib135" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Qi et al<span id="bib.bib135.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Tao Qi, Fangzhao Wu, Chuhan Wu, Lingjuan Lyu, Tong Xu, Hao Liao, Zhongliang Yang, Yongfeng Huang, and Xing Xie. 2022.

</span>
<span class="ltx_bibblock">Fairvfl: A fair vertical federated learning framework with contrastive adversarial learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib135.3.1" class="ltx_emph ltx_font_italic">NeurIPS</em> 35 (2022), 7852–7865.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib136" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Qiu et al<span id="bib.bib136.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Pengyu Qiu, Xuhong Zhang, Shouling Ji, Tianyu Du, Yuwen Pu, Jun Zhou, and Ting Wang. 2022.

</span>
<span class="ltx_bibblock">Your labels are selling you out: Relation leaks in vertical federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib136.3.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Dependable and Secure Computing</em> (2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib137" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Qiu et al<span id="bib.bib137.2.2.1" class="ltx_text">.</span> (2024a)</span>
<span class="ltx_bibblock">
Pengyu Qiu, Xuhong Zhang, Shouling Ji, Chong Fu, Xing Yang, and Ting Wang. 2024a.

</span>
<span class="ltx_bibblock">HashVFL: Defending Against Data Reconstruction Attacks in Vertical Federated Learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib137.3.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Information Forensics and Security</em> (2024).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib138" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Qiu et al<span id="bib.bib138.2.2.1" class="ltx_text">.</span> (2024b)</span>
<span class="ltx_bibblock">
Pengyu Qiu, Xuhong Zhang, Shouling Ji, Changjiang Li, Yuwen Pu, Xing Yang, and Ting Wang. 2024b.

</span>
<span class="ltx_bibblock">Hijack Vertical Federated Learning Models As One Party.

</span>
<span class="ltx_bibblock"><em id="bib.bib138.3.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Dependable and Secure Computing</em> (2024).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib139" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Qiu et al<span id="bib.bib139.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Xinchi Qiu, Heng Pan, Wanru Zhao, Chenyang Ma, Pedro PB Gusmao, and Nicholas D Lane. 2023.

</span>
<span class="ltx_bibblock">vfedsec: Efficient secure aggregation for vertical federated learning via secure layer.

</span>
<span class="ltx_bibblock"><em id="bib.bib139.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2305.16794</em> (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib140" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Qu et al<span id="bib.bib140.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Youyang Qu, Md Palash Uddin, Chenquan Gan, Yong Xiang, Longxiang Gao, and John Yearwood. 2022.

</span>
<span class="ltx_bibblock">Blockchain-enabled federated learning: A survey.

</span>
<span class="ltx_bibblock"><em id="bib.bib140.3.1" class="ltx_emph ltx_font_italic">Comput. Surveys</em> 55, 4 (2022), 1–35.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib141" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Radford et al<span id="bib.bib141.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et al<span id="bib.bib141.3.1" class="ltx_text">.</span> 2019.

</span>
<span class="ltx_bibblock">Language models are unsupervised multitask learners.

</span>
<span class="ltx_bibblock"><em id="bib.bib141.4.1" class="ltx_emph ltx_font_italic">OpenAI blog</em> 1, 8 (2019), 9.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib142" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rassouli et al<span id="bib.bib142.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Borzoo Rassouli, Morteza Varasteh, and Deniz Gunduz. 2022.

</span>
<span class="ltx_bibblock">Privacy against inference attacks in vertical federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib142.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2207.11788</em> (2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib143" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Romanini et al<span id="bib.bib143.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Daniele Romanini, Adam James Hall, Pavlos Papadopoulos, Tom Titcombe, Abbas Ismail, Tudor Cebere, Robert Sandmann, Robin Roehm, and Michael A Hoeh. 2021.

</span>
<span class="ltx_bibblock">Pyvertical: A vertical federated learning framework for multi-headed splitnn.

</span>
<span class="ltx_bibblock"><em id="bib.bib143.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2104.00489</em> (2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib144" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rooijakkers (2020)</span>
<span class="ltx_bibblock">
Thomas Rooijakkers. 2020.

</span>
<span class="ltx_bibblock">CONVINCED—Enabling privacy-preserving survival analyses using Multi-Party Computation.

</span>
<span class="ltx_bibblock">(2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib145" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Saha and Ahmad (2021)</span>
<span class="ltx_bibblock">
Sudipan Saha and Tahir Ahmad. 2021.

</span>
<span class="ltx_bibblock">Federated transfer learning: concept and applications.

</span>
<span class="ltx_bibblock"><em id="bib.bib145.1.1" class="ltx_emph ltx_font_italic">Intelligenza Artificiale</em> 15, 1 (2021), 35–44.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib146" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Salehzadeh Niksirat et al<span id="bib.bib146.2.2.1" class="ltx_text">.</span> (2024)</span>
<span class="ltx_bibblock">
Kavous Salehzadeh Niksirat, Lev Velykoivanenko, Noé Zufferey, Mauro Cherubini, Kévin Huguenin, and Mathias Humbert. 2024.

</span>
<span class="ltx_bibblock">Wearable activity trackers: A survey on utility, privacy, and security.

</span>
<span class="ltx_bibblock"><em id="bib.bib146.3.1" class="ltx_emph ltx_font_italic">Comput. Surveys</em> 56, 7 (2024), 1–40.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib147" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shang et al<span id="bib.bib147.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Xinyi Shang, Yang Lu, Gang Huang, and Hanzi Wang. 2022.

</span>
<span class="ltx_bibblock">Federated learning on heterogeneous and long-tailed data via classifier re-training with federated features.

</span>
<span class="ltx_bibblock"><em id="bib.bib147.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2204.13399</em> (2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib148" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shi et al<span id="bib.bib148.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Haoran Shi, Yonghui Xu, Yali Jiang, Han Yu, and Lizhen Cui. 2022.

</span>
<span class="ltx_bibblock">Efficient Asynchronous Multi-Participant Vertical Federated Learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib148.3.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Big Data</em> (2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib149" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Song et al<span id="bib.bib149.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Yong Song, Yuchen Xie, Hongwei Zhang, Yuxin Liang, Xiaozhou Ye, Aidong Yang, and Ye Ouyang. 2021.

</span>
<span class="ltx_bibblock">Federated learning application on telecommunication-joint healthcare recommendation. In <em id="bib.bib149.3.1" class="ltx_emph ltx_font_italic">2021 IEEE 21st International Conference on Communication Technology (ICCT)</em>. 1443–1448.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib150" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Street et al<span id="bib.bib150.2.2.1" class="ltx_text">.</span> (1993)</span>
<span class="ltx_bibblock">
W Nick Street, William H Wolberg, and Olvi L Mangasarian. 1993.

</span>
<span class="ltx_bibblock">Nuclear feature extraction for breast tumor diagnosis. In <em id="bib.bib150.3.1" class="ltx_emph ltx_font_italic">Biomedical image processing and biomedical visualization</em>, Vol. 1905. 861–870.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib151" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sun et al<span id="bib.bib151.2.2.1" class="ltx_text">.</span> (2023a)</span>
<span class="ltx_bibblock">
Jingwei Sun, Zhixu Du, Anna Dai, Saleh Baghersalimi, Alireza Amirshahi, David Atienza, and Yiran Chen. 2023a.

</span>
<span class="ltx_bibblock">Robust and ip-protecting vertical federated learning against unexpected quitting of parties.

</span>
<span class="ltx_bibblock"><em id="bib.bib151.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2303.18178</em> (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib152" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sun et al<span id="bib.bib152.2.2.1" class="ltx_text">.</span> (2023b)</span>
<span class="ltx_bibblock">
Jingwei Sun, Ziyue Xu, Dong Yang, Vishwesh Nath, Wenqi Li, Can Zhao, Daguang Xu, Yiran Chen, and Holger R Roth. 2023b.

</span>
<span class="ltx_bibblock">Communication-efficient vertical federated learning with limited overlapping samples. In <em id="bib.bib152.3.1" class="ltx_emph ltx_font_italic">ICCV</em>. 5203–5212.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib153" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sun et al<span id="bib.bib153.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Jiankai Sun, Xin Yang, Yuanshun Yao, and Chong Wang. 2022.

</span>
<span class="ltx_bibblock">Label leakage and protection from forward embedding in vertical federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib153.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2203.01451</em> (2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib154" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sun et al<span id="bib.bib154.2.2.1" class="ltx_text">.</span> (2021a)</span>
<span class="ltx_bibblock">
Jiankai Sun, Xin Yang, Yuanshun Yao, Aonan Zhang, Weihao Gao, Junyuan Xie, and Chong Wang. 2021a.

</span>
<span class="ltx_bibblock">Vertical federated learning without revealing intersection membership.

</span>
<span class="ltx_bibblock"><em id="bib.bib154.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2106.05508</em> (2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib155" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sun et al<span id="bib.bib155.2.2.1" class="ltx_text">.</span> (2021b)</span>
<span class="ltx_bibblock">
Jiankai Sun, Yuanshun Yao, Weihao Gao, Junyuan Xie, and Chong Wang. 2021b.

</span>
<span class="ltx_bibblock">Defending against reconstruction attack in vertical federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib155.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2107.09898</em> (2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib156" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Takahashi et al<span id="bib.bib156.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Hideaki Takahashi, Jingjing Liu, and Yang Liu. 2023.

</span>
<span class="ltx_bibblock">Eliminating Label Leakage in Tree-Based Vertical Federated Learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib156.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2307.10318</em> (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib157" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Teimoori et al<span id="bib.bib157.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Zeinab Teimoori, Abdulsalam Yassine, and M Shamim Hossain. 2022.

</span>
<span class="ltx_bibblock">A secure cloudlet-based charging station recommendation for electric vehicles empowered by federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib157.3.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Industrial Informatics</em> 18, 9 (2022), 6464–6473.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib158" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tian et al<span id="bib.bib158.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Zhihua Tian, Rui Zhang, Xiaoyang Hou, Jian Liu, and Kui Ren. 2020.

</span>
<span class="ltx_bibblock">Federboost: Private federated learning for gbdt.

</span>
<span class="ltx_bibblock"><em id="bib.bib158.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2011.02796</em> (2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib159" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Touvron et al<span id="bib.bib159.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, et al<span id="bib.bib159.3.1" class="ltx_text">.</span> 2023.

</span>
<span class="ltx_bibblock">Llama: Open and efficient foundation language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib159.4.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2302.13971</em> (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib160" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tran et al<span id="bib.bib160.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Linh Tran, Timothy Castiglia, Stacy Patterson, and Ana Milanova. 2023.

</span>
<span class="ltx_bibblock">Privacy Tradeoffs in Vertical Federated Learning. In <em id="bib.bib160.3.1" class="ltx_emph ltx_font_italic">Federated Learning Systems Workshop@ MLSys 2023</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib161" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wagner and Eckhoff (2018)</span>
<span class="ltx_bibblock">
Isabel Wagner and David Eckhoff. 2018.

</span>
<span class="ltx_bibblock">Technical privacy metrics: a systematic survey.

</span>
<span class="ltx_bibblock"><em id="bib.bib161.1.1" class="ltx_emph ltx_font_italic">Comput. Surveys</em> 51, 3 (2018), 1–38.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib162" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al<span id="bib.bib162.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Chang Wang, Jian Liang, Mingkai Huang, Bing Bai, Kun Bai, and Hao Li. 2020.

</span>
<span class="ltx_bibblock">Hybrid differentially private federated learning on vertically partitioned data.

</span>
<span class="ltx_bibblock"><em id="bib.bib162.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2009.02763</em> (2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib163" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al<span id="bib.bib163.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Guan Wang, Charlie Xiaoqian Dang, and Ziye Zhou. 2019.

</span>
<span class="ltx_bibblock">Measure contribution of participants in federated learning. In <em id="bib.bib163.3.1" class="ltx_emph ltx_font_italic">2019 IEEE international conference on big data (Big Data)</em>. 2597–2604.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib164" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al<span id="bib.bib164.2.2.1" class="ltx_text">.</span> (2024)</span>
<span class="ltx_bibblock">
Ganyu Wang, Bin Gu, Qingsong Zhang, Xiang Li, Boyu Wang, and Charles X Ling. 2024.

</span>
<span class="ltx_bibblock">A Unified Solution for Privacy and Communication Efficiency in Vertical Federated Learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib164.3.1" class="ltx_emph ltx_font_italic">NeurIPS</em> 36 (2024).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib165" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al<span id="bib.bib165.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Yilei Wang, Qingzhe Lv, Huang Zhang, Minghao Zhao, Yuhong Sun, Lingkai Ran, and Tao Li. 2023.

</span>
<span class="ltx_bibblock">Beyond model splitting: Preventing label inference attacks in vertical federated learning with dispersed training.

</span>
<span class="ltx_bibblock"><em id="bib.bib165.3.1" class="ltx_emph ltx_font_italic">World Wide Web</em> 26, 5 (2023), 2691–2707.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib166" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wei et al<span id="bib.bib166.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Kang Wei, Jun Li, Chuan Ma, Ming Ding, Sha Wei, Fan Wu, Guihai Chen, and Thilina Ranbaduge. 2022.

</span>
<span class="ltx_bibblock">Vertical federated learning: Challenges, methodologies and experiments.

</span>
<span class="ltx_bibblock"><em id="bib.bib166.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2202.04309</em> (2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib167" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wei et al<span id="bib.bib167.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Penghui Wei, Hongjian Dou, Shaoguo Liu, Rongjun Tang, Li Liu, Liang Wang, and Bo Zheng. 2023.

</span>
<span class="ltx_bibblock">Fedads: A benchmark for privacy-preserving cvr estimation with vertical federated learning. In <em id="bib.bib167.3.1" class="ltx_emph ltx_font_italic">SIGIR</em>. 3037–3046.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib168" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu et al<span id="bib.bib168.2.2.1" class="ltx_text">.</span> (2023a)</span>
<span class="ltx_bibblock">
Jiajun Wu, Fan Dong, Henry Leung, Zhuangdi Zhu, Jiayu Zhou, and Steve Drew. 2023a.

</span>
<span class="ltx_bibblock">Topology-aware federated learning in edge computing: A comprehensive survey.

</span>
<span class="ltx_bibblock"><em id="bib.bib168.3.1" class="ltx_emph ltx_font_italic">Comput. Surveys</em> (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib169" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu et al<span id="bib.bib169.2.2.1" class="ltx_text">.</span> (2023d)</span>
<span class="ltx_bibblock">
Ruofan Wu, Mingyang Zhang, Lingjuan Lyu, Xiaolong Xu, Xiuquan Hao, Xinyi Fu, Tengfei Liu, Tianyi Zhang, and Weiqiang Wang. 2023d.

</span>
<span class="ltx_bibblock">Privacy-preserving design of graph neural networks with applications to vertical federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib169.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2310.20552</em> (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib170" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu et al<span id="bib.bib170.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Yuncheng Wu, Shaofeng Cai, Xiaokui Xiao, Gang Chen, and Beng Chin Ooi. 2020.

</span>
<span class="ltx_bibblock">Privacy preserving vertical federated learning for tree-based models.

</span>
<span class="ltx_bibblock"><em id="bib.bib170.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2008.06170</em> (2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib171" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu et al<span id="bib.bib171.2.2.1" class="ltx_text">.</span> (2023c)</span>
<span class="ltx_bibblock">
Yuncheng Wu, Naili Xing, Gang Chen, Tien Tuan Anh Dinh, Zhaojing Luo, Beng Chin Ooi, Xiaokui Xiao, and Meihui Zhang. 2023c.

</span>
<span class="ltx_bibblock">Falcon: A Privacy-Preserving and Interpretable Vertical Federated Learning System.

</span>
<span class="ltx_bibblock"><em id="bib.bib171.3.1" class="ltx_emph ltx_font_italic">Proceedings of the VLDB Endowment</em> 16, 10 (2023), 2471–2484.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib172" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu et al<span id="bib.bib172.2.2.1" class="ltx_text">.</span> (2023b)</span>
<span class="ltx_bibblock">
Zhaomin Wu, Junyi Hou, and Bingsheng He. 2023b.

</span>
<span class="ltx_bibblock">Vertibench: Advancing feature distribution diversity in vertical federated learning benchmarks.

</span>
<span class="ltx_bibblock"><em id="bib.bib172.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2307.02040</em> (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib173" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu et al<span id="bib.bib173.2.2.1" class="ltx_text">.</span> (2022a)</span>
<span class="ltx_bibblock">
Zhaomin Wu, Qinbin Li, and Bingsheng He. 2022a.

</span>
<span class="ltx_bibblock">A coupled design of exploiting record similarity for practical vertical federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib173.3.1" class="ltx_emph ltx_font_italic">NeurIPS</em> 35 (2022), 21087–21100.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib174" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu et al<span id="bib.bib174.2.2.1" class="ltx_text">.</span> (2022b)</span>
<span class="ltx_bibblock">
Zhaomin Wu, Qinbin Li, and Bingsheng He. 2022b.

</span>
<span class="ltx_bibblock">Practical vertical federated learning with unsupervised representation learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib174.3.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Big Data</em> (2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib175" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu et al<span id="bib.bib175.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Runhua Xu, Nathalie Baracaldo, Yi Zhou, Annie Abay, and Ali Anwar. 2022.

</span>
<span class="ltx_bibblock">Privacy-preserving vertical federated learning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib175.3.1" class="ltx_emph ltx_font_italic">Federated Learning: A Comprehensive Overview of Methods and Applications</em>. 417–438.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib176" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu et al<span id="bib.bib176.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Runhua Xu, Nathalie Baracaldo, Yi Zhou, Ali Anwar, James Joshi, and Heiko Ludwig. 2021.

</span>
<span class="ltx_bibblock">Fedv: Privacy-preserving federated learning over vertically partitioned data. In <em id="bib.bib176.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 14th ACM workshop on artificial intelligence and security</em>. 181–192.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib177" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xuan et al<span id="bib.bib177.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Yuexin Xuan, Xiaojun Chen, Zhendong Zhao, Bisheng Tang, and Ye Dong. 2023.

</span>
<span class="ltx_bibblock">Practical and general backdoor attacks against vertical federated learning. In <em id="bib.bib177.3.1" class="ltx_emph ltx_font_italic">Joint European Conference on Machine Learning and Knowledge Discovery in Databases</em>. 402–417.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib178" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yan et al<span id="bib.bib178.2.2.1" class="ltx_text">.</span> (2024)</span>
<span class="ltx_bibblock">
Yunlu Yan, Hong Wang, Yawen Huang, Nanjun He, Lei Zhu, Yong Xu, Yuexiang Li, and Yefeng Zheng. 2024.

</span>
<span class="ltx_bibblock">Cross-modal vertical federated learning for mri reconstruction.

</span>
<span class="ltx_bibblock"><em id="bib.bib178.3.1" class="ltx_emph ltx_font_italic">IEEE Journal of Biomedical and Health Informatics</em> (2024).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib179" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et al<span id="bib.bib179.2.2.1" class="ltx_text">.</span> (2023a)</span>
<span class="ltx_bibblock">
Liu Yang, Di Chai, Junxue Zhang, Yilun Jin, Leye Wang, Hao Liu, Han Tian, Qian Xu, and Kai Chen. 2023a.

</span>
<span class="ltx_bibblock">A survey on vertical federated learning: From a layered perspective.

</span>
<span class="ltx_bibblock"><em id="bib.bib179.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2304.01829</em> (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib180" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et al<span id="bib.bib180.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Qiang Yang, Yang Liu, Tianjian Chen, and Yongxin Tong. 2019.

</span>
<span class="ltx_bibblock">Federated machine learning: Concept and applications.

</span>
<span class="ltx_bibblock"><em id="bib.bib180.3.1" class="ltx_emph ltx_font_italic">ACM Transactions on Intelligent Systems and Technology</em> 10, 2 (2019), 1–19.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib181" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et al<span id="bib.bib181.2.2.1" class="ltx_text">.</span> (2023c)</span>
<span class="ltx_bibblock">
Ruikang Yang, Jianfeng Ma, Junying Zhang, Saru Kumari, Sachin Kumar, and Joel JPC Rodrigues. 2023c.

</span>
<span class="ltx_bibblock">Practical feature inference attack in vertical federated learning during prediction in artificial internet of things.

</span>
<span class="ltx_bibblock"><em id="bib.bib181.3.1" class="ltx_emph ltx_font_italic">IEEE Internet of Things Journal</em> (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib182" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et al<span id="bib.bib182.2.2.1" class="ltx_text">.</span> (2023b)</span>
<span class="ltx_bibblock">
Xiyuan Yang, Wenke Huang, and Mang Ye. 2023b.

</span>
<span class="ltx_bibblock">Dynamic personalized federated learning with adaptive differential privacy.

</span>
<span class="ltx_bibblock"><em id="bib.bib182.3.1" class="ltx_emph ltx_font_italic">NeurIPS</em> 36 (2023), 72181–72192.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib183" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et al<span id="bib.bib183.2.2.1" class="ltx_text">.</span> (2022a)</span>
<span class="ltx_bibblock">
Xin Yang, Jiankai Sun, Yuanshun Yao, Junyuan Xie, and Chong Wang. 2022a.

</span>
<span class="ltx_bibblock">Differentially private label protection in split learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib183.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2203.02073</em> (2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib184" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et al<span id="bib.bib184.2.2.1" class="ltx_text">.</span> (2022b)</span>
<span class="ltx_bibblock">
Yitao Yang, Xiucai Ye, and Tetsuya Sakurai. 2022b.

</span>
<span class="ltx_bibblock">Multi-view federated learning with data collaboration. In <em id="bib.bib184.3.1" class="ltx_emph ltx_font_italic">ICMLC</em>. 178–183.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib185" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yao et al<span id="bib.bib185.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Houpu Yao, Jiazhou Wang, Peng Dai, Liefeng Bo, and Yanqing Chen. 2022.

</span>
<span class="ltx_bibblock">An efficient and robust system for vertically federated random forest.

</span>
<span class="ltx_bibblock"><em id="bib.bib185.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2201.10761</em> (2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib186" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ye et al<span id="bib.bib186.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Mang Ye, Xiuwen Fang, Bo Du, Pong C Yuen, and Dacheng Tao. 2023.

</span>
<span class="ltx_bibblock">Heterogeneous federated learning: State-of-the-art and research challenges.

</span>
<span class="ltx_bibblock"><em id="bib.bib186.3.1" class="ltx_emph ltx_font_italic">Comput. Surveys</em> 56, 3 (2023), 1–44.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib187" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ye et al<span id="bib.bib187.2.2.1" class="ltx_text">.</span> (2024)</span>
<span class="ltx_bibblock">
Mang Ye, Wei Shen, Junwu Zhang, Yao Yang, and Bo Du. 2024.

</span>
<span class="ltx_bibblock">Securereid: Privacy-preserving anonymization for person re-identification.

</span>
<span class="ltx_bibblock"><em id="bib.bib187.3.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Information Forensics and Security</em> (2024).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib188" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ye et al<span id="bib.bib188.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Peng Ye, Zhifeng Jiang, Wei Wang, Bo Li, and Baochun Li. 2022.

</span>
<span class="ltx_bibblock">Feature reconstruction attacks and countermeasures of dnn training in vertical federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib188.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2210.06771</em> (2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib189" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yin et al<span id="bib.bib189.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Xuefei Yin, Yanming Zhu, and Jiankun Hu. 2021.

</span>
<span class="ltx_bibblock">A comprehensive survey of privacy-preserving federated learning: A taxonomy, review, and future directions.

</span>
<span class="ltx_bibblock"><em id="bib.bib189.3.1" class="ltx_emph ltx_font_italic">Comput. Surveys</em> 54, 6 (2021), 1–36.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib190" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu et al<span id="bib.bib190.2.2.1" class="ltx_text">.</span> (2024)</span>
<span class="ltx_bibblock">
Lei Yu, Meng Han, Yiming Li, Changting Lin, Yao Zhang, Mingyang Zhang, Yan Liu, Haiqin Weng, Yuseok Jeon, Ka-Ho Chow, et al<span id="bib.bib190.3.1" class="ltx_text">.</span> 2024.

</span>
<span class="ltx_bibblock">A Survey of Privacy Threats and Defense in Vertical Federated Learning: From Model Life Cycle Perspective.

</span>
<span class="ltx_bibblock"><em id="bib.bib190.4.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2402.03688</em> (2024).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib191" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu et al<span id="bib.bib191.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Sixing Yu, J Pablo Muñoz, and Ali Jannesari. 2023.

</span>
<span class="ltx_bibblock">Federated foundation models: Privacy-preserving and collaborative learning for large models.

</span>
<span class="ltx_bibblock"><em id="bib.bib191.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2305.11414</em> (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib192" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yuan et al<span id="bib.bib192.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Haochen Yuan, Chao Ma, Zhenxiang Zhao, Xiaofei Xu, and Zhongjie Wang. 2022.

</span>
<span class="ltx_bibblock">A privacy-preserving oriented service recommendation approach based on personal data cloud and federated learning. In <em id="bib.bib192.3.1" class="ltx_emph ltx_font_italic">2022 IEEE International Conference on Web Services</em>. 322–330.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib193" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yuan et al<span id="bib.bib193.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Lu Yuan, Dongdong Chen, Yi-Ling Chen, Noel Codella, Xiyang Dai, Jianfeng Gao, Houdong Hu, Xuedong Huang, Boxin Li, Chunyuan Li, et al<span id="bib.bib193.3.1" class="ltx_text">.</span> 2021.

</span>
<span class="ltx_bibblock">Florence: A new foundation model for computer vision.

</span>
<span class="ltx_bibblock"><em id="bib.bib193.4.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2111.11432</em> (2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib194" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang and Jiang (2021)</span>
<span class="ltx_bibblock">
JianFei Zhang and YuChen Jiang. 2021.

</span>
<span class="ltx_bibblock">A vertical federation recommendation method based on clustering and latent factor model. In <em id="bib.bib194.1.1" class="ltx_emph ltx_font_italic">2021 International Conference on Electronic Information Engineering and Computer Science</em>. 362–366.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib195" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al<span id="bib.bib195.2.2.1" class="ltx_text">.</span> (2021b)</span>
<span class="ltx_bibblock">
Qingsong Zhang, Bin Gu, Cheng Deng, Songxiang Gu, Liefeng Bo, Jian Pei, and Heng Huang. 2021b.

</span>
<span class="ltx_bibblock">Asysqn: Faster vertical federated learning algorithms with better computation resource utilization. In <em id="bib.bib195.3.1" class="ltx_emph ltx_font_italic">SIGKDD</em>. 3917–3927.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib196" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al<span id="bib.bib196.2.2.1" class="ltx_text">.</span> (2021a)</span>
<span class="ltx_bibblock">
Qingsong Zhang, Bin Gu, Cheng Deng, and Heng Huang. 2021a.

</span>
<span class="ltx_bibblock">Secure bilevel asynchronous vertical federated learning with backward updating. In <em id="bib.bib196.3.1" class="ltx_emph ltx_font_italic">AAAI</em>, Vol. 35. 10896–10904.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib197" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al<span id="bib.bib197.2.2.1" class="ltx_text">.</span> (2022b)</span>
<span class="ltx_bibblock">
Rui Zhang, Hongwei Li, Meng Hao, Hanxiao Chen, and Yuan Zhang. 2022b.

</span>
<span class="ltx_bibblock">Secure feature selection for vertical federated learning in ehealth systems. In <em id="bib.bib197.3.1" class="ltx_emph ltx_font_italic">ICC 2022-IEEE International Conference on Communications</em>. 1257–1262.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib198" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al<span id="bib.bib198.2.2.1" class="ltx_text">.</span> (2022a)</span>
<span class="ltx_bibblock">
Xiaojin Zhang, Hanlin Gu, Lixin Fan, Kai Chen, and Qiang Yang. 2022a.

</span>
<span class="ltx_bibblock">No free lunch theorem for security and utility in federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib198.3.1" class="ltx_emph ltx_font_italic">ACM Transactions on Intelligent Systems and Technology</em> 14, 1 (2022), 1–35.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib199" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al<span id="bib.bib199.2.2.1" class="ltx_text">.</span> (2023a)</span>
<span class="ltx_bibblock">
Xinwei Zhang, Mingyi Hong, and Jie Chen. 2023a.

</span>
<span class="ltx_bibblock">Glasu: A communication-efficient algorithm for federated learning with vertically distributed graph data.

</span>
<span class="ltx_bibblock"><em id="bib.bib199.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2303.09531</em> (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib200" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al<span id="bib.bib200.2.2.1" class="ltx_text">.</span> (2023c)</span>
<span class="ltx_bibblock">
Xiaojin Zhang, Yan Kang, Kai Chen, Lixin Fan, and Qiang Yang. 2023c.

</span>
<span class="ltx_bibblock">Trading Off Privacy, Utility, and Efficiency in Federated Learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib200.3.1" class="ltx_emph ltx_font_italic">ACM Transactions on Intelligent Systems and Technology</em> 14, 6 (2023), 1–32.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib201" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al<span id="bib.bib201.2.2.1" class="ltx_text">.</span> (2023b)</span>
<span class="ltx_bibblock">
Yong Zhang, Ying Hu, Xiaozhi Gao, Dunwei Gong, Yinan Guo, Kaizhou Gao, and Wanqiu Zhang. 2023b.

</span>
<span class="ltx_bibblock">An embedded vertical-federated feature selection algorithm based on particle swarm optimisation.

</span>
<span class="ltx_bibblock"><em id="bib.bib201.3.1" class="ltx_emph ltx_font_italic">CAAI Transactions on Intelligence Technology</em> 8, 3 (2023), 734–754.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib202" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al<span id="bib.bib202.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Yirun Zhang, Qirui Wu, and Mohammad Shikh-Bahaei. 2020.

</span>
<span class="ltx_bibblock">Vertical federated learning based privacy-preserving cooperative sensing in cognitive radio networks. In <em id="bib.bib202.3.1" class="ltx_emph ltx_font_italic">2020 IEEE Globecom Workshops</em>. 1–6.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib203" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao et al<span id="bib.bib203.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Jianzhe Zhao, Jiayi Wang, Zhaocheng Li, Weiting Yuan, and Stan Matwin. 2022.

</span>
<span class="ltx_bibblock">Vertically Federated Learning with Correlated Differential Privacy.

</span>
<span class="ltx_bibblock"><em id="bib.bib203.3.1" class="ltx_emph ltx_font_italic">Electronics</em> 11, 23 (2022), 3958.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib204" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zheng (2023)</span>
<span class="ltx_bibblock">
Fei Zheng. 2023.

</span>
<span class="ltx_bibblock">Input reconstruction attack against vertical federated large language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib204.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2311.07585</em> (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib205" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zheng et al<span id="bib.bib205.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Fei Zheng, Chaochao Chen, Binhui Yao, and Xiaolin Zheng. 2022.

</span>
<span class="ltx_bibblock">Making split learning resilient to label leakage by potential energy loss.

</span>
<span class="ltx_bibblock"><em id="bib.bib205.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2210.09617</em> (2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib206" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zheng et al<span id="bib.bib206.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Fanglan Zheng, Kun Li, Jiang Tian, Xiaojia Xiang, et al<span id="bib.bib206.3.1" class="ltx_text">.</span> 2020.

</span>
<span class="ltx_bibblock">A vertical federated learning method for interpretable scorecard and its application in credit scoring.

</span>
<span class="ltx_bibblock"><em id="bib.bib206.4.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2009.06218</em> (2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib207" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhu et al<span id="bib.bib207.2.2.1" class="ltx_text">.</span> (2024)</span>
<span class="ltx_bibblock">
Derui Zhu, Jinfu Chen, Xuebing Zhou, Weiyi Shang, Ahmed E Hassan, and Jens Grossklags. 2024.

</span>
<span class="ltx_bibblock">Vulnerabilities of Data Protection in Vertical Federated Learning Training and Countermeasures.

</span>
<span class="ltx_bibblock"><em id="bib.bib207.3.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Information Forensics and Security</em> (2024).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib208" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhuang et al<span id="bib.bib208.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Weiming Zhuang, Chen Chen, and Lingjuan Lyu. 2023.

</span>
<span class="ltx_bibblock">When foundation model meets federated learning: Motivations, challenges, and future directions.

</span>
<span class="ltx_bibblock"><em id="bib.bib208.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2306.15546</em> (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib209" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zou et al<span id="bib.bib209.2.2.1" class="ltx_text">.</span> (2024)</span>
<span class="ltx_bibblock">
Tianyuan Zou, Zixuan Gu, Yu He, Hideaki Takahashi, Yang Liu, Guangnan Ye, and Ya-Qin Zhang. 2024.

</span>
<span class="ltx_bibblock">VFLAIR: A Research Library and Benchmark for Vertical Federated Learning. In <em id="bib.bib209.3.1" class="ltx_emph ltx_font_italic">ICLR</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib210" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zou et al<span id="bib.bib210.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Tianyuan Zou, Yang Liu, Yan Kang, Wenhan Liu, Yuanqin He, Zhihao Yi, Qiang Yang, and Ya-Qin Zhang. 2022.

</span>
<span class="ltx_bibblock">Defending Batch-Level Label Inference and Replacement Attacks in Vertical Federated Learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib210.3.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Big Data</em> (2022), 1–12.

</span>
<span class="ltx_bibblock">
</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<section id="A1" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Appendix</h2>

<figure id="A1.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering" style="font-size:80%;"><span class="ltx_tag ltx_tag_table">Table 1. </span><span id="A1.T1.5.1" class="ltx_text ltx_font_bold">Works on Model Design.</span></figcaption>
<table id="A1.T1.2" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="A1.T1.2.2" class="ltx_tr">
<td id="A1.T1.2.2.3" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="A1.T1.2.2.3.1" class="ltx_text" style="font-size:80%;">Topics</span></td>
<td id="A1.T1.2.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T1.2.2.4.1" class="ltx_text"></span><span id="A1.T1.2.2.4.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T1.2.2.4.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T1.2.2.4.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T1.2.2.4.3.1.1" class="ltx_tr">
<span id="A1.T1.2.2.4.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Ref.</span></span>
</span></span><span id="A1.T1.2.2.4.4" class="ltx_text"></span><span id="A1.T1.2.2.4.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="A1.T1.1.1.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:136.6pt;padding-left:2.0pt;padding-right:2.0pt;"><span id="A1.T1.1.1.1.1" class="ltx_inline-logical-block ltx_align_top">
<span id="A1.T1.1.1.1.1.p1" class="ltx_para ltx_noindent">
<span id="A1.T1.1.1.1.1.p1.1" class="ltx_p"><span id="A1.T1.1.1.1.1.p1.1.1" class="ltx_text"></span><span id="A1.T1.1.1.1.1.p1.1.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T1.1.1.1.1.p1.1.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T1.1.1.1.1.p1.1.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T1.1.1.1.1.p1.1.3.1.1" class="ltx_tr">
<span id="A1.T1.1.1.1.1.p1.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Key Contributions</span></span>
</span></span><span id="A1.T1.1.1.1.1.p1.1.4" class="ltx_text"></span><span id="A1.T1.1.1.1.1.p1.1.5" class="ltx_text" style="font-size:80%;"></span></span>
</span></span></td>
<td id="A1.T1.2.2.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:136.6pt;padding-left:2.0pt;padding-right:2.0pt;"><span id="A1.T1.2.2.2.1" class="ltx_inline-logical-block ltx_align_top">
<span id="A1.T1.2.2.2.1.p1" class="ltx_para ltx_noindent">
<span id="A1.T1.2.2.2.1.p1.1" class="ltx_p"><span id="A1.T1.2.2.2.1.p1.1.1" class="ltx_text"></span><span id="A1.T1.2.2.2.1.p1.1.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T1.2.2.2.1.p1.1.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T1.2.2.2.1.p1.1.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T1.2.2.2.1.p1.1.3.1.1" class="ltx_tr">
<span id="A1.T1.2.2.2.1.p1.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Limitations</span></span>
</span></span><span id="A1.T1.2.2.2.1.p1.1.4" class="ltx_text"></span><span id="A1.T1.2.2.2.1.p1.1.5" class="ltx_text" style="font-size:80%;"></span></span>
</span></span></td>
</tr>
<tr id="A1.T1.2.3" class="ltx_tr">
<td id="A1.T1.2.3.1" class="ltx_td ltx_border_l ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"></td>
<td id="A1.T1.2.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T1.2.3.2.1" class="ltx_text"></span><span id="A1.T1.2.3.2.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T1.2.3.2.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T1.2.3.2.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T1.2.3.2.3.1.1" class="ltx_tr">
<span id="A1.T1.2.3.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep">(Wu et al<span class="ltx_text">.</span>, <a href="#bib.bib170" title="" class="ltx_ref">2020</a>; Cheng et al<span class="ltx_text">.</span>, <a href="#bib.bib31" title="" class="ltx_ref">2021</a>; Chen et al<span class="ltx_text">.</span>, <a href="#bib.bib27" title="" class="ltx_ref">2021</a>; Feng et al<span class="ltx_text">.</span>, <a href="#bib.bib47" title="" class="ltx_ref">2019</a>; Fang et al<span class="ltx_text">.</span>, <a href="#bib.bib42" title="" class="ltx_ref">2021</a>)</cite></span></span>
</span></span><span id="A1.T1.2.3.2.4" class="ltx_text"></span><span id="A1.T1.2.3.2.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="A1.T1.2.3.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:136.6pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T1.2.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T1.2.3.3.1.1" class="ltx_p"><span id="A1.T1.2.3.3.1.1.1" class="ltx_text" style="font-size:80%;">Explore privacy-preserving strategies for IDs and feature embeddings, which intuitively achieve vertical federated learning, providing the foundation for effective collaboration.</span></span>
</span>
</td>
<td id="A1.T1.2.3.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:136.6pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T1.2.3.4.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T1.2.3.4.1.1" class="ltx_p"><span id="A1.T1.2.3.4.1.1.1" class="ltx_text" style="font-size:80%;">They rely on specific designs for certain scenarios and lack a general solution to construct effective collaboration models.</span></span>
</span>
</td>
</tr>
<tr id="A1.T1.2.4" class="ltx_tr">
<td id="A1.T1.2.4.1" class="ltx_td ltx_border_l ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;"></td>
<td id="A1.T1.2.4.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T1.2.4.2.1" class="ltx_text"></span><span id="A1.T1.2.4.2.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T1.2.4.2.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T1.2.4.2.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T1.2.4.2.3.1.1" class="ltx_tr">
<span id="A1.T1.2.4.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep">(Tian et al<span class="ltx_text">.</span>, <a href="#bib.bib158" title="" class="ltx_ref">2020</a>; Li et al<span class="ltx_text">.</span>, <a href="#bib.bib103" title="" class="ltx_ref">2022</a>)</cite></span></span>
</span></span><span id="A1.T1.2.4.2.4" class="ltx_text"></span><span id="A1.T1.2.4.2.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="A1.T1.2.4.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:136.6pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T1.2.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T1.2.4.3.1.1" class="ltx_p"><span id="A1.T1.2.4.3.1.1.1" class="ltx_text" style="font-size:80%;">Utilize different privacy measures in the context of vertical federated learning to achieve effective feature aggregation.</span></span>
</span>
</td>
<td id="A1.T1.2.4.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:136.6pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T1.2.4.4.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T1.2.4.4.1.1" class="ltx_p"><span id="A1.T1.2.4.4.1.1.1" class="ltx_text" style="font-size:80%;">The differential privacy may lead to performance degradation due to additional perturbations.</span></span>
</span>
</td>
</tr>
<tr id="A1.T1.2.5" class="ltx_tr">
<td id="A1.T1.2.5.1" class="ltx_td ltx_border_l ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;"></td>
<td id="A1.T1.2.5.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T1.2.5.2.1" class="ltx_text"></span><span id="A1.T1.2.5.2.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T1.2.5.2.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T1.2.5.2.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T1.2.5.2.3.1.1" class="ltx_tr">
<span id="A1.T1.2.5.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep">(Liu et al<span class="ltx_text">.</span>, <a href="#bib.bib114" title="" class="ltx_ref">2020b</a>)</cite></span></span>
</span></span><span id="A1.T1.2.5.2.4" class="ltx_text"></span><span id="A1.T1.2.5.2.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="A1.T1.2.5.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:136.6pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T1.2.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T1.2.5.3.1.1" class="ltx_p"><span id="A1.T1.2.5.3.1.1.1" class="ltx_text" style="font-size:80%;">Construct the forest algorithm using CART tree and bagging for both classification and regression tasks in vertical federated learning.</span></span>
</span>
</td>
<td id="A1.T1.2.5.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:136.6pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T1.2.5.4.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T1.2.5.4.1.1" class="ltx_p"><span id="A1.T1.2.5.4.1.1.1" class="ltx_text" style="font-size:80%;">The privacy issues related to sharing intermediate embeddings and the potential privacy leakage of task labels have not been thoroughly explored.</span></span>
</span>
</td>
</tr>
<tr id="A1.T1.2.6" class="ltx_tr">
<td id="A1.T1.2.6.1" class="ltx_td ltx_border_l ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;"></td>
<td id="A1.T1.2.6.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T1.2.6.2.1" class="ltx_text"></span><span id="A1.T1.2.6.2.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T1.2.6.2.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T1.2.6.2.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T1.2.6.2.3.1.1" class="ltx_tr">
<span id="A1.T1.2.6.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep">(Yao et al<span class="ltx_text">.</span>, <a href="#bib.bib185" title="" class="ltx_ref">2022</a>)</cite></span></span>
</span></span><span id="A1.T1.2.6.2.4" class="ltx_text"></span><span id="A1.T1.2.6.2.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="A1.T1.2.6.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:136.6pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T1.2.6.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T1.2.6.3.1.1" class="ltx_p"><span id="A1.T1.2.6.3.1.1.1" class="ltx_text" style="font-size:80%;">Explore an efficient and robust vertical federated random forest algorithm for real-world large-scale data applications.</span></span>
</span>
</td>
<td id="A1.T1.2.6.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:136.6pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T1.2.6.4.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T1.2.6.4.1.1" class="ltx_p"><span id="A1.T1.2.6.4.1.1.1" class="ltx_text" style="font-size:80%;">While data scalability is considered, the scale of the participants is also critical for efficiency.</span></span>
</span>
</td>
</tr>
<tr id="A1.T1.2.7" class="ltx_tr">
<td id="A1.T1.2.7.1" class="ltx_td ltx_border_l ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;"></td>
<td id="A1.T1.2.7.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T1.2.7.2.1" class="ltx_text"></span><span id="A1.T1.2.7.2.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T1.2.7.2.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T1.2.7.2.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T1.2.7.2.3.1.1" class="ltx_tr">
<span id="A1.T1.2.7.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep">(Hou et al<span class="ltx_text">.</span>, <a href="#bib.bib68" title="" class="ltx_ref">2021</a>)</cite></span></span>
</span></span><span id="A1.T1.2.7.2.4" class="ltx_text"></span><span id="A1.T1.2.7.2.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="A1.T1.2.7.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:136.6pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T1.2.7.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T1.2.7.3.1.1" class="ltx_p"><span id="A1.T1.2.7.3.1.1.1" class="ltx_text" style="font-size:80%;">Propose a verifiable vertical federated random forest algorithm applicable to dynamic client scenarios.</span></span>
</span>
</td>
<td id="A1.T1.2.7.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:136.6pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T1.2.7.4.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T1.2.7.4.1.1" class="ltx_p"><span id="A1.T1.2.7.4.1.1.1" class="ltx_text" style="font-size:80%;">There are additional communication costs associated with third-party homomorphic encryption.</span></span>
</span>
</td>
</tr>
<tr id="A1.T1.2.8" class="ltx_tr">
<td id="A1.T1.2.8.1" class="ltx_td ltx_border_l ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;"></td>
<td id="A1.T1.2.8.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T1.2.8.2.1" class="ltx_text"></span><span id="A1.T1.2.8.2.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T1.2.8.2.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T1.2.8.2.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T1.2.8.2.3.1.1" class="ltx_tr">
<span id="A1.T1.2.8.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep">(Lu et al<span class="ltx_text">.</span>, <a href="#bib.bib120" title="" class="ltx_ref">2023</a>)</cite></span></span>
</span></span><span id="A1.T1.2.8.2.4" class="ltx_text"></span><span id="A1.T1.2.8.2.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="A1.T1.2.8.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:136.6pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T1.2.8.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T1.2.8.3.1.1" class="ltx_p"><span id="A1.T1.2.8.3.1.1.1" class="ltx_text" style="font-size:80%;">Squirrel integrates innovative GBDT algorithm designs with advanced cryptography, including methods to obscure sample distribution and optimize gradient aggregation efficiently.</span></span>
</span>
</td>
<td id="A1.T1.2.8.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:136.6pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T1.2.8.4.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T1.2.8.4.1.1" class="ltx_p"><span id="A1.T1.2.8.4.1.1.1" class="ltx_text" style="font-size:80%;">The complexities involved in preserving privacy during training and the risks of publishing decision trees between clients have yet to be fully addressed.</span></span>
</span>
</td>
</tr>
<tr id="A1.T1.2.9" class="ltx_tr">
<td id="A1.T1.2.9.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="A1.T1.2.9.1.1" class="ltx_text" style="font-size:80%;"><span id="A1.T1.2.9.1.1.1" class="ltx_text"></span> <span id="A1.T1.2.9.1.1.2" class="ltx_text">
<span id="A1.T1.2.9.1.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T1.2.9.1.1.2.1.1" class="ltx_tr">
<span id="A1.T1.2.9.1.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Tree</span></span>
<span id="A1.T1.2.9.1.1.2.1.2" class="ltx_tr">
<span id="A1.T1.2.9.1.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">-based</span></span>
<span id="A1.T1.2.9.1.1.2.1.3" class="ltx_tr">
<span id="A1.T1.2.9.1.1.2.1.3.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Model</span></span>
</span></span> <span id="A1.T1.2.9.1.1.3" class="ltx_text"></span></span></td>
<td id="A1.T1.2.9.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T1.2.9.2.1" class="ltx_text"></span><span id="A1.T1.2.9.2.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T1.2.9.2.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T1.2.9.2.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T1.2.9.2.3.1.1" class="ltx_tr">
<span id="A1.T1.2.9.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a href="#bib.bib100" title="" class="ltx_ref">2023c</a>)</cite></span></span>
</span></span><span id="A1.T1.2.9.2.4" class="ltx_text"></span><span id="A1.T1.2.9.2.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="A1.T1.2.9.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:136.6pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T1.2.9.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T1.2.9.3.1.1" class="ltx_p"><span id="A1.T1.2.9.3.1.1.1" class="ltx_text" style="font-size:80%;">Propose to integrate client-specific knowledge by adding layers to the tree structure, enabling accelerated training and scalability.</span></span>
</span>
</td>
<td id="A1.T1.2.9.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:136.6pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T1.2.9.4.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T1.2.9.4.1.1" class="ltx_p"><span id="A1.T1.2.9.4.1.1.1" class="ltx_text" style="font-size:80%;">The method is particularly suited for tabular data and may not be directly applicable to other data types like images or text.</span></span>
</span>
</td>
</tr>
<tr id="A1.T1.2.10" class="ltx_tr">
<td id="A1.T1.2.10.1" class="ltx_td ltx_border_l ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"></td>
<td id="A1.T1.2.10.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T1.2.10.2.1" class="ltx_text"></span><span id="A1.T1.2.10.2.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T1.2.10.2.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T1.2.10.2.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T1.2.10.2.3.1.1" class="ltx_tr">
<span id="A1.T1.2.10.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep">(Romanini et al<span class="ltx_text">.</span>, <a href="#bib.bib143" title="" class="ltx_ref">2021</a>)</cite></span></span>
</span></span><span id="A1.T1.2.10.2.4" class="ltx_text"></span><span id="A1.T1.2.10.2.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="A1.T1.2.10.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:136.6pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T1.2.10.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T1.2.10.3.1.1" class="ltx_p"><span id="A1.T1.2.10.3.1.1.1" class="ltx_text" style="font-size:80%;">PyVertical proposes a basic design utilizing split neural networks for vertical federated learning.</span></span>
</span>
</td>
<td id="A1.T1.2.10.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:136.6pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T1.2.10.4.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T1.2.10.4.1.1" class="ltx_p"><span id="A1.T1.2.10.4.1.1.1" class="ltx_text" style="font-size:80%;">The privacy issue is severe as it directly exchanges intermediate features, yet lacks comprehensive discussions on privacy protection measures.</span></span>
</span>
</td>
</tr>
<tr id="A1.T1.2.11" class="ltx_tr">
<td id="A1.T1.2.11.1" class="ltx_td ltx_border_l ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;"></td>
<td id="A1.T1.2.11.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T1.2.11.2.1" class="ltx_text"></span><span id="A1.T1.2.11.2.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T1.2.11.2.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T1.2.11.2.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T1.2.11.2.3.1.1" class="ltx_tr">
<span id="A1.T1.2.11.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep">(Feng and Yu, <a href="#bib.bib46" title="" class="ltx_ref">2020</a>)</cite></span></span>
</span></span><span id="A1.T1.2.11.2.4" class="ltx_text"></span><span id="A1.T1.2.11.2.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="A1.T1.2.11.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:136.6pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T1.2.11.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T1.2.11.3.1.1" class="ltx_p"><span id="A1.T1.2.11.3.1.1.1" class="ltx_text" style="font-size:80%;">MMVFL proposes to achieve label sharing through sparse learning and optimization with a global pseudo-label matrix.</span></span>
</span>
</td>
<td id="A1.T1.2.11.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:136.6pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T1.2.11.4.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T1.2.11.4.1.1" class="ltx_p"><span id="A1.T1.2.11.4.1.1.1" class="ltx_text" style="font-size:80%;">Its applicability is limited to situations where all clients share the same label space.</span></span>
</span>
</td>
</tr>
<tr id="A1.T1.2.12" class="ltx_tr">
<td id="A1.T1.2.12.1" class="ltx_td ltx_border_l ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;"></td>
<td id="A1.T1.2.12.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T1.2.12.2.1" class="ltx_text"></span><span id="A1.T1.2.12.2.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T1.2.12.2.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T1.2.12.2.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T1.2.12.2.3.1.1" class="ltx_tr">
<span id="A1.T1.2.12.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep">(Liu et al<span class="ltx_text">.</span>, <a href="#bib.bib112" title="" class="ltx_ref">2020a</a>)</cite></span></span>
</span></span><span id="A1.T1.2.12.2.4" class="ltx_text"></span><span id="A1.T1.2.12.2.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="A1.T1.2.12.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:136.6pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T1.2.12.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T1.2.12.3.1.1" class="ltx_p"><span id="A1.T1.2.12.3.1.1.1" class="ltx_text" style="font-size:80%;">FTL achieves knowledge transfer through shared samples and feature space.</span></span>
</span>
</td>
<td id="A1.T1.2.12.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:136.6pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T1.2.12.4.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T1.2.12.4.1.1" class="ltx_p"><span id="A1.T1.2.12.4.1.1.1" class="ltx_text" style="font-size:80%;">Its reliance on the shared feature space limits its application.</span></span>
</span>
</td>
</tr>
<tr id="A1.T1.2.13" class="ltx_tr">
<td id="A1.T1.2.13.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="A1.T1.2.13.1.1" class="ltx_text" style="font-size:80%;"><span id="A1.T1.2.13.1.1.1" class="ltx_text"></span> <span id="A1.T1.2.13.1.1.2" class="ltx_text">
<span id="A1.T1.2.13.1.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T1.2.13.1.1.2.1.1" class="ltx_tr">
<span id="A1.T1.2.13.1.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Neural</span></span>
<span id="A1.T1.2.13.1.1.2.1.2" class="ltx_tr">
<span id="A1.T1.2.13.1.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Network-</span></span>
<span id="A1.T1.2.13.1.1.2.1.3" class="ltx_tr">
<span id="A1.T1.2.13.1.1.2.1.3.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">based</span></span>
<span id="A1.T1.2.13.1.1.2.1.4" class="ltx_tr">
<span id="A1.T1.2.13.1.1.2.1.4.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Model</span></span>
</span></span> <span id="A1.T1.2.13.1.1.3" class="ltx_text"></span></span></td>
<td id="A1.T1.2.13.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T1.2.13.2.1" class="ltx_text"></span><span id="A1.T1.2.13.2.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T1.2.13.2.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T1.2.13.2.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T1.2.13.2.3.1.1" class="ltx_tr">
<span id="A1.T1.2.13.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep">(Abedi and Khan, <a href="#bib.bib4" title="" class="ltx_ref">2024</a>)</cite></span></span>
</span></span><span id="A1.T1.2.13.2.4" class="ltx_text"></span><span id="A1.T1.2.13.2.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="A1.T1.2.13.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_b ltx_border_r ltx_border_t" style="width:136.6pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T1.2.13.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T1.2.13.3.1.1" class="ltx_p"><span id="A1.T1.2.13.3.1.1.1" class="ltx_text" style="font-size:80%;">FedSL constructs split Recurrent Neural Networks for handling sequential data in vertical federated learning.</span></span>
</span>
</td>
<td id="A1.T1.2.13.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_b ltx_border_r ltx_border_t" style="width:136.6pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T1.2.13.4.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T1.2.13.4.1.1" class="ltx_p"><span id="A1.T1.2.13.4.1.1.1" class="ltx_text" style="font-size:80%;">It lacks discussions on scenarios where multiple data segments can be stored in a single client.</span></span>
</span>
</td>
</tr>
</table>
</figure>
<figure id="A1.T2" class="ltx_table">
<figcaption class="ltx_caption ltx_centering" style="font-size:80%;"><span class="ltx_tag ltx_tag_table">Table 2. </span><span id="A1.T2.5.1" class="ltx_text ltx_font_bold">Works on Feature &amp; Client Selection.</span></figcaption>
<table id="A1.T2.2" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="A1.T2.2.2" class="ltx_tr">
<td id="A1.T2.2.2.3" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="A1.T2.2.2.3.1" class="ltx_text" style="font-size:80%;">Topics</span></td>
<td id="A1.T2.2.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T2.2.2.4.1" class="ltx_text"></span><span id="A1.T2.2.2.4.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T2.2.2.4.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T2.2.2.4.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T2.2.2.4.3.1.1" class="ltx_tr">
<span id="A1.T2.2.2.4.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Ref.</span></span>
</span></span><span id="A1.T2.2.2.4.4" class="ltx_text"></span><span id="A1.T2.2.2.4.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="A1.T2.1.1.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:162.2pt;padding-left:2.0pt;padding-right:2.0pt;"><span id="A1.T2.1.1.1.1" class="ltx_inline-logical-block ltx_align_top">
<span id="A1.T2.1.1.1.1.p1" class="ltx_para ltx_noindent">
<span id="A1.T2.1.1.1.1.p1.1" class="ltx_p"><span id="A1.T2.1.1.1.1.p1.1.1" class="ltx_text"></span><span id="A1.T2.1.1.1.1.p1.1.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T2.1.1.1.1.p1.1.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T2.1.1.1.1.p1.1.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T2.1.1.1.1.p1.1.3.1.1" class="ltx_tr">
<span id="A1.T2.1.1.1.1.p1.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Key Contributions</span></span>
</span></span><span id="A1.T2.1.1.1.1.p1.1.4" class="ltx_text"></span><span id="A1.T2.1.1.1.1.p1.1.5" class="ltx_text" style="font-size:80%;"></span></span>
</span></span></td>
<td id="A1.T2.2.2.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:162.2pt;padding-left:2.0pt;padding-right:2.0pt;"><span id="A1.T2.2.2.2.1" class="ltx_inline-logical-block ltx_align_top">
<span id="A1.T2.2.2.2.1.p1" class="ltx_para ltx_noindent">
<span id="A1.T2.2.2.2.1.p1.1" class="ltx_p"><span id="A1.T2.2.2.2.1.p1.1.1" class="ltx_text"></span><span id="A1.T2.2.2.2.1.p1.1.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T2.2.2.2.1.p1.1.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T2.2.2.2.1.p1.1.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T2.2.2.2.1.p1.1.3.1.1" class="ltx_tr">
<span id="A1.T2.2.2.2.1.p1.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Limitations</span></span>
</span></span><span id="A1.T2.2.2.2.1.p1.1.4" class="ltx_text"></span><span id="A1.T2.2.2.2.1.p1.1.5" class="ltx_text" style="font-size:80%;"></span></span>
</span></span></td>
</tr>
<tr id="A1.T2.2.3" class="ltx_tr">
<td id="A1.T2.2.3.1" class="ltx_td ltx_border_l ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"></td>
<td id="A1.T2.2.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T2.2.3.2.1" class="ltx_text"></span><span id="A1.T2.2.3.2.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T2.2.3.2.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T2.2.3.2.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T2.2.3.2.3.1.1" class="ltx_tr">
<span id="A1.T2.2.3.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a href="#bib.bib95" title="" class="ltx_ref">2023a</a>)</cite></span></span>
</span></span><span id="A1.T2.2.3.2.4" class="ltx_text"></span><span id="A1.T2.2.3.2.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="A1.T2.2.3.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:162.2pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T2.2.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T2.2.3.3.1.1" class="ltx_p"><span id="A1.T2.2.3.3.1.1.1" class="ltx_text" style="font-size:80%;">FedSDG-FS constructs dual-gate feature selection based on Gini impurity while ensuring privacy protection with differential privacy.</span></span>
</span>
</td>
<td id="A1.T2.2.3.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:162.2pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T2.2.3.4.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T2.2.3.4.1.1" class="ltx_p"><span id="A1.T2.2.3.4.1.1.1" class="ltx_text" style="font-size:80%;">It assumes that all participants are honest, lacking a privacy discussion regarding malicious clients.</span></span>
</span>
</td>
</tr>
<tr id="A1.T2.2.4" class="ltx_tr">
<td id="A1.T2.2.4.1" class="ltx_td ltx_border_l ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;"></td>
<td id="A1.T2.2.4.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T2.2.4.2.1" class="ltx_text"></span><span id="A1.T2.2.4.2.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T2.2.4.2.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T2.2.4.2.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T2.2.4.2.3.1.1" class="ltx_tr">
<span id="A1.T2.2.4.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep">(Castiglia et al<span class="ltx_text">.</span>, <a href="#bib.bib15" title="" class="ltx_ref">2023</a>)</cite></span></span>
</span></span><span id="A1.T2.2.4.2.4" class="ltx_text"></span><span id="A1.T2.2.4.2.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="A1.T2.2.4.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:162.2pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T2.2.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T2.2.4.3.1.1" class="ltx_p"><span id="A1.T2.2.4.3.1.1.1" class="ltx_text" style="font-size:80%;">LESS-VFL proposes a communication-effective method based on the group lasso algorithm.</span></span>
</span>
</td>
<td id="A1.T2.2.4.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:162.2pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T2.2.4.4.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T2.2.4.4.1.1" class="ltx_p"><span id="A1.T2.2.4.4.1.1.1" class="ltx_text" style="font-size:80%;">It introduces additional complexity with weight regularization terms.</span></span>
</span>
</td>
</tr>
<tr id="A1.T2.2.5" class="ltx_tr">
<td id="A1.T2.2.5.1" class="ltx_td ltx_border_l ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;"></td>
<td id="A1.T2.2.5.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T2.2.5.2.1" class="ltx_text"></span><span id="A1.T2.2.5.2.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T2.2.5.2.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T2.2.5.2.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T2.2.5.2.3.1.1" class="ltx_tr">
<span id="A1.T2.2.5.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep">(Feng, <a href="#bib.bib45" title="" class="ltx_ref">2022</a>)</cite></span></span>
</span></span><span id="A1.T2.2.5.2.4" class="ltx_text"></span><span id="A1.T2.2.5.2.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="A1.T2.2.5.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:162.2pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T2.2.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T2.2.5.3.1.1" class="ltx_p"><span id="A1.T2.2.5.3.1.1.1" class="ltx_text" style="font-size:80%;">It achieves feature selection through local feature construction and weight sparse learning.</span></span>
</span>
</td>
<td id="A1.T2.2.5.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:162.2pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T2.2.5.4.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T2.2.5.4.1.1" class="ltx_p"><span id="A1.T2.2.5.4.1.1.1" class="ltx_text" style="font-size:80%;">The samples are not fully utilized for collaboration, which hinders the generalization of feature selection.</span></span>
</span>
</td>
</tr>
<tr id="A1.T2.2.6" class="ltx_tr">
<td id="A1.T2.2.6.1" class="ltx_td ltx_border_l ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;"></td>
<td id="A1.T2.2.6.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T2.2.6.2.1" class="ltx_text"></span><span id="A1.T2.2.6.2.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T2.2.6.2.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T2.2.6.2.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T2.2.6.2.3.1.1" class="ltx_tr">
<span id="A1.T2.2.6.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep">(Zhang et al<span class="ltx_text">.</span>, <a href="#bib.bib197" title="" class="ltx_ref">2022b</a>)</cite></span></span>
</span></span><span id="A1.T2.2.6.2.4" class="ltx_text"></span><span id="A1.T2.2.6.2.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="A1.T2.2.6.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:162.2pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T2.2.6.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T2.2.6.3.1.1" class="ltx_p"><span id="A1.T2.2.6.3.1.1.1" class="ltx_text" style="font-size:80%;">Build an efficient and privacy-preserving framework for eHealth data in vertical federated learning.</span></span>
</span>
</td>
<td id="A1.T2.2.6.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:162.2pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T2.2.6.4.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T2.2.6.4.1.1" class="ltx_p"><span id="A1.T2.2.6.4.1.1.1" class="ltx_text" style="font-size:80%;">The features are selected only with the active client, while the remaining critical clients are ignored.</span></span>
</span>
</td>
</tr>
<tr id="A1.T2.2.7" class="ltx_tr">
<td id="A1.T2.2.7.1" class="ltx_td ltx_border_l ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;"></td>
<td id="A1.T2.2.7.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T2.2.7.2.1" class="ltx_text"></span><span id="A1.T2.2.7.2.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T2.2.7.2.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T2.2.7.2.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T2.2.7.2.3.1.1" class="ltx_tr">
<span id="A1.T2.2.7.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep">(Fu et al<span class="ltx_text">.</span>, <a href="#bib.bib51" title="" class="ltx_ref">2023</a>)</cite></span></span>
</span></span><span id="A1.T2.2.7.2.4" class="ltx_text"></span><span id="A1.T2.2.7.2.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="A1.T2.2.7.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:162.2pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T2.2.7.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T2.2.7.3.1.1" class="ltx_p"><span id="A1.T2.2.7.3.1.1.1" class="ltx_text" style="font-size:80%;">FEAST constructs the feature selection based on the mutual information.</span></span>
</span>
</td>
<td id="A1.T2.2.7.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:162.2pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T2.2.7.4.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T2.2.7.4.1.1" class="ltx_p"><span id="A1.T2.2.7.4.1.1.1" class="ltx_text" style="font-size:80%;">The greedy search selection may fail to converge to the optimal feature set.</span></span>
</span>
</td>
</tr>
<tr id="A1.T2.2.8" class="ltx_tr">
<td id="A1.T2.2.8.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="A1.T2.2.8.1.1" class="ltx_text" style="font-size:80%;"><span id="A1.T2.2.8.1.1.1" class="ltx_text"></span> <span id="A1.T2.2.8.1.1.2" class="ltx_text">
<span id="A1.T2.2.8.1.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T2.2.8.1.1.2.1.1" class="ltx_tr">
<span id="A1.T2.2.8.1.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Feature</span></span>
<span id="A1.T2.2.8.1.1.2.1.2" class="ltx_tr">
<span id="A1.T2.2.8.1.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Selection</span></span>
</span></span> <span id="A1.T2.2.8.1.1.3" class="ltx_text"></span></span></td>
<td id="A1.T2.2.8.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T2.2.8.2.1" class="ltx_text"></span><span id="A1.T2.2.8.2.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T2.2.8.2.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T2.2.8.2.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T2.2.8.2.3.1.1" class="ltx_tr">
<span id="A1.T2.2.8.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep">(Zhang et al<span class="ltx_text">.</span>, <a href="#bib.bib201" title="" class="ltx_ref">2023b</a>)</cite></span></span>
</span></span><span id="A1.T2.2.8.2.4" class="ltx_text"></span><span id="A1.T2.2.8.2.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="A1.T2.2.8.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:162.2pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T2.2.8.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T2.2.8.3.1.1" class="ltx_p"><span id="A1.T2.2.8.3.1.1.1" class="ltx_text" style="font-size:80%;">PSO-EVFFS integrates evolutionary feature selection into the SecureBoost framework, optimizing both hyperparameters and feature subsets.</span></span>
</span>
</td>
<td id="A1.T2.2.8.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:162.2pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T2.2.8.4.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T2.2.8.4.1.1" class="ltx_p"><span id="A1.T2.2.8.4.1.1.1" class="ltx_text" style="font-size:80%;">Its generalization to other backbones has not been explored.</span></span>
</span>
</td>
</tr>
<tr id="A1.T2.2.9" class="ltx_tr">
<td id="A1.T2.2.9.1" class="ltx_td ltx_border_l ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"></td>
<td id="A1.T2.2.9.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T2.2.9.2.1" class="ltx_text"></span><span id="A1.T2.2.9.2.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T2.2.9.2.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T2.2.9.2.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T2.2.9.2.3.1.1" class="ltx_tr">
<span id="A1.T2.2.9.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep">(Wang et al<span class="ltx_text">.</span>, <a href="#bib.bib163" title="" class="ltx_ref">2019</a>)</cite></span></span>
</span></span><span id="A1.T2.2.9.2.4" class="ltx_text"></span><span id="A1.T2.2.9.2.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="A1.T2.2.9.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:162.2pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T2.2.9.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T2.2.9.3.1.1" class="ltx_p"><span id="A1.T2.2.9.3.1.1.1" class="ltx_text" style="font-size:80%;">Construct a secure and fair contribution measurement based on Shapley value.</span></span>
</span>
</td>
<td id="A1.T2.2.9.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:162.2pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T2.2.9.4.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T2.2.9.4.1.1" class="ltx_p"><span id="A1.T2.2.9.4.1.1.1" class="ltx_text" style="font-size:80%;">Entail assumptions that all clients hold the data with the same scale and have no correlations.</span></span>
</span>
</td>
</tr>
<tr id="A1.T2.2.10" class="ltx_tr">
<td id="A1.T2.2.10.1" class="ltx_td ltx_border_l ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;"></td>
<td id="A1.T2.2.10.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T2.2.10.2.1" class="ltx_text"></span><span id="A1.T2.2.10.2.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T2.2.10.2.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T2.2.10.2.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T2.2.10.2.3.1.1" class="ltx_tr">
<span id="A1.T2.2.10.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep">(Fan et al<span class="ltx_text">.</span>, <a href="#bib.bib41" title="" class="ltx_ref">2024</a>)</cite></span></span>
</span></span><span id="A1.T2.2.10.2.4" class="ltx_text"></span><span id="A1.T2.2.10.2.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="A1.T2.2.10.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:162.2pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T2.2.10.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T2.2.10.3.1.1" class="ltx_p"><span id="A1.T2.2.10.3.1.1.1" class="ltx_text" style="font-size:80%;">The proposed VerFedSV achieves fair and efficient client contribution calculation by leveraging Shapley value principles. It is efficient to compute and retains many fairness properties.</span></span>
</span>
</td>
<td id="A1.T2.2.10.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:162.2pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T2.2.10.4.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T2.2.10.4.1.1" class="ltx_p"><span id="A1.T2.2.10.4.1.1.1" class="ltx_text" style="font-size:80%;">It relies on the preset timestamps which hinders its accuracy and stability.</span></span>
</span>
</td>
</tr>
<tr id="A1.T2.2.11" class="ltx_tr">
<td id="A1.T2.2.11.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="A1.T2.2.11.1.1" class="ltx_text" style="font-size:80%;"><span id="A1.T2.2.11.1.1.1" class="ltx_text"></span> <span id="A1.T2.2.11.1.1.2" class="ltx_text">
<span id="A1.T2.2.11.1.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T2.2.11.1.1.2.1.1" class="ltx_tr">
<span id="A1.T2.2.11.1.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Client</span></span>
<span id="A1.T2.2.11.1.1.2.1.2" class="ltx_tr">
<span id="A1.T2.2.11.1.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Selection</span></span>
</span></span> <span id="A1.T2.2.11.1.1.3" class="ltx_text"></span></span></td>
<td id="A1.T2.2.11.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T2.2.11.2.1" class="ltx_text"></span><span id="A1.T2.2.11.2.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T2.2.11.2.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T2.2.11.2.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T2.2.11.2.3.1.1" class="ltx_tr">
<span id="A1.T2.2.11.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep">(Jiang et al<span class="ltx_text">.</span>, <a href="#bib.bib81" title="" class="ltx_ref">2022a</a>)</cite></span></span>
</span></span><span id="A1.T2.2.11.2.4" class="ltx_text"></span><span id="A1.T2.2.11.2.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="A1.T2.2.11.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_b ltx_border_r ltx_border_t" style="width:162.2pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T2.2.11.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T2.2.11.3.1.1" class="ltx_p"><span id="A1.T2.2.11.3.1.1.1" class="ltx_text" style="font-size:80%;">VF-MINE calculates client contributions based on mutual information of each client.</span></span>
</span>
</td>
<td id="A1.T2.2.11.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_b ltx_border_r ltx_border_t" style="width:162.2pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T2.2.11.4.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T2.2.11.4.1.1" class="ltx_p"><span id="A1.T2.2.11.4.1.1.1" class="ltx_text" style="font-size:80%;">The importance of participants may change over time, which client selection might not account for; The mutual information estimator will deviate to the small feature set, which will introduce bias for the final contribution estimation.</span></span>
</span>
</td>
</tr>
</table>
</figure>
<figure id="A1.T3" class="ltx_table">
<figcaption class="ltx_caption ltx_centering" style="font-size:80%;"><span class="ltx_tag ltx_tag_table">Table 3. </span><span id="A1.T3.5.1" class="ltx_text ltx_font_bold">Works on Addressing Privacy Leakage.</span></figcaption>
<table id="A1.T3.2" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="A1.T3.2.2" class="ltx_tr">
<td id="A1.T3.2.2.3" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="A1.T3.2.2.3.1" class="ltx_text" style="font-size:80%;">Topics</span></td>
<td id="A1.T3.2.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T3.2.2.4.1" class="ltx_text"></span><span id="A1.T3.2.2.4.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T3.2.2.4.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T3.2.2.4.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T3.2.2.4.3.1.1" class="ltx_tr">
<span id="A1.T3.2.2.4.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Ref.</span></span>
</span></span><span id="A1.T3.2.2.4.4" class="ltx_text"></span><span id="A1.T3.2.2.4.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="A1.T3.1.1.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:149.4pt;padding-left:2.0pt;padding-right:2.0pt;"><span id="A1.T3.1.1.1.1" class="ltx_inline-logical-block ltx_align_top">
<span id="A1.T3.1.1.1.1.p1" class="ltx_para ltx_noindent">
<span id="A1.T3.1.1.1.1.p1.1" class="ltx_p"><span id="A1.T3.1.1.1.1.p1.1.1" class="ltx_text"></span><span id="A1.T3.1.1.1.1.p1.1.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T3.1.1.1.1.p1.1.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T3.1.1.1.1.p1.1.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T3.1.1.1.1.p1.1.3.1.1" class="ltx_tr">
<span id="A1.T3.1.1.1.1.p1.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Key Contributions</span></span>
</span></span><span id="A1.T3.1.1.1.1.p1.1.4" class="ltx_text"></span><span id="A1.T3.1.1.1.1.p1.1.5" class="ltx_text" style="font-size:80%;"></span></span>
</span></span></td>
<td id="A1.T3.2.2.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:149.4pt;padding-left:2.0pt;padding-right:2.0pt;"><span id="A1.T3.2.2.2.1" class="ltx_inline-logical-block ltx_align_top">
<span id="A1.T3.2.2.2.1.p1" class="ltx_para ltx_noindent">
<span id="A1.T3.2.2.2.1.p1.1" class="ltx_p"><span id="A1.T3.2.2.2.1.p1.1.1" class="ltx_text"></span><span id="A1.T3.2.2.2.1.p1.1.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T3.2.2.2.1.p1.1.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T3.2.2.2.1.p1.1.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T3.2.2.2.1.p1.1.3.1.1" class="ltx_tr">
<span id="A1.T3.2.2.2.1.p1.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Limitations</span></span>
</span></span><span id="A1.T3.2.2.2.1.p1.1.4" class="ltx_text"></span><span id="A1.T3.2.2.2.1.p1.1.5" class="ltx_text" style="font-size:80%;"></span></span>
</span></span></td>
</tr>
<tr id="A1.T3.2.3" class="ltx_tr">
<td id="A1.T3.2.3.1" class="ltx_td ltx_border_l ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"></td>
<td id="A1.T3.2.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T3.2.3.2.1" class="ltx_text"></span><span id="A1.T3.2.3.2.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T3.2.3.2.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T3.2.3.2.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T3.2.3.2.3.1.1" class="ltx_tr">
<span id="A1.T3.2.3.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep">(Lu and Ding, <a href="#bib.bib119" title="" class="ltx_ref">2020</a>)</cite></span></span>
</span></span><span id="A1.T3.2.3.2.4" class="ltx_text"></span><span id="A1.T3.2.3.2.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="A1.T3.2.3.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:149.4pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T3.2.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T3.2.3.3.1.1" class="ltx_p"><span id="A1.T3.2.3.3.1.1.1" class="ltx_text" style="font-size:80%;">Propose a multi-party private set intersection protocol that can handle cases where some parties drop out during the protocol execution.</span></span>
</span>
</td>
<td id="A1.T3.2.3.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:149.4pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T3.2.3.4.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T3.2.3.4.1.1" class="ltx_p"><span id="A1.T3.2.3.4.1.1.1" class="ltx_text" style="font-size:80%;">It requires synchronous warm-up training at the beginning, and the gradient prediction method may introduce estimation errors.</span></span>
</span>
</td>
</tr>
<tr id="A1.T3.2.4" class="ltx_tr">
<td id="A1.T3.2.4.1" class="ltx_td ltx_border_l ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;"></td>
<td id="A1.T3.2.4.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T3.2.4.2.1" class="ltx_text"></span><span id="A1.T3.2.4.2.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T3.2.4.2.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T3.2.4.2.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T3.2.4.2.3.1.1" class="ltx_tr">
<span id="A1.T3.2.4.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep">(Sun et al<span class="ltx_text">.</span>, <a href="#bib.bib154" title="" class="ltx_ref">2021a</a>)</cite></span></span>
</span></span><span id="A1.T3.2.4.2.4" class="ltx_text"></span><span id="A1.T3.2.4.2.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="A1.T3.2.4.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:149.4pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T3.2.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T3.2.4.3.1.1" class="ltx_p"><span id="A1.T3.2.4.3.1.1.1" class="ltx_text" style="font-size:80%;">FLORIST proposes to utilize a Private Set Union (PSU) protocol to align data entities without revealing sensitive membership information.</span></span>
</span>
</td>
<td id="A1.T3.2.4.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:149.4pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T3.2.4.4.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T3.2.4.4.1.1" class="ltx_p"><span id="A1.T3.2.4.4.1.1.1" class="ltx_text" style="font-size:80%;">The PSU approach may increase the training sample size, leading to a potential rise in training costs.</span></span>
</span>
</td>
</tr>
<tr id="A1.T3.2.5" class="ltx_tr">
<td id="A1.T3.2.5.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="A1.T3.2.5.1.1" class="ltx_text" style="font-size:80%;"><span id="A1.T3.2.5.1.1.1" class="ltx_text"></span> <span id="A1.T3.2.5.1.1.2" class="ltx_text">
<span id="A1.T3.2.5.1.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T3.2.5.1.1.2.1.1" class="ltx_tr">
<span id="A1.T3.2.5.1.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Secure</span></span>
<span id="A1.T3.2.5.1.1.2.1.2" class="ltx_tr">
<span id="A1.T3.2.5.1.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Alignment</span></span>
</span></span> <span id="A1.T3.2.5.1.1.3" class="ltx_text"></span></span></td>
<td id="A1.T3.2.5.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T3.2.5.2.1" class="ltx_text"></span><span id="A1.T3.2.5.2.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T3.2.5.2.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T3.2.5.2.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T3.2.5.2.3.1.1" class="ltx_tr">
<span id="A1.T3.2.5.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep">(Hardy et al<span class="ltx_text">.</span>, <a href="#bib.bib63" title="" class="ltx_ref">2017</a>)</cite></span></span>
</span></span><span id="A1.T3.2.5.2.4" class="ltx_text"></span><span id="A1.T3.2.5.2.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="A1.T3.2.5.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:149.4pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T3.2.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T3.2.5.3.1.1" class="ltx_p"><span id="A1.T3.2.5.3.1.1.1" class="ltx_text" style="font-size:80%;">Propose Privacy-Preserving Entity Resolution, where the raw data in clients is encrypted into a cryptographic long-term key (CLK).</span></span>
</span>
</td>
<td id="A1.T3.2.5.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:149.4pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T3.2.5.4.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T3.2.5.4.1.1" class="ltx_p"><span id="A1.T3.2.5.4.1.1.1" class="ltx_text" style="font-size:80%;">The method may not be effective if identifiers are unstable or recorded with errors.</span></span>
</span>
</td>
</tr>
<tr id="A1.T3.2.6" class="ltx_tr">
<td id="A1.T3.2.6.1" class="ltx_td ltx_border_l ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"></td>
<td id="A1.T3.2.6.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T3.2.6.2.1" class="ltx_text"></span><span id="A1.T3.2.6.2.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T3.2.6.2.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T3.2.6.2.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T3.2.6.2.3.1.1" class="ltx_tr">
<span id="A1.T3.2.6.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep">(Lu and Ding, <a href="#bib.bib119" title="" class="ltx_ref">2020</a>)</cite></span></span>
</span></span><span id="A1.T3.2.6.2.4" class="ltx_text"></span><span id="A1.T3.2.6.2.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="A1.T3.2.6.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:149.4pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T3.2.6.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T3.2.6.3.1.1" class="ltx_p"><span id="A1.T3.2.6.3.1.1.1" class="ltx_text" style="font-size:80%;">Propose to leverage homomorphic encryption for intermediate embeddings to ensure data privacy without leaking information from raw data.</span></span>
</span>
</td>
<td id="A1.T3.2.6.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:149.4pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T3.2.6.4.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T3.2.6.4.1.1" class="ltx_p"><span id="A1.T3.2.6.4.1.1.1" class="ltx_text" style="font-size:80%;">It introduces additional communication costs with a third-party coordinator for decryption and encryption.</span></span>
</span>
</td>
</tr>
<tr id="A1.T3.2.7" class="ltx_tr">
<td id="A1.T3.2.7.1" class="ltx_td ltx_border_l ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;"></td>
<td id="A1.T3.2.7.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T3.2.7.2.1" class="ltx_text"></span><span id="A1.T3.2.7.2.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T3.2.7.2.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T3.2.7.2.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T3.2.7.2.3.1.1" class="ltx_tr">
<span id="A1.T3.2.7.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep">(Wu et al<span class="ltx_text">.</span>, <a href="#bib.bib171" title="" class="ltx_ref">2023c</a>)</cite></span></span>
</span></span><span id="A1.T3.2.7.2.4" class="ltx_text"></span><span id="A1.T3.2.7.2.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="A1.T3.2.7.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:149.4pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T3.2.7.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T3.2.7.3.1.1" class="ltx_p"><span id="A1.T3.2.7.3.1.1.1" class="ltx_text" style="font-size:80%;">Falcon supports VFL training for various backbones with strong privacy protection, using a hybrid strategy of threshold partially homomorphic encryption (PHE) and additive secret sharing scheme (SSS).</span></span>
</span>
</td>
<td id="A1.T3.2.7.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:149.4pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T3.2.7.4.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T3.2.7.4.1.1" class="ltx_p"><span id="A1.T3.2.7.4.1.1.1" class="ltx_text" style="font-size:80%;">The need for threshold decryption in PHE and SSS conversion can be computationally expensive.</span></span>
</span>
</td>
</tr>
<tr id="A1.T3.2.8" class="ltx_tr">
<td id="A1.T3.2.8.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="A1.T3.2.8.1.1" class="ltx_text" style="font-size:80%;"><span id="A1.T3.2.8.1.1.1" class="ltx_text"></span> <span id="A1.T3.2.8.1.1.2" class="ltx_text">
<span id="A1.T3.2.8.1.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T3.2.8.1.1.2.1.1" class="ltx_tr">
<span id="A1.T3.2.8.1.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Secure</span></span>
<span id="A1.T3.2.8.1.1.2.1.2" class="ltx_tr">
<span id="A1.T3.2.8.1.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Embedding</span></span>
<span id="A1.T3.2.8.1.1.2.1.3" class="ltx_tr">
<span id="A1.T3.2.8.1.1.2.1.3.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Transportation</span></span>
</span></span> <span id="A1.T3.2.8.1.1.3" class="ltx_text"></span></span></td>
<td id="A1.T3.2.8.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T3.2.8.2.1" class="ltx_text"></span><span id="A1.T3.2.8.2.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T3.2.8.2.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T3.2.8.2.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T3.2.8.2.3.1.1" class="ltx_tr">
<span id="A1.T3.2.8.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep">(Wang et al<span class="ltx_text">.</span>, <a href="#bib.bib162" title="" class="ltx_ref">2020</a>)</cite></span></span>
</span></span><span id="A1.T3.2.8.2.4" class="ltx_text"></span><span id="A1.T3.2.8.2.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="A1.T3.2.8.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:149.4pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T3.2.8.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T3.2.8.3.1.1" class="ltx_p"><span id="A1.T3.2.8.3.1.1.1" class="ltx_text" style="font-size:80%;">HDP-VFL enables joint learning of a generalized linear model from vertically partitioned data with minimal cost in terms of training time and accuracy. It leverages differential privacy (DP) to protect intermediate results during VFL, avoiding the need for Homomorphic Encryption or Secure Multi-Party Computation.</span></span>
</span>
</td>
<td id="A1.T3.2.8.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:149.4pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T3.2.8.4.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T3.2.8.4.1.1" class="ltx_p"><span id="A1.T3.2.8.4.1.1.1" class="ltx_text" style="font-size:80%;">The accuracy of the joint model may be decreased with tight privacy budgets.</span></span>
</span>
</td>
</tr>
<tr id="A1.T3.2.9" class="ltx_tr">
<td id="A1.T3.2.9.1" class="ltx_td ltx_border_l ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"></td>
<td id="A1.T3.2.9.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T3.2.9.2.1" class="ltx_text"></span><span id="A1.T3.2.9.2.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T3.2.9.2.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T3.2.9.2.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T3.2.9.2.3.1.1" class="ltx_tr">
<span id="A1.T3.2.9.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep">(Xu et al<span class="ltx_text">.</span>, <a href="#bib.bib176" title="" class="ltx_ref">2021</a>)</cite></span></span>
</span></span><span id="A1.T3.2.9.2.4" class="ltx_text"></span><span id="A1.T3.2.9.2.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="A1.T3.2.9.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:149.4pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T3.2.9.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T3.2.9.3.1.1" class="ltx_p"><span id="A1.T3.2.9.3.1.1.1" class="ltx_text" style="font-size:80%;">FedV enables collaborative training of machine learning models without peer-to-peer communication among parties. It uses functional encryption to secure gradient computation for models like linear regression, logistic regression, and SVMs.</span></span>
</span>
</td>
<td id="A1.T3.2.9.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:149.4pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T3.2.9.4.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T3.2.9.4.1.1" class="ltx_p"><span id="A1.T3.2.9.4.1.1.1" class="ltx_text" style="font-size:80%;">The use of functional encryption may introduce computational complexity.</span></span>
</span>
</td>
</tr>
<tr id="A1.T3.2.10" class="ltx_tr">
<td id="A1.T3.2.10.1" class="ltx_td ltx_border_l ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;"></td>
<td id="A1.T3.2.10.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T3.2.10.2.1" class="ltx_text"></span><span id="A1.T3.2.10.2.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T3.2.10.2.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T3.2.10.2.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T3.2.10.2.3.1.1" class="ltx_tr">
<span id="A1.T3.2.10.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep">(Zhao et al<span class="ltx_text">.</span>, <a href="#bib.bib203" title="" class="ltx_ref">2022</a>)</cite></span></span>
</span></span><span id="A1.T3.2.10.2.4" class="ltx_text"></span><span id="A1.T3.2.10.2.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="A1.T3.2.10.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:149.4pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T3.2.10.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T3.2.10.3.1.1" class="ltx_p"><span id="A1.T3.2.10.3.1.1.1" class="ltx_text" style="font-size:80%;">CRDP-FL integrates differential privacy into a VFL framework to protect privacy while maintaining utility. By injecting differential privacy noise, CRDP-FL ensures strong privacy guarantees.</span></span>
</span>
</td>
<td id="A1.T3.2.10.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:149.4pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T3.2.10.4.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T3.2.10.4.1.1" class="ltx_p"><span id="A1.T3.2.10.4.1.1.1" class="ltx_text" style="font-size:80%;">The trade-off between the performance and the privacy needs to be carefully considered.</span></span>
</span>
</td>
</tr>
<tr id="A1.T3.2.11" class="ltx_tr">
<td id="A1.T3.2.11.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="A1.T3.2.11.1.1" class="ltx_text" style="font-size:80%;"><span id="A1.T3.2.11.1.1.1" class="ltx_text"></span> <span id="A1.T3.2.11.1.1.2" class="ltx_text">
<span id="A1.T3.2.11.1.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T3.2.11.1.1.2.1.1" class="ltx_tr">
<span id="A1.T3.2.11.1.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Secure</span></span>
<span id="A1.T3.2.11.1.1.2.1.2" class="ltx_tr">
<span id="A1.T3.2.11.1.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Gradient</span></span>
<span id="A1.T3.2.11.1.1.2.1.3" class="ltx_tr">
<span id="A1.T3.2.11.1.1.2.1.3.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Transportation</span></span>
</span></span> <span id="A1.T3.2.11.1.1.3" class="ltx_text"></span></span></td>
<td id="A1.T3.2.11.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T3.2.11.2.1" class="ltx_text"></span><span id="A1.T3.2.11.2.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T3.2.11.2.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T3.2.11.2.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T3.2.11.2.3.1.1" class="ltx_tr">
<span id="A1.T3.2.11.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep">(Errounda and Liu, <a href="#bib.bib38" title="" class="ltx_ref">2023</a>)</cite></span></span>
</span></span><span id="A1.T3.2.11.2.4" class="ltx_text"></span><span id="A1.T3.2.11.2.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="A1.T3.2.11.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_b ltx_border_r ltx_border_t" style="width:149.4pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T3.2.11.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T3.2.11.3.1.1" class="ltx_p"><span id="A1.T3.2.11.3.1.1.1" class="ltx_text" style="font-size:80%;">AdaVFL adapts privacy protection to feature contributions and model convergence in vertical federated learning. It uses zero-Concentrated Differential Privacy (zCDP) for privacy accounting, aiming to balance privacy protection and utility.</span></span>
</span>
</td>
<td id="A1.T3.2.11.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_b ltx_border_r ltx_border_t" style="width:149.4pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T3.2.11.4.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T3.2.11.4.1.1" class="ltx_p"><span id="A1.T3.2.11.4.1.1.1" class="ltx_text" style="font-size:80%;">It assumes honest-but-curious adversaries and secure communication protocol, which may not hold in practical scenarios. Besides, the adaptive budgeting scheme relies on the model convergence dynamics, which may vary with different datasets and learning tasks.</span></span>
</span>
</td>
</tr>
</table>
</figure>
<figure id="A1.T4" class="ltx_table">
<figcaption class="ltx_caption ltx_centering" style="font-size:80%;"><span class="ltx_tag ltx_tag_table">Table 4. </span><span id="A1.T4.5.1" class="ltx_text ltx_font_bold">Works on Inference Attack.</span></figcaption>
<table id="A1.T4.2" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="A1.T4.2.2" class="ltx_tr">
<td id="A1.T4.2.2.3" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="A1.T4.2.2.3.1" class="ltx_text" style="font-size:80%;">Topics</span></td>
<td id="A1.T4.2.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T4.2.2.4.1" class="ltx_text"></span><span id="A1.T4.2.2.4.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T4.2.2.4.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T4.2.2.4.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T4.2.2.4.3.1.1" class="ltx_tr">
<span id="A1.T4.2.2.4.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Ref.</span></span>
</span></span><span id="A1.T4.2.2.4.4" class="ltx_text"></span><span id="A1.T4.2.2.4.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="A1.T4.1.1.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:156.5pt;padding-left:2.0pt;padding-right:2.0pt;"><span id="A1.T4.1.1.1.1" class="ltx_inline-logical-block ltx_align_top">
<span id="A1.T4.1.1.1.1.p1" class="ltx_para ltx_noindent">
<span id="A1.T4.1.1.1.1.p1.1" class="ltx_p"><span id="A1.T4.1.1.1.1.p1.1.1" class="ltx_text"></span><span id="A1.T4.1.1.1.1.p1.1.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T4.1.1.1.1.p1.1.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T4.1.1.1.1.p1.1.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T4.1.1.1.1.p1.1.3.1.1" class="ltx_tr">
<span id="A1.T4.1.1.1.1.p1.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Key Contributions</span></span>
</span></span><span id="A1.T4.1.1.1.1.p1.1.4" class="ltx_text"></span><span id="A1.T4.1.1.1.1.p1.1.5" class="ltx_text" style="font-size:80%;"></span></span>
</span></span></td>
<td id="A1.T4.2.2.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:156.5pt;padding-left:2.0pt;padding-right:2.0pt;"><span id="A1.T4.2.2.2.1" class="ltx_inline-logical-block ltx_align_top">
<span id="A1.T4.2.2.2.1.p1" class="ltx_para ltx_noindent">
<span id="A1.T4.2.2.2.1.p1.1" class="ltx_p"><span id="A1.T4.2.2.2.1.p1.1.1" class="ltx_text"></span><span id="A1.T4.2.2.2.1.p1.1.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T4.2.2.2.1.p1.1.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T4.2.2.2.1.p1.1.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T4.2.2.2.1.p1.1.3.1.1" class="ltx_tr">
<span id="A1.T4.2.2.2.1.p1.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Limitations</span></span>
</span></span><span id="A1.T4.2.2.2.1.p1.1.4" class="ltx_text"></span><span id="A1.T4.2.2.2.1.p1.1.5" class="ltx_text" style="font-size:80%;"></span></span>
</span></span></td>
</tr>
<tr id="A1.T4.2.3" class="ltx_tr">
<td id="A1.T4.2.3.1" class="ltx_td ltx_border_l ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"></td>
<td id="A1.T4.2.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T4.2.3.2.1" class="ltx_text"></span><span id="A1.T4.2.3.2.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T4.2.3.2.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T4.2.3.2.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T4.2.3.2.3.1.1" class="ltx_tr">
<span id="A1.T4.2.3.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep">(Luo et al<span class="ltx_text">.</span>, <a href="#bib.bib121" title="" class="ltx_ref">2021</a>)</cite></span></span>
</span></span><span id="A1.T4.2.3.2.4" class="ltx_text"></span><span id="A1.T4.2.3.2.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="A1.T4.2.3.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:156.5pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T4.2.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T4.2.3.3.1.1" class="ltx_p"><span id="A1.T4.2.3.3.1.1.1" class="ltx_text" style="font-size:80%;">Constructs specific attacks with both single and multiple prediction outputs, with precise inference and generative inference, without any background information about the target data distribution.</span></span>
</span>
</td>
<td id="A1.T4.2.3.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:156.5pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T4.2.3.4.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T4.2.3.4.1.1" class="ltx_p"><span id="A1.T4.2.3.4.1.1.1" class="ltx_text" style="font-size:80%;">The effectiveness of the attacks depends on the correlation between the features of the adversary and passive clients.</span></span>
</span>
</td>
</tr>
<tr id="A1.T4.2.4" class="ltx_tr">
<td id="A1.T4.2.4.1" class="ltx_td ltx_border_l ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;"></td>
<td id="A1.T4.2.4.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T4.2.4.2.1" class="ltx_text"></span><span id="A1.T4.2.4.2.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T4.2.4.2.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T4.2.4.2.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T4.2.4.2.3.1.1" class="ltx_tr">
<span id="A1.T4.2.4.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep">(Jin et al<span class="ltx_text">.</span>, <a href="#bib.bib83" title="" class="ltx_ref">2021</a>)</cite></span></span>
</span></span><span id="A1.T4.2.4.2.4" class="ltx_text"></span><span id="A1.T4.2.4.2.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="A1.T4.2.4.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:156.5pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T4.2.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T4.2.4.3.1.1" class="ltx_p"><span id="A1.T4.2.4.3.1.1.1" class="ltx_text" style="font-size:80%;">CAFE is designed to recover data in batches from shared aggregated gradients by leveraging data index and internal representation alignments.</span></span>
</span>
</td>
<td id="A1.T4.2.4.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:156.5pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T4.2.4.4.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T4.2.4.4.1.1" class="ltx_p"><span id="A1.T4.2.4.4.1.1.1" class="ltx_text" style="font-size:80%;">The effectiveness of CAFE is influenced by the model architecture and weight distribution initialization.</span></span>
</span>
</td>
</tr>
<tr id="A1.T4.2.5" class="ltx_tr">
<td id="A1.T4.2.5.1" class="ltx_td ltx_border_l ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;"></td>
<td id="A1.T4.2.5.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T4.2.5.2.1" class="ltx_text"></span><span id="A1.T4.2.5.2.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T4.2.5.2.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T4.2.5.2.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T4.2.5.2.3.1.1" class="ltx_tr">
<span id="A1.T4.2.5.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep">(Rassouli et al<span class="ltx_text">.</span>, <a href="#bib.bib142" title="" class="ltx_ref">2022</a>)</cite></span></span>
</span></span><span id="A1.T4.2.5.2.4" class="ltx_text"></span><span id="A1.T4.2.5.2.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="A1.T4.2.5.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:156.5pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T4.2.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T4.2.5.3.1.1" class="ltx_p"><span id="A1.T4.2.5.3.1.1.1" class="ltx_text" style="font-size:80%;">Propose to utilize the Chebyshev center concept for attacks and provide theoretical performance guarantees.</span></span>
</span>
</td>
<td id="A1.T4.2.5.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:156.5pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T4.2.5.4.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T4.2.5.4.1.1" class="ltx_p"><span id="A1.T4.2.5.4.1.1.1" class="ltx_text" style="font-size:80%;">Computing the Chebyshev center is complex and computationally intensive.</span></span>
</span>
</td>
</tr>
<tr id="A1.T4.2.6" class="ltx_tr">
<td id="A1.T4.2.6.1" class="ltx_td ltx_border_l ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;"></td>
<td id="A1.T4.2.6.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T4.2.6.2.1" class="ltx_text"></span><span id="A1.T4.2.6.2.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T4.2.6.2.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T4.2.6.2.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T4.2.6.2.3.1.1" class="ltx_tr">
<span id="A1.T4.2.6.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep">(Ye et al<span class="ltx_text">.</span>, <a href="#bib.bib188" title="" class="ltx_ref">2022</a>)</cite></span></span>
</span></span><span id="A1.T4.2.6.2.4" class="ltx_text"></span><span id="A1.T4.2.6.2.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="A1.T4.2.6.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:156.5pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T4.2.6.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T4.2.6.3.1.1" class="ltx_p"><span id="A1.T4.2.6.3.1.1.1" class="ltx_text" style="font-size:80%;">It proves that while reconstructing general features is NP-hard, binary feature reconstruction is feasible and presents a search-based attack algorithm.</span></span>
</span>
</td>
<td id="A1.T4.2.6.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:156.5pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T4.2.6.4.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T4.2.6.4.1.1" class="ltx_p"><span id="A1.T4.2.6.4.1.1.1" class="ltx_text" style="font-size:80%;">The attack primarily targets binary features. It may not be directly applicable to other types of data or features.</span></span>
</span>
</td>
</tr>
<tr id="A1.T4.2.7" class="ltx_tr">
<td id="A1.T4.2.7.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="A1.T4.2.7.1.1" class="ltx_text" style="font-size:80%;"><span id="A1.T4.2.7.1.1.1" class="ltx_text"></span> <span id="A1.T4.2.7.1.1.2" class="ltx_text">
<span id="A1.T4.2.7.1.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T4.2.7.1.1.2.1.1" class="ltx_tr">
<span id="A1.T4.2.7.1.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Feature</span></span>
<span id="A1.T4.2.7.1.1.2.1.2" class="ltx_tr">
<span id="A1.T4.2.7.1.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Inference</span></span>
<span id="A1.T4.2.7.1.1.2.1.3" class="ltx_tr">
<span id="A1.T4.2.7.1.1.2.1.3.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Attack</span></span>
</span></span> <span id="A1.T4.2.7.1.1.3" class="ltx_text"></span></span></td>
<td id="A1.T4.2.7.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T4.2.7.2.1" class="ltx_text"></span><span id="A1.T4.2.7.2.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T4.2.7.2.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T4.2.7.2.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T4.2.7.2.3.1.1" class="ltx_tr">
<span id="A1.T4.2.7.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep">(Yang et al<span class="ltx_text">.</span>, <a href="#bib.bib181" title="" class="ltx_ref">2023c</a>)</cite></span></span>
</span></span><span id="A1.T4.2.7.2.4" class="ltx_text"></span><span id="A1.T4.2.7.2.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="A1.T4.2.7.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:156.5pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T4.2.7.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T4.2.7.3.1.1" class="ltx_p"><span id="A1.T4.2.7.3.1.1.1" class="ltx_text" style="font-size:80%;">Propose utilizing an inference model to minimize the distance between predictions from inferred and target features. It employs zeroth-order gradient estimation to train the inference model without direct access to the global model and other local models.</span></span>
</span>
</td>
<td id="A1.T4.2.7.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:156.5pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T4.2.7.4.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T4.2.7.4.1.1" class="ltx_p"><span id="A1.T4.2.7.4.1.1.1" class="ltx_text" style="font-size:80%;">The effectiveness of the attack is influenced by the correlation between known features and target features. Higher correlations lead to better attack performance.</span></span>
</span>
</td>
</tr>
<tr id="A1.T4.2.8" class="ltx_tr">
<td id="A1.T4.2.8.1" class="ltx_td ltx_border_l ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"></td>
<td id="A1.T4.2.8.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T4.2.8.2.1" class="ltx_text"></span><span id="A1.T4.2.8.2.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T4.2.8.2.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T4.2.8.2.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T4.2.8.2.3.1.1" class="ltx_tr">
<span id="A1.T4.2.8.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep">(Liu et al<span class="ltx_text">.</span>, <a href="#bib.bib117" title="" class="ltx_ref">2021f</a>)</cite></span></span>
</span></span><span id="A1.T4.2.8.2.4" class="ltx_text"></span><span id="A1.T4.2.8.2.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="A1.T4.2.8.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:156.5pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T4.2.8.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T4.2.8.3.1.1" class="ltx_p"><span id="A1.T4.2.8.3.1.1.1" class="ltx_text" style="font-size:80%;">It introduces a gradient inversion model to reconstruct private labels with high accuracy by exploiting batch-averaged local gradients. It also presents a gradient-replacement attack that allows label replacement in black-boxed VFL without altering VFL protocols.</span></span>
</span>
</td>
<td id="A1.T4.2.8.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:156.5pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T4.2.8.4.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T4.2.8.4.1.1" class="ltx_p"><span id="A1.T4.2.8.4.1.1.1" class="ltx_text" style="font-size:80%;">The success of the attack depends on the batch size being smaller than the dimension of the final fully connected layer.</span></span>
</span>
</td>
</tr>
<tr id="A1.T4.2.9" class="ltx_tr">
<td id="A1.T4.2.9.1" class="ltx_td ltx_border_l ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;"></td>
<td id="A1.T4.2.9.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T4.2.9.2.1" class="ltx_text"></span><span id="A1.T4.2.9.2.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T4.2.9.2.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T4.2.9.2.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T4.2.9.2.3.1.1" class="ltx_tr">
<span id="A1.T4.2.9.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a href="#bib.bib98" title="" class="ltx_ref">2021</a>)</cite></span></span>
</span></span><span id="A1.T4.2.9.2.4" class="ltx_text"></span><span id="A1.T4.2.9.2.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="A1.T4.2.9.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:156.5pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T4.2.9.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T4.2.9.3.1.1" class="ltx_p"><span id="A1.T4.2.9.3.1.1.1" class="ltx_text" style="font-size:80%;">Propose a norm-based scoring function, which exploits the observation that the norm of the gradient vector potentially reveals label information. It uses the gradient norm as a predictor of the unseen label.</span></span>
</span>
</td>
<td id="A1.T4.2.9.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:156.5pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T4.2.9.4.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T4.2.9.4.1.1" class="ltx_p"><span id="A1.T4.2.9.4.1.1.1" class="ltx_text" style="font-size:80%;">It is tailored to a specific threat model within two-party split learning, which may not generalize to other models or settings.</span></span>
</span>
</td>
</tr>
<tr id="A1.T4.2.10" class="ltx_tr">
<td id="A1.T4.2.10.1" class="ltx_td ltx_border_l ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;"></td>
<td id="A1.T4.2.10.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T4.2.10.2.1" class="ltx_text"></span><span id="A1.T4.2.10.2.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T4.2.10.2.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T4.2.10.2.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T4.2.10.2.3.1.1" class="ltx_tr">
<span id="A1.T4.2.10.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep">(Fu et al<span class="ltx_text">.</span>, <a href="#bib.bib48" title="" class="ltx_ref">2022b</a>)</cite></span></span>
</span></span><span id="A1.T4.2.10.2.4" class="ltx_text"></span><span id="A1.T4.2.10.2.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="A1.T4.2.10.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:156.5pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T4.2.10.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T4.2.10.3.1.1" class="ltx_p"><span id="A1.T4.2.10.3.1.1.1" class="ltx_text" style="font-size:80%;">Introduce label inference attacks exploiting the local model structure and gradient update mechanism in VFL. It proposes passive attacks using model completion, active attacks with a malicious local optimizer, and direct attacks by analyzing gradient signs.</span></span>
</span>
</td>
<td id="A1.T4.2.10.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:156.5pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T4.2.10.4.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T4.2.10.4.1.1" class="ltx_p"><span id="A1.T4.2.10.4.1.1.1" class="ltx_text" style="font-size:80%;">The direct label inference attack is limited to training examples and requires additional steps for inference on new samples.</span></span>
</span>
</td>
</tr>
<tr id="A1.T4.2.11" class="ltx_tr">
<td id="A1.T4.2.11.1" class="ltx_td ltx_border_l ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;"></td>
<td id="A1.T4.2.11.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T4.2.11.2.1" class="ltx_text"></span><span id="A1.T4.2.11.2.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T4.2.11.2.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T4.2.11.2.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T4.2.11.2.3.1.1" class="ltx_tr">
<span id="A1.T4.2.11.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep">(Sun et al<span class="ltx_text">.</span>, <a href="#bib.bib153" title="" class="ltx_ref">2022</a>)</cite></span></span>
</span></span><span id="A1.T4.2.11.2.4" class="ltx_text"></span><span id="A1.T4.2.11.2.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="A1.T4.2.11.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:156.5pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T4.2.11.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T4.2.11.3.1.1" class="ltx_p"><span id="A1.T4.2.11.3.1.1.1" class="ltx_text" style="font-size:80%;">Introduce a label inference attack method that exploits the correlation between intermediate embeddings and private labels to steal sensitive label information.</span></span>
</span>
</td>
<td id="A1.T4.2.11.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:156.5pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T4.2.11.4.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T4.2.11.4.1.1" class="ltx_p"><span id="A1.T4.2.11.4.1.1.1" class="ltx_text" style="font-size:80%;">The label party may need additional computational costs to re-learn the correlation between embeddings and labels to maintain model utility.</span></span>
</span>
</td>
</tr>
<tr id="A1.T4.2.12" class="ltx_tr">
<td id="A1.T4.2.12.1" class="ltx_td ltx_border_l ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;"></td>
<td id="A1.T4.2.12.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T4.2.12.2.1" class="ltx_text"></span><span id="A1.T4.2.12.2.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T4.2.12.2.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T4.2.12.2.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T4.2.12.2.3.1.1" class="ltx_tr">
<span id="A1.T4.2.12.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep">(Kariyappa and Qureshi, <a href="#bib.bib87" title="" class="ltx_ref">2023</a>)</cite></span></span>
</span></span><span id="A1.T4.2.12.2.4" class="ltx_text"></span><span id="A1.T4.2.12.2.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="A1.T4.2.12.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:156.5pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T4.2.12.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T4.2.12.3.1.1" class="ltx_p"><span id="A1.T4.2.12.3.1.1.1" class="ltx_text" style="font-size:80%;">Exploit frames the attack as a supervised learning task using gradient information obtained during split learning.</span></span>
</span>
</td>
<td id="A1.T4.2.12.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:156.5pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T4.2.12.4.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T4.2.12.4.1.1" class="ltx_p"><span id="A1.T4.2.12.4.1.1.1" class="ltx_text" style="font-size:80%;">The efficacy of Exploit varies based on the chosen splitting layer.</span></span>
</span>
</td>
</tr>
<tr id="A1.T4.2.13" class="ltx_tr">
<td id="A1.T4.2.13.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="A1.T4.2.13.1.1" class="ltx_text" style="font-size:80%;"><span id="A1.T4.2.13.1.1.1" class="ltx_text"></span> <span id="A1.T4.2.13.1.1.2" class="ltx_text">
<span id="A1.T4.2.13.1.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T4.2.13.1.1.2.1.1" class="ltx_tr">
<span id="A1.T4.2.13.1.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Label</span></span>
<span id="A1.T4.2.13.1.1.2.1.2" class="ltx_tr">
<span id="A1.T4.2.13.1.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Inference</span></span>
<span id="A1.T4.2.13.1.1.2.1.3" class="ltx_tr">
<span id="A1.T4.2.13.1.1.2.1.3.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Attack</span></span>
</span></span> <span id="A1.T4.2.13.1.1.3" class="ltx_text"></span></span></td>
<td id="A1.T4.2.13.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T4.2.13.2.1" class="ltx_text"></span><span id="A1.T4.2.13.2.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T4.2.13.2.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T4.2.13.2.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T4.2.13.2.3.1.1" class="ltx_tr">
<span id="A1.T4.2.13.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep">(Qiu et al<span class="ltx_text">.</span>, <a href="#bib.bib136" title="" class="ltx_ref">2022</a>)</cite></span></span>
</span></span><span id="A1.T4.2.13.2.4" class="ltx_text"></span><span id="A1.T4.2.13.2.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="A1.T4.2.13.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_b ltx_border_r ltx_border_t" style="width:156.5pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T4.2.13.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T4.2.13.3.1.1" class="ltx_p"><span id="A1.T4.2.13.3.1.1.1" class="ltx_text" style="font-size:80%;">Propose a numerical approximation method designed to approximate encrypted representations, enabling the inference of private label-related relations.</span></span>
</span>
</td>
<td id="A1.T4.2.13.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_b ltx_border_r ltx_border_t" style="width:156.5pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T4.2.13.4.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T4.2.13.4.1.1" class="ltx_p"><span id="A1.T4.2.13.4.1.1.1" class="ltx_text" style="font-size:80%;">The effectiveness of the attack is contingent on the knowledge of the adversary such as prediction results and global model parameters.</span></span>
</span>
</td>
</tr>
</table>
</figure>
<figure id="A1.T5" class="ltx_table">
<figcaption class="ltx_caption ltx_centering" style="font-size:80%;"><span class="ltx_tag ltx_tag_table">Table 5. </span><span id="A1.T5.5.1" class="ltx_text ltx_font_bold">Works on Destructive Attack.</span></figcaption>
<table id="A1.T5.2" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="A1.T5.2.2" class="ltx_tr">
<td id="A1.T5.2.2.3" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="A1.T5.2.2.3.1" class="ltx_text" style="font-size:80%;">Topics</span></td>
<td id="A1.T5.2.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T5.2.2.4.1" class="ltx_text"></span><span id="A1.T5.2.2.4.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T5.2.2.4.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T5.2.2.4.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T5.2.2.4.3.1.1" class="ltx_tr">
<span id="A1.T5.2.2.4.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Ref.</span></span>
</span></span><span id="A1.T5.2.2.4.4" class="ltx_text"></span><span id="A1.T5.2.2.4.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="A1.T5.1.1.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:184.9pt;padding-left:2.0pt;padding-right:2.0pt;"><span id="A1.T5.1.1.1.1" class="ltx_inline-logical-block ltx_align_top">
<span id="A1.T5.1.1.1.1.p1" class="ltx_para ltx_noindent">
<span id="A1.T5.1.1.1.1.p1.1" class="ltx_p"><span id="A1.T5.1.1.1.1.p1.1.1" class="ltx_text"></span><span id="A1.T5.1.1.1.1.p1.1.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T5.1.1.1.1.p1.1.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T5.1.1.1.1.p1.1.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T5.1.1.1.1.p1.1.3.1.1" class="ltx_tr">
<span id="A1.T5.1.1.1.1.p1.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Key Contributions</span></span>
</span></span><span id="A1.T5.1.1.1.1.p1.1.4" class="ltx_text"></span><span id="A1.T5.1.1.1.1.p1.1.5" class="ltx_text" style="font-size:80%;"></span></span>
</span></span></td>
<td id="A1.T5.2.2.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:119.5pt;padding-left:2.0pt;padding-right:2.0pt;"><span id="A1.T5.2.2.2.1" class="ltx_inline-logical-block ltx_align_top">
<span id="A1.T5.2.2.2.1.p1" class="ltx_para ltx_noindent">
<span id="A1.T5.2.2.2.1.p1.1" class="ltx_p"><span id="A1.T5.2.2.2.1.p1.1.1" class="ltx_text"></span><span id="A1.T5.2.2.2.1.p1.1.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T5.2.2.2.1.p1.1.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T5.2.2.2.1.p1.1.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T5.2.2.2.1.p1.1.3.1.1" class="ltx_tr">
<span id="A1.T5.2.2.2.1.p1.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Limitations</span></span>
</span></span><span id="A1.T5.2.2.2.1.p1.1.4" class="ltx_text"></span><span id="A1.T5.2.2.2.1.p1.1.5" class="ltx_text" style="font-size:80%;"></span></span>
</span></span></td>
</tr>
<tr id="A1.T5.2.3" class="ltx_tr">
<td id="A1.T5.2.3.1" class="ltx_td ltx_border_l ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"></td>
<td id="A1.T5.2.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T5.2.3.2.1" class="ltx_text"></span><span id="A1.T5.2.3.2.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T5.2.3.2.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T5.2.3.2.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T5.2.3.2.3.1.1" class="ltx_tr">
<span id="A1.T5.2.3.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep">(Liu et al<span class="ltx_text">.</span>, <a href="#bib.bib115" title="" class="ltx_ref">2020c</a>)</cite></span></span>
</span></span><span id="A1.T5.2.3.2.4" class="ltx_text"></span><span id="A1.T5.2.3.2.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="A1.T5.2.3.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:184.9pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T5.2.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T5.2.3.3.1.1" class="ltx_p"><span id="A1.T5.2.3.3.1.1.1" class="ltx_text" style="font-size:80%;">Propose recording the intermediate gradient of a clean sample with the targeted label and using this recorded gradient for poisoned samples.</span></span>
</span>
</td>
<td id="A1.T5.2.3.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:119.5pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T5.2.3.4.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T5.2.3.4.1.1" class="ltx_p"><span id="A1.T5.2.3.4.1.1.1" class="ltx_text" style="font-size:80%;">The modification of gradients will influence the performance on the clean data.</span></span>
</span>
</td>
</tr>
<tr id="A1.T5.2.4" class="ltx_tr">
<td id="A1.T5.2.4.1" class="ltx_td ltx_border_l ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;"></td>
<td id="A1.T5.2.4.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T5.2.4.2.1" class="ltx_text"></span><span id="A1.T5.2.4.2.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T5.2.4.2.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T5.2.4.2.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T5.2.4.2.3.1.1" class="ltx_tr">
<span id="A1.T5.2.4.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep">(Chen et al<span class="ltx_text">.</span>, <a href="#bib.bib25" title="" class="ltx_ref">2024a</a>)</cite></span></span>
</span></span><span id="A1.T5.2.4.2.4" class="ltx_text"></span><span id="A1.T5.2.4.2.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="A1.T5.2.4.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:184.9pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T5.2.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T5.2.4.3.1.1" class="ltx_p"><span id="A1.T5.2.4.3.1.1.1" class="ltx_text" style="font-size:80%;">UAB utilizes bi-level optimization to optimize universal backdoor trigger generation and model parameters during VFL training, without additional data from other clients.</span></span>
</span>
</td>
<td id="A1.T5.2.4.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:119.5pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T5.2.4.4.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T5.2.4.4.1.1" class="ltx_p"><span id="A1.T5.2.4.4.1.1.1" class="ltx_text" style="font-size:80%;">The performance will be affected if the dataset is imbalanced.</span></span>
</span>
</td>
</tr>
<tr id="A1.T5.2.5" class="ltx_tr">
<td id="A1.T5.2.5.1" class="ltx_td ltx_border_l ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;"></td>
<td id="A1.T5.2.5.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T5.2.5.2.1" class="ltx_text"></span><span id="A1.T5.2.5.2.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T5.2.5.2.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T5.2.5.2.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T5.2.5.2.3.1.1" class="ltx_tr">
<span id="A1.T5.2.5.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep">(Gu and Bai, <a href="#bib.bib60" title="" class="ltx_ref">2023</a>)</cite></span></span>
</span></span><span id="A1.T5.2.5.2.4" class="ltx_text"></span><span id="A1.T5.2.5.2.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="A1.T5.2.5.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:184.9pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T5.2.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T5.2.5.3.1.1" class="ltx_p"><span id="A1.T5.2.5.3.1.1.1" class="ltx_text" style="font-size:80%;">Involve an adversarial participant in VFL who fine-tunes its local model to output specific latent representations for backdoor instances. It can be executed even without access to labels, using only local latent representations.</span></span>
</span>
</td>
<td id="A1.T5.2.5.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:119.5pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T5.2.5.4.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T5.2.5.4.1.1" class="ltx_p"><span id="A1.T5.2.5.4.1.1.1" class="ltx_text" style="font-size:80%;">The attack performance may vary depending on the dataset and the number of classes.</span></span>
</span>
</td>
</tr>
<tr id="A1.T5.2.6" class="ltx_tr">
<td id="A1.T5.2.6.1" class="ltx_td ltx_border_l ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;"></td>
<td id="A1.T5.2.6.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T5.2.6.2.1" class="ltx_text"></span><span id="A1.T5.2.6.2.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T5.2.6.2.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T5.2.6.2.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T5.2.6.2.3.1.1" class="ltx_tr">
<span id="A1.T5.2.6.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep">(He et al<span class="ltx_text">.</span>, <a href="#bib.bib67" title="" class="ltx_ref">2023</a>)</cite></span></span>
</span></span><span id="A1.T5.2.6.2.4" class="ltx_text"></span><span id="A1.T5.2.6.2.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="A1.T5.2.6.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:184.9pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T5.2.6.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T5.2.6.3.1.1" class="ltx_p"><span id="A1.T5.2.6.3.1.1.1" class="ltx_text" style="font-size:80%;">Propose to inject a stealthy backdoor into the global model during training. It is achieved by replacing the local embeddings of a small number of target-class samples with a carefully constructed trigger vector, without modifying any labels.</span></span>
</span>
</td>
<td id="A1.T5.2.6.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:119.5pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T5.2.6.4.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T5.2.6.4.1.1" class="ltx_p"><span id="A1.T5.2.6.4.1.1.1" class="ltx_text" style="font-size:80%;">The attack method is non-trivial and requires careful construction of the trigger vector.</span></span>
</span>
</td>
</tr>
<tr id="A1.T5.2.7" class="ltx_tr">
<td id="A1.T5.2.7.1" class="ltx_td ltx_border_l ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;"></td>
<td id="A1.T5.2.7.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T5.2.7.2.1" class="ltx_text"></span><span id="A1.T5.2.7.2.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T5.2.7.2.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T5.2.7.2.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T5.2.7.2.3.1.1" class="ltx_tr">
<span id="A1.T5.2.7.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep">(Bai et al<span class="ltx_text">.</span>, <a href="#bib.bib7" title="" class="ltx_ref">2023</a>)</cite></span></span>
</span></span><span id="A1.T5.2.7.2.4" class="ltx_text"></span><span id="A1.T5.2.7.2.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="A1.T5.2.7.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:184.9pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T5.2.7.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T5.2.7.3.1.1" class="ltx_p"><span id="A1.T5.2.7.3.1.1.1" class="ltx_text" style="font-size:80%;">VILLAIN introduces a label inference algorithm to insert a backdoor into the global model. It enhances the backdoor attack power by designing a stealthy additive trigger and introducing backdoor augmentation strategies to impose a larger influence on the global model.</span></span>
</span>
</td>
<td id="A1.T5.2.7.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:119.5pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T5.2.7.4.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T5.2.7.4.1.1" class="ltx_p"><span id="A1.T5.2.7.4.1.1.1" class="ltx_text" style="font-size:80%;">Its effectiveness relies on the sophisticated label inference algorithm, which introduces additional complexity.</span></span>
</span>
</td>
</tr>
<tr id="A1.T5.2.8" class="ltx_tr">
<td id="A1.T5.2.8.1" class="ltx_td ltx_border_l ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;"></td>
<td id="A1.T5.2.8.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T5.2.8.2.1" class="ltx_text"></span><span id="A1.T5.2.8.2.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T5.2.8.2.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T5.2.8.2.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T5.2.8.2.3.1.1" class="ltx_tr">
<span id="A1.T5.2.8.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep">(Xuan et al<span class="ltx_text">.</span>, <a href="#bib.bib177" title="" class="ltx_ref">2023</a>)</cite></span></span>
</span></span><span id="A1.T5.2.8.2.4" class="ltx_text"></span><span id="A1.T5.2.8.2.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="A1.T5.2.8.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:184.9pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T5.2.8.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T5.2.8.3.1.1" class="ltx_p"><span id="A1.T5.2.8.3.1.1.1" class="ltx_text" style="font-size:80%;">BadVFL uses a Source Data Detection (SDD) module to trace data categories based on gradients and a Source Data Perturbation (SDP) scheme to enhance the decision dependency between the trigger and attack target.</span></span>
</span>
</td>
<td id="A1.T5.2.8.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:119.5pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T5.2.8.4.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T5.2.8.4.1.1" class="ltx_p"><span id="A1.T5.2.8.4.1.1.1" class="ltx_text" style="font-size:80%;">The effectiveness of the attack may vary with the complexity of the global model structure, affecting gradient-based calculations.</span></span>
</span>
</td>
</tr>
<tr id="A1.T5.2.9" class="ltx_tr">
<td id="A1.T5.2.9.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="A1.T5.2.9.1.1" class="ltx_text" style="font-size:80%;"><span id="A1.T5.2.9.1.1.1" class="ltx_text"></span> <span id="A1.T5.2.9.1.1.2" class="ltx_text">
<span id="A1.T5.2.9.1.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T5.2.9.1.1.2.1.1" class="ltx_tr">
<span id="A1.T5.2.9.1.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Backdoor</span></span>
<span id="A1.T5.2.9.1.1.2.1.2" class="ltx_tr">
<span id="A1.T5.2.9.1.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Attack</span></span>
</span></span> <span id="A1.T5.2.9.1.1.3" class="ltx_text"></span></span></td>
<td id="A1.T5.2.9.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T5.2.9.2.1" class="ltx_text"></span><span id="A1.T5.2.9.2.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T5.2.9.2.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T5.2.9.2.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T5.2.9.2.3.1.1" class="ltx_tr">
<span id="A1.T5.2.9.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep">(Chen et al<span class="ltx_text">.</span>, <a href="#bib.bib24" title="" class="ltx_ref">2022</a>)</cite></span></span>
</span></span><span id="A1.T5.2.9.2.4" class="ltx_text"></span><span id="A1.T5.2.9.2.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="A1.T5.2.9.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:184.9pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T5.2.9.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T5.2.9.3.1.1" class="ltx_p"><span id="A1.T5.2.9.3.1.1.1" class="ltx_text" style="font-size:80%;">Graph-Fraudster exploits the vulnerability of VFL for graph data by generating adversarial perturbations. It leverages noise-added global node embeddings and gradients of pairwise nodes to confuse the global model.</span></span>
</span>
</td>
<td id="A1.T5.2.9.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:119.5pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T5.2.9.4.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T5.2.9.4.1.1" class="ltx_p"><span id="A1.T5.2.9.4.1.1.1" class="ltx_text" style="font-size:80%;">The success of the attack relies on the leakage of global node embeddings.</span></span>
</span>
</td>
</tr>
<tr id="A1.T5.2.10" class="ltx_tr">
<td id="A1.T5.2.10.1" class="ltx_td ltx_border_l ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"></td>
<td id="A1.T5.2.10.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T5.2.10.2.1" class="ltx_text"></span><span id="A1.T5.2.10.2.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T5.2.10.2.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T5.2.10.2.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T5.2.10.2.3.1.1" class="ltx_tr">
<span id="A1.T5.2.10.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep">(Lai et al<span class="ltx_text">.</span>, <a href="#bib.bib93" title="" class="ltx_ref">2023</a>)</cite></span></span>
</span></span><span id="A1.T5.2.10.2.4" class="ltx_text"></span><span id="A1.T5.2.10.2.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="A1.T5.2.10.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:184.9pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T5.2.10.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T5.2.10.3.1.1" class="ltx_p"><span id="A1.T5.2.10.3.1.1.1" class="ltx_text" style="font-size:80%;">VFedAD proposes three kinds of data-level poison attack methods: Random Failure, which adds noises to raw data for performing attacks; Random Mismatch, where the attack may shuffle the IDs in clients to disrupt the collaboration; Targeted Tampering, where the attacker attempts to replace some samples with target features.</span></span>
</span>
</td>
<td id="A1.T5.2.10.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:119.5pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T5.2.10.4.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T5.2.10.4.1.1" class="ltx_p"><span id="A1.T5.2.10.4.1.1.1" class="ltx_text" style="font-size:80%;">It is easy to detect due to the obvious raw data modification.</span></span>
</span>
</td>
</tr>
<tr id="A1.T5.2.11" class="ltx_tr">
<td id="A1.T5.2.11.1" class="ltx_td ltx_border_l ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;"></td>
<td id="A1.T5.2.11.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T5.2.11.2.1" class="ltx_text"></span><span id="A1.T5.2.11.2.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T5.2.11.2.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T5.2.11.2.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T5.2.11.2.3.1.1" class="ltx_tr">
<span id="A1.T5.2.11.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep">(Qiu et al<span class="ltx_text">.</span>, <a href="#bib.bib138" title="" class="ltx_ref">2024b</a>)</cite></span></span>
</span></span><span id="A1.T5.2.11.2.4" class="ltx_text"></span><span id="A1.T5.2.11.2.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="A1.T5.2.11.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:184.9pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T5.2.11.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T5.2.11.3.1.1" class="ltx_p"><span id="A1.T5.2.11.3.1.1.1" class="ltx_text" style="font-size:80%;">Introduce two attacks, the replay attack and the generation attack, to demonstrate the vulnerability of VFL systems to the Byzantine Generals Problem.</span></span>
</span>
</td>
<td id="A1.T5.2.11.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:119.5pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T5.2.11.4.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T5.2.11.4.1.1" class="ltx_p"><span id="A1.T5.2.11.4.1.1.1" class="ltx_text" style="font-size:80%;">The success of attacks is affected by the completeness of features controlled by the adversary. Incomplete features can make attacks more challenging.</span></span>
</span>
</td>
</tr>
<tr id="A1.T5.2.12" class="ltx_tr">
<td id="A1.T5.2.12.1" class="ltx_td ltx_border_l ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;"></td>
<td id="A1.T5.2.12.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T5.2.12.2.1" class="ltx_text"></span><span id="A1.T5.2.12.2.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T5.2.12.2.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T5.2.12.2.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T5.2.12.2.3.1.1" class="ltx_tr">
<span id="A1.T5.2.12.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep">(Duanyi et al<span class="ltx_text">.</span>, <a href="#bib.bib37" title="" class="ltx_ref">2023</a>)</cite></span></span>
</span></span><span id="A1.T5.2.12.2.4" class="ltx_text"></span><span id="A1.T5.2.12.2.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="A1.T5.2.12.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:184.9pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T5.2.12.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T5.2.12.3.1.1" class="ltx_p"><span id="A1.T5.2.12.3.1.1.1" class="ltx_text" style="font-size:80%;">Propose to disrupt the inference process by adaptively corrupting a subset of clients. It formulates finding optimal attack strategies as an online optimization problem, involving adversarial example generation and corruption pattern selection.</span></span>
</span>
</td>
<td id="A1.T5.2.12.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:119.5pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T5.2.12.4.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T5.2.12.4.1.1" class="ltx_p"><span id="A1.T5.2.12.4.1.1.1" class="ltx_text" style="font-size:80%;">The ability to adjust corruption patterns is based on the effectiveness of previous attacks, which may not always lead to the discovery of the optimal pattern.</span></span>
</span>
</td>
</tr>
<tr id="A1.T5.2.13" class="ltx_tr">
<td id="A1.T5.2.13.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="A1.T5.2.13.1.1" class="ltx_text" style="font-size:80%;"><span id="A1.T5.2.13.1.1.1" class="ltx_text"></span> <span id="A1.T5.2.13.1.1.2" class="ltx_text">
<span id="A1.T5.2.13.1.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T5.2.13.1.1.2.1.1" class="ltx_tr">
<span id="A1.T5.2.13.1.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Poison</span></span>
<span id="A1.T5.2.13.1.1.2.1.2" class="ltx_tr">
<span id="A1.T5.2.13.1.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Attack</span></span>
</span></span> <span id="A1.T5.2.13.1.1.3" class="ltx_text"></span></span></td>
<td id="A1.T5.2.13.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T5.2.13.2.1" class="ltx_text"></span><span id="A1.T5.2.13.2.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T5.2.13.2.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T5.2.13.2.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T5.2.13.2.3.1.1" class="ltx_tr">
<span id="A1.T5.2.13.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep">(Chen et al<span class="ltx_text">.</span>, <a href="#bib.bib28" title="" class="ltx_ref">2024c</a>)</cite></span></span>
</span></span><span id="A1.T5.2.13.2.4" class="ltx_text"></span><span id="A1.T5.2.13.2.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="A1.T5.2.13.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_b ltx_border_r ltx_border_t" style="width:184.9pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T5.2.13.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T5.2.13.3.1.1" class="ltx_p"><span id="A1.T5.2.13.3.1.1.1" class="ltx_text" style="font-size:80%;">It utilizes semi-supervised learning to create a surrogate target model, then employs a GAN-based method to generate adversarial perturbations that degrade the model performance.</span></span>
</span>
</td>
<td id="A1.T5.2.13.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_b ltx_border_r ltx_border_t" style="width:119.5pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T5.2.13.4.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T5.2.13.4.1.1" class="ltx_p"><span id="A1.T5.2.13.4.1.1.1" class="ltx_text" style="font-size:80%;">The effectiveness is influenced by various factors like the number of attacker features and the known labels.</span></span>
</span>
</td>
</tr>
</table>
</figure>
<figure id="A1.T6" class="ltx_table">
<figcaption class="ltx_caption ltx_centering" style="font-size:80%;"><span class="ltx_tag ltx_tag_table">Table 6. </span><span id="A1.T6.5.1" class="ltx_text ltx_font_bold">Works on Defending Against Inference Attack.</span></figcaption>
<table id="A1.T6.2" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="A1.T6.2.2" class="ltx_tr">
<td id="A1.T6.2.2.3" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="A1.T6.2.2.3.1" class="ltx_text" style="font-size:80%;">Topics</span></td>
<td id="A1.T6.2.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.2.2.4.1" class="ltx_text"></span><span id="A1.T6.2.2.4.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T6.2.2.4.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T6.2.2.4.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T6.2.2.4.3.1.1" class="ltx_tr">
<span id="A1.T6.2.2.4.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Ref.</span></span>
</span></span><span id="A1.T6.2.2.4.4" class="ltx_text"></span><span id="A1.T6.2.2.4.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="A1.T6.1.1.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:187.8pt;padding-left:2.0pt;padding-right:2.0pt;"><span id="A1.T6.1.1.1.1" class="ltx_inline-logical-block ltx_align_top">
<span id="A1.T6.1.1.1.1.p1" class="ltx_para ltx_noindent">
<span id="A1.T6.1.1.1.1.p1.1" class="ltx_p"><span id="A1.T6.1.1.1.1.p1.1.1" class="ltx_text"></span><span id="A1.T6.1.1.1.1.p1.1.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T6.1.1.1.1.p1.1.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T6.1.1.1.1.p1.1.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T6.1.1.1.1.p1.1.3.1.1" class="ltx_tr">
<span id="A1.T6.1.1.1.1.p1.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Key Contributions</span></span>
</span></span><span id="A1.T6.1.1.1.1.p1.1.4" class="ltx_text"></span><span id="A1.T6.1.1.1.1.p1.1.5" class="ltx_text" style="font-size:80%;"></span></span>
</span></span></td>
<td id="A1.T6.2.2.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:133.7pt;padding-left:2.0pt;padding-right:2.0pt;"><span id="A1.T6.2.2.2.1" class="ltx_inline-logical-block ltx_align_top">
<span id="A1.T6.2.2.2.1.p1" class="ltx_para ltx_noindent">
<span id="A1.T6.2.2.2.1.p1.1" class="ltx_p"><span id="A1.T6.2.2.2.1.p1.1.1" class="ltx_text"></span><span id="A1.T6.2.2.2.1.p1.1.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T6.2.2.2.1.p1.1.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T6.2.2.2.1.p1.1.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T6.2.2.2.1.p1.1.3.1.1" class="ltx_tr">
<span id="A1.T6.2.2.2.1.p1.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Limitations</span></span>
</span></span><span id="A1.T6.2.2.2.1.p1.1.4" class="ltx_text"></span><span id="A1.T6.2.2.2.1.p1.1.5" class="ltx_text" style="font-size:80%;"></span></span>
</span></span></td>
</tr>
<tr id="A1.T6.2.3" class="ltx_tr">
<td id="A1.T6.2.3.1" class="ltx_td ltx_border_l ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"></td>
<td id="A1.T6.2.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.2.3.2.1" class="ltx_text"></span><span id="A1.T6.2.3.2.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T6.2.3.2.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T6.2.3.2.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T6.2.3.2.3.1.1" class="ltx_tr">
<span id="A1.T6.2.3.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep">(Sun et al<span class="ltx_text">.</span>, <a href="#bib.bib155" title="" class="ltx_ref">2021b</a>)</cite></span></span>
</span></span><span id="A1.T6.2.3.2.4" class="ltx_text"></span><span id="A1.T6.2.3.2.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="A1.T6.2.3.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:187.8pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.2.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T6.2.3.3.1.1" class="ltx_p"><span id="A1.T6.2.3.3.1.1.1" class="ltx_text" style="font-size:80%;">Propose an adversarial training framework, which makes the collaboration model robust against reconstruct attacks from shared gradients.</span></span>
</span>
</td>
<td id="A1.T6.2.3.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:133.7pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.2.3.4.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T6.2.3.4.1.1" class="ltx_p"><span id="A1.T6.2.3.4.1.1.1" class="ltx_text" style="font-size:80%;">The adversarial training process adds complexity and requires careful tuning to achieve the desired balance between privacy and performance.</span></span>
</span>
</td>
</tr>
<tr id="A1.T6.2.4" class="ltx_tr">
<td id="A1.T6.2.4.1" class="ltx_td ltx_border_l ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;"></td>
<td id="A1.T6.2.4.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.2.4.2.1" class="ltx_text"></span><span id="A1.T6.2.4.2.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T6.2.4.2.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T6.2.4.2.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T6.2.4.2.3.1.1" class="ltx_tr">
<span id="A1.T6.2.4.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep">(Zhu et al<span class="ltx_text">.</span>, <a href="#bib.bib207" title="" class="ltx_ref">2024</a>)</cite></span></span>
</span></span><span id="A1.T6.2.4.2.4" class="ltx_text"></span><span id="A1.T6.2.4.2.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="A1.T6.2.4.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:187.8pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.2.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T6.2.4.3.1.1" class="ltx_p"><span id="A1.T6.2.4.3.1.1.1" class="ltx_text" style="font-size:80%;">VFLDefender employs gradient obfuscation to reduce the correlation between model updates and training data, effectively preventing reconstruction attacks.</span></span>
</span>
</td>
<td id="A1.T6.2.4.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:133.7pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.2.4.4.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T6.2.4.4.1.1" class="ltx_p"><span id="A1.T6.2.4.4.1.1.1" class="ltx_text" style="font-size:80%;">It impacts model utility and the balance between privacy and performance needs further exploration.</span></span>
</span>
</td>
</tr>
<tr id="A1.T6.2.5" class="ltx_tr">
<td id="A1.T6.2.5.1" class="ltx_td ltx_border_l ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;"></td>
<td id="A1.T6.2.5.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.2.5.2.1" class="ltx_text"></span><span id="A1.T6.2.5.2.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T6.2.5.2.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T6.2.5.2.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T6.2.5.2.3.1.1" class="ltx_tr">
<span id="A1.T6.2.5.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep">(Chang and Zhu, <a href="#bib.bib18" title="" class="ltx_ref">2024</a>)</cite></span></span>
</span></span><span id="A1.T6.2.5.2.4" class="ltx_text"></span><span id="A1.T6.2.5.2.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="A1.T6.2.5.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:187.8pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.2.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T6.2.5.3.1.1" class="ltx_p"><span id="A1.T6.2.5.3.1.1.1" class="ltx_text" style="font-size:80%;">Propose selectively transmitting a portion of the gradient components to reduce the risk of data leakage while maintaining model training accuracy.</span></span>
</span>
</td>
<td id="A1.T6.2.5.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:133.7pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.2.5.4.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T6.2.5.4.1.1" class="ltx_p"><span id="A1.T6.2.5.4.1.1.1" class="ltx_text" style="font-size:80%;">It requires additional processing of gradient components, which are computationally intensive.</span></span>
</span>
</td>
</tr>
<tr id="A1.T6.2.6" class="ltx_tr">
<td id="A1.T6.2.6.1" class="ltx_td ltx_border_l ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;"></td>
<td id="A1.T6.2.6.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.2.6.2.1" class="ltx_text"></span><span id="A1.T6.2.6.2.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T6.2.6.2.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T6.2.6.2.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T6.2.6.2.3.1.1" class="ltx_tr">
<span id="A1.T6.2.6.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep">(Mao et al<span class="ltx_text">.</span>, <a href="#bib.bib123" title="" class="ltx_ref">2022</a>)</cite></span></span>
</span></span><span id="A1.T6.2.6.2.4" class="ltx_text"></span><span id="A1.T6.2.6.2.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="A1.T6.2.6.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:187.8pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.2.6.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T6.2.6.3.1.1" class="ltx_p"><span id="A1.T6.2.6.3.1.1.1" class="ltx_text" style="font-size:80%;">Implement a privacy budget allocation scheme to perturb information exchange between the passive and the active client, protecting against data reconstruction attacks.</span></span>
</span>
</td>
<td id="A1.T6.2.6.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:133.7pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.2.6.4.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T6.2.6.4.1.1" class="ltx_p"><span id="A1.T6.2.6.4.1.1.1" class="ltx_text" style="font-size:80%;">The dynamic privacy budget allocation method requires careful estimation of parameter importance, introducing additional complexity.</span></span>
</span>
</td>
</tr>
<tr id="A1.T6.2.7" class="ltx_tr">
<td id="A1.T6.2.7.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="A1.T6.2.7.1.1" class="ltx_text" style="font-size:80%;"><span id="A1.T6.2.7.1.1.1" class="ltx_text"></span> <span id="A1.T6.2.7.1.1.2" class="ltx_text">
<span id="A1.T6.2.7.1.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T6.2.7.1.1.2.1.1" class="ltx_tr">
<span id="A1.T6.2.7.1.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Defend</span></span>
<span id="A1.T6.2.7.1.1.2.1.2" class="ltx_tr">
<span id="A1.T6.2.7.1.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Against</span></span>
<span id="A1.T6.2.7.1.1.2.1.3" class="ltx_tr">
<span id="A1.T6.2.7.1.1.2.1.3.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Feature</span></span>
<span id="A1.T6.2.7.1.1.2.1.4" class="ltx_tr">
<span id="A1.T6.2.7.1.1.2.1.4.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Inference</span></span>
<span id="A1.T6.2.7.1.1.2.1.5" class="ltx_tr">
<span id="A1.T6.2.7.1.1.2.1.5.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Attack</span></span>
</span></span> <span id="A1.T6.2.7.1.1.3" class="ltx_text"></span></span></td>
<td id="A1.T6.2.7.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.2.7.2.1" class="ltx_text"></span><span id="A1.T6.2.7.2.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T6.2.7.2.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T6.2.7.2.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T6.2.7.2.3.1.1" class="ltx_tr">
<span id="A1.T6.2.7.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep">(Gu et al<span class="ltx_text">.</span>, <a href="#bib.bib59" title="" class="ltx_ref">2023</a>)</cite></span></span>
</span></span><span id="A1.T6.2.7.2.4" class="ltx_text"></span><span id="A1.T6.2.7.2.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="A1.T6.2.7.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:187.8pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.2.7.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T6.2.7.3.1.1" class="ltx_p"><span id="A1.T6.2.7.3.1.1.1" class="ltx_text" style="font-size:80%;">FedPass introduces an adaptive obfuscation mechanism that adjusts during the learning process to protect features and labels simultaneously. It embeds private passports in both passive and active party models, making it exponentially hard for attackers to infer features and nearly impossible to infer private labels.</span></span>
</span>
</td>
<td id="A1.T6.2.7.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:133.7pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.2.7.4.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T6.2.7.4.1.1" class="ltx_p"><span id="A1.T6.2.7.4.1.1.1" class="ltx_text" style="font-size:80%;">The randomness in passport generation is crucial for data privacy, but the process and its security implications require careful consideration.</span></span>
</span>
</td>
</tr>
<tr id="A1.T6.2.8" class="ltx_tr">
<td id="A1.T6.2.8.1" class="ltx_td ltx_border_l ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"></td>
<td id="A1.T6.2.8.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.2.8.2.1" class="ltx_text"></span><span id="A1.T6.2.8.2.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T6.2.8.2.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T6.2.8.2.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T6.2.8.2.3.1.1" class="ltx_tr">
<span id="A1.T6.2.8.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep">(Sun et al<span class="ltx_text">.</span>, <a href="#bib.bib153" title="" class="ltx_ref">2022</a>)</cite></span></span>
</span></span><span id="A1.T6.2.8.2.4" class="ltx_text"></span><span id="A1.T6.2.8.2.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="A1.T6.2.8.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:187.8pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.2.8.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T6.2.8.3.1.1" class="ltx_p"><span id="A1.T6.2.8.3.1.1.1" class="ltx_text" style="font-size:80%;">Propose an additional optimization goal at the label party to minimize the distance correlation, making it difficult for an adversary to infer private labels from the shared intermediate embedding.</span></span>
</span>
</td>
<td id="A1.T6.2.8.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:133.7pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.2.8.4.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T6.2.8.4.1.1" class="ltx_p"><span id="A1.T6.2.8.4.1.1.1" class="ltx_text" style="font-size:80%;">The method is primarily evaluated in a binary classification setting, and its effectiveness in other scenarios or with different data distributions is not extensively discussed.</span></span>
</span>
</td>
</tr>
<tr id="A1.T6.2.9" class="ltx_tr">
<td id="A1.T6.2.9.1" class="ltx_td ltx_border_l ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;"></td>
<td id="A1.T6.2.9.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.2.9.2.1" class="ltx_text"></span><span id="A1.T6.2.9.2.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T6.2.9.2.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T6.2.9.2.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T6.2.9.2.3.1.1" class="ltx_tr">
<span id="A1.T6.2.9.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a href="#bib.bib98" title="" class="ltx_ref">2021</a>)</cite></span></span>
</span></span><span id="A1.T6.2.9.2.4" class="ltx_text"></span><span id="A1.T6.2.9.2.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="A1.T6.2.9.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:187.8pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.2.9.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T6.2.9.3.1.1" class="ltx_p"><span id="A1.T6.2.9.3.1.1.1" class="ltx_text" style="font-size:80%;">Propose minimizing label leakage in split learning by optimizing noise perturbation structures. It strategically adds random noise to gradients to prevent adversaries from recovering private labels.</span></span>
</span>
</td>
<td id="A1.T6.2.9.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:133.7pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.2.9.4.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T6.2.9.4.1.1" class="ltx_p"><span id="A1.T6.2.9.4.1.1.1" class="ltx_text" style="font-size:80%;">It assumes a Gaussian distribution for unperturbed gradients and can be computationally intensive with multiple optimizations.</span></span>
</span>
</td>
</tr>
<tr id="A1.T6.2.10" class="ltx_tr">
<td id="A1.T6.2.10.1" class="ltx_td ltx_border_l ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;"></td>
<td id="A1.T6.2.10.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.2.10.2.1" class="ltx_text"></span><span id="A1.T6.2.10.2.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T6.2.10.2.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T6.2.10.2.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T6.2.10.2.3.1.1" class="ltx_tr">
<span id="A1.T6.2.10.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep">(Zou et al<span class="ltx_text">.</span>, <a href="#bib.bib210" title="" class="ltx_ref">2022</a>)</cite></span></span>
</span></span><span id="A1.T6.2.10.2.4" class="ltx_text"></span><span id="A1.T6.2.10.2.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="A1.T6.2.10.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:187.8pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.2.10.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T6.2.10.3.1.1" class="ltx_p"><span id="A1.T6.2.10.3.1.1.1" class="ltx_text" style="font-size:80%;">DCAE proposes to defend against label inference and replacement attacks by disguising true labels using autoencoder and entropy regularization with prior label knowledge.</span></span>
</span>
</td>
<td id="A1.T6.2.10.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:133.7pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.2.10.4.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T6.2.10.4.1.1" class="ltx_p"><span id="A1.T6.2.10.4.1.1.1" class="ltx_text" style="font-size:80%;">The implementation of DCAE may add complexity to the VFL system.</span></span>
</span>
</td>
</tr>
<tr id="A1.T6.2.11" class="ltx_tr">
<td id="A1.T6.2.11.1" class="ltx_td ltx_border_l ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;"></td>
<td id="A1.T6.2.11.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.2.11.2.1" class="ltx_text"></span><span id="A1.T6.2.11.2.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T6.2.11.2.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T6.2.11.2.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T6.2.11.2.3.1.1" class="ltx_tr">
<span id="A1.T6.2.11.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep">(Fan et al<span class="ltx_text">.</span>, <a href="#bib.bib39" title="" class="ltx_ref">2023a</a>)</cite></span></span>
</span></span><span id="A1.T6.2.11.2.4" class="ltx_text"></span><span id="A1.T6.2.11.2.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="A1.T6.2.11.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:187.8pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.2.11.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T6.2.11.3.1.1" class="ltx_p"><span id="A1.T6.2.11.3.1.1.1" class="ltx_text" style="font-size:80%;">FLSG defends against passive label inference attacks by generating gradients similar to the original ones using a Gaussian distribution.</span></span>
</span>
</td>
<td id="A1.T6.2.11.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:133.7pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.2.11.4.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T6.2.11.4.1.1" class="ltx_p"><span id="A1.T6.2.11.4.1.1.1" class="ltx_text" style="font-size:80%;">Implementing FLSG increases the training time compared to the original VFL framework.</span></span>
</span>
</td>
</tr>
<tr id="A1.T6.2.12" class="ltx_tr">
<td id="A1.T6.2.12.1" class="ltx_td ltx_border_l ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;"></td>
<td id="A1.T6.2.12.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.2.12.2.1" class="ltx_text"></span><span id="A1.T6.2.12.2.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T6.2.12.2.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T6.2.12.2.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T6.2.12.2.3.1.1" class="ltx_tr">
<span id="A1.T6.2.12.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep">(Wang et al<span class="ltx_text">.</span>, <a href="#bib.bib165" title="" class="ltx_ref">2023</a>)</cite></span></span>
</span></span><span id="A1.T6.2.12.2.4" class="ltx_text"></span><span id="A1.T6.2.12.2.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="A1.T6.2.12.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:187.8pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.2.12.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T6.2.12.3.1.1" class="ltx_p"><span id="A1.T6.2.12.3.1.1.1" class="ltx_text" style="font-size:80%;">Introduce a shadow model to share gradients during training, disrupting the correlation between gradients and training data, which hinders attackers from inferring labels.</span></span>
</span>
</td>
<td id="A1.T6.2.12.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:133.7pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.2.12.4.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T6.2.12.4.1.1" class="ltx_p"><span id="A1.T6.2.12.4.1.1.1" class="ltx_text" style="font-size:80%;">The new local model and the need for secret sharing during training add complexity and potential cost to the process.</span></span>
</span>
</td>
</tr>
<tr id="A1.T6.2.13" class="ltx_tr">
<td id="A1.T6.2.13.1" class="ltx_td ltx_border_l ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;"></td>
<td id="A1.T6.2.13.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.2.13.2.1" class="ltx_text"></span><span id="A1.T6.2.13.2.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T6.2.13.2.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T6.2.13.2.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T6.2.13.2.3.1.1" class="ltx_tr">
<span id="A1.T6.2.13.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep">(Fu et al<span class="ltx_text">.</span>, <a href="#bib.bib50" title="" class="ltx_ref">2024</a>)</cite></span></span>
</span></span><span id="A1.T6.2.13.2.4" class="ltx_text"></span><span id="A1.T6.2.13.2.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="A1.T6.2.13.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:187.8pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.2.13.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T6.2.13.3.1.1" class="ltx_p"><span id="A1.T6.2.13.3.1.1.1" class="ltx_text" style="font-size:80%;">ProjPert addresses label leakage by formulating an optimization problem that minimizes the impact on model quality while satisfying a pre-set privacy guarantee.</span></span>
</span>
</td>
<td id="A1.T6.2.13.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:133.7pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.2.13.4.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T6.2.13.4.1.1" class="ltx_p"><span id="A1.T6.2.13.4.1.1.1" class="ltx_text" style="font-size:80%;">The heuristic variant may not always provide the optimal solution but is designed to be close to it.</span></span>
</span>
</td>
</tr>
<tr id="A1.T6.2.14" class="ltx_tr">
<td id="A1.T6.2.14.1" class="ltx_td ltx_border_l ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;"></td>
<td id="A1.T6.2.14.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.2.14.2.1" class="ltx_text"></span><span id="A1.T6.2.14.2.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T6.2.14.2.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T6.2.14.2.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T6.2.14.2.3.1.1" class="ltx_tr">
<span id="A1.T6.2.14.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep">(Qiu et al<span class="ltx_text">.</span>, <a href="#bib.bib137" title="" class="ltx_ref">2024a</a>)</cite></span></span>
</span></span><span id="A1.T6.2.14.2.4" class="ltx_text"></span><span id="A1.T6.2.14.2.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="A1.T6.2.14.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:187.8pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.2.14.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T6.2.14.3.1.1" class="ltx_p"><span id="A1.T6.2.14.3.1.1.1" class="ltx_text" style="font-size:80%;">HashVFL addresses the challenges of learnability, bit balance, and consistency in VFL by employing a sign function for binarization, batch normalization for bit balance, and predefined binary codes for consistency.</span></span>
</span>
</td>
<td id="A1.T6.2.14.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:133.7pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.2.14.4.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T6.2.14.4.1.1" class="ltx_p"><span id="A1.T6.2.14.4.1.1.1" class="ltx_text" style="font-size:80%;">The integration of hashing can lead to vanishing gradients during model training.</span></span>
</span>
</td>
</tr>
<tr id="A1.T6.2.15" class="ltx_tr">
<td id="A1.T6.2.15.1" class="ltx_td ltx_border_l ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;"></td>
<td id="A1.T6.2.15.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.2.15.2.1" class="ltx_text"></span><span id="A1.T6.2.15.2.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T6.2.15.2.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T6.2.15.2.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T6.2.15.2.3.1.1" class="ltx_tr">
<span id="A1.T6.2.15.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep">(Zheng et al<span class="ltx_text">.</span>, <a href="#bib.bib205" title="" class="ltx_ref">2022</a>)</cite></span></span>
</span></span><span id="A1.T6.2.15.2.4" class="ltx_text"></span><span id="A1.T6.2.15.2.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="A1.T6.2.15.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:187.8pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.2.15.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T6.2.15.3.1.1" class="ltx_p"><span id="A1.T6.2.15.3.1.1.1" class="ltx_text" style="font-size:80%;">Propose the use of potential energy loss (PELoss) to make the output distribution of the local model more complex, protecting against label leakage.</span></span>
</span>
</td>
<td id="A1.T6.2.15.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:133.7pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.2.15.4.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T6.2.15.4.1.1" class="ltx_p"><span id="A1.T6.2.15.4.1.1.1" class="ltx_text" style="font-size:80%;">The method assumes the attacker uses supervised learning to fine-tune the local model and does not consider attacks based on unsupervised learning approaches.</span></span>
</span>
</td>
</tr>
<tr id="A1.T6.2.16" class="ltx_tr">
<td id="A1.T6.2.16.1" class="ltx_td ltx_border_l ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;"></td>
<td id="A1.T6.2.16.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.2.16.2.1" class="ltx_text"></span><span id="A1.T6.2.16.2.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T6.2.16.2.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T6.2.16.2.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T6.2.16.2.3.1.1" class="ltx_tr">
<span id="A1.T6.2.16.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep">(Yang et al<span class="ltx_text">.</span>, <a href="#bib.bib183" title="" class="ltx_ref">2022a</a>)</cite></span></span>
</span></span><span id="A1.T6.2.16.2.4" class="ltx_text"></span><span id="A1.T6.2.16.2.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="A1.T6.2.16.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:187.8pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.2.16.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T6.2.16.3.1.1" class="ltx_p"><span id="A1.T6.2.16.3.1.1.1" class="ltx_text" style="font-size:80%;">TPSL adds noise to gradients and model updates during training to ensure differential privacy, focusing on protecting sensitive label information.</span></span>
</span>
</td>
<td id="A1.T6.2.16.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:133.7pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.2.16.4.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T6.2.16.4.1.1" class="ltx_p"><span id="A1.T6.2.16.4.1.1.1" class="ltx_text" style="font-size:80%;">The method involves adding noise to gradients and model updates, which may affect the utility of the trained model.</span></span>
</span>
</td>
</tr>
<tr id="A1.T6.2.17" class="ltx_tr">
<td id="A1.T6.2.17.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="A1.T6.2.17.1.1" class="ltx_text" style="font-size:80%;"><span id="A1.T6.2.17.1.1.1" class="ltx_text"></span> <span id="A1.T6.2.17.1.1.2" class="ltx_text">
<span id="A1.T6.2.17.1.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T6.2.17.1.1.2.1.1" class="ltx_tr">
<span id="A1.T6.2.17.1.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Defend</span></span>
<span id="A1.T6.2.17.1.1.2.1.2" class="ltx_tr">
<span id="A1.T6.2.17.1.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Against</span></span>
<span id="A1.T6.2.17.1.1.2.1.3" class="ltx_tr">
<span id="A1.T6.2.17.1.1.2.1.3.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Label</span></span>
<span id="A1.T6.2.17.1.1.2.1.4" class="ltx_tr">
<span id="A1.T6.2.17.1.1.2.1.4.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Inference</span></span>
<span id="A1.T6.2.17.1.1.2.1.5" class="ltx_tr">
<span id="A1.T6.2.17.1.1.2.1.5.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Attack</span></span>
</span></span> <span id="A1.T6.2.17.1.1.3" class="ltx_text"></span></span></td>
<td id="A1.T6.2.17.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.2.17.2.1" class="ltx_text"></span><span id="A1.T6.2.17.2.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T6.2.17.2.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T6.2.17.2.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T6.2.17.2.3.1.1" class="ltx_tr">
<span id="A1.T6.2.17.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep">(Takahashi et al<span class="ltx_text">.</span>, <a href="#bib.bib156" title="" class="ltx_ref">2023</a>)</cite></span></span>
</span></span><span id="A1.T6.2.17.2.4" class="ltx_text"></span><span id="A1.T6.2.17.2.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="A1.T6.2.17.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_b ltx_border_r ltx_border_t" style="width:187.8pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.2.17.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T6.2.17.3.1.1" class="ltx_p"><span id="A1.T6.2.17.3.1.1.1" class="ltx_text" style="font-size:80%;">Propose defense mechanisms to mitigate label leakage in tree-based VFL, by utilizing label differential privacy with post-processing and mutual information regularization.</span></span>
</span>
</td>
<td id="A1.T6.2.17.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_b ltx_border_r ltx_border_t" style="width:133.7pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T6.2.17.4.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T6.2.17.4.1.1" class="ltx_p"><span id="A1.T6.2.17.4.1.1.1" class="ltx_text" style="font-size:80%;">It requires additional training and communications.</span></span>
</span>
</td>
</tr>
</table>
</figure>
<figure id="A1.T7" class="ltx_table">
<figcaption class="ltx_caption ltx_centering" style="font-size:80%;"><span class="ltx_tag ltx_tag_table">Table 7. </span><span id="A1.T7.5.1" class="ltx_text ltx_font_bold">Works on Defending Against Destructive Attack.</span></figcaption>
<table id="A1.T7.2" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="A1.T7.2.2" class="ltx_tr">
<td id="A1.T7.2.2.3" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="A1.T7.2.2.3.1" class="ltx_text" style="font-size:80%;">Topics</span></td>
<td id="A1.T7.2.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T7.2.2.4.1" class="ltx_text"></span><span id="A1.T7.2.2.4.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T7.2.2.4.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T7.2.2.4.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T7.2.2.4.3.1.1" class="ltx_tr">
<span id="A1.T7.2.2.4.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Ref.</span></span>
</span></span><span id="A1.T7.2.2.4.4" class="ltx_text"></span><span id="A1.T7.2.2.4.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="A1.T7.1.1.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:153.6pt;padding-left:2.0pt;padding-right:2.0pt;"><span id="A1.T7.1.1.1.1" class="ltx_inline-logical-block ltx_align_top">
<span id="A1.T7.1.1.1.1.p1" class="ltx_para ltx_noindent">
<span id="A1.T7.1.1.1.1.p1.1" class="ltx_p"><span id="A1.T7.1.1.1.1.p1.1.1" class="ltx_text"></span><span id="A1.T7.1.1.1.1.p1.1.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T7.1.1.1.1.p1.1.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T7.1.1.1.1.p1.1.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T7.1.1.1.1.p1.1.3.1.1" class="ltx_tr">
<span id="A1.T7.1.1.1.1.p1.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Key Contributions</span></span>
</span></span><span id="A1.T7.1.1.1.1.p1.1.4" class="ltx_text"></span><span id="A1.T7.1.1.1.1.p1.1.5" class="ltx_text" style="font-size:80%;"></span></span>
</span></span></td>
<td id="A1.T7.2.2.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:153.6pt;padding-left:2.0pt;padding-right:2.0pt;"><span id="A1.T7.2.2.2.1" class="ltx_inline-logical-block ltx_align_top">
<span id="A1.T7.2.2.2.1.p1" class="ltx_para ltx_noindent">
<span id="A1.T7.2.2.2.1.p1.1" class="ltx_p"><span id="A1.T7.2.2.2.1.p1.1.1" class="ltx_text"></span><span id="A1.T7.2.2.2.1.p1.1.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T7.2.2.2.1.p1.1.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T7.2.2.2.1.p1.1.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T7.2.2.2.1.p1.1.3.1.1" class="ltx_tr">
<span id="A1.T7.2.2.2.1.p1.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Limitations</span></span>
</span></span><span id="A1.T7.2.2.2.1.p1.1.4" class="ltx_text"></span><span id="A1.T7.2.2.2.1.p1.1.5" class="ltx_text" style="font-size:80%;"></span></span>
</span></span></td>
</tr>
<tr id="A1.T7.2.3" class="ltx_tr">
<td id="A1.T7.2.3.1" class="ltx_td ltx_border_l ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"></td>
<td id="A1.T7.2.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T7.2.3.2.1" class="ltx_text"></span><span id="A1.T7.2.3.2.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T7.2.3.2.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T7.2.3.2.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T7.2.3.2.3.1.1" class="ltx_tr">
<span id="A1.T7.2.3.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep">(He et al<span class="ltx_text">.</span>, <a href="#bib.bib67" title="" class="ltx_ref">2023</a>)</cite></span></span>
</span></span><span id="A1.T7.2.3.2.4" class="ltx_text"></span><span id="A1.T7.2.3.2.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="A1.T7.2.3.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:153.6pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T7.2.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T7.2.3.3.1.1" class="ltx_p"><span id="A1.T7.2.3.3.1.1.1" class="ltx_text" style="font-size:80%;">Propose strategies from three aspects: Statistical Filtering, which filters out abnormal local embeddings that deviate from natural outputs; Reverse Engineering Detection, identifies backdoored models by comparing reversed trigger vectors for different classes; Confusional Autoencoder, which maps original labels to fake labels to minimize classification probability differences.</span></span>
</span>
</td>
<td id="A1.T7.2.3.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:153.6pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T7.2.3.4.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T7.2.3.4.1.1" class="ltx_p"><span id="A1.T7.2.3.4.1.1.1" class="ltx_text" style="font-size:80%;">Can not detect stealthy attacks with well-crafted trigger vectors; With low detection rates, indicating difficulty in identifying malicious models; Does not significantly hinder the proposed attack, as it does not rely on gradients or label inference.</span></span>
</span>
</td>
</tr>
<tr id="A1.T7.2.4" class="ltx_tr">
<td id="A1.T7.2.4.1" class="ltx_td ltx_border_l ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;"></td>
<td id="A1.T7.2.4.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T7.2.4.2.1" class="ltx_text"></span><span id="A1.T7.2.4.2.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T7.2.4.2.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T7.2.4.2.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T7.2.4.2.3.1.1" class="ltx_tr">
<span id="A1.T7.2.4.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep">(Lai et al<span class="ltx_text">.</span>, <a href="#bib.bib93" title="" class="ltx_ref">2023</a>)</cite></span></span>
</span></span><span id="A1.T7.2.4.2.4" class="ltx_text"></span><span id="A1.T7.2.4.2.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="A1.T7.2.4.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:153.6pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T7.2.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T7.2.4.3.1.1" class="ltx_p"><span id="A1.T7.2.4.3.1.1.1" class="ltx_text" style="font-size:80%;">VFedAD utilizes information theory to detect anomalies in vertical federated learning. It employs contrastive learning and cross-client prediction tasks to learn data representations that help identify poisoned samples.</span></span>
</span>
</td>
<td id="A1.T7.2.4.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:153.6pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T7.2.4.4.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T7.2.4.4.1.1" class="ltx_p"><span id="A1.T7.2.4.4.1.1.1" class="ltx_text" style="font-size:80%;">The success of anomaly detection hinges on the quality of learned data representations.</span></span>
</span>
</td>
</tr>
<tr id="A1.T7.2.5" class="ltx_tr">
<td id="A1.T7.2.5.1" class="ltx_td ltx_border_l ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;"></td>
<td id="A1.T7.2.5.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T7.2.5.2.1" class="ltx_text"></span><span id="A1.T7.2.5.2.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T7.2.5.2.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T7.2.5.2.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T7.2.5.2.3.1.1" class="ltx_tr">
<span id="A1.T7.2.5.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep">(Qiu et al<span class="ltx_text">.</span>, <a href="#bib.bib138" title="" class="ltx_ref">2024b</a>)</cite></span></span>
</span></span><span id="A1.T7.2.5.2.4" class="ltx_text"></span><span id="A1.T7.2.5.2.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="A1.T7.2.5.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:153.6pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T7.2.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T7.2.5.3.1.1" class="ltx_p"><span id="A1.T7.2.5.3.1.1.1" class="ltx_text" style="font-size:80%;">Utilize two strategies to defend the destructive attack: Normalization, which is effective against black-box attacks like ZOO by transforming perturbed input, preventing gradient approximation; Dropout, which reduces model memorization of specific patterns and mitigates attacks.</span></span>
</span>
</td>
<td id="A1.T7.2.5.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:153.6pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T7.2.5.4.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T7.2.5.4.1.1" class="ltx_p"><span id="A1.T7.2.5.4.1.1.1" class="ltx_text" style="font-size:80%;">The impact is limited when the attacker has a significant feature ratio, as the threat persists; High dropout probability can drastically reduce main task performance, making it impractical for collaborative learning.</span></span>
</span>
</td>
</tr>
<tr id="A1.T7.2.6" class="ltx_tr">
<td id="A1.T7.2.6.1" class="ltx_td ltx_border_l ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;"></td>
<td id="A1.T7.2.6.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T7.2.6.2.1" class="ltx_text"></span><span id="A1.T7.2.6.2.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T7.2.6.2.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T7.2.6.2.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T7.2.6.2.3.1.1" class="ltx_tr">
<span id="A1.T7.2.6.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep">(Chen et al<span class="ltx_text">.</span>, <a href="#bib.bib28" title="" class="ltx_ref">2024c</a>)</cite></span></span>
</span></span><span id="A1.T7.2.6.2.4" class="ltx_text"></span><span id="A1.T7.2.6.2.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="A1.T7.2.6.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:153.6pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T7.2.6.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T7.2.6.3.1.1" class="ltx_p"><span id="A1.T7.2.6.3.1.1.1" class="ltx_text" style="font-size:80%;">Focus on a server-side anomaly detection algorithm based on a deep auto-encoder (DAE) to combat data poisoning attacks. It is used to identify outliers in embeddings with reconstruction errors and filter out anomalous data.</span></span>
</span>
</td>
<td id="A1.T7.2.6.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:153.6pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T7.2.6.4.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T7.2.6.4.1.1" class="ltx_p"><span id="A1.T7.2.6.4.1.1.1" class="ltx_text" style="font-size:80%;">The detection might struggle with high proportions of poisoned data.</span></span>
</span>
</td>
</tr>
<tr id="A1.T7.2.7" class="ltx_tr">
<td id="A1.T7.2.7.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="A1.T7.2.7.1.1" class="ltx_text" style="font-size:80%;"><span id="A1.T7.2.7.1.1.1" class="ltx_text"></span> <span id="A1.T7.2.7.1.1.2" class="ltx_text">
<span id="A1.T7.2.7.1.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T7.2.7.1.1.2.1.1" class="ltx_tr">
<span id="A1.T7.2.7.1.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Defend</span></span>
<span id="A1.T7.2.7.1.1.2.1.2" class="ltx_tr">
<span id="A1.T7.2.7.1.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Against</span></span>
<span id="A1.T7.2.7.1.1.2.1.3" class="ltx_tr">
<span id="A1.T7.2.7.1.1.2.1.3.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Destructive</span></span>
<span id="A1.T7.2.7.1.1.2.1.4" class="ltx_tr">
<span id="A1.T7.2.7.1.1.2.1.4.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Attack</span></span>
</span></span> <span id="A1.T7.2.7.1.1.3" class="ltx_text"></span></span></td>
<td id="A1.T7.2.7.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T7.2.7.2.1" class="ltx_text"></span><span id="A1.T7.2.7.2.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T7.2.7.2.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T7.2.7.2.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T7.2.7.2.3.1.1" class="ltx_tr">
<span id="A1.T7.2.7.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep">(Liu et al<span class="ltx_text">.</span>, <a href="#bib.bib110" title="" class="ltx_ref">2021d</a>)</cite></span></span>
</span></span><span id="A1.T7.2.7.2.4" class="ltx_text"></span><span id="A1.T7.2.7.2.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="A1.T7.2.7.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_b ltx_border_r ltx_border_t" style="width:153.6pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T7.2.7.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T7.2.7.3.1.1" class="ltx_p"><span id="A1.T7.2.7.3.1.1.1" class="ltx_text" style="font-size:80%;">RVFR operates by training individual feature extractors seperately, followed by a robust feature subspace recovery process, and feature purification based on the assumption that only a small fraction of agents are malicious.</span></span>
</span>
</td>
<td id="A1.T7.2.7.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_b ltx_border_r ltx_border_t" style="width:153.6pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T7.2.7.4.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T7.2.7.4.1.1" class="ltx_p"><span id="A1.T7.2.7.4.1.1.1" class="ltx_text" style="font-size:80%;">The effectiveness of RVFR relies on certain assumptions, such as a low-rank feature subspace and a small fraction of malicious agents.</span></span>
</span>
</td>
</tr>
</table>
</figure>
<figure id="A1.T8" class="ltx_table">
<figcaption class="ltx_caption ltx_centering" style="font-size:80%;"><span class="ltx_tag ltx_tag_table">Table 8. </span><span id="A1.T8.5.1" class="ltx_text ltx_font_bold">Works on Limited Data.</span></figcaption>
<table id="A1.T8.2" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="A1.T8.2.2" class="ltx_tr">
<td id="A1.T8.2.2.3" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="A1.T8.2.2.3.1" class="ltx_text" style="font-size:80%;">Topics</span></td>
<td id="A1.T8.2.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T8.2.2.4.1" class="ltx_text"></span><span id="A1.T8.2.2.4.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T8.2.2.4.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T8.2.2.4.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T8.2.2.4.3.1.1" class="ltx_tr">
<span id="A1.T8.2.2.4.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Ref.</span></span>
</span></span><span id="A1.T8.2.2.4.4" class="ltx_text"></span><span id="A1.T8.2.2.4.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="A1.T8.1.1.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:156.5pt;padding-left:2.0pt;padding-right:2.0pt;"><span id="A1.T8.1.1.1.1" class="ltx_inline-logical-block ltx_align_top">
<span id="A1.T8.1.1.1.1.p1" class="ltx_para ltx_noindent">
<span id="A1.T8.1.1.1.1.p1.1" class="ltx_p"><span id="A1.T8.1.1.1.1.p1.1.1" class="ltx_text"></span><span id="A1.T8.1.1.1.1.p1.1.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T8.1.1.1.1.p1.1.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T8.1.1.1.1.p1.1.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T8.1.1.1.1.p1.1.3.1.1" class="ltx_tr">
<span id="A1.T8.1.1.1.1.p1.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Key Contributions</span></span>
</span></span><span id="A1.T8.1.1.1.1.p1.1.4" class="ltx_text"></span><span id="A1.T8.1.1.1.1.p1.1.5" class="ltx_text" style="font-size:80%;"></span></span>
</span></span></td>
<td id="A1.T8.2.2.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:156.5pt;padding-left:2.0pt;padding-right:2.0pt;"><span id="A1.T8.2.2.2.1" class="ltx_inline-logical-block ltx_align_top">
<span id="A1.T8.2.2.2.1.p1" class="ltx_para ltx_noindent">
<span id="A1.T8.2.2.2.1.p1.1" class="ltx_p"><span id="A1.T8.2.2.2.1.p1.1.1" class="ltx_text"></span><span id="A1.T8.2.2.2.1.p1.1.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T8.2.2.2.1.p1.1.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T8.2.2.2.1.p1.1.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T8.2.2.2.1.p1.1.3.1.1" class="ltx_tr">
<span id="A1.T8.2.2.2.1.p1.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Limitations</span></span>
</span></span><span id="A1.T8.2.2.2.1.p1.1.4" class="ltx_text"></span><span id="A1.T8.2.2.2.1.p1.1.5" class="ltx_text" style="font-size:80%;"></span></span>
</span></span></td>
</tr>
<tr id="A1.T8.2.3" class="ltx_tr">
<td id="A1.T8.2.3.1" class="ltx_td ltx_border_l ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"></td>
<td id="A1.T8.2.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T8.2.3.2.1" class="ltx_text"></span><span id="A1.T8.2.3.2.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T8.2.3.2.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T8.2.3.2.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T8.2.3.2.3.1.1" class="ltx_tr">
<span id="A1.T8.2.3.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep">(Kang et al<span class="ltx_text">.</span>, <a href="#bib.bib85" title="" class="ltx_ref">2022a</a>)</cite></span></span>
</span></span><span id="A1.T8.2.3.2.4" class="ltx_text"></span><span id="A1.T8.2.3.2.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="A1.T8.2.3.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:156.5pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T8.2.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T8.2.3.3.1.1" class="ltx_p"><span id="A1.T8.2.3.3.1.1.1" class="ltx_text" style="font-size:80%;">FedCVT generates missing features and assigns pseudo-labels for unaligned samples.</span></span>
</span>
</td>
<td id="A1.T8.2.3.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:156.5pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T8.2.3.4.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T8.2.3.4.1.1" class="ltx_p"><span id="A1.T8.2.3.4.1.1.1" class="ltx_text" style="font-size:80%;">The feature generation introduces noise information, and the unaligned samples are not fully utilized; only those with high-confidence pseudo-labels are employed.</span></span>
</span>
</td>
</tr>
<tr id="A1.T8.2.4" class="ltx_tr">
<td id="A1.T8.2.4.1" class="ltx_td ltx_border_l ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;"></td>
<td id="A1.T8.2.4.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T8.2.4.2.1" class="ltx_text"></span><span id="A1.T8.2.4.2.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T8.2.4.2.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T8.2.4.2.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T8.2.4.2.3.1.1" class="ltx_tr">
<span id="A1.T8.2.4.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep">(Sun et al<span class="ltx_text">.</span>, <a href="#bib.bib152" title="" class="ltx_ref">2023b</a>)</cite></span></span>
</span></span><span id="A1.T8.2.4.2.4" class="ltx_text"></span><span id="A1.T8.2.4.2.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="A1.T8.2.4.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:156.5pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T8.2.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T8.2.4.3.1.1" class="ltx_p"><span id="A1.T8.2.4.3.1.1.1" class="ltx_text" style="font-size:80%;">Few-shot VFL introduces the semi-supervised paradigm, where each client updates with estimated labels to improve sample utilization.</span></span>
</span>
</td>
<td id="A1.T8.2.4.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:156.5pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T8.2.4.4.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T8.2.4.4.1.1" class="ltx_p"><span id="A1.T8.2.4.4.1.1.1" class="ltx_text" style="font-size:80%;">Unaligned samples are not fully utilized due to the confidence threshold.</span></span>
</span>
</td>
</tr>
<tr id="A1.T8.2.5" class="ltx_tr">
<td id="A1.T8.2.5.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="A1.T8.2.5.1.1" class="ltx_text" style="font-size:80%;"><span id="A1.T8.2.5.1.1.1" class="ltx_text"></span> <span id="A1.T8.2.5.1.1.2" class="ltx_text">
<span id="A1.T8.2.5.1.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T8.2.5.1.1.2.1.1" class="ltx_tr">
<span id="A1.T8.2.5.1.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Limited</span></span>
<span id="A1.T8.2.5.1.1.2.1.2" class="ltx_tr">
<span id="A1.T8.2.5.1.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Aligned</span></span>
<span id="A1.T8.2.5.1.1.2.1.3" class="ltx_tr">
<span id="A1.T8.2.5.1.1.2.1.3.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Samples</span></span>
</span></span> <span id="A1.T8.2.5.1.1.3" class="ltx_text"></span></span></td>
<td id="A1.T8.2.5.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T8.2.5.2.1" class="ltx_text"></span><span id="A1.T8.2.5.2.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T8.2.5.2.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T8.2.5.2.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T8.2.5.2.3.1.1" class="ltx_tr">
<span id="A1.T8.2.5.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep">(Yang et al<span class="ltx_text">.</span>, <a href="#bib.bib184" title="" class="ltx_ref">2022b</a>)</cite></span></span>
</span></span><span id="A1.T8.2.5.2.4" class="ltx_text"></span><span id="A1.T8.2.5.2.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="A1.T8.2.5.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:156.5pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T8.2.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T8.2.5.3.1.1" class="ltx_p"><span id="A1.T8.2.5.3.1.1.1" class="ltx_text" style="font-size:80%;">FedMC expands the training data by matching non-overlapping samples based on similarity, thus improving the effectiveness of the jointly trained model.</span></span>
</span>
</td>
<td id="A1.T8.2.5.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:156.5pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T8.2.5.4.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T8.2.5.4.1.1" class="ltx_p"><span id="A1.T8.2.5.4.1.1.1" class="ltx_text" style="font-size:80%;">It aims to pair the unaligned samples above the desired similarity threshold for collaboration training, which cannot fully utilize all samples.</span></span>
</span>
</td>
</tr>
<tr id="A1.T8.2.6" class="ltx_tr">
<td id="A1.T8.2.6.1" class="ltx_td ltx_border_l ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"></td>
<td id="A1.T8.2.6.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T8.2.6.2.1" class="ltx_text"></span><span id="A1.T8.2.6.2.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T8.2.6.2.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T8.2.6.2.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T8.2.6.2.3.1.1" class="ltx_tr">
<span id="A1.T8.2.6.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep">(Cha et al<span class="ltx_text">.</span>, <a href="#bib.bib17" title="" class="ltx_ref">2021</a>)</cite></span></span>
</span></span><span id="A1.T8.2.6.2.4" class="ltx_text"></span><span id="A1.T8.2.6.2.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="A1.T8.2.6.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:156.5pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T8.2.6.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T8.2.6.3.1.1" class="ltx_p"><span id="A1.T8.2.6.3.1.1.1" class="ltx_text" style="font-size:80%;">They propose to leverage auto-encoder which does not require labels for training.</span></span>
</span>
</td>
<td id="A1.T8.2.6.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:156.5pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T8.2.6.4.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T8.2.6.4.1.1" class="ltx_p"><span id="A1.T8.2.6.4.1.1.1" class="ltx_text" style="font-size:80%;">Redundant information is introduced and may overfit short sequence data.</span></span>
</span>
</td>
</tr>
<tr id="A1.T8.2.7" class="ltx_tr">
<td id="A1.T8.2.7.1" class="ltx_td ltx_border_l ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;"></td>
<td id="A1.T8.2.7.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T8.2.7.2.1" class="ltx_text"></span><span id="A1.T8.2.7.2.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T8.2.7.2.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T8.2.7.2.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T8.2.7.2.3.1.1" class="ltx_tr">
<span id="A1.T8.2.7.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep">(Wu et al<span class="ltx_text">.</span>, <a href="#bib.bib174" title="" class="ltx_ref">2022b</a>)</cite></span></span>
</span></span><span id="A1.T8.2.7.2.4" class="ltx_text"></span><span id="A1.T8.2.7.2.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="A1.T8.2.7.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:156.5pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T8.2.7.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T8.2.7.3.1.1" class="ltx_p"><span id="A1.T8.2.7.3.1.1.1" class="ltx_text" style="font-size:80%;">FedOnce enhances intermediate features through local unsupervised learning.</span></span>
</span>
</td>
<td id="A1.T8.2.7.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:156.5pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T8.2.7.4.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T8.2.7.4.1.1" class="ltx_p"><span id="A1.T8.2.7.4.1.1.1" class="ltx_text" style="font-size:80%;">It requires a sufficient amount of labels for the collaboration task; Additional computational costs are introduced with local updation.</span></span>
</span>
</td>
</tr>
<tr id="A1.T8.2.8" class="ltx_tr">
<td id="A1.T8.2.8.1" class="ltx_td ltx_border_l ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;"></td>
<td id="A1.T8.2.8.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T8.2.8.2.1" class="ltx_text"></span><span id="A1.T8.2.8.2.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T8.2.8.2.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T8.2.8.2.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T8.2.8.2.3.1.1" class="ltx_tr">
<span id="A1.T8.2.8.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep">(He et al<span class="ltx_text">.</span>, <a href="#bib.bib66" title="" class="ltx_ref">2024</a>)</cite></span></span>
</span></span><span id="A1.T8.2.8.2.4" class="ltx_text"></span><span id="A1.T8.2.8.2.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="A1.T8.2.8.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:156.5pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T8.2.8.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T8.2.8.3.1.1" class="ltx_p"><span id="A1.T8.2.8.3.1.1.1" class="ltx_text" style="font-size:80%;">FedHSSL leverages cross-party views, local views, and invariant features of samples to improve the performance of VFL collaboration with limited labels.</span></span>
</span>
</td>
<td id="A1.T8.2.8.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:156.5pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T8.2.8.4.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T8.2.8.4.1.1" class="ltx_p"><span id="A1.T8.2.8.4.1.1.1" class="ltx_text" style="font-size:80%;">Assume the participants have similar data distributions; Additional communication costs are introduced.</span></span>
</span>
</td>
</tr>
<tr id="A1.T8.2.9" class="ltx_tr">
<td id="A1.T8.2.9.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="A1.T8.2.9.1.1" class="ltx_text" style="font-size:80%;"><span id="A1.T8.2.9.1.1.1" class="ltx_text"></span> <span id="A1.T8.2.9.1.1.2" class="ltx_text">
<span id="A1.T8.2.9.1.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T8.2.9.1.1.2.1.1" class="ltx_tr">
<span id="A1.T8.2.9.1.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Limited</span></span>
<span id="A1.T8.2.9.1.1.2.1.2" class="ltx_tr">
<span id="A1.T8.2.9.1.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Labels</span></span>
</span></span> <span id="A1.T8.2.9.1.1.3" class="ltx_text"></span></span></td>
<td id="A1.T8.2.9.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T8.2.9.2.1" class="ltx_text"></span><span id="A1.T8.2.9.2.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T8.2.9.2.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T8.2.9.2.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T8.2.9.2.3.1.1" class="ltx_tr">
<span id="A1.T8.2.9.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep">(Castiglia et al<span class="ltx_text">.</span>, <a href="#bib.bib14" title="" class="ltx_ref">2022b</a>)</cite></span></span>
</span></span><span id="A1.T8.2.9.2.4" class="ltx_text"></span><span id="A1.T8.2.9.2.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="A1.T8.2.9.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_b ltx_border_r ltx_border_t" style="width:156.5pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T8.2.9.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T8.2.9.3.1.1" class="ltx_p"><span id="A1.T8.2.9.3.1.1.1" class="ltx_text" style="font-size:80%;">SS-VFL leverages unlabeled data to train representation networks and labeled data for a downstream prediction network, aiming to achieve higher accuracy with reduced communication costs.</span></span>
</span>
</td>
<td id="A1.T8.2.9.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_b ltx_border_r ltx_border_t" style="width:156.5pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T8.2.9.4.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T8.2.9.4.1.1" class="ltx_p"><span id="A1.T8.2.9.4.1.1.1" class="ltx_text" style="font-size:80%;">The effectiveness may vary depending on the similarity between local and centralized class probability distributions. Additionally, there is a potential for model bias if the datasets used for training are biased.</span></span>
</span>
</td>
</tr>
</table>
</figure>
<figure id="A1.T9" class="ltx_table">
<figcaption class="ltx_caption ltx_centering" style="font-size:80%;"><span class="ltx_tag ltx_tag_table">Table 9. </span><span id="A1.T9.5.1" class="ltx_text ltx_font_bold">Works on Communication Efficiency.</span></figcaption>
<table id="A1.T9.2" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="A1.T9.2.2" class="ltx_tr">
<td id="A1.T9.2.2.3" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="A1.T9.2.2.3.1" class="ltx_text" style="font-size:80%;">Topics</span></td>
<td id="A1.T9.2.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T9.2.2.4.1" class="ltx_text"></span><span id="A1.T9.2.2.4.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T9.2.2.4.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T9.2.2.4.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T9.2.2.4.3.1.1" class="ltx_tr">
<span id="A1.T9.2.2.4.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Ref.</span></span>
</span></span><span id="A1.T9.2.2.4.4" class="ltx_text"></span><span id="A1.T9.2.2.4.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="A1.T9.1.1.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:136.6pt;padding-left:2.0pt;padding-right:2.0pt;"><span id="A1.T9.1.1.1.1" class="ltx_inline-logical-block ltx_align_top">
<span id="A1.T9.1.1.1.1.p1" class="ltx_para ltx_noindent">
<span id="A1.T9.1.1.1.1.p1.1" class="ltx_p"><span id="A1.T9.1.1.1.1.p1.1.1" class="ltx_text"></span><span id="A1.T9.1.1.1.1.p1.1.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T9.1.1.1.1.p1.1.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T9.1.1.1.1.p1.1.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T9.1.1.1.1.p1.1.3.1.1" class="ltx_tr">
<span id="A1.T9.1.1.1.1.p1.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Key Contributions</span></span>
</span></span><span id="A1.T9.1.1.1.1.p1.1.4" class="ltx_text"></span><span id="A1.T9.1.1.1.1.p1.1.5" class="ltx_text" style="font-size:80%;"></span></span>
</span></span></td>
<td id="A1.T9.2.2.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:136.6pt;padding-left:2.0pt;padding-right:2.0pt;"><span id="A1.T9.2.2.2.1" class="ltx_inline-logical-block ltx_align_top">
<span id="A1.T9.2.2.2.1.p1" class="ltx_para ltx_noindent">
<span id="A1.T9.2.2.2.1.p1.1" class="ltx_p"><span id="A1.T9.2.2.2.1.p1.1.1" class="ltx_text"></span><span id="A1.T9.2.2.2.1.p1.1.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T9.2.2.2.1.p1.1.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T9.2.2.2.1.p1.1.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T9.2.2.2.1.p1.1.3.1.1" class="ltx_tr">
<span id="A1.T9.2.2.2.1.p1.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Limitations</span></span>
</span></span><span id="A1.T9.2.2.2.1.p1.1.4" class="ltx_text"></span><span id="A1.T9.2.2.2.1.p1.1.5" class="ltx_text" style="font-size:80%;"></span></span>
</span></span></td>
</tr>
<tr id="A1.T9.2.3" class="ltx_tr">
<td id="A1.T9.2.3.1" class="ltx_td ltx_border_l ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"></td>
<td id="A1.T9.2.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T9.2.3.2.1" class="ltx_text"></span><span id="A1.T9.2.3.2.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T9.2.3.2.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T9.2.3.2.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T9.2.3.2.3.1.1" class="ltx_tr">
<span id="A1.T9.2.3.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep">(Zhang et al<span class="ltx_text">.</span>, <a href="#bib.bib195" title="" class="ltx_ref">2021b</a>)</cite></span></span>
</span></span><span id="A1.T9.2.3.2.4" class="ltx_text"></span><span id="A1.T9.2.3.2.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="A1.T9.2.3.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:136.6pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T9.2.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T9.2.3.3.1.1" class="ltx_p"><span id="A1.T9.2.3.3.1.1.1" class="ltx_text" style="font-size:80%;">AsySQN utilizes approximate second-order information to reduce the communication rounds and improve the convergence speed.</span></span>
</span>
</td>
<td id="A1.T9.2.3.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:136.6pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T9.2.3.4.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T9.2.3.4.1.1" class="ltx_p"><span id="A1.T9.2.3.4.1.1.1" class="ltx_text" style="font-size:80%;">Require collaboration labels to be held by all clients.</span></span>
</span>
</td>
</tr>
<tr id="A1.T9.2.4" class="ltx_tr">
<td id="A1.T9.2.4.1" class="ltx_td ltx_border_l ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;"></td>
<td id="A1.T9.2.4.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T9.2.4.2.1" class="ltx_text"></span><span id="A1.T9.2.4.2.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T9.2.4.2.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T9.2.4.2.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T9.2.4.2.3.1.1" class="ltx_tr">
<span id="A1.T9.2.4.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep">(Khan et al<span class="ltx_text">.</span>, <a href="#bib.bib88" title="" class="ltx_ref">2022a</a>)</cite></span></span>
</span></span><span id="A1.T9.2.4.2.4" class="ltx_text"></span><span id="A1.T9.2.4.2.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="A1.T9.2.4.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:136.6pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T9.2.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T9.2.4.3.1.1" class="ltx_p"><span id="A1.T9.2.4.3.1.1.1" class="ltx_text" style="font-size:80%;">They propose to utilize feature compression methods to compress the local data into latent representations and reduce the communication rounds to one.</span></span>
</span>
</td>
<td id="A1.T9.2.4.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:136.6pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T9.2.4.4.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T9.2.4.4.1.1" class="ltx_p"><span id="A1.T9.2.4.4.1.1.1" class="ltx_text" style="font-size:80%;">The feature compression method should be carefully selected for different scenarios.</span></span>
</span>
</td>
</tr>
<tr id="A1.T9.2.5" class="ltx_tr">
<td id="A1.T9.2.5.1" class="ltx_td ltx_border_l ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;"></td>
<td id="A1.T9.2.5.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T9.2.5.2.1" class="ltx_text"></span><span id="A1.T9.2.5.2.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T9.2.5.2.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T9.2.5.2.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T9.2.5.2.3.1.1" class="ltx_tr">
<span id="A1.T9.2.5.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep">(Liu et al<span class="ltx_text">.</span>, <a href="#bib.bib116" title="" class="ltx_ref">2022</a>)</cite></span></span>
</span></span><span id="A1.T9.2.5.2.4" class="ltx_text"></span><span id="A1.T9.2.5.2.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="A1.T9.2.5.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:136.6pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T9.2.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T9.2.5.3.1.1" class="ltx_p"><span id="A1.T9.2.5.3.1.1.1" class="ltx_text" style="font-size:80%;">FedBCD utilizes a Federated Stochastic Block Coordinate Descent algorithm, enabling parties to perform multiple local updates to reduce communication rounds.</span></span>
</span>
</td>
<td id="A1.T9.2.5.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:136.6pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T9.2.5.4.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T9.2.5.4.1.1" class="ltx_p"><span id="A1.T9.2.5.4.1.1.1" class="ltx_text" style="font-size:80%;">The number of local rounds needs careful selection to avoid divergence.</span></span>
</span>
</td>
</tr>
<tr id="A1.T9.2.6" class="ltx_tr">
<td id="A1.T9.2.6.1" class="ltx_td ltx_border_l ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;"></td>
<td id="A1.T9.2.6.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T9.2.6.2.1" class="ltx_text"></span><span id="A1.T9.2.6.2.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T9.2.6.2.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T9.2.6.2.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T9.2.6.2.3.1.1" class="ltx_tr">
<span id="A1.T9.2.6.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep">(Castiglia et al<span class="ltx_text">.</span>, <a href="#bib.bib16" title="" class="ltx_ref">2022a</a>)</cite></span></span>
</span></span><span id="A1.T9.2.6.2.4" class="ltx_text"></span><span id="A1.T9.2.6.2.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="A1.T9.2.6.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:136.6pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T9.2.6.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T9.2.6.3.1.1" class="ltx_p"><span id="A1.T9.2.6.3.1.1.1" class="ltx_text" style="font-size:80%;">They propose to leverage local updating and sharing compressed embeddings to reduce communication.</span></span>
</span>
</td>
<td id="A1.T9.2.6.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:136.6pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T9.2.6.4.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T9.2.6.4.1.1" class="ltx_p"><span id="A1.T9.2.6.4.1.1.1" class="ltx_text" style="font-size:80%;">It is limited to the bounded embedding gradients and bounded Hessian of the objective function.</span></span>
</span>
</td>
</tr>
<tr id="A1.T9.2.7" class="ltx_tr">
<td id="A1.T9.2.7.1" class="ltx_td ltx_border_l ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;"></td>
<td id="A1.T9.2.7.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T9.2.7.2.1" class="ltx_text"></span><span id="A1.T9.2.7.2.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T9.2.7.2.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T9.2.7.2.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T9.2.7.2.3.1.1" class="ltx_tr">
<span id="A1.T9.2.7.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep">(Fu et al<span class="ltx_text">.</span>, <a href="#bib.bib49" title="" class="ltx_ref">2022a</a>)</cite></span></span>
</span></span><span id="A1.T9.2.7.2.4" class="ltx_text"></span><span id="A1.T9.2.7.2.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="A1.T9.2.7.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:136.6pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T9.2.7.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T9.2.7.3.1.1" class="ltx_p"><span id="A1.T9.2.7.3.1.1.1" class="ltx_text" style="font-size:80%;">CELU-VFL utilizes cached stale statistics to estimate model gradients for local updating, thereby reducing frequent communications.</span></span>
</span>
</td>
<td id="A1.T9.2.7.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:136.6pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T9.2.7.4.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T9.2.7.4.1.1" class="ltx_p"><span id="A1.T9.2.7.4.1.1.1" class="ltx_text" style="font-size:80%;">It involves approximation with stale statistics, which introduces potential errors in estimation.</span></span>
</span>
</td>
</tr>
<tr id="A1.T9.2.8" class="ltx_tr">
<td id="A1.T9.2.8.1" class="ltx_td ltx_border_l ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;"></td>
<td id="A1.T9.2.8.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T9.2.8.2.1" class="ltx_text"></span><span id="A1.T9.2.8.2.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T9.2.8.2.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T9.2.8.2.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T9.2.8.2.3.1.1" class="ltx_tr">
<span id="A1.T9.2.8.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep">(Inoue et al<span class="ltx_text">.</span>, <a href="#bib.bib79" title="" class="ltx_ref">2023</a>)</cite></span></span>
</span></span><span id="A1.T9.2.8.2.4" class="ltx_text"></span><span id="A1.T9.2.8.2.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="A1.T9.2.8.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:136.6pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T9.2.8.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T9.2.8.3.1.1" class="ltx_p"><span id="A1.T9.2.8.3.1.1.1" class="ltx_text" style="font-size:80%;">SparseVFL reduces the data size exchanged between the server and clients by exploiting the sparsity of embeddings and gradients.</span></span>
</span>
</td>
<td id="A1.T9.2.8.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:136.6pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T9.2.8.4.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T9.2.8.4.1.1" class="ltx_p"><span id="A1.T9.2.8.4.1.1.1" class="ltx_text" style="font-size:80%;">It is not effective for dense embeddings/gradients or high-dimensional embeddings/gradients.</span></span>
</span>
</td>
</tr>
<tr id="A1.T9.2.9" class="ltx_tr">
<td id="A1.T9.2.9.1" class="ltx_td ltx_border_l ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;"></td>
<td id="A1.T9.2.9.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T9.2.9.2.1" class="ltx_text"></span><span id="A1.T9.2.9.2.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T9.2.9.2.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T9.2.9.2.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T9.2.9.2.3.1.1" class="ltx_tr">
<span id="A1.T9.2.9.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep">(Wang et al<span class="ltx_text">.</span>, <a href="#bib.bib164" title="" class="ltx_ref">2024</a>)</cite></span></span>
</span></span><span id="A1.T9.2.9.2.4" class="ltx_text"></span><span id="A1.T9.2.9.2.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="A1.T9.2.9.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:136.6pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T9.2.9.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T9.2.9.3.1.1" class="ltx_p"><span id="A1.T9.2.9.3.1.1.1" class="ltx_text" style="font-size:80%;">VFL-CZOFO applies a cascaded hybrid optimization to alleviate the slow convergence problem of ZO-based VFL, significantly reducing the communication cost.</span></span>
</span>
</td>
<td id="A1.T9.2.9.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:136.6pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T9.2.9.4.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T9.2.9.4.1.1" class="ltx_p"><span id="A1.T9.2.9.4.1.1.1" class="ltx_text" style="font-size:80%;">It increases the computational cost for the server. Besides, it requires a trade-off between compression rate and test accuracy.</span></span>
</span>
</td>
</tr>
<tr id="A1.T9.2.10" class="ltx_tr">
<td id="A1.T9.2.10.1" class="ltx_td ltx_border_l ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;"></td>
<td id="A1.T9.2.10.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T9.2.10.2.1" class="ltx_text"></span><span id="A1.T9.2.10.2.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T9.2.10.2.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T9.2.10.2.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T9.2.10.2.3.1.1" class="ltx_tr">
<span id="A1.T9.2.10.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep">(Huang et al<span class="ltx_text">.</span>, <a href="#bib.bib77" title="" class="ltx_ref">2022a</a>)</cite></span></span>
</span></span><span id="A1.T9.2.10.2.4" class="ltx_text"></span><span id="A1.T9.2.10.2.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="A1.T9.2.10.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:136.6pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T9.2.10.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T9.2.10.3.1.1" class="ltx_p"><span id="A1.T9.2.10.3.1.1.1" class="ltx_text" style="font-size:80%;">Cheetah introduces homomorphic encryption-based protocols for linear layers without expensive rotation operations and efficient primitives for non-linear functions, resulting in faster and more communication-efficient 2PC-NN inference.</span></span>
</span>
</td>
<td id="A1.T9.2.10.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:136.6pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T9.2.10.4.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T9.2.10.4.1.1" class="ltx_p"><span id="A1.T9.2.10.4.1.1.1" class="ltx_text" style="font-size:80%;">It involves multiple computationally intensive steps, including partitioning input shares, encoding to polynomials, homomorphic operations, and re-masking.</span></span>
</span>
</td>
</tr>
<tr id="A1.T9.2.11" class="ltx_tr">
<td id="A1.T9.2.11.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="A1.T9.2.11.1.1" class="ltx_text" style="font-size:80%;"><span id="A1.T9.2.11.1.1.1" class="ltx_text"></span> <span id="A1.T9.2.11.1.1.2" class="ltx_text">
<span id="A1.T9.2.11.1.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T9.2.11.1.1.2.1.1" class="ltx_tr">
<span id="A1.T9.2.11.1.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Large</span></span>
<span id="A1.T9.2.11.1.1.2.1.2" class="ltx_tr">
<span id="A1.T9.2.11.1.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Communication</span></span>
<span id="A1.T9.2.11.1.1.2.1.3" class="ltx_tr">
<span id="A1.T9.2.11.1.1.2.1.3.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Burden</span></span>
</span></span> <span id="A1.T9.2.11.1.1.3" class="ltx_text"></span></span></td>
<td id="A1.T9.2.11.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T9.2.11.2.1" class="ltx_text"></span><span id="A1.T9.2.11.2.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T9.2.11.2.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T9.2.11.2.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T9.2.11.2.3.1.1" class="ltx_tr">
<span id="A1.T9.2.11.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep">(Gu et al<span class="ltx_text">.</span>, <a href="#bib.bib57" title="" class="ltx_ref">2020</a>)</cite></span></span>
</span></span><span id="A1.T9.2.11.2.4" class="ltx_text"></span><span id="A1.T9.2.11.2.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="A1.T9.2.11.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_b ltx_border_r ltx_border_t" style="width:136.6pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T9.2.11.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T9.2.11.3.1.1" class="ltx_p"><span id="A1.T9.2.11.3.1.1.1" class="ltx_text" style="font-size:80%;">FDSKL uses random features to approximate kernel mapping functions and doubly stochastic gradients for solution updates, shown to be faster and more communication-efficient while maintaining similar generalization performance.</span></span>
</span>
</td>
<td id="A1.T9.2.11.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_b ltx_border_r ltx_border_t" style="width:136.6pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T9.2.11.4.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T9.2.11.4.1.1" class="ltx_p"><span id="A1.T9.2.11.4.1.1.1" class="ltx_text" style="font-size:80%;">The model coefficients are stored separately across different clients to maintain privacy, which introduces additional complexity.</span></span>
</span>
</td>
</tr>
</table>
</figure>
<figure id="A1.T10" class="ltx_table">
<figcaption class="ltx_caption ltx_centering" style="font-size:80%;"><span class="ltx_tag ltx_tag_table">Table 10. </span><span id="A1.T10.5.1" class="ltx_text ltx_font_bold">Works on Client Asynchrony.</span></figcaption>
<table id="A1.T10.2" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="A1.T10.2.2" class="ltx_tr">
<td id="A1.T10.2.2.3" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="A1.T10.2.2.3.1" class="ltx_text" style="font-size:80%;">Topics</span></td>
<td id="A1.T10.2.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T10.2.2.4.1" class="ltx_text"></span><span id="A1.T10.2.2.4.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T10.2.2.4.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T10.2.2.4.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T10.2.2.4.3.1.1" class="ltx_tr">
<span id="A1.T10.2.2.4.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Ref.</span></span>
</span></span><span id="A1.T10.2.2.4.4" class="ltx_text"></span><span id="A1.T10.2.2.4.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="A1.T10.1.1.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:145.1pt;padding-left:2.0pt;padding-right:2.0pt;"><span id="A1.T10.1.1.1.1" class="ltx_inline-logical-block ltx_align_top">
<span id="A1.T10.1.1.1.1.p1" class="ltx_para ltx_noindent">
<span id="A1.T10.1.1.1.1.p1.1" class="ltx_p"><span id="A1.T10.1.1.1.1.p1.1.1" class="ltx_text"></span><span id="A1.T10.1.1.1.1.p1.1.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T10.1.1.1.1.p1.1.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T10.1.1.1.1.p1.1.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T10.1.1.1.1.p1.1.3.1.1" class="ltx_tr">
<span id="A1.T10.1.1.1.1.p1.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Key Contributions</span></span>
</span></span><span id="A1.T10.1.1.1.1.p1.1.4" class="ltx_text"></span><span id="A1.T10.1.1.1.1.p1.1.5" class="ltx_text" style="font-size:80%;"></span></span>
</span></span></td>
<td id="A1.T10.2.2.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:145.1pt;padding-left:2.0pt;padding-right:2.0pt;"><span id="A1.T10.2.2.2.1" class="ltx_inline-logical-block ltx_align_top">
<span id="A1.T10.2.2.2.1.p1" class="ltx_para ltx_noindent">
<span id="A1.T10.2.2.2.1.p1.1" class="ltx_p"><span id="A1.T10.2.2.2.1.p1.1.1" class="ltx_text"></span><span id="A1.T10.2.2.2.1.p1.1.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T10.2.2.2.1.p1.1.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T10.2.2.2.1.p1.1.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T10.2.2.2.1.p1.1.3.1.1" class="ltx_tr">
<span id="A1.T10.2.2.2.1.p1.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Limitations</span></span>
</span></span><span id="A1.T10.2.2.2.1.p1.1.4" class="ltx_text"></span><span id="A1.T10.2.2.2.1.p1.1.5" class="ltx_text" style="font-size:80%;"></span></span>
</span></span></td>
</tr>
<tr id="A1.T10.2.3" class="ltx_tr">
<td id="A1.T10.2.3.1" class="ltx_td ltx_border_l ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"></td>
<td id="A1.T10.2.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T10.2.3.2.1" class="ltx_text"></span><span id="A1.T10.2.3.2.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T10.2.3.2.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T10.2.3.2.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T10.2.3.2.3.1.1" class="ltx_tr">
<span id="A1.T10.2.3.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep">(Chen et al<span class="ltx_text">.</span>, <a href="#bib.bib26" title="" class="ltx_ref">2020a</a>)</cite></span></span>
</span></span><span id="A1.T10.2.3.2.4" class="ltx_text"></span><span id="A1.T10.2.3.2.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="A1.T10.2.3.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:145.1pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T10.2.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T10.2.3.3.1.1" class="ltx_p"><span id="A1.T10.2.3.3.1.1.1" class="ltx_text" style="font-size:80%;">They propose utilizing stochastic gradient algorithms independently on each client without coordination, allowing clients to participate intermittently or strategically.</span></span>
</span>
</td>
<td id="A1.T10.2.3.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:145.1pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T10.2.3.4.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T10.2.3.4.1.1" class="ltx_p"><span id="A1.T10.2.3.4.1.1.1" class="ltx_text" style="font-size:80%;">It may become complex when dealing with nonlinear local embedding functions.</span></span>
</span>
</td>
</tr>
<tr id="A1.T10.2.4" class="ltx_tr">
<td id="A1.T10.2.4.1" class="ltx_td ltx_border_l ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;"></td>
<td id="A1.T10.2.4.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T10.2.4.2.1" class="ltx_text"></span><span id="A1.T10.2.4.2.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T10.2.4.2.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T10.2.4.2.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T10.2.4.2.3.1.1" class="ltx_tr">
<span id="A1.T10.2.4.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a href="#bib.bib97" title="" class="ltx_ref">2020a</a>)</cite></span></span>
</span></span><span id="A1.T10.2.4.2.4" class="ltx_text"></span><span id="A1.T10.2.4.2.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="A1.T10.2.4.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:145.1pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T10.2.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T10.2.4.3.1.1" class="ltx_p"><span id="A1.T10.2.4.3.1.1.1" class="ltx_text" style="font-size:80%;">They propose an efficient method for handling client asynchrony, by utilizing gradient prediction through Taylor expansion and double-end sparse compression to reduce training costs.</span></span>
</span>
</td>
<td id="A1.T10.2.4.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:145.1pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T10.2.4.4.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T10.2.4.4.1.1" class="ltx_p"><span id="A1.T10.2.4.4.1.1.1" class="ltx_text" style="font-size:80%;">It requires synchronous warm-up training at the outset, and the gradient prediction method may introduce estimation errors.</span></span>
</span>
</td>
</tr>
<tr id="A1.T10.2.5" class="ltx_tr">
<td id="A1.T10.2.5.1" class="ltx_td ltx_border_l ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;"></td>
<td id="A1.T10.2.5.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T10.2.5.2.1" class="ltx_text"></span><span id="A1.T10.2.5.2.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T10.2.5.2.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T10.2.5.2.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T10.2.5.2.3.1.1" class="ltx_tr">
<span id="A1.T10.2.5.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep">(Gu et al<span class="ltx_text">.</span>, <a href="#bib.bib58" title="" class="ltx_ref">2021</a>)</cite></span></span>
</span></span><span id="A1.T10.2.5.2.4" class="ltx_text"></span><span id="A1.T10.2.5.2.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="A1.T10.2.5.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:145.1pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T10.2.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T10.2.5.3.1.1" class="ltx_p"><span id="A1.T10.2.5.3.1.1.1" class="ltx_text" style="font-size:80%;">AFSGD-VP enhances efficiency by ensuring all computational resources remain engaged, eliminating idle time waiting for synchronization.</span></span>
</span>
</td>
<td id="A1.T10.2.5.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:145.1pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T10.2.5.4.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T10.2.5.4.1.1" class="ltx_p"><span id="A1.T10.2.5.4.1.1.1" class="ltx_text" style="font-size:80%;">As the number of clients grows, the communication overheads can restrict the scalability and speedup of the algorithms.</span></span>
</span>
</td>
</tr>
<tr id="A1.T10.2.6" class="ltx_tr">
<td id="A1.T10.2.6.1" class="ltx_td ltx_border_l ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;"></td>
<td id="A1.T10.2.6.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T10.2.6.2.1" class="ltx_text"></span><span id="A1.T10.2.6.2.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T10.2.6.2.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T10.2.6.2.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T10.2.6.2.3.1.1" class="ltx_tr">
<span id="A1.T10.2.6.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep">(Zhang et al<span class="ltx_text">.</span>, <a href="#bib.bib196" title="" class="ltx_ref">2021a</a>)</cite></span></span>
</span></span><span id="A1.T10.2.6.2.4" class="ltx_text"></span><span id="A1.T10.2.6.2.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="A1.T10.2.6.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:145.1pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T10.2.6.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T10.2.6.3.1.1" class="ltx_p"><span id="A1.T10.2.6.3.1.1.1" class="ltx_text" style="font-size:80%;">They propose a bilevel asynchronous parallel architecture, enabling asynchronous model updates across parties.</span></span>
</span>
</td>
<td id="A1.T10.2.6.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:145.1pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T10.2.6.4.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T10.2.6.4.1.1" class="ltx_p"><span id="A1.T10.2.6.4.1.1.1" class="ltx_text" style="font-size:80%;">It assumes that one or partial parties hold labels, which may not be the case in practical applications.</span></span>
</span>
</td>
</tr>
<tr id="A1.T10.2.7" class="ltx_tr">
<td id="A1.T10.2.7.1" class="ltx_td ltx_border_l ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;"></td>
<td id="A1.T10.2.7.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T10.2.7.2.1" class="ltx_text"></span><span id="A1.T10.2.7.2.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T10.2.7.2.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T10.2.7.2.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T10.2.7.2.3.1.1" class="ltx_tr">
<span id="A1.T10.2.7.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep">(Shi et al<span class="ltx_text">.</span>, <a href="#bib.bib148" title="" class="ltx_ref">2022</a>)</cite></span></span>
</span></span><span id="A1.T10.2.7.2.4" class="ltx_text"></span><span id="A1.T10.2.7.2.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="A1.T10.2.7.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:145.1pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T10.2.7.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T10.2.7.3.1.1" class="ltx_p"><span id="A1.T10.2.7.3.1.1.1" class="ltx_text" style="font-size:80%;">They propose leveraging asynchronous training to reduce waiting time.</span></span>
</span>
</td>
<td id="A1.T10.2.7.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:145.1pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T10.2.7.4.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T10.2.7.4.1.1" class="ltx_p"><span id="A1.T10.2.7.4.1.1.1" class="ltx_text" style="font-size:80%;">The computational complexity and communication cost may increase with the number of participants and the data size.</span></span>
</span>
</td>
</tr>
<tr id="A1.T10.2.8" class="ltx_tr">
<td id="A1.T10.2.8.1" class="ltx_td ltx_border_l ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;"></td>
<td id="A1.T10.2.8.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T10.2.8.2.1" class="ltx_text"></span><span id="A1.T10.2.8.2.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T10.2.8.2.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T10.2.8.2.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T10.2.8.2.3.1.1" class="ltx_tr">
<span id="A1.T10.2.8.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep">(Qiu et al<span class="ltx_text">.</span>, <a href="#bib.bib139" title="" class="ltx_ref">2023</a>)</cite></span></span>
</span></span><span id="A1.T10.2.8.2.4" class="ltx_text"></span><span id="A1.T10.2.8.2.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="A1.T10.2.8.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:145.1pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T10.2.8.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T10.2.8.3.1.1" class="ltx_p"><span id="A1.T10.2.8.3.1.1.1" class="ltx_text" style="font-size:80%;">Utilize a robust aggregation mechanism capable of handling missing or temporarily disconnected clients.</span></span>
</span>
</td>
<td id="A1.T10.2.8.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:145.1pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T10.2.8.4.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T10.2.8.4.1.1" class="ltx_p"><span id="A1.T10.2.8.4.1.1.1" class="ltx_text" style="font-size:80%;">It might require significant computational costs, rendering it less practical for real-time applications.</span></span>
</span>
</td>
</tr>
<tr id="A1.T10.2.9" class="ltx_tr">
<td id="A1.T10.2.9.1" class="ltx_td ltx_border_l ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;"></td>
<td id="A1.T10.2.9.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T10.2.9.2.1" class="ltx_text"></span><span id="A1.T10.2.9.2.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T10.2.9.2.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T10.2.9.2.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T10.2.9.2.3.1.1" class="ltx_tr">
<span id="A1.T10.2.9.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep">(Sun et al<span class="ltx_text">.</span>, <a href="#bib.bib151" title="" class="ltx_ref">2023a</a>)</cite></span></span>
</span></span><span id="A1.T10.2.9.2.4" class="ltx_text"></span><span id="A1.T10.2.9.2.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="A1.T10.2.9.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:145.1pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T10.2.9.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T10.2.9.3.1.1" class="ltx_p"><span id="A1.T10.2.9.3.1.1.1" class="ltx_text" style="font-size:80%;">Propose party-wise dropout to prevent the co-adaptation of feature extractors across parties.</span></span>
</span>
</td>
<td id="A1.T10.2.9.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:145.1pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T10.2.9.4.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T10.2.9.4.1.1" class="ltx_p"><span id="A1.T10.2.9.4.1.1.1" class="ltx_text" style="font-size:80%;">The model may rely on certain representation components from specific parties.</span></span>
</span>
</td>
</tr>
<tr id="A1.T10.2.10" class="ltx_tr">
<td id="A1.T10.2.10.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="A1.T10.2.10.1.1" class="ltx_text" style="font-size:80%;"><span id="A1.T10.2.10.1.1.1" class="ltx_text"></span> <span id="A1.T10.2.10.1.1.2" class="ltx_text">
<span id="A1.T10.2.10.1.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T10.2.10.1.1.2.1.1" class="ltx_tr">
<span id="A1.T10.2.10.1.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Client</span></span>
<span id="A1.T10.2.10.1.1.2.1.2" class="ltx_tr">
<span id="A1.T10.2.10.1.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Asynchrony</span></span>
</span></span> <span id="A1.T10.2.10.1.1.3" class="ltx_text"></span></span></td>
<td id="A1.T10.2.10.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T10.2.10.2.1" class="ltx_text"></span><span id="A1.T10.2.10.2.2" class="ltx_text" style="font-size:80%;"> </span><span id="A1.T10.2.10.2.3" class="ltx_text" style="font-size:80%;">
<span id="A1.T10.2.10.2.3.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T10.2.10.2.3.1.1" class="ltx_tr">
<span id="A1.T10.2.10.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a href="#bib.bib101" title="" class="ltx_ref">2023d</a>)</cite></span></span>
</span></span><span id="A1.T10.2.10.2.4" class="ltx_text"></span><span id="A1.T10.2.10.2.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="A1.T10.2.10.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_b ltx_border_r ltx_border_t" style="width:145.1pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T10.2.10.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T10.2.10.3.1.1" class="ltx_p"><span id="A1.T10.2.10.3.1.1.1" class="ltx_text" style="font-size:80%;">It uses secret sharing schemes for local data and models, and the aggregation of embeddings is reconstructed from non-straggling clients.</span></span>
</span>
</td>
<td id="A1.T10.2.10.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_b ltx_border_r ltx_border_t" style="width:145.1pt;padding-left:2.0pt;padding-right:2.0pt;">
<span id="A1.T10.2.10.4.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T10.2.10.4.1.1" class="ltx_p"><span id="A1.T10.2.10.4.1.1.1" class="ltx_text" style="font-size:80%;">The reconstruction may have limitations when the number of non-straggling clients is limited.</span></span>
</span>
</td>
</tr>
</table>
</figure>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2405.17494" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2405.17495" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2405.17495">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2405.17495" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2405.17496" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Wed Jun  5 16:30:01 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
