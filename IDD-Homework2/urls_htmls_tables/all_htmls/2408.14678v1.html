<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Bridging the Gap: Unpacking the Hidden Challenges in Knowledge Distillation for Online Ranking Systems</title>
<!--Generated on Mon Aug 26 22:55:33 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<meta content="Recommender Systems,  Knowledge Distillation,  Learning to Rank, 
Multitask Learning" lang="en" name="keywords"/>
<base href="/html/2408.14678v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2408.14678v1#S1" title="In Bridging the Gap: Unpacking the Hidden Challenges in Knowledge Distillation for Online Ranking Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2408.14678v1#S2" title="In Bridging the Gap: Unpacking the Hidden Challenges in Knowledge Distillation for Online Ranking Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Challenges &amp; Distillation Setup</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2408.14678v1#S3" title="In Bridging the Gap: Unpacking the Hidden Challenges in Knowledge Distillation for Online Ranking Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Live Experiments</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2408.14678v1#S4" title="In Bridging the Gap: Unpacking the Hidden Challenges in Knowledge Distillation for Online Ranking Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Conclusions And Future Work</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2408.14678v1#S5" title="In Bridging the Gap: Unpacking the Hidden Challenges in Knowledge Distillation for Online Ranking Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Speaker Bio</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line ltx_leqno">
<h1 class="ltx_title ltx_title_document">Bridging the Gap: Unpacking the Hidden Challenges in Knowledge Distillation for Online Ranking Systems</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Nikhil Khani
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_orcid"><a class="ltx_ref" href="https://orcid.org/0009-0002-8735-8955" title="ORCID identifier">0009-0002-8735-8955</a></span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id1.1.id1">Google LLC</span><span class="ltx_text ltx_affiliation_country" id="id2.2.id2">USA</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:nkhani@google.com">nkhani@google.com</a>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Shuo Yang
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_orcid"><a class="ltx_ref" href="https://orcid.org/0009-0009-1613-4031" title="ORCID identifier">0009-0009-1613-4031</a></span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id3.1.id1">Google LLC</span><span class="ltx_text ltx_affiliation_country" id="id4.2.id2">USA</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:yshuo@google.com">yshuo@google.com</a>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Aniruddh Nath
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_orcid"><a class="ltx_ref" href="https://orcid.org/0009-0006-2815-3035" title="ORCID identifier">0009-0006-2815-3035</a></span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id5.1.id1">Google LLC</span><span class="ltx_text ltx_affiliation_country" id="id6.2.id2">USA</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:aniruddhnath@google.com">aniruddhnath@google.com</a>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Yang Liu
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_orcid"><a class="ltx_ref" href="https://orcid.org/0000-0002-6010-507X" title="ORCID identifier">0000-0002-6010-507X</a></span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id7.1.id1">Google LLC</span><span class="ltx_text ltx_affiliation_country" id="id8.2.id2">USA</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:ylyangliu@google.com">ylyangliu@google.com</a>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Pendo Abbo
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_orcid"><a class="ltx_ref" href="https://orcid.org/0009-0001-1235-4231" title="ORCID identifier">0009-0001-1235-4231</a></span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id9.1.id1">Google LLC</span><span class="ltx_text ltx_affiliation_country" id="id10.2.id2">USA</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:pabbo@google.com">pabbo@google.com</a>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Li Wei
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_orcid"><a class="ltx_ref" href="https://orcid.org/0009-0008-9321-3983" title="ORCID identifier">0009-0008-9321-3983</a></span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id11.1.id1">Google LLC</span><span class="ltx_text ltx_affiliation_country" id="id12.2.id2">USA</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:liwei@google.com">liwei@google.com</a>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Shawn Andrews
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_orcid"><a class="ltx_ref" href="https://orcid.org/0009-0004-1129-8196" title="ORCID identifier">0009-0004-1129-8196</a></span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id13.1.id1">Google LLC</span><span class="ltx_text ltx_affiliation_country" id="id14.2.id2">USA</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:shawnandrews@google.com">shawnandrews@google.com</a>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Maciej Kula
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_orcid"><a class="ltx_ref" href="https://orcid.org/0009-0004-0430-5052" title="ORCID identifier">0009-0004-0430-5052</a></span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id15.1.id1">Google DeepMind</span><span class="ltx_text ltx_affiliation_country" id="id16.2.id2">USA</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:maciejkula@google.com">maciejkula@google.com</a>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Jarrod Kahn
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_orcid"><a class="ltx_ref" href="https://orcid.org/0009-0004-5401-3242" title="ORCID identifier">0009-0004-5401-3242</a></span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id17.1.id1">Google DeepMind</span><span class="ltx_text ltx_affiliation_country" id="id18.2.id2">USA</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:jarrodk@google.com">jarrodk@google.com</a>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Zhe Zhao
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_orcid"><a class="ltx_ref" href="https://orcid.org/0000-0002-6847-0186" title="ORCID identifier">0000-0002-6847-0186</a></span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id19.1.id1">University of California, Davis</span><span class="ltx_text ltx_affiliation_country" id="id20.2.id2">USA</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:zao@ucdavis.edu">zao@ucdavis.edu</a>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Lichan Hong
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_orcid"><a class="ltx_ref" href="https://orcid.org/0009-0004-9563-554X" title="ORCID identifier">0009-0004-9563-554X</a></span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id21.1.id1">Google DeepMind</span><span class="ltx_text ltx_affiliation_country" id="id22.2.id2">USA</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:lichan@google.com">lichan@google.com</a>
</span></span></span>
<span class="ltx_author_before"> and </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Ed Chi
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_orcid"><a class="ltx_ref" href="https://orcid.org/0000-0003-3230-5338" title="ORCID identifier">0000-0003-3230-5338</a></span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id23.1.id1">Google DeepMind</span><span class="ltx_text ltx_affiliation_country" id="id24.2.id2">USA</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:edchi@google.com">edchi@google.com</a>
</span></span></span>
</div>
<div class="ltx_dates">(2024)</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract.</h6>
<p class="ltx_p" id="id25.id1">Knowledge Distillation (KD) is a powerful approach for compressing a large model into a smaller, more efficient model, particularly beneficial for latency-sensitive applications like recommender systems. However, current KD research predominantly focuses on Computer Vision (CV) and NLP tasks, overlooking unique data characteristics and challenges inherent to recommender systems. This paper addresses these overlooked challenges, specifically: (1) mitigating data distribution shifts between teacher and student models, (2) efficiently identifying optimal teacher configurations within time and budgetary constraints, and (3) enabling computationally efficient and rapid sharing of teacher labels to support multiple students. We present a robust KD system developed and rigorously evaluated on multiple large-scale personalized video recommendation systems within Google. Our live experiment results demonstrate significant improvements in student model performance while ensuring consistent and reliable generation of high-quality teacher labels from a continuous data stream of data.</p>
</div>
<div class="ltx_keywords">Recommender Systems, Knowledge Distillation, Learning to Rank,
Multitask Learning
</div>
<span class="ltx_note ltx_note_frontmatter ltx_role_copyright" id="id1"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">copyright: </span>acmlicensed</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_journalyear" id="id2"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">journalyear: </span>2024</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_copyright" id="id3"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">copyright: </span>rightsretained</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_conference" id="id4"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">conference: </span>18th ACM Conference on Recommender Systems; October 14–18, 2024; Bari, Italy</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_booktitle" id="id5"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">booktitle: </span>18th ACM Conference on Recommender Systems (RecSys ’24), October 14–18, 2024, Bari, Italy</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_doi" id="id6"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">doi: </span>10.1145/3640457.3688055</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_isbn" id="id7"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">isbn: </span>979-8-4007-0505-2/24/10</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_ccs" id="id8"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">ccs: </span>Information systems Recommender systems</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_ccs" id="id9"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">ccs: </span>Information systems Learning to rank</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_ccs" id="id10"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">ccs: </span>Computing methodologies Multi-task learning</span></span></span>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1. </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Modern recommendation systems demand minimal latency. Even slight delays can negatively impact user experience, especially for large-scale video platforms serving billions of users<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a class="ltx_ref ltx_href" href="https://www.thinkwithgoogle.com/marketing-strategies/app-and-mobile/page-load-time-statistics/" title="">https://www.thinkwithgoogle.com/marketing-strategies/app-and-mobile/page-load-time-statistics/</a></span></span></span>. While larger models improve accuracy <cite class="ltx_cite ltx_citemacro_citep">(Cheng et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.14678v1#bib.bib2" title="">2016</a>; Gomez-Uribe and Hunt, <a class="ltx_ref" href="https://arxiv.org/html/2408.14678v1#bib.bib5" title="">2015</a>; Covington et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.14678v1#bib.bib4" title="">2016</a>)</cite>, they also increase serving latency, presenting a critical speed and accuracy trade off. Knowledge Distillation (KD) offers a compelling solution by transferring knowledge from a complex ”teacher” to a smaller ”student” model <cite class="ltx_cite ltx_citemacro_citep">(Hinton et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.14678v1#bib.bib7" title="">2015</a>; Cheng et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.14678v1#bib.bib3" title="">2017</a>)</cite>. This process allows the student to achieve comparable performance to the teacher without additional latency. The most prevalent method of KD involves three main steps: (1) training a large teacher model on observed data (hard-labels), (2) using teacher to generate predictions on student’s training data (soft-labels), (3) training the student on both soft and hard labels.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">This paper addresses three key challenges in deploying KD to real-world recommender systems: (1) mitigating data distribution shifts between teacher and student models using an online distillation framework with continuous teacher updates and a novel auxiliary task based distillation strategy that allows the student to ground its learning in teacher’s knowledge without leaking teacher biases in the student; (2) navigating the costly and time-consuming process of identifying optimal teacher configurations, which can take months (Fig 1), by providing empirically-backed heuristics derived from real-world experiments; and (3) highlighting the overlooked infrastructure challenge of efficiently supporting multiple students distilling from a single teacher for cost amortization and practical deployment.</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2. </span>Challenges &amp; Distillation Setup</h2>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">Our study examines multi-objective pointwise models for ranking videos within a large-scale recommendation system. These models predict short-term objectives like CTR (Click-Through Rate) and long term ones like <span class="ltx_text ltx_font_italic" id="S2.p1.1.1">E(LTV)</span>, estimating the overall value a user drives on the platform over an extended horizon.</p>
</div>
<figure class="ltx_figure" id="S2.F1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="210" id="S2.F1.g1" src="extracted/5815077/fig_3.png" width="598"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 1. </span><span class="ltx_text ltx_align_center" id="S2.F1.2.1" style="font-size:90%;">A timeline of stages in KD setup</span></figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S2.p2">
<p class="ltx_p" id="S2.p2.1">Our teacher/student models share similar architectures (Fig. 2), beginning with input and embedding layers at the bottom, then multiple shared layers stacked together. The output from the last shared layer feeds into individual towers, producing final per-task prediction logits.
<br class="ltx_break"/>
<br class="ltx_break"/><span class="ltx_text ltx_font_bold ltx_font_italic" id="S2.p2.1.1">Teacher Setup</span> typically utilizes deeper and/or wider shared and task layers compared to the students. To address model divergence common in large models, we employ training stabilization techniques, including learning rate warmup<cite class="ltx_cite ltx_citemacro_citep">(Goyal et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.14678v1#bib.bib6" title="">2017</a>)</cite>, activation clipping<cite class="ltx_cite ltx_citemacro_citep">(Krizhevsky and Hinton, <a class="ltx_ref" href="https://arxiv.org/html/2408.14678v1#bib.bib8" title="">2010</a>)</cite>, and Clippy optimizer<cite class="ltx_cite ltx_citemacro_citep">(Tang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.14678v1#bib.bib11" title="">2023</a>)</cite>.
<br class="ltx_break"/>
<br class="ltx_break"/><span class="ltx_text ltx_font_bold ltx_font_italic" id="S2.p2.1.2">Student Setup</span> jointly trains on both hard (observed data) and soft labels (teacher predictions) by incorporating an additional distillation loss term. The most commonly used method of distillation, referred as <span class="ltx_text ltx_font_italic" id="S2.p2.1.3">“direct distillation”</span> (Fig 2) uses a single logit to minimize both hard and soft label losses. While effective in CV/NLP with static data distribution, this is suboptimal for recommender systems with rapidly changing data. As an example, we have E(LTV), a noisy and under-calibrated objective. While larger models with more learning capacity can predict LTV accurately, they continue to be under-calibrated <cite class="ltx_cite ltx_citemacro_citep">(Steck, <a class="ltx_ref" href="https://arxiv.org/html/2408.14678v1#bib.bib10" title="">2018</a>)</cite>. Directly using these biased predictions from teachers as guiding examples in students leads to ”noise-compounding” <em class="ltx_emph ltx_font_italic" id="S2.p2.1.4">(Challenge #1)</em>. This observation highlights that during distillation <span class="ltx_text ltx_font_bold" id="S2.p2.1.5">the teacher imparts not only its knowledge, but also its inherent biases to the student</span>. Our auxiliary distillation strategy addresses this by using separate task logits for hard and soft label losses. This reduces the coupling between observed data and teacher labels, improving the student’s ability to leverage teacher knowledge while avoiding bias. Table 1 shows a <span class="ltx_text ltx_font_bold" id="S2.p2.1.6">0.4%</span> reduction in E(LTV) loss using this technique. Auxiliary distillation has shown to be effective in multiple KD implementations within Google. Additionally, we also continuously train the teacher on new data to ensure up-to-date guidance for students.
<br class="ltx_break"/>
<br class="ltx_break"/><span class="ltx_text ltx_font_bold ltx_font_italic" id="S2.p2.1.7">Experimentation Time:</span> As illustrated in Fig. 1, distillation life-cycle involves months of continuously training teachers and additional weeks of student training and live experiments. This extensive process makes teacher development computationally expensive, especially for new teacher setups <em class="ltx_emph ltx_font_italic" id="S2.p2.1.8">(Challenge #2)</em>. To reduce this burden, we offer empirically-backed heuristics based on experimental results (Section 3), addressing questions such as: (1) <span class="ltx_text ltx_font_italic" id="S2.p2.1.9">What’s an ideal teacher size to train?</span>, (2) <span class="ltx_text ltx_font_italic" id="S2.p2.1.10">Should all objectives be distilled?</span>, (3) <span class="ltx_text ltx_font_italic" id="S2.p2.1.11">If not, which ones to avoid?</span></p>
</div>
<figure class="ltx_figure" id="S2.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="372" id="S2.F2.g1" src="extracted/5815077/fig_4.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2. </span>Direct vs Auxiliary distillation</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S2.p3">
<p class="ltx_p" id="S2.p3.1"><span class="ltx_text ltx_font_bold ltx_font_italic" id="S2.p3.1.1">Amortizing Teacher Cost:</span> A commonly overlooked infrastructure challenge in KD is the high cost of training and maintaining a teacher. Unlike CV/NLP where data stability allows for less frequent retraining, recommendation systems with dynamic user preferences and item catalogs require continuous model updates. To reduce this burden of continuously updating the large model we amortize its cost across multiple student models served in different contexts (Fig 3) allowing a single teacher model to improve a fleet of students. This requires efficient storage and sharing of teacher labels <em class="ltx_emph ltx_font_italic" id="S2.p3.1.2">(Challenge #3)</em>. Our proposed solution involves writing inferences from the trained teacher into a columnar database, prioritizing read performance over strict ACID properties. High data consistency is required to ensure students access the same soft-labels and have similar teacher label coverage. Doing all this on new data (teacher training, label writing, label dissemination) with minimal delay, consistently and reliably is a significant infrastructure challenge. While we use an internal version of BigQuery for our implementation, other columnar databases like Apache Cassandra would work equally well.</p>
</div>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3. </span>Live Experiments</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">We evaluate our setup with various teacher configurations and distillation strategies, comparing their offline (AUC for classification, RMSE for regression) and online (engagement, satisfaction) performance against a control model with similar architecture as the student, but trained on hard labels only (no-distillation).
<br class="ltx_break"/></p>
</div>
<figure class="ltx_figure" id="S3.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="329" id="S3.F3.g1" src="extracted/5815077/fig_5.png" width="473"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3. </span>Fleet of students sharing a single teacher’s labels</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S3.p2">
<p class="ltx_p" id="S3.p2.1"><span class="ltx_text ltx_font_bold ltx_font_italic" id="S3.p2.1.1">Limiting Bias Leakage in Distillation:</span> Table 1 shows the benefit of using auxiliary distillation on noisy tasks, or more generally, as a way to reduce teacher bias from leaking into students. Auxiliary distillation shows a <span class="ltx_text ltx_font_bold" id="S3.p2.1.2">0.4%</span> improvement in E(LTV) compared to direct distillation. In addition, students using direct distillation learn very little from the teacher, as evidenced by the fact that its offline E(LTV) performance is virtually identical to the no-distillation control.</p>
</div>
<figure class="ltx_table" id="S3.tab1">
<table class="ltx_tabular ltx_align_middle" id="S3.tab1.1">
<tr class="ltx_tr" id="S3.tab1.1.1">
<td class="ltx_td ltx_border_r ltx_border_tt" id="S3.tab1.1.1.1"></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.tab1.1.1.2">
<span class="ltx_text" id="S3.tab1.1.1.2.1"></span><span class="ltx_text ltx_font_bold" id="S3.tab1.1.1.2.2" style="font-size:90%;"> <span class="ltx_text" id="S3.tab1.1.1.2.2.1">
<span class="ltx_tabular ltx_align_middle" id="S3.tab1.1.1.2.2.1.1">
<span class="ltx_tr" id="S3.tab1.1.1.2.2.1.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S3.tab1.1.1.2.2.1.1.1.1">Control</span></span>
<span class="ltx_tr" id="S3.tab1.1.1.2.2.1.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S3.tab1.1.1.2.2.1.1.2.1">(no-distillation)</span></span>
</span></span><span class="ltx_text" id="S3.tab1.1.1.2.2.2"></span></span>
</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.tab1.1.1.3">
<span class="ltx_text" id="S3.tab1.1.1.3.1"></span><span class="ltx_text ltx_font_bold" id="S3.tab1.1.1.3.2" style="font-size:90%;"> <span class="ltx_text" id="S3.tab1.1.1.3.2.1">
<span class="ltx_tabular ltx_align_middle" id="S3.tab1.1.1.3.2.1.1">
<span class="ltx_tr" id="S3.tab1.1.1.3.2.1.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S3.tab1.1.1.3.2.1.1.1.1">Direct</span></span>
<span class="ltx_tr" id="S3.tab1.1.1.3.2.1.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S3.tab1.1.1.3.2.1.1.2.1">Distillation</span></span>
</span></span><span class="ltx_text" id="S3.tab1.1.1.3.2.2"></span></span>
</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.tab1.1.1.4">
<span class="ltx_text" id="S3.tab1.1.1.4.1"></span><span class="ltx_text ltx_font_bold" id="S3.tab1.1.1.4.2" style="font-size:90%;"> <span class="ltx_text" id="S3.tab1.1.1.4.2.1">
<span class="ltx_tabular ltx_align_middle" id="S3.tab1.1.1.4.2.1.1">
<span class="ltx_tr" id="S3.tab1.1.1.4.2.1.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S3.tab1.1.1.4.2.1.1.1.1">Auxiliary</span></span>
<span class="ltx_tr" id="S3.tab1.1.1.4.2.1.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S3.tab1.1.1.4.2.1.1.2.1">Distillation</span></span>
</span></span><span class="ltx_text" id="S3.tab1.1.1.4.2.2"></span></span>
</td>
</tr>
<tr class="ltx_tr" id="S3.tab1.1.2">
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_r ltx_border_t" id="S3.tab1.1.2.1"><span class="ltx_text" id="S3.tab1.1.2.1.1" style="font-size:90%;">E(LTV) RMSE</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S3.tab1.1.2.2"><span class="ltx_text" id="S3.tab1.1.2.2.1" style="font-size:90%;">12.21</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S3.tab1.1.2.3"><span class="ltx_text" id="S3.tab1.1.2.3.1" style="font-size:90%;">12.20</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S3.tab1.1.2.4"><span class="ltx_text ltx_font_bold" id="S3.tab1.1.2.4.1" style="font-size:90%;">12.15</span></td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;">Table 1: Effect of distillation strategy on noisy objectives (lower rmse is better).</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S3.p3">
<p class="ltx_p" id="S3.p3.1"><span class="ltx_text ltx_font_bold ltx_font_italic" id="S3.p3.1.1">Knowledge Distillation By Teacher/Student Size:</span> Table 2 shows how student performance improves when distilling even from a relatively small teacher (2x the student size). The 4x teacher yields further gains (additional <span class="ltx_text ltx_font_bold" id="S3.p3.1.2">0.43%</span> engagement, <span class="ltx_text ltx_font_bold" id="S3.p3.1.3">0.46%</span> satisfaction). However, this scaling effect of teacher is not expected to continue indefinitely. As demonstrated by <cite class="ltx_cite ltx_citemacro_citet">Mirzadeh et al<span class="ltx_text">.</span> (<a class="ltx_ref" href="https://arxiv.org/html/2408.14678v1#bib.bib9" title="">2020</a>)</cite>, excessively growing the teacher size eventually creates a large knowledge gap between teacher-student making it harder for the student to learn from teacher predictions and hindering the overall performance.</p>
</div>
<figure class="ltx_table" id="S3.4">
<table class="ltx_tabular ltx_align_middle" id="S3.4.4">
<tr class="ltx_tr" id="S3.4.4.4">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S3.4.4.4.5">
<span class="ltx_text" id="S3.4.4.4.5.1"></span><span class="ltx_text ltx_font_bold" id="S3.4.4.4.5.2" style="font-size:90%;"> <span class="ltx_text" id="S3.4.4.4.5.2.1">
<span class="ltx_tabular ltx_align_middle" id="S3.4.4.4.5.2.1.1">
<span class="ltx_tr" id="S3.4.4.4.5.2.1.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S3.4.4.4.5.2.1.1.1.1">Teacher</span></span>
<span class="ltx_tr" id="S3.4.4.4.5.2.1.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S3.4.4.4.5.2.1.1.2.1">Size</span></span>
</span></span><span class="ltx_text" id="S3.4.4.4.5.2.2"></span></span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_middle ltx_border_tt" id="S3.1.1.1.1" style="width:25.6pt;"><span class="ltx_inline-logical-block ltx_align_top" id="S3.1.1.1.1.1">
<span class="ltx_para ltx_noindent" id="S3.1.1.1.1.1.p1">
<span class="ltx_p" id="S3.1.1.1.1.1.p1.1"><span class="ltx_text" id="S3.1.1.1.1.1.p1.1.1"></span><span class="ltx_text ltx_font_bold" id="S3.1.1.1.1.1.p1.1.2" style="font-size:90%;"> </span><span class="ltx_text ltx_font_bold" id="S3.1.1.1.1.1.p1.1.3" style="font-size:90%;">
<span class="ltx_tabular ltx_align_middle" id="S3.1.1.1.1.1.p1.1.3.1">
<span class="ltx_tr" id="S3.1.1.1.1.1.p1.1.3.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S3.1.1.1.1.1.p1.1.3.1.1.1">Teacher</span></span>
<span class="ltx_tr" id="S3.1.1.1.1.1.p1.1.3.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S3.1.1.1.1.1.p1.1.3.1.2.1">AUC</span></span>
</span></span><span class="ltx_text" id="S3.1.1.1.1.1.p1.1.4"></span><span class="ltx_text ltx_font_bold" id="S3.1.1.1.1.1.p1.1.5" style="font-size:90%;"></span></span>
</span></span></td>
<td class="ltx_td ltx_align_justify ltx_align_middle ltx_border_tt" id="S3.2.2.2.2" style="width:25.6pt;"><span class="ltx_inline-logical-block ltx_align_top" id="S3.2.2.2.2.1">
<span class="ltx_para ltx_noindent" id="S3.2.2.2.2.1.p1">
<span class="ltx_p" id="S3.2.2.2.2.1.p1.1"><span class="ltx_text" id="S3.2.2.2.2.1.p1.1.1"></span><span class="ltx_text ltx_font_bold" id="S3.2.2.2.2.1.p1.1.2" style="font-size:90%;"> </span><span class="ltx_text ltx_font_bold" id="S3.2.2.2.2.1.p1.1.3" style="font-size:90%;">
<span class="ltx_tabular ltx_align_middle" id="S3.2.2.2.2.1.p1.1.3.1">
<span class="ltx_tr" id="S3.2.2.2.2.1.p1.1.3.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S3.2.2.2.2.1.p1.1.3.1.1.1">Student</span></span>
<span class="ltx_tr" id="S3.2.2.2.2.1.p1.1.3.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S3.2.2.2.2.1.p1.1.3.1.2.1">AUC</span></span>
</span></span><span class="ltx_text" id="S3.2.2.2.2.1.p1.1.4"></span><span class="ltx_text ltx_font_bold" id="S3.2.2.2.2.1.p1.1.5" style="font-size:90%;"></span></span>
</span></span></td>
<td class="ltx_td ltx_align_justify ltx_align_middle ltx_border_tt" id="S3.3.3.3.3" style="width:41.3pt;"><span class="ltx_inline-logical-block ltx_align_top" id="S3.3.3.3.3.1">
<span class="ltx_para ltx_noindent" id="S3.3.3.3.3.1.p1">
<span class="ltx_p" id="S3.3.3.3.3.1.p1.1"><span class="ltx_text" id="S3.3.3.3.3.1.p1.1.1"></span><span class="ltx_text ltx_font_bold" id="S3.3.3.3.3.1.p1.1.2" style="font-size:90%;"> </span><span class="ltx_text ltx_font_bold" id="S3.3.3.3.3.1.p1.1.3" style="font-size:90%;">
<span class="ltx_tabular ltx_align_middle" id="S3.3.3.3.3.1.p1.1.3.1">
<span class="ltx_tr" id="S3.3.3.3.3.1.p1.1.3.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S3.3.3.3.3.1.p1.1.3.1.1.1">Engagement</span></span>
<span class="ltx_tr" id="S3.3.3.3.3.1.p1.1.3.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S3.3.3.3.3.1.p1.1.3.1.2.1">metric</span></span>
</span></span><span class="ltx_text" id="S3.3.3.3.3.1.p1.1.4"></span><span class="ltx_text ltx_font_bold" id="S3.3.3.3.3.1.p1.1.5" style="font-size:90%;"></span></span>
</span></span></td>
<td class="ltx_td ltx_align_justify ltx_align_middle ltx_border_tt" id="S3.4.4.4.4" style="width:41.3pt;"><span class="ltx_inline-logical-block ltx_align_top" id="S3.4.4.4.4.1">
<span class="ltx_para ltx_noindent" id="S3.4.4.4.4.1.p1">
<span class="ltx_p" id="S3.4.4.4.4.1.p1.1"><span class="ltx_text" id="S3.4.4.4.4.1.p1.1.1"></span><span class="ltx_text ltx_font_bold" id="S3.4.4.4.4.1.p1.1.2" style="font-size:90%;"> </span><span class="ltx_text ltx_font_bold" id="S3.4.4.4.4.1.p1.1.3" style="font-size:90%;">
<span class="ltx_tabular ltx_align_middle" id="S3.4.4.4.4.1.p1.1.3.1">
<span class="ltx_tr" id="S3.4.4.4.4.1.p1.1.3.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S3.4.4.4.4.1.p1.1.3.1.1.1">Satisfaction</span></span>
<span class="ltx_tr" id="S3.4.4.4.4.1.p1.1.3.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S3.4.4.4.4.1.p1.1.3.1.2.1">metric</span></span>
</span></span><span class="ltx_text" id="S3.4.4.4.4.1.p1.1.4"></span><span class="ltx_text ltx_font_bold" id="S3.4.4.4.4.1.p1.1.5" style="font-size:90%;"></span></span>
</span></span></td>
</tr>
<tr class="ltx_tr" id="S3.4.4.5">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.4.4.5.1">
<span class="ltx_text" id="S3.4.4.5.1.1"></span><span class="ltx_text ltx_font_bold" id="S3.4.4.5.1.2" style="font-size:90%;"> <span class="ltx_text" id="S3.4.4.5.1.2.1">
<span class="ltx_tabular ltx_align_middle" id="S3.4.4.5.1.2.1.1">
<span class="ltx_tr" id="S3.4.4.5.1.2.1.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S3.4.4.5.1.2.1.1.1.1">Control</span></span>
<span class="ltx_tr" id="S3.4.4.5.1.2.1.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S3.4.4.5.1.2.1.1.2.1">(no-distillation)</span></span>
</span></span><span class="ltx_text" id="S3.4.4.5.1.2.2"></span></span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" id="S3.4.4.5.2" style="width:25.6pt;">
<span class="ltx_inline-block ltx_align_top" id="S3.4.4.5.2.1">
<span class="ltx_p" id="S3.4.4.5.2.1.1"><span class="ltx_text" id="S3.4.4.5.2.1.1.1" style="font-size:90%;">-</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" id="S3.4.4.5.3" style="width:25.6pt;">
<span class="ltx_inline-block ltx_align_top" id="S3.4.4.5.3.1">
<span class="ltx_p" id="S3.4.4.5.3.1.1"><span class="ltx_text" id="S3.4.4.5.3.1.1.1" style="font-size:90%;">77.86</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" id="S3.4.4.5.4" style="width:41.3pt;">
<span class="ltx_inline-block ltx_align_top" id="S3.4.4.5.4.1">
<span class="ltx_p" id="S3.4.4.5.4.1.1"><span class="ltx_text" id="S3.4.4.5.4.1.1.1" style="font-size:90%;">-</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" id="S3.4.4.5.5" style="width:41.3pt;">
<span class="ltx_inline-block ltx_align_top" id="S3.4.4.5.5.1">
<span class="ltx_p" id="S3.4.4.5.5.1.1"><span class="ltx_text" id="S3.4.4.5.5.1.1.1" style="font-size:90%;">-</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S3.4.4.6">
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.4.4.6.1"><span class="ltx_text ltx_font_bold" id="S3.4.4.6.1.1" style="font-size:90%;">Large (2x)</span></td>
<td class="ltx_td ltx_align_justify ltx_align_middle" id="S3.4.4.6.2" style="width:25.6pt;">
<span class="ltx_inline-block ltx_align_top" id="S3.4.4.6.2.1">
<span class="ltx_p" id="S3.4.4.6.2.1.1"><span class="ltx_text" id="S3.4.4.6.2.1.1.1" style="font-size:90%;">78.34</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_middle" id="S3.4.4.6.3" style="width:25.6pt;">
<span class="ltx_inline-block ltx_align_top" id="S3.4.4.6.3.1">
<span class="ltx_p" id="S3.4.4.6.3.1.1"><span class="ltx_text" id="S3.4.4.6.3.1.1.1" style="font-size:90%;">78.02</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_middle" id="S3.4.4.6.4" style="width:41.3pt;">
<span class="ltx_inline-block ltx_align_top" id="S3.4.4.6.4.1">
<span class="ltx_p" id="S3.4.4.6.4.1.1"><span class="ltx_text" id="S3.4.4.6.4.1.1.1" style="font-size:90%;">+0.42% (+0.42%)*</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_middle" id="S3.4.4.6.5" style="width:41.3pt;">
<span class="ltx_inline-block ltx_align_top" id="S3.4.4.6.5.1">
<span class="ltx_p" id="S3.4.4.6.5.1.1"><span class="ltx_text" id="S3.4.4.6.5.1.1.1" style="font-size:90%;">+0.34% (+0.34%)*</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S3.4.4.7">
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S3.4.4.7.1"><span class="ltx_text ltx_font_bold" id="S3.4.4.7.1.1" style="font-size:90%;">X-Large (4x)</span></td>
<td class="ltx_td ltx_align_justify ltx_align_middle ltx_border_bb" id="S3.4.4.7.2" style="width:25.6pt;">
<span class="ltx_inline-block ltx_align_top" id="S3.4.4.7.2.1">
<span class="ltx_p" id="S3.4.4.7.2.1.1"><span class="ltx_text ltx_font_bold" id="S3.4.4.7.2.1.1.1" style="font-size:90%;">78.65</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_middle ltx_border_bb" id="S3.4.4.7.3" style="width:25.6pt;">
<span class="ltx_inline-block ltx_align_top" id="S3.4.4.7.3.1">
<span class="ltx_p" id="S3.4.4.7.3.1.1"><span class="ltx_text ltx_font_bold" id="S3.4.4.7.3.1.1.1" style="font-size:90%;">78.06</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_middle ltx_border_bb" id="S3.4.4.7.4" style="width:41.3pt;">
<span class="ltx_inline-block ltx_align_top" id="S3.4.4.7.4.1">
<span class="ltx_p" id="S3.4.4.7.4.1.1"><span class="ltx_text ltx_font_bold" id="S3.4.4.7.4.1.1.1" style="font-size:90%;">+0.85%</span><span class="ltx_text" id="S3.4.4.7.4.1.1.2" style="font-size:90%;"> (+0.43%)*</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_middle ltx_border_bb" id="S3.4.4.7.5" style="width:41.3pt;">
<span class="ltx_inline-block ltx_align_top" id="S3.4.4.7.5.1">
<span class="ltx_p" id="S3.4.4.7.5.1.1"><span class="ltx_text ltx_font_bold" id="S3.4.4.7.5.1.1.1" style="font-size:90%;">+0.80%</span><span class="ltx_text" id="S3.4.4.7.5.1.1.2" style="font-size:90%;"> (+0.46%)*</span></span>
</span>
</td>
</tr>
</table>
<figcaption class="ltx_caption" style="font-size:90%;">Table 2: Student offline (CTR AUC) and online (LE metrics) performance (higher is better), as teacher size increases. All values compared to no-distillation control. Values in parenthesis indicate % change from the previous row and * denotes statsig with 95% CI</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S3.p4">
<br class="ltx_break"/>
<p class="ltx_p" id="S3.p4.1"><span class="ltx_text ltx_font_bold ltx_font_italic" id="S3.p4.1.1">Identifying the Objectives to Distill:</span> Determining a priori which tasks benefit from KD in a multi-task setup is difficult. We investigate this by categorizing model objectives into (1) Primary Engagement Tasks (PET) (2) Primary Satisfaction Tasks (PST) and (3) Others. We train student models with a combinations of these objectives. Table 3 shows that distilling only PET objectives results in the lowest performance gains, aligning with our existing understanding that overemphasizing engagement can promote clickbaity recommendations and harm user satisfaction. Interestingly, distilling both PET and PST objectives led to the highest improvements, even surpassing distilling all objectives (PET+PST+Others). This suggests that while KD targets individual tasks, its effects can spread to shared model layers, potentially causing task conflicts. Thus, a selective approach to task distillation is crucial for optimizing student model performance in multi-task setting.</p>
</div>
<figure class="ltx_table" id="S3.tab2">
<table class="ltx_tabular ltx_align_middle" id="S3.tab2.1">
<tr class="ltx_tr" id="S3.tab2.1.1">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" id="S3.tab2.1.1.1"><span class="ltx_text" id="S3.tab2.1.1.1.1" style="font-size:90%;">Distilled Objectives</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.tab2.1.1.2"><span class="ltx_text ltx_font_bold" id="S3.tab2.1.1.2.1" style="font-size:90%;">Engagement Metric</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.tab2.1.1.3"><span class="ltx_text ltx_font_bold" id="S3.tab2.1.1.3.1" style="font-size:90%;">Satisfaction Metric</span></td>
</tr>
<tr class="ltx_tr" id="S3.tab2.1.2">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.tab2.1.2.1"><span class="ltx_text" id="S3.tab2.1.2.1.1" style="font-size:90%;">PET</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.tab2.1.2.2"><span class="ltx_text" id="S3.tab2.1.2.2.1" style="font-size:90%;">+0.75%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.tab2.1.2.3"><span class="ltx_text" id="S3.tab2.1.2.3.1" style="font-size:90%;">+0.39%</span></td>
</tr>
<tr class="ltx_tr" id="S3.tab2.1.3">
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.tab2.1.3.1"><span class="ltx_text" id="S3.tab2.1.3.1.1" style="font-size:90%;">PET + PST</span></td>
<td class="ltx_td ltx_align_center" id="S3.tab2.1.3.2"><span class="ltx_text ltx_font_bold" id="S3.tab2.1.3.2.1" style="font-size:90%;">+1.13%</span></td>
<td class="ltx_td ltx_align_center" id="S3.tab2.1.3.3"><span class="ltx_text ltx_font_bold" id="S3.tab2.1.3.3.1" style="font-size:90%;">+0.39%</span></td>
</tr>
<tr class="ltx_tr" id="S3.tab2.1.4">
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_r" id="S3.tab2.1.4.1"><span class="ltx_text" id="S3.tab2.1.4.1.1" style="font-size:90%;">PET + PST + Others</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.tab2.1.4.2"><span class="ltx_text" id="S3.tab2.1.4.2.1" style="font-size:90%;">+0.85%</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.tab2.1.4.3"><span class="ltx_text" id="S3.tab2.1.4.3.1" style="font-size:90%;">+0.39%</span></td>
</tr>
</table>
<figcaption class="ltx_caption" style="font-size:90%;">Table 3: Effect of distilling various objectives on student quality.</figcaption>
</figure>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4. </span>Conclusions And Future Work</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">In this paper, we addressed the unique challenges of implementing Knowledge Distillation (KD) in large-scale recommender systems, a domain often neglected in KD research. We introduced an online distillation framework with continuous teacher updates and a novel auxiliary task-based distillation strategy to mitigate data distribution shifts and bias leakage. Additionally, we presented empirically-derived heuristics gleaned from real-world experiments. We recommend starting with a teacher model 2x the size of the student, so it can train and converge faster, without being so over-parameterized as to increase the knowledge gap between teacher and student. And, while the ideal set of distilled objectives is context-dependent, we recommend prioritizing primary engagement and satisfaction tasks, to reduce task conflict during distillation. Removing these tasks from teacher training altogether can further enhance the teacher’s accuracy on PET and PST.
<br class="ltx_break"/>Future work in this area will focus on optimizing the latency of teacher label propagation, efficiently training larger model sizes and increasing the breadth of the teacher by including data and objectives from from multiple surfaces while incorporating domain generalization techniques.</p>
</div>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5. </span>Speaker Bio</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1"><span class="ltx_text ltx_font_bold" id="S5.p1.1.1">Nikhil Khani</span> is a Senior Software Engineer at YouTube (Google), where he works on improving YouTube’s Homepage Ranking.
<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="S5.p1.1.2">Li Wei</span> is a Senior Staff Engineer at YouTube (Google), working on the WatchNext Team.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(1)</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cheng et al<span class="ltx_text" id="bib.bib2.2.2.1">.</span> (2016)</span>
<span class="ltx_bibblock">
Heng-Tze Cheng, Levent Koc, Jeremiah Harmsen, Tal Shaked, Tushar Chandra, Hrishi Aradhye, Glen Anderson, Greg Corrado, Wei Chai, Mustafa Ispir, et al<span class="ltx_text" id="bib.bib2.3.1">.</span> 2016.

</span>
<span class="ltx_bibblock">Wide &amp; deep learning for recommender systems. In <em class="ltx_emph ltx_font_italic" id="bib.bib2.4.1">Proceedings of the 1st workshop on deep learning for recommender systems</em>. 7–10.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cheng et al<span class="ltx_text" id="bib.bib3.2.2.1">.</span> (2017)</span>
<span class="ltx_bibblock">
Yu Cheng, Duo Wang, Pan Zhou, and Tao Zhang. 2017.

</span>
<span class="ltx_bibblock">A survey of model compression and acceleration for deep neural networks. arXiv 2017.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib3.3.1">arXiv preprint arXiv:1710.09282</em> (2017).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Covington et al<span class="ltx_text" id="bib.bib4.2.2.1">.</span> (2016)</span>
<span class="ltx_bibblock">
Paul Covington, Jay Adams, and Emre Sargin. 2016.

</span>
<span class="ltx_bibblock">Deep neural networks for youtube recommendations. In <em class="ltx_emph ltx_font_italic" id="bib.bib4.3.1">Proceedings of the 10th ACM conference on recommender systems</em>. 191–198.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gomez-Uribe and Hunt (2015)</span>
<span class="ltx_bibblock">
Carlos A Gomez-Uribe and Neil Hunt. 2015.

</span>
<span class="ltx_bibblock">The netflix recommender system: Algorithms, business value, and innovation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">ACM Transactions on Management Information Systems (TMIS)</em> 6, 4 (2015), 1–19.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Goyal et al<span class="ltx_text" id="bib.bib6.2.2.1">.</span> (2017)</span>
<span class="ltx_bibblock">
Priya Goyal, Piotr Dollár, Ross Girshick, Pieter Noordhuis, Lukasz Wesolowski, Aapo Kyrola, Andrew Tulloch, Yangqing Jia, and Kaiming He. 2017.

</span>
<span class="ltx_bibblock">Accurate, large minibatch sgd: Training imagenet in 1 hour.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib6.3.1">arXiv preprint arXiv:1706.02677</em> (2017).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hinton et al<span class="ltx_text" id="bib.bib7.2.2.1">.</span> (2015)</span>
<span class="ltx_bibblock">
Geoffrey Hinton, Oriol Vinyals, and Jeff Dean. 2015.

</span>
<span class="ltx_bibblock">Distilling the knowledge in a neural network.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib7.3.1">arXiv preprint arXiv:1503.02531</em> (2015).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Krizhevsky and Hinton (2010)</span>
<span class="ltx_bibblock">
Alex Krizhevsky and Geoff Hinton. 2010.

</span>
<span class="ltx_bibblock">Convolutional deep belief networks on cifar-10.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">Unpublished manuscript</em> 40, 7 (2010), 1–9.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mirzadeh et al<span class="ltx_text" id="bib.bib9.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Seyed Iman Mirzadeh, Mehrdad Farajtabar, Ang Li, Nir Levine, Akihiro Matsukawa, and Hassan Ghasemzadeh. 2020.

</span>
<span class="ltx_bibblock">Improved knowledge distillation via teacher assistant. In <em class="ltx_emph ltx_font_italic" id="bib.bib9.3.1">Proceedings of the AAAI conference on artificial intelligence</em>, Vol. 34. 5191–5198.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Steck (2018)</span>
<span class="ltx_bibblock">
Harald Steck. 2018.

</span>
<span class="ltx_bibblock">Calibrated recommendations. In <em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">Proceedings of the 12th ACM conference on recommender systems</em>. 154–162.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tang et al<span class="ltx_text" id="bib.bib11.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Jiaxi Tang, Yoel Drori, Daryl Chang, Maheswaran Sathiamoorthy, Justin Gilmer, Li Wei, Xinyang Yi, Lichan Hong, and Ed H Chi. 2023.

</span>
<span class="ltx_bibblock">Improving Training Stability for Multitask Ranking Models in Recommender Systems.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib11.3.1">arXiv preprint arXiv:2302.09178</em> (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
</ul>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Mon Aug 26 22:55:33 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
