<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2104.07557] Decentralized Federated Learning for UAV Networks: Architecture, Challenges, and Opportunities</title><meta property="og:description" content="Unmanned aerial vehicles (UAVs), or say drones, are envisioned to support extensive applications in next-generation wireless networks in both civil and military fields. Empowering UAVs networks intelligence by artifici…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Decentralized Federated Learning for UAV Networks: Architecture, Challenges, and Opportunities">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Decentralized Federated Learning for UAV Networks: Architecture, Challenges, and Opportunities">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2104.07557">

<!--Generated on Sun Mar 17 02:53:57 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Decentralized Federated Learning for UAV Networks: Architecture, Challenges, and Opportunities</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Yuben Qu,
Haipeng Dai,
Yan Zhuang,
Jiafa Chen,
Chao Dong,
Fan Wu,
Song Guo
</span><span class="ltx_author_notes">Y. Qu, J. Chen and C. Dong are with Nanjing University of Aeronautics and Astronautics, Nanjing, China. Y. Qu is also with Shanghai Jiao Tong University, Shanghai, China.Y. Zhuang, and F. Wu are with Shanghai Jiao Tong University, Shanghai, China.H. Dai is with Nanjing University, Nanjing, China.S. Guo is with The Hong Kong Polytechnic University, Hong Kong, China.</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id9.id1" class="ltx_p">Unmanned aerial vehicles (UAVs), or say drones, are envisioned to support extensive applications in next-generation wireless networks in both civil and military fields. Empowering UAVs networks intelligence by artificial intelligence (AI) especially machine learning (ML) techniques is inevitable and appealing to enable the aforementioned applications. To solve the problems of traditional cloud-centric ML for UAV networks such as privacy concern, unacceptable latency, and resource burden, a distributed ML technique, <span id="id9.id1.1" class="ltx_text ltx_font_italic">i.e.</span>, federated learning (FL), has been recently proposed to enable multiple UAVs to collaboratively train ML model without letting out raw data. However, almost all existing FL paradigms are still centralized, <span id="id9.id1.2" class="ltx_text ltx_font_italic">i.e.</span>, a central entity is in charge of ML model aggregation and fusion over the whole network, which could result in the issue of a single point of failure and are inappropriate to UAV networks with both unreliable nodes and links. Thus motivated, in this article, we propose a novel architecture called DFL-UN (<span id="id9.id1.3" class="ltx_text ltx_framed ltx_framed_underline">D</span>ecentralized <span id="id9.id1.4" class="ltx_text ltx_framed ltx_framed_underline">F</span>ederated <span id="id9.id1.5" class="ltx_text ltx_framed ltx_framed_underline">L</span>earning for <span id="id9.id1.6" class="ltx_text ltx_framed ltx_framed_underline">U</span>AV <span id="id9.id1.7" class="ltx_text ltx_framed ltx_framed_underline">N</span>etworks), which enables FL within UAV networks without a central entity. We also conduct a preliminary simulation study to validate the feasibility and effectiveness of the DFL-UN architecture. Finally, we discuss the main challenges and potential research directions in the DFL-UN.</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">I </span><span id="S1.1.1" class="ltx_text ltx_font_smallcaps">Introduction</span>
</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Unmanned aerial vehicles (UAVs), also known as drones, are expected to play a critical role in numerous stirring applications in next-generation wireless networks, ranging from delivery of goods, monitoring, surveillance, to telecommunications in both civil and military fields. On one hand, owing to their flexibility, line-of-sight (LoS) connections, and 3D mobility, UAVs could act as flying base stations (BSs) to deliver communication/computing/caching services in future wireless networks, which compensates the shortcoming of traditional infrastructure-based networks. On the other hand, UAVs can also serve as flying users to support emerging applications including remote sensing, item delivery, target recognition/tracking, and even virtual reality. To enable the aforementioned applications, it is an inevitable and appealing trend to intelligentize UAV networks by artificial intelligence (AI) especially machine learning (ML) techniques.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">While ML has already demonstrated its power to bring intelligence to wireless networks including UAV networks, traditional ML approaches are cloud-centric, <span id="S1.p2.1.1" class="ltx_text ltx_font_italic">i.e.</span>, all the data is required to be transmitted to a cloud data center and processed therein, which may be inappropriate for UAV networks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>. Firstly, the data generated by each UAV may be inaccessible due to the well-known privacy concern, since it might contain some sensitive information (<span id="S1.p2.1.2" class="ltx_text ltx_font_italic">e.g.</span>, UAV’s identity and localization). Secondly, the experienced latency from sending raw data to receiving well trained model is unacceptable for some real-time UAV applications (<span id="S1.p2.1.3" class="ltx_text ltx_font_italic">e.g.</span>, autonomous drones monitoring and target tracking). Lastly, the transfer of huge raw data such as image and video to the cloud consumes a lot of bandwidth and energy, which is unacceptable for UAV networks with limited bandwidth and energy supply. Hence, it would be greatly beneficial if the ML model training could be conducted in a distributive manner in UAV networks directly, without sending data out.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">Recently, federated learning (FL), firstly proposed by Google <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>, emerges as a promising distributed ML paradigm to solve the drawback of traditional cloud-centric ML. At its core, FL enables multiple devices to collaboratively train an ML model without sending the raw data out, thereby protecting device privacy, improving experienced latency, and relieving bandwidth and energy burden. It was demonstrated that FL is more suitable for wireless edge networks as compared to the cloud-centric ML <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>, because it enables wireless edge devices to collaboratively learn a shared ML model in parallel, while keeping all raw data on device. Furthermore, to better adapt to the characteristics of wireless edge networks such as multi-hop, several FL paradigms including collaborative FL <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>, multi-hop FL <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>, and fog learning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite> have been proposed, while a first FL framework within UAV networks is recently presented in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>. Nevertheless, all the aforementioned FL schemes are <span id="S1.p3.1.1" class="ltx_text ltx_font_italic">centralized</span>, <span id="S1.p3.1.2" class="ltx_text ltx_font_italic">i.e.</span>, relying on a central entity for continuous ML model aggregation. They could face the problem of a single point of failure, which is thus inappropriate for UAV networks with unreliable nodes and links, <span id="S1.p3.1.3" class="ltx_text ltx_font_italic">i.e.</span>, when the UAV serving as the central entity is out of battery or the wireless link between it and other UAVs fails, the FL training would have to terminate. Worthy noting that there exist some studies about decentralized ML such as <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a>, <a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>, where <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite> fall into the scope of classical distributed ML rather than FL, and they seldom discuss how to apply decentralized FL to UAV networks.</p>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/2104.07557/assets/x1.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_square" width="321" height="261" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Conventional FL and its representative counterparts.</figcaption>
</figure>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">In this article, to deal with the limitation of conventional FL schemes, we propose a novel architecture of <span id="S1.p4.1.1" class="ltx_text ltx_framed ltx_framed_underline">D</span>ecentralized <span id="S1.p4.1.2" class="ltx_text ltx_framed ltx_framed_underline">F</span>ederated <span id="S1.p4.1.3" class="ltx_text ltx_framed ltx_framed_underline">L</span>earning for <span id="S1.p4.1.4" class="ltx_text ltx_framed ltx_framed_underline">U</span>AV <span id="S1.p4.1.5" class="ltx_text ltx_framed ltx_framed_underline">N</span>etworks (DFL-UN). Unlike conventional server-based FL schemes, while the DFL-UN follows the basic principles of FL (<span id="S1.p4.1.6" class="ltx_text ltx_font_italic">e.g.</span>, each UAV trains a local model based on its own data), it does not need a central entity for global model aggregation and fusion, that is to say, each UAV only exchanges local models with its one-hop neighboring UAVs by aggregation. To the best of our knowledge, this is first work that proposes a server-less FL architecture for UAV networks. We also present some preliminary results to validate the feasibility and effectiveness of the proposed DFL-UN, compared to a conventional FL scheme. In the rest of this article, we first introduce several conventional FL paradigms in detail and discuss the limitation for UAV networks in Section II. The proposed DFL-UN architecture is formally presented in Section III, whose effectiveness is validated by simulation results in Section IV. In Section V, we highlight several challenges and potential research directions in the DFL-UN. Section VI concludes this article.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">II </span><span id="S2.1.1" class="ltx_text ltx_font_smallcaps">Conventional FL Paradigms and Its Limitation for UAV Networks</span>
</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">In this section, we first introduce several conventional FL paradigms including the original FL and its three representative counterparts, and then discuss their main limitation for UAV networks.</p>
</div>
<figure id="S2.F2" class="ltx_figure"><img src="/html/2104.07557/assets/x2.png" id="S2.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="273" height="145" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>An illustration of the proposed DFL-UN architecture for UAV networks.</figcaption>
</figure>
<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS1.4.1.1" class="ltx_text">II-A</span> </span><span id="S2.SS1.5.2" class="ltx_text ltx_font_italic">Overview of Conventional FL Paradigms</span>
</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p"><span id="S2.SS1.p1.1.1" class="ltx_text ltx_font_bold">Google’s seminal FL:</span> to reduce privacy risk and communication cost, McMahan <span id="S2.SS1.p1.1.2" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite> proposed the first FL framework. Different from the centralized ML, FL enables each user equipment (UE) to train a local ML model based on its local dataset rather than directly send out its own data, which is transmitted to a cloud (called “parameter server”) for global model averaging, as shown in Fig. <a href="#S1.F1" title="Figure 1 ‣ I Introduction ‣ Decentralized Federated Learning for UAV Networks: Architecture, Challenges, and Opportunities" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> (a). Note that the FL model is trained in an iterative manner, <span id="S2.SS1.p1.1.3" class="ltx_text ltx_font_italic">i.e.</span>, the local model is always updated based on the latest averaged global model, until the convergence about the global model is achieved. Recently, much efforts have been devoted to <span id="S2.SS1.p1.1.4" class="ltx_text ltx_font_italic">wireless edge FL</span>, where the global model averaging happens at the one-hop wireless edge server (<span id="S2.SS1.p1.1.5" class="ltx_text ltx_font_italic">e.g.</span>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>, <a href="#bib.bib13" title="" class="ltx_ref">13</a>, <a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>), rather than the remote cloud server.</p>
</div>
<div id="S2.SS1.p2" class="ltx_para">
<p id="S2.SS1.p2.1" class="ltx_p"><span id="S2.SS1.p2.1.1" class="ltx_text ltx_font_bold">Collaborative FL:</span> Chen <span id="S2.SS1.p2.1.2" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite> proposed the concept of collaborative FL, where some UEs far away from, or even not connected to a cloud or a BS can engage in FL by device-to-device (D2D) communications, <span id="S2.SS1.p2.1.3" class="ltx_text ltx_font_italic">i.e.</span>, transmitting their local models to nearby neighbors associated with the BS, as illustrated in Fig. <a href="#S1.F1" title="Figure 1 ‣ I Introduction ‣ Decentralized Federated Learning for UAV Networks: Architecture, Challenges, and Opportunities" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> (b). Note that in collaborative FL, any UE should aggregate its received local models from all neighbors and then send the aggregated local model to the BS. While Google’s seminal FL can been seen as a special case of collaborative FL, <span id="S2.SS1.p2.1.4" class="ltx_text ltx_font_italic">i.e.</span>, they are equivalent when all UEs are connected to a BS, the prominent advantage of the latter is that it can involve more UEs and data for better training performance <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>.</p>
</div>
<div id="S2.SS1.p3" class="ltx_para">
<p id="S2.SS1.p3.1" class="ltx_p"><span id="S2.SS1.p3.1.1" class="ltx_text ltx_font_bold">Multi-hop FL:</span> similar to collaborative FL involving more UEs for training, Pinyoanuntapong <span id="S2.SS1.p3.1.2" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite> proposed multi-hop FL, which aims to enable FL over wireless multi-hop networks. In multi-hop FL, the local models of some UEs not directly connected to the parameter server node will be forwarded by the UE based on the routing policy, as shown in Fig. <a href="#S1.F1" title="Figure 1 ‣ I Introduction ‣ Decentralized Federated Learning for UAV Networks: Architecture, Challenges, and Opportunities" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> (c). The only difference between collaborative FL and multi-hop FL is that the local models received from neighbors are aggregated before forwarding by each UE in the former, while they are directly forwarded in the latter.</p>
</div>
<div id="S2.SS1.p4" class="ltx_para">
<p id="S2.SS1.p4.1" class="ltx_p"><span id="S2.SS1.p4.1.1" class="ltx_text ltx_font_bold">Fog learning:</span> considering both network and topology structures in fog environment, Hosseinalipour <span id="S2.SS1.p4.1.2" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite> proposed fog learning, which intelligently distributes model training across the continuum of various nodes from edge UEs to cloud servers, as illustrated in Fig. <a href="#S1.F1" title="Figure 1 ‣ I Introduction ‣ Decentralized Federated Learning for UAV Networks: Architecture, Challenges, and Opportunities" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> (d). Similar to collaborative ML, fog learning employs D2D links to orchestrate heterogeneous UEs with various proximities, which forms a multi-layer hybrid FL framework. While UEs also aggregate the local models received from neighbors in fog learning, it divides all UEs into different layers according to their proximities, which are not clearly divided in collaborative FL.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS2.4.1.1" class="ltx_text">II-B</span> </span><span id="S2.SS2.5.2" class="ltx_text ltx_font_italic">Limitation for UAV Networks</span>
</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">Although the aforementioned collaborative FL, multi-hop FL, and fog learning have modified the celebrated Google’s seminal FL to migrate from the star network topology for model parameters exchange in FL to more distributed topology at scale, all of them are <span id="S2.SS2.p1.1.1" class="ltx_text ltx_font_italic">centralized</span>, <span id="S2.SS2.p1.1.2" class="ltx_text ltx_font_italic">i.e.</span>, they rely on a central parameter server for global model aggregation and fusion. Unlike the relatively reliable parameter server (<span id="S2.SS2.p1.1.3" class="ltx_text ltx_font_italic">e.g.</span>, cellular BS) in terrestrial FL, such server-based FL is inevitably faced with a single point of failure when applied in UAV networks. For example, in the FL framework within a swarm of multiple wireless-connected UAVs proposed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>, a leading UAV acts as the parameter server, while several following UAVs train their local models and send them to the leading UAV for aggregation. The leading UAV may be unreachable since air-to-air (A2A) wireless links are subject to errors, or even cannot work properly due to attacks or out of battery.</p>
</div>
<figure id="S2.F3" class="ltx_figure"><img src="/html/2104.07557/assets/x3.png" id="S2.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="329" height="123" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>The UAV network topology in the simulation.</figcaption>
</figure>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">III </span><span id="S3.1.1" class="ltx_text ltx_font_smallcaps">Decentralized FL for UAV Networks: Architecture, Advantages, and Novelty</span>
</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">In this section, to resolve the aforementioned limitation of conventional FL, we propose the architecture of <span id="S3.p1.1.1" class="ltx_text ltx_framed ltx_framed_underline">D</span>ecentralized <span id="S3.p1.1.2" class="ltx_text ltx_framed ltx_framed_underline">F</span>ederated <span id="S3.p1.1.3" class="ltx_text ltx_framed ltx_framed_underline">L</span>earning for <span id="S3.p1.1.4" class="ltx_text ltx_framed ltx_framed_underline">U</span>AV <span id="S3.p1.1.5" class="ltx_text ltx_framed ltx_framed_underline">N</span>etworks (DFL-UN). In the following, we first present the architecture overview of the DFL-UN, and then explain its advantages and novelty.</p>
</div>
<div id="S3.p2" class="ltx_para">
<p id="S3.p2.21" class="ltx_p"><span id="S3.p2.21.1" class="ltx_text ltx_font_bold">Architecture:</span> in general, in the proposed DFL-UN architecture, the FL is conducted over different UAVs in a fully distributed manner, without a central parameter server for global model aggregation across the UAV network. More specifically, each UAV always employs its local dataset to update a local model, upon receiving the local model weights from its neighboring UAVs. Take Fig. <a href="#S2.F2" title="Figure 2 ‣ II Conventional FL Paradigms and Its Limitation for UAV Networks ‣ Decentralized Federated Learning for UAV Networks: Architecture, Challenges, and Opportunities" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> as an example. Assume that UAV <math id="S3.p2.1.m1.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S3.p2.1.m1.1a"><mi id="S3.p2.1.m1.1.1" xref="S3.p2.1.m1.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.p2.1.m1.1b"><ci id="S3.p2.1.m1.1.1.cmml" xref="S3.p2.1.m1.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.1.m1.1c">i</annotation></semantics></math>’s one-hop neighbors are UAVs <math id="S3.p2.2.m2.1" class="ltx_Math" alttext="i+1" display="inline"><semantics id="S3.p2.2.m2.1a"><mrow id="S3.p2.2.m2.1.1" xref="S3.p2.2.m2.1.1.cmml"><mi id="S3.p2.2.m2.1.1.2" xref="S3.p2.2.m2.1.1.2.cmml">i</mi><mo id="S3.p2.2.m2.1.1.1" xref="S3.p2.2.m2.1.1.1.cmml">+</mo><mn id="S3.p2.2.m2.1.1.3" xref="S3.p2.2.m2.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.p2.2.m2.1b"><apply id="S3.p2.2.m2.1.1.cmml" xref="S3.p2.2.m2.1.1"><plus id="S3.p2.2.m2.1.1.1.cmml" xref="S3.p2.2.m2.1.1.1"></plus><ci id="S3.p2.2.m2.1.1.2.cmml" xref="S3.p2.2.m2.1.1.2">𝑖</ci><cn type="integer" id="S3.p2.2.m2.1.1.3.cmml" xref="S3.p2.2.m2.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.2.m2.1c">i+1</annotation></semantics></math>, <math id="S3.p2.3.m3.1" class="ltx_Math" alttext="i+2" display="inline"><semantics id="S3.p2.3.m3.1a"><mrow id="S3.p2.3.m3.1.1" xref="S3.p2.3.m3.1.1.cmml"><mi id="S3.p2.3.m3.1.1.2" xref="S3.p2.3.m3.1.1.2.cmml">i</mi><mo id="S3.p2.3.m3.1.1.1" xref="S3.p2.3.m3.1.1.1.cmml">+</mo><mn id="S3.p2.3.m3.1.1.3" xref="S3.p2.3.m3.1.1.3.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.p2.3.m3.1b"><apply id="S3.p2.3.m3.1.1.cmml" xref="S3.p2.3.m3.1.1"><plus id="S3.p2.3.m3.1.1.1.cmml" xref="S3.p2.3.m3.1.1.1"></plus><ci id="S3.p2.3.m3.1.1.2.cmml" xref="S3.p2.3.m3.1.1.2">𝑖</ci><cn type="integer" id="S3.p2.3.m3.1.1.3.cmml" xref="S3.p2.3.m3.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.3.m3.1c">i+2</annotation></semantics></math>, and <math id="S3.p2.4.m4.1" class="ltx_Math" alttext="i+3" display="inline"><semantics id="S3.p2.4.m4.1a"><mrow id="S3.p2.4.m4.1.1" xref="S3.p2.4.m4.1.1.cmml"><mi id="S3.p2.4.m4.1.1.2" xref="S3.p2.4.m4.1.1.2.cmml">i</mi><mo id="S3.p2.4.m4.1.1.1" xref="S3.p2.4.m4.1.1.1.cmml">+</mo><mn id="S3.p2.4.m4.1.1.3" xref="S3.p2.4.m4.1.1.3.cmml">3</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.p2.4.m4.1b"><apply id="S3.p2.4.m4.1.1.cmml" xref="S3.p2.4.m4.1.1"><plus id="S3.p2.4.m4.1.1.1.cmml" xref="S3.p2.4.m4.1.1.1"></plus><ci id="S3.p2.4.m4.1.1.2.cmml" xref="S3.p2.4.m4.1.1.2">𝑖</ci><cn type="integer" id="S3.p2.4.m4.1.1.3.cmml" xref="S3.p2.4.m4.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.4.m4.1c">i+3</annotation></semantics></math>. Each UAV trains a local FL model based on its local dataset, where <math id="S3.p2.5.m5.2" class="ltx_Math" alttext="W_{i,t}" display="inline"><semantics id="S3.p2.5.m5.2a"><msub id="S3.p2.5.m5.2.3" xref="S3.p2.5.m5.2.3.cmml"><mi id="S3.p2.5.m5.2.3.2" xref="S3.p2.5.m5.2.3.2.cmml">W</mi><mrow id="S3.p2.5.m5.2.2.2.4" xref="S3.p2.5.m5.2.2.2.3.cmml"><mi id="S3.p2.5.m5.1.1.1.1" xref="S3.p2.5.m5.1.1.1.1.cmml">i</mi><mo id="S3.p2.5.m5.2.2.2.4.1" xref="S3.p2.5.m5.2.2.2.3.cmml">,</mo><mi id="S3.p2.5.m5.2.2.2.2" xref="S3.p2.5.m5.2.2.2.2.cmml">t</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.p2.5.m5.2b"><apply id="S3.p2.5.m5.2.3.cmml" xref="S3.p2.5.m5.2.3"><csymbol cd="ambiguous" id="S3.p2.5.m5.2.3.1.cmml" xref="S3.p2.5.m5.2.3">subscript</csymbol><ci id="S3.p2.5.m5.2.3.2.cmml" xref="S3.p2.5.m5.2.3.2">𝑊</ci><list id="S3.p2.5.m5.2.2.2.3.cmml" xref="S3.p2.5.m5.2.2.2.4"><ci id="S3.p2.5.m5.1.1.1.1.cmml" xref="S3.p2.5.m5.1.1.1.1">𝑖</ci><ci id="S3.p2.5.m5.2.2.2.2.cmml" xref="S3.p2.5.m5.2.2.2.2">𝑡</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.5.m5.2c">W_{i,t}</annotation></semantics></math> represents UAV <math id="S3.p2.6.m6.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S3.p2.6.m6.1a"><mi id="S3.p2.6.m6.1.1" xref="S3.p2.6.m6.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.p2.6.m6.1b"><ci id="S3.p2.6.m6.1.1.cmml" xref="S3.p2.6.m6.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.6.m6.1c">i</annotation></semantics></math>’s local model parameter (weight) at training round <math id="S3.p2.7.m7.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S3.p2.7.m7.1a"><mi id="S3.p2.7.m7.1.1" xref="S3.p2.7.m7.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S3.p2.7.m7.1b"><ci id="S3.p2.7.m7.1.1.cmml" xref="S3.p2.7.m7.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.7.m7.1c">t</annotation></semantics></math>. We suppose that the data are respectively collected by the UAVs and labeled based on the local observation according to the given phenomenon or available public UAV datasets. Initially, each UAV <math id="S3.p2.8.m8.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S3.p2.8.m8.1a"><mi id="S3.p2.8.m8.1.1" xref="S3.p2.8.m8.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.p2.8.m8.1b"><ci id="S3.p2.8.m8.1.1.cmml" xref="S3.p2.8.m8.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.8.m8.1c">i</annotation></semantics></math> generates a local model <math id="S3.p2.9.m9.2" class="ltx_Math" alttext="W_{i,0}" display="inline"><semantics id="S3.p2.9.m9.2a"><msub id="S3.p2.9.m9.2.3" xref="S3.p2.9.m9.2.3.cmml"><mi id="S3.p2.9.m9.2.3.2" xref="S3.p2.9.m9.2.3.2.cmml">W</mi><mrow id="S3.p2.9.m9.2.2.2.4" xref="S3.p2.9.m9.2.2.2.3.cmml"><mi id="S3.p2.9.m9.1.1.1.1" xref="S3.p2.9.m9.1.1.1.1.cmml">i</mi><mo id="S3.p2.9.m9.2.2.2.4.1" xref="S3.p2.9.m9.2.2.2.3.cmml">,</mo><mn id="S3.p2.9.m9.2.2.2.2" xref="S3.p2.9.m9.2.2.2.2.cmml">0</mn></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.p2.9.m9.2b"><apply id="S3.p2.9.m9.2.3.cmml" xref="S3.p2.9.m9.2.3"><csymbol cd="ambiguous" id="S3.p2.9.m9.2.3.1.cmml" xref="S3.p2.9.m9.2.3">subscript</csymbol><ci id="S3.p2.9.m9.2.3.2.cmml" xref="S3.p2.9.m9.2.3.2">𝑊</ci><list id="S3.p2.9.m9.2.2.2.3.cmml" xref="S3.p2.9.m9.2.2.2.4"><ci id="S3.p2.9.m9.1.1.1.1.cmml" xref="S3.p2.9.m9.1.1.1.1">𝑖</ci><cn type="integer" id="S3.p2.9.m9.2.2.2.2.cmml" xref="S3.p2.9.m9.2.2.2.2">0</cn></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.9.m9.2c">W_{i,0}</annotation></semantics></math>. Firstly, at round <math id="S3.p2.10.m10.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S3.p2.10.m10.1a"><mi id="S3.p2.10.m10.1.1" xref="S3.p2.10.m10.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S3.p2.10.m10.1b"><ci id="S3.p2.10.m10.1.1.cmml" xref="S3.p2.10.m10.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.10.m10.1c">t</annotation></semantics></math>, UAVs <math id="S3.p2.11.m11.1" class="ltx_Math" alttext="i+1" display="inline"><semantics id="S3.p2.11.m11.1a"><mrow id="S3.p2.11.m11.1.1" xref="S3.p2.11.m11.1.1.cmml"><mi id="S3.p2.11.m11.1.1.2" xref="S3.p2.11.m11.1.1.2.cmml">i</mi><mo id="S3.p2.11.m11.1.1.1" xref="S3.p2.11.m11.1.1.1.cmml">+</mo><mn id="S3.p2.11.m11.1.1.3" xref="S3.p2.11.m11.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.p2.11.m11.1b"><apply id="S3.p2.11.m11.1.1.cmml" xref="S3.p2.11.m11.1.1"><plus id="S3.p2.11.m11.1.1.1.cmml" xref="S3.p2.11.m11.1.1.1"></plus><ci id="S3.p2.11.m11.1.1.2.cmml" xref="S3.p2.11.m11.1.1.2">𝑖</ci><cn type="integer" id="S3.p2.11.m11.1.1.3.cmml" xref="S3.p2.11.m11.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.11.m11.1c">i+1</annotation></semantics></math>, <math id="S3.p2.12.m12.1" class="ltx_Math" alttext="i+2" display="inline"><semantics id="S3.p2.12.m12.1a"><mrow id="S3.p2.12.m12.1.1" xref="S3.p2.12.m12.1.1.cmml"><mi id="S3.p2.12.m12.1.1.2" xref="S3.p2.12.m12.1.1.2.cmml">i</mi><mo id="S3.p2.12.m12.1.1.1" xref="S3.p2.12.m12.1.1.1.cmml">+</mo><mn id="S3.p2.12.m12.1.1.3" xref="S3.p2.12.m12.1.1.3.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.p2.12.m12.1b"><apply id="S3.p2.12.m12.1.1.cmml" xref="S3.p2.12.m12.1.1"><plus id="S3.p2.12.m12.1.1.1.cmml" xref="S3.p2.12.m12.1.1.1"></plus><ci id="S3.p2.12.m12.1.1.2.cmml" xref="S3.p2.12.m12.1.1.2">𝑖</ci><cn type="integer" id="S3.p2.12.m12.1.1.3.cmml" xref="S3.p2.12.m12.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.12.m12.1c">i+2</annotation></semantics></math>, and <math id="S3.p2.13.m13.1" class="ltx_Math" alttext="i+3" display="inline"><semantics id="S3.p2.13.m13.1a"><mrow id="S3.p2.13.m13.1.1" xref="S3.p2.13.m13.1.1.cmml"><mi id="S3.p2.13.m13.1.1.2" xref="S3.p2.13.m13.1.1.2.cmml">i</mi><mo id="S3.p2.13.m13.1.1.1" xref="S3.p2.13.m13.1.1.1.cmml">+</mo><mn id="S3.p2.13.m13.1.1.3" xref="S3.p2.13.m13.1.1.3.cmml">3</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.p2.13.m13.1b"><apply id="S3.p2.13.m13.1.1.cmml" xref="S3.p2.13.m13.1.1"><plus id="S3.p2.13.m13.1.1.1.cmml" xref="S3.p2.13.m13.1.1.1"></plus><ci id="S3.p2.13.m13.1.1.2.cmml" xref="S3.p2.13.m13.1.1.2">𝑖</ci><cn type="integer" id="S3.p2.13.m13.1.1.3.cmml" xref="S3.p2.13.m13.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.13.m13.1c">i+3</annotation></semantics></math> send their corresponding model weights <math id="S3.p2.14.m14.2" class="ltx_Math" alttext="W_{i+1,t}" display="inline"><semantics id="S3.p2.14.m14.2a"><msub id="S3.p2.14.m14.2.3" xref="S3.p2.14.m14.2.3.cmml"><mi id="S3.p2.14.m14.2.3.2" xref="S3.p2.14.m14.2.3.2.cmml">W</mi><mrow id="S3.p2.14.m14.2.2.2.2" xref="S3.p2.14.m14.2.2.2.3.cmml"><mrow id="S3.p2.14.m14.2.2.2.2.1" xref="S3.p2.14.m14.2.2.2.2.1.cmml"><mi id="S3.p2.14.m14.2.2.2.2.1.2" xref="S3.p2.14.m14.2.2.2.2.1.2.cmml">i</mi><mo id="S3.p2.14.m14.2.2.2.2.1.1" xref="S3.p2.14.m14.2.2.2.2.1.1.cmml">+</mo><mn id="S3.p2.14.m14.2.2.2.2.1.3" xref="S3.p2.14.m14.2.2.2.2.1.3.cmml">1</mn></mrow><mo id="S3.p2.14.m14.2.2.2.2.2" xref="S3.p2.14.m14.2.2.2.3.cmml">,</mo><mi id="S3.p2.14.m14.1.1.1.1" xref="S3.p2.14.m14.1.1.1.1.cmml">t</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.p2.14.m14.2b"><apply id="S3.p2.14.m14.2.3.cmml" xref="S3.p2.14.m14.2.3"><csymbol cd="ambiguous" id="S3.p2.14.m14.2.3.1.cmml" xref="S3.p2.14.m14.2.3">subscript</csymbol><ci id="S3.p2.14.m14.2.3.2.cmml" xref="S3.p2.14.m14.2.3.2">𝑊</ci><list id="S3.p2.14.m14.2.2.2.3.cmml" xref="S3.p2.14.m14.2.2.2.2"><apply id="S3.p2.14.m14.2.2.2.2.1.cmml" xref="S3.p2.14.m14.2.2.2.2.1"><plus id="S3.p2.14.m14.2.2.2.2.1.1.cmml" xref="S3.p2.14.m14.2.2.2.2.1.1"></plus><ci id="S3.p2.14.m14.2.2.2.2.1.2.cmml" xref="S3.p2.14.m14.2.2.2.2.1.2">𝑖</ci><cn type="integer" id="S3.p2.14.m14.2.2.2.2.1.3.cmml" xref="S3.p2.14.m14.2.2.2.2.1.3">1</cn></apply><ci id="S3.p2.14.m14.1.1.1.1.cmml" xref="S3.p2.14.m14.1.1.1.1">𝑡</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.14.m14.2c">W_{i+1,t}</annotation></semantics></math>, <math id="S3.p2.15.m15.2" class="ltx_Math" alttext="W_{i+2,t}" display="inline"><semantics id="S3.p2.15.m15.2a"><msub id="S3.p2.15.m15.2.3" xref="S3.p2.15.m15.2.3.cmml"><mi id="S3.p2.15.m15.2.3.2" xref="S3.p2.15.m15.2.3.2.cmml">W</mi><mrow id="S3.p2.15.m15.2.2.2.2" xref="S3.p2.15.m15.2.2.2.3.cmml"><mrow id="S3.p2.15.m15.2.2.2.2.1" xref="S3.p2.15.m15.2.2.2.2.1.cmml"><mi id="S3.p2.15.m15.2.2.2.2.1.2" xref="S3.p2.15.m15.2.2.2.2.1.2.cmml">i</mi><mo id="S3.p2.15.m15.2.2.2.2.1.1" xref="S3.p2.15.m15.2.2.2.2.1.1.cmml">+</mo><mn id="S3.p2.15.m15.2.2.2.2.1.3" xref="S3.p2.15.m15.2.2.2.2.1.3.cmml">2</mn></mrow><mo id="S3.p2.15.m15.2.2.2.2.2" xref="S3.p2.15.m15.2.2.2.3.cmml">,</mo><mi id="S3.p2.15.m15.1.1.1.1" xref="S3.p2.15.m15.1.1.1.1.cmml">t</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.p2.15.m15.2b"><apply id="S3.p2.15.m15.2.3.cmml" xref="S3.p2.15.m15.2.3"><csymbol cd="ambiguous" id="S3.p2.15.m15.2.3.1.cmml" xref="S3.p2.15.m15.2.3">subscript</csymbol><ci id="S3.p2.15.m15.2.3.2.cmml" xref="S3.p2.15.m15.2.3.2">𝑊</ci><list id="S3.p2.15.m15.2.2.2.3.cmml" xref="S3.p2.15.m15.2.2.2.2"><apply id="S3.p2.15.m15.2.2.2.2.1.cmml" xref="S3.p2.15.m15.2.2.2.2.1"><plus id="S3.p2.15.m15.2.2.2.2.1.1.cmml" xref="S3.p2.15.m15.2.2.2.2.1.1"></plus><ci id="S3.p2.15.m15.2.2.2.2.1.2.cmml" xref="S3.p2.15.m15.2.2.2.2.1.2">𝑖</ci><cn type="integer" id="S3.p2.15.m15.2.2.2.2.1.3.cmml" xref="S3.p2.15.m15.2.2.2.2.1.3">2</cn></apply><ci id="S3.p2.15.m15.1.1.1.1.cmml" xref="S3.p2.15.m15.1.1.1.1">𝑡</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.15.m15.2c">W_{i+2,t}</annotation></semantics></math>, and <math id="S3.p2.16.m16.2" class="ltx_Math" alttext="W_{i+3,t}" display="inline"><semantics id="S3.p2.16.m16.2a"><msub id="S3.p2.16.m16.2.3" xref="S3.p2.16.m16.2.3.cmml"><mi id="S3.p2.16.m16.2.3.2" xref="S3.p2.16.m16.2.3.2.cmml">W</mi><mrow id="S3.p2.16.m16.2.2.2.2" xref="S3.p2.16.m16.2.2.2.3.cmml"><mrow id="S3.p2.16.m16.2.2.2.2.1" xref="S3.p2.16.m16.2.2.2.2.1.cmml"><mi id="S3.p2.16.m16.2.2.2.2.1.2" xref="S3.p2.16.m16.2.2.2.2.1.2.cmml">i</mi><mo id="S3.p2.16.m16.2.2.2.2.1.1" xref="S3.p2.16.m16.2.2.2.2.1.1.cmml">+</mo><mn id="S3.p2.16.m16.2.2.2.2.1.3" xref="S3.p2.16.m16.2.2.2.2.1.3.cmml">3</mn></mrow><mo id="S3.p2.16.m16.2.2.2.2.2" xref="S3.p2.16.m16.2.2.2.3.cmml">,</mo><mi id="S3.p2.16.m16.1.1.1.1" xref="S3.p2.16.m16.1.1.1.1.cmml">t</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.p2.16.m16.2b"><apply id="S3.p2.16.m16.2.3.cmml" xref="S3.p2.16.m16.2.3"><csymbol cd="ambiguous" id="S3.p2.16.m16.2.3.1.cmml" xref="S3.p2.16.m16.2.3">subscript</csymbol><ci id="S3.p2.16.m16.2.3.2.cmml" xref="S3.p2.16.m16.2.3.2">𝑊</ci><list id="S3.p2.16.m16.2.2.2.3.cmml" xref="S3.p2.16.m16.2.2.2.2"><apply id="S3.p2.16.m16.2.2.2.2.1.cmml" xref="S3.p2.16.m16.2.2.2.2.1"><plus id="S3.p2.16.m16.2.2.2.2.1.1.cmml" xref="S3.p2.16.m16.2.2.2.2.1.1"></plus><ci id="S3.p2.16.m16.2.2.2.2.1.2.cmml" xref="S3.p2.16.m16.2.2.2.2.1.2">𝑖</ci><cn type="integer" id="S3.p2.16.m16.2.2.2.2.1.3.cmml" xref="S3.p2.16.m16.2.2.2.2.1.3">3</cn></apply><ci id="S3.p2.16.m16.1.1.1.1.cmml" xref="S3.p2.16.m16.1.1.1.1">𝑡</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.16.m16.2c">W_{i+3,t}</annotation></semantics></math> to UAV <math id="S3.p2.17.m17.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S3.p2.17.m17.1a"><mi id="S3.p2.17.m17.1.1" xref="S3.p2.17.m17.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.p2.17.m17.1b"><ci id="S3.p2.17.m17.1.1.cmml" xref="S3.p2.17.m17.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.17.m17.1c">i</annotation></semantics></math>. Secondly, these neighbors’ model weights and UAV <math id="S3.p2.18.m18.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S3.p2.18.m18.1a"><mi id="S3.p2.18.m18.1.1" xref="S3.p2.18.m18.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.p2.18.m18.1b"><ci id="S3.p2.18.m18.1.1.cmml" xref="S3.p2.18.m18.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.18.m18.1c">i</annotation></semantics></math>’s current model weight are used to generate an aggregated local model at UAV <math id="S3.p2.19.m19.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S3.p2.19.m19.1a"><mi id="S3.p2.19.m19.1.1" xref="S3.p2.19.m19.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.p2.19.m19.1b"><ci id="S3.p2.19.m19.1.1.cmml" xref="S3.p2.19.m19.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.19.m19.1c">i</annotation></semantics></math>. Thirdly, based on that aggregated local model, UAV <math id="S3.p2.20.m20.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S3.p2.20.m20.1a"><mi id="S3.p2.20.m20.1.1" xref="S3.p2.20.m20.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.p2.20.m20.1b"><ci id="S3.p2.20.m20.1.1.cmml" xref="S3.p2.20.m20.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.20.m20.1c">i</annotation></semantics></math> updates its local model as <math id="S3.p2.21.m21.2" class="ltx_Math" alttext="W_{i,t+1}" display="inline"><semantics id="S3.p2.21.m21.2a"><msub id="S3.p2.21.m21.2.3" xref="S3.p2.21.m21.2.3.cmml"><mi id="S3.p2.21.m21.2.3.2" xref="S3.p2.21.m21.2.3.2.cmml">W</mi><mrow id="S3.p2.21.m21.2.2.2.2" xref="S3.p2.21.m21.2.2.2.3.cmml"><mi id="S3.p2.21.m21.1.1.1.1" xref="S3.p2.21.m21.1.1.1.1.cmml">i</mi><mo id="S3.p2.21.m21.2.2.2.2.2" xref="S3.p2.21.m21.2.2.2.3.cmml">,</mo><mrow id="S3.p2.21.m21.2.2.2.2.1" xref="S3.p2.21.m21.2.2.2.2.1.cmml"><mi id="S3.p2.21.m21.2.2.2.2.1.2" xref="S3.p2.21.m21.2.2.2.2.1.2.cmml">t</mi><mo id="S3.p2.21.m21.2.2.2.2.1.1" xref="S3.p2.21.m21.2.2.2.2.1.1.cmml">+</mo><mn id="S3.p2.21.m21.2.2.2.2.1.3" xref="S3.p2.21.m21.2.2.2.2.1.3.cmml">1</mn></mrow></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.p2.21.m21.2b"><apply id="S3.p2.21.m21.2.3.cmml" xref="S3.p2.21.m21.2.3"><csymbol cd="ambiguous" id="S3.p2.21.m21.2.3.1.cmml" xref="S3.p2.21.m21.2.3">subscript</csymbol><ci id="S3.p2.21.m21.2.3.2.cmml" xref="S3.p2.21.m21.2.3.2">𝑊</ci><list id="S3.p2.21.m21.2.2.2.3.cmml" xref="S3.p2.21.m21.2.2.2.2"><ci id="S3.p2.21.m21.1.1.1.1.cmml" xref="S3.p2.21.m21.1.1.1.1">𝑖</ci><apply id="S3.p2.21.m21.2.2.2.2.1.cmml" xref="S3.p2.21.m21.2.2.2.2.1"><plus id="S3.p2.21.m21.2.2.2.2.1.1.cmml" xref="S3.p2.21.m21.2.2.2.2.1.1"></plus><ci id="S3.p2.21.m21.2.2.2.2.1.2.cmml" xref="S3.p2.21.m21.2.2.2.2.1.2">𝑡</ci><cn type="integer" id="S3.p2.21.m21.2.2.2.2.1.3.cmml" xref="S3.p2.21.m21.2.2.2.2.1.3">1</cn></apply></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.21.m21.2c">W_{i,t+1}</annotation></semantics></math>, which will be “broadcast” to the neighbors afterwards for aggregation and update at each neighbor. In essence, while each UAV acts as a “parameter server” to aggregate local models for its neighbors, it also updates its own local model based on the aggregated local model.</p>
</div>
<div id="S3.p3" class="ltx_para">
<p id="S3.p3.1" class="ltx_p">Note that to avoid large latency and low efficiency by full wireless broadcasting, we suppose that the model parameter exchange between any two neighboring UAVs is transmitted by D2D communications, and the channel access among these D2D pairs could be efficiently managed by using a Time Division Multiple Access (TDMA) or a Frequency Division Multiple Access (FDMA) medium sharing scheme. How to optimize D2D communications with resource allocation to boost the learning performance of the DFL-UN is left for future study. By this way, the information of each local model is in fact propagated over the UAV network by multiple D2D exchanges. Similar to <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>, there exists a coordinator in the proposed DFL-UN, who is in charge of initializing the FL training task, distributing the global information to all involved UAVs, and monitoring the training process of the FL.</p>
</div>
<div id="S3.p4" class="ltx_para">
<p id="S3.p4.1" class="ltx_p"><span id="S3.p4.1.1" class="ltx_text ltx_font_bold">Advantages and novelty:</span> the proposed DFL-UN architecture can well adapt to UAV networks with high dynamics in both A2A wireless links and network topology. This brings two main advantages when boosting edge/on-device intelligence for UAV networks as follows. i) The DFL-UN can enable distributed ML with high robustness over UAV networks. Specifically, since there exists no such a central node coordinating the learning process in the DFL-UN, the FL will not terminate if any UAV or A2A link is unavailable. ii) The DFL-UN provides high flexibility and agility for collaborative ML within UAV networks. No matter how the network topology changes due to the dynamic joining and leaving of some UAVs, the FL does not need to reorganize and will continue with negligible efforts. In a nutshell, the novelty of the DFL-UN lies in that it proposes a fully decentralized FL framework for UAV networks, which perfectly matches the unique characteristics of UAV networks.</p>
</div>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">IV </span><span id="S4.1.1" class="ltx_text ltx_font_smallcaps">Performance Evaluation</span>
</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">In this section, we conduct numerical simulations to validate the feasibility as well as effectiveness of the proposed DFL-UN architecture. We study the performance of the DFL-UN in a UAV network, where one of the UAVs acting as the parameter server is unavailable during the training period. We involve the conventional centralized FL (<span id="S4.p1.1.1" class="ltx_text ltx_font_italic">i.e.</span>, FedAvg <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>) as the benchmark, where the parameter server node is assumed to be available in this case. Therefore, the learning performance of the conventional FL could be seen as a theoretical upper bound for the DFL-UN. The DFL-UN is effective if the gap of the performances between it and conventional FL is very small after multiple training rounds. Here a training (communication) round is defined as follows: the training will not enter the next communication round until all UAVs have completed the four steps in Fig. 2.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS1.4.1.1" class="ltx_text">IV-A</span> </span><span id="S4.SS1.5.2" class="ltx_text ltx_font_italic">Simulation Settings</span>
</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">We assume that there exist six UAVs flying at the fixed altitude of 100 m in a UAV network, five of which aim to collaboratively train an ML model by FL based on their own data. The distance between each two UAVs is randomly chosen from [80, 120] m. As shown in Fig. <a href="#S2.F3" title="Figure 3 ‣ II-B Limitation for UAV Networks ‣ II Conventional FL Paradigms and Its Limitation for UAV Networks ‣ Decentralized Federated Learning for UAV Networks: Architecture, Challenges, and Opportunities" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, if UAV#1 who acts as the parameter server is available (UAV#1 can directly communicate with the rest UAVs), the rest five UAVs can conduct the conventional centralized FL with the help of UAV#1 (Fig. <a href="#S2.F3" title="Figure 3 ‣ II-B Limitation for UAV Networks ‣ II Conventional FL Paradigms and Its Limitation for UAV Networks ‣ Decentralized Federated Learning for UAV Networks: Architecture, Challenges, and Opportunities" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> (a)); otherwise, they can only conduct the decentralized FL following the proposed DFL-UN (Fig. <a href="#S2.F3" title="Figure 3 ‣ II-B Limitation for UAV Networks ‣ II Conventional FL Paradigms and Its Limitation for UAV Networks ‣ Decentralized Federated Learning for UAV Networks: Architecture, Challenges, and Opportunities" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> (b), the link relationship among the UAVs is also illustrated in this figure). The learning rate is fixed at 0.025 and the number of local epochs is set as 3 with the mini-batch size 5. In the simulation, for the training task, we consider the classification task using Convolutional Neural Network (CNN) model <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>. For the training dataset, we assume each UAV collects 25 samples and the data distribution is non-IID, and the number of CPU cycles needed per sample is 6<math id="S4.SS1.p1.1.m1.1" class="ltx_Math" alttext="\times 10^{4}" display="inline"><semantics id="S4.SS1.p1.1.m1.1a"><mrow id="S4.SS1.p1.1.m1.1.1" xref="S4.SS1.p1.1.m1.1.1.cmml"><mi id="S4.SS1.p1.1.m1.1.1.2" xref="S4.SS1.p1.1.m1.1.1.2.cmml"></mi><mo lspace="0.222em" rspace="0.222em" id="S4.SS1.p1.1.m1.1.1.1" xref="S4.SS1.p1.1.m1.1.1.1.cmml">×</mo><msup id="S4.SS1.p1.1.m1.1.1.3" xref="S4.SS1.p1.1.m1.1.1.3.cmml"><mn id="S4.SS1.p1.1.m1.1.1.3.2" xref="S4.SS1.p1.1.m1.1.1.3.2.cmml">10</mn><mn id="S4.SS1.p1.1.m1.1.1.3.3" xref="S4.SS1.p1.1.m1.1.1.3.3.cmml">4</mn></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.1.m1.1b"><apply id="S4.SS1.p1.1.m1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1"><times id="S4.SS1.p1.1.m1.1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1.1"></times><csymbol cd="latexml" id="S4.SS1.p1.1.m1.1.1.2.cmml" xref="S4.SS1.p1.1.m1.1.1.2">absent</csymbol><apply id="S4.SS1.p1.1.m1.1.1.3.cmml" xref="S4.SS1.p1.1.m1.1.1.3"><csymbol cd="ambiguous" id="S4.SS1.p1.1.m1.1.1.3.1.cmml" xref="S4.SS1.p1.1.m1.1.1.3">superscript</csymbol><cn type="integer" id="S4.SS1.p1.1.m1.1.1.3.2.cmml" xref="S4.SS1.p1.1.m1.1.1.3.2">10</cn><cn type="integer" id="S4.SS1.p1.1.m1.1.1.3.3.cmml" xref="S4.SS1.p1.1.m1.1.1.3.3">4</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.1.m1.1c">\times 10^{4}</annotation></semantics></math>. The data size of the FL model parameter is 56 Kbits. For the setting of the UAV network, in the communication, we assume the channel power gain, noise power, the transmission power, and spectrum bandwidth allocated to each UAV, as -50 dBm, -90 dBm, 30 dBm, and 0.4 MHz, respectively; in the computation, the computing capacity of each UAV is randomly selected from [1, 2] GHz. For the performance metrics, we consider the cross-entropy loss (including both the average loss of all UAVs during the training period and individual loss of each UAV after the training), and the overall training latency, which mainly consists of three parts: i) the latency for receiving the local model parameter from each neighbor; ii) the latency for aggregating all received local models and updating local model based on the aggregation; iii) the latency for transmitting the updated local model to each neighbor.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS2.4.1.1" class="ltx_text">IV-B</span> </span><span id="S4.SS2.5.2" class="ltx_text ltx_font_italic">Result Analysis</span>
</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">Fig. <a href="#S4.F4" title="Figure 4 ‣ IV-B Result Analysis ‣ IV Performance Evaluation ‣ Decentralized Federated Learning for UAV Networks: Architecture, Challenges, and Opportunities" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> presents the performance evaluation results of the decentralized FL in the proposed DFL-UN and conventional centralized FL for the UAV network in Fig. <a href="#S2.F3" title="Figure 3 ‣ II-B Limitation for UAV Networks ‣ II Conventional FL Paradigms and Its Limitation for UAV Networks ‣ Decentralized Federated Learning for UAV Networks: Architecture, Challenges, and Opportunities" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>. Specifically, as shown in Fig. <a href="#S4.F4" title="Figure 4 ‣ IV-B Result Analysis ‣ IV Performance Evaluation ‣ Decentralized Federated Learning for UAV Networks: Architecture, Challenges, and Opportunities" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> (a), although the average loss value achieved by the decentralized FL is always higher than that by the conventional centralized FL during the training, the final gap between them is only 0.0156, which implies that the decentralized FL is almost as effective as the conventional centralized FL, without the help of a central parameter server. Furthermore, according to Fig. <a href="#S4.F4" title="Figure 4 ‣ IV-B Result Analysis ‣ IV Performance Evaluation ‣ Decentralized Federated Learning for UAV Networks: Architecture, Challenges, and Opportunities" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> (b), for each UAV, the difference of the loss value after 60 communication rounds between the decentralized FL and the conventional centralized FL is no more than 0.0229 only. And the individual loss of each UAV after 60 rounds is totally different owing to the following reasons. Firstly, since there is no such a global FL model trained in the proposed DFL-UN, the final local FL model will not be updated based on a shared global FL model and differs at different UAV. Secondly, the data at each UAV is also different. Thus, based on the definition of the (cross-entropy) loss, the individual loss of each UAV is different. Lastly, as illustrated in Fig. <a href="#S4.F4" title="Figure 4 ‣ IV-B Result Analysis ‣ IV Performance Evaluation ‣ Decentralized Federated Learning for UAV Networks: Architecture, Challenges, and Opportunities" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> (c), the training latency by the decentralized FL is always smaller than that by the conventional centralized FL, since in the latter it needs to broadcast the global aggregated FL model in each communication round, where the final decreased latency is about 101.72 ms. We also notice that the training latency curves of both schemes are linear to the number of communication rounds, mainly because both the network topology and resource allocation within each communication round are identical, thereby making the training latency within each round identical. To sum up, our results validate the effectiveness of the proposed DFL-UN, in terms of achieving almost the same learning performance with lower training latency. Note that since it is only a preliminary simulation study, we would like to conduct more extensive evaluation studies in the future, <span id="S4.SS2.p1.1.1" class="ltx_text ltx_font_italic">e.g.</span>, the inference accuracy of the trained model by the DFL-UN, and robustness to the failures of the UAVs in the DFL-UN.</p>
</div>
<figure id="S4.F4" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F4.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2104.07557/assets/x4.png" id="S4.F4.sf1.g1" class="ltx_graphics ltx_img_landscape" width="172" height="115" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(a) </span>Average loss</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F4.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2104.07557/assets/x5.png" id="S4.F4.sf2.g1" class="ltx_graphics ltx_img_landscape" width="180" height="115" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(b) </span>Individual loss</figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S4.F4.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2104.07557/assets/x6.png" id="S4.F4.sf3.g1" class="ltx_graphics ltx_img_landscape" width="171" height="115" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(c) </span>Training latency</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Evaluation results of the decentralized FL compared with conventional centralized FL.</figcaption>
</figure>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">V </span><span id="S5.1.1" class="ltx_text ltx_font_smallcaps">Challenges and Potential Research Directions</span>
</h2>

<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S5.SS1.4.1.1" class="ltx_text">V-A</span> </span><span id="S5.SS1.5.2" class="ltx_text ltx_font_italic">Main Technical Challenges</span>
</h3>

<div id="S5.SS1.p1" class="ltx_para">
<p id="S5.SS1.p1.1" class="ltx_p">The proposed DFL-UN can avoid the drawback of single point of failure in the distributed collaborative ML, especially when some UAV acting as the parameter server fails or is unreachable. And the effectiveness of the DFL-UN compared to conventional FL is also validated by the preliminary evaluation results in Section IV. However, there exist many technical challenges in the DFL-UN to be addressed before fully realizing its benefits as follows.</p>
</div>
<div id="S5.SS1.p2" class="ltx_para">
<p id="S5.SS1.p2.1" class="ltx_p"><span id="S5.SS1.p2.1.1" class="ltx_text ltx_font_bold">Convergence judgment vs. Fully distributed learning:</span> in conventional FLs, there is a central controller that monitors whether the whole training converges or not in a straightforward way. In the DFL-UN, the whole training is actually asynchronous and fully distributed over multiple UAVs. Although there also exists a coordinator to monitor the training process of the FL following <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>, the communication link between it and each UAV might be temporary in the context of highly dynamic UAV networks, which makes it challenging to timely judge the convergence sometimes.</p>
</div>
<div id="S5.SS1.p3" class="ltx_para">
<p id="S5.SS1.p3.1" class="ltx_p"><span id="S5.SS1.p3.1.1" class="ltx_text ltx_font_bold">Learning robustness vs. UAV network unreliability and heterogeneity:</span> UAV networks are intrinsically unreliable since UAVs with high mobility are easily affected by environment factors such as mechanical and wind vibrations, and the A2A links are wireless and unreliable. And different UAVs are probably heterogeneous in terms of collected data samples for training, computation and communication capabilities, and available energy. How to guarantee the robustness of the learning in the DFL-UN facing the network unreliability and heterogeneity is extremely challenging.</p>
</div>
<div id="S5.SS1.p4" class="ltx_para">
<p id="S5.SS1.p4.1" class="ltx_p"><span id="S5.SS1.p4.1.1" class="ltx_text ltx_font_bold">Communication and energy efficiency vs. Extensive A2A transmissions:</span> unlike conventional FLs that involve no D2D (<span id="S5.SS1.p4.1.2" class="ltx_text ltx_font_italic">i.e.</span>, A2A) data transmissions or a small amount of A2A transmissions, the DFL-UN incurs extensive A2A transmissions, which makes the issue of communication and energy efficiency more severe. Specifically, considering the limited energy of each UAV, if it spends much energy in the A2A communication for the local model exchange, the energy left for the local model computation may be in a shortage. The joint FL learning and spectrum sharing optimization problem is also worthy studied.</p>
</div>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S5.SS2.4.1.1" class="ltx_text">V-B</span> </span><span id="S5.SS2.5.2" class="ltx_text ltx_font_italic">Potential Research Directions</span>
</h3>

<div id="S5.SS2.p1" class="ltx_para">
<p id="S5.SS2.p1.1" class="ltx_p">In light of the aforementioned technical challenges as well as the development trend of future UAV networks, we discuss the following potential research directions in the future study.</p>
</div>
<div id="S5.SS2.p2" class="ltx_para">
<p id="S5.SS2.p2.1" class="ltx_p"><span id="S5.SS2.p2.1.1" class="ltx_text ltx_font_bold">Convergence behavior analysis:</span> as mentioned in Section V-A, it is challenging to judge the convergence of the DFL-UN. Intuitively, the convergence behavior of the DFL-UN not only relates to the evolution of this fully distributed collaborative ML, which is totally different from conventional FLs, but also is greatly affected by the unique characteristics of UAV networks such as dynamic topology and intermittent A2A links. In fact, the analysis of the convergence behavior of the DFL-UN is an open problem so far.</p>
</div>
<div id="S5.SS2.p3" class="ltx_para">
<p id="S5.SS2.p3.1" class="ltx_p"><span id="S5.SS2.p3.1.1" class="ltx_text ltx_font_bold">Secure model exchange by blockchain:</span> similar to conventional FLs, the DFL-UN involves extensive model parameters data exchange among the UAVs therein, which may be exploited by malicious participants. For the data security of the DFL-UN, blockchain that is also distributed could be leveraged to enable the secure model exchange in FL, in the presence of malicious UAVs. Nonetheless, the blockchain-based DFL-UN might incur extra significant overhead including additional block propagation, which deserves deeply investigation.</p>
</div>
<div id="S5.SS2.p4" class="ltx_para">
<p id="S5.SS2.p4.1" class="ltx_p"><span id="S5.SS2.p4.1.1" class="ltx_text ltx_font_bold">Energy/communication-efficient FL strategy:</span> the DFL-UN is different from conventional FLs as well as recent FLs over general wireless networks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>, <a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>, which makes existing energy/communication-efficient FL strategies not applicable. Specifically, from a role standpoint, compared to conventional FLs, each node (<span id="S5.SS2.p4.1.2" class="ltx_text ltx_font_italic">i.e.</span>, UAV) takes more responsibility, <span id="S5.SS2.p4.1.3" class="ltx_text ltx_font_italic">i.e.</span>, model aggregation besides local model training, which consumes more energy. And the sharing of communication resources within the DFL-UN is also essentially different.</p>
</div>
<div id="S5.SS2.p5" class="ltx_para">
<p id="S5.SS2.p5.1" class="ltx_p"><span id="S5.SS2.p5.1.1" class="ltx_text ltx_font_bold">Joint UAV placement, network resource, and training parameters optimization:</span> motivated by the above challenges, a critical but challenging question is how to jointly optimize the placement of UAVs, various network resources, and basic training parameters, to achieve the considerable learning performance. Many critical factors including UAV network unreliability and heterogeneity should be considered in the optimization problem. Thus, unlike existing works such as <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite> optimizing network resources only or <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> jointly optimizing network resources and learning parameters, the problem is brand-new and cannot be solved by existing UAV placement strategies as well as joint network resource and training optimization methods.</p>
</div>
<div id="S5.SS2.p6" class="ltx_para">
<p id="S5.SS2.p6.1" class="ltx_p"><span id="S5.SS2.p6.1.1" class="ltx_text ltx_font_bold">Adaptive decentralized FL for clustering/hierarchical UAV networks:</span> in practical, many UAV networks are cluster-based or hierarchical rather than ad hoc, where several UAVs form a small group with a leader who is in charge of the rest members. In such UAV networks, the proposed DFL-UN could be modified to enhance the performance, <span id="S5.SS2.p6.1.2" class="ltx_text ltx_font_italic">e.g.</span>, borrowing the ideas in centralized FL such as <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>, <a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>, each group could be seen as a virtual “node” that exchanges its local model parameter with other neighboring “node”, while the local models within any group are always aggregated as a single local model of this group.</p>
</div>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VI </span><span id="S6.1.1" class="ltx_text ltx_font_smallcaps">Conclusion</span>
</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">In this article, we have proposed the DFL-UN architecture to achieve fully decentralized FL over UAV networks. To be specific, each UAV not only trains a local FL model over its own data, but also aggregates several FL models from its neighboring UAVs for the update of the local FL model, which does not need a central entity for global model aggregation and fusion over the whole network. The key advantages lie in the high robustness of FL and flexibility and agility. We have also presented some preliminary results to validate its feasibility and effectiveness, and discussed several challenges and promising future research directions in the DFL-UN.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography" style="font-size:80%;">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock"><span id="bib.bib1.1.1" class="ltx_text" style="font-size:80%;">
B. Brik, A. Ksentini, and M. Bouaziz, “Federated learning for UAVs-enabled wireless networks: Use cases, challenges, and open problems,” </span><span id="bib.bib1.2.2" class="ltx_text ltx_font_italic" style="font-size:80%;">IEEE ACCESS</span><span id="bib.bib1.3.3" class="ltx_text" style="font-size:80%;">, vol. 8, pp. 53841-53849, 2020.
</span>
</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock"><span id="bib.bib2.1.1" class="ltx_text" style="font-size:80%;">
B. McMahan, E. Moore, D. Ramage, S. Hampson, and B. A. Arcas, “Communication-efficient learning of deep networks from decentralized data,” in </span><span id="bib.bib2.2.2" class="ltx_text ltx_font_italic" style="font-size:80%;">Proc. AISTATS</span><span id="bib.bib2.3.3" class="ltx_text" style="font-size:80%;">, pp. 1273-1282, 2017.
</span>
</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock"><span id="bib.bib3.1.1" class="ltx_text" style="font-size:80%;">
S. Samarakoon, M. Bennis, W. Saad, and M. Debbah, “Federated learning for ultra-reliable low-latency V2V communications,” in </span><span id="bib.bib3.2.2" class="ltx_text ltx_font_italic" style="font-size:80%;">Proc. IEEE GLOBECOM</span><span id="bib.bib3.3.3" class="ltx_text" style="font-size:80%;">, pp. 1-7, 2018.
</span>
</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock"><span id="bib.bib4.1.1" class="ltx_text" style="font-size:80%;">
M. Chen, H. V. Poor, W. Saad, and S. Cui, “Wireless communications for collaborative federated learning,” </span><span id="bib.bib4.2.2" class="ltx_text ltx_font_italic" style="font-size:80%;">IEEE Communications Magazine</span><span id="bib.bib4.3.3" class="ltx_text" style="font-size:80%;">, vol. 58, no. 12, pp. 48-54, 2020.
</span>
</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock"><span id="bib.bib5.1.1" class="ltx_text" style="font-size:80%;">
P. Pinyoanuntapong, P. Janakaraj, P. Wang, M. Lee, and C. Chen, “FedAir: Towards multi-hop federated learning over-the-air,” in </span><span id="bib.bib5.2.2" class="ltx_text ltx_font_italic" style="font-size:80%;">Proc. IEEE SPAWC</span><span id="bib.bib5.3.3" class="ltx_text" style="font-size:80%;">, pp. 1-5, 2020.
</span>
</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock"><span id="bib.bib6.1.1" class="ltx_text" style="font-size:80%;">
S. Hosseinalipour, C. G. Brinton, V. Aggarwal, H. Dai, and M. Chiang, “From federated to fog learning: Distributed machine learning over heterogeneous wireless networks,” </span><span id="bib.bib6.2.2" class="ltx_text ltx_font_italic" style="font-size:80%;">IEEE Communications Magazine</span><span id="bib.bib6.3.3" class="ltx_text" style="font-size:80%;">, vol. 58, no. 12, pp. 41-47, 2020.
</span>
</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock"><span id="bib.bib7.1.1" class="ltx_text" style="font-size:80%;">
T. Zeng, O. Semiari, M. Mozaffari, M. Chen, W. Saad, and M. Bennis, “Federated learning in the sky: Joint power allocation and scheduling with UAV swarms,” in </span><span id="bib.bib7.2.2" class="ltx_text ltx_font_italic" style="font-size:80%;">Proc. IEEE ICC</span><span id="bib.bib7.3.3" class="ltx_text" style="font-size:80%;">, pp. 1-6, 2020.
</span>
</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock"><span id="bib.bib8.1.1" class="ltx_text" style="font-size:80%;">
S. S. Ram, A. Nedic, and V. V. Veeravalli, “Asynchronous gossip algorithms for stochastic optimization,” in </span><span id="bib.bib8.2.2" class="ltx_text ltx_font_italic" style="font-size:80%;">Proc. IEEE CDC</span><span id="bib.bib8.3.3" class="ltx_text" style="font-size:80%;">, pp. 3581-3586, 2009.
</span>
</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock"><span id="bib.bib9.1.1" class="ltx_text" style="font-size:80%;">
A. Nedic and A. E. Ozdaglar, “Distributed subgradient methods for multi-agent optimization,” </span><span id="bib.bib9.2.2" class="ltx_text ltx_font_italic" style="font-size:80%;">IEEE Transactions on Automatic Control</span><span id="bib.bib9.3.3" class="ltx_text" style="font-size:80%;">, vol. 54, no. 1, pp. 48-61, 2009.
</span>
</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock"><span id="bib.bib10.1.1" class="ltx_text" style="font-size:80%;">
X. Lian, C. Zhang, H. Zhang, C.-J. Hsieh, W. Zhang, and J. Liu, “Can decentralized algorithms outperform centralized algorithms? A case study for decentralized parallel stochastic gradient descent,” in </span><span id="bib.bib10.2.2" class="ltx_text ltx_font_italic" style="font-size:80%;">Proc. NIPS</span><span id="bib.bib10.3.3" class="ltx_text" style="font-size:80%;">, pp. 5330-5340, 2017.
</span>
</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock"><span id="bib.bib11.1.1" class="ltx_text" style="font-size:80%;">
Z. Tang, S. Shi, and X. Chu, “Communication-efficient decentralized learning with sparsification and adaptive peer selection,” in </span><span id="bib.bib11.2.2" class="ltx_text ltx_font_italic" style="font-size:80%;">Proc. IEEE ICDCS</span><span id="bib.bib11.3.3" class="ltx_text" style="font-size:80%;">, pp. 1207-1208, 2020.
</span>
</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock"><span id="bib.bib12.1.1" class="ltx_text" style="font-size:80%;">
M. Chen, Z. Yang, W. Saad, C. Yin, H. V. Poor, and S. Cui, “A joint learning and communications framework for federated learning over wireless networks,” </span><span id="bib.bib12.2.2" class="ltx_text ltx_font_italic" style="font-size:80%;">IEEE Transactions on Wireless Communications</span><span id="bib.bib12.3.3" class="ltx_text" style="font-size:80%;">, vol. 20, no. 1, pp. 269-283, 2021.
</span>
</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock"><span id="bib.bib13.1.1" class="ltx_text" style="font-size:80%;">
N. H. Tran, W. Bao, A. Y. Zomaya, M. N. H. Nguren, and C. S. Hong, “Federated learning over wireless networks: Optimization model design and analysis,” in </span><span id="bib.bib13.2.2" class="ltx_text ltx_font_italic" style="font-size:80%;">Proc. IEEE INFOCOM</span><span id="bib.bib13.3.3" class="ltx_text" style="font-size:80%;">, pp. 1387-1395, 2019.
</span>
</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock"><span id="bib.bib14.1.1" class="ltx_text" style="font-size:80%;">
J. Ren, G. Yu, and G. Ding, “Accelerating DNN training in wireless federated edge learning systems,” </span><span id="bib.bib14.2.2" class="ltx_text ltx_font_italic" style="font-size:80%;">IEEE Journal on Selected Areas in Communications</span><span id="bib.bib14.3.3" class="ltx_text" style="font-size:80%;">, vol. 39, no. 1, pp. 219-232, 2021.
</span>
</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock"><span id="bib.bib15.1.1" class="ltx_text" style="font-size:80%;">
S. Savazzi, V. Rampa, F. Vicentini, and M. Giussani, “Device-free human sensing and localization in collaborative human-robot workspaces: A case study,” </span><span id="bib.bib15.2.2" class="ltx_text ltx_font_italic" style="font-size:80%;">IEEE Sensors Journal</span><span id="bib.bib15.3.3" class="ltx_text" style="font-size:80%;">, vol. 16, no. 5, pp. 1253-1264, 2016.
</span>
</span>
</li>
</ul>
</section>
<figure id="id1" class="ltx_float biography">
<table id="id1.1" class="ltx_tabular">
<tr id="id1.1.1" class="ltx_tr">
<td id="id1.1.1.1" class="ltx_td"><img src="/html/2104.07557/assets/x7.png" id="id1.1.1.1.g1" class="ltx_graphics ltx_img_portrait" width="55" height="76" alt="[Uncaptioned image]"></td>
<td id="id1.1.1.2" class="ltx_td">
<span id="id1.1.1.2.1" class="ltx_inline-block">
<span id="id1.1.1.2.1.1" class="ltx_p"><span id="id1.1.1.2.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Yuben Qu</span><span id="id1.1.1.2.1.1.2" class="ltx_text" style="font-size:80%;">  received the B.S. degree in Mathematics and Applied Mathematics from Nanjing University, and both the M.S. degree in Communication and Information Systems and the Ph.D degree in Computer Science and Technology from Nanjing Institute of Communications, in 2009, 2012 and 2016, respectively. He is currently a research assistant in the College of Electronic and Information Engineering, Nanjing University of Aeronautics and Astronautics, Nanjing, China, and also a post-doc in the Department of Computer Science and Engineering, Shanghai Jiao Tong University, China. He is a recipient of The 2019 Post-doc Innovative Talent Support Program. From October 2015 to January 2016, he was a visiting research associate in the School of Computer Science and Engineering, The University of Aizu, Japan. His current research interests include edge intelligence computing, air-ground integrated networks, D2D communications, and crowdsensing.</span></span>
</span>
</td>
</tr>
</table>
</figure>
<figure id="id2" class="ltx_float biography">
<table id="id2.1" class="ltx_tabular">
<tr id="id2.1.1" class="ltx_tr">
<td id="id2.1.1.1" class="ltx_td"><img src="/html/2104.07557/assets/HaipengDai.jpg" id="id2.1.1.1.g1" class="ltx_graphics ltx_img_portrait" width="76" height="100" alt="[Uncaptioned image]"></td>
<td id="id2.1.1.2" class="ltx_td">
<span id="id2.1.1.2.1" class="ltx_inline-block">
<span id="id2.1.1.2.1.1" class="ltx_p"><span id="id2.1.1.2.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Haipeng Dai</span><span id="id2.1.1.2.1.1.2" class="ltx_text" style="font-size:80%;"> 
received the B.S. degree in the Department of Electronic Engineering from Shanghai Jiao Tong University, Shanghai, China, in 2010, and the Ph.D. degree in the Department of Computer Science and Technology in Nanjing University, Nanjing, China, in 2014.
His research interests are mainly in the areas of wireless charging, mobile computing, and data mining.
He is an associate professor in the Department of Computer Science and Technology in Nanjing University.
His research papers have been published in many prestigious conferences and journals such as ACM MobiSys, ACM MobiHoc, ACM VLDB, IEEE ICDE, ACM SIGMETRICS, ACM UbiComp, IEEE INFOCOM, IEEE ICDCS, IEEE ICNP, IEEE SECON, IEEE IPSN, IEEE JSAC, IEEE/ACM TON, IEEE TMC, IEEE TPDS, and IEEE TOSN.
He is an IEEE and ACM member.
He serves/ed as Poster Chair of the IEEE ICNP’14, Track Chair of the ICCCN’19, TPC member of the ACM MobiHoc’20-21, IEEE INFOCOM’20-21, IEEE ICDCS’20-21, IEEE ICNP’14, IEEE IWQoS’19-21, IEEE IPDPS’20 and IEEE MASS’18-19.
He received Best Paper Award from IEEE ICNP’15, Best Paper Award Runner-up from IEEE SECON’18, and Best Paper Award Candidate from IEEE INFOCOM’17.</span></span>
</span>
</td>
</tr>
</table>
</figure>
<figure id="id3" class="ltx_float biography">
<table id="id3.1" class="ltx_tabular">
<tr id="id3.1.1" class="ltx_tr">
<td id="id3.1.1.1" class="ltx_td"><img src="/html/2104.07557/assets/YanZhuang.jpg" id="id3.1.1.1.g1" class="ltx_graphics ltx_img_portrait" width="75" height="100" alt="[Uncaptioned image]"></td>
<td id="id3.1.1.2" class="ltx_td">
<span id="id3.1.1.2.1" class="ltx_inline-block">
<span id="id3.1.1.2.1.1" class="ltx_p"><span id="id3.1.1.2.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Yan Zhuang</span><span id="id3.1.1.2.1.1.2" class="ltx_text" style="font-size:80%;">  received his B.S. degree in the Department of Automation, University of Science and Technology of China, in 2019. He is currently working towards his M.S. degree in the Department of Computer Science and Engineering, Shanghai Jiao Tong University, China. His research interests include federated learning, wireless network and mobile edge computing.</span></span>
</span>
</td>
</tr>
</table>
</figure>
<figure id="id4" class="ltx_float biography">
<table id="id4.1" class="ltx_tabular">
<tr id="id4.1.1" class="ltx_tr">
<td id="id4.1.1.1" class="ltx_td"><img src="/html/2104.07557/assets/JiafaChen.png" id="id4.1.1.1.g1" class="ltx_graphics ltx_img_portrait" width="73" height="100" alt="[Uncaptioned image]"></td>
<td id="id4.1.1.2" class="ltx_td">
<span id="id4.1.1.2.1" class="ltx_inline-block">
<span id="id4.1.1.2.1.1" class="ltx_p"><span id="id4.1.1.2.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Jiafa Chen</span><span id="id4.1.1.2.1.1.2" class="ltx_text" style="font-size:80%;">  received the B.Eng. degree in communication engineering from Putian University, China, in 2017. He is currently a PhD student with the College of Electronic and Information Engineering, Nanjing University of Aeronautics and Astronautics, Nanjing, China. His research interests include energy harvesting communications, mobile edge computing, and radio resource management.</span></span>
</span>
</td>
</tr>
</table>
</figure>
<figure id="id5" class="ltx_float biography">
<table id="id5.1" class="ltx_tabular">
<tr id="id5.1.1" class="ltx_tr">
<td id="id5.1.1.1" class="ltx_td"><img src="/html/2104.07557/assets/x8.png" id="id5.1.1.1.g1" class="ltx_graphics ltx_img_portrait" width="57" height="77" alt="[Uncaptioned image]"></td>
<td id="id5.1.1.2" class="ltx_td">
<span id="id5.1.1.2.1" class="ltx_inline-block">
<span id="id5.1.1.2.1.1" class="ltx_p"><span id="id5.1.1.2.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Chao Dong</span><span id="id5.1.1.2.1.1.2" class="ltx_text" style="font-size:80%;">  received his Ph.D degree in Communication Engineering from PLA University of Science and Technology, China, in 2007. From 2008 to 2011, he worked as a post Doc at the Department of Computer Science and Technology, Nanjing University, China. From 2011 to 2017, he was an Associate Professor with the Institute of Communications Engineering, PLA University of Science and Technology, Nanjing, China. He is now a full professor with the College of Electronic and Information Engineering, Nanjing University of Aeronautics and Astronautics, Nanjing, China. His current research interests include D2D communications, UAVs swarm networking and anti-jamming network protocol. He is a member of IEEE, ACM and IEICE.</span></span>
</span>
</td>
</tr>
</table>
</figure>
<figure id="id7" class="ltx_float biography">
<table id="id7.2" class="ltx_tabular">
<tr id="id7.2.2" class="ltx_tr">
<td id="id6.1.1.1" class="ltx_td"><img src="/html/2104.07557/assets/x9.png" id="id6.1.1.1.g1" class="ltx_graphics ltx_img_portrait" width="54" height="77" alt="[Uncaptioned image]"></td>
<td id="id7.2.2.2" class="ltx_td">
<span id="id7.2.2.2.1" class="ltx_inline-block">
<span id="id7.2.2.2.1.1" class="ltx_p"><span id="id7.2.2.2.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Fan Wu</span><span id="id7.2.2.2.1.1.2" class="ltx_text" style="font-size:80%;">  is a professor in the Department of Computer Science and Engineering, Shanghai Jiao Tong University. He received his B.S. in Computer Science from Nanjing University in 2004, and Ph.D. in Computer Science and Engineering from the State University of New York at Buffalo in 2009. His research interests include wireless networking and mobile computing, algorithmic game theory and its applications, and privacy preservation. He has published more than 150 peer-reviewed papers in technical journals and conference proceedings. He has served as an editor of IEEE Transactions on Mobile Computing, an area editor of Elsevier Computer Networks, and as the member of technical program committees of more than 90 academic conferences. For more information, please visit http://www.cs.sjtu.edu.cn/</span><math id="id7.2.2.2.1.1.m1.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="id7.2.2.2.1.1.m1.1a"><mo mathsize="80%" id="id7.2.2.2.1.1.m1.1.1" xref="id7.2.2.2.1.1.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="id7.2.2.2.1.1.m1.1b"><csymbol cd="latexml" id="id7.2.2.2.1.1.m1.1.1.cmml" xref="id7.2.2.2.1.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="id7.2.2.2.1.1.m1.1c">\sim</annotation></semantics></math><span id="id7.2.2.2.1.1.3" class="ltx_text" style="font-size:80%;">fwu/.</span></span>
</span>
</td>
</tr>
</table>
</figure>
<figure id="id8" class="ltx_float biography">
<table id="id8.1" class="ltx_tabular">
<tr id="id8.1.1" class="ltx_tr">
<td id="id8.1.1.1" class="ltx_td"><img src="/html/2104.07557/assets/x10.png" id="id8.1.1.1.g1" class="ltx_graphics ltx_img_portrait" width="60" height="77" alt="[Uncaptioned image]"></td>
<td id="id8.1.1.2" class="ltx_td">
<span id="id8.1.1.2.1" class="ltx_inline-block">
<span id="id8.1.1.2.1.1" class="ltx_p"><span id="id8.1.1.2.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Song Guo</span><span id="id8.1.1.2.1.1.2" class="ltx_text" style="font-size:80%;">  is a Full Professor at Department of Computing, The Hong Kong Polytechnic University. His research interests are mainly in the areas of big data, cloud computing, mobile computing, and distributed systems with over 450 papers published in major conferences and journals. His work was recognized by the 2016 Annual Best of Computing: Notable Books and Articles in Computing in ACM Computing Reviews. He is the recipient of the 2018 IEEE TCGCC Best Magazine Paper Award, 2017 IEEE Systems Journal Annual Best Paper Award, and other six Best Paper Awards from IEEE/ACM conferences. Prof. Guo was an Associate Editor of IEEE Transactions on Parallel and Distributed Systems and an IEEE ComSoc Distinguished Lecturer. He is now an Associate Editor of IEEE Transactions on Cloud Computing, IEEE Transactions on Emerging Topics in Computing, IEEE Transactions on Sustainable Computing, IEEE Transactions on Green Communications and Networking, and IEEE Network. Prof. Guo also served as General and Program Chair for numerous IEEE conferences. He currently serves as a Director and Member of the Board of Governors of IEEE ComSoc. He is a fellow of the IEEE.</span></span>
</span>
</td>
</tr>
</table>
</figure>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2104.07556" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2104.07557" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2104.07557">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2104.07557" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2104.07558" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Sun Mar 17 02:53:57 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
