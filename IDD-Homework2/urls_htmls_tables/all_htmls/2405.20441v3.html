<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>SECURE: Benchmarking Large Language Models for Cybersecurity Advisory</title>
<!--Generated on Thu Sep 19 20:46:44 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<meta content="
Large Language Models,  Security,  Cyber Advisory,  Dataset.
" lang="en" name="keywords"/>
<base href="/html/2405.20441v3/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#S1" title="In SECURE: Benchmarking Large Language Models for Cybersecurity Advisory"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">I </span><span class="ltx_text ltx_font_smallcaps">Introduction</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#S2" title="In SECURE: Benchmarking Large Language Models for Cybersecurity Advisory"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">II </span><span class="ltx_text ltx_font_smallcaps">Background and Related Work</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#S3" title="In SECURE: Benchmarking Large Language Models for Cybersecurity Advisory"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">III </span><span class="ltx_text ltx_font_smallcaps">Proposed Benchmark: SECURE</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#S3.SS1" title="In III Proposed Benchmark: SECURE ‣ SECURE: Benchmarking Large Language Models for Cybersecurity Advisory"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-A</span> </span><span class="ltx_text ltx_font_italic">Modeling</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#S3.SS2" title="In III Proposed Benchmark: SECURE ‣ SECURE: Benchmarking Large Language Models for Cybersecurity Advisory"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-B</span> </span><span class="ltx_text ltx_font_italic">Data Sources and Tasks</span></span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#S3.SS2.SSS1" title="In III-B Data Sources and Tasks ‣ III Proposed Benchmark: SECURE ‣ SECURE: Benchmarking Large Language Models for Cybersecurity Advisory"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-B</span>1 </span>Extraction Task</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#S3.SS2.SSS2" title="In III-B Data Sources and Tasks ‣ III Proposed Benchmark: SECURE ‣ SECURE: Benchmarking Large Language Models for Cybersecurity Advisory"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-B</span>2 </span>Understanding Task</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#S3.SS2.SSS3" title="In III-B Data Sources and Tasks ‣ III Proposed Benchmark: SECURE ‣ SECURE: Benchmarking Large Language Models for Cybersecurity Advisory"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-B</span>3 </span>Reasoning Task</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#S3.SS3" title="In III Proposed Benchmark: SECURE ‣ SECURE: Benchmarking Large Language Models for Cybersecurity Advisory"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-C</span> </span><span class="ltx_text ltx_font_italic">Dataset Validation</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#S3.SS4" title="In III Proposed Benchmark: SECURE ‣ SECURE: Benchmarking Large Language Models for Cybersecurity Advisory"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-D</span> </span><span class="ltx_text ltx_font_italic">Benchmark Dataset and Evaluation</span></span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#S4" title="In SECURE: Benchmarking Large Language Models for Cybersecurity Advisory"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">IV </span><span class="ltx_text ltx_font_smallcaps">Experiments &amp; Results</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#S4.SS1" title="In IV Experiments &amp; Results ‣ SECURE: Benchmarking Large Language Models for Cybersecurity Advisory"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">IV-A</span> </span><span class="ltx_text ltx_font_italic">Prompting Strategy for Evaluation</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#S4.SS2" title="In IV Experiments &amp; Results ‣ SECURE: Benchmarking Large Language Models for Cybersecurity Advisory"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">IV-B</span> </span><span class="ltx_text ltx_font_italic">Evaluation Metrics</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#S4.SS3" title="In IV Experiments &amp; Results ‣ SECURE: Benchmarking Large Language Models for Cybersecurity Advisory"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">IV-C</span> </span><span class="ltx_text ltx_font_italic">Results Summary</span></span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#S5" title="In SECURE: Benchmarking Large Language Models for Cybersecurity Advisory"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">V </span><span class="ltx_text ltx_font_smallcaps">Discussion &amp; Analysis</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#S5.SS1" title="In V Discussion &amp; Analysis ‣ SECURE: Benchmarking Large Language Models for Cybersecurity Advisory"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">V-A</span> </span><span class="ltx_text ltx_font_italic">Error Analysis</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#S5.SS2" title="In V Discussion &amp; Analysis ‣ SECURE: Benchmarking Large Language Models for Cybersecurity Advisory"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">V-B</span> </span><span class="ltx_text ltx_font_italic">Impact of Confidence on LLM Accuracy</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#S5.SS3" title="In V Discussion &amp; Analysis ‣ SECURE: Benchmarking Large Language Models for Cybersecurity Advisory"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">V-C</span> </span><span class="ltx_text ltx_font_italic">Open vs. Closed Model Performance</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#S5.SS4" title="In V Discussion &amp; Analysis ‣ SECURE: Benchmarking Large Language Models for Cybersecurity Advisory"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">V-D</span> </span><span class="ltx_text ltx_font_italic">Evaluating Reasoning Abilities</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#S5.SS5" title="In V Discussion &amp; Analysis ‣ SECURE: Benchmarking Large Language Models for Cybersecurity Advisory"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">V-E</span> </span><span class="ltx_text ltx_font_italic">Variance in Prediction</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#S5.SS6" title="In V Discussion &amp; Analysis ‣ SECURE: Benchmarking Large Language Models for Cybersecurity Advisory"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">V-F</span> </span><span class="ltx_text ltx_font_italic">Model Agreement Bias</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#S5.SS7" title="In V Discussion &amp; Analysis ‣ SECURE: Benchmarking Large Language Models for Cybersecurity Advisory"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">V-G</span> </span><span class="ltx_text ltx_font_italic">Task Correlation Analysis</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#S5.SS8" title="In V Discussion &amp; Analysis ‣ SECURE: Benchmarking Large Language Models for Cybersecurity Advisory"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">V-H</span> </span><span class="ltx_text ltx_font_italic">LLM Performance Across Expertise Levels</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#S5.SS9" title="In V Discussion &amp; Analysis ‣ SECURE: Benchmarking Large Language Models for Cybersecurity Advisory"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">V-I</span> </span><span class="ltx_text ltx_font_italic">Human Benchmark</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#S5.SS10" title="In V Discussion &amp; Analysis ‣ SECURE: Benchmarking Large Language Models for Cybersecurity Advisory"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">V-J</span> </span><span class="ltx_text ltx_font_italic">Recommendations</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#S5.SS11" title="In V Discussion &amp; Analysis ‣ SECURE: Benchmarking Large Language Models for Cybersecurity Advisory"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">V-K</span> </span><span class="ltx_text ltx_font_italic">Ethical concerns</span></span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#S6" title="In SECURE: Benchmarking Large Language Models for Cybersecurity Advisory"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">VI </span><span class="ltx_text ltx_font_smallcaps">Customized LLMs</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#S6.SS1" title="In VI Customized LLMs ‣ SECURE: Benchmarking Large Language Models for Cybersecurity Advisory"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">VI-A</span> </span><span class="ltx_text ltx_font_italic">Retrieval Augmented Generation</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#S6.SS2" title="In VI Customized LLMs ‣ SECURE: Benchmarking Large Language Models for Cybersecurity Advisory"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">VI-B</span> </span><span class="ltx_text ltx_font_italic">Fine-tuning</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#S6.SS3" title="In VI Customized LLMs ‣ SECURE: Benchmarking Large Language Models for Cybersecurity Advisory"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">VI-C</span> </span><span class="ltx_text ltx_font_italic">Results:</span></span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#S7" title="In SECURE: Benchmarking Large Language Models for Cybersecurity Advisory"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">VII </span><span class="ltx_text ltx_font_smallcaps">Limitations &amp; Future Work</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#S8" title="In SECURE: Benchmarking Large Language Models for Cybersecurity Advisory"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">VIII </span><span class="ltx_text ltx_font_smallcaps">Conclusion</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#A0.SS1" title="In SECURE: Benchmarking Large Language Models for Cybersecurity Advisory"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">-A</span> </span><span class="ltx_text ltx_font_italic">Large Language Models</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#A0.SS2" title="In SECURE: Benchmarking Large Language Models for Cybersecurity Advisory"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">-B</span> </span><span class="ltx_text ltx_font_italic">Evaluation Metrics</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#A0.SS3" title="In SECURE: Benchmarking Large Language Models for Cybersecurity Advisory"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">-C</span> </span><span class="ltx_text ltx_font_italic">Prompt templates for evaluation</span></span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#A0.SS3.SSS1" title="In -C Prompt templates for evaluation ‣ SECURE: Benchmarking Large Language Models for Cybersecurity Advisory"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">-C</span>1 </span>Extraction Task</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#A0.SS3.SSS2" title="In -C Prompt templates for evaluation ‣ SECURE: Benchmarking Large Language Models for Cybersecurity Advisory"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">-C</span>2 </span>Understanding Task</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#A0.SS3.SSS3" title="In -C Prompt templates for evaluation ‣ SECURE: Benchmarking Large Language Models for Cybersecurity Advisory"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">-C</span>3 </span>Reasoning Task</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#A0.SS4" title="In SECURE: Benchmarking Large Language Models for Cybersecurity Advisory"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">-D</span> </span><span class="ltx_text ltx_font_italic">LLM Reasoning Example</span></span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">SECURE: Benchmarking Large Language Models for Cybersecurity Advisory</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname"> 1<sup class="ltx_sup" id="id1.1.id1">st</sup> Dipkamal Bhusal1
</span><span class="ltx_author_notes">1 Equal contribution.
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_font_italic" id="id2.2.id1">RIT
<br class="ltx_break"/></span>Rochester, USA 
<br class="ltx_break"/>db1702@rit.edu
</span></span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">2<sup class="ltx_sup" id="id3.1.id1">nd</sup> Md Tanvirul Alam1
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_font_italic" id="id4.2.id1">RIT
<br class="ltx_break"/></span>Rochester, USA
<br class="ltx_break"/>ma8235@g.rit.edu
</span></span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">3<sup class="ltx_sup" id="id5.1.id1">rd</sup> Le Nguyen
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_font_italic" id="id6.2.id1">RIT
<br class="ltx_break"/></span>Rochester, USA 
<br class="ltx_break"/>ln8378@rit.edu
</span></span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">4<sup class="ltx_sup" id="id7.1.id1">th</sup> Ashim Mahara
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_font_italic" id="id8.2.id1">RIT
<br class="ltx_break"/></span>Rochester, USA
<br class="ltx_break"/>am7539@g.rit.edu
</span></span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">      5<sup class="ltx_sup" id="id9.1.id1">th</sup> Zachary Lightcap
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_font_italic" id="id10.2.id1">RIT
<br class="ltx_break"/></span>Rochester, USA 
<br class="ltx_break"/>ztl1776@rit.edu
</span></span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">6<sup class="ltx_sup" id="id11.1.id1">th</sup> Rodney Frazier
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_font_italic" id="id12.2.id1">RIT
<br class="ltx_break"/></span>Rochester, USA 
<br class="ltx_break"/>rlf9328@rit.edu
</span></span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">7<sup class="ltx_sup" id="id13.1.id1">th</sup> Romy Fieblinger
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_font_italic" id="id14.2.id1">RIT
<br class="ltx_break"/></span>Rochester, USA 
<br class="ltx_break"/>rf7344@g.rit.edu
</span></span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">8<sup class="ltx_sup" id="id15.1.id1">th</sup> Grace Long Torales
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_font_italic" id="id16.2.id1">RIT
<br class="ltx_break"/></span>Rochester, USA 
<br class="ltx_break"/>gtl1500@rit.edu
</span></span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">                   9<sup class="ltx_sup" id="id17.1.id1">th</sup> Benjamin A. Blakely
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_font_italic" id="id18.2.id1">                   Argonne National Lab
<br class="ltx_break"/></span>                   Lemont, USA 
<br class="ltx_break"/>                   bblakely@anl.gov
</span></span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">10<sup class="ltx_sup" id="id19.1.id1">th</sup> Nidhi Rastogi
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_font_italic" id="id20.2.id1">Rochester Institute of Technology (RIT)
<br class="ltx_break"/></span>Rochester, USA 
<br class="ltx_break"/>nxrvse@rit.edu
</span></span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id21.id1">Large Language Models (LLMs) have demonstrated potential in cybersecurity applications but have also caused lower confidence due to problems like hallucinations and a lack of truthfulness. Existing benchmarks provide general evaluations but do not sufficiently address the practical and applied aspects of LLM performance in cybersecurity-specific tasks. To address this gap, we introduce the SECURE (Security Extraction, Understanding &amp; Reasoning Evaluation), a benchmark designed to assess LLMs performance in realistic cybersecurity scenarios. SECURE includes six datasets focussed on the Industrial Control System sector to evaluate knowledge extraction, understanding, and reasoning based on industry-standard sources. Our study evaluates seven state-of-the-art models on these tasks, providing insights into their strengths and weaknesses in cybersecurity contexts. We also offer recommendations for improving LLMs reliability as cyber advisory tools and release our benchmark datasets and framework for community use at <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/aiforsec/SECURE" style="color:#0000FF;" title="">https://github.com/aiforsec/SECURE</a>.</p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Index Terms: </h6>
Large Language Models, Security, Cyber Advisory, Dataset.

</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">I </span><span class="ltx_text ltx_font_smallcaps" id="S1.1.1">Introduction</span>
</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Recent breakthroughs in large language models (LLM) like OpenAI’s ChatGPT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib1" title="">1</a>]</cite> have opened up their applications in many domains, including security <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib2" title="">2</a>]</cite>. These models, trained on vast datasets, can generate, understand, and reason across a multitude of domains <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib3" title="">3</a>]</cite>. Users can interact with these models in a conversational style through a simple web interface and obtain answers to their questions in a short time. Despite demonstrating high potential, LLMs are plagued by issues such as hallucinations <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib4" title="">4</a>]</cite> and truthfulness <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib5" title="">5</a>]</cite>. Hence, a standard evaluation benchmark is crucial to evaluate the reliability of such models. Several benchmarks like GLUE <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib6" title="">6</a>]</cite>, MMLU <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib7" title="">7</a>]</cite>, Helm <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib8" title="">8</a>]</cite> and KOLA <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib9" title="">9</a>]</cite>, provide standard datasets and tasks to evaluate general-purpose understanding and capabilities of LLMs. GLUE assesses LLMs’ performance in understanding language, while MMLU and HELM offer a holistic evaluation across various domains like mathematics, history, computer science, and law. KOLA focuses on tasks designed to measure the cognitive abilities of LLMs.</p>
</div>
<figure class="ltx_figure" id="S1.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="135" id="S1.F1.g1" src="extracted/5866847/chat.png" width="216"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S1.F1.2.1.1" style="font-size:90%;">Figure 1</span>: </span><span class="ltx_text" id="S1.F1.3.2" style="font-size:90%;">Conversation between a user and a ChatGPT-3.5 on ICS security questions.</span></figcaption>
</figure>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">Despite these advancements, there remains a significant gap in the evaluation of LLMs specifically tailored for security industries such as information security, network security, and critical infrastructure protection. Traditional benchmarks often fail to capture the practical and applied aspects of cybersecurity, leading to an incomplete assessment of LLM capabilities. These benchmarks typically focus on general language tasks and do not address specific challenges such as recognizing emerging threats, handling specialized terminology, or performing tasks like vulnerability assessment and incident response. More practical, domain-specific, and comprehensive evaluations are necessary to understand LLM performance in realistic cybersecurity scenarios <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib10" title="">10</a>]</cite>. In Figure <a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#S1.F1" title="Figure 1 ‣ I Introduction ‣ SECURE: Benchmarking Large Language Models for Cybersecurity Advisory"><span class="ltx_text ltx_ref_tag">1</span></a>, we demonstrate a conversation between ChatGPT-3.5 and a user based on our benchmark dataset (see Section <a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#S3" title="III Proposed Benchmark: SECURE ‣ SECURE: Benchmarking Large Language Models for Cybersecurity Advisory"><span class="ltx_text ltx_ref_tag">III</span></a>). ChatGPT-3.5 model was prompted to act as a security expert, and yet, all three responses, spanning different kinds of tasks, were incorrect, showing the unreliability of these models in cybersecurity. Especially, on the first task, we ask questions about vulnerabilities discovered in 2024. Even though the model is not trained on any such recent data, it confidently makes a decision, despite our instructions to return ’X’ when it is not confident.</p>
</div>
<figure class="ltx_figure" id="S1.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="181" id="S1.F2.g1" src="x1.png" width="373"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S1.F2.2.1.1" style="font-size:90%;">Figure 2</span>: </span><span class="ltx_text" id="S1.F2.3.2" style="font-size:90%;">Overview of the SECURE benchmark.</span></figcaption>
</figure>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">To address this gap, we introduce a comprehensive benchmarking framework encompassing real-world cybersecurity scenarios, practical tasks, and applied knowledge assessments. We introduce <span class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" id="S1.p3.1.1">S</span>ecurity <span class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" id="S1.p3.1.2">E</span>xtra<span class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" id="S1.p3.1.3">C</span>tion, <span class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" id="S1.p3.1.4">U</span>nderstanding &amp; <span class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" id="S1.p3.1.5">R</span>easoning <span class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" id="S1.p3.1.6">E</span>valuation (SECURE) for large language models. This benchmark provides a holistic evaluation of LLMs performance in cybersecurity applications, ensuring they meet the high standards required for deployment in critical infrastructure environments, such as Industrial Control Systems (ICS). Figure <a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#S1.F2" title="Figure 2 ‣ I Introduction ‣ SECURE: Benchmarking Large Language Models for Cybersecurity Advisory"><span class="ltx_text ltx_ref_tag">2</span></a> shows an overview of our proposed benchmark. SECURE incorporates knowledge modeling to design six different datasets (MAET: Mitre Attack Extraction Task, CWET: Common Weakness Extraction Task, KCV: Knowledge test on Common Vulnerabilities, VOOD: Vulnerability Out-of-Distribution task, RERT: Risk Evaluation Reasoning Task, and CPST: CVSS Problem Solving Task) focused on three types of knowledge evaluations: extraction, understanding, and reasoning. These datasets are sourced from standard sources, such as MITRE <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib11" title="">11</a>]</cite> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib12" title="">12</a>]</cite>, CVE <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib13" title="">13</a>]</cite>, CWE <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib14" title="">14</a>]</cite>, and Cybersecurity and Infrastructure Security Agency (CISA) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib15" title="">15</a>]</cite>.</p>
</div>
<section class="ltx_subsection" id="S1.SSx1">
<h3 class="ltx_title ltx_font_italic ltx_title_subsection">Main Contributions</h3>
<div class="ltx_para" id="S1.SSx1.p1">
<ol class="ltx_enumerate" id="S1.I1">
<li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="S1.I1.i1.p1">
<p class="ltx_p" id="S1.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S1.I1.i1.p1.1.1">Assessment of cybersecurity knowledge:</span> We evaluate the cybersecurity knowledge of LLMs in assisting security analysts. To achieve this, we develop a series of benchmark tasks specifically for evaluating LLMs in the context of ICS cyber advisory (see Section <a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#S3" title="III Proposed Benchmark: SECURE ‣ SECURE: Benchmarking Large Language Models for Cybersecurity Advisory"><span class="ltx_text ltx_ref_tag">III</span></a>). These tasks are based on comprehensive protocol specifications detailing communication standards and procedures, historical cyber threats and attacks, CVEs with contextual information on exploitability and severity, and detailed remediation strategies, including patch notes and mitigation steps from MITRE.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="S1.I1.i2.p1">
<p class="ltx_p" id="S1.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S1.I1.i2.p1.1.1">Evaluation of LLMs</span>: Recent works have shown that customized LLMs introduce a loss of safety measures <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib16" title="">16</a>]</cite>, &amp; increased hallucinations <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib17" title="">17</a>]</cite>. In addition, the computational &amp; technical requirements of building customized LLMs can push researchers &amp; industries to use commercial LLMs. However, before we can confidently claim the application of general-purpose LLMs in a specific domain, we first need to evaluate it on domain-specific tasks. For this, we first evaluate 7 open and closed source state-of-the-art models (ChatGPT-4 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib1" title="">1</a>]</cite>, ChatGPT-3.5 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib18" title="">18</a>]</cite>, Llama3-70b <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib19" title="">19</a>]</cite>, Llama3-8b <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib20" title="">20</a>]</cite>, Gemini-Pro <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib21" title="">21</a>]</cite>, Mistral-7B <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib22" title="">22</a>]</cite> , Mixtral-8x7b <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib23" title="">23</a>]</cite>) on our benchmark tasks (see Section <a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#S4" title="IV Experiments &amp; Results ‣ SECURE: Benchmarking Large Language Models for Cybersecurity Advisory"><span class="ltx_text ltx_ref_tag">IV</span></a>). We then customize Llama3-8b using Retrieval Augmented Generation (RAG) framework and fine-tuning and evaluate the LLMs on our benchmark (see Section <a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#S6" title="VI Customized LLMs ‣ SECURE: Benchmarking Large Language Models for Cybersecurity Advisory"><span class="ltx_text ltx_ref_tag">VI</span></a>).</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span>
<div class="ltx_para" id="S1.I1.i3.p1">
<p class="ltx_p" id="S1.I1.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S1.I1.i3.p1.1.1">Insights and Recommendations:</span> Our findings demonstrate that while LLMs demonstrate some capability in cybersecurity tasks, their use as advisory tools requires careful consideration. We provide insightful observations and propose recommendations to enhance their usability (see Section <a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#S5" title="V Discussion &amp; Analysis ‣ SECURE: Benchmarking Large Language Models for Cybersecurity Advisory"><span class="ltx_text ltx_ref_tag">V</span></a>).</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span>
<div class="ltx_para" id="S1.I1.i4.p1">
<p class="ltx_p" id="S1.I1.i4.p1.1"><span class="ltx_text ltx_font_bold" id="S1.I1.i4.p1.1.1">Benchmark Dataset and Framework:</span> We provide our benchmark datasets (MAET: Mitre Attack Extraction Task, CWET: Common Weakness Extraction Task, KCV: Knowledge test on Common Vulnerabilities, VOOD: Vulnerability Out-of-Distribution, RERT: Risk Evaluation Reasoning Task, and CPST: CVSS Problem Solving Task) and framework to the security community so that they can be openly used to evaluate future LLMs in various security applications.</p>
</div>
</li>
</ol>
</div>
</section>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">II </span><span class="ltx_text ltx_font_smallcaps" id="S2.1.1">Background and Related Work</span>
</h2>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1"><span class="ltx_text ltx_font_bold" id="S2.p1.1.1">Large Language Model (LLM) in Security:</span> LLMs, trained on vast amounts of textual data, are capable of producing coherent and contextually relevant text. While earlier BERT-language models like SecureBERT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib24" title="">24</a>]</cite> and CySecBERT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib25" title="">25</a>]</cite> were used for language modeling in cybersecurity, the release of GPT (Generative Pre-trained Transformer) models has changed the nature of language models. There are two types of LLMs in the industry. Open Source LLMs like Llama <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib19" title="">19</a>]</cite> and Mixtral <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib22" title="">22</a>]</cite> make their models public so they can be fine-tuned for specific downstream tasks. Closed-source LLMs like ChatGPT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib1" title="">1</a>]</cite> and Gemini <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib26" title="">26</a>]</cite> allow restricted access through APIs. The most notable language models in security are code-based LLMs such as CodeLlama <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib27" title="">27</a>]</cite>, adapted to analyze and generate secure code. Open-sourced models have also been fine-tuned for several cybersecurity tasks like vulnerability detection <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib28" title="">28</a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib29" title="">29</a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib30" title="">30</a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib31" title="">31</a>]</cite>, program repair <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib32" title="">32</a>]</cite>, IT operations <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib33" title="">33</a>]</cite>, and security knowledge assistance <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib34" title="">34</a>]</cite>.

<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="S2.p1.1.2">Evaluation Benchmark:</span> While there are various benchmarks like GLUE <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib6" title="">6</a>]</cite>, MMLU <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib7" title="">7</a>]</cite>, Helm <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib8" title="">8</a>]</cite> and KOLA <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib9" title="">9</a>]</cite> for evaluating general-purpose LLMs, comprehensive cybersecurity-specific benchmarks remain limited. Existing approaches to evaluating LLMs in security tend to focus on factual knowledge rather than applied, practical cybersecurity tasks. For example: the CyberMetric dataset <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib35" title="">35</a>]</cite> comprises 10,000 questions sourced from cybersecurity standards. CyberBench <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib36" title="">36</a>]</cite> comprises ten datasets from different tasks namely, named-entity recognition, summarization, multiple choice, and classification. SecEval <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib37" title="">37</a>]</cite> evaluates cybersecurity knowledge in LLMs with 2000 multiple-choice questions across Software Security, Application Security, System Security, Web Security, Cryptography, Memory Safety, Network Security, and PenTest. SecQA <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib38" title="">38</a>]</cite> consists of multiple-choice questions based on the ”Computer Systems Security: Planning for Success” textbook to evaluate LLM’s understanding of security principles. NetEval <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib39" title="">39</a>]</cite> evaluates the knowledge of large language models in IT operational tasks within a multilingual context. OpsEval <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib40" title="">40</a>]</cite> also contains multi-choice questions designed for fault root cause analysis, operational script generation, and alert information summarization. Ullah et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib41" title="">41</a>]</cite> tests LLMs on identifying and reasoning about software vulnerabilities using 228 code scenarios. Their findings suggest existing LLMs are unreliable in identifying vulnerabilities in source code. CTIBench <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib42" title="">42</a>]</cite> is a benchmark of four tasks to evaluate the ability of LLMs in cyber threat intelligence (CTI) landscape.</p>
</div>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">III </span><span class="ltx_text ltx_font_smallcaps" id="S3.1.1">Proposed Benchmark: SECURE</span>
</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">Consider an LLM as a cybersecurity advisor in an organization facing diverse threats, from malware to advanced persistent threats. To mitigate these risks, cybersecurity professionals must remain constantly informed about threat intelligence, security best practices, and incident response strategies specific to their organization. LLMs have the potential to leverage their vast knowledge base and natural language processing capabilities and assist security teams in identifying vulnerabilities, interpreting threat reports, and suggesting proactive measures to fortify an organization’s defenses.</p>
</div>
<div class="ltx_para" id="S3.p2">
<p class="ltx_p" id="S3.p2.1">However, the truthfulness and reliability of the information provided by the LLMs acting as cybersecurity advisors is crucial. To achieve this, we propose <span class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" id="S3.p2.1.1">S</span>ecurity <span class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" id="S3.p2.1.2">E</span>xtra<span class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" id="S3.p2.1.3">C</span>tion, <span class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" id="S3.p2.1.4">U</span>nderstanding &amp; <span class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" id="S3.p2.1.5">R</span>easoning <span class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" id="S3.p2.1.6">E</span>valuation (SECURE) benchmark. SECURE can comprehensively evaluate LLMs, ensuring they can be trusted as reliable advisors in the high-stakes field of cybersecurity. Below, we illustrate the main components in the design of SECURE.</p>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S3.SS1.5.1.1">III-A</span> </span><span class="ltx_text ltx_font_italic" id="S3.SS1.6.2">Modeling</span>
</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">We emphasize <span class="ltx_text ltx_font_italic" id="S3.SS1.p1.1.1">knowledge modeling</span> in designing our evaluation benchmark. Knowledge, which includes both facts and skills, is a core indicator of intelligence <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib43" title="">43</a>]</cite>. Prior research shows that knowledge-intensive tasks can reliably evaluate the capabilities of LLMs <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib9" title="">9</a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib44" title="">44</a>]</cite>. For cyber-advisory LLM, we aim to assess not only its ability to retrieve known facts but also gauge its proficiency in a) <span class="ltx_text ltx_font_italic" id="S3.SS1.p1.1.2">using context to answer questions</span> and b) <span class="ltx_text ltx_font_italic" id="S3.SS1.p1.1.3">performing reasoning based on given some knowledge source</span>. To create a robust evaluation benchmark, we focus on the following critical abilities of LLMs in handling knowledge-intensive tasks:</p>
</div>
<div class="ltx_para" id="S3.SS1.p2">
<p class="ltx_p" id="S3.SS1.p2.1"><span class="ltx_text ltx_font_bold" id="S3.SS1.p2.1.1">Extraction:</span> Knowledge extraction tasks are crucial for measuring the ability of a language model to access its vast knowledge base and accurately recall specific facts <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib44" title="">44</a>]</cite>. As a cybersecurity advisor, an LLM could be asked to retrieve information on various security architectures, incidents, best practices, and historical data on known vulnerabilities. Accurate extraction ensures the LLM can provide reliable and precise information quickly, which is essential for addressing security concerns, preventing breaches, and supporting security professionals in their decision-making processes.</p>
</div>
<div class="ltx_para" id="S3.SS1.p3">
<p class="ltx_p" id="S3.SS1.p3.1"><span class="ltx_text ltx_font_bold" id="S3.SS1.p3.1.1">Understanding:</span> While knowledge extraction tasks focus on recalling information, knowledge understanding tasks are designed to assess the cognitive abilities of a model <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib45" title="">45</a>]</cite>. This involves evaluating the model’s capability to discern the truthfulness of statements and comprehend underlying knowledge within a given context. For instance, an LLM might be tested on its ability to interpret the accuracy of security issues described in a report, thereby demonstrating its grasp of complex cybersecurity concepts and scenarios. Effective understanding ensures that the LLM can accurately interpret and respond to nuanced security challenges.</p>
</div>
<div class="ltx_para" id="S3.SS1.p4">
<p class="ltx_p" id="S3.SS1.p4.1"><span class="ltx_text ltx_font_bold" id="S3.SS1.p4.1.1">Reasoning:</span> Knowledge reasoning tasks aim to evaluate the problem-solving capabilities of LLMs <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib46" title="">46</a>]</cite>. This is particularly important in the cyber-advisory role of LLMs, as they need to assist security professionals in reading, analyzing, and summarizing extensive and detailed threat reports. Effective reasoning enables the LLM to make informed recommendations, identify potential security risks, and suggest mitigation strategies based on the comprehensive analysis of the available data.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S3.SS2.5.1.1">III-B</span> </span><span class="ltx_text ltx_font_italic" id="S3.SS2.6.2">Data Sources and Tasks</span>
</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">Employing a proprietary LLM like ChatGPT-4 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib1" title="">1</a>]</cite> is now a research standard in generating evaluation benchmarks in long-form responses <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib9" title="">9</a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib47" title="">47</a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib48" title="">48</a>]</cite>. We utilize the more recent OpenAI’s ChatGPT-4o <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib49" title="">49</a>]</cite> in extracting our benchmark datasets, using suitable prompts. We also evaluate the quality of ChatGPT-4o output with human annotators to discard incorrect responses (annotation process and results discussed in Section <a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#S3.SS3" title="III-C Dataset Validation ‣ III Proposed Benchmark: SECURE ‣ SECURE: Benchmarking Large Language Models for Cybersecurity Advisory"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">III-C</span></span></a>). Below we explain the three different tasks of SECURE and various data sources:</p>
</div>
<figure class="ltx_table" id="S3.T1">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S3.T1.2.1.1" style="font-size:90%;">TABLE I</span>: </span><span class="ltx_text" id="S3.T1.3.2" style="font-size:90%;">Sample MCQs and Answers from MAET and CWET</span></figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S3.T1.4" style="width:433.6pt;height:59.6pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-149.9pt,20.6pt) scale(0.591254182985631,0.591254182985631) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S3.T1.4.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S3.T1.4.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S3.T1.4.1.1.1.1">URL</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S3.T1.4.1.1.1.2">Question</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S3.T1.4.1.1.1.3">Option A</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S3.T1.4.1.1.1.4">Option B</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S3.T1.4.1.1.1.5">Option C</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S3.T1.4.1.1.1.6">Option D</th>
<th class="ltx_td ltx_nopad_r ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S3.T1.4.1.1.1.7">Answer</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T1.4.1.2.1">
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T1.4.1.2.1.1"><a class="ltx_ref ltx_href" href="https://attack.mitre.org/techniques/T0848/" style="color:#0000FF;" title="">Link1</a></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T1.4.1.2.1.2">
<table class="ltx_tabular ltx_align_middle" id="S3.T1.4.1.2.1.2.1">
<tr class="ltx_tr" id="S3.T1.4.1.2.1.2.1.1">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S3.T1.4.1.2.1.2.1.1.1">What is a primary purpose of setting up</td>
</tr>
<tr class="ltx_tr" id="S3.T1.4.1.2.1.2.1.2">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S3.T1.4.1.2.1.2.1.2.1">a rogue master in an ICS environment?</td>
</tr>
</table>
</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T1.4.1.2.1.3">
<table class="ltx_tabular ltx_align_middle" id="S3.T1.4.1.2.1.3.1">
<tr class="ltx_tr" id="S3.T1.4.1.2.1.3.1.1">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S3.T1.4.1.2.1.3.1.1.1">Sending legitimate control</td>
</tr>
<tr class="ltx_tr" id="S3.T1.4.1.2.1.3.1.2">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S3.T1.4.1.2.1.3.1.2.1">messages to devices</td>
</tr>
</table>
</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T1.4.1.2.1.4">
<table class="ltx_tabular ltx_align_middle" id="S3.T1.4.1.2.1.4.1">
<tr class="ltx_tr" id="S3.T1.4.1.2.1.4.1.1">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S3.T1.4.1.2.1.4.1.1.1">Intercepting internal</td>
</tr>
<tr class="ltx_tr" id="S3.T1.4.1.2.1.4.1.2">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S3.T1.4.1.2.1.4.1.2.1">communications</td>
</tr>
</table>
</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T1.4.1.2.1.5">Encrypting network traffic</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T1.4.1.2.1.6">
<table class="ltx_tabular ltx_align_middle" id="S3.T1.4.1.2.1.6.1">
<tr class="ltx_tr" id="S3.T1.4.1.2.1.6.1.1">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S3.T1.4.1.2.1.6.1.1.1">Creating network</td>
</tr>
<tr class="ltx_tr" id="S3.T1.4.1.2.1.6.1.2">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S3.T1.4.1.2.1.6.1.2.1">segmentation</td>
</tr>
</table>
</td>
<td class="ltx_td ltx_nopad_r ltx_align_left ltx_border_t" id="S3.T1.4.1.2.1.7">A</td>
</tr>
<tr class="ltx_tr" id="S3.T1.4.1.3.2">
<td class="ltx_td ltx_align_left ltx_border_bb" id="S3.T1.4.1.3.2.1"><a class="ltx_ref ltx_href" href="https://attack.mitre.org/mitigations/M0924/" style="color:#0000FF;" title="">Link2</a></td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="S3.T1.4.1.3.2.2">
<table class="ltx_tabular ltx_align_middle" id="S3.T1.4.1.3.2.2.1">
<tr class="ltx_tr" id="S3.T1.4.1.3.2.2.1.1">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S3.T1.4.1.3.2.2.1.1.1">Which technique is addressed by</td>
</tr>
<tr class="ltx_tr" id="S3.T1.4.1.3.2.2.1.2">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S3.T1.4.1.3.2.2.1.2.1">restricting registry permissions in ICS?</td>
</tr>
</table>
</td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="S3.T1.4.1.3.2.3">Phishing</td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="S3.T1.4.1.3.2.4">Denial of Service</td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="S3.T1.4.1.3.2.5">
<table class="ltx_tabular ltx_align_middle" id="S3.T1.4.1.3.2.5.1">
<tr class="ltx_tr" id="S3.T1.4.1.3.2.5.1.1">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S3.T1.4.1.3.2.5.1.1.1">Unauthorized Registry</td>
</tr>
<tr class="ltx_tr" id="S3.T1.4.1.3.2.5.1.2">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S3.T1.4.1.3.2.5.1.2.1">Modifications</td>
</tr>
</table>
</td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="S3.T1.4.1.3.2.6">SQL Injection</td>
<td class="ltx_td ltx_nopad_r ltx_align_left ltx_border_bb" id="S3.T1.4.1.3.2.7">C</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<section class="ltx_subsubsection" id="S3.SS2.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span class="ltx_text" id="S3.SS2.SSS1.5.1.1">III-B</span>1 </span>Extraction Task</h4>
<div class="ltx_para" id="S3.SS2.SSS1.p1">
<p class="ltx_p" id="S3.SS2.SSS1.p1.1">We frame the knowledge extraction task as a multiple-choice question answering (MCQ) task. The model is expected to answer questions without any given context, relying solely on its memory or training data. For this purpose, we focus on the MITRE ATT&amp;CK <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib50" title="">50</a>]</cite> and CWE (Common Weakness Enumeration) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib14" title="">14</a>]</cite> websites to create two datasets: MAET (Mitre Attack Extraction Task) and CWET (Common Weakness Extraction Task). Specifically, we utilize the attack patterns for ICS <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib11" title="">11</a>]</cite> and mitigation plans for ICS <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib12" title="">12</a>]</cite> to generate the questions. For CWE, we utilize the weaknesses belonging to the class CWE-1358 “CWE VIEW: Weaknesses in SEI ETF Categories of Security Vulnerabilities in ICS” <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib14" title="">14</a>]</cite>, which enumerates all ICS-related security vulnerabilities.</p>
</div>
<div class="ltx_para" id="S3.SS2.SSS1.p2">
<p class="ltx_p" id="S3.SS2.SSS1.p2.1">We selected these resources due to their high relevance and quality in the domain of ICS cybersecurity. The MITRE ATT&amp;CK framework is a globally recognized repository of tactics and techniques based on real-world observations, making it an authoritative source for constructing a benchmark dataset <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib50" title="">50</a>]</cite>. Similarly, the CWE provides a community-developed list of software and hardware weaknesses that can become vulnerabilities, which is crucial for a comprehensive understanding of ICS security. The detailed and structured information from both MITRE ATT&amp;CK and CWE ensures that the generated questions cover fundamental concepts and advanced technical details pertinent to ICS security. Below is an example prompt used in generating the questions for the MAET and CWET tasks in Prompt A (shortened). Using such prompts, we extract a total of 2036 questions. These questions test both basic and advanced understanding of ICS cybersecurity, ensuring the robustness of SECURE in evaluating the knowledge-intensive tasks by the LLM.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.SSS1.p3">
<svg class="ltx_picture" height="73.34" id="S3.SS2.SSS1.p3.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,73.34) matrix(1 0 0 -1 0 0)"><g fill="#969696" fill-opacity="1.0"><path d="M 0 4.15 L 0 69.19 C 0 71.48 1.86 73.34 4.15 73.34 L 595.85 73.34 C 598.14 73.34 600 71.48 600 69.19 L 600 4.15 C 600 1.86 598.14 0 595.85 0 L 4.15 0 C 1.86 0 0 1.86 0 4.15 Z" style="stroke:none"></path></g><g fill="#E6E6E6" fill-opacity="1.0"><path d="M 0.69 4.15 L 0.69 69.19 C 0.69 71.1 2.24 72.64 4.15 72.64 L 595.85 72.64 C 597.76 72.64 599.31 71.1 599.31 69.19 L 599.31 4.15 C 599.31 2.24 597.76 0.69 595.85 0.69 L 4.15 0.69 C 2.24 0.69 0.69 2.24 0.69 4.15 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 7.61 6.23)"><foreignobject color="#000000" height="60.88" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="584.78">
<span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="S3.SS2.SSS1.p3.pic1.1.1.1.1.1" style="width:422.6pt;">
<span class="ltx_p" id="S3.SS2.SSS1.p3.pic1.1.1.1.1.1.1"><span class="ltx_text ltx_framed ltx_framed_underline" id="S3.SS2.SSS1.p3.pic1.1.1.1.1.1.1.1" style="font-size:80%;">Prompt A:</span><span class="ltx_text" id="S3.SS2.SSS1.p3.pic1.1.1.1.1.1.1.2" style="font-size:80%;"> From the following URL ’${URL}’, generate a set of MCQs (zero to five) for ‘novices’ and similarly for ‘experts’ with four possible answers each. … Return the output in CSV format (tab separated) for the responses with the following nine columns: URL, Level (Novice or Expert), Question, Option A, Option B, Option C, Option D, Correct Answer (A, B, C or D), Explanation…</span></span>
</span></foreignobject></g></g></svg>
</div>
<div class="ltx_para" id="S3.SS2.SSS1.p4">
<p class="ltx_p" id="S3.SS2.SSS1.p4.1"><span class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" id="S3.SS2.SSS1.p4.1.1">Use-case:</span> Knowledge extraction tasks measure the ability of a language model to access its vast knowledge base and accurately recall specific facts. This is useful when a cybersecurity professional has to find answers to a threat, system weakness, mitigation plans, attack patterns, and vulnerability given a specific attack scenario or just simply to gain information to assist the other tasks they are performing. LLMs are considered to be repositories of world knowledge with few-shot learning <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib51" title="">51</a>]</cite> and zero-shot reasoning <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib52" title="">52</a>]</cite> skills and hence are frequently inquired to obtain answers for different questions. MAET and CWET, both extraction tasks, consist of such questions that replicate this situation and evaluate if LLMs have sufficient knowledge in the ICS domain. Since state-of-the-art LLMs are trained on world knowledge and have seen documents on MITRE and CWE, such questions measure whether they can accurately recall answers to these kinds of questions.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S3.SS2.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span class="ltx_text" id="S3.SS2.SSS2.5.1.1">III-B</span>2 </span>Understanding Task</h4>
<div class="ltx_para" id="S3.SS2.SSS2.p1">
<p class="ltx_p" id="S3.SS2.SSS2.p1.1">Our second task dataset is designed to evaluate the ability of LLM to comprehend and understand the security-related text. Given the continuously evolving landscape of cybersecurity, it is crucial that LLMs can assimilate new information and use it to generate accurate responses. For this purpose, we utilize the CVEs (Common Vulnerabilities and Exposures) published in 2024, available at CVE project repository <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib13" title="">13</a>]</cite>. CVE is better for this task since they are always updated but CWEs are more appropriate for the extraction task as they are updated less frequently.</p>
</div>
<div class="ltx_para" id="S3.SS2.SSS2.p2">
<p class="ltx_p" id="S3.SS2.SSS2.p2.1">To ensure the integrity of our evaluation, we verified that none of the pretrained models we selected for evaluation (ChatGPT-4 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib1" title="">1</a>]</cite>, ChatGPT-3.5 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib18" title="">18</a>]</cite>, Llama3-70b <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib19" title="">19</a>]</cite>, Llama3-8b <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib20" title="">20</a>]</cite>, Gemini-Pro <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib21" title="">21</a>]</cite>, Mistral-7B <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib22" title="">22</a>]</cite> , Mixtral-8x7b <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib23" title="">23</a>]</cite>) had access to these CVEs during their training phase by confirming their training-cut-off date (See Table <a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#A0.T8" title="TABLE VIII ‣ -A Large Language Models ‣ SECURE: Benchmarking Large Language Models for Cybersecurity Advisory"><span class="ltx_text ltx_ref_tag">VIII</span></a>). This precaution guarantees that the models have not been exposed to this specific information and thus must rely on their comprehension abilities, and therefore, maintain the validity and reliability of SECURE.</p>
</div>
<div class="ltx_para" id="S3.SS2.SSS2.p3">
<p class="ltx_p" id="S3.SS2.SSS2.p3.1">We generate the KCV (Knowledge test on common vulnerabilities ) dataset, a series of boolean questions that require the LLMs to read the CVE descriptions provided in JSON format and determine whether the given statements are True or False based on the available information. This setup tests the models’ ability to accurately process and understand newly introduced data.</p>
</div>
<div class="ltx_para" id="S3.SS2.SSS2.p4">
<p class="ltx_p" id="S3.SS2.SSS2.p4.1">In addition, we created a supplementary dataset named VOOD (Vulnerability Out-of-Distribution task), which contains questions without relevant context to assess the model’s ability to recognize when it lacks sufficient information to answer a question. None of these questions could be answered truthfully without access to the discussed vulnerability. Ideally, the model should indicate its inability to answer in such cases.</p>
</div>
<div class="ltx_para" id="S3.SS2.SSS2.p5">
<p class="ltx_p" id="S3.SS2.SSS2.p5.1">For this task, we generated 466 boolean questions. This dataset serves as a robust benchmark for evaluating the comprehension capabilities of LLMs in cybersecurity, mainly focusing on their ability to adapt to and reason about newly encountered vulnerabilities.</p>
</div>
<div class="ltx_para" id="S3.SS2.SSS2.p6">
<p class="ltx_p" id="S3.SS2.SSS2.p6.1"><span class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" id="S3.SS2.SSS2.p6.1.1">Use-case:</span> Knowledge understanding tasks are designed to assess the model’s capability to discern the truthfulness of statements with and without a context. KCV evaluates whether existing LLMs can comprehend security documents, and answer questions based on a given context. VOOD inspects how the models perform when the context is not provided. Both of these tasks measure the reliability of LLMs. An effective understanding of cybersecurity can only ensure that the LLM can accurately interpret and respond to nuanced security challenges.</p>
</div>
<figure class="ltx_table" id="S3.T2">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S3.T2.2.1.1" style="font-size:90%;">TABLE II</span>: </span><span class="ltx_text" id="S3.T2.3.2" style="font-size:90%;">An example row from RERT dataset. Overview &amp; vulnerability description shortened for readability.</span></figcaption>
<div class="ltx_inline-block ltx_transformed_outer" id="S3.T2.4" style="width:433.6pt;height:65.1pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-221.1pt,33.2pt) scale(0.495077546566066,0.495077546566066) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S3.T2.4.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S3.T2.4.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S3.T2.4.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S3.T2.4.1.1.1.1.1">URL</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S3.T2.4.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S3.T2.4.1.1.1.2.1">Overview</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S3.T2.4.1.1.1.3"><span class="ltx_text ltx_font_bold" id="S3.T2.4.1.1.1.3.1">Vulnerability</span></th>
<th class="ltx_td ltx_nopad_r ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S3.T2.4.1.1.1.4"><span class="ltx_text ltx_font_bold" id="S3.T2.4.1.1.1.4.1">Risk Evaluation</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T2.4.1.2.1">
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" id="S3.T2.4.1.2.1.1"><a class="ltx_ref ltx_href" href="https://www.cisa.gov/news-events/ics-advisories/icsa-24-142-01" style="color:#0000FF;" title="">Link</a></td>
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" id="S3.T2.4.1.2.1.2">
<table class="ltx_tabular ltx_align_middle" id="S3.T2.4.1.2.1.2.1">
<tr class="ltx_tr" id="S3.T2.4.1.2.1.2.1.1">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S3.T2.4.1.2.1.2.1.1.1">Successful exploitation of this vulnerability could allow an attacker</td>
</tr>
<tr class="ltx_tr" id="S3.T2.4.1.2.1.2.1.2">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S3.T2.4.1.2.1.2.1.2.1">to inject arbitrary JavaScript into a user’s web browser for a single</td>
</tr>
<tr class="ltx_tr" id="S3.T2.4.1.2.1.2.1.3">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S3.T2.4.1.2.1.2.1.3.1">vulnerability, successful exploitation of these vulnerabilities could</td>
</tr>
<tr class="ltx_tr" id="S3.T2.4.1.2.1.2.1.4">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S3.T2.4.1.2.1.2.1.4.1">cause a denial of service, disclosure of sensitive information,</td>
</tr>
<tr class="ltx_tr" id="S3.T2.4.1.2.1.2.1.5">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S3.T2.4.1.2.1.2.1.5.1">communication loss, and modification of settings or ladder logic</td>
</tr>
<tr class="ltx_tr" id="S3.T2.4.1.2.1.2.1.6">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S3.T2.4.1.2.1.2.1.6.1">for multiple vulnerabilities.</td>
</tr>
</table>
</td>
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" id="S3.T2.4.1.2.1.3">
<table class="ltx_tabular ltx_align_middle" id="S3.T2.4.1.2.1.3.1">
<tr class="ltx_tr" id="S3.T2.4.1.2.1.3.1.1">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S3.T2.4.1.2.1.3.1.1.1">3.2.1 Path Traversal CWE-22 There are multiple ways in LAquis</td>
</tr>
<tr class="ltx_tr" id="S3.T2.4.1.2.1.3.1.2">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S3.T2.4.1.2.1.3.1.2.1">SCADA for an attacker to access locations outside of their own</td>
</tr>
<tr class="ltx_tr" id="S3.T2.4.1.2.1.3.1.3">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S3.T2.4.1.2.1.3.1.3.1">directory. CVE-2024-5040 has been assigned to this vulnerability.</td>
</tr>
<tr class="ltx_tr" id="S3.T2.4.1.2.1.3.1.4">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S3.T2.4.1.2.1.3.1.4.1">A CVSS v3.1 base score of 7.8 has been calculated;</td>
</tr>
</table>
</td>
<td class="ltx_td ltx_nopad_r ltx_align_left ltx_border_bb ltx_border_t" id="S3.T2.4.1.2.1.4">
<table class="ltx_tabular ltx_align_middle" id="S3.T2.4.1.2.1.4.1">
<tr class="ltx_tr" id="S3.T2.4.1.2.1.4.1.1">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S3.T2.4.1.2.1.4.1.1.1">Successful exploitation of this vulnerability could</td>
</tr>
<tr class="ltx_tr" id="S3.T2.4.1.2.1.4.1.2">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S3.T2.4.1.2.1.4.1.2.1">allow an attacker to read and write files outside</td>
</tr>
<tr class="ltx_tr" id="S3.T2.4.1.2.1.4.1.3">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S3.T2.4.1.2.1.4.1.3.1">of their own directory.</td>
</tr>
</table>
</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
<section class="ltx_subsubsection" id="S3.SS2.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span class="ltx_text" id="S3.SS2.SSS3.5.1.1">III-B</span>3 </span>Reasoning Task</h4>
<div class="ltx_para" id="S3.SS2.SSS3.p1">
<p class="ltx_p" id="S3.SS2.SSS3.p1.1">Our third task evaluates the LLM’s reasoning capability in the context of ICS security through the Risk Evaluation Reasoning Task (RERT). To create RERT, we compile a risk assessment dataset using cybersecurity advisories from the Cybersecurity and Infrastructure Security Agency (CISA) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib15" title="">15</a>]</cite>. We focus on all significant ICS-related advisory reports, each containing an <span class="ltx_text ltx_font_italic" id="S3.SS2.SSS3.p1.1.1">Executive Summary</span>, <span class="ltx_text ltx_font_italic" id="S3.SS2.SSS3.p1.1.2">Risk Evaluation</span>, <span class="ltx_text ltx_font_italic" id="S3.SS2.SSS3.p1.1.3">Technical Details</span> (including <span class="ltx_text ltx_font_italic" id="S3.SS2.SSS3.p1.1.4">Vulnerability Overview</span>, <span class="ltx_text ltx_font_italic" id="S3.SS2.SSS3.p1.1.5">Affected Products</span>, <span class="ltx_text ltx_font_italic" id="S3.SS2.SSS3.p1.1.6">Background Researcher</span>), and <span class="ltx_text ltx_font_italic" id="S3.SS2.SSS3.p1.1.7">Mitigations</span>. Reports lacking essential information are discarded to ensure data quality, and the remaining comprehensive reports are processed for inclusion.</p>
</div>
<div class="ltx_para" id="S3.SS2.SSS3.p2">
<p class="ltx_p" id="S3.SS2.SSS3.p2.1">The <span class="ltx_text ltx_font_italic" id="S3.SS2.SSS3.p2.1.1">Risk Evaluation</span> section of these advisories consistently summarizes the key risks associated with the identified vulnerabilities. This summary is presented in a specific format that can be inferred from the detailed vulnerability information, assuming a sufficient background in cybersecurity. As these reports are meticulously curated by security professionals, we treat their risk evaluations as gold standards, allowing us to accurately assess the performance of LLMs against the high benchmarks set by human experts.</p>
</div>
<div class="ltx_para" id="S3.SS2.SSS3.p3">
<p class="ltx_p" id="S3.SS2.SSS3.p3.1">Therefore, the task involves predicting the <span class="ltx_text ltx_font_italic" id="S3.SS2.SSS3.p3.1.1">Risk Evaluation</span> based on the provided vulnerability details. This setup allows us to gauge the LLM’s ability to understand and reason about complex ICS security scenarios. We compiled 1,000 samples from the most recent ICS advisories to construct this dataset, ensuring a robust and up-to-date benchmark for evaluation.</p>
</div>
<div class="ltx_para" id="S3.SS2.SSS3.p4">
<p class="ltx_p" id="S3.SS2.SSS3.p4.1">In addition, we create another dataset CPST (CVSS Problem Solving Task) to measure the problem-solving skills of LLMs in security. Specifically, we use the CVSS (Common Vulnerability Scoring System) framework and manually collect 100 unique CVSS3.1 vector strings from the Cybersecurity and Infrastructure Security Agency (CISA) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib15" title="">15</a>]</cite>. These scores, in the range of 0-10, can be computed using the CVSS calculator which uses the Base, Temporal, and Environmental scores to determine the overall severity of a vulnerability <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib53" title="">53</a>]</cite>. This task involves using an existing formula from CVSS3.1 standard and computing a value. This computation allows the evaluation of the problem-solving skills of LLMs in practical security settings.</p>
</div>
<div class="ltx_para" id="S3.SS2.SSS3.p5">
<p class="ltx_p" id="S3.SS2.SSS3.p5.1"><span class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" id="S3.SS2.SSS3.p5.1.1">Use-case:</span> LLMs are now integrated into emails and document software to summarize conversations and texts. Such LLMs work quite well in handling the general English language but summarizing a threat report is significantly different as the LLMs need to understand the technical details that consist of vulnerability, affected products, and risks. RERT dataset is designed to evaluate the ability of LLMs in summarizing an extensive threat report. The CVSS Problem Solving Task checks if LLMs can understand and use the CVSS formula without being explicitly programmed (zero-shot evaluation). While a simple program can do this deterministically, this task shows if LLMs can help in real-world scenarios where users might not know the formula. It shows LLMs’ ability to reason and solve problems, not just follow set rules.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S3.SS3.5.1.1">III-C</span> </span><span class="ltx_text ltx_font_italic" id="S3.SS3.6.2">Dataset Validation</span>
</h3>
<div class="ltx_para" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.1">To ensure the quality and validity of our evaluation datasets, we conducted a rigorous manual verification process for all generated questions. This process involved independent assessment by human annotators with expertise in computer security, specifically Masters or Ph.D. students in the field. Discrepancies between the human annotators’ labels and the original ground truth provided by ChatGPT-4o were resolved through adjudication by a second, more experienced annotator.</p>
</div>
<div class="ltx_para" id="S3.SS3.p2">
<p class="ltx_p" id="S3.SS3.p2.1">Our analysis revealed several categories of issues within the generated questions. Some questions were deemed unanswerable from the provided context, particularly within the True/False format. In the Multiple Choice Question (MCQ) format, we encountered instances where multiple answer choices were deemed correct. To maintain the integrity of our evaluation, we removed questions deemed unanswerable or exhibiting multiple correct answers from the dataset. Questions with identifiable issues that could be rectified were corrected accordingly. We fixed 13 questions in MAET, 0 in CWE and 22 questions in KCV. This manual verification and refinement process removed a small percentage of questions originally collected for each dataset. Specifically, we removed 2.9% of questions from the MAET dataset, 3.5% from the CWET dataset, and 6.9% from the KCV dataset, totaling 29, 36, and 32 questions respectively.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S3.SS4.5.1.1">III-D</span> </span><span class="ltx_text ltx_font_italic" id="S3.SS4.6.2">Benchmark Dataset and Evaluation</span>
</h3>
<div class="ltx_para" id="S3.SS4.p1">
<p class="ltx_p" id="S3.SS4.p1.1">Based on the modeling and task descriptions of Section <a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#S3.SS1" title="III-A Modeling ‣ III Proposed Benchmark: SECURE ‣ SECURE: Benchmarking Large Language Models for Cybersecurity Advisory"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">III-A</span></span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#S3.SS2" title="III-B Data Sources and Tasks ‣ III Proposed Benchmark: SECURE ‣ SECURE: Benchmarking Large Language Models for Cybersecurity Advisory"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">III-B</span></span></a>, we have created the following benchmark datasets:</p>
</div>
<div class="ltx_para" id="S3.SS4.p2">
<p class="ltx_p" id="S3.SS4.p2.1"><span class="ltx_text ltx_font_bold" id="S3.SS4.p2.1.1">Knowledge extraction dataset:</span> As detailed in Section <a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#S3.SS2.SSS1" title="III-B1 Extraction Task ‣ III-B Data Sources and Tasks ‣ III Proposed Benchmark: SECURE ‣ SECURE: Benchmarking Large Language Models for Cybersecurity Advisory"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">III-B</span>1</span></a>, these tasks are framed as MCQs derived from MITRE ATT&amp;CK and CWE websites. We have released two datasets: <span class="ltx_text ltx_font_bold" id="S3.SS4.p2.1.2">MAET</span> and <span class="ltx_text ltx_font_bold" id="S3.SS4.p2.1.3">CWET</span>, comprising a total of 2036 MCQs. We show a sample in Table <a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#S3.T1" title="TABLE I ‣ III-B Data Sources and Tasks ‣ III Proposed Benchmark: SECURE ‣ SECURE: Benchmarking Large Language Models for Cybersecurity Advisory"><span class="ltx_text ltx_ref_tag">I</span></a>. Different LLMs are evaluated based on their accuracy in predicting the correct answers from the provided options, allowing us to measure their effectiveness in knowledge extraction.</p>
</div>
<figure class="ltx_table" id="S3.T3">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S3.T3.2.1.1" style="font-size:90%;">TABLE III</span>: </span><span class="ltx_text" id="S3.T3.3.2" style="font-size:90%;">Sample from KCV and VOOD dataset</span></figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S3.T3.4" style="width:195.1pt;height:49pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-103.0pt,25.9pt) scale(0.486534465191629,0.486534465191629) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S3.T3.4.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S3.T3.4.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S3.T3.4.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S3.T3.4.1.1.1.1.1">CVE-ID</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S3.T3.4.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S3.T3.4.1.1.1.2.1">Question</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S3.T3.4.1.1.1.3"><span class="ltx_text ltx_font_bold" id="S3.T3.4.1.1.1.3.1">Answer</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T3.4.1.2.1">
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T3.4.1.2.1.1">CVE-2024-0011</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T3.4.1.2.1.2">
<table class="ltx_tabular ltx_align_middle" id="S3.T3.4.1.2.1.2.1">
<tr class="ltx_tr" id="S3.T3.4.1.2.1.2.1.1">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S3.T3.4.1.2.1.2.1.1.1">The vulnerability described in CVE-2024-0011 allows</td>
</tr>
<tr class="ltx_tr" id="S3.T3.4.1.2.1.2.1.2">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S3.T3.4.1.2.1.2.1.2.1">for the execution of arbitrary code on the affected system.</td>
</tr>
</table>
</td>
<td class="ltx_td ltx_nopad_r ltx_align_right ltx_border_t" id="S3.T3.4.1.2.1.3">FALSE</td>
</tr>
<tr class="ltx_tr" id="S3.T3.4.1.3.2">
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" id="S3.T3.4.1.3.2.1">CVE-2024-0017</td>
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" id="S3.T3.4.1.3.2.2">
<table class="ltx_tabular ltx_align_middle" id="S3.T3.4.1.3.2.2.1">
<tr class="ltx_tr" id="S3.T3.4.1.3.2.2.1.1">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S3.T3.4.1.3.2.2.1.1.1">User interaction is required for the exploitation of the</td>
</tr>
<tr class="ltx_tr" id="S3.T3.4.1.3.2.2.1.2">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S3.T3.4.1.3.2.2.1.2.1">CVE-2024-0017 vulnerability.</td>
</tr>
</table>
</td>
<td class="ltx_td ltx_nopad_r ltx_align_right ltx_border_bb ltx_border_t" id="S3.T3.4.1.3.2.3">TRUE</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div class="ltx_para" id="S3.SS4.p3">
<p class="ltx_p" id="S3.SS4.p3.1"><span class="ltx_text ltx_font_bold" id="S3.SS4.p3.1.1">Knowledge understanding dataset:</span> As explained in Section <a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#S3.SS2.SSS2" title="III-B2 Understanding Task ‣ III-B Data Sources and Tasks ‣ III Proposed Benchmark: SECURE ‣ SECURE: Benchmarking Large Language Models for Cybersecurity Advisory"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">III-B</span>2</span></a>, we utilize CVE published in 2024 to create this boolean dataset. There are two variants: <span class="ltx_text ltx_font_bold" id="S3.SS4.p3.1.2">KCV</span>, which includes the context from CVE JSON files, and <span class="ltx_text ltx_font_bold" id="S3.SS4.p3.1.3">VOOD</span>, which lacks this context to assess the out-of-distribution performance of LLMs. Each dataset contains 466 Boolean questions. Along with the questions and answers, we also provide the JSON files used as context for evaluating the LLM’s comprehension abilities. A sample is shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#S3.T3" title="TABLE III ‣ III-D Benchmark Dataset and Evaluation ‣ III Proposed Benchmark: SECURE ‣ SECURE: Benchmarking Large Language Models for Cybersecurity Advisory"><span class="ltx_text ltx_ref_tag">III</span></a>. Different LLM models are evaluated based on their accuracy in predicting the truthfulness of statements, both with and without context.</p>
</div>
<figure class="ltx_table" id="S3.T4">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S3.T4.2.1.1" style="font-size:90%;">TABLE IV</span>: </span><span class="ltx_text" id="S3.T4.3.2" style="font-size:90%;">Sample from CPST dataset</span></figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S3.T4.4" style="width:151.8pt;height:73.4pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(1.4pt,-0.7pt) scale(1.01877847473738,1.01877847473738) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S3.T4.4.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S3.T4.4.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S3.T4.4.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S3.T4.4.1.1.1.1.1" style="font-size:50%;">CVSS v3 Vector String</span></th>
<th class="ltx_td ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T4.4.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S3.T4.4.1.1.1.2.1" style="font-size:50%;">Correct Answer</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T4.4.1.2.1">
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T4.4.1.2.1.1"><span class="ltx_text" id="S3.T4.4.1.2.1.1.1" style="font-size:50%;">AV:L/AC:L/PR:N/UI:R/S:U/C:H/I:H/A:H</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" id="S3.T4.4.1.2.1.2"><span class="ltx_text" id="S3.T4.4.1.2.1.2.1" style="font-size:50%;">7.8</span></td>
</tr>
<tr class="ltx_tr" id="S3.T4.4.1.3.2">
<td class="ltx_td ltx_align_left" id="S3.T4.4.1.3.2.1"><span class="ltx_text" id="S3.T4.4.1.3.2.1.1" style="font-size:50%;">AV:N/AC:H/PR:N/UI:R/S:C/C:L/I:L/A:N</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T4.4.1.3.2.2"><span class="ltx_text" id="S3.T4.4.1.3.2.2.1" style="font-size:50%;">4.7</span></td>
</tr>
<tr class="ltx_tr" id="S3.T4.4.1.4.3">
<td class="ltx_td ltx_align_left ltx_border_bb" id="S3.T4.4.1.4.3.1"><span class="ltx_text" id="S3.T4.4.1.4.3.1.1" style="font-size:50%;">AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb" id="S3.T4.4.1.4.3.2"><span class="ltx_text" id="S3.T4.4.1.4.3.2.1" style="font-size:50%;">9.8</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div class="ltx_para" id="S3.SS4.p4">
<p class="ltx_p" id="S3.SS4.p4.1"><span class="ltx_text ltx_font_bold" id="S3.SS4.p4.1.1">Knowledge reasoning dataset:</span> We have released <span class="ltx_text ltx_font_bold" id="S3.SS4.p4.1.2">RERT</span>, a dataset consisting of 1000 questions based on security advisories from CISA, as detailed in Section <a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#S3.SS2.SSS3" title="III-B3 Reasoning Task ‣ III-B Data Sources and Tasks ‣ III Proposed Benchmark: SECURE ‣ SECURE: Benchmarking Large Language Models for Cybersecurity Advisory"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">III-B</span>3</span></a>. We show a sample in Table <a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#S3.T2" title="TABLE II ‣ III-B2 Understanding Task ‣ III-B Data Sources and Tasks ‣ III Proposed Benchmark: SECURE ‣ SECURE: Benchmarking Large Language Models for Cybersecurity Advisory"><span class="ltx_text ltx_ref_tag">II</span></a>. Different LLM models are evaluated using the ROGUE-L metric <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib54" title="">54</a>]</cite> between the LLM-generated response and the ground truth. Additionally, we have released <span class="ltx_text ltx_font_bold" id="S3.SS4.p4.1.3">CPST</span>, which includes 100 manually crafted CVSS3.1 vector strings along with their associated vulnerability scores. A sample of these is provided in Table <a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#S3.T4" title="TABLE IV ‣ III-D Benchmark Dataset and Evaluation ‣ III Proposed Benchmark: SECURE ‣ SECURE: Benchmarking Large Language Models for Cybersecurity Advisory"><span class="ltx_text ltx_ref_tag">IV</span></a>. LLM models are evaluated using the mean average deviation (MAD) against the ground-truth scores, assessing their accuracy in generating precise vulnerability assessments.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">IV </span><span class="ltx_text ltx_font_smallcaps" id="S4.1.1">Experiments &amp; Results</span>
</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">We evaluate 7 state-of-the-art LLMs varying in parameter size, organization, and access (See Appendix <a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#A0.SS1" title="-A Large Language Models ‣ SECURE: Benchmarking Large Language Models for Cybersecurity Advisory"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">-A</span></span></a> and Table <a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#A0.T8" title="TABLE VIII ‣ -A Large Language Models ‣ SECURE: Benchmarking Large Language Models for Cybersecurity Advisory"><span class="ltx_text ltx_ref_tag">VIII</span></a> for detail and comparative summary). We pick both open-source and closed models based on LLM leaderboards (ChatArena <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib55" title="">55</a>]</cite>). Open-source models allow the download of full model weights whereas closed models provide an API for restricted access. We evaluate our benchmark against the following models:</p>
</div>
<div class="ltx_para" id="S4.p2">
<p class="ltx_p" id="S4.p2.1"><span class="ltx_text ltx_font_bold" id="S4.p2.1.1">Open-source models:</span> Llama3-70B <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib19" title="">19</a>]</cite>, Llama3-8B <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib20" title="">20</a>]</cite>, Mistral-7B <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib22" title="">22</a>]</cite>, Mixtral-8x7b <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib23" title="">23</a>]</cite></p>
</div>
<div class="ltx_para" id="S4.p3">
<p class="ltx_p" id="S4.p3.1"><span class="ltx_text ltx_font_bold" id="S4.p3.1.1">Closed-source models:</span> ChatGPT-3.5 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib18" title="">18</a>]</cite>, ChatGPT-4 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib1" title="">1</a>]</cite>, Gemini-Pro (v1.5) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib21" title="">21</a>]</cite></p>
</div>
<figure class="ltx_table" id="S4.T5">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T5.12.3.1" style="font-size:90%;">TABLE V</span>: </span><span class="ltx_text" id="S4.T5.4.2" style="font-size:90%;">Result of different models on our benchmark tasks. <math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T5.3.1.m1.1"><semantics id="S4.T5.3.1.m1.1b"><mo id="S4.T5.3.1.m1.1.1" stretchy="false" xref="S4.T5.3.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T5.3.1.m1.1c"><ci id="S4.T5.3.1.m1.1.1.cmml" xref="S4.T5.3.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.3.1.m1.1d">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T5.3.1.m1.1e">↑</annotation></semantics></math>-<math alttext="\downarrow" class="ltx_Math" display="inline" id="S4.T5.4.2.m2.1"><semantics id="S4.T5.4.2.m2.1b"><mo id="S4.T5.4.2.m2.1.1" stretchy="false" xref="S4.T5.4.2.m2.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T5.4.2.m2.1c"><ci id="S4.T5.4.2.m2.1.1.cmml" xref="S4.T5.4.2.m2.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.4.2.m2.1d">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S4.T5.4.2.m2.1e">↓</annotation></semantics></math> indicate higher-lower values are better.</span></figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S4.T5.10" style="width:368.6pt;height:92.5pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-102.5pt,25.7pt) scale(0.642621471036823,0.642621471036823) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T5.10.6">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T5.10.6.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt" id="S4.T5.10.6.6.7"><span class="ltx_text ltx_font_bold" id="S4.T5.10.6.6.7.1">Model</span></th>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T5.5.1.1.1"><span class="ltx_text ltx_font_bold" id="S4.T5.5.1.1.1.1">MAET (Acc <math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T5.5.1.1.1.1.m1.1"><semantics id="S4.T5.5.1.1.1.1.m1.1a"><mo id="S4.T5.5.1.1.1.1.m1.1.1" stretchy="false" xref="S4.T5.5.1.1.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T5.5.1.1.1.1.m1.1b"><ci id="S4.T5.5.1.1.1.1.m1.1.1.cmml" xref="S4.T5.5.1.1.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.5.1.1.1.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T5.5.1.1.1.1.m1.1d">↑</annotation></semantics></math>)</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T5.6.2.2.2"><span class="ltx_text ltx_font_bold" id="S4.T5.6.2.2.2.1">CWET (Acc <math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T5.6.2.2.2.1.m1.1"><semantics id="S4.T5.6.2.2.2.1.m1.1a"><mo id="S4.T5.6.2.2.2.1.m1.1.1" stretchy="false" xref="S4.T5.6.2.2.2.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T5.6.2.2.2.1.m1.1b"><ci id="S4.T5.6.2.2.2.1.m1.1.1.cmml" xref="S4.T5.6.2.2.2.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.6.2.2.2.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T5.6.2.2.2.1.m1.1d">↑</annotation></semantics></math>)</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T5.7.3.3.3"><span class="ltx_text ltx_font_bold" id="S4.T5.7.3.3.3.1">KCV (Acc<math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T5.7.3.3.3.1.m1.1"><semantics id="S4.T5.7.3.3.3.1.m1.1a"><mo id="S4.T5.7.3.3.3.1.m1.1.1" stretchy="false" xref="S4.T5.7.3.3.3.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T5.7.3.3.3.1.m1.1b"><ci id="S4.T5.7.3.3.3.1.m1.1.1.cmml" xref="S4.T5.7.3.3.3.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.7.3.3.3.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T5.7.3.3.3.1.m1.1d">↑</annotation></semantics></math>)</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T5.8.4.4.4"><span class="ltx_text ltx_font_bold" id="S4.T5.8.4.4.4.1">VOOD (OOD-Acc<math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T5.8.4.4.4.1.m1.1"><semantics id="S4.T5.8.4.4.4.1.m1.1a"><mo id="S4.T5.8.4.4.4.1.m1.1.1" stretchy="false" xref="S4.T5.8.4.4.4.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T5.8.4.4.4.1.m1.1b"><ci id="S4.T5.8.4.4.4.1.m1.1.1.cmml" xref="S4.T5.8.4.4.4.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.8.4.4.4.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T5.8.4.4.4.1.m1.1d">↑</annotation></semantics></math>)</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T5.9.5.5.5"><span class="ltx_text ltx_font_bold" id="S4.T5.9.5.5.5.1">RERT (ROGUE-L<math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T5.9.5.5.5.1.m1.1"><semantics id="S4.T5.9.5.5.5.1.m1.1a"><mo id="S4.T5.9.5.5.5.1.m1.1.1" stretchy="false" xref="S4.T5.9.5.5.5.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T5.9.5.5.5.1.m1.1b"><ci id="S4.T5.9.5.5.5.1.m1.1.1.cmml" xref="S4.T5.9.5.5.5.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.9.5.5.5.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T5.9.5.5.5.1.m1.1d">↑</annotation></semantics></math>)</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_tt" id="S4.T5.10.6.6.6"><span class="ltx_text ltx_font_bold" id="S4.T5.10.6.6.6.1">CPST (MAD<math alttext="\downarrow" class="ltx_Math" display="inline" id="S4.T5.10.6.6.6.1.m1.1"><semantics id="S4.T5.10.6.6.6.1.m1.1a"><mo id="S4.T5.10.6.6.6.1.m1.1.1" stretchy="false" xref="S4.T5.10.6.6.6.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T5.10.6.6.6.1.m1.1b"><ci id="S4.T5.10.6.6.6.1.m1.1.1.cmml" xref="S4.T5.10.6.6.6.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.10.6.6.6.1.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S4.T5.10.6.6.6.1.m1.1d">↓</annotation></semantics></math>)</span></td>
</tr>
<tr class="ltx_tr" id="S4.T5.10.6.7.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T5.10.6.7.1.1">ChatGPT-4</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.10.6.7.1.2"><span class="ltx_text ltx_font_bold" id="S4.T5.10.6.7.1.2.1">88.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.10.6.7.1.3"><span class="ltx_text ltx_font_italic" id="S4.T5.10.6.7.1.3.1">89.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.10.6.7.1.4"><span class="ltx_text ltx_font_bold" id="S4.T5.10.6.7.1.4.1">87.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.10.6.7.1.5"><span class="ltx_text ltx_font_bold" id="S4.T5.10.6.7.1.5.1">87.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.10.6.7.1.6">0.53</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" id="S4.T5.10.6.7.1.7"><span class="ltx_text ltx_font_bold" id="S4.T5.10.6.7.1.7.1">0.81</span></td>
</tr>
<tr class="ltx_tr" id="S4.T5.10.6.8.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T5.10.6.8.2.1">ChatGPT-3.5</th>
<td class="ltx_td ltx_align_center" id="S4.T5.10.6.8.2.2">82.8</td>
<td class="ltx_td ltx_align_center" id="S4.T5.10.6.8.2.3">84.2</td>
<td class="ltx_td ltx_align_center" id="S4.T5.10.6.8.2.4">78.3</td>
<td class="ltx_td ltx_align_center" id="S4.T5.10.6.8.2.5">8.4</td>
<td class="ltx_td ltx_align_center" id="S4.T5.10.6.8.2.6">0.48</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T5.10.6.8.2.7">1.26</td>
</tr>
<tr class="ltx_tr" id="S4.T5.10.6.9.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T5.10.6.9.3.1">Gemini-Pro</th>
<td class="ltx_td ltx_align_center" id="S4.T5.10.6.9.3.2"><span class="ltx_text ltx_font_italic" id="S4.T5.10.6.9.3.2.1">86.2</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.10.6.9.3.3">87.8</td>
<td class="ltx_td ltx_align_center" id="S4.T5.10.6.9.3.4">83.5</td>
<td class="ltx_td ltx_align_center" id="S4.T5.10.6.9.3.5">86.7</td>
<td class="ltx_td ltx_align_center" id="S4.T5.10.6.9.3.6"><span class="ltx_text ltx_font_bold" id="S4.T5.10.6.9.3.6.1">0.54</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T5.10.6.9.3.7"><span class="ltx_text ltx_font_italic" id="S4.T5.10.6.9.3.7.1">1.0</span></td>
</tr>
<tr class="ltx_tr" id="S4.T5.10.6.10.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T5.10.6.10.4.1">Llama3-70B</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.10.6.10.4.2">86.3</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.10.6.10.4.3"><span class="ltx_text ltx_font_bold" id="S4.T5.10.6.10.4.3.1">90.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.10.6.10.4.4"><span class="ltx_text ltx_font_italic" id="S4.T5.10.6.10.4.4.1">85.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.10.6.10.4.5">27.1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.10.6.10.4.6">0.51</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" id="S4.T5.10.6.10.4.7">1.54</td>
</tr>
<tr class="ltx_tr" id="S4.T5.10.6.11.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T5.10.6.11.5.1">Llama3-8B</th>
<td class="ltx_td ltx_align_center" id="S4.T5.10.6.11.5.2">82.1</td>
<td class="ltx_td ltx_align_center" id="S4.T5.10.6.11.5.3">83.9</td>
<td class="ltx_td ltx_align_center" id="S4.T5.10.6.11.5.4">82.8</td>
<td class="ltx_td ltx_align_center" id="S4.T5.10.6.11.5.5">56.4</td>
<td class="ltx_td ltx_align_center" id="S4.T5.10.6.11.5.6">0.48</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T5.10.6.11.5.7">1.77</td>
</tr>
<tr class="ltx_tr" id="S4.T5.10.6.12.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T5.10.6.12.6.1">Mistral-7B</th>
<td class="ltx_td ltx_align_center" id="S4.T5.10.6.12.6.2">77.9</td>
<td class="ltx_td ltx_align_center" id="S4.T5.10.6.12.6.3">80.1</td>
<td class="ltx_td ltx_align_center" id="S4.T5.10.6.12.6.4">64.2</td>
<td class="ltx_td ltx_align_center" id="S4.T5.10.6.12.6.5">57.1</td>
<td class="ltx_td ltx_align_center" id="S4.T5.10.6.12.6.6">0.42</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T5.10.6.12.6.7">1.82</td>
</tr>
<tr class="ltx_tr" id="S4.T5.10.6.13.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S4.T5.10.6.13.7.1">Mixtral-8x7B</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T5.10.6.13.7.2">80.9</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T5.10.6.13.7.3">83.4</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T5.10.6.13.7.4">79.6</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T5.10.6.13.7.5">69.3</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T5.10.6.13.7.6">0.39</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb" id="S4.T5.10.6.13.7.7">1.63</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S4.SS1.5.1.1">IV-A</span> </span><span class="ltx_text ltx_font_italic" id="S4.SS1.6.2">Prompting Strategy for Evaluation</span>
</h3>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">We use consistent prompt engineering approach to ensure uniformity across different LLMs. Instead of customizing prompts for each model, we employed a single prompt structure per task type that produced responses in the required format.</p>
</div>
<div class="ltx_para" id="S4.SS1.p2">
<p class="ltx_p" id="S4.SS1.p2.1"><span class="ltx_text ltx_font_bold" id="S4.SS1.p2.1.1">Example Prompt (MCQ Tasks: MAET and CWET)</span>: <span class="ltx_text ltx_font_typewriter" id="S4.SS1.p2.1.2" style="font-size:90%;background-color:#EBEBEB;"> For the given question: Which protocol function can be disabled to prevent unauthorized device shutdowns?, and four options: A) DNP3 0x0D, B) HTTP GET, C) SMTP HELO, or D) FTP LIST, pick the best option as the answer, and return as either A, B, C or D. If you do not know the answer, return X. Choose the appropriate letter from A, B, C, D, or X as your answer. Please provide only the letter corresponding to your choice without any additional text or explanations.</span></p>
</div>
<div class="ltx_para" id="S4.SS1.p3">
<p class="ltx_p" id="S4.SS1.p3.1">We embedded relevant information from the JSON files directly within the prompt for the KCV task, which requires external knowledge. To maintain compatibility with model input constraints and avoid exceeding maximum token limits, we selectively included questions whose prompt length, including the embedded knowledge, did not exceed 5000 words. Although the models generally followed the specified output format, there were instances where responses deviated slightly from the instructions. In such cases, we manually corrected the outputs for accurate evaluation. We include all prompts we used to generate the responses in our dataset for reproducibility, and demonstrate more examples in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#A0.SS3" title="-C Prompt templates for evaluation ‣ SECURE: Benchmarking Large Language Models for Cybersecurity Advisory"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">-C</span></span></a>.</p>
</div>
<div class="ltx_para" id="S4.SS1.p4">
<p class="ltx_p" id="S4.SS1.p4.1"><span class="ltx_text ltx_font_bold" id="S4.SS1.p4.1.1">Temperature Setting</span>: LLM temperature influences the output of language models by adjusting the randomness or predictability of generated text. A higher temperature results in more creative but potentially less coherent outputs, as the model is more likely to choose less probable words. Conversely, a lower temperature makes the output more deterministic and predictable, often resulting in repetitive and conservative responses. Typically set between 0 and 1, the temperature modifies the probability distribution of the next word in a sequence. We use the default temperature parameter (set at 0.7) for all evaluation prompts.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S4.SS2.5.1.1">IV-B</span> </span><span class="ltx_text ltx_font_italic" id="S4.SS2.6.2">Evaluation Metrics</span>
</h3>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">We employ a range of evaluation metrics tailored to the specific nature of each task within our benchmarking framework: accuracy for <span class="ltx_text ltx_font_bold" id="S4.SS2.p1.1.1">MAET</span>, <span class="ltx_text ltx_font_bold" id="S4.SS2.p1.1.2">CWET</span>, <span class="ltx_text ltx_font_bold" id="S4.SS2.p1.1.3">VOOD</span> and <span class="ltx_text ltx_font_bold" id="S4.SS2.p1.1.4">KCV</span>, ROGUE-L <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib54" title="">54</a>]</cite> for <span class="ltx_text ltx_font_bold" id="S4.SS2.p1.1.5">RERT</span> and mean absolute deviation (MAD) for <span class="ltx_text ltx_font_bold" id="S4.SS2.p1.1.6">CPST</span>. Because of the page-limit, we explain the metrics in detail in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#A0.SS2" title="-B Evaluation Metrics ‣ SECURE: Benchmarking Large Language Models for Cybersecurity Advisory"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">-B</span></span></a>.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S4.SS3.5.1.1">IV-C</span> </span><span class="ltx_text ltx_font_italic" id="S4.SS3.6.2">Results Summary</span>
</h3>
<div class="ltx_para" id="S4.SS3.p1">
<p class="ltx_p" id="S4.SS3.p1.1">Table <a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#S4.T5" title="TABLE V ‣ IV Experiments &amp; Results ‣ SECURE: Benchmarking Large Language Models for Cybersecurity Advisory"><span class="ltx_text ltx_ref_tag">V</span></a> presents a comparative summary of the performance of various language models (LLMs) evaluated across the six benchmark tasks of SECURE. Our analysis reveals a consistent trend of closed-source models, particularly ChatGPT-4 and Gemini-Pro, exhibiting superior performance across most tasks.</p>
</div>
<div class="ltx_para" id="S4.SS3.p2">
<p class="ltx_p" id="S4.SS3.p2.1">ChatGPT-4 emerges as the top performer, achieving the highest scores on four key metrics: accuracy in MAET (88.6%), KCV (87.6%), and VOOD (87.9%), as well as the lowest mean absolute deviation on CPST (0.81). These results underscore ChatGPT-4’s robust capabilities in handling a variety of tasks, including out-of-distribution detection and complex problem-solving scenarios. Gemini-Pro closely trails ChatGPT-4, achieving comparable results on most tasks and slightly outperforming it on the summarization task based on the ROUGE-L metric. While ChatGPT-3.5 shows decent overall performance, it struggles significantly on the VOOD task, with an accuracy of only 8.4%.</p>
</div>
<div class="ltx_para" id="S4.SS3.p3">
<p class="ltx_p" id="S4.SS3.p3.1">Among the open-source models evaluated, Llama3-70B stands out due to its higher model capacity, consistently demonstrating superior performance. It achieves results comparable to ChatGPT-4 and even surpasses it on the CWET task. However, its subpar performance on the VOOD task indicates a potential weakness in handling out-of-domain scenarios. In contrast, models such as Llama3-8B, Mistral-7B, and Mixtral-8x7B exhibit moderate performance levels across the evaluated tasks.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">V </span><span class="ltx_text ltx_font_smallcaps" id="S5.1.1">Discussion &amp; Analysis</span>
</h2>
<section class="ltx_subsection" id="S5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S5.SS1.5.1.1">V-A</span> </span><span class="ltx_text ltx_font_italic" id="S5.SS1.6.2">Error Analysis</span>
</h3>
<div class="ltx_para" id="S5.SS1.p1">
<p class="ltx_p" id="S5.SS1.p1.1">In this section, we analyze the incorrect responses of LLMs on some representative examples to understand their shortcomings.</p>
</div>
<div class="ltx_para" id="S5.SS1.p2">
<p class="ltx_p" id="S5.SS1.p2.1">Q1. <span class="ltx_text ltx_font_typewriter" id="S5.SS1.p2.1.1" style="font-size:90%;background-color:#EBEBEB;">What is the primary purpose of setting up a rogue master in an ICS environment? A) Sending legitimate control messages to devices, B) Intercepting internal communications, C) Encrypting network traffic, and D) Creating network segmentation.</span></p>
</div>
<div class="ltx_para" id="S5.SS1.p3">
<p class="ltx_p" id="S5.SS1.p3.1">The correct answer for this question is <span class="ltx_text ltx_font_italic" id="S5.SS1.p3.1.1">A) Sending legitimate control messages to devices</span>. However, among all the LLMs evaluated, only ChatGPT-4 provided the correct response. This discrepancy might be due to the LLMs difficulty in recognizing the malicious intent embedded in the term “legitimate control messages”. The positive sentiment associated with the word “legitimate” could have misled the models, causing them to overlook the actual malicious purpose.</p>
</div>
<div class="ltx_para" id="S5.SS1.p4">
<p class="ltx_p" id="S5.SS1.p4.1">Q2. <span class="ltx_text ltx_font_typewriter" id="S5.SS1.p4.1.1" style="font-size:90%;background-color:#EBEBEB;">What is the main vulnerability exploited in CAPEC-477? A) Incorrect hashing algorithm, B) Incorrect data storage structure, C) Mixing signed and unsigned content, D) Weak encryption</span></p>
</div>
<div class="ltx_para" id="S5.SS1.p5">
<p class="ltx_p" id="S5.SS1.p5.1">The correct answer for this question is <span class="ltx_text ltx_font_italic" id="S5.SS1.p5.1.1">C) Mixing signed and unsigned content</span>. Only ChatGPT-4 and Llama3-70B managed to answer correctly. This might be because options A, B, and D explicitly mention common vulnerability types, which could have led the models to favor these options over the correct one. The subtlety of mixing signed and unsigned content as a specific vulnerability might have been less recognizable to the other LLMs.</p>
</div>
<div class="ltx_para" id="S5.SS1.p6">
<p class="ltx_p" id="S5.SS1.p6.1">Q3. <span class="ltx_text ltx_font_typewriter" id="S5.SS1.p6.1.1" style="font-size:90%;background-color:#EBEBEB;">State whether this statement is True or False given the JSON file as context (Source<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note"><span class="ltx_text ltx_font_serif" id="footnote1.1.1.1" style="font-size:111%;">1</span></span><a class="ltx_ref ltx_url" href="https://github.com/CVEProject/cvelistV5/blob/main/cves/2024/36xxx/CVE-2024-36039.json" style="font-size:111%;" title="">https://github.com/CVEProject/cvelistV5/blob/main/cves/2024/36xxx/CVE-2024-36039.json</a></span></span></span>): The CVE-2024-36039 vulnerability is caused by improper escaping of JSON values when using PyMySQL. Answer: F</span></p>
</div>
<div class="ltx_para" id="S5.SS1.p7">
<p class="ltx_p" id="S5.SS1.p7.1">All LLMs incorrectly answered this statement as True. The JSON file clearly states that the vulnerability is due to improper escaping of JSON keys, not values. This indicates that the models failed to differentiate between JSON values and keys within the given context. Such nuanced distinctions are crucial for accurate comprehension and response, highlighting a significant area for improvement in the models’ contextual understanding and attention to detail.</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S5.SS2.5.1.1">V-B</span> </span><span class="ltx_text ltx_font_italic" id="S5.SS2.6.2">Impact of Confidence on LLM Accuracy</span>
</h3>
<div class="ltx_para" id="S5.SS2.p1">
<p class="ltx_p" id="S5.SS2.p1.1">Prior studies have demonstrated that large language models (LLMs) can be calibrated through self-reflection or confidence analysis <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib56" title="">56</a>]</cite>. In this study, we evaluate the relationship between model confidence and performance across different confidence levels using the CWET task. Specifically, we measure the confidence of two representative LLMs, ChatGPT-4 and Llama3-70B, across five temperature settings: 0.6, 0.7, 0.8, 0.9, and 1.0, to obtain a more robust confidence estimate.</p>
</div>
<div class="ltx_para" id="S5.SS2.p2">
<p class="ltx_p" id="S5.SS2.p2.1">The LLMs were prompted to provide both their answers and the probability that their answers were correct (ranging from 0% to 100%), formatted as follows: <span class="ltx_text ltx_font_typewriter" id="S5.SS2.p2.1.1" style="font-size:90%;background-color:#EBEBEB;">‘‘Provide your answer and the probability that the answer is correct (0% to 100%) separated by a space.’’</span> We then averaged the confidence scores provided by the LLMs across the different temperatures. The accuracy of the models was plotted against five different confidence bins, as shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#S5.F3" title="Figure 3 ‣ V-B Impact of Confidence on LLM Accuracy ‣ V Discussion &amp; Analysis ‣ SECURE: Benchmarking Large Language Models for Cybersecurity Advisory"><span class="ltx_text ltx_ref_tag">3</span></a>.</p>
</div>
<div class="ltx_para" id="S5.SS2.p3">
<p class="ltx_p" id="S5.SS2.p3.1">The results indicate a clear trend: as confidence decreases, so does accuracy, particularly within the lowest confidence bins. Furthermore, ChatGPT-4 consistently exhibits higher confidence scores than Llama3.
These findings suggest that different LLMs may necessitate tailored calibration techniques to effectively mitigate incorrect responses. Specifically, while both models show a correlation between confidence and accuracy, the disparity in their confidence levels highlights the need for model-specific calibration. Future research could explore more sophisticated self-reflection and confidence estimation techniques to further improve the reliability and accuracy of LLMs in the cyber advisory tasks.</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS2.p4">
<svg class="ltx_picture" height="40.13" id="S5.SS2.p4.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,40.13) matrix(1 0 0 -1 0 0)"><g fill="#969696" fill-opacity="1.0"><path d="M 0 4.15 L 0 35.98 C 0 38.27 1.86 40.13 4.15 40.13 L 595.85 40.13 C 598.14 40.13 600 38.27 600 35.98 L 600 4.15 C 600 1.86 598.14 0 595.85 0 L 4.15 0 C 1.86 0 0 1.86 0 4.15 Z" style="stroke:none"></path></g><g fill="#E6E6E6" fill-opacity="1.0"><path d="M 0.69 4.15 L 0.69 35.98 C 0.69 37.89 2.24 39.44 4.15 39.44 L 595.85 39.44 C 597.76 39.44 599.31 37.89 599.31 35.98 L 599.31 4.15 C 599.31 2.24 597.76 0.69 595.85 0.69 L 4.15 0.69 C 2.24 0.69 0.69 2.24 0.69 4.15 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 7.61 6.23)"><foreignobject color="#000000" height="27.67" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="584.78">
<span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="S5.SS2.p4.pic1.1.1.1.1.1" style="width:422.6pt;">
<span class="ltx_p" id="S5.SS2.p4.pic1.1.1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S5.SS2.p4.pic1.1.1.1.1.1.1.1" style="font-size:90%;">Finding: <span class="ltx_text ltx_font_medium" id="S5.SS2.p4.pic1.1.1.1.1.1.1.1.1"> Responses from various LLMs with lower confidence levels tend to be less accurate, and different LLMs exhibit varying degrees of confidence, impacting their overall reliability.</span></span></span>
</span></foreignobject></g></g></svg>
</div>
<figure class="ltx_figure" id="S5.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="216" id="S5.F3.g1" src="extracted/5866847/figures/confidence.png" width="503"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S5.F3.2.1.1" style="font-size:90%;">Figure 3</span>: </span><span class="ltx_text" id="S5.F3.3.2" style="font-size:90%;">Confidence vs. Accuracy of LLMs</span></figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S5.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S5.SS3.5.1.1">V-C</span> </span><span class="ltx_text ltx_font_italic" id="S5.SS3.6.2">Open vs. Closed Model Performance</span>
</h3>
<div class="ltx_para" id="S5.SS3.p1">
<p class="ltx_p" id="S5.SS3.p1.1">This section analyzes the performance disparity between open-source and closed-source LLMs utilized in our study. Figure <a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#S5.F4" title="Figure 4 ‣ V-C Open vs. Closed Model Performance ‣ V Discussion &amp; Analysis ‣ SECURE: Benchmarking Large Language Models for Cybersecurity Advisory"><span class="ltx_text ltx_ref_tag">4</span></a> presents a comparative analysis showcasing the peak performance achieved by the three closed LLMs (ChatGPT-3.5, ChatGPT-4, and Gemini-Pro) and the remaining four open-source LLMs.</p>
</div>
<div class="ltx_para" id="S5.SS3.p2">
<p class="ltx_p" id="S5.SS3.p2.1">Our analysis reveals a consistent trend of closed-source models outperforming their open-source counterparts across most tasks. ChatGPT-4 demonstrates superior performance across all tasks except CWET, where Llama3-70B achieves marginally better results. While the performance difference remains relatively small for MAET, CWET, KCV, and RERT tasks, it becomes more pronounced in VOOD and CPST.</p>
</div>
<div class="ltx_para" id="S5.SS3.p3">
<p class="ltx_p" id="S5.SS3.p3.1">The superior performance of ChatGPT-4 and Gemini-Pro on VOOD (Out-of-Distribution Detection) suggests the implementation of more robust safeguarding mechanisms within these models. This observation is particularly evident in the substantial performance difference between ChatGPT-4 and ChatGPT-3.5, highlighting significant advancements in out-of-distribution detection capabilities. Closed models also exhibit significantly better performance on the CPST task, indicating a higher proficiency in problem-solving related to CVSS score calculation.</p>
</div>
<figure class="ltx_figure" id="S5.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="269" id="S5.F4.g1" src="extracted/5866847/figures/open-closed.png" width="359"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S5.F4.2.1.1" style="font-size:90%;">Figure 4</span>: </span><span class="ltx_text" id="S5.F4.3.2" style="font-size:90%;">Performance Comparison of Open-Source and Closed-Source LLMs Across Different Tasks (Note: For CPST, lower scores indicate better performance).</span></figcaption>
</figure>
<div class="ltx_para" id="S5.SS3.p4">
<p class="ltx_p" id="S5.SS3.p4.1">However, these safeguarding features, while crucial for enhancing security, may inadvertently hinder analysis by restricting access to crucial cyber threat intelligence. This limitation was particularly pronounced when working with the Gemini model. Specifically, during the RERT summarization task, the API refused 319 out of 1000 queries, deeming them potentially harmful due to their inclusion of vulnerability information. This finding raises a critical question: how can we strike a balance between robust security measures and the necessary access to sensitive information for effective cybersecurity research and practice?</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS3.p5">
<svg class="ltx_picture" height="57.96" id="S5.SS3.p5.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,57.96) matrix(1 0 0 -1 0 0)"><g fill="#969696" fill-opacity="1.0"><path d="M 0 4.15 L 0 53.81 C 0 56.1 1.86 57.96 4.15 57.96 L 595.85 57.96 C 598.14 57.96 600 56.1 600 53.81 L 600 4.15 C 600 1.86 598.14 0 595.85 0 L 4.15 0 C 1.86 0 0 1.86 0 4.15 Z" style="stroke:none"></path></g><g fill="#E6E6E6" fill-opacity="1.0"><path d="M 0.69 4.15 L 0.69 53.81 C 0.69 55.72 2.24 57.27 4.15 57.27 L 595.85 57.27 C 597.76 57.27 599.31 55.72 599.31 53.81 L 599.31 4.15 C 599.31 2.24 597.76 0.69 595.85 0.69 L 4.15 0.69 C 2.24 0.69 0.69 2.24 0.69 4.15 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 7.61 6.23)"><foreignobject color="#000000" height="45.51" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="584.78">
<span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="S5.SS3.p5.pic1.1.1.1.1.1" style="width:422.6pt;">
<span class="ltx_p" id="S5.SS3.p5.pic1.1.1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S5.SS3.p5.pic1.1.1.1.1.1.1.1">Finding: </span> The performance difference between open and closed models is negligible except for problem-solving or out-of-distribution tasks, where closed LLMs yield better results due to more strict safeguarding.</span>
</span></foreignobject></g></g></svg>
</div>
</section>
<section class="ltx_subsection" id="S5.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S5.SS4.5.1.1">V-D</span> </span><span class="ltx_text ltx_font_italic" id="S5.SS4.6.2">Evaluating Reasoning Abilities</span>
</h3>
<figure class="ltx_figure" id="S5.F5"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="187" id="S5.F5.g1" src="extracted/5866847/figures/reasoning.png" width="449"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S5.F5.2.1.1" style="font-size:90%;">Figure 5</span>: </span><span class="ltx_text" id="S5.F5.3.2" style="font-size:90%;">Performance of LLMs when asked to perform step-by-step analysis</span></figcaption>
</figure>
<figure class="ltx_figure" id="S5.F6"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="187" id="S5.F6.g1" src="extracted/5866847/figures/reasoning-timing.png" width="449"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S5.F6.2.1.1" style="font-size:90%;">Figure 6</span>: </span><span class="ltx_text" id="S5.F6.3.2" style="font-size:90%;">Inference time on reasoning tasks when asked to perform step-by-step analysis</span></figcaption>
</figure>
<div class="ltx_para" id="S5.SS4.p1">
<p class="ltx_p" id="S5.SS4.p1.1">We further evaluate LLMs’ reasoning capabilities on KCV and CPST by asking the model to perform step-by-step analysis to arrive at the result. For both tasks, we modify the prompt to include the sentence: <span class="ltx_text ltx_font_typewriter" id="S5.SS4.p1.1.1" style="font-size:90%;background-color:#EBEBEB;">Provide a detailed explanation of how you arrived at the answer.</span></p>
</div>
<div class="ltx_para" id="S5.SS4.p2">
<p class="ltx_p" id="S5.SS4.p2.1">We assess the performance of the ChatGPT-4 and Llama3-70B models on these tasks. The performance results are illustrated in Figure <a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#S5.F5" title="Figure 5 ‣ V-D Evaluating Reasoning Abilities ‣ V Discussion &amp; Analysis ‣ SECURE: Benchmarking Large Language Models for Cybersecurity Advisory"><span class="ltx_text ltx_ref_tag">5</span></a>. As shown, explicit instructions for providing explanations enhance performance on both tasks for these models. For the KCV task, the relative improvement in accuracy with reasoning is 2.52% for ChatGPT-4 and 4.43% for Llama3-70B. For the CPST task, the relative improvement in the Mean Absolute Deviation (MAD) score with reasoning is 20.99% for ChatGPT-4 and 14.29% for Llama3-70B compared to the baseline.</p>
</div>
<div class="ltx_para" id="S5.SS4.p3">
<p class="ltx_p" id="S5.SS4.p3.1">However, this advantage comes with a caveat. Requiring models to provide detailed reasoning steps can increase inference time, as illustrated in Figure <a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#S5.F6" title="Figure 6 ‣ V-D Evaluating Reasoning Abilities ‣ V Discussion &amp; Analysis ‣ SECURE: Benchmarking Large Language Models for Cybersecurity Advisory"><span class="ltx_text ltx_ref_tag">6</span></a>. The figure demonstrates that the time increase can be substantial depending on the specific task, as much as 35 times compared to the base task for CPST. This potential for elevated inference time translates to additional computational costs, highlighting a crucial trade-off between enhanced reasoning capabilities and computational expenses.</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS4.p4">
<svg class="ltx_picture" height="54.17" id="S5.SS4.p4.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,54.17) matrix(1 0 0 -1 0 0)"><g fill="#969696" fill-opacity="1.0"><path d="M 0 4.15 L 0 50.02 C 0 52.31 1.86 54.17 4.15 54.17 L 595.85 54.17 C 598.14 54.17 600 52.31 600 50.02 L 600 4.15 C 600 1.86 598.14 0 595.85 0 L 4.15 0 C 1.86 0 0 1.86 0 4.15 Z" style="stroke:none"></path></g><g fill="#E6E6E6" fill-opacity="1.0"><path d="M 0.69 4.15 L 0.69 50.02 C 0.69 51.93 2.24 53.48 4.15 53.48 L 595.85 53.48 C 597.76 53.48 599.31 51.93 599.31 50.02 L 599.31 4.15 C 599.31 2.24 597.76 0.69 595.85 0.69 L 4.15 0.69 C 2.24 0.69 0.69 2.24 0.69 4.15 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 7.61 6.23)"><foreignobject color="#000000" height="41.72" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="584.78">
<span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="S5.SS4.p4.pic1.1.1.1.1.1" style="width:422.6pt;">
<span class="ltx_p" id="S5.SS4.p4.pic1.1.1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S5.SS4.p4.pic1.1.1.1.1.1.1.1">Finding: </span> Explicitly asking LLMs for explanations or details about their reasoning steps to solve a task can yield significant performance gains but usually comes at a higher computational budget.</span>
</span></foreignobject></g></g></svg>
</div>
</section>
<section class="ltx_subsection" id="S5.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S5.SS5.5.1.1">V-E</span> </span><span class="ltx_text ltx_font_italic" id="S5.SS5.6.2">Variance in Prediction</span>
</h3>
<figure class="ltx_figure" id="S5.F7"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="234" id="S5.F7.g1" src="extracted/5866847/figures/variance.png" width="389"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S5.F7.2.1.1" style="font-size:90%;">Figure 7</span>: </span><span class="ltx_text" id="S5.F7.3.2" style="font-size:90%;">Distribution of variance among predictions for different LLMs</span></figcaption>
</figure>
<div class="ltx_para" id="S5.SS5.p1">
<p class="ltx_p" id="S5.SS5.p1.1">Figure <a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#S5.F7" title="Figure 7 ‣ V-E Variance in Prediction ‣ V Discussion &amp; Analysis ‣ SECURE: Benchmarking Large Language Models for Cybersecurity Advisory"><span class="ltx_text ltx_ref_tag">7</span></a> presents a comparative analysis of response variance across different LLMs on the CPST task. This task, requiring a real-number output, is well-suited for distribution analysis. We evaluated each model’s responses over five runs, utilizing their default temperature settings. The standard deviation of scores across these runs was calculated for each model, and the resulting distributions are visualized in the violin plot. The visualization reveals a trend: smaller models, such as Llama3-8b and Mistral-7b, tend towards wider variance, suggesting more significant variability in their responses. An exception is Mixtral-8x7b, which exhibits more deterministic behavior despite its smaller size. Larger models generally exhibit minor variance, indicating more stable outputs. However, ChatGPT-4 displays a slightly higher variance than Gemini-Pro and Llama3-70b on this specific task.</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS6">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S5.SS6.5.1.1">V-F</span> </span><span class="ltx_text ltx_font_italic" id="S5.SS6.6.2">Model Agreement Bias</span>
</h3>
<figure class="ltx_figure" id="S5.F8">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S5.F8.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="449" id="S5.F8.sf1.g1" src="extracted/5866847/figures/bias-no-context.png" width="598"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S5.F8.sf1.2.1.1" style="font-size:90%;">(a)</span> </span><span class="ltx_text" id="S5.F8.sf1.3.2" style="font-size:90%;">No context</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S5.F8.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="449" id="S5.F8.sf2.g1" src="extracted/5866847/figures/bias-context.png" width="598"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S5.F8.sf2.2.1.1" style="font-size:90%;">(b)</span> </span><span class="ltx_text" id="S5.F8.sf2.3.2" style="font-size:90%;">With context</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S5.F8.2.1.1" style="font-size:90%;">Figure 8</span>: </span><span class="ltx_text" id="S5.F8.3.2" style="font-size:90%;">Fraction of incorrect prediction with no context and context</span></figcaption>
</figure>
<div class="ltx_para" id="S5.SS6.p1">
<p class="ltx_p" id="S5.SS6.p1.1">This section investigates the tendency of LLMs to exhibit agreement bias when presented with factual statements within the context of cyber advisory. Specifically, we analyze the KCV and VOOD tasks, both of which assess the model’s ability to correctly classify a given statement as true or false. The distinction between KCV and VOOD lies in the provision of contextual information. While both tasks utilize the same set of statements, KCV provides additional context relevant to the statement, whereas VOOD presents the statements in isolation. This design allows us to examine how the presence or absence of context influences the model’s susceptibility to agreement bias.</p>
</div>
<div class="ltx_para" id="S5.SS6.p2">
<p class="ltx_p" id="S5.SS6.p2.1">Figure <a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#S5.F8" title="Figure 8 ‣ V-F Model Agreement Bias ‣ V Discussion &amp; Analysis ‣ SECURE: Benchmarking Large Language Models for Cybersecurity Advisory"><span class="ltx_text ltx_ref_tag">8</span></a> illustrates the distribution of incorrect predictions for both tasks, categorized by whether the LLM agreed (predicted True) or disagreed (predicted False) with the statement. In VOOD, most errors stem from the LLMs agreeing with the statement, even though the statements related to vulnerabilities were not in their training data. This tendency to affirm novel information suggests a potential for hallucination, where the model generates plausible-sounding but unsubstantiated claims <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib57" title="">57</a>]</cite>. It is also possible that the models are incorrectly associating information from known CVEs to newer, unseen vulnerabilities.</p>
</div>
<div class="ltx_para" id="S5.SS6.p3">
<p class="ltx_p" id="S5.SS6.p3.1">Conversely, the KCV task, where context is provided, exhibits a higher proportion of errors arising from the LLMs disagreeing with the statement. This pattern indicates a potential limitation in the models’ ability to effectively leverage the provided context for accurate information retrieval and association.</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS6.p4">
<svg class="ltx_picture" height="40.13" id="S5.SS6.p4.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,40.13) matrix(1 0 0 -1 0 0)"><g fill="#969696" fill-opacity="1.0"><path d="M 0 4.15 L 0 35.98 C 0 38.27 1.86 40.13 4.15 40.13 L 595.85 40.13 C 598.14 40.13 600 38.27 600 35.98 L 600 4.15 C 600 1.86 598.14 0 595.85 0 L 4.15 0 C 1.86 0 0 1.86 0 4.15 Z" style="stroke:none"></path></g><g fill="#E6E6E6" fill-opacity="1.0"><path d="M 0.69 4.15 L 0.69 35.98 C 0.69 37.89 2.24 39.44 4.15 39.44 L 595.85 39.44 C 597.76 39.44 599.31 37.89 599.31 35.98 L 599.31 4.15 C 599.31 2.24 597.76 0.69 595.85 0.69 L 4.15 0.69 C 2.24 0.69 0.69 2.24 0.69 4.15 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 7.61 6.23)"><foreignobject color="#000000" height="27.67" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="584.78">
<span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="S5.SS6.p4.pic1.1.1.1.1.1" style="width:422.6pt;">
<span class="ltx_p" id="S5.SS6.p4.pic1.1.1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S5.SS6.p4.pic1.1.1.1.1.1.1.1" style="font-size:90%;">Finding: <span class="ltx_text ltx_font_medium" id="S5.SS6.p4.pic1.1.1.1.1.1.1.1.1"> LLMs can hallucinate information when they lack up-to-date information and may fail to infer correct responses even when context is included.</span></span></span>
</span></foreignobject></g></g></svg>
</div>
</section>
<section class="ltx_subsection" id="S5.SS7">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S5.SS7.5.1.1">V-G</span> </span><span class="ltx_text ltx_font_italic" id="S5.SS7.6.2">Task Correlation Analysis</span>
</h3>
<div class="ltx_para" id="S5.SS7.p1">
<p class="ltx_p" id="S5.SS7.p1.1">To understand the relationships between the different tasks in the SECURE benchmark, we conducted a Spearman rank correlation analysis. The results, visualized in Figure <a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#S5.F9" title="Figure 9 ‣ V-G Task Correlation Analysis ‣ V Discussion &amp; Analysis ‣ SECURE: Benchmarking Large Language Models for Cybersecurity Advisory"><span class="ltx_text ltx_ref_tag">9</span></a>, reveal interesting insights into the inter-task dependencies. The heatmap shows that most tasks exhibit a moderate to strong positive correlation revealing some inherent relationship between knowledge required for different tasks. For example, the knowledge extraction tasks (MAET) shows notable correlations with other reasoning tasks (CPST, RERT) and comprehension tasks (KCV). This indicates that high-level tasks like reasoning and comprehension also rely on memorized knowledge acquired during model training. As expected, the lowest correlation is between VOOD and other tasks as VOOD task is crafted to evaluate out-of-distribution capabilities of LLMs.</p>
</div>
<figure class="ltx_figure" id="S5.F9"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="287" id="S5.F9.g1" src="extracted/5866847/figures/spearman.png" width="359"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S5.F9.2.1.1" style="font-size:90%;">Figure 9</span>: </span><span class="ltx_text" id="S5.F9.3.2" style="font-size:90%;">Spearman correlation between different tasks in SECURE benchmark</span></figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S5.SS7.p2">
<svg class="ltx_picture" height="40.13" id="S5.SS7.p2.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,40.13) matrix(1 0 0 -1 0 0)"><g fill="#969696" fill-opacity="1.0"><path d="M 0 4.15 L 0 35.98 C 0 38.27 1.86 40.13 4.15 40.13 L 595.85 40.13 C 598.14 40.13 600 38.27 600 35.98 L 600 4.15 C 600 1.86 598.14 0 595.85 0 L 4.15 0 C 1.86 0 0 1.86 0 4.15 Z" style="stroke:none"></path></g><g fill="#E6E6E6" fill-opacity="1.0"><path d="M 0.69 4.15 L 0.69 35.98 C 0.69 37.89 2.24 39.44 4.15 39.44 L 595.85 39.44 C 597.76 39.44 599.31 37.89 599.31 35.98 L 599.31 4.15 C 599.31 2.24 597.76 0.69 595.85 0.69 L 4.15 0.69 C 2.24 0.69 0.69 2.24 0.69 4.15 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 7.61 6.23)"><foreignobject color="#000000" height="27.67" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="584.78">
<span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="S5.SS7.p2.pic1.1.1.1.1.1" style="width:422.6pt;">
<span class="ltx_p" id="S5.SS7.p2.pic1.1.1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S5.SS7.p2.pic1.1.1.1.1.1.1.1" style="font-size:90%;">Finding: <span class="ltx_text ltx_font_medium" id="S5.SS7.p2.pic1.1.1.1.1.1.1.1.1"> Different tasks in SECURE exhibit strong inter-task correlations, suggesting that performance gains in one task may also beneficially impact others.</span></span></span>
</span></foreignobject></g></g></svg>
</div>
</section>
<section class="ltx_subsection" id="S5.SS8">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S5.SS8.5.1.1">V-H</span> </span><span class="ltx_text ltx_font_italic" id="S5.SS8.6.2">LLM Performance Across Expertise Levels</span>
</h3>
<figure class="ltx_figure" id="S5.F10"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="243" id="S5.F10.g1" src="extracted/5866847/figures/task-level.png" width="389"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S5.F10.2.1.1" style="font-size:90%;">Figure 10</span>: </span><span class="ltx_text" id="S5.F10.3.2" style="font-size:90%;">Performance comparison of LLMs across two different levels of question difficulty.</span></figcaption>
</figure>
<div class="ltx_para" id="S5.SS8.p1">
<p class="ltx_p" id="S5.SS8.p1.1">During the question generation phase for the Multiple Choice Question (MCQ) and Boolean tasks, we developed distinct question sets reflecting two levels of expertise: expert (5+ years of experience in security) and novice (1-2 years of experience in security). The focus of the questions were on ‘fundamental concepts’ for ‘novices’ and ‘advanced technical details, problem-solving skills, and implications’ for ‘experts’. This section analyzes the performance variations observed across these expertise levels.</p>
</div>
<div class="ltx_para" id="S5.SS8.p2">
<p class="ltx_p" id="S5.SS8.p2.1">Figure <a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#S5.F10" title="Figure 10 ‣ V-H LLM Performance Across Expertise Levels ‣ V Discussion &amp; Analysis ‣ SECURE: Benchmarking Large Language Models for Cybersecurity Advisory"><span class="ltx_text ltx_ref_tag">10</span></a> presents the average accuracy of all evaluated LLMs on the CWET and KCV tasks. Notably, LLMs demonstrate marginally superior performance on the “expert” questions for the CWET task, showing an improvement of 2.31% compared to the “novice” security questions. This suggests that LLMs can leverage their extensive training data to excel even in specialized cybersecurity domains for tasks primarily reliant on existing knowledge and pattern recognition. However, as discussed in Section <a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#S5.SS1" title="V-A Error Analysis ‣ V Discussion &amp; Analysis ‣ SECURE: Benchmarking Large Language Models for Cybersecurity Advisory"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">V-A</span></span></a>, they often fail to retrieve the correct source for more factual questions.</p>
</div>
<div class="ltx_para" id="S5.SS8.p3">
<p class="ltx_p" id="S5.SS8.p3.1">In contrast, the KCV task, which requires integrating new information and context-aware reasoning, reveals a different trend. Here, LLMs experience a significant decrease in accuracy, with a 5.44% drop for “expert” tasks compared to “novice” tasks. This finding underscores a potential limitation of LLMs: while proficient at utilizing pre-existing knowledge, their capability to effectively incorporate and reason with novel information, particularly in complex and dynamic fields like cybersecurity, necessitates further investigation and refinement.</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS9">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S5.SS9.5.1.1">V-I</span> </span><span class="ltx_text ltx_font_italic" id="S5.SS9.6.2">Human Benchmark</span>
</h3>
<div class="ltx_para" id="S5.SS9.p1">
<p class="ltx_p" id="S5.SS9.p1.1">We conducted an experiment involving human subjects where participants were asked to answer a subset of the SECURE benchmark questions. 7 PhD students and 7 industry professionals working in cybersecurity and threat intelligence with years of experience ranging from 2-10 years were participants of this study.</p>
</div>
<div class="ltx_para" id="S5.SS9.p2">
<p class="ltx_p" id="S5.SS9.p2.1">We provided an MCQ form to each participant consisting of 75 questions from MAET, CWET, and KCV datasets divided into three sets, and were asked to provide their answers. We also collected their confidence level (high or low) when providing the answers and the total time taken for each set. Table <a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#S5.T6" title="TABLE VI ‣ V-I Human Benchmark ‣ V Discussion &amp; Analysis ‣ SECURE: Benchmarking Large Language Models for Cybersecurity Advisory"><span class="ltx_text ltx_ref_tag">VI</span></a> shows the average performance of the human subjects on the dataset. Comparing the results with Table <a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#S4.T5" title="TABLE V ‣ IV Experiments &amp; Results ‣ SECURE: Benchmarking Large Language Models for Cybersecurity Advisory"><span class="ltx_text ltx_ref_tag">V</span></a>, we can observe that large language models outperform human subjects on the three tasks. Most participants considered KCV a difficult task as it involves CVE document analysis before validating or refuting the given statement. On average, PhD students scored higher accuracy than industry professionals. While analysts scored an average accuracy of 72.2% accuracy on all tasks, PhD students scored 77.3% accuracy.</p>
</div>
<figure class="ltx_table" id="S5.T6">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S5.T6.2.1.1" style="font-size:90%;">TABLE VI</span>: </span><span class="ltx_text" id="S5.T6.3.2" style="font-size:90%;">Average performance of human subjects on the subset of SECURE benchmark</span></figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S5.T6.4" style="width:173.4pt;height:36pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-86.8pt,18.0pt) scale(0.499721671343579,0.499721671343579) ;">
<table class="ltx_tabular ltx_align_middle" id="S5.T6.4.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T6.4.1.1.1">
<td class="ltx_td ltx_align_left ltx_border_tt" id="S5.T6.4.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S5.T6.4.1.1.1.1.1">Dataset</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T6.4.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S5.T6.4.1.1.1.2.1">Accuracy (Average)</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T6.4.1.1.1.3"><span class="ltx_text ltx_font_bold" id="S5.T6.4.1.1.1.3.1">Confidence (Average)</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_tt" id="S5.T6.4.1.1.1.4"><span class="ltx_text ltx_font_bold" id="S5.T6.4.1.1.1.4.1">Average time (mins)</span></td>
</tr>
<tr class="ltx_tr" id="S5.T6.4.1.2.2">
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T6.4.1.2.2.1">MAET</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T6.4.1.2.2.2">77%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T6.4.1.2.2.3">76%</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T6.4.1.2.2.4">25</td>
</tr>
<tr class="ltx_tr" id="S5.T6.4.1.3.3">
<td class="ltx_td ltx_align_left" id="S5.T6.4.1.3.3.1">CWET</td>
<td class="ltx_td ltx_align_center" id="S5.T6.4.1.3.3.2">78%</td>
<td class="ltx_td ltx_align_center" id="S5.T6.4.1.3.3.3">81%</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S5.T6.4.1.3.3.4">23</td>
</tr>
<tr class="ltx_tr" id="S5.T6.4.1.4.4">
<td class="ltx_td ltx_align_left ltx_border_bb" id="S5.T6.4.1.4.4.1">KCV</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T6.4.1.4.4.2">68%</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T6.4.1.4.4.3">72%</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb" id="S5.T6.4.1.4.4.4">30</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
<section class="ltx_subsection" id="S5.SS10">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S5.SS10.5.1.1">V-J</span> </span><span class="ltx_text ltx_font_italic" id="S5.SS10.6.2">Recommendations</span>
</h3>
<div class="ltx_para" id="S5.SS10.p1">
<p class="ltx_p" id="S5.SS10.p1.1">Based on our findings from the analysis of LLMs on the SECURE benchmark, we provide the following targeted recommendations specifically designed to enhance ICS security:</p>
<ol class="ltx_enumerate" id="S5.I1">
<li class="ltx_item" id="S5.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="S5.I1.i1.p1">
<p class="ltx_p" id="S5.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S5.I1.i1.p1.1.1">Confidence Calibration and Monitoring:</span> Implement robust mechanisms to monitor and adjust the confidence levels of LLMs when responding to sector-related queries. In ICS environments, inaccurate responses can have severe consequences.</p>
</div>
</li>
<li class="ltx_item" id="S5.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="S5.I1.i2.p1">
<p class="ltx_p" id="S5.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S5.I1.i2.p1.1.1">Model Selection:</span> Unless open-source models demonstrate improved performance, prioritize the use of closed-source LLMs for problem-solving or out-of-distribution tasks (unless cost is a concern). These models have demonstrated superior performance in handling complex and unfamiliar scenarios.</p>
</div>
</li>
<li class="ltx_item" id="S5.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span>
<div class="ltx_para" id="S5.I1.i3.p1">
<p class="ltx_p" id="S5.I1.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S5.I1.i3.p1.1.1">Encourage Detailed Explanations:</span> Require LLMs to provide detailed explanations or reasoning steps for their responses to security issues. This transparency not only improves trust but also allows human operators to understand the model’s decision-making process. Implement this strategy where detailed insights are critical for accurate and informed decision-making.</p>
</div>
</li>
<li class="ltx_item" id="S5.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span>
<div class="ltx_para" id="S5.I1.i4.p1">
<p class="ltx_p" id="S5.I1.i4.p1.1"><span class="ltx_text ltx_font_bold" id="S5.I1.i4.p1.1.1">Addressing Hallucinations:</span> Integrate a human-in-the-loop process to review and validate LLM responses before implementation. This step is crucial to mitigate the risk of hallucinations, ensuring that the information and recommendations provided are reliable and actionable. This approach is especially important in environments where incorrect data can lead to significant operational disruptions or safety hazards.</p>
</div>
</li>
<li class="ltx_item" id="S5.I1.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">5.</span>
<div class="ltx_para" id="S5.I1.i5.p1">
<p class="ltx_p" id="S5.I1.i5.p1.1"><span class="ltx_text ltx_font_bold" id="S5.I1.i5.p1.1.1">Improving Contextual Understanding:</span> Enhance LLMs’ ability to interpret and respond accurately by improving their understanding of sector-specific terminology and scenarios. This can be achieved through better context framing and providing comprehensive background information relevant to the sector.</p>
</div>
</li>
</ol>
</div>
</section>
<section class="ltx_subsection" id="S5.SS11">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S5.SS11.5.1.1">V-K</span> </span><span class="ltx_text ltx_font_italic" id="S5.SS11.6.2">Ethical concerns</span>
</h3>
<div class="ltx_para" id="S5.SS11.p1">
<p class="ltx_p" id="S5.SS11.p1.1">All of the evaluation tasks in our proposed benchmark SECURE use publicly available threat information from credible sources like MITRE <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib11" title="">11</a>]</cite> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib12" title="">12</a>]</cite>, CVE <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib13" title="">13</a>]</cite>, CWE <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib14" title="">14</a>]</cite>, and Cybersecurity and Infrastructure Security Agency (CISA) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib15" title="">15</a>]</cite>. None of the datasets contain any personal information, and they do not make sensitive judgments on social issues for bias, deception, or discrimination.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VI </span><span class="ltx_text ltx_font_smallcaps" id="S6.1.1">Customized LLMs</span>
</h2>
<section class="ltx_subsection" id="S6.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S6.SS1.5.1.1">VI-A</span> </span><span class="ltx_text ltx_font_italic" id="S6.SS1.6.2">Retrieval Augmented Generation</span>
</h3>
<div class="ltx_para" id="S6.SS1.p1">
<p class="ltx_p" id="S6.SS1.p1.1">Retrieval Augmented Generation (RAG) is a method that combines the strengths of retrieval based models and generation based models <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib58" title="">58</a>]</cite>. It consists of two major components: <span class="ltx_text ltx_font_italic" id="S6.SS1.p1.1.1">retriever and generator</span>. The retriever searches for relevant information from a large database or knowledge base, using retrieval techniques to find the most relevant documents, paragraphs, or data points. Once relevant information is retrieved, the generator component (typically a language model like GPT) uses this information as context to generate a more accurate and contextually relevant response.</p>
</div>
<figure class="ltx_figure" id="S6.F11"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="227" id="S6.F11.g1" src="extracted/5866847/figures/asdfadf.png" width="538"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S6.F11.2.1.1" style="font-size:90%;">Figure 11</span>: </span><span class="ltx_text" id="S6.F11.3.2" style="font-size:90%;">RAG Model</span></figcaption>
</figure>
<div class="ltx_para" id="S6.SS1.p2">
<p class="ltx_p" id="S6.SS1.p2.1">We use LLAMA3-8B as our generator model and design retriever to search for relevant information from sources like MITRE, CWE, and CVEs. We utilize the LangChain framework <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib59" title="">59</a>]</cite> for data-handling. The documents are segmented into chunks of 512 tokens with an overlap of 20 tokens using LangChain’s RecursiveCharacterTextSplitter. This chunk size ensures that the model retains enough contextual information. The chunks are then transformed into vector embeddings using the ”mixedbread-ai/mxbai-embed-large-v1” model <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib60" title="">60</a>]</cite>, and stored these embeddings in the FAISS database <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib61" title="">61</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S6.SS1.p3">
<p class="ltx_p" id="S6.SS1.p3.1">When a user queries the RAG model, it is first converted into vector embeddings using the same ”mixedbread-ai/mxbai-embed-large-v1” model. These embeddings are then processed through LangChain’s ConversationalRetrievalChain, which identifies the closest matches to the query from the stored documents. The matched documents, along with the query, are then fed into Llama3 to generate a coherent response. Figure <a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#S6.F11" title="Figure 11 ‣ VI-A Retrieval Augmented Generation ‣ VI Customized LLMs ‣ SECURE: Benchmarking Large Language Models for Cybersecurity Advisory"><span class="ltx_text ltx_ref_tag">11</span></a> shows the block diagram of our RAG model.</p>
</div>
</section>
<section class="ltx_subsection" id="S6.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S6.SS2.5.1.1">VI-B</span> </span><span class="ltx_text ltx_font_italic" id="S6.SS2.6.2">Fine-tuning</span>
</h3>
<div class="ltx_para" id="S6.SS2.p1">
<p class="ltx_p" id="S6.SS2.p1.1">Fine-tuning is the process of taking a pretrained model and training it further on a specific dataset to adapt it to particular tasks. The goal of this ‘tuning’ is to help the model learn the nuances of the new data. We follow the following steps:</p>
</div>
<div class="ltx_para" id="S6.SS2.p2">
<p class="ltx_p" id="S6.SS2.p2.1"><span class="ltx_text ltx_font_bold" id="S6.SS2.p2.1.1">Data preparation:</span> We collect data using the web-graph data from Common Crawl <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib62" title="">62</a>]</cite>, and filter nodes of representative domains, based on their eigenvector centrality. We select the top 1 million nodes, ranked by highest centrality, for community detection, and scrap web pages from the identified domains within the community using Trafilatura <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib63" title="">63</a>]</cite>. We use this dataset for continual pre-training but exclude from the instruction fine-tuning stage.</p>
</div>
<div class="ltx_para" id="S6.SS2.p3">
<p class="ltx_p" id="S6.SS2.p3.1">We also utilize a a set of human-collected URLs to ensure the dataset is specific to Industrial Control Systems (ICS) by sorting and filtering the data extracted with Trafilatura. This step ensures the dataset focuses on ICS-specific content before proceeding to create the instruction dataset.</p>
</div>
<div class="ltx_para" id="S6.SS2.p4">
<p class="ltx_p" id="S6.SS2.p4.1"><span class="ltx_text ltx_font_bold" id="S6.SS2.p4.1.1">Instruction generation and fine-tuning:</span> We apply the Self-Instruct method to generate instructions from the parsed text, using the default system prompt from the Self-Instruct paper <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib64" title="">64</a>]</cite>. This step yielded 10,000 instructions. We generate responses using the Llama3.1 70B Instruct model, with 8-bit quantization, and a custom system prompt. We then apply instruction fine-tuning on the Llama3-8B Instruct model with 4-bit training.</p>
</div>
<figure class="ltx_table" id="S6.T7">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S6.T7.2.1.1" style="font-size:90%;">TABLE VII</span>: </span><span class="ltx_text" id="S6.T7.3.2" style="font-size:90%;">Benchmark results on customized LLMs</span></figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S6.T7.4" style="width:130.1pt;height:45.1pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-38.8pt,13.5pt) scale(0.626338768130183,0.626338768130183) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S6.T7.4.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S6.T7.4.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S6.T7.4.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S6.T7.4.1.1.1.1.1">Model</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S6.T7.4.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S6.T7.4.1.1.1.2.1">MAET</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S6.T7.4.1.1.1.3"><span class="ltx_text ltx_font_bold" id="S6.T7.4.1.1.1.3.1">CWET</span></th>
<th class="ltx_td ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S6.T7.4.1.1.1.4"><span class="ltx_text ltx_font_bold" id="S6.T7.4.1.1.1.4.1">KCV</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S6.T7.4.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S6.T7.4.1.2.1.1">Base-Llama3-8B</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T7.4.1.2.1.2">82.1%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T7.4.1.2.1.3">83.9%</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" id="S6.T7.4.1.2.1.4">82.8%</td>
</tr>
<tr class="ltx_tr" id="S6.T7.4.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S6.T7.4.1.3.2.1">RAG model</th>
<td class="ltx_td ltx_align_center" id="S6.T7.4.1.3.2.2">86.6%</td>
<td class="ltx_td ltx_align_center" id="S6.T7.4.1.3.2.3">77.3%</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S6.T7.4.1.3.2.4">60.5%</td>
</tr>
<tr class="ltx_tr" id="S6.T7.4.1.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S6.T7.4.1.4.3.1">Fine-tuned model</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S6.T7.4.1.4.3.2">84%</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S6.T7.4.1.4.3.3">85%</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb" id="S6.T7.4.1.4.3.4">76%</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
<section class="ltx_subsection" id="S6.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S6.SS3.5.1.1">VI-C</span> </span><span class="ltx_text ltx_font_italic" id="S6.SS3.6.2">Results:</span>
</h3>
<div class="ltx_para" id="S6.SS3.p1">
<p class="ltx_p" id="S6.SS3.p1.1">Table <a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#S6.T7" title="TABLE VII ‣ VI-B Fine-tuning ‣ VI Customized LLMs ‣ SECURE: Benchmarking Large Language Models for Cybersecurity Advisory"><span class="ltx_text ltx_ref_tag">VII</span></a> shows the result of the benchmark. MAET, CWET, and KCV do not have source URLs provided as a context, and hence can accurately evaluate customized models performance against general LLMs. We can observe that both of the customized models perform better on MAET. Fine-tuned model outperform RAG on CWET. While fine-tuned model performs comparable to base model on KCV, RAG model has a significant drop. One key weakness of “Retrieve-Read” framework for RAG is that during the retrieval phase, the model can select irrelevant chunks and miss crucial information for accurate response. Hence, if the content is not supported by the retrieved context, the model faces hallucinations <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib65" title="">65</a>]</cite>. This could be one of the reasons behind lower performance in CWET and KCV. We will explore advanced RAGs framework in our future works.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S7">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VII </span><span class="ltx_text ltx_font_smallcaps" id="S7.1.1">Limitations &amp; Future Work</span>
</h2>
<div class="ltx_para" id="S7.p1">
<p class="ltx_p" id="S7.p1.1">The reliance on standardized sources such as MITRE ATT&amp;CK, CWE, CVE, and CVSS introduces potential biases and coverage gaps in our benchmark datasets. While these sources are integral to the cybersecurity community and are frequently used in research, they are not entirely without limitations. In particular, issues such as incorrect versioning in CVE entries or incomplete coverage of attack techniques in MITRE ATT&amp;CK could impact the accuracy of SECURE’s evaluation tasks.</p>
</div>
<div class="ltx_para" id="S7.p2">
<p class="ltx_p" id="S7.p2.1">To address this, we have validated the datasets through expert review and cross-referencing with additional sources. However, these measures cannot eliminate the inherent biases of the original databases. In future work, we will continue refining these datasets and exploring alternative data sources.</p>
</div>
<div class="ltx_para" id="S7.p3">
<p class="ltx_p" id="S7.p3.1">We focused on three distinct knowledge tasks (extraction, understanding, and reasoning) to assess the knowledge acquired by LLMs in the cybersecurity context, especially for ICS. While our current work involved designing six datasets centered on ICS security, we plan to extend this framework to encompass other areas of the cybersecurity industry. By adding more datasets, we aim to increase the evaluation “breadth” and provide a more comprehensive assessment. In future work, we also intend to explore various dimensions of trustworthiness, including toxicity, bias, adversarial robustness, out-of-distribution robustness, privacy, and fairness. These investigations are expected to reveal unidentified vulnerabilities and threats to the reliability of using LLMs in cybersecurity.</p>
</div>
</section>
<section class="ltx_section" id="S8">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VIII </span><span class="ltx_text ltx_font_smallcaps" id="S8.1.1">Conclusion</span>
</h2>
<div class="ltx_para" id="S8.p1">
<p class="ltx_p" id="S8.p1.1">LLMs are rapidly transforming the landscape of AI, with vast potential applications in cybersecurity. However, concerns regarding their reliability, and understanding, particularly within the sensitive domain of cybersecurity, remain paramount. The SECURE benchmark, introduced in this paper, aims to address these concerns by providing a holistic framework for evaluating the capabilities of LLMs in a cybersecurity advisory context. Our experiments and analysis demonstrate the potential of LLMs as valuable tools for cybersecurity professionals. However, our findings also underscore the need for caution, especially when handling reasoning tasks. By open-sourcing our benchmark datasets, we invite the research community to contribute to their improvement, enhancing LLMs reliability and paving the way for responsible and beneficial large language models in cybersecurity.</p>
</div>
</section>
<section class="ltx_section" id="Sx1">
<h2 class="ltx_title ltx_font_smallcaps ltx_title_section">Acknowledgement</h2>
<div class="ltx_para" id="Sx1.p1">
<p class="ltx_p" id="Sx1.p1.1">This work is supported by Grant H98230-21-1-0317.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
(2024) Gpt-4-turbo and gpt-4 model openai. Available at <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://platform.openai.com/docs/models/gpt-4-turbo-and-gpt-4" title="">https://platform.openai.com/docs/models/gpt-4-turbo-and-gpt-4</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
A. Zaboli, S. L. Choi, T.-J. Song, and J. Hong, “Chatgpt and other large language models for cybersecurity of smart grid applications,” <em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">arXiv preprint arXiv:2311.05462</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
S. Bubeck, V. Chandrasekaran, R. Eldan, J. Gehrke, E. Horvitz, E. Kamar, P. Lee, Y. T. Lee, Y. Li, S. Lundberg <em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">et al.</em>, “Sparks of artificial general intelligence: Early experiments with gpt-4,” <em class="ltx_emph ltx_font_italic" id="bib.bib3.2.2">arXiv preprint arXiv:2303.12712</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
L. Weidinger, J. Mellor, M. Rauh, C. Griffin, J. Uesato, P.-S. Huang, M. Cheng, M. Glaese, B. Balle, A. Kasirzadeh <em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">et al.</em>, “Ethical and social risks of harm from language models,” <em class="ltx_emph ltx_font_italic" id="bib.bib4.2.2">arXiv preprint arXiv:2112.04359</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
A. Madaan and A. Yazdanbakhsh, “Text and patterns: For effective chain of thought, it takes two to tango,” <em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">arXiv preprint arXiv:2209.07686</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
A. Wang, A. Singh, J. Michael, F. Hill, O. Levy, and S. R. Bowman, “Glue: A multi-task benchmark and analysis platform for natural language understanding,” <em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">arXiv preprint arXiv:1804.07461</em>, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
D. Hendrycks, C. Burns, S. Basart, A. Zou, M. Mazeika, D. Song, and J. Steinhardt, “Measuring massive multitask language understanding,” <em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">arXiv preprint arXiv:2009.03300</em>, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
P. Liang, R. Bommasani, T. Lee, D. Tsipras, D. Soylu, M. Yasunaga, Y. Zhang, D. Narayanan, Y. Wu, A. Kumar <em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">et al.</em>, “Holistic evaluation of language models,” <em class="ltx_emph ltx_font_italic" id="bib.bib8.2.2">arXiv preprint arXiv:2211.09110</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
J. Yu, X. Wang, S. Tu, S. Cao, D. Zhang-Li, X. Lv, H. Peng, Z. Yao, X. Zhang, H. Li <em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">et al.</em>, “Kola: Carefully benchmarking world knowledge of large language models,” in <em class="ltx_emph ltx_font_italic" id="bib.bib9.2.2">The Twelfth International Conference on Learning Representations</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
J. Gennari, S.-h. Lau, S. Perl, J. Parish, and G. Sastry, “Considerations for evaluating large language models for cybersecurity tasks,” 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
(2024) Techniques - ics — mitre att&amp;ck®. Available at <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://attack.mitre.org/techniques/ics/" title="">https://attack.mitre.org/techniques/ics/</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
(2024) Mitigations - ics — mitre att&amp;ck®. Available at <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://attack.mitre.org/mitigations/ics/" title="">https://attack.mitre.org/mitigations/ics/</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
C. Project, “Cves published in 2024,” 2024, available at <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/CVEProject/cvelistV5/tree/main/cves/2024" title="">https://github.com/CVEProject/cvelistV5/tree/main/cves/2024</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
——, “Cwe-1358: Weaknesses in sei etf categories of security vulnerabilities in ics,” 2024, available at <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://cwe.mitre.org/data/definitions/1358.html" title="">https://cwe.mitre.org/data/definitions/1358.html</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
C. A. . Advisories, “Cybersecurity and infrastructure security agency,” 2024, available at <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.cisa.gov/news-events/cybersecurity-advisories" title="">https://www.cisa.gov/news-events/cybersecurity-advisories</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
X. Qi, Y. Zeng, T. Xie, P.-Y. Chen, R. Jia, P. Mittal, and P. Henderson, “Fine-tuning aligned language models compromises safety, even when users do not intend to!” <em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">arXiv preprint arXiv:2310.03693</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
Z. Gekhman, G. Yona, R. Aharoni, M. Eyal, A. Feder, R. Reichart, and J. Herzig, “Does fine-tuning llms on new knowledge encourage hallucinations?” <em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">arXiv preprint arXiv:2405.05904</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
(2024) Gpt-3.5 turbo model openai. Available at <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://platform.openai.com/docs/models/gpt-3-5-turbo" title="">https://platform.openai.com/docs/models/gpt-3-5-turbo</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
(2024) Meta llama3-70b. Available at <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://huggingface.co/meta-llama/Meta-Llama-3-70B" title="">https://huggingface.co/meta-llama/Meta-Llama-3-70B</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
(2024) Meta llama3-8b. Available at <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://huggingface.co/meta-llama/Meta-Llama-3-8B" title="">https://huggingface.co/meta-llama/Meta-Llama-3-8B</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
(2024) Gemini models. Available at <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://deepmind.google/technologies/gemini/pro/" title="">https://deepmind.google/technologies/gemini/pro/</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
A. Q. Jiang, A. Sablayrolles, A. Mensch, C. Bamford, D. S. Chaplot, D. d. l. Casas, F. Bressand, G. Lengyel, G. Lample, L. Saulnier <em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">et al.</em>, “Mistral 7b,” <em class="ltx_emph ltx_font_italic" id="bib.bib22.2.2">arXiv preprint arXiv:2310.06825</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
(2024) mixtral-8x7b-instruct-v0.1. Available at <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://replicate.com/mistralai/mixtral-8x7b-instruct-v0.1" title="">https://replicate.com/mistralai/mixtral-8x7b-instruct-v0.1</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
E. Aghaei, X. Niu, W. Shadid, and E. Al-Shaer, “Securebert: A domain-specific language model for cybersecurity,” in <em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">International Conference on Security and Privacy in Communication Systems</em>.   Springer, 2022, pp. 39–56.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
M. Bayer, P. Kuehn, R. Shanehsaz, and C. Reuter, “Cysecbert: A domain-adapted language model for the cybersecurity domain,” <em class="ltx_emph ltx_font_italic" id="bib.bib25.1.1">ACM Transactions on Privacy and Security</em>, vol. 27, no. 2, pp. 1–20, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
G. Team, T. Mesnard, C. Hardin, R. Dadashi, S. Bhupatiraju, S. Pathak, L. Sifre, M. Rivière, M. S. Kale, J. Love <em class="ltx_emph ltx_font_italic" id="bib.bib26.1.1">et al.</em>, “Gemma: Open models based on gemini research and technology,” <em class="ltx_emph ltx_font_italic" id="bib.bib26.2.2">arXiv preprint arXiv:2403.08295</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
B. Roziere, J. Gehring, F. Gloeckle, S. Sootla, I. Gat, X. E. Tan, Y. Adi, J. Liu, T. Remez, J. Rapin <em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">et al.</em>, “Code llama: Open foundation models for code,” <em class="ltx_emph ltx_font_italic" id="bib.bib27.2.2">arXiv preprint arXiv:2308.12950</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
A. Shestov, A. Cheshkov, R. Levichev, R. Mussabayev, P. Zadorozhny, E. Maslov, C. Vadim, and E. Bulychev, “Finetuning large language models for vulnerability detection,” <em class="ltx_emph ltx_font_italic" id="bib.bib28.1.1">arXiv preprint arXiv:2401.17010</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
M. A. Ferrag, A. Battah, N. Tihanyi, M. Debbah, T. Lestable, and L. C. Cordeiro, “Securefalcon: The next cyber reasoning system for cyber security,” <em class="ltx_emph ltx_font_italic" id="bib.bib29.1.1">arXiv preprint arXiv:2307.06616</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
R. Fang, R. Bindu, A. Gupta, and D. Kang, “Llm agents can autonomously exploit one-day vulnerabilities,” <em class="ltx_emph ltx_font_italic" id="bib.bib30.1.1">arXiv preprint arXiv:2404.08144</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
Z. Li, S. Dutta, and M. Naik, “Llm-assisted static analysis for detecting security vulnerabilities,” <em class="ltx_emph ltx_font_italic" id="bib.bib31.1.1">arXiv preprint arXiv:2405.17238</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
A. Silva, S. Fang, and M. Monperrus, “Repairllama: Efficient representations and fine-tuned adapters for program repair,” <em class="ltx_emph ltx_font_italic" id="bib.bib32.1.1">arXiv preprint arXiv:2312.15698</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
H. Guo, J. Yang, J. Liu, L. Yang, L. Chai, J. Bai, J. Peng, X. Hu, C. Chen, D. Zhang <em class="ltx_emph ltx_font_italic" id="bib.bib33.1.1">et al.</em>, “Owl: A large language model for it operations,” <em class="ltx_emph ltx_font_italic" id="bib.bib33.2.2">arXiv preprint arXiv:2309.09298</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
M. Sultana, A. Taylor, L. Li, and S. Majumdar, “Towards evaluation and understanding of large language models for cyber operation automation,” in <em class="ltx_emph ltx_font_italic" id="bib.bib34.1.1">2023 IEEE Conference on Communications and Network Security (CNS)</em>.   IEEE, 2023, pp. 1–6.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
N. Tihanyi, M. A. Ferrag, R. Jain, and M. Debbah, “Cybermetric: A benchmark dataset for evaluating large language models knowledge in cybersecurity,” <em class="ltx_emph ltx_font_italic" id="bib.bib35.1.1">arXiv preprint arXiv:2402.07688</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock">
Z. Liu, J. Shi, and J. F. Buford, “Cyberbench: A multi-task benchmark for evaluating large language models in cybersecurity.”

</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock">
G. Li, Y. Li, W. Guannan, H. Yang, and Y. Yu, “Seceval: A comprehensive benchmark for evaluating cybersecurity knowledge of foundation models,” https://github.com/XuanwuAI/SecEval, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock">
Z. Liu, “Secqa: A concise question-answering dataset for evaluating large language models in computer security,” <em class="ltx_emph ltx_font_italic" id="bib.bib38.1.1">arXiv preprint arXiv:2312.15838</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock">
Y. Miao, Y. Bai, L. Chen, D. Li, H. Sun, X. Wang, Z. Luo, D. Sun, and X. Xu, “An empirical study of netops capability of pre-trained large language models,” <em class="ltx_emph ltx_font_italic" id="bib.bib39.1.1">arXiv preprint arXiv:2309.05557</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock">
Y. Liu, C. Pei, L. Xu, B. Chen, M. Sun, Z. Zhang, Y. Sun, S. Zhang, K. Wang, H. Zhang <em class="ltx_emph ltx_font_italic" id="bib.bib40.1.1">et al.</em>, “Opseval: A comprehensive task-oriented aiops benchmark for large language models,” <em class="ltx_emph ltx_font_italic" id="bib.bib40.2.2">arXiv preprint arXiv:2310.07637</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock">
S. Ullah, M. Han, S. Pujar, H. Pearce, A. Coskun, and G. Stringhini, “Llms cannot reliably identify and reason about security vulnerabilities (yet?): A comprehensive evaluation, framework, and benchmarks,” in <em class="ltx_emph ltx_font_italic" id="bib.bib41.1.1">IEEE Symposium on Security and Privacy</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock">
M. T. Alam, D. Bhushl, L. Nguyen, and N. Rastogi, “Ctibench: A benchmark for evaluating llms in cyber threat intelligence,” <em class="ltx_emph ltx_font_italic" id="bib.bib42.1.1">arXiv preprint arXiv:2406.07599</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock">
E. A. Feigenbaum <em class="ltx_emph ltx_font_italic" id="bib.bib43.1.1">et al.</em>, “The art of artificial intelligence: Themes and case studies of knowledge engineering,” 1977.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_tag_bibitem">[44]</span>
<span class="ltx_bibblock">
F. Petroni, T. Rocktäschel, P. Lewis, A. Bakhtin, Y. Wu, A. H. Miller, and S. Riedel, “Language models as knowledge bases?” <em class="ltx_emph ltx_font_italic" id="bib.bib44.1.1">arXiv preprint arXiv:1909.01066</em>, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_tag_bibitem">[45]</span>
<span class="ltx_bibblock">
J. A. Collins and I. R. Olson, “Knowledge is power: How conceptual knowledge transforms visual cognition,” <em class="ltx_emph ltx_font_italic" id="bib.bib45.1.1">Psychonomic bulletin &amp; review</em>, vol. 21, pp. 843–860, 2014.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib46">
<span class="ltx_tag ltx_tag_bibitem">[46]</span>
<span class="ltx_bibblock">
S. Cao, J. Shi, L. Pan, L. Nie, Y. Xiang, L. Hou, J. Li, B. He, and H. Zhang, “Kqa pro: A dataset with explicit compositional programs for complex question answering over knowledge base,” in <em class="ltx_emph ltx_font_italic" id="bib.bib46.1.1">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em>, 2022, pp. 6101–6119.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib47">
<span class="ltx_tag ltx_tag_bibitem">[47]</span>
<span class="ltx_bibblock">
S. Kim, J. Shin, Y. Cho, J. Jang, S. Longpre, H. Lee, S. Yun, S. Shin, S. Kim, J. Thorne <em class="ltx_emph ltx_font_italic" id="bib.bib47.1.1">et al.</em>, “Prometheus: Inducing evaluation capability in language models,” in <em class="ltx_emph ltx_font_italic" id="bib.bib47.2.2">NeurIPS 2023 Workshop on Instruction Tuning and Instruction Following</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib48">
<span class="ltx_tag ltx_tag_bibitem">[48]</span>
<span class="ltx_bibblock">
L. Zheng, W.-L. Chiang, Y. Sheng, S. Zhuang, Z. Wu, Y. Zhuang, Z. Lin, Z. Li, D. Li, E. Xing <em class="ltx_emph ltx_font_italic" id="bib.bib48.1.1">et al.</em>, “Judging llm-as-a-judge with mt-bench and chatbot arena,” <em class="ltx_emph ltx_font_italic" id="bib.bib48.2.2">Advances in Neural Information Processing Systems</em>, vol. 36, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib49">
<span class="ltx_tag ltx_tag_bibitem">[49]</span>
<span class="ltx_bibblock">
(2024) Gpt-4o model openai. <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://platform.openai.com/docs/models/gpt-4o" title="">https://platform.openai.com/docs/models/gpt-4o</a>. Accessed: 2024-05-24.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib50">
<span class="ltx_tag ltx_tag_bibitem">[50]</span>
<span class="ltx_bibblock">
(2024) Mitre att&amp;ck. Available at <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://attack.mitre.org/" title="">https://attack.mitre.org/</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib51">
<span class="ltx_tag ltx_tag_bibitem">[51]</span>
<span class="ltx_bibblock">
T. B. Brown, “Language models are few-shot learners,” <em class="ltx_emph ltx_font_italic" id="bib.bib51.1.1">arXiv preprint arXiv:2005.14165</em>, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib52">
<span class="ltx_tag ltx_tag_bibitem">[52]</span>
<span class="ltx_bibblock">
T. Kojima, S. S. Gu, M. Reid, Y. Matsuo, and Y. Iwasawa, “Large language models are zero-shot reasoners,” <em class="ltx_emph ltx_font_italic" id="bib.bib52.1.1">Advances in neural information processing systems</em>, vol. 35, pp. 22 199–22 213, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib53">
<span class="ltx_tag ltx_tag_bibitem">[53]</span>
<span class="ltx_bibblock">
(2024) Cvss 3.1 calculator. Available at <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://nvd.nist.gov/vuln-metrics/cvss/v3-calculator" title="">https://nvd.nist.gov/vuln-metrics/cvss/v3-calculator</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib54">
<span class="ltx_tag ltx_tag_bibitem">[54]</span>
<span class="ltx_bibblock">
C.-Y. Lin, “ROUGE: A package for automatic evaluation of summaries,” in <em class="ltx_emph ltx_font_italic" id="bib.bib54.1.1">Text Summarization Branches Out</em>.   Barcelona, Spain: Association for Computational Linguistics, Jul. 2004, pp. 74–81. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/W04-1013" title="">https://aclanthology.org/W04-1013</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib55">
<span class="ltx_tag ltx_tag_bibitem">[55]</span>
<span class="ltx_bibblock">
“Chatarena: Multi-agent language game environments for large language models,” <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/chatarena/chatarena" title="">https://github.com/chatarena/chatarena</a>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib56">
<span class="ltx_tag ltx_tag_bibitem">[56]</span>
<span class="ltx_bibblock">
J. Chen and J. Mueller, “Quantifying uncertainty in answers from any language model and enhancing their trustworthiness,” 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib57">
<span class="ltx_tag ltx_tag_bibitem">[57]</span>
<span class="ltx_bibblock">
V. Adlakha, P. BehnamGhader, X. H. Lu, N. Meade, and S. Reddy, “Evaluating correctness and faithfulness of instruction-following models for question answering,” <em class="ltx_emph ltx_font_italic" id="bib.bib57.1.1">Transactions of the Association for Computational Linguistics</em>, vol. 12, pp. 775–793, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib58">
<span class="ltx_tag ltx_tag_bibitem">[58]</span>
<span class="ltx_bibblock">
P. Lewis, E. Perez, A. Piktus, F. Petroni, V. Karpukhin, N. Goyal, H. Küttler, M. Lewis, W.-t. Yih, T. Rocktäschel <em class="ltx_emph ltx_font_italic" id="bib.bib58.1.1">et al.</em>, “Retrieval-augmented generation for knowledge-intensive nlp tasks,” <em class="ltx_emph ltx_font_italic" id="bib.bib58.2.2">Advances in Neural Information Processing Systems</em>, vol. 33, pp. 9459–9474, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib59">
<span class="ltx_tag ltx_tag_bibitem">[59]</span>
<span class="ltx_bibblock">
(2024) Langchaink. Available at <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://python.langchain.com/v0.2/docs/introduction/" title="">https://python.langchain.com/v0.2/docs/introduction/</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib60">
<span class="ltx_tag ltx_tag_bibitem">[60]</span>
<span class="ltx_bibblock">
S. Lee, A. Shakir, D. Koenig, and J. Lipp. (2024) Open source strikes bread - new fluffy embeddings model. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.mixedbread.ai/blog/mxbai-embed-large-v1" title="">https://www.mixedbread.ai/blog/mxbai-embed-large-v1</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib61">
<span class="ltx_tag ltx_tag_bibitem">[61]</span>
<span class="ltx_bibblock">
(2024) Faiss: A library for efficient similarity search by meta. <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://engineering.fb.com/2017/03/29/data-infrastructure/faiss-a-library-for-efficient-similarity-search/" title="">https://engineering.fb.com/2017/03/29/data-infrastructure/faiss-a-library-for-efficient-similarity-search/</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib62">
<span class="ltx_tag ltx_tag_bibitem">[62]</span>
<span class="ltx_bibblock">
(2024) Common crawl. Available at <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://commoncrawl.org/" title="">https://commoncrawl.org/</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib63">
<span class="ltx_tag ltx_tag_bibitem">[63]</span>
<span class="ltx_bibblock">
A. Barbaresi, “Trafilatura: A Web Scraping Library and Command-Line Tool for Text Discovery and Extraction,” in <em class="ltx_emph ltx_font_italic" id="bib.bib63.1.1">Proceedings of the Joint Conference of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing: System Demonstrations</em>.   Association for Computational Linguistics, 2021, pp. 122–131. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/2021.acl-demo.15" title="">https://aclanthology.org/2021.acl-demo.15</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib64">
<span class="ltx_tag ltx_tag_bibitem">[64]</span>
<span class="ltx_bibblock">
Y. Wang, Y. Kordi, S. Mishra, A. Liu, N. A. Smith, D. Khashabi, and H. Hajishirzi, “Self-instruct: Aligning language models with self-generated instructions,” <em class="ltx_emph ltx_font_italic" id="bib.bib64.1.1">arXiv preprint arXiv:2212.10560</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib65">
<span class="ltx_tag ltx_tag_bibitem">[65]</span>
<span class="ltx_bibblock">
Y. Gao, Y. Xiong, X. Gao, K. Jia, J. Pan, Y. Bi, Y. Dai, J. Sun, and H. Wang, “Retrieval-augmented generation for large language models: A survey,” <em class="ltx_emph ltx_font_italic" id="bib.bib65.1.1">arXiv preprint arXiv:2312.10997</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib66">
<span class="ltx_tag ltx_tag_bibitem">[66]</span>
<span class="ltx_bibblock">
A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, Ł. Kaiser, and I. Polosukhin, “Attention is all you need,” <em class="ltx_emph ltx_font_italic" id="bib.bib66.1.1">Advances in neural information processing systems</em>, vol. 30, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib67">
<span class="ltx_tag ltx_tag_bibitem">[67]</span>
<span class="ltx_bibblock">
(2024) Openai api. Available at <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://platform.openai.com/" title="">https://platform.openai.com/</a>.

</span>
</li>
</ul>
</section>
<section class="ltx_subsection" id="A0.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="A0.SS1.5.1.1">-A</span> </span><span class="ltx_text ltx_font_italic" id="A0.SS1.6.2">Large Language Models</span>
</h3>
<div class="ltx_para" id="A0.SS1.p1">
<p class="ltx_p" id="A0.SS1.p1.1">Large Language Models (LLMs) are pretrained autoregressive transformers <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib66" title="">66</a>]</cite> capable of generating one token at a time given a set of generated tokens as input. These are trained to maximize the probability of the next token given a history of tokens. We use the following LLMs in our evaluation:</p>
<ol class="ltx_enumerate" id="A0.I1">
<li class="ltx_item" id="A0.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="A0.I1.i1.p1">
<p class="ltx_p" id="A0.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="A0.I1.i1.p1.1.1">ChatGPT models:</span> ChatGPT models by OpenAI have brought remarkable improvements in LLMs and sparked a trend for building more intelligent AI models. We use the following LLMs from OpenAI in our work, accessed via OpenAI’s API querying system <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib67" title="">67</a>]</cite>:</p>
</div>
<div class="ltx_para" id="A0.I1.i1.p2">
<p class="ltx_p" id="A0.I1.i1.p2.1"><span class="ltx_text ltx_font_bold" id="A0.I1.i1.p2.1.1">a)</span> <span class="ltx_text ltx_font_bold" id="A0.I1.i1.p2.1.2">GPT-3.5</span> models can understand and generate natural language. We use the <span class="ltx_text ltx_font_italic" id="A0.I1.i1.p2.1.3">gpt-3.5-turbo</span> model that has been optimized for chat. It has a context window of 16385 tokens and the model was trained up to the cutoff time of September 2021.</p>
</div>
<div class="ltx_para" id="A0.I1.i1.p3">
<p class="ltx_p" id="A0.I1.i1.p3.1"><span class="ltx_text ltx_font_bold" id="A0.I1.i1.p3.1.1">b)</span> <span class="ltx_text ltx_font_bold" id="A0.I1.i1.p3.1.2">GPT-4</span> is a multimodal modal that can accept both text and image as inputs. This model excels in solving various linguistic tasks compared to GPT-3.5 model. We use the <span class="ltx_text ltx_font_italic" id="A0.I1.i1.p3.1.3">gpt-4-turbo</span> version which is optimized for chat. It has a context window of 128000 tokens. The model was trained on a dataset collected upto to December 2023.</p>
</div>
<div class="ltx_para" id="A0.I1.i1.p4">
<p class="ltx_p" id="A0.I1.i1.p4.1"><span class="ltx_text ltx_font_bold" id="A0.I1.i1.p4.1.1">c)</span> <span class="ltx_text ltx_font_bold" id="A0.I1.i1.p4.1.2">GPT-4o</span> is the latest model from openAI that can accept text and images as inputs. It is faster than GPT-4 Turbo but has the same context window size. We use this latest model to create the dataset.</p>
</div>
</li>
<li class="ltx_item" id="A0.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="A0.I1.i2.p1">
<p class="ltx_p" id="A0.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="A0.I1.i2.p1.1.1">Llama3-70B and Llama3-8B:</span> Llama3 models <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib19" title="">19</a>]</cite> are a family of large language models developed by Meta, which is open-sourced to the researchers. These models are available in parameter sizes of 8B and 70B with both pre-trained and instruction-tuned (optimized for chat) available in public. These models input text only, and generate text and code only. We use these models through huggingface API. Llama3 models were released on April 18, 2024.</p>
</div>
</li>
<li class="ltx_item" id="A0.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span>
<div class="ltx_para" id="A0.I1.i3.p1">
<p class="ltx_p" id="A0.I1.i3.p1.1"><span class="ltx_text ltx_font_bold" id="A0.I1.i3.p1.1.1">Gemini <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib21" title="">21</a>]</cite>:</span> Gemini models are a family of multimodal generative models released by Google which are capable of handling extremely long contexts, and take input as documents, video, audio and pictures. We use the Gemini-Pro 1.5 version of the LLM available through API.</p>
</div>
</li>
<li class="ltx_item" id="A0.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span>
<div class="ltx_para" id="A0.I1.i4.p1">
<p class="ltx_p" id="A0.I1.i4.p1.1"><span class="ltx_text ltx_font_bold" id="A0.I1.i4.p1.1.1">Mistral-7B and Mixtral 8x7B:</span> Mixtral 8x7b <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib23" title="">23</a>]</cite> is a mixture-of-experts model ( Mixtral-7B <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib22" title="">22</a>]</cite>), consisting of 8 distinct groups of parameters. We use both of these models through huggingface API.</p>
</div>
</li>
</ol>
</div>
<figure class="ltx_table" id="A0.T8">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="A0.T8.2.1.1" style="font-size:90%;">TABLE VIII</span>: </span><span class="ltx_text" id="A0.T8.3.2" style="font-size:90%;">Comparison between different LLMs</span></figcaption>
<div class="ltx_inline-block ltx_transformed_outer" id="A0.T8.4" style="width:199.5pt;height:67.2pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-114.0pt,38.4pt) scale(0.466727769563602,0.466727769563602) ;">
<table class="ltx_tabular ltx_align_middle" id="A0.T8.4.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A0.T8.4.1.1.1">
<td class="ltx_td ltx_align_center ltx_border_tt" id="A0.T8.4.1.1.1.1"><span class="ltx_text ltx_font_bold" id="A0.T8.4.1.1.1.1.1">Type</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A0.T8.4.1.1.1.2"><span class="ltx_text ltx_font_bold" id="A0.T8.4.1.1.1.2.1">Model</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A0.T8.4.1.1.1.3"><span class="ltx_text ltx_font_bold" id="A0.T8.4.1.1.1.3.1">Provider</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A0.T8.4.1.1.1.4"><span class="ltx_text ltx_font_bold" id="A0.T8.4.1.1.1.4.1">Training data</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A0.T8.4.1.1.1.5"><span class="ltx_text ltx_font_bold" id="A0.T8.4.1.1.1.5.1"># of parameters</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A0.T8.4.1.1.1.6"><span class="ltx_text ltx_font_bold" id="A0.T8.4.1.1.1.6.1">Context-window</span></td>
</tr>
<tr class="ltx_tr" id="A0.T8.4.1.2.2">
<td class="ltx_td ltx_align_left ltx_border_t" id="A0.T8.4.1.2.2.1" rowspan="3"><span class="ltx_text" id="A0.T8.4.1.2.2.1.1">Closed</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A0.T8.4.1.2.2.2">ChatGPT-3.5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A0.T8.4.1.2.2.3">OpenaAI</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A0.T8.4.1.2.2.4">Upto Sept. 2021</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A0.T8.4.1.2.2.5">-</td>
<td class="ltx_td ltx_nopad_r ltx_align_left ltx_border_t" id="A0.T8.4.1.2.2.6">16385</td>
</tr>
<tr class="ltx_tr" id="A0.T8.4.1.3.3">
<td class="ltx_td ltx_align_center" id="A0.T8.4.1.3.3.1">ChatGPT-4</td>
<td class="ltx_td ltx_align_center" id="A0.T8.4.1.3.3.2">OpenaAI</td>
<td class="ltx_td ltx_align_left" id="A0.T8.4.1.3.3.3">Upto Dec. 2023</td>
<td class="ltx_td ltx_align_left" id="A0.T8.4.1.3.3.4">-</td>
<td class="ltx_td ltx_nopad_r ltx_align_left" id="A0.T8.4.1.3.3.5">128000</td>
</tr>
<tr class="ltx_tr" id="A0.T8.4.1.4.4">
<td class="ltx_td ltx_align_center" id="A0.T8.4.1.4.4.1">Gemini-Pro</td>
<td class="ltx_td ltx_align_center" id="A0.T8.4.1.4.4.2">Google</td>
<td class="ltx_td ltx_align_left" id="A0.T8.4.1.4.4.3">Upto Nov. 2023</td>
<td class="ltx_td ltx_align_left" id="A0.T8.4.1.4.4.4">-</td>
<td class="ltx_td ltx_nopad_r ltx_align_left" id="A0.T8.4.1.4.4.5">128000</td>
</tr>
<tr class="ltx_tr" id="A0.T8.4.1.5.5">
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" id="A0.T8.4.1.5.5.1" rowspan="4"><span class="ltx_text" id="A0.T8.4.1.5.5.1.1">Open</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A0.T8.4.1.5.5.2">Llama3-70b</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A0.T8.4.1.5.5.3">Meta</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A0.T8.4.1.5.5.4">Upto Dec. 2023</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A0.T8.4.1.5.5.5">70.6B</td>
<td class="ltx_td ltx_nopad_r ltx_align_left ltx_border_t" id="A0.T8.4.1.5.5.6">8000</td>
</tr>
<tr class="ltx_tr" id="A0.T8.4.1.6.6">
<td class="ltx_td ltx_align_center" id="A0.T8.4.1.6.6.1">Llama3-8b</td>
<td class="ltx_td ltx_align_center" id="A0.T8.4.1.6.6.2">Meta</td>
<td class="ltx_td ltx_align_left" id="A0.T8.4.1.6.6.3">Upto Mar. 2023</td>
<td class="ltx_td ltx_align_left" id="A0.T8.4.1.6.6.4">8B</td>
<td class="ltx_td ltx_nopad_r ltx_align_left" id="A0.T8.4.1.6.6.5">8000</td>
</tr>
<tr class="ltx_tr" id="A0.T8.4.1.7.7">
<td class="ltx_td ltx_align_center" id="A0.T8.4.1.7.7.1">Mistral-7B</td>
<td class="ltx_td ltx_align_center" id="A0.T8.4.1.7.7.2">Mistral</td>
<td class="ltx_td ltx_align_left" id="A0.T8.4.1.7.7.3">Upto Sept. 2021</td>
<td class="ltx_td ltx_align_left" id="A0.T8.4.1.7.7.4">7B</td>
<td class="ltx_td ltx_nopad_r ltx_align_left" id="A0.T8.4.1.7.7.5">8192</td>
</tr>
<tr class="ltx_tr" id="A0.T8.4.1.8.8">
<td class="ltx_td ltx_align_center ltx_border_bb" id="A0.T8.4.1.8.8.1">Mixtral-8x7B</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A0.T8.4.1.8.8.2">Mistral</td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="A0.T8.4.1.8.8.3">Upto Sept. 2021</td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="A0.T8.4.1.8.8.4">46.7B</td>
<td class="ltx_td ltx_nopad_r ltx_align_left ltx_border_bb" id="A0.T8.4.1.8.8.5">32000</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div class="ltx_para" id="A0.SS1.p2">
<p class="ltx_p" id="A0.SS1.p2.1"><span class="ltx_text" id="A0.SS1.p2.1.1"></span></p>
</div>
</section>
<section class="ltx_subsection" id="A0.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="A0.SS2.5.1.1">-B</span> </span><span class="ltx_text ltx_font_italic" id="A0.SS2.6.2">Evaluation Metrics</span>
</h3>
<div class="ltx_para" id="A0.SS2.p1">
<ol class="ltx_enumerate" id="A0.I2">
<li class="ltx_item" id="A0.I2.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="A0.I2.i1.p1">
<p class="ltx_p" id="A0.I2.i1.p1.1"><span class="ltx_text ltx_font_bold" id="A0.I2.i1.p1.1.1">MAET, CWET &amp; KCV:</span> For these three tasks, we utilize <span class="ltx_text ltx_font_bold" id="A0.I2.i1.p1.1.2">accuracy</span> as the primary evaluation metric. Accuracy represents the percentage of questions answered correctly by the LLM.</p>
</div>
</li>
<li class="ltx_item" id="A0.I2.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="A0.I2.i2.p1">
<p class="ltx_p" id="A0.I2.i2.p1.1"><span class="ltx_text ltx_font_bold" id="A0.I2.i2.p1.1.1">VOOD:</span> This out-of-distribution task presents models with True, False, and ”Don’t Know (X)” options. We consider a model’s prediction accurate if it selects ”Don’t Know (X),” demonstrating its ability to recognize when it lacks sufficient information to answer.</p>
</div>
</li>
<li class="ltx_item" id="A0.I2.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span>
<div class="ltx_para" id="A0.I2.i3.p1">
<p class="ltx_p" id="A0.I2.i3.p1.10"><span class="ltx_text ltx_font_bold" id="A0.I2.i3.p1.10.1">RERT:</span> We treat the RERT task as a summarization task, evaluating generated summaries against reference summaries using the <span class="ltx_text ltx_font_bold" id="A0.I2.i3.p1.10.2">ROGUE-L</span> metric <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.20441v3#bib.bib54" title="">54</a>]</cite>. ROGUE score is used in natural language processing (NLP) tasks to measure the similarity between a generated text and a reference text using overlapping units (such as n-grams, word sequences, or word pairs). In RERT, the LLMs are tasked with predicting the Risk Evaluation based on the provided vulnerability details that has a ground truth. We compute ROGUE-L by measuring the longest common subsequence (LCS) between the generated risk evaluation and reference ground truth. Given a ground truth summary <math alttext="X" class="ltx_Math" display="inline" id="A0.I2.i3.p1.1.m1.1"><semantics id="A0.I2.i3.p1.1.m1.1a"><mi id="A0.I2.i3.p1.1.m1.1.1" xref="A0.I2.i3.p1.1.m1.1.1.cmml">X</mi><annotation-xml encoding="MathML-Content" id="A0.I2.i3.p1.1.m1.1b"><ci id="A0.I2.i3.p1.1.m1.1.1.cmml" xref="A0.I2.i3.p1.1.m1.1.1">𝑋</ci></annotation-xml><annotation encoding="application/x-tex" id="A0.I2.i3.p1.1.m1.1c">X</annotation><annotation encoding="application/x-llamapun" id="A0.I2.i3.p1.1.m1.1d">italic_X</annotation></semantics></math> of length <math alttext="m" class="ltx_Math" display="inline" id="A0.I2.i3.p1.2.m2.1"><semantics id="A0.I2.i3.p1.2.m2.1a"><mi id="A0.I2.i3.p1.2.m2.1.1" xref="A0.I2.i3.p1.2.m2.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="A0.I2.i3.p1.2.m2.1b"><ci id="A0.I2.i3.p1.2.m2.1.1.cmml" xref="A0.I2.i3.p1.2.m2.1.1">𝑚</ci></annotation-xml><annotation encoding="application/x-tex" id="A0.I2.i3.p1.2.m2.1c">m</annotation><annotation encoding="application/x-llamapun" id="A0.I2.i3.p1.2.m2.1d">italic_m</annotation></semantics></math> and generated summary <math alttext="Y" class="ltx_Math" display="inline" id="A0.I2.i3.p1.3.m3.1"><semantics id="A0.I2.i3.p1.3.m3.1a"><mi id="A0.I2.i3.p1.3.m3.1.1" xref="A0.I2.i3.p1.3.m3.1.1.cmml">Y</mi><annotation-xml encoding="MathML-Content" id="A0.I2.i3.p1.3.m3.1b"><ci id="A0.I2.i3.p1.3.m3.1.1.cmml" xref="A0.I2.i3.p1.3.m3.1.1">𝑌</ci></annotation-xml><annotation encoding="application/x-tex" id="A0.I2.i3.p1.3.m3.1c">Y</annotation><annotation encoding="application/x-llamapun" id="A0.I2.i3.p1.3.m3.1d">italic_Y</annotation></semantics></math> of length <math alttext="n" class="ltx_Math" display="inline" id="A0.I2.i3.p1.4.m4.1"><semantics id="A0.I2.i3.p1.4.m4.1a"><mi id="A0.I2.i3.p1.4.m4.1.1" xref="A0.I2.i3.p1.4.m4.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="A0.I2.i3.p1.4.m4.1b"><ci id="A0.I2.i3.p1.4.m4.1.1.cmml" xref="A0.I2.i3.p1.4.m4.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="A0.I2.i3.p1.4.m4.1c">n</annotation><annotation encoding="application/x-llamapun" id="A0.I2.i3.p1.4.m4.1d">italic_n</annotation></semantics></math>, to compute ROGUE-L, we first compute <math alttext="R_{LCS}=\frac{LCS(X,Y)}{m}" class="ltx_Math" display="inline" id="A0.I2.i3.p1.5.m5.2"><semantics id="A0.I2.i3.p1.5.m5.2a"><mrow id="A0.I2.i3.p1.5.m5.2.3" xref="A0.I2.i3.p1.5.m5.2.3.cmml"><msub id="A0.I2.i3.p1.5.m5.2.3.2" xref="A0.I2.i3.p1.5.m5.2.3.2.cmml"><mi id="A0.I2.i3.p1.5.m5.2.3.2.2" xref="A0.I2.i3.p1.5.m5.2.3.2.2.cmml">R</mi><mrow id="A0.I2.i3.p1.5.m5.2.3.2.3" xref="A0.I2.i3.p1.5.m5.2.3.2.3.cmml"><mi id="A0.I2.i3.p1.5.m5.2.3.2.3.2" xref="A0.I2.i3.p1.5.m5.2.3.2.3.2.cmml">L</mi><mo id="A0.I2.i3.p1.5.m5.2.3.2.3.1" xref="A0.I2.i3.p1.5.m5.2.3.2.3.1.cmml">⁢</mo><mi id="A0.I2.i3.p1.5.m5.2.3.2.3.3" xref="A0.I2.i3.p1.5.m5.2.3.2.3.3.cmml">C</mi><mo id="A0.I2.i3.p1.5.m5.2.3.2.3.1a" xref="A0.I2.i3.p1.5.m5.2.3.2.3.1.cmml">⁢</mo><mi id="A0.I2.i3.p1.5.m5.2.3.2.3.4" xref="A0.I2.i3.p1.5.m5.2.3.2.3.4.cmml">S</mi></mrow></msub><mo id="A0.I2.i3.p1.5.m5.2.3.1" xref="A0.I2.i3.p1.5.m5.2.3.1.cmml">=</mo><mfrac id="A0.I2.i3.p1.5.m5.2.2" xref="A0.I2.i3.p1.5.m5.2.2.cmml"><mrow id="A0.I2.i3.p1.5.m5.2.2.2" xref="A0.I2.i3.p1.5.m5.2.2.2.cmml"><mi id="A0.I2.i3.p1.5.m5.2.2.2.4" xref="A0.I2.i3.p1.5.m5.2.2.2.4.cmml">L</mi><mo id="A0.I2.i3.p1.5.m5.2.2.2.3" xref="A0.I2.i3.p1.5.m5.2.2.2.3.cmml">⁢</mo><mi id="A0.I2.i3.p1.5.m5.2.2.2.5" xref="A0.I2.i3.p1.5.m5.2.2.2.5.cmml">C</mi><mo id="A0.I2.i3.p1.5.m5.2.2.2.3a" xref="A0.I2.i3.p1.5.m5.2.2.2.3.cmml">⁢</mo><mi id="A0.I2.i3.p1.5.m5.2.2.2.6" xref="A0.I2.i3.p1.5.m5.2.2.2.6.cmml">S</mi><mo id="A0.I2.i3.p1.5.m5.2.2.2.3b" xref="A0.I2.i3.p1.5.m5.2.2.2.3.cmml">⁢</mo><mrow id="A0.I2.i3.p1.5.m5.2.2.2.7.2" xref="A0.I2.i3.p1.5.m5.2.2.2.7.1.cmml"><mo id="A0.I2.i3.p1.5.m5.2.2.2.7.2.1" stretchy="false" xref="A0.I2.i3.p1.5.m5.2.2.2.7.1.cmml">(</mo><mi id="A0.I2.i3.p1.5.m5.1.1.1.1" xref="A0.I2.i3.p1.5.m5.1.1.1.1.cmml">X</mi><mo id="A0.I2.i3.p1.5.m5.2.2.2.7.2.2" xref="A0.I2.i3.p1.5.m5.2.2.2.7.1.cmml">,</mo><mi id="A0.I2.i3.p1.5.m5.2.2.2.2" xref="A0.I2.i3.p1.5.m5.2.2.2.2.cmml">Y</mi><mo id="A0.I2.i3.p1.5.m5.2.2.2.7.2.3" stretchy="false" xref="A0.I2.i3.p1.5.m5.2.2.2.7.1.cmml">)</mo></mrow></mrow><mi id="A0.I2.i3.p1.5.m5.2.2.4" xref="A0.I2.i3.p1.5.m5.2.2.4.cmml">m</mi></mfrac></mrow><annotation-xml encoding="MathML-Content" id="A0.I2.i3.p1.5.m5.2b"><apply id="A0.I2.i3.p1.5.m5.2.3.cmml" xref="A0.I2.i3.p1.5.m5.2.3"><eq id="A0.I2.i3.p1.5.m5.2.3.1.cmml" xref="A0.I2.i3.p1.5.m5.2.3.1"></eq><apply id="A0.I2.i3.p1.5.m5.2.3.2.cmml" xref="A0.I2.i3.p1.5.m5.2.3.2"><csymbol cd="ambiguous" id="A0.I2.i3.p1.5.m5.2.3.2.1.cmml" xref="A0.I2.i3.p1.5.m5.2.3.2">subscript</csymbol><ci id="A0.I2.i3.p1.5.m5.2.3.2.2.cmml" xref="A0.I2.i3.p1.5.m5.2.3.2.2">𝑅</ci><apply id="A0.I2.i3.p1.5.m5.2.3.2.3.cmml" xref="A0.I2.i3.p1.5.m5.2.3.2.3"><times id="A0.I2.i3.p1.5.m5.2.3.2.3.1.cmml" xref="A0.I2.i3.p1.5.m5.2.3.2.3.1"></times><ci id="A0.I2.i3.p1.5.m5.2.3.2.3.2.cmml" xref="A0.I2.i3.p1.5.m5.2.3.2.3.2">𝐿</ci><ci id="A0.I2.i3.p1.5.m5.2.3.2.3.3.cmml" xref="A0.I2.i3.p1.5.m5.2.3.2.3.3">𝐶</ci><ci id="A0.I2.i3.p1.5.m5.2.3.2.3.4.cmml" xref="A0.I2.i3.p1.5.m5.2.3.2.3.4">𝑆</ci></apply></apply><apply id="A0.I2.i3.p1.5.m5.2.2.cmml" xref="A0.I2.i3.p1.5.m5.2.2"><divide id="A0.I2.i3.p1.5.m5.2.2.3.cmml" xref="A0.I2.i3.p1.5.m5.2.2"></divide><apply id="A0.I2.i3.p1.5.m5.2.2.2.cmml" xref="A0.I2.i3.p1.5.m5.2.2.2"><times id="A0.I2.i3.p1.5.m5.2.2.2.3.cmml" xref="A0.I2.i3.p1.5.m5.2.2.2.3"></times><ci id="A0.I2.i3.p1.5.m5.2.2.2.4.cmml" xref="A0.I2.i3.p1.5.m5.2.2.2.4">𝐿</ci><ci id="A0.I2.i3.p1.5.m5.2.2.2.5.cmml" xref="A0.I2.i3.p1.5.m5.2.2.2.5">𝐶</ci><ci id="A0.I2.i3.p1.5.m5.2.2.2.6.cmml" xref="A0.I2.i3.p1.5.m5.2.2.2.6">𝑆</ci><interval closure="open" id="A0.I2.i3.p1.5.m5.2.2.2.7.1.cmml" xref="A0.I2.i3.p1.5.m5.2.2.2.7.2"><ci id="A0.I2.i3.p1.5.m5.1.1.1.1.cmml" xref="A0.I2.i3.p1.5.m5.1.1.1.1">𝑋</ci><ci id="A0.I2.i3.p1.5.m5.2.2.2.2.cmml" xref="A0.I2.i3.p1.5.m5.2.2.2.2">𝑌</ci></interval></apply><ci id="A0.I2.i3.p1.5.m5.2.2.4.cmml" xref="A0.I2.i3.p1.5.m5.2.2.4">𝑚</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A0.I2.i3.p1.5.m5.2c">R_{LCS}=\frac{LCS(X,Y)}{m}</annotation><annotation encoding="application/x-llamapun" id="A0.I2.i3.p1.5.m5.2d">italic_R start_POSTSUBSCRIPT italic_L italic_C italic_S end_POSTSUBSCRIPT = divide start_ARG italic_L italic_C italic_S ( italic_X , italic_Y ) end_ARG start_ARG italic_m end_ARG</annotation></semantics></math> and <math alttext="P_{LCS}=\frac{LCS(X,Y)}{n}" class="ltx_Math" display="inline" id="A0.I2.i3.p1.6.m6.2"><semantics id="A0.I2.i3.p1.6.m6.2a"><mrow id="A0.I2.i3.p1.6.m6.2.3" xref="A0.I2.i3.p1.6.m6.2.3.cmml"><msub id="A0.I2.i3.p1.6.m6.2.3.2" xref="A0.I2.i3.p1.6.m6.2.3.2.cmml"><mi id="A0.I2.i3.p1.6.m6.2.3.2.2" xref="A0.I2.i3.p1.6.m6.2.3.2.2.cmml">P</mi><mrow id="A0.I2.i3.p1.6.m6.2.3.2.3" xref="A0.I2.i3.p1.6.m6.2.3.2.3.cmml"><mi id="A0.I2.i3.p1.6.m6.2.3.2.3.2" xref="A0.I2.i3.p1.6.m6.2.3.2.3.2.cmml">L</mi><mo id="A0.I2.i3.p1.6.m6.2.3.2.3.1" xref="A0.I2.i3.p1.6.m6.2.3.2.3.1.cmml">⁢</mo><mi id="A0.I2.i3.p1.6.m6.2.3.2.3.3" xref="A0.I2.i3.p1.6.m6.2.3.2.3.3.cmml">C</mi><mo id="A0.I2.i3.p1.6.m6.2.3.2.3.1a" xref="A0.I2.i3.p1.6.m6.2.3.2.3.1.cmml">⁢</mo><mi id="A0.I2.i3.p1.6.m6.2.3.2.3.4" xref="A0.I2.i3.p1.6.m6.2.3.2.3.4.cmml">S</mi></mrow></msub><mo id="A0.I2.i3.p1.6.m6.2.3.1" xref="A0.I2.i3.p1.6.m6.2.3.1.cmml">=</mo><mfrac id="A0.I2.i3.p1.6.m6.2.2" xref="A0.I2.i3.p1.6.m6.2.2.cmml"><mrow id="A0.I2.i3.p1.6.m6.2.2.2" xref="A0.I2.i3.p1.6.m6.2.2.2.cmml"><mi id="A0.I2.i3.p1.6.m6.2.2.2.4" xref="A0.I2.i3.p1.6.m6.2.2.2.4.cmml">L</mi><mo id="A0.I2.i3.p1.6.m6.2.2.2.3" xref="A0.I2.i3.p1.6.m6.2.2.2.3.cmml">⁢</mo><mi id="A0.I2.i3.p1.6.m6.2.2.2.5" xref="A0.I2.i3.p1.6.m6.2.2.2.5.cmml">C</mi><mo id="A0.I2.i3.p1.6.m6.2.2.2.3a" xref="A0.I2.i3.p1.6.m6.2.2.2.3.cmml">⁢</mo><mi id="A0.I2.i3.p1.6.m6.2.2.2.6" xref="A0.I2.i3.p1.6.m6.2.2.2.6.cmml">S</mi><mo id="A0.I2.i3.p1.6.m6.2.2.2.3b" xref="A0.I2.i3.p1.6.m6.2.2.2.3.cmml">⁢</mo><mrow id="A0.I2.i3.p1.6.m6.2.2.2.7.2" xref="A0.I2.i3.p1.6.m6.2.2.2.7.1.cmml"><mo id="A0.I2.i3.p1.6.m6.2.2.2.7.2.1" stretchy="false" xref="A0.I2.i3.p1.6.m6.2.2.2.7.1.cmml">(</mo><mi id="A0.I2.i3.p1.6.m6.1.1.1.1" xref="A0.I2.i3.p1.6.m6.1.1.1.1.cmml">X</mi><mo id="A0.I2.i3.p1.6.m6.2.2.2.7.2.2" xref="A0.I2.i3.p1.6.m6.2.2.2.7.1.cmml">,</mo><mi id="A0.I2.i3.p1.6.m6.2.2.2.2" xref="A0.I2.i3.p1.6.m6.2.2.2.2.cmml">Y</mi><mo id="A0.I2.i3.p1.6.m6.2.2.2.7.2.3" stretchy="false" xref="A0.I2.i3.p1.6.m6.2.2.2.7.1.cmml">)</mo></mrow></mrow><mi id="A0.I2.i3.p1.6.m6.2.2.4" xref="A0.I2.i3.p1.6.m6.2.2.4.cmml">n</mi></mfrac></mrow><annotation-xml encoding="MathML-Content" id="A0.I2.i3.p1.6.m6.2b"><apply id="A0.I2.i3.p1.6.m6.2.3.cmml" xref="A0.I2.i3.p1.6.m6.2.3"><eq id="A0.I2.i3.p1.6.m6.2.3.1.cmml" xref="A0.I2.i3.p1.6.m6.2.3.1"></eq><apply id="A0.I2.i3.p1.6.m6.2.3.2.cmml" xref="A0.I2.i3.p1.6.m6.2.3.2"><csymbol cd="ambiguous" id="A0.I2.i3.p1.6.m6.2.3.2.1.cmml" xref="A0.I2.i3.p1.6.m6.2.3.2">subscript</csymbol><ci id="A0.I2.i3.p1.6.m6.2.3.2.2.cmml" xref="A0.I2.i3.p1.6.m6.2.3.2.2">𝑃</ci><apply id="A0.I2.i3.p1.6.m6.2.3.2.3.cmml" xref="A0.I2.i3.p1.6.m6.2.3.2.3"><times id="A0.I2.i3.p1.6.m6.2.3.2.3.1.cmml" xref="A0.I2.i3.p1.6.m6.2.3.2.3.1"></times><ci id="A0.I2.i3.p1.6.m6.2.3.2.3.2.cmml" xref="A0.I2.i3.p1.6.m6.2.3.2.3.2">𝐿</ci><ci id="A0.I2.i3.p1.6.m6.2.3.2.3.3.cmml" xref="A0.I2.i3.p1.6.m6.2.3.2.3.3">𝐶</ci><ci id="A0.I2.i3.p1.6.m6.2.3.2.3.4.cmml" xref="A0.I2.i3.p1.6.m6.2.3.2.3.4">𝑆</ci></apply></apply><apply id="A0.I2.i3.p1.6.m6.2.2.cmml" xref="A0.I2.i3.p1.6.m6.2.2"><divide id="A0.I2.i3.p1.6.m6.2.2.3.cmml" xref="A0.I2.i3.p1.6.m6.2.2"></divide><apply id="A0.I2.i3.p1.6.m6.2.2.2.cmml" xref="A0.I2.i3.p1.6.m6.2.2.2"><times id="A0.I2.i3.p1.6.m6.2.2.2.3.cmml" xref="A0.I2.i3.p1.6.m6.2.2.2.3"></times><ci id="A0.I2.i3.p1.6.m6.2.2.2.4.cmml" xref="A0.I2.i3.p1.6.m6.2.2.2.4">𝐿</ci><ci id="A0.I2.i3.p1.6.m6.2.2.2.5.cmml" xref="A0.I2.i3.p1.6.m6.2.2.2.5">𝐶</ci><ci id="A0.I2.i3.p1.6.m6.2.2.2.6.cmml" xref="A0.I2.i3.p1.6.m6.2.2.2.6">𝑆</ci><interval closure="open" id="A0.I2.i3.p1.6.m6.2.2.2.7.1.cmml" xref="A0.I2.i3.p1.6.m6.2.2.2.7.2"><ci id="A0.I2.i3.p1.6.m6.1.1.1.1.cmml" xref="A0.I2.i3.p1.6.m6.1.1.1.1">𝑋</ci><ci id="A0.I2.i3.p1.6.m6.2.2.2.2.cmml" xref="A0.I2.i3.p1.6.m6.2.2.2.2">𝑌</ci></interval></apply><ci id="A0.I2.i3.p1.6.m6.2.2.4.cmml" xref="A0.I2.i3.p1.6.m6.2.2.4">𝑛</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A0.I2.i3.p1.6.m6.2c">P_{LCS}=\frac{LCS(X,Y)}{n}</annotation><annotation encoding="application/x-llamapun" id="A0.I2.i3.p1.6.m6.2d">italic_P start_POSTSUBSCRIPT italic_L italic_C italic_S end_POSTSUBSCRIPT = divide start_ARG italic_L italic_C italic_S ( italic_X , italic_Y ) end_ARG start_ARG italic_n end_ARG</annotation></semantics></math>, where <math alttext="LCS(X,Y)" class="ltx_Math" display="inline" id="A0.I2.i3.p1.7.m7.2"><semantics id="A0.I2.i3.p1.7.m7.2a"><mrow id="A0.I2.i3.p1.7.m7.2.3" xref="A0.I2.i3.p1.7.m7.2.3.cmml"><mi id="A0.I2.i3.p1.7.m7.2.3.2" xref="A0.I2.i3.p1.7.m7.2.3.2.cmml">L</mi><mo id="A0.I2.i3.p1.7.m7.2.3.1" xref="A0.I2.i3.p1.7.m7.2.3.1.cmml">⁢</mo><mi id="A0.I2.i3.p1.7.m7.2.3.3" xref="A0.I2.i3.p1.7.m7.2.3.3.cmml">C</mi><mo id="A0.I2.i3.p1.7.m7.2.3.1a" xref="A0.I2.i3.p1.7.m7.2.3.1.cmml">⁢</mo><mi id="A0.I2.i3.p1.7.m7.2.3.4" xref="A0.I2.i3.p1.7.m7.2.3.4.cmml">S</mi><mo id="A0.I2.i3.p1.7.m7.2.3.1b" xref="A0.I2.i3.p1.7.m7.2.3.1.cmml">⁢</mo><mrow id="A0.I2.i3.p1.7.m7.2.3.5.2" xref="A0.I2.i3.p1.7.m7.2.3.5.1.cmml"><mo id="A0.I2.i3.p1.7.m7.2.3.5.2.1" stretchy="false" xref="A0.I2.i3.p1.7.m7.2.3.5.1.cmml">(</mo><mi id="A0.I2.i3.p1.7.m7.1.1" xref="A0.I2.i3.p1.7.m7.1.1.cmml">X</mi><mo id="A0.I2.i3.p1.7.m7.2.3.5.2.2" xref="A0.I2.i3.p1.7.m7.2.3.5.1.cmml">,</mo><mi id="A0.I2.i3.p1.7.m7.2.2" xref="A0.I2.i3.p1.7.m7.2.2.cmml">Y</mi><mo id="A0.I2.i3.p1.7.m7.2.3.5.2.3" stretchy="false" xref="A0.I2.i3.p1.7.m7.2.3.5.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A0.I2.i3.p1.7.m7.2b"><apply id="A0.I2.i3.p1.7.m7.2.3.cmml" xref="A0.I2.i3.p1.7.m7.2.3"><times id="A0.I2.i3.p1.7.m7.2.3.1.cmml" xref="A0.I2.i3.p1.7.m7.2.3.1"></times><ci id="A0.I2.i3.p1.7.m7.2.3.2.cmml" xref="A0.I2.i3.p1.7.m7.2.3.2">𝐿</ci><ci id="A0.I2.i3.p1.7.m7.2.3.3.cmml" xref="A0.I2.i3.p1.7.m7.2.3.3">𝐶</ci><ci id="A0.I2.i3.p1.7.m7.2.3.4.cmml" xref="A0.I2.i3.p1.7.m7.2.3.4">𝑆</ci><interval closure="open" id="A0.I2.i3.p1.7.m7.2.3.5.1.cmml" xref="A0.I2.i3.p1.7.m7.2.3.5.2"><ci id="A0.I2.i3.p1.7.m7.1.1.cmml" xref="A0.I2.i3.p1.7.m7.1.1">𝑋</ci><ci id="A0.I2.i3.p1.7.m7.2.2.cmml" xref="A0.I2.i3.p1.7.m7.2.2">𝑌</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="A0.I2.i3.p1.7.m7.2c">LCS(X,Y)</annotation><annotation encoding="application/x-llamapun" id="A0.I2.i3.p1.7.m7.2d">italic_L italic_C italic_S ( italic_X , italic_Y )</annotation></semantics></math> is the length of the longest common subsequence of X and Y. Then, ROGUE score can be computed as <math alttext="ROGUE_{L}" class="ltx_Math" display="inline" id="A0.I2.i3.p1.8.m8.1"><semantics id="A0.I2.i3.p1.8.m8.1a"><mrow id="A0.I2.i3.p1.8.m8.1.1" xref="A0.I2.i3.p1.8.m8.1.1.cmml"><mi id="A0.I2.i3.p1.8.m8.1.1.2" xref="A0.I2.i3.p1.8.m8.1.1.2.cmml">R</mi><mo id="A0.I2.i3.p1.8.m8.1.1.1" xref="A0.I2.i3.p1.8.m8.1.1.1.cmml">⁢</mo><mi id="A0.I2.i3.p1.8.m8.1.1.3" xref="A0.I2.i3.p1.8.m8.1.1.3.cmml">O</mi><mo id="A0.I2.i3.p1.8.m8.1.1.1a" xref="A0.I2.i3.p1.8.m8.1.1.1.cmml">⁢</mo><mi id="A0.I2.i3.p1.8.m8.1.1.4" xref="A0.I2.i3.p1.8.m8.1.1.4.cmml">G</mi><mo id="A0.I2.i3.p1.8.m8.1.1.1b" xref="A0.I2.i3.p1.8.m8.1.1.1.cmml">⁢</mo><mi id="A0.I2.i3.p1.8.m8.1.1.5" xref="A0.I2.i3.p1.8.m8.1.1.5.cmml">U</mi><mo id="A0.I2.i3.p1.8.m8.1.1.1c" xref="A0.I2.i3.p1.8.m8.1.1.1.cmml">⁢</mo><msub id="A0.I2.i3.p1.8.m8.1.1.6" xref="A0.I2.i3.p1.8.m8.1.1.6.cmml"><mi id="A0.I2.i3.p1.8.m8.1.1.6.2" xref="A0.I2.i3.p1.8.m8.1.1.6.2.cmml">E</mi><mi id="A0.I2.i3.p1.8.m8.1.1.6.3" xref="A0.I2.i3.p1.8.m8.1.1.6.3.cmml">L</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="A0.I2.i3.p1.8.m8.1b"><apply id="A0.I2.i3.p1.8.m8.1.1.cmml" xref="A0.I2.i3.p1.8.m8.1.1"><times id="A0.I2.i3.p1.8.m8.1.1.1.cmml" xref="A0.I2.i3.p1.8.m8.1.1.1"></times><ci id="A0.I2.i3.p1.8.m8.1.1.2.cmml" xref="A0.I2.i3.p1.8.m8.1.1.2">𝑅</ci><ci id="A0.I2.i3.p1.8.m8.1.1.3.cmml" xref="A0.I2.i3.p1.8.m8.1.1.3">𝑂</ci><ci id="A0.I2.i3.p1.8.m8.1.1.4.cmml" xref="A0.I2.i3.p1.8.m8.1.1.4">𝐺</ci><ci id="A0.I2.i3.p1.8.m8.1.1.5.cmml" xref="A0.I2.i3.p1.8.m8.1.1.5">𝑈</ci><apply id="A0.I2.i3.p1.8.m8.1.1.6.cmml" xref="A0.I2.i3.p1.8.m8.1.1.6"><csymbol cd="ambiguous" id="A0.I2.i3.p1.8.m8.1.1.6.1.cmml" xref="A0.I2.i3.p1.8.m8.1.1.6">subscript</csymbol><ci id="A0.I2.i3.p1.8.m8.1.1.6.2.cmml" xref="A0.I2.i3.p1.8.m8.1.1.6.2">𝐸</ci><ci id="A0.I2.i3.p1.8.m8.1.1.6.3.cmml" xref="A0.I2.i3.p1.8.m8.1.1.6.3">𝐿</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A0.I2.i3.p1.8.m8.1c">ROGUE_{L}</annotation><annotation encoding="application/x-llamapun" id="A0.I2.i3.p1.8.m8.1d">italic_R italic_O italic_G italic_U italic_E start_POSTSUBSCRIPT italic_L end_POSTSUBSCRIPT</annotation></semantics></math> = <math alttext="\frac{(1+\beta^{2})R_{LCS}*P_{LCS}}{R_{LCS}+\beta^{2}*P_{LCS}}" class="ltx_Math" display="inline" id="A0.I2.i3.p1.9.m9.1"><semantics id="A0.I2.i3.p1.9.m9.1a"><mfrac id="A0.I2.i3.p1.9.m9.1.1" xref="A0.I2.i3.p1.9.m9.1.1.cmml"><mrow id="A0.I2.i3.p1.9.m9.1.1.1" xref="A0.I2.i3.p1.9.m9.1.1.1.cmml"><mrow id="A0.I2.i3.p1.9.m9.1.1.1.1" xref="A0.I2.i3.p1.9.m9.1.1.1.1.cmml"><mrow id="A0.I2.i3.p1.9.m9.1.1.1.1.1.1" xref="A0.I2.i3.p1.9.m9.1.1.1.1.1.1.1.cmml"><mo id="A0.I2.i3.p1.9.m9.1.1.1.1.1.1.2" stretchy="false" xref="A0.I2.i3.p1.9.m9.1.1.1.1.1.1.1.cmml">(</mo><mrow id="A0.I2.i3.p1.9.m9.1.1.1.1.1.1.1" xref="A0.I2.i3.p1.9.m9.1.1.1.1.1.1.1.cmml"><mn id="A0.I2.i3.p1.9.m9.1.1.1.1.1.1.1.2" xref="A0.I2.i3.p1.9.m9.1.1.1.1.1.1.1.2.cmml">1</mn><mo id="A0.I2.i3.p1.9.m9.1.1.1.1.1.1.1.1" xref="A0.I2.i3.p1.9.m9.1.1.1.1.1.1.1.1.cmml">+</mo><msup id="A0.I2.i3.p1.9.m9.1.1.1.1.1.1.1.3" xref="A0.I2.i3.p1.9.m9.1.1.1.1.1.1.1.3.cmml"><mi id="A0.I2.i3.p1.9.m9.1.1.1.1.1.1.1.3.2" xref="A0.I2.i3.p1.9.m9.1.1.1.1.1.1.1.3.2.cmml">β</mi><mn id="A0.I2.i3.p1.9.m9.1.1.1.1.1.1.1.3.3" xref="A0.I2.i3.p1.9.m9.1.1.1.1.1.1.1.3.3.cmml">2</mn></msup></mrow><mo id="A0.I2.i3.p1.9.m9.1.1.1.1.1.1.3" stretchy="false" xref="A0.I2.i3.p1.9.m9.1.1.1.1.1.1.1.cmml">)</mo></mrow><mo id="A0.I2.i3.p1.9.m9.1.1.1.1.2" xref="A0.I2.i3.p1.9.m9.1.1.1.1.2.cmml">⁢</mo><msub id="A0.I2.i3.p1.9.m9.1.1.1.1.3" xref="A0.I2.i3.p1.9.m9.1.1.1.1.3.cmml"><mi id="A0.I2.i3.p1.9.m9.1.1.1.1.3.2" xref="A0.I2.i3.p1.9.m9.1.1.1.1.3.2.cmml">R</mi><mrow id="A0.I2.i3.p1.9.m9.1.1.1.1.3.3" xref="A0.I2.i3.p1.9.m9.1.1.1.1.3.3.cmml"><mi id="A0.I2.i3.p1.9.m9.1.1.1.1.3.3.2" xref="A0.I2.i3.p1.9.m9.1.1.1.1.3.3.2.cmml">L</mi><mo id="A0.I2.i3.p1.9.m9.1.1.1.1.3.3.1" xref="A0.I2.i3.p1.9.m9.1.1.1.1.3.3.1.cmml">⁢</mo><mi id="A0.I2.i3.p1.9.m9.1.1.1.1.3.3.3" xref="A0.I2.i3.p1.9.m9.1.1.1.1.3.3.3.cmml">C</mi><mo id="A0.I2.i3.p1.9.m9.1.1.1.1.3.3.1a" xref="A0.I2.i3.p1.9.m9.1.1.1.1.3.3.1.cmml">⁢</mo><mi id="A0.I2.i3.p1.9.m9.1.1.1.1.3.3.4" xref="A0.I2.i3.p1.9.m9.1.1.1.1.3.3.4.cmml">S</mi></mrow></msub></mrow><mo id="A0.I2.i3.p1.9.m9.1.1.1.2" lspace="0.222em" rspace="0.222em" xref="A0.I2.i3.p1.9.m9.1.1.1.2.cmml">∗</mo><msub id="A0.I2.i3.p1.9.m9.1.1.1.3" xref="A0.I2.i3.p1.9.m9.1.1.1.3.cmml"><mi id="A0.I2.i3.p1.9.m9.1.1.1.3.2" xref="A0.I2.i3.p1.9.m9.1.1.1.3.2.cmml">P</mi><mrow id="A0.I2.i3.p1.9.m9.1.1.1.3.3" xref="A0.I2.i3.p1.9.m9.1.1.1.3.3.cmml"><mi id="A0.I2.i3.p1.9.m9.1.1.1.3.3.2" xref="A0.I2.i3.p1.9.m9.1.1.1.3.3.2.cmml">L</mi><mo id="A0.I2.i3.p1.9.m9.1.1.1.3.3.1" xref="A0.I2.i3.p1.9.m9.1.1.1.3.3.1.cmml">⁢</mo><mi id="A0.I2.i3.p1.9.m9.1.1.1.3.3.3" xref="A0.I2.i3.p1.9.m9.1.1.1.3.3.3.cmml">C</mi><mo id="A0.I2.i3.p1.9.m9.1.1.1.3.3.1a" xref="A0.I2.i3.p1.9.m9.1.1.1.3.3.1.cmml">⁢</mo><mi id="A0.I2.i3.p1.9.m9.1.1.1.3.3.4" xref="A0.I2.i3.p1.9.m9.1.1.1.3.3.4.cmml">S</mi></mrow></msub></mrow><mrow id="A0.I2.i3.p1.9.m9.1.1.3" xref="A0.I2.i3.p1.9.m9.1.1.3.cmml"><msub id="A0.I2.i3.p1.9.m9.1.1.3.2" xref="A0.I2.i3.p1.9.m9.1.1.3.2.cmml"><mi id="A0.I2.i3.p1.9.m9.1.1.3.2.2" xref="A0.I2.i3.p1.9.m9.1.1.3.2.2.cmml">R</mi><mrow id="A0.I2.i3.p1.9.m9.1.1.3.2.3" xref="A0.I2.i3.p1.9.m9.1.1.3.2.3.cmml"><mi id="A0.I2.i3.p1.9.m9.1.1.3.2.3.2" xref="A0.I2.i3.p1.9.m9.1.1.3.2.3.2.cmml">L</mi><mo id="A0.I2.i3.p1.9.m9.1.1.3.2.3.1" xref="A0.I2.i3.p1.9.m9.1.1.3.2.3.1.cmml">⁢</mo><mi id="A0.I2.i3.p1.9.m9.1.1.3.2.3.3" xref="A0.I2.i3.p1.9.m9.1.1.3.2.3.3.cmml">C</mi><mo id="A0.I2.i3.p1.9.m9.1.1.3.2.3.1a" xref="A0.I2.i3.p1.9.m9.1.1.3.2.3.1.cmml">⁢</mo><mi id="A0.I2.i3.p1.9.m9.1.1.3.2.3.4" xref="A0.I2.i3.p1.9.m9.1.1.3.2.3.4.cmml">S</mi></mrow></msub><mo id="A0.I2.i3.p1.9.m9.1.1.3.1" xref="A0.I2.i3.p1.9.m9.1.1.3.1.cmml">+</mo><mrow id="A0.I2.i3.p1.9.m9.1.1.3.3" xref="A0.I2.i3.p1.9.m9.1.1.3.3.cmml"><msup id="A0.I2.i3.p1.9.m9.1.1.3.3.2" xref="A0.I2.i3.p1.9.m9.1.1.3.3.2.cmml"><mi id="A0.I2.i3.p1.9.m9.1.1.3.3.2.2" xref="A0.I2.i3.p1.9.m9.1.1.3.3.2.2.cmml">β</mi><mn id="A0.I2.i3.p1.9.m9.1.1.3.3.2.3" xref="A0.I2.i3.p1.9.m9.1.1.3.3.2.3.cmml">2</mn></msup><mo id="A0.I2.i3.p1.9.m9.1.1.3.3.1" lspace="0.222em" rspace="0.222em" xref="A0.I2.i3.p1.9.m9.1.1.3.3.1.cmml">∗</mo><msub id="A0.I2.i3.p1.9.m9.1.1.3.3.3" xref="A0.I2.i3.p1.9.m9.1.1.3.3.3.cmml"><mi id="A0.I2.i3.p1.9.m9.1.1.3.3.3.2" xref="A0.I2.i3.p1.9.m9.1.1.3.3.3.2.cmml">P</mi><mrow id="A0.I2.i3.p1.9.m9.1.1.3.3.3.3" xref="A0.I2.i3.p1.9.m9.1.1.3.3.3.3.cmml"><mi id="A0.I2.i3.p1.9.m9.1.1.3.3.3.3.2" xref="A0.I2.i3.p1.9.m9.1.1.3.3.3.3.2.cmml">L</mi><mo id="A0.I2.i3.p1.9.m9.1.1.3.3.3.3.1" xref="A0.I2.i3.p1.9.m9.1.1.3.3.3.3.1.cmml">⁢</mo><mi id="A0.I2.i3.p1.9.m9.1.1.3.3.3.3.3" xref="A0.I2.i3.p1.9.m9.1.1.3.3.3.3.3.cmml">C</mi><mo id="A0.I2.i3.p1.9.m9.1.1.3.3.3.3.1a" xref="A0.I2.i3.p1.9.m9.1.1.3.3.3.3.1.cmml">⁢</mo><mi id="A0.I2.i3.p1.9.m9.1.1.3.3.3.3.4" xref="A0.I2.i3.p1.9.m9.1.1.3.3.3.3.4.cmml">S</mi></mrow></msub></mrow></mrow></mfrac><annotation-xml encoding="MathML-Content" id="A0.I2.i3.p1.9.m9.1b"><apply id="A0.I2.i3.p1.9.m9.1.1.cmml" xref="A0.I2.i3.p1.9.m9.1.1"><divide id="A0.I2.i3.p1.9.m9.1.1.2.cmml" xref="A0.I2.i3.p1.9.m9.1.1"></divide><apply id="A0.I2.i3.p1.9.m9.1.1.1.cmml" xref="A0.I2.i3.p1.9.m9.1.1.1"><times id="A0.I2.i3.p1.9.m9.1.1.1.2.cmml" xref="A0.I2.i3.p1.9.m9.1.1.1.2"></times><apply id="A0.I2.i3.p1.9.m9.1.1.1.1.cmml" xref="A0.I2.i3.p1.9.m9.1.1.1.1"><times id="A0.I2.i3.p1.9.m9.1.1.1.1.2.cmml" xref="A0.I2.i3.p1.9.m9.1.1.1.1.2"></times><apply id="A0.I2.i3.p1.9.m9.1.1.1.1.1.1.1.cmml" xref="A0.I2.i3.p1.9.m9.1.1.1.1.1.1"><plus id="A0.I2.i3.p1.9.m9.1.1.1.1.1.1.1.1.cmml" xref="A0.I2.i3.p1.9.m9.1.1.1.1.1.1.1.1"></plus><cn id="A0.I2.i3.p1.9.m9.1.1.1.1.1.1.1.2.cmml" type="integer" xref="A0.I2.i3.p1.9.m9.1.1.1.1.1.1.1.2">1</cn><apply id="A0.I2.i3.p1.9.m9.1.1.1.1.1.1.1.3.cmml" xref="A0.I2.i3.p1.9.m9.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="A0.I2.i3.p1.9.m9.1.1.1.1.1.1.1.3.1.cmml" xref="A0.I2.i3.p1.9.m9.1.1.1.1.1.1.1.3">superscript</csymbol><ci id="A0.I2.i3.p1.9.m9.1.1.1.1.1.1.1.3.2.cmml" xref="A0.I2.i3.p1.9.m9.1.1.1.1.1.1.1.3.2">𝛽</ci><cn id="A0.I2.i3.p1.9.m9.1.1.1.1.1.1.1.3.3.cmml" type="integer" xref="A0.I2.i3.p1.9.m9.1.1.1.1.1.1.1.3.3">2</cn></apply></apply><apply id="A0.I2.i3.p1.9.m9.1.1.1.1.3.cmml" xref="A0.I2.i3.p1.9.m9.1.1.1.1.3"><csymbol cd="ambiguous" id="A0.I2.i3.p1.9.m9.1.1.1.1.3.1.cmml" xref="A0.I2.i3.p1.9.m9.1.1.1.1.3">subscript</csymbol><ci id="A0.I2.i3.p1.9.m9.1.1.1.1.3.2.cmml" xref="A0.I2.i3.p1.9.m9.1.1.1.1.3.2">𝑅</ci><apply id="A0.I2.i3.p1.9.m9.1.1.1.1.3.3.cmml" xref="A0.I2.i3.p1.9.m9.1.1.1.1.3.3"><times id="A0.I2.i3.p1.9.m9.1.1.1.1.3.3.1.cmml" xref="A0.I2.i3.p1.9.m9.1.1.1.1.3.3.1"></times><ci id="A0.I2.i3.p1.9.m9.1.1.1.1.3.3.2.cmml" xref="A0.I2.i3.p1.9.m9.1.1.1.1.3.3.2">𝐿</ci><ci id="A0.I2.i3.p1.9.m9.1.1.1.1.3.3.3.cmml" xref="A0.I2.i3.p1.9.m9.1.1.1.1.3.3.3">𝐶</ci><ci id="A0.I2.i3.p1.9.m9.1.1.1.1.3.3.4.cmml" xref="A0.I2.i3.p1.9.m9.1.1.1.1.3.3.4">𝑆</ci></apply></apply></apply><apply id="A0.I2.i3.p1.9.m9.1.1.1.3.cmml" xref="A0.I2.i3.p1.9.m9.1.1.1.3"><csymbol cd="ambiguous" id="A0.I2.i3.p1.9.m9.1.1.1.3.1.cmml" xref="A0.I2.i3.p1.9.m9.1.1.1.3">subscript</csymbol><ci id="A0.I2.i3.p1.9.m9.1.1.1.3.2.cmml" xref="A0.I2.i3.p1.9.m9.1.1.1.3.2">𝑃</ci><apply id="A0.I2.i3.p1.9.m9.1.1.1.3.3.cmml" xref="A0.I2.i3.p1.9.m9.1.1.1.3.3"><times id="A0.I2.i3.p1.9.m9.1.1.1.3.3.1.cmml" xref="A0.I2.i3.p1.9.m9.1.1.1.3.3.1"></times><ci id="A0.I2.i3.p1.9.m9.1.1.1.3.3.2.cmml" xref="A0.I2.i3.p1.9.m9.1.1.1.3.3.2">𝐿</ci><ci id="A0.I2.i3.p1.9.m9.1.1.1.3.3.3.cmml" xref="A0.I2.i3.p1.9.m9.1.1.1.3.3.3">𝐶</ci><ci id="A0.I2.i3.p1.9.m9.1.1.1.3.3.4.cmml" xref="A0.I2.i3.p1.9.m9.1.1.1.3.3.4">𝑆</ci></apply></apply></apply><apply id="A0.I2.i3.p1.9.m9.1.1.3.cmml" xref="A0.I2.i3.p1.9.m9.1.1.3"><plus id="A0.I2.i3.p1.9.m9.1.1.3.1.cmml" xref="A0.I2.i3.p1.9.m9.1.1.3.1"></plus><apply id="A0.I2.i3.p1.9.m9.1.1.3.2.cmml" xref="A0.I2.i3.p1.9.m9.1.1.3.2"><csymbol cd="ambiguous" id="A0.I2.i3.p1.9.m9.1.1.3.2.1.cmml" xref="A0.I2.i3.p1.9.m9.1.1.3.2">subscript</csymbol><ci id="A0.I2.i3.p1.9.m9.1.1.3.2.2.cmml" xref="A0.I2.i3.p1.9.m9.1.1.3.2.2">𝑅</ci><apply id="A0.I2.i3.p1.9.m9.1.1.3.2.3.cmml" xref="A0.I2.i3.p1.9.m9.1.1.3.2.3"><times id="A0.I2.i3.p1.9.m9.1.1.3.2.3.1.cmml" xref="A0.I2.i3.p1.9.m9.1.1.3.2.3.1"></times><ci id="A0.I2.i3.p1.9.m9.1.1.3.2.3.2.cmml" xref="A0.I2.i3.p1.9.m9.1.1.3.2.3.2">𝐿</ci><ci id="A0.I2.i3.p1.9.m9.1.1.3.2.3.3.cmml" xref="A0.I2.i3.p1.9.m9.1.1.3.2.3.3">𝐶</ci><ci id="A0.I2.i3.p1.9.m9.1.1.3.2.3.4.cmml" xref="A0.I2.i3.p1.9.m9.1.1.3.2.3.4">𝑆</ci></apply></apply><apply id="A0.I2.i3.p1.9.m9.1.1.3.3.cmml" xref="A0.I2.i3.p1.9.m9.1.1.3.3"><times id="A0.I2.i3.p1.9.m9.1.1.3.3.1.cmml" xref="A0.I2.i3.p1.9.m9.1.1.3.3.1"></times><apply id="A0.I2.i3.p1.9.m9.1.1.3.3.2.cmml" xref="A0.I2.i3.p1.9.m9.1.1.3.3.2"><csymbol cd="ambiguous" id="A0.I2.i3.p1.9.m9.1.1.3.3.2.1.cmml" xref="A0.I2.i3.p1.9.m9.1.1.3.3.2">superscript</csymbol><ci id="A0.I2.i3.p1.9.m9.1.1.3.3.2.2.cmml" xref="A0.I2.i3.p1.9.m9.1.1.3.3.2.2">𝛽</ci><cn id="A0.I2.i3.p1.9.m9.1.1.3.3.2.3.cmml" type="integer" xref="A0.I2.i3.p1.9.m9.1.1.3.3.2.3">2</cn></apply><apply id="A0.I2.i3.p1.9.m9.1.1.3.3.3.cmml" xref="A0.I2.i3.p1.9.m9.1.1.3.3.3"><csymbol cd="ambiguous" id="A0.I2.i3.p1.9.m9.1.1.3.3.3.1.cmml" xref="A0.I2.i3.p1.9.m9.1.1.3.3.3">subscript</csymbol><ci id="A0.I2.i3.p1.9.m9.1.1.3.3.3.2.cmml" xref="A0.I2.i3.p1.9.m9.1.1.3.3.3.2">𝑃</ci><apply id="A0.I2.i3.p1.9.m9.1.1.3.3.3.3.cmml" xref="A0.I2.i3.p1.9.m9.1.1.3.3.3.3"><times id="A0.I2.i3.p1.9.m9.1.1.3.3.3.3.1.cmml" xref="A0.I2.i3.p1.9.m9.1.1.3.3.3.3.1"></times><ci id="A0.I2.i3.p1.9.m9.1.1.3.3.3.3.2.cmml" xref="A0.I2.i3.p1.9.m9.1.1.3.3.3.3.2">𝐿</ci><ci id="A0.I2.i3.p1.9.m9.1.1.3.3.3.3.3.cmml" xref="A0.I2.i3.p1.9.m9.1.1.3.3.3.3.3">𝐶</ci><ci id="A0.I2.i3.p1.9.m9.1.1.3.3.3.3.4.cmml" xref="A0.I2.i3.p1.9.m9.1.1.3.3.3.3.4">𝑆</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A0.I2.i3.p1.9.m9.1c">\frac{(1+\beta^{2})R_{LCS}*P_{LCS}}{R_{LCS}+\beta^{2}*P_{LCS}}</annotation><annotation encoding="application/x-llamapun" id="A0.I2.i3.p1.9.m9.1d">divide start_ARG ( 1 + italic_β start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) italic_R start_POSTSUBSCRIPT italic_L italic_C italic_S end_POSTSUBSCRIPT ∗ italic_P start_POSTSUBSCRIPT italic_L italic_C italic_S end_POSTSUBSCRIPT end_ARG start_ARG italic_R start_POSTSUBSCRIPT italic_L italic_C italic_S end_POSTSUBSCRIPT + italic_β start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ∗ italic_P start_POSTSUBSCRIPT italic_L italic_C italic_S end_POSTSUBSCRIPT end_ARG</annotation></semantics></math>, where, <math alttext="\beta=\frac{P_{LCS}}{R_{LCS}}" class="ltx_Math" display="inline" id="A0.I2.i3.p1.10.m10.1"><semantics id="A0.I2.i3.p1.10.m10.1a"><mrow id="A0.I2.i3.p1.10.m10.1.1" xref="A0.I2.i3.p1.10.m10.1.1.cmml"><mi id="A0.I2.i3.p1.10.m10.1.1.2" xref="A0.I2.i3.p1.10.m10.1.1.2.cmml">β</mi><mo id="A0.I2.i3.p1.10.m10.1.1.1" xref="A0.I2.i3.p1.10.m10.1.1.1.cmml">=</mo><mfrac id="A0.I2.i3.p1.10.m10.1.1.3" xref="A0.I2.i3.p1.10.m10.1.1.3.cmml"><msub id="A0.I2.i3.p1.10.m10.1.1.3.2" xref="A0.I2.i3.p1.10.m10.1.1.3.2.cmml"><mi id="A0.I2.i3.p1.10.m10.1.1.3.2.2" xref="A0.I2.i3.p1.10.m10.1.1.3.2.2.cmml">P</mi><mrow id="A0.I2.i3.p1.10.m10.1.1.3.2.3" xref="A0.I2.i3.p1.10.m10.1.1.3.2.3.cmml"><mi id="A0.I2.i3.p1.10.m10.1.1.3.2.3.2" xref="A0.I2.i3.p1.10.m10.1.1.3.2.3.2.cmml">L</mi><mo id="A0.I2.i3.p1.10.m10.1.1.3.2.3.1" xref="A0.I2.i3.p1.10.m10.1.1.3.2.3.1.cmml">⁢</mo><mi id="A0.I2.i3.p1.10.m10.1.1.3.2.3.3" xref="A0.I2.i3.p1.10.m10.1.1.3.2.3.3.cmml">C</mi><mo id="A0.I2.i3.p1.10.m10.1.1.3.2.3.1a" xref="A0.I2.i3.p1.10.m10.1.1.3.2.3.1.cmml">⁢</mo><mi id="A0.I2.i3.p1.10.m10.1.1.3.2.3.4" xref="A0.I2.i3.p1.10.m10.1.1.3.2.3.4.cmml">S</mi></mrow></msub><msub id="A0.I2.i3.p1.10.m10.1.1.3.3" xref="A0.I2.i3.p1.10.m10.1.1.3.3.cmml"><mi id="A0.I2.i3.p1.10.m10.1.1.3.3.2" xref="A0.I2.i3.p1.10.m10.1.1.3.3.2.cmml">R</mi><mrow id="A0.I2.i3.p1.10.m10.1.1.3.3.3" xref="A0.I2.i3.p1.10.m10.1.1.3.3.3.cmml"><mi id="A0.I2.i3.p1.10.m10.1.1.3.3.3.2" xref="A0.I2.i3.p1.10.m10.1.1.3.3.3.2.cmml">L</mi><mo id="A0.I2.i3.p1.10.m10.1.1.3.3.3.1" xref="A0.I2.i3.p1.10.m10.1.1.3.3.3.1.cmml">⁢</mo><mi id="A0.I2.i3.p1.10.m10.1.1.3.3.3.3" xref="A0.I2.i3.p1.10.m10.1.1.3.3.3.3.cmml">C</mi><mo id="A0.I2.i3.p1.10.m10.1.1.3.3.3.1a" xref="A0.I2.i3.p1.10.m10.1.1.3.3.3.1.cmml">⁢</mo><mi id="A0.I2.i3.p1.10.m10.1.1.3.3.3.4" xref="A0.I2.i3.p1.10.m10.1.1.3.3.3.4.cmml">S</mi></mrow></msub></mfrac></mrow><annotation-xml encoding="MathML-Content" id="A0.I2.i3.p1.10.m10.1b"><apply id="A0.I2.i3.p1.10.m10.1.1.cmml" xref="A0.I2.i3.p1.10.m10.1.1"><eq id="A0.I2.i3.p1.10.m10.1.1.1.cmml" xref="A0.I2.i3.p1.10.m10.1.1.1"></eq><ci id="A0.I2.i3.p1.10.m10.1.1.2.cmml" xref="A0.I2.i3.p1.10.m10.1.1.2">𝛽</ci><apply id="A0.I2.i3.p1.10.m10.1.1.3.cmml" xref="A0.I2.i3.p1.10.m10.1.1.3"><divide id="A0.I2.i3.p1.10.m10.1.1.3.1.cmml" xref="A0.I2.i3.p1.10.m10.1.1.3"></divide><apply id="A0.I2.i3.p1.10.m10.1.1.3.2.cmml" xref="A0.I2.i3.p1.10.m10.1.1.3.2"><csymbol cd="ambiguous" id="A0.I2.i3.p1.10.m10.1.1.3.2.1.cmml" xref="A0.I2.i3.p1.10.m10.1.1.3.2">subscript</csymbol><ci id="A0.I2.i3.p1.10.m10.1.1.3.2.2.cmml" xref="A0.I2.i3.p1.10.m10.1.1.3.2.2">𝑃</ci><apply id="A0.I2.i3.p1.10.m10.1.1.3.2.3.cmml" xref="A0.I2.i3.p1.10.m10.1.1.3.2.3"><times id="A0.I2.i3.p1.10.m10.1.1.3.2.3.1.cmml" xref="A0.I2.i3.p1.10.m10.1.1.3.2.3.1"></times><ci id="A0.I2.i3.p1.10.m10.1.1.3.2.3.2.cmml" xref="A0.I2.i3.p1.10.m10.1.1.3.2.3.2">𝐿</ci><ci id="A0.I2.i3.p1.10.m10.1.1.3.2.3.3.cmml" xref="A0.I2.i3.p1.10.m10.1.1.3.2.3.3">𝐶</ci><ci id="A0.I2.i3.p1.10.m10.1.1.3.2.3.4.cmml" xref="A0.I2.i3.p1.10.m10.1.1.3.2.3.4">𝑆</ci></apply></apply><apply id="A0.I2.i3.p1.10.m10.1.1.3.3.cmml" xref="A0.I2.i3.p1.10.m10.1.1.3.3"><csymbol cd="ambiguous" id="A0.I2.i3.p1.10.m10.1.1.3.3.1.cmml" xref="A0.I2.i3.p1.10.m10.1.1.3.3">subscript</csymbol><ci id="A0.I2.i3.p1.10.m10.1.1.3.3.2.cmml" xref="A0.I2.i3.p1.10.m10.1.1.3.3.2">𝑅</ci><apply id="A0.I2.i3.p1.10.m10.1.1.3.3.3.cmml" xref="A0.I2.i3.p1.10.m10.1.1.3.3.3"><times id="A0.I2.i3.p1.10.m10.1.1.3.3.3.1.cmml" xref="A0.I2.i3.p1.10.m10.1.1.3.3.3.1"></times><ci id="A0.I2.i3.p1.10.m10.1.1.3.3.3.2.cmml" xref="A0.I2.i3.p1.10.m10.1.1.3.3.3.2">𝐿</ci><ci id="A0.I2.i3.p1.10.m10.1.1.3.3.3.3.cmml" xref="A0.I2.i3.p1.10.m10.1.1.3.3.3.3">𝐶</ci><ci id="A0.I2.i3.p1.10.m10.1.1.3.3.3.4.cmml" xref="A0.I2.i3.p1.10.m10.1.1.3.3.3.4">𝑆</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A0.I2.i3.p1.10.m10.1c">\beta=\frac{P_{LCS}}{R_{LCS}}</annotation><annotation encoding="application/x-llamapun" id="A0.I2.i3.p1.10.m10.1d">italic_β = divide start_ARG italic_P start_POSTSUBSCRIPT italic_L italic_C italic_S end_POSTSUBSCRIPT end_ARG start_ARG italic_R start_POSTSUBSCRIPT italic_L italic_C italic_S end_POSTSUBSCRIPT end_ARG</annotation></semantics></math>.</p>
</div>
</li>
<li class="ltx_item" id="A0.I2.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span>
<div class="ltx_para" id="A0.I2.i4.p1">
<p class="ltx_p" id="A0.I2.i4.p1.1"><span class="ltx_text ltx_font_bold" id="A0.I2.i4.p1.1.1">CPST:</span> The CPST task requires models to predict a real number within the range of 0 to 10. Given a ground truth of true CVSS scores, we compute its difference with the LLM predicted CVSS score and finally compute the average. This is measure of <span class="ltx_text ltx_font_bold" id="A0.I2.i4.p1.1.2">mean absolute deviation (MAD)</span>, that quantifies the average distance between each data point in a set and the mean of that set.</p>
</div>
</li>
</ol>
</div>
</section>
<section class="ltx_subsection" id="A0.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="A0.SS3.5.1.1">-C</span> </span><span class="ltx_text ltx_font_italic" id="A0.SS3.6.2">Prompt templates for evaluation</span>
</h3>
<section class="ltx_subsubsection" id="A0.SS3.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span class="ltx_text" id="A0.SS3.SSS1.5.1.1">-C</span>1 </span>Extraction Task</h4>
<div class="ltx_para" id="A0.SS3.SSS1.p1">
<p class="ltx_p" id="A0.SS3.SSS1.p1.1"><span class="ltx_text ltx_font_bold" id="A0.SS3.SSS1.p1.1.1">Example Prompt (Task: MAET)</span></p>
</div>
<div class="ltx_para ltx_noindent" id="A0.SS3.SSS1.p2">
<svg class="ltx_picture" height="95.48" id="A0.SS3.SSS1.p2.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,95.48) matrix(1 0 0 -1 0 0)"><g fill="#969696" fill-opacity="1.0"><path d="M 0 4.15 L 0 91.32 C 0 93.62 1.86 95.48 4.15 95.48 L 595.85 95.48 C 598.14 95.48 600 93.62 600 91.32 L 600 4.15 C 600 1.86 598.14 0 595.85 0 L 4.15 0 C 1.86 0 0 1.86 0 4.15 Z" style="stroke:none"></path></g><g fill="#E6E6E6" fill-opacity="1.0"><path d="M 0.69 4.15 L 0.69 91.32 C 0.69 93.23 2.24 94.78 4.15 94.78 L 595.85 94.78 C 597.76 94.78 599.31 93.23 599.31 91.32 L 599.31 4.15 C 599.31 2.24 597.76 0.69 595.85 0.69 L 4.15 0.69 C 2.24 0.69 0.69 2.24 0.69 4.15 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 7.61 6.23)"><foreignobject color="#000000" height="83.02" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="584.78">
<span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="A0.SS3.SSS1.p2.pic1.1.1.1.1.1" style="width:422.6pt;">
<span class="ltx_p" id="A0.SS3.SSS1.p2.pic1.1.1.1.1.1.1">For the given question: Which protocol function can be disabled to prevent unauthorized device shutdowns?, and four options: A) DNP3 0x0D, B) HTTP GET, C) SMTP HELO, or D) FTP LIST, pick the best option as the answer, and return as either A, B, C or D. If you do not know the answer, return X. Choose the appropriate letter from A, B, C, D, or X as your answer. Please provide only the letter corresponding to your choice without any additional text or explanations.</span>
</span></foreignobject></g></g></svg>
</div>
<div class="ltx_para" id="A0.SS3.SSS1.p3">
<p class="ltx_p" id="A0.SS3.SSS1.p3.1"><span class="ltx_text ltx_font_bold" id="A0.SS3.SSS1.p3.1.1">Example Prompt (Task: CWET)</span></p>
</div>
<div class="ltx_para ltx_noindent" id="A0.SS3.SSS1.p4">
<svg class="ltx_picture" height="107.77" id="A0.SS3.SSS1.p4.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,107.77) matrix(1 0 0 -1 0 0)"><g fill="#969696" fill-opacity="1.0"><path d="M 0 4.15 L 0 103.62 C 0 105.92 1.86 107.77 4.15 107.77 L 595.85 107.77 C 598.14 107.77 600 105.92 600 103.62 L 600 4.15 C 600 1.86 598.14 0 595.85 0 L 4.15 0 C 1.86 0 0 1.86 0 4.15 Z" style="stroke:none"></path></g><g fill="#E6E6E6" fill-opacity="1.0"><path d="M 0.69 4.15 L 0.69 103.62 C 0.69 105.53 2.24 107.08 4.15 107.08 L 595.85 107.08 C 597.76 107.08 599.31 105.53 599.31 103.62 L 599.31 4.15 C 599.31 2.24 597.76 0.69 595.85 0.69 L 4.15 0.69 C 2.24 0.69 0.69 2.24 0.69 4.15 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 7.61 6.23)"><foreignobject color="#000000" height="95.32" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="584.78">
<span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="A0.SS3.SSS1.p4.pic1.1.1.1.1.1" style="width:422.6pt;">
<span class="ltx_p" id="A0.SS3.SSS1.p4.pic1.1.1.1.1.1.1">For the given question: What is a common method used by attackers to bypass ATA password security?, and four options: A) Using a BIOS exploit, B) Hot swapping the drive, C) Encrypting the drive, or D) Using default passwords, pick the best option as the answer, and return as either A, B, C or D. If you do not know the answer, return X. Choose the appropriate letter from A, B, C, D, or X as your answer. Please provide only the letter corresponding to your choice without any additional text or explanations.</span>
</span></foreignobject></g></g></svg>
</div>
</section>
<section class="ltx_subsubsection" id="A0.SS3.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span class="ltx_text" id="A0.SS3.SSS2.5.1.1">-C</span>2 </span>Understanding Task</h4>
<div class="ltx_para" id="A0.SS3.SSS2.p1">
<p class="ltx_p" id="A0.SS3.SSS2.p1.1"><span class="ltx_text ltx_font_bold" id="A0.SS3.SSS2.p1.1.1">Example Prompt (Task: KCV)</span></p>
</div>
<div class="ltx_para ltx_noindent" id="A0.SS3.SSS2.p2">
<svg class="ltx_picture" height="92.71" id="A0.SS3.SSS2.p2.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,92.71) matrix(1 0 0 -1 0 0)"><g fill="#969696" fill-opacity="1.0"><path d="M 0 4.15 L 0 88.56 C 0 90.85 1.86 92.71 4.15 92.71 L 595.85 92.71 C 598.14 92.71 600 90.85 600 88.56 L 600 4.15 C 600 1.86 598.14 0 595.85 0 L 4.15 0 C 1.86 0 0 1.86 0 4.15 Z" style="stroke:none"></path></g><g fill="#E6E6E6" fill-opacity="1.0"><path d="M 0.69 4.15 L 0.69 88.56 C 0.69 90.47 2.24 92.02 4.15 92.02 L 595.85 92.02 C 597.76 92.02 599.31 90.47 599.31 88.56 L 599.31 4.15 C 599.31 2.24 597.76 0.69 595.85 0.69 L 4.15 0.69 C 2.24 0.69 0.69 2.24 0.69 4.15 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 7.61 6.23)"><foreignobject color="#000000" height="80.25" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="584.78">
<span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="A0.SS3.SSS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1" style="width:422.6pt;">
<span class="ltx_p" id="A0.SS3.SSS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1">You are given the following JSON data as context: <math alttext="JSON\_FILE" class="ltx_Math" display="inline" id="A0.SS3.SSS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1"><semantics id="A0.SS3.SSS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1a"><mrow id="A0.SS3.SSS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1" xref="A0.SS3.SSS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.cmml"><mi id="A0.SS3.SSS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.2" xref="A0.SS3.SSS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.2.cmml">J</mi><mo id="A0.SS3.SSS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.1" xref="A0.SS3.SSS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.1.cmml">⁢</mo><mi id="A0.SS3.SSS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.3" xref="A0.SS3.SSS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.3.cmml">S</mi><mo id="A0.SS3.SSS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.1a" xref="A0.SS3.SSS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.1.cmml">⁢</mo><mi id="A0.SS3.SSS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.4" xref="A0.SS3.SSS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.4.cmml">O</mi><mo id="A0.SS3.SSS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.1b" xref="A0.SS3.SSS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.1.cmml">⁢</mo><mi id="A0.SS3.SSS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.5" xref="A0.SS3.SSS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.5.cmml">N</mi><mo id="A0.SS3.SSS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.1c" xref="A0.SS3.SSS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.1.cmml">⁢</mo><mi id="A0.SS3.SSS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.6" mathvariant="normal" xref="A0.SS3.SSS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.6.cmml">_</mi><mo id="A0.SS3.SSS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.1d" xref="A0.SS3.SSS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.1.cmml">⁢</mo><mi id="A0.SS3.SSS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.7" xref="A0.SS3.SSS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.7.cmml">F</mi><mo id="A0.SS3.SSS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.1e" xref="A0.SS3.SSS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.1.cmml">⁢</mo><mi id="A0.SS3.SSS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.8" xref="A0.SS3.SSS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.8.cmml">I</mi><mo id="A0.SS3.SSS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.1f" xref="A0.SS3.SSS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.1.cmml">⁢</mo><mi id="A0.SS3.SSS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.9" xref="A0.SS3.SSS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.9.cmml">L</mi><mo id="A0.SS3.SSS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.1g" xref="A0.SS3.SSS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.1.cmml">⁢</mo><mi id="A0.SS3.SSS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.10" xref="A0.SS3.SSS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.10.cmml">E</mi></mrow><annotation-xml encoding="MathML-Content" id="A0.SS3.SSS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1b"><apply id="A0.SS3.SSS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.cmml" xref="A0.SS3.SSS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1"><times id="A0.SS3.SSS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.1.cmml" xref="A0.SS3.SSS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.1"></times><ci id="A0.SS3.SSS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.2.cmml" xref="A0.SS3.SSS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.2">𝐽</ci><ci id="A0.SS3.SSS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.3.cmml" xref="A0.SS3.SSS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.3">𝑆</ci><ci id="A0.SS3.SSS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.4.cmml" xref="A0.SS3.SSS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.4">𝑂</ci><ci id="A0.SS3.SSS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.5.cmml" xref="A0.SS3.SSS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.5">𝑁</ci><ci id="A0.SS3.SSS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.6.cmml" xref="A0.SS3.SSS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.6">_</ci><ci id="A0.SS3.SSS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.7.cmml" xref="A0.SS3.SSS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.7">𝐹</ci><ci id="A0.SS3.SSS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.8.cmml" xref="A0.SS3.SSS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.8">𝐼</ci><ci id="A0.SS3.SSS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.9.cmml" xref="A0.SS3.SSS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.9">𝐿</ci><ci id="A0.SS3.SSS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.10.cmml" xref="A0.SS3.SSS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.10">𝐸</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A0.SS3.SSS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1c">JSON\_FILE</annotation><annotation encoding="application/x-llamapun" id="A0.SS3.SSS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1d">italic_J italic_S italic_O italic_N _ italic_F italic_I italic_L italic_E</annotation></semantics></math>. Based on the context, you have to analyze the following statement: PAN-OS versions 9.0.17 and later are unaffected by the vulnerability. and indicate whether the statement is True or False. Return your answer as either T (for True) or F (for False). If you do not know the answer, return X. Provide only the letter corresponding to your choice (T, F, or X) without any additional text or explanations.</span>
</span></foreignobject></g></g></svg>
</div>
<div class="ltx_para" id="A0.SS3.SSS2.p3">
<p class="ltx_p" id="A0.SS3.SSS2.p3.1">For this example we pass the <math alttext="JSON\_file" class="ltx_Math" display="inline" id="A0.SS3.SSS2.p3.1.m1.1"><semantics id="A0.SS3.SSS2.p3.1.m1.1a"><mrow id="A0.SS3.SSS2.p3.1.m1.1.1" xref="A0.SS3.SSS2.p3.1.m1.1.1.cmml"><mi id="A0.SS3.SSS2.p3.1.m1.1.1.2" xref="A0.SS3.SSS2.p3.1.m1.1.1.2.cmml">J</mi><mo id="A0.SS3.SSS2.p3.1.m1.1.1.1" xref="A0.SS3.SSS2.p3.1.m1.1.1.1.cmml">⁢</mo><mi id="A0.SS3.SSS2.p3.1.m1.1.1.3" xref="A0.SS3.SSS2.p3.1.m1.1.1.3.cmml">S</mi><mo id="A0.SS3.SSS2.p3.1.m1.1.1.1a" xref="A0.SS3.SSS2.p3.1.m1.1.1.1.cmml">⁢</mo><mi id="A0.SS3.SSS2.p3.1.m1.1.1.4" xref="A0.SS3.SSS2.p3.1.m1.1.1.4.cmml">O</mi><mo id="A0.SS3.SSS2.p3.1.m1.1.1.1b" xref="A0.SS3.SSS2.p3.1.m1.1.1.1.cmml">⁢</mo><mi id="A0.SS3.SSS2.p3.1.m1.1.1.5" xref="A0.SS3.SSS2.p3.1.m1.1.1.5.cmml">N</mi><mo id="A0.SS3.SSS2.p3.1.m1.1.1.1c" xref="A0.SS3.SSS2.p3.1.m1.1.1.1.cmml">⁢</mo><mi id="A0.SS3.SSS2.p3.1.m1.1.1.6" mathvariant="normal" xref="A0.SS3.SSS2.p3.1.m1.1.1.6.cmml">_</mi><mo id="A0.SS3.SSS2.p3.1.m1.1.1.1d" xref="A0.SS3.SSS2.p3.1.m1.1.1.1.cmml">⁢</mo><mi id="A0.SS3.SSS2.p3.1.m1.1.1.7" xref="A0.SS3.SSS2.p3.1.m1.1.1.7.cmml">f</mi><mo id="A0.SS3.SSS2.p3.1.m1.1.1.1e" xref="A0.SS3.SSS2.p3.1.m1.1.1.1.cmml">⁢</mo><mi id="A0.SS3.SSS2.p3.1.m1.1.1.8" xref="A0.SS3.SSS2.p3.1.m1.1.1.8.cmml">i</mi><mo id="A0.SS3.SSS2.p3.1.m1.1.1.1f" xref="A0.SS3.SSS2.p3.1.m1.1.1.1.cmml">⁢</mo><mi id="A0.SS3.SSS2.p3.1.m1.1.1.9" xref="A0.SS3.SSS2.p3.1.m1.1.1.9.cmml">l</mi><mo id="A0.SS3.SSS2.p3.1.m1.1.1.1g" xref="A0.SS3.SSS2.p3.1.m1.1.1.1.cmml">⁢</mo><mi id="A0.SS3.SSS2.p3.1.m1.1.1.10" xref="A0.SS3.SSS2.p3.1.m1.1.1.10.cmml">e</mi></mrow><annotation-xml encoding="MathML-Content" id="A0.SS3.SSS2.p3.1.m1.1b"><apply id="A0.SS3.SSS2.p3.1.m1.1.1.cmml" xref="A0.SS3.SSS2.p3.1.m1.1.1"><times id="A0.SS3.SSS2.p3.1.m1.1.1.1.cmml" xref="A0.SS3.SSS2.p3.1.m1.1.1.1"></times><ci id="A0.SS3.SSS2.p3.1.m1.1.1.2.cmml" xref="A0.SS3.SSS2.p3.1.m1.1.1.2">𝐽</ci><ci id="A0.SS3.SSS2.p3.1.m1.1.1.3.cmml" xref="A0.SS3.SSS2.p3.1.m1.1.1.3">𝑆</ci><ci id="A0.SS3.SSS2.p3.1.m1.1.1.4.cmml" xref="A0.SS3.SSS2.p3.1.m1.1.1.4">𝑂</ci><ci id="A0.SS3.SSS2.p3.1.m1.1.1.5.cmml" xref="A0.SS3.SSS2.p3.1.m1.1.1.5">𝑁</ci><ci id="A0.SS3.SSS2.p3.1.m1.1.1.6.cmml" xref="A0.SS3.SSS2.p3.1.m1.1.1.6">_</ci><ci id="A0.SS3.SSS2.p3.1.m1.1.1.7.cmml" xref="A0.SS3.SSS2.p3.1.m1.1.1.7">𝑓</ci><ci id="A0.SS3.SSS2.p3.1.m1.1.1.8.cmml" xref="A0.SS3.SSS2.p3.1.m1.1.1.8">𝑖</ci><ci id="A0.SS3.SSS2.p3.1.m1.1.1.9.cmml" xref="A0.SS3.SSS2.p3.1.m1.1.1.9">𝑙</ci><ci id="A0.SS3.SSS2.p3.1.m1.1.1.10.cmml" xref="A0.SS3.SSS2.p3.1.m1.1.1.10">𝑒</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A0.SS3.SSS2.p3.1.m1.1c">JSON\_file</annotation><annotation encoding="application/x-llamapun" id="A0.SS3.SSS2.p3.1.m1.1d">italic_J italic_S italic_O italic_N _ italic_f italic_i italic_l italic_e</annotation></semantics></math> downloaded from this CVE-Link<span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/CVEProject/cvelistV5/blob/main/cves/2024/0xxx/CVE-2024-0008.json" title="">https://github.com/CVEProject/cvelistV5/blob/main/cves/2024/0xxx/CVE-2024-0008.json</a></span></span></span>.</p>
</div>
<div class="ltx_para" id="A0.SS3.SSS2.p4">
<p class="ltx_p" id="A0.SS3.SSS2.p4.1"><span class="ltx_text ltx_font_bold" id="A0.SS3.SSS2.p4.1.1">Example Prompt (Task: VOOD)</span>
In VOOD, we do not pass any context to the LLMs and inspect how the models perform on information that has not been seen by them during training.</p>
</div>
<div class="ltx_para ltx_noindent" id="A0.SS3.SSS2.p5">
<svg class="ltx_picture" height="91.17" id="A0.SS3.SSS2.p5.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,91.17) matrix(1 0 0 -1 0 0)"><g fill="#969696" fill-opacity="1.0"><path d="M 0 4.15 L 0 87.02 C 0 89.31 1.86 91.17 4.15 91.17 L 595.85 91.17 C 598.14 91.17 600 89.31 600 87.02 L 600 4.15 C 600 1.86 598.14 0 595.85 0 L 4.15 0 C 1.86 0 0 1.86 0 4.15 Z" style="stroke:none"></path></g><g fill="#E6E6E6" fill-opacity="1.0"><path d="M 0.69 4.15 L 0.69 87.02 C 0.69 88.93 2.24 90.48 4.15 90.48 L 595.85 90.48 C 597.76 90.48 599.31 88.93 599.31 87.02 L 599.31 4.15 C 599.31 2.24 597.76 0.69 595.85 0.69 L 4.15 0.69 C 2.24 0.69 0.69 2.24 0.69 4.15 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 7.61 6.23)"><foreignobject color="#000000" height="78.72" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="584.78">
<span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="A0.SS3.SSS2.p5.pic1.1.1.1.1.1" style="width:422.6pt;">
<span class="ltx_p" id="A0.SS3.SSS2.p5.pic1.1.1.1.1.1.1">For the given statement: The vulnerability described in CVE-2024-0011 allows for the execution of arbitrary code on the affected system., indicate whether the statement is True or False. Return your answer as either T (for True) or F (for False). If you do not know the answer, return X. Provide only the letter corresponding to your choice (T, F, or X) without any additional text or explanations.</span>
</span></foreignobject></g></g></svg>
</div>
</section>
<section class="ltx_subsubsection" id="A0.SS3.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span class="ltx_text" id="A0.SS3.SSS3.5.1.1">-C</span>3 </span>Reasoning Task</h4>
<div class="ltx_para" id="A0.SS3.SSS3.p1">
<p class="ltx_p" id="A0.SS3.SSS3.p1.1"><span class="ltx_text ltx_font_bold" id="A0.SS3.SSS3.p1.1.1">Example Prompt (Task: RERT)</span></p>
</div>
<div class="ltx_para ltx_noindent" id="A0.SS3.SSS3.p2">
<svg class="ltx_picture" height="208.94" id="A0.SS3.SSS3.p2.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,208.94) matrix(1 0 0 -1 0 0)"><g fill="#969696" fill-opacity="1.0"><path d="M 0 4.15 L 0 204.79 C 0 207.08 1.86 208.94 4.15 208.94 L 595.85 208.94 C 598.14 208.94 600 207.08 600 204.79 L 600 4.15 C 600 1.86 598.14 0 595.85 0 L 4.15 0 C 1.86 0 0 1.86 0 4.15 Z" style="stroke:none"></path></g><g fill="#E6E6E6" fill-opacity="1.0"><path d="M 0.69 4.15 L 0.69 204.79 C 0.69 206.7 2.24 208.25 4.15 208.25 L 595.85 208.25 C 597.76 208.25 599.31 206.7 599.31 204.79 L 599.31 4.15 C 599.31 2.24 597.76 0.69 595.85 0.69 L 4.15 0.69 C 2.24 0.69 0.69 2.24 0.69 4.15 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 7.61 6.23)"><foreignobject color="#000000" height="196.49" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="584.78">
<span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="A0.SS3.SSS3.p2.pic1.1.1.1.1.1" style="width:422.6pt;">
<span class="ltx_p" id="A0.SS3.SSS3.p2.pic1.1.1.1.1.1.1">You are given the following descriptions of a cyber incident Vulnerability Overview. Please perform an analysis and deduce the risk evaluation. Return your answer in one sentence in a format such as ”Successful exploitation of this vulnerability could allow an attacker to inject arbitrary JavaScript into a user’s web browser” for a single vulnerability, or ”Successful exploitation of these vulnerabilities could cause a denial of service, disclosure of sensitive information, communication loss, and modification of settings or ladder logic” for multiple vulnerabilities.
3.2.1 Path Traversal CWE-22 There are multiple ways in LAquis SCADA for an attacker to access locations outside of their own directory. CVE-2024-5040 has been assigned to this vulnerability. A CVSS v3.1 base score of 7.8 has been calculated; the CVSS vector string is (AV:L/AC:L/PR:N/UI:R/S:U/C:H/I:H/A:H). A CVSS v4 score has also been calculated for CVE-2024-5040. A base score of 8.5 has been calculated; the CVSS vector string is (CVSS4.0/AV:L/AC:L/AT:N/PR:N/</span>
<span class="ltx_p" id="A0.SS3.SSS3.p2.pic1.1.1.1.1.1.2">UI:P/VC:H/VI:H/VA:H/SC:N/SI:N/SA:N).</span>
</span></foreignobject></g></g></svg>
</div>
<div class="ltx_para" id="A0.SS3.SSS3.p3">
<p class="ltx_p" id="A0.SS3.SSS3.p3.1"><span class="ltx_text ltx_font_bold" id="A0.SS3.SSS3.p3.1.1">Example Prompt (Task: CPST)</span></p>
</div>
<div class="ltx_para ltx_noindent" id="A0.SS3.SSS3.p4">
<svg class="ltx_picture" height="74.57" id="A0.SS3.SSS3.p4.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,74.57) matrix(1 0 0 -1 0 0)"><g fill="#969696" fill-opacity="1.0"><path d="M 0 4.15 L 0 70.41 C 0 72.71 1.86 74.57 4.15 74.57 L 595.85 74.57 C 598.14 74.57 600 72.71 600 70.41 L 600 4.15 C 600 1.86 598.14 0 595.85 0 L 4.15 0 C 1.86 0 0 1.86 0 4.15 Z" style="stroke:none"></path></g><g fill="#E6E6E6" fill-opacity="1.0"><path d="M 0.69 4.15 L 0.69 70.41 C 0.69 72.33 2.24 73.87 4.15 73.87 L 595.85 73.87 C 597.76 73.87 599.31 72.33 599.31 70.41 L 599.31 4.15 C 599.31 2.24 597.76 0.69 595.85 0.69 L 4.15 0.69 C 2.24 0.69 0.69 2.24 0.69 4.15 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 7.61 6.23)"><foreignobject color="#000000" height="62.11" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="584.78">
<span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="A0.SS3.SSS3.p4.pic1.1.1.1.1.1" style="width:422.6pt;">
<span class="ltx_p" id="A0.SS3.SSS3.p4.pic1.1.1.1.1.1.1">Calculate the CVSS v3 score for the following CVSS v3 Vector String:</span>
<span class="ltx_p" id="A0.SS3.SSS3.p4.pic1.1.1.1.1.1.2">AV:L/AC:L/PR:N/UI:R/S:U/C:H/I:H/A:H. Return your answer as a single number between 0.0 and 10.0. Provide only the number corresponding to your answer without any additional text or explanations.</span>
</span></foreignobject></g></g></svg>
</div>
<div class="ltx_para" id="A0.SS3.SSS3.p5">
<p class="ltx_p" id="A0.SS3.SSS3.p5.1"><span class="ltx_text" id="A0.SS3.SSS3.p5.1.1"></span></p>
</div>
</section>
</section>
<section class="ltx_subsection" id="A0.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="A0.SS4.5.1.1">-D</span> </span><span class="ltx_text ltx_font_italic" id="A0.SS4.6.2">LLM Reasoning Example</span>
</h3>
<div class="ltx_para" id="A0.SS4.p1">
<p class="ltx_p" id="A0.SS4.p1.1">Example Llama3-70b reasoning for one question in the KCV task</p>
</div>
<div class="ltx_para ltx_noindent" id="A0.SS4.p2">
<svg class="ltx_picture" height="257.21" id="A0.SS4.p2.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,257.21) matrix(1 0 0 -1 0 0)"><g fill="#969696" fill-opacity="1.0"><path d="M 0 4.15 L 0 253.06 C 0 255.36 1.86 257.21 4.15 257.21 L 595.85 257.21 C 598.14 257.21 600 255.36 600 253.06 L 600 4.15 C 600 1.86 598.14 0 595.85 0 L 4.15 0 C 1.86 0 0 1.86 0 4.15 Z" style="stroke:none"></path></g><g fill="#E6E6E6" fill-opacity="1.0"><path d="M 0.69 4.15 L 0.69 253.06 C 0.69 254.97 2.24 256.52 4.15 256.52 L 595.85 256.52 C 597.76 256.52 599.31 254.97 599.31 253.06 L 599.31 4.15 C 599.31 2.24 597.76 0.69 595.85 0.69 L 4.15 0.69 C 2.24 0.69 0.69 2.24 0.69 4.15 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 7.61 6.23)"><foreignobject color="#000000" height="244.76" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="584.78">
<span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="A0.SS4.p2.pic1.1.1.1.1.1" style="width:422.6pt;">
<span class="ltx_p" id="A0.SS4.p2.pic1.1.1.1.1.1.1">To determine the accuracy of the statement, I analyzed the provided JSON data, which describes a CVE record for CVE-2024-0011. The vulnerability is a reflected cross-site scripting (XSS) issue in the Captive Portal feature of Palo Alto Networks PAN-OS software.</span>
<span class="ltx_p" id="A0.SS4.p2.pic1.1.1.1.1.1.2">The description of the vulnerability states: ”A reflected cross-site scripting (XSS) vulnerability in the Captive Portal feature of Palo Alto Networks PAN-OS software enables execution of malicious JavaScript (in the context of an authenticated Captive Portal user’s browser) if a user clicks on a malicious link, allowing phishing attacks that could lead to credential theft.”</span>
<span class="ltx_p" id="A0.SS4.p2.pic1.1.1.1.1.1.3">The key points to note are:</span>
<span class="ltx_p" id="A0.SS4.p2.pic1.1.1.1.1.1.4">1. The vulnerability is a reflected XSS issue, which means it allows an attacker to inject malicious JavaScript code into a user’s browser.
2. The vulnerability is limited to the context of an authenticated Captive Portal user’s browser.
3. The goal of the attack is to perform phishing attacks that could lead to credential theft.</span>
<span class="ltx_p" id="A0.SS4.p2.pic1.1.1.1.1.1.5">Nowhere in the description or the provided data is there any indication that the vulnerability allows for the execution of arbitrary code on the affected system. The vulnerability is primarily a client-side issue, affecting the user’s browser, rather than a server-side issue that could lead to arbitrary code execution on the system.</span>
<span class="ltx_p" id="A0.SS4.p2.pic1.1.1.1.1.1.6">Therefore, based on the analysis of the provided data, I conclude that the statement is False.</span>
</span></foreignobject></g></g></svg>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Thu Sep 19 20:46:44 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
