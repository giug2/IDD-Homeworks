<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>SuperCoder2.0: Technical Report on Exploring the feasibility of LLMs as Autonomous Programmer * These authors have contributed equally.</title>
<!--Generated on Tue Sep 17 13:42:30 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<meta content="
LLM,  Agents,  Multi Agent System,  Autonomous coding system
" lang="en" name="keywords"/>
<base href="/html/2409.11190v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.11190v1#S1" title="In SuperCoder2.0: Technical Report on Exploring the feasibility of LLMs as Autonomous Programmer * These authors have contributed equally."><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">I </span><span class="ltx_text ltx_font_smallcaps">Introduction</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.11190v1#S2" title="In SuperCoder2.0: Technical Report on Exploring the feasibility of LLMs as Autonomous Programmer * These authors have contributed equally."><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">II </span><span class="ltx_text ltx_font_smallcaps">Literature Survey</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.11190v1#S3" title="In SuperCoder2.0: Technical Report on Exploring the feasibility of LLMs as Autonomous Programmer * These authors have contributed equally."><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">III </span><span class="ltx_text ltx_font_smallcaps">Methodology</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2409.11190v1#S3.SS1" title="In III Methodology ‣ SuperCoder2.0: Technical Report on Exploring the feasibility of LLMs as Autonomous Programmer * These authors have contributed equally."><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-A</span> </span><span class="ltx_text ltx_font_italic">Search</span></span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.11190v1#S3.SS1.SSS1" title="In III-A Search ‣ III Methodology ‣ SuperCoder2.0: Technical Report on Exploring the feasibility of LLMs as Autonomous Programmer * These authors have contributed equally."><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-A</span>1 </span>RAG and Repository File Level Map</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.11190v1#S3.SS1.SSS2" title="In III-A Search ‣ III Methodology ‣ SuperCoder2.0: Technical Report on Exploring the feasibility of LLMs as Autonomous Programmer * These authors have contributed equally."><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-A</span>2 </span>File Prioritization using File Level Schematic Map</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.11190v1#S3.SS1.SSS3" title="In III-A Search ‣ III Methodology ‣ SuperCoder2.0: Technical Report on Exploring the feasibility of LLMs as Autonomous Programmer * These authors have contributed equally."><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-A</span>3 </span>Localization of ’Relevant Locations’</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2409.11190v1#S3.SS2" title="In III Methodology ‣ SuperCoder2.0: Technical Report on Exploring the feasibility of LLMs as Autonomous Programmer * These authors have contributed equally."><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-B</span> </span><span class="ltx_text ltx_font_italic">Code Modification and Insertion</span></span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.11190v1#S3.SS2.SSS1" title="In III-B Code Modification and Insertion ‣ III Methodology ‣ SuperCoder2.0: Technical Report on Exploring the feasibility of LLMs as Autonomous Programmer * These authors have contributed equally."><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-B</span>1 </span>Code Generation and Editing Process</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.11190v1#S3.SS3" title="In III Methodology ‣ SuperCoder2.0: Technical Report on Exploring the feasibility of LLMs as Autonomous Programmer * These authors have contributed equally."><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-C</span> </span><span class="ltx_text ltx_font_italic">Iterative Feedback and Refinement Mechanism</span></span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.11190v1#S4" title="In SuperCoder2.0: Technical Report on Exploring the feasibility of LLMs as Autonomous Programmer * These authors have contributed equally."><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">IV </span><span class="ltx_text ltx_font_smallcaps">Experimental Methodology and Dataset Analysis</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.11190v1#S4.SS1" title="In IV Experimental Methodology and Dataset Analysis ‣ SuperCoder2.0: Technical Report on Exploring the feasibility of LLMs as Autonomous Programmer * These authors have contributed equally."><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">IV-A</span> </span><span class="ltx_text ltx_font_italic">Experimental Design on SWE-Bench Lite</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2409.11190v1#S4.SS2" title="In IV Experimental Methodology and Dataset Analysis ‣ SuperCoder2.0: Technical Report on Exploring the feasibility of LLMs as Autonomous Programmer * These authors have contributed equally."><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">IV-B</span> </span><span class="ltx_text ltx_font_italic">Dataset Characteristics and Selection Rationale</span></span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.11190v1#S4.SS2.SSS1" title="In IV-B Dataset Characteristics and Selection Rationale ‣ IV Experimental Methodology and Dataset Analysis ‣ SuperCoder2.0: Technical Report on Exploring the feasibility of LLMs as Autonomous Programmer * These authors have contributed equally."><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">IV-B</span>1 </span>Original SWE-bench Dataset</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.11190v1#S4.SS2.SSS2" title="In IV-B Dataset Characteristics and Selection Rationale ‣ IV Experimental Methodology and Dataset Analysis ‣ SuperCoder2.0: Technical Report on Exploring the feasibility of LLMs as Autonomous Programmer * These authors have contributed equally."><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">IV-B</span>2 </span>SWE-bench Lite: A Focused Subset</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.11190v1#S4.SS3" title="In IV Experimental Methodology and Dataset Analysis ‣ SuperCoder2.0: Technical Report on Exploring the feasibility of LLMs as Autonomous Programmer * These authors have contributed equally."><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">IV-C</span> </span><span class="ltx_text ltx_font_italic">Evaluation Metrics and Performance Analysis</span></span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.11190v1#S5" title="In SuperCoder2.0: Technical Report on Exploring the feasibility of LLMs as Autonomous Programmer * These authors have contributed equally."><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">V </span><span class="ltx_text ltx_font_smallcaps">Results and Analysis on SWE-Bench Lite</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.11190v1#S5.SS1" title="In V Results and Analysis on SWE-Bench Lite ‣ SuperCoder2.0: Technical Report on Exploring the feasibility of LLMs as Autonomous Programmer * These authors have contributed equally."><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">V-A</span> </span><span class="ltx_text ltx_font_italic">File Localization Efficiency</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.11190v1#S5.SS2" title="In V Results and Analysis on SWE-Bench Lite ‣ SuperCoder2.0: Technical Report on Exploring the feasibility of LLMs as Autonomous Programmer * These authors have contributed equally."><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">V-B</span> </span><span class="ltx_text ltx_font_italic">Code Analysis and Editing Strategies</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.11190v1#S5.SS3" title="In V Results and Analysis on SWE-Bench Lite ‣ SuperCoder2.0: Technical Report on Exploring the feasibility of LLMs as Autonomous Programmer * These authors have contributed equally."><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">V-C</span> </span><span class="ltx_text ltx_font_italic">Embedding Model Efficacy</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.11190v1#S5.SS4" title="In V Results and Analysis on SWE-Bench Lite ‣ SuperCoder2.0: Technical Report on Exploring the feasibility of LLMs as Autonomous Programmer * These authors have contributed equally."><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">V-D</span> </span><span class="ltx_text ltx_font_italic">Cross-Repository Performance</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.11190v1#S5.SS5" title="In V Results and Analysis on SWE-Bench Lite ‣ SuperCoder2.0: Technical Report on Exploring the feasibility of LLMs as Autonomous Programmer * These authors have contributed equally."><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">V-E</span> </span><span class="ltx_text ltx_font_italic">Overall Performance Metrics</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.11190v1#S5.SS6" title="In V Results and Analysis on SWE-Bench Lite ‣ SuperCoder2.0: Technical Report on Exploring the feasibility of LLMs as Autonomous Programmer * These authors have contributed equally."><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">V-F</span> </span><span class="ltx_text ltx_font_italic">Comparative Analysis</span></span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.11190v1#S6" title="In SuperCoder2.0: Technical Report on Exploring the feasibility of LLMs as Autonomous Programmer * These authors have contributed equally."><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">VI </span><span class="ltx_text ltx_font_smallcaps">Conclusion and Future Work</span></span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">SuperCoder2.0: Technical Report on Exploring the feasibility of LLMs as Autonomous Programmer
<br class="ltx_break"/><sup class="ltx_sup" id="id3.id1"></sup>
<span class="ltx_note ltx_role_thanks" id="id4.id2"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">thanks: </span><sup class="ltx_sup" id="id4.id2.1">*</sup> These authors have contributed equally.</span></span></span>
</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Anmol Gautam<sup class="ltx_sup" id="id5.2.id1">∗</sup>
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_font_italic" id="id6.3.id1">SuperAGI Research
<br class="ltx_break"/></span>Bengaluru, India 
<br class="ltx_break"/><span class="ltx_ERROR undefined" id="id7.4.id2">\orcidlink</span>0009-0002-8166-9592
</span></span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Kishore Kumar<sup class="ltx_sup" id="id8.2.id1">∗</sup>
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_font_italic" id="id9.3.id1">SuperAGI Research
<br class="ltx_break"/></span>Bengaluru, India 
<br class="ltx_break"/><span class="ltx_ERROR undefined" id="id10.4.id2">\orcidlink</span>0009-0000-0527-6493
</span></span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Adarsh Jha
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_font_italic" id="id11.1.id1">SuperAGI Research
<br class="ltx_break"/></span>Bengaluru, India 
<br class="ltx_break"/><span class="ltx_ERROR undefined" id="id12.2.id2">\orcidlink</span>0009-0006-8062-4092
</span></span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Mukunda NS
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_font_italic" id="id13.1.id1">SuperAGI Research
<br class="ltx_break"/></span>Bengaluru, India 
<br class="ltx_break"/>mukunda@superagi.com
</span></span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Ishaan Bhola
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_font_italic" id="id14.1.id1">SuperAGI Research
<br class="ltx_break"/></span>Bengaluru, India 
<br class="ltx_break"/>ishaan@superagi.com
</span></span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id15.id1">We present SuperCoder2.0, an advanced autonomous system designed to enhance software development through artificial intelligence. The system combines an AI-native development approach with intelligent agents to enable fully autonomous coding. Key focus areas include a retry mechanism with error output traceback, comprehensive code rewriting and replacement using Abstract Syntax Tree (ast) parsing to minimize linting issues, code embedding technique for retrieval-augmented generation, and a focus on localizing methods for problem-solving rather than identifying specific line numbers. The methodology employs a three-step hierarchical search space reduction approach for code base navigation and bug localization:utilizing Retrieval Augmented Generation (RAG) and a Repository File Level Map to identify candidate files, (2) narrowing down to the most relevant files using a File Level Schematic Map, and (3) extracting ’relevant locations’ within these files. Code editing is performed through a two-part module comprising CodeGeneration and CodeEditing, which generates multiple solutions at different temperature values and replaces entire methods or classes to maintain code integrity. A feedback loop executes repository-level test cases to validate and refine solutions. Experiments conducted on the SWE-bench Lite dataset demonstrate SuperCoder2.0’s effectiveness, achieving correct file localization in 84.33% of cases within the top 5 candidates and successfully resolving 34% of test instances. This performance places SuperCoder2.0 globally on the SWE-bench leaderboard. The system’s ability to handle diverse repositories and problem types highlights its potential as a versatile tool for autonomous software development. Future work will focus on refining the code editing process and exploring advanced embedding models for improved natural language to code mapping.</p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Index Terms: </h6>
LLM, Agents, Multi Agent System, Autonomous coding system

</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">I </span><span class="ltx_text ltx_font_smallcaps" id="S1.1.1">Introduction</span>
</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">SuperCoder2.0 is an advanced autonomous system designed to enhance software development through artificial intelligence. Combining an AI-native development platform with intelligent agents, it allows for fully autonomous coding, particularly in Python. This system introduces several innovative features such as an advanced retry mechanism with error output traceback, comprehensive code rewriting to avoid linting issues, a unique code embedding technique for retrieval-augmented generation, and a focus on localising methods for problem-solving rather than identifying specific line numbers.
Current Landscape of Autonomous Systems in Software Development
The domain of AI-assisted development has seen substantial research and development. Techniques such as automated code generation, error detection, and project management have demonstrated significant improvements in developer productivity and code quality. Research on AI-native platforms emphasizes the importance of integrating AI models into the development lifecycle to enhance deployment fluidity and operational efficiency. In this context, autonomous systems like OpenAI’s Codex <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11190v1#bib.bib1" title="">1</a>]</cite>, which powers GitHub Copilot, exemplify AI’s potential to transform traditional coding practices by enabling more intuitive coding environments and reducing manual efforts. Techniques such as RAG <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11190v1#bib.bib2" title="">2</a>]</cite>, combining strengths of retrieval-based and generation-based models, are pivotal in enhancing contextually accurate code suggestions.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">SuperCoder2.0 incorporates advanced error handling and retry mechanisms, critical for autonomous systems. These features minimize debugging time and enhance robustness through proactive error management, automated retries, and error output traceback. The implementation of error output traceback and automated retries in SuperCoder2.0 aligns with advanced techniques seen in recent studies, which highlight the importance of learning from previous mistakes to improve AI model performance. Research demonstrates that proper error handling can significantly reduce manual debugging efforts and improve overall system reliability<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11190v1#bib.bib3" title="">3</a>]</cite><cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11190v1#bib.bib4" title="">4</a>]</cite>.
The comprehensive approach of code rewriting of SuperCoder2.0 involves rewriting the entire files to avoid linting issues, a method that ensures a consistent and cohesive codebase. This technique is crucial for maintaining code quality and avoiding fragmented, inconsistent updates, a challenge frequently noted in modern software development practices.
Leveraging RAG, particularly with specialized code embeddings, SuperCoder2.0 enhances its ability to provide relevant and accurate code suggestions. This is especially pertinent given the growing body of research advocating for improved accuracy and relevance in AI-driven code assistance tools. The embedding of code documents using the code embeddings instead of traditional embeddings, advances beyond standard RAG approaches by offering more contextually relevant retrievals with natural language input.
Localisation of Problem-Solving is another place where SuperCoder2.0 takes a unique approach to avoid identifying a wrong location. Traditional debugging approaches often focus on identifying specific line numbers where issues occur. However, the localisation of methods rather than specific lines, as practised by SuperCoder2.0, aligns with current research that suggests higher abstraction methods can improve the understanding and solving of complex coding problems<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11190v1#bib.bib5" title="">5</a>]</cite>. This method provides a more strategic approach to debugging and problem resolution, making it easier to manage and fix intricate issues that span multiple code segments.</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">II </span><span class="ltx_text ltx_font_smallcaps" id="S2.1.1">Literature Survey</span>
</h2>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">The rapid advancement in artificial intelligence, particularly in large language models (LLMs), has improved the development of autonomous systems capable of performing complex tasks managed by humans. This is especially true in the domain of software development, where the integration of AI-driven autonomous agents is increasingly adopted. Autonomous Software Development Systems are evolving to automate various phases of the software lifecycle, from requirements gathering and design to coding, testing, and maintenance. One such benchmark, SWE-bench<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11190v1#bib.bib6" title="">6</a>]</cite>, has emerged as a pivotal tool in assessing the capabilities of language models in performing software engineering tasks autonomously. SWE-bench is designed to measure the effectiveness of language models in handling tasks that range from basic code comprehension to more complex activities such as code synthesis and bug fixing. The benchmark provides a structured evaluation environment, offering a diverse set of challenges that reflect real-world software development scenarios. SWE-bench has been instrumental in highlighting the strengths and limitations of various autonomous systems. For instance, it has been used to compare the performance of different LMs in coding tasks, revealing significant variations in their ability to understand and generate syntactically correct and semantically meaningful code. SWE-bench has played a crucial role in driving innovation in the development of more sophisticated LMs. Providing a clear set of performance metrics encourages researchers and developers to push the boundaries of what these models can achieve. The benchmark has been vital in identifying areas where current models fall short, such as in handling highly complex or creative tasks that require deep contextual understanding.
LLMs like GPT-4 by OpenAI and Claude by Anthropic are pivotal in advancing autonomous software development. Initially, LLMs were designed to handle basic natural language processing tasks, including translation and summarization. Their potential in code generation became evident with early models like GPT-2, which could generate simple<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11190v1#bib.bib7" title="">7</a>]</cite>. Over time, models like GPT-4 have shown marked improvements in both the accuracy and complexity of generated code, evolving from handling basic tasks to performing sophisticated programming activities<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11190v1#bib.bib8" title="">8</a>]</cite>. GPT-4 builds on its predecessors’ architectures with enhanced capabilities, trained on vast and diverse datasets, enabling it to understand complex programming languages and generate more sophisticated code. Its ability to interpret nuanced queries and produce functional code makes it a powerful tool for automating software development tasks<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11190v1#bib.bib9" title="">9</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S2.p2">
<p class="ltx_p" id="S2.p2.1">Claude, with its focus on safety and alignment, has developed robust mechanisms to generate precise, error-free code, ensuring higher reliability in autonomous coding systems<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11190v1#bib.bib10" title="">10</a>]</cite>. The emphasis on reducing biases and achieving high fidelity in generated code has made Claude particularly beneficial for applications that require safe and reliable outputs. Through iterative training on extensive and varied datasets, Claude ensures the correct semantic interpretation of programming tasks, thus generating precise and dependable code<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11190v1#bib.bib11" title="">11</a>]</cite>. These models demonstrate the potential to automate various aspects of software development, providing a technical backbone for more sophisticated autonomous coding systems.</p>
</div>
<div class="ltx_para" id="S2.p3">
<p class="ltx_p" id="S2.p3.1">The incorporation of LLMs into autonomous agents represents a significant leap toward realizing fully autonomous software development systems. Frameworks like LangChain enable LLMs to function as part of autonomous agents capable of executing complex tasks with minimal human intervention<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11190v1#bib.bib12" title="">12</a>]</cite>. These agents can request and utilize information, develop strategies, and make decisions based on the extensive knowledge embedded in the LLMs, significantly enhancing their capabilities in autonomous coding environments. Methodologies like Reasoning and Acting (ReACT) and Chain-of-Thought (COT) further enhance the application of LLMs.</p>
</div>
<div class="ltx_para" id="S2.p4">
<p class="ltx_p" id="S2.p4.1">ReACT integrates reasoning with action, enabling LLMs to autonomously devise and execute plans, crucial in real-time coding environments<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11190v1#bib.bib13" title="">13</a>]</cite>. This approach leverages the model’s reasoning capabilities to interpret tasks and generate corresponding actions autonomously. By integrating structured reasoning and action-based planning, ReACT empowers LLMs to handle complex coding tasks with greater accuracy and consistency<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11190v1#bib.bib14" title="">14</a>]</cite>. COT further improves the problem-solving capabilities of LLMs by breaking down tasks into sequential steps, enhancing their ability to generate coherent and functional code<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11190v1#bib.bib15" title="">15</a>]</cite>. This step-by-step reasoning approach allows models to process and address each part methodically, making it particularly effective in software development where logical sequences and dependencies are critical. Studies have revealed that COT prompting enhances an LLM’s capacity to generate clear and coherent code by improving its logical reasoning processes<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11190v1#bib.bib16" title="">16</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S2.p5">
<p class="ltx_p" id="S2.p5.1">The capability of LLMs to generate code has been extensively researched, demonstrating the profound impact these models can have on software development. Benchmark datasets like CodeXGLUE evaluate and advance LLM capabilities in code-related tasks, highlighting how pre-trained models can be fine-tuned for specific applications<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11190v1#bib.bib17" title="">17</a>]</cite>. This benchmark includes a suite of tasks designed to test various aspects of code intelligence, from code completion to translation between different programming languages. Research efforts have developed tools like GitHub Copilot, built on advanced LLMs like Codex, a descendant of GPT-3, which have practical applications in improving developer productivity by providing context-aware code completions. Copilot can generate boilerplate code, suggest entire functions, and even automate repetitive coding tasks, significantly reducing the manual workload for developers<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11190v1#bib.bib18" title="">18</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S2.p6">
<p class="ltx_p" id="S2.p6.1">Another empirical study delves into the adaptive capabilities of models like GPT-4 across various programming languages and tasks. Fine-tuning these models on domain-specific datasets has shown to lead to high accuracy and functionality in code generation, underscoring the versatility and robustness of LLMs in different coding environments<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11190v1#bib.bib19" title="">19</a>]</cite>. Further research has explored the integration of LLMs in more complex programming tasks, demonstrating how models trained on diverse code examples can understand and replicate intricate programming patterns. This approach significantly enhances the model’s ability to generate contextually appropriate and syntactically correct code that adheres to best practices<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11190v1#bib.bib20" title="">20</a>]</cite>. Multi-modal code generation, which integrates natural language tasks with coding tasks within a single model framework, has demonstrated improved code generation capabilities, achieving better contextual understanding and producing more accurate and coherent code<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11190v1#bib.bib21" title="">21</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S2.p7">
<p class="ltx_p" id="S2.p7.1">Numerous research efforts and advancements in the AI programmer space have led to the development of sophisticated tools like OpenDevin and Agentless. OpenDevin facilitates end-to-end programming tasks, bridging the gap between natural language specifications and functional software<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11190v1#bib.bib22" title="">22</a>]</cite>. This tool leverages state-of-the-art LLMs to understand complex programming requirements and produce accurate, high-quality code, effectively automating comprehensive development processes. The introduction of such tools showcases the potential for AI systems to handle substantial portions of the software development lifecycle.</p>
</div>
<div class="ltx_para" id="S2.p8">
<p class="ltx_p" id="S2.p8.1">Agentless, another cutting-edge AI tool, exemplifies current strides in autonomous software engineering by focusing on intelligent automation for maintaining and managing codebases. It employs an initial file localization and code generation phase that reduces complexity and leverages the capabilities of LLMs<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11190v1#bib.bib23" title="">23</a>]</cite>. Agentless utilizes advanced reasoning capabilities and machine learning algorithms to understand code dependencies, suggest improvements, and perform refactoring, thus enhancing both the efficiency and reliability of software projects. AutoCodeRover enhances software code quality through a combination of static and dynamic analysis techniques, autonomously navigating through the codebase and applying transformations to improve performance and readability<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11190v1#bib.bib24" title="">24</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S2.p9">
<p class="ltx_p" id="S2.p9.1">The CodeAct agent consolidates an LLM agent’s actions into a unified code action space, operating in a turn-based environment where it can converse with the user or perform actions such as running scripts and navigating files. This approach allows the LLM to reason, create plans, and incorporate feedback from the user, improving robustness<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11190v1#bib.bib25" title="">25</a>]</cite>. A multi-agent approach for autonomous software development is presented where different real-world roles involved in the software development lifecycle are assigned to multiple agents, which communicate to solve problems collaboratively. This task graph methodology allows for efficient planning and execution of tasks by different agents<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11190v1#bib.bib26" title="">26</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S2.p10">
<p class="ltx_p" id="S2.p10.1">The agent-based approaches have their drawbacks, as discussed in research supporting the agentless paradigm. The agentless approach employs a simplified initial file localization and a code generation phase, bypassing the need for complex agent-based tools and utilizing repo maps for file searches, significantly reducing complexity<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11190v1#bib.bib27" title="">27</a>]</cite>. The modular architecture for software-engineering AI agents (MASAI) follows a similar strategy, where different LLM-powered sub-agents are instantiated with specific objectives like edit localization, fault fixing, and issue reproduction, distributing responsibilities and simplifying problem-solving<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11190v1#bib.bib28" title="">28</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S2.p11">
<p class="ltx_p" id="S2.p11.1">Aider utilizes static analysis to offer a concise overview of repositories, identifying files that need editing and performing iterative modifications until the code is syntactically correct and passes existing tests<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11190v1#bib.bib29" title="">29</a>]</cite>. Another approach, Moatless, employs a semantic search tool to use natural language queries to find relevant code segments within the repository, simplifying the localization and correction of code<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11190v1#bib.bib30" title="">30</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S2.p12">
<p class="ltx_p" id="S2.p12.1">In conclusion, the fusion of LLMs like GPT-4 and Claude with methodologies such as ReACT and COT, coupled with innovative tools like OpenDevIN and Agentless, signifies a transformative period in autonomous software development. By automating various programming activities, these AI systems promise to enhance productivity, reduce errors, and allow human developers to focus on more strategic and creative aspects of software engineering. As research continues to evolve, the integration of AI in the programming field is set to revolutionize the development, maintenance, and optimization of software, paving the way for a new era of autonomous coding.</p>
</div>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">III </span><span class="ltx_text ltx_font_smallcaps" id="S3.1.1">Methodology</span>
</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">This section elucidates the operational framework of SuperCoder2.0, focusing on its approach to codebase navigation and issue resolution. The methodology addresses two critical aspects of automated debugging:<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11190v1#bib.bib33" title="">33</a>]</cite> efficient codebase traversal with precise localization of the target code section, and <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11190v1#bib.bib34" title="">34</a>]</cite> generation and implementation of corrective code. While individual components of this approach have precedents in existing literature, the novel integration and sequential application of these elements yield significant performance improvements. The methodology is bifurcated into two primary phases: Search and Edit. The Search phase employs a hierarchical approach to narrow down the problem space, while the Edit phase utilizes advanced code generation and modification techniques. This structured approach enables SuperCoder2.0 to effectively navigate complex codebases and implement targeted solutions, demonstrating enhanced efficiency in autonomous software development tasks. The system leverages state-of-the-art language models, specifically GPT-4 and Claude Sonnet 3.5, for code generation and analysis tasks, while Jina Code Embeddings are utilized for efficient code retrieval and semantic search operations. This combination of advanced models contributes to the system’s robust performance across diverse programming challenges.</p>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S3.SS1.5.1.1">III-A</span> </span><span class="ltx_text ltx_font_italic" id="S3.SS1.6.2">Search</span>
</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">To effectively resolve issues within a codebase, it is crucial to precisely identify the root of the problem, henceforth referred to as the ’relevant location’. In SuperCoder2.0, we define the ’relevant location’ as belonging to one of three hierarchical levels: Method/Function, Class, or Top-Level. Top-level code encompasses elements outside any class or function, including import statements. Class-level code is contained within a class but external to its methods, while method/function-level code is encapsulated within specific methods or functions.
The primary objective of the Search module is to localize the bug’s residence. When identified within a method or function, the module returns the method/function name along with its start line number, facilitating disambiguation between identically named methods. Empirical observations on the SWE-Bench-Lite dataset demonstrated that accurate method localization yielded optimal results. Considering that most LLMs can generate up to 4,000 tokens in a single iteration, we posit that methods or functions adhering to best software engineering practices are likely to fall within these generation limits.
Our approach implements a hierarchical search space reduction strategy, systematically narrowing down from file-level to method-level granularity. This process is executed in three distinct steps:</p>
<ul class="ltx_itemize" id="S3.I1">
<li class="ltx_item" id="S3.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I1.i1.p1">
<p class="ltx_p" id="S3.I1.i1.p1.1">Identification of candidate files from the repository, utilizing RAG and a Repository File Level Map.</p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I1.i2.p1">
<p class="ltx_p" id="S3.I1.i2.p1.1">Refinement of candidate files to the most relevant subset, employing a File Level Schematic Map.</p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I1.i3.p1">
<p class="ltx_p" id="S3.I1.i3.p1.1">Extraction of ’relevant locations’ within the identified files.</p>
</div>
</li>
</ul>
<p class="ltx_p" id="S3.SS1.p1.2">Each step in this process involves a discrete LLM call. Notably, our empirical findings suggest that providing comprehensive context and posing targeted questions in a single LLM call proves more effective than an iterative, reason-action-observation based agentic approach. This observation aligns with findings from the Agentless team. The subsequent sections will elaborate on each step of this process in detail.</p>
</div>
<section class="ltx_subsubsection" id="S3.SS1.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span class="ltx_text" id="S3.SS1.SSS1.5.1.1">III-A</span>1 </span>RAG and Repository File Level Map</h4>
<div class="ltx_para" id="S3.SS1.SSS1.p1">
<p class="ltx_p" id="S3.SS1.SSS1.p1.1">The initial phase involves the creation of a vector store for the codebase, facilitating the retrieval of files most pertinent to a given problem statement. This process remains largely static for a given codebase. The document structure employed for embedding and searching is detailed in Listing 1.</p>
</div>
<figure class="ltx_float ltx_lstlisting" id="LST1">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_float">Listing 1: </span>Embedding document structure with metadata</figcaption>
<div class="ltx_listing ltx_lstlisting ltx_listing" id="LST1.1">
<div class="ltx_listing_data"><a download="" href="data:text/plain;base64,CnsKICAgICJkb2N1bWVudCI6ICJ7CiAgICAgICAgTWV0aG9kIHt7bWV0aG9kX25hbWV9fSB3aXRoCiAgICAgICAgYXJndW1lbnRzIHt7YXJnc319IGhhdmUgc2lnbmF0dXJlCiAgICAgICAgYXMge3tzaWduYXR1cmV9fSBpcyBkZXNjcmliZWQKICAgICAgICB1c2luZyB7e2RvY3N0cmluZ319IGFsc28KICAgICAgICBoYXZlIHt7ZGVjb3JhdG9yc319IGFzIGRlY29yYXRvcnMKICAgICAgICBhbmQgcmV0dXJuIHN0YXRlbWVudCBkZXNjcmliZWQKICAgICAgICBhcyB7e3JldHVybl9zdGF0ZW1lbnR9fS4KICAgICAgICB9LAogICAgImZpbGVfbmFtZSI6PDxuYW1lIG9mIHRoZSBmaWxlPj4sCiAgICAicGFyZW50X2NsYXNzIjo8PG5hbWUgb2YgdGhlIHBhcmVudAogICAgY2xhc3Mgb3IgTm9uZSBpZiBpdHMgYSBtZXRob2Q+PgogICAgfSIKfQ==">⬇</a></div>
<div class="ltx_listingline" id="lstnumberx1">
</div>
<div class="ltx_listingline" id="lstnumberx2">{
</div>
<div class="ltx_listingline" id="lstnumberx3">
<span class="ltx_text ltx_lst_space" id="lstnumberx3.1"> </span>”<span class="ltx_text ltx_lst_identifier" id="lstnumberx3.2">document</span>”:<span class="ltx_text ltx_lst_space" id="lstnumberx3.3"> </span>”{
</div>
<div class="ltx_listingline" id="lstnumberx4">
<span class="ltx_text ltx_lst_space" id="lstnumberx4.1"> </span><span class="ltx_text ltx_lst_identifier" id="lstnumberx4.2">Method</span><span class="ltx_text ltx_lst_space" id="lstnumberx4.3"> </span>{{<span class="ltx_text ltx_lst_identifier" id="lstnumberx4.4">method_name</span>}}<span class="ltx_text ltx_lst_space" id="lstnumberx4.5"> </span><span class="ltx_text ltx_lst_identifier" id="lstnumberx4.6">with</span>
</div>
<div class="ltx_listingline" id="lstnumberx5">
<span class="ltx_text ltx_lst_space" id="lstnumberx5.1"> </span><span class="ltx_text ltx_lst_identifier" id="lstnumberx5.2">arguments</span><span class="ltx_text ltx_lst_space" id="lstnumberx5.3"> </span>{{<span class="ltx_text ltx_lst_identifier" id="lstnumberx5.4">args</span>}}<span class="ltx_text ltx_lst_space" id="lstnumberx5.5"> </span><span class="ltx_text ltx_lst_identifier" id="lstnumberx5.6">have</span><span class="ltx_text ltx_lst_space" id="lstnumberx5.7"> </span><span class="ltx_text ltx_lst_identifier" id="lstnumberx5.8">signature</span>
</div>
<div class="ltx_listingline" id="lstnumberx6">
<span class="ltx_text ltx_lst_space" id="lstnumberx6.1"> </span><span class="ltx_text ltx_lst_identifier" id="lstnumberx6.2">as</span><span class="ltx_text ltx_lst_space" id="lstnumberx6.3"> </span>{{<span class="ltx_text ltx_lst_identifier" id="lstnumberx6.4">signature</span>}}<span class="ltx_text ltx_lst_space" id="lstnumberx6.5"> </span><span class="ltx_text ltx_lst_identifier" id="lstnumberx6.6">is</span><span class="ltx_text ltx_lst_space" id="lstnumberx6.7"> </span><span class="ltx_text ltx_lst_identifier" id="lstnumberx6.8">described</span>
</div>
<div class="ltx_listingline" id="lstnumberx7">
<span class="ltx_text ltx_lst_space" id="lstnumberx7.1"> </span><span class="ltx_text ltx_lst_identifier" id="lstnumberx7.2">using</span><span class="ltx_text ltx_lst_space" id="lstnumberx7.3"> </span>{{<span class="ltx_text ltx_lst_identifier" id="lstnumberx7.4">docstring</span>}}<span class="ltx_text ltx_lst_space" id="lstnumberx7.5"> </span><span class="ltx_text ltx_lst_identifier" id="lstnumberx7.6">also</span>
</div>
<div class="ltx_listingline" id="lstnumberx8">
<span class="ltx_text ltx_lst_space" id="lstnumberx8.1"> </span><span class="ltx_text ltx_lst_identifier" id="lstnumberx8.2">have</span><span class="ltx_text ltx_lst_space" id="lstnumberx8.3"> </span>{{<span class="ltx_text ltx_lst_identifier" id="lstnumberx8.4">decorators</span>}}<span class="ltx_text ltx_lst_space" id="lstnumberx8.5"> </span><span class="ltx_text ltx_lst_identifier" id="lstnumberx8.6">as</span><span class="ltx_text ltx_lst_space" id="lstnumberx8.7"> </span><span class="ltx_text ltx_lst_identifier" id="lstnumberx8.8">decorators</span>
</div>
<div class="ltx_listingline" id="lstnumberx9">
<span class="ltx_text ltx_lst_space" id="lstnumberx9.1"> </span><span class="ltx_text ltx_lst_identifier" id="lstnumberx9.2">and</span><span class="ltx_text ltx_lst_space" id="lstnumberx9.3"> </span><span class="ltx_text ltx_lst_identifier" id="lstnumberx9.4">return</span><span class="ltx_text ltx_lst_space" id="lstnumberx9.5"> </span><span class="ltx_text ltx_lst_identifier" id="lstnumberx9.6">statement</span><span class="ltx_text ltx_lst_space" id="lstnumberx9.7"> </span><span class="ltx_text ltx_lst_identifier" id="lstnumberx9.8">described</span>
</div>
<div class="ltx_listingline" id="lstnumberx10">
<span class="ltx_text ltx_lst_space" id="lstnumberx10.1"> </span><span class="ltx_text ltx_lst_identifier" id="lstnumberx10.2">as</span><span class="ltx_text ltx_lst_space" id="lstnumberx10.3"> </span>{{<span class="ltx_text ltx_lst_identifier" id="lstnumberx10.4">return_statement</span>}}.
</div>
<div class="ltx_listingline" id="lstnumberx11">
<span class="ltx_text ltx_lst_space" id="lstnumberx11.1"> </span>},
</div>
<div class="ltx_listingline" id="lstnumberx12">
<span class="ltx_text ltx_lst_space" id="lstnumberx12.1"> </span>”<span class="ltx_text ltx_lst_identifier" id="lstnumberx12.2">file_name</span>”:&lt;&lt;<span class="ltx_text ltx_lst_identifier" id="lstnumberx12.3">name</span><span class="ltx_text ltx_lst_space" id="lstnumberx12.4"> </span><span class="ltx_text ltx_lst_identifier" id="lstnumberx12.5">of</span><span class="ltx_text ltx_lst_space" id="lstnumberx12.6"> </span><span class="ltx_text ltx_lst_identifier" id="lstnumberx12.7">the</span><span class="ltx_text ltx_lst_space" id="lstnumberx12.8"> </span><span class="ltx_text ltx_lst_identifier" id="lstnumberx12.9">file</span>&gt;&gt;,
</div>
<div class="ltx_listingline" id="lstnumberx13">
<span class="ltx_text ltx_lst_space" id="lstnumberx13.1"> </span>”<span class="ltx_text ltx_lst_identifier" id="lstnumberx13.2">parent_class</span>”:&lt;&lt;<span class="ltx_text ltx_lst_identifier" id="lstnumberx13.3">name</span><span class="ltx_text ltx_lst_space" id="lstnumberx13.4"> </span><span class="ltx_text ltx_lst_identifier" id="lstnumberx13.5">of</span><span class="ltx_text ltx_lst_space" id="lstnumberx13.6"> </span><span class="ltx_text ltx_lst_identifier" id="lstnumberx13.7">the</span><span class="ltx_text ltx_lst_space" id="lstnumberx13.8"> </span><span class="ltx_text ltx_lst_identifier" id="lstnumberx13.9">parent</span>
</div>
<div class="ltx_listingline" id="lstnumberx14">
<span class="ltx_text ltx_lst_space" id="lstnumberx14.1"> </span><span class="ltx_text ltx_lst_identifier" id="lstnumberx14.2">class</span><span class="ltx_text ltx_lst_space" id="lstnumberx14.3"> </span><span class="ltx_text ltx_lst_identifier" id="lstnumberx14.4">or</span><span class="ltx_text ltx_lst_space" id="lstnumberx14.5"> </span><span class="ltx_text ltx_lst_identifier" id="lstnumberx14.6">None</span><span class="ltx_text ltx_lst_space" id="lstnumberx14.7"> </span><span class="ltx_text ltx_lst_identifier" id="lstnumberx14.8">if</span><span class="ltx_text ltx_lst_space" id="lstnumberx14.9"> </span><span class="ltx_text ltx_lst_identifier" id="lstnumberx14.10">its</span><span class="ltx_text ltx_lst_space" id="lstnumberx14.11"> </span><span class="ltx_text ltx_lst_identifier" id="lstnumberx14.12">a</span><span class="ltx_text ltx_lst_space" id="lstnumberx14.13"> </span><span class="ltx_text ltx_lst_identifier" id="lstnumberx14.14">method</span>&gt;&gt;
</div>
<div class="ltx_listingline" id="lstnumberx15">
<span class="ltx_text ltx_lst_space" id="lstnumberx15.1"> </span>}”
</div>
<div class="ltx_listingline" id="lstnumberx16">}
</div>
</div>
</figure>
<div class="ltx_para" id="S3.SS1.SSS1.p2">
<p class="ltx_p" id="S3.SS1.SSS1.p2.1">We implemented method-level embeddings to identify the most relevant methods for a given problem statement. Each method or function within the codebase was parsed and its information was converted into a string representation for embedding generation. The embedding incorporates the method or function name, signature, return statements, and docstring. These individual document representations were then vectorized and stored in the vector store.
The Repository Level File Map was generated through a recursive parsing of the codebase, extracting relative filenames from the root folder. This map serves as an additional resource for inferring the most relevant files. A snippet of this is shown in Listing 2.</p>
</div>
<figure class="ltx_float ltx_lstlisting" id="LST2">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_float">Listing 2: </span>Repository Level File Map</figcaption>
<div class="ltx_listing ltx_lstlisting ltx_listing" id="LST2.1">
<div class="ltx_listing_data"><a download="" href="data:text/plain;base64,ICAgIHsKICAgICJtYXRwbG90bGliIjogWwogICAgICAgICJzZXR1cGV4dC5weSIsCiAgICAgICAgInNldHVwLnB5IiwKICAgICAgICAidGVzdHMucHkiCiAgICBdLAogICAgIm1hdHBsb3RsaWIvdG9vbHMiOiBbCiAgICAgICAgImdoX2FwaS5weSIsCiAgICAgICAgImJvaWxlcnBsYXRlLnB5IiwKICAgICAgICAiY2FjaGVfemVub2RvX3N2Zy5weSIsCiAgICAgICAgImdpdGh1Yl9zdGF0cy5weSIsCiAgICAgICAgImVtYmVkX2pzLnB5IiwKICAgICAgICAidHJpYWdlX3Rlc3RzLnB5IiwKICAgICAgICAicnVuX2V4YW1wbGVzLnB5IiwKICAgICAgICAic3Vic2V0LnB5IiwKICAgICAgICAidmlzdWFsaXplX3Rlc3RzLnB5IiwKICAgICAgICAibWVtbGVhay5weSIsCiAgICAgICAgIm1ha2VfaWNvbnMucHkiCiAgICBdLAogICAgIm1hdHBsb3RsaWIvY2kiOiBbCiAgICAgICAgImNoZWNrX3doZWVsX2xpY2Vuc2VzLnB5IgogICAgXSwKICAgIC4KICAgIC4KICAgIC4KICAgIH0=">⬇</a></div>
<div class="ltx_listingline" id="lstnumberx17">
<span class="ltx_text ltx_lst_space" id="lstnumberx17.1"> </span>{
</div>
<div class="ltx_listingline" id="lstnumberx18">
<span class="ltx_text ltx_lst_space" id="lstnumberx18.1"> </span>”<span class="ltx_text ltx_lst_identifier" id="lstnumberx18.2">matplotlib</span>”:<span class="ltx_text ltx_lst_space" id="lstnumberx18.3"> </span>[
</div>
<div class="ltx_listingline" id="lstnumberx19">
<span class="ltx_text ltx_lst_space" id="lstnumberx19.1"> </span>”<span class="ltx_text ltx_lst_identifier" id="lstnumberx19.2">setupext</span>.<span class="ltx_text ltx_lst_identifier" id="lstnumberx19.3">py</span>”,
</div>
<div class="ltx_listingline" id="lstnumberx20">
<span class="ltx_text ltx_lst_space" id="lstnumberx20.1"> </span>”<span class="ltx_text ltx_lst_identifier" id="lstnumberx20.2">setup</span>.<span class="ltx_text ltx_lst_identifier" id="lstnumberx20.3">py</span>”,
</div>
<div class="ltx_listingline" id="lstnumberx21">
<span class="ltx_text ltx_lst_space" id="lstnumberx21.1"> </span>”<span class="ltx_text ltx_lst_identifier" id="lstnumberx21.2">tests</span>.<span class="ltx_text ltx_lst_identifier" id="lstnumberx21.3">py</span>”
</div>
<div class="ltx_listingline" id="lstnumberx22">
<span class="ltx_text ltx_lst_space" id="lstnumberx22.1"> </span>],
</div>
<div class="ltx_listingline" id="lstnumberx23">
<span class="ltx_text ltx_lst_space" id="lstnumberx23.1"> </span>”<span class="ltx_text ltx_lst_identifier" id="lstnumberx23.2">matplotlib</span>/<span class="ltx_text ltx_lst_identifier" id="lstnumberx23.3">tools</span>”:<span class="ltx_text ltx_lst_space" id="lstnumberx23.4"> </span>[
</div>
<div class="ltx_listingline" id="lstnumberx24">
<span class="ltx_text ltx_lst_space" id="lstnumberx24.1"> </span>”<span class="ltx_text ltx_lst_identifier" id="lstnumberx24.2">gh_api</span>.<span class="ltx_text ltx_lst_identifier" id="lstnumberx24.3">py</span>”,
</div>
<div class="ltx_listingline" id="lstnumberx25">
<span class="ltx_text ltx_lst_space" id="lstnumberx25.1"> </span>”<span class="ltx_text ltx_lst_identifier" id="lstnumberx25.2">boilerplate</span>.<span class="ltx_text ltx_lst_identifier" id="lstnumberx25.3">py</span>”,
</div>
<div class="ltx_listingline" id="lstnumberx26">
<span class="ltx_text ltx_lst_space" id="lstnumberx26.1"> </span>”<span class="ltx_text ltx_lst_identifier" id="lstnumberx26.2">cache_zenodo_svg</span>.<span class="ltx_text ltx_lst_identifier" id="lstnumberx26.3">py</span>”,
</div>
<div class="ltx_listingline" id="lstnumberx27">
<span class="ltx_text ltx_lst_space" id="lstnumberx27.1"> </span>”<span class="ltx_text ltx_lst_identifier" id="lstnumberx27.2">github_stats</span>.<span class="ltx_text ltx_lst_identifier" id="lstnumberx27.3">py</span>”,
</div>
<div class="ltx_listingline" id="lstnumberx28">
<span class="ltx_text ltx_lst_space" id="lstnumberx28.1"> </span>”<span class="ltx_text ltx_lst_identifier" id="lstnumberx28.2">embed_js</span>.<span class="ltx_text ltx_lst_identifier" id="lstnumberx28.3">py</span>”,
</div>
<div class="ltx_listingline" id="lstnumberx29">
<span class="ltx_text ltx_lst_space" id="lstnumberx29.1"> </span>”<span class="ltx_text ltx_lst_identifier" id="lstnumberx29.2">triage_tests</span>.<span class="ltx_text ltx_lst_identifier" id="lstnumberx29.3">py</span>”,
</div>
<div class="ltx_listingline" id="lstnumberx30">
<span class="ltx_text ltx_lst_space" id="lstnumberx30.1"> </span>”<span class="ltx_text ltx_lst_identifier" id="lstnumberx30.2">run_examples</span>.<span class="ltx_text ltx_lst_identifier" id="lstnumberx30.3">py</span>”,
</div>
<div class="ltx_listingline" id="lstnumberx31">
<span class="ltx_text ltx_lst_space" id="lstnumberx31.1"> </span>”<span class="ltx_text ltx_lst_identifier" id="lstnumberx31.2">subset</span>.<span class="ltx_text ltx_lst_identifier" id="lstnumberx31.3">py</span>”,
</div>
<div class="ltx_listingline" id="lstnumberx32">
<span class="ltx_text ltx_lst_space" id="lstnumberx32.1"> </span>”<span class="ltx_text ltx_lst_identifier" id="lstnumberx32.2">visualize_tests</span>.<span class="ltx_text ltx_lst_identifier" id="lstnumberx32.3">py</span>”,
</div>
<div class="ltx_listingline" id="lstnumberx33">
<span class="ltx_text ltx_lst_space" id="lstnumberx33.1"> </span>”<span class="ltx_text ltx_lst_identifier" id="lstnumberx33.2">memleak</span>.<span class="ltx_text ltx_lst_identifier" id="lstnumberx33.3">py</span>”,
</div>
<div class="ltx_listingline" id="lstnumberx34">
<span class="ltx_text ltx_lst_space" id="lstnumberx34.1"> </span>”<span class="ltx_text ltx_lst_identifier" id="lstnumberx34.2">make_icons</span>.<span class="ltx_text ltx_lst_identifier" id="lstnumberx34.3">py</span>”
</div>
<div class="ltx_listingline" id="lstnumberx35">
<span class="ltx_text ltx_lst_space" id="lstnumberx35.1"> </span>],
</div>
<div class="ltx_listingline" id="lstnumberx36">
<span class="ltx_text ltx_lst_space" id="lstnumberx36.1"> </span>”<span class="ltx_text ltx_lst_identifier" id="lstnumberx36.2">matplotlib</span>/<span class="ltx_text ltx_lst_identifier" id="lstnumberx36.3">ci</span>”:<span class="ltx_text ltx_lst_space" id="lstnumberx36.4"> </span>[
</div>
<div class="ltx_listingline" id="lstnumberx37">
<span class="ltx_text ltx_lst_space" id="lstnumberx37.1"> </span>”<span class="ltx_text ltx_lst_identifier" id="lstnumberx37.2">check_wheel_licenses</span>.<span class="ltx_text ltx_lst_identifier" id="lstnumberx37.3">py</span>”
</div>
<div class="ltx_listingline" id="lstnumberx38">
<span class="ltx_text ltx_lst_space" id="lstnumberx38.1"> </span>],
</div>
<div class="ltx_listingline" id="lstnumberx39">
<span class="ltx_text ltx_lst_space" id="lstnumberx39.1"> </span>.
</div>
<div class="ltx_listingline" id="lstnumberx40">
<span class="ltx_text ltx_lst_space" id="lstnumberx40.1"> </span>.
</div>
<div class="ltx_listingline" id="lstnumberx41">
<span class="ltx_text ltx_lst_space" id="lstnumberx41.1"> </span>.
</div>
<div class="ltx_listingline" id="lstnumberx42">
<span class="ltx_text ltx_lst_space" id="lstnumberx42.1"> </span>}
</div>
</div>
</figure>
<div class="ltx_para" id="S3.SS1.SSS1.p3">
<p class="ltx_p" id="S3.SS1.SSS1.p3.1">Utilizing these two distinct modules, we process a problem statement by converting it into ’N’ queries via the QueryGeneration module, which employs a separate LLM call. These ’N’ queries are then used to interrogate the vector store, retrieving the most relevant filenames from the extracted chunks. Concurrently, we invoke the FileLocater module through another LLM call, which processes the Repository File Level Map to return the top ’M’ filenames. The final set of candidate files is determined by performing a union operation on these two lists of filenames.
This dual-pronged approach, combining semantic search through RAG with structural analysis via the Repository File Level Map, enhances the robustness and accuracy of our file localization process. The integration of these complementary methods allows for a more comprehensive and nuanced identification of relevant code sections, thereby improving the overall efficiency of the bug localization process.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S3.SS1.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span class="ltx_text" id="S3.SS1.SSS2.5.1.1">III-A</span>2 </span>File Prioritization using File Level Schematic Map</h4>
<div class="ltx_para" id="S3.SS1.SSS2.p1">
<p class="ltx_p" id="S3.SS1.SSS2.p1.1">Building upon the set of candidate files identified in the previous step, this phase involves the creation of a schematic representation for each file, providing a comprehensive overview of its internal structure. This schematic representation encompasses detailed descriptions of all classes and functions within the file. The schema includes class names, contained methods, method arguments, applied decorators, and available docstrings.
This abstracted representation enables the Large Language Model (LLM) to gain a high-level perspective of the filegroup, facilitating more accurate identification of files closely related to the problem statement. The PreAssimilation Module is then employed to further refine the search space, narrowing down the potential bug location to the top ’L’ files.
Notably, the value of ’L’ is dynamically determined by the LLM itself, allowing for adaptive file selection based on the complexity and nature of the problem. Through extensive experimentation, we observed that in exploratory scenarios, such as when SuperCoder2.0 is tasked with creating a new feature, allowing the LLM to autonomously select relevant files yields optimal results.
For the specific evaluation conducted on SWE Bench Lite, we implemented a constraint limiting ’L’ to a maximum of two files. In this configuration, the PreAssimilator module returns either the single most relevant file or, in more complex cases, the two most pertinent files along with a rationale for their selection.
This file and method localisation approach (Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.11190v1#S3.F1" title="Figure 1 ‣ III-A3 Localization of ’Relevant Locations’ ‣ III-A Search ‣ III Methodology ‣ SuperCoder2.0: Technical Report on Exploring the feasibility of LLMs as Autonomous Programmer * These authors have contributed equally."><span class="ltx_text ltx_ref_tag">1</span></a>) strikes a balance between comprehensive search and computational efficiency, enabling SuperCoder2.0 to focus on the most promising areas of the codebase while maintaining the flexibility to handle diverse problem types. The integration of LLM-driven file selection with the structured schematic representation enhances the system’s ability to navigate and understand complex codebases, thereby improving its overall problem-solving capabilities.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S3.SS1.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span class="ltx_text" id="S3.SS1.SSS3.5.1.1">III-A</span>3 </span>Localization of ’Relevant Locations’</h4>
<div class="ltx_para" id="S3.SS1.SSS3.p1">
<p class="ltx_p" id="S3.SS1.SSS3.p1.1">Following the identification of the top ’L’ files in the preceding steps, the process advances to pinpointing specific areas within these files where modifications are required. This task is accomplished through the deployment of the CoderParser Module, a sophisticated component designed to analyze the problem statement in conjunction with the entire file content.
The CoderParser Module performs a comprehensive analysis, outputting both the precise location and a detailed plan for necessary code alterations. The full specifications of this process are delineated in Appendix 1c. Our approach categorizes potential code changes into three distinct hierarchical levels:</p>
<ul class="ltx_itemize" id="S3.I2">
<li class="ltx_item" id="S3.I2.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I2.i1.p1">
<p class="ltx_p" id="S3.I2.i1.p1.1">Top-Level code modifications</p>
</div>
</li>
<li class="ltx_item" id="S3.I2.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I2.i2.p1">
<p class="ltx_p" id="S3.I2.i2.p1.1">Method or Function level alterations</p>
</div>
</li>
<li class="ltx_item" id="S3.I2.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I2.i3.p1">
<p class="ltx_p" id="S3.I2.i3.p1.1">Class-Level adjustments</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="S3.SS1.SSS3.p2">
<p class="ltx_p" id="S3.SS1.SSS3.p2.1">This stratified approach was developed in response to empirical observations revealing that line-level edits frequently resulted in linting issues, particularly in languages with strict indentation requirements such as Python. Consequently, we adopted a strategy of high-level code replacement, focusing on class-level or method-level modifications generated by the LLM.
For top-level code changes, the LLM is instructed to specify start and end line numbers delineating the section requiring modification. This demarcated code segment is then replaced in its entirety.
This methodology ensures the maintenance of code structure and integrity while allowing for comprehensive modifications. It mitigates potential syntax errors and maintains consistency with the existing codebase architecture. The specific implementation details of this editing process are elaborated upon in the subsequent Edit section.
By employing this hierarchical, structure-aware approach to code modification, SuperCoder2.0 achieves a balance between granular problem-solving and preservation of overall code quality and consistency. This method enhances the system’s ability to implement complex changes while minimizing unintended side effects or structural disruptions to the codebase.</p>
</div>
<figure class="ltx_figure" id="S3.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_portrait" height="471" id="S3.F1.g1" src="extracted/5860716/file_and_method.png" width="236"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>File and Method localisation</figcaption>
</figure>
</section>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S3.SS2.5.1.1">III-B</span> </span><span class="ltx_text ltx_font_italic" id="S3.SS2.6.2">Code Modification and Insertion</span>
</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">The Code Modification and Insertion module is responsible for implementing the actual code changes as determined by the preceding analysis. This module operates based on the action plan provided by the CodeParser module, processing each plan element sequentially. The module receives relevant class or method information, or in the case of top-level code modifications, it obtains the code segment defined by pre-determined start and end lines.
The module’s architecture comprises two primary components:</p>
<ul class="ltx_itemize" id="S3.I3">
<li class="ltx_item" id="S3.I3.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I3.i1.p1">
<p class="ltx_p" id="S3.I3.i1.p1.1">CodeGeneration Module</p>
</div>
</li>
<li class="ltx_item" id="S3.I3.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I3.i2.p1">
<p class="ltx_p" id="S3.I3.i2.p1.1">CodeEditing Module</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="S3.SS2.p2">
<p class="ltx_p" id="S3.SS2.p2.1">The CodeGeneration Module leverages advanced LLMs to generate new or modified code segments based on the provided action plan and context.
In contrast, the CodeEditing Module operates independently of LLMs, utilizing the Abstract Syntax Tree (AST) library in Python for precise code manipulation. This module processes the class name, method name, or specific lines of code targeted for modification, implementing the changes as specified in the action plan.
When modifications are suggested for a method, the CodeGeneration Module regenerates the entire method body. Subsequently, the CodeEditing Module replaces the original method with this newly generated code, ensuring syntactic correctness and maintaining the overall structure of the codebase.
This bifurcated approach allows for a separation of concerns between code generation and code integration, enhancing the system’s ability to produce contextually appropriate modifications while preserving the integrity of the existing codebase structure. The use of AST-based editing ensures that the modifications are implemented with precision, reducing the risk of introducing syntactic errors or inconsistencies.
By combining LLM-driven code generation with AST-based code editing, this module achieves a balance between creative problem-solving and structural code maintenance, contributing to the overall robustness and reliability of the SuperCoder2.0 system.</p>
</div>
<section class="ltx_subsubsection" id="S3.SS2.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span class="ltx_text" id="S3.SS2.SSS1.5.1.1">III-B</span>1 </span>Code Generation and Editing Process</h4>
<div class="ltx_para" id="S3.SS2.SSS1.p1">
<p class="ltx_p" id="S3.SS2.SSS1.p1.1">The code generation and editing process is initiated by invoking an LLM with inputs comprising the action plan, problem statement, and relevant code segments (class, method, or top-level code) identified in the preceding steps. This LLM invocation is executed iteratively for each plan element generated by the CodeParser module.
To enhance robustness and solution diversity, we employ a multi-temperature sampling approach. For each plan, ’k’ distinct LLM calls are made, each with a different temperature setting, yielding ’k’ potential solutions for the given problem statement. This strategy allows for the exploration of various solution spaces, potentially uncovering more optimal or creative resolutions.
The editing process is tailored to the hierarchical level of the relevant code location:</p>
<ul class="ltx_itemize" id="S3.I4">
<li class="ltx_item" id="S3.I4.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I4.i1.p1">
<p class="ltx_p" id="S3.I4.i1.p1.1">For class-level modifications, the entire class code is replaced with the newly generated class code using AST module.</p>
</div>
</li>
<li class="ltx_item" id="S3.I4.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I4.i2.p1">
<p class="ltx_p" id="S3.I4.i2.p1.1">For method or function-level changes, the AST module in Python is utilized to replace the entire method or function body.</p>
</div>
</li>
<li class="ltx_item" id="S3.I4.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I4.i3.p1">
<p class="ltx_p" id="S3.I4.i3.p1.1">For top-level code alterations, the LLM generates start and end line numbers, and the code within this range is substituted with the newly generated code.</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="S3.SS2.SSS1.p2">
<p class="ltx_p" id="S3.SS2.SSS1.p2.1">Following the generation of ’k’ potential solutions, a comprehensive validation process is initiated. Each solution undergoes evaluation against the full suite of repository-level test cases, rather than a subset, ensuring thorough verification of code integrity and functionality.
Solutions that induce failures in previously passing tests are systematically eliminated from consideration. In scenarios where multiple viable solutions remain post-validation, an additional LLM call is made. This final invocation is tasked with selecting the optimal solution based on the original problem statement and any additional context derived from the validation process.
This multi-stage, temperature-varied generation and rigorous validation approach significantly enhances the reliability and effectiveness of the code modification process. By leveraging both divergent solution generation and convergent solution selection, SuperCoder2.0 maximizes its potential to produce high-quality, contextually appropriate code modifications while minimizing the risk of introducing new errors or regressions.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S3.SS3.5.1.1">III-C</span> </span><span class="ltx_text ltx_font_italic" id="S3.SS3.6.2">Iterative Feedback and Refinement Mechanism</span>
</h3>
<div class="ltx_para" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.1">SuperCoder2.0 incorporates a sophisticated feedback and refinement mechanism to ensure the integrity and effectiveness of generated code solutions. This process is structured as follows:</p>
<ul class="ltx_itemize" id="S3.I5">
<li class="ltx_item" id="S3.I5.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I5.i1.p1">
<p class="ltx_p" id="S3.I5.i1.p1.1">Pre-Application Baseline:
Prior to the application of any generated code, a comprehensive execution of all repository-level test cases is conducted. The results, including both passed and failed tests, are meticulously recorded to establish a baseline performance metric.</p>
</div>
</li>
<li class="ltx_item" id="S3.I5.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I5.i2.p1">
<p class="ltx_p" id="S3.I5.i2.p1.1">Post-Application Evaluation:
Following the implementation of each generated solution, the entire suite of repository-level test cases is re-executed. This step is crucial for identifying any newly introduced failures or regressions.</p>
</div>
</li>
<li class="ltx_item" id="S3.I5.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I5.i3.p1">
<p class="ltx_p" id="S3.I5.i3.p1.1">Feedback Loop Activation:
In the event that new test case failures are detected, a feedback loop is initiated. This loop triggers the CodeGeneration module to refine the specific solution that induced the failure. Notably, this refinement process is targeted and does not involve the generation of multiple candidate solutions through temperature sweeps, as in the initial generation phase.</p>
</div>
</li>
<li class="ltx_item" id="S3.I5.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I5.i4.p1">
<p class="ltx_p" id="S3.I5.i4.p1.1">Iterative Refinement:
The feedback and refinement process is applied iteratively to each potential solution. While the system is designed to support multiple iterations of this process for each solution, we have implemented a constraint limiting it to a single iteration to optimize token usage and computational efficiency.</p>
</div>
</li>
<li class="ltx_item" id="S3.I5.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I5.i5.p1">
<p class="ltx_p" id="S3.I5.i5.p1.1">Contextual Information Provision:
The feedback loop supplies the CodeGeneration LLM with detailed information about the failed test case, including the relevant code segment and the original problem statement. This comprehensive context enables the LLM to perform targeted and informed corrections.</p>
</div>
</li>
</ul>
</div>
<figure class="ltx_figure" id="S3.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="345" id="S3.F2.g1" src="extracted/5860716/code_edit.png" width="314"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Code generation and retry mechanism to find viable solution</figcaption>
</figure>
<div class="ltx_para" id="S3.SS3.p2">
<p class="ltx_p" id="S3.SS3.p2.1">This iterative feedback mechanism (Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.11190v1#S3.F2" title="Figure 2 ‣ III-C Iterative Feedback and Refinement Mechanism ‣ III Methodology ‣ SuperCoder2.0: Technical Report on Exploring the feasibility of LLMs as Autonomous Programmer * These authors have contributed equally."><span class="ltx_text ltx_ref_tag">2</span></a>) enhances the system’s ability to produce robust, error-free code modifications. By providing specific failure information and allowing for targeted refinements, SuperCoder2.0 can adapt its solutions in response to complex, interdependent code structures and unforeseen edge cases. This approach strikes a balance between solution quality and computational efficiency, contributing to the overall effectiveness and reliability of the autonomous coding system.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">IV </span><span class="ltx_text ltx_font_smallcaps" id="S4.1.1">Experimental Methodology and Dataset Analysis</span>
</h2>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S4.SS1.5.1.1">IV-A</span> </span><span class="ltx_text ltx_font_italic" id="S4.SS1.6.2">Experimental Design on SWE-Bench Lite</span>
</h3>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">The development and experimental evaluation of SuperCoder2.0 were extensively conducted using the SWE-Bench Lite dataset. To ensure rigorous and unbiased assessment, several methodological adjustments were implemented during the evaluation phase:</p>
<ul class="ltx_itemize" id="S4.I1">
<li class="ltx_item" id="S4.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i1.p1">
<p class="ltx_p" id="S4.I1.i1.p1.1">Exclusion of Hints: No external hints or guidance were utilized during the problem-solving process.</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i2.p1">
<p class="ltx_p" id="S4.I1.i2.p1.1">Comprehensive Test Suite Execution: Instead of relying on pass-to-pass or fail-to-pass metrics for solution filtering, the entire test suite was executed on the repository both before and after the application of each generated solution. This approach provides a more holistic evaluation of solution impact.</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i3.p1">
<p class="ltx_p" id="S4.I1.i3.p1.1">Targeted Feedback Utilization: Feedback mechanisms were exclusively applied to test cases that transitioned from a passing state to a failing state post-solution implementation. This targeted approach focuses on addressing newly introduced issues.</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i4.p1">
<p class="ltx_p" id="S4.I1.i4.p1.1">Delayed Test Patch Application: The test patch was applied only after the final candidate solution was selected, thereby preventing any potential information leakage that could bias the solution generation process.</p>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S4.SS2.5.1.1">IV-B</span> </span><span class="ltx_text ltx_font_italic" id="S4.SS2.6.2">Dataset Characteristics and Selection Rationale</span>
</h3>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">The study employs the SWE-bench Lite dataset, a carefully curated subset of the original SWE-bench dataset provided by the SWE-Bench team itself.</p>
</div>
<section class="ltx_subsubsection" id="S4.SS2.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span class="ltx_text" id="S4.SS2.SSS1.5.1.1">IV-B</span>1 </span>Original SWE-bench Dataset</h4>
<div class="ltx_para" id="S4.SS2.SSS1.p1">
<p class="ltx_p" id="S4.SS2.SSS1.p1.1">The SWE-bench dataset was initially conceived to offer a comprehensive array of codebase problems verifiable through in-repository unit tests. It encompasses 2,294 issue-commit pairs distributed across 12 distinct Python repositories. While extensive, the dataset presented significant challenges:</p>
</div>
<div class="ltx_para" id="S4.SS2.SSS1.p2">
<p class="ltx_p" id="S4.SS2.SSS1.p2.1">Computational Intensity: The scale of SWE-bench imposed substantial demands on time and computational resources for thorough evaluation.
Complexity: The intricate nature of the problems made SWE-bench a formidable benchmark, potentially deterring systems aimed at incremental progress.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S4.SS2.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span class="ltx_text" id="S4.SS2.SSS2.5.1.1">IV-B</span>2 </span>SWE-bench Lite: A Focused Subset</h4>
<div class="ltx_para" id="S4.SS2.SSS2.p1">
<p class="ltx_p" id="S4.SS2.SSS2.p1.1">To address these limitations, SWE-bench Lite was developed, comprising 300 carefully selected instances from the original dataset. Key features of this subset include:</p>
</div>
<div class="ltx_para" id="S4.SS2.SSS2.p2">
<p class="ltx_p" id="S4.SS2.SSS2.p2.1">Self-Containment: Problems are more self-contained, facilitating focused evaluation.
Functional Bug Fix Emphasis: The subset prioritizes the assessment of functional bug-fixing capabilities.
Preserved Diversity: SWE-bench Lite maintains the repository distribution and problem diversity of the original dataset.
Computational Efficiency: The reduced scale allows for more manageable and efficient computational evaluations.</p>
</div>
<div class="ltx_para" id="S4.SS2.SSS2.p3">
<p class="ltx_p" id="S4.SS2.SSS2.p3.1">This strategic subset selection enables a more accessible yet representative benchmark, striking a balance between comprehensive evaluation and practical feasibility. It provides a platform for assessing incremental progress in autonomous coding systems while retaining the challenging and diverse nature of real-world software engineering problems.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S4.SS3.5.1.1">IV-C</span> </span><span class="ltx_text ltx_font_italic" id="S4.SS3.6.2">Evaluation Metrics and Performance Analysis</span>
</h3>
<div class="ltx_para" id="S4.SS3.p1">
<p class="ltx_p" id="S4.SS3.p1.1">To rigorously assess the efficacy of SuperCoder2.0 on the SWE-Bench Lite dataset, we employed a multi-faceted evaluation framework encompassing these primary metrics:</p>
</div>
<div class="ltx_para" id="S4.SS3.p2">
<ul class="ltx_itemize" id="S4.I2">
<li class="ltx_item" id="S4.I2.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I2.i1.p1">
<p class="ltx_p" id="S4.I2.i1.p1.1">Resolution Rate:
Defined as the ratio of successfully resolved instances to the total number of instances (300) in the dataset. This metric provides a direct measure of the system’s problem-solving capability across diverse coding challenges.</p>
</div>
</li>
<li class="ltx_item" id="S4.I2.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I2.i2.p1">
<p class="ltx_p" id="S4.I2.i2.p1.1">File-Level Localization Accuracy:
Measures the system’s ability to correctly identify the file(s) containing the bug or requiring modification.
</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="S4.SS3.p3">
<p class="ltx_p" id="S4.SS3.p3.1">These granular localization metrics provide valuable insights into the system’s diagnostic capabilities, which are crucial for efficient problem-solving in large codebases.
The combination of these
metrics offers a comprehensive view of SuperCoder2.0’s performance, balancing between problem-solving effectiveness, computational efficiency, and precision in issue localization. This multi-dimensional evaluation approach allows for a nuanced understanding of the system’s strengths and areas for potential improvement, facilitating targeted enhancements in future iterations of the technology.</p>
</div>
<figure class="ltx_table" id="S4.T1">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T1.1.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T1.1.1.1.1">Framework/Tool</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T1.1.1.1.2">Resolved (in %)</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T1.1.2.1">
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.2.1.1">CodeStory Aide + Mixed Models</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.2.1.2">43.00</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.3.2">
<td class="ltx_td ltx_align_center" id="S4.T1.1.3.2.1">AbanteAI MentatBot + GPT 4o (2024-05-13)</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.3.2.2">38.00</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.4.3">
<td class="ltx_td ltx_align_center" id="S4.T1.1.4.3.1">Gru(2024-08-11)</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.4.3.2">35.67</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.5.4">
<td class="ltx_td ltx_align_center" id="S4.T1.1.5.4.1"><span class="ltx_text ltx_font_bold" id="S4.T1.1.5.4.1.1">SuperCoder2.0</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.5.4.2"><span class="ltx_text ltx_font_bold" id="S4.T1.1.5.4.2.1">34.00</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.6.5">
<td class="ltx_td ltx_align_center" id="S4.T1.1.6.5.1">Bytedance MarsCode Agent + GPT 4o (2024-05-13)</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.6.5.2">34.00</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.7.6">
<td class="ltx_td ltx_align_center" id="S4.T1.1.7.6.1">Alibaba Lingma Agent</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.7.6.2">33.00</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.8.7">
<td class="ltx_td ltx_align_center" id="S4.T1.1.8.7.1">AutoCodeRover</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.8.7.2">30.67</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.9.8">
<td class="ltx_td ltx_align_center" id="S4.T1.1.9.8.1">Amazon Q Developer Agent</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.9.8.2">29.67</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.10.9">
<td class="ltx_td ltx_align_center" id="S4.T1.1.10.9.1">Agentless + RepoGraph + GPT-4o</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.10.9.2">29.67</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.11.10">
<td class="ltx_td ltx_align_center" id="S4.T1.1.11.10.1">CodeR + GPT 4</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.11.10.2">28.33</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.12.11">
<td class="ltx_td ltx_align_center" id="S4.T1.1.12.11.1">MASAI + GPT 4o</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.12.11.2">28.00</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.13.12">
<td class="ltx_td ltx_align_center" id="S4.T1.1.13.12.1">SIMA + GPT 4o</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.13.12.2">27.67</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.14.13">
<td class="ltx_td ltx_align_center" id="S4.T1.1.14.13.1">Moatless Tools + Claude 3.5 Sonnet</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.14.13.2">26.67</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.15.14">
<td class="ltx_td ltx_align_center" id="S4.T1.1.15.14.1">OpenDevin + CodeAct v1.8</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.15.14.2">26.67</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.16.15">
<td class="ltx_td ltx_align_center" id="S4.T1.1.16.15.1">IBM Research Agent-101</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.16.15.2">26.67</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.17.16">
<td class="ltx_td ltx_align_center" id="S4.T1.1.17.16.1">Aider + GPT 4o &amp; Claude 3 Opus</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.17.16.2">26.33</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.18.17">
<td class="ltx_td ltx_align_center" id="S4.T1.1.18.17.1">OpenCSG StarShip CodeGenAgent + GPT 4 (0613)</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.18.17.2">23.67</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.19.18">
<td class="ltx_td ltx_align_center" id="S4.T1.1.19.18.1">SWE-agent + Claude 3.5 Sonnet</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.19.18.2">23.00</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE I: </span>Performance of other models and frameworks on SWE Bench Lite</figcaption>
</figure>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">V </span><span class="ltx_text ltx_font_smallcaps" id="S5.1.1">Results and Analysis on SWE-Bench Lite</span>
</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">The empirical evaluation of SuperCoder2.0 on the SWE-Bench Lite dataset yielded several significant insights into its performance and effectiveness in autonomous code modification tasks.</p>
</div>
<figure class="ltx_figure" id="S5.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="221" id="S5.F3.g1" src="extracted/5860716/output.png" width="314"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Percentage of correct file among the top-5 candidate files</figcaption>
</figure>
<section class="ltx_subsection" id="S5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S5.SS1.5.1.1">V-A</span> </span><span class="ltx_text ltx_font_italic" id="S5.SS1.6.2">File Localization Efficiency</span>
</h3>
<div class="ltx_para" id="S5.SS1.p1">
<p class="ltx_p" id="S5.SS1.p1.1">Our analysis revealed that the combination of Agentless’s hierarchical file structure approach with our retrieval-based method resulted in a marginal but notable improvement in performance. We posit that LLMs may have an inherent ability to infer relevant files from file structures, possibly due to exposure to similar patterns during pre-training. However, this hypothesis requires further investigation for conclusive validation.
The file localization efficiency was quantitatively assessed using a top-k analysis, with k values of 1 and 5. Notably, for k=5, SuperCoder2.0 achieved an accuracy of 84.33% in identifying the correct file among the candidate files (Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.11190v1#S5.F3" title="Figure 3 ‣ V Results and Analysis on SWE-Bench Lite ‣ SuperCoder2.0: Technical Report on Exploring the feasibility of LLMs as Autonomous Programmer * These authors have contributed equally."><span class="ltx_text ltx_ref_tag">3</span></a>). This high accuracy underscores the effectiveness of our combined RAG and Repository File Level Map approach in narrowing down the search space for relevant code sections.</p>
</div>
<figure class="ltx_figure" id="S5.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="225" id="S5.F4.g1" src="extracted/5860716/distribution_plot.png" width="314"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Repository Wise Performance</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S5.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S5.SS2.5.1.1">V-B</span> </span><span class="ltx_text ltx_font_italic" id="S5.SS2.6.2">Code Analysis and Editing Strategies</span>
</h3>
<div class="ltx_para" id="S5.SS2.p1">
<p class="ltx_p" id="S5.SS2.p1.1">Our experiments indicated that providing the entire code file for bug localization was more effective than supplying a high-level map alone. This observation has led to the development and adoption of a hierarchical search space reduction strategy, which has been subsequently implemented in various other works in the field.
In the context of code editing, particularly within the SWE-Bench Lite framework, we found that replacing entire method bodies yielded optimal results. This approach significantly reduced indentation errors compared to more granular cut-and-insert techniques. This finding opens avenues for future research into more sophisticated code editing methodologies.</p>
</div>
<figure class="ltx_figure" id="S5.F5"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="314" id="S5.F5.g1" src="extracted/5860716/Solved_vs_Not_Solved.png" width="314"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Repository Wise Performance</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S5.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S5.SS3.5.1.1">V-C</span> </span><span class="ltx_text ltx_font_italic" id="S5.SS3.6.2">Embedding Model Efficacy</span>
</h3>
<div class="ltx_para" id="S5.SS3.p1">
<p class="ltx_p" id="S5.SS3.p1.1">The implementation of Jina Code Embeddings for natural language to code mapping in our RAG system proved highly effective. This success suggests that further development and refinement of embedding models specifically tailored for NLP-to-Code applications could yield substantial improvements in autonomous coding systems.</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S5.SS4.5.1.1">V-D</span> </span><span class="ltx_text ltx_font_italic" id="S5.SS4.6.2">Cross-Repository Performance</span>
</h3>
<div class="ltx_para" id="S5.SS4.p1">
<p class="ltx_p" id="S5.SS4.p1.1">Analysis of SuperCoder2.0’s performance across different repositories in the test set (Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.11190v1#S5.F4" title="Figure 4 ‣ V-A File Localization Efficiency ‣ V Results and Analysis on SWE-Bench Lite ‣ SuperCoder2.0: Technical Report on Exploring the feasibility of LLMs as Autonomous Programmer * These authors have contributed equally."><span class="ltx_text ltx_ref_tag">4</span></a>) demonstrates its versatility in handling diverse codebases and problem types. This cross-repository consistency is a crucial indicator of the system’s robustness and adaptability to varied software engineering challenges.</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S5.SS5.5.1.1">V-E</span> </span><span class="ltx_text ltx_font_italic" id="S5.SS5.6.2">Overall Performance Metrics</span>
</h3>
<div class="ltx_para" id="S5.SS5.p1">
<p class="ltx_p" id="S5.SS5.p1.1">SuperCoder2.0 successfully resolved 34% of the instances in the SWE-Bench Lite dataset (Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.11190v1#S5.F5" title="Figure 5 ‣ V-B Code Analysis and Editing Strategies ‣ V Results and Analysis on SWE-Bench Lite ‣ SuperCoder2.0: Technical Report on Exploring the feasibility of LLMs as Autonomous Programmer * These authors have contributed equally."><span class="ltx_text ltx_ref_tag">5</span></a>). This performance places the system globally on the SWE-Bench leaderboard at the time of this writing. Table <a class="ltx_ref" href="https://arxiv.org/html/2409.11190v1#S4.T1" title="TABLE I ‣ IV-C Evaluation Metrics and Performance Analysis ‣ IV Experimental Methodology and Dataset Analysis ‣ SuperCoder2.0: Technical Report on Exploring the feasibility of LLMs as Autonomous Programmer * These authors have contributed equally."><span class="ltx_text ltx_ref_tag">I</span></a> provides a comparative analysis of SuperCoder2.0’s performance against other state-of-the-art models and frameworks.</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS6">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S5.SS6.5.1.1">V-F</span> </span><span class="ltx_text ltx_font_italic" id="S5.SS6.6.2">Comparative Analysis</span>
</h3>
<div class="ltx_para" id="S5.SS6.p1">
<p class="ltx_p" id="S5.SS6.p1.1">When compared to other leading systems (Table <a class="ltx_ref" href="https://arxiv.org/html/2409.11190v1#S4.T1" title="TABLE I ‣ IV-C Evaluation Metrics and Performance Analysis ‣ IV Experimental Methodology and Dataset Analysis ‣ SuperCoder2.0: Technical Report on Exploring the feasibility of LLMs as Autonomous Programmer * These authors have contributed equally."><span class="ltx_text ltx_ref_tag">I</span></a>), SuperCoder2.0’s performance is competitive, particularly considering its novel approach to code localization and editing. The system’s performance is comparable to established frameworks like Bytedance MarsCode Agent and surpasses several other prominent systems, including AutoCodeRover and Amazon Q Developer Agent.
These results collectively demonstrate SuperCoder2.0’s efficacy in autonomous code modification tasks, highlighting its strong performance in file localization and its ability to handle diverse coding challenges across various repositories. The system’s competitive standing on the SWE-Bench Lite leaderboard underscores its potential as a robust tool for automated software engineering tasks.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VI </span><span class="ltx_text ltx_font_smallcaps" id="S6.1.1">Conclusion and Future Work</span>
</h2>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">This paper presents SuperCoder2.0, an advanced autonomous system for software development that demonstrates significant capabilities in code navigation, bug localization, and automated code modification. Through a novel combination of hierarchical search space reduction, retrieval-augmented generation, and structure-aware code editing, SuperCoder2.0 achieves competitive performance on the SWE-Bench Lite dataset, resolving 34% of instances.
Key contributions of this work include:</p>
</div>
<div class="ltx_para" id="S6.p2">
<p class="ltx_p" id="S6.p2.1">A three-step hierarchical approach to codebase navigation and bug localization, combining RAG and file-level mapping techniques.
An innovative code editing strategy that preserves code structure and integrity while implementing comprehensive modifications.
An iterative feedback and refinement mechanism that enhances solution quality and reliability.</p>
</div>
<div class="ltx_para" id="S6.p3">
<p class="ltx_p" id="S6.p3.1">The system’s performance, particularly its 84.33% accuracy in file localization within the top 5 candidates, underscores the effectiveness of our combined RAG and Repository File Level Map approach. Furthermore, SuperCoder2.0’s ability to handle diverse repositories and problem types demonstrates its potential as a versatile tool for automated software engineering tasks.
Future work will focus on several areas like refining the code editing process to further reduce indentation errors and improve code quality.
Exploring advanced embedding models specifically tailored for NLP-to-Code applications to enhance the system’s understanding and generation capabilities.
Investigating the potential for multi-agent architectures to handle more complex software engineering tasks.
Extending the system’s capabilities to support multiple programming languages and diverse software development paradigms.</p>
</div>
<div class="ltx_para" id="S6.p4">
<p class="ltx_p" id="S6.p4.1">As autonomous coding systems continue to evolve, SuperCoder2.0 represents a significant step towards more efficient, reliable, and adaptable software development processes. By addressing the challenges of code navigation, bug localization, and automated code modification, this research contributes to the ongoing advancement of AI-assisted software engineering, paving the way for more sophisticated and capable autonomous programming systems in the future.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock"> Chen, M., Tworek, J., Jun, H., Yuan, Q., Pinto, H. P., Kaplan, J., Edwards, H., Burda, Y., Joseph, N., Brockman, G., Ray, A., Puri, R., Krueger, G., Petrov, M., Khlaaf, H., Sastry, G., Mishkin, P., Chan, B., Gray, S., . . . Zaremba, W. (2021). Evaluating Large Language Models Trained on Code. ArXiv. /abs/2107.03374

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock"> Lewis, P., Perez, E., Piktus, A., Petroni, F., Karpukhin, V., Goyal, N., Küttler, H., Lewis, M., Yih, W., Rocktäschel, T., Riedel, S., &amp; Kiela, D. (2020). Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks. ArXiv. /abs/2005.11401

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock"> Levin, K., Van Kempen, N., Berger, E. D., &amp; Freund, S. N. (2024). ChatDBG: An AI-Powered Debugging Assistant. ArXiv. /abs/2403.16354

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock"> B. Lussier, R. Chatila, J. Guiochet, F. Ingrand, A. Lampe, M.-O. Killijian, and D. Powell, “Fault tolerance in autonomous systems: How and how much?,” in Proc. LAAS-CNRS, Toulouse, France, 2004.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock"> A. V. Lopes, R. S. Heller, and M. B. Feldman, “Very high-level debugging,” *Computers &amp; Education*, vol. 22, no. 3, pp. 231-238, 1994, doi: 10.1016/0360-1315(94)90004-3.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock"> Jimenez, C. E., Yang, J., Wettig, A., Yao, S., Pei, K., Press, O., &amp; Narasimhan, K. (2023). SWE-bench: Can Language Models Resolve Real-World GitHub Issues? ArXiv. /abs/2310.06770

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">Yan, S., Yu, H., Chen, Y., Shen, B., &amp; Jiang, L. (2020, February). Are the code snippets what we are searching for? a benchmark and an empirical study on code search with natural-language queries. In 2020 IEEE 27th International Conference on Software Analysis, Evolution and Reengineering (SANER) (pp. 344-354). IEEE

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">Wasserman, A. I., &amp; Gutz, S. (1982). The future of programming. Communications of the ACM, 25(3), 196-206.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">Guinan, Patricia J., Jay G. Cooprider, and Steve Sawyer. ”The effective use of automated application development tools.” IBM Systems Journal 36.1 (1997): 124-139.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">Fisher, M., Mascardi, V., Rozier, K. Y., Schlingloff, B. H., Winikoff, M., &amp; Yorke-Smith, N. (2021). Towards a framework for certification of reliable autonomous systems. Autonomous Agents and Multi-Agent Systems, 35, 1-65.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">Rehman, Semeen, et al. ”Reliable code generation and execution on unreliable hardware under joint functional and timing reliability considerations.” 2013 IEEE 19th Real-Time and Embedded Technology and Applications Symposium (RTAS). IEEE, 2013.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">Florian, R. V. (2003). Autonomous artificial intelligent agents. Center for Cognitive and Neural Studies (Coneural), Cluj-Napoca, Romania.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">Xiong, H., Bian, J., Yang, S., Zhang, X., Kong, L., &amp; Zhang, D. (2023). Natural language based context modeling and reasoning with llms: A tutorial. arXiv preprint arXiv:2309.15074.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">Yang, K., Liu, J., Wu, J., Yang, C., Fung, Y. R., Li, S., … &amp; Zhai, C. (2024). If llm is the wizard, then code is the wand: A survey on how code empowers large language models to serve as intelligent agents. arXiv preprint arXiv:2401.00812.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">Jin, Haolin, et al. ”From LLMs to LLM-based Agents for Software Engineering: A Survey of Current, Challenges and Future.” arXiv preprint arXiv:2408.02479 (2024).

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">Ma, Yingwei, et al. ”Bridging Code Semantic and LLMs: Semantic Chain-of-Thought Prompting for Code Generation.” arXiv preprint arXiv:2310.10698 (2023).

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">Ding, Ning, et al. ”Parameter-efficient fine-tuning of large-scale pre-trained language models.” Nature Machine Intelligence 5.3 (2023): 220-235.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">Božić, Velibor. ”Artificial Intelligence in program engineering.”

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">Brown, Nik Bear. ”Enhancing Trust in LLMs: Algorithms for Comparing and Interpreting LLMs.” arXiv preprint arXiv:2406.01943 (2024).

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">Le, Triet HM, Hao Chen, and Muhammad Ali Babar. ”Deep learning for source code modeling and generation: Models, applications, and challenges.” ACM Computing Surveys (CSUR) 53.3 (2020): 1-38.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">Nijkamp, Erik, et al. ”Codegen: An open large language model for code with multi-turn program synthesis.” arXiv preprint arXiv:2203.13474 (2022)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">Wang, Xingyao, et al. ”Opendevin: An open platform for ai software developers as generalist agents.” arXiv preprint arXiv:2407.16741 (2024).

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">Jin, Matthew, et al. ”Inferfix: End-to-end program repair with llms.” Proceedings of the 31st ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering. 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">Lapuz, Neil, Paul Clarke, and Yalemisew Abgaz. ”Digital transformation and the role of dynamic tooling in extracting microservices from existing software systems.” European Conference on Software Process Improvement. Cham: Springer International Publishing, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">Chen, Yanan, et al. ”Can We Rely on LLM Agents to Draft Long-Horizon Plans? Let’s Take TravelPlanner as an Example.” arXiv preprint arXiv:2408.06318 (2024).

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">Shen, Weiming, Lihui Wang, and Qi Hao. ”Agent-based distributed manufacturing process planning and scheduling: a state-of-the-art survey.” IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews) 36.4 (2006): 563-577.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">Ahciarliu, Cantemir M. Multi-agent architecture for integrating remote databases and expert sources with situational awareness tools humanitarian operations scenario. Diss. Monterey, California. Naval Postgraduate School, 2004.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">Arora, Daman, et al. ”MASAI: Modular Architecture for Software-engineering AI Agents.” arXiv preprint arXiv:2406.11638 (2024).

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">Aider: https://aider.chat/2024/06/02/main-swe-bench.html (2024).

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">Moatless: https://github.com/aorwall/moatless-tools (2024).

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">Ankolekar, Anupriya, et al. ”Supporting online problem-solving communities with the semantic web.” Proceedings of the 15th international conference on World Wide Web. 2006.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">Chakraborty, Saikat, et al. ”Codit: Code editing with tree-based neural models.” IEEE Transactions on Software Engineering 48.4 (2020): 1385-1399.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">Sharafi, Z., Bertram, I., Flanagan, M., &amp; Weimer, W. (2020). Eyes on code: A study on developers’ code navigation strategies. IEEE Transactions on Software Engineering, 48(5), 1692-1704.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">Panchenko, Oleksandr, et al. ”Precise and scalable querying of syntactical source code patterns using sample code snippets and a database.” 2011 IEEE 19th International Conference on Program Comprehension. IEEE, 2011.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Tue Sep 17 13:42:30 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
