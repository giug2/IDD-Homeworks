<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2110.03275] Doing Data Right: How Lessons Learned Working with Conventional Data should Inform the Future of Synthetic Data for Recommender Systems</title><meta property="og:description" content="We present a case that the newly emerging field of synthetic data in the area of recommender systems should prioritize ‘doing data right’.
We consider this catchphrase to have two aspects: First, we should not repeat t…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Doing Data Right: How Lessons Learned Working with Conventional Data should Inform the Future of Synthetic Data for Recommender Systems">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Doing Data Right: How Lessons Learned Working with Conventional Data should Inform the Future of Synthetic Data for Recommender Systems">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2110.03275">

<!--Generated on Tue Mar 19 14:44:21 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content="datasets,  data synthesis,  data bias,  evaluation,  data minimization,  FAIR principles,  responsible AI">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line ltx_leqno">
<h1 class="ltx_title ltx_title_document">Doing Data Right: How Lessons Learned Working with Conventional Data should Inform the Future of Synthetic Data for Recommender Systems</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Manel Slokom
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:m.slokom@tudelft.nl">m.slokom@tudelft.nl</a>
</span>
<span class="ltx_contact ltx_role_affiliation"><span id="id1.1.id1" class="ltx_text ltx_affiliation_institution">Delft University of Technology</span><span id="id2.2.id2" class="ltx_text ltx_affiliation_country">Netherlands</span>
</span></span></span>
<span class="ltx_author_before"> and </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Martha Larson
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:mlarson@science.ru.nl">mlarson@science.ru.nl</a>
</span>
<span class="ltx_contact ltx_role_affiliation"><span id="id3.1.id1" class="ltx_text ltx_affiliation_institution">Radboud University</span><span id="id4.2.id2" class="ltx_text ltx_affiliation_country">Netherlands</span>
</span></span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract.</h6>
<p id="id5.id1" class="ltx_p">We present a case that the newly emerging field of synthetic data in the area of recommender systems should prioritize ‘doing data right’.
We consider this catchphrase to have two aspects: First, we should not repeat the mistakes of the past, and, second, we should explore the full scope of opportunities presented by synthetic data as we move into the future.
We argue that explicit attention to dataset design and description will help to avoid past mistakes with dataset bias and evaluation.
In order to fully exploit the opportunities of synthetic data, we point out that researchers can investigate new areas such as using data synthesize to support reproducibility by making data open, as well as FAIR, and to push forward our understanding of data minimization.</p>
</div>
<div class="ltx_keywords">datasets, data synthesis, data bias, evaluation, data minimization, FAIR principles, responsible AI
</div>
<span id="id1" class="ltx_note ltx_note_frontmatter ltx_role_conference"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">conference: </span>SimuRec Workshop in conjunction with with the 15th ACM Conference on Recommender Systems; 27th September-01 October, 20218; Amsterdam, The Netherlands</span></span></span><span id="id2" class="ltx_note ltx_note_frontmatter ltx_role_copyright"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">copyright: </span>none</span></span></span>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1. </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">The era of big data has seen impressive examples of how knowledge and value can be created using data.
It has also seen sobering reminders of how easy it is to ‘do data wrong’, causing unintended outcomes and often outright harm to the people <cite class="ltx_cite ltx_citemacro_citep">(Joanna Redden and
Terzieva, <a href="#bib.bib18" title="" class="ltx_ref">2020</a>)</cite>.
In this position paper, we point out that we are at the beginning of a new era of synthetic data and that we should take this beginning as an opportunity to ‘do data right’.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p"><em id="S1.p2.1.1" class="ltx_emph ltx_font_italic">Synthetic data</em> is data that is created to serve in the place of original data, which is directly collected or captured.
Synthetic data makes it possible to carry out analyses or develop new algorithms on data that would be otherwise too sensitive to retain, share, or release.
Synthetic data can also be used to augment an existing dataset to improve the performance of algorithms.
Data that is only partially synthesized is referred to as <em id="S1.p2.1.2" class="ltx_emph ltx_font_italic">semi-synthetic data</em>.
The goal of this paper is remind researchers that we must not repeat mistakes that have been made in the past and must also ensure that as our research moves forward, we take advantage of the full scope of the opportunities presented by synthetic data.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.3" class="ltx_p">Our focus is on recommender system data, which takes the form of a user-item matrix <math id="S1.p3.1.m1.1" class="ltx_Math" alttext="\mathcal{R}" display="inline"><semantics id="S1.p3.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S1.p3.1.m1.1.1" xref="S1.p3.1.m1.1.1.cmml">ℛ</mi><annotation-xml encoding="MathML-Content" id="S1.p3.1.m1.1b"><ci id="S1.p3.1.m1.1.1.cmml" xref="S1.p3.1.m1.1.1">ℛ</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.p3.1.m1.1c">\mathcal{R}</annotation></semantics></math> with <math id="S1.p3.2.m2.1" class="ltx_math_unparsed" alttext="U=\{1,..,N\}" display="inline"><semantics id="S1.p3.2.m2.1a"><mrow id="S1.p3.2.m2.1b"><mi id="S1.p3.2.m2.1.1">U</mi><mo id="S1.p3.2.m2.1.2">=</mo><mrow id="S1.p3.2.m2.1.3"><mo stretchy="false" id="S1.p3.2.m2.1.3.1">{</mo><mn id="S1.p3.2.m2.1.3.2">1</mn><mo id="S1.p3.2.m2.1.3.3">,</mo><mo lspace="0em" rspace="0.0835em" id="S1.p3.2.m2.1.3.4">.</mo><mo lspace="0.0835em" rspace="0.167em" id="S1.p3.2.m2.1.3.5">.</mo><mo id="S1.p3.2.m2.1.3.6">,</mo><mi id="S1.p3.2.m2.1.3.7">N</mi><mo stretchy="false" id="S1.p3.2.m2.1.3.8">}</mo></mrow></mrow><annotation encoding="application/x-tex" id="S1.p3.2.m2.1c">U=\{1,..,N\}</annotation></semantics></math> users and <math id="S1.p3.3.m3.1" class="ltx_math_unparsed" alttext="I=\{1,..,M\}" display="inline"><semantics id="S1.p3.3.m3.1a"><mrow id="S1.p3.3.m3.1b"><mi id="S1.p3.3.m3.1.1">I</mi><mo id="S1.p3.3.m3.1.2">=</mo><mrow id="S1.p3.3.m3.1.3"><mo stretchy="false" id="S1.p3.3.m3.1.3.1">{</mo><mn id="S1.p3.3.m3.1.3.2">1</mn><mo id="S1.p3.3.m3.1.3.3">,</mo><mo lspace="0em" rspace="0.0835em" id="S1.p3.3.m3.1.3.4">.</mo><mo lspace="0.0835em" rspace="0.167em" id="S1.p3.3.m3.1.3.5">.</mo><mo id="S1.p3.3.m3.1.3.6">,</mo><mi id="S1.p3.3.m3.1.3.7">M</mi><mo stretchy="false" id="S1.p3.3.m3.1.3.8">}</mo></mrow></mrow><annotation encoding="application/x-tex" id="S1.p3.3.m3.1c">I=\{1,..,M\}</annotation></semantics></math> items.
If a user has interacted with an item, the corresponding matrix cell contains a 1.
Interactions can include clicks, views and purchases, which implicitly express a preference of a user.
Today, recommender system research focuses on such <em id="S1.p3.3.1" class="ltx_emph ltx_font_italic">implicit data</em>, since <em id="S1.p3.3.2" class="ltx_emph ltx_font_italic">explicit data</em>, which consists of ratings explicitly expressing user preferences, is harder to come by.
Recommender system data differs from many datasets of the big data era in that it is highly sparse and characterized by long-tail distributions.
Specifically, we have active users who watch/consume/click many items and non-active users (including cold start users) who attempt to watch/consume/click very few items.
Similarly for items, we have popular items that are consumed by many users and non popular items are consumed by few users.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">The special characteristics of recommender system datasets make them challenging to synthesize, and research has just begun in this direction.
This means that the time is right to avoid the pitfalls already encountered with conventional data.
Further motivation past failure in ‘doing data right’ with regards to user privacy, which is still fresh in the minds of recommender system researchers.
Memorably, in 2010, NetFlix Prize competition was discontinued after it was demonstrated that the data that was released to allow the competitors to develop recommender systems could be deanonymized, revealing the identity of individual users <cite class="ltx_cite ltx_citemacro_citep">(Narayanan and
Shmatikov, <a href="#bib.bib28" title="" class="ltx_ref">2008</a>)</cite>.
Flashing forward, the NetFlix Prize debacle has inspired research on synthetic data.
Via the experience of our own research we see two directions emerging.
First, research on using synthetic or semi-synthetic data to replace captured data in competitions <cite class="ltx_cite ltx_citemacro_citep">(Slokom
et al<span class="ltx_text">.</span>, <a href="#bib.bib33" title="" class="ltx_ref">2019</a>)</cite>.
Second, research on ensuring that synthetic or semi-synthetic data that is derived from data originally collected from users does not leak sensitive information on those users <cite class="ltx_cite ltx_citemacro_citep">(Slokom
et al<span class="ltx_text">.</span>, <a href="#bib.bib32" title="" class="ltx_ref">2021</a>)</cite>.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">The paper is structured as follows.
First, we look at two areas, going beyond privacy, where past research in recommender systems arguably failed in ‘doing data right’ when working with conventional: bias and evaluation.
We discuss how research in synthetic data can grab the chance of not repeating past mistakes.
Then, we discuss two opportunities that are opened by synthetic data, which are not offered by conventional data: open data and data minimization.
We present remarks on how the recommender system community can build on these opportunities.
Our paper closes with a short summary and an outlook.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2. </span>Addressing Past Mistakes</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">The era of big data has been driven by the idea that more data will automatically give rise to more reliable analysis and better systems.
In recent years, however, machine learning researchers have initiated a more systematic approach to data in which the quality, not just quantity, of data is central.
These efforts are well represented by the initiative of <em id="S2.p1.1.1" class="ltx_emph ltx_font_italic">datasheets for datasets</em> <cite class="ltx_cite ltx_citemacro_citep">(Gebru et al<span class="ltx_text">.</span>, <a href="#bib.bib14" title="" class="ltx_ref">2018</a>)</cite>.
In a nutshell, this initiative proposes that every dataset is described by a datasheet with a standardized format that documents: the motivation (why a dataset is created), creation (how the dataset is created), composition (what information it contains), intended uses (what tasks it should (not) be used for), data distribution (what are the properties of the dataset).
In this section, we look at past cases of ‘doing data wrong’ related to data bias and to evaluation.
We comment on how understanding, documenting, as well as explicitly designing, the characteristics of data is currently offering course correction for research practices and also on how work on synthetic data can be steered so that the same problems that we have confronted while working with conventional data do not arise anew.</p>
</div>
<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1. </span>Bias Mitigation</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">In its early days, the recommender systems community did not considered issues of bias and fairness.
Thankfully, recent work has started to illuminate these issues. Here, we provide a brief summary.
Discrimination and unfairness in recommender systems can originate from different sources:
First, <span id="S2.SS1.p1.1.1" class="ltx_text ltx_font_italic">input bias</span> <cite class="ltx_cite ltx_citemacro_citep">(Tsintzou
et al<span class="ltx_text">.</span>, <a href="#bib.bib35" title="" class="ltx_ref">2018</a>; Lin
et al<span class="ltx_text">.</span>, <a href="#bib.bib26" title="" class="ltx_ref">2019</a>)</cite> that users exhibit in the input data.
In <cite class="ltx_cite ltx_citemacro_citep">(Lin
et al<span class="ltx_text">.</span>, <a href="#bib.bib26" title="" class="ltx_ref">2019</a>)</cite>, the authors studied how different collaborative filtering algorithms propagate bias existing in the input data and its impact on users.
In <cite class="ltx_cite ltx_citemacro_citep">(Ekstrand et al<span class="ltx_text">.</span>, <a href="#bib.bib11" title="" class="ltx_ref">2018</a>)</cite>, the authors evaluated the ability of recommender system algorithms to produce equal utility for users of different demographic groups.
A set of results showed a statistically significant differences in effectiveness between users’ gender and age groups.
Second, <span id="S2.SS1.p1.1.2" class="ltx_text ltx_font_italic">algorithmic bias</span> <cite class="ltx_cite ltx_citemacro_citep">(Tsintzou
et al<span class="ltx_text">.</span>, <a href="#bib.bib35" title="" class="ltx_ref">2018</a>; Mansoury et al<span class="ltx_text">.</span>, <a href="#bib.bib27" title="" class="ltx_ref">2019</a>)</cite> examines the effectiveness of recommendation algorithms in capturing different users’ interests across item categories.
For example, popularity bias, where the recommender gives higher accuracy scores to algorithms that favor popular items irrespective of their ability to meet user needs.
In <cite class="ltx_cite ltx_citemacro_citep">(Edizel et al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2019</a>)</cite>, the authors proposed FaiRecSys, an algorithm that mitigates algorithmic bias by post-processing the recommendation matrix with minimum impact on the accuracy of recommendations provided to the end-users.
Third, <span id="S2.SS1.p1.1.3" class="ltx_text ltx_font_italic">evaluation metric error and bias</span> <cite class="ltx_cite ltx_citemacro_citep">(Tian and Ekstrand, <a href="#bib.bib34" title="" class="ltx_ref">2018</a>)</cite> simulates the recommender data generation and evaluation processes to quantify how erroneous current evaluation practices are. In <cite class="ltx_cite ltx_citemacro_citep">(Yao et al<span class="ltx_text">.</span>, <a href="#bib.bib36" title="" class="ltx_ref">2021</a>)</cite>, the authors proposed a simulation framework for measuring the impact of a recommender system under different types of user behavior.
The framework goes beyond one-step recommendation and incorporates the interaction between user preferences and system effects, to better understand recommender system biases over time.</p>
</div>
<div id="S2.SS1.p2" class="ltx_para">
<p id="S2.SS1.p2.1" class="ltx_p">Biased data, biased algorithm and a biased metric will have an impact on all users with different degrees, which leads to discrimination, unfairness and harm.
Data synthesis is an important approach to mitigate bias.
Synthesized data can potentially support recommender systems’ experimentation, tuning, validation and performance prediction.
When synthesizing data, there are some points that we attempt to achieve or test.
For instance, the (semi-)synthesized data can be used to mitigate bias <cite class="ltx_cite ltx_citemacro_citep">(Krishnan et al<span class="ltx_text">.</span>, <a href="#bib.bib21" title="" class="ltx_ref">2014</a>; Huang et al<span class="ltx_text">.</span>, <a href="#bib.bib16" title="" class="ltx_ref">2020</a>)</cite>, improve consumer-provider fairness <cite class="ltx_cite ltx_citemacro_citep">(Li
et al<span class="ltx_text">.</span>, <a href="#bib.bib25" title="" class="ltx_ref">2021</a>; Boratto
et al<span class="ltx_text">.</span>, <a href="#bib.bib7" title="" class="ltx_ref">2020</a>)</cite>, data augmentation <cite class="ltx_cite ltx_citemacro_citep">(Belletti
et al<span class="ltx_text">.</span>, <a href="#bib.bib3" title="" class="ltx_ref">2019</a>)</cite>.</p>
</div>
<div id="S2.SS1.p3" class="ltx_para">
<p id="S2.SS1.p3.1" class="ltx_p">We argue that although data synthesis is helpful to address bias, alone it is not enough.
It is critical that the design decisions that were made when creating a synthesized dataset are well motivated, and made explicit, and also that they are well documented.
In this way, future researchers can understand how bias was handled and assure themselves that new forms of bias were not introduced during the synthesis process.
With explicit design and careful documentation, we can learn, understand, and explain where things have gone wrong and ideally be able to work toward redressing problem i.e., harms and preventing further problems.
The goal of datasheets for datasets is to provide more transparency, accountability and control in the machine learning and recommender system communities.
Moving forward it is crucial that datasheets are also crated for synthetic data.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2. </span>Reliable Evaluation</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">In its early days, the recommender systems community did not fully appreciate the importance of systematic evaluation.
Arguably, it was <cite class="ltx_cite ltx_citemacro_citep">(Said and
Bellogín, <a href="#bib.bib31" title="" class="ltx_ref">2014</a>)</cite> that awakened researchers to the importance of completely controlling the dimensions of an evaluation in order to achieve a fair comparison.
The first dimension mentioned by <cite class="ltx_cite ltx_citemacro_citep">(Said and
Bellogín, <a href="#bib.bib31" title="" class="ltx_ref">2014</a>)</cite> is data.
In recent years, the community has made strides in evaluation practices and reproducibility, see <cite class="ltx_cite ltx_citemacro_citep">(Bellogín and
Said, <a href="#bib.bib4" title="" class="ltx_ref">2021</a>)</cite>, which contains a section documenting the effort.
We point out that a datasheets approach to synthetic data, will ensure that synthetic data will be used appropriately for evaluation from the start and invalid comparisons between datasets will be avoided.
Another dimension mentioned by <cite class="ltx_cite ltx_citemacro_citep">(Said and
Bellogín, <a href="#bib.bib31" title="" class="ltx_ref">2014</a>)</cite> is evaluation strategies. Here, we dive deeper to discuss why careful attention must be paid to evaluation strategies for synthetic or semi-synthetic data.</p>
</div>
<div id="S2.SS2.p2" class="ltx_para">
<p id="S2.SS2.p2.7" class="ltx_p">In the machine learning literature, the quality of synthetic data is often evaluated using machine learning performance.
Such an evaluation involves comparing the performance metrics of predictive models trained on synthetic and on real data (called as model compatibility).
This performance of a machine learning models trained and tested on real and or synthetic data is compared based on different scenarios <cite class="ltx_cite ltx_citemacro_citep">(Heyburn et al<span class="ltx_text">.</span>, <a href="#bib.bib15" title="" class="ltx_ref">2018</a>; Jordon
et al<span class="ltx_text">.</span>, <a href="#bib.bib19" title="" class="ltx_ref">2018a</a>; Fekri
et al<span class="ltx_text">.</span>, <a href="#bib.bib13" title="" class="ltx_ref">2020</a>)</cite>:
Train on Real and Test on Synthetic data (<math id="S2.SS2.p2.1.m1.1" class="ltx_Math" alttext="\mathcal{TRTS}" display="inline"><semantics id="S2.SS2.p2.1.m1.1a"><mrow id="S2.SS2.p2.1.m1.1.1" xref="S2.SS2.p2.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS2.p2.1.m1.1.1.2" xref="S2.SS2.p2.1.m1.1.1.2.cmml">𝒯</mi><mo lspace="0em" rspace="0em" id="S2.SS2.p2.1.m1.1.1.1" xref="S2.SS2.p2.1.m1.1.1.1.cmml">​</mo><mi class="ltx_font_mathcaligraphic" id="S2.SS2.p2.1.m1.1.1.3" xref="S2.SS2.p2.1.m1.1.1.3.cmml">ℛ</mi><mo lspace="0em" rspace="0em" id="S2.SS2.p2.1.m1.1.1.1a" xref="S2.SS2.p2.1.m1.1.1.1.cmml">​</mo><mi class="ltx_font_mathcaligraphic" id="S2.SS2.p2.1.m1.1.1.4" xref="S2.SS2.p2.1.m1.1.1.4.cmml">𝒯</mi><mo lspace="0em" rspace="0em" id="S2.SS2.p2.1.m1.1.1.1b" xref="S2.SS2.p2.1.m1.1.1.1.cmml">​</mo><mi class="ltx_font_mathcaligraphic" id="S2.SS2.p2.1.m1.1.1.5" xref="S2.SS2.p2.1.m1.1.1.5.cmml">𝒮</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p2.1.m1.1b"><apply id="S2.SS2.p2.1.m1.1.1.cmml" xref="S2.SS2.p2.1.m1.1.1"><times id="S2.SS2.p2.1.m1.1.1.1.cmml" xref="S2.SS2.p2.1.m1.1.1.1"></times><ci id="S2.SS2.p2.1.m1.1.1.2.cmml" xref="S2.SS2.p2.1.m1.1.1.2">𝒯</ci><ci id="S2.SS2.p2.1.m1.1.1.3.cmml" xref="S2.SS2.p2.1.m1.1.1.3">ℛ</ci><ci id="S2.SS2.p2.1.m1.1.1.4.cmml" xref="S2.SS2.p2.1.m1.1.1.4">𝒯</ci><ci id="S2.SS2.p2.1.m1.1.1.5.cmml" xref="S2.SS2.p2.1.m1.1.1.5">𝒮</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p2.1.m1.1c">\mathcal{TRTS}</annotation></semantics></math>)
Train on Synthetic and Test on Real (<math id="S2.SS2.p2.2.m2.1" class="ltx_Math" alttext="\mathcal{TSTR}" display="inline"><semantics id="S2.SS2.p2.2.m2.1a"><mrow id="S2.SS2.p2.2.m2.1.1" xref="S2.SS2.p2.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS2.p2.2.m2.1.1.2" xref="S2.SS2.p2.2.m2.1.1.2.cmml">𝒯</mi><mo lspace="0em" rspace="0em" id="S2.SS2.p2.2.m2.1.1.1" xref="S2.SS2.p2.2.m2.1.1.1.cmml">​</mo><mi class="ltx_font_mathcaligraphic" id="S2.SS2.p2.2.m2.1.1.3" xref="S2.SS2.p2.2.m2.1.1.3.cmml">𝒮</mi><mo lspace="0em" rspace="0em" id="S2.SS2.p2.2.m2.1.1.1a" xref="S2.SS2.p2.2.m2.1.1.1.cmml">​</mo><mi class="ltx_font_mathcaligraphic" id="S2.SS2.p2.2.m2.1.1.4" xref="S2.SS2.p2.2.m2.1.1.4.cmml">𝒯</mi><mo lspace="0em" rspace="0em" id="S2.SS2.p2.2.m2.1.1.1b" xref="S2.SS2.p2.2.m2.1.1.1.cmml">​</mo><mi class="ltx_font_mathcaligraphic" id="S2.SS2.p2.2.m2.1.1.5" xref="S2.SS2.p2.2.m2.1.1.5.cmml">ℛ</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p2.2.m2.1b"><apply id="S2.SS2.p2.2.m2.1.1.cmml" xref="S2.SS2.p2.2.m2.1.1"><times id="S2.SS2.p2.2.m2.1.1.1.cmml" xref="S2.SS2.p2.2.m2.1.1.1"></times><ci id="S2.SS2.p2.2.m2.1.1.2.cmml" xref="S2.SS2.p2.2.m2.1.1.2">𝒯</ci><ci id="S2.SS2.p2.2.m2.1.1.3.cmml" xref="S2.SS2.p2.2.m2.1.1.3">𝒮</ci><ci id="S2.SS2.p2.2.m2.1.1.4.cmml" xref="S2.SS2.p2.2.m2.1.1.4">𝒯</ci><ci id="S2.SS2.p2.2.m2.1.1.5.cmml" xref="S2.SS2.p2.2.m2.1.1.5">ℛ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p2.2.m2.1c">\mathcal{TSTR}</annotation></semantics></math>), Train on Real, Test on Real (<math id="S2.SS2.p2.3.m3.1" class="ltx_Math" alttext="\mathcal{TRTR}" display="inline"><semantics id="S2.SS2.p2.3.m3.1a"><mrow id="S2.SS2.p2.3.m3.1.1" xref="S2.SS2.p2.3.m3.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS2.p2.3.m3.1.1.2" xref="S2.SS2.p2.3.m3.1.1.2.cmml">𝒯</mi><mo lspace="0em" rspace="0em" id="S2.SS2.p2.3.m3.1.1.1" xref="S2.SS2.p2.3.m3.1.1.1.cmml">​</mo><mi class="ltx_font_mathcaligraphic" id="S2.SS2.p2.3.m3.1.1.3" xref="S2.SS2.p2.3.m3.1.1.3.cmml">ℛ</mi><mo lspace="0em" rspace="0em" id="S2.SS2.p2.3.m3.1.1.1a" xref="S2.SS2.p2.3.m3.1.1.1.cmml">​</mo><mi class="ltx_font_mathcaligraphic" id="S2.SS2.p2.3.m3.1.1.4" xref="S2.SS2.p2.3.m3.1.1.4.cmml">𝒯</mi><mo lspace="0em" rspace="0em" id="S2.SS2.p2.3.m3.1.1.1b" xref="S2.SS2.p2.3.m3.1.1.1.cmml">​</mo><mi class="ltx_font_mathcaligraphic" id="S2.SS2.p2.3.m3.1.1.5" xref="S2.SS2.p2.3.m3.1.1.5.cmml">ℛ</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p2.3.m3.1b"><apply id="S2.SS2.p2.3.m3.1.1.cmml" xref="S2.SS2.p2.3.m3.1.1"><times id="S2.SS2.p2.3.m3.1.1.1.cmml" xref="S2.SS2.p2.3.m3.1.1.1"></times><ci id="S2.SS2.p2.3.m3.1.1.2.cmml" xref="S2.SS2.p2.3.m3.1.1.2">𝒯</ci><ci id="S2.SS2.p2.3.m3.1.1.3.cmml" xref="S2.SS2.p2.3.m3.1.1.3">ℛ</ci><ci id="S2.SS2.p2.3.m3.1.1.4.cmml" xref="S2.SS2.p2.3.m3.1.1.4">𝒯</ci><ci id="S2.SS2.p2.3.m3.1.1.5.cmml" xref="S2.SS2.p2.3.m3.1.1.5">ℛ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p2.3.m3.1c">\mathcal{TRTR}</annotation></semantics></math>) and Train on Synthetic, Test on Synthetic (<math id="S2.SS2.p2.4.m4.1" class="ltx_Math" alttext="\mathcal{TSTS}" display="inline"><semantics id="S2.SS2.p2.4.m4.1a"><mrow id="S2.SS2.p2.4.m4.1.1" xref="S2.SS2.p2.4.m4.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS2.p2.4.m4.1.1.2" xref="S2.SS2.p2.4.m4.1.1.2.cmml">𝒯</mi><mo lspace="0em" rspace="0em" id="S2.SS2.p2.4.m4.1.1.1" xref="S2.SS2.p2.4.m4.1.1.1.cmml">​</mo><mi class="ltx_font_mathcaligraphic" id="S2.SS2.p2.4.m4.1.1.3" xref="S2.SS2.p2.4.m4.1.1.3.cmml">𝒮</mi><mo lspace="0em" rspace="0em" id="S2.SS2.p2.4.m4.1.1.1a" xref="S2.SS2.p2.4.m4.1.1.1.cmml">​</mo><mi class="ltx_font_mathcaligraphic" id="S2.SS2.p2.4.m4.1.1.4" xref="S2.SS2.p2.4.m4.1.1.4.cmml">𝒯</mi><mo lspace="0em" rspace="0em" id="S2.SS2.p2.4.m4.1.1.1b" xref="S2.SS2.p2.4.m4.1.1.1.cmml">​</mo><mi class="ltx_font_mathcaligraphic" id="S2.SS2.p2.4.m4.1.1.5" xref="S2.SS2.p2.4.m4.1.1.5.cmml">𝒮</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p2.4.m4.1b"><apply id="S2.SS2.p2.4.m4.1.1.cmml" xref="S2.SS2.p2.4.m4.1.1"><times id="S2.SS2.p2.4.m4.1.1.1.cmml" xref="S2.SS2.p2.4.m4.1.1.1"></times><ci id="S2.SS2.p2.4.m4.1.1.2.cmml" xref="S2.SS2.p2.4.m4.1.1.2">𝒯</ci><ci id="S2.SS2.p2.4.m4.1.1.3.cmml" xref="S2.SS2.p2.4.m4.1.1.3">𝒮</ci><ci id="S2.SS2.p2.4.m4.1.1.4.cmml" xref="S2.SS2.p2.4.m4.1.1.4">𝒯</ci><ci id="S2.SS2.p2.4.m4.1.1.5.cmml" xref="S2.SS2.p2.4.m4.1.1.5">𝒮</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p2.4.m4.1c">\mathcal{TSTS}</annotation></semantics></math>), and lastly trained and tested on a mixture of real and synthetic data (<math id="S2.SS2.p2.5.m5.1" class="ltx_Math" alttext="\mathcal{TMTM}" display="inline"><semantics id="S2.SS2.p2.5.m5.1a"><mrow id="S2.SS2.p2.5.m5.1.1" xref="S2.SS2.p2.5.m5.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS2.p2.5.m5.1.1.2" xref="S2.SS2.p2.5.m5.1.1.2.cmml">𝒯</mi><mo lspace="0em" rspace="0em" id="S2.SS2.p2.5.m5.1.1.1" xref="S2.SS2.p2.5.m5.1.1.1.cmml">​</mo><mi class="ltx_font_mathcaligraphic" id="S2.SS2.p2.5.m5.1.1.3" xref="S2.SS2.p2.5.m5.1.1.3.cmml">ℳ</mi><mo lspace="0em" rspace="0em" id="S2.SS2.p2.5.m5.1.1.1a" xref="S2.SS2.p2.5.m5.1.1.1.cmml">​</mo><mi class="ltx_font_mathcaligraphic" id="S2.SS2.p2.5.m5.1.1.4" xref="S2.SS2.p2.5.m5.1.1.4.cmml">𝒯</mi><mo lspace="0em" rspace="0em" id="S2.SS2.p2.5.m5.1.1.1b" xref="S2.SS2.p2.5.m5.1.1.1.cmml">​</mo><mi class="ltx_font_mathcaligraphic" id="S2.SS2.p2.5.m5.1.1.5" xref="S2.SS2.p2.5.m5.1.1.5.cmml">ℳ</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p2.5.m5.1b"><apply id="S2.SS2.p2.5.m5.1.1.cmml" xref="S2.SS2.p2.5.m5.1.1"><times id="S2.SS2.p2.5.m5.1.1.1.cmml" xref="S2.SS2.p2.5.m5.1.1.1"></times><ci id="S2.SS2.p2.5.m5.1.1.2.cmml" xref="S2.SS2.p2.5.m5.1.1.2">𝒯</ci><ci id="S2.SS2.p2.5.m5.1.1.3.cmml" xref="S2.SS2.p2.5.m5.1.1.3">ℳ</ci><ci id="S2.SS2.p2.5.m5.1.1.4.cmml" xref="S2.SS2.p2.5.m5.1.1.4">𝒯</ci><ci id="S2.SS2.p2.5.m5.1.1.5.cmml" xref="S2.SS2.p2.5.m5.1.1.5">ℳ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p2.5.m5.1c">\mathcal{TMTM}</annotation></semantics></math>).
In principle, these scenarios are transferable to the evaluation of synthetic data in recommender systems.
However, it is important to consider whether <math id="S2.SS2.p2.6.m6.1" class="ltx_Math" alttext="\mathcal{TRTS}" display="inline"><semantics id="S2.SS2.p2.6.m6.1a"><mrow id="S2.SS2.p2.6.m6.1.1" xref="S2.SS2.p2.6.m6.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS2.p2.6.m6.1.1.2" xref="S2.SS2.p2.6.m6.1.1.2.cmml">𝒯</mi><mo lspace="0em" rspace="0em" id="S2.SS2.p2.6.m6.1.1.1" xref="S2.SS2.p2.6.m6.1.1.1.cmml">​</mo><mi class="ltx_font_mathcaligraphic" id="S2.SS2.p2.6.m6.1.1.3" xref="S2.SS2.p2.6.m6.1.1.3.cmml">ℛ</mi><mo lspace="0em" rspace="0em" id="S2.SS2.p2.6.m6.1.1.1a" xref="S2.SS2.p2.6.m6.1.1.1.cmml">​</mo><mi class="ltx_font_mathcaligraphic" id="S2.SS2.p2.6.m6.1.1.4" xref="S2.SS2.p2.6.m6.1.1.4.cmml">𝒯</mi><mo lspace="0em" rspace="0em" id="S2.SS2.p2.6.m6.1.1.1b" xref="S2.SS2.p2.6.m6.1.1.1.cmml">​</mo><mi class="ltx_font_mathcaligraphic" id="S2.SS2.p2.6.m6.1.1.5" xref="S2.SS2.p2.6.m6.1.1.5.cmml">𝒮</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p2.6.m6.1b"><apply id="S2.SS2.p2.6.m6.1.1.cmml" xref="S2.SS2.p2.6.m6.1.1"><times id="S2.SS2.p2.6.m6.1.1.1.cmml" xref="S2.SS2.p2.6.m6.1.1.1"></times><ci id="S2.SS2.p2.6.m6.1.1.2.cmml" xref="S2.SS2.p2.6.m6.1.1.2">𝒯</ci><ci id="S2.SS2.p2.6.m6.1.1.3.cmml" xref="S2.SS2.p2.6.m6.1.1.3">ℛ</ci><ci id="S2.SS2.p2.6.m6.1.1.4.cmml" xref="S2.SS2.p2.6.m6.1.1.4">𝒯</ci><ci id="S2.SS2.p2.6.m6.1.1.5.cmml" xref="S2.SS2.p2.6.m6.1.1.5">𝒮</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p2.6.m6.1c">\mathcal{TRTS}</annotation></semantics></math> and
<math id="S2.SS2.p2.7.m7.1" class="ltx_Math" alttext="\mathcal{TSTR}" display="inline"><semantics id="S2.SS2.p2.7.m7.1a"><mrow id="S2.SS2.p2.7.m7.1.1" xref="S2.SS2.p2.7.m7.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS2.p2.7.m7.1.1.2" xref="S2.SS2.p2.7.m7.1.1.2.cmml">𝒯</mi><mo lspace="0em" rspace="0em" id="S2.SS2.p2.7.m7.1.1.1" xref="S2.SS2.p2.7.m7.1.1.1.cmml">​</mo><mi class="ltx_font_mathcaligraphic" id="S2.SS2.p2.7.m7.1.1.3" xref="S2.SS2.p2.7.m7.1.1.3.cmml">𝒮</mi><mo lspace="0em" rspace="0em" id="S2.SS2.p2.7.m7.1.1.1a" xref="S2.SS2.p2.7.m7.1.1.1.cmml">​</mo><mi class="ltx_font_mathcaligraphic" id="S2.SS2.p2.7.m7.1.1.4" xref="S2.SS2.p2.7.m7.1.1.4.cmml">𝒯</mi><mo lspace="0em" rspace="0em" id="S2.SS2.p2.7.m7.1.1.1b" xref="S2.SS2.p2.7.m7.1.1.1.cmml">​</mo><mi class="ltx_font_mathcaligraphic" id="S2.SS2.p2.7.m7.1.1.5" xref="S2.SS2.p2.7.m7.1.1.5.cmml">ℛ</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p2.7.m7.1b"><apply id="S2.SS2.p2.7.m7.1.1.cmml" xref="S2.SS2.p2.7.m7.1.1"><times id="S2.SS2.p2.7.m7.1.1.1.cmml" xref="S2.SS2.p2.7.m7.1.1.1"></times><ci id="S2.SS2.p2.7.m7.1.1.2.cmml" xref="S2.SS2.p2.7.m7.1.1.2">𝒯</ci><ci id="S2.SS2.p2.7.m7.1.1.3.cmml" xref="S2.SS2.p2.7.m7.1.1.3">𝒮</ci><ci id="S2.SS2.p2.7.m7.1.1.4.cmml" xref="S2.SS2.p2.7.m7.1.1.4">𝒯</ci><ci id="S2.SS2.p2.7.m7.1.1.5.cmml" xref="S2.SS2.p2.7.m7.1.1.5">ℛ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p2.7.m7.1c">\mathcal{TSTR}</annotation></semantics></math>
actually yield meaningful information about how useful synthetic data is for recommendation.
The reason is that, if the synthetic data provides synthetic users, then users in the training set (or test set) are different from those in the test set (respectively training set).</p>
</div>
<div id="S2.SS2.p3" class="ltx_para">
<p id="S2.SS2.p3.1" class="ltx_p">It is critical to develop evaluation frameworks that are suitable for use in evaluating synthetic data in the context of recommender systems.
In other words, evaluation itself must be an object of research.
Here, we cite two directions that could serve as a starting point.
First, relative ranking of a set of algorithms, rather than absolute scores could serve as an important tool.
The relative performance of a set of algorithms trained and tested on the synthetic dataset should be the same as their relative performance when trained and tested on the original dataset <cite class="ltx_cite ltx_citemacro_citep">(Jordon
et al<span class="ltx_text">.</span>, <a href="#bib.bib19" title="" class="ltx_ref">2018a</a>, <a href="#bib.bib20" title="" class="ltx_ref">b</a>; Bowen and Snoke, <a href="#bib.bib8" title="" class="ltx_ref">2019</a>; Slokom
et al<span class="ltx_text">.</span>, <a href="#bib.bib33" title="" class="ltx_ref">2019</a>)</cite>.
For example, if (semi-)synthetic data is released for use in a data science challenge, this relative ranking would be more important that the absolute scores achieved by the algorithms.
This direction of research is not yet well explored by researchers in recommender system community.
Second, special attention must be paid to ensure that the test set remains comparable when different types of (semi-)synthetic data are compared.
We have proposed on way to address this issue for semi-synthetic data <cite class="ltx_cite ltx_citemacro_citep">(Slokom
et al<span class="ltx_text">.</span>, <a href="#bib.bib32" title="" class="ltx_ref">2021</a>)</cite>.</p>
</div>
<div id="S2.SS2.p4" class="ltx_para">
<p id="S2.SS2.p4.1" class="ltx_p">We close this section on evaluation by mentioning the importance of studying data characteristics.
There is an interaction between the exact nature of the data, and the types or recommender system algorithms that perform well on that data.
These aspects have traditionally been understudied by the community, also the situation is hopefully changing in the wake of <cite class="ltx_cite ltx_citemacro_citep">(Adomavicius and
Zhang, <a href="#bib.bib2" title="" class="ltx_ref">2012</a>; Deldjoo
et al<span class="ltx_text">.</span>, <a href="#bib.bib9" title="" class="ltx_ref">2021</a>)</cite>.
Because it is straightforward to control the properties of synthetic data, the study of synthetic data opens a whole new world of possibilities for use to understand which algorithms works well with which type of data, and why.
Again, we see that the proper documentation of synthetic data in datasheets is critical for such research to be reproducible and thereby useful.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3. </span>Paving the Way for Future Research</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">Synthetic data is generally intended to take the place of original data.
However, in order to take advantage of the full potential of synthetic data, which must also invest research effort in developing the potential of synthetic data to transcend conventional data, and be used for purposes for which conventional data is not suited.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1. </span>FAIR and Beyond</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">FAIR is the combination of different small practices that make the data easier to <span id="S3.SS1.p1.1.1" class="ltx_text ltx_font_italic">find</span>, easier to <span id="S3.SS1.p1.1.2" class="ltx_text ltx_font_italic">understand</span>, less likely to be <span id="S3.SS1.p1.1.3" class="ltx_text ltx_font_italic">lost</span>, and more likely to be <span id="S3.SS1.p1.1.4" class="ltx_text ltx_font_italic">usable</span> during the project time and years later <cite class="ltx_cite ltx_citemacro_citep">(Inau
et al<span class="ltx_text">.</span>, <a href="#bib.bib17" title="" class="ltx_ref">2021</a>)</cite>.
FAIR principles <cite class="ltx_cite ltx_citemacro_citep">(Fair, <a href="#bib.bib12" title="" class="ltx_ref">[n.d.]</a>)</cite> are guidelines for data management and stewardship that are valid for both machines and humans:
<span id="S3.SS1.p1.1.5" class="ltx_text ltx_font_italic">Findable</span>: (meta)data should be discoverable, identifiable and searchable via the assignment of metadata and unique identifiers.
<span id="S3.SS1.p1.1.6" class="ltx_text ltx_font_italic">Accessible</span>: (meta)data should be available and retrievable with access via authentication and authorisation procedures.
<span id="S3.SS1.p1.1.7" class="ltx_text ltx_font_italic">Interoperable</span>: (meta)data should be semantically understandable, allowing the broadest possible data exchange i.e., exchange and reuse between researchers, institutions, organisations or countries.
<span id="S3.SS1.p1.1.8" class="ltx_text ltx_font_italic">Reusable</span>: (meta)data should be sufficiently described, well documented, and shared with the least restrictive licenses, allowing the widest reuse possible.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.1" class="ltx_p">The FAIR principles can drive forward progress in recommender system research because they can support reproducibility.
However, the FAIR principles do not dictate that the data has to be shared openly <cite class="ltx_cite ltx_citemacro_citep">(OpenAIRE, <a href="#bib.bib29" title="" class="ltx_ref">2018</a>)</cite>,
which is a hindrance to reproducibility.
For instance, <span id="S3.SS1.p2.1.1" class="ltx_text ltx_font_italic">the data can be FAIR but not open</span>: it is FAIR within the company but it does not open to researchers, scientists and users outside the company.
Data synthesis offers a possibility to make data
FAIRly open without the need to release the original data.
The (semi-)synthetic data could be designed to protect user’s sensitive information while still maintaining its value for training recommender systems, which is needed for reproducibility.
We have suggested one approach in <cite class="ltx_cite ltx_citemacro_citep">(Slokom
et al<span class="ltx_text">.</span>, <a href="#bib.bib32" title="" class="ltx_ref">2021</a>)</cite>, but this work represents only a beginning.
The (semi-)synthetic data could also be designed to protect information that is important for companies’ competitiveness while at the same time preserving the information that is necessary for the data to contain in order for third-parties to be able to have oversight over how companies collect and use the data of users.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2. </span>Data Minimization</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">Finally, we discuss the issue of data minimization.
Article 5(1)(c) of the European Union’s General Data Protection Regulation (GDPR) requires that personal data should be limited to only what is necessary to the purposes for which the data is processed <cite class="ltx_cite ltx_citemacro_citep">(Regulation, <a href="#bib.bib30" title="" class="ltx_ref">2018</a>)</cite>.
Linking back to the discussion of FAIR, we note that in <cite class="ltx_cite ltx_citemacro_citep">(Inau
et al<span class="ltx_text">.</span>, <a href="#bib.bib17" title="" class="ltx_ref">2021</a>; Boeckhout
et al<span class="ltx_text">.</span>, <a href="#bib.bib6" title="" class="ltx_ref">2018</a>)</cite>, authors suggested that FAIR data and metadata can facilitate compliance with data minimization principle since FAIR principles allow for an assessment of which data to reuse.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.1" class="ltx_p">Here, we zero in specifically on data minimization for recommender systems.
In <cite class="ltx_cite ltx_citemacro_citep">(Larson
et al<span class="ltx_text">.</span>, <a href="#bib.bib24" title="" class="ltx_ref">2017</a>)</cite>, the authors proposed to adopt training data requirements analysis to analyze and evaluate the trade-off between the amount of data that the system requires, and the performance of the system.
In <cite class="ltx_cite ltx_citemacro_citep">(Krishnaraj, <a href="#bib.bib22" title="" class="ltx_ref">2019</a>)</cite>, the authors proposed to extend the data minimzation principles advocated in GDPR and studied their effect on recommender systems.
They investigated the effects of reducing the amount of data used to model a recommender system and showed that a substantial amount of data can be dropped without a large impact on the performance.
In <cite class="ltx_cite ltx_citemacro_citep">(Biega et al<span class="ltx_text">.</span>, <a href="#bib.bib5" title="" class="ltx_ref">2020</a>)</cite>, authors pointed to the lack of an homogeneous interpretation of the data minimization principle.
They argued that personalization-based systems do not necessarily need to collect user data, but that they do so to improve the quality of the results.
They found that the performance decrease incurred by data minimization might not be substantial but that it might disparately impact different users.
To support minimization, <cite class="ltx_cite ltx_citemacro_citep">(Biega et al<span class="ltx_text">.</span>, <a href="#bib.bib5" title="" class="ltx_ref">2020</a>)</cite> suggested that we need to design new protocols for user-system interaction, a system that does not only focus on providing infinite recommendations while collecting infinite data about its users’.
In other words, we need to propose new learning mechanisms that select necessary data that respect specific minimization requirements while maintaining a good personalized-based recommendation performance.</p>
</div>
<div id="S3.SS2.p3" class="ltx_para">
<p id="S3.SS2.p3.1" class="ltx_p">Synthetic data presents a promising opportunity to understand what data minimizing means for recommender systems.
Minimized datasets can be synthesized with different characteristics and the impact of these characteristics could be studied.
We believe that cold start user profiles could be a good starting point to understand and find the minimal necessary data in a user profile.
Then, recommender system research need to look at how much data is really necessary to accomplish a given recommender system task.
We expect the study of data minimization to move forward the state of the art in recommender systems, but also to make it possible to gain understanding of how the GDPR must be enforced for recommender system data.</p>
</div>
<div id="S3.SS2.p4" class="ltx_para">
<p id="S3.SS2.p4.1" class="ltx_p">Using synthetic data to study data minimization is potentially relevant to oversight beyond the GDPR as well.
Currently, there is growing concern about the manipulative impact of hypertargeting, which infringes on privacy and consumer rights.
Previously, we have proposed the concept of hypotargeting <cite class="ltx_cite ltx_citemacro_citep">(Larson and Slokom, <a href="#bib.bib23" title="" class="ltx_ref">2019</a>)</cite>, i.e., imposing a constraint on the number of unique recommendation lists that a recommender system can present to its users in a given time window.
Because the number of unique lists remains finite, it becomes feasible to audit the experience that a recommender system is offering to its users.
Such oversight can watch for bias, filter bubbles, and unfair targeting.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4. </span>Summary and Outlook</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">In this position paper, we have described mistakes that have occurred over the history of recommender system research, specifically, neglecting the issue of bias and overlooking the importance of evaluation framework.
We have argued that we must ensure that these mistakes are not repeated as we develop approaches to craete synethetic data for evaluation.
We have also pointed to areas where synthetic data has a special contribution to make in the future, specifically, extending FAIR principles to make data open and also moving forward our understanding of data minimization for recommender systems and how to minimize data appropriately and effectively.</p>
</div>
<div id="S4.p2" class="ltx_para">
<p id="S4.p2.1" class="ltx_p">Throughout we have emphasized the importance of explicitly designing and documenting synthetic datasets, following the idea of datasheets for datasets <cite class="ltx_cite ltx_citemacro_citep">(Gebru et al<span class="ltx_text">.</span>, <a href="#bib.bib14" title="" class="ltx_ref">2018</a>)</cite>.
Future research will need to embrace the development of best practices for design, documentation, and evaluation of synthetic data as research areas in their own right.</p>
</div>
<div id="S4.p3" class="ltx_para">
<p id="S4.p3.1" class="ltx_p">Recommender system research must also create bridges across disciplines.
As pointed out by <cite class="ltx_cite ltx_citemacro_citep">(Gebru et al<span class="ltx_text">.</span>, <a href="#bib.bib14" title="" class="ltx_ref">2018</a>)</cite>, the risk datasets causing harm can be exacerbated when developers are not domain experts.
Moving forward it is essential to include experts from specific domains, such as health, psychology, and communication science, in synthetic data research.
Further, interdisciplinary collaboration is also necessary with legal experts to understand how synthetic data can best protect privacy, and support data minimization and regulatory oversight.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(1)</span>
<span class="ltx_bibblock">        




</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Adomavicius and
Zhang (2012)</span>
<span class="ltx_bibblock">
Gediminas Adomavicius and
Jingjing Zhang. 2012.

</span>
<span class="ltx_bibblock">Impact of Data Characteristics on Recommender
Systems Performance.

</span>
<span class="ltx_bibblock"><em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">ACM Transaction on Management Information
Systems</em> 3, 1, Article
3 (April 2012),
17 pages.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Belletti
et al<span id="bib.bib3.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Francois Belletti, Karthik
Lakshmanan, Walid Krichene, Nicolas
Mayoraz, Yi-Fan Chen, John Anderson,
Taylor Robie, Tayo Oguntebi,
Dan Shirron, and Amit Bleiwess.
2019.

</span>
<span class="ltx_bibblock">Scaling Up Collaborative Filtering Data Sets
through Randomized Fractal Expansions.

</span>
<span class="ltx_bibblock"><em id="bib.bib3.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1905.09874</em>
(2019).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bellogín and
Said (2021)</span>
<span class="ltx_bibblock">
Alejandro Bellogín and
Alan Said. 2021.

</span>
<span class="ltx_bibblock">Improving Accountability in Recommender Systems
Research Through Reproducibility.

</span>
<span class="ltx_bibblock"><em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2102.00482</em>
(2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Biega et al<span id="bib.bib5.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Asia J Biega, Peter
Potash, Hal Daumé, Fernando Diaz,
and Michèle Finck. 2020.

</span>
<span class="ltx_bibblock">Operationalizing the legal principle of data
minimization for personalization. In <em id="bib.bib5.3.1" class="ltx_emph ltx_font_italic">Proceedings
of the 43rd International ACM SIGIR Conference on Research and Development in
Information Retrieval</em>. 399–408.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Boeckhout
et al<span id="bib.bib6.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Martin Boeckhout,
Gerhard A Zielhuis, and Annelien L
Bredenoord. 2018.

</span>
<span class="ltx_bibblock">The FAIR guiding principles for data stewardship:
fair enough?

</span>
<span class="ltx_bibblock"><em id="bib.bib6.3.1" class="ltx_emph ltx_font_italic">European journal of human genetics</em>
26, 7 (2018),
931–936.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Boratto
et al<span id="bib.bib7.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Ludovico Boratto, Gianni
Fenu, and Mirko Marras.
2020.

</span>
<span class="ltx_bibblock">Interplay between Upsampling and Regularization for
Provider Fairness in Recommender Systems.

</span>
<span class="ltx_bibblock"><em id="bib.bib7.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2006.04279</em>
(2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bowen and Snoke (2019)</span>
<span class="ltx_bibblock">
Claire McKay Bowen and
Joshua Snoke. 2019.

</span>
<span class="ltx_bibblock">Comparative study of differentially private
synthetic data algorithms from the NIST PSCR differential privacy synthetic
data challenge.

</span>
<span class="ltx_bibblock"><em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1911.12704</em>
(2019).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Deldjoo
et al<span id="bib.bib9.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Yashar Deldjoo, Alejandro
Bellogin, and Tommaso Di Noia.
2021.

</span>
<span class="ltx_bibblock">Explaining recommender systems fairness and
accuracy through the lens of data characteristics.

</span>
<span class="ltx_bibblock"><em id="bib.bib9.3.1" class="ltx_emph ltx_font_italic">Information Processing &amp; Management</em>
58, 5 (2021),
102662.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Edizel et al<span id="bib.bib10.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Bora Edizel, Francesco
Bonchi, Sara Hajian, André Panisson,
and Tamir Tassa. 2019.

</span>
<span class="ltx_bibblock">FaiRecSys: mitigating algorithmic bias in
recommender systems.

</span>
<span class="ltx_bibblock"><em id="bib.bib10.3.1" class="ltx_emph ltx_font_italic">International Journal of Data Science and
Analytics</em> (2019), 1–17.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ekstrand et al<span id="bib.bib11.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Michael D. Ekstrand, Mucun
Tian, Ion Madrazo Azpiazu, Jennifer D.
Ekstrand, Oghenemaro Anuyah, David
McNeill, and Maria Soledad Pera.
2018.

</span>
<span class="ltx_bibblock">All The Cool Kids, How Do They Fit In?: Popularity
and Demographic Biases in Recommender Evaluation and Effectiveness. In
<em id="bib.bib11.3.1" class="ltx_emph ltx_font_italic">Proceeding FAT*</em>
<em id="bib.bib11.4.2" class="ltx_emph ltx_font_italic">(Proceedings of Machine Learning Research,
Vol. 81)</em>. PMLR,
172–186.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fair ([n.d.])</span>
<span class="ltx_bibblock">
Go Fair.
[n.d.].

</span>
<span class="ltx_bibblock"><em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">FAIR Principles</em>.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock"><a target="_blank" href="https://www.go-fair.org/fair-principles/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.go-fair.org/fair-principles/</a>, Online; accessed
22-August-2021.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fekri
et al<span id="bib.bib13.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Mohammad Navid Fekri,
Ananda Mohon Ghosh, and Katarina
Grolinger. 2020.

</span>
<span class="ltx_bibblock">Generating energy data for machine learning with
recurrent generative adversarial networks.

</span>
<span class="ltx_bibblock"><em id="bib.bib13.3.1" class="ltx_emph ltx_font_italic">Energies</em> 13,
1 (2020), 130.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gebru et al<span id="bib.bib14.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Timnit Gebru, Jamie
Morgenstern, Briana Vecchione,
Jennifer Wortman Vaughan, Hanna Wallach,
Hal Daumé III, and Kate Crawford.
2018.

</span>
<span class="ltx_bibblock">Datasheets for datasets.

</span>
<span class="ltx_bibblock"><em id="bib.bib14.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1803.09010</em>
(2018).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Heyburn et al<span id="bib.bib15.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Rachel Heyburn, Raymond R
Bond, Michaela Black, Maurice Mulvenna,
Jonathan Wallace, Deborah Rankin, and
Brian Cleland. 2018.

</span>
<span class="ltx_bibblock">Machine learning using synthetic and real data:
similarity of evaluation metrics for different healthcare datasets and for
different algorithms. In <em id="bib.bib15.3.1" class="ltx_emph ltx_font_italic">Data Science and
Knowledge Engineering for Sensing Decision Support: Proceedings of the 13th
International FLINS Conference (FLINS 2018)</em>. World Scientific,
1281–1291.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang et al<span id="bib.bib16.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Jin Huang, Harrie
Oosterhuis, Maarten de Rijke, and Herke
van Hoof. 2020.

</span>
<span class="ltx_bibblock">Keeping dataset biases out of the simulation: A
debiased simulator for reinforcement learning based recommender systems. In
<em id="bib.bib16.3.1" class="ltx_emph ltx_font_italic">Fourteenth ACM Conference on Recommender Systems</em>.
190–199.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Inau
et al<span id="bib.bib17.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Esther Thea Inau, Jean
Sack, Dagmar Waltemath, and
Atinkut Alamirrew Zeleke. 2021.

</span>
<span class="ltx_bibblock">Initiatives, Concepts, and Implementation Practices
of FAIR (Findable, Accessible, Interoperable, and Reusable) Data Principles
in Health Data Stewardship Practice: Protocol for a Scoping Review.

</span>
<span class="ltx_bibblock"><em id="bib.bib17.3.1" class="ltx_emph ltx_font_italic">JMIR Research Protocols</em>
10, 2 (2021),
e22505.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.2196/22505" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.2196/22505</a>

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Joanna Redden and
Terzieva (2020)</span>
<span class="ltx_bibblock">
Jessica Brand Joanna Redden and
Vanesa Terzieva. 2020.

</span>
<span class="ltx_bibblock"><em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">Data Harm Record (Updated)</em>.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock"><a target="_blank" href="https://datajusticelab.org/data-harm-record/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://datajusticelab.org/data-harm-record/</a>, Online; accessed
22-August-2021.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jordon
et al<span id="bib.bib19.2.2.1" class="ltx_text">.</span> (2018a)</span>
<span class="ltx_bibblock">
James Jordon, Jinsung
Yoon, and Mihaela van der Schaar.
2018a.

</span>
<span class="ltx_bibblock">Measuring the quality of synthetic data for use in
competitions.

</span>
<span class="ltx_bibblock"><em id="bib.bib19.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1806.11345</em>
(2018).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jordon
et al<span id="bib.bib20.2.2.1" class="ltx_text">.</span> (2018b)</span>
<span class="ltx_bibblock">
James Jordon, Jinsung
Yoon, and Mihaela Van Der Schaar.
2018b.

</span>
<span class="ltx_bibblock">PATE-GAN: Generating synthetic data with
differential privacy guarantees. In <em id="bib.bib20.3.1" class="ltx_emph ltx_font_italic">International
conference on learning representations</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Krishnan et al<span id="bib.bib21.2.2.1" class="ltx_text">.</span> (2014)</span>
<span class="ltx_bibblock">
Sanjay Krishnan, Jay
Patel, Michael J Franklin, and Ken
Goldberg. 2014.

</span>
<span class="ltx_bibblock">A methodology for learning, analyzing, and
mitigating social influence bias in recommender systems. In
<em id="bib.bib21.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 8th ACM Conference on
Recommender systems</em>. 137–144.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Krishnaraj (2019)</span>
<span class="ltx_bibblock">
Manoj Krishnaraj.
2019.

</span>
<span class="ltx_bibblock">Comparative Analysis of Techniques for Data
Minimization for Recommender System algorithms.

</span>
<span class="ltx_bibblock">(2019).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Larson and Slokom (2019)</span>
<span class="ltx_bibblock">
Martha Larson and Manel
Slokom. 2019.

</span>
<span class="ltx_bibblock">Up close, but not too personal: Hypotargeting for
recommender systems. In <em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">ImpactRS 2019 Workshop, in
conjunction with the 11th ACM Conference on Recommender Systems (RecSys)</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Larson
et al<span id="bib.bib24.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Martha Larson, Alessandro
Zito, Babak Loni, and Paolo
Cremonesi. 2017.

</span>
<span class="ltx_bibblock">Towards minimal necessary data: The case for
analyzing training data requirements of recommender algorithms. In
<em id="bib.bib24.3.1" class="ltx_emph ltx_font_italic">FATREC 2017 Workshop on Fairness, Accountability,
and Transparency in Recommender Systems, in conjunction with the 11th ACM
Conference on Recommender Systems (RecSys)</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li
et al<span id="bib.bib25.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Yunqi Li, Hanxiong Chen,
Zuohui Fu, Yingqiang Ge, and
Yongfeng Zhang. 2021.

</span>
<span class="ltx_bibblock">User-oriented Fairness in Recommendation. In
<em id="bib.bib25.3.1" class="ltx_emph ltx_font_italic">Proceedings of the Web Conference</em>.
624–632.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin
et al<span id="bib.bib26.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Kun Lin, Nasim Sonboli,
Bamshad Mobasher, and Robin Burke.
2019.

</span>
<span class="ltx_bibblock">Crank up the volume: preference bias amplification
in collaborative recommendation. In <em id="bib.bib26.3.1" class="ltx_emph ltx_font_italic">in
Multi-stakeholder Environments (RMSE’19), in conjunction with the 13th ACM
Conference on Recommender Systems (RecSys’19)</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mansoury et al<span id="bib.bib27.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Masoud Mansoury, Bamshad
Mobasher, Robin Burke, and Mykola
Pechenizkiy. 2019.

</span>
<span class="ltx_bibblock">Bias Disparity in Collaborative Recommendation:
Algorithmic Evaluation and Comparison. In <em id="bib.bib27.3.1" class="ltx_emph ltx_font_italic">in
Multi-stakeholder Environments (RMSE’19), in conjunction with the 13th ACM
Conference on Recommender Systems (RecSys’19)</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Narayanan and
Shmatikov (2008)</span>
<span class="ltx_bibblock">
Arvind Narayanan and
Vitaly Shmatikov. 2008.

</span>
<span class="ltx_bibblock">Robust de-anonymization of large sparse datasets.
In <em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">IEEE Symposium on Security and Privacy</em>.
111–125.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">OpenAIRE (2018)</span>
<span class="ltx_bibblock">
OpenAIRE. 2018.

</span>
<span class="ltx_bibblock"><em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">The Four Basics of FAIR</em>.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock"><a target="_blank" href="https://www.openaire.eu/what-is-fair-data" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.openaire.eu/what-is-fair-data</a>, Online; accessed
22-August-2021.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Regulation (2018)</span>
<span class="ltx_bibblock">
General Data Protection Regulation.
2018.

</span>
<span class="ltx_bibblock">Principles Relating to Processing of Personal Data.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Said and
Bellogín (2014)</span>
<span class="ltx_bibblock">
Alan Said and Alejandro
Bellogín. 2014.

</span>
<span class="ltx_bibblock">Comparative Recommender System Evaluation:
Benchmarking Recommendation Frameworks. In
<em id="bib.bib31.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 8th ACM Conference on
Recommender Systems</em> (Foster City, Silicon Valley, California, USA)
<em id="bib.bib31.2.2" class="ltx_emph ltx_font_italic">(RecSys ’14)</em>. Association for
Computing Machinery, New York, NY, USA,
129–136.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/2645710.2645746" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/2645710.2645746</a>

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Slokom
et al<span id="bib.bib32.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Manel Slokom, Alan
Hanjalic, and Martha Larson.
2021.

</span>
<span class="ltx_bibblock">Towards user-oriented privacy for recommender
system data: A personalization-based approach to gender obfuscation for user
profiles.

</span>
<span class="ltx_bibblock"><em id="bib.bib32.3.1" class="ltx_emph ltx_font_italic">Information Processing &amp; Management</em>
58, 6 (2021),
102722.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1016/j.ipm.2021.102722" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1016/j.ipm.2021.102722</a>

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Slokom
et al<span id="bib.bib33.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Manel Slokom, Martha
Larson, and Alan Hanjalic.
2019.

</span>
<span class="ltx_bibblock">Data Masking for Recommender Systems: Prediction
Performance and Rating Hiding.

</span>
<span class="ltx_bibblock"><em id="bib.bib33.3.1" class="ltx_emph ltx_font_italic">Late breaking results, in conjunction with
the 13th ACM Conference on Recommender Systems, RecSys</em>
(2019).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tian and Ekstrand (2018)</span>
<span class="ltx_bibblock">
Mucun Tian and Michael D
Ekstrand. 2018.

</span>
<span class="ltx_bibblock">Monte Carlo Estimates of Evaluation Metric Error
and Bias. In <em id="bib.bib34.1.1" class="ltx_emph ltx_font_italic">REVEAL 2018 Workshop on Offline
Evaluation in Recommender Systems, in conjunction with the 12th ACM
Conference on Recommender Systems (RecSys’18)</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tsintzou
et al<span id="bib.bib35.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Virginia Tsintzou,
Evaggelia Pitoura, and Panayiotis
Tsaparas. 2018.

</span>
<span class="ltx_bibblock">Bias Disparity in Recommendation Systems.

</span>
<span class="ltx_bibblock"><em id="bib.bib35.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1811.01461</em>
(2018).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yao et al<span id="bib.bib36.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Sirui Yao, Yoni Halpern,
Nithum Thain, Xuezhi Wang,
Kang Lee, Flavien Prost,
Ed H Chi, Jilin Chen, and
Alex Beutel. 2021.

</span>
<span class="ltx_bibblock">Measuring Recommender System Effects with Simulated
Users.

</span>
<span class="ltx_bibblock"><em id="bib.bib36.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2101.04526</em>
(2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2110.03274" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2110.03275" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2110.03275">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2110.03275" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2110.03276" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Tue Mar 19 14:44:21 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
