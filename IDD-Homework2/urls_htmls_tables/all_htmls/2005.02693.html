<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2005.02693] Shape of synth to come: Why we should use synthetic data for English surface realization</title><meta property="og:description" content="The Surface Realization Shared Tasks of 2018 and 2019 were Natural Language Generation shared tasks with the goal of exploring approaches to surface realization from Universal-Dependency-like trees to surface strings f…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Shape of synth to come: Why we should use synthetic data for English surface realization">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Shape of synth to come: Why we should use synthetic data for English surface realization">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2005.02693">

<!--Generated on Sat Mar  2 11:44:09 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Shape of synth to come: Why we should use synthetic data for English surface realization</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Henry Elder 
<br class="ltx_break">ADAPT Centre 
<br class="ltx_break">Dublin City University 
<br class="ltx_break"><span id="id1.1.id1" class="ltx_text ltx_font_typewriter">henry.elder@adaptcentre.ie </span> 
<br class="ltx_break"><span id="id2.2.id2" class="ltx_ERROR undefined">\And</span>Robert Burke 
<br class="ltx_break"><span id="id3.3.id3" class="ltx_text ltx_font_typewriter">sharpobject@gmail.com</span> 
<br class="ltx_break"><span id="id4.4.id4" class="ltx_ERROR undefined">\AND</span>Alexander O’Connor 
<br class="ltx_break">Autodesk, inc. 
<br class="ltx_break"><span id="id5.5.id5" class="ltx_text ltx_font_typewriter">alex.oconnor@autodesk.com</span> 
<br class="ltx_break"><span id="id6.6.id6" class="ltx_ERROR undefined">\And</span>Jennifer Foster 
<br class="ltx_break">School of Computing 
<br class="ltx_break">Dublin City University 
<br class="ltx_break"><span id="id7.7.id7" class="ltx_text ltx_font_typewriter">jennifer.foster@dcu.ie</span> 
<br class="ltx_break">
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id8.id1" class="ltx_p">The Surface Realization Shared Tasks of 2018 and 2019 were Natural Language Generation shared tasks with the goal of exploring approaches to surface realization from Universal-Dependency-like trees to surface strings for several languages. In the 2018 shared task there was very little difference in the absolute performance of systems trained with and without additional, synthetically created data, and a new rule prohibiting the use of synthetic data was introduced for the 2019 shared task. Contrary to the findings of the 2018 shared task, we show, in experiments on the English 2018 dataset, that the use of synthetic data can have a substantial positive effect – an improvement of almost 8 BLEU points for a previously state-of-the-art system. We analyse the effects of synthetic data, and we argue that its use should be encouraged rather than prohibited so that future research efforts continue to explore systems that can take advantage of such data.
</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">The shallow task of the recent surface realization (SR) shared tasks <cite class="ltx_cite ltx_citemacro_citep">(Belz et al., <a href="#bib.bib1" title="" class="ltx_ref">2011</a>; Mille et al., <a href="#bib.bib14" title="" class="ltx_ref">2018</a>, <a href="#bib.bib15" title="" class="ltx_ref">2019</a>)</cite> appears to be a relatively straightforward problem.
Given a tree of lemmas, a system has to restore the original word order of the sentence and inflect its lemmas, see Figure <a href="#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ Shape of synth to come: Why we should use synthetic data for English surface realization" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.
Yet SR systems often struggle, even for a relatively fixed word order language such as English.
Improved performance would facilitate investigation of more complex versions of the shallow task, such as the deep task in which function words are pruned from the tree, which may be of more practical use in pipeline natural language generation (NLG) systems <cite class="ltx_cite ltx_citemacro_citep">(Moryossef et al., <a href="#bib.bib16" title="" class="ltx_ref">2019</a>; Elder et al., <a href="#bib.bib4" title="" class="ltx_ref">2019</a>; Castro Ferreira et al., <a href="#bib.bib3" title="" class="ltx_ref">2019</a>)</cite>.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">In this paper we explore the use of synthetic data for the English shallow task.
Synthetic data is created by taking an unlabelled sentence, parsing it with
an open source universal dependency parser<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>A number of these exist, e.g. <a target="_blank" href="https://github.com/stanfordnlp/stanfordnlp" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/stanfordnlp/stanfordnlp</a> and <a target="_blank" href="http://lindat.mff.cuni.cz/services/udpipe/" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://lindat.mff.cuni.cz/services/udpipe/</a></span></span></span> and transforming the result into the input representation.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">Unlike in the 2018 shared task, where a system trained with synthetic data performed roughly the same as a system trained on the original dataset <cite class="ltx_cite ltx_citemacro_citep">(Elder and Hokamp, <a href="#bib.bib5" title="" class="ltx_ref">2018</a>; King and White, <a href="#bib.bib8" title="" class="ltx_ref">2018</a>)</cite>, we find its use leads to a large improvement in performance.
The state-of-the-art on the dataset is 72.7 BLEU-4 score <cite class="ltx_cite ltx_citemacro_citep">(Yu et al., <a href="#bib.bib26" title="" class="ltx_ref">2019b</a>)</cite> – our system achieves a similar result of 72.3, which improves to 80.1 with the use of synthetic data.
We analyse the ways in which synthetic data helps to improve performance, finding that longer sentences are particularly improved and more exactly correct linearizations are generated overall.</p>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/2005.02693/assets/x1.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_square" width="276" height="314" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Example tree and reference sentence</figcaption>
</figure>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">Although it is common knowledge that machine learning systems typically benefit from more data, this 7.4 point jump in BLEU is important and worth emphasizing. The 2019 shared task introduced a new rule which prohibited the use of synthetic data. This was done in order to make the results of different systems more comparable.
However, systems designed with smaller datasets in mind might not scale to the use of synthetic data, and an inadvertent consequence of such a rule is that it may produce results which could be misleading for future research directions.
</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">For instance, the system which was the clear winner of this year’s shared task <cite class="ltx_cite ltx_citemacro_cite">Yu et al. (<a href="#bib.bib25" title="" class="ltx_ref">2019a</a>)</cite> used tree-structured long short-term memory (LSTM) networks <cite class="ltx_cite ltx_citemacro_citep">(Tai et al., <a href="#bib.bib23" title="" class="ltx_ref">2015</a>)</cite>.
In general, tree LSTMs can be slow and difficult to train.<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span><a target="_blank" href="https://github.com/dasguptar/treelstm.pytorch/issues/6" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/dasguptar/treelstm.pytorch/issues/6</a></span></span></span>
<cite class="ltx_cite ltx_citemacro_citet">Song et al. (<a href="#bib.bib22" title="" class="ltx_ref">2018</a>)</cite> utilized a variant of the tree LSTM in a similar NLG task, converting abstract meaning representation (AMR) graphs to text.
Following the state-of-the-art system <cite class="ltx_cite ltx_citemacro_citep">(Konstas et al., <a href="#bib.bib10" title="" class="ltx_ref">2017</a>)</cite>, which used standard LSTMs, <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib22" title="" class="ltx_ref">Song et al.</a></cite> augmented their training with synthetic data.
Though their system outperformed <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib10" title="" class="ltx_ref">Konstas et al.</a></cite> at equivalent levels of additional training sentences, it was unable to scale up to the 20 million sentences used by the best <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib10" title="" class="ltx_ref">Konstas et al.</a></cite> system and ultimately did not outperform them.<span id="footnote3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span><cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib22" title="" class="ltx_ref">Song et al.</a></cite>’s best system achieved 33.0 BLEU score with 2 million additional sentences, while <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib10" title="" class="ltx_ref">Konstas et al.</a></cite> scored 32.3 with 2 million and 33.8 with 20 million (the best overall system).</span></span></span></p>
</div>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.1" class="ltx_p">Critics of neural NLG approaches<span id="footnote4" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span>See, for example, <a target="_blank" href="https://ehudreiter.com/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://ehudreiter.com/</a></span></span></span> emphasise that quality and reliability are at the core of production-ready NLG systems.
What we are essentially arguing is that if using synthetic data contributes to producing higher quality outputs, then we ought to ensure we are designing systems that can take advantage of synthetic data.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>System Description</h2>

<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Data</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">We evaluate on the Surface Realization Shared Task (SRST) 2018 dataset <cite class="ltx_cite ltx_citemacro_citep">(Mille et al., <a href="#bib.bib14" title="" class="ltx_ref">2018</a>)</cite> for English<span id="footnote5" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span><a target="_blank" href="http://taln.upf.edu/pages/msr2018-ws/SRST.html" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://taln.upf.edu/pages/msr2018-ws/SRST.html</a></span></span></span>, which was derived from the Universal Dependency English Web Treebank 2.0<span id="footnote6" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_tag ltx_tag_note">6</span><a target="_blank" href="https://github.com/UniversalDependencies/UD_English-EWT" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/UniversalDependencies/UD_English-EWT</a></span></span></span>. The training set consists of 12,375 sentences, dev 1,978, test 2,062.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Baseline system</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">The system we use is an improved version of a previous shared task participant’s system <cite class="ltx_cite ltx_citemacro_cite">Elder and Hokamp (<a href="#bib.bib5" title="" class="ltx_ref">2018</a>)</cite>.
This baseline system is a bidirectional LSTM encoder-decoder model.
The model is trained with copy attention <cite class="ltx_cite ltx_citemacro_citep">(Vinyals et al., <a href="#bib.bib24" title="" class="ltx_ref">2015</a>; See et al., <a href="#bib.bib21" title="" class="ltx_ref">2017</a>)</cite> which allows it to copy unknown tokens from the input sequence to the output.
The system performs both linearization and inflection in a single decoding step.
To aid inflection, a list is appended to the input sequence containing possible forms for each relevant lemma.</p>
</div>
<div id="S2.SS2.p2" class="ltx_para">
<p id="S2.SS2.p2.1" class="ltx_p">Depth first linearization <cite class="ltx_cite ltx_citemacro_citep">(Konstas et al., <a href="#bib.bib10" title="" class="ltx_ref">2017</a>)</cite> is used to convert the tree structure into a linear format, which is required for the encoder.
This linearization begins at the root node and adds each subsequent child to the sequence, before returning to the highest node not yet added.
Where there are multiple child nodes one is selected at random.
Decoding is done using beam search, the output sequence length is artificially constrained to contain the same number of tokens as the input.</p>
</div>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Improvements to baseline</h3>

<section id="S2.SS3.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Random linearizations</h4>

<div id="S2.SS3.SSS0.Px1.p1" class="ltx_para">
<p id="S2.SS3.SSS0.Px1.p1.1" class="ltx_p">In the baseline system, a single random depth first linearization of the training data is obtained and used repeatedly to train the model.
Instead, we obtain multiple linearizations, so that each epoch of training data potentially contains a different linearization of the same dependency tree.
This makes the model more robust to different linearizations, which is helpful as neural networks don’t generally deal well with randomness <cite class="ltx_cite ltx_citemacro_citep">(Juraska et al., <a href="#bib.bib7" title="" class="ltx_ref">2018</a>)</cite>.</p>
</div>
</section>
<section id="S2.SS3.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Scoping brackets</h4>

<div id="S2.SS3.SSS0.Px2.p1" class="ltx_para">
<p id="S2.SS3.SSS0.Px2.p1.1" class="ltx_p">Similar to <cite class="ltx_cite ltx_citemacro_citet">Konstas et al. (<a href="#bib.bib10" title="" class="ltx_ref">2017</a>)</cite> we apply scoping brackets around child nodes. This provides further indication of the tree structure to the model, despite using a linear sequence as input.</p>
</div>
</section>
<section id="S2.SS3.SSS0.Px3" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Restricted beam search</h4>

<div id="S2.SS3.SSS0.Px3.p1" class="ltx_para">
<p id="S2.SS3.SSS0.Px3.p1.1" class="ltx_p">In an attempt to reduce unnecessary errors during decoding, our beam search looks at the input sequence and restricts the available vocabulary to only tokens from the input, and tokens which have not yet appeared in the output sequence.
This is similar to the approach used by <cite class="ltx_cite ltx_citemacro_citet">King and White (<a href="#bib.bib8" title="" class="ltx_ref">2018</a>)</cite>.</p>
</div>
</section>
</section>
<section id="S2.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.4 </span>Synthetic Data</h3>

<div id="S2.SS4.p1" class="ltx_para">
<p id="S2.SS4.p1.1" class="ltx_p">To augment the existing training data we create synthetic data by parsing sentences from publicly available corpora.
The two corpora we investigated are Wikitext 103 <cite class="ltx_cite ltx_citemacro_citep">(Merity et al., <a href="#bib.bib13" title="" class="ltx_ref">2017</a>)</cite> and the CNN stories portion of the DeepMind Q&amp;A dataset <cite class="ltx_cite ltx_citemacro_citep">(Hermann et al., <a href="#bib.bib6" title="" class="ltx_ref">2015</a>)</cite>.</p>
</div>
<div id="S2.SS4.p2" class="ltx_para">
<p id="S2.SS4.p2.1" class="ltx_p">Each corpus requires some cleaning and formatting, after which they can be sentence tokenized using CoreNLP <cite class="ltx_cite ltx_citemacro_cite">Manning et al. (<a href="#bib.bib12" title="" class="ltx_ref">2014</a>)</cite>.
Sentences are filtered by length – min 5 tokens and max 50 – and for vocabulary overlap with the original training data – set to 80% of tokens in a sentence required to appear in the original vocabulary.
These sentences are then parsed using the Stanford NLP UD parser <cite class="ltx_cite ltx_citemacro_citep">(Qi et al., <a href="#bib.bib20" title="" class="ltx_ref">2018</a>)</cite>.
This leaves us with 2.4 million parsed sentences from the CNN stories corpus and 2.1 million from Wikitext.</p>
</div>
<div id="S2.SS4.p3" class="ltx_para">
<p id="S2.SS4.p3.1" class="ltx_p">It is a straightforward process to convert a parse tree into synthetic data.
First, word order information is removed by shuffling the IDs of the parse tree, then the tokens are lemmatised by removing the form column.
This is the same process used by the shared task organizers to create datasets from the UD treebanks.</p>
</div>
<div id="S2.SS4.p4" class="ltx_para">
<p id="S2.SS4.p4.1" class="ltx_p">While it has been noted that the use of synthetic data is problematic in NLG tasks (WeatherGov <cite class="ltx_cite ltx_citemacro_citep">(Liang et al., <a href="#bib.bib11" title="" class="ltx_ref">2009</a>)</cite> being the notable example) our data is created differently.
The WeatherGov dataset is constructed by pairing a table with the output of a rule-based NLG system.
This means any system trained on WeatherGov only re-learns the rules used to generate the text.
Our approach is the reverse; we parse an existing, naturally occurring sentence, and, thus, the model must learn to reverse the parsing algorithm.</p>
</div>
</section>
<section id="S2.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.5 </span>Training</h3>

<div id="S2.SS5.p1" class="ltx_para">
<p id="S2.SS5.p1.1" class="ltx_p">The system is trained using a custom fork<span id="footnote7" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">7</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">7</sup><span class="ltx_tag ltx_tag_note">7</span><a target="_blank" href="https://github.com/Henry-E/OpenNMT-py" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/Henry-E/OpenNMT-py</a></span></span></span> of the OpenNMT-py framework <cite class="ltx_cite ltx_citemacro_citep">(Klein et al., <a href="#bib.bib9" title="" class="ltx_ref">2017</a>)</cite>, the only change made was to the beam search decoding code. Hyperparameter details and replication instructions are provided in our project’s repository<span id="footnote8" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">8</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">8</sup><span class="ltx_tag ltx_tag_note">8</span><a target="_blank" href="https://github.com/Henry-E/surface-realization-shallow-task" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/Henry-E/surface-realization-shallow-task</a></span></span></span>, in particular in the config directory.</p>
</div>
<div id="S2.SS5.p2" class="ltx_para">
<p id="S2.SS5.p2.1" class="ltx_p">Vocabulary size varies based on the datasets in use. It is determined by using any tokens which appears 10 times or more.
When using the original shared task dataset, the vocabulary size is 2,193 tokens, training is done for 33 epochs and takes 40 minutes on two Nvidia 1080 Ti GPUs.
All hyperparameters stay the same when training with the synthetic data, except for vocabulary size and training time. For the combined shared task, Wikitext and CNN datasets the vocabulary size is 89,233, training time increases to around 2 days, and uses 60 random linearizations of the shared task dataset and 8 of the Wikitext and CNN datasets.</p>
</div>
</section>
<section id="S2.SS6" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.6 </span>Evaluation</h3>

<div id="S2.SS6.p1" class="ltx_para">
<p id="S2.SS6.p1.1" class="ltx_p">The evaluation is performed on detokenized sentences<span id="footnote9" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">9</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">9</sup><span class="ltx_tag ltx_tag_note">9</span>Using detokenized inputs for BLEU makes the score very sensitive to detokenization used and in the 2019 shared task evaluation was changed to use tokenized inputs instead.</span></span></span> using the official evaluation script from the 2018 shared task. We focus on BLEU-4 score <cite class="ltx_cite ltx_citemacro_citep">(Papineni et al., <a href="#bib.bib18" title="" class="ltx_ref">2002</a>)</cite> which was shown in both shared tasks to be highly correlated with human evaluation scores.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Results</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">In Table <a href="#S3.T1" title="Table 1 ‣ 3 Results ‣ Shape of synth to come: Why we should use synthetic data for English surface realization" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, we compare our results on the test set with those reported in <cite class="ltx_cite ltx_citemacro_citet">Yu et al. (<a href="#bib.bib26" title="" class="ltx_ref">2019b</a>)</cite>, which include the <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib26" title="" class="ltx_ref">Yu et al.</a></cite> system (Yu19), the best 2018 shared task result for English <cite class="ltx_cite ltx_citemacro_citep">(Elder and Hokamp, <a href="#bib.bib5" title="" class="ltx_ref">2018</a>)</cite> (ST18) and <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib26" title="" class="ltx_ref">Yu et al.</a></cite>’s implementation of two other baselines, <cite class="ltx_cite ltx_citemacro_citet">Bohnet et al. (<a href="#bib.bib2" title="" class="ltx_ref">2010</a>)</cite> (B10) and <cite class="ltx_cite ltx_citemacro_citet">Puduppully et al. (<a href="#bib.bib19" title="" class="ltx_ref">2016</a>)</cite> (P16) .
Ignoring for now the result with synthetic data, we can see that our system is competitive with that of Yu et al (72.3 vs 72.7).</p>
</div>
<figure id="S3.T1" class="ltx_table">
<table id="S3.T1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S3.T1.1.1.1" class="ltx_tr">
<td id="S3.T1.1.1.1.1" class="ltx_td ltx_border_t"></td>
<th id="S3.T1.1.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t">BLEU-4</th>
</tr>
<tr id="S3.T1.1.2.2" class="ltx_tr">
<td id="S3.T1.1.2.2.1" class="ltx_td ltx_align_left ltx_border_t">B10</td>
<td id="S3.T1.1.2.2.2" class="ltx_td ltx_align_left ltx_border_t">70.8</td>
</tr>
<tr id="S3.T1.1.3.3" class="ltx_tr">
<td id="S3.T1.1.3.3.1" class="ltx_td ltx_align_left">P16</td>
<td id="S3.T1.1.3.3.2" class="ltx_td ltx_align_left">65.9</td>
</tr>
<tr id="S3.T1.1.4.4" class="ltx_tr">
<td id="S3.T1.1.4.4.1" class="ltx_td ltx_align_left">ST18</td>
<td id="S3.T1.1.4.4.2" class="ltx_td ltx_align_left">69.1</td>
</tr>
<tr id="S3.T1.1.5.5" class="ltx_tr">
<td id="S3.T1.1.5.5.1" class="ltx_td ltx_align_left">Yu19</td>
<td id="S3.T1.1.5.5.2" class="ltx_td ltx_align_left"><span id="S3.T1.1.5.5.2.1" class="ltx_text ltx_font_bold">72.7</span></td>
</tr>
<tr id="S3.T1.1.6.6" class="ltx_tr">
<td id="S3.T1.1.6.6.1" class="ltx_td ltx_align_left">Ours</td>
<td id="S3.T1.1.6.6.2" class="ltx_td ltx_align_left">72.3</td>
</tr>
<tr id="S3.T1.1.7.7" class="ltx_tr">
<td id="S3.T1.1.7.7.1" class="ltx_td ltx_align_left ltx_border_b ltx_border_t">Ours + Synthetic data</td>
<td id="S3.T1.1.7.7.2" class="ltx_td ltx_align_left ltx_border_b ltx_border_t"><span id="S3.T1.1.7.7.2.1" class="ltx_text ltx_font_bold">80.1</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 1: </span>Test set results for baselines trained on the original dataset and the final model which uses synthetic data</figcaption>
</figure>
<div id="S3.p2" class="ltx_para">
<p id="S3.p2.1" class="ltx_p">In Section <a href="#S2.SS3" title="2.3 Improvements to baseline ‣ 2 System Description ‣ Shape of synth to come: Why we should use synthetic data for English surface realization" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.3</span></a>, we described three improvements to our baseline system: random linearization, scoping and restricted beam search. An ablation analysis of these improvements on the dev set is shown in Table <a href="#S3.T2" title="Table 2 ‣ 3 Results ‣ Shape of synth to come: Why we should use synthetic data for English surface realization" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. The biggest improvement comes from the introduction of random linearizations. However, all three make a meaningful, positive contribution.</p>
</div>
<figure id="S3.T2" class="ltx_table">
<div id="S3.T2.1" class="ltx_inline-block ltx_transformed_outer" style="width:433.6pt;height:142.9pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(80.3pt,-26.5pt) scale(1.58818749739077,1.58818749739077) ;">
<table id="S3.T2.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T2.1.1.1.1" class="ltx_tr">
<th id="S3.T2.1.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t">System</th>
<th id="S3.T2.1.1.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t">BLEU-4</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T2.1.1.2.1" class="ltx_tr">
<td id="S3.T2.1.1.2.1.1" class="ltx_td ltx_align_left ltx_border_t">SR Baseline</td>
<td id="S3.T2.1.1.2.1.2" class="ltx_td ltx_align_left ltx_border_t">57.3</td>
</tr>
<tr id="S3.T2.1.1.3.2" class="ltx_tr">
<td id="S3.T2.1.1.3.2.1" class="ltx_td ltx_align_left">SR + Random Lins</td>
<td id="S3.T2.1.1.3.2.2" class="ltx_td ltx_align_left">65.1</td>
</tr>
<tr id="S3.T2.1.1.4.3" class="ltx_tr">
<td id="S3.T2.1.1.4.3.1" class="ltx_td ltx_align_left">SR + Random Lins + Scope</td>
<td id="S3.T2.1.1.4.3.2" class="ltx_td ltx_align_left">69.2</td>
</tr>
<tr id="S3.T2.1.1.5.4" class="ltx_tr">
<td id="S3.T2.1.1.5.4.1" class="ltx_td ltx_align_left ltx_border_b">SR + Random Lins + Scope + Restricted Beam</td>
<td id="S3.T2.1.1.5.4.2" class="ltx_td ltx_align_left ltx_border_b">72.2</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 2: </span>Dev set results for ablation of the baseline system plus improvements, trained only on the original dataset</figcaption>
</figure>
<figure id="S3.T3" class="ltx_table">
<div id="S3.T3.1" class="ltx_inline-block ltx_transformed_outer" style="width:303.5pt;height:141.2pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(55.0pt,-25.6pt) scale(1.56841658915512,1.56841658915512) ;">
<table id="S3.T3.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T3.1.1.1.1" class="ltx_tr">
<th id="S3.T3.1.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t">Data used</th>
<th id="S3.T3.1.1.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t">BLEU-4</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T3.1.1.2.1" class="ltx_tr">
<td id="S3.T3.1.1.2.1.1" class="ltx_td ltx_align_left ltx_border_t">Improved SR Baseline (SRST)</td>
<td id="S3.T3.1.1.2.1.2" class="ltx_td ltx_align_left ltx_border_t">72.2</td>
</tr>
<tr id="S3.T3.1.1.3.2" class="ltx_tr">
<td id="S3.T3.1.1.3.2.1" class="ltx_td ltx_align_left">SR + Wikitext</td>
<td id="S3.T3.1.1.3.2.2" class="ltx_td ltx_align_left">79.8</td>
</tr>
<tr id="S3.T3.1.1.4.3" class="ltx_tr">
<td id="S3.T3.1.1.4.3.1" class="ltx_td ltx_align_left">SR + CNN</td>
<td id="S3.T3.1.1.4.3.2" class="ltx_td ltx_align_left">80.3</td>
</tr>
<tr id="S3.T3.1.1.5.4" class="ltx_tr">
<td id="S3.T3.1.1.5.4.1" class="ltx_td ltx_align_left ltx_border_b">SR + CNN + Wikitext</td>
<td id="S3.T3.1.1.5.4.2" class="ltx_td ltx_align_left ltx_border_b">80.8</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 3: </span>Dev set results for the SR shared task data with additional synthetic data: the role of the corpus</figcaption>
</figure>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>The Effect of Synthetic Data</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">The last row of Table <a href="#S3.T1" title="Table 1 ‣ 3 Results ‣ Shape of synth to come: Why we should use synthetic data for English surface realization" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> shows the effect of adding synthetic data. BLEU score on the test set jumps from 72.3 to 80.1.
To help understand why additional data makes such a substantial difference, we perform various analyses on the dev set, including examining the effect of the choice of unlabeled corpus and highlighting interesting differences between the systems trained with and without the synthetic data.</p>
</div>
<section id="S3.SS1.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">The role of corpus</h4>

<div id="S3.SS1.SSS0.Px1.p1" class="ltx_para">
<p id="S3.SS1.SSS0.Px1.p1.1" class="ltx_p">Table <a href="#S3.T3" title="Table 3 ‣ 3 Results ‣ Shape of synth to come: Why we should use synthetic data for English surface realization" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> compares the Wikitext corpus as a source of additional training data to the CNN corpus. Both the individual results and the result obtained by combining the two corpora show that there is little difference between the two.</p>
</div>
</section>
<section id="S3.SS1.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Sentence length and BLEU score</h4>

<div id="S3.SS1.SSS0.Px2.p1" class="ltx_para">
<p id="S3.SS1.SSS0.Px2.p1.1" class="ltx_p">Using compare-mt <cite class="ltx_cite ltx_citemacro_citep">(Neubig et al., <a href="#bib.bib17" title="" class="ltx_ref">2019</a>)</cite> we noticed a striking difference between the systems with regards to performance on sentences of different length.<span id="footnote10" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">10</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">10</sup><span class="ltx_tag ltx_tag_note">10</span>These are results for the tokenized versions of the generated and reference sentences, hence the higher numbers.</span></span></span> This is shown in Figure <a href="#S3.F2" title="Figure 2 ‣ Sentence length and BLEU score ‣ 3.1 The Effect of Synthetic Data ‣ 3 Results ‣ Shape of synth to come: Why we should use synthetic data for English surface realization" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
<div id="S3.SS1.SSS0.Px2.p2" class="ltx_para">
<p id="S3.SS1.SSS0.Px2.p2.1" class="ltx_p">Even though the synthetic data sentences were limited to 50 tokens in length, the synthetic data performed equally well for sentence length buckets 50-60 and 60+, while the baseline data system performed relatively worse. It is possible this is due to the synthetic data system containing a larger vocabulary and being exposed to a wider range of commonly occurring phrases, which make up parts of longer sentences.</p>
</div>
<figure id="S3.F2" class="ltx_figure"><img src="/html/2005.02693/assets/x2.png" id="S3.F2.g1" class="ltx_graphics ltx_centering ltx_img_square" width="369" height="306" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>BLEU score breakdown by sentence length buckets, comparing our best model trained on the original dataset with one trained with synthetic data</figcaption>
</figure>
<figure id="S3.T4" class="ltx_table">
<div id="S3.T4.1" class="ltx_inline-block ltx_transformed_outer" style="width:346.9pt;height:182.4pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(70.7pt,-37.2pt) scale(1.68851862161903,1.68851862161903) ;">
<table id="S3.T4.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S3.T4.1.1.1.1" class="ltx_tr">
<td id="S3.T4.1.1.1.1.1" class="ltx_td ltx_border_t"></td>
<th id="S3.T4.1.1.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t">SRST</th>
<th id="S3.T4.1.1.1.1.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t">Synth</th>
</tr>
<tr id="S3.T4.1.1.2.2" class="ltx_tr">
<td id="S3.T4.1.1.2.2.1" class="ltx_td ltx_align_left ltx_border_t">Exact match</td>
<td id="S3.T4.1.1.2.2.2" class="ltx_td ltx_align_left ltx_border_t">1159</td>
<td id="S3.T4.1.1.2.2.3" class="ltx_td ltx_align_left ltx_border_t">1314</td>
</tr>
<tr id="S3.T4.1.1.3.3" class="ltx_tr">
<td id="S3.T4.1.1.3.3.1" class="ltx_td ltx_align_left">+ Punctuation error only</td>
<td id="S3.T4.1.1.3.3.2" class="ltx_td ltx_align_left">43</td>
<td id="S3.T4.1.1.3.3.3" class="ltx_td ltx_align_left">46</td>
</tr>
<tr id="S3.T4.1.1.4.4" class="ltx_tr">
<td id="S3.T4.1.1.4.4.1" class="ltx_td ltx_align_left">+ Inflection error only</td>
<td id="S3.T4.1.1.4.4.2" class="ltx_td ltx_align_left">123</td>
<td id="S3.T4.1.1.4.4.3" class="ltx_td ltx_align_left">142</td>
</tr>
<tr id="S3.T4.1.1.5.5" class="ltx_tr">
<td id="S3.T4.1.1.5.5.1" class="ltx_td ltx_align_left">Total (relatively error free)</td>
<td id="S3.T4.1.1.5.5.2" class="ltx_td ltx_align_left ltx_border_t">1325</td>
<td id="S3.T4.1.1.5.5.3" class="ltx_td ltx_align_left ltx_border_t">1502</td>
</tr>
<tr id="S3.T4.1.1.6.6" class="ltx_tr">
<td id="S3.T4.1.1.6.6.1" class="ltx_td ltx_align_left ltx_border_b">Remaining errors</td>
<td id="S3.T4.1.1.6.6.2" class="ltx_td ltx_align_left ltx_border_b">653</td>
<td id="S3.T4.1.1.6.6.3" class="ltx_td ltx_align_left ltx_border_b">476</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 4: </span>Error analysis breakdown for the 1,978 dev sentences. SRST is our system without synthetic data and Synth is our system with synthetic data.</figcaption>
</figure>
</section>
<section id="S3.SS1.SSS0.Px3" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Error Analysis</h4>

<div id="S3.SS1.SSS0.Px3.p1" class="ltx_para">
<p id="S3.SS1.SSS0.Px3.p1.1" class="ltx_p">We perform some preliminary analysis that could serve as a precursor to more detailed human evaluation.
Table <a href="#S3.T4" title="Table 4 ‣ Sentence length and BLEU score ‣ 3.1 The Effect of Synthetic Data ‣ 3 Results ‣ Shape of synth to come: Why we should use synthetic data for English surface realization" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> lists the number of exact matches, in which the tokenized reference sentence and the generated sentence exactly match.
We also detect relatively minor errors, namely punctuation and inflection, in which these are the only differences between the reference and generated sentences.
Punctuation errors are typically minor and there is usually ambiguity about their placement.<span id="footnote11" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">11</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">11</sup><span class="ltx_tag ltx_tag_note">11</span>In the 2019 shared task an additional feature was provided to indicate the position of punctuation relative to its head token.</span></span></span>
Inflection errors occur when a different inflected form has been chosen by the model than in the reference sentence.
These tend to be small differences and are often valid alternatives, e.g. choosing <span id="S3.SS1.SSS0.Px3.p1.1.1" class="ltx_text ltx_font_italic">’m</span> over <span id="S3.SS1.SSS0.Px3.p1.1.2" class="ltx_text ltx_font_italic">am</span>.</p>
</div>
<div id="S3.SS1.SSS0.Px3.p2" class="ltx_para">
<p id="S3.SS1.SSS0.Px3.p2.1" class="ltx_p">Within the remaining uncategorized sentences are mostly linearization errors.
Linearization errors come in two main categories; non-breaking, in which the linearization is different from the reference sentence but is still valid and communicates the same meaning as the reference – see Example 1 below; and breaking, where the linearization has clear errors and doesn’t contain the same meaning as the reference sentence – see Example 2 below.</p>
</div>
<div id="S3.SS1.SSS0.Px3.p3" class="ltx_para">
<ol id="S3.I1" class="ltx_enumerate">
<li id="S3.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S3.I1.i1.p1" class="ltx_para">
<p id="S3.I1.i1.p1.1" class="ltx_p">Non-breaking</p>
<ol id="S3.I1.i1.I1" class="ltx_enumerate">
<li id="S3.I1.i1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(a)</span> 
<div id="S3.I1.i1.I1.i1.p1" class="ltx_para">
<p id="S3.I1.i1.I1.i1.p1.1" class="ltx_p">Ref: From the AP comes this story:</p>
</div>
</li>
<li id="S3.I1.i1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(b)</span> 
<div id="S3.I1.i1.I1.i2.p1" class="ltx_para">
<p id="S3.I1.i1.I1.i2.p1.1" class="ltx_p">Synth: This story comes from the AP:</p>
</div>
</li>
</ol>
</div>
</li>
<li id="S3.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S3.I1.i2.p1" class="ltx_para">
<p id="S3.I1.i2.p1.1" class="ltx_p">Breaking</p>
<ol id="S3.I1.i2.I1" class="ltx_enumerate">
<li id="S3.I1.i2.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(a)</span> 
<div id="S3.I1.i2.I1.i1.p1" class="ltx_para">
<p id="S3.I1.i2.I1.i1.p1.1" class="ltx_p">Ref: I ran across this item on the Internet.</p>
</div>
</li>
<li id="S3.I1.i2.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(b)</span> 
<div id="S3.I1.i2.I1.i2.p1" class="ltx_para">
<p id="S3.I1.i2.I1.i2.p1.1" class="ltx_p">Synth: I ran on the internet across this item.</p>
</div>
</li>
</ol>
</div>
</li>
</ol>
</div>
<div id="S3.SS1.SSS0.Px3.p4" class="ltx_para">
<p id="S3.SS1.SSS0.Px3.p4.1" class="ltx_p">This kind of breakdown in an error analysis may help understand the quality of these systems in more absolute terms, since it’s the overall number of accurate sentences which matters.
This could be more intuitive than comparing BLEU scores relative to prior models when deciding whether to apply a system in a business setting.</p>
</div>
</section>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Conclusion</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">We have argued for the use of synthetic data in English surface realization, justified by the fact that its use
gives a significant performance boost on the shallow task, from 72.7 BLEU up to 80.1. While this is not yet at the level of reliability needed for neural NLG systems to be used commercially, it is a step in the right direction.</p>
</div>
<div id="S4.p2" class="ltx_para">
<p id="S4.p2.1" class="ltx_p">Assuming the use of synthetic data, more needs to be investigated in order to fully maximize its benefit on performance. Future work will look more closely at the choice of corpus, construction details of the synthetic dataset, as well as the trade-off between training time and accuracy that comes with larger vocabularies.</p>
</div>
<div id="S4.p3" class="ltx_para">
<p id="S4.p3.1" class="ltx_p">The work described in this paper has focused on English. Another avenue of research would be to investigate the role of synthetic data in surface realization in other languages.</p>
</div>
</section>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Acknowledgments</h2>

<div id="Sx1.p1" class="ltx_para">
<p id="Sx1.p1.1" class="ltx_p">We thank the anonymous reviewers for their helpful comments. This research is supported by Science Foundation Ireland in the ADAPT Centre for Digital Content Technology. The ADAPT Centre for Digital Content Technology is funded under the SFI Research Centres Programme (Grant 13/RC/2106) and is co-funded under the European Regional Development Fund.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Belz et al. (2011)</span>
<span class="ltx_bibblock">
Anja Belz, Michael White, Dominic Espinosa, Eric Kow, Deirdre Hogan, and Amanda
Stent. 2011.

</span>
<span class="ltx_bibblock">The First Surface Realisation Shared Task: Overview and Evaluation
Results.

</span>
<span class="ltx_bibblock">In <em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">Proceedings of the European Workshop on Natural Language
Generation</em>, December, pages 217–226.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bohnet et al. (2010)</span>
<span class="ltx_bibblock">
Bernd Bohnet, Leo Wanner, Simon Mille, and Alicia Burga. 2010.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://www.aclweb.org/anthology/C10-1012" title="" class="ltx_ref ltx_href">Broad Coverage
Multilingual Deep Sentence Generation with a Stochastic Multi-Level
Realizer</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 23rd International Conference on
Computational Linguistics (Coling 2010)</em>, pages 98–106, Beijing, China.
Coling 2010 Organizing Committee.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Castro Ferreira et al. (2019)</span>
<span class="ltx_bibblock">
Thiago Castro Ferreira, Chris van der Lee, Emiel van Miltenburg, and Emiel
Krahmer. 2019.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/D19-1052" title="" class="ltx_ref ltx_href">Neural data-to-text
generation: A comparison between pipeline and end-to-end architectures</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2019 Conference on Empirical Methods in
Natural Language Processing and the 9th International Joint Conference on
Natural Language Processing (EMNLP-IJCNLP)</em>, pages 552–562, Stroudsburg, PA,
USA. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Elder et al. (2019)</span>
<span class="ltx_bibblock">
Henry Elder, Jennifer Foster, James Barry, and Alexander O’Connor. 2019.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/W19-2308" title="" class="ltx_ref ltx_href">Designing a Symbolic
Intermediate Representation for Neural Surface Realization</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Workshop on Methods for Optimizing and
Evaluating Neural Language Generation</em>, pages 65–73, Stroudsburg, PA, USA.
Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Elder and Hokamp (2018)</span>
<span class="ltx_bibblock">
Henry Elder and Chris Hokamp. 2018.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/W18-3606" title="" class="ltx_ref ltx_href">Generating
High-Quality Surface Realizations Using Data Augmentation and Factored
Sequence Models</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">Proceedings of the First Workshop on Multilingual Surface
Realisation</em>, pages 49–53, Stroudsburg, PA, USA. Association for
Computational Linguistics.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hermann et al. (2015)</span>
<span class="ltx_bibblock">
Karl Moritz Hermann, Tomas Kocisky, Edward Grefenstette, Lasse Espeholt, Will
Kay, Mustafa Suleyman, and Phil Blunsom. 2015.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://papers.nips.cc/paper/5945-teaching-machines-to-read-and-comprehend.pdf" title="" class="ltx_ref ltx_href">Teaching Machines to Read and Comprehend</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems 28</em>, pages
1693–1701. Curran Associates, Inc.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Juraska et al. (2018)</span>
<span class="ltx_bibblock">
Juraj Juraska, Panagiotis Karagiannis, Kevin Bowden, and Marilyn Walker. 2018.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/N18-1014" title="" class="ltx_ref ltx_href">A Deep Ensemble Model
with Slot Alignment for Sequence-to-Sequence Natural Language Generation</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2018 Conference of the North American
Chapter of the Association for Computational Linguistics: Human Language
Technologies, Volume 1 (Long Papers)</em>, pages 152–162, Stroudsburg, PA, USA.
Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">King and White (2018)</span>
<span class="ltx_bibblock">
David King and Michael White. 2018.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/W18-3605" title="" class="ltx_ref ltx_href">The OSU Realizer for
SRST ‘18: Neural Sequence-to-Sequence Inflection and Incremental
Locality-Based Linearization</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">Proceedings of the First Workshop on Multilingual Surface
Realisation</em>, 2009, pages 39–48, Stroudsburg, PA, USA. Association for
Computational Linguistics.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Klein et al. (2017)</span>
<span class="ltx_bibblock">
Guillaume Klein, Yoon Kim, Yuntian Deng, Jean Senellart, and Alexander Rush.
2017.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/P17-4012" title="" class="ltx_ref ltx_href">OpenNMT: Open-Source
Toolkit for Neural Machine Translation</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">Proceedings of ACL 2017, System Demonstrations</em>, pages
67–72, Stroudsburg, PA, USA. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Konstas et al. (2017)</span>
<span class="ltx_bibblock">
Ioannis Konstas, Srinivasan Iyer, Mark Yatskar, Yejin Choi, and Luke
Zettlemoyer. 2017.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/P17-1014" title="" class="ltx_ref ltx_href">Neural AMR:
Sequence-to-Sequence Models for Parsing and Generation</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 55th Annual Meeting of the Association
for Computational Linguistics (Volume 1: Long Papers)</em>, pages 146–157,
Stroudsburg, PA, USA. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liang et al. (2009)</span>
<span class="ltx_bibblock">
Percy Liang, Michael I. Jordan, and Dan Klein. 2009.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://aclweb.org/anthology/P09-1011" title="" class="ltx_ref ltx_href">Learning Semantic
Correspondences with Less Supervision</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Joint Conference of the 47th Annual Meeting
of the ACL and the 4th International Joint Conference on Natural Language
Processing of the AFNLP</em>, (August):91–99.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Manning et al. (2014)</span>
<span class="ltx_bibblock">
Christopher D Manning, Mihai Surdeanu, John Bauer, Jenny Finkel, Steven J
Bethard, and David McClosky. 2014.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://www.aclweb.org/anthology/P/P14/P14-5010" title="" class="ltx_ref ltx_href">The
{Stanford} {CoreNLP} Natural Language Processing Toolkit</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">Association for Computational Linguistics (ACL) System
Demonstrations</em>, pages 55–60.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Merity et al. (2017)</span>
<span class="ltx_bibblock">
Stephen Merity, Caiming Xiong, James Bradbury, and Richard Socher. 2017.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://openreview.net/forum?id=Byj72udxe" title="" class="ltx_ref ltx_href">Pointer Sentinel
Mixture Models</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">5th International Conference on Learning Representations,
<span id="bib.bib13.1.1.1" class="ltx_text ltx_font_upright">{</span>ICLR<span id="bib.bib13.1.1.2" class="ltx_text ltx_font_upright">}</span> 2017, Toulon, France, April 24-26, 2017, Conference Track
Proceedings</em>. OpenReview.net.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mille et al. (2018)</span>
<span class="ltx_bibblock">
Simon Mille, Anja Belz, Bernd Bohnet, Yvette Graham, Emily Pitler, and Leo
Wanner. 2018.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://universaldependencies.org/" title="" class="ltx_ref ltx_href">The First Multilingual
Surface Realisation Shared Task (SR’18): Overview and Evaluation Results</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 1st Workshop on Multilingual Surface
Realisation (MSR), 56th Annual Meeting of the Association for Computational
Linguistics</em>, pages 1–10, Melbourne, Australia.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mille et al. (2019)</span>
<span class="ltx_bibblock">
Simon Mille, Anja Belz, Bernd Bohnet, Yvette Graham, and Leo Wanner. 2019.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/D19-6301" title="" class="ltx_ref ltx_href">The Second
Multilingual Surface Realisation Shared Task (SR’19): Overview and
Evaluation Results</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2nd Workshop on Multilingual Surface
Realisation (MSR 2019)</em>, Msr, pages 1–17, Stroudsburg, PA, USA. Association
for Computational Linguistics.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Moryossef et al. (2019)</span>
<span class="ltx_bibblock">
Amit Moryossef, Yoav Goldberg, and Ido Dagan. 2019.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/N19-1236" title="" class="ltx_ref ltx_href">Step-by-Step:
Separating Planning from Realization in Neural Data-to-Text Generation</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2019 Conference of the North</em>, pages
2267–2277, Stroudsburg, PA, USA. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Neubig et al. (2019)</span>
<span class="ltx_bibblock">
Graham Neubig, Zi-Yi Dou, Junjie Hu, Paul Michel, Danish Pruthi, and Xinyi
Wang. 2019.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/1903.07926" title="" class="ltx_ref ltx_href">compare-mt: A Tool for
Holistic Comparison of Language Generation Systems</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">Meeting of the North American Chapter of the Association for
Computational Linguistics (NAACL) Demo Track</em>, Minneapolis, USA.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Papineni et al. (2002)</span>
<span class="ltx_bibblock">
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. 2002.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.3115/1073083.1073135" title="" class="ltx_ref ltx_href">BLEU: A Method for
Automatic Evaluation of Machine Translation</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 40th Annual Meeting on Association for
Computational Linguistics</em>, ACL ’02, pages 311–318, Stroudsburg, PA, USA.
Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Puduppully et al. (2016)</span>
<span class="ltx_bibblock">
Ratish Puduppully, Yue Zhang, and Manish Shrivastava. 2016.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/N16-1058" title="" class="ltx_ref ltx_href">Transition-Based
Syntactic Linearization with Lookahead Features</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2016 Conference of the North American
Chapter of the Association for Computational Linguistics: Human Language
Technologies</em>, pages 488–493, Stroudsburg, PA, USA. Association for
Computational Linguistics.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Qi et al. (2018)</span>
<span class="ltx_bibblock">
Peng Qi, Timothy Dozat, Yuhao Zhang, and Christopher D Manning. 2018.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://nlp.stanford.edu/pubs/qi2018universal.pdf" title="" class="ltx_ref ltx_href">Universal
Dependency Parsing from Scratch</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">Proceedings of the (CoNLL) 2018 Shared Task: Multilingual
Parsing from Raw Text to Universal Dependencies</em>, pages 160–170, Brussels,
Belgium. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">See et al. (2017)</span>
<span class="ltx_bibblock">
Abigail See, Peter J. Liu, and Christopher D. Manning. 2017.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/P17-1099" title="" class="ltx_ref ltx_href">Get To The Point:
Summarization with Pointer-Generator Networks</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 55th Annual Meeting of the Association
for Computational Linguistics (Volume 1: Long Papers)</em>, pages 1073–1083,
Stroudsburg, PA, USA. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Song et al. (2018)</span>
<span class="ltx_bibblock">
Linfeng Song, Yue Zhang, Zhiguo Wang, and Daniel Gildea. 2018.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/P18-1150" title="" class="ltx_ref ltx_href">A Graph-to-Sequence
Model for AMR-to-Text Generation</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 56th Annual Meeting of the Association
for Computational Linguistics (Volume 1: Long Papers)</em>, pages 1616–1626,
Stroudsburg, PA, USA. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tai et al. (2015)</span>
<span class="ltx_bibblock">
Kai Sheng Tai, Richard Socher, and Christopher D. Manning. 2015.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.3115/v1/P15-1150" title="" class="ltx_ref ltx_href">Improved Semantic
Representations From Tree-Structured Long Short-Term Memory Networks</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 53rd Annual Meeting of the Association
for Computational Linguistics and the 7th International Joint Conference on
Natural Language Processing (Volume 1: Long Papers)</em>, volume 2015, pages
1556–1566, Stroudsburg, PA, USA. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vinyals et al. (2015)</span>
<span class="ltx_bibblock">
Oriol Vinyals, Meire Fortunato, and Navdeep Jaitly. 2015.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/1506.03134%0Ahttp://papers.nips.cc/paper/5866-pointer-networks.pdf" title="" class="ltx_ref ltx_href">Pointer Networks</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems 28</em>, pages
2692–2700.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu et al. (2019a)</span>
<span class="ltx_bibblock">
Xiang Yu, Agnieszka Falenska, Marina Haid, Ngoc Thang Vu, and Jonas Kuhn.
2019a.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/D19-6306" title="" class="ltx_ref ltx_href">IMSurReal: IMS at the
Surface Realization Shared Task 2019</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2nd Workshop on Multilingual Surface
Realisation (MSR 2019)</em>, Msr, pages 50–58, Stroudsburg, PA, USA. Association
for Computational Linguistics.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu et al. (2019b)</span>
<span class="ltx_bibblock">
Xiang Yu, Agnieszka Falenska, Ngoc Thang Vu, and Jonas Kuhn.
2019b.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://www.aclweb.org/anthology/W19-8636" title="" class="ltx_ref ltx_href">Head-First
Linearization with Tree-Structured Representation</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 12th International Conference on Natural
Language Generation</em>, 2018, pages 279–289, Tokyo, Japan. Association for
Computational Linguistics.

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2005.02692" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2005.02693" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2005.02693">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2005.02693" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2005.02694" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Sat Mar  2 11:44:09 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
