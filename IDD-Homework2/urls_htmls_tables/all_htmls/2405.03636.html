<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2405.03636] Federated Learning Privacy: Attacks, Defenses, Applications, and Policy Landscape — A Survey</title><meta property="og:description" content="Deep learning has shown incredible potential across a vast array of tasks and accompanying this growth has been an insatiable appetite for data. However, a large amount of data needed for enabling deep learning is stor…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Federated Learning Privacy: Attacks, Defenses, Applications, and Policy Landscape — A Survey">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Federated Learning Privacy: Attacks, Defenses, Applications, and Policy Landscape — A Survey">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2405.03636">

<!--Generated on Wed Jun  5 15:43:25 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content="Distributed machine learning,  Federated learning,  Privacy in federated learning,  Application domains for federated learning,  Privacy policies">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line ltx_leqno">
<h1 class="ltx_title ltx_title_document">Federated Learning Privacy: Attacks, Defenses, Applications, and Policy Landscape — A Survey</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Joshua C. Zhao
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id1.1.id1" class="ltx_text ltx_affiliation_institution">Purdue University</span><span id="id2.2.id2" class="ltx_text ltx_affiliation_city">West Lafayette, IN</span><span id="id3.3.id3" class="ltx_text ltx_affiliation_country">United States of America</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:zhao1207@purdue.edu">zhao1207@purdue.edu</a>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Saurabh Bagchi
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id4.1.id1" class="ltx_text ltx_affiliation_institution">Purdue University and KeyByte</span><span id="id5.2.id2" class="ltx_text ltx_affiliation_city">West Lafayette, IN</span><span id="id6.3.id3" class="ltx_text ltx_affiliation_country">United States of America</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:sbagchi@purdue.edu">sbagchi@purdue.edu</a>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Salman Avestimehr
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id7.1.id1" class="ltx_text ltx_affiliation_institution">University of Southern California and FedML</span><span id="id8.2.id2" class="ltx_text ltx_affiliation_city">Los Angeles, CA</span><span id="id9.3.id3" class="ltx_text ltx_affiliation_country">United States of America</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:avestime@usc.edu">avestime@usc.edu</a>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Kevin S. Chan
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id10.1.id1" class="ltx_text ltx_affiliation_institution">DEVCOM Army Research Laboratory</span><span id="id11.2.id2" class="ltx_text ltx_affiliation_city">Adelphi, MD</span><span id="id12.3.id3" class="ltx_text ltx_affiliation_country">United States of America</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:kevin.s.chan.civ@army.mil">kevin.s.chan.civ@army.mil</a>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Somali Chaterji
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id13.1.id1" class="ltx_text ltx_affiliation_institution">Purdue University and KeyByte</span><span id="id14.2.id2" class="ltx_text ltx_affiliation_city">West Lafayette, IN</span><span id="id15.3.id3" class="ltx_text ltx_affiliation_country">United States of America</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:schaterji@purdue.edu">schaterji@purdue.edu</a>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Dimitris Dimitriadis
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id16.1.id1" class="ltx_text ltx_affiliation_institution">Amazon</span><span id="id17.2.id2" class="ltx_text ltx_affiliation_city">Bellevue, WA</span><span id="id18.3.id3" class="ltx_text ltx_affiliation_country">United States of America</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:dbdim@amazon.com">dbdim@amazon.com</a>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Jiacheng Li
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id19.1.id1" class="ltx_text ltx_affiliation_institution">Purdue University</span><span id="id20.2.id2" class="ltx_text ltx_affiliation_city">West Lafayette, IN</span><span id="id21.3.id3" class="ltx_text ltx_affiliation_country">United States of America</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:li2829@purdue.edu">li2829@purdue.edu</a>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Ninghui Li
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id22.1.id1" class="ltx_text ltx_affiliation_institution">Purdue University</span><span id="id23.2.id2" class="ltx_text ltx_affiliation_city">West Lafayette, IN</span><span id="id24.3.id3" class="ltx_text ltx_affiliation_country">United States of America</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:ninghui@purdue.edu">ninghui@purdue.edu</a>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Arash Nourian
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id25.1.id1" class="ltx_text ltx_affiliation_institution">Amazon</span><span id="id26.2.id2" class="ltx_text ltx_affiliation_city">Sunnyvale, CA</span><span id="id27.3.id3" class="ltx_text ltx_affiliation_country">United States of America</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:nourian@gmail.com">nourian@gmail.com</a>
</span></span></span>
<span class="ltx_author_before"> and </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Holger R. Roth
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id28.1.id1" class="ltx_text ltx_affiliation_institution">NVIDIA</span><span id="id29.2.id2" class="ltx_text ltx_affiliation_city">Bethesda, MD</span><span id="id30.3.id3" class="ltx_text ltx_affiliation_country">United States of America</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:hroth@nvidia.com">hroth@nvidia.com</a>
</span></span></span>
</div>
<div class="ltx_dates">(2024; XXX; XXX; XXX)</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract.</h6>
<p id="id31.id1" class="ltx_p">Deep learning has shown incredible potential across a vast array of tasks and accompanying this growth has been an insatiable appetite for data. However, a large amount of data needed for enabling deep learning is stored on personal devices and recent concerns on privacy have further highlighted challenges for accessing such data. As a result, federated learning (FL) has emerged as an important privacy-preserving technology enabling collaborative training of machine learning models without the need to send the raw, potentially sensitive, data to a central server. However, the fundamental premise that sending model updates to a server is privacy-preserving only holds if the updates cannot be ”reverse engineered” to infer information about the private training data. It has been shown under a wide variety of settings that this premise for privacy does <span id="id31.id1.1" class="ltx_text ltx_font_italic">not</span> hold.</p>
<p id="id32.id2" class="ltx_p">In this survey paper, we provide a comprehensive literature review of the different privacy attacks and defense methods in FL. We identify the current limitations of these attacks and highlight the settings in which FL client privacy can be broken.
We dissect some of the successful industry applications of FL and draw lessons for future successful adoption. We survey the emerging landscape of privacy regulation for FL. We conclude with future directions for taking FL toward the cherished goal of generating accurate models while preserving the privacy of the data from its participants.</p>
</div>
<div class="ltx_keywords">Distributed machine learning, Federated learning, Privacy in federated learning, Application domains for federated learning, Privacy policies
</div>
<div class="ltx_acknowledgements">*Other than the first two authors, all other authors are listed alphabetically. Corresponding author: Saurabh Bagchi.
</div>
<span id="id1" class="ltx_note ltx_note_frontmatter ltx_role_copyright"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">copyright: </span>acmcopyright</span></span></span><span id="id2" class="ltx_note ltx_note_frontmatter ltx_role_journalyear"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">journalyear: </span>2024</span></span></span><span id="id3" class="ltx_note ltx_note_frontmatter ltx_role_doi"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">doi: </span>XXXXXXX.XXXXXXX</span></span></span><span id="id4" class="ltx_note ltx_note_frontmatter ltx_role_journal"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">journal: </span>CSUR</span></span></span><span id="id5" class="ltx_note ltx_note_frontmatter ltx_role_journalvolume"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">journalvolume: </span>37</span></span></span><span id="id6" class="ltx_note ltx_note_frontmatter ltx_role_journalnumber"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">journalnumber: </span>4</span></span></span><span id="id7" class="ltx_note ltx_note_frontmatter ltx_role_article"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">article: </span>111</span></span></span><span id="id8" class="ltx_note ltx_note_frontmatter ltx_role_publicationmonth"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">publicationmonth: </span>8</span></span></span><span id="id9" class="ltx_note ltx_note_frontmatter ltx_role_price"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">price: </span>15.00</span></span></span><span id="id10" class="ltx_note ltx_note_frontmatter ltx_role_isbn"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">isbn: </span>978-1-4503-XXXX-X/18/06</span></span></span><span id="id11" class="ltx_note ltx_note_frontmatter ltx_role_ccs"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">ccs: </span>Security and privacy   Human and societal aspects of security and privacy, Systems security</span></span></span><span id="id12" class="ltx_note ltx_note_frontmatter ltx_role_ccs"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">ccs: </span>Computing methodologies   Machine learning</span></span></span>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1. </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Federated Learning (FL) is a widely popular learning architecture that allows one to learn a Machine Learning (ML) model collaboratively. The classical structure of FL is that there are multiple clients each with their own local data, which they would possibly like to keep private, and there is a server that is responsible for learning a global ML model.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">One of the two primary reasons for the popularity of FL is that clients can keep their data private and still benefit from the combined learning across all of their data. (The second reason is the “power of crowds”, i.e., many weak devices can come together to learn complex models, which would be beyond the compute power of any one client to learn on its own.) However, by 2018, this hope of FL had been effectively dashed. It was shown in a set of seminal papers that if the central aggregator has access to gradients sent by the clients (which it does in most versions of FL), then the aggregator can learn various things from these clients, each of which would be taken to effectively break the privacy of client data. <cite class="ltx_cite ltx_citemacro_citep">(Zhu et al<span class="ltx_text">.</span>, <a href="#bib.bib151" title="" class="ltx_ref">2019</a>; Zhao et al<span class="ltx_text">.</span>, <a href="#bib.bib146" title="" class="ltx_ref">2020</a>; Melis et al<span class="ltx_text">.</span>, <a href="#bib.bib92" title="" class="ltx_ref">2019</a>)</cite>
The simplest to understand form of this attack is that the aggregator can reconstruct the data of the clients from the gradient updates, to different degrees of fidelity. The attacker, the central aggregator here, has the unique advantage that it can observe the individual updates from the clients over time and can control the view of the participants of the global parameters. Also worryingly, the attacker could be one of the clients who can observe the global parameter updates, and can control his parameter uploads.
</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">In this article, we survey the constant back and forth that has been going on for the last 5 years or so in protecting the privacy of data through FL. We will have as one of the primary focus questions: what are the research challenges that need to be solved to achieve “good enough” protection for different application use cases. Our article takes a distinctive viewpoint of grounding the technical discussion of the attacks and the defenses in application use cases. For example, the kind of privacy expectation, and regulation, in the healthcare sector is very different from that in the finance or insurance sector, which again is distinct from that in Internet of Things (IoT).</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">We provide a categorization of the attacks against privacy in FL (Section <a href="#S6" title="6. Privacy Attacks ‣ Federated Learning Privacy: Attacks, Defenses, Applications, and Policy Landscape — A Survey" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>) and also a categorization of the defenses (Section <a href="#S7" title="7. Privacy Defenses ‣ Federated Learning Privacy: Attacks, Defenses, Applications, and Policy Landscape — A Survey" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>). A coupled dimension is the kind of FL that is happening — cross-device vs. cross-silo, horizontal FL vs. vertical FL, or derivatives of classical FL, such as, peer-to-peer learning or hierarchical FL. The discussion of attacks and defenses is meaningful only when we provide the context of what the threat model is, <span id="S1.p4.1.1" class="ltx_text ltx_font_italic">i.e.</span>, what are the capabilities available to the adversaries and to the defenders, what aspect of the learning process is attacked (model, data, or something else), and what is the proportion of benign vs. adversarial entities. We provide this kind of foundation-setting discussion in Section <a href="#S2" title="2. Problem Context ‣ Federated Learning Privacy: Attacks, Defenses, Applications, and Policy Landscape — A Survey" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
<div id="S1.p5" class="ltx_para ltx_noindent">
<p id="S1.p5.1" class="ltx_p"><span id="S1.p5.1.1" class="ltx_text ltx_font_italic">Policy considerations.</span>
Our article goes beyond the technology landscape and also surveys the policy landscape (Section <a href="#S5" title="5. Privacy-Related Policies ‣ Federated Learning Privacy: Attacks, Defenses, Applications, and Policy Landscape — A Survey" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>), which is nascent and developing. A central consideration of ML regulation, namely, regulation of the data, is central to FL since here we deal with data that is local, and possibly sensitive, to individual clients. Regulation of FL is therefore apt and a start needs to be made soon. We hope that this discussion of regulation, in the context of the technical achievements to date and the expected deliverables, will lead us to enlightened regulation in the space of privacy in FL.</p>
</div>
<div id="S1.p6" class="ltx_para ltx_noindent">
<p id="S1.p6.1" class="ltx_p"><span id="S1.p6.1.1" class="ltx_text ltx_font_italic">Privacy pushes-and-pulls.</span>
Given that being a privacy-preserving technology was a core reason for its introduction, it is vital that FL is indeed able to preserve the privacy of users. Despite this, the process of sending gradient or model updates to a server has been shown to be less than secure. Recent works in membership inference, property inference, and even data reconstruction have demonstrated that vanilla FL is vulnerable to a multitude of privacy attacks. On the other hand, defenses such as secure aggregation, differential privacy, or homomorphic encryption have also continued to be developed to prevent these attacks. Ultimately, the privacy expectation of FL is that an attacker, whether being the server, an outsider, or a participating client, is not able to infer any private information about the local training data of any of the clients. In this work, we discuss the current privacy attacks and pinpoint the vulnerabilities that make them possible. We then highlight the defenses that can prevent the attacks or make them more difficult along with the limitations and drawbacks of each.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2. </span>Problem Context</h2>

<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1. </span>Federated learning process</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">FL has emerged as a decentralized training framework that addresses the dual challenges of leveraging computational resources at the network’s edge and preserving data privacy. Central to FL is its unique approach to collaborative model training, which aggregates model updates from participating clients rather than transmitting the raw data of the clients. This method not only leverages the vast computational power distributed across edge devices but also aligns with the increasing demands for data privacy amidst the exponential growth and insatiable appetite for data of modern AI systems.
At the heart of FL’s philosophy is the distributed training of machine learning models, where the crux is the <span id="S2.SS1.p1.1.1" class="ltx_text ltx_font_italic">exchange of model updates</span> with a central server, sidestepping the need to share sensitive training data.</p>
</div>
<div id="S2.SS1.p2" class="ltx_para">
<p id="S2.SS1.p2.1" class="ltx_p">The vanilla FL training process typically involves the coordinated interplay of two principal actors: the central server and the participating clients. The central server orchestrates the workflow by selecting the clients, dispatching the global model to the participating clients for local refinement, and then aggregating the updates before finally updating the global model. Conversely, clients engage in a straightforward yet crucial role. They receive the global model from the server, apply training updates using their local datasets, and then transmit these training updates back to the server.</p>
</div>
<div id="S2.SS1.p3" class="ltx_para">
<p id="S2.SS1.p3.1" class="ltx_p">For a single FL training cycle, the operations unfold as follows:</p>
<ol id="S2.I1" class="ltx_enumerate">
<li id="S2.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(1)</span> 
<div id="S2.I1.i1.p1" class="ltx_para">
<p id="S2.I1.i1.p1.3" class="ltx_p"><span id="S2.I1.i1.p1.3.1" class="ltx_text ltx_font_bold">Client Selection and Model Dispatch</span>: The central server selects a subset of <math id="S2.I1.i1.p1.1.m1.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S2.I1.i1.p1.1.m1.1a"><mi id="S2.I1.i1.p1.1.m1.1.1" xref="S2.I1.i1.p1.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S2.I1.i1.p1.1.m1.1b"><ci id="S2.I1.i1.p1.1.m1.1.1.cmml" xref="S2.I1.i1.p1.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i1.p1.1.m1.1c">k</annotation></semantics></math> out of <math id="S2.I1.i1.p1.2.m2.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S2.I1.i1.p1.2.m2.1a"><mi id="S2.I1.i1.p1.2.m2.1.1" xref="S2.I1.i1.p1.2.m2.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S2.I1.i1.p1.2.m2.1b"><ci id="S2.I1.i1.p1.2.m2.1.1.cmml" xref="S2.I1.i1.p1.2.m2.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i1.p1.2.m2.1c">N</annotation></semantics></math> available clients, dispatching the current global model parameters, <math id="S2.I1.i1.p1.3.m3.1" class="ltx_Math" alttext="G_{t}" display="inline"><semantics id="S2.I1.i1.p1.3.m3.1a"><msub id="S2.I1.i1.p1.3.m3.1.1" xref="S2.I1.i1.p1.3.m3.1.1.cmml"><mi id="S2.I1.i1.p1.3.m3.1.1.2" xref="S2.I1.i1.p1.3.m3.1.1.2.cmml">G</mi><mi id="S2.I1.i1.p1.3.m3.1.1.3" xref="S2.I1.i1.p1.3.m3.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S2.I1.i1.p1.3.m3.1b"><apply id="S2.I1.i1.p1.3.m3.1.1.cmml" xref="S2.I1.i1.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S2.I1.i1.p1.3.m3.1.1.1.cmml" xref="S2.I1.i1.p1.3.m3.1.1">subscript</csymbol><ci id="S2.I1.i1.p1.3.m3.1.1.2.cmml" xref="S2.I1.i1.p1.3.m3.1.1.2">𝐺</ci><ci id="S2.I1.i1.p1.3.m3.1.1.3.cmml" xref="S2.I1.i1.p1.3.m3.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i1.p1.3.m3.1c">G_{t}</annotation></semantics></math>, to them. The selection count varies based on the FL scenario:</p>
<ul id="S2.I1.i1.I1" class="ltx_itemize">
<li id="S2.I1.i1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i1.I1.i1.p1" class="ltx_para">
<p id="S2.I1.i1.I1.i1.p1.2" class="ltx_p">In <span id="S2.I1.i1.I1.i1.p1.2.1" class="ltx_text ltx_font_italic">cross-device FL</span>, typically involving lightweight devices like smartphones or IoT devices, the selection ranges from <math id="S2.I1.i1.I1.i1.p1.1.m1.1" class="ltx_Math" alttext="100" display="inline"><semantics id="S2.I1.i1.I1.i1.p1.1.m1.1a"><mn id="S2.I1.i1.I1.i1.p1.1.m1.1.1" xref="S2.I1.i1.I1.i1.p1.1.m1.1.1.cmml">100</mn><annotation-xml encoding="MathML-Content" id="S2.I1.i1.I1.i1.p1.1.m1.1b"><cn type="integer" id="S2.I1.i1.I1.i1.p1.1.m1.1.1.cmml" xref="S2.I1.i1.I1.i1.p1.1.m1.1.1">100</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i1.I1.i1.p1.1.m1.1c">100</annotation></semantics></math> to <math id="S2.I1.i1.I1.i1.p1.2.m2.1" class="ltx_Math" alttext="1000" display="inline"><semantics id="S2.I1.i1.I1.i1.p1.2.m2.1a"><mn id="S2.I1.i1.I1.i1.p1.2.m2.1.1" xref="S2.I1.i1.I1.i1.p1.2.m2.1.1.cmml">1000</mn><annotation-xml encoding="MathML-Content" id="S2.I1.i1.I1.i1.p1.2.m2.1b"><cn type="integer" id="S2.I1.i1.I1.i1.p1.2.m2.1.1.cmml" xref="S2.I1.i1.I1.i1.p1.2.m2.1.1">1000</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i1.I1.i1.p1.2.m2.1c">1000</annotation></semantics></math>. This broad participation mitigates network unreliability and device dropouts, ensuring diverse data representation.</p>
</div>
</li>
<li id="S2.I1.i1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i1.I1.i2.p1" class="ltx_para">
<p id="S2.I1.i1.I1.i2.p1.2" class="ltx_p">In <span id="S2.I1.i1.I1.i2.p1.2.1" class="ltx_text ltx_font_italic">cross-silo FL</span>, involving entities like data centers or hospitals, a tighter group of <math id="S2.I1.i1.I1.i2.p1.1.m1.1" class="ltx_Math" alttext="5" display="inline"><semantics id="S2.I1.i1.I1.i2.p1.1.m1.1a"><mn id="S2.I1.i1.I1.i2.p1.1.m1.1.1" xref="S2.I1.i1.I1.i2.p1.1.m1.1.1.cmml">5</mn><annotation-xml encoding="MathML-Content" id="S2.I1.i1.I1.i2.p1.1.m1.1b"><cn type="integer" id="S2.I1.i1.I1.i2.p1.1.m1.1.1.cmml" xref="S2.I1.i1.I1.i2.p1.1.m1.1.1">5</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i1.I1.i2.p1.1.m1.1c">5</annotation></semantics></math>–<math id="S2.I1.i1.I1.i2.p1.2.m2.1" class="ltx_Math" alttext="10" display="inline"><semantics id="S2.I1.i1.I1.i2.p1.2.m2.1a"><mn id="S2.I1.i1.I1.i2.p1.2.m2.1.1" xref="S2.I1.i1.I1.i2.p1.2.m2.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="S2.I1.i1.I1.i2.p1.2.m2.1b"><cn type="integer" id="S2.I1.i1.I1.i2.p1.2.m2.1.1.cmml" xref="S2.I1.i1.I1.i2.p1.2.m2.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i1.I1.i2.p1.2.m2.1c">10</annotation></semantics></math> clients is chosen, reflecting the higher trust, collaboration levels, and substantial computational resources of these participants.</p>
</div>
</li>
</ul>
</div>
</li>
<li id="S2.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(2)</span> 
<div id="S2.I1.i2.p1" class="ltx_para">
<p id="S2.I1.i2.p1.2" class="ltx_p"><span id="S2.I1.i2.p1.2.1" class="ltx_text ltx_font_bold">Local Training and Update Generation</span>: Participating clients refine the global model <math id="S2.I1.i2.p1.1.m1.1" class="ltx_Math" alttext="G_{t}" display="inline"><semantics id="S2.I1.i2.p1.1.m1.1a"><msub id="S2.I1.i2.p1.1.m1.1.1" xref="S2.I1.i2.p1.1.m1.1.1.cmml"><mi id="S2.I1.i2.p1.1.m1.1.1.2" xref="S2.I1.i2.p1.1.m1.1.1.2.cmml">G</mi><mi id="S2.I1.i2.p1.1.m1.1.1.3" xref="S2.I1.i2.p1.1.m1.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S2.I1.i2.p1.1.m1.1b"><apply id="S2.I1.i2.p1.1.m1.1.1.cmml" xref="S2.I1.i2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S2.I1.i2.p1.1.m1.1.1.1.cmml" xref="S2.I1.i2.p1.1.m1.1.1">subscript</csymbol><ci id="S2.I1.i2.p1.1.m1.1.1.2.cmml" xref="S2.I1.i2.p1.1.m1.1.1.2">𝐺</ci><ci id="S2.I1.i2.p1.1.m1.1.1.3.cmml" xref="S2.I1.i2.p1.1.m1.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i2.p1.1.m1.1c">G_{t}</annotation></semantics></math> using their local data across one or more iterations. This process yields updates, either as computed gradients, <math id="S2.I1.i2.p1.2.m2.2" class="ltx_Math" alttext="\nabla G_{t,i}" display="inline"><semantics id="S2.I1.i2.p1.2.m2.2a"><mrow id="S2.I1.i2.p1.2.m2.2.3" xref="S2.I1.i2.p1.2.m2.2.3.cmml"><mo rspace="0.167em" id="S2.I1.i2.p1.2.m2.2.3.1" xref="S2.I1.i2.p1.2.m2.2.3.1.cmml">∇</mo><msub id="S2.I1.i2.p1.2.m2.2.3.2" xref="S2.I1.i2.p1.2.m2.2.3.2.cmml"><mi id="S2.I1.i2.p1.2.m2.2.3.2.2" xref="S2.I1.i2.p1.2.m2.2.3.2.2.cmml">G</mi><mrow id="S2.I1.i2.p1.2.m2.2.2.2.4" xref="S2.I1.i2.p1.2.m2.2.2.2.3.cmml"><mi id="S2.I1.i2.p1.2.m2.1.1.1.1" xref="S2.I1.i2.p1.2.m2.1.1.1.1.cmml">t</mi><mo id="S2.I1.i2.p1.2.m2.2.2.2.4.1" xref="S2.I1.i2.p1.2.m2.2.2.2.3.cmml">,</mo><mi id="S2.I1.i2.p1.2.m2.2.2.2.2" xref="S2.I1.i2.p1.2.m2.2.2.2.2.cmml">i</mi></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="S2.I1.i2.p1.2.m2.2b"><apply id="S2.I1.i2.p1.2.m2.2.3.cmml" xref="S2.I1.i2.p1.2.m2.2.3"><ci id="S2.I1.i2.p1.2.m2.2.3.1.cmml" xref="S2.I1.i2.p1.2.m2.2.3.1">∇</ci><apply id="S2.I1.i2.p1.2.m2.2.3.2.cmml" xref="S2.I1.i2.p1.2.m2.2.3.2"><csymbol cd="ambiguous" id="S2.I1.i2.p1.2.m2.2.3.2.1.cmml" xref="S2.I1.i2.p1.2.m2.2.3.2">subscript</csymbol><ci id="S2.I1.i2.p1.2.m2.2.3.2.2.cmml" xref="S2.I1.i2.p1.2.m2.2.3.2.2">𝐺</ci><list id="S2.I1.i2.p1.2.m2.2.2.2.3.cmml" xref="S2.I1.i2.p1.2.m2.2.2.2.4"><ci id="S2.I1.i2.p1.2.m2.1.1.1.1.cmml" xref="S2.I1.i2.p1.2.m2.1.1.1.1">𝑡</ci><ci id="S2.I1.i2.p1.2.m2.2.2.2.2.cmml" xref="S2.I1.i2.p1.2.m2.2.2.2.2">𝑖</ci></list></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i2.p1.2.m2.2c">\nabla G_{t,i}</annotation></semantics></math>, or direct model parameter modifications, which are then sent back to the central server.</p>
</div>
</li>
<li id="S2.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(3)</span> 
<div id="S2.I1.i3.p1" class="ltx_para">
<p id="S2.I1.i3.p1.1" class="ltx_p"><span id="S2.I1.i3.p1.1.1" class="ltx_text ltx_font_bold">Aggregation and Global Model Update</span>: The server aggregates these client updates using methods like mean or weighted mean to form the new global model parameters, <math id="S2.I1.i3.p1.1.m1.3" class="ltx_Math" alttext="G_{t+1}=G_{t}+\sum_{i=1}^{k}(w_{i}\cdot\nabla G_{t,i})" display="inline"><semantics id="S2.I1.i3.p1.1.m1.3a"><mrow id="S2.I1.i3.p1.1.m1.3.3" xref="S2.I1.i3.p1.1.m1.3.3.cmml"><msub id="S2.I1.i3.p1.1.m1.3.3.3" xref="S2.I1.i3.p1.1.m1.3.3.3.cmml"><mi id="S2.I1.i3.p1.1.m1.3.3.3.2" xref="S2.I1.i3.p1.1.m1.3.3.3.2.cmml">G</mi><mrow id="S2.I1.i3.p1.1.m1.3.3.3.3" xref="S2.I1.i3.p1.1.m1.3.3.3.3.cmml"><mi id="S2.I1.i3.p1.1.m1.3.3.3.3.2" xref="S2.I1.i3.p1.1.m1.3.3.3.3.2.cmml">t</mi><mo id="S2.I1.i3.p1.1.m1.3.3.3.3.1" xref="S2.I1.i3.p1.1.m1.3.3.3.3.1.cmml">+</mo><mn id="S2.I1.i3.p1.1.m1.3.3.3.3.3" xref="S2.I1.i3.p1.1.m1.3.3.3.3.3.cmml">1</mn></mrow></msub><mo id="S2.I1.i3.p1.1.m1.3.3.2" xref="S2.I1.i3.p1.1.m1.3.3.2.cmml">=</mo><mrow id="S2.I1.i3.p1.1.m1.3.3.1" xref="S2.I1.i3.p1.1.m1.3.3.1.cmml"><msub id="S2.I1.i3.p1.1.m1.3.3.1.3" xref="S2.I1.i3.p1.1.m1.3.3.1.3.cmml"><mi id="S2.I1.i3.p1.1.m1.3.3.1.3.2" xref="S2.I1.i3.p1.1.m1.3.3.1.3.2.cmml">G</mi><mi id="S2.I1.i3.p1.1.m1.3.3.1.3.3" xref="S2.I1.i3.p1.1.m1.3.3.1.3.3.cmml">t</mi></msub><mo rspace="0.055em" id="S2.I1.i3.p1.1.m1.3.3.1.2" xref="S2.I1.i3.p1.1.m1.3.3.1.2.cmml">+</mo><mrow id="S2.I1.i3.p1.1.m1.3.3.1.1" xref="S2.I1.i3.p1.1.m1.3.3.1.1.cmml"><msubsup id="S2.I1.i3.p1.1.m1.3.3.1.1.2" xref="S2.I1.i3.p1.1.m1.3.3.1.1.2.cmml"><mo rspace="0em" id="S2.I1.i3.p1.1.m1.3.3.1.1.2.2.2" xref="S2.I1.i3.p1.1.m1.3.3.1.1.2.2.2.cmml">∑</mo><mrow id="S2.I1.i3.p1.1.m1.3.3.1.1.2.2.3" xref="S2.I1.i3.p1.1.m1.3.3.1.1.2.2.3.cmml"><mi id="S2.I1.i3.p1.1.m1.3.3.1.1.2.2.3.2" xref="S2.I1.i3.p1.1.m1.3.3.1.1.2.2.3.2.cmml">i</mi><mo id="S2.I1.i3.p1.1.m1.3.3.1.1.2.2.3.1" xref="S2.I1.i3.p1.1.m1.3.3.1.1.2.2.3.1.cmml">=</mo><mn id="S2.I1.i3.p1.1.m1.3.3.1.1.2.2.3.3" xref="S2.I1.i3.p1.1.m1.3.3.1.1.2.2.3.3.cmml">1</mn></mrow><mi id="S2.I1.i3.p1.1.m1.3.3.1.1.2.3" xref="S2.I1.i3.p1.1.m1.3.3.1.1.2.3.cmml">k</mi></msubsup><mrow id="S2.I1.i3.p1.1.m1.3.3.1.1.1.1" xref="S2.I1.i3.p1.1.m1.3.3.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.I1.i3.p1.1.m1.3.3.1.1.1.1.2" xref="S2.I1.i3.p1.1.m1.3.3.1.1.1.1.1.cmml">(</mo><mrow id="S2.I1.i3.p1.1.m1.3.3.1.1.1.1.1" xref="S2.I1.i3.p1.1.m1.3.3.1.1.1.1.1.cmml"><msub id="S2.I1.i3.p1.1.m1.3.3.1.1.1.1.1.2" xref="S2.I1.i3.p1.1.m1.3.3.1.1.1.1.1.2.cmml"><mi id="S2.I1.i3.p1.1.m1.3.3.1.1.1.1.1.2.2" xref="S2.I1.i3.p1.1.m1.3.3.1.1.1.1.1.2.2.cmml">w</mi><mi id="S2.I1.i3.p1.1.m1.3.3.1.1.1.1.1.2.3" xref="S2.I1.i3.p1.1.m1.3.3.1.1.1.1.1.2.3.cmml">i</mi></msub><mo lspace="0.222em" rspace="0.222em" id="S2.I1.i3.p1.1.m1.3.3.1.1.1.1.1.1" xref="S2.I1.i3.p1.1.m1.3.3.1.1.1.1.1.1.cmml">⋅</mo><mrow id="S2.I1.i3.p1.1.m1.3.3.1.1.1.1.1.3" xref="S2.I1.i3.p1.1.m1.3.3.1.1.1.1.1.3.cmml"><mo rspace="0.167em" id="S2.I1.i3.p1.1.m1.3.3.1.1.1.1.1.3.1" xref="S2.I1.i3.p1.1.m1.3.3.1.1.1.1.1.3.1.cmml">∇</mo><msub id="S2.I1.i3.p1.1.m1.3.3.1.1.1.1.1.3.2" xref="S2.I1.i3.p1.1.m1.3.3.1.1.1.1.1.3.2.cmml"><mi id="S2.I1.i3.p1.1.m1.3.3.1.1.1.1.1.3.2.2" xref="S2.I1.i3.p1.1.m1.3.3.1.1.1.1.1.3.2.2.cmml">G</mi><mrow id="S2.I1.i3.p1.1.m1.2.2.2.4" xref="S2.I1.i3.p1.1.m1.2.2.2.3.cmml"><mi id="S2.I1.i3.p1.1.m1.1.1.1.1" xref="S2.I1.i3.p1.1.m1.1.1.1.1.cmml">t</mi><mo id="S2.I1.i3.p1.1.m1.2.2.2.4.1" xref="S2.I1.i3.p1.1.m1.2.2.2.3.cmml">,</mo><mi id="S2.I1.i3.p1.1.m1.2.2.2.2" xref="S2.I1.i3.p1.1.m1.2.2.2.2.cmml">i</mi></mrow></msub></mrow></mrow><mo stretchy="false" id="S2.I1.i3.p1.1.m1.3.3.1.1.1.1.3" xref="S2.I1.i3.p1.1.m1.3.3.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.I1.i3.p1.1.m1.3b"><apply id="S2.I1.i3.p1.1.m1.3.3.cmml" xref="S2.I1.i3.p1.1.m1.3.3"><eq id="S2.I1.i3.p1.1.m1.3.3.2.cmml" xref="S2.I1.i3.p1.1.m1.3.3.2"></eq><apply id="S2.I1.i3.p1.1.m1.3.3.3.cmml" xref="S2.I1.i3.p1.1.m1.3.3.3"><csymbol cd="ambiguous" id="S2.I1.i3.p1.1.m1.3.3.3.1.cmml" xref="S2.I1.i3.p1.1.m1.3.3.3">subscript</csymbol><ci id="S2.I1.i3.p1.1.m1.3.3.3.2.cmml" xref="S2.I1.i3.p1.1.m1.3.3.3.2">𝐺</ci><apply id="S2.I1.i3.p1.1.m1.3.3.3.3.cmml" xref="S2.I1.i3.p1.1.m1.3.3.3.3"><plus id="S2.I1.i3.p1.1.m1.3.3.3.3.1.cmml" xref="S2.I1.i3.p1.1.m1.3.3.3.3.1"></plus><ci id="S2.I1.i3.p1.1.m1.3.3.3.3.2.cmml" xref="S2.I1.i3.p1.1.m1.3.3.3.3.2">𝑡</ci><cn type="integer" id="S2.I1.i3.p1.1.m1.3.3.3.3.3.cmml" xref="S2.I1.i3.p1.1.m1.3.3.3.3.3">1</cn></apply></apply><apply id="S2.I1.i3.p1.1.m1.3.3.1.cmml" xref="S2.I1.i3.p1.1.m1.3.3.1"><plus id="S2.I1.i3.p1.1.m1.3.3.1.2.cmml" xref="S2.I1.i3.p1.1.m1.3.3.1.2"></plus><apply id="S2.I1.i3.p1.1.m1.3.3.1.3.cmml" xref="S2.I1.i3.p1.1.m1.3.3.1.3"><csymbol cd="ambiguous" id="S2.I1.i3.p1.1.m1.3.3.1.3.1.cmml" xref="S2.I1.i3.p1.1.m1.3.3.1.3">subscript</csymbol><ci id="S2.I1.i3.p1.1.m1.3.3.1.3.2.cmml" xref="S2.I1.i3.p1.1.m1.3.3.1.3.2">𝐺</ci><ci id="S2.I1.i3.p1.1.m1.3.3.1.3.3.cmml" xref="S2.I1.i3.p1.1.m1.3.3.1.3.3">𝑡</ci></apply><apply id="S2.I1.i3.p1.1.m1.3.3.1.1.cmml" xref="S2.I1.i3.p1.1.m1.3.3.1.1"><apply id="S2.I1.i3.p1.1.m1.3.3.1.1.2.cmml" xref="S2.I1.i3.p1.1.m1.3.3.1.1.2"><csymbol cd="ambiguous" id="S2.I1.i3.p1.1.m1.3.3.1.1.2.1.cmml" xref="S2.I1.i3.p1.1.m1.3.3.1.1.2">superscript</csymbol><apply id="S2.I1.i3.p1.1.m1.3.3.1.1.2.2.cmml" xref="S2.I1.i3.p1.1.m1.3.3.1.1.2"><csymbol cd="ambiguous" id="S2.I1.i3.p1.1.m1.3.3.1.1.2.2.1.cmml" xref="S2.I1.i3.p1.1.m1.3.3.1.1.2">subscript</csymbol><sum id="S2.I1.i3.p1.1.m1.3.3.1.1.2.2.2.cmml" xref="S2.I1.i3.p1.1.m1.3.3.1.1.2.2.2"></sum><apply id="S2.I1.i3.p1.1.m1.3.3.1.1.2.2.3.cmml" xref="S2.I1.i3.p1.1.m1.3.3.1.1.2.2.3"><eq id="S2.I1.i3.p1.1.m1.3.3.1.1.2.2.3.1.cmml" xref="S2.I1.i3.p1.1.m1.3.3.1.1.2.2.3.1"></eq><ci id="S2.I1.i3.p1.1.m1.3.3.1.1.2.2.3.2.cmml" xref="S2.I1.i3.p1.1.m1.3.3.1.1.2.2.3.2">𝑖</ci><cn type="integer" id="S2.I1.i3.p1.1.m1.3.3.1.1.2.2.3.3.cmml" xref="S2.I1.i3.p1.1.m1.3.3.1.1.2.2.3.3">1</cn></apply></apply><ci id="S2.I1.i3.p1.1.m1.3.3.1.1.2.3.cmml" xref="S2.I1.i3.p1.1.m1.3.3.1.1.2.3">𝑘</ci></apply><apply id="S2.I1.i3.p1.1.m1.3.3.1.1.1.1.1.cmml" xref="S2.I1.i3.p1.1.m1.3.3.1.1.1.1"><ci id="S2.I1.i3.p1.1.m1.3.3.1.1.1.1.1.1.cmml" xref="S2.I1.i3.p1.1.m1.3.3.1.1.1.1.1.1">⋅</ci><apply id="S2.I1.i3.p1.1.m1.3.3.1.1.1.1.1.2.cmml" xref="S2.I1.i3.p1.1.m1.3.3.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.I1.i3.p1.1.m1.3.3.1.1.1.1.1.2.1.cmml" xref="S2.I1.i3.p1.1.m1.3.3.1.1.1.1.1.2">subscript</csymbol><ci id="S2.I1.i3.p1.1.m1.3.3.1.1.1.1.1.2.2.cmml" xref="S2.I1.i3.p1.1.m1.3.3.1.1.1.1.1.2.2">𝑤</ci><ci id="S2.I1.i3.p1.1.m1.3.3.1.1.1.1.1.2.3.cmml" xref="S2.I1.i3.p1.1.m1.3.3.1.1.1.1.1.2.3">𝑖</ci></apply><apply id="S2.I1.i3.p1.1.m1.3.3.1.1.1.1.1.3.cmml" xref="S2.I1.i3.p1.1.m1.3.3.1.1.1.1.1.3"><ci id="S2.I1.i3.p1.1.m1.3.3.1.1.1.1.1.3.1.cmml" xref="S2.I1.i3.p1.1.m1.3.3.1.1.1.1.1.3.1">∇</ci><apply id="S2.I1.i3.p1.1.m1.3.3.1.1.1.1.1.3.2.cmml" xref="S2.I1.i3.p1.1.m1.3.3.1.1.1.1.1.3.2"><csymbol cd="ambiguous" id="S2.I1.i3.p1.1.m1.3.3.1.1.1.1.1.3.2.1.cmml" xref="S2.I1.i3.p1.1.m1.3.3.1.1.1.1.1.3.2">subscript</csymbol><ci id="S2.I1.i3.p1.1.m1.3.3.1.1.1.1.1.3.2.2.cmml" xref="S2.I1.i3.p1.1.m1.3.3.1.1.1.1.1.3.2.2">𝐺</ci><list id="S2.I1.i3.p1.1.m1.2.2.2.3.cmml" xref="S2.I1.i3.p1.1.m1.2.2.2.4"><ci id="S2.I1.i3.p1.1.m1.1.1.1.1.cmml" xref="S2.I1.i3.p1.1.m1.1.1.1.1">𝑡</ci><ci id="S2.I1.i3.p1.1.m1.2.2.2.2.cmml" xref="S2.I1.i3.p1.1.m1.2.2.2.2">𝑖</ci></list></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i3.p1.1.m1.3c">G_{t+1}=G_{t}+\sum_{i=1}^{k}(w_{i}\cdot\nabla G_{t,i})</annotation></semantics></math>. This prepares the model for the next distribution, refinement, and aggregation cycle.</p>
</div>
</li>
</ol>
<p id="S2.SS1.p3.2" class="ltx_p">This iterative process repeats until satisfactory model performance is reached, i.e., convergence is reached to a reasonable degree.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2. </span>Enhancing Federated Learning: Key Considerations for Operational Integrity and Security.</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">Several additional considerations come into play, ensuring the smooth and secure operation of this collaborative model training process. Here are some of the important considerations.
<br class="ltx_break"><span id="S2.SS2.p1.1.1" class="ltx_text ltx_font_bold">Client eligibility and selection:</span>
One of the initial steps in the FL cycle involves the selection of participating clients. In scenarios categorized under cross-device FL, where the participants are typically mobile or IoT devices, certain prerequisites must be met before a device is deemed eligible. These prerequisites often include having sufficient battery life to complete the training tasks without interruption and a stable network connection to facilitate seamless communication with the central server. These criteria are essential to prevent dropout or delays in the training process.
<br class="ltx_break"><span id="S2.SS2.p1.1.2" class="ltx_text ltx_font_bold">Security enhancement through encryption:</span>
Once selected and during the model refinement phase, enhancing security becomes paramount. To this end, clients may employ encryption techniques to the updates they generate. This encryption ensures that the gradients or model parameter modifications are securely transmitted to the central server, safeguarding the data against eavesdropping or tampering attempts. This layer of security is crucial in preserving the integrity of the data and the privacy of the clients’ information.
<br class="ltx_break"><span id="S2.SS2.p1.1.3" class="ltx_text ltx_font_bold">Robust aggregation by the central server:</span>
On the receiving end of this process, the central server plays a critical role in aggregating the updates from all participating clients. Given the potential for compromised devices or malicious actors within the network, the server might implement robust aggregation techniques. These techniques are designed to identify and neutralize the influence of any anomalous updates that could skew the model’s learning in an undesirable direction. By employing such strategies, the server ensures that the aggregated update accurately reflects the collective learning from all legitimate participants, thereby reinforcing the reliability and effectiveness of the FL process.</p>
</div>
<div id="S2.SS2.p2" class="ltx_para">
<p id="S2.SS2.p2.1" class="ltx_p">These considerations highlight the need for a multi-layered approach to address the practical challenges in deploying secure and private FL systems. There is often a tension between operational efficiency and the security/privacy achieved by the protocol.</p>
</div>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3. </span>Variants of Federated Learning</h3>

<section id="S2.SS3.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.3.1. </span>Cross-device and Cross-silo Federated Learning:</h4>

<div id="S2.SS3.SSS1.p1" class="ltx_para">
<p id="S2.SS3.SSS1.p1.1" class="ltx_p">FL can be broadly categorized into cross-device and cross-silo contexts, each presenting unique scalability and deployment challenges.
In cross-device FL, we envisage a vast network of personal devices, such as smartphones, wearables, or IoT devices, each participating in the learning process. This variant is marked by its massive scale, involving potentially <span id="S2.SS3.SSS1.p1.1.1" class="ltx_text ltx_font_italic">millions of devices</span>, each contributing data for model training. The finance sector, for example, could leverage cross-device FL to enhance fraud detection systems by learning from transactions across countless mobile banking apps without centralizing sensitive financial data. However, this approach is fraught with challenges, primarily due to the limited computational power and intermittent connectivity of devices, not to mention the heightened concerns over data privacy and security.
Conversely, cross-silo FL operates on a smaller scale with fewer, resource-ample entities like hospitals, featuring stable communications and higher computational resources. n healthcare, for instance, cross-silo FL enables hospitals to collaboratively improve diagnostic models by learning from diverse patient datasets while ensuring that sensitive medical records remain within hospital premises. Similarly, in finance, banks can utilize cross-silo FL to jointly develop more accurate credit scoring models without exposing their clients’ financial details to competitors. This form of FL, while offering more control and resources, still necessitates careful navigation of regulatory, privacy, and interoperability challenges.
FL showcases its adaptability and value across sectors through its two main variants: cross-device and cross-silo. In finance, cross-device FL can harness personal devices like smartphones to enhance fraud detection without centralizing sensitive data, balancing privacy with regulatory adherence despite challenges like limited device power and connectivity. Meanwhile, healthcare can benefit from cross-silo FL, where institutions like hospitals collaborate to improve diagnostics without sharing patient data, aligning with strict privacy laws and ethical standards. These approaches demonstrate FL’s capacity to meet sector-specific needs—offering scalable, privacy-preserving solutions in finance through cross-device models, and secure, collaborative advancements in healthcare via cross-silo frameworks. This duality not only underscores FL’s versatility in tackling regulatory and privacy challenges but also emphasizes its potential to drive innovation and security in sensitive domains.</p>
</div>
</section>
<section id="S2.SS3.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.3.2. </span>Federated transfer learning:</h4>

<div id="S2.SS3.SSS2.p1" class="ltx_para">
<p id="S2.SS3.SSS2.p1.1" class="ltx_p">Federated Transfer Learning (FTL) extends FL by facilitating knowledge sharing across different domains or tasks, aiming to enhance model performance where direct data sharing is infeasible. Unlike FL, which focuses on aggregating updates to refine a global model, FTL emphasizes transferring knowledge from a well-resourced source domain — rich in labeled data — to a target domain with limited labeled resources. This cross-domain learning is achieved by sharing model parameters or learned features instead of raw data, thus inherently supporting privacy by keeping the data localized while only model information traverses domains.</p>
</div>
<div id="S2.SS3.SSS2.p2" class="ltx_para">
<p id="S2.SS3.SSS2.p2.1" class="ltx_p">The crux of FTL’s effectiveness lies in its domain adaptation strategies, where the challenge is to make a model trained in one domain perform well in another with distinct data distributions, feature spaces, and tasks. This process, inherently more complex than the simple update aggregation in FL, demands sophisticated communication for exchanging not just model updates but also domain-specific adaptations, leading to higher communication overhead. Moreover, FTL must navigate the delicate balance between privacy and utility. It leverages the privacy-preserving nature of FL by ensuring that sensitive data remains within its original domain, with additional measures like differential privacy further enhancing security. However, this focus on privacy necessitates careful handling to ensure that the transferred model knowledge does not inadvertently leak sensitive information.</p>
</div>
<div id="S2.SS3.SSS2.p3" class="ltx_para">
<p id="S2.SS3.SSS2.p3.1" class="ltx_p">FTL’s requirement for domain adaptation introduces significant communication overhead and computational complexity. The iterative process of model adaptation and fine-tuning across domains entails multiple rounds of communication, each adding to the logistical and computational demands of deploying FTL at scale. Despite these challenges, the potential of FTL to leverage cross-domain knowledge without compromising data privacy stands as a compelling advancement in distributed machine learning.</p>
</div>
<div id="S2.SS3.SSS2.p4" class="ltx_para">
<p id="S2.SS3.SSS2.p4.1" class="ltx_p">FTL is particularly useful in scenarios where data cannot be pooled together due to privacy concerns but where tasks across domains are related. For example, in healthcare, models trained on data from one hospital can be adapted to improve predictions in another hospital, despite differences in patient demographics or data collection practices. Similarly, in finance, knowledge from credit scoring models in one region can be transferred to enhance models in another region.</p>
</div>
</section>
<section id="S2.SS3.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.3.3. </span>Hierarchical Federated Learning</h4>

<div id="S2.SS3.SSS3.p1" class="ltx_para">
<p id="S2.SS3.SSS3.p1.1" class="ltx_p">Hierarchical Federated Learning (HFL) <cite class="ltx_cite ltx_citemacro_citep">(Abad et al<span class="ltx_text">.</span>, <a href="#bib.bib20" title="" class="ltx_ref">2020</a>; Feng et al<span class="ltx_text">.</span>, <a href="#bib.bib49" title="" class="ltx_ref">2021</a>; Liu et al<span class="ltx_text">.</span>, <a href="#bib.bib84" title="" class="ltx_ref">2020</a>; Briggs et al<span class="ltx_text">.</span>, <a href="#bib.bib26" title="" class="ltx_ref">2020</a>; Liu et al<span class="ltx_text">.</span>, <a href="#bib.bib85" title="" class="ltx_ref">2022b</a>)</cite> introduces a multi-tiered aggregation framework, significantly enhancing the scalability and efficiency of collaborative learning models. This system incorporates several levels of servers, from edge parameter servers to a final cloud parameter server, facilitating a more structured and efficient communication and aggregation pathway. By leveraging edge servers for initial aggregation <cite class="ltx_cite ltx_citemacro_citep">(Liu et al<span class="ltx_text">.</span>, <a href="#bib.bib84" title="" class="ltx_ref">2020</a>)</cite>, HFL mitigates the communication bottlenecks often encountered in traditional FL, enabling faster, more energy-efficient training processes. In response to the limitations observed in both FL and P2PL — where FL’s centralized model can pose privacy risks, and P2PL’s decentralized nature complicates integrity and consensus — HFL emerges as a powerful hybrid solution. It employs a hierarchical structure where clients, or “spokes,” communicate updates to edge servers, or “hubs,” which then aggregate these updates before further communication among themselves or with a higher-level server. This architecture not only reduces the privacy concerns associated with a single central server but also addresses the communication and consensus challenges inherent in a fully decentralized setup.</p>
</div>
</section>
<section id="S2.SS3.SSSx1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">Horizontal and Vertical Federated Learning</h4>

<div id="S2.SS3.SSSx1.p1" class="ltx_para">
<p id="S2.SS3.SSSx1.p1.1" class="ltx_p">In FL, data can be partitioned in two primary ways: horizontally or vertically. This distinction significantly impacts the learning process and the approach to privacy and efficiency in collaborative learning environments. Horizontal Federated Learning involves clients that have data sharing the <em id="S2.SS3.SSSx1.p1.1.1" class="ltx_emph ltx_font_italic">same feature space</em> but differ in the <em id="S2.SS3.SSSx1.p1.1.2" class="ltx_emph ltx_font_italic">samples</em> or <em id="S2.SS3.SSSx1.p1.1.3" class="ltx_emph ltx_font_italic">IDs</em>. This is common in scenarios where different entities collect similar types of data across various subjects.
<br class="ltx_break"><span id="S2.SS3.SSSx1.p1.1.4" class="ltx_text ltx_font_bold">Example:</span> Consider multiple hospitals collecting health data. Each hospital has its own set of patient data, with the feature space (types of health data) being consistent, but the actual data (patient records) varying.
Mathematically, this can be represented as:</p>
<table id="S2.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left"><span class="ltx_tag ltx_tag_equation ltx_align_left">(1)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E1.m1.1" class="ltx_Math" alttext="\text{Let }D_{i}\text{ and }D_{j}\text{ be datasets from hospitals }i\text{ and }j\text{ respectively, where}" display="block"><semantics id="S2.E1.m1.1a"><mrow id="S2.E1.m1.1.1" xref="S2.E1.m1.1.1.cmml"><mtext id="S2.E1.m1.1.1.2" xref="S2.E1.m1.1.1.2a.cmml">Let </mtext><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.1" xref="S2.E1.m1.1.1.1.cmml">​</mo><msub id="S2.E1.m1.1.1.3" xref="S2.E1.m1.1.1.3.cmml"><mi id="S2.E1.m1.1.1.3.2" xref="S2.E1.m1.1.1.3.2.cmml">D</mi><mi id="S2.E1.m1.1.1.3.3" xref="S2.E1.m1.1.1.3.3.cmml">i</mi></msub><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.1a" xref="S2.E1.m1.1.1.1.cmml">​</mo><mtext id="S2.E1.m1.1.1.4" xref="S2.E1.m1.1.1.4a.cmml"> and </mtext><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.1b" xref="S2.E1.m1.1.1.1.cmml">​</mo><msub id="S2.E1.m1.1.1.5" xref="S2.E1.m1.1.1.5.cmml"><mi id="S2.E1.m1.1.1.5.2" xref="S2.E1.m1.1.1.5.2.cmml">D</mi><mi id="S2.E1.m1.1.1.5.3" xref="S2.E1.m1.1.1.5.3.cmml">j</mi></msub><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.1c" xref="S2.E1.m1.1.1.1.cmml">​</mo><mtext id="S2.E1.m1.1.1.6" xref="S2.E1.m1.1.1.6a.cmml"> be datasets from hospitals </mtext><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.1d" xref="S2.E1.m1.1.1.1.cmml">​</mo><mi id="S2.E1.m1.1.1.7" xref="S2.E1.m1.1.1.7.cmml">i</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.1e" xref="S2.E1.m1.1.1.1.cmml">​</mo><mtext id="S2.E1.m1.1.1.8" xref="S2.E1.m1.1.1.8a.cmml"> and </mtext><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.1f" xref="S2.E1.m1.1.1.1.cmml">​</mo><mi id="S2.E1.m1.1.1.9" xref="S2.E1.m1.1.1.9.cmml">j</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.1g" xref="S2.E1.m1.1.1.1.cmml">​</mo><mtext id="S2.E1.m1.1.1.10" xref="S2.E1.m1.1.1.10a.cmml"> respectively, where</mtext></mrow><annotation-xml encoding="MathML-Content" id="S2.E1.m1.1b"><apply id="S2.E1.m1.1.1.cmml" xref="S2.E1.m1.1.1"><times id="S2.E1.m1.1.1.1.cmml" xref="S2.E1.m1.1.1.1"></times><ci id="S2.E1.m1.1.1.2a.cmml" xref="S2.E1.m1.1.1.2"><mtext id="S2.E1.m1.1.1.2.cmml" xref="S2.E1.m1.1.1.2">Let </mtext></ci><apply id="S2.E1.m1.1.1.3.cmml" xref="S2.E1.m1.1.1.3"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.3.1.cmml" xref="S2.E1.m1.1.1.3">subscript</csymbol><ci id="S2.E1.m1.1.1.3.2.cmml" xref="S2.E1.m1.1.1.3.2">𝐷</ci><ci id="S2.E1.m1.1.1.3.3.cmml" xref="S2.E1.m1.1.1.3.3">𝑖</ci></apply><ci id="S2.E1.m1.1.1.4a.cmml" xref="S2.E1.m1.1.1.4"><mtext id="S2.E1.m1.1.1.4.cmml" xref="S2.E1.m1.1.1.4"> and </mtext></ci><apply id="S2.E1.m1.1.1.5.cmml" xref="S2.E1.m1.1.1.5"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.5.1.cmml" xref="S2.E1.m1.1.1.5">subscript</csymbol><ci id="S2.E1.m1.1.1.5.2.cmml" xref="S2.E1.m1.1.1.5.2">𝐷</ci><ci id="S2.E1.m1.1.1.5.3.cmml" xref="S2.E1.m1.1.1.5.3">𝑗</ci></apply><ci id="S2.E1.m1.1.1.6a.cmml" xref="S2.E1.m1.1.1.6"><mtext id="S2.E1.m1.1.1.6.cmml" xref="S2.E1.m1.1.1.6"> be datasets from hospitals </mtext></ci><ci id="S2.E1.m1.1.1.7.cmml" xref="S2.E1.m1.1.1.7">𝑖</ci><ci id="S2.E1.m1.1.1.8a.cmml" xref="S2.E1.m1.1.1.8"><mtext id="S2.E1.m1.1.1.8.cmml" xref="S2.E1.m1.1.1.8"> and </mtext></ci><ci id="S2.E1.m1.1.1.9.cmml" xref="S2.E1.m1.1.1.9">𝑗</ci><ci id="S2.E1.m1.1.1.10a.cmml" xref="S2.E1.m1.1.1.10"><mtext id="S2.E1.m1.1.1.10.cmml" xref="S2.E1.m1.1.1.10"> respectively, where</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E1.m1.1c">\text{Let }D_{i}\text{ and }D_{j}\text{ be datasets from hospitals }i\text{ and }j\text{ respectively, where}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<table id="S2.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left"><span class="ltx_tag ltx_tag_equation ltx_align_left">(2)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E2.m1.5" class="ltx_Math" alttext="D_{i},D_{j}\subseteq\mathcal{X}\times\mathcal{Y},\quad\text{and}\quad\mathcal{X}_{i}=\mathcal{X}_{j},\quad\text{but}\quad\mathcal{Y}_{i}\neq\mathcal{Y}_{j}" display="block"><semantics id="S2.E2.m1.5a"><mrow id="S2.E2.m1.5.5.3" xref="S2.E2.m1.5.5.4.cmml"><mrow id="S2.E2.m1.3.3.1.1" xref="S2.E2.m1.3.3.1.1.cmml"><mrow id="S2.E2.m1.3.3.1.1.2.2" xref="S2.E2.m1.3.3.1.1.2.3.cmml"><msub id="S2.E2.m1.3.3.1.1.1.1.1" xref="S2.E2.m1.3.3.1.1.1.1.1.cmml"><mi id="S2.E2.m1.3.3.1.1.1.1.1.2" xref="S2.E2.m1.3.3.1.1.1.1.1.2.cmml">D</mi><mi id="S2.E2.m1.3.3.1.1.1.1.1.3" xref="S2.E2.m1.3.3.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S2.E2.m1.3.3.1.1.2.2.3" xref="S2.E2.m1.3.3.1.1.2.3.cmml">,</mo><msub id="S2.E2.m1.3.3.1.1.2.2.2" xref="S2.E2.m1.3.3.1.1.2.2.2.cmml"><mi id="S2.E2.m1.3.3.1.1.2.2.2.2" xref="S2.E2.m1.3.3.1.1.2.2.2.2.cmml">D</mi><mi id="S2.E2.m1.3.3.1.1.2.2.2.3" xref="S2.E2.m1.3.3.1.1.2.2.2.3.cmml">j</mi></msub></mrow><mo id="S2.E2.m1.3.3.1.1.3" xref="S2.E2.m1.3.3.1.1.3.cmml">⊆</mo><mrow id="S2.E2.m1.3.3.1.1.4" xref="S2.E2.m1.3.3.1.1.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E2.m1.3.3.1.1.4.2" xref="S2.E2.m1.3.3.1.1.4.2.cmml">𝒳</mi><mo lspace="0.222em" rspace="0.222em" id="S2.E2.m1.3.3.1.1.4.1" xref="S2.E2.m1.3.3.1.1.4.1.cmml">×</mo><mi class="ltx_font_mathcaligraphic" id="S2.E2.m1.3.3.1.1.4.3" xref="S2.E2.m1.3.3.1.1.4.3.cmml">𝒴</mi></mrow></mrow><mo rspace="1.167em" id="S2.E2.m1.5.5.3.4" xref="S2.E2.m1.5.5.4a.cmml">,</mo><mrow id="S2.E2.m1.4.4.2.2" xref="S2.E2.m1.4.4.2.2.cmml"><mrow id="S2.E2.m1.4.4.2.2.1.1" xref="S2.E2.m1.4.4.2.2.1.2.cmml"><mtext id="S2.E2.m1.1.1" xref="S2.E2.m1.1.1a.cmml">and</mtext><mspace width="1em" id="S2.E2.m1.4.4.2.2.1.1.2" xref="S2.E2.m1.4.4.2.2.1.2.cmml"></mspace><msub id="S2.E2.m1.4.4.2.2.1.1.1" xref="S2.E2.m1.4.4.2.2.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E2.m1.4.4.2.2.1.1.1.2" xref="S2.E2.m1.4.4.2.2.1.1.1.2.cmml">𝒳</mi><mi id="S2.E2.m1.4.4.2.2.1.1.1.3" xref="S2.E2.m1.4.4.2.2.1.1.1.3.cmml">i</mi></msub></mrow><mo id="S2.E2.m1.4.4.2.2.2" xref="S2.E2.m1.4.4.2.2.2.cmml">=</mo><msub id="S2.E2.m1.4.4.2.2.3" xref="S2.E2.m1.4.4.2.2.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E2.m1.4.4.2.2.3.2" xref="S2.E2.m1.4.4.2.2.3.2.cmml">𝒳</mi><mi id="S2.E2.m1.4.4.2.2.3.3" xref="S2.E2.m1.4.4.2.2.3.3.cmml">j</mi></msub></mrow><mo rspace="1.167em" id="S2.E2.m1.5.5.3.5" xref="S2.E2.m1.5.5.4a.cmml">,</mo><mrow id="S2.E2.m1.5.5.3.3" xref="S2.E2.m1.5.5.3.3.cmml"><mrow id="S2.E2.m1.5.5.3.3.1.1" xref="S2.E2.m1.5.5.3.3.1.2.cmml"><mtext id="S2.E2.m1.2.2" xref="S2.E2.m1.2.2a.cmml">but</mtext><mspace width="1em" id="S2.E2.m1.5.5.3.3.1.1.2" xref="S2.E2.m1.5.5.3.3.1.2.cmml"></mspace><msub id="S2.E2.m1.5.5.3.3.1.1.1" xref="S2.E2.m1.5.5.3.3.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E2.m1.5.5.3.3.1.1.1.2" xref="S2.E2.m1.5.5.3.3.1.1.1.2.cmml">𝒴</mi><mi id="S2.E2.m1.5.5.3.3.1.1.1.3" xref="S2.E2.m1.5.5.3.3.1.1.1.3.cmml">i</mi></msub></mrow><mo id="S2.E2.m1.5.5.3.3.2" xref="S2.E2.m1.5.5.3.3.2.cmml">≠</mo><msub id="S2.E2.m1.5.5.3.3.3" xref="S2.E2.m1.5.5.3.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E2.m1.5.5.3.3.3.2" xref="S2.E2.m1.5.5.3.3.3.2.cmml">𝒴</mi><mi id="S2.E2.m1.5.5.3.3.3.3" xref="S2.E2.m1.5.5.3.3.3.3.cmml">j</mi></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E2.m1.5b"><apply id="S2.E2.m1.5.5.4.cmml" xref="S2.E2.m1.5.5.3"><csymbol cd="ambiguous" id="S2.E2.m1.5.5.4a.cmml" xref="S2.E2.m1.5.5.3.4">formulae-sequence</csymbol><apply id="S2.E2.m1.3.3.1.1.cmml" xref="S2.E2.m1.3.3.1.1"><subset id="S2.E2.m1.3.3.1.1.3.cmml" xref="S2.E2.m1.3.3.1.1.3"></subset><list id="S2.E2.m1.3.3.1.1.2.3.cmml" xref="S2.E2.m1.3.3.1.1.2.2"><apply id="S2.E2.m1.3.3.1.1.1.1.1.cmml" xref="S2.E2.m1.3.3.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E2.m1.3.3.1.1.1.1.1.1.cmml" xref="S2.E2.m1.3.3.1.1.1.1.1">subscript</csymbol><ci id="S2.E2.m1.3.3.1.1.1.1.1.2.cmml" xref="S2.E2.m1.3.3.1.1.1.1.1.2">𝐷</ci><ci id="S2.E2.m1.3.3.1.1.1.1.1.3.cmml" xref="S2.E2.m1.3.3.1.1.1.1.1.3">𝑖</ci></apply><apply id="S2.E2.m1.3.3.1.1.2.2.2.cmml" xref="S2.E2.m1.3.3.1.1.2.2.2"><csymbol cd="ambiguous" id="S2.E2.m1.3.3.1.1.2.2.2.1.cmml" xref="S2.E2.m1.3.3.1.1.2.2.2">subscript</csymbol><ci id="S2.E2.m1.3.3.1.1.2.2.2.2.cmml" xref="S2.E2.m1.3.3.1.1.2.2.2.2">𝐷</ci><ci id="S2.E2.m1.3.3.1.1.2.2.2.3.cmml" xref="S2.E2.m1.3.3.1.1.2.2.2.3">𝑗</ci></apply></list><apply id="S2.E2.m1.3.3.1.1.4.cmml" xref="S2.E2.m1.3.3.1.1.4"><times id="S2.E2.m1.3.3.1.1.4.1.cmml" xref="S2.E2.m1.3.3.1.1.4.1"></times><ci id="S2.E2.m1.3.3.1.1.4.2.cmml" xref="S2.E2.m1.3.3.1.1.4.2">𝒳</ci><ci id="S2.E2.m1.3.3.1.1.4.3.cmml" xref="S2.E2.m1.3.3.1.1.4.3">𝒴</ci></apply></apply><apply id="S2.E2.m1.4.4.2.2.cmml" xref="S2.E2.m1.4.4.2.2"><eq id="S2.E2.m1.4.4.2.2.2.cmml" xref="S2.E2.m1.4.4.2.2.2"></eq><list id="S2.E2.m1.4.4.2.2.1.2.cmml" xref="S2.E2.m1.4.4.2.2.1.1"><ci id="S2.E2.m1.1.1a.cmml" xref="S2.E2.m1.1.1"><mtext id="S2.E2.m1.1.1.cmml" xref="S2.E2.m1.1.1">and</mtext></ci><apply id="S2.E2.m1.4.4.2.2.1.1.1.cmml" xref="S2.E2.m1.4.4.2.2.1.1.1"><csymbol cd="ambiguous" id="S2.E2.m1.4.4.2.2.1.1.1.1.cmml" xref="S2.E2.m1.4.4.2.2.1.1.1">subscript</csymbol><ci id="S2.E2.m1.4.4.2.2.1.1.1.2.cmml" xref="S2.E2.m1.4.4.2.2.1.1.1.2">𝒳</ci><ci id="S2.E2.m1.4.4.2.2.1.1.1.3.cmml" xref="S2.E2.m1.4.4.2.2.1.1.1.3">𝑖</ci></apply></list><apply id="S2.E2.m1.4.4.2.2.3.cmml" xref="S2.E2.m1.4.4.2.2.3"><csymbol cd="ambiguous" id="S2.E2.m1.4.4.2.2.3.1.cmml" xref="S2.E2.m1.4.4.2.2.3">subscript</csymbol><ci id="S2.E2.m1.4.4.2.2.3.2.cmml" xref="S2.E2.m1.4.4.2.2.3.2">𝒳</ci><ci id="S2.E2.m1.4.4.2.2.3.3.cmml" xref="S2.E2.m1.4.4.2.2.3.3">𝑗</ci></apply></apply><apply id="S2.E2.m1.5.5.3.3.cmml" xref="S2.E2.m1.5.5.3.3"><neq id="S2.E2.m1.5.5.3.3.2.cmml" xref="S2.E2.m1.5.5.3.3.2"></neq><list id="S2.E2.m1.5.5.3.3.1.2.cmml" xref="S2.E2.m1.5.5.3.3.1.1"><ci id="S2.E2.m1.2.2a.cmml" xref="S2.E2.m1.2.2"><mtext id="S2.E2.m1.2.2.cmml" xref="S2.E2.m1.2.2">but</mtext></ci><apply id="S2.E2.m1.5.5.3.3.1.1.1.cmml" xref="S2.E2.m1.5.5.3.3.1.1.1"><csymbol cd="ambiguous" id="S2.E2.m1.5.5.3.3.1.1.1.1.cmml" xref="S2.E2.m1.5.5.3.3.1.1.1">subscript</csymbol><ci id="S2.E2.m1.5.5.3.3.1.1.1.2.cmml" xref="S2.E2.m1.5.5.3.3.1.1.1.2">𝒴</ci><ci id="S2.E2.m1.5.5.3.3.1.1.1.3.cmml" xref="S2.E2.m1.5.5.3.3.1.1.1.3">𝑖</ci></apply></list><apply id="S2.E2.m1.5.5.3.3.3.cmml" xref="S2.E2.m1.5.5.3.3.3"><csymbol cd="ambiguous" id="S2.E2.m1.5.5.3.3.3.1.cmml" xref="S2.E2.m1.5.5.3.3.3">subscript</csymbol><ci id="S2.E2.m1.5.5.3.3.3.2.cmml" xref="S2.E2.m1.5.5.3.3.3.2">𝒴</ci><ci id="S2.E2.m1.5.5.3.3.3.3.cmml" xref="S2.E2.m1.5.5.3.3.3.3">𝑗</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E2.m1.5c">D_{i},D_{j}\subseteq\mathcal{X}\times\mathcal{Y},\quad\text{and}\quad\mathcal{X}_{i}=\mathcal{X}_{j},\quad\text{but}\quad\mathcal{Y}_{i}\neq\mathcal{Y}_{j}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div id="S2.SS3.SSSx1.p2" class="ltx_para ltx_noindent">
<p id="S2.SS3.SSSx1.p2.1" class="ltx_p">Vertical Federated Learning involves clients that have data with the <em id="S2.SS3.SSSx1.p2.1.1" class="ltx_emph ltx_font_italic">same IDs</em> but inhabit different <em id="S2.SS3.SSSx1.p2.1.2" class="ltx_emph ltx_font_italic">feature spaces</em>. This setup is typical in collaborations between entities that collect different types of data about the same subjects.
<br class="ltx_break"><span id="S2.SS3.SSSx1.p2.1.3" class="ltx_text ltx_font_bold">Example:</span> A bank and a hospital share data about the same individuals, with the bank holding financial information and the hospital holding medical records. They share IDs but have vastly different feature spaces.</p>
<table id="S2.E3" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left"><span class="ltx_tag ltx_tag_equation ltx_align_left">(3)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E3.m1.1" class="ltx_Math" alttext="\text{Let }D_{a}\text{ from a bank and }D_{b}\text{ from a hospital, where}" display="block"><semantics id="S2.E3.m1.1a"><mrow id="S2.E3.m1.1.1" xref="S2.E3.m1.1.1.cmml"><mtext id="S2.E3.m1.1.1.2" xref="S2.E3.m1.1.1.2a.cmml">Let </mtext><mo lspace="0em" rspace="0em" id="S2.E3.m1.1.1.1" xref="S2.E3.m1.1.1.1.cmml">​</mo><msub id="S2.E3.m1.1.1.3" xref="S2.E3.m1.1.1.3.cmml"><mi id="S2.E3.m1.1.1.3.2" xref="S2.E3.m1.1.1.3.2.cmml">D</mi><mi id="S2.E3.m1.1.1.3.3" xref="S2.E3.m1.1.1.3.3.cmml">a</mi></msub><mo lspace="0em" rspace="0em" id="S2.E3.m1.1.1.1a" xref="S2.E3.m1.1.1.1.cmml">​</mo><mtext id="S2.E3.m1.1.1.4" xref="S2.E3.m1.1.1.4a.cmml"> from a bank and </mtext><mo lspace="0em" rspace="0em" id="S2.E3.m1.1.1.1b" xref="S2.E3.m1.1.1.1.cmml">​</mo><msub id="S2.E3.m1.1.1.5" xref="S2.E3.m1.1.1.5.cmml"><mi id="S2.E3.m1.1.1.5.2" xref="S2.E3.m1.1.1.5.2.cmml">D</mi><mi id="S2.E3.m1.1.1.5.3" xref="S2.E3.m1.1.1.5.3.cmml">b</mi></msub><mo lspace="0em" rspace="0em" id="S2.E3.m1.1.1.1c" xref="S2.E3.m1.1.1.1.cmml">​</mo><mtext id="S2.E3.m1.1.1.6" xref="S2.E3.m1.1.1.6a.cmml"> from a hospital, where</mtext></mrow><annotation-xml encoding="MathML-Content" id="S2.E3.m1.1b"><apply id="S2.E3.m1.1.1.cmml" xref="S2.E3.m1.1.1"><times id="S2.E3.m1.1.1.1.cmml" xref="S2.E3.m1.1.1.1"></times><ci id="S2.E3.m1.1.1.2a.cmml" xref="S2.E3.m1.1.1.2"><mtext id="S2.E3.m1.1.1.2.cmml" xref="S2.E3.m1.1.1.2">Let </mtext></ci><apply id="S2.E3.m1.1.1.3.cmml" xref="S2.E3.m1.1.1.3"><csymbol cd="ambiguous" id="S2.E3.m1.1.1.3.1.cmml" xref="S2.E3.m1.1.1.3">subscript</csymbol><ci id="S2.E3.m1.1.1.3.2.cmml" xref="S2.E3.m1.1.1.3.2">𝐷</ci><ci id="S2.E3.m1.1.1.3.3.cmml" xref="S2.E3.m1.1.1.3.3">𝑎</ci></apply><ci id="S2.E3.m1.1.1.4a.cmml" xref="S2.E3.m1.1.1.4"><mtext id="S2.E3.m1.1.1.4.cmml" xref="S2.E3.m1.1.1.4"> from a bank and </mtext></ci><apply id="S2.E3.m1.1.1.5.cmml" xref="S2.E3.m1.1.1.5"><csymbol cd="ambiguous" id="S2.E3.m1.1.1.5.1.cmml" xref="S2.E3.m1.1.1.5">subscript</csymbol><ci id="S2.E3.m1.1.1.5.2.cmml" xref="S2.E3.m1.1.1.5.2">𝐷</ci><ci id="S2.E3.m1.1.1.5.3.cmml" xref="S2.E3.m1.1.1.5.3">𝑏</ci></apply><ci id="S2.E3.m1.1.1.6a.cmml" xref="S2.E3.m1.1.1.6"><mtext id="S2.E3.m1.1.1.6.cmml" xref="S2.E3.m1.1.1.6"> from a hospital, where</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E3.m1.1c">\text{Let }D_{a}\text{ from a bank and }D_{b}\text{ from a hospital, where}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<table id="S2.E4" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left"><span class="ltx_tag ltx_tag_equation ltx_align_left">(4)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E4.m1.5" class="ltx_Math" alttext="D_{a},D_{b}\subseteq\mathcal{X}\times\mathcal{Y},\quad\text{and}\quad\mathcal{Y}_{a}=\mathcal{Y}_{b},\quad\text{but}\quad\mathcal{X}_{a}\neq\mathcal{X}_{b}" display="block"><semantics id="S2.E4.m1.5a"><mrow id="S2.E4.m1.5.5.3" xref="S2.E4.m1.5.5.4.cmml"><mrow id="S2.E4.m1.3.3.1.1" xref="S2.E4.m1.3.3.1.1.cmml"><mrow id="S2.E4.m1.3.3.1.1.2.2" xref="S2.E4.m1.3.3.1.1.2.3.cmml"><msub id="S2.E4.m1.3.3.1.1.1.1.1" xref="S2.E4.m1.3.3.1.1.1.1.1.cmml"><mi id="S2.E4.m1.3.3.1.1.1.1.1.2" xref="S2.E4.m1.3.3.1.1.1.1.1.2.cmml">D</mi><mi id="S2.E4.m1.3.3.1.1.1.1.1.3" xref="S2.E4.m1.3.3.1.1.1.1.1.3.cmml">a</mi></msub><mo id="S2.E4.m1.3.3.1.1.2.2.3" xref="S2.E4.m1.3.3.1.1.2.3.cmml">,</mo><msub id="S2.E4.m1.3.3.1.1.2.2.2" xref="S2.E4.m1.3.3.1.1.2.2.2.cmml"><mi id="S2.E4.m1.3.3.1.1.2.2.2.2" xref="S2.E4.m1.3.3.1.1.2.2.2.2.cmml">D</mi><mi id="S2.E4.m1.3.3.1.1.2.2.2.3" xref="S2.E4.m1.3.3.1.1.2.2.2.3.cmml">b</mi></msub></mrow><mo id="S2.E4.m1.3.3.1.1.3" xref="S2.E4.m1.3.3.1.1.3.cmml">⊆</mo><mrow id="S2.E4.m1.3.3.1.1.4" xref="S2.E4.m1.3.3.1.1.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E4.m1.3.3.1.1.4.2" xref="S2.E4.m1.3.3.1.1.4.2.cmml">𝒳</mi><mo lspace="0.222em" rspace="0.222em" id="S2.E4.m1.3.3.1.1.4.1" xref="S2.E4.m1.3.3.1.1.4.1.cmml">×</mo><mi class="ltx_font_mathcaligraphic" id="S2.E4.m1.3.3.1.1.4.3" xref="S2.E4.m1.3.3.1.1.4.3.cmml">𝒴</mi></mrow></mrow><mo rspace="1.167em" id="S2.E4.m1.5.5.3.4" xref="S2.E4.m1.5.5.4a.cmml">,</mo><mrow id="S2.E4.m1.4.4.2.2" xref="S2.E4.m1.4.4.2.2.cmml"><mrow id="S2.E4.m1.4.4.2.2.1.1" xref="S2.E4.m1.4.4.2.2.1.2.cmml"><mtext id="S2.E4.m1.1.1" xref="S2.E4.m1.1.1a.cmml">and</mtext><mspace width="1em" id="S2.E4.m1.4.4.2.2.1.1.2" xref="S2.E4.m1.4.4.2.2.1.2.cmml"></mspace><msub id="S2.E4.m1.4.4.2.2.1.1.1" xref="S2.E4.m1.4.4.2.2.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E4.m1.4.4.2.2.1.1.1.2" xref="S2.E4.m1.4.4.2.2.1.1.1.2.cmml">𝒴</mi><mi id="S2.E4.m1.4.4.2.2.1.1.1.3" xref="S2.E4.m1.4.4.2.2.1.1.1.3.cmml">a</mi></msub></mrow><mo id="S2.E4.m1.4.4.2.2.2" xref="S2.E4.m1.4.4.2.2.2.cmml">=</mo><msub id="S2.E4.m1.4.4.2.2.3" xref="S2.E4.m1.4.4.2.2.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E4.m1.4.4.2.2.3.2" xref="S2.E4.m1.4.4.2.2.3.2.cmml">𝒴</mi><mi id="S2.E4.m1.4.4.2.2.3.3" xref="S2.E4.m1.4.4.2.2.3.3.cmml">b</mi></msub></mrow><mo rspace="1.167em" id="S2.E4.m1.5.5.3.5" xref="S2.E4.m1.5.5.4a.cmml">,</mo><mrow id="S2.E4.m1.5.5.3.3" xref="S2.E4.m1.5.5.3.3.cmml"><mrow id="S2.E4.m1.5.5.3.3.1.1" xref="S2.E4.m1.5.5.3.3.1.2.cmml"><mtext id="S2.E4.m1.2.2" xref="S2.E4.m1.2.2a.cmml">but</mtext><mspace width="1em" id="S2.E4.m1.5.5.3.3.1.1.2" xref="S2.E4.m1.5.5.3.3.1.2.cmml"></mspace><msub id="S2.E4.m1.5.5.3.3.1.1.1" xref="S2.E4.m1.5.5.3.3.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E4.m1.5.5.3.3.1.1.1.2" xref="S2.E4.m1.5.5.3.3.1.1.1.2.cmml">𝒳</mi><mi id="S2.E4.m1.5.5.3.3.1.1.1.3" xref="S2.E4.m1.5.5.3.3.1.1.1.3.cmml">a</mi></msub></mrow><mo id="S2.E4.m1.5.5.3.3.2" xref="S2.E4.m1.5.5.3.3.2.cmml">≠</mo><msub id="S2.E4.m1.5.5.3.3.3" xref="S2.E4.m1.5.5.3.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E4.m1.5.5.3.3.3.2" xref="S2.E4.m1.5.5.3.3.3.2.cmml">𝒳</mi><mi id="S2.E4.m1.5.5.3.3.3.3" xref="S2.E4.m1.5.5.3.3.3.3.cmml">b</mi></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E4.m1.5b"><apply id="S2.E4.m1.5.5.4.cmml" xref="S2.E4.m1.5.5.3"><csymbol cd="ambiguous" id="S2.E4.m1.5.5.4a.cmml" xref="S2.E4.m1.5.5.3.4">formulae-sequence</csymbol><apply id="S2.E4.m1.3.3.1.1.cmml" xref="S2.E4.m1.3.3.1.1"><subset id="S2.E4.m1.3.3.1.1.3.cmml" xref="S2.E4.m1.3.3.1.1.3"></subset><list id="S2.E4.m1.3.3.1.1.2.3.cmml" xref="S2.E4.m1.3.3.1.1.2.2"><apply id="S2.E4.m1.3.3.1.1.1.1.1.cmml" xref="S2.E4.m1.3.3.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E4.m1.3.3.1.1.1.1.1.1.cmml" xref="S2.E4.m1.3.3.1.1.1.1.1">subscript</csymbol><ci id="S2.E4.m1.3.3.1.1.1.1.1.2.cmml" xref="S2.E4.m1.3.3.1.1.1.1.1.2">𝐷</ci><ci id="S2.E4.m1.3.3.1.1.1.1.1.3.cmml" xref="S2.E4.m1.3.3.1.1.1.1.1.3">𝑎</ci></apply><apply id="S2.E4.m1.3.3.1.1.2.2.2.cmml" xref="S2.E4.m1.3.3.1.1.2.2.2"><csymbol cd="ambiguous" id="S2.E4.m1.3.3.1.1.2.2.2.1.cmml" xref="S2.E4.m1.3.3.1.1.2.2.2">subscript</csymbol><ci id="S2.E4.m1.3.3.1.1.2.2.2.2.cmml" xref="S2.E4.m1.3.3.1.1.2.2.2.2">𝐷</ci><ci id="S2.E4.m1.3.3.1.1.2.2.2.3.cmml" xref="S2.E4.m1.3.3.1.1.2.2.2.3">𝑏</ci></apply></list><apply id="S2.E4.m1.3.3.1.1.4.cmml" xref="S2.E4.m1.3.3.1.1.4"><times id="S2.E4.m1.3.3.1.1.4.1.cmml" xref="S2.E4.m1.3.3.1.1.4.1"></times><ci id="S2.E4.m1.3.3.1.1.4.2.cmml" xref="S2.E4.m1.3.3.1.1.4.2">𝒳</ci><ci id="S2.E4.m1.3.3.1.1.4.3.cmml" xref="S2.E4.m1.3.3.1.1.4.3">𝒴</ci></apply></apply><apply id="S2.E4.m1.4.4.2.2.cmml" xref="S2.E4.m1.4.4.2.2"><eq id="S2.E4.m1.4.4.2.2.2.cmml" xref="S2.E4.m1.4.4.2.2.2"></eq><list id="S2.E4.m1.4.4.2.2.1.2.cmml" xref="S2.E4.m1.4.4.2.2.1.1"><ci id="S2.E4.m1.1.1a.cmml" xref="S2.E4.m1.1.1"><mtext id="S2.E4.m1.1.1.cmml" xref="S2.E4.m1.1.1">and</mtext></ci><apply id="S2.E4.m1.4.4.2.2.1.1.1.cmml" xref="S2.E4.m1.4.4.2.2.1.1.1"><csymbol cd="ambiguous" id="S2.E4.m1.4.4.2.2.1.1.1.1.cmml" xref="S2.E4.m1.4.4.2.2.1.1.1">subscript</csymbol><ci id="S2.E4.m1.4.4.2.2.1.1.1.2.cmml" xref="S2.E4.m1.4.4.2.2.1.1.1.2">𝒴</ci><ci id="S2.E4.m1.4.4.2.2.1.1.1.3.cmml" xref="S2.E4.m1.4.4.2.2.1.1.1.3">𝑎</ci></apply></list><apply id="S2.E4.m1.4.4.2.2.3.cmml" xref="S2.E4.m1.4.4.2.2.3"><csymbol cd="ambiguous" id="S2.E4.m1.4.4.2.2.3.1.cmml" xref="S2.E4.m1.4.4.2.2.3">subscript</csymbol><ci id="S2.E4.m1.4.4.2.2.3.2.cmml" xref="S2.E4.m1.4.4.2.2.3.2">𝒴</ci><ci id="S2.E4.m1.4.4.2.2.3.3.cmml" xref="S2.E4.m1.4.4.2.2.3.3">𝑏</ci></apply></apply><apply id="S2.E4.m1.5.5.3.3.cmml" xref="S2.E4.m1.5.5.3.3"><neq id="S2.E4.m1.5.5.3.3.2.cmml" xref="S2.E4.m1.5.5.3.3.2"></neq><list id="S2.E4.m1.5.5.3.3.1.2.cmml" xref="S2.E4.m1.5.5.3.3.1.1"><ci id="S2.E4.m1.2.2a.cmml" xref="S2.E4.m1.2.2"><mtext id="S2.E4.m1.2.2.cmml" xref="S2.E4.m1.2.2">but</mtext></ci><apply id="S2.E4.m1.5.5.3.3.1.1.1.cmml" xref="S2.E4.m1.5.5.3.3.1.1.1"><csymbol cd="ambiguous" id="S2.E4.m1.5.5.3.3.1.1.1.1.cmml" xref="S2.E4.m1.5.5.3.3.1.1.1">subscript</csymbol><ci id="S2.E4.m1.5.5.3.3.1.1.1.2.cmml" xref="S2.E4.m1.5.5.3.3.1.1.1.2">𝒳</ci><ci id="S2.E4.m1.5.5.3.3.1.1.1.3.cmml" xref="S2.E4.m1.5.5.3.3.1.1.1.3">𝑎</ci></apply></list><apply id="S2.E4.m1.5.5.3.3.3.cmml" xref="S2.E4.m1.5.5.3.3.3"><csymbol cd="ambiguous" id="S2.E4.m1.5.5.3.3.3.1.cmml" xref="S2.E4.m1.5.5.3.3.3">subscript</csymbol><ci id="S2.E4.m1.5.5.3.3.3.2.cmml" xref="S2.E4.m1.5.5.3.3.3.2">𝒳</ci><ci id="S2.E4.m1.5.5.3.3.3.3.cmml" xref="S2.E4.m1.5.5.3.3.3.3">𝑏</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E4.m1.5c">D_{a},D_{b}\subseteq\mathcal{X}\times\mathcal{Y},\quad\text{and}\quad\mathcal{Y}_{a}=\mathcal{Y}_{b},\quad\text{but}\quad\mathcal{X}_{a}\neq\mathcal{X}_{b}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
</section>
<section id="S2.SS3.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.3.4. </span>IID and non-IID Data Distributions</h4>

<div id="S2.SS3.SSS4.p1" class="ltx_para">
<p id="S2.SS3.SSS4.p1.1" class="ltx_p"><span id="S2.SS3.SSS4.p1.1.1" class="ltx_text ltx_font_bold">IID Data Distributions:</span>
In scenarios where data is considered IID, each client’s dataset is assumed to be drawn from the same probability distribution. This uniformity suggests that datasets across varied domains, such as those of a bank and a hospital, exhibit similar statistical properties and structures, despite their distinct contexts.</p>
</div>
<div id="S2.SS3.SSS4.p2" class="ltx_para">
<p id="S2.SS3.SSS4.p2.1" class="ltx_p"><span id="S2.SS3.SSS4.p2.1.1" class="ltx_text ltx_font_bold">Non-IID Data Distributions:</span>
Contrastingly, non-IID data distributions reflect situations where data across clients originate from heterogeneous distributions. This diversity is rooted in demographic variances, regional characteristics, or the intrinsic nature of the collected data.</p>
</div>
<div id="S2.SS3.SSS4.p3" class="ltx_para">
<p id="S2.SS3.SSS4.p3.1" class="ltx_p"><span id="S2.SS3.SSS4.p3.1.1" class="ltx_text ltx_font_bold">Implications on Privacy and Learning:</span>
<span id="S2.SS3.SSS4.p3.1.2" class="ltx_text ltx_font_italic">Privacy Concerns:</span> The heterogeneity of non-IID data amplifies privacy concerns, necessitating robust privacy-preserving mechanisms that can handle the diversity of data sources. The specificity of models to certain data characteristics could inadvertently lead to data leakage or facilitate inference attacks, underscoring the need for privacy techniques that are adaptable to varying data distributions.</p>
</div>
</section>
<section id="S2.SS3.SSS5" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.3.5. </span>FedSGD and FedAvg: Core FL algorithms</h4>

<div id="S2.SS3.SSS5.p1" class="ltx_para">
<p id="S2.SS3.SSS5.p1.1" class="ltx_p">The two standard FL algorithms are FedSGD and FedAvg <cite class="ltx_cite ltx_citemacro_citep">(McMahan et al<span class="ltx_text">.</span>, <a href="#bib.bib90" title="" class="ltx_ref">2017</a>)</cite>, mainly differing in the number of local iterations. FedSGD, the federated adaptation of stochastic gradient descent, operates on the principle of minimalism. It mandates that clients engage in a singular iteration of training on a localized data batch before transmitting the resultant gradient to a central server. This server, in turn, aggregates the gradients from all participating clients, adjusting the weights in proportion to each client’s contribution to the total dataset. This process is especially pertinent in scenarios demanding rapid model updates.</p>
</div>
<div id="S2.SS3.SSS5.p2" class="ltx_para">
<p id="S2.SS3.SSS5.p2.1" class="ltx_p">Advancing beyond FedSGD, FedAvg introduces multiple local iterations or epochs at each client before communicating updates to the server. These updates can comprise either the computed gradients over all local iterations or the updated model parameters themselves.
The algorithm’s structure inherently minimizes the frequency of communication with the server, addressing privacy concerns by limiting the exposure of initial and final model states only. This characteristic is crucial in contexts where data sensitivity is paramount, as it effectively conceals the intermediate computational states from potential external eavesdropping. Moreover, FedAvg facilitates a deeper, more nuanced learning from the complex datasets typical of financial and medical sectors. By allowing for extended local training periods, the algorithm empowers the model to better capture and adapt to the intricate patterns present within such diverse data sources. This capability not only enhances the model’s precision but also its applicability and relevance to the distinct challenges and requirements of these domains.</p>
</div>
</section>
</section>
<section id="S2.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.4. </span>Threat model</h3>

<div id="S2.SS4.p1" class="ltx_para">
<p id="S2.SS4.p1.1" class="ltx_p">For privacy attacks within the domain of FL, the the threat landscape is complex and varies significantly based on the nature of the attack. The architecture of FL inherently poses unique challenges in safeguarding privacy due to the decentralized nature of data processing. Here, the central server and the clients play pivotal roles, each representing potential vectors for privacy breaches and attacks. Understanding the nuances of these threats is crucial for developing robust defense mechanisms. At the heart of FL, the central server embodies a critical point of vulnerability. It plays a dual role: distributing the learning model to clients and aggregating their updates. This centralized control positions the server as a potent target for attacks, making it the focal point for the strongest privacy threats in FL. The server’s pivotal role in managing the flow of information — both disseminating and receiving — means that attacks can take on various forms, each tailored to exploit specific weaknesses in the server-client interaction.
This is split into two broad types of threats as follows:
<br class="ltx_break"><span id="S2.SS4.p1.1.1" class="ltx_text ltx_font_bold">Central Server Threats:</span>
<span id="S2.SS4.p1.1.2" class="ltx_text ltx_font_italic">Honest-but-Curious Server:</span> This scenario presupposes a server that adheres strictly to the prescribed FL protocol without any malicious alterations. However, it harbors intentions to infer private information from the updates received from clients. Despite its non-intrusive facade, this model represents a significant privacy threat as the server possesses the capability to analyze aggregated data and potentially extract sensitive client information without overtly compromising the integrity of the training process.
<br class="ltx_break"><span id="S2.SS4.p1.1.3" class="ltx_text ltx_font_italic">Malicious Server:</span> A more daunting threat emerges with the malicious server, which actively seeks to undermine the privacy and integrity of the FL process. This adversary is not bound by the ethical constraints of the honest-but-curious model and may engage in manipulative tactics such as altering client model parameters, tweaking the model architecture, or distorting the training process. The objective is clear: to siphon off private data from clients or to inject biases into the model, thereby compromising both privacy and model fidelity.</p>
</div>
<div id="S2.SS4.p2" class="ltx_para ltx_noindent">
<p id="S2.SS4.p2.1" class="ltx_p"><span id="S2.SS4.p2.1.1" class="ltx_text ltx_font_bold">Client-Side Threats:</span>
A parallel threat model arises due to the clients. Corresponding to the server case, here also the clients can be:
<span id="S2.SS4.p2.1.2" class="ltx_text ltx_font_italic">Honest-but-Curious Clients:</span> Parallel to the server-side threat, clients under this model operate within the bounds of the FL protocol but with ulterior motives. They aim to intercept and analyze communications between other clients and the server, with the ultimate goal of reconstructing the local data of their peers. This form of eavesdropping introduces a subtle yet potent risk to data confidentiality within the FL ecosystem.
<br class="ltx_break"><span id="S2.SS4.p2.1.3" class="ltx_text ltx_font_italic">Malicious Clients:</span> Beyond mere curiosity, malicious clients actively engage in sabotaging the FL process. By submitting falsified updates, these adversaries attempt to derail the collective learning effort, leading to a degraded model utility. While this behavior does not directly infringe on privacy, it undermines the integrity and reliability of the FL system, posing a significant challenge to maintaining model quality.</p>
</div>
<div id="S2.SS4.p3" class="ltx_para ltx_noindent">
<p id="S2.SS4.p3.1" class="ltx_p"><span id="S2.SS4.p3.1.1" class="ltx_text ltx_font_bold">Complexities of Misbehaving Clients:</span>
The threat landscape is further complicated by the variability in the behavior of misbehaving clients. Two critical factors need consideration: the proportion of clients engaged in malicious activities and the extent of their collaboration. Misbehaving clients may operate independently, presenting a scattered threat. However, the danger amplifies when they collude, orchestrating their attacks to maximize disruption or data extraction. This coordinated effort can significantly exacerbate the challenges in defending against privacy breaches and ensuring the integrity of the FL process.</p>
</div>
</section>
<section id="S2.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.5. </span>Metrics measuring privacy</h3>

<div id="S2.SS5.p1" class="ltx_para">
<p id="S2.SS5.p1.1" class="ltx_p"><span id="S2.SS5.p1.1.1" class="ltx_text ltx_font_bold">Membership inference attacks - accuracy.</span> The goal of membership inference attacks is to infer whether a particular instance is used in the training of a target model. A balanced evaluation set, which consists of the same number of members and non-members, is used in the membership inference attack evaluations in most existing literature.
For membership inference attacks, the attack accuracy measures the attack effectiveness over the whole data population <cite class="ltx_cite ltx_citemacro_citep">(Shokri et al<span class="ltx_text">.</span>, <a href="#bib.bib115" title="" class="ltx_ref">2017</a>)</cite>.
Attack AUC can also be used to measure the privacy leakage in terms of membership inference over the whole population. The higher the attack accuracy is, the more privacy leakage the target model has on its training set for the whole set.
</p>
</div>
<div id="S2.SS5.p2" class="ltx_para">
<p id="S2.SS5.p2.6" class="ltx_p"><span id="S2.SS5.p2.6.1" class="ltx_text ltx_font_bold">Membership inference attacks - TPR at a low FPR.</span> Accuracy and AUC measures the average privacy vulnerability across all instances. In the context of privacy, one usually wants to ensure that every individual’s privacy is protected. It is thus necessary to measure membership leakage threat for the most vulnerable instances. In <cite class="ltx_cite ltx_citemacro_citep">(Carlini et al<span class="ltx_text">.</span>, <a href="#bib.bib27" title="" class="ltx_ref">2022</a>)</cite>, it was proposed to use true positive rate (TPR) at a low false positive rate (FPR) to measure effects of MI attacks.
Consider, for example, TPR at FPR<math id="S2.SS5.p2.1.m1.1" class="ltx_Math" alttext="=0.001" display="inline"><semantics id="S2.SS5.p2.1.m1.1a"><mrow id="S2.SS5.p2.1.m1.1.1" xref="S2.SS5.p2.1.m1.1.1.cmml"><mi id="S2.SS5.p2.1.m1.1.1.2" xref="S2.SS5.p2.1.m1.1.1.2.cmml"></mi><mo id="S2.SS5.p2.1.m1.1.1.1" xref="S2.SS5.p2.1.m1.1.1.1.cmml">=</mo><mn id="S2.SS5.p2.1.m1.1.1.3" xref="S2.SS5.p2.1.m1.1.1.3.cmml">0.001</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS5.p2.1.m1.1b"><apply id="S2.SS5.p2.1.m1.1.1.cmml" xref="S2.SS5.p2.1.m1.1.1"><eq id="S2.SS5.p2.1.m1.1.1.1.cmml" xref="S2.SS5.p2.1.m1.1.1.1"></eq><csymbol cd="latexml" id="S2.SS5.p2.1.m1.1.1.2.cmml" xref="S2.SS5.p2.1.m1.1.1.2">absent</csymbol><cn type="float" id="S2.SS5.p2.1.m1.1.1.3.cmml" xref="S2.SS5.p2.1.m1.1.1.3">0.001</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS5.p2.1.m1.1c">=0.001</annotation></semantics></math>. If <math id="S2.SS5.p2.2.m2.1" class="ltx_Math" alttext="TPR" display="inline"><semantics id="S2.SS5.p2.2.m2.1a"><mrow id="S2.SS5.p2.2.m2.1.1" xref="S2.SS5.p2.2.m2.1.1.cmml"><mi id="S2.SS5.p2.2.m2.1.1.2" xref="S2.SS5.p2.2.m2.1.1.2.cmml">T</mi><mo lspace="0em" rspace="0em" id="S2.SS5.p2.2.m2.1.1.1" xref="S2.SS5.p2.2.m2.1.1.1.cmml">​</mo><mi id="S2.SS5.p2.2.m2.1.1.3" xref="S2.SS5.p2.2.m2.1.1.3.cmml">P</mi><mo lspace="0em" rspace="0em" id="S2.SS5.p2.2.m2.1.1.1a" xref="S2.SS5.p2.2.m2.1.1.1.cmml">​</mo><mi id="S2.SS5.p2.2.m2.1.1.4" xref="S2.SS5.p2.2.m2.1.1.4.cmml">R</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS5.p2.2.m2.1b"><apply id="S2.SS5.p2.2.m2.1.1.cmml" xref="S2.SS5.p2.2.m2.1.1"><times id="S2.SS5.p2.2.m2.1.1.1.cmml" xref="S2.SS5.p2.2.m2.1.1.1"></times><ci id="S2.SS5.p2.2.m2.1.1.2.cmml" xref="S2.SS5.p2.2.m2.1.1.2">𝑇</ci><ci id="S2.SS5.p2.2.m2.1.1.3.cmml" xref="S2.SS5.p2.2.m2.1.1.3">𝑃</ci><ci id="S2.SS5.p2.2.m2.1.1.4.cmml" xref="S2.SS5.p2.2.m2.1.1.4">𝑅</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS5.p2.2.m2.1c">TPR</annotation></semantics></math> is also around <math id="S2.SS5.p2.3.m3.1" class="ltx_Math" alttext="0.001" display="inline"><semantics id="S2.SS5.p2.3.m3.1a"><mn id="S2.SS5.p2.3.m3.1.1" xref="S2.SS5.p2.3.m3.1.1.cmml">0.001</mn><annotation-xml encoding="MathML-Content" id="S2.SS5.p2.3.m3.1b"><cn type="float" id="S2.SS5.p2.3.m3.1.1.cmml" xref="S2.SS5.p2.3.m3.1.1">0.001</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.SS5.p2.3.m3.1c">0.001</annotation></semantics></math>, then that means the adversary cannot do better than random guessing even when they are very confident about MI inference. On the other hand, if If <math id="S2.SS5.p2.4.m4.1" class="ltx_Math" alttext="TPR" display="inline"><semantics id="S2.SS5.p2.4.m4.1a"><mrow id="S2.SS5.p2.4.m4.1.1" xref="S2.SS5.p2.4.m4.1.1.cmml"><mi id="S2.SS5.p2.4.m4.1.1.2" xref="S2.SS5.p2.4.m4.1.1.2.cmml">T</mi><mo lspace="0em" rspace="0em" id="S2.SS5.p2.4.m4.1.1.1" xref="S2.SS5.p2.4.m4.1.1.1.cmml">​</mo><mi id="S2.SS5.p2.4.m4.1.1.3" xref="S2.SS5.p2.4.m4.1.1.3.cmml">P</mi><mo lspace="0em" rspace="0em" id="S2.SS5.p2.4.m4.1.1.1a" xref="S2.SS5.p2.4.m4.1.1.1.cmml">​</mo><mi id="S2.SS5.p2.4.m4.1.1.4" xref="S2.SS5.p2.4.m4.1.1.4.cmml">R</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS5.p2.4.m4.1b"><apply id="S2.SS5.p2.4.m4.1.1.cmml" xref="S2.SS5.p2.4.m4.1.1"><times id="S2.SS5.p2.4.m4.1.1.1.cmml" xref="S2.SS5.p2.4.m4.1.1.1"></times><ci id="S2.SS5.p2.4.m4.1.1.2.cmml" xref="S2.SS5.p2.4.m4.1.1.2">𝑇</ci><ci id="S2.SS5.p2.4.m4.1.1.3.cmml" xref="S2.SS5.p2.4.m4.1.1.3">𝑃</ci><ci id="S2.SS5.p2.4.m4.1.1.4.cmml" xref="S2.SS5.p2.4.m4.1.1.4">𝑅</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS5.p2.4.m4.1c">TPR</annotation></semantics></math> is also around <math id="S2.SS5.p2.5.m5.1" class="ltx_Math" alttext="0.01" display="inline"><semantics id="S2.SS5.p2.5.m5.1a"><mn id="S2.SS5.p2.5.m5.1.1" xref="S2.SS5.p2.5.m5.1.1.cmml">0.01</mn><annotation-xml encoding="MathML-Content" id="S2.SS5.p2.5.m5.1b"><cn type="float" id="S2.SS5.p2.5.m5.1.1.cmml" xref="S2.SS5.p2.5.m5.1.1">0.01</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.SS5.p2.5.m5.1c">0.01</annotation></semantics></math>, then that means the adversary would be able to correctly identify (a small percentage of) members with a <math id="S2.SS5.p2.6.m6.1" class="ltx_Math" alttext="10:1" display="inline"><semantics id="S2.SS5.p2.6.m6.1a"><mrow id="S2.SS5.p2.6.m6.1.1" xref="S2.SS5.p2.6.m6.1.1.cmml"><mn id="S2.SS5.p2.6.m6.1.1.2" xref="S2.SS5.p2.6.m6.1.1.2.cmml">10</mn><mo lspace="0.278em" rspace="0.278em" id="S2.SS5.p2.6.m6.1.1.1" xref="S2.SS5.p2.6.m6.1.1.1.cmml">:</mo><mn id="S2.SS5.p2.6.m6.1.1.3" xref="S2.SS5.p2.6.m6.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS5.p2.6.m6.1b"><apply id="S2.SS5.p2.6.m6.1.1.cmml" xref="S2.SS5.p2.6.m6.1.1"><ci id="S2.SS5.p2.6.m6.1.1.1.cmml" xref="S2.SS5.p2.6.m6.1.1.1">:</ci><cn type="integer" id="S2.SS5.p2.6.m6.1.1.2.cmml" xref="S2.SS5.p2.6.m6.1.1.2">10</cn><cn type="integer" id="S2.SS5.p2.6.m6.1.1.3.cmml" xref="S2.SS5.p2.6.m6.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS5.p2.6.m6.1c">10:1</annotation></semantics></math> odds ratio.</p>
</div>
<div id="S2.SS5.p3" class="ltx_para">
<p id="S2.SS5.p3.2" class="ltx_p"><span id="S2.SS5.p3.2.1" class="ltx_text ltx_font_bold">Data reconstruction attacks - reconstruction quality.</span> One important metric for gauging the success of data reconstruction attacks is in the similarity of the reconstructions to the ground truth images. This measure can be visual and is typically quantified through image similarity metrics such as PSNR (peak signal-to-noise ratio), SSIM (structural similarity index measure), or L-PIPS (learned perceptual image patch similarity). Image identifiability precision (IIP) was also introduced as a potential metric for reconstruction quality <cite class="ltx_cite ltx_citemacro_citep">(Yin et al<span class="ltx_text">.</span>, <a href="#bib.bib137" title="" class="ltx_ref">2021a</a>)</cite>. Instead of per-image calculatioins, compared to all images in the ground truth batch, IIP finds the nearest neighbor of each reconstructed image. The metric is quantified as the fraction of reconstructions that have the ground truth image as their nearest neighbor. Additionally, <cite class="ltx_cite ltx_citemacro_citep">(Zhao et al<span class="ltx_text">.</span>, <a href="#bib.bib147" title="" class="ltx_ref">2024</a>)</cite> discusses the use of leaked data for training models in downstream prediction tasks related to the image similarity metrics. Even reconstructed images with some of the lowest metric scores (e.g., PSNR<math id="S2.SS5.p3.1.m1.1" class="ltx_Math" alttext="&lt;12" display="inline"><semantics id="S2.SS5.p3.1.m1.1a"><mrow id="S2.SS5.p3.1.m1.1.1" xref="S2.SS5.p3.1.m1.1.1.cmml"><mi id="S2.SS5.p3.1.m1.1.1.2" xref="S2.SS5.p3.1.m1.1.1.2.cmml"></mi><mo id="S2.SS5.p3.1.m1.1.1.1" xref="S2.SS5.p3.1.m1.1.1.1.cmml">&lt;</mo><mn id="S2.SS5.p3.1.m1.1.1.3" xref="S2.SS5.p3.1.m1.1.1.3.cmml">12</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS5.p3.1.m1.1b"><apply id="S2.SS5.p3.1.m1.1.1.cmml" xref="S2.SS5.p3.1.m1.1.1"><lt id="S2.SS5.p3.1.m1.1.1.1.cmml" xref="S2.SS5.p3.1.m1.1.1.1"></lt><csymbol cd="latexml" id="S2.SS5.p3.1.m1.1.1.2.cmml" xref="S2.SS5.p3.1.m1.1.1.2">absent</csymbol><cn type="integer" id="S2.SS5.p3.1.m1.1.1.3.cmml" xref="S2.SS5.p3.1.m1.1.1.3">12</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS5.p3.1.m1.1c">&lt;12</annotation></semantics></math>, SSIM<math id="S2.SS5.p3.2.m2.1" class="ltx_Math" alttext="&lt;0.2" display="inline"><semantics id="S2.SS5.p3.2.m2.1a"><mrow id="S2.SS5.p3.2.m2.1.1" xref="S2.SS5.p3.2.m2.1.1.cmml"><mi id="S2.SS5.p3.2.m2.1.1.2" xref="S2.SS5.p3.2.m2.1.1.2.cmml"></mi><mo id="S2.SS5.p3.2.m2.1.1.1" xref="S2.SS5.p3.2.m2.1.1.1.cmml">&lt;</mo><mn id="S2.SS5.p3.2.m2.1.1.3" xref="S2.SS5.p3.2.m2.1.1.3.cmml">0.2</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS5.p3.2.m2.1b"><apply id="S2.SS5.p3.2.m2.1.1.cmml" xref="S2.SS5.p3.2.m2.1.1"><lt id="S2.SS5.p3.2.m2.1.1.1.cmml" xref="S2.SS5.p3.2.m2.1.1.1"></lt><csymbol cd="latexml" id="S2.SS5.p3.2.m2.1.1.2.cmml" xref="S2.SS5.p3.2.m2.1.1.2">absent</csymbol><cn type="float" id="S2.SS5.p3.2.m2.1.1.3.cmml" xref="S2.SS5.p3.2.m2.1.1.3">0.2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS5.p3.2.m2.1c">&lt;0.2</annotation></semantics></math>) were still shown to improve the accuracy of the trained models <cite class="ltx_cite ltx_citemacro_citep">(Zhao et al<span class="ltx_text">.</span>, <a href="#bib.bib147" title="" class="ltx_ref">2024</a>)</cite>.</p>
</div>
<div id="S2.SS5.p4" class="ltx_para">
<p id="S2.SS5.p4.1" class="ltx_p"><span id="S2.SS5.p4.1.1" class="ltx_text ltx_font_bold">Data reconstruction attacks - leakage rate.</span> Another metric used to quantify success of data reconstruction attacks is leakage rate. While leakage rate can be simply defined as the number of leaked images, quantification can still vary. Some methods such as linear layer leakage can result in leaking a single image with multiple ground truth images overlapping. Here, leakage rate is typically defined as the number of reconstructions that only have a single image leaked. While methods such as gradient inversion typically rely on image similarity to measure the quality, leakage rate can also be used based on the number of images above a given threshold for any metric (e.g., PSNR<math id="S2.SS5.p4.1.m1.1" class="ltx_Math" alttext="&gt;16" display="inline"><semantics id="S2.SS5.p4.1.m1.1a"><mrow id="S2.SS5.p4.1.m1.1.1" xref="S2.SS5.p4.1.m1.1.1.cmml"><mi id="S2.SS5.p4.1.m1.1.1.2" xref="S2.SS5.p4.1.m1.1.1.2.cmml"></mi><mo id="S2.SS5.p4.1.m1.1.1.1" xref="S2.SS5.p4.1.m1.1.1.1.cmml">&gt;</mo><mn id="S2.SS5.p4.1.m1.1.1.3" xref="S2.SS5.p4.1.m1.1.1.3.cmml">16</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS5.p4.1.m1.1b"><apply id="S2.SS5.p4.1.m1.1.1.cmml" xref="S2.SS5.p4.1.m1.1.1"><gt id="S2.SS5.p4.1.m1.1.1.1.cmml" xref="S2.SS5.p4.1.m1.1.1.1"></gt><csymbol cd="latexml" id="S2.SS5.p4.1.m1.1.1.2.cmml" xref="S2.SS5.p4.1.m1.1.1.2">absent</csymbol><cn type="integer" id="S2.SS5.p4.1.m1.1.1.3.cmml" xref="S2.SS5.p4.1.m1.1.1.3">16</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS5.p4.1.m1.1c">&gt;16</annotation></semantics></math>) <cite class="ltx_cite ltx_citemacro_citep">(Hatamizadeh et al<span class="ltx_text">.</span>, <a href="#bib.bib59" title="" class="ltx_ref">2023</a>)</cite>.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3. </span>Relation to Prior Surveys</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">Federated learning was originally introduced as a method to collaboratively train machine learning models while allowing users to keep their data local and private. Despite this, many prior works have shown that the updates sent to a server still inherently include sensitive information that can be used to leak either properties of the data or reconstruct them directly. Following this, much work has also been done in the area of FL privacy defense. To motivate our work, we first compare the prior surveys in FL privacy and discuss the missing pieces. Table <a href="#S3.T1" title="Table 1 ‣ 3. Relation to Prior Surveys ‣ Federated Learning Privacy: Attacks, Defenses, Applications, and Policy Landscape — A Survey" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> shows a summary of prior surveys compared to this work.</p>
</div>
<div id="S3.p2" class="ltx_para">
<p id="S3.p2.1" class="ltx_p">Many surveys have looked at the privacy aspect of FL. <cite class="ltx_cite ltx_citemacro_citep">(El Ouadrhiri and Abdelhadi, <a href="#bib.bib45" title="" class="ltx_ref">2022</a>; Khan et al<span class="ltx_text">.</span>, <a href="#bib.bib72" title="" class="ltx_ref">2023</a>; Li et al<span class="ltx_text">.</span>, <a href="#bib.bib83" title="" class="ltx_ref">2020</a>)</cite> discuss privacy defense in FL with little discussion on privacy attacks. Other surveys <cite class="ltx_cite ltx_citemacro_citep">(Mothukuri et al<span class="ltx_text">.</span>, <a href="#bib.bib94" title="" class="ltx_ref">2021</a>; Zhang et al<span class="ltx_text">.</span>, <a href="#bib.bib144" title="" class="ltx_ref">2022</a>; Yin et al<span class="ltx_text">.</span>, <a href="#bib.bib139" title="" class="ltx_ref">2021b</a>; Bouacida and Mohapatra, <a href="#bib.bib25" title="" class="ltx_ref">2021</a>; Chen et al<span class="ltx_text">.</span>, <a href="#bib.bib31" title="" class="ltx_ref">2022</a>; Sikandar et al<span class="ltx_text">.</span>, <a href="#bib.bib116" title="" class="ltx_ref">2023</a>; Liu et al<span class="ltx_text">.</span>, <a href="#bib.bib86" title="" class="ltx_ref">2022a</a>)</cite> look at privacy attacks, but are missing discussion on more recent catastrophic attack methods such as linear layer leakage for data reconstruction or membership inference attacks that don’t require training data. <cite class="ltx_cite ltx_citemacro_citep">(Chen et al<span class="ltx_text">.</span>, <a href="#bib.bib28" title="" class="ltx_ref">2023b</a>)</cite> discuss the trade-off between privacy and fairness in FL. While the methods of optimization and closed-form linear layer leakage attacks are discussed, the work still misses other key data reconstruction methods such as multi-round disaggregation or attacks targeted against secure aggregation. Similarly, <cite class="ltx_cite ltx_citemacro_citep">(Rigaki and Garcia, <a href="#bib.bib108" title="" class="ltx_ref">2023</a>)</cite> discusses privacy attacks in machine learning but also lacks many current privacy attacks specific to FL. <cite class="ltx_cite ltx_citemacro_citep">(Lyu et al<span class="ltx_text">.</span>, <a href="#bib.bib88" title="" class="ltx_ref">2022</a>)</cite> is the closest survey to ours, focusing on security and privacy attacks and defenses in FL. However, important discussion on the key limitations of attacks and defenses is missing. Similarly, discussion into recently introduced data reconstruction attacks such as <cite class="ltx_cite ltx_citemacro_citep">(Fowl et al<span class="ltx_text">.</span>, <a href="#bib.bib51" title="" class="ltx_ref">2022</a>; Wen et al<span class="ltx_text">.</span>, <a href="#bib.bib134" title="" class="ltx_ref">2022</a>; Lam et al<span class="ltx_text">.</span>, <a href="#bib.bib77" title="" class="ltx_ref">2021</a>; Kariyappa et al<span class="ltx_text">.</span>, <a href="#bib.bib71" title="" class="ltx_ref">2023</a>)</cite> are also missing.</p>
</div>
<div id="S3.p3" class="ltx_para">
<p id="S3.p3.1" class="ltx_p">With the rapid development of FL privacy attacks and defenses, prior surveys are missing discussion of many current key privacy attacks and defenses. Our work bridges this gap and provides a comprehensive discussion on the current privacy attack threats (data reconstruction, membership-inference, and property inference attacks) along with defenses (differential privacy, secure aggregation, homomorphic encryption, and trusted execution environments) while highlighting the limitations of these methods along with areas where improvement is needed. Additionally, to the best of our knowledge, we are the only work to discuss current industry applications utilizing FL in a variety of industry sectors including healthcare, finance, and IoT edge applications. Similarly, we are the only work to include crucial discussion on government data privacy policies and their relation to FL. We close our work by looking ahead and hypothesizing the key developments that would be necessary for FL to become a privacy-preserving technology that addresses user privacy concerns and policy mandates in real-world deployments.</p>
</div>
<figure id="S3.T1" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 1. </span> Comparison table of federated learning privacy surveys</figcaption>
<table id="S3.T1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T1.1.1.1" class="ltx_tr">
<th id="S3.T1.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" rowspan="2"><span id="S3.T1.1.1.1.1.1" class="ltx_text ltx_font_bold">References</span></th>
<th id="S3.T1.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="2"><span id="S3.T1.1.1.1.2.1" class="ltx_text ltx_font_bold">Privacy</span></th>
<th id="S3.T1.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="2"><span id="S3.T1.1.1.1.3.1" class="ltx_text ltx_font_bold">Industry</span></th>
</tr>
<tr id="S3.T1.1.2.2" class="ltx_tr">
<th id="S3.T1.1.2.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">Defenses</th>
<th id="S3.T1.1.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">Attacks</th>
<th id="S3.T1.1.2.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">Applications</th>
<th id="S3.T1.1.2.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">Policy</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T1.1.3.1" class="ltx_tr">
<td id="S3.T1.1.3.1.1" class="ltx_td ltx_align_left ltx_border_t">Li et al <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a href="#bib.bib83" title="" class="ltx_ref">2020</a>)</cite>
</td>
<td id="S3.T1.1.3.1.2" class="ltx_td ltx_align_center ltx_border_t">✗</td>
<td id="S3.T1.1.3.1.3" class="ltx_td ltx_border_t"></td>
<td id="S3.T1.1.3.1.4" class="ltx_td ltx_border_t"></td>
<td id="S3.T1.1.3.1.5" class="ltx_td ltx_border_t"></td>
</tr>
<tr id="S3.T1.1.4.2" class="ltx_tr">
<td id="S3.T1.1.4.2.1" class="ltx_td ltx_align_left">Ouadrhiri et al <cite class="ltx_cite ltx_citemacro_citep">(El Ouadrhiri and Abdelhadi, <a href="#bib.bib45" title="" class="ltx_ref">2022</a>)</cite>
</td>
<td id="S3.T1.1.4.2.2" class="ltx_td ltx_align_center">✗</td>
<td id="S3.T1.1.4.2.3" class="ltx_td"></td>
<td id="S3.T1.1.4.2.4" class="ltx_td"></td>
<td id="S3.T1.1.4.2.5" class="ltx_td"></td>
</tr>
<tr id="S3.T1.1.5.3" class="ltx_tr">
<td id="S3.T1.1.5.3.1" class="ltx_td ltx_align_left">Chen et al <cite class="ltx_cite ltx_citemacro_citep">(Chen et al<span class="ltx_text">.</span>, <a href="#bib.bib28" title="" class="ltx_ref">2023b</a>)</cite>
</td>
<td id="S3.T1.1.5.3.2" class="ltx_td ltx_align_center">✗</td>
<td id="S3.T1.1.5.3.3" class="ltx_td ltx_align_center">✗</td>
<td id="S3.T1.1.5.3.4" class="ltx_td"></td>
<td id="S3.T1.1.5.3.5" class="ltx_td"></td>
</tr>
<tr id="S3.T1.1.6.4" class="ltx_tr">
<td id="S3.T1.1.6.4.1" class="ltx_td ltx_align_left">Lyu et al <cite class="ltx_cite ltx_citemacro_citep">(Lyu et al<span class="ltx_text">.</span>, <a href="#bib.bib88" title="" class="ltx_ref">2022</a>)</cite>
</td>
<td id="S3.T1.1.6.4.2" class="ltx_td ltx_align_center">✗</td>
<td id="S3.T1.1.6.4.3" class="ltx_td ltx_align_center">✗</td>
<td id="S3.T1.1.6.4.4" class="ltx_td"></td>
<td id="S3.T1.1.6.4.5" class="ltx_td"></td>
</tr>
<tr id="S3.T1.1.7.5" class="ltx_tr">
<td id="S3.T1.1.7.5.1" class="ltx_td ltx_align_left">Rigaki et al <cite class="ltx_cite ltx_citemacro_citep">(Rigaki and Garcia, <a href="#bib.bib108" title="" class="ltx_ref">2023</a>)</cite>
</td>
<td id="S3.T1.1.7.5.2" class="ltx_td ltx_align_center">✗</td>
<td id="S3.T1.1.7.5.3" class="ltx_td ltx_align_center">✗</td>
<td id="S3.T1.1.7.5.4" class="ltx_td"></td>
<td id="S3.T1.1.7.5.5" class="ltx_td"></td>
</tr>
<tr id="S3.T1.1.8.6" class="ltx_tr">
<td id="S3.T1.1.8.6.1" class="ltx_td ltx_align_left ltx_border_b">Our work</td>
<td id="S3.T1.1.8.6.2" class="ltx_td ltx_align_center ltx_border_b">✗</td>
<td id="S3.T1.1.8.6.3" class="ltx_td ltx_align_center ltx_border_b">✗</td>
<td id="S3.T1.1.8.6.4" class="ltx_td ltx_align_center ltx_border_b">✗</td>
<td id="S3.T1.1.8.6.5" class="ltx_td ltx_align_center ltx_border_b">✗</td>
</tr>
</tbody>
</table>
</figure>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4. </span>Application Use Cases and Policy Drivers</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.3" class="ltx_p">As part of the research in FL, investigating when the participating parties are adequately incentivized to participate is crucial, especially for real-life scenarios.
The incentive mechanism expects that not all clients have the same interests in the global model as the server. The existing FL incentive mechanism is typically designed by sampling a fixed subset of clients based on their data quantity or resources <cite class="ltx_cite ltx_citemacro_citep">(Luo et al<span class="ltx_text">.</span>, <a href="#bib.bib87" title="" class="ltx_ref">2023</a>)</cite>. On the far-end of this spectrum, on the non-federated setting, clients can train their own local model <math id="S4.p1.1.m1.1" class="ltx_Math" alttext="M_{i}" display="inline"><semantics id="S4.p1.1.m1.1a"><msub id="S4.p1.1.m1.1.1" xref="S4.p1.1.m1.1.1.cmml"><mi id="S4.p1.1.m1.1.1.2" xref="S4.p1.1.m1.1.1.2.cmml">M</mi><mi id="S4.p1.1.m1.1.1.3" xref="S4.p1.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S4.p1.1.m1.1b"><apply id="S4.p1.1.m1.1.1.cmml" xref="S4.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.p1.1.m1.1.1.1.cmml" xref="S4.p1.1.m1.1.1">subscript</csymbol><ci id="S4.p1.1.m1.1.1.2.cmml" xref="S4.p1.1.m1.1.1.2">𝑀</ci><ci id="S4.p1.1.m1.1.1.3.cmml" xref="S4.p1.1.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.1.m1.1c">M_{i}</annotation></semantics></math> using only the available local data <math id="S4.p1.2.m2.1" class="ltx_Math" alttext="D_{i}" display="inline"><semantics id="S4.p1.2.m2.1a"><msub id="S4.p1.2.m2.1.1" xref="S4.p1.2.m2.1.1.cmml"><mi id="S4.p1.2.m2.1.1.2" xref="S4.p1.2.m2.1.1.2.cmml">D</mi><mi id="S4.p1.2.m2.1.1.3" xref="S4.p1.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S4.p1.2.m2.1b"><apply id="S4.p1.2.m2.1.1.cmml" xref="S4.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S4.p1.2.m2.1.1.1.cmml" xref="S4.p1.2.m2.1.1">subscript</csymbol><ci id="S4.p1.2.m2.1.1.2.cmml" xref="S4.p1.2.m2.1.1.2">𝐷</ci><ci id="S4.p1.2.m2.1.1.3.cmml" xref="S4.p1.2.m2.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.2.m2.1c">D_{i}</annotation></semantics></math> and send the local model parameters to the server. Analysis based on <cite class="ltx_cite ltx_citemacro_citep">(Mansour et al<span class="ltx_text">.</span>, <a href="#bib.bib89" title="" class="ltx_ref">2020</a>)</cite> shows that local training often outperforms federated models, depending on the local data <math id="S4.p1.3.m3.1" class="ltx_Math" alttext="D_{i}" display="inline"><semantics id="S4.p1.3.m3.1a"><msub id="S4.p1.3.m3.1.1" xref="S4.p1.3.m3.1.1.cmml"><mi id="S4.p1.3.m3.1.1.2" xref="S4.p1.3.m3.1.1.2.cmml">D</mi><mi id="S4.p1.3.m3.1.1.3" xref="S4.p1.3.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S4.p1.3.m3.1b"><apply id="S4.p1.3.m3.1.1.cmml" xref="S4.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S4.p1.3.m3.1.1.1.cmml" xref="S4.p1.3.m3.1.1">subscript</csymbol><ci id="S4.p1.3.m3.1.1.2.cmml" xref="S4.p1.3.m3.1.1.2">𝐷</ci><ci id="S4.p1.3.m3.1.1.3.cmml" xref="S4.p1.3.m3.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.3.m3.1c">D_{i}</annotation></semantics></math>.
Federated learning has multiple applications across various industries, including healthcare, finance, automotive, and personalized medicine. In healthcare, we can use federated learning to train models on patients’ data without compromising their privacy, especially when using Differential Privacy. Similarly, in the financial industry, we can employ federated learning to train fraud detection models without exposing any sensitive financial data to potentially malicious entities. In the automotive industry, we can employ federated learning to train autonomous driving models on real-life data avoiding transferring huge volumes of data back to the servers.
</p>
</div>
<figure id="S4.T2" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 2. </span> Characterization of federated learning application domains into cross-device and cross silo deployments</figcaption>
<table id="S4.T2.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T2.1.1.1" class="ltx_tr">
<th id="S4.T2.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t"><span id="S4.T2.1.1.1.1.1" class="ltx_text ltx_font_bold">Application Domain</span></th>
<th id="S4.T2.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S4.T2.1.1.1.2.1" class="ltx_text ltx_font_bold">Cross-Device</span></th>
<th id="S4.T2.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S4.T2.1.1.1.3.1" class="ltx_text ltx_font_bold">Cross Silo</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T2.1.2.1" class="ltx_tr">
<td id="S4.T2.1.2.1.1" class="ltx_td ltx_align_left ltx_border_t">Healthcare</td>
<td id="S4.T2.1.2.1.2" class="ltx_td ltx_align_center ltx_border_t">✓</td>
<td id="S4.T2.1.2.1.3" class="ltx_td ltx_align_center ltx_border_t">✓</td>
</tr>
<tr id="S4.T2.1.3.2" class="ltx_tr">
<td id="S4.T2.1.3.2.1" class="ltx_td ltx_align_left">Finance</td>
<td id="S4.T2.1.3.2.2" class="ltx_td"></td>
<td id="S4.T2.1.3.2.3" class="ltx_td ltx_align_center">✓</td>
</tr>
<tr id="S4.T2.1.4.3" class="ltx_tr">
<td id="S4.T2.1.4.3.1" class="ltx_td ltx_align_left">IoT / Edge</td>
<td id="S4.T2.1.4.3.2" class="ltx_td ltx_align_center">✓</td>
<td id="S4.T2.1.4.3.3" class="ltx_td ltx_align_center">✓</td>
</tr>
<tr id="S4.T2.1.5.4" class="ltx_tr">
<td id="S4.T2.1.5.4.1" class="ltx_td ltx_align_left ltx_border_b">Autonomous Driving</td>
<td id="S4.T2.1.5.4.2" class="ltx_td ltx_align_center ltx_border_b">✓</td>
<td id="S4.T2.1.5.4.3" class="ltx_td ltx_border_b"></td>
</tr>
</tbody>
</table>
</figure>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1. </span>Application of FL in Healthcare</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">In the past few years, we have experienced a flood of changes in automation in the healthcare industry,
increasing the need and expectation for better ML models. Healthcare professionals have turned to technology to help them treat patients better, improve their understanding of the emerging global demand, etc. However, training healthcare-related models requires vast and diverse datasets. On the other hand, sharing information is becoming even more challenging due to the ever-stricter privacy regulations. Using FL, participating institutions can train a global model on their in-house data without exposing sensitive local data. This new paradigm leads to better models and more accurate training algorithms, allowing them to access and also work around various regulations. Thus, the potential benefits of FL in the healthcare industry are significant.</p>
</div>
<div id="S4.SS1.p2" class="ltx_para">
<p id="S4.SS1.p2.1" class="ltx_p">There have been several real-world efforts around FL in the healthcare sector, including proof-of-concept projects and establishing long-running consortia <cite class="ltx_cite ltx_citemacro_citep">(Rieke et al<span class="ltx_text">.</span>, <a href="#bib.bib107" title="" class="ltx_ref">2020</a>; Rehman et al<span class="ltx_text">.</span>, <a href="#bib.bib106" title="" class="ltx_ref">2023</a>)</cite>.
For example, in the United Kingdom, FLIP enables AI researchers to develop clinical applications using NHS patient data without transferring the information outside the hospital network, addressing the challenge of confidentiality in healthcare <cite class="ltx_cite ltx_citemacro_citep">(FLI, <a href="#bib.bib7" title="" class="ltx_ref">[n. d.]</a>)</cite>. In France, the HealthChain consortium <cite class="ltx_cite ltx_citemacro_citep">(hea, <a href="#bib.bib14" title="" class="ltx_ref">[n. d.]</a>)</cite> aims to address the bottleneck in accessing medical data for AI models that could lead to medical breakthroughs. In Germany, the Trustworthy Federated Data Analytics (TFDA) project <cite class="ltx_cite ltx_citemacro_citep">(TFD, <a href="#bib.bib18" title="" class="ltx_ref">[n. d.]</a>)</cite> aims to address the challenges posed by centralized data structures in the context of growing data needs for machine learning. Recognizing the drawbacks and threats associated with data centralization, TFDA focuses on implementing decentralized, cooperative data analytics architectures, specifically within and beyond the Helmholtz research community. The MELLODDY project <cite class="ltx_cite ltx_citemacro_citep">(Heyndrickx et al<span class="ltx_text">.</span>, <a href="#bib.bib61" title="" class="ltx_ref">2023</a>; Oldenhof et al<span class="ltx_text">.</span>, <a href="#bib.bib99" title="" class="ltx_ref">2023</a>)</cite>, co-funded by the European Union and EFPIA companies, has successfully demonstrated the feasibility of large-scale collaborative artificial intelligence (AI) for drug discovery. By leveraging a large collection of small molecules, the project utilized federated and privacy-preserving machine learning to achieve more accurate predictive modeling, leading to potential efficiencies in drug discovery. The German Cancer Consortium’s Joint Imaging Platform (JIP) <cite class="ltx_cite ltx_citemacro_citep">(Scherer et al<span class="ltx_text">.</span>, <a href="#bib.bib112" title="" class="ltx_ref">2020</a>)</cite> is a strategic initiative within the German Cancer Consortium (DKTK) with the goal of establishing a technical infrastructure to facilitate modern and distributed imaging research. Emphasizing the use of contemporary machine learning methods in medical image processing, the project aims to enhance collaboration among clinical sites and support multicenter trials. Internationally, the Federated Tumor Segmentation (FeTS) initiative <cite class="ltx_cite ltx_citemacro_citep">(fet, <a href="#bib.bib9" title="" class="ltx_ref">[n. d.]</a>; Pati et al<span class="ltx_text">.</span>, <a href="#bib.bib103" title="" class="ltx_ref">2021</a>)</cite> is developing one of the largest federations of healthcare institutions. This initiative aims to gain knowledge for tumor boundary detection from diverse patient populations without sharing patient data.In a collaborative effort involving seven clinical institutions worldwide, an early study explored using FL to construct robust medical imaging classification models for breast density based on BI-RADS <cite class="ltx_cite ltx_citemacro_citep">(Roth et al<span class="ltx_text">.</span>, <a href="#bib.bib109" title="" class="ltx_ref">2020</a>)</cite>. Despite significant differences in datasets across sites, including mammography systems, class distribution, and data set size, the results demonstrated successful AI model training in a federated manner.
The EXAM project <cite class="ltx_cite ltx_citemacro_citep">(Dayan et al<span class="ltx_text">.</span>, <a href="#bib.bib38" title="" class="ltx_ref">2021</a>)</cite> aimed to build a common predictive model to estimate the oxygen treatment requirements of patients arriving at the emergency department (ED) with symptoms of COVID-19 for the next 24h and 72h periods. A consortium of 20 hospital sites across the globe participated in this real-world application of FL. Furthermore, institutions such as The American College of Radiology (ACR) enable privacy-preserving AI utilizing federated learning technology <cite class="ltx_cite ltx_citemacro_citep">(acr, <a href="#bib.bib16" title="" class="ltx_ref">[n. d.]</a>)</cite>.</p>
</div>
<div id="S4.SS1.p3" class="ltx_para">
<p id="S4.SS1.p3.1" class="ltx_p">These efforts show the trend within the healthcare industries to decentralize data for AI workflows while keeping regulatory challenges in mind for the benefit of patient privacy. FL technology might be the key to enabling trustworthy AI development, such as diversity <cite class="ltx_cite ltx_citemacro_citep">(Commission et al<span class="ltx_text">.</span>, <a href="#bib.bib36" title="" class="ltx_ref">2019</a>)</cite>.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2. </span>Application of FL in Finance</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">The data privacy and protection laws are becoming ever more restrictive, especially in industries like the Financial sector. This allows consumers and businesses to trust each other to keep the data safe and secure. With traditional ML, businesses dependent on FinTech face several issues, such as getting clearance and lawful consent, the governance of the customers’ data and the time and finally, the cost in collecting and of managing such data. FL provides an efficient way for managing this data by keeping it local, on the financial institutions servers. FL is an encrypted and distributed machine learning approach that allows joint training on decentralized data where participants do not share any of it.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.1" class="ltx_p">One of the most promising application of federated learning in financial services is anti-money laundering (AML). In a typical money laundering scheme, criminals try to conceal the origin, identity, and destination of financial transactions to look normal as they are from a legitimate source. AML solutions allow financial institutions to prevent, detect, investigate and report any activity that is suspicious of money laundering and stop criminals from illegally obtained funds as legitimate income. The estimated amount of money laundered globally in one year is 2 - 5% of global GDP ($800 billion - $2 trillion)<cite class="ltx_cite ltx_citemacro_citep">(UN-, <a href="#bib.bib19" title="" class="ltx_ref">[n. d.]</a>)</cite>. Failure to prevent money laundering can endanger the integrity and stability of global financial system. Financial institutions are required to put strict policies and measures to prevent, detect, and report laundered money and combat these crimes.
However, each financial institution has typically access to its own transnational data and can not prevent and detect complex money laundry cases where the money routes through multiple financial institutions that could look legitimate to some of involved institutions in the chain.
Cross-silo Federated AML can greatly help financial institutions to create better predictive models with broader context for identifying bad actors. Such models learn more global and deeper correlation identifiers for bad actors and money laundry specific actions based on contributed data provided by consortium of financial institutions.</p>
</div>
<div id="S4.SS2.p3" class="ltx_para">
<p id="S4.SS2.p3.1" class="ltx_p">Another application of federated learning is in insurance underwriting. The main use cases for federated learning in insurance include origination- predicting if a person contracts an insurance offer, insurer’s risk assessment, fraud detection, and claim processing. Due to soiled data in different companies on different demographics or customers movement across insurance companies, Insurers can significantly improve their predictive models for these use cases by utilizing federated learning. Claim history processing is of the most challenging use cases that federated learning can lead to more accurate and efficient operations. Insurance companies often need to have access to previous claims history of an insurer in details to give a better pricing or benefits to new clients. However, having access to such historical data in a privacy preserving manner is challenging due to regulations governing the insurance industry. Insurance companies can leverage cross-silo federated learning to privately train their models without compromising customers privacy and satisfying the governing regulations. Such models lead to more accurate offers while helping customers get the benefits of having a long-term history of free claims across different categories.</p>
</div>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3. </span>Application of FL in IoT or at the Edge</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">The Internet of Things (IoT) is the current concept of ubiquitous internet connectivity of all devices (refrigerators, toasters, doorbells, street cameras, …, the list is unending). As these devices suggest the availability of data from these devices from anywhere, the privacy and security of these devices and the data is paramount. However, there is strong interest from companies and individuals to exploit the available data for constructive applications to benefit more than just the immediate use-case and users. One prominent example is the Google keyboard (Gboard) prediction <cite class="ltx_cite ltx_citemacro_citep">(Hard et al<span class="ltx_text">.</span>, <a href="#bib.bib58" title="" class="ltx_ref">2018</a>)</cite>, where Google improves the performance of their mobile keyboard prediction by gaining information from user interaction. However, this example highlights information privacy in that improvements to this technology will benefit all users but users are willing to share only if their privacy is assured. Therefore, FL techniques that exploit data and maintain user and data privacy are attractive for IoT applications <cite class="ltx_cite ltx_citemacro_citep">(Zhang et al<span class="ltx_text">.</span>, <a href="#bib.bib145" title="" class="ltx_ref">2021</a>)</cite>.</p>
</div>
<div id="S4.SS3.p2" class="ltx_para">
<p id="S4.SS3.p2.1" class="ltx_p">In such scenarios and related application domains, it is well understood that communication and computing resources are two of the bottlenecks for federated learning in real-life applications. The devices are often used for tasks other than FL, so the FL task usually competes with these other ones for computing resources, making scheduling and coordinating even more complicated. Asynchronous strategies like PAPAYA<cite class="ltx_cite ltx_citemacro_citep">(Huba et al<span class="ltx_text">.</span>, <a href="#bib.bib64" title="" class="ltx_ref">2022</a>)</cite> appear to address such issues. Other scenarios include heterogeneity in the computing resources <cite class="ltx_cite ltx_citemacro_citep">(Diao et al<span class="ltx_text">.</span>, <a href="#bib.bib39" title="" class="ltx_ref">2021</a>)</cite> or drift in local device clocks <cite class="ltx_cite ltx_citemacro_citep">(Koo et al<span class="ltx_text">.</span>, <a href="#bib.bib75" title="" class="ltx_ref">2009</a>)</cite>, leading to asynchrony caused by varying compute and resulting in delays in the aggregation step. Methods to account for or dynamically adapt to changing available resources will greatly enhance the utility of FL techniques in these scenarios. The increased need for bandwidth for FL iterations has led to significant research efforts in reducing it. Methods combining optimizers such as FedAvg with sparsification and/or quantization of model updates to a small number of bits have demonstrated significant reductions in communication overhead. However, it still remains an open research question how communication overheads can be further reduced, and whether any of these methods or their combinations can come close to providing optimal trade-offs between communication and accuracy in federated learning. For example, the Fed-ET approach is promising where smaller models are communicated <cite class="ltx_cite ltx_citemacro_citep">(Cho et al<span class="ltx_text">.</span>, <a href="#bib.bib35" title="" class="ltx_ref">2022</a>)</cite>. Another class of approach to maximizing bandwidth usage in FL approaches include device selection <cite class="ltx_cite ltx_citemacro_citep">(Perazzone et al<span class="ltx_text">.</span>, <a href="#bib.bib104" title="" class="ltx_ref">2022</a>)</cite>. While efforts in these situations are motivated by increasing communications efficiency, device selection methods can potentially provide device privacy in terms of revealing which nodes are contributing to FL process. Moreover, there has also been recent work that allows for the control information exchange to limit communications, but can similarly be used to provide some privacy to node utility to FL algorithms <cite class="ltx_cite ltx_citemacro_citep">(Wang et al<span class="ltx_text">.</span>, <a href="#bib.bib129" title="" class="ltx_ref">2023</a>)</cite>.</p>
</div>
<div id="S4.SS3.p3" class="ltx_para">
<p id="S4.SS3.p3.1" class="ltx_p">Additionally, IoT has been promoted as a use-case for edge networks where networks are bandwidth-limited and storage and compute is also limited. These systems operate in a variety of environments often characterized by having stringent operational requirements despite having to cope with sophisticated adversarial influences and constraints in both computational and network resources. These environments include resource-constraints inhibiting information exchange to other nodes, specifically a central node with which centralized computation and decisions can be conducted. Federated approaches have been proposed for use in sensor networks, swarms of unmanned aerial vehicle and on coalition networks for shared situational awareness. They have also been proposed for FL at the edge by reducing the network overhead incurred by such learning processes <cite class="ltx_cite ltx_citemacro_citep">(Wang et al<span class="ltx_text">.</span>, <a href="#bib.bib130" title="" class="ltx_ref">2019b</a>)</cite>. The promise of IoT and edge computing will continue to be revealed, with FL techniques potentially as a main driver of the technologies.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5. </span>Privacy-Related Policies</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">Most of the existing regulations on safeguarding consumers privacy, both nationally and internationally were conceived in a pre-AI/ML era and have not been able to keep up with the rapid evolution of AI/Ml and their privacy implications. The European Union’s General Data Protection Regulation (”GDPR”) <cite class="ltx_cite ltx_citemacro_citep">(GDP, <a href="#bib.bib11" title="" class="ltx_ref">[n. d.]</a>)</cite> governs data protection and privacy for all citizens within the EU and imposes strict obligations on data controllers and processors. GDPR contains the <span id="S5.p1.1.1" class="ltx_text ltx_font_italic">principle of data minimization</span> in article 5.1 (c) which requires that the data that are not necessary to achieve the intended purpose cannot be lawfully collected, stored or otherwise processed. Since federated learning restricts the transfer of raw data to a central location, it provides more compliance with the principle of data minimization than other approaches that do require the transfer of all raw date to a central location to train a model. Federated learning also protects the collected data from unwanted processing that are not compliant with the collection purpose satisfying the <span id="S5.p1.1.2" class="ltx_text ltx_font_italic">principle of purpose limitation</span>, as described in article 5.1.(b).</p>
</div>
<div id="S5.p2" class="ltx_para">
<p id="S5.p2.1" class="ltx_p">In the United States, the state of Privacy and AI laws is tracked by the EPIC project which shows recent large number of states effective privacy laws <cite class="ltx_cite ltx_citemacro_citep">(EPI, <a href="#bib.bib6" title="" class="ltx_ref">[n. d.]</a>)</cite>. Each of these privacy laws has specific requirements when accessing and processing personal data. Even FTC is enforcing the same privacy rights for companies using AI <cite class="ltx_cite ltx_citemacro_citep">(FTC, <a href="#bib.bib10" title="" class="ltx_ref">[n. d.]</a>)</cite>.
At the federal level, sector-specific privacy polices in the US such as Graham-Leach-Bliley Act (GLBA) <cite class="ltx_cite ltx_citemacro_citep">(GLB, <a href="#bib.bib12" title="" class="ltx_ref">[n. d.]</a>)</cite> for financial data or Health Insurance Portability and Accountability Act (HIPAA) <cite class="ltx_cite ltx_citemacro_citep">(HIP, <a href="#bib.bib13" title="" class="ltx_ref">[n. d.]</a>)</cite> for medical date provide consumers with limited protection scope when it comes to using AI and ML.
Recently, US introduced H.R. 8152-The American Data Privacy and Protection Act <cite class="ltx_cite ltx_citemacro_citep">(HR8, <a href="#bib.bib15" title="" class="ltx_ref">[n. d.]</a>)</cite>-to catch up with various amendments proposed in EU on AI/ML workloads by extending the covered algorithm to AI/ML space. Some states also patched their existing policies such as California Privacy Rights Act (CPRA) <cite class="ltx_cite ltx_citemacro_citep">(CPR, <a href="#bib.bib5" title="" class="ltx_ref">[n. d.]</a>)</cite> amendments to the CCPA <cite class="ltx_cite ltx_citemacro_citep">(CCP, <a href="#bib.bib4" title="" class="ltx_ref">[n. d.]</a>)</cite>
or
Texas Data Privacy
and Security Act (TDPSA) <cite class="ltx_cite ltx_citemacro_citep">(tex, <a href="#bib.bib17" title="" class="ltx_ref">[n. d.]</a>)</cite>.</p>
</div>
<div id="S5.p3" class="ltx_para">
<p id="S5.p3.1" class="ltx_p">GenAI’s remarkable capacity to analyze data and make complex analyses further amplifies privacy concerns.
There is clear a privacy gaps in existing privacy policies as it relates to AI systems. Most of these policies and regulations were proposed pre-AI and even newer ones per Gen AI where there has been less information on privacy implications of these systems. Such gap may pose significant challenges to privacy laws and they will need further amendments to address emerging privacy concerns from Gen AI.</p>
</div>
<div id="S5.p4" class="ltx_para">
<p id="S5.p4.1" class="ltx_p">The recent AI Foundation Model Transparency Act <cite class="ltx_cite ltx_citemacro_citep">(AIF, <a href="#bib.bib2" title="" class="ltx_ref">[n. d.]</a>)</cite> mandates FTC and NIST to establish standards for data sharing by foundation model deployers. This legislation goal is to empower consumers to make well informed decisions when they interact with AI. The Algorithmic Accountability Act of 2023 <cite class="ltx_cite ltx_citemacro_citep">(AIA, <a href="#bib.bib3" title="" class="ltx_ref">[n. d.]</a>)</cite> also requires companies to assess the impacts of the AI systems on consumer privacy and give users choices when they interact with AI systems.</p>
</div>
<div id="S5.p5" class="ltx_para">
<p id="S5.p5.1" class="ltx_p">These regulations mostly require keeping the data in its location and restrict its processing based on the intended collection purposes. Federated learning is a potential solution to facilitate compliance with these privacy laws.</p>
</div>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6. </span>Privacy Attacks</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">In this section, we first discuss the leading categories of privacy attacks against FL. We summarize this, with the most significant attributes of each attack type, in Table <a href="#S6.T3" title="Table 3 ‣ 6.1. Data Reconstruction Attacks ‣ 6. Privacy Attacks ‣ Federated Learning Privacy: Attacks, Defenses, Applications, and Policy Landscape — A Survey" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>.</p>
</div>
<section id="S6.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.1. </span>Data Reconstruction Attacks</h3>

<figure id="S6.F1" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S6.F1.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2405.03636/assets/x1.png" id="S6.F1.sf1.g1" class="ltx_graphics ltx_img_square" width="226" height="226" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(a) </span>Ground truth</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S6.F1.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2405.03636/assets/x2.png" id="S6.F1.sf2.g1" class="ltx_graphics ltx_img_square" width="226" height="226" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(b) </span>Reconstruction</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1. </span> Images reconstructed using LOKI <cite class="ltx_cite ltx_citemacro_citep">(Zhao et al<span class="ltx_text">.</span>, <a href="#bib.bib149" title="" class="ltx_ref">2023b</a>)</cite>, a linear layer leakage attack, on a batch of 64 CIFAR-10 images. FedAvg with 8 local iterations of mini-batch size 8 used. Out of 64 images, 55 are reconstructed successfully with high visual recognizability.</figcaption>
</figure>
<figure id="S6.F2" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S6.F2.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2405.03636/assets/x3.png" id="S6.F2.sf1.g1" class="ltx_graphics ltx_img_landscape" width="216" height="108" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(a) </span>Ground truth</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S6.F2.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2405.03636/assets/x4.png" id="S6.F2.sf2.g1" class="ltx_graphics ltx_img_landscape" width="216" height="108" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(b) </span>Reconstruction</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2. </span> Images reconstructed using Inverting Gradients <cite class="ltx_cite ltx_citemacro_citep">(Geiping et al<span class="ltx_text">.</span>, <a href="#bib.bib55" title="" class="ltx_ref">2020</a>)</cite>, an optimization attack, on a batch of 8 CIFAR-10 images in FedSGD. Images have high visual recognizability.</figcaption>
</figure>
<figure id="S6.F3" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S6.F3.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2405.03636/assets/x5.png" id="S6.F3.sf1.g1" class="ltx_graphics ltx_img_square" width="216" height="216" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(a) </span>Ground truth</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S6.F3.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2405.03636/assets/x6.png" id="S6.F3.sf2.g1" class="ltx_graphics ltx_img_square" width="216" height="216" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(b) </span>Reconstruction</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3. </span> Images reconstructed using Inverting Gradients <cite class="ltx_cite ltx_citemacro_citep">(Geiping et al<span class="ltx_text">.</span>, <a href="#bib.bib55" title="" class="ltx_ref">2020</a>)</cite>, an optimization attack, on a batch of 16 CIFAR-10 images in FedSGD. Images are much less visually recognizability, with a few containing some recognizable parts.</figcaption>
</figure>
<figure id="S6.T3" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 3. </span> Summary of privacy attacks in federated learning</figcaption>
<table id="S6.T3.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S6.T3.1.1.1" class="ltx_tr">
<th id="S6.T3.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t"><span id="S6.T3.1.1.1.1.1" class="ltx_text ltx_font_bold">Attack class</span></th>
<th id="S6.T3.1.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t"><span id="S6.T3.1.1.1.2.1" class="ltx_text ltx_font_bold">Summary</span></th>
<th id="S6.T3.1.1.1.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t"><span id="S6.T3.1.1.1.3.1" class="ltx_text ltx_font_bold">Sub-category</span></th>
<th id="S6.T3.1.1.1.4" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t"><span id="S6.T3.1.1.1.4.1" class="ltx_text ltx_font_bold">Citation</span></th>
<th id="S6.T3.1.1.1.5" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t"><span id="S6.T3.1.1.1.5.1" class="ltx_text ltx_font_bold">Requirements</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S6.T3.1.2.1" class="ltx_tr">
<td id="S6.T3.1.2.1.1" class="ltx_td ltx_align_left ltx_border_t">Data reconstruction</td>
<td id="S6.T3.1.2.1.2" class="ltx_td ltx_align_left ltx_border_t" rowspan="4"><span id="S6.T3.1.2.1.2.1" class="ltx_text">
<span id="S6.T3.1.2.1.2.1.1" class="ltx_tabular ltx_align_middle">
<span id="S6.T3.1.2.1.2.1.1.1" class="ltx_tr">
<span id="S6.T3.1.2.1.2.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Attacker aims to</span></span>
<span id="S6.T3.1.2.1.2.1.1.2" class="ltx_tr">
<span id="S6.T3.1.2.1.2.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">directly reconstruct</span></span>
<span id="S6.T3.1.2.1.2.1.1.3" class="ltx_tr">
<span id="S6.T3.1.2.1.2.1.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left">the client private</span></span>
<span id="S6.T3.1.2.1.2.1.1.4" class="ltx_tr">
<span id="S6.T3.1.2.1.2.1.1.4.1" class="ltx_td ltx_nopad_r ltx_align_left">data or a</span></span>
<span id="S6.T3.1.2.1.2.1.1.5" class="ltx_tr">
<span id="S6.T3.1.2.1.2.1.1.5.1" class="ltx_td ltx_nopad_r ltx_align_left">representation of</span></span>
<span id="S6.T3.1.2.1.2.1.1.6" class="ltx_tr">
<span id="S6.T3.1.2.1.2.1.1.6.1" class="ltx_td ltx_nopad_r ltx_align_left">the private data.</span></span>
</span></span></td>
<td id="S6.T3.1.2.1.3" class="ltx_td ltx_align_left ltx_border_t">Gradient inversion</td>
<td id="S6.T3.1.2.1.4" class="ltx_td ltx_align_left ltx_border_t"><cite class="ltx_cite ltx_citemacro_citep">(Zhu et al<span class="ltx_text">.</span>, <a href="#bib.bib151" title="" class="ltx_ref">2019</a>; Zhao et al<span class="ltx_text">.</span>, <a href="#bib.bib146" title="" class="ltx_ref">2020</a>; Geiping et al<span class="ltx_text">.</span>, <a href="#bib.bib55" title="" class="ltx_ref">2020</a>; Yin et al<span class="ltx_text">.</span>, <a href="#bib.bib137" title="" class="ltx_ref">2021a</a>)</cite></td>
<td id="S6.T3.1.2.1.5" class="ltx_td ltx_align_left ltx_border_t">
<table id="S6.T3.1.2.1.5.1" class="ltx_tabular ltx_align_middle">
<tr id="S6.T3.1.2.1.5.1.1" class="ltx_tr">
<td id="S6.T3.1.2.1.5.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Access to model and</td>
</tr>
<tr id="S6.T3.1.2.1.5.1.2" class="ltx_tr">
<td id="S6.T3.1.2.1.5.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">individual updates.</td>
</tr>
</table>
</td>
</tr>
<tr id="S6.T3.1.3.2" class="ltx_tr">
<td id="S6.T3.1.3.2.1" class="ltx_td"></td>
<td id="S6.T3.1.3.2.2" class="ltx_td ltx_align_left ltx_border_t">
<table id="S6.T3.1.3.2.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S6.T3.1.3.2.2.1.1" class="ltx_tr">
<td id="S6.T3.1.3.2.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Linear layer</td>
</tr>
<tr id="S6.T3.1.3.2.2.1.2" class="ltx_tr">
<td id="S6.T3.1.3.2.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">leakage</td>
</tr>
</table>
</td>
<td id="S6.T3.1.3.2.3" class="ltx_td ltx_align_left ltx_border_t"><cite class="ltx_cite ltx_citemacro_citep">(Zhao et al<span class="ltx_text">.</span>, <a href="#bib.bib149" title="" class="ltx_ref">2023b</a>; Fowl et al<span class="ltx_text">.</span>, <a href="#bib.bib51" title="" class="ltx_ref">2022</a>; Boenisch et al<span class="ltx_text">.</span>, <a href="#bib.bib23" title="" class="ltx_ref">2023</a>)</cite></td>
<td id="S6.T3.1.3.2.4" class="ltx_td ltx_align_left ltx_border_t">
<table id="S6.T3.1.3.2.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S6.T3.1.3.2.4.1.1" class="ltx_tr">
<td id="S6.T3.1.3.2.4.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Modification to the</td>
</tr>
<tr id="S6.T3.1.3.2.4.1.2" class="ltx_tr">
<td id="S6.T3.1.3.2.4.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">network parameters</td>
</tr>
<tr id="S6.T3.1.3.2.4.1.3" class="ltx_tr">
<td id="S6.T3.1.3.2.4.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left">and/or architecture.</td>
</tr>
</table>
</td>
</tr>
<tr id="S6.T3.1.4.3" class="ltx_tr">
<td id="S6.T3.1.4.3.1" class="ltx_td"></td>
<td id="S6.T3.1.4.3.2" class="ltx_td ltx_align_left ltx_border_t">GAN-based</td>
<td id="S6.T3.1.4.3.3" class="ltx_td ltx_align_left ltx_border_t"><cite class="ltx_cite ltx_citemacro_citep">(Hitaj et al<span class="ltx_text">.</span>, <a href="#bib.bib63" title="" class="ltx_ref">2017</a>; Wang et al<span class="ltx_text">.</span>, <a href="#bib.bib132" title="" class="ltx_ref">2019a</a>)</cite></td>
<td id="S6.T3.1.4.3.4" class="ltx_td ltx_align_left ltx_border_t">
<table id="S6.T3.1.4.3.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S6.T3.1.4.3.4.1.1" class="ltx_tr">
<td id="S6.T3.1.4.3.4.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Clients target a</td>
</tr>
<tr id="S6.T3.1.4.3.4.1.2" class="ltx_tr">
<td id="S6.T3.1.4.3.4.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">specific class by</td>
</tr>
<tr id="S6.T3.1.4.3.4.1.3" class="ltx_tr">
<td id="S6.T3.1.4.3.4.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left">sending malicious</td>
</tr>
<tr id="S6.T3.1.4.3.4.1.4" class="ltx_tr">
<td id="S6.T3.1.4.3.4.1.4.1" class="ltx_td ltx_nopad_r ltx_align_left">updates.</td>
</tr>
</table>
</td>
</tr>
<tr id="S6.T3.1.5.4" class="ltx_tr">
<td id="S6.T3.1.5.4.1" class="ltx_td"></td>
<td id="S6.T3.1.5.4.2" class="ltx_td ltx_align_left ltx_border_t">Other</td>
<td id="S6.T3.1.5.4.3" class="ltx_td ltx_align_left ltx_border_t"><cite class="ltx_cite ltx_citemacro_citep">(Wen et al<span class="ltx_text">.</span>, <a href="#bib.bib134" title="" class="ltx_ref">2022</a>; Pasquini et al<span class="ltx_text">.</span>, <a href="#bib.bib102" title="" class="ltx_ref">2022</a>; Lam et al<span class="ltx_text">.</span>, <a href="#bib.bib77" title="" class="ltx_ref">2021</a>)</cite></td>
<td id="S6.T3.1.5.4.4" class="ltx_td ltx_align_left ltx_border_t">
<table id="S6.T3.1.5.4.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S6.T3.1.5.4.4.1.1" class="ltx_tr">
<td id="S6.T3.1.5.4.4.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Varies based on</td>
</tr>
<tr id="S6.T3.1.5.4.4.1.2" class="ltx_tr">
<td id="S6.T3.1.5.4.4.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">attack. Attacker may</td>
</tr>
<tr id="S6.T3.1.5.4.4.1.3" class="ltx_tr">
<td id="S6.T3.1.5.4.4.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left">need to modify the</td>
</tr>
<tr id="S6.T3.1.5.4.4.1.4" class="ltx_tr">
<td id="S6.T3.1.5.4.4.1.4.1" class="ltx_td ltx_nopad_r ltx_align_left">model parameters,</td>
</tr>
<tr id="S6.T3.1.5.4.4.1.5" class="ltx_tr">
<td id="S6.T3.1.5.4.4.1.5.1" class="ltx_td ltx_nopad_r ltx_align_left">know additional</td>
</tr>
<tr id="S6.T3.1.5.4.4.1.6" class="ltx_tr">
<td id="S6.T3.1.5.4.4.1.6.1" class="ltx_td ltx_nopad_r ltx_align_left">training information,</td>
</tr>
<tr id="S6.T3.1.5.4.4.1.7" class="ltx_tr">
<td id="S6.T3.1.5.4.4.1.7.1" class="ltx_td ltx_nopad_r ltx_align_left">or send clients</td>
</tr>
<tr id="S6.T3.1.5.4.4.1.8" class="ltx_tr">
<td id="S6.T3.1.5.4.4.1.8.1" class="ltx_td ltx_nopad_r ltx_align_left">different updates.</td>
</tr>
</table>
</td>
</tr>
<tr id="S6.T3.1.6.5" class="ltx_tr">
<td id="S6.T3.1.6.5.1" class="ltx_td ltx_align_left ltx_border_t">Membership inference</td>
<td id="S6.T3.1.6.5.2" class="ltx_td ltx_align_left ltx_border_t">
<table id="S6.T3.1.6.5.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S6.T3.1.6.5.2.1.1" class="ltx_tr">
<td id="S6.T3.1.6.5.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Attacker infers if a</td>
</tr>
<tr id="S6.T3.1.6.5.2.1.2" class="ltx_tr">
<td id="S6.T3.1.6.5.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">sample was used in</td>
</tr>
<tr id="S6.T3.1.6.5.2.1.3" class="ltx_tr">
<td id="S6.T3.1.6.5.2.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left">the training of the</td>
</tr>
<tr id="S6.T3.1.6.5.2.1.4" class="ltx_tr">
<td id="S6.T3.1.6.5.2.1.4.1" class="ltx_td ltx_nopad_r ltx_align_left">model.</td>
</tr>
</table>
</td>
<td id="S6.T3.1.6.5.3" class="ltx_td ltx_border_t"></td>
<td id="S6.T3.1.6.5.4" class="ltx_td ltx_align_left ltx_border_t"><cite class="ltx_cite ltx_citemacro_citep">(Song et al<span class="ltx_text">.</span>, <a href="#bib.bib122" title="" class="ltx_ref">2019</a>; Li et al<span class="ltx_text">.</span>, <a href="#bib.bib80" title="" class="ltx_ref">2022a</a>; Nasr et al<span class="ltx_text">.</span>, <a href="#bib.bib98" title="" class="ltx_ref">2019</a>; Zari et al<span class="ltx_text">.</span>, <a href="#bib.bib141" title="" class="ltx_ref">2021</a>; Melis et al<span class="ltx_text">.</span>, <a href="#bib.bib92" title="" class="ltx_ref">2019</a>)</cite></td>
<td id="S6.T3.1.6.5.5" class="ltx_td ltx_align_left ltx_border_t">
<table id="S6.T3.1.6.5.5.1" class="ltx_tabular ltx_align_middle">
<tr id="S6.T3.1.6.5.5.1.1" class="ltx_tr">
<td id="S6.T3.1.6.5.5.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Most require access</td>
</tr>
<tr id="S6.T3.1.6.5.5.1.2" class="ltx_tr">
<td id="S6.T3.1.6.5.5.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">to training data from</td>
</tr>
<tr id="S6.T3.1.6.5.5.1.3" class="ltx_tr">
<td id="S6.T3.1.6.5.5.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left">the overall</td>
</tr>
<tr id="S6.T3.1.6.5.5.1.4" class="ltx_tr">
<td id="S6.T3.1.6.5.5.1.4.1" class="ltx_td ltx_nopad_r ltx_align_left">distribution. Some</td>
</tr>
<tr id="S6.T3.1.6.5.5.1.5" class="ltx_tr">
<td id="S6.T3.1.6.5.5.1.5.1" class="ltx_td ltx_nopad_r ltx_align_left">attacks require white-</td>
</tr>
<tr id="S6.T3.1.6.5.5.1.6" class="ltx_tr">
<td id="S6.T3.1.6.5.5.1.6.1" class="ltx_td ltx_nopad_r ltx_align_left">box access to model</td>
</tr>
<tr id="S6.T3.1.6.5.5.1.7" class="ltx_tr">
<td id="S6.T3.1.6.5.5.1.7.1" class="ltx_td ltx_nopad_r ltx_align_left">or the ability to send</td>
</tr>
<tr id="S6.T3.1.6.5.5.1.8" class="ltx_tr">
<td id="S6.T3.1.6.5.5.1.8.1" class="ltx_td ltx_nopad_r ltx_align_left">malicious updates.</td>
</tr>
</table>
</td>
</tr>
<tr id="S6.T3.1.7.6" class="ltx_tr">
<td id="S6.T3.1.7.6.1" class="ltx_td ltx_align_left ltx_border_t">Property inference</td>
<td id="S6.T3.1.7.6.2" class="ltx_td ltx_align_left ltx_border_t">
<table id="S6.T3.1.7.6.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S6.T3.1.7.6.2.1.1" class="ltx_tr">
<td id="S6.T3.1.7.6.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Attacker learns</td>
</tr>
<tr id="S6.T3.1.7.6.2.1.2" class="ltx_tr">
<td id="S6.T3.1.7.6.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">about sensitive</td>
</tr>
<tr id="S6.T3.1.7.6.2.1.3" class="ltx_tr">
<td id="S6.T3.1.7.6.2.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left">properties within</td>
</tr>
<tr id="S6.T3.1.7.6.2.1.4" class="ltx_tr">
<td id="S6.T3.1.7.6.2.1.4.1" class="ltx_td ltx_nopad_r ltx_align_left">the training set</td>
</tr>
<tr id="S6.T3.1.7.6.2.1.5" class="ltx_tr">
<td id="S6.T3.1.7.6.2.1.5.1" class="ltx_td ltx_nopad_r ltx_align_left">(e.g., race, gender,</td>
</tr>
<tr id="S6.T3.1.7.6.2.1.6" class="ltx_tr">
<td id="S6.T3.1.7.6.2.1.6.1" class="ltx_td ltx_nopad_r ltx_align_left">age, etc.)</td>
</tr>
</table>
</td>
<td id="S6.T3.1.7.6.3" class="ltx_td ltx_border_t"></td>
<td id="S6.T3.1.7.6.4" class="ltx_td ltx_align_left ltx_border_t"><cite class="ltx_cite ltx_citemacro_citep">(Fredrikson et al<span class="ltx_text">.</span>, <a href="#bib.bib52" title="" class="ltx_ref">2015</a>; Mehnaz et al<span class="ltx_text">.</span>, <a href="#bib.bib91" title="" class="ltx_ref">2022</a>; Dibbo et al<span class="ltx_text">.</span>, <a href="#bib.bib40" title="" class="ltx_ref">2023</a>; Ganju et al<span class="ltx_text">.</span>, <a href="#bib.bib54" title="" class="ltx_ref">2018</a>)</cite></td>
<td id="S6.T3.1.7.6.5" class="ltx_td ltx_align_left ltx_border_t">
<table id="S6.T3.1.7.6.5.1" class="ltx_tabular ltx_align_middle">
<tr id="S6.T3.1.7.6.5.1.1" class="ltx_tr">
<td id="S6.T3.1.7.6.5.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Attacker has black-</td>
</tr>
<tr id="S6.T3.1.7.6.5.1.2" class="ltx_tr">
<td id="S6.T3.1.7.6.5.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">box access to the</td>
</tr>
<tr id="S6.T3.1.7.6.5.1.3" class="ltx_tr">
<td id="S6.T3.1.7.6.5.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left">model and can access</td>
</tr>
<tr id="S6.T3.1.7.6.5.1.4" class="ltx_tr">
<td id="S6.T3.1.7.6.5.1.4.1" class="ltx_td ltx_nopad_r ltx_align_left">the output. They have</td>
</tr>
<tr id="S6.T3.1.7.6.5.1.5" class="ltx_tr">
<td id="S6.T3.1.7.6.5.1.5.1" class="ltx_td ltx_nopad_r ltx_align_left">access to other</td>
</tr>
<tr id="S6.T3.1.7.6.5.1.6" class="ltx_tr">
<td id="S6.T3.1.7.6.5.1.6.1" class="ltx_td ltx_nopad_r ltx_align_left">attributes besides the</td>
</tr>
<tr id="S6.T3.1.7.6.5.1.7" class="ltx_tr">
<td id="S6.T3.1.7.6.5.1.7.1" class="ltx_td ltx_nopad_r ltx_align_left">targeted one.</td>
</tr>
</table>
</td>
</tr>
<tr id="S6.T3.1.8.7" class="ltx_tr">
<td id="S6.T3.1.8.7.1" class="ltx_td ltx_align_left ltx_border_b ltx_border_t">Model extraction</td>
<td id="S6.T3.1.8.7.2" class="ltx_td ltx_align_left ltx_border_b ltx_border_t">
<table id="S6.T3.1.8.7.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S6.T3.1.8.7.2.1.1" class="ltx_tr">
<td id="S6.T3.1.8.7.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Attacker wants to</td>
</tr>
<tr id="S6.T3.1.8.7.2.1.2" class="ltx_tr">
<td id="S6.T3.1.8.7.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">steal functionality</td>
</tr>
<tr id="S6.T3.1.8.7.2.1.3" class="ltx_tr">
<td id="S6.T3.1.8.7.2.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left">of a model. This can</td>
</tr>
<tr id="S6.T3.1.8.7.2.1.4" class="ltx_tr">
<td id="S6.T3.1.8.7.2.1.4.1" class="ltx_td ltx_nopad_r ltx_align_left">be the parameters,</td>
</tr>
<tr id="S6.T3.1.8.7.2.1.5" class="ltx_tr">
<td id="S6.T3.1.8.7.2.1.5.1" class="ltx_td ltx_nopad_r ltx_align_left">hyperparameters, etc</td>
</tr>
</table>
</td>
<td id="S6.T3.1.8.7.3" class="ltx_td ltx_border_b ltx_border_t"></td>
<td id="S6.T3.1.8.7.4" class="ltx_td ltx_align_left ltx_border_b ltx_border_t"><cite class="ltx_cite ltx_citemacro_citep">(Tramèr et al<span class="ltx_text">.</span>, <a href="#bib.bib126" title="" class="ltx_ref">2016</a>; Wang and Gong, <a href="#bib.bib128" title="" class="ltx_ref">2018</a>; Orekondy et al<span class="ltx_text">.</span>, <a href="#bib.bib101" title="" class="ltx_ref">2019</a>)</cite></td>
<td id="S6.T3.1.8.7.5" class="ltx_td ltx_align_left ltx_border_b ltx_border_t">
<table id="S6.T3.1.8.7.5.1" class="ltx_tabular ltx_align_middle">
<tr id="S6.T3.1.8.7.5.1.1" class="ltx_tr">
<td id="S6.T3.1.8.7.5.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Attacker needs black-</td>
</tr>
<tr id="S6.T3.1.8.7.5.1.2" class="ltx_tr">
<td id="S6.T3.1.8.7.5.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">box access to the</td>
</tr>
<tr id="S6.T3.1.8.7.5.1.3" class="ltx_tr">
<td id="S6.T3.1.8.7.5.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left">model in order to</td>
</tr>
<tr id="S6.T3.1.8.7.5.1.4" class="ltx_tr">
<td id="S6.T3.1.8.7.5.1.4.1" class="ltx_td ltx_nopad_r ltx_align_left">query the model and</td>
</tr>
<tr id="S6.T3.1.8.7.5.1.5" class="ltx_tr">
<td id="S6.T3.1.8.7.5.1.5.1" class="ltx_td ltx_nopad_r ltx_align_left">observe the outputs.</td>
</tr>
</table>
</td>
</tr>
</tbody>
</table>
</figure>
<section id="S6.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">6.1.1. </span>Optimization-based.</h4>

<div id="S6.SS1.SSS1.p1" class="ltx_para ltx_noindent">
<p id="S6.SS1.SSS1.p1.8" class="ltx_p">Optimization (a.k.a. gradient inversion) approaches have shown great success in leaking data from individual updates, especially with smaller batch sizes. These attacks typically operate under the threat model of an honest-but-curious server or an external attacker that has access to the model and individual gradients from each client. With only this information, the attacker initializes some dummy data and computes the gradient of that data on the model.</p>
<table id="S6.E5" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left"><span class="ltx_tag ltx_tag_equation ltx_align_left">(5)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S6.E5.m1.4" class="ltx_Math" alttext="x^{*}=\arg\min_{x}||\nabla L(x,y,\theta)-\nabla W||_{2}" display="block"><semantics id="S6.E5.m1.4a"><mrow id="S6.E5.m1.4.4" xref="S6.E5.m1.4.4.cmml"><msup id="S6.E5.m1.4.4.3" xref="S6.E5.m1.4.4.3.cmml"><mi id="S6.E5.m1.4.4.3.2" xref="S6.E5.m1.4.4.3.2.cmml">x</mi><mo id="S6.E5.m1.4.4.3.3" xref="S6.E5.m1.4.4.3.3.cmml">∗</mo></msup><mo id="S6.E5.m1.4.4.2" xref="S6.E5.m1.4.4.2.cmml">=</mo><mrow id="S6.E5.m1.4.4.1" xref="S6.E5.m1.4.4.1.cmml"><mrow id="S6.E5.m1.4.4.1.3" xref="S6.E5.m1.4.4.1.3.cmml"><mi id="S6.E5.m1.4.4.1.3.1" xref="S6.E5.m1.4.4.1.3.1.cmml">arg</mi><mo lspace="0.167em" id="S6.E5.m1.4.4.1.3a" xref="S6.E5.m1.4.4.1.3.cmml">⁡</mo><munder id="S6.E5.m1.4.4.1.3.2" xref="S6.E5.m1.4.4.1.3.2.cmml"><mi id="S6.E5.m1.4.4.1.3.2.2" xref="S6.E5.m1.4.4.1.3.2.2.cmml">min</mi><mi id="S6.E5.m1.4.4.1.3.2.3" xref="S6.E5.m1.4.4.1.3.2.3.cmml">x</mi></munder></mrow><mo lspace="0em" rspace="0em" id="S6.E5.m1.4.4.1.2" xref="S6.E5.m1.4.4.1.2.cmml">​</mo><msub id="S6.E5.m1.4.4.1.1" xref="S6.E5.m1.4.4.1.1.cmml"><mrow id="S6.E5.m1.4.4.1.1.1.1" xref="S6.E5.m1.4.4.1.1.1.2.cmml"><mo stretchy="false" id="S6.E5.m1.4.4.1.1.1.1.2" xref="S6.E5.m1.4.4.1.1.1.2.1.cmml">‖</mo><mrow id="S6.E5.m1.4.4.1.1.1.1.1" xref="S6.E5.m1.4.4.1.1.1.1.1.cmml"><mrow id="S6.E5.m1.4.4.1.1.1.1.1.2" xref="S6.E5.m1.4.4.1.1.1.1.1.2.cmml"><mrow id="S6.E5.m1.4.4.1.1.1.1.1.2.2" xref="S6.E5.m1.4.4.1.1.1.1.1.2.2.cmml"><mo rspace="0.167em" id="S6.E5.m1.4.4.1.1.1.1.1.2.2.1" xref="S6.E5.m1.4.4.1.1.1.1.1.2.2.1.cmml">∇</mo><mi id="S6.E5.m1.4.4.1.1.1.1.1.2.2.2" xref="S6.E5.m1.4.4.1.1.1.1.1.2.2.2.cmml">L</mi></mrow><mo lspace="0em" rspace="0em" id="S6.E5.m1.4.4.1.1.1.1.1.2.1" xref="S6.E5.m1.4.4.1.1.1.1.1.2.1.cmml">​</mo><mrow id="S6.E5.m1.4.4.1.1.1.1.1.2.3.2" xref="S6.E5.m1.4.4.1.1.1.1.1.2.3.1.cmml"><mo stretchy="false" id="S6.E5.m1.4.4.1.1.1.1.1.2.3.2.1" xref="S6.E5.m1.4.4.1.1.1.1.1.2.3.1.cmml">(</mo><mi id="S6.E5.m1.1.1" xref="S6.E5.m1.1.1.cmml">x</mi><mo id="S6.E5.m1.4.4.1.1.1.1.1.2.3.2.2" xref="S6.E5.m1.4.4.1.1.1.1.1.2.3.1.cmml">,</mo><mi id="S6.E5.m1.2.2" xref="S6.E5.m1.2.2.cmml">y</mi><mo id="S6.E5.m1.4.4.1.1.1.1.1.2.3.2.3" xref="S6.E5.m1.4.4.1.1.1.1.1.2.3.1.cmml">,</mo><mi id="S6.E5.m1.3.3" xref="S6.E5.m1.3.3.cmml">θ</mi><mo stretchy="false" id="S6.E5.m1.4.4.1.1.1.1.1.2.3.2.4" xref="S6.E5.m1.4.4.1.1.1.1.1.2.3.1.cmml">)</mo></mrow></mrow><mo id="S6.E5.m1.4.4.1.1.1.1.1.1" xref="S6.E5.m1.4.4.1.1.1.1.1.1.cmml">−</mo><mrow id="S6.E5.m1.4.4.1.1.1.1.1.3" xref="S6.E5.m1.4.4.1.1.1.1.1.3.cmml"><mo rspace="0.167em" id="S6.E5.m1.4.4.1.1.1.1.1.3.1" xref="S6.E5.m1.4.4.1.1.1.1.1.3.1.cmml">∇</mo><mi id="S6.E5.m1.4.4.1.1.1.1.1.3.2" xref="S6.E5.m1.4.4.1.1.1.1.1.3.2.cmml">W</mi></mrow></mrow><mo stretchy="false" id="S6.E5.m1.4.4.1.1.1.1.3" xref="S6.E5.m1.4.4.1.1.1.2.1.cmml">‖</mo></mrow><mn id="S6.E5.m1.4.4.1.1.3" xref="S6.E5.m1.4.4.1.1.3.cmml">2</mn></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S6.E5.m1.4b"><apply id="S6.E5.m1.4.4.cmml" xref="S6.E5.m1.4.4"><eq id="S6.E5.m1.4.4.2.cmml" xref="S6.E5.m1.4.4.2"></eq><apply id="S6.E5.m1.4.4.3.cmml" xref="S6.E5.m1.4.4.3"><csymbol cd="ambiguous" id="S6.E5.m1.4.4.3.1.cmml" xref="S6.E5.m1.4.4.3">superscript</csymbol><ci id="S6.E5.m1.4.4.3.2.cmml" xref="S6.E5.m1.4.4.3.2">𝑥</ci><times id="S6.E5.m1.4.4.3.3.cmml" xref="S6.E5.m1.4.4.3.3"></times></apply><apply id="S6.E5.m1.4.4.1.cmml" xref="S6.E5.m1.4.4.1"><times id="S6.E5.m1.4.4.1.2.cmml" xref="S6.E5.m1.4.4.1.2"></times><apply id="S6.E5.m1.4.4.1.3.cmml" xref="S6.E5.m1.4.4.1.3"><arg id="S6.E5.m1.4.4.1.3.1.cmml" xref="S6.E5.m1.4.4.1.3.1"></arg><apply id="S6.E5.m1.4.4.1.3.2.cmml" xref="S6.E5.m1.4.4.1.3.2"><csymbol cd="ambiguous" id="S6.E5.m1.4.4.1.3.2.1.cmml" xref="S6.E5.m1.4.4.1.3.2">subscript</csymbol><min id="S6.E5.m1.4.4.1.3.2.2.cmml" xref="S6.E5.m1.4.4.1.3.2.2"></min><ci id="S6.E5.m1.4.4.1.3.2.3.cmml" xref="S6.E5.m1.4.4.1.3.2.3">𝑥</ci></apply></apply><apply id="S6.E5.m1.4.4.1.1.cmml" xref="S6.E5.m1.4.4.1.1"><csymbol cd="ambiguous" id="S6.E5.m1.4.4.1.1.2.cmml" xref="S6.E5.m1.4.4.1.1">subscript</csymbol><apply id="S6.E5.m1.4.4.1.1.1.2.cmml" xref="S6.E5.m1.4.4.1.1.1.1"><csymbol cd="latexml" id="S6.E5.m1.4.4.1.1.1.2.1.cmml" xref="S6.E5.m1.4.4.1.1.1.1.2">norm</csymbol><apply id="S6.E5.m1.4.4.1.1.1.1.1.cmml" xref="S6.E5.m1.4.4.1.1.1.1.1"><minus id="S6.E5.m1.4.4.1.1.1.1.1.1.cmml" xref="S6.E5.m1.4.4.1.1.1.1.1.1"></minus><apply id="S6.E5.m1.4.4.1.1.1.1.1.2.cmml" xref="S6.E5.m1.4.4.1.1.1.1.1.2"><times id="S6.E5.m1.4.4.1.1.1.1.1.2.1.cmml" xref="S6.E5.m1.4.4.1.1.1.1.1.2.1"></times><apply id="S6.E5.m1.4.4.1.1.1.1.1.2.2.cmml" xref="S6.E5.m1.4.4.1.1.1.1.1.2.2"><ci id="S6.E5.m1.4.4.1.1.1.1.1.2.2.1.cmml" xref="S6.E5.m1.4.4.1.1.1.1.1.2.2.1">∇</ci><ci id="S6.E5.m1.4.4.1.1.1.1.1.2.2.2.cmml" xref="S6.E5.m1.4.4.1.1.1.1.1.2.2.2">𝐿</ci></apply><vector id="S6.E5.m1.4.4.1.1.1.1.1.2.3.1.cmml" xref="S6.E5.m1.4.4.1.1.1.1.1.2.3.2"><ci id="S6.E5.m1.1.1.cmml" xref="S6.E5.m1.1.1">𝑥</ci><ci id="S6.E5.m1.2.2.cmml" xref="S6.E5.m1.2.2">𝑦</ci><ci id="S6.E5.m1.3.3.cmml" xref="S6.E5.m1.3.3">𝜃</ci></vector></apply><apply id="S6.E5.m1.4.4.1.1.1.1.1.3.cmml" xref="S6.E5.m1.4.4.1.1.1.1.1.3"><ci id="S6.E5.m1.4.4.1.1.1.1.1.3.1.cmml" xref="S6.E5.m1.4.4.1.1.1.1.1.3.1">∇</ci><ci id="S6.E5.m1.4.4.1.1.1.1.1.3.2.cmml" xref="S6.E5.m1.4.4.1.1.1.1.1.3.2">𝑊</ci></apply></apply></apply><cn type="integer" id="S6.E5.m1.4.4.1.1.3.cmml" xref="S6.E5.m1.4.4.1.1.3">2</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.E5.m1.4c">x^{*}=\arg\min_{x}||\nabla L(x,y,\theta)-\nabla W||_{2}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p id="S6.SS1.SSS1.p1.7" class="ltx_p">An optimizer minimizes the difference between the generated gradient <math id="S6.SS1.SSS1.p1.1.m1.3" class="ltx_Math" alttext="\nabla L(x,y,\theta)" display="inline"><semantics id="S6.SS1.SSS1.p1.1.m1.3a"><mrow id="S6.SS1.SSS1.p1.1.m1.3.4" xref="S6.SS1.SSS1.p1.1.m1.3.4.cmml"><mrow id="S6.SS1.SSS1.p1.1.m1.3.4.2" xref="S6.SS1.SSS1.p1.1.m1.3.4.2.cmml"><mo rspace="0.167em" id="S6.SS1.SSS1.p1.1.m1.3.4.2.1" xref="S6.SS1.SSS1.p1.1.m1.3.4.2.1.cmml">∇</mo><mi id="S6.SS1.SSS1.p1.1.m1.3.4.2.2" xref="S6.SS1.SSS1.p1.1.m1.3.4.2.2.cmml">L</mi></mrow><mo lspace="0em" rspace="0em" id="S6.SS1.SSS1.p1.1.m1.3.4.1" xref="S6.SS1.SSS1.p1.1.m1.3.4.1.cmml">​</mo><mrow id="S6.SS1.SSS1.p1.1.m1.3.4.3.2" xref="S6.SS1.SSS1.p1.1.m1.3.4.3.1.cmml"><mo stretchy="false" id="S6.SS1.SSS1.p1.1.m1.3.4.3.2.1" xref="S6.SS1.SSS1.p1.1.m1.3.4.3.1.cmml">(</mo><mi id="S6.SS1.SSS1.p1.1.m1.1.1" xref="S6.SS1.SSS1.p1.1.m1.1.1.cmml">x</mi><mo id="S6.SS1.SSS1.p1.1.m1.3.4.3.2.2" xref="S6.SS1.SSS1.p1.1.m1.3.4.3.1.cmml">,</mo><mi id="S6.SS1.SSS1.p1.1.m1.2.2" xref="S6.SS1.SSS1.p1.1.m1.2.2.cmml">y</mi><mo id="S6.SS1.SSS1.p1.1.m1.3.4.3.2.3" xref="S6.SS1.SSS1.p1.1.m1.3.4.3.1.cmml">,</mo><mi id="S6.SS1.SSS1.p1.1.m1.3.3" xref="S6.SS1.SSS1.p1.1.m1.3.3.cmml">θ</mi><mo stretchy="false" id="S6.SS1.SSS1.p1.1.m1.3.4.3.2.4" xref="S6.SS1.SSS1.p1.1.m1.3.4.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S6.SS1.SSS1.p1.1.m1.3b"><apply id="S6.SS1.SSS1.p1.1.m1.3.4.cmml" xref="S6.SS1.SSS1.p1.1.m1.3.4"><times id="S6.SS1.SSS1.p1.1.m1.3.4.1.cmml" xref="S6.SS1.SSS1.p1.1.m1.3.4.1"></times><apply id="S6.SS1.SSS1.p1.1.m1.3.4.2.cmml" xref="S6.SS1.SSS1.p1.1.m1.3.4.2"><ci id="S6.SS1.SSS1.p1.1.m1.3.4.2.1.cmml" xref="S6.SS1.SSS1.p1.1.m1.3.4.2.1">∇</ci><ci id="S6.SS1.SSS1.p1.1.m1.3.4.2.2.cmml" xref="S6.SS1.SSS1.p1.1.m1.3.4.2.2">𝐿</ci></apply><vector id="S6.SS1.SSS1.p1.1.m1.3.4.3.1.cmml" xref="S6.SS1.SSS1.p1.1.m1.3.4.3.2"><ci id="S6.SS1.SSS1.p1.1.m1.1.1.cmml" xref="S6.SS1.SSS1.p1.1.m1.1.1">𝑥</ci><ci id="S6.SS1.SSS1.p1.1.m1.2.2.cmml" xref="S6.SS1.SSS1.p1.1.m1.2.2">𝑦</ci><ci id="S6.SS1.SSS1.p1.1.m1.3.3.cmml" xref="S6.SS1.SSS1.p1.1.m1.3.3">𝜃</ci></vector></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.SSS1.p1.1.m1.3c">\nabla L(x,y,\theta)</annotation></semantics></math> and the ground truth gradient <math id="S6.SS1.SSS1.p1.2.m2.1" class="ltx_Math" alttext="\nabla W" display="inline"><semantics id="S6.SS1.SSS1.p1.2.m2.1a"><mrow id="S6.SS1.SSS1.p1.2.m2.1.1" xref="S6.SS1.SSS1.p1.2.m2.1.1.cmml"><mo rspace="0.167em" id="S6.SS1.SSS1.p1.2.m2.1.1.1" xref="S6.SS1.SSS1.p1.2.m2.1.1.1.cmml">∇</mo><mi id="S6.SS1.SSS1.p1.2.m2.1.1.2" xref="S6.SS1.SSS1.p1.2.m2.1.1.2.cmml">W</mi></mrow><annotation-xml encoding="MathML-Content" id="S6.SS1.SSS1.p1.2.m2.1b"><apply id="S6.SS1.SSS1.p1.2.m2.1.1.cmml" xref="S6.SS1.SSS1.p1.2.m2.1.1"><ci id="S6.SS1.SSS1.p1.2.m2.1.1.1.cmml" xref="S6.SS1.SSS1.p1.2.m2.1.1.1">∇</ci><ci id="S6.SS1.SSS1.p1.2.m2.1.1.2.cmml" xref="S6.SS1.SSS1.p1.2.m2.1.1.2">𝑊</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.SSS1.p1.2.m2.1c">\nabla W</annotation></semantics></math> (benign client update). Here <math id="S6.SS1.SSS1.p1.3.m3.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S6.SS1.SSS1.p1.3.m3.1a"><mi id="S6.SS1.SSS1.p1.3.m3.1.1" xref="S6.SS1.SSS1.p1.3.m3.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S6.SS1.SSS1.p1.3.m3.1b"><ci id="S6.SS1.SSS1.p1.3.m3.1.1.cmml" xref="S6.SS1.SSS1.p1.3.m3.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.SSS1.p1.3.m3.1c">x</annotation></semantics></math> is the dummy data, <math id="S6.SS1.SSS1.p1.4.m4.1" class="ltx_Math" alttext="x^{*}" display="inline"><semantics id="S6.SS1.SSS1.p1.4.m4.1a"><msup id="S6.SS1.SSS1.p1.4.m4.1.1" xref="S6.SS1.SSS1.p1.4.m4.1.1.cmml"><mi id="S6.SS1.SSS1.p1.4.m4.1.1.2" xref="S6.SS1.SSS1.p1.4.m4.1.1.2.cmml">x</mi><mo id="S6.SS1.SSS1.p1.4.m4.1.1.3" xref="S6.SS1.SSS1.p1.4.m4.1.1.3.cmml">∗</mo></msup><annotation-xml encoding="MathML-Content" id="S6.SS1.SSS1.p1.4.m4.1b"><apply id="S6.SS1.SSS1.p1.4.m4.1.1.cmml" xref="S6.SS1.SSS1.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S6.SS1.SSS1.p1.4.m4.1.1.1.cmml" xref="S6.SS1.SSS1.p1.4.m4.1.1">superscript</csymbol><ci id="S6.SS1.SSS1.p1.4.m4.1.1.2.cmml" xref="S6.SS1.SSS1.p1.4.m4.1.1.2">𝑥</ci><times id="S6.SS1.SSS1.p1.4.m4.1.1.3.cmml" xref="S6.SS1.SSS1.p1.4.m4.1.1.3"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.SSS1.p1.4.m4.1c">x^{*}</annotation></semantics></math> is the reconstructed data, <math id="S6.SS1.SSS1.p1.5.m5.1" class="ltx_Math" alttext="L" display="inline"><semantics id="S6.SS1.SSS1.p1.5.m5.1a"><mi id="S6.SS1.SSS1.p1.5.m5.1.1" xref="S6.SS1.SSS1.p1.5.m5.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S6.SS1.SSS1.p1.5.m5.1b"><ci id="S6.SS1.SSS1.p1.5.m5.1.1.cmml" xref="S6.SS1.SSS1.p1.5.m5.1.1">𝐿</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.SSS1.p1.5.m5.1c">L</annotation></semantics></math> is the loss function, <math id="S6.SS1.SSS1.p1.6.m6.1" class="ltx_Math" alttext="y" display="inline"><semantics id="S6.SS1.SSS1.p1.6.m6.1a"><mi id="S6.SS1.SSS1.p1.6.m6.1.1" xref="S6.SS1.SSS1.p1.6.m6.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S6.SS1.SSS1.p1.6.m6.1b"><ci id="S6.SS1.SSS1.p1.6.m6.1.1.cmml" xref="S6.SS1.SSS1.p1.6.m6.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.SSS1.p1.6.m6.1c">y</annotation></semantics></math> is the label, and <math id="S6.SS1.SSS1.p1.7.m7.1" class="ltx_Math" alttext="\theta" display="inline"><semantics id="S6.SS1.SSS1.p1.7.m7.1a"><mi id="S6.SS1.SSS1.p1.7.m7.1.1" xref="S6.SS1.SSS1.p1.7.m7.1.1.cmml">θ</mi><annotation-xml encoding="MathML-Content" id="S6.SS1.SSS1.p1.7.m7.1b"><ci id="S6.SS1.SSS1.p1.7.m7.1.1.cmml" xref="S6.SS1.SSS1.p1.7.m7.1.1">𝜃</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.SSS1.p1.7.m7.1c">\theta</annotation></semantics></math> is the model parameters.</p>
</div>
<div id="S6.SS1.SSS1.p2" class="ltx_para">
<p id="S6.SS1.SSS1.p2.1" class="ltx_p">More recent optimization approaches <cite class="ltx_cite ltx_citemacro_citep">(Geiping et al<span class="ltx_text">.</span>, <a href="#bib.bib55" title="" class="ltx_ref">2020</a>; Yin et al<span class="ltx_text">.</span>, <a href="#bib.bib137" title="" class="ltx_ref">2021a</a>)</cite> work under the assumption that user labels are known prior to optimization. Typically, these labels are directly retrieved through a zero-shot solution without using optimization approaches <cite class="ltx_cite ltx_citemacro_citep">(Zhao et al<span class="ltx_text">.</span>, <a href="#bib.bib146" title="" class="ltx_ref">2020</a>; Yin et al<span class="ltx_text">.</span>, <a href="#bib.bib137" title="" class="ltx_ref">2021a</a>)</cite>. Furthermore, regularizers and strong image priors specific to image data are often used to guide optimization results <cite class="ltx_cite ltx_citemacro_citep">(Geiping et al<span class="ltx_text">.</span>, <a href="#bib.bib55" title="" class="ltx_ref">2020</a>; Yin et al<span class="ltx_text">.</span>, <a href="#bib.bib137" title="" class="ltx_ref">2021a</a>; Hatamizadeh et al<span class="ltx_text">.</span>, <a href="#bib.bib59" title="" class="ltx_ref">2023</a>; Usynin et al<span class="ltx_text">.</span>, <a href="#bib.bib127" title="" class="ltx_ref">2023</a>)</cite>. These can also result in image artifacts typical of an image class, but not in the actual training image. These approaches have shown surprising success with image data on smaller batch sizes. However, as batch sizes increase, the fraction of images recovered decreases along with the reconstruction quality and the number of iterations required for the optimization also increases. One reason stated by <cite class="ltx_cite ltx_citemacro_citep">(Zhu et al<span class="ltx_text">.</span>, <a href="#bib.bib151" title="" class="ltx_ref">2019</a>)</cite> was that regardless of the order of images in the batch, the gradient will remain the same. Having multiple possible permutations then makes the optimization more difficult. Another fundamental reason is that a larger batch size means more images and more variables for optimization.</p>
</div>
<div id="S6.SS1.SSS1.p3" class="ltx_para">
<p id="S6.SS1.SSS1.p3.1" class="ltx_p">Both secure aggregation and FedAvg also pose a particularly difficult challenge for optimization attacks. For secure aggregation, the aggregated updated can be thought of as large-batch consisting of the batch images from all clients. This directly exacerbates the difficulty of reconstructing larger batch sizes. FedAvg, on the other hand, adds another layer of unknowns for the optimization since the intermediate model updates are unknown to the attacker. While <cite class="ltx_cite ltx_citemacro_citep">(Geiping et al<span class="ltx_text">.</span>, <a href="#bib.bib55" title="" class="ltx_ref">2020</a>)</cite> discuss attacking FedAvg, the attack is only shown with a very small local dataset size of up to 8 images on CIFAR-10. Furthermore, it needs to be investigated how different model architectures, such as transformers <cite class="ltx_cite ltx_citemacro_citep">(Hatamizadeh et al<span class="ltx_text">.</span>, <a href="#bib.bib60" title="" class="ltx_ref">2022</a>)</cite>, impact the success of gradient inversion attacks.</p>
</div>
</section>
<section id="S6.SS1.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">6.1.2. </span>Linear layer leakage.</h4>

<div id="S6.SS1.SSS2.p1" class="ltx_para ltx_noindent">
<p id="S6.SS1.SSS2.p1.6" class="ltx_p">Linear layer leakage attacks are a sub-class of analytic attacks that modify FC layers to leak inputs. Using the weight and bias gradients of an FC layer to leak inputs was discussed in <cite class="ltx_cite ltx_citemacro_citep">(Phong et al<span class="ltx_text">.</span>, <a href="#bib.bib105" title="" class="ltx_ref">2017</a>; Fan et al<span class="ltx_text">.</span>, <a href="#bib.bib47" title="" class="ltx_ref">2020</a>)</cite>. When only a single image activates a neuron in a fully connected layer, the input to that layer can be directly computed using the resulting gradients as</p>
<table id="S6.E6" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left"><span class="ltx_tag ltx_tag_equation ltx_align_left">(6)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S6.E6.m1.1" class="ltx_Math" alttext="x^{i}=\frac{\delta L}{\delta W^{i}}/\frac{\delta L}{\delta B^{i}}" display="block"><semantics id="S6.E6.m1.1a"><mrow id="S6.E6.m1.1.1" xref="S6.E6.m1.1.1.cmml"><msup id="S6.E6.m1.1.1.2" xref="S6.E6.m1.1.1.2.cmml"><mi id="S6.E6.m1.1.1.2.2" xref="S6.E6.m1.1.1.2.2.cmml">x</mi><mi id="S6.E6.m1.1.1.2.3" xref="S6.E6.m1.1.1.2.3.cmml">i</mi></msup><mo id="S6.E6.m1.1.1.1" xref="S6.E6.m1.1.1.1.cmml">=</mo><mrow id="S6.E6.m1.1.1.3" xref="S6.E6.m1.1.1.3.cmml"><mfrac id="S6.E6.m1.1.1.3.2" xref="S6.E6.m1.1.1.3.2.cmml"><mrow id="S6.E6.m1.1.1.3.2.2" xref="S6.E6.m1.1.1.3.2.2.cmml"><mi id="S6.E6.m1.1.1.3.2.2.2" xref="S6.E6.m1.1.1.3.2.2.2.cmml">δ</mi><mo lspace="0em" rspace="0em" id="S6.E6.m1.1.1.3.2.2.1" xref="S6.E6.m1.1.1.3.2.2.1.cmml">​</mo><mi id="S6.E6.m1.1.1.3.2.2.3" xref="S6.E6.m1.1.1.3.2.2.3.cmml">L</mi></mrow><mrow id="S6.E6.m1.1.1.3.2.3" xref="S6.E6.m1.1.1.3.2.3.cmml"><mi id="S6.E6.m1.1.1.3.2.3.2" xref="S6.E6.m1.1.1.3.2.3.2.cmml">δ</mi><mo lspace="0em" rspace="0em" id="S6.E6.m1.1.1.3.2.3.1" xref="S6.E6.m1.1.1.3.2.3.1.cmml">​</mo><msup id="S6.E6.m1.1.1.3.2.3.3" xref="S6.E6.m1.1.1.3.2.3.3.cmml"><mi id="S6.E6.m1.1.1.3.2.3.3.2" xref="S6.E6.m1.1.1.3.2.3.3.2.cmml">W</mi><mi id="S6.E6.m1.1.1.3.2.3.3.3" xref="S6.E6.m1.1.1.3.2.3.3.3.cmml">i</mi></msup></mrow></mfrac><mo id="S6.E6.m1.1.1.3.1" xref="S6.E6.m1.1.1.3.1.cmml">/</mo><mfrac id="S6.E6.m1.1.1.3.3" xref="S6.E6.m1.1.1.3.3.cmml"><mrow id="S6.E6.m1.1.1.3.3.2" xref="S6.E6.m1.1.1.3.3.2.cmml"><mi id="S6.E6.m1.1.1.3.3.2.2" xref="S6.E6.m1.1.1.3.3.2.2.cmml">δ</mi><mo lspace="0em" rspace="0em" id="S6.E6.m1.1.1.3.3.2.1" xref="S6.E6.m1.1.1.3.3.2.1.cmml">​</mo><mi id="S6.E6.m1.1.1.3.3.2.3" xref="S6.E6.m1.1.1.3.3.2.3.cmml">L</mi></mrow><mrow id="S6.E6.m1.1.1.3.3.3" xref="S6.E6.m1.1.1.3.3.3.cmml"><mi id="S6.E6.m1.1.1.3.3.3.2" xref="S6.E6.m1.1.1.3.3.3.2.cmml">δ</mi><mo lspace="0em" rspace="0em" id="S6.E6.m1.1.1.3.3.3.1" xref="S6.E6.m1.1.1.3.3.3.1.cmml">​</mo><msup id="S6.E6.m1.1.1.3.3.3.3" xref="S6.E6.m1.1.1.3.3.3.3.cmml"><mi id="S6.E6.m1.1.1.3.3.3.3.2" xref="S6.E6.m1.1.1.3.3.3.3.2.cmml">B</mi><mi id="S6.E6.m1.1.1.3.3.3.3.3" xref="S6.E6.m1.1.1.3.3.3.3.3.cmml">i</mi></msup></mrow></mfrac></mrow></mrow><annotation-xml encoding="MathML-Content" id="S6.E6.m1.1b"><apply id="S6.E6.m1.1.1.cmml" xref="S6.E6.m1.1.1"><eq id="S6.E6.m1.1.1.1.cmml" xref="S6.E6.m1.1.1.1"></eq><apply id="S6.E6.m1.1.1.2.cmml" xref="S6.E6.m1.1.1.2"><csymbol cd="ambiguous" id="S6.E6.m1.1.1.2.1.cmml" xref="S6.E6.m1.1.1.2">superscript</csymbol><ci id="S6.E6.m1.1.1.2.2.cmml" xref="S6.E6.m1.1.1.2.2">𝑥</ci><ci id="S6.E6.m1.1.1.2.3.cmml" xref="S6.E6.m1.1.1.2.3">𝑖</ci></apply><apply id="S6.E6.m1.1.1.3.cmml" xref="S6.E6.m1.1.1.3"><divide id="S6.E6.m1.1.1.3.1.cmml" xref="S6.E6.m1.1.1.3.1"></divide><apply id="S6.E6.m1.1.1.3.2.cmml" xref="S6.E6.m1.1.1.3.2"><divide id="S6.E6.m1.1.1.3.2.1.cmml" xref="S6.E6.m1.1.1.3.2"></divide><apply id="S6.E6.m1.1.1.3.2.2.cmml" xref="S6.E6.m1.1.1.3.2.2"><times id="S6.E6.m1.1.1.3.2.2.1.cmml" xref="S6.E6.m1.1.1.3.2.2.1"></times><ci id="S6.E6.m1.1.1.3.2.2.2.cmml" xref="S6.E6.m1.1.1.3.2.2.2">𝛿</ci><ci id="S6.E6.m1.1.1.3.2.2.3.cmml" xref="S6.E6.m1.1.1.3.2.2.3">𝐿</ci></apply><apply id="S6.E6.m1.1.1.3.2.3.cmml" xref="S6.E6.m1.1.1.3.2.3"><times id="S6.E6.m1.1.1.3.2.3.1.cmml" xref="S6.E6.m1.1.1.3.2.3.1"></times><ci id="S6.E6.m1.1.1.3.2.3.2.cmml" xref="S6.E6.m1.1.1.3.2.3.2">𝛿</ci><apply id="S6.E6.m1.1.1.3.2.3.3.cmml" xref="S6.E6.m1.1.1.3.2.3.3"><csymbol cd="ambiguous" id="S6.E6.m1.1.1.3.2.3.3.1.cmml" xref="S6.E6.m1.1.1.3.2.3.3">superscript</csymbol><ci id="S6.E6.m1.1.1.3.2.3.3.2.cmml" xref="S6.E6.m1.1.1.3.2.3.3.2">𝑊</ci><ci id="S6.E6.m1.1.1.3.2.3.3.3.cmml" xref="S6.E6.m1.1.1.3.2.3.3.3">𝑖</ci></apply></apply></apply><apply id="S6.E6.m1.1.1.3.3.cmml" xref="S6.E6.m1.1.1.3.3"><divide id="S6.E6.m1.1.1.3.3.1.cmml" xref="S6.E6.m1.1.1.3.3"></divide><apply id="S6.E6.m1.1.1.3.3.2.cmml" xref="S6.E6.m1.1.1.3.3.2"><times id="S6.E6.m1.1.1.3.3.2.1.cmml" xref="S6.E6.m1.1.1.3.3.2.1"></times><ci id="S6.E6.m1.1.1.3.3.2.2.cmml" xref="S6.E6.m1.1.1.3.3.2.2">𝛿</ci><ci id="S6.E6.m1.1.1.3.3.2.3.cmml" xref="S6.E6.m1.1.1.3.3.2.3">𝐿</ci></apply><apply id="S6.E6.m1.1.1.3.3.3.cmml" xref="S6.E6.m1.1.1.3.3.3"><times id="S6.E6.m1.1.1.3.3.3.1.cmml" xref="S6.E6.m1.1.1.3.3.3.1"></times><ci id="S6.E6.m1.1.1.3.3.3.2.cmml" xref="S6.E6.m1.1.1.3.3.3.2">𝛿</ci><apply id="S6.E6.m1.1.1.3.3.3.3.cmml" xref="S6.E6.m1.1.1.3.3.3.3"><csymbol cd="ambiguous" id="S6.E6.m1.1.1.3.3.3.3.1.cmml" xref="S6.E6.m1.1.1.3.3.3.3">superscript</csymbol><ci id="S6.E6.m1.1.1.3.3.3.3.2.cmml" xref="S6.E6.m1.1.1.3.3.3.3.2">𝐵</ci><ci id="S6.E6.m1.1.1.3.3.3.3.3.cmml" xref="S6.E6.m1.1.1.3.3.3.3.3">𝑖</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.E6.m1.1c">x^{i}=\frac{\delta L}{\delta W^{i}}/\frac{\delta L}{\delta B^{i}}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p id="S6.SS1.SSS2.p1.5" class="ltx_p">where <math id="S6.SS1.SSS2.p1.1.m1.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S6.SS1.SSS2.p1.1.m1.1a"><mi id="S6.SS1.SSS2.p1.1.m1.1.1" xref="S6.SS1.SSS2.p1.1.m1.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S6.SS1.SSS2.p1.1.m1.1b"><ci id="S6.SS1.SSS2.p1.1.m1.1.1.cmml" xref="S6.SS1.SSS2.p1.1.m1.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.SSS2.p1.1.m1.1c">i</annotation></semantics></math> is the activated neuron, <math id="S6.SS1.SSS2.p1.2.m2.1" class="ltx_Math" alttext="x^{i}" display="inline"><semantics id="S6.SS1.SSS2.p1.2.m2.1a"><msup id="S6.SS1.SSS2.p1.2.m2.1.1" xref="S6.SS1.SSS2.p1.2.m2.1.1.cmml"><mi id="S6.SS1.SSS2.p1.2.m2.1.1.2" xref="S6.SS1.SSS2.p1.2.m2.1.1.2.cmml">x</mi><mi id="S6.SS1.SSS2.p1.2.m2.1.1.3" xref="S6.SS1.SSS2.p1.2.m2.1.1.3.cmml">i</mi></msup><annotation-xml encoding="MathML-Content" id="S6.SS1.SSS2.p1.2.m2.1b"><apply id="S6.SS1.SSS2.p1.2.m2.1.1.cmml" xref="S6.SS1.SSS2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S6.SS1.SSS2.p1.2.m2.1.1.1.cmml" xref="S6.SS1.SSS2.p1.2.m2.1.1">superscript</csymbol><ci id="S6.SS1.SSS2.p1.2.m2.1.1.2.cmml" xref="S6.SS1.SSS2.p1.2.m2.1.1.2">𝑥</ci><ci id="S6.SS1.SSS2.p1.2.m2.1.1.3.cmml" xref="S6.SS1.SSS2.p1.2.m2.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.SSS2.p1.2.m2.1c">x^{i}</annotation></semantics></math> is the input that activates neuron <math id="S6.SS1.SSS2.p1.3.m3.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S6.SS1.SSS2.p1.3.m3.1a"><mi id="S6.SS1.SSS2.p1.3.m3.1.1" xref="S6.SS1.SSS2.p1.3.m3.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S6.SS1.SSS2.p1.3.m3.1b"><ci id="S6.SS1.SSS2.p1.3.m3.1.1.cmml" xref="S6.SS1.SSS2.p1.3.m3.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.SSS2.p1.3.m3.1c">i</annotation></semantics></math>, and <math id="S6.SS1.SSS2.p1.4.m4.1" class="ltx_Math" alttext="\frac{\delta L}{\delta W^{i}}" display="inline"><semantics id="S6.SS1.SSS2.p1.4.m4.1a"><mfrac id="S6.SS1.SSS2.p1.4.m4.1.1" xref="S6.SS1.SSS2.p1.4.m4.1.1.cmml"><mrow id="S6.SS1.SSS2.p1.4.m4.1.1.2" xref="S6.SS1.SSS2.p1.4.m4.1.1.2.cmml"><mi id="S6.SS1.SSS2.p1.4.m4.1.1.2.2" xref="S6.SS1.SSS2.p1.4.m4.1.1.2.2.cmml">δ</mi><mo lspace="0em" rspace="0em" id="S6.SS1.SSS2.p1.4.m4.1.1.2.1" xref="S6.SS1.SSS2.p1.4.m4.1.1.2.1.cmml">​</mo><mi id="S6.SS1.SSS2.p1.4.m4.1.1.2.3" xref="S6.SS1.SSS2.p1.4.m4.1.1.2.3.cmml">L</mi></mrow><mrow id="S6.SS1.SSS2.p1.4.m4.1.1.3" xref="S6.SS1.SSS2.p1.4.m4.1.1.3.cmml"><mi id="S6.SS1.SSS2.p1.4.m4.1.1.3.2" xref="S6.SS1.SSS2.p1.4.m4.1.1.3.2.cmml">δ</mi><mo lspace="0em" rspace="0em" id="S6.SS1.SSS2.p1.4.m4.1.1.3.1" xref="S6.SS1.SSS2.p1.4.m4.1.1.3.1.cmml">​</mo><msup id="S6.SS1.SSS2.p1.4.m4.1.1.3.3" xref="S6.SS1.SSS2.p1.4.m4.1.1.3.3.cmml"><mi id="S6.SS1.SSS2.p1.4.m4.1.1.3.3.2" xref="S6.SS1.SSS2.p1.4.m4.1.1.3.3.2.cmml">W</mi><mi id="S6.SS1.SSS2.p1.4.m4.1.1.3.3.3" xref="S6.SS1.SSS2.p1.4.m4.1.1.3.3.3.cmml">i</mi></msup></mrow></mfrac><annotation-xml encoding="MathML-Content" id="S6.SS1.SSS2.p1.4.m4.1b"><apply id="S6.SS1.SSS2.p1.4.m4.1.1.cmml" xref="S6.SS1.SSS2.p1.4.m4.1.1"><divide id="S6.SS1.SSS2.p1.4.m4.1.1.1.cmml" xref="S6.SS1.SSS2.p1.4.m4.1.1"></divide><apply id="S6.SS1.SSS2.p1.4.m4.1.1.2.cmml" xref="S6.SS1.SSS2.p1.4.m4.1.1.2"><times id="S6.SS1.SSS2.p1.4.m4.1.1.2.1.cmml" xref="S6.SS1.SSS2.p1.4.m4.1.1.2.1"></times><ci id="S6.SS1.SSS2.p1.4.m4.1.1.2.2.cmml" xref="S6.SS1.SSS2.p1.4.m4.1.1.2.2">𝛿</ci><ci id="S6.SS1.SSS2.p1.4.m4.1.1.2.3.cmml" xref="S6.SS1.SSS2.p1.4.m4.1.1.2.3">𝐿</ci></apply><apply id="S6.SS1.SSS2.p1.4.m4.1.1.3.cmml" xref="S6.SS1.SSS2.p1.4.m4.1.1.3"><times id="S6.SS1.SSS2.p1.4.m4.1.1.3.1.cmml" xref="S6.SS1.SSS2.p1.4.m4.1.1.3.1"></times><ci id="S6.SS1.SSS2.p1.4.m4.1.1.3.2.cmml" xref="S6.SS1.SSS2.p1.4.m4.1.1.3.2">𝛿</ci><apply id="S6.SS1.SSS2.p1.4.m4.1.1.3.3.cmml" xref="S6.SS1.SSS2.p1.4.m4.1.1.3.3"><csymbol cd="ambiguous" id="S6.SS1.SSS2.p1.4.m4.1.1.3.3.1.cmml" xref="S6.SS1.SSS2.p1.4.m4.1.1.3.3">superscript</csymbol><ci id="S6.SS1.SSS2.p1.4.m4.1.1.3.3.2.cmml" xref="S6.SS1.SSS2.p1.4.m4.1.1.3.3.2">𝑊</ci><ci id="S6.SS1.SSS2.p1.4.m4.1.1.3.3.3.cmml" xref="S6.SS1.SSS2.p1.4.m4.1.1.3.3.3">𝑖</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.SSS2.p1.4.m4.1c">\frac{\delta L}{\delta W^{i}}</annotation></semantics></math>, <math id="S6.SS1.SSS2.p1.5.m5.1" class="ltx_Math" alttext="\frac{\delta L}{\delta B^{i}}" display="inline"><semantics id="S6.SS1.SSS2.p1.5.m5.1a"><mfrac id="S6.SS1.SSS2.p1.5.m5.1.1" xref="S6.SS1.SSS2.p1.5.m5.1.1.cmml"><mrow id="S6.SS1.SSS2.p1.5.m5.1.1.2" xref="S6.SS1.SSS2.p1.5.m5.1.1.2.cmml"><mi id="S6.SS1.SSS2.p1.5.m5.1.1.2.2" xref="S6.SS1.SSS2.p1.5.m5.1.1.2.2.cmml">δ</mi><mo lspace="0em" rspace="0em" id="S6.SS1.SSS2.p1.5.m5.1.1.2.1" xref="S6.SS1.SSS2.p1.5.m5.1.1.2.1.cmml">​</mo><mi id="S6.SS1.SSS2.p1.5.m5.1.1.2.3" xref="S6.SS1.SSS2.p1.5.m5.1.1.2.3.cmml">L</mi></mrow><mrow id="S6.SS1.SSS2.p1.5.m5.1.1.3" xref="S6.SS1.SSS2.p1.5.m5.1.1.3.cmml"><mi id="S6.SS1.SSS2.p1.5.m5.1.1.3.2" xref="S6.SS1.SSS2.p1.5.m5.1.1.3.2.cmml">δ</mi><mo lspace="0em" rspace="0em" id="S6.SS1.SSS2.p1.5.m5.1.1.3.1" xref="S6.SS1.SSS2.p1.5.m5.1.1.3.1.cmml">​</mo><msup id="S6.SS1.SSS2.p1.5.m5.1.1.3.3" xref="S6.SS1.SSS2.p1.5.m5.1.1.3.3.cmml"><mi id="S6.SS1.SSS2.p1.5.m5.1.1.3.3.2" xref="S6.SS1.SSS2.p1.5.m5.1.1.3.3.2.cmml">B</mi><mi id="S6.SS1.SSS2.p1.5.m5.1.1.3.3.3" xref="S6.SS1.SSS2.p1.5.m5.1.1.3.3.3.cmml">i</mi></msup></mrow></mfrac><annotation-xml encoding="MathML-Content" id="S6.SS1.SSS2.p1.5.m5.1b"><apply id="S6.SS1.SSS2.p1.5.m5.1.1.cmml" xref="S6.SS1.SSS2.p1.5.m5.1.1"><divide id="S6.SS1.SSS2.p1.5.m5.1.1.1.cmml" xref="S6.SS1.SSS2.p1.5.m5.1.1"></divide><apply id="S6.SS1.SSS2.p1.5.m5.1.1.2.cmml" xref="S6.SS1.SSS2.p1.5.m5.1.1.2"><times id="S6.SS1.SSS2.p1.5.m5.1.1.2.1.cmml" xref="S6.SS1.SSS2.p1.5.m5.1.1.2.1"></times><ci id="S6.SS1.SSS2.p1.5.m5.1.1.2.2.cmml" xref="S6.SS1.SSS2.p1.5.m5.1.1.2.2">𝛿</ci><ci id="S6.SS1.SSS2.p1.5.m5.1.1.2.3.cmml" xref="S6.SS1.SSS2.p1.5.m5.1.1.2.3">𝐿</ci></apply><apply id="S6.SS1.SSS2.p1.5.m5.1.1.3.cmml" xref="S6.SS1.SSS2.p1.5.m5.1.1.3"><times id="S6.SS1.SSS2.p1.5.m5.1.1.3.1.cmml" xref="S6.SS1.SSS2.p1.5.m5.1.1.3.1"></times><ci id="S6.SS1.SSS2.p1.5.m5.1.1.3.2.cmml" xref="S6.SS1.SSS2.p1.5.m5.1.1.3.2">𝛿</ci><apply id="S6.SS1.SSS2.p1.5.m5.1.1.3.3.cmml" xref="S6.SS1.SSS2.p1.5.m5.1.1.3.3"><csymbol cd="ambiguous" id="S6.SS1.SSS2.p1.5.m5.1.1.3.3.1.cmml" xref="S6.SS1.SSS2.p1.5.m5.1.1.3.3">superscript</csymbol><ci id="S6.SS1.SSS2.p1.5.m5.1.1.3.3.2.cmml" xref="S6.SS1.SSS2.p1.5.m5.1.1.3.3.2">𝐵</ci><ci id="S6.SS1.SSS2.p1.5.m5.1.1.3.3.3.cmml" xref="S6.SS1.SSS2.p1.5.m5.1.1.3.3.3">𝑖</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.SSS2.p1.5.m5.1c">\frac{\delta L}{\delta B^{i}}</annotation></semantics></math> are the weight gradient and bias gradient of the neuron respectively. This idea forms the basis for several reconstruction attacks <cite class="ltx_cite ltx_citemacro_citep">(Boenisch et al<span class="ltx_text">.</span>, <a href="#bib.bib23" title="" class="ltx_ref">2023</a>; Fowl et al<span class="ltx_text">.</span>, <a href="#bib.bib51" title="" class="ltx_ref">2022</a>)</cite>. Figure <a href="#S6.F4" title="Figure 4 ‣ 6.1.2. Linear layer leakage. ‣ 6.1. Data Reconstruction Attacks ‣ 6. Privacy Attacks ‣ Federated Learning Privacy: Attacks, Defenses, Applications, and Policy Landscape — A Survey" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> shows the basic process of leaking images through an FC layer.</p>
</div>
<figure id="S6.F4" class="ltx_figure"><img src="/html/2405.03636/assets/x7.png" id="S6.F4.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="230" height="103" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 4. </span> Using the weight gradient <math id="S6.F4.8.m1.1" class="ltx_Math" alttext="\frac{\delta L}{\delta W}" display="inline"><semantics id="S6.F4.8.m1.1b"><mfrac id="S6.F4.8.m1.1.1" xref="S6.F4.8.m1.1.1.cmml"><mrow id="S6.F4.8.m1.1.1.2" xref="S6.F4.8.m1.1.1.2.cmml"><mi id="S6.F4.8.m1.1.1.2.2" xref="S6.F4.8.m1.1.1.2.2.cmml">δ</mi><mo lspace="0em" rspace="0em" id="S6.F4.8.m1.1.1.2.1" xref="S6.F4.8.m1.1.1.2.1.cmml">​</mo><mi id="S6.F4.8.m1.1.1.2.3" xref="S6.F4.8.m1.1.1.2.3.cmml">L</mi></mrow><mrow id="S6.F4.8.m1.1.1.3" xref="S6.F4.8.m1.1.1.3.cmml"><mi id="S6.F4.8.m1.1.1.3.2" xref="S6.F4.8.m1.1.1.3.2.cmml">δ</mi><mo lspace="0em" rspace="0em" id="S6.F4.8.m1.1.1.3.1" xref="S6.F4.8.m1.1.1.3.1.cmml">​</mo><mi id="S6.F4.8.m1.1.1.3.3" xref="S6.F4.8.m1.1.1.3.3.cmml">W</mi></mrow></mfrac><annotation-xml encoding="MathML-Content" id="S6.F4.8.m1.1c"><apply id="S6.F4.8.m1.1.1.cmml" xref="S6.F4.8.m1.1.1"><divide id="S6.F4.8.m1.1.1.1.cmml" xref="S6.F4.8.m1.1.1"></divide><apply id="S6.F4.8.m1.1.1.2.cmml" xref="S6.F4.8.m1.1.1.2"><times id="S6.F4.8.m1.1.1.2.1.cmml" xref="S6.F4.8.m1.1.1.2.1"></times><ci id="S6.F4.8.m1.1.1.2.2.cmml" xref="S6.F4.8.m1.1.1.2.2">𝛿</ci><ci id="S6.F4.8.m1.1.1.2.3.cmml" xref="S6.F4.8.m1.1.1.2.3">𝐿</ci></apply><apply id="S6.F4.8.m1.1.1.3.cmml" xref="S6.F4.8.m1.1.1.3"><times id="S6.F4.8.m1.1.1.3.1.cmml" xref="S6.F4.8.m1.1.1.3.1"></times><ci id="S6.F4.8.m1.1.1.3.2.cmml" xref="S6.F4.8.m1.1.1.3.2">𝛿</ci><ci id="S6.F4.8.m1.1.1.3.3.cmml" xref="S6.F4.8.m1.1.1.3.3">𝑊</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.F4.8.m1.1d">\frac{\delta L}{\delta W}</annotation></semantics></math> and bias gradient <math id="S6.F4.9.m2.1" class="ltx_Math" alttext="\frac{\delta L}{\delta B}" display="inline"><semantics id="S6.F4.9.m2.1b"><mfrac id="S6.F4.9.m2.1.1" xref="S6.F4.9.m2.1.1.cmml"><mrow id="S6.F4.9.m2.1.1.2" xref="S6.F4.9.m2.1.1.2.cmml"><mi id="S6.F4.9.m2.1.1.2.2" xref="S6.F4.9.m2.1.1.2.2.cmml">δ</mi><mo lspace="0em" rspace="0em" id="S6.F4.9.m2.1.1.2.1" xref="S6.F4.9.m2.1.1.2.1.cmml">​</mo><mi id="S6.F4.9.m2.1.1.2.3" xref="S6.F4.9.m2.1.1.2.3.cmml">L</mi></mrow><mrow id="S6.F4.9.m2.1.1.3" xref="S6.F4.9.m2.1.1.3.cmml"><mi id="S6.F4.9.m2.1.1.3.2" xref="S6.F4.9.m2.1.1.3.2.cmml">δ</mi><mo lspace="0em" rspace="0em" id="S6.F4.9.m2.1.1.3.1" xref="S6.F4.9.m2.1.1.3.1.cmml">​</mo><mi id="S6.F4.9.m2.1.1.3.3" xref="S6.F4.9.m2.1.1.3.3.cmml">B</mi></mrow></mfrac><annotation-xml encoding="MathML-Content" id="S6.F4.9.m2.1c"><apply id="S6.F4.9.m2.1.1.cmml" xref="S6.F4.9.m2.1.1"><divide id="S6.F4.9.m2.1.1.1.cmml" xref="S6.F4.9.m2.1.1"></divide><apply id="S6.F4.9.m2.1.1.2.cmml" xref="S6.F4.9.m2.1.1.2"><times id="S6.F4.9.m2.1.1.2.1.cmml" xref="S6.F4.9.m2.1.1.2.1"></times><ci id="S6.F4.9.m2.1.1.2.2.cmml" xref="S6.F4.9.m2.1.1.2.2">𝛿</ci><ci id="S6.F4.9.m2.1.1.2.3.cmml" xref="S6.F4.9.m2.1.1.2.3">𝐿</ci></apply><apply id="S6.F4.9.m2.1.1.3.cmml" xref="S6.F4.9.m2.1.1.3"><times id="S6.F4.9.m2.1.1.3.1.cmml" xref="S6.F4.9.m2.1.1.3.1"></times><ci id="S6.F4.9.m2.1.1.3.2.cmml" xref="S6.F4.9.m2.1.1.3.2">𝛿</ci><ci id="S6.F4.9.m2.1.1.3.3.cmml" xref="S6.F4.9.m2.1.1.3.3">𝐵</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.F4.9.m2.1d">\frac{\delta L}{\delta B}</annotation></semantics></math> of a fully connected layer to reconstruct the inputs. Neuron <math id="S6.F4.10.m3.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S6.F4.10.m3.1b"><mi id="S6.F4.10.m3.1.1" xref="S6.F4.10.m3.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S6.F4.10.m3.1c"><ci id="S6.F4.10.m3.1.1.cmml" xref="S6.F4.10.m3.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.F4.10.m3.1d">i</annotation></semantics></math> is only activated by a single image, while <math id="S6.F4.11.m4.1" class="ltx_Math" alttext="j" display="inline"><semantics id="S6.F4.11.m4.1b"><mi id="S6.F4.11.m4.1.1" xref="S6.F4.11.m4.1.1.cmml">j</mi><annotation-xml encoding="MathML-Content" id="S6.F4.11.m4.1c"><ci id="S6.F4.11.m4.1.1.cmml" xref="S6.F4.11.m4.1.1">𝑗</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.F4.11.m4.1d">j</annotation></semantics></math> is activated by two. As a result, the reconstruction of neuron <math id="S6.F4.12.m5.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S6.F4.12.m5.1b"><mi id="S6.F4.12.m5.1.1" xref="S6.F4.12.m5.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S6.F4.12.m5.1c"><ci id="S6.F4.12.m5.1.1.cmml" xref="S6.F4.12.m5.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.F4.12.m5.1d">i</annotation></semantics></math> is correct while <math id="S6.F4.13.m6.1" class="ltx_Math" alttext="j" display="inline"><semantics id="S6.F4.13.m6.1b"><mi id="S6.F4.13.m6.1.1" xref="S6.F4.13.m6.1.1.cmml">j</mi><annotation-xml encoding="MathML-Content" id="S6.F4.13.m6.1c"><ci id="S6.F4.13.m6.1.1.cmml" xref="S6.F4.13.m6.1.1">𝑗</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.F4.13.m6.1d">j</annotation></semantics></math> is a combination of images.</figcaption>
</figure>
<div id="S6.SS1.SSS2.p2" class="ltx_para">
<p id="S6.SS1.SSS2.p2.1" class="ltx_p">When the fully-connected layer is placed at the start of a network, the data reconstructed from the the layer would be the input data. This reconstruction is exact, as opposed to the optimization approaches which function as estimations. However, inputs are only reconstructed exactly when a single data sample activates that neuron. If more than one input activates the neuron, the weight and bias gradients of these inputs will contribute to the batch gradient. When the gradient division of Equation <a href="#S6.E6" title="In 6.1.2. Linear layer leakage. ‣ 6.1. Data Reconstruction Attacks ‣ 6. Privacy Attacks ‣ Federated Learning Privacy: Attacks, Defenses, Applications, and Policy Landscape — A Survey" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> is done to retrieve the input, the resulting reconstruction would be a combination of all contributing images, a case of failed attack.</p>
</div>
<div id="S6.SS1.SSS2.p3" class="ltx_para ltx_noindent">
<p id="S6.SS1.SSS2.p3.9" class="ltx_p">To alleviate this problem, <cite class="ltx_cite ltx_citemacro_citep">(Fowl et al<span class="ltx_text">.</span>, <a href="#bib.bib51" title="" class="ltx_ref">2022</a>; Boenisch et al<span class="ltx_text">.</span>, <a href="#bib.bib23" title="" class="ltx_ref">2023</a>)</cite> use malicious modification of the parameters in the FC layer. For <cite class="ltx_cite ltx_citemacro_citep">(Boenisch et al<span class="ltx_text">.</span>, <a href="#bib.bib23" title="" class="ltx_ref">2023</a>)</cite>, trap weights were introduced, initializing the weights randomly to be half positive, half negative. In order to ensure that neuron activation is less common, the negative weights come from a larger negative magnitude range than the positive weights. They also discuss the use of convolutional layers to push the input image forward, allowing the attack to function on models starting with convolutional layers followed by fully-connected layers. However, one of the main problems of the method lies with scalability. Even if the size of the FC layer increases proportionately with an increasing total number of images, the leakage rate decreases. On the other hand, Robbing the Fed (RtF) <cite class="ltx_cite ltx_citemacro_citep">(Fowl et al<span class="ltx_text">.</span>, <a href="#bib.bib51" title="" class="ltx_ref">2022</a>)</cite> introduced another approach with higher leakage rate called “binning”, where the weights of the FC layer would measure some known continuous CDF of the input data such as image brightness. The bias for each neuron then serves as a different cutoff, allowing only inputs with a high enough value to activate it. The goal of this method would be that only one input activates each “bin”, where the bin is defined as the activated neuron with the largest cutoff (for ReLU, the largest negative bias)<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>The bin biases are set as negative. The weights are positive and so the negative bins are used to prevent ReLU activation.</span></span></span>. For any case where only one input activates a bin, it can then be reconstructed as</p>
<table id="S6.E7" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left"><span class="ltx_tag ltx_tag_equation ltx_align_left">(7)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S6.E7.m1.2" class="ltx_Math" alttext="x^{i}=(\frac{\delta L}{\delta W^{i}}-\frac{\delta L}{\delta W^{i+1}})/(\frac{\delta L}{\delta B^{i}}-\frac{\delta L}{\delta B^{i+1}})" display="block"><semantics id="S6.E7.m1.2a"><mrow id="S6.E7.m1.2.2" xref="S6.E7.m1.2.2.cmml"><msup id="S6.E7.m1.2.2.4" xref="S6.E7.m1.2.2.4.cmml"><mi id="S6.E7.m1.2.2.4.2" xref="S6.E7.m1.2.2.4.2.cmml">x</mi><mi id="S6.E7.m1.2.2.4.3" xref="S6.E7.m1.2.2.4.3.cmml">i</mi></msup><mo id="S6.E7.m1.2.2.3" xref="S6.E7.m1.2.2.3.cmml">=</mo><mrow id="S6.E7.m1.2.2.2" xref="S6.E7.m1.2.2.2.cmml"><mrow id="S6.E7.m1.1.1.1.1.1" xref="S6.E7.m1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S6.E7.m1.1.1.1.1.1.2" xref="S6.E7.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="S6.E7.m1.1.1.1.1.1.1" xref="S6.E7.m1.1.1.1.1.1.1.cmml"><mfrac id="S6.E7.m1.1.1.1.1.1.1.2" xref="S6.E7.m1.1.1.1.1.1.1.2.cmml"><mrow id="S6.E7.m1.1.1.1.1.1.1.2.2" xref="S6.E7.m1.1.1.1.1.1.1.2.2.cmml"><mi id="S6.E7.m1.1.1.1.1.1.1.2.2.2" xref="S6.E7.m1.1.1.1.1.1.1.2.2.2.cmml">δ</mi><mo lspace="0em" rspace="0em" id="S6.E7.m1.1.1.1.1.1.1.2.2.1" xref="S6.E7.m1.1.1.1.1.1.1.2.2.1.cmml">​</mo><mi id="S6.E7.m1.1.1.1.1.1.1.2.2.3" xref="S6.E7.m1.1.1.1.1.1.1.2.2.3.cmml">L</mi></mrow><mrow id="S6.E7.m1.1.1.1.1.1.1.2.3" xref="S6.E7.m1.1.1.1.1.1.1.2.3.cmml"><mi id="S6.E7.m1.1.1.1.1.1.1.2.3.2" xref="S6.E7.m1.1.1.1.1.1.1.2.3.2.cmml">δ</mi><mo lspace="0em" rspace="0em" id="S6.E7.m1.1.1.1.1.1.1.2.3.1" xref="S6.E7.m1.1.1.1.1.1.1.2.3.1.cmml">​</mo><msup id="S6.E7.m1.1.1.1.1.1.1.2.3.3" xref="S6.E7.m1.1.1.1.1.1.1.2.3.3.cmml"><mi id="S6.E7.m1.1.1.1.1.1.1.2.3.3.2" xref="S6.E7.m1.1.1.1.1.1.1.2.3.3.2.cmml">W</mi><mi id="S6.E7.m1.1.1.1.1.1.1.2.3.3.3" xref="S6.E7.m1.1.1.1.1.1.1.2.3.3.3.cmml">i</mi></msup></mrow></mfrac><mo id="S6.E7.m1.1.1.1.1.1.1.1" xref="S6.E7.m1.1.1.1.1.1.1.1.cmml">−</mo><mfrac id="S6.E7.m1.1.1.1.1.1.1.3" xref="S6.E7.m1.1.1.1.1.1.1.3.cmml"><mrow id="S6.E7.m1.1.1.1.1.1.1.3.2" xref="S6.E7.m1.1.1.1.1.1.1.3.2.cmml"><mi id="S6.E7.m1.1.1.1.1.1.1.3.2.2" xref="S6.E7.m1.1.1.1.1.1.1.3.2.2.cmml">δ</mi><mo lspace="0em" rspace="0em" id="S6.E7.m1.1.1.1.1.1.1.3.2.1" xref="S6.E7.m1.1.1.1.1.1.1.3.2.1.cmml">​</mo><mi id="S6.E7.m1.1.1.1.1.1.1.3.2.3" xref="S6.E7.m1.1.1.1.1.1.1.3.2.3.cmml">L</mi></mrow><mrow id="S6.E7.m1.1.1.1.1.1.1.3.3" xref="S6.E7.m1.1.1.1.1.1.1.3.3.cmml"><mi id="S6.E7.m1.1.1.1.1.1.1.3.3.2" xref="S6.E7.m1.1.1.1.1.1.1.3.3.2.cmml">δ</mi><mo lspace="0em" rspace="0em" id="S6.E7.m1.1.1.1.1.1.1.3.3.1" xref="S6.E7.m1.1.1.1.1.1.1.3.3.1.cmml">​</mo><msup id="S6.E7.m1.1.1.1.1.1.1.3.3.3" xref="S6.E7.m1.1.1.1.1.1.1.3.3.3.cmml"><mi id="S6.E7.m1.1.1.1.1.1.1.3.3.3.2" xref="S6.E7.m1.1.1.1.1.1.1.3.3.3.2.cmml">W</mi><mrow id="S6.E7.m1.1.1.1.1.1.1.3.3.3.3" xref="S6.E7.m1.1.1.1.1.1.1.3.3.3.3.cmml"><mi id="S6.E7.m1.1.1.1.1.1.1.3.3.3.3.2" xref="S6.E7.m1.1.1.1.1.1.1.3.3.3.3.2.cmml">i</mi><mo id="S6.E7.m1.1.1.1.1.1.1.3.3.3.3.1" xref="S6.E7.m1.1.1.1.1.1.1.3.3.3.3.1.cmml">+</mo><mn id="S6.E7.m1.1.1.1.1.1.1.3.3.3.3.3" xref="S6.E7.m1.1.1.1.1.1.1.3.3.3.3.3.cmml">1</mn></mrow></msup></mrow></mfrac></mrow><mo stretchy="false" id="S6.E7.m1.1.1.1.1.1.3" xref="S6.E7.m1.1.1.1.1.1.1.cmml">)</mo></mrow><mo id="S6.E7.m1.2.2.2.3" xref="S6.E7.m1.2.2.2.3.cmml">/</mo><mrow id="S6.E7.m1.2.2.2.2.1" xref="S6.E7.m1.2.2.2.2.1.1.cmml"><mo stretchy="false" id="S6.E7.m1.2.2.2.2.1.2" xref="S6.E7.m1.2.2.2.2.1.1.cmml">(</mo><mrow id="S6.E7.m1.2.2.2.2.1.1" xref="S6.E7.m1.2.2.2.2.1.1.cmml"><mfrac id="S6.E7.m1.2.2.2.2.1.1.2" xref="S6.E7.m1.2.2.2.2.1.1.2.cmml"><mrow id="S6.E7.m1.2.2.2.2.1.1.2.2" xref="S6.E7.m1.2.2.2.2.1.1.2.2.cmml"><mi id="S6.E7.m1.2.2.2.2.1.1.2.2.2" xref="S6.E7.m1.2.2.2.2.1.1.2.2.2.cmml">δ</mi><mo lspace="0em" rspace="0em" id="S6.E7.m1.2.2.2.2.1.1.2.2.1" xref="S6.E7.m1.2.2.2.2.1.1.2.2.1.cmml">​</mo><mi id="S6.E7.m1.2.2.2.2.1.1.2.2.3" xref="S6.E7.m1.2.2.2.2.1.1.2.2.3.cmml">L</mi></mrow><mrow id="S6.E7.m1.2.2.2.2.1.1.2.3" xref="S6.E7.m1.2.2.2.2.1.1.2.3.cmml"><mi id="S6.E7.m1.2.2.2.2.1.1.2.3.2" xref="S6.E7.m1.2.2.2.2.1.1.2.3.2.cmml">δ</mi><mo lspace="0em" rspace="0em" id="S6.E7.m1.2.2.2.2.1.1.2.3.1" xref="S6.E7.m1.2.2.2.2.1.1.2.3.1.cmml">​</mo><msup id="S6.E7.m1.2.2.2.2.1.1.2.3.3" xref="S6.E7.m1.2.2.2.2.1.1.2.3.3.cmml"><mi id="S6.E7.m1.2.2.2.2.1.1.2.3.3.2" xref="S6.E7.m1.2.2.2.2.1.1.2.3.3.2.cmml">B</mi><mi id="S6.E7.m1.2.2.2.2.1.1.2.3.3.3" xref="S6.E7.m1.2.2.2.2.1.1.2.3.3.3.cmml">i</mi></msup></mrow></mfrac><mo id="S6.E7.m1.2.2.2.2.1.1.1" xref="S6.E7.m1.2.2.2.2.1.1.1.cmml">−</mo><mfrac id="S6.E7.m1.2.2.2.2.1.1.3" xref="S6.E7.m1.2.2.2.2.1.1.3.cmml"><mrow id="S6.E7.m1.2.2.2.2.1.1.3.2" xref="S6.E7.m1.2.2.2.2.1.1.3.2.cmml"><mi id="S6.E7.m1.2.2.2.2.1.1.3.2.2" xref="S6.E7.m1.2.2.2.2.1.1.3.2.2.cmml">δ</mi><mo lspace="0em" rspace="0em" id="S6.E7.m1.2.2.2.2.1.1.3.2.1" xref="S6.E7.m1.2.2.2.2.1.1.3.2.1.cmml">​</mo><mi id="S6.E7.m1.2.2.2.2.1.1.3.2.3" xref="S6.E7.m1.2.2.2.2.1.1.3.2.3.cmml">L</mi></mrow><mrow id="S6.E7.m1.2.2.2.2.1.1.3.3" xref="S6.E7.m1.2.2.2.2.1.1.3.3.cmml"><mi id="S6.E7.m1.2.2.2.2.1.1.3.3.2" xref="S6.E7.m1.2.2.2.2.1.1.3.3.2.cmml">δ</mi><mo lspace="0em" rspace="0em" id="S6.E7.m1.2.2.2.2.1.1.3.3.1" xref="S6.E7.m1.2.2.2.2.1.1.3.3.1.cmml">​</mo><msup id="S6.E7.m1.2.2.2.2.1.1.3.3.3" xref="S6.E7.m1.2.2.2.2.1.1.3.3.3.cmml"><mi id="S6.E7.m1.2.2.2.2.1.1.3.3.3.2" xref="S6.E7.m1.2.2.2.2.1.1.3.3.3.2.cmml">B</mi><mrow id="S6.E7.m1.2.2.2.2.1.1.3.3.3.3" xref="S6.E7.m1.2.2.2.2.1.1.3.3.3.3.cmml"><mi id="S6.E7.m1.2.2.2.2.1.1.3.3.3.3.2" xref="S6.E7.m1.2.2.2.2.1.1.3.3.3.3.2.cmml">i</mi><mo id="S6.E7.m1.2.2.2.2.1.1.3.3.3.3.1" xref="S6.E7.m1.2.2.2.2.1.1.3.3.3.3.1.cmml">+</mo><mn id="S6.E7.m1.2.2.2.2.1.1.3.3.3.3.3" xref="S6.E7.m1.2.2.2.2.1.1.3.3.3.3.3.cmml">1</mn></mrow></msup></mrow></mfrac></mrow><mo stretchy="false" id="S6.E7.m1.2.2.2.2.1.3" xref="S6.E7.m1.2.2.2.2.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S6.E7.m1.2b"><apply id="S6.E7.m1.2.2.cmml" xref="S6.E7.m1.2.2"><eq id="S6.E7.m1.2.2.3.cmml" xref="S6.E7.m1.2.2.3"></eq><apply id="S6.E7.m1.2.2.4.cmml" xref="S6.E7.m1.2.2.4"><csymbol cd="ambiguous" id="S6.E7.m1.2.2.4.1.cmml" xref="S6.E7.m1.2.2.4">superscript</csymbol><ci id="S6.E7.m1.2.2.4.2.cmml" xref="S6.E7.m1.2.2.4.2">𝑥</ci><ci id="S6.E7.m1.2.2.4.3.cmml" xref="S6.E7.m1.2.2.4.3">𝑖</ci></apply><apply id="S6.E7.m1.2.2.2.cmml" xref="S6.E7.m1.2.2.2"><divide id="S6.E7.m1.2.2.2.3.cmml" xref="S6.E7.m1.2.2.2.3"></divide><apply id="S6.E7.m1.1.1.1.1.1.1.cmml" xref="S6.E7.m1.1.1.1.1.1"><minus id="S6.E7.m1.1.1.1.1.1.1.1.cmml" xref="S6.E7.m1.1.1.1.1.1.1.1"></minus><apply id="S6.E7.m1.1.1.1.1.1.1.2.cmml" xref="S6.E7.m1.1.1.1.1.1.1.2"><divide id="S6.E7.m1.1.1.1.1.1.1.2.1.cmml" xref="S6.E7.m1.1.1.1.1.1.1.2"></divide><apply id="S6.E7.m1.1.1.1.1.1.1.2.2.cmml" xref="S6.E7.m1.1.1.1.1.1.1.2.2"><times id="S6.E7.m1.1.1.1.1.1.1.2.2.1.cmml" xref="S6.E7.m1.1.1.1.1.1.1.2.2.1"></times><ci id="S6.E7.m1.1.1.1.1.1.1.2.2.2.cmml" xref="S6.E7.m1.1.1.1.1.1.1.2.2.2">𝛿</ci><ci id="S6.E7.m1.1.1.1.1.1.1.2.2.3.cmml" xref="S6.E7.m1.1.1.1.1.1.1.2.2.3">𝐿</ci></apply><apply id="S6.E7.m1.1.1.1.1.1.1.2.3.cmml" xref="S6.E7.m1.1.1.1.1.1.1.2.3"><times id="S6.E7.m1.1.1.1.1.1.1.2.3.1.cmml" xref="S6.E7.m1.1.1.1.1.1.1.2.3.1"></times><ci id="S6.E7.m1.1.1.1.1.1.1.2.3.2.cmml" xref="S6.E7.m1.1.1.1.1.1.1.2.3.2">𝛿</ci><apply id="S6.E7.m1.1.1.1.1.1.1.2.3.3.cmml" xref="S6.E7.m1.1.1.1.1.1.1.2.3.3"><csymbol cd="ambiguous" id="S6.E7.m1.1.1.1.1.1.1.2.3.3.1.cmml" xref="S6.E7.m1.1.1.1.1.1.1.2.3.3">superscript</csymbol><ci id="S6.E7.m1.1.1.1.1.1.1.2.3.3.2.cmml" xref="S6.E7.m1.1.1.1.1.1.1.2.3.3.2">𝑊</ci><ci id="S6.E7.m1.1.1.1.1.1.1.2.3.3.3.cmml" xref="S6.E7.m1.1.1.1.1.1.1.2.3.3.3">𝑖</ci></apply></apply></apply><apply id="S6.E7.m1.1.1.1.1.1.1.3.cmml" xref="S6.E7.m1.1.1.1.1.1.1.3"><divide id="S6.E7.m1.1.1.1.1.1.1.3.1.cmml" xref="S6.E7.m1.1.1.1.1.1.1.3"></divide><apply id="S6.E7.m1.1.1.1.1.1.1.3.2.cmml" xref="S6.E7.m1.1.1.1.1.1.1.3.2"><times id="S6.E7.m1.1.1.1.1.1.1.3.2.1.cmml" xref="S6.E7.m1.1.1.1.1.1.1.3.2.1"></times><ci id="S6.E7.m1.1.1.1.1.1.1.3.2.2.cmml" xref="S6.E7.m1.1.1.1.1.1.1.3.2.2">𝛿</ci><ci id="S6.E7.m1.1.1.1.1.1.1.3.2.3.cmml" xref="S6.E7.m1.1.1.1.1.1.1.3.2.3">𝐿</ci></apply><apply id="S6.E7.m1.1.1.1.1.1.1.3.3.cmml" xref="S6.E7.m1.1.1.1.1.1.1.3.3"><times id="S6.E7.m1.1.1.1.1.1.1.3.3.1.cmml" xref="S6.E7.m1.1.1.1.1.1.1.3.3.1"></times><ci id="S6.E7.m1.1.1.1.1.1.1.3.3.2.cmml" xref="S6.E7.m1.1.1.1.1.1.1.3.3.2">𝛿</ci><apply id="S6.E7.m1.1.1.1.1.1.1.3.3.3.cmml" xref="S6.E7.m1.1.1.1.1.1.1.3.3.3"><csymbol cd="ambiguous" id="S6.E7.m1.1.1.1.1.1.1.3.3.3.1.cmml" xref="S6.E7.m1.1.1.1.1.1.1.3.3.3">superscript</csymbol><ci id="S6.E7.m1.1.1.1.1.1.1.3.3.3.2.cmml" xref="S6.E7.m1.1.1.1.1.1.1.3.3.3.2">𝑊</ci><apply id="S6.E7.m1.1.1.1.1.1.1.3.3.3.3.cmml" xref="S6.E7.m1.1.1.1.1.1.1.3.3.3.3"><plus id="S6.E7.m1.1.1.1.1.1.1.3.3.3.3.1.cmml" xref="S6.E7.m1.1.1.1.1.1.1.3.3.3.3.1"></plus><ci id="S6.E7.m1.1.1.1.1.1.1.3.3.3.3.2.cmml" xref="S6.E7.m1.1.1.1.1.1.1.3.3.3.3.2">𝑖</ci><cn type="integer" id="S6.E7.m1.1.1.1.1.1.1.3.3.3.3.3.cmml" xref="S6.E7.m1.1.1.1.1.1.1.3.3.3.3.3">1</cn></apply></apply></apply></apply></apply><apply id="S6.E7.m1.2.2.2.2.1.1.cmml" xref="S6.E7.m1.2.2.2.2.1"><minus id="S6.E7.m1.2.2.2.2.1.1.1.cmml" xref="S6.E7.m1.2.2.2.2.1.1.1"></minus><apply id="S6.E7.m1.2.2.2.2.1.1.2.cmml" xref="S6.E7.m1.2.2.2.2.1.1.2"><divide id="S6.E7.m1.2.2.2.2.1.1.2.1.cmml" xref="S6.E7.m1.2.2.2.2.1.1.2"></divide><apply id="S6.E7.m1.2.2.2.2.1.1.2.2.cmml" xref="S6.E7.m1.2.2.2.2.1.1.2.2"><times id="S6.E7.m1.2.2.2.2.1.1.2.2.1.cmml" xref="S6.E7.m1.2.2.2.2.1.1.2.2.1"></times><ci id="S6.E7.m1.2.2.2.2.1.1.2.2.2.cmml" xref="S6.E7.m1.2.2.2.2.1.1.2.2.2">𝛿</ci><ci id="S6.E7.m1.2.2.2.2.1.1.2.2.3.cmml" xref="S6.E7.m1.2.2.2.2.1.1.2.2.3">𝐿</ci></apply><apply id="S6.E7.m1.2.2.2.2.1.1.2.3.cmml" xref="S6.E7.m1.2.2.2.2.1.1.2.3"><times id="S6.E7.m1.2.2.2.2.1.1.2.3.1.cmml" xref="S6.E7.m1.2.2.2.2.1.1.2.3.1"></times><ci id="S6.E7.m1.2.2.2.2.1.1.2.3.2.cmml" xref="S6.E7.m1.2.2.2.2.1.1.2.3.2">𝛿</ci><apply id="S6.E7.m1.2.2.2.2.1.1.2.3.3.cmml" xref="S6.E7.m1.2.2.2.2.1.1.2.3.3"><csymbol cd="ambiguous" id="S6.E7.m1.2.2.2.2.1.1.2.3.3.1.cmml" xref="S6.E7.m1.2.2.2.2.1.1.2.3.3">superscript</csymbol><ci id="S6.E7.m1.2.2.2.2.1.1.2.3.3.2.cmml" xref="S6.E7.m1.2.2.2.2.1.1.2.3.3.2">𝐵</ci><ci id="S6.E7.m1.2.2.2.2.1.1.2.3.3.3.cmml" xref="S6.E7.m1.2.2.2.2.1.1.2.3.3.3">𝑖</ci></apply></apply></apply><apply id="S6.E7.m1.2.2.2.2.1.1.3.cmml" xref="S6.E7.m1.2.2.2.2.1.1.3"><divide id="S6.E7.m1.2.2.2.2.1.1.3.1.cmml" xref="S6.E7.m1.2.2.2.2.1.1.3"></divide><apply id="S6.E7.m1.2.2.2.2.1.1.3.2.cmml" xref="S6.E7.m1.2.2.2.2.1.1.3.2"><times id="S6.E7.m1.2.2.2.2.1.1.3.2.1.cmml" xref="S6.E7.m1.2.2.2.2.1.1.3.2.1"></times><ci id="S6.E7.m1.2.2.2.2.1.1.3.2.2.cmml" xref="S6.E7.m1.2.2.2.2.1.1.3.2.2">𝛿</ci><ci id="S6.E7.m1.2.2.2.2.1.1.3.2.3.cmml" xref="S6.E7.m1.2.2.2.2.1.1.3.2.3">𝐿</ci></apply><apply id="S6.E7.m1.2.2.2.2.1.1.3.3.cmml" xref="S6.E7.m1.2.2.2.2.1.1.3.3"><times id="S6.E7.m1.2.2.2.2.1.1.3.3.1.cmml" xref="S6.E7.m1.2.2.2.2.1.1.3.3.1"></times><ci id="S6.E7.m1.2.2.2.2.1.1.3.3.2.cmml" xref="S6.E7.m1.2.2.2.2.1.1.3.3.2">𝛿</ci><apply id="S6.E7.m1.2.2.2.2.1.1.3.3.3.cmml" xref="S6.E7.m1.2.2.2.2.1.1.3.3.3"><csymbol cd="ambiguous" id="S6.E7.m1.2.2.2.2.1.1.3.3.3.1.cmml" xref="S6.E7.m1.2.2.2.2.1.1.3.3.3">superscript</csymbol><ci id="S6.E7.m1.2.2.2.2.1.1.3.3.3.2.cmml" xref="S6.E7.m1.2.2.2.2.1.1.3.3.3.2">𝐵</ci><apply id="S6.E7.m1.2.2.2.2.1.1.3.3.3.3.cmml" xref="S6.E7.m1.2.2.2.2.1.1.3.3.3.3"><plus id="S6.E7.m1.2.2.2.2.1.1.3.3.3.3.1.cmml" xref="S6.E7.m1.2.2.2.2.1.1.3.3.3.3.1"></plus><ci id="S6.E7.m1.2.2.2.2.1.1.3.3.3.3.2.cmml" xref="S6.E7.m1.2.2.2.2.1.1.3.3.3.3.2">𝑖</ci><cn type="integer" id="S6.E7.m1.2.2.2.2.1.1.3.3.3.3.3.cmml" xref="S6.E7.m1.2.2.2.2.1.1.3.3.3.3.3">1</cn></apply></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.E7.m1.2c">x^{i}=(\frac{\delta L}{\delta W^{i}}-\frac{\delta L}{\delta W^{i+1}})/(\frac{\delta L}{\delta B^{i}}-\frac{\delta L}{\delta B^{i+1}})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p id="S6.SS1.SSS2.p3.8" class="ltx_p">where <math id="S6.SS1.SSS2.p3.1.m1.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S6.SS1.SSS2.p3.1.m1.1a"><mi id="S6.SS1.SSS2.p3.1.m1.1.1" xref="S6.SS1.SSS2.p3.1.m1.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S6.SS1.SSS2.p3.1.m1.1b"><ci id="S6.SS1.SSS2.p3.1.m1.1.1.cmml" xref="S6.SS1.SSS2.p3.1.m1.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.SSS2.p3.1.m1.1c">i</annotation></semantics></math> is the activated bin and <math id="S6.SS1.SSS2.p3.2.m2.1" class="ltx_Math" alttext="i+1" display="inline"><semantics id="S6.SS1.SSS2.p3.2.m2.1a"><mrow id="S6.SS1.SSS2.p3.2.m2.1.1" xref="S6.SS1.SSS2.p3.2.m2.1.1.cmml"><mi id="S6.SS1.SSS2.p3.2.m2.1.1.2" xref="S6.SS1.SSS2.p3.2.m2.1.1.2.cmml">i</mi><mo id="S6.SS1.SSS2.p3.2.m2.1.1.1" xref="S6.SS1.SSS2.p3.2.m2.1.1.1.cmml">+</mo><mn id="S6.SS1.SSS2.p3.2.m2.1.1.3" xref="S6.SS1.SSS2.p3.2.m2.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.SS1.SSS2.p3.2.m2.1b"><apply id="S6.SS1.SSS2.p3.2.m2.1.1.cmml" xref="S6.SS1.SSS2.p3.2.m2.1.1"><plus id="S6.SS1.SSS2.p3.2.m2.1.1.1.cmml" xref="S6.SS1.SSS2.p3.2.m2.1.1.1"></plus><ci id="S6.SS1.SSS2.p3.2.m2.1.1.2.cmml" xref="S6.SS1.SSS2.p3.2.m2.1.1.2">𝑖</ci><cn type="integer" id="S6.SS1.SSS2.p3.2.m2.1.1.3.cmml" xref="S6.SS1.SSS2.p3.2.m2.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.SSS2.p3.2.m2.1c">i+1</annotation></semantics></math> is the bin with the next higher cutoff bias. For Equation <a href="#S6.E7" title="In 6.1.2. Linear layer leakage. ‣ 6.1. Data Reconstruction Attacks ‣ 6. Privacy Attacks ‣ Federated Learning Privacy: Attacks, Defenses, Applications, and Policy Landscape — A Survey" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> to hold true, the attack requires the use of two consecutive FC layers. The first layer is used to leak the inputs using Equation <a href="#S6.E7" title="In 6.1.2. Linear layer leakage. ‣ 6.1. Data Reconstruction Attacks ‣ 6. Privacy Attacks ‣ Federated Learning Privacy: Attacks, Defenses, Applications, and Policy Landscape — A Survey" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> and the second FC layer maintains the requirement that <math id="S6.SS1.SSS2.p3.3.m3.1" class="ltx_Math" alttext="\frac{\delta L}{\delta B^{i}}" display="inline"><semantics id="S6.SS1.SSS2.p3.3.m3.1a"><mfrac id="S6.SS1.SSS2.p3.3.m3.1.1" xref="S6.SS1.SSS2.p3.3.m3.1.1.cmml"><mrow id="S6.SS1.SSS2.p3.3.m3.1.1.2" xref="S6.SS1.SSS2.p3.3.m3.1.1.2.cmml"><mi id="S6.SS1.SSS2.p3.3.m3.1.1.2.2" xref="S6.SS1.SSS2.p3.3.m3.1.1.2.2.cmml">δ</mi><mo lspace="0em" rspace="0em" id="S6.SS1.SSS2.p3.3.m3.1.1.2.1" xref="S6.SS1.SSS2.p3.3.m3.1.1.2.1.cmml">​</mo><mi id="S6.SS1.SSS2.p3.3.m3.1.1.2.3" xref="S6.SS1.SSS2.p3.3.m3.1.1.2.3.cmml">L</mi></mrow><mrow id="S6.SS1.SSS2.p3.3.m3.1.1.3" xref="S6.SS1.SSS2.p3.3.m3.1.1.3.cmml"><mi id="S6.SS1.SSS2.p3.3.m3.1.1.3.2" xref="S6.SS1.SSS2.p3.3.m3.1.1.3.2.cmml">δ</mi><mo lspace="0em" rspace="0em" id="S6.SS1.SSS2.p3.3.m3.1.1.3.1" xref="S6.SS1.SSS2.p3.3.m3.1.1.3.1.cmml">​</mo><msup id="S6.SS1.SSS2.p3.3.m3.1.1.3.3" xref="S6.SS1.SSS2.p3.3.m3.1.1.3.3.cmml"><mi id="S6.SS1.SSS2.p3.3.m3.1.1.3.3.2" xref="S6.SS1.SSS2.p3.3.m3.1.1.3.3.2.cmml">B</mi><mi id="S6.SS1.SSS2.p3.3.m3.1.1.3.3.3" xref="S6.SS1.SSS2.p3.3.m3.1.1.3.3.3.cmml">i</mi></msup></mrow></mfrac><annotation-xml encoding="MathML-Content" id="S6.SS1.SSS2.p3.3.m3.1b"><apply id="S6.SS1.SSS2.p3.3.m3.1.1.cmml" xref="S6.SS1.SSS2.p3.3.m3.1.1"><divide id="S6.SS1.SSS2.p3.3.m3.1.1.1.cmml" xref="S6.SS1.SSS2.p3.3.m3.1.1"></divide><apply id="S6.SS1.SSS2.p3.3.m3.1.1.2.cmml" xref="S6.SS1.SSS2.p3.3.m3.1.1.2"><times id="S6.SS1.SSS2.p3.3.m3.1.1.2.1.cmml" xref="S6.SS1.SSS2.p3.3.m3.1.1.2.1"></times><ci id="S6.SS1.SSS2.p3.3.m3.1.1.2.2.cmml" xref="S6.SS1.SSS2.p3.3.m3.1.1.2.2">𝛿</ci><ci id="S6.SS1.SSS2.p3.3.m3.1.1.2.3.cmml" xref="S6.SS1.SSS2.p3.3.m3.1.1.2.3">𝐿</ci></apply><apply id="S6.SS1.SSS2.p3.3.m3.1.1.3.cmml" xref="S6.SS1.SSS2.p3.3.m3.1.1.3"><times id="S6.SS1.SSS2.p3.3.m3.1.1.3.1.cmml" xref="S6.SS1.SSS2.p3.3.m3.1.1.3.1"></times><ci id="S6.SS1.SSS2.p3.3.m3.1.1.3.2.cmml" xref="S6.SS1.SSS2.p3.3.m3.1.1.3.2">𝛿</ci><apply id="S6.SS1.SSS2.p3.3.m3.1.1.3.3.cmml" xref="S6.SS1.SSS2.p3.3.m3.1.1.3.3"><csymbol cd="ambiguous" id="S6.SS1.SSS2.p3.3.m3.1.1.3.3.1.cmml" xref="S6.SS1.SSS2.p3.3.m3.1.1.3.3">superscript</csymbol><ci id="S6.SS1.SSS2.p3.3.m3.1.1.3.3.2.cmml" xref="S6.SS1.SSS2.p3.3.m3.1.1.3.3.2">𝐵</ci><ci id="S6.SS1.SSS2.p3.3.m3.1.1.3.3.3.cmml" xref="S6.SS1.SSS2.p3.3.m3.1.1.3.3.3">𝑖</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.SSS2.p3.3.m3.1c">\frac{\delta L}{\delta B^{i}}</annotation></semantics></math> and <math id="S6.SS1.SSS2.p3.4.m4.1" class="ltx_Math" alttext="\frac{\delta L}{\delta W^{i}}" display="inline"><semantics id="S6.SS1.SSS2.p3.4.m4.1a"><mfrac id="S6.SS1.SSS2.p3.4.m4.1.1" xref="S6.SS1.SSS2.p3.4.m4.1.1.cmml"><mrow id="S6.SS1.SSS2.p3.4.m4.1.1.2" xref="S6.SS1.SSS2.p3.4.m4.1.1.2.cmml"><mi id="S6.SS1.SSS2.p3.4.m4.1.1.2.2" xref="S6.SS1.SSS2.p3.4.m4.1.1.2.2.cmml">δ</mi><mo lspace="0em" rspace="0em" id="S6.SS1.SSS2.p3.4.m4.1.1.2.1" xref="S6.SS1.SSS2.p3.4.m4.1.1.2.1.cmml">​</mo><mi id="S6.SS1.SSS2.p3.4.m4.1.1.2.3" xref="S6.SS1.SSS2.p3.4.m4.1.1.2.3.cmml">L</mi></mrow><mrow id="S6.SS1.SSS2.p3.4.m4.1.1.3" xref="S6.SS1.SSS2.p3.4.m4.1.1.3.cmml"><mi id="S6.SS1.SSS2.p3.4.m4.1.1.3.2" xref="S6.SS1.SSS2.p3.4.m4.1.1.3.2.cmml">δ</mi><mo lspace="0em" rspace="0em" id="S6.SS1.SSS2.p3.4.m4.1.1.3.1" xref="S6.SS1.SSS2.p3.4.m4.1.1.3.1.cmml">​</mo><msup id="S6.SS1.SSS2.p3.4.m4.1.1.3.3" xref="S6.SS1.SSS2.p3.4.m4.1.1.3.3.cmml"><mi id="S6.SS1.SSS2.p3.4.m4.1.1.3.3.2" xref="S6.SS1.SSS2.p3.4.m4.1.1.3.3.2.cmml">W</mi><mi id="S6.SS1.SSS2.p3.4.m4.1.1.3.3.3" xref="S6.SS1.SSS2.p3.4.m4.1.1.3.3.3.cmml">i</mi></msup></mrow></mfrac><annotation-xml encoding="MathML-Content" id="S6.SS1.SSS2.p3.4.m4.1b"><apply id="S6.SS1.SSS2.p3.4.m4.1.1.cmml" xref="S6.SS1.SSS2.p3.4.m4.1.1"><divide id="S6.SS1.SSS2.p3.4.m4.1.1.1.cmml" xref="S6.SS1.SSS2.p3.4.m4.1.1"></divide><apply id="S6.SS1.SSS2.p3.4.m4.1.1.2.cmml" xref="S6.SS1.SSS2.p3.4.m4.1.1.2"><times id="S6.SS1.SSS2.p3.4.m4.1.1.2.1.cmml" xref="S6.SS1.SSS2.p3.4.m4.1.1.2.1"></times><ci id="S6.SS1.SSS2.p3.4.m4.1.1.2.2.cmml" xref="S6.SS1.SSS2.p3.4.m4.1.1.2.2">𝛿</ci><ci id="S6.SS1.SSS2.p3.4.m4.1.1.2.3.cmml" xref="S6.SS1.SSS2.p3.4.m4.1.1.2.3">𝐿</ci></apply><apply id="S6.SS1.SSS2.p3.4.m4.1.1.3.cmml" xref="S6.SS1.SSS2.p3.4.m4.1.1.3"><times id="S6.SS1.SSS2.p3.4.m4.1.1.3.1.cmml" xref="S6.SS1.SSS2.p3.4.m4.1.1.3.1"></times><ci id="S6.SS1.SSS2.p3.4.m4.1.1.3.2.cmml" xref="S6.SS1.SSS2.p3.4.m4.1.1.3.2">𝛿</ci><apply id="S6.SS1.SSS2.p3.4.m4.1.1.3.3.cmml" xref="S6.SS1.SSS2.p3.4.m4.1.1.3.3"><csymbol cd="ambiguous" id="S6.SS1.SSS2.p3.4.m4.1.1.3.3.1.cmml" xref="S6.SS1.SSS2.p3.4.m4.1.1.3.3">superscript</csymbol><ci id="S6.SS1.SSS2.p3.4.m4.1.1.3.3.2.cmml" xref="S6.SS1.SSS2.p3.4.m4.1.1.3.3.2">𝑊</ci><ci id="S6.SS1.SSS2.p3.4.m4.1.1.3.3.3.cmml" xref="S6.SS1.SSS2.p3.4.m4.1.1.3.3.3">𝑖</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.SSS2.p3.4.m4.1c">\frac{\delta L}{\delta W^{i}}</annotation></semantics></math> are the same for any neuron that the same input activates. This is achieved by having the same weight parameters connecting each neuron of the first FC layer to the second FC layer. For example, if the first FC layer has <math id="S6.SS1.SSS2.p3.5.m5.1" class="ltx_Math" alttext="1024" display="inline"><semantics id="S6.SS1.SSS2.p3.5.m5.1a"><mn id="S6.SS1.SSS2.p3.5.m5.1.1" xref="S6.SS1.SSS2.p3.5.m5.1.1.cmml">1024</mn><annotation-xml encoding="MathML-Content" id="S6.SS1.SSS2.p3.5.m5.1b"><cn type="integer" id="S6.SS1.SSS2.p3.5.m5.1.1.cmml" xref="S6.SS1.SSS2.p3.5.m5.1.1">1024</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.SSS2.p3.5.m5.1c">1024</annotation></semantics></math> units and the second has <math id="S6.SS1.SSS2.p3.6.m6.1" class="ltx_Math" alttext="256" display="inline"><semantics id="S6.SS1.SSS2.p3.6.m6.1a"><mn id="S6.SS1.SSS2.p3.6.m6.1.1" xref="S6.SS1.SSS2.p3.6.m6.1.1.cmml">256</mn><annotation-xml encoding="MathML-Content" id="S6.SS1.SSS2.p3.6.m6.1b"><cn type="integer" id="S6.SS1.SSS2.p3.6.m6.1.1.cmml" xref="S6.SS1.SSS2.p3.6.m6.1.1">256</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.SSS2.p3.6.m6.1c">256</annotation></semantics></math>, the weights connecting them would have
a dimension of <math id="S6.SS1.SSS2.p3.7.m7.1" class="ltx_Math" alttext="1024\times 256" display="inline"><semantics id="S6.SS1.SSS2.p3.7.m7.1a"><mrow id="S6.SS1.SSS2.p3.7.m7.1.1" xref="S6.SS1.SSS2.p3.7.m7.1.1.cmml"><mn id="S6.SS1.SSS2.p3.7.m7.1.1.2" xref="S6.SS1.SSS2.p3.7.m7.1.1.2.cmml">1024</mn><mo lspace="0.222em" rspace="0.222em" id="S6.SS1.SSS2.p3.7.m7.1.1.1" xref="S6.SS1.SSS2.p3.7.m7.1.1.1.cmml">×</mo><mn id="S6.SS1.SSS2.p3.7.m7.1.1.3" xref="S6.SS1.SSS2.p3.7.m7.1.1.3.cmml">256</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.SS1.SSS2.p3.7.m7.1b"><apply id="S6.SS1.SSS2.p3.7.m7.1.1.cmml" xref="S6.SS1.SSS2.p3.7.m7.1.1"><times id="S6.SS1.SSS2.p3.7.m7.1.1.1.cmml" xref="S6.SS1.SSS2.p3.7.m7.1.1.1"></times><cn type="integer" id="S6.SS1.SSS2.p3.7.m7.1.1.2.cmml" xref="S6.SS1.SSS2.p3.7.m7.1.1.2">1024</cn><cn type="integer" id="S6.SS1.SSS2.p3.7.m7.1.1.3.cmml" xref="S6.SS1.SSS2.p3.7.m7.1.1.3">256</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.SSS2.p3.7.m7.1c">1024\times 256</annotation></semantics></math>. The above property indicates that every row of the weight matrix is equivalent, e.g. <math id="S6.SS1.SSS2.p3.8.m8.6" class="ltx_Math" alttext="[0,:]=[1,:]=\dots=[1023,:]" display="inline"><semantics id="S6.SS1.SSS2.p3.8.m8.6a"><mrow id="S6.SS1.SSS2.p3.8.m8.6.7" xref="S6.SS1.SSS2.p3.8.m8.6.7.cmml"><mrow id="S6.SS1.SSS2.p3.8.m8.6.7.2.2" xref="S6.SS1.SSS2.p3.8.m8.6.7.2.1.cmml"><mo stretchy="false" id="S6.SS1.SSS2.p3.8.m8.6.7.2.2.1" xref="S6.SS1.SSS2.p3.8.m8.6.7.2.1.cmml">[</mo><mn id="S6.SS1.SSS2.p3.8.m8.1.1" xref="S6.SS1.SSS2.p3.8.m8.1.1.cmml">0</mn><mo id="S6.SS1.SSS2.p3.8.m8.6.7.2.2.2" xref="S6.SS1.SSS2.p3.8.m8.6.7.2.1.cmml">,</mo><mo rspace="0em" id="S6.SS1.SSS2.p3.8.m8.2.2" xref="S6.SS1.SSS2.p3.8.m8.2.2.cmml">:</mo><mo stretchy="false" id="S6.SS1.SSS2.p3.8.m8.6.7.2.2.3" xref="S6.SS1.SSS2.p3.8.m8.6.7.2.1.cmml">]</mo></mrow><mo id="S6.SS1.SSS2.p3.8.m8.6.7.3" xref="S6.SS1.SSS2.p3.8.m8.6.7.3.cmml">=</mo><mrow id="S6.SS1.SSS2.p3.8.m8.6.7.4.2" xref="S6.SS1.SSS2.p3.8.m8.6.7.4.1.cmml"><mo stretchy="false" id="S6.SS1.SSS2.p3.8.m8.6.7.4.2.1" xref="S6.SS1.SSS2.p3.8.m8.6.7.4.1.cmml">[</mo><mn id="S6.SS1.SSS2.p3.8.m8.3.3" xref="S6.SS1.SSS2.p3.8.m8.3.3.cmml">1</mn><mo id="S6.SS1.SSS2.p3.8.m8.6.7.4.2.2" xref="S6.SS1.SSS2.p3.8.m8.6.7.4.1.cmml">,</mo><mo rspace="0em" id="S6.SS1.SSS2.p3.8.m8.4.4" xref="S6.SS1.SSS2.p3.8.m8.4.4.cmml">:</mo><mo stretchy="false" id="S6.SS1.SSS2.p3.8.m8.6.7.4.2.3" xref="S6.SS1.SSS2.p3.8.m8.6.7.4.1.cmml">]</mo></mrow><mo id="S6.SS1.SSS2.p3.8.m8.6.7.5" xref="S6.SS1.SSS2.p3.8.m8.6.7.5.cmml">=</mo><mi mathvariant="normal" id="S6.SS1.SSS2.p3.8.m8.6.7.6" xref="S6.SS1.SSS2.p3.8.m8.6.7.6.cmml">⋯</mi><mo id="S6.SS1.SSS2.p3.8.m8.6.7.7" xref="S6.SS1.SSS2.p3.8.m8.6.7.7.cmml">=</mo><mrow id="S6.SS1.SSS2.p3.8.m8.6.7.8.2" xref="S6.SS1.SSS2.p3.8.m8.6.7.8.1.cmml"><mo stretchy="false" id="S6.SS1.SSS2.p3.8.m8.6.7.8.2.1" xref="S6.SS1.SSS2.p3.8.m8.6.7.8.1.cmml">[</mo><mn id="S6.SS1.SSS2.p3.8.m8.5.5" xref="S6.SS1.SSS2.p3.8.m8.5.5.cmml">1023</mn><mo id="S6.SS1.SSS2.p3.8.m8.6.7.8.2.2" xref="S6.SS1.SSS2.p3.8.m8.6.7.8.1.cmml">,</mo><mo rspace="0em" id="S6.SS1.SSS2.p3.8.m8.6.6" xref="S6.SS1.SSS2.p3.8.m8.6.6.cmml">:</mo><mo stretchy="false" id="S6.SS1.SSS2.p3.8.m8.6.7.8.2.3" xref="S6.SS1.SSS2.p3.8.m8.6.7.8.1.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S6.SS1.SSS2.p3.8.m8.6b"><apply id="S6.SS1.SSS2.p3.8.m8.6.7.cmml" xref="S6.SS1.SSS2.p3.8.m8.6.7"><and id="S6.SS1.SSS2.p3.8.m8.6.7a.cmml" xref="S6.SS1.SSS2.p3.8.m8.6.7"></and><apply id="S6.SS1.SSS2.p3.8.m8.6.7b.cmml" xref="S6.SS1.SSS2.p3.8.m8.6.7"><eq id="S6.SS1.SSS2.p3.8.m8.6.7.3.cmml" xref="S6.SS1.SSS2.p3.8.m8.6.7.3"></eq><interval closure="closed" id="S6.SS1.SSS2.p3.8.m8.6.7.2.1.cmml" xref="S6.SS1.SSS2.p3.8.m8.6.7.2.2"><cn type="integer" id="S6.SS1.SSS2.p3.8.m8.1.1.cmml" xref="S6.SS1.SSS2.p3.8.m8.1.1">0</cn><ci id="S6.SS1.SSS2.p3.8.m8.2.2.cmml" xref="S6.SS1.SSS2.p3.8.m8.2.2">:</ci></interval><interval closure="closed" id="S6.SS1.SSS2.p3.8.m8.6.7.4.1.cmml" xref="S6.SS1.SSS2.p3.8.m8.6.7.4.2"><cn type="integer" id="S6.SS1.SSS2.p3.8.m8.3.3.cmml" xref="S6.SS1.SSS2.p3.8.m8.3.3">1</cn><ci id="S6.SS1.SSS2.p3.8.m8.4.4.cmml" xref="S6.SS1.SSS2.p3.8.m8.4.4">:</ci></interval></apply><apply id="S6.SS1.SSS2.p3.8.m8.6.7c.cmml" xref="S6.SS1.SSS2.p3.8.m8.6.7"><eq id="S6.SS1.SSS2.p3.8.m8.6.7.5.cmml" xref="S6.SS1.SSS2.p3.8.m8.6.7.5"></eq><share href="#S6.SS1.SSS2.p3.8.m8.6.7.4.cmml" id="S6.SS1.SSS2.p3.8.m8.6.7d.cmml" xref="S6.SS1.SSS2.p3.8.m8.6.7"></share><ci id="S6.SS1.SSS2.p3.8.m8.6.7.6.cmml" xref="S6.SS1.SSS2.p3.8.m8.6.7.6">⋯</ci></apply><apply id="S6.SS1.SSS2.p3.8.m8.6.7e.cmml" xref="S6.SS1.SSS2.p3.8.m8.6.7"><eq id="S6.SS1.SSS2.p3.8.m8.6.7.7.cmml" xref="S6.SS1.SSS2.p3.8.m8.6.7.7"></eq><share href="#S6.SS1.SSS2.p3.8.m8.6.7.6.cmml" id="S6.SS1.SSS2.p3.8.m8.6.7f.cmml" xref="S6.SS1.SSS2.p3.8.m8.6.7"></share><interval closure="closed" id="S6.SS1.SSS2.p3.8.m8.6.7.8.1.cmml" xref="S6.SS1.SSS2.p3.8.m8.6.7.8.2"><cn type="integer" id="S6.SS1.SSS2.p3.8.m8.5.5.cmml" xref="S6.SS1.SSS2.p3.8.m8.5.5">1023</cn><ci id="S6.SS1.SSS2.p3.8.m8.6.6.cmml" xref="S6.SS1.SSS2.p3.8.m8.6.6">:</ci></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.SSS2.p3.8.m8.6c">[0,:]=[1,:]=\dots=[1023,:]</annotation></semantics></math>.</p>
</div>
<div id="S6.SS1.SSS2.p4" class="ltx_para ltx_noindent">
<p id="S6.SS1.SSS2.p4.3" class="ltx_p"><span id="S6.SS1.SSS2.p4.3.1" class="ltx_text ltx_font_bold">FedAvg</span>. While the previous method works for FedSGD, for FedAvg, the model changes during local iterations and this prevents the reconstruction attack. As a result, <cite class="ltx_cite ltx_citemacro_citep">(Fowl et al<span class="ltx_text">.</span>, <a href="#bib.bib51" title="" class="ltx_ref">2022</a>)</cite> proposed the sparse variant of the attack which uses an activation function with a double-sided threshold (e.g., Hardtanh) such as:</p>
<table id="S6.E8" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left"><span class="ltx_tag ltx_tag_equation ltx_align_left">(8)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S6.E8.m1.7" class="ltx_Math" alttext="f(x)=\begin{cases}0&amp;x\leq 0\\
x&amp;0\leq x\leq 1\\
1&amp;1\leq x\end{cases}" display="block"><semantics id="S6.E8.m1.7a"><mrow id="S6.E8.m1.7.8" xref="S6.E8.m1.7.8.cmml"><mrow id="S6.E8.m1.7.8.2" xref="S6.E8.m1.7.8.2.cmml"><mi id="S6.E8.m1.7.8.2.2" xref="S6.E8.m1.7.8.2.2.cmml">f</mi><mo lspace="0em" rspace="0em" id="S6.E8.m1.7.8.2.1" xref="S6.E8.m1.7.8.2.1.cmml">​</mo><mrow id="S6.E8.m1.7.8.2.3.2" xref="S6.E8.m1.7.8.2.cmml"><mo stretchy="false" id="S6.E8.m1.7.8.2.3.2.1" xref="S6.E8.m1.7.8.2.cmml">(</mo><mi id="S6.E8.m1.7.7" xref="S6.E8.m1.7.7.cmml">x</mi><mo stretchy="false" id="S6.E8.m1.7.8.2.3.2.2" xref="S6.E8.m1.7.8.2.cmml">)</mo></mrow></mrow><mo id="S6.E8.m1.7.8.1" xref="S6.E8.m1.7.8.1.cmml">=</mo><mrow id="S6.E8.m1.6.6" xref="S6.E8.m1.7.8.3.1.cmml"><mo id="S6.E8.m1.6.6.7" xref="S6.E8.m1.7.8.3.1.1.cmml">{</mo><mtable columnspacing="5pt" displaystyle="true" rowspacing="0pt" id="S6.E8.m1.6.6.6" xref="S6.E8.m1.7.8.3.1.cmml"><mtr id="S6.E8.m1.6.6.6a" xref="S6.E8.m1.7.8.3.1.cmml"><mtd class="ltx_align_left" columnalign="left" id="S6.E8.m1.6.6.6b" xref="S6.E8.m1.7.8.3.1.cmml"><mn id="S6.E8.m1.1.1.1.1.1.1" xref="S6.E8.m1.1.1.1.1.1.1.cmml">0</mn></mtd><mtd class="ltx_align_left" columnalign="left" id="S6.E8.m1.6.6.6c" xref="S6.E8.m1.7.8.3.1.cmml"><mrow id="S6.E8.m1.2.2.2.2.2.1" xref="S6.E8.m1.2.2.2.2.2.1.cmml"><mi id="S6.E8.m1.2.2.2.2.2.1.2" xref="S6.E8.m1.2.2.2.2.2.1.2.cmml">x</mi><mo id="S6.E8.m1.2.2.2.2.2.1.1" xref="S6.E8.m1.2.2.2.2.2.1.1.cmml">≤</mo><mn id="S6.E8.m1.2.2.2.2.2.1.3" xref="S6.E8.m1.2.2.2.2.2.1.3.cmml">0</mn></mrow></mtd></mtr><mtr id="S6.E8.m1.6.6.6d" xref="S6.E8.m1.7.8.3.1.cmml"><mtd class="ltx_align_left" columnalign="left" id="S6.E8.m1.6.6.6e" xref="S6.E8.m1.7.8.3.1.cmml"><mi id="S6.E8.m1.3.3.3.3.1.1" xref="S6.E8.m1.3.3.3.3.1.1.cmml">x</mi></mtd><mtd class="ltx_align_left" columnalign="left" id="S6.E8.m1.6.6.6f" xref="S6.E8.m1.7.8.3.1.cmml"><mrow id="S6.E8.m1.4.4.4.4.2.1" xref="S6.E8.m1.4.4.4.4.2.1.cmml"><mn id="S6.E8.m1.4.4.4.4.2.1.2" xref="S6.E8.m1.4.4.4.4.2.1.2.cmml">0</mn><mo id="S6.E8.m1.4.4.4.4.2.1.3" xref="S6.E8.m1.4.4.4.4.2.1.3.cmml">≤</mo><mi id="S6.E8.m1.4.4.4.4.2.1.4" xref="S6.E8.m1.4.4.4.4.2.1.4.cmml">x</mi><mo id="S6.E8.m1.4.4.4.4.2.1.5" xref="S6.E8.m1.4.4.4.4.2.1.5.cmml">≤</mo><mn id="S6.E8.m1.4.4.4.4.2.1.6" xref="S6.E8.m1.4.4.4.4.2.1.6.cmml">1</mn></mrow></mtd></mtr><mtr id="S6.E8.m1.6.6.6g" xref="S6.E8.m1.7.8.3.1.cmml"><mtd class="ltx_align_left" columnalign="left" id="S6.E8.m1.6.6.6h" xref="S6.E8.m1.7.8.3.1.cmml"><mn id="S6.E8.m1.5.5.5.5.1.1" xref="S6.E8.m1.5.5.5.5.1.1.cmml">1</mn></mtd><mtd class="ltx_align_left" columnalign="left" id="S6.E8.m1.6.6.6i" xref="S6.E8.m1.7.8.3.1.cmml"><mrow id="S6.E8.m1.6.6.6.6.2.1" xref="S6.E8.m1.6.6.6.6.2.1.cmml"><mn id="S6.E8.m1.6.6.6.6.2.1.2" xref="S6.E8.m1.6.6.6.6.2.1.2.cmml">1</mn><mo id="S6.E8.m1.6.6.6.6.2.1.1" xref="S6.E8.m1.6.6.6.6.2.1.1.cmml">≤</mo><mi id="S6.E8.m1.6.6.6.6.2.1.3" xref="S6.E8.m1.6.6.6.6.2.1.3.cmml">x</mi></mrow></mtd></mtr></mtable></mrow></mrow><annotation-xml encoding="MathML-Content" id="S6.E8.m1.7b"><apply id="S6.E8.m1.7.8.cmml" xref="S6.E8.m1.7.8"><eq id="S6.E8.m1.7.8.1.cmml" xref="S6.E8.m1.7.8.1"></eq><apply id="S6.E8.m1.7.8.2.cmml" xref="S6.E8.m1.7.8.2"><times id="S6.E8.m1.7.8.2.1.cmml" xref="S6.E8.m1.7.8.2.1"></times><ci id="S6.E8.m1.7.8.2.2.cmml" xref="S6.E8.m1.7.8.2.2">𝑓</ci><ci id="S6.E8.m1.7.7.cmml" xref="S6.E8.m1.7.7">𝑥</ci></apply><apply id="S6.E8.m1.7.8.3.1.cmml" xref="S6.E8.m1.6.6"><csymbol cd="latexml" id="S6.E8.m1.7.8.3.1.1.cmml" xref="S6.E8.m1.6.6.7">cases</csymbol><cn type="integer" id="S6.E8.m1.1.1.1.1.1.1.cmml" xref="S6.E8.m1.1.1.1.1.1.1">0</cn><apply id="S6.E8.m1.2.2.2.2.2.1.cmml" xref="S6.E8.m1.2.2.2.2.2.1"><leq id="S6.E8.m1.2.2.2.2.2.1.1.cmml" xref="S6.E8.m1.2.2.2.2.2.1.1"></leq><ci id="S6.E8.m1.2.2.2.2.2.1.2.cmml" xref="S6.E8.m1.2.2.2.2.2.1.2">𝑥</ci><cn type="integer" id="S6.E8.m1.2.2.2.2.2.1.3.cmml" xref="S6.E8.m1.2.2.2.2.2.1.3">0</cn></apply><ci id="S6.E8.m1.3.3.3.3.1.1.cmml" xref="S6.E8.m1.3.3.3.3.1.1">𝑥</ci><apply id="S6.E8.m1.4.4.4.4.2.1.cmml" xref="S6.E8.m1.4.4.4.4.2.1"><and id="S6.E8.m1.4.4.4.4.2.1a.cmml" xref="S6.E8.m1.4.4.4.4.2.1"></and><apply id="S6.E8.m1.4.4.4.4.2.1b.cmml" xref="S6.E8.m1.4.4.4.4.2.1"><leq id="S6.E8.m1.4.4.4.4.2.1.3.cmml" xref="S6.E8.m1.4.4.4.4.2.1.3"></leq><cn type="integer" id="S6.E8.m1.4.4.4.4.2.1.2.cmml" xref="S6.E8.m1.4.4.4.4.2.1.2">0</cn><ci id="S6.E8.m1.4.4.4.4.2.1.4.cmml" xref="S6.E8.m1.4.4.4.4.2.1.4">𝑥</ci></apply><apply id="S6.E8.m1.4.4.4.4.2.1c.cmml" xref="S6.E8.m1.4.4.4.4.2.1"><leq id="S6.E8.m1.4.4.4.4.2.1.5.cmml" xref="S6.E8.m1.4.4.4.4.2.1.5"></leq><share href="#S6.E8.m1.4.4.4.4.2.1.4.cmml" id="S6.E8.m1.4.4.4.4.2.1d.cmml" xref="S6.E8.m1.4.4.4.4.2.1"></share><cn type="integer" id="S6.E8.m1.4.4.4.4.2.1.6.cmml" xref="S6.E8.m1.4.4.4.4.2.1.6">1</cn></apply></apply><cn type="integer" id="S6.E8.m1.5.5.5.5.1.1.cmml" xref="S6.E8.m1.5.5.5.5.1.1">1</cn><apply id="S6.E8.m1.6.6.6.6.2.1.cmml" xref="S6.E8.m1.6.6.6.6.2.1"><leq id="S6.E8.m1.6.6.6.6.2.1.1.cmml" xref="S6.E8.m1.6.6.6.6.2.1.1"></leq><cn type="integer" id="S6.E8.m1.6.6.6.6.2.1.2.cmml" xref="S6.E8.m1.6.6.6.6.2.1.2">1</cn><ci id="S6.E8.m1.6.6.6.6.2.1.3.cmml" xref="S6.E8.m1.6.6.6.6.2.1.3">𝑥</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.E8.m1.7c">f(x)=\begin{cases}0&amp;x\leq 0\\
x&amp;0\leq x\leq 1\\
1&amp;1\leq x\end{cases}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p id="S6.SS1.SSS2.p4.2" class="ltx_p">With this activation function, only when the input is between <math id="S6.SS1.SSS2.p4.1.m1.1" class="ltx_Math" alttext="0" display="inline"><semantics id="S6.SS1.SSS2.p4.1.m1.1a"><mn id="S6.SS1.SSS2.p4.1.m1.1.1" xref="S6.SS1.SSS2.p4.1.m1.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="S6.SS1.SSS2.p4.1.m1.1b"><cn type="integer" id="S6.SS1.SSS2.p4.1.m1.1.1.cmml" xref="S6.SS1.SSS2.p4.1.m1.1.1">0</cn></annotation-xml></semantics></math> and <math id="S6.SS1.SSS2.p4.2.m2.1" class="ltx_Math" alttext="1" display="inline"><semantics id="S6.SS1.SSS2.p4.2.m2.1a"><mn id="S6.SS1.SSS2.p4.2.m2.1.1" xref="S6.SS1.SSS2.p4.2.m2.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="S6.SS1.SSS2.p4.2.m2.1b"><cn type="integer" id="S6.SS1.SSS2.p4.2.m2.1.1.cmml" xref="S6.SS1.SSS2.p4.2.m2.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.SSS2.p4.2.m2.1c">1</annotation></semantics></math> will there be a non-zero gradient.</p>
</div>
<div id="S6.SS1.SSS2.p5" class="ltx_para ltx_noindent">
<p id="S6.SS1.SSS2.p5.2" class="ltx_p">Using this activation function, neuron activation will be sparse (i.e., images will only activate a single neuron). However, this range between 0 and 1 for the non-zero gradient is fixed for all neurons. Since RtF’s approach sets up neuron biases following a distribution of the images, the weights and biases of the FC layer will need to be adjusted to follow the new non-zero gradient range. This requires scaling the magnitude of these parameters based on the distance between the subsequent neuron biases. Consider that the weights originally measure average pixel brightness. In this case, all the weights would originally be set to <math id="S6.SS1.SSS2.p5.1.m1.1" class="ltx_Math" alttext="\frac{1}{N}" display="inline"><semantics id="S6.SS1.SSS2.p5.1.m1.1a"><mfrac id="S6.SS1.SSS2.p5.1.m1.1.1" xref="S6.SS1.SSS2.p5.1.m1.1.1.cmml"><mn id="S6.SS1.SSS2.p5.1.m1.1.1.2" xref="S6.SS1.SSS2.p5.1.m1.1.1.2.cmml">1</mn><mi id="S6.SS1.SSS2.p5.1.m1.1.1.3" xref="S6.SS1.SSS2.p5.1.m1.1.1.3.cmml">N</mi></mfrac><annotation-xml encoding="MathML-Content" id="S6.SS1.SSS2.p5.1.m1.1b"><apply id="S6.SS1.SSS2.p5.1.m1.1.1.cmml" xref="S6.SS1.SSS2.p5.1.m1.1.1"><divide id="S6.SS1.SSS2.p5.1.m1.1.1.1.cmml" xref="S6.SS1.SSS2.p5.1.m1.1.1"></divide><cn type="integer" id="S6.SS1.SSS2.p5.1.m1.1.1.2.cmml" xref="S6.SS1.SSS2.p5.1.m1.1.1.2">1</cn><ci id="S6.SS1.SSS2.p5.1.m1.1.1.3.cmml" xref="S6.SS1.SSS2.p5.1.m1.1.1.3">𝑁</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.SSS2.p5.1.m1.1c">\frac{1}{N}</annotation></semantics></math>, where <math id="S6.SS1.SSS2.p5.2.m2.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S6.SS1.SSS2.p5.2.m2.1a"><mi id="S6.SS1.SSS2.p5.2.m2.1.1" xref="S6.SS1.SSS2.p5.2.m2.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S6.SS1.SSS2.p5.2.m2.1b"><ci id="S6.SS1.SSS2.p5.2.m2.1.1.cmml" xref="S6.SS1.SSS2.p5.2.m2.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.SSS2.p5.2.m2.1c">N</annotation></semantics></math> is the total number of pixels. Then, the weights and biases are rescaled as:</p>
<table id="S6.E9" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left"><span class="ltx_tag ltx_tag_equation ltx_align_left">(9)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S6.E9.m1.17" class="ltx_Math" alttext="\begin{split}W^{*}_{i}=\frac{W_{i}}{b_{i+1}-b_{i}}\text{ },\text{ }b^{*}_{i}=\frac{b_{i}}{b_{i+1}-b_{i}}\end{split}" display="block"><semantics id="S6.E9.m1.17a"><mtable displaystyle="true" id="S6.E9.m1.17.17.4"><mtr id="S6.E9.m1.17.17.4a"><mtd class="ltx_align_right" columnalign="right" id="S6.E9.m1.17.17.4b"><mrow id="S6.E9.m1.17.17.4.15.15.15.15"><mrow id="S6.E9.m1.16.16.3.14.14.14.14.1"><msubsup id="S6.E9.m1.16.16.3.14.14.14.14.1.1"><mi id="S6.E9.m1.1.1.1.1.1.1" xref="S6.E9.m1.1.1.1.1.1.1.cmml">W</mi><mi id="S6.E9.m1.3.3.3.3.3.3.1" xref="S6.E9.m1.3.3.3.3.3.3.1.cmml">i</mi><mo id="S6.E9.m1.2.2.2.2.2.2.1" xref="S6.E9.m1.2.2.2.2.2.2.1.cmml">∗</mo></msubsup><mo id="S6.E9.m1.4.4.4.4.4.4" xref="S6.E9.m1.4.4.4.4.4.4.cmml">=</mo><mrow id="S6.E9.m1.16.16.3.14.14.14.14.1.2"><mfrac id="S6.E9.m1.5.5.5.5.5.5" xref="S6.E9.m1.5.5.5.5.5.5.cmml"><msub id="S6.E9.m1.5.5.5.5.5.5.2" xref="S6.E9.m1.5.5.5.5.5.5.2.cmml"><mi id="S6.E9.m1.5.5.5.5.5.5.2.2" xref="S6.E9.m1.5.5.5.5.5.5.2.2.cmml">W</mi><mi id="S6.E9.m1.5.5.5.5.5.5.2.3" xref="S6.E9.m1.5.5.5.5.5.5.2.3.cmml">i</mi></msub><mrow id="S6.E9.m1.5.5.5.5.5.5.3" xref="S6.E9.m1.5.5.5.5.5.5.3.cmml"><msub id="S6.E9.m1.5.5.5.5.5.5.3.2" xref="S6.E9.m1.5.5.5.5.5.5.3.2.cmml"><mi id="S6.E9.m1.5.5.5.5.5.5.3.2.2" xref="S6.E9.m1.5.5.5.5.5.5.3.2.2.cmml">b</mi><mrow id="S6.E9.m1.5.5.5.5.5.5.3.2.3" xref="S6.E9.m1.5.5.5.5.5.5.3.2.3.cmml"><mi id="S6.E9.m1.5.5.5.5.5.5.3.2.3.2" xref="S6.E9.m1.5.5.5.5.5.5.3.2.3.2.cmml">i</mi><mo id="S6.E9.m1.5.5.5.5.5.5.3.2.3.1" xref="S6.E9.m1.5.5.5.5.5.5.3.2.3.1.cmml">+</mo><mn id="S6.E9.m1.5.5.5.5.5.5.3.2.3.3" xref="S6.E9.m1.5.5.5.5.5.5.3.2.3.3.cmml">1</mn></mrow></msub><mo id="S6.E9.m1.5.5.5.5.5.5.3.1" xref="S6.E9.m1.5.5.5.5.5.5.3.1.cmml">−</mo><msub id="S6.E9.m1.5.5.5.5.5.5.3.3" xref="S6.E9.m1.5.5.5.5.5.5.3.3.cmml"><mi id="S6.E9.m1.5.5.5.5.5.5.3.3.2" xref="S6.E9.m1.5.5.5.5.5.5.3.3.2.cmml">b</mi><mi id="S6.E9.m1.5.5.5.5.5.5.3.3.3" xref="S6.E9.m1.5.5.5.5.5.5.3.3.3.cmml">i</mi></msub></mrow></mfrac><mo lspace="0em" rspace="0em" id="S6.E9.m1.16.16.3.14.14.14.14.1.2.1" xref="S6.E9.m1.15.15.2.3.cmml">​</mo><mtext id="S6.E9.m1.6.6.6.6.6.6" xref="S6.E9.m1.6.6.6.6.6.6a.cmml"> </mtext></mrow></mrow><mo id="S6.E9.m1.7.7.7.7.7.7" xref="S6.E9.m1.15.15.2.3.cmml">,</mo><mrow id="S6.E9.m1.17.17.4.15.15.15.15.2"><mrow id="S6.E9.m1.17.17.4.15.15.15.15.2.1"><mtext id="S6.E9.m1.8.8.8.8.8.8" xref="S6.E9.m1.8.8.8.8.8.8a.cmml"> </mtext><mo lspace="0em" rspace="0em" id="S6.E9.m1.17.17.4.15.15.15.15.2.1.1" xref="S6.E9.m1.15.15.2.3.cmml">​</mo><msubsup id="S6.E9.m1.17.17.4.15.15.15.15.2.1.2"><mi id="S6.E9.m1.9.9.9.9.9.9" xref="S6.E9.m1.9.9.9.9.9.9.cmml">b</mi><mi id="S6.E9.m1.11.11.11.11.11.11.1" xref="S6.E9.m1.11.11.11.11.11.11.1.cmml">i</mi><mo id="S6.E9.m1.10.10.10.10.10.10.1" xref="S6.E9.m1.10.10.10.10.10.10.1.cmml">∗</mo></msubsup></mrow><mo id="S6.E9.m1.12.12.12.12.12.12" xref="S6.E9.m1.12.12.12.12.12.12.cmml">=</mo><mfrac id="S6.E9.m1.13.13.13.13.13.13" xref="S6.E9.m1.13.13.13.13.13.13.cmml"><msub id="S6.E9.m1.13.13.13.13.13.13.2" xref="S6.E9.m1.13.13.13.13.13.13.2.cmml"><mi id="S6.E9.m1.13.13.13.13.13.13.2.2" xref="S6.E9.m1.13.13.13.13.13.13.2.2.cmml">b</mi><mi id="S6.E9.m1.13.13.13.13.13.13.2.3" xref="S6.E9.m1.13.13.13.13.13.13.2.3.cmml">i</mi></msub><mrow id="S6.E9.m1.13.13.13.13.13.13.3" xref="S6.E9.m1.13.13.13.13.13.13.3.cmml"><msub id="S6.E9.m1.13.13.13.13.13.13.3.2" xref="S6.E9.m1.13.13.13.13.13.13.3.2.cmml"><mi id="S6.E9.m1.13.13.13.13.13.13.3.2.2" xref="S6.E9.m1.13.13.13.13.13.13.3.2.2.cmml">b</mi><mrow id="S6.E9.m1.13.13.13.13.13.13.3.2.3" xref="S6.E9.m1.13.13.13.13.13.13.3.2.3.cmml"><mi id="S6.E9.m1.13.13.13.13.13.13.3.2.3.2" xref="S6.E9.m1.13.13.13.13.13.13.3.2.3.2.cmml">i</mi><mo id="S6.E9.m1.13.13.13.13.13.13.3.2.3.1" xref="S6.E9.m1.13.13.13.13.13.13.3.2.3.1.cmml">+</mo><mn id="S6.E9.m1.13.13.13.13.13.13.3.2.3.3" xref="S6.E9.m1.13.13.13.13.13.13.3.2.3.3.cmml">1</mn></mrow></msub><mo id="S6.E9.m1.13.13.13.13.13.13.3.1" xref="S6.E9.m1.13.13.13.13.13.13.3.1.cmml">−</mo><msub id="S6.E9.m1.13.13.13.13.13.13.3.3" xref="S6.E9.m1.13.13.13.13.13.13.3.3.cmml"><mi id="S6.E9.m1.13.13.13.13.13.13.3.3.2" xref="S6.E9.m1.13.13.13.13.13.13.3.3.2.cmml">b</mi><mi id="S6.E9.m1.13.13.13.13.13.13.3.3.3" xref="S6.E9.m1.13.13.13.13.13.13.3.3.3.cmml">i</mi></msub></mrow></mfrac></mrow></mrow></mtd></mtr></mtable><annotation-xml encoding="MathML-Content" id="S6.E9.m1.17b"><apply id="S6.E9.m1.15.15.2.3.cmml" xref="S6.E9.m1.16.16.3.14.14.14.14.1.2.1"><csymbol cd="ambiguous" id="S6.E9.m1.15.15.2.3a.cmml" xref="S6.E9.m1.16.16.3.14.14.14.14.1.2.1">formulae-sequence</csymbol><apply id="S6.E9.m1.14.14.1.1.1.cmml" xref="S6.E9.m1.16.16.3.14.14.14.14.1.2.1"><eq id="S6.E9.m1.4.4.4.4.4.4.cmml" xref="S6.E9.m1.4.4.4.4.4.4"></eq><apply id="S6.E9.m1.14.14.1.1.1.2.cmml" xref="S6.E9.m1.16.16.3.14.14.14.14.1.2.1"><csymbol cd="ambiguous" id="S6.E9.m1.14.14.1.1.1.2.1.cmml" xref="S6.E9.m1.16.16.3.14.14.14.14.1.2.1">subscript</csymbol><apply id="S6.E9.m1.14.14.1.1.1.2.2.cmml" xref="S6.E9.m1.16.16.3.14.14.14.14.1.2.1"><csymbol cd="ambiguous" id="S6.E9.m1.14.14.1.1.1.2.2.1.cmml" xref="S6.E9.m1.16.16.3.14.14.14.14.1.2.1">superscript</csymbol><ci id="S6.E9.m1.1.1.1.1.1.1.cmml" xref="S6.E9.m1.1.1.1.1.1.1">𝑊</ci><times id="S6.E9.m1.2.2.2.2.2.2.1.cmml" xref="S6.E9.m1.2.2.2.2.2.2.1"></times></apply><ci id="S6.E9.m1.3.3.3.3.3.3.1.cmml" xref="S6.E9.m1.3.3.3.3.3.3.1">𝑖</ci></apply><apply id="S6.E9.m1.14.14.1.1.1.3.cmml" xref="S6.E9.m1.16.16.3.14.14.14.14.1.2.1"><times id="S6.E9.m1.14.14.1.1.1.3.1.cmml" xref="S6.E9.m1.16.16.3.14.14.14.14.1.2.1"></times><apply id="S6.E9.m1.5.5.5.5.5.5.cmml" xref="S6.E9.m1.5.5.5.5.5.5"><divide id="S6.E9.m1.5.5.5.5.5.5.1.cmml" xref="S6.E9.m1.5.5.5.5.5.5"></divide><apply id="S6.E9.m1.5.5.5.5.5.5.2.cmml" xref="S6.E9.m1.5.5.5.5.5.5.2"><csymbol cd="ambiguous" id="S6.E9.m1.5.5.5.5.5.5.2.1.cmml" xref="S6.E9.m1.5.5.5.5.5.5.2">subscript</csymbol><ci id="S6.E9.m1.5.5.5.5.5.5.2.2.cmml" xref="S6.E9.m1.5.5.5.5.5.5.2.2">𝑊</ci><ci id="S6.E9.m1.5.5.5.5.5.5.2.3.cmml" xref="S6.E9.m1.5.5.5.5.5.5.2.3">𝑖</ci></apply><apply id="S6.E9.m1.5.5.5.5.5.5.3.cmml" xref="S6.E9.m1.5.5.5.5.5.5.3"><minus id="S6.E9.m1.5.5.5.5.5.5.3.1.cmml" xref="S6.E9.m1.5.5.5.5.5.5.3.1"></minus><apply id="S6.E9.m1.5.5.5.5.5.5.3.2.cmml" xref="S6.E9.m1.5.5.5.5.5.5.3.2"><csymbol cd="ambiguous" id="S6.E9.m1.5.5.5.5.5.5.3.2.1.cmml" xref="S6.E9.m1.5.5.5.5.5.5.3.2">subscript</csymbol><ci id="S6.E9.m1.5.5.5.5.5.5.3.2.2.cmml" xref="S6.E9.m1.5.5.5.5.5.5.3.2.2">𝑏</ci><apply id="S6.E9.m1.5.5.5.5.5.5.3.2.3.cmml" xref="S6.E9.m1.5.5.5.5.5.5.3.2.3"><plus id="S6.E9.m1.5.5.5.5.5.5.3.2.3.1.cmml" xref="S6.E9.m1.5.5.5.5.5.5.3.2.3.1"></plus><ci id="S6.E9.m1.5.5.5.5.5.5.3.2.3.2.cmml" xref="S6.E9.m1.5.5.5.5.5.5.3.2.3.2">𝑖</ci><cn type="integer" id="S6.E9.m1.5.5.5.5.5.5.3.2.3.3.cmml" xref="S6.E9.m1.5.5.5.5.5.5.3.2.3.3">1</cn></apply></apply><apply id="S6.E9.m1.5.5.5.5.5.5.3.3.cmml" xref="S6.E9.m1.5.5.5.5.5.5.3.3"><csymbol cd="ambiguous" id="S6.E9.m1.5.5.5.5.5.5.3.3.1.cmml" xref="S6.E9.m1.5.5.5.5.5.5.3.3">subscript</csymbol><ci id="S6.E9.m1.5.5.5.5.5.5.3.3.2.cmml" xref="S6.E9.m1.5.5.5.5.5.5.3.3.2">𝑏</ci><ci id="S6.E9.m1.5.5.5.5.5.5.3.3.3.cmml" xref="S6.E9.m1.5.5.5.5.5.5.3.3.3">𝑖</ci></apply></apply></apply><ci id="S6.E9.m1.6.6.6.6.6.6a.cmml" xref="S6.E9.m1.6.6.6.6.6.6"><mtext id="S6.E9.m1.6.6.6.6.6.6.cmml" xref="S6.E9.m1.6.6.6.6.6.6"> </mtext></ci></apply></apply><apply id="S6.E9.m1.15.15.2.2.2.cmml" xref="S6.E9.m1.16.16.3.14.14.14.14.1.2.1"><eq id="S6.E9.m1.12.12.12.12.12.12.cmml" xref="S6.E9.m1.12.12.12.12.12.12"></eq><apply id="S6.E9.m1.15.15.2.2.2.2.cmml" xref="S6.E9.m1.16.16.3.14.14.14.14.1.2.1"><times id="S6.E9.m1.15.15.2.2.2.2.1.cmml" xref="S6.E9.m1.16.16.3.14.14.14.14.1.2.1"></times><ci id="S6.E9.m1.8.8.8.8.8.8a.cmml" xref="S6.E9.m1.8.8.8.8.8.8"><mtext id="S6.E9.m1.8.8.8.8.8.8.cmml" xref="S6.E9.m1.8.8.8.8.8.8"> </mtext></ci><apply id="S6.E9.m1.15.15.2.2.2.2.3.cmml" xref="S6.E9.m1.16.16.3.14.14.14.14.1.2.1"><csymbol cd="ambiguous" id="S6.E9.m1.15.15.2.2.2.2.3.1.cmml" xref="S6.E9.m1.16.16.3.14.14.14.14.1.2.1">subscript</csymbol><apply id="S6.E9.m1.15.15.2.2.2.2.3.2.cmml" xref="S6.E9.m1.16.16.3.14.14.14.14.1.2.1"><csymbol cd="ambiguous" id="S6.E9.m1.15.15.2.2.2.2.3.2.1.cmml" xref="S6.E9.m1.16.16.3.14.14.14.14.1.2.1">superscript</csymbol><ci id="S6.E9.m1.9.9.9.9.9.9.cmml" xref="S6.E9.m1.9.9.9.9.9.9">𝑏</ci><times id="S6.E9.m1.10.10.10.10.10.10.1.cmml" xref="S6.E9.m1.10.10.10.10.10.10.1"></times></apply><ci id="S6.E9.m1.11.11.11.11.11.11.1.cmml" xref="S6.E9.m1.11.11.11.11.11.11.1">𝑖</ci></apply></apply><apply id="S6.E9.m1.13.13.13.13.13.13.cmml" xref="S6.E9.m1.13.13.13.13.13.13"><divide id="S6.E9.m1.13.13.13.13.13.13.1.cmml" xref="S6.E9.m1.13.13.13.13.13.13"></divide><apply id="S6.E9.m1.13.13.13.13.13.13.2.cmml" xref="S6.E9.m1.13.13.13.13.13.13.2"><csymbol cd="ambiguous" id="S6.E9.m1.13.13.13.13.13.13.2.1.cmml" xref="S6.E9.m1.13.13.13.13.13.13.2">subscript</csymbol><ci id="S6.E9.m1.13.13.13.13.13.13.2.2.cmml" xref="S6.E9.m1.13.13.13.13.13.13.2.2">𝑏</ci><ci id="S6.E9.m1.13.13.13.13.13.13.2.3.cmml" xref="S6.E9.m1.13.13.13.13.13.13.2.3">𝑖</ci></apply><apply id="S6.E9.m1.13.13.13.13.13.13.3.cmml" xref="S6.E9.m1.13.13.13.13.13.13.3"><minus id="S6.E9.m1.13.13.13.13.13.13.3.1.cmml" xref="S6.E9.m1.13.13.13.13.13.13.3.1"></minus><apply id="S6.E9.m1.13.13.13.13.13.13.3.2.cmml" xref="S6.E9.m1.13.13.13.13.13.13.3.2"><csymbol cd="ambiguous" id="S6.E9.m1.13.13.13.13.13.13.3.2.1.cmml" xref="S6.E9.m1.13.13.13.13.13.13.3.2">subscript</csymbol><ci id="S6.E9.m1.13.13.13.13.13.13.3.2.2.cmml" xref="S6.E9.m1.13.13.13.13.13.13.3.2.2">𝑏</ci><apply id="S6.E9.m1.13.13.13.13.13.13.3.2.3.cmml" xref="S6.E9.m1.13.13.13.13.13.13.3.2.3"><plus id="S6.E9.m1.13.13.13.13.13.13.3.2.3.1.cmml" xref="S6.E9.m1.13.13.13.13.13.13.3.2.3.1"></plus><ci id="S6.E9.m1.13.13.13.13.13.13.3.2.3.2.cmml" xref="S6.E9.m1.13.13.13.13.13.13.3.2.3.2">𝑖</ci><cn type="integer" id="S6.E9.m1.13.13.13.13.13.13.3.2.3.3.cmml" xref="S6.E9.m1.13.13.13.13.13.13.3.2.3.3">1</cn></apply></apply><apply id="S6.E9.m1.13.13.13.13.13.13.3.3.cmml" xref="S6.E9.m1.13.13.13.13.13.13.3.3"><csymbol cd="ambiguous" id="S6.E9.m1.13.13.13.13.13.13.3.3.1.cmml" xref="S6.E9.m1.13.13.13.13.13.13.3.3">subscript</csymbol><ci id="S6.E9.m1.13.13.13.13.13.13.3.3.2.cmml" xref="S6.E9.m1.13.13.13.13.13.13.3.3.2">𝑏</ci><ci id="S6.E9.m1.13.13.13.13.13.13.3.3.3.cmml" xref="S6.E9.m1.13.13.13.13.13.13.3.3.3">𝑖</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.E9.m1.17c">\begin{split}W^{*}_{i}=\frac{W_{i}}{b_{i+1}-b_{i}}\text{ },\text{ }b^{*}_{i}=\frac{b_{i}}{b_{i+1}-b_{i}}\end{split}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p id="S6.SS1.SSS2.p5.6" class="ltx_p">where <math id="S6.SS1.SSS2.p5.3.m1.1" class="ltx_Math" alttext="W^{*}_{i}" display="inline"><semantics id="S6.SS1.SSS2.p5.3.m1.1a"><msubsup id="S6.SS1.SSS2.p5.3.m1.1.1" xref="S6.SS1.SSS2.p5.3.m1.1.1.cmml"><mi id="S6.SS1.SSS2.p5.3.m1.1.1.2.2" xref="S6.SS1.SSS2.p5.3.m1.1.1.2.2.cmml">W</mi><mi id="S6.SS1.SSS2.p5.3.m1.1.1.3" xref="S6.SS1.SSS2.p5.3.m1.1.1.3.cmml">i</mi><mo id="S6.SS1.SSS2.p5.3.m1.1.1.2.3" xref="S6.SS1.SSS2.p5.3.m1.1.1.2.3.cmml">∗</mo></msubsup><annotation-xml encoding="MathML-Content" id="S6.SS1.SSS2.p5.3.m1.1b"><apply id="S6.SS1.SSS2.p5.3.m1.1.1.cmml" xref="S6.SS1.SSS2.p5.3.m1.1.1"><csymbol cd="ambiguous" id="S6.SS1.SSS2.p5.3.m1.1.1.1.cmml" xref="S6.SS1.SSS2.p5.3.m1.1.1">subscript</csymbol><apply id="S6.SS1.SSS2.p5.3.m1.1.1.2.cmml" xref="S6.SS1.SSS2.p5.3.m1.1.1"><csymbol cd="ambiguous" id="S6.SS1.SSS2.p5.3.m1.1.1.2.1.cmml" xref="S6.SS1.SSS2.p5.3.m1.1.1">superscript</csymbol><ci id="S6.SS1.SSS2.p5.3.m1.1.1.2.2.cmml" xref="S6.SS1.SSS2.p5.3.m1.1.1.2.2">𝑊</ci><times id="S6.SS1.SSS2.p5.3.m1.1.1.2.3.cmml" xref="S6.SS1.SSS2.p5.3.m1.1.1.2.3"></times></apply><ci id="S6.SS1.SSS2.p5.3.m1.1.1.3.cmml" xref="S6.SS1.SSS2.p5.3.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.SSS2.p5.3.m1.1c">W^{*}_{i}</annotation></semantics></math> and <math id="S6.SS1.SSS2.p5.4.m2.1" class="ltx_Math" alttext="b^{*}_{i}" display="inline"><semantics id="S6.SS1.SSS2.p5.4.m2.1a"><msubsup id="S6.SS1.SSS2.p5.4.m2.1.1" xref="S6.SS1.SSS2.p5.4.m2.1.1.cmml"><mi id="S6.SS1.SSS2.p5.4.m2.1.1.2.2" xref="S6.SS1.SSS2.p5.4.m2.1.1.2.2.cmml">b</mi><mi id="S6.SS1.SSS2.p5.4.m2.1.1.3" xref="S6.SS1.SSS2.p5.4.m2.1.1.3.cmml">i</mi><mo id="S6.SS1.SSS2.p5.4.m2.1.1.2.3" xref="S6.SS1.SSS2.p5.4.m2.1.1.2.3.cmml">∗</mo></msubsup><annotation-xml encoding="MathML-Content" id="S6.SS1.SSS2.p5.4.m2.1b"><apply id="S6.SS1.SSS2.p5.4.m2.1.1.cmml" xref="S6.SS1.SSS2.p5.4.m2.1.1"><csymbol cd="ambiguous" id="S6.SS1.SSS2.p5.4.m2.1.1.1.cmml" xref="S6.SS1.SSS2.p5.4.m2.1.1">subscript</csymbol><apply id="S6.SS1.SSS2.p5.4.m2.1.1.2.cmml" xref="S6.SS1.SSS2.p5.4.m2.1.1"><csymbol cd="ambiguous" id="S6.SS1.SSS2.p5.4.m2.1.1.2.1.cmml" xref="S6.SS1.SSS2.p5.4.m2.1.1">superscript</csymbol><ci id="S6.SS1.SSS2.p5.4.m2.1.1.2.2.cmml" xref="S6.SS1.SSS2.p5.4.m2.1.1.2.2">𝑏</ci><times id="S6.SS1.SSS2.p5.4.m2.1.1.2.3.cmml" xref="S6.SS1.SSS2.p5.4.m2.1.1.2.3"></times></apply><ci id="S6.SS1.SSS2.p5.4.m2.1.1.3.cmml" xref="S6.SS1.SSS2.p5.4.m2.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.SSS2.p5.4.m2.1c">b^{*}_{i}</annotation></semantics></math> are the scaled weights and biases of neuron <math id="S6.SS1.SSS2.p5.5.m3.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S6.SS1.SSS2.p5.5.m3.1a"><mi id="S6.SS1.SSS2.p5.5.m3.1.1" xref="S6.SS1.SSS2.p5.5.m3.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S6.SS1.SSS2.p5.5.m3.1b"><ci id="S6.SS1.SSS2.p5.5.m3.1.1.cmml" xref="S6.SS1.SSS2.p5.5.m3.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.SSS2.p5.5.m3.1c">i</annotation></semantics></math> respectively and <math id="S6.SS1.SSS2.p5.6.m4.1" class="ltx_Math" alttext="b_{i+1}-b_{i}" display="inline"><semantics id="S6.SS1.SSS2.p5.6.m4.1a"><mrow id="S6.SS1.SSS2.p5.6.m4.1.1" xref="S6.SS1.SSS2.p5.6.m4.1.1.cmml"><msub id="S6.SS1.SSS2.p5.6.m4.1.1.2" xref="S6.SS1.SSS2.p5.6.m4.1.1.2.cmml"><mi id="S6.SS1.SSS2.p5.6.m4.1.1.2.2" xref="S6.SS1.SSS2.p5.6.m4.1.1.2.2.cmml">b</mi><mrow id="S6.SS1.SSS2.p5.6.m4.1.1.2.3" xref="S6.SS1.SSS2.p5.6.m4.1.1.2.3.cmml"><mi id="S6.SS1.SSS2.p5.6.m4.1.1.2.3.2" xref="S6.SS1.SSS2.p5.6.m4.1.1.2.3.2.cmml">i</mi><mo id="S6.SS1.SSS2.p5.6.m4.1.1.2.3.1" xref="S6.SS1.SSS2.p5.6.m4.1.1.2.3.1.cmml">+</mo><mn id="S6.SS1.SSS2.p5.6.m4.1.1.2.3.3" xref="S6.SS1.SSS2.p5.6.m4.1.1.2.3.3.cmml">1</mn></mrow></msub><mo id="S6.SS1.SSS2.p5.6.m4.1.1.1" xref="S6.SS1.SSS2.p5.6.m4.1.1.1.cmml">−</mo><msub id="S6.SS1.SSS2.p5.6.m4.1.1.3" xref="S6.SS1.SSS2.p5.6.m4.1.1.3.cmml"><mi id="S6.SS1.SSS2.p5.6.m4.1.1.3.2" xref="S6.SS1.SSS2.p5.6.m4.1.1.3.2.cmml">b</mi><mi id="S6.SS1.SSS2.p5.6.m4.1.1.3.3" xref="S6.SS1.SSS2.p5.6.m4.1.1.3.3.cmml">i</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S6.SS1.SSS2.p5.6.m4.1b"><apply id="S6.SS1.SSS2.p5.6.m4.1.1.cmml" xref="S6.SS1.SSS2.p5.6.m4.1.1"><minus id="S6.SS1.SSS2.p5.6.m4.1.1.1.cmml" xref="S6.SS1.SSS2.p5.6.m4.1.1.1"></minus><apply id="S6.SS1.SSS2.p5.6.m4.1.1.2.cmml" xref="S6.SS1.SSS2.p5.6.m4.1.1.2"><csymbol cd="ambiguous" id="S6.SS1.SSS2.p5.6.m4.1.1.2.1.cmml" xref="S6.SS1.SSS2.p5.6.m4.1.1.2">subscript</csymbol><ci id="S6.SS1.SSS2.p5.6.m4.1.1.2.2.cmml" xref="S6.SS1.SSS2.p5.6.m4.1.1.2.2">𝑏</ci><apply id="S6.SS1.SSS2.p5.6.m4.1.1.2.3.cmml" xref="S6.SS1.SSS2.p5.6.m4.1.1.2.3"><plus id="S6.SS1.SSS2.p5.6.m4.1.1.2.3.1.cmml" xref="S6.SS1.SSS2.p5.6.m4.1.1.2.3.1"></plus><ci id="S6.SS1.SSS2.p5.6.m4.1.1.2.3.2.cmml" xref="S6.SS1.SSS2.p5.6.m4.1.1.2.3.2">𝑖</ci><cn type="integer" id="S6.SS1.SSS2.p5.6.m4.1.1.2.3.3.cmml" xref="S6.SS1.SSS2.p5.6.m4.1.1.2.3.3">1</cn></apply></apply><apply id="S6.SS1.SSS2.p5.6.m4.1.1.3.cmml" xref="S6.SS1.SSS2.p5.6.m4.1.1.3"><csymbol cd="ambiguous" id="S6.SS1.SSS2.p5.6.m4.1.1.3.1.cmml" xref="S6.SS1.SSS2.p5.6.m4.1.1.3">subscript</csymbol><ci id="S6.SS1.SSS2.p5.6.m4.1.1.3.2.cmml" xref="S6.SS1.SSS2.p5.6.m4.1.1.3.2">𝑏</ci><ci id="S6.SS1.SSS2.p5.6.m4.1.1.3.3.cmml" xref="S6.SS1.SSS2.p5.6.m4.1.1.3.3">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.SSS2.p5.6.m4.1c">b_{i+1}-b_{i}</annotation></semantics></math> is the distance between adjacent biases in the original distribution. This process uses the same distribution as the FedSGD case to setup the initial biases, while incorporating the fixed range of the new activation function by scaling the parameters. In FedAvg, after the clients send the updated model parameters, the server computes a “gradient” as:</p>
<table id="S6.E10" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left"><span class="ltx_tag ltx_tag_equation ltx_align_left">(10)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S6.E10.m1.1" class="ltx_Math" alttext="\nabla W_{FedAvg}=\Theta_{t+1}-\Theta_{t}" display="block"><semantics id="S6.E10.m1.1a"><mrow id="S6.E10.m1.1.1" xref="S6.E10.m1.1.1.cmml"><mrow id="S6.E10.m1.1.1.2" xref="S6.E10.m1.1.1.2.cmml"><mo rspace="0.167em" id="S6.E10.m1.1.1.2.1" xref="S6.E10.m1.1.1.2.1.cmml">∇</mo><msub id="S6.E10.m1.1.1.2.2" xref="S6.E10.m1.1.1.2.2.cmml"><mi id="S6.E10.m1.1.1.2.2.2" xref="S6.E10.m1.1.1.2.2.2.cmml">W</mi><mrow id="S6.E10.m1.1.1.2.2.3" xref="S6.E10.m1.1.1.2.2.3.cmml"><mi id="S6.E10.m1.1.1.2.2.3.2" xref="S6.E10.m1.1.1.2.2.3.2.cmml">F</mi><mo lspace="0em" rspace="0em" id="S6.E10.m1.1.1.2.2.3.1" xref="S6.E10.m1.1.1.2.2.3.1.cmml">​</mo><mi id="S6.E10.m1.1.1.2.2.3.3" xref="S6.E10.m1.1.1.2.2.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S6.E10.m1.1.1.2.2.3.1a" xref="S6.E10.m1.1.1.2.2.3.1.cmml">​</mo><mi id="S6.E10.m1.1.1.2.2.3.4" xref="S6.E10.m1.1.1.2.2.3.4.cmml">d</mi><mo lspace="0em" rspace="0em" id="S6.E10.m1.1.1.2.2.3.1b" xref="S6.E10.m1.1.1.2.2.3.1.cmml">​</mo><mi id="S6.E10.m1.1.1.2.2.3.5" xref="S6.E10.m1.1.1.2.2.3.5.cmml">A</mi><mo lspace="0em" rspace="0em" id="S6.E10.m1.1.1.2.2.3.1c" xref="S6.E10.m1.1.1.2.2.3.1.cmml">​</mo><mi id="S6.E10.m1.1.1.2.2.3.6" xref="S6.E10.m1.1.1.2.2.3.6.cmml">v</mi><mo lspace="0em" rspace="0em" id="S6.E10.m1.1.1.2.2.3.1d" xref="S6.E10.m1.1.1.2.2.3.1.cmml">​</mo><mi id="S6.E10.m1.1.1.2.2.3.7" xref="S6.E10.m1.1.1.2.2.3.7.cmml">g</mi></mrow></msub></mrow><mo id="S6.E10.m1.1.1.1" xref="S6.E10.m1.1.1.1.cmml">=</mo><mrow id="S6.E10.m1.1.1.3" xref="S6.E10.m1.1.1.3.cmml"><msub id="S6.E10.m1.1.1.3.2" xref="S6.E10.m1.1.1.3.2.cmml"><mi mathvariant="normal" id="S6.E10.m1.1.1.3.2.2" xref="S6.E10.m1.1.1.3.2.2.cmml">Θ</mi><mrow id="S6.E10.m1.1.1.3.2.3" xref="S6.E10.m1.1.1.3.2.3.cmml"><mi id="S6.E10.m1.1.1.3.2.3.2" xref="S6.E10.m1.1.1.3.2.3.2.cmml">t</mi><mo id="S6.E10.m1.1.1.3.2.3.1" xref="S6.E10.m1.1.1.3.2.3.1.cmml">+</mo><mn id="S6.E10.m1.1.1.3.2.3.3" xref="S6.E10.m1.1.1.3.2.3.3.cmml">1</mn></mrow></msub><mo id="S6.E10.m1.1.1.3.1" xref="S6.E10.m1.1.1.3.1.cmml">−</mo><msub id="S6.E10.m1.1.1.3.3" xref="S6.E10.m1.1.1.3.3.cmml"><mi mathvariant="normal" id="S6.E10.m1.1.1.3.3.2" xref="S6.E10.m1.1.1.3.3.2.cmml">Θ</mi><mi id="S6.E10.m1.1.1.3.3.3" xref="S6.E10.m1.1.1.3.3.3.cmml">t</mi></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S6.E10.m1.1b"><apply id="S6.E10.m1.1.1.cmml" xref="S6.E10.m1.1.1"><eq id="S6.E10.m1.1.1.1.cmml" xref="S6.E10.m1.1.1.1"></eq><apply id="S6.E10.m1.1.1.2.cmml" xref="S6.E10.m1.1.1.2"><ci id="S6.E10.m1.1.1.2.1.cmml" xref="S6.E10.m1.1.1.2.1">∇</ci><apply id="S6.E10.m1.1.1.2.2.cmml" xref="S6.E10.m1.1.1.2.2"><csymbol cd="ambiguous" id="S6.E10.m1.1.1.2.2.1.cmml" xref="S6.E10.m1.1.1.2.2">subscript</csymbol><ci id="S6.E10.m1.1.1.2.2.2.cmml" xref="S6.E10.m1.1.1.2.2.2">𝑊</ci><apply id="S6.E10.m1.1.1.2.2.3.cmml" xref="S6.E10.m1.1.1.2.2.3"><times id="S6.E10.m1.1.1.2.2.3.1.cmml" xref="S6.E10.m1.1.1.2.2.3.1"></times><ci id="S6.E10.m1.1.1.2.2.3.2.cmml" xref="S6.E10.m1.1.1.2.2.3.2">𝐹</ci><ci id="S6.E10.m1.1.1.2.2.3.3.cmml" xref="S6.E10.m1.1.1.2.2.3.3">𝑒</ci><ci id="S6.E10.m1.1.1.2.2.3.4.cmml" xref="S6.E10.m1.1.1.2.2.3.4">𝑑</ci><ci id="S6.E10.m1.1.1.2.2.3.5.cmml" xref="S6.E10.m1.1.1.2.2.3.5">𝐴</ci><ci id="S6.E10.m1.1.1.2.2.3.6.cmml" xref="S6.E10.m1.1.1.2.2.3.6">𝑣</ci><ci id="S6.E10.m1.1.1.2.2.3.7.cmml" xref="S6.E10.m1.1.1.2.2.3.7">𝑔</ci></apply></apply></apply><apply id="S6.E10.m1.1.1.3.cmml" xref="S6.E10.m1.1.1.3"><minus id="S6.E10.m1.1.1.3.1.cmml" xref="S6.E10.m1.1.1.3.1"></minus><apply id="S6.E10.m1.1.1.3.2.cmml" xref="S6.E10.m1.1.1.3.2"><csymbol cd="ambiguous" id="S6.E10.m1.1.1.3.2.1.cmml" xref="S6.E10.m1.1.1.3.2">subscript</csymbol><ci id="S6.E10.m1.1.1.3.2.2.cmml" xref="S6.E10.m1.1.1.3.2.2">Θ</ci><apply id="S6.E10.m1.1.1.3.2.3.cmml" xref="S6.E10.m1.1.1.3.2.3"><plus id="S6.E10.m1.1.1.3.2.3.1.cmml" xref="S6.E10.m1.1.1.3.2.3.1"></plus><ci id="S6.E10.m1.1.1.3.2.3.2.cmml" xref="S6.E10.m1.1.1.3.2.3.2">𝑡</ci><cn type="integer" id="S6.E10.m1.1.1.3.2.3.3.cmml" xref="S6.E10.m1.1.1.3.2.3.3">1</cn></apply></apply><apply id="S6.E10.m1.1.1.3.3.cmml" xref="S6.E10.m1.1.1.3.3"><csymbol cd="ambiguous" id="S6.E10.m1.1.1.3.3.1.cmml" xref="S6.E10.m1.1.1.3.3">subscript</csymbol><ci id="S6.E10.m1.1.1.3.3.2.cmml" xref="S6.E10.m1.1.1.3.3.2">Θ</ci><ci id="S6.E10.m1.1.1.3.3.3.cmml" xref="S6.E10.m1.1.1.3.3.3">𝑡</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.E10.m1.1c">\nabla W_{FedAvg}=\Theta_{t+1}-\Theta_{t}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p id="S6.SS1.SSS2.p5.8" class="ltx_p">where <math id="S6.SS1.SSS2.p5.7.m1.1" class="ltx_Math" alttext="\Theta" display="inline"><semantics id="S6.SS1.SSS2.p5.7.m1.1a"><mi mathvariant="normal" id="S6.SS1.SSS2.p5.7.m1.1.1" xref="S6.SS1.SSS2.p5.7.m1.1.1.cmml">Θ</mi><annotation-xml encoding="MathML-Content" id="S6.SS1.SSS2.p5.7.m1.1b"><ci id="S6.SS1.SSS2.p5.7.m1.1.1.cmml" xref="S6.SS1.SSS2.p5.7.m1.1.1">Θ</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.SSS2.p5.7.m1.1c">\Theta</annotation></semantics></math> is the model parameters for the securely aggregated model and <math id="S6.SS1.SSS2.p5.8.m2.1" class="ltx_Math" alttext="\nabla W_{FedAvg}" display="inline"><semantics id="S6.SS1.SSS2.p5.8.m2.1a"><mrow id="S6.SS1.SSS2.p5.8.m2.1.1" xref="S6.SS1.SSS2.p5.8.m2.1.1.cmml"><mo rspace="0.167em" id="S6.SS1.SSS2.p5.8.m2.1.1.1" xref="S6.SS1.SSS2.p5.8.m2.1.1.1.cmml">∇</mo><msub id="S6.SS1.SSS2.p5.8.m2.1.1.2" xref="S6.SS1.SSS2.p5.8.m2.1.1.2.cmml"><mi id="S6.SS1.SSS2.p5.8.m2.1.1.2.2" xref="S6.SS1.SSS2.p5.8.m2.1.1.2.2.cmml">W</mi><mrow id="S6.SS1.SSS2.p5.8.m2.1.1.2.3" xref="S6.SS1.SSS2.p5.8.m2.1.1.2.3.cmml"><mi id="S6.SS1.SSS2.p5.8.m2.1.1.2.3.2" xref="S6.SS1.SSS2.p5.8.m2.1.1.2.3.2.cmml">F</mi><mo lspace="0em" rspace="0em" id="S6.SS1.SSS2.p5.8.m2.1.1.2.3.1" xref="S6.SS1.SSS2.p5.8.m2.1.1.2.3.1.cmml">​</mo><mi id="S6.SS1.SSS2.p5.8.m2.1.1.2.3.3" xref="S6.SS1.SSS2.p5.8.m2.1.1.2.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S6.SS1.SSS2.p5.8.m2.1.1.2.3.1a" xref="S6.SS1.SSS2.p5.8.m2.1.1.2.3.1.cmml">​</mo><mi id="S6.SS1.SSS2.p5.8.m2.1.1.2.3.4" xref="S6.SS1.SSS2.p5.8.m2.1.1.2.3.4.cmml">d</mi><mo lspace="0em" rspace="0em" id="S6.SS1.SSS2.p5.8.m2.1.1.2.3.1b" xref="S6.SS1.SSS2.p5.8.m2.1.1.2.3.1.cmml">​</mo><mi id="S6.SS1.SSS2.p5.8.m2.1.1.2.3.5" xref="S6.SS1.SSS2.p5.8.m2.1.1.2.3.5.cmml">A</mi><mo lspace="0em" rspace="0em" id="S6.SS1.SSS2.p5.8.m2.1.1.2.3.1c" xref="S6.SS1.SSS2.p5.8.m2.1.1.2.3.1.cmml">​</mo><mi id="S6.SS1.SSS2.p5.8.m2.1.1.2.3.6" xref="S6.SS1.SSS2.p5.8.m2.1.1.2.3.6.cmml">v</mi><mo lspace="0em" rspace="0em" id="S6.SS1.SSS2.p5.8.m2.1.1.2.3.1d" xref="S6.SS1.SSS2.p5.8.m2.1.1.2.3.1.cmml">​</mo><mi id="S6.SS1.SSS2.p5.8.m2.1.1.2.3.7" xref="S6.SS1.SSS2.p5.8.m2.1.1.2.3.7.cmml">g</mi></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="S6.SS1.SSS2.p5.8.m2.1b"><apply id="S6.SS1.SSS2.p5.8.m2.1.1.cmml" xref="S6.SS1.SSS2.p5.8.m2.1.1"><ci id="S6.SS1.SSS2.p5.8.m2.1.1.1.cmml" xref="S6.SS1.SSS2.p5.8.m2.1.1.1">∇</ci><apply id="S6.SS1.SSS2.p5.8.m2.1.1.2.cmml" xref="S6.SS1.SSS2.p5.8.m2.1.1.2"><csymbol cd="ambiguous" id="S6.SS1.SSS2.p5.8.m2.1.1.2.1.cmml" xref="S6.SS1.SSS2.p5.8.m2.1.1.2">subscript</csymbol><ci id="S6.SS1.SSS2.p5.8.m2.1.1.2.2.cmml" xref="S6.SS1.SSS2.p5.8.m2.1.1.2.2">𝑊</ci><apply id="S6.SS1.SSS2.p5.8.m2.1.1.2.3.cmml" xref="S6.SS1.SSS2.p5.8.m2.1.1.2.3"><times id="S6.SS1.SSS2.p5.8.m2.1.1.2.3.1.cmml" xref="S6.SS1.SSS2.p5.8.m2.1.1.2.3.1"></times><ci id="S6.SS1.SSS2.p5.8.m2.1.1.2.3.2.cmml" xref="S6.SS1.SSS2.p5.8.m2.1.1.2.3.2">𝐹</ci><ci id="S6.SS1.SSS2.p5.8.m2.1.1.2.3.3.cmml" xref="S6.SS1.SSS2.p5.8.m2.1.1.2.3.3">𝑒</ci><ci id="S6.SS1.SSS2.p5.8.m2.1.1.2.3.4.cmml" xref="S6.SS1.SSS2.p5.8.m2.1.1.2.3.4">𝑑</ci><ci id="S6.SS1.SSS2.p5.8.m2.1.1.2.3.5.cmml" xref="S6.SS1.SSS2.p5.8.m2.1.1.2.3.5">𝐴</ci><ci id="S6.SS1.SSS2.p5.8.m2.1.1.2.3.6.cmml" xref="S6.SS1.SSS2.p5.8.m2.1.1.2.3.6">𝑣</ci><ci id="S6.SS1.SSS2.p5.8.m2.1.1.2.3.7.cmml" xref="S6.SS1.SSS2.p5.8.m2.1.1.2.3.7">𝑔</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.SSS2.p5.8.m2.1c">\nabla W_{FedAvg}</annotation></semantics></math> the computed gradient.</p>
</div>
<div id="S6.SS1.SSS2.p6" class="ltx_para">
<p id="S6.SS1.SSS2.p6.1" class="ltx_p">This FedAvg attack <cite class="ltx_cite ltx_citemacro_citep">(Fowl et al<span class="ltx_text">.</span>, <a href="#bib.bib51" title="" class="ltx_ref">2022</a>)</cite> works well in the context of single client attacks. However, attacking secure aggregated gradients becomes a problem as the total images in the gradient increases multiplicative to the number of clients. Particularly, <cite class="ltx_cite ltx_citemacro_citep">(Zhao et al<span class="ltx_text">.</span>, <a href="#bib.bib149" title="" class="ltx_ref">2023b</a>)</cite> finds that numerical precision poses a problem for the FedAvg linear layer leakage attack when a large number of clients is attacked. Through the use of convolutional layers and a convolutional scaling factor (CSF), <cite class="ltx_cite ltx_citemacro_citep">(Zhao et al<span class="ltx_text">.</span>, <a href="#bib.bib149" title="" class="ltx_ref">2023b</a>)</cite> is able to scale to an arbitrary number of clients while maintaining a high leakage rate. Furthermore, the CSF improves on the multiple-image reconstruction problem, only allowing images within the same local mini-batch to activate the same units. Notably, this allows the leakage rate on FedAvg attacks to be <span id="S6.SS1.SSS2.p6.1.1" class="ltx_text ltx_font_italic">higher</span> than in FedSGD (where FedAvg is typically harder to attack than FedSGD).</p>
</div>
<div id="S6.SS1.SSS2.p7" class="ltx_para">
<p id="S6.SS1.SSS2.p7.1" class="ltx_p">Linear layer leakage reconstruction quality is typically higher quality than optimization-based attacks and does not rely on the number of clients. However, it also requires malicious modification of the model parameters and/or architecture, resulting in more detectable attacks. Furthermore, the attack also adds a resource overhead to the model size. This problem is exacerbated by the number of clients as the attack layer sizes need to scale to keep the attack effective. This problem and the use of sparse tensors to alleviate the problem are discussed by <cite class="ltx_cite ltx_citemacro_citep">(Zhao et al<span class="ltx_text">.</span>, <a href="#bib.bib148" title="" class="ltx_ref">2023a</a>)</cite>.</p>
</div>
</section>
<section id="S6.SS1.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">6.1.3. </span>GAN-based.</h4>

<div id="S6.SS1.SSS3.p1" class="ltx_para">
<p id="S6.SS1.SSS3.p1.1" class="ltx_p">Generative networks were introduced to attack collaborative learning in <cite class="ltx_cite ltx_citemacro_citep">(Hitaj et al<span class="ltx_text">.</span>, <a href="#bib.bib63" title="" class="ltx_ref">2017</a>; Wang et al<span class="ltx_text">.</span>, <a href="#bib.bib132" title="" class="ltx_ref">2019a</a>)</cite>. However, contrary to optimization-based attacks and linear layer leakage, the attack does not aim to directly reconstruct exact training images, but instead reconstructs representations of a targeted class which the attacker does not hold any images of. In the attack, an adversary (a client in collaborative or federated learning training) trains a generative network in conjunction with the benign collaborative model. For a single training round, the attack process goes as follows:</p>
<ol id="S6.I1" class="ltx_enumerate">
<li id="S6.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(1)</span> 
<div id="S6.I1.i1.p1" class="ltx_para">
<p id="S6.I1.i1.p1.1" class="ltx_p">The adversary downloads the model (or a portion of parameters in certain forms of collaborative training).</p>
</div>
</li>
<li id="S6.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(2)</span> 
<div id="S6.I1.i2.p1" class="ltx_para">
<p id="S6.I1.i2.p1.1" class="ltx_p">Images for the targeted class are generated by the generator and the generator is updated based on the discriminator (the global model).</p>
</div>
</li>
<li id="S6.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(3)</span> 
<div id="S6.I1.i3.p1" class="ltx_para">
<p id="S6.I1.i3.p1.1" class="ltx_p">Images for the targeted class are generated by the updated generator and mislabeled.</p>
</div>
</li>
<li id="S6.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(4)</span> 
<div id="S6.I1.i4.p1" class="ltx_para">
<p id="S6.I1.i4.p1.1" class="ltx_p">The adversary trains on the set of mislabeled images and any actual training images.</p>
</div>
</li>
<li id="S6.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(5)</span> 
<div id="S6.I1.i5.p1" class="ltx_para">
<p id="S6.I1.i5.p1.1" class="ltx_p">The adversary uploads the update to the parameter server.</p>
</div>
</li>
</ol>
<p id="S6.SS1.SSS3.p1.2" class="ltx_p">Both training the generator and training on mislabeled images are critically important to the attack process. Firstly, training the generator is crucial since the ultimate goal is to be able to generate representations of a targeted class. Secondly, the process of including mislabeled generated images in order to influence the training process is also very important. Without this additional influence on training, the authors note that the generated image quality does not converge to a visible reconstruction.</p>
</div>
<div id="S6.SS1.SSS3.p2" class="ltx_para">
<p id="S6.SS1.SSS3.p2.2" class="ltx_p">One main strength of the mention is also in the ability to work through differential privacy. Specifically, the attack relies on the fact that the client model is able to learn and improve the accuracy. As long as the model is learning, the generator is also able to learn to reconstruct better images. This makes the GAN attack remarkably resilient to (at least record-level) differential privacy. As long as the privacy budget <math id="S6.SS1.SSS3.p2.1.m1.1" class="ltx_Math" alttext="\epsilon" display="inline"><semantics id="S6.SS1.SSS3.p2.1.m1.1a"><mi id="S6.SS1.SSS3.p2.1.m1.1.1" xref="S6.SS1.SSS3.p2.1.m1.1.1.cmml">ϵ</mi><annotation-xml encoding="MathML-Content" id="S6.SS1.SSS3.p2.1.m1.1b"><ci id="S6.SS1.SSS3.p2.1.m1.1.1.cmml" xref="S6.SS1.SSS3.p2.1.m1.1.1">italic-ϵ</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.SSS3.p2.1.m1.1c">\epsilon</annotation></semantics></math> allows the model to continue learning, the attack works. When too restrictive of an <math id="S6.SS1.SSS3.p2.2.m2.1" class="ltx_Math" alttext="\epsilon" display="inline"><semantics id="S6.SS1.SSS3.p2.2.m2.1a"><mi id="S6.SS1.SSS3.p2.2.m2.1.1" xref="S6.SS1.SSS3.p2.2.m2.1.1.cmml">ϵ</mi><annotation-xml encoding="MathML-Content" id="S6.SS1.SSS3.p2.2.m2.1b"><ci id="S6.SS1.SSS3.p2.2.m2.1.1.cmml" xref="S6.SS1.SSS3.p2.2.m2.1.1">italic-ϵ</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.SSS3.p2.2.m2.1c">\epsilon</annotation></semantics></math> is used, the attack fails but the model is also unable to learn.</p>
</div>
<div id="S6.SS1.SSS3.p3" class="ltx_para">
<p id="S6.SS1.SSS3.p3.1" class="ltx_p">Another strength of the GAN attack is that it can be employed through any malicious client as opposed to a parameter server. Optimization-based attacks require the observation of individual gradient updates along with the initial model. While clients receive the initial model state, the observation of individual gradient updates from other clients would not happen in the vanilla protocol. Linear layer leakage on the other hand can only be enacted by the server. Modification of the model parameters is required, and this can only be done by the parameter server. Compared to both these methods, only the GAN attack can be easily employed by a client. This larger attack surface also points to potentially greater privacy risks in collaborative training compared to even centralized training. It should also be noted that the attack only generates representations instead of actual reconstructions. However, this can still pose a great privacy risk depending the content of the private client training data.</p>
</div>
</section>
<section id="S6.SS1.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">6.1.4. </span>Other attacks.</h4>

<div id="S6.SS1.SSS4.p1" class="ltx_para">
<p id="S6.SS1.SSS4.p1.1" class="ltx_p">While we have previously discussed the major categories of optimization, linear layer leakage, and GAN-based attacks for data reconstruction, other attacks have also been proposed that leak data differently or assist existing methods in attacking more challenging scenarios such as secure aggregation.</p>
</div>
<div id="S6.SS1.SSS4.p2" class="ltx_para">
<p id="S6.SS1.SSS4.p2.6" class="ltx_p">In order to tackle secure aggregation, a gradient suppression attack <cite class="ltx_cite ltx_citemacro_citep">(Pasquini et al<span class="ltx_text">.</span>, <a href="#bib.bib102" title="" class="ltx_ref">2022</a>)</cite> was proposed whereby a malicious server sends customized model parameters to different clients such that only a single client would return a non-zero gradient update. This attack used a dead ReLU trick where the ReLU activation functions of a layer using were set to 0.</p>
<table id="S6.E11" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left"><span class="ltx_tag ltx_tag_equation ltx_align_left">(11)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S6.E11.m1.5" class="ltx_Math" alttext="ReLU(x)=\begin{cases}0&amp;x\leq 0\\
x&amp;x&gt;0\end{cases}" display="block"><semantics id="S6.E11.m1.5a"><mrow id="S6.E11.m1.5.6" xref="S6.E11.m1.5.6.cmml"><mrow id="S6.E11.m1.5.6.2" xref="S6.E11.m1.5.6.2.cmml"><mi id="S6.E11.m1.5.6.2.2" xref="S6.E11.m1.5.6.2.2.cmml">R</mi><mo lspace="0em" rspace="0em" id="S6.E11.m1.5.6.2.1" xref="S6.E11.m1.5.6.2.1.cmml">​</mo><mi id="S6.E11.m1.5.6.2.3" xref="S6.E11.m1.5.6.2.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S6.E11.m1.5.6.2.1a" xref="S6.E11.m1.5.6.2.1.cmml">​</mo><mi id="S6.E11.m1.5.6.2.4" xref="S6.E11.m1.5.6.2.4.cmml">L</mi><mo lspace="0em" rspace="0em" id="S6.E11.m1.5.6.2.1b" xref="S6.E11.m1.5.6.2.1.cmml">​</mo><mi id="S6.E11.m1.5.6.2.5" xref="S6.E11.m1.5.6.2.5.cmml">U</mi><mo lspace="0em" rspace="0em" id="S6.E11.m1.5.6.2.1c" xref="S6.E11.m1.5.6.2.1.cmml">​</mo><mrow id="S6.E11.m1.5.6.2.6.2" xref="S6.E11.m1.5.6.2.cmml"><mo stretchy="false" id="S6.E11.m1.5.6.2.6.2.1" xref="S6.E11.m1.5.6.2.cmml">(</mo><mi id="S6.E11.m1.5.5" xref="S6.E11.m1.5.5.cmml">x</mi><mo stretchy="false" id="S6.E11.m1.5.6.2.6.2.2" xref="S6.E11.m1.5.6.2.cmml">)</mo></mrow></mrow><mo id="S6.E11.m1.5.6.1" xref="S6.E11.m1.5.6.1.cmml">=</mo><mrow id="S6.E11.m1.4.4" xref="S6.E11.m1.5.6.3.1.cmml"><mo id="S6.E11.m1.4.4.5" xref="S6.E11.m1.5.6.3.1.1.cmml">{</mo><mtable columnspacing="5pt" displaystyle="true" rowspacing="0pt" id="S6.E11.m1.4.4.4" xref="S6.E11.m1.5.6.3.1.cmml"><mtr id="S6.E11.m1.4.4.4a" xref="S6.E11.m1.5.6.3.1.cmml"><mtd class="ltx_align_left" columnalign="left" id="S6.E11.m1.4.4.4b" xref="S6.E11.m1.5.6.3.1.cmml"><mn id="S6.E11.m1.1.1.1.1.1.1" xref="S6.E11.m1.1.1.1.1.1.1.cmml">0</mn></mtd><mtd class="ltx_align_left" columnalign="left" id="S6.E11.m1.4.4.4c" xref="S6.E11.m1.5.6.3.1.cmml"><mrow id="S6.E11.m1.2.2.2.2.2.1" xref="S6.E11.m1.2.2.2.2.2.1.cmml"><mi id="S6.E11.m1.2.2.2.2.2.1.2" xref="S6.E11.m1.2.2.2.2.2.1.2.cmml">x</mi><mo id="S6.E11.m1.2.2.2.2.2.1.1" xref="S6.E11.m1.2.2.2.2.2.1.1.cmml">≤</mo><mn id="S6.E11.m1.2.2.2.2.2.1.3" xref="S6.E11.m1.2.2.2.2.2.1.3.cmml">0</mn></mrow></mtd></mtr><mtr id="S6.E11.m1.4.4.4d" xref="S6.E11.m1.5.6.3.1.cmml"><mtd class="ltx_align_left" columnalign="left" id="S6.E11.m1.4.4.4e" xref="S6.E11.m1.5.6.3.1.cmml"><mi id="S6.E11.m1.3.3.3.3.1.1" xref="S6.E11.m1.3.3.3.3.1.1.cmml">x</mi></mtd><mtd class="ltx_align_left" columnalign="left" id="S6.E11.m1.4.4.4f" xref="S6.E11.m1.5.6.3.1.cmml"><mrow id="S6.E11.m1.4.4.4.4.2.1" xref="S6.E11.m1.4.4.4.4.2.1.cmml"><mi id="S6.E11.m1.4.4.4.4.2.1.2" xref="S6.E11.m1.4.4.4.4.2.1.2.cmml">x</mi><mo id="S6.E11.m1.4.4.4.4.2.1.1" xref="S6.E11.m1.4.4.4.4.2.1.1.cmml">&gt;</mo><mn id="S6.E11.m1.4.4.4.4.2.1.3" xref="S6.E11.m1.4.4.4.4.2.1.3.cmml">0</mn></mrow></mtd></mtr></mtable></mrow></mrow><annotation-xml encoding="MathML-Content" id="S6.E11.m1.5b"><apply id="S6.E11.m1.5.6.cmml" xref="S6.E11.m1.5.6"><eq id="S6.E11.m1.5.6.1.cmml" xref="S6.E11.m1.5.6.1"></eq><apply id="S6.E11.m1.5.6.2.cmml" xref="S6.E11.m1.5.6.2"><times id="S6.E11.m1.5.6.2.1.cmml" xref="S6.E11.m1.5.6.2.1"></times><ci id="S6.E11.m1.5.6.2.2.cmml" xref="S6.E11.m1.5.6.2.2">𝑅</ci><ci id="S6.E11.m1.5.6.2.3.cmml" xref="S6.E11.m1.5.6.2.3">𝑒</ci><ci id="S6.E11.m1.5.6.2.4.cmml" xref="S6.E11.m1.5.6.2.4">𝐿</ci><ci id="S6.E11.m1.5.6.2.5.cmml" xref="S6.E11.m1.5.6.2.5">𝑈</ci><ci id="S6.E11.m1.5.5.cmml" xref="S6.E11.m1.5.5">𝑥</ci></apply><apply id="S6.E11.m1.5.6.3.1.cmml" xref="S6.E11.m1.4.4"><csymbol cd="latexml" id="S6.E11.m1.5.6.3.1.1.cmml" xref="S6.E11.m1.4.4.5">cases</csymbol><cn type="integer" id="S6.E11.m1.1.1.1.1.1.1.cmml" xref="S6.E11.m1.1.1.1.1.1.1">0</cn><apply id="S6.E11.m1.2.2.2.2.2.1.cmml" xref="S6.E11.m1.2.2.2.2.2.1"><leq id="S6.E11.m1.2.2.2.2.2.1.1.cmml" xref="S6.E11.m1.2.2.2.2.2.1.1"></leq><ci id="S6.E11.m1.2.2.2.2.2.1.2.cmml" xref="S6.E11.m1.2.2.2.2.2.1.2">𝑥</ci><cn type="integer" id="S6.E11.m1.2.2.2.2.2.1.3.cmml" xref="S6.E11.m1.2.2.2.2.2.1.3">0</cn></apply><ci id="S6.E11.m1.3.3.3.3.1.1.cmml" xref="S6.E11.m1.3.3.3.3.1.1">𝑥</ci><apply id="S6.E11.m1.4.4.4.4.2.1.cmml" xref="S6.E11.m1.4.4.4.4.2.1"><gt id="S6.E11.m1.4.4.4.4.2.1.1.cmml" xref="S6.E11.m1.4.4.4.4.2.1.1"></gt><ci id="S6.E11.m1.4.4.4.4.2.1.2.cmml" xref="S6.E11.m1.4.4.4.4.2.1.2">𝑥</ci><cn type="integer" id="S6.E11.m1.4.4.4.4.2.1.3.cmml" xref="S6.E11.m1.4.4.4.4.2.1.3">0</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.E11.m1.5c">ReLU(x)=\begin{cases}0&amp;x\leq 0\\
x&amp;x&gt;0\end{cases}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p id="S6.SS1.SSS4.p2.5" class="ltx_p">For a ReLU activation, any input below 0 returns a value of 0. Given the constant function when <math id="S6.SS1.SSS4.p2.1.m1.1" class="ltx_Math" alttext="x\leq 0" display="inline"><semantics id="S6.SS1.SSS4.p2.1.m1.1a"><mrow id="S6.SS1.SSS4.p2.1.m1.1.1" xref="S6.SS1.SSS4.p2.1.m1.1.1.cmml"><mi id="S6.SS1.SSS4.p2.1.m1.1.1.2" xref="S6.SS1.SSS4.p2.1.m1.1.1.2.cmml">x</mi><mo id="S6.SS1.SSS4.p2.1.m1.1.1.1" xref="S6.SS1.SSS4.p2.1.m1.1.1.1.cmml">≤</mo><mn id="S6.SS1.SSS4.p2.1.m1.1.1.3" xref="S6.SS1.SSS4.p2.1.m1.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.SS1.SSS4.p2.1.m1.1b"><apply id="S6.SS1.SSS4.p2.1.m1.1.1.cmml" xref="S6.SS1.SSS4.p2.1.m1.1.1"><leq id="S6.SS1.SSS4.p2.1.m1.1.1.1.cmml" xref="S6.SS1.SSS4.p2.1.m1.1.1.1"></leq><ci id="S6.SS1.SSS4.p2.1.m1.1.1.2.cmml" xref="S6.SS1.SSS4.p2.1.m1.1.1.2">𝑥</ci><cn type="integer" id="S6.SS1.SSS4.p2.1.m1.1.1.3.cmml" xref="S6.SS1.SSS4.p2.1.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.SSS4.p2.1.m1.1c">x\leq 0</annotation></semantics></math>, this ultimately results in the gradients <math id="S6.SS1.SSS4.p2.2.m2.1" class="ltx_Math" alttext="\frac{\delta L}{\delta W}=0" display="inline"><semantics id="S6.SS1.SSS4.p2.2.m2.1a"><mrow id="S6.SS1.SSS4.p2.2.m2.1.1" xref="S6.SS1.SSS4.p2.2.m2.1.1.cmml"><mfrac id="S6.SS1.SSS4.p2.2.m2.1.1.2" xref="S6.SS1.SSS4.p2.2.m2.1.1.2.cmml"><mrow id="S6.SS1.SSS4.p2.2.m2.1.1.2.2" xref="S6.SS1.SSS4.p2.2.m2.1.1.2.2.cmml"><mi id="S6.SS1.SSS4.p2.2.m2.1.1.2.2.2" xref="S6.SS1.SSS4.p2.2.m2.1.1.2.2.2.cmml">δ</mi><mo lspace="0em" rspace="0em" id="S6.SS1.SSS4.p2.2.m2.1.1.2.2.1" xref="S6.SS1.SSS4.p2.2.m2.1.1.2.2.1.cmml">​</mo><mi id="S6.SS1.SSS4.p2.2.m2.1.1.2.2.3" xref="S6.SS1.SSS4.p2.2.m2.1.1.2.2.3.cmml">L</mi></mrow><mrow id="S6.SS1.SSS4.p2.2.m2.1.1.2.3" xref="S6.SS1.SSS4.p2.2.m2.1.1.2.3.cmml"><mi id="S6.SS1.SSS4.p2.2.m2.1.1.2.3.2" xref="S6.SS1.SSS4.p2.2.m2.1.1.2.3.2.cmml">δ</mi><mo lspace="0em" rspace="0em" id="S6.SS1.SSS4.p2.2.m2.1.1.2.3.1" xref="S6.SS1.SSS4.p2.2.m2.1.1.2.3.1.cmml">​</mo><mi id="S6.SS1.SSS4.p2.2.m2.1.1.2.3.3" xref="S6.SS1.SSS4.p2.2.m2.1.1.2.3.3.cmml">W</mi></mrow></mfrac><mo id="S6.SS1.SSS4.p2.2.m2.1.1.1" xref="S6.SS1.SSS4.p2.2.m2.1.1.1.cmml">=</mo><mn id="S6.SS1.SSS4.p2.2.m2.1.1.3" xref="S6.SS1.SSS4.p2.2.m2.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.SS1.SSS4.p2.2.m2.1b"><apply id="S6.SS1.SSS4.p2.2.m2.1.1.cmml" xref="S6.SS1.SSS4.p2.2.m2.1.1"><eq id="S6.SS1.SSS4.p2.2.m2.1.1.1.cmml" xref="S6.SS1.SSS4.p2.2.m2.1.1.1"></eq><apply id="S6.SS1.SSS4.p2.2.m2.1.1.2.cmml" xref="S6.SS1.SSS4.p2.2.m2.1.1.2"><divide id="S6.SS1.SSS4.p2.2.m2.1.1.2.1.cmml" xref="S6.SS1.SSS4.p2.2.m2.1.1.2"></divide><apply id="S6.SS1.SSS4.p2.2.m2.1.1.2.2.cmml" xref="S6.SS1.SSS4.p2.2.m2.1.1.2.2"><times id="S6.SS1.SSS4.p2.2.m2.1.1.2.2.1.cmml" xref="S6.SS1.SSS4.p2.2.m2.1.1.2.2.1"></times><ci id="S6.SS1.SSS4.p2.2.m2.1.1.2.2.2.cmml" xref="S6.SS1.SSS4.p2.2.m2.1.1.2.2.2">𝛿</ci><ci id="S6.SS1.SSS4.p2.2.m2.1.1.2.2.3.cmml" xref="S6.SS1.SSS4.p2.2.m2.1.1.2.2.3">𝐿</ci></apply><apply id="S6.SS1.SSS4.p2.2.m2.1.1.2.3.cmml" xref="S6.SS1.SSS4.p2.2.m2.1.1.2.3"><times id="S6.SS1.SSS4.p2.2.m2.1.1.2.3.1.cmml" xref="S6.SS1.SSS4.p2.2.m2.1.1.2.3.1"></times><ci id="S6.SS1.SSS4.p2.2.m2.1.1.2.3.2.cmml" xref="S6.SS1.SSS4.p2.2.m2.1.1.2.3.2">𝛿</ci><ci id="S6.SS1.SSS4.p2.2.m2.1.1.2.3.3.cmml" xref="S6.SS1.SSS4.p2.2.m2.1.1.2.3.3">𝑊</ci></apply></apply><cn type="integer" id="S6.SS1.SSS4.p2.2.m2.1.1.3.cmml" xref="S6.SS1.SSS4.p2.2.m2.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.SSS4.p2.2.m2.1c">\frac{\delta L}{\delta W}=0</annotation></semantics></math> and <math id="S6.SS1.SSS4.p2.3.m3.1" class="ltx_Math" alttext="\frac{\delta L}{\delta b}=0" display="inline"><semantics id="S6.SS1.SSS4.p2.3.m3.1a"><mrow id="S6.SS1.SSS4.p2.3.m3.1.1" xref="S6.SS1.SSS4.p2.3.m3.1.1.cmml"><mfrac id="S6.SS1.SSS4.p2.3.m3.1.1.2" xref="S6.SS1.SSS4.p2.3.m3.1.1.2.cmml"><mrow id="S6.SS1.SSS4.p2.3.m3.1.1.2.2" xref="S6.SS1.SSS4.p2.3.m3.1.1.2.2.cmml"><mi id="S6.SS1.SSS4.p2.3.m3.1.1.2.2.2" xref="S6.SS1.SSS4.p2.3.m3.1.1.2.2.2.cmml">δ</mi><mo lspace="0em" rspace="0em" id="S6.SS1.SSS4.p2.3.m3.1.1.2.2.1" xref="S6.SS1.SSS4.p2.3.m3.1.1.2.2.1.cmml">​</mo><mi id="S6.SS1.SSS4.p2.3.m3.1.1.2.2.3" xref="S6.SS1.SSS4.p2.3.m3.1.1.2.2.3.cmml">L</mi></mrow><mrow id="S6.SS1.SSS4.p2.3.m3.1.1.2.3" xref="S6.SS1.SSS4.p2.3.m3.1.1.2.3.cmml"><mi id="S6.SS1.SSS4.p2.3.m3.1.1.2.3.2" xref="S6.SS1.SSS4.p2.3.m3.1.1.2.3.2.cmml">δ</mi><mo lspace="0em" rspace="0em" id="S6.SS1.SSS4.p2.3.m3.1.1.2.3.1" xref="S6.SS1.SSS4.p2.3.m3.1.1.2.3.1.cmml">​</mo><mi id="S6.SS1.SSS4.p2.3.m3.1.1.2.3.3" xref="S6.SS1.SSS4.p2.3.m3.1.1.2.3.3.cmml">b</mi></mrow></mfrac><mo id="S6.SS1.SSS4.p2.3.m3.1.1.1" xref="S6.SS1.SSS4.p2.3.m3.1.1.1.cmml">=</mo><mn id="S6.SS1.SSS4.p2.3.m3.1.1.3" xref="S6.SS1.SSS4.p2.3.m3.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.SS1.SSS4.p2.3.m3.1b"><apply id="S6.SS1.SSS4.p2.3.m3.1.1.cmml" xref="S6.SS1.SSS4.p2.3.m3.1.1"><eq id="S6.SS1.SSS4.p2.3.m3.1.1.1.cmml" xref="S6.SS1.SSS4.p2.3.m3.1.1.1"></eq><apply id="S6.SS1.SSS4.p2.3.m3.1.1.2.cmml" xref="S6.SS1.SSS4.p2.3.m3.1.1.2"><divide id="S6.SS1.SSS4.p2.3.m3.1.1.2.1.cmml" xref="S6.SS1.SSS4.p2.3.m3.1.1.2"></divide><apply id="S6.SS1.SSS4.p2.3.m3.1.1.2.2.cmml" xref="S6.SS1.SSS4.p2.3.m3.1.1.2.2"><times id="S6.SS1.SSS4.p2.3.m3.1.1.2.2.1.cmml" xref="S6.SS1.SSS4.p2.3.m3.1.1.2.2.1"></times><ci id="S6.SS1.SSS4.p2.3.m3.1.1.2.2.2.cmml" xref="S6.SS1.SSS4.p2.3.m3.1.1.2.2.2">𝛿</ci><ci id="S6.SS1.SSS4.p2.3.m3.1.1.2.2.3.cmml" xref="S6.SS1.SSS4.p2.3.m3.1.1.2.2.3">𝐿</ci></apply><apply id="S6.SS1.SSS4.p2.3.m3.1.1.2.3.cmml" xref="S6.SS1.SSS4.p2.3.m3.1.1.2.3"><times id="S6.SS1.SSS4.p2.3.m3.1.1.2.3.1.cmml" xref="S6.SS1.SSS4.p2.3.m3.1.1.2.3.1"></times><ci id="S6.SS1.SSS4.p2.3.m3.1.1.2.3.2.cmml" xref="S6.SS1.SSS4.p2.3.m3.1.1.2.3.2">𝛿</ci><ci id="S6.SS1.SSS4.p2.3.m3.1.1.2.3.3.cmml" xref="S6.SS1.SSS4.p2.3.m3.1.1.2.3.3">𝑏</ci></apply></apply><cn type="integer" id="S6.SS1.SSS4.p2.3.m3.1.1.3.cmml" xref="S6.SS1.SSS4.p2.3.m3.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.SSS4.p2.3.m3.1c">\frac{\delta L}{\delta b}=0</annotation></semantics></math>. Therefore, ensuring the input to the ReLU function is negative (which can be as simple as having weights <math id="S6.SS1.SSS4.p2.4.m4.1" class="ltx_Math" alttext="w" display="inline"><semantics id="S6.SS1.SSS4.p2.4.m4.1a"><mi id="S6.SS1.SSS4.p2.4.m4.1.1" xref="S6.SS1.SSS4.p2.4.m4.1.1.cmml">w</mi><annotation-xml encoding="MathML-Content" id="S6.SS1.SSS4.p2.4.m4.1b"><ci id="S6.SS1.SSS4.p2.4.m4.1.1.cmml" xref="S6.SS1.SSS4.p2.4.m4.1.1">𝑤</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.SSS4.p2.4.m4.1c">w</annotation></semantics></math> as 0 and the bias <math id="S6.SS1.SSS4.p2.5.m5.1" class="ltx_Math" alttext="b" display="inline"><semantics id="S6.SS1.SSS4.p2.5.m5.1a"><mi id="S6.SS1.SSS4.p2.5.m5.1.1" xref="S6.SS1.SSS4.p2.5.m5.1.1.cmml">b</mi><annotation-xml encoding="MathML-Content" id="S6.SS1.SSS4.p2.5.m5.1b"><ci id="S6.SS1.SSS4.p2.5.m5.1.1.cmml" xref="S6.SS1.SSS4.p2.5.m5.1.1">𝑏</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.SSS4.p2.5.m5.1c">b</annotation></semantics></math> as negative for a fully-connected layer) is a sufficient condition for achieving zeroed gradients. Using this method, a malicious server will then send a malicious model with dead-ReLUs to all clients except for a single targeted client. After secure aggregation, the aggregated update would only comprise of a single non-zero update from the targeted client allow for a single-update attack. Another work <cite class="ltx_cite ltx_citemacro_citep">(Lam et al<span class="ltx_text">.</span>, <a href="#bib.bib77" title="" class="ltx_ref">2021</a>)</cite> aims to disaggregate the updates with the same goal of breaking aggregation. This method utilizes the additional training summary information, in particular the client participation rate, to allow the server to reconstruct the user participation matrix through observation of the aggregated updates over multiple training rounds. The attack works particularly well with a malicious server when the a fixed model is sent during each round and the clients send the same updates. When the server does not modify the training process (honest-but-curious), user participation reconstruction becomes more difficult. With a smaller batch size and a larger number of local epochs or local dataset size, reconstruction begins to fail.</p>
</div>
<div id="S6.SS1.SSS4.p3" class="ltx_para">
<p id="S6.SS1.SSS4.p3.1" class="ltx_p">In <cite class="ltx_cite ltx_citemacro_citep">(Wen et al<span class="ltx_text">.</span>, <a href="#bib.bib134" title="" class="ltx_ref">2022</a>)</cite>, attackers attack a target image in an arbitrarily large batch by manipulating the model parameters to magnify the update of only the single image. Magnification is done in two steps: the magnification of the target class followed by a specific feature for a target image. In order to estimate a boundary for the features, the server uses several rounds of additional FL training for setup. This requires for the batch data to be the same across training rounds. In <cite class="ltx_cite ltx_citemacro_citep">(Kariyappa et al<span class="ltx_text">.</span>, <a href="#bib.bib71" title="" class="ltx_ref">2023</a>)</cite>, the attacker formulates the problem of data reconstruction as a blind source separation problem. Given the observation that inputs to a linear layer can be directly reconstructed through the gradients, solving for the inputs is similar to solving for a unknown variables given a set of linear equations.</p>
</div>
<div id="S6.SS1.SSS4.p4" class="ltx_para">
<p id="S6.SS1.SSS4.p4.1" class="ltx_p">These attacks are all able to break some levels of aggregation. <cite class="ltx_cite ltx_citemacro_citep">(Pasquini et al<span class="ltx_text">.</span>, <a href="#bib.bib102" title="" class="ltx_ref">2022</a>; Lam et al<span class="ltx_text">.</span>, <a href="#bib.bib77" title="" class="ltx_ref">2021</a>)</cite> break aggregation itself to allow for other data reconstruction attacks to work with an aggregate setting.  <cite class="ltx_cite ltx_citemacro_citep">(Wen et al<span class="ltx_text">.</span>, <a href="#bib.bib134" title="" class="ltx_ref">2022</a>; Kariyappa et al<span class="ltx_text">.</span>, <a href="#bib.bib71" title="" class="ltx_ref">2023</a>)</cite> both function on both individual and aggregate updates. Each of these methods have their own strengths and weaknesses. <cite class="ltx_cite ltx_citemacro_citep">(Pasquini et al<span class="ltx_text">.</span>, <a href="#bib.bib102" title="" class="ltx_ref">2022</a>)</cite> requires sending different models to different clients but allows an attacker to single out a single update. <cite class="ltx_cite ltx_citemacro_citep">(Lam et al<span class="ltx_text">.</span>, <a href="#bib.bib77" title="" class="ltx_ref">2021</a>)</cite> requires multiple training rounds and additional knowledge on top of the client update. However, it can essentially completely disaggregate aggregate updates over time. <cite class="ltx_cite ltx_citemacro_citep">(Kariyappa et al<span class="ltx_text">.</span>, <a href="#bib.bib71" title="" class="ltx_ref">2023</a>)</cite> can attack batch sizes up to 1024, but also requires malicious modification of the network parameters. <cite class="ltx_cite ltx_citemacro_citep">(Wen et al<span class="ltx_text">.</span>, <a href="#bib.bib134" title="" class="ltx_ref">2022</a>)</cite> targets a single image in an arbitary update size, but requires malicious modification of network parameters along with a few rounds of setup.</p>
</div>
</section>
</section>
<section id="S6.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.2. </span>Membership Inference Attacks</h3>

<div id="S6.SS2.p1" class="ltx_para">
<p id="S6.SS2.p1.1" class="ltx_p">The goal of membership inference attacks is to infer whether any particular data instance has been used in the training of a specific model. If a particular data instance has been used in the training, this instance is called a <span id="S6.SS2.p1.1.1" class="ltx_text ltx_font_bold">member</span>, otherwise it is a <span id="S6.SS2.p1.1.2" class="ltx_text ltx_font_bold">non-member</span>. Knowing the membership of one particular data point could result in revealing private information, for example if someone’s data is known to be in a cancer dataset (used to train a cancer prediction model), then it is highly likely that this particular person has cancer.</p>
</div>
<section id="S6.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">6.2.1. </span>With access to some training data.</h4>

<div id="S6.SS2.SSS1.p1" class="ltx_para">
<p id="S6.SS2.SSS1.p1.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citet">Nasr et al<span class="ltx_text">.</span> (<a href="#bib.bib98" title="" class="ltx_ref">2019</a>)</cite> presented the very first analysis on membership inference attack against neural networks under FL with access to some training members and white-box access to the trained neural networks. The adversary can be either the central server or one of the participants in the FL framework. Besides, they presented the definition of passive attacker and active attacker, where the passive attacker does the training normally and the active attacker breaks the FL protocols to improve the effectiveness of MI attacks.</p>
</div>
<div id="S6.SS2.SSS1.p2" class="ltx_para">
<p id="S6.SS2.SSS1.p2.1" class="ltx_p">For passive attackers, they showed that the attackers can take advantage of the gradients, activation maps, prediction vectors, loss and true label of one instance using local model of each user at different epochs during the training process and perform MI attacks. An attack model is trained using some known members.</p>
</div>
<div id="S6.SS2.SSS1.p3" class="ltx_para">
<p id="S6.SS2.SSS1.p3.1" class="ltx_p">On the other hand, two active attacker strategies were proposed. The first one is called <span id="S6.SS2.SSS1.p3.1.1" class="ltx_text ltx_font_bold">gradient ascent attacker</span>, which means that the attacker will do gradient ascent on targeted samples. By taking the action of gradient ascent, the loss of the targeted samples will be increased. For member instances, their loss will be abruptly decreased by one client, thus can be distinguished from non-members. Both central server adversary and client adversary can utilize this strategy. The second active attack method is called <span id="S6.SS2.SSS1.p3.1.2" class="ltx_text ltx_font_bold">isolating attacker</span>. The attacker can isolate one special target participant by creating a separated copy of the aggregated model. This is equivalent to training a model on a single machine using the data from the targeted client. To use this isolation attack, the adversary needs to be the central server.</p>
</div>
<div id="S6.SS2.SSS1.p4" class="ltx_para">
<p id="S6.SS2.SSS1.p4.2" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citet">Zari et al<span class="ltx_text">.</span> (<a href="#bib.bib141" title="" class="ltx_ref">2021</a>)</cite> proposed a computationally more efficient passive membership inference attack under FL which also requires some known members. Their attack uses as the feature vector the probabilities of the correct label under local models at different epochs, namely <math id="S6.SS2.SSS1.p4.1.m1.10" class="ltx_Math" alttext="\big{\langle}F_{\theta_{C_{i}}^{(1)}}(x)_{y},F_{\theta_{C_{i}}^{(2)}}(x)_{y},\cdots,F_{\theta_{C_{i}}^{(T)}}(x)_{y}\big{\rangle}" display="inline"><semantics id="S6.SS2.SSS1.p4.1.m1.10a"><mrow id="S6.SS2.SSS1.p4.1.m1.10.10.3" xref="S6.SS2.SSS1.p4.1.m1.10.10.4.cmml"><mo maxsize="120%" minsize="120%" id="S6.SS2.SSS1.p4.1.m1.10.10.3.4" xref="S6.SS2.SSS1.p4.1.m1.10.10.4.cmml">⟨</mo><mrow id="S6.SS2.SSS1.p4.1.m1.8.8.1.1" xref="S6.SS2.SSS1.p4.1.m1.8.8.1.1.cmml"><msub id="S6.SS2.SSS1.p4.1.m1.8.8.1.1.2" xref="S6.SS2.SSS1.p4.1.m1.8.8.1.1.2.cmml"><mi id="S6.SS2.SSS1.p4.1.m1.8.8.1.1.2.2" xref="S6.SS2.SSS1.p4.1.m1.8.8.1.1.2.2.cmml">F</mi><msubsup id="S6.SS2.SSS1.p4.1.m1.1.1.1" xref="S6.SS2.SSS1.p4.1.m1.1.1.1.cmml"><mi id="S6.SS2.SSS1.p4.1.m1.1.1.1.3.2" xref="S6.SS2.SSS1.p4.1.m1.1.1.1.3.2.cmml">θ</mi><msub id="S6.SS2.SSS1.p4.1.m1.1.1.1.3.3" xref="S6.SS2.SSS1.p4.1.m1.1.1.1.3.3.cmml"><mi id="S6.SS2.SSS1.p4.1.m1.1.1.1.3.3.2" xref="S6.SS2.SSS1.p4.1.m1.1.1.1.3.3.2.cmml">C</mi><mi id="S6.SS2.SSS1.p4.1.m1.1.1.1.3.3.3" xref="S6.SS2.SSS1.p4.1.m1.1.1.1.3.3.3.cmml">i</mi></msub><mrow id="S6.SS2.SSS1.p4.1.m1.1.1.1.1.1.3" xref="S6.SS2.SSS1.p4.1.m1.1.1.1.cmml"><mo stretchy="false" id="S6.SS2.SSS1.p4.1.m1.1.1.1.1.1.3.1" xref="S6.SS2.SSS1.p4.1.m1.1.1.1.cmml">(</mo><mn id="S6.SS2.SSS1.p4.1.m1.1.1.1.1.1.1" xref="S6.SS2.SSS1.p4.1.m1.1.1.1.1.1.1.cmml">1</mn><mo stretchy="false" id="S6.SS2.SSS1.p4.1.m1.1.1.1.1.1.3.2" xref="S6.SS2.SSS1.p4.1.m1.1.1.1.cmml">)</mo></mrow></msubsup></msub><mo lspace="0em" rspace="0em" id="S6.SS2.SSS1.p4.1.m1.8.8.1.1.1" xref="S6.SS2.SSS1.p4.1.m1.8.8.1.1.1.cmml">​</mo><msub id="S6.SS2.SSS1.p4.1.m1.8.8.1.1.3" xref="S6.SS2.SSS1.p4.1.m1.8.8.1.1.3.cmml"><mrow id="S6.SS2.SSS1.p4.1.m1.8.8.1.1.3.2.2" xref="S6.SS2.SSS1.p4.1.m1.8.8.1.1.3.cmml"><mo stretchy="false" id="S6.SS2.SSS1.p4.1.m1.8.8.1.1.3.2.2.1" xref="S6.SS2.SSS1.p4.1.m1.8.8.1.1.3.cmml">(</mo><mi id="S6.SS2.SSS1.p4.1.m1.4.4" xref="S6.SS2.SSS1.p4.1.m1.4.4.cmml">x</mi><mo stretchy="false" id="S6.SS2.SSS1.p4.1.m1.8.8.1.1.3.2.2.2" xref="S6.SS2.SSS1.p4.1.m1.8.8.1.1.3.cmml">)</mo></mrow><mi id="S6.SS2.SSS1.p4.1.m1.8.8.1.1.3.3" xref="S6.SS2.SSS1.p4.1.m1.8.8.1.1.3.3.cmml">y</mi></msub></mrow><mo id="S6.SS2.SSS1.p4.1.m1.10.10.3.5" xref="S6.SS2.SSS1.p4.1.m1.10.10.4.cmml">,</mo><mrow id="S6.SS2.SSS1.p4.1.m1.9.9.2.2" xref="S6.SS2.SSS1.p4.1.m1.9.9.2.2.cmml"><msub id="S6.SS2.SSS1.p4.1.m1.9.9.2.2.2" xref="S6.SS2.SSS1.p4.1.m1.9.9.2.2.2.cmml"><mi id="S6.SS2.SSS1.p4.1.m1.9.9.2.2.2.2" xref="S6.SS2.SSS1.p4.1.m1.9.9.2.2.2.2.cmml">F</mi><msubsup id="S6.SS2.SSS1.p4.1.m1.2.2.1" xref="S6.SS2.SSS1.p4.1.m1.2.2.1.cmml"><mi id="S6.SS2.SSS1.p4.1.m1.2.2.1.3.2" xref="S6.SS2.SSS1.p4.1.m1.2.2.1.3.2.cmml">θ</mi><msub id="S6.SS2.SSS1.p4.1.m1.2.2.1.3.3" xref="S6.SS2.SSS1.p4.1.m1.2.2.1.3.3.cmml"><mi id="S6.SS2.SSS1.p4.1.m1.2.2.1.3.3.2" xref="S6.SS2.SSS1.p4.1.m1.2.2.1.3.3.2.cmml">C</mi><mi id="S6.SS2.SSS1.p4.1.m1.2.2.1.3.3.3" xref="S6.SS2.SSS1.p4.1.m1.2.2.1.3.3.3.cmml">i</mi></msub><mrow id="S6.SS2.SSS1.p4.1.m1.2.2.1.1.1.3" xref="S6.SS2.SSS1.p4.1.m1.2.2.1.cmml"><mo stretchy="false" id="S6.SS2.SSS1.p4.1.m1.2.2.1.1.1.3.1" xref="S6.SS2.SSS1.p4.1.m1.2.2.1.cmml">(</mo><mn id="S6.SS2.SSS1.p4.1.m1.2.2.1.1.1.1" xref="S6.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.cmml">2</mn><mo stretchy="false" id="S6.SS2.SSS1.p4.1.m1.2.2.1.1.1.3.2" xref="S6.SS2.SSS1.p4.1.m1.2.2.1.cmml">)</mo></mrow></msubsup></msub><mo lspace="0em" rspace="0em" id="S6.SS2.SSS1.p4.1.m1.9.9.2.2.1" xref="S6.SS2.SSS1.p4.1.m1.9.9.2.2.1.cmml">​</mo><msub id="S6.SS2.SSS1.p4.1.m1.9.9.2.2.3" xref="S6.SS2.SSS1.p4.1.m1.9.9.2.2.3.cmml"><mrow id="S6.SS2.SSS1.p4.1.m1.9.9.2.2.3.2.2" xref="S6.SS2.SSS1.p4.1.m1.9.9.2.2.3.cmml"><mo stretchy="false" id="S6.SS2.SSS1.p4.1.m1.9.9.2.2.3.2.2.1" xref="S6.SS2.SSS1.p4.1.m1.9.9.2.2.3.cmml">(</mo><mi id="S6.SS2.SSS1.p4.1.m1.5.5" xref="S6.SS2.SSS1.p4.1.m1.5.5.cmml">x</mi><mo stretchy="false" id="S6.SS2.SSS1.p4.1.m1.9.9.2.2.3.2.2.2" xref="S6.SS2.SSS1.p4.1.m1.9.9.2.2.3.cmml">)</mo></mrow><mi id="S6.SS2.SSS1.p4.1.m1.9.9.2.2.3.3" xref="S6.SS2.SSS1.p4.1.m1.9.9.2.2.3.3.cmml">y</mi></msub></mrow><mo id="S6.SS2.SSS1.p4.1.m1.10.10.3.6" xref="S6.SS2.SSS1.p4.1.m1.10.10.4.cmml">,</mo><mi mathvariant="normal" id="S6.SS2.SSS1.p4.1.m1.7.7" xref="S6.SS2.SSS1.p4.1.m1.7.7.cmml">⋯</mi><mo id="S6.SS2.SSS1.p4.1.m1.10.10.3.7" xref="S6.SS2.SSS1.p4.1.m1.10.10.4.cmml">,</mo><mrow id="S6.SS2.SSS1.p4.1.m1.10.10.3.3" xref="S6.SS2.SSS1.p4.1.m1.10.10.3.3.cmml"><msub id="S6.SS2.SSS1.p4.1.m1.10.10.3.3.2" xref="S6.SS2.SSS1.p4.1.m1.10.10.3.3.2.cmml"><mi id="S6.SS2.SSS1.p4.1.m1.10.10.3.3.2.2" xref="S6.SS2.SSS1.p4.1.m1.10.10.3.3.2.2.cmml">F</mi><msubsup id="S6.SS2.SSS1.p4.1.m1.3.3.1" xref="S6.SS2.SSS1.p4.1.m1.3.3.1.cmml"><mi id="S6.SS2.SSS1.p4.1.m1.3.3.1.3.2" xref="S6.SS2.SSS1.p4.1.m1.3.3.1.3.2.cmml">θ</mi><msub id="S6.SS2.SSS1.p4.1.m1.3.3.1.3.3" xref="S6.SS2.SSS1.p4.1.m1.3.3.1.3.3.cmml"><mi id="S6.SS2.SSS1.p4.1.m1.3.3.1.3.3.2" xref="S6.SS2.SSS1.p4.1.m1.3.3.1.3.3.2.cmml">C</mi><mi id="S6.SS2.SSS1.p4.1.m1.3.3.1.3.3.3" xref="S6.SS2.SSS1.p4.1.m1.3.3.1.3.3.3.cmml">i</mi></msub><mrow id="S6.SS2.SSS1.p4.1.m1.3.3.1.1.1.3" xref="S6.SS2.SSS1.p4.1.m1.3.3.1.cmml"><mo stretchy="false" id="S6.SS2.SSS1.p4.1.m1.3.3.1.1.1.3.1" xref="S6.SS2.SSS1.p4.1.m1.3.3.1.cmml">(</mo><mi id="S6.SS2.SSS1.p4.1.m1.3.3.1.1.1.1" xref="S6.SS2.SSS1.p4.1.m1.3.3.1.1.1.1.cmml">T</mi><mo stretchy="false" id="S6.SS2.SSS1.p4.1.m1.3.3.1.1.1.3.2" xref="S6.SS2.SSS1.p4.1.m1.3.3.1.cmml">)</mo></mrow></msubsup></msub><mo lspace="0em" rspace="0em" id="S6.SS2.SSS1.p4.1.m1.10.10.3.3.1" xref="S6.SS2.SSS1.p4.1.m1.10.10.3.3.1.cmml">​</mo><msub id="S6.SS2.SSS1.p4.1.m1.10.10.3.3.3" xref="S6.SS2.SSS1.p4.1.m1.10.10.3.3.3.cmml"><mrow id="S6.SS2.SSS1.p4.1.m1.10.10.3.3.3.2.2" xref="S6.SS2.SSS1.p4.1.m1.10.10.3.3.3.cmml"><mo stretchy="false" id="S6.SS2.SSS1.p4.1.m1.10.10.3.3.3.2.2.1" xref="S6.SS2.SSS1.p4.1.m1.10.10.3.3.3.cmml">(</mo><mi id="S6.SS2.SSS1.p4.1.m1.6.6" xref="S6.SS2.SSS1.p4.1.m1.6.6.cmml">x</mi><mo stretchy="false" id="S6.SS2.SSS1.p4.1.m1.10.10.3.3.3.2.2.2" xref="S6.SS2.SSS1.p4.1.m1.10.10.3.3.3.cmml">)</mo></mrow><mi id="S6.SS2.SSS1.p4.1.m1.10.10.3.3.3.3" xref="S6.SS2.SSS1.p4.1.m1.10.10.3.3.3.3.cmml">y</mi></msub></mrow><mo maxsize="120%" minsize="120%" id="S6.SS2.SSS1.p4.1.m1.10.10.3.8" xref="S6.SS2.SSS1.p4.1.m1.10.10.4.cmml">⟩</mo></mrow><annotation-xml encoding="MathML-Content" id="S6.SS2.SSS1.p4.1.m1.10b"><list id="S6.SS2.SSS1.p4.1.m1.10.10.4.cmml" xref="S6.SS2.SSS1.p4.1.m1.10.10.3"><apply id="S6.SS2.SSS1.p4.1.m1.8.8.1.1.cmml" xref="S6.SS2.SSS1.p4.1.m1.8.8.1.1"><times id="S6.SS2.SSS1.p4.1.m1.8.8.1.1.1.cmml" xref="S6.SS2.SSS1.p4.1.m1.8.8.1.1.1"></times><apply id="S6.SS2.SSS1.p4.1.m1.8.8.1.1.2.cmml" xref="S6.SS2.SSS1.p4.1.m1.8.8.1.1.2"><csymbol cd="ambiguous" id="S6.SS2.SSS1.p4.1.m1.8.8.1.1.2.1.cmml" xref="S6.SS2.SSS1.p4.1.m1.8.8.1.1.2">subscript</csymbol><ci id="S6.SS2.SSS1.p4.1.m1.8.8.1.1.2.2.cmml" xref="S6.SS2.SSS1.p4.1.m1.8.8.1.1.2.2">𝐹</ci><apply id="S6.SS2.SSS1.p4.1.m1.1.1.1.cmml" xref="S6.SS2.SSS1.p4.1.m1.1.1.1"><csymbol cd="ambiguous" id="S6.SS2.SSS1.p4.1.m1.1.1.1.2.cmml" xref="S6.SS2.SSS1.p4.1.m1.1.1.1">superscript</csymbol><apply id="S6.SS2.SSS1.p4.1.m1.1.1.1.3.cmml" xref="S6.SS2.SSS1.p4.1.m1.1.1.1"><csymbol cd="ambiguous" id="S6.SS2.SSS1.p4.1.m1.1.1.1.3.1.cmml" xref="S6.SS2.SSS1.p4.1.m1.1.1.1">subscript</csymbol><ci id="S6.SS2.SSS1.p4.1.m1.1.1.1.3.2.cmml" xref="S6.SS2.SSS1.p4.1.m1.1.1.1.3.2">𝜃</ci><apply id="S6.SS2.SSS1.p4.1.m1.1.1.1.3.3.cmml" xref="S6.SS2.SSS1.p4.1.m1.1.1.1.3.3"><csymbol cd="ambiguous" id="S6.SS2.SSS1.p4.1.m1.1.1.1.3.3.1.cmml" xref="S6.SS2.SSS1.p4.1.m1.1.1.1.3.3">subscript</csymbol><ci id="S6.SS2.SSS1.p4.1.m1.1.1.1.3.3.2.cmml" xref="S6.SS2.SSS1.p4.1.m1.1.1.1.3.3.2">𝐶</ci><ci id="S6.SS2.SSS1.p4.1.m1.1.1.1.3.3.3.cmml" xref="S6.SS2.SSS1.p4.1.m1.1.1.1.3.3.3">𝑖</ci></apply></apply><cn type="integer" id="S6.SS2.SSS1.p4.1.m1.1.1.1.1.1.1.cmml" xref="S6.SS2.SSS1.p4.1.m1.1.1.1.1.1.1">1</cn></apply></apply><apply id="S6.SS2.SSS1.p4.1.m1.8.8.1.1.3.cmml" xref="S6.SS2.SSS1.p4.1.m1.8.8.1.1.3"><csymbol cd="ambiguous" id="S6.SS2.SSS1.p4.1.m1.8.8.1.1.3.1.cmml" xref="S6.SS2.SSS1.p4.1.m1.8.8.1.1.3">subscript</csymbol><ci id="S6.SS2.SSS1.p4.1.m1.4.4.cmml" xref="S6.SS2.SSS1.p4.1.m1.4.4">𝑥</ci><ci id="S6.SS2.SSS1.p4.1.m1.8.8.1.1.3.3.cmml" xref="S6.SS2.SSS1.p4.1.m1.8.8.1.1.3.3">𝑦</ci></apply></apply><apply id="S6.SS2.SSS1.p4.1.m1.9.9.2.2.cmml" xref="S6.SS2.SSS1.p4.1.m1.9.9.2.2"><times id="S6.SS2.SSS1.p4.1.m1.9.9.2.2.1.cmml" xref="S6.SS2.SSS1.p4.1.m1.9.9.2.2.1"></times><apply id="S6.SS2.SSS1.p4.1.m1.9.9.2.2.2.cmml" xref="S6.SS2.SSS1.p4.1.m1.9.9.2.2.2"><csymbol cd="ambiguous" id="S6.SS2.SSS1.p4.1.m1.9.9.2.2.2.1.cmml" xref="S6.SS2.SSS1.p4.1.m1.9.9.2.2.2">subscript</csymbol><ci id="S6.SS2.SSS1.p4.1.m1.9.9.2.2.2.2.cmml" xref="S6.SS2.SSS1.p4.1.m1.9.9.2.2.2.2">𝐹</ci><apply id="S6.SS2.SSS1.p4.1.m1.2.2.1.cmml" xref="S6.SS2.SSS1.p4.1.m1.2.2.1"><csymbol cd="ambiguous" id="S6.SS2.SSS1.p4.1.m1.2.2.1.2.cmml" xref="S6.SS2.SSS1.p4.1.m1.2.2.1">superscript</csymbol><apply id="S6.SS2.SSS1.p4.1.m1.2.2.1.3.cmml" xref="S6.SS2.SSS1.p4.1.m1.2.2.1"><csymbol cd="ambiguous" id="S6.SS2.SSS1.p4.1.m1.2.2.1.3.1.cmml" xref="S6.SS2.SSS1.p4.1.m1.2.2.1">subscript</csymbol><ci id="S6.SS2.SSS1.p4.1.m1.2.2.1.3.2.cmml" xref="S6.SS2.SSS1.p4.1.m1.2.2.1.3.2">𝜃</ci><apply id="S6.SS2.SSS1.p4.1.m1.2.2.1.3.3.cmml" xref="S6.SS2.SSS1.p4.1.m1.2.2.1.3.3"><csymbol cd="ambiguous" id="S6.SS2.SSS1.p4.1.m1.2.2.1.3.3.1.cmml" xref="S6.SS2.SSS1.p4.1.m1.2.2.1.3.3">subscript</csymbol><ci id="S6.SS2.SSS1.p4.1.m1.2.2.1.3.3.2.cmml" xref="S6.SS2.SSS1.p4.1.m1.2.2.1.3.3.2">𝐶</ci><ci id="S6.SS2.SSS1.p4.1.m1.2.2.1.3.3.3.cmml" xref="S6.SS2.SSS1.p4.1.m1.2.2.1.3.3.3">𝑖</ci></apply></apply><cn type="integer" id="S6.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.cmml" xref="S6.SS2.SSS1.p4.1.m1.2.2.1.1.1.1">2</cn></apply></apply><apply id="S6.SS2.SSS1.p4.1.m1.9.9.2.2.3.cmml" xref="S6.SS2.SSS1.p4.1.m1.9.9.2.2.3"><csymbol cd="ambiguous" id="S6.SS2.SSS1.p4.1.m1.9.9.2.2.3.1.cmml" xref="S6.SS2.SSS1.p4.1.m1.9.9.2.2.3">subscript</csymbol><ci id="S6.SS2.SSS1.p4.1.m1.5.5.cmml" xref="S6.SS2.SSS1.p4.1.m1.5.5">𝑥</ci><ci id="S6.SS2.SSS1.p4.1.m1.9.9.2.2.3.3.cmml" xref="S6.SS2.SSS1.p4.1.m1.9.9.2.2.3.3">𝑦</ci></apply></apply><ci id="S6.SS2.SSS1.p4.1.m1.7.7.cmml" xref="S6.SS2.SSS1.p4.1.m1.7.7">⋯</ci><apply id="S6.SS2.SSS1.p4.1.m1.10.10.3.3.cmml" xref="S6.SS2.SSS1.p4.1.m1.10.10.3.3"><times id="S6.SS2.SSS1.p4.1.m1.10.10.3.3.1.cmml" xref="S6.SS2.SSS1.p4.1.m1.10.10.3.3.1"></times><apply id="S6.SS2.SSS1.p4.1.m1.10.10.3.3.2.cmml" xref="S6.SS2.SSS1.p4.1.m1.10.10.3.3.2"><csymbol cd="ambiguous" id="S6.SS2.SSS1.p4.1.m1.10.10.3.3.2.1.cmml" xref="S6.SS2.SSS1.p4.1.m1.10.10.3.3.2">subscript</csymbol><ci id="S6.SS2.SSS1.p4.1.m1.10.10.3.3.2.2.cmml" xref="S6.SS2.SSS1.p4.1.m1.10.10.3.3.2.2">𝐹</ci><apply id="S6.SS2.SSS1.p4.1.m1.3.3.1.cmml" xref="S6.SS2.SSS1.p4.1.m1.3.3.1"><csymbol cd="ambiguous" id="S6.SS2.SSS1.p4.1.m1.3.3.1.2.cmml" xref="S6.SS2.SSS1.p4.1.m1.3.3.1">superscript</csymbol><apply id="S6.SS2.SSS1.p4.1.m1.3.3.1.3.cmml" xref="S6.SS2.SSS1.p4.1.m1.3.3.1"><csymbol cd="ambiguous" id="S6.SS2.SSS1.p4.1.m1.3.3.1.3.1.cmml" xref="S6.SS2.SSS1.p4.1.m1.3.3.1">subscript</csymbol><ci id="S6.SS2.SSS1.p4.1.m1.3.3.1.3.2.cmml" xref="S6.SS2.SSS1.p4.1.m1.3.3.1.3.2">𝜃</ci><apply id="S6.SS2.SSS1.p4.1.m1.3.3.1.3.3.cmml" xref="S6.SS2.SSS1.p4.1.m1.3.3.1.3.3"><csymbol cd="ambiguous" id="S6.SS2.SSS1.p4.1.m1.3.3.1.3.3.1.cmml" xref="S6.SS2.SSS1.p4.1.m1.3.3.1.3.3">subscript</csymbol><ci id="S6.SS2.SSS1.p4.1.m1.3.3.1.3.3.2.cmml" xref="S6.SS2.SSS1.p4.1.m1.3.3.1.3.3.2">𝐶</ci><ci id="S6.SS2.SSS1.p4.1.m1.3.3.1.3.3.3.cmml" xref="S6.SS2.SSS1.p4.1.m1.3.3.1.3.3.3">𝑖</ci></apply></apply><ci id="S6.SS2.SSS1.p4.1.m1.3.3.1.1.1.1.cmml" xref="S6.SS2.SSS1.p4.1.m1.3.3.1.1.1.1">𝑇</ci></apply></apply><apply id="S6.SS2.SSS1.p4.1.m1.10.10.3.3.3.cmml" xref="S6.SS2.SSS1.p4.1.m1.10.10.3.3.3"><csymbol cd="ambiguous" id="S6.SS2.SSS1.p4.1.m1.10.10.3.3.3.1.cmml" xref="S6.SS2.SSS1.p4.1.m1.10.10.3.3.3">subscript</csymbol><ci id="S6.SS2.SSS1.p4.1.m1.6.6.cmml" xref="S6.SS2.SSS1.p4.1.m1.6.6">𝑥</ci><ci id="S6.SS2.SSS1.p4.1.m1.10.10.3.3.3.3.cmml" xref="S6.SS2.SSS1.p4.1.m1.10.10.3.3.3.3">𝑦</ci></apply></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.SSS1.p4.1.m1.10c">\big{\langle}F_{\theta_{C_{i}}^{(1)}}(x)_{y},F_{\theta_{C_{i}}^{(2)}}(x)_{y},\cdots,F_{\theta_{C_{i}}^{(T)}}(x)_{y}\big{\rangle}</annotation></semantics></math>, where <math id="S6.SS2.SSS1.p4.2.m2.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S6.SS2.SSS1.p4.2.m2.1a"><mi id="S6.SS2.SSS1.p4.2.m2.1.1" xref="S6.SS2.SSS1.p4.2.m2.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S6.SS2.SSS1.p4.2.m2.1b"><ci id="S6.SS2.SSS1.p4.2.m2.1.1.cmml" xref="S6.SS2.SSS1.p4.2.m2.1.1">𝑇</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.SSS1.p4.2.m2.1c">T</annotation></semantics></math> is the number of communication rounds. An attack model is trained to predict membership using known members and known non-members (which come from validation). Since the feature vector contains only one number from one epoch, this attack requires significantly less computational resources than the Nasr’s attack which uses information such as gradient and activation maps. The authors showed that using this probability feature vector can achieve higher membership inference attack accuracy than Nasr’s attack on CIFAR-100 dataset with AlexNet and DenseNet, but lower accuracy than Nasr’s attack on Purchase dataset.</p>
</div>
<figure id="S6.F5" class="ltx_figure"><img src="/html/2405.03636/assets/plots-images/zari_attack.png" id="S6.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="314" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5. </span>Membership inference attack workflow from <cite class="ltx_cite ltx_citemacro_citep">(Zari et al<span class="ltx_text">.</span>, <a href="#bib.bib141" title="" class="ltx_ref">2021</a>)</cite>. The attacker first collects information (e.g. parameter updates) from clients. Then, the attacker uses auxiliary dataset to train shadow models which can mimic the whole federated learning procedure, so that one attack model can be trained using the information collected from shadow models. Lastly, the attacker feeds the information collected from real clients into the attack model to perform membership inference attacks.</figcaption>
</figure>
<div id="S6.SS2.SSS1.p5" class="ltx_para">
<p id="S6.SS2.SSS1.p5.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citet">Melis et al<span class="ltx_text">.</span> (<a href="#bib.bib92" title="" class="ltx_ref">2019</a>)</cite> identified membership leakage when using FL for training a word embedding function, which is a deterministic function that maps each word to a high-dimensional vector. Given a training batch (composed of sentences), the gradients are all <math id="S6.SS2.SSS1.p5.1.m1.1" class="ltx_Math" alttext="0" display="inline"><semantics id="S6.SS2.SSS1.p5.1.m1.1a"><mn id="S6.SS2.SSS1.p5.1.m1.1.1" xref="S6.SS2.SSS1.p5.1.m1.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="S6.SS2.SSS1.p5.1.m1.1b"><cn type="integer" id="S6.SS2.SSS1.p5.1.m1.1.1.cmml" xref="S6.SS2.SSS1.p5.1.m1.1.1">0</cn></annotation-xml></semantics></math>’s for the words that do not appear in this batch, and thus the set of words used in the training sentences can be inferred. The attack assumes that the participants update the central server after each mini-batch, as opposed to updating after each training epoch.</p>
</div>
</section>
<section id="S6.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">6.2.2. </span>Without access to any training data.</h4>

<div id="S6.SS2.SSS2.p1" class="ltx_para">
<p id="S6.SS2.SSS2.p1.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citet">Li et al<span class="ltx_text">.</span> (<a href="#bib.bib80" title="" class="ltx_ref">2022a</a>)</cite> proposed a novel membership inference attack specifically against FL <span id="S6.SS2.SSS2.p1.1.1" class="ltx_text ltx_font_italic">without</span> requiring access to private training data. The key insight is that large overparameterized neural network models usually generalize well and the gradients of large overparameterized neural network models statistically behave like high-dimensional independent isotropic random vectors (shown in Figure <a href="#S6.F6" title="Figure 6 ‣ 6.2.2. Without access to any training data. ‣ 6.2. Membership Inference Attacks ‣ 6. Privacy Attacks ‣ Federated Learning Privacy: Attacks, Defenses, Applications, and Policy Landscape — A Survey" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>). Thus, they reformulated the task of membership inference attacks under FL as the following question: given a set of (largely unknown) orthogonal vectors, which is the parameter update coming from a particular client, does this set contain the gradients of a specific target instance?</p>
</div>
<figure id="S6.F6" class="ltx_figure"><img src="/html/2405.03636/assets/x8.png" id="S6.F6.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="121" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6. </span>Representative example of orthogonality of gradients of distinct instances (at epoch 250, AlexNet, CIFAR-100 dataset) from  <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a href="#bib.bib80" title="" class="ltx_ref">2022a</a>)</cite>: (a) Distribution of cosine similarity (cosim) between gradients of two distinct member instances. (b) Distribution of cosine similarity between gradients of one member instance and one non-member instance. (c) Distribution of cosine similarity between gradients of two distinct non-member instances. </figcaption>
</figure>
<div id="S6.SS2.SSS2.p2" class="ltx_para">
<p id="S6.SS2.SSS2.p2.1" class="ltx_p">One straightforward solution to this question is to test the cosine similarity between the gradients of the target instance and the parameter update from one particular client. If the cosine similarity is significantly higher than <math id="S6.SS2.SSS2.p2.1.m1.1" class="ltx_Math" alttext="0" display="inline"><semantics id="S6.SS2.SSS2.p2.1.m1.1a"><mn id="S6.SS2.SSS2.p2.1.m1.1.1" xref="S6.SS2.SSS2.p2.1.m1.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="S6.SS2.SSS2.p2.1.m1.1b"><cn type="integer" id="S6.SS2.SSS2.p2.1.m1.1.1.cmml" xref="S6.SS2.SSS2.p2.1.m1.1.1">0</cn></annotation-xml></semantics></math>, then the attacker can claim with high confidence that this target instance is used in the training of this particular client, hence successful membership inference.</p>
</div>
<div id="S6.SS2.SSS2.p3" class="ltx_para">
<p id="S6.SS2.SSS2.p3.17" class="ltx_p">From another perspective, if <math id="S6.SS2.SSS2.p3.1.m1.1" class="ltx_Math" alttext="S=a+b+c" display="inline"><semantics id="S6.SS2.SSS2.p3.1.m1.1a"><mrow id="S6.SS2.SSS2.p3.1.m1.1.1" xref="S6.SS2.SSS2.p3.1.m1.1.1.cmml"><mi id="S6.SS2.SSS2.p3.1.m1.1.1.2" xref="S6.SS2.SSS2.p3.1.m1.1.1.2.cmml">S</mi><mo id="S6.SS2.SSS2.p3.1.m1.1.1.1" xref="S6.SS2.SSS2.p3.1.m1.1.1.1.cmml">=</mo><mrow id="S6.SS2.SSS2.p3.1.m1.1.1.3" xref="S6.SS2.SSS2.p3.1.m1.1.1.3.cmml"><mi id="S6.SS2.SSS2.p3.1.m1.1.1.3.2" xref="S6.SS2.SSS2.p3.1.m1.1.1.3.2.cmml">a</mi><mo id="S6.SS2.SSS2.p3.1.m1.1.1.3.1" xref="S6.SS2.SSS2.p3.1.m1.1.1.3.1.cmml">+</mo><mi id="S6.SS2.SSS2.p3.1.m1.1.1.3.3" xref="S6.SS2.SSS2.p3.1.m1.1.1.3.3.cmml">b</mi><mo id="S6.SS2.SSS2.p3.1.m1.1.1.3.1a" xref="S6.SS2.SSS2.p3.1.m1.1.1.3.1.cmml">+</mo><mi id="S6.SS2.SSS2.p3.1.m1.1.1.3.4" xref="S6.SS2.SSS2.p3.1.m1.1.1.3.4.cmml">c</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S6.SS2.SSS2.p3.1.m1.1b"><apply id="S6.SS2.SSS2.p3.1.m1.1.1.cmml" xref="S6.SS2.SSS2.p3.1.m1.1.1"><eq id="S6.SS2.SSS2.p3.1.m1.1.1.1.cmml" xref="S6.SS2.SSS2.p3.1.m1.1.1.1"></eq><ci id="S6.SS2.SSS2.p3.1.m1.1.1.2.cmml" xref="S6.SS2.SSS2.p3.1.m1.1.1.2">𝑆</ci><apply id="S6.SS2.SSS2.p3.1.m1.1.1.3.cmml" xref="S6.SS2.SSS2.p3.1.m1.1.1.3"><plus id="S6.SS2.SSS2.p3.1.m1.1.1.3.1.cmml" xref="S6.SS2.SSS2.p3.1.m1.1.1.3.1"></plus><ci id="S6.SS2.SSS2.p3.1.m1.1.1.3.2.cmml" xref="S6.SS2.SSS2.p3.1.m1.1.1.3.2">𝑎</ci><ci id="S6.SS2.SSS2.p3.1.m1.1.1.3.3.cmml" xref="S6.SS2.SSS2.p3.1.m1.1.1.3.3">𝑏</ci><ci id="S6.SS2.SSS2.p3.1.m1.1.1.3.4.cmml" xref="S6.SS2.SSS2.p3.1.m1.1.1.3.4">𝑐</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.SSS2.p3.1.m1.1c">S=a+b+c</annotation></semantics></math> is a sum of orthogonal vectors, then <math id="S6.SS2.SSS2.p3.2.m2.3" class="ltx_Math" alttext="\|S\|^{2}_{2}-\|S-a\|^{2}_{2}=\|a\|^{2}_{2}" display="inline"><semantics id="S6.SS2.SSS2.p3.2.m2.3a"><mrow id="S6.SS2.SSS2.p3.2.m2.3.3" xref="S6.SS2.SSS2.p3.2.m2.3.3.cmml"><mrow id="S6.SS2.SSS2.p3.2.m2.3.3.1" xref="S6.SS2.SSS2.p3.2.m2.3.3.1.cmml"><msubsup id="S6.SS2.SSS2.p3.2.m2.3.3.1.3" xref="S6.SS2.SSS2.p3.2.m2.3.3.1.3.cmml"><mrow id="S6.SS2.SSS2.p3.2.m2.3.3.1.3.2.2.2" xref="S6.SS2.SSS2.p3.2.m2.3.3.1.3.2.2.1.cmml"><mo stretchy="false" id="S6.SS2.SSS2.p3.2.m2.3.3.1.3.2.2.2.1" xref="S6.SS2.SSS2.p3.2.m2.3.3.1.3.2.2.1.1.cmml">‖</mo><mi id="S6.SS2.SSS2.p3.2.m2.1.1" xref="S6.SS2.SSS2.p3.2.m2.1.1.cmml">S</mi><mo stretchy="false" id="S6.SS2.SSS2.p3.2.m2.3.3.1.3.2.2.2.2" xref="S6.SS2.SSS2.p3.2.m2.3.3.1.3.2.2.1.1.cmml">‖</mo></mrow><mn id="S6.SS2.SSS2.p3.2.m2.3.3.1.3.3" xref="S6.SS2.SSS2.p3.2.m2.3.3.1.3.3.cmml">2</mn><mn id="S6.SS2.SSS2.p3.2.m2.3.3.1.3.2.3" xref="S6.SS2.SSS2.p3.2.m2.3.3.1.3.2.3.cmml">2</mn></msubsup><mo id="S6.SS2.SSS2.p3.2.m2.3.3.1.2" xref="S6.SS2.SSS2.p3.2.m2.3.3.1.2.cmml">−</mo><msubsup id="S6.SS2.SSS2.p3.2.m2.3.3.1.1" xref="S6.SS2.SSS2.p3.2.m2.3.3.1.1.cmml"><mrow id="S6.SS2.SSS2.p3.2.m2.3.3.1.1.1.1.1" xref="S6.SS2.SSS2.p3.2.m2.3.3.1.1.1.1.2.cmml"><mo stretchy="false" id="S6.SS2.SSS2.p3.2.m2.3.3.1.1.1.1.1.2" xref="S6.SS2.SSS2.p3.2.m2.3.3.1.1.1.1.2.1.cmml">‖</mo><mrow id="S6.SS2.SSS2.p3.2.m2.3.3.1.1.1.1.1.1" xref="S6.SS2.SSS2.p3.2.m2.3.3.1.1.1.1.1.1.cmml"><mi id="S6.SS2.SSS2.p3.2.m2.3.3.1.1.1.1.1.1.2" xref="S6.SS2.SSS2.p3.2.m2.3.3.1.1.1.1.1.1.2.cmml">S</mi><mo id="S6.SS2.SSS2.p3.2.m2.3.3.1.1.1.1.1.1.1" xref="S6.SS2.SSS2.p3.2.m2.3.3.1.1.1.1.1.1.1.cmml">−</mo><mi id="S6.SS2.SSS2.p3.2.m2.3.3.1.1.1.1.1.1.3" xref="S6.SS2.SSS2.p3.2.m2.3.3.1.1.1.1.1.1.3.cmml">a</mi></mrow><mo stretchy="false" id="S6.SS2.SSS2.p3.2.m2.3.3.1.1.1.1.1.3" xref="S6.SS2.SSS2.p3.2.m2.3.3.1.1.1.1.2.1.cmml">‖</mo></mrow><mn id="S6.SS2.SSS2.p3.2.m2.3.3.1.1.3" xref="S6.SS2.SSS2.p3.2.m2.3.3.1.1.3.cmml">2</mn><mn id="S6.SS2.SSS2.p3.2.m2.3.3.1.1.1.3" xref="S6.SS2.SSS2.p3.2.m2.3.3.1.1.1.3.cmml">2</mn></msubsup></mrow><mo id="S6.SS2.SSS2.p3.2.m2.3.3.2" xref="S6.SS2.SSS2.p3.2.m2.3.3.2.cmml">=</mo><msubsup id="S6.SS2.SSS2.p3.2.m2.3.3.3" xref="S6.SS2.SSS2.p3.2.m2.3.3.3.cmml"><mrow id="S6.SS2.SSS2.p3.2.m2.3.3.3.2.2.2" xref="S6.SS2.SSS2.p3.2.m2.3.3.3.2.2.1.cmml"><mo stretchy="false" id="S6.SS2.SSS2.p3.2.m2.3.3.3.2.2.2.1" xref="S6.SS2.SSS2.p3.2.m2.3.3.3.2.2.1.1.cmml">‖</mo><mi id="S6.SS2.SSS2.p3.2.m2.2.2" xref="S6.SS2.SSS2.p3.2.m2.2.2.cmml">a</mi><mo stretchy="false" id="S6.SS2.SSS2.p3.2.m2.3.3.3.2.2.2.2" xref="S6.SS2.SSS2.p3.2.m2.3.3.3.2.2.1.1.cmml">‖</mo></mrow><mn id="S6.SS2.SSS2.p3.2.m2.3.3.3.3" xref="S6.SS2.SSS2.p3.2.m2.3.3.3.3.cmml">2</mn><mn id="S6.SS2.SSS2.p3.2.m2.3.3.3.2.3" xref="S6.SS2.SSS2.p3.2.m2.3.3.3.2.3.cmml">2</mn></msubsup></mrow><annotation-xml encoding="MathML-Content" id="S6.SS2.SSS2.p3.2.m2.3b"><apply id="S6.SS2.SSS2.p3.2.m2.3.3.cmml" xref="S6.SS2.SSS2.p3.2.m2.3.3"><eq id="S6.SS2.SSS2.p3.2.m2.3.3.2.cmml" xref="S6.SS2.SSS2.p3.2.m2.3.3.2"></eq><apply id="S6.SS2.SSS2.p3.2.m2.3.3.1.cmml" xref="S6.SS2.SSS2.p3.2.m2.3.3.1"><minus id="S6.SS2.SSS2.p3.2.m2.3.3.1.2.cmml" xref="S6.SS2.SSS2.p3.2.m2.3.3.1.2"></minus><apply id="S6.SS2.SSS2.p3.2.m2.3.3.1.3.cmml" xref="S6.SS2.SSS2.p3.2.m2.3.3.1.3"><csymbol cd="ambiguous" id="S6.SS2.SSS2.p3.2.m2.3.3.1.3.1.cmml" xref="S6.SS2.SSS2.p3.2.m2.3.3.1.3">subscript</csymbol><apply id="S6.SS2.SSS2.p3.2.m2.3.3.1.3.2.cmml" xref="S6.SS2.SSS2.p3.2.m2.3.3.1.3"><csymbol cd="ambiguous" id="S6.SS2.SSS2.p3.2.m2.3.3.1.3.2.1.cmml" xref="S6.SS2.SSS2.p3.2.m2.3.3.1.3">superscript</csymbol><apply id="S6.SS2.SSS2.p3.2.m2.3.3.1.3.2.2.1.cmml" xref="S6.SS2.SSS2.p3.2.m2.3.3.1.3.2.2.2"><csymbol cd="latexml" id="S6.SS2.SSS2.p3.2.m2.3.3.1.3.2.2.1.1.cmml" xref="S6.SS2.SSS2.p3.2.m2.3.3.1.3.2.2.2.1">norm</csymbol><ci id="S6.SS2.SSS2.p3.2.m2.1.1.cmml" xref="S6.SS2.SSS2.p3.2.m2.1.1">𝑆</ci></apply><cn type="integer" id="S6.SS2.SSS2.p3.2.m2.3.3.1.3.2.3.cmml" xref="S6.SS2.SSS2.p3.2.m2.3.3.1.3.2.3">2</cn></apply><cn type="integer" id="S6.SS2.SSS2.p3.2.m2.3.3.1.3.3.cmml" xref="S6.SS2.SSS2.p3.2.m2.3.3.1.3.3">2</cn></apply><apply id="S6.SS2.SSS2.p3.2.m2.3.3.1.1.cmml" xref="S6.SS2.SSS2.p3.2.m2.3.3.1.1"><csymbol cd="ambiguous" id="S6.SS2.SSS2.p3.2.m2.3.3.1.1.2.cmml" xref="S6.SS2.SSS2.p3.2.m2.3.3.1.1">subscript</csymbol><apply id="S6.SS2.SSS2.p3.2.m2.3.3.1.1.1.cmml" xref="S6.SS2.SSS2.p3.2.m2.3.3.1.1"><csymbol cd="ambiguous" id="S6.SS2.SSS2.p3.2.m2.3.3.1.1.1.2.cmml" xref="S6.SS2.SSS2.p3.2.m2.3.3.1.1">superscript</csymbol><apply id="S6.SS2.SSS2.p3.2.m2.3.3.1.1.1.1.2.cmml" xref="S6.SS2.SSS2.p3.2.m2.3.3.1.1.1.1.1"><csymbol cd="latexml" id="S6.SS2.SSS2.p3.2.m2.3.3.1.1.1.1.2.1.cmml" xref="S6.SS2.SSS2.p3.2.m2.3.3.1.1.1.1.1.2">norm</csymbol><apply id="S6.SS2.SSS2.p3.2.m2.3.3.1.1.1.1.1.1.cmml" xref="S6.SS2.SSS2.p3.2.m2.3.3.1.1.1.1.1.1"><minus id="S6.SS2.SSS2.p3.2.m2.3.3.1.1.1.1.1.1.1.cmml" xref="S6.SS2.SSS2.p3.2.m2.3.3.1.1.1.1.1.1.1"></minus><ci id="S6.SS2.SSS2.p3.2.m2.3.3.1.1.1.1.1.1.2.cmml" xref="S6.SS2.SSS2.p3.2.m2.3.3.1.1.1.1.1.1.2">𝑆</ci><ci id="S6.SS2.SSS2.p3.2.m2.3.3.1.1.1.1.1.1.3.cmml" xref="S6.SS2.SSS2.p3.2.m2.3.3.1.1.1.1.1.1.3">𝑎</ci></apply></apply><cn type="integer" id="S6.SS2.SSS2.p3.2.m2.3.3.1.1.1.3.cmml" xref="S6.SS2.SSS2.p3.2.m2.3.3.1.1.1.3">2</cn></apply><cn type="integer" id="S6.SS2.SSS2.p3.2.m2.3.3.1.1.3.cmml" xref="S6.SS2.SSS2.p3.2.m2.3.3.1.1.3">2</cn></apply></apply><apply id="S6.SS2.SSS2.p3.2.m2.3.3.3.cmml" xref="S6.SS2.SSS2.p3.2.m2.3.3.3"><csymbol cd="ambiguous" id="S6.SS2.SSS2.p3.2.m2.3.3.3.1.cmml" xref="S6.SS2.SSS2.p3.2.m2.3.3.3">subscript</csymbol><apply id="S6.SS2.SSS2.p3.2.m2.3.3.3.2.cmml" xref="S6.SS2.SSS2.p3.2.m2.3.3.3"><csymbol cd="ambiguous" id="S6.SS2.SSS2.p3.2.m2.3.3.3.2.1.cmml" xref="S6.SS2.SSS2.p3.2.m2.3.3.3">superscript</csymbol><apply id="S6.SS2.SSS2.p3.2.m2.3.3.3.2.2.1.cmml" xref="S6.SS2.SSS2.p3.2.m2.3.3.3.2.2.2"><csymbol cd="latexml" id="S6.SS2.SSS2.p3.2.m2.3.3.3.2.2.1.1.cmml" xref="S6.SS2.SSS2.p3.2.m2.3.3.3.2.2.2.1">norm</csymbol><ci id="S6.SS2.SSS2.p3.2.m2.2.2.cmml" xref="S6.SS2.SSS2.p3.2.m2.2.2">𝑎</ci></apply><cn type="integer" id="S6.SS2.SSS2.p3.2.m2.3.3.3.2.3.cmml" xref="S6.SS2.SSS2.p3.2.m2.3.3.3.2.3">2</cn></apply><cn type="integer" id="S6.SS2.SSS2.p3.2.m2.3.3.3.3.cmml" xref="S6.SS2.SSS2.p3.2.m2.3.3.3.3">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.SSS2.p3.2.m2.3c">\|S\|^{2}_{2}-\|S-a\|^{2}_{2}=\|a\|^{2}_{2}</annotation></semantics></math>, otherwise for another vector <math id="S6.SS2.SSS2.p3.3.m3.1" class="ltx_Math" alttext="f" display="inline"><semantics id="S6.SS2.SSS2.p3.3.m3.1a"><mi id="S6.SS2.SSS2.p3.3.m3.1.1" xref="S6.SS2.SSS2.p3.3.m3.1.1.cmml">f</mi><annotation-xml encoding="MathML-Content" id="S6.SS2.SSS2.p3.3.m3.1b"><ci id="S6.SS2.SSS2.p3.3.m3.1.1.cmml" xref="S6.SS2.SSS2.p3.3.m3.1.1">𝑓</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.SSS2.p3.3.m3.1c">f</annotation></semantics></math> orthogonal to <math id="S6.SS2.SSS2.p3.4.m4.3" class="ltx_Math" alttext="a,b,c" display="inline"><semantics id="S6.SS2.SSS2.p3.4.m4.3a"><mrow id="S6.SS2.SSS2.p3.4.m4.3.4.2" xref="S6.SS2.SSS2.p3.4.m4.3.4.1.cmml"><mi id="S6.SS2.SSS2.p3.4.m4.1.1" xref="S6.SS2.SSS2.p3.4.m4.1.1.cmml">a</mi><mo id="S6.SS2.SSS2.p3.4.m4.3.4.2.1" xref="S6.SS2.SSS2.p3.4.m4.3.4.1.cmml">,</mo><mi id="S6.SS2.SSS2.p3.4.m4.2.2" xref="S6.SS2.SSS2.p3.4.m4.2.2.cmml">b</mi><mo id="S6.SS2.SSS2.p3.4.m4.3.4.2.2" xref="S6.SS2.SSS2.p3.4.m4.3.4.1.cmml">,</mo><mi id="S6.SS2.SSS2.p3.4.m4.3.3" xref="S6.SS2.SSS2.p3.4.m4.3.3.cmml">c</mi></mrow><annotation-xml encoding="MathML-Content" id="S6.SS2.SSS2.p3.4.m4.3b"><list id="S6.SS2.SSS2.p3.4.m4.3.4.1.cmml" xref="S6.SS2.SSS2.p3.4.m4.3.4.2"><ci id="S6.SS2.SSS2.p3.4.m4.1.1.cmml" xref="S6.SS2.SSS2.p3.4.m4.1.1">𝑎</ci><ci id="S6.SS2.SSS2.p3.4.m4.2.2.cmml" xref="S6.SS2.SSS2.p3.4.m4.2.2">𝑏</ci><ci id="S6.SS2.SSS2.p3.4.m4.3.3.cmml" xref="S6.SS2.SSS2.p3.4.m4.3.3">𝑐</ci></list></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.SSS2.p3.4.m4.3c">a,b,c</annotation></semantics></math> we have <math id="S6.SS2.SSS2.p3.5.m5.3" class="ltx_Math" alttext="\|S\|^{2}_{2}-\|S-f\|^{2}_{2}=-\|f\|^{2}_{2}" display="inline"><semantics id="S6.SS2.SSS2.p3.5.m5.3a"><mrow id="S6.SS2.SSS2.p3.5.m5.3.3" xref="S6.SS2.SSS2.p3.5.m5.3.3.cmml"><mrow id="S6.SS2.SSS2.p3.5.m5.3.3.1" xref="S6.SS2.SSS2.p3.5.m5.3.3.1.cmml"><msubsup id="S6.SS2.SSS2.p3.5.m5.3.3.1.3" xref="S6.SS2.SSS2.p3.5.m5.3.3.1.3.cmml"><mrow id="S6.SS2.SSS2.p3.5.m5.3.3.1.3.2.2.2" xref="S6.SS2.SSS2.p3.5.m5.3.3.1.3.2.2.1.cmml"><mo stretchy="false" id="S6.SS2.SSS2.p3.5.m5.3.3.1.3.2.2.2.1" xref="S6.SS2.SSS2.p3.5.m5.3.3.1.3.2.2.1.1.cmml">‖</mo><mi id="S6.SS2.SSS2.p3.5.m5.1.1" xref="S6.SS2.SSS2.p3.5.m5.1.1.cmml">S</mi><mo stretchy="false" id="S6.SS2.SSS2.p3.5.m5.3.3.1.3.2.2.2.2" xref="S6.SS2.SSS2.p3.5.m5.3.3.1.3.2.2.1.1.cmml">‖</mo></mrow><mn id="S6.SS2.SSS2.p3.5.m5.3.3.1.3.3" xref="S6.SS2.SSS2.p3.5.m5.3.3.1.3.3.cmml">2</mn><mn id="S6.SS2.SSS2.p3.5.m5.3.3.1.3.2.3" xref="S6.SS2.SSS2.p3.5.m5.3.3.1.3.2.3.cmml">2</mn></msubsup><mo id="S6.SS2.SSS2.p3.5.m5.3.3.1.2" xref="S6.SS2.SSS2.p3.5.m5.3.3.1.2.cmml">−</mo><msubsup id="S6.SS2.SSS2.p3.5.m5.3.3.1.1" xref="S6.SS2.SSS2.p3.5.m5.3.3.1.1.cmml"><mrow id="S6.SS2.SSS2.p3.5.m5.3.3.1.1.1.1.1" xref="S6.SS2.SSS2.p3.5.m5.3.3.1.1.1.1.2.cmml"><mo stretchy="false" id="S6.SS2.SSS2.p3.5.m5.3.3.1.1.1.1.1.2" xref="S6.SS2.SSS2.p3.5.m5.3.3.1.1.1.1.2.1.cmml">‖</mo><mrow id="S6.SS2.SSS2.p3.5.m5.3.3.1.1.1.1.1.1" xref="S6.SS2.SSS2.p3.5.m5.3.3.1.1.1.1.1.1.cmml"><mi id="S6.SS2.SSS2.p3.5.m5.3.3.1.1.1.1.1.1.2" xref="S6.SS2.SSS2.p3.5.m5.3.3.1.1.1.1.1.1.2.cmml">S</mi><mo id="S6.SS2.SSS2.p3.5.m5.3.3.1.1.1.1.1.1.1" xref="S6.SS2.SSS2.p3.5.m5.3.3.1.1.1.1.1.1.1.cmml">−</mo><mi id="S6.SS2.SSS2.p3.5.m5.3.3.1.1.1.1.1.1.3" xref="S6.SS2.SSS2.p3.5.m5.3.3.1.1.1.1.1.1.3.cmml">f</mi></mrow><mo stretchy="false" id="S6.SS2.SSS2.p3.5.m5.3.3.1.1.1.1.1.3" xref="S6.SS2.SSS2.p3.5.m5.3.3.1.1.1.1.2.1.cmml">‖</mo></mrow><mn id="S6.SS2.SSS2.p3.5.m5.3.3.1.1.3" xref="S6.SS2.SSS2.p3.5.m5.3.3.1.1.3.cmml">2</mn><mn id="S6.SS2.SSS2.p3.5.m5.3.3.1.1.1.3" xref="S6.SS2.SSS2.p3.5.m5.3.3.1.1.1.3.cmml">2</mn></msubsup></mrow><mo id="S6.SS2.SSS2.p3.5.m5.3.3.2" xref="S6.SS2.SSS2.p3.5.m5.3.3.2.cmml">=</mo><mrow id="S6.SS2.SSS2.p3.5.m5.3.3.3" xref="S6.SS2.SSS2.p3.5.m5.3.3.3.cmml"><mo id="S6.SS2.SSS2.p3.5.m5.3.3.3a" xref="S6.SS2.SSS2.p3.5.m5.3.3.3.cmml">−</mo><msubsup id="S6.SS2.SSS2.p3.5.m5.3.3.3.2" xref="S6.SS2.SSS2.p3.5.m5.3.3.3.2.cmml"><mrow id="S6.SS2.SSS2.p3.5.m5.3.3.3.2.2.2.2" xref="S6.SS2.SSS2.p3.5.m5.3.3.3.2.2.2.1.cmml"><mo stretchy="false" id="S6.SS2.SSS2.p3.5.m5.3.3.3.2.2.2.2.1" xref="S6.SS2.SSS2.p3.5.m5.3.3.3.2.2.2.1.1.cmml">‖</mo><mi id="S6.SS2.SSS2.p3.5.m5.2.2" xref="S6.SS2.SSS2.p3.5.m5.2.2.cmml">f</mi><mo stretchy="false" id="S6.SS2.SSS2.p3.5.m5.3.3.3.2.2.2.2.2" xref="S6.SS2.SSS2.p3.5.m5.3.3.3.2.2.2.1.1.cmml">‖</mo></mrow><mn id="S6.SS2.SSS2.p3.5.m5.3.3.3.2.3" xref="S6.SS2.SSS2.p3.5.m5.3.3.3.2.3.cmml">2</mn><mn id="S6.SS2.SSS2.p3.5.m5.3.3.3.2.2.3" xref="S6.SS2.SSS2.p3.5.m5.3.3.3.2.2.3.cmml">2</mn></msubsup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S6.SS2.SSS2.p3.5.m5.3b"><apply id="S6.SS2.SSS2.p3.5.m5.3.3.cmml" xref="S6.SS2.SSS2.p3.5.m5.3.3"><eq id="S6.SS2.SSS2.p3.5.m5.3.3.2.cmml" xref="S6.SS2.SSS2.p3.5.m5.3.3.2"></eq><apply id="S6.SS2.SSS2.p3.5.m5.3.3.1.cmml" xref="S6.SS2.SSS2.p3.5.m5.3.3.1"><minus id="S6.SS2.SSS2.p3.5.m5.3.3.1.2.cmml" xref="S6.SS2.SSS2.p3.5.m5.3.3.1.2"></minus><apply id="S6.SS2.SSS2.p3.5.m5.3.3.1.3.cmml" xref="S6.SS2.SSS2.p3.5.m5.3.3.1.3"><csymbol cd="ambiguous" id="S6.SS2.SSS2.p3.5.m5.3.3.1.3.1.cmml" xref="S6.SS2.SSS2.p3.5.m5.3.3.1.3">subscript</csymbol><apply id="S6.SS2.SSS2.p3.5.m5.3.3.1.3.2.cmml" xref="S6.SS2.SSS2.p3.5.m5.3.3.1.3"><csymbol cd="ambiguous" id="S6.SS2.SSS2.p3.5.m5.3.3.1.3.2.1.cmml" xref="S6.SS2.SSS2.p3.5.m5.3.3.1.3">superscript</csymbol><apply id="S6.SS2.SSS2.p3.5.m5.3.3.1.3.2.2.1.cmml" xref="S6.SS2.SSS2.p3.5.m5.3.3.1.3.2.2.2"><csymbol cd="latexml" id="S6.SS2.SSS2.p3.5.m5.3.3.1.3.2.2.1.1.cmml" xref="S6.SS2.SSS2.p3.5.m5.3.3.1.3.2.2.2.1">norm</csymbol><ci id="S6.SS2.SSS2.p3.5.m5.1.1.cmml" xref="S6.SS2.SSS2.p3.5.m5.1.1">𝑆</ci></apply><cn type="integer" id="S6.SS2.SSS2.p3.5.m5.3.3.1.3.2.3.cmml" xref="S6.SS2.SSS2.p3.5.m5.3.3.1.3.2.3">2</cn></apply><cn type="integer" id="S6.SS2.SSS2.p3.5.m5.3.3.1.3.3.cmml" xref="S6.SS2.SSS2.p3.5.m5.3.3.1.3.3">2</cn></apply><apply id="S6.SS2.SSS2.p3.5.m5.3.3.1.1.cmml" xref="S6.SS2.SSS2.p3.5.m5.3.3.1.1"><csymbol cd="ambiguous" id="S6.SS2.SSS2.p3.5.m5.3.3.1.1.2.cmml" xref="S6.SS2.SSS2.p3.5.m5.3.3.1.1">subscript</csymbol><apply id="S6.SS2.SSS2.p3.5.m5.3.3.1.1.1.cmml" xref="S6.SS2.SSS2.p3.5.m5.3.3.1.1"><csymbol cd="ambiguous" id="S6.SS2.SSS2.p3.5.m5.3.3.1.1.1.2.cmml" xref="S6.SS2.SSS2.p3.5.m5.3.3.1.1">superscript</csymbol><apply id="S6.SS2.SSS2.p3.5.m5.3.3.1.1.1.1.2.cmml" xref="S6.SS2.SSS2.p3.5.m5.3.3.1.1.1.1.1"><csymbol cd="latexml" id="S6.SS2.SSS2.p3.5.m5.3.3.1.1.1.1.2.1.cmml" xref="S6.SS2.SSS2.p3.5.m5.3.3.1.1.1.1.1.2">norm</csymbol><apply id="S6.SS2.SSS2.p3.5.m5.3.3.1.1.1.1.1.1.cmml" xref="S6.SS2.SSS2.p3.5.m5.3.3.1.1.1.1.1.1"><minus id="S6.SS2.SSS2.p3.5.m5.3.3.1.1.1.1.1.1.1.cmml" xref="S6.SS2.SSS2.p3.5.m5.3.3.1.1.1.1.1.1.1"></minus><ci id="S6.SS2.SSS2.p3.5.m5.3.3.1.1.1.1.1.1.2.cmml" xref="S6.SS2.SSS2.p3.5.m5.3.3.1.1.1.1.1.1.2">𝑆</ci><ci id="S6.SS2.SSS2.p3.5.m5.3.3.1.1.1.1.1.1.3.cmml" xref="S6.SS2.SSS2.p3.5.m5.3.3.1.1.1.1.1.1.3">𝑓</ci></apply></apply><cn type="integer" id="S6.SS2.SSS2.p3.5.m5.3.3.1.1.1.3.cmml" xref="S6.SS2.SSS2.p3.5.m5.3.3.1.1.1.3">2</cn></apply><cn type="integer" id="S6.SS2.SSS2.p3.5.m5.3.3.1.1.3.cmml" xref="S6.SS2.SSS2.p3.5.m5.3.3.1.1.3">2</cn></apply></apply><apply id="S6.SS2.SSS2.p3.5.m5.3.3.3.cmml" xref="S6.SS2.SSS2.p3.5.m5.3.3.3"><minus id="S6.SS2.SSS2.p3.5.m5.3.3.3.1.cmml" xref="S6.SS2.SSS2.p3.5.m5.3.3.3"></minus><apply id="S6.SS2.SSS2.p3.5.m5.3.3.3.2.cmml" xref="S6.SS2.SSS2.p3.5.m5.3.3.3.2"><csymbol cd="ambiguous" id="S6.SS2.SSS2.p3.5.m5.3.3.3.2.1.cmml" xref="S6.SS2.SSS2.p3.5.m5.3.3.3.2">subscript</csymbol><apply id="S6.SS2.SSS2.p3.5.m5.3.3.3.2.2.cmml" xref="S6.SS2.SSS2.p3.5.m5.3.3.3.2"><csymbol cd="ambiguous" id="S6.SS2.SSS2.p3.5.m5.3.3.3.2.2.1.cmml" xref="S6.SS2.SSS2.p3.5.m5.3.3.3.2">superscript</csymbol><apply id="S6.SS2.SSS2.p3.5.m5.3.3.3.2.2.2.1.cmml" xref="S6.SS2.SSS2.p3.5.m5.3.3.3.2.2.2.2"><csymbol cd="latexml" id="S6.SS2.SSS2.p3.5.m5.3.3.3.2.2.2.1.1.cmml" xref="S6.SS2.SSS2.p3.5.m5.3.3.3.2.2.2.2.1">norm</csymbol><ci id="S6.SS2.SSS2.p3.5.m5.2.2.cmml" xref="S6.SS2.SSS2.p3.5.m5.2.2">𝑓</ci></apply><cn type="integer" id="S6.SS2.SSS2.p3.5.m5.3.3.3.2.2.3.cmml" xref="S6.SS2.SSS2.p3.5.m5.3.3.3.2.2.3">2</cn></apply><cn type="integer" id="S6.SS2.SSS2.p3.5.m5.3.3.3.2.3.cmml" xref="S6.SS2.SSS2.p3.5.m5.3.3.3.2.3">2</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.SSS2.p3.5.m5.3c">\|S\|^{2}_{2}-\|S-f\|^{2}_{2}=-\|f\|^{2}_{2}</annotation></semantics></math>.
These equations are easy to understand if we rotate the (orthogonal) vectors to form a canonical orthogonal basis <math id="S6.SS2.SSS2.p3.6.m6.12" class="ltx_Math" alttext="(a^{\prime},0,0,\ldots),(0,b^{\prime},0,\ldots),(0,0,c^{\prime},\ldots)" display="inline"><semantics id="S6.SS2.SSS2.p3.6.m6.12a"><mrow id="S6.SS2.SSS2.p3.6.m6.12.12.3" xref="S6.SS2.SSS2.p3.6.m6.12.12.4.cmml"><mrow id="S6.SS2.SSS2.p3.6.m6.10.10.1.1.1" xref="S6.SS2.SSS2.p3.6.m6.10.10.1.1.2.cmml"><mo stretchy="false" id="S6.SS2.SSS2.p3.6.m6.10.10.1.1.1.2" xref="S6.SS2.SSS2.p3.6.m6.10.10.1.1.2.cmml">(</mo><msup id="S6.SS2.SSS2.p3.6.m6.10.10.1.1.1.1" xref="S6.SS2.SSS2.p3.6.m6.10.10.1.1.1.1.cmml"><mi id="S6.SS2.SSS2.p3.6.m6.10.10.1.1.1.1.2" xref="S6.SS2.SSS2.p3.6.m6.10.10.1.1.1.1.2.cmml">a</mi><mo id="S6.SS2.SSS2.p3.6.m6.10.10.1.1.1.1.3" xref="S6.SS2.SSS2.p3.6.m6.10.10.1.1.1.1.3.cmml">′</mo></msup><mo id="S6.SS2.SSS2.p3.6.m6.10.10.1.1.1.3" xref="S6.SS2.SSS2.p3.6.m6.10.10.1.1.2.cmml">,</mo><mn id="S6.SS2.SSS2.p3.6.m6.1.1" xref="S6.SS2.SSS2.p3.6.m6.1.1.cmml">0</mn><mo id="S6.SS2.SSS2.p3.6.m6.10.10.1.1.1.4" xref="S6.SS2.SSS2.p3.6.m6.10.10.1.1.2.cmml">,</mo><mn id="S6.SS2.SSS2.p3.6.m6.2.2" xref="S6.SS2.SSS2.p3.6.m6.2.2.cmml">0</mn><mo id="S6.SS2.SSS2.p3.6.m6.10.10.1.1.1.5" xref="S6.SS2.SSS2.p3.6.m6.10.10.1.1.2.cmml">,</mo><mi mathvariant="normal" id="S6.SS2.SSS2.p3.6.m6.3.3" xref="S6.SS2.SSS2.p3.6.m6.3.3.cmml">…</mi><mo stretchy="false" id="S6.SS2.SSS2.p3.6.m6.10.10.1.1.1.6" xref="S6.SS2.SSS2.p3.6.m6.10.10.1.1.2.cmml">)</mo></mrow><mo id="S6.SS2.SSS2.p3.6.m6.12.12.3.4" xref="S6.SS2.SSS2.p3.6.m6.12.12.4.cmml">,</mo><mrow id="S6.SS2.SSS2.p3.6.m6.11.11.2.2.1" xref="S6.SS2.SSS2.p3.6.m6.11.11.2.2.2.cmml"><mo stretchy="false" id="S6.SS2.SSS2.p3.6.m6.11.11.2.2.1.2" xref="S6.SS2.SSS2.p3.6.m6.11.11.2.2.2.cmml">(</mo><mn id="S6.SS2.SSS2.p3.6.m6.4.4" xref="S6.SS2.SSS2.p3.6.m6.4.4.cmml">0</mn><mo id="S6.SS2.SSS2.p3.6.m6.11.11.2.2.1.3" xref="S6.SS2.SSS2.p3.6.m6.11.11.2.2.2.cmml">,</mo><msup id="S6.SS2.SSS2.p3.6.m6.11.11.2.2.1.1" xref="S6.SS2.SSS2.p3.6.m6.11.11.2.2.1.1.cmml"><mi id="S6.SS2.SSS2.p3.6.m6.11.11.2.2.1.1.2" xref="S6.SS2.SSS2.p3.6.m6.11.11.2.2.1.1.2.cmml">b</mi><mo id="S6.SS2.SSS2.p3.6.m6.11.11.2.2.1.1.3" xref="S6.SS2.SSS2.p3.6.m6.11.11.2.2.1.1.3.cmml">′</mo></msup><mo id="S6.SS2.SSS2.p3.6.m6.11.11.2.2.1.4" xref="S6.SS2.SSS2.p3.6.m6.11.11.2.2.2.cmml">,</mo><mn id="S6.SS2.SSS2.p3.6.m6.5.5" xref="S6.SS2.SSS2.p3.6.m6.5.5.cmml">0</mn><mo id="S6.SS2.SSS2.p3.6.m6.11.11.2.2.1.5" xref="S6.SS2.SSS2.p3.6.m6.11.11.2.2.2.cmml">,</mo><mi mathvariant="normal" id="S6.SS2.SSS2.p3.6.m6.6.6" xref="S6.SS2.SSS2.p3.6.m6.6.6.cmml">…</mi><mo stretchy="false" id="S6.SS2.SSS2.p3.6.m6.11.11.2.2.1.6" xref="S6.SS2.SSS2.p3.6.m6.11.11.2.2.2.cmml">)</mo></mrow><mo id="S6.SS2.SSS2.p3.6.m6.12.12.3.5" xref="S6.SS2.SSS2.p3.6.m6.12.12.4.cmml">,</mo><mrow id="S6.SS2.SSS2.p3.6.m6.12.12.3.3.1" xref="S6.SS2.SSS2.p3.6.m6.12.12.3.3.2.cmml"><mo stretchy="false" id="S6.SS2.SSS2.p3.6.m6.12.12.3.3.1.2" xref="S6.SS2.SSS2.p3.6.m6.12.12.3.3.2.cmml">(</mo><mn id="S6.SS2.SSS2.p3.6.m6.7.7" xref="S6.SS2.SSS2.p3.6.m6.7.7.cmml">0</mn><mo id="S6.SS2.SSS2.p3.6.m6.12.12.3.3.1.3" xref="S6.SS2.SSS2.p3.6.m6.12.12.3.3.2.cmml">,</mo><mn id="S6.SS2.SSS2.p3.6.m6.8.8" xref="S6.SS2.SSS2.p3.6.m6.8.8.cmml">0</mn><mo id="S6.SS2.SSS2.p3.6.m6.12.12.3.3.1.4" xref="S6.SS2.SSS2.p3.6.m6.12.12.3.3.2.cmml">,</mo><msup id="S6.SS2.SSS2.p3.6.m6.12.12.3.3.1.1" xref="S6.SS2.SSS2.p3.6.m6.12.12.3.3.1.1.cmml"><mi id="S6.SS2.SSS2.p3.6.m6.12.12.3.3.1.1.2" xref="S6.SS2.SSS2.p3.6.m6.12.12.3.3.1.1.2.cmml">c</mi><mo id="S6.SS2.SSS2.p3.6.m6.12.12.3.3.1.1.3" xref="S6.SS2.SSS2.p3.6.m6.12.12.3.3.1.1.3.cmml">′</mo></msup><mo id="S6.SS2.SSS2.p3.6.m6.12.12.3.3.1.5" xref="S6.SS2.SSS2.p3.6.m6.12.12.3.3.2.cmml">,</mo><mi mathvariant="normal" id="S6.SS2.SSS2.p3.6.m6.9.9" xref="S6.SS2.SSS2.p3.6.m6.9.9.cmml">…</mi><mo stretchy="false" id="S6.SS2.SSS2.p3.6.m6.12.12.3.3.1.6" xref="S6.SS2.SSS2.p3.6.m6.12.12.3.3.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S6.SS2.SSS2.p3.6.m6.12b"><list id="S6.SS2.SSS2.p3.6.m6.12.12.4.cmml" xref="S6.SS2.SSS2.p3.6.m6.12.12.3"><vector id="S6.SS2.SSS2.p3.6.m6.10.10.1.1.2.cmml" xref="S6.SS2.SSS2.p3.6.m6.10.10.1.1.1"><apply id="S6.SS2.SSS2.p3.6.m6.10.10.1.1.1.1.cmml" xref="S6.SS2.SSS2.p3.6.m6.10.10.1.1.1.1"><csymbol cd="ambiguous" id="S6.SS2.SSS2.p3.6.m6.10.10.1.1.1.1.1.cmml" xref="S6.SS2.SSS2.p3.6.m6.10.10.1.1.1.1">superscript</csymbol><ci id="S6.SS2.SSS2.p3.6.m6.10.10.1.1.1.1.2.cmml" xref="S6.SS2.SSS2.p3.6.m6.10.10.1.1.1.1.2">𝑎</ci><ci id="S6.SS2.SSS2.p3.6.m6.10.10.1.1.1.1.3.cmml" xref="S6.SS2.SSS2.p3.6.m6.10.10.1.1.1.1.3">′</ci></apply><cn type="integer" id="S6.SS2.SSS2.p3.6.m6.1.1.cmml" xref="S6.SS2.SSS2.p3.6.m6.1.1">0</cn><cn type="integer" id="S6.SS2.SSS2.p3.6.m6.2.2.cmml" xref="S6.SS2.SSS2.p3.6.m6.2.2">0</cn><ci id="S6.SS2.SSS2.p3.6.m6.3.3.cmml" xref="S6.SS2.SSS2.p3.6.m6.3.3">…</ci></vector><vector id="S6.SS2.SSS2.p3.6.m6.11.11.2.2.2.cmml" xref="S6.SS2.SSS2.p3.6.m6.11.11.2.2.1"><cn type="integer" id="S6.SS2.SSS2.p3.6.m6.4.4.cmml" xref="S6.SS2.SSS2.p3.6.m6.4.4">0</cn><apply id="S6.SS2.SSS2.p3.6.m6.11.11.2.2.1.1.cmml" xref="S6.SS2.SSS2.p3.6.m6.11.11.2.2.1.1"><csymbol cd="ambiguous" id="S6.SS2.SSS2.p3.6.m6.11.11.2.2.1.1.1.cmml" xref="S6.SS2.SSS2.p3.6.m6.11.11.2.2.1.1">superscript</csymbol><ci id="S6.SS2.SSS2.p3.6.m6.11.11.2.2.1.1.2.cmml" xref="S6.SS2.SSS2.p3.6.m6.11.11.2.2.1.1.2">𝑏</ci><ci id="S6.SS2.SSS2.p3.6.m6.11.11.2.2.1.1.3.cmml" xref="S6.SS2.SSS2.p3.6.m6.11.11.2.2.1.1.3">′</ci></apply><cn type="integer" id="S6.SS2.SSS2.p3.6.m6.5.5.cmml" xref="S6.SS2.SSS2.p3.6.m6.5.5">0</cn><ci id="S6.SS2.SSS2.p3.6.m6.6.6.cmml" xref="S6.SS2.SSS2.p3.6.m6.6.6">…</ci></vector><vector id="S6.SS2.SSS2.p3.6.m6.12.12.3.3.2.cmml" xref="S6.SS2.SSS2.p3.6.m6.12.12.3.3.1"><cn type="integer" id="S6.SS2.SSS2.p3.6.m6.7.7.cmml" xref="S6.SS2.SSS2.p3.6.m6.7.7">0</cn><cn type="integer" id="S6.SS2.SSS2.p3.6.m6.8.8.cmml" xref="S6.SS2.SSS2.p3.6.m6.8.8">0</cn><apply id="S6.SS2.SSS2.p3.6.m6.12.12.3.3.1.1.cmml" xref="S6.SS2.SSS2.p3.6.m6.12.12.3.3.1.1"><csymbol cd="ambiguous" id="S6.SS2.SSS2.p3.6.m6.12.12.3.3.1.1.1.cmml" xref="S6.SS2.SSS2.p3.6.m6.12.12.3.3.1.1">superscript</csymbol><ci id="S6.SS2.SSS2.p3.6.m6.12.12.3.3.1.1.2.cmml" xref="S6.SS2.SSS2.p3.6.m6.12.12.3.3.1.1.2">𝑐</ci><ci id="S6.SS2.SSS2.p3.6.m6.12.12.3.3.1.1.3.cmml" xref="S6.SS2.SSS2.p3.6.m6.12.12.3.3.1.1.3">′</ci></apply><ci id="S6.SS2.SSS2.p3.6.m6.9.9.cmml" xref="S6.SS2.SSS2.p3.6.m6.9.9">…</ci></vector></list></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.SSS2.p3.6.m6.12c">(a^{\prime},0,0,\ldots),(0,b^{\prime},0,\ldots),(0,0,c^{\prime},\ldots)</annotation></semantics></math>, with <math id="S6.SS2.SSS2.p3.7.m7.4" class="ltx_Math" alttext="a^{\prime},b^{\prime},c^{\prime}\in\mathbb{R}\backslash\{0\}" display="inline"><semantics id="S6.SS2.SSS2.p3.7.m7.4a"><mrow id="S6.SS2.SSS2.p3.7.m7.4.4" xref="S6.SS2.SSS2.p3.7.m7.4.4.cmml"><mrow id="S6.SS2.SSS2.p3.7.m7.4.4.3.3" xref="S6.SS2.SSS2.p3.7.m7.4.4.3.4.cmml"><msup id="S6.SS2.SSS2.p3.7.m7.2.2.1.1.1" xref="S6.SS2.SSS2.p3.7.m7.2.2.1.1.1.cmml"><mi id="S6.SS2.SSS2.p3.7.m7.2.2.1.1.1.2" xref="S6.SS2.SSS2.p3.7.m7.2.2.1.1.1.2.cmml">a</mi><mo id="S6.SS2.SSS2.p3.7.m7.2.2.1.1.1.3" xref="S6.SS2.SSS2.p3.7.m7.2.2.1.1.1.3.cmml">′</mo></msup><mo id="S6.SS2.SSS2.p3.7.m7.4.4.3.3.4" xref="S6.SS2.SSS2.p3.7.m7.4.4.3.4.cmml">,</mo><msup id="S6.SS2.SSS2.p3.7.m7.3.3.2.2.2" xref="S6.SS2.SSS2.p3.7.m7.3.3.2.2.2.cmml"><mi id="S6.SS2.SSS2.p3.7.m7.3.3.2.2.2.2" xref="S6.SS2.SSS2.p3.7.m7.3.3.2.2.2.2.cmml">b</mi><mo id="S6.SS2.SSS2.p3.7.m7.3.3.2.2.2.3" xref="S6.SS2.SSS2.p3.7.m7.3.3.2.2.2.3.cmml">′</mo></msup><mo id="S6.SS2.SSS2.p3.7.m7.4.4.3.3.5" xref="S6.SS2.SSS2.p3.7.m7.4.4.3.4.cmml">,</mo><msup id="S6.SS2.SSS2.p3.7.m7.4.4.3.3.3" xref="S6.SS2.SSS2.p3.7.m7.4.4.3.3.3.cmml"><mi id="S6.SS2.SSS2.p3.7.m7.4.4.3.3.3.2" xref="S6.SS2.SSS2.p3.7.m7.4.4.3.3.3.2.cmml">c</mi><mo id="S6.SS2.SSS2.p3.7.m7.4.4.3.3.3.3" xref="S6.SS2.SSS2.p3.7.m7.4.4.3.3.3.3.cmml">′</mo></msup></mrow><mo id="S6.SS2.SSS2.p3.7.m7.4.4.4" xref="S6.SS2.SSS2.p3.7.m7.4.4.4.cmml">∈</mo><mrow id="S6.SS2.SSS2.p3.7.m7.4.4.5" xref="S6.SS2.SSS2.p3.7.m7.4.4.5.cmml"><mi id="S6.SS2.SSS2.p3.7.m7.4.4.5.2" xref="S6.SS2.SSS2.p3.7.m7.4.4.5.2.cmml">ℝ</mi><mo lspace="0.222em" rspace="0.222em" id="S6.SS2.SSS2.p3.7.m7.4.4.5.1" xref="S6.SS2.SSS2.p3.7.m7.4.4.5.1.cmml">\</mo><mrow id="S6.SS2.SSS2.p3.7.m7.4.4.5.3.2" xref="S6.SS2.SSS2.p3.7.m7.4.4.5.3.1.cmml"><mo stretchy="false" id="S6.SS2.SSS2.p3.7.m7.4.4.5.3.2.1" xref="S6.SS2.SSS2.p3.7.m7.4.4.5.3.1.cmml">{</mo><mn id="S6.SS2.SSS2.p3.7.m7.1.1" xref="S6.SS2.SSS2.p3.7.m7.1.1.cmml">0</mn><mo stretchy="false" id="S6.SS2.SSS2.p3.7.m7.4.4.5.3.2.2" xref="S6.SS2.SSS2.p3.7.m7.4.4.5.3.1.cmml">}</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S6.SS2.SSS2.p3.7.m7.4b"><apply id="S6.SS2.SSS2.p3.7.m7.4.4.cmml" xref="S6.SS2.SSS2.p3.7.m7.4.4"><in id="S6.SS2.SSS2.p3.7.m7.4.4.4.cmml" xref="S6.SS2.SSS2.p3.7.m7.4.4.4"></in><list id="S6.SS2.SSS2.p3.7.m7.4.4.3.4.cmml" xref="S6.SS2.SSS2.p3.7.m7.4.4.3.3"><apply id="S6.SS2.SSS2.p3.7.m7.2.2.1.1.1.cmml" xref="S6.SS2.SSS2.p3.7.m7.2.2.1.1.1"><csymbol cd="ambiguous" id="S6.SS2.SSS2.p3.7.m7.2.2.1.1.1.1.cmml" xref="S6.SS2.SSS2.p3.7.m7.2.2.1.1.1">superscript</csymbol><ci id="S6.SS2.SSS2.p3.7.m7.2.2.1.1.1.2.cmml" xref="S6.SS2.SSS2.p3.7.m7.2.2.1.1.1.2">𝑎</ci><ci id="S6.SS2.SSS2.p3.7.m7.2.2.1.1.1.3.cmml" xref="S6.SS2.SSS2.p3.7.m7.2.2.1.1.1.3">′</ci></apply><apply id="S6.SS2.SSS2.p3.7.m7.3.3.2.2.2.cmml" xref="S6.SS2.SSS2.p3.7.m7.3.3.2.2.2"><csymbol cd="ambiguous" id="S6.SS2.SSS2.p3.7.m7.3.3.2.2.2.1.cmml" xref="S6.SS2.SSS2.p3.7.m7.3.3.2.2.2">superscript</csymbol><ci id="S6.SS2.SSS2.p3.7.m7.3.3.2.2.2.2.cmml" xref="S6.SS2.SSS2.p3.7.m7.3.3.2.2.2.2">𝑏</ci><ci id="S6.SS2.SSS2.p3.7.m7.3.3.2.2.2.3.cmml" xref="S6.SS2.SSS2.p3.7.m7.3.3.2.2.2.3">′</ci></apply><apply id="S6.SS2.SSS2.p3.7.m7.4.4.3.3.3.cmml" xref="S6.SS2.SSS2.p3.7.m7.4.4.3.3.3"><csymbol cd="ambiguous" id="S6.SS2.SSS2.p3.7.m7.4.4.3.3.3.1.cmml" xref="S6.SS2.SSS2.p3.7.m7.4.4.3.3.3">superscript</csymbol><ci id="S6.SS2.SSS2.p3.7.m7.4.4.3.3.3.2.cmml" xref="S6.SS2.SSS2.p3.7.m7.4.4.3.3.3.2">𝑐</ci><ci id="S6.SS2.SSS2.p3.7.m7.4.4.3.3.3.3.cmml" xref="S6.SS2.SSS2.p3.7.m7.4.4.3.3.3.3">′</ci></apply></list><apply id="S6.SS2.SSS2.p3.7.m7.4.4.5.cmml" xref="S6.SS2.SSS2.p3.7.m7.4.4.5"><ci id="S6.SS2.SSS2.p3.7.m7.4.4.5.1.cmml" xref="S6.SS2.SSS2.p3.7.m7.4.4.5.1">\</ci><ci id="S6.SS2.SSS2.p3.7.m7.4.4.5.2.cmml" xref="S6.SS2.SSS2.p3.7.m7.4.4.5.2">ℝ</ci><set id="S6.SS2.SSS2.p3.7.m7.4.4.5.3.1.cmml" xref="S6.SS2.SSS2.p3.7.m7.4.4.5.3.2"><cn type="integer" id="S6.SS2.SSS2.p3.7.m7.1.1.cmml" xref="S6.SS2.SSS2.p3.7.m7.1.1">0</cn></set></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.SSS2.p3.7.m7.4c">a^{\prime},b^{\prime},c^{\prime}\in\mathbb{R}\backslash\{0\}</annotation></semantics></math>. Each gradient vector in the sum <math id="S6.SS2.SSS2.p3.8.m8.1" class="ltx_Math" alttext="S" display="inline"><semantics id="S6.SS2.SSS2.p3.8.m8.1a"><mi id="S6.SS2.SSS2.p3.8.m8.1.1" xref="S6.SS2.SSS2.p3.8.m8.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="S6.SS2.SSS2.p3.8.m8.1b"><ci id="S6.SS2.SSS2.p3.8.m8.1.1.cmml" xref="S6.SS2.SSS2.p3.8.m8.1.1">𝑆</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.SSS2.p3.8.m8.1c">S</annotation></semantics></math> is now associated with a unique canonical orthogonal basis. Since the <math id="S6.SS2.SSS2.p3.9.m9.1" class="ltx_Math" alttext="L_{2}" display="inline"><semantics id="S6.SS2.SSS2.p3.9.m9.1a"><msub id="S6.SS2.SSS2.p3.9.m9.1.1" xref="S6.SS2.SSS2.p3.9.m9.1.1.cmml"><mi id="S6.SS2.SSS2.p3.9.m9.1.1.2" xref="S6.SS2.SSS2.p3.9.m9.1.1.2.cmml">L</mi><mn id="S6.SS2.SSS2.p3.9.m9.1.1.3" xref="S6.SS2.SSS2.p3.9.m9.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S6.SS2.SSS2.p3.9.m9.1b"><apply id="S6.SS2.SSS2.p3.9.m9.1.1.cmml" xref="S6.SS2.SSS2.p3.9.m9.1.1"><csymbol cd="ambiguous" id="S6.SS2.SSS2.p3.9.m9.1.1.1.cmml" xref="S6.SS2.SSS2.p3.9.m9.1.1">subscript</csymbol><ci id="S6.SS2.SSS2.p3.9.m9.1.1.2.cmml" xref="S6.SS2.SSS2.p3.9.m9.1.1.2">𝐿</ci><cn type="integer" id="S6.SS2.SSS2.p3.9.m9.1.1.3.cmml" xref="S6.SS2.SSS2.p3.9.m9.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.SSS2.p3.9.m9.1c">L_{2}</annotation></semantics></math> norm is invariant under basis rotations (for the same reason the length of a vector is invariant under rotation), it now becomes clear why subtracting a vector <math id="S6.SS2.SSS2.p3.10.m10.1" class="ltx_Math" alttext="v" display="inline"><semantics id="S6.SS2.SSS2.p3.10.m10.1a"><mi id="S6.SS2.SSS2.p3.10.m10.1.1" xref="S6.SS2.SSS2.p3.10.m10.1.1.cmml">v</mi><annotation-xml encoding="MathML-Content" id="S6.SS2.SSS2.p3.10.m10.1b"><ci id="S6.SS2.SSS2.p3.10.m10.1.1.cmml" xref="S6.SS2.SSS2.p3.10.m10.1.1">𝑣</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.SSS2.p3.10.m10.1c">v</annotation></semantics></math> of the orthogonal basis from <math id="S6.SS2.SSS2.p3.11.m11.1" class="ltx_Math" alttext="S" display="inline"><semantics id="S6.SS2.SSS2.p3.11.m11.1a"><mi id="S6.SS2.SSS2.p3.11.m11.1.1" xref="S6.SS2.SSS2.p3.11.m11.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="S6.SS2.SSS2.p3.11.m11.1b"><ci id="S6.SS2.SSS2.p3.11.m11.1.1.cmml" xref="S6.SS2.SSS2.p3.11.m11.1.1">𝑆</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.SSS2.p3.11.m11.1c">S</annotation></semantics></math> reduces the <math id="S6.SS2.SSS2.p3.12.m12.1" class="ltx_Math" alttext="L_{2}" display="inline"><semantics id="S6.SS2.SSS2.p3.12.m12.1a"><msub id="S6.SS2.SSS2.p3.12.m12.1.1" xref="S6.SS2.SSS2.p3.12.m12.1.1.cmml"><mi id="S6.SS2.SSS2.p3.12.m12.1.1.2" xref="S6.SS2.SSS2.p3.12.m12.1.1.2.cmml">L</mi><mn id="S6.SS2.SSS2.p3.12.m12.1.1.3" xref="S6.SS2.SSS2.p3.12.m12.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S6.SS2.SSS2.p3.12.m12.1b"><apply id="S6.SS2.SSS2.p3.12.m12.1.1.cmml" xref="S6.SS2.SSS2.p3.12.m12.1.1"><csymbol cd="ambiguous" id="S6.SS2.SSS2.p3.12.m12.1.1.1.cmml" xref="S6.SS2.SSS2.p3.12.m12.1.1">subscript</csymbol><ci id="S6.SS2.SSS2.p3.12.m12.1.1.2.cmml" xref="S6.SS2.SSS2.p3.12.m12.1.1.2">𝐿</ci><cn type="integer" id="S6.SS2.SSS2.p3.12.m12.1.1.3.cmml" xref="S6.SS2.SSS2.p3.12.m12.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.SSS2.p3.12.m12.1c">L_{2}</annotation></semantics></math> norm of <math id="S6.SS2.SSS2.p3.13.m13.1" class="ltx_Math" alttext="S" display="inline"><semantics id="S6.SS2.SSS2.p3.13.m13.1a"><mi id="S6.SS2.SSS2.p3.13.m13.1.1" xref="S6.SS2.SSS2.p3.13.m13.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="S6.SS2.SSS2.p3.13.m13.1b"><ci id="S6.SS2.SSS2.p3.13.m13.1.1.cmml" xref="S6.SS2.SSS2.p3.13.m13.1.1">𝑆</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.SSS2.p3.13.m13.1c">S</annotation></semantics></math> (if <math id="S6.SS2.SSS2.p3.14.m14.1" class="ltx_Math" alttext="v" display="inline"><semantics id="S6.SS2.SSS2.p3.14.m14.1a"><mi id="S6.SS2.SSS2.p3.14.m14.1.1" xref="S6.SS2.SSS2.p3.14.m14.1.1.cmml">v</mi><annotation-xml encoding="MathML-Content" id="S6.SS2.SSS2.p3.14.m14.1b"><ci id="S6.SS2.SSS2.p3.14.m14.1.1.cmml" xref="S6.SS2.SSS2.p3.14.m14.1.1">𝑣</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.SSS2.p3.14.m14.1c">v</annotation></semantics></math> is in the sum) or increases the sum’s <math id="S6.SS2.SSS2.p3.15.m15.1" class="ltx_Math" alttext="L_{2}" display="inline"><semantics id="S6.SS2.SSS2.p3.15.m15.1a"><msub id="S6.SS2.SSS2.p3.15.m15.1.1" xref="S6.SS2.SSS2.p3.15.m15.1.1.cmml"><mi id="S6.SS2.SSS2.p3.15.m15.1.1.2" xref="S6.SS2.SSS2.p3.15.m15.1.1.2.cmml">L</mi><mn id="S6.SS2.SSS2.p3.15.m15.1.1.3" xref="S6.SS2.SSS2.p3.15.m15.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S6.SS2.SSS2.p3.15.m15.1b"><apply id="S6.SS2.SSS2.p3.15.m15.1.1.cmml" xref="S6.SS2.SSS2.p3.15.m15.1.1"><csymbol cd="ambiguous" id="S6.SS2.SSS2.p3.15.m15.1.1.1.cmml" xref="S6.SS2.SSS2.p3.15.m15.1.1">subscript</csymbol><ci id="S6.SS2.SSS2.p3.15.m15.1.1.2.cmml" xref="S6.SS2.SSS2.p3.15.m15.1.1.2">𝐿</ci><cn type="integer" id="S6.SS2.SSS2.p3.15.m15.1.1.3.cmml" xref="S6.SS2.SSS2.p3.15.m15.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.SSS2.p3.15.m15.1c">L_{2}</annotation></semantics></math> (if <math id="S6.SS2.SSS2.p3.16.m16.1" class="ltx_Math" alttext="v" display="inline"><semantics id="S6.SS2.SSS2.p3.16.m16.1a"><mi id="S6.SS2.SSS2.p3.16.m16.1.1" xref="S6.SS2.SSS2.p3.16.m16.1.1.cmml">v</mi><annotation-xml encoding="MathML-Content" id="S6.SS2.SSS2.p3.16.m16.1b"><ci id="S6.SS2.SSS2.p3.16.m16.1.1.cmml" xref="S6.SS2.SSS2.p3.16.m16.1.1">𝑣</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.SSS2.p3.16.m16.1c">v</annotation></semantics></math> is not in the sum). If the <math id="S6.SS2.SSS2.p3.17.m17.1" class="ltx_Math" alttext="L_{2}" display="inline"><semantics id="S6.SS2.SSS2.p3.17.m17.1a"><msub id="S6.SS2.SSS2.p3.17.m17.1.1" xref="S6.SS2.SSS2.p3.17.m17.1.1.cmml"><mi id="S6.SS2.SSS2.p3.17.m17.1.1.2" xref="S6.SS2.SSS2.p3.17.m17.1.1.2.cmml">L</mi><mn id="S6.SS2.SSS2.p3.17.m17.1.1.3" xref="S6.SS2.SSS2.p3.17.m17.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S6.SS2.SSS2.p3.17.m17.1b"><apply id="S6.SS2.SSS2.p3.17.m17.1.1.cmml" xref="S6.SS2.SSS2.p3.17.m17.1.1"><csymbol cd="ambiguous" id="S6.SS2.SSS2.p3.17.m17.1.1.1.cmml" xref="S6.SS2.SSS2.p3.17.m17.1.1">subscript</csymbol><ci id="S6.SS2.SSS2.p3.17.m17.1.1.2.cmml" xref="S6.SS2.SSS2.p3.17.m17.1.1.2">𝐿</ci><cn type="integer" id="S6.SS2.SSS2.p3.17.m17.1.1.3.cmml" xref="S6.SS2.SSS2.p3.17.m17.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.SSS2.p3.17.m17.1c">L_{2}</annotation></semantics></math> norm is reduced, the attacker could claim that the target instance is a member, otherwise it is a non-member.</p>
</div>
</section>
<section id="S6.SS2.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">6.2.3. </span>Membership inference attacks from centralized setting.</h4>

<div id="S6.SS2.SSS3.p1" class="ltx_para">
<p id="S6.SS2.SSS3.p1.1" class="ltx_p">It is worth noting that all the membership inference attacks that do not require <span id="S6.SS2.SSS3.p1.1.1" class="ltx_text ltx_font_bold">shadow models</span> can be applied to FL setting as well. <span id="S6.SS2.SSS3.p1.1.2" class="ltx_text ltx_font_bold">Shadow model</span> is a commonly used technique in membership inferences and by this technique, the attacker is able to train models similar to the target model using data drawn from the same distribution of the training data of the target model. Thus, shadow models enable attackers to collect any information necessary for membership inference, for example, what the loss would be for one instance if this instance is not included in training.</p>
</div>
<div id="S6.SS2.SSS3.p2" class="ltx_para">
<p id="S6.SS2.SSS3.p2.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citet">Yeom et al<span class="ltx_text">.</span> (<a href="#bib.bib136" title="" class="ltx_ref">2018</a>)</cite> presented a theoretical analysis on privacy leakage based on prediction loss. They showed that the generalization gap between training accuracy and testing accuracy could serve as a lower bound for MI attack accuracy, as the attacker predicts member if and only if the model’s prediction is correct. Besides, they proposed a threshold attack based on prediction loss, and the attacker predicts member if and only if the prediction loss is lower than the threshold, since the loss of members is generally lower than the loss of non-members.</p>
</div>
<div id="S6.SS2.SSS3.p3" class="ltx_para">
<p id="S6.SS2.SSS3.p3.1" class="ltx_p">Inspired by <cite class="ltx_cite ltx_citemacro_citet">Yeom et al<span class="ltx_text">.</span> (<a href="#bib.bib136" title="" class="ltx_ref">2018</a>)</cite>, <cite class="ltx_cite ltx_citemacro_citet">Song et al<span class="ltx_text">.</span> (<a href="#bib.bib122" title="" class="ltx_ref">2019</a>)</cite> proposed to adjust the prediction loss by a class-dependent value by noticing that some classes are harder to correctly classify than other classes. In addition, <cite class="ltx_cite ltx_citemacro_citet">Song et al<span class="ltx_text">.</span> (<a href="#bib.bib122" title="" class="ltx_ref">2019</a>)</cite> proposed to use a modified prediction entropy to predict membership. The modified prediction entropy is calculated using this formula:
<math id="S6.SS2.SSS3.p3.1.m1.12" class="ltx_Math" alttext="Mentr(F_{\theta}(x),y)=-(1-F_{\theta}(x)_{y})\log(F_{\theta}(x)_{y})-\sum_{i\neq y}F_{\theta}(x)_{i}\log(1-F_{\theta}(x)_{i})" display="inline"><semantics id="S6.SS2.SSS3.p3.1.m1.12a"><mrow id="S6.SS2.SSS3.p3.1.m1.12.12" xref="S6.SS2.SSS3.p3.1.m1.12.12.cmml"><mrow id="S6.SS2.SSS3.p3.1.m1.9.9.1" xref="S6.SS2.SSS3.p3.1.m1.9.9.1.cmml"><mi id="S6.SS2.SSS3.p3.1.m1.9.9.1.3" xref="S6.SS2.SSS3.p3.1.m1.9.9.1.3.cmml">M</mi><mo lspace="0em" rspace="0em" id="S6.SS2.SSS3.p3.1.m1.9.9.1.2" xref="S6.SS2.SSS3.p3.1.m1.9.9.1.2.cmml">​</mo><mi id="S6.SS2.SSS3.p3.1.m1.9.9.1.4" xref="S6.SS2.SSS3.p3.1.m1.9.9.1.4.cmml">e</mi><mo lspace="0em" rspace="0em" id="S6.SS2.SSS3.p3.1.m1.9.9.1.2a" xref="S6.SS2.SSS3.p3.1.m1.9.9.1.2.cmml">​</mo><mi id="S6.SS2.SSS3.p3.1.m1.9.9.1.5" xref="S6.SS2.SSS3.p3.1.m1.9.9.1.5.cmml">n</mi><mo lspace="0em" rspace="0em" id="S6.SS2.SSS3.p3.1.m1.9.9.1.2b" xref="S6.SS2.SSS3.p3.1.m1.9.9.1.2.cmml">​</mo><mi id="S6.SS2.SSS3.p3.1.m1.9.9.1.6" xref="S6.SS2.SSS3.p3.1.m1.9.9.1.6.cmml">t</mi><mo lspace="0em" rspace="0em" id="S6.SS2.SSS3.p3.1.m1.9.9.1.2c" xref="S6.SS2.SSS3.p3.1.m1.9.9.1.2.cmml">​</mo><mi id="S6.SS2.SSS3.p3.1.m1.9.9.1.7" xref="S6.SS2.SSS3.p3.1.m1.9.9.1.7.cmml">r</mi><mo lspace="0em" rspace="0em" id="S6.SS2.SSS3.p3.1.m1.9.9.1.2d" xref="S6.SS2.SSS3.p3.1.m1.9.9.1.2.cmml">​</mo><mrow id="S6.SS2.SSS3.p3.1.m1.9.9.1.1.1" xref="S6.SS2.SSS3.p3.1.m1.9.9.1.1.2.cmml"><mo stretchy="false" id="S6.SS2.SSS3.p3.1.m1.9.9.1.1.1.2" xref="S6.SS2.SSS3.p3.1.m1.9.9.1.1.2.cmml">(</mo><mrow id="S6.SS2.SSS3.p3.1.m1.9.9.1.1.1.1" xref="S6.SS2.SSS3.p3.1.m1.9.9.1.1.1.1.cmml"><msub id="S6.SS2.SSS3.p3.1.m1.9.9.1.1.1.1.2" xref="S6.SS2.SSS3.p3.1.m1.9.9.1.1.1.1.2.cmml"><mi id="S6.SS2.SSS3.p3.1.m1.9.9.1.1.1.1.2.2" xref="S6.SS2.SSS3.p3.1.m1.9.9.1.1.1.1.2.2.cmml">F</mi><mi id="S6.SS2.SSS3.p3.1.m1.9.9.1.1.1.1.2.3" xref="S6.SS2.SSS3.p3.1.m1.9.9.1.1.1.1.2.3.cmml">θ</mi></msub><mo lspace="0em" rspace="0em" id="S6.SS2.SSS3.p3.1.m1.9.9.1.1.1.1.1" xref="S6.SS2.SSS3.p3.1.m1.9.9.1.1.1.1.1.cmml">​</mo><mrow id="S6.SS2.SSS3.p3.1.m1.9.9.1.1.1.1.3.2" xref="S6.SS2.SSS3.p3.1.m1.9.9.1.1.1.1.cmml"><mo stretchy="false" id="S6.SS2.SSS3.p3.1.m1.9.9.1.1.1.1.3.2.1" xref="S6.SS2.SSS3.p3.1.m1.9.9.1.1.1.1.cmml">(</mo><mi id="S6.SS2.SSS3.p3.1.m1.1.1" xref="S6.SS2.SSS3.p3.1.m1.1.1.cmml">x</mi><mo stretchy="false" id="S6.SS2.SSS3.p3.1.m1.9.9.1.1.1.1.3.2.2" xref="S6.SS2.SSS3.p3.1.m1.9.9.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S6.SS2.SSS3.p3.1.m1.9.9.1.1.1.3" xref="S6.SS2.SSS3.p3.1.m1.9.9.1.1.2.cmml">,</mo><mi id="S6.SS2.SSS3.p3.1.m1.2.2" xref="S6.SS2.SSS3.p3.1.m1.2.2.cmml">y</mi><mo stretchy="false" id="S6.SS2.SSS3.p3.1.m1.9.9.1.1.1.4" xref="S6.SS2.SSS3.p3.1.m1.9.9.1.1.2.cmml">)</mo></mrow></mrow><mo id="S6.SS2.SSS3.p3.1.m1.12.12.5" xref="S6.SS2.SSS3.p3.1.m1.12.12.5.cmml">=</mo><mrow id="S6.SS2.SSS3.p3.1.m1.12.12.4" xref="S6.SS2.SSS3.p3.1.m1.12.12.4.cmml"><mrow id="S6.SS2.SSS3.p3.1.m1.11.11.3.2" xref="S6.SS2.SSS3.p3.1.m1.11.11.3.2.cmml"><mo id="S6.SS2.SSS3.p3.1.m1.11.11.3.2a" xref="S6.SS2.SSS3.p3.1.m1.11.11.3.2.cmml">−</mo><mrow id="S6.SS2.SSS3.p3.1.m1.11.11.3.2.2" xref="S6.SS2.SSS3.p3.1.m1.11.11.3.2.2.cmml"><mrow id="S6.SS2.SSS3.p3.1.m1.10.10.2.1.1.1.1" xref="S6.SS2.SSS3.p3.1.m1.10.10.2.1.1.1.1.1.cmml"><mo stretchy="false" id="S6.SS2.SSS3.p3.1.m1.10.10.2.1.1.1.1.2" xref="S6.SS2.SSS3.p3.1.m1.10.10.2.1.1.1.1.1.cmml">(</mo><mrow id="S6.SS2.SSS3.p3.1.m1.10.10.2.1.1.1.1.1" xref="S6.SS2.SSS3.p3.1.m1.10.10.2.1.1.1.1.1.cmml"><mn id="S6.SS2.SSS3.p3.1.m1.10.10.2.1.1.1.1.1.2" xref="S6.SS2.SSS3.p3.1.m1.10.10.2.1.1.1.1.1.2.cmml">1</mn><mo id="S6.SS2.SSS3.p3.1.m1.10.10.2.1.1.1.1.1.1" xref="S6.SS2.SSS3.p3.1.m1.10.10.2.1.1.1.1.1.1.cmml">−</mo><mrow id="S6.SS2.SSS3.p3.1.m1.10.10.2.1.1.1.1.1.3" xref="S6.SS2.SSS3.p3.1.m1.10.10.2.1.1.1.1.1.3.cmml"><msub id="S6.SS2.SSS3.p3.1.m1.10.10.2.1.1.1.1.1.3.2" xref="S6.SS2.SSS3.p3.1.m1.10.10.2.1.1.1.1.1.3.2.cmml"><mi id="S6.SS2.SSS3.p3.1.m1.10.10.2.1.1.1.1.1.3.2.2" xref="S6.SS2.SSS3.p3.1.m1.10.10.2.1.1.1.1.1.3.2.2.cmml">F</mi><mi id="S6.SS2.SSS3.p3.1.m1.10.10.2.1.1.1.1.1.3.2.3" xref="S6.SS2.SSS3.p3.1.m1.10.10.2.1.1.1.1.1.3.2.3.cmml">θ</mi></msub><mo lspace="0em" rspace="0em" id="S6.SS2.SSS3.p3.1.m1.10.10.2.1.1.1.1.1.3.1" xref="S6.SS2.SSS3.p3.1.m1.10.10.2.1.1.1.1.1.3.1.cmml">​</mo><msub id="S6.SS2.SSS3.p3.1.m1.10.10.2.1.1.1.1.1.3.3" xref="S6.SS2.SSS3.p3.1.m1.10.10.2.1.1.1.1.1.3.3.cmml"><mrow id="S6.SS2.SSS3.p3.1.m1.10.10.2.1.1.1.1.1.3.3.2.2" xref="S6.SS2.SSS3.p3.1.m1.10.10.2.1.1.1.1.1.3.3.cmml"><mo stretchy="false" id="S6.SS2.SSS3.p3.1.m1.10.10.2.1.1.1.1.1.3.3.2.2.1" xref="S6.SS2.SSS3.p3.1.m1.10.10.2.1.1.1.1.1.3.3.cmml">(</mo><mi id="S6.SS2.SSS3.p3.1.m1.3.3" xref="S6.SS2.SSS3.p3.1.m1.3.3.cmml">x</mi><mo stretchy="false" id="S6.SS2.SSS3.p3.1.m1.10.10.2.1.1.1.1.1.3.3.2.2.2" xref="S6.SS2.SSS3.p3.1.m1.10.10.2.1.1.1.1.1.3.3.cmml">)</mo></mrow><mi id="S6.SS2.SSS3.p3.1.m1.10.10.2.1.1.1.1.1.3.3.3" xref="S6.SS2.SSS3.p3.1.m1.10.10.2.1.1.1.1.1.3.3.3.cmml">y</mi></msub></mrow></mrow><mo stretchy="false" id="S6.SS2.SSS3.p3.1.m1.10.10.2.1.1.1.1.3" xref="S6.SS2.SSS3.p3.1.m1.10.10.2.1.1.1.1.1.cmml">)</mo></mrow><mo lspace="0.167em" rspace="0em" id="S6.SS2.SSS3.p3.1.m1.11.11.3.2.2.3" xref="S6.SS2.SSS3.p3.1.m1.11.11.3.2.2.3.cmml">​</mo><mrow id="S6.SS2.SSS3.p3.1.m1.11.11.3.2.2.2.1" xref="S6.SS2.SSS3.p3.1.m1.11.11.3.2.2.2.2.cmml"><mi id="S6.SS2.SSS3.p3.1.m1.5.5" xref="S6.SS2.SSS3.p3.1.m1.5.5.cmml">log</mi><mo id="S6.SS2.SSS3.p3.1.m1.11.11.3.2.2.2.1a" xref="S6.SS2.SSS3.p3.1.m1.11.11.3.2.2.2.2.cmml">⁡</mo><mrow id="S6.SS2.SSS3.p3.1.m1.11.11.3.2.2.2.1.1" xref="S6.SS2.SSS3.p3.1.m1.11.11.3.2.2.2.2.cmml"><mo stretchy="false" id="S6.SS2.SSS3.p3.1.m1.11.11.3.2.2.2.1.1.2" xref="S6.SS2.SSS3.p3.1.m1.11.11.3.2.2.2.2.cmml">(</mo><mrow id="S6.SS2.SSS3.p3.1.m1.11.11.3.2.2.2.1.1.1" xref="S6.SS2.SSS3.p3.1.m1.11.11.3.2.2.2.1.1.1.cmml"><msub id="S6.SS2.SSS3.p3.1.m1.11.11.3.2.2.2.1.1.1.2" xref="S6.SS2.SSS3.p3.1.m1.11.11.3.2.2.2.1.1.1.2.cmml"><mi id="S6.SS2.SSS3.p3.1.m1.11.11.3.2.2.2.1.1.1.2.2" xref="S6.SS2.SSS3.p3.1.m1.11.11.3.2.2.2.1.1.1.2.2.cmml">F</mi><mi id="S6.SS2.SSS3.p3.1.m1.11.11.3.2.2.2.1.1.1.2.3" xref="S6.SS2.SSS3.p3.1.m1.11.11.3.2.2.2.1.1.1.2.3.cmml">θ</mi></msub><mo lspace="0em" rspace="0em" id="S6.SS2.SSS3.p3.1.m1.11.11.3.2.2.2.1.1.1.1" xref="S6.SS2.SSS3.p3.1.m1.11.11.3.2.2.2.1.1.1.1.cmml">​</mo><msub id="S6.SS2.SSS3.p3.1.m1.11.11.3.2.2.2.1.1.1.3" xref="S6.SS2.SSS3.p3.1.m1.11.11.3.2.2.2.1.1.1.3.cmml"><mrow id="S6.SS2.SSS3.p3.1.m1.11.11.3.2.2.2.1.1.1.3.2.2" xref="S6.SS2.SSS3.p3.1.m1.11.11.3.2.2.2.1.1.1.3.cmml"><mo stretchy="false" id="S6.SS2.SSS3.p3.1.m1.11.11.3.2.2.2.1.1.1.3.2.2.1" xref="S6.SS2.SSS3.p3.1.m1.11.11.3.2.2.2.1.1.1.3.cmml">(</mo><mi id="S6.SS2.SSS3.p3.1.m1.4.4" xref="S6.SS2.SSS3.p3.1.m1.4.4.cmml">x</mi><mo stretchy="false" id="S6.SS2.SSS3.p3.1.m1.11.11.3.2.2.2.1.1.1.3.2.2.2" xref="S6.SS2.SSS3.p3.1.m1.11.11.3.2.2.2.1.1.1.3.cmml">)</mo></mrow><mi id="S6.SS2.SSS3.p3.1.m1.11.11.3.2.2.2.1.1.1.3.3" xref="S6.SS2.SSS3.p3.1.m1.11.11.3.2.2.2.1.1.1.3.3.cmml">y</mi></msub></mrow><mo stretchy="false" id="S6.SS2.SSS3.p3.1.m1.11.11.3.2.2.2.1.1.3" xref="S6.SS2.SSS3.p3.1.m1.11.11.3.2.2.2.2.cmml">)</mo></mrow></mrow></mrow></mrow><mo rspace="0.055em" id="S6.SS2.SSS3.p3.1.m1.12.12.4.4" xref="S6.SS2.SSS3.p3.1.m1.12.12.4.4.cmml">−</mo><mrow id="S6.SS2.SSS3.p3.1.m1.12.12.4.3" xref="S6.SS2.SSS3.p3.1.m1.12.12.4.3.cmml"><msub id="S6.SS2.SSS3.p3.1.m1.12.12.4.3.2" xref="S6.SS2.SSS3.p3.1.m1.12.12.4.3.2.cmml"><mo id="S6.SS2.SSS3.p3.1.m1.12.12.4.3.2.2" xref="S6.SS2.SSS3.p3.1.m1.12.12.4.3.2.2.cmml">∑</mo><mrow id="S6.SS2.SSS3.p3.1.m1.12.12.4.3.2.3" xref="S6.SS2.SSS3.p3.1.m1.12.12.4.3.2.3.cmml"><mi id="S6.SS2.SSS3.p3.1.m1.12.12.4.3.2.3.2" xref="S6.SS2.SSS3.p3.1.m1.12.12.4.3.2.3.2.cmml">i</mi><mo id="S6.SS2.SSS3.p3.1.m1.12.12.4.3.2.3.1" xref="S6.SS2.SSS3.p3.1.m1.12.12.4.3.2.3.1.cmml">≠</mo><mi id="S6.SS2.SSS3.p3.1.m1.12.12.4.3.2.3.3" xref="S6.SS2.SSS3.p3.1.m1.12.12.4.3.2.3.3.cmml">y</mi></mrow></msub><mrow id="S6.SS2.SSS3.p3.1.m1.12.12.4.3.1" xref="S6.SS2.SSS3.p3.1.m1.12.12.4.3.1.cmml"><msub id="S6.SS2.SSS3.p3.1.m1.12.12.4.3.1.3" xref="S6.SS2.SSS3.p3.1.m1.12.12.4.3.1.3.cmml"><mi id="S6.SS2.SSS3.p3.1.m1.12.12.4.3.1.3.2" xref="S6.SS2.SSS3.p3.1.m1.12.12.4.3.1.3.2.cmml">F</mi><mi id="S6.SS2.SSS3.p3.1.m1.12.12.4.3.1.3.3" xref="S6.SS2.SSS3.p3.1.m1.12.12.4.3.1.3.3.cmml">θ</mi></msub><mo lspace="0em" rspace="0em" id="S6.SS2.SSS3.p3.1.m1.12.12.4.3.1.2" xref="S6.SS2.SSS3.p3.1.m1.12.12.4.3.1.2.cmml">​</mo><msub id="S6.SS2.SSS3.p3.1.m1.12.12.4.3.1.4" xref="S6.SS2.SSS3.p3.1.m1.12.12.4.3.1.4.cmml"><mrow id="S6.SS2.SSS3.p3.1.m1.12.12.4.3.1.4.2.2" xref="S6.SS2.SSS3.p3.1.m1.12.12.4.3.1.4.cmml"><mo stretchy="false" id="S6.SS2.SSS3.p3.1.m1.12.12.4.3.1.4.2.2.1" xref="S6.SS2.SSS3.p3.1.m1.12.12.4.3.1.4.cmml">(</mo><mi id="S6.SS2.SSS3.p3.1.m1.6.6" xref="S6.SS2.SSS3.p3.1.m1.6.6.cmml">x</mi><mo stretchy="false" id="S6.SS2.SSS3.p3.1.m1.12.12.4.3.1.4.2.2.2" xref="S6.SS2.SSS3.p3.1.m1.12.12.4.3.1.4.cmml">)</mo></mrow><mi id="S6.SS2.SSS3.p3.1.m1.12.12.4.3.1.4.3" xref="S6.SS2.SSS3.p3.1.m1.12.12.4.3.1.4.3.cmml">i</mi></msub><mo lspace="0.167em" rspace="0em" id="S6.SS2.SSS3.p3.1.m1.12.12.4.3.1.2a" xref="S6.SS2.SSS3.p3.1.m1.12.12.4.3.1.2.cmml">​</mo><mrow id="S6.SS2.SSS3.p3.1.m1.12.12.4.3.1.1.1" xref="S6.SS2.SSS3.p3.1.m1.12.12.4.3.1.1.2.cmml"><mi id="S6.SS2.SSS3.p3.1.m1.8.8" xref="S6.SS2.SSS3.p3.1.m1.8.8.cmml">log</mi><mo id="S6.SS2.SSS3.p3.1.m1.12.12.4.3.1.1.1a" xref="S6.SS2.SSS3.p3.1.m1.12.12.4.3.1.1.2.cmml">⁡</mo><mrow id="S6.SS2.SSS3.p3.1.m1.12.12.4.3.1.1.1.1" xref="S6.SS2.SSS3.p3.1.m1.12.12.4.3.1.1.2.cmml"><mo stretchy="false" id="S6.SS2.SSS3.p3.1.m1.12.12.4.3.1.1.1.1.2" xref="S6.SS2.SSS3.p3.1.m1.12.12.4.3.1.1.2.cmml">(</mo><mrow id="S6.SS2.SSS3.p3.1.m1.12.12.4.3.1.1.1.1.1" xref="S6.SS2.SSS3.p3.1.m1.12.12.4.3.1.1.1.1.1.cmml"><mn id="S6.SS2.SSS3.p3.1.m1.12.12.4.3.1.1.1.1.1.2" xref="S6.SS2.SSS3.p3.1.m1.12.12.4.3.1.1.1.1.1.2.cmml">1</mn><mo id="S6.SS2.SSS3.p3.1.m1.12.12.4.3.1.1.1.1.1.1" xref="S6.SS2.SSS3.p3.1.m1.12.12.4.3.1.1.1.1.1.1.cmml">−</mo><mrow id="S6.SS2.SSS3.p3.1.m1.12.12.4.3.1.1.1.1.1.3" xref="S6.SS2.SSS3.p3.1.m1.12.12.4.3.1.1.1.1.1.3.cmml"><msub id="S6.SS2.SSS3.p3.1.m1.12.12.4.3.1.1.1.1.1.3.2" xref="S6.SS2.SSS3.p3.1.m1.12.12.4.3.1.1.1.1.1.3.2.cmml"><mi id="S6.SS2.SSS3.p3.1.m1.12.12.4.3.1.1.1.1.1.3.2.2" xref="S6.SS2.SSS3.p3.1.m1.12.12.4.3.1.1.1.1.1.3.2.2.cmml">F</mi><mi id="S6.SS2.SSS3.p3.1.m1.12.12.4.3.1.1.1.1.1.3.2.3" xref="S6.SS2.SSS3.p3.1.m1.12.12.4.3.1.1.1.1.1.3.2.3.cmml">θ</mi></msub><mo lspace="0em" rspace="0em" id="S6.SS2.SSS3.p3.1.m1.12.12.4.3.1.1.1.1.1.3.1" xref="S6.SS2.SSS3.p3.1.m1.12.12.4.3.1.1.1.1.1.3.1.cmml">​</mo><msub id="S6.SS2.SSS3.p3.1.m1.12.12.4.3.1.1.1.1.1.3.3" xref="S6.SS2.SSS3.p3.1.m1.12.12.4.3.1.1.1.1.1.3.3.cmml"><mrow id="S6.SS2.SSS3.p3.1.m1.12.12.4.3.1.1.1.1.1.3.3.2.2" xref="S6.SS2.SSS3.p3.1.m1.12.12.4.3.1.1.1.1.1.3.3.cmml"><mo stretchy="false" id="S6.SS2.SSS3.p3.1.m1.12.12.4.3.1.1.1.1.1.3.3.2.2.1" xref="S6.SS2.SSS3.p3.1.m1.12.12.4.3.1.1.1.1.1.3.3.cmml">(</mo><mi id="S6.SS2.SSS3.p3.1.m1.7.7" xref="S6.SS2.SSS3.p3.1.m1.7.7.cmml">x</mi><mo stretchy="false" id="S6.SS2.SSS3.p3.1.m1.12.12.4.3.1.1.1.1.1.3.3.2.2.2" xref="S6.SS2.SSS3.p3.1.m1.12.12.4.3.1.1.1.1.1.3.3.cmml">)</mo></mrow><mi id="S6.SS2.SSS3.p3.1.m1.12.12.4.3.1.1.1.1.1.3.3.3" xref="S6.SS2.SSS3.p3.1.m1.12.12.4.3.1.1.1.1.1.3.3.3.cmml">i</mi></msub></mrow></mrow><mo stretchy="false" id="S6.SS2.SSS3.p3.1.m1.12.12.4.3.1.1.1.1.3" xref="S6.SS2.SSS3.p3.1.m1.12.12.4.3.1.1.2.cmml">)</mo></mrow></mrow></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S6.SS2.SSS3.p3.1.m1.12b"><apply id="S6.SS2.SSS3.p3.1.m1.12.12.cmml" xref="S6.SS2.SSS3.p3.1.m1.12.12"><eq id="S6.SS2.SSS3.p3.1.m1.12.12.5.cmml" xref="S6.SS2.SSS3.p3.1.m1.12.12.5"></eq><apply id="S6.SS2.SSS3.p3.1.m1.9.9.1.cmml" xref="S6.SS2.SSS3.p3.1.m1.9.9.1"><times id="S6.SS2.SSS3.p3.1.m1.9.9.1.2.cmml" xref="S6.SS2.SSS3.p3.1.m1.9.9.1.2"></times><ci id="S6.SS2.SSS3.p3.1.m1.9.9.1.3.cmml" xref="S6.SS2.SSS3.p3.1.m1.9.9.1.3">𝑀</ci><ci id="S6.SS2.SSS3.p3.1.m1.9.9.1.4.cmml" xref="S6.SS2.SSS3.p3.1.m1.9.9.1.4">𝑒</ci><ci id="S6.SS2.SSS3.p3.1.m1.9.9.1.5.cmml" xref="S6.SS2.SSS3.p3.1.m1.9.9.1.5">𝑛</ci><ci id="S6.SS2.SSS3.p3.1.m1.9.9.1.6.cmml" xref="S6.SS2.SSS3.p3.1.m1.9.9.1.6">𝑡</ci><ci id="S6.SS2.SSS3.p3.1.m1.9.9.1.7.cmml" xref="S6.SS2.SSS3.p3.1.m1.9.9.1.7">𝑟</ci><interval closure="open" id="S6.SS2.SSS3.p3.1.m1.9.9.1.1.2.cmml" xref="S6.SS2.SSS3.p3.1.m1.9.9.1.1.1"><apply id="S6.SS2.SSS3.p3.1.m1.9.9.1.1.1.1.cmml" xref="S6.SS2.SSS3.p3.1.m1.9.9.1.1.1.1"><times id="S6.SS2.SSS3.p3.1.m1.9.9.1.1.1.1.1.cmml" xref="S6.SS2.SSS3.p3.1.m1.9.9.1.1.1.1.1"></times><apply id="S6.SS2.SSS3.p3.1.m1.9.9.1.1.1.1.2.cmml" xref="S6.SS2.SSS3.p3.1.m1.9.9.1.1.1.1.2"><csymbol cd="ambiguous" id="S6.SS2.SSS3.p3.1.m1.9.9.1.1.1.1.2.1.cmml" xref="S6.SS2.SSS3.p3.1.m1.9.9.1.1.1.1.2">subscript</csymbol><ci id="S6.SS2.SSS3.p3.1.m1.9.9.1.1.1.1.2.2.cmml" xref="S6.SS2.SSS3.p3.1.m1.9.9.1.1.1.1.2.2">𝐹</ci><ci id="S6.SS2.SSS3.p3.1.m1.9.9.1.1.1.1.2.3.cmml" xref="S6.SS2.SSS3.p3.1.m1.9.9.1.1.1.1.2.3">𝜃</ci></apply><ci id="S6.SS2.SSS3.p3.1.m1.1.1.cmml" xref="S6.SS2.SSS3.p3.1.m1.1.1">𝑥</ci></apply><ci id="S6.SS2.SSS3.p3.1.m1.2.2.cmml" xref="S6.SS2.SSS3.p3.1.m1.2.2">𝑦</ci></interval></apply><apply id="S6.SS2.SSS3.p3.1.m1.12.12.4.cmml" xref="S6.SS2.SSS3.p3.1.m1.12.12.4"><minus id="S6.SS2.SSS3.p3.1.m1.12.12.4.4.cmml" xref="S6.SS2.SSS3.p3.1.m1.12.12.4.4"></minus><apply id="S6.SS2.SSS3.p3.1.m1.11.11.3.2.cmml" xref="S6.SS2.SSS3.p3.1.m1.11.11.3.2"><minus id="S6.SS2.SSS3.p3.1.m1.11.11.3.2.3.cmml" xref="S6.SS2.SSS3.p3.1.m1.11.11.3.2"></minus><apply id="S6.SS2.SSS3.p3.1.m1.11.11.3.2.2.cmml" xref="S6.SS2.SSS3.p3.1.m1.11.11.3.2.2"><times id="S6.SS2.SSS3.p3.1.m1.11.11.3.2.2.3.cmml" xref="S6.SS2.SSS3.p3.1.m1.11.11.3.2.2.3"></times><apply id="S6.SS2.SSS3.p3.1.m1.10.10.2.1.1.1.1.1.cmml" xref="S6.SS2.SSS3.p3.1.m1.10.10.2.1.1.1.1"><minus id="S6.SS2.SSS3.p3.1.m1.10.10.2.1.1.1.1.1.1.cmml" xref="S6.SS2.SSS3.p3.1.m1.10.10.2.1.1.1.1.1.1"></minus><cn type="integer" id="S6.SS2.SSS3.p3.1.m1.10.10.2.1.1.1.1.1.2.cmml" xref="S6.SS2.SSS3.p3.1.m1.10.10.2.1.1.1.1.1.2">1</cn><apply id="S6.SS2.SSS3.p3.1.m1.10.10.2.1.1.1.1.1.3.cmml" xref="S6.SS2.SSS3.p3.1.m1.10.10.2.1.1.1.1.1.3"><times id="S6.SS2.SSS3.p3.1.m1.10.10.2.1.1.1.1.1.3.1.cmml" xref="S6.SS2.SSS3.p3.1.m1.10.10.2.1.1.1.1.1.3.1"></times><apply id="S6.SS2.SSS3.p3.1.m1.10.10.2.1.1.1.1.1.3.2.cmml" xref="S6.SS2.SSS3.p3.1.m1.10.10.2.1.1.1.1.1.3.2"><csymbol cd="ambiguous" id="S6.SS2.SSS3.p3.1.m1.10.10.2.1.1.1.1.1.3.2.1.cmml" xref="S6.SS2.SSS3.p3.1.m1.10.10.2.1.1.1.1.1.3.2">subscript</csymbol><ci id="S6.SS2.SSS3.p3.1.m1.10.10.2.1.1.1.1.1.3.2.2.cmml" xref="S6.SS2.SSS3.p3.1.m1.10.10.2.1.1.1.1.1.3.2.2">𝐹</ci><ci id="S6.SS2.SSS3.p3.1.m1.10.10.2.1.1.1.1.1.3.2.3.cmml" xref="S6.SS2.SSS3.p3.1.m1.10.10.2.1.1.1.1.1.3.2.3">𝜃</ci></apply><apply id="S6.SS2.SSS3.p3.1.m1.10.10.2.1.1.1.1.1.3.3.cmml" xref="S6.SS2.SSS3.p3.1.m1.10.10.2.1.1.1.1.1.3.3"><csymbol cd="ambiguous" id="S6.SS2.SSS3.p3.1.m1.10.10.2.1.1.1.1.1.3.3.1.cmml" xref="S6.SS2.SSS3.p3.1.m1.10.10.2.1.1.1.1.1.3.3">subscript</csymbol><ci id="S6.SS2.SSS3.p3.1.m1.3.3.cmml" xref="S6.SS2.SSS3.p3.1.m1.3.3">𝑥</ci><ci id="S6.SS2.SSS3.p3.1.m1.10.10.2.1.1.1.1.1.3.3.3.cmml" xref="S6.SS2.SSS3.p3.1.m1.10.10.2.1.1.1.1.1.3.3.3">𝑦</ci></apply></apply></apply><apply id="S6.SS2.SSS3.p3.1.m1.11.11.3.2.2.2.2.cmml" xref="S6.SS2.SSS3.p3.1.m1.11.11.3.2.2.2.1"><log id="S6.SS2.SSS3.p3.1.m1.5.5.cmml" xref="S6.SS2.SSS3.p3.1.m1.5.5"></log><apply id="S6.SS2.SSS3.p3.1.m1.11.11.3.2.2.2.1.1.1.cmml" xref="S6.SS2.SSS3.p3.1.m1.11.11.3.2.2.2.1.1.1"><times id="S6.SS2.SSS3.p3.1.m1.11.11.3.2.2.2.1.1.1.1.cmml" xref="S6.SS2.SSS3.p3.1.m1.11.11.3.2.2.2.1.1.1.1"></times><apply id="S6.SS2.SSS3.p3.1.m1.11.11.3.2.2.2.1.1.1.2.cmml" xref="S6.SS2.SSS3.p3.1.m1.11.11.3.2.2.2.1.1.1.2"><csymbol cd="ambiguous" id="S6.SS2.SSS3.p3.1.m1.11.11.3.2.2.2.1.1.1.2.1.cmml" xref="S6.SS2.SSS3.p3.1.m1.11.11.3.2.2.2.1.1.1.2">subscript</csymbol><ci id="S6.SS2.SSS3.p3.1.m1.11.11.3.2.2.2.1.1.1.2.2.cmml" xref="S6.SS2.SSS3.p3.1.m1.11.11.3.2.2.2.1.1.1.2.2">𝐹</ci><ci id="S6.SS2.SSS3.p3.1.m1.11.11.3.2.2.2.1.1.1.2.3.cmml" xref="S6.SS2.SSS3.p3.1.m1.11.11.3.2.2.2.1.1.1.2.3">𝜃</ci></apply><apply id="S6.SS2.SSS3.p3.1.m1.11.11.3.2.2.2.1.1.1.3.cmml" xref="S6.SS2.SSS3.p3.1.m1.11.11.3.2.2.2.1.1.1.3"><csymbol cd="ambiguous" id="S6.SS2.SSS3.p3.1.m1.11.11.3.2.2.2.1.1.1.3.1.cmml" xref="S6.SS2.SSS3.p3.1.m1.11.11.3.2.2.2.1.1.1.3">subscript</csymbol><ci id="S6.SS2.SSS3.p3.1.m1.4.4.cmml" xref="S6.SS2.SSS3.p3.1.m1.4.4">𝑥</ci><ci id="S6.SS2.SSS3.p3.1.m1.11.11.3.2.2.2.1.1.1.3.3.cmml" xref="S6.SS2.SSS3.p3.1.m1.11.11.3.2.2.2.1.1.1.3.3">𝑦</ci></apply></apply></apply></apply></apply><apply id="S6.SS2.SSS3.p3.1.m1.12.12.4.3.cmml" xref="S6.SS2.SSS3.p3.1.m1.12.12.4.3"><apply id="S6.SS2.SSS3.p3.1.m1.12.12.4.3.2.cmml" xref="S6.SS2.SSS3.p3.1.m1.12.12.4.3.2"><csymbol cd="ambiguous" id="S6.SS2.SSS3.p3.1.m1.12.12.4.3.2.1.cmml" xref="S6.SS2.SSS3.p3.1.m1.12.12.4.3.2">subscript</csymbol><sum id="S6.SS2.SSS3.p3.1.m1.12.12.4.3.2.2.cmml" xref="S6.SS2.SSS3.p3.1.m1.12.12.4.3.2.2"></sum><apply id="S6.SS2.SSS3.p3.1.m1.12.12.4.3.2.3.cmml" xref="S6.SS2.SSS3.p3.1.m1.12.12.4.3.2.3"><neq id="S6.SS2.SSS3.p3.1.m1.12.12.4.3.2.3.1.cmml" xref="S6.SS2.SSS3.p3.1.m1.12.12.4.3.2.3.1"></neq><ci id="S6.SS2.SSS3.p3.1.m1.12.12.4.3.2.3.2.cmml" xref="S6.SS2.SSS3.p3.1.m1.12.12.4.3.2.3.2">𝑖</ci><ci id="S6.SS2.SSS3.p3.1.m1.12.12.4.3.2.3.3.cmml" xref="S6.SS2.SSS3.p3.1.m1.12.12.4.3.2.3.3">𝑦</ci></apply></apply><apply id="S6.SS2.SSS3.p3.1.m1.12.12.4.3.1.cmml" xref="S6.SS2.SSS3.p3.1.m1.12.12.4.3.1"><times id="S6.SS2.SSS3.p3.1.m1.12.12.4.3.1.2.cmml" xref="S6.SS2.SSS3.p3.1.m1.12.12.4.3.1.2"></times><apply id="S6.SS2.SSS3.p3.1.m1.12.12.4.3.1.3.cmml" xref="S6.SS2.SSS3.p3.1.m1.12.12.4.3.1.3"><csymbol cd="ambiguous" id="S6.SS2.SSS3.p3.1.m1.12.12.4.3.1.3.1.cmml" xref="S6.SS2.SSS3.p3.1.m1.12.12.4.3.1.3">subscript</csymbol><ci id="S6.SS2.SSS3.p3.1.m1.12.12.4.3.1.3.2.cmml" xref="S6.SS2.SSS3.p3.1.m1.12.12.4.3.1.3.2">𝐹</ci><ci id="S6.SS2.SSS3.p3.1.m1.12.12.4.3.1.3.3.cmml" xref="S6.SS2.SSS3.p3.1.m1.12.12.4.3.1.3.3">𝜃</ci></apply><apply id="S6.SS2.SSS3.p3.1.m1.12.12.4.3.1.4.cmml" xref="S6.SS2.SSS3.p3.1.m1.12.12.4.3.1.4"><csymbol cd="ambiguous" id="S6.SS2.SSS3.p3.1.m1.12.12.4.3.1.4.1.cmml" xref="S6.SS2.SSS3.p3.1.m1.12.12.4.3.1.4">subscript</csymbol><ci id="S6.SS2.SSS3.p3.1.m1.6.6.cmml" xref="S6.SS2.SSS3.p3.1.m1.6.6">𝑥</ci><ci id="S6.SS2.SSS3.p3.1.m1.12.12.4.3.1.4.3.cmml" xref="S6.SS2.SSS3.p3.1.m1.12.12.4.3.1.4.3">𝑖</ci></apply><apply id="S6.SS2.SSS3.p3.1.m1.12.12.4.3.1.1.2.cmml" xref="S6.SS2.SSS3.p3.1.m1.12.12.4.3.1.1.1"><log id="S6.SS2.SSS3.p3.1.m1.8.8.cmml" xref="S6.SS2.SSS3.p3.1.m1.8.8"></log><apply id="S6.SS2.SSS3.p3.1.m1.12.12.4.3.1.1.1.1.1.cmml" xref="S6.SS2.SSS3.p3.1.m1.12.12.4.3.1.1.1.1.1"><minus id="S6.SS2.SSS3.p3.1.m1.12.12.4.3.1.1.1.1.1.1.cmml" xref="S6.SS2.SSS3.p3.1.m1.12.12.4.3.1.1.1.1.1.1"></minus><cn type="integer" id="S6.SS2.SSS3.p3.1.m1.12.12.4.3.1.1.1.1.1.2.cmml" xref="S6.SS2.SSS3.p3.1.m1.12.12.4.3.1.1.1.1.1.2">1</cn><apply id="S6.SS2.SSS3.p3.1.m1.12.12.4.3.1.1.1.1.1.3.cmml" xref="S6.SS2.SSS3.p3.1.m1.12.12.4.3.1.1.1.1.1.3"><times id="S6.SS2.SSS3.p3.1.m1.12.12.4.3.1.1.1.1.1.3.1.cmml" xref="S6.SS2.SSS3.p3.1.m1.12.12.4.3.1.1.1.1.1.3.1"></times><apply id="S6.SS2.SSS3.p3.1.m1.12.12.4.3.1.1.1.1.1.3.2.cmml" xref="S6.SS2.SSS3.p3.1.m1.12.12.4.3.1.1.1.1.1.3.2"><csymbol cd="ambiguous" id="S6.SS2.SSS3.p3.1.m1.12.12.4.3.1.1.1.1.1.3.2.1.cmml" xref="S6.SS2.SSS3.p3.1.m1.12.12.4.3.1.1.1.1.1.3.2">subscript</csymbol><ci id="S6.SS2.SSS3.p3.1.m1.12.12.4.3.1.1.1.1.1.3.2.2.cmml" xref="S6.SS2.SSS3.p3.1.m1.12.12.4.3.1.1.1.1.1.3.2.2">𝐹</ci><ci id="S6.SS2.SSS3.p3.1.m1.12.12.4.3.1.1.1.1.1.3.2.3.cmml" xref="S6.SS2.SSS3.p3.1.m1.12.12.4.3.1.1.1.1.1.3.2.3">𝜃</ci></apply><apply id="S6.SS2.SSS3.p3.1.m1.12.12.4.3.1.1.1.1.1.3.3.cmml" xref="S6.SS2.SSS3.p3.1.m1.12.12.4.3.1.1.1.1.1.3.3"><csymbol cd="ambiguous" id="S6.SS2.SSS3.p3.1.m1.12.12.4.3.1.1.1.1.1.3.3.1.cmml" xref="S6.SS2.SSS3.p3.1.m1.12.12.4.3.1.1.1.1.1.3.3">subscript</csymbol><ci id="S6.SS2.SSS3.p3.1.m1.7.7.cmml" xref="S6.SS2.SSS3.p3.1.m1.7.7">𝑥</ci><ci id="S6.SS2.SSS3.p3.1.m1.12.12.4.3.1.1.1.1.1.3.3.3.cmml" xref="S6.SS2.SSS3.p3.1.m1.12.12.4.3.1.1.1.1.1.3.3.3">𝑖</ci></apply></apply></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.SSS3.p3.1.m1.12c">Mentr(F_{\theta}(x),y)=-(1-F_{\theta}(x)_{y})\log(F_{\theta}(x)_{y})-\sum_{i\neq y}F_{\theta}(x)_{i}\log(1-F_{\theta}(x)_{i})</annotation></semantics></math>.</p>
</div>
<div id="S6.SS2.SSS3.p4" class="ltx_para">
<p id="S6.SS2.SSS3.p4.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citet">Jayaraman et al<span class="ltx_text">.</span> (<a href="#bib.bib67" title="" class="ltx_ref">2021</a>)</cite> suggested one MI attack based on Gaussian noise. The intuition is that for a member instance, the prediction loss should increase after adding random noise. This MI attack adds multiple different random noise to the given instance and count how many times the prediction loss of the noisy instance is higher than the prediction loss of the original instance. The given instance is predicted to be a member if the count is beyond a threshold set by the attacker.</p>
</div>
<div id="S6.SS2.SSS3.p5" class="ltx_para">
<p id="S6.SS2.SSS3.p5.9" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citet">Hui et al<span class="ltx_text">.</span> (<a href="#bib.bib65" title="" class="ltx_ref">2021</a>)</cite> exploits the model’s prediction in a special “set” fashion. The adversary is aware of a set <math id="S6.SS2.SSS3.p5.1.m1.1" class="ltx_Math" alttext="M" display="inline"><semantics id="S6.SS2.SSS3.p5.1.m1.1a"><mi id="S6.SS2.SSS3.p5.1.m1.1.1" xref="S6.SS2.SSS3.p5.1.m1.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S6.SS2.SSS3.p5.1.m1.1b"><ci id="S6.SS2.SSS3.p5.1.m1.1.1.cmml" xref="S6.SS2.SSS3.p5.1.m1.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.SSS3.p5.1.m1.1c">M</annotation></semantics></math> of members, and <math id="S6.SS2.SSS3.p5.2.m2.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S6.SS2.SSS3.p5.2.m2.1a"><mi id="S6.SS2.SSS3.p5.2.m2.1.1" xref="S6.SS2.SSS3.p5.2.m2.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S6.SS2.SSS3.p5.2.m2.1b"><ci id="S6.SS2.SSS3.p5.2.m2.1.1.cmml" xref="S6.SS2.SSS3.p5.2.m2.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.SSS3.p5.2.m2.1c">N</annotation></semantics></math> of non-members, and compute <math id="S6.SS2.SSS3.p5.3.m3.3" class="ltx_Math" alttext="d_{1}=D(M\cup\{x\},N)" display="inline"><semantics id="S6.SS2.SSS3.p5.3.m3.3a"><mrow id="S6.SS2.SSS3.p5.3.m3.3.3" xref="S6.SS2.SSS3.p5.3.m3.3.3.cmml"><msub id="S6.SS2.SSS3.p5.3.m3.3.3.3" xref="S6.SS2.SSS3.p5.3.m3.3.3.3.cmml"><mi id="S6.SS2.SSS3.p5.3.m3.3.3.3.2" xref="S6.SS2.SSS3.p5.3.m3.3.3.3.2.cmml">d</mi><mn id="S6.SS2.SSS3.p5.3.m3.3.3.3.3" xref="S6.SS2.SSS3.p5.3.m3.3.3.3.3.cmml">1</mn></msub><mo id="S6.SS2.SSS3.p5.3.m3.3.3.2" xref="S6.SS2.SSS3.p5.3.m3.3.3.2.cmml">=</mo><mrow id="S6.SS2.SSS3.p5.3.m3.3.3.1" xref="S6.SS2.SSS3.p5.3.m3.3.3.1.cmml"><mi id="S6.SS2.SSS3.p5.3.m3.3.3.1.3" xref="S6.SS2.SSS3.p5.3.m3.3.3.1.3.cmml">D</mi><mo lspace="0em" rspace="0em" id="S6.SS2.SSS3.p5.3.m3.3.3.1.2" xref="S6.SS2.SSS3.p5.3.m3.3.3.1.2.cmml">​</mo><mrow id="S6.SS2.SSS3.p5.3.m3.3.3.1.1.1" xref="S6.SS2.SSS3.p5.3.m3.3.3.1.1.2.cmml"><mo stretchy="false" id="S6.SS2.SSS3.p5.3.m3.3.3.1.1.1.2" xref="S6.SS2.SSS3.p5.3.m3.3.3.1.1.2.cmml">(</mo><mrow id="S6.SS2.SSS3.p5.3.m3.3.3.1.1.1.1" xref="S6.SS2.SSS3.p5.3.m3.3.3.1.1.1.1.cmml"><mi id="S6.SS2.SSS3.p5.3.m3.3.3.1.1.1.1.2" xref="S6.SS2.SSS3.p5.3.m3.3.3.1.1.1.1.2.cmml">M</mi><mo id="S6.SS2.SSS3.p5.3.m3.3.3.1.1.1.1.1" xref="S6.SS2.SSS3.p5.3.m3.3.3.1.1.1.1.1.cmml">∪</mo><mrow id="S6.SS2.SSS3.p5.3.m3.3.3.1.1.1.1.3.2" xref="S6.SS2.SSS3.p5.3.m3.3.3.1.1.1.1.3.1.cmml"><mo stretchy="false" id="S6.SS2.SSS3.p5.3.m3.3.3.1.1.1.1.3.2.1" xref="S6.SS2.SSS3.p5.3.m3.3.3.1.1.1.1.3.1.cmml">{</mo><mi id="S6.SS2.SSS3.p5.3.m3.1.1" xref="S6.SS2.SSS3.p5.3.m3.1.1.cmml">x</mi><mo stretchy="false" id="S6.SS2.SSS3.p5.3.m3.3.3.1.1.1.1.3.2.2" xref="S6.SS2.SSS3.p5.3.m3.3.3.1.1.1.1.3.1.cmml">}</mo></mrow></mrow><mo id="S6.SS2.SSS3.p5.3.m3.3.3.1.1.1.3" xref="S6.SS2.SSS3.p5.3.m3.3.3.1.1.2.cmml">,</mo><mi id="S6.SS2.SSS3.p5.3.m3.2.2" xref="S6.SS2.SSS3.p5.3.m3.2.2.cmml">N</mi><mo stretchy="false" id="S6.SS2.SSS3.p5.3.m3.3.3.1.1.1.4" xref="S6.SS2.SSS3.p5.3.m3.3.3.1.1.2.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S6.SS2.SSS3.p5.3.m3.3b"><apply id="S6.SS2.SSS3.p5.3.m3.3.3.cmml" xref="S6.SS2.SSS3.p5.3.m3.3.3"><eq id="S6.SS2.SSS3.p5.3.m3.3.3.2.cmml" xref="S6.SS2.SSS3.p5.3.m3.3.3.2"></eq><apply id="S6.SS2.SSS3.p5.3.m3.3.3.3.cmml" xref="S6.SS2.SSS3.p5.3.m3.3.3.3"><csymbol cd="ambiguous" id="S6.SS2.SSS3.p5.3.m3.3.3.3.1.cmml" xref="S6.SS2.SSS3.p5.3.m3.3.3.3">subscript</csymbol><ci id="S6.SS2.SSS3.p5.3.m3.3.3.3.2.cmml" xref="S6.SS2.SSS3.p5.3.m3.3.3.3.2">𝑑</ci><cn type="integer" id="S6.SS2.SSS3.p5.3.m3.3.3.3.3.cmml" xref="S6.SS2.SSS3.p5.3.m3.3.3.3.3">1</cn></apply><apply id="S6.SS2.SSS3.p5.3.m3.3.3.1.cmml" xref="S6.SS2.SSS3.p5.3.m3.3.3.1"><times id="S6.SS2.SSS3.p5.3.m3.3.3.1.2.cmml" xref="S6.SS2.SSS3.p5.3.m3.3.3.1.2"></times><ci id="S6.SS2.SSS3.p5.3.m3.3.3.1.3.cmml" xref="S6.SS2.SSS3.p5.3.m3.3.3.1.3">𝐷</ci><interval closure="open" id="S6.SS2.SSS3.p5.3.m3.3.3.1.1.2.cmml" xref="S6.SS2.SSS3.p5.3.m3.3.3.1.1.1"><apply id="S6.SS2.SSS3.p5.3.m3.3.3.1.1.1.1.cmml" xref="S6.SS2.SSS3.p5.3.m3.3.3.1.1.1.1"><union id="S6.SS2.SSS3.p5.3.m3.3.3.1.1.1.1.1.cmml" xref="S6.SS2.SSS3.p5.3.m3.3.3.1.1.1.1.1"></union><ci id="S6.SS2.SSS3.p5.3.m3.3.3.1.1.1.1.2.cmml" xref="S6.SS2.SSS3.p5.3.m3.3.3.1.1.1.1.2">𝑀</ci><set id="S6.SS2.SSS3.p5.3.m3.3.3.1.1.1.1.3.1.cmml" xref="S6.SS2.SSS3.p5.3.m3.3.3.1.1.1.1.3.2"><ci id="S6.SS2.SSS3.p5.3.m3.1.1.cmml" xref="S6.SS2.SSS3.p5.3.m3.1.1">𝑥</ci></set></apply><ci id="S6.SS2.SSS3.p5.3.m3.2.2.cmml" xref="S6.SS2.SSS3.p5.3.m3.2.2">𝑁</ci></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.SSS3.p5.3.m3.3c">d_{1}=D(M\cup\{x\},N)</annotation></semantics></math> and <math id="S6.SS2.SSS3.p5.4.m4.3" class="ltx_Math" alttext="d_{2}=D(M,N\cup\{x\})" display="inline"><semantics id="S6.SS2.SSS3.p5.4.m4.3a"><mrow id="S6.SS2.SSS3.p5.4.m4.3.3" xref="S6.SS2.SSS3.p5.4.m4.3.3.cmml"><msub id="S6.SS2.SSS3.p5.4.m4.3.3.3" xref="S6.SS2.SSS3.p5.4.m4.3.3.3.cmml"><mi id="S6.SS2.SSS3.p5.4.m4.3.3.3.2" xref="S6.SS2.SSS3.p5.4.m4.3.3.3.2.cmml">d</mi><mn id="S6.SS2.SSS3.p5.4.m4.3.3.3.3" xref="S6.SS2.SSS3.p5.4.m4.3.3.3.3.cmml">2</mn></msub><mo id="S6.SS2.SSS3.p5.4.m4.3.3.2" xref="S6.SS2.SSS3.p5.4.m4.3.3.2.cmml">=</mo><mrow id="S6.SS2.SSS3.p5.4.m4.3.3.1" xref="S6.SS2.SSS3.p5.4.m4.3.3.1.cmml"><mi id="S6.SS2.SSS3.p5.4.m4.3.3.1.3" xref="S6.SS2.SSS3.p5.4.m4.3.3.1.3.cmml">D</mi><mo lspace="0em" rspace="0em" id="S6.SS2.SSS3.p5.4.m4.3.3.1.2" xref="S6.SS2.SSS3.p5.4.m4.3.3.1.2.cmml">​</mo><mrow id="S6.SS2.SSS3.p5.4.m4.3.3.1.1.1" xref="S6.SS2.SSS3.p5.4.m4.3.3.1.1.2.cmml"><mo stretchy="false" id="S6.SS2.SSS3.p5.4.m4.3.3.1.1.1.2" xref="S6.SS2.SSS3.p5.4.m4.3.3.1.1.2.cmml">(</mo><mi id="S6.SS2.SSS3.p5.4.m4.2.2" xref="S6.SS2.SSS3.p5.4.m4.2.2.cmml">M</mi><mo id="S6.SS2.SSS3.p5.4.m4.3.3.1.1.1.3" xref="S6.SS2.SSS3.p5.4.m4.3.3.1.1.2.cmml">,</mo><mrow id="S6.SS2.SSS3.p5.4.m4.3.3.1.1.1.1" xref="S6.SS2.SSS3.p5.4.m4.3.3.1.1.1.1.cmml"><mi id="S6.SS2.SSS3.p5.4.m4.3.3.1.1.1.1.2" xref="S6.SS2.SSS3.p5.4.m4.3.3.1.1.1.1.2.cmml">N</mi><mo id="S6.SS2.SSS3.p5.4.m4.3.3.1.1.1.1.1" xref="S6.SS2.SSS3.p5.4.m4.3.3.1.1.1.1.1.cmml">∪</mo><mrow id="S6.SS2.SSS3.p5.4.m4.3.3.1.1.1.1.3.2" xref="S6.SS2.SSS3.p5.4.m4.3.3.1.1.1.1.3.1.cmml"><mo stretchy="false" id="S6.SS2.SSS3.p5.4.m4.3.3.1.1.1.1.3.2.1" xref="S6.SS2.SSS3.p5.4.m4.3.3.1.1.1.1.3.1.cmml">{</mo><mi id="S6.SS2.SSS3.p5.4.m4.1.1" xref="S6.SS2.SSS3.p5.4.m4.1.1.cmml">x</mi><mo stretchy="false" id="S6.SS2.SSS3.p5.4.m4.3.3.1.1.1.1.3.2.2" xref="S6.SS2.SSS3.p5.4.m4.3.3.1.1.1.1.3.1.cmml">}</mo></mrow></mrow><mo stretchy="false" id="S6.SS2.SSS3.p5.4.m4.3.3.1.1.1.4" xref="S6.SS2.SSS3.p5.4.m4.3.3.1.1.2.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S6.SS2.SSS3.p5.4.m4.3b"><apply id="S6.SS2.SSS3.p5.4.m4.3.3.cmml" xref="S6.SS2.SSS3.p5.4.m4.3.3"><eq id="S6.SS2.SSS3.p5.4.m4.3.3.2.cmml" xref="S6.SS2.SSS3.p5.4.m4.3.3.2"></eq><apply id="S6.SS2.SSS3.p5.4.m4.3.3.3.cmml" xref="S6.SS2.SSS3.p5.4.m4.3.3.3"><csymbol cd="ambiguous" id="S6.SS2.SSS3.p5.4.m4.3.3.3.1.cmml" xref="S6.SS2.SSS3.p5.4.m4.3.3.3">subscript</csymbol><ci id="S6.SS2.SSS3.p5.4.m4.3.3.3.2.cmml" xref="S6.SS2.SSS3.p5.4.m4.3.3.3.2">𝑑</ci><cn type="integer" id="S6.SS2.SSS3.p5.4.m4.3.3.3.3.cmml" xref="S6.SS2.SSS3.p5.4.m4.3.3.3.3">2</cn></apply><apply id="S6.SS2.SSS3.p5.4.m4.3.3.1.cmml" xref="S6.SS2.SSS3.p5.4.m4.3.3.1"><times id="S6.SS2.SSS3.p5.4.m4.3.3.1.2.cmml" xref="S6.SS2.SSS3.p5.4.m4.3.3.1.2"></times><ci id="S6.SS2.SSS3.p5.4.m4.3.3.1.3.cmml" xref="S6.SS2.SSS3.p5.4.m4.3.3.1.3">𝐷</ci><interval closure="open" id="S6.SS2.SSS3.p5.4.m4.3.3.1.1.2.cmml" xref="S6.SS2.SSS3.p5.4.m4.3.3.1.1.1"><ci id="S6.SS2.SSS3.p5.4.m4.2.2.cmml" xref="S6.SS2.SSS3.p5.4.m4.2.2">𝑀</ci><apply id="S6.SS2.SSS3.p5.4.m4.3.3.1.1.1.1.cmml" xref="S6.SS2.SSS3.p5.4.m4.3.3.1.1.1.1"><union id="S6.SS2.SSS3.p5.4.m4.3.3.1.1.1.1.1.cmml" xref="S6.SS2.SSS3.p5.4.m4.3.3.1.1.1.1.1"></union><ci id="S6.SS2.SSS3.p5.4.m4.3.3.1.1.1.1.2.cmml" xref="S6.SS2.SSS3.p5.4.m4.3.3.1.1.1.1.2">𝑁</ci><set id="S6.SS2.SSS3.p5.4.m4.3.3.1.1.1.1.3.1.cmml" xref="S6.SS2.SSS3.p5.4.m4.3.3.1.1.1.1.3.2"><ci id="S6.SS2.SSS3.p5.4.m4.1.1.cmml" xref="S6.SS2.SSS3.p5.4.m4.1.1">𝑥</ci></set></apply></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.SSS3.p5.4.m4.3c">d_{2}=D(M,N\cup\{x\})</annotation></semantics></math>, where <math id="S6.SS2.SSS3.p5.5.m5.1" class="ltx_Math" alttext="D" display="inline"><semantics id="S6.SS2.SSS3.p5.5.m5.1a"><mi id="S6.SS2.SSS3.p5.5.m5.1.1" xref="S6.SS2.SSS3.p5.5.m5.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S6.SS2.SSS3.p5.5.m5.1b"><ci id="S6.SS2.SSS3.p5.5.m5.1.1.cmml" xref="S6.SS2.SSS3.p5.5.m5.1.1">𝐷</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.SSS3.p5.5.m5.1c">D</annotation></semantics></math> denotes the <em id="S6.SS2.SSS3.p5.9.1" class="ltx_emph ltx_font_italic">Maximum Mean Discrepancy (MMD)</em> <cite class="ltx_cite ltx_citemacro_citep">(Fortet and Mourier, <a href="#bib.bib50" title="" class="ltx_ref">1953</a>)</cite> of two distributions of features extracted from the prediction vectors. The intuition is that if <math id="S6.SS2.SSS3.p5.6.m6.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S6.SS2.SSS3.p5.6.m6.1a"><mi id="S6.SS2.SSS3.p5.6.m6.1.1" xref="S6.SS2.SSS3.p5.6.m6.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S6.SS2.SSS3.p5.6.m6.1b"><ci id="S6.SS2.SSS3.p5.6.m6.1.1.cmml" xref="S6.SS2.SSS3.p5.6.m6.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.SSS3.p5.6.m6.1c">x</annotation></semantics></math> is a member, then we tend to have <math id="S6.SS2.SSS3.p5.7.m7.1" class="ltx_Math" alttext="d_{1}&gt;d_{2}" display="inline"><semantics id="S6.SS2.SSS3.p5.7.m7.1a"><mrow id="S6.SS2.SSS3.p5.7.m7.1.1" xref="S6.SS2.SSS3.p5.7.m7.1.1.cmml"><msub id="S6.SS2.SSS3.p5.7.m7.1.1.2" xref="S6.SS2.SSS3.p5.7.m7.1.1.2.cmml"><mi id="S6.SS2.SSS3.p5.7.m7.1.1.2.2" xref="S6.SS2.SSS3.p5.7.m7.1.1.2.2.cmml">d</mi><mn id="S6.SS2.SSS3.p5.7.m7.1.1.2.3" xref="S6.SS2.SSS3.p5.7.m7.1.1.2.3.cmml">1</mn></msub><mo id="S6.SS2.SSS3.p5.7.m7.1.1.1" xref="S6.SS2.SSS3.p5.7.m7.1.1.1.cmml">&gt;</mo><msub id="S6.SS2.SSS3.p5.7.m7.1.1.3" xref="S6.SS2.SSS3.p5.7.m7.1.1.3.cmml"><mi id="S6.SS2.SSS3.p5.7.m7.1.1.3.2" xref="S6.SS2.SSS3.p5.7.m7.1.1.3.2.cmml">d</mi><mn id="S6.SS2.SSS3.p5.7.m7.1.1.3.3" xref="S6.SS2.SSS3.p5.7.m7.1.1.3.3.cmml">2</mn></msub></mrow><annotation-xml encoding="MathML-Content" id="S6.SS2.SSS3.p5.7.m7.1b"><apply id="S6.SS2.SSS3.p5.7.m7.1.1.cmml" xref="S6.SS2.SSS3.p5.7.m7.1.1"><gt id="S6.SS2.SSS3.p5.7.m7.1.1.1.cmml" xref="S6.SS2.SSS3.p5.7.m7.1.1.1"></gt><apply id="S6.SS2.SSS3.p5.7.m7.1.1.2.cmml" xref="S6.SS2.SSS3.p5.7.m7.1.1.2"><csymbol cd="ambiguous" id="S6.SS2.SSS3.p5.7.m7.1.1.2.1.cmml" xref="S6.SS2.SSS3.p5.7.m7.1.1.2">subscript</csymbol><ci id="S6.SS2.SSS3.p5.7.m7.1.1.2.2.cmml" xref="S6.SS2.SSS3.p5.7.m7.1.1.2.2">𝑑</ci><cn type="integer" id="S6.SS2.SSS3.p5.7.m7.1.1.2.3.cmml" xref="S6.SS2.SSS3.p5.7.m7.1.1.2.3">1</cn></apply><apply id="S6.SS2.SSS3.p5.7.m7.1.1.3.cmml" xref="S6.SS2.SSS3.p5.7.m7.1.1.3"><csymbol cd="ambiguous" id="S6.SS2.SSS3.p5.7.m7.1.1.3.1.cmml" xref="S6.SS2.SSS3.p5.7.m7.1.1.3">subscript</csymbol><ci id="S6.SS2.SSS3.p5.7.m7.1.1.3.2.cmml" xref="S6.SS2.SSS3.p5.7.m7.1.1.3.2">𝑑</ci><cn type="integer" id="S6.SS2.SSS3.p5.7.m7.1.1.3.3.cmml" xref="S6.SS2.SSS3.p5.7.m7.1.1.3.3">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.SSS3.p5.7.m7.1c">d_{1}&gt;d_{2}</annotation></semantics></math>, and if <math id="S6.SS2.SSS3.p5.8.m8.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S6.SS2.SSS3.p5.8.m8.1a"><mi id="S6.SS2.SSS3.p5.8.m8.1.1" xref="S6.SS2.SSS3.p5.8.m8.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S6.SS2.SSS3.p5.8.m8.1b"><ci id="S6.SS2.SSS3.p5.8.m8.1.1.cmml" xref="S6.SS2.SSS3.p5.8.m8.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.SSS3.p5.8.m8.1c">x</annotation></semantics></math> is non-member, we tend to have <math id="S6.SS2.SSS3.p5.9.m9.1" class="ltx_Math" alttext="d_{1}&lt;d_{2}" display="inline"><semantics id="S6.SS2.SSS3.p5.9.m9.1a"><mrow id="S6.SS2.SSS3.p5.9.m9.1.1" xref="S6.SS2.SSS3.p5.9.m9.1.1.cmml"><msub id="S6.SS2.SSS3.p5.9.m9.1.1.2" xref="S6.SS2.SSS3.p5.9.m9.1.1.2.cmml"><mi id="S6.SS2.SSS3.p5.9.m9.1.1.2.2" xref="S6.SS2.SSS3.p5.9.m9.1.1.2.2.cmml">d</mi><mn id="S6.SS2.SSS3.p5.9.m9.1.1.2.3" xref="S6.SS2.SSS3.p5.9.m9.1.1.2.3.cmml">1</mn></msub><mo id="S6.SS2.SSS3.p5.9.m9.1.1.1" xref="S6.SS2.SSS3.p5.9.m9.1.1.1.cmml">&lt;</mo><msub id="S6.SS2.SSS3.p5.9.m9.1.1.3" xref="S6.SS2.SSS3.p5.9.m9.1.1.3.cmml"><mi id="S6.SS2.SSS3.p5.9.m9.1.1.3.2" xref="S6.SS2.SSS3.p5.9.m9.1.1.3.2.cmml">d</mi><mn id="S6.SS2.SSS3.p5.9.m9.1.1.3.3" xref="S6.SS2.SSS3.p5.9.m9.1.1.3.3.cmml">2</mn></msub></mrow><annotation-xml encoding="MathML-Content" id="S6.SS2.SSS3.p5.9.m9.1b"><apply id="S6.SS2.SSS3.p5.9.m9.1.1.cmml" xref="S6.SS2.SSS3.p5.9.m9.1.1"><lt id="S6.SS2.SSS3.p5.9.m9.1.1.1.cmml" xref="S6.SS2.SSS3.p5.9.m9.1.1.1"></lt><apply id="S6.SS2.SSS3.p5.9.m9.1.1.2.cmml" xref="S6.SS2.SSS3.p5.9.m9.1.1.2"><csymbol cd="ambiguous" id="S6.SS2.SSS3.p5.9.m9.1.1.2.1.cmml" xref="S6.SS2.SSS3.p5.9.m9.1.1.2">subscript</csymbol><ci id="S6.SS2.SSS3.p5.9.m9.1.1.2.2.cmml" xref="S6.SS2.SSS3.p5.9.m9.1.1.2.2">𝑑</ci><cn type="integer" id="S6.SS2.SSS3.p5.9.m9.1.1.2.3.cmml" xref="S6.SS2.SSS3.p5.9.m9.1.1.2.3">1</cn></apply><apply id="S6.SS2.SSS3.p5.9.m9.1.1.3.cmml" xref="S6.SS2.SSS3.p5.9.m9.1.1.3"><csymbol cd="ambiguous" id="S6.SS2.SSS3.p5.9.m9.1.1.3.1.cmml" xref="S6.SS2.SSS3.p5.9.m9.1.1.3">subscript</csymbol><ci id="S6.SS2.SSS3.p5.9.m9.1.1.3.2.cmml" xref="S6.SS2.SSS3.p5.9.m9.1.1.3.2">𝑑</ci><cn type="integer" id="S6.SS2.SSS3.p5.9.m9.1.1.3.3.cmml" xref="S6.SS2.SSS3.p5.9.m9.1.1.3.3">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.SSS3.p5.9.m9.1c">d_{1}&lt;d_{2}</annotation></semantics></math>. This attack only provides predicted membership, which means it is infeasible to evaluate its effectiveness at a low false positive rate.</p>
</div>
</section>
</section>
<section id="S6.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.3. </span>Property Inference Attacks</h3>

<div id="S6.SS3.p1" class="ltx_para">
<p id="S6.SS3.p1.6" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citet">Fredrikson et al<span class="ltx_text">.</span> (<a href="#bib.bib52" title="" class="ltx_ref">2015</a>)</cite> proposed the very first black-box property inference attack where the goal is to infer sensitive attributes of a given target record which is used in the training of a target model. This black box property inference attack assumes that the adversary can obtain the model’s predicted label, has knowledge of all the attributes of a targeted record (including the true label) except the sensitive attribute, has access to the marginal priors of all the attributes, and also to the confusion matrix of the target model (which is usually not known by the attacker). The adversary queries the target model by varying the sensitive attribute and obtains the predicted labels. Assuming that there is <math id="S6.SS3.p1.1.m1.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S6.SS3.p1.1.m1.1a"><mi id="S6.SS3.p1.1.m1.1.1" xref="S6.SS3.p1.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S6.SS3.p1.1.m1.1b"><ci id="S6.SS3.p1.1.m1.1.1.cmml" xref="S6.SS3.p1.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS3.p1.1.m1.1c">k</annotation></semantics></math> different values for the single sensitive attribute that the attacker wants to know, after querying the model multiple times with <math id="S6.SS3.p1.2.m2.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S6.SS3.p1.2.m2.1a"><mi id="S6.SS3.p1.2.m2.1.1" xref="S6.SS3.p1.2.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S6.SS3.p1.2.m2.1b"><ci id="S6.SS3.p1.2.m2.1.1.cmml" xref="S6.SS3.p1.2.m2.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS3.p1.2.m2.1c">k</annotation></semantics></math> different possible values while keeping the other known attributes unchanged, the adversary computes <math id="S6.SS3.p1.3.m3.2" class="ltx_Math" alttext="C(y,y^{\prime})*p_{i}" display="inline"><semantics id="S6.SS3.p1.3.m3.2a"><mrow id="S6.SS3.p1.3.m3.2.2" xref="S6.SS3.p1.3.m3.2.2.cmml"><mrow id="S6.SS3.p1.3.m3.2.2.1" xref="S6.SS3.p1.3.m3.2.2.1.cmml"><mi id="S6.SS3.p1.3.m3.2.2.1.3" xref="S6.SS3.p1.3.m3.2.2.1.3.cmml">C</mi><mo lspace="0em" rspace="0em" id="S6.SS3.p1.3.m3.2.2.1.2" xref="S6.SS3.p1.3.m3.2.2.1.2.cmml">​</mo><mrow id="S6.SS3.p1.3.m3.2.2.1.1.1" xref="S6.SS3.p1.3.m3.2.2.1.1.2.cmml"><mo stretchy="false" id="S6.SS3.p1.3.m3.2.2.1.1.1.2" xref="S6.SS3.p1.3.m3.2.2.1.1.2.cmml">(</mo><mi id="S6.SS3.p1.3.m3.1.1" xref="S6.SS3.p1.3.m3.1.1.cmml">y</mi><mo id="S6.SS3.p1.3.m3.2.2.1.1.1.3" xref="S6.SS3.p1.3.m3.2.2.1.1.2.cmml">,</mo><msup id="S6.SS3.p1.3.m3.2.2.1.1.1.1" xref="S6.SS3.p1.3.m3.2.2.1.1.1.1.cmml"><mi id="S6.SS3.p1.3.m3.2.2.1.1.1.1.2" xref="S6.SS3.p1.3.m3.2.2.1.1.1.1.2.cmml">y</mi><mo id="S6.SS3.p1.3.m3.2.2.1.1.1.1.3" xref="S6.SS3.p1.3.m3.2.2.1.1.1.1.3.cmml">′</mo></msup><mo rspace="0.055em" stretchy="false" id="S6.SS3.p1.3.m3.2.2.1.1.1.4" xref="S6.SS3.p1.3.m3.2.2.1.1.2.cmml">)</mo></mrow></mrow><mo rspace="0.222em" id="S6.SS3.p1.3.m3.2.2.2" xref="S6.SS3.p1.3.m3.2.2.2.cmml">∗</mo><msub id="S6.SS3.p1.3.m3.2.2.3" xref="S6.SS3.p1.3.m3.2.2.3.cmml"><mi id="S6.SS3.p1.3.m3.2.2.3.2" xref="S6.SS3.p1.3.m3.2.2.3.2.cmml">p</mi><mi id="S6.SS3.p1.3.m3.2.2.3.3" xref="S6.SS3.p1.3.m3.2.2.3.3.cmml">i</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S6.SS3.p1.3.m3.2b"><apply id="S6.SS3.p1.3.m3.2.2.cmml" xref="S6.SS3.p1.3.m3.2.2"><times id="S6.SS3.p1.3.m3.2.2.2.cmml" xref="S6.SS3.p1.3.m3.2.2.2"></times><apply id="S6.SS3.p1.3.m3.2.2.1.cmml" xref="S6.SS3.p1.3.m3.2.2.1"><times id="S6.SS3.p1.3.m3.2.2.1.2.cmml" xref="S6.SS3.p1.3.m3.2.2.1.2"></times><ci id="S6.SS3.p1.3.m3.2.2.1.3.cmml" xref="S6.SS3.p1.3.m3.2.2.1.3">𝐶</ci><interval closure="open" id="S6.SS3.p1.3.m3.2.2.1.1.2.cmml" xref="S6.SS3.p1.3.m3.2.2.1.1.1"><ci id="S6.SS3.p1.3.m3.1.1.cmml" xref="S6.SS3.p1.3.m3.1.1">𝑦</ci><apply id="S6.SS3.p1.3.m3.2.2.1.1.1.1.cmml" xref="S6.SS3.p1.3.m3.2.2.1.1.1.1"><csymbol cd="ambiguous" id="S6.SS3.p1.3.m3.2.2.1.1.1.1.1.cmml" xref="S6.SS3.p1.3.m3.2.2.1.1.1.1">superscript</csymbol><ci id="S6.SS3.p1.3.m3.2.2.1.1.1.1.2.cmml" xref="S6.SS3.p1.3.m3.2.2.1.1.1.1.2">𝑦</ci><ci id="S6.SS3.p1.3.m3.2.2.1.1.1.1.3.cmml" xref="S6.SS3.p1.3.m3.2.2.1.1.1.1.3">′</ci></apply></interval></apply><apply id="S6.SS3.p1.3.m3.2.2.3.cmml" xref="S6.SS3.p1.3.m3.2.2.3"><csymbol cd="ambiguous" id="S6.SS3.p1.3.m3.2.2.3.1.cmml" xref="S6.SS3.p1.3.m3.2.2.3">subscript</csymbol><ci id="S6.SS3.p1.3.m3.2.2.3.2.cmml" xref="S6.SS3.p1.3.m3.2.2.3.2">𝑝</ci><ci id="S6.SS3.p1.3.m3.2.2.3.3.cmml" xref="S6.SS3.p1.3.m3.2.2.3.3">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS3.p1.3.m3.2c">C(y,y^{\prime})*p_{i}</annotation></semantics></math> for each possible sensitive attribute value, where <math id="S6.SS3.p1.4.m4.4" class="ltx_Math" alttext="C(y,y^{\prime})=Pr[F(x)=y^{\prime}|y]" display="inline"><semantics id="S6.SS3.p1.4.m4.4a"><mrow id="S6.SS3.p1.4.m4.4.4" xref="S6.SS3.p1.4.m4.4.4.cmml"><mrow id="S6.SS3.p1.4.m4.3.3.1" xref="S6.SS3.p1.4.m4.3.3.1.cmml"><mi id="S6.SS3.p1.4.m4.3.3.1.3" xref="S6.SS3.p1.4.m4.3.3.1.3.cmml">C</mi><mo lspace="0em" rspace="0em" id="S6.SS3.p1.4.m4.3.3.1.2" xref="S6.SS3.p1.4.m4.3.3.1.2.cmml">​</mo><mrow id="S6.SS3.p1.4.m4.3.3.1.1.1" xref="S6.SS3.p1.4.m4.3.3.1.1.2.cmml"><mo stretchy="false" id="S6.SS3.p1.4.m4.3.3.1.1.1.2" xref="S6.SS3.p1.4.m4.3.3.1.1.2.cmml">(</mo><mi id="S6.SS3.p1.4.m4.1.1" xref="S6.SS3.p1.4.m4.1.1.cmml">y</mi><mo id="S6.SS3.p1.4.m4.3.3.1.1.1.3" xref="S6.SS3.p1.4.m4.3.3.1.1.2.cmml">,</mo><msup id="S6.SS3.p1.4.m4.3.3.1.1.1.1" xref="S6.SS3.p1.4.m4.3.3.1.1.1.1.cmml"><mi id="S6.SS3.p1.4.m4.3.3.1.1.1.1.2" xref="S6.SS3.p1.4.m4.3.3.1.1.1.1.2.cmml">y</mi><mo id="S6.SS3.p1.4.m4.3.3.1.1.1.1.3" xref="S6.SS3.p1.4.m4.3.3.1.1.1.1.3.cmml">′</mo></msup><mo stretchy="false" id="S6.SS3.p1.4.m4.3.3.1.1.1.4" xref="S6.SS3.p1.4.m4.3.3.1.1.2.cmml">)</mo></mrow></mrow><mo id="S6.SS3.p1.4.m4.4.4.3" xref="S6.SS3.p1.4.m4.4.4.3.cmml">=</mo><mrow id="S6.SS3.p1.4.m4.4.4.2" xref="S6.SS3.p1.4.m4.4.4.2.cmml"><mi id="S6.SS3.p1.4.m4.4.4.2.3" xref="S6.SS3.p1.4.m4.4.4.2.3.cmml">P</mi><mo lspace="0em" rspace="0em" id="S6.SS3.p1.4.m4.4.4.2.2" xref="S6.SS3.p1.4.m4.4.4.2.2.cmml">​</mo><mi id="S6.SS3.p1.4.m4.4.4.2.4" xref="S6.SS3.p1.4.m4.4.4.2.4.cmml">r</mi><mo lspace="0em" rspace="0em" id="S6.SS3.p1.4.m4.4.4.2.2a" xref="S6.SS3.p1.4.m4.4.4.2.2.cmml">​</mo><mrow id="S6.SS3.p1.4.m4.4.4.2.1.1" xref="S6.SS3.p1.4.m4.4.4.2.1.2.cmml"><mo stretchy="false" id="S6.SS3.p1.4.m4.4.4.2.1.1.2" xref="S6.SS3.p1.4.m4.4.4.2.1.2.1.cmml">[</mo><mrow id="S6.SS3.p1.4.m4.4.4.2.1.1.1" xref="S6.SS3.p1.4.m4.4.4.2.1.1.1.cmml"><mrow id="S6.SS3.p1.4.m4.4.4.2.1.1.1.2" xref="S6.SS3.p1.4.m4.4.4.2.1.1.1.2.cmml"><mi id="S6.SS3.p1.4.m4.4.4.2.1.1.1.2.2" xref="S6.SS3.p1.4.m4.4.4.2.1.1.1.2.2.cmml">F</mi><mo lspace="0em" rspace="0em" id="S6.SS3.p1.4.m4.4.4.2.1.1.1.2.1" xref="S6.SS3.p1.4.m4.4.4.2.1.1.1.2.1.cmml">​</mo><mrow id="S6.SS3.p1.4.m4.4.4.2.1.1.1.2.3.2" xref="S6.SS3.p1.4.m4.4.4.2.1.1.1.2.cmml"><mo stretchy="false" id="S6.SS3.p1.4.m4.4.4.2.1.1.1.2.3.2.1" xref="S6.SS3.p1.4.m4.4.4.2.1.1.1.2.cmml">(</mo><mi id="S6.SS3.p1.4.m4.2.2" xref="S6.SS3.p1.4.m4.2.2.cmml">x</mi><mo stretchy="false" id="S6.SS3.p1.4.m4.4.4.2.1.1.1.2.3.2.2" xref="S6.SS3.p1.4.m4.4.4.2.1.1.1.2.cmml">)</mo></mrow></mrow><mo id="S6.SS3.p1.4.m4.4.4.2.1.1.1.1" xref="S6.SS3.p1.4.m4.4.4.2.1.1.1.1.cmml">=</mo><mrow id="S6.SS3.p1.4.m4.4.4.2.1.1.1.3" xref="S6.SS3.p1.4.m4.4.4.2.1.1.1.3.cmml"><msup id="S6.SS3.p1.4.m4.4.4.2.1.1.1.3.2" xref="S6.SS3.p1.4.m4.4.4.2.1.1.1.3.2.cmml"><mi id="S6.SS3.p1.4.m4.4.4.2.1.1.1.3.2.2" xref="S6.SS3.p1.4.m4.4.4.2.1.1.1.3.2.2.cmml">y</mi><mo id="S6.SS3.p1.4.m4.4.4.2.1.1.1.3.2.3" xref="S6.SS3.p1.4.m4.4.4.2.1.1.1.3.2.3.cmml">′</mo></msup><mo fence="false" id="S6.SS3.p1.4.m4.4.4.2.1.1.1.3.1" xref="S6.SS3.p1.4.m4.4.4.2.1.1.1.3.1.cmml">|</mo><mi id="S6.SS3.p1.4.m4.4.4.2.1.1.1.3.3" xref="S6.SS3.p1.4.m4.4.4.2.1.1.1.3.3.cmml">y</mi></mrow></mrow><mo stretchy="false" id="S6.SS3.p1.4.m4.4.4.2.1.1.3" xref="S6.SS3.p1.4.m4.4.4.2.1.2.1.cmml">]</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S6.SS3.p1.4.m4.4b"><apply id="S6.SS3.p1.4.m4.4.4.cmml" xref="S6.SS3.p1.4.m4.4.4"><eq id="S6.SS3.p1.4.m4.4.4.3.cmml" xref="S6.SS3.p1.4.m4.4.4.3"></eq><apply id="S6.SS3.p1.4.m4.3.3.1.cmml" xref="S6.SS3.p1.4.m4.3.3.1"><times id="S6.SS3.p1.4.m4.3.3.1.2.cmml" xref="S6.SS3.p1.4.m4.3.3.1.2"></times><ci id="S6.SS3.p1.4.m4.3.3.1.3.cmml" xref="S6.SS3.p1.4.m4.3.3.1.3">𝐶</ci><interval closure="open" id="S6.SS3.p1.4.m4.3.3.1.1.2.cmml" xref="S6.SS3.p1.4.m4.3.3.1.1.1"><ci id="S6.SS3.p1.4.m4.1.1.cmml" xref="S6.SS3.p1.4.m4.1.1">𝑦</ci><apply id="S6.SS3.p1.4.m4.3.3.1.1.1.1.cmml" xref="S6.SS3.p1.4.m4.3.3.1.1.1.1"><csymbol cd="ambiguous" id="S6.SS3.p1.4.m4.3.3.1.1.1.1.1.cmml" xref="S6.SS3.p1.4.m4.3.3.1.1.1.1">superscript</csymbol><ci id="S6.SS3.p1.4.m4.3.3.1.1.1.1.2.cmml" xref="S6.SS3.p1.4.m4.3.3.1.1.1.1.2">𝑦</ci><ci id="S6.SS3.p1.4.m4.3.3.1.1.1.1.3.cmml" xref="S6.SS3.p1.4.m4.3.3.1.1.1.1.3">′</ci></apply></interval></apply><apply id="S6.SS3.p1.4.m4.4.4.2.cmml" xref="S6.SS3.p1.4.m4.4.4.2"><times id="S6.SS3.p1.4.m4.4.4.2.2.cmml" xref="S6.SS3.p1.4.m4.4.4.2.2"></times><ci id="S6.SS3.p1.4.m4.4.4.2.3.cmml" xref="S6.SS3.p1.4.m4.4.4.2.3">𝑃</ci><ci id="S6.SS3.p1.4.m4.4.4.2.4.cmml" xref="S6.SS3.p1.4.m4.4.4.2.4">𝑟</ci><apply id="S6.SS3.p1.4.m4.4.4.2.1.2.cmml" xref="S6.SS3.p1.4.m4.4.4.2.1.1"><csymbol cd="latexml" id="S6.SS3.p1.4.m4.4.4.2.1.2.1.cmml" xref="S6.SS3.p1.4.m4.4.4.2.1.1.2">delimited-[]</csymbol><apply id="S6.SS3.p1.4.m4.4.4.2.1.1.1.cmml" xref="S6.SS3.p1.4.m4.4.4.2.1.1.1"><eq id="S6.SS3.p1.4.m4.4.4.2.1.1.1.1.cmml" xref="S6.SS3.p1.4.m4.4.4.2.1.1.1.1"></eq><apply id="S6.SS3.p1.4.m4.4.4.2.1.1.1.2.cmml" xref="S6.SS3.p1.4.m4.4.4.2.1.1.1.2"><times id="S6.SS3.p1.4.m4.4.4.2.1.1.1.2.1.cmml" xref="S6.SS3.p1.4.m4.4.4.2.1.1.1.2.1"></times><ci id="S6.SS3.p1.4.m4.4.4.2.1.1.1.2.2.cmml" xref="S6.SS3.p1.4.m4.4.4.2.1.1.1.2.2">𝐹</ci><ci id="S6.SS3.p1.4.m4.2.2.cmml" xref="S6.SS3.p1.4.m4.2.2">𝑥</ci></apply><apply id="S6.SS3.p1.4.m4.4.4.2.1.1.1.3.cmml" xref="S6.SS3.p1.4.m4.4.4.2.1.1.1.3"><csymbol cd="latexml" id="S6.SS3.p1.4.m4.4.4.2.1.1.1.3.1.cmml" xref="S6.SS3.p1.4.m4.4.4.2.1.1.1.3.1">conditional</csymbol><apply id="S6.SS3.p1.4.m4.4.4.2.1.1.1.3.2.cmml" xref="S6.SS3.p1.4.m4.4.4.2.1.1.1.3.2"><csymbol cd="ambiguous" id="S6.SS3.p1.4.m4.4.4.2.1.1.1.3.2.1.cmml" xref="S6.SS3.p1.4.m4.4.4.2.1.1.1.3.2">superscript</csymbol><ci id="S6.SS3.p1.4.m4.4.4.2.1.1.1.3.2.2.cmml" xref="S6.SS3.p1.4.m4.4.4.2.1.1.1.3.2.2">𝑦</ci><ci id="S6.SS3.p1.4.m4.4.4.2.1.1.1.3.2.3.cmml" xref="S6.SS3.p1.4.m4.4.4.2.1.1.1.3.2.3">′</ci></apply><ci id="S6.SS3.p1.4.m4.4.4.2.1.1.1.3.3.cmml" xref="S6.SS3.p1.4.m4.4.4.2.1.1.1.3.3">𝑦</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS3.p1.4.m4.4c">C(y,y^{\prime})=Pr[F(x)=y^{\prime}|y]</annotation></semantics></math> (which comes from the confusion matrix) and <math id="S6.SS3.p1.5.m5.1" class="ltx_Math" alttext="p_{i}" display="inline"><semantics id="S6.SS3.p1.5.m5.1a"><msub id="S6.SS3.p1.5.m5.1.1" xref="S6.SS3.p1.5.m5.1.1.cmml"><mi id="S6.SS3.p1.5.m5.1.1.2" xref="S6.SS3.p1.5.m5.1.1.2.cmml">p</mi><mi id="S6.SS3.p1.5.m5.1.1.3" xref="S6.SS3.p1.5.m5.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S6.SS3.p1.5.m5.1b"><apply id="S6.SS3.p1.5.m5.1.1.cmml" xref="S6.SS3.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S6.SS3.p1.5.m5.1.1.1.cmml" xref="S6.SS3.p1.5.m5.1.1">subscript</csymbol><ci id="S6.SS3.p1.5.m5.1.1.2.cmml" xref="S6.SS3.p1.5.m5.1.1.2">𝑝</ci><ci id="S6.SS3.p1.5.m5.1.1.3.cmml" xref="S6.SS3.p1.5.m5.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS3.p1.5.m5.1c">p_{i}</annotation></semantics></math>, which is the marginal prior of i-th possible sensitive attribute value. Finally, the attack predicts the sensitive attribute value for which the <math id="S6.SS3.p1.6.m6.2" class="ltx_Math" alttext="C(y,y^{\prime})*p_{i}" display="inline"><semantics id="S6.SS3.p1.6.m6.2a"><mrow id="S6.SS3.p1.6.m6.2.2" xref="S6.SS3.p1.6.m6.2.2.cmml"><mrow id="S6.SS3.p1.6.m6.2.2.1" xref="S6.SS3.p1.6.m6.2.2.1.cmml"><mi id="S6.SS3.p1.6.m6.2.2.1.3" xref="S6.SS3.p1.6.m6.2.2.1.3.cmml">C</mi><mo lspace="0em" rspace="0em" id="S6.SS3.p1.6.m6.2.2.1.2" xref="S6.SS3.p1.6.m6.2.2.1.2.cmml">​</mo><mrow id="S6.SS3.p1.6.m6.2.2.1.1.1" xref="S6.SS3.p1.6.m6.2.2.1.1.2.cmml"><mo stretchy="false" id="S6.SS3.p1.6.m6.2.2.1.1.1.2" xref="S6.SS3.p1.6.m6.2.2.1.1.2.cmml">(</mo><mi id="S6.SS3.p1.6.m6.1.1" xref="S6.SS3.p1.6.m6.1.1.cmml">y</mi><mo id="S6.SS3.p1.6.m6.2.2.1.1.1.3" xref="S6.SS3.p1.6.m6.2.2.1.1.2.cmml">,</mo><msup id="S6.SS3.p1.6.m6.2.2.1.1.1.1" xref="S6.SS3.p1.6.m6.2.2.1.1.1.1.cmml"><mi id="S6.SS3.p1.6.m6.2.2.1.1.1.1.2" xref="S6.SS3.p1.6.m6.2.2.1.1.1.1.2.cmml">y</mi><mo id="S6.SS3.p1.6.m6.2.2.1.1.1.1.3" xref="S6.SS3.p1.6.m6.2.2.1.1.1.1.3.cmml">′</mo></msup><mo rspace="0.055em" stretchy="false" id="S6.SS3.p1.6.m6.2.2.1.1.1.4" xref="S6.SS3.p1.6.m6.2.2.1.1.2.cmml">)</mo></mrow></mrow><mo rspace="0.222em" id="S6.SS3.p1.6.m6.2.2.2" xref="S6.SS3.p1.6.m6.2.2.2.cmml">∗</mo><msub id="S6.SS3.p1.6.m6.2.2.3" xref="S6.SS3.p1.6.m6.2.2.3.cmml"><mi id="S6.SS3.p1.6.m6.2.2.3.2" xref="S6.SS3.p1.6.m6.2.2.3.2.cmml">p</mi><mi id="S6.SS3.p1.6.m6.2.2.3.3" xref="S6.SS3.p1.6.m6.2.2.3.3.cmml">i</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S6.SS3.p1.6.m6.2b"><apply id="S6.SS3.p1.6.m6.2.2.cmml" xref="S6.SS3.p1.6.m6.2.2"><times id="S6.SS3.p1.6.m6.2.2.2.cmml" xref="S6.SS3.p1.6.m6.2.2.2"></times><apply id="S6.SS3.p1.6.m6.2.2.1.cmml" xref="S6.SS3.p1.6.m6.2.2.1"><times id="S6.SS3.p1.6.m6.2.2.1.2.cmml" xref="S6.SS3.p1.6.m6.2.2.1.2"></times><ci id="S6.SS3.p1.6.m6.2.2.1.3.cmml" xref="S6.SS3.p1.6.m6.2.2.1.3">𝐶</ci><interval closure="open" id="S6.SS3.p1.6.m6.2.2.1.1.2.cmml" xref="S6.SS3.p1.6.m6.2.2.1.1.1"><ci id="S6.SS3.p1.6.m6.1.1.cmml" xref="S6.SS3.p1.6.m6.1.1">𝑦</ci><apply id="S6.SS3.p1.6.m6.2.2.1.1.1.1.cmml" xref="S6.SS3.p1.6.m6.2.2.1.1.1.1"><csymbol cd="ambiguous" id="S6.SS3.p1.6.m6.2.2.1.1.1.1.1.cmml" xref="S6.SS3.p1.6.m6.2.2.1.1.1.1">superscript</csymbol><ci id="S6.SS3.p1.6.m6.2.2.1.1.1.1.2.cmml" xref="S6.SS3.p1.6.m6.2.2.1.1.1.1.2">𝑦</ci><ci id="S6.SS3.p1.6.m6.2.2.1.1.1.1.3.cmml" xref="S6.SS3.p1.6.m6.2.2.1.1.1.1.3">′</ci></apply></interval></apply><apply id="S6.SS3.p1.6.m6.2.2.3.cmml" xref="S6.SS3.p1.6.m6.2.2.3"><csymbol cd="ambiguous" id="S6.SS3.p1.6.m6.2.2.3.1.cmml" xref="S6.SS3.p1.6.m6.2.2.3">subscript</csymbol><ci id="S6.SS3.p1.6.m6.2.2.3.2.cmml" xref="S6.SS3.p1.6.m6.2.2.3.2">𝑝</ci><ci id="S6.SS3.p1.6.m6.2.2.3.3.cmml" xref="S6.SS3.p1.6.m6.2.2.3.3">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS3.p1.6.m6.2c">C(y,y^{\prime})*p_{i}</annotation></semantics></math> value is the maximum.</p>
</div>
<div id="S6.SS3.p2" class="ltx_para">
<p id="S6.SS3.p2.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citet">Mehnaz et al<span class="ltx_text">.</span> (<a href="#bib.bib91" title="" class="ltx_ref">2022</a>)</cite> proposed two new attacks: a confidence score based model inversion attribute inference attack and a label-only model inversion attack. The key intuition of the confidence score based attack is that the target model’s returned prediction is more likely to be correct and the confidence score is more likely to be higher when it is queried with a record containing the original sensitive attribute value. Thus, the value that can get correct prediction and yield lowest loss is predicted to be the correct value of the sensitive attribute. For the label-only model inversion attack, the attacker can collect a subset of target samples which satisfy the following conditions: there is only a single value of the sensitive attribute to make the prediction correct. Once this subset is successfully collected, the attacker can train an attack model to predict the value of the sensitive attribute, assuming the collected set is always correct. They also extend our attacks to the scenario where some of the other (non-sensitive) attributes of a target record are unknown to the adversary. Moreover, they empirically demonstrate the disparate vulnerability of model inversion attacks, i.e., specific groups in the training dataset (grouped by gender, race, etc.) could be more vulnerable to model inversion attacks. In  <cite class="ltx_cite ltx_citemacro_citep">(Dibbo et al<span class="ltx_text">.</span>, <a href="#bib.bib40" title="" class="ltx_ref">2023</a>)</cite>, Dibbo et al. refined the method above by proposing a new strategy to collect training data for the attack model. Instead of using real world data, they proposed to use generated random instances and change the value of the sensitive attribute to query the target model. Moreover, for each random instance, it is only accepted when each different sensitive attribute results in a different predicted label. Once this random instance set is gathered, an attack model is trained to predict the sensitive attribute for instances that the attacker is interested in.</p>
</div>
</section>
<section id="S6.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.4. </span>Model Extraction Attacks</h3>

<div id="S6.SS4.p1" class="ltx_para">
<p id="S6.SS4.p1.1" class="ltx_p">In model extraction attacks <cite class="ltx_cite ltx_citemacro_citep">(Oliynyk et al<span class="ltx_text">.</span>, <a href="#bib.bib100" title="" class="ltx_ref">2023</a>; Gong et al<span class="ltx_text">.</span>, <a href="#bib.bib56" title="" class="ltx_ref">2020</a>)</cite>, an attacker can establish a substitute model with almost the same functionalities as the target victim model via simply querying the victim model. While these attacks are not a direct threat to client data privacy in FL, they pose a threat against the server, stealing either the parameters, hyper parameters, architecture, or functionality of the model <cite class="ltx_cite ltx_citemacro_citep">(Tramèr et al<span class="ltx_text">.</span>, <a href="#bib.bib126" title="" class="ltx_ref">2016</a>; Wang and Gong, <a href="#bib.bib128" title="" class="ltx_ref">2018</a>; Orekondy et al<span class="ltx_text">.</span>, <a href="#bib.bib101" title="" class="ltx_ref">2019</a>)</cite>. As such, model extraction attacks serve as a privacy threat for the intellectual property (i.e., the trained model) of a company.
This is a practical impediment to the widespread deployment of FL as the trained model at the server is considered a precious asset. Hence, threats that allow an adversary to steal that asset have to be defended with a high degree of certainty.</p>
</div>
<div id="S6.SS4.p2" class="ltx_para">
<p id="S6.SS4.p2.1" class="ltx_p">Further, model extraction attacks can serve as a springboard to attacks that violate client data privacy. For example, the adversary can use the proxy model created using model extraction to launch attacks that translate well to the original model. Due to the transferability property of such attacks (the attacks against the proxy model are accurate against the original model) <cite class="ltx_cite ltx_citemacro_citep">(Wang and He, <a href="#bib.bib131" title="" class="ltx_ref">2021</a>)</cite>, the adversary can do a membership inference attack to determine which client data items were used in creating the model. This is worrisome as it has been shown recently that the best previous defense of perturbing the results of the query by the adversary as it is trying to construct the proxy model is still vulnerable to model extraction <cite class="ltx_cite ltx_citemacro_citep">(Chen et al<span class="ltx_text">.</span>, <a href="#bib.bib30" title="" class="ltx_ref">2023a</a>)</cite>. The basic idea is that this attack module, which can be integrated with any model extraction attack, can determine the difference in distribution between the unperturbed and perturbed query results and ”reset” that difference.</p>
</div>
</section>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7. </span>Privacy Defenses</h2>

<figure id="S7.T4" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 4. </span> Summary of defenses against privacy attacks in federated learning</figcaption>
<table id="S7.T4.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S7.T4.1.1.1" class="ltx_tr">
<th id="S7.T4.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t"><span id="S7.T4.1.1.1.1.1" class="ltx_text ltx_font_bold">Defense class</span></th>
<th id="S7.T4.1.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t"><span id="S7.T4.1.1.1.2.1" class="ltx_text ltx_font_bold">Summary</span></th>
<th id="S7.T4.1.1.1.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t"><span id="S7.T4.1.1.1.3.1" class="ltx_text ltx_font_bold">Citations</span></th>
<th id="S7.T4.1.1.1.4" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t"><span id="S7.T4.1.1.1.4.1" class="ltx_text ltx_font_bold">Effective against</span></th>
<th id="S7.T4.1.1.1.5" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t"><span id="S7.T4.1.1.1.5.1" class="ltx_text ltx_font_bold">Resources</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S7.T4.1.2.1" class="ltx_tr">
<td id="S7.T4.1.2.1.1" class="ltx_td ltx_align_left ltx_border_t">
<table id="S7.T4.1.2.1.1.1" class="ltx_tabular ltx_align_middle">
<tr id="S7.T4.1.2.1.1.1.1" class="ltx_tr">
<td id="S7.T4.1.2.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Differential</td>
</tr>
<tr id="S7.T4.1.2.1.1.1.2" class="ltx_tr">
<td id="S7.T4.1.2.1.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">privacy</td>
</tr>
</table>
</td>
<td id="S7.T4.1.2.1.2" class="ltx_td ltx_align_left ltx_border_t">
<table id="S7.T4.1.2.1.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S7.T4.1.2.1.2.1.1" class="ltx_tr">
<td id="S7.T4.1.2.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Prevents privacy</td>
</tr>
<tr id="S7.T4.1.2.1.2.1.2" class="ltx_tr">
<td id="S7.T4.1.2.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">leakage of any</td>
</tr>
<tr id="S7.T4.1.2.1.2.1.3" class="ltx_tr">
<td id="S7.T4.1.2.1.2.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left">individual</td>
</tr>
<tr id="S7.T4.1.2.1.2.1.4" class="ltx_tr">
<td id="S7.T4.1.2.1.2.1.4.1" class="ltx_td ltx_nopad_r ltx_align_left">training samples.</td>
</tr>
</table>
</td>
<td id="S7.T4.1.2.1.3" class="ltx_td ltx_align_left ltx_border_t"><cite class="ltx_cite ltx_citemacro_citep">(Dwork, <a href="#bib.bib43" title="" class="ltx_ref">2008</a>; Abadi et al<span class="ltx_text">.</span>, <a href="#bib.bib21" title="" class="ltx_ref">2016</a>; Dong et al<span class="ltx_text">.</span>, <a href="#bib.bib42" title="" class="ltx_ref">2019</a>; Koskela et al<span class="ltx_text">.</span>, <a href="#bib.bib76" title="" class="ltx_ref">2020</a>; Steinke et al<span class="ltx_text">.</span>, <a href="#bib.bib123" title="" class="ltx_ref">2023</a>)</cite></td>
<td id="S7.T4.1.2.1.4" class="ltx_td ltx_align_left ltx_border_t">
<table id="S7.T4.1.2.1.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S7.T4.1.2.1.4.1.1" class="ltx_tr">
<td id="S7.T4.1.2.1.4.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Data reconstruction,</td>
</tr>
<tr id="S7.T4.1.2.1.4.1.2" class="ltx_tr">
<td id="S7.T4.1.2.1.4.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">membership inference</td>
</tr>
<tr id="S7.T4.1.2.1.4.1.3" class="ltx_tr">
<td id="S7.T4.1.2.1.4.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left">Cross-silo and</td>
</tr>
<tr id="S7.T4.1.2.1.4.1.4" class="ltx_tr">
<td id="S7.T4.1.2.1.4.1.4.1" class="ltx_td ltx_nopad_r ltx_align_left">Cross-device</td>
</tr>
</table>
</td>
<td id="S7.T4.1.2.1.5" class="ltx_td ltx_align_left ltx_border_t">
<table id="S7.T4.1.2.1.5.1" class="ltx_tabular ltx_align_middle">
<tr id="S7.T4.1.2.1.5.1.1" class="ltx_tr">
<td id="S7.T4.1.2.1.5.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Clipping and noise</td>
</tr>
<tr id="S7.T4.1.2.1.5.1.2" class="ltx_tr">
<td id="S7.T4.1.2.1.5.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">added to updates</td>
</tr>
<tr id="S7.T4.1.2.1.5.1.3" class="ltx_tr">
<td id="S7.T4.1.2.1.5.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left">based on a privacy</td>
</tr>
<tr id="S7.T4.1.2.1.5.1.4" class="ltx_tr">
<td id="S7.T4.1.2.1.5.1.4.1" class="ltx_td ltx_nopad_r ltx_align_left">budget. Noise</td>
</tr>
<tr id="S7.T4.1.2.1.5.1.5" class="ltx_tr">
<td id="S7.T4.1.2.1.5.1.5.1" class="ltx_td ltx_nopad_r ltx_align_left">injection can be</td>
</tr>
<tr id="S7.T4.1.2.1.5.1.6" class="ltx_tr">
<td id="S7.T4.1.2.1.5.1.6.1" class="ltx_td ltx_nopad_r ltx_align_left">done at each client</td>
</tr>
<tr id="S7.T4.1.2.1.5.1.7" class="ltx_tr">
<td id="S7.T4.1.2.1.5.1.7.1" class="ltx_td ltx_nopad_r ltx_align_left">or at the level of</td>
</tr>
<tr id="S7.T4.1.2.1.5.1.8" class="ltx_tr">
<td id="S7.T4.1.2.1.5.1.8.1" class="ltx_td ltx_nopad_r ltx_align_left">updates aggregated</td>
</tr>
<tr id="S7.T4.1.2.1.5.1.9" class="ltx_tr">
<td id="S7.T4.1.2.1.5.1.9.1" class="ltx_td ltx_nopad_r ltx_align_left">from all clients.</td>
</tr>
</table>
</td>
</tr>
<tr id="S7.T4.1.3.2" class="ltx_tr">
<td id="S7.T4.1.3.2.1" class="ltx_td ltx_align_left ltx_border_t">
<table id="S7.T4.1.3.2.1.1" class="ltx_tabular ltx_align_middle">
<tr id="S7.T4.1.3.2.1.1.1" class="ltx_tr">
<td id="S7.T4.1.3.2.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Secure</td>
</tr>
<tr id="S7.T4.1.3.2.1.1.2" class="ltx_tr">
<td id="S7.T4.1.3.2.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">aggregation</td>
</tr>
</table>
</td>
<td id="S7.T4.1.3.2.2" class="ltx_td ltx_align_left ltx_border_t">
<table id="S7.T4.1.3.2.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S7.T4.1.3.2.2.1.1" class="ltx_tr">
<td id="S7.T4.1.3.2.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Individual updates</td>
</tr>
<tr id="S7.T4.1.3.2.2.1.2" class="ltx_tr">
<td id="S7.T4.1.3.2.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">are encrypted to</td>
</tr>
<tr id="S7.T4.1.3.2.2.1.3" class="ltx_tr">
<td id="S7.T4.1.3.2.2.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left">ensure that a server</td>
</tr>
<tr id="S7.T4.1.3.2.2.1.4" class="ltx_tr">
<td id="S7.T4.1.3.2.2.1.4.1" class="ltx_td ltx_nopad_r ltx_align_left">or any attacker only</td>
</tr>
<tr id="S7.T4.1.3.2.2.1.5" class="ltx_tr">
<td id="S7.T4.1.3.2.2.1.5.1" class="ltx_td ltx_nopad_r ltx_align_left">has access to an</td>
</tr>
<tr id="S7.T4.1.3.2.2.1.6" class="ltx_tr">
<td id="S7.T4.1.3.2.2.1.6.1" class="ltx_td ltx_nopad_r ltx_align_left">unencrypted</td>
</tr>
<tr id="S7.T4.1.3.2.2.1.7" class="ltx_tr">
<td id="S7.T4.1.3.2.2.1.7.1" class="ltx_td ltx_nopad_r ltx_align_left">
<span id="S7.T4.1.3.2.2.1.7.1.1" class="ltx_text ltx_font_italic">aggregate</span> update.</td>
</tr>
</table>
</td>
<td id="S7.T4.1.3.2.3" class="ltx_td ltx_align_left ltx_border_t"><cite class="ltx_cite ltx_citemacro_citep">(Bonawitz et al<span class="ltx_text">.</span>, <a href="#bib.bib24" title="" class="ltx_ref">2017</a>; Bell et al<span class="ltx_text">.</span>, <a href="#bib.bib22" title="" class="ltx_ref">2020</a>; Kadhe et al<span class="ltx_text">.</span>, <a href="#bib.bib70" title="" class="ltx_ref">2020</a>; Zhao and Sun, <a href="#bib.bib150" title="" class="ltx_ref">2022</a>; So et al<span class="ltx_text">.</span>, <a href="#bib.bib121" title="" class="ltx_ref">2022</a>)</cite></td>
<td id="S7.T4.1.3.2.4" class="ltx_td ltx_align_left ltx_border_t">
<table id="S7.T4.1.3.2.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S7.T4.1.3.2.4.1.1" class="ltx_tr">
<td id="S7.T4.1.3.2.4.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Data reconstruction</td>
</tr>
<tr id="S7.T4.1.3.2.4.1.2" class="ltx_tr">
<td id="S7.T4.1.3.2.4.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">Cross-device</td>
</tr>
</table>
</td>
<td id="S7.T4.1.3.2.5" class="ltx_td ltx_align_left ltx_border_t">
<table id="S7.T4.1.3.2.5.1" class="ltx_tabular ltx_align_middle">
<tr id="S7.T4.1.3.2.5.1.1" class="ltx_tr">
<td id="S7.T4.1.3.2.5.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Additional</td>
</tr>
<tr id="S7.T4.1.3.2.5.1.2" class="ltx_tr">
<td id="S7.T4.1.3.2.5.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">communication</td>
</tr>
<tr id="S7.T4.1.3.2.5.1.3" class="ltx_tr">
<td id="S7.T4.1.3.2.5.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left">between clients</td>
</tr>
<tr id="S7.T4.1.3.2.5.1.4" class="ltx_tr">
<td id="S7.T4.1.3.2.5.1.4.1" class="ltx_td ltx_nopad_r ltx_align_left">required to create</td>
</tr>
<tr id="S7.T4.1.3.2.5.1.5" class="ltx_tr">
<td id="S7.T4.1.3.2.5.1.5.1" class="ltx_td ltx_nopad_r ltx_align_left">encryption masks.</td>
</tr>
</table>
</td>
</tr>
<tr id="S7.T4.1.4.3" class="ltx_tr">
<td id="S7.T4.1.4.3.1" class="ltx_td ltx_align_left ltx_border_b ltx_border_t">
<table id="S7.T4.1.4.3.1.1" class="ltx_tabular ltx_align_middle">
<tr id="S7.T4.1.4.3.1.1.1" class="ltx_tr">
<td id="S7.T4.1.4.3.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Homomorphic</td>
</tr>
<tr id="S7.T4.1.4.3.1.1.2" class="ltx_tr">
<td id="S7.T4.1.4.3.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">encryption</td>
</tr>
</table>
</td>
<td id="S7.T4.1.4.3.2" class="ltx_td ltx_align_left ltx_border_b ltx_border_t">
<table id="S7.T4.1.4.3.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S7.T4.1.4.3.2.1.1" class="ltx_tr">
<td id="S7.T4.1.4.3.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Clients send encrypted</td>
</tr>
<tr id="S7.T4.1.4.3.2.1.2" class="ltx_tr">
<td id="S7.T4.1.4.3.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">updates to a server.</td>
</tr>
<tr id="S7.T4.1.4.3.2.1.3" class="ltx_tr">
<td id="S7.T4.1.4.3.2.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left">Certain arithmetic</td>
</tr>
<tr id="S7.T4.1.4.3.2.1.4" class="ltx_tr">
<td id="S7.T4.1.4.3.2.1.4.1" class="ltx_td ltx_nopad_r ltx_align_left">operations can be</td>
</tr>
<tr id="S7.T4.1.4.3.2.1.5" class="ltx_tr">
<td id="S7.T4.1.4.3.2.1.5.1" class="ltx_td ltx_nopad_r ltx_align_left">performed without</td>
</tr>
<tr id="S7.T4.1.4.3.2.1.6" class="ltx_tr">
<td id="S7.T4.1.4.3.2.1.6.1" class="ltx_td ltx_nopad_r ltx_align_left">requiring decryption.</td>
</tr>
<tr id="S7.T4.1.4.3.2.1.7" class="ltx_tr">
<td id="S7.T4.1.4.3.2.1.7.1" class="ltx_td ltx_nopad_r ltx_align_left">Server sends encrypted</td>
</tr>
<tr id="S7.T4.1.4.3.2.1.8" class="ltx_tr">
<td id="S7.T4.1.4.3.2.1.8.1" class="ltx_td ltx_nopad_r ltx_align_left">updated model back to</td>
</tr>
<tr id="S7.T4.1.4.3.2.1.9" class="ltx_tr">
<td id="S7.T4.1.4.3.2.1.9.1" class="ltx_td ltx_nopad_r ltx_align_left">clients. Similar to</td>
</tr>
<tr id="S7.T4.1.4.3.2.1.10" class="ltx_tr">
<td id="S7.T4.1.4.3.2.1.10.1" class="ltx_td ltx_nopad_r ltx_align_left">SA, but the server</td>
</tr>
<tr id="S7.T4.1.4.3.2.1.11" class="ltx_tr">
<td id="S7.T4.1.4.3.2.1.11.1" class="ltx_td ltx_nopad_r ltx_align_left">does not access</td>
</tr>
<tr id="S7.T4.1.4.3.2.1.12" class="ltx_tr">
<td id="S7.T4.1.4.3.2.1.12.1" class="ltx_td ltx_nopad_r ltx_align_left">unencrypted aggregate</td>
</tr>
<tr id="S7.T4.1.4.3.2.1.13" class="ltx_tr">
<td id="S7.T4.1.4.3.2.1.13.1" class="ltx_td ltx_nopad_r ltx_align_left">update.</td>
</tr>
</table>
</td>
<td id="S7.T4.1.4.3.3" class="ltx_td ltx_align_left ltx_border_b ltx_border_t"><cite class="ltx_cite ltx_citemacro_citep">(Cheon et al<span class="ltx_text">.</span>, <a href="#bib.bib34" title="" class="ltx_ref">2017</a>; Zhang et al<span class="ltx_text">.</span>, <a href="#bib.bib142" title="" class="ltx_ref">2020</a>; Fang and Qian, <a href="#bib.bib48" title="" class="ltx_ref">2021</a>)</cite></td>
<td id="S7.T4.1.4.3.4" class="ltx_td ltx_align_left ltx_border_b ltx_border_t">
<table id="S7.T4.1.4.3.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S7.T4.1.4.3.4.1.1" class="ltx_tr">
<td id="S7.T4.1.4.3.4.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Data reconstruction,</td>
</tr>
<tr id="S7.T4.1.4.3.4.1.2" class="ltx_tr">
<td id="S7.T4.1.4.3.4.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">membership inference,</td>
</tr>
<tr id="S7.T4.1.4.3.4.1.3" class="ltx_tr">
<td id="S7.T4.1.4.3.4.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left">property inference</td>
</tr>
<tr id="S7.T4.1.4.3.4.1.4" class="ltx_tr">
<td id="S7.T4.1.4.3.4.1.4.1" class="ltx_td ltx_nopad_r ltx_align_left">Cross-silo</td>
</tr>
</table>
</td>
<td id="S7.T4.1.4.3.5" class="ltx_td ltx_align_left ltx_border_b ltx_border_t">
<table id="S7.T4.1.4.3.5.1" class="ltx_tabular ltx_align_middle">
<tr id="S7.T4.1.4.3.5.1.1" class="ltx_tr">
<td id="S7.T4.1.4.3.5.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Requires large</td>
</tr>
<tr id="S7.T4.1.4.3.5.1.2" class="ltx_tr">
<td id="S7.T4.1.4.3.5.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">communication and</td>
</tr>
<tr id="S7.T4.1.4.3.5.1.3" class="ltx_tr">
<td id="S7.T4.1.4.3.5.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left">computation</td>
</tr>
<tr id="S7.T4.1.4.3.5.1.4" class="ltx_tr">
<td id="S7.T4.1.4.3.5.1.4.1" class="ltx_td ltx_nopad_r ltx_align_left">overhead for clients</td>
</tr>
<tr id="S7.T4.1.4.3.5.1.5" class="ltx_tr">
<td id="S7.T4.1.4.3.5.1.5.1" class="ltx_td ltx_nopad_r ltx_align_left">to encrypt updates</td>
</tr>
<tr id="S7.T4.1.4.3.5.1.6" class="ltx_tr">
<td id="S7.T4.1.4.3.5.1.6.1" class="ltx_td ltx_nopad_r ltx_align_left">and send them to a</td>
</tr>
<tr id="S7.T4.1.4.3.5.1.7" class="ltx_tr">
<td id="S7.T4.1.4.3.5.1.7.1" class="ltx_td ltx_nopad_r ltx_align_left">server. More</td>
</tr>
<tr id="S7.T4.1.4.3.5.1.8" class="ltx_tr">
<td id="S7.T4.1.4.3.5.1.8.1" class="ltx_td ltx_nopad_r ltx_align_left">practical for</td>
</tr>
<tr id="S7.T4.1.4.3.5.1.9" class="ltx_tr">
<td id="S7.T4.1.4.3.5.1.9.1" class="ltx_td ltx_nopad_r ltx_align_left">cross-silo FL.</td>
</tr>
</table>
</td>
</tr>
</tbody>
</table>
</figure>
<section id="S7.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">7.1. </span>Differential Privacy</h3>

<div id="S7.SS1.p1" class="ltx_para">
<p id="S7.SS1.p1.5" class="ltx_p">Differential Privacy (DP) <cite class="ltx_cite ltx_citemacro_citep">(Dwork, <a href="#bib.bib43" title="" class="ltx_ref">2008</a>; Dwork et al<span class="ltx_text">.</span>, <a href="#bib.bib44" title="" class="ltx_ref">2006</a>)</cite> is a widely used privacy-preserving technique. DP based defense techniques, such as DP-SGD <cite class="ltx_cite ltx_citemacro_citep">(Abadi et al<span class="ltx_text">.</span>, <a href="#bib.bib21" title="" class="ltx_ref">2016</a>)</cite>, add noise to the training process. Each iteration of DP-SGD satisfies a particular <math id="S7.SS1.p1.1.m1.2" class="ltx_Math" alttext="(\epsilon,\delta)" display="inline"><semantics id="S7.SS1.p1.1.m1.2a"><mrow id="S7.SS1.p1.1.m1.2.3.2" xref="S7.SS1.p1.1.m1.2.3.1.cmml"><mo stretchy="false" id="S7.SS1.p1.1.m1.2.3.2.1" xref="S7.SS1.p1.1.m1.2.3.1.cmml">(</mo><mi id="S7.SS1.p1.1.m1.1.1" xref="S7.SS1.p1.1.m1.1.1.cmml">ϵ</mi><mo id="S7.SS1.p1.1.m1.2.3.2.2" xref="S7.SS1.p1.1.m1.2.3.1.cmml">,</mo><mi id="S7.SS1.p1.1.m1.2.2" xref="S7.SS1.p1.1.m1.2.2.cmml">δ</mi><mo stretchy="false" id="S7.SS1.p1.1.m1.2.3.2.3" xref="S7.SS1.p1.1.m1.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S7.SS1.p1.1.m1.2b"><interval closure="open" id="S7.SS1.p1.1.m1.2.3.1.cmml" xref="S7.SS1.p1.1.m1.2.3.2"><ci id="S7.SS1.p1.1.m1.1.1.cmml" xref="S7.SS1.p1.1.m1.1.1">italic-ϵ</ci><ci id="S7.SS1.p1.1.m1.2.2.cmml" xref="S7.SS1.p1.1.m1.2.2">𝛿</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="S7.SS1.p1.1.m1.2c">(\epsilon,\delta)</annotation></semantics></math>-DP guarantee through the sub-sampled Gaussian Mechanism - a composition of data sub-sampling and Gaussian noise addition. Since DP is immune to post-processing, we can compose this guarantee over multiple updates to reach a final <math id="S7.SS1.p1.2.m2.2" class="ltx_Math" alttext="(\epsilon,\delta)" display="inline"><semantics id="S7.SS1.p1.2.m2.2a"><mrow id="S7.SS1.p1.2.m2.2.3.2" xref="S7.SS1.p1.2.m2.2.3.1.cmml"><mo stretchy="false" id="S7.SS1.p1.2.m2.2.3.2.1" xref="S7.SS1.p1.2.m2.2.3.1.cmml">(</mo><mi id="S7.SS1.p1.2.m2.1.1" xref="S7.SS1.p1.2.m2.1.1.cmml">ϵ</mi><mo id="S7.SS1.p1.2.m2.2.3.2.2" xref="S7.SS1.p1.2.m2.2.3.1.cmml">,</mo><mi id="S7.SS1.p1.2.m2.2.2" xref="S7.SS1.p1.2.m2.2.2.cmml">δ</mi><mo stretchy="false" id="S7.SS1.p1.2.m2.2.3.2.3" xref="S7.SS1.p1.2.m2.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S7.SS1.p1.2.m2.2b"><interval closure="open" id="S7.SS1.p1.2.m2.2.3.1.cmml" xref="S7.SS1.p1.2.m2.2.3.2"><ci id="S7.SS1.p1.2.m2.1.1.cmml" xref="S7.SS1.p1.2.m2.1.1">italic-ϵ</ci><ci id="S7.SS1.p1.2.m2.2.2.cmml" xref="S7.SS1.p1.2.m2.2.2">𝛿</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="S7.SS1.p1.2.m2.2c">(\epsilon,\delta)</annotation></semantics></math>-DP guarantee. However, a naive composition—by summing the <math id="S7.SS1.p1.3.m3.1" class="ltx_Math" alttext="\epsilon" display="inline"><semantics id="S7.SS1.p1.3.m3.1a"><mi id="S7.SS1.p1.3.m3.1.1" xref="S7.SS1.p1.3.m3.1.1.cmml">ϵ</mi><annotation-xml encoding="MathML-Content" id="S7.SS1.p1.3.m3.1b"><ci id="S7.SS1.p1.3.m3.1.1.cmml" xref="S7.SS1.p1.3.m3.1.1">italic-ϵ</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.SS1.p1.3.m3.1c">\epsilon</annotation></semantics></math>’s from each iteration would give a huge <math id="S7.SS1.p1.4.m4.1" class="ltx_Math" alttext="\epsilon" display="inline"><semantics id="S7.SS1.p1.4.m4.1a"><mi id="S7.SS1.p1.4.m4.1.1" xref="S7.SS1.p1.4.m4.1.1.cmml">ϵ</mi><annotation-xml encoding="MathML-Content" id="S7.SS1.p1.4.m4.1b"><ci id="S7.SS1.p1.4.m4.1.1.cmml" xref="S7.SS1.p1.4.m4.1.1">italic-ϵ</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.SS1.p1.4.m4.1c">\epsilon</annotation></semantics></math> for accurate neural networks. This usually yields a trivial but not meaningful privacy guarantee. As a result, many works have proposed more sophisticated methods for analyzing the composition of DP-SGD iterations, which can prove much tighter values of <math id="S7.SS1.p1.5.m5.1" class="ltx_Math" alttext="\epsilon\leq 10" display="inline"><semantics id="S7.SS1.p1.5.m5.1a"><mrow id="S7.SS1.p1.5.m5.1.1" xref="S7.SS1.p1.5.m5.1.1.cmml"><mi id="S7.SS1.p1.5.m5.1.1.2" xref="S7.SS1.p1.5.m5.1.1.2.cmml">ϵ</mi><mo id="S7.SS1.p1.5.m5.1.1.1" xref="S7.SS1.p1.5.m5.1.1.1.cmml">≤</mo><mn id="S7.SS1.p1.5.m5.1.1.3" xref="S7.SS1.p1.5.m5.1.1.3.cmml">10</mn></mrow><annotation-xml encoding="MathML-Content" id="S7.SS1.p1.5.m5.1b"><apply id="S7.SS1.p1.5.m5.1.1.cmml" xref="S7.SS1.p1.5.m5.1.1"><leq id="S7.SS1.p1.5.m5.1.1.1.cmml" xref="S7.SS1.p1.5.m5.1.1.1"></leq><ci id="S7.SS1.p1.5.m5.1.1.2.cmml" xref="S7.SS1.p1.5.m5.1.1.2">italic-ϵ</ci><cn type="integer" id="S7.SS1.p1.5.m5.1.1.3.cmml" xref="S7.SS1.p1.5.m5.1.1.3">10</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.SS1.p1.5.m5.1c">\epsilon\leq 10</annotation></semantics></math> for the same algorithm <cite class="ltx_cite ltx_citemacro_citep">(Dong et al<span class="ltx_text">.</span>, <a href="#bib.bib42" title="" class="ltx_ref">2019</a>; Koskela et al<span class="ltx_text">.</span>, <a href="#bib.bib76" title="" class="ltx_ref">2020</a>; Mironov, <a href="#bib.bib93" title="" class="ltx_ref">2017</a>)</cite>.
In addition, another line of work for differential privacy based privacy auditing is also crucial to validate that the privacy guarantee is correctly deployed. The most naive method to check if privacy guarantee is enforced requires significant computational resource because even for a single instance the training needs to be reproduced multiple times in order to get enough observation to verify the privacy guarantee.  <cite class="ltx_cite ltx_citemacro_citet">Nasr et al<span class="ltx_text">.</span> (<a href="#bib.bib96" title="" class="ltx_ref">2023</a>)</cite> proposed an auditing method which requires only two runs of model training and the most recent work from  <cite class="ltx_cite ltx_citemacro_citet">Steinke et al<span class="ltx_text">.</span> (<a href="#bib.bib123" title="" class="ltx_ref">2023</a>)</cite> proposed one method which only requires a single run. Existing libraries such as Tensorflow privacy and Tensorflow federated <cite class="ltx_cite ltx_citemacro_citep">(ten, <a href="#bib.bib8" title="" class="ltx_ref">[n. d.]</a>)</cite> already provide implementations of many differential privacy based algorithms. However, practitioners should still be cautious about existing implementations and perform privacy auditing when necessary.</p>
</div>
<div id="S7.SS1.p2" class="ltx_para">
<p id="S7.SS1.p2.2" class="ltx_p">DP based methods can provide a theoretical upper-bound on the effectiveness of any MI attack against any instance. Unfortunately, achieving a meaningful theoretical guarantee (e.g., with a resulting <math id="S7.SS1.p2.1.m1.1" class="ltx_Math" alttext="\epsilon&lt;5" display="inline"><semantics id="S7.SS1.p2.1.m1.1a"><mrow id="S7.SS1.p2.1.m1.1.1" xref="S7.SS1.p2.1.m1.1.1.cmml"><mi id="S7.SS1.p2.1.m1.1.1.2" xref="S7.SS1.p2.1.m1.1.1.2.cmml">ϵ</mi><mo id="S7.SS1.p2.1.m1.1.1.1" xref="S7.SS1.p2.1.m1.1.1.1.cmml">&lt;</mo><mn id="S7.SS1.p2.1.m1.1.1.3" xref="S7.SS1.p2.1.m1.1.1.3.cmml">5</mn></mrow><annotation-xml encoding="MathML-Content" id="S7.SS1.p2.1.m1.1b"><apply id="S7.SS1.p2.1.m1.1.1.cmml" xref="S7.SS1.p2.1.m1.1.1"><lt id="S7.SS1.p2.1.m1.1.1.1.cmml" xref="S7.SS1.p2.1.m1.1.1.1"></lt><ci id="S7.SS1.p2.1.m1.1.1.2.cmml" xref="S7.SS1.p2.1.m1.1.1.2">italic-ϵ</ci><cn type="integer" id="S7.SS1.p2.1.m1.1.1.3.cmml" xref="S7.SS1.p2.1.m1.1.1.3">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.SS1.p2.1.m1.1c">\epsilon&lt;5</annotation></semantics></math>) requires the usage of very large noises and thus resulting a huge utility loss. However, model trainer could use much smaller noises in DP-SGD. While doing this fails to provide a meaningful theoretical guarantee (the <math id="S7.SS1.p2.2.m2.1" class="ltx_Math" alttext="\epsilon" display="inline"><semantics id="S7.SS1.p2.2.m2.1a"><mi id="S7.SS1.p2.2.m2.1.1" xref="S7.SS1.p2.2.m2.1.1.cmml">ϵ</mi><annotation-xml encoding="MathML-Content" id="S7.SS1.p2.2.m2.1b"><ci id="S7.SS1.p2.2.m2.1.1.cmml" xref="S7.SS1.p2.2.m2.1.1">italic-ϵ</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.SS1.p2.2.m2.1c">\epsilon</annotation></semantics></math> value would be too large), this can nonetheless provide empirical defense against MI attacks to protect privacy.</p>
</div>
</section>
<section id="S7.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">7.2. </span>Secure Aggregation</h3>

<div id="S7.SS2.p1" class="ltx_para">
<p id="S7.SS2.p1.1" class="ltx_p">Secure aggregation (SA) <cite class="ltx_cite ltx_citemacro_citep">(Bonawitz et al<span class="ltx_text">.</span>, <a href="#bib.bib24" title="" class="ltx_ref">2017</a>)</cite> enables the server to aggregate local model updates from a number of users, without observing any of their model updates in the clear. Specifically, SA protocols ensure that (1) the server and any set of users do not learn any information about the local dataset of any user from the encrypted model updates in the information theoretic sense; (2) the server only learns the aggregated model; (3) correct decoding of the aggregated model in the presence of users dropout.</p>
</div>
<figure id="S7.F7" class="ltx_figure"><img src="/html/2405.03636/assets/plots-images/secure_agg4.png" id="S7.F7.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="708" height="255" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7. </span>An illustration of SecAgg in the example of 3 users.</figcaption>
</figure>
<div id="S7.SS2.p2" class="ltx_para">
<p id="S7.SS2.p2.15" class="ltx_p">The state-of-the-art for secure aggregation protocols in FL is to use additive masking to protect the privacy of individual models <cite class="ltx_cite ltx_citemacro_citep">(Bonawitz et al<span class="ltx_text">.</span>, <a href="#bib.bib24" title="" class="ltx_ref">2017</a>; Bell et al<span class="ltx_text">.</span>, <a href="#bib.bib22" title="" class="ltx_ref">2020</a>; So et al<span class="ltx_text">.</span>, <a href="#bib.bib118" title="" class="ltx_ref">2021a</a>; Kadhe et al<span class="ltx_text">.</span>, <a href="#bib.bib70" title="" class="ltx_ref">2020</a>; Zhao and Sun, <a href="#bib.bib150" title="" class="ltx_ref">2022</a>; So et al<span class="ltx_text">.</span>, <a href="#bib.bib121" title="" class="ltx_ref">2022</a>, <a href="#bib.bib119" title="" class="ltx_ref">2021b</a>)</cite>. SecAgg <cite class="ltx_cite ltx_citemacro_citep">(Bonawitz et al<span class="ltx_text">.</span>, <a href="#bib.bib24" title="" class="ltx_ref">2017</a>)</cite> is the first practical protocol proposed by Google for FL that is resilient for both user failures or dropouts and collusion between users as well as the server. Particularly, SecAgg as depicted in Figure <a href="#S7.F7" title="Figure 7 ‣ 7.2. Secure Aggregation ‣ 7. Privacy Defenses ‣ Federated Learning Privacy: Attacks, Defenses, Applications, and Policy Landscape — A Survey" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> leverages pairwise random seed <math id="S7.SS2.p2.1.m1.2" class="ltx_Math" alttext="a_{i,j}" display="inline"><semantics id="S7.SS2.p2.1.m1.2a"><msub id="S7.SS2.p2.1.m1.2.3" xref="S7.SS2.p2.1.m1.2.3.cmml"><mi id="S7.SS2.p2.1.m1.2.3.2" xref="S7.SS2.p2.1.m1.2.3.2.cmml">a</mi><mrow id="S7.SS2.p2.1.m1.2.2.2.4" xref="S7.SS2.p2.1.m1.2.2.2.3.cmml"><mi id="S7.SS2.p2.1.m1.1.1.1.1" xref="S7.SS2.p2.1.m1.1.1.1.1.cmml">i</mi><mo id="S7.SS2.p2.1.m1.2.2.2.4.1" xref="S7.SS2.p2.1.m1.2.2.2.3.cmml">,</mo><mi id="S7.SS2.p2.1.m1.2.2.2.2" xref="S7.SS2.p2.1.m1.2.2.2.2.cmml">j</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S7.SS2.p2.1.m1.2b"><apply id="S7.SS2.p2.1.m1.2.3.cmml" xref="S7.SS2.p2.1.m1.2.3"><csymbol cd="ambiguous" id="S7.SS2.p2.1.m1.2.3.1.cmml" xref="S7.SS2.p2.1.m1.2.3">subscript</csymbol><ci id="S7.SS2.p2.1.m1.2.3.2.cmml" xref="S7.SS2.p2.1.m1.2.3.2">𝑎</ci><list id="S7.SS2.p2.1.m1.2.2.2.3.cmml" xref="S7.SS2.p2.1.m1.2.2.2.4"><ci id="S7.SS2.p2.1.m1.1.1.1.1.cmml" xref="S7.SS2.p2.1.m1.1.1.1.1">𝑖</ci><ci id="S7.SS2.p2.1.m1.2.2.2.2.cmml" xref="S7.SS2.p2.1.m1.2.2.2.2">𝑗</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.SS2.p2.1.m1.2c">a_{i,j}</annotation></semantics></math>, for <math id="S7.SS2.p2.2.m2.3" class="ltx_Math" alttext="i,j\in[N]" display="inline"><semantics id="S7.SS2.p2.2.m2.3a"><mrow id="S7.SS2.p2.2.m2.3.4" xref="S7.SS2.p2.2.m2.3.4.cmml"><mrow id="S7.SS2.p2.2.m2.3.4.2.2" xref="S7.SS2.p2.2.m2.3.4.2.1.cmml"><mi id="S7.SS2.p2.2.m2.2.2" xref="S7.SS2.p2.2.m2.2.2.cmml">i</mi><mo id="S7.SS2.p2.2.m2.3.4.2.2.1" xref="S7.SS2.p2.2.m2.3.4.2.1.cmml">,</mo><mi id="S7.SS2.p2.2.m2.3.3" xref="S7.SS2.p2.2.m2.3.3.cmml">j</mi></mrow><mo id="S7.SS2.p2.2.m2.3.4.1" xref="S7.SS2.p2.2.m2.3.4.1.cmml">∈</mo><mrow id="S7.SS2.p2.2.m2.3.4.3.2" xref="S7.SS2.p2.2.m2.3.4.3.1.cmml"><mo stretchy="false" id="S7.SS2.p2.2.m2.3.4.3.2.1" xref="S7.SS2.p2.2.m2.3.4.3.1.1.cmml">[</mo><mi id="S7.SS2.p2.2.m2.1.1" xref="S7.SS2.p2.2.m2.1.1.cmml">N</mi><mo stretchy="false" id="S7.SS2.p2.2.m2.3.4.3.2.2" xref="S7.SS2.p2.2.m2.3.4.3.1.1.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S7.SS2.p2.2.m2.3b"><apply id="S7.SS2.p2.2.m2.3.4.cmml" xref="S7.SS2.p2.2.m2.3.4"><in id="S7.SS2.p2.2.m2.3.4.1.cmml" xref="S7.SS2.p2.2.m2.3.4.1"></in><list id="S7.SS2.p2.2.m2.3.4.2.1.cmml" xref="S7.SS2.p2.2.m2.3.4.2.2"><ci id="S7.SS2.p2.2.m2.2.2.cmml" xref="S7.SS2.p2.2.m2.2.2">𝑖</ci><ci id="S7.SS2.p2.2.m2.3.3.cmml" xref="S7.SS2.p2.2.m2.3.3">𝑗</ci></list><apply id="S7.SS2.p2.2.m2.3.4.3.1.cmml" xref="S7.SS2.p2.2.m2.3.4.3.2"><csymbol cd="latexml" id="S7.SS2.p2.2.m2.3.4.3.1.1.cmml" xref="S7.SS2.p2.2.m2.3.4.3.2.1">delimited-[]</csymbol><ci id="S7.SS2.p2.2.m2.1.1.cmml" xref="S7.SS2.p2.2.m2.1.1">𝑁</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.SS2.p2.2.m2.3c">i,j\in[N]</annotation></semantics></math>, to be generated between each pair of users for masking the model updates. Each pair of users generate the pairwise random seed by using key agreement protocol (e.g., Diffie-Hellman <cite class="ltx_cite ltx_citemacro_citep">(Diffie and Hellman, <a href="#bib.bib41" title="" class="ltx_ref">1976</a>)</cite>), such that the random seed <math id="S7.SS2.p2.3.m3.2" class="ltx_Math" alttext="a_{i,j}" display="inline"><semantics id="S7.SS2.p2.3.m3.2a"><msub id="S7.SS2.p2.3.m3.2.3" xref="S7.SS2.p2.3.m3.2.3.cmml"><mi id="S7.SS2.p2.3.m3.2.3.2" xref="S7.SS2.p2.3.m3.2.3.2.cmml">a</mi><mrow id="S7.SS2.p2.3.m3.2.2.2.4" xref="S7.SS2.p2.3.m3.2.2.2.3.cmml"><mi id="S7.SS2.p2.3.m3.1.1.1.1" xref="S7.SS2.p2.3.m3.1.1.1.1.cmml">i</mi><mo id="S7.SS2.p2.3.m3.2.2.2.4.1" xref="S7.SS2.p2.3.m3.2.2.2.3.cmml">,</mo><mi id="S7.SS2.p2.3.m3.2.2.2.2" xref="S7.SS2.p2.3.m3.2.2.2.2.cmml">j</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S7.SS2.p2.3.m3.2b"><apply id="S7.SS2.p2.3.m3.2.3.cmml" xref="S7.SS2.p2.3.m3.2.3"><csymbol cd="ambiguous" id="S7.SS2.p2.3.m3.2.3.1.cmml" xref="S7.SS2.p2.3.m3.2.3">subscript</csymbol><ci id="S7.SS2.p2.3.m3.2.3.2.cmml" xref="S7.SS2.p2.3.m3.2.3.2">𝑎</ci><list id="S7.SS2.p2.3.m3.2.2.2.3.cmml" xref="S7.SS2.p2.3.m3.2.2.2.4"><ci id="S7.SS2.p2.3.m3.1.1.1.1.cmml" xref="S7.SS2.p2.3.m3.1.1.1.1">𝑖</ci><ci id="S7.SS2.p2.3.m3.2.2.2.2.cmml" xref="S7.SS2.p2.3.m3.2.2.2.2">𝑗</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.SS2.p2.3.m3.2c">a_{i,j}</annotation></semantics></math> is a function of the public key <math id="S7.SS2.p2.4.m4.1" class="ltx_Math" alttext="pk_{i}" display="inline"><semantics id="S7.SS2.p2.4.m4.1a"><mrow id="S7.SS2.p2.4.m4.1.1" xref="S7.SS2.p2.4.m4.1.1.cmml"><mi id="S7.SS2.p2.4.m4.1.1.2" xref="S7.SS2.p2.4.m4.1.1.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S7.SS2.p2.4.m4.1.1.1" xref="S7.SS2.p2.4.m4.1.1.1.cmml">​</mo><msub id="S7.SS2.p2.4.m4.1.1.3" xref="S7.SS2.p2.4.m4.1.1.3.cmml"><mi id="S7.SS2.p2.4.m4.1.1.3.2" xref="S7.SS2.p2.4.m4.1.1.3.2.cmml">k</mi><mi id="S7.SS2.p2.4.m4.1.1.3.3" xref="S7.SS2.p2.4.m4.1.1.3.3.cmml">i</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S7.SS2.p2.4.m4.1b"><apply id="S7.SS2.p2.4.m4.1.1.cmml" xref="S7.SS2.p2.4.m4.1.1"><times id="S7.SS2.p2.4.m4.1.1.1.cmml" xref="S7.SS2.p2.4.m4.1.1.1"></times><ci id="S7.SS2.p2.4.m4.1.1.2.cmml" xref="S7.SS2.p2.4.m4.1.1.2">𝑝</ci><apply id="S7.SS2.p2.4.m4.1.1.3.cmml" xref="S7.SS2.p2.4.m4.1.1.3"><csymbol cd="ambiguous" id="S7.SS2.p2.4.m4.1.1.3.1.cmml" xref="S7.SS2.p2.4.m4.1.1.3">subscript</csymbol><ci id="S7.SS2.p2.4.m4.1.1.3.2.cmml" xref="S7.SS2.p2.4.m4.1.1.3.2">𝑘</ci><ci id="S7.SS2.p2.4.m4.1.1.3.3.cmml" xref="S7.SS2.p2.4.m4.1.1.3.3">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.SS2.p2.4.m4.1c">pk_{i}</annotation></semantics></math> of user <math id="S7.SS2.p2.5.m5.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S7.SS2.p2.5.m5.1a"><mi id="S7.SS2.p2.5.m5.1.1" xref="S7.SS2.p2.5.m5.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S7.SS2.p2.5.m5.1b"><ci id="S7.SS2.p2.5.m5.1.1.cmml" xref="S7.SS2.p2.5.m5.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.SS2.p2.5.m5.1c">i</annotation></semantics></math> and the private key <math id="S7.SS2.p2.6.m6.1" class="ltx_Math" alttext="sk_{j}" display="inline"><semantics id="S7.SS2.p2.6.m6.1a"><mrow id="S7.SS2.p2.6.m6.1.1" xref="S7.SS2.p2.6.m6.1.1.cmml"><mi id="S7.SS2.p2.6.m6.1.1.2" xref="S7.SS2.p2.6.m6.1.1.2.cmml">s</mi><mo lspace="0em" rspace="0em" id="S7.SS2.p2.6.m6.1.1.1" xref="S7.SS2.p2.6.m6.1.1.1.cmml">​</mo><msub id="S7.SS2.p2.6.m6.1.1.3" xref="S7.SS2.p2.6.m6.1.1.3.cmml"><mi id="S7.SS2.p2.6.m6.1.1.3.2" xref="S7.SS2.p2.6.m6.1.1.3.2.cmml">k</mi><mi id="S7.SS2.p2.6.m6.1.1.3.3" xref="S7.SS2.p2.6.m6.1.1.3.3.cmml">j</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S7.SS2.p2.6.m6.1b"><apply id="S7.SS2.p2.6.m6.1.1.cmml" xref="S7.SS2.p2.6.m6.1.1"><times id="S7.SS2.p2.6.m6.1.1.1.cmml" xref="S7.SS2.p2.6.m6.1.1.1"></times><ci id="S7.SS2.p2.6.m6.1.1.2.cmml" xref="S7.SS2.p2.6.m6.1.1.2">𝑠</ci><apply id="S7.SS2.p2.6.m6.1.1.3.cmml" xref="S7.SS2.p2.6.m6.1.1.3"><csymbol cd="ambiguous" id="S7.SS2.p2.6.m6.1.1.3.1.cmml" xref="S7.SS2.p2.6.m6.1.1.3">subscript</csymbol><ci id="S7.SS2.p2.6.m6.1.1.3.2.cmml" xref="S7.SS2.p2.6.m6.1.1.3.2">𝑘</ci><ci id="S7.SS2.p2.6.m6.1.1.3.3.cmml" xref="S7.SS2.p2.6.m6.1.1.3.3">𝑗</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.SS2.p2.6.m6.1c">sk_{j}</annotation></semantics></math> of user <math id="S7.SS2.p2.7.m7.1" class="ltx_Math" alttext="j" display="inline"><semantics id="S7.SS2.p2.7.m7.1a"><mi id="S7.SS2.p2.7.m7.1.1" xref="S7.SS2.p2.7.m7.1.1.cmml">j</mi><annotation-xml encoding="MathML-Content" id="S7.SS2.p2.7.m7.1b"><ci id="S7.SS2.p2.7.m7.1.1.cmml" xref="S7.SS2.p2.7.m7.1.1">𝑗</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.SS2.p2.7.m7.1c">j</annotation></semantics></math>. In addition, user <math id="S7.SS2.p2.8.m8.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S7.SS2.p2.8.m8.1a"><mi id="S7.SS2.p2.8.m8.1.1" xref="S7.SS2.p2.8.m8.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S7.SS2.p2.8.m8.1b"><ci id="S7.SS2.p2.8.m8.1.1.cmml" xref="S7.SS2.p2.8.m8.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.SS2.p2.8.m8.1c">i</annotation></semantics></math> creates a private random seed <math id="S7.SS2.p2.9.m9.1" class="ltx_Math" alttext="b_{i}" display="inline"><semantics id="S7.SS2.p2.9.m9.1a"><msub id="S7.SS2.p2.9.m9.1.1" xref="S7.SS2.p2.9.m9.1.1.cmml"><mi id="S7.SS2.p2.9.m9.1.1.2" xref="S7.SS2.p2.9.m9.1.1.2.cmml">b</mi><mi id="S7.SS2.p2.9.m9.1.1.3" xref="S7.SS2.p2.9.m9.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S7.SS2.p2.9.m9.1b"><apply id="S7.SS2.p2.9.m9.1.1.cmml" xref="S7.SS2.p2.9.m9.1.1"><csymbol cd="ambiguous" id="S7.SS2.p2.9.m9.1.1.1.cmml" xref="S7.SS2.p2.9.m9.1.1">subscript</csymbol><ci id="S7.SS2.p2.9.m9.1.1.2.cmml" xref="S7.SS2.p2.9.m9.1.1.2">𝑏</ci><ci id="S7.SS2.p2.9.m9.1.1.3.cmml" xref="S7.SS2.p2.9.m9.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.SS2.p2.9.m9.1c">b_{i}</annotation></semantics></math> to prevent the privacy breaches that may occur if user <math id="S7.SS2.p2.10.m10.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S7.SS2.p2.10.m10.1a"><mi id="S7.SS2.p2.10.m10.1.1" xref="S7.SS2.p2.10.m10.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S7.SS2.p2.10.m10.1b"><ci id="S7.SS2.p2.10.m10.1.1.cmml" xref="S7.SS2.p2.10.m10.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.SS2.p2.10.m10.1c">i</annotation></semantics></math> is only delayed rather than dropped, in which case the pairwise masks alone are not sufficient for privacy protection. For handling users failures or dropouts, the private key and the private random seed of each user are secret shared among all other users, and can be reconstructed by the server if any user drops during the protocol, which allows for a more resilient recovery protocol against user dropouts. User <math id="S7.SS2.p2.11.m11.1" class="ltx_Math" alttext="i\in[N]" display="inline"><semantics id="S7.SS2.p2.11.m11.1a"><mrow id="S7.SS2.p2.11.m11.1.2" xref="S7.SS2.p2.11.m11.1.2.cmml"><mi id="S7.SS2.p2.11.m11.1.2.2" xref="S7.SS2.p2.11.m11.1.2.2.cmml">i</mi><mo id="S7.SS2.p2.11.m11.1.2.1" xref="S7.SS2.p2.11.m11.1.2.1.cmml">∈</mo><mrow id="S7.SS2.p2.11.m11.1.2.3.2" xref="S7.SS2.p2.11.m11.1.2.3.1.cmml"><mo stretchy="false" id="S7.SS2.p2.11.m11.1.2.3.2.1" xref="S7.SS2.p2.11.m11.1.2.3.1.1.cmml">[</mo><mi id="S7.SS2.p2.11.m11.1.1" xref="S7.SS2.p2.11.m11.1.1.cmml">N</mi><mo stretchy="false" id="S7.SS2.p2.11.m11.1.2.3.2.2" xref="S7.SS2.p2.11.m11.1.2.3.1.1.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S7.SS2.p2.11.m11.1b"><apply id="S7.SS2.p2.11.m11.1.2.cmml" xref="S7.SS2.p2.11.m11.1.2"><in id="S7.SS2.p2.11.m11.1.2.1.cmml" xref="S7.SS2.p2.11.m11.1.2.1"></in><ci id="S7.SS2.p2.11.m11.1.2.2.cmml" xref="S7.SS2.p2.11.m11.1.2.2">𝑖</ci><apply id="S7.SS2.p2.11.m11.1.2.3.1.cmml" xref="S7.SS2.p2.11.m11.1.2.3.2"><csymbol cd="latexml" id="S7.SS2.p2.11.m11.1.2.3.1.1.cmml" xref="S7.SS2.p2.11.m11.1.2.3.2.1">delimited-[]</csymbol><ci id="S7.SS2.p2.11.m11.1.1.cmml" xref="S7.SS2.p2.11.m11.1.1">𝑁</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.SS2.p2.11.m11.1c">i\in[N]</annotation></semantics></math> then masks its model <math id="S7.SS2.p2.12.m12.1" class="ltx_Math" alttext="\mathbf{x}_{i}" display="inline"><semantics id="S7.SS2.p2.12.m12.1a"><msub id="S7.SS2.p2.12.m12.1.1" xref="S7.SS2.p2.12.m12.1.1.cmml"><mi id="S7.SS2.p2.12.m12.1.1.2" xref="S7.SS2.p2.12.m12.1.1.2.cmml">𝐱</mi><mi id="S7.SS2.p2.12.m12.1.1.3" xref="S7.SS2.p2.12.m12.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S7.SS2.p2.12.m12.1b"><apply id="S7.SS2.p2.12.m12.1.1.cmml" xref="S7.SS2.p2.12.m12.1.1"><csymbol cd="ambiguous" id="S7.SS2.p2.12.m12.1.1.1.cmml" xref="S7.SS2.p2.12.m12.1.1">subscript</csymbol><ci id="S7.SS2.p2.12.m12.1.1.2.cmml" xref="S7.SS2.p2.12.m12.1.1.2">𝐱</ci><ci id="S7.SS2.p2.12.m12.1.1.3.cmml" xref="S7.SS2.p2.12.m12.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.SS2.p2.12.m12.1c">\mathbf{x}_{i}</annotation></semantics></math> as <math id="S7.SS2.p2.13.m13.7" class="ltx_Math" alttext="\mathbf{\tilde{x}}_{i}=\mathbf{x}_{i}+\text{PRG}(b_{i})+\sum_{j:i&lt;j}\text{PRG}(a_{i,j})-\sum_{j:i&gt;j}\text{PRG}(a_{j,i})" display="inline"><semantics id="S7.SS2.p2.13.m13.7a"><mrow id="S7.SS2.p2.13.m13.7.7" xref="S7.SS2.p2.13.m13.7.7.cmml"><msub id="S7.SS2.p2.13.m13.7.7.5" xref="S7.SS2.p2.13.m13.7.7.5.cmml"><mover accent="true" id="S7.SS2.p2.13.m13.7.7.5.2" xref="S7.SS2.p2.13.m13.7.7.5.2.cmml"><mi id="S7.SS2.p2.13.m13.7.7.5.2.2" xref="S7.SS2.p2.13.m13.7.7.5.2.2.cmml">𝐱</mi><mo id="S7.SS2.p2.13.m13.7.7.5.2.1" xref="S7.SS2.p2.13.m13.7.7.5.2.1.cmml">~</mo></mover><mi id="S7.SS2.p2.13.m13.7.7.5.3" xref="S7.SS2.p2.13.m13.7.7.5.3.cmml">i</mi></msub><mo id="S7.SS2.p2.13.m13.7.7.4" xref="S7.SS2.p2.13.m13.7.7.4.cmml">=</mo><mrow id="S7.SS2.p2.13.m13.7.7.3" xref="S7.SS2.p2.13.m13.7.7.3.cmml"><mrow id="S7.SS2.p2.13.m13.6.6.2.2" xref="S7.SS2.p2.13.m13.6.6.2.2.cmml"><msub id="S7.SS2.p2.13.m13.6.6.2.2.4" xref="S7.SS2.p2.13.m13.6.6.2.2.4.cmml"><mi id="S7.SS2.p2.13.m13.6.6.2.2.4.2" xref="S7.SS2.p2.13.m13.6.6.2.2.4.2.cmml">𝐱</mi><mi id="S7.SS2.p2.13.m13.6.6.2.2.4.3" xref="S7.SS2.p2.13.m13.6.6.2.2.4.3.cmml">i</mi></msub><mo id="S7.SS2.p2.13.m13.6.6.2.2.3" xref="S7.SS2.p2.13.m13.6.6.2.2.3.cmml">+</mo><mrow id="S7.SS2.p2.13.m13.5.5.1.1.1" xref="S7.SS2.p2.13.m13.5.5.1.1.1.cmml"><mtext id="S7.SS2.p2.13.m13.5.5.1.1.1.3" xref="S7.SS2.p2.13.m13.5.5.1.1.1.3a.cmml">PRG</mtext><mo lspace="0em" rspace="0em" id="S7.SS2.p2.13.m13.5.5.1.1.1.2" xref="S7.SS2.p2.13.m13.5.5.1.1.1.2.cmml">​</mo><mrow id="S7.SS2.p2.13.m13.5.5.1.1.1.1.1" xref="S7.SS2.p2.13.m13.5.5.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S7.SS2.p2.13.m13.5.5.1.1.1.1.1.2" xref="S7.SS2.p2.13.m13.5.5.1.1.1.1.1.1.cmml">(</mo><msub id="S7.SS2.p2.13.m13.5.5.1.1.1.1.1.1" xref="S7.SS2.p2.13.m13.5.5.1.1.1.1.1.1.cmml"><mi id="S7.SS2.p2.13.m13.5.5.1.1.1.1.1.1.2" xref="S7.SS2.p2.13.m13.5.5.1.1.1.1.1.1.2.cmml">b</mi><mi id="S7.SS2.p2.13.m13.5.5.1.1.1.1.1.1.3" xref="S7.SS2.p2.13.m13.5.5.1.1.1.1.1.1.3.cmml">i</mi></msub><mo stretchy="false" id="S7.SS2.p2.13.m13.5.5.1.1.1.1.1.3" xref="S7.SS2.p2.13.m13.5.5.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo rspace="0.055em" id="S7.SS2.p2.13.m13.6.6.2.2.3a" xref="S7.SS2.p2.13.m13.6.6.2.2.3.cmml">+</mo><mrow id="S7.SS2.p2.13.m13.6.6.2.2.2" xref="S7.SS2.p2.13.m13.6.6.2.2.2.cmml"><msub id="S7.SS2.p2.13.m13.6.6.2.2.2.2" xref="S7.SS2.p2.13.m13.6.6.2.2.2.2.cmml"><mo id="S7.SS2.p2.13.m13.6.6.2.2.2.2.2" xref="S7.SS2.p2.13.m13.6.6.2.2.2.2.2.cmml">∑</mo><mrow id="S7.SS2.p2.13.m13.6.6.2.2.2.2.3" xref="S7.SS2.p2.13.m13.6.6.2.2.2.2.3.cmml"><mi id="S7.SS2.p2.13.m13.6.6.2.2.2.2.3.2" xref="S7.SS2.p2.13.m13.6.6.2.2.2.2.3.2.cmml">j</mi><mo lspace="0.278em" rspace="0.278em" id="S7.SS2.p2.13.m13.6.6.2.2.2.2.3.1" xref="S7.SS2.p2.13.m13.6.6.2.2.2.2.3.1.cmml">:</mo><mrow id="S7.SS2.p2.13.m13.6.6.2.2.2.2.3.3" xref="S7.SS2.p2.13.m13.6.6.2.2.2.2.3.3.cmml"><mi id="S7.SS2.p2.13.m13.6.6.2.2.2.2.3.3.2" xref="S7.SS2.p2.13.m13.6.6.2.2.2.2.3.3.2.cmml">i</mi><mo id="S7.SS2.p2.13.m13.6.6.2.2.2.2.3.3.1" xref="S7.SS2.p2.13.m13.6.6.2.2.2.2.3.3.1.cmml">&lt;</mo><mi id="S7.SS2.p2.13.m13.6.6.2.2.2.2.3.3.3" xref="S7.SS2.p2.13.m13.6.6.2.2.2.2.3.3.3.cmml">j</mi></mrow></mrow></msub><mrow id="S7.SS2.p2.13.m13.6.6.2.2.2.1" xref="S7.SS2.p2.13.m13.6.6.2.2.2.1.cmml"><mtext id="S7.SS2.p2.13.m13.6.6.2.2.2.1.3" xref="S7.SS2.p2.13.m13.6.6.2.2.2.1.3a.cmml">PRG</mtext><mo lspace="0em" rspace="0em" id="S7.SS2.p2.13.m13.6.6.2.2.2.1.2" xref="S7.SS2.p2.13.m13.6.6.2.2.2.1.2.cmml">​</mo><mrow id="S7.SS2.p2.13.m13.6.6.2.2.2.1.1.1" xref="S7.SS2.p2.13.m13.6.6.2.2.2.1.1.1.1.cmml"><mo stretchy="false" id="S7.SS2.p2.13.m13.6.6.2.2.2.1.1.1.2" xref="S7.SS2.p2.13.m13.6.6.2.2.2.1.1.1.1.cmml">(</mo><msub id="S7.SS2.p2.13.m13.6.6.2.2.2.1.1.1.1" xref="S7.SS2.p2.13.m13.6.6.2.2.2.1.1.1.1.cmml"><mi id="S7.SS2.p2.13.m13.6.6.2.2.2.1.1.1.1.2" xref="S7.SS2.p2.13.m13.6.6.2.2.2.1.1.1.1.2.cmml">a</mi><mrow id="S7.SS2.p2.13.m13.2.2.2.4" xref="S7.SS2.p2.13.m13.2.2.2.3.cmml"><mi id="S7.SS2.p2.13.m13.1.1.1.1" xref="S7.SS2.p2.13.m13.1.1.1.1.cmml">i</mi><mo id="S7.SS2.p2.13.m13.2.2.2.4.1" xref="S7.SS2.p2.13.m13.2.2.2.3.cmml">,</mo><mi id="S7.SS2.p2.13.m13.2.2.2.2" xref="S7.SS2.p2.13.m13.2.2.2.2.cmml">j</mi></mrow></msub><mo stretchy="false" id="S7.SS2.p2.13.m13.6.6.2.2.2.1.1.1.3" xref="S7.SS2.p2.13.m13.6.6.2.2.2.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow><mo rspace="0.055em" id="S7.SS2.p2.13.m13.7.7.3.4" xref="S7.SS2.p2.13.m13.7.7.3.4.cmml">−</mo><mrow id="S7.SS2.p2.13.m13.7.7.3.3" xref="S7.SS2.p2.13.m13.7.7.3.3.cmml"><msub id="S7.SS2.p2.13.m13.7.7.3.3.2" xref="S7.SS2.p2.13.m13.7.7.3.3.2.cmml"><mo id="S7.SS2.p2.13.m13.7.7.3.3.2.2" xref="S7.SS2.p2.13.m13.7.7.3.3.2.2.cmml">∑</mo><mrow id="S7.SS2.p2.13.m13.7.7.3.3.2.3" xref="S7.SS2.p2.13.m13.7.7.3.3.2.3.cmml"><mi id="S7.SS2.p2.13.m13.7.7.3.3.2.3.2" xref="S7.SS2.p2.13.m13.7.7.3.3.2.3.2.cmml">j</mi><mo lspace="0.278em" rspace="0.278em" id="S7.SS2.p2.13.m13.7.7.3.3.2.3.1" xref="S7.SS2.p2.13.m13.7.7.3.3.2.3.1.cmml">:</mo><mrow id="S7.SS2.p2.13.m13.7.7.3.3.2.3.3" xref="S7.SS2.p2.13.m13.7.7.3.3.2.3.3.cmml"><mi id="S7.SS2.p2.13.m13.7.7.3.3.2.3.3.2" xref="S7.SS2.p2.13.m13.7.7.3.3.2.3.3.2.cmml">i</mi><mo id="S7.SS2.p2.13.m13.7.7.3.3.2.3.3.1" xref="S7.SS2.p2.13.m13.7.7.3.3.2.3.3.1.cmml">&gt;</mo><mi id="S7.SS2.p2.13.m13.7.7.3.3.2.3.3.3" xref="S7.SS2.p2.13.m13.7.7.3.3.2.3.3.3.cmml">j</mi></mrow></mrow></msub><mrow id="S7.SS2.p2.13.m13.7.7.3.3.1" xref="S7.SS2.p2.13.m13.7.7.3.3.1.cmml"><mtext id="S7.SS2.p2.13.m13.7.7.3.3.1.3" xref="S7.SS2.p2.13.m13.7.7.3.3.1.3a.cmml">PRG</mtext><mo lspace="0em" rspace="0em" id="S7.SS2.p2.13.m13.7.7.3.3.1.2" xref="S7.SS2.p2.13.m13.7.7.3.3.1.2.cmml">​</mo><mrow id="S7.SS2.p2.13.m13.7.7.3.3.1.1.1" xref="S7.SS2.p2.13.m13.7.7.3.3.1.1.1.1.cmml"><mo stretchy="false" id="S7.SS2.p2.13.m13.7.7.3.3.1.1.1.2" xref="S7.SS2.p2.13.m13.7.7.3.3.1.1.1.1.cmml">(</mo><msub id="S7.SS2.p2.13.m13.7.7.3.3.1.1.1.1" xref="S7.SS2.p2.13.m13.7.7.3.3.1.1.1.1.cmml"><mi id="S7.SS2.p2.13.m13.7.7.3.3.1.1.1.1.2" xref="S7.SS2.p2.13.m13.7.7.3.3.1.1.1.1.2.cmml">a</mi><mrow id="S7.SS2.p2.13.m13.4.4.2.4" xref="S7.SS2.p2.13.m13.4.4.2.3.cmml"><mi id="S7.SS2.p2.13.m13.3.3.1.1" xref="S7.SS2.p2.13.m13.3.3.1.1.cmml">j</mi><mo id="S7.SS2.p2.13.m13.4.4.2.4.1" xref="S7.SS2.p2.13.m13.4.4.2.3.cmml">,</mo><mi id="S7.SS2.p2.13.m13.4.4.2.2" xref="S7.SS2.p2.13.m13.4.4.2.2.cmml">i</mi></mrow></msub><mo stretchy="false" id="S7.SS2.p2.13.m13.7.7.3.3.1.1.1.3" xref="S7.SS2.p2.13.m13.7.7.3.3.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S7.SS2.p2.13.m13.7b"><apply id="S7.SS2.p2.13.m13.7.7.cmml" xref="S7.SS2.p2.13.m13.7.7"><eq id="S7.SS2.p2.13.m13.7.7.4.cmml" xref="S7.SS2.p2.13.m13.7.7.4"></eq><apply id="S7.SS2.p2.13.m13.7.7.5.cmml" xref="S7.SS2.p2.13.m13.7.7.5"><csymbol cd="ambiguous" id="S7.SS2.p2.13.m13.7.7.5.1.cmml" xref="S7.SS2.p2.13.m13.7.7.5">subscript</csymbol><apply id="S7.SS2.p2.13.m13.7.7.5.2.cmml" xref="S7.SS2.p2.13.m13.7.7.5.2"><ci id="S7.SS2.p2.13.m13.7.7.5.2.1.cmml" xref="S7.SS2.p2.13.m13.7.7.5.2.1">~</ci><ci id="S7.SS2.p2.13.m13.7.7.5.2.2.cmml" xref="S7.SS2.p2.13.m13.7.7.5.2.2">𝐱</ci></apply><ci id="S7.SS2.p2.13.m13.7.7.5.3.cmml" xref="S7.SS2.p2.13.m13.7.7.5.3">𝑖</ci></apply><apply id="S7.SS2.p2.13.m13.7.7.3.cmml" xref="S7.SS2.p2.13.m13.7.7.3"><minus id="S7.SS2.p2.13.m13.7.7.3.4.cmml" xref="S7.SS2.p2.13.m13.7.7.3.4"></minus><apply id="S7.SS2.p2.13.m13.6.6.2.2.cmml" xref="S7.SS2.p2.13.m13.6.6.2.2"><plus id="S7.SS2.p2.13.m13.6.6.2.2.3.cmml" xref="S7.SS2.p2.13.m13.6.6.2.2.3"></plus><apply id="S7.SS2.p2.13.m13.6.6.2.2.4.cmml" xref="S7.SS2.p2.13.m13.6.6.2.2.4"><csymbol cd="ambiguous" id="S7.SS2.p2.13.m13.6.6.2.2.4.1.cmml" xref="S7.SS2.p2.13.m13.6.6.2.2.4">subscript</csymbol><ci id="S7.SS2.p2.13.m13.6.6.2.2.4.2.cmml" xref="S7.SS2.p2.13.m13.6.6.2.2.4.2">𝐱</ci><ci id="S7.SS2.p2.13.m13.6.6.2.2.4.3.cmml" xref="S7.SS2.p2.13.m13.6.6.2.2.4.3">𝑖</ci></apply><apply id="S7.SS2.p2.13.m13.5.5.1.1.1.cmml" xref="S7.SS2.p2.13.m13.5.5.1.1.1"><times id="S7.SS2.p2.13.m13.5.5.1.1.1.2.cmml" xref="S7.SS2.p2.13.m13.5.5.1.1.1.2"></times><ci id="S7.SS2.p2.13.m13.5.5.1.1.1.3a.cmml" xref="S7.SS2.p2.13.m13.5.5.1.1.1.3"><mtext id="S7.SS2.p2.13.m13.5.5.1.1.1.3.cmml" xref="S7.SS2.p2.13.m13.5.5.1.1.1.3">PRG</mtext></ci><apply id="S7.SS2.p2.13.m13.5.5.1.1.1.1.1.1.cmml" xref="S7.SS2.p2.13.m13.5.5.1.1.1.1.1"><csymbol cd="ambiguous" id="S7.SS2.p2.13.m13.5.5.1.1.1.1.1.1.1.cmml" xref="S7.SS2.p2.13.m13.5.5.1.1.1.1.1">subscript</csymbol><ci id="S7.SS2.p2.13.m13.5.5.1.1.1.1.1.1.2.cmml" xref="S7.SS2.p2.13.m13.5.5.1.1.1.1.1.1.2">𝑏</ci><ci id="S7.SS2.p2.13.m13.5.5.1.1.1.1.1.1.3.cmml" xref="S7.SS2.p2.13.m13.5.5.1.1.1.1.1.1.3">𝑖</ci></apply></apply><apply id="S7.SS2.p2.13.m13.6.6.2.2.2.cmml" xref="S7.SS2.p2.13.m13.6.6.2.2.2"><apply id="S7.SS2.p2.13.m13.6.6.2.2.2.2.cmml" xref="S7.SS2.p2.13.m13.6.6.2.2.2.2"><csymbol cd="ambiguous" id="S7.SS2.p2.13.m13.6.6.2.2.2.2.1.cmml" xref="S7.SS2.p2.13.m13.6.6.2.2.2.2">subscript</csymbol><sum id="S7.SS2.p2.13.m13.6.6.2.2.2.2.2.cmml" xref="S7.SS2.p2.13.m13.6.6.2.2.2.2.2"></sum><apply id="S7.SS2.p2.13.m13.6.6.2.2.2.2.3.cmml" xref="S7.SS2.p2.13.m13.6.6.2.2.2.2.3"><ci id="S7.SS2.p2.13.m13.6.6.2.2.2.2.3.1.cmml" xref="S7.SS2.p2.13.m13.6.6.2.2.2.2.3.1">:</ci><ci id="S7.SS2.p2.13.m13.6.6.2.2.2.2.3.2.cmml" xref="S7.SS2.p2.13.m13.6.6.2.2.2.2.3.2">𝑗</ci><apply id="S7.SS2.p2.13.m13.6.6.2.2.2.2.3.3.cmml" xref="S7.SS2.p2.13.m13.6.6.2.2.2.2.3.3"><lt id="S7.SS2.p2.13.m13.6.6.2.2.2.2.3.3.1.cmml" xref="S7.SS2.p2.13.m13.6.6.2.2.2.2.3.3.1"></lt><ci id="S7.SS2.p2.13.m13.6.6.2.2.2.2.3.3.2.cmml" xref="S7.SS2.p2.13.m13.6.6.2.2.2.2.3.3.2">𝑖</ci><ci id="S7.SS2.p2.13.m13.6.6.2.2.2.2.3.3.3.cmml" xref="S7.SS2.p2.13.m13.6.6.2.2.2.2.3.3.3">𝑗</ci></apply></apply></apply><apply id="S7.SS2.p2.13.m13.6.6.2.2.2.1.cmml" xref="S7.SS2.p2.13.m13.6.6.2.2.2.1"><times id="S7.SS2.p2.13.m13.6.6.2.2.2.1.2.cmml" xref="S7.SS2.p2.13.m13.6.6.2.2.2.1.2"></times><ci id="S7.SS2.p2.13.m13.6.6.2.2.2.1.3a.cmml" xref="S7.SS2.p2.13.m13.6.6.2.2.2.1.3"><mtext id="S7.SS2.p2.13.m13.6.6.2.2.2.1.3.cmml" xref="S7.SS2.p2.13.m13.6.6.2.2.2.1.3">PRG</mtext></ci><apply id="S7.SS2.p2.13.m13.6.6.2.2.2.1.1.1.1.cmml" xref="S7.SS2.p2.13.m13.6.6.2.2.2.1.1.1"><csymbol cd="ambiguous" id="S7.SS2.p2.13.m13.6.6.2.2.2.1.1.1.1.1.cmml" xref="S7.SS2.p2.13.m13.6.6.2.2.2.1.1.1">subscript</csymbol><ci id="S7.SS2.p2.13.m13.6.6.2.2.2.1.1.1.1.2.cmml" xref="S7.SS2.p2.13.m13.6.6.2.2.2.1.1.1.1.2">𝑎</ci><list id="S7.SS2.p2.13.m13.2.2.2.3.cmml" xref="S7.SS2.p2.13.m13.2.2.2.4"><ci id="S7.SS2.p2.13.m13.1.1.1.1.cmml" xref="S7.SS2.p2.13.m13.1.1.1.1">𝑖</ci><ci id="S7.SS2.p2.13.m13.2.2.2.2.cmml" xref="S7.SS2.p2.13.m13.2.2.2.2">𝑗</ci></list></apply></apply></apply></apply><apply id="S7.SS2.p2.13.m13.7.7.3.3.cmml" xref="S7.SS2.p2.13.m13.7.7.3.3"><apply id="S7.SS2.p2.13.m13.7.7.3.3.2.cmml" xref="S7.SS2.p2.13.m13.7.7.3.3.2"><csymbol cd="ambiguous" id="S7.SS2.p2.13.m13.7.7.3.3.2.1.cmml" xref="S7.SS2.p2.13.m13.7.7.3.3.2">subscript</csymbol><sum id="S7.SS2.p2.13.m13.7.7.3.3.2.2.cmml" xref="S7.SS2.p2.13.m13.7.7.3.3.2.2"></sum><apply id="S7.SS2.p2.13.m13.7.7.3.3.2.3.cmml" xref="S7.SS2.p2.13.m13.7.7.3.3.2.3"><ci id="S7.SS2.p2.13.m13.7.7.3.3.2.3.1.cmml" xref="S7.SS2.p2.13.m13.7.7.3.3.2.3.1">:</ci><ci id="S7.SS2.p2.13.m13.7.7.3.3.2.3.2.cmml" xref="S7.SS2.p2.13.m13.7.7.3.3.2.3.2">𝑗</ci><apply id="S7.SS2.p2.13.m13.7.7.3.3.2.3.3.cmml" xref="S7.SS2.p2.13.m13.7.7.3.3.2.3.3"><gt id="S7.SS2.p2.13.m13.7.7.3.3.2.3.3.1.cmml" xref="S7.SS2.p2.13.m13.7.7.3.3.2.3.3.1"></gt><ci id="S7.SS2.p2.13.m13.7.7.3.3.2.3.3.2.cmml" xref="S7.SS2.p2.13.m13.7.7.3.3.2.3.3.2">𝑖</ci><ci id="S7.SS2.p2.13.m13.7.7.3.3.2.3.3.3.cmml" xref="S7.SS2.p2.13.m13.7.7.3.3.2.3.3.3">𝑗</ci></apply></apply></apply><apply id="S7.SS2.p2.13.m13.7.7.3.3.1.cmml" xref="S7.SS2.p2.13.m13.7.7.3.3.1"><times id="S7.SS2.p2.13.m13.7.7.3.3.1.2.cmml" xref="S7.SS2.p2.13.m13.7.7.3.3.1.2"></times><ci id="S7.SS2.p2.13.m13.7.7.3.3.1.3a.cmml" xref="S7.SS2.p2.13.m13.7.7.3.3.1.3"><mtext id="S7.SS2.p2.13.m13.7.7.3.3.1.3.cmml" xref="S7.SS2.p2.13.m13.7.7.3.3.1.3">PRG</mtext></ci><apply id="S7.SS2.p2.13.m13.7.7.3.3.1.1.1.1.cmml" xref="S7.SS2.p2.13.m13.7.7.3.3.1.1.1"><csymbol cd="ambiguous" id="S7.SS2.p2.13.m13.7.7.3.3.1.1.1.1.1.cmml" xref="S7.SS2.p2.13.m13.7.7.3.3.1.1.1">subscript</csymbol><ci id="S7.SS2.p2.13.m13.7.7.3.3.1.1.1.1.2.cmml" xref="S7.SS2.p2.13.m13.7.7.3.3.1.1.1.1.2">𝑎</ci><list id="S7.SS2.p2.13.m13.4.4.2.3.cmml" xref="S7.SS2.p2.13.m13.4.4.2.4"><ci id="S7.SS2.p2.13.m13.3.3.1.1.cmml" xref="S7.SS2.p2.13.m13.3.3.1.1">𝑗</ci><ci id="S7.SS2.p2.13.m13.4.4.2.2.cmml" xref="S7.SS2.p2.13.m13.4.4.2.2">𝑖</ci></list></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.SS2.p2.13.m13.7c">\mathbf{\tilde{x}}_{i}=\mathbf{x}_{i}+\text{PRG}(b_{i})+\sum_{j:i&lt;j}\text{PRG}(a_{i,j})-\sum_{j:i&gt;j}\text{PRG}(a_{j,i})</annotation></semantics></math>, where PRG is a pseudo random generator, and sends it to the server. Finally, to remove the masks that involves the dropped users, the server asks the set of survived users for the shares of the private keys of the dropped users and the shares of the private seeds of the survived users. Figure <a href="#S7.F7" title="Figure 7 ‣ 7.2. Secure Aggregation ‣ 7. Privacy Defenses ‣ Federated Learning Privacy: Attacks, Defenses, Applications, and Policy Landscape — A Survey" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> gives an example for applying SA in the FL setting of three users. The cost of constructing and sharing the masks in SecAgg, however, scales with respect to <math id="S7.SS2.p2.14.m14.1" class="ltx_Math" alttext="O(N^{2})" display="inline"><semantics id="S7.SS2.p2.14.m14.1a"><mrow id="S7.SS2.p2.14.m14.1.1" xref="S7.SS2.p2.14.m14.1.1.cmml"><mi id="S7.SS2.p2.14.m14.1.1.3" xref="S7.SS2.p2.14.m14.1.1.3.cmml">O</mi><mo lspace="0em" rspace="0em" id="S7.SS2.p2.14.m14.1.1.2" xref="S7.SS2.p2.14.m14.1.1.2.cmml">​</mo><mrow id="S7.SS2.p2.14.m14.1.1.1.1" xref="S7.SS2.p2.14.m14.1.1.1.1.1.cmml"><mo stretchy="false" id="S7.SS2.p2.14.m14.1.1.1.1.2" xref="S7.SS2.p2.14.m14.1.1.1.1.1.cmml">(</mo><msup id="S7.SS2.p2.14.m14.1.1.1.1.1" xref="S7.SS2.p2.14.m14.1.1.1.1.1.cmml"><mi id="S7.SS2.p2.14.m14.1.1.1.1.1.2" xref="S7.SS2.p2.14.m14.1.1.1.1.1.2.cmml">N</mi><mn id="S7.SS2.p2.14.m14.1.1.1.1.1.3" xref="S7.SS2.p2.14.m14.1.1.1.1.1.3.cmml">2</mn></msup><mo stretchy="false" id="S7.SS2.p2.14.m14.1.1.1.1.3" xref="S7.SS2.p2.14.m14.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S7.SS2.p2.14.m14.1b"><apply id="S7.SS2.p2.14.m14.1.1.cmml" xref="S7.SS2.p2.14.m14.1.1"><times id="S7.SS2.p2.14.m14.1.1.2.cmml" xref="S7.SS2.p2.14.m14.1.1.2"></times><ci id="S7.SS2.p2.14.m14.1.1.3.cmml" xref="S7.SS2.p2.14.m14.1.1.3">𝑂</ci><apply id="S7.SS2.p2.14.m14.1.1.1.1.1.cmml" xref="S7.SS2.p2.14.m14.1.1.1.1"><csymbol cd="ambiguous" id="S7.SS2.p2.14.m14.1.1.1.1.1.1.cmml" xref="S7.SS2.p2.14.m14.1.1.1.1">superscript</csymbol><ci id="S7.SS2.p2.14.m14.1.1.1.1.1.2.cmml" xref="S7.SS2.p2.14.m14.1.1.1.1.1.2">𝑁</ci><cn type="integer" id="S7.SS2.p2.14.m14.1.1.1.1.1.3.cmml" xref="S7.SS2.p2.14.m14.1.1.1.1.1.3">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.SS2.p2.14.m14.1c">O(N^{2})</annotation></semantics></math> with <math id="S7.SS2.p2.15.m15.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S7.SS2.p2.15.m15.1a"><mi id="S7.SS2.p2.15.m15.1.1" xref="S7.SS2.p2.15.m15.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S7.SS2.p2.15.m15.1b"><ci id="S7.SS2.p2.15.m15.1.1.cmml" xref="S7.SS2.p2.15.m15.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.SS2.p2.15.m15.1c">N</annotation></semantics></math> corresponding to the number of users, which takes the majority of execution time.</p>
</div>
<div id="S7.SS2.p3" class="ltx_para">
<p id="S7.SS2.p3.1" class="ltx_p">One active research direction for secure aggregation in FL has been to reduce the complexity of SecAgg. In particular, SecAgg+ <cite class="ltx_cite ltx_citemacro_citep">(Bell et al<span class="ltx_text">.</span>, <a href="#bib.bib22" title="" class="ltx_ref">2020</a>)</cite> and TruboAggregate <cite class="ltx_cite ltx_citemacro_citep">(So et al<span class="ltx_text">.</span>, <a href="#bib.bib120" title="" class="ltx_ref">2021c</a>)</cite> managed to reduce the quadratic complexity of SecAgg to <math id="S7.SS2.p3.1.m1.1" class="ltx_Math" alttext="O(N\log N)" display="inline"><semantics id="S7.SS2.p3.1.m1.1a"><mrow id="S7.SS2.p3.1.m1.1.1" xref="S7.SS2.p3.1.m1.1.1.cmml"><mi id="S7.SS2.p3.1.m1.1.1.3" xref="S7.SS2.p3.1.m1.1.1.3.cmml">O</mi><mo lspace="0em" rspace="0em" id="S7.SS2.p3.1.m1.1.1.2" xref="S7.SS2.p3.1.m1.1.1.2.cmml">​</mo><mrow id="S7.SS2.p3.1.m1.1.1.1.1" xref="S7.SS2.p3.1.m1.1.1.1.1.1.cmml"><mo stretchy="false" id="S7.SS2.p3.1.m1.1.1.1.1.2" xref="S7.SS2.p3.1.m1.1.1.1.1.1.cmml">(</mo><mrow id="S7.SS2.p3.1.m1.1.1.1.1.1" xref="S7.SS2.p3.1.m1.1.1.1.1.1.cmml"><mi id="S7.SS2.p3.1.m1.1.1.1.1.1.2" xref="S7.SS2.p3.1.m1.1.1.1.1.1.2.cmml">N</mi><mo lspace="0.167em" rspace="0em" id="S7.SS2.p3.1.m1.1.1.1.1.1.1" xref="S7.SS2.p3.1.m1.1.1.1.1.1.1.cmml">​</mo><mrow id="S7.SS2.p3.1.m1.1.1.1.1.1.3" xref="S7.SS2.p3.1.m1.1.1.1.1.1.3.cmml"><mi id="S7.SS2.p3.1.m1.1.1.1.1.1.3.1" xref="S7.SS2.p3.1.m1.1.1.1.1.1.3.1.cmml">log</mi><mo lspace="0.167em" id="S7.SS2.p3.1.m1.1.1.1.1.1.3a" xref="S7.SS2.p3.1.m1.1.1.1.1.1.3.cmml">⁡</mo><mi id="S7.SS2.p3.1.m1.1.1.1.1.1.3.2" xref="S7.SS2.p3.1.m1.1.1.1.1.1.3.2.cmml">N</mi></mrow></mrow><mo stretchy="false" id="S7.SS2.p3.1.m1.1.1.1.1.3" xref="S7.SS2.p3.1.m1.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S7.SS2.p3.1.m1.1b"><apply id="S7.SS2.p3.1.m1.1.1.cmml" xref="S7.SS2.p3.1.m1.1.1"><times id="S7.SS2.p3.1.m1.1.1.2.cmml" xref="S7.SS2.p3.1.m1.1.1.2"></times><ci id="S7.SS2.p3.1.m1.1.1.3.cmml" xref="S7.SS2.p3.1.m1.1.1.3">𝑂</ci><apply id="S7.SS2.p3.1.m1.1.1.1.1.1.cmml" xref="S7.SS2.p3.1.m1.1.1.1.1"><times id="S7.SS2.p3.1.m1.1.1.1.1.1.1.cmml" xref="S7.SS2.p3.1.m1.1.1.1.1.1.1"></times><ci id="S7.SS2.p3.1.m1.1.1.1.1.1.2.cmml" xref="S7.SS2.p3.1.m1.1.1.1.1.1.2">𝑁</ci><apply id="S7.SS2.p3.1.m1.1.1.1.1.1.3.cmml" xref="S7.SS2.p3.1.m1.1.1.1.1.1.3"><log id="S7.SS2.p3.1.m1.1.1.1.1.1.3.1.cmml" xref="S7.SS2.p3.1.m1.1.1.1.1.1.3.1"></log><ci id="S7.SS2.p3.1.m1.1.1.1.1.1.3.2.cmml" xref="S7.SS2.p3.1.m1.1.1.1.1.1.3.2">𝑁</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.SS2.p3.1.m1.1c">O(N\log N)</annotation></semantics></math>. TruboAggregate leverages both sequential training over groups of rings and lagrange coded computing <cite class="ltx_cite ltx_citemacro_citep">(Yu et al<span class="ltx_text">.</span>, <a href="#bib.bib140" title="" class="ltx_ref">2019</a>)</cite>, while SecAgg+ leverages a sparse random graph where each user jointly encodes its model update with only a subset of user. However, the cost of mask reconstructions in SecAgg+ still increases as more users drop, while TruboAggregate results in increasing the round/communication complexity. There have been other secure aggregation protocols proposed to
reduce the computation/communication complexity of SecAgg <cite class="ltx_cite ltx_citemacro_citep">(Kadhe et al<span class="ltx_text">.</span>, <a href="#bib.bib70" title="" class="ltx_ref">2020</a>; Zhao and Sun, <a href="#bib.bib150" title="" class="ltx_ref">2022</a>; Jahani-Nezhad et al<span class="ltx_text">.</span>, <a href="#bib.bib66" title="" class="ltx_ref">2022</a>)</cite>.</p>
</div>
<figure id="S7.F8" class="ltx_figure"><img src="/html/2405.03636/assets/plots-images/LightSec.png" id="S7.F8.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="641" height="235" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 8. </span>An illustration of LightSecAgg in the example of 3 users.</figcaption>
</figure>
<div id="S7.SS2.p4" class="ltx_para">
<p id="S7.SS2.p4.5" class="ltx_p">Recently, <cite class="ltx_cite ltx_citemacro_citep">(So et al<span class="ltx_text">.</span>, <a href="#bib.bib121" title="" class="ltx_ref">2022</a>)</cite> reduced the overhead of model aggregation in SecAgg by proposing LightSecAgg that relies on using private Maximum Distance Separable (MDS) codes <cite class="ltx_cite ltx_citemacro_citep">(Roth and Lempel, <a href="#bib.bib111" title="" class="ltx_ref">1989</a>; Yu et al<span class="ltx_text">.</span>, <a href="#bib.bib140" title="" class="ltx_ref">2019</a>; Tang et al<span class="ltx_text">.</span>, <a href="#bib.bib124" title="" class="ltx_ref">2021</a>)</cite>. The reduction in complexity achieved by LightSecAgg is based on using one-shot aggregate-mask reconstruction of the surviving users instead of pairwise random-seed reconstruction of the dropped users that reduces the reconstruction complexity to <math id="S7.SS2.p4.1.m1.1" class="ltx_Math" alttext="O(\log N)" display="inline"><semantics id="S7.SS2.p4.1.m1.1a"><mrow id="S7.SS2.p4.1.m1.1.1" xref="S7.SS2.p4.1.m1.1.1.cmml"><mi id="S7.SS2.p4.1.m1.1.1.3" xref="S7.SS2.p4.1.m1.1.1.3.cmml">O</mi><mo lspace="0em" rspace="0em" id="S7.SS2.p4.1.m1.1.1.2" xref="S7.SS2.p4.1.m1.1.1.2.cmml">​</mo><mrow id="S7.SS2.p4.1.m1.1.1.1.1" xref="S7.SS2.p4.1.m1.1.1.1.1.1.cmml"><mo stretchy="false" id="S7.SS2.p4.1.m1.1.1.1.1.2" xref="S7.SS2.p4.1.m1.1.1.1.1.1.cmml">(</mo><mrow id="S7.SS2.p4.1.m1.1.1.1.1.1" xref="S7.SS2.p4.1.m1.1.1.1.1.1.cmml"><mi id="S7.SS2.p4.1.m1.1.1.1.1.1.1" xref="S7.SS2.p4.1.m1.1.1.1.1.1.1.cmml">log</mi><mo lspace="0.167em" id="S7.SS2.p4.1.m1.1.1.1.1.1a" xref="S7.SS2.p4.1.m1.1.1.1.1.1.cmml">⁡</mo><mi id="S7.SS2.p4.1.m1.1.1.1.1.1.2" xref="S7.SS2.p4.1.m1.1.1.1.1.1.2.cmml">N</mi></mrow><mo stretchy="false" id="S7.SS2.p4.1.m1.1.1.1.1.3" xref="S7.SS2.p4.1.m1.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S7.SS2.p4.1.m1.1b"><apply id="S7.SS2.p4.1.m1.1.1.cmml" xref="S7.SS2.p4.1.m1.1.1"><times id="S7.SS2.p4.1.m1.1.1.2.cmml" xref="S7.SS2.p4.1.m1.1.1.2"></times><ci id="S7.SS2.p4.1.m1.1.1.3.cmml" xref="S7.SS2.p4.1.m1.1.1.3">𝑂</ci><apply id="S7.SS2.p4.1.m1.1.1.1.1.1.cmml" xref="S7.SS2.p4.1.m1.1.1.1.1"><log id="S7.SS2.p4.1.m1.1.1.1.1.1.1.cmml" xref="S7.SS2.p4.1.m1.1.1.1.1.1.1"></log><ci id="S7.SS2.p4.1.m1.1.1.1.1.1.2.cmml" xref="S7.SS2.p4.1.m1.1.1.1.1.1.2">𝑁</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.SS2.p4.1.m1.1c">O(\log N)</annotation></semantics></math> compared to <math id="S7.SS2.p4.2.m2.1" class="ltx_Math" alttext="O(N\log N)" display="inline"><semantics id="S7.SS2.p4.2.m2.1a"><mrow id="S7.SS2.p4.2.m2.1.1" xref="S7.SS2.p4.2.m2.1.1.cmml"><mi id="S7.SS2.p4.2.m2.1.1.3" xref="S7.SS2.p4.2.m2.1.1.3.cmml">O</mi><mo lspace="0em" rspace="0em" id="S7.SS2.p4.2.m2.1.1.2" xref="S7.SS2.p4.2.m2.1.1.2.cmml">​</mo><mrow id="S7.SS2.p4.2.m2.1.1.1.1" xref="S7.SS2.p4.2.m2.1.1.1.1.1.cmml"><mo stretchy="false" id="S7.SS2.p4.2.m2.1.1.1.1.2" xref="S7.SS2.p4.2.m2.1.1.1.1.1.cmml">(</mo><mrow id="S7.SS2.p4.2.m2.1.1.1.1.1" xref="S7.SS2.p4.2.m2.1.1.1.1.1.cmml"><mi id="S7.SS2.p4.2.m2.1.1.1.1.1.2" xref="S7.SS2.p4.2.m2.1.1.1.1.1.2.cmml">N</mi><mo lspace="0.167em" rspace="0em" id="S7.SS2.p4.2.m2.1.1.1.1.1.1" xref="S7.SS2.p4.2.m2.1.1.1.1.1.1.cmml">​</mo><mrow id="S7.SS2.p4.2.m2.1.1.1.1.1.3" xref="S7.SS2.p4.2.m2.1.1.1.1.1.3.cmml"><mi id="S7.SS2.p4.2.m2.1.1.1.1.1.3.1" xref="S7.SS2.p4.2.m2.1.1.1.1.1.3.1.cmml">log</mi><mo lspace="0.167em" id="S7.SS2.p4.2.m2.1.1.1.1.1.3a" xref="S7.SS2.p4.2.m2.1.1.1.1.1.3.cmml">⁡</mo><mi id="S7.SS2.p4.2.m2.1.1.1.1.1.3.2" xref="S7.SS2.p4.2.m2.1.1.1.1.1.3.2.cmml">N</mi></mrow></mrow><mo stretchy="false" id="S7.SS2.p4.2.m2.1.1.1.1.3" xref="S7.SS2.p4.2.m2.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S7.SS2.p4.2.m2.1b"><apply id="S7.SS2.p4.2.m2.1.1.cmml" xref="S7.SS2.p4.2.m2.1.1"><times id="S7.SS2.p4.2.m2.1.1.2.cmml" xref="S7.SS2.p4.2.m2.1.1.2"></times><ci id="S7.SS2.p4.2.m2.1.1.3.cmml" xref="S7.SS2.p4.2.m2.1.1.3">𝑂</ci><apply id="S7.SS2.p4.2.m2.1.1.1.1.1.cmml" xref="S7.SS2.p4.2.m2.1.1.1.1"><times id="S7.SS2.p4.2.m2.1.1.1.1.1.1.cmml" xref="S7.SS2.p4.2.m2.1.1.1.1.1.1"></times><ci id="S7.SS2.p4.2.m2.1.1.1.1.1.2.cmml" xref="S7.SS2.p4.2.m2.1.1.1.1.1.2">𝑁</ci><apply id="S7.SS2.p4.2.m2.1.1.1.1.1.3.cmml" xref="S7.SS2.p4.2.m2.1.1.1.1.1.3"><log id="S7.SS2.p4.2.m2.1.1.1.1.1.3.1.cmml" xref="S7.SS2.p4.2.m2.1.1.1.1.1.3.1"></log><ci id="S7.SS2.p4.2.m2.1.1.1.1.1.3.2.cmml" xref="S7.SS2.p4.2.m2.1.1.1.1.1.3.2">𝑁</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.SS2.p4.2.m2.1c">O(N\log N)</annotation></semantics></math> and <math id="S7.SS2.p4.3.m3.1" class="ltx_Math" alttext="O(N^{2})" display="inline"><semantics id="S7.SS2.p4.3.m3.1a"><mrow id="S7.SS2.p4.3.m3.1.1" xref="S7.SS2.p4.3.m3.1.1.cmml"><mi id="S7.SS2.p4.3.m3.1.1.3" xref="S7.SS2.p4.3.m3.1.1.3.cmml">O</mi><mo lspace="0em" rspace="0em" id="S7.SS2.p4.3.m3.1.1.2" xref="S7.SS2.p4.3.m3.1.1.2.cmml">​</mo><mrow id="S7.SS2.p4.3.m3.1.1.1.1" xref="S7.SS2.p4.3.m3.1.1.1.1.1.cmml"><mo stretchy="false" id="S7.SS2.p4.3.m3.1.1.1.1.2" xref="S7.SS2.p4.3.m3.1.1.1.1.1.cmml">(</mo><msup id="S7.SS2.p4.3.m3.1.1.1.1.1" xref="S7.SS2.p4.3.m3.1.1.1.1.1.cmml"><mi id="S7.SS2.p4.3.m3.1.1.1.1.1.2" xref="S7.SS2.p4.3.m3.1.1.1.1.1.2.cmml">N</mi><mn id="S7.SS2.p4.3.m3.1.1.1.1.1.3" xref="S7.SS2.p4.3.m3.1.1.1.1.1.3.cmml">2</mn></msup><mo stretchy="false" id="S7.SS2.p4.3.m3.1.1.1.1.3" xref="S7.SS2.p4.3.m3.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S7.SS2.p4.3.m3.1b"><apply id="S7.SS2.p4.3.m3.1.1.cmml" xref="S7.SS2.p4.3.m3.1.1"><times id="S7.SS2.p4.3.m3.1.1.2.cmml" xref="S7.SS2.p4.3.m3.1.1.2"></times><ci id="S7.SS2.p4.3.m3.1.1.3.cmml" xref="S7.SS2.p4.3.m3.1.1.3">𝑂</ci><apply id="S7.SS2.p4.3.m3.1.1.1.1.1.cmml" xref="S7.SS2.p4.3.m3.1.1.1.1"><csymbol cd="ambiguous" id="S7.SS2.p4.3.m3.1.1.1.1.1.1.cmml" xref="S7.SS2.p4.3.m3.1.1.1.1">superscript</csymbol><ci id="S7.SS2.p4.3.m3.1.1.1.1.1.2.cmml" xref="S7.SS2.p4.3.m3.1.1.1.1.1.2">𝑁</ci><cn type="integer" id="S7.SS2.p4.3.m3.1.1.1.1.1.3.cmml" xref="S7.SS2.p4.3.m3.1.1.1.1.1.3">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.SS2.p4.3.m3.1c">O(N^{2})</annotation></semantics></math> for SecAgg+ and SecAgg, respectively. LightSecAgg
is composed of three main phases as shown in Figure <a href="#S7.F8" title="Figure 8 ‣ 7.2. Secure Aggregation ‣ 7. Privacy Defenses ‣ Federated Learning Privacy: Attacks, Defenses, Applications, and Policy Landscape — A Survey" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a>. First, each user <math id="S7.SS2.p4.4.m4.1" class="ltx_Math" alttext="i\in[N]" display="inline"><semantics id="S7.SS2.p4.4.m4.1a"><mrow id="S7.SS2.p4.4.m4.1.2" xref="S7.SS2.p4.4.m4.1.2.cmml"><mi id="S7.SS2.p4.4.m4.1.2.2" xref="S7.SS2.p4.4.m4.1.2.2.cmml">i</mi><mo id="S7.SS2.p4.4.m4.1.2.1" xref="S7.SS2.p4.4.m4.1.2.1.cmml">∈</mo><mrow id="S7.SS2.p4.4.m4.1.2.3.2" xref="S7.SS2.p4.4.m4.1.2.3.1.cmml"><mo stretchy="false" id="S7.SS2.p4.4.m4.1.2.3.2.1" xref="S7.SS2.p4.4.m4.1.2.3.1.1.cmml">[</mo><mi id="S7.SS2.p4.4.m4.1.1" xref="S7.SS2.p4.4.m4.1.1.cmml">N</mi><mo stretchy="false" id="S7.SS2.p4.4.m4.1.2.3.2.2" xref="S7.SS2.p4.4.m4.1.2.3.1.1.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S7.SS2.p4.4.m4.1b"><apply id="S7.SS2.p4.4.m4.1.2.cmml" xref="S7.SS2.p4.4.m4.1.2"><in id="S7.SS2.p4.4.m4.1.2.1.cmml" xref="S7.SS2.p4.4.m4.1.2.1"></in><ci id="S7.SS2.p4.4.m4.1.2.2.cmml" xref="S7.SS2.p4.4.m4.1.2.2">𝑖</ci><apply id="S7.SS2.p4.4.m4.1.2.3.1.cmml" xref="S7.SS2.p4.4.m4.1.2.3.2"><csymbol cd="latexml" id="S7.SS2.p4.4.m4.1.2.3.1.1.cmml" xref="S7.SS2.p4.4.m4.1.2.3.2.1">delimited-[]</csymbol><ci id="S7.SS2.p4.4.m4.1.1.cmml" xref="S7.SS2.p4.4.m4.1.1">𝑁</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.SS2.p4.4.m4.1c">i\in[N]</annotation></semantics></math> partitions its local random mask <math id="S7.SS2.p4.5.m5.1" class="ltx_Math" alttext="\mathbf{z}_{i}" display="inline"><semantics id="S7.SS2.p4.5.m5.1a"><msub id="S7.SS2.p4.5.m5.1.1" xref="S7.SS2.p4.5.m5.1.1.cmml"><mi id="S7.SS2.p4.5.m5.1.1.2" xref="S7.SS2.p4.5.m5.1.1.2.cmml">𝐳</mi><mi id="S7.SS2.p4.5.m5.1.1.3" xref="S7.SS2.p4.5.m5.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S7.SS2.p4.5.m5.1b"><apply id="S7.SS2.p4.5.m5.1.1.cmml" xref="S7.SS2.p4.5.m5.1.1"><csymbol cd="ambiguous" id="S7.SS2.p4.5.m5.1.1.1.cmml" xref="S7.SS2.p4.5.m5.1.1">subscript</csymbol><ci id="S7.SS2.p4.5.m5.1.1.2.cmml" xref="S7.SS2.p4.5.m5.1.1.2">𝐳</ci><ci id="S7.SS2.p4.5.m5.1.1.3.cmml" xref="S7.SS2.p4.5.m5.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.SS2.p4.5.m5.1c">\mathbf{z}_{i}</annotation></semantics></math> to pieces and creates encoded masks via private MDS code to provide robustness against dropped users and privacy against colluding users. Each user sends one of the encoded masks to one of the other users for the purpose of one-shot recovery. Second, each user uploads its masked local model to the server. Third, the server reconstructs the aggregated masks of the surviving users to recover their aggregate of models. Each surviving user sends the aggregated encoded masks to the server. After receiving enough aggregated encoded masks from the surviving users, the server recovers the aggregate-mask and the desired aggregate-model.</p>
</div>
<div id="S7.SS2.p5" class="ltx_para">
<p id="S7.SS2.p5.4" class="ltx_p">Another interesting research direction of SA in FL has been to further analyze its formal privacy guarantees either over multi-rounds <cite class="ltx_cite ltx_citemacro_citep">(So et al<span class="ltx_text">.</span>, <a href="#bib.bib117" title="" class="ltx_ref">2023</a>)</cite> or from the aggregated model <cite class="ltx_cite ltx_citemacro_citep">(Elkordy et al<span class="ltx_text">.</span>, <a href="#bib.bib46" title="" class="ltx_ref">2022</a>)</cite>. In particular, while secure aggregation protocols have provable privacy guarantees at any single round, in the sense that no information is leaked beyond the aggregate model at each round, the privacy guarantees do not extend to attacks that span multiple training rounds. The authors in <cite class="ltx_cite ltx_citemacro_citep">(So et al<span class="ltx_text">.</span>, <a href="#bib.bib117" title="" class="ltx_ref">2023</a>)</cite> have shown that the individual model may be reconstructed by leveraging the participation information and the aggregate models across multiple rounds.
Assuming a scenario where the local updates do not change significantly over time (e.g., models start to converge), i.e., <math id="S7.SS2.p5.1.m1.1" class="ltx_Math" alttext="\mathbf{x}_{i}=\mathbf{x}^{(t)}_{i}" display="inline"><semantics id="S7.SS2.p5.1.m1.1a"><mrow id="S7.SS2.p5.1.m1.1.2" xref="S7.SS2.p5.1.m1.1.2.cmml"><msub id="S7.SS2.p5.1.m1.1.2.2" xref="S7.SS2.p5.1.m1.1.2.2.cmml"><mi id="S7.SS2.p5.1.m1.1.2.2.2" xref="S7.SS2.p5.1.m1.1.2.2.2.cmml">𝐱</mi><mi id="S7.SS2.p5.1.m1.1.2.2.3" xref="S7.SS2.p5.1.m1.1.2.2.3.cmml">i</mi></msub><mo id="S7.SS2.p5.1.m1.1.2.1" xref="S7.SS2.p5.1.m1.1.2.1.cmml">=</mo><msubsup id="S7.SS2.p5.1.m1.1.2.3" xref="S7.SS2.p5.1.m1.1.2.3.cmml"><mi id="S7.SS2.p5.1.m1.1.2.3.2.2" xref="S7.SS2.p5.1.m1.1.2.3.2.2.cmml">𝐱</mi><mi id="S7.SS2.p5.1.m1.1.2.3.3" xref="S7.SS2.p5.1.m1.1.2.3.3.cmml">i</mi><mrow id="S7.SS2.p5.1.m1.1.1.1.3" xref="S7.SS2.p5.1.m1.1.2.3.cmml"><mo stretchy="false" id="S7.SS2.p5.1.m1.1.1.1.3.1" xref="S7.SS2.p5.1.m1.1.2.3.cmml">(</mo><mi id="S7.SS2.p5.1.m1.1.1.1.1" xref="S7.SS2.p5.1.m1.1.1.1.1.cmml">t</mi><mo stretchy="false" id="S7.SS2.p5.1.m1.1.1.1.3.2" xref="S7.SS2.p5.1.m1.1.2.3.cmml">)</mo></mrow></msubsup></mrow><annotation-xml encoding="MathML-Content" id="S7.SS2.p5.1.m1.1b"><apply id="S7.SS2.p5.1.m1.1.2.cmml" xref="S7.SS2.p5.1.m1.1.2"><eq id="S7.SS2.p5.1.m1.1.2.1.cmml" xref="S7.SS2.p5.1.m1.1.2.1"></eq><apply id="S7.SS2.p5.1.m1.1.2.2.cmml" xref="S7.SS2.p5.1.m1.1.2.2"><csymbol cd="ambiguous" id="S7.SS2.p5.1.m1.1.2.2.1.cmml" xref="S7.SS2.p5.1.m1.1.2.2">subscript</csymbol><ci id="S7.SS2.p5.1.m1.1.2.2.2.cmml" xref="S7.SS2.p5.1.m1.1.2.2.2">𝐱</ci><ci id="S7.SS2.p5.1.m1.1.2.2.3.cmml" xref="S7.SS2.p5.1.m1.1.2.2.3">𝑖</ci></apply><apply id="S7.SS2.p5.1.m1.1.2.3.cmml" xref="S7.SS2.p5.1.m1.1.2.3"><csymbol cd="ambiguous" id="S7.SS2.p5.1.m1.1.2.3.1.cmml" xref="S7.SS2.p5.1.m1.1.2.3">subscript</csymbol><apply id="S7.SS2.p5.1.m1.1.2.3.2.cmml" xref="S7.SS2.p5.1.m1.1.2.3"><csymbol cd="ambiguous" id="S7.SS2.p5.1.m1.1.2.3.2.1.cmml" xref="S7.SS2.p5.1.m1.1.2.3">superscript</csymbol><ci id="S7.SS2.p5.1.m1.1.2.3.2.2.cmml" xref="S7.SS2.p5.1.m1.1.2.3.2.2">𝐱</ci><ci id="S7.SS2.p5.1.m1.1.1.1.1.cmml" xref="S7.SS2.p5.1.m1.1.1.1.1">𝑡</ci></apply><ci id="S7.SS2.p5.1.m1.1.2.3.3.cmml" xref="S7.SS2.p5.1.m1.1.2.3.3">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.SS2.p5.1.m1.1c">\mathbf{x}_{i}=\mathbf{x}^{(t)}_{i}</annotation></semantics></math> for all <math id="S7.SS2.p5.2.m2.1" class="ltx_Math" alttext="i\in[3]" display="inline"><semantics id="S7.SS2.p5.2.m2.1a"><mrow id="S7.SS2.p5.2.m2.1.2" xref="S7.SS2.p5.2.m2.1.2.cmml"><mi id="S7.SS2.p5.2.m2.1.2.2" xref="S7.SS2.p5.2.m2.1.2.2.cmml">i</mi><mo id="S7.SS2.p5.2.m2.1.2.1" xref="S7.SS2.p5.2.m2.1.2.1.cmml">∈</mo><mrow id="S7.SS2.p5.2.m2.1.2.3.2" xref="S7.SS2.p5.2.m2.1.2.3.1.cmml"><mo stretchy="false" id="S7.SS2.p5.2.m2.1.2.3.2.1" xref="S7.SS2.p5.2.m2.1.2.3.1.1.cmml">[</mo><mn id="S7.SS2.p5.2.m2.1.1" xref="S7.SS2.p5.2.m2.1.1.cmml">3</mn><mo stretchy="false" id="S7.SS2.p5.2.m2.1.2.3.2.2" xref="S7.SS2.p5.2.m2.1.2.3.1.1.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S7.SS2.p5.2.m2.1b"><apply id="S7.SS2.p5.2.m2.1.2.cmml" xref="S7.SS2.p5.2.m2.1.2"><in id="S7.SS2.p5.2.m2.1.2.1.cmml" xref="S7.SS2.p5.2.m2.1.2.1"></in><ci id="S7.SS2.p5.2.m2.1.2.2.cmml" xref="S7.SS2.p5.2.m2.1.2.2">𝑖</ci><apply id="S7.SS2.p5.2.m2.1.2.3.1.cmml" xref="S7.SS2.p5.2.m2.1.2.3.2"><csymbol cd="latexml" id="S7.SS2.p5.2.m2.1.2.3.1.1.cmml" xref="S7.SS2.p5.2.m2.1.2.3.2.1">delimited-[]</csymbol><cn type="integer" id="S7.SS2.p5.2.m2.1.1.cmml" xref="S7.SS2.p5.2.m2.1.1">3</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.SS2.p5.2.m2.1c">i\in[3]</annotation></semantics></math> and <math id="S7.SS2.p5.3.m3.1" class="ltx_Math" alttext="t\in[2]" display="inline"><semantics id="S7.SS2.p5.3.m3.1a"><mrow id="S7.SS2.p5.3.m3.1.2" xref="S7.SS2.p5.3.m3.1.2.cmml"><mi id="S7.SS2.p5.3.m3.1.2.2" xref="S7.SS2.p5.3.m3.1.2.2.cmml">t</mi><mo id="S7.SS2.p5.3.m3.1.2.1" xref="S7.SS2.p5.3.m3.1.2.1.cmml">∈</mo><mrow id="S7.SS2.p5.3.m3.1.2.3.2" xref="S7.SS2.p5.3.m3.1.2.3.1.cmml"><mo stretchy="false" id="S7.SS2.p5.3.m3.1.2.3.2.1" xref="S7.SS2.p5.3.m3.1.2.3.1.1.cmml">[</mo><mn id="S7.SS2.p5.3.m3.1.1" xref="S7.SS2.p5.3.m3.1.1.cmml">2</mn><mo stretchy="false" id="S7.SS2.p5.3.m3.1.2.3.2.2" xref="S7.SS2.p5.3.m3.1.2.3.1.1.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S7.SS2.p5.3.m3.1b"><apply id="S7.SS2.p5.3.m3.1.2.cmml" xref="S7.SS2.p5.3.m3.1.2"><in id="S7.SS2.p5.3.m3.1.2.1.cmml" xref="S7.SS2.p5.3.m3.1.2.1"></in><ci id="S7.SS2.p5.3.m3.1.2.2.cmml" xref="S7.SS2.p5.3.m3.1.2.2">𝑡</ci><apply id="S7.SS2.p5.3.m3.1.2.3.1.cmml" xref="S7.SS2.p5.3.m3.1.2.3.2"><csymbol cd="latexml" id="S7.SS2.p5.3.m3.1.2.3.1.1.cmml" xref="S7.SS2.p5.3.m3.1.2.3.2.1">delimited-[]</csymbol><cn type="integer" id="S7.SS2.p5.3.m3.1.1.cmml" xref="S7.SS2.p5.3.m3.1.1">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.SS2.p5.3.m3.1c">t\in[2]</annotation></semantics></math>. Then the server can single out
a model, say <math id="S7.SS2.p5.4.m4.1" class="ltx_Math" alttext="\mathbf{x}^{(t)}_{3}" display="inline"><semantics id="S7.SS2.p5.4.m4.1a"><msubsup id="S7.SS2.p5.4.m4.1.2" xref="S7.SS2.p5.4.m4.1.2.cmml"><mi id="S7.SS2.p5.4.m4.1.2.2.2" xref="S7.SS2.p5.4.m4.1.2.2.2.cmml">𝐱</mi><mn id="S7.SS2.p5.4.m4.1.2.3" xref="S7.SS2.p5.4.m4.1.2.3.cmml">3</mn><mrow id="S7.SS2.p5.4.m4.1.1.1.3" xref="S7.SS2.p5.4.m4.1.2.cmml"><mo stretchy="false" id="S7.SS2.p5.4.m4.1.1.1.3.1" xref="S7.SS2.p5.4.m4.1.2.cmml">(</mo><mi id="S7.SS2.p5.4.m4.1.1.1.1" xref="S7.SS2.p5.4.m4.1.1.1.1.cmml">t</mi><mo stretchy="false" id="S7.SS2.p5.4.m4.1.1.1.3.2" xref="S7.SS2.p5.4.m4.1.2.cmml">)</mo></mrow></msubsup><annotation-xml encoding="MathML-Content" id="S7.SS2.p5.4.m4.1b"><apply id="S7.SS2.p5.4.m4.1.2.cmml" xref="S7.SS2.p5.4.m4.1.2"><csymbol cd="ambiguous" id="S7.SS2.p5.4.m4.1.2.1.cmml" xref="S7.SS2.p5.4.m4.1.2">subscript</csymbol><apply id="S7.SS2.p5.4.m4.1.2.2.cmml" xref="S7.SS2.p5.4.m4.1.2"><csymbol cd="ambiguous" id="S7.SS2.p5.4.m4.1.2.2.1.cmml" xref="S7.SS2.p5.4.m4.1.2">superscript</csymbol><ci id="S7.SS2.p5.4.m4.1.2.2.2.cmml" xref="S7.SS2.p5.4.m4.1.2.2.2">𝐱</ci><ci id="S7.SS2.p5.4.m4.1.1.1.1.cmml" xref="S7.SS2.p5.4.m4.1.1.1.1">𝑡</ci></apply><cn type="integer" id="S7.SS2.p5.4.m4.1.2.3.cmml" xref="S7.SS2.p5.4.m4.1.2.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.SS2.p5.4.m4.1c">\mathbf{x}^{(t)}_{3}</annotation></semantics></math>, even if a secure aggregation protocol is employed at each round. Instead of random users participation, the authors managed to resolve this limitation of secure aggregation by developing a structured user selection strategy that guarantees long-term privacy while taking into account the fairness in user selection and average number of participating users, and showed that provides a trade-off between long-term privacy and the convergence rate.</p>
</div>
<figure id="S7.F9" class="ltx_figure"><img src="/html/2405.03636/assets/plots-images/How_much.png" id="S7.F9.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="627" height="256" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 9. </span>Privacy leakage from the aggregated model in SA.</figcaption>
</figure>
<div id="S7.SS2.p6" class="ltx_para">
<p id="S7.SS2.p6.2" class="ltx_p">SA design ensures that the server only learns the aggregated model on each round, Figure <a href="#S7.F9" title="Figure 9 ‣ 7.2. Secure Aggregation ‣ 7. Privacy Defenses ‣ Federated Learning Privacy: Attacks, Defenses, Applications, and Policy Landscape — A Survey" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a>.
However, even with these SA guarantees on individual updates, it is not yet fully understood how much privacy is guaranteed in FL using SA, since the aggregated model update from all users may still leak information about an individual user’s local dataset <cite class="ltx_cite ltx_citemacro_citep">(Pasquini et al<span class="ltx_text">.</span>, <a href="#bib.bib102" title="" class="ltx_ref">2022</a>; Zhao et al<span class="ltx_text">.</span>, <a href="#bib.bib149" title="" class="ltx_ref">2023b</a>)</cite>. The work in <cite class="ltx_cite ltx_citemacro_citep">(Elkordy et al<span class="ltx_text">.</span>, <a href="#bib.bib46" title="" class="ltx_ref">2022</a>)</cite> measures the amount information the aggregated model leak about the local dataset of an individual user. They provide theoretical bounds on the mutual information (MI) privacy leakage in theory and demonstrate through an empirical study that these bounds hold in practice. Their key observations indicate that when employing FL in conjunction with SA, several significant trends emerge. First, they found that the MI privacy leakage decreases at a rate of <math id="S7.SS2.p6.1.m1.1" class="ltx_Math" alttext="\mathcal{O}(\frac{1}{N})" display="inline"><semantics id="S7.SS2.p6.1.m1.1a"><mrow id="S7.SS2.p6.1.m1.1.2" xref="S7.SS2.p6.1.m1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S7.SS2.p6.1.m1.1.2.2" xref="S7.SS2.p6.1.m1.1.2.2.cmml">𝒪</mi><mo lspace="0em" rspace="0em" id="S7.SS2.p6.1.m1.1.2.1" xref="S7.SS2.p6.1.m1.1.2.1.cmml">​</mo><mrow id="S7.SS2.p6.1.m1.1.2.3.2" xref="S7.SS2.p6.1.m1.1.1.cmml"><mo stretchy="false" id="S7.SS2.p6.1.m1.1.2.3.2.1" xref="S7.SS2.p6.1.m1.1.1.cmml">(</mo><mfrac id="S7.SS2.p6.1.m1.1.1" xref="S7.SS2.p6.1.m1.1.1.cmml"><mn id="S7.SS2.p6.1.m1.1.1.2" xref="S7.SS2.p6.1.m1.1.1.2.cmml">1</mn><mi id="S7.SS2.p6.1.m1.1.1.3" xref="S7.SS2.p6.1.m1.1.1.3.cmml">N</mi></mfrac><mo stretchy="false" id="S7.SS2.p6.1.m1.1.2.3.2.2" xref="S7.SS2.p6.1.m1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S7.SS2.p6.1.m1.1b"><apply id="S7.SS2.p6.1.m1.1.2.cmml" xref="S7.SS2.p6.1.m1.1.2"><times id="S7.SS2.p6.1.m1.1.2.1.cmml" xref="S7.SS2.p6.1.m1.1.2.1"></times><ci id="S7.SS2.p6.1.m1.1.2.2.cmml" xref="S7.SS2.p6.1.m1.1.2.2">𝒪</ci><apply id="S7.SS2.p6.1.m1.1.1.cmml" xref="S7.SS2.p6.1.m1.1.2.3.2"><divide id="S7.SS2.p6.1.m1.1.1.1.cmml" xref="S7.SS2.p6.1.m1.1.2.3.2"></divide><cn type="integer" id="S7.SS2.p6.1.m1.1.1.2.cmml" xref="S7.SS2.p6.1.m1.1.1.2">1</cn><ci id="S7.SS2.p6.1.m1.1.1.3.cmml" xref="S7.SS2.p6.1.m1.1.1.3">𝑁</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.SS2.p6.1.m1.1c">\mathcal{O}(\frac{1}{N})</annotation></semantics></math>, where <math id="S7.SS2.p6.2.m2.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S7.SS2.p6.2.m2.1a"><mi id="S7.SS2.p6.2.m2.1.1" xref="S7.SS2.p6.2.m2.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S7.SS2.p6.2.m2.1b"><ci id="S7.SS2.p6.2.m2.1.1.cmml" xref="S7.SS2.p6.2.m2.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.SS2.p6.2.m2.1c">N</annotation></semantics></math> is the number of users participating in FL with SA. Second, they noted that increasing model size does not lead to a linear increase of MI privacy leakage, and the MI privacy leakage only linearly increases with the rank of the covariance matrix of the individual model update. Lastly, using larger batch size during local training can help to reduce the MI privacy leakage. As highlighted, the privacy metric used in that work (mutual information) measures the on-average privacy leakage, without providing any privacy guarantees for worse-case scenarios. Measuring how much differential privacy SA can achieve might be an interesting direction to be explored.</p>
</div>
</section>
<section id="S7.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">7.3. </span>Homomorphic Encryption</h3>

<div id="S7.SS3.p1" class="ltx_para">
<p id="S7.SS3.p1.1" class="ltx_p">Homomorphic encryption (HE) can be considered an extension to SecAgg within FL. While SecAgg can still expose the aggregate model to the server, HE completely shields the model information from non-data owners. HE is a cryptographic technique that enables computations to be executed on encrypted data without requiring prior decryption. In essence, HE facilitates computation while preserving data in its encrypted state. This feature is essential for upholding privacy and security in contexts necessitating processing or analyzing sensitive information. Popular schemes such as CKKS allow encrypted arithmetic on approximate numbers <cite class="ltx_cite ltx_citemacro_citep">(Cheon et al<span class="ltx_text">.</span>, <a href="#bib.bib34" title="" class="ltx_ref">2017</a>)</cite> and are therefore interesting as a solution for encrypted machine learning. With HE, computations can be conducted on encrypted data, and subsequently, the results remain interpretable upon decryption without compromising the confidentiality of the underlying data.</p>
</div>
<div id="S7.SS3.p2" class="ltx_para">
<p id="S7.SS3.p2.1" class="ltx_p">Clients can employ HE to encrypt their model updates within the FL paradigm before transmission. Consequently, the server exclusively receives encrypted updates and is precluded from accessing any raw model updates. Utilizing an HE protocol, the server aggregates only encrypted weights, thereby preserving privacy. Following aggregation, the updated global model is sent back to the clients while still being encrypted. Subsequently, clients decrypt the model using their keys for further local training. HE serves to conceal each client’s contributions, thereby removing the server’s access to sensitive information. Despite the computational overhead associated with HE, its implementation can markedly enhance patient data security within collaborative learning environments.</p>
</div>
<div id="S7.SS3.p3" class="ltx_para">
<p id="S7.SS3.p3.1" class="ltx_p">While HE mitigates risks such as model inversion or data leakage attributable to compromised servers, it is important to consider that the final models themselves may still retain privacy-sensitive information (see model inversion <cite class="ltx_cite ltx_citemacro_citep">(Yin et al<span class="ltx_text">.</span>, <a href="#bib.bib138" title="" class="ltx_ref">2020</a>)</cite> and membership inference <cite class="ltx_cite ltx_citemacro_citep">(Shokri et al<span class="ltx_text">.</span>, <a href="#bib.bib115" title="" class="ltx_ref">2017</a>)</cite>). Consequently, integrating additional privacy safeguards, such as differential privacy or partial model sharing, warrants consideration to prevent the potential for memorization of individual training data.</p>
</div>
<div id="S7.SS3.p4" class="ltx_para">
<p id="S7.SS3.p4.1" class="ltx_p">Several FL frameworks implement HE-based solutions for secure federated aggregation <cite class="ltx_cite ltx_citemacro_citep">(Jin et al<span class="ltx_text">.</span>, <a href="#bib.bib69" title="" class="ltx_ref">2023</a>; Cremonesi et al<span class="ltx_text">.</span>, <a href="#bib.bib37" title="" class="ltx_ref">2023</a>; Roth et al<span class="ltx_text">.</span>, <a href="#bib.bib110" title="" class="ltx_ref">2022</a>)</cite>, thereby significantly addressing privacy concerns in FL. These frameworks focus on typical applications of horizontal FL and deep learning models. Other approaches include HE in vertical FL applications, such as SecureBoost <cite class="ltx_cite ltx_citemacro_citep">(Cheng et al<span class="ltx_text">.</span>, <a href="#bib.bib33" title="" class="ltx_ref">2021</a>)</cite> aimed for financial applications of XGBoost <cite class="ltx_cite ltx_citemacro_citep">(Chen and Guestrin, <a href="#bib.bib29" title="" class="ltx_ref">2016</a>)</cite> and encrypted Kaplan-Meier for survival analysis in oncology and genome-wide association studies in FL settings <cite class="ltx_cite ltx_citemacro_citep">(Froelicher et al<span class="ltx_text">.</span>, <a href="#bib.bib53" title="" class="ltx_ref">2021</a>)</cite>.</p>
</div>
<div id="S7.SS3.p5" class="ltx_para">
<p id="S7.SS3.p5.1" class="ltx_p">Although HE holds great promise for enhancing the security of FL applications, its scalability is constrained due to larger ciphertext messages, which could be impractical in scenarios with limited bandwidth and computing resources. Consequently, HE has been predominantly investigated in the context of cross-silo or enterprise FL applications with fewer clients, which is particularly prevalent in industries such as healthcare and finance. Furthermore, HE offers additional potential for securing client training operations through its capability for training on encrypted data <cite class="ltx_cite ltx_citemacro_citep">(Lee et al<span class="ltx_text">.</span>, <a href="#bib.bib78" title="" class="ltx_ref">2022</a>)</cite>.</p>
</div>
</section>
<section id="S7.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">7.4. </span>Additional defenses against membership inference attacks</h3>

<div id="S7.SS4.p1" class="ltx_para">
<p id="S7.SS4.p1.1" class="ltx_p"><span id="S7.SS4.p1.1.1" class="ltx_text ltx_font_bold">Adversarial Regularization (Adv-reg).</span>
Nasr et al. <cite class="ltx_cite ltx_citemacro_citep">(Nasr et al<span class="ltx_text">.</span>, <a href="#bib.bib97" title="" class="ltx_ref">2018</a>)</cite> proposed a defense that uses similar ideas as GAN.
The classifier is trained in conjunction with an MI attacker model. The optimization objective of the target classifier is to reduce the prediction loss while minimizing the MI attack accuracy.</p>
</div>
<div id="S7.SS4.p2" class="ltx_para">
<p id="S7.SS4.p2.1" class="ltx_p"><span id="S7.SS4.p2.1.1" class="ltx_text ltx_font_bold">Mixup+MMD.</span>
Li et al. <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a href="#bib.bib79" title="" class="ltx_ref">2021</a>)</cite> proposed a defense that combines mixup data augmentation and MMD (Maximum Mean Discrepancy <cite class="ltx_cite ltx_citemacro_citep">(Fortet and Mourier, <a href="#bib.bib50" title="" class="ltx_ref">1953</a>; Gretton et al<span class="ltx_text">.</span>, <a href="#bib.bib57" title="" class="ltx_ref">2012</a>)</cite>) based regularization. Instead of training with original instances, mixup data augmentation uses linear combinations of two original instances to train the model. It was shown in <cite class="ltx_cite ltx_citemacro_citep">(Zhang et al<span class="ltx_text">.</span>, <a href="#bib.bib143" title="" class="ltx_ref">2017</a>)</cite> that this can improve target model’s generalization. Li et al. <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a href="#bib.bib79" title="" class="ltx_ref">2021</a>)</cite> found that they also help to defend against MI attacks. They also proposed to add a regularizer that is the MMD between the loss distribution of members and the loss distribution of a validation set not used in training. This helps make the loss distribution of members to be more similar to the loss distribution on non-members.</p>
</div>
<div id="S7.SS4.p3" class="ltx_para">
<p id="S7.SS4.p3.1" class="ltx_p"><span id="S7.SS4.p3.1.1" class="ltx_text ltx_font_bold">Distillation for membership privacy (DMP).</span>
Distillation uses labels generated by a teacher model to train a student model. It was proposed in <cite class="ltx_cite ltx_citemacro_citep">(Hinton et al<span class="ltx_text">.</span>, <a href="#bib.bib62" title="" class="ltx_ref">2015</a>)</cite> for the purpose of model compression.
Shejwalkar et al. <cite class="ltx_cite ltx_citemacro_citep">(Shejwalkar and Houmansadr, <a href="#bib.bib114" title="" class="ltx_ref">2021</a>)</cite> proposed to use distillation to defend against MI attacks. One first trains a teacher model using the private training set, and then trains a student model using another unlabeled dataset from the same distribution as the private set. The intuition is that since the student model is not directly optimized over the private set, their membership may be protected. the authors also suggested to train a GAN using the private training set and draw samples from the trained GAN to train the student model, when no auxiliary unlabeled data is available.</p>
</div>
<div id="S7.SS4.p4" class="ltx_para">
<p id="S7.SS4.p4.1" class="ltx_p"><span id="S7.SS4.p4.1.1" class="ltx_text ltx_font_bold">SELENA.</span> Tang et al. <cite class="ltx_cite ltx_citemacro_citep">(Tang et al<span class="ltx_text">.</span>, <a href="#bib.bib125" title="" class="ltx_ref">2022</a>)</cite> proposed a framework named SELENA.
One first generates multiple (overlapping) subsets from the training data, then trains one model from each subset. One then generates a new label for each training instance, using the average of predictions generated by models trained without using that instance. Finally, one trains a model using the training dataset using these new labels.</p>
</div>
<div id="S7.SS4.p5" class="ltx_para">
<p id="S7.SS4.p5.8" class="ltx_p"><span id="S7.SS4.p5.8.1" class="ltx_text ltx_font_bold">HAMP.</span> Chen et al. <cite class="ltx_cite ltx_citemacro_citep">(Chen and Pattabiraman, <a href="#bib.bib32" title="" class="ltx_ref">2023</a>)</cite> proposed a defense combining several ideas. First, labels for training instances are made smoother, by changing <math id="S7.SS4.p5.1.m1.1" class="ltx_Math" alttext="1" display="inline"><semantics id="S7.SS4.p5.1.m1.1a"><mn id="S7.SS4.p5.1.m1.1.1" xref="S7.SS4.p5.1.m1.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="S7.SS4.p5.1.m1.1b"><cn type="integer" id="S7.SS4.p5.1.m1.1.1.cmml" xref="S7.SS4.p5.1.m1.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="S7.SS4.p5.1.m1.1c">1</annotation></semantics></math> to <math id="S7.SS4.p5.2.m2.1" class="ltx_Math" alttext="\lambda" display="inline"><semantics id="S7.SS4.p5.2.m2.1a"><mi id="S7.SS4.p5.2.m2.1.1" xref="S7.SS4.p5.2.m2.1.1.cmml">λ</mi><annotation-xml encoding="MathML-Content" id="S7.SS4.p5.2.m2.1b"><ci id="S7.SS4.p5.2.m2.1.1.cmml" xref="S7.SS4.p5.2.m2.1.1">𝜆</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.SS4.p5.2.m2.1c">\lambda</annotation></semantics></math> and each <math id="S7.SS4.p5.3.m3.1" class="ltx_Math" alttext="0" display="inline"><semantics id="S7.SS4.p5.3.m3.1a"><mn id="S7.SS4.p5.3.m3.1.1" xref="S7.SS4.p5.3.m3.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="S7.SS4.p5.3.m3.1b"><cn type="integer" id="S7.SS4.p5.3.m3.1.1.cmml" xref="S7.SS4.p5.3.m3.1.1">0</cn></annotation-xml></semantics></math> to <math id="S7.SS4.p5.4.m4.1" class="ltx_Math" alttext="\frac{1-\lambda}{k-1}" display="inline"><semantics id="S7.SS4.p5.4.m4.1a"><mfrac id="S7.SS4.p5.4.m4.1.1" xref="S7.SS4.p5.4.m4.1.1.cmml"><mrow id="S7.SS4.p5.4.m4.1.1.2" xref="S7.SS4.p5.4.m4.1.1.2.cmml"><mn id="S7.SS4.p5.4.m4.1.1.2.2" xref="S7.SS4.p5.4.m4.1.1.2.2.cmml">1</mn><mo id="S7.SS4.p5.4.m4.1.1.2.1" xref="S7.SS4.p5.4.m4.1.1.2.1.cmml">−</mo><mi id="S7.SS4.p5.4.m4.1.1.2.3" xref="S7.SS4.p5.4.m4.1.1.2.3.cmml">λ</mi></mrow><mrow id="S7.SS4.p5.4.m4.1.1.3" xref="S7.SS4.p5.4.m4.1.1.3.cmml"><mi id="S7.SS4.p5.4.m4.1.1.3.2" xref="S7.SS4.p5.4.m4.1.1.3.2.cmml">k</mi><mo id="S7.SS4.p5.4.m4.1.1.3.1" xref="S7.SS4.p5.4.m4.1.1.3.1.cmml">−</mo><mn id="S7.SS4.p5.4.m4.1.1.3.3" xref="S7.SS4.p5.4.m4.1.1.3.3.cmml">1</mn></mrow></mfrac><annotation-xml encoding="MathML-Content" id="S7.SS4.p5.4.m4.1b"><apply id="S7.SS4.p5.4.m4.1.1.cmml" xref="S7.SS4.p5.4.m4.1.1"><divide id="S7.SS4.p5.4.m4.1.1.1.cmml" xref="S7.SS4.p5.4.m4.1.1"></divide><apply id="S7.SS4.p5.4.m4.1.1.2.cmml" xref="S7.SS4.p5.4.m4.1.1.2"><minus id="S7.SS4.p5.4.m4.1.1.2.1.cmml" xref="S7.SS4.p5.4.m4.1.1.2.1"></minus><cn type="integer" id="S7.SS4.p5.4.m4.1.1.2.2.cmml" xref="S7.SS4.p5.4.m4.1.1.2.2">1</cn><ci id="S7.SS4.p5.4.m4.1.1.2.3.cmml" xref="S7.SS4.p5.4.m4.1.1.2.3">𝜆</ci></apply><apply id="S7.SS4.p5.4.m4.1.1.3.cmml" xref="S7.SS4.p5.4.m4.1.1.3"><minus id="S7.SS4.p5.4.m4.1.1.3.1.cmml" xref="S7.SS4.p5.4.m4.1.1.3.1"></minus><ci id="S7.SS4.p5.4.m4.1.1.3.2.cmml" xref="S7.SS4.p5.4.m4.1.1.3.2">𝑘</ci><cn type="integer" id="S7.SS4.p5.4.m4.1.1.3.3.cmml" xref="S7.SS4.p5.4.m4.1.1.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.SS4.p5.4.m4.1c">\frac{1-\lambda}{k-1}</annotation></semantics></math>, where <math id="S7.SS4.p5.5.m5.1" class="ltx_Math" alttext="\lambda" display="inline"><semantics id="S7.SS4.p5.5.m5.1a"><mi id="S7.SS4.p5.5.m5.1.1" xref="S7.SS4.p5.5.m5.1.1.cmml">λ</mi><annotation-xml encoding="MathML-Content" id="S7.SS4.p5.5.m5.1b"><ci id="S7.SS4.p5.5.m5.1.1.cmml" xref="S7.SS4.p5.5.m5.1.1">𝜆</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.SS4.p5.5.m5.1c">\lambda</annotation></semantics></math> is a hyperparameter and <math id="S7.SS4.p5.6.m6.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S7.SS4.p5.6.m6.1a"><mi id="S7.SS4.p5.6.m6.1.1" xref="S7.SS4.p5.6.m6.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S7.SS4.p5.6.m6.1b"><ci id="S7.SS4.p5.6.m6.1.1.cmml" xref="S7.SS4.p5.6.m6.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.SS4.p5.6.m6.1c">k</annotation></semantics></math> is the number of classes. Second, an entropy based regularizer is added in the optimization objective. This step is somewhat redundant give that the first step already increases the entropy of the labels. Third, the model does not directly return its output on a queried instance <math id="S7.SS4.p5.7.m7.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S7.SS4.p5.7.m7.1a"><mi id="S7.SS4.p5.7.m7.1.1" xref="S7.SS4.p5.7.m7.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S7.SS4.p5.7.m7.1b"><ci id="S7.SS4.p5.7.m7.1.1.cmml" xref="S7.SS4.p5.7.m7.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.SS4.p5.7.m7.1c">x</annotation></semantics></math>. Instead, one randomly generates another instance, reshuffle the prediction vector of the randomly generated instance based on the order of the probabilities of <math id="S7.SS4.p5.8.m8.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S7.SS4.p5.8.m8.1a"><mi id="S7.SS4.p5.8.m8.1.1" xref="S7.SS4.p5.8.m8.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S7.SS4.p5.8.m8.1b"><ci id="S7.SS4.p5.8.m8.1.1.cmml" xref="S7.SS4.p5.8.m8.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.SS4.p5.8.m8.1c">x</annotation></semantics></math> and returns the reshuffled prediction vector. In essence, this last defense means returning only the order the classes in the prediction vector but not the actual values.</p>
</div>
<div id="S7.SS4.p6" class="ltx_para">
<p id="S7.SS4.p6.1" class="ltx_p"><span id="S7.SS4.p6.1.1" class="ltx_text ltx_font_bold">Mem-guard.</span> Jia et al. <cite class="ltx_cite ltx_citemacro_citep">(Jia et al<span class="ltx_text">.</span>, <a href="#bib.bib68" title="" class="ltx_ref">2019</a>)</cite> proposed the <span id="S7.SS4.p6.1.2" class="ltx_text ltx_font_bold">Mem-guard</span> defense. In this defense, one trains an MI attack model in addition to the target classifier. When the target classifier is queried with an instance, the resulting prediction vector is not directly returned. Instead, one tries to find a perturbed version of the vector such that the perturbation is minimal and does not change the predicted label, and the MI attack model output (0.5,0.5) as its prediction vector.</p>
</div>
<div id="S7.SS4.p7" class="ltx_para">
<p id="S7.SS4.p7.1" class="ltx_p"><span id="S7.SS4.p7.1.1" class="ltx_text ltx_font_bold">MIST.</span> Li et al. <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a href="#bib.bib81" title="" class="ltx_ref">2023</a>)</cite> proposed the <span id="S7.SS4.p7.1.2" class="ltx_text ltx_font_bold">Membership-Invariant Subspace Training (MIST)</span> defense. In this work, the authors showed that subspace learning methods can help defend against membership inference attacks and make the trained model more generalizable. In a typical subspace learning scenario, the whole training set is divided into disjoint subsets and the original model is copied multiple times to generate a submodel set. For each submodel, it is trained using an unique disjoint subset for several optimization steps and then all the submodels are aggregated together to get a new central model. This diversify-aggregate step is repeated until convergence. Based on the subspace learning methods, a new loss called <span id="S7.SS4.p7.1.3" class="ltx_text ltx_font_bold">cross-difference loss</span> is proposed. The cross difference loss is defined to be the difference between prediction from the submodel trained with one particular instance and the average predictions from all other submodels trained without this particular instance, since each instance can only be in one subset and thus be used in the training for one submodel. The experiments showed that MIST defense can achieve the state-of-the-art privacy-utility tradeoff. In <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a href="#bib.bib79" title="" class="ltx_ref">2021</a>; Tang et al<span class="ltx_text">.</span>, <a href="#bib.bib125" title="" class="ltx_ref">2022</a>; Chen and Pattabiraman, <a href="#bib.bib32" title="" class="ltx_ref">2023</a>; Li et al<span class="ltx_text">.</span>, <a href="#bib.bib81" title="" class="ltx_ref">2023</a>)</cite>, extensive experiments have shown that several other defenses can provide better empirical privacy-utility tradeoff than DP-SGD.</p>
</div>
</section>
</section>
<section id="S8" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">8. </span>Looking Ahead: Important Open Questions and Solution Directions</h2>

<div id="S8.p1" class="ltx_para">
<p id="S8.p1.1" class="ltx_p">The topic of Federated Learning privacy is seeing a lot of interest in research, development, and deployment. We expect that for the foreseeable future, there will be robust activity on this topic with the balance between research, development, and deployment shifting over time. Here are five high-level directions that will need to be pursued and answered for FL to become truly useful in practice.</p>
</div>
<div id="S8.p2" class="ltx_para">
<ol id="S8.I1" class="ltx_enumerate">
<li id="S8.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(1)</span> 
<div id="S8.I1.i1.p1" class="ltx_para">
<p id="S8.I1.i1.p1.1" class="ltx_p"><span id="S8.I1.i1.p1.1.1" class="ltx_text ltx_font_italic">Tradeoff between utility and privacy.</span>
Most privacy-preserving techniques in FL fall in the tradeoff space between utility of the model (how accurate is the model under benign circumstances) and the privacy afforded to the data. A prototypical example is perturbation of the gradients being reported by the clients. This can be done for example through Differential Privacy (DP). Existing solutions show that the loss in utility is sharp for reasonable levels of privacy protection <cite class="ltx_cite ltx_citemacro_citep">(Wei et al<span class="ltx_text">.</span>, <a href="#bib.bib133" title="" class="ltx_ref">2020</a>; Naseri et al<span class="ltx_text">.</span>, <a href="#bib.bib95" title="" class="ltx_ref">2020</a>; Kim et al<span class="ltx_text">.</span>, <a href="#bib.bib73" title="" class="ltx_ref">2021</a>)</cite>. There is work to be done in making this tradeoff more gradual. Broadly, compelling solutions in this space should be able to provide an adjustable tradeoff between these two dimensions.</p>
</div>
</li>
<li id="S8.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(2)</span> 
<div id="S8.I1.i2.p1" class="ltx_para">
<p id="S8.I1.i2.p1.1" class="ltx_p"><span id="S8.I1.i2.p1.1.1" class="ltx_text ltx_font_italic">From centralization to decentralization.</span>
The question is will privacy be helped by a move toward greater decentralization, away from the coordination of a central federated server. The direction of decentralized learning has seen some initial results that indicate the answer to the above question is a yes <cite class="ltx_cite ltx_citemacro_citep">(Koloskova et al<span class="ltx_text">.</span>, <a href="#bib.bib74" title="" class="ltx_ref">2020</a>; Sharma et al<span class="ltx_text">.</span>, <a href="#bib.bib113" title="" class="ltx_ref">2023</a>; Li et al<span class="ltx_text">.</span>, <a href="#bib.bib82" title="" class="ltx_ref">2022b</a>)</cite>. However, such decentralization also brings in the vulnerability of the learning process to malicious clients. The question of how to ensure security to malicious clients in such learning remains open. The challenge is how to make such a solution, which has some inherent privacy benefits, also secure to misbehaving participants.</p>
</div>
</li>
<li id="S8.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(3)</span> 
<div id="S8.I1.i3.p1" class="ltx_para">
<p id="S8.I1.i3.p1.1" class="ltx_p"><span id="S8.I1.i3.p1.1.1" class="ltx_text ltx_font_italic">Cerification of privacy.</span>
We need to be able to certify that the privacy achieved by a given solution meets any given regulation, which holds within a jurisdiction. Such certification is difficult enough in traditional deterministic programs and more so for the stochastic programs that are at the basis of the FL systems. In line with the policy and regulation discussion in Section <a href="#S5" title="5. Privacy-Related Policies ‣ Federated Learning Privacy: Attacks, Defenses, Applications, and Policy Landscape — A Survey" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>, for FL to become widely adopted in some critical application domains, it would be essential to provide privacy proofs so that the systems can be certified.</p>
</div>
</li>
<li id="S8.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(4)</span> 
<div id="S8.I1.i4.p1" class="ltx_para">
<p id="S8.I1.i4.p1.1" class="ltx_p"><span id="S8.I1.i4.p1.1.1" class="ltx_text ltx_font_italic">Verification of privacy.</span>
In one major line of work <cite class="ltx_cite ltx_citemacro_citep">(Zhao et al<span class="ltx_text">.</span>, <a href="#bib.bib149" title="" class="ltx_ref">2023b</a>; Fowl et al<span class="ltx_text">.</span>, <a href="#bib.bib51" title="" class="ltx_ref">2022</a>; Pasquini et al<span class="ltx_text">.</span>, <a href="#bib.bib102" title="" class="ltx_ref">2022</a>; Boenisch et al<span class="ltx_text">.</span>, <a href="#bib.bib23" title="" class="ltx_ref">2023</a>)</cite>, we have seen that privacy can be violated by the server by sending maliciously crafted models to the clients. This triggers the question what types of malicious models can be examined and detected by the faulty clients. The comparison can be quite a daunting task because of the relative weak computing power of clients, especially mobile and embedded clients, relative to the sizes of the models. The broad question is what does stealthiness of local data exfiltration mean with respect to the capability to verify by the clients.</p>
</div>
</li>
<li id="S8.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(5)</span> 
<div id="S8.I1.i5.p1" class="ltx_para">
<p id="S8.I1.i5.p1.1" class="ltx_p"><span id="S8.I1.i5.p1.1.1" class="ltx_text ltx_font_italic">Regulatory compliance</span> As FL systems become more prevalent, it is imperative to address ethical concerns and ensure transparency in the process towards regulatory compliance of AI systems. This involves understanding the implications of FL on various stakeholders, including data providers, model owners, and end-users. Transparency measures should be implemented to provide visibility into how FL operates, including data usage, model training, and decision-making processes. Additionally, ethical guidelines should be established to govern the responsible development and deployment of FL systems, considering factors such as fairness, bias mitigation, and accountability. Incorporating ethical considerations and transparency measures will enhance trust in FL systems and promote their responsible use in various applications. They are a step towards compliance with emerging AI regulations, such as the EU AI act <cite class="ltx_cite ltx_citemacro_citep">(Woisetschläger et al<span class="ltx_text">.</span>, <a href="#bib.bib135" title="" class="ltx_ref">2024</a>)</cite>.</p>
</div>
</li>
</ol>
</div>
<div id="S8.p3" class="ltx_para">
<p id="S8.p3.1" class="ltx_p">Each of these directions presents unique challenges that must be addressed to realize the full potential of FL while safeguarding data privacy.</p>
</div>
<div class="ltx_acknowledgements">
<h6 class="ltx_title ltx_title_acknowledgements">Acknowledgements.</h6>
To all our funding agencies.

</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(1)</span>
<span class="ltx_bibblock">        




</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">AIF ([n. d.])</span>
<span class="ltx_bibblock">
[n. d.].

</span>
<span class="ltx_bibblock">AI Foundation Model Transparency Act.

</span>
<span class="ltx_bibblock">([n. d.]).

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://beyer.house.gov/uploadedfiles/ai_foundation_model_transparency_act_text_118.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://beyer.house.gov/uploadedfiles/ai_foundation_model_transparency_act_text_118.pdf</a>

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">AIA ([n. d.])</span>
<span class="ltx_bibblock">
[n. d.].

</span>
<span class="ltx_bibblock">Algorithmic Accountability Act.

</span>
<span class="ltx_bibblock">([n. d.]).

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://www.congress.gov/bill/116th-congress/house-bill/2231" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.congress.gov/bill/116th-congress/house-bill/2231</a>

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">CCP ([n. d.])</span>
<span class="ltx_bibblock">
[n. d.].

</span>
<span class="ltx_bibblock">California Consumer Privacy Act.

</span>
<span class="ltx_bibblock">([n. d.]).

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://oag.ca.gov/privacy/ccpa" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://oag.ca.gov/privacy/ccpa</a>

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">CPR ([n. d.])</span>
<span class="ltx_bibblock">
[n. d.].

</span>
<span class="ltx_bibblock">California Privacy Rights Act.

</span>
<span class="ltx_bibblock">([n. d.]).

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://leginfo.legislature.ca.gov/faces/codes_displayText.xhtml?division=3.&amp;part=4.&amp;lawCode=CIV&amp;title=1.81.5" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://leginfo.legislature.ca.gov/faces/codes_displayText.xhtml?division=3.&amp;part=4.&amp;lawCode=CIV&amp;title=1.81.5</a>

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">EPI ([n. d.])</span>
<span class="ltx_bibblock">
[n. d.].

</span>
<span class="ltx_bibblock">EPIC Project.

</span>
<span class="ltx_bibblock">([n. d.]).

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://epic.org/the-state-of-state-ai-laws-2023/#:~:text=Of%20the%20AI%2Drelated%20laws,profiling%20and%20requiring%20impact%20assessments" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://epic.org/the-state-of-state-ai-laws-2023/#:~:text=Of%20the%20AI%2Drelated%20laws,profiling%20and%20requiring%20impact%20assessments</a>

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">FLI ([n. d.])</span>
<span class="ltx_bibblock">
[n. d.].

</span>
<span class="ltx_bibblock">Federated learning may provide a solution for future digital health challenges, howpublished = <a target="_blank" href="https://www.kcl.ac.uk/news/federated-learning-may-provide-a-solution-for-future-digital-health-challenges" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.kcl.ac.uk/news/federated-learning-may-provide-a-solution-for-future-digital-health-challenges</a>, note = Accessed: .

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">ten ([n. d.])</span>
<span class="ltx_bibblock">
[n. d.].

</span>
<span class="ltx_bibblock">Federated Learning with Formal Differential Privacy Guarantees.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://blog.research.google/2022/02/federated-learning-with-formal.html" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://blog.research.google/2022/02/federated-learning-with-formal.html</a>.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">Accessed: 2023-12-18.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">fet ([n. d.])</span>
<span class="ltx_bibblock">
[n. d.].

</span>
<span class="ltx_bibblock">The federated tumor segmentation (fets) initiative.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://www.med.upenn.edu/cbica/fets" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.med.upenn.edu/cbica/fets</a>.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">Accessed: .

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">FTC ([n. d.])</span>
<span class="ltx_bibblock">
[n. d.].

</span>
<span class="ltx_bibblock">FTC: AI Companies: Uphold Your Privacy and Confidentiality Commitments.

</span>
<span class="ltx_bibblock">([n. d.]).

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://www.ftc.gov/policy/advocacy-research/tech-at-ftc/2024/01/ai-companies-uphold-your-privacy-confidentiality-commitments" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.ftc.gov/policy/advocacy-research/tech-at-ftc/2024/01/ai-companies-uphold-your-privacy-confidentiality-commitments</a>

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">GDP ([n. d.])</span>
<span class="ltx_bibblock">
[n. d.].

</span>
<span class="ltx_bibblock">GDPR-General Data Protection Regulation.

</span>
<span class="ltx_bibblock">([n. d.]).

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://gdpr-info.eu/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://gdpr-info.eu/</a>

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">GLB ([n. d.])</span>
<span class="ltx_bibblock">
[n. d.].

</span>
<span class="ltx_bibblock">Gramm-Leach-Bliley Act.

</span>
<span class="ltx_bibblock">([n. d.]).

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://www.ftc.gov/business-guidance/privacy-security/gramm-leach-bliley-act" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.ftc.gov/business-guidance/privacy-security/gramm-leach-bliley-act</a>

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">HIP ([n. d.])</span>
<span class="ltx_bibblock">
[n. d.].

</span>
<span class="ltx_bibblock">Health Insurance Portability and Accountability Act.

</span>
<span class="ltx_bibblock">([n. d.]).

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://www.hhs.gov/hipaa/index.html" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.hhs.gov/hipaa/index.html</a>

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">hea ([n. d.])</span>
<span class="ltx_bibblock">
[n. d.].

</span>
<span class="ltx_bibblock">HealthChain consortium, howpublished = <a target="_blank" href="https://www.labelia.org/en/healthchain-project" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.labelia.org/en/healthchain-project</a>, note = Accessed: .

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">HR8 ([n. d.])</span>
<span class="ltx_bibblock">
[n. d.].

</span>
<span class="ltx_bibblock">H.R.8152 - American Data Privacy and Protection Act.

</span>
<span class="ltx_bibblock">([n. d.]).

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://www.congress.gov/bill/117th-congress/house-bill/8152/text" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.congress.gov/bill/117th-congress/house-bill/8152/text</a>

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">acr ([n. d.])</span>
<span class="ltx_bibblock">
[n. d.].

</span>
<span class="ltx_bibblock">Rhino Health and the American College of Radiology Enable Privacy-Preserving Artificial Intelligence.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://www.accesswire.com/728071/rhino-health-and-the-american-college-of-radiology-enable-privacy-preserving-artificial-intelligence" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.accesswire.com/728071/rhino-health-and-the-american-college-of-radiology-enable-privacy-preserving-artificial-intelligence</a>.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">Accessed: .

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">tex ([n. d.])</span>
<span class="ltx_bibblock">
[n. d.].

</span>
<span class="ltx_bibblock">Texas Data Privacy and Security Act.

</span>
<span class="ltx_bibblock">([n. d.]).

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://capitol.texas.gov/BillLookup/Text.aspx?LegSess=88R&amp;Bill=HB4" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://capitol.texas.gov/BillLookup/Text.aspx?LegSess=88R&amp;Bill=HB4</a>

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">TFD ([n. d.])</span>
<span class="ltx_bibblock">
[n. d.].

</span>
<span class="ltx_bibblock">Trustworthy Federated Data Analytics (TFDA).

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://tfda.hmsp.center/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://tfda.hmsp.center/</a>.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">Accessed: .

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">UN- ([n. d.])</span>
<span class="ltx_bibblock">
[n. d.].

</span>
<span class="ltx_bibblock">United Nations Money Laundering Overview.

</span>
<span class="ltx_bibblock">([n. d.]).

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://www.unodc.org/unodc/en/money-laundering/overview.html" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.unodc.org/unodc/en/money-laundering/overview.html</a>

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Abad et al<span id="bib.bib20.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Mehdi Salehi Heydar Abad, Emre Ozfatura, Deniz Gunduz, and Ozgur Ercetin. 2020.

</span>
<span class="ltx_bibblock">Hierarchical federated learning across heterogeneous cellular networks. In <em id="bib.bib20.3.1" class="ltx_emph ltx_font_italic">ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>. IEEE, 8866–8870.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Abadi et al<span id="bib.bib21.2.2.1" class="ltx_text">.</span> (2016)</span>
<span class="ltx_bibblock">
Martín Abadi, Andy Chu, Ian Goodfellow, H Brendan McMahan, Ilya Mironov, Kunal Talwar, and Li Zhang. 2016.

</span>
<span class="ltx_bibblock">Deep learning with differential privacy. In <em id="bib.bib21.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security</em>. ACM, 308–318.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bell et al<span id="bib.bib22.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
James Henry Bell, Kallista A Bonawitz, Adrià Gascón, Tancrède Lepoint, and Mariana Raykova. 2020.

</span>
<span class="ltx_bibblock">Secure single-server aggregation with (poly) logarithmic overhead. In <em id="bib.bib22.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 2020 ACM SIGSAC Conference on Computer and Communications Security</em>. 1253–1269.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Boenisch et al<span id="bib.bib23.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Franziska Boenisch, Adam Dziedzic, Roei Schuster, Ali Shahin Shamsabadi, Ilia Shumailov, and Nicolas Papernot. 2023.

</span>
<span class="ltx_bibblock">When the curious abandon honesty: Federated learning is not private.

</span>
<span class="ltx_bibblock"><em id="bib.bib23.3.1" class="ltx_emph ltx_font_italic">8th IEEE European Symposium on Security and Privacy (IEEE Euro S&amp;P)</em> (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bonawitz et al<span id="bib.bib24.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Keith Bonawitz, Vladimir Ivanov, Ben Kreuter, Antonio Marcedone, H Brendan McMahan, Sarvar Patel, Daniel Ramage, Aaron Segal, and Karn Seth. 2017.

</span>
<span class="ltx_bibblock">Practical secure aggregation for privacy-preserving machine learning. In <em id="bib.bib24.3.1" class="ltx_emph ltx_font_italic">proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security</em>. 1175–1191.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bouacida and Mohapatra (2021)</span>
<span class="ltx_bibblock">
Nader Bouacida and Prasant Mohapatra. 2021.

</span>
<span class="ltx_bibblock">Vulnerabilities in federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">IEEE Access</em> 9 (2021), 63229–63249.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Briggs et al<span id="bib.bib26.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Christopher Briggs, Zhong Fan, and Peter Andras. 2020.

</span>
<span class="ltx_bibblock">Federated learning with hierarchical clustering of local updates to improve training on non-IID data. In <em id="bib.bib26.3.1" class="ltx_emph ltx_font_italic">2020 International Joint Conference on Neural Networks (IJCNN)</em>. IEEE, 1–9.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Carlini et al<span id="bib.bib27.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Nicholas Carlini, Steve Chien, Milad Nasr, Shuang Song, Andreas Terzis, and Florian Tramer. 2022.

</span>
<span class="ltx_bibblock">Membership inference attacks from first principles. In <em id="bib.bib27.3.1" class="ltx_emph ltx_font_italic">2022 IEEE Symposium on Security and Privacy (SP)</em>. IEEE, 1897–1914.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al<span id="bib.bib28.2.2.1" class="ltx_text">.</span> (2023b)</span>
<span class="ltx_bibblock">
Huiqiang Chen, Tianqing Zhu, Tao Zhang, Wanlei Zhou, and Philip S Yu. 2023b.

</span>
<span class="ltx_bibblock">Privacy and Fairness in Federated Learning: on the Perspective of Trade-off.

</span>
<span class="ltx_bibblock"><em id="bib.bib28.3.1" class="ltx_emph ltx_font_italic">Comput. Surveys</em> (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen and Guestrin (2016)</span>
<span class="ltx_bibblock">
Tianqi Chen and Carlos Guestrin. 2016.

</span>
<span class="ltx_bibblock">XGBoost: A Scalable Tree Boosting System. In <em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</em> (San Francisco, California, USA) <em id="bib.bib29.2.2" class="ltx_emph ltx_font_italic">(KDD ’16)</em>. ACM, New York, NY, USA, 785–794.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/2939672.2939785" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/2939672.2939785</a>

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al<span id="bib.bib30.2.2.1" class="ltx_text">.</span> (2023a)</span>
<span class="ltx_bibblock">
Yanjiao Chen, Rui Guan, Xueluan Gong, Jianshuo Dong, and Meng Xue. 2023a.

</span>
<span class="ltx_bibblock">D-dae: Defense-penetrating model extraction attacks. In <em id="bib.bib30.3.1" class="ltx_emph ltx_font_italic">IEEE Symposium on Security and Privacy (SP)</em>. IEEE, 382–399.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al<span id="bib.bib31.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Yao Chen, Yijie Gui, Hong Lin, Wensheng Gan, and Yongdong Wu. 2022.

</span>
<span class="ltx_bibblock">Federated learning attacks and defenses: A survey. In <em id="bib.bib31.3.1" class="ltx_emph ltx_font_italic">2022 IEEE International Conference on Big Data (Big Data)</em>. IEEE, 4256–4265.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen and Pattabiraman (2023)</span>
<span class="ltx_bibblock">
Zitao Chen and Karthik Pattabiraman. 2023.

</span>
<span class="ltx_bibblock">Overconfidence is a Dangerous Thing: Mitigating Membership Inference Attacks by Enforcing Less Confident Prediction.

</span>
<span class="ltx_bibblock"><em id="bib.bib32.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2307.01610</em> (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cheng et al<span id="bib.bib33.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Kewei Cheng, Tao Fan, Yilun Jin, Yang Liu, Tianjian Chen, Dimitrios Papadopoulos, and Qiang Yang. 2021.

</span>
<span class="ltx_bibblock">SecureBoost: A lossless federated learning framework.

</span>
<span class="ltx_bibblock"><em id="bib.bib33.3.1" class="ltx_emph ltx_font_italic">IEEE Intelligent Systems</em> 36, 6 (2021), 87–98.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cheon et al<span id="bib.bib34.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Jung Hee Cheon, Andrey Kim, Miran Kim, and Yongsoo Song. 2017.

</span>
<span class="ltx_bibblock">Homomorphic encryption for arithmetic of approximate numbers. In <em id="bib.bib34.3.1" class="ltx_emph ltx_font_italic">Advances in Cryptology–ASIACRYPT 2017: 23rd International Conference on the Theory and Applications of Cryptology and Information Security, Hong Kong, China, December 3-7, 2017, Proceedings, Part I 23</em>. Springer, 409–437.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cho et al<span id="bib.bib35.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Yae Jee Cho, Andre Manoel, Gauri Joshi, Robert Sim, and Dimitrios Dimitriadis. 2022.

</span>
<span class="ltx_bibblock">Heterogeneous Ensemble Knowledge Transfer for Training Large Models in Federated Learning. In <em id="bib.bib35.3.1" class="ltx_emph ltx_font_italic">Proceedings of the Thirty-First International Joint Conference on Artificial Intelligence, IJCAI-22</em>. International Joint Conferences on Artificial Intelligence Organization, 2881–2887.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Commission et al<span id="bib.bib36.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
European Commission, Content Directorate-General for Communications Networks, and Technology. 2019.

</span>
<span class="ltx_bibblock"><em id="bib.bib36.3.1" class="ltx_emph ltx_font_italic">Ethics guidelines for trustworthy AI</em>.

</span>
<span class="ltx_bibblock">Publications Office.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/doi/10.2759/346720" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/doi/10.2759/346720</a>

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cremonesi et al<span id="bib.bib37.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Francesco Cremonesi, Marc Vesin, Sergen Cansiz, Yannick Bouillard, Irene Balelli, Lucia Innocenti, Santiago Silva, Samy-Safwan Ayed, Riccardo Taiello, Laetita Kameni, et al<span id="bib.bib37.3.1" class="ltx_text">.</span> 2023.

</span>
<span class="ltx_bibblock">Fed-BioMed: Open, Transparent and Trusted Federated Learning for Real-world Healthcare Applications.

</span>
<span class="ltx_bibblock"><em id="bib.bib37.4.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2304.12012</em> (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dayan et al<span id="bib.bib38.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Ittai Dayan, Holger R Roth, Aoxiao Zhong, Ahmed Harouni, Amilcare Gentili, Anas Z Abidin, Andrew Liu, Anthony Beardsworth Costa, Bradford J Wood, Chien-Sung Tsai, et al<span id="bib.bib38.3.1" class="ltx_text">.</span> 2021.

</span>
<span class="ltx_bibblock">Federated learning for predicting clinical outcomes in patients with COVID-19.

</span>
<span class="ltx_bibblock"><em id="bib.bib38.4.1" class="ltx_emph ltx_font_italic">Nature medicine</em> 27, 10 (2021), 1735–1743.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Diao et al<span id="bib.bib39.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Enmao Diao, Jie Ding, and Vahid Tarokh. 2021.

</span>
<span class="ltx_bibblock">Hetero{FL}: Computation and Communication Efficient Federated Learning for Heterogeneous Clients. In <em id="bib.bib39.3.1" class="ltx_emph ltx_font_italic">International Conference on Learning Representations</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dibbo et al<span id="bib.bib40.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Sayanton V Dibbo, Dae Lim Chung, and Shagufta Mehnaz. 2023.

</span>
<span class="ltx_bibblock">Model inversion attack with least information and an in-depth analysis of its disparate vulnerability. In <em id="bib.bib40.3.1" class="ltx_emph ltx_font_italic">2023 IEEE Conference on Secure and Trustworthy Machine Learning (SaTML)</em>. IEEE, 119–135.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Diffie and Hellman (1976)</span>
<span class="ltx_bibblock">
Whitfield Diffie and Martin Hellman. 1976.

</span>
<span class="ltx_bibblock">New directions in cryptography.

</span>
<span class="ltx_bibblock"><em id="bib.bib41.1.1" class="ltx_emph ltx_font_italic">IEEE transactions on Information Theory</em> 22, 6 (1976), 644–654.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dong et al<span id="bib.bib42.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Jinshuo Dong, Aaron Roth, and Weijie J Su. 2019.

</span>
<span class="ltx_bibblock">Gaussian differential privacy.

</span>
<span class="ltx_bibblock"><em id="bib.bib42.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1905.02383</em> (2019).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dwork (2008)</span>
<span class="ltx_bibblock">
Cynthia Dwork. 2008.

</span>
<span class="ltx_bibblock">Differential privacy: A survey of results. In <em id="bib.bib43.1.1" class="ltx_emph ltx_font_italic">International Conference on Theory and Applications of Models of Computation</em>. Springer, 1–19.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dwork et al<span id="bib.bib44.2.2.1" class="ltx_text">.</span> (2006)</span>
<span class="ltx_bibblock">
Cynthia Dwork, Frank McSherry, Kobbi Nissim, and Adam Smith. 2006.

</span>
<span class="ltx_bibblock">Calibrating noise to sensitivity in private data analysis. In <em id="bib.bib44.3.1" class="ltx_emph ltx_font_italic">Theory of cryptography conference</em>. Springer, 265–284.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">El Ouadrhiri and Abdelhadi (2022)</span>
<span class="ltx_bibblock">
Ahmed El Ouadrhiri and Ahmed Abdelhadi. 2022.

</span>
<span class="ltx_bibblock">Differential privacy for deep and federated learning: A survey.

</span>
<span class="ltx_bibblock"><em id="bib.bib45.1.1" class="ltx_emph ltx_font_italic">IEEE access</em> 10 (2022), 22359–22380.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Elkordy et al<span id="bib.bib46.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Ahmed Roushdy Elkordy, Jiang Zhang, Yahya H Ezzeldin, Konstantinos Psounis, and Salman Avestimehr. 2022.

</span>
<span class="ltx_bibblock">How much privacy does federated learning with secure aggregation guarantee?

</span>
<span class="ltx_bibblock"><em id="bib.bib46.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2208.02304</em> (2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fan et al<span id="bib.bib47.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Lixin Fan, Kam Woh Ng, Ce Ju, Tianyu Zhang, Chang Liu, Chee Seng Chan, and Qiang Yang. 2020.

</span>
<span class="ltx_bibblock">Rethinking privacy preserving deep learning: How to evaluate and thwart privacy attacks.

</span>
<span class="ltx_bibblock">In <em id="bib.bib47.3.1" class="ltx_emph ltx_font_italic">Federated Learning</em>. Springer, 32–50.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fang and Qian (2021)</span>
<span class="ltx_bibblock">
Haokun Fang and Quan Qian. 2021.

</span>
<span class="ltx_bibblock">Privacy preserving machine learning with homomorphic encryption and federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib48.1.1" class="ltx_emph ltx_font_italic">Future Internet</em> 13, 4 (2021), 94.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Feng et al<span id="bib.bib49.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Jie Feng, Lei Liu, Qingqi Pei, and Keqin Li. 2021.

</span>
<span class="ltx_bibblock">Min-max cost optimization for efficient hierarchical federated learning in wireless edge networks.

</span>
<span class="ltx_bibblock"><em id="bib.bib49.3.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Parallel and Distributed Systems</em> 33, 11 (2021), 2687–2700.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fortet and Mourier (1953)</span>
<span class="ltx_bibblock">
Robert Fortet and Edith Mourier. 1953.

</span>
<span class="ltx_bibblock">Convergence de la répartition empirique vers la répartition théorique.

</span>
<span class="ltx_bibblock"><em id="bib.bib50.1.1" class="ltx_emph ltx_font_italic">Annales scientifiques de l’École Normale Supérieure</em> 70, 3 (1953), 267–285.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fowl et al<span id="bib.bib51.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Liam H Fowl, Jonas Geiping, Wojciech Czaja, Micah Goldblum, and Tom Goldstein. 2022.

</span>
<span class="ltx_bibblock">Robbing the Fed: Directly Obtaining Private Data in Federated Learning with Modified Models. In <em id="bib.bib51.3.1" class="ltx_emph ltx_font_italic">International Conference on Learning Representations</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fredrikson et al<span id="bib.bib52.2.2.1" class="ltx_text">.</span> (2015)</span>
<span class="ltx_bibblock">
Matt Fredrikson, Somesh Jha, and Thomas Ristenpart. 2015.

</span>
<span class="ltx_bibblock">Model inversion attacks that exploit confidence information and basic countermeasures. In <em id="bib.bib52.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 22nd ACM SIGSAC Conference on Computer and Communications Security</em>. 1322–1333.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Froelicher et al<span id="bib.bib53.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
David Froelicher, Juan R Troncoso-Pastoriza, Jean Louis Raisaro, Michel A Cuendet, Joao Sa Sousa, Hyunghoon Cho, Bonnie Berger, Jacques Fellay, and Jean-Pierre Hubaux. 2021.

</span>
<span class="ltx_bibblock">Truly privacy-preserving federated analytics for precision medicine with multiparty homomorphic encryption.

</span>
<span class="ltx_bibblock"><em id="bib.bib53.3.1" class="ltx_emph ltx_font_italic">Nature communications</em> 12, 1 (2021), 5910.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ganju et al<span id="bib.bib54.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Karan Ganju, Qi Wang, Wei Yang, Carl A Gunter, and Nikita Borisov. 2018.

</span>
<span class="ltx_bibblock">Property inference attacks on fully connected neural networks using permutation invariant representations. In <em id="bib.bib54.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 2018 ACM SIGSAC conference on computer and communications security</em>. 619–633.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Geiping et al<span id="bib.bib55.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Jonas Geiping, Hartmut Bauermeister, Hannah Dröge, and Michael Moeller. 2020.

</span>
<span class="ltx_bibblock">Inverting gradients-how easy is it to break privacy in federated learning?

</span>
<span class="ltx_bibblock"><em id="bib.bib55.3.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em> 33 (2020), 16937–16947.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gong et al<span id="bib.bib56.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Xueluan Gong, Qian Wang, Yanjiao Chen, Wang Yang, and Xinchang Jiang. 2020.

</span>
<span class="ltx_bibblock">Model extraction attacks and defenses on cloud-based machine learning models.

</span>
<span class="ltx_bibblock"><em id="bib.bib56.3.1" class="ltx_emph ltx_font_italic">IEEE Communications Magazine</em> 58, 12 (2020), 83–89.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gretton et al<span id="bib.bib57.2.2.1" class="ltx_text">.</span> (2012)</span>
<span class="ltx_bibblock">
Arthur Gretton, Karsten M Borgwardt, Malte J Rasch, Bernhard Schölkopf, and Alexander Smola. 2012.

</span>
<span class="ltx_bibblock">A kernel two-sample test.

</span>
<span class="ltx_bibblock"><em id="bib.bib57.3.1" class="ltx_emph ltx_font_italic">Journal of Machine Learning Research</em> 13, Mar (2012), 723–773.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hard et al<span id="bib.bib58.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Andrew Hard, Chloé M Kiddon, Daniel Ramage, Francoise Beaufays, Hubert Eichner, Kanishka Rao, Rajiv Mathews, and Sean Augenstein. 2018.

</span>
<span class="ltx_bibblock">Federated Learning for Mobile Keyboard Prediction.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://arxiv.org/abs/1811.03604" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/abs/1811.03604</a>

</span>
</li>
<li id="bib.bib59" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hatamizadeh et al<span id="bib.bib59.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Ali Hatamizadeh, Hongxu Yin, Pavlo Molchanov, Andriy Myronenko, Wenqi Li, Prerna Dogra, Andrew Feng, Mona G Flores, Jan Kautz, Daguang Xu, et al<span id="bib.bib59.3.1" class="ltx_text">.</span> 2023.

</span>
<span class="ltx_bibblock">Do gradient inversion attacks make federated learning unsafe?

</span>
<span class="ltx_bibblock"><em id="bib.bib59.4.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Medical Imaging</em> (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib60" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hatamizadeh et al<span id="bib.bib60.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Ali Hatamizadeh, Hongxu Yin, Holger R Roth, Wenqi Li, Jan Kautz, Daguang Xu, and Pavlo Molchanov. 2022.

</span>
<span class="ltx_bibblock">Gradvit: Gradient inversion of vision transformers. In <em id="bib.bib60.3.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>. 10021–10030.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib61" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Heyndrickx et al<span id="bib.bib61.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Wouter Heyndrickx, Lewis Mervin, Tobias Morawietz, Noé Sturm, Lukas Friedrich, Adam Zalewski, Anastasia Pentina, Lina Humbeck, Martijn Oldenhof, Ritsuya Niwayama, et al<span id="bib.bib61.3.1" class="ltx_text">.</span> 2023.

</span>
<span class="ltx_bibblock">Melloddy: Cross-pharma federated learning at unprecedented scale unlocks benefits in qsar without compromising proprietary information.

</span>
<span class="ltx_bibblock"><em id="bib.bib61.4.1" class="ltx_emph ltx_font_italic">Journal of chemical information and modeling</em> (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib62" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hinton et al<span id="bib.bib62.2.2.1" class="ltx_text">.</span> (2015)</span>
<span class="ltx_bibblock">
Geoffrey Hinton, Oriol Vinyals, and Jeff Dean. 2015.

</span>
<span class="ltx_bibblock">Distilling the knowledge in a neural network.

</span>
<span class="ltx_bibblock"><em id="bib.bib62.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1503.02531</em> (2015).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib63" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hitaj et al<span id="bib.bib63.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Briland Hitaj, Giuseppe Ateniese, and Fernando Perez-Cruz. 2017.

</span>
<span class="ltx_bibblock">Deep models under the GAN: information leakage from collaborative deep learning. In <em id="bib.bib63.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 2017 ACM SIGSAC conference on computer and communications security</em>. 603–618.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib64" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huba et al<span id="bib.bib64.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Dzmitry Huba, John Nguyen, Kshitiz Malik, Ruiyu Zhu, Mike Rabbat, Ashkan Yousefpour, Carole-Jean Wu, Hongyuan Zhan, Pavel Ustinov, Harish Srinivas, et al<span id="bib.bib64.3.1" class="ltx_text">.</span> 2022.

</span>
<span class="ltx_bibblock">Papaya: Practical, private, and scalable federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib64.4.1" class="ltx_emph ltx_font_italic">Proceedings of Machine Learning and Systems</em> 4 (2022), 814–832.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib65" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hui et al<span id="bib.bib65.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Bo Hui, Yuchen Yang, Haolin Yuan, Philippe Burlina, Neil Zhenqiang Gong, and Yinzhi Cao. 2021.

</span>
<span class="ltx_bibblock">Practical Blind Membership Inference Attack via Differential Comparisons. In <em id="bib.bib65.3.1" class="ltx_emph ltx_font_italic">ISOC Network and Distributed System Security Symposium (NDSS)</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib66" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jahani-Nezhad et al<span id="bib.bib66.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Tayyebeh Jahani-Nezhad, Mohammad Ali Maddah-Ali, Songze Li, and Giuseppe Caire. 2022.

</span>
<span class="ltx_bibblock">Swiftagg: Communication-efficient and dropout-resistant secure aggregation for federated learning with worst-case security guarantees.

</span>
<span class="ltx_bibblock"><em id="bib.bib66.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2202.04169</em> (2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib67" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jayaraman et al<span id="bib.bib67.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Bargav Jayaraman, Lingxiao Wang, Katherine Knipmeyer, Quanquan Gu, and David Evans. 2021.

</span>
<span class="ltx_bibblock">Revisiting Membership Inference Under Realistic Assumptions.

</span>
<span class="ltx_bibblock"><em id="bib.bib67.3.1" class="ltx_emph ltx_font_italic">Proceedings on Privacy Enhancing Technologies</em> 2021, 2 (2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib68" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jia et al<span id="bib.bib68.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Jinyuan Jia, Ahmed Salem, Michael Backes, Yang Zhang, and Neil Zhenqiang Gong. 2019.

</span>
<span class="ltx_bibblock">MemGuard: Defending against Black-Box Membership Inference Attacks via Adversarial Examples. In <em id="bib.bib68.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 2019 ACM SIGSAC Conference on Computer and Communications Security</em>. 259–274.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib69" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jin et al<span id="bib.bib69.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Weizhao Jin, Yuhang Yao, Shanshan Han, Carlee Joe-Wong, Srivatsan Ravi, Salman Avestimehr, and Chaoyang He. 2023.

</span>
<span class="ltx_bibblock">FedML-HE: An Efficient Homomorphic-Encryption-Based Privacy-Preserving Federated Learning System.

</span>
<span class="ltx_bibblock"><em id="bib.bib69.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2303.10837</em> (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib70" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kadhe et al<span id="bib.bib70.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Swanand Kadhe, Nived Rajaraman, O Ozan Koyluoglu, and Kannan Ramchandran. 2020.

</span>
<span class="ltx_bibblock">Fastsecagg: Scalable secure aggregation for privacy-preserving federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib70.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2009.11248</em> (2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib71" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kariyappa et al<span id="bib.bib71.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Sanjay Kariyappa, Chuan Guo, Kiwan Maeng, Wenjie Xiong, G Edward Suh, Moinuddin K Qureshi, and Hsien-Hsin S Lee. 2023.

</span>
<span class="ltx_bibblock">Cocktail party attack: Breaking aggregation-based privacy in federated learning using independent component analysis. In <em id="bib.bib71.3.1" class="ltx_emph ltx_font_italic">International Conference on Machine Learning</em>. PMLR, 15884–15899.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib72" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Khan et al<span id="bib.bib72.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Mashal Khan, Frank G Glavin, and Matthias Nickles. 2023.

</span>
<span class="ltx_bibblock">Federated learning as a privacy solution-an overview.

</span>
<span class="ltx_bibblock"><em id="bib.bib72.3.1" class="ltx_emph ltx_font_italic">Procedia Computer Science</em> 217 (2023), 316–325.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib73" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kim et al<span id="bib.bib73.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Muah Kim, Onur Günlü, and Rafael F Schaefer. 2021.

</span>
<span class="ltx_bibblock">Federated learning with local differential privacy: Trade-offs between privacy, utility, and communication. In <em id="bib.bib73.3.1" class="ltx_emph ltx_font_italic">ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>. IEEE, 2650–2654.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib74" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Koloskova et al<span id="bib.bib74.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Anastasia Koloskova, Nicolas Loizou, Sadra Boreiri, Martin Jaggi, and Sebastian Stich. 2020.

</span>
<span class="ltx_bibblock">A unified theory of decentralized sgd with changing topology and local updates. In <em id="bib.bib74.3.1" class="ltx_emph ltx_font_italic">International Conference on Machine Learning</em>. PMLR, 5381–5393.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib75" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Koo et al<span id="bib.bib75.2.2.1" class="ltx_text">.</span> (2009)</span>
<span class="ltx_bibblock">
Jinkyu Koo, Rajesh K Panta, Saurabh Bagchi, and Luis Montestruque. 2009.

</span>
<span class="ltx_bibblock">A tale of two synchronizing clocks. In <em id="bib.bib75.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 7th ACM Conference on Embedded Networked Sensor Systems (Sensys)</em>. 239–252.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib76" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Koskela et al<span id="bib.bib76.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Antti Koskela, Joonas Jälkö, and Antti Honkela. 2020.

</span>
<span class="ltx_bibblock">Computing tight differential privacy guarantees using fft. In <em id="bib.bib76.3.1" class="ltx_emph ltx_font_italic">International Conference on Artificial Intelligence and Statistics</em>. PMLR, 2560–2569.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib77" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lam et al<span id="bib.bib77.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Maximilian Lam, Gu-Yeon Wei, David Brooks, Vijay Janapa Reddi, and Michael Mitzenmacher. 2021.

</span>
<span class="ltx_bibblock">Gradient disaggregation: Breaking privacy in federated learning by reconstructing the user participant matrix. In <em id="bib.bib77.3.1" class="ltx_emph ltx_font_italic">International Conference on Machine Learning</em>. PMLR, 5959–5968.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib78" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lee et al<span id="bib.bib78.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Joon-Woo Lee, HyungChul Kang, Yongwoo Lee, Woosuk Choi, Jieun Eom, Maxim Deryabin, Eunsang Lee, Junghyun Lee, Donghoon Yoo, Young-Sik Kim, et al<span id="bib.bib78.3.1" class="ltx_text">.</span> 2022.

</span>
<span class="ltx_bibblock">Privacy-preserving machine learning with fully homomorphic encryption for deep neural network.

</span>
<span class="ltx_bibblock"><em id="bib.bib78.4.1" class="ltx_emph ltx_font_italic">IEEE Access</em> 10 (2022), 30039–30054.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib79" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al<span id="bib.bib79.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Jiacheng Li, Ninghui Li, and Bruno Ribeiro. 2021.

</span>
<span class="ltx_bibblock">Membership inference attacks and defenses in classification models. In <em id="bib.bib79.3.1" class="ltx_emph ltx_font_italic">Proceedings of the Eleventh ACM Conference on Data and Application Security and Privacy</em>. 5–16.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib80" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al<span id="bib.bib80.2.2.1" class="ltx_text">.</span> (2022a)</span>
<span class="ltx_bibblock">
Jiacheng Li, Ninghui Li, and Bruno Ribeiro. 2022a.

</span>
<span class="ltx_bibblock">Effective passive membership inference attacks in federated learning against overparameterized models. In <em id="bib.bib80.3.1" class="ltx_emph ltx_font_italic">The Eleventh International Conference on Learning Representations</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib81" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al<span id="bib.bib81.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Jiacheng Li, Ninghui Li, and Bruno Ribeiro. 2023.

</span>
<span class="ltx_bibblock">MIST: Defending Against Membership Inference Attacks Through Membership-Invariant Subspace Training.

</span>
<span class="ltx_bibblock"><em id="bib.bib81.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2311.00919</em> (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib82" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al<span id="bib.bib82.2.2.1" class="ltx_text">.</span> (2022b)</span>
<span class="ltx_bibblock">
Shuangtong Li, Tianyi Zhou, Xinmei Tian, and Dacheng Tao. 2022b.

</span>
<span class="ltx_bibblock">Learning to collaborate in decentralized learning of personalized models. In <em id="bib.bib82.3.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>. 9766–9775.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib83" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al<span id="bib.bib83.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Tian Li, Anit Kumar Sahu, Ameet Talwalkar, and Virginia Smith. 2020.

</span>
<span class="ltx_bibblock">Federated learning: Challenges, methods, and future directions.

</span>
<span class="ltx_bibblock"><em id="bib.bib83.3.1" class="ltx_emph ltx_font_italic">IEEE signal processing magazine</em> 37, 3 (2020), 50–60.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib84" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al<span id="bib.bib84.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Lumin Liu, Jun Zhang, SH Song, and Khaled B Letaief. 2020.

</span>
<span class="ltx_bibblock">Client-edge-cloud hierarchical federated learning. In <em id="bib.bib84.3.1" class="ltx_emph ltx_font_italic">ICC 2020-2020 IEEE International Conference on Communications (ICC)</em>. IEEE, 1–6.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib85" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al<span id="bib.bib85.2.2.1" class="ltx_text">.</span> (2022b)</span>
<span class="ltx_bibblock">
Lumin Liu, Jun Zhang, Shenghui Song, and Khaled B Letaief. 2022b.

</span>
<span class="ltx_bibblock">Hierarchical federated learning with quantization: Convergence analysis and system design.

</span>
<span class="ltx_bibblock"><em id="bib.bib85.3.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Wireless Communications</em> 22, 1 (2022), 2–18.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib86" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al<span id="bib.bib86.2.2.1" class="ltx_text">.</span> (2022a)</span>
<span class="ltx_bibblock">
Pengrui Liu, Xiangrui Xu, and Wei Wang. 2022a.

</span>
<span class="ltx_bibblock">Threats, attacks and defenses to federated learning: issues, taxonomy and perspectives.

</span>
<span class="ltx_bibblock"><em id="bib.bib86.3.1" class="ltx_emph ltx_font_italic">Cybersecurity</em> 5, 1 (2022), 1–19.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib87" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Luo et al<span id="bib.bib87.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
B. Luo, Y. Feng, S. Wang, J. Huang, and L. Tassiulas. 2023.

</span>
<span class="ltx_bibblock">Incentive Mechanism Design for Unbiased Federated Learning with Randomized Client Participation. In <em id="bib.bib87.3.1" class="ltx_emph ltx_font_italic">2023 IEEE 43rd International Conference on Distributed Computing Systems (ICDCS)</em>. IEEE Computer Society, Los Alamitos, CA, USA, 545–555.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib88" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lyu et al<span id="bib.bib88.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Lingjuan Lyu, Han Yu, Xingjun Ma, Chen Chen, Lichao Sun, Jun Zhao, Qiang Yang, and S Yu Philip. 2022.

</span>
<span class="ltx_bibblock">Privacy and robustness in federated learning: Attacks and defenses.

</span>
<span class="ltx_bibblock"><em id="bib.bib88.3.1" class="ltx_emph ltx_font_italic">IEEE transactions on neural networks and learning systems</em> (2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib89" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mansour et al<span id="bib.bib89.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Y. Mansour, Mehryar Mohri, Jae Ro, and Ananda Theertha Suresh. 2020.

</span>
<span class="ltx_bibblock">Three Approaches for Personalization with Applications to Federated Learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib89.3.1" class="ltx_emph ltx_font_italic">ArXiv</em> abs/2002.10619 (2020).

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://api.semanticscholar.org/CorpusID:211296702" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://api.semanticscholar.org/CorpusID:211296702</a>

</span>
</li>
<li id="bib.bib90" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">McMahan et al<span id="bib.bib90.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Aguera y Arcas. 2017.

</span>
<span class="ltx_bibblock">Communication-efficient learning of deep networks from decentralized data. In <em id="bib.bib90.3.1" class="ltx_emph ltx_font_italic">Artificial intelligence and statistics</em>. PMLR, 1273–1282.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib91" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mehnaz et al<span id="bib.bib91.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Shagufta Mehnaz, Sayanton V Dibbo, Roberta De Viti, Ehsanul Kabir, Björn B Brandenburg, Stefan Mangard, Ninghui Li, Elisa Bertino, Michael Backes, Emiliano De Cristofaro, et al<span id="bib.bib91.3.1" class="ltx_text">.</span> 2022.

</span>
<span class="ltx_bibblock">Are your sensitive attributes private? Novel model inversion attribute inference attacks on classification models. In <em id="bib.bib91.4.1" class="ltx_emph ltx_font_italic">31st USENIX Security Symposium (USENIX Security 22)</em>. 4579–4596.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib92" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Melis et al<span id="bib.bib92.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Luca Melis, Congzheng Song, Emiliano De Cristofaro, and Vitaly Shmatikov. 2019.

</span>
<span class="ltx_bibblock">Exploiting unintended feature leakage in collaborative learning. In <em id="bib.bib92.3.1" class="ltx_emph ltx_font_italic">2019 IEEE symposium on security and privacy (SP)</em>. IEEE, 691–706.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib93" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mironov (2017)</span>
<span class="ltx_bibblock">
Ilya Mironov. 2017.

</span>
<span class="ltx_bibblock">Rényi differential privacy. In <em id="bib.bib93.1.1" class="ltx_emph ltx_font_italic">2017 IEEE 30th computer security foundations symposium (CSF)</em>. IEEE, 263–275.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib94" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mothukuri et al<span id="bib.bib94.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Viraaji Mothukuri, Reza M Parizi, Seyedamin Pouriyeh, Yan Huang, Ali Dehghantanha, and Gautam Srivastava. 2021.

</span>
<span class="ltx_bibblock">A survey on security and privacy of federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib94.3.1" class="ltx_emph ltx_font_italic">Future Generation Computer Systems</em> 115 (2021), 619–640.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib95" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Naseri et al<span id="bib.bib95.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Mohammad Naseri, Jamie Hayes, and Emiliano De Cristofaro. 2020.

</span>
<span class="ltx_bibblock">Local and central differential privacy for robustness and privacy in federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib95.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2009.03561</em> (2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib96" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nasr et al<span id="bib.bib96.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Milad Nasr, Jamie Hayes, Thomas Steinke, Borja Balle, Florian Tramèr, Matthew Jagielski, Nicholas Carlini, and Andreas Terzis. 2023.

</span>
<span class="ltx_bibblock">Tight Auditing of Differentially Private Machine Learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib96.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2302.07956</em> (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib97" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nasr et al<span id="bib.bib97.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Milad Nasr, Reza Shokri, and Amir Houmansadr. 2018.

</span>
<span class="ltx_bibblock">Machine learning with membership privacy using adversarial regularization. In <em id="bib.bib97.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 2018 ACM SIGSAC Conference on Computer and Communications Security</em>. ACM, 634–646.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib98" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nasr et al<span id="bib.bib98.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Milad Nasr, Reza Shokri, and Amir Houmansadr. 2019.

</span>
<span class="ltx_bibblock">Comprehensive privacy analysis of deep learning: Passive and active white-box inference attacks against centralized and federated learning. In <em id="bib.bib98.3.1" class="ltx_emph ltx_font_italic">2019 IEEE symposium on security and privacy (SP)</em>. IEEE, 739–753.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib99" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Oldenhof et al<span id="bib.bib99.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Martijn Oldenhof, Gergely Ács, Balázs Pejó, Ansgar Schuffenhauer, Nicholas Holway, Noé Sturm, Arne Dieckmann, Oliver Fortmeier, Eric Boniface, Clément Mayer, et al<span id="bib.bib99.3.1" class="ltx_text">.</span> 2023.

</span>
<span class="ltx_bibblock">Industry-scale orchestrated federated learning for drug discovery. In <em id="bib.bib99.4.1" class="ltx_emph ltx_font_italic">Proceedings of the AAAI Conference on Artificial Intelligence</em>, Vol. 37. 15576–15584.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib100" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Oliynyk et al<span id="bib.bib100.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Daryna Oliynyk, Rudolf Mayer, and Andreas Rauber. 2023.

</span>
<span class="ltx_bibblock">I know what you trained last summer: A survey on stealing machine learning models and defences.

</span>
<span class="ltx_bibblock"><em id="bib.bib100.3.1" class="ltx_emph ltx_font_italic">Comput. Surveys</em> 55, 14s (2023), 1–41.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib101" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Orekondy et al<span id="bib.bib101.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Tribhuvanesh Orekondy, Bernt Schiele, and Mario Fritz. 2019.

</span>
<span class="ltx_bibblock">Knockoff nets: Stealing functionality of black-box models. In <em id="bib.bib101.3.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</em>. 4954–4963.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib102" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pasquini et al<span id="bib.bib102.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Dario Pasquini, Danilo Francati, and Giuseppe Ateniese. 2022.

</span>
<span class="ltx_bibblock">Eluding secure aggregation in federated learning via model inconsistency. In <em id="bib.bib102.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 2022 ACM SIGSAC Conference on Computer and Communications Security</em>. 2429–2443.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib103" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pati et al<span id="bib.bib103.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Sarthak Pati, Ujjwal Baid, Maximilian Zenk, Brandon Edwards, Micah Sheller, G Anthony Reina, Patrick Foley, Alexey Gruzdev, Jason Martin, Shadi Albarqouni, et al<span id="bib.bib103.3.1" class="ltx_text">.</span> 2021.

</span>
<span class="ltx_bibblock">The federated tumor segmentation (fets) challenge.

</span>
<span class="ltx_bibblock"><em id="bib.bib103.4.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2105.05874</em> (2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib104" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Perazzone et al<span id="bib.bib104.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Jake Perazzone, Shiqiang Wang, Mingyue Ji, and Kevin S. Chan. 2022.

</span>
<span class="ltx_bibblock">Communication-Efficient Device Scheduling for Federated Learning Using Stochastic Optimization. In <em id="bib.bib104.3.1" class="ltx_emph ltx_font_italic">IEEE INFOCOM 2022 - IEEE Conference on Computer Communications</em>. 1449–1458.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1109/INFOCOM48880.2022.9796818" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/INFOCOM48880.2022.9796818</a>

</span>
</li>
<li id="bib.bib105" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Phong et al<span id="bib.bib105.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Le Trieu Phong, Yoshinori Aono, Takuya Hayashi, Lihua Wang, and Shiho Moriai. 2017.

</span>
<span class="ltx_bibblock">Privacy-preserving deep learning: Revisited and enhanced. In <em id="bib.bib105.3.1" class="ltx_emph ltx_font_italic">International Conference on Applications and Techniques in Information Security</em>. Springer, 100–110.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib106" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rehman et al<span id="bib.bib106.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Muhammad Habib ur Rehman, Walter Hugo Lopez Pinaya, Parashkev Nachev, James T Teo, Sebastin Ourselin, and M Jorge Cardoso. 2023.

</span>
<span class="ltx_bibblock">Federated learning for medical imaging radiology.

</span>
<span class="ltx_bibblock"><em id="bib.bib106.3.1" class="ltx_emph ltx_font_italic">The British Journal of Radiology</em> 96, 1150 (2023), 20220890.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib107" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rieke et al<span id="bib.bib107.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Nicola Rieke, Jonny Hancox, Wenqi Li, Fausto Milletari, Holger R Roth, Shadi Albarqouni, Spyridon Bakas, Mathieu N Galtier, Bennett A Landman, Klaus Maier-Hein, et al<span id="bib.bib107.3.1" class="ltx_text">.</span> 2020.

</span>
<span class="ltx_bibblock">The future of digital health with federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib107.4.1" class="ltx_emph ltx_font_italic">NPJ digital medicine</em> 3, 1 (2020), 119.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib108" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rigaki and Garcia (2023)</span>
<span class="ltx_bibblock">
Maria Rigaki and Sebastian Garcia. 2023.

</span>
<span class="ltx_bibblock">A survey of privacy attacks in machine learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib108.1.1" class="ltx_emph ltx_font_italic">Comput. Surveys</em> 56, 4 (2023), 1–34.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib109" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Roth et al<span id="bib.bib109.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Holger R Roth, Ken Chang, Praveer Singh, Nir Neumark, Wenqi Li, Vikash Gupta, Sharut Gupta, Liangqiong Qu, Alvin Ihsani, Bernardo C Bizzo, et al<span id="bib.bib109.3.1" class="ltx_text">.</span> 2020.

</span>
<span class="ltx_bibblock">Federated learning for breast density classification: A real-world implementation. In <em id="bib.bib109.4.1" class="ltx_emph ltx_font_italic">Domain Adaptation and Representation Transfer, and Distributed and Collaborative Learning: Second MICCAI Workshop, DART 2020, and First MICCAI Workshop, DCL 2020, Held in Conjunction with MICCAI 2020, Lima, Peru, October 4–8, 2020, Proceedings 2</em>. Springer, 181–191.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib110" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Roth et al<span id="bib.bib110.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Holger R Roth, Yan Cheng, Yuhong Wen, Isaac Yang, Ziyue Xu, Yuan-Ting Hsieh, Kristopher Kersten, Ahmed Harouni, Can Zhao, Kevin Lu, et al<span id="bib.bib110.3.1" class="ltx_text">.</span> 2022.

</span>
<span class="ltx_bibblock">NVIDIA FLARE: Federated learning from simulation to real-world.

</span>
<span class="ltx_bibblock"><em id="bib.bib110.4.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2210.13291</em> (2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib111" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Roth and Lempel (1989)</span>
<span class="ltx_bibblock">
Ron M Roth and Abraham Lempel. 1989.

</span>
<span class="ltx_bibblock">On MDS codes via Cauchy matrices.

</span>
<span class="ltx_bibblock"><em id="bib.bib111.1.1" class="ltx_emph ltx_font_italic">IEEE transactions on information theory</em> 35, 6 (1989), 1314–1319.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib112" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Scherer et al<span id="bib.bib112.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Jonas Scherer, Marco Nolden, Jens Kleesiek, Jasmin Metzger, Klaus Kades, Verena Schneider, Michael Bach, Oliver Sedlaczek, Andreas M Bucher, Thomas J Vogl, et al<span id="bib.bib112.3.1" class="ltx_text">.</span> 2020.

</span>
<span class="ltx_bibblock">Joint imaging platform for federated clinical data analytics.

</span>
<span class="ltx_bibblock"><em id="bib.bib112.4.1" class="ltx_emph ltx_font_italic">JCO clinical cancer informatics</em> 4 (2020), 1027–1038.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib113" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sharma et al<span id="bib.bib113.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Atul Sharma, Joshua C Zhao, Wei Chen, Qiang Qiu, Saurabh Bagchi, and Somali Chaterji. 2023.

</span>
<span class="ltx_bibblock">How to Learn Collaboratively-Federated Learning to Peer-to-Peer Learning and What’s at Stake. In <em id="bib.bib113.3.1" class="ltx_emph ltx_font_italic">2023 53rd Annual IEEE/IFIP International Conference on Dependable Systems and Networks-Supplemental Volume (DSN-S)</em>. IEEE, 122–126.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib114" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shejwalkar and Houmansadr (2021)</span>
<span class="ltx_bibblock">
Virat Shejwalkar and Amir Houmansadr. 2021.

</span>
<span class="ltx_bibblock">Membership privacy for machine learning models through knowledge transfer. In <em id="bib.bib114.1.1" class="ltx_emph ltx_font_italic">Proceedings of the AAAI Conference on Artificial Intelligence</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib115" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shokri et al<span id="bib.bib115.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Reza Shokri, Marco Stronati, Congzheng Song, and Vitaly Shmatikov. 2017.

</span>
<span class="ltx_bibblock">Membership inference attacks against machine learning models. In <em id="bib.bib115.3.1" class="ltx_emph ltx_font_italic">2017 IEEE symposium on security and privacy (SP)</em>. IEEE, 3–18.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib116" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sikandar et al<span id="bib.bib116.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Hira Shahzadi Sikandar, Huda Waheed, Sibgha Tahir, Saif UR Malik, and Waqas Rafique. 2023.

</span>
<span class="ltx_bibblock">A Detailed Survey on Federated Learning Attacks and Defenses.

</span>
<span class="ltx_bibblock"><em id="bib.bib116.3.1" class="ltx_emph ltx_font_italic">Electronics</em> 12, 2 (2023), 260.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib117" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">So et al<span id="bib.bib117.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Jinhyun So, Ramy E Ali, Başak Güler, Jiantao Jiao, and A Salman Avestimehr. 2023.

</span>
<span class="ltx_bibblock">Securing secure aggregation: Mitigating multi-round privacy leakage in federated learning. In <em id="bib.bib117.3.1" class="ltx_emph ltx_font_italic">Proceedings of the AAAI Conference on Artificial Intelligence</em>, Vol. 37. 9864–9873.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib118" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">So et al<span id="bib.bib118.2.2.1" class="ltx_text">.</span> (2021a)</span>
<span class="ltx_bibblock">
Jinhyun So, Ramy E Ali, Basak Guler, Jiantao Jiao, and Salman Avestimehr. 2021a.

</span>
<span class="ltx_bibblock">Securing secure aggregation: Mitigating multi-round privacy leakage in federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib118.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2106.03328</em> (2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib119" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">So et al<span id="bib.bib119.2.2.1" class="ltx_text">.</span> (2021b)</span>
<span class="ltx_bibblock">
Jinhyun So, Başak Güler, and A Salman Avestimehr. 2021b.

</span>
<span class="ltx_bibblock">Turbo-aggregate: Breaking the quadratic aggregation barrier in secure federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib119.3.1" class="ltx_emph ltx_font_italic">IEEE Journal on Selected Areas in Information Theory</em> 2, 1 (2021), 479–489.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib120" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">So et al<span id="bib.bib120.2.2.1" class="ltx_text">.</span> (2021c)</span>
<span class="ltx_bibblock">
Jinhyun So, Basak Guler, and A Salman Avestimehr. 2021c.

</span>
<span class="ltx_bibblock">Turbo-Aggregate: Breaking the Quadratic Aggregation Barrier in Secure Federated Learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib120.3.1" class="ltx_emph ltx_font_italic">IEEE Journal on Selected Areas in Information Theory</em> (2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib121" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">So et al<span id="bib.bib121.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Jinhyun So, Corey J Nolet, Chien-Sheng Yang, Songze Li, Qian Yu, Ramy E Ali, Basak Guler, and Salman Avestimehr. 2022.

</span>
<span class="ltx_bibblock">Lightsecagg: a lightweight and versatile design for secure aggregation in federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib121.3.1" class="ltx_emph ltx_font_italic">Proceedings of Machine Learning and Systems</em> 4 (2022), 694–720.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib122" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Song et al<span id="bib.bib122.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Liwei Song, Reza Shokri, and Prateek Mittal. 2019.

</span>
<span class="ltx_bibblock">Membership inference attacks against adversarially robust deep learning models. In <em id="bib.bib122.3.1" class="ltx_emph ltx_font_italic">2019 IEEE Security and Privacy Workshops (SPW)</em>. IEEE, 50–56.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib123" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Steinke et al<span id="bib.bib123.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Thomas Steinke, Milad Nasr, and Matthew Jagielski. 2023.

</span>
<span class="ltx_bibblock">Privacy Auditing with One (1) Training Run.

</span>
<span class="ltx_bibblock"><em id="bib.bib123.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2305.08846</em> (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib124" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tang et al<span id="bib.bib124.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Tingting Tang, Ramy E Ali, Hanieh Hashemi, Tynan Gangwani, Salman Avestimehr, and Murali Annavaram. 2021.

</span>
<span class="ltx_bibblock">Verifiable coded computing: Towards fast, secure and private distributed machine learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib124.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2107.12958</em> (2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib125" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tang et al<span id="bib.bib125.4.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Xinyu Tang, Saeed Mahloujifar, Liwei Song, Virat Shejwalkar, Milad Nasr, Amir Houmansadr, and Prateek Mittal. 2022.

</span>
<span class="ltx_bibblock">Mitigating membership inference attacks by <math id="bib.bib125.1.m1.1" class="ltx_Math" alttext="\{" display="inline"><semantics id="bib.bib125.1.m1.1a"><mo stretchy="false" id="bib.bib125.1.m1.1.1" xref="bib.bib125.1.m1.1.1.cmml">{</mo><annotation-xml encoding="MathML-Content" id="bib.bib125.1.m1.1b"><ci id="bib.bib125.1.m1.1.1.cmml" xref="bib.bib125.1.m1.1.1">{</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib125.1.m1.1c">\{</annotation></semantics></math>Self-Distillation<math id="bib.bib125.2.m2.1" class="ltx_Math" alttext="\}" display="inline"><semantics id="bib.bib125.2.m2.1a"><mo stretchy="false" id="bib.bib125.2.m2.1.1" xref="bib.bib125.2.m2.1.1.cmml">}</mo><annotation-xml encoding="MathML-Content" id="bib.bib125.2.m2.1b"><ci id="bib.bib125.2.m2.1.1.cmml" xref="bib.bib125.2.m2.1.1">}</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib125.2.m2.1c">\}</annotation></semantics></math> through a novel ensemble architecture. In <em id="bib.bib125.5.1" class="ltx_emph ltx_font_italic">31st USENIX Security Symposium (USENIX Security 22)</em>. 1433–1450.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib126" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tramèr et al<span id="bib.bib126.4.2.1" class="ltx_text">.</span> (2016)</span>
<span class="ltx_bibblock">
Florian Tramèr, Fan Zhang, Ari Juels, Michael K Reiter, and Thomas Ristenpart. 2016.

</span>
<span class="ltx_bibblock">Stealing machine learning models via prediction <math id="bib.bib126.1.m1.1" class="ltx_Math" alttext="\{" display="inline"><semantics id="bib.bib126.1.m1.1a"><mo stretchy="false" id="bib.bib126.1.m1.1.1" xref="bib.bib126.1.m1.1.1.cmml">{</mo><annotation-xml encoding="MathML-Content" id="bib.bib126.1.m1.1b"><ci id="bib.bib126.1.m1.1.1.cmml" xref="bib.bib126.1.m1.1.1">{</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib126.1.m1.1c">\{</annotation></semantics></math>APIs<math id="bib.bib126.2.m2.1" class="ltx_Math" alttext="\}" display="inline"><semantics id="bib.bib126.2.m2.1a"><mo stretchy="false" id="bib.bib126.2.m2.1.1" xref="bib.bib126.2.m2.1.1.cmml">}</mo><annotation-xml encoding="MathML-Content" id="bib.bib126.2.m2.1b"><ci id="bib.bib126.2.m2.1.1.cmml" xref="bib.bib126.2.m2.1.1">}</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib126.2.m2.1c">\}</annotation></semantics></math>. In <em id="bib.bib126.5.1" class="ltx_emph ltx_font_italic">25th USENIX security symposium (USENIX Security 16)</em>. 601–618.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib127" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Usynin et al<span id="bib.bib127.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Dmitrii Usynin, Daniel Rueckert, and Georgios Kaissis. 2023.

</span>
<span class="ltx_bibblock">Beyond gradients: Exploiting adversarial priors in model inversion attacks.

</span>
<span class="ltx_bibblock"><em id="bib.bib127.3.1" class="ltx_emph ltx_font_italic">ACM Transactions on Privacy and Security</em> 26, 3 (2023), 1–30.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib128" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang and Gong (2018)</span>
<span class="ltx_bibblock">
Binghui Wang and Neil Zhenqiang Gong. 2018.

</span>
<span class="ltx_bibblock">Stealing hyperparameters in machine learning. In <em id="bib.bib128.1.1" class="ltx_emph ltx_font_italic">2018 IEEE symposium on security and privacy (SP)</em>. IEEE, 36–52.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib129" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al<span id="bib.bib129.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Shiqiang Wang, Jake Perazzone, Mingyue Ji, and Kevin S. Chan. 2023.

</span>
<span class="ltx_bibblock">Federated Learning with Flexible Control. In <em id="bib.bib129.3.1" class="ltx_emph ltx_font_italic">IEEE INFOCOM 2023 - IEEE Conference on Computer Communications</em>. 1–10.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1109/INFOCOM53939.2023.10229070" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/INFOCOM53939.2023.10229070</a>

</span>
</li>
<li id="bib.bib130" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al<span id="bib.bib130.2.2.1" class="ltx_text">.</span> (2019b)</span>
<span class="ltx_bibblock">
Shiqiang Wang, Tiffany Tuor, Theodoros Salonidis, Kin K. Leung, Christian Makaya, Ting He, and Kevin Chan. 2019b.

</span>
<span class="ltx_bibblock">Adaptive Federated Learning in Resource Constrained Edge Computing Systems.

</span>
<span class="ltx_bibblock"><em id="bib.bib130.3.1" class="ltx_emph ltx_font_italic">IEEE Journal on Selected Areas in Communications</em> 37, 6 (2019), 1205–1221.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1109/JSAC.2019.2904348" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/JSAC.2019.2904348</a>

</span>
</li>
<li id="bib.bib131" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang and He (2021)</span>
<span class="ltx_bibblock">
Xiaosen Wang and Kun He. 2021.

</span>
<span class="ltx_bibblock">Enhancing the transferability of adversarial attacks through variance tuning. In <em id="bib.bib131.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</em>. 1924–1933.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib132" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al<span id="bib.bib132.2.2.1" class="ltx_text">.</span> (2019a)</span>
<span class="ltx_bibblock">
Zhibo Wang, Mengkai Song, Zhifei Zhang, Yang Song, Qian Wang, and Hairong Qi. 2019a.

</span>
<span class="ltx_bibblock">Beyond inferring class representatives: User-level privacy leakage from federated learning. In <em id="bib.bib132.3.1" class="ltx_emph ltx_font_italic">IEEE INFOCOM 2019-IEEE Conference on Computer Communications</em>. IEEE, 2512–2520.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib133" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wei et al<span id="bib.bib133.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Kang Wei, Jun Li, Ming Ding, Chuan Ma, Howard H Yang, Farhad Farokhi, Shi Jin, Tony QS Quek, and H Vincent Poor. 2020.

</span>
<span class="ltx_bibblock">Federated learning with differential privacy: Algorithms and performance analysis.

</span>
<span class="ltx_bibblock"><em id="bib.bib133.3.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Information Forensics and Security</em> 15 (2020), 3454–3469.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib134" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wen et al<span id="bib.bib134.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Yuxin Wen, Jonas Geiping, Liam Fowl, Micah Goldblum, and Tom Goldstein. 2022.

</span>
<span class="ltx_bibblock">Fishing for user data in large-batch federated learning via gradient magnification.

</span>
<span class="ltx_bibblock"><em id="bib.bib134.3.1" class="ltx_emph ltx_font_italic">International Conference on Machine Learning</em> (2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib135" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Woisetschläger et al<span id="bib.bib135.2.2.1" class="ltx_text">.</span> (2024)</span>
<span class="ltx_bibblock">
Herbert Woisetschläger, Alexander Erben, Bill Marino, Shiqiang Wang, Nicholas D Lane, Ruben Mayer, and Hans-Arno Jacobsen. 2024.

</span>
<span class="ltx_bibblock">Federated Learning Priorities Under the European Union Artificial Intelligence Act.

</span>
<span class="ltx_bibblock"><em id="bib.bib135.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2402.05968</em> (2024).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib136" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yeom et al<span id="bib.bib136.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Samuel Yeom, Irene Giacomelli, Matt Fredrikson, and Somesh Jha. 2018.

</span>
<span class="ltx_bibblock">Privacy risk in machine learning: Analyzing the connection to overfitting. In <em id="bib.bib136.3.1" class="ltx_emph ltx_font_italic">2018 IEEE 31st Computer Security Foundations Symposium (CSF)</em>. IEEE, 268–282.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib137" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yin et al<span id="bib.bib137.2.2.1" class="ltx_text">.</span> (2021a)</span>
<span class="ltx_bibblock">
Hongxu Yin, Arun Mallya, Arash Vahdat, Jose M Alvarez, Jan Kautz, and Pavlo Molchanov. 2021a.

</span>
<span class="ltx_bibblock">See through gradients: Image batch recovery via gradinversion. In <em id="bib.bib137.3.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>. 16337–16346.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib138" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yin et al<span id="bib.bib138.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Hongxu Yin, Pavlo Molchanov, Jose M Alvarez, Zhizhong Li, Arun Mallya, Derek Hoiem, Niraj K Jha, and Jan Kautz. 2020.

</span>
<span class="ltx_bibblock">Dreaming to distill: Data-free knowledge transfer via deepinversion. In <em id="bib.bib138.3.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>. 8715–8724.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib139" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yin et al<span id="bib.bib139.2.2.1" class="ltx_text">.</span> (2021b)</span>
<span class="ltx_bibblock">
Xuefei Yin, Yanming Zhu, and Jiankun Hu. 2021b.

</span>
<span class="ltx_bibblock">A comprehensive survey of privacy-preserving federated learning: A taxonomy, review, and future directions.

</span>
<span class="ltx_bibblock"><em id="bib.bib139.3.1" class="ltx_emph ltx_font_italic">ACM Computing Surveys (CSUR)</em> 54, 6 (2021), 1–36.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib140" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu et al<span id="bib.bib140.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Qian Yu, Songze Li, Netanel Raviv, Seyed Mohammadreza Mousavi Kalan, Mahdi Soltanolkotabi, and Salman A Avestimehr. 2019.

</span>
<span class="ltx_bibblock">Lagrange coded computing: Optimal design for resiliency, security, and privacy. In <em id="bib.bib140.3.1" class="ltx_emph ltx_font_italic">The 22nd International Conference on Artificial Intelligence and Statistics</em>. PMLR, 1215–1225.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib141" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zari et al<span id="bib.bib141.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Oualid Zari, Chuan Xu, and Giovanni Neglia. 2021.

</span>
<span class="ltx_bibblock">Efficient passive membership inference attack in federated learning. In <em id="bib.bib141.3.1" class="ltx_emph ltx_font_italic">NeurIPS PriML 2021-workshop Privacy in Machine Learning</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib142" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al<span id="bib.bib142.6.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Chengliang Zhang, Suyi Li, Junzhe Xia, Wei Wang, Feng Yan, and Yang Liu. 2020.

</span>
<span class="ltx_bibblock"><math id="bib.bib142.1.m1.1" class="ltx_Math" alttext="\{" display="inline"><semantics id="bib.bib142.1.m1.1a"><mo stretchy="false" id="bib.bib142.1.m1.1.1" xref="bib.bib142.1.m1.1.1.cmml">{</mo><annotation-xml encoding="MathML-Content" id="bib.bib142.1.m1.1b"><ci id="bib.bib142.1.m1.1.1.cmml" xref="bib.bib142.1.m1.1.1">{</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib142.1.m1.1c">\{</annotation></semantics></math>BatchCrypt<math id="bib.bib142.2.m2.1" class="ltx_Math" alttext="\}" display="inline"><semantics id="bib.bib142.2.m2.1a"><mo stretchy="false" id="bib.bib142.2.m2.1.1" xref="bib.bib142.2.m2.1.1.cmml">}</mo><annotation-xml encoding="MathML-Content" id="bib.bib142.2.m2.1b"><ci id="bib.bib142.2.m2.1.1.cmml" xref="bib.bib142.2.m2.1.1">}</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib142.2.m2.1c">\}</annotation></semantics></math>: Efficient homomorphic encryption for <math id="bib.bib142.3.m3.1" class="ltx_Math" alttext="\{" display="inline"><semantics id="bib.bib142.3.m3.1a"><mo stretchy="false" id="bib.bib142.3.m3.1.1" xref="bib.bib142.3.m3.1.1.cmml">{</mo><annotation-xml encoding="MathML-Content" id="bib.bib142.3.m3.1b"><ci id="bib.bib142.3.m3.1.1.cmml" xref="bib.bib142.3.m3.1.1">{</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib142.3.m3.1c">\{</annotation></semantics></math>Cross-Silo<math id="bib.bib142.4.m4.1" class="ltx_Math" alttext="\}" display="inline"><semantics id="bib.bib142.4.m4.1a"><mo stretchy="false" id="bib.bib142.4.m4.1.1" xref="bib.bib142.4.m4.1.1.cmml">}</mo><annotation-xml encoding="MathML-Content" id="bib.bib142.4.m4.1b"><ci id="bib.bib142.4.m4.1.1.cmml" xref="bib.bib142.4.m4.1.1">}</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib142.4.m4.1c">\}</annotation></semantics></math> federated learning. In <em id="bib.bib142.7.1" class="ltx_emph ltx_font_italic">2020 USENIX annual technical conference (USENIX ATC 20)</em>. 493–506.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib143" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al<span id="bib.bib143.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Hongyi Zhang, Moustapha Cisse, Yann N Dauphin, and David Lopez-Paz. 2017.

</span>
<span class="ltx_bibblock">mixup: Beyond empirical risk minimization.

</span>
<span class="ltx_bibblock"><em id="bib.bib143.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1710.09412</em> (2017).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib144" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al<span id="bib.bib144.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Kaiyue Zhang, Xuan Song, Chenhan Zhang, and Shui Yu. 2022.

</span>
<span class="ltx_bibblock">Challenges and future directions of secure federated learning: a survey.

</span>
<span class="ltx_bibblock"><em id="bib.bib144.3.1" class="ltx_emph ltx_font_italic">Frontiers of computer science</em> 16 (2022), 1–8.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib145" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al<span id="bib.bib145.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Tuo Zhang, Chaoyang He, Tianhao Ma, Lei Gao, Mark Ma, and Salman Avestimehr. 2021.

</span>
<span class="ltx_bibblock">Federated Learning for Internet of Things. In <em id="bib.bib145.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 19th ACM Conference on Embedded Networked Sensor Systems</em> (Coimbra, Portugal) <em id="bib.bib145.4.2" class="ltx_emph ltx_font_italic">(SenSys ’21)</em>. Association for Computing Machinery, New York, NY, USA, 413–419.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/3485730.3493444" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3485730.3493444</a>

</span>
</li>
<li id="bib.bib146" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao et al<span id="bib.bib146.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Bo Zhao, Konda Reddy Mopuri, and Hakan Bilen. 2020.

</span>
<span class="ltx_bibblock">idlg: Improved deep leakage from gradients.

</span>
<span class="ltx_bibblock"><em id="bib.bib146.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2001.02610</em> (2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib147" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao et al<span id="bib.bib147.2.2.1" class="ltx_text">.</span> (2024)</span>
<span class="ltx_bibblock">
Joshua Christian Zhao, Ahaan Dabholkar, Atul Sharma, and Saurabh Bagchi. 2024.

</span>
<span class="ltx_bibblock">Leak and Learn: An Attacker’s Cookbook to Train Using Leaked Data from Federated Learning. In <em id="bib.bib147.3.1" class="ltx_emph ltx_font_italic">Conference on Computer Vision and Pattern Recognition (CVPR)</em>. IEEE Computer Society, 1–10.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib148" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao et al<span id="bib.bib148.2.2.1" class="ltx_text">.</span> (2023a)</span>
<span class="ltx_bibblock">
Joshua C Zhao, Ahmed Roushdy Elkordy, Atul Sharma, Yahya H Ezzeldin, Salman Avestimehr, and Saurabh Bagchi. 2023a.

</span>
<span class="ltx_bibblock">The Resource Problem of Using Linear Layer Leakage Attack in Federated Learning. In <em id="bib.bib148.3.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>. 3974–3983.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib149" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao et al<span id="bib.bib149.2.2.1" class="ltx_text">.</span> (2023b)</span>
<span class="ltx_bibblock">
Joshua Christian Zhao, Atul Sharma, Ahmed Roushdy Elkordy, Yahya H Ezzeldin, Salman Avestimehr, and Saurabh Bagchi. 2023b.

</span>
<span class="ltx_bibblock">LOKI: Large-scale Data Reconstruction Attack against Federated Learning through Model Manipulation. In <em id="bib.bib149.3.1" class="ltx_emph ltx_font_italic">2024 IEEE Symposium on Security and Privacy (SP)</em>. IEEE Computer Society, 30–30.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib150" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao and Sun (2022)</span>
<span class="ltx_bibblock">
Yizhou Zhao and Hua Sun. 2022.

</span>
<span class="ltx_bibblock">Information theoretic secure aggregation with user dropouts.

</span>
<span class="ltx_bibblock"><em id="bib.bib150.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Information Theory</em> 68, 11 (2022), 7471–7484.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib151" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhu et al<span id="bib.bib151.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Ligeng Zhu, Zhijian Liu, and Song Han. 2019.

</span>
<span class="ltx_bibblock">Deep leakage from gradients.

</span>
<span class="ltx_bibblock"><em id="bib.bib151.3.1" class="ltx_emph ltx_font_italic">Advances in neural information processing systems</em> 32 (2019).

</span>
<span class="ltx_bibblock">
</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2405.03635" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2405.03636" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2405.03636">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2405.03636" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2405.03637" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Wed Jun  5 15:43:25 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
