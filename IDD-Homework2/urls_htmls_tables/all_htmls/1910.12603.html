<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[1910.12603] A blockchain-orchestrated Federated Learning architecture for healthcare consortia</title><meta property="og:description" content="We propose a novel architecture for federated learning within healthcare consortia. At the heart of the solution is a unique integration of privacy preserving technologies, built upon native enterprise blockchain compo…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="A blockchain-orchestrated Federated Learning architecture for healthcare consortia">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="A blockchain-orchestrated Federated Learning architecture for healthcare consortia">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/1910.12603">

<!--Generated on Sat Mar 16 10:23:39 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">A blockchain-orchestrated Federated Learning architecture for healthcare consortia</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Jonathan Passerat-Palmbach 
<br class="ltx_break">ConsenSys Health / Imperial College London 
<br class="ltx_break"><span id="id1.1.id1" class="ltx_text ltx_font_typewriter">j.passerat-palmbach@imperial.ac.uk</span> 
<br class="ltx_break">Tyler Farnan 
<br class="ltx_break">ConsenSys Health / UC San Diego 
<br class="ltx_break"><span id="id2.2.id2" class="ltx_text ltx_font_typewriter">tfarnan@ucsd.edu</span>
Robert Miller 
<br class="ltx_break">ConsenSys Health 
<br class="ltx_break"><span id="id3.3.id3" class="ltx_text ltx_font_typewriter">robert.miller@consensys.net</span> 
<br class="ltx_break">Marielle S. Gross 
<br class="ltx_break">Johns Hopkins Berman Institute of Bioethics 
<br class="ltx_break"><span id="id4.4.id4" class="ltx_text ltx_font_typewriter">mgross23@jhmi.edu</span> 
<br class="ltx_break">Heather Leigh Flannery 
<br class="ltx_break">ConsenSys Health 
<br class="ltx_break"><span id="id5.5.id5" class="ltx_text ltx_font_typewriter">heather.flannery@consensys.net</span> 
<br class="ltx_break">Bill Gleim 
<br class="ltx_break">ConsenSys Health 
<br class="ltx_break"><span id="id6.6.id6" class="ltx_text ltx_font_typewriter">bill.gleim@consensys.net</span> 
<br class="ltx_break">
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id7.id1" class="ltx_p">We propose a novel architecture for federated learning within healthcare consortia. At the heart of the solution is a unique integration of privacy preserving technologies, built upon native enterprise blockchain components available in the Ethereum ecosystem. We show how the specific characteristics and challenges of healthcare consortia informed our design choices, notably the conception of a new Secure Aggregation protocol assembled with a protected hardware component and an encryption toolkit native to Ethereum. Our architecture also brings in a privacy preserving audit trail that logs events in the network without revealing identities.</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span><a name="context-for-privacy-in-healthcare" id="context-for-privacy-in-healthcare" class="ltx_anchor">Privacy in healthcare and Federated Learning Consortia</a>
</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">The healthcare sector is uniquely positioned to leverage data for the purpose of creating value and improving human health. However, our ability to learn from health data is in tension with a unique set of ethical, legal, economic and technical challenges related to data privacy.
But traditional methods of mitigating health data privacy concerns, namely HIPAA and the use of deidentified data, have proven insufficient to protect individuals’ interests. Realizing data’s promise will require new tools, and we propose a novel federated learning architecture that is uniquely suited to these problems.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Large scale federated learning as depicted in the original series of
papers <cite class="ltx_cite ltx_citemacro_cite">Bonawitz et al. (<a href="#bib.bib3" title="" class="ltx_ref">2017</a>, <a href="#bib.bib4" title="" class="ltx_ref">2019</a>)</cite> involves a great number of mobile devices
that take part in the training rounds. This introduces a series of
design constraints and challenges to enable learning to happen on these
resource-limited devices without disrupting the end-user’s experience nor privacy.
We argue that among the challenges highlighted in <cite class="ltx_cite ltx_citemacro_cite">Bonawitz et al. (<a href="#bib.bib4" title="" class="ltx_ref">2019</a>)</cite>, some elements are not relevant anymore when considering a
consortium context.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">The most significant change lies in the data distribution. A consortium
will contain less parties than a public network of mobile devices, but
each of these participants will host a larger quantity of data. They
will also benefit from substantially more compute and storage resources,
as the devices involved in the training rounds will be server-grade
machines rather than
smartphones. Another discrepancy exposed by servers is that they can be
leveraged in a training round at any time of the day (contrary to
mobile devices which will be leveraged mostly when charging and connected to a home Wi-Fi network). Network
connectivity will also be more reliable, thus almost no participant will
drop out during a training round.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">These elements informed our design choices, which as a
result differ from the blueprints established in <cite class="ltx_cite ltx_citemacro_cite">Bonawitz et al. (<a href="#bib.bib4" title="" class="ltx_ref">2019</a>); Lalitha et al. (<a href="#bib.bib5" title="" class="ltx_ref">2018</a>)</cite>.
The architecture we introduce in this paper draws its specificity and
novelty from the combination of four main features making it
particularly suitable for the healthcare consortia settings we are considering: <span id="S1.p4.1.1" class="ltx_text ltx_font_italic">1)</span> Data owners can define fine-grained access policy to their data,
restricting access to certain members of the
consortium only (Section <a href="#S2.SS2" title="2.2 Role of Ethereum and Fine grained data permissioning ‣ 2 System architecture ‣ A blockchain-orchestrated Federated Learning architecture for healthcare consortia" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.2</span></a>), <span id="S1.p4.1.2" class="ltx_text ltx_font_italic">2)</span> An alternative implementation of Secure Aggregation based on AMD SEV
in memory encryption, which introduces a trusted third-party more
suitable than a potentially brittle Multi-Party Computation (MPC) with
a limited number of non-anonymous participants (Section <a href="#S2.SS3" title="2.3 AMD SEV based Secure Aggregator ‣ 2 System architecture ‣ A blockchain-orchestrated Federated Learning architecture for healthcare consortia" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.3</span></a>), <span id="S1.p4.1.3" class="ltx_text ltx_font_italic">3)</span> Peer-to-peer transit encryption of updated weights between the
workers and the Secure Aggregator leveraging cutting edge Ethereum
technology <cite class="ltx_cite ltx_citemacro_cite">Alabi (<a href="#bib.bib2" title="" class="ltx_ref">2018</a>)</cite> (Section <a href="#S2.SS4" title="2.4 Peer-to-peer in transit encryption of updated weights ‣ 2 System architecture ‣ A blockchain-orchestrated Federated Learning architecture for healthcare consortia" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.4</span></a>), <span id="S1.p4.1.4" class="ltx_text ltx_font_italic">4)</span> A privacy preserving audit trail logs actions undertaken within the network while
keeping the actual list of participants to a training round hidden (Section <a href="#S3.SS2" title="3.2 Privacy preserving audit trail ‣ 3 Security requirements ‣ A blockchain-orchestrated Federated Learning architecture for healthcare consortia" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.2</span></a>).</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span><a name="system-architecture" id="system-architecture" class="ltx_anchor">System architecture</a>
</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">Figure <a href="#S2.F1" title="Figure 1 ‣ 2 System architecture ‣ A blockchain-orchestrated Federated Learning architecture for healthcare consortia" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> gives an overview of the system architecture and and of a training round. All the parties in the network have access to their own Ethereum account that will identify them and enable them to interact with the rest of the network. Our solution exploits the Federated Learning building bricks provided by the PySyft library <cite class="ltx_cite ltx_citemacro_cite">Ryffel et al. (<a href="#bib.bib10" title="" class="ltx_ref">2018</a>)</cite>.</p>
</div>
<figure id="S2.F1" class="ltx_figure"><img src="/html/1910.12603/assets/architecture.png" id="S2.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="317" height="179" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Global overview of a training round</figcaption>
</figure>
<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span><a name="overview-architecture" id="overview-architecture" class="ltx_anchor">Overview</a>
</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">The <span id="S2.SS1.p1.1.1" class="ltx_text ltx_font_italic">Model Owner</span> (MO) initiates the process by uploading his model to a distributed storage infrastructure (IPFS, Swarm, …) available to all the members of the consortium. MO then registers the model and a training description to an <span id="S2.SS1.p1.1.2" class="ltx_text ltx_font_italic">Orchestrator</span> smart contract. This description will contain similar information to what a <span id="S2.SS1.p1.1.3" class="ltx_text ltx_font_italic">FL Plan</span> does in <cite class="ltx_cite ltx_citemacro_cite">Bonawitz et al. (<a href="#bib.bib4" title="" class="ltx_ref">2019</a>)</cite>.</p>
</div>
<div id="S2.SS1.p2" class="ltx_para">
<p id="S2.SS1.p2.1" class="ltx_p">The <span id="S2.SS1.p2.1.1" class="ltx_text ltx_font_italic">Orchestrator</span> is embodied by one or potentially several smart contracts. In addition to storing the models, it maintains a list of <span id="S2.SS1.p2.1.2" class="ltx_text ltx_font_italic">Data Workers</span> (DW). A DW is a node in the network that possesses one or many datasets that can be of interest for MOs to improve their models. DWs are communicating by instantiating a web socket server as available in PySyft. DWs have the ability to specify a blacklist of model owners that shouldn’t have access to some or all of their data. They do so by updating a mapping of Ethereum addresses (representing the blacklisted MOs) and dataset identifiers stored in the <span id="S2.SS1.p2.1.3" class="ltx_text ltx_font_italic">Orchestrator</span> smart contract.</p>
</div>
<div id="S2.SS1.p3" class="ltx_para">
<p id="S2.SS1.p3.1" class="ltx_p">In order to initiate a training round, the <span id="S2.SS1.p3.1.1" class="ltx_text ltx_font_italic">Orchestrator</span> first determines the full set of data workers that comply with the previous exclusion rules (a post training selection will further reduce the set as described in <a href="#S3.SS1" title="3.1 Random selection of contributions to aggregate ‣ 3 Security requirements ‣ A blockchain-orchestrated Federated Learning architecture for healthcare consortia" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.1</span></a>). The Orchestrator schedules a training task for the selected workers using private transactions. All the actions undertaken by the Orchestrator are logged on chain in a privacy preserving fashion as described in Section <a href="#S3.SS2" title="3.2 Privacy preserving audit trail ‣ 3 Security requirements ‣ A blockchain-orchestrated Federated Learning architecture for healthcare consortia" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.2</span></a>. Each selected worker now pulls the latest checkpoint of the model from the shared distributed storage. The worker performs a training step as defined in the corresponding training description stored in the Orchestrator. Once it has completed its training round, the worker encrypts the newly obtained set of weights for the <span id="S2.SS1.p3.1.2" class="ltx_text ltx_font_italic">Secure Aggregator</span> (SA).</p>
</div>
<div id="S2.SS1.p4" class="ltx_para">
<p id="S2.SS1.p4.1" class="ltx_p">SA is a special entity, a Virtual Machine or container, whose memory is encrypted from its host using the AMD SEV technology (Section <a href="#S2.SS3" title="2.3 AMD SEV based Secure Aggregator ‣ 2 System architecture ‣ A blockchain-orchestrated Federated Learning architecture for healthcare consortia" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.3</span></a>). The Aggregator fetches all the encrypted weights from the decentralised storage, decrypts them within the safe realm of its encrypted memory and performs the aggregation. It finally uploads the new model checkpoint to the shared storage and updates the Orchestrator smart contract with new pointer. Multiple SA could be instantiated to accommodate a larger workload or introduce more decentralisation and reliability.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span><a name="fine-grained-data-permissioning" id="fine-grained-data-permissioning" class="ltx_anchor">Role of Ethereum and Fine grained data
permissioning</a>
</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">In the context of federated learning consortia, it is critical to prevent legal, ethical, and competitive requirements from being compromised. We argue in this paper that the Ethereum <cite class="ltx_cite ltx_citemacro_cite">Wood and others (<a href="#bib.bib13" title="" class="ltx_ref">2014</a>)</cite> blockchain can fulfill such a role and benefit an architecture targeting consortia in the healthcare industry in particular. The combination of a decentralised immutable ledger that can be updated programmatically in a highly trustable flavour makes Ethereum a very appealing choice to design modern decentralised and secure systems. Hyperledger Besu is an enterprise-grade Ethereum client. These tools enable consortia to implement cooperative standards for viewing, transacting, and communicating within in the network. For example, providing read-only access of an audit trail to an external third-party or restricting data exchange to a subset of network nodes for private communication.</p>
</div>
<div id="S2.SS2.p2" class="ltx_para">
<p id="S2.SS2.p2.1" class="ltx_p">On top of Besu’s native features, an Orchestrator smart contract controls the traffic in the network, keeping track of permissions set by each user regarding the level of data-sharing access with other members in the consortium. In addition to governing activity and authorizations, smart contracts can also support the exchange of native tokens within the Ethereum blockchain. Tokens have been proposed as a way of incentivizing network participants to perform actions; in our architecture they could be used to incentivize computations. However, they extend naturally as a fungible or non-fungible measure of value in an information exchange, and can serve as the backbone for incentivized data-sharing in a federated learning consortia. In our use case, smart contract(s) can record metrics throughout federated learning lifecycles, and specify the execution of remuneration policies chosen by the consortia.</p>
</div>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span><a name="amd-sev-based-secure-aggregator" id="amd-sev-based-secure-aggregator" class="ltx_anchor">AMD SEV based Secure
Aggregator</a>
</h3>

<div id="S2.SS3.p1" class="ltx_para">
<p id="S2.SS3.p1.1" class="ltx_p">Architectures like <cite class="ltx_cite ltx_citemacro_cite">Bonawitz et al. (<a href="#bib.bib4" title="" class="ltx_ref">2019</a>)</cite>
are designed for training rounds involving “a few hundred devices”. Within the context of healthcare, federated learning consortia are mostly likely to be adopted by enterprises first. This will limit the number of members in a network, likely to be under 100. This number will shrink even more when
applying the data selection filters and account permissioning rules.</p>
</div>
<div id="S2.SS3.p2" class="ltx_para">
<p id="S2.SS3.p2.1" class="ltx_p">While medical applications have been shown to successfully leverage
federated learning with a lower number of workers (20-30) <cite class="ltx_cite ltx_citemacro_cite">Roy et al. (<a href="#bib.bib9" title="" class="ltx_ref">2019</a>); Sheller et al. (<a href="#bib.bib12" title="" class="ltx_ref">2019</a>)</cite> compared to <cite class="ltx_cite ltx_citemacro_cite">Bonawitz et al. (<a href="#bib.bib4" title="" class="ltx_ref">2019</a>)</cite>, this could break
the security properties of the Secure Aggregation scheme presented in
<cite class="ltx_cite ltx_citemacro_cite">Bonawitz et al. (<a href="#bib.bib3" title="" class="ltx_ref">2017</a>)</cite>. Secure Aggregation <cite class="ltx_cite ltx_citemacro_cite">Bonawitz et al. (<a href="#bib.bib4" title="" class="ltx_ref">2019</a>)</cite> is
performed via a MPC protocol built on top of
Shamir’s Secret Sharing (SSS) scheme <cite class="ltx_cite ltx_citemacro_cite">Shamir (<a href="#bib.bib11" title="" class="ltx_ref">1979</a>)</cite>. In our present
context, the number of active devices would be too low to provide
the same level of guarantees for the MPC. On top of that, members of a
consortium are highly likely to know each other and this would
dramatically increase the risks of compromising the security threshold
of the SSS scheme.</p>
</div>
<div id="S2.SS3.p3" class="ltx_para">
<p id="S2.SS3.p3.1" class="ltx_p">We introduce a better suited approach for such consortia based on protected hardware such as AMD’s
Secure Encrypted Virtualization (SEV) memory encryption technology and Intel’s Software Guard
Extensions (SGX). <cite class="ltx_cite ltx_citemacro_cite">Mofrad et al. (<a href="#bib.bib7" title="" class="ltx_ref">2018</a>)</cite> provides a
concise comparison of these technologies, each of which generally cryptographically isolate software containers from the host system to
better protect confidential data.</p>
</div>
<div id="S2.SS3.p4" class="ltx_para">
<p id="S2.SS3.p4.1" class="ltx_p">Secure Aggregation as described in <cite class="ltx_cite ltx_citemacro_cite">Bonawitz et al. (<a href="#bib.bib3" title="" class="ltx_ref">2017</a>)</cite> is secure
in the <em id="S2.SS3.p4.1.1" class="ltx_emph ltx_font_italic">honest but curious</em> context. That is, if an attacker gains
access to a participant in the MPC, he will only find secret
shares from which he will not be able to reconstruct the private data.
Here, SEV provides equivalent guarantees of in-memory privacy from attackers
outside the VM/container it protects. As a result, we implement a
Secure Aggregator as a trusted third party running inside an AMD SEV
protected VM. At the end of a training round, workers communicate their encrypted computed weights to the Secure Aggregator who performs the aggregation then uploads a non-encrypted updated model back to the shared storage.</p>
</div>
</section>
<section id="S2.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.4 </span><a name="peer-to-peer-in-transit-encryption-of-updated-weights" id="peer-to-peer-in-transit-encryption-of-updated-weights" class="ltx_anchor">Peer-to-peer in transit encryption of updated
weights</a>
</h3>

<div id="S2.SS4.p1" class="ltx_para">
<p id="S2.SS4.p1.1" class="ltx_p">Weight encryption while in transit between worker and aggregator is
however extremely important since it contains the private data used for
this training step that should remain private to the worker. We assume
here that the members of the consortium will adopt honest but curious behaviour, and would have a strong incentive to
eavesdrop on the network to learn of the raw updates shared by other
members containing valuable information on their private datasets.</p>
</div>
<div id="S2.SS4.p2" class="ltx_para">
<p id="S2.SS4.p2.1" class="ltx_p">At the time of writing, encryption over the wire is not available to protect the traffic between two workers in PySyft. While this feature is under active
development, our system will leverage Ethereum Improvement
Proposal (EIP) 1024 <cite class="ltx_cite ltx_citemacro_cite">Alabi (<a href="#bib.bib2" title="" class="ltx_ref">2018</a>)</cite> that offers peer-to-peer transit encryption of
arbitrary data between two Ethereum accounts. Using EIP-1024, we can encrypt the new weights calculated by each worker before they are being sent back to the Secure Aggregator.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span><a name="security-requirements" id="security-requirements" class="ltx_anchor">Security requirements</a>
</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">Secure aggregation brings a first level of privacy by hiding the raw
updates to a model from a given data owner. However, the
identity of the data owners who took part in a training round could
allow an attacker to extract meaningful information from the aggregated
weights. We describe two counter-measure to this issue in this section.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span><a name="random-selection-of-contributions-to-aggregate" id="random-selection-of-contributions-to-aggregate" class="ltx_anchor">Random selection of contributions to
aggregate</a>
</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">For a given federated training round, all chosen workers will compute gradient updates, but the Secure Aggregator will randomly select a subset of weights for aggregation. After each training round, the Secure Aggregator will forget the unpicked weight updates and the workers will not be notified whether or not their updated weights were selected for aggregation.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.1" class="ltx_p">In the most critical case, a malicious worker or a cartel of workers could communicate their weight updates for a given training round via a third-party channel. This would allow the model owner to reverse engineer a round update and extract the exact contribution of each worker as highlighted in <cite class="ltx_cite ltx_citemacro_cite">Melis et al. (<a href="#bib.bib6" title="" class="ltx_ref">2018</a>)</cite>. By selecting updates for aggregation, such malicious intent to expose another member’s data contribution can be prevented. Note that while this privacy preserving mechanism is distinct from Differential Privacy (DP) <cite class="ltx_cite ltx_citemacro_cite">Papernot et al. (<a href="#bib.bib8" title="" class="ltx_ref">2016</a>); Abadi et al. (<a href="#bib.bib1" title="" class="ltx_ref">2016</a>)</cite>, they can be combined to provide even more enhanced privacy guarantees.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span><a name="privacy-preserving-audit-trail" id="privacy-preserving-audit-trail" class="ltx_anchor">Privacy preserving audit
trail</a>
</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">As described in the global overview of the architecture, a residual benefit from our Ethereum-based system is the immutable audit trail stored
on chain. The audit trail gathers events related to the learning
process. As part of our privacy in depth proposal, we must not leak sensitive information that may compromise the
privacy guarantees of the federated learning process.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.1" class="ltx_p">The Secure Aggregator (SA) will spearhead this non-identifiable update
protocol. First, for each data worker taking part in the round the SA
will generate a new unique random nonce for the current round. Each
worker already has an established secure communication channel with SA
given EIP 1024 transit encryption. Data between SA
and a worker are encrypted using a symmetric Diffie-Helmann (DH) secret
derived from the worker’s public key and SA’s private key (or
conversely). SA will apply Ethereum’s <span id="S3.SS2.p2.1.1" class="ltx_text ltx_font_typewriter">keccak256</span> function to the
concatenation of this shared DH secret and the nonce it just generated, sending the resulting hash encrypted via EIP 1024 to the
corresponding worker. The hash is published on chain and will serve
as an anonymous identifier for the corresponding data worker during a training round.</p>
</div>
<div id="S3.SS2.p3" class="ltx_para">
<p id="S3.SS2.p3.1" class="ltx_p">The only attack to uniquely identify a data worker in the audit trail is to
know the DH secret that has been concatenated to the random nonce. Thus,
as long as the worker’s and SA’s respective private keys remain private,
they are the only two entities in the system able to reidentify the
worker’s corresponding entries in the audit trail.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span><a name="conclusion" id="conclusion" class="ltx_anchor">Conclusion</a>
</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">This work introduced an architecture for federated learning in healthcare consortia built on the Ethereum blockchain. The architecture leverages Ethereum and its ecosystem (e.g., EIP 1024 encryption and the Besu enterprise client) to provide a coherent design reflecting the specific challenges in healthcare consortia. The novel architecture relies on a series of four "privacy in depth" blocks that provide a unique combination of features: fine-grained data access policies, a new Secure Aggregation agent running in hardware-protected processes, weight encryption via EIP 1024 and a privacy preserving audit trail of the events in a training round.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Abadi et al. [2016]</span>
<span class="ltx_bibblock">
M. Abadi, A. Chu, I. Goodfellow, H. B. McMahan, I. Mironov, K. Talwar, and
L. Zhang.

</span>
<span class="ltx_bibblock">Deep learning with differential privacy.

</span>
<span class="ltx_bibblock">In <em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2016 ACM SIGSAC Conference on
Computer and Communications Security</em>, pages 308–318. ACM, 2016.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Alabi [2018]</span>
<span class="ltx_bibblock">
T. Alabi.

</span>
<span class="ltx_bibblock">Ethereum Improvement Proposal-1024 - Add web3.eth.encrypt and
web3.eth.decrypt functions.

</span>
<span class="ltx_bibblock">Technical report, 2018.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://github.com/ethereum/EIPs/pull/1098" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/ethereum/EIPs/pull/1098</a>.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bonawitz et al. [2017]</span>
<span class="ltx_bibblock">
K. Bonawitz, V. Ivanov, B. Kreuter, A. Marcedone, H. B. McMahan, S. Patel,
D. Ramage, A. Segal, and K. Seth.

</span>
<span class="ltx_bibblock">Practical Secure Aggregation for Privacy-Preserving Machine
Learning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2017 ACM SIGSAC Conference on
Computer and Communications Security - CCS ’17</em>, pages 1175–1191,
Dallas, Texas, USA, 2017. ACM Press.

</span>
<span class="ltx_bibblock">ISBN 978-1-4503-4946-8.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1145/3133956.3133982</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="http://dl.acm.org/citation.cfm?doid=3133956.3133982" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://dl.acm.org/citation.cfm?doid=3133956.3133982</a>.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bonawitz et al. [2019]</span>
<span class="ltx_bibblock">
K. Bonawitz, H. Eichner, W. Grieskamp, D. Huba, A. Ingerman, V. Ivanov,
C. Kiddon, J. Konečný, S. Mazzocchi, H. B. McMahan, T. Van Overveldt,
D. Petrou, D. Ramage, and J. Roselander.

</span>
<span class="ltx_bibblock">Towards Federated Learning at Scale: System Design.

</span>
<span class="ltx_bibblock"><em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">arXiv:1902.01046 [cs, stat]</em>, Feb. 2019.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="http://arxiv.org/abs/1902.01046" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://arxiv.org/abs/1902.01046</a>.

</span>
<span class="ltx_bibblock">arXiv: 1902.01046.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lalitha et al. [2018]</span>
<span class="ltx_bibblock">
A. Lalitha, T. Javidi, S. Shekhar, and F. Koushanfar.

</span>
<span class="ltx_bibblock">Fully Decentralized Federated Learning.

</span>
<span class="ltx_bibblock">page 9, Montreal, Canada, 2018.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Melis et al. [2018]</span>
<span class="ltx_bibblock">
L. Melis, C. Song, E. De Cristofaro, and V. Shmatikov.

</span>
<span class="ltx_bibblock">Exploiting Unintended Feature Leakage in Collaborative
Learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">arXiv:1805.04049 [cs]</em>, May 2018.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="http://arxiv.org/abs/1805.04049" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://arxiv.org/abs/1805.04049</a>.

</span>
<span class="ltx_bibblock">arXiv: 1805.04049.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mofrad et al. [2018]</span>
<span class="ltx_bibblock">
S. Mofrad, F. Zhang, S. Lu, and W. Shi.

</span>
<span class="ltx_bibblock">A comparison study of intel SGX and AMD memory encryption
technology.

</span>
<span class="ltx_bibblock">In <em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 7th International Workshop on
Hardware and Architectural Support for Security and Privacy -
HASP ’18</em>, pages 1–8, Los Angeles, California, 2018. ACM Press.

</span>
<span class="ltx_bibblock">ISBN 978-1-4503-6500-0.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1145/3214292.3214301</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="http://dl.acm.org/citation.cfm?doid=3214292.3214301" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://dl.acm.org/citation.cfm?doid=3214292.3214301</a>.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Papernot et al. [2016]</span>
<span class="ltx_bibblock">
N. Papernot, M. Abadi, U. Erlingsson, I. Goodfellow, and K. Talwar.

</span>
<span class="ltx_bibblock">Semi-supervised knowledge transfer for deep learning from private
training data.

</span>
<span class="ltx_bibblock"><em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1610.05755</em>, 2016.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Roy et al. [2019]</span>
<span class="ltx_bibblock">
A. G. Roy, S. Siddiqui, S. Pölsterl, N. Navab, and C. Wachinger.

</span>
<span class="ltx_bibblock">BrainTorrent: A Peer-to-Peer Environment for
Decentralized Federated Learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">arXiv:1905.06731 [cs, stat]</em>, May 2019.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="http://arxiv.org/abs/1905.06731" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://arxiv.org/abs/1905.06731</a>.

</span>
<span class="ltx_bibblock">arXiv: 1905.06731.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ryffel et al. [2018]</span>
<span class="ltx_bibblock">
T. Ryffel, A. Trask, M. Dahl, B. Wagner, J. Mancuso, D. Rueckert, and
J. Passerat-Palmbach.

</span>
<span class="ltx_bibblock">A generic framework for privacy preserving deep learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/1811.04017, 2018.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="http://arxiv.org/abs/1811.04017" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://arxiv.org/abs/1811.04017</a>.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shamir [1979]</span>
<span class="ltx_bibblock">
A. Shamir.

</span>
<span class="ltx_bibblock">How to share a secret.

</span>
<span class="ltx_bibblock"><em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">Communications of the ACM</em>, 22(11):612–613, 1979.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sheller et al. [2019]</span>
<span class="ltx_bibblock">
M. J. Sheller, G. A. Reina, B. Edwards, J. Martin, and S. Bakas.

</span>
<span class="ltx_bibblock">Multi-institutional Deep Learning Modeling Without Sharing
Patient Data: A Feasibility Study on Brain Tumor
Segmentation.

</span>
<span class="ltx_bibblock">In A. Crimi, S. Bakas, H. Kuijf, F. Keyvan, M. Reyes, and T. van
Walsum, editors, <em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">Brainlesion: Glioma, Multiple Sclerosis,
Stroke and Traumatic Brain Injuries</em>, volume 11383, pages 92–104.
Springer International Publishing, Cham, 2019.

</span>
<span class="ltx_bibblock">ISBN 978-3-030-11722-1 978-3-030-11723-8.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1007/978-3-030-11723-8_9</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="http://link.springer.com/10.1007/978-3-030-11723-8_9" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://link.springer.com/10.1007/978-3-030-11723-8_9</a>.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wood and others [2014]</span>
<span class="ltx_bibblock">
G. Wood and others.

</span>
<span class="ltx_bibblock">Ethereum: A secure decentralised generalised transaction ledger.

</span>
<span class="ltx_bibblock"><em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">Ethereum project yellow paper</em>, 151(2014):1–32, 2014.

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/1910.12602" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/1910.12603" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+1910.12603">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/1910.12603" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/1910.12604" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Sat Mar 16 10:23:39 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
