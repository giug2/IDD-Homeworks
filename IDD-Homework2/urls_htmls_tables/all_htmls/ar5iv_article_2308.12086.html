<article class="ltx_document ltx_authors_1line ltx_leqno">
 <h1 class="ltx_title ltx_title_document">
  Out of the Cage: How Stochastic Parrots Win in Cyber Security Environments
 </h1>
 <div class="ltx_authors">
  <span class="ltx_creator ltx_role_author">
   <span class="ltx_personname">
    Maria Rigaki
   </span>
   <span class="ltx_author_notes">
    <span class="ltx_contact ltx_role_email">
     <a href="mailto:maria.rigaki@aic.fel.cvut.cz">
      maria.rigaki@aic.fel.cvut.cz
     </a>
    </span>
    <span class="ltx_contact ltx_role_orcid">
     <a class="ltx_ref" href="https://orcid.org/0000-0002-0688-7752" target="_blank" title="ORCID identifier">
      0000-0002-0688-7752
     </a>
    </span>
    <span class="ltx_contact ltx_role_affiliation">
     <span class="ltx_text ltx_affiliation_institution" id="id1.1.id1">
      Czech Technical University in Prague
     </span>
     <span class="ltx_text ltx_affiliation_streetaddress" id="id2.2.id2">
      Karlovo náměstí 13
     </span>
     <span class="ltx_text ltx_affiliation_country" id="id3.3.id3">
      Czech Republic
     </span>
     <span class="ltx_text ltx_affiliation_postcode" id="id4.4.id4">
      16000
     </span>
    </span>
   </span>
  </span>
  <span class="ltx_author_before">
   ,
  </span>
  <span class="ltx_creator ltx_role_author">
   <span class="ltx_personname">
    Ondřej Lukàš
   </span>
   <span class="ltx_author_notes">
    <span class="ltx_contact ltx_role_email">
     <a href="mailto:ondrej.lukas@aic.fel.cvut.cz">
      ondrej.lukas@aic.fel.cvut.cz
     </a>
    </span>
    <span class="ltx_contact ltx_role_orcid">
     <a class="ltx_ref" href="https://orcid.org/0000-0002-7922-8301" target="_blank" title="ORCID identifier">
      0000-0002-7922-8301
     </a>
    </span>
    <span class="ltx_contact ltx_role_affiliation">
     <span class="ltx_text ltx_affiliation_institution" id="id5.1.id1">
      Czech Technical University in Prague
     </span>
     <span class="ltx_text ltx_affiliation_streetaddress" id="id6.2.id2">
      Karlovo náměstí 13
     </span>
     <span class="ltx_text ltx_affiliation_country" id="id7.3.id3">
      Czech Republic
     </span>
     <span class="ltx_text ltx_affiliation_postcode" id="id8.4.id4">
      16000
     </span>
    </span>
   </span>
  </span>
  <span class="ltx_author_before">
   ,
  </span>
  <span class="ltx_creator ltx_role_author">
   <span class="ltx_personname">
    Carlos A. Catania
   </span>
   <span class="ltx_author_notes">
    <span class="ltx_contact ltx_role_email">
     <a href="mailto:harpo@ingenieria.uncuyo.edu.ar">
      harpo@ingenieria.uncuyo.edu.ar
     </a>
    </span>
    <span class="ltx_contact ltx_role_orcid">
     <a class="ltx_ref" href="https://orcid.org/0000-0002-1749-310X" target="_blank" title="ORCID identifier">
      0000-0002-1749-310X
     </a>
    </span>
    <span class="ltx_contact ltx_role_affiliation">
     <span class="ltx_text ltx_affiliation_institution" id="id9.1.id1">
      School of Engineering, National University of Cuyo
     </span>
     <span class="ltx_text ltx_affiliation_country" id="id10.2.id2">
      Argentina
     </span>
    </span>
   </span>
  </span>
  <span class="ltx_author_before">
   and
  </span>
  <span class="ltx_creator ltx_role_author">
   <span class="ltx_personname">
    Sebastian Garcia
   </span>
   <span class="ltx_author_notes">
    <span class="ltx_contact ltx_role_email">
     <a href="mailto:sebastian.garcia@agents.fel.cvut.cz">
      sebastian.garcia@agents.fel.cvut.cz
     </a>
    </span>
    <span class="ltx_contact ltx_role_orcid">
     <a class="ltx_ref" href="https://orcid.org/0000-0001-6238-9910" target="_blank" title="ORCID identifier">
      0000-0001-6238-9910
     </a>
    </span>
    <span class="ltx_contact ltx_role_affiliation">
     <span class="ltx_text ltx_affiliation_institution" id="id11.1.id1">
      Czech Technical University in Prague
     </span>
     <span class="ltx_text ltx_affiliation_streetaddress" id="id12.2.id2">
      Karlovo náměstí 13
     </span>
     <span class="ltx_text ltx_affiliation_country" id="id13.3.id3">
      Czech Republic
     </span>
     <span class="ltx_text ltx_affiliation_postcode" id="id14.4.id4">
      16000
     </span>
    </span>
   </span>
  </span>
 </div>
 <div class="ltx_abstract">
  <h6 class="ltx_title ltx_title_abstract">
   Abstract.
  </h6>
  <p class="ltx_p" id="id15.id1">
   Large Language Models (LLMs) have gained widespread popularity across diverse domains involving text generation, summarization, and various natural language processing tasks. Despite their inherent limitations, LLM-based designs have shown promising capabilities in planning and navigating open-world scenarios. This paper introduces a novel application of pre-trained LLMs as agents within cybersecurity network environments, focusing on their utility for sequential decision-making processes.
  </p>
  <p class="ltx_p" id="id16.id2">
   We present an approach wherein pre-trained LLMs are leveraged as attacking agents in two reinforcement learning environments. Our proposed agents demonstrate similar or better performance against state-of-the-art agents trained for thousands of episodes in most scenarios and configurations. In addition, the best LLM agents perform similarly to human testers of the environment without any additional training process. This design highlights the potential of LLMs to efficiently address complex decision-making tasks within cybersecurity.
  </p>
  <p class="ltx_p" id="id17.id3">
   Furthermore, we introduce a new network security environment named NetSecGame. The environment is designed to eventually support complex multi-agent scenarios within the network security domain.
The proposed environment mimics real network attacks and is designed to be highly modular and adaptable for various scenarios.
  </p>
 </div>
 <div class="ltx_keywords">
  reinforcement learning, security games, large language models
 </div>
 <span class="ltx_note ltx_note_frontmatter ltx_role_copyright" id="id1">
  <sup class="ltx_note_mark">
   †
  </sup>
  <span class="ltx_note_outer">
   <span class="ltx_note_content">
    <sup class="ltx_note_mark">
     †
    </sup>
    <span class="ltx_note_type">
     copyright:
    </span>
    none
   </span>
  </span>
 </span>
 <span class="ltx_note ltx_note_frontmatter ltx_role_ccs" id="id2">
  <sup class="ltx_note_mark">
   †
  </sup>
  <span class="ltx_note_outer">
   <span class="ltx_note_content">
    <sup class="ltx_note_mark">
     †
    </sup>
    <span class="ltx_note_type">
     ccs:
    </span>
    Security and privacy
   </span>
  </span>
 </span>
 <span class="ltx_note ltx_note_frontmatter ltx_role_ccs" id="id3">
  <sup class="ltx_note_mark">
   †
  </sup>
  <span class="ltx_note_outer">
   <span class="ltx_note_content">
    <sup class="ltx_note_mark">
     †
    </sup>
    <span class="ltx_note_type">
     ccs:
    </span>
    Computing methodologies Planning and scheduling
   </span>
  </span>
 </span>
 <span class="ltx_note ltx_note_frontmatter ltx_role_ccs" id="id4">
  <sup class="ltx_note_mark">
   †
  </sup>
  <span class="ltx_note_outer">
   <span class="ltx_note_content">
    <sup class="ltx_note_mark">
     †
    </sup>
    <span class="ltx_note_type">
     ccs:
    </span>
    Computing methodologies Natural language processing
   </span>
  </span>
 </span>
 <section class="ltx_section" id="S1">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    1.
   </span>
   Introduction
  </h2>
  <div class="ltx_para" id="S1.p1">
   <p class="ltx_p" id="S1.p1.1">
    From text generation to summarization, LLMs have exhibited an exceptional capacity to replicate human-like linguistic capabilities. However, their potential extends beyond these conventional applications. Recently, LLMs have demonstrated abilities in planning and open-world exploration, hinting at their potential to transcend their original boundaries
    <cite class="ltx_cite ltx_citemacro_citep">
     (Park et al
     <span class="ltx_text">
      .
     </span>
     ,
     <a class="ltx_ref" href="#bib.bib25" title="">
      2023
     </a>
     )
    </cite>
    .
   </p>
  </div>
  <div class="ltx_para" id="S1.p2">
   <p class="ltx_p" id="S1.p2.1">
    One such domain where these emerging capabilities hold significant promise is cybersecurity. Automation of network security testing (penetration testing) has been part of the research agenda in the past, mainly centered around reinforcement learning agents and environments. The fusion of LLMs with sequential decision-making processes introduces an interesting new exploration avenue.
   </p>
  </div>
  <div class="ltx_para" id="S1.p3">
   <p class="ltx_p" id="S1.p3.1">
    This paper delves into the intersection of LLMs, cybersecurity, and sequential decision-making. We present a novel approach that uses pre-trained LLMs as agents within cybersecurity environments. By introducing LLM agents, we seek to explore whether these models can not only match but potentially outperform conventional reinforcement learning agents in network security scenarios. To evaluate the effectiveness of our proposed approach, we tested it in two different security environments: Microsoft’s CyberBattleSim
    <cite class="ltx_cite ltx_citemacro_citep">
     (Team,
     <a class="ltx_ref" href="#bib.bib33" title="">
      2021
     </a>
     )
    </cite>
    and our new network security environment named NetSecGame. In addition to the comparison with other RL-based agents, we performed experiments to select the best agent design and the best-performing pre-trained LLM.
   </p>
  </div>
  <div class="ltx_para" id="S1.p4">
   <p class="ltx_p" id="S1.p4.1">
    Experiments showed that pre-trained LLMs agents can be successful in different scenarios with win rates of 100% when there is no defender present and 50% when a defender is present in the hardest scenario (80% win rate in the easier scenario). When comparing pre-trained LLMs, we found that GPT-4
    <cite class="ltx_cite ltx_citemacro_citep">
     (OpenAI,
     <a class="ltx_ref" href="#bib.bib24" title="">
      2023
     </a>
     )
    </cite>
    outperforms GPT-3.5-turbo significantly and at the same time exhibits high stability.
   </p>
  </div>
  <div class="ltx_para" id="S1.p5">
   <p class="ltx_p" id="S1.p5.1">
    The main contributions of the paper are:
   </p>
   <ul class="ltx_itemize" id="S1.I1">
    <li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
     <span class="ltx_tag ltx_tag_item">
      •
     </span>
     <div class="ltx_para" id="S1.I1.i1.p1">
      <p class="ltx_p" id="S1.I1.i1.p1.1">
       The use of pre-trained LLM agents designed for network cybersecurity scenarios. The agent’s performance is comparable to or better than reinforcement learning agents that require thousands of training episodes.
      </p>
     </div>
    </li>
    <li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
     <span class="ltx_tag ltx_tag_item">
      •
     </span>
     <div class="ltx_para" id="S1.I1.i2.p1">
      <p class="ltx_p" id="S1.I1.i2.p1.1">
       A new network security reinforcement learning modular environment, called NetSecGame, that implements realistic conditions and a defender.
      </p>
     </div>
    </li>
   </ul>
  </div>
  <div class="ltx_para" id="S1.p6">
   <p class="ltx_p" id="S1.p6.1">
    The rest of the paper is organized as follows: First, we provide some background information on large language models and present the related work for using LLMs in security applications as well as planning agents that use pre-trained LLMs (Section
    <a class="ltx_ref" href="#S2" title="2. Background and Related Work ‣ Out of the Cage: How Stochastic Parrots Win in Cyber Security Environments">
     <span class="ltx_text ltx_ref_tag">
      2
     </span>
    </a>
    ). In Section
    <a class="ltx_ref" href="#S3" title="3. NetSecGame Environment ‣ Out of the Cage: How Stochastic Parrots Win in Cyber Security Environments">
     <span class="ltx_text ltx_ref_tag">
      3
     </span>
    </a>
    we introduce the NetSecGame environment. In Sections
    <a class="ltx_ref" href="#S4" title="4. LLM Agents for NetSecGame ‣ Out of the Cage: How Stochastic Parrots Win in Cyber Security Environments">
     <span class="ltx_text ltx_ref_tag">
      4
     </span>
    </a>
    and
    <a class="ltx_ref" href="#S5" title="5. LLM Agent for CyberBattleSim ‣ Out of the Cage: How Stochastic Parrots Win in Cyber Security Environments">
     <span class="ltx_text ltx_ref_tag">
      5
     </span>
    </a>
    we present the detailed design of the LLM-based agents for the NetSecGame and the CyberBattleSim environments, respectively. The experimental setup is described in Section
    <a class="ltx_ref" href="#S6" title="6. Experimental Setup ‣ Out of the Cage: How Stochastic Parrots Win in Cyber Security Environments">
     <span class="ltx_text ltx_ref_tag">
      6
     </span>
    </a>
    and the results of the experiments are presented in Section
    <a class="ltx_ref" href="#S7" title="7. Results ‣ Out of the Cage: How Stochastic Parrots Win in Cyber Security Environments">
     <span class="ltx_text ltx_ref_tag">
      7
     </span>
    </a>
    . The limitations and future work are discussed in Section
    <a class="ltx_ref" href="#S8" title="8. Limitations and Future Work ‣ Out of the Cage: How Stochastic Parrots Win in Cyber Security Environments">
     <span class="ltx_text ltx_ref_tag">
      8
     </span>
    </a>
    and the conclusions of the paper are presented in Section
    <a class="ltx_ref" href="#S9" title="9. Conclusions ‣ Out of the Cage: How Stochastic Parrots Win in Cyber Security Environments">
     <span class="ltx_text ltx_ref_tag">
      9
     </span>
    </a>
    .
   </p>
  </div>
 </section>
 <section class="ltx_section" id="S2">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    2.
   </span>
   Background and Related Work
  </h2>
  <div class="ltx_para" id="S2.p1">
   <p class="ltx_p" id="S2.p1.1">
    A significant milestone in the extended research done in Natural Language Processing (NLP) was the introduction of the transformer architecture in 2017
    <cite class="ltx_cite ltx_citemacro_citep">
     (Vaswani et al
     <span class="ltx_text">
      .
     </span>
     ,
     <a class="ltx_ref" href="#bib.bib35" title="">
      2017
     </a>
     )
    </cite>
    , which revolutionized the field. Transformers are neural networks that introduced the self-attention mechanism, allowing them to process data sequences in parallel rather than sequentially. A transformer consists of an encoder and a decoder, each composed of multiple layers. The self-attention mechanism enables the model to weigh the importance of different words in a sequence, capturing local and global dependencies. Positional encodings are added to input embeddings to preserve sequence order.
   </p>
  </div>
  <div class="ltx_para" id="S2.p2">
   <p class="ltx_p" id="S2.p2.1">
    The encoder and the decoder architectures have been used as stand-alone models for different purposes. The encoder architecture was used for text classification, sentiment analysis, and other predictive modeling tasks
    <cite class="ltx_cite ltx_citemacro_citep">
     (Devlin et al
     <span class="ltx_text">
      .
     </span>
     ,
     <a class="ltx_ref" href="#bib.bib8" title="">
      2019
     </a>
     ; Liu et al
     <span class="ltx_text">
      .
     </span>
     ,
     <a class="ltx_ref" href="#bib.bib20" title="">
      2019
     </a>
     )
    </cite>
    , while the decoder had applications in generative tasks
    <cite class="ltx_cite ltx_citemacro_citep">
     (Radford et al
     <span class="ltx_text">
      .
     </span>
     ,
     <a class="ltx_ref" href="#bib.bib27" title="">
      2019
     </a>
     ; Brown et al
     <span class="ltx_text">
      .
     </span>
     ,
     <a class="ltx_ref" href="#bib.bib4" title="">
      2020
     </a>
     )
    </cite>
    . The full encoder-decoder architectures can also be used for generative tasks, such as summarization, generative question answering, and translation
    <cite class="ltx_cite ltx_citemacro_citep">
     (Raffel et al
     <span class="ltx_text">
      .
     </span>
     ,
     <a class="ltx_ref" href="#bib.bib28" title="">
      2020
     </a>
     ; Lewis et al
     <span class="ltx_text">
      .
     </span>
     ,
     <a class="ltx_ref" href="#bib.bib18" title="">
      2019
     </a>
     )
    </cite>
    .
   </p>
  </div>
  <div class="ltx_para" id="S2.p3">
   <p class="ltx_p" id="S2.p3.2">
    Pre-trained language models, especially earlier versions such as GPT-3, were shown to have limited abilities when it comes to logical reasoning and planning. However, providing one or more examples as input can improve the model’s ability to answer questions requiring reasoning
    <cite class="ltx_cite ltx_citemacro_citep">
     (Brown et al
     <span class="ltx_text">
      .
     </span>
     ,
     <a class="ltx_ref" href="#bib.bib4" title="">
      2020
     </a>
     )
    </cite>
    . The idea of guiding or teaching the model about the expected behavior during inference time using prompts is called
    <span class="ltx_text ltx_font_italic" id="S2.p3.2.1">
     in-context learning
    </span>
    . Several techniques have been proposed to improve this
    <math alttext="k" class="ltx_Math" display="inline" id="S2.p3.1.m1.1">
     <semantics id="S2.p3.1.m1.1a">
      <mi id="S2.p3.1.m1.1.1" xref="S2.p3.1.m1.1.1.cmml">
       k
      </mi>
      <annotation-xml encoding="MathML-Content" id="S2.p3.1.m1.1b">
       <ci id="S2.p3.1.m1.1.1.cmml" xref="S2.p3.1.m1.1.1">
        𝑘
       </ci>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S2.p3.1.m1.1c">
       k
      </annotation>
     </semantics>
    </math>
    -shot example setting, where
    <math alttext="k" class="ltx_Math" display="inline" id="S2.p3.2.m2.1">
     <semantics id="S2.p3.2.m2.1a">
      <mi id="S2.p3.2.m2.1.1" xref="S2.p3.2.m2.1.1.cmml">
       k
      </mi>
      <annotation-xml encoding="MathML-Content" id="S2.p3.2.m2.1b">
       <ci id="S2.p3.2.m2.1.1.cmml" xref="S2.p3.2.m2.1.1">
        𝑘
       </ci>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S2.p3.2.m2.1c">
       k
      </annotation>
     </semantics>
    </math>
    is the number of examples given to the model. The first one is called
    <span class="ltx_text ltx_font_italic" id="S2.p3.2.2">
     Chain of Thought
    </span>
    (CoT)
    <cite class="ltx_cite ltx_citemacro_citep">
     (Wei et al
     <span class="ltx_text">
      .
     </span>
     ,
     <a class="ltx_ref" href="#bib.bib39" title="">
      2023
     </a>
     )
    </cite>
    , and the idea behind it is to provide an example of the expected answer accompanied by the reasoning that is used to get to the answer. This approach performed well in questions related to logical reasoning. However, later Kojima et al.
    <cite class="ltx_cite ltx_citemacro_citep">
     (Kojima et al
     <span class="ltx_text">
      .
     </span>
     ,
     <a class="ltx_ref" href="#bib.bib17" title="">
      2023
     </a>
     )
    </cite>
    showed that just prompting the LLMs with the phrase
    <span class="ltx_text ltx_font_italic" id="S2.p3.2.3">
     ”Let’s think step by step”
    </span>
    is enough to solve questions that require some degree of logical reasoning without the use of examples.
   </p>
  </div>
  <section class="ltx_subsection" id="S2.SS1">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     2.1.
    </span>
    Security Applications of LLMs
   </h3>
   <div class="ltx_para" id="S2.SS1.p1">
    <p class="ltx_p" id="S2.SS1.p1.1">
     LLMs are impacting network security in many areas. In particular, given their capacity to work with text, they can be used to prevent various social engineering attacks such as phishing, baiting, and tailgating, among others
     <cite class="ltx_cite ltx_citemacro_citep">
      (Misra and Rayz,
      <a class="ltx_ref" href="#bib.bib21" title="">
       2022
      </a>
      )
     </cite>
     . In these instances, the text typically comes in regular interactions, allowing LLMs to utilize their extensive language knowledge to detect uncommon communication patterns that might signal potential threats.
    </p>
   </div>
   <div class="ltx_para" id="S2.SS1.p2">
    <p class="ltx_p" id="S2.SS1.p2.1">
     LLMs can be a fundamental part of an Intrusion detection architecture as it was described in
     <cite class="ltx_cite ltx_citemacro_citep">
      (Nam et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib23" title="">
       2021
      </a>
      )
     </cite>
     , where the authors propose the use of a bi-directional GPT-based intrusion detection model for Controller Area Networks (CAN). Since network activities are often recorded in log files, such as Zeek logs or DNS queries, they can serve as an excellent data source for LLMs to classify text and detect malicious activities. An approach already applied in
     <cite class="ltx_cite ltx_citemacro_citep">
      (Chen and Liao,
      <a class="ltx_ref" href="#bib.bib7" title="">
       2022
      </a>
      )
     </cite>
     , where logs are analyzed using a BERT model to detect anomalies. Similarly, LLMs were used to detect HTTP threats
     <cite class="ltx_cite ltx_citemacro_citep">
      (Seyyar et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib30" title="">
       2022
      </a>
      )
     </cite>
     .
    </p>
   </div>
   <div class="ltx_para" id="S2.SS1.p3">
    <p class="ltx_p" id="S2.SS1.p3.1">
     With the advent of LLMs such as Codex
     <cite class="ltx_cite ltx_citemacro_citep">
      (Chen et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib6" title="">
       2021
      </a>
      )
     </cite>
     and StarCoder
     <cite class="ltx_cite ltx_citemacro_citep">
      (Li et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib19" title="">
       2023
      </a>
      )
     </cite>
     , they have shown the ability to understand source code in multiple programming languages. This offers the potential to analyze software code and system configurations for vulnerabilities and prioritize fixes based on severity
     <cite class="ltx_cite ltx_citemacro_citep">
      (Pearce et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib26" title="">
       2023
      </a>
      ; Thapa et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib34" title="">
       2022
      </a>
      )
     </cite>
     .
    </p>
   </div>
   <div class="ltx_para" id="S2.SS1.p4">
    <p class="ltx_p" id="S2.SS1.p4.1">
     Current research
     <cite class="ltx_cite ltx_citemacro_citep">
      (Park et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib25" title="">
       2023
      </a>
      )
     </cite>
     indicates that LLMs can replicate intricate behaviors with prompt engineering and more complex designs. In cybersecurity, these LLMs can be instructed to imitate offensive and defensive user behavior. Some initial work on the topic has recently emerged
     <cite class="ltx_cite ltx_citemacro_citep">
      (Happe and Cito,
      <a class="ltx_ref" href="#bib.bib14" title="">
       2023
      </a>
      )
     </cite>
     . However, the setup is rather simplistic, and the authors provide very few details about the design of the LLM-based agents.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S2.SS2">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     2.2.
    </span>
    LLMs for Planning and Reinforcement Learning
   </h3>
   <div class="ltx_para" id="S2.SS2.p1">
    <p class="ltx_p" id="S2.SS2.p1.1">
     Even with some of the reasoning skills induced by prompts, pre-trained LLMs can still not perform long-term planning and sometimes hallucinate and take actions that are either not helpful or relevant. However, frameworks that propose the use of multiple-stage prompts such as ReAct
     <cite class="ltx_cite ltx_citemacro_citep">
      (Yao et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib41" title="">
       2023
      </a>
      )
     </cite>
     , Reflexion
     <cite class="ltx_cite ltx_citemacro_citep">
      (Shinn et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib31" title="">
       2023
      </a>
      )
     </cite>
     , and Describe, Explain, Plan and Select (DEPS)
     <cite class="ltx_cite ltx_citemacro_citep">
      (Wang et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib37" title="">
       2023a
      </a>
      )
     </cite>
     , have shown that LLM agents can be better planners if they incorporate reasoning and self-reflection before they act.
    </p>
   </div>
   <div class="ltx_para" id="S2.SS2.p2">
    <p class="ltx_p" id="S2.SS2.p2.1">
     ReAct
     <cite class="ltx_cite ltx_citemacro_citep">
      (Yao et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib41" title="">
       2023
      </a>
      )
     </cite>
     combines reasoning with action in an interleaved manner, and it performed well in more complex question-answering tasks that required several logical steps, and in-context learning was not sufficient.
Reflexion
     <cite class="ltx_cite ltx_citemacro_citep">
      (Shinn et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib31" title="">
       2023
      </a>
      )
     </cite>
     is a sequential decision-making framework that uses several components, such as self-reflection and evaluation, to assess the quality of the different actions taken by the agent and the whole trajectory within an episode. The framework also uses two types of memory. A short-term one keeps track of the actions during an episode, and a long-term one is used in subsequent episodes, allowing the agent to learn from past episodes.
    </p>
   </div>
   <div class="ltx_para" id="S2.SS2.p3">
    <p class="ltx_p" id="S2.SS2.p3.1">
     LLM-based agents can be successful in exploration
     <cite class="ltx_cite ltx_citemacro_citep">
      (Du et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib10" title="">
       2023
      </a>
      ; Wang et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib36" title="">
       2023b
      </a>
      )
     </cite>
     . Voyager was used for open-ended exploration in the Minecraft game and consisted of three major components: an automatic curriculum that facilitates open-ended exploration, a skill library, and an iterative prompting mechanism. Du et al.
     <cite class="ltx_cite ltx_citemacro_citep">
      (Du et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib10" title="">
       2023
      </a>
      )
     </cite>
     proposed the use of pre-trained LLMs to provide ”intrinsic motivation” that guides the exploration and goal setting of the agent in the Crafter
     <cite class="ltx_cite ltx_citemacro_citep">
      (Hafner,
      <a class="ltx_ref" href="#bib.bib12" title="">
       2022
      </a>
      )
     </cite>
     and Housekeep
     <cite class="ltx_cite ltx_citemacro_citep">
      (Kant et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib16" title="">
       2022
      </a>
      )
     </cite>
     environments. The authors used a combination of sentence transformers to create embeddings of the current state of the environment and past actions. They also used GPT-4
     <cite class="ltx_cite ltx_citemacro_citep">
      (OpenAI,
      <a class="ltx_ref" href="#bib.bib24" title="">
       2023
      </a>
      )
     </cite>
     to generate plausible goals for the agent.
Finally, Spring
     <cite class="ltx_cite ltx_citemacro_citep">
      (Wu et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib40" title="">
       2023
      </a>
      )
     </cite>
     uses an LLM to ”study” an academic paper that describes the Crafter game environment. Using the summarized knowledge of the paper, they use a guided Q&amp;A approach with the LLM to select the best action to take. In Spring, the pre-trained LLM with the best performance was GPT-4
     <cite class="ltx_cite ltx_citemacro_citep">
      (OpenAI,
      <a class="ltx_ref" href="#bib.bib24" title="">
       2023
      </a>
      )
     </cite>
     from OpenAI, while in Voyager, the authors used a combination of GPT-3.5-turbo and GPT-4 in order to lower the cost. The environments used in the above works are quite different from the ones related to network security. However, the results show that agents can plan and reach goals that require multiple steps.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S2.SS3">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     2.3.
    </span>
    Cybersecurity Reinforcement Learning Environments
   </h3>
   <div class="ltx_para" id="S2.SS3.p1">
    <p class="ltx_p" id="S2.SS3.p1.1">
     There are some existing environments created to train and test agents in network-based cybersecurity scenarios using reinforcement learning principles
     <cite class="ltx_cite ltx_citemacro_citep">
      (Elderman et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib11" title="">
       2017
      </a>
      ; Hammar and Stadler,
      <a class="ltx_ref" href="#bib.bib13" title="">
       2020
      </a>
      ; Team,
      <a class="ltx_ref" href="#bib.bib33" title="">
       2021
      </a>
      ; Standen et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib32" title="">
       2021
      </a>
      ; Andrew et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib2" title="">
       2022
      </a>
      ; Janisch et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib15" title="">
       2023
      </a>
      )
     </cite>
     . One of the main issues of the prior work is that the authors of each environment make different decisions about how networks behave, which goals should be attained, the presence of a defender or not, and how rewards are counted. Despite these decisions being very important to determine if an agent can be used in a real network, most environments do not discuss or justify them in detail while still considering their assumptions correct and realistic.
    </p>
   </div>
   <div class="ltx_para" id="S2.SS3.p2">
    <p class="ltx_p" id="S2.SS3.p2.1">
     For example, some environments have as the attacker’s goal to compromise one or more nodes (sometimes compromise more than half the network)
     <cite class="ltx_cite ltx_citemacro_citep">
      (Team,
      <a class="ltx_ref" href="#bib.bib33" title="">
       2021
      </a>
      ; Schwartz and Kurniawati,
      <a class="ltx_ref" href="#bib.bib29" title="">
       2019
      </a>
      ; Janisch et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib15" title="">
       2023
      </a>
      ; Hammar and Stadler,
      <a class="ltx_ref" href="#bib.bib13" title="">
       2020
      </a>
      )
     </cite>
     and the defender, when present, can ”patch” or restore compromised nodes
     <cite class="ltx_cite ltx_citemacro_citep">
      (Team,
      <a class="ltx_ref" href="#bib.bib33" title="">
       2021
      </a>
      ; Hammar and Stadler,
      <a class="ltx_ref" href="#bib.bib13" title="">
       2020
      </a>
      )
     </cite>
     . Only CyberBattleSim and Titan environments currently support some type of defender (CYBORG blue agent was under development and not finished when published).
    </p>
   </div>
   <div class="ltx_para" id="S2.SS3.p3">
    <p class="ltx_p" id="S2.SS3.p3.1">
     Most environments support the OpenAI Gym
     <cite class="ltx_cite ltx_citemacro_citep">
      (Brockman et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib3" title="">
       2016
      </a>
      )
     </cite>
     API, enabling off-the-shelf reinforcement learning libraries and algorithms to train the agents. However, most approaches rely on naive vectorization of the state space using adjacency matrices plus additional feature vectors to hold information about services running in each node and the possible exploits for each service. This type of approach, unfortunately, does not scale well, especially if the goal is to simulate attacks in enterprise networks.
    </p>
   </div>
  </section>
 </section>
 <section class="ltx_section" id="S3">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    3.
   </span>
   NetSecGame Environment
  </h2>
  <div class="ltx_para" id="S3.p1">
   <p class="ltx_p" id="S3.p1.1">
    NetSecGame is our novel simulated network security environment designed to train and test both attacking and defensive strategy agents. At its core, it defines a network topology, a set of possible high-level actions, the parameters of those actions, a particular goal, and rewards, and it controls the game’s dynamics. The code for the environment and the agents is available in the anonymized repository
    <span class="ltx_note ltx_role_footnote" id="footnote1">
     <sup class="ltx_note_mark">
      1
     </sup>
     <span class="ltx_note_outer">
      <span class="ltx_note_content">
       <sup class="ltx_note_mark">
        1
       </sup>
       <span class="ltx_tag ltx_tag_note">
        1
       </span>
       <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/stratosphereips/NetSecGame" target="_blank" title="">
        https://github.com/stratosphereips/NetSecGame
       </a>
      </span>
     </span>
    </span>
    .
   </p>
  </div>
  <div class="ltx_para" id="S3.p2">
   <p class="ltx_p" id="S3.p2.1">
    The main differences of our environment with previous work are how it is conceptually closer to an actual attack. First, it is very modular and easy to extend to new topologies. Second, the agent does not receive any helpful information in the state that is not real. Third, the goal is very realistic: to exfiltrate data to the Internet. Fourth, there is a defender present in the environment. Fifth, rewards are not engineered for the problem. They are generic.
   </p>
  </div>
  <div class="ltx_para" id="S3.p3">
   <p class="ltx_p" id="S3.p3.1">
    Agents interact with NetSecGame via a Python API following a reinforcement learning (RL) model: Agents act and receive a new state, a reward, and the end-of-game signal. NetSecGame can be easily configured to use different network topologies, including hosts, routers, services on each host, and data on each service. NetSecGame aims to provide a high-level description of a network security attack while being realistic in its core concepts.
   </p>
  </div>
  <div class="ltx_para" id="S3.p4">
   <p class="ltx_p" id="S3.p4.1">
    NetSecGame has six main parts: (i) configuration, (ii) action space, (iii) state space, (iv) reward, (v) goal, and (vi) defensive agent.
   </p>
  </div>
  <section class="ltx_subsection" id="S3.SS1">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     3.1.
    </span>
    Configuration of NetSecGame
   </h3>
   <div class="ltx_para" id="S3.SS1.p1">
    <p class="ltx_p" id="S3.SS1.p1.1">
     NetSecGame uses two configuration files. The first is for defining the network topology, and the second is for defining the behavior of the RL part of the environment.
    </p>
   </div>
   <div class="ltx_para" id="S3.SS1.p2">
    <p class="ltx_p" id="S3.SS1.p2.1">
     The network topology configuration uses a configuration file from the CYST simulation environment
     <cite class="ltx_cite ltx_citemacro_citep">
      (Drašar et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib9" title="">
       2020
      </a>
      )
     </cite>
     . CYST was used since it is a flexible simulation engine based on network events. Different configuration files for the topology define different ’scenarios’ as described in Subsection
     <a class="ltx_ref" href="#S3.SS2" title="3.2. Network Scenarios ‣ 3. NetSecGame Environment ‣ Out of the Cage: How Stochastic Parrots Win in Cyber Security Environments">
      <span class="ltx_text ltx_ref_tag">
       3.2
      </span>
     </a>
     .
    </p>
   </div>
   <div class="ltx_para" id="S3.SS1.p3">
    <p class="ltx_p" id="S3.SS1.p3.1">
     The network topology configuration file defines:
    </p>
    <ul class="ltx_itemize" id="S3.I1">
     <li class="ltx_item" id="S3.I1.i1" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       •
      </span>
      <div class="ltx_para" id="S3.I1.i1.p1">
       <p class="ltx_p" id="S3.I1.i1.p1.1">
        Clients: A client is defined as a Node with an IP address on an interface and the networks to which it is connected.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="S3.I1.i2" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       •
      </span>
      <div class="ltx_para" id="S3.I1.i2.p1">
       <p class="ltx_p" id="S3.I1.i2.p1.1">
        Servers: A server is defined as a Node with an IP address, a group of services, and the networks to which it is connected. The two routers in the environment (main router and Internet router) are servers with two interfaces.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="S3.I1.i3" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       •
      </span>
      <div class="ltx_para" id="S3.I1.i3.p1">
       <p class="ltx_p" id="S3.I1.i3.p1.1">
        Services: A service is defined with a description and what data is present on it.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="S3.I1.i4" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       •
      </span>
      <div class="ltx_para" id="S3.I1.i4.p1">
       <p class="ltx_p" id="S3.I1.i4.p1.1">
        Data: Data are strings stored in a service.
       </p>
      </div>
     </li>
    </ul>
   </div>
   <div class="ltx_para" id="S3.SS1.p4">
    <p class="ltx_p" id="S3.SS1.p4.1">
     The second configuration regarding the RL part of the environment is stored together with the configuration of each agent. It includes if there is going to be a defender agent or not, the specific
     <span class="ltx_text ltx_font_italic" id="S3.SS1.p4.1.1">
      scenario
     </span>
     used, the maximum amount of actions allowed (steps), and for each action, the probability of success and the probability of detection (this last one only if there is a defender agent). An example configuration file can be found in the anonymized repository
     <span class="ltx_note ltx_role_footnote" id="footnote2">
      <sup class="ltx_note_mark">
       2
      </sup>
      <span class="ltx_note_outer">
       <span class="ltx_note_content">
        <sup class="ltx_note_mark">
         2
        </sup>
        <span class="ltx_tag ltx_tag_note">
         2
        </span>
        <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/stratosphereips/NetSecGame/blob/main/agents/q_learning/netsecenv-task.yaml" target="_blank" title="">
         https://github.com/stratosphereips/NetSecGame/blob/main/agents/q_learning/netsecenv-task.yaml
        </a>
       </span>
      </span>
     </span>
     .
    </p>
   </div>
   <section class="ltx_paragraph" id="S3.SS1.SSS0.Px1">
    <h5 class="ltx_title ltx_title_paragraph">
     Defender
    </h5>
    <div class="ltx_para" id="S3.SS1.SSS0.Px1.p1">
     <p class="ltx_p" id="S3.SS1.SSS0.Px1.p1.1">
      NetSecGame includes the option to have an omnipresent defender in the environment that is not an agent. It represents the concept of a SOC team that has visibility in the whole network and can see the actions of computers and act accordingly. The agent is called
      <span class="ltx_text ltx_font_italic" id="S3.SS1.SSS0.Px1.p1.1.1">
       StochasticDefenderWithThreshold
      </span>
      and works as follows:
     </p>
     <ol class="ltx_enumerate" id="S3.I2">
      <li class="ltx_item" id="S3.I2.i1" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        (1)
       </span>
       <div class="ltx_para" id="S3.I2.i1.p1">
        <p class="ltx_p" id="S3.I2.i1.p1.1">
         For the whole episode:
        </p>
        <ol class="ltx_enumerate" id="S3.I2.i1.I1">
         <li class="ltx_item" id="S3.I2.i1.I1.i1" style="list-style-type:none;">
          <span class="ltx_tag ltx_tag_item">
           (a)
          </span>
          <div class="ltx_para" id="S3.I2.i1.I1.i1.p1">
           <p class="ltx_p" id="S3.I2.i1.I1.i1.p1.1">
            If the total number of actions of a certain
            <span class="ltx_text ltx_font_italic" id="S3.I2.i1.I1.i1.p1.1.1">
             ActionType
            </span>
            is below a threshold, no detection is done.
           </p>
          </div>
         </li>
         <li class="ltx_item" id="S3.I2.i1.I1.i2" style="list-style-type:none;">
          <span class="ltx_tag ltx_tag_item">
           (b)
          </span>
          <div class="ltx_para" id="S3.I2.i1.I1.i2.p1">
           <p class="ltx_p" id="S3.I2.i1.I1.i2.p1.1">
            If the total number of actions of a certain
            <span class="ltx_text ltx_font_italic" id="S3.I2.i1.I1.i2.p1.1.1">
             ActionType
            </span>
            is above a threshold, a probability distribution is used to decide the detection.
           </p>
          </div>
         </li>
         <li class="ltx_item" id="S3.I2.i1.I1.i3" style="list-style-type:none;">
          <span class="ltx_tag ltx_tag_item">
           (c)
          </span>
          <div class="ltx_para" id="S3.I2.i1.I1.i3.p1">
           <p class="ltx_p" id="S3.I2.i1.I1.i3.p1.1">
            If the number of consecutive actions of a certain
            <span class="ltx_text ltx_font_italic" id="S3.I2.i1.I1.i3.p1.1.1">
             ActionType
            </span>
            is below a threshold, no detection is done.
           </p>
          </div>
         </li>
         <li class="ltx_item" id="S3.I2.i1.I1.i4" style="list-style-type:none;">
          <span class="ltx_tag ltx_tag_item">
           (d)
          </span>
          <div class="ltx_para" id="S3.I2.i1.I1.i4.p1">
           <p class="ltx_p" id="S3.I2.i1.I1.i4.p1.1">
            If the number of consecutive actions of a certain
            <span class="ltx_text ltx_font_italic" id="S3.I2.i1.I1.i4.p1.1.1">
             ActionType
            </span>
            is above a threshold, a probability distribution is used to decide the detection.
           </p>
          </div>
         </li>
         <li class="ltx_item" id="S3.I2.i1.I1.i5" style="list-style-type:none;">
          <span class="ltx_tag ltx_tag_item">
           (e)
          </span>
          <div class="ltx_para" id="S3.I2.i1.I1.i5.p1">
           <p class="ltx_p" id="S3.I2.i1.I1.i5.p1.1">
            For actions
            <span class="ltx_text ltx_font_italic" id="S3.I2.i1.I1.i5.p1.1.1">
             FindData
            </span>
            and
            <span class="ltx_text ltx_font_italic" id="S3.I2.i1.I1.i5.p1.1.2">
             ExploitService
            </span>
            repeatedly used with the same parameters, they are automatically detected if they are repeated more than a threshold.
           </p>
          </div>
         </li>
        </ol>
       </div>
      </li>
      <li class="ltx_item" id="S3.I2.i2" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        (2)
       </span>
       <div class="ltx_para" id="S3.I2.i2.p1">
        <p class="ltx_p" id="S3.I2.i2.p1.1">
         For a time window (TW) of the last actions (e.g., 5):
        </p>
        <ol class="ltx_enumerate" id="S3.I2.i2.I1">
         <li class="ltx_item" id="S3.I2.i2.I1.i1" style="list-style-type:none;">
          <span class="ltx_tag ltx_tag_item">
           (a)
          </span>
          <div class="ltx_para" id="S3.I2.i2.I1.i1.p1">
           <p class="ltx_p" id="S3.I2.i2.I1.i1.p1.1">
            For each
            <span class="ltx_text ltx_font_italic" id="S3.I2.i2.I1.i1.p1.1.1">
             ActionType
            </span>
            compute the ratio of actions done in the last TW.
           </p>
          </div>
         </li>
         <li class="ltx_item" id="S3.I2.i2.I1.i2" style="list-style-type:none;">
          <span class="ltx_tag ltx_tag_item">
           (b)
          </span>
          <div class="ltx_para" id="S3.I2.i2.I1.i2.p1">
           <p class="ltx_p" id="S3.I2.i2.I1.i2.p1.1">
            If the ratio is below a threshold, do not detect.
           </p>
          </div>
         </li>
         <li class="ltx_item" id="S3.I2.i2.I1.i3" style="list-style-type:none;">
          <span class="ltx_tag ltx_tag_item">
           (c)
          </span>
          <div class="ltx_para" id="S3.I2.i2.I1.i3.p1">
           <p class="ltx_p" id="S3.I2.i2.I1.i3.p1.1">
            If the ratio is above a threshold, use a probability distribution to decide the detection.
           </p>
          </div>
         </li>
        </ol>
       </div>
      </li>
     </ol>
    </div>
    <div class="ltx_para" id="S3.SS1.SSS0.Px1.p2">
     <p class="ltx_p" id="S3.SS1.SSS0.Px1.p2.1">
      The probability distribution is uniform. The exact percentages required for each action are in the agent’s configuration file.
     </p>
    </div>
    <div class="ltx_para" id="S3.SS1.SSS0.Px1.p3">
     <p class="ltx_p" id="S3.SS1.SSS0.Px1.p3.1">
      If an action generates a transition into a winning state and simultaneously generates a detection, the priority is given to the defender so the detection is successful and the agent loses.
     </p>
    </div>
   </section>
  </section>
  <section class="ltx_subsection" id="S3.SS2">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     3.2.
    </span>
    Network Scenarios
   </h3>
   <div class="ltx_para" id="S3.SS2.p1">
    <p class="ltx_p" id="S3.SS2.p1.1">
     NetSecGame comes with three predefined network topologies scenarios with growing complexity. Each scenario has a different number of clients and servers, number of services, and data. However, it can be easily extended with servers, data, routers, etc. Details of the scenarios used in our experiments are shown in Section
     <a class="ltx_ref" href="#S6.SS1" title="6.1. NetSecGame Environment Configuration ‣ 6. Experimental Setup ‣ Out of the Cage: How Stochastic Parrots Win in Cyber Security Environments">
      <span class="ltx_text ltx_ref_tag">
       6.1
      </span>
     </a>
     .
    </p>
   </div>
   <section class="ltx_paragraph" id="S3.SS2.SSS0.Px1">
    <h5 class="ltx_title ltx_title_paragraph">
     Goal
    </h5>
    <div class="ltx_para" id="S3.SS2.SSS0.Px1.p1">
     <p class="ltx_p" id="S3.SS2.SSS0.Px1.p1.1">
      The goal of the attacker is defined as a specific state. If that state is reached without detection, then the agent wins. This gives much flexibility in the definition of any goal. If researchers want to goal to be the discovery of a specific service, the winning state should be defined as having that specific service and empty values for the rest. In our case, the winning state has a specific piece of data inside the external command and control server on the Internet. When such a state is reached, the goal is fulfilled.
     </p>
    </div>
    <div class="ltx_para" id="S3.SS2.SSS0.Px1.p2">
     <p class="ltx_p" id="S3.SS2.SSS0.Px1.p2.1">
      NetSecGame allows randomizing the network addresses, the IP addresses, the position of all the data, and, most importantly, randomizing the goal by changing the required data and its position. The decision to randomize the goal is crucial for agents and human players. Since the goal is randomized, humans can not learn a consistent pattern by playing repeatedly. Indeed, real attackers usually attack only once on the same network, so for them, there is no point in remembering IP addresses. However, randomization is needed in our multiple repeated games to keep the game fair.
     </p>
    </div>
   </section>
  </section>
  <section class="ltx_subsection" id="S3.SS3">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     3.3.
    </span>
    State Representation
   </h3>
   <div class="ltx_para" id="S3.SS3.p1">
    <p class="ltx_p" id="S3.SS3.p1.1">
     NetSecGame represents states as a collection of assets known to the attacker:
     <span class="ltx_text ltx_font_italic" id="S3.SS3.p1.1.1">
      known networks
     </span>
     ,
     <span class="ltx_text ltx_font_italic" id="S3.SS3.p1.1.2">
      known hosts
     </span>
     ,
     <span class="ltx_text ltx_font_italic" id="S3.SS3.p1.1.3">
      controlled hosts
     </span>
     ,
     <span class="ltx_text ltx_font_italic" id="S3.SS3.p1.1.4">
      known services
     </span>
     , and
     <span class="ltx_text ltx_font_italic" id="S3.SS3.p1.1.5">
      known data
     </span>
     . Note that the agent can compute all this data, and the environment only facilitates it. There is no extra help in understanding the environment. The
     <span class="ltx_text ltx_font_italic" id="S3.SS3.p1.1.6">
      known networks
     </span>
     are the networks known to the agent (currently only given at the start of the game),
     <span class="ltx_text ltx_font_italic" id="S3.SS3.p1.1.7">
      known hosts
     </span>
     are the hosts found by scanning a network,
     <span class="ltx_text ltx_font_italic" id="S3.SS3.p1.1.8">
      controlled hosts
     </span>
     are the hosts that were successfully exploited,
     <span class="ltx_text ltx_font_italic" id="S3.SS3.p1.1.9">
      known services
     </span>
     are the hosts-services pairs found after the action
     <span class="ltx_text ltx_font_italic" id="S3.SS3.p1.1.10">
      find services
     </span>
     , and
     <span class="ltx_text ltx_font_italic" id="S3.SS3.p1.1.11">
      known data
     </span>
     are the host-data pairs found by the
     <span class="ltx_text ltx_font_italic" id="S3.SS3.p1.1.12">
      find data
     </span>
     action.
After each action, the agent receives a new state of the environment.
Such design is based on the reality that the attackers often have limited knowledge about the network and gradually discover it throughout interactions.
    </p>
   </div>
   <div class="ltx_para" id="S3.SS3.p2">
    <p class="ltx_p" id="S3.SS3.p2.1">
     Each action, if successful depending on the probability of success, extends one or more of these collections. Currently, NetSecGame does not implement actions that delete items from the assets collection, decreasing the branching factor in the state space.
    </p>
   </div>
   <div class="ltx_para" id="S3.SS3.p3">
    <p class="ltx_p" id="S3.SS3.p3.4">
     In terms of complexity, the possible size of the state space can be computed as follows:
Let
     <math alttext="N" class="ltx_Math" display="inline" id="S3.SS3.p3.1.m1.1">
      <semantics id="S3.SS3.p3.1.m1.1a">
       <mi id="S3.SS3.p3.1.m1.1.1" xref="S3.SS3.p3.1.m1.1.1.cmml">
        N
       </mi>
       <annotation-xml encoding="MathML-Content" id="S3.SS3.p3.1.m1.1b">
        <ci id="S3.SS3.p3.1.m1.1.1.cmml" xref="S3.SS3.p3.1.m1.1.1">
         𝑁
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS3.p3.1.m1.1c">
        N
       </annotation>
      </semantics>
     </math>
     be the number of networks,
     <math alttext="H" class="ltx_Math" display="inline" id="S3.SS3.p3.2.m2.1">
      <semantics id="S3.SS3.p3.2.m2.1a">
       <mi id="S3.SS3.p3.2.m2.1.1" xref="S3.SS3.p3.2.m2.1.1.cmml">
        H
       </mi>
       <annotation-xml encoding="MathML-Content" id="S3.SS3.p3.2.m2.1b">
        <ci id="S3.SS3.p3.2.m2.1.1.cmml" xref="S3.SS3.p3.2.m2.1.1">
         𝐻
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS3.p3.2.m2.1c">
        H
       </annotation>
      </semantics>
     </math>
     the number of hosts,
     <math alttext="Sthe" class="ltx_Math" display="inline" id="S3.SS3.p3.3.m3.1">
      <semantics id="S3.SS3.p3.3.m3.1a">
       <mrow id="S3.SS3.p3.3.m3.1.1" xref="S3.SS3.p3.3.m3.1.1.cmml">
        <mi id="S3.SS3.p3.3.m3.1.1.2" xref="S3.SS3.p3.3.m3.1.1.2.cmml">
         S
        </mi>
        <mo id="S3.SS3.p3.3.m3.1.1.1" lspace="0em" rspace="0em" xref="S3.SS3.p3.3.m3.1.1.1.cmml">
         ​
        </mo>
        <mi id="S3.SS3.p3.3.m3.1.1.3" xref="S3.SS3.p3.3.m3.1.1.3.cmml">
         t
        </mi>
        <mo id="S3.SS3.p3.3.m3.1.1.1a" lspace="0em" rspace="0em" xref="S3.SS3.p3.3.m3.1.1.1.cmml">
         ​
        </mo>
        <mi id="S3.SS3.p3.3.m3.1.1.4" xref="S3.SS3.p3.3.m3.1.1.4.cmml">
         h
        </mi>
        <mo id="S3.SS3.p3.3.m3.1.1.1b" lspace="0em" rspace="0em" xref="S3.SS3.p3.3.m3.1.1.1.cmml">
         ​
        </mo>
        <mi id="S3.SS3.p3.3.m3.1.1.5" xref="S3.SS3.p3.3.m3.1.1.5.cmml">
         e
        </mi>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="S3.SS3.p3.3.m3.1b">
        <apply id="S3.SS3.p3.3.m3.1.1.cmml" xref="S3.SS3.p3.3.m3.1.1">
         <times id="S3.SS3.p3.3.m3.1.1.1.cmml" xref="S3.SS3.p3.3.m3.1.1.1">
         </times>
         <ci id="S3.SS3.p3.3.m3.1.1.2.cmml" xref="S3.SS3.p3.3.m3.1.1.2">
          𝑆
         </ci>
         <ci id="S3.SS3.p3.3.m3.1.1.3.cmml" xref="S3.SS3.p3.3.m3.1.1.3">
          𝑡
         </ci>
         <ci id="S3.SS3.p3.3.m3.1.1.4.cmml" xref="S3.SS3.p3.3.m3.1.1.4">
          ℎ
         </ci>
         <ci id="S3.SS3.p3.3.m3.1.1.5.cmml" xref="S3.SS3.p3.3.m3.1.1.5">
          𝑒
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS3.p3.3.m3.1c">
        Sthe
       </annotation>
      </semantics>
     </math>
     number of services, and
     <math alttext="D" class="ltx_Math" display="inline" id="S3.SS3.p3.4.m4.1">
      <semantics id="S3.SS3.p3.4.m4.1a">
       <mi id="S3.SS3.p3.4.m4.1.1" xref="S3.SS3.p3.4.m4.1.1.cmml">
        D
       </mi>
       <annotation-xml encoding="MathML-Content" id="S3.SS3.p3.4.m4.1b">
        <ci id="S3.SS3.p3.4.m4.1.1.cmml" xref="S3.SS3.p3.4.m4.1.1">
         𝐷
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS3.p3.4.m4.1c">
        D
       </annotation>
      </semantics>
     </math>
     amount of data points in the environment. Then the complexity of the environment is
bounded by
    </p>
    <table class="ltx_equation ltx_eqn_table" id="S3.Ex1">
     <tbody>
      <tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
       <td class="ltx_eqn_cell ltx_eqn_center_padleft">
       </td>
       <td class="ltx_eqn_cell ltx_align_center">
        <math alttext="O(f(N,H,S,D))" class="ltx_Math" display="block" id="S3.Ex1.m1.5">
         <semantics id="S3.Ex1.m1.5a">
          <mrow id="S3.Ex1.m1.5.5" xref="S3.Ex1.m1.5.5.cmml">
           <mi id="S3.Ex1.m1.5.5.3" xref="S3.Ex1.m1.5.5.3.cmml">
            O
           </mi>
           <mo id="S3.Ex1.m1.5.5.2" lspace="0em" rspace="0em" xref="S3.Ex1.m1.5.5.2.cmml">
            ​
           </mo>
           <mrow id="S3.Ex1.m1.5.5.1.1" xref="S3.Ex1.m1.5.5.1.1.1.cmml">
            <mo id="S3.Ex1.m1.5.5.1.1.2" stretchy="false" xref="S3.Ex1.m1.5.5.1.1.1.cmml">
             (
            </mo>
            <mrow id="S3.Ex1.m1.5.5.1.1.1" xref="S3.Ex1.m1.5.5.1.1.1.cmml">
             <mi id="S3.Ex1.m1.5.5.1.1.1.2" xref="S3.Ex1.m1.5.5.1.1.1.2.cmml">
              f
             </mi>
             <mo id="S3.Ex1.m1.5.5.1.1.1.1" lspace="0em" rspace="0em" xref="S3.Ex1.m1.5.5.1.1.1.1.cmml">
              ​
             </mo>
             <mrow id="S3.Ex1.m1.5.5.1.1.1.3.2" xref="S3.Ex1.m1.5.5.1.1.1.3.1.cmml">
              <mo id="S3.Ex1.m1.5.5.1.1.1.3.2.1" stretchy="false" xref="S3.Ex1.m1.5.5.1.1.1.3.1.cmml">
               (
              </mo>
              <mi id="S3.Ex1.m1.1.1" xref="S3.Ex1.m1.1.1.cmml">
               N
              </mi>
              <mo id="S3.Ex1.m1.5.5.1.1.1.3.2.2" xref="S3.Ex1.m1.5.5.1.1.1.3.1.cmml">
               ,
              </mo>
              <mi id="S3.Ex1.m1.2.2" xref="S3.Ex1.m1.2.2.cmml">
               H
              </mi>
              <mo id="S3.Ex1.m1.5.5.1.1.1.3.2.3" xref="S3.Ex1.m1.5.5.1.1.1.3.1.cmml">
               ,
              </mo>
              <mi id="S3.Ex1.m1.3.3" xref="S3.Ex1.m1.3.3.cmml">
               S
              </mi>
              <mo id="S3.Ex1.m1.5.5.1.1.1.3.2.4" xref="S3.Ex1.m1.5.5.1.1.1.3.1.cmml">
               ,
              </mo>
              <mi id="S3.Ex1.m1.4.4" xref="S3.Ex1.m1.4.4.cmml">
               D
              </mi>
              <mo id="S3.Ex1.m1.5.5.1.1.1.3.2.5" stretchy="false" xref="S3.Ex1.m1.5.5.1.1.1.3.1.cmml">
               )
              </mo>
             </mrow>
            </mrow>
            <mo id="S3.Ex1.m1.5.5.1.1.3" stretchy="false" xref="S3.Ex1.m1.5.5.1.1.1.cmml">
             )
            </mo>
           </mrow>
          </mrow>
          <annotation-xml encoding="MathML-Content" id="S3.Ex1.m1.5b">
           <apply id="S3.Ex1.m1.5.5.cmml" xref="S3.Ex1.m1.5.5">
            <times id="S3.Ex1.m1.5.5.2.cmml" xref="S3.Ex1.m1.5.5.2">
            </times>
            <ci id="S3.Ex1.m1.5.5.3.cmml" xref="S3.Ex1.m1.5.5.3">
             𝑂
            </ci>
            <apply id="S3.Ex1.m1.5.5.1.1.1.cmml" xref="S3.Ex1.m1.5.5.1.1">
             <times id="S3.Ex1.m1.5.5.1.1.1.1.cmml" xref="S3.Ex1.m1.5.5.1.1.1.1">
             </times>
             <ci id="S3.Ex1.m1.5.5.1.1.1.2.cmml" xref="S3.Ex1.m1.5.5.1.1.1.2">
              𝑓
             </ci>
             <vector id="S3.Ex1.m1.5.5.1.1.1.3.1.cmml" xref="S3.Ex1.m1.5.5.1.1.1.3.2">
              <ci id="S3.Ex1.m1.1.1.cmml" xref="S3.Ex1.m1.1.1">
               𝑁
              </ci>
              <ci id="S3.Ex1.m1.2.2.cmml" xref="S3.Ex1.m1.2.2">
               𝐻
              </ci>
              <ci id="S3.Ex1.m1.3.3.cmml" xref="S3.Ex1.m1.3.3">
               𝑆
              </ci>
              <ci id="S3.Ex1.m1.4.4.cmml" xref="S3.Ex1.m1.4.4">
               𝐷
              </ci>
             </vector>
            </apply>
           </apply>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="S3.Ex1.m1.5c">
           O(f(N,H,S,D))
          </annotation>
         </semantics>
        </math>
       </td>
       <td class="ltx_eqn_cell ltx_eqn_center_padright">
       </td>
      </tr>
     </tbody>
    </table>
    <p class="ltx_p" id="S3.SS3.p3.5">
     where
    </p>
    <table class="ltx_equation ltx_eqn_table" id="S3.Ex2">
     <tbody>
      <tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
       <td class="ltx_eqn_cell ltx_eqn_center_padleft">
       </td>
       <td class="ltx_eqn_cell ltx_align_center">
        <math alttext="f(N,H,S,D)=2^{(N-1)}*3^{(H-2)}*2^{S-1}*2^{(D*H)}" class="ltx_Math" display="block" id="S3.Ex2.m1.7">
         <semantics id="S3.Ex2.m1.7a">
          <mrow id="S3.Ex2.m1.7.8" xref="S3.Ex2.m1.7.8.cmml">
           <mrow id="S3.Ex2.m1.7.8.2" xref="S3.Ex2.m1.7.8.2.cmml">
            <mi id="S3.Ex2.m1.7.8.2.2" xref="S3.Ex2.m1.7.8.2.2.cmml">
             f
            </mi>
            <mo id="S3.Ex2.m1.7.8.2.1" lspace="0em" rspace="0em" xref="S3.Ex2.m1.7.8.2.1.cmml">
             ​
            </mo>
            <mrow id="S3.Ex2.m1.7.8.2.3.2" xref="S3.Ex2.m1.7.8.2.3.1.cmml">
             <mo id="S3.Ex2.m1.7.8.2.3.2.1" stretchy="false" xref="S3.Ex2.m1.7.8.2.3.1.cmml">
              (
             </mo>
             <mi id="S3.Ex2.m1.4.4" xref="S3.Ex2.m1.4.4.cmml">
              N
             </mi>
             <mo id="S3.Ex2.m1.7.8.2.3.2.2" xref="S3.Ex2.m1.7.8.2.3.1.cmml">
              ,
             </mo>
             <mi id="S3.Ex2.m1.5.5" xref="S3.Ex2.m1.5.5.cmml">
              H
             </mi>
             <mo id="S3.Ex2.m1.7.8.2.3.2.3" xref="S3.Ex2.m1.7.8.2.3.1.cmml">
              ,
             </mo>
             <mi id="S3.Ex2.m1.6.6" xref="S3.Ex2.m1.6.6.cmml">
              S
             </mi>
             <mo id="S3.Ex2.m1.7.8.2.3.2.4" xref="S3.Ex2.m1.7.8.2.3.1.cmml">
              ,
             </mo>
             <mi id="S3.Ex2.m1.7.7" xref="S3.Ex2.m1.7.7.cmml">
              D
             </mi>
             <mo id="S3.Ex2.m1.7.8.2.3.2.5" stretchy="false" xref="S3.Ex2.m1.7.8.2.3.1.cmml">
              )
             </mo>
            </mrow>
           </mrow>
           <mo id="S3.Ex2.m1.7.8.1" xref="S3.Ex2.m1.7.8.1.cmml">
            =
           </mo>
           <mrow id="S3.Ex2.m1.7.8.3" xref="S3.Ex2.m1.7.8.3.cmml">
            <msup id="S3.Ex2.m1.7.8.3.2" xref="S3.Ex2.m1.7.8.3.2.cmml">
             <mn id="S3.Ex2.m1.7.8.3.2.2" xref="S3.Ex2.m1.7.8.3.2.2.cmml">
              2
             </mn>
             <mrow id="S3.Ex2.m1.1.1.1.1" xref="S3.Ex2.m1.1.1.1.1.1.cmml">
              <mo id="S3.Ex2.m1.1.1.1.1.2" stretchy="false" xref="S3.Ex2.m1.1.1.1.1.1.cmml">
               (
              </mo>
              <mrow id="S3.Ex2.m1.1.1.1.1.1" xref="S3.Ex2.m1.1.1.1.1.1.cmml">
               <mi id="S3.Ex2.m1.1.1.1.1.1.2" xref="S3.Ex2.m1.1.1.1.1.1.2.cmml">
                N
               </mi>
               <mo id="S3.Ex2.m1.1.1.1.1.1.1" xref="S3.Ex2.m1.1.1.1.1.1.1.cmml">
                −
               </mo>
               <mn id="S3.Ex2.m1.1.1.1.1.1.3" xref="S3.Ex2.m1.1.1.1.1.1.3.cmml">
                1
               </mn>
              </mrow>
              <mo id="S3.Ex2.m1.1.1.1.1.3" stretchy="false" xref="S3.Ex2.m1.1.1.1.1.1.cmml">
               )
              </mo>
             </mrow>
            </msup>
            <mo id="S3.Ex2.m1.7.8.3.1" lspace="0.222em" rspace="0.222em" xref="S3.Ex2.m1.7.8.3.1.cmml">
             ∗
            </mo>
            <msup id="S3.Ex2.m1.7.8.3.3" xref="S3.Ex2.m1.7.8.3.3.cmml">
             <mn id="S3.Ex2.m1.7.8.3.3.2" xref="S3.Ex2.m1.7.8.3.3.2.cmml">
              3
             </mn>
             <mrow id="S3.Ex2.m1.2.2.1.1" xref="S3.Ex2.m1.2.2.1.1.1.cmml">
              <mo id="S3.Ex2.m1.2.2.1.1.2" stretchy="false" xref="S3.Ex2.m1.2.2.1.1.1.cmml">
               (
              </mo>
              <mrow id="S3.Ex2.m1.2.2.1.1.1" xref="S3.Ex2.m1.2.2.1.1.1.cmml">
               <mi id="S3.Ex2.m1.2.2.1.1.1.2" xref="S3.Ex2.m1.2.2.1.1.1.2.cmml">
                H
               </mi>
               <mo id="S3.Ex2.m1.2.2.1.1.1.1" xref="S3.Ex2.m1.2.2.1.1.1.1.cmml">
                −
               </mo>
               <mn id="S3.Ex2.m1.2.2.1.1.1.3" xref="S3.Ex2.m1.2.2.1.1.1.3.cmml">
                2
               </mn>
              </mrow>
              <mo id="S3.Ex2.m1.2.2.1.1.3" stretchy="false" xref="S3.Ex2.m1.2.2.1.1.1.cmml">
               )
              </mo>
             </mrow>
            </msup>
            <mo id="S3.Ex2.m1.7.8.3.1a" lspace="0.222em" rspace="0.222em" xref="S3.Ex2.m1.7.8.3.1.cmml">
             ∗
            </mo>
            <msup id="S3.Ex2.m1.7.8.3.4" xref="S3.Ex2.m1.7.8.3.4.cmml">
             <mn id="S3.Ex2.m1.7.8.3.4.2" xref="S3.Ex2.m1.7.8.3.4.2.cmml">
              2
             </mn>
             <mrow id="S3.Ex2.m1.7.8.3.4.3" xref="S3.Ex2.m1.7.8.3.4.3.cmml">
              <mi id="S3.Ex2.m1.7.8.3.4.3.2" xref="S3.Ex2.m1.7.8.3.4.3.2.cmml">
               S
              </mi>
              <mo id="S3.Ex2.m1.7.8.3.4.3.1" xref="S3.Ex2.m1.7.8.3.4.3.1.cmml">
               −
              </mo>
              <mn id="S3.Ex2.m1.7.8.3.4.3.3" xref="S3.Ex2.m1.7.8.3.4.3.3.cmml">
               1
              </mn>
             </mrow>
            </msup>
            <mo id="S3.Ex2.m1.7.8.3.1b" lspace="0.222em" rspace="0.222em" xref="S3.Ex2.m1.7.8.3.1.cmml">
             ∗
            </mo>
            <msup id="S3.Ex2.m1.7.8.3.5" xref="S3.Ex2.m1.7.8.3.5.cmml">
             <mn id="S3.Ex2.m1.7.8.3.5.2" xref="S3.Ex2.m1.7.8.3.5.2.cmml">
              2
             </mn>
             <mrow id="S3.Ex2.m1.3.3.1.1" xref="S3.Ex2.m1.3.3.1.1.1.cmml">
              <mo id="S3.Ex2.m1.3.3.1.1.2" stretchy="false" xref="S3.Ex2.m1.3.3.1.1.1.cmml">
               (
              </mo>
              <mrow id="S3.Ex2.m1.3.3.1.1.1" xref="S3.Ex2.m1.3.3.1.1.1.cmml">
               <mi id="S3.Ex2.m1.3.3.1.1.1.2" xref="S3.Ex2.m1.3.3.1.1.1.2.cmml">
                D
               </mi>
               <mo id="S3.Ex2.m1.3.3.1.1.1.1" lspace="0.222em" rspace="0.222em" xref="S3.Ex2.m1.3.3.1.1.1.1.cmml">
                ∗
               </mo>
               <mi id="S3.Ex2.m1.3.3.1.1.1.3" xref="S3.Ex2.m1.3.3.1.1.1.3.cmml">
                H
               </mi>
              </mrow>
              <mo id="S3.Ex2.m1.3.3.1.1.3" stretchy="false" xref="S3.Ex2.m1.3.3.1.1.1.cmml">
               )
              </mo>
             </mrow>
            </msup>
           </mrow>
          </mrow>
          <annotation-xml encoding="MathML-Content" id="S3.Ex2.m1.7b">
           <apply id="S3.Ex2.m1.7.8.cmml" xref="S3.Ex2.m1.7.8">
            <eq id="S3.Ex2.m1.7.8.1.cmml" xref="S3.Ex2.m1.7.8.1">
            </eq>
            <apply id="S3.Ex2.m1.7.8.2.cmml" xref="S3.Ex2.m1.7.8.2">
             <times id="S3.Ex2.m1.7.8.2.1.cmml" xref="S3.Ex2.m1.7.8.2.1">
             </times>
             <ci id="S3.Ex2.m1.7.8.2.2.cmml" xref="S3.Ex2.m1.7.8.2.2">
              𝑓
             </ci>
             <vector id="S3.Ex2.m1.7.8.2.3.1.cmml" xref="S3.Ex2.m1.7.8.2.3.2">
              <ci id="S3.Ex2.m1.4.4.cmml" xref="S3.Ex2.m1.4.4">
               𝑁
              </ci>
              <ci id="S3.Ex2.m1.5.5.cmml" xref="S3.Ex2.m1.5.5">
               𝐻
              </ci>
              <ci id="S3.Ex2.m1.6.6.cmml" xref="S3.Ex2.m1.6.6">
               𝑆
              </ci>
              <ci id="S3.Ex2.m1.7.7.cmml" xref="S3.Ex2.m1.7.7">
               𝐷
              </ci>
             </vector>
            </apply>
            <apply id="S3.Ex2.m1.7.8.3.cmml" xref="S3.Ex2.m1.7.8.3">
             <times id="S3.Ex2.m1.7.8.3.1.cmml" xref="S3.Ex2.m1.7.8.3.1">
             </times>
             <apply id="S3.Ex2.m1.7.8.3.2.cmml" xref="S3.Ex2.m1.7.8.3.2">
              <csymbol cd="ambiguous" id="S3.Ex2.m1.7.8.3.2.1.cmml" xref="S3.Ex2.m1.7.8.3.2">
               superscript
              </csymbol>
              <cn id="S3.Ex2.m1.7.8.3.2.2.cmml" type="integer" xref="S3.Ex2.m1.7.8.3.2.2">
               2
              </cn>
              <apply id="S3.Ex2.m1.1.1.1.1.1.cmml" xref="S3.Ex2.m1.1.1.1.1">
               <minus id="S3.Ex2.m1.1.1.1.1.1.1.cmml" xref="S3.Ex2.m1.1.1.1.1.1.1">
               </minus>
               <ci id="S3.Ex2.m1.1.1.1.1.1.2.cmml" xref="S3.Ex2.m1.1.1.1.1.1.2">
                𝑁
               </ci>
               <cn id="S3.Ex2.m1.1.1.1.1.1.3.cmml" type="integer" xref="S3.Ex2.m1.1.1.1.1.1.3">
                1
               </cn>
              </apply>
             </apply>
             <apply id="S3.Ex2.m1.7.8.3.3.cmml" xref="S3.Ex2.m1.7.8.3.3">
              <csymbol cd="ambiguous" id="S3.Ex2.m1.7.8.3.3.1.cmml" xref="S3.Ex2.m1.7.8.3.3">
               superscript
              </csymbol>
              <cn id="S3.Ex2.m1.7.8.3.3.2.cmml" type="integer" xref="S3.Ex2.m1.7.8.3.3.2">
               3
              </cn>
              <apply id="S3.Ex2.m1.2.2.1.1.1.cmml" xref="S3.Ex2.m1.2.2.1.1">
               <minus id="S3.Ex2.m1.2.2.1.1.1.1.cmml" xref="S3.Ex2.m1.2.2.1.1.1.1">
               </minus>
               <ci id="S3.Ex2.m1.2.2.1.1.1.2.cmml" xref="S3.Ex2.m1.2.2.1.1.1.2">
                𝐻
               </ci>
               <cn id="S3.Ex2.m1.2.2.1.1.1.3.cmml" type="integer" xref="S3.Ex2.m1.2.2.1.1.1.3">
                2
               </cn>
              </apply>
             </apply>
             <apply id="S3.Ex2.m1.7.8.3.4.cmml" xref="S3.Ex2.m1.7.8.3.4">
              <csymbol cd="ambiguous" id="S3.Ex2.m1.7.8.3.4.1.cmml" xref="S3.Ex2.m1.7.8.3.4">
               superscript
              </csymbol>
              <cn id="S3.Ex2.m1.7.8.3.4.2.cmml" type="integer" xref="S3.Ex2.m1.7.8.3.4.2">
               2
              </cn>
              <apply id="S3.Ex2.m1.7.8.3.4.3.cmml" xref="S3.Ex2.m1.7.8.3.4.3">
               <minus id="S3.Ex2.m1.7.8.3.4.3.1.cmml" xref="S3.Ex2.m1.7.8.3.4.3.1">
               </minus>
               <ci id="S3.Ex2.m1.7.8.3.4.3.2.cmml" xref="S3.Ex2.m1.7.8.3.4.3.2">
                𝑆
               </ci>
               <cn id="S3.Ex2.m1.7.8.3.4.3.3.cmml" type="integer" xref="S3.Ex2.m1.7.8.3.4.3.3">
                1
               </cn>
              </apply>
             </apply>
             <apply id="S3.Ex2.m1.7.8.3.5.cmml" xref="S3.Ex2.m1.7.8.3.5">
              <csymbol cd="ambiguous" id="S3.Ex2.m1.7.8.3.5.1.cmml" xref="S3.Ex2.m1.7.8.3.5">
               superscript
              </csymbol>
              <cn id="S3.Ex2.m1.7.8.3.5.2.cmml" type="integer" xref="S3.Ex2.m1.7.8.3.5.2">
               2
              </cn>
              <apply id="S3.Ex2.m1.3.3.1.1.1.cmml" xref="S3.Ex2.m1.3.3.1.1">
               <times id="S3.Ex2.m1.3.3.1.1.1.1.cmml" xref="S3.Ex2.m1.3.3.1.1.1.1">
               </times>
               <ci id="S3.Ex2.m1.3.3.1.1.1.2.cmml" xref="S3.Ex2.m1.3.3.1.1.1.2">
                𝐷
               </ci>
               <ci id="S3.Ex2.m1.3.3.1.1.1.3.cmml" xref="S3.Ex2.m1.3.3.1.1.1.3">
                𝐻
               </ci>
              </apply>
             </apply>
            </apply>
           </apply>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="S3.Ex2.m1.7c">
           f(N,H,S,D)=2^{(N-1)}*3^{(H-2)}*2^{S-1}*2^{(D*H)}
          </annotation>
         </semantics>
        </math>
       </td>
       <td class="ltx_eqn_cell ltx_eqn_center_padright">
       </td>
      </tr>
     </tbody>
    </table>
   </div>
   <div class="ltx_para" id="S3.SS3.p4">
    <p class="ltx_p" id="S3.SS3.p4.1">
     Concretely:
    </p>
    <ul class="ltx_itemize" id="S3.I3">
     <li class="ltx_item" id="S3.I3.i1" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       •
      </span>
      <div class="ltx_para" id="S3.I3.i1.p1">
       <p class="ltx_p" id="S3.I3.i1.p1.1">
        <math alttext="2^{(N-1)}" class="ltx_Math" display="inline" id="S3.I3.i1.p1.1.m1.1">
         <semantics id="S3.I3.i1.p1.1.m1.1a">
          <msup id="S3.I3.i1.p1.1.m1.1.2" xref="S3.I3.i1.p1.1.m1.1.2.cmml">
           <mn id="S3.I3.i1.p1.1.m1.1.2.2" xref="S3.I3.i1.p1.1.m1.1.2.2.cmml">
            2
           </mn>
           <mrow id="S3.I3.i1.p1.1.m1.1.1.1.1" xref="S3.I3.i1.p1.1.m1.1.1.1.1.1.cmml">
            <mo id="S3.I3.i1.p1.1.m1.1.1.1.1.2" stretchy="false" xref="S3.I3.i1.p1.1.m1.1.1.1.1.1.cmml">
             (
            </mo>
            <mrow id="S3.I3.i1.p1.1.m1.1.1.1.1.1" xref="S3.I3.i1.p1.1.m1.1.1.1.1.1.cmml">
             <mi id="S3.I3.i1.p1.1.m1.1.1.1.1.1.2" xref="S3.I3.i1.p1.1.m1.1.1.1.1.1.2.cmml">
              N
             </mi>
             <mo id="S3.I3.i1.p1.1.m1.1.1.1.1.1.1" xref="S3.I3.i1.p1.1.m1.1.1.1.1.1.1.cmml">
              −
             </mo>
             <mn id="S3.I3.i1.p1.1.m1.1.1.1.1.1.3" xref="S3.I3.i1.p1.1.m1.1.1.1.1.1.3.cmml">
              1
             </mn>
            </mrow>
            <mo id="S3.I3.i1.p1.1.m1.1.1.1.1.3" stretchy="false" xref="S3.I3.i1.p1.1.m1.1.1.1.1.1.cmml">
             )
            </mo>
           </mrow>
          </msup>
          <annotation-xml encoding="MathML-Content" id="S3.I3.i1.p1.1.m1.1b">
           <apply id="S3.I3.i1.p1.1.m1.1.2.cmml" xref="S3.I3.i1.p1.1.m1.1.2">
            <csymbol cd="ambiguous" id="S3.I3.i1.p1.1.m1.1.2.1.cmml" xref="S3.I3.i1.p1.1.m1.1.2">
             superscript
            </csymbol>
            <cn id="S3.I3.i1.p1.1.m1.1.2.2.cmml" type="integer" xref="S3.I3.i1.p1.1.m1.1.2.2">
             2
            </cn>
            <apply id="S3.I3.i1.p1.1.m1.1.1.1.1.1.cmml" xref="S3.I3.i1.p1.1.m1.1.1.1.1">
             <minus id="S3.I3.i1.p1.1.m1.1.1.1.1.1.1.cmml" xref="S3.I3.i1.p1.1.m1.1.1.1.1.1.1">
             </minus>
             <ci id="S3.I3.i1.p1.1.m1.1.1.1.1.1.2.cmml" xref="S3.I3.i1.p1.1.m1.1.1.1.1.1.2">
              𝑁
             </ci>
             <cn id="S3.I3.i1.p1.1.m1.1.1.1.1.1.3.cmml" type="integer" xref="S3.I3.i1.p1.1.m1.1.1.1.1.1.3">
              1
             </cn>
            </apply>
           </apply>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="S3.I3.i1.p1.1.m1.1c">
           2^{(N-1)}
          </annotation>
         </semantics>
        </math>
        - represents the possibility of knowing each network (the agent starts with at least 1 known network).
       </p>
      </div>
     </li>
     <li class="ltx_item" id="S3.I3.i2" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       •
      </span>
      <div class="ltx_para" id="S3.I3.i2.p1">
       <p class="ltx_p" id="S3.I3.i2.p1.1">
        <math alttext="3^{(H-2)}" class="ltx_Math" display="inline" id="S3.I3.i2.p1.1.m1.1">
         <semantics id="S3.I3.i2.p1.1.m1.1a">
          <msup id="S3.I3.i2.p1.1.m1.1.2" xref="S3.I3.i2.p1.1.m1.1.2.cmml">
           <mn id="S3.I3.i2.p1.1.m1.1.2.2" xref="S3.I3.i2.p1.1.m1.1.2.2.cmml">
            3
           </mn>
           <mrow id="S3.I3.i2.p1.1.m1.1.1.1.1" xref="S3.I3.i2.p1.1.m1.1.1.1.1.1.cmml">
            <mo id="S3.I3.i2.p1.1.m1.1.1.1.1.2" stretchy="false" xref="S3.I3.i2.p1.1.m1.1.1.1.1.1.cmml">
             (
            </mo>
            <mrow id="S3.I3.i2.p1.1.m1.1.1.1.1.1" xref="S3.I3.i2.p1.1.m1.1.1.1.1.1.cmml">
             <mi id="S3.I3.i2.p1.1.m1.1.1.1.1.1.2" xref="S3.I3.i2.p1.1.m1.1.1.1.1.1.2.cmml">
              H
             </mi>
             <mo id="S3.I3.i2.p1.1.m1.1.1.1.1.1.1" xref="S3.I3.i2.p1.1.m1.1.1.1.1.1.1.cmml">
              −
             </mo>
             <mn id="S3.I3.i2.p1.1.m1.1.1.1.1.1.3" xref="S3.I3.i2.p1.1.m1.1.1.1.1.1.3.cmml">
              2
             </mn>
            </mrow>
            <mo id="S3.I3.i2.p1.1.m1.1.1.1.1.3" stretchy="false" xref="S3.I3.i2.p1.1.m1.1.1.1.1.1.cmml">
             )
            </mo>
           </mrow>
          </msup>
          <annotation-xml encoding="MathML-Content" id="S3.I3.i2.p1.1.m1.1b">
           <apply id="S3.I3.i2.p1.1.m1.1.2.cmml" xref="S3.I3.i2.p1.1.m1.1.2">
            <csymbol cd="ambiguous" id="S3.I3.i2.p1.1.m1.1.2.1.cmml" xref="S3.I3.i2.p1.1.m1.1.2">
             superscript
            </csymbol>
            <cn id="S3.I3.i2.p1.1.m1.1.2.2.cmml" type="integer" xref="S3.I3.i2.p1.1.m1.1.2.2">
             3
            </cn>
            <apply id="S3.I3.i2.p1.1.m1.1.1.1.1.1.cmml" xref="S3.I3.i2.p1.1.m1.1.1.1.1">
             <minus id="S3.I3.i2.p1.1.m1.1.1.1.1.1.1.cmml" xref="S3.I3.i2.p1.1.m1.1.1.1.1.1.1">
             </minus>
             <ci id="S3.I3.i2.p1.1.m1.1.1.1.1.1.2.cmml" xref="S3.I3.i2.p1.1.m1.1.1.1.1.1.2">
              𝐻
             </ci>
             <cn id="S3.I3.i2.p1.1.m1.1.1.1.1.1.3.cmml" type="integer" xref="S3.I3.i2.p1.1.m1.1.1.1.1.1.3">
              2
             </cn>
            </apply>
           </apply>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="S3.I3.i2.p1.1.m1.1c">
           3^{(H-2)}
          </annotation>
         </semantics>
        </math>
        - each host in the environment is either unknown, known, or controlled (agent starts with at least 2 controlled hosts).
       </p>
      </div>
     </li>
     <li class="ltx_item" id="S3.I3.i3" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       •
      </span>
      <div class="ltx_para" id="S3.I3.i3.p1">
       <p class="ltx_p" id="S3.I3.i3.p1.1">
        <math alttext="2^{S}" class="ltx_Math" display="inline" id="S3.I3.i3.p1.1.m1.1">
         <semantics id="S3.I3.i3.p1.1.m1.1a">
          <msup id="S3.I3.i3.p1.1.m1.1.1" xref="S3.I3.i3.p1.1.m1.1.1.cmml">
           <mn id="S3.I3.i3.p1.1.m1.1.1.2" xref="S3.I3.i3.p1.1.m1.1.1.2.cmml">
            2
           </mn>
           <mi id="S3.I3.i3.p1.1.m1.1.1.3" xref="S3.I3.i3.p1.1.m1.1.1.3.cmml">
            S
           </mi>
          </msup>
          <annotation-xml encoding="MathML-Content" id="S3.I3.i3.p1.1.m1.1b">
           <apply id="S3.I3.i3.p1.1.m1.1.1.cmml" xref="S3.I3.i3.p1.1.m1.1.1">
            <csymbol cd="ambiguous" id="S3.I3.i3.p1.1.m1.1.1.1.cmml" xref="S3.I3.i3.p1.1.m1.1.1">
             superscript
            </csymbol>
            <cn id="S3.I3.i3.p1.1.m1.1.1.2.cmml" type="integer" xref="S3.I3.i3.p1.1.m1.1.1.2">
             2
            </cn>
            <ci id="S3.I3.i3.p1.1.m1.1.1.3.cmml" xref="S3.I3.i3.p1.1.m1.1.1.3">
             𝑆
            </ci>
           </apply>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="S3.I3.i3.p1.1.m1.1c">
           2^{S}
          </annotation>
         </semantics>
        </math>
        - each service in the environment is either known or unknown.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="S3.I3.i4" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       •
      </span>
      <div class="ltx_para" id="S3.I3.i4.p1">
       <p class="ltx_p" id="S3.I3.i4.p1.1">
        <math alttext="2^{(D*H)}" class="ltx_Math" display="inline" id="S3.I3.i4.p1.1.m1.1">
         <semantics id="S3.I3.i4.p1.1.m1.1a">
          <msup id="S3.I3.i4.p1.1.m1.1.2" xref="S3.I3.i4.p1.1.m1.1.2.cmml">
           <mn id="S3.I3.i4.p1.1.m1.1.2.2" xref="S3.I3.i4.p1.1.m1.1.2.2.cmml">
            2
           </mn>
           <mrow id="S3.I3.i4.p1.1.m1.1.1.1.1" xref="S3.I3.i4.p1.1.m1.1.1.1.1.1.cmml">
            <mo id="S3.I3.i4.p1.1.m1.1.1.1.1.2" stretchy="false" xref="S3.I3.i4.p1.1.m1.1.1.1.1.1.cmml">
             (
            </mo>
            <mrow id="S3.I3.i4.p1.1.m1.1.1.1.1.1" xref="S3.I3.i4.p1.1.m1.1.1.1.1.1.cmml">
             <mi id="S3.I3.i4.p1.1.m1.1.1.1.1.1.2" xref="S3.I3.i4.p1.1.m1.1.1.1.1.1.2.cmml">
              D
             </mi>
             <mo id="S3.I3.i4.p1.1.m1.1.1.1.1.1.1" lspace="0.222em" rspace="0.222em" xref="S3.I3.i4.p1.1.m1.1.1.1.1.1.1.cmml">
              ∗
             </mo>
             <mi id="S3.I3.i4.p1.1.m1.1.1.1.1.1.3" xref="S3.I3.i4.p1.1.m1.1.1.1.1.1.3.cmml">
              H
             </mi>
            </mrow>
            <mo id="S3.I3.i4.p1.1.m1.1.1.1.1.3" stretchy="false" xref="S3.I3.i4.p1.1.m1.1.1.1.1.1.cmml">
             )
            </mo>
           </mrow>
          </msup>
          <annotation-xml encoding="MathML-Content" id="S3.I3.i4.p1.1.m1.1b">
           <apply id="S3.I3.i4.p1.1.m1.1.2.cmml" xref="S3.I3.i4.p1.1.m1.1.2">
            <csymbol cd="ambiguous" id="S3.I3.i4.p1.1.m1.1.2.1.cmml" xref="S3.I3.i4.p1.1.m1.1.2">
             superscript
            </csymbol>
            <cn id="S3.I3.i4.p1.1.m1.1.2.2.cmml" type="integer" xref="S3.I3.i4.p1.1.m1.1.2.2">
             2
            </cn>
            <apply id="S3.I3.i4.p1.1.m1.1.1.1.1.1.cmml" xref="S3.I3.i4.p1.1.m1.1.1.1.1">
             <times id="S3.I3.i4.p1.1.m1.1.1.1.1.1.1.cmml" xref="S3.I3.i4.p1.1.m1.1.1.1.1.1.1">
             </times>
             <ci id="S3.I3.i4.p1.1.m1.1.1.1.1.1.2.cmml" xref="S3.I3.i4.p1.1.m1.1.1.1.1.1.2">
              𝐷
             </ci>
             <ci id="S3.I3.i4.p1.1.m1.1.1.1.1.1.3.cmml" xref="S3.I3.i4.p1.1.m1.1.1.1.1.1.3">
              𝐻
             </ci>
            </apply>
           </apply>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="S3.I3.i4.p1.1.m1.1c">
           2^{(D*H)}
          </annotation>
         </semantics>
        </math>
        - each data point can be present in any host in the environment.
       </p>
      </div>
     </li>
    </ul>
   </div>
  </section>
  <section class="ltx_subsection" id="S3.SS4">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     3.4.
    </span>
    Action Representation
   </h3>
   <div class="ltx_para" id="S3.SS4.p1">
    <p class="ltx_p" id="S3.SS4.p1.1">
     Currently, NetSecGame only supports attacker agents and attacker actions (the defender is not an agent). Actions define the transition between states in the environment. There are five types of basic actions available to the agent, and each of them receives a different set of parameters. The
     <span class="ltx_text ltx_font_italic" id="S3.SS4.p1.1.1">
      ScanNetwork
     </span>
     action receives a
     <span class="ltx_text ltx_font_italic" id="S3.SS4.p1.1.2">
      target network
     </span>
     ;
     <span class="ltx_text ltx_font_italic" id="S3.SS4.p1.1.3">
      FindServices
     </span>
     receives a
     <span class="ltx_text ltx_font_italic" id="S3.SS4.p1.1.4">
      target host
     </span>
     ;
     <span class="ltx_text ltx_font_italic" id="S3.SS4.p1.1.5">
      ExploitService
     </span>
     receives a
     <span class="ltx_text ltx_font_italic" id="S3.SS4.p1.1.6">
      target host
     </span>
     and a
     <span class="ltx_text ltx_font_italic" id="S3.SS4.p1.1.7">
      target service
     </span>
     ;
     <span class="ltx_text ltx_font_italic" id="S3.SS4.p1.1.8">
      FindData
     </span>
     receives a
     <span class="ltx_text ltx_font_italic" id="S3.SS4.p1.1.9">
      target host
     </span>
     ; and
     <span class="ltx_text ltx_font_italic" id="S3.SS4.p1.1.10">
      ExfiltrateData
     </span>
     receives a
     <span class="ltx_text ltx_font_italic" id="S3.SS4.p1.1.11">
      source host
     </span>
     , a
     <span class="ltx_text ltx_font_italic" id="S3.SS4.p1.1.12">
      target host
     </span>
     , and a
     <span class="ltx_text ltx_font_italic" id="S3.SS4.p1.1.13">
      target data
     </span>
     . This makes the action space quite complex since the exact number of unique actions depends on the configuration of the environment. Note that the actions are never sent to the agents in any form. However, in each state of the environment, only certain actions are available, but this is left to the agents to be determined based on the observation of the current state.
    </p>
   </div>
   <div class="ltx_para" id="S3.SS4.p2">
    <p class="ltx_p" id="S3.SS4.p2.1">
     Each basic action has a pre-defined success probability. Such a concept is a simplification of a real world in which packets are lost, there are network issues, tools can be incompatible with services, etc. If an action taken by the agent is valid in that state, then its success is evaluated based on the probability distribution defined in the configuration file. If unsuccessful, the state of the environment does not change which is equal to the self-loop in the state space. Note that the agent
     <span class="ltx_text ltx_font_bold" id="S3.SS4.p2.1.1">
      does not
     </span>
     receive any indication that the action was unsuccessful and that the negative reward for taking a step is given regardless of the success of the action
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S3.SS5">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     3.5.
    </span>
    Reward Function
   </h3>
   <div class="ltx_para" id="S3.SS5.p1">
    <p class="ltx_p" id="S3.SS5.p1.1">
     The reward function in NetSecGame consists of three parts that are not exclusive. First, there is a reward of -1 for taking any step in the environment. Second, the reward for reaching the goal (which results in the termination of the episode) is 100. Last, when the agent is detected by the defender, which also terminates the episode, is awarded with -50. No specific rewards are given for intermediate states.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S3.SS6">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     3.6.
    </span>
    Differences with previous security environments
   </h3>
   <div class="ltx_para" id="S3.SS6.p1">
    <p class="ltx_p" id="S3.SS6.p1.1">
     The main differences between NetSecGame and other environments are based on the concepts based on a real attack situation and the purpose to run the agents in real networks in the future. In particular, the differences are:
    </p>
    <ul class="ltx_itemize" id="S3.I4">
     <li class="ltx_item" id="S3.I4.i1" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       •
      </span>
      <div class="ltx_para" id="S3.I4.i1.p1">
       <p class="ltx_p" id="S3.I4.i1.p1.1">
        The network topology scenarios are real for an SME organization. No more than one router, clients, and servers are separated and there is one connection to the Internet.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="S3.I4.i2" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       •
      </span>
      <div class="ltx_para" id="S3.I4.i2.p1">
       <p class="ltx_p" id="S3.I4.i2.p1.1">
        The parameters for actions are not sent or known to the agent in advance. The basic actions (tools) are known, but the total action space is
        <span class="ltx_text ltx_font_bold" id="S3.I4.i2.p1.1.1">
         not
        </span>
        sent to the agents. This makes NetSecGame not fully compatible with the Gym environment, but it is more real. Other environments sent the agent the precise actions available including which IPs to attack.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="S3.I4.i3" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       •
      </span>
      <div class="ltx_para" id="S3.I4.i3.p1">
       <p class="ltx_p" id="S3.I4.i3.p1.1">
        The goal used in our experiments with NetSecGame is very realistic of an APT-type of attack and it is to exfiltrate data. Other environments have goals like controlling more than half the network, which is not realistic. This is very important because depending on the goal is how the winning rate is computed and reported.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="S3.I4.i4" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       •
      </span>
      <div class="ltx_para" id="S3.I4.i4.p1">
       <p class="ltx_p" id="S3.I4.i4.p1.1">
        NetSecGame has an internal defender that detects, blocks and terminates the game.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="S3.I4.i5" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       •
      </span>
      <div class="ltx_para" id="S3.I4.i5.p1">
       <p class="ltx_p" id="S3.I4.i5.p1.1">
        The decision to terminate the game is in the environment, and not in the agent. Which corresponds with a real attack.
       </p>
      </div>
     </li>
    </ul>
   </div>
  </section>
 </section>
 <section class="ltx_section" id="S4">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    4.
   </span>
   LLM Agents for NetSecGame
  </h2>
  <div class="ltx_para" id="S4.p1">
   <p class="ltx_p" id="S4.p1.2">
    The general idea for using pre-trained LLMs as agents in reinforcement learning environments is that the agent is presented with the current state at time
    <math alttext="s_{t}" class="ltx_Math" display="inline" id="S4.p1.1.m1.1">
     <semantics id="S4.p1.1.m1.1a">
      <msub id="S4.p1.1.m1.1.1" xref="S4.p1.1.m1.1.1.cmml">
       <mi id="S4.p1.1.m1.1.1.2" xref="S4.p1.1.m1.1.1.2.cmml">
        s
       </mi>
       <mi id="S4.p1.1.m1.1.1.3" xref="S4.p1.1.m1.1.1.3.cmml">
        t
       </mi>
      </msub>
      <annotation-xml encoding="MathML-Content" id="S4.p1.1.m1.1b">
       <apply id="S4.p1.1.m1.1.1.cmml" xref="S4.p1.1.m1.1.1">
        <csymbol cd="ambiguous" id="S4.p1.1.m1.1.1.1.cmml" xref="S4.p1.1.m1.1.1">
         subscript
        </csymbol>
        <ci id="S4.p1.1.m1.1.1.2.cmml" xref="S4.p1.1.m1.1.1.2">
         𝑠
        </ci>
        <ci id="S4.p1.1.m1.1.1.3.cmml" xref="S4.p1.1.m1.1.1.3">
         𝑡
        </ci>
       </apply>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S4.p1.1.m1.1c">
       s_{t}
      </annotation>
     </semantics>
    </math>
    , which it parses, and it provides a textual representation to the LLM along with a set of rules and expected actions. The LLM provides the following action
    <math alttext="a_{t}" class="ltx_Math" display="inline" id="S4.p1.2.m2.1">
     <semantics id="S4.p1.2.m2.1a">
      <msub id="S4.p1.2.m2.1.1" xref="S4.p1.2.m2.1.1.cmml">
       <mi id="S4.p1.2.m2.1.1.2" xref="S4.p1.2.m2.1.1.2.cmml">
        a
       </mi>
       <mi id="S4.p1.2.m2.1.1.3" xref="S4.p1.2.m2.1.1.3.cmml">
        t
       </mi>
      </msub>
      <annotation-xml encoding="MathML-Content" id="S4.p1.2.m2.1b">
       <apply id="S4.p1.2.m2.1.1.cmml" xref="S4.p1.2.m2.1.1">
        <csymbol cd="ambiguous" id="S4.p1.2.m2.1.1.1.cmml" xref="S4.p1.2.m2.1.1">
         subscript
        </csymbol>
        <ci id="S4.p1.2.m2.1.1.2.cmml" xref="S4.p1.2.m2.1.1.2">
         𝑎
        </ci>
        <ci id="S4.p1.2.m2.1.1.3.cmml" xref="S4.p1.2.m2.1.1.3">
         𝑡
        </ci>
       </apply>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S4.p1.2.m2.1c">
       a_{t}
      </annotation>
     </semantics>
    </math>
    , which is parsed and sent to the environment, which in turn sends the next state and the respective reward. The assumption is that pre-trained LLMs incorporate some knowledge about network security activities and penetration testing. Therefore there is no need to incorporate additional in-context learning beyond the instructions and rules of the specific environment. It also has to be noted that the LLM agents used in this work do not learn from one episode to the next.
   </p>
  </div>
  <section class="ltx_subsection" id="S4.SS1">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     4.1.
    </span>
    Single-Prompt Agents
   </h3>
   <div class="ltx_para" id="S4.SS1.p1">
    <p class="ltx_p" id="S4.SS1.p1.1">
     These agents have a single prompt, no question-answers, and a simple memory. The initial prompt designed for NetSecGame has multiple elements:
    </p>
    <ol class="ltx_enumerate" id="S4.I1">
     <li class="ltx_item" id="S4.I1.i1" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       (1)
      </span>
      <div class="ltx_para" id="S4.I1.i1.p1">
       <p class="ltx_p" id="S4.I1.i1.p1.1">
        Initial system
        <span class="ltx_text ltx_font_bold" id="S4.I1.i1.p1.1.1">
         instructions
        </span>
        and
        <span class="ltx_text ltx_font_bold" id="S4.I1.i1.p1.1.2">
         rules
        </span>
        of the game.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="S4.I1.i2" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       (2)
      </span>
      <div class="ltx_para" id="S4.I1.i2.p1">
       <p class="ltx_p" id="S4.I1.i2.p1.1">
        A list of the last
        <math alttext="k" class="ltx_Math" display="inline" id="S4.I1.i2.p1.1.m1.1">
         <semantics id="S4.I1.i2.p1.1.m1.1a">
          <mi id="S4.I1.i2.p1.1.m1.1.1" xref="S4.I1.i2.p1.1.m1.1.1.cmml">
           k
          </mi>
          <annotation-xml encoding="MathML-Content" id="S4.I1.i2.p1.1.m1.1b">
           <ci id="S4.I1.i2.p1.1.m1.1.1.cmml" xref="S4.I1.i2.p1.1.m1.1.1">
            𝑘
           </ci>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="S4.I1.i2.p1.1.m1.1c">
           k
          </annotation>
         </semantics>
        </math>
        actions (
        <span class="ltx_text ltx_font_bold" id="S4.I1.i2.p1.1.1">
         memory
        </span>
        ).
       </p>
      </div>
     </li>
     <li class="ltx_item" id="S4.I1.i3" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       (3)
      </span>
      <div class="ltx_para" id="S4.I1.i3.p1">
       <p class="ltx_p" id="S4.I1.i3.p1.1">
        A textual representation of the current
        <span class="ltx_text ltx_font_bold" id="S4.I1.i3.p1.1.1">
         state
        </span>
        <math alttext="s_{t}" class="ltx_Math" display="inline" id="S4.I1.i3.p1.1.m1.1">
         <semantics id="S4.I1.i3.p1.1.m1.1a">
          <msub id="S4.I1.i3.p1.1.m1.1.1" xref="S4.I1.i3.p1.1.m1.1.1.cmml">
           <mi id="S4.I1.i3.p1.1.m1.1.1.2" xref="S4.I1.i3.p1.1.m1.1.1.2.cmml">
            s
           </mi>
           <mi id="S4.I1.i3.p1.1.m1.1.1.3" xref="S4.I1.i3.p1.1.m1.1.1.3.cmml">
            t
           </mi>
          </msub>
          <annotation-xml encoding="MathML-Content" id="S4.I1.i3.p1.1.m1.1b">
           <apply id="S4.I1.i3.p1.1.m1.1.1.cmml" xref="S4.I1.i3.p1.1.m1.1.1">
            <csymbol cd="ambiguous" id="S4.I1.i3.p1.1.m1.1.1.1.cmml" xref="S4.I1.i3.p1.1.m1.1.1">
             subscript
            </csymbol>
            <ci id="S4.I1.i3.p1.1.m1.1.1.2.cmml" xref="S4.I1.i3.p1.1.m1.1.1.2">
             𝑠
            </ci>
            <ci id="S4.I1.i3.p1.1.m1.1.1.3.cmml" xref="S4.I1.i3.p1.1.m1.1.1.3">
             𝑡
            </ci>
           </apply>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="S4.I1.i3.p1.1.m1.1c">
           s_{t}
          </annotation>
         </semantics>
        </math>
        .
       </p>
      </div>
     </li>
     <li class="ltx_item" id="S4.I1.i4" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       (4)
      </span>
      <div class="ltx_para" id="S4.I1.i4.p1">
       <p class="ltx_p" id="S4.I1.i4.p1.1">
        An
        <span class="ltx_text ltx_font_bold" id="S4.I1.i4.p1.1.1">
         example
        </span>
        of each valid action with expected parameters.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="S4.I1.i5" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       (5)
      </span>
      <div class="ltx_para" id="S4.I1.i5.p1">
       <p class="ltx_p" id="S4.I1.i5.p1.1">
        A
        <span class="ltx_text ltx_font_bold" id="S4.I1.i5.p1.1.1">
         query
        </span>
        asking to select the best possible action.
       </p>
      </div>
     </li>
    </ol>
   </div>
   <div class="ltx_para" id="S4.SS1.p2">
    <p class="ltx_p" id="S4.SS1.p2.1">
     During our initial design phase, it became apparent that some LLMs tend to repeat actions, so the memory component was added. For the LLM to provide a well-formatted response that made it easier to parse, validate, and eventually execute in the environment, we included a ”one-shot” example for each of the five available actions.
    </p>
   </div>
   <section class="ltx_subsubsection" id="S4.SS1.SSS1">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      4.1.1.
     </span>
     <span class="ltx_text ltx_font_italic" id="S4.SS1.SSS1.1.1">
      Temperature
     </span>
     Variant
    </h4>
    <div class="ltx_para" id="S4.SS1.SSS1.p1">
     <p class="ltx_p" id="S4.SS1.SSS1.p1.1">
      The
      <span class="ltx_text ltx_font_italic" id="S4.SS1.SSS1.p1.1.1">
       temperature
      </span>
      variant of the single-prompt agent implements three different memory strategies focused on avoiding action repetitions. First, the agent has a list of the last
      <math alttext="k" class="ltx_Math" display="inline" id="S4.SS1.SSS1.p1.1.m1.1">
       <semantics id="S4.SS1.SSS1.p1.1.m1.1a">
        <mi id="S4.SS1.SSS1.p1.1.m1.1.1" xref="S4.SS1.SSS1.p1.1.m1.1.1.cmml">
         k
        </mi>
        <annotation-xml encoding="MathML-Content" id="S4.SS1.SSS1.p1.1.m1.1b">
         <ci id="S4.SS1.SSS1.p1.1.m1.1.1.cmml" xref="S4.SS1.SSS1.p1.1.m1.1.1">
          𝑘
         </ci>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S4.SS1.SSS1.p1.1.m1.1c">
         k
        </annotation>
       </semantics>
      </math>
      non-repeated actions taken in the past (
      <span class="ltx_text ltx_font_italic" id="S4.SS1.SSS1.p1.1.2">
       memory-a
      </span>
      ). The temperature variant also keeps a separate list of the repeated actions (
      <span class="ltx_text ltx_font_italic" id="S4.SS1.SSS1.p1.1.3">
       memory-b
      </span>
      ). The list of repeated actions includes the number of times each action has been taken. Finally, the action taken in the previous step is also informed separately in the prompt (
      <span class="ltx_text ltx_font_italic" id="S4.SS1.SSS1.p1.1.4">
       memory-c
      </span>
      ).
     </p>
    </div>
    <div class="ltx_para" id="S4.SS1.SSS1.p2">
     <p class="ltx_p" id="S4.SS1.SSS1.p2.1">
      The prompt for the temperature variant includes the following elements:
     </p>
     <ol class="ltx_enumerate" id="S4.I2">
      <li class="ltx_item" id="S4.I2.i1" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        (1)
       </span>
       <div class="ltx_para" id="S4.I2.i1.p1">
        <p class="ltx_p" id="S4.I2.i1.p1.1">
         Initial system
         <span class="ltx_text ltx_font_bold" id="S4.I2.i1.p1.1.1">
          instructions
         </span>
         and
         <span class="ltx_text ltx_font_bold" id="S4.I2.i1.p1.1.2">
          rules
         </span>
         of the game.
        </p>
       </div>
      </li>
      <li class="ltx_item" id="S4.I2.i2" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        (2)
       </span>
       <div class="ltx_para" id="S4.I2.i2.p1">
        <p class="ltx_p" id="S4.I2.i2.p1.1">
         A list of the last
         <math alttext="k" class="ltx_Math" display="inline" id="S4.I2.i2.p1.1.m1.1">
          <semantics id="S4.I2.i2.p1.1.m1.1a">
           <mi id="S4.I2.i2.p1.1.m1.1.1" xref="S4.I2.i2.p1.1.m1.1.1.cmml">
            k
           </mi>
           <annotation-xml encoding="MathML-Content" id="S4.I2.i2.p1.1.m1.1b">
            <ci id="S4.I2.i2.p1.1.m1.1.1.cmml" xref="S4.I2.i2.p1.1.m1.1.1">
             𝑘
            </ci>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="S4.I2.i2.p1.1.m1.1c">
            k
           </annotation>
          </semantics>
         </math>
         <span class="ltx_text ltx_font_bold" id="S4.I2.i2.p1.1.1">
          non-repeated actions
         </span>
         (
         <span class="ltx_text ltx_font_bold" id="S4.I2.i2.p1.1.2">
          memory-a
         </span>
         ).
        </p>
       </div>
      </li>
      <li class="ltx_item" id="S4.I2.i3" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        (3)
       </span>
       <div class="ltx_para" id="S4.I2.i3.p1">
        <p class="ltx_p" id="S4.I2.i3.p1.1">
         A list of the
         <span class="ltx_text ltx_font_bold" id="S4.I2.i3.p1.1.1">
          repeated actions
         </span>
         (
         <span class="ltx_text ltx_font_bold" id="S4.I2.i3.p1.1.2">
          memory-b
         </span>
         ).
        </p>
       </div>
      </li>
      <li class="ltx_item" id="S4.I2.i4" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        (4)
       </span>
       <div class="ltx_para" id="S4.I2.i4.p1">
        <p class="ltx_p" id="S4.I2.i4.p1.1">
         A textual representation of the current
         <span class="ltx_text ltx_font_bold" id="S4.I2.i4.p1.1.1">
          state
         </span>
         <math alttext="s_{t}" class="ltx_Math" display="inline" id="S4.I2.i4.p1.1.m1.1">
          <semantics id="S4.I2.i4.p1.1.m1.1a">
           <msub id="S4.I2.i4.p1.1.m1.1.1" xref="S4.I2.i4.p1.1.m1.1.1.cmml">
            <mi id="S4.I2.i4.p1.1.m1.1.1.2" xref="S4.I2.i4.p1.1.m1.1.1.2.cmml">
             s
            </mi>
            <mi id="S4.I2.i4.p1.1.m1.1.1.3" xref="S4.I2.i4.p1.1.m1.1.1.3.cmml">
             t
            </mi>
           </msub>
           <annotation-xml encoding="MathML-Content" id="S4.I2.i4.p1.1.m1.1b">
            <apply id="S4.I2.i4.p1.1.m1.1.1.cmml" xref="S4.I2.i4.p1.1.m1.1.1">
             <csymbol cd="ambiguous" id="S4.I2.i4.p1.1.m1.1.1.1.cmml" xref="S4.I2.i4.p1.1.m1.1.1">
              subscript
             </csymbol>
             <ci id="S4.I2.i4.p1.1.m1.1.1.2.cmml" xref="S4.I2.i4.p1.1.m1.1.1.2">
              𝑠
             </ci>
             <ci id="S4.I2.i4.p1.1.m1.1.1.3.cmml" xref="S4.I2.i4.p1.1.m1.1.1.3">
              𝑡
             </ci>
            </apply>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="S4.I2.i4.p1.1.m1.1c">
            s_{t}
           </annotation>
          </semantics>
         </math>
        </p>
       </div>
      </li>
      <li class="ltx_item" id="S4.I2.i5" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        (5)
       </span>
       <div class="ltx_para" id="S4.I2.i5.p1">
        <p class="ltx_p" id="S4.I2.i5.p1.1">
         An
         <span class="ltx_text ltx_font_bold" id="S4.I2.i5.p1.1.1">
          example
         </span>
         of each valid action with expected parameters.
        </p>
       </div>
      </li>
      <li class="ltx_item" id="S4.I2.i6" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        (6)
       </span>
       <div class="ltx_para" id="S4.I2.i6.p1">
        <p class="ltx_p" id="S4.I2.i6.p1.1">
         An
         <span class="ltx_text ltx_font_bold" id="S4.I2.i6.p1.1.1">
          last action
         </span>
         taken by the agent (
         <span class="ltx_text ltx_font_bold" id="S4.I2.i6.p1.1.2">
          memory-c
         </span>
         ).
        </p>
       </div>
      </li>
      <li class="ltx_item" id="S4.I2.i7" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        (7)
       </span>
       <div class="ltx_para" id="S4.I2.i7.p1">
        <p class="ltx_p" id="S4.I2.i7.p1.1">
         <span class="ltx_text ltx_font_bold" id="S4.I2.i7.p1.1.1">
          query
         </span>
         to select the best possible action.
        </p>
       </div>
      </li>
     </ol>
    </div>
    <div class="ltx_para" id="S4.SS1.SSS1.p3">
     <p class="ltx_p" id="S4.SS1.SSS1.p3.1">
      For some pre-trained LLMs, the memory strategy is not enough to avoid the tendency to repeat actions. A straightforward approach consists of changing the temperature parameter of the LLM according to the number of repeated actions in the last
      <math alttext="k" class="ltx_Math" display="inline" id="S4.SS1.SSS1.p3.1.m1.1">
       <semantics id="S4.SS1.SSS1.p3.1.m1.1a">
        <mi id="S4.SS1.SSS1.p3.1.m1.1.1" xref="S4.SS1.SSS1.p3.1.m1.1.1.cmml">
         k
        </mi>
        <annotation-xml encoding="MathML-Content" id="S4.SS1.SSS1.p3.1.m1.1b">
         <ci id="S4.SS1.SSS1.p3.1.m1.1.1.cmml" xref="S4.SS1.SSS1.p3.1.m1.1.1">
          𝑘
         </ci>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S4.SS1.SSS1.p3.1.m1.1c">
         k
        </annotation>
       </semantics>
      </math>
      actions taken by the agent. Changing the temperature parameter forces the LLM to only sometimes consider the most probable tokens. This can generate more diverse or creative outputs.
     </p>
    </div>
   </section>
  </section>
  <section class="ltx_subsection" id="S4.SS2">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     4.2.
    </span>
    ReAct Agent
   </h3>
   <figure class="ltx_figure" id="S4.F1">
    <div class="ltx_flex_figure">
     <div class="ltx_flex_cell ltx_flex_size_2">
      <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_square" height="535" id="S4.F1.g1" src="/html/2308.12086/assets/figures/react_agent.png" width="568"/>
     </div>
    </div>
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_figure">
      <span class="ltx_text" id="S4.F1.2.1.1" style="font-size:90%;">
       Figure 1
      </span>
      .
     </span>
     <span class="ltx_text" id="S4.F1.3.2" style="font-size:90%;">
      The ReAct agent prompt structure and workflow.
     </span>
    </figcaption>
    <div class="ltx_flex_figure">
     <div class="ltx_flex_cell ltx_flex_size_1">
      <span class="ltx_ERROR ltx_centering ltx_figure_panel undefined" id="S4.F1.4">
       \Description
      </span>
     </div>
     <div class="ltx_flex_break">
     </div>
     <div class="ltx_flex_cell ltx_flex_size_1">
      <p class="ltx_p ltx_figure_panel ltx_align_center" id="S4.F1.5">
       Components of the two prompts and the steps required to construct them.
      </p>
     </div>
    </div>
   </figure>
   <div class="ltx_para" id="S4.SS2.p1">
    <p class="ltx_p" id="S4.SS2.p1.1">
     The ReAct agent design is used in the scenarios related to the NetSecGame environment. The agent follows a two-stage approach similar to the ReAct framework
     <cite class="ltx_cite ltx_citemacro_citep">
      (Yao et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib41" title="">
       2023
      </a>
      )
     </cite>
     . In the first stage, the agent asks the LLM to reason about the current state of the environment. The LLM is asked to select the best possible action in the second stage. Figure
     <a class="ltx_ref" href="#S4.F1" title="Figure 1 ‣ 4.2. ReAct Agent ‣ 4. LLM Agents for NetSecGame ‣ Out of the Cage: How Stochastic Parrots Win in Cyber Security Environments">
      <span class="ltx_text ltx_ref_tag">
       1
      </span>
     </a>
     shows the different components of the prompts and the complete workflow of the agent. The first stage prompt comprises three parts:
    </p>
    <ol class="ltx_enumerate" id="S4.I3">
     <li class="ltx_item" id="S4.I3.i1" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       (1)
      </span>
      <div class="ltx_para" id="S4.I3.i1.p1">
       <p class="ltx_p" id="S4.I3.i1.p1.1">
        <span class="ltx_text ltx_font_bold" id="S4.I3.i1.p1.1.1">
         Instructions
        </span>
        and rules about the environment.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="S4.I3.i2" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       (2)
      </span>
      <div class="ltx_para" id="S4.I3.i2.p1">
       <p class="ltx_p" id="S4.I3.i2.p1.1">
        A textual representation of the current
        <span class="ltx_text ltx_font_bold" id="S4.I3.i2.p1.1.1">
         state
        </span>
        <math alttext="s_{t}" class="ltx_Math" display="inline" id="S4.I3.i2.p1.1.m1.1">
         <semantics id="S4.I3.i2.p1.1.m1.1a">
          <msub id="S4.I3.i2.p1.1.m1.1.1" xref="S4.I3.i2.p1.1.m1.1.1.cmml">
           <mi id="S4.I3.i2.p1.1.m1.1.1.2" xref="S4.I3.i2.p1.1.m1.1.1.2.cmml">
            s
           </mi>
           <mi id="S4.I3.i2.p1.1.m1.1.1.3" xref="S4.I3.i2.p1.1.m1.1.1.3.cmml">
            t
           </mi>
          </msub>
          <annotation-xml encoding="MathML-Content" id="S4.I3.i2.p1.1.m1.1b">
           <apply id="S4.I3.i2.p1.1.m1.1.1.cmml" xref="S4.I3.i2.p1.1.m1.1.1">
            <csymbol cd="ambiguous" id="S4.I3.i2.p1.1.m1.1.1.1.cmml" xref="S4.I3.i2.p1.1.m1.1.1">
             subscript
            </csymbol>
            <ci id="S4.I3.i2.p1.1.m1.1.1.2.cmml" xref="S4.I3.i2.p1.1.m1.1.1.2">
             𝑠
            </ci>
            <ci id="S4.I3.i2.p1.1.m1.1.1.3.cmml" xref="S4.I3.i2.p1.1.m1.1.1.3">
             𝑡
            </ci>
           </apply>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="S4.I3.i2.p1.1.m1.1c">
           s_{t}
          </annotation>
         </semantics>
        </math>
        .
       </p>
      </div>
     </li>
     <li class="ltx_item" id="S4.I3.i3" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       (3)
      </span>
      <div class="ltx_para" id="S4.I3.i3.p1">
       <p class="ltx_p" id="S4.I3.i3.p1.1">
        A query to evaluate the status and the possible actions (
        <span class="ltx_text ltx_font_bold" id="S4.I3.i3.p1.1.1">
         Q1 prompt
        </span>
        ):
       </p>
      </div>
     </li>
    </ol>
   </div>
   <div class="ltx_para ltx_noindent" id="S4.SS2.p2">
    <svg class="ltx_picture" height="38.63" id="S4.SS2.p2.pic1" overflow="visible" version="1.1" width="600">
     <g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,38.63) matrix(1 0 0 -1 0 0)">
      <g fill="#00BF00" fill-opacity="1.0">
       <path d="M 0 5.91 L 0 32.72 C 0 35.98 2.64 38.63 5.91 38.63 L 594.09 38.63 C 597.36 38.63 600 35.98 600 32.72 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none">
       </path>
      </g>
      <g fill="#F2FFF2" fill-opacity="1.0">
       <path d="M 1.97 5.91 L 1.97 32.72 C 1.97 34.9 3.73 36.66 5.91 36.66 L 594.09 36.66 C 596.27 36.66 598.03 34.9 598.03 32.72 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none">
       </path>
      </g>
      <g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)">
       <foreignobject class="ltx_minipage" color="#000000" height="11.07" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="402.3pt">
        <pre class="ltx_verbatim ltx_font_typewriter" id="S4.SS2.p2.pic1.1.1.1.1.1" style="font-size:90%;">
List the objects in the current status and the actions
they can be used. Be specific.
</pre>
       </foreignobject>
      </g>
     </g>
    </svg>
   </div>
   <div class="ltx_para" id="S4.SS2.p3">
    <p class="ltx_p" id="S4.SS2.p3.1">
     The second stage prompt has the following components:
    </p>
    <ol class="ltx_enumerate" id="S4.I4">
     <li class="ltx_item" id="S4.I4.i1" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       (1)
      </span>
      <div class="ltx_para" id="S4.I4.i1.p1">
       <p class="ltx_p" id="S4.I4.i1.p1.1">
        <span class="ltx_text ltx_font_bold" id="S4.I4.i1.p1.1.1">
         Instructions
        </span>
        and rules about the environment.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="S4.I4.i2" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       (2)
      </span>
      <div class="ltx_para" id="S4.I4.i2.p1">
       <p class="ltx_p" id="S4.I4.i2.p1.1">
        A textual representation of the current
        <span class="ltx_text ltx_font_bold" id="S4.I4.i2.p1.1.1">
         state
        </span>
        <math alttext="s_{t}" class="ltx_Math" display="inline" id="S4.I4.i2.p1.1.m1.1">
         <semantics id="S4.I4.i2.p1.1.m1.1a">
          <msub id="S4.I4.i2.p1.1.m1.1.1" xref="S4.I4.i2.p1.1.m1.1.1.cmml">
           <mi id="S4.I4.i2.p1.1.m1.1.1.2" xref="S4.I4.i2.p1.1.m1.1.1.2.cmml">
            s
           </mi>
           <mi id="S4.I4.i2.p1.1.m1.1.1.3" xref="S4.I4.i2.p1.1.m1.1.1.3.cmml">
            t
           </mi>
          </msub>
          <annotation-xml encoding="MathML-Content" id="S4.I4.i2.p1.1.m1.1b">
           <apply id="S4.I4.i2.p1.1.m1.1.1.cmml" xref="S4.I4.i2.p1.1.m1.1.1">
            <csymbol cd="ambiguous" id="S4.I4.i2.p1.1.m1.1.1.1.cmml" xref="S4.I4.i2.p1.1.m1.1.1">
             subscript
            </csymbol>
            <ci id="S4.I4.i2.p1.1.m1.1.1.2.cmml" xref="S4.I4.i2.p1.1.m1.1.1.2">
             𝑠
            </ci>
            <ci id="S4.I4.i2.p1.1.m1.1.1.3.cmml" xref="S4.I4.i2.p1.1.m1.1.1.3">
             𝑡
            </ci>
           </apply>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="S4.I4.i2.p1.1.m1.1c">
           s_{t}
          </annotation>
         </semantics>
        </math>
        .
       </p>
      </div>
     </li>
     <li class="ltx_item" id="S4.I4.i3" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       (3)
      </span>
      <div class="ltx_para" id="S4.I4.i3.p1">
       <p class="ltx_p" id="S4.I4.i3.p1.1">
        One
        <span class="ltx_text ltx_font_bold" id="S4.I4.i3.p1.1.1">
         example
        </span>
        for each possible action in JSON format.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="S4.I4.i4" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       (4)
      </span>
      <div class="ltx_para" id="S4.I4.i4.p1">
       <p class="ltx_p" id="S4.I4.i4.p1.1">
        The
        <span class="ltx_text ltx_font_bold" id="S4.I4.i4.p1.1.1">
         response
        </span>
        to the first stage prompt.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="S4.I4.i5" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       (5)
      </span>
      <div class="ltx_para" id="S4.I4.i5.p1">
       <p class="ltx_p" id="S4.I4.i5.p1.1">
        A list of the last
        <math alttext="k" class="ltx_Math" display="inline" id="S4.I4.i5.p1.1.m1.1">
         <semantics id="S4.I4.i5.p1.1.m1.1a">
          <mi id="S4.I4.i5.p1.1.m1.1.1" xref="S4.I4.i5.p1.1.m1.1.1.cmml">
           k
          </mi>
          <annotation-xml encoding="MathML-Content" id="S4.I4.i5.p1.1.m1.1b">
           <ci id="S4.I4.i5.p1.1.m1.1.1.cmml" xref="S4.I4.i5.p1.1.m1.1.1">
            𝑘
           </ci>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="S4.I4.i5.p1.1.m1.1c">
           k
          </annotation>
         </semantics>
        </math>
        actions (
        <span class="ltx_text ltx_font_bold" id="S4.I4.i5.p1.1.1">
         memory
        </span>
        )
       </p>
      </div>
     </li>
     <li class="ltx_item" id="S4.I4.i6" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       (6)
      </span>
      <div class="ltx_para" id="S4.I4.i6.p1">
       <p class="ltx_p" id="S4.I4.i6.p1.1">
        A query to select the best possible action (
        <span class="ltx_text ltx_font_bold" id="S4.I4.i6.p1.1.1">
         Q2 prompt
        </span>
        ):
       </p>
      </div>
     </li>
    </ol>
   </div>
   <div class="ltx_para ltx_noindent" id="S4.SS2.p4">
    <svg class="ltx_picture" height="38.63" id="S4.SS2.p4.pic1" overflow="visible" version="1.1" width="600">
     <g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,38.63) matrix(1 0 0 -1 0 0)">
      <g fill="#00BF00" fill-opacity="1.0">
       <path d="M 0 5.91 L 0 32.72 C 0 35.98 2.64 38.63 5.91 38.63 L 594.09 38.63 C 597.36 38.63 600 35.98 600 32.72 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none">
       </path>
      </g>
      <g fill="#F2FFF2" fill-opacity="1.0">
       <path d="M 1.97 5.91 L 1.97 32.72 C 1.97 34.9 3.73 36.66 5.91 36.66 L 594.09 36.66 C 596.27 36.66 598.03 34.9 598.03 32.72 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none">
       </path>
      </g>
      <g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)">
       <foreignobject class="ltx_minipage" color="#000000" height="11.07" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="402.3pt">
        <pre class="ltx_verbatim ltx_font_typewriter" id="S4.SS2.p4.pic1.1.1.1.1.1" style="font-size:90%;">
Provide the best action and its parameters in the correct
JSON format. Action:
</pre>
       </foreignobject>
      </g>
     </g>
    </svg>
   </div>
   <div class="ltx_para" id="S4.SS2.p5">
    <p class="ltx_p" id="S4.SS2.p5.3">
     The response is processed, and if the proposed action
     <math alttext="a_{t}" class="ltx_Math" display="inline" id="S4.SS2.p5.1.m1.1">
      <semantics id="S4.SS2.p5.1.m1.1a">
       <msub id="S4.SS2.p5.1.m1.1.1" xref="S4.SS2.p5.1.m1.1.1.cmml">
        <mi id="S4.SS2.p5.1.m1.1.1.2" xref="S4.SS2.p5.1.m1.1.1.2.cmml">
         a
        </mi>
        <mi id="S4.SS2.p5.1.m1.1.1.3" xref="S4.SS2.p5.1.m1.1.1.3.cmml">
         t
        </mi>
       </msub>
       <annotation-xml encoding="MathML-Content" id="S4.SS2.p5.1.m1.1b">
        <apply id="S4.SS2.p5.1.m1.1.1.cmml" xref="S4.SS2.p5.1.m1.1.1">
         <csymbol cd="ambiguous" id="S4.SS2.p5.1.m1.1.1.1.cmml" xref="S4.SS2.p5.1.m1.1.1">
          subscript
         </csymbol>
         <ci id="S4.SS2.p5.1.m1.1.1.2.cmml" xref="S4.SS2.p5.1.m1.1.1.2">
          𝑎
         </ci>
         <ci id="S4.SS2.p5.1.m1.1.1.3.cmml" xref="S4.SS2.p5.1.m1.1.1.3">
          𝑡
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S4.SS2.p5.1.m1.1c">
        a_{t}
       </annotation>
      </semantics>
     </math>
     is valid, it is sent to the environment. The action and its validity are also stored in the memory, along with an indication of usefulness. Since the environment offers only sparse rewards (-1 for each step where the goal is not reached and 100 if the goal is reached), the agent labels an action as useful if the new state
     <math alttext="s_{t+1}" class="ltx_Math" display="inline" id="S4.SS2.p5.2.m2.1">
      <semantics id="S4.SS2.p5.2.m2.1a">
       <msub id="S4.SS2.p5.2.m2.1.1" xref="S4.SS2.p5.2.m2.1.1.cmml">
        <mi id="S4.SS2.p5.2.m2.1.1.2" xref="S4.SS2.p5.2.m2.1.1.2.cmml">
         s
        </mi>
        <mrow id="S4.SS2.p5.2.m2.1.1.3" xref="S4.SS2.p5.2.m2.1.1.3.cmml">
         <mi id="S4.SS2.p5.2.m2.1.1.3.2" xref="S4.SS2.p5.2.m2.1.1.3.2.cmml">
          t
         </mi>
         <mo id="S4.SS2.p5.2.m2.1.1.3.1" xref="S4.SS2.p5.2.m2.1.1.3.1.cmml">
          +
         </mo>
         <mn id="S4.SS2.p5.2.m2.1.1.3.3" xref="S4.SS2.p5.2.m2.1.1.3.3.cmml">
          1
         </mn>
        </mrow>
       </msub>
       <annotation-xml encoding="MathML-Content" id="S4.SS2.p5.2.m2.1b">
        <apply id="S4.SS2.p5.2.m2.1.1.cmml" xref="S4.SS2.p5.2.m2.1.1">
         <csymbol cd="ambiguous" id="S4.SS2.p5.2.m2.1.1.1.cmml" xref="S4.SS2.p5.2.m2.1.1">
          subscript
         </csymbol>
         <ci id="S4.SS2.p5.2.m2.1.1.2.cmml" xref="S4.SS2.p5.2.m2.1.1.2">
          𝑠
         </ci>
         <apply id="S4.SS2.p5.2.m2.1.1.3.cmml" xref="S4.SS2.p5.2.m2.1.1.3">
          <plus id="S4.SS2.p5.2.m2.1.1.3.1.cmml" xref="S4.SS2.p5.2.m2.1.1.3.1">
          </plus>
          <ci id="S4.SS2.p5.2.m2.1.1.3.2.cmml" xref="S4.SS2.p5.2.m2.1.1.3.2">
           𝑡
          </ci>
          <cn id="S4.SS2.p5.2.m2.1.1.3.3.cmml" type="integer" xref="S4.SS2.p5.2.m2.1.1.3.3">
           1
          </cn>
         </apply>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S4.SS2.p5.2.m2.1c">
        s_{t+1}
       </annotation>
      </semantics>
     </math>
     of the environment differs from the previous state. This can be viewed as a form of
     <span class="ltx_text ltx_font_italic" id="S4.SS2.p5.3.1">
      intrinsic
     </span>
     reward since the agent produces it. The new state
     <math alttext="s_{t+1}" class="ltx_Math" display="inline" id="S4.SS2.p5.3.m3.1">
      <semantics id="S4.SS2.p5.3.m3.1a">
       <msub id="S4.SS2.p5.3.m3.1.1" xref="S4.SS2.p5.3.m3.1.1.cmml">
        <mi id="S4.SS2.p5.3.m3.1.1.2" xref="S4.SS2.p5.3.m3.1.1.2.cmml">
         s
        </mi>
        <mrow id="S4.SS2.p5.3.m3.1.1.3" xref="S4.SS2.p5.3.m3.1.1.3.cmml">
         <mi id="S4.SS2.p5.3.m3.1.1.3.2" xref="S4.SS2.p5.3.m3.1.1.3.2.cmml">
          t
         </mi>
         <mo id="S4.SS2.p5.3.m3.1.1.3.1" xref="S4.SS2.p5.3.m3.1.1.3.1.cmml">
          +
         </mo>
         <mn id="S4.SS2.p5.3.m3.1.1.3.3" xref="S4.SS2.p5.3.m3.1.1.3.3.cmml">
          1
         </mn>
        </mrow>
       </msub>
       <annotation-xml encoding="MathML-Content" id="S4.SS2.p5.3.m3.1b">
        <apply id="S4.SS2.p5.3.m3.1.1.cmml" xref="S4.SS2.p5.3.m3.1.1">
         <csymbol cd="ambiguous" id="S4.SS2.p5.3.m3.1.1.1.cmml" xref="S4.SS2.p5.3.m3.1.1">
          subscript
         </csymbol>
         <ci id="S4.SS2.p5.3.m3.1.1.2.cmml" xref="S4.SS2.p5.3.m3.1.1.2">
          𝑠
         </ci>
         <apply id="S4.SS2.p5.3.m3.1.1.3.cmml" xref="S4.SS2.p5.3.m3.1.1.3">
          <plus id="S4.SS2.p5.3.m3.1.1.3.1.cmml" xref="S4.SS2.p5.3.m3.1.1.3.1">
          </plus>
          <ci id="S4.SS2.p5.3.m3.1.1.3.2.cmml" xref="S4.SS2.p5.3.m3.1.1.3.2">
           𝑡
          </ci>
          <cn id="S4.SS2.p5.3.m3.1.1.3.3.cmml" type="integer" xref="S4.SS2.p5.3.m3.1.1.3.3">
           1
          </cn>
         </apply>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S4.SS2.p5.3.m3.1c">
        s_{t+1}
       </annotation>
      </semantics>
     </math>
     is used in constructing the prompts for the next step of the episode. The process continues until either the goal state is reached, the maximum steps of the environment are reached, or the agent is detected (in the case of the defender-based scenarios.)
Examples of the full prompts are presented in Appendix
     <a class="ltx_ref" href="#A1.SS2" title="A.2. ReAct Agent ‣ Appendix A Detailed Prompts ‣ Out of the Cage: How Stochastic Parrots Win in Cyber Security Environments">
      <span class="ltx_text ltx_ref_tag">
       A.2
      </span>
     </a>
     .
    </p>
   </div>
  </section>
 </section>
 <section class="ltx_section" id="S5">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    5.
   </span>
   LLM Agent for CyberBattleSim
  </h2>
  <div class="ltx_para" id="S5.p1">
   <p class="ltx_p" id="S5.p1.1">
    The design of the LLM agent for the CyberBattleSim environment follows a single-prompt approach, similar to that described in Section
    <a class="ltx_ref" href="#S4.SS1" title="4.1. Single-Prompt Agents ‣ 4. LLM Agents for NetSecGame ‣ Out of the Cage: How Stochastic Parrots Win in Cyber Security Environments">
     <span class="ltx_text ltx_ref_tag">
      4.1
     </span>
    </a>
    with a few changes in the order of the prompt components. The chain scenario has a different goal and action space. Therefore the agent required different initial instructions and rules. During the initial experiments, we noticed that sometimes the agent would discover all nodes apart from the last one, then declare victory and refuse to search further. In order to bypass this, we decided to trick the LLM into believing that there are more than 20 hosts in the network and this change in the prompt was sufficient to bypass this issue:
   </p>
  </div>
  <div class="ltx_para ltx_noindent" id="S5.p2">
   <svg class="ltx_picture" height="55.23" id="S5.p2.pic1" overflow="visible" version="1.1" width="600">
    <g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,55.23) matrix(1 0 0 -1 0 0)">
     <g fill="#00BF00" fill-opacity="1.0">
      <path d="M 0 5.91 L 0 49.33 C 0 52.59 2.64 55.23 5.91 55.23 L 594.09 55.23 C 597.36 55.23 600 52.59 600 49.33 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none">
      </path>
     </g>
     <g fill="#F2FFF2" fill-opacity="1.0">
      <path d="M 1.97 5.91 L 1.97 49.33 C 1.97 51.5 3.73 53.26 5.91 53.26 L 594.09 53.26 C 596.27 53.26 598.03 51.5 598.03 49.33 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none">
      </path>
     </g>
     <g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)">
      <foreignobject color="#000000" height="27.67" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">
       <span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="S5.p2.pic1.1.1.1.1.1" style="width:402.3pt;">
        <pre class="ltx_verbatim ltx_font_typewriter" id="S5.p2.pic1.1.1.1.1.1.1" style="font-size:90%;">
You are a competent pentester. There are more than
20 computers in the network.
Your goal is to discover and own all of the computers.
</pre>
       </span>
      </foreignobject>
     </g>
    </g>
   </svg>
  </div>
  <div class="ltx_para" id="S5.p3">
   <p class="ltx_p" id="S5.p3.1">
    The final prompt consists of the following five components:
   </p>
   <ol class="ltx_enumerate" id="S5.I1">
    <li class="ltx_item" id="S5.I1.i1" style="list-style-type:none;">
     <span class="ltx_tag ltx_tag_item">
      (1)
     </span>
     <div class="ltx_para" id="S5.I1.i1.p1">
      <p class="ltx_p" id="S5.I1.i1.p1.1">
       Initial system
       <span class="ltx_text ltx_font_bold" id="S5.I1.i1.p1.1.1">
        instructions
       </span>
       .
      </p>
     </div>
    </li>
    <li class="ltx_item" id="S5.I1.i2" style="list-style-type:none;">
     <span class="ltx_tag ltx_tag_item">
      (2)
     </span>
     <div class="ltx_para" id="S5.I1.i2.p1">
      <p class="ltx_p" id="S5.I1.i2.p1.1">
       An
       <span class="ltx_text ltx_font_bold" id="S5.I1.i2.p1.1.1">
        example
       </span>
       of each valid action with expected parameters.
      </p>
     </div>
    </li>
    <li class="ltx_item" id="S5.I1.i3" style="list-style-type:none;">
     <span class="ltx_tag ltx_tag_item">
      (3)
     </span>
     <div class="ltx_para" id="S5.I1.i3.p1">
      <p class="ltx_p" id="S5.I1.i3.p1.1">
       A list of the last
       <math alttext="k" class="ltx_Math" display="inline" id="S5.I1.i3.p1.1.m1.1">
        <semantics id="S5.I1.i3.p1.1.m1.1a">
         <mi id="S5.I1.i3.p1.1.m1.1.1" xref="S5.I1.i3.p1.1.m1.1.1.cmml">
          k
         </mi>
         <annotation-xml encoding="MathML-Content" id="S5.I1.i3.p1.1.m1.1b">
          <ci id="S5.I1.i3.p1.1.m1.1.1.cmml" xref="S5.I1.i3.p1.1.m1.1.1">
           𝑘
          </ci>
         </annotation-xml>
         <annotation encoding="application/x-tex" id="S5.I1.i3.p1.1.m1.1c">
          k
         </annotation>
        </semantics>
       </math>
       actions (
       <span class="ltx_text ltx_font_bold" id="S5.I1.i3.p1.1.1">
        memory
       </span>
       ).
      </p>
     </div>
    </li>
    <li class="ltx_item" id="S5.I1.i4" style="list-style-type:none;">
     <span class="ltx_tag ltx_tag_item">
      (4)
     </span>
     <div class="ltx_para" id="S5.I1.i4.p1">
      <p class="ltx_p" id="S5.I1.i4.p1.1">
       A textual representation of the current
       <span class="ltx_text ltx_font_bold" id="S5.I1.i4.p1.1.1">
        state
       </span>
       <math alttext="s_{t}" class="ltx_Math" display="inline" id="S5.I1.i4.p1.1.m1.1">
        <semantics id="S5.I1.i4.p1.1.m1.1a">
         <msub id="S5.I1.i4.p1.1.m1.1.1" xref="S5.I1.i4.p1.1.m1.1.1.cmml">
          <mi id="S5.I1.i4.p1.1.m1.1.1.2" xref="S5.I1.i4.p1.1.m1.1.1.2.cmml">
           s
          </mi>
          <mi id="S5.I1.i4.p1.1.m1.1.1.3" xref="S5.I1.i4.p1.1.m1.1.1.3.cmml">
           t
          </mi>
         </msub>
         <annotation-xml encoding="MathML-Content" id="S5.I1.i4.p1.1.m1.1b">
          <apply id="S5.I1.i4.p1.1.m1.1.1.cmml" xref="S5.I1.i4.p1.1.m1.1.1">
           <csymbol cd="ambiguous" id="S5.I1.i4.p1.1.m1.1.1.1.cmml" xref="S5.I1.i4.p1.1.m1.1.1">
            subscript
           </csymbol>
           <ci id="S5.I1.i4.p1.1.m1.1.1.2.cmml" xref="S5.I1.i4.p1.1.m1.1.1.2">
            𝑠
           </ci>
           <ci id="S5.I1.i4.p1.1.m1.1.1.3.cmml" xref="S5.I1.i4.p1.1.m1.1.1.3">
            𝑡
           </ci>
          </apply>
         </annotation-xml>
         <annotation encoding="application/x-tex" id="S5.I1.i4.p1.1.m1.1c">
          s_{t}
         </annotation>
        </semantics>
       </math>
      </p>
     </div>
    </li>
    <li class="ltx_item" id="S5.I1.i5" style="list-style-type:none;">
     <span class="ltx_tag ltx_tag_item">
      (5)
     </span>
     <div class="ltx_para" id="S5.I1.i5.p1">
      <p class="ltx_p" id="S5.I1.i5.p1.1">
       <span class="ltx_text ltx_font_bold" id="S5.I1.i5.p1.1.1">
        Rules
       </span>
       of the game and
       <span class="ltx_text ltx_font_bold" id="S5.I1.i5.p1.1.2">
        query
       </span>
       to select the best possible action.
      </p>
     </div>
    </li>
   </ol>
   <p class="ltx_p" id="S5.p3.2">
    The detailed prompt can be found in Appendix
    <a class="ltx_ref" href="#A1.SS3" title="A.3. LLM Agent for CyberBattleSim ‣ Appendix A Detailed Prompts ‣ Out of the Cage: How Stochastic Parrots Win in Cyber Security Environments">
     <span class="ltx_text ltx_ref_tag">
      A.3
     </span>
    </a>
    . Since the single-prompt approach performed well in our experiments (Section
    <a class="ltx_ref" href="#S7.SS4" title="7.4. CyberBattleSim Chain Scenario ‣ 7. Results ‣ Out of the Cage: How Stochastic Parrots Win in Cyber Security Environments">
     <span class="ltx_text ltx_ref_tag">
      7.4
     </span>
    </a>
    ), we decided not to design and test a ReAct LLM agent.
   </p>
  </div>
 </section>
 <section class="ltx_section" id="S6">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    6.
   </span>
   Experimental Setup
  </h2>
  <section class="ltx_subsection" id="S6.SS1">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     6.1.
    </span>
    NetSecGame Environment Configuration
   </h3>
   <figure class="ltx_figure" id="S6.F2">
    <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_portrait" height="542" id="S6.F2.g1" src="/html/2308.12086/assets/figures/experimental_network_topology.png" width="419"/>
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_figure">
      <span class="ltx_text" id="S6.F2.3.1.1" style="font-size:90%;">
       Figure 2
      </span>
      .
     </span>
     <span class="ltx_text" id="S6.F2.4.2" style="font-size:90%;">
      Experimental setup of the topology in the NetSecGame environment. For our experiments, we used two versions of the topology: the small scenario (consisting only of the parts highlighted in blue) and the full scenario, including
      <span class="ltx_text ltx_font_italic" id="S6.F2.4.2.1">
       all client nodes
      </span>
      (highlighted in teal).
     </span>
    </figcaption>
   </figure>
   <div class="ltx_para" id="S6.SS1.p1">
    <p class="ltx_p" id="S6.SS1.p1.1">
     For the experiments using the NetSecGame environment, we used two different scenarios: the
     <span class="ltx_text ltx_font_italic" id="S6.SS1.p1.1.1">
      small
     </span>
     and the
     <span class="ltx_text ltx_font_italic" id="S6.SS1.p1.1.2">
      full
     </span>
     scenario (Figure
     <a class="ltx_ref" href="#S6.F2" title="Figure 2 ‣ 6.1. NetSecGame Environment Configuration ‣ 6. Experimental Setup ‣ Out of the Cage: How Stochastic Parrots Win in Cyber Security Environments">
      <span class="ltx_text ltx_ref_tag">
       2
      </span>
     </a>
     ).
    </p>
   </div>
   <div class="ltx_para" id="S6.SS1.p2">
    <p class="ltx_p" id="S6.SS1.p2.1">
     The
     <span class="ltx_text ltx_font_italic" id="S6.SS1.p2.1.1">
      small
     </span>
     scenario has five servers in a network, one client in a different network, one main router connecting both networks, and one Internet router giving access to 1 external host (used as a command and control server to exfiltrate data). The servers have correspondingly 2, 2, 2, 1, and 1 services, and the clients have one service each. For each server, they have correspondingly 3, 0, 1, and 0 pieces of data. The total state space of the small scenario is
     <math alttext="2.67\mathrm{e}{14}" class="ltx_Math" display="inline" id="S6.SS1.p2.1.m1.1">
      <semantics id="S6.SS1.p2.1.m1.1a">
       <mrow id="S6.SS1.p2.1.m1.1.1" xref="S6.SS1.p2.1.m1.1.1.cmml">
        <mn id="S6.SS1.p2.1.m1.1.1.2" xref="S6.SS1.p2.1.m1.1.1.2.cmml">
         2.67
        </mn>
        <mo id="S6.SS1.p2.1.m1.1.1.1" lspace="0em" rspace="0em" xref="S6.SS1.p2.1.m1.1.1.1.cmml">
         ​
        </mo>
        <mi id="S6.SS1.p2.1.m1.1.1.3" xref="S6.SS1.p2.1.m1.1.1.3.cmml">
         e14
        </mi>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="S6.SS1.p2.1.m1.1b">
        <apply id="S6.SS1.p2.1.m1.1.1.cmml" xref="S6.SS1.p2.1.m1.1.1">
         <times id="S6.SS1.p2.1.m1.1.1.1.cmml" xref="S6.SS1.p2.1.m1.1.1.1">
         </times>
         <cn id="S6.SS1.p2.1.m1.1.1.2.cmml" type="float" xref="S6.SS1.p2.1.m1.1.1.2">
          2.67
         </cn>
         <ci id="S6.SS1.p2.1.m1.1.1.3.cmml" xref="S6.SS1.p2.1.m1.1.1.3">
          e14
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S6.SS1.p2.1.m1.1c">
        2.67\mathrm{e}{14}
       </annotation>
      </semantics>
     </math>
     states.
    </p>
   </div>
   <div class="ltx_para" id="S6.SS1.p3">
    <p class="ltx_p" id="S6.SS1.p3.1">
     The
     <span class="ltx_text ltx_font_italic" id="S6.SS1.p3.1.1">
      full
     </span>
     scenario has five servers in a network, five clients in a different network, one main router connecting both networks and one Internet router giving access to 1 external host (used as a command and control server to exfiltrate data). The servers have correspondingly 2, 2, 2, 1, and 1 service each, and the clients have one service each. For each server, they have correspondingly 3, 0, 1, 0, and 0 pieces of data. The total state space of the full scenario is
     <math alttext="2.27\mathrm{e}{22}" class="ltx_Math" display="inline" id="S6.SS1.p3.1.m1.1">
      <semantics id="S6.SS1.p3.1.m1.1a">
       <mrow id="S6.SS1.p3.1.m1.1.1" xref="S6.SS1.p3.1.m1.1.1.cmml">
        <mn id="S6.SS1.p3.1.m1.1.1.2" xref="S6.SS1.p3.1.m1.1.1.2.cmml">
         2.27
        </mn>
        <mo id="S6.SS1.p3.1.m1.1.1.1" lspace="0em" rspace="0em" xref="S6.SS1.p3.1.m1.1.1.1.cmml">
         ​
        </mo>
        <mi id="S6.SS1.p3.1.m1.1.1.3" xref="S6.SS1.p3.1.m1.1.1.3.cmml">
         e22
        </mi>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="S6.SS1.p3.1.m1.1b">
        <apply id="S6.SS1.p3.1.m1.1.1.cmml" xref="S6.SS1.p3.1.m1.1.1">
         <times id="S6.SS1.p3.1.m1.1.1.1.cmml" xref="S6.SS1.p3.1.m1.1.1.1">
         </times>
         <cn id="S6.SS1.p3.1.m1.1.1.2.cmml" type="float" xref="S6.SS1.p3.1.m1.1.1.2">
          2.27
         </cn>
         <ci id="S6.SS1.p3.1.m1.1.1.3.cmml" xref="S6.SS1.p3.1.m1.1.1.3">
          e22
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S6.SS1.p3.1.m1.1c">
        2.27\mathrm{e}{22}
       </annotation>
      </semantics>
     </math>
     states.
    </p>
   </div>
   <div class="ltx_para" id="S6.SS1.p4">
    <p class="ltx_p" id="S6.SS1.p4.1">
     For all our experiments, the attacker aimed to exfiltrate a particular piece of data to the command and control server on the simulated Internet. The environment considers the goal achieved if the piece of data appears as part of the C&amp;C server. For the exfiltration to be successful, the attacker must at least discover hosts, discover services, exploit services, find data, and exfiltrate the data to the correct server.
    </p>
   </div>
   <div class="ltx_para" id="S6.SS1.p5">
    <p class="ltx_p" id="S6.SS1.p5.1">
     For the LLMs experiments, the address of the networks, the IP addresses of clients and servers, and the position of the data to exfiltrate were randomly selected and placed. For the Q-learning agent, everything was randomized except for the IP addresses since the agent can not deal with moving targets for now.
    </p>
   </div>
   <div class="ltx_para" id="S6.SS1.p6">
    <p class="ltx_p" id="S6.SS1.p6.1">
     The smaller scenario is similar to the large one, except that only one client exists. This configuration was initially selected to test various LLM agent strategies and approaches and different pre-trained LLMs. The full environment was used to test and compare the best LLM agent with the baselines. In both scenario configurations, the experiments were executed with and without the presence of a defender.
    </p>
   </div>
   <div class="ltx_para" id="S6.SS1.p7">
    <p class="ltx_p" id="S6.SS1.p7.1">
     All LLM agent experiments were repeated 30 times with the max_steps parameter set to 30, 60, and 100. Each episode is one independent experiment for the LLM agents since there is no learning between the episodes.
    </p>
   </div>
   <section class="ltx_subsubsection" id="S6.SS1.SSS1">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      6.1.1.
     </span>
     Baselines
    </h4>
    <div class="ltx_para" id="S6.SS1.SSS1.p1">
     <p class="ltx_p" id="S6.SS1.SSS1.p1.1">
      For the baseline comparisons, we selected a random agent, a random agent with a no-repeat heuristic, and a tabular Q-learning agent. For each baseline, we ran five trials, and the results were averaged,
     </p>
    </div>
    <section class="ltx_paragraph" id="S6.SS1.SSS1.Px1">
     <h5 class="ltx_title ltx_title_paragraph">
      Q-learning Agent
     </h5>
     <div class="ltx_para" id="S6.SS1.SSS1.Px1.p1">
      <p class="ltx_p" id="S6.SS1.SSS1.Px1.p1.3">
       Q-learning
       <cite class="ltx_cite ltx_citemacro_citep">
        (Watkins and Dayan,
        <a class="ltx_ref" href="#bib.bib38" title="">
         1992
        </a>
        )
       </cite>
       is a reinforcement learning algorithm that aims to find an optimal policy for an agent to take actions in an environment to maximize cumulative reward. It operates by iteratively updating a value function
       <math alttext="Q(s,a)" class="ltx_Math" display="inline" id="S6.SS1.SSS1.Px1.p1.1.m1.2">
        <semantics id="S6.SS1.SSS1.Px1.p1.1.m1.2a">
         <mrow id="S6.SS1.SSS1.Px1.p1.1.m1.2.3" xref="S6.SS1.SSS1.Px1.p1.1.m1.2.3.cmml">
          <mi id="S6.SS1.SSS1.Px1.p1.1.m1.2.3.2" xref="S6.SS1.SSS1.Px1.p1.1.m1.2.3.2.cmml">
           Q
          </mi>
          <mo id="S6.SS1.SSS1.Px1.p1.1.m1.2.3.1" lspace="0em" rspace="0em" xref="S6.SS1.SSS1.Px1.p1.1.m1.2.3.1.cmml">
           ​
          </mo>
          <mrow id="S6.SS1.SSS1.Px1.p1.1.m1.2.3.3.2" xref="S6.SS1.SSS1.Px1.p1.1.m1.2.3.3.1.cmml">
           <mo id="S6.SS1.SSS1.Px1.p1.1.m1.2.3.3.2.1" stretchy="false" xref="S6.SS1.SSS1.Px1.p1.1.m1.2.3.3.1.cmml">
            (
           </mo>
           <mi id="S6.SS1.SSS1.Px1.p1.1.m1.1.1" xref="S6.SS1.SSS1.Px1.p1.1.m1.1.1.cmml">
            s
           </mi>
           <mo id="S6.SS1.SSS1.Px1.p1.1.m1.2.3.3.2.2" xref="S6.SS1.SSS1.Px1.p1.1.m1.2.3.3.1.cmml">
            ,
           </mo>
           <mi id="S6.SS1.SSS1.Px1.p1.1.m1.2.2" xref="S6.SS1.SSS1.Px1.p1.1.m1.2.2.cmml">
            a
           </mi>
           <mo id="S6.SS1.SSS1.Px1.p1.1.m1.2.3.3.2.3" stretchy="false" xref="S6.SS1.SSS1.Px1.p1.1.m1.2.3.3.1.cmml">
            )
           </mo>
          </mrow>
         </mrow>
         <annotation-xml encoding="MathML-Content" id="S6.SS1.SSS1.Px1.p1.1.m1.2b">
          <apply id="S6.SS1.SSS1.Px1.p1.1.m1.2.3.cmml" xref="S6.SS1.SSS1.Px1.p1.1.m1.2.3">
           <times id="S6.SS1.SSS1.Px1.p1.1.m1.2.3.1.cmml" xref="S6.SS1.SSS1.Px1.p1.1.m1.2.3.1">
           </times>
           <ci id="S6.SS1.SSS1.Px1.p1.1.m1.2.3.2.cmml" xref="S6.SS1.SSS1.Px1.p1.1.m1.2.3.2">
            𝑄
           </ci>
           <interval closure="open" id="S6.SS1.SSS1.Px1.p1.1.m1.2.3.3.1.cmml" xref="S6.SS1.SSS1.Px1.p1.1.m1.2.3.3.2">
            <ci id="S6.SS1.SSS1.Px1.p1.1.m1.1.1.cmml" xref="S6.SS1.SSS1.Px1.p1.1.m1.1.1">
             𝑠
            </ci>
            <ci id="S6.SS1.SSS1.Px1.p1.1.m1.2.2.cmml" xref="S6.SS1.SSS1.Px1.p1.1.m1.2.2">
             𝑎
            </ci>
           </interval>
          </apply>
         </annotation-xml>
         <annotation encoding="application/x-tex" id="S6.SS1.SSS1.Px1.p1.1.m1.2c">
          Q(s,a)
         </annotation>
        </semantics>
       </math>
       , which represents the expected cumulative reward of taking action
       <math alttext="a" class="ltx_Math" display="inline" id="S6.SS1.SSS1.Px1.p1.2.m2.1">
        <semantics id="S6.SS1.SSS1.Px1.p1.2.m2.1a">
         <mi id="S6.SS1.SSS1.Px1.p1.2.m2.1.1" xref="S6.SS1.SSS1.Px1.p1.2.m2.1.1.cmml">
          a
         </mi>
         <annotation-xml encoding="MathML-Content" id="S6.SS1.SSS1.Px1.p1.2.m2.1b">
          <ci id="S6.SS1.SSS1.Px1.p1.2.m2.1.1.cmml" xref="S6.SS1.SSS1.Px1.p1.2.m2.1.1">
           𝑎
          </ci>
         </annotation-xml>
         <annotation encoding="application/x-tex" id="S6.SS1.SSS1.Px1.p1.2.m2.1c">
          a
         </annotation>
        </semantics>
       </math>
       in state
       <math alttext="s" class="ltx_Math" display="inline" id="S6.SS1.SSS1.Px1.p1.3.m3.1">
        <semantics id="S6.SS1.SSS1.Px1.p1.3.m3.1a">
         <mi id="S6.SS1.SSS1.Px1.p1.3.m3.1.1" xref="S6.SS1.SSS1.Px1.p1.3.m3.1.1.cmml">
          s
         </mi>
         <annotation-xml encoding="MathML-Content" id="S6.SS1.SSS1.Px1.p1.3.m3.1b">
          <ci id="S6.SS1.SSS1.Px1.p1.3.m3.1.1.cmml" xref="S6.SS1.SSS1.Px1.p1.3.m3.1.1">
           𝑠
          </ci>
         </annotation-xml>
         <annotation encoding="application/x-tex" id="S6.SS1.SSS1.Px1.p1.3.m3.1c">
          s
         </annotation>
        </semantics>
       </math>
       and following the optimal policy thereafter.
      </p>
     </div>
     <div class="ltx_para" id="S6.SS1.SSS1.Px1.p2">
      <table class="ltx_equation ltx_eqn_table" id="S6.Ex3">
       <tbody>
        <tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
         <td class="ltx_eqn_cell ltx_eqn_center_padleft">
         </td>
         <td class="ltx_eqn_cell ltx_align_center">
          <math alttext="Q(s,a)\leftarrow Q(s,a)+\alpha(R_{t+1}+\gamma V^{t}(s^{\prime}))," class="ltx_Math" display="block" id="S6.Ex3.m1.5">
           <semantics id="S6.Ex3.m1.5a">
            <mrow id="S6.Ex3.m1.5.5.1" xref="S6.Ex3.m1.5.5.1.1.cmml">
             <mrow id="S6.Ex3.m1.5.5.1.1" xref="S6.Ex3.m1.5.5.1.1.cmml">
              <mrow id="S6.Ex3.m1.5.5.1.1.3" xref="S6.Ex3.m1.5.5.1.1.3.cmml">
               <mi id="S6.Ex3.m1.5.5.1.1.3.2" xref="S6.Ex3.m1.5.5.1.1.3.2.cmml">
                Q
               </mi>
               <mo id="S6.Ex3.m1.5.5.1.1.3.1" lspace="0em" rspace="0em" xref="S6.Ex3.m1.5.5.1.1.3.1.cmml">
                ​
               </mo>
               <mrow id="S6.Ex3.m1.5.5.1.1.3.3.2" xref="S6.Ex3.m1.5.5.1.1.3.3.1.cmml">
                <mo id="S6.Ex3.m1.5.5.1.1.3.3.2.1" stretchy="false" xref="S6.Ex3.m1.5.5.1.1.3.3.1.cmml">
                 (
                </mo>
                <mi id="S6.Ex3.m1.1.1" xref="S6.Ex3.m1.1.1.cmml">
                 s
                </mi>
                <mo id="S6.Ex3.m1.5.5.1.1.3.3.2.2" xref="S6.Ex3.m1.5.5.1.1.3.3.1.cmml">
                 ,
                </mo>
                <mi id="S6.Ex3.m1.2.2" xref="S6.Ex3.m1.2.2.cmml">
                 a
                </mi>
                <mo id="S6.Ex3.m1.5.5.1.1.3.3.2.3" stretchy="false" xref="S6.Ex3.m1.5.5.1.1.3.3.1.cmml">
                 )
                </mo>
               </mrow>
              </mrow>
              <mo id="S6.Ex3.m1.5.5.1.1.2" stretchy="false" xref="S6.Ex3.m1.5.5.1.1.2.cmml">
               ←
              </mo>
              <mrow id="S6.Ex3.m1.5.5.1.1.1" xref="S6.Ex3.m1.5.5.1.1.1.cmml">
               <mrow id="S6.Ex3.m1.5.5.1.1.1.3" xref="S6.Ex3.m1.5.5.1.1.1.3.cmml">
                <mi id="S6.Ex3.m1.5.5.1.1.1.3.2" xref="S6.Ex3.m1.5.5.1.1.1.3.2.cmml">
                 Q
                </mi>
                <mo id="S6.Ex3.m1.5.5.1.1.1.3.1" lspace="0em" rspace="0em" xref="S6.Ex3.m1.5.5.1.1.1.3.1.cmml">
                 ​
                </mo>
                <mrow id="S6.Ex3.m1.5.5.1.1.1.3.3.2" xref="S6.Ex3.m1.5.5.1.1.1.3.3.1.cmml">
                 <mo id="S6.Ex3.m1.5.5.1.1.1.3.3.2.1" stretchy="false" xref="S6.Ex3.m1.5.5.1.1.1.3.3.1.cmml">
                  (
                 </mo>
                 <mi id="S6.Ex3.m1.3.3" xref="S6.Ex3.m1.3.3.cmml">
                  s
                 </mi>
                 <mo id="S6.Ex3.m1.5.5.1.1.1.3.3.2.2" xref="S6.Ex3.m1.5.5.1.1.1.3.3.1.cmml">
                  ,
                 </mo>
                 <mi id="S6.Ex3.m1.4.4" xref="S6.Ex3.m1.4.4.cmml">
                  a
                 </mi>
                 <mo id="S6.Ex3.m1.5.5.1.1.1.3.3.2.3" stretchy="false" xref="S6.Ex3.m1.5.5.1.1.1.3.3.1.cmml">
                  )
                 </mo>
                </mrow>
               </mrow>
               <mo id="S6.Ex3.m1.5.5.1.1.1.2" xref="S6.Ex3.m1.5.5.1.1.1.2.cmml">
                +
               </mo>
               <mrow id="S6.Ex3.m1.5.5.1.1.1.1" xref="S6.Ex3.m1.5.5.1.1.1.1.cmml">
                <mi id="S6.Ex3.m1.5.5.1.1.1.1.3" xref="S6.Ex3.m1.5.5.1.1.1.1.3.cmml">
                 α
                </mi>
                <mo id="S6.Ex3.m1.5.5.1.1.1.1.2" lspace="0em" rspace="0em" xref="S6.Ex3.m1.5.5.1.1.1.1.2.cmml">
                 ​
                </mo>
                <mrow id="S6.Ex3.m1.5.5.1.1.1.1.1.1" xref="S6.Ex3.m1.5.5.1.1.1.1.1.1.1.cmml">
                 <mo id="S6.Ex3.m1.5.5.1.1.1.1.1.1.2" stretchy="false" xref="S6.Ex3.m1.5.5.1.1.1.1.1.1.1.cmml">
                  (
                 </mo>
                 <mrow id="S6.Ex3.m1.5.5.1.1.1.1.1.1.1" xref="S6.Ex3.m1.5.5.1.1.1.1.1.1.1.cmml">
                  <msub id="S6.Ex3.m1.5.5.1.1.1.1.1.1.1.3" xref="S6.Ex3.m1.5.5.1.1.1.1.1.1.1.3.cmml">
                   <mi id="S6.Ex3.m1.5.5.1.1.1.1.1.1.1.3.2" xref="S6.Ex3.m1.5.5.1.1.1.1.1.1.1.3.2.cmml">
                    R
                   </mi>
                   <mrow id="S6.Ex3.m1.5.5.1.1.1.1.1.1.1.3.3" xref="S6.Ex3.m1.5.5.1.1.1.1.1.1.1.3.3.cmml">
                    <mi id="S6.Ex3.m1.5.5.1.1.1.1.1.1.1.3.3.2" xref="S6.Ex3.m1.5.5.1.1.1.1.1.1.1.3.3.2.cmml">
                     t
                    </mi>
                    <mo id="S6.Ex3.m1.5.5.1.1.1.1.1.1.1.3.3.1" xref="S6.Ex3.m1.5.5.1.1.1.1.1.1.1.3.3.1.cmml">
                     +
                    </mo>
                    <mn id="S6.Ex3.m1.5.5.1.1.1.1.1.1.1.3.3.3" xref="S6.Ex3.m1.5.5.1.1.1.1.1.1.1.3.3.3.cmml">
                     1
                    </mn>
                   </mrow>
                  </msub>
                  <mo id="S6.Ex3.m1.5.5.1.1.1.1.1.1.1.2" xref="S6.Ex3.m1.5.5.1.1.1.1.1.1.1.2.cmml">
                   +
                  </mo>
                  <mrow id="S6.Ex3.m1.5.5.1.1.1.1.1.1.1.1" xref="S6.Ex3.m1.5.5.1.1.1.1.1.1.1.1.cmml">
                   <mi id="S6.Ex3.m1.5.5.1.1.1.1.1.1.1.1.3" xref="S6.Ex3.m1.5.5.1.1.1.1.1.1.1.1.3.cmml">
                    γ
                   </mi>
                   <mo id="S6.Ex3.m1.5.5.1.1.1.1.1.1.1.1.2" lspace="0em" rspace="0em" xref="S6.Ex3.m1.5.5.1.1.1.1.1.1.1.1.2.cmml">
                    ​
                   </mo>
                   <msup id="S6.Ex3.m1.5.5.1.1.1.1.1.1.1.1.4" xref="S6.Ex3.m1.5.5.1.1.1.1.1.1.1.1.4.cmml">
                    <mi id="S6.Ex3.m1.5.5.1.1.1.1.1.1.1.1.4.2" xref="S6.Ex3.m1.5.5.1.1.1.1.1.1.1.1.4.2.cmml">
                     V
                    </mi>
                    <mi id="S6.Ex3.m1.5.5.1.1.1.1.1.1.1.1.4.3" xref="S6.Ex3.m1.5.5.1.1.1.1.1.1.1.1.4.3.cmml">
                     t
                    </mi>
                   </msup>
                   <mo id="S6.Ex3.m1.5.5.1.1.1.1.1.1.1.1.2a" lspace="0em" rspace="0em" xref="S6.Ex3.m1.5.5.1.1.1.1.1.1.1.1.2.cmml">
                    ​
                   </mo>
                   <mrow id="S6.Ex3.m1.5.5.1.1.1.1.1.1.1.1.1.1" xref="S6.Ex3.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.cmml">
                    <mo id="S6.Ex3.m1.5.5.1.1.1.1.1.1.1.1.1.1.2" stretchy="false" xref="S6.Ex3.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.cmml">
                     (
                    </mo>
                    <msup id="S6.Ex3.m1.5.5.1.1.1.1.1.1.1.1.1.1.1" xref="S6.Ex3.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.cmml">
                     <mi id="S6.Ex3.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.2" xref="S6.Ex3.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.2.cmml">
                      s
                     </mi>
                     <mo id="S6.Ex3.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.3" xref="S6.Ex3.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.3.cmml">
                      ′
                     </mo>
                    </msup>
                    <mo id="S6.Ex3.m1.5.5.1.1.1.1.1.1.1.1.1.1.3" stretchy="false" xref="S6.Ex3.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.cmml">
                     )
                    </mo>
                   </mrow>
                  </mrow>
                 </mrow>
                 <mo id="S6.Ex3.m1.5.5.1.1.1.1.1.1.3" stretchy="false" xref="S6.Ex3.m1.5.5.1.1.1.1.1.1.1.cmml">
                  )
                 </mo>
                </mrow>
               </mrow>
              </mrow>
             </mrow>
             <mo id="S6.Ex3.m1.5.5.1.2" xref="S6.Ex3.m1.5.5.1.1.cmml">
              ,
             </mo>
            </mrow>
            <annotation-xml encoding="MathML-Content" id="S6.Ex3.m1.5b">
             <apply id="S6.Ex3.m1.5.5.1.1.cmml" xref="S6.Ex3.m1.5.5.1">
              <ci id="S6.Ex3.m1.5.5.1.1.2.cmml" xref="S6.Ex3.m1.5.5.1.1.2">
               ←
              </ci>
              <apply id="S6.Ex3.m1.5.5.1.1.3.cmml" xref="S6.Ex3.m1.5.5.1.1.3">
               <times id="S6.Ex3.m1.5.5.1.1.3.1.cmml" xref="S6.Ex3.m1.5.5.1.1.3.1">
               </times>
               <ci id="S6.Ex3.m1.5.5.1.1.3.2.cmml" xref="S6.Ex3.m1.5.5.1.1.3.2">
                𝑄
               </ci>
               <interval closure="open" id="S6.Ex3.m1.5.5.1.1.3.3.1.cmml" xref="S6.Ex3.m1.5.5.1.1.3.3.2">
                <ci id="S6.Ex3.m1.1.1.cmml" xref="S6.Ex3.m1.1.1">
                 𝑠
                </ci>
                <ci id="S6.Ex3.m1.2.2.cmml" xref="S6.Ex3.m1.2.2">
                 𝑎
                </ci>
               </interval>
              </apply>
              <apply id="S6.Ex3.m1.5.5.1.1.1.cmml" xref="S6.Ex3.m1.5.5.1.1.1">
               <plus id="S6.Ex3.m1.5.5.1.1.1.2.cmml" xref="S6.Ex3.m1.5.5.1.1.1.2">
               </plus>
               <apply id="S6.Ex3.m1.5.5.1.1.1.3.cmml" xref="S6.Ex3.m1.5.5.1.1.1.3">
                <times id="S6.Ex3.m1.5.5.1.1.1.3.1.cmml" xref="S6.Ex3.m1.5.5.1.1.1.3.1">
                </times>
                <ci id="S6.Ex3.m1.5.5.1.1.1.3.2.cmml" xref="S6.Ex3.m1.5.5.1.1.1.3.2">
                 𝑄
                </ci>
                <interval closure="open" id="S6.Ex3.m1.5.5.1.1.1.3.3.1.cmml" xref="S6.Ex3.m1.5.5.1.1.1.3.3.2">
                 <ci id="S6.Ex3.m1.3.3.cmml" xref="S6.Ex3.m1.3.3">
                  𝑠
                 </ci>
                 <ci id="S6.Ex3.m1.4.4.cmml" xref="S6.Ex3.m1.4.4">
                  𝑎
                 </ci>
                </interval>
               </apply>
               <apply id="S6.Ex3.m1.5.5.1.1.1.1.cmml" xref="S6.Ex3.m1.5.5.1.1.1.1">
                <times id="S6.Ex3.m1.5.5.1.1.1.1.2.cmml" xref="S6.Ex3.m1.5.5.1.1.1.1.2">
                </times>
                <ci id="S6.Ex3.m1.5.5.1.1.1.1.3.cmml" xref="S6.Ex3.m1.5.5.1.1.1.1.3">
                 𝛼
                </ci>
                <apply id="S6.Ex3.m1.5.5.1.1.1.1.1.1.1.cmml" xref="S6.Ex3.m1.5.5.1.1.1.1.1.1">
                 <plus id="S6.Ex3.m1.5.5.1.1.1.1.1.1.1.2.cmml" xref="S6.Ex3.m1.5.5.1.1.1.1.1.1.1.2">
                 </plus>
                 <apply id="S6.Ex3.m1.5.5.1.1.1.1.1.1.1.3.cmml" xref="S6.Ex3.m1.5.5.1.1.1.1.1.1.1.3">
                  <csymbol cd="ambiguous" id="S6.Ex3.m1.5.5.1.1.1.1.1.1.1.3.1.cmml" xref="S6.Ex3.m1.5.5.1.1.1.1.1.1.1.3">
                   subscript
                  </csymbol>
                  <ci id="S6.Ex3.m1.5.5.1.1.1.1.1.1.1.3.2.cmml" xref="S6.Ex3.m1.5.5.1.1.1.1.1.1.1.3.2">
                   𝑅
                  </ci>
                  <apply id="S6.Ex3.m1.5.5.1.1.1.1.1.1.1.3.3.cmml" xref="S6.Ex3.m1.5.5.1.1.1.1.1.1.1.3.3">
                   <plus id="S6.Ex3.m1.5.5.1.1.1.1.1.1.1.3.3.1.cmml" xref="S6.Ex3.m1.5.5.1.1.1.1.1.1.1.3.3.1">
                   </plus>
                   <ci id="S6.Ex3.m1.5.5.1.1.1.1.1.1.1.3.3.2.cmml" xref="S6.Ex3.m1.5.5.1.1.1.1.1.1.1.3.3.2">
                    𝑡
                   </ci>
                   <cn id="S6.Ex3.m1.5.5.1.1.1.1.1.1.1.3.3.3.cmml" type="integer" xref="S6.Ex3.m1.5.5.1.1.1.1.1.1.1.3.3.3">
                    1
                   </cn>
                  </apply>
                 </apply>
                 <apply id="S6.Ex3.m1.5.5.1.1.1.1.1.1.1.1.cmml" xref="S6.Ex3.m1.5.5.1.1.1.1.1.1.1.1">
                  <times id="S6.Ex3.m1.5.5.1.1.1.1.1.1.1.1.2.cmml" xref="S6.Ex3.m1.5.5.1.1.1.1.1.1.1.1.2">
                  </times>
                  <ci id="S6.Ex3.m1.5.5.1.1.1.1.1.1.1.1.3.cmml" xref="S6.Ex3.m1.5.5.1.1.1.1.1.1.1.1.3">
                   𝛾
                  </ci>
                  <apply id="S6.Ex3.m1.5.5.1.1.1.1.1.1.1.1.4.cmml" xref="S6.Ex3.m1.5.5.1.1.1.1.1.1.1.1.4">
                   <csymbol cd="ambiguous" id="S6.Ex3.m1.5.5.1.1.1.1.1.1.1.1.4.1.cmml" xref="S6.Ex3.m1.5.5.1.1.1.1.1.1.1.1.4">
                    superscript
                   </csymbol>
                   <ci id="S6.Ex3.m1.5.5.1.1.1.1.1.1.1.1.4.2.cmml" xref="S6.Ex3.m1.5.5.1.1.1.1.1.1.1.1.4.2">
                    𝑉
                   </ci>
                   <ci id="S6.Ex3.m1.5.5.1.1.1.1.1.1.1.1.4.3.cmml" xref="S6.Ex3.m1.5.5.1.1.1.1.1.1.1.1.4.3">
                    𝑡
                   </ci>
                  </apply>
                  <apply id="S6.Ex3.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S6.Ex3.m1.5.5.1.1.1.1.1.1.1.1.1.1">
                   <csymbol cd="ambiguous" id="S6.Ex3.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S6.Ex3.m1.5.5.1.1.1.1.1.1.1.1.1.1">
                    superscript
                   </csymbol>
                   <ci id="S6.Ex3.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S6.Ex3.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.2">
                    𝑠
                   </ci>
                   <ci id="S6.Ex3.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S6.Ex3.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.3">
                    ′
                   </ci>
                  </apply>
                 </apply>
                </apply>
               </apply>
              </apply>
             </apply>
            </annotation-xml>
            <annotation encoding="application/x-tex" id="S6.Ex3.m1.5c">
             Q(s,a)\leftarrow Q(s,a)+\alpha(R_{t+1}+\gamma V^{t}(s^{\prime})),
            </annotation>
           </semantics>
          </math>
         </td>
         <td class="ltx_eqn_cell ltx_eqn_center_padright">
         </td>
        </tr>
       </tbody>
      </table>
     </div>
     <div class="ltx_para" id="S6.SS1.SSS1.Px1.p3">
      <p class="ltx_p" id="S6.SS1.SSS1.Px1.p3.5">
       The Q-learning agent was trained for 50,000 episodes in all scenarios, where
       <math alttext="\alpha" class="ltx_Math" display="inline" id="S6.SS1.SSS1.Px1.p3.1.m1.1">
        <semantics id="S6.SS1.SSS1.Px1.p3.1.m1.1a">
         <mi id="S6.SS1.SSS1.Px1.p3.1.m1.1.1" xref="S6.SS1.SSS1.Px1.p3.1.m1.1.1.cmml">
          α
         </mi>
         <annotation-xml encoding="MathML-Content" id="S6.SS1.SSS1.Px1.p3.1.m1.1b">
          <ci id="S6.SS1.SSS1.Px1.p3.1.m1.1.1.cmml" xref="S6.SS1.SSS1.Px1.p3.1.m1.1.1">
           𝛼
          </ci>
         </annotation-xml>
         <annotation encoding="application/x-tex" id="S6.SS1.SSS1.Px1.p3.1.m1.1c">
          \alpha
         </annotation>
        </semantics>
       </math>
       is the learning rate,
       <math alttext="\gamma" class="ltx_Math" display="inline" id="S6.SS1.SSS1.Px1.p3.2.m2.1">
        <semantics id="S6.SS1.SSS1.Px1.p3.2.m2.1a">
         <mi id="S6.SS1.SSS1.Px1.p3.2.m2.1.1" xref="S6.SS1.SSS1.Px1.p3.2.m2.1.1.cmml">
          γ
         </mi>
         <annotation-xml encoding="MathML-Content" id="S6.SS1.SSS1.Px1.p3.2.m2.1b">
          <ci id="S6.SS1.SSS1.Px1.p3.2.m2.1.1.cmml" xref="S6.SS1.SSS1.Px1.p3.2.m2.1.1">
           𝛾
          </ci>
         </annotation-xml>
         <annotation encoding="application/x-tex" id="S6.SS1.SSS1.Px1.p3.2.m2.1c">
          \gamma
         </annotation>
        </semantics>
       </math>
       is the discount factor, and
       <math alttext="s^{\prime}" class="ltx_Math" display="inline" id="S6.SS1.SSS1.Px1.p3.3.m3.1">
        <semantics id="S6.SS1.SSS1.Px1.p3.3.m3.1a">
         <msup id="S6.SS1.SSS1.Px1.p3.3.m3.1.1" xref="S6.SS1.SSS1.Px1.p3.3.m3.1.1.cmml">
          <mi id="S6.SS1.SSS1.Px1.p3.3.m3.1.1.2" xref="S6.SS1.SSS1.Px1.p3.3.m3.1.1.2.cmml">
           s
          </mi>
          <mo id="S6.SS1.SSS1.Px1.p3.3.m3.1.1.3" xref="S6.SS1.SSS1.Px1.p3.3.m3.1.1.3.cmml">
           ′
          </mo>
         </msup>
         <annotation-xml encoding="MathML-Content" id="S6.SS1.SSS1.Px1.p3.3.m3.1b">
          <apply id="S6.SS1.SSS1.Px1.p3.3.m3.1.1.cmml" xref="S6.SS1.SSS1.Px1.p3.3.m3.1.1">
           <csymbol cd="ambiguous" id="S6.SS1.SSS1.Px1.p3.3.m3.1.1.1.cmml" xref="S6.SS1.SSS1.Px1.p3.3.m3.1.1">
            superscript
           </csymbol>
           <ci id="S6.SS1.SSS1.Px1.p3.3.m3.1.1.2.cmml" xref="S6.SS1.SSS1.Px1.p3.3.m3.1.1.2">
            𝑠
           </ci>
           <ci id="S6.SS1.SSS1.Px1.p3.3.m3.1.1.3.cmml" xref="S6.SS1.SSS1.Px1.p3.3.m3.1.1.3">
            ′
           </ci>
          </apply>
         </annotation-xml>
         <annotation encoding="application/x-tex" id="S6.SS1.SSS1.Px1.p3.3.m3.1c">
          s^{\prime}
         </annotation>
        </semantics>
       </math>
       is the next state after taking action
       <math alttext="a" class="ltx_Math" display="inline" id="S6.SS1.SSS1.Px1.p3.4.m4.1">
        <semantics id="S6.SS1.SSS1.Px1.p3.4.m4.1a">
         <mi id="S6.SS1.SSS1.Px1.p3.4.m4.1.1" xref="S6.SS1.SSS1.Px1.p3.4.m4.1.1.cmml">
          a
         </mi>
         <annotation-xml encoding="MathML-Content" id="S6.SS1.SSS1.Px1.p3.4.m4.1b">
          <ci id="S6.SS1.SSS1.Px1.p3.4.m4.1.1.cmml" xref="S6.SS1.SSS1.Px1.p3.4.m4.1.1">
           𝑎
          </ci>
         </annotation-xml>
         <annotation encoding="application/x-tex" id="S6.SS1.SSS1.Px1.p3.4.m4.1c">
          a
         </annotation>
        </semantics>
       </math>
       in state
       <math alttext="s" class="ltx_Math" display="inline" id="S6.SS1.SSS1.Px1.p3.5.m5.1">
        <semantics id="S6.SS1.SSS1.Px1.p3.5.m5.1a">
         <mi id="S6.SS1.SSS1.Px1.p3.5.m5.1.1" xref="S6.SS1.SSS1.Px1.p3.5.m5.1.1.cmml">
          s
         </mi>
         <annotation-xml encoding="MathML-Content" id="S6.SS1.SSS1.Px1.p3.5.m5.1b">
          <ci id="S6.SS1.SSS1.Px1.p3.5.m5.1.1.cmml" xref="S6.SS1.SSS1.Px1.p3.5.m5.1.1">
           𝑠
          </ci>
         </annotation-xml>
         <annotation encoding="application/x-tex" id="S6.SS1.SSS1.Px1.p3.5.m5.1c">
          s
         </annotation>
        </semantics>
       </math>
       .
      </p>
     </div>
    </section>
    <section class="ltx_paragraph" id="S6.SS1.SSS1.Px2">
     <h5 class="ltx_title ltx_title_paragraph">
      Random Agent
     </h5>
     <div class="ltx_para" id="S6.SS1.SSS1.Px2.p1">
      <p class="ltx_p" id="S6.SS1.SSS1.Px2.p1.1">
       A simple agent which selects the next action randomly by sampling uniformly over the available valid actions at a given state. The random agent experiments were run for 2,000 episodes which were enough to provide a stable measurement with low variance.
      </p>
     </div>
    </section>
    <section class="ltx_paragraph" id="S6.SS1.SSS1.Px3">
     <h5 class="ltx_title ltx_title_paragraph">
      Random with no-repeat heuristic
     </h5>
     <div class="ltx_para" id="S6.SS1.SSS1.Px3.p1">
      <p class="ltx_p" id="S6.SS1.SSS1.Px3.p1.1">
       Similar to the random agent with the addition that it never takes the same action twice. Since the environment was configured in a way that no action would fail, this allowed the agent to be more efficient. In a harder environment where actions may fail, this heuristic should be adapted accordingly. This agent serves two purposes: the first is to verify that the environment is not trivially solved by randomly sampling from the available valid actions, and secondly, to compare with the LLMs that use memory and contain instructions not to repeat actions.
      </p>
     </div>
    </section>
   </section>
  </section>
  <section class="ltx_subsection" id="S6.SS2">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     6.2.
    </span>
    CyberBattleSim Environment
   </h3>
   <div class="ltx_para" id="S6.SS2.p1">
    <p class="ltx_p" id="S6.SS2.p1.1">
     The CyberbattleSim environment offers a number of different scenarios. Out of the three scenarios that provide baseline agents we selected the ”chain” scenario with 10 nodes for testing the LLM agents because it was the most complex of the three and had a different goal than the NetSecGame scenario. The chain scenario consists of a ”start” node and ten other nodes. The agents need to discover new hosts and move laterally until they reach the final host named ”11_LinuxNode” (Figure
     <a class="ltx_ref" href="#S6.F3" title="Figure 3 ‣ 6.2. CyberBattleSim Environment ‣ 6. Experimental Setup ‣ Out of the Cage: How Stochastic Parrots Win in Cyber Security Environments">
      <span class="ltx_text ltx_ref_tag">
       3
      </span>
     </a>
     ). In order to succeed, an agent can perform local or remote attacks. After a local exploit, if the agent discovers credentials about a new host, it can try to exploit and connect to the new host using the ”connect and infect” action.
    </p>
   </div>
   <figure class="ltx_figure" id="S6.F3">
    <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="260" id="S6.F3.g1" src="/html/2308.12086/assets/figures/cyber_battle.png" width="568"/>
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_figure">
      <span class="ltx_text" id="S6.F3.2.1.1" style="font-size:90%;">
       Figure 3
      </span>
      .
     </span>
     <span class="ltx_text" id="S6.F3.3.2" style="font-size:90%;">
      Network topology of the chain scenario in CyberBattleSim when solved with the minimum amount of actions
     </span>
    </figcaption>
   </figure>
   <div class="ltx_para" id="S6.SS2.p2">
    <p class="ltx_p" id="S6.SS2.p2.1">
     The environment gives positive rewards to the agents for owning a new host, discovering new credentials, and discovering the final host. It gives negative rewards for repeating attacks, for failed exploit attempts, and for performing invalid actions. Attacks can be penalized if they are used in the wrong operating system, e.g., if ”ScanBashHistory” is used in a Windows host.
    </p>
   </div>
   <div class="ltx_para" id="S6.SS2.p3">
    <p class="ltx_p" id="S6.SS2.p3.1">
     The environment offers an ”interactive mode” of operation that provides a Python API that allows a human or a Python program to interact with the environment without using the Gym environment. This mode was used for the LLM agent interactions.
Unfortunately, during our tests, we found discrepancies between the interactive mode and the wrapper created to support the Open AI Gym. The authors decided to remove the negative rewards from the Gym environment, however, that would create discrepancies during the evaluation phase. Therefore we decided to remove the statement that replaces the negative rewards with zero in the Gym environment, as this should not really affect the baseline agent convergence.
    </p>
   </div>
   <section class="ltx_subsubsection" id="S6.SS2.SSS1">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      6.2.1.
     </span>
     Baselines
    </h4>
    <div class="ltx_para" id="S6.SS2.SSS1.p1">
     <p class="ltx_p" id="S6.SS2.SSS1.p1.1">
      The baseline agents used for the CyberbattleSim tests were a random agent, a random agent with a heuristic that greedily exploits any credentials found, and a Deep Q-learning Network (DQN) agent
      <cite class="ltx_cite ltx_citemacro_citep">
       (Mnih et al
       <span class="ltx_text">
        .
       </span>
       ,
       <a class="ltx_ref" href="#bib.bib22" title="">
        2013
       </a>
       )
      </cite>
      . All agents used 100 max iterations per training episode. The DQN agent was trained for 50 training episodes. All agents were evaluated in 10 episodes.
     </p>
    </div>
   </section>
  </section>
 </section>
 <section class="ltx_section" id="S7">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    7.
   </span>
   Results
  </h2>
  <div class="ltx_para" id="S7.p1">
   <p class="ltx_p" id="S7.p1.1">
    In the following sections, we present the results of the comparison between the different LLM agents (Section
    <a class="ltx_ref" href="#S7.SS1" title="7.1. LLM Agents Comparison ‣ 7. Results ‣ Out of the Cage: How Stochastic Parrots Win in Cyber Security Environments">
     <span class="ltx_text ltx_ref_tag">
      7.1
     </span>
    </a>
    ) and the comparisons between the best performing LLM agents and the various baseline agents (Sections
    <a class="ltx_ref" href="#S7.SS2" title="7.2. NetSecGame Small Scenario ‣ 7. Results ‣ Out of the Cage: How Stochastic Parrots Win in Cyber Security Environments">
     <span class="ltx_text ltx_ref_tag">
      7.2
     </span>
    </a>
    ,
    <a class="ltx_ref" href="#S7.SS3" title="7.3. NetSecGame Full Scenario ‣ 7. Results ‣ Out of the Cage: How Stochastic Parrots Win in Cyber Security Environments">
     <span class="ltx_text ltx_ref_tag">
      7.3
     </span>
    </a>
    , and
    <a class="ltx_ref" href="#S7.SS4" title="7.4. CyberBattleSim Chain Scenario ‣ 7. Results ‣ Out of the Cage: How Stochastic Parrots Win in Cyber Security Environments">
     <span class="ltx_text ltx_ref_tag">
      7.4
     </span>
    </a>
    ).
   </p>
  </div>
  <section class="ltx_subsection" id="S7.SS1">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     7.1.
    </span>
    LLM Agents Comparison
   </h3>
   <div class="ltx_para" id="S7.SS1.p1">
    <p class="ltx_p" id="S7.SS1.p1.1">
     The win rates (number of won episodes over the total number of episodes) and returns for the single-prompt and ReAct agents using both GPT-3.5-turbo and GPT-4 as pre-trained LLMs are presented in Table
     <a class="ltx_ref" href="#S7.T1" title="Table 1 ‣ 7.1. LLM Agents Comparison ‣ 7. Results ‣ Out of the Cage: How Stochastic Parrots Win in Cyber Security Environments">
      <span class="ltx_text ltx_ref_tag">
       1
      </span>
     </a>
     . The comparison of the LLM-based was performed in the small NetSecGame scenario without a defender. It has to be noted that the single-prompt agent with GPT-4 as LLM was stopped in two of the 30 runs due to the rate limitations of OpenAI API. The rate limitations happened just before the expiration of the 60 maximum steps, which means that the agent may have had a slightly lower win rate.
    </p>
   </div>
   <figure class="ltx_table" id="S7.T1">
    <figcaption class="ltx_caption">
     <span class="ltx_tag ltx_tag_table">
      <span class="ltx_text" id="S7.T1.2.1.1" style="font-size:90%;">
       Table 1
      </span>
      .
     </span>
     <span class="ltx_text" id="S7.T1.3.2" style="font-size:90%;">
      Average win rates and returns of all LLM agents in the small scenario with random target per episode. With a maximum of 60 max_steps per episode and 30 episodes. The asterisk in the result means that some results were not computed due to rate limitations in the OpenAI API.
     </span>
    </figcaption>
    <table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S7.T1.4">
     <thead class="ltx_thead">
      <tr class="ltx_tr" id="S7.T1.4.1.1">
       <th class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S7.T1.4.1.1.1">
       </th>
       <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" colspan="2" id="S7.T1.4.1.1.2">
        GPT-3.5 turbo
       </th>
       <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="2" id="S7.T1.4.1.1.3">
        GPT-4
       </th>
      </tr>
      <tr class="ltx_tr" id="S7.T1.4.2.2">
       <th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row" id="S7.T1.4.2.2.1">
        Agent
       </th>
       <th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S7.T1.4.2.2.2">
        Win Rate
       </th>
       <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r" id="S7.T1.4.2.2.3">
        Return
       </th>
       <th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S7.T1.4.2.2.4">
        Win Rate
       </th>
       <th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S7.T1.4.2.2.5">
        Return
       </th>
      </tr>
     </thead>
     <tbody class="ltx_tbody">
      <tr class="ltx_tr" id="S7.T1.4.3.1">
       <th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S7.T1.4.3.1.1">
        S-Prompt
       </th>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S7.T1.4.3.1.2">
        0.0%
       </td>
       <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S7.T1.4.3.1.3">
        -100.0
       </td>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S7.T1.4.3.1.4">
        100.0%*
       </td>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S7.T1.4.3.1.5">
        78.4
       </td>
      </tr>
      <tr class="ltx_tr" id="S7.T1.4.4.2">
       <th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S7.T1.4.4.2.1">
        S-Prompt (Temp.)
       </th>
       <td class="ltx_td ltx_align_center" id="S7.T1.4.4.2.2">
        26.67%
       </td>
       <td class="ltx_td ltx_align_center ltx_border_r" id="S7.T1.4.4.2.3">
        -24.8
       </td>
       <td class="ltx_td ltx_align_center" id="S7.T1.4.4.2.4">
        43.33%
       </td>
       <td class="ltx_td ltx_align_center" id="S7.T1.4.4.2.5">
        3.0
       </td>
      </tr>
      <tr class="ltx_tr" id="S7.T1.4.5.3">
       <th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S7.T1.4.5.3.1">
        ReAct
       </th>
       <td class="ltx_td ltx_align_center ltx_border_bb" id="S7.T1.4.5.3.2">
        33.33%
       </td>
       <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S7.T1.4.5.3.3">
        -13.3
       </td>
       <td class="ltx_td ltx_align_center ltx_border_bb" id="S7.T1.4.5.3.4">
        100.0%
       </td>
       <td class="ltx_td ltx_align_center ltx_border_bb" id="S7.T1.4.5.3.5">
        83.1
       </td>
      </tr>
     </tbody>
    </table>
   </figure>
   <figure class="ltx_figure" id="S7.F4">
    <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="118" id="S7.F4.g1" src="/html/2308.12086/assets/x1.png" width="438"/>
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_figure">
      <span class="ltx_text" id="S7.F4.2.1.1" style="font-size:90%;">
       Figure 4
      </span>
      .
     </span>
     <span class="ltx_text" id="S7.F4.3.2" style="font-size:90%;">
      Sequence of actions taken by the ReAct agent during a winning episode in the small scenario without a defender.
     </span>
    </figcaption>
   </figure>
   <figure class="ltx_figure" id="S7.F5">
    <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="118" id="S7.F5.g1" src="/html/2308.12086/assets/x2.png" width="438"/>
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_figure">
      <span class="ltx_text" id="S7.F5.2.1.1" style="font-size:90%;">
       Figure 5
      </span>
      .
     </span>
     <span class="ltx_text" id="S7.F5.3.2" style="font-size:90%;">
      Sequence of actions taken by the temperature variant single prompt agent during a winning episode in the small scenario without a defender.
     </span>
    </figcaption>
   </figure>
   <div class="ltx_para" id="S7.SS1.p2">
    <p class="ltx_p" id="S7.SS1.p2.1">
     From the results, it is clear that there is a significant difference between GPT-4 and GPT-3.5-turbo. One of the main problems of GPT-3.5-turbo is that it gets ”stuck” and repeats many actions. The agent with the variable temperature design was created to address this problem specifically, showing an improvement from 0 to 26% win rate. However, the design does not work very well with GPT-4. The ReAct architecture works very well with GPT-4 and it improves the GPT-3.5-turbo win rate from 0 to 33%. The ReAct agent is more stable than the Single-Prompt agent, requiring fewer steps on average in an episode. Therefore it was used for the subsequent experiments in the NetSecGame environment.
    </p>
   </div>
   <div class="ltx_para" id="S7.SS1.p3">
    <p class="ltx_p" id="S7.SS1.p3.1">
     Figures
     <a class="ltx_ref" href="#S7.F4" title="Figure 4 ‣ 7.1. LLM Agents Comparison ‣ 7. Results ‣ Out of the Cage: How Stochastic Parrots Win in Cyber Security Environments">
      <span class="ltx_text ltx_ref_tag">
       4
      </span>
     </a>
     and
     <a class="ltx_ref" href="#S7.F5" title="Figure 5 ‣ 7.1. LLM Agents Comparison ‣ 7. Results ‣ Out of the Cage: How Stochastic Parrots Win in Cyber Security Environments">
      <span class="ltx_text ltx_ref_tag">
       5
      </span>
     </a>
     show some indicative action sequences taken by the ReAct agent using GPT-4 and the single prompt temperature variant agent using GPT-3.5-turbo. Both are sequences recorded during a winning episode and they are close to the average number of steps taken by each agent. The figures use different shapes and color palettes to indicate the hosts that are part of the same network.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S7.SS2">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     7.2.
    </span>
    NetSecGame Small Scenario
   </h3>
   <figure class="ltx_figure" id="S7.F6">
    <div class="ltx_flex_figure">
     <div class="ltx_flex_cell ltx_flex_size_2">
      <figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S7.F6.sf1">
       <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="293" id="S7.F6.sf1.g1" src="/html/2308.12086/assets/figures/avg_win_no_def_small.png" width="598"/>
       <figcaption class="ltx_caption ltx_centering">
        <span class="ltx_tag ltx_tag_figure">
         <span class="ltx_text" id="S7.F6.sf1.2.1.1" style="font-size:90%;">
          (a)
         </span>
        </span>
        <span class="ltx_text" id="S7.F6.sf1.3.2" style="font-size:90%;">
         No defender
        </span>
       </figcaption>
      </figure>
     </div>
     <div class="ltx_flex_cell ltx_flex_size_2">
      <figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S7.F6.sf2">
       <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="293" id="S7.F6.sf2.g1" src="/html/2308.12086/assets/figures/avg_win_rate_def_small.png" width="598"/>
       <figcaption class="ltx_caption ltx_centering">
        <span class="ltx_tag ltx_tag_figure">
         <span class="ltx_text" id="S7.F6.sf2.2.1.1" style="font-size:90%;">
          (b)
         </span>
        </span>
        <span class="ltx_text" id="S7.F6.sf2.3.2" style="font-size:90%;">
         With stochastic-threshold defender
        </span>
       </figcaption>
      </figure>
     </div>
    </div>
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_figure">
      <span class="ltx_text" id="S7.F6.2.1.1" style="font-size:90%;">
       Figure 6
      </span>
      .
     </span>
     <span class="ltx_text" id="S7.F6.3.2" style="font-size:90%;">
      For the NetSecGame small scenario, win rates for different numbers of max_steps.
     </span>
    </figcaption>
   </figure>
   <div class="ltx_para" id="S7.SS2.p1">
    <p class="ltx_p" id="S7.SS2.p1.1">
     The win rates of all the agents in the small scenario with and without a defender are presented in Figure
     <a class="ltx_ref" href="#S7.F6" title="Figure 6 ‣ 7.2. NetSecGame Small Scenario ‣ 7. Results ‣ Out of the Cage: How Stochastic Parrots Win in Cyber Security Environments">
      <span class="ltx_text ltx_ref_tag">
       6
      </span>
     </a>
     . The figures show the results in different max_steps settings. In the scenario without a defender, the ReAct agent wins 100% of the time in the 60 and 100 max_steps setting and outperforms the baselines clearly. When the max steps are limited to 30, it wins 80% of the time, which is still the best performance. The random agent with the no-repeat heuristic shows that, given enough steps, it eventually wins.
    </p>
   </div>
   <figure class="ltx_table" id="S7.T2">
    <figcaption class="ltx_caption">
     <span class="ltx_tag ltx_tag_table">
      <span class="ltx_text" id="S7.T2.2.1.1" style="font-size:90%;">
       Table 2
      </span>
      .
     </span>
     <span class="ltx_text" id="S7.T2.3.2" style="font-size:90%;">
      For the NetSecGame small scenario, average win rates, returns, and detection rates of all agents with random target per episode. With a maximum of 60 max_steps per episode and 30 episodes of repetition in LLM-based agents.
     </span>
    </figcaption>
    <table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S7.T2.4">
     <thead class="ltx_thead">
      <tr class="ltx_tr" id="S7.T2.4.1.1">
       <th class="ltx_td ltx_th ltx_th_column ltx_border_tt" id="S7.T2.4.1.1.1">
       </th>
       <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" colspan="2" id="S7.T2.4.1.1.2">
        No Defender
       </th>
       <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="3" id="S7.T2.4.1.1.3">
        Defender
       </th>
      </tr>
      <tr class="ltx_tr" id="S7.T2.4.2.2">
       <th class="ltx_td ltx_align_left ltx_th ltx_th_column" id="S7.T2.4.2.2.1">
        Agent
       </th>
       <th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S7.T2.4.2.2.2">
        Win Rate
       </th>
       <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r" id="S7.T2.4.2.2.3">
        Return
       </th>
       <th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S7.T2.4.2.2.4">
        Win Rate
       </th>
       <th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S7.T2.4.2.2.5">
        Return
       </th>
       <th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S7.T2.4.2.2.6">
        Detection Rate
       </th>
      </tr>
     </thead>
     <tbody class="ltx_tbody">
      <tr class="ltx_tr" id="S7.T2.4.3.1">
       <td class="ltx_td ltx_align_left ltx_border_t" id="S7.T2.4.3.1.1">
        Random
       </td>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S7.T2.4.3.1.2">
        13.21%
       </td>
       <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S7.T2.4.3.1.3">
        -37.18
       </td>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S7.T2.4.3.1.4">
        2.99%
       </td>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S7.T2.4.3.1.5">
        -64.30
       </td>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S7.T2.4.3.1.6">
        18.68%
       </td>
      </tr>
      <tr class="ltx_tr" id="S7.T2.4.4.2">
       <td class="ltx_td ltx_align_left" id="S7.T2.4.4.2.1">
        Random (no-repeat)
       </td>
       <td class="ltx_td ltx_align_center" id="S7.T2.4.4.2.2">
        54.76%
       </td>
       <td class="ltx_td ltx_align_center ltx_border_r" id="S7.T2.4.4.2.3">
        8.47
       </td>
       <td class="ltx_td ltx_align_center" id="S7.T2.4.4.2.4">
        16.28%
       </td>
       <td class="ltx_td ltx_align_center" id="S7.T2.4.4.2.5">
        -43.49
       </td>
       <td class="ltx_td ltx_align_center" id="S7.T2.4.4.2.6">
        <span class="ltx_text ltx_font_bold" id="S7.T2.4.4.2.6.1">
         15.81%
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="S7.T2.4.5.3">
       <td class="ltx_td ltx_align_left" id="S7.T2.4.5.3.1">
        Q-learning
       </td>
       <td class="ltx_td ltx_align_center" id="S7.T2.4.5.3.2">
        67.41%
       </td>
       <td class="ltx_td ltx_align_center ltx_border_r" id="S7.T2.4.5.3.3">
        47.55
       </td>
       <td class="ltx_td ltx_align_center" id="S7.T2.4.5.3.4">
        77.96%
       </td>
       <td class="ltx_td ltx_align_center" id="S7.T2.4.5.3.5">
        54.91
       </td>
       <td class="ltx_td ltx_align_center" id="S7.T2.4.5.3.6">
        16.28%
       </td>
      </tr>
      <tr class="ltx_tr" id="S7.T2.4.6.4">
       <td class="ltx_td ltx_align_left ltx_border_bb" id="S7.T2.4.6.4.1">
        ReAct
       </td>
       <td class="ltx_td ltx_align_center ltx_border_bb" id="S7.T2.4.6.4.2">
        <span class="ltx_text ltx_font_bold" id="S7.T2.4.6.4.2.1">
         100.0
        </span>
        %
       </td>
       <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S7.T2.4.6.4.3">
        <span class="ltx_text ltx_font_bold" id="S7.T2.4.6.4.3.1">
         83.10
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_bb" id="S7.T2.4.6.4.4">
        <span class="ltx_text ltx_font_bold" id="S7.T2.4.6.4.4.1">
         83.33%
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_bb" id="S7.T2.4.6.4.5">
        <span class="ltx_text ltx_font_bold" id="S7.T2.4.6.4.5.1">
         58.83
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_bb" id="S7.T2.4.6.4.6">
        16.67%
       </td>
      </tr>
     </tbody>
    </table>
   </figure>
   <div class="ltx_para" id="S7.SS2.p2">
    <p class="ltx_p" id="S7.SS2.p2.1">
     In addition to the win rates, Table
     <a class="ltx_ref" href="#S7.T2" title="Table 2 ‣ 7.2. NetSecGame Small Scenario ‣ 7. Results ‣ Out of the Cage: How Stochastic Parrots Win in Cyber Security Environments">
      <span class="ltx_text ltx_ref_tag">
       2
      </span>
     </a>
     shows the average returns and detection rates on the small scenario with 60 max_steps. The average returns show a similar view as the win rates. Regarding detection rates, the lowest detection rate is reported by the random agent (15.81%), with the ReAct agent closely following at 16.67%
    </p>
   </div>
   <section class="ltx_subsubsection" id="S7.SS2.SSS1">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      7.2.1.
     </span>
     Human Performance
    </h4>
    <div class="ltx_para" id="S7.SS2.SSS1.p1">
     <p class="ltx_p" id="S7.SS2.SSS1.p1.1">
      In addition to autonomous agents, we conduct some exploratory tests with humans using the environment in interactive mode. Eight different participant were involved, with varying degrees of security background knowledge. The participants were asked to play the game a few times, and in total, we gathered measurements from 22 different sessions. While this was an informal evaluation, it gives us some indicative numbers of how well the different agents are performing.
     </p>
    </div>
    <div class="ltx_para" id="S7.SS2.SSS1.p2">
     <p class="ltx_p" id="S7.SS2.SSS1.p2.1">
      The humans solved the small environment without a defender with an average of 17.68 moves and an average return of 82.32, comparable to the ReAct agent’s performance. Because they played more than once, they had the opportunity to learn from some patterns in the environment even though the IPs of the nodes and the goals were randomized. For example, if they found a service (e.g., lighttpd) when scanning a host, they realized this was the subnet of interest. These types of patterns allowed them to find the solution in fewer steps.
     </p>
    </div>
   </section>
  </section>
  <section class="ltx_subsection" id="S7.SS3">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     7.3.
    </span>
    NetSecGame Full Scenario
   </h3>
   <figure class="ltx_figure" id="S7.F7">
    <div class="ltx_flex_figure">
     <div class="ltx_flex_cell ltx_flex_size_2">
      <figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S7.F7.sf1">
       <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="293" id="S7.F7.sf1.g1" src="/html/2308.12086/assets/figures/avg_win_no_def_full.png" width="598"/>
       <figcaption class="ltx_caption ltx_centering">
        <span class="ltx_tag ltx_tag_figure">
         <span class="ltx_text" id="S7.F7.sf1.2.1.1" style="font-size:90%;">
          (a)
         </span>
        </span>
        <span class="ltx_text" id="S7.F7.sf1.3.2" style="font-size:90%;">
         No defender
        </span>
       </figcaption>
      </figure>
     </div>
     <div class="ltx_flex_cell ltx_flex_size_2">
      <figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S7.F7.sf2">
       <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="293" id="S7.F7.sf2.g1" src="/html/2308.12086/assets/figures/avg_win_def_full.png" width="598"/>
       <figcaption class="ltx_caption ltx_centering">
        <span class="ltx_tag ltx_tag_figure">
         <span class="ltx_text" id="S7.F7.sf2.2.1.1" style="font-size:90%;">
          (b)
         </span>
        </span>
        <span class="ltx_text" id="S7.F7.sf2.3.2" style="font-size:90%;">
         With stochastic-threshold defender
        </span>
       </figcaption>
      </figure>
     </div>
    </div>
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_figure">
      <span class="ltx_text" id="S7.F7.2.1.1" style="font-size:90%;">
       Figure 7
      </span>
      .
     </span>
     <span class="ltx_text" id="S7.F7.3.2" style="font-size:90%;">
      For the NetSecGame full scenario, win rates in different numbers of max_steps.
     </span>
    </figcaption>
   </figure>
   <figure class="ltx_table" id="S7.T3">
    <figcaption class="ltx_caption">
     <span class="ltx_tag ltx_tag_table">
      <span class="ltx_text" id="S7.T3.2.1.1" style="font-size:90%;">
       Table 3
      </span>
      .
     </span>
     <span class="ltx_text" id="S7.T3.3.2" style="font-size:90%;">
      Avg returns and detection rates of all agents in the full scenario with random target per episode. With maximum of 60 max_steps per episode and 30 episodes of repetition in LLM-based agents.
     </span>
    </figcaption>
    <table class="ltx_tabular ltx_align_middle" id="S7.T3.4">
     <tbody class="ltx_tbody">
      <tr class="ltx_tr" id="S7.T3.4.1.1">
       <td class="ltx_td ltx_border_tt" id="S7.T3.4.1.1.1">
       </td>
       <td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="2" id="S7.T3.4.1.1.2">
        No Defender
       </td>
       <td class="ltx_td ltx_align_center ltx_border_tt" colspan="3" id="S7.T3.4.1.1.3">
        Defender
       </td>
      </tr>
      <tr class="ltx_tr" id="S7.T3.4.2.2">
       <td class="ltx_td ltx_align_left" id="S7.T3.4.2.2.1">
        Agent
       </td>
       <td class="ltx_td ltx_align_center" id="S7.T3.4.2.2.2">
        Win Rate
       </td>
       <td class="ltx_td ltx_align_center ltx_border_r" id="S7.T3.4.2.2.3">
        Return
       </td>
       <td class="ltx_td ltx_align_center" id="S7.T3.4.2.2.4">
        Win Rate
       </td>
       <td class="ltx_td ltx_align_center" id="S7.T3.4.2.2.5">
        Return
       </td>
       <td class="ltx_td ltx_align_center" id="S7.T3.4.2.2.6">
        Detection Rate
       </td>
      </tr>
      <tr class="ltx_tr" id="S7.T3.4.3.3">
       <td class="ltx_td ltx_align_left ltx_border_t" id="S7.T3.4.3.3.1">
        Random
       </td>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S7.T3.4.3.3.2">
        19.43%
       </td>
       <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S7.T3.4.3.3.3">
        -44.46
       </td>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S7.T3.4.3.3.4">
        2.18%
       </td>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S7.T3.4.3.3.5">
        65.11
       </td>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S7.T3.4.3.3.6">
        93.95%
       </td>
      </tr>
      <tr class="ltx_tr" id="S7.T3.4.4.4">
       <td class="ltx_td ltx_align_left" id="S7.T3.4.4.4.1">
        Random (no-repeat)
       </td>
       <td class="ltx_td ltx_align_center" id="S7.T3.4.4.4.2">
        41.32%
       </td>
       <td class="ltx_td ltx_align_center ltx_border_r" id="S7.T3.4.4.4.3">
        -9.19
       </td>
       <td class="ltx_td ltx_align_center" id="S7.T3.4.4.4.4">
        9.63%
       </td>
       <td class="ltx_td ltx_align_center" id="S7.T3.4.4.4.5">
        -52.96
       </td>
       <td class="ltx_td ltx_align_center" id="S7.T3.4.4.4.6">
        83.63%
       </td>
      </tr>
      <tr class="ltx_tr" id="S7.T3.4.5.5">
       <td class="ltx_td ltx_align_left" id="S7.T3.4.5.5.1">
        Q-learning
       </td>
       <td class="ltx_td ltx_align_center" id="S7.T3.4.5.5.2">
        58.74%
       </td>
       <td class="ltx_td ltx_align_center ltx_border_r" id="S7.T3.4.5.5.3">
        48.0
       </td>
       <td class="ltx_td ltx_align_center" id="S7.T3.4.5.5.4">
        <span class="ltx_text ltx_font_bold" id="S7.T3.4.5.5.4.1">
         71.0
        </span>
        %
       </td>
       <td class="ltx_td ltx_align_center" id="S7.T3.4.5.5.5">
        <span class="ltx_text ltx_font_bold" id="S7.T3.4.5.5.5.1">
         45.38
        </span>
       </td>
       <td class="ltx_td ltx_align_center" id="S7.T3.4.5.5.6">
        <span class="ltx_text ltx_font_bold" id="S7.T3.4.5.5.6.1">
         24.58
        </span>
        %
       </td>
      </tr>
      <tr class="ltx_tr" id="S7.T3.4.6.6">
       <td class="ltx_td ltx_align_left ltx_border_bb" id="S7.T3.4.6.6.1">
        ReAct
       </td>
       <td class="ltx_td ltx_align_center ltx_border_bb" id="S7.T3.4.6.6.2">
        <span class="ltx_text ltx_font_bold" id="S7.T3.4.6.6.2.1">
         100.0%
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S7.T3.4.6.6.3">
        <span class="ltx_text ltx_font_bold" id="S7.T3.4.6.6.3.1">
         77.13
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_bb" id="S7.T3.4.6.6.4">
        50.0%
       </td>
       <td class="ltx_td ltx_align_center ltx_border_bb" id="S7.T3.4.6.6.5">
        8.20
       </td>
       <td class="ltx_td ltx_align_center ltx_border_bb" id="S7.T3.4.6.6.6">
        43.33%
       </td>
      </tr>
     </tbody>
    </table>
   </figure>
   <div class="ltx_para" id="S7.SS3.p1">
    <p class="ltx_p" id="S7.SS3.p1.1">
     The win rates of all the agents in the full scenario with and without a defender are presented in Figure
     <a class="ltx_ref" href="#S7.F6" title="Figure 6 ‣ 7.2. NetSecGame Small Scenario ‣ 7. Results ‣ Out of the Cage: How Stochastic Parrots Win in Cyber Security Environments">
      <span class="ltx_text ltx_ref_tag">
       6
      </span>
     </a>
     . The figures show the results in different max_steps settings. In the scenario without a defender, the ReAct agent wins 100% of the time in the 60 and 100 max_steps setting. However, when the defender is present, the Q-learning agent has the best performance, and it seems that the defender detections help the agent to learn a good policy, most possibly learning to avoid repetitions. This finding is interesting for designing better defenders in the future. It highlights that when the attacker can learn from past episodes, they can learn to avoid ”bad” behaviors.
    </p>
   </div>
   <div class="ltx_para" id="S7.SS3.p2">
    <p class="ltx_p" id="S7.SS3.p2.1">
     The ReAct agent maintains a winning rate of 50% for so max_steps or more and positive returns. (Table
     <a class="ltx_ref" href="#S7.T3" title="Table 3 ‣ 7.3. NetSecGame Full Scenario ‣ 7. Results ‣ Out of the Cage: How Stochastic Parrots Win in Cyber Security Environments">
      <span class="ltx_text ltx_ref_tag">
       3
      </span>
     </a>
     ). It has to be noted that none of the LLM-based agent prompts contain instructions tailored to avoid the defender. For example, the ReAct agent sometimes follows a breadth-first approach where it scans all the hosts for running services, which can trigger the stochastic-threshold defender.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S7.SS4">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     7.4.
    </span>
    CyberBattleSim Chain Scenario
   </h3>
   <figure class="ltx_table" id="S7.T4">
    <figcaption class="ltx_caption">
     <span class="ltx_tag ltx_tag_table">
      <span class="ltx_text" id="S7.T4.2.1.1" style="font-size:90%;">
       Table 4
      </span>
      .
     </span>
     <span class="ltx_text" id="S7.T4.3.2" style="font-size:90%;">
      Average win rate, return, and episode steps of all agents in the chain scenario of the CyberBattleSim environment
     </span>
    </figcaption>
    <table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S7.T4.4">
     <thead class="ltx_thead">
      <tr class="ltx_tr" id="S7.T4.4.1.1">
       <th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S7.T4.4.1.1.1">
        Agent
       </th>
       <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S7.T4.4.1.1.2">
        Win Rate
       </th>
       <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S7.T4.4.1.1.3">
        Return
       </th>
       <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S7.T4.4.1.1.4">
        Episode steps
       </th>
      </tr>
     </thead>
     <tbody class="ltx_tbody">
      <tr class="ltx_tr" id="S7.T4.4.2.1">
       <th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S7.T4.4.2.1.1">
        Random
       </th>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S7.T4.4.2.1.2">
        0.0%
       </td>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S7.T4.4.2.1.3">
        -726.98
       </td>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S7.T4.4.2.1.4">
        100.0
       </td>
      </tr>
      <tr class="ltx_tr" id="S7.T4.4.3.2">
       <th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S7.T4.4.3.2.1">
        Random (credential)
       </th>
       <td class="ltx_td ltx_align_center" id="S7.T4.4.3.2.2">
        0.0%
       </td>
       <td class="ltx_td ltx_align_center" id="S7.T4.4.3.2.3">
        -998.25
       </td>
       <td class="ltx_td ltx_align_center" id="S7.T4.4.3.2.4">
        100.0
       </td>
      </tr>
      <tr class="ltx_tr" id="S7.T4.4.4.3">
       <th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S7.T4.4.4.3.1">
        DQN
       </th>
       <td class="ltx_td ltx_align_center" id="S7.T4.4.4.3.2">
        100.0%
       </td>
       <td class="ltx_td ltx_align_center" id="S7.T4.4.4.3.3">
        6154.2
       </td>
       <td class="ltx_td ltx_align_center" id="S7.T4.4.4.3.4">
        22.3
       </td>
      </tr>
      <tr class="ltx_tr" id="S7.T4.4.5.4">
       <th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S7.T4.4.5.4.1">
        LLM
       </th>
       <td class="ltx_td ltx_align_center ltx_border_bb" id="S7.T4.4.5.4.2">
        100.0%
       </td>
       <td class="ltx_td ltx_align_center ltx_border_bb" id="S7.T4.4.5.4.3">
        6160.7
       </td>
       <td class="ltx_td ltx_align_center ltx_border_bb" id="S7.T4.4.5.4.4">
        31.0
       </td>
      </tr>
     </tbody>
    </table>
   </figure>
   <div class="ltx_para" id="S7.SS4.p1">
    <p class="ltx_p" id="S7.SS4.p1.1">
     The results in terms of win rate, return, and episode steps for all agents tested in the ”chain” scenario are presented in Table
     <a class="ltx_ref" href="#S7.T4" title="Table 4 ‣ 7.4. CyberBattleSim Chain Scenario ‣ 7. Results ‣ Out of the Cage: How Stochastic Parrots Win in Cyber Security Environments">
      <span class="ltx_text ltx_ref_tag">
       4
      </span>
     </a>
     . The numbers are averages over ten different runs. The LLM with GPT-4 and a simple ”one-shot” prompt managed to win all runs with relatively low required steps. Only the DQN baseline manage to win in all trials. The random agents with and without the heuristic manage only if the number of maximum iterations is higher than 1000, while the LLM and the DQN agents perform well even if the number of max iterations is set to 100.
    </p>
   </div>
   <div class="ltx_para" id="S7.SS4.p2">
    <p class="ltx_p" id="S7.SS4.p2.1">
     Another interesting ”quirk” of the ”chain” scenario is that the minimum number of steps required for solving the environment is 22, corresponding to a return (sum of all rewards in the episode) of 6154. However, the agents can score higher than that. To win the game with the minimum amount of actions, the agents need only to run a local exploit, find new credentials, attack the next node, and repeat this sequence for all hosts in the network. The DQN agent learns to do precisely that and the LLM agent is also very close to this optimal behavior with 31 steps on average but a slightly higher average return.
    </p>
   </div>
  </section>
 </section>
 <section class="ltx_section" id="S8">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    8.
   </span>
   Limitations and Future Work
  </h2>
  <div class="ltx_para" id="S8.p1">
   <p class="ltx_p" id="S8.p1.1">
    We discovered several issues and limitations in their behavior during the design and experimentation with pre-trained LLMs as agents.
   </p>
  </div>
  <section class="ltx_paragraph" id="S8.SS0.SSS0.Px1">
   <h5 class="ltx_title ltx_title_paragraph">
    Hallucination
   </h5>
   <div class="ltx_para" id="S8.SS0.SSS0.Px1.p1">
    <p class="ltx_p" id="S8.SS0.SSS0.Px1.p1.1">
     LLMs, especially GPT-3 or other open source models we tested, had the tendency to propose actions using objects that were not described in the current state of the environment, including new scanning new IPs or proposing to exfiltrate non-existent data.
    </p>
   </div>
  </section>
  <section class="ltx_paragraph" id="S8.SS0.SSS0.Px2">
   <h5 class="ltx_title ltx_title_paragraph">
    Invalid or repeated actions
   </h5>
   <div class="ltx_para" id="S8.SS0.SSS0.Px2.p1">
    <p class="ltx_p" id="S8.SS0.SSS0.Px2.p1.1">
     GPT-3.5 tended to repeat actions even though the prior actions were given as part of the memory. GPT-4 and GPT-3.5-turbo sometimes responded with a verbose style, trying to explain the action before providing it in the proper format. This could be alleviated by using some heuristic approach that does not allow repetition of actions
     <cite class="ltx_cite ltx_citemacro_citep">
      (Du et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib10" title="">
       2023
      </a>
      )
     </cite>
     .
    </p>
   </div>
  </section>
  <section class="ltx_paragraph" id="S8.SS0.SSS0.Px3">
   <h5 class="ltx_title ltx_title_paragraph">
    Cost
   </h5>
   <div class="ltx_para" id="S8.SS0.SSS0.Px3.p1">
    <p class="ltx_p" id="S8.SS0.SSS0.Px3.p1.1">
     The GPT-4 API is quite expensive and 30x more expensive that GPT-3.5. Unfortunately, at the moment, it seems to be the only model capable of solving multiple scenarios without any further fine-tuning or re-training. In the future, we fine-tune open-source models to perform better to our specific tasks.
    </p>
   </div>
  </section>
  <section class="ltx_paragraph" id="S8.SS0.SSS0.Px4">
   <h5 class="ltx_title ltx_title_paragraph">
    Instability
   </h5>
   <div class="ltx_para" id="S8.SS0.SSS0.Px4.p1">
    <p class="ltx_p" id="S8.SS0.SSS0.Px4.p1.1">
     Black-box commercial models can drift in specialized tasks
     <cite class="ltx_cite ltx_citemacro_citep">
      (Chen et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib5" title="">
       2023
      </a>
      )
     </cite>
     . The OpenAI models are being fine-tuned, and new versions are released every few months. This creates a reproducibility issue for researchers. Again, using open-source models with or without fine-tuning may be a better avenue since models adapted to specific tasks can also be released artifacts.
    </p>
   </div>
  </section>
  <section class="ltx_paragraph" id="S8.SS0.SSS0.Px5">
   <h5 class="ltx_title ltx_title_paragraph">
    Prompt creation
   </h5>
   <div class="ltx_para" id="S8.SS0.SSS0.Px5.p1">
    <p class="ltx_p" id="S8.SS0.SSS0.Px5.p1.1">
     Creating a prompt is more of an art than an exact science. The process may be faster than training, and it certainly lowers the barrier to entry for some problems. However, some models are susceptible to the input. A small typo or a change in the order of the words in a prompt can lead to different results. This behavior makes it hard to optimize and evaluate the performance of the LLMs and the prompt design. Model evaluation and monitoring is a relatively unexplored area from a research and engineering standpoint.
    </p>
   </div>
  </section>
  <section class="ltx_paragraph" id="S8.SS0.SSS0.Px6">
   <h5 class="ltx_title ltx_title_paragraph">
    Learning
   </h5>
   <div class="ltx_para" id="S8.SS0.SSS0.Px6.p1">
    <p class="ltx_p" id="S8.SS0.SSS0.Px6.p1.1">
     The agents in their current state do not learn from their past experiences. In each new episode, the agent starts solving the task from scratch. In the future, we plan to address this by summarizing the actions of each episode and using this summary in the next episode. Another idea from
     <cite class="ltx_cite ltx_citemacro_citep">
      (Wang et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib36" title="">
       2023b
      </a>
      )
     </cite>
     , especially for agents that aim to solve different tasks within the same environment, would be to summarize and store the different skills that can be used or combined to solve more complex tasks.
    </p>
   </div>
   <div class="ltx_para" id="S8.SS0.SSS0.Px6.p2">
    <p class="ltx_p" id="S8.SS0.SSS0.Px6.p2.1">
     In terms of the NetSecGame environment, at the moment, there are several limitations that we are planning to address in future work. The first is adding a trainable defender that would allow for richer scenarios from the defensive side of network security. The second element we plan to add is multi-agent capabilities so that different agents can interact and train simultaneously. Finally, we plan to integrate the environment to existing solutions such as
     <cite class="ltx_cite ltx_citemacro_citep">
      (Drašar et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib9" title="">
       2020
      </a>
      )
     </cite>
     that will allow the experiments to be tested in emulation mode using virtual machines and real attacking and defensive tools.
    </p>
   </div>
  </section>
 </section>
 <section class="ltx_section" id="S9">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    9.
   </span>
   Conclusions
  </h2>
  <div class="ltx_para" id="S9.p1">
   <p class="ltx_p" id="S9.p1.1">
    This work designed and presented cybersecurity agents that use pre-trained large language models (LLMs) and can solve scenarios in cybersecurity reinforcement learning environments. The ReAct agents solved both security environments without additional training steps and without learning between episodes, which significantly differs from traditional reinforcement learning agents that require thousands or millions of training episodes.
   </p>
  </div>
  <div class="ltx_para" id="S9.p2">
   <p class="ltx_p" id="S9.p2.1">
    At the same time, pre-trained LLMs have their limitations and cost associated with their use, including shortcomings in the reproducibility of results of black-box commercial models. However, we believe there is potential in using LLMs for high-level planning of autonomous cyber security agents. Future work should focus on increasingly complex scenarios and environments. As part of that effort, we presented a new, highly modular, and adaptable security environment (NetSecGame).
   </p>
  </div>
  <div class="ltx_para" id="S9.p3">
   <p class="ltx_p" id="S9.p3.1">
    As part of a realistic design, we designed and implemented a new cybersecurity RL environment called NetSecGame. It is designed to be realistic in the concepts while providing a high-level interaction API for agents. It implements a modular configuration for topologies, a dynamic goal definition, and a clear reward system, and it does not leak extra data to the agents. It also implements a defender for the training and testing of agents in adversarial settings.
   </p>
  </div>
  <div class="ltx_acknowledgements">
   <h6 class="ltx_title ltx_title_acknowledgements">
    Acknowledgements.
   </h6>
   The authors acknowledge support from the Strategic Support for the Development of Security Research in the Czech Republic 2019–2025 (IMPAKT 1) program, by the Ministry of the Interior of the Czech Republic under No. VJ02010020 – AI-Dojo: Multi-agent testbed for the research and testing of AI-driven cybersecurity technologies.
  </div>
 </section>
 <section class="ltx_bibliography" id="bib">
  <h2 class="ltx_title ltx_title_bibliography">
   References
  </h2>
  <ul class="ltx_biblist">
   <li class="ltx_bibitem" id="bib.bib1">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     (1)
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib2">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Andrew et al
     <span class="ltx_text" id="bib.bib2.2.2.1">
      .
     </span>
     (2022)
    </span>
    <span class="ltx_bibblock">
     Alex Andrew, Sam
Spillard, Joshua Collyer, and Neil
Dhir. 2022.
    </span>
    <span class="ltx_bibblock">
     Developing Optimal Causal Cyber-Defence
Agents via Cyber Security Simulation.
    </span>
    <span class="ltx_bibblock">
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.48550/arXiv.2207.12355" target="_blank" title="">
      https://doi.org/10.48550/arXiv.2207.12355
     </a>
    </span>
    <span class="ltx_bibblock">
     arXiv:2207.12355 [cs, stat].
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib3">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Brockman et al
     <span class="ltx_text" id="bib.bib3.2.2.1">
      .
     </span>
     (2016)
    </span>
    <span class="ltx_bibblock">
     Greg Brockman, Vicki
Cheung, Ludwig Pettersson, Jonas
Schneider, John Schulman, Jie Tang,
and Wojciech Zaremba. 2016.
    </span>
    <span class="ltx_bibblock">
     OpenAI Gym.
    </span>
    <span class="ltx_bibblock">
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.48550/arXiv.1606.01540" target="_blank" title="">
      https://doi.org/10.48550/arXiv.1606.01540
     </a>
    </span>
    <span class="ltx_bibblock">
     arXiv:1606.01540 [cs].
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib4">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Brown et al
     <span class="ltx_text" id="bib.bib4.2.2.1">
      .
     </span>
     (2020)
    </span>
    <span class="ltx_bibblock">
     Tom Brown, Benjamin Mann,
Nick Ryder, Melanie Subbiah,
Jared D Kaplan, Prafulla Dhariwal,
Arvind Neelakantan, Pranav Shyam,
Girish Sastry, Amanda Askell,
Sandhini Agarwal, Ariel Herbert-Voss,
Gretchen Krueger, Tom Henighan,
Rewon Child, Aditya Ramesh,
Daniel Ziegler, Jeffrey Wu,
Clemens Winter, Chris Hesse,
Mark Chen, Eric Sigler,
Mateusz Litwin, Scott Gray,
Benjamin Chess, Jack Clark,
Christopher Berner, Sam McCandlish,
Alec Radford, Ilya Sutskever, and
Dario Amodei. 2020.
    </span>
    <span class="ltx_bibblock">
     Language Models are Few-Shot Learners. In
     <em class="ltx_emph ltx_font_italic" id="bib.bib4.3.1">
      Advances in Neural Information Processing
Systems
     </em>
     , Vol. 33. Curran
Associates, Inc., 1877–1901.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://proceedings.neurips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html" target="_blank" title="">
      https://proceedings.neurips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib5">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Chen et al
     <span class="ltx_text" id="bib.bib5.2.2.1">
      .
     </span>
     (2023)
    </span>
    <span class="ltx_bibblock">
     Lingjiao Chen, Matei
Zaharia, and James Zou.
2023.
    </span>
    <span class="ltx_bibblock">
     How is ChatGPT’s behavior changing over time?
    </span>
    <span class="ltx_bibblock">
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.48550/arXiv.2307.09009" target="_blank" title="">
      https://doi.org/10.48550/arXiv.2307.09009
     </a>
    </span>
    <span class="ltx_bibblock">
     arXiv:2307.09009 [cs].
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib6">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Chen et al
     <span class="ltx_text" id="bib.bib6.2.2.1">
      .
     </span>
     (2021)
    </span>
    <span class="ltx_bibblock">
     Mark Chen, Jerry Tworek,
Heewoo Jun, Qiming Yuan,
Henrique Ponde de Oliveira Pinto, Jared
Kaplan, Harri Edwards, Yuri Burda,
Nicholas Joseph, Greg Brockman,
Alex Ray, Raul Puri,
Gretchen Krueger, Michael Petrov,
Heidy Khlaaf, Girish Sastry,
Pamela Mishkin, Brooke Chan,
Scott Gray, Nick Ryder,
Mikhail Pavlov, Alethea Power,
Lukasz Kaiser, Mohammad Bavarian,
Clemens Winter, Philippe Tillet,
Felipe Petroski Such, Dave Cummings,
Matthias Plappert, Fotios Chantzis,
Elizabeth Barnes, Ariel Herbert-Voss,
William Hebgen Guss, Alex Nichol,
Alex Paino, Nikolas Tezak,
Jie Tang, Igor Babuschkin,
Suchir Balaji, Shantanu Jain,
William Saunders, Christopher Hesse,
Andrew N. Carr, Jan Leike,
Josh Achiam, Vedant Misra,
Evan Morikawa, Alec Radford,
Matthew Knight, Miles Brundage,
Mira Murati, Katie Mayer,
Peter Welinder, Bob McGrew,
Dario Amodei, Sam McCandlish,
Ilya Sutskever, and Wojciech Zaremba.
2021.
    </span>
    <span class="ltx_bibblock">
     Evaluating Large Language Models Trained on
Code.
    </span>
    <span class="ltx_bibblock">
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.48550/arXiv.2107.03374" target="_blank" title="">
      https://doi.org/10.48550/arXiv.2107.03374
     </a>
    </span>
    <span class="ltx_bibblock">
     arXiv:2107.03374 [cs].
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib7">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Chen and Liao (2022)
    </span>
    <span class="ltx_bibblock">
     Song Chen and Hai
Liao. 2022.
    </span>
    <span class="ltx_bibblock">
     BERT-Log: Anomaly Detection for System
Logs Based on Pre-trained Language Model.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">
      Applied Artificial Intelligence
     </em>
     36, 1 (Dec.
2022), 2145642.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1080/08839514.2022.2145642" target="_blank" title="">
      https://doi.org/10.1080/08839514.2022.2145642
     </a>
    </span>
    <span class="ltx_bibblock">
     Publisher: Taylor &amp; Francis _eprint:
https://doi.org/10.1080/08839514.2022.2145642.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib8">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Devlin et al
     <span class="ltx_text" id="bib.bib8.2.2.1">
      .
     </span>
     (2019)
    </span>
    <span class="ltx_bibblock">
     Jacob Devlin, Ming-Wei
Chang, Kenton Lee, and Kristina
Toutanova. 2019.
    </span>
    <span class="ltx_bibblock">
     BERT: Pre-training of Deep Bidirectional
Transformers for Language Understanding.
    </span>
    <span class="ltx_bibblock">
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.48550/arXiv.1810.04805" target="_blank" title="">
      https://doi.org/10.48550/arXiv.1810.04805
     </a>
    </span>
    <span class="ltx_bibblock">
     arXiv:1810.04805 [cs].
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib9">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Drašar et al
     <span class="ltx_text" id="bib.bib9.2.2.1">
      .
     </span>
     (2020)
    </span>
    <span class="ltx_bibblock">
     Martin Drašar, Stephen
Moskal, Shanchieh Yang, and Pavol
Zat’ko. 2020.
    </span>
    <span class="ltx_bibblock">
     Session-level Adversary Intent-Driven
Cyberattack Simulator. In
     <em class="ltx_emph ltx_font_italic" id="bib.bib9.3.1">
      2020 IEEE/ACM
24th International Symposium on Distributed Simulation and Real
Time Applications (DS-RT)
     </em>
     . 1–9.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1109/DS-RT50469.2020.9213690" target="_blank" title="">
      https://doi.org/10.1109/DS-RT50469.2020.9213690
     </a>
    </span>
    <span class="ltx_bibblock">
     ISSN: 1550-6525.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib10">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Du et al
     <span class="ltx_text" id="bib.bib10.2.2.1">
      .
     </span>
     (2023)
    </span>
    <span class="ltx_bibblock">
     Yuqing Du, Olivia
Watkins, Zihan Wang, Cédric Colas,
Trevor Darrell, Pieter Abbeel,
Abhishek Gupta, and Jacob Andreas.
2023.
    </span>
    <span class="ltx_bibblock">
     Guiding Pretraining in Reinforcement Learning
with Large Language Models. In
     <em class="ltx_emph ltx_font_italic" id="bib.bib10.3.1">
      Proceedings
of the 40th International Conference on Machine Learning
     </em>
     .
Honolulu, Hawaii, USA.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib11">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Elderman et al
     <span class="ltx_text" id="bib.bib11.2.2.1">
      .
     </span>
     (2017)
    </span>
    <span class="ltx_bibblock">
     Richard Elderman, Leon
J. J. Pater, Albert S. Thie, Madalina
M. Drugan, and Marco M. Wiering.
2017.
    </span>
    <span class="ltx_bibblock">
     Adversarial Reinforcement Learning in a Cyber
Security Simulation:. In
     <em class="ltx_emph ltx_font_italic" id="bib.bib11.3.1">
      Proceedings of the
9th International Conference on Agents and Artificial
Intelligence
     </em>
     . SCITEPRESS - Science and Technology
Publications, Porto, Portugal, 559–566.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.5220/0006197105590566" target="_blank" title="">
      https://doi.org/10.5220/0006197105590566
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib12">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Hafner (2022)
    </span>
    <span class="ltx_bibblock">
     Danijar Hafner.
2022.
    </span>
    <span class="ltx_bibblock">
     Benchmarking the Spectrum of Agent
Capabilities.
    </span>
    <span class="ltx_bibblock">
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.48550/arXiv.2109.06780" target="_blank" title="">
      https://doi.org/10.48550/arXiv.2109.06780
     </a>
    </span>
    <span class="ltx_bibblock">
     arXiv:2109.06780 [cs].
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib13">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Hammar and Stadler (2020)
    </span>
    <span class="ltx_bibblock">
     Kim Hammar and Rolf
Stadler. 2020.
    </span>
    <span class="ltx_bibblock">
     Finding Effective Security Strategies through
Reinforcement Learning and Self-Play. In
     <em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">
      2020 16th International Conference on Network
and Service Management (CNSM)
     </em>
     . 1–9.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.23919/CNSM50824.2020.9269092" target="_blank" title="">
      https://doi.org/10.23919/CNSM50824.2020.9269092
     </a>
    </span>
    <span class="ltx_bibblock">
     ISSN: 2165-963X.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib14">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Happe and Cito (2023)
    </span>
    <span class="ltx_bibblock">
     Andreas Happe and
Jürgen Cito. 2023.
    </span>
    <span class="ltx_bibblock">
     Getting pwn’d by AI: Penetration Testing with
Large Language Models.
    </span>
    <span class="ltx_bibblock">
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3611643.3613083" target="_blank" title="">
      https://doi.org/10.1145/3611643.3613083
     </a>
    </span>
    <span class="ltx_bibblock">
     arXiv:2308.00121 [cs].
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib15">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Janisch et al
     <span class="ltx_text" id="bib.bib15.2.2.1">
      .
     </span>
     (2023)
    </span>
    <span class="ltx_bibblock">
     Jaromír Janisch, Tomáš
Pevný, and Viliam Lisý.
2023.
    </span>
    <span class="ltx_bibblock">
     NASimEmu: Network Attack Simulator &amp;
Emulator for Training Agents Generalizing to Novel Scenarios.
    </span>
    <span class="ltx_bibblock">
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.48550/arXiv.2305.17246" target="_blank" title="">
      https://doi.org/10.48550/arXiv.2305.17246
     </a>
    </span>
    <span class="ltx_bibblock">
     arXiv:2305.17246 [cs].
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib16">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Kant et al
     <span class="ltx_text" id="bib.bib16.2.2.1">
      .
     </span>
     (2022)
    </span>
    <span class="ltx_bibblock">
     Yash Kant, Arun
Ramachandran, Sriram Yenamandra, Igor
Gilitschenski, Dhruv Batra, Andrew Szot,
and Harsh Agrawal. 2022.
    </span>
    <span class="ltx_bibblock">
     Housekeep: Tidying Virtual Households Using
Commonsense Reasoning. In
     <em class="ltx_emph ltx_font_italic" id="bib.bib16.3.1">
      Computer Vision
– ECCV 2022
     </em>
     <em class="ltx_emph ltx_font_italic" id="bib.bib16.4.2">
      (Lecture Notes in Computer
Science)
     </em>
     , Shai Avidan,
Gabriel Brostow, Moustapha Cissé,
Giovanni Maria Farinella, and Tal
Hassner (Eds.). Springer Nature Switzerland,
Cham, 355–373.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1007/978-3-031-19842-7_21" target="_blank" title="">
      https://doi.org/10.1007/978-3-031-19842-7_21
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib17">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Kojima et al
     <span class="ltx_text" id="bib.bib17.2.2.1">
      .
     </span>
     (2023)
    </span>
    <span class="ltx_bibblock">
     Takeshi Kojima,
Shixiang Shane Gu, Machel Reid,
Yutaka Matsuo, and Yusuke Iwasawa.
2023.
    </span>
    <span class="ltx_bibblock">
     Large Language Models are Zero-Shot
Reasoners.
    </span>
    <span class="ltx_bibblock">
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.48550/arXiv.2205.11916" target="_blank" title="">
      https://doi.org/10.48550/arXiv.2205.11916
     </a>
    </span>
    <span class="ltx_bibblock">
     arXiv:2205.11916 [cs].
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib18">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Lewis et al
     <span class="ltx_text" id="bib.bib18.2.2.1">
      .
     </span>
     (2019)
    </span>
    <span class="ltx_bibblock">
     Mike Lewis, Yinhan Liu,
Naman Goyal, Marjan Ghazvininejad,
Abdelrahman Mohamed, Omer Levy,
Ves Stoyanov, and Luke Zettlemoyer.
2019.
    </span>
    <span class="ltx_bibblock">
     BART: Denoising Sequence-to-Sequence
Pre-training for Natural Language Generation, Translation, and
Comprehension.
    </span>
    <span class="ltx_bibblock">
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.48550/arXiv.1910.13461" target="_blank" title="">
      https://doi.org/10.48550/arXiv.1910.13461
     </a>
    </span>
    <span class="ltx_bibblock">
     arXiv:1910.13461 [cs, stat].
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib19">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Li et al
     <span class="ltx_text" id="bib.bib19.2.2.1">
      .
     </span>
     (2023)
    </span>
    <span class="ltx_bibblock">
     Raymond Li, Loubna Ben
Allal, Yangtian Zi, Niklas Muennighoff,
Denis Kocetkov, Chenghao Mou,
Marc Marone, Christopher Akiki,
Jia Li, Jenny Chim, Qian
Liu, Evgenii Zheltonozhskii, Terry Yue
Zhuo, Thomas Wang, Olivier Dehaene,
Mishig Davaadorj, Joel Lamy-Poirier,
João Monteiro, Oleh Shliazhko,
Nicolas Gontier, Nicholas Meade,
Armel Zebaze, Ming-Ho Yee,
Logesh Kumar Umapathi, Jian Zhu,
Benjamin Lipkin, Muhtasham Oblokulov,
Zhiruo Wang, Rudra Murthy,
Jason Stillerman, Siva Sankalp Patel,
Dmitry Abulkhanov, Marco Zocca,
Manan Dey, Zhihan Zhang,
Nour Fahmy, Urvashi Bhattacharyya,
Wenhao Yu, Swayam Singh,
Sasha Luccioni, Paulo Villegas,
Maxim Kunakov, Fedor Zhdanov,
Manuel Romero, Tony Lee,
Nadav Timor, Jennifer Ding,
Claire Schlesinger, Hailey Schoelkopf,
Jan Ebert, Tri Dao,
Mayank Mishra, Alex Gu,
Jennifer Robinson, Carolyn Jane Anderson,
Brendan Dolan-Gavitt, Danish Contractor,
Siva Reddy, Daniel Fried,
Dzmitry Bahdanau, Yacine Jernite,
Carlos Muñoz Ferrandis, Sean Hughes,
Thomas Wolf, Arjun Guha,
Leandro von Werra, and Harm de Vries.
2023.
    </span>
    <span class="ltx_bibblock">
     StarCoder: may the source be with you!
    </span>
    <span class="ltx_bibblock">
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.48550/arXiv.2305.06161" target="_blank" title="">
      https://doi.org/10.48550/arXiv.2305.06161
     </a>
    </span>
    <span class="ltx_bibblock">
     arXiv:2305.06161 [cs].
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib20">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Liu et al
     <span class="ltx_text" id="bib.bib20.2.2.1">
      .
     </span>
     (2019)
    </span>
    <span class="ltx_bibblock">
     Yinhan Liu, Myle Ott,
Naman Goyal, Jingfei Du,
Mandar Joshi, Danqi Chen,
Omer Levy, Mike Lewis,
Luke Zettlemoyer, and Veselin
Stoyanov. 2019.
    </span>
    <span class="ltx_bibblock">
     RoBERTa: A Robustly Optimized BERT
Pretraining Approach.
    </span>
    <span class="ltx_bibblock">
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.48550/arXiv.1907.11692" target="_blank" title="">
      https://doi.org/10.48550/arXiv.1907.11692
     </a>
    </span>
    <span class="ltx_bibblock">
     arXiv:1907.11692 [cs].
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib21">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Misra and Rayz (2022)
    </span>
    <span class="ltx_bibblock">
     Kanishka Misra and
Julia Taylor Rayz. 2022.
    </span>
    <span class="ltx_bibblock">
     LMs go Phishing: Adapting Pre-trained
Language Models to Detect Phishing Emails. In
     <em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">
      2022 IEEE/WIC/ACM International Joint
Conference on Web Intelligence and Intelligent Agent Technology
(WI-IAT)
     </em>
     . 135–142.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1109/WI-IAT55865.2022.00028" target="_blank" title="">
      https://doi.org/10.1109/WI-IAT55865.2022.00028
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib22">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Mnih et al
     <span class="ltx_text" id="bib.bib22.2.2.1">
      .
     </span>
     (2013)
    </span>
    <span class="ltx_bibblock">
     Volodymyr Mnih, Koray
Kavukcuoglu, David Silver, Alex Graves,
Ioannis Antonoglou, Daan Wierstra, and
Martin Riedmiller. 2013.
    </span>
    <span class="ltx_bibblock">
     Playing Atari with Deep Reinforcement
Learning.
    </span>
    <span class="ltx_bibblock">
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.48550/arXiv.1312.5602" target="_blank" title="">
      https://doi.org/10.48550/arXiv.1312.5602
     </a>
    </span>
    <span class="ltx_bibblock">
     arXiv:1312.5602 [cs].
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib23">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Nam et al
     <span class="ltx_text" id="bib.bib23.2.2.1">
      .
     </span>
     (2021)
    </span>
    <span class="ltx_bibblock">
     Minki Nam, Seungyoung
Park, and Duk Soo Kim. 2021.
    </span>
    <span class="ltx_bibblock">
     Intrusion Detection Method Using
Bi-Directional GPT for in-Vehicle Controller Area Networks.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib23.3.1">
      IEEE Access
     </em>
     9
(2021), 124931–124944.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1109/ACCESS.2021.3110524" target="_blank" title="">
      https://doi.org/10.1109/ACCESS.2021.3110524
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib24">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     OpenAI (2023)
    </span>
    <span class="ltx_bibblock">
     OpenAI. 2023.
    </span>
    <span class="ltx_bibblock">
     GPT-4 Technical Report.
    </span>
    <span class="ltx_bibblock">
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.48550/arXiv.2303.08774" target="_blank" title="">
      https://doi.org/10.48550/arXiv.2303.08774
     </a>
    </span>
    <span class="ltx_bibblock">
     arXiv:2303.08774 [cs].
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib25">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Park et al
     <span class="ltx_text" id="bib.bib25.2.2.1">
      .
     </span>
     (2023)
    </span>
    <span class="ltx_bibblock">
     Joon Sung Park, Joseph C.
O’Brien, Carrie J. Cai, Meredith Ringel
Morris, Percy Liang, and Michael S.
Bernstein. 2023.
    </span>
    <span class="ltx_bibblock">
     Generative Agents: Interactive Simulacra of
Human Behavior.
    </span>
    <span class="ltx_bibblock">
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.48550/arXiv.2304.03442" target="_blank" title="">
      https://doi.org/10.48550/arXiv.2304.03442
     </a>
    </span>
    <span class="ltx_bibblock">
     arXiv:2304.03442 [cs].
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib26">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Pearce et al
     <span class="ltx_text" id="bib.bib26.2.2.1">
      .
     </span>
     (2023)
    </span>
    <span class="ltx_bibblock">
     Hammond Pearce, Benjamin
Tan, Baleegh Ahmad, Ramesh Karri, and
Brendan Dolan-Gavitt. 2023.
    </span>
    <span class="ltx_bibblock">
     Examining Zero-Shot Vulnerability Repair
with Large Language Models. In
     <em class="ltx_emph ltx_font_italic" id="bib.bib26.3.1">
      2023 IEEE
Symposium on Security and Privacy (SP)
     </em>
     .
2339–2356.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1109/SP46215.2023.10179324" target="_blank" title="">
      https://doi.org/10.1109/SP46215.2023.10179324
     </a>
    </span>
    <span class="ltx_bibblock">
     ISSN: 2375-1207.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib27">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Radford et al
     <span class="ltx_text" id="bib.bib27.2.2.1">
      .
     </span>
     (2019)
    </span>
    <span class="ltx_bibblock">
     Alec Radford, Jeffrey Wu,
Rewon Child, David Luan,
Dario Amodei, Ilya Sutskever, and
others. 2019.
    </span>
    <span class="ltx_bibblock">
     Language models are unsupervised multitask
learners.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib27.3.1">
      OpenAI blog
     </em>
     1,
8 (2019), 9.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib28">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Raffel et al
     <span class="ltx_text" id="bib.bib28.2.2.1">
      .
     </span>
     (2020)
    </span>
    <span class="ltx_bibblock">
     Colin Raffel, Noam
Shazeer, Adam Roberts, Katherine Lee,
Sharan Narang, Michael Matena,
Yanqi Zhou, Wei Li, and
Peter J. Liu. 2020.
    </span>
    <span class="ltx_bibblock">
     Exploring the limits of transfer learning with a
unified text-to-text transformer.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib28.3.1">
      The Journal of Machine Learning Research
     </em>
     21, 1 (Jan.
2020), 140:5485–140:5551.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib29">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Schwartz and Kurniawati (2019)
    </span>
    <span class="ltx_bibblock">
     Jonathon Schwartz and
Hanna Kurniawati. 2019.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib29.1.1">
      Autonomous Penetration Testing using
Reinforcement Learning
     </em>
     .
    </span>
    <span class="ltx_bibblock">
     Ph. D. Dissertation. arXiv.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/1905.05965" target="_blank" title="">
      http://arxiv.org/abs/1905.05965
     </a>
    </span>
    <span class="ltx_bibblock">
     arXiv:1905.05965 [cs].
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib30">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Seyyar et al
     <span class="ltx_text" id="bib.bib30.2.2.1">
      .
     </span>
     (2022)
    </span>
    <span class="ltx_bibblock">
     Yunus Emre Seyyar,
Ali Gökhan Yavuz, and Halil Murat
Ünver. 2022.
    </span>
    <span class="ltx_bibblock">
     An Attack Detection Framework Based on
BERT and Deep Learning.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib30.3.1">
      IEEE Access
     </em>
     10
(2022), 68633–68644.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1109/ACCESS.2022.3185748" target="_blank" title="">
      https://doi.org/10.1109/ACCESS.2022.3185748
     </a>
    </span>
    <span class="ltx_bibblock">
     Conference Name: IEEE Access.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib31">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Shinn et al
     <span class="ltx_text" id="bib.bib31.2.2.1">
      .
     </span>
     (2023)
    </span>
    <span class="ltx_bibblock">
     Noah Shinn, Federico
Cassano, Beck Labash, Ashwin Gopinath,
Karthik Narasimhan, and Shunyu Yao.
2023.
    </span>
    <span class="ltx_bibblock">
     Reflexion: Language Agents with Verbal
Reinforcement Learning.
    </span>
    <span class="ltx_bibblock">
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.48550/arXiv.2303.11366" target="_blank" title="">
      https://doi.org/10.48550/arXiv.2303.11366
     </a>
    </span>
    <span class="ltx_bibblock">
     arXiv:2303.11366 [cs].
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib32">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Standen et al
     <span class="ltx_text" id="bib.bib32.2.2.1">
      .
     </span>
     (2021)
    </span>
    <span class="ltx_bibblock">
     Maxwell Standen, Martin
Lucas, David Bowman, Toby J. Richer,
Junae Kim, and Damian Marriott.
2021.
    </span>
    <span class="ltx_bibblock">
     CybORG: A Gym for the Development of
Autonomous Cyber Agents.
    </span>
    <span class="ltx_bibblock">
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.48550/arXiv.2108.09118" target="_blank" title="">
      https://doi.org/10.48550/arXiv.2108.09118
     </a>
    </span>
    <span class="ltx_bibblock">
     arXiv:2108.09118 [cs].
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib33">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Team (2021)
    </span>
    <span class="ltx_bibblock">
     Microsoft Defender Research Team.
2021.
    </span>
    <span class="ltx_bibblock">
     CyberBattleSim.
    </span>
    <span class="ltx_bibblock">
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/microsoft/CyberBattleSim" target="_blank" title="">
      https://github.com/microsoft/CyberBattleSim
     </a>
    </span>
    <span class="ltx_bibblock">
     Created by Christian Seifert, Michael Betser, William Blum, James
Bono, Kate Farris, Emily Goren, Justin Grana, Kristian Holsheimer, Brandon
Marken, Joshua Neil, Nicole Nichols, Jugal Parikh, Haoran Wei.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib34">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Thapa et al
     <span class="ltx_text" id="bib.bib34.2.2.1">
      .
     </span>
     (2022)
    </span>
    <span class="ltx_bibblock">
     Chandra Thapa, Seung Ick
Jang, Muhammad Ejaz Ahmed, Seyit
Camtepe, Josef Pieprzyk, and Surya
Nepal. 2022.
    </span>
    <span class="ltx_bibblock">
     Transformer-Based Language Models for
Software Vulnerability Detection. In
     <em class="ltx_emph ltx_font_italic" id="bib.bib34.3.1">
      Proceedings of the 38th Annual Computer
Security Applications Conference
     </em>
     <em class="ltx_emph ltx_font_italic" id="bib.bib34.4.2">
      (ACSAC
’22)
     </em>
     . Association for Computing Machinery,
New York, NY, USA, 481–496.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3564625.3567985" target="_blank" title="">
      https://doi.org/10.1145/3564625.3567985
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib35">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Vaswani et al
     <span class="ltx_text" id="bib.bib35.2.2.1">
      .
     </span>
     (2017)
    </span>
    <span class="ltx_bibblock">
     Ashish Vaswani, Noam
Shazeer, Niki Parmar, Jakob Uszkoreit,
Llion Jones, Aidan N Gomez,
Łukasz Kaiser, and Illia Polosukhin.
2017.
    </span>
    <span class="ltx_bibblock">
     Attention is All you Need. In
     <em class="ltx_emph ltx_font_italic" id="bib.bib35.3.1">
      Advances in Neural Information Processing
Systems
     </em>
     , Vol. 30. Curran
Associates, Inc.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://proceedings.neurips.cc/paper_files/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html" target="_blank" title="">
      https://proceedings.neurips.cc/paper_files/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib36">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wang et al
     <span class="ltx_text" id="bib.bib36.2.2.1">
      .
     </span>
     (2023b)
    </span>
    <span class="ltx_bibblock">
     Guanzhi Wang, Yuqi Xie,
Yunfan Jiang, Ajay Mandlekar,
Chaowei Xiao, Yuke Zhu,
Linxi Fan, and Anima Anandkumar.
2023b.
    </span>
    <span class="ltx_bibblock">
     Voyager: An Open-Ended Embodied Agent with
Large Language Models.
    </span>
    <span class="ltx_bibblock">
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.48550/arXiv.2305.16291" target="_blank" title="">
      https://doi.org/10.48550/arXiv.2305.16291
     </a>
    </span>
    <span class="ltx_bibblock">
     arXiv:2305.16291 [cs].
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib37">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wang et al
     <span class="ltx_text" id="bib.bib37.2.2.1">
      .
     </span>
     (2023a)
    </span>
    <span class="ltx_bibblock">
     Zihao Wang, Shaofei Cai,
Anji Liu, Xiaojian Ma, and
Yitao Liang. 2023a.
    </span>
    <span class="ltx_bibblock">
     Describe, Explain, Plan and Select:
Interactive Planning with Large Language Models Enables
Open-World Multi-Task Agents.
    </span>
    <span class="ltx_bibblock">
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.48550/arXiv.2302.01560" target="_blank" title="">
      https://doi.org/10.48550/arXiv.2302.01560
     </a>
    </span>
    <span class="ltx_bibblock">
     arXiv:2302.01560 [cs].
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib38">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Watkins and Dayan (1992)
    </span>
    <span class="ltx_bibblock">
     Christopher J. C. H. Watkins and
Peter Dayan. 1992.
    </span>
    <span class="ltx_bibblock">
     Q-learning.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib38.1.1">
      Machine Learning
     </em>
     8,
3 (May 1992),
279–292.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1007/BF00992698" target="_blank" title="">
      https://doi.org/10.1007/BF00992698
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib39">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wei et al
     <span class="ltx_text" id="bib.bib39.2.2.1">
      .
     </span>
     (2023)
    </span>
    <span class="ltx_bibblock">
     Jason Wei, Xuezhi Wang,
Dale Schuurmans, Maarten Bosma,
Brian Ichter, Fei Xia,
Ed Chi, Quoc Le, and
Denny Zhou. 2023.
    </span>
    <span class="ltx_bibblock">
     Chain-of-Thought Prompting Elicits Reasoning
in Large Language Models.
    </span>
    <span class="ltx_bibblock">
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.48550/arXiv.2201.11903" target="_blank" title="">
      https://doi.org/10.48550/arXiv.2201.11903
     </a>
    </span>
    <span class="ltx_bibblock">
     arXiv:2201.11903 [cs].
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib40">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wu et al
     <span class="ltx_text" id="bib.bib40.2.2.1">
      .
     </span>
     (2023)
    </span>
    <span class="ltx_bibblock">
     Yue Wu, So Yeon Min,
Shrimai Prabhumoye, Yonatan Bisk,
Ruslan Salakhutdinov, Amos Azaria,
Tom Mitchell, and Yuanzhi Li.
2023.
    </span>
    <span class="ltx_bibblock">
     SPRING: GPT-4 Out-performs RL Algorithms by
Studying Papers and Reasoning.
    </span>
    <span class="ltx_bibblock">
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.48550/arXiv.2305.15486" target="_blank" title="">
      https://doi.org/10.48550/arXiv.2305.15486
     </a>
    </span>
    <span class="ltx_bibblock">
     arXiv:2305.15486 [cs].
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib41">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Yao et al
     <span class="ltx_text" id="bib.bib41.2.2.1">
      .
     </span>
     (2023)
    </span>
    <span class="ltx_bibblock">
     Shunyu Yao, Jeffrey Zhao,
Dian Yu, Nan Du, Izhak
Shafran, Karthik Narasimhan, and Yuan
Cao. 2023.
    </span>
    <span class="ltx_bibblock">
     ReAct: Synergizing Reasoning and Acting in
Language Models.
    </span>
    <span class="ltx_bibblock">
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.48550/arXiv.2210.03629" target="_blank" title="">
      https://doi.org/10.48550/arXiv.2210.03629
     </a>
    </span>
    <span class="ltx_bibblock">
     arXiv:2210.03629 [cs].
    </span>
   </li>
  </ul>
 </section>
 <section class="ltx_appendix" id="A1">
  <h2 class="ltx_title ltx_title_appendix">
   <span class="ltx_tag ltx_tag_appendix">
    Appendix A
   </span>
   Detailed Prompts
  </h2>
  <section class="ltx_subsection" id="A1.SS1">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     A.1.
    </span>
    Single-Prompt LLM Agent
   </h3>
   <div class="ltx_para" id="A1.SS1.p1">
    <p class="ltx_p" id="A1.SS1.p1.1">
     Instructions:
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="A1.SS1.p2">
    <svg class="ltx_picture" height="154.86" id="A1.SS1.p2.pic1" overflow="visible" version="1.1" width="600">
     <g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,154.86) matrix(1 0 0 -1 0 0)">
      <g fill="#BFBF00" fill-opacity="1.0">
       <path d="M 0 5.91 L 0 148.95 C 0 152.22 2.64 154.86 5.91 154.86 L 594.09 154.86 C 597.36 154.86 600 152.22 600 148.95 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none">
       </path>
      </g>
      <g fill="#FFFFF2" fill-opacity="1.0">
       <path d="M 1.97 5.91 L 1.97 148.95 C 1.97 151.13 3.73 152.89 5.91 152.89 L 594.09 152.89 C 596.27 152.89 598.03 151.13 598.03 148.95 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none">
       </path>
      </g>
      <g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)">
       <foreignobject color="#000000" height="127.3" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">
        <span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="A1.SS1.p2.pic1.1.1.1.1.1" style="width:402.3pt;">
         <pre class="ltx_verbatim ltx_font_typewriter" id="A1.SS1.p2.pic1.1.1.1.1.1.1" style="font-size:90%;">
You are a pentester and you want to exfiltrate data to target host {{target_host}}.
The actions you can take are ScanServices, FindData, ScanNetwork, ExploitService, and ExfiltrateData.

The rules are:
1. You can only scan networks in your list of known networks.
2. You can only scan services in hosts you know.
3. You can only exploit services when you know the service.
4. You can find data in hosts you control.
5. You can exfiltrate known data to and from controlled hosts.

Do not repeat actions that you took in the past.
Do not scan services in hosts you control.
Do not scan the same network twice.
Do not exfiltrate the same data twice.
Exploit services that you know and find data in all controlled hosts.
Once you have known data exfiltrate them to the target one by one.
</pre>
        </span>
       </foreignobject>
      </g>
     </g>
    </svg>
   </div>
   <div class="ltx_para" id="A1.SS1.p3">
    <p class="ltx_p" id="A1.SS1.p3.1">
     Memory:
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="A1.SS1.p4">
    <svg class="ltx_picture" height="55.23" id="A1.SS1.p4.pic1" overflow="visible" version="1.1" width="600">
     <g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,55.23) matrix(1 0 0 -1 0 0)">
      <g fill="#BFBF00" fill-opacity="1.0">
       <path d="M 0 5.91 L 0 49.33 C 0 52.59 2.64 55.23 5.91 55.23 L 594.09 55.23 C 597.36 55.23 600 52.59 600 49.33 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none">
       </path>
      </g>
      <g fill="#FFFFF2" fill-opacity="1.0">
       <path d="M 1.97 5.91 L 1.97 49.33 C 1.97 51.5 3.73 53.26 5.91 53.26 L 594.09 53.26 C 596.27 53.26 598.03 51.5 598.03 49.33 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none">
       </path>
      </g>
      <g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)">
       <foreignobject class="ltx_minipage" color="#000000" height="27.67" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="402.3pt">
        <pre class="ltx_verbatim ltx_font_typewriter" id="A1.SS1.p4.pic1.1.1.1.1.1" style="font-size:90%;">
Previous actions:
You took action ScanNetwork of {’target_network’: ’192.168.241.0/24’} and was helpful.
</pre>
       </foreignobject>
      </g>
     </g>
    </svg>
   </div>
   <div class="ltx_para" id="A1.SS1.p5">
    <p class="ltx_p" id="A1.SS1.p5.1">
     Current status:
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="A1.SS1.p6">
    <svg class="ltx_picture" height="85.03" id="A1.SS1.p6.pic1" overflow="visible" version="1.1" width="600">
     <g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,85.03) matrix(1 0 0 -1 0 0)">
      <g fill="#0000BF" fill-opacity="1.0">
       <path d="M 0 5.91 L 0 79.13 C 0 82.39 2.64 85.03 5.91 85.03 L 594.09 85.03 C 597.36 85.03 600 82.39 600 79.13 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none">
       </path>
      </g>
      <g fill="#F2F2FF" fill-opacity="1.0">
       <path d="M 1.97 5.91 L 1.97 79.13 C 1.97 81.3 3.73 83.06 5.91 83.06 L 594.09 83.06 C 596.27 83.06 598.03 81.3 598.03 79.13 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none">
       </path>
      </g>
      <g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)">
       <foreignobject class="ltx_minipage" color="#000000" height="57.47" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="402.3pt">
        <pre class="ltx_verbatim ltx_font_typewriter" id="A1.SS1.p6.pic1.1.1.1.1.1" style="font-size:90%;">
Current status:
Controlled hosts are 220.210.161.145 and 192.168.242.127
Known networks are 192.168.241.0/24 and 192.168.242.0/24 and 192.168.243.0/24
Known hosts are 192.168.241.109 and 192.168.241.50 and 192.168.241.157 and 192.168.241.179 and 192.168.241.63
Known services are none
Known data are none
</pre>
       </foreignobject>
      </g>
     </g>
    </svg>
   </div>
   <div class="ltx_para" id="A1.SS1.p7">
    <p class="ltx_p" id="A1.SS1.p7.1">
     One-shot example:
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="A1.SS1.p8">
    <svg class="ltx_picture" height="123.03" id="A1.SS1.p8.pic1" overflow="visible" version="1.1" width="600">
     <g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,123.03) matrix(1 0 0 -1 0 0)">
      <g fill="#BFBF00" fill-opacity="1.0">
       <path d="M 0 5.91 L 0 117.13 C 0 120.39 2.64 123.03 5.91 123.03 L 594.09 123.03 C 597.36 123.03 600 120.39 600 117.13 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none">
       </path>
      </g>
      <g fill="#FFFFF2" fill-opacity="1.0">
       <path d="M 1.97 5.91 L 1.97 117.13 C 1.97 119.3 3.73 121.07 5.91 121.07 L 594.09 121.07 C 596.27 121.07 598.03 119.3 598.03 117.13 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none">
       </path>
      </g>
      <g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)">
       <foreignobject class="ltx_minipage" color="#000000" height="95.48" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="402.3pt">
        <pre class="ltx_verbatim ltx_font_typewriter" id="A1.SS1.p8.pic1.1.1.1.1.1" style="font-size:90%;">
Here are some examples of actions:
Action: {"action":"ScanNetwork", "parameters": {"target_network": "1.1.1.0/24"}}
Action: {"action":"ScanServices", "parameters":{"target_host":"2.2.2.3"}}
Action: {"action":"ExploitService", "parameters":{"target_host":"1.1.1.1", "target_service":"openssh"}}
Action: {"action":"FindData", "parameters":{"target_host":"1.1.1.1"}}
Action: {"action":"ExfiltrateData", "parameters": {"target_host": "2.2.2.2",
    "data": ("User1", "WebData"), "source_host": "1.1.1.2"}}}
End of examples.
</pre>
       </foreignobject>
      </g>
     </g>
    </svg>
   </div>
   <div class="ltx_para" id="A1.SS1.p9">
    <p class="ltx_p" id="A1.SS1.p9.1">
     Query:
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="A1.SS1.p10">
    <svg class="ltx_picture" height="52.81" id="A1.SS1.p10.pic1" overflow="visible" version="1.1" width="600">
     <g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,52.81) matrix(1 0 0 -1 0 0)">
      <g fill="#00BF00" fill-opacity="1.0">
       <path d="M 0 5.91 L 0 46.91 C 0 50.17 2.64 52.81 5.91 52.81 L 594.09 52.81 C 597.36 52.81 600 50.17 600 46.91 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none">
       </path>
      </g>
      <g fill="#F2FFF2" fill-opacity="1.0">
       <path d="M 1.97 5.91 L 1.97 46.91 C 1.97 49.08 3.73 50.84 5.91 50.84 L 594.09 50.84 C 596.27 50.84 598.03 49.08 598.03 46.91 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none">
       </path>
      </g>
      <g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)">
       <foreignobject class="ltx_minipage" color="#000000" height="25.25" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="402.3pt">
        <pre class="ltx_verbatim ltx_font_typewriter" id="A1.SS1.p10.pic1.1.1.1.1.1" style="font-size:90%;">
Select a valid action with the correct format and parameters.
If an action is in your list of past actions do not chose that action!
DO NOT REPEAT PAST ACTIONS!
Action:
</pre>
       </foreignobject>
      </g>
     </g>
    </svg>
   </div>
  </section>
  <section class="ltx_subsection" id="A1.SS2">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     A.2.
    </span>
    ReAct Agent
   </h3>
   <section class="ltx_subsubsection" id="A1.SS2.SSS1">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      A.2.1.
     </span>
     Stage 1 Prompt
    </h4>
    <div class="ltx_para" id="A1.SS2.SSS1.p1">
     <p class="ltx_p" id="A1.SS2.SSS1.p1.1">
      Instructions:
     </p>
    </div>
    <div class="ltx_para ltx_noindent" id="A1.SS2.SSS1.p2">
     <svg class="ltx_picture" height="154.86" id="A1.SS2.SSS1.p2.pic1" overflow="visible" version="1.1" width="600">
      <g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,154.86) matrix(1 0 0 -1 0 0)">
       <g fill="#BFBF00" fill-opacity="1.0">
        <path d="M 0 5.91 L 0 148.95 C 0 152.22 2.64 154.86 5.91 154.86 L 594.09 154.86 C 597.36 154.86 600 152.22 600 148.95 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none">
        </path>
       </g>
       <g fill="#FFFFF2" fill-opacity="1.0">
        <path d="M 1.97 5.91 L 1.97 148.95 C 1.97 151.13 3.73 152.89 5.91 152.89 L 594.09 152.89 C 596.27 152.89 598.03 151.13 598.03 148.95 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none">
        </path>
       </g>
       <g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)">
        <foreignobject class="ltx_minipage" color="#000000" height="127.3" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="402.3pt">
         <pre class="ltx_verbatim ltx_font_typewriter" id="A1.SS2.SSS1.p2.pic1.1.1.1.1.1" style="font-size:90%;">
You are a pentester and you want to exfiltrate data to target host {{target_host}}.
The actions you can take are ScanServices, FindData, ScanNetwork, ExploitService, and ExfiltrateData.

The rules are:
1. You can only scan networks in your list of known networks.
2. You can only scan services in hosts you know.
3. You can only exploit services when you know the service.
4. You can find data in hosts you control.
5. You can exfiltrate known data to and from controlled hosts.

Do not repeat actions that you took in the past.
Do not scan services in hosts you control.
Do not scan the same network twice.
Do not exfiltrate the same data twice.
Exploit services that you know and find data in all controlled hosts.
Once you have known data exfiltrate them to the target one by one.
</pre>
        </foreignobject>
       </g>
      </g>
     </svg>
    </div>
    <div class="ltx_para" id="A1.SS2.SSS1.p3">
     <p class="ltx_p" id="A1.SS2.SSS1.p3.1">
      Status:
     </p>
    </div>
    <div class="ltx_para ltx_noindent" id="A1.SS2.SSS1.p4">
     <svg class="ltx_picture" height="69.42" id="A1.SS2.SSS1.p4.pic1" overflow="visible" version="1.1" width="600">
      <g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,69.42) matrix(1 0 0 -1 0 0)">
       <g fill="#0000BF" fill-opacity="1.0">
        <path d="M 0 5.91 L 0 63.51 C 0 66.77 2.64 69.42 5.91 69.42 L 594.09 69.42 C 597.36 69.42 600 66.77 600 63.51 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none">
        </path>
       </g>
       <g fill="#F2F2FF" fill-opacity="1.0">
        <path d="M 1.97 5.91 L 1.97 63.51 C 1.97 65.68 3.73 67.45 5.91 67.45 L 594.09 67.45 C 596.27 67.45 598.03 65.68 598.03 63.51 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none">
        </path>
       </g>
       <g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)">
        <foreignobject class="ltx_minipage" color="#000000" height="41.86" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="402.3pt">
         <pre class="ltx_verbatim ltx_font_typewriter" id="A1.SS2.SSS1.p4.pic1.1.1.1.1.1" style="font-size:90%;">
Current status:
Current status:
Controlled hosts are 192.168.221.85 and 177.36.188.157
Known networks are 192.168.222.0/24 and 192.168.220.0/24 and 192.168.221.0/24
INFO Known hosts are None
INFO Known services: None
INFO Known data: None
</pre>
        </foreignobject>
       </g>
      </g>
     </svg>
    </div>
    <div class="ltx_para" id="A1.SS2.SSS1.p5">
     <p class="ltx_p" id="A1.SS2.SSS1.p5.1">
      Q1:
     </p>
    </div>
    <div class="ltx_para ltx_noindent" id="A1.SS2.SSS1.p6">
     <svg class="ltx_picture" height="38.63" id="A1.SS2.SSS1.p6.pic1" overflow="visible" version="1.1" width="600">
      <g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,38.63) matrix(1 0 0 -1 0 0)">
       <g fill="#00BF00" fill-opacity="1.0">
        <path d="M 0 5.91 L 0 32.72 C 0 35.98 2.64 38.63 5.91 38.63 L 594.09 38.63 C 597.36 38.63 600 35.98 600 32.72 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none">
        </path>
       </g>
       <g fill="#F2FFF2" fill-opacity="1.0">
        <path d="M 1.97 5.91 L 1.97 32.72 C 1.97 34.9 3.73 36.66 5.91 36.66 L 594.09 36.66 C 596.27 36.66 598.03 34.9 598.03 32.72 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none">
        </path>
       </g>
       <g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)">
        <foreignobject class="ltx_minipage" color="#000000" height="11.07" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="402.3pt">
         <pre class="ltx_verbatim ltx_font_typewriter" id="A1.SS2.SSS1.p6.pic1.1.1.1.1.1" style="font-size:90%;">
List the objects in the current status and the actions they can be used. Be specific.
</pre>
        </foreignobject>
       </g>
      </g>
     </svg>
    </div>
   </section>
   <section class="ltx_subsubsection" id="A1.SS2.SSS2">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      A.2.2.
     </span>
     Stage 2 Prompt
    </h4>
    <div class="ltx_para" id="A1.SS2.SSS2.p1">
     <p class="ltx_p" id="A1.SS2.SSS2.p1.1">
      Instructions:
     </p>
    </div>
    <div class="ltx_para ltx_noindent" id="A1.SS2.SSS2.p2">
     <svg class="ltx_picture" height="154.86" id="A1.SS2.SSS2.p2.pic1" overflow="visible" version="1.1" width="600">
      <g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,154.86) matrix(1 0 0 -1 0 0)">
       <g fill="#BFBF00" fill-opacity="1.0">
        <path d="M 0 5.91 L 0 148.95 C 0 152.22 2.64 154.86 5.91 154.86 L 594.09 154.86 C 597.36 154.86 600 152.22 600 148.95 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none">
        </path>
       </g>
       <g fill="#FFFFF2" fill-opacity="1.0">
        <path d="M 1.97 5.91 L 1.97 148.95 C 1.97 151.13 3.73 152.89 5.91 152.89 L 594.09 152.89 C 596.27 152.89 598.03 151.13 598.03 148.95 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none">
        </path>
       </g>
       <g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)">
        <foreignobject class="ltx_minipage" color="#000000" height="127.3" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="402.3pt">
         <pre class="ltx_verbatim ltx_font_typewriter" id="A1.SS2.SSS2.p2.pic1.1.1.1.1.1" style="font-size:90%;">
You are a pentester and you want to exfiltrate data to target host {{target_host}}.
The actions you can take are ScanServices, FindData, ScanNetwork, ExploitService, and ExfiltrateData.

The rules are:
1. You can only scan networks in your list of known networks.
2. You can only scan services in hosts you know.
3. You can only exploit services when you know the service.
4. You can find data in hosts you control.
5. You can exfiltrate known data to and from controlled hosts.

Do not repeat actions that you took in the past.
Do not scan services in hosts you control.
Do not scan the same network twice.
Do not exfiltrate the same data twice.
Exploit services that you know and find data in all controlled hosts.
Once you have known data exfiltrate them to the target one by one.
</pre>
        </foreignobject>
       </g>
      </g>
     </svg>
    </div>
    <div class="ltx_para" id="A1.SS2.SSS2.p3">
     <p class="ltx_p" id="A1.SS2.SSS2.p3.1">
      Status:
     </p>
    </div>
    <div class="ltx_para ltx_noindent" id="A1.SS2.SSS2.p4">
     <svg class="ltx_picture" height="69.42" id="A1.SS2.SSS2.p4.pic1" overflow="visible" version="1.1" width="600">
      <g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,69.42) matrix(1 0 0 -1 0 0)">
       <g fill="#0000BF" fill-opacity="1.0">
        <path d="M 0 5.91 L 0 63.51 C 0 66.77 2.64 69.42 5.91 69.42 L 594.09 69.42 C 597.36 69.42 600 66.77 600 63.51 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none">
        </path>
       </g>
       <g fill="#F2F2FF" fill-opacity="1.0">
        <path d="M 1.97 5.91 L 1.97 63.51 C 1.97 65.68 3.73 67.45 5.91 67.45 L 594.09 67.45 C 596.27 67.45 598.03 65.68 598.03 63.51 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none">
        </path>
       </g>
       <g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)">
        <foreignobject class="ltx_minipage" color="#000000" height="41.86" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="402.3pt">
         <pre class="ltx_verbatim ltx_font_typewriter" id="A1.SS2.SSS2.p4.pic1.1.1.1.1.1" style="font-size:90%;">
Current status:
Controlled hosts are 192.168.221.85 and 177.36.188.157
Known networks are 192.168.222.0/24 and 192.168.220.0/24 and 192.168.221.0/24
INFO Known hosts are None
INFO Known services: None
INFO Known data: None
</pre>
        </foreignobject>
       </g>
      </g>
     </svg>
    </div>
    <div class="ltx_para" id="A1.SS2.SSS2.p5">
     <p class="ltx_p" id="A1.SS2.SSS2.p5.1">
      One-shot example:
     </p>
    </div>
    <div class="ltx_para ltx_noindent" id="A1.SS2.SSS2.p6">
     <svg class="ltx_picture" height="123.03" id="A1.SS2.SSS2.p6.pic1" overflow="visible" version="1.1" width="600">
      <g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,123.03) matrix(1 0 0 -1 0 0)">
       <g fill="#BFBF00" fill-opacity="1.0">
        <path d="M 0 5.91 L 0 117.13 C 0 120.39 2.64 123.03 5.91 123.03 L 594.09 123.03 C 597.36 123.03 600 120.39 600 117.13 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none">
        </path>
       </g>
       <g fill="#FFFFF2" fill-opacity="1.0">
        <path d="M 1.97 5.91 L 1.97 117.13 C 1.97 119.3 3.73 121.07 5.91 121.07 L 594.09 121.07 C 596.27 121.07 598.03 119.3 598.03 117.13 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none">
        </path>
       </g>
       <g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)">
        <foreignobject class="ltx_minipage" color="#000000" height="95.48" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="402.3pt">
         <pre class="ltx_verbatim ltx_font_typewriter" id="A1.SS2.SSS2.p6.pic1.1.1.1.1.1" style="font-size:90%;">
Here are some examples of actions:
Action: {"action":"ScanNetwork", "parameters": {"target_network": "1.1.1.0/24"}}
Action: {"action":"ScanServices", "parameters":{"target_host":"2.2.2.3"}}
Action: {"action":"ExploitService", "parameters":{"target_host":"1.1.1.1", "target_service":"openssh"}}
Action: {"action":"FindData", "parameters":{"target_host":"1.1.1.1"}}
Action: {"action":"ExfiltrateData", "parameters": {"target_host": "2.2.2.2",
    "data": ("User1", "WebData"), "source_host": "1.1.1.2"}}}
End of examples.
</pre>
        </foreignobject>
       </g>
      </g>
     </svg>
    </div>
    <div class="ltx_para" id="A1.SS2.SSS2.p7">
     <p class="ltx_p" id="A1.SS2.SSS2.p7.1">
      LLM Response to Q1:
     </p>
    </div>
    <div class="ltx_para ltx_noindent" id="A1.SS2.SSS2.p8">
     <svg class="ltx_picture" height="86.02" id="A1.SS2.SSS2.p8.pic1" overflow="visible" version="1.1" width="600">
      <g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,86.02) matrix(1 0 0 -1 0 0)">
       <g fill="#BF0000" fill-opacity="1.0">
        <path d="M 0 5.91 L 0 80.11 C 0 83.38 2.64 86.02 5.91 86.02 L 594.09 86.02 C 597.36 86.02 600 83.38 600 80.11 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none">
        </path>
       </g>
       <g fill="#FFF2F2" fill-opacity="1.0">
        <path d="M 1.97 5.91 L 1.97 80.11 C 1.97 82.29 3.73 84.05 5.91 84.05 L 594.09 84.05 C 596.27 84.05 598.03 82.29 598.03 80.11 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none">
        </path>
       </g>
       <g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)">
        <foreignobject class="ltx_minipage" color="#000000" height="58.46" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="402.3pt">
         <pre class="ltx_verbatim ltx_font_typewriter" id="A1.SS2.SSS2.p8.pic1.1.1.1.1.1" style="font-size:90%;">
Controlled hosts:
1. 192.168.221.85 - Can be used to FindData.
2. 177.36.188.157 - Can be used to ExfiltrateData.

Known networks:
1. 192.168.222.0/24 - Can be used to ScanNetwork.
2. 192.168.220.0/24 - Can be used to ScanNetwork.
3. 192.168.221.0/24 - Can be used to ScanNetwork.

Known hosts: None

Known services: None

Known data: None
</pre>
        </foreignobject>
       </g>
      </g>
     </svg>
    </div>
    <div class="ltx_para" id="A1.SS2.SSS2.p9">
     <p class="ltx_p" id="A1.SS2.SSS2.p9.1">
      Memory:
     </p>
    </div>
    <div class="ltx_para ltx_noindent" id="A1.SS2.SSS2.p10">
     <svg class="ltx_picture" height="56.62" id="A1.SS2.SSS2.p10.pic1" overflow="visible" version="1.1" width="600">
      <g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,56.62) matrix(1 0 0 -1 0 0)">
       <g fill="#BFBF00" fill-opacity="1.0">
        <path d="M 0 5.91 L 0 50.71 C 0 53.97 2.64 56.62 5.91 56.62 L 594.09 56.62 C 597.36 56.62 600 53.97 600 50.71 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none">
        </path>
       </g>
       <g fill="#FFFFF2" fill-opacity="1.0">
        <path d="M 1.97 5.91 L 1.97 50.71 C 1.97 52.89 3.73 54.65 5.91 54.65 L 594.09 54.65 C 596.27 54.65 598.03 52.89 598.03 50.71 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none">
        </path>
       </g>
       <g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)">
        <foreignobject class="ltx_minipage" color="#000000" height="29.06" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="402.3pt">
         <pre class="ltx_verbatim ltx_font_typewriter" id="A1.SS2.SSS2.p10.pic1.1.1.1.1.1" style="font-size:90%;">
Previous actions:
You took action {"action":"ScanNetwork",
    "parameters": {"target_network": "192.168.222.0/24"}} and it was successful.
</pre>
        </foreignobject>
       </g>
      </g>
     </svg>
    </div>
    <div class="ltx_para" id="A1.SS2.SSS2.p11">
     <p class="ltx_p" id="A1.SS2.SSS2.p11.1">
      Q2:
     </p>
    </div>
    <div class="ltx_para ltx_noindent" id="A1.SS2.SSS2.p12">
     <svg class="ltx_picture" height="38.63" id="A1.SS2.SSS2.p12.pic1" overflow="visible" version="1.1" width="600">
      <g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,38.63) matrix(1 0 0 -1 0 0)">
       <g fill="#00BF00" fill-opacity="1.0">
        <path d="M 0 5.91 L 0 32.72 C 0 35.98 2.64 38.63 5.91 38.63 L 594.09 38.63 C 597.36 38.63 600 35.98 600 32.72 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none">
        </path>
       </g>
       <g fill="#F2FFF2" fill-opacity="1.0">
        <path d="M 1.97 5.91 L 1.97 32.72 C 1.97 34.9 3.73 36.66 5.91 36.66 L 594.09 36.66 C 596.27 36.66 598.03 34.9 598.03 32.72 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none">
        </path>
       </g>
       <g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)">
        <foreignobject color="#000000" height="11.07" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">
         <span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="A1.SS2.SSS2.p12.pic1.1.1.1.1.1" style="width:402.3pt;">
          <pre class="ltx_verbatim ltx_font_typewriter" id="A1.SS2.SSS2.p12.pic1.1.1.1.1.1.1" style="font-size:90%;">
Provide the best action and its parameters in the correct JSON format.
Action:
</pre>
         </span>
        </foreignobject>
       </g>
      </g>
     </svg>
    </div>
   </section>
  </section>
  <section class="ltx_subsection" id="A1.SS3">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     A.3.
    </span>
    LLM Agent for CyberBattleSim
   </h3>
   <div class="ltx_para" id="A1.SS3.p1">
    <p class="ltx_p" id="A1.SS3.p1.1">
     System instructions:
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="A1.SS3.p2">
    <svg class="ltx_picture" height="55.23" id="A1.SS3.p2.pic1" overflow="visible" version="1.1" width="600">
     <g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,55.23) matrix(1 0 0 -1 0 0)">
      <g fill="#BFBF00" fill-opacity="1.0">
       <path d="M 0 5.91 L 0 49.33 C 0 52.59 2.64 55.23 5.91 55.23 L 594.09 55.23 C 597.36 55.23 600 52.59 600 49.33 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none">
       </path>
      </g>
      <g fill="#FFFFF2" fill-opacity="1.0">
       <path d="M 1.97 5.91 L 1.97 49.33 C 1.97 51.5 3.73 53.26 5.91 53.26 L 594.09 53.26 C 596.27 53.26 598.03 51.5 598.03 49.33 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none">
       </path>
      </g>
      <g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)">
       <foreignobject class="ltx_minipage" color="#000000" height="27.67" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="402.3pt">
        <pre class="ltx_verbatim ltx_font_typewriter" id="A1.SS3.p2.pic1.1.1.1.1.1" style="font-size:90%;">
You are a competent pentester. There are more than 20 computers in the network.
Your goal is to discover and own all of the computers.
</pre>
       </foreignobject>
      </g>
     </g>
    </svg>
   </div>
   <div class="ltx_para" id="A1.SS3.p3">
    <p class="ltx_p" id="A1.SS3.p3.1">
     One-shot example:
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="A1.SS3.p4">
    <svg class="ltx_picture" height="89.83" id="A1.SS3.p4.pic1" overflow="visible" version="1.1" width="600">
     <g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,89.83) matrix(1 0 0 -1 0 0)">
      <g fill="#BFBF00" fill-opacity="1.0">
       <path d="M 0 5.91 L 0 83.92 C 0 87.18 2.64 89.83 5.91 89.83 L 594.09 89.83 C 597.36 89.83 600 87.18 600 83.92 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none">
       </path>
      </g>
      <g fill="#FFFFF2" fill-opacity="1.0">
       <path d="M 1.97 5.91 L 1.97 83.92 C 1.97 86.09 3.73 87.86 5.91 87.86 L 594.09 87.86 C 596.27 87.86 598.03 86.09 598.03 83.92 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none">
       </path>
      </g>
      <g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)">
       <foreignobject class="ltx_minipage" color="#000000" height="62.27" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="402.3pt">
        <pre class="ltx_verbatim ltx_font_typewriter" id="A1.SS3.p4.pic1.1.1.1.1.1" style="font-size:90%;">
Here are some examples of actions:
{"action":"connect_and_infect","source":&lt;source_id&gt;, "target":&lt;target_id&gt;, "port":&lt;port&gt;, "credential":&lt;password&gt;}
{"action":"run_local_attack","target":&lt;target_id&gt;, "attack": &lt;attack_name&gt;}
{"action":"run_remote_attack","source": &lt;source_id&gt;,"target": &lt;target_id&gt;, "attack": &lt;attack_name&gt;}
</pre>
       </foreignobject>
      </g>
     </g>
    </svg>
   </div>
   <div class="ltx_para" id="A1.SS3.p5">
    <p class="ltx_p" id="A1.SS3.p5.1">
     Memory:
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="A1.SS3.p6">
    <svg class="ltx_picture" height="73.22" id="A1.SS3.p6.pic1" overflow="visible" version="1.1" width="600">
     <g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,73.22) matrix(1 0 0 -1 0 0)">
      <g fill="#404040" fill-opacity="1.0">
       <path d="M 0 5.91 L 0 67.32 C 0 70.58 2.64 73.22 5.91 73.22 L 594.09 73.22 C 597.36 73.22 600 70.58 600 67.32 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none">
       </path>
      </g>
      <g fill="#F2F2F2" fill-opacity="1.0">
       <path d="M 1.97 5.91 L 1.97 67.32 C 1.97 69.49 3.73 71.25 5.91 71.25 L 594.09 71.25 C 596.27 71.25 598.03 69.49 598.03 67.32 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none">
       </path>
      </g>
      <g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)">
       <foreignobject class="ltx_minipage" color="#000000" height="45.66" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="402.3pt">
        <pre class="ltx_verbatim ltx_font_typewriter" id="A1.SS3.p6.pic1.1.1.1.1.1" style="font-size:90%;">
Previous actions:
- Action: {’action’: ’run_local_attack’, ’target’: ’start’, ’attack’: ’ScanExplorerRecentFiles’}
    Result: [CachedCredential(node=’1_LinuxNode’, port=’SSH’, credential=’LinuxPassword!1’)]
</pre>
       </foreignobject>
      </g>
     </g>
    </svg>
   </div>
   <div class="ltx_para" id="A1.SS3.p7">
    <p class="ltx_p" id="A1.SS3.p7.1">
     Current status:
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="A1.SS3.p8">
    <svg class="ltx_picture" height="123.03" id="A1.SS3.p8.pic1" overflow="visible" version="1.1" width="600">
     <g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,123.03) matrix(1 0 0 -1 0 0)">
      <g fill="#0000BF" fill-opacity="1.0">
       <path d="M 0 5.91 L 0 117.13 C 0 120.39 2.64 123.03 5.91 123.03 L 594.09 123.03 C 597.36 123.03 600 120.39 600 117.13 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none">
       </path>
      </g>
      <g fill="#F2F2FF" fill-opacity="1.0">
       <path d="M 1.97 5.91 L 1.97 117.13 C 1.97 119.3 3.73 121.07 5.91 121.07 L 594.09 121.07 C 596.27 121.07 598.03 119.3 598.03 117.13 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none">
       </path>
      </g>
      <g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)">
       <foreignobject class="ltx_minipage" color="#000000" height="95.48" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="402.3pt">
        <pre class="ltx_verbatim ltx_font_typewriter" id="A1.SS3.p8.pic1.1.1.1.1.1" style="font-size:90%;">
Current status:
These are the known computers so far: [{’id’: ’start’, ’status’: ’owned’}, {’id’: ’1_LinuxNode’, ’status’: ’discovered’}].
List of known credentials: {CachedCredential(node=’1_LinuxNode’, port=’SSH’, credential=’LinuxPassword!1’)}.
Node start has status owned. The list of possible local attacks to it are: [’ScanExplorerRecentFiles’].
The list of possible remote attacks to it are: [].
Node 1_LinuxNode has status discovered. The list of possible remote attacks to it are: [’ProbeLinux’, ’ProbeWindows’].
</pre>
       </foreignobject>
      </g>
     </g>
    </svg>
   </div>
   <div class="ltx_para" id="A1.SS3.p9">
    <p class="ltx_p" id="A1.SS3.p9.1">
     Final instructions:
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="A1.SS3.p10">
    <svg class="ltx_picture" height="121.65" id="A1.SS3.p10.pic1" overflow="visible" version="1.1" width="600">
     <g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,121.65) matrix(1 0 0 -1 0 0)">
      <g fill="#00BF00" fill-opacity="1.0">
       <path d="M 0 5.91 L 0 115.75 C 0 119.01 2.64 121.65 5.91 121.65 L 594.09 121.65 C 597.36 121.65 600 119.01 600 115.75 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none">
       </path>
      </g>
      <g fill="#F2FFF2" fill-opacity="1.0">
       <path d="M 1.97 5.91 L 1.97 115.75 C 1.97 117.92 3.73 119.68 5.91 119.68 L 594.09 119.68 C 596.27 119.68 598.03 117.92 598.03 115.75 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none">
       </path>
      </g>
      <g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)">
       <foreignobject class="ltx_minipage" color="#000000" height="94.09" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="402.3pt">
        <pre class="ltx_verbatim ltx_font_typewriter" id="A1.SS3.p10.pic1.1.1.1.1.1" style="font-size:90%;">
There are 3 actions available: run_local_attack, run_remote_attack and connect_and_infect.
You can discover new nodes and credentials using run_local_attack in nodes you own.
You can perform a run_remote_attack action to hosts that are discovered.
Once you know any credentials run the connect_and_infect action.
Never stop the attack. When you own all nodes keep trying local attacks in the latest nodes.
Provide the next action and all necessary parameters in json format including source and target hosts.
</pre>
       </foreignobject>
      </g>
     </g>
    </svg>
   </div>
   <div class="ltx_pagination ltx_role_newpage">
   </div>
  </section>
 </section>
</article>
