<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2005.01239] Visual Question Answering with Prior Class Semantics</title><meta property="og:description" content="We present a novel mechanism to embed prior knowledge in a model for visual question answering.
The open-set nature of the task is at odds with the ubiquitous approach of training of a fixed classifier.
We show how to …">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Visual Question Answering with Prior Class Semantics">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Visual Question Answering with Prior Class Semantics">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2005.01239">

<!--Generated on Mon Feb 26 19:53:27 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Visual Question Answering with Prior Class Semantics</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Violetta Shevchenko, Damien Teney, Anthony Dick, Anton van den Hengel 
<br class="ltx_break">The University of Adelaide
<br class="ltx_break"><span id="id1.1.id1" class="ltx_text ltx_font_typewriter" style="font-size:90%;">{violetta.shevchenko,damien.teney,anthony.dick,anton.vandenhengel}@adelaide.edu.au</span>
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id2.id1" class="ltx_p">We present a novel mechanism to embed prior knowledge in a model for visual question answering.
The open-set nature of the task is at odds with the ubiquitous approach of training of a fixed classifier.
We show how to exploit additional information pertaining to the semantics of candidate answers.
We extend the answer prediction process with a regression objective in a semantic space, in which we project candidate answers using prior knowledge derived from word embeddings.
We perform an extensive study of learned representations with the GQA dataset, revealing that important semantic information is captured in the <em id="id2.id1.1" class="ltx_emph ltx_font_italic">relations</em> between embeddings in the answer space.
Our method brings improvements in consistency and accuracy over a range of question types.
Experiments with novel answers, unseen during training, indicate the method’s potential for open-set prediction.</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">The task of visual question answering (VQA) has become a benchmark to evaluate joint progress in computer vision and natural language processing. This complex task, in its most general formulation, requires deep analysis of both visual and textual information in order to correctly answer a question, given an associated image. Behind its simple formulation, VQA is an extremely complex task that offers a testbed for a multitude of capabilities required to develop strong AI systems.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Most recent developments in the field of VQA have focused on the development of deep learning architectures that can be trained with end-to-end supervision (<em id="S1.p2.1.1" class="ltx_emph ltx_font_italic">i.e</em>.<span id="S1.p2.1.2" class="ltx_text"></span> questions, images, and answers). However, even current large-scale datasets
 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>, <a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite> can only cover a limited fraction of all knowledge potentially useful for the task. The underlying reasons for this limitation are that

<span id="S1.I1" class="ltx_inline-enumerate">
<span id="S1.I1.i1" class="ltx_inline-item"><span class="ltx_tag ltx_tag_inline-item">1)</span> <span id="S1.I1.i1.1" class="ltx_text">the collection of data with end-to-end annotations, <em id="S1.I1.i1.1.1" class="ltx_emph ltx_font_italic">i.e</em>.<span id="S1.I1.i1.1.2" class="ltx_text"></span> questions/answers is expensive as it usually requires human resources,
</span></span>
<span id="S1.I1.i2" class="ltx_inline-item"><span class="ltx_tag ltx_tag_inline-item">2)</span> <span id="S1.I1.i2.1" class="ltx_text">the desirable knowledge about the world is constantly expanding, and no single dataset can ever capture it all.
</span></span>
</span>
Existing models trained once and for all on any of these datasets lack the generalization and adaptation capabilities desirable in real-world applications. These shortcomings motivate our search for alternative sources of information, and a method to exploit them in a VQA model.</p>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/2005.01239/assets/x1.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="209" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Existing models treat VQA as a classification task over predefined answers (upper branch). We supplement our model with a regression objective in a semantic answer space (lower branch). This allows incorporating additional prior knowledge about answer semantics. This improves its accuracy and consistency. In the above example, <span id="S1.F1.5.1" class="ltx_text ltx_font_italic">red</span> and <span id="S1.F1.6.2" class="ltx_text ltx_font_italic">orange</span> are similarly likely with the traditional objective. Our regression lands closer to the representation of <span id="S1.F1.7.3" class="ltx_text ltx_font_italic">red</span> in the answer space. This resolves the ambiguity and <span id="S1.F1.8.4" class="ltx_text ltx_font_italic">red</span> is chosen as the final answer.</figcaption>
</figure>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">A common approach to include existing knowledge in VQA models is to use pretrained models to obtain image and question features. On the image side, pretrained convolutional neural networks (CNNs) or object detectors are ubiquitous <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite> to extract representative image features. On the language side, pretrained word embeddings like Word2Vec <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite> and GloVe <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite> usually serve to encode the words of the question. The advantage of these techniques is to leverage knowledge learned from larger, non-VQA specific data (<em id="S1.p3.1.1" class="ltx_emph ltx_font_italic">e.g</em>.<span id="S1.p3.1.2" class="ltx_text"></span> ImageNet and large text corpora). The benefit of these approaches has been widely demonstrated, which further motivates our quest for additional sources of usable knowledge and techniques to incorporate it.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">Existing models for VQA follow the common blueprint of a two-stream embedding, followed by fusion and classification stages <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>, <a href="#bib.bib21" title="" class="ltx_ref">21</a>, <a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite>. The typical setting in VQA consists of an image and a related question. The model takes this image-question pair and predicts the correct answer by solving a classification problem over the set of candidate answers that occur in the training data. This classification approach, in contrast to text generation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>, <a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>, considerably simplifies the evaluation process, as the model can be assessed by its classification accuracy. However, treating VQA as a classification task has major drawbacks. The answers are treated as distinct class labels and answer words are abstracted from their meanings. This disregards semantic relations between related answers. Moreover, some questions contain possible answers in their wording (<em id="S1.p4.1.1" class="ltx_emph ltx_font_italic">e.g</em>.<span id="S1.p4.1.2" class="ltx_text"></span> <span id="S1.p4.1.3" class="ltx_text ltx_font_italic">Is this car red or white ?</span>) and it seems natural to include mechanisms to explicitly represent the semantics of possible answers as done for question words. Guided by these observations, we develop an architecture that leverages prior knowledge about answer to improve the performance of a VQA model.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">Our main technical contribution is to treat VQA as a multitask problem, where we both predict the answer label based on classification scores, and we additionally learn a mapping into an answer representation space that captures the semantics of these answers (see Fig. <a href="#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ Visual Question Answering with Prior Class Semantics" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>). We incorporate prior knowledge into the model by initializing the representations of answers with pretrained word embeddings. We perform an extensive and rigorous analysis of the trained model. It demonstrates the benefits of the approach and provides us with insights in the ways language semantics are useful for the task of VQA. Moreover, we show that learned answer representations can be used for out-of-vocabulary answer prediction which is an important, yet understudied problem in VQA field <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>.</p>
</div>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.1" class="ltx_p">The contributions of this paper are as follows.</p>
<ul id="S1.I2" class="ltx_itemize">
<li id="S1.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I2.i1.p1" class="ltx_para">
<p id="S1.I2.i1.p1.1" class="ltx_p">We formulate VQA as a multitask problem, where we train the model, not only to assign scores to answer candidates, but also to perform a regression in a vector space that represents answer semantics.</p>
</div>
</li>
<li id="S1.I2.i2" class="ltx_item" style="list-style-type:none;padding-top:-1.5pt;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I2.i2.p1" class="ltx_para">
<p id="S1.I2.i2.p1.1" class="ltx_p">We use this multitask formulation to incorporate additional information into the model with a particular loss and initialization of the semantic answer space. We also show that it allows the model to predict novel answers that were not seen during training.</p>
</div>
</li>
<li id="S1.I2.i3" class="ltx_item" style="list-style-type:none;padding-top:-1.5pt;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I2.i3.p1" class="ltx_para">
<p id="S1.I2.i3.p1.1" class="ltx_p">We perform an extensive analysis of the model and various ablations. We demonstrate clear advantages on the GQA dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>, and obtain insights on the ways in which answer semantics are useful for the task of VQA.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">The overarching motivation for research on VQA is that of tackling a complex, open-world and multimodal task. These aspects are among the foundations required in general AI systems. While the task has attracted considerable attention over the past few years <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>, <a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>, its open-set and open-domain aspects have largely been overlooked. The common practice of training a model with end-to-end supervision using a fixed dataset is inherently limited. Our discussion focuses on the incorporation of additional knowledge and training signals into VQA models.</p>
</div>
<section id="S2.SS0.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Answer embeddings for VQA.</h4>

<div id="S2.SS0.SSS0.Px1.p1" class="ltx_para">
<p id="S2.SS0.SSS0.Px1.p1.1" class="ltx_p">Most techniques to incorporate additional information into VQA models are based on representations of language, both of questions and of candidate answers. In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite> pretrained word embeddings are used as bag-of-words representations of candidate answers, which are passed to the network as additional inputs, along with question and image features. In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite> authors proposed to initialize the weights of the output classifier with pretrained answer embeddings. They used both a textual branch, initialized with GloVe vectors, and a visual one, initialized with visual features from images representing the candidate answers. In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>, the authors propose to learn two sets of embeddings, image-question vectors and answer embeddings. They optimize a projection of these two embeddings into a joint space where the distances between compatible pairs are minimized. Their experiments showed interestingly that the learned projections was transferable, to some extent, across datasets with different sets of possible answers.</p>
</div>
<div id="S2.SS0.SSS0.Px1.p2" class="ltx_para">
<p id="S2.SS0.SSS0.Px1.p2.1" class="ltx_p">Different from the methods cited above, our model forgoes the notion of a fixed answer set, and the output of the network is a location in a space representing answer semantics. The final prediction is still obtained by searching for the closest representation among answer candidates in this same space, but the formulation offers improved flexibility. This allows us to explore different distance measures in this semantic space. It also allows control over the contribution made by prior and task-specific data. Finally, it easily accommodates multiple representations of a same answer, thereby accounting for polysemy and context-dependent meaning of certain words and expressions.</p>
</div>
</section>
<section id="S2.SS0.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Class embeddings for image classification.</h4>

<div id="S2.SS0.SSS0.Px2.p1" class="ltx_para">
<p id="S2.SS0.SSS0.Px2.p1.1" class="ltx_p">A related line of works use non-visual data to improve image classifiers. Techniques have been proposed to use unannotated text <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>, knowledge graphs <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite> or hierarchical word databases <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite> to obtain meaningful class embeddings, which proved beneficial for fine-grained image classification. Our work applies similar ideas to the task of VQA, where the key challenge is to find embeddings semantically connecting both visual and textual modalities.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Proposed Approach</h2>

<figure id="S3.F2" class="ltx_figure"><img src="/html/2005.01239/assets/x2.png" id="S3.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="392" height="136" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Our contributions apply to the classifier stage (dashed box) of a VQA model. We feed the fused image/question representation into two separate branches. (1) In the upper branch, a traditional scoring model over predefined candidate answers. (2) In the lower branch, a novel, learned projection to a semantic answer space. The resulting vector <math id="S3.F2.4.m1.1" class="ltx_Math" alttext="p" display="inline"><semantics id="S3.F2.4.m1.1b"><mi id="S3.F2.4.m1.1.1" xref="S3.F2.4.m1.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="S3.F2.4.m1.1c"><ci id="S3.F2.4.m1.1.1.cmml" xref="S3.F2.4.m1.1.1">𝑝</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.4.m1.1d">p</annotation></semantics></math> serves to measure pairwise distances (<math id="S3.F2.5.m2.1" class="ltx_Math" alttext="d" display="inline"><semantics id="S3.F2.5.m2.1b"><mi id="S3.F2.5.m2.1.1" xref="S3.F2.5.m2.1.1.cmml">d</mi><annotation-xml encoding="MathML-Content" id="S3.F2.5.m2.1c"><ci id="S3.F2.5.m2.1.1.cmml" xref="S3.F2.5.m2.1.1">𝑑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.5.m2.1d">d</annotation></semantics></math>) with pretrained representations of candidate answers (<math id="S3.F2.6.m3.1" class="ltx_Math" alttext="M" display="inline"><semantics id="S3.F2.6.m3.1b"><mi id="S3.F2.6.m3.1.1" xref="S3.F2.6.m3.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S3.F2.6.m3.1c"><ci id="S3.F2.6.m3.1.1.cmml" xref="S3.F2.6.m3.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.6.m3.1d">M</annotation></semantics></math>). Nodes marked <span id="S3.F2.10.1" class="ltx_text ltx_font_sansserif">N</span> denote non-linear layers, <span id="S3.F2.11.2" class="ltx_text ltx_font_sansserif">L</span> linear layers, and <span id="S3.F2.12.3" class="ltx_text ltx_font_sansserif">X</span> an element-wise product.</figcaption>
</figure>
<div id="S3.p1" class="ltx_para">
<p id="S3.p1.4" class="ltx_p">Our main idea is to extend VQA with a regression objective, where the model outputs a high-dimensional vector that represents the semantics of the answer. This is a shift from the traditional classification objective over predefined candidate answers. Our formulation will open the door to compositional and unbounded sets of answers, and the possibility of truly open-set prediction. Technically, our method concerns only the latter stage of a VQA model and is thus applicable to most existing “joint embedding” models, such as <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>, <a href="#bib.bib27" title="" class="ltx_ref">27</a>, <a href="#bib.bib5" title="" class="ltx_ref">5</a>, <a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>. In these models, the network produces a vector <math id="S3.p1.1.m1.1" class="ltx_Math" alttext="\boldsymbol{x}" display="inline"><semantics id="S3.p1.1.m1.1a"><mi id="S3.p1.1.m1.1.1" xref="S3.p1.1.m1.1.1.cmml">𝒙</mi><annotation-xml encoding="MathML-Content" id="S3.p1.1.m1.1b"><ci id="S3.p1.1.m1.1.1.cmml" xref="S3.p1.1.m1.1.1">𝒙</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.1.m1.1c">\boldsymbol{x}</annotation></semantics></math> from the fusion of the image and question representations (see Fig. <a href="#S3.F2" title="Figure 2 ‣ 3 Proposed Approach ‣ Visual Question Answering with Prior Class Semantics" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>). The traditional approach then feeds this to a classifier and obtain <math id="S3.p1.2.m2.1" class="ltx_Math" alttext="\boldsymbol{y}=f_{\theta}(\boldsymbol{x})" display="inline"><semantics id="S3.p1.2.m2.1a"><mrow id="S3.p1.2.m2.1.2" xref="S3.p1.2.m2.1.2.cmml"><mi id="S3.p1.2.m2.1.2.2" xref="S3.p1.2.m2.1.2.2.cmml">𝒚</mi><mo id="S3.p1.2.m2.1.2.1" xref="S3.p1.2.m2.1.2.1.cmml">=</mo><mrow id="S3.p1.2.m2.1.2.3" xref="S3.p1.2.m2.1.2.3.cmml"><msub id="S3.p1.2.m2.1.2.3.2" xref="S3.p1.2.m2.1.2.3.2.cmml"><mi id="S3.p1.2.m2.1.2.3.2.2" xref="S3.p1.2.m2.1.2.3.2.2.cmml">f</mi><mi id="S3.p1.2.m2.1.2.3.2.3" xref="S3.p1.2.m2.1.2.3.2.3.cmml">θ</mi></msub><mo lspace="0em" rspace="0em" id="S3.p1.2.m2.1.2.3.1" xref="S3.p1.2.m2.1.2.3.1.cmml">​</mo><mrow id="S3.p1.2.m2.1.2.3.3.2" xref="S3.p1.2.m2.1.2.3.cmml"><mo stretchy="false" id="S3.p1.2.m2.1.2.3.3.2.1" xref="S3.p1.2.m2.1.2.3.cmml">(</mo><mi id="S3.p1.2.m2.1.1" xref="S3.p1.2.m2.1.1.cmml">𝒙</mi><mo stretchy="false" id="S3.p1.2.m2.1.2.3.3.2.2" xref="S3.p1.2.m2.1.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.p1.2.m2.1b"><apply id="S3.p1.2.m2.1.2.cmml" xref="S3.p1.2.m2.1.2"><eq id="S3.p1.2.m2.1.2.1.cmml" xref="S3.p1.2.m2.1.2.1"></eq><ci id="S3.p1.2.m2.1.2.2.cmml" xref="S3.p1.2.m2.1.2.2">𝒚</ci><apply id="S3.p1.2.m2.1.2.3.cmml" xref="S3.p1.2.m2.1.2.3"><times id="S3.p1.2.m2.1.2.3.1.cmml" xref="S3.p1.2.m2.1.2.3.1"></times><apply id="S3.p1.2.m2.1.2.3.2.cmml" xref="S3.p1.2.m2.1.2.3.2"><csymbol cd="ambiguous" id="S3.p1.2.m2.1.2.3.2.1.cmml" xref="S3.p1.2.m2.1.2.3.2">subscript</csymbol><ci id="S3.p1.2.m2.1.2.3.2.2.cmml" xref="S3.p1.2.m2.1.2.3.2.2">𝑓</ci><ci id="S3.p1.2.m2.1.2.3.2.3.cmml" xref="S3.p1.2.m2.1.2.3.2.3">𝜃</ci></apply><ci id="S3.p1.2.m2.1.1.cmml" xref="S3.p1.2.m2.1.1">𝒙</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.2.m2.1c">\boldsymbol{y}=f_{\theta}(\boldsymbol{x})</annotation></semantics></math>, with <math id="S3.p1.3.m3.1" class="ltx_Math" alttext="\boldsymbol{y}\in\mathbb{R}^{A}" display="inline"><semantics id="S3.p1.3.m3.1a"><mrow id="S3.p1.3.m3.1.1" xref="S3.p1.3.m3.1.1.cmml"><mi id="S3.p1.3.m3.1.1.2" xref="S3.p1.3.m3.1.1.2.cmml">𝒚</mi><mo id="S3.p1.3.m3.1.1.1" xref="S3.p1.3.m3.1.1.1.cmml">∈</mo><msup id="S3.p1.3.m3.1.1.3" xref="S3.p1.3.m3.1.1.3.cmml"><mi id="S3.p1.3.m3.1.1.3.2" xref="S3.p1.3.m3.1.1.3.2.cmml">ℝ</mi><mi id="S3.p1.3.m3.1.1.3.3" xref="S3.p1.3.m3.1.1.3.3.cmml">A</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.p1.3.m3.1b"><apply id="S3.p1.3.m3.1.1.cmml" xref="S3.p1.3.m3.1.1"><in id="S3.p1.3.m3.1.1.1.cmml" xref="S3.p1.3.m3.1.1.1"></in><ci id="S3.p1.3.m3.1.1.2.cmml" xref="S3.p1.3.m3.1.1.2">𝒚</ci><apply id="S3.p1.3.m3.1.1.3.cmml" xref="S3.p1.3.m3.1.1.3"><csymbol cd="ambiguous" id="S3.p1.3.m3.1.1.3.1.cmml" xref="S3.p1.3.m3.1.1.3">superscript</csymbol><ci id="S3.p1.3.m3.1.1.3.2.cmml" xref="S3.p1.3.m3.1.1.3.2">ℝ</ci><ci id="S3.p1.3.m3.1.1.3.3.cmml" xref="S3.p1.3.m3.1.1.3.3">𝐴</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.3.m3.1c">\boldsymbol{y}\in\mathbb{R}^{A}</annotation></semantics></math> being a vector of scores of length <math id="S3.p1.4.m4.1" class="ltx_Math" alttext="A" display="inline"><semantics id="S3.p1.4.m4.1a"><mi id="S3.p1.4.m4.1.1" xref="S3.p1.4.m4.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S3.p1.4.m4.1b"><ci id="S3.p1.4.m4.1.1.cmml" xref="S3.p1.4.m4.1.1">𝐴</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.4.m4.1c">A</annotation></semantics></math>, the cardinality of a predefined set of candidate answers.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>VQA as a Regression Task</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.4" class="ltx_p">Our contribution is to learn a supplementary branch from <math id="S3.SS1.p1.1.m1.1" class="ltx_Math" alttext="\boldsymbol{x}" display="inline"><semantics id="S3.SS1.p1.1.m1.1a"><mi id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml">𝒙</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.1b"><ci id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1">𝒙</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.1c">\boldsymbol{x}</annotation></semantics></math>, which produces a projection <math id="S3.SS1.p1.2.m2.1" class="ltx_Math" alttext="\boldsymbol{p}=g_{\psi}(\boldsymbol{x})" display="inline"><semantics id="S3.SS1.p1.2.m2.1a"><mrow id="S3.SS1.p1.2.m2.1.2" xref="S3.SS1.p1.2.m2.1.2.cmml"><mi id="S3.SS1.p1.2.m2.1.2.2" xref="S3.SS1.p1.2.m2.1.2.2.cmml">𝒑</mi><mo id="S3.SS1.p1.2.m2.1.2.1" xref="S3.SS1.p1.2.m2.1.2.1.cmml">=</mo><mrow id="S3.SS1.p1.2.m2.1.2.3" xref="S3.SS1.p1.2.m2.1.2.3.cmml"><msub id="S3.SS1.p1.2.m2.1.2.3.2" xref="S3.SS1.p1.2.m2.1.2.3.2.cmml"><mi id="S3.SS1.p1.2.m2.1.2.3.2.2" xref="S3.SS1.p1.2.m2.1.2.3.2.2.cmml">g</mi><mi id="S3.SS1.p1.2.m2.1.2.3.2.3" xref="S3.SS1.p1.2.m2.1.2.3.2.3.cmml">ψ</mi></msub><mo lspace="0em" rspace="0em" id="S3.SS1.p1.2.m2.1.2.3.1" xref="S3.SS1.p1.2.m2.1.2.3.1.cmml">​</mo><mrow id="S3.SS1.p1.2.m2.1.2.3.3.2" xref="S3.SS1.p1.2.m2.1.2.3.cmml"><mo stretchy="false" id="S3.SS1.p1.2.m2.1.2.3.3.2.1" xref="S3.SS1.p1.2.m2.1.2.3.cmml">(</mo><mi id="S3.SS1.p1.2.m2.1.1" xref="S3.SS1.p1.2.m2.1.1.cmml">𝒙</mi><mo stretchy="false" id="S3.SS1.p1.2.m2.1.2.3.3.2.2" xref="S3.SS1.p1.2.m2.1.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.2.m2.1b"><apply id="S3.SS1.p1.2.m2.1.2.cmml" xref="S3.SS1.p1.2.m2.1.2"><eq id="S3.SS1.p1.2.m2.1.2.1.cmml" xref="S3.SS1.p1.2.m2.1.2.1"></eq><ci id="S3.SS1.p1.2.m2.1.2.2.cmml" xref="S3.SS1.p1.2.m2.1.2.2">𝒑</ci><apply id="S3.SS1.p1.2.m2.1.2.3.cmml" xref="S3.SS1.p1.2.m2.1.2.3"><times id="S3.SS1.p1.2.m2.1.2.3.1.cmml" xref="S3.SS1.p1.2.m2.1.2.3.1"></times><apply id="S3.SS1.p1.2.m2.1.2.3.2.cmml" xref="S3.SS1.p1.2.m2.1.2.3.2"><csymbol cd="ambiguous" id="S3.SS1.p1.2.m2.1.2.3.2.1.cmml" xref="S3.SS1.p1.2.m2.1.2.3.2">subscript</csymbol><ci id="S3.SS1.p1.2.m2.1.2.3.2.2.cmml" xref="S3.SS1.p1.2.m2.1.2.3.2.2">𝑔</ci><ci id="S3.SS1.p1.2.m2.1.2.3.2.3.cmml" xref="S3.SS1.p1.2.m2.1.2.3.2.3">𝜓</ci></apply><ci id="S3.SS1.p1.2.m2.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1">𝒙</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.2.m2.1c">\boldsymbol{p}=g_{\psi}(\boldsymbol{x})</annotation></semantics></math>, where <math id="S3.SS1.p1.3.m3.1" class="ltx_Math" alttext="\psi" display="inline"><semantics id="S3.SS1.p1.3.m3.1a"><mi id="S3.SS1.p1.3.m3.1.1" xref="S3.SS1.p1.3.m3.1.1.cmml">ψ</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.3.m3.1b"><ci id="S3.SS1.p1.3.m3.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1">𝜓</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.3.m3.1c">\psi</annotation></semantics></math> are the parameters of the projection. The vector <math id="S3.SS1.p1.4.m4.1" class="ltx_Math" alttext="\boldsymbol{p}\in\mathbb{R}^{P}" display="inline"><semantics id="S3.SS1.p1.4.m4.1a"><mrow id="S3.SS1.p1.4.m4.1.1" xref="S3.SS1.p1.4.m4.1.1.cmml"><mi id="S3.SS1.p1.4.m4.1.1.2" xref="S3.SS1.p1.4.m4.1.1.2.cmml">𝒑</mi><mo id="S3.SS1.p1.4.m4.1.1.1" xref="S3.SS1.p1.4.m4.1.1.1.cmml">∈</mo><msup id="S3.SS1.p1.4.m4.1.1.3" xref="S3.SS1.p1.4.m4.1.1.3.cmml"><mi id="S3.SS1.p1.4.m4.1.1.3.2" xref="S3.SS1.p1.4.m4.1.1.3.2.cmml">ℝ</mi><mi id="S3.SS1.p1.4.m4.1.1.3.3" xref="S3.SS1.p1.4.m4.1.1.3.3.cmml">P</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.4.m4.1b"><apply id="S3.SS1.p1.4.m4.1.1.cmml" xref="S3.SS1.p1.4.m4.1.1"><in id="S3.SS1.p1.4.m4.1.1.1.cmml" xref="S3.SS1.p1.4.m4.1.1.1"></in><ci id="S3.SS1.p1.4.m4.1.1.2.cmml" xref="S3.SS1.p1.4.m4.1.1.2">𝒑</ci><apply id="S3.SS1.p1.4.m4.1.1.3.cmml" xref="S3.SS1.p1.4.m4.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p1.4.m4.1.1.3.1.cmml" xref="S3.SS1.p1.4.m4.1.1.3">superscript</csymbol><ci id="S3.SS1.p1.4.m4.1.1.3.2.cmml" xref="S3.SS1.p1.4.m4.1.1.3.2">ℝ</ci><ci id="S3.SS1.p1.4.m4.1.1.3.3.cmml" xref="S3.SS1.p1.4.m4.1.1.3.3">𝑃</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.4.m4.1c">\boldsymbol{p}\in\mathbb{R}^{P}</annotation></semantics></math> is interpreted as a representation of the semantics of the predicted answer. The key to this simple approach is both in the objective used to train this branch, and in its use to select an actual textual answer, which we both describe below.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.2" class="ltx_p">Note that the traditional classifier over <math id="S3.SS1.p2.1.m1.1" class="ltx_Math" alttext="\boldsymbol{x}" display="inline"><semantics id="S3.SS1.p2.1.m1.1a"><mi id="S3.SS1.p2.1.m1.1.1" xref="S3.SS1.p2.1.m1.1.1.cmml">𝒙</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.1.m1.1b"><ci id="S3.SS1.p2.1.m1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1">𝒙</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.1.m1.1c">\boldsymbol{x}</annotation></semantics></math> can be interpreted as a special case of our formulation. The classifier <math id="S3.SS1.p2.2.m2.1" class="ltx_Math" alttext="f_{\theta}(\cdot)" display="inline"><semantics id="S3.SS1.p2.2.m2.1a"><mrow id="S3.SS1.p2.2.m2.1.2" xref="S3.SS1.p2.2.m2.1.2.cmml"><msub id="S3.SS1.p2.2.m2.1.2.2" xref="S3.SS1.p2.2.m2.1.2.2.cmml"><mi id="S3.SS1.p2.2.m2.1.2.2.2" xref="S3.SS1.p2.2.m2.1.2.2.2.cmml">f</mi><mi id="S3.SS1.p2.2.m2.1.2.2.3" xref="S3.SS1.p2.2.m2.1.2.2.3.cmml">θ</mi></msub><mo lspace="0em" rspace="0em" id="S3.SS1.p2.2.m2.1.2.1" xref="S3.SS1.p2.2.m2.1.2.1.cmml">​</mo><mrow id="S3.SS1.p2.2.m2.1.2.3.2" xref="S3.SS1.p2.2.m2.1.2.cmml"><mo stretchy="false" id="S3.SS1.p2.2.m2.1.2.3.2.1" xref="S3.SS1.p2.2.m2.1.2.cmml">(</mo><mo lspace="0em" rspace="0em" id="S3.SS1.p2.2.m2.1.1" xref="S3.SS1.p2.2.m2.1.1.cmml">⋅</mo><mo stretchy="false" id="S3.SS1.p2.2.m2.1.2.3.2.2" xref="S3.SS1.p2.2.m2.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.2.m2.1b"><apply id="S3.SS1.p2.2.m2.1.2.cmml" xref="S3.SS1.p2.2.m2.1.2"><times id="S3.SS1.p2.2.m2.1.2.1.cmml" xref="S3.SS1.p2.2.m2.1.2.1"></times><apply id="S3.SS1.p2.2.m2.1.2.2.cmml" xref="S3.SS1.p2.2.m2.1.2.2"><csymbol cd="ambiguous" id="S3.SS1.p2.2.m2.1.2.2.1.cmml" xref="S3.SS1.p2.2.m2.1.2.2">subscript</csymbol><ci id="S3.SS1.p2.2.m2.1.2.2.2.cmml" xref="S3.SS1.p2.2.m2.1.2.2.2">𝑓</ci><ci id="S3.SS1.p2.2.m2.1.2.2.3.cmml" xref="S3.SS1.p2.2.m2.1.2.2.3">𝜃</ci></apply><ci id="S3.SS1.p2.2.m2.1.1.cmml" xref="S3.SS1.p2.2.m2.1.1">⋅</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.2.m2.1c">f_{\theta}(\cdot)</annotation></semantics></math> typically includes a non-linear layer followed by a linear one. They can be interpreted as a non-linear projection followed by the computation of distances (dot products) with representations of answers. These representations then correspond to the rows of the weight matrix of the linear layer. In this view, our model is a generalization of the classical approach, with benefits of increased flexibility in the choice of the distance measure, of the optimization loss, and of the representations of candidate answers including their initial and/or frozen values.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Training</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.4" class="ltx_p">To evaluate the possibility of mutual benefits of the classification and regression objectives, our full model includes both branches on top of the fused representation <math id="S3.SS2.p1.1.m1.1" class="ltx_Math" alttext="\boldsymbol{x}" display="inline"><semantics id="S3.SS2.p1.1.m1.1a"><mi id="S3.SS2.p1.1.m1.1.1" xref="S3.SS2.p1.1.m1.1.1.cmml">𝒙</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.m1.1b"><ci id="S3.SS2.p1.1.m1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1">𝒙</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.1.m1.1c">\boldsymbol{x}</annotation></semantics></math>. Each of their respective outputs <math id="S3.SS2.p1.2.m2.1" class="ltx_Math" alttext="\boldsymbol{y}" display="inline"><semantics id="S3.SS2.p1.2.m2.1a"><mi id="S3.SS2.p1.2.m2.1.1" xref="S3.SS2.p1.2.m2.1.1.cmml">𝒚</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.2.m2.1b"><ci id="S3.SS2.p1.2.m2.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1">𝒚</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.2.m2.1c">\boldsymbol{y}</annotation></semantics></math> and <math id="S3.SS2.p1.3.m3.1" class="ltx_Math" alttext="\boldsymbol{p}" display="inline"><semantics id="S3.SS2.p1.3.m3.1a"><mi id="S3.SS2.p1.3.m3.1.1" xref="S3.SS2.p1.3.m3.1.1.cmml">𝒑</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.3.m3.1b"><ci id="S3.SS2.p1.3.m3.1.1.cmml" xref="S3.SS2.p1.3.m3.1.1">𝒑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.3.m3.1c">\boldsymbol{p}</annotation></semantics></math> is fed into a specific loss. The whole network is trained by backpropagation of the gradient of the two losses through all the layers leading to <math id="S3.SS2.p1.4.m4.1" class="ltx_Math" alttext="\boldsymbol{x}" display="inline"><semantics id="S3.SS2.p1.4.m4.1a"><mi id="S3.SS2.p1.4.m4.1.1" xref="S3.SS2.p1.4.m4.1.1.cmml">𝒙</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.4.m4.1b"><ci id="S3.SS2.p1.4.m4.1.1.cmml" xref="S3.SS2.p1.4.m4.1.1">𝒙</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.4.m4.1c">\boldsymbol{x}</annotation></semantics></math>.</p>
</div>
<section id="S3.SS2.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Classification loss.</h4>

<div id="S3.SS2.SSS0.Px1.p1" class="ltx_para">
<p id="S3.SS2.SSS0.Px1.p1.4" class="ltx_p">The output of the classification branch <math id="S3.SS2.SSS0.Px1.p1.1.m1.1" class="ltx_Math" alttext="\boldsymbol{y}" display="inline"><semantics id="S3.SS2.SSS0.Px1.p1.1.m1.1a"><mi id="S3.SS2.SSS0.Px1.p1.1.m1.1.1" xref="S3.SS2.SSS0.Px1.p1.1.m1.1.1.cmml">𝒚</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px1.p1.1.m1.1b"><ci id="S3.SS2.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S3.SS2.SSS0.Px1.p1.1.m1.1.1">𝒚</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px1.p1.1.m1.1c">\boldsymbol{y}</annotation></semantics></math> goes through a standard logistic function <math id="S3.SS2.SSS0.Px1.p1.2.m2.1" class="ltx_Math" alttext="\sigma(\cdot)" display="inline"><semantics id="S3.SS2.SSS0.Px1.p1.2.m2.1a"><mrow id="S3.SS2.SSS0.Px1.p1.2.m2.1.2" xref="S3.SS2.SSS0.Px1.p1.2.m2.1.2.cmml"><mi id="S3.SS2.SSS0.Px1.p1.2.m2.1.2.2" xref="S3.SS2.SSS0.Px1.p1.2.m2.1.2.2.cmml">σ</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS0.Px1.p1.2.m2.1.2.1" xref="S3.SS2.SSS0.Px1.p1.2.m2.1.2.1.cmml">​</mo><mrow id="S3.SS2.SSS0.Px1.p1.2.m2.1.2.3.2" xref="S3.SS2.SSS0.Px1.p1.2.m2.1.2.cmml"><mo stretchy="false" id="S3.SS2.SSS0.Px1.p1.2.m2.1.2.3.2.1" xref="S3.SS2.SSS0.Px1.p1.2.m2.1.2.cmml">(</mo><mo lspace="0em" rspace="0em" id="S3.SS2.SSS0.Px1.p1.2.m2.1.1" xref="S3.SS2.SSS0.Px1.p1.2.m2.1.1.cmml">⋅</mo><mo stretchy="false" id="S3.SS2.SSS0.Px1.p1.2.m2.1.2.3.2.2" xref="S3.SS2.SSS0.Px1.p1.2.m2.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px1.p1.2.m2.1b"><apply id="S3.SS2.SSS0.Px1.p1.2.m2.1.2.cmml" xref="S3.SS2.SSS0.Px1.p1.2.m2.1.2"><times id="S3.SS2.SSS0.Px1.p1.2.m2.1.2.1.cmml" xref="S3.SS2.SSS0.Px1.p1.2.m2.1.2.1"></times><ci id="S3.SS2.SSS0.Px1.p1.2.m2.1.2.2.cmml" xref="S3.SS2.SSS0.Px1.p1.2.m2.1.2.2">𝜎</ci><ci id="S3.SS2.SSS0.Px1.p1.2.m2.1.1.cmml" xref="S3.SS2.SSS0.Px1.p1.2.m2.1.1">⋅</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px1.p1.2.m2.1c">\sigma(\cdot)</annotation></semantics></math> and binary cross entropy loss <math id="S3.SS2.SSS0.Px1.p1.3.m3.1" class="ltx_Math" alttext="L_{c}" display="inline"><semantics id="S3.SS2.SSS0.Px1.p1.3.m3.1a"><msub id="S3.SS2.SSS0.Px1.p1.3.m3.1.1" xref="S3.SS2.SSS0.Px1.p1.3.m3.1.1.cmml"><mi id="S3.SS2.SSS0.Px1.p1.3.m3.1.1.2" xref="S3.SS2.SSS0.Px1.p1.3.m3.1.1.2.cmml">L</mi><mi id="S3.SS2.SSS0.Px1.p1.3.m3.1.1.3" xref="S3.SS2.SSS0.Px1.p1.3.m3.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px1.p1.3.m3.1b"><apply id="S3.SS2.SSS0.Px1.p1.3.m3.1.1.cmml" xref="S3.SS2.SSS0.Px1.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px1.p1.3.m3.1.1.1.cmml" xref="S3.SS2.SSS0.Px1.p1.3.m3.1.1">subscript</csymbol><ci id="S3.SS2.SSS0.Px1.p1.3.m3.1.1.2.cmml" xref="S3.SS2.SSS0.Px1.p1.3.m3.1.1.2">𝐿</ci><ci id="S3.SS2.SSS0.Px1.p1.3.m3.1.1.3.cmml" xref="S3.SS2.SSS0.Px1.p1.3.m3.1.1.3">𝑐</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px1.p1.3.m3.1c">L_{c}</annotation></semantics></math>. Denoting with <math id="S3.SS2.SSS0.Px1.p1.4.m4.2" class="ltx_Math" alttext="\hat{\boldsymbol{a}}\in{0,1}^{A}" display="inline"><semantics id="S3.SS2.SSS0.Px1.p1.4.m4.2a"><mrow id="S3.SS2.SSS0.Px1.p1.4.m4.2.2" xref="S3.SS2.SSS0.Px1.p1.4.m4.2.2.cmml"><mover accent="true" id="S3.SS2.SSS0.Px1.p1.4.m4.2.2.3" xref="S3.SS2.SSS0.Px1.p1.4.m4.2.2.3.cmml"><mi id="S3.SS2.SSS0.Px1.p1.4.m4.2.2.3.2" xref="S3.SS2.SSS0.Px1.p1.4.m4.2.2.3.2.cmml">𝒂</mi><mo id="S3.SS2.SSS0.Px1.p1.4.m4.2.2.3.1" xref="S3.SS2.SSS0.Px1.p1.4.m4.2.2.3.1.cmml">^</mo></mover><mo id="S3.SS2.SSS0.Px1.p1.4.m4.2.2.2" xref="S3.SS2.SSS0.Px1.p1.4.m4.2.2.2.cmml">∈</mo><mrow id="S3.SS2.SSS0.Px1.p1.4.m4.2.2.1.1" xref="S3.SS2.SSS0.Px1.p1.4.m4.2.2.1.2.cmml"><mn id="S3.SS2.SSS0.Px1.p1.4.m4.1.1" xref="S3.SS2.SSS0.Px1.p1.4.m4.1.1.cmml">0</mn><mo id="S3.SS2.SSS0.Px1.p1.4.m4.2.2.1.1.2" xref="S3.SS2.SSS0.Px1.p1.4.m4.2.2.1.2.cmml">,</mo><msup id="S3.SS2.SSS0.Px1.p1.4.m4.2.2.1.1.1" xref="S3.SS2.SSS0.Px1.p1.4.m4.2.2.1.1.1.cmml"><mn id="S3.SS2.SSS0.Px1.p1.4.m4.2.2.1.1.1.2" xref="S3.SS2.SSS0.Px1.p1.4.m4.2.2.1.1.1.2.cmml">1</mn><mi id="S3.SS2.SSS0.Px1.p1.4.m4.2.2.1.1.1.3" xref="S3.SS2.SSS0.Px1.p1.4.m4.2.2.1.1.1.3.cmml">A</mi></msup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px1.p1.4.m4.2b"><apply id="S3.SS2.SSS0.Px1.p1.4.m4.2.2.cmml" xref="S3.SS2.SSS0.Px1.p1.4.m4.2.2"><in id="S3.SS2.SSS0.Px1.p1.4.m4.2.2.2.cmml" xref="S3.SS2.SSS0.Px1.p1.4.m4.2.2.2"></in><apply id="S3.SS2.SSS0.Px1.p1.4.m4.2.2.3.cmml" xref="S3.SS2.SSS0.Px1.p1.4.m4.2.2.3"><ci id="S3.SS2.SSS0.Px1.p1.4.m4.2.2.3.1.cmml" xref="S3.SS2.SSS0.Px1.p1.4.m4.2.2.3.1">^</ci><ci id="S3.SS2.SSS0.Px1.p1.4.m4.2.2.3.2.cmml" xref="S3.SS2.SSS0.Px1.p1.4.m4.2.2.3.2">𝒂</ci></apply><list id="S3.SS2.SSS0.Px1.p1.4.m4.2.2.1.2.cmml" xref="S3.SS2.SSS0.Px1.p1.4.m4.2.2.1.1"><cn type="integer" id="S3.SS2.SSS0.Px1.p1.4.m4.1.1.cmml" xref="S3.SS2.SSS0.Px1.p1.4.m4.1.1">0</cn><apply id="S3.SS2.SSS0.Px1.p1.4.m4.2.2.1.1.1.cmml" xref="S3.SS2.SSS0.Px1.p1.4.m4.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px1.p1.4.m4.2.2.1.1.1.1.cmml" xref="S3.SS2.SSS0.Px1.p1.4.m4.2.2.1.1.1">superscript</csymbol><cn type="integer" id="S3.SS2.SSS0.Px1.p1.4.m4.2.2.1.1.1.2.cmml" xref="S3.SS2.SSS0.Px1.p1.4.m4.2.2.1.1.1.2">1</cn><ci id="S3.SS2.SSS0.Px1.p1.4.m4.2.2.1.1.1.3.cmml" xref="S3.SS2.SSS0.Px1.p1.4.m4.2.2.1.1.1.3">𝐴</ci></apply></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px1.p1.4.m4.2c">\hat{\boldsymbol{a}}\in{0,1}^{A}</annotation></semantics></math> the one-hot (multi-hot) vector of the ground truth answer(s) of a specific training instance, we have</p>
<table id="S3.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E1.m1.2" class="ltx_Math" alttext="L_{c}=\sum_{i=1}^{A}-[\hat{a}_{i}*\log\sigma(y_{i})+(1-\hat{a}_{i})*\log(1-\sigma(y_{i}))]" display="block"><semantics id="S3.E1.m1.2a"><mrow id="S3.E1.m1.2.2" xref="S3.E1.m1.2.2.cmml"><msub id="S3.E1.m1.2.2.3" xref="S3.E1.m1.2.2.3.cmml"><mi id="S3.E1.m1.2.2.3.2" xref="S3.E1.m1.2.2.3.2.cmml">L</mi><mi id="S3.E1.m1.2.2.3.3" xref="S3.E1.m1.2.2.3.3.cmml">c</mi></msub><mo rspace="0.111em" id="S3.E1.m1.2.2.2" xref="S3.E1.m1.2.2.2.cmml">=</mo><mrow id="S3.E1.m1.2.2.1" xref="S3.E1.m1.2.2.1.cmml"><munderover id="S3.E1.m1.2.2.1.3" xref="S3.E1.m1.2.2.1.3.cmml"><mo movablelimits="false" rspace="0em" id="S3.E1.m1.2.2.1.3.2.2" xref="S3.E1.m1.2.2.1.3.2.2.cmml">∑</mo><mrow id="S3.E1.m1.2.2.1.3.2.3" xref="S3.E1.m1.2.2.1.3.2.3.cmml"><mi id="S3.E1.m1.2.2.1.3.2.3.2" xref="S3.E1.m1.2.2.1.3.2.3.2.cmml">i</mi><mo id="S3.E1.m1.2.2.1.3.2.3.1" xref="S3.E1.m1.2.2.1.3.2.3.1.cmml">=</mo><mn id="S3.E1.m1.2.2.1.3.2.3.3" xref="S3.E1.m1.2.2.1.3.2.3.3.cmml">1</mn></mrow><mi id="S3.E1.m1.2.2.1.3.3" xref="S3.E1.m1.2.2.1.3.3.cmml">A</mi></munderover><mo lspace="0em" id="S3.E1.m1.2.2.1.2" xref="S3.E1.m1.2.2.1.2.cmml">−</mo><mrow id="S3.E1.m1.2.2.1.1.1" xref="S3.E1.m1.2.2.1.1.2.cmml"><mo stretchy="false" id="S3.E1.m1.2.2.1.1.1.2" xref="S3.E1.m1.2.2.1.1.2.1.cmml">[</mo><mrow id="S3.E1.m1.2.2.1.1.1.1" xref="S3.E1.m1.2.2.1.1.1.1.cmml"><mrow id="S3.E1.m1.2.2.1.1.1.1.1" xref="S3.E1.m1.2.2.1.1.1.1.1.cmml"><mrow id="S3.E1.m1.2.2.1.1.1.1.1.3" xref="S3.E1.m1.2.2.1.1.1.1.1.3.cmml"><msub id="S3.E1.m1.2.2.1.1.1.1.1.3.2" xref="S3.E1.m1.2.2.1.1.1.1.1.3.2.cmml"><mover accent="true" id="S3.E1.m1.2.2.1.1.1.1.1.3.2.2" xref="S3.E1.m1.2.2.1.1.1.1.1.3.2.2.cmml"><mi id="S3.E1.m1.2.2.1.1.1.1.1.3.2.2.2" xref="S3.E1.m1.2.2.1.1.1.1.1.3.2.2.2.cmml">a</mi><mo id="S3.E1.m1.2.2.1.1.1.1.1.3.2.2.1" xref="S3.E1.m1.2.2.1.1.1.1.1.3.2.2.1.cmml">^</mo></mover><mi id="S3.E1.m1.2.2.1.1.1.1.1.3.2.3" xref="S3.E1.m1.2.2.1.1.1.1.1.3.2.3.cmml">i</mi></msub><mo lspace="0.222em" rspace="0.222em" id="S3.E1.m1.2.2.1.1.1.1.1.3.1" xref="S3.E1.m1.2.2.1.1.1.1.1.3.1.cmml">∗</mo><mrow id="S3.E1.m1.2.2.1.1.1.1.1.3.3" xref="S3.E1.m1.2.2.1.1.1.1.1.3.3.cmml"><mi id="S3.E1.m1.2.2.1.1.1.1.1.3.3.1" xref="S3.E1.m1.2.2.1.1.1.1.1.3.3.1.cmml">log</mi><mo lspace="0.167em" id="S3.E1.m1.2.2.1.1.1.1.1.3.3a" xref="S3.E1.m1.2.2.1.1.1.1.1.3.3.cmml">⁡</mo><mi id="S3.E1.m1.2.2.1.1.1.1.1.3.3.2" xref="S3.E1.m1.2.2.1.1.1.1.1.3.3.2.cmml">σ</mi></mrow></mrow><mo lspace="0em" rspace="0em" id="S3.E1.m1.2.2.1.1.1.1.1.2" xref="S3.E1.m1.2.2.1.1.1.1.1.2.cmml">​</mo><mrow id="S3.E1.m1.2.2.1.1.1.1.1.1.1" xref="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E1.m1.2.2.1.1.1.1.1.1.1.2" xref="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.cmml">(</mo><msub id="S3.E1.m1.2.2.1.1.1.1.1.1.1.1" xref="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.2" xref="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.2.cmml">y</mi><mi id="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.3" xref="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo stretchy="false" id="S3.E1.m1.2.2.1.1.1.1.1.1.1.3" xref="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E1.m1.2.2.1.1.1.1.4" xref="S3.E1.m1.2.2.1.1.1.1.4.cmml">+</mo><mrow id="S3.E1.m1.2.2.1.1.1.1.3" xref="S3.E1.m1.2.2.1.1.1.1.3.cmml"><mrow id="S3.E1.m1.2.2.1.1.1.1.2.1.1" xref="S3.E1.m1.2.2.1.1.1.1.2.1.1.1.cmml"><mo stretchy="false" id="S3.E1.m1.2.2.1.1.1.1.2.1.1.2" xref="S3.E1.m1.2.2.1.1.1.1.2.1.1.1.cmml">(</mo><mrow id="S3.E1.m1.2.2.1.1.1.1.2.1.1.1" xref="S3.E1.m1.2.2.1.1.1.1.2.1.1.1.cmml"><mn id="S3.E1.m1.2.2.1.1.1.1.2.1.1.1.2" xref="S3.E1.m1.2.2.1.1.1.1.2.1.1.1.2.cmml">1</mn><mo id="S3.E1.m1.2.2.1.1.1.1.2.1.1.1.1" xref="S3.E1.m1.2.2.1.1.1.1.2.1.1.1.1.cmml">−</mo><msub id="S3.E1.m1.2.2.1.1.1.1.2.1.1.1.3" xref="S3.E1.m1.2.2.1.1.1.1.2.1.1.1.3.cmml"><mover accent="true" id="S3.E1.m1.2.2.1.1.1.1.2.1.1.1.3.2" xref="S3.E1.m1.2.2.1.1.1.1.2.1.1.1.3.2.cmml"><mi id="S3.E1.m1.2.2.1.1.1.1.2.1.1.1.3.2.2" xref="S3.E1.m1.2.2.1.1.1.1.2.1.1.1.3.2.2.cmml">a</mi><mo id="S3.E1.m1.2.2.1.1.1.1.2.1.1.1.3.2.1" xref="S3.E1.m1.2.2.1.1.1.1.2.1.1.1.3.2.1.cmml">^</mo></mover><mi id="S3.E1.m1.2.2.1.1.1.1.2.1.1.1.3.3" xref="S3.E1.m1.2.2.1.1.1.1.2.1.1.1.3.3.cmml">i</mi></msub></mrow><mo rspace="0.055em" stretchy="false" id="S3.E1.m1.2.2.1.1.1.1.2.1.1.3" xref="S3.E1.m1.2.2.1.1.1.1.2.1.1.1.cmml">)</mo></mrow><mo rspace="0.222em" id="S3.E1.m1.2.2.1.1.1.1.3.3" xref="S3.E1.m1.2.2.1.1.1.1.3.3.cmml">∗</mo><mrow id="S3.E1.m1.2.2.1.1.1.1.3.2.1" xref="S3.E1.m1.2.2.1.1.1.1.3.2.2.cmml"><mi id="S3.E1.m1.1.1" xref="S3.E1.m1.1.1.cmml">log</mi><mo id="S3.E1.m1.2.2.1.1.1.1.3.2.1a" xref="S3.E1.m1.2.2.1.1.1.1.3.2.2.cmml">⁡</mo><mrow id="S3.E1.m1.2.2.1.1.1.1.3.2.1.1" xref="S3.E1.m1.2.2.1.1.1.1.3.2.2.cmml"><mo stretchy="false" id="S3.E1.m1.2.2.1.1.1.1.3.2.1.1.2" xref="S3.E1.m1.2.2.1.1.1.1.3.2.2.cmml">(</mo><mrow id="S3.E1.m1.2.2.1.1.1.1.3.2.1.1.1" xref="S3.E1.m1.2.2.1.1.1.1.3.2.1.1.1.cmml"><mn id="S3.E1.m1.2.2.1.1.1.1.3.2.1.1.1.3" xref="S3.E1.m1.2.2.1.1.1.1.3.2.1.1.1.3.cmml">1</mn><mo id="S3.E1.m1.2.2.1.1.1.1.3.2.1.1.1.2" xref="S3.E1.m1.2.2.1.1.1.1.3.2.1.1.1.2.cmml">−</mo><mrow id="S3.E1.m1.2.2.1.1.1.1.3.2.1.1.1.1" xref="S3.E1.m1.2.2.1.1.1.1.3.2.1.1.1.1.cmml"><mi id="S3.E1.m1.2.2.1.1.1.1.3.2.1.1.1.1.3" xref="S3.E1.m1.2.2.1.1.1.1.3.2.1.1.1.1.3.cmml">σ</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.2.2.1.1.1.1.3.2.1.1.1.1.2" xref="S3.E1.m1.2.2.1.1.1.1.3.2.1.1.1.1.2.cmml">​</mo><mrow id="S3.E1.m1.2.2.1.1.1.1.3.2.1.1.1.1.1.1" xref="S3.E1.m1.2.2.1.1.1.1.3.2.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E1.m1.2.2.1.1.1.1.3.2.1.1.1.1.1.1.2" xref="S3.E1.m1.2.2.1.1.1.1.3.2.1.1.1.1.1.1.1.cmml">(</mo><msub id="S3.E1.m1.2.2.1.1.1.1.3.2.1.1.1.1.1.1.1" xref="S3.E1.m1.2.2.1.1.1.1.3.2.1.1.1.1.1.1.1.cmml"><mi id="S3.E1.m1.2.2.1.1.1.1.3.2.1.1.1.1.1.1.1.2" xref="S3.E1.m1.2.2.1.1.1.1.3.2.1.1.1.1.1.1.1.2.cmml">y</mi><mi id="S3.E1.m1.2.2.1.1.1.1.3.2.1.1.1.1.1.1.1.3" xref="S3.E1.m1.2.2.1.1.1.1.3.2.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo stretchy="false" id="S3.E1.m1.2.2.1.1.1.1.3.2.1.1.1.1.1.1.3" xref="S3.E1.m1.2.2.1.1.1.1.3.2.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo stretchy="false" id="S3.E1.m1.2.2.1.1.1.1.3.2.1.1.3" xref="S3.E1.m1.2.2.1.1.1.1.3.2.2.cmml">)</mo></mrow></mrow></mrow></mrow><mo stretchy="false" id="S3.E1.m1.2.2.1.1.1.3" xref="S3.E1.m1.2.2.1.1.2.1.cmml">]</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.2b"><apply id="S3.E1.m1.2.2.cmml" xref="S3.E1.m1.2.2"><eq id="S3.E1.m1.2.2.2.cmml" xref="S3.E1.m1.2.2.2"></eq><apply id="S3.E1.m1.2.2.3.cmml" xref="S3.E1.m1.2.2.3"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.3.1.cmml" xref="S3.E1.m1.2.2.3">subscript</csymbol><ci id="S3.E1.m1.2.2.3.2.cmml" xref="S3.E1.m1.2.2.3.2">𝐿</ci><ci id="S3.E1.m1.2.2.3.3.cmml" xref="S3.E1.m1.2.2.3.3">𝑐</ci></apply><apply id="S3.E1.m1.2.2.1.cmml" xref="S3.E1.m1.2.2.1"><minus id="S3.E1.m1.2.2.1.2.cmml" xref="S3.E1.m1.2.2.1.2"></minus><apply id="S3.E1.m1.2.2.1.3.cmml" xref="S3.E1.m1.2.2.1.3"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.1.3.1.cmml" xref="S3.E1.m1.2.2.1.3">superscript</csymbol><apply id="S3.E1.m1.2.2.1.3.2.cmml" xref="S3.E1.m1.2.2.1.3"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.1.3.2.1.cmml" xref="S3.E1.m1.2.2.1.3">subscript</csymbol><sum id="S3.E1.m1.2.2.1.3.2.2.cmml" xref="S3.E1.m1.2.2.1.3.2.2"></sum><apply id="S3.E1.m1.2.2.1.3.2.3.cmml" xref="S3.E1.m1.2.2.1.3.2.3"><eq id="S3.E1.m1.2.2.1.3.2.3.1.cmml" xref="S3.E1.m1.2.2.1.3.2.3.1"></eq><ci id="S3.E1.m1.2.2.1.3.2.3.2.cmml" xref="S3.E1.m1.2.2.1.3.2.3.2">𝑖</ci><cn type="integer" id="S3.E1.m1.2.2.1.3.2.3.3.cmml" xref="S3.E1.m1.2.2.1.3.2.3.3">1</cn></apply></apply><ci id="S3.E1.m1.2.2.1.3.3.cmml" xref="S3.E1.m1.2.2.1.3.3">𝐴</ci></apply><apply id="S3.E1.m1.2.2.1.1.2.cmml" xref="S3.E1.m1.2.2.1.1.1"><csymbol cd="latexml" id="S3.E1.m1.2.2.1.1.2.1.cmml" xref="S3.E1.m1.2.2.1.1.1.2">delimited-[]</csymbol><apply id="S3.E1.m1.2.2.1.1.1.1.cmml" xref="S3.E1.m1.2.2.1.1.1.1"><plus id="S3.E1.m1.2.2.1.1.1.1.4.cmml" xref="S3.E1.m1.2.2.1.1.1.1.4"></plus><apply id="S3.E1.m1.2.2.1.1.1.1.1.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1"><times id="S3.E1.m1.2.2.1.1.1.1.1.2.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.2"></times><apply id="S3.E1.m1.2.2.1.1.1.1.1.3.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.3"><times id="S3.E1.m1.2.2.1.1.1.1.1.3.1.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.3.1"></times><apply id="S3.E1.m1.2.2.1.1.1.1.1.3.2.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.3.2"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.1.1.1.1.1.3.2.1.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.3.2">subscript</csymbol><apply id="S3.E1.m1.2.2.1.1.1.1.1.3.2.2.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.3.2.2"><ci id="S3.E1.m1.2.2.1.1.1.1.1.3.2.2.1.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.3.2.2.1">^</ci><ci id="S3.E1.m1.2.2.1.1.1.1.1.3.2.2.2.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.3.2.2.2">𝑎</ci></apply><ci id="S3.E1.m1.2.2.1.1.1.1.1.3.2.3.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.3.2.3">𝑖</ci></apply><apply id="S3.E1.m1.2.2.1.1.1.1.1.3.3.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.3.3"><log id="S3.E1.m1.2.2.1.1.1.1.1.3.3.1.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.3.3.1"></log><ci id="S3.E1.m1.2.2.1.1.1.1.1.3.3.2.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.3.3.2">𝜎</ci></apply></apply><apply id="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.2">𝑦</ci><ci id="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.3">𝑖</ci></apply></apply><apply id="S3.E1.m1.2.2.1.1.1.1.3.cmml" xref="S3.E1.m1.2.2.1.1.1.1.3"><times id="S3.E1.m1.2.2.1.1.1.1.3.3.cmml" xref="S3.E1.m1.2.2.1.1.1.1.3.3"></times><apply id="S3.E1.m1.2.2.1.1.1.1.2.1.1.1.cmml" xref="S3.E1.m1.2.2.1.1.1.1.2.1.1"><minus id="S3.E1.m1.2.2.1.1.1.1.2.1.1.1.1.cmml" xref="S3.E1.m1.2.2.1.1.1.1.2.1.1.1.1"></minus><cn type="integer" id="S3.E1.m1.2.2.1.1.1.1.2.1.1.1.2.cmml" xref="S3.E1.m1.2.2.1.1.1.1.2.1.1.1.2">1</cn><apply id="S3.E1.m1.2.2.1.1.1.1.2.1.1.1.3.cmml" xref="S3.E1.m1.2.2.1.1.1.1.2.1.1.1.3"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.1.1.1.1.2.1.1.1.3.1.cmml" xref="S3.E1.m1.2.2.1.1.1.1.2.1.1.1.3">subscript</csymbol><apply id="S3.E1.m1.2.2.1.1.1.1.2.1.1.1.3.2.cmml" xref="S3.E1.m1.2.2.1.1.1.1.2.1.1.1.3.2"><ci id="S3.E1.m1.2.2.1.1.1.1.2.1.1.1.3.2.1.cmml" xref="S3.E1.m1.2.2.1.1.1.1.2.1.1.1.3.2.1">^</ci><ci id="S3.E1.m1.2.2.1.1.1.1.2.1.1.1.3.2.2.cmml" xref="S3.E1.m1.2.2.1.1.1.1.2.1.1.1.3.2.2">𝑎</ci></apply><ci id="S3.E1.m1.2.2.1.1.1.1.2.1.1.1.3.3.cmml" xref="S3.E1.m1.2.2.1.1.1.1.2.1.1.1.3.3">𝑖</ci></apply></apply><apply id="S3.E1.m1.2.2.1.1.1.1.3.2.2.cmml" xref="S3.E1.m1.2.2.1.1.1.1.3.2.1"><log id="S3.E1.m1.1.1.cmml" xref="S3.E1.m1.1.1"></log><apply id="S3.E1.m1.2.2.1.1.1.1.3.2.1.1.1.cmml" xref="S3.E1.m1.2.2.1.1.1.1.3.2.1.1.1"><minus id="S3.E1.m1.2.2.1.1.1.1.3.2.1.1.1.2.cmml" xref="S3.E1.m1.2.2.1.1.1.1.3.2.1.1.1.2"></minus><cn type="integer" id="S3.E1.m1.2.2.1.1.1.1.3.2.1.1.1.3.cmml" xref="S3.E1.m1.2.2.1.1.1.1.3.2.1.1.1.3">1</cn><apply id="S3.E1.m1.2.2.1.1.1.1.3.2.1.1.1.1.cmml" xref="S3.E1.m1.2.2.1.1.1.1.3.2.1.1.1.1"><times id="S3.E1.m1.2.2.1.1.1.1.3.2.1.1.1.1.2.cmml" xref="S3.E1.m1.2.2.1.1.1.1.3.2.1.1.1.1.2"></times><ci id="S3.E1.m1.2.2.1.1.1.1.3.2.1.1.1.1.3.cmml" xref="S3.E1.m1.2.2.1.1.1.1.3.2.1.1.1.1.3">𝜎</ci><apply id="S3.E1.m1.2.2.1.1.1.1.3.2.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.2.2.1.1.1.1.3.2.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.1.1.1.1.3.2.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.2.2.1.1.1.1.3.2.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E1.m1.2.2.1.1.1.1.3.2.1.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.2.2.1.1.1.1.3.2.1.1.1.1.1.1.1.2">𝑦</ci><ci id="S3.E1.m1.2.2.1.1.1.1.3.2.1.1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.2.2.1.1.1.1.3.2.1.1.1.1.1.1.1.3">𝑖</ci></apply></apply></apply></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.2c">L_{c}=\sum_{i=1}^{A}-[\hat{a}_{i}*\log\sigma(y_{i})+(1-\hat{a}_{i})*\log(1-\sigma(y_{i}))]</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p id="S3.SS2.SSS0.Px1.p1.5" class="ltx_p">where <math id="S3.SS2.SSS0.Px1.p1.5.m1.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S3.SS2.SSS0.Px1.p1.5.m1.1a"><mi id="S3.SS2.SSS0.Px1.p1.5.m1.1.1" xref="S3.SS2.SSS0.Px1.p1.5.m1.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px1.p1.5.m1.1b"><ci id="S3.SS2.SSS0.Px1.p1.5.m1.1.1.cmml" xref="S3.SS2.SSS0.Px1.p1.5.m1.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px1.p1.5.m1.1c">i</annotation></semantics></math> indexes vector elements. The sum allows for multiple ground truth answers to a single training question.</p>
</div>
</section>
<section id="S3.SS2.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Regression loss.</h4>

<div id="S3.SS2.SSS0.Px2.p1" class="ltx_para">
<p id="S3.SS2.SSS0.Px2.p1.9" class="ltx_p">The output of the additional regression branch produces the vector <math id="S3.SS2.SSS0.Px2.p1.1.m1.1" class="ltx_Math" alttext="\boldsymbol{p}\in\mathbb{R}^{P}" display="inline"><semantics id="S3.SS2.SSS0.Px2.p1.1.m1.1a"><mrow id="S3.SS2.SSS0.Px2.p1.1.m1.1.1" xref="S3.SS2.SSS0.Px2.p1.1.m1.1.1.cmml"><mi id="S3.SS2.SSS0.Px2.p1.1.m1.1.1.2" xref="S3.SS2.SSS0.Px2.p1.1.m1.1.1.2.cmml">𝒑</mi><mo id="S3.SS2.SSS0.Px2.p1.1.m1.1.1.1" xref="S3.SS2.SSS0.Px2.p1.1.m1.1.1.1.cmml">∈</mo><msup id="S3.SS2.SSS0.Px2.p1.1.m1.1.1.3" xref="S3.SS2.SSS0.Px2.p1.1.m1.1.1.3.cmml"><mi id="S3.SS2.SSS0.Px2.p1.1.m1.1.1.3.2" xref="S3.SS2.SSS0.Px2.p1.1.m1.1.1.3.2.cmml">ℝ</mi><mi id="S3.SS2.SSS0.Px2.p1.1.m1.1.1.3.3" xref="S3.SS2.SSS0.Px2.p1.1.m1.1.1.3.3.cmml">P</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px2.p1.1.m1.1b"><apply id="S3.SS2.SSS0.Px2.p1.1.m1.1.1.cmml" xref="S3.SS2.SSS0.Px2.p1.1.m1.1.1"><in id="S3.SS2.SSS0.Px2.p1.1.m1.1.1.1.cmml" xref="S3.SS2.SSS0.Px2.p1.1.m1.1.1.1"></in><ci id="S3.SS2.SSS0.Px2.p1.1.m1.1.1.2.cmml" xref="S3.SS2.SSS0.Px2.p1.1.m1.1.1.2">𝒑</ci><apply id="S3.SS2.SSS0.Px2.p1.1.m1.1.1.3.cmml" xref="S3.SS2.SSS0.Px2.p1.1.m1.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px2.p1.1.m1.1.1.3.1.cmml" xref="S3.SS2.SSS0.Px2.p1.1.m1.1.1.3">superscript</csymbol><ci id="S3.SS2.SSS0.Px2.p1.1.m1.1.1.3.2.cmml" xref="S3.SS2.SSS0.Px2.p1.1.m1.1.1.3.2">ℝ</ci><ci id="S3.SS2.SSS0.Px2.p1.1.m1.1.1.3.3.cmml" xref="S3.SS2.SSS0.Px2.p1.1.m1.1.1.3.3">𝑃</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px2.p1.1.m1.1c">\boldsymbol{p}\in\mathbb{R}^{P}</annotation></semantics></math>. It is interpreted as a location in a high-dimensional space that captures the semantics of the predicted answer. We store in a matrix <math id="S3.SS2.SSS0.Px2.p1.2.m2.1" class="ltx_Math" alttext="M_{{A}\times{P}}" display="inline"><semantics id="S3.SS2.SSS0.Px2.p1.2.m2.1a"><msub id="S3.SS2.SSS0.Px2.p1.2.m2.1.1" xref="S3.SS2.SSS0.Px2.p1.2.m2.1.1.cmml"><mi id="S3.SS2.SSS0.Px2.p1.2.m2.1.1.2" xref="S3.SS2.SSS0.Px2.p1.2.m2.1.1.2.cmml">M</mi><mrow id="S3.SS2.SSS0.Px2.p1.2.m2.1.1.3" xref="S3.SS2.SSS0.Px2.p1.2.m2.1.1.3.cmml"><mi id="S3.SS2.SSS0.Px2.p1.2.m2.1.1.3.2" xref="S3.SS2.SSS0.Px2.p1.2.m2.1.1.3.2.cmml">A</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS2.SSS0.Px2.p1.2.m2.1.1.3.1" xref="S3.SS2.SSS0.Px2.p1.2.m2.1.1.3.1.cmml">×</mo><mi id="S3.SS2.SSS0.Px2.p1.2.m2.1.1.3.3" xref="S3.SS2.SSS0.Px2.p1.2.m2.1.1.3.3.cmml">P</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px2.p1.2.m2.1b"><apply id="S3.SS2.SSS0.Px2.p1.2.m2.1.1.cmml" xref="S3.SS2.SSS0.Px2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px2.p1.2.m2.1.1.1.cmml" xref="S3.SS2.SSS0.Px2.p1.2.m2.1.1">subscript</csymbol><ci id="S3.SS2.SSS0.Px2.p1.2.m2.1.1.2.cmml" xref="S3.SS2.SSS0.Px2.p1.2.m2.1.1.2">𝑀</ci><apply id="S3.SS2.SSS0.Px2.p1.2.m2.1.1.3.cmml" xref="S3.SS2.SSS0.Px2.p1.2.m2.1.1.3"><times id="S3.SS2.SSS0.Px2.p1.2.m2.1.1.3.1.cmml" xref="S3.SS2.SSS0.Px2.p1.2.m2.1.1.3.1"></times><ci id="S3.SS2.SSS0.Px2.p1.2.m2.1.1.3.2.cmml" xref="S3.SS2.SSS0.Px2.p1.2.m2.1.1.3.2">𝐴</ci><ci id="S3.SS2.SSS0.Px2.p1.2.m2.1.1.3.3.cmml" xref="S3.SS2.SSS0.Px2.p1.2.m2.1.1.3.3">𝑃</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px2.p1.2.m2.1c">M_{{A}\times{P}}</annotation></semantics></math> representations of <math id="S3.SS2.SSS0.Px2.p1.3.m3.1" class="ltx_Math" alttext="{A}" display="inline"><semantics id="S3.SS2.SSS0.Px2.p1.3.m3.1a"><mi id="S3.SS2.SSS0.Px2.p1.3.m3.1.1" xref="S3.SS2.SSS0.Px2.p1.3.m3.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px2.p1.3.m3.1b"><ci id="S3.SS2.SSS0.Px2.p1.3.m3.1.1.cmml" xref="S3.SS2.SSS0.Px2.p1.3.m3.1.1">𝐴</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px2.p1.3.m3.1c">{A}</annotation></semantics></math> candidate answers in this space (<math id="S3.SS2.SSS0.Px2.p1.4.m4.1" class="ltx_Math" alttext="{P}" display="inline"><semantics id="S3.SS2.SSS0.Px2.p1.4.m4.1a"><mi id="S3.SS2.SSS0.Px2.p1.4.m4.1.1" xref="S3.SS2.SSS0.Px2.p1.4.m4.1.1.cmml">P</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px2.p1.4.m4.1b"><ci id="S3.SS2.SSS0.Px2.p1.4.m4.1.1.cmml" xref="S3.SS2.SSS0.Px2.p1.4.m4.1.1">𝑃</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px2.p1.4.m4.1c">{P}</annotation></semantics></math>-dimensional row vectors). These representations can be learned or initialized using prior knowledge, as described below. The objective of the regression branch is to produce a vector <math id="S3.SS2.SSS0.Px2.p1.5.m5.1" class="ltx_Math" alttext="\boldsymbol{p}" display="inline"><semantics id="S3.SS2.SSS0.Px2.p1.5.m5.1a"><mi id="S3.SS2.SSS0.Px2.p1.5.m5.1.1" xref="S3.SS2.SSS0.Px2.p1.5.m5.1.1.cmml">𝒑</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px2.p1.5.m5.1b"><ci id="S3.SS2.SSS0.Px2.p1.5.m5.1.1.cmml" xref="S3.SS2.SSS0.Px2.p1.5.m5.1.1">𝒑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px2.p1.5.m5.1c">\boldsymbol{p}</annotation></semantics></math> close to the representation of the ground truth answer, and distinct from those of incorrect ones. Using a metric <math id="S3.SS2.SSS0.Px2.p1.6.m6.3" class="ltx_Math" alttext="\operatorname*{dist}(\cdot,\cdot)" display="inline"><semantics id="S3.SS2.SSS0.Px2.p1.6.m6.3a"><mrow id="S3.SS2.SSS0.Px2.p1.6.m6.3.4.2" xref="S3.SS2.SSS0.Px2.p1.6.m6.3.4.1.cmml"><mo rspace="0em" id="S3.SS2.SSS0.Px2.p1.6.m6.1.1" xref="S3.SS2.SSS0.Px2.p1.6.m6.1.1.cmml">dist</mo><mrow id="S3.SS2.SSS0.Px2.p1.6.m6.3.4.2.1" xref="S3.SS2.SSS0.Px2.p1.6.m6.3.4.1.cmml"><mo stretchy="false" id="S3.SS2.SSS0.Px2.p1.6.m6.3.4.2.1.1" xref="S3.SS2.SSS0.Px2.p1.6.m6.3.4.1.cmml">(</mo><mo lspace="0em" rspace="0em" id="S3.SS2.SSS0.Px2.p1.6.m6.2.2" xref="S3.SS2.SSS0.Px2.p1.6.m6.2.2.cmml">⋅</mo><mo rspace="0em" id="S3.SS2.SSS0.Px2.p1.6.m6.3.4.2.1.2" xref="S3.SS2.SSS0.Px2.p1.6.m6.3.4.1.cmml">,</mo><mo lspace="0em" rspace="0em" id="S3.SS2.SSS0.Px2.p1.6.m6.3.3" xref="S3.SS2.SSS0.Px2.p1.6.m6.3.3.cmml">⋅</mo><mo stretchy="false" id="S3.SS2.SSS0.Px2.p1.6.m6.3.4.2.1.3" xref="S3.SS2.SSS0.Px2.p1.6.m6.3.4.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px2.p1.6.m6.3b"><apply id="S3.SS2.SSS0.Px2.p1.6.m6.3.4.1.cmml" xref="S3.SS2.SSS0.Px2.p1.6.m6.3.4.2"><ci id="S3.SS2.SSS0.Px2.p1.6.m6.1.1.cmml" xref="S3.SS2.SSS0.Px2.p1.6.m6.1.1">dist</ci><ci id="S3.SS2.SSS0.Px2.p1.6.m6.2.2.cmml" xref="S3.SS2.SSS0.Px2.p1.6.m6.2.2">⋅</ci><ci id="S3.SS2.SSS0.Px2.p1.6.m6.3.3.cmml" xref="S3.SS2.SSS0.Px2.p1.6.m6.3.3">⋅</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px2.p1.6.m6.3c">\operatorname*{dist}(\cdot,\cdot)</annotation></semantics></math>, we compute all distances between <math id="S3.SS2.SSS0.Px2.p1.7.m7.1" class="ltx_Math" alttext="\boldsymbol{p}" display="inline"><semantics id="S3.SS2.SSS0.Px2.p1.7.m7.1a"><mi id="S3.SS2.SSS0.Px2.p1.7.m7.1.1" xref="S3.SS2.SSS0.Px2.p1.7.m7.1.1.cmml">𝒑</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px2.p1.7.m7.1b"><ci id="S3.SS2.SSS0.Px2.p1.7.m7.1.1.cmml" xref="S3.SS2.SSS0.Px2.p1.7.m7.1.1">𝒑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px2.p1.7.m7.1c">\boldsymbol{p}</annotation></semantics></math> and the rows of <math id="S3.SS2.SSS0.Px2.p1.8.m8.1" class="ltx_Math" alttext="M" display="inline"><semantics id="S3.SS2.SSS0.Px2.p1.8.m8.1a"><mi id="S3.SS2.SSS0.Px2.p1.8.m8.1.1" xref="S3.SS2.SSS0.Px2.p1.8.m8.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px2.p1.8.m8.1b"><ci id="S3.SS2.SSS0.Px2.p1.8.m8.1.1.cmml" xref="S3.SS2.SSS0.Px2.p1.8.m8.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px2.p1.8.m8.1c">M</annotation></semantics></math>, noted as <math id="S3.SS2.SSS0.Px2.p1.9.m9.1" class="ltx_Math" alttext="M_{i}" display="inline"><semantics id="S3.SS2.SSS0.Px2.p1.9.m9.1a"><msub id="S3.SS2.SSS0.Px2.p1.9.m9.1.1" xref="S3.SS2.SSS0.Px2.p1.9.m9.1.1.cmml"><mi id="S3.SS2.SSS0.Px2.p1.9.m9.1.1.2" xref="S3.SS2.SSS0.Px2.p1.9.m9.1.1.2.cmml">M</mi><mi id="S3.SS2.SSS0.Px2.p1.9.m9.1.1.3" xref="S3.SS2.SSS0.Px2.p1.9.m9.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px2.p1.9.m9.1b"><apply id="S3.SS2.SSS0.Px2.p1.9.m9.1.1.cmml" xref="S3.SS2.SSS0.Px2.p1.9.m9.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px2.p1.9.m9.1.1.1.cmml" xref="S3.SS2.SSS0.Px2.p1.9.m9.1.1">subscript</csymbol><ci id="S3.SS2.SSS0.Px2.p1.9.m9.1.1.2.cmml" xref="S3.SS2.SSS0.Px2.p1.9.m9.1.1.2">𝑀</ci><ci id="S3.SS2.SSS0.Px2.p1.9.m9.1.1.3.cmml" xref="S3.SS2.SSS0.Px2.p1.9.m9.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px2.p1.9.m9.1c">M_{i}</annotation></semantics></math>. We have</p>
<table id="S3.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E2.m1.4" class="ltx_Math" alttext="\boldsymbol{d}=[d_{1},d_{2},...,d_{A}]~{}~{}~{}\textrm{with}~{}~{}d_{i}=\operatorname*{dist}(\boldsymbol{p},M_{i})~{}." display="block"><semantics id="S3.E2.m1.4a"><mrow id="S3.E2.m1.4.4.1" xref="S3.E2.m1.4.4.1.1.cmml"><mrow id="S3.E2.m1.4.4.1.1" xref="S3.E2.m1.4.4.1.1.cmml"><mi id="S3.E2.m1.4.4.1.1.6" xref="S3.E2.m1.4.4.1.1.6.cmml">𝒅</mi><mo id="S3.E2.m1.4.4.1.1.7" xref="S3.E2.m1.4.4.1.1.7.cmml">=</mo><mrow id="S3.E2.m1.4.4.1.1.3" xref="S3.E2.m1.4.4.1.1.3.cmml"><mrow id="S3.E2.m1.4.4.1.1.3.3.3" xref="S3.E2.m1.4.4.1.1.3.3.4.cmml"><mo stretchy="false" id="S3.E2.m1.4.4.1.1.3.3.3.4" xref="S3.E2.m1.4.4.1.1.3.3.4.cmml">[</mo><msub id="S3.E2.m1.4.4.1.1.1.1.1.1" xref="S3.E2.m1.4.4.1.1.1.1.1.1.cmml"><mi id="S3.E2.m1.4.4.1.1.1.1.1.1.2" xref="S3.E2.m1.4.4.1.1.1.1.1.1.2.cmml">d</mi><mn id="S3.E2.m1.4.4.1.1.1.1.1.1.3" xref="S3.E2.m1.4.4.1.1.1.1.1.1.3.cmml">1</mn></msub><mo id="S3.E2.m1.4.4.1.1.3.3.3.5" xref="S3.E2.m1.4.4.1.1.3.3.4.cmml">,</mo><msub id="S3.E2.m1.4.4.1.1.2.2.2.2" xref="S3.E2.m1.4.4.1.1.2.2.2.2.cmml"><mi id="S3.E2.m1.4.4.1.1.2.2.2.2.2" xref="S3.E2.m1.4.4.1.1.2.2.2.2.2.cmml">d</mi><mn id="S3.E2.m1.4.4.1.1.2.2.2.2.3" xref="S3.E2.m1.4.4.1.1.2.2.2.2.3.cmml">2</mn></msub><mo id="S3.E2.m1.4.4.1.1.3.3.3.6" xref="S3.E2.m1.4.4.1.1.3.3.4.cmml">,</mo><mi mathvariant="normal" id="S3.E2.m1.1.1" xref="S3.E2.m1.1.1.cmml">…</mi><mo id="S3.E2.m1.4.4.1.1.3.3.3.7" xref="S3.E2.m1.4.4.1.1.3.3.4.cmml">,</mo><msub id="S3.E2.m1.4.4.1.1.3.3.3.3" xref="S3.E2.m1.4.4.1.1.3.3.3.3.cmml"><mi id="S3.E2.m1.4.4.1.1.3.3.3.3.2" xref="S3.E2.m1.4.4.1.1.3.3.3.3.2.cmml">d</mi><mi id="S3.E2.m1.4.4.1.1.3.3.3.3.3" xref="S3.E2.m1.4.4.1.1.3.3.3.3.3.cmml">A</mi></msub><mo stretchy="false" id="S3.E2.m1.4.4.1.1.3.3.3.8" xref="S3.E2.m1.4.4.1.1.3.3.4.cmml">]</mo></mrow><mo lspace="0.990em" rspace="0em" id="S3.E2.m1.4.4.1.1.3.4" xref="S3.E2.m1.4.4.1.1.3.4.cmml">​</mo><mtext id="S3.E2.m1.4.4.1.1.3.5" xref="S3.E2.m1.4.4.1.1.3.5a.cmml">with</mtext><mo lspace="0.660em" rspace="0em" id="S3.E2.m1.4.4.1.1.3.4a" xref="S3.E2.m1.4.4.1.1.3.4.cmml">​</mo><msub id="S3.E2.m1.4.4.1.1.3.6" xref="S3.E2.m1.4.4.1.1.3.6.cmml"><mi id="S3.E2.m1.4.4.1.1.3.6.2" xref="S3.E2.m1.4.4.1.1.3.6.2.cmml">d</mi><mi id="S3.E2.m1.4.4.1.1.3.6.3" xref="S3.E2.m1.4.4.1.1.3.6.3.cmml">i</mi></msub></mrow><mo rspace="0.1389em" id="S3.E2.m1.4.4.1.1.8" xref="S3.E2.m1.4.4.1.1.8.cmml">=</mo><mrow id="S3.E2.m1.4.4.1.1.4.1" xref="S3.E2.m1.4.4.1.1.4.2.cmml"><mo lspace="0.1389em" rspace="0em" id="S3.E2.m1.2.2" xref="S3.E2.m1.2.2.cmml">dist</mo><mrow id="S3.E2.m1.4.4.1.1.4.1.1" xref="S3.E2.m1.4.4.1.1.4.2.cmml"><mo stretchy="false" id="S3.E2.m1.4.4.1.1.4.1.1.2" xref="S3.E2.m1.4.4.1.1.4.2.cmml">(</mo><mi id="S3.E2.m1.3.3" xref="S3.E2.m1.3.3.cmml">𝒑</mi><mo id="S3.E2.m1.4.4.1.1.4.1.1.3" xref="S3.E2.m1.4.4.1.1.4.2.cmml">,</mo><msub id="S3.E2.m1.4.4.1.1.4.1.1.1" xref="S3.E2.m1.4.4.1.1.4.1.1.1.cmml"><mi id="S3.E2.m1.4.4.1.1.4.1.1.1.2" xref="S3.E2.m1.4.4.1.1.4.1.1.1.2.cmml">M</mi><mi id="S3.E2.m1.4.4.1.1.4.1.1.1.3" xref="S3.E2.m1.4.4.1.1.4.1.1.1.3.cmml">i</mi></msub><mo rspace="0.052em" stretchy="false" id="S3.E2.m1.4.4.1.1.4.1.1.4" xref="S3.E2.m1.4.4.1.1.4.2.cmml">)</mo></mrow></mrow></mrow><mo id="S3.E2.m1.4.4.1.2" xref="S3.E2.m1.4.4.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.4b"><apply id="S3.E2.m1.4.4.1.1.cmml" xref="S3.E2.m1.4.4.1"><and id="S3.E2.m1.4.4.1.1a.cmml" xref="S3.E2.m1.4.4.1"></and><apply id="S3.E2.m1.4.4.1.1b.cmml" xref="S3.E2.m1.4.4.1"><eq id="S3.E2.m1.4.4.1.1.7.cmml" xref="S3.E2.m1.4.4.1.1.7"></eq><ci id="S3.E2.m1.4.4.1.1.6.cmml" xref="S3.E2.m1.4.4.1.1.6">𝒅</ci><apply id="S3.E2.m1.4.4.1.1.3.cmml" xref="S3.E2.m1.4.4.1.1.3"><times id="S3.E2.m1.4.4.1.1.3.4.cmml" xref="S3.E2.m1.4.4.1.1.3.4"></times><list id="S3.E2.m1.4.4.1.1.3.3.4.cmml" xref="S3.E2.m1.4.4.1.1.3.3.3"><apply id="S3.E2.m1.4.4.1.1.1.1.1.1.cmml" xref="S3.E2.m1.4.4.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.4.4.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.4.4.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E2.m1.4.4.1.1.1.1.1.1.2.cmml" xref="S3.E2.m1.4.4.1.1.1.1.1.1.2">𝑑</ci><cn type="integer" id="S3.E2.m1.4.4.1.1.1.1.1.1.3.cmml" xref="S3.E2.m1.4.4.1.1.1.1.1.1.3">1</cn></apply><apply id="S3.E2.m1.4.4.1.1.2.2.2.2.cmml" xref="S3.E2.m1.4.4.1.1.2.2.2.2"><csymbol cd="ambiguous" id="S3.E2.m1.4.4.1.1.2.2.2.2.1.cmml" xref="S3.E2.m1.4.4.1.1.2.2.2.2">subscript</csymbol><ci id="S3.E2.m1.4.4.1.1.2.2.2.2.2.cmml" xref="S3.E2.m1.4.4.1.1.2.2.2.2.2">𝑑</ci><cn type="integer" id="S3.E2.m1.4.4.1.1.2.2.2.2.3.cmml" xref="S3.E2.m1.4.4.1.1.2.2.2.2.3">2</cn></apply><ci id="S3.E2.m1.1.1.cmml" xref="S3.E2.m1.1.1">…</ci><apply id="S3.E2.m1.4.4.1.1.3.3.3.3.cmml" xref="S3.E2.m1.4.4.1.1.3.3.3.3"><csymbol cd="ambiguous" id="S3.E2.m1.4.4.1.1.3.3.3.3.1.cmml" xref="S3.E2.m1.4.4.1.1.3.3.3.3">subscript</csymbol><ci id="S3.E2.m1.4.4.1.1.3.3.3.3.2.cmml" xref="S3.E2.m1.4.4.1.1.3.3.3.3.2">𝑑</ci><ci id="S3.E2.m1.4.4.1.1.3.3.3.3.3.cmml" xref="S3.E2.m1.4.4.1.1.3.3.3.3.3">𝐴</ci></apply></list><ci id="S3.E2.m1.4.4.1.1.3.5a.cmml" xref="S3.E2.m1.4.4.1.1.3.5"><mtext id="S3.E2.m1.4.4.1.1.3.5.cmml" xref="S3.E2.m1.4.4.1.1.3.5">with</mtext></ci><apply id="S3.E2.m1.4.4.1.1.3.6.cmml" xref="S3.E2.m1.4.4.1.1.3.6"><csymbol cd="ambiguous" id="S3.E2.m1.4.4.1.1.3.6.1.cmml" xref="S3.E2.m1.4.4.1.1.3.6">subscript</csymbol><ci id="S3.E2.m1.4.4.1.1.3.6.2.cmml" xref="S3.E2.m1.4.4.1.1.3.6.2">𝑑</ci><ci id="S3.E2.m1.4.4.1.1.3.6.3.cmml" xref="S3.E2.m1.4.4.1.1.3.6.3">𝑖</ci></apply></apply></apply><apply id="S3.E2.m1.4.4.1.1c.cmml" xref="S3.E2.m1.4.4.1"><eq id="S3.E2.m1.4.4.1.1.8.cmml" xref="S3.E2.m1.4.4.1.1.8"></eq><share href="#S3.E2.m1.4.4.1.1.3.cmml" id="S3.E2.m1.4.4.1.1d.cmml" xref="S3.E2.m1.4.4.1"></share><apply id="S3.E2.m1.4.4.1.1.4.2.cmml" xref="S3.E2.m1.4.4.1.1.4.1"><ci id="S3.E2.m1.2.2.cmml" xref="S3.E2.m1.2.2">dist</ci><ci id="S3.E2.m1.3.3.cmml" xref="S3.E2.m1.3.3">𝒑</ci><apply id="S3.E2.m1.4.4.1.1.4.1.1.1.cmml" xref="S3.E2.m1.4.4.1.1.4.1.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.4.4.1.1.4.1.1.1.1.cmml" xref="S3.E2.m1.4.4.1.1.4.1.1.1">subscript</csymbol><ci id="S3.E2.m1.4.4.1.1.4.1.1.1.2.cmml" xref="S3.E2.m1.4.4.1.1.4.1.1.1.2">𝑀</ci><ci id="S3.E2.m1.4.4.1.1.4.1.1.1.3.cmml" xref="S3.E2.m1.4.4.1.1.4.1.1.1.3">𝑖</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.4c">\boldsymbol{d}=[d_{1},d_{2},...,d_{A}]~{}~{}~{}\textrm{with}~{}~{}d_{i}=\operatorname*{dist}(\boldsymbol{p},M_{i})~{}.</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
</div>
<div id="S3.SS2.SSS0.Px2.p2" class="ltx_para">
<p id="S3.SS2.SSS0.Px2.p2.4" class="ltx_p">We then define a hinge loss on these distances:</p>
<table id="S3.E3" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center">
<div id="S3.E3.m1.1.1.1" class="ltx_inline-block ltx_markedasmath ltx_transformed_outer" style="width:216.8pt;height:36.4pt;vertical-align:-12.5pt;"><span class="ltx_transformed_inner" style="transform:translate(21.4pt,-2.4pt) scale(1.24539916931083,1.24539916931083) ;">
<p id="S3.E3.m1.1.1.1.1" class="ltx_p"><math id="S3.E3.m1.1.1.1.1.m1.4" class="ltx_Math" alttext="L_{p}=\sum_{i=1}^{{A}}l_{i}~{}~{}\textrm{with}~{}~{}l_{i}=\begin{cases}d_{i}&amp;\text{if }\hat{a}_{i}=1,\\
\max\{0,\delta-d_{i}\}&amp;\text{if }\hat{a}_{i}=0.\end{cases}" display="inline"><semantics id="S3.E3.m1.1.1.1.1.m1.4a"><mrow id="S3.E3.m1.1.1.1.1.m1.4.5" xref="S3.E3.m1.1.1.1.1.m1.4.5.cmml"><msub id="S3.E3.m1.1.1.1.1.m1.4.5.2" xref="S3.E3.m1.1.1.1.1.m1.4.5.2.cmml"><mi id="S3.E3.m1.1.1.1.1.m1.4.5.2.2" xref="S3.E3.m1.1.1.1.1.m1.4.5.2.2.cmml">L</mi><mi id="S3.E3.m1.1.1.1.1.m1.4.5.2.3" xref="S3.E3.m1.1.1.1.1.m1.4.5.2.3.cmml">p</mi></msub><mo rspace="0.111em" id="S3.E3.m1.1.1.1.1.m1.4.5.3" xref="S3.E3.m1.1.1.1.1.m1.4.5.3.cmml">=</mo><mrow id="S3.E3.m1.1.1.1.1.m1.4.5.4" xref="S3.E3.m1.1.1.1.1.m1.4.5.4.cmml"><msubsup id="S3.E3.m1.1.1.1.1.m1.4.5.4.1" xref="S3.E3.m1.1.1.1.1.m1.4.5.4.1.cmml"><mo id="S3.E3.m1.1.1.1.1.m1.4.5.4.1.2.2" xref="S3.E3.m1.1.1.1.1.m1.4.5.4.1.2.2.cmml">∑</mo><mrow id="S3.E3.m1.1.1.1.1.m1.4.5.4.1.2.3" xref="S3.E3.m1.1.1.1.1.m1.4.5.4.1.2.3.cmml"><mi id="S3.E3.m1.1.1.1.1.m1.4.5.4.1.2.3.2" xref="S3.E3.m1.1.1.1.1.m1.4.5.4.1.2.3.2.cmml">i</mi><mo id="S3.E3.m1.1.1.1.1.m1.4.5.4.1.2.3.1" xref="S3.E3.m1.1.1.1.1.m1.4.5.4.1.2.3.1.cmml">=</mo><mn id="S3.E3.m1.1.1.1.1.m1.4.5.4.1.2.3.3" xref="S3.E3.m1.1.1.1.1.m1.4.5.4.1.2.3.3.cmml">1</mn></mrow><mi id="S3.E3.m1.1.1.1.1.m1.4.5.4.1.3" xref="S3.E3.m1.1.1.1.1.m1.4.5.4.1.3.cmml">A</mi></msubsup><mrow id="S3.E3.m1.1.1.1.1.m1.4.5.4.2" xref="S3.E3.m1.1.1.1.1.m1.4.5.4.2.cmml"><msub id="S3.E3.m1.1.1.1.1.m1.4.5.4.2.2" xref="S3.E3.m1.1.1.1.1.m1.4.5.4.2.2.cmml"><mi id="S3.E3.m1.1.1.1.1.m1.4.5.4.2.2.2" xref="S3.E3.m1.1.1.1.1.m1.4.5.4.2.2.2.cmml">l</mi><mi id="S3.E3.m1.1.1.1.1.m1.4.5.4.2.2.3" xref="S3.E3.m1.1.1.1.1.m1.4.5.4.2.2.3.cmml">i</mi></msub><mo lspace="0em" rspace="0em" id="S3.E3.m1.1.1.1.1.m1.4.5.4.2.1" xref="S3.E3.m1.1.1.1.1.m1.4.5.4.2.1.cmml">​</mo><mtext id="S3.E3.m1.1.1.1.1.m1.4.5.4.2.3" xref="S3.E3.m1.1.1.1.1.m1.4.5.4.2.3a.cmml">with</mtext><mo lspace="0.660em" rspace="0em" id="S3.E3.m1.1.1.1.1.m1.4.5.4.2.1a" xref="S3.E3.m1.1.1.1.1.m1.4.5.4.2.1.cmml">​</mo><msub id="S3.E3.m1.1.1.1.1.m1.4.5.4.2.4" xref="S3.E3.m1.1.1.1.1.m1.4.5.4.2.4.cmml"><mi id="S3.E3.m1.1.1.1.1.m1.4.5.4.2.4.2" xref="S3.E3.m1.1.1.1.1.m1.4.5.4.2.4.2.cmml">l</mi><mi id="S3.E3.m1.1.1.1.1.m1.4.5.4.2.4.3" xref="S3.E3.m1.1.1.1.1.m1.4.5.4.2.4.3.cmml">i</mi></msub></mrow></mrow><mo id="S3.E3.m1.1.1.1.1.m1.4.5.5" xref="S3.E3.m1.1.1.1.1.m1.4.5.5.cmml">=</mo><mrow id="S3.E3.m1.1.1.1.1.m1.4.4" xref="S3.E3.m1.1.1.1.1.m1.4.5.6.1.cmml"><mo id="S3.E3.m1.1.1.1.1.m1.4.4.5" xref="S3.E3.m1.1.1.1.1.m1.4.5.6.1.1.cmml">{</mo><mtable columnspacing="5pt" rowspacing="0pt" id="S3.E3.m1.1.1.1.1.m1.4.4.4" xref="S3.E3.m1.1.1.1.1.m1.4.5.6.1.cmml"><mtr id="S3.E3.m1.1.1.1.1.m1.4.4.4a" xref="S3.E3.m1.1.1.1.1.m1.4.5.6.1.cmml"><mtd class="ltx_align_left" columnalign="left" id="S3.E3.m1.1.1.1.1.m1.4.4.4b" xref="S3.E3.m1.1.1.1.1.m1.4.5.6.1.cmml"><msub id="S3.E3.m1.1.1.1.1.m1.1.1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.m1.1.1.1.1.1.1.cmml"><mi id="S3.E3.m1.1.1.1.1.m1.1.1.1.1.1.1.2" xref="S3.E3.m1.1.1.1.1.m1.1.1.1.1.1.1.2.cmml">d</mi><mi id="S3.E3.m1.1.1.1.1.m1.1.1.1.1.1.1.3" xref="S3.E3.m1.1.1.1.1.m1.1.1.1.1.1.1.3.cmml">i</mi></msub></mtd><mtd class="ltx_align_left" columnalign="left" id="S3.E3.m1.1.1.1.1.m1.4.4.4c" xref="S3.E3.m1.1.1.1.1.m1.4.5.6.1.cmml"><mrow id="S3.E3.m1.1.1.1.1.m1.2.2.2.2.2.1.1" xref="S3.E3.m1.1.1.1.1.m1.2.2.2.2.2.1.1.1.cmml"><mrow id="S3.E3.m1.1.1.1.1.m1.2.2.2.2.2.1.1.1" xref="S3.E3.m1.1.1.1.1.m1.2.2.2.2.2.1.1.1.cmml"><mrow id="S3.E3.m1.1.1.1.1.m1.2.2.2.2.2.1.1.1.2" xref="S3.E3.m1.1.1.1.1.m1.2.2.2.2.2.1.1.1.2.cmml"><mtext id="S3.E3.m1.1.1.1.1.m1.2.2.2.2.2.1.1.1.2.2" xref="S3.E3.m1.1.1.1.1.m1.2.2.2.2.2.1.1.1.2.2a.cmml">if </mtext><mo lspace="0em" rspace="0em" id="S3.E3.m1.1.1.1.1.m1.2.2.2.2.2.1.1.1.2.1" xref="S3.E3.m1.1.1.1.1.m1.2.2.2.2.2.1.1.1.2.1.cmml">​</mo><msub id="S3.E3.m1.1.1.1.1.m1.2.2.2.2.2.1.1.1.2.3" xref="S3.E3.m1.1.1.1.1.m1.2.2.2.2.2.1.1.1.2.3.cmml"><mover accent="true" id="S3.E3.m1.1.1.1.1.m1.2.2.2.2.2.1.1.1.2.3.2" xref="S3.E3.m1.1.1.1.1.m1.2.2.2.2.2.1.1.1.2.3.2.cmml"><mi id="S3.E3.m1.1.1.1.1.m1.2.2.2.2.2.1.1.1.2.3.2.2" xref="S3.E3.m1.1.1.1.1.m1.2.2.2.2.2.1.1.1.2.3.2.2.cmml">a</mi><mo id="S3.E3.m1.1.1.1.1.m1.2.2.2.2.2.1.1.1.2.3.2.1" xref="S3.E3.m1.1.1.1.1.m1.2.2.2.2.2.1.1.1.2.3.2.1.cmml">^</mo></mover><mi id="S3.E3.m1.1.1.1.1.m1.2.2.2.2.2.1.1.1.2.3.3" xref="S3.E3.m1.1.1.1.1.m1.2.2.2.2.2.1.1.1.2.3.3.cmml">i</mi></msub></mrow><mo id="S3.E3.m1.1.1.1.1.m1.2.2.2.2.2.1.1.1.1" xref="S3.E3.m1.1.1.1.1.m1.2.2.2.2.2.1.1.1.1.cmml">=</mo><mn id="S3.E3.m1.1.1.1.1.m1.2.2.2.2.2.1.1.1.3" xref="S3.E3.m1.1.1.1.1.m1.2.2.2.2.2.1.1.1.3.cmml">1</mn></mrow><mo id="S3.E3.m1.1.1.1.1.m1.2.2.2.2.2.1.1.2" xref="S3.E3.m1.1.1.1.1.m1.2.2.2.2.2.1.1.1.cmml">,</mo></mrow></mtd></mtr><mtr id="S3.E3.m1.1.1.1.1.m1.4.4.4d" xref="S3.E3.m1.1.1.1.1.m1.4.5.6.1.cmml"><mtd class="ltx_align_left" columnalign="left" id="S3.E3.m1.1.1.1.1.m1.4.4.4e" xref="S3.E3.m1.1.1.1.1.m1.4.5.6.1.cmml"><mrow id="S3.E3.m1.1.1.1.1.m1.3.3.3.3.1.1.3" xref="S3.E3.m1.1.1.1.1.m1.3.3.3.3.1.1.4.cmml"><mi id="S3.E3.m1.1.1.1.1.m1.3.3.3.3.1.1.1" xref="S3.E3.m1.1.1.1.1.m1.3.3.3.3.1.1.1.cmml">max</mi><mo id="S3.E3.m1.1.1.1.1.m1.3.3.3.3.1.1.3a" xref="S3.E3.m1.1.1.1.1.m1.3.3.3.3.1.1.4.cmml">⁡</mo><mrow id="S3.E3.m1.1.1.1.1.m1.3.3.3.3.1.1.3.1" xref="S3.E3.m1.1.1.1.1.m1.3.3.3.3.1.1.4.cmml"><mo stretchy="false" id="S3.E3.m1.1.1.1.1.m1.3.3.3.3.1.1.3.1.2" xref="S3.E3.m1.1.1.1.1.m1.3.3.3.3.1.1.4.cmml">{</mo><mn id="S3.E3.m1.1.1.1.1.m1.3.3.3.3.1.1.2" xref="S3.E3.m1.1.1.1.1.m1.3.3.3.3.1.1.2.cmml">0</mn><mo id="S3.E3.m1.1.1.1.1.m1.3.3.3.3.1.1.3.1.3" xref="S3.E3.m1.1.1.1.1.m1.3.3.3.3.1.1.4.cmml">,</mo><mrow id="S3.E3.m1.1.1.1.1.m1.3.3.3.3.1.1.3.1.1" xref="S3.E3.m1.1.1.1.1.m1.3.3.3.3.1.1.3.1.1.cmml"><mi id="S3.E3.m1.1.1.1.1.m1.3.3.3.3.1.1.3.1.1.2" xref="S3.E3.m1.1.1.1.1.m1.3.3.3.3.1.1.3.1.1.2.cmml">δ</mi><mo id="S3.E3.m1.1.1.1.1.m1.3.3.3.3.1.1.3.1.1.1" xref="S3.E3.m1.1.1.1.1.m1.3.3.3.3.1.1.3.1.1.1.cmml">−</mo><msub id="S3.E3.m1.1.1.1.1.m1.3.3.3.3.1.1.3.1.1.3" xref="S3.E3.m1.1.1.1.1.m1.3.3.3.3.1.1.3.1.1.3.cmml"><mi id="S3.E3.m1.1.1.1.1.m1.3.3.3.3.1.1.3.1.1.3.2" xref="S3.E3.m1.1.1.1.1.m1.3.3.3.3.1.1.3.1.1.3.2.cmml">d</mi><mi id="S3.E3.m1.1.1.1.1.m1.3.3.3.3.1.1.3.1.1.3.3" xref="S3.E3.m1.1.1.1.1.m1.3.3.3.3.1.1.3.1.1.3.3.cmml">i</mi></msub></mrow><mo stretchy="false" id="S3.E3.m1.1.1.1.1.m1.3.3.3.3.1.1.3.1.4" xref="S3.E3.m1.1.1.1.1.m1.3.3.3.3.1.1.4.cmml">}</mo></mrow></mrow></mtd><mtd class="ltx_align_left" columnalign="left" id="S3.E3.m1.1.1.1.1.m1.4.4.4f" xref="S3.E3.m1.1.1.1.1.m1.4.5.6.1.cmml"><mrow id="S3.E3.m1.1.1.1.1.m1.4.4.4.4.2.1.1" xref="S3.E3.m1.1.1.1.1.m1.4.4.4.4.2.1.1.1.cmml"><mrow id="S3.E3.m1.1.1.1.1.m1.4.4.4.4.2.1.1.1" xref="S3.E3.m1.1.1.1.1.m1.4.4.4.4.2.1.1.1.cmml"><mrow id="S3.E3.m1.1.1.1.1.m1.4.4.4.4.2.1.1.1.2" xref="S3.E3.m1.1.1.1.1.m1.4.4.4.4.2.1.1.1.2.cmml"><mtext id="S3.E3.m1.1.1.1.1.m1.4.4.4.4.2.1.1.1.2.2" xref="S3.E3.m1.1.1.1.1.m1.4.4.4.4.2.1.1.1.2.2a.cmml">if </mtext><mo lspace="0em" rspace="0em" id="S3.E3.m1.1.1.1.1.m1.4.4.4.4.2.1.1.1.2.1" xref="S3.E3.m1.1.1.1.1.m1.4.4.4.4.2.1.1.1.2.1.cmml">​</mo><msub id="S3.E3.m1.1.1.1.1.m1.4.4.4.4.2.1.1.1.2.3" xref="S3.E3.m1.1.1.1.1.m1.4.4.4.4.2.1.1.1.2.3.cmml"><mover accent="true" id="S3.E3.m1.1.1.1.1.m1.4.4.4.4.2.1.1.1.2.3.2" xref="S3.E3.m1.1.1.1.1.m1.4.4.4.4.2.1.1.1.2.3.2.cmml"><mi id="S3.E3.m1.1.1.1.1.m1.4.4.4.4.2.1.1.1.2.3.2.2" xref="S3.E3.m1.1.1.1.1.m1.4.4.4.4.2.1.1.1.2.3.2.2.cmml">a</mi><mo id="S3.E3.m1.1.1.1.1.m1.4.4.4.4.2.1.1.1.2.3.2.1" xref="S3.E3.m1.1.1.1.1.m1.4.4.4.4.2.1.1.1.2.3.2.1.cmml">^</mo></mover><mi id="S3.E3.m1.1.1.1.1.m1.4.4.4.4.2.1.1.1.2.3.3" xref="S3.E3.m1.1.1.1.1.m1.4.4.4.4.2.1.1.1.2.3.3.cmml">i</mi></msub></mrow><mo id="S3.E3.m1.1.1.1.1.m1.4.4.4.4.2.1.1.1.1" xref="S3.E3.m1.1.1.1.1.m1.4.4.4.4.2.1.1.1.1.cmml">=</mo><mn id="S3.E3.m1.1.1.1.1.m1.4.4.4.4.2.1.1.1.3" xref="S3.E3.m1.1.1.1.1.m1.4.4.4.4.2.1.1.1.3.cmml">0</mn></mrow><mo lspace="0em" id="S3.E3.m1.1.1.1.1.m1.4.4.4.4.2.1.1.2" xref="S3.E3.m1.1.1.1.1.m1.4.4.4.4.2.1.1.1.cmml">.</mo></mrow></mtd></mtr></mtable></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E3.m1.1.1.1.1.m1.4b"><apply id="S3.E3.m1.1.1.1.1.m1.4.5.cmml" xref="S3.E3.m1.1.1.1.1.m1.4.5"><and id="S3.E3.m1.1.1.1.1.m1.4.5a.cmml" xref="S3.E3.m1.1.1.1.1.m1.4.5"></and><apply id="S3.E3.m1.1.1.1.1.m1.4.5b.cmml" xref="S3.E3.m1.1.1.1.1.m1.4.5"><eq id="S3.E3.m1.1.1.1.1.m1.4.5.3.cmml" xref="S3.E3.m1.1.1.1.1.m1.4.5.3"></eq><apply id="S3.E3.m1.1.1.1.1.m1.4.5.2.cmml" xref="S3.E3.m1.1.1.1.1.m1.4.5.2"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.1.1.m1.4.5.2.1.cmml" xref="S3.E3.m1.1.1.1.1.m1.4.5.2">subscript</csymbol><ci id="S3.E3.m1.1.1.1.1.m1.4.5.2.2.cmml" xref="S3.E3.m1.1.1.1.1.m1.4.5.2.2">𝐿</ci><ci id="S3.E3.m1.1.1.1.1.m1.4.5.2.3.cmml" xref="S3.E3.m1.1.1.1.1.m1.4.5.2.3">𝑝</ci></apply><apply id="S3.E3.m1.1.1.1.1.m1.4.5.4.cmml" xref="S3.E3.m1.1.1.1.1.m1.4.5.4"><apply id="S3.E3.m1.1.1.1.1.m1.4.5.4.1.cmml" xref="S3.E3.m1.1.1.1.1.m1.4.5.4.1"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.1.1.m1.4.5.4.1.1.cmml" xref="S3.E3.m1.1.1.1.1.m1.4.5.4.1">superscript</csymbol><apply id="S3.E3.m1.1.1.1.1.m1.4.5.4.1.2.cmml" xref="S3.E3.m1.1.1.1.1.m1.4.5.4.1"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.1.1.m1.4.5.4.1.2.1.cmml" xref="S3.E3.m1.1.1.1.1.m1.4.5.4.1">subscript</csymbol><sum id="S3.E3.m1.1.1.1.1.m1.4.5.4.1.2.2.cmml" xref="S3.E3.m1.1.1.1.1.m1.4.5.4.1.2.2"></sum><apply id="S3.E3.m1.1.1.1.1.m1.4.5.4.1.2.3.cmml" xref="S3.E3.m1.1.1.1.1.m1.4.5.4.1.2.3"><eq id="S3.E3.m1.1.1.1.1.m1.4.5.4.1.2.3.1.cmml" xref="S3.E3.m1.1.1.1.1.m1.4.5.4.1.2.3.1"></eq><ci id="S3.E3.m1.1.1.1.1.m1.4.5.4.1.2.3.2.cmml" xref="S3.E3.m1.1.1.1.1.m1.4.5.4.1.2.3.2">𝑖</ci><cn type="integer" id="S3.E3.m1.1.1.1.1.m1.4.5.4.1.2.3.3.cmml" xref="S3.E3.m1.1.1.1.1.m1.4.5.4.1.2.3.3">1</cn></apply></apply><ci id="S3.E3.m1.1.1.1.1.m1.4.5.4.1.3.cmml" xref="S3.E3.m1.1.1.1.1.m1.4.5.4.1.3">𝐴</ci></apply><apply id="S3.E3.m1.1.1.1.1.m1.4.5.4.2.cmml" xref="S3.E3.m1.1.1.1.1.m1.4.5.4.2"><times id="S3.E3.m1.1.1.1.1.m1.4.5.4.2.1.cmml" xref="S3.E3.m1.1.1.1.1.m1.4.5.4.2.1"></times><apply id="S3.E3.m1.1.1.1.1.m1.4.5.4.2.2.cmml" xref="S3.E3.m1.1.1.1.1.m1.4.5.4.2.2"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.1.1.m1.4.5.4.2.2.1.cmml" xref="S3.E3.m1.1.1.1.1.m1.4.5.4.2.2">subscript</csymbol><ci id="S3.E3.m1.1.1.1.1.m1.4.5.4.2.2.2.cmml" xref="S3.E3.m1.1.1.1.1.m1.4.5.4.2.2.2">𝑙</ci><ci id="S3.E3.m1.1.1.1.1.m1.4.5.4.2.2.3.cmml" xref="S3.E3.m1.1.1.1.1.m1.4.5.4.2.2.3">𝑖</ci></apply><ci id="S3.E3.m1.1.1.1.1.m1.4.5.4.2.3a.cmml" xref="S3.E3.m1.1.1.1.1.m1.4.5.4.2.3"><mtext id="S3.E3.m1.1.1.1.1.m1.4.5.4.2.3.cmml" xref="S3.E3.m1.1.1.1.1.m1.4.5.4.2.3">with</mtext></ci><apply id="S3.E3.m1.1.1.1.1.m1.4.5.4.2.4.cmml" xref="S3.E3.m1.1.1.1.1.m1.4.5.4.2.4"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.1.1.m1.4.5.4.2.4.1.cmml" xref="S3.E3.m1.1.1.1.1.m1.4.5.4.2.4">subscript</csymbol><ci id="S3.E3.m1.1.1.1.1.m1.4.5.4.2.4.2.cmml" xref="S3.E3.m1.1.1.1.1.m1.4.5.4.2.4.2">𝑙</ci><ci id="S3.E3.m1.1.1.1.1.m1.4.5.4.2.4.3.cmml" xref="S3.E3.m1.1.1.1.1.m1.4.5.4.2.4.3">𝑖</ci></apply></apply></apply></apply><apply id="S3.E3.m1.1.1.1.1.m1.4.5c.cmml" xref="S3.E3.m1.1.1.1.1.m1.4.5"><eq id="S3.E3.m1.1.1.1.1.m1.4.5.5.cmml" xref="S3.E3.m1.1.1.1.1.m1.4.5.5"></eq><share href="#S3.E3.m1.1.1.1.1.m1.4.5.4.cmml" id="S3.E3.m1.1.1.1.1.m1.4.5d.cmml" xref="S3.E3.m1.1.1.1.1.m1.4.5"></share><apply id="S3.E3.m1.1.1.1.1.m1.4.5.6.1.cmml" xref="S3.E3.m1.1.1.1.1.m1.4.4"><csymbol cd="latexml" id="S3.E3.m1.1.1.1.1.m1.4.5.6.1.1.cmml" xref="S3.E3.m1.1.1.1.1.m1.4.4.5">cases</csymbol><apply id="S3.E3.m1.1.1.1.1.m1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.m1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.1.1.m1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.m1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E3.m1.1.1.1.1.m1.1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.1.1.1.1.m1.1.1.1.1.1.1.2">𝑑</ci><ci id="S3.E3.m1.1.1.1.1.m1.1.1.1.1.1.1.3.cmml" xref="S3.E3.m1.1.1.1.1.m1.1.1.1.1.1.1.3">𝑖</ci></apply><apply id="S3.E3.m1.1.1.1.1.m1.2.2.2.2.2.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.m1.2.2.2.2.2.1.1"><eq id="S3.E3.m1.1.1.1.1.m1.2.2.2.2.2.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.m1.2.2.2.2.2.1.1.1.1"></eq><apply id="S3.E3.m1.1.1.1.1.m1.2.2.2.2.2.1.1.1.2.cmml" xref="S3.E3.m1.1.1.1.1.m1.2.2.2.2.2.1.1.1.2"><times id="S3.E3.m1.1.1.1.1.m1.2.2.2.2.2.1.1.1.2.1.cmml" xref="S3.E3.m1.1.1.1.1.m1.2.2.2.2.2.1.1.1.2.1"></times><ci id="S3.E3.m1.1.1.1.1.m1.2.2.2.2.2.1.1.1.2.2a.cmml" xref="S3.E3.m1.1.1.1.1.m1.2.2.2.2.2.1.1.1.2.2"><mtext id="S3.E3.m1.1.1.1.1.m1.2.2.2.2.2.1.1.1.2.2.cmml" xref="S3.E3.m1.1.1.1.1.m1.2.2.2.2.2.1.1.1.2.2">if </mtext></ci><apply id="S3.E3.m1.1.1.1.1.m1.2.2.2.2.2.1.1.1.2.3.cmml" xref="S3.E3.m1.1.1.1.1.m1.2.2.2.2.2.1.1.1.2.3"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.1.1.m1.2.2.2.2.2.1.1.1.2.3.1.cmml" xref="S3.E3.m1.1.1.1.1.m1.2.2.2.2.2.1.1.1.2.3">subscript</csymbol><apply id="S3.E3.m1.1.1.1.1.m1.2.2.2.2.2.1.1.1.2.3.2.cmml" xref="S3.E3.m1.1.1.1.1.m1.2.2.2.2.2.1.1.1.2.3.2"><ci id="S3.E3.m1.1.1.1.1.m1.2.2.2.2.2.1.1.1.2.3.2.1.cmml" xref="S3.E3.m1.1.1.1.1.m1.2.2.2.2.2.1.1.1.2.3.2.1">^</ci><ci id="S3.E3.m1.1.1.1.1.m1.2.2.2.2.2.1.1.1.2.3.2.2.cmml" xref="S3.E3.m1.1.1.1.1.m1.2.2.2.2.2.1.1.1.2.3.2.2">𝑎</ci></apply><ci id="S3.E3.m1.1.1.1.1.m1.2.2.2.2.2.1.1.1.2.3.3.cmml" xref="S3.E3.m1.1.1.1.1.m1.2.2.2.2.2.1.1.1.2.3.3">𝑖</ci></apply></apply><cn type="integer" id="S3.E3.m1.1.1.1.1.m1.2.2.2.2.2.1.1.1.3.cmml" xref="S3.E3.m1.1.1.1.1.m1.2.2.2.2.2.1.1.1.3">1</cn></apply><apply id="S3.E3.m1.1.1.1.1.m1.3.3.3.3.1.1.4.cmml" xref="S3.E3.m1.1.1.1.1.m1.3.3.3.3.1.1.3"><max id="S3.E3.m1.1.1.1.1.m1.3.3.3.3.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.m1.3.3.3.3.1.1.1"></max><cn type="integer" id="S3.E3.m1.1.1.1.1.m1.3.3.3.3.1.1.2.cmml" xref="S3.E3.m1.1.1.1.1.m1.3.3.3.3.1.1.2">0</cn><apply id="S3.E3.m1.1.1.1.1.m1.3.3.3.3.1.1.3.1.1.cmml" xref="S3.E3.m1.1.1.1.1.m1.3.3.3.3.1.1.3.1.1"><minus id="S3.E3.m1.1.1.1.1.m1.3.3.3.3.1.1.3.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.m1.3.3.3.3.1.1.3.1.1.1"></minus><ci id="S3.E3.m1.1.1.1.1.m1.3.3.3.3.1.1.3.1.1.2.cmml" xref="S3.E3.m1.1.1.1.1.m1.3.3.3.3.1.1.3.1.1.2">𝛿</ci><apply id="S3.E3.m1.1.1.1.1.m1.3.3.3.3.1.1.3.1.1.3.cmml" xref="S3.E3.m1.1.1.1.1.m1.3.3.3.3.1.1.3.1.1.3"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.1.1.m1.3.3.3.3.1.1.3.1.1.3.1.cmml" xref="S3.E3.m1.1.1.1.1.m1.3.3.3.3.1.1.3.1.1.3">subscript</csymbol><ci id="S3.E3.m1.1.1.1.1.m1.3.3.3.3.1.1.3.1.1.3.2.cmml" xref="S3.E3.m1.1.1.1.1.m1.3.3.3.3.1.1.3.1.1.3.2">𝑑</ci><ci id="S3.E3.m1.1.1.1.1.m1.3.3.3.3.1.1.3.1.1.3.3.cmml" xref="S3.E3.m1.1.1.1.1.m1.3.3.3.3.1.1.3.1.1.3.3">𝑖</ci></apply></apply></apply><apply id="S3.E3.m1.1.1.1.1.m1.4.4.4.4.2.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.m1.4.4.4.4.2.1.1"><eq id="S3.E3.m1.1.1.1.1.m1.4.4.4.4.2.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.m1.4.4.4.4.2.1.1.1.1"></eq><apply id="S3.E3.m1.1.1.1.1.m1.4.4.4.4.2.1.1.1.2.cmml" xref="S3.E3.m1.1.1.1.1.m1.4.4.4.4.2.1.1.1.2"><times id="S3.E3.m1.1.1.1.1.m1.4.4.4.4.2.1.1.1.2.1.cmml" xref="S3.E3.m1.1.1.1.1.m1.4.4.4.4.2.1.1.1.2.1"></times><ci id="S3.E3.m1.1.1.1.1.m1.4.4.4.4.2.1.1.1.2.2a.cmml" xref="S3.E3.m1.1.1.1.1.m1.4.4.4.4.2.1.1.1.2.2"><mtext id="S3.E3.m1.1.1.1.1.m1.4.4.4.4.2.1.1.1.2.2.cmml" xref="S3.E3.m1.1.1.1.1.m1.4.4.4.4.2.1.1.1.2.2">if </mtext></ci><apply id="S3.E3.m1.1.1.1.1.m1.4.4.4.4.2.1.1.1.2.3.cmml" xref="S3.E3.m1.1.1.1.1.m1.4.4.4.4.2.1.1.1.2.3"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.1.1.m1.4.4.4.4.2.1.1.1.2.3.1.cmml" xref="S3.E3.m1.1.1.1.1.m1.4.4.4.4.2.1.1.1.2.3">subscript</csymbol><apply id="S3.E3.m1.1.1.1.1.m1.4.4.4.4.2.1.1.1.2.3.2.cmml" xref="S3.E3.m1.1.1.1.1.m1.4.4.4.4.2.1.1.1.2.3.2"><ci id="S3.E3.m1.1.1.1.1.m1.4.4.4.4.2.1.1.1.2.3.2.1.cmml" xref="S3.E3.m1.1.1.1.1.m1.4.4.4.4.2.1.1.1.2.3.2.1">^</ci><ci id="S3.E3.m1.1.1.1.1.m1.4.4.4.4.2.1.1.1.2.3.2.2.cmml" xref="S3.E3.m1.1.1.1.1.m1.4.4.4.4.2.1.1.1.2.3.2.2">𝑎</ci></apply><ci id="S3.E3.m1.1.1.1.1.m1.4.4.4.4.2.1.1.1.2.3.3.cmml" xref="S3.E3.m1.1.1.1.1.m1.4.4.4.4.2.1.1.1.2.3.3">𝑖</ci></apply></apply><cn type="integer" id="S3.E3.m1.1.1.1.1.m1.4.4.4.4.2.1.1.1.3.cmml" xref="S3.E3.m1.1.1.1.1.m1.4.4.4.4.2.1.1.1.3">0</cn></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E3.m1.1.1.1.1.m1.4c">L_{p}=\sum_{i=1}^{{A}}l_{i}~{}~{}\textrm{with}~{}~{}l_{i}=\begin{cases}d_{i}&amp;\text{if }\hat{a}_{i}=1,\\
\max\{0,\delta-d_{i}\}&amp;\text{if }\hat{a}_{i}=0.\end{cases}</annotation></semantics></math></p>
</span></div>
</td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="0" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<p id="S3.SS2.SSS0.Px2.p2.1" class="ltx_p">where <math id="S3.SS2.SSS0.Px2.p2.1.m1.1" class="ltx_Math" alttext="\delta" display="inline"><semantics id="S3.SS2.SSS0.Px2.p2.1.m1.1a"><mi id="S3.SS2.SSS0.Px2.p2.1.m1.1.1" xref="S3.SS2.SSS0.Px2.p2.1.m1.1.1.cmml">δ</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px2.p2.1.m1.1b"><ci id="S3.SS2.SSS0.Px2.p2.1.m1.1.1.cmml" xref="S3.SS2.SSS0.Px2.p2.1.m1.1.1">𝛿</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px2.p2.1.m1.1c">\delta</annotation></semantics></math> is a scalar margin hyperparameter. Our overall optimization objective is the convex combination of the classification and regression losses:</p>
<table id="S3.E4" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E4.m1.1" class="ltx_Math" alttext="L~{}=~{}\lambda\;L_{c}~{}+~{}(1-\lambda)\;L_{p}~{}," display="block"><semantics id="S3.E4.m1.1a"><mrow id="S3.E4.m1.1.1.1" xref="S3.E4.m1.1.1.1.1.cmml"><mrow id="S3.E4.m1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.cmml"><mi id="S3.E4.m1.1.1.1.1.3" xref="S3.E4.m1.1.1.1.1.3.cmml">L</mi><mo lspace="0.608em" rspace="0.608em" id="S3.E4.m1.1.1.1.1.2" xref="S3.E4.m1.1.1.1.1.2.cmml">=</mo><mrow id="S3.E4.m1.1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.1.cmml"><mrow id="S3.E4.m1.1.1.1.1.1.3" xref="S3.E4.m1.1.1.1.1.1.3.cmml"><mi id="S3.E4.m1.1.1.1.1.1.3.2" xref="S3.E4.m1.1.1.1.1.1.3.2.cmml">λ</mi><mo lspace="0.280em" rspace="0em" id="S3.E4.m1.1.1.1.1.1.3.1" xref="S3.E4.m1.1.1.1.1.1.3.1.cmml">​</mo><msub id="S3.E4.m1.1.1.1.1.1.3.3" xref="S3.E4.m1.1.1.1.1.1.3.3.cmml"><mi id="S3.E4.m1.1.1.1.1.1.3.3.2" xref="S3.E4.m1.1.1.1.1.1.3.3.2.cmml">L</mi><mi id="S3.E4.m1.1.1.1.1.1.3.3.3" xref="S3.E4.m1.1.1.1.1.1.3.3.3.cmml">c</mi></msub></mrow><mo rspace="0.552em" id="S3.E4.m1.1.1.1.1.1.2" xref="S3.E4.m1.1.1.1.1.1.2.cmml">+</mo><mrow id="S3.E4.m1.1.1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.1.1.cmml"><mrow id="S3.E4.m1.1.1.1.1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E4.m1.1.1.1.1.1.1.1.1.2" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E4.m1.1.1.1.1.1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.cmml"><mn id="S3.E4.m1.1.1.1.1.1.1.1.1.1.2" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.2.cmml">1</mn><mo id="S3.E4.m1.1.1.1.1.1.1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.cmml">−</mo><mi id="S3.E4.m1.1.1.1.1.1.1.1.1.1.3" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.3.cmml">λ</mi></mrow><mo stretchy="false" id="S3.E4.m1.1.1.1.1.1.1.1.1.3" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow><mo lspace="0.280em" rspace="0em" id="S3.E4.m1.1.1.1.1.1.1.2" xref="S3.E4.m1.1.1.1.1.1.1.2.cmml">​</mo><msub id="S3.E4.m1.1.1.1.1.1.1.3" xref="S3.E4.m1.1.1.1.1.1.1.3.cmml"><mi id="S3.E4.m1.1.1.1.1.1.1.3.2" xref="S3.E4.m1.1.1.1.1.1.1.3.2.cmml">L</mi><mi id="S3.E4.m1.1.1.1.1.1.1.3.3" xref="S3.E4.m1.1.1.1.1.1.1.3.3.cmml">p</mi></msub></mrow></mrow></mrow><mo id="S3.E4.m1.1.1.1.2" xref="S3.E4.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E4.m1.1b"><apply id="S3.E4.m1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1"><eq id="S3.E4.m1.1.1.1.1.2.cmml" xref="S3.E4.m1.1.1.1.1.2"></eq><ci id="S3.E4.m1.1.1.1.1.3.cmml" xref="S3.E4.m1.1.1.1.1.3">𝐿</ci><apply id="S3.E4.m1.1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.1"><plus id="S3.E4.m1.1.1.1.1.1.2.cmml" xref="S3.E4.m1.1.1.1.1.1.2"></plus><apply id="S3.E4.m1.1.1.1.1.1.3.cmml" xref="S3.E4.m1.1.1.1.1.1.3"><times id="S3.E4.m1.1.1.1.1.1.3.1.cmml" xref="S3.E4.m1.1.1.1.1.1.3.1"></times><ci id="S3.E4.m1.1.1.1.1.1.3.2.cmml" xref="S3.E4.m1.1.1.1.1.1.3.2">𝜆</ci><apply id="S3.E4.m1.1.1.1.1.1.3.3.cmml" xref="S3.E4.m1.1.1.1.1.1.3.3"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.1.1.3.3.1.cmml" xref="S3.E4.m1.1.1.1.1.1.3.3">subscript</csymbol><ci id="S3.E4.m1.1.1.1.1.1.3.3.2.cmml" xref="S3.E4.m1.1.1.1.1.1.3.3.2">𝐿</ci><ci id="S3.E4.m1.1.1.1.1.1.3.3.3.cmml" xref="S3.E4.m1.1.1.1.1.1.3.3.3">𝑐</ci></apply></apply><apply id="S3.E4.m1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1"><times id="S3.E4.m1.1.1.1.1.1.1.2.cmml" xref="S3.E4.m1.1.1.1.1.1.1.2"></times><apply id="S3.E4.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1"><minus id="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.1"></minus><cn type="integer" id="S3.E4.m1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.2">1</cn><ci id="S3.E4.m1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.3">𝜆</ci></apply><apply id="S3.E4.m1.1.1.1.1.1.1.3.cmml" xref="S3.E4.m1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.1.1.1.3.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E4.m1.1.1.1.1.1.1.3.2.cmml" xref="S3.E4.m1.1.1.1.1.1.1.3.2">𝐿</ci><ci id="S3.E4.m1.1.1.1.1.1.1.3.3.cmml" xref="S3.E4.m1.1.1.1.1.1.1.3.3">𝑝</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E4.m1.1c">L~{}=~{}\lambda\;L_{c}~{}+~{}(1-\lambda)\;L_{p}~{},</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
<p id="S3.SS2.SSS0.Px2.p2.3" class="ltx_p">where the scalar hyperparameter <math id="S3.SS2.SSS0.Px2.p2.2.m1.1" class="ltx_Math" alttext="\lambda" display="inline"><semantics id="S3.SS2.SSS0.Px2.p2.2.m1.1a"><mi id="S3.SS2.SSS0.Px2.p2.2.m1.1.1" xref="S3.SS2.SSS0.Px2.p2.2.m1.1.1.cmml">λ</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px2.p2.2.m1.1b"><ci id="S3.SS2.SSS0.Px2.p2.2.m1.1.1.cmml" xref="S3.SS2.SSS0.Px2.p2.2.m1.1.1">𝜆</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px2.p2.2.m1.1c">\lambda</annotation></semantics></math> balances the two objectives. By setting <math id="S3.SS2.SSS0.Px2.p2.3.m2.1" class="ltx_Math" alttext="\lambda=1" display="inline"><semantics id="S3.SS2.SSS0.Px2.p2.3.m2.1a"><mrow id="S3.SS2.SSS0.Px2.p2.3.m2.1.1" xref="S3.SS2.SSS0.Px2.p2.3.m2.1.1.cmml"><mi id="S3.SS2.SSS0.Px2.p2.3.m2.1.1.2" xref="S3.SS2.SSS0.Px2.p2.3.m2.1.1.2.cmml">λ</mi><mo id="S3.SS2.SSS0.Px2.p2.3.m2.1.1.1" xref="S3.SS2.SSS0.Px2.p2.3.m2.1.1.1.cmml">=</mo><mn id="S3.SS2.SSS0.Px2.p2.3.m2.1.1.3" xref="S3.SS2.SSS0.Px2.p2.3.m2.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px2.p2.3.m2.1b"><apply id="S3.SS2.SSS0.Px2.p2.3.m2.1.1.cmml" xref="S3.SS2.SSS0.Px2.p2.3.m2.1.1"><eq id="S3.SS2.SSS0.Px2.p2.3.m2.1.1.1.cmml" xref="S3.SS2.SSS0.Px2.p2.3.m2.1.1.1"></eq><ci id="S3.SS2.SSS0.Px2.p2.3.m2.1.1.2.cmml" xref="S3.SS2.SSS0.Px2.p2.3.m2.1.1.2">𝜆</ci><cn type="integer" id="S3.SS2.SSS0.Px2.p2.3.m2.1.1.3.cmml" xref="S3.SS2.SSS0.Px2.p2.3.m2.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px2.p2.3.m2.1c">\lambda=1</annotation></semantics></math>, the loss falls back to a unique traditional classification objective, which serves as our baseline.</p>
</div>
</section>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Predictions</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">Due to the nature of existing datasets, answer prediction during test time do not differ from the training, since both train and test splits typically share common answer set. Our current experiments thus simply use the answers predicted by the network with the same combination of the classification and regression branches as the training objective. That is, the final predicted answer <math id="S3.SS3.p1.1.m1.1" class="ltx_Math" alttext="a^{\star}\in[1...{A}]" display="inline"><semantics id="S3.SS3.p1.1.m1.1a"><mrow id="S3.SS3.p1.1.m1.1.1" xref="S3.SS3.p1.1.m1.1.1.cmml"><msup id="S3.SS3.p1.1.m1.1.1.3" xref="S3.SS3.p1.1.m1.1.1.3.cmml"><mi id="S3.SS3.p1.1.m1.1.1.3.2" xref="S3.SS3.p1.1.m1.1.1.3.2.cmml">a</mi><mo id="S3.SS3.p1.1.m1.1.1.3.3" xref="S3.SS3.p1.1.m1.1.1.3.3.cmml">⋆</mo></msup><mo id="S3.SS3.p1.1.m1.1.1.2" xref="S3.SS3.p1.1.m1.1.1.2.cmml">∈</mo><mrow id="S3.SS3.p1.1.m1.1.1.1.1" xref="S3.SS3.p1.1.m1.1.1.1.2.cmml"><mo stretchy="false" id="S3.SS3.p1.1.m1.1.1.1.1.2" xref="S3.SS3.p1.1.m1.1.1.1.2.1.cmml">[</mo><mrow id="S3.SS3.p1.1.m1.1.1.1.1.1" xref="S3.SS3.p1.1.m1.1.1.1.1.1.cmml"><mn id="S3.SS3.p1.1.m1.1.1.1.1.1.2" xref="S3.SS3.p1.1.m1.1.1.1.1.1.2.cmml">1</mn><mo lspace="0em" rspace="0em" id="S3.SS3.p1.1.m1.1.1.1.1.1.1" xref="S3.SS3.p1.1.m1.1.1.1.1.1.1.cmml">​</mo><mi mathvariant="normal" id="S3.SS3.p1.1.m1.1.1.1.1.1.3" xref="S3.SS3.p1.1.m1.1.1.1.1.1.3.cmml">…</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p1.1.m1.1.1.1.1.1.1a" xref="S3.SS3.p1.1.m1.1.1.1.1.1.1.cmml">​</mo><mi id="S3.SS3.p1.1.m1.1.1.1.1.1.4" xref="S3.SS3.p1.1.m1.1.1.1.1.1.4.cmml">A</mi></mrow><mo stretchy="false" id="S3.SS3.p1.1.m1.1.1.1.1.3" xref="S3.SS3.p1.1.m1.1.1.1.2.1.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.1.m1.1b"><apply id="S3.SS3.p1.1.m1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1"><in id="S3.SS3.p1.1.m1.1.1.2.cmml" xref="S3.SS3.p1.1.m1.1.1.2"></in><apply id="S3.SS3.p1.1.m1.1.1.3.cmml" xref="S3.SS3.p1.1.m1.1.1.3"><csymbol cd="ambiguous" id="S3.SS3.p1.1.m1.1.1.3.1.cmml" xref="S3.SS3.p1.1.m1.1.1.3">superscript</csymbol><ci id="S3.SS3.p1.1.m1.1.1.3.2.cmml" xref="S3.SS3.p1.1.m1.1.1.3.2">𝑎</ci><ci id="S3.SS3.p1.1.m1.1.1.3.3.cmml" xref="S3.SS3.p1.1.m1.1.1.3.3">⋆</ci></apply><apply id="S3.SS3.p1.1.m1.1.1.1.2.cmml" xref="S3.SS3.p1.1.m1.1.1.1.1"><csymbol cd="latexml" id="S3.SS3.p1.1.m1.1.1.1.2.1.cmml" xref="S3.SS3.p1.1.m1.1.1.1.1.2">delimited-[]</csymbol><apply id="S3.SS3.p1.1.m1.1.1.1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1.1.1.1"><times id="S3.SS3.p1.1.m1.1.1.1.1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1.1.1.1.1"></times><cn type="integer" id="S3.SS3.p1.1.m1.1.1.1.1.1.2.cmml" xref="S3.SS3.p1.1.m1.1.1.1.1.1.2">1</cn><ci id="S3.SS3.p1.1.m1.1.1.1.1.1.3.cmml" xref="S3.SS3.p1.1.m1.1.1.1.1.1.3">…</ci><ci id="S3.SS3.p1.1.m1.1.1.1.1.1.4.cmml" xref="S3.SS3.p1.1.m1.1.1.1.1.1.4">𝐴</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.1.m1.1c">a^{\star}\in[1...{A}]</annotation></semantics></math> is the one from the set of candidates with the combination of highest score and the lowest distance. Formally:</p>
<table id="S3.E5" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center">
<div id="S3.E5.m1.1.1.1" class="ltx_inline-block ltx_markedasmath ltx_transformed_outer" style="width:216.8pt;height:11.2pt;vertical-align:-2.8pt;"><span class="ltx_transformed_inner" style="transform:translate(-7.5pt,0.3pt) scale(0.934948917820016,0.934948917820016) ;">
<p id="S3.E5.m1.1.1.1.1" class="ltx_p"><math id="S3.E5.m1.1.1.1.1.m1.4" class="ltx_Math" alttext="a^{\star}=\operatorname*{arg\,max}_{i}\big{(}\lambda\,\operatorname*{softmax}(\boldsymbol{y})\,+\,(1-\lambda)\,\operatorname*{softmax}(-\boldsymbol{d})\big{)}~{}." display="inline"><semantics id="S3.E5.m1.1.1.1.1.m1.4a"><mrow id="S3.E5.m1.1.1.1.1.m1.4.4.1" xref="S3.E5.m1.1.1.1.1.m1.4.4.1.1.cmml"><mrow id="S3.E5.m1.1.1.1.1.m1.4.4.1.1" xref="S3.E5.m1.1.1.1.1.m1.4.4.1.1.cmml"><msup id="S3.E5.m1.1.1.1.1.m1.4.4.1.1.4" xref="S3.E5.m1.1.1.1.1.m1.4.4.1.1.4.cmml"><mi id="S3.E5.m1.1.1.1.1.m1.4.4.1.1.4.2" xref="S3.E5.m1.1.1.1.1.m1.4.4.1.1.4.2.cmml">a</mi><mo id="S3.E5.m1.1.1.1.1.m1.4.4.1.1.4.3" xref="S3.E5.m1.1.1.1.1.m1.4.4.1.1.4.3.cmml">⋆</mo></msup><mo id="S3.E5.m1.1.1.1.1.m1.4.4.1.1.3" xref="S3.E5.m1.1.1.1.1.m1.4.4.1.1.3.cmml">=</mo><mrow id="S3.E5.m1.1.1.1.1.m1.4.4.1.1.2.2" xref="S3.E5.m1.1.1.1.1.m1.4.4.1.1.2.3.cmml"><msub id="S3.E5.m1.1.1.1.1.m1.4.4.1.1.1.1.1" xref="S3.E5.m1.1.1.1.1.m1.4.4.1.1.1.1.1.cmml"><mrow id="S3.E5.m1.1.1.1.1.m1.4.4.1.1.1.1.1.2" xref="S3.E5.m1.1.1.1.1.m1.4.4.1.1.1.1.1.2.cmml"><mi id="S3.E5.m1.1.1.1.1.m1.4.4.1.1.1.1.1.2.2" xref="S3.E5.m1.1.1.1.1.m1.4.4.1.1.1.1.1.2.2.cmml">arg</mi><mo lspace="0.170em" rspace="0em" id="S3.E5.m1.1.1.1.1.m1.4.4.1.1.1.1.1.2.1" xref="S3.E5.m1.1.1.1.1.m1.4.4.1.1.1.1.1.2.1.cmml">​</mo><mi id="S3.E5.m1.1.1.1.1.m1.4.4.1.1.1.1.1.2.3" xref="S3.E5.m1.1.1.1.1.m1.4.4.1.1.1.1.1.2.3.cmml">max</mi></mrow><mi id="S3.E5.m1.1.1.1.1.m1.4.4.1.1.1.1.1.3" xref="S3.E5.m1.1.1.1.1.m1.4.4.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.E5.m1.1.1.1.1.m1.4.4.1.1.2.2a" xref="S3.E5.m1.1.1.1.1.m1.4.4.1.1.2.3.cmml">⁡</mo><mrow id="S3.E5.m1.1.1.1.1.m1.4.4.1.1.2.2.2" xref="S3.E5.m1.1.1.1.1.m1.4.4.1.1.2.3.cmml"><mo maxsize="120%" minsize="120%" id="S3.E5.m1.1.1.1.1.m1.4.4.1.1.2.2.2.2" xref="S3.E5.m1.1.1.1.1.m1.4.4.1.1.2.3.cmml">(</mo><mrow id="S3.E5.m1.1.1.1.1.m1.4.4.1.1.2.2.2.1" xref="S3.E5.m1.1.1.1.1.m1.4.4.1.1.2.2.2.1.cmml"><mrow id="S3.E5.m1.1.1.1.1.m1.4.4.1.1.2.2.2.1.4" xref="S3.E5.m1.1.1.1.1.m1.4.4.1.1.2.2.2.1.4.cmml"><mi id="S3.E5.m1.1.1.1.1.m1.4.4.1.1.2.2.2.1.4.2" xref="S3.E5.m1.1.1.1.1.m1.4.4.1.1.2.2.2.1.4.2.cmml">λ</mi><mo lspace="0.337em" rspace="0em" id="S3.E5.m1.1.1.1.1.m1.4.4.1.1.2.2.2.1.4.1" xref="S3.E5.m1.1.1.1.1.m1.4.4.1.1.2.2.2.1.4.1.cmml">​</mo><mrow id="S3.E5.m1.1.1.1.1.m1.4.4.1.1.2.2.2.1.4.3.2" xref="S3.E5.m1.1.1.1.1.m1.4.4.1.1.2.2.2.1.4.3.1.cmml"><mo rspace="0em" id="S3.E5.m1.1.1.1.1.m1.1.1" xref="S3.E5.m1.1.1.1.1.m1.1.1.cmml">softmax</mo><mrow id="S3.E5.m1.1.1.1.1.m1.4.4.1.1.2.2.2.1.4.3.2.1" xref="S3.E5.m1.1.1.1.1.m1.4.4.1.1.2.2.2.1.4.3.1.cmml"><mo stretchy="false" id="S3.E5.m1.1.1.1.1.m1.4.4.1.1.2.2.2.1.4.3.2.1.1" xref="S3.E5.m1.1.1.1.1.m1.4.4.1.1.2.2.2.1.4.3.1.cmml">(</mo><mi id="S3.E5.m1.1.1.1.1.m1.2.2" xref="S3.E5.m1.1.1.1.1.m1.2.2.cmml">𝒚</mi><mo rspace="0.170em" stretchy="false" id="S3.E5.m1.1.1.1.1.m1.4.4.1.1.2.2.2.1.4.3.2.1.2" xref="S3.E5.m1.1.1.1.1.m1.4.4.1.1.2.2.2.1.4.3.1.cmml">)</mo></mrow></mrow></mrow><mo rspace="0.392em" id="S3.E5.m1.1.1.1.1.m1.4.4.1.1.2.2.2.1.3" xref="S3.E5.m1.1.1.1.1.m1.4.4.1.1.2.2.2.1.3.cmml">+</mo><mrow id="S3.E5.m1.1.1.1.1.m1.4.4.1.1.2.2.2.1.2" xref="S3.E5.m1.1.1.1.1.m1.4.4.1.1.2.2.2.1.2.cmml"><mrow id="S3.E5.m1.1.1.1.1.m1.4.4.1.1.2.2.2.1.1.1.1" xref="S3.E5.m1.1.1.1.1.m1.4.4.1.1.2.2.2.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E5.m1.1.1.1.1.m1.4.4.1.1.2.2.2.1.1.1.1.2" xref="S3.E5.m1.1.1.1.1.m1.4.4.1.1.2.2.2.1.1.1.1.1.cmml">(</mo><mrow id="S3.E5.m1.1.1.1.1.m1.4.4.1.1.2.2.2.1.1.1.1.1" xref="S3.E5.m1.1.1.1.1.m1.4.4.1.1.2.2.2.1.1.1.1.1.cmml"><mn id="S3.E5.m1.1.1.1.1.m1.4.4.1.1.2.2.2.1.1.1.1.1.2" xref="S3.E5.m1.1.1.1.1.m1.4.4.1.1.2.2.2.1.1.1.1.1.2.cmml">1</mn><mo id="S3.E5.m1.1.1.1.1.m1.4.4.1.1.2.2.2.1.1.1.1.1.1" xref="S3.E5.m1.1.1.1.1.m1.4.4.1.1.2.2.2.1.1.1.1.1.1.cmml">−</mo><mi id="S3.E5.m1.1.1.1.1.m1.4.4.1.1.2.2.2.1.1.1.1.1.3" xref="S3.E5.m1.1.1.1.1.m1.4.4.1.1.2.2.2.1.1.1.1.1.3.cmml">λ</mi></mrow><mo stretchy="false" id="S3.E5.m1.1.1.1.1.m1.4.4.1.1.2.2.2.1.1.1.1.3" xref="S3.E5.m1.1.1.1.1.m1.4.4.1.1.2.2.2.1.1.1.1.1.cmml">)</mo></mrow><mo lspace="0.337em" rspace="0em" id="S3.E5.m1.1.1.1.1.m1.4.4.1.1.2.2.2.1.2.3" xref="S3.E5.m1.1.1.1.1.m1.4.4.1.1.2.2.2.1.2.3.cmml">​</mo><mrow id="S3.E5.m1.1.1.1.1.m1.4.4.1.1.2.2.2.1.2.2.1" xref="S3.E5.m1.1.1.1.1.m1.4.4.1.1.2.2.2.1.2.2.2.cmml"><mo rspace="0em" id="S3.E5.m1.1.1.1.1.m1.3.3" xref="S3.E5.m1.1.1.1.1.m1.3.3.cmml">softmax</mo><mrow id="S3.E5.m1.1.1.1.1.m1.4.4.1.1.2.2.2.1.2.2.1.1" xref="S3.E5.m1.1.1.1.1.m1.4.4.1.1.2.2.2.1.2.2.2.cmml"><mo stretchy="false" id="S3.E5.m1.1.1.1.1.m1.4.4.1.1.2.2.2.1.2.2.1.1.2" xref="S3.E5.m1.1.1.1.1.m1.4.4.1.1.2.2.2.1.2.2.2.cmml">(</mo><mrow id="S3.E5.m1.1.1.1.1.m1.4.4.1.1.2.2.2.1.2.2.1.1.1" xref="S3.E5.m1.1.1.1.1.m1.4.4.1.1.2.2.2.1.2.2.1.1.1.cmml"><mo id="S3.E5.m1.1.1.1.1.m1.4.4.1.1.2.2.2.1.2.2.1.1.1a" xref="S3.E5.m1.1.1.1.1.m1.4.4.1.1.2.2.2.1.2.2.1.1.1.cmml">−</mo><mi id="S3.E5.m1.1.1.1.1.m1.4.4.1.1.2.2.2.1.2.2.1.1.1.2" xref="S3.E5.m1.1.1.1.1.m1.4.4.1.1.2.2.2.1.2.2.1.1.1.2.cmml">𝒅</mi></mrow><mo stretchy="false" id="S3.E5.m1.1.1.1.1.m1.4.4.1.1.2.2.2.1.2.2.1.1.3" xref="S3.E5.m1.1.1.1.1.m1.4.4.1.1.2.2.2.1.2.2.2.cmml">)</mo></mrow></mrow></mrow></mrow><mo maxsize="120%" minsize="120%" rspace="0.052em" id="S3.E5.m1.1.1.1.1.m1.4.4.1.1.2.2.2.3" xref="S3.E5.m1.1.1.1.1.m1.4.4.1.1.2.3.cmml">)</mo></mrow></mrow></mrow><mo id="S3.E5.m1.1.1.1.1.m1.4.4.1.2" xref="S3.E5.m1.1.1.1.1.m1.4.4.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E5.m1.1.1.1.1.m1.4b"><apply id="S3.E5.m1.1.1.1.1.m1.4.4.1.1.cmml" xref="S3.E5.m1.1.1.1.1.m1.4.4.1"><eq id="S3.E5.m1.1.1.1.1.m1.4.4.1.1.3.cmml" xref="S3.E5.m1.1.1.1.1.m1.4.4.1.1.3"></eq><apply id="S3.E5.m1.1.1.1.1.m1.4.4.1.1.4.cmml" xref="S3.E5.m1.1.1.1.1.m1.4.4.1.1.4"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.1.1.m1.4.4.1.1.4.1.cmml" xref="S3.E5.m1.1.1.1.1.m1.4.4.1.1.4">superscript</csymbol><ci id="S3.E5.m1.1.1.1.1.m1.4.4.1.1.4.2.cmml" xref="S3.E5.m1.1.1.1.1.m1.4.4.1.1.4.2">𝑎</ci><ci id="S3.E5.m1.1.1.1.1.m1.4.4.1.1.4.3.cmml" xref="S3.E5.m1.1.1.1.1.m1.4.4.1.1.4.3">⋆</ci></apply><apply id="S3.E5.m1.1.1.1.1.m1.4.4.1.1.2.3.cmml" xref="S3.E5.m1.1.1.1.1.m1.4.4.1.1.2.2"><apply id="S3.E5.m1.1.1.1.1.m1.4.4.1.1.1.1.1.cmml" xref="S3.E5.m1.1.1.1.1.m1.4.4.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.1.1.m1.4.4.1.1.1.1.1.1.cmml" xref="S3.E5.m1.1.1.1.1.m1.4.4.1.1.1.1.1">subscript</csymbol><apply id="S3.E5.m1.1.1.1.1.m1.4.4.1.1.1.1.1.2.cmml" xref="S3.E5.m1.1.1.1.1.m1.4.4.1.1.1.1.1.2"><times id="S3.E5.m1.1.1.1.1.m1.4.4.1.1.1.1.1.2.1.cmml" xref="S3.E5.m1.1.1.1.1.m1.4.4.1.1.1.1.1.2.1"></times><ci id="S3.E5.m1.1.1.1.1.m1.4.4.1.1.1.1.1.2.2.cmml" xref="S3.E5.m1.1.1.1.1.m1.4.4.1.1.1.1.1.2.2">arg</ci><ci id="S3.E5.m1.1.1.1.1.m1.4.4.1.1.1.1.1.2.3.cmml" xref="S3.E5.m1.1.1.1.1.m1.4.4.1.1.1.1.1.2.3">max</ci></apply><ci id="S3.E5.m1.1.1.1.1.m1.4.4.1.1.1.1.1.3.cmml" xref="S3.E5.m1.1.1.1.1.m1.4.4.1.1.1.1.1.3">𝑖</ci></apply><apply id="S3.E5.m1.1.1.1.1.m1.4.4.1.1.2.2.2.1.cmml" xref="S3.E5.m1.1.1.1.1.m1.4.4.1.1.2.2.2.1"><plus id="S3.E5.m1.1.1.1.1.m1.4.4.1.1.2.2.2.1.3.cmml" xref="S3.E5.m1.1.1.1.1.m1.4.4.1.1.2.2.2.1.3"></plus><apply id="S3.E5.m1.1.1.1.1.m1.4.4.1.1.2.2.2.1.4.cmml" xref="S3.E5.m1.1.1.1.1.m1.4.4.1.1.2.2.2.1.4"><times id="S3.E5.m1.1.1.1.1.m1.4.4.1.1.2.2.2.1.4.1.cmml" xref="S3.E5.m1.1.1.1.1.m1.4.4.1.1.2.2.2.1.4.1"></times><ci id="S3.E5.m1.1.1.1.1.m1.4.4.1.1.2.2.2.1.4.2.cmml" xref="S3.E5.m1.1.1.1.1.m1.4.4.1.1.2.2.2.1.4.2">𝜆</ci><apply id="S3.E5.m1.1.1.1.1.m1.4.4.1.1.2.2.2.1.4.3.1.cmml" xref="S3.E5.m1.1.1.1.1.m1.4.4.1.1.2.2.2.1.4.3.2"><ci id="S3.E5.m1.1.1.1.1.m1.1.1.cmml" xref="S3.E5.m1.1.1.1.1.m1.1.1">softmax</ci><ci id="S3.E5.m1.1.1.1.1.m1.2.2.cmml" xref="S3.E5.m1.1.1.1.1.m1.2.2">𝒚</ci></apply></apply><apply id="S3.E5.m1.1.1.1.1.m1.4.4.1.1.2.2.2.1.2.cmml" xref="S3.E5.m1.1.1.1.1.m1.4.4.1.1.2.2.2.1.2"><times id="S3.E5.m1.1.1.1.1.m1.4.4.1.1.2.2.2.1.2.3.cmml" xref="S3.E5.m1.1.1.1.1.m1.4.4.1.1.2.2.2.1.2.3"></times><apply id="S3.E5.m1.1.1.1.1.m1.4.4.1.1.2.2.2.1.1.1.1.1.cmml" xref="S3.E5.m1.1.1.1.1.m1.4.4.1.1.2.2.2.1.1.1.1"><minus id="S3.E5.m1.1.1.1.1.m1.4.4.1.1.2.2.2.1.1.1.1.1.1.cmml" xref="S3.E5.m1.1.1.1.1.m1.4.4.1.1.2.2.2.1.1.1.1.1.1"></minus><cn type="integer" id="S3.E5.m1.1.1.1.1.m1.4.4.1.1.2.2.2.1.1.1.1.1.2.cmml" xref="S3.E5.m1.1.1.1.1.m1.4.4.1.1.2.2.2.1.1.1.1.1.2">1</cn><ci id="S3.E5.m1.1.1.1.1.m1.4.4.1.1.2.2.2.1.1.1.1.1.3.cmml" xref="S3.E5.m1.1.1.1.1.m1.4.4.1.1.2.2.2.1.1.1.1.1.3">𝜆</ci></apply><apply id="S3.E5.m1.1.1.1.1.m1.4.4.1.1.2.2.2.1.2.2.2.cmml" xref="S3.E5.m1.1.1.1.1.m1.4.4.1.1.2.2.2.1.2.2.1"><ci id="S3.E5.m1.1.1.1.1.m1.3.3.cmml" xref="S3.E5.m1.1.1.1.1.m1.3.3">softmax</ci><apply id="S3.E5.m1.1.1.1.1.m1.4.4.1.1.2.2.2.1.2.2.1.1.1.cmml" xref="S3.E5.m1.1.1.1.1.m1.4.4.1.1.2.2.2.1.2.2.1.1.1"><minus id="S3.E5.m1.1.1.1.1.m1.4.4.1.1.2.2.2.1.2.2.1.1.1.1.cmml" xref="S3.E5.m1.1.1.1.1.m1.4.4.1.1.2.2.2.1.2.2.1.1.1"></minus><ci id="S3.E5.m1.1.1.1.1.m1.4.4.1.1.2.2.2.1.2.2.1.1.1.2.cmml" xref="S3.E5.m1.1.1.1.1.m1.4.4.1.1.2.2.2.1.2.2.1.1.1.2">𝒅</ci></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E5.m1.1.1.1.1.m1.4c">a^{\star}=\operatorname*{arg\,max}_{i}\big{(}\lambda\,\operatorname*{softmax}(\boldsymbol{y})\,+\,(1-\lambda)\,\operatorname*{softmax}(-\boldsymbol{d})\big{)}~{}.</annotation></semantics></math></p>
</span></div>
</td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="0" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5)</span></td>
</tr></tbody>
</table>
</div>
</section>
<section id="S3.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4 </span>Incorporating Prior Knowledge about Answers</h3>

<div id="S3.SS4.p1" class="ltx_para">
<p id="S3.SS4.p1.3" class="ltx_p">The matrix <math id="S3.SS4.p1.1.m1.1" class="ltx_Math" alttext="M" display="inline"><semantics id="S3.SS4.p1.1.m1.1a"><mi id="S3.SS4.p1.1.m1.1.1" xref="S3.SS4.p1.1.m1.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.1.m1.1b"><ci id="S3.SS4.p1.1.m1.1.1.cmml" xref="S3.SS4.p1.1.m1.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.1.m1.1c">M</annotation></semantics></math> of the regression branch contains, in each of its rows, the representation of a candidate answer. <math id="S3.SS4.p1.2.m2.1" class="ltx_Math" alttext="M" display="inline"><semantics id="S3.SS4.p1.2.m2.1a"><mi id="S3.SS4.p1.2.m2.1.1" xref="S3.SS4.p1.2.m2.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.2.m2.1b"><ci id="S3.SS4.p1.2.m2.1.1.cmml" xref="S3.SS4.p1.2.m2.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.2.m2.1c">M</annotation></semantics></math> can be treated and optimized as any other parameter of the network, but it can also be initialized with values that contain prior knowledge about answers. In particular, we experiment with GloVe embeddings <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite> for single-word answers, and averaged (<em id="S3.SS4.p1.3.1" class="ltx_emph ltx_font_italic">i.e</em>.<span id="S3.SS4.p1.3.2" class="ltx_text"></span> as a bag-of-words) in the case of multi-word ones. The values of <math id="S3.SS4.p1.3.m3.1" class="ltx_Math" alttext="M" display="inline"><semantics id="S3.SS4.p1.3.m3.1a"><mi id="S3.SS4.p1.3.m3.1.1" xref="S3.SS4.p1.3.m3.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.3.m3.1b"><ci id="S3.SS4.p1.3.m3.1.1.cmml" xref="S3.SS4.p1.3.m3.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.3.m3.1c">M</annotation></semantics></math> are further fine-tuned during training. Freezing them always proved inferior in our preliminary experiments (not reported).</p>
</div>
<div id="S3.SS4.p2" class="ltx_para">
<p id="S3.SS4.p2.1" class="ltx_p">As ablations of our model, we consider two other initialization schemes of <math id="S3.SS4.p2.1.m1.1" class="ltx_Math" alttext="M" display="inline"><semantics id="S3.SS4.p2.1.m1.1a"><mi id="S3.SS4.p2.1.m1.1.1" xref="S3.SS4.p2.1.m1.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.1.m1.1b"><ci id="S3.SS4.p2.1.m1.1.1.cmml" xref="S3.SS4.p2.1.m1.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.1.m1.1c">M</annotation></semantics></math>. They will serve to probe for the source of the gains of our model.</p>
<ul id="S3.I1" class="ltx_itemize">
<li id="S3.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i1.p1" class="ltx_para">
<p id="S3.I1.i1.p1.1" class="ltx_p"><span id="S3.I1.i1.p1.1.1" class="ltx_text ltx_font_italic">Random.</span> We initialize <math id="S3.I1.i1.p1.1.m1.1" class="ltx_Math" alttext="M" display="inline"><semantics id="S3.I1.i1.p1.1.m1.1a"><mi id="S3.I1.i1.p1.1.m1.1.1" xref="S3.I1.i1.p1.1.m1.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S3.I1.i1.p1.1.m1.1b"><ci id="S3.I1.i1.p1.1.m1.1.1.cmml" xref="S3.I1.i1.p1.1.m1.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i1.p1.1.m1.1c">M</annotation></semantics></math> with normally distributed random values, as would be any other weight matrix of the network.</p>
</div>
</li>
<li id="S3.I1.i2" class="ltx_item" style="list-style-type:none;padding-top:1.0pt;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i2.p1" class="ltx_para">
<p id="S3.I1.i2.p1.2" class="ltx_p"><span id="S3.I1.i2.p1.2.1" class="ltx_text ltx_font_italic">Shuffled GloVe.</span> We initialize <math id="S3.I1.i2.p1.1.m1.1" class="ltx_Math" alttext="M" display="inline"><semantics id="S3.I1.i2.p1.1.m1.1a"><mi id="S3.I1.i2.p1.1.m1.1.1" xref="S3.I1.i2.p1.1.m1.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S3.I1.i2.p1.1.m1.1b"><ci id="S3.I1.i2.p1.1.m1.1.1.cmml" xref="S3.I1.i2.p1.1.m1.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i2.p1.1.m1.1c">M</annotation></semantics></math> with GloVe embeddings as described above, but subsequently shuffle its rows randomly, as in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>. The rows of <math id="S3.I1.i2.p1.2.m2.1" class="ltx_Math" alttext="M" display="inline"><semantics id="S3.I1.i2.p1.2.m2.1a"><mi id="S3.I1.i2.p1.2.m2.1.1" xref="S3.I1.i2.p1.2.m2.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S3.I1.i2.p1.2.m2.1b"><ci id="S3.I1.i2.p1.2.m2.1.1.cmml" xref="S3.I1.i2.p1.2.m2.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i2.p1.2.m2.1c">M</annotation></semantics></math> are thus mismatched from their corresponding answers. This allows us to disentangle the anticipated benefits of using the semantic information carried in GloVe vectors, from the mere numerical effects of using them as initial values.</p>
</div>
</li>
</ul>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experiments</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">We performed an extensive evaluation to thoroughly validate the benefits of the proposed method, and understand the exact source of improvement. The overall conclusion is that the improvements indeed stem from the information brought in by the use of external data, rather than numerical artifacts or structural modifications to the network architecture.</p>
</div>
<div id="S4.p2" class="ltx_para">
<p id="S4.p2.1" class="ltx_p">Our contributions are implemented on top of the open-source Pythia framework <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>, the winning entry of the 2018 VQA Challenge. The technique is however applicable to a wide range of current and future models. Pythia thus serves as the main baseline. We also evaluate the Pythia model where the weights of the output classifier are initialized with pretrained answer embeddings (noted ‘Pythia+GloVe’) in the manner proposed by <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>. We also compare our method to existing methods designed to inject prior knowledge in the model in the form of answer embeddings. Precisely, we consider the two variants of the “factorized Probabilistic Model of Compatibility” (fPMC) proposed by <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>, using the code provided by the authors. All tested models use the same image features (those provided with the GQA dataset) and representations of question words (300-dimensional pretrained GloVe embeddings). Details are provided in Appendix <span class="ltx_ref ltx_nolink ltx_ref_self"><span class="ltx_text ltx_ref_tag">A</span></span>.</p>
</div>
<div id="S4.p3" class="ltx_para">
<p id="S4.p3.4" class="ltx_p">The general hyperparameters of Pythia (batch size, learning rate, <em id="S4.p3.4.1" class="ltx_emph ltx_font_italic">etc</em>.<span id="S4.p3.4.2" class="ltx_text"></span>) were chosen by grid search for best performance of the <em id="S4.p3.4.3" class="ltx_emph ltx_font_italic">baseline</em> model (<em id="S4.p3.4.4" class="ltx_emph ltx_font_italic">i.e</em>.<span id="S4.p3.4.5" class="ltx_text"></span> without our contributions) on the GQA validation set. They were not modified once our contributions were added. This ensures a fair and challenging baseline. The distance function <math id="S4.p3.1.m1.3" class="ltx_Math" alttext="\operatorname*{dist}(\cdot,\cdot)" display="inline"><semantics id="S4.p3.1.m1.3a"><mrow id="S4.p3.1.m1.3.4.2" xref="S4.p3.1.m1.3.4.1.cmml"><mo rspace="0em" id="S4.p3.1.m1.1.1" xref="S4.p3.1.m1.1.1.cmml">dist</mo><mrow id="S4.p3.1.m1.3.4.2.1" xref="S4.p3.1.m1.3.4.1.cmml"><mo stretchy="false" id="S4.p3.1.m1.3.4.2.1.1" xref="S4.p3.1.m1.3.4.1.cmml">(</mo><mo lspace="0em" rspace="0em" id="S4.p3.1.m1.2.2" xref="S4.p3.1.m1.2.2.cmml">⋅</mo><mo rspace="0em" id="S4.p3.1.m1.3.4.2.1.2" xref="S4.p3.1.m1.3.4.1.cmml">,</mo><mo lspace="0em" rspace="0em" id="S4.p3.1.m1.3.3" xref="S4.p3.1.m1.3.3.cmml">⋅</mo><mo stretchy="false" id="S4.p3.1.m1.3.4.2.1.3" xref="S4.p3.1.m1.3.4.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.p3.1.m1.3b"><apply id="S4.p3.1.m1.3.4.1.cmml" xref="S4.p3.1.m1.3.4.2"><ci id="S4.p3.1.m1.1.1.cmml" xref="S4.p3.1.m1.1.1">dist</ci><ci id="S4.p3.1.m1.2.2.cmml" xref="S4.p3.1.m1.2.2">⋅</ci><ci id="S4.p3.1.m1.3.3.cmml" xref="S4.p3.1.m1.3.3">⋅</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p3.1.m1.3c">\operatorname*{dist}(\cdot,\cdot)</annotation></semantics></math> is implemented as the Euclidean distance. This choice proved empirically superior, on the GQA validation set, to a dot product or a cosine similarity. The parameter <math id="S4.p3.2.m2.1" class="ltx_Math" alttext="\lambda" display="inline"><semantics id="S4.p3.2.m2.1a"><mi id="S4.p3.2.m2.1.1" xref="S4.p3.2.m2.1.1.cmml">λ</mi><annotation-xml encoding="MathML-Content" id="S4.p3.2.m2.1b"><ci id="S4.p3.2.m2.1.1.cmml" xref="S4.p3.2.m2.1.1">𝜆</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p3.2.m2.1c">\lambda</annotation></semantics></math> is set to <math id="S4.p3.3.m3.1" class="ltx_Math" alttext="0.5" display="inline"><semantics id="S4.p3.3.m3.1a"><mn id="S4.p3.3.m3.1.1" xref="S4.p3.3.m3.1.1.cmml">0.5</mn><annotation-xml encoding="MathML-Content" id="S4.p3.3.m3.1b"><cn type="float" id="S4.p3.3.m3.1.1.cmml" xref="S4.p3.3.m3.1.1">0.5</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.p3.3.m3.1c">0.5</annotation></semantics></math>, unless otherwise noted. Every experiment was repeated with five different random seeds, and we report the average over the five runs. The ensembles use the average of the predicted scores/distances of several models trained with different random seeds, before taking the <math id="S4.p3.4.m4.1" class="ltx_Math" alttext="\operatorname*{arg\,max}" display="inline"><semantics id="S4.p3.4.m4.1a"><mrow id="S4.p3.4.m4.1.1" xref="S4.p3.4.m4.1.1.cmml"><mi id="S4.p3.4.m4.1.1.2" xref="S4.p3.4.m4.1.1.2.cmml">arg</mi><mo lspace="0.170em" rspace="0em" id="S4.p3.4.m4.1.1.1" xref="S4.p3.4.m4.1.1.1.cmml">​</mo><mi id="S4.p3.4.m4.1.1.3" xref="S4.p3.4.m4.1.1.3.cmml">max</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.p3.4.m4.1b"><apply id="S4.p3.4.m4.1.1.cmml" xref="S4.p3.4.m4.1.1"><times id="S4.p3.4.m4.1.1.1.cmml" xref="S4.p3.4.m4.1.1.1"></times><ci id="S4.p3.4.m4.1.1.2.cmml" xref="S4.p3.4.m4.1.1.2">arg</ci><ci id="S4.p3.4.m4.1.1.3.cmml" xref="S4.p3.4.m4.1.1.3">max</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p3.4.m4.1c">\operatorname*{arg\,max}</annotation></semantics></math> of Eq. <a href="#S3.E5" title="In 3.3 Predictions ‣ 3 Proposed Approach ‣ Visual Question Answering with Prior Class Semantics" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>.</p>
</div>
<figure id="S4.T1" class="ltx_table">
<div id="S4.T1.4.4" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:496.9pt;height:273.7pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-12.9pt,7.1pt) scale(0.950489777642932,0.950489777642932) ;">
<table id="S4.T1.4.4.4" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T1.4.4.4.5.1" class="ltx_tr">
<th id="S4.T1.4.4.4.5.1.1" class="ltx_td ltx_th ltx_th_row ltx_border_tt"></th>
<td id="S4.T1.4.4.4.5.1.2" class="ltx_td ltx_align_center ltx_border_tt" colspan="3">GQA validation</td>
<td id="S4.T1.4.4.4.5.1.3" class="ltx_td ltx_border_tt"></td>
<td id="S4.T1.4.4.4.5.1.4" class="ltx_td ltx_align_center ltx_border_tt" colspan="3">GQA test-dev</td>
<td id="S4.T1.4.4.4.5.1.5" class="ltx_td ltx_border_tt"></td>
<td id="S4.T1.4.4.4.5.1.6" class="ltx_td ltx_align_center ltx_border_tt" colspan="3">GQA test</td>
</tr>
<tr id="S4.T1.4.4.4.6.2" class="ltx_tr">
<th id="S4.T1.4.4.4.6.2.1" class="ltx_td ltx_th ltx_th_row"></th>
<td id="S4.T1.4.4.4.6.2.2" class="ltx_td ltx_align_center ltx_border_t">Binary</td>
<td id="S4.T1.4.4.4.6.2.3" class="ltx_td ltx_align_center ltx_border_t">Open</td>
<td id="S4.T1.4.4.4.6.2.4" class="ltx_td ltx_align_center ltx_border_t">All</td>
<td id="S4.T1.4.4.4.6.2.5" class="ltx_td"></td>
<td id="S4.T1.4.4.4.6.2.6" class="ltx_td ltx_align_center ltx_border_t">Binary</td>
<td id="S4.T1.4.4.4.6.2.7" class="ltx_td ltx_align_center ltx_border_t">Open</td>
<td id="S4.T1.4.4.4.6.2.8" class="ltx_td ltx_align_center ltx_border_t">All</td>
<td id="S4.T1.4.4.4.6.2.9" class="ltx_td"></td>
<td id="S4.T1.4.4.4.6.2.10" class="ltx_td ltx_align_center ltx_border_t">Binary</td>
<td id="S4.T1.4.4.4.6.2.11" class="ltx_td ltx_align_center ltx_border_t">Open</td>
<td id="S4.T1.4.4.4.6.2.12" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">All</td>
</tr>
<tr id="S4.T1.4.4.4.7.3" class="ltx_tr">
<th id="S4.T1.4.4.4.7.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">Blind LSTM</th>
<td id="S4.T1.4.4.4.7.3.2" class="ltx_td ltx_align_center ltx_border_t">–</td>
<td id="S4.T1.4.4.4.7.3.3" class="ltx_td ltx_align_center ltx_border_t">–</td>
<td id="S4.T1.4.4.4.7.3.4" class="ltx_td ltx_align_center ltx_border_t">–</td>
<td id="S4.T1.4.4.4.7.3.5" class="ltx_td ltx_border_t"></td>
<td id="S4.T1.4.4.4.7.3.6" class="ltx_td ltx_align_center ltx_border_t">–</td>
<td id="S4.T1.4.4.4.7.3.7" class="ltx_td ltx_align_center ltx_border_t">–</td>
<td id="S4.T1.4.4.4.7.3.8" class="ltx_td ltx_align_center ltx_border_t">–</td>
<td id="S4.T1.4.4.4.7.3.9" class="ltx_td ltx_border_t"></td>
<td id="S4.T1.4.4.4.7.3.10" class="ltx_td ltx_align_center ltx_border_t">61.90</td>
<td id="S4.T1.4.4.4.7.3.11" class="ltx_td ltx_align_center ltx_border_t">22.69</td>
<td id="S4.T1.4.4.4.7.3.12" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">41.07</td>
</tr>
<tr id="S4.T1.4.4.4.8.4" class="ltx_tr">
<th id="S4.T1.4.4.4.8.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">BUTD</th>
<td id="S4.T1.4.4.4.8.4.2" class="ltx_td ltx_align_center">–</td>
<td id="S4.T1.4.4.4.8.4.3" class="ltx_td ltx_align_center">–</td>
<td id="S4.T1.4.4.4.8.4.4" class="ltx_td ltx_align_center">–</td>
<td id="S4.T1.4.4.4.8.4.5" class="ltx_td"></td>
<td id="S4.T1.4.4.4.8.4.6" class="ltx_td ltx_align_center">–</td>
<td id="S4.T1.4.4.4.8.4.7" class="ltx_td ltx_align_center">–</td>
<td id="S4.T1.4.4.4.8.4.8" class="ltx_td ltx_align_center">–</td>
<td id="S4.T1.4.4.4.8.4.9" class="ltx_td"></td>
<td id="S4.T1.4.4.4.8.4.10" class="ltx_td ltx_align_center">66.64</td>
<td id="S4.T1.4.4.4.8.4.11" class="ltx_td ltx_align_center">34.83</td>
<td id="S4.T1.4.4.4.8.4.12" class="ltx_td ltx_nopad_r ltx_align_center">49.74</td>
</tr>
<tr id="S4.T1.4.4.4.9.5" class="ltx_tr">
<th id="S4.T1.4.4.4.9.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">MAC</th>
<td id="S4.T1.4.4.4.9.5.2" class="ltx_td ltx_align_center">–</td>
<td id="S4.T1.4.4.4.9.5.3" class="ltx_td ltx_align_center">–</td>
<td id="S4.T1.4.4.4.9.5.4" class="ltx_td ltx_align_center">–</td>
<td id="S4.T1.4.4.4.9.5.5" class="ltx_td"></td>
<td id="S4.T1.4.4.4.9.5.6" class="ltx_td ltx_align_center">–</td>
<td id="S4.T1.4.4.4.9.5.7" class="ltx_td ltx_align_center">–</td>
<td id="S4.T1.4.4.4.9.5.8" class="ltx_td ltx_align_center">–</td>
<td id="S4.T1.4.4.4.9.5.9" class="ltx_td"></td>
<td id="S4.T1.4.4.4.9.5.10" class="ltx_td ltx_align_center">71.23</td>
<td id="S4.T1.4.4.4.9.5.11" class="ltx_td ltx_align_center">38.91</td>
<td id="S4.T1.4.4.4.9.5.12" class="ltx_td ltx_nopad_r ltx_align_center">54.06</td>
</tr>
<tr id="S4.T1.4.4.4.10.6" class="ltx_tr">
<th id="S4.T1.4.4.4.10.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">LXMERT</th>
<td id="S4.T1.4.4.4.10.6.2" class="ltx_td ltx_align_center">–</td>
<td id="S4.T1.4.4.4.10.6.3" class="ltx_td ltx_align_center">–</td>
<td id="S4.T1.4.4.4.10.6.4" class="ltx_td ltx_align_center">–</td>
<td id="S4.T1.4.4.4.10.6.5" class="ltx_td"></td>
<td id="S4.T1.4.4.4.10.6.6" class="ltx_td ltx_align_center">–</td>
<td id="S4.T1.4.4.4.10.6.7" class="ltx_td ltx_align_center">–</td>
<td id="S4.T1.4.4.4.10.6.8" class="ltx_td ltx_align_center">–</td>
<td id="S4.T1.4.4.4.10.6.9" class="ltx_td"></td>
<td id="S4.T1.4.4.4.10.6.10" class="ltx_td ltx_align_center">77.80</td>
<td id="S4.T1.4.4.4.10.6.11" class="ltx_td ltx_align_center">45.00</td>
<td id="S4.T1.4.4.4.10.6.12" class="ltx_td ltx_nopad_r ltx_align_center">60.30</td>
</tr>
<tr id="S4.T1.4.4.4.11.7" class="ltx_tr">
<th id="S4.T1.4.4.4.11.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">NSM</th>
<td id="S4.T1.4.4.4.11.7.2" class="ltx_td ltx_align_center">–</td>
<td id="S4.T1.4.4.4.11.7.3" class="ltx_td ltx_align_center">–</td>
<td id="S4.T1.4.4.4.11.7.4" class="ltx_td ltx_align_center">–</td>
<td id="S4.T1.4.4.4.11.7.5" class="ltx_td"></td>
<td id="S4.T1.4.4.4.11.7.6" class="ltx_td ltx_align_center">–</td>
<td id="S4.T1.4.4.4.11.7.7" class="ltx_td ltx_align_center">–</td>
<td id="S4.T1.4.4.4.11.7.8" class="ltx_td ltx_align_center">–</td>
<td id="S4.T1.4.4.4.11.7.9" class="ltx_td"></td>
<td id="S4.T1.4.4.4.11.7.10" class="ltx_td ltx_align_center"><span id="S4.T1.4.4.4.11.7.10.1" class="ltx_text ltx_font_bold">78.94</span></td>
<td id="S4.T1.4.4.4.11.7.11" class="ltx_td ltx_align_center"><span id="S4.T1.4.4.4.11.7.11.1" class="ltx_text ltx_font_bold">49.25</span></td>
<td id="S4.T1.4.4.4.11.7.12" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T1.4.4.4.11.7.12.1" class="ltx_text ltx_font_bold">63.17</span></td>
</tr>
<tr id="S4.T1.4.4.4.12.8" class="ltx_tr">
<th id="S4.T1.4.4.4.12.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Pythia</th>
<td id="S4.T1.4.4.4.12.8.2" class="ltx_td ltx_align_center">75.45</td>
<td id="S4.T1.4.4.4.12.8.3" class="ltx_td ltx_align_center">45.76</td>
<td id="S4.T1.4.4.4.12.8.4" class="ltx_td ltx_align_center">60.13</td>
<td id="S4.T1.4.4.4.12.8.5" class="ltx_td"></td>
<td id="S4.T1.4.4.4.12.8.6" class="ltx_td ltx_align_center">71.51</td>
<td id="S4.T1.4.4.4.12.8.7" class="ltx_td ltx_align_center">38.15</td>
<td id="S4.T1.4.4.4.12.8.8" class="ltx_td ltx_align_center">53.46</td>
<td id="S4.T1.4.4.4.12.8.9" class="ltx_td"></td>
<td id="S4.T1.4.4.4.12.8.10" class="ltx_td ltx_align_center">–</td>
<td id="S4.T1.4.4.4.12.8.11" class="ltx_td ltx_align_center">–</td>
<td id="S4.T1.4.4.4.12.8.12" class="ltx_td ltx_nopad_r ltx_align_center">–</td>
</tr>
<tr id="S4.T1.4.4.4.13.9" class="ltx_tr">
<th id="S4.T1.4.4.4.13.9.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Pythia + GloVe</th>
<td id="S4.T1.4.4.4.13.9.2" class="ltx_td ltx_align_center">74.91</td>
<td id="S4.T1.4.4.4.13.9.3" class="ltx_td ltx_align_center">45.77</td>
<td id="S4.T1.4.4.4.13.9.4" class="ltx_td ltx_align_center">59.87</td>
<td id="S4.T1.4.4.4.13.9.5" class="ltx_td"></td>
<td id="S4.T1.4.4.4.13.9.6" class="ltx_td ltx_align_center">71.36</td>
<td id="S4.T1.4.4.4.13.9.7" class="ltx_td ltx_align_center">37.94</td>
<td id="S4.T1.4.4.4.13.9.8" class="ltx_td ltx_align_center">53.28</td>
<td id="S4.T1.4.4.4.13.9.9" class="ltx_td"></td>
<td id="S4.T1.4.4.4.13.9.10" class="ltx_td ltx_align_center">–</td>
<td id="S4.T1.4.4.4.13.9.11" class="ltx_td ltx_align_center">–</td>
<td id="S4.T1.4.4.4.13.9.12" class="ltx_td ltx_nopad_r ltx_align_center">–</td>
</tr>
<tr id="S4.T1.1.1.1.1" class="ltx_tr">
<th id="S4.T1.1.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">fPMC(BUTD<math id="S4.T1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\star" display="inline"><semantics id="S4.T1.1.1.1.1.1.m1.1a"><mo id="S4.T1.1.1.1.1.1.m1.1.1" xref="S4.T1.1.1.1.1.1.m1.1.1.cmml">⋆</mo><annotation-xml encoding="MathML-Content" id="S4.T1.1.1.1.1.1.m1.1b"><ci id="S4.T1.1.1.1.1.1.m1.1.1.cmml" xref="S4.T1.1.1.1.1.1.m1.1.1">⋆</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.1.1.1.1.1.m1.1c">\star</annotation></semantics></math>)</th>
<td id="S4.T1.1.1.1.1.2" class="ltx_td ltx_align_center">69.85</td>
<td id="S4.T1.1.1.1.1.3" class="ltx_td ltx_align_center">42.28</td>
<td id="S4.T1.1.1.1.1.4" class="ltx_td ltx_align_center">55.62</td>
<td id="S4.T1.1.1.1.1.5" class="ltx_td"></td>
<td id="S4.T1.1.1.1.1.6" class="ltx_td ltx_align_center">64.80</td>
<td id="S4.T1.1.1.1.1.7" class="ltx_td ltx_align_center">35.40</td>
<td id="S4.T1.1.1.1.1.8" class="ltx_td ltx_align_center">48.90</td>
<td id="S4.T1.1.1.1.1.9" class="ltx_td"></td>
<td id="S4.T1.1.1.1.1.10" class="ltx_td ltx_align_center">–</td>
<td id="S4.T1.1.1.1.1.11" class="ltx_td ltx_align_center">–</td>
<td id="S4.T1.1.1.1.1.12" class="ltx_td ltx_nopad_r ltx_align_center">–</td>
</tr>
<tr id="S4.T1.2.2.2.2" class="ltx_tr">
<th id="S4.T1.2.2.2.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">fPMC(SAN<math id="S4.T1.2.2.2.2.1.m1.1" class="ltx_Math" alttext="\star" display="inline"><semantics id="S4.T1.2.2.2.2.1.m1.1a"><mo id="S4.T1.2.2.2.2.1.m1.1.1" xref="S4.T1.2.2.2.2.1.m1.1.1.cmml">⋆</mo><annotation-xml encoding="MathML-Content" id="S4.T1.2.2.2.2.1.m1.1b"><ci id="S4.T1.2.2.2.2.1.m1.1.1.cmml" xref="S4.T1.2.2.2.2.1.m1.1.1">⋆</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.2.2.2.2.1.m1.1c">\star</annotation></semantics></math>)</th>
<td id="S4.T1.2.2.2.2.2" class="ltx_td ltx_align_center">71.94</td>
<td id="S4.T1.2.2.2.2.3" class="ltx_td ltx_align_center">41.78</td>
<td id="S4.T1.2.2.2.2.4" class="ltx_td ltx_align_center">56.37</td>
<td id="S4.T1.2.2.2.2.5" class="ltx_td"></td>
<td id="S4.T1.2.2.2.2.6" class="ltx_td ltx_align_center">67.02</td>
<td id="S4.T1.2.2.2.2.7" class="ltx_td ltx_align_center">35.83</td>
<td id="S4.T1.2.2.2.2.8" class="ltx_td ltx_align_center">50.14</td>
<td id="S4.T1.2.2.2.2.9" class="ltx_td"></td>
<td id="S4.T1.2.2.2.2.10" class="ltx_td ltx_align_center">–</td>
<td id="S4.T1.2.2.2.2.11" class="ltx_td ltx_align_center">–</td>
<td id="S4.T1.2.2.2.2.12" class="ltx_td ltx_nopad_r ltx_align_center">–</td>
</tr>
<tr id="S4.T1.4.4.4.14.10" class="ltx_tr">
<th id="S4.T1.4.4.4.14.10.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Ours + random</th>
<td id="S4.T1.4.4.4.14.10.2" class="ltx_td ltx_align_center">75.15</td>
<td id="S4.T1.4.4.4.14.10.3" class="ltx_td ltx_align_center">46.33</td>
<td id="S4.T1.4.4.4.14.10.4" class="ltx_td ltx_align_center">60.27</td>
<td id="S4.T1.4.4.4.14.10.5" class="ltx_td"></td>
<td id="S4.T1.4.4.4.14.10.6" class="ltx_td ltx_align_center">70.67</td>
<td id="S4.T1.4.4.4.14.10.7" class="ltx_td ltx_align_center">38.14</td>
<td id="S4.T1.4.4.4.14.10.8" class="ltx_td ltx_align_center">53.08</td>
<td id="S4.T1.4.4.4.14.10.9" class="ltx_td"></td>
<td id="S4.T1.4.4.4.14.10.10" class="ltx_td ltx_align_center">–</td>
<td id="S4.T1.4.4.4.14.10.11" class="ltx_td ltx_align_center">–</td>
<td id="S4.T1.4.4.4.14.10.12" class="ltx_td ltx_nopad_r ltx_align_center">–</td>
</tr>
<tr id="S4.T1.4.4.4.15.11" class="ltx_tr">
<th id="S4.T1.4.4.4.15.11.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Ours + shuffled GloVe</th>
<td id="S4.T1.4.4.4.15.11.2" class="ltx_td ltx_align_center">76.17</td>
<td id="S4.T1.4.4.4.15.11.3" class="ltx_td ltx_align_center">46.53</td>
<td id="S4.T1.4.4.4.15.11.4" class="ltx_td ltx_align_center">60.87</td>
<td id="S4.T1.4.4.4.15.11.5" class="ltx_td"></td>
<td id="S4.T1.4.4.4.15.11.6" class="ltx_td ltx_align_center">71.80</td>
<td id="S4.T1.4.4.4.15.11.7" class="ltx_td ltx_align_center">38.48</td>
<td id="S4.T1.4.4.4.15.11.8" class="ltx_td ltx_align_center">53.78</td>
<td id="S4.T1.4.4.4.15.11.9" class="ltx_td"></td>
<td id="S4.T1.4.4.4.15.11.10" class="ltx_td ltx_align_center">–</td>
<td id="S4.T1.4.4.4.15.11.11" class="ltx_td ltx_align_center">–</td>
<td id="S4.T1.4.4.4.15.11.12" class="ltx_td ltx_nopad_r ltx_align_center">–</td>
</tr>
<tr id="S4.T1.4.4.4.16.12" class="ltx_tr">
<th id="S4.T1.4.4.4.16.12.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Ours + GloVe</th>
<td id="S4.T1.4.4.4.16.12.2" class="ltx_td ltx_align_center"><span id="S4.T1.4.4.4.16.12.2.1" class="ltx_text ltx_font_bold">76.93</span></td>
<td id="S4.T1.4.4.4.16.12.3" class="ltx_td ltx_align_center"><span id="S4.T1.4.4.4.16.12.3.1" class="ltx_text ltx_font_bold">46.99</span></td>
<td id="S4.T1.4.4.4.16.12.4" class="ltx_td ltx_align_center"><span id="S4.T1.4.4.4.16.12.4.1" class="ltx_text ltx_font_bold">61.48</span></td>
<td id="S4.T1.4.4.4.16.12.5" class="ltx_td"></td>
<td id="S4.T1.4.4.4.16.12.6" class="ltx_td ltx_align_center"><span id="S4.T1.4.4.4.16.12.6.1" class="ltx_text ltx_font_bold">72.19</span></td>
<td id="S4.T1.4.4.4.16.12.7" class="ltx_td ltx_align_center"><span id="S4.T1.4.4.4.16.12.7.1" class="ltx_text ltx_font_bold">39.31</span></td>
<td id="S4.T1.4.4.4.16.12.8" class="ltx_td ltx_align_center"><span id="S4.T1.4.4.4.16.12.8.1" class="ltx_text ltx_font_bold">54.40</span></td>
<td id="S4.T1.4.4.4.16.12.9" class="ltx_td"></td>
<td id="S4.T1.4.4.4.16.12.10" class="ltx_td ltx_align_center">71.35</td>
<td id="S4.T1.4.4.4.16.12.11" class="ltx_td ltx_align_center">40.07</td>
<td id="S4.T1.4.4.4.16.12.12" class="ltx_td ltx_nopad_r ltx_align_center">54.73</td>
</tr>
<tr id="S4.T1.3.3.3.3" class="ltx_tr">
<th id="S4.T1.3.3.3.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">Ensemble: 5<math id="S4.T1.3.3.3.3.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.T1.3.3.3.3.1.m1.1a"><mo id="S4.T1.3.3.3.3.1.m1.1.1" xref="S4.T1.3.3.3.3.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.T1.3.3.3.3.1.m1.1b"><times id="S4.T1.3.3.3.3.1.m1.1.1.cmml" xref="S4.T1.3.3.3.3.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.3.3.3.3.1.m1.1c">\times</annotation></semantics></math> Pythia</th>
<td id="S4.T1.3.3.3.3.2" class="ltx_td ltx_align_center ltx_border_t">77.24</td>
<td id="S4.T1.3.3.3.3.3" class="ltx_td ltx_align_center ltx_border_t">48.41</td>
<td id="S4.T1.3.3.3.3.4" class="ltx_td ltx_align_center ltx_border_t">62.36</td>
<td id="S4.T1.3.3.3.3.5" class="ltx_td ltx_border_t"></td>
<td id="S4.T1.3.3.3.3.6" class="ltx_td ltx_align_center ltx_border_t">73.43</td>
<td id="S4.T1.3.3.3.3.7" class="ltx_td ltx_align_center ltx_border_t">39.85</td>
<td id="S4.T1.3.3.3.3.8" class="ltx_td ltx_align_center ltx_border_t">55.26</td>
<td id="S4.T1.3.3.3.3.9" class="ltx_td ltx_border_t"></td>
<td id="S4.T1.3.3.3.3.10" class="ltx_td ltx_align_center ltx_border_t">–</td>
<td id="S4.T1.3.3.3.3.11" class="ltx_td ltx_align_center ltx_border_t">–</td>
<td id="S4.T1.3.3.3.3.12" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">–</td>
</tr>
<tr id="S4.T1.4.4.4.4" class="ltx_tr">
<th id="S4.T1.4.4.4.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb">Ensemble: 5<math id="S4.T1.4.4.4.4.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.T1.4.4.4.4.1.m1.1a"><mo id="S4.T1.4.4.4.4.1.m1.1.1" xref="S4.T1.4.4.4.4.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.T1.4.4.4.4.1.m1.1b"><times id="S4.T1.4.4.4.4.1.m1.1.1.cmml" xref="S4.T1.4.4.4.4.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.4.4.4.4.1.m1.1c">\times</annotation></semantics></math> Ours + GloVe</th>
<td id="S4.T1.4.4.4.4.2" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T1.4.4.4.4.2.1" class="ltx_text ltx_font_bold">79.32</span></td>
<td id="S4.T1.4.4.4.4.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T1.4.4.4.4.3.1" class="ltx_text ltx_font_bold">49.48</span></td>
<td id="S4.T1.4.4.4.4.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T1.4.4.4.4.4.1" class="ltx_text ltx_font_bold">63.92</span></td>
<td id="S4.T1.4.4.4.4.5" class="ltx_td ltx_border_bb"></td>
<td id="S4.T1.4.4.4.4.6" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T1.4.4.4.4.6.1" class="ltx_text ltx_font_bold">74.35</span></td>
<td id="S4.T1.4.4.4.4.7" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T1.4.4.4.4.7.1" class="ltx_text ltx_font_bold">41.40</span></td>
<td id="S4.T1.4.4.4.4.8" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T1.4.4.4.4.8.1" class="ltx_text ltx_font_bold">56.52</span></td>
<td id="S4.T1.4.4.4.4.9" class="ltx_td ltx_border_bb"></td>
<td id="S4.T1.4.4.4.4.10" class="ltx_td ltx_align_center ltx_border_bb">–</td>
<td id="S4.T1.4.4.4.4.11" class="ltx_td ltx_align_center ltx_border_bb">–</td>
<td id="S4.T1.4.4.4.4.12" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb">–</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Accuracy (%) on GQA. Our method shows clear improvements on both binary and open-ended questions.</figcaption>
</figure>
<figure id="S4.T2" class="ltx_table">
<div id="S4.T2.4.4" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:496.9pt;height:214.9pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(19.5pt,-8.4pt) scale(1.08523165443783,1.08523165443783) ;">
<table id="S4.T2.4.4.4" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T2.4.4.4.5.1" class="ltx_tr">
<th id="S4.T2.4.4.4.5.1.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_th ltx_th_row ltx_border_tt" style="padding-left:0.0pt;padding-right:0.0pt;"></th>
<td id="S4.T2.4.4.4.5.1.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_tt" style="padding-left:0.0pt;padding-right:0.0pt;" colspan="10">GQA test-dev</td>
</tr>
<tr id="S4.T2.4.4.4.6.2" class="ltx_tr">
<th id="S4.T2.4.4.4.6.2.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_th ltx_th_row" style="padding-left:0.0pt;padding-right:0.0pt;"></th>
<td id="S4.T2.4.4.4.6.2.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">Choose</td>
<td id="S4.T2.4.4.4.6.2.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">Compare</td>
<td id="S4.T2.4.4.4.6.2.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">Logical</td>
<td id="S4.T2.4.4.4.6.2.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">Query</td>
<td id="S4.T2.4.4.4.6.2.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">Verify</td>
<td id="S4.T2.4.4.4.6.2.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">Attribute</td>
<td id="S4.T2.4.4.4.6.2.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">Category</td>
<td id="S4.T2.4.4.4.6.2.9" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">Global</td>
<td id="S4.T2.4.4.4.6.2.10" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">Object</td>
<td id="S4.T2.4.4.4.6.2.11" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">Relation</td>
</tr>
<tr id="S4.T2.4.4.4.7.3" class="ltx_tr">
<th id="S4.T2.4.4.4.7.3.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">Pythia</th>
<td id="S4.T2.4.4.4.7.3.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">67.93</td>
<td id="S4.T2.4.4.4.7.3.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">62.14</td>
<td id="S4.T2.4.4.4.7.3.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S4.T2.4.4.4.7.3.4.1" class="ltx_text ltx_font_bold">72.11</span></td>
<td id="S4.T2.4.4.4.7.3.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">38.15</td>
<td id="S4.T2.4.4.4.7.3.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">75.28</td>
<td id="S4.T2.4.4.4.7.3.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">60.04</td>
<td id="S4.T2.4.4.4.7.3.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">45.59</td>
<td id="S4.T2.4.4.4.7.3.9" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">51.85</td>
<td id="S4.T2.4.4.4.7.3.10" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">84.53</td>
<td id="S4.T2.4.4.4.7.3.11" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">44.24</td>
</tr>
<tr id="S4.T2.4.4.4.8.4" class="ltx_tr">
<th id="S4.T2.4.4.4.8.4.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row" style="padding-left:0.0pt;padding-right:0.0pt;">Pythia + GloVe</th>
<td id="S4.T2.4.4.4.8.4.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">68.45</td>
<td id="S4.T2.4.4.4.8.4.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S4.T2.4.4.4.8.4.3.1" class="ltx_text ltx_font_bold">62.72</span></td>
<td id="S4.T2.4.4.4.8.4.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">71.69</td>
<td id="S4.T2.4.4.4.8.4.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">37.94</td>
<td id="S4.T2.4.4.4.8.4.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">74.81</td>
<td id="S4.T2.4.4.4.8.4.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">59.40</td>
<td id="S4.T2.4.4.4.8.4.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">44.72</td>
<td id="S4.T2.4.4.4.8.4.9" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">54.14</td>
<td id="S4.T2.4.4.4.8.4.10" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">84.78</td>
<td id="S4.T2.4.4.4.8.4.11" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">44.51</td>
</tr>
<tr id="S4.T2.1.1.1.1" class="ltx_tr">
<th id="S4.T2.1.1.1.1.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row" style="padding-left:0.0pt;padding-right:0.0pt;">fPMC(BUTD<math id="S4.T2.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\star" display="inline"><semantics id="S4.T2.1.1.1.1.1.m1.1a"><mo id="S4.T2.1.1.1.1.1.m1.1.1" xref="S4.T2.1.1.1.1.1.m1.1.1.cmml">⋆</mo><annotation-xml encoding="MathML-Content" id="S4.T2.1.1.1.1.1.m1.1b"><ci id="S4.T2.1.1.1.1.1.m1.1.1.cmml" xref="S4.T2.1.1.1.1.1.m1.1.1">⋆</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.1.1.1.1.1.m1.1c">\star</annotation></semantics></math>)</th>
<td id="S4.T2.1.1.1.1.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">60.39</td>
<td id="S4.T2.1.1.1.1.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">57.83</td>
<td id="S4.T2.1.1.1.1.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">63.36</td>
<td id="S4.T2.1.1.1.1.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">35.40</td>
<td id="S4.T2.1.1.1.1.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">69.99</td>
<td id="S4.T2.1.1.1.1.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">51.17</td>
<td id="S4.T2.1.1.1.1.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">42.90</td>
<td id="S4.T2.1.1.1.1.9" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">51.97</td>
<td id="S4.T2.1.1.1.1.10" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">81.95</td>
<td id="S4.T2.1.1.1.1.11" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">43.04</td>
</tr>
<tr id="S4.T2.2.2.2.2" class="ltx_tr">
<th id="S4.T2.2.2.2.2.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row" style="padding-left:0.0pt;padding-right:0.0pt;">fPMC(SAN<math id="S4.T2.2.2.2.2.1.m1.1" class="ltx_Math" alttext="\star" display="inline"><semantics id="S4.T2.2.2.2.2.1.m1.1a"><mo id="S4.T2.2.2.2.2.1.m1.1.1" xref="S4.T2.2.2.2.2.1.m1.1.1.cmml">⋆</mo><annotation-xml encoding="MathML-Content" id="S4.T2.2.2.2.2.1.m1.1b"><ci id="S4.T2.2.2.2.2.1.m1.1.1.cmml" xref="S4.T2.2.2.2.2.1.m1.1.1">⋆</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.2.2.2.2.1.m1.1c">\star</annotation></semantics></math>)</th>
<td id="S4.T2.2.2.2.2.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">64.80</td>
<td id="S4.T2.2.2.2.2.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">61.53</td>
<td id="S4.T2.2.2.2.2.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">65.62</td>
<td id="S4.T2.2.2.2.2.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">35.83</td>
<td id="S4.T2.2.2.2.2.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">70.69</td>
<td id="S4.T2.2.2.2.2.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">53.80</td>
<td id="S4.T2.2.2.2.2.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">43.69</td>
<td id="S4.T2.2.2.2.2.9" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">54.01</td>
<td id="S4.T2.2.2.2.2.10" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">80.95</td>
<td id="S4.T2.2.2.2.2.11" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">43.32</td>
</tr>
<tr id="S4.T2.4.4.4.9.5" class="ltx_tr">
<th id="S4.T2.4.4.4.9.5.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row" style="padding-left:0.0pt;padding-right:0.0pt;">Ours + random</th>
<td id="S4.T2.4.4.4.9.5.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">67.42</td>
<td id="S4.T2.4.4.4.9.5.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">62.07</td>
<td id="S4.T2.4.4.4.9.5.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">70.87</td>
<td id="S4.T2.4.4.4.9.5.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">38.14</td>
<td id="S4.T2.4.4.4.9.5.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">74.40</td>
<td id="S4.T2.4.4.4.9.5.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">58.53</td>
<td id="S4.T2.4.4.4.9.5.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">45.01</td>
<td id="S4.T2.4.4.4.9.5.9" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S4.T2.4.4.4.9.5.9.1" class="ltx_text ltx_font_bold">55.42</span></td>
<td id="S4.T2.4.4.4.9.5.10" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">84.68</td>
<td id="S4.T2.4.4.4.9.5.11" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">44.79</td>
</tr>
<tr id="S4.T2.4.4.4.10.6" class="ltx_tr">
<th id="S4.T2.4.4.4.10.6.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row" style="padding-left:0.0pt;padding-right:0.0pt;">Ours + shuffled GloVe</th>
<td id="S4.T2.4.4.4.10.6.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">70.88</td>
<td id="S4.T2.4.4.4.10.6.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">62.14</td>
<td id="S4.T2.4.4.4.10.6.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">71.38</td>
<td id="S4.T2.4.4.4.10.6.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">38.48</td>
<td id="S4.T2.4.4.4.10.6.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">75.14</td>
<td id="S4.T2.4.4.4.10.6.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">59.65</td>
<td id="S4.T2.4.4.4.10.6.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">45.36</td>
<td id="S4.T2.4.4.4.10.6.9" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">54.14</td>
<td id="S4.T2.4.4.4.10.6.10" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">84.60</td>
<td id="S4.T2.4.4.4.10.6.11" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">45.33</td>
</tr>
<tr id="S4.T2.4.4.4.11.7" class="ltx_tr">
<th id="S4.T2.4.4.4.11.7.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row" style="padding-left:0.0pt;padding-right:0.0pt;">Ours + GloVe</th>
<td id="S4.T2.4.4.4.11.7.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S4.T2.4.4.4.11.7.2.1" class="ltx_text ltx_font_bold">71.12</span></td>
<td id="S4.T2.4.4.4.11.7.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">62.21</td>
<td id="S4.T2.4.4.4.11.7.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">71.14</td>
<td id="S4.T2.4.4.4.11.7.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S4.T2.4.4.4.11.7.5.1" class="ltx_text ltx_font_bold">39.31</span></td>
<td id="S4.T2.4.4.4.11.7.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S4.T2.4.4.4.11.7.6.1" class="ltx_text ltx_font_bold">76.17</span></td>
<td id="S4.T2.4.4.4.11.7.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S4.T2.4.4.4.11.7.7.1" class="ltx_text ltx_font_bold">60.28</span></td>
<td id="S4.T2.4.4.4.11.7.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S4.T2.4.4.4.11.7.8.1" class="ltx_text ltx_font_bold">46.04</span></td>
<td id="S4.T2.4.4.4.11.7.9" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">53.88</td>
<td id="S4.T2.4.4.4.11.7.10" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S4.T2.4.4.4.11.7.10.1" class="ltx_text ltx_font_bold">85.01</span></td>
<td id="S4.T2.4.4.4.11.7.11" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S4.T2.4.4.4.11.7.11.1" class="ltx_text ltx_font_bold">46.01</span></td>
</tr>
<tr id="S4.T2.3.3.3.3" class="ltx_tr">
<th id="S4.T2.3.3.3.3.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">Ensemble: 5<math id="S4.T2.3.3.3.3.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.T2.3.3.3.3.1.m1.1a"><mo id="S4.T2.3.3.3.3.1.m1.1.1" xref="S4.T2.3.3.3.3.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.T2.3.3.3.3.1.m1.1b"><times id="S4.T2.3.3.3.3.1.m1.1.1.cmml" xref="S4.T2.3.3.3.3.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.3.3.3.3.1.m1.1c">\times</annotation></semantics></math> Pythia</th>
<td id="S4.T2.3.3.3.3.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">70.95</td>
<td id="S4.T2.3.3.3.3.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">63.33</td>
<td id="S4.T2.3.3.3.3.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S4.T2.3.3.3.3.4.1" class="ltx_text ltx_font_bold">73.54</span></td>
<td id="S4.T2.3.3.3.3.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">39.85</td>
<td id="S4.T2.3.3.3.3.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">77.22</td>
<td id="S4.T2.3.3.3.3.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">61.84</td>
<td id="S4.T2.3.3.3.3.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">47.87</td>
<td id="S4.T2.3.3.3.3.9" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">52.23</td>
<td id="S4.T2.3.3.3.3.10" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S4.T2.3.3.3.3.10.1" class="ltx_text ltx_font_bold">86.50</span></td>
<td id="S4.T2.3.3.3.3.11" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">45.95</td>
</tr>
<tr id="S4.T2.4.4.4.4" class="ltx_tr">
<th id="S4.T2.4.4.4.4.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row ltx_border_bb" style="padding-left:0.0pt;padding-right:0.0pt;">Ensemble: 5<math id="S4.T2.4.4.4.4.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.T2.4.4.4.4.1.m1.1a"><mo id="S4.T2.4.4.4.4.1.m1.1.1" xref="S4.T2.4.4.4.4.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.T2.4.4.4.4.1.m1.1b"><times id="S4.T2.4.4.4.4.1.m1.1.1.cmml" xref="S4.T2.4.4.4.4.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.4.4.4.4.1.m1.1c">\times</annotation></semantics></math> Ours + GloVe</th>
<td id="S4.T2.4.4.4.4.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S4.T2.4.4.4.4.2.1" class="ltx_text ltx_font_bold">75.11</span></td>
<td id="S4.T2.4.4.4.4.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S4.T2.4.4.4.4.3.1" class="ltx_text ltx_font_bold">64.18</span></td>
<td id="S4.T2.4.4.4.4.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:0.0pt;padding-right:0.0pt;">73.04</td>
<td id="S4.T2.4.4.4.4.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S4.T2.4.4.4.4.5.1" class="ltx_text ltx_font_bold">41.40</span></td>
<td id="S4.T2.4.4.4.4.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S4.T2.4.4.4.4.6.1" class="ltx_text ltx_font_bold">77.66</span></td>
<td id="S4.T2.4.4.4.4.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S4.T2.4.4.4.4.7.1" class="ltx_text ltx_font_bold">63.00</span></td>
<td id="S4.T2.4.4.4.4.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S4.T2.4.4.4.4.8.1" class="ltx_text ltx_font_bold">48.30</span></td>
<td id="S4.T2.4.4.4.4.9" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S4.T2.4.4.4.4.9.1" class="ltx_text ltx_font_bold">53.50</span></td>
<td id="S4.T2.4.4.4.4.10" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:0.0pt;padding-right:0.0pt;">86.25</td>
<td id="S4.T2.4.4.4.4.11" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S4.T2.4.4.4.4.11.1" class="ltx_text ltx_font_bold">47.70</span></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Accuracy (%) over question types on GQA test-dev. Our contributions bring clear improvements on most question types, with the highest gain on the <span id="S4.T2.6.1" class="ltx_text ltx_font_italic">choose</span> category.</figcaption>
</figure>
<div id="S4.p4" class="ltx_para">
<p id="S4.p4.1" class="ltx_p">For evaluation of our approach we use the GQA dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite> as it provides the most comprehensive suite of metrics and cleanest data of current VQA datasets. However, we do not aim to build a data-specific solution, so our model does not utilize scene graphs and functional programs included in the dataset.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Quantitative Results</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">Our main results on the GQA dataset are provided in Table <a href="#S4.T1" title="Table 1 ‣ 4 Experiments ‣ Visual Question Answering with Prior Class Semantics" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. Looking at the overall accuracy, our model clearly outperforms all baselines and ablations. The same observations can be drawn on both the binary and open-ended questions. The trend is also confirmed when evaluating an ensemble of our model, versus a similar ensemble of the Pythia baseline. The fPMC model <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite> obtains the lowest results, including our modified version fPMC(BUTD<math id="S4.SS1.p1.1.m1.1" class="ltx_Math" alttext="\star" display="inline"><semantics id="S4.SS1.p1.1.m1.1a"><mo id="S4.SS1.p1.1.m1.1.1" xref="S4.SS1.p1.1.m1.1.1.cmml">⋆</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.1.m1.1b"><ci id="S4.SS1.p1.1.m1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1">⋆</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.1.m1.1c">\star</annotation></semantics></math>) (details in Appendix <span class="ltx_ref ltx_nolink ltx_ref_self"><span class="ltx_text ltx_ref_tag">A</span></span>), which indicates its lack of adaptivity to complex feature representation methods. The fPMC model was initially tested only on the very noisy VQA v2 dataset, and a possible reason for its weak performance on GQA is the narrower answer set. A surprising outcome is that Pythia with pretrained classifier (‘Pythia+GloVe’) shows worse accuracy results than the baseline. This occurs mostly due to overfitting of the pre-initialized classifier to the most common answers in the training set, as observed by the reduced accuracy on both the validation (see Table <span class="ltx_ref ltx_nolink ltx_ref_self"><span class="ltx_text ltx_ref_tag">5</span></span> in Appendix <span class="ltx_ref ltx_nolink ltx_ref_self"><span class="ltx_text ltx_ref_tag">D</span></span>) and test-dev sets. Unlike the other described architectures, our model exploits the additional information contained in the representations of answers in an effective way, increasing performance without overfitting.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Comparison with Existing Models</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">We compare our model with existing methods reported in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite> and several recent state-of-the-art (see Table <a href="#S4.T1" title="Table 1 ‣ 4 Experiments ‣ Visual Question Answering with Prior Class Semantics" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>). We report the performance of the blind LSTM, the bottom-up top-down attention model <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>, MAC <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>, LXMERT <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite> and the neural state machine (NSM) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>. Our model shows better results than all the baselines, and in spite of a much simpler architecture, it notably surpasses the MAC model. However, the newest methods LXMERT and NSM show higher performance which is not surprising. LXMERT model explores more sophisticated technique of image and language representation and is pretrained on a significantly larger amount of data. NSM implements compositional approach and performs explicit multi-step reasoning. Differently, our approach focuses on the output stage of VQA model, thus the contributions of this article are expected to be applicable to these models.</p>
</div>
<figure id="S4.T3" class="ltx_table">
<div id="S4.T3.4.4" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:216.8pt;height:161.2pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-24.7pt,18.4pt) scale(0.814181019740116,0.814181019740116) ;">
<table id="S4.T3.4.4.4" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T3.4.4.4.5.1" class="ltx_tr">
<th id="S4.T3.4.4.4.5.1.1" class="ltx_td ltx_th ltx_th_row ltx_border_tt"></th>
<td id="S4.T3.4.4.4.5.1.2" class="ltx_td ltx_align_center ltx_border_tt" colspan="4">GQA validation</td>
</tr>
<tr id="S4.T3.4.4.4.6.2" class="ltx_tr">
<th id="S4.T3.4.4.4.6.2.1" class="ltx_td ltx_th ltx_th_row"></th>
<td id="S4.T3.4.4.4.6.2.2" class="ltx_td ltx_align_center ltx_border_t">V</td>
<td id="S4.T3.4.4.4.6.2.3" class="ltx_td ltx_align_center ltx_border_t">P</td>
<td id="S4.T3.4.4.4.6.2.4" class="ltx_td ltx_align_center ltx_border_t">D</td>
<td id="S4.T3.4.4.4.6.2.5" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">C</td>
</tr>
<tr id="S4.T3.4.4.4.7.3" class="ltx_tr">
<th id="S4.T3.4.4.4.7.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">Pythia</th>
<td id="S4.T3.4.4.4.7.3.2" class="ltx_td ltx_align_center ltx_border_t">95.07</td>
<td id="S4.T3.4.4.4.7.3.3" class="ltx_td ltx_align_center ltx_border_t">91.39</td>
<td id="S4.T3.4.4.4.7.3.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T3.4.4.4.7.3.4.1" class="ltx_text ltx_font_bold">3.93</span></td>
<td id="S4.T3.4.4.4.7.3.5" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">83.12</td>
</tr>
<tr id="S4.T3.4.4.4.8.4" class="ltx_tr">
<th id="S4.T3.4.4.4.8.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Pythia + GloVe</th>
<td id="S4.T3.4.4.4.8.4.2" class="ltx_td ltx_align_center">95.13</td>
<td id="S4.T3.4.4.4.8.4.3" class="ltx_td ltx_align_center">91.40</td>
<td id="S4.T3.4.4.4.8.4.4" class="ltx_td ltx_align_center">4.07</td>
<td id="S4.T3.4.4.4.8.4.5" class="ltx_td ltx_nopad_r ltx_align_center">82.68</td>
</tr>
<tr id="S4.T3.1.1.1.1" class="ltx_tr">
<th id="S4.T3.1.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">fPMC(BUTD<math id="S4.T3.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\star" display="inline"><semantics id="S4.T3.1.1.1.1.1.m1.1a"><mo id="S4.T3.1.1.1.1.1.m1.1.1" xref="S4.T3.1.1.1.1.1.m1.1.1.cmml">⋆</mo><annotation-xml encoding="MathML-Content" id="S4.T3.1.1.1.1.1.m1.1b"><ci id="S4.T3.1.1.1.1.1.m1.1.1.cmml" xref="S4.T3.1.1.1.1.1.m1.1.1">⋆</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.1.1.1.1.1.m1.1c">\star</annotation></semantics></math>)</th>
<td id="S4.T3.1.1.1.1.2" class="ltx_td ltx_align_center">94.99</td>
<td id="S4.T3.1.1.1.1.3" class="ltx_td ltx_align_center">90.91</td>
<td id="S4.T3.1.1.1.1.4" class="ltx_td ltx_align_center">6.20</td>
<td id="S4.T3.1.1.1.1.5" class="ltx_td ltx_nopad_r ltx_align_center">76.53</td>
</tr>
<tr id="S4.T3.2.2.2.2" class="ltx_tr">
<th id="S4.T3.2.2.2.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">fPMC(SAN<math id="S4.T3.2.2.2.2.1.m1.1" class="ltx_Math" alttext="\star" display="inline"><semantics id="S4.T3.2.2.2.2.1.m1.1a"><mo id="S4.T3.2.2.2.2.1.m1.1.1" xref="S4.T3.2.2.2.2.1.m1.1.1.cmml">⋆</mo><annotation-xml encoding="MathML-Content" id="S4.T3.2.2.2.2.1.m1.1b"><ci id="S4.T3.2.2.2.2.1.m1.1.1.cmml" xref="S4.T3.2.2.2.2.1.m1.1.1">⋆</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.2.2.2.2.1.m1.1c">\star</annotation></semantics></math>)</th>
<td id="S4.T3.2.2.2.2.2" class="ltx_td ltx_align_center">95.11</td>
<td id="S4.T3.2.2.2.2.3" class="ltx_td ltx_align_center"><span id="S4.T3.2.2.2.2.3.1" class="ltx_text ltx_font_bold">91.62</span></td>
<td id="S4.T3.2.2.2.2.4" class="ltx_td ltx_align_center">5.66</td>
<td id="S4.T3.2.2.2.2.5" class="ltx_td ltx_nopad_r ltx_align_center">78.67</td>
</tr>
<tr id="S4.T3.4.4.4.9.5" class="ltx_tr">
<th id="S4.T3.4.4.4.9.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Ours + random</th>
<td id="S4.T3.4.4.4.9.5.2" class="ltx_td ltx_align_center">95.07</td>
<td id="S4.T3.4.4.4.9.5.3" class="ltx_td ltx_align_center">91.53</td>
<td id="S4.T3.4.4.4.9.5.4" class="ltx_td ltx_align_center">4.26</td>
<td id="S4.T3.4.4.4.9.5.5" class="ltx_td ltx_nopad_r ltx_align_center">83.00</td>
</tr>
<tr id="S4.T3.4.4.4.10.6" class="ltx_tr">
<th id="S4.T3.4.4.4.10.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Ours + shuffled GloVe</th>
<td id="S4.T3.4.4.4.10.6.2" class="ltx_td ltx_align_center">95.14</td>
<td id="S4.T3.4.4.4.10.6.3" class="ltx_td ltx_align_center">91.48</td>
<td id="S4.T3.4.4.4.10.6.4" class="ltx_td ltx_align_center">4.01</td>
<td id="S4.T3.4.4.4.10.6.5" class="ltx_td ltx_nopad_r ltx_align_center">83.37</td>
</tr>
<tr id="S4.T3.4.4.4.11.7" class="ltx_tr">
<th id="S4.T3.4.4.4.11.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Ours + GloVe</th>
<td id="S4.T3.4.4.4.11.7.2" class="ltx_td ltx_align_center"><span id="S4.T3.4.4.4.11.7.2.1" class="ltx_text ltx_font_bold">95.16</span></td>
<td id="S4.T3.4.4.4.11.7.3" class="ltx_td ltx_align_center">91.55</td>
<td id="S4.T3.4.4.4.11.7.4" class="ltx_td ltx_align_center">4.01</td>
<td id="S4.T3.4.4.4.11.7.5" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T3.4.4.4.11.7.5.1" class="ltx_text ltx_font_bold">84.57</span></td>
</tr>
<tr id="S4.T3.3.3.3.3" class="ltx_tr">
<th id="S4.T3.3.3.3.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">Ensemble: 5<math id="S4.T3.3.3.3.3.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.T3.3.3.3.3.1.m1.1a"><mo id="S4.T3.3.3.3.3.1.m1.1.1" xref="S4.T3.3.3.3.3.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.T3.3.3.3.3.1.m1.1b"><times id="S4.T3.3.3.3.3.1.m1.1.1.cmml" xref="S4.T3.3.3.3.3.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.3.3.3.3.1.m1.1c">\times</annotation></semantics></math> Pythia</th>
<td id="S4.T3.3.3.3.3.2" class="ltx_td ltx_align_center ltx_border_t">95.17</td>
<td id="S4.T3.3.3.3.3.3" class="ltx_td ltx_align_center ltx_border_t">91.90</td>
<td id="S4.T3.3.3.3.3.4" class="ltx_td ltx_align_center ltx_border_t">4.78</td>
<td id="S4.T3.3.3.3.3.5" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">85.27</td>
</tr>
<tr id="S4.T3.4.4.4.4" class="ltx_tr">
<th id="S4.T3.4.4.4.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb">Ensemble: 5<math id="S4.T3.4.4.4.4.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.T3.4.4.4.4.1.m1.1a"><mo id="S4.T3.4.4.4.4.1.m1.1.1" xref="S4.T3.4.4.4.4.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.T3.4.4.4.4.1.m1.1b"><times id="S4.T3.4.4.4.4.1.m1.1.1.cmml" xref="S4.T3.4.4.4.4.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.4.4.4.4.1.m1.1c">\times</annotation></semantics></math> Ours + GloVe</th>
<td id="S4.T3.4.4.4.4.2" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T3.4.4.4.4.2.1" class="ltx_text ltx_font_bold">95.25</span></td>
<td id="S4.T3.4.4.4.4.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T3.4.4.4.4.3.1" class="ltx_text ltx_font_bold">92.06</span></td>
<td id="S4.T3.4.4.4.4.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T3.4.4.4.4.4.1" class="ltx_text ltx_font_bold">4.56</span></td>
<td id="S4.T3.4.4.4.4.5" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb"><span id="S4.T3.4.4.4.4.5.1" class="ltx_text ltx_font_bold">87.33</span></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>Results on additional metrics: <span id="S4.T3.9.1" class="ltx_text ltx_framed ltx_framed_underline">V</span>alidity, <span id="S4.T3.10.2" class="ltx_text ltx_framed ltx_framed_underline">P</span>lausibility, <span id="S4.T3.11.3" class="ltx_text ltx_framed ltx_framed_underline">D</span>istribution (lower is better), and <span id="S4.T3.12.4" class="ltx_text ltx_framed ltx_framed_underline">C</span>onsistency. Our model noticeably improves in consistency over the baseline. It ranks slightly worse on the distribution metric (see discussion in text).</figcaption>
</figure>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>In-Depth Analysis</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">We report the detailed metrics of the GQA dataset in Table <a href="#S4.T3" title="Table 3 ‣ 4.2 Comparison with Existing Models ‣ 4 Experiments ‣ Visual Question Answering with Prior Class Semantics" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>. The first observation is that a similar ranking of methods and ablations can be drawn from most of the metrics. This stability further confirms the benefits of the proposed method. The improvements on these advanced metrics also indicate benefits beyond the sole increase in accuracy. The <span id="S4.SS3.p1.1.1" class="ltx_text ltx_font_italic">validity</span> and <span id="S4.SS3.p1.1.2" class="ltx_text ltx_font_italic">plausibility</span> scores, in particular, which are noticeably higher, indicate a generally more robust model. The higher <span id="S4.SS3.p1.1.3" class="ltx_text ltx_font_italic">consistency</span> score implies that the answers produced over related questions are compatible with one another (see Fig. <a href="#S4.F5" title="Figure 5 ‣ 4.3 In-Depth Analysis ‣ 4 Experiments ‣ Visual Question Answering with Prior Class Semantics" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>). The only metric on which our model falls below the baseline is the <span id="S4.SS3.p1.1.4" class="ltx_text ltx_font_italic">answer distribution</span>. It indicates that the model occasionally favors one answer over most others. We explain this by the fact that some answers are not assigned appropriate initial representations (see the rest of the discussion below). We also look at the accuracy metric broken down by question categories (Table <a href="#S4.T2" title="Table 2 ‣ 4 Experiments ‣ Visual Question Answering with Prior Class Semantics" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>). We observe no significant drop in accuracy for any type, and the highest improvements occur on the <span id="S4.SS3.p1.1.5" class="ltx_text ltx_font_italic">choose</span>, <span id="S4.SS3.p1.1.6" class="ltx_text ltx_font_italic">query</span>, <span id="S4.SS3.p1.1.7" class="ltx_text ltx_font_italic">attribute</span>, and <span id="S4.SS3.p1.1.8" class="ltx_text ltx_font_italic">relational</span> questions.</p>
</div>
<figure id="S4.F3" class="ltx_figure"><img src="/html/2005.01239/assets/x3.png" id="S4.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="415" height="245" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>The performance of our model varies smoothly with the relative weight of the classification and regression losses (Eq.  <a href="#S3.E4" title="In Regression loss. ‣ 3.2 Training ‣ 3 Proposed Approach ‣ Visual Question Answering with Prior Class Semantics" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>). The value <math id="S4.F3.5.m1.1" class="ltx_Math" alttext="\lambda" display="inline"><semantics id="S4.F3.5.m1.1b"><mi id="S4.F3.5.m1.1.1" xref="S4.F3.5.m1.1.1.cmml">λ</mi><annotation-xml encoding="MathML-Content" id="S4.F3.5.m1.1c"><ci id="S4.F3.5.m1.1.1.cmml" xref="S4.F3.5.m1.1.1">𝜆</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.F3.5.m1.1d">\lambda</annotation></semantics></math>=<math id="S4.F3.6.m2.1" class="ltx_Math" alttext="1" display="inline"><semantics id="S4.F3.6.m2.1b"><mn id="S4.F3.6.m2.1.1" xref="S4.F3.6.m2.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="S4.F3.6.m2.1c"><cn type="integer" id="S4.F3.6.m2.1.1.cmml" xref="S4.F3.6.m2.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.F3.6.m2.1d">1</annotation></semantics></math> corresponds to a traditional classification-only baseline, while the optimal value <math id="S4.F3.7.m3.1" class="ltx_Math" alttext="\lambda" display="inline"><semantics id="S4.F3.7.m3.1b"><mi id="S4.F3.7.m3.1.1" xref="S4.F3.7.m3.1.1.cmml">λ</mi><annotation-xml encoding="MathML-Content" id="S4.F3.7.m3.1c"><ci id="S4.F3.7.m3.1.1.cmml" xref="S4.F3.7.m3.1.1">𝜆</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.F3.7.m3.1d">\lambda</annotation></semantics></math>=<math id="S4.F3.8.m4.1" class="ltx_Math" alttext="0.5" display="inline"><semantics id="S4.F3.8.m4.1b"><mn id="S4.F3.8.m4.1.1" xref="S4.F3.8.m4.1.1.cmml">0.5</mn><annotation-xml encoding="MathML-Content" id="S4.F3.8.m4.1c"><cn type="float" id="S4.F3.8.m4.1.1.cmml" xref="S4.F3.8.m4.1.1">0.5</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.F3.8.m4.1d">0.5</annotation></semantics></math> corresponds to an even contribution of the two losses.</figcaption>
</figure>
<div id="S4.SS3.p2" class="ltx_para">
<p id="S4.SS3.p2.2" class="ltx_p">The ablations of our method (<span id="S4.SS3.p2.2.1" class="ltx_text ltx_font_italic">Ours+random</span> and <span id="S4.SS3.p2.2.2" class="ltx_text ltx_font_italic">Ours+shuffled GloVe</span>) are important to determine whether the source of improvements is in the architecture of our model (the additional output branch and loss), in numerical effects from the initialization of the matrix <math id="S4.SS3.p2.1.m1.1" class="ltx_Math" alttext="M" display="inline"><semantics id="S4.SS3.p2.1.m1.1a"><mi id="S4.SS3.p2.1.m1.1.1" xref="S4.SS3.p2.1.m1.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.1.m1.1b"><ci id="S4.SS3.p2.1.m1.1.1.cmml" xref="S4.SS3.p2.1.m1.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.1.m1.1c">M</annotation></semantics></math> with values from GloVe vectors, or in the actual information conveyed in the GloVe vectors. The ablation with random initial values is essentially similar to the Pythia baseline, which shows no significant effect from the architecture alone. Surprisingly, the <span id="S4.SS3.p2.2.3" class="ltx_text ltx_font_italic">shuffled GloVe</span> ablation brings some improvement, which we explain by two factors. First, since the values of <math id="S4.SS3.p2.2.m2.1" class="ltx_Math" alttext="M" display="inline"><semantics id="S4.SS3.p2.2.m2.1a"><mi id="S4.SS3.p2.2.m2.1.1" xref="S4.SS3.p2.2.m2.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.2.m2.1b"><ci id="S4.SS3.p2.2.m2.1.1.cmml" xref="S4.SS3.p2.2.m2.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.2.m2.1c">M</annotation></semantics></math> are further fine-tuned with the rest of model, they can still incorporate useful information from the task-specific supervision even if the initial values do not contain relevant semantic information. Second, some answers may actually benefit from the “wrong” initialization: we have determined that the absolute values of the representations of answers do not play the most significant role, but that their mutual relations are what encodes the critical information. This shows up in particular with pairs of antonym answers such as <span id="S4.SS3.p2.2.4" class="ltx_text ltx_font_italic">yes</span>/<span id="S4.SS3.p2.2.5" class="ltx_text ltx_font_italic">no</span> or <span id="S4.SS3.p2.2.6" class="ltx_text ltx_font_italic">left</span>/<span id="S4.SS3.p2.2.7" class="ltx_text ltx_font_italic">right</span>. The GloVe embeddings of these pairs are usually similar, whereas the VQA task-specific supervision tends to push their representations apart. The <span id="S4.SS3.p2.2.8" class="ltx_text ltx_font_italic">shuffled</span> initialization can thus prove better than the “correct” one for some cases. This can also be observed on the high accuracy of the <span id="S4.SS3.p2.2.9" class="ltx_text ltx_font_italic">shuffled</span> ablation on the <span id="S4.SS3.p2.2.10" class="ltx_text ltx_font_italic">choose</span> category of questions which do specifically contain this type of antonym answers (see Table <a href="#A3.T4" title="Table 4 ‣ GQA ‣ Appendix C Datasets ‣ Visual Question Answering with Prior Class Semantics" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>). Despite these effects, the full model still performs clearly better than the ablations, indicating an overall benefit from the information conveyed in the GloVe representations of answers.</p>
</div>
<div id="S4.SS3.p3" class="ltx_para">
<p id="S4.SS3.p3.6" class="ltx_p">Since our architecture is trained to minimize a sum of two losses (classification and regression), we sought to evaluate their possible mutual benefit by varying their relative weight (<math id="S4.SS3.p3.1.m1.1" class="ltx_Math" alttext="\lambda" display="inline"><semantics id="S4.SS3.p3.1.m1.1a"><mi id="S4.SS3.p3.1.m1.1.1" xref="S4.SS3.p3.1.m1.1.1.cmml">λ</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.1.m1.1b"><ci id="S4.SS3.p3.1.m1.1.1.cmml" xref="S4.SS3.p3.1.m1.1.1">𝜆</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.1.m1.1c">\lambda</annotation></semantics></math> in Eq. <a href="#S3.E4" title="In Regression loss. ‣ 3.2 Training ‣ 3 Proposed Approach ‣ Visual Question Answering with Prior Class Semantics" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>). A Value of <math id="S4.SS3.p3.2.m2.1" class="ltx_Math" alttext="\lambda" display="inline"><semantics id="S4.SS3.p3.2.m2.1a"><mi id="S4.SS3.p3.2.m2.1.1" xref="S4.SS3.p3.2.m2.1.1.cmml">λ</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.2.m2.1b"><ci id="S4.SS3.p3.2.m2.1.1.cmml" xref="S4.SS3.p3.2.m2.1.1">𝜆</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.2.m2.1c">\lambda</annotation></semantics></math>=<math id="S4.SS3.p3.3.m3.1" class="ltx_Math" alttext="0" display="inline"><semantics id="S4.SS3.p3.3.m3.1a"><mn id="S4.SS3.p3.3.m3.1.1" xref="S4.SS3.p3.3.m3.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.3.m3.1b"><cn type="integer" id="S4.SS3.p3.3.m3.1.1.cmml" xref="S4.SS3.p3.3.m3.1.1">0</cn></annotation-xml></semantics></math> corresponds to the regression loss alone, and <math id="S4.SS3.p3.4.m4.1" class="ltx_Math" alttext="\lambda" display="inline"><semantics id="S4.SS3.p3.4.m4.1a"><mi id="S4.SS3.p3.4.m4.1.1" xref="S4.SS3.p3.4.m4.1.1.cmml">λ</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.4.m4.1b"><ci id="S4.SS3.p3.4.m4.1.1.cmml" xref="S4.SS3.p3.4.m4.1.1">𝜆</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.4.m4.1c">\lambda</annotation></semantics></math>=<math id="S4.SS3.p3.5.m5.1" class="ltx_Math" alttext="1" display="inline"><semantics id="S4.SS3.p3.5.m5.1a"><mn id="S4.SS3.p3.5.m5.1.1" xref="S4.SS3.p3.5.m5.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.5.m5.1b"><cn type="integer" id="S4.SS3.p3.5.m5.1.1.cmml" xref="S4.SS3.p3.5.m5.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.5.m5.1c">1</annotation></semantics></math> to the baseline using the traditional classification loss alone. Interestingly, a balanced value of <math id="S4.SS3.p3.6.m6.1" class="ltx_Math" alttext="0.5" display="inline"><semantics id="S4.SS3.p3.6.m6.1a"><mn id="S4.SS3.p3.6.m6.1.1" xref="S4.SS3.p3.6.m6.1.1.cmml">0.5</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.6.m6.1b"><cn type="float" id="S4.SS3.p3.6.m6.1.1.cmml" xref="S4.SS3.p3.6.m6.1.1">0.5</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.6.m6.1c">0.5</annotation></semantics></math> leads to the highest accuracy (Fig. <a href="#S4.F3" title="Figure 3 ‣ 4.3 In-Depth Analysis ‣ 4 Experiments ‣ Visual Question Answering with Prior Class Semantics" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>), demonstrating that they are indeed complementary.</p>
</div>
<figure id="S4.F4" class="ltx_figure"><img src="/html/2005.01239/assets/x4.png" id="S4.F4.g1" class="ltx_graphics ltx_centering ltx_img_portrait" width="461" height="627" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Absolute gain in answer recall of our model over the Pythia baseline (positive is an improvement). We report an even subset of answers (every <math id="S4.F4.2.m1.1" class="ltx_Math" alttext="25^{\text{\tiny th}}" display="inline"><semantics id="S4.F4.2.m1.1b"><msup id="S4.F4.2.m1.1.1" xref="S4.F4.2.m1.1.1.cmml"><mn id="S4.F4.2.m1.1.1.2" xref="S4.F4.2.m1.1.1.2.cmml">25</mn><mtext mathsize="71%" id="S4.F4.2.m1.1.1.3" xref="S4.F4.2.m1.1.1.3a.cmml">th</mtext></msup><annotation-xml encoding="MathML-Content" id="S4.F4.2.m1.1c"><apply id="S4.F4.2.m1.1.1.cmml" xref="S4.F4.2.m1.1.1"><csymbol cd="ambiguous" id="S4.F4.2.m1.1.1.1.cmml" xref="S4.F4.2.m1.1.1">superscript</csymbol><cn type="integer" id="S4.F4.2.m1.1.1.2.cmml" xref="S4.F4.2.m1.1.1.2">25</cn><ci id="S4.F4.2.m1.1.1.3a.cmml" xref="S4.F4.2.m1.1.1.3"><mtext mathsize="50%" id="S4.F4.2.m1.1.1.3.cmml" xref="S4.F4.2.m1.1.1.3">th</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F4.2.m1.1d">25^{\text{\tiny th}}</annotation></semantics></math> one in descending recall gain). See the text for a discussion.</figcaption>
</figure>
<div id="S4.SS3.p4" class="ltx_para">
<p id="S4.SS3.p4.6" class="ltx_p">To obtain deeper insights into the additional knowledge that is actually most beneficial, we examined the improvements of our model over the Pythia baseline on individual answers. We report, in Fig. <a href="#S4.F4" title="Figure 4 ‣ 4.3 In-Depth Analysis ‣ 4 Experiments ‣ Visual Question Answering with Prior Class Semantics" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, the change in answer recall for a random selection of answers. We define the answer recall as, for an answer candidate <math id="S4.SS3.p4.1.m1.1" class="ltx_Math" alttext="\hat{a}" display="inline"><semantics id="S4.SS3.p4.1.m1.1a"><mover accent="true" id="S4.SS3.p4.1.m1.1.1" xref="S4.SS3.p4.1.m1.1.1.cmml"><mi id="S4.SS3.p4.1.m1.1.1.2" xref="S4.SS3.p4.1.m1.1.1.2.cmml">a</mi><mo id="S4.SS3.p4.1.m1.1.1.1" xref="S4.SS3.p4.1.m1.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S4.SS3.p4.1.m1.1b"><apply id="S4.SS3.p4.1.m1.1.1.cmml" xref="S4.SS3.p4.1.m1.1.1"><ci id="S4.SS3.p4.1.m1.1.1.1.cmml" xref="S4.SS3.p4.1.m1.1.1.1">^</ci><ci id="S4.SS3.p4.1.m1.1.1.2.cmml" xref="S4.SS3.p4.1.m1.1.1.2">𝑎</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p4.1.m1.1c">\hat{a}</annotation></semantics></math>, the ratio of questions with <math id="S4.SS3.p4.2.m2.1" class="ltx_Math" alttext="\hat{a}" display="inline"><semantics id="S4.SS3.p4.2.m2.1a"><mover accent="true" id="S4.SS3.p4.2.m2.1.1" xref="S4.SS3.p4.2.m2.1.1.cmml"><mi id="S4.SS3.p4.2.m2.1.1.2" xref="S4.SS3.p4.2.m2.1.1.2.cmml">a</mi><mo id="S4.SS3.p4.2.m2.1.1.1" xref="S4.SS3.p4.2.m2.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S4.SS3.p4.2.m2.1b"><apply id="S4.SS3.p4.2.m2.1.1.cmml" xref="S4.SS3.p4.2.m2.1.1"><ci id="S4.SS3.p4.2.m2.1.1.1.cmml" xref="S4.SS3.p4.2.m2.1.1.1">^</ci><ci id="S4.SS3.p4.2.m2.1.1.2.cmml" xref="S4.SS3.p4.2.m2.1.1.2">𝑎</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p4.2.m2.1c">\hat{a}</annotation></semantics></math> as ground truth that are correctly answered by the model. The recall of most answers improves, but it stays similar or even degrades on some others. We investigated the possible reasons. A degradation is presumably related to less relevant initial representations of the corresponding answer. To assess this, we examined the closest other answers in the space of pretrained GloVe vectors. Most answers with a negative gain in answer recall have neighbors with no semantic or syntactic connections. For instance, the three closest neighbors to <span id="S4.SS3.p4.6.3" class="ltx_text ltx_font_italic">modern</span> are <math id="S4.SS3.p4.3.m3.1" class="ltx_Math" alttext="\{" display="inline"><semantics id="S4.SS3.p4.3.m3.1a"><mo stretchy="false" id="S4.SS3.p4.3.m3.1.1" xref="S4.SS3.p4.3.m3.1.1.cmml">{</mo><annotation-xml encoding="MathML-Content" id="S4.SS3.p4.3.m3.1b"><ci id="S4.SS3.p4.3.m3.1.1.cmml" xref="S4.SS3.p4.3.m3.1.1">{</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p4.3.m3.1c">\{</annotation></semantics></math><span id="S4.SS3.p4.6.4" class="ltx_text ltx_font_italic">under</span>, <span id="S4.SS3.p4.6.5" class="ltx_text ltx_font_italic">rooftop</span>, <span id="S4.SS3.p4.4.1" class="ltx_text ltx_font_italic">visitor<math id="S4.SS3.p4.4.1.m1.1" class="ltx_Math" alttext="\}" display="inline"><semantics id="S4.SS3.p4.4.1.m1.1a"><mo stretchy="false" id="S4.SS3.p4.4.1.m1.1.1" xref="S4.SS3.p4.4.1.m1.1.1.cmml">}</mo><annotation-xml encoding="MathML-Content" id="S4.SS3.p4.4.1.m1.1b"><ci id="S4.SS3.p4.4.1.m1.1.1.cmml" xref="S4.SS3.p4.4.1.m1.1.1">}</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p4.4.1.m1.1c">\}</annotation></semantics></math></span>. Answers with a high recall improvement, on the contrary, tend to have semantically related neighbors. For example, <span id="S4.SS3.p4.6.6" class="ltx_text ltx_font_italic">basket</span> has the closest neighbors <math id="S4.SS3.p4.5.m4.1" class="ltx_Math" alttext="\{" display="inline"><semantics id="S4.SS3.p4.5.m4.1a"><mo stretchy="false" id="S4.SS3.p4.5.m4.1.1" xref="S4.SS3.p4.5.m4.1.1.cmml">{</mo><annotation-xml encoding="MathML-Content" id="S4.SS3.p4.5.m4.1b"><ci id="S4.SS3.p4.5.m4.1.1.cmml" xref="S4.SS3.p4.5.m4.1.1">{</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p4.5.m4.1c">\{</annotation></semantics></math><span id="S4.SS3.p4.6.7" class="ltx_text ltx_font_italic">baskets</span>, <span id="S4.SS3.p4.6.8" class="ltx_text ltx_font_italic">cane</span>, <span id="S4.SS3.p4.6.2" class="ltx_text ltx_font_italic">sack<math id="S4.SS3.p4.6.2.m1.1" class="ltx_Math" alttext="\}" display="inline"><semantics id="S4.SS3.p4.6.2.m1.1a"><mo stretchy="false" id="S4.SS3.p4.6.2.m1.1.1" xref="S4.SS3.p4.6.2.m1.1.1.cmml">}</mo><annotation-xml encoding="MathML-Content" id="S4.SS3.p4.6.2.m1.1b"><ci id="S4.SS3.p4.6.2.m1.1.1.cmml" xref="S4.SS3.p4.6.2.m1.1.1">}</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p4.6.2.m1.1c">\}</annotation></semantics></math></span>. These observations further support the claim that mutual relations between representations of answers are the major way in which the network stores and uses semantic information.</p>
</div>
<figure id="S4.F5" class="ltx_figure"><img src="/html/2005.01239/assets/x5.png" id="S4.F5.g1" class="ltx_graphics ltx_centering ltx_img_square" width="461" height="455" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Qualitative examples from the GQA dataset, with predictions of our model and of the Pythia baseline. We show pairs of questions about a same image where the first entails the second (this information is never provided to the model during training nor testing). Our model improves in consistency over the baseline, producing pairs of answers compatible with one another.</figcaption>
</figure>
</section>
<section id="S4.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>Prediction of Novel Answers</h3>

<div id="S4.SS4.p1" class="ltx_para">
<p id="S4.SS4.p1.2" class="ltx_p">Our model trained with the regression objective can predict answers at test time that are outside the predefined set of candidates used for training (<em id="S4.SS4.p1.2.1" class="ltx_emph ltx_font_italic">i.e</em>.<span id="S4.SS4.p1.2.2" class="ltx_text"></span> open-set prediction a.k.a. zero-shot VQA <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>). This is achieved by replacing the matrix <math id="S4.SS4.p1.1.m1.1" class="ltx_Math" alttext="M" display="inline"><semantics id="S4.SS4.p1.1.m1.1a"><mi id="S4.SS4.p1.1.m1.1.1" xref="S4.SS4.p1.1.m1.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.1.m1.1b"><ci id="S4.SS4.p1.1.m1.1.1.cmml" xref="S4.SS4.p1.1.m1.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.1.m1.1c">M</annotation></semantics></math> with new answers and setting <math id="S4.SS4.p1.2.m2.1" class="ltx_Math" alttext="\lambda" display="inline"><semantics id="S4.SS4.p1.2.m2.1a"><mi id="S4.SS4.p1.2.m2.1.1" xref="S4.SS4.p1.2.m2.1.1.cmml">λ</mi><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.2.m2.1b"><ci id="S4.SS4.p1.2.m2.1.1.cmml" xref="S4.SS4.p1.2.m2.1.1">𝜆</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.2.m2.1c">\lambda</annotation></semantics></math> to 0 at test time. To evaluate this setting, we use ConceptNet embeddings <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>, which are designed to common sense knowledge.We use the VQA v2 dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite> since it features a more diverse set of answers than GQA. We use splits with disjoint sets of answers at training and test time (see details in Appendix <span class="ltx_ref ltx_nolink ltx_ref_self"><span class="ltx_text ltx_ref_tag">C</span></span>). In this setting, our model achieves an accuracy of 27% on the test set, while fPMC model, which also has tools for out-of-vocabulary prediction, obtains about 15% accuracy. Given that test questions feature exclusively answers never seen during training, this clearly demonstrates a capability for predictions beyond the scope of the training set. However, the performance on novel answers is highly depended on the used answer representations.
Embeddings like GloVe and ConceptNet carry only limited, mostly linguistic information, which is insufficient for the full scope of their use in VQA.
We discovered that embeddings learned end-to-end in a VQA model capture visual co-occurrences (Fig. <span class="ltx_ref ltx_nolink ltx_ref_self"><span class="ltx_text ltx_ref_tag">6</span></span> in Appendix <span class="ltx_ref ltx_nolink ltx_ref_self"><span class="ltx_text ltx_ref_tag">D.3</span></span>). This implies that additional knowledge extracted from visual data (<em id="S4.SS4.p1.2.3" class="ltx_emph ltx_font_italic">e.g</em>.<span id="S4.SS4.p1.2.4" class="ltx_text"></span> as <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>) should be a useful complement to boost out-of-vocabulary performance. The combination of multiple types of pretrained embeddings is a promising avenue for future work.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusions</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">In this paper, we reformulated VQA as a multitask problem, which allowed us to exploit prior semantic knowledge about answers. We demonstrated that GloVe word embeddings carry information about typical answers that is relevant to the task. In contrast to existing methods for incorporating additional data into VQA models, our technique is both simple and effective, and allows to tune the reliance of the model on general prior knowledge, and learned task-specific information. We evaluated our technique on the GQA dataset and obtained consistent improvement in accuracy in the majority of question categories. The extensive set of metrics also allowed identifying benefits in robustness and consistency of the model across related questions.</p>
</div>
<div id="S5.p2" class="ltx_para">
<p id="S5.p2.1" class="ltx_p">The fundamental idea in this paper of including a regression task as part of VQA has implications that go beyond what could be demonstrated with existing datasets.
This formulation opens the door to the generation of compositional multi-word answers, and to open-set prediction, that is, predicting answers beyond the set of candidate answers predefined at training time.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography" style="font-size:90%;">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock"><span id="bib.bib1.1.1" class="ltx_text" style="font-size:90%;">
Zeynep Akata, Scott Reed, Daniel Walter, Honglak Lee, and Bernt Schiele.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib1.2.1" class="ltx_text" style="font-size:90%;">Evaluation of output embeddings for fine-grained image
classification.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib1.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib1.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition</span><span id="bib.bib1.5.3" class="ltx_text" style="font-size:90%;">, pages 2927–2936, 2015.
</span>
</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock"><span id="bib.bib2.1.1" class="ltx_text" style="font-size:90%;">
Peter Anderson, Xiaodong He, Chris Buehler, Damien Teney, Mark Johnson, Stephen
Gould, and Lei Zhang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib2.2.1" class="ltx_text" style="font-size:90%;">Bottom-up and top-down attention for image captioning and visual
question answering.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib2.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib2.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition</span><span id="bib.bib2.5.3" class="ltx_text" style="font-size:90%;">, volume 3, page 6, 2018.
</span>
</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock"><span id="bib.bib3.1.1" class="ltx_text" style="font-size:90%;">
Stanislaw Antol, Aishwarya Agrawal, Jiasen Lu, Margaret Mitchell, Dhruv Batra,
C Lawrence Zitnick, and Devi Parikh.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib3.2.1" class="ltx_text" style="font-size:90%;">VQA: Visual question answering.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib3.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib3.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE International Conference on Computer
Vision</span><span id="bib.bib3.5.3" class="ltx_text" style="font-size:90%;">, pages 2425–2433, 2015.
</span>
</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock"><span id="bib.bib4.1.1" class="ltx_text" style="font-size:90%;">
Andrea Frome, Greg S Corrado, Jon Shlens, Samy Bengio, Jeff Dean, Tomas
Mikolov, et al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib4.2.1" class="ltx_text" style="font-size:90%;">Devise: A deep visual-semantic embedding model.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib4.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib4.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Advances in Neural Information Processing Systems</span><span id="bib.bib4.5.3" class="ltx_text" style="font-size:90%;">, pages
2121–2129, 2013.
</span>
</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock"><span id="bib.bib5.1.1" class="ltx_text" style="font-size:90%;">
Haoyuan Gao, Junhua Mao, Jie Zhou, Zhiheng Huang, Lei Wang, and Wei Xu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib5.2.1" class="ltx_text" style="font-size:90%;">Are you talking to a machine? dataset and methods for multilingual
image question.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib5.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib5.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the Advances in Neural Information Processing
Systems</span><span id="bib.bib5.5.3" class="ltx_text" style="font-size:90%;">, pages 2296–2304, 2015.
</span>
</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock"><span id="bib.bib6.1.1" class="ltx_text" style="font-size:90%;">
Yash Goyal, Tejas Khot, Douglas Summers-Stay, Dhruv Batra, and Devi Parikh.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib6.2.1" class="ltx_text" style="font-size:90%;">Making the V in VQA matter: Elevating the role of image
understanding in visual question answering.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib6.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib6.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition</span><span id="bib.bib6.5.3" class="ltx_text" style="font-size:90%;">, volume 1, page 3, 2017.
</span>
</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock"><span id="bib.bib7.1.1" class="ltx_text" style="font-size:90%;">
Hexiang Hu, Wei-Lun Chao, and Fei Sha.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib7.2.1" class="ltx_text" style="font-size:90%;">Learning answer embeddings for visual question answering.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib7.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib7.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition</span><span id="bib.bib7.5.3" class="ltx_text" style="font-size:90%;">, pages 5428–5436, 2018.
</span>
</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock"><span id="bib.bib8.1.1" class="ltx_text" style="font-size:90%;">
Drew Hudson and Christopher D. Manning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.2.1" class="ltx_text" style="font-size:90%;">Learning by abstraction: The neural state machine.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib8.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Advances in Neural Information Processing Systems</span><span id="bib.bib8.5.3" class="ltx_text" style="font-size:90%;">, pages
5901–5914, 2019.
</span>
</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock"><span id="bib.bib9.1.1" class="ltx_text" style="font-size:90%;">
Drew A Hudson and Christopher D Manning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.2.1" class="ltx_text" style="font-size:90%;">Compositional attention networks for machine reasoning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1803.03067</span><span id="bib.bib9.4.2" class="ltx_text" style="font-size:90%;">, 2018.
</span>
</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock"><span id="bib.bib10.1.1" class="ltx_text" style="font-size:90%;">
Drew A Hudson and Christopher D Manning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib10.2.1" class="ltx_text" style="font-size:90%;">GQA: A new dataset for real-world visual reasoning and
compositional question answering.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib10.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Conference on Computer Vision and Pattern Recognition</span><span id="bib.bib10.4.2" class="ltx_text" style="font-size:90%;">, 2019.
</span>
</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock"><span id="bib.bib11.1.1" class="ltx_text" style="font-size:90%;">
Yu Jiang, Vivek Natarajan, Xinlei Chen, Marcus Rohrbach, Dhruv Batra, and Devi
Parikh.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib11.2.1" class="ltx_text" style="font-size:90%;">Pythia v0. 1: the winning entry to the VQA challenge 2018.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib11.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1807.09956</span><span id="bib.bib11.4.2" class="ltx_text" style="font-size:90%;">, 2018.
</span>
</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock"><span id="bib.bib12.1.1" class="ltx_text" style="font-size:90%;">
Kushal Kafle and Christopher Kanan.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.2.1" class="ltx_text" style="font-size:90%;">Visual question answering: Datasets, algorithms, and future
challenges.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Computer Vision and Image Understanding</span><span id="bib.bib12.4.2" class="ltx_text" style="font-size:90%;">, 163:3–20, 2017.
</span>
</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock"><span id="bib.bib13.1.1" class="ltx_text" style="font-size:90%;">
Diederik P Kingma and Jimmy Ba.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.2.1" class="ltx_text" style="font-size:90%;">Adam: A method for stochastic optimization.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1412.6980</span><span id="bib.bib13.4.2" class="ltx_text" style="font-size:90%;">, 2014.
</span>
</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock"><span id="bib.bib14.1.1" class="ltx_text" style="font-size:90%;">
Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib14.2.1" class="ltx_text" style="font-size:90%;">Efficient estimation of word representations in vector space.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib14.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1301.3781</span><span id="bib.bib14.4.2" class="ltx_text" style="font-size:90%;">, 2013.
</span>
</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock"><span id="bib.bib15.1.1" class="ltx_text" style="font-size:90%;">
Hyeonwoo Noh, Taehoon Kim, Jonghwan Mun, and Bohyung Han.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.2.1" class="ltx_text" style="font-size:90%;">Transfer learning via unsupervised task discovery for visual question
answering.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib15.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE Conference on Computer Vision
and Pattern Recognition</span><span id="bib.bib15.5.3" class="ltx_text" style="font-size:90%;">, pages 8385–8394, 2019.
</span>
</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock"><span id="bib.bib16.1.1" class="ltx_text" style="font-size:90%;">
Jeffrey Pennington, Richard Socher, and Christopher Manning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib16.2.1" class="ltx_text" style="font-size:90%;">Glove: Global vectors for word representation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib16.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib16.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the Conference on Empirical Methods in Natural
Language Processing</span><span id="bib.bib16.5.3" class="ltx_text" style="font-size:90%;">, pages 1532–1543, 2014.
</span>
</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock"><span id="bib.bib17.1.1" class="ltx_text" style="font-size:90%;">
Kuniaki Saito, Andrew Shin, Yoshitaka Ushiku, and Tatsuya Harada.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib17.2.1" class="ltx_text" style="font-size:90%;">Dualnet: Domain-invariant network for visual question answering.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib17.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib17.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE International Conference on
Multimedia and Expo</span><span id="bib.bib17.5.3" class="ltx_text" style="font-size:90%;">, pages 829–834. IEEE, 2017.
</span>
</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock"><span id="bib.bib18.1.1" class="ltx_text" style="font-size:90%;">
Tim Salimans and Durk P Kingma.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib18.2.1" class="ltx_text" style="font-size:90%;">Weight normalization: A simple reparameterization to accelerate
training of deep neural networks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib18.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib18.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Advances in Neural Information Processing Systems</span><span id="bib.bib18.5.3" class="ltx_text" style="font-size:90%;">, pages
901–909, 2016.
</span>
</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock"><span id="bib.bib19.1.1" class="ltx_text" style="font-size:90%;">
Robert Speer, Joshua Chin, and Catherine Havasi.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib19.2.1" class="ltx_text" style="font-size:90%;">Conceptnet 5.5: An open multilingual graph of general knowledge.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib19.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib19.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Thirty-First AAAI Conference on Artificial Intelligence</span><span id="bib.bib19.5.3" class="ltx_text" style="font-size:90%;">,
2017.
</span>
</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock"><span id="bib.bib20.1.1" class="ltx_text" style="font-size:90%;">
Hao Tan and Mohit Bansal.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib20.2.1" class="ltx_text" style="font-size:90%;">Lxmert: Learning cross-modality encoder representations from
transformers.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib20.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1908.07490</span><span id="bib.bib20.4.2" class="ltx_text" style="font-size:90%;">, 2019.
</span>
</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock"><span id="bib.bib21.1.1" class="ltx_text" style="font-size:90%;">
Damien Teney, Peter Anderson, Xiaodong He, and Anton van den Hengel.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib21.2.1" class="ltx_text" style="font-size:90%;">Tips and tricks for visual question answering: Learnings from the
2017 challenge.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib21.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib21.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition</span><span id="bib.bib21.5.3" class="ltx_text" style="font-size:90%;">, pages 4223–4232, 2018.
</span>
</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock"><span id="bib.bib22.1.1" class="ltx_text" style="font-size:90%;">
Damien Teney and Anton van den Hengel.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib22.2.1" class="ltx_text" style="font-size:90%;">Zero-shot visual question answering.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib22.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1611.05546</span><span id="bib.bib22.4.2" class="ltx_text" style="font-size:90%;">, 2016.
</span>
</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock"><span id="bib.bib23.1.1" class="ltx_text" style="font-size:90%;">
Damien Teney, Qi Wu, and Anton van den Hengel.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib23.2.1" class="ltx_text" style="font-size:90%;">Visual question answering: A tutorial.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib23.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Signal Processing Magazine</span><span id="bib.bib23.4.2" class="ltx_text" style="font-size:90%;">, 34(6):63–75, 2017.
</span>
</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock"><span id="bib.bib24.1.1" class="ltx_text" style="font-size:90%;">
Qi Wu, Chunhua Shen, Peng Wang, Anthony Dick, and Anton van den Hengel.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib24.2.1" class="ltx_text" style="font-size:90%;">Image captioning and visual question answering based on attributes
and external knowledge.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib24.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Transactions on Pattern Analysis and Machine Intelligence</span><span id="bib.bib24.4.2" class="ltx_text" style="font-size:90%;">,
40(6):1367–1381, 2017.
</span>
</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock"><span id="bib.bib25.1.1" class="ltx_text" style="font-size:90%;">
Huapeng Xu, Guilin Qi, Jingjing Li, Meng Wang, Kang Xu, and Huan Gao.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib25.2.1" class="ltx_text" style="font-size:90%;">Fine-grained image classification by visual-semantic embedding.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib25.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib25.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the International Joint Conference on
Artificial Intelligence</span><span id="bib.bib25.5.3" class="ltx_text" style="font-size:90%;">, pages 1043–1049, 2018.
</span>
</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock"><span id="bib.bib26.1.1" class="ltx_text" style="font-size:90%;">
Zichao Yang, Xiaodong He, Jianfeng Gao, Li Deng, and Alex Smola.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib26.2.1" class="ltx_text" style="font-size:90%;">Stacked attention networks for image question answering.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib26.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib26.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition</span><span id="bib.bib26.5.3" class="ltx_text" style="font-size:90%;">, pages 21–29, 2016.
</span>
</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock"><span id="bib.bib27.1.1" class="ltx_text" style="font-size:90%;">
Bolei Zhou, Yuandong Tian, Sainbayar Sukhbaatar, Arthur Szlam, and Rob Fergus.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib27.2.1" class="ltx_text" style="font-size:90%;">Simple baseline for visual question answering.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib27.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1512.02167</span><span id="bib.bib27.4.2" class="ltx_text" style="font-size:90%;">, 2015.
</span>
</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<section id="Ax1" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">Visual Question Answering with Prior Class Semantics</h2>

</section>
<section id="Ax2" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">Appendices</h2>

</section>
<section id="A1" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Baseline Methods</h2>

<section id="A1.SS0.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Pythia</h4>

<div id="A1.SS0.SSS0.Px1.p1" class="ltx_para">
<p id="A1.SS0.SSS0.Px1.p1.1" class="ltx_p">Our baseline model is the Pythia implementation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite> of the classical joint embedding model <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>, <a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>. Pythia uses object image features extracted with the pretrained Faster R-CNN model provided with the GQA dataset. On the language side, words are represented with word embeddings initialized with pretrained GloVe vectors, followed by an LSTM to produce a vector representation of the whole question. A question-guided top-down attention is applied on image features to identify relevant image regions. The image and question features are passed through non-linear layers and finally combined with an element-wise multiplication. The final classifier comprises a non-linear layer and a linear one, which produces a score for each candidate answer. All non-linear layers throughout the network use weight normalization <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite> and ReLU activations.</p>
</div>
<div id="A1.SS0.SSS0.Px1.p2" class="ltx_para">
<p id="A1.SS0.SSS0.Px1.p2.1" class="ltx_p">Pythia serves as reference for evaluation, and as the bare model on which to build our contributions. This choice is justified by a few reasons. It is a high-performing open-source implementation that still outperforms many others on the VQA v2 dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>. This provides us with a strong – and thus challenging – starting point to demonstrate the proposed method. Moreover, the implementation of Pythia is modular and easily allows one to separate, replace, and compare the various blocks of the model. In our case, this enables us to focus specifically on the classification part of the model, leaving the rest unchanged.</p>
</div>
</section>
<section id="A1.SS0.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Pythia with pretrained classifier</h4>

<div id="A1.SS0.SSS0.Px2.p1" class="ltx_para">
<p id="A1.SS0.SSS0.Px2.p1.3" class="ltx_p">We compare our method to the Pythia model, in which the output classifier is initialized with pretrained answer embeddings. As discussed in the related works section, this is a reasonable approach to embed semantic information about candidate answers within the model. Following a procedure similar to <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>, we collect 300-dimensional GloVe embeddings for all words in the answer vocabulary (substituting unknown words with zero vectors). We represent each answer directly by its matching word embedding, or, in the case of multi-word answers, by the average embedding of the constituent words. Next, we design the classifier block of the model as follows: one non-linear layer with output dimension equal to the dimensionality of used GloVe embeddings followed by a linear layer with a weight matrix <math id="A1.SS0.SSS0.Px2.p1.1.m1.1" class="ltx_Math" alttext="w\in\mathbb{R}^{300\times A}" display="inline"><semantics id="A1.SS0.SSS0.Px2.p1.1.m1.1a"><mrow id="A1.SS0.SSS0.Px2.p1.1.m1.1.1" xref="A1.SS0.SSS0.Px2.p1.1.m1.1.1.cmml"><mi id="A1.SS0.SSS0.Px2.p1.1.m1.1.1.2" xref="A1.SS0.SSS0.Px2.p1.1.m1.1.1.2.cmml">w</mi><mo id="A1.SS0.SSS0.Px2.p1.1.m1.1.1.1" xref="A1.SS0.SSS0.Px2.p1.1.m1.1.1.1.cmml">∈</mo><msup id="A1.SS0.SSS0.Px2.p1.1.m1.1.1.3" xref="A1.SS0.SSS0.Px2.p1.1.m1.1.1.3.cmml"><mi id="A1.SS0.SSS0.Px2.p1.1.m1.1.1.3.2" xref="A1.SS0.SSS0.Px2.p1.1.m1.1.1.3.2.cmml">ℝ</mi><mrow id="A1.SS0.SSS0.Px2.p1.1.m1.1.1.3.3" xref="A1.SS0.SSS0.Px2.p1.1.m1.1.1.3.3.cmml"><mn id="A1.SS0.SSS0.Px2.p1.1.m1.1.1.3.3.2" xref="A1.SS0.SSS0.Px2.p1.1.m1.1.1.3.3.2.cmml">300</mn><mo lspace="0.222em" rspace="0.222em" id="A1.SS0.SSS0.Px2.p1.1.m1.1.1.3.3.1" xref="A1.SS0.SSS0.Px2.p1.1.m1.1.1.3.3.1.cmml">×</mo><mi id="A1.SS0.SSS0.Px2.p1.1.m1.1.1.3.3.3" xref="A1.SS0.SSS0.Px2.p1.1.m1.1.1.3.3.3.cmml">A</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="A1.SS0.SSS0.Px2.p1.1.m1.1b"><apply id="A1.SS0.SSS0.Px2.p1.1.m1.1.1.cmml" xref="A1.SS0.SSS0.Px2.p1.1.m1.1.1"><in id="A1.SS0.SSS0.Px2.p1.1.m1.1.1.1.cmml" xref="A1.SS0.SSS0.Px2.p1.1.m1.1.1.1"></in><ci id="A1.SS0.SSS0.Px2.p1.1.m1.1.1.2.cmml" xref="A1.SS0.SSS0.Px2.p1.1.m1.1.1.2">𝑤</ci><apply id="A1.SS0.SSS0.Px2.p1.1.m1.1.1.3.cmml" xref="A1.SS0.SSS0.Px2.p1.1.m1.1.1.3"><csymbol cd="ambiguous" id="A1.SS0.SSS0.Px2.p1.1.m1.1.1.3.1.cmml" xref="A1.SS0.SSS0.Px2.p1.1.m1.1.1.3">superscript</csymbol><ci id="A1.SS0.SSS0.Px2.p1.1.m1.1.1.3.2.cmml" xref="A1.SS0.SSS0.Px2.p1.1.m1.1.1.3.2">ℝ</ci><apply id="A1.SS0.SSS0.Px2.p1.1.m1.1.1.3.3.cmml" xref="A1.SS0.SSS0.Px2.p1.1.m1.1.1.3.3"><times id="A1.SS0.SSS0.Px2.p1.1.m1.1.1.3.3.1.cmml" xref="A1.SS0.SSS0.Px2.p1.1.m1.1.1.3.3.1"></times><cn type="integer" id="A1.SS0.SSS0.Px2.p1.1.m1.1.1.3.3.2.cmml" xref="A1.SS0.SSS0.Px2.p1.1.m1.1.1.3.3.2">300</cn><ci id="A1.SS0.SSS0.Px2.p1.1.m1.1.1.3.3.3.cmml" xref="A1.SS0.SSS0.Px2.p1.1.m1.1.1.3.3.3">𝐴</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS0.SSS0.Px2.p1.1.m1.1c">w\in\mathbb{R}^{300\times A}</annotation></semantics></math>. Each row of <math id="A1.SS0.SSS0.Px2.p1.2.m2.1" class="ltx_Math" alttext="w" display="inline"><semantics id="A1.SS0.SSS0.Px2.p1.2.m2.1a"><mi id="A1.SS0.SSS0.Px2.p1.2.m2.1.1" xref="A1.SS0.SSS0.Px2.p1.2.m2.1.1.cmml">w</mi><annotation-xml encoding="MathML-Content" id="A1.SS0.SSS0.Px2.p1.2.m2.1b"><ci id="A1.SS0.SSS0.Px2.p1.2.m2.1.1.cmml" xref="A1.SS0.SSS0.Px2.p1.2.m2.1.1">𝑤</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS0.SSS0.Px2.p1.2.m2.1c">w</annotation></semantics></math> thus contains the vector corresponding to one specific answer. Besides the non-random initialization of <math id="A1.SS0.SSS0.Px2.p1.3.m3.1" class="ltx_Math" alttext="w" display="inline"><semantics id="A1.SS0.SSS0.Px2.p1.3.m3.1a"><mi id="A1.SS0.SSS0.Px2.p1.3.m3.1.1" xref="A1.SS0.SSS0.Px2.p1.3.m3.1.1.cmml">w</mi><annotation-xml encoding="MathML-Content" id="A1.SS0.SSS0.Px2.p1.3.m3.1b"><ci id="A1.SS0.SSS0.Px2.p1.3.m3.1.1.cmml" xref="A1.SS0.SSS0.Px2.p1.3.m3.1.1">𝑤</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS0.SSS0.Px2.p1.3.m3.1c">w</annotation></semantics></math>, the only distinction with the original Pythia model is that the output dimension of the non-linear layer is reduced from 5000 to 300 to match the dimensionality of the GloVe vectors.</p>
</div>
</section>
<section id="A1.SS0.SSS0.Px3" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Factorized probabilistic model of compatibility</h4>

<div id="A1.SS0.SSS0.Px3.p1" class="ltx_para">
<p id="A1.SS0.SSS0.Px3.p1.1" class="ltx_p">We also compare the proposed approach to the factorized Probabilistic Model of Compatibility (fPMC) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>. In this architecture, a joint image-question embedding is learned alongside the answer embedding, and the model is trained to increase the likelihood of the correct answer. We performed all experiments with the following two variants proposed by the authors.</p>
<ul id="A1.I1" class="ltx_itemize">
<li id="A1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A1.I1.i1.p1" class="ltx_para">
<p id="A1.I1.i1.p1.1" class="ltx_p">fPMC(SAN<math id="A1.I1.i1.p1.1.m1.1" class="ltx_Math" alttext="\star" display="inline"><semantics id="A1.I1.i1.p1.1.m1.1a"><mo id="A1.I1.i1.p1.1.m1.1.1" xref="A1.I1.i1.p1.1.m1.1.1.cmml">⋆</mo><annotation-xml encoding="MathML-Content" id="A1.I1.i1.p1.1.m1.1b"><ci id="A1.I1.i1.p1.1.m1.1.1.cmml" xref="A1.I1.i1.p1.1.m1.1.1">⋆</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.I1.i1.p1.1.m1.1c">\star</annotation></semantics></math>) model, described in the original paper, that utilizes stacked attention network <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite> together with bidirectional LSTM and spatial image features extracted with ResNet-152. For obtaining answer embeddings, the model exploits two-layer bidirectional LSTM over GloVe vectors. We used the code provided by the authors of the paper and made the adjustments only required to make it compatible with GQA dataset.</p>
</div>
</li>
<li id="A1.I1.i2" class="ltx_item" style="list-style-type:none;padding-top:1.0pt;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A1.I1.i2.p1" class="ltx_para">
<p id="A1.I1.i2.p1.2" class="ltx_p">fPMC(BUTD<math id="A1.I1.i2.p1.1.m1.1" class="ltx_Math" alttext="\star" display="inline"><semantics id="A1.I1.i2.p1.1.m1.1a"><mo id="A1.I1.i2.p1.1.m1.1.1" xref="A1.I1.i2.p1.1.m1.1.1.cmml">⋆</mo><annotation-xml encoding="MathML-Content" id="A1.I1.i2.p1.1.m1.1b"><ci id="A1.I1.i2.p1.1.m1.1.1.cmml" xref="A1.I1.i2.p1.1.m1.1.1">⋆</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.I1.i2.p1.1.m1.1c">\star</annotation></semantics></math>) model is our modification of fPMC(SAN<math id="A1.I1.i2.p1.2.m2.1" class="ltx_Math" alttext="\star" display="inline"><semantics id="A1.I1.i2.p1.2.m2.1a"><mo id="A1.I1.i2.p1.2.m2.1.1" xref="A1.I1.i2.p1.2.m2.1.1.cmml">⋆</mo><annotation-xml encoding="MathML-Content" id="A1.I1.i2.p1.2.m2.1b"><ci id="A1.I1.i2.p1.2.m2.1.1.cmml" xref="A1.I1.i2.p1.2.m2.1.1">⋆</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.I1.i2.p1.2.m2.1c">\star</annotation></semantics></math>) where we used the “bottom-up and top-down attention” <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite> model with object image features for parameterizing the joint embedding in the same way as all the other models used in our experiments. We were thus able to explicitly evaluate the approach of learning aligned answer embeddings independently from the impact of different feature initializations.</p>
</div>
</li>
</ul>
</div>
</section>
</section>
<section id="A2" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>Implementation of the Proposed Method</h2>

<div id="A2.p1" class="ltx_para">
<p id="A2.p1.2" class="ltx_p">The proposed method builds directly on the open source Pythia implementation<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>https://github.com/facebookresearch/pythia/tree/0.1</span></span></span>, which uses PyTorch. Our model is trained for 20,000 iterations with a batch size of 512 and AdaMax optimizer <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>. We adopted a warm-up learning schedule strategy from <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite> and tuned it to the current setup. Specifically, the starting learning rate of 0.002 is linearly growing up to 0.1 during first 1000 iterations and then decreased by a factor of 0.1 at 11,000, 13,000 and 15,000 iterations. Importantly, these hyperparameters were selected for best performance of the <span id="A2.p1.2.1" class="ltx_text ltx_font_bold">baseline</span> model on the validation set of the GQA dataset, thus avoiding any unfair advantage for our contributions. The values of the regression loss margin (<math id="A2.p1.1.m1.1" class="ltx_Math" alttext="\delta=1" display="inline"><semantics id="A2.p1.1.m1.1a"><mrow id="A2.p1.1.m1.1.1" xref="A2.p1.1.m1.1.1.cmml"><mi id="A2.p1.1.m1.1.1.2" xref="A2.p1.1.m1.1.1.2.cmml">δ</mi><mo id="A2.p1.1.m1.1.1.1" xref="A2.p1.1.m1.1.1.1.cmml">=</mo><mn id="A2.p1.1.m1.1.1.3" xref="A2.p1.1.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="A2.p1.1.m1.1b"><apply id="A2.p1.1.m1.1.1.cmml" xref="A2.p1.1.m1.1.1"><eq id="A2.p1.1.m1.1.1.1.cmml" xref="A2.p1.1.m1.1.1.1"></eq><ci id="A2.p1.1.m1.1.1.2.cmml" xref="A2.p1.1.m1.1.1.2">𝛿</ci><cn type="integer" id="A2.p1.1.m1.1.1.3.cmml" xref="A2.p1.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.p1.1.m1.1c">\delta=1</annotation></semantics></math>) and of the loss weight (<math id="A2.p1.2.m2.1" class="ltx_Math" alttext="\lambda=0.5" display="inline"><semantics id="A2.p1.2.m2.1a"><mrow id="A2.p1.2.m2.1.1" xref="A2.p1.2.m2.1.1.cmml"><mi id="A2.p1.2.m2.1.1.2" xref="A2.p1.2.m2.1.1.2.cmml">λ</mi><mo id="A2.p1.2.m2.1.1.1" xref="A2.p1.2.m2.1.1.1.cmml">=</mo><mn id="A2.p1.2.m2.1.1.3" xref="A2.p1.2.m2.1.1.3.cmml">0.5</mn></mrow><annotation-xml encoding="MathML-Content" id="A2.p1.2.m2.1b"><apply id="A2.p1.2.m2.1.1.cmml" xref="A2.p1.2.m2.1.1"><eq id="A2.p1.2.m2.1.1.1.cmml" xref="A2.p1.2.m2.1.1.1"></eq><ci id="A2.p1.2.m2.1.1.2.cmml" xref="A2.p1.2.m2.1.1.2">𝜆</ci><cn type="float" id="A2.p1.2.m2.1.1.3.cmml" xref="A2.p1.2.m2.1.1.3">0.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.p1.2.m2.1c">\lambda=0.5</annotation></semantics></math>) were determined by grid search for best overall accuracy on the GQA validation set.</p>
</div>
<div id="A2.p2" class="ltx_para">
<p id="A2.p2.1" class="ltx_p">For VQA v2 dataset the only difference in hyperparameters is the learning schedule. The model is trained for 12000 iterations with learning rate decreasing at 5000, 7000, 9000 and 11,000 iterations, following the original Pythia implementation. We also found it beneficial to apply L2 normalization after projection layer. In out-of-vocabulary experimental setting we used a subset of VQA v2 data, so the parameter were adjusted to fit the smaller dataset. Specifically, we reduced the batch size to 128 and increased the number of iterations to 30,000 with decreasing steps at 12,000, 17,000, 22,000, and 25,000 iterations.</p>
</div>
</section>
<section id="A3" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix C </span>Datasets</h2>

<section id="A3.SS0.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">GQA</h4>

<div id="A3.SS0.SSS0.Px1.p1" class="ltx_para">
<p id="A3.SS0.SSS0.Px1.p1.1" class="ltx_p">The dataset was designed as benchmark for compositional question answering over real-world images. The authors proposed new metrics for a detailed assessment of a model’s performance:</p>
<ul id="A3.I1" class="ltx_itemize">
<li id="A3.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A3.I1.i1.p1" class="ltx_para">
<p id="A3.I1.i1.p1.1" class="ltx_p"><span id="A3.I1.i1.p1.1.1" class="ltx_text ltx_font_italic">Validity</span> measures whether the predicted answer fits the scope of the question (<em id="A3.I1.i1.p1.1.2" class="ltx_emph ltx_font_italic">e.g</em>.<span id="A3.I1.i1.p1.1.3" class="ltx_text"></span> a number for a counting question).</p>
</div>
</li>
<li id="A3.I1.i2" class="ltx_item" style="list-style-type:none;padding-top:1.0pt;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A3.I1.i2.p1" class="ltx_para">
<p id="A3.I1.i2.p1.1" class="ltx_p"><span id="A3.I1.i2.p1.1.1" class="ltx_text ltx_font_italic">Plausibility</span> checks that the answer is semantically reasonable, defined as occurring at least once with the given question in the whole dataset.</p>
</div>
</li>
<li id="A3.I1.i3" class="ltx_item" style="list-style-type:none;padding-top:1.0pt;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A3.I1.i3.p1" class="ltx_para">
<p id="A3.I1.i3.p1.1" class="ltx_p"><span id="A3.I1.i3.p1.1.1" class="ltx_text ltx_font_italic">Distribution</span> is the <math id="A3.I1.i3.p1.1.m1.1" class="ltx_Math" alttext="\chi^{2}" display="inline"><semantics id="A3.I1.i3.p1.1.m1.1a"><msup id="A3.I1.i3.p1.1.m1.1.1" xref="A3.I1.i3.p1.1.m1.1.1.cmml"><mi id="A3.I1.i3.p1.1.m1.1.1.2" xref="A3.I1.i3.p1.1.m1.1.1.2.cmml">χ</mi><mn id="A3.I1.i3.p1.1.m1.1.1.3" xref="A3.I1.i3.p1.1.m1.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="A3.I1.i3.p1.1.m1.1b"><apply id="A3.I1.i3.p1.1.m1.1.1.cmml" xref="A3.I1.i3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="A3.I1.i3.p1.1.m1.1.1.1.cmml" xref="A3.I1.i3.p1.1.m1.1.1">superscript</csymbol><ci id="A3.I1.i3.p1.1.m1.1.1.2.cmml" xref="A3.I1.i3.p1.1.m1.1.1.2">𝜒</ci><cn type="integer" id="A3.I1.i3.p1.1.m1.1.1.3.cmml" xref="A3.I1.i3.p1.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.I1.i3.p1.1.m1.1c">\chi^{2}</annotation></semantics></math> distance between the distributions of predicted and ground truth answers over groups of questions. A lower value means a better ability to predict less frequent answers.</p>
</div>
</li>
<li id="A3.I1.i4" class="ltx_item" style="list-style-type:none;padding-top:1.0pt;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A3.I1.i4.p1" class="ltx_para">
<p id="A3.I1.i4.p1.1" class="ltx_p"><span id="A3.I1.i4.p1.1.1" class="ltx_text ltx_font_italic">Consistency</span> measures the agreement between answers to pairs of questions about a same image where one entails the other.</p>
</div>
</li>
<li id="A3.I1.i5" class="ltx_item" style="list-style-type:none;padding-top:1.0pt;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A3.I1.i5.p1" class="ltx_para">
<p id="A3.I1.i5.p1.1" class="ltx_p"><span id="A3.I1.i5.p1.1.1" class="ltx_text ltx_font_italic">Grounding</span> is used for evaluation of attention-based models and is not tested in our study since an attention is not the focus of this research.</p>
</div>
</li>
</ul>
<p id="A3.SS0.SSS0.Px1.p1.2" class="ltx_p">The dataset also assigns test questions to categories (Table <a href="#A3.T4" title="Table 4 ‣ GQA ‣ Appendix C Datasets ‣ Visual Question Answering with Prior Class Semantics" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>), across which the accuracy can be measured separately (as done in Table <span class="ltx_ref ltx_nolink ltx_ref_self"><span class="ltx_text ltx_ref_tag">2</span></span>).</p>
</div>
<figure id="A3.T4" class="ltx_table">
<div id="A3.T4.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:216.8pt;height:163pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-23.3pt,17.5pt) scale(0.823164752930247,0.823164752930247) ;">
<table id="A3.T4.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="A3.T4.1.1.1.1" class="ltx_tr">
<th id="A3.T4.1.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt">Type</th>
<th id="A3.T4.1.1.1.1.2" class="ltx_td ltx_nopad_r ltx_align_left ltx_th ltx_th_column ltx_border_tt">Example</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="A3.T4.1.1.2.1" class="ltx_tr">
<td id="A3.T4.1.1.2.1.1" class="ltx_td ltx_align_left ltx_border_t">Choose</td>
<td id="A3.T4.1.1.2.1.2" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_t">Is it an indoors or outdoors scene ?</td>
</tr>
<tr id="A3.T4.1.1.3.2" class="ltx_tr">
<td id="A3.T4.1.1.3.2.1" class="ltx_td ltx_align_left">Compare</td>
<td id="A3.T4.1.1.3.2.2" class="ltx_td ltx_nopad_r ltx_align_left">Are all these animals of the same type ?</td>
</tr>
<tr id="A3.T4.1.1.4.3" class="ltx_tr">
<td id="A3.T4.1.1.4.3.1" class="ltx_td ltx_align_left">Logical</td>
<td id="A3.T4.1.1.4.3.2" class="ltx_td ltx_nopad_r ltx_align_left">Are there nuts or vegetables ?</td>
</tr>
<tr id="A3.T4.1.1.5.4" class="ltx_tr">
<td id="A3.T4.1.1.5.4.1" class="ltx_td ltx_align_left">Query</td>
<td id="A3.T4.1.1.5.4.2" class="ltx_td ltx_nopad_r ltx_align_left">What is this bird called ?</td>
</tr>
<tr id="A3.T4.1.1.6.5" class="ltx_tr">
<td id="A3.T4.1.1.6.5.1" class="ltx_td ltx_align_left">Verify</td>
<td id="A3.T4.1.1.6.5.2" class="ltx_td ltx_nopad_r ltx_align_left">Is there a cat that is not white ?</td>
</tr>
<tr id="A3.T4.1.1.7.6" class="ltx_tr">
<td id="A3.T4.1.1.7.6.1" class="ltx_td ltx_align_left">Attribute</td>
<td id="A3.T4.1.1.7.6.2" class="ltx_td ltx_nopad_r ltx_align_left">What is the color of the fence made of metal ?</td>
</tr>
<tr id="A3.T4.1.1.8.7" class="ltx_tr">
<td id="A3.T4.1.1.8.7.1" class="ltx_td ltx_align_left">Category</td>
<td id="A3.T4.1.1.8.7.2" class="ltx_td ltx_nopad_r ltx_align_left">What piece of furniture is not small ?</td>
</tr>
<tr id="A3.T4.1.1.9.8" class="ltx_tr">
<td id="A3.T4.1.1.9.8.1" class="ltx_td ltx_align_left">Global</td>
<td id="A3.T4.1.1.9.8.2" class="ltx_td ltx_nopad_r ltx_align_left">Which place is it ?</td>
</tr>
<tr id="A3.T4.1.1.10.9" class="ltx_tr">
<td id="A3.T4.1.1.10.9.1" class="ltx_td ltx_align_left">Object</td>
<td id="A3.T4.1.1.10.9.2" class="ltx_td ltx_nopad_r ltx_align_left">Is there a train in the picture ?</td>
</tr>
<tr id="A3.T4.1.1.11.10" class="ltx_tr">
<td id="A3.T4.1.1.11.10.1" class="ltx_td ltx_align_left ltx_border_bb">Relation</td>
<td id="A3.T4.1.1.11.10.2" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_bb">What is the vegetable on top of the pizza ?</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 4: </span>Examples of each question type of the GQA dataset.</figcaption>
</figure>
</section>
<section id="A3.SS0.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">VQA v2 with Novel Answers</h4>

<div id="A3.SS0.SSS0.Px2.p1" class="ltx_para">
<p id="A3.SS0.SSS0.Px2.p1.1" class="ltx_p">For testing the out-of-vocabulary answer prediction, we created a subset of VQA v2 dataset. We used the original training and validation splits as our new training and test splits respectively. In each of them, we filtered the questions according to the following rules:

<span id="A3.I2" class="ltx_inline-enumerate">
<span id="A3.I2.i1" class="ltx_inline-item"><span class="ltx_tag ltx_tag_inline-item">1)</span> <span id="A3.I2.i1.1" class="ltx_text">every ground truth answer has a corresponding ConceptNet embedding (exact match),
</span></span>
<span id="A3.I2.i2" class="ltx_inline-item"><span class="ltx_tag ltx_tag_inline-item">2)</span> <span id="A3.I2.i2.1" class="ltx_text">every ground truth answer consists of one word only (<em id="A3.I2.i2.1.1" class="ltx_emph ltx_font_italic">e.g</em>.<span id="A3.I2.i2.1.2" class="ltx_text"></span> discarding <span id="A3.I2.i2.1.3" class="ltx_text ltx_font_italic">black and white</span> or <span id="A3.I2.i2.1.4" class="ltx_text ltx_font_italic">don’t know</span>),
</span></span>
<span id="A3.I2.i3" class="ltx_inline-item"><span class="ltx_tag ltx_tag_inline-item">3)</span> <span id="A3.I2.i3.1" class="ltx_text">every ground truth answer must occur in the original dataset between 5 and 500 times (thus discarding very rare and extremely frequent answers such as <span id="A3.I2.i3.1.1" class="ltx_text ltx_font_italic">yes</span> and <span id="A3.I2.i3.1.2" class="ltx_text ltx_font_italic">no</span>),
</span></span>
<span id="A3.I2.i4" class="ltx_inline-item"><span class="ltx_tag ltx_tag_inline-item">4)</span> <span id="A3.I2.i4.1" class="ltx_text">the sets of ground truth answers in the training and test splits do not intersect.
</span></span>
</span>
With this procedure, we obtain 91,255 training questions with 6,928 possible answers, and 13,367 test questions with another 1,187 answers.</p>
</div>
</section>
</section>
<section id="A4" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix D </span>Additional Results</h2>

<section id="A4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">D.1 </span>GQA</h3>

<div id="A4.SS1.p1" class="ltx_para">
<p id="A4.SS1.p1.1" class="ltx_p">We provide in Table <a href="#A4.T5" title="Table 5 ‣ D.1 GQA ‣ Appendix D Additional Results ‣ Visual Question Answering with Prior Class Semantics" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> the performance on the GQA validation set, matching the experiments provided in Table <span class="ltx_ref ltx_nolink ltx_ref_self"><span class="ltx_text ltx_ref_tag">2</span></span> of the main paper.</p>
</div>
<figure id="A4.T5" class="ltx_table">
<div id="A4.T5.4.4" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:496.9pt;height:168.5pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-43.5pt,14.7pt) scale(0.851022745368577,0.851022745368577) ;">
<table id="A4.T5.4.4.4" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="A4.T5.4.4.4.5.1" class="ltx_tr">
<th id="A4.T5.4.4.4.5.1.1" class="ltx_td ltx_th ltx_th_row ltx_border_tt"></th>
<td id="A4.T5.4.4.4.5.1.2" class="ltx_td ltx_align_center ltx_border_tt" colspan="10">GQA validation</td>
</tr>
<tr id="A4.T5.4.4.4.6.2" class="ltx_tr">
<th id="A4.T5.4.4.4.6.2.1" class="ltx_td ltx_th ltx_th_row"></th>
<td id="A4.T5.4.4.4.6.2.2" class="ltx_td ltx_align_center ltx_border_t">Choose</td>
<td id="A4.T5.4.4.4.6.2.3" class="ltx_td ltx_align_center ltx_border_t">Compare</td>
<td id="A4.T5.4.4.4.6.2.4" class="ltx_td ltx_align_center ltx_border_t">Logical</td>
<td id="A4.T5.4.4.4.6.2.5" class="ltx_td ltx_align_center ltx_border_t">Query</td>
<td id="A4.T5.4.4.4.6.2.6" class="ltx_td ltx_align_center ltx_border_t">Verify</td>
<td id="A4.T5.4.4.4.6.2.7" class="ltx_td ltx_align_center ltx_border_t">Attribute</td>
<td id="A4.T5.4.4.4.6.2.8" class="ltx_td ltx_align_center ltx_border_t">Category</td>
<td id="A4.T5.4.4.4.6.2.9" class="ltx_td ltx_align_center ltx_border_t">Global</td>
<td id="A4.T5.4.4.4.6.2.10" class="ltx_td ltx_align_center ltx_border_t">Object</td>
<td id="A4.T5.4.4.4.6.2.11" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">Relation</td>
</tr>
<tr id="A4.T5.4.4.4.7.3" class="ltx_tr">
<th id="A4.T5.4.4.4.7.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">Pythia</th>
<td id="A4.T5.4.4.4.7.3.2" class="ltx_td ltx_align_center ltx_border_t">70.64</td>
<td id="A4.T5.4.4.4.7.3.3" class="ltx_td ltx_align_center ltx_border_t"><span id="A4.T5.4.4.4.7.3.3.1" class="ltx_text ltx_font_bold">67.57</span></td>
<td id="A4.T5.4.4.4.7.3.4" class="ltx_td ltx_align_center ltx_border_t"><span id="A4.T5.4.4.4.7.3.4.1" class="ltx_text ltx_font_bold">81.66</span></td>
<td id="A4.T5.4.4.4.7.3.5" class="ltx_td ltx_align_center ltx_border_t">45.76</td>
<td id="A4.T5.4.4.4.7.3.6" class="ltx_td ltx_align_center ltx_border_t">75.86</td>
<td id="A4.T5.4.4.4.7.3.7" class="ltx_td ltx_align_center ltx_border_t">64.43</td>
<td id="A4.T5.4.4.4.7.3.8" class="ltx_td ltx_align_center ltx_border_t">56.58</td>
<td id="A4.T5.4.4.4.7.3.9" class="ltx_td ltx_align_center ltx_border_t">64.81</td>
<td id="A4.T5.4.4.4.7.3.10" class="ltx_td ltx_align_center ltx_border_t">83.69</td>
<td id="A4.T5.4.4.4.7.3.11" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">51.42</td>
</tr>
<tr id="A4.T5.4.4.4.8.4" class="ltx_tr">
<th id="A4.T5.4.4.4.8.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Pythia + GloVe</th>
<td id="A4.T5.4.4.4.8.4.2" class="ltx_td ltx_align_center">69.94</td>
<td id="A4.T5.4.4.4.8.4.3" class="ltx_td ltx_align_center">67.11</td>
<td id="A4.T5.4.4.4.8.4.4" class="ltx_td ltx_align_center">81.28</td>
<td id="A4.T5.4.4.4.8.4.5" class="ltx_td ltx_align_center">45.77</td>
<td id="A4.T5.4.4.4.8.4.6" class="ltx_td ltx_align_center">75.30</td>
<td id="A4.T5.4.4.4.8.4.7" class="ltx_td ltx_align_center">63.84</td>
<td id="A4.T5.4.4.4.8.4.8" class="ltx_td ltx_align_center">57.19</td>
<td id="A4.T5.4.4.4.8.4.9" class="ltx_td ltx_align_center">65.20</td>
<td id="A4.T5.4.4.4.8.4.10" class="ltx_td ltx_align_center">83.44</td>
<td id="A4.T5.4.4.4.8.4.11" class="ltx_td ltx_nopad_r ltx_align_center">51.22</td>
</tr>
<tr id="A4.T5.1.1.1.1" class="ltx_tr">
<th id="A4.T5.1.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">fPMC(BUTD<math id="A4.T5.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\star" display="inline"><semantics id="A4.T5.1.1.1.1.1.m1.1a"><mo id="A4.T5.1.1.1.1.1.m1.1.1" xref="A4.T5.1.1.1.1.1.m1.1.1.cmml">⋆</mo><annotation-xml encoding="MathML-Content" id="A4.T5.1.1.1.1.1.m1.1b"><ci id="A4.T5.1.1.1.1.1.m1.1.1.cmml" xref="A4.T5.1.1.1.1.1.m1.1.1">⋆</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.T5.1.1.1.1.1.m1.1c">\star</annotation></semantics></math>)</th>
<td id="A4.T5.1.1.1.1.2" class="ltx_td ltx_align_center">65.05</td>
<td id="A4.T5.1.1.1.1.3" class="ltx_td ltx_align_center">60.54</td>
<td id="A4.T5.1.1.1.1.4" class="ltx_td ltx_align_center">75.93</td>
<td id="A4.T5.1.1.1.1.5" class="ltx_td ltx_align_center">42.28</td>
<td id="A4.T5.1.1.1.1.6" class="ltx_td ltx_align_center">70.54</td>
<td id="A4.T5.1.1.1.1.7" class="ltx_td ltx_align_center">55.32</td>
<td id="A4.T5.1.1.1.1.8" class="ltx_td ltx_align_center">53.91</td>
<td id="A4.T5.1.1.1.1.9" class="ltx_td ltx_align_center">62.61</td>
<td id="A4.T5.1.1.1.1.10" class="ltx_td ltx_align_center">80.00</td>
<td id="A4.T5.1.1.1.1.11" class="ltx_td ltx_nopad_r ltx_align_center">49.45</td>
</tr>
<tr id="A4.T5.2.2.2.2" class="ltx_tr">
<th id="A4.T5.2.2.2.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">fPMC(SAN<math id="A4.T5.2.2.2.2.1.m1.1" class="ltx_Math" alttext="\star" display="inline"><semantics id="A4.T5.2.2.2.2.1.m1.1a"><mo id="A4.T5.2.2.2.2.1.m1.1.1" xref="A4.T5.2.2.2.2.1.m1.1.1.cmml">⋆</mo><annotation-xml encoding="MathML-Content" id="A4.T5.2.2.2.2.1.m1.1b"><ci id="A4.T5.2.2.2.2.1.m1.1.1.cmml" xref="A4.T5.2.2.2.2.1.m1.1.1">⋆</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.T5.2.2.2.2.1.m1.1c">\star</annotation></semantics></math>)</th>
<td id="A4.T5.2.2.2.2.2" class="ltx_td ltx_align_center">69.72</td>
<td id="A4.T5.2.2.2.2.3" class="ltx_td ltx_align_center">64.04</td>
<td id="A4.T5.2.2.2.2.4" class="ltx_td ltx_align_center">77.38</td>
<td id="A4.T5.2.2.2.2.5" class="ltx_td ltx_align_center">41.78</td>
<td id="A4.T5.2.2.2.2.6" class="ltx_td ltx_align_center">71.25</td>
<td id="A4.T5.2.2.2.2.7" class="ltx_td ltx_align_center">56.28</td>
<td id="A4.T5.2.2.2.2.8" class="ltx_td ltx_align_center">55.20</td>
<td id="A4.T5.2.2.2.2.9" class="ltx_td ltx_align_center">63.99</td>
<td id="A4.T5.2.2.2.2.10" class="ltx_td ltx_align_center">80.38</td>
<td id="A4.T5.2.2.2.2.11" class="ltx_td ltx_nopad_r ltx_align_center">50.04</td>
</tr>
<tr id="A4.T5.4.4.4.9.5" class="ltx_tr">
<th id="A4.T5.4.4.4.9.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Ours + random</th>
<td id="A4.T5.4.4.4.9.5.2" class="ltx_td ltx_align_center">71.08</td>
<td id="A4.T5.4.4.4.9.5.3" class="ltx_td ltx_align_center">67.02</td>
<td id="A4.T5.4.4.4.9.5.4" class="ltx_td ltx_align_center">81.13</td>
<td id="A4.T5.4.4.4.9.5.5" class="ltx_td ltx_align_center">46.33</td>
<td id="A4.T5.4.4.4.9.5.6" class="ltx_td ltx_align_center">75.28</td>
<td id="A4.T5.4.4.4.9.5.7" class="ltx_td ltx_align_center">63.63</td>
<td id="A4.T5.4.4.4.9.5.8" class="ltx_td ltx_align_center">56.52</td>
<td id="A4.T5.4.4.4.9.5.9" class="ltx_td ltx_align_center">65.66</td>
<td id="A4.T5.4.4.4.9.5.10" class="ltx_td ltx_align_center">83.36</td>
<td id="A4.T5.4.4.4.9.5.11" class="ltx_td ltx_nopad_r ltx_align_center">52.32</td>
</tr>
<tr id="A4.T5.4.4.4.10.6" class="ltx_tr">
<th id="A4.T5.4.4.4.10.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Ours + shuffled GloVe</th>
<td id="A4.T5.4.4.4.10.6.2" class="ltx_td ltx_align_center">74.27</td>
<td id="A4.T5.4.4.4.10.6.3" class="ltx_td ltx_align_center">66.92</td>
<td id="A4.T5.4.4.4.10.6.4" class="ltx_td ltx_align_center">81.31</td>
<td id="A4.T5.4.4.4.10.6.5" class="ltx_td ltx_align_center">46.53</td>
<td id="A4.T5.4.4.4.10.6.6" class="ltx_td ltx_align_center">75.68</td>
<td id="A4.T5.4.4.4.10.6.7" class="ltx_td ltx_align_center">64.88</td>
<td id="A4.T5.4.4.4.10.6.8" class="ltx_td ltx_align_center">56.89</td>
<td id="A4.T5.4.4.4.10.6.9" class="ltx_td ltx_align_center"><span id="A4.T5.4.4.4.10.6.9.1" class="ltx_text ltx_font_bold">65.74</span></td>
<td id="A4.T5.4.4.4.10.6.10" class="ltx_td ltx_align_center">83.54</td>
<td id="A4.T5.4.4.4.10.6.11" class="ltx_td ltx_nopad_r ltx_align_center">52.64</td>
</tr>
<tr id="A4.T5.4.4.4.11.7" class="ltx_tr">
<th id="A4.T5.4.4.4.11.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Ours + GloVe</th>
<td id="A4.T5.4.4.4.11.7.2" class="ltx_td ltx_align_center"><span id="A4.T5.4.4.4.11.7.2.1" class="ltx_text ltx_font_bold">75.36</span></td>
<td id="A4.T5.4.4.4.11.7.3" class="ltx_td ltx_align_center">67.33</td>
<td id="A4.T5.4.4.4.11.7.4" class="ltx_td ltx_align_center">81.60</td>
<td id="A4.T5.4.4.4.11.7.5" class="ltx_td ltx_align_center"><span id="A4.T5.4.4.4.11.7.5.1" class="ltx_text ltx_font_bold">46.99</span></td>
<td id="A4.T5.4.4.4.11.7.6" class="ltx_td ltx_align_center"><span id="A4.T5.4.4.4.11.7.6.1" class="ltx_text ltx_font_bold">76.58</span></td>
<td id="A4.T5.4.4.4.11.7.7" class="ltx_td ltx_align_center"><span id="A4.T5.4.4.4.11.7.7.1" class="ltx_text ltx_font_bold">66.21</span></td>
<td id="A4.T5.4.4.4.11.7.8" class="ltx_td ltx_align_center"><span id="A4.T5.4.4.4.11.7.8.1" class="ltx_text ltx_font_bold">57.23</span></td>
<td id="A4.T5.4.4.4.11.7.9" class="ltx_td ltx_align_center">65.58</td>
<td id="A4.T5.4.4.4.11.7.10" class="ltx_td ltx_align_center"><span id="A4.T5.4.4.4.11.7.10.1" class="ltx_text ltx_font_bold">83.71</span></td>
<td id="A4.T5.4.4.4.11.7.11" class="ltx_td ltx_nopad_r ltx_align_center"><span id="A4.T5.4.4.4.11.7.11.1" class="ltx_text ltx_font_bold">52.94</span></td>
</tr>
<tr id="A4.T5.3.3.3.3" class="ltx_tr">
<th id="A4.T5.3.3.3.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">Ensemble: 5<math id="A4.T5.3.3.3.3.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="A4.T5.3.3.3.3.1.m1.1a"><mo id="A4.T5.3.3.3.3.1.m1.1.1" xref="A4.T5.3.3.3.3.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="A4.T5.3.3.3.3.1.m1.1b"><times id="A4.T5.3.3.3.3.1.m1.1.1.cmml" xref="A4.T5.3.3.3.3.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="A4.T5.3.3.3.3.1.m1.1c">\times</annotation></semantics></math> Pythia</th>
<td id="A4.T5.3.3.3.3.2" class="ltx_td ltx_align_center ltx_border_t">73.65</td>
<td id="A4.T5.3.3.3.3.3" class="ltx_td ltx_align_center ltx_border_t"><span id="A4.T5.3.3.3.3.3.1" class="ltx_text ltx_font_bold">69.40</span></td>
<td id="A4.T5.3.3.3.3.4" class="ltx_td ltx_align_center ltx_border_t">82.92</td>
<td id="A4.T5.3.3.3.3.5" class="ltx_td ltx_align_center ltx_border_t">48.41</td>
<td id="A4.T5.3.3.3.3.6" class="ltx_td ltx_align_center ltx_border_t">77.23</td>
<td id="A4.T5.3.3.3.3.7" class="ltx_td ltx_align_center ltx_border_t">67.48</td>
<td id="A4.T5.3.3.3.3.8" class="ltx_td ltx_align_center ltx_border_t">58.77</td>
<td id="A4.T5.3.3.3.3.9" class="ltx_td ltx_align_center ltx_border_t">65.90</td>
<td id="A4.T5.3.3.3.3.10" class="ltx_td ltx_align_center ltx_border_t">84.71</td>
<td id="A4.T5.3.3.3.3.11" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">53.48</td>
</tr>
<tr id="A4.T5.4.4.4.4" class="ltx_tr">
<th id="A4.T5.4.4.4.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb">Ensemble: 5<math id="A4.T5.4.4.4.4.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="A4.T5.4.4.4.4.1.m1.1a"><mo id="A4.T5.4.4.4.4.1.m1.1.1" xref="A4.T5.4.4.4.4.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="A4.T5.4.4.4.4.1.m1.1b"><times id="A4.T5.4.4.4.4.1.m1.1.1.cmml" xref="A4.T5.4.4.4.4.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="A4.T5.4.4.4.4.1.m1.1c">\times</annotation></semantics></math> Ours + GloVe</th>
<td id="A4.T5.4.4.4.4.2" class="ltx_td ltx_align_center ltx_border_bb"><span id="A4.T5.4.4.4.4.2.1" class="ltx_text ltx_font_bold">79.28</span></td>
<td id="A4.T5.4.4.4.4.3" class="ltx_td ltx_align_center ltx_border_bb">69.33</td>
<td id="A4.T5.4.4.4.4.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="A4.T5.4.4.4.4.4.1" class="ltx_text ltx_font_bold">83.08</span></td>
<td id="A4.T5.4.4.4.4.5" class="ltx_td ltx_align_center ltx_border_bb"><span id="A4.T5.4.4.4.4.5.1" class="ltx_text ltx_font_bold">49.48</span></td>
<td id="A4.T5.4.4.4.4.6" class="ltx_td ltx_align_center ltx_border_bb"><span id="A4.T5.4.4.4.4.6.1" class="ltx_text ltx_font_bold">78.65</span></td>
<td id="A4.T5.4.4.4.4.7" class="ltx_td ltx_align_center ltx_border_bb"><span id="A4.T5.4.4.4.4.7.1" class="ltx_text ltx_font_bold">69.38</span></td>
<td id="A4.T5.4.4.4.4.8" class="ltx_td ltx_align_center ltx_border_bb"><span id="A4.T5.4.4.4.4.8.1" class="ltx_text ltx_font_bold">58.83</span></td>
<td id="A4.T5.4.4.4.4.9" class="ltx_td ltx_align_center ltx_border_bb"><span id="A4.T5.4.4.4.4.9.1" class="ltx_text ltx_font_bold">66.54</span></td>
<td id="A4.T5.4.4.4.4.10" class="ltx_td ltx_align_center ltx_border_bb"><span id="A4.T5.4.4.4.4.10.1" class="ltx_text ltx_font_bold">85.09</span></td>
<td id="A4.T5.4.4.4.4.11" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb"><span id="A4.T5.4.4.4.4.11.1" class="ltx_text ltx_font_bold">55.37</span></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 5: </span>Performance for different question types (accuracy in %) on the GQA validation split.</figcaption>
</figure>
</section>
<section id="A4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">D.2 </span>VQA v2</h3>

<figure id="A4.T6" class="ltx_table">
<div id="A4.T6.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:447.2pt;height:80pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-28.0pt,5.0pt) scale(0.888533593596862,0.888533593596862) ;">
<table id="A4.T6.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="A4.T6.1.1.1.1" class="ltx_tr">
<th id="A4.T6.1.1.1.1.1" class="ltx_td ltx_th ltx_th_row ltx_border_tt"></th>
<th id="A4.T6.1.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="4">VQA v2 validation</th>
<th id="A4.T6.1.1.1.1.3" class="ltx_td ltx_th ltx_th_column ltx_border_tt"></th>
<th id="A4.T6.1.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="4">VQA v2 test-dev</th>
</tr>
<tr id="A4.T6.1.1.2.2" class="ltx_tr">
<th id="A4.T6.1.1.2.2.1" class="ltx_td ltx_th ltx_th_row"></th>
<th id="A4.T6.1.1.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">Yes/No</th>
<th id="A4.T6.1.1.2.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">Number</th>
<th id="A4.T6.1.1.2.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">Other</th>
<th id="A4.T6.1.1.2.2.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">All</th>
<th id="A4.T6.1.1.2.2.6" class="ltx_td ltx_th ltx_th_column"></th>
<th id="A4.T6.1.1.2.2.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">Yes/No</th>
<th id="A4.T6.1.1.2.2.8" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">Number</th>
<th id="A4.T6.1.1.2.2.9" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">Other</th>
<th id="A4.T6.1.1.2.2.10" class="ltx_td ltx_nopad_r ltx_align_center ltx_th ltx_th_column">All</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="A4.T6.1.1.3.1" class="ltx_tr">
<th id="A4.T6.1.1.3.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">Pythia</th>
<td id="A4.T6.1.1.3.1.2" class="ltx_td ltx_align_center ltx_border_t"><span id="A4.T6.1.1.3.1.2.1" class="ltx_text ltx_font_bold">83.11</span></td>
<td id="A4.T6.1.1.3.1.3" class="ltx_td ltx_align_center ltx_border_t">44.50</td>
<td id="A4.T6.1.1.3.1.4" class="ltx_td ltx_align_center ltx_border_t">56.86</td>
<td id="A4.T6.1.1.3.1.5" class="ltx_td ltx_align_center ltx_border_t">65.11</td>
<td id="A4.T6.1.1.3.1.6" class="ltx_td ltx_border_t"></td>
<td id="A4.T6.1.1.3.1.7" class="ltx_td ltx_align_center ltx_border_t"><span id="A4.T6.1.1.3.1.7.1" class="ltx_text ltx_font_bold">83.42</span></td>
<td id="A4.T6.1.1.3.1.8" class="ltx_td ltx_align_center ltx_border_t">45.53</td>
<td id="A4.T6.1.1.3.1.9" class="ltx_td ltx_align_center ltx_border_t">57.13</td>
<td id="A4.T6.1.1.3.1.10" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">66.64</td>
</tr>
<tr id="A4.T6.1.1.4.2" class="ltx_tr">
<th id="A4.T6.1.1.4.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Ours + GloVe</th>
<td id="A4.T6.1.1.4.2.2" class="ltx_td ltx_align_center">82.90</td>
<td id="A4.T6.1.1.4.2.3" class="ltx_td ltx_align_center"><span id="A4.T6.1.1.4.2.3.1" class="ltx_text ltx_font_bold">44.68</span></td>
<td id="A4.T6.1.1.4.2.4" class="ltx_td ltx_align_center">56.93</td>
<td id="A4.T6.1.1.4.2.5" class="ltx_td ltx_align_center">65.08</td>
<td id="A4.T6.1.1.4.2.6" class="ltx_td"></td>
<td id="A4.T6.1.1.4.2.7" class="ltx_td ltx_align_center">83.33</td>
<td id="A4.T6.1.1.4.2.8" class="ltx_td ltx_align_center">45.46</td>
<td id="A4.T6.1.1.4.2.9" class="ltx_td ltx_align_center">57.18</td>
<td id="A4.T6.1.1.4.2.10" class="ltx_td ltx_nopad_r ltx_align_center">66.62</td>
</tr>
<tr id="A4.T6.1.1.5.3" class="ltx_tr">
<th id="A4.T6.1.1.5.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb">Ours + GloVe (w/o fine-tuning)</th>
<td id="A4.T6.1.1.5.3.2" class="ltx_td ltx_align_center ltx_border_bb">82.87</td>
<td id="A4.T6.1.1.5.3.3" class="ltx_td ltx_align_center ltx_border_bb">44.55</td>
<td id="A4.T6.1.1.5.3.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="A4.T6.1.1.5.3.4.1" class="ltx_text ltx_font_bold">57.19</span></td>
<td id="A4.T6.1.1.5.3.5" class="ltx_td ltx_align_center ltx_border_bb"><span id="A4.T6.1.1.5.3.5.1" class="ltx_text ltx_font_bold">65.18</span></td>
<td id="A4.T6.1.1.5.3.6" class="ltx_td ltx_border_bb"></td>
<td id="A4.T6.1.1.5.3.7" class="ltx_td ltx_align_center ltx_border_bb">83.20</td>
<td id="A4.T6.1.1.5.3.8" class="ltx_td ltx_align_center ltx_border_bb"><span id="A4.T6.1.1.5.3.8.1" class="ltx_text ltx_font_bold">45.54</span></td>
<td id="A4.T6.1.1.5.3.9" class="ltx_td ltx_align_center ltx_border_bb"><span id="A4.T6.1.1.5.3.9.1" class="ltx_text ltx_font_bold">57.53</span></td>
<td id="A4.T6.1.1.5.3.10" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb"><span id="A4.T6.1.1.5.3.10.1" class="ltx_text ltx_font_bold">66.74</span></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 6: </span>Accuracy (%) on VQA v2 validation and test-dev sets. Our model with fixed (not fine-tuned) GloVe embeddings shows the highest results on the category <span id="A4.T6.3.1" class="ltx_text ltx_font_italic">other</span> and on all questions overall for both splits.</figcaption>
</figure>
<div id="A4.SS2.p1" class="ltx_para">
<p id="A4.SS2.p1.1" class="ltx_p">We present experiments on the VQA v2 dataset in Table <a href="#A4.T6" title="Table 6 ‣ D.2 VQA v2 ‣ Appendix D Additional Results ‣ Visual Question Answering with Prior Class Semantics" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>. Contrary to our results on GQA, we observe no significant difference compared to the baseline. We attribute this to the nature of the dataset.
In VQA v2, a large fraction of the questions (over 37%) are to be answered with <span id="A4.SS2.p1.1.1" class="ltx_text ltx_font_italic">yes</span> or <span id="A4.SS2.p1.1.2" class="ltx_text ltx_font_italic">no</span>, and another 13% with a number.
Our approach, which focuses on the representation of answer semantics, is already expected to have no influence on this large part of the dataset.
Moreover, numbers in VQA v2 are used not only for counting questions, but also to refer to abstract concepts, as in questions like <span id="A4.SS2.p1.1.3" class="ltx_text ltx_font_italic">How old is animal ?</span>, <span id="A4.SS2.p1.1.4" class="ltx_text ltx_font_italic">What time is the clock showing ?</span>, or <span id="A4.SS2.p1.1.5" class="ltx_text ltx_font_italic">What is the size of the TV ?</span>. It would certainly be difficult to infer a single representation of numbers that would encompass such a variety of concepts.</p>
</div>
<div id="A4.SS2.p2" class="ltx_para">
<p id="A4.SS2.p2.1" class="ltx_p">An additional challenge with VQA v2 is that most questions have multiple ground truth answers that are actually synonyms. Other times, annotation noise means that multiple answers with contradictory meanings are marked as correct. For example, a question <span id="A4.SS2.p2.1.1" class="ltx_text ltx_font_italic">Is the dog male or female ?</span> has both <span id="A4.SS2.p2.1.2" class="ltx_text ltx_font_italic">male</span> and <span id="A4.SS2.p2.1.3" class="ltx_text ltx_font_italic">female</span> answers in the annotation. In our model, all ground truth answers contribute equally to the projection loss, meaning that noisy or incorrect answer labels can push the learned projection in wrong directions. This issue could be mitigated by introducing instance-specific weights in the projection loss. This is an interesting avenue for future work.</p>
</div>
<div id="A4.SS2.p3" class="ltx_para">
<p id="A4.SS2.p3.1" class="ltx_p">Overall, our approach still has a positive impact on VQA v2 for out-of-vocabulary prediction (see Section <span class="ltx_ref ltx_nolink ltx_ref_self"><span class="ltx_text ltx_ref_tag">4.4</span></span>). And importantly, the above issues did not incur a decrease in performance compared to the baseline model.</p>
</div>
</section>
<section id="A4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">D.3 </span>Learned Representations</h3>

<div id="A4.SS3.p1" class="ltx_para">
<p id="A4.SS3.p1.1" class="ltx_p">We use t-SNE projections to visualize and compare off-the-shelf GloVe embeddings of candidate answers, which we use as prior knowledge to initialize the representations, with these representations after fine-tuning within our VQA model. As expected, the GloVe embeddings carry the kind of semantic similarity that emerges from co-occurrence of words in natural language. In the fine-tuned representations, we rather observe that the proximity of representations captures common co-occurrences of concepts in a same image, such that they are plausible answers to possible questions about this image. For example, the word <span id="A4.SS3.p1.1.1" class="ltx_text ltx_font_italic">steak</span> is projected close to the words {<span id="A4.SS3.p1.1.2" class="ltx_text ltx_font_italic">potato</span>, <span id="A4.SS3.p1.1.3" class="ltx_text ltx_font_italic">carrot</span>, <span id="A4.SS3.p1.1.4" class="ltx_text ltx_font_italic">broccoli</span>, <span id="A4.SS3.p1.1.5" class="ltx_text ltx_font_italic">tomato</span>, <span id="A4.SS3.p1.1.6" class="ltx_text ltx_font_italic">pickles</span>} (Fig. <a href="#A4.F6" title="Figure 6 ‣ D.3 Learned Representations ‣ Appendix D Additional Results ‣ Visual Question Answering with Prior Class Semantics" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> (b)). We indeed observe co-occurrence of these objects in images from the GQA dataset (Fig. <a href="#A4.F6" title="Figure 6 ‣ D.3 Learned Representations ‣ Appendix D Additional Results ‣ Visual Question Answering with Prior Class Semantics" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> (c)).</p>
</div>
<figure id="A4.F6" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="A4.F6.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2005.01239/assets/x6.png" id="A4.F6.sf1.g1" class="ltx_graphics ltx_img_landscape" width="207" height="155" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="A4.F6.sf1.2.1.1" class="ltx_text" style="font-size:80%;">(a)</span> </span><span id="A4.F6.sf1.3.2" class="ltx_text" style="font-size:80%;">GloVe embeddings.</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="A4.F6.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2005.01239/assets/x7.png" id="A4.F6.sf2.g1" class="ltx_graphics ltx_img_landscape" width="207" height="155" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="A4.F6.sf2.2.1.1" class="ltx_text" style="font-size:80%;">(b)</span> </span><span id="A4.F6.sf2.3.2" class="ltx_text" style="font-size:80%;">Learned answer representations.</span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="A4.F6.sf3" class="ltx_figure ltx_figure_panel ltx_align_center">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2005.01239/assets/figures/steak1.jpg" id="A4.F6.sf3.g1" class="ltx_graphics ltx_figure_panel ltx_img_landscape" width="269" height="203" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2005.01239/assets/figures/steak2.jpg" id="A4.F6.sf3.g2" class="ltx_graphics ltx_figure_panel ltx_img_landscape" width="269" height="202" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="A4.F6.sf3.2.1.1" class="ltx_text" style="font-size:80%;">(c)</span> </span><span id="A4.F6.sf3.3.2" class="ltx_text" style="font-size:80%;">Example images from the GQA dataset.</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>Examples of t-SNE projections in 2D of (a) initial and (b) fine-tuned representations of answers. The proximity of the learned representations better captures typical co-occurrences of the corresponding concepts in images from the dataset (c).</figcaption>
</figure>
</section>
<section id="A4.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">D.4 </span>Prediction of Novel Answers</h3>

<figure id="A4.F7" class="ltx_figure"><img src="/html/2005.01239/assets/x8.png" id="A4.F7.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="528" height="337" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7: </span>Examples of out-of-vocabulary predictions. The model works well when the ground truth answer has a clear and distinct pretrained embedding (top row), but fails to distinguish between synonymous answers (bottom row).</figcaption>
</figure>
<div id="A4.SS4.p1" class="ltx_para">
<p id="A4.SS4.p1.1" class="ltx_p">We analyzed the predicted answers in out-of-vocabulary test setting to discover the cause of reduced performance and possible ways for improvement (Fig. <a href="#A4.F7" title="Figure 7 ‣ D.4 Prediction of Novel Answers ‣ Appendix D Additional Results ‣ Visual Question Answering with Prior Class Semantics" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>). The reason for many failure cases is due to synonymous and/or related answers. When the representations of multiple candidate answers are close in the semantic space, it is difficult for the model to distinguish them, especially when they are both plausible for a given question.</p>
</div>
<div id="A4.SS4.p2" class="ltx_para">
<p id="A4.SS4.p2.1" class="ltx_p">Another important factor in the success of our method is how well the semantic space is covered by answers seen during training. For example, if the training questions all have similar answers, <em id="A4.SS4.p2.1.1" class="ltx_emph ltx_font_italic">e.g</em>.<span id="A4.SS4.p2.1.2" class="ltx_text"></span> different animal species, the model could generalize well to novel animals, but not as well to anything outside these. In otherwords, the model is perfectly capable of interpolation, but extrapolation remains a challenge.</p>
</div>
<div id="A4.SS4.p3" class="ltx_para">
<p id="A4.SS4.p3.1" class="ltx_p">The VQA v2 dataset was not originally designed to test the out-of-vocabulary prediction, and existing attempts to repurpose it (<em id="A4.SS4.p3.1.1" class="ltx_emph ltx_font_italic">e.g</em>.<span id="A4.SS4.p3.1.2" class="ltx_text"></span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>) all have notable issues. For our experiments, we created our own splits with novel answers in the test split, but we made no particular provision for an “even” coverage of semantic concepts with the training answers. These considerations suggest the need for a specific benchmark to allow a more rigorous evaluation of models designed for out-of-vocabulary and “zero-shot” VQA.</p>
</div>
</section>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2005.01237" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2005.01239" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2005.01239">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2005.01239" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2005.01240" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Mon Feb 26 19:53:27 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
