<article class="ltx_document ltx_authors_1line">
 <div class="ltx_para" id="p1">
  <span class="ltx_ERROR undefined" id="p1.1">
   \setlength
  </span>
  <p class="ltx_p" id="p1.2">
   2em
  </p>
 </div>
 <h1 class="ltx_title ltx_title_document">
  Large Language Model Enhanced Multi-Agent Systems for 6G Communications
 </h1>
 <div class="ltx_authors">
  <span class="ltx_creator ltx_role_author">
   <span class="ltx_personname">
    Feibo Jiang,
    <span class="ltx_text ltx_font_italic" id="id1.1.id1">
     Member, IEEE
    </span>
    , Li Dong, Yubo Peng, Kezhi Wang,
    <span class="ltx_text ltx_font_italic" id="id2.2.id2">
     Senior Member, IEEE
    </span>
    , Kun Yang,
    <span class="ltx_text ltx_font_italic" id="id3.3.id3">
     Fellow, IEEE
    </span>
    , Cunhua Pan,
    <span class="ltx_text ltx_font_italic" id="id4.4.id4">
     Senior Member, IEEE
    </span>
    , Dusit Niyato,
    <span class="ltx_text ltx_font_italic" id="id5.5.id5">
     Fellow, IEEE
    </span>
    , Octavia A. Dobre,
    <span class="ltx_text ltx_font_italic" id="id6.6.id6">
     Fellow, IEEE
    </span>
   </span>
  </span>
 </div>
 <div class="ltx_abstract">
  <h6 class="ltx_title ltx_title_abstract">
   Abstract
  </h6>
  <p class="ltx_p" id="id7.id1">
   The rapid development of the Large Language Model (LLM) presents huge opportunities for 6G communications, e.g., network optimization and management by allowing users to input task requirements to LLMs by nature language. However, directly applying native LLMs in 6G encounters various challenges, such as a lack of private communication data and knowledge, limited logical reasoning, evaluation, and refinement abilities.
Integrating LLMs with the capabilities of retrieval, planning, memory, evaluation and reflection in agents can greatly enhance the potential of LLMs for 6G communications. To this end, we propose a multi-agent system with customized communication knowledge and tools for solving communication related tasks using natural language, comprising three components:
(1) Multi-agent Data Retrieval (MDR), which employs the condensate and inference agents to refine and summarize communication knowledge from the knowledge base, expanding the knowledge boundaries of LLMs in 6G communications;
(2) Multi-agent Collaborative Planning (MCP), which utilizes multiple planning agents to generate feasible solutions for the communication related task from different perspectives based on the retrieved knowledge;
(3) Multi-agent Evaluation and Reflecxion (MER), which utilizes the evaluation agent to assess the solutions, and applies the reflexion agent and refinement agent to provide improvement suggestions for current solutions.
Finally, we validate the effectiveness of the proposed multi-agent system by designing a semantic communication system, as a case study of 6G communications.
  </p>
 </div>
 <div class="ltx_keywords">
  <h6 class="ltx_title ltx_title_keywords">
   Index Terms:
  </h6>
  Large language model, Multi-agent system, Semantic communications, GPT, 6G communications.
 </div>
 <section class="ltx_section" id="S1">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    I
   </span>
   <span class="ltx_text ltx_font_smallcaps" id="S1.1.1">
    Introduction
   </span>
  </h2>
  <div class="ltx_para" id="S1.p1">
   <p class="ltx_p" id="S1.p1.1">
    The future generation of wireless communication, e.g., 6G, is anticipated to provide exceptional data rates, ultra-low latency, and significantly enhanced capacity to accommodate a massive number of user devices. To support the above vision, several innovative techniques such as edge intelligence and Semantic Communication (SC) have been proposed, where Artificial Intelligence (AI)/Machine Learning (ML) has been applied as a key enabling technology. However, the current intelligent communication system design is mainly based on the traditional AI/ML that can be seen as a discriminative AI technique that faces the following challenges, when applied in 6G communications.
   </p>
  </div>
  <section class="ltx_subsection" id="S1.SS1">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     <span class="ltx_text" id="S1.SS1.4.1.1">
      I-A
     </span>
    </span>
    <span class="ltx_text ltx_font_italic" id="S1.SS1.5.2">
     Challenges of discriminative AI for 6G
    </span>
   </h3>
   <section class="ltx_subsubsection" id="S1.SS1.SSS1">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      <span class="ltx_text" id="S1.SS1.SSS1.4.1.1">
       I-A
      </span>
      1
     </span>
     For dynamic environments
    </h4>
    <div class="ltx_para" id="S1.SS1.SSS1.p1">
     <p class="ltx_p" id="S1.SS1.SSS1.p1.1">
      Future communication systems are expected to operate in rapidly changing environments, due to a variety of factors, such as the movement of devices and network traffic fluctuations. However, the traditional discriminative AI/ML mainly relies on learning local features, leading to trapping local extreme values or having difficulties in learning the long-term dependency of the dynamic network as well as achieving stable operation in a scalable way. Large AI Models (LAMs), as state-of-the-art pretrained foundation models, utilizing multi-head attention mechanisms with even trillions of parameters, enable capturing of a large number of features from a global perspective, which allows the system to achieve a global optimal solution effectively, regardless of how the system changes.
     </p>
    </div>
   </section>
   <section class="ltx_subsubsection" id="S1.SS1.SSS2">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      <span class="ltx_text" id="S1.SS1.SSS2.4.1.1">
       I-A
      </span>
      2
     </span>
     For heterogeneous devices
    </h4>
    <div class="ltx_para" id="S1.SS1.SSS2.p1">
     <p class="ltx_p" id="S1.SS1.SSS2.p1.1">
      Future communication systems will support a variety of devices, e.g., Internet of Things (IoT) or Unnamed Aerial Vehicles (UAVs), as well as provide various management strategies, like beamforming design, user association, and edge resource allocation. However, the traditional discriminative AI/ML is mainly based on learning task specific features, e.g., only focusing on one type of task. However, LAMs, on the other hand, trained on various types of data and tasks, can be seen as universal models, allowing the same trained model to address different kinds of tasks, e.g., through prompting or fine-tuning processes.
     </p>
    </div>
   </section>
   <section class="ltx_subsubsection" id="S1.SS1.SSS3">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      <span class="ltx_text" id="S1.SS1.SSS3.4.1.1">
       I-A
      </span>
      3
     </span>
     For different applications
    </h4>
    <div class="ltx_para" id="S1.SS1.SSS3.p1">
     <p class="ltx_p" id="S1.SS1.SSS3.p1.1">
      Future communication systems need to provide customized solutions for different application scenarios, such as Virtual Reality (VR) and Augmented Reality (AR). For example, in autonomous driving services, the system requires extremely low latency and high reliability transmission, whereas in IoT applications, it must support a massive number of connections. Traditional discriminative AI/ML consists of small models trained for specific application scenarios, limiting them to those particular contexts. In contrast, LAMs possess astounding understanding and creativity and can comprehend and adapt to various application scenarios, allowing them to provide personalized services for different applications.
     </p>
    </div>
   </section>
  </section>
  <section class="ltx_subsection" id="S1.SS2">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     <span class="ltx_text" id="S1.SS2.4.1.1">
      I-B
     </span>
    </span>
    <span class="ltx_text ltx_font_italic" id="S1.SS2.5.2">
     Opportunities of generative AI for 6G
    </span>
   </h3>
   <div class="ltx_para" id="S1.SS2.p1">
    <p class="ltx_p" id="S1.SS2.p1.1">
     LAMs offer an entirely new paradigm for solving the above-mentioned challenges
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib1" title="">
       1
      </a>
      ]
     </cite>
     . LAMs represent a significant advancement in generative AI, leveraging their immense size, extensive computational requirements, and vast amounts of training data to achieve state-of-the-art performance in various tasks. Their ability to understand intent and generate solutions opens up new possibilities for improving a wide range of applications for 6G communications. LAMs have the potential to revolutionize how we interact with and utilize AI in networks. The main features of LAMs are as follows:
    </p>
   </div>
   <section class="ltx_subsubsection" id="S1.SS2.SSS1">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      <span class="ltx_text" id="S1.SS2.SSS1.4.1.1">
       I-B
      </span>
      1
     </span>
     Multi-head self-attention
    </h4>
    <div class="ltx_para" id="S1.SS2.SSS1.p1">
     <p class="ltx_p" id="S1.SS2.SSS1.p1.1">
      Multi-head self-attention allows LAMs to focus on the global perspective and it can analyze and capture spatio-temporal dependencies in changing environments at different scales. This mechanism enables the LAM to generate stable and timely responses, unlike traditional recurrent neural networks that require retraining to adapt to environmental changes.
For example, the multi-head attention enables comprehensive learning of dynamic factors in the network, such as user mobility and traffic fluctuations. This mechanism avoids the long-term forgetting effect caused by dynamic environments, leading to accurate traffic prediction and optimal resource allocation.
     </p>
    </div>
   </section>
   <section class="ltx_subsubsection" id="S1.SS2.SSS2">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      <span class="ltx_text" id="S1.SS2.SSS2.4.1.1">
       I-B
      </span>
      2
     </span>
     Universal task model
    </h4>
    <div class="ltx_para" id="S1.SS2.SSS2.p1">
     <p class="ltx_p" id="S1.SS2.SSS2.p1.1">
      LAMs typically have an extensive number of parameters, which can range from tens of billions to trillions. The large number of parameters allows LAMs to capture intricate network patterns and nuances between heterogeneous devices and imbalance data during training. For example, by learning the Channel State Information (CSI), the constraints for computation, communication, and storage resources of various edge devices and edge servers, it is possible to design a universal offloading model that achieves offloading optimization and resource scheduling for different system models or optimization objectives using prompts, without the need for retraining the model.
     </p>
    </div>
   </section>
   <section class="ltx_subsubsection" id="S1.SS2.SSS3">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      <span class="ltx_text" id="S1.SS2.SSS3.4.1.1">
       I-B
      </span>
      3
     </span>
     Astounding understanding and creativity
    </h4>
    <div class="ltx_para" id="S1.SS2.SSS3.p1">
     <p class="ltx_p" id="S1.SS2.SSS3.p1.1">
      LAMs have demonstrated remarkable abilities that go beyond analyzing and generating human language. These abilities stem from the vast amount of knowledge and patterns they acquire during training.
Based on its exceptional understanding capabilities, LAM can proactively analyze user demands and preferences in 6G networks, enabling the provision of personalized computing and communication services. Leveraging its astonishing creativity, LAM can dynamically plan, configure, and optimize the future communication network through self-learning and self-adaptation abilities.
     </p>
    </div>
   </section>
  </section>
  <section class="ltx_subsection" id="S1.SS3">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     <span class="ltx_text" id="S1.SS3.4.1.1">
      I-C
     </span>
    </span>
    <span class="ltx_text ltx_font_italic" id="S1.SS3.5.2">
     Contributions
    </span>
   </h3>
   <div class="ltx_para" id="S1.SS3.p1">
    <p class="ltx_p" id="S1.SS3.p1.1">
     In the article,
we describe the possible roles of Large Language Models (LLMs) and how to unleash their potential in future communication networks. To overcome the current challenges of applying LLMs to 6G, we propose an LLM-enhanced multi-agent system with customized communication knowledge and tools, which leverages collaboration and interaction among multiple agents to optimize the task-solving capabilities in 6G networks. Specifically, users express their task requirements by natural language firstly. Then, the Multi-agent Data Retrieval (MDR) is proposed to query and summarize domain-specific knowledge in 6G communications from private data. Next, a novel Multi-agent Collaborative Planning (MCP) decomposes the original task based on retrieved communication knowledge, generates multiple feasible sub-task chains, and solves them. Subsequently, the Multi-agent Evaluation and Reflexion (MER) is proposed to evaluate, reflect, and improve the current feasible solutions. As a whole, these form a self-learning and adaptive multi-agent system for solving communication-related problems by natural language. Finally, we validate the effectiveness of the multi-agent system through a case study.
    </p>
   </div>
  </section>
 </section>
 <section class="ltx_section" id="S2">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    II
   </span>
   <span class="ltx_text ltx_font_smallcaps" id="S2.1.1">
    How LLMs Support 6G Communications
   </span>
  </h2>
  <div class="ltx_para" id="S2.p1">
   <p class="ltx_p" id="S2.p1.1">
    LLMs constitute the most significant category of LAMs. On one hand, LLMs exhibit stronger comprehension, decision-making, and robustness compared to traditional ML models widely used in wireless networks. This higher level of intelligence brings new opportunities for sensor, communication, and computation in 6G wireless networks, enabling efficient and scalable general-purpose wireless intelligence. On the other hand, the massive and diverse wireless data, along with ubiquitous wireless devices in 6G wireless networks, provide powerful support in terms of data and computational resources for LLMs
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib1" title="">
      1
     </a>
     ]
    </cite>
    . Therefore, the application of LLMs to enhance the intrinsic intelligence of 6G networks holds significant importance.
   </p>
  </div>
  <section class="ltx_subsection" id="S2.SS1">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     <span class="ltx_text" id="S2.SS1.4.1.1">
      II-A
     </span>
    </span>
    <span class="ltx_text ltx_font_italic" id="S2.SS1.5.2">
     The roles of LLMs in 6G communications
    </span>
   </h3>
   <div class="ltx_para" id="S2.SS1.p1">
    <p class="ltx_p" id="S2.SS1.p1.1">
     In 6G communications, LLMs can play the following roles and fulfill functions as:
    </p>
   </div>
   <section class="ltx_subsubsection" id="S2.SS1.SSS1">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      <span class="ltx_text" id="S2.SS1.SSS1.4.1.1">
       II-A
      </span>
      1
     </span>
     Data generator
    </h4>
    <div class="ltx_para" id="S2.SS1.SSS1.p1">
     <p class="ltx_p" id="S2.SS1.SSS1.p1.1">
      LLM is a powerful generative AI, which can generate specific types of data based on their domain knowledge. Some novel generative structures (e.g., autoregression decoder and diffusion model) are introduced to LLMs for creating data efficiently. For instance, LLMs can generate high-quality synthetic CSI data without identification information for network optimization, encompassing aspects such as positioning, bandwidth allocation, and network architecture design. This data can assist operators in more effectively planning and developing their 6G networks without violating privacy.
     </p>
    </div>
   </section>
   <section class="ltx_subsubsection" id="S2.SS1.SSS2">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      <span class="ltx_text" id="S2.SS1.SSS2.4.1.1">
       II-A
      </span>
      2
     </span>
     Knowledge organizer
    </h4>
    <div class="ltx_para" id="S2.SS1.SSS2.p1">
     <p class="ltx_p" id="S2.SS1.SSS2.p1.1">
      LLMs can reprocess or mine raw data for knowledge extraction and analysis, which take both user requirements and raw data processed as input and utilize the extensive domain knowledge of LLMs to deduce new information. For example, LLMs can be introduced as the knowledge base to assist the encoder of SC and can reduce ambiguity and enhance semantic understandings
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib2" title="">
        2
       </a>
       ]
      </cite>
      .
     </p>
    </div>
   </section>
   <section class="ltx_subsubsection" id="S2.SS1.SSS3">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      <span class="ltx_text" id="S2.SS1.SSS3.4.1.1">
       II-A
      </span>
      3
     </span>
     Task scheduler
    </h4>
    <div class="ltx_para" id="S2.SS1.SSS3.p1">
     <p class="ltx_p" id="S2.SS1.SSS3.p1.1">
      LLMs can understand instructions and schedule algorithms or protocols to collectively address complicated communication tasks. By using LLMs as a bridge between communication requirement and solutions, LLMs can manage and invoke proper algorithms, and collaboratively fulfill task requirements while producing results. For instance, LLMs can autonomously allocate service areas to different UAVs, plan their trajectories, guide UAVs to avoid obstacles, and provide critical communication links and computational resources in emergency environment
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib3" title="">
        3
       </a>
       ]
      </cite>
      .
     </p>
    </div>
   </section>
   <section class="ltx_subsubsection" id="S2.SS1.SSS4">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      <span class="ltx_text" id="S2.SS1.SSS4.4.1.1">
       II-A
      </span>
      4
     </span>
     System designer
    </h4>
    <div class="ltx_para" id="S2.SS1.SSS4.p1">
     <p class="ltx_p" id="S2.SS1.SSS4.p1.1">
      LLMs possess powerful natural language understanding and deduction capabilities, enabling them to design communication systems based on given system requirements. They exhibit strong multi-task processing and multi-module design capabilities within the boundaries of various training data. For instance, utilizing its intrinsic AI knowledge, LLMs can automatically design a federated learning system based on a given functional description of fedavg algorithm, and continuously optimize the system through prompt engineering
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib4" title="">
        4
       </a>
       ]
      </cite>
      .
     </p>
    </div>
   </section>
  </section>
  <section class="ltx_subsection" id="S2.SS2">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     <span class="ltx_text" id="S2.SS2.4.1.1">
      II-B
     </span>
    </span>
    <span class="ltx_text ltx_font_italic" id="S2.SS2.5.2">
     How to unleash the LLM potential for 6G communications
    </span>
   </h3>
   <div class="ltx_para" id="S2.SS2.p1">
    <p class="ltx_p" id="S2.SS2.p1.1">
     We can unleash the potential of LLMs in 6G communications by the prompt engineering which employs the following approaches:
    </p>
   </div>
   <section class="ltx_subsubsection" id="S2.SS2.SSS1">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      <span class="ltx_text" id="S2.SS2.SSS1.4.1.1">
       II-B
      </span>
      1
     </span>
     In-context learning
    </h4>
    <div class="ltx_para" id="S2.SS2.SSS1.p1">
     <p class="ltx_p" id="S2.SS2.SSS1.p1.1">
      In-Context Learning (ICL) is a form of analogical learning that incorporates explicit examples in the prompt to assist LLMs in making decisions
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib5" title="">
        5
       </a>
       ]
      </cite>
      . It enables the LLM to generate accurate expected results for a new task based on one provided example (i.e., one shot learning) or few similar examples (i.e., few shot learning) without the need for fine-tuning model weights. For instance, ICL can be applied to anomaly detection in industrial IoT. By providing few anomaly examples in the prompt, the LLM can learn and adapt to unique patterns and behaviors of edge devices, enabling real-time detection of anomalies and potential faults without relying on model training.
     </p>
    </div>
   </section>
   <section class="ltx_subsubsection" id="S2.SS2.SSS2">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      <span class="ltx_text" id="S2.SS2.SSS2.4.1.1">
       II-B
      </span>
      2
     </span>
     Chain-of-Thought
    </h4>
    <div class="ltx_para" id="S2.SS2.SSS2.p1">
     <p class="ltx_p" id="S2.SS2.SSS2.p1.1">
      Chain-of-Thought (CoT) is a form of discrete prompt learning that goes beyond providing examples with input-output pairs
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib6" title="">
        6
       </a>
       ]
      </cite>
      . It also includes the thought process and steps leading to the desired output when presenting the examples. This approach guides the LLMs’ way of thinking in their reasoning process step-by-step, thereby enhancing the logical reasoning capabilities of the LLMs. For instance, in trajectory planning of UAVs for 6G communications, CoT can be used to break down the trajectory planning process into multiple stages. Each stage focuses on a specific aspect, such as path generation, obstacle avoidance, or mission objectives. The outputs from one stage serve as inputs to the next, ensuring a coherent and sequential planning process.
     </p>
    </div>
   </section>
  </section>
  <section class="ltx_subsection" id="S2.SS3">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     <span class="ltx_text" id="S2.SS3.4.1.1">
      II-C
     </span>
    </span>
    <span class="ltx_text ltx_font_italic" id="S2.SS3.5.2">
     Challenges of applying LLM in 6G communications
    </span>
   </h3>
   <div class="ltx_para" id="S2.SS3.p1">
    <p class="ltx_p" id="S2.SS3.p1.1">
     Challenges arise when applying LLMs to 6G, and they can be categorized as follows:
    </p>
   </div>
   <section class="ltx_subsubsection" id="S2.SS3.SSS1">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      <span class="ltx_text" id="S2.SS3.SSS1.4.1.1">
       II-C
      </span>
      1
     </span>
     Untimely and covertly private data
    </h4>
    <div class="ltx_para" id="S2.SS3.SSS1.p1">
     <p class="ltx_p" id="S2.SS3.SSS1.p1.1">
      LLMs are typically trained on static datasets, while data and information in 6G communication may constantly change. Especially, a vast amount of data can be generated daily at the edge, and a significant portion of this data comprises private and confidential information, rendering it inaccessible for public training purposes. As a result, the LLMs may not capture the latest data and concepts, emerging protocols and standards in a timely manner. This can lead to outputs that are less accurate or not fully aligned with the current communication system.
     </p>
    </div>
   </section>
   <section class="ltx_subsubsection" id="S2.SS3.SSS2">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      <span class="ltx_text" id="S2.SS3.SSS2.4.1.1">
       II-C
      </span>
      2
     </span>
     Lack of domain knowledge
    </h4>
    <div class="ltx_para" id="S2.SS3.SSS2.p1">
     <p class="ltx_p" id="S2.SS3.SSS2.p1.1">
      6G communication has specific technical requirements and constraints, such as extremely low latency and very high data rate. However, LLMs may be trained on general data sets, which lack an in-depth understanding of domain-specific expertise. For example, the latest GPT-3.5 does not have an inherent understanding of what the SC system is and its structure. Instead, it interprets the SC system as a mode of semantic interaction employed by humans.
This can result in degraded performance of the LLM in communications, as it may struggle to accurately predict and optimize specific task parameters and system performance.
     </p>
    </div>
   </section>
   <section class="ltx_subsubsection" id="S2.SS3.SSS3">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      <span class="ltx_text" id="S2.SS3.SSS3.4.1.1">
       II-C
      </span>
      3
     </span>
     Insufficient logical reasoning ability
    </h4>
    <div class="ltx_para" id="S2.SS3.SSS3.p1">
     <p class="ltx_p" id="S2.SS3.SSS3.p1.1">
      6G communication involves complex signal processing, optimization, and decision-making tasks. Although LLMs excel in language generation and comprehension, they have limitations in logical reasoning and inferential capabilities. For instance, tasks like wireless channel estimation or resource scheduling require intricate reasoning and decision-making abilities, where LLMs may struggle to perform accurately. This may result in logical errors, or lack understanding of causal relationships, which is common in optimization tasks in 6G communications.
     </p>
    </div>
   </section>
   <section class="ltx_subsubsection" id="S2.SS3.SSS4">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      <span class="ltx_text" id="S2.SS3.SSS4.4.1.1">
       II-C
      </span>
      4
     </span>
     Inadequate evaluation and refinement
    </h4>
    <div class="ltx_para" id="S2.SS3.SSS4.p1">
     <p class="ltx_p" id="S2.SS3.SSS4.p1.1">
      The evaluation of outputs from LLMs by the single-instance result can be challenging due to the complexity and diversity of wireless communication environments. Assessing the LLM’s performance and effectiveness in real-world scenarios requires considering multiple factors, such as channel conditions, user requirements, and mobility. Therefore, evaluating LLMs necessitates adopting multiple perspectives, considering various factors, and providing feedback to continuously refine the performance of LLMs to ensure reliability and usability.
     </p>
    </div>
    <div class="ltx_para" id="S2.SS3.SSS4.p2">
     <p class="ltx_p" id="S2.SS3.SSS4.p2.1">
      Hence, we could improve the performance of LLMs in 6G communications by training on up-to-date datasets, incorporating communication knowledge and reasoning capabilities, and developing more comprehensive evaluation and refinement methods.
     </p>
    </div>
   </section>
  </section>
 </section>
 <section class="ltx_section" id="S3">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    III
   </span>
   <span class="ltx_text ltx_font_smallcaps" id="S3.1.1">
    LLM Enhanced Multi-Agent Systems
   </span>
  </h2>
  <section class="ltx_subsection" id="S3.SS1">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     <span class="ltx_text" id="S3.SS1.4.1.1">
      III-A
     </span>
    </span>
    <span class="ltx_text ltx_font_italic" id="S3.SS1.5.2">
     LLM enhanced agent system
    </span>
   </h3>
   <div class="ltx_para" id="S3.SS1.p1">
    <p class="ltx_p" id="S3.SS1.p1.1">
     AI agents can address the above challenges, and they are computational entities designed to simulate or mimic intelligent behavior, possessing traits such as autonomy, reactivity, and communication capacity. Due to their versatile and remarkable capabilities, LLMs are regarded as powerful tools for constructing AI agents. In the paper, we define a typical LLM enhanced agent system in Fig.
     <a class="ltx_ref" href="#S3.F1" title="Figure 1 ‣ III-A LLM enhanced agent system ‣ III LLM Enhanced Multi-Agent Systems ‣ Large Language Model Enhanced Multi-Agent Systems for 6G Communications">
      <span class="ltx_text ltx_ref_tag">
       1
      </span>
     </a>
     , which has the following components:
    </p>
   </div>
   <div class="ltx_para" id="S3.SS1.p2">
    <ul class="ltx_itemize" id="S3.I1">
     <li class="ltx_item" id="S3.I1.i1" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       •
      </span>
      <div class="ltx_para" id="S3.I1.i1.p1">
       <p class="ltx_p" id="S3.I1.i1.p1.1">
        <span class="ltx_text ltx_font_bold" id="S3.I1.i1.p1.1.1">
         Knowledge base
        </span>
        represents the component that stores the latest private data, consisting of communication standards, documents, and papers that can be connected to the agent, and provides a way to index, query, and update domain-specific knowledge in 6G communications.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="S3.I1.i2" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       •
      </span>
      <div class="ltx_para" id="S3.I1.i2.p1">
       <p class="ltx_p" id="S3.I1.i2.p1.1">
        <span class="ltx_text ltx_font_bold" id="S3.I1.i2.p1.1.1">
         Tools
        </span>
        are interfaces that an agent can use to process tasks. They can be generic utilities (such as Bing search and file system tools), endogenous intelligence in the LLM (such as AI model), or customized communication models (such as the wireless channel model). Tools can also be defined by the user, or integrated from external sources.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="S3.I1.i3" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       •
      </span>
      <div class="ltx_para" id="S3.I1.i3.p1">
       <p class="ltx_p" id="S3.I1.i3.p1.1">
        <span class="ltx_text ltx_font_bold" id="S3.I1.i3.p1.1.1">
         Memory
        </span>
        is the component that stores the intermediate and final outputs of agents for evaluation and reflexion, providing a way to manage, retrieve, and modify these historical outputs.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="S3.I1.i4" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       •
      </span>
      <div class="ltx_para" id="S3.I1.i4.p1">
       <p class="ltx_p" id="S3.I1.i4.p1.1">
        <span class="ltx_text ltx_font_bold" id="S3.I1.i4.p1.1.1">
         Model
        </span>
        is introduced to comprehend and interpret human language inputs, extracting meaning, intent, and context. Agent system supports different LLMs such as OpenAI’s GPT, Meta’s LLaMA and Anthropic’s Claude.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="S3.I1.i5" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       •
      </span>
      <div class="ltx_para" id="S3.I1.i5.p1">
       <p class="ltx_p" id="S3.I1.i5.p1.1">
        <span class="ltx_text ltx_font_bold" id="S3.I1.i5.p1.1.1">
         Agent
        </span>
        represents the entity that interacts with LLMs, memories, tools and knowledge base, providing a way to plan, control, introspect and communicate with other agents using LLM with a profile. The profile defines and manages the characteristics and behaviors of an agent by specific prompt. It encompasses a set of parameters and rules that describe various attributes of the agent, including its role, goals, capabilities, knowledge, and behavioral patterns.
       </p>
      </div>
     </li>
    </ul>
   </div>
   <figure class="ltx_figure" id="S3.F1">
    <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="209" id="S3.F1.g1" src="/html/2312.07850/assets/agent.png" width="354"/>
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_figure">
      <span class="ltx_text" id="S3.F1.2.1.1" style="font-size:90%;">
       Figure 1
      </span>
      :
     </span>
     <span class="ltx_text" id="S3.F1.3.2" style="font-size:90%;">
      LLM enhanced agent system.
     </span>
    </figcaption>
   </figure>
  </section>
  <section class="ltx_subsection" id="S3.SS2">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     <span class="ltx_text" id="S3.SS2.4.1.1">
      III-B
     </span>
    </span>
    <span class="ltx_text ltx_font_italic" id="S3.SS2.5.2">
     Overview of the proposed multi-agent system
    </span>
   </h3>
   <div class="ltx_para" id="S3.SS2.p1">
    <p class="ltx_p" id="S3.SS2.p1.1">
     We design an LLM enhanced multi-agent system for 6G communications, which constructs a specialized knowledge base and tools for 6G communications, and possesses planning, memory, tool utilization and introspection capabilities beyond protogenetic LLMs.
Here, an agent serves as the core of this system, which can engage in planning and reflexion based on LLMs, acquire specialized knowledge and tools, and leverage their combination for autonomous learning and adaptive enhancement
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib7" title="">
       7
      </a>
      ]
     </cite>
     .
Moreover, to avoid biases and hallucinations caused by a single agent, we introduce the multi-agent collaboration, which involves designing multiple agents to engage in multi-round cooperation. By combining their individual opinions and knowledge, this system enhances the problem-solving capabilities in complex communication tasks and fully unleashes the cognitive synergy potential of the LLM.
    </p>
   </div>
   <div class="ltx_para" id="S3.SS2.p2">
    <p class="ltx_p" id="S3.SS2.p2.1">
     As depicted in Fig.
     <a class="ltx_ref" href="#S3.F2" title="Figure 2 ‣ III-B Overview of the proposed multi-agent system ‣ III LLM Enhanced Multi-Agent Systems ‣ Large Language Model Enhanced Multi-Agent Systems for 6G Communications">
      <span class="ltx_text ltx_ref_tag">
       2
      </span>
     </a>
     , the process begins with the MDR module querying communication knowledge from external data sources based on user requirements by natural language. This step involves several agents, including a
     <span class="ltx_text ltx_font_italic" id="S3.SS2.p2.1.1">
      secure agent
     </span>
     , a
     <span class="ltx_text ltx_font_italic" id="S3.SS2.p2.1.2">
      condensate agent
     </span>
     , and an
     <span class="ltx_text ltx_font_italic" id="S3.SS2.p2.1.3">
      inference agent
     </span>
     .
Once the communication knowledge is obtained along with task requirements, they are fed into the MCP module. Then, multiple
     <span class="ltx_text ltx_font_italic" id="S3.SS2.p2.1.4">
      planning agents
     </span>
     and sub-task chains are employed to formulate solutions for the given task and retrieved knowledge. With assistance from the tools, we can derive the final results based on solving the sub-task chain.
Subsequently, the MER module introduces an
     <span class="ltx_text ltx_font_italic" id="S3.SS2.p2.1.5">
      evaluation agent
     </span>
     that assesses the final results of each sub-task chain and assigns corresponding rewards. Furthermore, it uses a
     <span class="ltx_text ltx_font_italic" id="S3.SS2.p2.1.6">
      reflexion agent
     </span>
     and a
     <span class="ltx_text ltx_font_italic" id="S3.SS2.p2.1.7">
      refinement agent
     </span>
     to provide refined suggestions.
Finally, these suggestions are looped back to the MER module, guiding it to re-plan and generate new sub-task chains and results. By iterating through this process, we eventually reach an optimal solution that is then delivered to the user by natural language.
    </p>
   </div>
   <figure class="ltx_figure" id="S3.F2">
    <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="260" id="S3.F2.g1" src="/html/2312.07850/assets/MGPT.png" width="707"/>
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_figure">
      <span class="ltx_text" id="S3.F2.2.1.1" style="font-size:90%;">
       Figure 2
      </span>
      :
     </span>
     <span class="ltx_text" id="S3.F2.3.2" style="font-size:90%;">
      The proposed LLM enhanced multi-agent system.
     </span>
    </figcaption>
   </figure>
  </section>
  <section class="ltx_subsection" id="S3.SS3">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     <span class="ltx_text" id="S3.SS3.4.1.1">
      III-C
     </span>
    </span>
    <span class="ltx_text ltx_font_italic" id="S3.SS3.5.2">
     Multi-agent data retrieval
    </span>
   </h3>
   <div class="ltx_para" id="S3.SS3.p1">
    <p class="ltx_p" id="S3.SS3.p1.1">
     MDR enables LLMs to extract and summarize knowledge from external privacy data sources regarding the 6G communications.
MDR can also use the LLM as a reasoning engine over new domain knowledge provided in the knowledge base. The steps of MDR are as follows:
    </p>
   </div>
   <section class="ltx_subsubsection" id="S3.SS3.SSS1">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      <span class="ltx_text" id="S3.SS3.SSS1.4.1.1">
       III-C
      </span>
      1
     </span>
     Document segmentation
    </h4>
    <div class="ltx_para" id="S3.SS3.SSS1.p1">
     <p class="ltx_p" id="S3.SS3.SSS1.p1.1">
      External domain data, including latest communication standards, documents, and papers in various formats, can be loaded and then segmented to improve the efficiency of data retrieval. The segmentation process involves dividing the documents into multiple coherent and meaningful fragments while maintaining the semantic coherence and integrity.
     </p>
    </div>
   </section>
   <section class="ltx_subsubsection" id="S3.SS3.SSS2">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      <span class="ltx_text" id="S3.SS3.SSS2.4.1.1">
       III-C
      </span>
      2
     </span>
     Knowledge base construction
    </h4>
    <div class="ltx_para" id="S3.SS3.SSS2.p1">
     <p class="ltx_p" id="S3.SS3.SSS2.p1.1">
      The segmented document fragments are transformed into numerical vectors using embedding neural networks. Document fragments with similar semantic content will have similar vectors in the numerical space. By comparing these vectors, we can identify similar text fragments. The segmented document fragments and their corresponding embeddings are stored in vector format to construct a knowledge base, facilitating subsequent retrievals.
     </p>
    </div>
   </section>
   <section class="ltx_subsubsection" id="S3.SS3.SSS3">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      <span class="ltx_text" id="S3.SS3.SSS3.4.1.1">
       III-C
      </span>
      3
     </span>
     Document retrieval
    </h4>
    <div class="ltx_para" id="S3.SS3.SSS3.p1">
     <p class="ltx_p" id="S3.SS3.SSS3.p1.1">
      A
      <span class="ltx_text ltx_font_italic" id="S3.SS3.SSS3.p1.1.1">
       secure agent
      </span>
      is employed to scrutinize user requirements, thereby preventing any unauthorized requests or potential injection attacks
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib8" title="">
        8
       </a>
       ]
      </cite>
      . Once validated, these legal requirements are transformed into vectors through the use of embedding networks. These requirement vectors are then compared with document vectors already stored in the knowledge base, and the most closely matching vectors along with their corresponding document fragments are selected. To increase retrieval diversity and minimize redundancy during this querying process in the knowledge base, we employ the Maximum Marginal Relevance (MMR)
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib9" title="">
        9
       </a>
       ]
      </cite>
      for selecting document fragments.
     </p>
    </div>
   </section>
   <section class="ltx_subsubsection" id="S3.SS3.SSS4">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      <span class="ltx_text" id="S3.SS3.SSS4.4.1.1">
       III-C
      </span>
      4
     </span>
     Compression and summarization
    </h4>
    <div class="ltx_para" id="S3.SS3.SSS4.p1">
     <p class="ltx_p" id="S3.SS3.SSS4.p1.1">
      To reduce irrelevant information in the documents, a
      <em class="ltx_emph ltx_font_italic" id="S3.SS3.SSS4.p1.1.1">
       condensate agent
      </em>
      is utilized to compress the documents, resulting in more accurate and focused results
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib8" title="">
        8
       </a>
       ]
      </cite>
      . The selected fragments, along with the query, are then inputted into an
      <em class="ltx_emph ltx_font_italic" id="S3.SS3.SSS4.p1.1.2">
       inference agent
      </em>
      to obtain specialized communication knowledge corresponding to the user’s requirements by natural language
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib6" title="">
        6
       </a>
       ]
      </cite>
      .
     </p>
    </div>
   </section>
  </section>
  <section class="ltx_subsection" id="S3.SS4">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     <span class="ltx_text" id="S3.SS4.4.1.1">
      III-D
     </span>
    </span>
    <span class="ltx_text ltx_font_italic" id="S3.SS4.5.2">
     Multi-agent collaborative planning
    </span>
   </h3>
   <div class="ltx_para" id="S3.SS4.p1">
    <p class="ltx_p" id="S3.SS4.p1.1">
     MCP generates multiple feasible sub-task chains by constructing multiple
     <em class="ltx_emph ltx_font_italic" id="S3.SS4.p1.1.1">
      planning agents
     </em>
     . By combining their individual knowledge and planning capabilities from different perspectives, the quality of response in solving complex problems is enhanced. The steps of MCP are as follows:
    </p>
   </div>
   <section class="ltx_subsubsection" id="S3.SS4.SSS1">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      <span class="ltx_text" id="S3.SS4.SSS1.4.1.1">
       III-D
      </span>
      1
     </span>
     Task planning
    </h4>
    <div class="ltx_para" id="S3.SS4.SSS1.p1">
     <p class="ltx_p" id="S3.SS4.SSS1.p1.1">
      Based on the current task requirements and retrieved communication knowledge, multiple
      <em class="ltx_emph ltx_font_italic" id="S3.SS4.SSS1.p1.1.1">
       planning agents
      </em>
      are initialized. Each agent employs either the CoT or Plan-and-Solve approach
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib10" title="">
        10
       </a>
       ]
      </cite>
      to decompose the original task into a series of sub-tasks.
     </p>
    </div>
   </section>
   <section class="ltx_subsubsection" id="S3.SS4.SSS2">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      <span class="ltx_text" id="S3.SS4.SSS2.4.1.1">
       III-D
      </span>
      2
     </span>
     Sub-task chain construction
    </h4>
    <div class="ltx_para" id="S3.SS4.SSS2.p1">
     <p class="ltx_p" id="S3.SS4.SSS2.p1.1">
      Considering the order and dependency relationships of all sub-tasks, a sub-task chain is constructed by connecting the individual sub-tasks in a sequential or parallel manner, ensuring the coherence and uniformity of all sub-tasks.
     </p>
    </div>
   </section>
   <section class="ltx_subsubsection" id="S3.SS4.SSS3">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      <span class="ltx_text" id="S3.SS4.SSS3.4.1.1">
       III-D
      </span>
      3
     </span>
     Solving sub-task chains
    </h4>
    <div class="ltx_para" id="S3.SS4.SSS3.p1">
     <p class="ltx_p" id="S3.SS4.SSS3.p1.1">
      Each sub-task chain is then solved by invoking either the intrinsic general-purpose tools or external custom tools to address each sub-task separately, until the final result of the sub-task chain is obtained.
     </p>
    </div>
   </section>
  </section>
  <section class="ltx_subsection" id="S3.SS5">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     <span class="ltx_text" id="S3.SS5.4.1.1">
      III-E
     </span>
    </span>
    <span class="ltx_text ltx_font_italic" id="S3.SS5.5.2">
     Multi-agent evaluation and reflecxion
    </span>
   </h3>
   <div class="ltx_para" id="S3.SS5.p1">
    <p class="ltx_p" id="S3.SS5.p1.1">
     MER is used to evaluate the quality of the results generated by MCP and then to reflect on the planning results by memory, thereby facilitating automatic learning, continuous improvement, and self-refinement. The steps of MER are as follows:
    </p>
   </div>
   <section class="ltx_subsubsection" id="S3.SS5.SSS1">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      <span class="ltx_text" id="S3.SS5.SSS1.4.1.1">
       III-E
      </span>
      1
     </span>
     Result Evaluation
    </h4>
    <div class="ltx_para" id="S3.SS5.SSS1.p1">
     <p class="ltx_p" id="S3.SS5.SSS1.p1.1">
      All sub-task chains and their results from MCP are collected and the rewards of all planning results are calculated using an
      <span class="ltx_text ltx_font_italic" id="S3.SS5.SSS1.p1.1.1">
       evaluation agent
      </span>
      .
     </p>
    </div>
   </section>
   <section class="ltx_subsubsection" id="S3.SS5.SSS2">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      <span class="ltx_text" id="S3.SS5.SSS2.4.1.1">
       III-E
      </span>
      2
     </span>
     Memory Storage
    </h4>
    <div class="ltx_para" id="S3.SS5.SSS2.p1">
     <p class="ltx_p" id="S3.SS5.SSS2.p1.1">
      A comparison is made between the current sub-task chain and historical sub-task chains. Task chains with significant differences in semantic space are stored in the long-term memory, while task chains with similar semantics are stored in the short-term memory, along with their corresponding results and rewards.
     </p>
    </div>
   </section>
   <section class="ltx_subsubsection" id="S3.SS5.SSS3">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      <span class="ltx_text" id="S3.SS5.SSS3.4.1.1">
       III-E
      </span>
      3
     </span>
     Introspection
    </h4>
    <div class="ltx_para" id="S3.SS5.SSS3.p1">
     <p class="ltx_p" id="S3.SS5.SSS3.p1.1">
      A
      <em class="ltx_emph ltx_font_italic" id="S3.SS5.SSS3.p1.1.1">
       reflexion agent
      </em>
      is employed to extract the fine-grained information from the short-term memory, similar to how humans can recall recent details
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib11" title="">
        11
       </a>
       ]
      </cite>
      . It allows for contemplating the performance of the current sub-task chains across historical schemes, providing valuable small-scale feedback for refinement.
     </p>
    </div>
   </section>
   <section class="ltx_subsubsection" id="S3.SS5.SSS4">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      <span class="ltx_text" id="S3.SS5.SSS4.4.1.1">
       III-E
      </span>
      4
     </span>
     Refinement
    </h4>
    <div class="ltx_para" id="S3.SS5.SSS4.p1">
     <p class="ltx_p" id="S3.SS5.SSS4.p1.1">
      A
      <em class="ltx_emph ltx_font_italic" id="S3.SS5.SSS4.p1.1.1">
       refinement agent
      </em>
      is utilized to reference coarse-grained information from the long-term memory, similar to how humans extract important experiences from long-term decisions
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib12" title="">
        12
       </a>
       ]
      </cite>
      . It involves contemplating the performance of the current sub-task chains from a global perspective and providing large-scale feedback for improving the sub-task chains.
     </p>
    </div>
    <div class="ltx_para" id="S3.SS5.SSS4.p2">
     <p class="ltx_p" id="S3.SS5.SSS4.p2.1">
      The introspection and refinement enable us to examine the contents of sub-task chains from different scales, gaining an in-depth understanding of the effectiveness and applicability of each sub-task.
Based on the feedback of the suggestions proposed by introspection and refinement, the MCP is re-driven to generate new sub-task chains, which are then evaluated through MER. This iterative process continues until the optimal scheme is obtained. All agents used in the system are summarized in Table
      <a class="ltx_ref" href="#S3.T1" title="TABLE I ‣ III-E4 Refinement ‣ III-E Multi-agent evaluation and reflecxion ‣ III LLM Enhanced Multi-Agent Systems ‣ Large Language Model Enhanced Multi-Agent Systems for 6G Communications">
       <span class="ltx_text ltx_ref_tag">
        I
       </span>
      </a>
      .
     </p>
    </div>
    <figure class="ltx_table" id="S3.T1">
     <figcaption class="ltx_caption">
      <span class="ltx_tag ltx_tag_table">
       <span class="ltx_text" id="S3.T1.2.1.1" style="font-size:90%;">
        TABLE I
       </span>
       :
      </span>
      <span class="ltx_text" id="S3.T1.3.2" style="font-size:90%;">
       Summary of agents.
      </span>
     </figcaption>
     <table class="ltx_tabular ltx_align_middle" id="S3.T1.4">
      <tr class="ltx_tr" id="S3.T1.4.1">
       <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" id="S3.T1.4.1.1">
        <span class="ltx_inline-block ltx_align_top" id="S3.T1.4.1.1.1">
         <span class="ltx_p" id="S3.T1.4.1.1.1.1" style="width:50.0pt;">
          Agent
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T1.4.1.2">
        <span class="ltx_inline-block ltx_align_top" id="S3.T1.4.1.2.1">
         <span class="ltx_p" id="S3.T1.4.1.2.1.1" style="width:140.0pt;">
          Function
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T1.4.1.3">
        <span class="ltx_inline-block ltx_align_top" id="S3.T1.4.1.3.1">
         <span class="ltx_p" id="S3.T1.4.1.3.1.1" style="width:15.0pt;">
          Ref.
         </span>
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="S3.T1.4.2">
       <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" id="S3.T1.4.2.1">
        <span class="ltx_inline-block ltx_align_top" id="S3.T1.4.2.1.1">
         <span class="ltx_p" id="S3.T1.4.2.1.1.1" style="width:50.0pt;">
          Secure agent
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T1.4.2.2">
        <span class="ltx_inline-block ltx_align_top" id="S3.T1.4.2.2.1">
         <span class="ltx_p" id="S3.T1.4.2.2.1.1" style="width:140.0pt;">
          Prevents any unauthorized requests or potential injection attacks
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T1.4.2.3">
        <span class="ltx_inline-block ltx_align_top" id="S3.T1.4.2.3.1">
         <span class="ltx_p" id="S3.T1.4.2.3.1.1" style="width:15.0pt;">
          <cite class="ltx_cite ltx_citemacro_cite">
           [
           <a class="ltx_ref" href="#bib.bib8" title="">
            8
           </a>
           ]
          </cite>
         </span>
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="S3.T1.4.3">
       <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" id="S3.T1.4.3.1">
        <span class="ltx_inline-block ltx_align_top" id="S3.T1.4.3.1.1">
         <span class="ltx_p" id="S3.T1.4.3.1.1.1" style="width:50.0pt;">
          Condensate agent
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T1.4.3.2">
        <span class="ltx_inline-block ltx_align_top" id="S3.T1.4.3.2.1">
         <span class="ltx_p" id="S3.T1.4.3.2.1.1" style="width:140.0pt;">
          Compresses retrieved documents for more accurate and focused results
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T1.4.3.3">
        <span class="ltx_inline-block ltx_align_top" id="S3.T1.4.3.3.1">
         <span class="ltx_p" id="S3.T1.4.3.3.1.1" style="width:15.0pt;">
          <cite class="ltx_cite ltx_citemacro_cite">
           [
           <a class="ltx_ref" href="#bib.bib8" title="">
            8
           </a>
           ]
          </cite>
         </span>
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="S3.T1.4.4">
       <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" id="S3.T1.4.4.1">
        <span class="ltx_inline-block ltx_align_top" id="S3.T1.4.4.1.1">
         <span class="ltx_p" id="S3.T1.4.4.1.1.1" style="width:50.0pt;">
          Inference agent
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T1.4.4.2">
        <span class="ltx_inline-block ltx_align_top" id="S3.T1.4.4.2.1">
         <span class="ltx_p" id="S3.T1.4.4.2.1.1" style="width:140.0pt;">
          Concludes specialized domain knowledge corresponding to user’s requirements
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T1.4.4.3">
        <span class="ltx_inline-block ltx_align_top" id="S3.T1.4.4.3.1">
         <span class="ltx_p" id="S3.T1.4.4.3.1.1" style="width:15.0pt;">
          <cite class="ltx_cite ltx_citemacro_cite">
           [
           <a class="ltx_ref" href="#bib.bib6" title="">
            6
           </a>
           ]
          </cite>
         </span>
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="S3.T1.4.5">
       <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" id="S3.T1.4.5.1">
        <span class="ltx_inline-block ltx_align_top" id="S3.T1.4.5.1.1">
         <span class="ltx_p" id="S3.T1.4.5.1.1.1" style="width:50.0pt;">
          Planning agent
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T1.4.5.2">
        <span class="ltx_inline-block ltx_align_top" id="S3.T1.4.5.2.1">
         <span class="ltx_p" id="S3.T1.4.5.2.1.1" style="width:140.0pt;">
          Decomposes the original task into a series of sub-tasks
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T1.4.5.3">
        <span class="ltx_inline-block ltx_align_top" id="S3.T1.4.5.3.1">
         <span class="ltx_p" id="S3.T1.4.5.3.1.1" style="width:15.0pt;">
          <cite class="ltx_cite ltx_citemacro_cite">
           [
           <a class="ltx_ref" href="#bib.bib10" title="">
            10
           </a>
           ]
          </cite>
         </span>
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="S3.T1.4.6">
       <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" id="S3.T1.4.6.1">
        <span class="ltx_inline-block ltx_align_top" id="S3.T1.4.6.1.1">
         <span class="ltx_p" id="S3.T1.4.6.1.1.1" style="width:50.0pt;">
          Evaluation agent
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T1.4.6.2">
        <span class="ltx_inline-block ltx_align_top" id="S3.T1.4.6.2.1">
         <span class="ltx_p" id="S3.T1.4.6.2.1.1" style="width:140.0pt;">
          Evaluates results of sub-task chains and calculate the rewards of planning agents
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T1.4.6.3">
        <span class="ltx_inline-block ltx_align_top" id="S3.T1.4.6.3.1">
         <span class="ltx_p" id="S3.T1.4.6.3.1.1" style="width:15.0pt;">
          -
         </span>
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="S3.T1.4.7">
       <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" id="S3.T1.4.7.1">
        <span class="ltx_inline-block ltx_align_top" id="S3.T1.4.7.1.1">
         <span class="ltx_p" id="S3.T1.4.7.1.1.1" style="width:50.0pt;">
          Reflexion agent
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T1.4.7.2">
        <span class="ltx_inline-block ltx_align_top" id="S3.T1.4.7.2.1">
         <span class="ltx_p" id="S3.T1.4.7.2.1.1" style="width:140.0pt;">
          Extracts the fine-grained information from the short-term memory
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T1.4.7.3">
        <span class="ltx_inline-block ltx_align_top" id="S3.T1.4.7.3.1">
         <span class="ltx_p" id="S3.T1.4.7.3.1.1" style="width:15.0pt;">
          <cite class="ltx_cite ltx_citemacro_cite">
           [
           <a class="ltx_ref" href="#bib.bib11" title="">
            11
           </a>
           ]
          </cite>
         </span>
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="S3.T1.4.8">
       <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_l ltx_border_r ltx_border_t" id="S3.T1.4.8.1">
        <span class="ltx_inline-block ltx_align_top" id="S3.T1.4.8.1.1">
         <span class="ltx_p" id="S3.T1.4.8.1.1.1" style="width:50.0pt;">
          Refinement agent
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r ltx_border_t" id="S3.T1.4.8.2">
        <span class="ltx_inline-block ltx_align_top" id="S3.T1.4.8.2.1">
         <span class="ltx_p" id="S3.T1.4.8.2.1.1" style="width:140.0pt;">
          References coarse-grained information from the long-term memory
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r ltx_border_t" id="S3.T1.4.8.3">
        <span class="ltx_inline-block ltx_align_top" id="S3.T1.4.8.3.1">
         <span class="ltx_p" id="S3.T1.4.8.3.1.1" style="width:15.0pt;">
          <cite class="ltx_cite ltx_citemacro_cite">
           [
           <a class="ltx_ref" href="#bib.bib12" title="">
            12
           </a>
           ]
          </cite>
         </span>
        </span>
       </td>
      </tr>
     </table>
    </figure>
   </section>
  </section>
 </section>
 <section class="ltx_section" id="S4">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    IV
   </span>
   <span class="ltx_text ltx_font_smallcaps" id="S4.1.1">
    Case Study
   </span>
  </h2>
  <figure class="ltx_figure" id="S4.F3">
   <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="331" id="S4.F3.g1" src="/html/2312.07850/assets/SC.png" width="707"/>
   <figcaption class="ltx_caption ltx_centering">
    <span class="ltx_tag ltx_tag_figure">
     <span class="ltx_text" id="S4.F3.2.1.1" style="font-size:90%;">
      Figure 3
     </span>
     :
    </span>
    <span class="ltx_text" id="S4.F3.3.2" style="font-size:90%;">
     The illustration of implementing the SC model based on the LLM-enhanced multi-agent system.
    </span>
   </figcaption>
  </figure>
  <div class="ltx_para" id="S4.p1">
   <p class="ltx_p" id="S4.p1.1">
    In this section, we introduce a case study in 6G communications, i.e., LLM for SC, which is expected to become the key applications
of next generation intelligent communication paradigms. Specifically, we utilize the proposed multi-agent system to automatically generate an SC model based on user requirements and resource constraints.
   </p>
  </div>
  <section class="ltx_subsection" id="S4.SS1">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     <span class="ltx_text" id="S4.SS1.4.1.1">
      IV-A
     </span>
    </span>
    <span class="ltx_text ltx_font_italic" id="S4.SS1.5.2">
     SC model designed by the multi-agent system
    </span>
   </h3>
   <div class="ltx_para" id="S4.SS1.p1">
    <p class="ltx_p" id="S4.SS1.p1.1">
     As illustrated in Fig.
     <a class="ltx_ref" href="#S4.F3" title="Figure 3 ‣ IV Case Study ‣ Large Language Model Enhanced Multi-Agent Systems for 6G Communications">
      <span class="ltx_text ltx_ref_tag">
       3
      </span>
     </a>
     , we apply the multi-agent system to construct the SC model. In this study, we chose GPT-3.5 as our LLM. The input content is expressed in natural language, encompassing user requirements, design objectives and constraints, as well as evaluation metrics as follows:
    </p>
   </div>
   <div class="ltx_para" id="S4.SS1.p2">
    <p class="ltx_p" id="S4.SS1.p2.1">
     <span class="ltx_text ltx_font_bold" id="S4.SS1.p2.1.1">
      Input
     </span>
     :
     <em class="ltx_emph ltx_font_italic" id="S4.SS1.p2.1.2">
      Please produce Python code that implements an SC model for text transmission.
The Additive Gaussian White Noise (AWGN) can serve as the physical channel.
The bilingual evaluation understudy (BLEU) score is adopted as the metric that evaluates the SC model.
We expect that the generated SC model achieves no less than a 0.6 BLEU score when the Signal-to-Noise Ratio (SNR) is 10 dB. The total number of model parameters does not exceed 2,000,000 for the resource constraints of devices.
     </em>
    </p>
   </div>
   <div class="ltx_para" id="S4.SS1.p3">
    <p class="ltx_p" id="S4.SS1.p3.1">
     It is worth noting that the current multi-agent system lacks any knowledge about the SC system beyond the input, as the native GPT-3.5 does not understand the structure and functionality of SC. The multi-agent system needs to autonomously learn from the knowledge base and address these issues. The output is the outline and implementation code for this SC model. In this study, the specific contents of the outline part are listed as follows:
    </p>
   </div>
   <div class="ltx_para" id="S4.SS1.p4">
    <p class="ltx_p" id="S4.SS1.p4.1">
     <span class="ltx_text ltx_font_bold" id="S4.SS1.p4.1.1">
      Output
     </span>
     :
     <em class="ltx_emph ltx_font_italic" id="S4.SS1.p4.1.2">
      The Python-based SC model has been successfully implemented, incorporating all necessary modules. The semantic encoder and decoder are realized using Long Short-Term Memory (LSTM) networks. The channel encoder and decoder are constructed based on the Multilayer Perceptron (MLP) architecture. The final SC model can achieve a 0.68 BLEU score when SNR is 10 dB, which meets expectations. In addition, the total number of model parameters is 1,826,762.
     </em>
    </p>
   </div>
   <div class="ltx_para" id="S4.SS1.p5">
    <p class="ltx_p" id="S4.SS1.p5.1">
     We have gathered a selection of research papers from arxiv that are relevant to 6G communications to build a basic communication knowledge base. In addition, we have included essential communication models, such as channel models, as specialized communication tools.
Next, the specific progress of applying the multi-agent system to design the SC model is as follows:
    </p>
    <ol class="ltx_enumerate" id="S4.I1">
     <li class="ltx_item" id="S4.I1.i1" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       1.
      </span>
      <div class="ltx_para" id="S4.I1.i1.p1">
       <p class="ltx_p" id="S4.I1.i1.p1.1">
        The
        <em class="ltx_emph ltx_font_italic" id="S4.I1.i1.p1.1.1">
         secure agent
        </em>
        is utilized to validate the legitimacy of the input, while the relevant arxiv papers (e.g.,
        <cite class="ltx_cite ltx_citemacro_cite">
         [
         <a class="ltx_ref" href="#bib.bib13" title="">
          13
         </a>
         ]
        </cite>
        ) in the knowledge base are retrieved. Then, the
        <em class="ltx_emph ltx_font_italic" id="S4.I1.i1.p1.1.2">
         condensate agent
        </em>
        is applied to refine the retrieved SC knowledge in papers. Next, the
        <em class="ltx_emph ltx_font_italic" id="S4.I1.i1.p1.1.3">
         inference agent
        </em>
        amalgamates user input and SC knowledge to distill relevant SC knowledge for constructing the SC model, which includes the definitions and functions of each module in the SC.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="S4.I1.i2" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       2.
      </span>
      <div class="ltx_para" id="S4.I1.i2.p1">
       <p class="ltx_p" id="S4.I1.i2.p1.1">
        Once the necessary SC knowledge is obtained, each
        <em class="ltx_emph ltx_font_italic" id="S4.I1.i2.p1.1.1">
         planning agent
        </em>
        formulates a specific sub-task chain for the SC model. This chain delineates the architecture of each module in the SC model, including their respective inputs and outputs, network structure, as well as training settings (e.g., loss function and optimizer).
       </p>
      </div>
     </li>
     <li class="ltx_item" id="S4.I1.i3" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       3.
      </span>
      <div class="ltx_para" id="S4.I1.i3.p1">
       <p class="ltx_p" id="S4.I1.i3.p1.1">
        Sub-task chains are then handled by the endogenous AI code generation tool of the LLM. Each sub-task chain manages one feasible scheme of the SC model including semantic encoder/decoder, channel encoder/decoder, and other codes (e.g., data processing, feedforward and back propagation). The wireless channel code is generated by the predefined communication tools (e.g., channel models). This results in obtaining precisely Python code.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="S4.I1.i4" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       4.
      </span>
      <div class="ltx_para" id="S4.I1.i4.p1">
       <p class="ltx_p" id="S4.I1.i4.p1.1">
        The
        <em class="ltx_emph ltx_font_italic" id="S4.I1.i4.p1.1.1">
         evaluation agent
        </em>
        subsequently assesses the quality of generated codes.
The evaluative score encompasses three components: the quality of the generated code, the value of the objective function, and the penalty for constraint violations.
The value of the objective function is defined as the BLEU score of the designed SC model.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="S4.I1.i5" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       5.
      </span>
      <div class="ltx_para" id="S4.I1.i5.p1">
       <p class="ltx_p" id="S4.I1.i5.p1.1">
        Based on these evaluation results, the
        <em class="ltx_emph ltx_font_italic" id="S4.I1.i5.p1.1.1">
         reflexion agent
        </em>
        gives fine-grained introspective comments (e.g., syntax errors of codes and parameter adjustments of modules), and the
        <em class="ltx_emph ltx_font_italic" id="S4.I1.i5.p1.1.2">
         refinement agent
        </em>
        gives coarse-gained reinforced comments (e.g., logic errors of codes and structural adjustments of modules) taking into account both strengths and weaknesses of the current SC model.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="S4.I1.i6" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       6.
      </span>
      <div class="ltx_para" id="S4.I1.i6.p1">
       <p class="ltx_p" id="S4.I1.i6.p1.1">
        These proposed improvement suggestions are then fed back into the planning agent for introspection and refinement purposes. This process undergoes iterative optimization until satisfactory results are obtained.
       </p>
      </div>
     </li>
    </ol>
   </div>
  </section>
  <section class="ltx_subsection" id="S4.SS2">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     <span class="ltx_text" id="S4.SS2.4.1.1">
      IV-B
     </span>
    </span>
    <span class="ltx_text ltx_font_italic" id="S4.SS2.5.2">
     Simulation results
    </span>
   </h3>
   <div class="ltx_para" id="S4.SS2.p1">
    <p class="ltx_p" id="S4.SS2.p1.1">
     All schemes and experimental codes are generated by GPT-3.5, and all parameter optimizations are performed automatically by the multi-agent system. We only assign two planning agents in the multi-agent system. This implies that two independent SC models, each based on a unique scheme, are concurrently generated. We also set the number of iterations to four.
Fig.
     <a class="ltx_ref" href="#S4.F5" title="Figure 5 ‣ IV-B Simulation results ‣ IV Case Study ‣ Large Language Model Enhanced Multi-Agent Systems for 6G Communications">
      <span class="ltx_text ltx_ref_tag">
       5
      </span>
     </a>
     presents simulation results for the SC model with different structures. It displays evaluative scores for both schemes. Notably, as the iterations advance, there is a distinct enhancement in evaluative scores. Initially, Scheme 2 trailed behind Scheme 1 in terms of evaluation scores. However, in the second iteration, the semantic encoder-decoder of Scheme 2 underwent coarse-gained refinement and transformed to the LSTM structure. As a result, Scheme 2 eventually caught up and surpassed Scheme 1.
The adopted network architectures in the final SC models of the two schemes are described as follows:
    </p>
    <ul class="ltx_itemize" id="S4.I2">
     <li class="ltx_item" id="S4.I2.i1" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       •
      </span>
      <div class="ltx_para" id="S4.I2.i1.p1">
       <p class="ltx_p" id="S4.I2.i1.p1.1">
        <em class="ltx_emph ltx_font_italic" id="S4.I2.i1.p1.1.1">
         Scheme 1
        </em>
        :
An MLP with 3 layers is employed as the semantic encoder and decoder. The MLP with 2 layers is integrated into the channel encoder and decoder. The SC model is trained using the SGD optimizer.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="S4.I2.i2" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       •
      </span>
      <div class="ltx_para" id="S4.I2.i2.p1">
       <p class="ltx_p" id="S4.I2.i2.p1.1">
        <em class="ltx_emph ltx_font_italic" id="S4.I2.i2.p1.1.1">
         Scheme 2
        </em>
        :
An LSTM with 4 layers is utilized for the semantic encoder and decoder. Similarly, the MLP with 2 layers is used for both channel encoding and decoding. Training of this SC model is based on the Adam optimizer.
       </p>
      </div>
     </li>
    </ul>
   </div>
   <div class="ltx_para" id="S4.SS2.p2">
    <p class="ltx_p" id="S4.SS2.p2.1">
     In summary, this simulation demonstrates the proposed multi-agent system’s ability to autonomously generate an SC model while iteratively refining it through self-introspection and refinement.
    </p>
   </div>
   <figure class="ltx_figure" id="S4.F4">
    <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="288" id="S4.F4.g1" src="/html/2312.07850/assets/exp1_1.jpg" width="354"/>
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_figure">
      <span class="ltx_text" id="S4.F4.2.1.1" style="font-size:90%;">
       Figure 4
      </span>
      :
     </span>
     <span class="ltx_text" id="S4.F4.3.2" style="font-size:90%;">
      Evaluative score versus iteration number.
     </span>
    </figcaption>
   </figure>
   <div class="ltx_para" id="S4.SS2.p3">
    <p class="ltx_p" id="S4.SS2.p3.1">
     To assess the effectiveness of the generated SC model by Scheme 2, we utilize the Cornell Movie-Dialogs Corpus dataset
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib14" title="">
       14
      </a>
      ]
     </cite>
     , a collection of dialogues from 617 film scripts, to train the SC model. Specifically, we use 8,000 dialogues for training and reserve 2,000 dialogues for testing. The training epoch is set at 50.
As for the evaluation metric, we employ a BERT-based semantic evaluation method complemented by cosine similarity
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib15" title="">
       15
      </a>
      ]
     </cite>
     . Subsequently, we compute the cosine similarity between these text encodings from raw and recovered text data.
Fig.
     <a class="ltx_ref" href="#S4.F5" title="Figure 5 ‣ IV-B Simulation results ‣ IV Case Study ‣ Large Language Model Enhanced Multi-Agent Systems for 6G Communications">
      <span class="ltx_text ltx_ref_tag">
       5
      </span>
     </a>
     depicts the semantic similarity results of our SC model on the test set while varying the SNR. The figure clearly illustrates that the performance of our SC model improves as the SNR increases. These findings not only showcase the functionalities, but also underscore the effectiveness of the SC model generated through the proposed multi-agent system.
    </p>
   </div>
   <figure class="ltx_figure" id="S4.F5">
    <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="285" id="S4.F5.g1" src="/html/2312.07850/assets/exp2_2.jpg" width="354"/>
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_figure">
      <span class="ltx_text" id="S4.F5.2.1.1" style="font-size:90%;">
       Figure 5
      </span>
      :
     </span>
     <span class="ltx_text" id="S4.F5.3.2" style="font-size:90%;">
      Cosine similarity versus SNR.
     </span>
    </figcaption>
   </figure>
  </section>
 </section>
 <section class="ltx_section" id="S5">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    V
   </span>
   <span class="ltx_text ltx_font_smallcaps" id="S5.1.1">
    Open Issues
   </span>
  </h2>
  <section class="ltx_subsubsection" id="S5.SS0.SSS1">
   <h4 class="ltx_title ltx_title_subsubsection">
    <span class="ltx_tag ltx_tag_subsubsection">
     <span class="ltx_text" id="S5.SS0.SSS1.4.1.1">
      V-
     </span>
     1
    </span>
    Limited Resources
   </h4>
   <div class="ltx_para" id="S5.SS0.SSS1.p1">
    <p class="ltx_p" id="S5.SS0.SSS1.p1.1">
     The multi-agent system relies heavily on the availability of LLMs and the private communication data at the edge.
However, edge devices often have limited computing, storage and energy resources compared to powerful cloud servers. LLMs are resource-intensive models that may exceed the processing capabilities of edge devices, making it challenging to deploy multi-agent systems on the edge.
    </p>
   </div>
  </section>
  <section class="ltx_subsubsection" id="S5.SS0.SSS2">
   <h4 class="ltx_title ltx_title_subsubsection">
    <span class="ltx_tag ltx_tag_subsubsection">
     <span class="ltx_text" id="S5.SS0.SSS2.4.1.1">
      V-
     </span>
     2
    </span>
    Cooperation and competition
   </h4>
   <div class="ltx_para" id="S5.SS0.SSS2.p1">
    <p class="ltx_p" id="S5.SS0.SSS2.p1.1">
     The proposed multi-agent system adopts a cooperative approach for all agents to accomplish the design of the SC system. The interaction mode among agents is important for the multi-agent system and LLMs facilitate diverse modes of interaction among agents.
Exploring alternative modes of interaction, such as competition, and their application in 6G communications would be an intriguing research direction.
    </p>
   </div>
  </section>
  <section class="ltx_subsubsection" id="S5.SS0.SSS3">
   <h4 class="ltx_title ltx_title_subsubsection">
    <span class="ltx_tag ltx_tag_subsubsection">
     <span class="ltx_text" id="S5.SS0.SSS3.4.1.1">
      V-
     </span>
     3
    </span>
    Real-time interaction
   </h4>
   <div class="ltx_para" id="S5.SS0.SSS3.p1">
    <p class="ltx_p" id="S5.SS0.SSS3.p1.1">
     LLMs often suffer from slow response times, making them impractical for real-time, interactive 6G applications. Developing efficient and faster inference methods to enable real-time interaction with LLM-based agents is an ongoing challenge.
    </p>
   </div>
  </section>
 </section>
 <section class="ltx_section" id="S6">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    VI
   </span>
   <span class="ltx_text ltx_font_smallcaps" id="S6.1.1">
    Conclusion
   </span>
  </h2>
  <div class="ltx_para" id="S6.p1">
   <p class="ltx_p" id="S6.p1.1">
    In this paper, we proposed a multi-agent system that utilized natural language to design solutions for 6G communications and provided the case study in SC tasks. The system leveraged multiple LLM-enhanced agents to collaborate, self-learn, self-improve, and effectively solve defined problems in 6G communications. Specifically, we first employed the MDR to query private data in the system and extracted communication knowledge relevant to the task requirements. Next, we utilized the MCP to generate feasible solutions from different perspectives. Subsequently, we employed the MER to evaluate and reflect on the current solutions, provide improvement suggestions, and guide MCP in enhancing the solutions. Through iterations, an optimal solution was obtained. Finally, we demonstrated and validated the effectiveness of the proposed multi-agent system through the SC case study.
   </p>
  </div>
 </section>
 <section class="ltx_bibliography" id="bib">
  <h2 class="ltx_title ltx_title_bibliography">
   References
  </h2>
  <ul class="ltx_biblist">
   <li class="ltx_bibitem" id="bib.bib1">
    <span class="ltx_tag ltx_tag_bibitem">
     [1]
    </span>
    <span class="ltx_bibblock">
     Z. Chen, Z. Zhang, and Z. Yang, “Big ai models for 6g wireless networks:
Opportunities, challenges, and research directions,”
     <em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">
      arXiv preprint
arXiv:2308.06250
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib2">
    <span class="ltx_tag ltx_tag_bibitem">
     [2]
    </span>
    <span class="ltx_bibblock">
     F. Jiang
     <em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">
      et al.
     </em>
     , “Large ai model-based semantic communications,”
     <em class="ltx_emph ltx_font_italic" id="bib.bib2.2.2">
      arXiv preprint arXiv:2307.03492
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib3">
    <span class="ltx_tag ltx_tag_bibitem">
     [3]
    </span>
    <span class="ltx_bibblock">
     J. Zhong
     <em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">
      et al.
     </em>
     , “A safer vision-based autonomous planning system for
quadrotor uavs with dynamic obstacle trajectory prediction and its
application with llms,”
     <em class="ltx_emph ltx_font_italic" id="bib.bib3.2.2">
      arXiv preprint arXiv:2311.12893
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib4">
    <span class="ltx_tag ltx_tag_bibitem">
     [4]
    </span>
    <span class="ltx_bibblock">
     Y. Shen
     <em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">
      et al.
     </em>
     , “Large language models empowered autonomous edge ai for
connected intelligence,”
     <em class="ltx_emph ltx_font_italic" id="bib.bib4.2.2">
      arXiv preprint arXiv:2307.02779
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib5">
    <span class="ltx_tag ltx_tag_bibitem">
     [5]
    </span>
    <span class="ltx_bibblock">
     S. Chan
     <em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">
      et al.
     </em>
     , “Data distributional properties drive emergent
in-context learning in transformers,”
     <em class="ltx_emph ltx_font_italic" id="bib.bib5.2.2">
      Advances in Neural Information
Processing Systems
     </em>
     , vol. 35, pp. 18 878–18 891, 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib6">
    <span class="ltx_tag ltx_tag_bibitem">
     [6]
    </span>
    <span class="ltx_bibblock">
     J. Wei
     <em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">
      et al.
     </em>
     , “Chain-of-thought prompting elicits reasoning in large
language models,”
     <em class="ltx_emph ltx_font_italic" id="bib.bib6.2.2">
      Advances in Neural Information Processing Systems
     </em>
     ,
vol. 35, pp. 24 824–24 837, 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib7">
    <span class="ltx_tag ltx_tag_bibitem">
     [7]
    </span>
    <span class="ltx_bibblock">
     Q. Wu
     <em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">
      et al.
     </em>
     , “Autogen: Enabling next-gen llm applications via
multi-agent conversation framework,”
     <em class="ltx_emph ltx_font_italic" id="bib.bib7.2.2">
      arXiv preprint arXiv:2308.08155
     </em>
     ,
2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib8">
    <span class="ltx_tag ltx_tag_bibitem">
     [8]
    </span>
    <span class="ltx_bibblock">
     O. Topsakal and T. C. Akinci, “Creating large language model applications
utilizing langchain: A primer on developing llm apps fast,” in
     <em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">
      International Conference on Applied Engineering and Natural Sciences
     </em>
     ,
vol. 1, no. 1, 2023, pp. 1050–1056.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib9">
    <span class="ltx_tag ltx_tag_bibitem">
     [9]
    </span>
    <span class="ltx_bibblock">
     W. Luan
     <em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">
      et al.
     </em>
     , “Mptr: A maximal-marginal-relevance-based personalized
trip recommendation method,”
     <em class="ltx_emph ltx_font_italic" id="bib.bib9.2.2">
      IEEE Transactions on Intelligent
Transportation Systems
     </em>
     , vol. 19, no. 11, pp. 3461–3474, 2018.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib10">
    <span class="ltx_tag ltx_tag_bibitem">
     [10]
    </span>
    <span class="ltx_bibblock">
     L. Wang
     <em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">
      et al.
     </em>
     , “Plan-and-solve prompting: Improving zero-shot
chain-of-thought reasoning by large language models,”
     <em class="ltx_emph ltx_font_italic" id="bib.bib10.2.2">
      arXiv preprint
arXiv:2305.04091
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib11">
    <span class="ltx_tag ltx_tag_bibitem">
     [11]
    </span>
    <span class="ltx_bibblock">
     N. Shinn, B. Labash, and A. Gopinath, “Reflexion: an autonomous agent with
dynamic memory and self-reflection,”
     <em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">
      arXiv preprint arXiv:2303.11366
     </em>
     ,
2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib12">
    <span class="ltx_tag ltx_tag_bibitem">
     [12]
    </span>
    <span class="ltx_bibblock">
     A. Madaan
     <em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">
      et al.
     </em>
     , “Self-refine: Iterative refinement with
self-feedback,”
     <em class="ltx_emph ltx_font_italic" id="bib.bib12.2.2">
      arXiv preprint arXiv:2303.17651
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib13">
    <span class="ltx_tag ltx_tag_bibitem">
     [13]
    </span>
    <span class="ltx_bibblock">
     W. Yang
     <em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">
      et al.
     </em>
     , “Semantic communication meets edge intelligence,”
     <em class="ltx_emph ltx_font_italic" id="bib.bib13.2.2">
      IEEE Wireless Communications
     </em>
     , vol. 29, no. 5, pp. 28–35, 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib14">
    <span class="ltx_tag ltx_tag_bibitem">
     [14]
    </span>
    <span class="ltx_bibblock">
     C. Danescu-Niculescu-Mizil
     <em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">
      et al.
     </em>
     , “You had me at hello: How phrasing
affects memorability,” in
     <em class="ltx_emph ltx_font_italic" id="bib.bib14.2.2">
      Proceedings of the 50th Annual Meeting of
the Association for Computational Linguistics (Volume 1: Long Papers)
     </em>
     , 2012,
pp. 892–901.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib15">
    <span class="ltx_tag ltx_tag_bibitem">
     [15]
    </span>
    <span class="ltx_bibblock">
     N. Reimers and I. Gurevych, “Sentence-bert: Sentence embeddings using siamese
bert-networks,” in
     <em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">
      Proceedings of the 2019 Conference on Empirical
Methods in Natural Language Processing and the 9th International Joint
Conference on Natural Language Processing (EMNLP-IJCNLP)
     </em>
     , 2019, pp.
3982–3992.
    </span>
   </li>
  </ul>
 </section>
 <section class="ltx_section" id="Sx1">
  <h2 class="ltx_title ltx_font_smallcaps ltx_title_section">
   Biographies
  </h2>
  <div class="ltx_para" id="Sx1.p1">
   <p class="ltx_p" id="Sx1.p1.1">
    <span class="ltx_text ltx_font_bold" id="Sx1.p1.1.1">
     Feibo Jiang
    </span>
    (jiangfb@hunnu.edu.cn) received Ph.D. degree from the Central South University, China. He is currently an Associate Professor at Hunan Normal University, China.
   </p>
  </div>
  <div class="ltx_para" id="Sx1.p2">
   <p class="ltx_p" id="Sx1.p2.1">
    <span class="ltx_text ltx_font_bold" id="Sx1.p2.1.1">
     Li Dong
    </span>
    (Dlj2017@hunnu.edu.cn) received Ph.D. degree from the Central South University, China. She is currently an Associate Professor at Hunan University of Technology and Business, China.
   </p>
  </div>
  <div class="ltx_para" id="Sx1.p3">
   <p class="ltx_p" id="Sx1.p3.1">
    <span class="ltx_text ltx_font_bold" id="Sx1.p3.1.1">
     Yubo Peng
    </span>
    (pengyubo@hunnu.edu.cn) is currently pursuing the master’s degree with Hunan Normal University, China.
   </p>
  </div>
  <div class="ltx_para" id="Sx1.p4">
   <p class="ltx_p" id="Sx1.p4.1">
    <span class="ltx_text ltx_font_bold" id="Sx1.p4.1.1">
     Kezhi Wang
    </span>
    (Kezhi.Wang@brunel.ac.uk) received Ph.D. degree from University of Warwick, U.K. in 2015. Currently he is a Senior Lecturer with the Department of Computer Science, Brunel University London, U.K.
   </p>
  </div>
  <div class="ltx_para" id="Sx1.p5">
   <p class="ltx_p" id="Sx1.p5.1">
    <span class="ltx_text ltx_font_bold" id="Sx1.p5.1.1">
     Kun Yang
    </span>
    (kunyang@essex.ac.uk) received his PhD from the Department of Electronic &amp; Electrical Engineering of University College London (UCL), U.K. He is currently a Chair Professor in the School of Computer Science &amp; Electronic Engineering, University of Essex, U.K.
   </p>
  </div>
  <div class="ltx_para" id="Sx1.p6">
   <p class="ltx_p" id="Sx1.p6.1">
    <span class="ltx_text ltx_font_bold" id="Sx1.p6.1.1">
     Cunhua Pan
    </span>
    (cpan@seu.edu.cn) received Ph.D. degrees from Southeast University, China, in 2015.
He is a full professor in Southeast University, China.
   </p>
  </div>
  <div class="ltx_para" id="Sx1.p7">
   <p class="ltx_p" id="Sx1.p7.1">
    <span class="ltx_text ltx_font_bold" id="Sx1.p7.1.1">
     Dusit Niyato
    </span>
    (dniyato@ntu.edu.sg) received the Ph.D. degree in electrical and computer engineering from the University of Manitoba in Canada in 2008. He is a professor in the School of Computer Science and Engineering, Nanyang Technological University, 639798 Singapore.
   </p>
  </div>
  <div class="ltx_para" id="Sx1.p8">
   <p class="ltx_p" id="Sx1.p8.1">
    <span class="ltx_text ltx_font_bold" id="Sx1.p8.1.1">
     Octavia A. Dobre
    </span>
    (odobre@mun.ca) is a professor and Canada Research Chair Tier 1 at Memorial University, Canada. She is a Fellow of the Canadian Academy of Engineering, Fellow of the Engineering Institute of Canada, and elected member of the European Academy of Sciences and Arts. She is the Director of Journals of the IEEE Communications Society.
   </p>
  </div>
 </section>
</article>
