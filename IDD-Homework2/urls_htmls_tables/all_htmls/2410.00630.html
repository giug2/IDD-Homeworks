<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Cafca: High-quality Novel View Synthesis of Expressive Faces from Casual Few-shot Captures</title>
<!--Generated on Tue Oct  1 01:46:15 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<meta content="Neural rendering,  face reconstruction,  novel view synthesis,  sparse reconstruction,  synthetic data" lang="en" name="keywords"/>
<base href="/html/2410.00630v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#S1" title="In Cafca: High-quality Novel View Synthesis of Expressive Faces from Casual Few-shot Captures"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#S2" title="In Cafca: High-quality Novel View Synthesis of Expressive Faces from Casual Few-shot Captures"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Related Work</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#S2.SS0.SSS0.Px1" title="In 2. Related Work ‣ Cafca: High-quality Novel View Synthesis of Expressive Faces from Casual Few-shot Captures"><span class="ltx_text ltx_ref_title">Regularization</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#S2.SS0.SSS0.Px2" title="In 2. Related Work ‣ Cafca: High-quality Novel View Synthesis of Expressive Faces from Casual Few-shot Captures"><span class="ltx_text ltx_ref_title">Initialization</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#S2.SS0.SSS0.Px3" title="In 2. Related Work ‣ Cafca: High-quality Novel View Synthesis of Expressive Faces from Casual Few-shot Captures"><span class="ltx_text ltx_ref_title">Data-driven Priors</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#S3" title="In Cafca: High-quality Novel View Synthesis of Expressive Faces from Casual Few-shot Captures"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Method</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#S3.SS1" title="In 3. Method ‣ Cafca: High-quality Novel View Synthesis of Expressive Faces from Casual Few-shot Captures"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Background: NeRF and Preface</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#S3.SS1.SSS0.Px1" title="In 3.1. Background: NeRF and Preface ‣ 3. Method ‣ Cafca: High-quality Novel View Synthesis of Expressive Faces from Casual Few-shot Captures"><span class="ltx_text ltx_ref_title">NeRF</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#S3.SS1.SSS0.Px2" title="In 3.1. Background: NeRF and Preface ‣ 3. Method ‣ Cafca: High-quality Novel View Synthesis of Expressive Faces from Casual Few-shot Captures"><span class="ltx_text ltx_ref_title">Preface</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#S3.SS2" title="In 3. Method ‣ Cafca: High-quality Novel View Synthesis of Expressive Faces from Casual Few-shot Captures"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Pretraining an Expressive Prior Model</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#S3.SS3" title="In 3. Method ‣ Cafca: High-quality Novel View Synthesis of Expressive Faces from Casual Few-shot Captures"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>Inference from Sparse Views</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#S3.SS3.SSS1" title="In 3.3. Inference from Sparse Views ‣ 3. Method ‣ Cafca: High-quality Novel View Synthesis of Expressive Faces from Casual Few-shot Captures"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3.1 </span>3DMM Fitting and Camera Estimation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection">
<a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#S3.SS3.SSS2" title="In 3.3. Inference from Sparse Views ‣ 3. Method ‣ Cafca: High-quality Novel View Synthesis of Expressive Faces from Casual Few-shot Captures"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3.2 </span>Fine-tuning on Sparse Views</span></a>
<ol class="ltx_toclist ltx_toclist_subsubsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#S3.SS3.SSS2.Px1" title="In 3.3.2. Fine-tuning on Sparse Views ‣ 3.3. Inference from Sparse Views ‣ 3. Method ‣ Cafca: High-quality Novel View Synthesis of Expressive Faces from Casual Few-shot Captures"><span class="ltx_text ltx_ref_title">Warm-up by Latent Code Inversion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#S3.SS3.SSS2.Px2" title="In 3.3.2. Fine-tuning on Sparse Views ‣ 3.3. Inference from Sparse Views ‣ 3. Method ‣ Cafca: High-quality Novel View Synthesis of Expressive Faces from Casual Few-shot Captures"><span class="ltx_text ltx_ref_title">Model Fitting</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#S3.SS3.SSS2.Px3" title="In 3.3.2. Fine-tuning on Sparse Views ‣ 3.3. Inference from Sparse Views ‣ 3. Method ‣ Cafca: High-quality Novel View Synthesis of Expressive Faces from Casual Few-shot Captures"><span class="ltx_text ltx_ref_title">Inference In-the-wild</span></a></li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#S4" title="In Cafca: High-quality Novel View Synthesis of Expressive Faces from Casual Few-shot Captures"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Experiments</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#S4.SS1" title="In 4. Experiments ‣ Cafca: High-quality Novel View Synthesis of Expressive Faces from Casual Few-shot Captures"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Quantitative Evaluation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#S4.SS2" title="In 4. Experiments ‣ Cafca: High-quality Novel View Synthesis of Expressive Faces from Casual Few-shot Captures"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Qualitative Results in the Wild</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#S4.SS3" title="In 4. Experiments ‣ Cafca: High-quality Novel View Synthesis of Expressive Faces from Casual Few-shot Captures"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3 </span>Ablation Study</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#S4.SS3.SSS0.Px1" title="In 4.3. Ablation Study ‣ 4. Experiments ‣ Cafca: High-quality Novel View Synthesis of Expressive Faces from Casual Few-shot Captures"><span class="ltx_text ltx_ref_title">Dataset Size</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#S4.SS3.SSS0.Px2" title="In 4.3. Ablation Study ‣ 4. Experiments ‣ Cafca: High-quality Novel View Synthesis of Expressive Faces from Casual Few-shot Captures"><span class="ltx_text ltx_ref_title">Number of Pre-training Steps</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#S4.SS3.SSS0.Px3" title="In 4.3. Ablation Study ‣ 4. Experiments ‣ Cafca: High-quality Novel View Synthesis of Expressive Faces from Casual Few-shot Captures"><span class="ltx_text ltx_ref_title">Synthetic Data Quality</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#S4.SS3.SSS0.Px4" title="In 4.3. Ablation Study ‣ 4. Experiments ‣ Cafca: High-quality Novel View Synthesis of Expressive Faces from Casual Few-shot Captures"><span class="ltx_text ltx_ref_title">Including Real Data</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#S4.SS4" title="In 4. Experiments ‣ Cafca: High-quality Novel View Synthesis of Expressive Faces from Casual Few-shot Captures"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.4 </span>Limitations</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#S5" title="In Cafca: High-quality Novel View Synthesis of Expressive Faces from Casual Few-shot Captures"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Conclusion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#A1" title="In Cafca: High-quality Novel View Synthesis of Expressive Faces from Casual Few-shot Captures"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A </span>Supplementary</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#A1.SS1" title="In Appendix A Supplementary ‣ Cafca: High-quality Novel View Synthesis of Expressive Faces from Casual Few-shot Captures"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.1 </span>Dataset Details</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#A1.SS2" title="In Appendix A Supplementary ‣ Cafca: High-quality Novel View Synthesis of Expressive Faces from Casual Few-shot Captures"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.2 </span>Method Details</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection">
<a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#A1.SS2.SSS1" title="In A.2. Method Details ‣ Appendix A Supplementary ‣ Cafca: High-quality Novel View Synthesis of Expressive Faces from Casual Few-shot Captures"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.2.1 </span>Prior Model Details</span></a>
<ol class="ltx_toclist ltx_toclist_subsubsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#A1.SS2.SSS1.Px1" title="In A.2.1. Prior Model Details ‣ A.2. Method Details ‣ Appendix A Supplementary ‣ Cafca: High-quality Novel View Synthesis of Expressive Faces from Casual Few-shot Captures"><span class="ltx_text ltx_ref_title">Architecture</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#A1.SS2.SSS1.Px2" title="In A.2.1. Prior Model Details ‣ A.2. Method Details ‣ Appendix A Supplementary ‣ Cafca: High-quality Novel View Synthesis of Expressive Faces from Casual Few-shot Captures"><span class="ltx_text ltx_ref_title">Training</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#A1.SS2.SSS1.Px3" title="In A.2.1. Prior Model Details ‣ A.2. Method Details ‣ Appendix A Supplementary ‣ Cafca: High-quality Novel View Synthesis of Expressive Faces from Casual Few-shot Captures"><span class="ltx_text ltx_ref_title">Losses</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#A1.SS3" title="In Appendix A Supplementary ‣ Cafca: High-quality Novel View Synthesis of Expressive Faces from Casual Few-shot Captures"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.3 </span>Inference Details</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#A1.SS3.SSS0.Px1" title="In A.3. Inference Details ‣ Appendix A Supplementary ‣ Cafca: High-quality Novel View Synthesis of Expressive Faces from Casual Few-shot Captures"><span class="ltx_text ltx_ref_title">3DMM Fitting</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#A1.SS3.SSS0.Px2" title="In A.3. Inference Details ‣ Appendix A Supplementary ‣ Cafca: High-quality Novel View Synthesis of Expressive Faces from Casual Few-shot Captures"><span class="ltx_text ltx_ref_title">Warm-up by Inversion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#A1.SS3.SSS0.Px3" title="In A.3. Inference Details ‣ Appendix A Supplementary ‣ Cafca: High-quality Novel View Synthesis of Expressive Faces from Casual Few-shot Captures"><span class="ltx_text ltx_ref_title">Optimization</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#A1.SS3.SSS0.Px4" title="In A.3. Inference Details ‣ Appendix A Supplementary ‣ Cafca: High-quality Novel View Synthesis of Expressive Faces from Casual Few-shot Captures"><span class="ltx_text ltx_ref_title">Losses</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#A1.SS3.SSS0.Px5" title="In A.3. Inference Details ‣ Appendix A Supplementary ‣ Cafca: High-quality Novel View Synthesis of Expressive Faces from Casual Few-shot Captures"><span class="ltx_text ltx_ref_title">Rendering Time</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#A1.SS4" title="In Appendix A Supplementary ‣ Cafca: High-quality Novel View Synthesis of Expressive Faces from Casual Few-shot Captures"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.4 </span>Experimental Details</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#A1.SS4.SSS1" title="In A.4. Experimental Details ‣ Appendix A Supplementary ‣ Cafca: High-quality Novel View Synthesis of Expressive Faces from Casual Few-shot Captures"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.4.1 </span>Multiface Dataset</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#A1.SS4.SSS2" title="In A.4. Experimental Details ‣ Appendix A Supplementary ‣ Cafca: High-quality Novel View Synthesis of Expressive Faces from Casual Few-shot Captures"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.4.2 </span>Preface Dataset</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#A1.SS5" title="In Appendix A Supplementary ‣ Cafca: High-quality Novel View Synthesis of Expressive Faces from Casual Few-shot Captures"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.5 </span>Supplementary Results</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#A1.SS5.SSS1" title="In A.5. Supplementary Results ‣ Appendix A Supplementary ‣ Cafca: High-quality Novel View Synthesis of Expressive Faces from Casual Few-shot Captures"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.5.1 </span>In-the-wild Results</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#A1.SS5.SSS2" title="In A.5. Supplementary Results ‣ Appendix A Supplementary ‣ Cafca: High-quality Novel View Synthesis of Expressive Faces from Casual Few-shot Captures"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.5.2 </span>Supplementary Ablations and Comparisons</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#A1.SS6" title="In Appendix A Supplementary ‣ Cafca: High-quality Novel View Synthesis of Expressive Faces from Casual Few-shot Captures"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.6 </span>Ethics</span></a></li>
</ol>
</li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line ltx_leqno">
<figure class="ltx_figure ltx_teaserfigure" id="S0.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="270" id="S0.F1.g1" src="x1.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1. </span>We propose a method for high-quality novel view synthesis of expressive faces captured in-the-wild. From a casual capture with only three images, our method synthesizes novel views at an unprecedented level of detail showing wrinkles, hair strands, skin pores, and eyelashes.</figcaption>
</figure>
<h1 class="ltx_title ltx_title_document">Cafca: High-quality Novel View Synthesis of Expressive Faces from Casual Few-shot Captures</h1>
<div class="ltx_subtitle">
<a class="ltx_ref ltx_href" href="https://syntec-research.github.io/Cafca" title="">https://syntec-research.github.io/Cafca</a>
</div>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Marcel C. Buehler
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_orcid"><a class="ltx_ref" href="https://orcid.org/0000-0001-8104-9313" title="ORCID identifier">0000-0001-8104-9313</a></span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id1.1.id1">ETH Zurich</span><span class="ltx_text ltx_affiliation_country" id="id2.2.id2">Switzerland</span>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Gengyan Li
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_orcid"><a class="ltx_ref" href="https://orcid.org/0000-0002-1427-7612" title="ORCID identifier">0000-0002-1427-7612</a></span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id3.1.id1">ETH Zurich and Google</span><span class="ltx_text ltx_affiliation_country" id="id4.2.id2">Switzerland</span>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Erroll Wood
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_orcid"><a class="ltx_ref" href="https://orcid.org/0009-0006-2033-4704" title="ORCID identifier">0009-0006-2033-4704</a></span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id5.1.id1">Google</span><span class="ltx_text ltx_affiliation_country" id="id6.2.id2">UK</span>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Leonhard Helminger
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_orcid"><a class="ltx_ref" href="https://orcid.org/0000-0001-8528-2059" title="ORCID identifier">0000-0001-8528-2059</a></span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id7.1.id1">Google</span><span class="ltx_text ltx_affiliation_country" id="id8.2.id2">Switzerland</span>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Xu Chen
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_orcid"><a class="ltx_ref" href="https://orcid.org/0000-0003-1715-2820" title="ORCID identifier">0000-0003-1715-2820</a></span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id9.1.id1">Google</span><span class="ltx_text ltx_affiliation_country" id="id10.2.id2">Switzerland</span>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Tanmay Shah
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_orcid"><a class="ltx_ref" href="https://orcid.org/0009-0007-6492-8413" title="ORCID identifier">0009-0007-6492-8413</a></span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id11.1.id1">Google</span><span class="ltx_text ltx_affiliation_country" id="id12.2.id2">USA</span>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Daoye Wang
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_orcid"><a class="ltx_ref" href="https://orcid.org/0000-0002-2879-6114" title="ORCID identifier">0000-0002-2879-6114</a></span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id13.1.id1">Google</span><span class="ltx_text ltx_affiliation_country" id="id14.2.id2">Switzerland</span>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Stephan Garbin
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_orcid"><a class="ltx_ref" href="https://orcid.org/0009-0000-5005-8110" title="ORCID identifier">0009-0000-5005-8110</a></span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id15.1.id1">Google</span><span class="ltx_text ltx_affiliation_country" id="id16.2.id2">UK</span>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Sergio Orts-Escolano
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_orcid"><a class="ltx_ref" href="https://orcid.org/0000-0001-6817-6326" title="ORCID identifier">0000-0001-6817-6326</a></span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id17.1.id1">Google</span><span class="ltx_text ltx_affiliation_country" id="id18.2.id2">Switzerland</span>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Otmar Hilliges
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_orcid"><a class="ltx_ref" href="https://orcid.org/0000-0002-5068-3474" title="ORCID identifier">0000-0002-5068-3474</a></span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id19.1.id1">ETH Zurich</span><span class="ltx_text ltx_affiliation_country" id="id20.2.id2">Switzerland</span>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Dmitry Lagun
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_orcid"><a class="ltx_ref" href="https://orcid.org/0009-0002-5077-3469" title="ORCID identifier">0009-0002-5077-3469</a></span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id21.1.id1">Google</span><span class="ltx_text ltx_affiliation_country" id="id22.2.id2">USA</span>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Jérémy Riviere
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_orcid"><a class="ltx_ref" href="https://orcid.org/0000-0002-5249-5135" title="ORCID identifier">0000-0002-5249-5135</a></span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id23.1.id1">Google</span><span class="ltx_text ltx_affiliation_country" id="id24.2.id2">Switzerland</span>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Paulo Gotardo
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_orcid"><a class="ltx_ref" href="https://orcid.org/0000-0001-8217-5848" title="ORCID identifier">0000-0001-8217-5848</a></span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id25.1.id1">Google</span><span class="ltx_text ltx_affiliation_country" id="id26.2.id2">Switzerland</span>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Thabo Beeler
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_orcid"><a class="ltx_ref" href="https://orcid.org/0000-0002-8077-1205" title="ORCID identifier">0000-0002-8077-1205</a></span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id27.1.id1">Google</span><span class="ltx_text ltx_affiliation_country" id="id28.2.id2">Switzerland</span>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Abhimitra Meka
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_orcid"><a class="ltx_ref" href="https://orcid.org/0000-0001-7906-4004" title="ORCID identifier">0000-0001-7906-4004</a></span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id29.1.id1">Google</span><span class="ltx_text ltx_affiliation_country" id="id30.2.id2">USA</span>
</span></span></span>
<span class="ltx_author_before"> and </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Kripasindhu Sarkar
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_orcid"><a class="ltx_ref" href="https://orcid.org/0000-0002-0220-0853" title="ORCID identifier">0000-0002-0220-0853</a></span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id31.1.id1">Google</span><span class="ltx_text ltx_affiliation_country" id="id32.2.id2">Switzerland</span>
</span></span></span>
</div>
<div class="ltx_dates">(2024)</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract.</h6>
<p class="ltx_p" id="id33.id1">Volumetric modeling and neural radiance field representations have revolutionized 3D face capture and photorealistic novel view synthesis. However, these methods often require hundreds of multi-view input images and are thus inapplicable to cases with less than a handful of inputs.
We present a novel volumetric prior on human faces that allows for high-fidelity expressive face modeling from as few as three input views captured in the wild. Our key insight is that an implicit prior trained on synthetic data alone can generalize to extremely challenging real-world identities and expressions and render novel views with fine idiosyncratic details like wrinkles and eyelashes.
We leverage a 3D Morphable Face Model to synthesize a large training set, rendering each identity with different expressions, hair, clothing, and other assets. We then train a conditional Neural Radiance Field prior on this synthetic dataset and, at inference time, fine-tune the model on a very sparse set of real images of a single subject. On average, the fine-tuning requires only three inputs to cross the synthetic-to-real domain gap. The resulting personalized 3D model reconstructs strong idiosyncratic facial expressions and outperforms the state-of-the-art in high-quality novel view synthesis of faces from sparse inputs in terms of perceptual and photo-metric quality.</p>
</div>
<div class="ltx_keywords">Neural rendering, face reconstruction, novel view synthesis, sparse reconstruction, synthetic data
</div>
<span class="ltx_note ltx_note_frontmatter ltx_role_submissionid" id="id1"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">submissionid: </span>253</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_journalyear" id="id2"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">journalyear: </span>2024</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_copyright" id="id3"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">copyright: </span>rightsretained</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_conference" id="id4"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">conference: </span>SIGGRAPH Asia 2024 Conference Papers; December 3–6, 2024; Tokyo, Japan</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_booktitle" id="id5"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">booktitle: </span>SIGGRAPH Asia 2024 Conference Papers (SA Conference Papers ’24), December 3–6, 2024, Tokyo, Japan</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_doi" id="id6"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">doi: </span>10.1145/3680528.3687580</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_isbn" id="id7"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">isbn: </span>979-8-4007-1131-2/24/12</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_ccs" id="id8"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">ccs: </span>Computing methodologies Reconstruction</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_ccs" id="id9"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">ccs: </span>Computing methodologies Shape representations</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_ccs" id="id10"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">ccs: </span>Computing methodologies Appearance and texture representations</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_ccs" id="id11"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">ccs: </span>Computing methodologies Neural networks</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_ccs" id="id12"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">ccs: </span>Computing methodologies Volumetric models</span></span></span>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1. </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">“Who sees the human face correctly: the photographer, the mirror, or the painter?” - Pablo Picasso. Our visual acuity is remarkably hypertuned to perceive the details of human faces due to evolutionary design <cite class="ltx_cite ltx_citemacro_citep">(Pascalis and Kelly, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib49" title="">2009</a>)</cite>. Individual-specific expressions play a particularly significant role in perception tasks such as identification or estimation of emotion and intent <cite class="ltx_cite ltx_citemacro_citep">(Sinha et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib58" title="">2006</a>; Kret, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib30" title="">2015</a>; Lee and Anderson, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib32" title="">2017</a>)</cite>. Highly personalizable 3D representations that model the idiosyncracies of face shape and deformation at high quality are crucial to truly immersive and photorealistic 3D portrait photography. Perhaps, if trained well, an AI could join Picasso’s list.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">Wide-scale adoption and democratization of 3D portrait photography demands casual captures in uncontrolled environments – <em class="ltx_emph ltx_font_italic" id="S1.p2.1.1">i.e.</em>, only a few shots taken with a handheld camera.
Volumetric representations <cite class="ltx_cite ltx_citemacro_citep">(Mildenhall et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib40" title="">2020</a>; Barron et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib3" title="">2022</a>; Park et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib47" title="">2021a</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib48" title="">b</a>)</cite>, have demonstrated impressive quality and photorealism in synthesizing novel views of a large variety of 3D scenes using densely captured 2D images. Extended works relax the requirement for dense capture through various forms of regularization – for instance, entropy minimization <cite class="ltx_cite ltx_citemacro_citep">(Rebain et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib54" title="">2022</a>)</cite>, spatial smoothness <cite class="ltx_cite ltx_citemacro_citep">(Niemeyer et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib42" title="">2022</a>)</cite>, depth regularization <cite class="ltx_cite ltx_citemacro_citep">(Prinzler et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib51" title="">2023</a>; Guangcong et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib22" title="">2023</a>)</cite> and volume bounds <cite class="ltx_cite ltx_citemacro_citep">(Sarkar et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib55" title="">2023</a>)</cite>. These methods target general scenes and still require dozens of views captured simultaneously. As such, they cannot be applied to expressive 3D portrait photography in the wild, due to ambiguities that arise from the limited input and uncontrolled conditions.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">Lifting very sparse 2D views onto a 3D reconstruction requires a strong face prior, crafted using diverse data captured across the human population. However, large real datasets are expensive and challenging to collect and typically suffer from low resolution, sampling limitations, and biases in their coverage of diversity and detail of facial geometry and appearance, under varied viewpoints and lighting. Here, our key insight is that such prior can be built from synthetic data alone and fine-tuned on a few real-world images to bridge the synthetic-real domain gap, generalizing robustly to challenging portraits captured in the wild, as shown in Figs. <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#S0.F1" title="Figure 1 ‣ Cafca: High-quality Novel View Synthesis of Expressive Faces from Casual Few-shot Captures"><span class="ltx_text ltx_ref_tag">1</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#S5.F9" title="Figure 9 ‣ Cafca: High-quality Novel View Synthesis of Expressive Faces from Casual Few-shot Captures"><span class="ltx_text ltx_ref_tag">9</span></a>.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">Recent works have shown that well-curated, calibrated, and diverse datasets can be built from synthetic graphical renderings. Such data has been successfully applied to various face perception tasks, including sparse problems like landmark localization and segmentation <cite class="ltx_cite ltx_citemacro_citep">(Wood et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib72" title="">2021</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib73" title="">2022</a>)</cite> and dense problems like view synthesis <cite class="ltx_cite ltx_citemacro_citep">(Sun et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib60" title="">2021</a>)</cite> and relighting <cite class="ltx_cite ltx_citemacro_citep">(Yeh et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib79" title="">2022</a>)</cite>. However, such synthetic data is unable to model the full light transport of complex interactions like sub-surface scattering, specular polarization, and global illumination, thus presenting a significant domain gap. Interestingly, sparse regression problems can robustly overcome such gaps at inference time. In contrast, denser synthesis problems cannot, requiring domain adaptation solutions that suffer from quality losses that prevent their use in building a 3D face prior.</p>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">We propose a novel, volumetric facial prior that is learned from a large dataset of synthetic images of different identities and expressions, rendered with accessories like hair and beard styles, glasses, clothing, and skin textures.
At inference time, given a few input images at arbitrary resolutions, we fine-tune this prior to reconstruct a high-quality, personalized volumetric model of the captured subject. This new model then allows for 3D-consistent novel view synthesis at high resolution, even when the original input shows exaggerated facial expressions and challenging lighting conditions. We overcome the domain gap between synthetic and real by using an MLP-based generator for volumetric rendering.
This MLP learns a strong prior over geometry while generalizing to unseen appearance domains, including colored lighting and shadows. We demonstrate the efficacy of our method through extensive evaluation, ablations, and comparison with the state of the art.</p>
</div>
<div class="ltx_para" id="S1.p6">
<p class="ltx_p" id="S1.p6.1">In summary, our key contributions are:</p>
<ul class="ltx_itemize" id="S1.I1">
<li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i1.p1">
<p class="ltx_p" id="S1.I1.i1.p1.1">We show that synthetic data alone can be successfully leveraged to learn a strong face prior for few-shot, personalized 3D face modeling in the wild.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i2.p1">
<p class="ltx_p" id="S1.I1.i2.p1.1">Our new model and few-shot fine-tuning method can robustly reconstruct expressive faces under challenging in-the-wild lighting and synthesize photorealistic novel views with unprecedented quality and fine-scale idiosyncratic details.</p>
</div>
</li>
</ul>
<p class="ltx_p" id="S1.p6.2">Our synthetic dataset is available for research purposes at 
<br class="ltx_break"/><a class="ltx_ref ltx_href" href="https://syntec-research.github.io/Cafca" title="">https://syntec-research.github.io/Cafca</a>.</p>
</div>
<figure class="ltx_figure" id="S1.F2">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S1.F2.4.4">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S1.F2.4.4.4">
<td class="ltx_td ltx_align_center" id="S1.F2.1.1.1.1" style="padding-left:2.0pt;padding-right:2.0pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="79" id="S1.F2.1.1.1.1.g1" src="extracted/5891401/figures/details_in_3dmm/sub0_gt_cropped_0.jpg" width="79"/></td>
<td class="ltx_td ltx_align_center" id="S1.F2.2.2.2.2" style="padding-left:2.0pt;padding-right:2.0pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="512" id="S1.F2.2.2.2.2.g1" src="extracted/5891401/figures/details_in_3dmm/sub0_3dmm.jpg" width="512"/></td>
<td class="ltx_td ltx_align_center" id="S1.F2.4.4.4.4" style="padding-left:2.0pt;padding-right:2.0pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="512" id="S1.F2.3.3.3.3.g1" src="extracted/5891401/figures/details_in_3dmm/sub0_color_pred.jpg" width="512"/><span class="ltx_text" id="S1.F2.4.4.4.4.1" style="font-size:90%;">
</span><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="512" id="S1.F2.4.4.4.4.g2" src="extracted/5891401/figures/details_in_3dmm/sub0_normals_pred.jpg" width="512"/>
</td>
</tr>
<tr class="ltx_tr" id="S1.F2.4.4.5.1">
<td class="ltx_td ltx_align_center" id="S1.F2.4.4.5.1.1" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S1.F2.4.4.5.1.1.1" style="font-size:90%;">Input</span></td>
<td class="ltx_td ltx_align_center" id="S1.F2.4.4.5.1.2" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S1.F2.4.4.5.1.2.1" style="font-size:90%;">3DMM Fit</span></td>
<td class="ltx_td ltx_align_center" id="S1.F2.4.4.5.1.3" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S1.F2.4.4.5.1.3.1" style="font-size:90%;">Reconstruction with Normals</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 2. </span>Our method reconstructs details that go far beyond the capabilities of our synthetic dataset. We show a crop of one of the input views from the teaser and its corresponding 3DMM fit. While the 3DMM lacks details, our reconstruction models the wrinkles on the forehead.</figcaption>
</figure>
<figure class="ltx_figure" id="S1.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="186" id="S1.F3.g1" src="x2.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3. </span>Method Overview. We train an implicit prior model on renderings of a 3DMM combined with assets like hair, beard, clothing, and more (Sec. <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#S3.SS2" title="3.2. Pretraining an Expressive Prior Model ‣ 3. Method ‣ Cafca: High-quality Novel View Synthesis of Expressive Faces from Casual Few-shot Captures"><span class="ltx_text ltx_ref_tag">3.2</span></a>). For inference, we first estimate the camera, identity, and expression parameters (Sec. <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#S3.SS3.SSS1" title="3.3.1. 3DMM Fitting and Camera Estimation ‣ 3.3. Inference from Sparse Views ‣ 3. Method ‣ Cafca: High-quality Novel View Synthesis of Expressive Faces from Casual Few-shot Captures"><span class="ltx_text ltx_ref_tag">3.3.1</span></a>) and then fine-tune the implicit model (Sec. <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#S3.SS3.SSS2" title="3.3.2. Fine-tuning on Sparse Views ‣ 3.3. Inference from Sparse Views ‣ 3. Method ‣ Cafca: High-quality Novel View Synthesis of Expressive Faces from Casual Few-shot Captures"><span class="ltx_text ltx_ref_tag">3.3.2</span></a>).
The implicit prior trained on synthetic data alone can generalize to extremely difficult real-world expressions and render fine details like wrinkles and eyelashes (Figs. <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#S0.F1" title="Figure 1 ‣ Cafca: High-quality Novel View Synthesis of Expressive Faces from Casual Few-shot Captures"><span class="ltx_text ltx_ref_tag">1</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#S5.F9" title="Figure 9 ‣ Cafca: High-quality Novel View Synthesis of Expressive Faces from Casual Few-shot Captures"><span class="ltx_text ltx_ref_tag">9</span></a>).
While we show three input views for the average case, our method can also work with one (Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#S5.F10" title="Figure 10 ‣ Cafca: High-quality Novel View Synthesis of Expressive Faces from Casual Few-shot Captures"><span class="ltx_text ltx_ref_tag">10</span></a>) or more input views (supplementary material).</figcaption>
</figure>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2. </span>Related Work</h2>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">Multiple works have explored ways to mitigate the data-intensive nature of volumetric reconstruction, where some main themes have emerged: regularization schemes <cite class="ltx_cite ltx_citemacro_citep">(Niemeyer et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib42" title="">2022</a>; Yang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib78" title="">2023</a>; Rebain et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib54" title="">2022</a>; Jain et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib26" title="">2021</a>; Truong et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib65" title="">2023</a>)</cite>, carefully crafted initialization of model parameters <cite class="ltx_cite ltx_citemacro_citep">(Tancik et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib62" title="">2021</a>; Vora et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib67" title="">2021</a>; Kundu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib31" title="">2022</a>)</cite>,
depth signals or feature embeddings <cite class="ltx_cite ltx_citemacro_citep">(Jain et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib26" title="">2021</a>; Truong et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib65" title="">2023</a>; Guangcong et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib22" title="">2023</a>)</cite>, and data-driven, pre-trained priors <cite class="ltx_cite ltx_citemacro_citep">(Rebain et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib54" title="">2022</a>; Chan et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib11" title="">2022</a>; Gu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib21" title="">2021</a>; Ramon et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib52" title="">2021</a>; Tan et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib61" title="">2022</a>; Yu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib80" title="">2021</a>; Wang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib69" title="">2021</a>; Mihajlovic et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib39" title="">2022</a>; Chen et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib13" title="">2021</a>; Prinzler et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib51" title="">2023</a>; Truong et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib65" title="">2023</a>; Jain et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib26" title="">2021</a>; Zhang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib83" title="">2022</a>; Buehler et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib9" title="">2023</a>; Or-El et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib44" title="">2022</a>)</cite>.</p>
</div>
<section class="ltx_paragraph" id="S2.SS0.SSS0.Px1">
<h5 class="ltx_title ltx_title_paragraph">Regularization</h5>
<div class="ltx_para" id="S2.SS0.SSS0.Px1.p1">
<p class="ltx_p" id="S2.SS0.SSS0.Px1.p1.1">RegNeRF <cite class="ltx_cite ltx_citemacro_citep">(Niemeyer et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib42" title="">2022</a>)</cite> employs a smoothness regularization term on the expected depth derived from the predicted density, in conjunction with a patch-based regularizer on appearance which together bias the model towards a 3D consistent solution. FreeNeRF <cite class="ltx_cite ltx_citemacro_citep">(Yang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib78" title="">2023</a>)</cite> proposes a gradual, coarse-to-fine training scheme to prevent overfitting caused by high-frequency, position encoding components early in the fit. Despite their promising results on in-the-wild images, these methods cannot yet provide high-quality reconstructions from few-shot inputs, as we show in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#S5.F7" title="Figure 7 ‣ Cafca: High-quality Novel View Synthesis of Expressive Faces from Casual Few-shot Captures"><span class="ltx_text ltx_ref_tag">7</span></a>.</p>
</div>
</section>
<section class="ltx_paragraph" id="S2.SS0.SSS0.Px2">
<h5 class="ltx_title ltx_title_paragraph">Initialization</h5>
<div class="ltx_para" id="S2.SS0.SSS0.Px2.p1">
<p class="ltx_p" id="S2.SS0.SSS0.Px2.p1.1">A common strategy is to learn initial model parameters <cite class="ltx_cite ltx_citemacro_citep">(Finn et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib18" title="">2017</a>; Nichol et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib41" title="">2018</a>; Sitzmann et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib59" title="">2020</a>; Zakharov et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib81" title="">2019</a>; Tancik et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib62" title="">2021</a>)</cite> from a large collection of images. While this strategy has been shown to offer faster convergence, its applicability to high-resolution settings remains challenging due to computational requirements of large neural networks.</p>
</div>
</section>
<section class="ltx_paragraph" id="S2.SS0.SSS0.Px3">
<h5 class="ltx_title ltx_title_paragraph">Data-driven Priors</h5>
<div class="ltx_para" id="S2.SS0.SSS0.Px3.p1">
<p class="ltx_p" id="S2.SS0.SSS0.Px3.p1.1">With the advent of large datasets of particular domains <cite class="ltx_cite ltx_citemacro_citep">(Choi et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib14" title="">2020</a>; Liu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib35" title="">2018</a>; Karras et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib27" title="">2019</a>)</cite>, recent works have explored data-driven priors trained on a corpus of data specific to the reconstruction task at hand. Generative neural field models in particular  <cite class="ltx_cite ltx_citemacro_citep">(Chan et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib11" title="">2022</a>; Gu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib21" title="">2021</a>; Zhou et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib88" title="">2021</a>; Deng et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib15" title="">2022a</a>; Rebain et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib54" title="">2022</a>; Chan et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib12" title="">2021</a>; Niemeyer and Geiger, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib43" title="">2021</a>; Schwarz et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib56" title="">2020</a>; Tan et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib61" title="">2022</a>; Rao et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib53" title="">2022</a>; Wang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib68" title="">2022</a>; Deng et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib16" title="">2022b</a>)</cite> have shown promising results.
To tackle the heavy computational and memory requirement of volumetric rendering, EG3D <cite class="ltx_cite ltx_citemacro_citep">(Chan et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib11" title="">2022</a>)</cite> proposes to use a lightweight tri-plane feature representation. Most of these models further rely on an extra 2D super-resolution step <cite class="ltx_cite ltx_citemacro_citep">(Chan et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib11" title="">2022</a>; Gu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib21" title="">2021</a>; Tan et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib61" title="">2022</a>; Chan et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib12" title="">2021</a>; Wang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib70" title="">2023</a>; Hong et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib25" title="">2022</a>)</cite> as they can only be trained at low resolutions due to high memory footprint requirements.</p>
</div>
<div class="ltx_para" id="S2.SS0.SSS0.Px3.p2">
<p class="ltx_p" id="S2.SS0.SSS0.Px3.p2.1">Recent works <cite class="ltx_cite ltx_citemacro_citep">(Wang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib68" title="">2022</a>; Cao et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib10" title="">2022</a>; Buehler et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib9" title="">2023</a>)</cite> have overcome the need for 2D super-resolution. MoRF <cite class="ltx_cite ltx_citemacro_citep">(Wang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib68" title="">2022</a>)</cite> learns a conditional neural reflectance field of faces from a small training dataset comprising of 12 views of 15 real subjects making neutral expressions, further augmented with synthetic renderings.  <cite class="ltx_cite ltx_citemacro_citep">(Cao et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib10" title="">2022</a>)</cite> trains an avatar prior with a Mixture of Volumetric Primitives (MVP) <cite class="ltx_cite ltx_citemacro_citep">(Lombardi et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib36" title="">2021</a>)</cite> from data captured in a controlled environment. They leverage their model to fine-tune to a specific target subject’s identity based on a short sequence of a casually captured RGB-D video. Another line of work leverages 2D generative priors <cite class="ltx_cite ltx_citemacro_citep">(Liu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib34" title="">2023</a>; Melas-Kyriazi et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib38" title="">2023</a>; Tang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib63" title="">2023</a>; Wu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib74" title="">2024</a>; Zeng et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib82" title="">2023</a>; Massague et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib37" title="">2024</a>)</cite>. These methods typically employ score distillation sampling <cite class="ltx_cite ltx_citemacro_citep">(Poole et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib50" title="">2022</a>; Wang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib71" title="">2024</a>)</cite> for injecting signals from unseen views given text prompts or sparse input images.</p>
</div>
<div class="ltx_para" id="S2.SS0.SSS0.Px3.p3">
<p class="ltx_p" id="S2.SS0.SSS0.Px3.p3.1">Multiple recent works have leveraged 3D Morphable Face Models (3DMM) <cite class="ltx_cite ltx_citemacro_citep">(Blanz and Vetter, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib5" title="">1999</a>)</cite> as strong priors. This has led to the development of avatars that can be driven by 3DMM expression coefficients <cite class="ltx_cite ltx_citemacro_citep">(Xu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib77" title="">2023</a>; Zheng et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib87" title="">2023</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib86" title="">2022</a>; Niemeyer et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib42" title="">2022</a>; Zhao et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib85" title="">2023</a>; Duan et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib17" title="">2023</a>; Buehler et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib8" title="">2021</a>; Li et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib33" title="">2024</a>)</cite>. Such avatars are typically trained on a sequence of monocular video frames showing various head poses and facial expressions. Other works have explored the reconstruction of faces and textures from a single input image <cite class="ltx_cite ltx_citemacro_citep">(Gao et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib19" title="">2020</a>; Vinod et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib66" title="">2024</a>; Papantoniou et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib46" title="">2023</a>)</cite>. Another body of work has explored novel view synthesis from sparse inputs by training their model as an auto-encoder, coupled with image-based rendering. These methods <cite class="ltx_cite ltx_citemacro_citep">(Yu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib80" title="">2021</a>; Wang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib69" title="">2021</a>; Mihajlovic et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib39" title="">2022</a>; Chen et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib13" title="">2021</a>)</cite> typically train a convolutional encoder that maps input images to 2D feature maps in images-space to condition the scene’s volume. This approach can typically be extended with additional priors such as keypoints <cite class="ltx_cite ltx_citemacro_citep">(Mihajlovic et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib39" title="">2022</a>)</cite>, depth <cite class="ltx_cite ltx_citemacro_citep">(Prinzler et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib51" title="">2023</a>; Xu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib76" title="">2022</a>; Guangcong et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib22" title="">2023</a>)</cite> or pixel-matches across input views <cite class="ltx_cite ltx_citemacro_citep">(Truong et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib65" title="">2023</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S2.SS0.SSS0.Px3.p4">
<p class="ltx_p" id="S2.SS0.SSS0.Px3.p4.1">Preface <cite class="ltx_cite ltx_citemacro_citep">(Buehler et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib9" title="">2023</a>)</cite> is a method for high-quality face avatar creation in which they train a low-resolution, generative prior on a dataset of facial identities captured in-studio.
They could not reconstruct strong expressions due to the domain limitation of their prior model trained only on neutral faces. Our method tackles this challenging problem and we demonstrate compelling examples of novel view synthesis of expressive faces from sparse inputs.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3. </span>Method</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">We present a method that takes as input as few as three images of a person’s face – of arbitrary identity, expression, and lighting condition – and reconstructs a personalized 3D face model that can render high-quality, photorealistic novel views of that person, including fine details like freckles, wrinkles, eyelashes, and teeth.</p>
</div>
<div class="ltx_para" id="S3.p2">
<p class="ltx_p" id="S3.p2.1">To overcome reconstruction ambiguities, our method uses a pre-trained volumetric face model as prior, trained on a large dataset of synthetic faces with a variety of identities, expressions, and viewpoints rendered in a single environment.
At inference time, our method first fits the coefficients of our prior model to a small set of real input images. It then further fine-tunes the model weights and effectively performs domain adaptation during the few-shot reconstruction process, see Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#S1.F3" title="Figure 3 ‣ 1. Introduction ‣ Cafca: High-quality Novel View Synthesis of Expressive Faces from Casual Few-shot Captures"><span class="ltx_text ltx_ref_tag">3</span></a>.
While the prior model is trained only once on a large collection of synthetic face images, the inference-time optimization is performed on a per-subject basis from as few as three (<em class="ltx_emph ltx_font_italic" id="S3.p2.1.1">e.g.</em>, smartphone) images captured in-the-wild (see Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#S5.F9" title="Figure 9 ‣ Cafca: High-quality Novel View Synthesis of Expressive Faces from Casual Few-shot Captures"><span class="ltx_text ltx_ref_tag">9</span></a>).</p>
</div>
<div class="ltx_para" id="S3.p3">
<p class="ltx_p" id="S3.p3.1">This section starts with background information (Sec. <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#S3.SS1" title="3.1. Background: NeRF and Preface ‣ 3. Method ‣ Cafca: High-quality Novel View Synthesis of Expressive Faces from Casual Few-shot Captures"><span class="ltx_text ltx_ref_tag">3.1</span></a>), details the training of synthetic prior (Sec. <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#S3.SS2" title="3.2. Pretraining an Expressive Prior Model ‣ 3. Method ‣ Cafca: High-quality Novel View Synthesis of Expressive Faces from Casual Few-shot Captures"><span class="ltx_text ltx_ref_tag">3.2</span></a>) and then finetuning from three input views (Sec. <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#S3.SS3" title="3.3. Inference from Sparse Views ‣ 3. Method ‣ Cafca: High-quality Novel View Synthesis of Expressive Faces from Casual Few-shot Captures"><span class="ltx_text ltx_ref_tag">3.3</span></a>).</p>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1. </span>Background: NeRF and Preface</h3>
<section class="ltx_paragraph" id="S3.SS1.SSS0.Px1">
<h5 class="ltx_title ltx_title_paragraph">NeRF</h5>
<div class="ltx_para" id="S3.SS1.SSS0.Px1.p1">
<p class="ltx_p" id="S3.SS1.SSS0.Px1.p1.10">Our prior face model is built upon Neural Radiance Fields (NeRF) <cite class="ltx_cite ltx_citemacro_citep">(Mildenhall et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib40" title="">2020</a>)</cite>. NeRFs represent 3D objects as density and (emissive) radiance fields parameterized by neural networks. Given a camera ray <span class="ltx_text ltx_markedasmath ltx_font_bold" id="S3.SS1.SSS0.Px1.p1.10.1">r</span>, a NeRF samples 3D points <span class="ltx_text ltx_markedasmath ltx_font_bold" id="S3.SS1.SSS0.Px1.p1.10.2">x</span> along the ray that are fed together with the view direction <span class="ltx_text ltx_markedasmath ltx_font_bold" id="S3.SS1.SSS0.Px1.p1.10.3">d</span> into an MLP. The output is the corresponding density <math alttext="\sigma" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px1.p1.4.m4.1"><semantics id="S3.SS1.SSS0.Px1.p1.4.m4.1a"><mi id="S3.SS1.SSS0.Px1.p1.4.m4.1.1" xref="S3.SS1.SSS0.Px1.p1.4.m4.1.1.cmml">σ</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px1.p1.4.m4.1b"><ci id="S3.SS1.SSS0.Px1.p1.4.m4.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.4.m4.1.1">𝜎</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px1.p1.4.m4.1c">\sigma</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS0.Px1.p1.4.m4.1d">italic_σ</annotation></semantics></math> and color value <span class="ltx_text ltx_markedasmath ltx_font_bold" id="S3.SS1.SSS0.Px1.p1.10.4">c</span> at <span class="ltx_text ltx_markedasmath ltx_font_bold" id="S3.SS1.SSS0.Px1.p1.10.5">x</span>. A NeRF is rendered into any view via volumetric rendering. The color <math alttext="{\bf c({\bf p})}" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px1.p1.7.m7.1"><semantics id="S3.SS1.SSS0.Px1.p1.7.m7.1a"><mrow id="S3.SS1.SSS0.Px1.p1.7.m7.1.2" xref="S3.SS1.SSS0.Px1.p1.7.m7.1.2.cmml"><mi id="S3.SS1.SSS0.Px1.p1.7.m7.1.2.2" xref="S3.SS1.SSS0.Px1.p1.7.m7.1.2.2.cmml">𝐜</mi><mo id="S3.SS1.SSS0.Px1.p1.7.m7.1.2.1" xref="S3.SS1.SSS0.Px1.p1.7.m7.1.2.1.cmml">⁢</mo><mrow id="S3.SS1.SSS0.Px1.p1.7.m7.1.2.3.2" xref="S3.SS1.SSS0.Px1.p1.7.m7.1.2.cmml"><mo id="S3.SS1.SSS0.Px1.p1.7.m7.1.2.3.2.1" stretchy="false" xref="S3.SS1.SSS0.Px1.p1.7.m7.1.2.cmml">(</mo><mi id="S3.SS1.SSS0.Px1.p1.7.m7.1.1" xref="S3.SS1.SSS0.Px1.p1.7.m7.1.1.cmml">𝐩</mi><mo id="S3.SS1.SSS0.Px1.p1.7.m7.1.2.3.2.2" stretchy="false" xref="S3.SS1.SSS0.Px1.p1.7.m7.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px1.p1.7.m7.1b"><apply id="S3.SS1.SSS0.Px1.p1.7.m7.1.2.cmml" xref="S3.SS1.SSS0.Px1.p1.7.m7.1.2"><times id="S3.SS1.SSS0.Px1.p1.7.m7.1.2.1.cmml" xref="S3.SS1.SSS0.Px1.p1.7.m7.1.2.1"></times><ci id="S3.SS1.SSS0.Px1.p1.7.m7.1.2.2.cmml" xref="S3.SS1.SSS0.Px1.p1.7.m7.1.2.2">𝐜</ci><ci id="S3.SS1.SSS0.Px1.p1.7.m7.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.7.m7.1.1">𝐩</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px1.p1.7.m7.1c">{\bf c({\bf p})}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS0.Px1.p1.7.m7.1d">bold_c ( bold_p )</annotation></semantics></math> of a pixel <math alttext="{\bf p}" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px1.p1.8.m8.1"><semantics id="S3.SS1.SSS0.Px1.p1.8.m8.1a"><mi id="S3.SS1.SSS0.Px1.p1.8.m8.1.1" xref="S3.SS1.SSS0.Px1.p1.8.m8.1.1.cmml">𝐩</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px1.p1.8.m8.1b"><ci id="S3.SS1.SSS0.Px1.p1.8.m8.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.8.m8.1.1">𝐩</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px1.p1.8.m8.1c">{\bf p}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS0.Px1.p1.8.m8.1d">bold_p</annotation></semantics></math> is determined by compositing the density and color along the camera ray <math alttext="\mathbf{r}" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px1.p1.9.m9.1"><semantics id="S3.SS1.SSS0.Px1.p1.9.m9.1a"><mi id="S3.SS1.SSS0.Px1.p1.9.m9.1.1" xref="S3.SS1.SSS0.Px1.p1.9.m9.1.1.cmml">𝐫</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px1.p1.9.m9.1b"><ci id="S3.SS1.SSS0.Px1.p1.9.m9.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.9.m9.1.1">𝐫</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px1.p1.9.m9.1c">\mathbf{r}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS0.Px1.p1.9.m9.1d">bold_r</annotation></semantics></math> within an interval between a near and a far camera plane <math alttext="[t_{n},t_{f}]" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px1.p1.10.m10.2"><semantics id="S3.SS1.SSS0.Px1.p1.10.m10.2a"><mrow id="S3.SS1.SSS0.Px1.p1.10.m10.2.2.2" xref="S3.SS1.SSS0.Px1.p1.10.m10.2.2.3.cmml"><mo id="S3.SS1.SSS0.Px1.p1.10.m10.2.2.2.3" stretchy="false" xref="S3.SS1.SSS0.Px1.p1.10.m10.2.2.3.cmml">[</mo><msub id="S3.SS1.SSS0.Px1.p1.10.m10.1.1.1.1" xref="S3.SS1.SSS0.Px1.p1.10.m10.1.1.1.1.cmml"><mi id="S3.SS1.SSS0.Px1.p1.10.m10.1.1.1.1.2" xref="S3.SS1.SSS0.Px1.p1.10.m10.1.1.1.1.2.cmml">t</mi><mi id="S3.SS1.SSS0.Px1.p1.10.m10.1.1.1.1.3" xref="S3.SS1.SSS0.Px1.p1.10.m10.1.1.1.1.3.cmml">n</mi></msub><mo id="S3.SS1.SSS0.Px1.p1.10.m10.2.2.2.4" xref="S3.SS1.SSS0.Px1.p1.10.m10.2.2.3.cmml">,</mo><msub id="S3.SS1.SSS0.Px1.p1.10.m10.2.2.2.2" xref="S3.SS1.SSS0.Px1.p1.10.m10.2.2.2.2.cmml"><mi id="S3.SS1.SSS0.Px1.p1.10.m10.2.2.2.2.2" xref="S3.SS1.SSS0.Px1.p1.10.m10.2.2.2.2.2.cmml">t</mi><mi id="S3.SS1.SSS0.Px1.p1.10.m10.2.2.2.2.3" xref="S3.SS1.SSS0.Px1.p1.10.m10.2.2.2.2.3.cmml">f</mi></msub><mo id="S3.SS1.SSS0.Px1.p1.10.m10.2.2.2.5" stretchy="false" xref="S3.SS1.SSS0.Px1.p1.10.m10.2.2.3.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px1.p1.10.m10.2b"><interval closure="closed" id="S3.SS1.SSS0.Px1.p1.10.m10.2.2.3.cmml" xref="S3.SS1.SSS0.Px1.p1.10.m10.2.2.2"><apply id="S3.SS1.SSS0.Px1.p1.10.m10.1.1.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.10.m10.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px1.p1.10.m10.1.1.1.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.10.m10.1.1.1.1">subscript</csymbol><ci id="S3.SS1.SSS0.Px1.p1.10.m10.1.1.1.1.2.cmml" xref="S3.SS1.SSS0.Px1.p1.10.m10.1.1.1.1.2">𝑡</ci><ci id="S3.SS1.SSS0.Px1.p1.10.m10.1.1.1.1.3.cmml" xref="S3.SS1.SSS0.Px1.p1.10.m10.1.1.1.1.3">𝑛</ci></apply><apply id="S3.SS1.SSS0.Px1.p1.10.m10.2.2.2.2.cmml" xref="S3.SS1.SSS0.Px1.p1.10.m10.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px1.p1.10.m10.2.2.2.2.1.cmml" xref="S3.SS1.SSS0.Px1.p1.10.m10.2.2.2.2">subscript</csymbol><ci id="S3.SS1.SSS0.Px1.p1.10.m10.2.2.2.2.2.cmml" xref="S3.SS1.SSS0.Px1.p1.10.m10.2.2.2.2.2">𝑡</ci><ci id="S3.SS1.SSS0.Px1.p1.10.m10.2.2.2.2.3.cmml" xref="S3.SS1.SSS0.Px1.p1.10.m10.2.2.2.2.3">𝑓</ci></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px1.p1.10.m10.2c">[t_{n},t_{f}]</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS0.Px1.p1.10.m10.2d">[ italic_t start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT , italic_t start_POSTSUBSCRIPT italic_f end_POSTSUBSCRIPT ]</annotation></semantics></math>:</p>
</div>
<div class="ltx_para" id="S3.SS1.SSS0.Px1.p2">
<table class="ltx_equationgroup ltx_eqn_align ltx_eqn_table" id="A1.EGx1">
<tbody id="S3.E1"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_left">(1)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle\mathbf{c}(\mathbf{p})=\textbf{F}_{\theta}(\textbf{r})=\int_{t_{n%
}}^{t_{f}}T(t)\sigma(\textbf{r}(t))\textbf{c}(\textbf{r}(t),\textbf{d})dt\text%
{,}" class="ltx_Math" display="inline" id="S3.E1.m1.8"><semantics id="S3.E1.m1.8a"><mrow id="S3.E1.m1.8.8" xref="S3.E1.m1.8.8.cmml"><mrow id="S3.E1.m1.8.8.4" xref="S3.E1.m1.8.8.4.cmml"><mi id="S3.E1.m1.8.8.4.2" xref="S3.E1.m1.8.8.4.2.cmml">𝐜</mi><mo id="S3.E1.m1.8.8.4.1" xref="S3.E1.m1.8.8.4.1.cmml">⁢</mo><mrow id="S3.E1.m1.8.8.4.3.2" xref="S3.E1.m1.8.8.4.cmml"><mo id="S3.E1.m1.8.8.4.3.2.1" stretchy="false" xref="S3.E1.m1.8.8.4.cmml">(</mo><mi id="S3.E1.m1.1.1" xref="S3.E1.m1.1.1.cmml">𝐩</mi><mo id="S3.E1.m1.8.8.4.3.2.2" stretchy="false" xref="S3.E1.m1.8.8.4.cmml">)</mo></mrow></mrow><mo id="S3.E1.m1.8.8.5" xref="S3.E1.m1.8.8.5.cmml">=</mo><mrow id="S3.E1.m1.8.8.6" xref="S3.E1.m1.8.8.6.cmml"><msub id="S3.E1.m1.8.8.6.2" xref="S3.E1.m1.8.8.6.2.cmml"><mtext class="ltx_mathvariant_bold" id="S3.E1.m1.8.8.6.2.2" xref="S3.E1.m1.8.8.6.2.2a.cmml">F</mtext><mi id="S3.E1.m1.8.8.6.2.3" xref="S3.E1.m1.8.8.6.2.3.cmml">θ</mi></msub><mo id="S3.E1.m1.8.8.6.1" xref="S3.E1.m1.8.8.6.1.cmml">⁢</mo><mrow id="S3.E1.m1.8.8.6.3.2" xref="S3.E1.m1.2.2a.cmml"><mo id="S3.E1.m1.8.8.6.3.2.1" stretchy="false" xref="S3.E1.m1.2.2a.cmml">(</mo><mtext class="ltx_mathvariant_bold" id="S3.E1.m1.2.2" xref="S3.E1.m1.2.2.cmml">r</mtext><mo id="S3.E1.m1.8.8.6.3.2.2" stretchy="false" xref="S3.E1.m1.2.2a.cmml">)</mo></mrow></mrow><mo id="S3.E1.m1.8.8.7" xref="S3.E1.m1.8.8.7.cmml">=</mo><mrow id="S3.E1.m1.8.8.2" xref="S3.E1.m1.8.8.2.cmml"><mstyle displaystyle="true" id="S3.E1.m1.8.8.2.3" xref="S3.E1.m1.8.8.2.3.cmml"><msubsup id="S3.E1.m1.8.8.2.3a" xref="S3.E1.m1.8.8.2.3.cmml"><mo id="S3.E1.m1.8.8.2.3.2.2" xref="S3.E1.m1.8.8.2.3.2.2.cmml">∫</mo><msub id="S3.E1.m1.8.8.2.3.2.3" xref="S3.E1.m1.8.8.2.3.2.3.cmml"><mi id="S3.E1.m1.8.8.2.3.2.3.2" xref="S3.E1.m1.8.8.2.3.2.3.2.cmml">t</mi><mi id="S3.E1.m1.8.8.2.3.2.3.3" xref="S3.E1.m1.8.8.2.3.2.3.3.cmml">n</mi></msub><msub id="S3.E1.m1.8.8.2.3.3" xref="S3.E1.m1.8.8.2.3.3.cmml"><mi id="S3.E1.m1.8.8.2.3.3.2" xref="S3.E1.m1.8.8.2.3.3.2.cmml">t</mi><mi id="S3.E1.m1.8.8.2.3.3.3" xref="S3.E1.m1.8.8.2.3.3.3.cmml">f</mi></msub></msubsup></mstyle><mrow id="S3.E1.m1.8.8.2.2" xref="S3.E1.m1.8.8.2.2.cmml"><mi id="S3.E1.m1.8.8.2.2.4" xref="S3.E1.m1.8.8.2.2.4.cmml">T</mi><mo id="S3.E1.m1.8.8.2.2.3" xref="S3.E1.m1.8.8.2.2.3.cmml">⁢</mo><mrow id="S3.E1.m1.8.8.2.2.5.2" xref="S3.E1.m1.8.8.2.2.cmml"><mo id="S3.E1.m1.8.8.2.2.5.2.1" stretchy="false" xref="S3.E1.m1.8.8.2.2.cmml">(</mo><mi id="S3.E1.m1.3.3" xref="S3.E1.m1.3.3.cmml">t</mi><mo id="S3.E1.m1.8.8.2.2.5.2.2" stretchy="false" xref="S3.E1.m1.8.8.2.2.cmml">)</mo></mrow><mo id="S3.E1.m1.8.8.2.2.3a" xref="S3.E1.m1.8.8.2.2.3.cmml">⁢</mo><mi id="S3.E1.m1.8.8.2.2.6" xref="S3.E1.m1.8.8.2.2.6.cmml">σ</mi><mo id="S3.E1.m1.8.8.2.2.3b" xref="S3.E1.m1.8.8.2.2.3.cmml">⁢</mo><mrow id="S3.E1.m1.7.7.1.1.1.1" xref="S3.E1.m1.7.7.1.1.1.1.1.cmml"><mo id="S3.E1.m1.7.7.1.1.1.1.2" stretchy="false" xref="S3.E1.m1.7.7.1.1.1.1.1.cmml">(</mo><mrow id="S3.E1.m1.7.7.1.1.1.1.1" xref="S3.E1.m1.7.7.1.1.1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S3.E1.m1.7.7.1.1.1.1.1.2" xref="S3.E1.m1.7.7.1.1.1.1.1.2a.cmml">r</mtext><mo id="S3.E1.m1.7.7.1.1.1.1.1.1" xref="S3.E1.m1.7.7.1.1.1.1.1.1.cmml">⁢</mo><mrow id="S3.E1.m1.7.7.1.1.1.1.1.3.2" xref="S3.E1.m1.7.7.1.1.1.1.1.cmml"><mo id="S3.E1.m1.7.7.1.1.1.1.1.3.2.1" stretchy="false" xref="S3.E1.m1.7.7.1.1.1.1.1.cmml">(</mo><mi id="S3.E1.m1.4.4" xref="S3.E1.m1.4.4.cmml">t</mi><mo id="S3.E1.m1.7.7.1.1.1.1.1.3.2.2" stretchy="false" xref="S3.E1.m1.7.7.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E1.m1.7.7.1.1.1.1.3" stretchy="false" xref="S3.E1.m1.7.7.1.1.1.1.1.cmml">)</mo></mrow><mo id="S3.E1.m1.8.8.2.2.3c" xref="S3.E1.m1.8.8.2.2.3.cmml">⁢</mo><mtext class="ltx_mathvariant_bold" id="S3.E1.m1.8.8.2.2.7" xref="S3.E1.m1.8.8.2.2.7a.cmml">c</mtext><mo id="S3.E1.m1.8.8.2.2.3d" xref="S3.E1.m1.8.8.2.2.3.cmml">⁢</mo><mrow id="S3.E1.m1.8.8.2.2.2.1" xref="S3.E1.m1.8.8.2.2.2.2.cmml"><mo id="S3.E1.m1.8.8.2.2.2.1.2" stretchy="false" xref="S3.E1.m1.8.8.2.2.2.2.cmml">(</mo><mrow id="S3.E1.m1.8.8.2.2.2.1.1" xref="S3.E1.m1.8.8.2.2.2.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S3.E1.m1.8.8.2.2.2.1.1.2" xref="S3.E1.m1.8.8.2.2.2.1.1.2a.cmml">r</mtext><mo id="S3.E1.m1.8.8.2.2.2.1.1.1" xref="S3.E1.m1.8.8.2.2.2.1.1.1.cmml">⁢</mo><mrow id="S3.E1.m1.8.8.2.2.2.1.1.3.2" xref="S3.E1.m1.8.8.2.2.2.1.1.cmml"><mo id="S3.E1.m1.8.8.2.2.2.1.1.3.2.1" stretchy="false" xref="S3.E1.m1.8.8.2.2.2.1.1.cmml">(</mo><mi id="S3.E1.m1.5.5" xref="S3.E1.m1.5.5.cmml">t</mi><mo id="S3.E1.m1.8.8.2.2.2.1.1.3.2.2" stretchy="false" xref="S3.E1.m1.8.8.2.2.2.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E1.m1.8.8.2.2.2.1.3" xref="S3.E1.m1.8.8.2.2.2.2.cmml">,</mo><mtext class="ltx_mathvariant_bold" id="S3.E1.m1.6.6" xref="S3.E1.m1.6.6a.cmml">d</mtext><mo id="S3.E1.m1.8.8.2.2.2.1.4" stretchy="false" xref="S3.E1.m1.8.8.2.2.2.2.cmml">)</mo></mrow><mo id="S3.E1.m1.8.8.2.2.3e" lspace="0em" xref="S3.E1.m1.8.8.2.2.3.cmml">⁢</mo><mrow id="S3.E1.m1.8.8.2.2.8" xref="S3.E1.m1.8.8.2.2.8.cmml"><mo id="S3.E1.m1.8.8.2.2.8.1" rspace="0em" xref="S3.E1.m1.8.8.2.2.8.1.cmml">𝑑</mo><mi id="S3.E1.m1.8.8.2.2.8.2" xref="S3.E1.m1.8.8.2.2.8.2.cmml">t</mi></mrow><mo id="S3.E1.m1.8.8.2.2.3f" xref="S3.E1.m1.8.8.2.2.3.cmml">⁢</mo><mtext id="S3.E1.m1.8.8.2.2.9" xref="S3.E1.m1.8.8.2.2.9a.cmml">,</mtext></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.8b"><apply id="S3.E1.m1.8.8.cmml" xref="S3.E1.m1.8.8"><and id="S3.E1.m1.8.8a.cmml" xref="S3.E1.m1.8.8"></and><apply id="S3.E1.m1.8.8b.cmml" xref="S3.E1.m1.8.8"><eq id="S3.E1.m1.8.8.5.cmml" xref="S3.E1.m1.8.8.5"></eq><apply id="S3.E1.m1.8.8.4.cmml" xref="S3.E1.m1.8.8.4"><times id="S3.E1.m1.8.8.4.1.cmml" xref="S3.E1.m1.8.8.4.1"></times><ci id="S3.E1.m1.8.8.4.2.cmml" xref="S3.E1.m1.8.8.4.2">𝐜</ci><ci id="S3.E1.m1.1.1.cmml" xref="S3.E1.m1.1.1">𝐩</ci></apply><apply id="S3.E1.m1.8.8.6.cmml" xref="S3.E1.m1.8.8.6"><times id="S3.E1.m1.8.8.6.1.cmml" xref="S3.E1.m1.8.8.6.1"></times><apply id="S3.E1.m1.8.8.6.2.cmml" xref="S3.E1.m1.8.8.6.2"><csymbol cd="ambiguous" id="S3.E1.m1.8.8.6.2.1.cmml" xref="S3.E1.m1.8.8.6.2">subscript</csymbol><ci id="S3.E1.m1.8.8.6.2.2a.cmml" xref="S3.E1.m1.8.8.6.2.2"><mtext class="ltx_mathvariant_bold" id="S3.E1.m1.8.8.6.2.2.cmml" xref="S3.E1.m1.8.8.6.2.2">F</mtext></ci><ci id="S3.E1.m1.8.8.6.2.3.cmml" xref="S3.E1.m1.8.8.6.2.3">𝜃</ci></apply><ci id="S3.E1.m1.2.2a.cmml" xref="S3.E1.m1.8.8.6.3.2"><mtext class="ltx_mathvariant_bold" id="S3.E1.m1.2.2.cmml" xref="S3.E1.m1.2.2">r</mtext></ci></apply></apply><apply id="S3.E1.m1.8.8c.cmml" xref="S3.E1.m1.8.8"><eq id="S3.E1.m1.8.8.7.cmml" xref="S3.E1.m1.8.8.7"></eq><share href="https://arxiv.org/html/2410.00630v1#S3.E1.m1.8.8.6.cmml" id="S3.E1.m1.8.8d.cmml" xref="S3.E1.m1.8.8"></share><apply id="S3.E1.m1.8.8.2.cmml" xref="S3.E1.m1.8.8.2"><apply id="S3.E1.m1.8.8.2.3.cmml" xref="S3.E1.m1.8.8.2.3"><csymbol cd="ambiguous" id="S3.E1.m1.8.8.2.3.1.cmml" xref="S3.E1.m1.8.8.2.3">superscript</csymbol><apply id="S3.E1.m1.8.8.2.3.2.cmml" xref="S3.E1.m1.8.8.2.3"><csymbol cd="ambiguous" id="S3.E1.m1.8.8.2.3.2.1.cmml" xref="S3.E1.m1.8.8.2.3">subscript</csymbol><int id="S3.E1.m1.8.8.2.3.2.2.cmml" xref="S3.E1.m1.8.8.2.3.2.2"></int><apply id="S3.E1.m1.8.8.2.3.2.3.cmml" xref="S3.E1.m1.8.8.2.3.2.3"><csymbol cd="ambiguous" id="S3.E1.m1.8.8.2.3.2.3.1.cmml" xref="S3.E1.m1.8.8.2.3.2.3">subscript</csymbol><ci id="S3.E1.m1.8.8.2.3.2.3.2.cmml" xref="S3.E1.m1.8.8.2.3.2.3.2">𝑡</ci><ci id="S3.E1.m1.8.8.2.3.2.3.3.cmml" xref="S3.E1.m1.8.8.2.3.2.3.3">𝑛</ci></apply></apply><apply id="S3.E1.m1.8.8.2.3.3.cmml" xref="S3.E1.m1.8.8.2.3.3"><csymbol cd="ambiguous" id="S3.E1.m1.8.8.2.3.3.1.cmml" xref="S3.E1.m1.8.8.2.3.3">subscript</csymbol><ci id="S3.E1.m1.8.8.2.3.3.2.cmml" xref="S3.E1.m1.8.8.2.3.3.2">𝑡</ci><ci id="S3.E1.m1.8.8.2.3.3.3.cmml" xref="S3.E1.m1.8.8.2.3.3.3">𝑓</ci></apply></apply><apply id="S3.E1.m1.8.8.2.2.cmml" xref="S3.E1.m1.8.8.2.2"><times id="S3.E1.m1.8.8.2.2.3.cmml" xref="S3.E1.m1.8.8.2.2.3"></times><ci id="S3.E1.m1.8.8.2.2.4.cmml" xref="S3.E1.m1.8.8.2.2.4">𝑇</ci><ci id="S3.E1.m1.3.3.cmml" xref="S3.E1.m1.3.3">𝑡</ci><ci id="S3.E1.m1.8.8.2.2.6.cmml" xref="S3.E1.m1.8.8.2.2.6">𝜎</ci><apply id="S3.E1.m1.7.7.1.1.1.1.1.cmml" xref="S3.E1.m1.7.7.1.1.1.1"><times id="S3.E1.m1.7.7.1.1.1.1.1.1.cmml" xref="S3.E1.m1.7.7.1.1.1.1.1.1"></times><ci id="S3.E1.m1.7.7.1.1.1.1.1.2a.cmml" xref="S3.E1.m1.7.7.1.1.1.1.1.2"><mtext class="ltx_mathvariant_bold" id="S3.E1.m1.7.7.1.1.1.1.1.2.cmml" xref="S3.E1.m1.7.7.1.1.1.1.1.2">r</mtext></ci><ci id="S3.E1.m1.4.4.cmml" xref="S3.E1.m1.4.4">𝑡</ci></apply><ci id="S3.E1.m1.8.8.2.2.7a.cmml" xref="S3.E1.m1.8.8.2.2.7"><mtext class="ltx_mathvariant_bold" id="S3.E1.m1.8.8.2.2.7.cmml" xref="S3.E1.m1.8.8.2.2.7">c</mtext></ci><interval closure="open" id="S3.E1.m1.8.8.2.2.2.2.cmml" xref="S3.E1.m1.8.8.2.2.2.1"><apply id="S3.E1.m1.8.8.2.2.2.1.1.cmml" xref="S3.E1.m1.8.8.2.2.2.1.1"><times id="S3.E1.m1.8.8.2.2.2.1.1.1.cmml" xref="S3.E1.m1.8.8.2.2.2.1.1.1"></times><ci id="S3.E1.m1.8.8.2.2.2.1.1.2a.cmml" xref="S3.E1.m1.8.8.2.2.2.1.1.2"><mtext class="ltx_mathvariant_bold" id="S3.E1.m1.8.8.2.2.2.1.1.2.cmml" xref="S3.E1.m1.8.8.2.2.2.1.1.2">r</mtext></ci><ci id="S3.E1.m1.5.5.cmml" xref="S3.E1.m1.5.5">𝑡</ci></apply><ci id="S3.E1.m1.6.6a.cmml" xref="S3.E1.m1.6.6"><mtext class="ltx_mathvariant_bold" id="S3.E1.m1.6.6.cmml" xref="S3.E1.m1.6.6">d</mtext></ci></interval><apply id="S3.E1.m1.8.8.2.2.8.cmml" xref="S3.E1.m1.8.8.2.2.8"><csymbol cd="latexml" id="S3.E1.m1.8.8.2.2.8.1.cmml" xref="S3.E1.m1.8.8.2.2.8.1">differential-d</csymbol><ci id="S3.E1.m1.8.8.2.2.8.2.cmml" xref="S3.E1.m1.8.8.2.2.8.2">𝑡</ci></apply><ci id="S3.E1.m1.8.8.2.2.9a.cmml" xref="S3.E1.m1.8.8.2.2.9"><mtext id="S3.E1.m1.8.8.2.2.9.cmml" xref="S3.E1.m1.8.8.2.2.9">,</mtext></ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.8c">\displaystyle\mathbf{c}(\mathbf{p})=\textbf{F}_{\theta}(\textbf{r})=\int_{t_{n%
}}^{t_{f}}T(t)\sigma(\textbf{r}(t))\textbf{c}(\textbf{r}(t),\textbf{d})dt\text%
{,}</annotation><annotation encoding="application/x-llamapun" id="S3.E1.m1.8d">bold_c ( bold_p ) = F start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT ( r ) = ∫ start_POSTSUBSCRIPT italic_t start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_t start_POSTSUBSCRIPT italic_f end_POSTSUBSCRIPT end_POSTSUPERSCRIPT italic_T ( italic_t ) italic_σ ( r ( italic_t ) ) c ( r ( italic_t ) , d ) italic_d italic_t ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
<tbody id="S3.E2"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_left">(2)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle\text{ where }T(t)=\text{exp}\left(-\int_{t_{n}}^{t}\sigma(%
\textbf{r}(s))ds\right)." class="ltx_Math" display="inline" id="S3.E2.m1.3"><semantics id="S3.E2.m1.3a"><mrow id="S3.E2.m1.3.3.1" xref="S3.E2.m1.3.3.1.1.cmml"><mrow id="S3.E2.m1.3.3.1.1" xref="S3.E2.m1.3.3.1.1.cmml"><mrow id="S3.E2.m1.3.3.1.1.3" xref="S3.E2.m1.3.3.1.1.3.cmml"><mtext id="S3.E2.m1.3.3.1.1.3.2" xref="S3.E2.m1.3.3.1.1.3.2a.cmml">where </mtext><mo id="S3.E2.m1.3.3.1.1.3.1" xref="S3.E2.m1.3.3.1.1.3.1.cmml">⁢</mo><mi id="S3.E2.m1.3.3.1.1.3.3" xref="S3.E2.m1.3.3.1.1.3.3.cmml">T</mi><mo id="S3.E2.m1.3.3.1.1.3.1a" xref="S3.E2.m1.3.3.1.1.3.1.cmml">⁢</mo><mrow id="S3.E2.m1.3.3.1.1.3.4.2" xref="S3.E2.m1.3.3.1.1.3.cmml"><mo id="S3.E2.m1.3.3.1.1.3.4.2.1" stretchy="false" xref="S3.E2.m1.3.3.1.1.3.cmml">(</mo><mi id="S3.E2.m1.1.1" xref="S3.E2.m1.1.1.cmml">t</mi><mo id="S3.E2.m1.3.3.1.1.3.4.2.2" stretchy="false" xref="S3.E2.m1.3.3.1.1.3.cmml">)</mo></mrow></mrow><mo id="S3.E2.m1.3.3.1.1.2" xref="S3.E2.m1.3.3.1.1.2.cmml">=</mo><mrow id="S3.E2.m1.3.3.1.1.1" xref="S3.E2.m1.3.3.1.1.1.cmml"><mtext id="S3.E2.m1.3.3.1.1.1.3" xref="S3.E2.m1.3.3.1.1.1.3a.cmml">exp</mtext><mo id="S3.E2.m1.3.3.1.1.1.2" xref="S3.E2.m1.3.3.1.1.1.2.cmml">⁢</mo><mrow id="S3.E2.m1.3.3.1.1.1.1.1" xref="S3.E2.m1.3.3.1.1.1.1.1.1.cmml"><mo id="S3.E2.m1.3.3.1.1.1.1.1.2" xref="S3.E2.m1.3.3.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E2.m1.3.3.1.1.1.1.1.1" xref="S3.E2.m1.3.3.1.1.1.1.1.1.cmml"><mo id="S3.E2.m1.3.3.1.1.1.1.1.1a" xref="S3.E2.m1.3.3.1.1.1.1.1.1.cmml">−</mo><mrow id="S3.E2.m1.3.3.1.1.1.1.1.1.1" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1.cmml"><mstyle displaystyle="true" id="S3.E2.m1.3.3.1.1.1.1.1.1.1.2" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1.2.cmml"><msubsup id="S3.E2.m1.3.3.1.1.1.1.1.1.1.2a" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1.2.cmml"><mo id="S3.E2.m1.3.3.1.1.1.1.1.1.1.2.2.2" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1.2.2.2.cmml">∫</mo><msub id="S3.E2.m1.3.3.1.1.1.1.1.1.1.2.2.3" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1.2.2.3.cmml"><mi id="S3.E2.m1.3.3.1.1.1.1.1.1.1.2.2.3.2" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1.2.2.3.2.cmml">t</mi><mi id="S3.E2.m1.3.3.1.1.1.1.1.1.1.2.2.3.3" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1.2.2.3.3.cmml">n</mi></msub><mi id="S3.E2.m1.3.3.1.1.1.1.1.1.1.2.3" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1.2.3.cmml">t</mi></msubsup></mstyle><mrow id="S3.E2.m1.3.3.1.1.1.1.1.1.1.1" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.3" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.3.cmml">σ</mi><mo id="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.2" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.2.cmml">⁢</mo><mrow id="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1.1" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.cmml"><mo id="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1.1.2" stretchy="false" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.2a.cmml">r</mtext><mo id="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.cmml">⁢</mo><mrow id="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.3.2" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.cmml"><mo id="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.3.2.1" stretchy="false" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><mi id="S3.E2.m1.2.2" xref="S3.E2.m1.2.2.cmml">s</mi><mo id="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.3.2.2" stretchy="false" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1.1.3" stretchy="false" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow><mo id="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.2a" lspace="0em" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.2.cmml">⁢</mo><mrow id="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.4" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.4.cmml"><mo id="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.4.1" rspace="0em" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.4.1.cmml">𝑑</mo><mi id="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.4.2" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.4.2.cmml">s</mi></mrow></mrow></mrow></mrow><mo id="S3.E2.m1.3.3.1.1.1.1.1.3" xref="S3.E2.m1.3.3.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo id="S3.E2.m1.3.3.1.2" lspace="0em" xref="S3.E2.m1.3.3.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.3b"><apply id="S3.E2.m1.3.3.1.1.cmml" xref="S3.E2.m1.3.3.1"><eq id="S3.E2.m1.3.3.1.1.2.cmml" xref="S3.E2.m1.3.3.1.1.2"></eq><apply id="S3.E2.m1.3.3.1.1.3.cmml" xref="S3.E2.m1.3.3.1.1.3"><times id="S3.E2.m1.3.3.1.1.3.1.cmml" xref="S3.E2.m1.3.3.1.1.3.1"></times><ci id="S3.E2.m1.3.3.1.1.3.2a.cmml" xref="S3.E2.m1.3.3.1.1.3.2"><mtext id="S3.E2.m1.3.3.1.1.3.2.cmml" xref="S3.E2.m1.3.3.1.1.3.2">where </mtext></ci><ci id="S3.E2.m1.3.3.1.1.3.3.cmml" xref="S3.E2.m1.3.3.1.1.3.3">𝑇</ci><ci id="S3.E2.m1.1.1.cmml" xref="S3.E2.m1.1.1">𝑡</ci></apply><apply id="S3.E2.m1.3.3.1.1.1.cmml" xref="S3.E2.m1.3.3.1.1.1"><times id="S3.E2.m1.3.3.1.1.1.2.cmml" xref="S3.E2.m1.3.3.1.1.1.2"></times><ci id="S3.E2.m1.3.3.1.1.1.3a.cmml" xref="S3.E2.m1.3.3.1.1.1.3"><mtext id="S3.E2.m1.3.3.1.1.1.3.cmml" xref="S3.E2.m1.3.3.1.1.1.3">exp</mtext></ci><apply id="S3.E2.m1.3.3.1.1.1.1.1.1.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1"><minus id="S3.E2.m1.3.3.1.1.1.1.1.1.2.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1"></minus><apply id="S3.E2.m1.3.3.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1"><apply id="S3.E2.m1.3.3.1.1.1.1.1.1.1.2.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E2.m1.3.3.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1.2">superscript</csymbol><apply id="S3.E2.m1.3.3.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E2.m1.3.3.1.1.1.1.1.1.1.2.2.1.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1.2">subscript</csymbol><int id="S3.E2.m1.3.3.1.1.1.1.1.1.1.2.2.2.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1.2.2.2"></int><apply id="S3.E2.m1.3.3.1.1.1.1.1.1.1.2.2.3.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1.2.2.3"><csymbol cd="ambiguous" id="S3.E2.m1.3.3.1.1.1.1.1.1.1.2.2.3.1.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1.2.2.3">subscript</csymbol><ci id="S3.E2.m1.3.3.1.1.1.1.1.1.1.2.2.3.2.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1.2.2.3.2">𝑡</ci><ci id="S3.E2.m1.3.3.1.1.1.1.1.1.1.2.2.3.3.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1.2.2.3.3">𝑛</ci></apply></apply><ci id="S3.E2.m1.3.3.1.1.1.1.1.1.1.2.3.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1.2.3">𝑡</ci></apply><apply id="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1.1"><times id="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.2"></times><ci id="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.3">𝜎</ci><apply id="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1.1"><times id="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1"></times><ci id="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.2a.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.2"><mtext class="ltx_mathvariant_bold" id="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.2">r</mtext></ci><ci id="S3.E2.m1.2.2.cmml" xref="S3.E2.m1.2.2">𝑠</ci></apply><apply id="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.4.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.4"><csymbol cd="latexml" id="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.4.1.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.4.1">differential-d</csymbol><ci id="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.4.2.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.4.2">𝑠</ci></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.3c">\displaystyle\text{ where }T(t)=\text{exp}\left(-\int_{t_{n}}^{t}\sigma(%
\textbf{r}(s))ds\right).</annotation><annotation encoding="application/x-llamapun" id="S3.E2.m1.3d">where italic_T ( italic_t ) = exp ( - ∫ start_POSTSUBSCRIPT italic_t start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT italic_σ ( r ( italic_s ) ) italic_d italic_s ) .</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS1.SSS0.Px1.p2.1">The variable <math alttext="\theta" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px1.p2.1.m1.1"><semantics id="S3.SS1.SSS0.Px1.p2.1.m1.1a"><mi id="S3.SS1.SSS0.Px1.p2.1.m1.1.1" xref="S3.SS1.SSS0.Px1.p2.1.m1.1.1.cmml">θ</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px1.p2.1.m1.1b"><ci id="S3.SS1.SSS0.Px1.p2.1.m1.1.1.cmml" xref="S3.SS1.SSS0.Px1.p2.1.m1.1.1">𝜃</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px1.p2.1.m1.1c">\theta</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS0.Px1.p2.1.m1.1d">italic_θ</annotation></semantics></math> denotes the model parameters that are fit to the input data.</p>
</div>
</section>
<section class="ltx_paragraph" id="S3.SS1.SSS0.Px2">
<h5 class="ltx_title ltx_title_paragraph">Preface</h5>
<div class="ltx_para" id="S3.SS1.SSS0.Px2.p1">
<p class="ltx_p" id="S3.SS1.SSS0.Px2.p1.4">Our method also extends Preface <cite class="ltx_cite ltx_citemacro_citep">(Buehler et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib9" title="">2023</a>)</cite>, a method for novel view synthesis of neutral faces given sparse inputs.
Besides the position <span class="ltx_text ltx_markedasmath ltx_font_bold" id="S3.SS1.SSS0.Px2.p1.4.1">x</span> and view direction <span class="ltx_text ltx_markedasmath ltx_font_bold" id="S3.SS1.SSS0.Px2.p1.4.2">d</span>, Preface also takes a learned latent code <span class="ltx_text ltx_markedasmath ltx_font_bold" id="S3.SS1.SSS0.Px2.p1.4.3">w</span> as input. The latent code represents the identity and is optimized while training the model as an auto-decoder <cite class="ltx_cite ltx_citemacro_citep">(Bojanowski et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib7" title="">2018</a>)</cite>. During inference, Preface first projects the sparse input images into its latent space, by optimizing one identity code <span class="ltx_text ltx_markedasmath ltx_font_bold" id="S3.SS1.SSS0.Px2.p1.4.4">w</span>. Then, it fine-tunes all model parameters under regularization constraints on the predicted normals and the view weights.
While Preface excels at high-resolution novel view synthesis of neutral faces, it struggles in the presence of strong, idiosyncratic expressions (Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#S5.F7" title="Figure 7 ‣ Cafca: High-quality Novel View Synthesis of Expressive Faces from Casual Few-shot Captures"><span class="ltx_text ltx_ref_tag">7</span></a>). In the following, we address this limitation while building an improved prior from synthetic images alone.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2. </span>Pretraining an Expressive Prior Model</h3>
<figure class="ltx_figure" id="S3.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="363" id="S3.F4.g1" src="x3.png" width="667"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4. </span> We implement our prior model as a conditional NeRF <cite class="ltx_cite ltx_citemacro_citep">(Mildenhall et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib40" title="">2020</a>; Barron et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib3" title="">2022</a>)</cite>. We condition by concatenating (<math alttext="||" class="ltx_math_unparsed" display="inline" id="S3.F4.8.m1.1"><semantics id="S3.F4.8.m1.1b"><mrow id="S3.F4.8.m1.1c"><mo fence="false" id="S3.F4.8.m1.1.1" rspace="0.167em" stretchy="false">|</mo><mo fence="false" id="S3.F4.8.m1.1.2" stretchy="false">|</mo></mrow><annotation encoding="application/x-tex" id="S3.F4.8.m1.1d">||</annotation><annotation encoding="application/x-llamapun" id="S3.F4.8.m1.1e">| |</annotation></semantics></math>) three codes: a 3DMM identity code <math alttext="\boldsymbol{\beta}" class="ltx_Math" display="inline" id="S3.F4.9.m2.1"><semantics id="S3.F4.9.m2.1b"><mi id="S3.F4.9.m2.1.1" xref="S3.F4.9.m2.1.1.cmml">𝜷</mi><annotation-xml encoding="MathML-Content" id="S3.F4.9.m2.1c"><ci id="S3.F4.9.m2.1.1.cmml" xref="S3.F4.9.m2.1.1">𝜷</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.F4.9.m2.1d">\boldsymbol{\beta}</annotation><annotation encoding="application/x-llamapun" id="S3.F4.9.m2.1e">bold_italic_β</annotation></semantics></math>, a 3DMM expression code <math alttext="\boldsymbol{\psi}" class="ltx_Math" display="inline" id="S3.F4.10.m3.1"><semantics id="S3.F4.10.m3.1b"><mi id="S3.F4.10.m3.1.1" xref="S3.F4.10.m3.1.1.cmml">𝝍</mi><annotation-xml encoding="MathML-Content" id="S3.F4.10.m3.1c"><ci id="S3.F4.10.m3.1.1.cmml" xref="S3.F4.10.m3.1.1">𝝍</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.F4.10.m3.1d">\boldsymbol{\psi}</annotation><annotation encoding="application/x-llamapun" id="S3.F4.10.m3.1e">bold_italic_ψ</annotation></semantics></math>, and a learned latent code <span class="ltx_text ltx_markedasmath ltx_font_bold" id="S3.F4.16.1">w</span> representing out-of-model characteristics like hair, clothing, etc. The outputs include the color <math alttext="\boldsymbol{\hat{c}}" class="ltx_Math" display="inline" id="S3.F4.12.m5.1"><semantics id="S3.F4.12.m5.1b"><mover accent="true" id="S3.F4.12.m5.1.1" xref="S3.F4.12.m5.1.1.cmml"><mi id="S3.F4.12.m5.1.1.2" xref="S3.F4.12.m5.1.1.2.cmml">𝒄</mi><mo class="ltx_mathvariant_bold" id="S3.F4.12.m5.1.1.1" mathvariant="bold" xref="S3.F4.12.m5.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S3.F4.12.m5.1c"><apply id="S3.F4.12.m5.1.1.cmml" xref="S3.F4.12.m5.1.1"><ci id="S3.F4.12.m5.1.1.1.cmml" xref="S3.F4.12.m5.1.1.1">bold-^</ci><ci id="S3.F4.12.m5.1.1.2.cmml" xref="S3.F4.12.m5.1.1.2">𝒄</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F4.12.m5.1d">\boldsymbol{\hat{c}}</annotation><annotation encoding="application/x-llamapun" id="S3.F4.12.m5.1e">overbold_^ start_ARG bold_italic_c end_ARG</annotation></semantics></math>, the density <math alttext="\sigma" class="ltx_Math" display="inline" id="S3.F4.13.m6.1"><semantics id="S3.F4.13.m6.1b"><mi id="S3.F4.13.m6.1.1" xref="S3.F4.13.m6.1.1.cmml">σ</mi><annotation-xml encoding="MathML-Content" id="S3.F4.13.m6.1c"><ci id="S3.F4.13.m6.1.1.cmml" xref="S3.F4.13.m6.1.1">𝜎</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.F4.13.m6.1d">\sigma</annotation><annotation encoding="application/x-llamapun" id="S3.F4.13.m6.1e">italic_σ</annotation></semantics></math>, and a normal vector <math alttext="\vec{\text{n}}" class="ltx_Math" display="inline" id="S3.F4.14.m7.1"><semantics id="S3.F4.14.m7.1b"><mover accent="true" id="S3.F4.14.m7.1.1" xref="S3.F4.14.m7.1.1.cmml"><mtext id="S3.F4.14.m7.1.1.2" xref="S3.F4.14.m7.1.1.2a.cmml">n</mtext><mo id="S3.F4.14.m7.1.1.1" stretchy="false" xref="S3.F4.14.m7.1.1.1.cmml">→</mo></mover><annotation-xml encoding="MathML-Content" id="S3.F4.14.m7.1c"><apply id="S3.F4.14.m7.1.1.cmml" xref="S3.F4.14.m7.1.1"><ci id="S3.F4.14.m7.1.1.1.cmml" xref="S3.F4.14.m7.1.1.1">→</ci><ci id="S3.F4.14.m7.1.1.2a.cmml" xref="S3.F4.14.m7.1.1.2"><mtext id="S3.F4.14.m7.1.1.2.cmml" xref="S3.F4.14.m7.1.1.2">n</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F4.14.m7.1d">\vec{\text{n}}</annotation><annotation encoding="application/x-llamapun" id="S3.F4.14.m7.1e">over→ start_ARG n end_ARG</annotation></semantics></math>. Please see Sec. 2 in the supp. PDF for details.</figcaption>
</figure>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.4">We train a prior model to capture the distribution of human heads with arbitrary facial expressions.
As Preface <cite class="ltx_cite ltx_citemacro_citep">(Buehler et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib9" title="">2023</a>)</cite>, our prior model is implemented as a conditional Neural Radiance Field (NeRF) <cite class="ltx_cite ltx_citemacro_citep">(Mildenhall et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib40" title="">2020</a>; Rebain et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib54" title="">2022</a>)</cite> with a Mip-NeRF 360 backbone <cite class="ltx_cite ltx_citemacro_citep">(Barron et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib3" title="">2022</a>)</cite>, Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#S3.F4" title="Figure 4 ‣ 3.2. Pretraining an Expressive Prior Model ‣ 3. Method ‣ Cafca: High-quality Novel View Synthesis of Expressive Faces from Casual Few-shot Captures"><span class="ltx_text ltx_ref_tag">4</span></a>.
Yet, we observe that the simple Preface auto-decoder <cite class="ltx_cite ltx_citemacro_citep">(Rebain et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib54" title="">2022</a>; Bojanowski et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib7" title="">2018</a>)</cite> cannot achieve high-quality fitting results on expressive faces (see the ablation in Sec. <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#S4.SS3" title="4.3. Ablation Study ‣ 4. Experiments ‣ Cafca: High-quality Novel View Synthesis of Expressive Faces from Casual Few-shot Captures"><span class="ltx_text ltx_ref_tag">4.3</span></a>).
We hypothesize that the distribution of expressive faces is much more difficult to model and disentangle than the distribution of neutral faces.
To address this limitation, we decompose the latent space of our prior model into three latent spaces: a predefined identity space <math alttext="\mathcal{B}" class="ltx_Math" display="inline" id="S3.SS2.p1.1.m1.1"><semantics id="S3.SS2.p1.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p1.1.m1.1.1" xref="S3.SS2.p1.1.m1.1.1.cmml">ℬ</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.m1.1b"><ci id="S3.SS2.p1.1.m1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1">ℬ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.1.m1.1c">\mathcal{B}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.1.m1.1d">caligraphic_B</annotation></semantics></math>, a predefined expression space <math alttext="\Psi" class="ltx_Math" display="inline" id="S3.SS2.p1.2.m2.1"><semantics id="S3.SS2.p1.2.m2.1a"><mi id="S3.SS2.p1.2.m2.1.1" mathvariant="normal" xref="S3.SS2.p1.2.m2.1.1.cmml">Ψ</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.2.m2.1b"><ci id="S3.SS2.p1.2.m2.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1">Ψ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.2.m2.1c">\Psi</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.2.m2.1d">roman_Ψ</annotation></semantics></math>, and a learned latent space <math alttext="\mathcal{W}" class="ltx_Math" display="inline" id="S3.SS2.p1.3.m3.1"><semantics id="S3.SS2.p1.3.m3.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p1.3.m3.1.1" xref="S3.SS2.p1.3.m3.1.1.cmml">𝒲</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.3.m3.1b"><ci id="S3.SS2.p1.3.m3.1.1.cmml" xref="S3.SS2.p1.3.m3.1.1">𝒲</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.3.m3.1c">\mathcal{W}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.3.m3.1d">caligraphic_W</annotation></semantics></math>.
The identity and expression spaces come from a linear 3D Morphable Model (3DMM) in the style of <cite class="ltx_cite ltx_citemacro_citep">(Wood et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib72" title="">2021</a>)</cite>.
The latent codes in these two spaces are known <span class="ltx_text ltx_font_italic" id="S3.SS2.p1.4.1">a priori</span> and represent the face shape for the arbitrary identity and expression in each synthetic training image.
These codes are also frozen and do not change during training.
The latent space <math alttext="\mathcal{W}" class="ltx_Math" display="inline" id="S3.SS2.p1.4.m4.1"><semantics id="S3.SS2.p1.4.m4.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p1.4.m4.1.1" xref="S3.SS2.p1.4.m4.1.1.cmml">𝒲</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.4.m4.1b"><ci id="S3.SS2.p1.4.m4.1.1.cmml" xref="S3.SS2.p1.4.m4.1.1">𝒲</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.4.m4.1c">\mathcal{W}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.4.m4.1d">caligraphic_W</annotation></semantics></math> represents characteristics that are not modeled by the 3DMM like hair, beard, clothing, glasses, appearance, lighting, etc., and is learned while training the auto-decoder as in Preface <cite class="ltx_cite ltx_citemacro_citep">(Buehler et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib9" title="">2023</a>)</cite>.
Considering this model, we adapt Eq. <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#S3.E1" title="In NeRF ‣ 3.1. Background: NeRF and Preface ‣ 3. Method ‣ Cafca: High-quality Novel View Synthesis of Expressive Faces from Casual Few-shot Captures"><span class="ltx_text ltx_ref_tag">1</span></a> to obtain:</p>
<table class="ltx_equationgroup ltx_eqn_align ltx_eqn_table" id="A1.EGx2">
<tbody id="S3.E3"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_left">(3)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle\textbf{F}_{\theta_{\text{p}}}(\textbf{r},\boldsymbol{\beta},%
\boldsymbol{\psi},\mathbf{w})=\int_{t_{n}}^{t_{f}}T(t)\sigma(\textbf{r}(t),%
\boldsymbol{\beta},\boldsymbol{\psi},\mathbf{w})\textbf{c}(\textbf{r}(t),%
\textbf{d},\boldsymbol{\beta},\boldsymbol{\psi},\mathbf{w})dt\text{,}" class="ltx_Math" display="inline" id="S3.E3.m1.16"><semantics id="S3.E3.m1.16a"><mrow id="S3.E3.m1.16.16" xref="S3.E3.m1.16.16.cmml"><mrow id="S3.E3.m1.16.16.4" xref="S3.E3.m1.16.16.4.cmml"><msub id="S3.E3.m1.16.16.4.2" xref="S3.E3.m1.16.16.4.2.cmml"><mtext class="ltx_mathvariant_bold" id="S3.E3.m1.16.16.4.2.2" xref="S3.E3.m1.16.16.4.2.2a.cmml">F</mtext><msub id="S3.E3.m1.16.16.4.2.3" xref="S3.E3.m1.16.16.4.2.3.cmml"><mi id="S3.E3.m1.16.16.4.2.3.2" xref="S3.E3.m1.16.16.4.2.3.2.cmml">θ</mi><mtext id="S3.E3.m1.16.16.4.2.3.3" xref="S3.E3.m1.16.16.4.2.3.3a.cmml">p</mtext></msub></msub><mo id="S3.E3.m1.16.16.4.1" xref="S3.E3.m1.16.16.4.1.cmml">⁢</mo><mrow id="S3.E3.m1.16.16.4.3.2" xref="S3.E3.m1.16.16.4.3.1.cmml"><mo id="S3.E3.m1.16.16.4.3.2.1" stretchy="false" xref="S3.E3.m1.16.16.4.3.1.cmml">(</mo><mtext class="ltx_mathvariant_bold" id="S3.E3.m1.1.1" xref="S3.E3.m1.1.1a.cmml">r</mtext><mo id="S3.E3.m1.16.16.4.3.2.2" xref="S3.E3.m1.16.16.4.3.1.cmml">,</mo><mi id="S3.E3.m1.2.2" xref="S3.E3.m1.2.2.cmml">𝜷</mi><mo id="S3.E3.m1.16.16.4.3.2.3" xref="S3.E3.m1.16.16.4.3.1.cmml">,</mo><mi id="S3.E3.m1.3.3" xref="S3.E3.m1.3.3.cmml">𝝍</mi><mo id="S3.E3.m1.16.16.4.3.2.4" xref="S3.E3.m1.16.16.4.3.1.cmml">,</mo><mi id="S3.E3.m1.4.4" xref="S3.E3.m1.4.4.cmml">𝐰</mi><mo id="S3.E3.m1.16.16.4.3.2.5" stretchy="false" xref="S3.E3.m1.16.16.4.3.1.cmml">)</mo></mrow></mrow><mo id="S3.E3.m1.16.16.3" xref="S3.E3.m1.16.16.3.cmml">=</mo><mrow id="S3.E3.m1.16.16.2" xref="S3.E3.m1.16.16.2.cmml"><mstyle displaystyle="true" id="S3.E3.m1.16.16.2.3" xref="S3.E3.m1.16.16.2.3.cmml"><msubsup id="S3.E3.m1.16.16.2.3a" xref="S3.E3.m1.16.16.2.3.cmml"><mo id="S3.E3.m1.16.16.2.3.2.2" xref="S3.E3.m1.16.16.2.3.2.2.cmml">∫</mo><msub id="S3.E3.m1.16.16.2.3.2.3" xref="S3.E3.m1.16.16.2.3.2.3.cmml"><mi id="S3.E3.m1.16.16.2.3.2.3.2" xref="S3.E3.m1.16.16.2.3.2.3.2.cmml">t</mi><mi id="S3.E3.m1.16.16.2.3.2.3.3" xref="S3.E3.m1.16.16.2.3.2.3.3.cmml">n</mi></msub><msub id="S3.E3.m1.16.16.2.3.3" xref="S3.E3.m1.16.16.2.3.3.cmml"><mi id="S3.E3.m1.16.16.2.3.3.2" xref="S3.E3.m1.16.16.2.3.3.2.cmml">t</mi><mi id="S3.E3.m1.16.16.2.3.3.3" xref="S3.E3.m1.16.16.2.3.3.3.cmml">f</mi></msub></msubsup></mstyle><mrow id="S3.E3.m1.16.16.2.2" xref="S3.E3.m1.16.16.2.2.cmml"><mi id="S3.E3.m1.16.16.2.2.4" xref="S3.E3.m1.16.16.2.2.4.cmml">T</mi><mo id="S3.E3.m1.16.16.2.2.3" xref="S3.E3.m1.16.16.2.2.3.cmml">⁢</mo><mrow id="S3.E3.m1.16.16.2.2.5.2" xref="S3.E3.m1.16.16.2.2.cmml"><mo id="S3.E3.m1.16.16.2.2.5.2.1" stretchy="false" xref="S3.E3.m1.16.16.2.2.cmml">(</mo><mi id="S3.E3.m1.5.5" xref="S3.E3.m1.5.5.cmml">t</mi><mo id="S3.E3.m1.16.16.2.2.5.2.2" stretchy="false" xref="S3.E3.m1.16.16.2.2.cmml">)</mo></mrow><mo id="S3.E3.m1.16.16.2.2.3a" xref="S3.E3.m1.16.16.2.2.3.cmml">⁢</mo><mi id="S3.E3.m1.16.16.2.2.6" xref="S3.E3.m1.16.16.2.2.6.cmml">σ</mi><mo id="S3.E3.m1.16.16.2.2.3b" xref="S3.E3.m1.16.16.2.2.3.cmml">⁢</mo><mrow id="S3.E3.m1.15.15.1.1.1.1" xref="S3.E3.m1.15.15.1.1.1.2.cmml"><mo id="S3.E3.m1.15.15.1.1.1.1.2" stretchy="false" xref="S3.E3.m1.15.15.1.1.1.2.cmml">(</mo><mrow id="S3.E3.m1.15.15.1.1.1.1.1" xref="S3.E3.m1.15.15.1.1.1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S3.E3.m1.15.15.1.1.1.1.1.2" xref="S3.E3.m1.15.15.1.1.1.1.1.2a.cmml">r</mtext><mo id="S3.E3.m1.15.15.1.1.1.1.1.1" xref="S3.E3.m1.15.15.1.1.1.1.1.1.cmml">⁢</mo><mrow id="S3.E3.m1.15.15.1.1.1.1.1.3.2" xref="S3.E3.m1.15.15.1.1.1.1.1.cmml"><mo id="S3.E3.m1.15.15.1.1.1.1.1.3.2.1" stretchy="false" xref="S3.E3.m1.15.15.1.1.1.1.1.cmml">(</mo><mi id="S3.E3.m1.6.6" xref="S3.E3.m1.6.6.cmml">t</mi><mo id="S3.E3.m1.15.15.1.1.1.1.1.3.2.2" stretchy="false" xref="S3.E3.m1.15.15.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E3.m1.15.15.1.1.1.1.3" xref="S3.E3.m1.15.15.1.1.1.2.cmml">,</mo><mi id="S3.E3.m1.7.7" xref="S3.E3.m1.7.7.cmml">𝜷</mi><mo id="S3.E3.m1.15.15.1.1.1.1.4" xref="S3.E3.m1.15.15.1.1.1.2.cmml">,</mo><mi id="S3.E3.m1.8.8" xref="S3.E3.m1.8.8.cmml">𝝍</mi><mo id="S3.E3.m1.15.15.1.1.1.1.5" xref="S3.E3.m1.15.15.1.1.1.2.cmml">,</mo><mi id="S3.E3.m1.9.9" xref="S3.E3.m1.9.9.cmml">𝐰</mi><mo id="S3.E3.m1.15.15.1.1.1.1.6" stretchy="false" xref="S3.E3.m1.15.15.1.1.1.2.cmml">)</mo></mrow><mo id="S3.E3.m1.16.16.2.2.3c" xref="S3.E3.m1.16.16.2.2.3.cmml">⁢</mo><mtext class="ltx_mathvariant_bold" id="S3.E3.m1.16.16.2.2.7" xref="S3.E3.m1.16.16.2.2.7a.cmml">c</mtext><mo id="S3.E3.m1.16.16.2.2.3d" xref="S3.E3.m1.16.16.2.2.3.cmml">⁢</mo><mrow id="S3.E3.m1.16.16.2.2.2.1" xref="S3.E3.m1.16.16.2.2.2.2.cmml"><mo id="S3.E3.m1.16.16.2.2.2.1.2" stretchy="false" xref="S3.E3.m1.16.16.2.2.2.2.cmml">(</mo><mrow id="S3.E3.m1.16.16.2.2.2.1.1" xref="S3.E3.m1.16.16.2.2.2.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S3.E3.m1.16.16.2.2.2.1.1.2" xref="S3.E3.m1.16.16.2.2.2.1.1.2a.cmml">r</mtext><mo id="S3.E3.m1.16.16.2.2.2.1.1.1" xref="S3.E3.m1.16.16.2.2.2.1.1.1.cmml">⁢</mo><mrow id="S3.E3.m1.16.16.2.2.2.1.1.3.2" xref="S3.E3.m1.16.16.2.2.2.1.1.cmml"><mo id="S3.E3.m1.16.16.2.2.2.1.1.3.2.1" stretchy="false" xref="S3.E3.m1.16.16.2.2.2.1.1.cmml">(</mo><mi id="S3.E3.m1.10.10" xref="S3.E3.m1.10.10.cmml">t</mi><mo id="S3.E3.m1.16.16.2.2.2.1.1.3.2.2" stretchy="false" xref="S3.E3.m1.16.16.2.2.2.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E3.m1.16.16.2.2.2.1.3" xref="S3.E3.m1.16.16.2.2.2.2.cmml">,</mo><mtext class="ltx_mathvariant_bold" id="S3.E3.m1.11.11" xref="S3.E3.m1.11.11a.cmml">d</mtext><mo id="S3.E3.m1.16.16.2.2.2.1.4" xref="S3.E3.m1.16.16.2.2.2.2.cmml">,</mo><mi id="S3.E3.m1.12.12" xref="S3.E3.m1.12.12.cmml">𝜷</mi><mo id="S3.E3.m1.16.16.2.2.2.1.5" xref="S3.E3.m1.16.16.2.2.2.2.cmml">,</mo><mi id="S3.E3.m1.13.13" xref="S3.E3.m1.13.13.cmml">𝝍</mi><mo id="S3.E3.m1.16.16.2.2.2.1.6" xref="S3.E3.m1.16.16.2.2.2.2.cmml">,</mo><mi id="S3.E3.m1.14.14" xref="S3.E3.m1.14.14.cmml">𝐰</mi><mo id="S3.E3.m1.16.16.2.2.2.1.7" stretchy="false" xref="S3.E3.m1.16.16.2.2.2.2.cmml">)</mo></mrow><mo id="S3.E3.m1.16.16.2.2.3e" lspace="0em" xref="S3.E3.m1.16.16.2.2.3.cmml">⁢</mo><mrow id="S3.E3.m1.16.16.2.2.8" xref="S3.E3.m1.16.16.2.2.8.cmml"><mo id="S3.E3.m1.16.16.2.2.8.1" rspace="0em" xref="S3.E3.m1.16.16.2.2.8.1.cmml">𝑑</mo><mi id="S3.E3.m1.16.16.2.2.8.2" xref="S3.E3.m1.16.16.2.2.8.2.cmml">t</mi></mrow><mo id="S3.E3.m1.16.16.2.2.3f" xref="S3.E3.m1.16.16.2.2.3.cmml">⁢</mo><mtext id="S3.E3.m1.16.16.2.2.9" xref="S3.E3.m1.16.16.2.2.9a.cmml">,</mtext></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E3.m1.16b"><apply id="S3.E3.m1.16.16.cmml" xref="S3.E3.m1.16.16"><eq id="S3.E3.m1.16.16.3.cmml" xref="S3.E3.m1.16.16.3"></eq><apply id="S3.E3.m1.16.16.4.cmml" xref="S3.E3.m1.16.16.4"><times id="S3.E3.m1.16.16.4.1.cmml" xref="S3.E3.m1.16.16.4.1"></times><apply id="S3.E3.m1.16.16.4.2.cmml" xref="S3.E3.m1.16.16.4.2"><csymbol cd="ambiguous" id="S3.E3.m1.16.16.4.2.1.cmml" xref="S3.E3.m1.16.16.4.2">subscript</csymbol><ci id="S3.E3.m1.16.16.4.2.2a.cmml" xref="S3.E3.m1.16.16.4.2.2"><mtext class="ltx_mathvariant_bold" id="S3.E3.m1.16.16.4.2.2.cmml" xref="S3.E3.m1.16.16.4.2.2">F</mtext></ci><apply id="S3.E3.m1.16.16.4.2.3.cmml" xref="S3.E3.m1.16.16.4.2.3"><csymbol cd="ambiguous" id="S3.E3.m1.16.16.4.2.3.1.cmml" xref="S3.E3.m1.16.16.4.2.3">subscript</csymbol><ci id="S3.E3.m1.16.16.4.2.3.2.cmml" xref="S3.E3.m1.16.16.4.2.3.2">𝜃</ci><ci id="S3.E3.m1.16.16.4.2.3.3a.cmml" xref="S3.E3.m1.16.16.4.2.3.3"><mtext id="S3.E3.m1.16.16.4.2.3.3.cmml" mathsize="50%" xref="S3.E3.m1.16.16.4.2.3.3">p</mtext></ci></apply></apply><vector id="S3.E3.m1.16.16.4.3.1.cmml" xref="S3.E3.m1.16.16.4.3.2"><ci id="S3.E3.m1.1.1a.cmml" xref="S3.E3.m1.1.1"><mtext class="ltx_mathvariant_bold" id="S3.E3.m1.1.1.cmml" xref="S3.E3.m1.1.1">r</mtext></ci><ci id="S3.E3.m1.2.2.cmml" xref="S3.E3.m1.2.2">𝜷</ci><ci id="S3.E3.m1.3.3.cmml" xref="S3.E3.m1.3.3">𝝍</ci><ci id="S3.E3.m1.4.4.cmml" xref="S3.E3.m1.4.4">𝐰</ci></vector></apply><apply id="S3.E3.m1.16.16.2.cmml" xref="S3.E3.m1.16.16.2"><apply id="S3.E3.m1.16.16.2.3.cmml" xref="S3.E3.m1.16.16.2.3"><csymbol cd="ambiguous" id="S3.E3.m1.16.16.2.3.1.cmml" xref="S3.E3.m1.16.16.2.3">superscript</csymbol><apply id="S3.E3.m1.16.16.2.3.2.cmml" xref="S3.E3.m1.16.16.2.3"><csymbol cd="ambiguous" id="S3.E3.m1.16.16.2.3.2.1.cmml" xref="S3.E3.m1.16.16.2.3">subscript</csymbol><int id="S3.E3.m1.16.16.2.3.2.2.cmml" xref="S3.E3.m1.16.16.2.3.2.2"></int><apply id="S3.E3.m1.16.16.2.3.2.3.cmml" xref="S3.E3.m1.16.16.2.3.2.3"><csymbol cd="ambiguous" id="S3.E3.m1.16.16.2.3.2.3.1.cmml" xref="S3.E3.m1.16.16.2.3.2.3">subscript</csymbol><ci id="S3.E3.m1.16.16.2.3.2.3.2.cmml" xref="S3.E3.m1.16.16.2.3.2.3.2">𝑡</ci><ci id="S3.E3.m1.16.16.2.3.2.3.3.cmml" xref="S3.E3.m1.16.16.2.3.2.3.3">𝑛</ci></apply></apply><apply id="S3.E3.m1.16.16.2.3.3.cmml" xref="S3.E3.m1.16.16.2.3.3"><csymbol cd="ambiguous" id="S3.E3.m1.16.16.2.3.3.1.cmml" xref="S3.E3.m1.16.16.2.3.3">subscript</csymbol><ci id="S3.E3.m1.16.16.2.3.3.2.cmml" xref="S3.E3.m1.16.16.2.3.3.2">𝑡</ci><ci id="S3.E3.m1.16.16.2.3.3.3.cmml" xref="S3.E3.m1.16.16.2.3.3.3">𝑓</ci></apply></apply><apply id="S3.E3.m1.16.16.2.2.cmml" xref="S3.E3.m1.16.16.2.2"><times id="S3.E3.m1.16.16.2.2.3.cmml" xref="S3.E3.m1.16.16.2.2.3"></times><ci id="S3.E3.m1.16.16.2.2.4.cmml" xref="S3.E3.m1.16.16.2.2.4">𝑇</ci><ci id="S3.E3.m1.5.5.cmml" xref="S3.E3.m1.5.5">𝑡</ci><ci id="S3.E3.m1.16.16.2.2.6.cmml" xref="S3.E3.m1.16.16.2.2.6">𝜎</ci><vector id="S3.E3.m1.15.15.1.1.1.2.cmml" xref="S3.E3.m1.15.15.1.1.1.1"><apply id="S3.E3.m1.15.15.1.1.1.1.1.cmml" xref="S3.E3.m1.15.15.1.1.1.1.1"><times id="S3.E3.m1.15.15.1.1.1.1.1.1.cmml" xref="S3.E3.m1.15.15.1.1.1.1.1.1"></times><ci id="S3.E3.m1.15.15.1.1.1.1.1.2a.cmml" xref="S3.E3.m1.15.15.1.1.1.1.1.2"><mtext class="ltx_mathvariant_bold" id="S3.E3.m1.15.15.1.1.1.1.1.2.cmml" xref="S3.E3.m1.15.15.1.1.1.1.1.2">r</mtext></ci><ci id="S3.E3.m1.6.6.cmml" xref="S3.E3.m1.6.6">𝑡</ci></apply><ci id="S3.E3.m1.7.7.cmml" xref="S3.E3.m1.7.7">𝜷</ci><ci id="S3.E3.m1.8.8.cmml" xref="S3.E3.m1.8.8">𝝍</ci><ci id="S3.E3.m1.9.9.cmml" xref="S3.E3.m1.9.9">𝐰</ci></vector><ci id="S3.E3.m1.16.16.2.2.7a.cmml" xref="S3.E3.m1.16.16.2.2.7"><mtext class="ltx_mathvariant_bold" id="S3.E3.m1.16.16.2.2.7.cmml" xref="S3.E3.m1.16.16.2.2.7">c</mtext></ci><vector id="S3.E3.m1.16.16.2.2.2.2.cmml" xref="S3.E3.m1.16.16.2.2.2.1"><apply id="S3.E3.m1.16.16.2.2.2.1.1.cmml" xref="S3.E3.m1.16.16.2.2.2.1.1"><times id="S3.E3.m1.16.16.2.2.2.1.1.1.cmml" xref="S3.E3.m1.16.16.2.2.2.1.1.1"></times><ci id="S3.E3.m1.16.16.2.2.2.1.1.2a.cmml" xref="S3.E3.m1.16.16.2.2.2.1.1.2"><mtext class="ltx_mathvariant_bold" id="S3.E3.m1.16.16.2.2.2.1.1.2.cmml" xref="S3.E3.m1.16.16.2.2.2.1.1.2">r</mtext></ci><ci id="S3.E3.m1.10.10.cmml" xref="S3.E3.m1.10.10">𝑡</ci></apply><ci id="S3.E3.m1.11.11a.cmml" xref="S3.E3.m1.11.11"><mtext class="ltx_mathvariant_bold" id="S3.E3.m1.11.11.cmml" xref="S3.E3.m1.11.11">d</mtext></ci><ci id="S3.E3.m1.12.12.cmml" xref="S3.E3.m1.12.12">𝜷</ci><ci id="S3.E3.m1.13.13.cmml" xref="S3.E3.m1.13.13">𝝍</ci><ci id="S3.E3.m1.14.14.cmml" xref="S3.E3.m1.14.14">𝐰</ci></vector><apply id="S3.E3.m1.16.16.2.2.8.cmml" xref="S3.E3.m1.16.16.2.2.8"><csymbol cd="latexml" id="S3.E3.m1.16.16.2.2.8.1.cmml" xref="S3.E3.m1.16.16.2.2.8.1">differential-d</csymbol><ci id="S3.E3.m1.16.16.2.2.8.2.cmml" xref="S3.E3.m1.16.16.2.2.8.2">𝑡</ci></apply><ci id="S3.E3.m1.16.16.2.2.9a.cmml" xref="S3.E3.m1.16.16.2.2.9"><mtext id="S3.E3.m1.16.16.2.2.9.cmml" xref="S3.E3.m1.16.16.2.2.9">,</mtext></ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E3.m1.16c">\displaystyle\textbf{F}_{\theta_{\text{p}}}(\textbf{r},\boldsymbol{\beta},%
\boldsymbol{\psi},\mathbf{w})=\int_{t_{n}}^{t_{f}}T(t)\sigma(\textbf{r}(t),%
\boldsymbol{\beta},\boldsymbol{\psi},\mathbf{w})\textbf{c}(\textbf{r}(t),%
\textbf{d},\boldsymbol{\beta},\boldsymbol{\psi},\mathbf{w})dt\text{,}</annotation><annotation encoding="application/x-llamapun" id="S3.E3.m1.16d">F start_POSTSUBSCRIPT italic_θ start_POSTSUBSCRIPT p end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( r , bold_italic_β , bold_italic_ψ , bold_w ) = ∫ start_POSTSUBSCRIPT italic_t start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_t start_POSTSUBSCRIPT italic_f end_POSTSUBSCRIPT end_POSTSUPERSCRIPT italic_T ( italic_t ) italic_σ ( r ( italic_t ) , bold_italic_β , bold_italic_ψ , bold_w ) c ( r ( italic_t ) , d , bold_italic_β , bold_italic_ψ , bold_w ) italic_d italic_t ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
<tbody id="S3.E4"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_left">(4)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle\text{ where }T(t)=\text{exp}\left(-\int_{t_{n}}^{t}\sigma(%
\textbf{r}(s),\boldsymbol{\beta},\boldsymbol{\psi},\mathbf{w})ds\right)," class="ltx_Math" display="inline" id="S3.E4.m1.6"><semantics id="S3.E4.m1.6a"><mrow id="S3.E4.m1.6.6.1" xref="S3.E4.m1.6.6.1.1.cmml"><mrow id="S3.E4.m1.6.6.1.1" xref="S3.E4.m1.6.6.1.1.cmml"><mrow id="S3.E4.m1.6.6.1.1.3" xref="S3.E4.m1.6.6.1.1.3.cmml"><mtext id="S3.E4.m1.6.6.1.1.3.2" xref="S3.E4.m1.6.6.1.1.3.2a.cmml">where </mtext><mo id="S3.E4.m1.6.6.1.1.3.1" xref="S3.E4.m1.6.6.1.1.3.1.cmml">⁢</mo><mi id="S3.E4.m1.6.6.1.1.3.3" xref="S3.E4.m1.6.6.1.1.3.3.cmml">T</mi><mo id="S3.E4.m1.6.6.1.1.3.1a" xref="S3.E4.m1.6.6.1.1.3.1.cmml">⁢</mo><mrow id="S3.E4.m1.6.6.1.1.3.4.2" xref="S3.E4.m1.6.6.1.1.3.cmml"><mo id="S3.E4.m1.6.6.1.1.3.4.2.1" stretchy="false" xref="S3.E4.m1.6.6.1.1.3.cmml">(</mo><mi id="S3.E4.m1.1.1" xref="S3.E4.m1.1.1.cmml">t</mi><mo id="S3.E4.m1.6.6.1.1.3.4.2.2" stretchy="false" xref="S3.E4.m1.6.6.1.1.3.cmml">)</mo></mrow></mrow><mo id="S3.E4.m1.6.6.1.1.2" xref="S3.E4.m1.6.6.1.1.2.cmml">=</mo><mrow id="S3.E4.m1.6.6.1.1.1" xref="S3.E4.m1.6.6.1.1.1.cmml"><mtext id="S3.E4.m1.6.6.1.1.1.3" xref="S3.E4.m1.6.6.1.1.1.3a.cmml">exp</mtext><mo id="S3.E4.m1.6.6.1.1.1.2" xref="S3.E4.m1.6.6.1.1.1.2.cmml">⁢</mo><mrow id="S3.E4.m1.6.6.1.1.1.1.1" xref="S3.E4.m1.6.6.1.1.1.1.1.1.cmml"><mo id="S3.E4.m1.6.6.1.1.1.1.1.2" xref="S3.E4.m1.6.6.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E4.m1.6.6.1.1.1.1.1.1" xref="S3.E4.m1.6.6.1.1.1.1.1.1.cmml"><mo id="S3.E4.m1.6.6.1.1.1.1.1.1a" xref="S3.E4.m1.6.6.1.1.1.1.1.1.cmml">−</mo><mrow id="S3.E4.m1.6.6.1.1.1.1.1.1.1" xref="S3.E4.m1.6.6.1.1.1.1.1.1.1.cmml"><mstyle displaystyle="true" id="S3.E4.m1.6.6.1.1.1.1.1.1.1.2" xref="S3.E4.m1.6.6.1.1.1.1.1.1.1.2.cmml"><msubsup id="S3.E4.m1.6.6.1.1.1.1.1.1.1.2a" xref="S3.E4.m1.6.6.1.1.1.1.1.1.1.2.cmml"><mo id="S3.E4.m1.6.6.1.1.1.1.1.1.1.2.2.2" xref="S3.E4.m1.6.6.1.1.1.1.1.1.1.2.2.2.cmml">∫</mo><msub id="S3.E4.m1.6.6.1.1.1.1.1.1.1.2.2.3" xref="S3.E4.m1.6.6.1.1.1.1.1.1.1.2.2.3.cmml"><mi id="S3.E4.m1.6.6.1.1.1.1.1.1.1.2.2.3.2" xref="S3.E4.m1.6.6.1.1.1.1.1.1.1.2.2.3.2.cmml">t</mi><mi id="S3.E4.m1.6.6.1.1.1.1.1.1.1.2.2.3.3" xref="S3.E4.m1.6.6.1.1.1.1.1.1.1.2.2.3.3.cmml">n</mi></msub><mi id="S3.E4.m1.6.6.1.1.1.1.1.1.1.2.3" xref="S3.E4.m1.6.6.1.1.1.1.1.1.1.2.3.cmml">t</mi></msubsup></mstyle><mrow id="S3.E4.m1.6.6.1.1.1.1.1.1.1.1" xref="S3.E4.m1.6.6.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E4.m1.6.6.1.1.1.1.1.1.1.1.3" xref="S3.E4.m1.6.6.1.1.1.1.1.1.1.1.3.cmml">σ</mi><mo id="S3.E4.m1.6.6.1.1.1.1.1.1.1.1.2" xref="S3.E4.m1.6.6.1.1.1.1.1.1.1.1.2.cmml">⁢</mo><mrow id="S3.E4.m1.6.6.1.1.1.1.1.1.1.1.1.1" xref="S3.E4.m1.6.6.1.1.1.1.1.1.1.1.1.2.cmml"><mo id="S3.E4.m1.6.6.1.1.1.1.1.1.1.1.1.1.2" stretchy="false" xref="S3.E4.m1.6.6.1.1.1.1.1.1.1.1.1.2.cmml">(</mo><mrow id="S3.E4.m1.6.6.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E4.m1.6.6.1.1.1.1.1.1.1.1.1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S3.E4.m1.6.6.1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E4.m1.6.6.1.1.1.1.1.1.1.1.1.1.1.2a.cmml">r</mtext><mo id="S3.E4.m1.6.6.1.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E4.m1.6.6.1.1.1.1.1.1.1.1.1.1.1.1.cmml">⁢</mo><mrow id="S3.E4.m1.6.6.1.1.1.1.1.1.1.1.1.1.1.3.2" xref="S3.E4.m1.6.6.1.1.1.1.1.1.1.1.1.1.1.cmml"><mo id="S3.E4.m1.6.6.1.1.1.1.1.1.1.1.1.1.1.3.2.1" stretchy="false" xref="S3.E4.m1.6.6.1.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><mi id="S3.E4.m1.2.2" xref="S3.E4.m1.2.2.cmml">s</mi><mo id="S3.E4.m1.6.6.1.1.1.1.1.1.1.1.1.1.1.3.2.2" stretchy="false" xref="S3.E4.m1.6.6.1.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E4.m1.6.6.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E4.m1.6.6.1.1.1.1.1.1.1.1.1.2.cmml">,</mo><mi id="S3.E4.m1.3.3" xref="S3.E4.m1.3.3.cmml">𝜷</mi><mo id="S3.E4.m1.6.6.1.1.1.1.1.1.1.1.1.1.4" xref="S3.E4.m1.6.6.1.1.1.1.1.1.1.1.1.2.cmml">,</mo><mi id="S3.E4.m1.4.4" xref="S3.E4.m1.4.4.cmml">𝝍</mi><mo id="S3.E4.m1.6.6.1.1.1.1.1.1.1.1.1.1.5" xref="S3.E4.m1.6.6.1.1.1.1.1.1.1.1.1.2.cmml">,</mo><mi id="S3.E4.m1.5.5" xref="S3.E4.m1.5.5.cmml">𝐰</mi><mo id="S3.E4.m1.6.6.1.1.1.1.1.1.1.1.1.1.6" stretchy="false" xref="S3.E4.m1.6.6.1.1.1.1.1.1.1.1.1.2.cmml">)</mo></mrow><mo id="S3.E4.m1.6.6.1.1.1.1.1.1.1.1.2a" lspace="0em" xref="S3.E4.m1.6.6.1.1.1.1.1.1.1.1.2.cmml">⁢</mo><mrow id="S3.E4.m1.6.6.1.1.1.1.1.1.1.1.4" xref="S3.E4.m1.6.6.1.1.1.1.1.1.1.1.4.cmml"><mo id="S3.E4.m1.6.6.1.1.1.1.1.1.1.1.4.1" rspace="0em" xref="S3.E4.m1.6.6.1.1.1.1.1.1.1.1.4.1.cmml">𝑑</mo><mi id="S3.E4.m1.6.6.1.1.1.1.1.1.1.1.4.2" xref="S3.E4.m1.6.6.1.1.1.1.1.1.1.1.4.2.cmml">s</mi></mrow></mrow></mrow></mrow><mo id="S3.E4.m1.6.6.1.1.1.1.1.3" xref="S3.E4.m1.6.6.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo id="S3.E4.m1.6.6.1.2" xref="S3.E4.m1.6.6.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E4.m1.6b"><apply id="S3.E4.m1.6.6.1.1.cmml" xref="S3.E4.m1.6.6.1"><eq id="S3.E4.m1.6.6.1.1.2.cmml" xref="S3.E4.m1.6.6.1.1.2"></eq><apply id="S3.E4.m1.6.6.1.1.3.cmml" xref="S3.E4.m1.6.6.1.1.3"><times id="S3.E4.m1.6.6.1.1.3.1.cmml" xref="S3.E4.m1.6.6.1.1.3.1"></times><ci id="S3.E4.m1.6.6.1.1.3.2a.cmml" xref="S3.E4.m1.6.6.1.1.3.2"><mtext id="S3.E4.m1.6.6.1.1.3.2.cmml" xref="S3.E4.m1.6.6.1.1.3.2">where </mtext></ci><ci id="S3.E4.m1.6.6.1.1.3.3.cmml" xref="S3.E4.m1.6.6.1.1.3.3">𝑇</ci><ci id="S3.E4.m1.1.1.cmml" xref="S3.E4.m1.1.1">𝑡</ci></apply><apply id="S3.E4.m1.6.6.1.1.1.cmml" xref="S3.E4.m1.6.6.1.1.1"><times id="S3.E4.m1.6.6.1.1.1.2.cmml" xref="S3.E4.m1.6.6.1.1.1.2"></times><ci id="S3.E4.m1.6.6.1.1.1.3a.cmml" xref="S3.E4.m1.6.6.1.1.1.3"><mtext id="S3.E4.m1.6.6.1.1.1.3.cmml" xref="S3.E4.m1.6.6.1.1.1.3">exp</mtext></ci><apply id="S3.E4.m1.6.6.1.1.1.1.1.1.cmml" xref="S3.E4.m1.6.6.1.1.1.1.1"><minus id="S3.E4.m1.6.6.1.1.1.1.1.1.2.cmml" xref="S3.E4.m1.6.6.1.1.1.1.1"></minus><apply id="S3.E4.m1.6.6.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.6.6.1.1.1.1.1.1.1"><apply id="S3.E4.m1.6.6.1.1.1.1.1.1.1.2.cmml" xref="S3.E4.m1.6.6.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E4.m1.6.6.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E4.m1.6.6.1.1.1.1.1.1.1.2">superscript</csymbol><apply id="S3.E4.m1.6.6.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E4.m1.6.6.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E4.m1.6.6.1.1.1.1.1.1.1.2.2.1.cmml" xref="S3.E4.m1.6.6.1.1.1.1.1.1.1.2">subscript</csymbol><int id="S3.E4.m1.6.6.1.1.1.1.1.1.1.2.2.2.cmml" xref="S3.E4.m1.6.6.1.1.1.1.1.1.1.2.2.2"></int><apply id="S3.E4.m1.6.6.1.1.1.1.1.1.1.2.2.3.cmml" xref="S3.E4.m1.6.6.1.1.1.1.1.1.1.2.2.3"><csymbol cd="ambiguous" id="S3.E4.m1.6.6.1.1.1.1.1.1.1.2.2.3.1.cmml" xref="S3.E4.m1.6.6.1.1.1.1.1.1.1.2.2.3">subscript</csymbol><ci id="S3.E4.m1.6.6.1.1.1.1.1.1.1.2.2.3.2.cmml" xref="S3.E4.m1.6.6.1.1.1.1.1.1.1.2.2.3.2">𝑡</ci><ci id="S3.E4.m1.6.6.1.1.1.1.1.1.1.2.2.3.3.cmml" xref="S3.E4.m1.6.6.1.1.1.1.1.1.1.2.2.3.3">𝑛</ci></apply></apply><ci id="S3.E4.m1.6.6.1.1.1.1.1.1.1.2.3.cmml" xref="S3.E4.m1.6.6.1.1.1.1.1.1.1.2.3">𝑡</ci></apply><apply id="S3.E4.m1.6.6.1.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.6.6.1.1.1.1.1.1.1.1"><times id="S3.E4.m1.6.6.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E4.m1.6.6.1.1.1.1.1.1.1.1.2"></times><ci id="S3.E4.m1.6.6.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E4.m1.6.6.1.1.1.1.1.1.1.1.3">𝜎</ci><vector id="S3.E4.m1.6.6.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E4.m1.6.6.1.1.1.1.1.1.1.1.1.1"><apply id="S3.E4.m1.6.6.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.6.6.1.1.1.1.1.1.1.1.1.1.1"><times id="S3.E4.m1.6.6.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.6.6.1.1.1.1.1.1.1.1.1.1.1.1"></times><ci id="S3.E4.m1.6.6.1.1.1.1.1.1.1.1.1.1.1.2a.cmml" xref="S3.E4.m1.6.6.1.1.1.1.1.1.1.1.1.1.1.2"><mtext class="ltx_mathvariant_bold" id="S3.E4.m1.6.6.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E4.m1.6.6.1.1.1.1.1.1.1.1.1.1.1.2">r</mtext></ci><ci id="S3.E4.m1.2.2.cmml" xref="S3.E4.m1.2.2">𝑠</ci></apply><ci id="S3.E4.m1.3.3.cmml" xref="S3.E4.m1.3.3">𝜷</ci><ci id="S3.E4.m1.4.4.cmml" xref="S3.E4.m1.4.4">𝝍</ci><ci id="S3.E4.m1.5.5.cmml" xref="S3.E4.m1.5.5">𝐰</ci></vector><apply id="S3.E4.m1.6.6.1.1.1.1.1.1.1.1.4.cmml" xref="S3.E4.m1.6.6.1.1.1.1.1.1.1.1.4"><csymbol cd="latexml" id="S3.E4.m1.6.6.1.1.1.1.1.1.1.1.4.1.cmml" xref="S3.E4.m1.6.6.1.1.1.1.1.1.1.1.4.1">differential-d</csymbol><ci id="S3.E4.m1.6.6.1.1.1.1.1.1.1.1.4.2.cmml" xref="S3.E4.m1.6.6.1.1.1.1.1.1.1.1.4.2">𝑠</ci></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E4.m1.6c">\displaystyle\text{ where }T(t)=\text{exp}\left(-\int_{t_{n}}^{t}\sigma(%
\textbf{r}(s),\boldsymbol{\beta},\boldsymbol{\psi},\mathbf{w})ds\right),</annotation><annotation encoding="application/x-llamapun" id="S3.E4.m1.6d">where italic_T ( italic_t ) = exp ( - ∫ start_POSTSUBSCRIPT italic_t start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT italic_σ ( r ( italic_s ) , bold_italic_β , bold_italic_ψ , bold_w ) italic_d italic_s ) ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS2.p1.7">where <math alttext="\boldsymbol{\beta}\in\mathcal{B}\subset\mathbb{R}^{48}" class="ltx_Math" display="inline" id="S3.SS2.p1.5.m1.1"><semantics id="S3.SS2.p1.5.m1.1a"><mrow id="S3.SS2.p1.5.m1.1.1" xref="S3.SS2.p1.5.m1.1.1.cmml"><mi id="S3.SS2.p1.5.m1.1.1.2" xref="S3.SS2.p1.5.m1.1.1.2.cmml">𝜷</mi><mo id="S3.SS2.p1.5.m1.1.1.3" xref="S3.SS2.p1.5.m1.1.1.3.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p1.5.m1.1.1.4" xref="S3.SS2.p1.5.m1.1.1.4.cmml">ℬ</mi><mo id="S3.SS2.p1.5.m1.1.1.5" xref="S3.SS2.p1.5.m1.1.1.5.cmml">⊂</mo><msup id="S3.SS2.p1.5.m1.1.1.6" xref="S3.SS2.p1.5.m1.1.1.6.cmml"><mi id="S3.SS2.p1.5.m1.1.1.6.2" xref="S3.SS2.p1.5.m1.1.1.6.2.cmml">ℝ</mi><mn id="S3.SS2.p1.5.m1.1.1.6.3" xref="S3.SS2.p1.5.m1.1.1.6.3.cmml">48</mn></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.5.m1.1b"><apply id="S3.SS2.p1.5.m1.1.1.cmml" xref="S3.SS2.p1.5.m1.1.1"><and id="S3.SS2.p1.5.m1.1.1a.cmml" xref="S3.SS2.p1.5.m1.1.1"></and><apply id="S3.SS2.p1.5.m1.1.1b.cmml" xref="S3.SS2.p1.5.m1.1.1"><in id="S3.SS2.p1.5.m1.1.1.3.cmml" xref="S3.SS2.p1.5.m1.1.1.3"></in><ci id="S3.SS2.p1.5.m1.1.1.2.cmml" xref="S3.SS2.p1.5.m1.1.1.2">𝜷</ci><ci id="S3.SS2.p1.5.m1.1.1.4.cmml" xref="S3.SS2.p1.5.m1.1.1.4">ℬ</ci></apply><apply id="S3.SS2.p1.5.m1.1.1c.cmml" xref="S3.SS2.p1.5.m1.1.1"><subset id="S3.SS2.p1.5.m1.1.1.5.cmml" xref="S3.SS2.p1.5.m1.1.1.5"></subset><share href="https://arxiv.org/html/2410.00630v1#S3.SS2.p1.5.m1.1.1.4.cmml" id="S3.SS2.p1.5.m1.1.1d.cmml" xref="S3.SS2.p1.5.m1.1.1"></share><apply id="S3.SS2.p1.5.m1.1.1.6.cmml" xref="S3.SS2.p1.5.m1.1.1.6"><csymbol cd="ambiguous" id="S3.SS2.p1.5.m1.1.1.6.1.cmml" xref="S3.SS2.p1.5.m1.1.1.6">superscript</csymbol><ci id="S3.SS2.p1.5.m1.1.1.6.2.cmml" xref="S3.SS2.p1.5.m1.1.1.6.2">ℝ</ci><cn id="S3.SS2.p1.5.m1.1.1.6.3.cmml" type="integer" xref="S3.SS2.p1.5.m1.1.1.6.3">48</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.5.m1.1c">\boldsymbol{\beta}\in\mathcal{B}\subset\mathbb{R}^{48}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.5.m1.1d">bold_italic_β ∈ caligraphic_B ⊂ blackboard_R start_POSTSUPERSCRIPT 48 end_POSTSUPERSCRIPT</annotation></semantics></math> and <math alttext="\boldsymbol{\psi}\in\Psi\subset\mathbb{R}^{157}" class="ltx_Math" display="inline" id="S3.SS2.p1.6.m2.1"><semantics id="S3.SS2.p1.6.m2.1a"><mrow id="S3.SS2.p1.6.m2.1.1" xref="S3.SS2.p1.6.m2.1.1.cmml"><mi id="S3.SS2.p1.6.m2.1.1.2" xref="S3.SS2.p1.6.m2.1.1.2.cmml">𝝍</mi><mo id="S3.SS2.p1.6.m2.1.1.3" xref="S3.SS2.p1.6.m2.1.1.3.cmml">∈</mo><mi id="S3.SS2.p1.6.m2.1.1.4" mathvariant="normal" xref="S3.SS2.p1.6.m2.1.1.4.cmml">Ψ</mi><mo id="S3.SS2.p1.6.m2.1.1.5" xref="S3.SS2.p1.6.m2.1.1.5.cmml">⊂</mo><msup id="S3.SS2.p1.6.m2.1.1.6" xref="S3.SS2.p1.6.m2.1.1.6.cmml"><mi id="S3.SS2.p1.6.m2.1.1.6.2" xref="S3.SS2.p1.6.m2.1.1.6.2.cmml">ℝ</mi><mn id="S3.SS2.p1.6.m2.1.1.6.3" xref="S3.SS2.p1.6.m2.1.1.6.3.cmml">157</mn></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.6.m2.1b"><apply id="S3.SS2.p1.6.m2.1.1.cmml" xref="S3.SS2.p1.6.m2.1.1"><and id="S3.SS2.p1.6.m2.1.1a.cmml" xref="S3.SS2.p1.6.m2.1.1"></and><apply id="S3.SS2.p1.6.m2.1.1b.cmml" xref="S3.SS2.p1.6.m2.1.1"><in id="S3.SS2.p1.6.m2.1.1.3.cmml" xref="S3.SS2.p1.6.m2.1.1.3"></in><ci id="S3.SS2.p1.6.m2.1.1.2.cmml" xref="S3.SS2.p1.6.m2.1.1.2">𝝍</ci><ci id="S3.SS2.p1.6.m2.1.1.4.cmml" xref="S3.SS2.p1.6.m2.1.1.4">Ψ</ci></apply><apply id="S3.SS2.p1.6.m2.1.1c.cmml" xref="S3.SS2.p1.6.m2.1.1"><subset id="S3.SS2.p1.6.m2.1.1.5.cmml" xref="S3.SS2.p1.6.m2.1.1.5"></subset><share href="https://arxiv.org/html/2410.00630v1#S3.SS2.p1.6.m2.1.1.4.cmml" id="S3.SS2.p1.6.m2.1.1d.cmml" xref="S3.SS2.p1.6.m2.1.1"></share><apply id="S3.SS2.p1.6.m2.1.1.6.cmml" xref="S3.SS2.p1.6.m2.1.1.6"><csymbol cd="ambiguous" id="S3.SS2.p1.6.m2.1.1.6.1.cmml" xref="S3.SS2.p1.6.m2.1.1.6">superscript</csymbol><ci id="S3.SS2.p1.6.m2.1.1.6.2.cmml" xref="S3.SS2.p1.6.m2.1.1.6.2">ℝ</ci><cn id="S3.SS2.p1.6.m2.1.1.6.3.cmml" type="integer" xref="S3.SS2.p1.6.m2.1.1.6.3">157</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.6.m2.1c">\boldsymbol{\psi}\in\Psi\subset\mathbb{R}^{157}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.6.m2.1d">bold_italic_ψ ∈ roman_Ψ ⊂ blackboard_R start_POSTSUPERSCRIPT 157 end_POSTSUPERSCRIPT</annotation></semantics></math> are the 3DMM identity and expression parameters, and <math alttext="\mathbf{w}\in\mathcal{W}\subset\mathbb{R}^{64}" class="ltx_Math" display="inline" id="S3.SS2.p1.7.m3.1"><semantics id="S3.SS2.p1.7.m3.1a"><mrow id="S3.SS2.p1.7.m3.1.1" xref="S3.SS2.p1.7.m3.1.1.cmml"><mi id="S3.SS2.p1.7.m3.1.1.2" xref="S3.SS2.p1.7.m3.1.1.2.cmml">𝐰</mi><mo id="S3.SS2.p1.7.m3.1.1.3" xref="S3.SS2.p1.7.m3.1.1.3.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p1.7.m3.1.1.4" xref="S3.SS2.p1.7.m3.1.1.4.cmml">𝒲</mi><mo id="S3.SS2.p1.7.m3.1.1.5" xref="S3.SS2.p1.7.m3.1.1.5.cmml">⊂</mo><msup id="S3.SS2.p1.7.m3.1.1.6" xref="S3.SS2.p1.7.m3.1.1.6.cmml"><mi id="S3.SS2.p1.7.m3.1.1.6.2" xref="S3.SS2.p1.7.m3.1.1.6.2.cmml">ℝ</mi><mn id="S3.SS2.p1.7.m3.1.1.6.3" xref="S3.SS2.p1.7.m3.1.1.6.3.cmml">64</mn></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.7.m3.1b"><apply id="S3.SS2.p1.7.m3.1.1.cmml" xref="S3.SS2.p1.7.m3.1.1"><and id="S3.SS2.p1.7.m3.1.1a.cmml" xref="S3.SS2.p1.7.m3.1.1"></and><apply id="S3.SS2.p1.7.m3.1.1b.cmml" xref="S3.SS2.p1.7.m3.1.1"><in id="S3.SS2.p1.7.m3.1.1.3.cmml" xref="S3.SS2.p1.7.m3.1.1.3"></in><ci id="S3.SS2.p1.7.m3.1.1.2.cmml" xref="S3.SS2.p1.7.m3.1.1.2">𝐰</ci><ci id="S3.SS2.p1.7.m3.1.1.4.cmml" xref="S3.SS2.p1.7.m3.1.1.4">𝒲</ci></apply><apply id="S3.SS2.p1.7.m3.1.1c.cmml" xref="S3.SS2.p1.7.m3.1.1"><subset id="S3.SS2.p1.7.m3.1.1.5.cmml" xref="S3.SS2.p1.7.m3.1.1.5"></subset><share href="https://arxiv.org/html/2410.00630v1#S3.SS2.p1.7.m3.1.1.4.cmml" id="S3.SS2.p1.7.m3.1.1d.cmml" xref="S3.SS2.p1.7.m3.1.1"></share><apply id="S3.SS2.p1.7.m3.1.1.6.cmml" xref="S3.SS2.p1.7.m3.1.1.6"><csymbol cd="ambiguous" id="S3.SS2.p1.7.m3.1.1.6.1.cmml" xref="S3.SS2.p1.7.m3.1.1.6">superscript</csymbol><ci id="S3.SS2.p1.7.m3.1.1.6.2.cmml" xref="S3.SS2.p1.7.m3.1.1.6.2">ℝ</ci><cn id="S3.SS2.p1.7.m3.1.1.6.3.cmml" type="integer" xref="S3.SS2.p1.7.m3.1.1.6.3">64</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.7.m3.1c">\mathbf{w}\in\mathcal{W}\subset\mathbb{R}^{64}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.7.m3.1d">bold_w ∈ caligraphic_W ⊂ blackboard_R start_POSTSUPERSCRIPT 64 end_POSTSUPERSCRIPT</annotation></semantics></math> is a learned parameter encoding additional characteristics.</p>
</div>
<div class="ltx_para" id="S3.SS2.p2">
<p class="ltx_p" id="S3.SS2.p2.1">We train this prior on synthetic data alone – it never sees a real face. While it would be feasible to train a prior model on real data (see our ablation in Tbl. <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#S4.T2" title="Table 2 ‣ 4.1. Quantitative Evaluation ‣ 4. Experiments ‣ Cafca: High-quality Novel View Synthesis of Expressive Faces from Casual Few-shot Captures"><span class="ltx_text ltx_ref_tag">2</span></a>), we chose synthetic over real for multiple reasons. Real datasets exhibit limited diversity.
Most face datasets feature monocular frontal views only, with few expressions other than smiles.
Some multi-view, multi-expression datasets exist <cite class="ltx_cite ltx_citemacro_citep">(Wuu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib75" title="">2022</a>; Kirschstein et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib29" title="">2023</a>; Zhu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib89" title="">2023</a>)</cite>, but consist of relatively few individuals due to the complexity and expense of running a capture studio.
Further, subjects must adhere to wardrobe restrictions: glasses are forbidden and hair must be tucked away.
A prior trained on such data will not generalize well to expressive faces captured in the wild. Besides, the logistics of capturing large-scale real data is extremely expensive, time and energy-consuming, and cumbersome.
Instead, synthetics guarantee us a wide range of identity, expression, and appearance diversity, at orders of magnitude lower cost and effort. In addition, synthetics provide perfect ground truth annotations: each render is accompanied by 3DMM latent codes <math alttext="\boldsymbol{\beta},\boldsymbol{\psi}" class="ltx_Math" display="inline" id="S3.SS2.p2.1.m1.2"><semantics id="S3.SS2.p2.1.m1.2a"><mrow id="S3.SS2.p2.1.m1.2.3.2" xref="S3.SS2.p2.1.m1.2.3.1.cmml"><mi id="S3.SS2.p2.1.m1.1.1" xref="S3.SS2.p2.1.m1.1.1.cmml">𝜷</mi><mo id="S3.SS2.p2.1.m1.2.3.2.1" xref="S3.SS2.p2.1.m1.2.3.1.cmml">,</mo><mi id="S3.SS2.p2.1.m1.2.2" xref="S3.SS2.p2.1.m1.2.2.cmml">𝝍</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.1.m1.2b"><list id="S3.SS2.p2.1.m1.2.3.1.cmml" xref="S3.SS2.p2.1.m1.2.3.2"><ci id="S3.SS2.p2.1.m1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1">𝜷</ci><ci id="S3.SS2.p2.1.m1.2.2.cmml" xref="S3.SS2.p2.1.m1.2.2">𝝍</ci></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.1.m1.2c">\boldsymbol{\beta},\boldsymbol{\psi}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.1.m1.2d">bold_italic_β , bold_italic_ψ</annotation></semantics></math>.</p>
</div>
<figure class="ltx_figure" id="S3.F5"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="364" id="S3.F5.g1" src="extracted/5891401/figures/synthetic_examples.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5. </span>Our synthetic faces exhibit a wide range of geometric and expression diversity and can be rendered from any viewpoint.</figcaption>
</figure>
<div class="ltx_para" id="S3.SS2.p3">
<p class="ltx_p" id="S3.SS2.p3.1">We synthesize facial training data as in  <cite class="ltx_cite ltx_citemacro_citet">Wood et al<span class="ltx_text">.</span> (<a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib72" title="">2021</a>)</cite>.
We first generate the 3D face geometry by sampling the identity and expression spaces of the 3DMM.
We then make these faces look realistic by applying physically based skin materials, attaching strand-based hairstyles, and dressing them up with clothes and glasses from our digital wardrobe.
The scene is rendered with environment lighting using Cycles, a physically-based ray tracer (<span class="ltx_text ltx_font_typewriter" id="S3.SS2.p3.1.1">www.cycles-renderer.org</span>).
Examples are shown in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#S3.F5" title="Figure 5 ‣ 3.2. Pretraining an Expressive Prior Model ‣ 3. Method ‣ Cafca: High-quality Novel View Synthesis of Expressive Faces from Casual Few-shot Captures"><span class="ltx_text ltx_ref_tag">5</span></a> and on the supplementary HTML page.
To help disentangle identity from expression, we sample 13 different random expressions for each random identity.
Each expression is then rendered from 30 random viewpoints around the head.
All faces are rendered under the same lighting condition, which was chosen to minimize shadows on the face.</p>
</div>
<div class="ltx_para" id="S3.SS2.p4">
<p class="ltx_p" id="S3.SS2.p4.6">Each training iteration randomly samples rays <math alttext="\bf r" class="ltx_Math" display="inline" id="S3.SS2.p4.1.m1.1"><semantics id="S3.SS2.p4.1.m1.1a"><mi id="S3.SS2.p4.1.m1.1.1" xref="S3.SS2.p4.1.m1.1.1.cmml">𝐫</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.1.m1.1b"><ci id="S3.SS2.p4.1.m1.1.1.cmml" xref="S3.SS2.p4.1.m1.1.1">𝐫</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.1.m1.1c">\bf r</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p4.1.m1.1d">bold_r</annotation></semantics></math> from a subset of all identities and expressions. A ray is rendered into a pixel color as given by Eq. <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#S3.E3" title="In 3.2. Pretraining an Expressive Prior Model ‣ 3. Method ‣ Cafca: High-quality Novel View Synthesis of Expressive Faces from Casual Few-shot Captures"><span class="ltx_text ltx_ref_tag">3</span></a>.
We optimize the network parameters <math alttext="\bf\theta_{\text{p}}" class="ltx_Math" display="inline" id="S3.SS2.p4.2.m2.1"><semantics id="S3.SS2.p4.2.m2.1a"><msub id="S3.SS2.p4.2.m2.1.1" xref="S3.SS2.p4.2.m2.1.1.cmml"><mi id="S3.SS2.p4.2.m2.1.1.2" xref="S3.SS2.p4.2.m2.1.1.2.cmml">θ</mi><mtext id="S3.SS2.p4.2.m2.1.1.3" xref="S3.SS2.p4.2.m2.1.1.3a.cmml">p</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.2.m2.1b"><apply id="S3.SS2.p4.2.m2.1.1.cmml" xref="S3.SS2.p4.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p4.2.m2.1.1.1.cmml" xref="S3.SS2.p4.2.m2.1.1">subscript</csymbol><ci id="S3.SS2.p4.2.m2.1.1.2.cmml" xref="S3.SS2.p4.2.m2.1.1.2">𝜃</ci><ci id="S3.SS2.p4.2.m2.1.1.3a.cmml" xref="S3.SS2.p4.2.m2.1.1.3"><mtext id="S3.SS2.p4.2.m2.1.1.3.cmml" mathsize="70%" xref="S3.SS2.p4.2.m2.1.1.3">p</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.2.m2.1c">\bf\theta_{\text{p}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p4.2.m2.1d">italic_θ start_POSTSUBSCRIPT p end_POSTSUBSCRIPT</annotation></semantics></math> and <span class="ltx_text ltx_markedasmath" id="S3.SS2.p4.6.1">N</span> per-identity latent codes <math alttext="\mathbf{w}_{1..\text{N}}" class="ltx_math_unparsed" display="inline" id="S3.SS2.p4.4.m4.1"><semantics id="S3.SS2.p4.4.m4.1a"><msub id="S3.SS2.p4.4.m4.1.2"><mi id="S3.SS2.p4.4.m4.1.2.2">𝐰</mi><mrow id="S3.SS2.p4.4.m4.1.1.1"><mn id="S3.SS2.p4.4.m4.1.1.1.1">1</mn><mo id="S3.SS2.p4.4.m4.1.1.1.2" lspace="0em" rspace="0.0835em">.</mo><mo id="S3.SS2.p4.4.m4.1.1.1.3" lspace="0.0835em" rspace="0.167em">.</mo><mtext id="S3.SS2.p4.4.m4.1.1.1.4">N</mtext></mrow></msub><annotation encoding="application/x-tex" id="S3.SS2.p4.4.m4.1b">\mathbf{w}_{1..\text{N}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p4.4.m4.1c">bold_w start_POSTSUBSCRIPT 1 . . N end_POSTSUBSCRIPT</annotation></semantics></math> while keeping the 3DMM expression and identity codes <math alttext="\boldsymbol{\beta}" class="ltx_Math" display="inline" id="S3.SS2.p4.5.m5.1"><semantics id="S3.SS2.p4.5.m5.1a"><mi id="S3.SS2.p4.5.m5.1.1" xref="S3.SS2.p4.5.m5.1.1.cmml">𝜷</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.5.m5.1b"><ci id="S3.SS2.p4.5.m5.1.1.cmml" xref="S3.SS2.p4.5.m5.1.1">𝜷</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.5.m5.1c">\boldsymbol{\beta}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p4.5.m5.1d">bold_italic_β</annotation></semantics></math> and <math alttext="\boldsymbol{\psi}" class="ltx_Math" display="inline" id="S3.SS2.p4.6.m6.1"><semantics id="S3.SS2.p4.6.m6.1a"><mi id="S3.SS2.p4.6.m6.1.1" xref="S3.SS2.p4.6.m6.1.1.cmml">𝝍</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.6.m6.1b"><ci id="S3.SS2.p4.6.m6.1.1.cmml" xref="S3.SS2.p4.6.m6.1.1">𝝍</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.6.m6.1c">\boldsymbol{\psi}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p4.6.m6.1d">bold_italic_ψ</annotation></semantics></math> frozen:</p>
<table class="ltx_equationgroup ltx_eqn_align ltx_eqn_table" id="A1.EGx3">
<tbody id="S3.E5"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_left">(5)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle\theta_{\text{p}},\textbf{w}_{\text{1..N}}=\operatorname*{arg\,%
min}_{\bf\theta,\textbf{w}_{\text{1..N}}}\mathcal{L}_{\text{prior}}\,,\qquad%
\mathcal{L}_{\text{prior}}=\mathcal{L}_{\text{recon}}+\lambda_{\text{prop}}%
\mathcal{L}_{\text{prop}}." class="ltx_Math" display="inline" id="S3.E5.m1.3"><semantics id="S3.E5.m1.3a"><mrow id="S3.E5.m1.3.3.1"><mrow id="S3.E5.m1.3.3.1.1.2" xref="S3.E5.m1.3.3.1.1.3.cmml"><mrow id="S3.E5.m1.3.3.1.1.1.1" xref="S3.E5.m1.3.3.1.1.1.1.cmml"><mrow id="S3.E5.m1.3.3.1.1.1.1.2.2" xref="S3.E5.m1.3.3.1.1.1.1.2.3.cmml"><msub id="S3.E5.m1.3.3.1.1.1.1.1.1.1" xref="S3.E5.m1.3.3.1.1.1.1.1.1.1.cmml"><mi id="S3.E5.m1.3.3.1.1.1.1.1.1.1.2" xref="S3.E5.m1.3.3.1.1.1.1.1.1.1.2.cmml">θ</mi><mtext id="S3.E5.m1.3.3.1.1.1.1.1.1.1.3" xref="S3.E5.m1.3.3.1.1.1.1.1.1.1.3a.cmml">p</mtext></msub><mo id="S3.E5.m1.3.3.1.1.1.1.2.2.3" xref="S3.E5.m1.3.3.1.1.1.1.2.3.cmml">,</mo><msub id="S3.E5.m1.3.3.1.1.1.1.2.2.2" xref="S3.E5.m1.3.3.1.1.1.1.2.2.2.cmml"><mtext class="ltx_mathvariant_bold" id="S3.E5.m1.3.3.1.1.1.1.2.2.2.2" xref="S3.E5.m1.3.3.1.1.1.1.2.2.2.2a.cmml">w</mtext><mtext id="S3.E5.m1.3.3.1.1.1.1.2.2.2.3" xref="S3.E5.m1.3.3.1.1.1.1.2.2.2.3a.cmml">1..N</mtext></msub></mrow><mo id="S3.E5.m1.3.3.1.1.1.1.3" xref="S3.E5.m1.3.3.1.1.1.1.3.cmml">=</mo><mrow id="S3.E5.m1.3.3.1.1.1.1.4" xref="S3.E5.m1.3.3.1.1.1.1.4.cmml"><munder id="S3.E5.m1.3.3.1.1.1.1.4.1" xref="S3.E5.m1.3.3.1.1.1.1.4.1.cmml"><mrow id="S3.E5.m1.3.3.1.1.1.1.4.1.2" xref="S3.E5.m1.3.3.1.1.1.1.4.1.2.cmml"><mi id="S3.E5.m1.3.3.1.1.1.1.4.1.2.2" xref="S3.E5.m1.3.3.1.1.1.1.4.1.2.2.cmml">arg</mi><mo id="S3.E5.m1.3.3.1.1.1.1.4.1.2.1" lspace="0.170em" xref="S3.E5.m1.3.3.1.1.1.1.4.1.2.1.cmml">⁢</mo><mi id="S3.E5.m1.3.3.1.1.1.1.4.1.2.3" xref="S3.E5.m1.3.3.1.1.1.1.4.1.2.3.cmml">min</mi></mrow><mrow id="S3.E5.m1.2.2.2.2" xref="S3.E5.m1.2.2.2.3.cmml"><mi id="S3.E5.m1.1.1.1.1" xref="S3.E5.m1.1.1.1.1.cmml">θ</mi><mo id="S3.E5.m1.2.2.2.2.2" xref="S3.E5.m1.2.2.2.3.cmml">,</mo><msub id="S3.E5.m1.2.2.2.2.1" xref="S3.E5.m1.2.2.2.2.1.cmml"><mtext class="ltx_mathvariant_bold" id="S3.E5.m1.2.2.2.2.1.2" xref="S3.E5.m1.2.2.2.2.1.2a.cmml">w</mtext><mtext id="S3.E5.m1.2.2.2.2.1.3" xref="S3.E5.m1.2.2.2.2.1.3a.cmml">1..N</mtext></msub></mrow></munder><mo id="S3.E5.m1.3.3.1.1.1.1.4a" xref="S3.E5.m1.3.3.1.1.1.1.4.cmml">⁡</mo><msub id="S3.E5.m1.3.3.1.1.1.1.4.2" xref="S3.E5.m1.3.3.1.1.1.1.4.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E5.m1.3.3.1.1.1.1.4.2.2" xref="S3.E5.m1.3.3.1.1.1.1.4.2.2.cmml">ℒ</mi><mtext id="S3.E5.m1.3.3.1.1.1.1.4.2.3" xref="S3.E5.m1.3.3.1.1.1.1.4.2.3a.cmml">prior</mtext></msub></mrow></mrow><mo id="S3.E5.m1.3.3.1.1.2.3" rspace="2.167em" xref="S3.E5.m1.3.3.1.1.3a.cmml">,</mo><mrow id="S3.E5.m1.3.3.1.1.2.2" xref="S3.E5.m1.3.3.1.1.2.2.cmml"><msub id="S3.E5.m1.3.3.1.1.2.2.2" xref="S3.E5.m1.3.3.1.1.2.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E5.m1.3.3.1.1.2.2.2.2" xref="S3.E5.m1.3.3.1.1.2.2.2.2.cmml">ℒ</mi><mtext id="S3.E5.m1.3.3.1.1.2.2.2.3" xref="S3.E5.m1.3.3.1.1.2.2.2.3a.cmml">prior</mtext></msub><mo id="S3.E5.m1.3.3.1.1.2.2.1" xref="S3.E5.m1.3.3.1.1.2.2.1.cmml">=</mo><mrow id="S3.E5.m1.3.3.1.1.2.2.3" xref="S3.E5.m1.3.3.1.1.2.2.3.cmml"><msub id="S3.E5.m1.3.3.1.1.2.2.3.2" xref="S3.E5.m1.3.3.1.1.2.2.3.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E5.m1.3.3.1.1.2.2.3.2.2" xref="S3.E5.m1.3.3.1.1.2.2.3.2.2.cmml">ℒ</mi><mtext id="S3.E5.m1.3.3.1.1.2.2.3.2.3" xref="S3.E5.m1.3.3.1.1.2.2.3.2.3a.cmml">recon</mtext></msub><mo id="S3.E5.m1.3.3.1.1.2.2.3.1" xref="S3.E5.m1.3.3.1.1.2.2.3.1.cmml">+</mo><mrow id="S3.E5.m1.3.3.1.1.2.2.3.3" xref="S3.E5.m1.3.3.1.1.2.2.3.3.cmml"><msub id="S3.E5.m1.3.3.1.1.2.2.3.3.2" xref="S3.E5.m1.3.3.1.1.2.2.3.3.2.cmml"><mi id="S3.E5.m1.3.3.1.1.2.2.3.3.2.2" xref="S3.E5.m1.3.3.1.1.2.2.3.3.2.2.cmml">λ</mi><mtext id="S3.E5.m1.3.3.1.1.2.2.3.3.2.3" xref="S3.E5.m1.3.3.1.1.2.2.3.3.2.3a.cmml">prop</mtext></msub><mo id="S3.E5.m1.3.3.1.1.2.2.3.3.1" xref="S3.E5.m1.3.3.1.1.2.2.3.3.1.cmml">⁢</mo><msub id="S3.E5.m1.3.3.1.1.2.2.3.3.3" xref="S3.E5.m1.3.3.1.1.2.2.3.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E5.m1.3.3.1.1.2.2.3.3.3.2" xref="S3.E5.m1.3.3.1.1.2.2.3.3.3.2.cmml">ℒ</mi><mtext id="S3.E5.m1.3.3.1.1.2.2.3.3.3.3" xref="S3.E5.m1.3.3.1.1.2.2.3.3.3.3a.cmml">prop</mtext></msub></mrow></mrow></mrow></mrow><mo id="S3.E5.m1.3.3.1.2" lspace="0em">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E5.m1.3b"><apply id="S3.E5.m1.3.3.1.1.3.cmml" xref="S3.E5.m1.3.3.1.1.2"><csymbol cd="ambiguous" id="S3.E5.m1.3.3.1.1.3a.cmml" xref="S3.E5.m1.3.3.1.1.2.3">formulae-sequence</csymbol><apply id="S3.E5.m1.3.3.1.1.1.1.cmml" xref="S3.E5.m1.3.3.1.1.1.1"><eq id="S3.E5.m1.3.3.1.1.1.1.3.cmml" xref="S3.E5.m1.3.3.1.1.1.1.3"></eq><list id="S3.E5.m1.3.3.1.1.1.1.2.3.cmml" xref="S3.E5.m1.3.3.1.1.1.1.2.2"><apply id="S3.E5.m1.3.3.1.1.1.1.1.1.1.cmml" xref="S3.E5.m1.3.3.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E5.m1.3.3.1.1.1.1.1.1.1.1.cmml" xref="S3.E5.m1.3.3.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E5.m1.3.3.1.1.1.1.1.1.1.2.cmml" xref="S3.E5.m1.3.3.1.1.1.1.1.1.1.2">𝜃</ci><ci id="S3.E5.m1.3.3.1.1.1.1.1.1.1.3a.cmml" xref="S3.E5.m1.3.3.1.1.1.1.1.1.1.3"><mtext id="S3.E5.m1.3.3.1.1.1.1.1.1.1.3.cmml" mathsize="70%" xref="S3.E5.m1.3.3.1.1.1.1.1.1.1.3">p</mtext></ci></apply><apply id="S3.E5.m1.3.3.1.1.1.1.2.2.2.cmml" xref="S3.E5.m1.3.3.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S3.E5.m1.3.3.1.1.1.1.2.2.2.1.cmml" xref="S3.E5.m1.3.3.1.1.1.1.2.2.2">subscript</csymbol><ci id="S3.E5.m1.3.3.1.1.1.1.2.2.2.2a.cmml" xref="S3.E5.m1.3.3.1.1.1.1.2.2.2.2"><mtext class="ltx_mathvariant_bold" id="S3.E5.m1.3.3.1.1.1.1.2.2.2.2.cmml" xref="S3.E5.m1.3.3.1.1.1.1.2.2.2.2">w</mtext></ci><ci id="S3.E5.m1.3.3.1.1.1.1.2.2.2.3a.cmml" xref="S3.E5.m1.3.3.1.1.1.1.2.2.2.3"><mtext id="S3.E5.m1.3.3.1.1.1.1.2.2.2.3.cmml" mathsize="70%" xref="S3.E5.m1.3.3.1.1.1.1.2.2.2.3">1..N</mtext></ci></apply></list><apply id="S3.E5.m1.3.3.1.1.1.1.4.cmml" xref="S3.E5.m1.3.3.1.1.1.1.4"><apply id="S3.E5.m1.3.3.1.1.1.1.4.1.cmml" xref="S3.E5.m1.3.3.1.1.1.1.4.1"><csymbol cd="ambiguous" id="S3.E5.m1.3.3.1.1.1.1.4.1.1.cmml" xref="S3.E5.m1.3.3.1.1.1.1.4.1">subscript</csymbol><apply id="S3.E5.m1.3.3.1.1.1.1.4.1.2.cmml" xref="S3.E5.m1.3.3.1.1.1.1.4.1.2"><times id="S3.E5.m1.3.3.1.1.1.1.4.1.2.1.cmml" xref="S3.E5.m1.3.3.1.1.1.1.4.1.2.1"></times><ci id="S3.E5.m1.3.3.1.1.1.1.4.1.2.2.cmml" xref="S3.E5.m1.3.3.1.1.1.1.4.1.2.2">arg</ci><ci id="S3.E5.m1.3.3.1.1.1.1.4.1.2.3.cmml" xref="S3.E5.m1.3.3.1.1.1.1.4.1.2.3">min</ci></apply><list id="S3.E5.m1.2.2.2.3.cmml" xref="S3.E5.m1.2.2.2.2"><ci id="S3.E5.m1.1.1.1.1.cmml" xref="S3.E5.m1.1.1.1.1">𝜃</ci><apply id="S3.E5.m1.2.2.2.2.1.cmml" xref="S3.E5.m1.2.2.2.2.1"><csymbol cd="ambiguous" id="S3.E5.m1.2.2.2.2.1.1.cmml" xref="S3.E5.m1.2.2.2.2.1">subscript</csymbol><ci id="S3.E5.m1.2.2.2.2.1.2a.cmml" xref="S3.E5.m1.2.2.2.2.1.2"><mtext class="ltx_mathvariant_bold" id="S3.E5.m1.2.2.2.2.1.2.cmml" mathsize="70%" xref="S3.E5.m1.2.2.2.2.1.2">w</mtext></ci><ci id="S3.E5.m1.2.2.2.2.1.3a.cmml" xref="S3.E5.m1.2.2.2.2.1.3"><mtext id="S3.E5.m1.2.2.2.2.1.3.cmml" mathsize="50%" xref="S3.E5.m1.2.2.2.2.1.3">1..N</mtext></ci></apply></list></apply><apply id="S3.E5.m1.3.3.1.1.1.1.4.2.cmml" xref="S3.E5.m1.3.3.1.1.1.1.4.2"><csymbol cd="ambiguous" id="S3.E5.m1.3.3.1.1.1.1.4.2.1.cmml" xref="S3.E5.m1.3.3.1.1.1.1.4.2">subscript</csymbol><ci id="S3.E5.m1.3.3.1.1.1.1.4.2.2.cmml" xref="S3.E5.m1.3.3.1.1.1.1.4.2.2">ℒ</ci><ci id="S3.E5.m1.3.3.1.1.1.1.4.2.3a.cmml" xref="S3.E5.m1.3.3.1.1.1.1.4.2.3"><mtext id="S3.E5.m1.3.3.1.1.1.1.4.2.3.cmml" mathsize="70%" xref="S3.E5.m1.3.3.1.1.1.1.4.2.3">prior</mtext></ci></apply></apply></apply><apply id="S3.E5.m1.3.3.1.1.2.2.cmml" xref="S3.E5.m1.3.3.1.1.2.2"><eq id="S3.E5.m1.3.3.1.1.2.2.1.cmml" xref="S3.E5.m1.3.3.1.1.2.2.1"></eq><apply id="S3.E5.m1.3.3.1.1.2.2.2.cmml" xref="S3.E5.m1.3.3.1.1.2.2.2"><csymbol cd="ambiguous" id="S3.E5.m1.3.3.1.1.2.2.2.1.cmml" xref="S3.E5.m1.3.3.1.1.2.2.2">subscript</csymbol><ci id="S3.E5.m1.3.3.1.1.2.2.2.2.cmml" xref="S3.E5.m1.3.3.1.1.2.2.2.2">ℒ</ci><ci id="S3.E5.m1.3.3.1.1.2.2.2.3a.cmml" xref="S3.E5.m1.3.3.1.1.2.2.2.3"><mtext id="S3.E5.m1.3.3.1.1.2.2.2.3.cmml" mathsize="70%" xref="S3.E5.m1.3.3.1.1.2.2.2.3">prior</mtext></ci></apply><apply id="S3.E5.m1.3.3.1.1.2.2.3.cmml" xref="S3.E5.m1.3.3.1.1.2.2.3"><plus id="S3.E5.m1.3.3.1.1.2.2.3.1.cmml" xref="S3.E5.m1.3.3.1.1.2.2.3.1"></plus><apply id="S3.E5.m1.3.3.1.1.2.2.3.2.cmml" xref="S3.E5.m1.3.3.1.1.2.2.3.2"><csymbol cd="ambiguous" id="S3.E5.m1.3.3.1.1.2.2.3.2.1.cmml" xref="S3.E5.m1.3.3.1.1.2.2.3.2">subscript</csymbol><ci id="S3.E5.m1.3.3.1.1.2.2.3.2.2.cmml" xref="S3.E5.m1.3.3.1.1.2.2.3.2.2">ℒ</ci><ci id="S3.E5.m1.3.3.1.1.2.2.3.2.3a.cmml" xref="S3.E5.m1.3.3.1.1.2.2.3.2.3"><mtext id="S3.E5.m1.3.3.1.1.2.2.3.2.3.cmml" mathsize="70%" xref="S3.E5.m1.3.3.1.1.2.2.3.2.3">recon</mtext></ci></apply><apply id="S3.E5.m1.3.3.1.1.2.2.3.3.cmml" xref="S3.E5.m1.3.3.1.1.2.2.3.3"><times id="S3.E5.m1.3.3.1.1.2.2.3.3.1.cmml" xref="S3.E5.m1.3.3.1.1.2.2.3.3.1"></times><apply id="S3.E5.m1.3.3.1.1.2.2.3.3.2.cmml" xref="S3.E5.m1.3.3.1.1.2.2.3.3.2"><csymbol cd="ambiguous" id="S3.E5.m1.3.3.1.1.2.2.3.3.2.1.cmml" xref="S3.E5.m1.3.3.1.1.2.2.3.3.2">subscript</csymbol><ci id="S3.E5.m1.3.3.1.1.2.2.3.3.2.2.cmml" xref="S3.E5.m1.3.3.1.1.2.2.3.3.2.2">𝜆</ci><ci id="S3.E5.m1.3.3.1.1.2.2.3.3.2.3a.cmml" xref="S3.E5.m1.3.3.1.1.2.2.3.3.2.3"><mtext id="S3.E5.m1.3.3.1.1.2.2.3.3.2.3.cmml" mathsize="70%" xref="S3.E5.m1.3.3.1.1.2.2.3.3.2.3">prop</mtext></ci></apply><apply id="S3.E5.m1.3.3.1.1.2.2.3.3.3.cmml" xref="S3.E5.m1.3.3.1.1.2.2.3.3.3"><csymbol cd="ambiguous" id="S3.E5.m1.3.3.1.1.2.2.3.3.3.1.cmml" xref="S3.E5.m1.3.3.1.1.2.2.3.3.3">subscript</csymbol><ci id="S3.E5.m1.3.3.1.1.2.2.3.3.3.2.cmml" xref="S3.E5.m1.3.3.1.1.2.2.3.3.3.2">ℒ</ci><ci id="S3.E5.m1.3.3.1.1.2.2.3.3.3.3a.cmml" xref="S3.E5.m1.3.3.1.1.2.2.3.3.3.3"><mtext id="S3.E5.m1.3.3.1.1.2.2.3.3.3.3.cmml" mathsize="70%" xref="S3.E5.m1.3.3.1.1.2.2.3.3.3.3">prop</mtext></ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E5.m1.3c">\displaystyle\theta_{\text{p}},\textbf{w}_{\text{1..N}}=\operatorname*{arg\,%
min}_{\bf\theta,\textbf{w}_{\text{1..N}}}\mathcal{L}_{\text{prior}}\,,\qquad%
\mathcal{L}_{\text{prior}}=\mathcal{L}_{\text{recon}}+\lambda_{\text{prop}}%
\mathcal{L}_{\text{prop}}.</annotation><annotation encoding="application/x-llamapun" id="S3.E5.m1.3d">italic_θ start_POSTSUBSCRIPT p end_POSTSUBSCRIPT , w start_POSTSUBSCRIPT 1..N end_POSTSUBSCRIPT = start_OPERATOR roman_arg roman_min end_OPERATOR start_POSTSUBSCRIPT italic_θ , w start_POSTSUBSCRIPT 1..N end_POSTSUBSCRIPT end_POSTSUBSCRIPT caligraphic_L start_POSTSUBSCRIPT prior end_POSTSUBSCRIPT , caligraphic_L start_POSTSUBSCRIPT prior end_POSTSUBSCRIPT = caligraphic_L start_POSTSUBSCRIPT recon end_POSTSUBSCRIPT + italic_λ start_POSTSUBSCRIPT prop end_POSTSUBSCRIPT caligraphic_L start_POSTSUBSCRIPT prop end_POSTSUBSCRIPT .</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS2.p4.8">Here <math alttext="\mathcal{L}_{\text{recon}}" class="ltx_Math" display="inline" id="S3.SS2.p4.7.m1.1"><semantics id="S3.SS2.p4.7.m1.1a"><msub id="S3.SS2.p4.7.m1.1.1" xref="S3.SS2.p4.7.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p4.7.m1.1.1.2" xref="S3.SS2.p4.7.m1.1.1.2.cmml">ℒ</mi><mtext id="S3.SS2.p4.7.m1.1.1.3" xref="S3.SS2.p4.7.m1.1.1.3a.cmml">recon</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.7.m1.1b"><apply id="S3.SS2.p4.7.m1.1.1.cmml" xref="S3.SS2.p4.7.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p4.7.m1.1.1.1.cmml" xref="S3.SS2.p4.7.m1.1.1">subscript</csymbol><ci id="S3.SS2.p4.7.m1.1.1.2.cmml" xref="S3.SS2.p4.7.m1.1.1.2">ℒ</ci><ci id="S3.SS2.p4.7.m1.1.1.3a.cmml" xref="S3.SS2.p4.7.m1.1.1.3"><mtext id="S3.SS2.p4.7.m1.1.1.3.cmml" mathsize="70%" xref="S3.SS2.p4.7.m1.1.1.3">recon</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.7.m1.1c">\mathcal{L}_{\text{recon}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p4.7.m1.1d">caligraphic_L start_POSTSUBSCRIPT recon end_POSTSUBSCRIPT</annotation></semantics></math> is the mean-absolute error between the predicted and ground-truth colors, and <math alttext="\mathcal{L}_{\text{prop}}" class="ltx_Math" display="inline" id="S3.SS2.p4.8.m2.1"><semantics id="S3.SS2.p4.8.m2.1a"><msub id="S3.SS2.p4.8.m2.1.1" xref="S3.SS2.p4.8.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p4.8.m2.1.1.2" xref="S3.SS2.p4.8.m2.1.1.2.cmml">ℒ</mi><mtext id="S3.SS2.p4.8.m2.1.1.3" xref="S3.SS2.p4.8.m2.1.1.3a.cmml">prop</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.8.m2.1b"><apply id="S3.SS2.p4.8.m2.1.1.cmml" xref="S3.SS2.p4.8.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p4.8.m2.1.1.1.cmml" xref="S3.SS2.p4.8.m2.1.1">subscript</csymbol><ci id="S3.SS2.p4.8.m2.1.1.2.cmml" xref="S3.SS2.p4.8.m2.1.1.2">ℒ</ci><ci id="S3.SS2.p4.8.m2.1.1.3a.cmml" xref="S3.SS2.p4.8.m2.1.1.3"><mtext id="S3.SS2.p4.8.m2.1.1.3.cmml" mathsize="70%" xref="S3.SS2.p4.8.m2.1.1.3">prop</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.8.m2.1c">\mathcal{L}_{\text{prop}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p4.8.m2.1d">caligraphic_L start_POSTSUBSCRIPT prop end_POSTSUBSCRIPT</annotation></semantics></math> is the weight distribution matching loss from Mip-NeRF <cite class="ltx_cite ltx_citemacro_citep">(Barron et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib2" title="">2021</a>)</cite>. Please see Sec. 2 in the supp. PDF for the spelled-out loss terms.</p>
</div>
<div class="ltx_para" id="S3.SS2.p5">
<p class="ltx_p" id="S3.SS2.p5.1">We find that, when training from scratch, the model quickly collapses and outputs zero densities everywhere. We solve this by first training on images with background for 50,000 steps and continuing without background.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3. </span>Inference from Sparse Views</h3>
<div class="ltx_para" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.1">We use our low-resolution synthetic prior model to enable high-resolution novel view synthesis of real expressive faces from few input images. We first describe how we obtain the conditional inputs and camera parameters in Sec. <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#S3.SS3.SSS1" title="3.3.1. 3DMM Fitting and Camera Estimation ‣ 3.3. Inference from Sparse Views ‣ 3. Method ‣ Cafca: High-quality Novel View Synthesis of Expressive Faces from Casual Few-shot Captures"><span class="ltx_text ltx_ref_tag">3.3.1</span></a> and the subsequent fine-tuning of our model in Sec. <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#S3.SS3.SSS2" title="3.3.2. Fine-tuning on Sparse Views ‣ 3.3. Inference from Sparse Views ‣ 3. Method ‣ Cafca: High-quality Novel View Synthesis of Expressive Faces from Casual Few-shot Captures"><span class="ltx_text ltx_ref_tag">3.3.2</span></a>.</p>
</div>
<section class="ltx_subsubsection" id="S3.SS3.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.3.1. </span>3DMM Fitting and Camera Estimation</h4>
<figure class="ltx_figure" id="S3.F6"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="150" id="S3.F6.g1" src="extracted/5891401/figures/landmarks/gnome_landmarks_and_fit_v2.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6. </span>For inference, we first recover the 3DMM and camera parameters through model-fitting to probabilistic 2D landmarks (Sec. <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#S3.SS3.SSS1" title="3.3.1. 3DMM Fitting and Camera Estimation ‣ 3.3. Inference from Sparse Views ‣ 3. Method ‣ Cafca: High-quality Novel View Synthesis of Expressive Faces from Casual Few-shot Captures"><span class="ltx_text ltx_ref_tag">3.3.1</span></a>).</figcaption>
</figure>
<div class="ltx_para" id="S3.SS3.SSS1.p1">
<p class="ltx_p" id="S3.SS3.SSS1.p1.5">Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#S1.F3" title="Figure 3 ‣ 1. Introduction ‣ Cafca: High-quality Novel View Synthesis of Expressive Faces from Casual Few-shot Captures"><span class="ltx_text ltx_ref_tag">3</span></a> gives an overview of the 3DMM fitting.
During inference, the first step is to recover camera and 3DMM parameters from un-calibrated input images.
We follow the approach of previous work  <cite class="ltx_cite ltx_citemacro_citep">(Wood et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib73" title="">2022</a>)</cite> and fit to dense 2D landmarks (see Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#S3.F6" title="Figure 6 ‣ 3.3.1. 3DMM Fitting and Camera Estimation ‣ 3.3. Inference from Sparse Views ‣ 3. Method ‣ Cafca: High-quality Novel View Synthesis of Expressive Faces from Casual Few-shot Captures"><span class="ltx_text ltx_ref_tag">6</span></a>).
We first predict 599 2D probabilistic landmarks.
Each landmark corresponds to a vertex in our 3DMM and is predicted as a 2D isotropic Gaussian with expected 2D location <math alttext="\mu" class="ltx_Math" display="inline" id="S3.SS3.SSS1.p1.1.m1.1"><semantics id="S3.SS3.SSS1.p1.1.m1.1a"><mi id="S3.SS3.SSS1.p1.1.m1.1.1" xref="S3.SS3.SSS1.p1.1.m1.1.1.cmml">μ</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p1.1.m1.1b"><ci id="S3.SS3.SSS1.p1.1.m1.1.1.cmml" xref="S3.SS3.SSS1.p1.1.m1.1.1">𝜇</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.p1.1.m1.1c">\mu</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.SSS1.p1.1.m1.1d">italic_μ</annotation></semantics></math> and scalar uncertainty <math alttext="\sigma" class="ltx_Math" display="inline" id="S3.SS3.SSS1.p1.2.m2.1"><semantics id="S3.SS3.SSS1.p1.2.m2.1a"><mi id="S3.SS3.SSS1.p1.2.m2.1.1" xref="S3.SS3.SSS1.p1.2.m2.1.1.cmml">σ</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p1.2.m2.1b"><ci id="S3.SS3.SSS1.p1.2.m2.1.1.cmml" xref="S3.SS3.SSS1.p1.2.m2.1.1">𝜎</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.p1.2.m2.1c">\sigma</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.SSS1.p1.2.m2.1d">italic_σ</annotation></semantics></math>.
Next, we minimize an energy <math alttext="E(\boldsymbol{\Phi};L)" class="ltx_Math" display="inline" id="S3.SS3.SSS1.p1.3.m3.2"><semantics id="S3.SS3.SSS1.p1.3.m3.2a"><mrow id="S3.SS3.SSS1.p1.3.m3.2.3" xref="S3.SS3.SSS1.p1.3.m3.2.3.cmml"><mi id="S3.SS3.SSS1.p1.3.m3.2.3.2" xref="S3.SS3.SSS1.p1.3.m3.2.3.2.cmml">E</mi><mo id="S3.SS3.SSS1.p1.3.m3.2.3.1" xref="S3.SS3.SSS1.p1.3.m3.2.3.1.cmml">⁢</mo><mrow id="S3.SS3.SSS1.p1.3.m3.2.3.3.2" xref="S3.SS3.SSS1.p1.3.m3.2.3.3.1.cmml"><mo id="S3.SS3.SSS1.p1.3.m3.2.3.3.2.1" stretchy="false" xref="S3.SS3.SSS1.p1.3.m3.2.3.3.1.cmml">(</mo><mi id="S3.SS3.SSS1.p1.3.m3.1.1" xref="S3.SS3.SSS1.p1.3.m3.1.1.cmml">𝚽</mi><mo id="S3.SS3.SSS1.p1.3.m3.2.3.3.2.2" xref="S3.SS3.SSS1.p1.3.m3.2.3.3.1.cmml">;</mo><mi id="S3.SS3.SSS1.p1.3.m3.2.2" xref="S3.SS3.SSS1.p1.3.m3.2.2.cmml">L</mi><mo id="S3.SS3.SSS1.p1.3.m3.2.3.3.2.3" stretchy="false" xref="S3.SS3.SSS1.p1.3.m3.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p1.3.m3.2b"><apply id="S3.SS3.SSS1.p1.3.m3.2.3.cmml" xref="S3.SS3.SSS1.p1.3.m3.2.3"><times id="S3.SS3.SSS1.p1.3.m3.2.3.1.cmml" xref="S3.SS3.SSS1.p1.3.m3.2.3.1"></times><ci id="S3.SS3.SSS1.p1.3.m3.2.3.2.cmml" xref="S3.SS3.SSS1.p1.3.m3.2.3.2">𝐸</ci><list id="S3.SS3.SSS1.p1.3.m3.2.3.3.1.cmml" xref="S3.SS3.SSS1.p1.3.m3.2.3.3.2"><ci id="S3.SS3.SSS1.p1.3.m3.1.1.cmml" xref="S3.SS3.SSS1.p1.3.m3.1.1">𝚽</ci><ci id="S3.SS3.SSS1.p1.3.m3.2.2.cmml" xref="S3.SS3.SSS1.p1.3.m3.2.2">𝐿</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.p1.3.m3.2c">E(\boldsymbol{\Phi};L)</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.SSS1.p1.3.m3.2d">italic_E ( bold_Φ ; italic_L )</annotation></semantics></math>, where <math alttext="L" class="ltx_Math" display="inline" id="S3.SS3.SSS1.p1.4.m4.1"><semantics id="S3.SS3.SSS1.p1.4.m4.1a"><mi id="S3.SS3.SSS1.p1.4.m4.1.1" xref="S3.SS3.SSS1.p1.4.m4.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p1.4.m4.1b"><ci id="S3.SS3.SSS1.p1.4.m4.1.1.cmml" xref="S3.SS3.SSS1.p1.4.m4.1.1">𝐿</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.p1.4.m4.1c">L</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.SSS1.p1.4.m4.1d">italic_L</annotation></semantics></math> denotes the landmarks and <math alttext="\boldsymbol{\Phi}" class="ltx_Math" display="inline" id="S3.SS3.SSS1.p1.5.m5.1"><semantics id="S3.SS3.SSS1.p1.5.m5.1a"><mi id="S3.SS3.SSS1.p1.5.m5.1.1" xref="S3.SS3.SSS1.p1.5.m5.1.1.cmml">𝚽</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p1.5.m5.1b"><ci id="S3.SS3.SSS1.p1.5.m5.1.1.cmml" xref="S3.SS3.SSS1.p1.5.m5.1.1">𝚽</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.p1.5.m5.1c">\boldsymbol{\Phi}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.SSS1.p1.5.m5.1d">bold_Φ</annotation></semantics></math> all the optimized 3DMM parameters including identity, expressions, joint rotations, and global translation, and intrinsic and extrinsic camera parameters, if unknown.</p>
</div>
<div class="ltx_para" id="S3.SS3.SSS1.p2">
<p class="ltx_p" id="S3.SS3.SSS1.p2.1">Minimizing <math alttext="E" class="ltx_Math" display="inline" id="S3.SS3.SSS1.p2.1.m1.1"><semantics id="S3.SS3.SSS1.p2.1.m1.1a"><mi id="S3.SS3.SSS1.p2.1.m1.1.1" xref="S3.SS3.SSS1.p2.1.m1.1.1.cmml">E</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p2.1.m1.1b"><ci id="S3.SS3.SSS1.p2.1.m1.1.1.cmml" xref="S3.SS3.SSS1.p2.1.m1.1.1">𝐸</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.p2.1.m1.1c">E</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.SSS1.p2.1.m1.1d">italic_E</annotation></semantics></math> encourages the 3DMM to explain the observed landmarks with a probabilistic 2D landmark energy, and discourages unlikely faces using regularizers on 3DMM parameters and mesh self-intersection (additional detail is given in <cite class="ltx_cite ltx_citemacro_citep">(Wood et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib73" title="">2022</a>)</cite> and in Sec. 2 of the supp. mat.).</p>
</div>
<div class="ltx_para" id="S3.SS3.SSS1.p3">
<p class="ltx_p" id="S3.SS3.SSS1.p3.1">The benefit of the 3DMM fitting is two-fold. First, we get a good estimate of the world position of the camera and the head, so that later during inversion and finetuning of the model, camera parameters can be frozen. Second, thanks to the alignment of the 3DMM latent space and our prior model’s latent space, we directly feed the 3DMM parameters into the model, which serves as a good initialization during the subsequent inversion stage.</p>
</div>
<div class="ltx_para" id="S3.SS3.SSS1.p4">
<p class="ltx_p" id="S3.SS3.SSS1.p4.4">The outputs of this step are the camera parameters (shared intrinsics <span class="ltx_text ltx_markedasmath" id="S3.SS3.SSS1.p4.4.1">K</span> and per-camera extrinsics <math alttext="[\boldsymbol{\text{R}}_{i}|\boldsymbol{\text{t}}_{i}]" class="ltx_Math" display="inline" id="S3.SS3.SSS1.p4.2.m2.1"><semantics id="S3.SS3.SSS1.p4.2.m2.1a"><mrow id="S3.SS3.SSS1.p4.2.m2.1.1.1" xref="S3.SS3.SSS1.p4.2.m2.1.1.2.cmml"><mo id="S3.SS3.SSS1.p4.2.m2.1.1.1.2" stretchy="false" xref="S3.SS3.SSS1.p4.2.m2.1.1.2.1.cmml">[</mo><mrow id="S3.SS3.SSS1.p4.2.m2.1.1.1.1" xref="S3.SS3.SSS1.p4.2.m2.1.1.1.1.cmml"><msub id="S3.SS3.SSS1.p4.2.m2.1.1.1.1.2" xref="S3.SS3.SSS1.p4.2.m2.1.1.1.1.2.cmml"><mtext id="S3.SS3.SSS1.p4.2.m2.1.1.1.1.2.2" xref="S3.SS3.SSS1.p4.2.m2.1.1.1.1.2.2a.cmml">R</mtext><mi id="S3.SS3.SSS1.p4.2.m2.1.1.1.1.2.3" xref="S3.SS3.SSS1.p4.2.m2.1.1.1.1.2.3.cmml">i</mi></msub><mo fence="false" id="S3.SS3.SSS1.p4.2.m2.1.1.1.1.1" xref="S3.SS3.SSS1.p4.2.m2.1.1.1.1.1.cmml">|</mo><msub id="S3.SS3.SSS1.p4.2.m2.1.1.1.1.3" xref="S3.SS3.SSS1.p4.2.m2.1.1.1.1.3.cmml"><mtext id="S3.SS3.SSS1.p4.2.m2.1.1.1.1.3.2" xref="S3.SS3.SSS1.p4.2.m2.1.1.1.1.3.2a.cmml">t</mtext><mi id="S3.SS3.SSS1.p4.2.m2.1.1.1.1.3.3" xref="S3.SS3.SSS1.p4.2.m2.1.1.1.1.3.3.cmml">i</mi></msub></mrow><mo id="S3.SS3.SSS1.p4.2.m2.1.1.1.3" stretchy="false" xref="S3.SS3.SSS1.p4.2.m2.1.1.2.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p4.2.m2.1b"><apply id="S3.SS3.SSS1.p4.2.m2.1.1.2.cmml" xref="S3.SS3.SSS1.p4.2.m2.1.1.1"><csymbol cd="latexml" id="S3.SS3.SSS1.p4.2.m2.1.1.2.1.cmml" xref="S3.SS3.SSS1.p4.2.m2.1.1.1.2">delimited-[]</csymbol><apply id="S3.SS3.SSS1.p4.2.m2.1.1.1.1.cmml" xref="S3.SS3.SSS1.p4.2.m2.1.1.1.1"><csymbol cd="latexml" id="S3.SS3.SSS1.p4.2.m2.1.1.1.1.1.cmml" xref="S3.SS3.SSS1.p4.2.m2.1.1.1.1.1">conditional</csymbol><apply id="S3.SS3.SSS1.p4.2.m2.1.1.1.1.2.cmml" xref="S3.SS3.SSS1.p4.2.m2.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.SS3.SSS1.p4.2.m2.1.1.1.1.2.1.cmml" xref="S3.SS3.SSS1.p4.2.m2.1.1.1.1.2">subscript</csymbol><ci id="S3.SS3.SSS1.p4.2.m2.1.1.1.1.2.2a.cmml" xref="S3.SS3.SSS1.p4.2.m2.1.1.1.1.2.2"><mtext id="S3.SS3.SSS1.p4.2.m2.1.1.1.1.2.2.cmml" xref="S3.SS3.SSS1.p4.2.m2.1.1.1.1.2.2">R</mtext></ci><ci id="S3.SS3.SSS1.p4.2.m2.1.1.1.1.2.3.cmml" xref="S3.SS3.SSS1.p4.2.m2.1.1.1.1.2.3">𝑖</ci></apply><apply id="S3.SS3.SSS1.p4.2.m2.1.1.1.1.3.cmml" xref="S3.SS3.SSS1.p4.2.m2.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.SS3.SSS1.p4.2.m2.1.1.1.1.3.1.cmml" xref="S3.SS3.SSS1.p4.2.m2.1.1.1.1.3">subscript</csymbol><ci id="S3.SS3.SSS1.p4.2.m2.1.1.1.1.3.2a.cmml" xref="S3.SS3.SSS1.p4.2.m2.1.1.1.1.3.2"><mtext id="S3.SS3.SSS1.p4.2.m2.1.1.1.1.3.2.cmml" xref="S3.SS3.SSS1.p4.2.m2.1.1.1.1.3.2">t</mtext></ci><ci id="S3.SS3.SSS1.p4.2.m2.1.1.1.1.3.3.cmml" xref="S3.SS3.SSS1.p4.2.m2.1.1.1.1.3.3">𝑖</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.p4.2.m2.1c">[\boldsymbol{\text{R}}_{i}|\boldsymbol{\text{t}}_{i}]</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.SSS1.p4.2.m2.1d">[ R start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT | t start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ]</annotation></semantics></math>), a shared identity code <math alttext="\boldsymbol{\beta}" class="ltx_Math" display="inline" id="S3.SS3.SSS1.p4.3.m3.1"><semantics id="S3.SS3.SSS1.p4.3.m3.1a"><mi id="S3.SS3.SSS1.p4.3.m3.1.1" xref="S3.SS3.SSS1.p4.3.m3.1.1.cmml">𝜷</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p4.3.m3.1b"><ci id="S3.SS3.SSS1.p4.3.m3.1.1.cmml" xref="S3.SS3.SSS1.p4.3.m3.1.1">𝜷</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.p4.3.m3.1c">\boldsymbol{\beta}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.SSS1.p4.3.m3.1d">bold_italic_β</annotation></semantics></math>, and per-image expression codes <math alttext="\boldsymbol{\psi}_{i}" class="ltx_Math" display="inline" id="S3.SS3.SSS1.p4.4.m4.1"><semantics id="S3.SS3.SSS1.p4.4.m4.1a"><msub id="S3.SS3.SSS1.p4.4.m4.1.1" xref="S3.SS3.SSS1.p4.4.m4.1.1.cmml"><mi id="S3.SS3.SSS1.p4.4.m4.1.1.2" xref="S3.SS3.SSS1.p4.4.m4.1.1.2.cmml">𝝍</mi><mi id="S3.SS3.SSS1.p4.4.m4.1.1.3" xref="S3.SS3.SSS1.p4.4.m4.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p4.4.m4.1b"><apply id="S3.SS3.SSS1.p4.4.m4.1.1.cmml" xref="S3.SS3.SSS1.p4.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS1.p4.4.m4.1.1.1.cmml" xref="S3.SS3.SSS1.p4.4.m4.1.1">subscript</csymbol><ci id="S3.SS3.SSS1.p4.4.m4.1.1.2.cmml" xref="S3.SS3.SSS1.p4.4.m4.1.1.2">𝝍</ci><ci id="S3.SS3.SSS1.p4.4.m4.1.1.3.cmml" xref="S3.SS3.SSS1.p4.4.m4.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.p4.4.m4.1c">\boldsymbol{\psi}_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.SSS1.p4.4.m4.1d">bold_italic_ψ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>.
For casual in-the-wild captures, it can be challenging to hold the same expression while the data is being captured.
Therefore, we allow expression code to vary slightly between images to make the inversion robust to small, involuntary micro-changes in expression.
In the studio setting, however, the cameras are synchronized and hence it is sufficient to optimize for a single, shared expression code.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S3.SS3.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.3.2. </span>Fine-tuning on Sparse Views</h4>
<div class="ltx_para" id="S3.SS3.SSS2.p1">
<p class="ltx_p" id="S3.SS3.SSS2.p1.1">This section describes how to fine-tune the low-resolution synthetic prior model to sparse, high-resolution real input images. Fine-tuning requires a short warm-up phase where only the latent code for the target <math alttext="\mathbf{w}_{\text{target}}" class="ltx_Math" display="inline" id="S3.SS3.SSS2.p1.1.m1.1"><semantics id="S3.SS3.SSS2.p1.1.m1.1a"><msub id="S3.SS3.SSS2.p1.1.m1.1.1" xref="S3.SS3.SSS2.p1.1.m1.1.1.cmml"><mi id="S3.SS3.SSS2.p1.1.m1.1.1.2" xref="S3.SS3.SSS2.p1.1.m1.1.1.2.cmml">𝐰</mi><mtext id="S3.SS3.SSS2.p1.1.m1.1.1.3" xref="S3.SS3.SSS2.p1.1.m1.1.1.3a.cmml">target</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS2.p1.1.m1.1b"><apply id="S3.SS3.SSS2.p1.1.m1.1.1.cmml" xref="S3.SS3.SSS2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS2.p1.1.m1.1.1.1.cmml" xref="S3.SS3.SSS2.p1.1.m1.1.1">subscript</csymbol><ci id="S3.SS3.SSS2.p1.1.m1.1.1.2.cmml" xref="S3.SS3.SSS2.p1.1.m1.1.1.2">𝐰</ci><ci id="S3.SS3.SSS2.p1.1.m1.1.1.3a.cmml" xref="S3.SS3.SSS2.p1.1.m1.1.1.3"><mtext id="S3.SS3.SSS2.p1.1.m1.1.1.3.cmml" mathsize="70%" xref="S3.SS3.SSS2.p1.1.m1.1.1.3">target</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS2.p1.1.m1.1c">\mathbf{w}_{\text{target}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.SSS2.p1.1.m1.1d">bold_w start_POSTSUBSCRIPT target end_POSTSUBSCRIPT</annotation></semantics></math> is optimized. After that, fine-tuning optimizes all model parameters under additional constraints on the geometry and the appearance weights. We randomly sample rays from all available inputs, typically three images, and mask them to the foreground by multiplying them by an estimated foreground mask <cite class="ltx_cite ltx_citemacro_citep">(Pandey et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib45" title="">2021</a>)</cite>.</p>
</div>
<section class="ltx_paragraph" id="S3.SS3.SSS2.Px1">
<h5 class="ltx_title ltx_title_paragraph">Warm-up by Latent Code Inversion</h5>
<div class="ltx_para" id="S3.SS3.SSS2.Px1.p1">
<p class="ltx_p" id="S3.SS3.SSS2.Px1.p1.3">While the 3DMM fitting provides the identity and expression codes <math alttext="\boldsymbol{\beta},\boldsymbol{\psi}_{\text{i}}" class="ltx_Math" display="inline" id="S3.SS3.SSS2.Px1.p1.1.m1.2"><semantics id="S3.SS3.SSS2.Px1.p1.1.m1.2a"><mrow id="S3.SS3.SSS2.Px1.p1.1.m1.2.2.1" xref="S3.SS3.SSS2.Px1.p1.1.m1.2.2.2.cmml"><mi id="S3.SS3.SSS2.Px1.p1.1.m1.1.1" xref="S3.SS3.SSS2.Px1.p1.1.m1.1.1.cmml">𝜷</mi><mo id="S3.SS3.SSS2.Px1.p1.1.m1.2.2.1.2" xref="S3.SS3.SSS2.Px1.p1.1.m1.2.2.2.cmml">,</mo><msub id="S3.SS3.SSS2.Px1.p1.1.m1.2.2.1.1" xref="S3.SS3.SSS2.Px1.p1.1.m1.2.2.1.1.cmml"><mi id="S3.SS3.SSS2.Px1.p1.1.m1.2.2.1.1.2" xref="S3.SS3.SSS2.Px1.p1.1.m1.2.2.1.1.2.cmml">𝝍</mi><mtext id="S3.SS3.SSS2.Px1.p1.1.m1.2.2.1.1.3" xref="S3.SS3.SSS2.Px1.p1.1.m1.2.2.1.1.3a.cmml">i</mtext></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS2.Px1.p1.1.m1.2b"><list id="S3.SS3.SSS2.Px1.p1.1.m1.2.2.2.cmml" xref="S3.SS3.SSS2.Px1.p1.1.m1.2.2.1"><ci id="S3.SS3.SSS2.Px1.p1.1.m1.1.1.cmml" xref="S3.SS3.SSS2.Px1.p1.1.m1.1.1">𝜷</ci><apply id="S3.SS3.SSS2.Px1.p1.1.m1.2.2.1.1.cmml" xref="S3.SS3.SSS2.Px1.p1.1.m1.2.2.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS2.Px1.p1.1.m1.2.2.1.1.1.cmml" xref="S3.SS3.SSS2.Px1.p1.1.m1.2.2.1.1">subscript</csymbol><ci id="S3.SS3.SSS2.Px1.p1.1.m1.2.2.1.1.2.cmml" xref="S3.SS3.SSS2.Px1.p1.1.m1.2.2.1.1.2">𝝍</ci><ci id="S3.SS3.SSS2.Px1.p1.1.m1.2.2.1.1.3a.cmml" xref="S3.SS3.SSS2.Px1.p1.1.m1.2.2.1.1.3"><mtext id="S3.SS3.SSS2.Px1.p1.1.m1.2.2.1.1.3.cmml" mathsize="70%" xref="S3.SS3.SSS2.Px1.p1.1.m1.2.2.1.1.3">i</mtext></ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS2.Px1.p1.1.m1.2c">\boldsymbol{\beta},\boldsymbol{\psi}_{\text{i}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.SSS2.Px1.p1.1.m1.2d">bold_italic_β , bold_italic_ψ start_POSTSUBSCRIPT i end_POSTSUBSCRIPT</annotation></semantics></math>, our model also requires the conditional input <math alttext="\mathbf{w}" class="ltx_Math" display="inline" id="S3.SS3.SSS2.Px1.p1.2.m2.1"><semantics id="S3.SS3.SSS2.Px1.p1.2.m2.1a"><mi id="S3.SS3.SSS2.Px1.p1.2.m2.1.1" xref="S3.SS3.SSS2.Px1.p1.2.m2.1.1.cmml">𝐰</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS2.Px1.p1.2.m2.1b"><ci id="S3.SS3.SSS2.Px1.p1.2.m2.1.1.cmml" xref="S3.SS3.SSS2.Px1.p1.2.m2.1.1">𝐰</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS2.Px1.p1.2.m2.1c">\mathbf{w}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.SSS2.Px1.p1.2.m2.1d">bold_w</annotation></semantics></math>, which models out-of-model characteristics like hair, clothing, and appearance. We follow <cite class="ltx_cite ltx_citemacro_citep">(Buehler et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib9" title="">2023</a>)</cite> and search the learned latent space <math alttext="\mathcal{W}" class="ltx_Math" display="inline" id="S3.SS3.SSS2.Px1.p1.3.m3.1"><semantics id="S3.SS3.SSS2.Px1.p1.3.m3.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.SSS2.Px1.p1.3.m3.1.1" xref="S3.SS3.SSS2.Px1.p1.3.m3.1.1.cmml">𝒲</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS2.Px1.p1.3.m3.1b"><ci id="S3.SS3.SSS2.Px1.p1.3.m3.1.1.cmml" xref="S3.SS3.SSS2.Px1.p1.3.m3.1.1">𝒲</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS2.Px1.p1.3.m3.1c">\mathcal{W}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.SSS2.Px1.p1.3.m3.1d">caligraphic_W</annotation></semantics></math> of the prior model for a latent code that roughly matches the geometry and appearance of the input images. We downscale the three input images to the resolution of the prior model, sample random patches, and optimize</p>
</div>
<div class="ltx_para" id="S3.SS3.SSS2.Px1.p2">
<table class="ltx_equation ltx_eqn_table" id="S3.E6">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_left">(6)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathbf{w}_{\text{target}}=\operatorname*{arg\,min}_{\mathbf{w}}\mathcal{L}_{%
\text{recon}}+\lambda_{\text{LPIPS}}\mathcal{L}_{\text{LPIPS}}." class="ltx_Math" display="block" id="S3.E6.m1.1"><semantics id="S3.E6.m1.1a"><mrow id="S3.E6.m1.1.1.1" xref="S3.E6.m1.1.1.1.1.cmml"><mrow id="S3.E6.m1.1.1.1.1" xref="S3.E6.m1.1.1.1.1.cmml"><msub id="S3.E6.m1.1.1.1.1.2" xref="S3.E6.m1.1.1.1.1.2.cmml"><mi id="S3.E6.m1.1.1.1.1.2.2" xref="S3.E6.m1.1.1.1.1.2.2.cmml">𝐰</mi><mtext id="S3.E6.m1.1.1.1.1.2.3" xref="S3.E6.m1.1.1.1.1.2.3a.cmml">target</mtext></msub><mo id="S3.E6.m1.1.1.1.1.1" xref="S3.E6.m1.1.1.1.1.1.cmml">=</mo><mrow id="S3.E6.m1.1.1.1.1.3" xref="S3.E6.m1.1.1.1.1.3.cmml"><mrow id="S3.E6.m1.1.1.1.1.3.2" xref="S3.E6.m1.1.1.1.1.3.2.cmml"><munder id="S3.E6.m1.1.1.1.1.3.2.1" xref="S3.E6.m1.1.1.1.1.3.2.1.cmml"><mrow id="S3.E6.m1.1.1.1.1.3.2.1.2" xref="S3.E6.m1.1.1.1.1.3.2.1.2.cmml"><mi id="S3.E6.m1.1.1.1.1.3.2.1.2.2" xref="S3.E6.m1.1.1.1.1.3.2.1.2.2.cmml">arg</mi><mo id="S3.E6.m1.1.1.1.1.3.2.1.2.1" lspace="0.170em" xref="S3.E6.m1.1.1.1.1.3.2.1.2.1.cmml">⁢</mo><mi id="S3.E6.m1.1.1.1.1.3.2.1.2.3" xref="S3.E6.m1.1.1.1.1.3.2.1.2.3.cmml">min</mi></mrow><mi id="S3.E6.m1.1.1.1.1.3.2.1.3" xref="S3.E6.m1.1.1.1.1.3.2.1.3.cmml">𝐰</mi></munder><mo id="S3.E6.m1.1.1.1.1.3.2a" xref="S3.E6.m1.1.1.1.1.3.2.cmml">⁡</mo><msub id="S3.E6.m1.1.1.1.1.3.2.2" xref="S3.E6.m1.1.1.1.1.3.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E6.m1.1.1.1.1.3.2.2.2" xref="S3.E6.m1.1.1.1.1.3.2.2.2.cmml">ℒ</mi><mtext id="S3.E6.m1.1.1.1.1.3.2.2.3" xref="S3.E6.m1.1.1.1.1.3.2.2.3a.cmml">recon</mtext></msub></mrow><mo id="S3.E6.m1.1.1.1.1.3.1" xref="S3.E6.m1.1.1.1.1.3.1.cmml">+</mo><mrow id="S3.E6.m1.1.1.1.1.3.3" xref="S3.E6.m1.1.1.1.1.3.3.cmml"><msub id="S3.E6.m1.1.1.1.1.3.3.2" xref="S3.E6.m1.1.1.1.1.3.3.2.cmml"><mi id="S3.E6.m1.1.1.1.1.3.3.2.2" xref="S3.E6.m1.1.1.1.1.3.3.2.2.cmml">λ</mi><mtext id="S3.E6.m1.1.1.1.1.3.3.2.3" xref="S3.E6.m1.1.1.1.1.3.3.2.3a.cmml">LPIPS</mtext></msub><mo id="S3.E6.m1.1.1.1.1.3.3.1" xref="S3.E6.m1.1.1.1.1.3.3.1.cmml">⁢</mo><msub id="S3.E6.m1.1.1.1.1.3.3.3" xref="S3.E6.m1.1.1.1.1.3.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E6.m1.1.1.1.1.3.3.3.2" xref="S3.E6.m1.1.1.1.1.3.3.3.2.cmml">ℒ</mi><mtext id="S3.E6.m1.1.1.1.1.3.3.3.3" xref="S3.E6.m1.1.1.1.1.3.3.3.3a.cmml">LPIPS</mtext></msub></mrow></mrow></mrow><mo id="S3.E6.m1.1.1.1.2" lspace="0em" xref="S3.E6.m1.1.1.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E6.m1.1b"><apply id="S3.E6.m1.1.1.1.1.cmml" xref="S3.E6.m1.1.1.1"><eq id="S3.E6.m1.1.1.1.1.1.cmml" xref="S3.E6.m1.1.1.1.1.1"></eq><apply id="S3.E6.m1.1.1.1.1.2.cmml" xref="S3.E6.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E6.m1.1.1.1.1.2.1.cmml" xref="S3.E6.m1.1.1.1.1.2">subscript</csymbol><ci id="S3.E6.m1.1.1.1.1.2.2.cmml" xref="S3.E6.m1.1.1.1.1.2.2">𝐰</ci><ci id="S3.E6.m1.1.1.1.1.2.3a.cmml" xref="S3.E6.m1.1.1.1.1.2.3"><mtext id="S3.E6.m1.1.1.1.1.2.3.cmml" mathsize="70%" xref="S3.E6.m1.1.1.1.1.2.3">target</mtext></ci></apply><apply id="S3.E6.m1.1.1.1.1.3.cmml" xref="S3.E6.m1.1.1.1.1.3"><plus id="S3.E6.m1.1.1.1.1.3.1.cmml" xref="S3.E6.m1.1.1.1.1.3.1"></plus><apply id="S3.E6.m1.1.1.1.1.3.2.cmml" xref="S3.E6.m1.1.1.1.1.3.2"><apply id="S3.E6.m1.1.1.1.1.3.2.1.cmml" xref="S3.E6.m1.1.1.1.1.3.2.1"><csymbol cd="ambiguous" id="S3.E6.m1.1.1.1.1.3.2.1.1.cmml" xref="S3.E6.m1.1.1.1.1.3.2.1">subscript</csymbol><apply id="S3.E6.m1.1.1.1.1.3.2.1.2.cmml" xref="S3.E6.m1.1.1.1.1.3.2.1.2"><times id="S3.E6.m1.1.1.1.1.3.2.1.2.1.cmml" xref="S3.E6.m1.1.1.1.1.3.2.1.2.1"></times><ci id="S3.E6.m1.1.1.1.1.3.2.1.2.2.cmml" xref="S3.E6.m1.1.1.1.1.3.2.1.2.2">arg</ci><ci id="S3.E6.m1.1.1.1.1.3.2.1.2.3.cmml" xref="S3.E6.m1.1.1.1.1.3.2.1.2.3">min</ci></apply><ci id="S3.E6.m1.1.1.1.1.3.2.1.3.cmml" xref="S3.E6.m1.1.1.1.1.3.2.1.3">𝐰</ci></apply><apply id="S3.E6.m1.1.1.1.1.3.2.2.cmml" xref="S3.E6.m1.1.1.1.1.3.2.2"><csymbol cd="ambiguous" id="S3.E6.m1.1.1.1.1.3.2.2.1.cmml" xref="S3.E6.m1.1.1.1.1.3.2.2">subscript</csymbol><ci id="S3.E6.m1.1.1.1.1.3.2.2.2.cmml" xref="S3.E6.m1.1.1.1.1.3.2.2.2">ℒ</ci><ci id="S3.E6.m1.1.1.1.1.3.2.2.3a.cmml" xref="S3.E6.m1.1.1.1.1.3.2.2.3"><mtext id="S3.E6.m1.1.1.1.1.3.2.2.3.cmml" mathsize="70%" xref="S3.E6.m1.1.1.1.1.3.2.2.3">recon</mtext></ci></apply></apply><apply id="S3.E6.m1.1.1.1.1.3.3.cmml" xref="S3.E6.m1.1.1.1.1.3.3"><times id="S3.E6.m1.1.1.1.1.3.3.1.cmml" xref="S3.E6.m1.1.1.1.1.3.3.1"></times><apply id="S3.E6.m1.1.1.1.1.3.3.2.cmml" xref="S3.E6.m1.1.1.1.1.3.3.2"><csymbol cd="ambiguous" id="S3.E6.m1.1.1.1.1.3.3.2.1.cmml" xref="S3.E6.m1.1.1.1.1.3.3.2">subscript</csymbol><ci id="S3.E6.m1.1.1.1.1.3.3.2.2.cmml" xref="S3.E6.m1.1.1.1.1.3.3.2.2">𝜆</ci><ci id="S3.E6.m1.1.1.1.1.3.3.2.3a.cmml" xref="S3.E6.m1.1.1.1.1.3.3.2.3"><mtext id="S3.E6.m1.1.1.1.1.3.3.2.3.cmml" mathsize="70%" xref="S3.E6.m1.1.1.1.1.3.3.2.3">LPIPS</mtext></ci></apply><apply id="S3.E6.m1.1.1.1.1.3.3.3.cmml" xref="S3.E6.m1.1.1.1.1.3.3.3"><csymbol cd="ambiguous" id="S3.E6.m1.1.1.1.1.3.3.3.1.cmml" xref="S3.E6.m1.1.1.1.1.3.3.3">subscript</csymbol><ci id="S3.E6.m1.1.1.1.1.3.3.3.2.cmml" xref="S3.E6.m1.1.1.1.1.3.3.3.2">ℒ</ci><ci id="S3.E6.m1.1.1.1.1.3.3.3.3a.cmml" xref="S3.E6.m1.1.1.1.1.3.3.3.3"><mtext id="S3.E6.m1.1.1.1.1.3.3.3.3.cmml" mathsize="70%" xref="S3.E6.m1.1.1.1.1.3.3.3.3">LPIPS</mtext></ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E6.m1.1c">\mathbf{w}_{\text{target}}=\operatorname*{arg\,min}_{\mathbf{w}}\mathcal{L}_{%
\text{recon}}+\lambda_{\text{LPIPS}}\mathcal{L}_{\text{LPIPS}}.</annotation><annotation encoding="application/x-llamapun" id="S3.E6.m1.1d">bold_w start_POSTSUBSCRIPT target end_POSTSUBSCRIPT = start_OPERATOR roman_arg roman_min end_OPERATOR start_POSTSUBSCRIPT bold_w end_POSTSUBSCRIPT caligraphic_L start_POSTSUBSCRIPT recon end_POSTSUBSCRIPT + italic_λ start_POSTSUBSCRIPT LPIPS end_POSTSUBSCRIPT caligraphic_L start_POSTSUBSCRIPT LPIPS end_POSTSUBSCRIPT .</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S3.SS3.SSS2.Px1.p3">
<p class="ltx_p" id="S3.SS3.SSS2.Px1.p3.2">The photo-metric reconstruction term <math alttext="\mathcal{L}_{\text{recon}}" class="ltx_Math" display="inline" id="S3.SS3.SSS2.Px1.p3.1.m1.1"><semantics id="S3.SS3.SSS2.Px1.p3.1.m1.1a"><msub id="S3.SS3.SSS2.Px1.p3.1.m1.1.1" xref="S3.SS3.SSS2.Px1.p3.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.SSS2.Px1.p3.1.m1.1.1.2" xref="S3.SS3.SSS2.Px1.p3.1.m1.1.1.2.cmml">ℒ</mi><mtext id="S3.SS3.SSS2.Px1.p3.1.m1.1.1.3" xref="S3.SS3.SSS2.Px1.p3.1.m1.1.1.3a.cmml">recon</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS2.Px1.p3.1.m1.1b"><apply id="S3.SS3.SSS2.Px1.p3.1.m1.1.1.cmml" xref="S3.SS3.SSS2.Px1.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS2.Px1.p3.1.m1.1.1.1.cmml" xref="S3.SS3.SSS2.Px1.p3.1.m1.1.1">subscript</csymbol><ci id="S3.SS3.SSS2.Px1.p3.1.m1.1.1.2.cmml" xref="S3.SS3.SSS2.Px1.p3.1.m1.1.1.2">ℒ</ci><ci id="S3.SS3.SSS2.Px1.p3.1.m1.1.1.3a.cmml" xref="S3.SS3.SSS2.Px1.p3.1.m1.1.1.3"><mtext id="S3.SS3.SSS2.Px1.p3.1.m1.1.1.3.cmml" mathsize="70%" xref="S3.SS3.SSS2.Px1.p3.1.m1.1.1.3">recon</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS2.Px1.p3.1.m1.1c">\mathcal{L}_{\text{recon}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.SSS2.Px1.p3.1.m1.1d">caligraphic_L start_POSTSUBSCRIPT recon end_POSTSUBSCRIPT</annotation></semantics></math> is the mean absolute error between the rendered and the ground-truth patch and <span class="ltx_text ltx_markedasmath" id="S3.SS3.SSS2.Px1.p3.2.1">LPIPS</span> is a perceptual loss in the feature space of a pre-trained image classifier <cite class="ltx_cite ltx_citemacro_citep">(Zhang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib84" title="">2018</a>; Simonyan and Zisserman, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib57" title="">2015</a>)</cite>. Note that the LPIPS loss is only employed during inversion, not during model fitting.
The camera, 3DMM identity, and expression parameters are frozen during inversion.</p>
</div>
</section>
<section class="ltx_paragraph" id="S3.SS3.SSS2.Px2">
<h5 class="ltx_title ltx_title_paragraph">Model Fitting</h5>
<div class="ltx_para" id="S3.SS3.SSS2.Px2.p1">
<p class="ltx_p" id="S3.SS3.SSS2.Px2.p1.1">The output of the warm-up is a rough approximation of the input images in a <em class="ltx_emph ltx_font_italic" id="S3.SS3.SSS2.Px2.p1.1.1">low-resolution, synthetic</em> space. In model fitting, we cross the domain gap to enable detailed novel view synthesis at <em class="ltx_emph ltx_font_italic" id="S3.SS3.SSS2.Px2.p1.1.2">high resolution</em> for <em class="ltx_emph ltx_font_italic" id="S3.SS3.SSS2.Px2.p1.1.3">realistic</em> faces. The model fitting needs to cross a substantial domain gap so that the output can contain details that have never been seen during prior model training.</p>
</div>
<div class="ltx_para" id="S3.SS3.SSS2.Px2.p2">
<p class="ltx_p" id="S3.SS3.SSS2.Px2.p2.1">Model fitting optimizes all model parameters on sparse, usually two or three, input images. In a randomly initialized NeRF <cite class="ltx_cite ltx_citemacro_citep">(Mildenhall et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib40" title="">2020</a>)</cite>, this optimization would overfit and would fail to produce correct novel views <cite class="ltx_cite ltx_citemacro_citep">(Yang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib78" title="">2023</a>; Truong et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib65" title="">2023</a>; Buehler et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib9" title="">2023</a>)</cite>. Thanks to our pretrained prior model, we can employ both <em class="ltx_emph ltx_font_italic" id="S3.SS3.SSS2.Px2.p2.1.1">implicit</em> and <em class="ltx_emph ltx_font_italic" id="S3.SS3.SSS2.Px2.p2.1.2">explicit</em> regularization, which yields high-quality results even in such sparse settings.</p>
</div>
<div class="ltx_para" id="S3.SS3.SSS2.Px2.p3">
<p class="ltx_p" id="S3.SS3.SSS2.Px2.p3.1">Implicit regularization comes from the fact that our prior model is trained on an aligned dataset of human faces. Initializing the weights of a NeRF with the correct latent code and weights of a prior model avoids total collapse. However, the optimization can still produce strong artifacts like duplicate ears and view-dependent color distortions.
We follow <cite class="ltx_cite ltx_citemacro_citep">(Buehler et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib9" title="">2023</a>)</cite> and add explicit regularization on the consistency of predicted vs. analytical normals and an L2 regularization on the weight of the view branch to avoid view-dependent flickering. In addition, we add a distortion loss term <cite class="ltx_cite ltx_citemacro_citep">(Barron et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib3" title="">2022</a>)</cite> <math alttext="\mathcal{L}_{\text{dist}}" class="ltx_Math" display="inline" id="S3.SS3.SSS2.Px2.p3.1.m1.1"><semantics id="S3.SS3.SSS2.Px2.p3.1.m1.1a"><msub id="S3.SS3.SSS2.Px2.p3.1.m1.1.1" xref="S3.SS3.SSS2.Px2.p3.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.SSS2.Px2.p3.1.m1.1.1.2" xref="S3.SS3.SSS2.Px2.p3.1.m1.1.1.2.cmml">ℒ</mi><mtext id="S3.SS3.SSS2.Px2.p3.1.m1.1.1.3" xref="S3.SS3.SSS2.Px2.p3.1.m1.1.1.3a.cmml">dist</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS2.Px2.p3.1.m1.1b"><apply id="S3.SS3.SSS2.Px2.p3.1.m1.1.1.cmml" xref="S3.SS3.SSS2.Px2.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS2.Px2.p3.1.m1.1.1.1.cmml" xref="S3.SS3.SSS2.Px2.p3.1.m1.1.1">subscript</csymbol><ci id="S3.SS3.SSS2.Px2.p3.1.m1.1.1.2.cmml" xref="S3.SS3.SSS2.Px2.p3.1.m1.1.1.2">ℒ</ci><ci id="S3.SS3.SSS2.Px2.p3.1.m1.1.1.3a.cmml" xref="S3.SS3.SSS2.Px2.p3.1.m1.1.1.3"><mtext id="S3.SS3.SSS2.Px2.p3.1.m1.1.1.3.cmml" mathsize="70%" xref="S3.SS3.SSS2.Px2.p3.1.m1.1.1.3">dist</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS2.Px2.p3.1.m1.1c">\mathcal{L}_{\text{dist}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.SSS2.Px2.p3.1.m1.1d">caligraphic_L start_POSTSUBSCRIPT dist end_POSTSUBSCRIPT</annotation></semantics></math> for a more compact geometry:</p>
</div>
<div class="ltx_para" id="S3.SS3.SSS2.Px2.p4">
<table class="ltx_equationgroup ltx_eqn_align ltx_eqn_table" id="A1.EGx4">
<tbody id="S3.E7"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_left">(7)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle\mathbf{\theta}_{\text{t}},\mathbf{w}_{\text{target}}=%
\operatorname*{arg\,min}_{\mathbf{\theta},\mathbf{w}}\mathcal{L}_{\text{fit}}" class="ltx_Math" display="inline" id="S3.E7.m1.4"><semantics id="S3.E7.m1.4a"><mrow id="S3.E7.m1.4.4" xref="S3.E7.m1.4.4.cmml"><mrow id="S3.E7.m1.4.4.2.2" xref="S3.E7.m1.4.4.2.3.cmml"><msub id="S3.E7.m1.3.3.1.1.1" xref="S3.E7.m1.3.3.1.1.1.cmml"><mi id="S3.E7.m1.3.3.1.1.1.2" xref="S3.E7.m1.3.3.1.1.1.2.cmml">θ</mi><mtext id="S3.E7.m1.3.3.1.1.1.3" xref="S3.E7.m1.3.3.1.1.1.3a.cmml">t</mtext></msub><mo id="S3.E7.m1.4.4.2.2.3" xref="S3.E7.m1.4.4.2.3.cmml">,</mo><msub id="S3.E7.m1.4.4.2.2.2" xref="S3.E7.m1.4.4.2.2.2.cmml"><mi id="S3.E7.m1.4.4.2.2.2.2" xref="S3.E7.m1.4.4.2.2.2.2.cmml">𝐰</mi><mtext id="S3.E7.m1.4.4.2.2.2.3" xref="S3.E7.m1.4.4.2.2.2.3a.cmml">target</mtext></msub></mrow><mo id="S3.E7.m1.4.4.3" xref="S3.E7.m1.4.4.3.cmml">=</mo><mrow id="S3.E7.m1.4.4.4" xref="S3.E7.m1.4.4.4.cmml"><munder id="S3.E7.m1.4.4.4.1" xref="S3.E7.m1.4.4.4.1.cmml"><mrow id="S3.E7.m1.4.4.4.1.2" xref="S3.E7.m1.4.4.4.1.2.cmml"><mi id="S3.E7.m1.4.4.4.1.2.2" xref="S3.E7.m1.4.4.4.1.2.2.cmml">arg</mi><mo id="S3.E7.m1.4.4.4.1.2.1" lspace="0.170em" xref="S3.E7.m1.4.4.4.1.2.1.cmml">⁢</mo><mi id="S3.E7.m1.4.4.4.1.2.3" xref="S3.E7.m1.4.4.4.1.2.3.cmml">min</mi></mrow><mrow id="S3.E7.m1.2.2.2.4" xref="S3.E7.m1.2.2.2.3.cmml"><mi id="S3.E7.m1.1.1.1.1" xref="S3.E7.m1.1.1.1.1.cmml">θ</mi><mo id="S3.E7.m1.2.2.2.4.1" xref="S3.E7.m1.2.2.2.3.cmml">,</mo><mi id="S3.E7.m1.2.2.2.2" xref="S3.E7.m1.2.2.2.2.cmml">𝐰</mi></mrow></munder><mo id="S3.E7.m1.4.4.4a" xref="S3.E7.m1.4.4.4.cmml">⁡</mo><msub id="S3.E7.m1.4.4.4.2" xref="S3.E7.m1.4.4.4.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E7.m1.4.4.4.2.2" xref="S3.E7.m1.4.4.4.2.2.cmml">ℒ</mi><mtext id="S3.E7.m1.4.4.4.2.3" xref="S3.E7.m1.4.4.4.2.3a.cmml">fit</mtext></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E7.m1.4b"><apply id="S3.E7.m1.4.4.cmml" xref="S3.E7.m1.4.4"><eq id="S3.E7.m1.4.4.3.cmml" xref="S3.E7.m1.4.4.3"></eq><list id="S3.E7.m1.4.4.2.3.cmml" xref="S3.E7.m1.4.4.2.2"><apply id="S3.E7.m1.3.3.1.1.1.cmml" xref="S3.E7.m1.3.3.1.1.1"><csymbol cd="ambiguous" id="S3.E7.m1.3.3.1.1.1.1.cmml" xref="S3.E7.m1.3.3.1.1.1">subscript</csymbol><ci id="S3.E7.m1.3.3.1.1.1.2.cmml" xref="S3.E7.m1.3.3.1.1.1.2">𝜃</ci><ci id="S3.E7.m1.3.3.1.1.1.3a.cmml" xref="S3.E7.m1.3.3.1.1.1.3"><mtext id="S3.E7.m1.3.3.1.1.1.3.cmml" mathsize="70%" xref="S3.E7.m1.3.3.1.1.1.3">t</mtext></ci></apply><apply id="S3.E7.m1.4.4.2.2.2.cmml" xref="S3.E7.m1.4.4.2.2.2"><csymbol cd="ambiguous" id="S3.E7.m1.4.4.2.2.2.1.cmml" xref="S3.E7.m1.4.4.2.2.2">subscript</csymbol><ci id="S3.E7.m1.4.4.2.2.2.2.cmml" xref="S3.E7.m1.4.4.2.2.2.2">𝐰</ci><ci id="S3.E7.m1.4.4.2.2.2.3a.cmml" xref="S3.E7.m1.4.4.2.2.2.3"><mtext id="S3.E7.m1.4.4.2.2.2.3.cmml" mathsize="70%" xref="S3.E7.m1.4.4.2.2.2.3">target</mtext></ci></apply></list><apply id="S3.E7.m1.4.4.4.cmml" xref="S3.E7.m1.4.4.4"><apply id="S3.E7.m1.4.4.4.1.cmml" xref="S3.E7.m1.4.4.4.1"><csymbol cd="ambiguous" id="S3.E7.m1.4.4.4.1.1.cmml" xref="S3.E7.m1.4.4.4.1">subscript</csymbol><apply id="S3.E7.m1.4.4.4.1.2.cmml" xref="S3.E7.m1.4.4.4.1.2"><times id="S3.E7.m1.4.4.4.1.2.1.cmml" xref="S3.E7.m1.4.4.4.1.2.1"></times><ci id="S3.E7.m1.4.4.4.1.2.2.cmml" xref="S3.E7.m1.4.4.4.1.2.2">arg</ci><ci id="S3.E7.m1.4.4.4.1.2.3.cmml" xref="S3.E7.m1.4.4.4.1.2.3">min</ci></apply><list id="S3.E7.m1.2.2.2.3.cmml" xref="S3.E7.m1.2.2.2.4"><ci id="S3.E7.m1.1.1.1.1.cmml" xref="S3.E7.m1.1.1.1.1">𝜃</ci><ci id="S3.E7.m1.2.2.2.2.cmml" xref="S3.E7.m1.2.2.2.2">𝐰</ci></list></apply><apply id="S3.E7.m1.4.4.4.2.cmml" xref="S3.E7.m1.4.4.4.2"><csymbol cd="ambiguous" id="S3.E7.m1.4.4.4.2.1.cmml" xref="S3.E7.m1.4.4.4.2">subscript</csymbol><ci id="S3.E7.m1.4.4.4.2.2.cmml" xref="S3.E7.m1.4.4.4.2.2">ℒ</ci><ci id="S3.E7.m1.4.4.4.2.3a.cmml" xref="S3.E7.m1.4.4.4.2.3"><mtext id="S3.E7.m1.4.4.4.2.3.cmml" mathsize="70%" xref="S3.E7.m1.4.4.4.2.3">fit</mtext></ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E7.m1.4c">\displaystyle\mathbf{\theta}_{\text{t}},\mathbf{w}_{\text{target}}=%
\operatorname*{arg\,min}_{\mathbf{\theta},\mathbf{w}}\mathcal{L}_{\text{fit}}</annotation><annotation encoding="application/x-llamapun" id="S3.E7.m1.4d">italic_θ start_POSTSUBSCRIPT t end_POSTSUBSCRIPT , bold_w start_POSTSUBSCRIPT target end_POSTSUBSCRIPT = start_OPERATOR roman_arg roman_min end_OPERATOR start_POSTSUBSCRIPT italic_θ , bold_w end_POSTSUBSCRIPT caligraphic_L start_POSTSUBSCRIPT fit end_POSTSUBSCRIPT</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle=\mathcal{L}_{\text{recon}}+\lambda_{\text{prop}}\mathcal{L}_{%
\text{prop}}" class="ltx_Math" display="inline" id="S3.E7.m2.1"><semantics id="S3.E7.m2.1a"><mrow id="S3.E7.m2.1.1" xref="S3.E7.m2.1.1.cmml"><mi id="S3.E7.m2.1.1.2" xref="S3.E7.m2.1.1.2.cmml"></mi><mo id="S3.E7.m2.1.1.1" xref="S3.E7.m2.1.1.1.cmml">=</mo><mrow id="S3.E7.m2.1.1.3" xref="S3.E7.m2.1.1.3.cmml"><msub id="S3.E7.m2.1.1.3.2" xref="S3.E7.m2.1.1.3.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E7.m2.1.1.3.2.2" xref="S3.E7.m2.1.1.3.2.2.cmml">ℒ</mi><mtext id="S3.E7.m2.1.1.3.2.3" xref="S3.E7.m2.1.1.3.2.3a.cmml">recon</mtext></msub><mo id="S3.E7.m2.1.1.3.1" xref="S3.E7.m2.1.1.3.1.cmml">+</mo><mrow id="S3.E7.m2.1.1.3.3" xref="S3.E7.m2.1.1.3.3.cmml"><msub id="S3.E7.m2.1.1.3.3.2" xref="S3.E7.m2.1.1.3.3.2.cmml"><mi id="S3.E7.m2.1.1.3.3.2.2" xref="S3.E7.m2.1.1.3.3.2.2.cmml">λ</mi><mtext id="S3.E7.m2.1.1.3.3.2.3" xref="S3.E7.m2.1.1.3.3.2.3a.cmml">prop</mtext></msub><mo id="S3.E7.m2.1.1.3.3.1" xref="S3.E7.m2.1.1.3.3.1.cmml">⁢</mo><msub id="S3.E7.m2.1.1.3.3.3" xref="S3.E7.m2.1.1.3.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E7.m2.1.1.3.3.3.2" xref="S3.E7.m2.1.1.3.3.3.2.cmml">ℒ</mi><mtext id="S3.E7.m2.1.1.3.3.3.3" xref="S3.E7.m2.1.1.3.3.3.3a.cmml">prop</mtext></msub></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E7.m2.1b"><apply id="S3.E7.m2.1.1.cmml" xref="S3.E7.m2.1.1"><eq id="S3.E7.m2.1.1.1.cmml" xref="S3.E7.m2.1.1.1"></eq><csymbol cd="latexml" id="S3.E7.m2.1.1.2.cmml" xref="S3.E7.m2.1.1.2">absent</csymbol><apply id="S3.E7.m2.1.1.3.cmml" xref="S3.E7.m2.1.1.3"><plus id="S3.E7.m2.1.1.3.1.cmml" xref="S3.E7.m2.1.1.3.1"></plus><apply id="S3.E7.m2.1.1.3.2.cmml" xref="S3.E7.m2.1.1.3.2"><csymbol cd="ambiguous" id="S3.E7.m2.1.1.3.2.1.cmml" xref="S3.E7.m2.1.1.3.2">subscript</csymbol><ci id="S3.E7.m2.1.1.3.2.2.cmml" xref="S3.E7.m2.1.1.3.2.2">ℒ</ci><ci id="S3.E7.m2.1.1.3.2.3a.cmml" xref="S3.E7.m2.1.1.3.2.3"><mtext id="S3.E7.m2.1.1.3.2.3.cmml" mathsize="70%" xref="S3.E7.m2.1.1.3.2.3">recon</mtext></ci></apply><apply id="S3.E7.m2.1.1.3.3.cmml" xref="S3.E7.m2.1.1.3.3"><times id="S3.E7.m2.1.1.3.3.1.cmml" xref="S3.E7.m2.1.1.3.3.1"></times><apply id="S3.E7.m2.1.1.3.3.2.cmml" xref="S3.E7.m2.1.1.3.3.2"><csymbol cd="ambiguous" id="S3.E7.m2.1.1.3.3.2.1.cmml" xref="S3.E7.m2.1.1.3.3.2">subscript</csymbol><ci id="S3.E7.m2.1.1.3.3.2.2.cmml" xref="S3.E7.m2.1.1.3.3.2.2">𝜆</ci><ci id="S3.E7.m2.1.1.3.3.2.3a.cmml" xref="S3.E7.m2.1.1.3.3.2.3"><mtext id="S3.E7.m2.1.1.3.3.2.3.cmml" mathsize="70%" xref="S3.E7.m2.1.1.3.3.2.3">prop</mtext></ci></apply><apply id="S3.E7.m2.1.1.3.3.3.cmml" xref="S3.E7.m2.1.1.3.3.3"><csymbol cd="ambiguous" id="S3.E7.m2.1.1.3.3.3.1.cmml" xref="S3.E7.m2.1.1.3.3.3">subscript</csymbol><ci id="S3.E7.m2.1.1.3.3.3.2.cmml" xref="S3.E7.m2.1.1.3.3.3.2">ℒ</ci><ci id="S3.E7.m2.1.1.3.3.3.3a.cmml" xref="S3.E7.m2.1.1.3.3.3.3"><mtext id="S3.E7.m2.1.1.3.3.3.3.cmml" mathsize="70%" xref="S3.E7.m2.1.1.3.3.3.3">prop</mtext></ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E7.m2.1c">\displaystyle=\mathcal{L}_{\text{recon}}+\lambda_{\text{prop}}\mathcal{L}_{%
\text{prop}}</annotation><annotation encoding="application/x-llamapun" id="S3.E7.m2.1d">= caligraphic_L start_POSTSUBSCRIPT recon end_POSTSUBSCRIPT + italic_λ start_POSTSUBSCRIPT prop end_POSTSUBSCRIPT caligraphic_L start_POSTSUBSCRIPT prop end_POSTSUBSCRIPT</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
<tbody id="S3.Ex1"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_eqn_cell"></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle+\lambda_{\text{normal}}\mathcal{L}_{\text{normal}}+\lambda_{d}%
\mathcal{L}_{d}+\lambda_{\text{dist}}\mathcal{L}_{\text{dist}}" class="ltx_Math" display="inline" id="S3.Ex1.m1.1"><semantics id="S3.Ex1.m1.1a"><mrow id="S3.Ex1.m1.1.1" xref="S3.Ex1.m1.1.1.cmml"><mrow id="S3.Ex1.m1.1.1.2" xref="S3.Ex1.m1.1.1.2.cmml"><mo id="S3.Ex1.m1.1.1.2a" xref="S3.Ex1.m1.1.1.2.cmml">+</mo><mrow id="S3.Ex1.m1.1.1.2.2" xref="S3.Ex1.m1.1.1.2.2.cmml"><msub id="S3.Ex1.m1.1.1.2.2.2" xref="S3.Ex1.m1.1.1.2.2.2.cmml"><mi id="S3.Ex1.m1.1.1.2.2.2.2" xref="S3.Ex1.m1.1.1.2.2.2.2.cmml">λ</mi><mtext id="S3.Ex1.m1.1.1.2.2.2.3" xref="S3.Ex1.m1.1.1.2.2.2.3a.cmml">normal</mtext></msub><mo id="S3.Ex1.m1.1.1.2.2.1" xref="S3.Ex1.m1.1.1.2.2.1.cmml">⁢</mo><msub id="S3.Ex1.m1.1.1.2.2.3" xref="S3.Ex1.m1.1.1.2.2.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.Ex1.m1.1.1.2.2.3.2" xref="S3.Ex1.m1.1.1.2.2.3.2.cmml">ℒ</mi><mtext id="S3.Ex1.m1.1.1.2.2.3.3" xref="S3.Ex1.m1.1.1.2.2.3.3a.cmml">normal</mtext></msub></mrow></mrow><mo id="S3.Ex1.m1.1.1.1" xref="S3.Ex1.m1.1.1.1.cmml">+</mo><mrow id="S3.Ex1.m1.1.1.3" xref="S3.Ex1.m1.1.1.3.cmml"><msub id="S3.Ex1.m1.1.1.3.2" xref="S3.Ex1.m1.1.1.3.2.cmml"><mi id="S3.Ex1.m1.1.1.3.2.2" xref="S3.Ex1.m1.1.1.3.2.2.cmml">λ</mi><mi id="S3.Ex1.m1.1.1.3.2.3" xref="S3.Ex1.m1.1.1.3.2.3.cmml">d</mi></msub><mo id="S3.Ex1.m1.1.1.3.1" xref="S3.Ex1.m1.1.1.3.1.cmml">⁢</mo><msub id="S3.Ex1.m1.1.1.3.3" xref="S3.Ex1.m1.1.1.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.Ex1.m1.1.1.3.3.2" xref="S3.Ex1.m1.1.1.3.3.2.cmml">ℒ</mi><mi id="S3.Ex1.m1.1.1.3.3.3" xref="S3.Ex1.m1.1.1.3.3.3.cmml">d</mi></msub></mrow><mo id="S3.Ex1.m1.1.1.1a" xref="S3.Ex1.m1.1.1.1.cmml">+</mo><mrow id="S3.Ex1.m1.1.1.4" xref="S3.Ex1.m1.1.1.4.cmml"><msub id="S3.Ex1.m1.1.1.4.2" xref="S3.Ex1.m1.1.1.4.2.cmml"><mi id="S3.Ex1.m1.1.1.4.2.2" xref="S3.Ex1.m1.1.1.4.2.2.cmml">λ</mi><mtext id="S3.Ex1.m1.1.1.4.2.3" xref="S3.Ex1.m1.1.1.4.2.3a.cmml">dist</mtext></msub><mo id="S3.Ex1.m1.1.1.4.1" xref="S3.Ex1.m1.1.1.4.1.cmml">⁢</mo><msub id="S3.Ex1.m1.1.1.4.3" xref="S3.Ex1.m1.1.1.4.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.Ex1.m1.1.1.4.3.2" xref="S3.Ex1.m1.1.1.4.3.2.cmml">ℒ</mi><mtext id="S3.Ex1.m1.1.1.4.3.3" xref="S3.Ex1.m1.1.1.4.3.3a.cmml">dist</mtext></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.Ex1.m1.1b"><apply id="S3.Ex1.m1.1.1.cmml" xref="S3.Ex1.m1.1.1"><plus id="S3.Ex1.m1.1.1.1.cmml" xref="S3.Ex1.m1.1.1.1"></plus><apply id="S3.Ex1.m1.1.1.2.cmml" xref="S3.Ex1.m1.1.1.2"><plus id="S3.Ex1.m1.1.1.2.1.cmml" xref="S3.Ex1.m1.1.1.2"></plus><apply id="S3.Ex1.m1.1.1.2.2.cmml" xref="S3.Ex1.m1.1.1.2.2"><times id="S3.Ex1.m1.1.1.2.2.1.cmml" xref="S3.Ex1.m1.1.1.2.2.1"></times><apply id="S3.Ex1.m1.1.1.2.2.2.cmml" xref="S3.Ex1.m1.1.1.2.2.2"><csymbol cd="ambiguous" id="S3.Ex1.m1.1.1.2.2.2.1.cmml" xref="S3.Ex1.m1.1.1.2.2.2">subscript</csymbol><ci id="S3.Ex1.m1.1.1.2.2.2.2.cmml" xref="S3.Ex1.m1.1.1.2.2.2.2">𝜆</ci><ci id="S3.Ex1.m1.1.1.2.2.2.3a.cmml" xref="S3.Ex1.m1.1.1.2.2.2.3"><mtext id="S3.Ex1.m1.1.1.2.2.2.3.cmml" mathsize="70%" xref="S3.Ex1.m1.1.1.2.2.2.3">normal</mtext></ci></apply><apply id="S3.Ex1.m1.1.1.2.2.3.cmml" xref="S3.Ex1.m1.1.1.2.2.3"><csymbol cd="ambiguous" id="S3.Ex1.m1.1.1.2.2.3.1.cmml" xref="S3.Ex1.m1.1.1.2.2.3">subscript</csymbol><ci id="S3.Ex1.m1.1.1.2.2.3.2.cmml" xref="S3.Ex1.m1.1.1.2.2.3.2">ℒ</ci><ci id="S3.Ex1.m1.1.1.2.2.3.3a.cmml" xref="S3.Ex1.m1.1.1.2.2.3.3"><mtext id="S3.Ex1.m1.1.1.2.2.3.3.cmml" mathsize="70%" xref="S3.Ex1.m1.1.1.2.2.3.3">normal</mtext></ci></apply></apply></apply><apply id="S3.Ex1.m1.1.1.3.cmml" xref="S3.Ex1.m1.1.1.3"><times id="S3.Ex1.m1.1.1.3.1.cmml" xref="S3.Ex1.m1.1.1.3.1"></times><apply id="S3.Ex1.m1.1.1.3.2.cmml" xref="S3.Ex1.m1.1.1.3.2"><csymbol cd="ambiguous" id="S3.Ex1.m1.1.1.3.2.1.cmml" xref="S3.Ex1.m1.1.1.3.2">subscript</csymbol><ci id="S3.Ex1.m1.1.1.3.2.2.cmml" xref="S3.Ex1.m1.1.1.3.2.2">𝜆</ci><ci id="S3.Ex1.m1.1.1.3.2.3.cmml" xref="S3.Ex1.m1.1.1.3.2.3">𝑑</ci></apply><apply id="S3.Ex1.m1.1.1.3.3.cmml" xref="S3.Ex1.m1.1.1.3.3"><csymbol cd="ambiguous" id="S3.Ex1.m1.1.1.3.3.1.cmml" xref="S3.Ex1.m1.1.1.3.3">subscript</csymbol><ci id="S3.Ex1.m1.1.1.3.3.2.cmml" xref="S3.Ex1.m1.1.1.3.3.2">ℒ</ci><ci id="S3.Ex1.m1.1.1.3.3.3.cmml" xref="S3.Ex1.m1.1.1.3.3.3">𝑑</ci></apply></apply><apply id="S3.Ex1.m1.1.1.4.cmml" xref="S3.Ex1.m1.1.1.4"><times id="S3.Ex1.m1.1.1.4.1.cmml" xref="S3.Ex1.m1.1.1.4.1"></times><apply id="S3.Ex1.m1.1.1.4.2.cmml" xref="S3.Ex1.m1.1.1.4.2"><csymbol cd="ambiguous" id="S3.Ex1.m1.1.1.4.2.1.cmml" xref="S3.Ex1.m1.1.1.4.2">subscript</csymbol><ci id="S3.Ex1.m1.1.1.4.2.2.cmml" xref="S3.Ex1.m1.1.1.4.2.2">𝜆</ci><ci id="S3.Ex1.m1.1.1.4.2.3a.cmml" xref="S3.Ex1.m1.1.1.4.2.3"><mtext id="S3.Ex1.m1.1.1.4.2.3.cmml" mathsize="70%" xref="S3.Ex1.m1.1.1.4.2.3">dist</mtext></ci></apply><apply id="S3.Ex1.m1.1.1.4.3.cmml" xref="S3.Ex1.m1.1.1.4.3"><csymbol cd="ambiguous" id="S3.Ex1.m1.1.1.4.3.1.cmml" xref="S3.Ex1.m1.1.1.4.3">subscript</csymbol><ci id="S3.Ex1.m1.1.1.4.3.2.cmml" xref="S3.Ex1.m1.1.1.4.3.2">ℒ</ci><ci id="S3.Ex1.m1.1.1.4.3.3a.cmml" xref="S3.Ex1.m1.1.1.4.3.3"><mtext id="S3.Ex1.m1.1.1.4.3.3.cmml" mathsize="70%" xref="S3.Ex1.m1.1.1.4.3.3">dist</mtext></ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.Ex1.m1.1c">\displaystyle+\lambda_{\text{normal}}\mathcal{L}_{\text{normal}}+\lambda_{d}%
\mathcal{L}_{d}+\lambda_{\text{dist}}\mathcal{L}_{\text{dist}}</annotation><annotation encoding="application/x-llamapun" id="S3.Ex1.m1.1d">+ italic_λ start_POSTSUBSCRIPT normal end_POSTSUBSCRIPT caligraphic_L start_POSTSUBSCRIPT normal end_POSTSUBSCRIPT + italic_λ start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT caligraphic_L start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT + italic_λ start_POSTSUBSCRIPT dist end_POSTSUBSCRIPT caligraphic_L start_POSTSUBSCRIPT dist end_POSTSUBSCRIPT</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS3.SSS2.Px2.p4.2">where <math alttext="\mathcal{L}_{\text{normal}}" class="ltx_Math" display="inline" id="S3.SS3.SSS2.Px2.p4.1.m1.1"><semantics id="S3.SS3.SSS2.Px2.p4.1.m1.1a"><msub id="S3.SS3.SSS2.Px2.p4.1.m1.1.1" xref="S3.SS3.SSS2.Px2.p4.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.SSS2.Px2.p4.1.m1.1.1.2" xref="S3.SS3.SSS2.Px2.p4.1.m1.1.1.2.cmml">ℒ</mi><mtext id="S3.SS3.SSS2.Px2.p4.1.m1.1.1.3" xref="S3.SS3.SSS2.Px2.p4.1.m1.1.1.3a.cmml">normal</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS2.Px2.p4.1.m1.1b"><apply id="S3.SS3.SSS2.Px2.p4.1.m1.1.1.cmml" xref="S3.SS3.SSS2.Px2.p4.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS2.Px2.p4.1.m1.1.1.1.cmml" xref="S3.SS3.SSS2.Px2.p4.1.m1.1.1">subscript</csymbol><ci id="S3.SS3.SSS2.Px2.p4.1.m1.1.1.2.cmml" xref="S3.SS3.SSS2.Px2.p4.1.m1.1.1.2">ℒ</ci><ci id="S3.SS3.SSS2.Px2.p4.1.m1.1.1.3a.cmml" xref="S3.SS3.SSS2.Px2.p4.1.m1.1.1.3"><mtext id="S3.SS3.SSS2.Px2.p4.1.m1.1.1.3.cmml" mathsize="70%" xref="S3.SS3.SSS2.Px2.p4.1.m1.1.1.3">normal</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS2.Px2.p4.1.m1.1c">\mathcal{L}_{\text{normal}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.SSS2.Px2.p4.1.m1.1d">caligraphic_L start_POSTSUBSCRIPT normal end_POSTSUBSCRIPT</annotation></semantics></math> and <math alttext="\mathcal{L}_{d}" class="ltx_Math" display="inline" id="S3.SS3.SSS2.Px2.p4.2.m2.1"><semantics id="S3.SS3.SSS2.Px2.p4.2.m2.1a"><msub id="S3.SS3.SSS2.Px2.p4.2.m2.1.1" xref="S3.SS3.SSS2.Px2.p4.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.SSS2.Px2.p4.2.m2.1.1.2" xref="S3.SS3.SSS2.Px2.p4.2.m2.1.1.2.cmml">ℒ</mi><mi id="S3.SS3.SSS2.Px2.p4.2.m2.1.1.3" xref="S3.SS3.SSS2.Px2.p4.2.m2.1.1.3.cmml">d</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS2.Px2.p4.2.m2.1b"><apply id="S3.SS3.SSS2.Px2.p4.2.m2.1.1.cmml" xref="S3.SS3.SSS2.Px2.p4.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS2.Px2.p4.2.m2.1.1.1.cmml" xref="S3.SS3.SSS2.Px2.p4.2.m2.1.1">subscript</csymbol><ci id="S3.SS3.SSS2.Px2.p4.2.m2.1.1.2.cmml" xref="S3.SS3.SSS2.Px2.p4.2.m2.1.1.2">ℒ</ci><ci id="S3.SS3.SSS2.Px2.p4.2.m2.1.1.3.cmml" xref="S3.SS3.SSS2.Px2.p4.2.m2.1.1.3">𝑑</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS2.Px2.p4.2.m2.1c">\mathcal{L}_{d}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.SSS2.Px2.p4.2.m2.1d">caligraphic_L start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT</annotation></semantics></math> are the regularizers on predicted normals and view weights from Preface. We list and explain all loss terms in more detail in Sec. 2 of the supp. PDF.</p>
</div>
</section>
<section class="ltx_paragraph" id="S3.SS3.SSS2.Px3">
<h5 class="ltx_title ltx_title_paragraph">Inference In-the-wild</h5>
<div class="ltx_para" id="S3.SS3.SSS2.Px3.p1">
<p class="ltx_p" id="S3.SS3.SSS2.Px3.p1.2">For in-the-wild (ITW) images, we capture three images sequentially with a hand-held camera. The captured face might inhibit small movements during the capture, called micromotions.
To mitigate these micromotions, we fine-tune with individual expression code for every input image. The 3DMM fitting yields a per-image expression code <math alttext="\boldsymbol{\hat{\psi}}_{i}" class="ltx_Math" display="inline" id="S3.SS3.SSS2.Px3.p1.1.m1.1"><semantics id="S3.SS3.SSS2.Px3.p1.1.m1.1a"><msub id="S3.SS3.SSS2.Px3.p1.1.m1.1.1" xref="S3.SS3.SSS2.Px3.p1.1.m1.1.1.cmml"><mover accent="true" id="S3.SS3.SSS2.Px3.p1.1.m1.1.1.2" xref="S3.SS3.SSS2.Px3.p1.1.m1.1.1.2.cmml"><mi id="S3.SS3.SSS2.Px3.p1.1.m1.1.1.2.2" xref="S3.SS3.SSS2.Px3.p1.1.m1.1.1.2.2.cmml">𝝍</mi><mo class="ltx_mathvariant_bold" id="S3.SS3.SSS2.Px3.p1.1.m1.1.1.2.1" mathvariant="bold" xref="S3.SS3.SSS2.Px3.p1.1.m1.1.1.2.1.cmml">^</mo></mover><mi id="S3.SS3.SSS2.Px3.p1.1.m1.1.1.3" xref="S3.SS3.SSS2.Px3.p1.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS2.Px3.p1.1.m1.1b"><apply id="S3.SS3.SSS2.Px3.p1.1.m1.1.1.cmml" xref="S3.SS3.SSS2.Px3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS2.Px3.p1.1.m1.1.1.1.cmml" xref="S3.SS3.SSS2.Px3.p1.1.m1.1.1">subscript</csymbol><apply id="S3.SS3.SSS2.Px3.p1.1.m1.1.1.2.cmml" xref="S3.SS3.SSS2.Px3.p1.1.m1.1.1.2"><ci id="S3.SS3.SSS2.Px3.p1.1.m1.1.1.2.1.cmml" xref="S3.SS3.SSS2.Px3.p1.1.m1.1.1.2.1">bold-^</ci><ci id="S3.SS3.SSS2.Px3.p1.1.m1.1.1.2.2.cmml" xref="S3.SS3.SSS2.Px3.p1.1.m1.1.1.2.2">𝝍</ci></apply><ci id="S3.SS3.SSS2.Px3.p1.1.m1.1.1.3.cmml" xref="S3.SS3.SSS2.Px3.p1.1.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS2.Px3.p1.1.m1.1c">\boldsymbol{\hat{\psi}}_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.SSS2.Px3.p1.1.m1.1d">overbold_^ start_ARG bold_italic_ψ end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>.
During inference, we interpolate these expression codes based on their distance to the target camera. The weight is computed as the inverse squared distance between the target and all training cameras. The interpolated expression code <math alttext="\boldsymbol{\tilde{\psi}}_{t}" class="ltx_Math" display="inline" id="S3.SS3.SSS2.Px3.p1.2.m2.1"><semantics id="S3.SS3.SSS2.Px3.p1.2.m2.1a"><msub id="S3.SS3.SSS2.Px3.p1.2.m2.1.1" xref="S3.SS3.SSS2.Px3.p1.2.m2.1.1.cmml"><mover accent="true" id="S3.SS3.SSS2.Px3.p1.2.m2.1.1.2" xref="S3.SS3.SSS2.Px3.p1.2.m2.1.1.2.cmml"><mi id="S3.SS3.SSS2.Px3.p1.2.m2.1.1.2.2" xref="S3.SS3.SSS2.Px3.p1.2.m2.1.1.2.2.cmml">𝝍</mi><mo class="ltx_mathvariant_bold" id="S3.SS3.SSS2.Px3.p1.2.m2.1.1.2.1" mathvariant="bold" xref="S3.SS3.SSS2.Px3.p1.2.m2.1.1.2.1.cmml">~</mo></mover><mi id="S3.SS3.SSS2.Px3.p1.2.m2.1.1.3" xref="S3.SS3.SSS2.Px3.p1.2.m2.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS2.Px3.p1.2.m2.1b"><apply id="S3.SS3.SSS2.Px3.p1.2.m2.1.1.cmml" xref="S3.SS3.SSS2.Px3.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS2.Px3.p1.2.m2.1.1.1.cmml" xref="S3.SS3.SSS2.Px3.p1.2.m2.1.1">subscript</csymbol><apply id="S3.SS3.SSS2.Px3.p1.2.m2.1.1.2.cmml" xref="S3.SS3.SSS2.Px3.p1.2.m2.1.1.2"><ci id="S3.SS3.SSS2.Px3.p1.2.m2.1.1.2.1.cmml" xref="S3.SS3.SSS2.Px3.p1.2.m2.1.1.2.1">bold-~</ci><ci id="S3.SS3.SSS2.Px3.p1.2.m2.1.1.2.2.cmml" xref="S3.SS3.SSS2.Px3.p1.2.m2.1.1.2.2">𝝍</ci></apply><ci id="S3.SS3.SSS2.Px3.p1.2.m2.1.1.3.cmml" xref="S3.SS3.SSS2.Px3.p1.2.m2.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS2.Px3.p1.2.m2.1c">\boldsymbol{\tilde{\psi}}_{t}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.SSS2.Px3.p1.2.m2.1d">overbold_~ start_ARG bold_italic_ψ end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> for a target camera is computed as</p>
<table class="ltx_equationgroup ltx_eqn_align ltx_eqn_table" id="A1.EGx5">
<tbody id="S3.E8"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_left">(8)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle\boldsymbol{\tilde{\psi}}_{t}" class="ltx_Math" display="inline" id="S3.E8.m1.1"><semantics id="S3.E8.m1.1a"><msub id="S3.E8.m1.1.1" xref="S3.E8.m1.1.1.cmml"><mover accent="true" id="S3.E8.m1.1.1.2" xref="S3.E8.m1.1.1.2.cmml"><mi id="S3.E8.m1.1.1.2.2" xref="S3.E8.m1.1.1.2.2.cmml">𝝍</mi><mo class="ltx_mathvariant_bold" id="S3.E8.m1.1.1.2.1" mathvariant="bold" xref="S3.E8.m1.1.1.2.1.cmml">~</mo></mover><mi id="S3.E8.m1.1.1.3" xref="S3.E8.m1.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.E8.m1.1b"><apply id="S3.E8.m1.1.1.cmml" xref="S3.E8.m1.1.1"><csymbol cd="ambiguous" id="S3.E8.m1.1.1.1.cmml" xref="S3.E8.m1.1.1">subscript</csymbol><apply id="S3.E8.m1.1.1.2.cmml" xref="S3.E8.m1.1.1.2"><ci id="S3.E8.m1.1.1.2.1.cmml" xref="S3.E8.m1.1.1.2.1">bold-~</ci><ci id="S3.E8.m1.1.1.2.2.cmml" xref="S3.E8.m1.1.1.2.2">𝝍</ci></apply><ci id="S3.E8.m1.1.1.3.cmml" xref="S3.E8.m1.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E8.m1.1c">\displaystyle\boldsymbol{\tilde{\psi}}_{t}</annotation><annotation encoding="application/x-llamapun" id="S3.E8.m1.1d">overbold_~ start_ARG bold_italic_ψ end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle=\sum_{i}\underbrace{\frac{Z}{\epsilon+||\boldsymbol{\tilde{l}}_{%
t}-\boldsymbol{\hat{l}}_{i}||^{2}_{2}}}_{\text{weight}}\underbrace{\boldsymbol%
{\hat{\psi}}_{i}}_{\text{training expression}}," class="ltx_Math" display="inline" id="S3.E8.m2.2"><semantics id="S3.E8.m2.2a"><mrow id="S3.E8.m2.2.2.1" xref="S3.E8.m2.2.2.1.1.cmml"><mrow id="S3.E8.m2.2.2.1.1" xref="S3.E8.m2.2.2.1.1.cmml"><mi id="S3.E8.m2.2.2.1.1.2" xref="S3.E8.m2.2.2.1.1.2.cmml"></mi><mo id="S3.E8.m2.2.2.1.1.1" xref="S3.E8.m2.2.2.1.1.1.cmml">=</mo><mrow id="S3.E8.m2.2.2.1.1.3" xref="S3.E8.m2.2.2.1.1.3.cmml"><mstyle displaystyle="true" id="S3.E8.m2.2.2.1.1.3.1" xref="S3.E8.m2.2.2.1.1.3.1.cmml"><munder id="S3.E8.m2.2.2.1.1.3.1a" xref="S3.E8.m2.2.2.1.1.3.1.cmml"><mo id="S3.E8.m2.2.2.1.1.3.1.2" movablelimits="false" xref="S3.E8.m2.2.2.1.1.3.1.2.cmml">∑</mo><mi id="S3.E8.m2.2.2.1.1.3.1.3" xref="S3.E8.m2.2.2.1.1.3.1.3.cmml">i</mi></munder></mstyle><mrow id="S3.E8.m2.2.2.1.1.3.2" xref="S3.E8.m2.2.2.1.1.3.2.cmml"><munder id="S3.E8.m2.2.2.1.1.3.2.2" xref="S3.E8.m2.2.2.1.1.3.2.2.cmml"><munder accentunder="true" id="S3.E8.m2.1.1" xref="S3.E8.m2.1.1.cmml"><mstyle displaystyle="true" id="S3.E8.m2.1.1.1" xref="S3.E8.m2.1.1.1.cmml"><mfrac id="S3.E8.m2.1.1.1a" xref="S3.E8.m2.1.1.1.cmml"><mi id="S3.E8.m2.1.1.1.3" xref="S3.E8.m2.1.1.1.3.cmml">Z</mi><mrow id="S3.E8.m2.1.1.1.1.1" xref="S3.E8.m2.1.1.1.1.1.cmml"><mi id="S3.E8.m2.1.1.1.1.1.3" xref="S3.E8.m2.1.1.1.1.1.3.cmml">ϵ</mi><mo id="S3.E8.m2.1.1.1.1.1.2" xref="S3.E8.m2.1.1.1.1.1.2.cmml">+</mo><msubsup id="S3.E8.m2.1.1.1.1.1.1" xref="S3.E8.m2.1.1.1.1.1.1.cmml"><mrow id="S3.E8.m2.1.1.1.1.1.1.1.1.1" xref="S3.E8.m2.1.1.1.1.1.1.1.1.2.cmml"><mo id="S3.E8.m2.1.1.1.1.1.1.1.1.1.2" stretchy="false" xref="S3.E8.m2.1.1.1.1.1.1.1.1.2.1.cmml">‖</mo><mrow id="S3.E8.m2.1.1.1.1.1.1.1.1.1.1" xref="S3.E8.m2.1.1.1.1.1.1.1.1.1.1.cmml"><msub id="S3.E8.m2.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E8.m2.1.1.1.1.1.1.1.1.1.1.2.cmml"><mover accent="true" id="S3.E8.m2.1.1.1.1.1.1.1.1.1.1.2.2" xref="S3.E8.m2.1.1.1.1.1.1.1.1.1.1.2.2.cmml"><mi id="S3.E8.m2.1.1.1.1.1.1.1.1.1.1.2.2.2" xref="S3.E8.m2.1.1.1.1.1.1.1.1.1.1.2.2.2.cmml">𝒍</mi><mo class="ltx_mathvariant_bold" id="S3.E8.m2.1.1.1.1.1.1.1.1.1.1.2.2.1" mathvariant="bold" xref="S3.E8.m2.1.1.1.1.1.1.1.1.1.1.2.2.1.cmml">~</mo></mover><mi id="S3.E8.m2.1.1.1.1.1.1.1.1.1.1.2.3" xref="S3.E8.m2.1.1.1.1.1.1.1.1.1.1.2.3.cmml">t</mi></msub><mo id="S3.E8.m2.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E8.m2.1.1.1.1.1.1.1.1.1.1.1.cmml">−</mo><msub id="S3.E8.m2.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E8.m2.1.1.1.1.1.1.1.1.1.1.3.cmml"><mover accent="true" id="S3.E8.m2.1.1.1.1.1.1.1.1.1.1.3.2" xref="S3.E8.m2.1.1.1.1.1.1.1.1.1.1.3.2.cmml"><mi id="S3.E8.m2.1.1.1.1.1.1.1.1.1.1.3.2.2" xref="S3.E8.m2.1.1.1.1.1.1.1.1.1.1.3.2.2.cmml">𝒍</mi><mo class="ltx_mathvariant_bold" id="S3.E8.m2.1.1.1.1.1.1.1.1.1.1.3.2.1" mathvariant="bold" xref="S3.E8.m2.1.1.1.1.1.1.1.1.1.1.3.2.1.cmml">^</mo></mover><mi id="S3.E8.m2.1.1.1.1.1.1.1.1.1.1.3.3" xref="S3.E8.m2.1.1.1.1.1.1.1.1.1.1.3.3.cmml">i</mi></msub></mrow><mo id="S3.E8.m2.1.1.1.1.1.1.1.1.1.3" stretchy="false" xref="S3.E8.m2.1.1.1.1.1.1.1.1.2.1.cmml">‖</mo></mrow><mn id="S3.E8.m2.1.1.1.1.1.1.3" xref="S3.E8.m2.1.1.1.1.1.1.3.cmml">2</mn><mn id="S3.E8.m2.1.1.1.1.1.1.1.3" xref="S3.E8.m2.1.1.1.1.1.1.1.3.cmml">2</mn></msubsup></mrow></mfrac></mstyle><mo id="S3.E8.m2.1.1.2" xref="S3.E8.m2.1.1.2.cmml">⏟</mo></munder><mtext id="S3.E8.m2.2.2.1.1.3.2.2.2" xref="S3.E8.m2.2.2.1.1.3.2.2.2a.cmml">weight</mtext></munder><mo id="S3.E8.m2.2.2.1.1.3.2.1" xref="S3.E8.m2.2.2.1.1.3.2.1.cmml">⁢</mo><munder id="S3.E8.m2.2.2.1.1.3.2.3" xref="S3.E8.m2.2.2.1.1.3.2.3.cmml"><munder accentunder="true" id="S3.E8.m2.2.2.1.1.3.2.3.2" xref="S3.E8.m2.2.2.1.1.3.2.3.2.cmml"><msub id="S3.E8.m2.2.2.1.1.3.2.3.2.2" xref="S3.E8.m2.2.2.1.1.3.2.3.2.2.cmml"><mover accent="true" id="S3.E8.m2.2.2.1.1.3.2.3.2.2.2" xref="S3.E8.m2.2.2.1.1.3.2.3.2.2.2.cmml"><mi id="S3.E8.m2.2.2.1.1.3.2.3.2.2.2.2" xref="S3.E8.m2.2.2.1.1.3.2.3.2.2.2.2.cmml">𝝍</mi><mo class="ltx_mathvariant_bold" id="S3.E8.m2.2.2.1.1.3.2.3.2.2.2.1" mathvariant="bold" xref="S3.E8.m2.2.2.1.1.3.2.3.2.2.2.1.cmml">^</mo></mover><mi id="S3.E8.m2.2.2.1.1.3.2.3.2.2.3" xref="S3.E8.m2.2.2.1.1.3.2.3.2.2.3.cmml">i</mi></msub><mo id="S3.E8.m2.2.2.1.1.3.2.3.2.1" xref="S3.E8.m2.2.2.1.1.3.2.3.2.1.cmml">⏟</mo></munder><mtext id="S3.E8.m2.2.2.1.1.3.2.3.3" xref="S3.E8.m2.2.2.1.1.3.2.3.3a.cmml">training expression</mtext></munder></mrow></mrow></mrow><mo id="S3.E8.m2.2.2.1.2" xref="S3.E8.m2.2.2.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E8.m2.2b"><apply id="S3.E8.m2.2.2.1.1.cmml" xref="S3.E8.m2.2.2.1"><eq id="S3.E8.m2.2.2.1.1.1.cmml" xref="S3.E8.m2.2.2.1.1.1"></eq><csymbol cd="latexml" id="S3.E8.m2.2.2.1.1.2.cmml" xref="S3.E8.m2.2.2.1.1.2">absent</csymbol><apply id="S3.E8.m2.2.2.1.1.3.cmml" xref="S3.E8.m2.2.2.1.1.3"><apply id="S3.E8.m2.2.2.1.1.3.1.cmml" xref="S3.E8.m2.2.2.1.1.3.1"><csymbol cd="ambiguous" id="S3.E8.m2.2.2.1.1.3.1.1.cmml" xref="S3.E8.m2.2.2.1.1.3.1">subscript</csymbol><sum id="S3.E8.m2.2.2.1.1.3.1.2.cmml" xref="S3.E8.m2.2.2.1.1.3.1.2"></sum><ci id="S3.E8.m2.2.2.1.1.3.1.3.cmml" xref="S3.E8.m2.2.2.1.1.3.1.3">𝑖</ci></apply><apply id="S3.E8.m2.2.2.1.1.3.2.cmml" xref="S3.E8.m2.2.2.1.1.3.2"><times id="S3.E8.m2.2.2.1.1.3.2.1.cmml" xref="S3.E8.m2.2.2.1.1.3.2.1"></times><apply id="S3.E8.m2.2.2.1.1.3.2.2.cmml" xref="S3.E8.m2.2.2.1.1.3.2.2"><csymbol cd="ambiguous" id="S3.E8.m2.2.2.1.1.3.2.2.1.cmml" xref="S3.E8.m2.2.2.1.1.3.2.2">subscript</csymbol><apply id="S3.E8.m2.1.1.cmml" xref="S3.E8.m2.1.1"><ci id="S3.E8.m2.1.1.2.cmml" xref="S3.E8.m2.1.1.2">⏟</ci><apply id="S3.E8.m2.1.1.1.cmml" xref="S3.E8.m2.1.1.1"><divide id="S3.E8.m2.1.1.1.2.cmml" xref="S3.E8.m2.1.1.1"></divide><ci id="S3.E8.m2.1.1.1.3.cmml" xref="S3.E8.m2.1.1.1.3">𝑍</ci><apply id="S3.E8.m2.1.1.1.1.1.cmml" xref="S3.E8.m2.1.1.1.1.1"><plus id="S3.E8.m2.1.1.1.1.1.2.cmml" xref="S3.E8.m2.1.1.1.1.1.2"></plus><ci id="S3.E8.m2.1.1.1.1.1.3.cmml" xref="S3.E8.m2.1.1.1.1.1.3">italic-ϵ</ci><apply id="S3.E8.m2.1.1.1.1.1.1.cmml" xref="S3.E8.m2.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E8.m2.1.1.1.1.1.1.2.cmml" xref="S3.E8.m2.1.1.1.1.1.1">subscript</csymbol><apply id="S3.E8.m2.1.1.1.1.1.1.1.cmml" xref="S3.E8.m2.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E8.m2.1.1.1.1.1.1.1.2.cmml" xref="S3.E8.m2.1.1.1.1.1.1">superscript</csymbol><apply id="S3.E8.m2.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E8.m2.1.1.1.1.1.1.1.1.1"><csymbol cd="latexml" id="S3.E8.m2.1.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E8.m2.1.1.1.1.1.1.1.1.1.2">norm</csymbol><apply id="S3.E8.m2.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E8.m2.1.1.1.1.1.1.1.1.1.1"><minus id="S3.E8.m2.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E8.m2.1.1.1.1.1.1.1.1.1.1.1"></minus><apply id="S3.E8.m2.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E8.m2.1.1.1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E8.m2.1.1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E8.m2.1.1.1.1.1.1.1.1.1.1.2">subscript</csymbol><apply id="S3.E8.m2.1.1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E8.m2.1.1.1.1.1.1.1.1.1.1.2.2"><ci id="S3.E8.m2.1.1.1.1.1.1.1.1.1.1.2.2.1.cmml" xref="S3.E8.m2.1.1.1.1.1.1.1.1.1.1.2.2.1">bold-~</ci><ci id="S3.E8.m2.1.1.1.1.1.1.1.1.1.1.2.2.2.cmml" xref="S3.E8.m2.1.1.1.1.1.1.1.1.1.1.2.2.2">𝒍</ci></apply><ci id="S3.E8.m2.1.1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S3.E8.m2.1.1.1.1.1.1.1.1.1.1.2.3">𝑡</ci></apply><apply id="S3.E8.m2.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E8.m2.1.1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E8.m2.1.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E8.m2.1.1.1.1.1.1.1.1.1.1.3">subscript</csymbol><apply id="S3.E8.m2.1.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E8.m2.1.1.1.1.1.1.1.1.1.1.3.2"><ci id="S3.E8.m2.1.1.1.1.1.1.1.1.1.1.3.2.1.cmml" xref="S3.E8.m2.1.1.1.1.1.1.1.1.1.1.3.2.1">bold-^</ci><ci id="S3.E8.m2.1.1.1.1.1.1.1.1.1.1.3.2.2.cmml" xref="S3.E8.m2.1.1.1.1.1.1.1.1.1.1.3.2.2">𝒍</ci></apply><ci id="S3.E8.m2.1.1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S3.E8.m2.1.1.1.1.1.1.1.1.1.1.3.3">𝑖</ci></apply></apply></apply><cn id="S3.E8.m2.1.1.1.1.1.1.1.3.cmml" type="integer" xref="S3.E8.m2.1.1.1.1.1.1.1.3">2</cn></apply><cn id="S3.E8.m2.1.1.1.1.1.1.3.cmml" type="integer" xref="S3.E8.m2.1.1.1.1.1.1.3">2</cn></apply></apply></apply></apply><ci id="S3.E8.m2.2.2.1.1.3.2.2.2a.cmml" xref="S3.E8.m2.2.2.1.1.3.2.2.2"><mtext id="S3.E8.m2.2.2.1.1.3.2.2.2.cmml" mathsize="70%" xref="S3.E8.m2.2.2.1.1.3.2.2.2">weight</mtext></ci></apply><apply id="S3.E8.m2.2.2.1.1.3.2.3.cmml" xref="S3.E8.m2.2.2.1.1.3.2.3"><csymbol cd="ambiguous" id="S3.E8.m2.2.2.1.1.3.2.3.1.cmml" xref="S3.E8.m2.2.2.1.1.3.2.3">subscript</csymbol><apply id="S3.E8.m2.2.2.1.1.3.2.3.2.cmml" xref="S3.E8.m2.2.2.1.1.3.2.3.2"><ci id="S3.E8.m2.2.2.1.1.3.2.3.2.1.cmml" xref="S3.E8.m2.2.2.1.1.3.2.3.2.1">⏟</ci><apply id="S3.E8.m2.2.2.1.1.3.2.3.2.2.cmml" xref="S3.E8.m2.2.2.1.1.3.2.3.2.2"><csymbol cd="ambiguous" id="S3.E8.m2.2.2.1.1.3.2.3.2.2.1.cmml" xref="S3.E8.m2.2.2.1.1.3.2.3.2.2">subscript</csymbol><apply id="S3.E8.m2.2.2.1.1.3.2.3.2.2.2.cmml" xref="S3.E8.m2.2.2.1.1.3.2.3.2.2.2"><ci id="S3.E8.m2.2.2.1.1.3.2.3.2.2.2.1.cmml" xref="S3.E8.m2.2.2.1.1.3.2.3.2.2.2.1">bold-^</ci><ci id="S3.E8.m2.2.2.1.1.3.2.3.2.2.2.2.cmml" xref="S3.E8.m2.2.2.1.1.3.2.3.2.2.2.2">𝝍</ci></apply><ci id="S3.E8.m2.2.2.1.1.3.2.3.2.2.3.cmml" xref="S3.E8.m2.2.2.1.1.3.2.3.2.2.3">𝑖</ci></apply></apply><ci id="S3.E8.m2.2.2.1.1.3.2.3.3a.cmml" xref="S3.E8.m2.2.2.1.1.3.2.3.3"><mtext id="S3.E8.m2.2.2.1.1.3.2.3.3.cmml" mathsize="70%" xref="S3.E8.m2.2.2.1.1.3.2.3.3">training expression</mtext></ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E8.m2.2c">\displaystyle=\sum_{i}\underbrace{\frac{Z}{\epsilon+||\boldsymbol{\tilde{l}}_{%
t}-\boldsymbol{\hat{l}}_{i}||^{2}_{2}}}_{\text{weight}}\underbrace{\boldsymbol%
{\hat{\psi}}_{i}}_{\text{training expression}},</annotation><annotation encoding="application/x-llamapun" id="S3.E8.m2.2d">= ∑ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT under⏟ start_ARG divide start_ARG italic_Z end_ARG start_ARG italic_ϵ + | | overbold_~ start_ARG bold_italic_l end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT - overbold_^ start_ARG bold_italic_l end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT | | start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_ARG end_ARG start_POSTSUBSCRIPT weight end_POSTSUBSCRIPT under⏟ start_ARG overbold_^ start_ARG bold_italic_ψ end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_ARG start_POSTSUBSCRIPT training expression end_POSTSUBSCRIPT ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS3.SSS2.Px3.p1.7">where <math alttext="\boldsymbol{\hat{\psi}}_{i}" class="ltx_Math" display="inline" id="S3.SS3.SSS2.Px3.p1.3.m1.1"><semantics id="S3.SS3.SSS2.Px3.p1.3.m1.1a"><msub id="S3.SS3.SSS2.Px3.p1.3.m1.1.1" xref="S3.SS3.SSS2.Px3.p1.3.m1.1.1.cmml"><mover accent="true" id="S3.SS3.SSS2.Px3.p1.3.m1.1.1.2" xref="S3.SS3.SSS2.Px3.p1.3.m1.1.1.2.cmml"><mi id="S3.SS3.SSS2.Px3.p1.3.m1.1.1.2.2" xref="S3.SS3.SSS2.Px3.p1.3.m1.1.1.2.2.cmml">𝝍</mi><mo class="ltx_mathvariant_bold" id="S3.SS3.SSS2.Px3.p1.3.m1.1.1.2.1" mathvariant="bold" xref="S3.SS3.SSS2.Px3.p1.3.m1.1.1.2.1.cmml">^</mo></mover><mi id="S3.SS3.SSS2.Px3.p1.3.m1.1.1.3" xref="S3.SS3.SSS2.Px3.p1.3.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS2.Px3.p1.3.m1.1b"><apply id="S3.SS3.SSS2.Px3.p1.3.m1.1.1.cmml" xref="S3.SS3.SSS2.Px3.p1.3.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS2.Px3.p1.3.m1.1.1.1.cmml" xref="S3.SS3.SSS2.Px3.p1.3.m1.1.1">subscript</csymbol><apply id="S3.SS3.SSS2.Px3.p1.3.m1.1.1.2.cmml" xref="S3.SS3.SSS2.Px3.p1.3.m1.1.1.2"><ci id="S3.SS3.SSS2.Px3.p1.3.m1.1.1.2.1.cmml" xref="S3.SS3.SSS2.Px3.p1.3.m1.1.1.2.1">bold-^</ci><ci id="S3.SS3.SSS2.Px3.p1.3.m1.1.1.2.2.cmml" xref="S3.SS3.SSS2.Px3.p1.3.m1.1.1.2.2">𝝍</ci></apply><ci id="S3.SS3.SSS2.Px3.p1.3.m1.1.1.3.cmml" xref="S3.SS3.SSS2.Px3.p1.3.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS2.Px3.p1.3.m1.1c">\boldsymbol{\hat{\psi}}_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.SSS2.Px3.p1.3.m1.1d">overbold_^ start_ARG bold_italic_ψ end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> are the expression codes of the training frames, <math alttext="\boldsymbol{\tilde{l}_{t}}" class="ltx_Math" display="inline" id="S3.SS3.SSS2.Px3.p1.4.m2.1"><semantics id="S3.SS3.SSS2.Px3.p1.4.m2.1a"><msub id="S3.SS3.SSS2.Px3.p1.4.m2.1.1" xref="S3.SS3.SSS2.Px3.p1.4.m2.1.1.cmml"><mover accent="true" id="S3.SS3.SSS2.Px3.p1.4.m2.1.1.2" xref="S3.SS3.SSS2.Px3.p1.4.m2.1.1.2.cmml"><mi id="S3.SS3.SSS2.Px3.p1.4.m2.1.1.2.2" xref="S3.SS3.SSS2.Px3.p1.4.m2.1.1.2.2.cmml">𝒍</mi><mo class="ltx_mathvariant_bold" id="S3.SS3.SSS2.Px3.p1.4.m2.1.1.2.1" mathvariant="bold" xref="S3.SS3.SSS2.Px3.p1.4.m2.1.1.2.1.cmml">~</mo></mover><mi id="S3.SS3.SSS2.Px3.p1.4.m2.1.1.3" xref="S3.SS3.SSS2.Px3.p1.4.m2.1.1.3.cmml">𝒕</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS2.Px3.p1.4.m2.1b"><apply id="S3.SS3.SSS2.Px3.p1.4.m2.1.1.cmml" xref="S3.SS3.SSS2.Px3.p1.4.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS2.Px3.p1.4.m2.1.1.1.cmml" xref="S3.SS3.SSS2.Px3.p1.4.m2.1.1">subscript</csymbol><apply id="S3.SS3.SSS2.Px3.p1.4.m2.1.1.2.cmml" xref="S3.SS3.SSS2.Px3.p1.4.m2.1.1.2"><ci id="S3.SS3.SSS2.Px3.p1.4.m2.1.1.2.1.cmml" xref="S3.SS3.SSS2.Px3.p1.4.m2.1.1.2.1">bold-~</ci><ci id="S3.SS3.SSS2.Px3.p1.4.m2.1.1.2.2.cmml" xref="S3.SS3.SSS2.Px3.p1.4.m2.1.1.2.2">𝒍</ci></apply><ci id="S3.SS3.SSS2.Px3.p1.4.m2.1.1.3.cmml" xref="S3.SS3.SSS2.Px3.p1.4.m2.1.1.3">𝒕</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS2.Px3.p1.4.m2.1c">\boldsymbol{\tilde{l}_{t}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.SSS2.Px3.p1.4.m2.1d">overbold_~ start_ARG bold_italic_l end_ARG start_POSTSUBSCRIPT bold_italic_t end_POSTSUBSCRIPT</annotation></semantics></math> is the position of the target camera, <math alttext="\boldsymbol{\hat{l}}_{i}" class="ltx_Math" display="inline" id="S3.SS3.SSS2.Px3.p1.5.m3.1"><semantics id="S3.SS3.SSS2.Px3.p1.5.m3.1a"><msub id="S3.SS3.SSS2.Px3.p1.5.m3.1.1" xref="S3.SS3.SSS2.Px3.p1.5.m3.1.1.cmml"><mover accent="true" id="S3.SS3.SSS2.Px3.p1.5.m3.1.1.2" xref="S3.SS3.SSS2.Px3.p1.5.m3.1.1.2.cmml"><mi id="S3.SS3.SSS2.Px3.p1.5.m3.1.1.2.2" xref="S3.SS3.SSS2.Px3.p1.5.m3.1.1.2.2.cmml">𝒍</mi><mo class="ltx_mathvariant_bold" id="S3.SS3.SSS2.Px3.p1.5.m3.1.1.2.1" mathvariant="bold" xref="S3.SS3.SSS2.Px3.p1.5.m3.1.1.2.1.cmml">^</mo></mover><mi id="S3.SS3.SSS2.Px3.p1.5.m3.1.1.3" xref="S3.SS3.SSS2.Px3.p1.5.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS2.Px3.p1.5.m3.1b"><apply id="S3.SS3.SSS2.Px3.p1.5.m3.1.1.cmml" xref="S3.SS3.SSS2.Px3.p1.5.m3.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS2.Px3.p1.5.m3.1.1.1.cmml" xref="S3.SS3.SSS2.Px3.p1.5.m3.1.1">subscript</csymbol><apply id="S3.SS3.SSS2.Px3.p1.5.m3.1.1.2.cmml" xref="S3.SS3.SSS2.Px3.p1.5.m3.1.1.2"><ci id="S3.SS3.SSS2.Px3.p1.5.m3.1.1.2.1.cmml" xref="S3.SS3.SSS2.Px3.p1.5.m3.1.1.2.1">bold-^</ci><ci id="S3.SS3.SSS2.Px3.p1.5.m3.1.1.2.2.cmml" xref="S3.SS3.SSS2.Px3.p1.5.m3.1.1.2.2">𝒍</ci></apply><ci id="S3.SS3.SSS2.Px3.p1.5.m3.1.1.3.cmml" xref="S3.SS3.SSS2.Px3.p1.5.m3.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS2.Px3.p1.5.m3.1c">\boldsymbol{\hat{l}}_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.SSS2.Px3.p1.5.m3.1d">overbold_^ start_ARG bold_italic_l end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> are the positions of the training cameras, <math alttext="\epsilon" class="ltx_Math" display="inline" id="S3.SS3.SSS2.Px3.p1.6.m4.1"><semantics id="S3.SS3.SSS2.Px3.p1.6.m4.1a"><mi id="S3.SS3.SSS2.Px3.p1.6.m4.1.1" xref="S3.SS3.SSS2.Px3.p1.6.m4.1.1.cmml">ϵ</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS2.Px3.p1.6.m4.1b"><ci id="S3.SS3.SSS2.Px3.p1.6.m4.1.1.cmml" xref="S3.SS3.SSS2.Px3.p1.6.m4.1.1">italic-ϵ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS2.Px3.p1.6.m4.1c">\epsilon</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.SSS2.Px3.p1.6.m4.1d">italic_ϵ</annotation></semantics></math> is a small constant, and <math alttext="Z" class="ltx_Math" display="inline" id="S3.SS3.SSS2.Px3.p1.7.m5.1"><semantics id="S3.SS3.SSS2.Px3.p1.7.m5.1a"><mi id="S3.SS3.SSS2.Px3.p1.7.m5.1.1" xref="S3.SS3.SSS2.Px3.p1.7.m5.1.1.cmml">Z</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS2.Px3.p1.7.m5.1b"><ci id="S3.SS3.SSS2.Px3.p1.7.m5.1.1.cmml" xref="S3.SS3.SSS2.Px3.p1.7.m5.1.1">𝑍</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS2.Px3.p1.7.m5.1c">Z</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.SSS2.Px3.p1.7.m5.1d">italic_Z</annotation></semantics></math> is a normalization factor to ensure that the weights sum up to 1.</p>
</div>
</section>
</section>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4. </span>Experiments</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.2">This section presents an extensive evaluation of our proposed method with both quantitative and qualitative comparisons to related work and additional ablations. For comparisons, we run publicly available code for SparseNeRF <cite class="ltx_cite ltx_citemacro_citep">(Guangcong et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib22" title="">2023</a>)</cite>, Sparf <cite class="ltx_cite ltx_citemacro_citep">(Truong et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib65" title="">2023</a>)</cite>, and Diner <cite class="ltx_cite ltx_citemacro_citep">(Prinzler et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib51" title="">2023</a>)</cite>. For FreeNeRF <cite class="ltx_cite ltx_citemacro_citep">(Yang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib78" title="">2023</a>)</cite> and Preface <cite class="ltx_cite ltx_citemacro_citep">(Buehler et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib9" title="">2023</a>)</cite>, we use our own implementation.
We compare renders at the resolution <math alttext="1334\times 2048" class="ltx_Math" display="inline" id="S4.p1.1.m1.1"><semantics id="S4.p1.1.m1.1a"><mrow id="S4.p1.1.m1.1.1" xref="S4.p1.1.m1.1.1.cmml"><mn id="S4.p1.1.m1.1.1.2" xref="S4.p1.1.m1.1.1.2.cmml">1334</mn><mo id="S4.p1.1.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="S4.p1.1.m1.1.1.1.cmml">×</mo><mn id="S4.p1.1.m1.1.1.3" xref="S4.p1.1.m1.1.1.3.cmml">2048</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.p1.1.m1.1b"><apply id="S4.p1.1.m1.1.1.cmml" xref="S4.p1.1.m1.1.1"><times id="S4.p1.1.m1.1.1.1.cmml" xref="S4.p1.1.m1.1.1.1"></times><cn id="S4.p1.1.m1.1.1.2.cmml" type="integer" xref="S4.p1.1.m1.1.1.2">1334</cn><cn id="S4.p1.1.m1.1.1.3.cmml" type="integer" xref="S4.p1.1.m1.1.1.3">2048</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.1.m1.1c">1334\times 2048</annotation><annotation encoding="application/x-llamapun" id="S4.p1.1.m1.1d">1334 × 2048</annotation></semantics></math> pixels, except for Diner, where we render at a lower resolution (<math alttext="160\times 256" class="ltx_Math" display="inline" id="S4.p1.2.m2.1"><semantics id="S4.p1.2.m2.1a"><mrow id="S4.p1.2.m2.1.1" xref="S4.p1.2.m2.1.1.cmml"><mn id="S4.p1.2.m2.1.1.2" xref="S4.p1.2.m2.1.1.2.cmml">160</mn><mo id="S4.p1.2.m2.1.1.1" lspace="0.222em" rspace="0.222em" xref="S4.p1.2.m2.1.1.1.cmml">×</mo><mn id="S4.p1.2.m2.1.1.3" xref="S4.p1.2.m2.1.1.3.cmml">256</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.p1.2.m2.1b"><apply id="S4.p1.2.m2.1.1.cmml" xref="S4.p1.2.m2.1.1"><times id="S4.p1.2.m2.1.1.1.cmml" xref="S4.p1.2.m2.1.1.1"></times><cn id="S4.p1.2.m2.1.1.2.cmml" type="integer" xref="S4.p1.2.m2.1.1.2">160</cn><cn id="S4.p1.2.m2.1.1.3.cmml" type="integer" xref="S4.p1.2.m2.1.1.3">256</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.2.m2.1c">160\times 256</annotation><annotation encoding="application/x-llamapun" id="S4.p1.2.m2.1d">160 × 256</annotation></semantics></math> pixels) due to its architecture and memory constraints.
Please refer to the supplementary video and HTML page for more results.</p>
</div>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1. </span>Quantitative Evaluation</h3>
<figure class="ltx_table" id="S4.T1">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 1. </span>Quantitative evaluation on the Multiface dataset <cite class="ltx_cite ltx_citemacro_citep">(Wuu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib75" title="">2022</a>)</cite>.</figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T1.3.3">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T1.3.3.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t" id="S4.T1.3.3.3.4"><span class="ltx_text ltx_font_bold" id="S4.T1.3.3.3.4.1" style="font-size:90%;">Method</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T1.1.1.1.1">
<span class="ltx_text ltx_font_bold" id="S4.T1.1.1.1.1.1" style="font-size:90%;">PSNR</span><span class="ltx_text" id="S4.T1.1.1.1.1.2" style="font-size:90%;"> </span><math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T1.1.1.1.1.m1.1"><semantics id="S4.T1.1.1.1.1.m1.1a"><mo id="S4.T1.1.1.1.1.m1.1.1" mathsize="90%" stretchy="false" xref="S4.T1.1.1.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T1.1.1.1.1.m1.1b"><ci id="S4.T1.1.1.1.1.m1.1.1.cmml" xref="S4.T1.1.1.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.1.1.1.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T1.1.1.1.1.m1.1d">↑</annotation></semantics></math>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T1.2.2.2.2">
<span class="ltx_text ltx_font_bold" id="S4.T1.2.2.2.2.1" style="font-size:90%;">SSIM</span><span class="ltx_text" id="S4.T1.2.2.2.2.2" style="font-size:90%;"> </span><math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T1.2.2.2.2.m1.1"><semantics id="S4.T1.2.2.2.2.m1.1a"><mo id="S4.T1.2.2.2.2.m1.1.1" mathsize="90%" stretchy="false" xref="S4.T1.2.2.2.2.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T1.2.2.2.2.m1.1b"><ci id="S4.T1.2.2.2.2.m1.1.1.cmml" xref="S4.T1.2.2.2.2.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.2.2.2.2.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T1.2.2.2.2.m1.1d">↑</annotation></semantics></math>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T1.3.3.3.3">
<span class="ltx_text ltx_font_bold" id="S4.T1.3.3.3.3.1" style="font-size:90%;">LPIPS</span><span class="ltx_text" id="S4.T1.3.3.3.3.2" style="font-size:90%;"> </span><math alttext="\downarrow" class="ltx_Math" display="inline" id="S4.T1.3.3.3.3.m1.1"><semantics id="S4.T1.3.3.3.3.m1.1a"><mo id="S4.T1.3.3.3.3.m1.1.1" mathsize="90%" stretchy="false" xref="S4.T1.3.3.3.3.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T1.3.3.3.3.m1.1b"><ci id="S4.T1.3.3.3.3.m1.1.1.cmml" xref="S4.T1.3.3.3.3.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.3.3.3.3.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S4.T1.3.3.3.3.m1.1d">↓</annotation></semantics></math>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T1.3.3.4.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T1.3.3.4.1.1">
<span class="ltx_text" id="S4.T1.3.3.4.1.1.1" style="font-size:90%;">Sparse NeRF </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S4.T1.3.3.4.1.1.2.1" style="font-size:90%;">(</span>Guangcong et al<span class="ltx_text">.</span><span class="ltx_text" id="S4.T1.3.3.4.1.1.3.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib22" title="">2023</a><span class="ltx_text" id="S4.T1.3.3.4.1.1.4.3" style="font-size:90%;">)</span></cite>
</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.3.3.4.1.2"><span class="ltx_text" id="S4.T1.3.3.4.1.2.1" style="font-size:90%;">16.29</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.3.3.4.1.3"><span class="ltx_text" id="S4.T1.3.3.4.1.3.1" style="font-size:90%;">0.6470</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.3.3.4.1.4"><span class="ltx_text" id="S4.T1.3.3.4.1.4.1" style="font-size:90%;">0.4024</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.3.3.5.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T1.3.3.5.2.1">
<span class="ltx_text" id="S4.T1.3.3.5.2.1.1" style="font-size:90%;">Diner </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S4.T1.3.3.5.2.1.2.1" style="font-size:90%;">(</span>Prinzler et al<span class="ltx_text">.</span><span class="ltx_text" id="S4.T1.3.3.5.2.1.3.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib51" title="">2023</a><span class="ltx_text" id="S4.T1.3.3.5.2.1.4.3" style="font-size:90%;">)</span></cite>
</th>
<td class="ltx_td ltx_align_center" id="S4.T1.3.3.5.2.2"><span class="ltx_text" id="S4.T1.3.3.5.2.2.1" style="font-size:90%;">17.08</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.3.5.2.3"><span class="ltx_text" id="S4.T1.3.3.5.2.3.1" style="font-size:90%;">0.6608</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.3.5.2.4"><span class="ltx_text" id="S4.T1.3.3.5.2.4.1" style="font-size:90%;">0.3123</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.3.3.6.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T1.3.3.6.3.1">
<span class="ltx_text" id="S4.T1.3.3.6.3.1.1" style="font-size:90%;">SPARF </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S4.T1.3.3.6.3.1.2.1" style="font-size:90%;">(</span>Truong et al<span class="ltx_text">.</span><span class="ltx_text" id="S4.T1.3.3.6.3.1.3.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib65" title="">2023</a><span class="ltx_text" id="S4.T1.3.3.6.3.1.4.3" style="font-size:90%;">)</span></cite>
</th>
<td class="ltx_td ltx_align_center" id="S4.T1.3.3.6.3.2"><span class="ltx_text" id="S4.T1.3.3.6.3.2.1" style="font-size:90%;">18.38</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.3.6.3.3"><span class="ltx_text" id="S4.T1.3.3.6.3.3.1" style="font-size:90%;">0.6401</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.3.6.3.4"><span class="ltx_text" id="S4.T1.3.3.6.3.4.1" style="font-size:90%;">0.4032</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.3.3.7.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T1.3.3.7.4.1">
<span class="ltx_text" id="S4.T1.3.3.7.4.1.1" style="font-size:90%;">FreeNeRF </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S4.T1.3.3.7.4.1.2.1" style="font-size:90%;">(</span>Yang et al<span class="ltx_text">.</span><span class="ltx_text" id="S4.T1.3.3.7.4.1.3.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib78" title="">2023</a><span class="ltx_text" id="S4.T1.3.3.7.4.1.4.3" style="font-size:90%;">)</span></cite>
</th>
<td class="ltx_td ltx_align_center" id="S4.T1.3.3.7.4.2"><span class="ltx_text" id="S4.T1.3.3.7.4.2.1" style="font-size:90%;">21.42</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.3.7.4.3"><span class="ltx_text" id="S4.T1.3.3.7.4.3.1" style="font-size:90%;">0.7093</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.3.7.4.4"><span class="ltx_text" id="S4.T1.3.3.7.4.4.1" style="font-size:90%;">0.3612</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.3.3.8.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T1.3.3.8.5.1">
<span class="ltx_text" id="S4.T1.3.3.8.5.1.1" style="font-size:90%;">Preface </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S4.T1.3.3.8.5.1.2.1" style="font-size:90%;">(</span>Buehler et al<span class="ltx_text">.</span><span class="ltx_text" id="S4.T1.3.3.8.5.1.3.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib9" title="">2023</a><span class="ltx_text" id="S4.T1.3.3.8.5.1.4.3" style="font-size:90%;">)</span></cite>
</th>
<td class="ltx_td ltx_align_center" id="S4.T1.3.3.8.5.2"><span class="ltx_text" id="S4.T1.3.3.8.5.2.1" style="font-size:90%;">25.02</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.3.8.5.3"><span class="ltx_text" id="S4.T1.3.3.8.5.3.1" style="font-size:90%;">0.7539</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.3.8.5.4"><span class="ltx_text" id="S4.T1.3.3.8.5.4.1" style="font-size:90%;">0.3129</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.3.3.9.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T1.3.3.9.6.1"><span class="ltx_text ltx_font_bold" id="S4.T1.3.3.9.6.1.1" style="font-size:90%;">Ours</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.3.3.9.6.2"><span class="ltx_text ltx_font_bold" id="S4.T1.3.3.9.6.2.1" style="font-size:90%;">26.49</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.3.3.9.6.3"><span class="ltx_text ltx_font_bold" id="S4.T1.3.3.9.6.3.1" style="font-size:90%;">0.7721</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.3.3.9.6.4"><span class="ltx_text ltx_font_bold" id="S4.T1.3.3.9.6.4.1" style="font-size:90%;">0.2970</span></td>
</tr>
</tbody>
</table>
</figure>
<figure class="ltx_table" id="S4.T2">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 2. </span>We ablate the performance for different variants of the prior model. We pre-train a) on a smaller training set with fewer subjects, b) for a shorter number of steps, c) with different configurations of our synthetic rendering pipeline, and d) include real data. The <em class="ltx_emph ltx_font_italic" id="S4.T2.5.1">full</em> prior model is trained on 1,500 subjects with 13 expressions each for 1 Mio. steps on synthetic renderings with all available accessories in a single environment map. Please see the supp. mat. for details of the rendering pipeline.
</figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T2.3.3">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T2.3.3.3">
<th class="ltx_td ltx_th ltx_th_row ltx_border_t" id="S4.T2.3.3.3.4"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T2.3.3.3.5"><span class="ltx_text ltx_font_bold" id="S4.T2.3.3.3.5.1" style="font-size:90%;">Pre-training Variant</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.1.1">
<span class="ltx_text ltx_font_bold" id="S4.T2.1.1.1.1.1" style="font-size:90%;">PSNR</span><span class="ltx_text" id="S4.T2.1.1.1.1.2" style="font-size:90%;"> </span><math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T2.1.1.1.1.m1.1"><semantics id="S4.T2.1.1.1.1.m1.1a"><mo id="S4.T2.1.1.1.1.m1.1.1" mathsize="90%" stretchy="false" xref="S4.T2.1.1.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T2.1.1.1.1.m1.1b"><ci id="S4.T2.1.1.1.1.m1.1.1.cmml" xref="S4.T2.1.1.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.1.1.1.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T2.1.1.1.1.m1.1d">↑</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.2.2.2.2">
<span class="ltx_text ltx_font_bold" id="S4.T2.2.2.2.2.1" style="font-size:90%;">SSIM</span><span class="ltx_text" id="S4.T2.2.2.2.2.2" style="font-size:90%;"> </span><math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T2.2.2.2.2.m1.1"><semantics id="S4.T2.2.2.2.2.m1.1a"><mo id="S4.T2.2.2.2.2.m1.1.1" mathsize="90%" stretchy="false" xref="S4.T2.2.2.2.2.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T2.2.2.2.2.m1.1b"><ci id="S4.T2.2.2.2.2.m1.1.1.cmml" xref="S4.T2.2.2.2.2.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.2.2.2.2.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T2.2.2.2.2.m1.1d">↑</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.3.3.3.3">
<span class="ltx_text ltx_font_bold" id="S4.T2.3.3.3.3.1" style="font-size:90%;">LPIPS</span><span class="ltx_text" id="S4.T2.3.3.3.3.2" style="font-size:90%;"> </span><math alttext="\downarrow" class="ltx_Math" display="inline" id="S4.T2.3.3.3.3.m1.1"><semantics id="S4.T2.3.3.3.3.m1.1a"><mo id="S4.T2.3.3.3.3.m1.1.1" mathsize="90%" stretchy="false" xref="S4.T2.3.3.3.3.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T2.3.3.3.3.m1.1b"><ci id="S4.T2.3.3.3.3.m1.1.1.cmml" xref="S4.T2.3.3.3.3.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.3.3.3.3.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S4.T2.3.3.3.3.m1.1d">↓</annotation></semantics></math>
</td>
</tr>
<tr class="ltx_tr" id="S4.T2.3.3.4.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T2.3.3.4.1.1"><span class="ltx_text" id="S4.T2.3.3.4.1.1.1" style="font-size:90%;">a.i)</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T2.3.3.4.1.2"><span class="ltx_text" id="S4.T2.3.3.4.1.2.1" style="font-size:90%;">No Pre-training</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.3.3.4.1.3"><span class="ltx_text" id="S4.T2.3.3.4.1.3.1" style="font-size:90%;">10.21</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.3.3.4.1.4"><span class="ltx_text" id="S4.T2.3.3.4.1.4.1" style="font-size:90%;">0.3448</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.3.3.4.1.5"><span class="ltx_text" id="S4.T2.3.3.4.1.5.1" style="font-size:90%;">0.4256</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.3.3.5.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T2.3.3.5.2.1"><span class="ltx_text" id="S4.T2.3.3.5.2.1.1" style="font-size:90%;">a.ii)</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T2.3.3.5.2.2"><span class="ltx_text" id="S4.T2.3.3.5.2.2.1" style="font-size:90%;">On 1 subject</span></th>
<td class="ltx_td ltx_align_center" id="S4.T2.3.3.5.2.3"><span class="ltx_text" id="S4.T2.3.3.5.2.3.1" style="font-size:90%;">24.00</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.3.5.2.4"><span class="ltx_text" id="S4.T2.3.3.5.2.4.1" style="font-size:90%;">0.7512</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.3.5.2.5"><span class="ltx_text" id="S4.T2.3.3.5.2.5.1" style="font-size:90%;">0.3358</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.3.3.6.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T2.3.3.6.3.1"><span class="ltx_text" id="S4.T2.3.3.6.3.1.1" style="font-size:90%;">a.iii)</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T2.3.3.6.3.2"><span class="ltx_text" id="S4.T2.3.3.6.3.2.1" style="font-size:90%;">On 15 subjects</span></th>
<td class="ltx_td ltx_align_center" id="S4.T2.3.3.6.3.3"><span class="ltx_text" id="S4.T2.3.3.6.3.3.1" style="font-size:90%;">25.47</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.3.6.3.4"><span class="ltx_text" id="S4.T2.3.3.6.3.4.1" style="font-size:90%;">0.7668</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.3.6.3.5"><span class="ltx_text" id="S4.T2.3.3.6.3.5.1" style="font-size:90%;">0.3248</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.3.3.7.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T2.3.3.7.4.1"><span class="ltx_text" id="S4.T2.3.3.7.4.1.1" style="font-size:90%;">a.iv)</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T2.3.3.7.4.2"><span class="ltx_text" id="S4.T2.3.3.7.4.2.1" style="font-size:90%;">On 1,500 subjects</span></th>
<td class="ltx_td ltx_align_center" id="S4.T2.3.3.7.4.3"><span class="ltx_text" id="S4.T2.3.3.7.4.3.1" style="font-size:90%;">26.54</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.3.7.4.4"><span class="ltx_text" id="S4.T2.3.3.7.4.4.1" style="font-size:90%;">0.7750</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.3.7.4.5"><span class="ltx_text" id="S4.T2.3.3.7.4.5.1" style="font-size:90%;">0.3144</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.3.3.8.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T2.3.3.8.5.1"><span class="ltx_text" id="S4.T2.3.3.8.5.1.1" style="font-size:90%;">b.i)</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T2.3.3.8.5.2"><span class="ltx_text" id="S4.T2.3.3.8.5.2.1" style="font-size:90%;">For 105K steps</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.3.3.8.5.3"><span class="ltx_text" id="S4.T2.3.3.8.5.3.1" style="font-size:90%;">26.64</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.3.3.8.5.4"><span class="ltx_text" id="S4.T2.3.3.8.5.4.1" style="font-size:90%;">0.7752</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.3.3.8.5.5"><span class="ltx_text" id="S4.T2.3.3.8.5.5.1" style="font-size:90%;">0.3208</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.3.3.9.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T2.3.3.9.6.1"><span class="ltx_text" id="S4.T2.3.3.9.6.1.1" style="font-size:90%;">b.ii)</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T2.3.3.9.6.2"><span class="ltx_text" id="S4.T2.3.3.9.6.2.1" style="font-size:90%;">For 500K steps</span></th>
<td class="ltx_td ltx_align_center" id="S4.T2.3.3.9.6.3"><span class="ltx_text" id="S4.T2.3.3.9.6.3.1" style="font-size:90%;">26.54</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.3.9.6.4"><span class="ltx_text" id="S4.T2.3.3.9.6.4.1" style="font-size:90%;">0.7750</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.3.9.6.5"><span class="ltx_text" id="S4.T2.3.3.9.6.5.1" style="font-size:90%;">0.3144</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.3.3.10.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T2.3.3.10.7.1"><span class="ltx_text" id="S4.T2.3.3.10.7.1.1" style="font-size:90%;">b.iii)</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T2.3.3.10.7.2"><span class="ltx_text" id="S4.T2.3.3.10.7.2.1" style="font-size:90%;">For 1 Mio. steps</span></th>
<td class="ltx_td ltx_align_center" id="S4.T2.3.3.10.7.3"><span class="ltx_text" id="S4.T2.3.3.10.7.3.1" style="font-size:90%;">26.49</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.3.10.7.4"><span class="ltx_text" id="S4.T2.3.3.10.7.4.1" style="font-size:90%;">0.7721</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.3.10.7.5"><span class="ltx_text" id="S4.T2.3.3.10.7.5.1" style="font-size:90%;">0.2970</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.3.3.11.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T2.3.3.11.8.1"><span class="ltx_text" id="S4.T2.3.3.11.8.1.1" style="font-size:90%;">c.i)</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T2.3.3.11.8.2"><span class="ltx_text" id="S4.T2.3.3.11.8.2.1" style="font-size:90%;">On gray-scale renderings</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.3.3.11.8.3"><span class="ltx_text" id="S4.T2.3.3.11.8.3.1" style="font-size:90%;">26.44</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.3.3.11.8.4"><span class="ltx_text" id="S4.T2.3.3.11.8.4.1" style="font-size:90%;">0.7740</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.3.3.11.8.5"><span class="ltx_text" id="S4.T2.3.3.11.8.5.1" style="font-size:90%;">0.3242</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.3.3.12.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T2.3.3.12.9.1"><span class="ltx_text" id="S4.T2.3.3.12.9.1.1" style="font-size:90%;">c.ii)</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T2.3.3.12.9.2"><span class="ltx_text" id="S4.T2.3.3.12.9.2.1" style="font-size:90%;">On low-quality renderings</span></th>
<td class="ltx_td ltx_align_center" id="S4.T2.3.3.12.9.3"><span class="ltx_text" id="S4.T2.3.3.12.9.3.1" style="font-size:90%;">26.53</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.3.12.9.4"><span class="ltx_text" id="S4.T2.3.3.12.9.4.1" style="font-size:90%;">0.7727</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.3.12.9.5"><span class="ltx_text" id="S4.T2.3.3.12.9.5.1" style="font-size:90%;">0.3401</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.3.3.13.10">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T2.3.3.13.10.1"><span class="ltx_text" id="S4.T2.3.3.13.10.1.1" style="font-size:90%;">c.iii)</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T2.3.3.13.10.2"><span class="ltx_text" id="S4.T2.3.3.13.10.2.1" style="font-size:90%;">In diverse environments</span></th>
<td class="ltx_td ltx_align_center" id="S4.T2.3.3.13.10.3"><span class="ltx_text" id="S4.T2.3.3.13.10.3.1" style="font-size:90%;">26.58</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.3.13.10.4"><span class="ltx_text" id="S4.T2.3.3.13.10.4.1" style="font-size:90%;">0.7727</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.3.13.10.5"><span class="ltx_text" id="S4.T2.3.3.13.10.5.1" style="font-size:90%;">0.3415</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.3.3.14.11">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T2.3.3.14.11.1"><span class="ltx_text" id="S4.T2.3.3.14.11.1.1" style="font-size:90%;">c.iv)</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T2.3.3.14.11.2"><span class="ltx_text" id="S4.T2.3.3.14.11.2.1" style="font-size:90%;">Without makeup</span></th>
<td class="ltx_td ltx_align_center" id="S4.T2.3.3.14.11.3"><span class="ltx_text" id="S4.T2.3.3.14.11.3.1" style="font-size:90%;">26.72</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.3.14.11.4"><span class="ltx_text" id="S4.T2.3.3.14.11.4.1" style="font-size:90%;">0.7755</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.3.14.11.5"><span class="ltx_text" id="S4.T2.3.3.14.11.5.1" style="font-size:90%;">0.3210</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.3.3.15.12">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T2.3.3.15.12.1"><span class="ltx_text" id="S4.T2.3.3.15.12.1.1" style="font-size:90%;">c.v)</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T2.3.3.15.12.2"><span class="ltx_text" id="S4.T2.3.3.15.12.2.1" style="font-size:90%;">Without accessories</span></th>
<td class="ltx_td ltx_align_center" id="S4.T2.3.3.15.12.3"><span class="ltx_text" id="S4.T2.3.3.15.12.3.1" style="font-size:90%;">26.00</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.3.15.12.4"><span class="ltx_text" id="S4.T2.3.3.15.12.4.1" style="font-size:90%;">0.7731</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.3.15.12.5"><span class="ltx_text" id="S4.T2.3.3.15.12.5.1" style="font-size:90%;">0.3484</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.3.3.16.13">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T2.3.3.16.13.1"><span class="ltx_text" id="S4.T2.3.3.16.13.1.1" style="font-size:90%;">c.vi)</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T2.3.3.16.13.2"><span class="ltx_text" id="S4.T2.3.3.16.13.2.1" style="font-size:90%;">Without hair</span></th>
<td class="ltx_td ltx_align_center" id="S4.T2.3.3.16.13.3"><span class="ltx_text" id="S4.T2.3.3.16.13.3.1" style="font-size:90%;">26.14</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.3.16.13.4"><span class="ltx_text" id="S4.T2.3.3.16.13.4.1" style="font-size:90%;">0.7727</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.3.16.13.5"><span class="ltx_text" id="S4.T2.3.3.16.13.5.1" style="font-size:90%;">0.3303</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.3.3.17.14">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T2.3.3.17.14.1"><span class="ltx_text" id="S4.T2.3.3.17.14.1.1" style="font-size:90%;">c.vii)</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T2.3.3.17.14.2"><span class="ltx_text" id="S4.T2.3.3.17.14.2.1" style="font-size:90%;">With all accessories</span></th>
<td class="ltx_td ltx_align_center" id="S4.T2.3.3.17.14.3"><span class="ltx_text" id="S4.T2.3.3.17.14.3.1" style="font-size:90%;">26.54</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.3.17.14.4"><span class="ltx_text" id="S4.T2.3.3.17.14.4.1" style="font-size:90%;">0.7750</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.3.17.14.5"><span class="ltx_text" id="S4.T2.3.3.17.14.5.1" style="font-size:90%;">0.3144</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.3.3.18.15">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T2.3.3.18.15.1"><span class="ltx_text" id="S4.T2.3.3.18.15.1.1" style="font-size:90%;">d.i)</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T2.3.3.18.15.2"><span class="ltx_text" id="S4.T2.3.3.18.15.2.1" style="font-size:90%;">On real images</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.3.3.18.15.3"><span class="ltx_text" id="S4.T2.3.3.18.15.3.1" style="font-size:90%;">26.14</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.3.3.18.15.4"><span class="ltx_text" id="S4.T2.3.3.18.15.4.1" style="font-size:90%;">0.7708</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.3.3.18.15.5"><span class="ltx_text" id="S4.T2.3.3.18.15.5.1" style="font-size:90%;">0.3237</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.3.3.19.16">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T2.3.3.19.16.1"><span class="ltx_text" id="S4.T2.3.3.19.16.1.1" style="font-size:90%;">d.ii)</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T2.3.3.19.16.2">
<span class="ltx_text" id="S4.T2.3.3.19.16.2.1" style="font-size:90%;">On real </span><em class="ltx_emph ltx_font_italic" id="S4.T2.3.3.19.16.2.2" style="font-size:90%;">and</em><span class="ltx_text" id="S4.T2.3.3.19.16.2.3" style="font-size:90%;"> synthetic images</span>
</th>
<td class="ltx_td ltx_align_center" id="S4.T2.3.3.19.16.3"><span class="ltx_text" id="S4.T2.3.3.19.16.3.1" style="font-size:90%;">26.41</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.3.19.16.4"><span class="ltx_text" id="S4.T2.3.3.19.16.4.1" style="font-size:90%;">0.7726</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.3.19.16.5"><span class="ltx_text" id="S4.T2.3.3.19.16.5.1" style="font-size:90%;">0.3227</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.3.3.20.17">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T2.3.3.20.17.1"><span class="ltx_text" id="S4.T2.3.3.20.17.1.1" style="font-size:90%;">d.iii)</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T2.3.3.20.17.2"><span class="ltx_text" id="S4.T2.3.3.20.17.2.1" style="font-size:90%;">On synthetic images</span></th>
<td class="ltx_td ltx_align_center" id="S4.T2.3.3.20.17.3"><span class="ltx_text" id="S4.T2.3.3.20.17.3.1" style="font-size:90%;">26.54</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.3.20.17.4"><span class="ltx_text" id="S4.T2.3.3.20.17.4.1" style="font-size:90%;">0.7750</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.3.20.17.5"><span class="ltx_text" id="S4.T2.3.3.20.17.5.1" style="font-size:90%;">0.3144</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.3.3.21.18">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T2.3.3.21.18.1"><span class="ltx_text" id="S4.T2.3.3.21.18.1.1" style="font-size:90%;">e)</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T2.3.3.21.18.2"><span class="ltx_text" id="S4.T2.3.3.21.18.2.1" style="font-size:90%;">Full</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.3.3.21.18.3"><span class="ltx_text" id="S4.T2.3.3.21.18.3.1" style="font-size:90%;">26.49</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.3.3.21.18.4"><span class="ltx_text" id="S4.T2.3.3.21.18.4.1" style="font-size:90%;">0.7721</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.3.3.21.18.5"><span class="ltx_text" id="S4.T2.3.3.21.18.5.1" style="font-size:90%;">0.2970</span></td>
</tr>
</tbody>
</table>
</figure>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">Performance on casual in-the-wild captures is inherently difficult to evaluate quantitatively due to the lack of proper validation views. Often, the captured subject can hardly remain completely still. Therefore, we quantitatively evaluate on the Multiface <cite class="ltx_cite ltx_citemacro_citep">(Wuu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib75" title="">2022</a>)</cite> studio dataset on nine scenes by randomly selecting three subjects with three expressions per subject. For each test subject, we use one frontal and two side views as input for training, as shown in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#S5.F7" title="Figure 7 ‣ Cafca: High-quality Novel View Synthesis of Expressive Faces from Casual Few-shot Captures"><span class="ltx_text ltx_ref_tag">7</span></a>. We remove the background by multiplying a foreground alpha matte estimated by <cite class="ltx_cite ltx_citemacro_citep">(Pandey et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib45" title="">2021</a>)</cite>.
We hold out from 26 to 29 validation images per subject, where the camera viewing direction is located in the frontal hemisphere (see details in the supplementary material). As evaluation metrics, we measure photo-metric distance and image similarity via PSNR, SSIM, and LPIPS <cite class="ltx_cite ltx_citemacro_citep">(Zhang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib84" title="">2018</a>)</cite>, as summarized in Tbl. <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#S4.T1" title="Table 1 ‣ 4.1. Quantitative Evaluation ‣ 4. Experiments ‣ Cafca: High-quality Novel View Synthesis of Expressive Faces from Casual Few-shot Captures"><span class="ltx_text ltx_ref_tag">1</span></a>. Note that photometric reconstruction metrics like PSNR and SSIM and perceptual metrics like LPIPS are at odds with each other <cite class="ltx_cite ltx_citemacro_citep">(Blau and Michaeli, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib6" title="">2018</a>)</cite>. We handle this tradeoff by optimizing perceptual quality in the warm-up (Eq. <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#S3.E6" title="In Warm-up by Latent Code Inversion ‣ 3.3.2. Fine-tuning on Sparse Views ‣ 3.3. Inference from Sparse Views ‣ 3. Method ‣ Cafca: High-quality Novel View Synthesis of Expressive Faces from Casual Few-shot Captures"><span class="ltx_text ltx_ref_tag">6</span></a>) and reconstruction quality in the fine-tuning (Eq. <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#S3.E7" title="In Model Fitting ‣ 3.3.2. Fine-tuning on Sparse Views ‣ 3.3. Inference from Sparse Views ‣ 3. Method ‣ Cafca: High-quality Novel View Synthesis of Expressive Faces from Casual Few-shot Captures"><span class="ltx_text ltx_ref_tag">7</span></a>).</p>
</div>
<div class="ltx_para" id="S4.SS1.p2">
<p class="ltx_p" id="S4.SS1.p2.1">As shown in Tbl. <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#S4.T1" title="Table 1 ‣ 4.1. Quantitative Evaluation ‣ 4. Experiments ‣ Cafca: High-quality Novel View Synthesis of Expressive Faces from Casual Few-shot Captures"><span class="ltx_text ltx_ref_tag">1</span></a>, our new method provides better modeling fidelity across all three metrics over the set of validation views. In particular, compared to the state-of-the-art Preface <cite class="ltx_cite ltx_citemacro_citep">(Buehler et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib9" title="">2023</a>)</cite>, we achieve the following improvement on the computed metrics: 6% PSNR, 2.4% SSIM, and 5% LPIPS. Visually, Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#S5.F7" title="Figure 7 ‣ Cafca: High-quality Novel View Synthesis of Expressive Faces from Casual Few-shot Captures"><span class="ltx_text ltx_ref_tag">7</span></a> shows that the novel views generated by our fine-tuned model more closely resemble the facial shape and appearance, including eye and mouth details, of the example (ground-truth) validation view.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2. </span>Qualitative Results in the Wild</h3>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">To demonstrate the robustness of our method in the wild, we captured subjects with a handheld DSLR camera (Canon EOS 4000D) and mobile phones (Pixel 7 and Pixel 8 Pro). We capture between one and three images per subject in various outdoor and indoor environments, including very challenging lighting conditions. These diverse in-the-wild results are shown in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#S0.F1" title="Figure 1 ‣ Cafca: High-quality Novel View Synthesis of Expressive Faces from Casual Few-shot Captures"><span class="ltx_text ltx_ref_tag">1</span></a>, Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#S5.F8" title="Figure 8 ‣ Cafca: High-quality Novel View Synthesis of Expressive Faces from Casual Few-shot Captures"><span class="ltx_text ltx_ref_tag">8</span></a>, Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#S5.F9" title="Figure 9 ‣ Cafca: High-quality Novel View Synthesis of Expressive Faces from Casual Few-shot Captures"><span class="ltx_text ltx_ref_tag">9</span></a>, and in the supplementary video and HTML page. The inlays in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#S0.F1" title="Figure 1 ‣ Cafca: High-quality Novel View Synthesis of Expressive Faces from Casual Few-shot Captures"><span class="ltx_text ltx_ref_tag">1</span></a> show the high level of modeled detail on the lips and on the individual hair strands and eyelashes. Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#S5.F8" title="Figure 8 ‣ Cafca: High-quality Novel View Synthesis of Expressive Faces from Casual Few-shot Captures"><span class="ltx_text ltx_ref_tag">8</span></a> compares with the best performing related work <cite class="ltx_cite ltx_citemacro_citep">(Buehler et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib9" title="">2023</a>)</cite>, which struggles with the mouth region. Of particular note is also the “tongue-out” expression in the third row of Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#S5.F9" title="Figure 9 ‣ Cafca: High-quality Novel View Synthesis of Expressive Faces from Casual Few-shot Captures"><span class="ltx_text ltx_ref_tag">9</span></a>. Note that our synthetic training data contains tongues but the tongues never stick out of the mouth.</p>
</div>
<div class="ltx_para" id="S4.SS2.p2">
<p class="ltx_p" id="S4.SS2.p2.1">We also consider the more challenging single input image scenario, see Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#S5.F10" title="Figure 10 ‣ Cafca: High-quality Novel View Synthesis of Expressive Faces from Casual Few-shot Captures"><span class="ltx_text ltx_ref_tag">10</span></a>. Our method achieves high-fidelity synthesis of the frontal face even for stylized and painted faces (right) but quickly degrades for side views. This behavior is expected, as our model is only trained on low-resolution synthetic images and has never seen high-resolution views from the side of a face. Please see the supp. HTML page for more examples.</p>
</div>
<div class="ltx_para" id="S4.SS2.p3">
<p class="ltx_p" id="S4.SS2.p3.1">Additional qualitative comparisons to previous work are shown in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#S5.F7" title="Figure 7 ‣ Cafca: High-quality Novel View Synthesis of Expressive Faces from Casual Few-shot Captures"><span class="ltx_text ltx_ref_tag">7</span></a>. Our method outperforms the other baseline methods in two main ways. First, our approach captures fine identity-specific details like teeth outlines (middle row) and stubble (bottom row), while previous methods degenerate into blur or noise. Second, the overall face shape is more accurate, as evidenced by the eyeball in the top row and the cheek silhouette in the middle row. Our synthetic face prior encourages the reconstruction to remain faithful to its learned understanding of faces, <em class="ltx_emph ltx_font_italic" id="S4.SS2.p3.1.1">e.g.</em>, that corneas should bulge outwards, not be flat. These results and the metrics in Tbl. <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#S4.T1" title="Table 1 ‣ 4.1. Quantitative Evaluation ‣ 4. Experiments ‣ Cafca: High-quality Novel View Synthesis of Expressive Faces from Casual Few-shot Captures"><span class="ltx_text ltx_ref_tag">1</span></a> demonstrate that our new model and fine-tuning method outperforms previous work both qualitatively and quantitatively.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3. </span>Ablation Study</h3>
<div class="ltx_para" id="S4.SS3.p1">
<p class="ltx_p" id="S4.SS3.p1.1">We conduct extensive ablation studies of the prior model. Table  <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#S4.T2" title="Table 2 ‣ 4.1. Quantitative Evaluation ‣ 4. Experiments ‣ Cafca: High-quality Novel View Synthesis of Expressive Faces from Casual Few-shot Captures"><span class="ltx_text ltx_ref_tag">2</span></a> lists metrics after fine-tuning to three inputs at 2K resolution. Please see the supp. PDF for more ablations and the HTML page for visuals.</p>
</div>
<section class="ltx_paragraph" id="S4.SS3.SSS0.Px1">
<h5 class="ltx_title ltx_title_paragraph">Dataset Size</h5>
<div class="ltx_para" id="S4.SS3.SSS0.Px1.p1">
<p class="ltx_p" id="S4.SS3.SSS0.Px1.p1.1">We compare prior models without any pre-training (a.i) with models pre-trained on a single subject (a.ii), on 15 subjects (a.iii), and on 1,500 subjects (a.iv). Note that each subject is rendered with 13 expressions and 30 views per expression (as described in Sec. <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#S3.SS2" title="3.2. Pretraining an Expressive Prior Model ‣ 3. Method ‣ Cafca: High-quality Novel View Synthesis of Expressive Faces from Casual Few-shot Captures"><span class="ltx_text ltx_ref_tag">3.2</span></a>). Hence, the model trained on 1 subject (a.ii) sees <math alttext="1\cdot 13\cdot 30=390" class="ltx_Math" display="inline" id="S4.SS3.SSS0.Px1.p1.1.m1.1"><semantics id="S4.SS3.SSS0.Px1.p1.1.m1.1a"><mrow id="S4.SS3.SSS0.Px1.p1.1.m1.1.1" xref="S4.SS3.SSS0.Px1.p1.1.m1.1.1.cmml"><mrow id="S4.SS3.SSS0.Px1.p1.1.m1.1.1.2" xref="S4.SS3.SSS0.Px1.p1.1.m1.1.1.2.cmml"><mn id="S4.SS3.SSS0.Px1.p1.1.m1.1.1.2.2" xref="S4.SS3.SSS0.Px1.p1.1.m1.1.1.2.2.cmml">1</mn><mo id="S4.SS3.SSS0.Px1.p1.1.m1.1.1.2.1" lspace="0.222em" rspace="0.222em" xref="S4.SS3.SSS0.Px1.p1.1.m1.1.1.2.1.cmml">⋅</mo><mn id="S4.SS3.SSS0.Px1.p1.1.m1.1.1.2.3" xref="S4.SS3.SSS0.Px1.p1.1.m1.1.1.2.3.cmml">13</mn><mo id="S4.SS3.SSS0.Px1.p1.1.m1.1.1.2.1a" lspace="0.222em" rspace="0.222em" xref="S4.SS3.SSS0.Px1.p1.1.m1.1.1.2.1.cmml">⋅</mo><mn id="S4.SS3.SSS0.Px1.p1.1.m1.1.1.2.4" xref="S4.SS3.SSS0.Px1.p1.1.m1.1.1.2.4.cmml">30</mn></mrow><mo id="S4.SS3.SSS0.Px1.p1.1.m1.1.1.1" xref="S4.SS3.SSS0.Px1.p1.1.m1.1.1.1.cmml">=</mo><mn id="S4.SS3.SSS0.Px1.p1.1.m1.1.1.3" xref="S4.SS3.SSS0.Px1.p1.1.m1.1.1.3.cmml">390</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px1.p1.1.m1.1b"><apply id="S4.SS3.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S4.SS3.SSS0.Px1.p1.1.m1.1.1"><eq id="S4.SS3.SSS0.Px1.p1.1.m1.1.1.1.cmml" xref="S4.SS3.SSS0.Px1.p1.1.m1.1.1.1"></eq><apply id="S4.SS3.SSS0.Px1.p1.1.m1.1.1.2.cmml" xref="S4.SS3.SSS0.Px1.p1.1.m1.1.1.2"><ci id="S4.SS3.SSS0.Px1.p1.1.m1.1.1.2.1.cmml" xref="S4.SS3.SSS0.Px1.p1.1.m1.1.1.2.1">⋅</ci><cn id="S4.SS3.SSS0.Px1.p1.1.m1.1.1.2.2.cmml" type="integer" xref="S4.SS3.SSS0.Px1.p1.1.m1.1.1.2.2">1</cn><cn id="S4.SS3.SSS0.Px1.p1.1.m1.1.1.2.3.cmml" type="integer" xref="S4.SS3.SSS0.Px1.p1.1.m1.1.1.2.3">13</cn><cn id="S4.SS3.SSS0.Px1.p1.1.m1.1.1.2.4.cmml" type="integer" xref="S4.SS3.SSS0.Px1.p1.1.m1.1.1.2.4">30</cn></apply><cn id="S4.SS3.SSS0.Px1.p1.1.m1.1.1.3.cmml" type="integer" xref="S4.SS3.SSS0.Px1.p1.1.m1.1.1.3">390</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS0.Px1.p1.1.m1.1c">1\cdot 13\cdot 30=390</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.SSS0.Px1.p1.1.m1.1d">1 ⋅ 13 ⋅ 30 = 390</annotation></semantics></math> images in total. Without pre-training (a.i), the reconstruction completely fails. Pre-training on a single subject (a.ii) leads to a noisy face geometry (see the surface normals in the supp. HTML page). The performance improves when more subjects are added (a.iii and a.iv). We conclude that pre-training is necessary and more data improves the reconstruction quality.</p>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS3.SSS0.Px2">
<h5 class="ltx_title ltx_title_paragraph">Number of Pre-training Steps</h5>
<div class="ltx_para" id="S4.SS3.SSS0.Px2.p1">
<p class="ltx_p" id="S4.SS3.SSS0.Px2.p1.1">We ablate the performance when pre-training for a fewer number of steps. We observe that pre-training for one day only (105K steps, b.i) already achieves very high photo-metric reconstruction quality (PSNR and SSIM). This shorter training duration offers a more accessible alternative while still delivering high-quality outcomes. While short pre-training already yields good results, longer training is required for the best perceptual quality (LPIPS) (b.ii and b.iii).</p>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS3.SSS0.Px3">
<h5 class="ltx_title ltx_title_paragraph">Synthetic Data Quality</h5>
<div class="ltx_para" id="S4.SS3.SSS0.Px3.p1">
<p class="ltx_p" id="S4.SS3.SSS0.Px3.p1.1">We investigate the effects of synthetic data quality in terms of appearance and texture (c.i - c.iv) and geometric diversity (c.v - c.vii). We find that the appearance and texture of the prior model have very little impact on the fine-tuning result but a higher geometry diversity achieves the best results.
Prior models trained on gray-scale and low-quality renderings (c.i and c.ii) perform similarly as training in diverse environments (c.iii) <cite class="ltx_cite ltx_citemacro_citep">(Gardner et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib20" title="">2017</a>; Hold-Geoffroy et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib24" title="">2019</a>)</cite>. Similarly, excluding details like makeup (c.iv) does not deteriorate the performance. However, the diversity in terms of geometry is important for the prior model. When removing hair (c.vi) and other accessories like beards, glasses, and clothing (c.v) from the prior model, the reconstruction still yields a valid face but it may contain some artifacts in non-surface regions like hair. This is notable as a drop in PSNR from 26.54 with all accessories (c.vii) to 26.00 without any accessories (c.v) (please see the supp. mat. for a list of the number of accessories). In summary, we find that the prior acts as a geometric regularization. Including all accessories yields a geometrically diverse prior model with the best results. Rendering even more assets is likely to improve the results for accessories like glasses, earrings, and clothing even further.</p>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS3.SSS0.Px4">
<h5 class="ltx_title ltx_title_paragraph">Including Real Data</h5>
<div class="ltx_para" id="S4.SS3.SSS0.Px4.p1">
<p class="ltx_p" id="S4.SS3.SSS0.Px4.p1.1">We study the synthetic vs. real domain gap by pre-training the prior model on real multi-view images (d.i), a mixed dataset with real and synthetic images (d.ii), and synthetic images alone (d.iii). Priors trained on a real and a mixed dataset perform well but synthetic data alone performs best on all metrics.
This behavior might seem non-intuitive. While it is very difficult to precisely determine why synthetic data outperforms real data, we are not the first to find that synthetic data can outperform real data <cite class="ltx_cite ltx_citemacro_citep">(Wood et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib72" title="">2021</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib73" title="">2022</a>; Yeh et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib79" title="">2022</a>; Sun et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib60" title="">2021</a>; Trevithick et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib64" title="">2023</a>)</cite>. In our experience, real data capture and processing is imperfect compared with synthetic data. Even under controlled conditions, there may be issues like motion blur and imperfect foreground matting.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S4.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4. </span>Limitations</h3>
<div class="ltx_para" id="S4.SS4.p1">
<p class="ltx_p" id="S4.SS4.p1.1">While our method can reconstruct 3D faces from even just one view, we notice that the quality degrades at side views in this extremely challenging case (see Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#S5.F10" title="Figure 10 ‣ Cafca: High-quality Novel View Synthesis of Expressive Faces from Casual Few-shot Captures"><span class="ltx_text ltx_ref_tag">10</span></a>) due to the lack of observation. Accessories like glasses frames and earrings may not be reconstructed perfectly and for extreme expressions, the mouth interior might not be fully consistent across all viewpoints
(see the supp. HTML page). Furthermore, our method assumes that faces are non-occluded in the input images. This can cause the camera estimation during the 3DMM fitting (Sec. <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#S3.SS3.SSS1" title="3.3.1. 3DMM Fitting and Camera Estimation ‣ 3.3. Inference from Sparse Views ‣ 3. Method ‣ Cafca: High-quality Novel View Synthesis of Expressive Faces from Casual Few-shot Captures"><span class="ltx_text ltx_ref_tag">3.3.1</span></a>) to fail. These limitations could be potentially addressed by leveraging large generative models to hallucinate unobserved regions, which is an interesting future direction to explore.
Another direction of future work could explore more efficient backbones to increase pre-training and fine-tuning efficiency, and potentially enable facial animation.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5. </span>Conclusion</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">We present a method for high-fidelity expressive face modeling from as few as three input views captured in the wild. This challenging goal is achieved by leveraging a volumetric face prior and fine-tuning the prior model to sparse observations. Our key insight is that a prior model trained on synthetic data alone can generalize to diverse real-world identities and expressions, bypassing the expensive process of capturing large-scale real-world 3D facial appearances. We experimentally demonstrate that our method can robustly reconstruct expressive faces from sparse or even single-view images with unprecedented fine-scale idiosyncratic details, and achieve superior quality compared to previous state-of-the-art methods for few-shot reconstruction and novel view synthesis.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(1)</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Barron et al<span class="ltx_text" id="bib.bib2.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Jonathan T Barron, Ben Mildenhall, Matthew Tancik, Peter Hedman, Ricardo Martin-Brualla, and Pratul P Srinivasan. 2021.

</span>
<span class="ltx_bibblock">Mip-nerf: A multiscale representation for anti-aliasing neural radiance fields. In <em class="ltx_emph ltx_font_italic" id="bib.bib2.3.1">Proceedings of the IEEE/CVF International Conference on Computer Vision</em>. 5855–5864.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Barron et al<span class="ltx_text" id="bib.bib3.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Jonathan T Barron, Ben Mildenhall, Dor Verbin, Pratul P Srinivasan, and Peter Hedman. 2022.

</span>
<span class="ltx_bibblock">Mip-nerf 360: Unbounded anti-aliased neural radiance fields. In <em class="ltx_emph ltx_font_italic" id="bib.bib3.3.1">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>. 5470–5479.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bednarik et al<span class="ltx_text" id="bib.bib4.2.2.1">.</span> (2024)</span>
<span class="ltx_bibblock">
Jan Bednarik, Erroll Wood, Vassilis Choutas, Timo Bolkart, Daoye Wang, Chenglei Wu, and Thabo Beeler. 2024.

</span>
<span class="ltx_bibblock">Learning to Stabilize Faces.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib4.3.1">Computer Graphics Forum</em> (2024).

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1111/cgf.15038" title="">https://doi.org/10.1111/cgf.15038</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Blanz and Vetter (1999)</span>
<span class="ltx_bibblock">
Volker Blanz and Thomas Vetter. 1999.

</span>
<span class="ltx_bibblock">A morphable model for the synthesis of 3D faces. In <em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">Proceedings of the 26th annual conference on Computer graphics and interactive techniques</em>. 187–194.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Blau and Michaeli (2018)</span>
<span class="ltx_bibblock">
Yochai Blau and Tomer Michaeli. 2018.

</span>
<span class="ltx_bibblock">The perception-distortion tradeoff. In <em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">Proceedings of the IEEE conference on computer vision and pattern recognition</em>. 6228–6237.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bojanowski et al<span class="ltx_text" id="bib.bib7.2.2.1">.</span> (2018)</span>
<span class="ltx_bibblock">
Piotr Bojanowski, Armand Joulin, David Lopez-Paz, and Arthur Szlam. 2018.

</span>
<span class="ltx_bibblock">Optimizing the latent space of generative networks. In <em class="ltx_emph ltx_font_italic" id="bib.bib7.3.1">Proceedings of the 35th International Conference on Machine Learning</em>. 2640–3498.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Buehler et al<span class="ltx_text" id="bib.bib8.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Marcel C. Buehler, Abhimitra Meka, Gengyan Li, Thabo Beeler, and Otmar Hilliges. 2021.

</span>
<span class="ltx_bibblock">VariTex: Variational Neural Face Textures. In <em class="ltx_emph ltx_font_italic" id="bib.bib8.3.1">Proceedings of the IEEE/CVF International Conference on Computer Vision</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Buehler et al<span class="ltx_text" id="bib.bib9.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Marcel C Buehler, Kripasindhu Sarkar, Tanmay Shah, Gengyan Li, Daoye Wang, Leonhard Helminger, Sergio Orts-Escolano, Dmitry Lagun, Otmar Hilliges, Thabo Beeler, et al<span class="ltx_text" id="bib.bib9.3.1">.</span> 2023.

</span>
<span class="ltx_bibblock">Preface: A Data-driven Volumetric Prior for Few-shot Ultra High-resolution Face Synthesis. In <em class="ltx_emph ltx_font_italic" id="bib.bib9.4.1">Proceedings of the IEEE/CVF International Conference on Computer Vision</em>. 3402–3413.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cao et al<span class="ltx_text" id="bib.bib10.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Chen Cao, Tomas Simon, Jin Kyu Kim, Gabe Schwartz, Michael Zollhoefer, Shun-Suke Saito, Stephen Lombardi, Shih-En Wei, Danielle Belko, Shoou-I Yu, et al<span class="ltx_text" id="bib.bib10.3.1">.</span> 2022.

</span>
<span class="ltx_bibblock">Authentic volumetric avatars from a phone scan.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib10.4.1">ACM Transactions on Graphics (TOG)</em> 41, 4 (2022), 1–19.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chan et al<span class="ltx_text" id="bib.bib11.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Eric R Chan, Connor Z Lin, Matthew A Chan, Koki Nagano, Boxiao Pan, Shalini De Mello, Orazio Gallo, Leonidas J Guibas, Jonathan Tremblay, Sameh Khamis, et al<span class="ltx_text" id="bib.bib11.3.1">.</span> 2022.

</span>
<span class="ltx_bibblock">Efficient geometry-aware 3D generative adversarial networks. In <em class="ltx_emph ltx_font_italic" id="bib.bib11.4.1">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>. 16123–16133.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chan et al<span class="ltx_text" id="bib.bib12.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Eric R Chan, Marco Monteiro, Petr Kellnhofer, Jiajun Wu, and Gordon Wetzstein. 2021.

</span>
<span class="ltx_bibblock">pi-gan: Periodic implicit generative adversarial networks for 3d-aware image synthesis. In <em class="ltx_emph ltx_font_italic" id="bib.bib12.3.1">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>. 5799–5809.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al<span class="ltx_text" id="bib.bib13.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Anpei Chen, Zexiang Xu, Fuqiang Zhao, Xiaoshuai Zhang, Fanbo Xiang, Jingyi Yu, and Hao Su. 2021.

</span>
<span class="ltx_bibblock">Mvsnerf: Fast generalizable radiance field reconstruction from multi-view stereo. In <em class="ltx_emph ltx_font_italic" id="bib.bib13.3.1">Proceedings of the IEEE/CVF International Conference on Computer Vision</em>. 14124–14133.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Choi et al<span class="ltx_text" id="bib.bib14.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Yunjey Choi, Youngjung Uh, Jaejun Yoo, and Jung-Woo Ha. 2020.

</span>
<span class="ltx_bibblock">Stargan v2: Diverse image synthesis for multiple domains. In <em class="ltx_emph ltx_font_italic" id="bib.bib14.3.1">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>. 8188–8197.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Deng et al<span class="ltx_text" id="bib.bib15.2.2.1">.</span> (2022a)</span>
<span class="ltx_bibblock">
Yu Deng, Jiaolong Yang, Jianfeng Xiang, and Xin Tong. 2022a.

</span>
<span class="ltx_bibblock">GRAM: Generative Radiance Manifolds for 3D-Aware Image Generation. In <em class="ltx_emph ltx_font_italic" id="bib.bib15.3.1">IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Deng et al<span class="ltx_text" id="bib.bib16.2.2.1">.</span> (2022b)</span>
<span class="ltx_bibblock">
Yu Deng, Jiaolong Yang, Jianfeng Xiang, and Xin Tong. 2022b.

</span>
<span class="ltx_bibblock">GRAM: Generative Radiance Manifolds for 3D-Aware Image Generation. In <em class="ltx_emph ltx_font_italic" id="bib.bib16.3.1">IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Duan et al<span class="ltx_text" id="bib.bib17.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Hao-Bin Duan, Miao Wang, Jin-Chuan Shi, Xu-Chuan Chen, and Yan-Pei Cao. 2023.

</span>
<span class="ltx_bibblock">Bakedavatar: Baking neural fields for real-time head avatar synthesis.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib17.3.1">ACM Transactions on Graphics (TOG)</em> 42, 6 (2023), 1–17.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Finn et al<span class="ltx_text" id="bib.bib18.2.2.1">.</span> (2017)</span>
<span class="ltx_bibblock">
Chelsea Finn, Pieter Abbeel, and Sergey Levine. 2017.

</span>
<span class="ltx_bibblock">Model-agnostic meta-learning for fast adaptation of deep networks. In <em class="ltx_emph ltx_font_italic" id="bib.bib18.3.1">International conference on machine learning</em>. PMLR, 1126–1135.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gao et al<span class="ltx_text" id="bib.bib19.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Chen Gao, Yichang Shih, Wei-Sheng Lai, Chia-Kai Liang, and Jia-Bin Huang. 2020.

</span>
<span class="ltx_bibblock">Portrait neural radiance fields from a single image.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib19.3.1">arXiv preprint arXiv:2012.05903</em> (2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gardner et al<span class="ltx_text" id="bib.bib20.2.2.1">.</span> (2017)</span>
<span class="ltx_bibblock">
Marc-André Gardner, Kalyan Sunkavalli, Ersin Yumer, Xiaohui Shen, Emiliano Gambaretto, Christian Gagné, and Jean-François Lalonde. 2017.

</span>
<span class="ltx_bibblock">Learning to predict indoor illumination from a single image.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib20.3.1">ACM Trans. Graph.</em> 36, 6, Article 176 (nov 2017), 14 pages.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3130800.3130891" title="">https://doi.org/10.1145/3130800.3130891</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gu et al<span class="ltx_text" id="bib.bib21.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Jiatao Gu, Lingjie Liu, Peng Wang, and Christian Theobalt. 2021.

</span>
<span class="ltx_bibblock">Stylenerf: A style-based 3d-aware generator for high-resolution image synthesis.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib21.3.1">arXiv preprint arXiv:2110.08985</em> (2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Guangcong et al<span class="ltx_text" id="bib.bib22.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Guangcong, Zhaoxi Chen, Chen Change Loy, and Ziwei Liu. 2023.

</span>
<span class="ltx_bibblock">SparseNeRF: Distilling Depth Ranking for Few-shot Novel View Synthesis.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib22.3.1">Technical Report</em> (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He et al<span class="ltx_text" id="bib.bib23.2.2.1">.</span> (2015)</span>
<span class="ltx_bibblock">
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2015.

</span>
<span class="ltx_bibblock">Delving deep into rectifiers: Surpassing human-level performance on imagenet classification. In <em class="ltx_emph ltx_font_italic" id="bib.bib23.3.1">Proceedings of the IEEE international conference on computer vision</em>. 1026–1034.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hold-Geoffroy et al<span class="ltx_text" id="bib.bib24.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Yannick Hold-Geoffroy, Akshaya Athawale, and Jean-François Lalonde. 2019.

</span>
<span class="ltx_bibblock">Deep sky modeling for single image outdoor lighting estimation. In <em class="ltx_emph ltx_font_italic" id="bib.bib24.3.1">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</em>. 6927–6935.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hong et al<span class="ltx_text" id="bib.bib25.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Yang Hong, Bo Peng, Haiyao Xiao, Ligang Liu, and Juyong Zhang. 2022.

</span>
<span class="ltx_bibblock">HeadNeRF: A Real-time NeRF-based Parametric Head Model. In <em class="ltx_emph ltx_font_italic" id="bib.bib25.3.1">IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jain et al<span class="ltx_text" id="bib.bib26.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Ajay Jain, Matthew Tancik, and Pieter Abbeel. 2021.

</span>
<span class="ltx_bibblock">Putting NeRF on a Diet: Semantically Consistent Few-Shot View Synthesis. In <em class="ltx_emph ltx_font_italic" id="bib.bib26.3.1">Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)</em>. 5885–5894.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Karras et al<span class="ltx_text" id="bib.bib27.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Tero Karras, Samuli Laine, and Timo Aila. 2019.

</span>
<span class="ltx_bibblock">A style-based generator architecture for generative adversarial networks. In <em class="ltx_emph ltx_font_italic" id="bib.bib27.3.1">Proceedings of the IEEE conference on computer vision and pattern recognition</em>. 4401–4410.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kingma and Ba (2015)</span>
<span class="ltx_bibblock">
Diederik P. Kingma and Jimmy Ba. 2015.

</span>
<span class="ltx_bibblock">Adam: A Method for Stochastic Optimization. In <em class="ltx_emph ltx_font_italic" id="bib.bib28.1.1">ICLR</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kirschstein et al<span class="ltx_text" id="bib.bib29.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Tobias Kirschstein, Shenhan Qian, Simon Giebenhain, Tim Walter, and Matthias Nießner. 2023.

</span>
<span class="ltx_bibblock">NeRSemble: Multi-View Radiance Field Reconstruction of Human Heads.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib29.3.1">ACM Trans. Graph.</em> 42, 4, Article 161 (jul 2023), 14 pages.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3592455" title="">https://doi.org/10.1145/3592455</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kret (2015)</span>
<span class="ltx_bibblock">
Mariska E. Kret. 2015.

</span>
<span class="ltx_bibblock">Emotional expressions beyond facial muscle actions. A call for studying autonomic signals and their impact on social perception.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib30.1.1">Frontiers in Psychology</em> 6 (2015).

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.3389/fpsyg.2015.00711" title="">https://doi.org/10.3389/fpsyg.2015.00711</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kundu et al<span class="ltx_text" id="bib.bib31.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Abhijit Kundu, Kyle Genova, Xiaoqi Yin, Alireza Fathi, Caroline Pantofaru, Leonidas J Guibas, Andrea Tagliasacchi, Frank Dellaert, and Thomas Funkhouser. 2022.

</span>
<span class="ltx_bibblock">Panoptic neural fields: A semantic object-aware neural scene representation. In <em class="ltx_emph ltx_font_italic" id="bib.bib31.3.1">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>. 12871–12881.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lee and Anderson (2017)</span>
<span class="ltx_bibblock">
Daniel H Lee and Adam K Anderson. 2017.

</span>
<span class="ltx_bibblock">Reading what the mind thinks from how the eye sees.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib32.1.1">Psychological science</em> 28, 4 (2017), 494–503.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al<span class="ltx_text" id="bib.bib33.2.2.1">.</span> (2024)</span>
<span class="ltx_bibblock">
Gengyan Li, Kripasindhu Sarkar, Abhimitra Meka, Marcel Buehler, Franziska Mueller, Paulo Gotardo, Otmar Hilliges, and Thabo Beeler. 2024.

</span>
<span class="ltx_bibblock">ShellNeRF: Learning a Controllable High-resolution Model of the Eye and Periocular Region. In <em class="ltx_emph ltx_font_italic" id="bib.bib33.3.1">Computer Graphics Forum</em>, Vol. 43. Wiley Online Library, e15041.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al<span class="ltx_text" id="bib.bib34.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Ruoshi Liu, Rundi Wu, Basile Van Hoorick, Pavel Tokmakov, Sergey Zakharov, and Carl Vondrick. 2023.

</span>
<span class="ltx_bibblock">Zero-1-to-3: Zero-shot one image to 3d object. In <em class="ltx_emph ltx_font_italic" id="bib.bib34.3.1">Proceedings of the IEEE/CVF International Conference on Computer Vision</em>. 9298–9309.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al<span class="ltx_text" id="bib.bib35.2.2.1">.</span> (2018)</span>
<span class="ltx_bibblock">
Ziwei Liu, Ping Luo, Xiaogang Wang, and Xiaoou Tang. 2018.

</span>
<span class="ltx_bibblock">Large-scale celebfaces attributes (celeba) dataset.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib35.3.1">Retrieved August</em> 15, 2018 (2018), 11.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lombardi et al<span class="ltx_text" id="bib.bib36.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Stephen Lombardi, Tomas Simon, Gabriel Schwartz, Michael Zollhoefer, Yaser Sheikh, and Jason Saragih. 2021.

</span>
<span class="ltx_bibblock">Mixture of Volumetric Primitives for Efficient Neural Rendering.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib36.3.1">ACM Trans. Graph.</em> 40, 4, Article 59 (jul 2021), 13 pages.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3450626.3459863" title="">https://doi.org/10.1145/3450626.3459863</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Massague et al<span class="ltx_text" id="bib.bib37.2.2.1">.</span> (2024)</span>
<span class="ltx_bibblock">
Armand Comas Massague, Di Qiu, Menglei Chai, Marcel C. Buehler, Amit Raj, Ruiqi Gao, Qiangeng Xu, Mark Matthews, Paulo F. U. Gotardo, Octavia Camps, Sergio Orts, and Thabo Beeler. 2024.

</span>
<span class="ltx_bibblock">MagicMirror: Fast and High-Quality Avatar Generation with a Constrained Search Space. In <em class="ltx_emph ltx_font_italic" id="bib.bib37.3.1">Proceedings of the European conference on computer vision (ECCV)</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Melas-Kyriazi et al<span class="ltx_text" id="bib.bib38.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Luke Melas-Kyriazi, Iro Laina, Christian Rupprecht, and Andrea Vedaldi. 2023.

</span>
<span class="ltx_bibblock">Realfusion: 360deg reconstruction of any object from a single image. In <em class="ltx_emph ltx_font_italic" id="bib.bib38.3.1">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</em>. 8446–8455.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mihajlovic et al<span class="ltx_text" id="bib.bib39.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Marko Mihajlovic, Aayush Bansal, Michael Zollhoefer, Siyu Tang, and Shunsuke Saito. 2022.

</span>
<span class="ltx_bibblock">KeypointNeRF: Generalizing Image-based Volumetric Avatars using Relative Spatial Encoding of Keypoints. In <em class="ltx_emph ltx_font_italic" id="bib.bib39.3.1">European conference on computer vision</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mildenhall et al<span class="ltx_text" id="bib.bib40.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Ben Mildenhall, Pratul P Srinivasan, Matthew Tancik, Jonathan T Barron, Ravi Ramamoorthi, and Ren Ng. 2020.

</span>
<span class="ltx_bibblock">Nerf: Representing scenes as neural radiance fields for view synthesis. In <em class="ltx_emph ltx_font_italic" id="bib.bib40.3.1">European Conference on Computer Vision</em>. Springer, 405–421.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nichol et al<span class="ltx_text" id="bib.bib41.2.2.1">.</span> (2018)</span>
<span class="ltx_bibblock">
Alex Nichol, Joshua Achiam, and John Schulman. 2018.

</span>
<span class="ltx_bibblock">On first-order meta-learning algorithms.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib41.3.1">arXiv preprint arXiv:1803.02999</em> (2018).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Niemeyer et al<span class="ltx_text" id="bib.bib42.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Michael Niemeyer, Jonathan T. Barron, Ben Mildenhall, Mehdi S. M. Sajjadi, Andreas Geiger, and Noha Radwan. 2022.

</span>
<span class="ltx_bibblock">RegNeRF: Regularizing Neural Radiance Fields for View Synthesis from Sparse Inputs. In <em class="ltx_emph ltx_font_italic" id="bib.bib42.3.1">Proc. IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Niemeyer and Geiger (2021)</span>
<span class="ltx_bibblock">
Michael Niemeyer and Andreas Geiger. 2021.

</span>
<span class="ltx_bibblock">Giraffe: Representing scenes as compositional generative neural feature fields. In <em class="ltx_emph ltx_font_italic" id="bib.bib43.1.1">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>. 11453–11464.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Or-El et al<span class="ltx_text" id="bib.bib44.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Roy Or-El, Xuan Luo, Mengyi Shan, Eli Shechtman, Jeong Joon Park, and Ira Kemelmacher-Shlizerman. 2022.

</span>
<span class="ltx_bibblock">Stylesdf: High-resolution 3d-consistent image and geometry generation. In <em class="ltx_emph ltx_font_italic" id="bib.bib44.3.1">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>. 13503–13513.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pandey et al<span class="ltx_text" id="bib.bib45.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Rohit Pandey, Sergio Orts Escolano, Chloe Legendre, Christian Haene, Sofien Bouaziz, Christoph Rhemann, Paul Debevec, and Sean Fanello. 2021.

</span>
<span class="ltx_bibblock">Total relighting: learning to relight portraits for background replacement.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib45.3.1">ACM Transactions on Graphics (TOG)</em> 40, 4 (2021), 1–21.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib46">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Papantoniou et al<span class="ltx_text" id="bib.bib46.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Foivos Paraperas Papantoniou, Alexandros Lattas, Stylianos Moschoglou, and Stefanos Zafeiriou. 2023.

</span>
<span class="ltx_bibblock">Relightify: Relightable 3d faces from a single image via diffusion models. In <em class="ltx_emph ltx_font_italic" id="bib.bib46.3.1">Proceedings of the IEEE/CVF International Conference on Computer Vision</em>. 8806–8817.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib47">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Park et al<span class="ltx_text" id="bib.bib47.2.2.1">.</span> (2021a)</span>
<span class="ltx_bibblock">
Keunhong Park, Utkarsh Sinha, Jonathan T. Barron, Sofien Bouaziz, Dan B Goldman, Steven M. Seitz, and Ricardo Martin-Brualla. 2021a.

</span>
<span class="ltx_bibblock">Nerfies: Deformable Neural Radiance Fields.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib47.3.1">ICCV</em> (2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib48">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Park et al<span class="ltx_text" id="bib.bib48.2.2.1">.</span> (2021b)</span>
<span class="ltx_bibblock">
Keunhong Park, Utkarsh Sinha, Peter Hedman, Jonathan T. Barron, Sofien Bouaziz, Dan B Goldman, Ricardo Martin-Brualla, and Steven M. Seitz. 2021b.

</span>
<span class="ltx_bibblock">HyperNeRF: A Higher-Dimensional Representation for Topologically Varying Neural Radiance Fields.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib48.3.1">ACM Trans. Graph.</em> 40, 6, Article 238 (dec 2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib49">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pascalis and Kelly (2009)</span>
<span class="ltx_bibblock">
Olivier Pascalis and David J Kelly. 2009.

</span>
<span class="ltx_bibblock">The origins of face processing in humans: Phylogeny and ontogeny.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib49.1.1">Perspectives on psychological science</em> 4, 2 (2009), 200–209.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib50">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Poole et al<span class="ltx_text" id="bib.bib50.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Ben Poole, Ajay Jain, Jonathan T. Barron, and Ben Mildenhall. 2022.

</span>
<span class="ltx_bibblock">DreamFusion: Text-to-3D using 2D Diffusion.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib50.3.1">arXiv</em> (2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib51">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Prinzler et al<span class="ltx_text" id="bib.bib51.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Malte Prinzler, Otmar Hilliges, and Justus Thies. 2023.

</span>
<span class="ltx_bibblock">Diner: Depth-aware image-based neural radiance fields. In <em class="ltx_emph ltx_font_italic" id="bib.bib51.3.1">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>. 12449–12459.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib52">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ramon et al<span class="ltx_text" id="bib.bib52.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Eduard Ramon, Gil Triginer, Janna Escur, Albert Pumarola, Jaime Garcia, Xavier Giro-i Nieto, and Francesc Moreno-Noguer. 2021.

</span>
<span class="ltx_bibblock">H3d-net: Few-shot high-fidelity 3d head reconstruction. In <em class="ltx_emph ltx_font_italic" id="bib.bib52.3.1">Proceedings of the IEEE/CVF International Conference on Computer Vision</em>. 5620–5629.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib53">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rao et al<span class="ltx_text" id="bib.bib53.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Pramod Rao, Mallikarjun B R, Gereon Fox, Tim Weyrich, Bernd Bickel, Hans-Peter Seidel, Hanspeter Pfister, Wojciech Matusik, Ayush Tewari, Christian Theobalt, and Mohamed Elgharib. 2022.

</span>
<span class="ltx_bibblock">VoRF: Volumetric Relightable Faces.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib53.3.1">British Machine Vision Conference (BMVC)</em> (2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib54">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rebain et al<span class="ltx_text" id="bib.bib54.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Daniel Rebain, Mark Matthews, Kwang Moo Yi, Dmitry Lagun, and Andrea Tagliasacchi. 2022.

</span>
<span class="ltx_bibblock">Lolnerf: Learn from one look. In <em class="ltx_emph ltx_font_italic" id="bib.bib54.3.1">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>. 1558–1567.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib55">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sarkar et al<span class="ltx_text" id="bib.bib55.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Kripasindhu Sarkar, Marcel C Bühler, Gengyan Li, Daoye Wang, Delio Vicini, Jérémy Riviere, Yinda Zhang, Sergio Orts-Escolano, Paulo Gotardo, Thabo Beeler, et al<span class="ltx_text" id="bib.bib55.3.1">.</span> 2023.

</span>
<span class="ltx_bibblock">LitNeRF: Intrinsic Radiance Decomposition for High-Quality View Synthesis and Relighting of Faces. In <em class="ltx_emph ltx_font_italic" id="bib.bib55.4.1">SIGGRAPH Asia 2023 Conference Papers</em>. 1–11.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib56">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Schwarz et al<span class="ltx_text" id="bib.bib56.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Katja Schwarz, Yiyi Liao, Michael Niemeyer, and Andreas Geiger. 2020.

</span>
<span class="ltx_bibblock">Graf: Generative radiance fields for 3d-aware image synthesis.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib56.3.1">Advances in Neural Information Processing Systems</em> 33 (2020), 20154–20166.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib57">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Simonyan and Zisserman (2015)</span>
<span class="ltx_bibblock">
Karen Simonyan and Andrew Zisserman. 2015.

</span>
<span class="ltx_bibblock">Very deep convolutional networks for large-scale image recognition. In <em class="ltx_emph ltx_font_italic" id="bib.bib57.1.1">International Conference on Learning Representations (ICLR)</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib58">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sinha et al<span class="ltx_text" id="bib.bib58.2.2.1">.</span> (2006)</span>
<span class="ltx_bibblock">
Pawan Sinha, Benjamin Balas, Yuri Ostrovsky, and Richard Russell. 2006.

</span>
<span class="ltx_bibblock">Face Recognition by Humans: Nineteen Results All Computer Vision Researchers Should Know About.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib58.3.1">Proc. IEEE</em> 94, 11 (2006), 1948–1962.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1109/JPROC.2006.884093" title="">https://doi.org/10.1109/JPROC.2006.884093</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib59">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sitzmann et al<span class="ltx_text" id="bib.bib59.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Vincent Sitzmann, Eric Chan, Richard Tucker, Noah Snavely, and Gordon Wetzstein. 2020.

</span>
<span class="ltx_bibblock">Metasdf: Meta-learning signed distance functions.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib59.3.1">Advances in Neural Information Processing Systems</em> 33 (2020), 10136–10147.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib60">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sun et al<span class="ltx_text" id="bib.bib60.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Tiancheng Sun, Kai-En Lin, Sai Bi, Zexiang Xu, and Ravi Ramamoorthi. 2021.

</span>
<span class="ltx_bibblock">NeLF: Neural Light-transport Field for Portrait View Synthesis and Relighting. In <em class="ltx_emph ltx_font_italic" id="bib.bib60.3.1">Eurographics Symposium on Rendering</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib61">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tan et al<span class="ltx_text" id="bib.bib61.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Feitong Tan, Sean Fanello, Abhimitra Meka, Sergio Orts-Escolano, Danhang Tang, Rohit Pandey, Jonathan Taylor, Ping Tan, and Yinda Zhang. 2022.

</span>
<span class="ltx_bibblock">VoLux-GAN: A Generative Model for 3D Face Synthesis with HDRI Relighting. In <em class="ltx_emph ltx_font_italic" id="bib.bib61.3.1">ACM SIGGRAPH 2022 Conference Proceedings</em> (Vancouver, BC, Canada) <em class="ltx_emph ltx_font_italic" id="bib.bib61.4.2">(SIGGRAPH ’22)</em>. Association for Computing Machinery, New York, NY, USA, Article 58, 9 pages.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3528233.3530751" title="">https://doi.org/10.1145/3528233.3530751</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib62">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tancik et al<span class="ltx_text" id="bib.bib62.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Matthew Tancik, Ben Mildenhall, Terrance Wang, Divi Schmidt, Pratul P Srinivasan, Jonathan T Barron, and Ren Ng. 2021.

</span>
<span class="ltx_bibblock">Learned initializations for optimizing coordinate-based neural representations. In <em class="ltx_emph ltx_font_italic" id="bib.bib62.3.1">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>. 2846–2855.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib63">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tang et al<span class="ltx_text" id="bib.bib63.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Junshu Tang, Tengfei Wang, Bo Zhang, Ting Zhang, Ran Yi, Lizhuang Ma, and Dong Chen. 2023.

</span>
<span class="ltx_bibblock">Make-it-3d: High-fidelity 3d creation from a single image with diffusion prior. In <em class="ltx_emph ltx_font_italic" id="bib.bib63.3.1">Proceedings of the IEEE/CVF International Conference on Computer Vision</em>. 22819–22829.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib64">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Trevithick et al<span class="ltx_text" id="bib.bib64.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Alex Trevithick, Matthew Chan, Michael Stengel, Eric R. Chan, Chao Liu, Zhiding Yu, Sameh Khamis, Manmohan Chandraker, Ravi Ramamoorthi, and Koki Nagano. 2023.

</span>
<span class="ltx_bibblock">Real-Time Radiance Fields for Single-Image Portrait View Synthesis. In <em class="ltx_emph ltx_font_italic" id="bib.bib64.3.1">ACM Transactions on Graphics (SIGGRAPH)</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib65">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Truong et al<span class="ltx_text" id="bib.bib65.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Prune Truong, Marie-Julie Rakotosaona, Fabian Manhardt, and Federico Tombari. 2023.

</span>
<span class="ltx_bibblock">SPARF: Neural Radiance Fields from Sparse and Noisy Poses. IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib66">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vinod et al<span class="ltx_text" id="bib.bib66.2.2.1">.</span> (2024)</span>
<span class="ltx_bibblock">
Vishal Vinod, Tanmay Shah, and Dmitry Lagun. 2024.

</span>
<span class="ltx_bibblock">TEGLO: High Fidelity Canonical Texture Mapping from Single-View Images. In <em class="ltx_emph ltx_font_italic" id="bib.bib66.3.1">Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision</em>. 3585–3595.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib67">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vora et al<span class="ltx_text" id="bib.bib67.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Suhani Vora, Noha Radwan, Klaus Greff, Henning Meyer, Kyle Genova, Mehdi SM Sajjadi, Etienne Pot, Andrea Tagliasacchi, and Daniel Duckworth. 2021.

</span>
<span class="ltx_bibblock">Nesf: Neural semantic fields for generalizable semantic segmentation of 3d scenes.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib67.3.1">arXiv preprint arXiv:2111.13260</em> (2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib68">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al<span class="ltx_text" id="bib.bib68.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Daoye Wang, Prashanth Chandran, Gaspard Zoss, Derek Bradley, and Paulo Gotardo. 2022.

</span>
<span class="ltx_bibblock">MoRF: Morphable Radiance Fields for Multiview Neural Head Modeling. In <em class="ltx_emph ltx_font_italic" id="bib.bib68.3.1">ACM SIGGRAPH 2022 Conference Proceedings</em> (Vancouver, BC, Canada) <em class="ltx_emph ltx_font_italic" id="bib.bib68.4.2">(SIGGRAPH ’22)</em>. Association for Computing Machinery, New York, NY, USA, Article 55, 9 pages.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3528233.3530753" title="">https://doi.org/10.1145/3528233.3530753</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib69">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al<span class="ltx_text" id="bib.bib69.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Qianqian Wang, Zhicheng Wang, Kyle Genova, Pratul Srinivasan, Howard Zhou, Jonathan T. Barron, Ricardo Martin-Brualla, Noah Snavely, and Thomas Funkhouser. 2021.

</span>
<span class="ltx_bibblock">IBRNet: Learning Multi-View Image-Based Rendering. In <em class="ltx_emph ltx_font_italic" id="bib.bib69.3.1">CVPR</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib70">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al<span class="ltx_text" id="bib.bib70.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Tengfei Wang, Bo Zhang, Ting Zhang, Shuyang Gu, Jianmin Bao, Tadas Baltrusaitis, Jingjing Shen, Dong Chen, Fang Wen, Qifeng Chen, et al<span class="ltx_text" id="bib.bib70.3.1">.</span> 2023.

</span>
<span class="ltx_bibblock">Rodin: A generative model for sculpting 3d digital avatars using diffusion. In <em class="ltx_emph ltx_font_italic" id="bib.bib70.4.1">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>. 4563–4573.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib71">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al<span class="ltx_text" id="bib.bib71.2.2.1">.</span> (2024)</span>
<span class="ltx_bibblock">
Zhengyi Wang, Cheng Lu, Yikai Wang, Fan Bao, Chongxuan Li, Hang Su, and Jun Zhu. 2024.

</span>
<span class="ltx_bibblock">Prolificdreamer: High-fidelity and diverse text-to-3d generation with variational score distillation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib71.3.1">Advances in Neural Information Processing Systems</em> 36 (2024).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib72">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wood et al<span class="ltx_text" id="bib.bib72.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Erroll Wood, Tadas Baltrušaitis, Charlie Hewitt, Sebastian Dziadzio, Thomas J Cashman, and Jamie Shotton. 2021.

</span>
<span class="ltx_bibblock">Fake it till you make it: face analysis in the wild using synthetic data alone. In <em class="ltx_emph ltx_font_italic" id="bib.bib72.3.1">Proceedings of the IEEE/CVF international conference on computer vision</em>. 3681–3691.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib73">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wood et al<span class="ltx_text" id="bib.bib73.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Erroll Wood, Tadas Baltrušaitis, Charlie Hewitt, Matthew Johnson, Jingjing Shen, Nikola Milosavljević, Daniel Wilde, Stephan Garbin, Toby Sharp, Ivan Stojiljković, et al<span class="ltx_text" id="bib.bib73.3.1">.</span> 2022.

</span>
<span class="ltx_bibblock">3d face reconstruction with dense landmarks. In <em class="ltx_emph ltx_font_italic" id="bib.bib73.4.1">European Conference on Computer Vision</em>. Springer, 160–177.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib74">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu et al<span class="ltx_text" id="bib.bib74.2.2.1">.</span> (2024)</span>
<span class="ltx_bibblock">
Rundi Wu, Ben Mildenhall, Philipp Henzler, Keunhong Park, Ruiqi Gao, Daniel Watson, Pratul P Srinivasan, Dor Verbin, Jonathan T Barron, Ben Poole, et al<span class="ltx_text" id="bib.bib74.3.1">.</span> 2024.

</span>
<span class="ltx_bibblock">Reconfusion: 3d reconstruction with diffusion priors. In <em class="ltx_emph ltx_font_italic" id="bib.bib74.4.1">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>. 21551–21561.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib75">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wuu et al<span class="ltx_text" id="bib.bib75.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Cheng-hsin Wuu, Ningyuan Zheng, Scott Ardisson, Rohan Bali, Danielle Belko, Eric Brockmeyer, Lucas Evans, Timothy Godisart, Hyowon Ha, Xuhua Huang, Alexander Hypes, Taylor Koska, Steven Krenn, Stephen Lombardi, Xiaomin Luo, Kevyn McPhail, Laura Millerschoen, Michal Perdoch, Mark Pitts, Alexander Richard, Jason Saragih, Junko Saragih, Takaaki Shiratori, Tomas Simon, Matt Stewart, Autumn Trimble, Xinshuo Weng, David Whitewolf, Chenglei Wu, Shoou-I Yu, and
Yaser Sheikh. 2022.

</span>
<span class="ltx_bibblock">Multiface: A Dataset for Neural Face Rendering. In <em class="ltx_emph ltx_font_italic" id="bib.bib75.3.1">arXiv</em>.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.48550/ARXIV.2207.11243" title="">https://doi.org/10.48550/ARXIV.2207.11243</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib76">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu et al<span class="ltx_text" id="bib.bib76.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Dejia Xu, Yifan Jiang, Peihao Wang, Zhiwen Fan, Humphrey Shi, and Zhangyang Wang. 2022.

</span>
<span class="ltx_bibblock">Sinnerf: Training neural radiance fields on complex scenes from a single image. In <em class="ltx_emph ltx_font_italic" id="bib.bib76.3.1">Computer Vision–ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23–27, 2022, Proceedings, Part XXII</em>. Springer, 736–753.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib77">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu et al<span class="ltx_text" id="bib.bib77.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Yuelang Xu, Hongwen Zhang, Lizhen Wang, Xiaochen Zhao, Han Huang, Guojun Qi, and Yebin Liu. 2023.

</span>
<span class="ltx_bibblock">Latentavatar: Learning latent expression code for expressive neural head avatar. In <em class="ltx_emph ltx_font_italic" id="bib.bib77.3.1">ACM SIGGRAPH 2023 Conference Proceedings</em>. 1–10.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib78">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et al<span class="ltx_text" id="bib.bib78.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Jiawei Yang, Marco Pavone, and Yue Wang. 2023.

</span>
<span class="ltx_bibblock">FreeNeRF: Improving Few-shot Neural Rendering with Free Frequency Regularization. In <em class="ltx_emph ltx_font_italic" id="bib.bib78.3.1">Proc. IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib79">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yeh et al<span class="ltx_text" id="bib.bib79.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Yu-Ying Yeh, Koki Nagano, Sameh Khamis, Jan Kautz, Ming-Yu Liu, and Ting-Chun Wang. 2022.

</span>
<span class="ltx_bibblock">Learning to Relight Portrait Images via a Virtual Light Stage and Synthetic-to-Real Adaptation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib79.3.1">ACM Transactions on Graphics (TOG)</em> (2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib80">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu et al<span class="ltx_text" id="bib.bib80.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Alex Yu, Vickie Ye, Matthew Tancik, and Angjoo Kanazawa. 2021.

</span>
<span class="ltx_bibblock">pixelNeRF: Neural Radiance Fields from One or Few Images. In <em class="ltx_emph ltx_font_italic" id="bib.bib80.3.1">CVPR</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib81">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zakharov et al<span class="ltx_text" id="bib.bib81.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Egor Zakharov, Aliaksandra Shysheya, Egor Burkov, and Victor Lempitsky. 2019.

</span>
<span class="ltx_bibblock">Few-Shot Adversarial Learning of Realistic Neural Talking Head Models. In <em class="ltx_emph ltx_font_italic" id="bib.bib81.3.1">Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib82">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zeng et al<span class="ltx_text" id="bib.bib82.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Yifei Zeng, Yuanxun Lu, Xinya Ji, Yao Yao, Hao Zhu, and Xun Cao. 2023.

</span>
<span class="ltx_bibblock">Avatarbooth: High-quality and customizable 3d human avatar generation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib82.3.1">arXiv preprint arXiv:2306.09864</em> (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib83">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al<span class="ltx_text" id="bib.bib83.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Jingbo Zhang, Xiaoyu Li, Ziyu Wan, Can Wang, and Jing Liao. 2022.

</span>
<span class="ltx_bibblock">Fdnerf: Few-shot dynamic neural radiance fields for face reconstruction and expression editing. In <em class="ltx_emph ltx_font_italic" id="bib.bib83.3.1">SIGGRAPH Asia 2022 Conference Papers</em>. 1–9.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib84">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al<span class="ltx_text" id="bib.bib84.2.2.1">.</span> (2018)</span>
<span class="ltx_bibblock">
Richard Zhang, Phillip Isola, Alexei A Efros, Eli Shechtman, and Oliver Wang. 2018.

</span>
<span class="ltx_bibblock">The Unreasonable Effectiveness of Deep Features as a Perceptual Metric. In <em class="ltx_emph ltx_font_italic" id="bib.bib84.3.1">CVPR</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib85">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao et al<span class="ltx_text" id="bib.bib85.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Xiaochen Zhao, Lizhen Wang, Jingxiang Sun, Hongwen Zhang, Jinli Suo, and Yebin Liu. 2023.

</span>
<span class="ltx_bibblock">Havatar: High-fidelity head avatar via facial model conditioned neural radiance field.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib85.3.1">ACM Transactions on Graphics</em> 43, 1 (2023), 1–16.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib86">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zheng et al<span class="ltx_text" id="bib.bib86.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Yufeng Zheng, Victoria Fernández Abrevaya, Marcel C Bühler, Xu Chen, Michael J Black, and Otmar Hilliges. 2022.

</span>
<span class="ltx_bibblock">Im avatar: Implicit morphable head avatars from videos. In <em class="ltx_emph ltx_font_italic" id="bib.bib86.3.1">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>. 13545–13555.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib87">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zheng et al<span class="ltx_text" id="bib.bib87.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Yufeng Zheng, Wang Yifan, Gordon Wetzstein, Michael J Black, and Otmar Hilliges. 2023.

</span>
<span class="ltx_bibblock">Pointavatar: Deformable point-based head avatars from videos. In <em class="ltx_emph ltx_font_italic" id="bib.bib87.3.1">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</em>. 21057–21067.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib88">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou et al<span class="ltx_text" id="bib.bib88.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Peng Zhou, Lingxi Xie, Bingbing Ni, and Qi Tian. 2021.

</span>
<span class="ltx_bibblock">CIPS-3D: A 3D-Aware Generator of GANs Based on Conditionally-Independent Pixel Synthesis.

</span>
<span class="ltx_bibblock">(2021).

</span>
<span class="ltx_bibblock">arXiv:2110.09788

</span>
</li>
<li class="ltx_bibitem" id="bib.bib89">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhu et al<span class="ltx_text" id="bib.bib89.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Hao Zhu, Haotian Yang, Longwei Guo, Yidi Zhang, Yanru Wang, Mingkai Huang, Menghua Wu, Qiu Shen, Ruigang Yang, and Xun Cao. 2023.

</span>
<span class="ltx_bibblock">FaceScape: 3D Facial Dataset and Benchmark for Single-View 3D Face Reconstruction.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib89.3.1">IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</em> (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
</ul>
</section>
<figure class="ltx_figure" id="S5.F7">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S5.F7.25.25">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.F7.8.8.8">
<td class="ltx_td ltx_align_center" id="S5.F7.1.1.1.1" style="padding-left:2.0pt;padding-right:2.0pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_portrait" height="133" id="S5.F7.1.1.1.1.g1" src="extracted/5891401/figures/main_comparison/gt_train/multiface_002539136_E006_Jaw_Drop_Brows_Up_input.jpg" width="87"/></td>
<td class="ltx_td ltx_align_center" id="S5.F7.2.2.2.2" style="padding-left:2.0pt;padding-right:2.0pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_portrait" height="933" id="S5.F7.2.2.2.2.g1" src="extracted/5891401/figures/main_comparison/sparsenerf_0_concat.jpg" width="512"/></td>
<td class="ltx_td ltx_align_center" id="S5.F7.3.3.3.3" style="padding-left:2.0pt;padding-right:2.0pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_portrait" height="933" id="S5.F7.3.3.3.3.g1" src="extracted/5891401/figures/main_comparison/sparf_0_concat.jpg" width="512"/></td>
<td class="ltx_td ltx_align_center" id="S5.F7.4.4.4.4" style="padding-left:2.0pt;padding-right:2.0pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_portrait" height="933" id="S5.F7.4.4.4.4.g1" src="extracted/5891401/figures/main_comparison/diner_0_concat.jpg" width="512"/></td>
<td class="ltx_td ltx_align_center" id="S5.F7.5.5.5.5" style="padding-left:2.0pt;padding-right:2.0pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_portrait" height="933" id="S5.F7.5.5.5.5.g1" src="extracted/5891401/figures/main_comparison/freenerf_0_concat.jpg" width="512"/></td>
<td class="ltx_td ltx_align_center" id="S5.F7.6.6.6.6" style="padding-left:2.0pt;padding-right:2.0pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_portrait" height="933" id="S5.F7.6.6.6.6.g1" src="extracted/5891401/figures/main_comparison/preface_0_concat.jpg" width="512"/></td>
<td class="ltx_td ltx_align_center" id="S5.F7.7.7.7.7" style="padding-left:2.0pt;padding-right:2.0pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_portrait" height="933" id="S5.F7.7.7.7.7.g1" src="extracted/5891401/figures/main_comparison/ours_0_concat.jpg" width="512"/></td>
<td class="ltx_td ltx_align_center" id="S5.F7.8.8.8.8" style="padding-left:2.0pt;padding-right:2.0pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_portrait" height="933" id="S5.F7.8.8.8.8.g1" src="extracted/5891401/figures/main_comparison/gt_0_concat.jpg" width="512"/></td>
</tr>
<tr class="ltx_tr" id="S5.F7.16.16.16">
<td class="ltx_td ltx_align_center" id="S5.F7.9.9.9.1" style="padding-left:2.0pt;padding-right:2.0pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_portrait" height="133" id="S5.F7.9.9.9.1.g1" src="extracted/5891401/figures/main_comparison/gt_train/multiface_7889059_E010_Smile_Stretched_input.jpg" width="87"/></td>
<td class="ltx_td ltx_align_center" id="S5.F7.10.10.10.2" style="padding-left:2.0pt;padding-right:2.0pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_portrait" height="933" id="S5.F7.10.10.10.2.g1" src="extracted/5891401/figures/main_comparison/sparsenerf_1_concat.jpg" width="512"/></td>
<td class="ltx_td ltx_align_center" id="S5.F7.11.11.11.3" style="padding-left:2.0pt;padding-right:2.0pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_portrait" height="933" id="S5.F7.11.11.11.3.g1" src="extracted/5891401/figures/main_comparison/sparf_1_concat.jpg" width="512"/></td>
<td class="ltx_td ltx_align_center" id="S5.F7.12.12.12.4" style="padding-left:2.0pt;padding-right:2.0pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_portrait" height="933" id="S5.F7.12.12.12.4.g1" src="extracted/5891401/figures/main_comparison/diner_1_concat.jpg" width="512"/></td>
<td class="ltx_td ltx_align_center" id="S5.F7.13.13.13.5" style="padding-left:2.0pt;padding-right:2.0pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_portrait" height="933" id="S5.F7.13.13.13.5.g1" src="extracted/5891401/figures/main_comparison/freenerf_1_concat.jpg" width="512"/></td>
<td class="ltx_td ltx_align_center" id="S5.F7.14.14.14.6" style="padding-left:2.0pt;padding-right:2.0pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_portrait" height="933" id="S5.F7.14.14.14.6.g1" src="extracted/5891401/figures/main_comparison/preface_1_concat.jpg" width="512"/></td>
<td class="ltx_td ltx_align_center" id="S5.F7.15.15.15.7" style="padding-left:2.0pt;padding-right:2.0pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_portrait" height="933" id="S5.F7.15.15.15.7.g1" src="extracted/5891401/figures/main_comparison/ours_1_concat.jpg" width="512"/></td>
<td class="ltx_td ltx_align_center" id="S5.F7.16.16.16.8" style="padding-left:2.0pt;padding-right:2.0pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_portrait" height="933" id="S5.F7.16.16.16.8.g1" src="extracted/5891401/figures/main_comparison/gt_1_concat.jpg" width="512"/></td>
</tr>
<tr class="ltx_tr" id="S5.F7.24.24.24">
<td class="ltx_td ltx_align_center" id="S5.F7.17.17.17.1" style="padding-left:2.0pt;padding-right:2.0pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_portrait" height="133" id="S5.F7.17.17.17.1.g1" src="extracted/5891401/figures/main_comparison/gt_train/multiface_002757580_E042_Mouth_Nose_Left_input.jpg" width="87"/></td>
<td class="ltx_td ltx_align_center" id="S5.F7.18.18.18.2" style="padding-left:2.0pt;padding-right:2.0pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_portrait" height="933" id="S5.F7.18.18.18.2.g1" src="extracted/5891401/figures/main_comparison/sparsenerf_2_concat.jpg" width="512"/></td>
<td class="ltx_td ltx_align_center" id="S5.F7.19.19.19.3" style="padding-left:2.0pt;padding-right:2.0pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_portrait" height="933" id="S5.F7.19.19.19.3.g1" src="extracted/5891401/figures/main_comparison/sparf_2_concat.jpg" width="512"/></td>
<td class="ltx_td ltx_align_center" id="S5.F7.20.20.20.4" style="padding-left:2.0pt;padding-right:2.0pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_portrait" height="933" id="S5.F7.20.20.20.4.g1" src="extracted/5891401/figures/main_comparison/diner_2_concat.jpg" width="512"/></td>
<td class="ltx_td ltx_align_center" id="S5.F7.21.21.21.5" style="padding-left:2.0pt;padding-right:2.0pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_portrait" height="933" id="S5.F7.21.21.21.5.g1" src="extracted/5891401/figures/main_comparison/freenerf_2_concat.jpg" width="512"/></td>
<td class="ltx_td ltx_align_center" id="S5.F7.22.22.22.6" style="padding-left:2.0pt;padding-right:2.0pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_portrait" height="933" id="S5.F7.22.22.22.6.g1" src="extracted/5891401/figures/main_comparison/preface_2_concat.jpg" width="512"/></td>
<td class="ltx_td ltx_align_center" id="S5.F7.23.23.23.7" style="padding-left:2.0pt;padding-right:2.0pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_portrait" height="933" id="S5.F7.23.23.23.7.g1" src="extracted/5891401/figures/main_comparison/ours_2_concat.jpg" width="512"/></td>
<td class="ltx_td ltx_align_center" id="S5.F7.24.24.24.8" style="padding-left:2.0pt;padding-right:2.0pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_portrait" height="933" id="S5.F7.24.24.24.8.g1" src="extracted/5891401/figures/main_comparison/gt_2_concat.jpg" width="512"/></td>
</tr>
<tr class="ltx_tr" id="S5.F7.25.25.25">
<td class="ltx_td ltx_align_center" id="S5.F7.25.25.25.2" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S5.F7.25.25.25.2.1" style="font-size:90%;">Input</span></td>
<td class="ltx_td ltx_align_center" id="S5.F7.25.25.25.3" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S5.F7.25.25.25.3.1" style="font-size:90%;">SparseNeRF</span></td>
<td class="ltx_td ltx_align_center" id="S5.F7.25.25.25.4" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S5.F7.25.25.25.4.1" style="font-size:90%;">SPARF</span></td>
<td class="ltx_td ltx_align_center" id="S5.F7.25.25.25.1" style="padding-left:2.0pt;padding-right:2.0pt;">
<span class="ltx_text" id="S5.F7.25.25.25.1.1" style="font-size:90%;">Diner</span><sup class="ltx_sup" id="S5.F7.25.25.25.1.2"><span class="ltx_text" id="S5.F7.25.25.25.1.2.1" style="font-size:90%;">∗</span></sup>
</td>
<td class="ltx_td ltx_align_center" id="S5.F7.25.25.25.5" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S5.F7.25.25.25.5.1" style="font-size:90%;">FreeNeRF</span></td>
<td class="ltx_td ltx_align_center" id="S5.F7.25.25.25.6" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S5.F7.25.25.25.6.1" style="font-size:90%;">Preface</span></td>
<td class="ltx_td ltx_align_center" id="S5.F7.25.25.25.7" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text ltx_font_bold" id="S5.F7.25.25.25.7.1" style="font-size:90%;">Ours</span></td>
<td class="ltx_td ltx_align_center" id="S5.F7.25.25.25.8" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S5.F7.25.25.25.8.1" style="font-size:90%;">GT</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 7. </span>We compare our method with previous work on the Multiface dataset <cite class="ltx_cite ltx_citemacro_citep">(Wuu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib75" title="">2022</a>)</cite>. For each expression, we show the novel-view results with three input views. The symbol <sup class="ltx_sup" id="S5.F7.29.1">∗</sup> indicates results at a lower resolution. Both visually and quantitatively, our method significantly outperforms SparseNeRF <cite class="ltx_cite ltx_citemacro_citep">(Guangcong et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib22" title="">2023</a>)</cite>, SPARF <cite class="ltx_cite ltx_citemacro_citep">(Truong et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib65" title="">2023</a>)</cite>, Diner <cite class="ltx_cite ltx_citemacro_citep">(Prinzler et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib51" title="">2023</a>)</cite>, and FreeNeRF <cite class="ltx_cite ltx_citemacro_citep">(Yang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib78" title="">2023</a>)</cite>. Compared to the state-of-the-art Preface <cite class="ltx_cite ltx_citemacro_citep">(Buehler et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib9" title="">2023</a>)</cite>, we see a clear improvement in areas like eye, chin, and face contours, as shown in the zoom-in. For example, our method better reconstructs the teeth on row 2. We also compare with Preface on in-the-wild captures, please see Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#S5.F8" title="Figure 8 ‣ Cafca: High-quality Novel View Synthesis of Expressive Faces from Casual Few-shot Captures"><span class="ltx_text ltx_ref_tag">8</span></a>.
</figcaption>
</figure>
<figure class="ltx_figure" id="S5.F8">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S5.F8.10.10">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.F8.5.5.5">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S5.F8.3.3.3.3" style="padding-left:2.0pt;padding-right:2.0pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_portrait" height="89" id="S5.F8.1.1.1.1.g1" src="extracted/5891401/figures/inthewild/gt_240117_000_000_C01.jpg" width="59"/><span class="ltx_text" id="S5.F8.3.3.3.3.1" style="font-size:90%;">
</span><img alt="Refer to caption" class="ltx_graphics ltx_img_portrait" height="89" id="S5.F8.2.2.2.2.g2" src="extracted/5891401/figures/inthewild/gt_240117_000_000_C00.jpg" width="59"/><span class="ltx_text" id="S5.F8.3.3.3.3.2" style="font-size:90%;">
</span><img alt="Refer to caption" class="ltx_graphics ltx_img_portrait" height="89" id="S5.F8.3.3.3.3.g3" src="extracted/5891401/figures/inthewild/gt_240117_000_000_C02.jpg" width="59"/>
</th>
<td class="ltx_td ltx_align_center" id="S5.F8.4.4.4.4" style="padding-left:2.0pt;padding-right:2.0pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="1290" id="S5.F8.4.4.4.4.g1" src="extracted/5891401/figures/comparison_itw/preface_00.png" width="2356"/></td>
<td class="ltx_td ltx_align_center" id="S5.F8.5.5.5.5" style="padding-left:2.0pt;padding-right:2.0pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="1290" id="S5.F8.5.5.5.5.g1" src="extracted/5891401/figures/comparison_itw/ours_00.png" width="2356"/></td>
</tr>
<tr class="ltx_tr" id="S5.F8.10.10.10">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S5.F8.8.8.8.3" style="padding-left:2.0pt;padding-right:2.0pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_portrait" height="79" id="S5.F8.6.6.6.1.g1" src="extracted/5891401/figures/comparison_itw/gt_01_C00.jpg" width="59"/><span class="ltx_text" id="S5.F8.8.8.8.3.1" style="font-size:90%;">
</span><img alt="Refer to caption" class="ltx_graphics ltx_img_portrait" height="79" id="S5.F8.7.7.7.2.g2" src="extracted/5891401/figures/comparison_itw/gt_01_C01.jpg" width="59"/><span class="ltx_text" id="S5.F8.8.8.8.3.2" style="font-size:90%;">
</span><img alt="Refer to caption" class="ltx_graphics ltx_img_portrait" height="79" id="S5.F8.8.8.8.3.g3" src="extracted/5891401/figures/comparison_itw/gt_01_C02.jpg" width="59"/>
</th>
<td class="ltx_td ltx_align_center" id="S5.F8.9.9.9.4" style="padding-left:2.0pt;padding-right:2.0pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="1291" id="S5.F8.9.9.9.4.g1" src="extracted/5891401/figures/comparison_itw/preface_01.png" width="2362"/></td>
<td class="ltx_td ltx_align_center" id="S5.F8.10.10.10.5" style="padding-left:2.0pt;padding-right:2.0pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="1291" id="S5.F8.10.10.10.5.g1" src="extracted/5891401/figures/comparison_itw/ours_01.png" width="2362"/></td>
</tr>
<tr class="ltx_tr" id="S5.F8.10.10.11.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S5.F8.10.10.11.1.1" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S5.F8.10.10.11.1.1.1" style="font-size:90%;">Input</span></th>
<td class="ltx_td ltx_align_center" id="S5.F8.10.10.11.1.2" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S5.F8.10.10.11.1.2.1" style="font-size:90%;">Preface</span></td>
<td class="ltx_td ltx_align_center" id="S5.F8.10.10.11.1.3" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text ltx_font_bold" id="S5.F8.10.10.11.1.3.1" style="font-size:90%;">Ours</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 8. </span>We highlight a typical failure case for the best-performing related work. Preface struggles <cite class="ltx_cite ltx_citemacro_citep">(Buehler et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib9" title="">2023</a>)</cite> with strong facial expressions, in particular in the mouth and chin region. Please see the supplementary HTML page for video results.
</figcaption>
</figure>
<figure class="ltx_figure" id="S5.F9">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S5.F9.40.40">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.F9.8.8.8">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S5.F9.3.3.3.3" style="padding-left:2.0pt;padding-right:2.0pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_portrait" height="53" id="S5.F9.1.1.1.1.g1" src="extracted/5891401/figures/inthewild/gt_240117_002_000_C00.jpg" width="40"/><span class="ltx_text" id="S5.F9.3.3.3.3.1" style="font-size:90%;">
</span><img alt="Refer to caption" class="ltx_graphics ltx_img_portrait" height="53" id="S5.F9.2.2.2.2.g2" src="extracted/5891401/figures/inthewild/gt_240117_002_000_C01.jpg" width="40"/><span class="ltx_text" id="S5.F9.3.3.3.3.2" style="font-size:90%;">
</span><img alt="Refer to caption" class="ltx_graphics ltx_img_portrait" height="53" id="S5.F9.3.3.3.3.g3" src="extracted/5891401/figures/inthewild/gt_240117_002_000_C02.jpg" width="40"/>
</th>
<td class="ltx_td ltx_align_center" id="S5.F9.4.4.4.4" style="padding-left:2.0pt;padding-right:2.0pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="512" id="S5.F9.4.4.4.4.g1" src="extracted/5891401/figures/inthewild/240117_002_000_100.jpg" width="768"/></td>
<td class="ltx_td ltx_align_center" id="S5.F9.5.5.5.5" style="padding-left:2.0pt;padding-right:2.0pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="512" id="S5.F9.5.5.5.5.g1" src="extracted/5891401/figures/inthewild/240117_002_000_110.jpg" width="768"/></td>
<td class="ltx_td ltx_align_center" id="S5.F9.6.6.6.6" style="padding-left:2.0pt;padding-right:2.0pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="512" id="S5.F9.6.6.6.6.g1" src="extracted/5891401/figures/inthewild/240117_002_000_000.jpg" width="768"/></td>
<td class="ltx_td ltx_align_center" id="S5.F9.7.7.7.7" style="padding-left:2.0pt;padding-right:2.0pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="512" id="S5.F9.7.7.7.7.g1" src="extracted/5891401/figures/inthewild/240117_002_000_010.jpg" width="768"/></td>
<td class="ltx_td ltx_align_center" id="S5.F9.8.8.8.8" style="padding-left:2.0pt;padding-right:2.0pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="512" id="S5.F9.8.8.8.8.g1" src="extracted/5891401/figures/inthewild/240117_002_000_020.jpg" width="768"/></td>
</tr>
<tr class="ltx_tr" id="S5.F9.16.16.16">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S5.F9.11.11.11.3" style="padding-left:2.0pt;padding-right:2.0pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_portrait" height="53" id="S5.F9.9.9.9.1.g1" src="extracted/5891401/figures/inthewild/gt_0d624022_003_C00.jpg" width="40"/><span class="ltx_text" id="S5.F9.11.11.11.3.1" style="font-size:90%;">
</span><img alt="Refer to caption" class="ltx_graphics ltx_img_portrait" height="53" id="S5.F9.10.10.10.2.g2" src="extracted/5891401/figures/inthewild/gt_0d624022_003_C01.jpg" width="40"/><span class="ltx_text" id="S5.F9.11.11.11.3.2" style="font-size:90%;">
</span><img alt="Refer to caption" class="ltx_graphics ltx_img_portrait" height="53" id="S5.F9.11.11.11.3.g3" src="extracted/5891401/figures/inthewild/gt_0d624022_003_C02.jpg" width="40"/>
</th>
<td class="ltx_td ltx_align_center" id="S5.F9.12.12.12.4" style="padding-left:2.0pt;padding-right:2.0pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="512" id="S5.F9.12.12.12.4.g1" src="extracted/5891401/figures/inthewild/0d624022_003_100.jpg" width="768"/></td>
<td class="ltx_td ltx_align_center" id="S5.F9.13.13.13.5" style="padding-left:2.0pt;padding-right:2.0pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="512" id="S5.F9.13.13.13.5.g1" src="extracted/5891401/figures/inthewild/0d624022_003_110.jpg" width="768"/></td>
<td class="ltx_td ltx_align_center" id="S5.F9.14.14.14.6" style="padding-left:2.0pt;padding-right:2.0pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="512" id="S5.F9.14.14.14.6.g1" src="extracted/5891401/figures/inthewild/0d624022_003_000.jpg" width="768"/></td>
<td class="ltx_td ltx_align_center" id="S5.F9.15.15.15.7" style="padding-left:2.0pt;padding-right:2.0pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="512" id="S5.F9.15.15.15.7.g1" src="extracted/5891401/figures/inthewild/0d624022_003_010.jpg" width="768"/></td>
<td class="ltx_td ltx_align_center" id="S5.F9.16.16.16.8" style="padding-left:2.0pt;padding-right:2.0pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="512" id="S5.F9.16.16.16.8.g1" src="extracted/5891401/figures/inthewild/0d624022_003_020.jpg" width="768"/></td>
</tr>
<tr class="ltx_tr" id="S5.F9.24.24.24">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S5.F9.19.19.19.3" style="padding-left:2.0pt;padding-right:2.0pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_portrait" height="59" id="S5.F9.17.17.17.1.g1" src="extracted/5891401/figures/inthewild/gt_240116_001_001_C00.jpg" width="40"/><span class="ltx_text" id="S5.F9.19.19.19.3.1" style="font-size:90%;">
</span><img alt="Refer to caption" class="ltx_graphics ltx_img_portrait" height="59" id="S5.F9.18.18.18.2.g2" src="extracted/5891401/figures/inthewild/gt_240116_001_001_C01.jpg" width="40"/><span class="ltx_text" id="S5.F9.19.19.19.3.2" style="font-size:90%;">
</span><img alt="Refer to caption" class="ltx_graphics ltx_img_portrait" height="59" id="S5.F9.19.19.19.3.g3" src="extracted/5891401/figures/inthewild/gt_240116_001_001_C02.jpg" width="40"/>
</th>
<td class="ltx_td ltx_align_center" id="S5.F9.20.20.20.4" style="padding-left:2.0pt;padding-right:2.0pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="512" id="S5.F9.20.20.20.4.g1" src="extracted/5891401/figures/inthewild/240116_001_001_100.jpg" width="768"/></td>
<td class="ltx_td ltx_align_center" id="S5.F9.21.21.21.5" style="padding-left:2.0pt;padding-right:2.0pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="512" id="S5.F9.21.21.21.5.g1" src="extracted/5891401/figures/inthewild/240116_001_001_110.jpg" width="768"/></td>
<td class="ltx_td ltx_align_center" id="S5.F9.22.22.22.6" style="padding-left:2.0pt;padding-right:2.0pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="512" id="S5.F9.22.22.22.6.g1" src="extracted/5891401/figures/inthewild/240116_001_001_000.jpg" width="768"/></td>
<td class="ltx_td ltx_align_center" id="S5.F9.23.23.23.7" style="padding-left:2.0pt;padding-right:2.0pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="512" id="S5.F9.23.23.23.7.g1" src="extracted/5891401/figures/inthewild/240116_001_001_010.jpg" width="768"/></td>
<td class="ltx_td ltx_align_center" id="S5.F9.24.24.24.8" style="padding-left:2.0pt;padding-right:2.0pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="512" id="S5.F9.24.24.24.8.g1" src="extracted/5891401/figures/inthewild/240116_001_001_020.jpg" width="768"/></td>
</tr>
<tr class="ltx_tr" id="S5.F9.32.32.32">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S5.F9.27.27.27.3" style="padding-left:2.0pt;padding-right:2.0pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_portrait" height="59" id="S5.F9.25.25.25.1.g1" src="extracted/5891401/figures/inthewild/gt_240116_002_002_C00.jpg" width="40"/><span class="ltx_text" id="S5.F9.27.27.27.3.1" style="font-size:90%;">
</span><img alt="Refer to caption" class="ltx_graphics ltx_img_portrait" height="59" id="S5.F9.26.26.26.2.g2" src="extracted/5891401/figures/inthewild/gt_240116_002_002_C01.jpg" width="40"/><span class="ltx_text" id="S5.F9.27.27.27.3.2" style="font-size:90%;">
</span><img alt="Refer to caption" class="ltx_graphics ltx_img_portrait" height="59" id="S5.F9.27.27.27.3.g3" src="extracted/5891401/figures/inthewild/gt_240116_002_002_C02.jpg" width="40"/>
</th>
<td class="ltx_td ltx_align_center" id="S5.F9.28.28.28.4" style="padding-left:2.0pt;padding-right:2.0pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="512" id="S5.F9.28.28.28.4.g1" src="extracted/5891401/figures/inthewild/240116_002_002_100.jpg" width="768"/></td>
<td class="ltx_td ltx_align_center" id="S5.F9.29.29.29.5" style="padding-left:2.0pt;padding-right:2.0pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="512" id="S5.F9.29.29.29.5.g1" src="extracted/5891401/figures/inthewild/240116_002_002_110.jpg" width="768"/></td>
<td class="ltx_td ltx_align_center" id="S5.F9.30.30.30.6" style="padding-left:2.0pt;padding-right:2.0pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="512" id="S5.F9.30.30.30.6.g1" src="extracted/5891401/figures/inthewild/240116_002_002_000.jpg" width="768"/></td>
<td class="ltx_td ltx_align_center" id="S5.F9.31.31.31.7" style="padding-left:2.0pt;padding-right:2.0pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="512" id="S5.F9.31.31.31.7.g1" src="extracted/5891401/figures/inthewild/240116_002_002_010.jpg" width="768"/></td>
<td class="ltx_td ltx_align_center" id="S5.F9.32.32.32.8" style="padding-left:2.0pt;padding-right:2.0pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="512" id="S5.F9.32.32.32.8.g1" src="extracted/5891401/figures/inthewild/240116_002_002_020.jpg" width="768"/></td>
</tr>
<tr class="ltx_tr" id="S5.F9.40.40.40">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S5.F9.35.35.35.3" style="padding-left:2.0pt;padding-right:2.0pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_portrait" height="59" id="S5.F9.33.33.33.1.g1" src="extracted/5891401/figures/inthewild/gt_240117_000_000_C01.jpg" width="40"/><span class="ltx_text" id="S5.F9.35.35.35.3.1" style="font-size:90%;">
</span><img alt="Refer to caption" class="ltx_graphics ltx_img_portrait" height="59" id="S5.F9.34.34.34.2.g2" src="extracted/5891401/figures/inthewild/gt_240117_000_000_C00.jpg" width="40"/><span class="ltx_text" id="S5.F9.35.35.35.3.2" style="font-size:90%;">
</span><img alt="Refer to caption" class="ltx_graphics ltx_img_portrait" height="59" id="S5.F9.35.35.35.3.g3" src="extracted/5891401/figures/inthewild/gt_240117_000_000_C02.jpg" width="40"/>
</th>
<td class="ltx_td ltx_align_center" id="S5.F9.36.36.36.4" style="padding-left:2.0pt;padding-right:2.0pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="512" id="S5.F9.36.36.36.4.g1" src="extracted/5891401/figures/inthewild/240117_000_000_100.jpg" width="768"/></td>
<td class="ltx_td ltx_align_center" id="S5.F9.37.37.37.5" style="padding-left:2.0pt;padding-right:2.0pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="512" id="S5.F9.37.37.37.5.g1" src="extracted/5891401/figures/inthewild/240117_000_000_110.jpg" width="768"/></td>
<td class="ltx_td ltx_align_center" id="S5.F9.38.38.38.6" style="padding-left:2.0pt;padding-right:2.0pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="512" id="S5.F9.38.38.38.6.g1" src="extracted/5891401/figures/inthewild/240117_000_000_000.jpg" width="768"/></td>
<td class="ltx_td ltx_align_center" id="S5.F9.39.39.39.7" style="padding-left:2.0pt;padding-right:2.0pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="512" id="S5.F9.39.39.39.7.g1" src="extracted/5891401/figures/inthewild/240117_000_000_010.jpg" width="768"/></td>
<td class="ltx_td ltx_align_center" id="S5.F9.40.40.40.8" style="padding-left:2.0pt;padding-right:2.0pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="512" id="S5.F9.40.40.40.8.g1" src="extracted/5891401/figures/inthewild/240117_000_000_020.jpg" width="768"/></td>
</tr>
<tr class="ltx_tr" id="S5.F9.40.40.41.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S5.F9.40.40.41.1.1" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S5.F9.40.40.41.1.1.1" style="font-size:90%;">Input</span></th>
<td class="ltx_td ltx_align_center" colspan="5" id="S5.F9.40.40.41.1.2" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S5.F9.40.40.41.1.2.1" style="font-size:90%;">Novel views with world-space normals (top) and depth (bottom)</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 9. </span> In-the-wild results. Given three in-the-wild images of a subject, our method reconstructs the subject and renders novel views with high resolution. The figure shows the input images (which can be taken sequentially), high-resolution rendering results in novel view, and also the reconstructed normal and depth maps. Our model generalizes to different challenging in-the-wild lighting. These results include indoor, outdoor, and dim scenes. Our method also captures strong idiosyncratic facial expressions such as the tongue-out case in row 3. This is an expression not included in the synthetic training data.</figcaption>
</figure>
<figure class="ltx_figure" id="S5.F10">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S5.F10.16.16">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.F10.8.8.8">
<td class="ltx_td ltx_align_center" id="S5.F10.1.1.1.1" style="padding-left:2.0pt;padding-right:2.0pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="768" id="S5.F10.1.1.1.1.g1" src="extracted/5891401/figures/single/00_input.jpg" width="768"/></td>
<td class="ltx_td ltx_align_center" id="S5.F10.2.2.2.2" style="padding-left:2.0pt;padding-right:2.0pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="412" id="S5.F10.2.2.2.2.g1" src="extracted/5891401/figures/single/00_00.jpg" width="412"/></td>
<td class="ltx_td ltx_align_center" id="S5.F10.3.3.3.3" style="padding-left:2.0pt;padding-right:2.0pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="412" id="S5.F10.3.3.3.3.g1" src="extracted/5891401/figures/single/00_01.jpg" width="412"/></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.F10.4.4.4.4" style="padding-left:2.0pt;padding-right:2.0pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="412" id="S5.F10.4.4.4.4.g1" src="extracted/5891401/figures/single/00_02.jpg" width="412"/></td>
<td class="ltx_td ltx_align_center" id="S5.F10.5.5.5.5" style="padding-left:2.0pt;padding-right:2.0pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="600" id="S5.F10.5.5.5.5.g1" src="extracted/5891401/figures/single/44.jpg" width="600"/></td>
<td class="ltx_td ltx_align_center" id="S5.F10.6.6.6.6" style="padding-left:2.0pt;padding-right:2.0pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="400" id="S5.F10.6.6.6.6.g1" src="extracted/5891401/figures/single/butterfly_color_100.jpg" width="512"/></td>
<td class="ltx_td ltx_align_center" id="S5.F10.7.7.7.7" style="padding-left:2.0pt;padding-right:2.0pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="400" id="S5.F10.7.7.7.7.g1" src="extracted/5891401/figures/single/butterfly_color_000.jpg" width="512"/></td>
<td class="ltx_td ltx_align_center" id="S5.F10.8.8.8.8" style="padding-left:2.0pt;padding-right:2.0pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="400" id="S5.F10.8.8.8.8.g1" src="extracted/5891401/figures/single/butterfly_color_020.jpg" width="512"/></td>
</tr>
<tr class="ltx_tr" id="S5.F10.16.16.16">
<td class="ltx_td ltx_align_center" id="S5.F10.9.9.9.1" style="padding-left:2.0pt;padding-right:2.0pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="1024" id="S5.F10.9.9.9.1.g1" src="extracted/5891401/figures/single/rodin_input.jpg" width="1024"/></td>
<td class="ltx_td ltx_align_center" id="S5.F10.10.10.10.2" style="padding-left:2.0pt;padding-right:2.0pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="412" id="S5.F10.10.10.10.2.g1" src="extracted/5891401/figures/single/rodin_0.jpg" width="412"/></td>
<td class="ltx_td ltx_align_center" id="S5.F10.11.11.11.3" style="padding-left:2.0pt;padding-right:2.0pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="412" id="S5.F10.11.11.11.3.g1" src="extracted/5891401/figures/single/rodin_1.jpg" width="412"/></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.F10.12.12.12.4" style="padding-left:2.0pt;padding-right:2.0pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="412" id="S5.F10.12.12.12.4.g1" src="extracted/5891401/figures/single/rodin_2.jpg" width="412"/></td>
<td class="ltx_td ltx_align_center" id="S5.F10.13.13.13.5" style="padding-left:2.0pt;padding-right:2.0pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="758" id="S5.F10.13.13.13.5.g1" src="extracted/5891401/figures/single/56.jpg" width="758"/></td>
<td class="ltx_td ltx_align_center" id="S5.F10.14.14.14.6" style="padding-left:2.0pt;padding-right:2.0pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="400" id="S5.F10.14.14.14.6.g1" src="extracted/5891401/figures/single/blond_color_100.jpg" width="512"/></td>
<td class="ltx_td ltx_align_center" id="S5.F10.15.15.15.7" style="padding-left:2.0pt;padding-right:2.0pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="400" id="S5.F10.15.15.15.7.g1" src="extracted/5891401/figures/single/blond_color_000.jpg" width="512"/></td>
<td class="ltx_td ltx_align_center" id="S5.F10.16.16.16.8" style="padding-left:2.0pt;padding-right:2.0pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="400" id="S5.F10.16.16.16.8.g1" src="extracted/5891401/figures/single/blond_color_020.jpg" width="512"/></td>
</tr>
<tr class="ltx_tr" id="S5.F10.16.16.17.1">
<td class="ltx_td ltx_align_center" id="S5.F10.16.16.17.1.1" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S5.F10.16.16.17.1.1.1" style="font-size:90%;">Input</span></td>
<td class="ltx_td ltx_align_center" colspan="3" id="S5.F10.16.16.17.1.2" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S5.F10.16.16.17.1.2.1" style="font-size:90%;">Novel Views</span></td>
<td class="ltx_td ltx_align_center" id="S5.F10.16.16.17.1.3" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S5.F10.16.16.17.1.3.1" style="font-size:90%;">Input</span></td>
<td class="ltx_td ltx_align_center" colspan="3" id="S5.F10.16.16.17.1.4" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S5.F10.16.16.17.1.4.1" style="font-size:90%;">Novel Views</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 10. </span>Single Image Results. We push the limits of our method by reconstructing the face with only a single input image. The top left image is a smartphone image, the bottom left an Image from Wang et al. (2023) <cite class="ltx_cite ltx_citemacro_citep">(Wang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib70" title="">2023</a>)</cite>, and the right two examples are stylized images from <cite class="ltx_cite ltx_citemacro_citep">(Trevithick et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib64" title="">2023</a>)</cite>.
</figcaption>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
<section class="ltx_appendix" id="A1">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Supplementary</h2>
<div class="ltx_para" id="A1.p1">
<p class="ltx_p" id="A1.p1.1">This supplementary document provides more details about the synthetic dataset (Sec. <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#A1.SS1" title="A.1. Dataset Details ‣ Appendix A Supplementary ‣ Cafca: High-quality Novel View Synthesis of Expressive Faces from Casual Few-shot Captures"><span class="ltx_text ltx_ref_tag">A.1</span></a>), the models and method (Sec. <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#A1.SS2" title="A.2. Method Details ‣ Appendix A Supplementary ‣ Cafca: High-quality Novel View Synthesis of Expressive Faces from Casual Few-shot Captures"><span class="ltx_text ltx_ref_tag">A.2</span></a>), experiments (Sec. <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#A1.SS4" title="A.4. Experimental Details ‣ Appendix A Supplementary ‣ Cafca: High-quality Novel View Synthesis of Expressive Faces from Casual Few-shot Captures"><span class="ltx_text ltx_ref_tag">A.4</span></a>), and supplementary results (Sec. <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#A1.SS5" title="A.5. Supplementary Results ‣ Appendix A Supplementary ‣ Cafca: High-quality Novel View Synthesis of Expressive Faces from Casual Few-shot Captures"><span class="ltx_text ltx_ref_tag">A.5</span></a>).</p>
</div>
<section class="ltx_subsection" id="A1.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.1. </span>Dataset Details</h3>
<div class="ltx_para" id="A1.SS1.p1">
<p class="ltx_p" id="A1.SS1.p1.10">Our synthetic dataset is generated in a similar fashion to previous work <cite class="ltx_cite ltx_citemacro_citep">(Wood et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib72" title="">2021</a>)</cite>.
We use Blender to both generate and render realistic and diverse 3D scenes containing a face.
We sample faces from a large dataset of <math alttext="50,000" class="ltx_Math" display="inline" id="A1.SS1.p1.1.m1.2"><semantics id="A1.SS1.p1.1.m1.2a"><mrow id="A1.SS1.p1.1.m1.2.3.2" xref="A1.SS1.p1.1.m1.2.3.1.cmml"><mn id="A1.SS1.p1.1.m1.1.1" xref="A1.SS1.p1.1.m1.1.1.cmml">50</mn><mo id="A1.SS1.p1.1.m1.2.3.2.1" xref="A1.SS1.p1.1.m1.2.3.1.cmml">,</mo><mn id="A1.SS1.p1.1.m1.2.2" xref="A1.SS1.p1.1.m1.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.SS1.p1.1.m1.2b"><list id="A1.SS1.p1.1.m1.2.3.1.cmml" xref="A1.SS1.p1.1.m1.2.3.2"><cn id="A1.SS1.p1.1.m1.1.1.cmml" type="integer" xref="A1.SS1.p1.1.m1.1.1">50</cn><cn id="A1.SS1.p1.1.m1.2.2.cmml" type="integer" xref="A1.SS1.p1.1.m1.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p1.1.m1.2c">50,000</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.p1.1.m1.2d">50 , 000</annotation></semantics></math> 3D scans that have been registered with a common template mesh <cite class="ltx_cite ltx_citemacro_citep">(Bednarik et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib4" title="">2024</a>)</cite>.
Then, we make each face mesh look realistic by applying a physically-based skin material from a high-resolution skin texture collection.
Next, we “dress up” our face by procedurally attaching traditional CG assets<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.3dscanstore.com/" title="">https://www.3dscanstore.com/</a></span></span></span>.
Our total asset library contains the following items: <math alttext="23" class="ltx_Math" display="inline" id="A1.SS1.p1.2.m2.1"><semantics id="A1.SS1.p1.2.m2.1a"><mn id="A1.SS1.p1.2.m2.1.1" xref="A1.SS1.p1.2.m2.1.1.cmml">23</mn><annotation-xml encoding="MathML-Content" id="A1.SS1.p1.2.m2.1b"><cn id="A1.SS1.p1.2.m2.1.1.cmml" type="integer" xref="A1.SS1.p1.2.m2.1.1">23</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p1.2.m2.1c">23</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.p1.2.m2.1d">23</annotation></semantics></math> upper-body garments (jackets, sweaters, suits, uniforms, coats, t-shirts, scarfs), <math alttext="8" class="ltx_Math" display="inline" id="A1.SS1.p1.3.m3.1"><semantics id="A1.SS1.p1.3.m3.1a"><mn id="A1.SS1.p1.3.m3.1.1" xref="A1.SS1.p1.3.m3.1.1.cmml">8</mn><annotation-xml encoding="MathML-Content" id="A1.SS1.p1.3.m3.1b"><cn id="A1.SS1.p1.3.m3.1.1.cmml" type="integer" xref="A1.SS1.p1.3.m3.1.1">8</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p1.3.m3.1c">8</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.p1.3.m3.1d">8</annotation></semantics></math> types of eye-glasses, <math alttext="157" class="ltx_Math" display="inline" id="A1.SS1.p1.4.m4.1"><semantics id="A1.SS1.p1.4.m4.1a"><mn id="A1.SS1.p1.4.m4.1.1" xref="A1.SS1.p1.4.m4.1.1.cmml">157</mn><annotation-xml encoding="MathML-Content" id="A1.SS1.p1.4.m4.1b"><cn id="A1.SS1.p1.4.m4.1.1.cmml" type="integer" xref="A1.SS1.p1.4.m4.1.1">157</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p1.4.m4.1c">157</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.p1.4.m4.1d">157</annotation></semantics></math> eyebrows, <math alttext="6" class="ltx_Math" display="inline" id="A1.SS1.p1.5.m5.1"><semantics id="A1.SS1.p1.5.m5.1a"><mn id="A1.SS1.p1.5.m5.1.1" xref="A1.SS1.p1.5.m5.1.1.cmml">6</mn><annotation-xml encoding="MathML-Content" id="A1.SS1.p1.5.m5.1b"><cn id="A1.SS1.p1.5.m5.1.1.cmml" type="integer" xref="A1.SS1.p1.5.m5.1.1">6</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p1.5.m5.1c">6</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.p1.5.m5.1d">6</annotation></semantics></math> types of makeup, <math alttext="2" class="ltx_Math" display="inline" id="A1.SS1.p1.6.m6.1"><semantics id="A1.SS1.p1.6.m6.1a"><mn id="A1.SS1.p1.6.m6.1.1" xref="A1.SS1.p1.6.m6.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="A1.SS1.p1.6.m6.1b"><cn id="A1.SS1.p1.6.m6.1.1.cmml" type="integer" xref="A1.SS1.p1.6.m6.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p1.6.m6.1c">2</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.p1.6.m6.1d">2</annotation></semantics></math> sets of eyelashes (with and without mascara), <math alttext="1,679" class="ltx_Math" display="inline" id="A1.SS1.p1.7.m7.2"><semantics id="A1.SS1.p1.7.m7.2a"><mrow id="A1.SS1.p1.7.m7.2.3.2" xref="A1.SS1.p1.7.m7.2.3.1.cmml"><mn id="A1.SS1.p1.7.m7.1.1" xref="A1.SS1.p1.7.m7.1.1.cmml">1</mn><mo id="A1.SS1.p1.7.m7.2.3.2.1" xref="A1.SS1.p1.7.m7.2.3.1.cmml">,</mo><mn id="A1.SS1.p1.7.m7.2.2" xref="A1.SS1.p1.7.m7.2.2.cmml">679</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.SS1.p1.7.m7.2b"><list id="A1.SS1.p1.7.m7.2.3.1.cmml" xref="A1.SS1.p1.7.m7.2.3.2"><cn id="A1.SS1.p1.7.m7.1.1.cmml" type="integer" xref="A1.SS1.p1.7.m7.1.1">1</cn><cn id="A1.SS1.p1.7.m7.2.2.cmml" type="integer" xref="A1.SS1.p1.7.m7.2.2">679</cn></list></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p1.7.m7.2c">1,679</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.p1.7.m7.2d">1 , 679</annotation></semantics></math> head textures, <math alttext="2" class="ltx_Math" display="inline" id="A1.SS1.p1.8.m8.1"><semantics id="A1.SS1.p1.8.m8.1a"><mn id="A1.SS1.p1.8.m8.1.1" xref="A1.SS1.p1.8.m8.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="A1.SS1.p1.8.m8.1b"><cn id="A1.SS1.p1.8.m8.1.1.cmml" type="integer" xref="A1.SS1.p1.8.m8.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p1.8.m8.1c">2</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.p1.8.m8.1d">2</annotation></semantics></math> headwear items, <math alttext="125" class="ltx_Math" display="inline" id="A1.SS1.p1.9.m9.1"><semantics id="A1.SS1.p1.9.m9.1a"><mn id="A1.SS1.p1.9.m9.1.1" xref="A1.SS1.p1.9.m9.1.1.cmml">125</mn><annotation-xml encoding="MathML-Content" id="A1.SS1.p1.9.m9.1b"><cn id="A1.SS1.p1.9.m9.1.1.cmml" type="integer" xref="A1.SS1.p1.9.m9.1.1">125</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p1.9.m9.1c">125</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.p1.9.m9.1d">125</annotation></semantics></math> strand-based hair / beard styles, and <math alttext="6" class="ltx_Math" display="inline" id="A1.SS1.p1.10.m10.1"><semantics id="A1.SS1.p1.10.m10.1a"><mn id="A1.SS1.p1.10.m10.1.1" xref="A1.SS1.p1.10.m10.1.1.cmml">6</mn><annotation-xml encoding="MathML-Content" id="A1.SS1.p1.10.m10.1b"><cn id="A1.SS1.p1.10.m10.1.1.cmml" type="integer" xref="A1.SS1.p1.10.m10.1.1">6</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p1.10.m10.1c">6</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.p1.10.m10.1d">6</annotation></semantics></math> eye textures.
Each asset is authored as a rig using Blender Geometry Nodes, and each class of item executes class-specific rig logic to robustly attach itself to arbitrary 3D face meshes, regardless of identity or expression.
For example, upper-body clothing items non-rigidly deform themselves to fit around the neck of a target face, but eyeglasses are posed using inverse kinematics to rest on the nose-bridge and ears.</p>
</div>
<div class="ltx_para" id="A1.SS1.p2">
<p class="ltx_p" id="A1.SS1.p2.2">Finally, we render the scenes with Cycles: a physically-based ray-tracing renderer.
We render all faces in the same environment: a uniform well-lit environment.
Each face is rendered from <math alttext="30" class="ltx_Math" display="inline" id="A1.SS1.p2.1.m1.1"><semantics id="A1.SS1.p2.1.m1.1a"><mn id="A1.SS1.p2.1.m1.1.1" xref="A1.SS1.p2.1.m1.1.1.cmml">30</mn><annotation-xml encoding="MathML-Content" id="A1.SS1.p2.1.m1.1b"><cn id="A1.SS1.p2.1.m1.1.1.cmml" type="integer" xref="A1.SS1.p2.1.m1.1.1">30</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p2.1.m1.1c">30</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.p2.1.m1.1d">30</annotation></semantics></math> distinct viewpoints, generated by placing the camera at random points around the head and pointing it at the face.
We choose random camera positions by sampling spherical coordinates: azimuthal angle, elevation angle, and radius.
We avoid overly similar viewpoints by discarding those with viewing directions closer than <math alttext="25" class="ltx_Math" display="inline" id="A1.SS1.p2.2.m2.1"><semantics id="A1.SS1.p2.2.m2.1a"><mn id="A1.SS1.p2.2.m2.1.1" xref="A1.SS1.p2.2.m2.1.1.cmml">25</mn><annotation-xml encoding="MathML-Content" id="A1.SS1.p2.2.m2.1b"><cn id="A1.SS1.p2.2.m2.1.1.cmml" type="integer" xref="A1.SS1.p2.2.m2.1.1">25</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p2.2.m2.1c">25</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.p2.2.m2.1d">25</annotation></semantics></math> degrees to a previous one and re-sampling.
We found it helpful to sample random viewpoints for each subject and expression rather than sampling the same viewpoints across the entire dataset. The latter led to more floaters when training the prior model.</p>
</div>
<div class="ltx_para" id="A1.SS1.p3">
<p class="ltx_p" id="A1.SS1.p3.1">For the ablation with diverse environments, we sample random environment maps from the Laval indoor dataset <cite class="ltx_cite ltx_citemacro_citep">(Hold-Geoffroy et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib24" title="">2019</a>; Gardner et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib20" title="">2017</a>)</cite>.</p>
</div>
</section>
<section class="ltx_subsection" id="A1.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.2. </span>Method Details</h3>
<section class="ltx_subsubsection" id="A1.SS2.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">A.2.1. </span>Prior Model Details</h4>
<section class="ltx_paragraph" id="A1.SS2.SSS1.Px1">
<h5 class="ltx_title ltx_title_paragraph">Architecture</h5>
<div class="ltx_para" id="A1.SS2.SSS1.Px1.p1">
<p class="ltx_p" id="A1.SS2.SSS1.Px1.p1.9">The prior model architecture largely follows Preface <cite class="ltx_cite ltx_citemacro_citep">(Buehler et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib9" title="">2023</a>)</cite>. The prior model has a <em class="ltx_emph ltx_font_italic" id="A1.SS2.SSS1.Px1.p1.9.1">proposal</em> MLP predicting density and normals, and a <em class="ltx_emph ltx_font_italic" id="A1.SS2.SSS1.Px1.p1.9.2">NeRF</em> MLP predicting density and color <cite class="ltx_cite ltx_citemacro_citep">(Barron et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib3" title="">2022</a>)</cite>. The proposal MLP has depth <math alttext="4" class="ltx_Math" display="inline" id="A1.SS2.SSS1.Px1.p1.1.m1.1"><semantics id="A1.SS2.SSS1.Px1.p1.1.m1.1a"><mn id="A1.SS2.SSS1.Px1.p1.1.m1.1.1" xref="A1.SS2.SSS1.Px1.p1.1.m1.1.1.cmml">4</mn><annotation-xml encoding="MathML-Content" id="A1.SS2.SSS1.Px1.p1.1.m1.1b"><cn id="A1.SS2.SSS1.Px1.p1.1.m1.1.1.cmml" type="integer" xref="A1.SS2.SSS1.Px1.p1.1.m1.1.1">4</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.SSS1.Px1.p1.1.m1.1c">4</annotation><annotation encoding="application/x-llamapun" id="A1.SS2.SSS1.Px1.p1.1.m1.1d">4</annotation></semantics></math> and layers width <math alttext="(256+|\boldsymbol{\beta}|+|\boldsymbol{\psi}|+|\boldsymbol{w}|)\times 256" class="ltx_Math" display="inline" id="A1.SS2.SSS1.Px1.p1.2.m2.4"><semantics id="A1.SS2.SSS1.Px1.p1.2.m2.4a"><mrow id="A1.SS2.SSS1.Px1.p1.2.m2.4.4" xref="A1.SS2.SSS1.Px1.p1.2.m2.4.4.cmml"><mrow id="A1.SS2.SSS1.Px1.p1.2.m2.4.4.1.1" xref="A1.SS2.SSS1.Px1.p1.2.m2.4.4.1.1.1.cmml"><mo id="A1.SS2.SSS1.Px1.p1.2.m2.4.4.1.1.2" stretchy="false" xref="A1.SS2.SSS1.Px1.p1.2.m2.4.4.1.1.1.cmml">(</mo><mrow id="A1.SS2.SSS1.Px1.p1.2.m2.4.4.1.1.1" xref="A1.SS2.SSS1.Px1.p1.2.m2.4.4.1.1.1.cmml"><mn id="A1.SS2.SSS1.Px1.p1.2.m2.4.4.1.1.1.2" xref="A1.SS2.SSS1.Px1.p1.2.m2.4.4.1.1.1.2.cmml">256</mn><mo id="A1.SS2.SSS1.Px1.p1.2.m2.4.4.1.1.1.1" xref="A1.SS2.SSS1.Px1.p1.2.m2.4.4.1.1.1.1.cmml">+</mo><mrow id="A1.SS2.SSS1.Px1.p1.2.m2.4.4.1.1.1.3.2" xref="A1.SS2.SSS1.Px1.p1.2.m2.4.4.1.1.1.3.1.cmml"><mo id="A1.SS2.SSS1.Px1.p1.2.m2.4.4.1.1.1.3.2.1" stretchy="false" xref="A1.SS2.SSS1.Px1.p1.2.m2.4.4.1.1.1.3.1.1.cmml">|</mo><mi id="A1.SS2.SSS1.Px1.p1.2.m2.1.1" xref="A1.SS2.SSS1.Px1.p1.2.m2.1.1.cmml">𝜷</mi><mo id="A1.SS2.SSS1.Px1.p1.2.m2.4.4.1.1.1.3.2.2" stretchy="false" xref="A1.SS2.SSS1.Px1.p1.2.m2.4.4.1.1.1.3.1.1.cmml">|</mo></mrow><mo id="A1.SS2.SSS1.Px1.p1.2.m2.4.4.1.1.1.1a" xref="A1.SS2.SSS1.Px1.p1.2.m2.4.4.1.1.1.1.cmml">+</mo><mrow id="A1.SS2.SSS1.Px1.p1.2.m2.4.4.1.1.1.4.2" xref="A1.SS2.SSS1.Px1.p1.2.m2.4.4.1.1.1.4.1.cmml"><mo id="A1.SS2.SSS1.Px1.p1.2.m2.4.4.1.1.1.4.2.1" stretchy="false" xref="A1.SS2.SSS1.Px1.p1.2.m2.4.4.1.1.1.4.1.1.cmml">|</mo><mi id="A1.SS2.SSS1.Px1.p1.2.m2.2.2" xref="A1.SS2.SSS1.Px1.p1.2.m2.2.2.cmml">𝝍</mi><mo id="A1.SS2.SSS1.Px1.p1.2.m2.4.4.1.1.1.4.2.2" stretchy="false" xref="A1.SS2.SSS1.Px1.p1.2.m2.4.4.1.1.1.4.1.1.cmml">|</mo></mrow><mo id="A1.SS2.SSS1.Px1.p1.2.m2.4.4.1.1.1.1b" xref="A1.SS2.SSS1.Px1.p1.2.m2.4.4.1.1.1.1.cmml">+</mo><mrow id="A1.SS2.SSS1.Px1.p1.2.m2.4.4.1.1.1.5.2" xref="A1.SS2.SSS1.Px1.p1.2.m2.4.4.1.1.1.5.1.cmml"><mo id="A1.SS2.SSS1.Px1.p1.2.m2.4.4.1.1.1.5.2.1" stretchy="false" xref="A1.SS2.SSS1.Px1.p1.2.m2.4.4.1.1.1.5.1.1.cmml">|</mo><mi id="A1.SS2.SSS1.Px1.p1.2.m2.3.3" xref="A1.SS2.SSS1.Px1.p1.2.m2.3.3.cmml">𝒘</mi><mo id="A1.SS2.SSS1.Px1.p1.2.m2.4.4.1.1.1.5.2.2" stretchy="false" xref="A1.SS2.SSS1.Px1.p1.2.m2.4.4.1.1.1.5.1.1.cmml">|</mo></mrow></mrow><mo id="A1.SS2.SSS1.Px1.p1.2.m2.4.4.1.1.3" rspace="0.055em" stretchy="false" xref="A1.SS2.SSS1.Px1.p1.2.m2.4.4.1.1.1.cmml">)</mo></mrow><mo id="A1.SS2.SSS1.Px1.p1.2.m2.4.4.2" rspace="0.222em" xref="A1.SS2.SSS1.Px1.p1.2.m2.4.4.2.cmml">×</mo><mn id="A1.SS2.SSS1.Px1.p1.2.m2.4.4.3" xref="A1.SS2.SSS1.Px1.p1.2.m2.4.4.3.cmml">256</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.SS2.SSS1.Px1.p1.2.m2.4b"><apply id="A1.SS2.SSS1.Px1.p1.2.m2.4.4.cmml" xref="A1.SS2.SSS1.Px1.p1.2.m2.4.4"><times id="A1.SS2.SSS1.Px1.p1.2.m2.4.4.2.cmml" xref="A1.SS2.SSS1.Px1.p1.2.m2.4.4.2"></times><apply id="A1.SS2.SSS1.Px1.p1.2.m2.4.4.1.1.1.cmml" xref="A1.SS2.SSS1.Px1.p1.2.m2.4.4.1.1"><plus id="A1.SS2.SSS1.Px1.p1.2.m2.4.4.1.1.1.1.cmml" xref="A1.SS2.SSS1.Px1.p1.2.m2.4.4.1.1.1.1"></plus><cn id="A1.SS2.SSS1.Px1.p1.2.m2.4.4.1.1.1.2.cmml" type="integer" xref="A1.SS2.SSS1.Px1.p1.2.m2.4.4.1.1.1.2">256</cn><apply id="A1.SS2.SSS1.Px1.p1.2.m2.4.4.1.1.1.3.1.cmml" xref="A1.SS2.SSS1.Px1.p1.2.m2.4.4.1.1.1.3.2"><abs id="A1.SS2.SSS1.Px1.p1.2.m2.4.4.1.1.1.3.1.1.cmml" xref="A1.SS2.SSS1.Px1.p1.2.m2.4.4.1.1.1.3.2.1"></abs><ci id="A1.SS2.SSS1.Px1.p1.2.m2.1.1.cmml" xref="A1.SS2.SSS1.Px1.p1.2.m2.1.1">𝜷</ci></apply><apply id="A1.SS2.SSS1.Px1.p1.2.m2.4.4.1.1.1.4.1.cmml" xref="A1.SS2.SSS1.Px1.p1.2.m2.4.4.1.1.1.4.2"><abs id="A1.SS2.SSS1.Px1.p1.2.m2.4.4.1.1.1.4.1.1.cmml" xref="A1.SS2.SSS1.Px1.p1.2.m2.4.4.1.1.1.4.2.1"></abs><ci id="A1.SS2.SSS1.Px1.p1.2.m2.2.2.cmml" xref="A1.SS2.SSS1.Px1.p1.2.m2.2.2">𝝍</ci></apply><apply id="A1.SS2.SSS1.Px1.p1.2.m2.4.4.1.1.1.5.1.cmml" xref="A1.SS2.SSS1.Px1.p1.2.m2.4.4.1.1.1.5.2"><abs id="A1.SS2.SSS1.Px1.p1.2.m2.4.4.1.1.1.5.1.1.cmml" xref="A1.SS2.SSS1.Px1.p1.2.m2.4.4.1.1.1.5.2.1"></abs><ci id="A1.SS2.SSS1.Px1.p1.2.m2.3.3.cmml" xref="A1.SS2.SSS1.Px1.p1.2.m2.3.3">𝒘</ci></apply></apply><cn id="A1.SS2.SSS1.Px1.p1.2.m2.4.4.3.cmml" type="integer" xref="A1.SS2.SSS1.Px1.p1.2.m2.4.4.3">256</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.SSS1.Px1.p1.2.m2.4c">(256+|\boldsymbol{\beta}|+|\boldsymbol{\psi}|+|\boldsymbol{w}|)\times 256</annotation><annotation encoding="application/x-llamapun" id="A1.SS2.SSS1.Px1.p1.2.m2.4d">( 256 + | bold_italic_β | + | bold_italic_ψ | + | bold_italic_w | ) × 256</annotation></semantics></math> parameters, where the <math alttext="\boldsymbol{\beta}\in\mathbb{R}^{48}" class="ltx_Math" display="inline" id="A1.SS2.SSS1.Px1.p1.3.m3.1"><semantics id="A1.SS2.SSS1.Px1.p1.3.m3.1a"><mrow id="A1.SS2.SSS1.Px1.p1.3.m3.1.1" xref="A1.SS2.SSS1.Px1.p1.3.m3.1.1.cmml"><mi id="A1.SS2.SSS1.Px1.p1.3.m3.1.1.2" xref="A1.SS2.SSS1.Px1.p1.3.m3.1.1.2.cmml">𝜷</mi><mo id="A1.SS2.SSS1.Px1.p1.3.m3.1.1.1" xref="A1.SS2.SSS1.Px1.p1.3.m3.1.1.1.cmml">∈</mo><msup id="A1.SS2.SSS1.Px1.p1.3.m3.1.1.3" xref="A1.SS2.SSS1.Px1.p1.3.m3.1.1.3.cmml"><mi id="A1.SS2.SSS1.Px1.p1.3.m3.1.1.3.2" xref="A1.SS2.SSS1.Px1.p1.3.m3.1.1.3.2.cmml">ℝ</mi><mn id="A1.SS2.SSS1.Px1.p1.3.m3.1.1.3.3" xref="A1.SS2.SSS1.Px1.p1.3.m3.1.1.3.3.cmml">48</mn></msup></mrow><annotation-xml encoding="MathML-Content" id="A1.SS2.SSS1.Px1.p1.3.m3.1b"><apply id="A1.SS2.SSS1.Px1.p1.3.m3.1.1.cmml" xref="A1.SS2.SSS1.Px1.p1.3.m3.1.1"><in id="A1.SS2.SSS1.Px1.p1.3.m3.1.1.1.cmml" xref="A1.SS2.SSS1.Px1.p1.3.m3.1.1.1"></in><ci id="A1.SS2.SSS1.Px1.p1.3.m3.1.1.2.cmml" xref="A1.SS2.SSS1.Px1.p1.3.m3.1.1.2">𝜷</ci><apply id="A1.SS2.SSS1.Px1.p1.3.m3.1.1.3.cmml" xref="A1.SS2.SSS1.Px1.p1.3.m3.1.1.3"><csymbol cd="ambiguous" id="A1.SS2.SSS1.Px1.p1.3.m3.1.1.3.1.cmml" xref="A1.SS2.SSS1.Px1.p1.3.m3.1.1.3">superscript</csymbol><ci id="A1.SS2.SSS1.Px1.p1.3.m3.1.1.3.2.cmml" xref="A1.SS2.SSS1.Px1.p1.3.m3.1.1.3.2">ℝ</ci><cn id="A1.SS2.SSS1.Px1.p1.3.m3.1.1.3.3.cmml" type="integer" xref="A1.SS2.SSS1.Px1.p1.3.m3.1.1.3.3">48</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.SSS1.Px1.p1.3.m3.1c">\boldsymbol{\beta}\in\mathbb{R}^{48}</annotation><annotation encoding="application/x-llamapun" id="A1.SS2.SSS1.Px1.p1.3.m3.1d">bold_italic_β ∈ blackboard_R start_POSTSUPERSCRIPT 48 end_POSTSUPERSCRIPT</annotation></semantics></math> are the 3DMM identity coefficients, <math alttext="\boldsymbol{\psi}\in\mathbb{R}^{157}" class="ltx_Math" display="inline" id="A1.SS2.SSS1.Px1.p1.4.m4.1"><semantics id="A1.SS2.SSS1.Px1.p1.4.m4.1a"><mrow id="A1.SS2.SSS1.Px1.p1.4.m4.1.1" xref="A1.SS2.SSS1.Px1.p1.4.m4.1.1.cmml"><mi id="A1.SS2.SSS1.Px1.p1.4.m4.1.1.2" xref="A1.SS2.SSS1.Px1.p1.4.m4.1.1.2.cmml">𝝍</mi><mo id="A1.SS2.SSS1.Px1.p1.4.m4.1.1.1" xref="A1.SS2.SSS1.Px1.p1.4.m4.1.1.1.cmml">∈</mo><msup id="A1.SS2.SSS1.Px1.p1.4.m4.1.1.3" xref="A1.SS2.SSS1.Px1.p1.4.m4.1.1.3.cmml"><mi id="A1.SS2.SSS1.Px1.p1.4.m4.1.1.3.2" xref="A1.SS2.SSS1.Px1.p1.4.m4.1.1.3.2.cmml">ℝ</mi><mn id="A1.SS2.SSS1.Px1.p1.4.m4.1.1.3.3" xref="A1.SS2.SSS1.Px1.p1.4.m4.1.1.3.3.cmml">157</mn></msup></mrow><annotation-xml encoding="MathML-Content" id="A1.SS2.SSS1.Px1.p1.4.m4.1b"><apply id="A1.SS2.SSS1.Px1.p1.4.m4.1.1.cmml" xref="A1.SS2.SSS1.Px1.p1.4.m4.1.1"><in id="A1.SS2.SSS1.Px1.p1.4.m4.1.1.1.cmml" xref="A1.SS2.SSS1.Px1.p1.4.m4.1.1.1"></in><ci id="A1.SS2.SSS1.Px1.p1.4.m4.1.1.2.cmml" xref="A1.SS2.SSS1.Px1.p1.4.m4.1.1.2">𝝍</ci><apply id="A1.SS2.SSS1.Px1.p1.4.m4.1.1.3.cmml" xref="A1.SS2.SSS1.Px1.p1.4.m4.1.1.3"><csymbol cd="ambiguous" id="A1.SS2.SSS1.Px1.p1.4.m4.1.1.3.1.cmml" xref="A1.SS2.SSS1.Px1.p1.4.m4.1.1.3">superscript</csymbol><ci id="A1.SS2.SSS1.Px1.p1.4.m4.1.1.3.2.cmml" xref="A1.SS2.SSS1.Px1.p1.4.m4.1.1.3.2">ℝ</ci><cn id="A1.SS2.SSS1.Px1.p1.4.m4.1.1.3.3.cmml" type="integer" xref="A1.SS2.SSS1.Px1.p1.4.m4.1.1.3.3">157</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.SSS1.Px1.p1.4.m4.1c">\boldsymbol{\psi}\in\mathbb{R}^{157}</annotation><annotation encoding="application/x-llamapun" id="A1.SS2.SSS1.Px1.p1.4.m4.1d">bold_italic_ψ ∈ blackboard_R start_POSTSUPERSCRIPT 157 end_POSTSUPERSCRIPT</annotation></semantics></math> are the 3DMM expression coefficients, and <math alttext="\boldsymbol{w}\in\mathbb{R}^{64}" class="ltx_Math" display="inline" id="A1.SS2.SSS1.Px1.p1.5.m5.1"><semantics id="A1.SS2.SSS1.Px1.p1.5.m5.1a"><mrow id="A1.SS2.SSS1.Px1.p1.5.m5.1.1" xref="A1.SS2.SSS1.Px1.p1.5.m5.1.1.cmml"><mi id="A1.SS2.SSS1.Px1.p1.5.m5.1.1.2" xref="A1.SS2.SSS1.Px1.p1.5.m5.1.1.2.cmml">𝒘</mi><mo id="A1.SS2.SSS1.Px1.p1.5.m5.1.1.1" xref="A1.SS2.SSS1.Px1.p1.5.m5.1.1.1.cmml">∈</mo><msup id="A1.SS2.SSS1.Px1.p1.5.m5.1.1.3" xref="A1.SS2.SSS1.Px1.p1.5.m5.1.1.3.cmml"><mi id="A1.SS2.SSS1.Px1.p1.5.m5.1.1.3.2" xref="A1.SS2.SSS1.Px1.p1.5.m5.1.1.3.2.cmml">ℝ</mi><mn id="A1.SS2.SSS1.Px1.p1.5.m5.1.1.3.3" xref="A1.SS2.SSS1.Px1.p1.5.m5.1.1.3.3.cmml">64</mn></msup></mrow><annotation-xml encoding="MathML-Content" id="A1.SS2.SSS1.Px1.p1.5.m5.1b"><apply id="A1.SS2.SSS1.Px1.p1.5.m5.1.1.cmml" xref="A1.SS2.SSS1.Px1.p1.5.m5.1.1"><in id="A1.SS2.SSS1.Px1.p1.5.m5.1.1.1.cmml" xref="A1.SS2.SSS1.Px1.p1.5.m5.1.1.1"></in><ci id="A1.SS2.SSS1.Px1.p1.5.m5.1.1.2.cmml" xref="A1.SS2.SSS1.Px1.p1.5.m5.1.1.2">𝒘</ci><apply id="A1.SS2.SSS1.Px1.p1.5.m5.1.1.3.cmml" xref="A1.SS2.SSS1.Px1.p1.5.m5.1.1.3"><csymbol cd="ambiguous" id="A1.SS2.SSS1.Px1.p1.5.m5.1.1.3.1.cmml" xref="A1.SS2.SSS1.Px1.p1.5.m5.1.1.3">superscript</csymbol><ci id="A1.SS2.SSS1.Px1.p1.5.m5.1.1.3.2.cmml" xref="A1.SS2.SSS1.Px1.p1.5.m5.1.1.3.2">ℝ</ci><cn id="A1.SS2.SSS1.Px1.p1.5.m5.1.1.3.3.cmml" type="integer" xref="A1.SS2.SSS1.Px1.p1.5.m5.1.1.3.3">64</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.SSS1.Px1.p1.5.m5.1c">\boldsymbol{w}\in\mathbb{R}^{64}</annotation><annotation encoding="application/x-llamapun" id="A1.SS2.SSS1.Px1.p1.5.m5.1d">bold_italic_w ∈ blackboard_R start_POSTSUPERSCRIPT 64 end_POSTSUPERSCRIPT</annotation></semantics></math> is the optimizable latent identity code. The NeRF MLP trunk has depth <math alttext="8" class="ltx_Math" display="inline" id="A1.SS2.SSS1.Px1.p1.6.m6.1"><semantics id="A1.SS2.SSS1.Px1.p1.6.m6.1a"><mn id="A1.SS2.SSS1.Px1.p1.6.m6.1.1" xref="A1.SS2.SSS1.Px1.p1.6.m6.1.1.cmml">8</mn><annotation-xml encoding="MathML-Content" id="A1.SS2.SSS1.Px1.p1.6.m6.1b"><cn id="A1.SS2.SSS1.Px1.p1.6.m6.1.1.cmml" type="integer" xref="A1.SS2.SSS1.Px1.p1.6.m6.1.1">8</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.SSS1.Px1.p1.6.m6.1c">8</annotation><annotation encoding="application/x-llamapun" id="A1.SS2.SSS1.Px1.p1.6.m6.1d">8</annotation></semantics></math> and layers width <math alttext="(1024+|\boldsymbol{\beta}|+|\boldsymbol{\psi}|+|\boldsymbol{w}|)\times 1024" class="ltx_Math" display="inline" id="A1.SS2.SSS1.Px1.p1.7.m7.4"><semantics id="A1.SS2.SSS1.Px1.p1.7.m7.4a"><mrow id="A1.SS2.SSS1.Px1.p1.7.m7.4.4" xref="A1.SS2.SSS1.Px1.p1.7.m7.4.4.cmml"><mrow id="A1.SS2.SSS1.Px1.p1.7.m7.4.4.1.1" xref="A1.SS2.SSS1.Px1.p1.7.m7.4.4.1.1.1.cmml"><mo id="A1.SS2.SSS1.Px1.p1.7.m7.4.4.1.1.2" stretchy="false" xref="A1.SS2.SSS1.Px1.p1.7.m7.4.4.1.1.1.cmml">(</mo><mrow id="A1.SS2.SSS1.Px1.p1.7.m7.4.4.1.1.1" xref="A1.SS2.SSS1.Px1.p1.7.m7.4.4.1.1.1.cmml"><mn id="A1.SS2.SSS1.Px1.p1.7.m7.4.4.1.1.1.2" xref="A1.SS2.SSS1.Px1.p1.7.m7.4.4.1.1.1.2.cmml">1024</mn><mo id="A1.SS2.SSS1.Px1.p1.7.m7.4.4.1.1.1.1" xref="A1.SS2.SSS1.Px1.p1.7.m7.4.4.1.1.1.1.cmml">+</mo><mrow id="A1.SS2.SSS1.Px1.p1.7.m7.4.4.1.1.1.3.2" xref="A1.SS2.SSS1.Px1.p1.7.m7.4.4.1.1.1.3.1.cmml"><mo id="A1.SS2.SSS1.Px1.p1.7.m7.4.4.1.1.1.3.2.1" stretchy="false" xref="A1.SS2.SSS1.Px1.p1.7.m7.4.4.1.1.1.3.1.1.cmml">|</mo><mi id="A1.SS2.SSS1.Px1.p1.7.m7.1.1" xref="A1.SS2.SSS1.Px1.p1.7.m7.1.1.cmml">𝜷</mi><mo id="A1.SS2.SSS1.Px1.p1.7.m7.4.4.1.1.1.3.2.2" stretchy="false" xref="A1.SS2.SSS1.Px1.p1.7.m7.4.4.1.1.1.3.1.1.cmml">|</mo></mrow><mo id="A1.SS2.SSS1.Px1.p1.7.m7.4.4.1.1.1.1a" xref="A1.SS2.SSS1.Px1.p1.7.m7.4.4.1.1.1.1.cmml">+</mo><mrow id="A1.SS2.SSS1.Px1.p1.7.m7.4.4.1.1.1.4.2" xref="A1.SS2.SSS1.Px1.p1.7.m7.4.4.1.1.1.4.1.cmml"><mo id="A1.SS2.SSS1.Px1.p1.7.m7.4.4.1.1.1.4.2.1" stretchy="false" xref="A1.SS2.SSS1.Px1.p1.7.m7.4.4.1.1.1.4.1.1.cmml">|</mo><mi id="A1.SS2.SSS1.Px1.p1.7.m7.2.2" xref="A1.SS2.SSS1.Px1.p1.7.m7.2.2.cmml">𝝍</mi><mo id="A1.SS2.SSS1.Px1.p1.7.m7.4.4.1.1.1.4.2.2" stretchy="false" xref="A1.SS2.SSS1.Px1.p1.7.m7.4.4.1.1.1.4.1.1.cmml">|</mo></mrow><mo id="A1.SS2.SSS1.Px1.p1.7.m7.4.4.1.1.1.1b" xref="A1.SS2.SSS1.Px1.p1.7.m7.4.4.1.1.1.1.cmml">+</mo><mrow id="A1.SS2.SSS1.Px1.p1.7.m7.4.4.1.1.1.5.2" xref="A1.SS2.SSS1.Px1.p1.7.m7.4.4.1.1.1.5.1.cmml"><mo id="A1.SS2.SSS1.Px1.p1.7.m7.4.4.1.1.1.5.2.1" stretchy="false" xref="A1.SS2.SSS1.Px1.p1.7.m7.4.4.1.1.1.5.1.1.cmml">|</mo><mi id="A1.SS2.SSS1.Px1.p1.7.m7.3.3" xref="A1.SS2.SSS1.Px1.p1.7.m7.3.3.cmml">𝒘</mi><mo id="A1.SS2.SSS1.Px1.p1.7.m7.4.4.1.1.1.5.2.2" stretchy="false" xref="A1.SS2.SSS1.Px1.p1.7.m7.4.4.1.1.1.5.1.1.cmml">|</mo></mrow></mrow><mo id="A1.SS2.SSS1.Px1.p1.7.m7.4.4.1.1.3" rspace="0.055em" stretchy="false" xref="A1.SS2.SSS1.Px1.p1.7.m7.4.4.1.1.1.cmml">)</mo></mrow><mo id="A1.SS2.SSS1.Px1.p1.7.m7.4.4.2" rspace="0.222em" xref="A1.SS2.SSS1.Px1.p1.7.m7.4.4.2.cmml">×</mo><mn id="A1.SS2.SSS1.Px1.p1.7.m7.4.4.3" xref="A1.SS2.SSS1.Px1.p1.7.m7.4.4.3.cmml">1024</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.SS2.SSS1.Px1.p1.7.m7.4b"><apply id="A1.SS2.SSS1.Px1.p1.7.m7.4.4.cmml" xref="A1.SS2.SSS1.Px1.p1.7.m7.4.4"><times id="A1.SS2.SSS1.Px1.p1.7.m7.4.4.2.cmml" xref="A1.SS2.SSS1.Px1.p1.7.m7.4.4.2"></times><apply id="A1.SS2.SSS1.Px1.p1.7.m7.4.4.1.1.1.cmml" xref="A1.SS2.SSS1.Px1.p1.7.m7.4.4.1.1"><plus id="A1.SS2.SSS1.Px1.p1.7.m7.4.4.1.1.1.1.cmml" xref="A1.SS2.SSS1.Px1.p1.7.m7.4.4.1.1.1.1"></plus><cn id="A1.SS2.SSS1.Px1.p1.7.m7.4.4.1.1.1.2.cmml" type="integer" xref="A1.SS2.SSS1.Px1.p1.7.m7.4.4.1.1.1.2">1024</cn><apply id="A1.SS2.SSS1.Px1.p1.7.m7.4.4.1.1.1.3.1.cmml" xref="A1.SS2.SSS1.Px1.p1.7.m7.4.4.1.1.1.3.2"><abs id="A1.SS2.SSS1.Px1.p1.7.m7.4.4.1.1.1.3.1.1.cmml" xref="A1.SS2.SSS1.Px1.p1.7.m7.4.4.1.1.1.3.2.1"></abs><ci id="A1.SS2.SSS1.Px1.p1.7.m7.1.1.cmml" xref="A1.SS2.SSS1.Px1.p1.7.m7.1.1">𝜷</ci></apply><apply id="A1.SS2.SSS1.Px1.p1.7.m7.4.4.1.1.1.4.1.cmml" xref="A1.SS2.SSS1.Px1.p1.7.m7.4.4.1.1.1.4.2"><abs id="A1.SS2.SSS1.Px1.p1.7.m7.4.4.1.1.1.4.1.1.cmml" xref="A1.SS2.SSS1.Px1.p1.7.m7.4.4.1.1.1.4.2.1"></abs><ci id="A1.SS2.SSS1.Px1.p1.7.m7.2.2.cmml" xref="A1.SS2.SSS1.Px1.p1.7.m7.2.2">𝝍</ci></apply><apply id="A1.SS2.SSS1.Px1.p1.7.m7.4.4.1.1.1.5.1.cmml" xref="A1.SS2.SSS1.Px1.p1.7.m7.4.4.1.1.1.5.2"><abs id="A1.SS2.SSS1.Px1.p1.7.m7.4.4.1.1.1.5.1.1.cmml" xref="A1.SS2.SSS1.Px1.p1.7.m7.4.4.1.1.1.5.2.1"></abs><ci id="A1.SS2.SSS1.Px1.p1.7.m7.3.3.cmml" xref="A1.SS2.SSS1.Px1.p1.7.m7.3.3">𝒘</ci></apply></apply><cn id="A1.SS2.SSS1.Px1.p1.7.m7.4.4.3.cmml" type="integer" xref="A1.SS2.SSS1.Px1.p1.7.m7.4.4.3">1024</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.SSS1.Px1.p1.7.m7.4c">(1024+|\boldsymbol{\beta}|+|\boldsymbol{\psi}|+|\boldsymbol{w}|)\times 1024</annotation><annotation encoding="application/x-llamapun" id="A1.SS2.SSS1.Px1.p1.7.m7.4d">( 1024 + | bold_italic_β | + | bold_italic_ψ | + | bold_italic_w | ) × 1024</annotation></semantics></math>. The NeRF MLP trunk features are projected to 3 dimensions and normalized to predict negative normals. The color is predicted from the NeRF MLP trunk features after a bottleneck with width 256 and a single view-conditioned layer with width 128. We optimize one <math alttext="\boldsymbol{w}" class="ltx_Math" display="inline" id="A1.SS2.SSS1.Px1.p1.8.m8.1"><semantics id="A1.SS2.SSS1.Px1.p1.8.m8.1a"><mi id="A1.SS2.SSS1.Px1.p1.8.m8.1.1" xref="A1.SS2.SSS1.Px1.p1.8.m8.1.1.cmml">𝒘</mi><annotation-xml encoding="MathML-Content" id="A1.SS2.SSS1.Px1.p1.8.m8.1b"><ci id="A1.SS2.SSS1.Px1.p1.8.m8.1.1.cmml" xref="A1.SS2.SSS1.Px1.p1.8.m8.1.1">𝒘</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.SSS1.Px1.p1.8.m8.1c">\boldsymbol{w}</annotation><annotation encoding="application/x-llamapun" id="A1.SS2.SSS1.Px1.p1.8.m8.1d">bold_italic_w</annotation></semantics></math> code per identity, which yields a codebook of size <math alttext="1500\times 64" class="ltx_Math" display="inline" id="A1.SS2.SSS1.Px1.p1.9.m9.1"><semantics id="A1.SS2.SSS1.Px1.p1.9.m9.1a"><mrow id="A1.SS2.SSS1.Px1.p1.9.m9.1.1" xref="A1.SS2.SSS1.Px1.p1.9.m9.1.1.cmml"><mn id="A1.SS2.SSS1.Px1.p1.9.m9.1.1.2" xref="A1.SS2.SSS1.Px1.p1.9.m9.1.1.2.cmml">1500</mn><mo id="A1.SS2.SSS1.Px1.p1.9.m9.1.1.1" lspace="0.222em" rspace="0.222em" xref="A1.SS2.SSS1.Px1.p1.9.m9.1.1.1.cmml">×</mo><mn id="A1.SS2.SSS1.Px1.p1.9.m9.1.1.3" xref="A1.SS2.SSS1.Px1.p1.9.m9.1.1.3.cmml">64</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.SS2.SSS1.Px1.p1.9.m9.1b"><apply id="A1.SS2.SSS1.Px1.p1.9.m9.1.1.cmml" xref="A1.SS2.SSS1.Px1.p1.9.m9.1.1"><times id="A1.SS2.SSS1.Px1.p1.9.m9.1.1.1.cmml" xref="A1.SS2.SSS1.Px1.p1.9.m9.1.1.1"></times><cn id="A1.SS2.SSS1.Px1.p1.9.m9.1.1.2.cmml" type="integer" xref="A1.SS2.SSS1.Px1.p1.9.m9.1.1.2">1500</cn><cn id="A1.SS2.SSS1.Px1.p1.9.m9.1.1.3.cmml" type="integer" xref="A1.SS2.SSS1.Px1.p1.9.m9.1.1.3">64</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.SSS1.Px1.p1.9.m9.1c">1500\times 64</annotation><annotation encoding="application/x-llamapun" id="A1.SS2.SSS1.Px1.p1.9.m9.1d">1500 × 64</annotation></semantics></math>. The total parameter count is 32 Mio.
The weights are initialized with He Uniform Variance Scaling <cite class="ltx_cite ltx_citemacro_citep">(He et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib23" title="">2015</a>)</cite>.</p>
</div>
</section>
<section class="ltx_paragraph" id="A1.SS2.SSS1.Px2">
<h5 class="ltx_title ltx_title_paragraph">Training</h5>
<div class="ltx_para" id="A1.SS2.SSS1.Px2.p1">
<p class="ltx_p" id="A1.SS2.SSS1.Px2.p1.6">We train the prior model on images of 1,500 synthetic identities, rendering each with 13 expressions and 30 views. In total, we train the full prior model for 1 Mio. steps on 64 TPUs with a batch size of
<math alttext="131,072" class="ltx_Math" display="inline" id="A1.SS2.SSS1.Px2.p1.1.m1.2"><semantics id="A1.SS2.SSS1.Px2.p1.1.m1.2a"><mrow id="A1.SS2.SSS1.Px2.p1.1.m1.2.3.2" xref="A1.SS2.SSS1.Px2.p1.1.m1.2.3.1.cmml"><mn id="A1.SS2.SSS1.Px2.p1.1.m1.1.1" xref="A1.SS2.SSS1.Px2.p1.1.m1.1.1.cmml">131</mn><mo id="A1.SS2.SSS1.Px2.p1.1.m1.2.3.2.1" xref="A1.SS2.SSS1.Px2.p1.1.m1.2.3.1.cmml">,</mo><mn id="A1.SS2.SSS1.Px2.p1.1.m1.2.2" xref="A1.SS2.SSS1.Px2.p1.1.m1.2.2.cmml">072</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.SS2.SSS1.Px2.p1.1.m1.2b"><list id="A1.SS2.SSS1.Px2.p1.1.m1.2.3.1.cmml" xref="A1.SS2.SSS1.Px2.p1.1.m1.2.3.2"><cn id="A1.SS2.SSS1.Px2.p1.1.m1.1.1.cmml" type="integer" xref="A1.SS2.SSS1.Px2.p1.1.m1.1.1">131</cn><cn id="A1.SS2.SSS1.Px2.p1.1.m1.2.2.cmml" type="integer" xref="A1.SS2.SSS1.Px2.p1.1.m1.2.2">072</cn></list></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.SSS1.Px2.p1.1.m1.2c">131,072</annotation><annotation encoding="application/x-llamapun" id="A1.SS2.SSS1.Px2.p1.1.m1.2d">131 , 072</annotation></semantics></math> rays per step (<math alttext="256" class="ltx_Math" display="inline" id="A1.SS2.SSS1.Px2.p1.2.m2.1"><semantics id="A1.SS2.SSS1.Px2.p1.2.m2.1a"><mn id="A1.SS2.SSS1.Px2.p1.2.m2.1.1" xref="A1.SS2.SSS1.Px2.p1.2.m2.1.1.cmml">256</mn><annotation-xml encoding="MathML-Content" id="A1.SS2.SSS1.Px2.p1.2.m2.1b"><cn id="A1.SS2.SSS1.Px2.p1.2.m2.1.1.cmml" type="integer" xref="A1.SS2.SSS1.Px2.p1.2.m2.1.1">256</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.SSS1.Px2.p1.2.m2.1c">256</annotation><annotation encoding="application/x-llamapun" id="A1.SS2.SSS1.Px2.p1.2.m2.1d">256</annotation></semantics></math> identities <math alttext="\times" class="ltx_Math" display="inline" id="A1.SS2.SSS1.Px2.p1.3.m3.1"><semantics id="A1.SS2.SSS1.Px2.p1.3.m3.1a"><mo id="A1.SS2.SSS1.Px2.p1.3.m3.1.1" xref="A1.SS2.SSS1.Px2.p1.3.m3.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="A1.SS2.SSS1.Px2.p1.3.m3.1b"><times id="A1.SS2.SSS1.Px2.p1.3.m3.1.1.cmml" xref="A1.SS2.SSS1.Px2.p1.3.m3.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.SSS1.Px2.p1.3.m3.1c">\times</annotation><annotation encoding="application/x-llamapun" id="A1.SS2.SSS1.Px2.p1.3.m3.1d">×</annotation></semantics></math> <math alttext="8" class="ltx_Math" display="inline" id="A1.SS2.SSS1.Px2.p1.4.m4.1"><semantics id="A1.SS2.SSS1.Px2.p1.4.m4.1a"><mn id="A1.SS2.SSS1.Px2.p1.4.m4.1.1" xref="A1.SS2.SSS1.Px2.p1.4.m4.1.1.cmml">8</mn><annotation-xml encoding="MathML-Content" id="A1.SS2.SSS1.Px2.p1.4.m4.1b"><cn id="A1.SS2.SSS1.Px2.p1.4.m4.1.1.cmml" type="integer" xref="A1.SS2.SSS1.Px2.p1.4.m4.1.1">8</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.SSS1.Px2.p1.4.m4.1c">8</annotation><annotation encoding="application/x-llamapun" id="A1.SS2.SSS1.Px2.p1.4.m4.1d">8</annotation></semantics></math> view <math alttext="\times" class="ltx_Math" display="inline" id="A1.SS2.SSS1.Px2.p1.5.m5.1"><semantics id="A1.SS2.SSS1.Px2.p1.5.m5.1a"><mo id="A1.SS2.SSS1.Px2.p1.5.m5.1.1" xref="A1.SS2.SSS1.Px2.p1.5.m5.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="A1.SS2.SSS1.Px2.p1.5.m5.1b"><times id="A1.SS2.SSS1.Px2.p1.5.m5.1.1.cmml" xref="A1.SS2.SSS1.Px2.p1.5.m5.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.SSS1.Px2.p1.5.m5.1c">\times</annotation><annotation encoding="application/x-llamapun" id="A1.SS2.SSS1.Px2.p1.5.m5.1d">×</annotation></semantics></math> <math alttext="64" class="ltx_Math" display="inline" id="A1.SS2.SSS1.Px2.p1.6.m6.1"><semantics id="A1.SS2.SSS1.Px2.p1.6.m6.1a"><mn id="A1.SS2.SSS1.Px2.p1.6.m6.1.1" xref="A1.SS2.SSS1.Px2.p1.6.m6.1.1.cmml">64</mn><annotation-xml encoding="MathML-Content" id="A1.SS2.SSS1.Px2.p1.6.m6.1b"><cn id="A1.SS2.SSS1.Px2.p1.6.m6.1.1.cmml" type="integer" xref="A1.SS2.SSS1.Px2.p1.6.m6.1.1">64</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.SSS1.Px2.p1.6.m6.1c">64</annotation><annotation encoding="application/x-llamapun" id="A1.SS2.SSS1.Px2.p1.6.m6.1d">64</annotation></semantics></math> pixels), which takes about 10 days. However, we observe that the model already reaches near convergence after 105,000 steps. In particular, fine-tuning that uses the model trained for 105,000 steps achieves very similar photo-metric quality as fine-tuning the model trained for 1 Mio. steps, please see our ablation study in Sec. <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#S4.SS3" title="4.3. Ablation Study ‣ 4. Experiments ‣ Cafca: High-quality Novel View Synthesis of Expressive Faces from Casual Few-shot Captures"><span class="ltx_text ltx_ref_tag">4.3</span></a> and the supp. HTML page for visuals.</p>
</div>
<div class="ltx_para" id="A1.SS2.SSS1.Px2.p2">
<p class="ltx_p" id="A1.SS2.SSS1.Px2.p2.1">We train our model with 128 samples for the proposal and 128 samples for the NeRF MLP. The proposal MLP is sampled twice and the NeRF MLP is sampled once. Both the proposal and NeRF MLP use the same positional encoding for the inputs. The xyz inputs use twelve levels; the view direction four levels and appends the view direction without positional encoding.</p>
</div>
</section>
<section class="ltx_paragraph" id="A1.SS2.SSS1.Px3">
<h5 class="ltx_title ltx_title_paragraph">Losses</h5>
<div class="ltx_para" id="A1.SS2.SSS1.Px3.p1">
<p class="ltx_p" id="A1.SS2.SSS1.Px3.p1.5">The terms in the loss function <math alttext="\mathcal{L}_{\text{prior}}=\mathcal{L}_{\text{recon}}+\lambda_{\text{prop}}%
\mathcal{L}_{\text{prop}}" class="ltx_Math" display="inline" id="A1.SS2.SSS1.Px3.p1.1.m1.1"><semantics id="A1.SS2.SSS1.Px3.p1.1.m1.1a"><mrow id="A1.SS2.SSS1.Px3.p1.1.m1.1.1" xref="A1.SS2.SSS1.Px3.p1.1.m1.1.1.cmml"><msub id="A1.SS2.SSS1.Px3.p1.1.m1.1.1.2" xref="A1.SS2.SSS1.Px3.p1.1.m1.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="A1.SS2.SSS1.Px3.p1.1.m1.1.1.2.2" xref="A1.SS2.SSS1.Px3.p1.1.m1.1.1.2.2.cmml">ℒ</mi><mtext id="A1.SS2.SSS1.Px3.p1.1.m1.1.1.2.3" xref="A1.SS2.SSS1.Px3.p1.1.m1.1.1.2.3a.cmml">prior</mtext></msub><mo id="A1.SS2.SSS1.Px3.p1.1.m1.1.1.1" xref="A1.SS2.SSS1.Px3.p1.1.m1.1.1.1.cmml">=</mo><mrow id="A1.SS2.SSS1.Px3.p1.1.m1.1.1.3" xref="A1.SS2.SSS1.Px3.p1.1.m1.1.1.3.cmml"><msub id="A1.SS2.SSS1.Px3.p1.1.m1.1.1.3.2" xref="A1.SS2.SSS1.Px3.p1.1.m1.1.1.3.2.cmml"><mi class="ltx_font_mathcaligraphic" id="A1.SS2.SSS1.Px3.p1.1.m1.1.1.3.2.2" xref="A1.SS2.SSS1.Px3.p1.1.m1.1.1.3.2.2.cmml">ℒ</mi><mtext id="A1.SS2.SSS1.Px3.p1.1.m1.1.1.3.2.3" xref="A1.SS2.SSS1.Px3.p1.1.m1.1.1.3.2.3a.cmml">recon</mtext></msub><mo id="A1.SS2.SSS1.Px3.p1.1.m1.1.1.3.1" xref="A1.SS2.SSS1.Px3.p1.1.m1.1.1.3.1.cmml">+</mo><mrow id="A1.SS2.SSS1.Px3.p1.1.m1.1.1.3.3" xref="A1.SS2.SSS1.Px3.p1.1.m1.1.1.3.3.cmml"><msub id="A1.SS2.SSS1.Px3.p1.1.m1.1.1.3.3.2" xref="A1.SS2.SSS1.Px3.p1.1.m1.1.1.3.3.2.cmml"><mi id="A1.SS2.SSS1.Px3.p1.1.m1.1.1.3.3.2.2" xref="A1.SS2.SSS1.Px3.p1.1.m1.1.1.3.3.2.2.cmml">λ</mi><mtext id="A1.SS2.SSS1.Px3.p1.1.m1.1.1.3.3.2.3" xref="A1.SS2.SSS1.Px3.p1.1.m1.1.1.3.3.2.3a.cmml">prop</mtext></msub><mo id="A1.SS2.SSS1.Px3.p1.1.m1.1.1.3.3.1" xref="A1.SS2.SSS1.Px3.p1.1.m1.1.1.3.3.1.cmml">⁢</mo><msub id="A1.SS2.SSS1.Px3.p1.1.m1.1.1.3.3.3" xref="A1.SS2.SSS1.Px3.p1.1.m1.1.1.3.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="A1.SS2.SSS1.Px3.p1.1.m1.1.1.3.3.3.2" xref="A1.SS2.SSS1.Px3.p1.1.m1.1.1.3.3.3.2.cmml">ℒ</mi><mtext id="A1.SS2.SSS1.Px3.p1.1.m1.1.1.3.3.3.3" xref="A1.SS2.SSS1.Px3.p1.1.m1.1.1.3.3.3.3a.cmml">prop</mtext></msub></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="A1.SS2.SSS1.Px3.p1.1.m1.1b"><apply id="A1.SS2.SSS1.Px3.p1.1.m1.1.1.cmml" xref="A1.SS2.SSS1.Px3.p1.1.m1.1.1"><eq id="A1.SS2.SSS1.Px3.p1.1.m1.1.1.1.cmml" xref="A1.SS2.SSS1.Px3.p1.1.m1.1.1.1"></eq><apply id="A1.SS2.SSS1.Px3.p1.1.m1.1.1.2.cmml" xref="A1.SS2.SSS1.Px3.p1.1.m1.1.1.2"><csymbol cd="ambiguous" id="A1.SS2.SSS1.Px3.p1.1.m1.1.1.2.1.cmml" xref="A1.SS2.SSS1.Px3.p1.1.m1.1.1.2">subscript</csymbol><ci id="A1.SS2.SSS1.Px3.p1.1.m1.1.1.2.2.cmml" xref="A1.SS2.SSS1.Px3.p1.1.m1.1.1.2.2">ℒ</ci><ci id="A1.SS2.SSS1.Px3.p1.1.m1.1.1.2.3a.cmml" xref="A1.SS2.SSS1.Px3.p1.1.m1.1.1.2.3"><mtext id="A1.SS2.SSS1.Px3.p1.1.m1.1.1.2.3.cmml" mathsize="70%" xref="A1.SS2.SSS1.Px3.p1.1.m1.1.1.2.3">prior</mtext></ci></apply><apply id="A1.SS2.SSS1.Px3.p1.1.m1.1.1.3.cmml" xref="A1.SS2.SSS1.Px3.p1.1.m1.1.1.3"><plus id="A1.SS2.SSS1.Px3.p1.1.m1.1.1.3.1.cmml" xref="A1.SS2.SSS1.Px3.p1.1.m1.1.1.3.1"></plus><apply id="A1.SS2.SSS1.Px3.p1.1.m1.1.1.3.2.cmml" xref="A1.SS2.SSS1.Px3.p1.1.m1.1.1.3.2"><csymbol cd="ambiguous" id="A1.SS2.SSS1.Px3.p1.1.m1.1.1.3.2.1.cmml" xref="A1.SS2.SSS1.Px3.p1.1.m1.1.1.3.2">subscript</csymbol><ci id="A1.SS2.SSS1.Px3.p1.1.m1.1.1.3.2.2.cmml" xref="A1.SS2.SSS1.Px3.p1.1.m1.1.1.3.2.2">ℒ</ci><ci id="A1.SS2.SSS1.Px3.p1.1.m1.1.1.3.2.3a.cmml" xref="A1.SS2.SSS1.Px3.p1.1.m1.1.1.3.2.3"><mtext id="A1.SS2.SSS1.Px3.p1.1.m1.1.1.3.2.3.cmml" mathsize="70%" xref="A1.SS2.SSS1.Px3.p1.1.m1.1.1.3.2.3">recon</mtext></ci></apply><apply id="A1.SS2.SSS1.Px3.p1.1.m1.1.1.3.3.cmml" xref="A1.SS2.SSS1.Px3.p1.1.m1.1.1.3.3"><times id="A1.SS2.SSS1.Px3.p1.1.m1.1.1.3.3.1.cmml" xref="A1.SS2.SSS1.Px3.p1.1.m1.1.1.3.3.1"></times><apply id="A1.SS2.SSS1.Px3.p1.1.m1.1.1.3.3.2.cmml" xref="A1.SS2.SSS1.Px3.p1.1.m1.1.1.3.3.2"><csymbol cd="ambiguous" id="A1.SS2.SSS1.Px3.p1.1.m1.1.1.3.3.2.1.cmml" xref="A1.SS2.SSS1.Px3.p1.1.m1.1.1.3.3.2">subscript</csymbol><ci id="A1.SS2.SSS1.Px3.p1.1.m1.1.1.3.3.2.2.cmml" xref="A1.SS2.SSS1.Px3.p1.1.m1.1.1.3.3.2.2">𝜆</ci><ci id="A1.SS2.SSS1.Px3.p1.1.m1.1.1.3.3.2.3a.cmml" xref="A1.SS2.SSS1.Px3.p1.1.m1.1.1.3.3.2.3"><mtext id="A1.SS2.SSS1.Px3.p1.1.m1.1.1.3.3.2.3.cmml" mathsize="70%" xref="A1.SS2.SSS1.Px3.p1.1.m1.1.1.3.3.2.3">prop</mtext></ci></apply><apply id="A1.SS2.SSS1.Px3.p1.1.m1.1.1.3.3.3.cmml" xref="A1.SS2.SSS1.Px3.p1.1.m1.1.1.3.3.3"><csymbol cd="ambiguous" id="A1.SS2.SSS1.Px3.p1.1.m1.1.1.3.3.3.1.cmml" xref="A1.SS2.SSS1.Px3.p1.1.m1.1.1.3.3.3">subscript</csymbol><ci id="A1.SS2.SSS1.Px3.p1.1.m1.1.1.3.3.3.2.cmml" xref="A1.SS2.SSS1.Px3.p1.1.m1.1.1.3.3.3.2">ℒ</ci><ci id="A1.SS2.SSS1.Px3.p1.1.m1.1.1.3.3.3.3a.cmml" xref="A1.SS2.SSS1.Px3.p1.1.m1.1.1.3.3.3.3"><mtext id="A1.SS2.SSS1.Px3.p1.1.m1.1.1.3.3.3.3.cmml" mathsize="70%" xref="A1.SS2.SSS1.Px3.p1.1.m1.1.1.3.3.3.3">prop</mtext></ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.SSS1.Px3.p1.1.m1.1c">\mathcal{L}_{\text{prior}}=\mathcal{L}_{\text{recon}}+\lambda_{\text{prop}}%
\mathcal{L}_{\text{prop}}</annotation><annotation encoding="application/x-llamapun" id="A1.SS2.SSS1.Px3.p1.1.m1.1d">caligraphic_L start_POSTSUBSCRIPT prior end_POSTSUBSCRIPT = caligraphic_L start_POSTSUBSCRIPT recon end_POSTSUBSCRIPT + italic_λ start_POSTSUBSCRIPT prop end_POSTSUBSCRIPT caligraphic_L start_POSTSUBSCRIPT prop end_POSTSUBSCRIPT</annotation></semantics></math> are a combination of the mean absolute photo-metric error of the ground truth color <math alttext="\boldsymbol{c}" class="ltx_Math" display="inline" id="A1.SS2.SSS1.Px3.p1.2.m2.1"><semantics id="A1.SS2.SSS1.Px3.p1.2.m2.1a"><mi id="A1.SS2.SSS1.Px3.p1.2.m2.1.1" xref="A1.SS2.SSS1.Px3.p1.2.m2.1.1.cmml">𝒄</mi><annotation-xml encoding="MathML-Content" id="A1.SS2.SSS1.Px3.p1.2.m2.1b"><ci id="A1.SS2.SSS1.Px3.p1.2.m2.1.1.cmml" xref="A1.SS2.SSS1.Px3.p1.2.m2.1.1">𝒄</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.SSS1.Px3.p1.2.m2.1c">\boldsymbol{c}</annotation><annotation encoding="application/x-llamapun" id="A1.SS2.SSS1.Px3.p1.2.m2.1d">bold_italic_c</annotation></semantics></math> versus the predicted color <math alttext="\boldsymbol{\hat{c}}" class="ltx_Math" display="inline" id="A1.SS2.SSS1.Px3.p1.3.m3.1"><semantics id="A1.SS2.SSS1.Px3.p1.3.m3.1a"><mover accent="true" id="A1.SS2.SSS1.Px3.p1.3.m3.1.1" xref="A1.SS2.SSS1.Px3.p1.3.m3.1.1.cmml"><mi id="A1.SS2.SSS1.Px3.p1.3.m3.1.1.2" xref="A1.SS2.SSS1.Px3.p1.3.m3.1.1.2.cmml">𝒄</mi><mo class="ltx_mathvariant_bold" id="A1.SS2.SSS1.Px3.p1.3.m3.1.1.1" mathvariant="bold" xref="A1.SS2.SSS1.Px3.p1.3.m3.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="A1.SS2.SSS1.Px3.p1.3.m3.1b"><apply id="A1.SS2.SSS1.Px3.p1.3.m3.1.1.cmml" xref="A1.SS2.SSS1.Px3.p1.3.m3.1.1"><ci id="A1.SS2.SSS1.Px3.p1.3.m3.1.1.1.cmml" xref="A1.SS2.SSS1.Px3.p1.3.m3.1.1.1">bold-^</ci><ci id="A1.SS2.SSS1.Px3.p1.3.m3.1.1.2.cmml" xref="A1.SS2.SSS1.Px3.p1.3.m3.1.1.2">𝒄</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.SSS1.Px3.p1.3.m3.1c">\boldsymbol{\hat{c}}</annotation><annotation encoding="application/x-llamapun" id="A1.SS2.SSS1.Px3.p1.3.m3.1d">overbold_^ start_ARG bold_italic_c end_ARG</annotation></semantics></math>: <math alttext="\mathcal{L}_{\text{recon}}=\lVert\boldsymbol{c}-\boldsymbol{\hat{c}}\rVert_{1}" class="ltx_Math" display="inline" id="A1.SS2.SSS1.Px3.p1.4.m4.1"><semantics id="A1.SS2.SSS1.Px3.p1.4.m4.1a"><mrow id="A1.SS2.SSS1.Px3.p1.4.m4.1.1" xref="A1.SS2.SSS1.Px3.p1.4.m4.1.1.cmml"><msub id="A1.SS2.SSS1.Px3.p1.4.m4.1.1.3" xref="A1.SS2.SSS1.Px3.p1.4.m4.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="A1.SS2.SSS1.Px3.p1.4.m4.1.1.3.2" xref="A1.SS2.SSS1.Px3.p1.4.m4.1.1.3.2.cmml">ℒ</mi><mtext id="A1.SS2.SSS1.Px3.p1.4.m4.1.1.3.3" xref="A1.SS2.SSS1.Px3.p1.4.m4.1.1.3.3a.cmml">recon</mtext></msub><mo id="A1.SS2.SSS1.Px3.p1.4.m4.1.1.2" rspace="0.1389em" xref="A1.SS2.SSS1.Px3.p1.4.m4.1.1.2.cmml">=</mo><msub id="A1.SS2.SSS1.Px3.p1.4.m4.1.1.1" xref="A1.SS2.SSS1.Px3.p1.4.m4.1.1.1.cmml"><mrow id="A1.SS2.SSS1.Px3.p1.4.m4.1.1.1.1.1" xref="A1.SS2.SSS1.Px3.p1.4.m4.1.1.1.1.2.cmml"><mo fence="true" id="A1.SS2.SSS1.Px3.p1.4.m4.1.1.1.1.1.2" lspace="0.1389em" rspace="0em" xref="A1.SS2.SSS1.Px3.p1.4.m4.1.1.1.1.2.1.cmml">∥</mo><mrow id="A1.SS2.SSS1.Px3.p1.4.m4.1.1.1.1.1.1" xref="A1.SS2.SSS1.Px3.p1.4.m4.1.1.1.1.1.1.cmml"><mi id="A1.SS2.SSS1.Px3.p1.4.m4.1.1.1.1.1.1.2" xref="A1.SS2.SSS1.Px3.p1.4.m4.1.1.1.1.1.1.2.cmml">𝒄</mi><mo id="A1.SS2.SSS1.Px3.p1.4.m4.1.1.1.1.1.1.1" xref="A1.SS2.SSS1.Px3.p1.4.m4.1.1.1.1.1.1.1.cmml">−</mo><mover accent="true" id="A1.SS2.SSS1.Px3.p1.4.m4.1.1.1.1.1.1.3" xref="A1.SS2.SSS1.Px3.p1.4.m4.1.1.1.1.1.1.3.cmml"><mi id="A1.SS2.SSS1.Px3.p1.4.m4.1.1.1.1.1.1.3.2" xref="A1.SS2.SSS1.Px3.p1.4.m4.1.1.1.1.1.1.3.2.cmml">𝒄</mi><mo class="ltx_mathvariant_bold" id="A1.SS2.SSS1.Px3.p1.4.m4.1.1.1.1.1.1.3.1" mathvariant="bold" xref="A1.SS2.SSS1.Px3.p1.4.m4.1.1.1.1.1.1.3.1.cmml">^</mo></mover></mrow><mo fence="true" id="A1.SS2.SSS1.Px3.p1.4.m4.1.1.1.1.1.3" lspace="0em" xref="A1.SS2.SSS1.Px3.p1.4.m4.1.1.1.1.2.1.cmml">∥</mo></mrow><mn id="A1.SS2.SSS1.Px3.p1.4.m4.1.1.1.3" xref="A1.SS2.SSS1.Px3.p1.4.m4.1.1.1.3.cmml">1</mn></msub></mrow><annotation-xml encoding="MathML-Content" id="A1.SS2.SSS1.Px3.p1.4.m4.1b"><apply id="A1.SS2.SSS1.Px3.p1.4.m4.1.1.cmml" xref="A1.SS2.SSS1.Px3.p1.4.m4.1.1"><eq id="A1.SS2.SSS1.Px3.p1.4.m4.1.1.2.cmml" xref="A1.SS2.SSS1.Px3.p1.4.m4.1.1.2"></eq><apply id="A1.SS2.SSS1.Px3.p1.4.m4.1.1.3.cmml" xref="A1.SS2.SSS1.Px3.p1.4.m4.1.1.3"><csymbol cd="ambiguous" id="A1.SS2.SSS1.Px3.p1.4.m4.1.1.3.1.cmml" xref="A1.SS2.SSS1.Px3.p1.4.m4.1.1.3">subscript</csymbol><ci id="A1.SS2.SSS1.Px3.p1.4.m4.1.1.3.2.cmml" xref="A1.SS2.SSS1.Px3.p1.4.m4.1.1.3.2">ℒ</ci><ci id="A1.SS2.SSS1.Px3.p1.4.m4.1.1.3.3a.cmml" xref="A1.SS2.SSS1.Px3.p1.4.m4.1.1.3.3"><mtext id="A1.SS2.SSS1.Px3.p1.4.m4.1.1.3.3.cmml" mathsize="70%" xref="A1.SS2.SSS1.Px3.p1.4.m4.1.1.3.3">recon</mtext></ci></apply><apply id="A1.SS2.SSS1.Px3.p1.4.m4.1.1.1.cmml" xref="A1.SS2.SSS1.Px3.p1.4.m4.1.1.1"><csymbol cd="ambiguous" id="A1.SS2.SSS1.Px3.p1.4.m4.1.1.1.2.cmml" xref="A1.SS2.SSS1.Px3.p1.4.m4.1.1.1">subscript</csymbol><apply id="A1.SS2.SSS1.Px3.p1.4.m4.1.1.1.1.2.cmml" xref="A1.SS2.SSS1.Px3.p1.4.m4.1.1.1.1.1"><csymbol cd="latexml" id="A1.SS2.SSS1.Px3.p1.4.m4.1.1.1.1.2.1.cmml" xref="A1.SS2.SSS1.Px3.p1.4.m4.1.1.1.1.1.2">delimited-∥∥</csymbol><apply id="A1.SS2.SSS1.Px3.p1.4.m4.1.1.1.1.1.1.cmml" xref="A1.SS2.SSS1.Px3.p1.4.m4.1.1.1.1.1.1"><minus id="A1.SS2.SSS1.Px3.p1.4.m4.1.1.1.1.1.1.1.cmml" xref="A1.SS2.SSS1.Px3.p1.4.m4.1.1.1.1.1.1.1"></minus><ci id="A1.SS2.SSS1.Px3.p1.4.m4.1.1.1.1.1.1.2.cmml" xref="A1.SS2.SSS1.Px3.p1.4.m4.1.1.1.1.1.1.2">𝒄</ci><apply id="A1.SS2.SSS1.Px3.p1.4.m4.1.1.1.1.1.1.3.cmml" xref="A1.SS2.SSS1.Px3.p1.4.m4.1.1.1.1.1.1.3"><ci id="A1.SS2.SSS1.Px3.p1.4.m4.1.1.1.1.1.1.3.1.cmml" xref="A1.SS2.SSS1.Px3.p1.4.m4.1.1.1.1.1.1.3.1">bold-^</ci><ci id="A1.SS2.SSS1.Px3.p1.4.m4.1.1.1.1.1.1.3.2.cmml" xref="A1.SS2.SSS1.Px3.p1.4.m4.1.1.1.1.1.1.3.2">𝒄</ci></apply></apply></apply><cn id="A1.SS2.SSS1.Px3.p1.4.m4.1.1.1.3.cmml" type="integer" xref="A1.SS2.SSS1.Px3.p1.4.m4.1.1.1.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.SSS1.Px3.p1.4.m4.1c">\mathcal{L}_{\text{recon}}=\lVert\boldsymbol{c}-\boldsymbol{\hat{c}}\rVert_{1}</annotation><annotation encoding="application/x-llamapun" id="A1.SS2.SSS1.Px3.p1.4.m4.1d">caligraphic_L start_POSTSUBSCRIPT recon end_POSTSUBSCRIPT = ∥ bold_italic_c - overbold_^ start_ARG bold_italic_c end_ARG ∥ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math>, and the MipNeRF360 proposal loss <math alttext="\mathcal{L}_{\text{prop}}=\sum_{i}\frac{1}{w_{i}}\max(0,w_{i}-\text{bound}(%
\hat{t},\boldsymbol{\hat{w}},T_{i}))^{2}" class="ltx_math_unparsed" display="inline" id="A1.SS2.SSS1.Px3.p1.5.m5.4"><semantics id="A1.SS2.SSS1.Px3.p1.5.m5.4a"><mrow id="A1.SS2.SSS1.Px3.p1.5.m5.4b"><msub id="A1.SS2.SSS1.Px3.p1.5.m5.4.5"><mi class="ltx_font_mathcaligraphic" id="A1.SS2.SSS1.Px3.p1.5.m5.4.5.2">ℒ</mi><mtext id="A1.SS2.SSS1.Px3.p1.5.m5.4.5.3">prop</mtext></msub><mo id="A1.SS2.SSS1.Px3.p1.5.m5.4.6" rspace="0.111em">=</mo><msub id="A1.SS2.SSS1.Px3.p1.5.m5.4.7"><mo id="A1.SS2.SSS1.Px3.p1.5.m5.4.7.2">∑</mo><mi id="A1.SS2.SSS1.Px3.p1.5.m5.4.7.3">i</mi></msub><mfrac id="A1.SS2.SSS1.Px3.p1.5.m5.4.8"><mn id="A1.SS2.SSS1.Px3.p1.5.m5.4.8.2">1</mn><msub id="A1.SS2.SSS1.Px3.p1.5.m5.4.8.3"><mi id="A1.SS2.SSS1.Px3.p1.5.m5.4.8.3.2">w</mi><mi id="A1.SS2.SSS1.Px3.p1.5.m5.4.8.3.3">i</mi></msub></mfrac><mi id="A1.SS2.SSS1.Px3.p1.5.m5.3.3">max</mi><msup id="A1.SS2.SSS1.Px3.p1.5.m5.4.9"><mrow id="A1.SS2.SSS1.Px3.p1.5.m5.4.9.2"><mo id="A1.SS2.SSS1.Px3.p1.5.m5.4.9.2.1" stretchy="false">(</mo><mn id="A1.SS2.SSS1.Px3.p1.5.m5.4.4">0</mn><mo id="A1.SS2.SSS1.Px3.p1.5.m5.4.9.2.2">,</mo><msub id="A1.SS2.SSS1.Px3.p1.5.m5.4.9.2.3"><mi id="A1.SS2.SSS1.Px3.p1.5.m5.4.9.2.3.2">w</mi><mi id="A1.SS2.SSS1.Px3.p1.5.m5.4.9.2.3.3">i</mi></msub><mo id="A1.SS2.SSS1.Px3.p1.5.m5.4.9.2.4">−</mo><mtext id="A1.SS2.SSS1.Px3.p1.5.m5.4.9.2.5">bound</mtext><mrow id="A1.SS2.SSS1.Px3.p1.5.m5.4.9.2.6"><mo id="A1.SS2.SSS1.Px3.p1.5.m5.4.9.2.6.1" stretchy="false">(</mo><mover accent="true" id="A1.SS2.SSS1.Px3.p1.5.m5.1.1"><mi id="A1.SS2.SSS1.Px3.p1.5.m5.1.1.2">t</mi><mo id="A1.SS2.SSS1.Px3.p1.5.m5.1.1.1">^</mo></mover><mo id="A1.SS2.SSS1.Px3.p1.5.m5.4.9.2.6.2">,</mo><mover accent="true" id="A1.SS2.SSS1.Px3.p1.5.m5.2.2"><mi id="A1.SS2.SSS1.Px3.p1.5.m5.2.2.2">𝒘</mi><mo class="ltx_mathvariant_bold" id="A1.SS2.SSS1.Px3.p1.5.m5.2.2.1" mathvariant="bold">^</mo></mover><mo id="A1.SS2.SSS1.Px3.p1.5.m5.4.9.2.6.3">,</mo><msub id="A1.SS2.SSS1.Px3.p1.5.m5.4.9.2.6.4"><mi id="A1.SS2.SSS1.Px3.p1.5.m5.4.9.2.6.4.2">T</mi><mi id="A1.SS2.SSS1.Px3.p1.5.m5.4.9.2.6.4.3">i</mi></msub><mo id="A1.SS2.SSS1.Px3.p1.5.m5.4.9.2.6.5" stretchy="false">)</mo></mrow><mo id="A1.SS2.SSS1.Px3.p1.5.m5.4.9.2.7" stretchy="false">)</mo></mrow><mn id="A1.SS2.SSS1.Px3.p1.5.m5.4.9.3">2</mn></msup></mrow><annotation encoding="application/x-tex" id="A1.SS2.SSS1.Px3.p1.5.m5.4c">\mathcal{L}_{\text{prop}}=\sum_{i}\frac{1}{w_{i}}\max(0,w_{i}-\text{bound}(%
\hat{t},\boldsymbol{\hat{w}},T_{i}))^{2}</annotation><annotation encoding="application/x-llamapun" id="A1.SS2.SSS1.Px3.p1.5.m5.4d">caligraphic_L start_POSTSUBSCRIPT prop end_POSTSUBSCRIPT = ∑ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT divide start_ARG 1 end_ARG start_ARG italic_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_ARG roman_max ( 0 , italic_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT - bound ( over^ start_ARG italic_t end_ARG , overbold_^ start_ARG bold_italic_w end_ARG , italic_T start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) ) start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math>. Please see Eq. 13 in the original paper for more details <cite class="ltx_cite ltx_citemacro_citep">(Barron et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib3" title="">2022</a>)</cite>).</p>
</div>
<div class="ltx_para" id="A1.SS2.SSS1.Px3.p2">
<p class="ltx_p" id="A1.SS2.SSS1.Px3.p2.3">The optimization employs Adam <cite class="ltx_cite ltx_citemacro_citep">(Kingma and Ba, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib28" title="">2015</a>)</cite> with <math alttext="\beta_{1}=0.9,\beta_{2}=0.999" class="ltx_Math" display="inline" id="A1.SS2.SSS1.Px3.p2.1.m1.2"><semantics id="A1.SS2.SSS1.Px3.p2.1.m1.2a"><mrow id="A1.SS2.SSS1.Px3.p2.1.m1.2.2.2" xref="A1.SS2.SSS1.Px3.p2.1.m1.2.2.3.cmml"><mrow id="A1.SS2.SSS1.Px3.p2.1.m1.1.1.1.1" xref="A1.SS2.SSS1.Px3.p2.1.m1.1.1.1.1.cmml"><msub id="A1.SS2.SSS1.Px3.p2.1.m1.1.1.1.1.2" xref="A1.SS2.SSS1.Px3.p2.1.m1.1.1.1.1.2.cmml"><mi id="A1.SS2.SSS1.Px3.p2.1.m1.1.1.1.1.2.2" xref="A1.SS2.SSS1.Px3.p2.1.m1.1.1.1.1.2.2.cmml">β</mi><mn id="A1.SS2.SSS1.Px3.p2.1.m1.1.1.1.1.2.3" xref="A1.SS2.SSS1.Px3.p2.1.m1.1.1.1.1.2.3.cmml">1</mn></msub><mo id="A1.SS2.SSS1.Px3.p2.1.m1.1.1.1.1.1" xref="A1.SS2.SSS1.Px3.p2.1.m1.1.1.1.1.1.cmml">=</mo><mn id="A1.SS2.SSS1.Px3.p2.1.m1.1.1.1.1.3" xref="A1.SS2.SSS1.Px3.p2.1.m1.1.1.1.1.3.cmml">0.9</mn></mrow><mo id="A1.SS2.SSS1.Px3.p2.1.m1.2.2.2.3" xref="A1.SS2.SSS1.Px3.p2.1.m1.2.2.3a.cmml">,</mo><mrow id="A1.SS2.SSS1.Px3.p2.1.m1.2.2.2.2" xref="A1.SS2.SSS1.Px3.p2.1.m1.2.2.2.2.cmml"><msub id="A1.SS2.SSS1.Px3.p2.1.m1.2.2.2.2.2" xref="A1.SS2.SSS1.Px3.p2.1.m1.2.2.2.2.2.cmml"><mi id="A1.SS2.SSS1.Px3.p2.1.m1.2.2.2.2.2.2" xref="A1.SS2.SSS1.Px3.p2.1.m1.2.2.2.2.2.2.cmml">β</mi><mn id="A1.SS2.SSS1.Px3.p2.1.m1.2.2.2.2.2.3" xref="A1.SS2.SSS1.Px3.p2.1.m1.2.2.2.2.2.3.cmml">2</mn></msub><mo id="A1.SS2.SSS1.Px3.p2.1.m1.2.2.2.2.1" xref="A1.SS2.SSS1.Px3.p2.1.m1.2.2.2.2.1.cmml">=</mo><mn id="A1.SS2.SSS1.Px3.p2.1.m1.2.2.2.2.3" xref="A1.SS2.SSS1.Px3.p2.1.m1.2.2.2.2.3.cmml">0.999</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="A1.SS2.SSS1.Px3.p2.1.m1.2b"><apply id="A1.SS2.SSS1.Px3.p2.1.m1.2.2.3.cmml" xref="A1.SS2.SSS1.Px3.p2.1.m1.2.2.2"><csymbol cd="ambiguous" id="A1.SS2.SSS1.Px3.p2.1.m1.2.2.3a.cmml" xref="A1.SS2.SSS1.Px3.p2.1.m1.2.2.2.3">formulae-sequence</csymbol><apply id="A1.SS2.SSS1.Px3.p2.1.m1.1.1.1.1.cmml" xref="A1.SS2.SSS1.Px3.p2.1.m1.1.1.1.1"><eq id="A1.SS2.SSS1.Px3.p2.1.m1.1.1.1.1.1.cmml" xref="A1.SS2.SSS1.Px3.p2.1.m1.1.1.1.1.1"></eq><apply id="A1.SS2.SSS1.Px3.p2.1.m1.1.1.1.1.2.cmml" xref="A1.SS2.SSS1.Px3.p2.1.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="A1.SS2.SSS1.Px3.p2.1.m1.1.1.1.1.2.1.cmml" xref="A1.SS2.SSS1.Px3.p2.1.m1.1.1.1.1.2">subscript</csymbol><ci id="A1.SS2.SSS1.Px3.p2.1.m1.1.1.1.1.2.2.cmml" xref="A1.SS2.SSS1.Px3.p2.1.m1.1.1.1.1.2.2">𝛽</ci><cn id="A1.SS2.SSS1.Px3.p2.1.m1.1.1.1.1.2.3.cmml" type="integer" xref="A1.SS2.SSS1.Px3.p2.1.m1.1.1.1.1.2.3">1</cn></apply><cn id="A1.SS2.SSS1.Px3.p2.1.m1.1.1.1.1.3.cmml" type="float" xref="A1.SS2.SSS1.Px3.p2.1.m1.1.1.1.1.3">0.9</cn></apply><apply id="A1.SS2.SSS1.Px3.p2.1.m1.2.2.2.2.cmml" xref="A1.SS2.SSS1.Px3.p2.1.m1.2.2.2.2"><eq id="A1.SS2.SSS1.Px3.p2.1.m1.2.2.2.2.1.cmml" xref="A1.SS2.SSS1.Px3.p2.1.m1.2.2.2.2.1"></eq><apply id="A1.SS2.SSS1.Px3.p2.1.m1.2.2.2.2.2.cmml" xref="A1.SS2.SSS1.Px3.p2.1.m1.2.2.2.2.2"><csymbol cd="ambiguous" id="A1.SS2.SSS1.Px3.p2.1.m1.2.2.2.2.2.1.cmml" xref="A1.SS2.SSS1.Px3.p2.1.m1.2.2.2.2.2">subscript</csymbol><ci id="A1.SS2.SSS1.Px3.p2.1.m1.2.2.2.2.2.2.cmml" xref="A1.SS2.SSS1.Px3.p2.1.m1.2.2.2.2.2.2">𝛽</ci><cn id="A1.SS2.SSS1.Px3.p2.1.m1.2.2.2.2.2.3.cmml" type="integer" xref="A1.SS2.SSS1.Px3.p2.1.m1.2.2.2.2.2.3">2</cn></apply><cn id="A1.SS2.SSS1.Px3.p2.1.m1.2.2.2.2.3.cmml" type="float" xref="A1.SS2.SSS1.Px3.p2.1.m1.2.2.2.2.3">0.999</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.SSS1.Px3.p2.1.m1.2c">\beta_{1}=0.9,\beta_{2}=0.999</annotation><annotation encoding="application/x-llamapun" id="A1.SS2.SSS1.Px3.p2.1.m1.2d">italic_β start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0.9 , italic_β start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0.999</annotation></semantics></math>. The learning rate decays exponentially from <math alttext="0.002" class="ltx_Math" display="inline" id="A1.SS2.SSS1.Px3.p2.2.m2.1"><semantics id="A1.SS2.SSS1.Px3.p2.2.m2.1a"><mn id="A1.SS2.SSS1.Px3.p2.2.m2.1.1" xref="A1.SS2.SSS1.Px3.p2.2.m2.1.1.cmml">0.002</mn><annotation-xml encoding="MathML-Content" id="A1.SS2.SSS1.Px3.p2.2.m2.1b"><cn id="A1.SS2.SSS1.Px3.p2.2.m2.1.1.cmml" type="float" xref="A1.SS2.SSS1.Px3.p2.2.m2.1.1">0.002</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.SSS1.Px3.p2.2.m2.1c">0.002</annotation><annotation encoding="application/x-llamapun" id="A1.SS2.SSS1.Px3.p2.2.m2.1d">0.002</annotation></semantics></math> to <math alttext="0.00002" class="ltx_Math" display="inline" id="A1.SS2.SSS1.Px3.p2.3.m3.1"><semantics id="A1.SS2.SSS1.Px3.p2.3.m3.1a"><mn id="A1.SS2.SSS1.Px3.p2.3.m3.1.1" xref="A1.SS2.SSS1.Px3.p2.3.m3.1.1.cmml">0.00002</mn><annotation-xml encoding="MathML-Content" id="A1.SS2.SSS1.Px3.p2.3.m3.1b"><cn id="A1.SS2.SSS1.Px3.p2.3.m3.1.1.cmml" type="float" xref="A1.SS2.SSS1.Px3.p2.3.m3.1.1">0.00002</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.SSS1.Px3.p2.3.m3.1c">0.00002</annotation><annotation encoding="application/x-llamapun" id="A1.SS2.SSS1.Px3.p2.3.m3.1d">0.00002</annotation></semantics></math>. We clip gradients with norms larger than 0.001.</p>
</div>
<div class="ltx_para" id="A1.SS2.SSS1.Px3.p3">
<p class="ltx_p" id="A1.SS2.SSS1.Px3.p3.1">We also experimented with the supervision of accumulation and depth but didn’t find an improvement.</p>
</div>
</section>
</section>
</section>
<section class="ltx_subsection" id="A1.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.3. </span>Inference Details</h3>
<section class="ltx_paragraph" id="A1.SS3.SSS0.Px1">
<h5 class="ltx_title ltx_title_paragraph">3DMM Fitting</h5>
<div class="ltx_para" id="A1.SS3.SSS0.Px1.p1">
<p class="ltx_p" id="A1.SS3.SSS0.Px1.p1.1">We fit the 3DMM <cite class="ltx_cite ltx_citemacro_citep">(Blanz and Vetter, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib5" title="">1999</a>)</cite> from 599 2D probabilistic landmarks, where each landmark is the projection of one vertex of the 3DMM mesh with an uncertainty <math alttext="\sigma" class="ltx_Math" display="inline" id="A1.SS3.SSS0.Px1.p1.1.m1.1"><semantics id="A1.SS3.SSS0.Px1.p1.1.m1.1a"><mi id="A1.SS3.SSS0.Px1.p1.1.m1.1.1" xref="A1.SS3.SSS0.Px1.p1.1.m1.1.1.cmml">σ</mi><annotation-xml encoding="MathML-Content" id="A1.SS3.SSS0.Px1.p1.1.m1.1b"><ci id="A1.SS3.SSS0.Px1.p1.1.m1.1.1.cmml" xref="A1.SS3.SSS0.Px1.p1.1.m1.1.1">𝜎</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS3.SSS0.Px1.p1.1.m1.1c">\sigma</annotation><annotation encoding="application/x-llamapun" id="A1.SS3.SSS0.Px1.p1.1.m1.1d">italic_σ</annotation></semantics></math>.
The landmark fitting follows <cite class="ltx_cite ltx_citemacro_citep">(Wood et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib73" title="">2022</a>)</cite> and minimizes the energy function</p>
<table class="ltx_equation ltx_eqn_table" id="A1.Ex2">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="E(\boldsymbol{\Phi};L)=E_{\text{landmarks}}+E_{\text{identity}}+E_{\text{%
expression}}+E_{\text{joints}}+E_{\text{intersect}}\text{,}" class="ltx_Math" display="block" id="A1.Ex2.m1.2"><semantics id="A1.Ex2.m1.2a"><mrow id="A1.Ex2.m1.2.3" xref="A1.Ex2.m1.2.3.cmml"><mrow id="A1.Ex2.m1.2.3.2" xref="A1.Ex2.m1.2.3.2.cmml"><mi id="A1.Ex2.m1.2.3.2.2" xref="A1.Ex2.m1.2.3.2.2.cmml">E</mi><mo id="A1.Ex2.m1.2.3.2.1" xref="A1.Ex2.m1.2.3.2.1.cmml">⁢</mo><mrow id="A1.Ex2.m1.2.3.2.3.2" xref="A1.Ex2.m1.2.3.2.3.1.cmml"><mo id="A1.Ex2.m1.2.3.2.3.2.1" stretchy="false" xref="A1.Ex2.m1.2.3.2.3.1.cmml">(</mo><mi id="A1.Ex2.m1.1.1" xref="A1.Ex2.m1.1.1.cmml">𝚽</mi><mo id="A1.Ex2.m1.2.3.2.3.2.2" xref="A1.Ex2.m1.2.3.2.3.1.cmml">;</mo><mi id="A1.Ex2.m1.2.2" xref="A1.Ex2.m1.2.2.cmml">L</mi><mo id="A1.Ex2.m1.2.3.2.3.2.3" stretchy="false" xref="A1.Ex2.m1.2.3.2.3.1.cmml">)</mo></mrow></mrow><mo id="A1.Ex2.m1.2.3.1" xref="A1.Ex2.m1.2.3.1.cmml">=</mo><mrow id="A1.Ex2.m1.2.3.3" xref="A1.Ex2.m1.2.3.3.cmml"><msub id="A1.Ex2.m1.2.3.3.2" xref="A1.Ex2.m1.2.3.3.2.cmml"><mi id="A1.Ex2.m1.2.3.3.2.2" xref="A1.Ex2.m1.2.3.3.2.2.cmml">E</mi><mtext id="A1.Ex2.m1.2.3.3.2.3" xref="A1.Ex2.m1.2.3.3.2.3a.cmml">landmarks</mtext></msub><mo id="A1.Ex2.m1.2.3.3.1" xref="A1.Ex2.m1.2.3.3.1.cmml">+</mo><msub id="A1.Ex2.m1.2.3.3.3" xref="A1.Ex2.m1.2.3.3.3.cmml"><mi id="A1.Ex2.m1.2.3.3.3.2" xref="A1.Ex2.m1.2.3.3.3.2.cmml">E</mi><mtext id="A1.Ex2.m1.2.3.3.3.3" xref="A1.Ex2.m1.2.3.3.3.3a.cmml">identity</mtext></msub><mo id="A1.Ex2.m1.2.3.3.1a" xref="A1.Ex2.m1.2.3.3.1.cmml">+</mo><msub id="A1.Ex2.m1.2.3.3.4" xref="A1.Ex2.m1.2.3.3.4.cmml"><mi id="A1.Ex2.m1.2.3.3.4.2" xref="A1.Ex2.m1.2.3.3.4.2.cmml">E</mi><mtext id="A1.Ex2.m1.2.3.3.4.3" xref="A1.Ex2.m1.2.3.3.4.3a.cmml">expression</mtext></msub><mo id="A1.Ex2.m1.2.3.3.1b" xref="A1.Ex2.m1.2.3.3.1.cmml">+</mo><msub id="A1.Ex2.m1.2.3.3.5" xref="A1.Ex2.m1.2.3.3.5.cmml"><mi id="A1.Ex2.m1.2.3.3.5.2" xref="A1.Ex2.m1.2.3.3.5.2.cmml">E</mi><mtext id="A1.Ex2.m1.2.3.3.5.3" xref="A1.Ex2.m1.2.3.3.5.3a.cmml">joints</mtext></msub><mo id="A1.Ex2.m1.2.3.3.1c" xref="A1.Ex2.m1.2.3.3.1.cmml">+</mo><mrow id="A1.Ex2.m1.2.3.3.6" xref="A1.Ex2.m1.2.3.3.6.cmml"><msub id="A1.Ex2.m1.2.3.3.6.2" xref="A1.Ex2.m1.2.3.3.6.2.cmml"><mi id="A1.Ex2.m1.2.3.3.6.2.2" xref="A1.Ex2.m1.2.3.3.6.2.2.cmml">E</mi><mtext id="A1.Ex2.m1.2.3.3.6.2.3" xref="A1.Ex2.m1.2.3.3.6.2.3a.cmml">intersect</mtext></msub><mo id="A1.Ex2.m1.2.3.3.6.1" xref="A1.Ex2.m1.2.3.3.6.1.cmml">⁢</mo><mtext id="A1.Ex2.m1.2.3.3.6.3" xref="A1.Ex2.m1.2.3.3.6.3a.cmml">,</mtext></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="A1.Ex2.m1.2b"><apply id="A1.Ex2.m1.2.3.cmml" xref="A1.Ex2.m1.2.3"><eq id="A1.Ex2.m1.2.3.1.cmml" xref="A1.Ex2.m1.2.3.1"></eq><apply id="A1.Ex2.m1.2.3.2.cmml" xref="A1.Ex2.m1.2.3.2"><times id="A1.Ex2.m1.2.3.2.1.cmml" xref="A1.Ex2.m1.2.3.2.1"></times><ci id="A1.Ex2.m1.2.3.2.2.cmml" xref="A1.Ex2.m1.2.3.2.2">𝐸</ci><list id="A1.Ex2.m1.2.3.2.3.1.cmml" xref="A1.Ex2.m1.2.3.2.3.2"><ci id="A1.Ex2.m1.1.1.cmml" xref="A1.Ex2.m1.1.1">𝚽</ci><ci id="A1.Ex2.m1.2.2.cmml" xref="A1.Ex2.m1.2.2">𝐿</ci></list></apply><apply id="A1.Ex2.m1.2.3.3.cmml" xref="A1.Ex2.m1.2.3.3"><plus id="A1.Ex2.m1.2.3.3.1.cmml" xref="A1.Ex2.m1.2.3.3.1"></plus><apply id="A1.Ex2.m1.2.3.3.2.cmml" xref="A1.Ex2.m1.2.3.3.2"><csymbol cd="ambiguous" id="A1.Ex2.m1.2.3.3.2.1.cmml" xref="A1.Ex2.m1.2.3.3.2">subscript</csymbol><ci id="A1.Ex2.m1.2.3.3.2.2.cmml" xref="A1.Ex2.m1.2.3.3.2.2">𝐸</ci><ci id="A1.Ex2.m1.2.3.3.2.3a.cmml" xref="A1.Ex2.m1.2.3.3.2.3"><mtext id="A1.Ex2.m1.2.3.3.2.3.cmml" mathsize="70%" xref="A1.Ex2.m1.2.3.3.2.3">landmarks</mtext></ci></apply><apply id="A1.Ex2.m1.2.3.3.3.cmml" xref="A1.Ex2.m1.2.3.3.3"><csymbol cd="ambiguous" id="A1.Ex2.m1.2.3.3.3.1.cmml" xref="A1.Ex2.m1.2.3.3.3">subscript</csymbol><ci id="A1.Ex2.m1.2.3.3.3.2.cmml" xref="A1.Ex2.m1.2.3.3.3.2">𝐸</ci><ci id="A1.Ex2.m1.2.3.3.3.3a.cmml" xref="A1.Ex2.m1.2.3.3.3.3"><mtext id="A1.Ex2.m1.2.3.3.3.3.cmml" mathsize="70%" xref="A1.Ex2.m1.2.3.3.3.3">identity</mtext></ci></apply><apply id="A1.Ex2.m1.2.3.3.4.cmml" xref="A1.Ex2.m1.2.3.3.4"><csymbol cd="ambiguous" id="A1.Ex2.m1.2.3.3.4.1.cmml" xref="A1.Ex2.m1.2.3.3.4">subscript</csymbol><ci id="A1.Ex2.m1.2.3.3.4.2.cmml" xref="A1.Ex2.m1.2.3.3.4.2">𝐸</ci><ci id="A1.Ex2.m1.2.3.3.4.3a.cmml" xref="A1.Ex2.m1.2.3.3.4.3"><mtext id="A1.Ex2.m1.2.3.3.4.3.cmml" mathsize="70%" xref="A1.Ex2.m1.2.3.3.4.3">expression</mtext></ci></apply><apply id="A1.Ex2.m1.2.3.3.5.cmml" xref="A1.Ex2.m1.2.3.3.5"><csymbol cd="ambiguous" id="A1.Ex2.m1.2.3.3.5.1.cmml" xref="A1.Ex2.m1.2.3.3.5">subscript</csymbol><ci id="A1.Ex2.m1.2.3.3.5.2.cmml" xref="A1.Ex2.m1.2.3.3.5.2">𝐸</ci><ci id="A1.Ex2.m1.2.3.3.5.3a.cmml" xref="A1.Ex2.m1.2.3.3.5.3"><mtext id="A1.Ex2.m1.2.3.3.5.3.cmml" mathsize="70%" xref="A1.Ex2.m1.2.3.3.5.3">joints</mtext></ci></apply><apply id="A1.Ex2.m1.2.3.3.6.cmml" xref="A1.Ex2.m1.2.3.3.6"><times id="A1.Ex2.m1.2.3.3.6.1.cmml" xref="A1.Ex2.m1.2.3.3.6.1"></times><apply id="A1.Ex2.m1.2.3.3.6.2.cmml" xref="A1.Ex2.m1.2.3.3.6.2"><csymbol cd="ambiguous" id="A1.Ex2.m1.2.3.3.6.2.1.cmml" xref="A1.Ex2.m1.2.3.3.6.2">subscript</csymbol><ci id="A1.Ex2.m1.2.3.3.6.2.2.cmml" xref="A1.Ex2.m1.2.3.3.6.2.2">𝐸</ci><ci id="A1.Ex2.m1.2.3.3.6.2.3a.cmml" xref="A1.Ex2.m1.2.3.3.6.2.3"><mtext id="A1.Ex2.m1.2.3.3.6.2.3.cmml" mathsize="70%" xref="A1.Ex2.m1.2.3.3.6.2.3">intersect</mtext></ci></apply><ci id="A1.Ex2.m1.2.3.3.6.3a.cmml" xref="A1.Ex2.m1.2.3.3.6.3"><mtext id="A1.Ex2.m1.2.3.3.6.3.cmml" xref="A1.Ex2.m1.2.3.3.6.3">,</mtext></ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.Ex2.m1.2c">E(\boldsymbol{\Phi};L)=E_{\text{landmarks}}+E_{\text{identity}}+E_{\text{%
expression}}+E_{\text{joints}}+E_{\text{intersect}}\text{,}</annotation><annotation encoding="application/x-llamapun" id="A1.Ex2.m1.2d">italic_E ( bold_Φ ; italic_L ) = italic_E start_POSTSUBSCRIPT landmarks end_POSTSUBSCRIPT + italic_E start_POSTSUBSCRIPT identity end_POSTSUBSCRIPT + italic_E start_POSTSUBSCRIPT expression end_POSTSUBSCRIPT + italic_E start_POSTSUBSCRIPT joints end_POSTSUBSCRIPT + italic_E start_POSTSUBSCRIPT intersect end_POSTSUBSCRIPT ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p class="ltx_p" id="A1.SS3.SSS0.Px1.p1.3">where <math alttext="L" class="ltx_Math" display="inline" id="A1.SS3.SSS0.Px1.p1.2.m1.1"><semantics id="A1.SS3.SSS0.Px1.p1.2.m1.1a"><mi id="A1.SS3.SSS0.Px1.p1.2.m1.1.1" xref="A1.SS3.SSS0.Px1.p1.2.m1.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="A1.SS3.SSS0.Px1.p1.2.m1.1b"><ci id="A1.SS3.SSS0.Px1.p1.2.m1.1.1.cmml" xref="A1.SS3.SSS0.Px1.p1.2.m1.1.1">𝐿</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS3.SSS0.Px1.p1.2.m1.1c">L</annotation><annotation encoding="application/x-llamapun" id="A1.SS3.SSS0.Px1.p1.2.m1.1d">italic_L</annotation></semantics></math> denotes the 599 probabilistic landmarks and <math alttext="\boldsymbol{\Phi}" class="ltx_Math" display="inline" id="A1.SS3.SSS0.Px1.p1.3.m2.1"><semantics id="A1.SS3.SSS0.Px1.p1.3.m2.1a"><mi id="A1.SS3.SSS0.Px1.p1.3.m2.1.1" xref="A1.SS3.SSS0.Px1.p1.3.m2.1.1.cmml">𝚽</mi><annotation-xml encoding="MathML-Content" id="A1.SS3.SSS0.Px1.p1.3.m2.1b"><ci id="A1.SS3.SSS0.Px1.p1.3.m2.1.1.cmml" xref="A1.SS3.SSS0.Px1.p1.3.m2.1.1">𝚽</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS3.SSS0.Px1.p1.3.m2.1c">\boldsymbol{\Phi}</annotation><annotation encoding="application/x-llamapun" id="A1.SS3.SSS0.Px1.p1.3.m2.1d">bold_Φ</annotation></semantics></math> all the optimized 3DMM parameters including identity, expressions, joint rotations, and global translation, and intrinsic and extrinsic camera parameters, if unknown.
The landmark term</p>
<table class="ltx_equation ltx_eqn_table" id="A1.Ex3">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="E_{\text{landmarks}}=\sum_{j,k}^{C,|L|}\frac{\lVert\boldsymbol{x}_{jk}-%
\boldsymbol{\mu}_{jk}\rVert^{2}}{2\sigma_{jk}^{2}}" class="ltx_Math" display="block" id="A1.Ex3.m1.6"><semantics id="A1.Ex3.m1.6a"><mrow id="A1.Ex3.m1.6.7" xref="A1.Ex3.m1.6.7.cmml"><msub id="A1.Ex3.m1.6.7.2" xref="A1.Ex3.m1.6.7.2.cmml"><mi id="A1.Ex3.m1.6.7.2.2" xref="A1.Ex3.m1.6.7.2.2.cmml">E</mi><mtext id="A1.Ex3.m1.6.7.2.3" xref="A1.Ex3.m1.6.7.2.3a.cmml">landmarks</mtext></msub><mo id="A1.Ex3.m1.6.7.1" rspace="0.111em" xref="A1.Ex3.m1.6.7.1.cmml">=</mo><mrow id="A1.Ex3.m1.6.7.3" xref="A1.Ex3.m1.6.7.3.cmml"><munderover id="A1.Ex3.m1.6.7.3.1" xref="A1.Ex3.m1.6.7.3.1.cmml"><mo id="A1.Ex3.m1.6.7.3.1.2.2" movablelimits="false" xref="A1.Ex3.m1.6.7.3.1.2.2.cmml">∑</mo><mrow id="A1.Ex3.m1.2.2.2.4" xref="A1.Ex3.m1.2.2.2.3.cmml"><mi id="A1.Ex3.m1.1.1.1.1" xref="A1.Ex3.m1.1.1.1.1.cmml">j</mi><mo id="A1.Ex3.m1.2.2.2.4.1" xref="A1.Ex3.m1.2.2.2.3.cmml">,</mo><mi id="A1.Ex3.m1.2.2.2.2" xref="A1.Ex3.m1.2.2.2.2.cmml">k</mi></mrow><mrow id="A1.Ex3.m1.5.5.3.3" xref="A1.Ex3.m1.5.5.3.4.cmml"><mi id="A1.Ex3.m1.4.4.2.2" xref="A1.Ex3.m1.4.4.2.2.cmml">C</mi><mo id="A1.Ex3.m1.5.5.3.3.2" xref="A1.Ex3.m1.5.5.3.4.cmml">,</mo><mrow id="A1.Ex3.m1.5.5.3.3.1.2" xref="A1.Ex3.m1.5.5.3.3.1.1.cmml"><mo id="A1.Ex3.m1.5.5.3.3.1.2.1" stretchy="false" xref="A1.Ex3.m1.5.5.3.3.1.1.1.cmml">|</mo><mi id="A1.Ex3.m1.3.3.1.1" xref="A1.Ex3.m1.3.3.1.1.cmml">L</mi><mo id="A1.Ex3.m1.5.5.3.3.1.2.2" stretchy="false" xref="A1.Ex3.m1.5.5.3.3.1.1.1.cmml">|</mo></mrow></mrow></munderover><mfrac id="A1.Ex3.m1.6.6" xref="A1.Ex3.m1.6.6.cmml"><msup id="A1.Ex3.m1.6.6.1" xref="A1.Ex3.m1.6.6.1.cmml"><mrow id="A1.Ex3.m1.6.6.1.1.1" xref="A1.Ex3.m1.6.6.1.1.2.cmml"><mo fence="true" id="A1.Ex3.m1.6.6.1.1.1.2" rspace="0em" xref="A1.Ex3.m1.6.6.1.1.2.1.cmml">∥</mo><mrow id="A1.Ex3.m1.6.6.1.1.1.1" xref="A1.Ex3.m1.6.6.1.1.1.1.cmml"><msub id="A1.Ex3.m1.6.6.1.1.1.1.2" xref="A1.Ex3.m1.6.6.1.1.1.1.2.cmml"><mi id="A1.Ex3.m1.6.6.1.1.1.1.2.2" xref="A1.Ex3.m1.6.6.1.1.1.1.2.2.cmml">𝒙</mi><mrow id="A1.Ex3.m1.6.6.1.1.1.1.2.3" xref="A1.Ex3.m1.6.6.1.1.1.1.2.3.cmml"><mi id="A1.Ex3.m1.6.6.1.1.1.1.2.3.2" xref="A1.Ex3.m1.6.6.1.1.1.1.2.3.2.cmml">j</mi><mo id="A1.Ex3.m1.6.6.1.1.1.1.2.3.1" xref="A1.Ex3.m1.6.6.1.1.1.1.2.3.1.cmml">⁢</mo><mi id="A1.Ex3.m1.6.6.1.1.1.1.2.3.3" xref="A1.Ex3.m1.6.6.1.1.1.1.2.3.3.cmml">k</mi></mrow></msub><mo id="A1.Ex3.m1.6.6.1.1.1.1.1" xref="A1.Ex3.m1.6.6.1.1.1.1.1.cmml">−</mo><msub id="A1.Ex3.m1.6.6.1.1.1.1.3" xref="A1.Ex3.m1.6.6.1.1.1.1.3.cmml"><mi id="A1.Ex3.m1.6.6.1.1.1.1.3.2" xref="A1.Ex3.m1.6.6.1.1.1.1.3.2.cmml">𝝁</mi><mrow id="A1.Ex3.m1.6.6.1.1.1.1.3.3" xref="A1.Ex3.m1.6.6.1.1.1.1.3.3.cmml"><mi id="A1.Ex3.m1.6.6.1.1.1.1.3.3.2" xref="A1.Ex3.m1.6.6.1.1.1.1.3.3.2.cmml">j</mi><mo id="A1.Ex3.m1.6.6.1.1.1.1.3.3.1" xref="A1.Ex3.m1.6.6.1.1.1.1.3.3.1.cmml">⁢</mo><mi id="A1.Ex3.m1.6.6.1.1.1.1.3.3.3" xref="A1.Ex3.m1.6.6.1.1.1.1.3.3.3.cmml">k</mi></mrow></msub></mrow><mo fence="true" id="A1.Ex3.m1.6.6.1.1.1.3" lspace="0em" xref="A1.Ex3.m1.6.6.1.1.2.1.cmml">∥</mo></mrow><mn id="A1.Ex3.m1.6.6.1.3" xref="A1.Ex3.m1.6.6.1.3.cmml">2</mn></msup><mrow id="A1.Ex3.m1.6.6.3" xref="A1.Ex3.m1.6.6.3.cmml"><mn id="A1.Ex3.m1.6.6.3.2" xref="A1.Ex3.m1.6.6.3.2.cmml">2</mn><mo id="A1.Ex3.m1.6.6.3.1" xref="A1.Ex3.m1.6.6.3.1.cmml">⁢</mo><msubsup id="A1.Ex3.m1.6.6.3.3" xref="A1.Ex3.m1.6.6.3.3.cmml"><mi id="A1.Ex3.m1.6.6.3.3.2.2" xref="A1.Ex3.m1.6.6.3.3.2.2.cmml">σ</mi><mrow id="A1.Ex3.m1.6.6.3.3.2.3" xref="A1.Ex3.m1.6.6.3.3.2.3.cmml"><mi id="A1.Ex3.m1.6.6.3.3.2.3.2" xref="A1.Ex3.m1.6.6.3.3.2.3.2.cmml">j</mi><mo id="A1.Ex3.m1.6.6.3.3.2.3.1" xref="A1.Ex3.m1.6.6.3.3.2.3.1.cmml">⁢</mo><mi id="A1.Ex3.m1.6.6.3.3.2.3.3" xref="A1.Ex3.m1.6.6.3.3.2.3.3.cmml">k</mi></mrow><mn id="A1.Ex3.m1.6.6.3.3.3" xref="A1.Ex3.m1.6.6.3.3.3.cmml">2</mn></msubsup></mrow></mfrac></mrow></mrow><annotation-xml encoding="MathML-Content" id="A1.Ex3.m1.6b"><apply id="A1.Ex3.m1.6.7.cmml" xref="A1.Ex3.m1.6.7"><eq id="A1.Ex3.m1.6.7.1.cmml" xref="A1.Ex3.m1.6.7.1"></eq><apply id="A1.Ex3.m1.6.7.2.cmml" xref="A1.Ex3.m1.6.7.2"><csymbol cd="ambiguous" id="A1.Ex3.m1.6.7.2.1.cmml" xref="A1.Ex3.m1.6.7.2">subscript</csymbol><ci id="A1.Ex3.m1.6.7.2.2.cmml" xref="A1.Ex3.m1.6.7.2.2">𝐸</ci><ci id="A1.Ex3.m1.6.7.2.3a.cmml" xref="A1.Ex3.m1.6.7.2.3"><mtext id="A1.Ex3.m1.6.7.2.3.cmml" mathsize="70%" xref="A1.Ex3.m1.6.7.2.3">landmarks</mtext></ci></apply><apply id="A1.Ex3.m1.6.7.3.cmml" xref="A1.Ex3.m1.6.7.3"><apply id="A1.Ex3.m1.6.7.3.1.cmml" xref="A1.Ex3.m1.6.7.3.1"><csymbol cd="ambiguous" id="A1.Ex3.m1.6.7.3.1.1.cmml" xref="A1.Ex3.m1.6.7.3.1">superscript</csymbol><apply id="A1.Ex3.m1.6.7.3.1.2.cmml" xref="A1.Ex3.m1.6.7.3.1"><csymbol cd="ambiguous" id="A1.Ex3.m1.6.7.3.1.2.1.cmml" xref="A1.Ex3.m1.6.7.3.1">subscript</csymbol><sum id="A1.Ex3.m1.6.7.3.1.2.2.cmml" xref="A1.Ex3.m1.6.7.3.1.2.2"></sum><list id="A1.Ex3.m1.2.2.2.3.cmml" xref="A1.Ex3.m1.2.2.2.4"><ci id="A1.Ex3.m1.1.1.1.1.cmml" xref="A1.Ex3.m1.1.1.1.1">𝑗</ci><ci id="A1.Ex3.m1.2.2.2.2.cmml" xref="A1.Ex3.m1.2.2.2.2">𝑘</ci></list></apply><list id="A1.Ex3.m1.5.5.3.4.cmml" xref="A1.Ex3.m1.5.5.3.3"><ci id="A1.Ex3.m1.4.4.2.2.cmml" xref="A1.Ex3.m1.4.4.2.2">𝐶</ci><apply id="A1.Ex3.m1.5.5.3.3.1.1.cmml" xref="A1.Ex3.m1.5.5.3.3.1.2"><abs id="A1.Ex3.m1.5.5.3.3.1.1.1.cmml" xref="A1.Ex3.m1.5.5.3.3.1.2.1"></abs><ci id="A1.Ex3.m1.3.3.1.1.cmml" xref="A1.Ex3.m1.3.3.1.1">𝐿</ci></apply></list></apply><apply id="A1.Ex3.m1.6.6.cmml" xref="A1.Ex3.m1.6.6"><divide id="A1.Ex3.m1.6.6.2.cmml" xref="A1.Ex3.m1.6.6"></divide><apply id="A1.Ex3.m1.6.6.1.cmml" xref="A1.Ex3.m1.6.6.1"><csymbol cd="ambiguous" id="A1.Ex3.m1.6.6.1.2.cmml" xref="A1.Ex3.m1.6.6.1">superscript</csymbol><apply id="A1.Ex3.m1.6.6.1.1.2.cmml" xref="A1.Ex3.m1.6.6.1.1.1"><csymbol cd="latexml" id="A1.Ex3.m1.6.6.1.1.2.1.cmml" xref="A1.Ex3.m1.6.6.1.1.1.2">delimited-∥∥</csymbol><apply id="A1.Ex3.m1.6.6.1.1.1.1.cmml" xref="A1.Ex3.m1.6.6.1.1.1.1"><minus id="A1.Ex3.m1.6.6.1.1.1.1.1.cmml" xref="A1.Ex3.m1.6.6.1.1.1.1.1"></minus><apply id="A1.Ex3.m1.6.6.1.1.1.1.2.cmml" xref="A1.Ex3.m1.6.6.1.1.1.1.2"><csymbol cd="ambiguous" id="A1.Ex3.m1.6.6.1.1.1.1.2.1.cmml" xref="A1.Ex3.m1.6.6.1.1.1.1.2">subscript</csymbol><ci id="A1.Ex3.m1.6.6.1.1.1.1.2.2.cmml" xref="A1.Ex3.m1.6.6.1.1.1.1.2.2">𝒙</ci><apply id="A1.Ex3.m1.6.6.1.1.1.1.2.3.cmml" xref="A1.Ex3.m1.6.6.1.1.1.1.2.3"><times id="A1.Ex3.m1.6.6.1.1.1.1.2.3.1.cmml" xref="A1.Ex3.m1.6.6.1.1.1.1.2.3.1"></times><ci id="A1.Ex3.m1.6.6.1.1.1.1.2.3.2.cmml" xref="A1.Ex3.m1.6.6.1.1.1.1.2.3.2">𝑗</ci><ci id="A1.Ex3.m1.6.6.1.1.1.1.2.3.3.cmml" xref="A1.Ex3.m1.6.6.1.1.1.1.2.3.3">𝑘</ci></apply></apply><apply id="A1.Ex3.m1.6.6.1.1.1.1.3.cmml" xref="A1.Ex3.m1.6.6.1.1.1.1.3"><csymbol cd="ambiguous" id="A1.Ex3.m1.6.6.1.1.1.1.3.1.cmml" xref="A1.Ex3.m1.6.6.1.1.1.1.3">subscript</csymbol><ci id="A1.Ex3.m1.6.6.1.1.1.1.3.2.cmml" xref="A1.Ex3.m1.6.6.1.1.1.1.3.2">𝝁</ci><apply id="A1.Ex3.m1.6.6.1.1.1.1.3.3.cmml" xref="A1.Ex3.m1.6.6.1.1.1.1.3.3"><times id="A1.Ex3.m1.6.6.1.1.1.1.3.3.1.cmml" xref="A1.Ex3.m1.6.6.1.1.1.1.3.3.1"></times><ci id="A1.Ex3.m1.6.6.1.1.1.1.3.3.2.cmml" xref="A1.Ex3.m1.6.6.1.1.1.1.3.3.2">𝑗</ci><ci id="A1.Ex3.m1.6.6.1.1.1.1.3.3.3.cmml" xref="A1.Ex3.m1.6.6.1.1.1.1.3.3.3">𝑘</ci></apply></apply></apply></apply><cn id="A1.Ex3.m1.6.6.1.3.cmml" type="integer" xref="A1.Ex3.m1.6.6.1.3">2</cn></apply><apply id="A1.Ex3.m1.6.6.3.cmml" xref="A1.Ex3.m1.6.6.3"><times id="A1.Ex3.m1.6.6.3.1.cmml" xref="A1.Ex3.m1.6.6.3.1"></times><cn id="A1.Ex3.m1.6.6.3.2.cmml" type="integer" xref="A1.Ex3.m1.6.6.3.2">2</cn><apply id="A1.Ex3.m1.6.6.3.3.cmml" xref="A1.Ex3.m1.6.6.3.3"><csymbol cd="ambiguous" id="A1.Ex3.m1.6.6.3.3.1.cmml" xref="A1.Ex3.m1.6.6.3.3">superscript</csymbol><apply id="A1.Ex3.m1.6.6.3.3.2.cmml" xref="A1.Ex3.m1.6.6.3.3"><csymbol cd="ambiguous" id="A1.Ex3.m1.6.6.3.3.2.1.cmml" xref="A1.Ex3.m1.6.6.3.3">subscript</csymbol><ci id="A1.Ex3.m1.6.6.3.3.2.2.cmml" xref="A1.Ex3.m1.6.6.3.3.2.2">𝜎</ci><apply id="A1.Ex3.m1.6.6.3.3.2.3.cmml" xref="A1.Ex3.m1.6.6.3.3.2.3"><times id="A1.Ex3.m1.6.6.3.3.2.3.1.cmml" xref="A1.Ex3.m1.6.6.3.3.2.3.1"></times><ci id="A1.Ex3.m1.6.6.3.3.2.3.2.cmml" xref="A1.Ex3.m1.6.6.3.3.2.3.2">𝑗</ci><ci id="A1.Ex3.m1.6.6.3.3.2.3.3.cmml" xref="A1.Ex3.m1.6.6.3.3.2.3.3">𝑘</ci></apply></apply><cn id="A1.Ex3.m1.6.6.3.3.3.cmml" type="integer" xref="A1.Ex3.m1.6.6.3.3.3">2</cn></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.Ex3.m1.6c">E_{\text{landmarks}}=\sum_{j,k}^{C,|L|}\frac{\lVert\boldsymbol{x}_{jk}-%
\boldsymbol{\mu}_{jk}\rVert^{2}}{2\sigma_{jk}^{2}}</annotation><annotation encoding="application/x-llamapun" id="A1.Ex3.m1.6d">italic_E start_POSTSUBSCRIPT landmarks end_POSTSUBSCRIPT = ∑ start_POSTSUBSCRIPT italic_j , italic_k end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_C , | italic_L | end_POSTSUPERSCRIPT divide start_ARG ∥ bold_italic_x start_POSTSUBSCRIPT italic_j italic_k end_POSTSUBSCRIPT - bold_italic_μ start_POSTSUBSCRIPT italic_j italic_k end_POSTSUBSCRIPT ∥ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG start_ARG 2 italic_σ start_POSTSUBSCRIPT italic_j italic_k end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p class="ltx_p" id="A1.SS3.SSS0.Px1.p1.13">minimizes the distance between the projected landmarks from the 3DMM <math alttext="\boldsymbol{x}_{jk}" class="ltx_Math" display="inline" id="A1.SS3.SSS0.Px1.p1.4.m1.1"><semantics id="A1.SS3.SSS0.Px1.p1.4.m1.1a"><msub id="A1.SS3.SSS0.Px1.p1.4.m1.1.1" xref="A1.SS3.SSS0.Px1.p1.4.m1.1.1.cmml"><mi id="A1.SS3.SSS0.Px1.p1.4.m1.1.1.2" xref="A1.SS3.SSS0.Px1.p1.4.m1.1.1.2.cmml">𝒙</mi><mrow id="A1.SS3.SSS0.Px1.p1.4.m1.1.1.3" xref="A1.SS3.SSS0.Px1.p1.4.m1.1.1.3.cmml"><mi id="A1.SS3.SSS0.Px1.p1.4.m1.1.1.3.2" xref="A1.SS3.SSS0.Px1.p1.4.m1.1.1.3.2.cmml">j</mi><mo id="A1.SS3.SSS0.Px1.p1.4.m1.1.1.3.1" xref="A1.SS3.SSS0.Px1.p1.4.m1.1.1.3.1.cmml">⁢</mo><mi id="A1.SS3.SSS0.Px1.p1.4.m1.1.1.3.3" xref="A1.SS3.SSS0.Px1.p1.4.m1.1.1.3.3.cmml">k</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="A1.SS3.SSS0.Px1.p1.4.m1.1b"><apply id="A1.SS3.SSS0.Px1.p1.4.m1.1.1.cmml" xref="A1.SS3.SSS0.Px1.p1.4.m1.1.1"><csymbol cd="ambiguous" id="A1.SS3.SSS0.Px1.p1.4.m1.1.1.1.cmml" xref="A1.SS3.SSS0.Px1.p1.4.m1.1.1">subscript</csymbol><ci id="A1.SS3.SSS0.Px1.p1.4.m1.1.1.2.cmml" xref="A1.SS3.SSS0.Px1.p1.4.m1.1.1.2">𝒙</ci><apply id="A1.SS3.SSS0.Px1.p1.4.m1.1.1.3.cmml" xref="A1.SS3.SSS0.Px1.p1.4.m1.1.1.3"><times id="A1.SS3.SSS0.Px1.p1.4.m1.1.1.3.1.cmml" xref="A1.SS3.SSS0.Px1.p1.4.m1.1.1.3.1"></times><ci id="A1.SS3.SSS0.Px1.p1.4.m1.1.1.3.2.cmml" xref="A1.SS3.SSS0.Px1.p1.4.m1.1.1.3.2">𝑗</ci><ci id="A1.SS3.SSS0.Px1.p1.4.m1.1.1.3.3.cmml" xref="A1.SS3.SSS0.Px1.p1.4.m1.1.1.3.3">𝑘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS3.SSS0.Px1.p1.4.m1.1c">\boldsymbol{x}_{jk}</annotation><annotation encoding="application/x-llamapun" id="A1.SS3.SSS0.Px1.p1.4.m1.1d">bold_italic_x start_POSTSUBSCRIPT italic_j italic_k end_POSTSUBSCRIPT</annotation></semantics></math> and the estimated probabilistic landmarks with mean <math alttext="\boldsymbol{\mu}_{jk}" class="ltx_Math" display="inline" id="A1.SS3.SSS0.Px1.p1.5.m2.1"><semantics id="A1.SS3.SSS0.Px1.p1.5.m2.1a"><msub id="A1.SS3.SSS0.Px1.p1.5.m2.1.1" xref="A1.SS3.SSS0.Px1.p1.5.m2.1.1.cmml"><mi id="A1.SS3.SSS0.Px1.p1.5.m2.1.1.2" xref="A1.SS3.SSS0.Px1.p1.5.m2.1.1.2.cmml">𝝁</mi><mrow id="A1.SS3.SSS0.Px1.p1.5.m2.1.1.3" xref="A1.SS3.SSS0.Px1.p1.5.m2.1.1.3.cmml"><mi id="A1.SS3.SSS0.Px1.p1.5.m2.1.1.3.2" xref="A1.SS3.SSS0.Px1.p1.5.m2.1.1.3.2.cmml">j</mi><mo id="A1.SS3.SSS0.Px1.p1.5.m2.1.1.3.1" xref="A1.SS3.SSS0.Px1.p1.5.m2.1.1.3.1.cmml">⁢</mo><mi id="A1.SS3.SSS0.Px1.p1.5.m2.1.1.3.3" xref="A1.SS3.SSS0.Px1.p1.5.m2.1.1.3.3.cmml">k</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="A1.SS3.SSS0.Px1.p1.5.m2.1b"><apply id="A1.SS3.SSS0.Px1.p1.5.m2.1.1.cmml" xref="A1.SS3.SSS0.Px1.p1.5.m2.1.1"><csymbol cd="ambiguous" id="A1.SS3.SSS0.Px1.p1.5.m2.1.1.1.cmml" xref="A1.SS3.SSS0.Px1.p1.5.m2.1.1">subscript</csymbol><ci id="A1.SS3.SSS0.Px1.p1.5.m2.1.1.2.cmml" xref="A1.SS3.SSS0.Px1.p1.5.m2.1.1.2">𝝁</ci><apply id="A1.SS3.SSS0.Px1.p1.5.m2.1.1.3.cmml" xref="A1.SS3.SSS0.Px1.p1.5.m2.1.1.3"><times id="A1.SS3.SSS0.Px1.p1.5.m2.1.1.3.1.cmml" xref="A1.SS3.SSS0.Px1.p1.5.m2.1.1.3.1"></times><ci id="A1.SS3.SSS0.Px1.p1.5.m2.1.1.3.2.cmml" xref="A1.SS3.SSS0.Px1.p1.5.m2.1.1.3.2">𝑗</ci><ci id="A1.SS3.SSS0.Px1.p1.5.m2.1.1.3.3.cmml" xref="A1.SS3.SSS0.Px1.p1.5.m2.1.1.3.3">𝑘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS3.SSS0.Px1.p1.5.m2.1c">\boldsymbol{\mu}_{jk}</annotation><annotation encoding="application/x-llamapun" id="A1.SS3.SSS0.Px1.p1.5.m2.1d">bold_italic_μ start_POSTSUBSCRIPT italic_j italic_k end_POSTSUBSCRIPT</annotation></semantics></math> and variance <math alttext="\sigma_{jk}^{2}" class="ltx_Math" display="inline" id="A1.SS3.SSS0.Px1.p1.6.m3.1"><semantics id="A1.SS3.SSS0.Px1.p1.6.m3.1a"><msubsup id="A1.SS3.SSS0.Px1.p1.6.m3.1.1" xref="A1.SS3.SSS0.Px1.p1.6.m3.1.1.cmml"><mi id="A1.SS3.SSS0.Px1.p1.6.m3.1.1.2.2" xref="A1.SS3.SSS0.Px1.p1.6.m3.1.1.2.2.cmml">σ</mi><mrow id="A1.SS3.SSS0.Px1.p1.6.m3.1.1.2.3" xref="A1.SS3.SSS0.Px1.p1.6.m3.1.1.2.3.cmml"><mi id="A1.SS3.SSS0.Px1.p1.6.m3.1.1.2.3.2" xref="A1.SS3.SSS0.Px1.p1.6.m3.1.1.2.3.2.cmml">j</mi><mo id="A1.SS3.SSS0.Px1.p1.6.m3.1.1.2.3.1" xref="A1.SS3.SSS0.Px1.p1.6.m3.1.1.2.3.1.cmml">⁢</mo><mi id="A1.SS3.SSS0.Px1.p1.6.m3.1.1.2.3.3" xref="A1.SS3.SSS0.Px1.p1.6.m3.1.1.2.3.3.cmml">k</mi></mrow><mn id="A1.SS3.SSS0.Px1.p1.6.m3.1.1.3" xref="A1.SS3.SSS0.Px1.p1.6.m3.1.1.3.cmml">2</mn></msubsup><annotation-xml encoding="MathML-Content" id="A1.SS3.SSS0.Px1.p1.6.m3.1b"><apply id="A1.SS3.SSS0.Px1.p1.6.m3.1.1.cmml" xref="A1.SS3.SSS0.Px1.p1.6.m3.1.1"><csymbol cd="ambiguous" id="A1.SS3.SSS0.Px1.p1.6.m3.1.1.1.cmml" xref="A1.SS3.SSS0.Px1.p1.6.m3.1.1">superscript</csymbol><apply id="A1.SS3.SSS0.Px1.p1.6.m3.1.1.2.cmml" xref="A1.SS3.SSS0.Px1.p1.6.m3.1.1"><csymbol cd="ambiguous" id="A1.SS3.SSS0.Px1.p1.6.m3.1.1.2.1.cmml" xref="A1.SS3.SSS0.Px1.p1.6.m3.1.1">subscript</csymbol><ci id="A1.SS3.SSS0.Px1.p1.6.m3.1.1.2.2.cmml" xref="A1.SS3.SSS0.Px1.p1.6.m3.1.1.2.2">𝜎</ci><apply id="A1.SS3.SSS0.Px1.p1.6.m3.1.1.2.3.cmml" xref="A1.SS3.SSS0.Px1.p1.6.m3.1.1.2.3"><times id="A1.SS3.SSS0.Px1.p1.6.m3.1.1.2.3.1.cmml" xref="A1.SS3.SSS0.Px1.p1.6.m3.1.1.2.3.1"></times><ci id="A1.SS3.SSS0.Px1.p1.6.m3.1.1.2.3.2.cmml" xref="A1.SS3.SSS0.Px1.p1.6.m3.1.1.2.3.2">𝑗</ci><ci id="A1.SS3.SSS0.Px1.p1.6.m3.1.1.2.3.3.cmml" xref="A1.SS3.SSS0.Px1.p1.6.m3.1.1.2.3.3">𝑘</ci></apply></apply><cn id="A1.SS3.SSS0.Px1.p1.6.m3.1.1.3.cmml" type="integer" xref="A1.SS3.SSS0.Px1.p1.6.m3.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS3.SSS0.Px1.p1.6.m3.1c">\sigma_{jk}^{2}</annotation><annotation encoding="application/x-llamapun" id="A1.SS3.SSS0.Px1.p1.6.m3.1d">italic_σ start_POSTSUBSCRIPT italic_j italic_k end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math> for all available camera views <math alttext="C" class="ltx_Math" display="inline" id="A1.SS3.SSS0.Px1.p1.7.m4.1"><semantics id="A1.SS3.SSS0.Px1.p1.7.m4.1a"><mi id="A1.SS3.SSS0.Px1.p1.7.m4.1.1" xref="A1.SS3.SSS0.Px1.p1.7.m4.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="A1.SS3.SSS0.Px1.p1.7.m4.1b"><ci id="A1.SS3.SSS0.Px1.p1.7.m4.1.1.cmml" xref="A1.SS3.SSS0.Px1.p1.7.m4.1.1">𝐶</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS3.SSS0.Px1.p1.7.m4.1c">C</annotation><annotation encoding="application/x-llamapun" id="A1.SS3.SSS0.Px1.p1.7.m4.1d">italic_C</annotation></semantics></math>.
The identity <math alttext="E_{\text{identity}}=-\log(p(\boldsymbol{\beta}))" class="ltx_Math" display="inline" id="A1.SS3.SSS0.Px1.p1.8.m5.3"><semantics id="A1.SS3.SSS0.Px1.p1.8.m5.3a"><mrow id="A1.SS3.SSS0.Px1.p1.8.m5.3.3" xref="A1.SS3.SSS0.Px1.p1.8.m5.3.3.cmml"><msub id="A1.SS3.SSS0.Px1.p1.8.m5.3.3.3" xref="A1.SS3.SSS0.Px1.p1.8.m5.3.3.3.cmml"><mi id="A1.SS3.SSS0.Px1.p1.8.m5.3.3.3.2" xref="A1.SS3.SSS0.Px1.p1.8.m5.3.3.3.2.cmml">E</mi><mtext id="A1.SS3.SSS0.Px1.p1.8.m5.3.3.3.3" xref="A1.SS3.SSS0.Px1.p1.8.m5.3.3.3.3a.cmml">identity</mtext></msub><mo id="A1.SS3.SSS0.Px1.p1.8.m5.3.3.2" xref="A1.SS3.SSS0.Px1.p1.8.m5.3.3.2.cmml">=</mo><mrow id="A1.SS3.SSS0.Px1.p1.8.m5.3.3.1" xref="A1.SS3.SSS0.Px1.p1.8.m5.3.3.1.cmml"><mo id="A1.SS3.SSS0.Px1.p1.8.m5.3.3.1a" rspace="0.167em" xref="A1.SS3.SSS0.Px1.p1.8.m5.3.3.1.cmml">−</mo><mrow id="A1.SS3.SSS0.Px1.p1.8.m5.3.3.1.1.1" xref="A1.SS3.SSS0.Px1.p1.8.m5.3.3.1.1.2.cmml"><mi id="A1.SS3.SSS0.Px1.p1.8.m5.2.2" xref="A1.SS3.SSS0.Px1.p1.8.m5.2.2.cmml">log</mi><mo id="A1.SS3.SSS0.Px1.p1.8.m5.3.3.1.1.1a" xref="A1.SS3.SSS0.Px1.p1.8.m5.3.3.1.1.2.cmml">⁡</mo><mrow id="A1.SS3.SSS0.Px1.p1.8.m5.3.3.1.1.1.1" xref="A1.SS3.SSS0.Px1.p1.8.m5.3.3.1.1.2.cmml"><mo id="A1.SS3.SSS0.Px1.p1.8.m5.3.3.1.1.1.1.2" stretchy="false" xref="A1.SS3.SSS0.Px1.p1.8.m5.3.3.1.1.2.cmml">(</mo><mrow id="A1.SS3.SSS0.Px1.p1.8.m5.3.3.1.1.1.1.1" xref="A1.SS3.SSS0.Px1.p1.8.m5.3.3.1.1.1.1.1.cmml"><mi id="A1.SS3.SSS0.Px1.p1.8.m5.3.3.1.1.1.1.1.2" xref="A1.SS3.SSS0.Px1.p1.8.m5.3.3.1.1.1.1.1.2.cmml">p</mi><mo id="A1.SS3.SSS0.Px1.p1.8.m5.3.3.1.1.1.1.1.1" xref="A1.SS3.SSS0.Px1.p1.8.m5.3.3.1.1.1.1.1.1.cmml">⁢</mo><mrow id="A1.SS3.SSS0.Px1.p1.8.m5.3.3.1.1.1.1.1.3.2" xref="A1.SS3.SSS0.Px1.p1.8.m5.3.3.1.1.1.1.1.cmml"><mo id="A1.SS3.SSS0.Px1.p1.8.m5.3.3.1.1.1.1.1.3.2.1" stretchy="false" xref="A1.SS3.SSS0.Px1.p1.8.m5.3.3.1.1.1.1.1.cmml">(</mo><mi id="A1.SS3.SSS0.Px1.p1.8.m5.1.1" xref="A1.SS3.SSS0.Px1.p1.8.m5.1.1.cmml">𝜷</mi><mo id="A1.SS3.SSS0.Px1.p1.8.m5.3.3.1.1.1.1.1.3.2.2" stretchy="false" xref="A1.SS3.SSS0.Px1.p1.8.m5.3.3.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="A1.SS3.SSS0.Px1.p1.8.m5.3.3.1.1.1.1.3" stretchy="false" xref="A1.SS3.SSS0.Px1.p1.8.m5.3.3.1.1.2.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="A1.SS3.SSS0.Px1.p1.8.m5.3b"><apply id="A1.SS3.SSS0.Px1.p1.8.m5.3.3.cmml" xref="A1.SS3.SSS0.Px1.p1.8.m5.3.3"><eq id="A1.SS3.SSS0.Px1.p1.8.m5.3.3.2.cmml" xref="A1.SS3.SSS0.Px1.p1.8.m5.3.3.2"></eq><apply id="A1.SS3.SSS0.Px1.p1.8.m5.3.3.3.cmml" xref="A1.SS3.SSS0.Px1.p1.8.m5.3.3.3"><csymbol cd="ambiguous" id="A1.SS3.SSS0.Px1.p1.8.m5.3.3.3.1.cmml" xref="A1.SS3.SSS0.Px1.p1.8.m5.3.3.3">subscript</csymbol><ci id="A1.SS3.SSS0.Px1.p1.8.m5.3.3.3.2.cmml" xref="A1.SS3.SSS0.Px1.p1.8.m5.3.3.3.2">𝐸</ci><ci id="A1.SS3.SSS0.Px1.p1.8.m5.3.3.3.3a.cmml" xref="A1.SS3.SSS0.Px1.p1.8.m5.3.3.3.3"><mtext id="A1.SS3.SSS0.Px1.p1.8.m5.3.3.3.3.cmml" mathsize="70%" xref="A1.SS3.SSS0.Px1.p1.8.m5.3.3.3.3">identity</mtext></ci></apply><apply id="A1.SS3.SSS0.Px1.p1.8.m5.3.3.1.cmml" xref="A1.SS3.SSS0.Px1.p1.8.m5.3.3.1"><minus id="A1.SS3.SSS0.Px1.p1.8.m5.3.3.1.2.cmml" xref="A1.SS3.SSS0.Px1.p1.8.m5.3.3.1"></minus><apply id="A1.SS3.SSS0.Px1.p1.8.m5.3.3.1.1.2.cmml" xref="A1.SS3.SSS0.Px1.p1.8.m5.3.3.1.1.1"><log id="A1.SS3.SSS0.Px1.p1.8.m5.2.2.cmml" xref="A1.SS3.SSS0.Px1.p1.8.m5.2.2"></log><apply id="A1.SS3.SSS0.Px1.p1.8.m5.3.3.1.1.1.1.1.cmml" xref="A1.SS3.SSS0.Px1.p1.8.m5.3.3.1.1.1.1.1"><times id="A1.SS3.SSS0.Px1.p1.8.m5.3.3.1.1.1.1.1.1.cmml" xref="A1.SS3.SSS0.Px1.p1.8.m5.3.3.1.1.1.1.1.1"></times><ci id="A1.SS3.SSS0.Px1.p1.8.m5.3.3.1.1.1.1.1.2.cmml" xref="A1.SS3.SSS0.Px1.p1.8.m5.3.3.1.1.1.1.1.2">𝑝</ci><ci id="A1.SS3.SSS0.Px1.p1.8.m5.1.1.cmml" xref="A1.SS3.SSS0.Px1.p1.8.m5.1.1">𝜷</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS3.SSS0.Px1.p1.8.m5.3c">E_{\text{identity}}=-\log(p(\boldsymbol{\beta}))</annotation><annotation encoding="application/x-llamapun" id="A1.SS3.SSS0.Px1.p1.8.m5.3d">italic_E start_POSTSUBSCRIPT identity end_POSTSUBSCRIPT = - roman_log ( italic_p ( bold_italic_β ) )</annotation></semantics></math> is a regularizer that encourages plausible face shapes. It is computed as the negative log-likelihood given a fitted Gaussian Mixture Model of 3D head scans <cite class="ltx_cite ltx_citemacro_citep">(Wood et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib72" title="">2021</a>)</cite>.
The expression and joints terms <math alttext="E_{\text{expression}}=\lVert\boldsymbol{\psi}\rVert^{2}" class="ltx_Math" display="inline" id="A1.SS3.SSS0.Px1.p1.9.m6.1"><semantics id="A1.SS3.SSS0.Px1.p1.9.m6.1a"><mrow id="A1.SS3.SSS0.Px1.p1.9.m6.1.2" xref="A1.SS3.SSS0.Px1.p1.9.m6.1.2.cmml"><msub id="A1.SS3.SSS0.Px1.p1.9.m6.1.2.2" xref="A1.SS3.SSS0.Px1.p1.9.m6.1.2.2.cmml"><mi id="A1.SS3.SSS0.Px1.p1.9.m6.1.2.2.2" xref="A1.SS3.SSS0.Px1.p1.9.m6.1.2.2.2.cmml">E</mi><mtext id="A1.SS3.SSS0.Px1.p1.9.m6.1.2.2.3" xref="A1.SS3.SSS0.Px1.p1.9.m6.1.2.2.3a.cmml">expression</mtext></msub><mo id="A1.SS3.SSS0.Px1.p1.9.m6.1.2.1" rspace="0.1389em" xref="A1.SS3.SSS0.Px1.p1.9.m6.1.2.1.cmml">=</mo><msup id="A1.SS3.SSS0.Px1.p1.9.m6.1.2.3" xref="A1.SS3.SSS0.Px1.p1.9.m6.1.2.3.cmml"><mrow id="A1.SS3.SSS0.Px1.p1.9.m6.1.2.3.2.2" xref="A1.SS3.SSS0.Px1.p1.9.m6.1.2.3.2.1.cmml"><mo fence="true" id="A1.SS3.SSS0.Px1.p1.9.m6.1.2.3.2.2.1" lspace="0.1389em" rspace="0em" xref="A1.SS3.SSS0.Px1.p1.9.m6.1.2.3.2.1.1.cmml">∥</mo><mi id="A1.SS3.SSS0.Px1.p1.9.m6.1.1" xref="A1.SS3.SSS0.Px1.p1.9.m6.1.1.cmml">𝝍</mi><mo fence="true" id="A1.SS3.SSS0.Px1.p1.9.m6.1.2.3.2.2.2" lspace="0em" xref="A1.SS3.SSS0.Px1.p1.9.m6.1.2.3.2.1.1.cmml">∥</mo></mrow><mn id="A1.SS3.SSS0.Px1.p1.9.m6.1.2.3.3" xref="A1.SS3.SSS0.Px1.p1.9.m6.1.2.3.3.cmml">2</mn></msup></mrow><annotation-xml encoding="MathML-Content" id="A1.SS3.SSS0.Px1.p1.9.m6.1b"><apply id="A1.SS3.SSS0.Px1.p1.9.m6.1.2.cmml" xref="A1.SS3.SSS0.Px1.p1.9.m6.1.2"><eq id="A1.SS3.SSS0.Px1.p1.9.m6.1.2.1.cmml" xref="A1.SS3.SSS0.Px1.p1.9.m6.1.2.1"></eq><apply id="A1.SS3.SSS0.Px1.p1.9.m6.1.2.2.cmml" xref="A1.SS3.SSS0.Px1.p1.9.m6.1.2.2"><csymbol cd="ambiguous" id="A1.SS3.SSS0.Px1.p1.9.m6.1.2.2.1.cmml" xref="A1.SS3.SSS0.Px1.p1.9.m6.1.2.2">subscript</csymbol><ci id="A1.SS3.SSS0.Px1.p1.9.m6.1.2.2.2.cmml" xref="A1.SS3.SSS0.Px1.p1.9.m6.1.2.2.2">𝐸</ci><ci id="A1.SS3.SSS0.Px1.p1.9.m6.1.2.2.3a.cmml" xref="A1.SS3.SSS0.Px1.p1.9.m6.1.2.2.3"><mtext id="A1.SS3.SSS0.Px1.p1.9.m6.1.2.2.3.cmml" mathsize="70%" xref="A1.SS3.SSS0.Px1.p1.9.m6.1.2.2.3">expression</mtext></ci></apply><apply id="A1.SS3.SSS0.Px1.p1.9.m6.1.2.3.cmml" xref="A1.SS3.SSS0.Px1.p1.9.m6.1.2.3"><csymbol cd="ambiguous" id="A1.SS3.SSS0.Px1.p1.9.m6.1.2.3.1.cmml" xref="A1.SS3.SSS0.Px1.p1.9.m6.1.2.3">superscript</csymbol><apply id="A1.SS3.SSS0.Px1.p1.9.m6.1.2.3.2.1.cmml" xref="A1.SS3.SSS0.Px1.p1.9.m6.1.2.3.2.2"><csymbol cd="latexml" id="A1.SS3.SSS0.Px1.p1.9.m6.1.2.3.2.1.1.cmml" xref="A1.SS3.SSS0.Px1.p1.9.m6.1.2.3.2.2.1">delimited-∥∥</csymbol><ci id="A1.SS3.SSS0.Px1.p1.9.m6.1.1.cmml" xref="A1.SS3.SSS0.Px1.p1.9.m6.1.1">𝝍</ci></apply><cn id="A1.SS3.SSS0.Px1.p1.9.m6.1.2.3.3.cmml" type="integer" xref="A1.SS3.SSS0.Px1.p1.9.m6.1.2.3.3">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS3.SSS0.Px1.p1.9.m6.1c">E_{\text{expression}}=\lVert\boldsymbol{\psi}\rVert^{2}</annotation><annotation encoding="application/x-llamapun" id="A1.SS3.SSS0.Px1.p1.9.m6.1d">italic_E start_POSTSUBSCRIPT expression end_POSTSUBSCRIPT = ∥ bold_italic_ψ ∥ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math> and <math alttext="E_{\text{joints}}=\lVert\boldsymbol{J}_{i}\rVert^{2}" class="ltx_Math" display="inline" id="A1.SS3.SSS0.Px1.p1.10.m7.1"><semantics id="A1.SS3.SSS0.Px1.p1.10.m7.1a"><mrow id="A1.SS3.SSS0.Px1.p1.10.m7.1.1" xref="A1.SS3.SSS0.Px1.p1.10.m7.1.1.cmml"><msub id="A1.SS3.SSS0.Px1.p1.10.m7.1.1.3" xref="A1.SS3.SSS0.Px1.p1.10.m7.1.1.3.cmml"><mi id="A1.SS3.SSS0.Px1.p1.10.m7.1.1.3.2" xref="A1.SS3.SSS0.Px1.p1.10.m7.1.1.3.2.cmml">E</mi><mtext id="A1.SS3.SSS0.Px1.p1.10.m7.1.1.3.3" xref="A1.SS3.SSS0.Px1.p1.10.m7.1.1.3.3a.cmml">joints</mtext></msub><mo id="A1.SS3.SSS0.Px1.p1.10.m7.1.1.2" rspace="0.1389em" xref="A1.SS3.SSS0.Px1.p1.10.m7.1.1.2.cmml">=</mo><msup id="A1.SS3.SSS0.Px1.p1.10.m7.1.1.1" xref="A1.SS3.SSS0.Px1.p1.10.m7.1.1.1.cmml"><mrow id="A1.SS3.SSS0.Px1.p1.10.m7.1.1.1.1.1" xref="A1.SS3.SSS0.Px1.p1.10.m7.1.1.1.1.2.cmml"><mo fence="true" id="A1.SS3.SSS0.Px1.p1.10.m7.1.1.1.1.1.2" lspace="0.1389em" rspace="0em" xref="A1.SS3.SSS0.Px1.p1.10.m7.1.1.1.1.2.1.cmml">∥</mo><msub id="A1.SS3.SSS0.Px1.p1.10.m7.1.1.1.1.1.1" xref="A1.SS3.SSS0.Px1.p1.10.m7.1.1.1.1.1.1.cmml"><mi id="A1.SS3.SSS0.Px1.p1.10.m7.1.1.1.1.1.1.2" xref="A1.SS3.SSS0.Px1.p1.10.m7.1.1.1.1.1.1.2.cmml">𝑱</mi><mi id="A1.SS3.SSS0.Px1.p1.10.m7.1.1.1.1.1.1.3" xref="A1.SS3.SSS0.Px1.p1.10.m7.1.1.1.1.1.1.3.cmml">i</mi></msub><mo fence="true" id="A1.SS3.SSS0.Px1.p1.10.m7.1.1.1.1.1.3" lspace="0em" xref="A1.SS3.SSS0.Px1.p1.10.m7.1.1.1.1.2.1.cmml">∥</mo></mrow><mn id="A1.SS3.SSS0.Px1.p1.10.m7.1.1.1.3" xref="A1.SS3.SSS0.Px1.p1.10.m7.1.1.1.3.cmml">2</mn></msup></mrow><annotation-xml encoding="MathML-Content" id="A1.SS3.SSS0.Px1.p1.10.m7.1b"><apply id="A1.SS3.SSS0.Px1.p1.10.m7.1.1.cmml" xref="A1.SS3.SSS0.Px1.p1.10.m7.1.1"><eq id="A1.SS3.SSS0.Px1.p1.10.m7.1.1.2.cmml" xref="A1.SS3.SSS0.Px1.p1.10.m7.1.1.2"></eq><apply id="A1.SS3.SSS0.Px1.p1.10.m7.1.1.3.cmml" xref="A1.SS3.SSS0.Px1.p1.10.m7.1.1.3"><csymbol cd="ambiguous" id="A1.SS3.SSS0.Px1.p1.10.m7.1.1.3.1.cmml" xref="A1.SS3.SSS0.Px1.p1.10.m7.1.1.3">subscript</csymbol><ci id="A1.SS3.SSS0.Px1.p1.10.m7.1.1.3.2.cmml" xref="A1.SS3.SSS0.Px1.p1.10.m7.1.1.3.2">𝐸</ci><ci id="A1.SS3.SSS0.Px1.p1.10.m7.1.1.3.3a.cmml" xref="A1.SS3.SSS0.Px1.p1.10.m7.1.1.3.3"><mtext id="A1.SS3.SSS0.Px1.p1.10.m7.1.1.3.3.cmml" mathsize="70%" xref="A1.SS3.SSS0.Px1.p1.10.m7.1.1.3.3">joints</mtext></ci></apply><apply id="A1.SS3.SSS0.Px1.p1.10.m7.1.1.1.cmml" xref="A1.SS3.SSS0.Px1.p1.10.m7.1.1.1"><csymbol cd="ambiguous" id="A1.SS3.SSS0.Px1.p1.10.m7.1.1.1.2.cmml" xref="A1.SS3.SSS0.Px1.p1.10.m7.1.1.1">superscript</csymbol><apply id="A1.SS3.SSS0.Px1.p1.10.m7.1.1.1.1.2.cmml" xref="A1.SS3.SSS0.Px1.p1.10.m7.1.1.1.1.1"><csymbol cd="latexml" id="A1.SS3.SSS0.Px1.p1.10.m7.1.1.1.1.2.1.cmml" xref="A1.SS3.SSS0.Px1.p1.10.m7.1.1.1.1.1.2">delimited-∥∥</csymbol><apply id="A1.SS3.SSS0.Px1.p1.10.m7.1.1.1.1.1.1.cmml" xref="A1.SS3.SSS0.Px1.p1.10.m7.1.1.1.1.1.1"><csymbol cd="ambiguous" id="A1.SS3.SSS0.Px1.p1.10.m7.1.1.1.1.1.1.1.cmml" xref="A1.SS3.SSS0.Px1.p1.10.m7.1.1.1.1.1.1">subscript</csymbol><ci id="A1.SS3.SSS0.Px1.p1.10.m7.1.1.1.1.1.1.2.cmml" xref="A1.SS3.SSS0.Px1.p1.10.m7.1.1.1.1.1.1.2">𝑱</ci><ci id="A1.SS3.SSS0.Px1.p1.10.m7.1.1.1.1.1.1.3.cmml" xref="A1.SS3.SSS0.Px1.p1.10.m7.1.1.1.1.1.1.3">𝑖</ci></apply></apply><cn id="A1.SS3.SSS0.Px1.p1.10.m7.1.1.1.3.cmml" type="integer" xref="A1.SS3.SSS0.Px1.p1.10.m7.1.1.1.3">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS3.SSS0.Px1.p1.10.m7.1c">E_{\text{joints}}=\lVert\boldsymbol{J}_{i}\rVert^{2}</annotation><annotation encoding="application/x-llamapun" id="A1.SS3.SSS0.Px1.p1.10.m7.1d">italic_E start_POSTSUBSCRIPT joints end_POSTSUBSCRIPT = ∥ bold_italic_J start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ∥ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math> are regularization terms to encourage small values in the expression code <math alttext="\boldsymbol{\psi}" class="ltx_Math" display="inline" id="A1.SS3.SSS0.Px1.p1.11.m8.1"><semantics id="A1.SS3.SSS0.Px1.p1.11.m8.1a"><mi id="A1.SS3.SSS0.Px1.p1.11.m8.1.1" xref="A1.SS3.SSS0.Px1.p1.11.m8.1.1.cmml">𝝍</mi><annotation-xml encoding="MathML-Content" id="A1.SS3.SSS0.Px1.p1.11.m8.1b"><ci id="A1.SS3.SSS0.Px1.p1.11.m8.1.1.cmml" xref="A1.SS3.SSS0.Px1.p1.11.m8.1.1">𝝍</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS3.SSS0.Px1.p1.11.m8.1c">\boldsymbol{\psi}</annotation><annotation encoding="application/x-llamapun" id="A1.SS3.SSS0.Px1.p1.11.m8.1d">bold_italic_ψ</annotation></semantics></math> and joint rotations <math alttext="\boldsymbol{J}_{i}" class="ltx_Math" display="inline" id="A1.SS3.SSS0.Px1.p1.12.m9.1"><semantics id="A1.SS3.SSS0.Px1.p1.12.m9.1a"><msub id="A1.SS3.SSS0.Px1.p1.12.m9.1.1" xref="A1.SS3.SSS0.Px1.p1.12.m9.1.1.cmml"><mi id="A1.SS3.SSS0.Px1.p1.12.m9.1.1.2" xref="A1.SS3.SSS0.Px1.p1.12.m9.1.1.2.cmml">𝑱</mi><mi id="A1.SS3.SSS0.Px1.p1.12.m9.1.1.3" xref="A1.SS3.SSS0.Px1.p1.12.m9.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="A1.SS3.SSS0.Px1.p1.12.m9.1b"><apply id="A1.SS3.SSS0.Px1.p1.12.m9.1.1.cmml" xref="A1.SS3.SSS0.Px1.p1.12.m9.1.1"><csymbol cd="ambiguous" id="A1.SS3.SSS0.Px1.p1.12.m9.1.1.1.cmml" xref="A1.SS3.SSS0.Px1.p1.12.m9.1.1">subscript</csymbol><ci id="A1.SS3.SSS0.Px1.p1.12.m9.1.1.2.cmml" xref="A1.SS3.SSS0.Px1.p1.12.m9.1.1.2">𝑱</ci><ci id="A1.SS3.SSS0.Px1.p1.12.m9.1.1.3.cmml" xref="A1.SS3.SSS0.Px1.p1.12.m9.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS3.SSS0.Px1.p1.12.m9.1c">\boldsymbol{J}_{i}</annotation><annotation encoding="application/x-llamapun" id="A1.SS3.SSS0.Px1.p1.12.m9.1d">bold_italic_J start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> for the neck and the two eyeball joints. Note that the regularization does not apply to the global (head) joint. <math alttext="E_{\text{intersect}}" class="ltx_Math" display="inline" id="A1.SS3.SSS0.Px1.p1.13.m10.1"><semantics id="A1.SS3.SSS0.Px1.p1.13.m10.1a"><msub id="A1.SS3.SSS0.Px1.p1.13.m10.1.1" xref="A1.SS3.SSS0.Px1.p1.13.m10.1.1.cmml"><mi id="A1.SS3.SSS0.Px1.p1.13.m10.1.1.2" xref="A1.SS3.SSS0.Px1.p1.13.m10.1.1.2.cmml">E</mi><mtext id="A1.SS3.SSS0.Px1.p1.13.m10.1.1.3" xref="A1.SS3.SSS0.Px1.p1.13.m10.1.1.3a.cmml">intersect</mtext></msub><annotation-xml encoding="MathML-Content" id="A1.SS3.SSS0.Px1.p1.13.m10.1b"><apply id="A1.SS3.SSS0.Px1.p1.13.m10.1.1.cmml" xref="A1.SS3.SSS0.Px1.p1.13.m10.1.1"><csymbol cd="ambiguous" id="A1.SS3.SSS0.Px1.p1.13.m10.1.1.1.cmml" xref="A1.SS3.SSS0.Px1.p1.13.m10.1.1">subscript</csymbol><ci id="A1.SS3.SSS0.Px1.p1.13.m10.1.1.2.cmml" xref="A1.SS3.SSS0.Px1.p1.13.m10.1.1.2">𝐸</ci><ci id="A1.SS3.SSS0.Px1.p1.13.m10.1.1.3a.cmml" xref="A1.SS3.SSS0.Px1.p1.13.m10.1.1.3"><mtext id="A1.SS3.SSS0.Px1.p1.13.m10.1.1.3.cmml" mathsize="70%" xref="A1.SS3.SSS0.Px1.p1.13.m10.1.1.3">intersect</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS3.SSS0.Px1.p1.13.m10.1c">E_{\text{intersect}}</annotation><annotation encoding="application/x-llamapun" id="A1.SS3.SSS0.Px1.p1.13.m10.1d">italic_E start_POSTSUBSCRIPT intersect end_POSTSUBSCRIPT</annotation></semantics></math> discourages intersecting vertices. Please see <cite class="ltx_cite ltx_citemacro_citep">(Wood et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib73" title="">2022</a>)</cite> for more details.</p>
</div>
</section>
<section class="ltx_paragraph" id="A1.SS3.SSS0.Px2">
<h5 class="ltx_title ltx_title_paragraph">Warm-up by Inversion</h5>
<div class="ltx_para" id="A1.SS3.SSS0.Px2.p1">
<p class="ltx_p" id="A1.SS3.SSS0.Px2.p1.3">We sample random patches of size <math alttext="32\times 32" class="ltx_Math" display="inline" id="A1.SS3.SSS0.Px2.p1.1.m1.1"><semantics id="A1.SS3.SSS0.Px2.p1.1.m1.1a"><mrow id="A1.SS3.SSS0.Px2.p1.1.m1.1.1" xref="A1.SS3.SSS0.Px2.p1.1.m1.1.1.cmml"><mn id="A1.SS3.SSS0.Px2.p1.1.m1.1.1.2" xref="A1.SS3.SSS0.Px2.p1.1.m1.1.1.2.cmml">32</mn><mo id="A1.SS3.SSS0.Px2.p1.1.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="A1.SS3.SSS0.Px2.p1.1.m1.1.1.1.cmml">×</mo><mn id="A1.SS3.SSS0.Px2.p1.1.m1.1.1.3" xref="A1.SS3.SSS0.Px2.p1.1.m1.1.1.3.cmml">32</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.SS3.SSS0.Px2.p1.1.m1.1b"><apply id="A1.SS3.SSS0.Px2.p1.1.m1.1.1.cmml" xref="A1.SS3.SSS0.Px2.p1.1.m1.1.1"><times id="A1.SS3.SSS0.Px2.p1.1.m1.1.1.1.cmml" xref="A1.SS3.SSS0.Px2.p1.1.m1.1.1.1"></times><cn id="A1.SS3.SSS0.Px2.p1.1.m1.1.1.2.cmml" type="integer" xref="A1.SS3.SSS0.Px2.p1.1.m1.1.1.2">32</cn><cn id="A1.SS3.SSS0.Px2.p1.1.m1.1.1.3.cmml" type="integer" xref="A1.SS3.SSS0.Px2.p1.1.m1.1.1.3">32</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS3.SSS0.Px2.p1.1.m1.1c">32\times 32</annotation><annotation encoding="application/x-llamapun" id="A1.SS3.SSS0.Px2.p1.1.m1.1d">32 × 32</annotation></semantics></math>. Our batch size is <math alttext="4096" class="ltx_Math" display="inline" id="A1.SS3.SSS0.Px2.p1.2.m2.1"><semantics id="A1.SS3.SSS0.Px2.p1.2.m2.1a"><mn id="A1.SS3.SSS0.Px2.p1.2.m2.1.1" xref="A1.SS3.SSS0.Px2.p1.2.m2.1.1.cmml">4096</mn><annotation-xml encoding="MathML-Content" id="A1.SS3.SSS0.Px2.p1.2.m2.1b"><cn id="A1.SS3.SSS0.Px2.p1.2.m2.1.1.cmml" type="integer" xref="A1.SS3.SSS0.Px2.p1.2.m2.1.1">4096</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS3.SSS0.Px2.p1.2.m2.1c">4096</annotation><annotation encoding="application/x-llamapun" id="A1.SS3.SSS0.Px2.p1.2.m2.1d">4096</annotation></semantics></math> rays so we use <math alttext="4" class="ltx_Math" display="inline" id="A1.SS3.SSS0.Px2.p1.3.m3.1"><semantics id="A1.SS3.SSS0.Px2.p1.3.m3.1a"><mn id="A1.SS3.SSS0.Px2.p1.3.m3.1.1" xref="A1.SS3.SSS0.Px2.p1.3.m3.1.1.cmml">4</mn><annotation-xml encoding="MathML-Content" id="A1.SS3.SSS0.Px2.p1.3.m3.1b"><cn id="A1.SS3.SSS0.Px2.p1.3.m3.1.1.cmml" type="integer" xref="A1.SS3.SSS0.Px2.p1.3.m3.1.1">4</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS3.SSS0.Px2.p1.3.m3.1c">4</annotation><annotation encoding="application/x-llamapun" id="A1.SS3.SSS0.Px2.p1.3.m3.1d">4</annotation></semantics></math> patches in each batch. We run 1,500 inversion steps, which takes about 10 minutes on four TPUs.</p>
</div>
</section>
<section class="ltx_paragraph" id="A1.SS3.SSS0.Px3">
<h5 class="ltx_title ltx_title_paragraph">Optimization</h5>
<div class="ltx_para" id="A1.SS3.SSS0.Px3.p1">
<p class="ltx_p" id="A1.SS3.SSS0.Px3.p1.1">The model fitting uses the same sampling strategy as prior model training (2x proposal and 1x NeRF sampling) and employs the Adam optimizer with the same parameters.
We sample <math alttext="4096" class="ltx_Math" display="inline" id="A1.SS3.SSS0.Px3.p1.1.m1.1"><semantics id="A1.SS3.SSS0.Px3.p1.1.m1.1a"><mn id="A1.SS3.SSS0.Px3.p1.1.m1.1.1" xref="A1.SS3.SSS0.Px3.p1.1.m1.1.1.cmml">4096</mn><annotation-xml encoding="MathML-Content" id="A1.SS3.SSS0.Px3.p1.1.m1.1b"><cn id="A1.SS3.SSS0.Px3.p1.1.m1.1.1.cmml" type="integer" xref="A1.SS3.SSS0.Px3.p1.1.m1.1.1">4096</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS3.SSS0.Px3.p1.1.m1.1c">4096</annotation><annotation encoding="application/x-llamapun" id="A1.SS3.SSS0.Px3.p1.1.m1.1d">4096</annotation></semantics></math> random rays across all available views in each step. We optimize for 50,000 steps, which takes about 3.5 hours.</p>
</div>
</section>
<section class="ltx_paragraph" id="A1.SS3.SSS0.Px4">
<h5 class="ltx_title ltx_title_paragraph">Losses</h5>
<div class="ltx_para" id="A1.SS3.SSS0.Px4.p1">
<p class="ltx_p" id="A1.SS3.SSS0.Px4.p1.10">The loss terms follow related works. In the following, the variable <math alttext="w" class="ltx_Math" display="inline" id="A1.SS3.SSS0.Px4.p1.1.m1.1"><semantics id="A1.SS3.SSS0.Px4.p1.1.m1.1a"><mi id="A1.SS3.SSS0.Px4.p1.1.m1.1.1" xref="A1.SS3.SSS0.Px4.p1.1.m1.1.1.cmml">w</mi><annotation-xml encoding="MathML-Content" id="A1.SS3.SSS0.Px4.p1.1.m1.1b"><ci id="A1.SS3.SSS0.Px4.p1.1.m1.1.1.cmml" xref="A1.SS3.SSS0.Px4.p1.1.m1.1.1">𝑤</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS3.SSS0.Px4.p1.1.m1.1c">w</annotation><annotation encoding="application/x-llamapun" id="A1.SS3.SSS0.Px4.p1.1.m1.1d">italic_w</annotation></semantics></math> corresponds to the NeRF sample weight defined in Eq. 5 of the original NeRF paper <cite class="ltx_cite ltx_citemacro_citep">(Mildenhall et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib40" title="">2020</a>)</cite>.
The normal consistency loss is defined as <math alttext="\mathcal{L}_{\text{normal}}=\sum_{i}w_{i}\cdot(1-\boldsymbol{\text{n}}^{\top}%
\boldsymbol{\hat{\text{n}}})" class="ltx_Math" display="inline" id="A1.SS3.SSS0.Px4.p1.2.m2.1"><semantics id="A1.SS3.SSS0.Px4.p1.2.m2.1a"><mrow id="A1.SS3.SSS0.Px4.p1.2.m2.1.1" xref="A1.SS3.SSS0.Px4.p1.2.m2.1.1.cmml"><msub id="A1.SS3.SSS0.Px4.p1.2.m2.1.1.3" xref="A1.SS3.SSS0.Px4.p1.2.m2.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="A1.SS3.SSS0.Px4.p1.2.m2.1.1.3.2" xref="A1.SS3.SSS0.Px4.p1.2.m2.1.1.3.2.cmml">ℒ</mi><mtext id="A1.SS3.SSS0.Px4.p1.2.m2.1.1.3.3" xref="A1.SS3.SSS0.Px4.p1.2.m2.1.1.3.3a.cmml">normal</mtext></msub><mo id="A1.SS3.SSS0.Px4.p1.2.m2.1.1.2" rspace="0.111em" xref="A1.SS3.SSS0.Px4.p1.2.m2.1.1.2.cmml">=</mo><mrow id="A1.SS3.SSS0.Px4.p1.2.m2.1.1.1" xref="A1.SS3.SSS0.Px4.p1.2.m2.1.1.1.cmml"><msub id="A1.SS3.SSS0.Px4.p1.2.m2.1.1.1.2" xref="A1.SS3.SSS0.Px4.p1.2.m2.1.1.1.2.cmml"><mo id="A1.SS3.SSS0.Px4.p1.2.m2.1.1.1.2.2" xref="A1.SS3.SSS0.Px4.p1.2.m2.1.1.1.2.2.cmml">∑</mo><mi id="A1.SS3.SSS0.Px4.p1.2.m2.1.1.1.2.3" xref="A1.SS3.SSS0.Px4.p1.2.m2.1.1.1.2.3.cmml">i</mi></msub><mrow id="A1.SS3.SSS0.Px4.p1.2.m2.1.1.1.1" xref="A1.SS3.SSS0.Px4.p1.2.m2.1.1.1.1.cmml"><msub id="A1.SS3.SSS0.Px4.p1.2.m2.1.1.1.1.3" xref="A1.SS3.SSS0.Px4.p1.2.m2.1.1.1.1.3.cmml"><mi id="A1.SS3.SSS0.Px4.p1.2.m2.1.1.1.1.3.2" xref="A1.SS3.SSS0.Px4.p1.2.m2.1.1.1.1.3.2.cmml">w</mi><mi id="A1.SS3.SSS0.Px4.p1.2.m2.1.1.1.1.3.3" xref="A1.SS3.SSS0.Px4.p1.2.m2.1.1.1.1.3.3.cmml">i</mi></msub><mo id="A1.SS3.SSS0.Px4.p1.2.m2.1.1.1.1.2" lspace="0.222em" rspace="0.222em" xref="A1.SS3.SSS0.Px4.p1.2.m2.1.1.1.1.2.cmml">⋅</mo><mrow id="A1.SS3.SSS0.Px4.p1.2.m2.1.1.1.1.1.1" xref="A1.SS3.SSS0.Px4.p1.2.m2.1.1.1.1.1.1.1.cmml"><mo id="A1.SS3.SSS0.Px4.p1.2.m2.1.1.1.1.1.1.2" stretchy="false" xref="A1.SS3.SSS0.Px4.p1.2.m2.1.1.1.1.1.1.1.cmml">(</mo><mrow id="A1.SS3.SSS0.Px4.p1.2.m2.1.1.1.1.1.1.1" xref="A1.SS3.SSS0.Px4.p1.2.m2.1.1.1.1.1.1.1.cmml"><mn id="A1.SS3.SSS0.Px4.p1.2.m2.1.1.1.1.1.1.1.2" xref="A1.SS3.SSS0.Px4.p1.2.m2.1.1.1.1.1.1.1.2.cmml">1</mn><mo id="A1.SS3.SSS0.Px4.p1.2.m2.1.1.1.1.1.1.1.1" xref="A1.SS3.SSS0.Px4.p1.2.m2.1.1.1.1.1.1.1.1.cmml">−</mo><mrow id="A1.SS3.SSS0.Px4.p1.2.m2.1.1.1.1.1.1.1.3" xref="A1.SS3.SSS0.Px4.p1.2.m2.1.1.1.1.1.1.1.3.cmml"><msup id="A1.SS3.SSS0.Px4.p1.2.m2.1.1.1.1.1.1.1.3.2" xref="A1.SS3.SSS0.Px4.p1.2.m2.1.1.1.1.1.1.1.3.2.cmml"><mtext id="A1.SS3.SSS0.Px4.p1.2.m2.1.1.1.1.1.1.1.3.2.2" xref="A1.SS3.SSS0.Px4.p1.2.m2.1.1.1.1.1.1.1.3.2.2a.cmml">n</mtext><mo id="A1.SS3.SSS0.Px4.p1.2.m2.1.1.1.1.1.1.1.3.2.3" xref="A1.SS3.SSS0.Px4.p1.2.m2.1.1.1.1.1.1.1.3.2.3.cmml">⊤</mo></msup><mo id="A1.SS3.SSS0.Px4.p1.2.m2.1.1.1.1.1.1.1.3.1" xref="A1.SS3.SSS0.Px4.p1.2.m2.1.1.1.1.1.1.1.3.1.cmml">⁢</mo><mover accent="true" id="A1.SS3.SSS0.Px4.p1.2.m2.1.1.1.1.1.1.1.3.3" xref="A1.SS3.SSS0.Px4.p1.2.m2.1.1.1.1.1.1.1.3.3.cmml"><mtext id="A1.SS3.SSS0.Px4.p1.2.m2.1.1.1.1.1.1.1.3.3.2" xref="A1.SS3.SSS0.Px4.p1.2.m2.1.1.1.1.1.1.1.3.3.2a.cmml">n</mtext><mo class="ltx_mathvariant_bold" id="A1.SS3.SSS0.Px4.p1.2.m2.1.1.1.1.1.1.1.3.3.1" mathvariant="bold" xref="A1.SS3.SSS0.Px4.p1.2.m2.1.1.1.1.1.1.1.3.3.1.cmml">^</mo></mover></mrow></mrow><mo id="A1.SS3.SSS0.Px4.p1.2.m2.1.1.1.1.1.1.3" stretchy="false" xref="A1.SS3.SSS0.Px4.p1.2.m2.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="A1.SS3.SSS0.Px4.p1.2.m2.1b"><apply id="A1.SS3.SSS0.Px4.p1.2.m2.1.1.cmml" xref="A1.SS3.SSS0.Px4.p1.2.m2.1.1"><eq id="A1.SS3.SSS0.Px4.p1.2.m2.1.1.2.cmml" xref="A1.SS3.SSS0.Px4.p1.2.m2.1.1.2"></eq><apply id="A1.SS3.SSS0.Px4.p1.2.m2.1.1.3.cmml" xref="A1.SS3.SSS0.Px4.p1.2.m2.1.1.3"><csymbol cd="ambiguous" id="A1.SS3.SSS0.Px4.p1.2.m2.1.1.3.1.cmml" xref="A1.SS3.SSS0.Px4.p1.2.m2.1.1.3">subscript</csymbol><ci id="A1.SS3.SSS0.Px4.p1.2.m2.1.1.3.2.cmml" xref="A1.SS3.SSS0.Px4.p1.2.m2.1.1.3.2">ℒ</ci><ci id="A1.SS3.SSS0.Px4.p1.2.m2.1.1.3.3a.cmml" xref="A1.SS3.SSS0.Px4.p1.2.m2.1.1.3.3"><mtext id="A1.SS3.SSS0.Px4.p1.2.m2.1.1.3.3.cmml" mathsize="70%" xref="A1.SS3.SSS0.Px4.p1.2.m2.1.1.3.3">normal</mtext></ci></apply><apply id="A1.SS3.SSS0.Px4.p1.2.m2.1.1.1.cmml" xref="A1.SS3.SSS0.Px4.p1.2.m2.1.1.1"><apply id="A1.SS3.SSS0.Px4.p1.2.m2.1.1.1.2.cmml" xref="A1.SS3.SSS0.Px4.p1.2.m2.1.1.1.2"><csymbol cd="ambiguous" id="A1.SS3.SSS0.Px4.p1.2.m2.1.1.1.2.1.cmml" xref="A1.SS3.SSS0.Px4.p1.2.m2.1.1.1.2">subscript</csymbol><sum id="A1.SS3.SSS0.Px4.p1.2.m2.1.1.1.2.2.cmml" xref="A1.SS3.SSS0.Px4.p1.2.m2.1.1.1.2.2"></sum><ci id="A1.SS3.SSS0.Px4.p1.2.m2.1.1.1.2.3.cmml" xref="A1.SS3.SSS0.Px4.p1.2.m2.1.1.1.2.3">𝑖</ci></apply><apply id="A1.SS3.SSS0.Px4.p1.2.m2.1.1.1.1.cmml" xref="A1.SS3.SSS0.Px4.p1.2.m2.1.1.1.1"><ci id="A1.SS3.SSS0.Px4.p1.2.m2.1.1.1.1.2.cmml" xref="A1.SS3.SSS0.Px4.p1.2.m2.1.1.1.1.2">⋅</ci><apply id="A1.SS3.SSS0.Px4.p1.2.m2.1.1.1.1.3.cmml" xref="A1.SS3.SSS0.Px4.p1.2.m2.1.1.1.1.3"><csymbol cd="ambiguous" id="A1.SS3.SSS0.Px4.p1.2.m2.1.1.1.1.3.1.cmml" xref="A1.SS3.SSS0.Px4.p1.2.m2.1.1.1.1.3">subscript</csymbol><ci id="A1.SS3.SSS0.Px4.p1.2.m2.1.1.1.1.3.2.cmml" xref="A1.SS3.SSS0.Px4.p1.2.m2.1.1.1.1.3.2">𝑤</ci><ci id="A1.SS3.SSS0.Px4.p1.2.m2.1.1.1.1.3.3.cmml" xref="A1.SS3.SSS0.Px4.p1.2.m2.1.1.1.1.3.3">𝑖</ci></apply><apply id="A1.SS3.SSS0.Px4.p1.2.m2.1.1.1.1.1.1.1.cmml" xref="A1.SS3.SSS0.Px4.p1.2.m2.1.1.1.1.1.1"><minus id="A1.SS3.SSS0.Px4.p1.2.m2.1.1.1.1.1.1.1.1.cmml" xref="A1.SS3.SSS0.Px4.p1.2.m2.1.1.1.1.1.1.1.1"></minus><cn id="A1.SS3.SSS0.Px4.p1.2.m2.1.1.1.1.1.1.1.2.cmml" type="integer" xref="A1.SS3.SSS0.Px4.p1.2.m2.1.1.1.1.1.1.1.2">1</cn><apply id="A1.SS3.SSS0.Px4.p1.2.m2.1.1.1.1.1.1.1.3.cmml" xref="A1.SS3.SSS0.Px4.p1.2.m2.1.1.1.1.1.1.1.3"><times id="A1.SS3.SSS0.Px4.p1.2.m2.1.1.1.1.1.1.1.3.1.cmml" xref="A1.SS3.SSS0.Px4.p1.2.m2.1.1.1.1.1.1.1.3.1"></times><apply id="A1.SS3.SSS0.Px4.p1.2.m2.1.1.1.1.1.1.1.3.2.cmml" xref="A1.SS3.SSS0.Px4.p1.2.m2.1.1.1.1.1.1.1.3.2"><csymbol cd="ambiguous" id="A1.SS3.SSS0.Px4.p1.2.m2.1.1.1.1.1.1.1.3.2.1.cmml" xref="A1.SS3.SSS0.Px4.p1.2.m2.1.1.1.1.1.1.1.3.2">superscript</csymbol><ci id="A1.SS3.SSS0.Px4.p1.2.m2.1.1.1.1.1.1.1.3.2.2a.cmml" xref="A1.SS3.SSS0.Px4.p1.2.m2.1.1.1.1.1.1.1.3.2.2"><mtext id="A1.SS3.SSS0.Px4.p1.2.m2.1.1.1.1.1.1.1.3.2.2.cmml" xref="A1.SS3.SSS0.Px4.p1.2.m2.1.1.1.1.1.1.1.3.2.2">n</mtext></ci><csymbol cd="latexml" id="A1.SS3.SSS0.Px4.p1.2.m2.1.1.1.1.1.1.1.3.2.3.cmml" xref="A1.SS3.SSS0.Px4.p1.2.m2.1.1.1.1.1.1.1.3.2.3">top</csymbol></apply><apply id="A1.SS3.SSS0.Px4.p1.2.m2.1.1.1.1.1.1.1.3.3.cmml" xref="A1.SS3.SSS0.Px4.p1.2.m2.1.1.1.1.1.1.1.3.3"><ci id="A1.SS3.SSS0.Px4.p1.2.m2.1.1.1.1.1.1.1.3.3.1.cmml" xref="A1.SS3.SSS0.Px4.p1.2.m2.1.1.1.1.1.1.1.3.3.1">bold-^</ci><ci id="A1.SS3.SSS0.Px4.p1.2.m2.1.1.1.1.1.1.1.3.3.2a.cmml" xref="A1.SS3.SSS0.Px4.p1.2.m2.1.1.1.1.1.1.1.3.3.2"><mtext id="A1.SS3.SSS0.Px4.p1.2.m2.1.1.1.1.1.1.1.3.3.2.cmml" xref="A1.SS3.SSS0.Px4.p1.2.m2.1.1.1.1.1.1.1.3.3.2">n</mtext></ci></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS3.SSS0.Px4.p1.2.m2.1c">\mathcal{L}_{\text{normal}}=\sum_{i}w_{i}\cdot(1-\boldsymbol{\text{n}}^{\top}%
\boldsymbol{\hat{\text{n}}})</annotation><annotation encoding="application/x-llamapun" id="A1.SS3.SSS0.Px4.p1.2.m2.1d">caligraphic_L start_POSTSUBSCRIPT normal end_POSTSUBSCRIPT = ∑ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ⋅ ( 1 - n start_POSTSUPERSCRIPT ⊤ end_POSTSUPERSCRIPT overbold_^ start_ARG n end_ARG )</annotation></semantics></math>, where <span class="ltx_text ltx_markedasmath" id="A1.SS3.SSS0.Px4.p1.10.1">n</span> are the analytical normals and <math alttext="\boldsymbol{\hat{\text{n}}}" class="ltx_Math" display="inline" id="A1.SS3.SSS0.Px4.p1.4.m4.1"><semantics id="A1.SS3.SSS0.Px4.p1.4.m4.1a"><mover accent="true" id="A1.SS3.SSS0.Px4.p1.4.m4.1.1" xref="A1.SS3.SSS0.Px4.p1.4.m4.1.1.cmml"><mtext id="A1.SS3.SSS0.Px4.p1.4.m4.1.1.2" xref="A1.SS3.SSS0.Px4.p1.4.m4.1.1.2a.cmml">n</mtext><mo class="ltx_mathvariant_bold" id="A1.SS3.SSS0.Px4.p1.4.m4.1.1.1" mathvariant="bold" xref="A1.SS3.SSS0.Px4.p1.4.m4.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="A1.SS3.SSS0.Px4.p1.4.m4.1b"><apply id="A1.SS3.SSS0.Px4.p1.4.m4.1.1.cmml" xref="A1.SS3.SSS0.Px4.p1.4.m4.1.1"><ci id="A1.SS3.SSS0.Px4.p1.4.m4.1.1.1.cmml" xref="A1.SS3.SSS0.Px4.p1.4.m4.1.1.1">bold-^</ci><ci id="A1.SS3.SSS0.Px4.p1.4.m4.1.1.2a.cmml" xref="A1.SS3.SSS0.Px4.p1.4.m4.1.1.2"><mtext id="A1.SS3.SSS0.Px4.p1.4.m4.1.1.2.cmml" xref="A1.SS3.SSS0.Px4.p1.4.m4.1.1.2">n</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS3.SSS0.Px4.p1.4.m4.1c">\boldsymbol{\hat{\text{n}}}</annotation><annotation encoding="application/x-llamapun" id="A1.SS3.SSS0.Px4.p1.4.m4.1d">overbold_^ start_ARG n end_ARG</annotation></semantics></math> are the predicted normals.
The regularization of the view direction weights is defined as
<math alttext="\mathcal{L}_{d}=\lVert\theta_{v}\rVert^{2}" class="ltx_Math" display="inline" id="A1.SS3.SSS0.Px4.p1.5.m5.1"><semantics id="A1.SS3.SSS0.Px4.p1.5.m5.1a"><mrow id="A1.SS3.SSS0.Px4.p1.5.m5.1.1" xref="A1.SS3.SSS0.Px4.p1.5.m5.1.1.cmml"><msub id="A1.SS3.SSS0.Px4.p1.5.m5.1.1.3" xref="A1.SS3.SSS0.Px4.p1.5.m5.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="A1.SS3.SSS0.Px4.p1.5.m5.1.1.3.2" xref="A1.SS3.SSS0.Px4.p1.5.m5.1.1.3.2.cmml">ℒ</mi><mi id="A1.SS3.SSS0.Px4.p1.5.m5.1.1.3.3" xref="A1.SS3.SSS0.Px4.p1.5.m5.1.1.3.3.cmml">d</mi></msub><mo id="A1.SS3.SSS0.Px4.p1.5.m5.1.1.2" rspace="0.1389em" xref="A1.SS3.SSS0.Px4.p1.5.m5.1.1.2.cmml">=</mo><msup id="A1.SS3.SSS0.Px4.p1.5.m5.1.1.1" xref="A1.SS3.SSS0.Px4.p1.5.m5.1.1.1.cmml"><mrow id="A1.SS3.SSS0.Px4.p1.5.m5.1.1.1.1.1" xref="A1.SS3.SSS0.Px4.p1.5.m5.1.1.1.1.2.cmml"><mo fence="true" id="A1.SS3.SSS0.Px4.p1.5.m5.1.1.1.1.1.2" lspace="0.1389em" rspace="0em" xref="A1.SS3.SSS0.Px4.p1.5.m5.1.1.1.1.2.1.cmml">∥</mo><msub id="A1.SS3.SSS0.Px4.p1.5.m5.1.1.1.1.1.1" xref="A1.SS3.SSS0.Px4.p1.5.m5.1.1.1.1.1.1.cmml"><mi id="A1.SS3.SSS0.Px4.p1.5.m5.1.1.1.1.1.1.2" xref="A1.SS3.SSS0.Px4.p1.5.m5.1.1.1.1.1.1.2.cmml">θ</mi><mi id="A1.SS3.SSS0.Px4.p1.5.m5.1.1.1.1.1.1.3" xref="A1.SS3.SSS0.Px4.p1.5.m5.1.1.1.1.1.1.3.cmml">v</mi></msub><mo fence="true" id="A1.SS3.SSS0.Px4.p1.5.m5.1.1.1.1.1.3" lspace="0em" xref="A1.SS3.SSS0.Px4.p1.5.m5.1.1.1.1.2.1.cmml">∥</mo></mrow><mn id="A1.SS3.SSS0.Px4.p1.5.m5.1.1.1.3" xref="A1.SS3.SSS0.Px4.p1.5.m5.1.1.1.3.cmml">2</mn></msup></mrow><annotation-xml encoding="MathML-Content" id="A1.SS3.SSS0.Px4.p1.5.m5.1b"><apply id="A1.SS3.SSS0.Px4.p1.5.m5.1.1.cmml" xref="A1.SS3.SSS0.Px4.p1.5.m5.1.1"><eq id="A1.SS3.SSS0.Px4.p1.5.m5.1.1.2.cmml" xref="A1.SS3.SSS0.Px4.p1.5.m5.1.1.2"></eq><apply id="A1.SS3.SSS0.Px4.p1.5.m5.1.1.3.cmml" xref="A1.SS3.SSS0.Px4.p1.5.m5.1.1.3"><csymbol cd="ambiguous" id="A1.SS3.SSS0.Px4.p1.5.m5.1.1.3.1.cmml" xref="A1.SS3.SSS0.Px4.p1.5.m5.1.1.3">subscript</csymbol><ci id="A1.SS3.SSS0.Px4.p1.5.m5.1.1.3.2.cmml" xref="A1.SS3.SSS0.Px4.p1.5.m5.1.1.3.2">ℒ</ci><ci id="A1.SS3.SSS0.Px4.p1.5.m5.1.1.3.3.cmml" xref="A1.SS3.SSS0.Px4.p1.5.m5.1.1.3.3">𝑑</ci></apply><apply id="A1.SS3.SSS0.Px4.p1.5.m5.1.1.1.cmml" xref="A1.SS3.SSS0.Px4.p1.5.m5.1.1.1"><csymbol cd="ambiguous" id="A1.SS3.SSS0.Px4.p1.5.m5.1.1.1.2.cmml" xref="A1.SS3.SSS0.Px4.p1.5.m5.1.1.1">superscript</csymbol><apply id="A1.SS3.SSS0.Px4.p1.5.m5.1.1.1.1.2.cmml" xref="A1.SS3.SSS0.Px4.p1.5.m5.1.1.1.1.1"><csymbol cd="latexml" id="A1.SS3.SSS0.Px4.p1.5.m5.1.1.1.1.2.1.cmml" xref="A1.SS3.SSS0.Px4.p1.5.m5.1.1.1.1.1.2">delimited-∥∥</csymbol><apply id="A1.SS3.SSS0.Px4.p1.5.m5.1.1.1.1.1.1.cmml" xref="A1.SS3.SSS0.Px4.p1.5.m5.1.1.1.1.1.1"><csymbol cd="ambiguous" id="A1.SS3.SSS0.Px4.p1.5.m5.1.1.1.1.1.1.1.cmml" xref="A1.SS3.SSS0.Px4.p1.5.m5.1.1.1.1.1.1">subscript</csymbol><ci id="A1.SS3.SSS0.Px4.p1.5.m5.1.1.1.1.1.1.2.cmml" xref="A1.SS3.SSS0.Px4.p1.5.m5.1.1.1.1.1.1.2">𝜃</ci><ci id="A1.SS3.SSS0.Px4.p1.5.m5.1.1.1.1.1.1.3.cmml" xref="A1.SS3.SSS0.Px4.p1.5.m5.1.1.1.1.1.1.3">𝑣</ci></apply></apply><cn id="A1.SS3.SSS0.Px4.p1.5.m5.1.1.1.3.cmml" type="integer" xref="A1.SS3.SSS0.Px4.p1.5.m5.1.1.1.3">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS3.SSS0.Px4.p1.5.m5.1c">\mathcal{L}_{d}=\lVert\theta_{v}\rVert^{2}</annotation><annotation encoding="application/x-llamapun" id="A1.SS3.SSS0.Px4.p1.5.m5.1d">caligraphic_L start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT = ∥ italic_θ start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT ∥ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math>, where <math alttext="\theta_{d}" class="ltx_Math" display="inline" id="A1.SS3.SSS0.Px4.p1.6.m6.1"><semantics id="A1.SS3.SSS0.Px4.p1.6.m6.1a"><msub id="A1.SS3.SSS0.Px4.p1.6.m6.1.1" xref="A1.SS3.SSS0.Px4.p1.6.m6.1.1.cmml"><mi id="A1.SS3.SSS0.Px4.p1.6.m6.1.1.2" xref="A1.SS3.SSS0.Px4.p1.6.m6.1.1.2.cmml">θ</mi><mi id="A1.SS3.SSS0.Px4.p1.6.m6.1.1.3" xref="A1.SS3.SSS0.Px4.p1.6.m6.1.1.3.cmml">d</mi></msub><annotation-xml encoding="MathML-Content" id="A1.SS3.SSS0.Px4.p1.6.m6.1b"><apply id="A1.SS3.SSS0.Px4.p1.6.m6.1.1.cmml" xref="A1.SS3.SSS0.Px4.p1.6.m6.1.1"><csymbol cd="ambiguous" id="A1.SS3.SSS0.Px4.p1.6.m6.1.1.1.cmml" xref="A1.SS3.SSS0.Px4.p1.6.m6.1.1">subscript</csymbol><ci id="A1.SS3.SSS0.Px4.p1.6.m6.1.1.2.cmml" xref="A1.SS3.SSS0.Px4.p1.6.m6.1.1.2">𝜃</ci><ci id="A1.SS3.SSS0.Px4.p1.6.m6.1.1.3.cmml" xref="A1.SS3.SSS0.Px4.p1.6.m6.1.1.3">𝑑</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS3.SSS0.Px4.p1.6.m6.1c">\theta_{d}</annotation><annotation encoding="application/x-llamapun" id="A1.SS3.SSS0.Px4.p1.6.m6.1d">italic_θ start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT</annotation></semantics></math> are the model parameters that process the positionally encoded view directions. The distortion loss is defined as
<math alttext="\mathcal{L}_{\text{dist}}=\sum_{i,j}w_{i}w_{j}\lVert\frac{s_{i}+s_{i+1}}{2}-%
\frac{s_{j}+s_{j+1}}{2}\rVert+\frac{1}{3}\sum_{i}w_{i}^{2}(s_{i+1}-s_{i})" class="ltx_Math" display="inline" id="A1.SS3.SSS0.Px4.p1.7.m7.4"><semantics id="A1.SS3.SSS0.Px4.p1.7.m7.4a"><mrow id="A1.SS3.SSS0.Px4.p1.7.m7.4.4" xref="A1.SS3.SSS0.Px4.p1.7.m7.4.4.cmml"><msub id="A1.SS3.SSS0.Px4.p1.7.m7.4.4.4" xref="A1.SS3.SSS0.Px4.p1.7.m7.4.4.4.cmml"><mi class="ltx_font_mathcaligraphic" id="A1.SS3.SSS0.Px4.p1.7.m7.4.4.4.2" xref="A1.SS3.SSS0.Px4.p1.7.m7.4.4.4.2.cmml">ℒ</mi><mtext id="A1.SS3.SSS0.Px4.p1.7.m7.4.4.4.3" xref="A1.SS3.SSS0.Px4.p1.7.m7.4.4.4.3a.cmml">dist</mtext></msub><mo id="A1.SS3.SSS0.Px4.p1.7.m7.4.4.3" rspace="0.111em" xref="A1.SS3.SSS0.Px4.p1.7.m7.4.4.3.cmml">=</mo><mrow id="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2" xref="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.cmml"><mrow id="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1" xref="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.cmml"><msub id="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.2" xref="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.2.cmml"><mo id="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.2.2" xref="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.2.2.cmml">∑</mo><mrow id="A1.SS3.SSS0.Px4.p1.7.m7.2.2.2.4" xref="A1.SS3.SSS0.Px4.p1.7.m7.2.2.2.3.cmml"><mi id="A1.SS3.SSS0.Px4.p1.7.m7.1.1.1.1" xref="A1.SS3.SSS0.Px4.p1.7.m7.1.1.1.1.cmml">i</mi><mo id="A1.SS3.SSS0.Px4.p1.7.m7.2.2.2.4.1" xref="A1.SS3.SSS0.Px4.p1.7.m7.2.2.2.3.cmml">,</mo><mi id="A1.SS3.SSS0.Px4.p1.7.m7.2.2.2.2" xref="A1.SS3.SSS0.Px4.p1.7.m7.2.2.2.2.cmml">j</mi></mrow></msub><mrow id="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1" xref="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.cmml"><msub id="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.3" xref="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.3.cmml"><mi id="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.3.2" xref="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.3.2.cmml">w</mi><mi id="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.3.3" xref="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.3.3.cmml">i</mi></msub><mo id="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.2" xref="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.2.cmml">⁢</mo><msub id="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.4" xref="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.4.cmml"><mi id="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.4.2" xref="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.4.2.cmml">w</mi><mi id="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.4.3" xref="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.4.3.cmml">j</mi></msub><mo id="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.2a" lspace="0em" xref="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.2.cmml">⁢</mo><mrow id="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1" xref="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.2.cmml"><mo fence="true" id="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.2" rspace="0em" xref="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.2.1.cmml">∥</mo><mrow id="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1" xref="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.cmml"><mfrac id="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.2" xref="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.2.cmml"><mrow id="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.2.2" xref="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.2.2.cmml"><msub id="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.2.2.2" xref="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.2.2.2.cmml"><mi id="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.2.2.2.2" xref="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.2.2.2.2.cmml">s</mi><mi id="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.2.2.2.3" xref="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.2.2.2.3.cmml">i</mi></msub><mo id="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.2.2.1" xref="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.2.2.1.cmml">+</mo><msub id="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.2.2.3" xref="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.2.2.3.cmml"><mi id="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.2.2.3.2" xref="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.2.2.3.2.cmml">s</mi><mrow id="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.2.2.3.3" xref="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.2.2.3.3.cmml"><mi id="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.2.2.3.3.2" xref="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.2.2.3.3.2.cmml">i</mi><mo id="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.2.2.3.3.1" xref="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.2.2.3.3.1.cmml">+</mo><mn id="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.2.2.3.3.3" xref="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.2.2.3.3.3.cmml">1</mn></mrow></msub></mrow><mn id="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.2.3" xref="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.2.3.cmml">2</mn></mfrac><mo id="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.1" xref="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.1.cmml">−</mo><mfrac id="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.3" xref="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.3.cmml"><mrow id="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.3.2" xref="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.3.2.cmml"><msub id="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.3.2.2" xref="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.3.2.2.cmml"><mi id="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.3.2.2.2" xref="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.3.2.2.2.cmml">s</mi><mi id="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.3.2.2.3" xref="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.3.2.2.3.cmml">j</mi></msub><mo id="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.3.2.1" xref="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.3.2.1.cmml">+</mo><msub id="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.3.2.3" xref="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.3.2.3.cmml"><mi id="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.3.2.3.2" xref="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.3.2.3.2.cmml">s</mi><mrow id="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.3.2.3.3" xref="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.3.2.3.3.cmml"><mi id="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.3.2.3.3.2" xref="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.3.2.3.3.2.cmml">j</mi><mo id="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.3.2.3.3.1" xref="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.3.2.3.3.1.cmml">+</mo><mn id="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.3.2.3.3.3" xref="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.3.2.3.3.3.cmml">1</mn></mrow></msub></mrow><mn id="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.3.3" xref="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.3.3.cmml">2</mn></mfrac></mrow><mo fence="true" id="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.3" lspace="0em" rspace="0em" xref="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.2.1.cmml">∥</mo></mrow></mrow></mrow><mo id="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.3" xref="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.3.cmml">+</mo><mrow id="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2" xref="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.cmml"><mfrac id="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.3" xref="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.3.cmml"><mn id="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.3.2" xref="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.3.2.cmml">1</mn><mn id="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.3.3" xref="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.3.3.cmml">3</mn></mfrac><mo id="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.2" xref="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.2.cmml">⁢</mo><mrow id="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.1" xref="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.1.cmml"><msub id="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.1.2" xref="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.1.2.cmml"><mo id="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.1.2.2" xref="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.1.2.2.cmml">∑</mo><mi id="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.1.2.3" xref="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.1.2.3.cmml">i</mi></msub><mrow id="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.1.1" xref="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.1.1.cmml"><msubsup id="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.1.1.3" xref="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.1.1.3.cmml"><mi id="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.1.1.3.2.2" xref="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.1.1.3.2.2.cmml">w</mi><mi id="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.1.1.3.2.3" xref="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.1.1.3.2.3.cmml">i</mi><mn id="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.1.1.3.3" xref="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.1.1.3.3.cmml">2</mn></msubsup><mo id="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.1.1.2" xref="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.1.1.2.cmml">⁢</mo><mrow id="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.1.1.1.1" xref="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.1.1.1.1.1.cmml"><mo id="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.1.1.1.1.2" stretchy="false" xref="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.1.1.1.1.1.cmml">(</mo><mrow id="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.1.1.1.1.1" xref="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.1.1.1.1.1.cmml"><msub id="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.1.1.1.1.1.2" xref="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.1.1.1.1.1.2.cmml"><mi id="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.1.1.1.1.1.2.2" xref="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.1.1.1.1.1.2.2.cmml">s</mi><mrow id="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.1.1.1.1.1.2.3" xref="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.1.1.1.1.1.2.3.cmml"><mi id="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.1.1.1.1.1.2.3.2" xref="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.1.1.1.1.1.2.3.2.cmml">i</mi><mo id="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.1.1.1.1.1.2.3.1" xref="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.1.1.1.1.1.2.3.1.cmml">+</mo><mn id="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.1.1.1.1.1.2.3.3" xref="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.1.1.1.1.1.2.3.3.cmml">1</mn></mrow></msub><mo id="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.1.1.1.1.1.1" xref="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.1.1.1.1.1.1.cmml">−</mo><msub id="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.1.1.1.1.1.3" xref="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.1.1.1.1.1.3.cmml"><mi id="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.1.1.1.1.1.3.2" xref="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.1.1.1.1.1.3.2.cmml">s</mi><mi id="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.1.1.1.1.1.3.3" xref="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.1.1.1.1.1.3.3.cmml">i</mi></msub></mrow><mo id="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.1.1.1.1.3" stretchy="false" xref="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="A1.SS3.SSS0.Px4.p1.7.m7.4b"><apply id="A1.SS3.SSS0.Px4.p1.7.m7.4.4.cmml" xref="A1.SS3.SSS0.Px4.p1.7.m7.4.4"><eq id="A1.SS3.SSS0.Px4.p1.7.m7.4.4.3.cmml" xref="A1.SS3.SSS0.Px4.p1.7.m7.4.4.3"></eq><apply id="A1.SS3.SSS0.Px4.p1.7.m7.4.4.4.cmml" xref="A1.SS3.SSS0.Px4.p1.7.m7.4.4.4"><csymbol cd="ambiguous" id="A1.SS3.SSS0.Px4.p1.7.m7.4.4.4.1.cmml" xref="A1.SS3.SSS0.Px4.p1.7.m7.4.4.4">subscript</csymbol><ci id="A1.SS3.SSS0.Px4.p1.7.m7.4.4.4.2.cmml" xref="A1.SS3.SSS0.Px4.p1.7.m7.4.4.4.2">ℒ</ci><ci id="A1.SS3.SSS0.Px4.p1.7.m7.4.4.4.3a.cmml" xref="A1.SS3.SSS0.Px4.p1.7.m7.4.4.4.3"><mtext id="A1.SS3.SSS0.Px4.p1.7.m7.4.4.4.3.cmml" mathsize="70%" xref="A1.SS3.SSS0.Px4.p1.7.m7.4.4.4.3">dist</mtext></ci></apply><apply id="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.cmml" xref="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2"><plus id="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.3.cmml" xref="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.3"></plus><apply id="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.cmml" xref="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1"><apply id="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.2.cmml" xref="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.2"><csymbol cd="ambiguous" id="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.2.1.cmml" xref="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.2">subscript</csymbol><sum id="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.2.2.cmml" xref="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.2.2"></sum><list id="A1.SS3.SSS0.Px4.p1.7.m7.2.2.2.3.cmml" xref="A1.SS3.SSS0.Px4.p1.7.m7.2.2.2.4"><ci id="A1.SS3.SSS0.Px4.p1.7.m7.1.1.1.1.cmml" xref="A1.SS3.SSS0.Px4.p1.7.m7.1.1.1.1">𝑖</ci><ci id="A1.SS3.SSS0.Px4.p1.7.m7.2.2.2.2.cmml" xref="A1.SS3.SSS0.Px4.p1.7.m7.2.2.2.2">𝑗</ci></list></apply><apply id="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.cmml" xref="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1"><times id="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.2.cmml" xref="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.2"></times><apply id="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.3.cmml" xref="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.3"><csymbol cd="ambiguous" id="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.3.1.cmml" xref="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.3">subscript</csymbol><ci id="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.3.2.cmml" xref="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.3.2">𝑤</ci><ci id="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.3.3.cmml" xref="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.3.3">𝑖</ci></apply><apply id="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.4.cmml" xref="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.4"><csymbol cd="ambiguous" id="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.4.1.cmml" xref="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.4">subscript</csymbol><ci id="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.4.2.cmml" xref="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.4.2">𝑤</ci><ci id="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.4.3.cmml" xref="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.4.3">𝑗</ci></apply><apply id="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.2.cmml" xref="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1"><csymbol cd="latexml" id="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.2.1.cmml" xref="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.2">delimited-∥∥</csymbol><apply id="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.cmml" xref="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1"><minus id="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.1.cmml" xref="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.1"></minus><apply id="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.2.cmml" xref="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.2"><divide id="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.2.1.cmml" xref="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.2"></divide><apply id="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.2.2.cmml" xref="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.2.2"><plus id="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.2.2.1.cmml" xref="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.2.2.1"></plus><apply id="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.2.2.2.cmml" xref="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.2.2.2.1.cmml" xref="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.2.2.2">subscript</csymbol><ci id="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.2.2.2.2.cmml" xref="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.2.2.2.2">𝑠</ci><ci id="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.2.2.2.3.cmml" xref="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.2.2.2.3">𝑖</ci></apply><apply id="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.2.2.3.cmml" xref="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.2.2.3"><csymbol cd="ambiguous" id="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.2.2.3.1.cmml" xref="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.2.2.3">subscript</csymbol><ci id="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.2.2.3.2.cmml" xref="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.2.2.3.2">𝑠</ci><apply id="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.2.2.3.3.cmml" xref="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.2.2.3.3"><plus id="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.2.2.3.3.1.cmml" xref="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.2.2.3.3.1"></plus><ci id="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.2.2.3.3.2.cmml" xref="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.2.2.3.3.2">𝑖</ci><cn id="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.2.2.3.3.3.cmml" type="integer" xref="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.2.2.3.3.3">1</cn></apply></apply></apply><cn id="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.2.3.cmml" type="integer" xref="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.2.3">2</cn></apply><apply id="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.3.cmml" xref="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.3"><divide id="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.3.1.cmml" xref="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.3"></divide><apply id="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.3.2.cmml" xref="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.3.2"><plus id="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.3.2.1.cmml" xref="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.3.2.1"></plus><apply id="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.3.2.2.cmml" xref="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.3.2.2"><csymbol cd="ambiguous" id="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.3.2.2.1.cmml" xref="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.3.2.2">subscript</csymbol><ci id="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.3.2.2.2.cmml" xref="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.3.2.2.2">𝑠</ci><ci id="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.3.2.2.3.cmml" xref="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.3.2.2.3">𝑗</ci></apply><apply id="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.3.2.3.cmml" xref="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.3.2.3"><csymbol cd="ambiguous" id="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.3.2.3.1.cmml" xref="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.3.2.3">subscript</csymbol><ci id="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.3.2.3.2.cmml" xref="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.3.2.3.2">𝑠</ci><apply id="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.3.2.3.3.cmml" xref="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.3.2.3.3"><plus id="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.3.2.3.3.1.cmml" xref="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.3.2.3.3.1"></plus><ci id="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.3.2.3.3.2.cmml" xref="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.3.2.3.3.2">𝑗</ci><cn id="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.3.2.3.3.3.cmml" type="integer" xref="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.3.2.3.3.3">1</cn></apply></apply></apply><cn id="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.3.3.cmml" type="integer" xref="A1.SS3.SSS0.Px4.p1.7.m7.3.3.1.1.1.1.1.1.3.3">2</cn></apply></apply></apply></apply></apply><apply id="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.cmml" xref="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2"><times id="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.2.cmml" xref="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.2"></times><apply id="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.3.cmml" xref="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.3"><divide id="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.3.1.cmml" xref="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.3"></divide><cn id="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.3.2.cmml" type="integer" xref="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.3.2">1</cn><cn id="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.3.3.cmml" type="integer" xref="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.3.3">3</cn></apply><apply id="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.1.cmml" xref="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.1"><apply id="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.1.2.cmml" xref="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.1.2"><csymbol cd="ambiguous" id="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.1.2.1.cmml" xref="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.1.2">subscript</csymbol><sum id="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.1.2.2.cmml" xref="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.1.2.2"></sum><ci id="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.1.2.3.cmml" xref="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.1.2.3">𝑖</ci></apply><apply id="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.1.1.cmml" xref="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.1.1"><times id="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.1.1.2.cmml" xref="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.1.1.2"></times><apply id="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.1.1.3.cmml" xref="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.1.1.3"><csymbol cd="ambiguous" id="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.1.1.3.1.cmml" xref="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.1.1.3">superscript</csymbol><apply id="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.1.1.3.2.cmml" xref="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.1.1.3"><csymbol cd="ambiguous" id="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.1.1.3.2.1.cmml" xref="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.1.1.3">subscript</csymbol><ci id="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.1.1.3.2.2.cmml" xref="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.1.1.3.2.2">𝑤</ci><ci id="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.1.1.3.2.3.cmml" xref="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.1.1.3.2.3">𝑖</ci></apply><cn id="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.1.1.3.3.cmml" type="integer" xref="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.1.1.3.3">2</cn></apply><apply id="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.1.1.1.1.1.cmml" xref="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.1.1.1.1"><minus id="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.1.1.1.1.1.1.cmml" xref="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.1.1.1.1.1.1"></minus><apply id="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.1.1.1.1.1.2.cmml" xref="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.1.1.1.1.1.2"><csymbol cd="ambiguous" id="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.1.1.1.1.1.2.1.cmml" xref="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.1.1.1.1.1.2">subscript</csymbol><ci id="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.1.1.1.1.1.2.2.cmml" xref="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.1.1.1.1.1.2.2">𝑠</ci><apply id="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.1.1.1.1.1.2.3.cmml" xref="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.1.1.1.1.1.2.3"><plus id="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.1.1.1.1.1.2.3.1.cmml" xref="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.1.1.1.1.1.2.3.1"></plus><ci id="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.1.1.1.1.1.2.3.2.cmml" xref="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.1.1.1.1.1.2.3.2">𝑖</ci><cn id="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.1.1.1.1.1.2.3.3.cmml" type="integer" xref="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.1.1.1.1.1.2.3.3">1</cn></apply></apply><apply id="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.1.1.1.1.1.3.cmml" xref="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.1.1.1.1.1.3"><csymbol cd="ambiguous" id="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.1.1.1.1.1.3.1.cmml" xref="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.1.1.1.1.1.3">subscript</csymbol><ci id="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.1.1.1.1.1.3.2.cmml" xref="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.1.1.1.1.1.3.2">𝑠</ci><ci id="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.1.1.1.1.1.3.3.cmml" xref="A1.SS3.SSS0.Px4.p1.7.m7.4.4.2.2.1.1.1.1.1.3.3">𝑖</ci></apply></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS3.SSS0.Px4.p1.7.m7.4c">\mathcal{L}_{\text{dist}}=\sum_{i,j}w_{i}w_{j}\lVert\frac{s_{i}+s_{i+1}}{2}-%
\frac{s_{j}+s_{j+1}}{2}\rVert+\frac{1}{3}\sum_{i}w_{i}^{2}(s_{i+1}-s_{i})</annotation><annotation encoding="application/x-llamapun" id="A1.SS3.SSS0.Px4.p1.7.m7.4d">caligraphic_L start_POSTSUBSCRIPT dist end_POSTSUBSCRIPT = ∑ start_POSTSUBSCRIPT italic_i , italic_j end_POSTSUBSCRIPT italic_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_w start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ∥ divide start_ARG italic_s start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT + italic_s start_POSTSUBSCRIPT italic_i + 1 end_POSTSUBSCRIPT end_ARG start_ARG 2 end_ARG - divide start_ARG italic_s start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT + italic_s start_POSTSUBSCRIPT italic_j + 1 end_POSTSUBSCRIPT end_ARG start_ARG 2 end_ARG ∥ + divide start_ARG 1 end_ARG start_ARG 3 end_ARG ∑ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ( italic_s start_POSTSUBSCRIPT italic_i + 1 end_POSTSUBSCRIPT - italic_s start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )</annotation></semantics></math>, where <math alttext="s" class="ltx_Math" display="inline" id="A1.SS3.SSS0.Px4.p1.8.m8.1"><semantics id="A1.SS3.SSS0.Px4.p1.8.m8.1a"><mi id="A1.SS3.SSS0.Px4.p1.8.m8.1.1" xref="A1.SS3.SSS0.Px4.p1.8.m8.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="A1.SS3.SSS0.Px4.p1.8.m8.1b"><ci id="A1.SS3.SSS0.Px4.p1.8.m8.1.1.cmml" xref="A1.SS3.SSS0.Px4.p1.8.m8.1.1">𝑠</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS3.SSS0.Px4.p1.8.m8.1c">s</annotation><annotation encoding="application/x-llamapun" id="A1.SS3.SSS0.Px4.p1.8.m8.1d">italic_s</annotation></semantics></math> is the normalized ray distance. For details about the LPIPS loss <math alttext="\mathcal{L}_{\text{LPIPS}}" class="ltx_Math" display="inline" id="A1.SS3.SSS0.Px4.p1.9.m9.1"><semantics id="A1.SS3.SSS0.Px4.p1.9.m9.1a"><msub id="A1.SS3.SSS0.Px4.p1.9.m9.1.1" xref="A1.SS3.SSS0.Px4.p1.9.m9.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="A1.SS3.SSS0.Px4.p1.9.m9.1.1.2" xref="A1.SS3.SSS0.Px4.p1.9.m9.1.1.2.cmml">ℒ</mi><mtext id="A1.SS3.SSS0.Px4.p1.9.m9.1.1.3" xref="A1.SS3.SSS0.Px4.p1.9.m9.1.1.3a.cmml">LPIPS</mtext></msub><annotation-xml encoding="MathML-Content" id="A1.SS3.SSS0.Px4.p1.9.m9.1b"><apply id="A1.SS3.SSS0.Px4.p1.9.m9.1.1.cmml" xref="A1.SS3.SSS0.Px4.p1.9.m9.1.1"><csymbol cd="ambiguous" id="A1.SS3.SSS0.Px4.p1.9.m9.1.1.1.cmml" xref="A1.SS3.SSS0.Px4.p1.9.m9.1.1">subscript</csymbol><ci id="A1.SS3.SSS0.Px4.p1.9.m9.1.1.2.cmml" xref="A1.SS3.SSS0.Px4.p1.9.m9.1.1.2">ℒ</ci><ci id="A1.SS3.SSS0.Px4.p1.9.m9.1.1.3a.cmml" xref="A1.SS3.SSS0.Px4.p1.9.m9.1.1.3"><mtext id="A1.SS3.SSS0.Px4.p1.9.m9.1.1.3.cmml" mathsize="70%" xref="A1.SS3.SSS0.Px4.p1.9.m9.1.1.3">LPIPS</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS3.SSS0.Px4.p1.9.m9.1c">\mathcal{L}_{\text{LPIPS}}</annotation><annotation encoding="application/x-llamapun" id="A1.SS3.SSS0.Px4.p1.9.m9.1d">caligraphic_L start_POSTSUBSCRIPT LPIPS end_POSTSUBSCRIPT</annotation></semantics></math>, please refer to Eq. 1 in <cite class="ltx_cite ltx_citemacro_citep">(Zhang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib84" title="">2018</a>)</cite>.
We find that sampling individual random rays during model fitting yields better results than sampling patches. Hence, we only employ the perceptual loss <math alttext="\mathcal{L}_{\text{LPIPS}}" class="ltx_Math" display="inline" id="A1.SS3.SSS0.Px4.p1.10.m10.1"><semantics id="A1.SS3.SSS0.Px4.p1.10.m10.1a"><msub id="A1.SS3.SSS0.Px4.p1.10.m10.1.1" xref="A1.SS3.SSS0.Px4.p1.10.m10.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="A1.SS3.SSS0.Px4.p1.10.m10.1.1.2" xref="A1.SS3.SSS0.Px4.p1.10.m10.1.1.2.cmml">ℒ</mi><mtext id="A1.SS3.SSS0.Px4.p1.10.m10.1.1.3" xref="A1.SS3.SSS0.Px4.p1.10.m10.1.1.3a.cmml">LPIPS</mtext></msub><annotation-xml encoding="MathML-Content" id="A1.SS3.SSS0.Px4.p1.10.m10.1b"><apply id="A1.SS3.SSS0.Px4.p1.10.m10.1.1.cmml" xref="A1.SS3.SSS0.Px4.p1.10.m10.1.1"><csymbol cd="ambiguous" id="A1.SS3.SSS0.Px4.p1.10.m10.1.1.1.cmml" xref="A1.SS3.SSS0.Px4.p1.10.m10.1.1">subscript</csymbol><ci id="A1.SS3.SSS0.Px4.p1.10.m10.1.1.2.cmml" xref="A1.SS3.SSS0.Px4.p1.10.m10.1.1.2">ℒ</ci><ci id="A1.SS3.SSS0.Px4.p1.10.m10.1.1.3a.cmml" xref="A1.SS3.SSS0.Px4.p1.10.m10.1.1.3"><mtext id="A1.SS3.SSS0.Px4.p1.10.m10.1.1.3.cmml" mathsize="70%" xref="A1.SS3.SSS0.Px4.p1.10.m10.1.1.3">LPIPS</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS3.SSS0.Px4.p1.10.m10.1c">\mathcal{L}_{\text{LPIPS}}</annotation><annotation encoding="application/x-llamapun" id="A1.SS3.SSS0.Px4.p1.10.m10.1d">caligraphic_L start_POSTSUBSCRIPT LPIPS end_POSTSUBSCRIPT</annotation></semantics></math> during warm-up but not during fine-tuning.</p>
</div>
</section>
<section class="ltx_paragraph" id="A1.SS3.SSS0.Px5">
<h5 class="ltx_title ltx_title_paragraph">Rendering Time</h5>
<div class="ltx_para" id="A1.SS3.SSS0.Px5.p1">
<p class="ltx_p" id="A1.SS3.SSS0.Px5.p1.1">We render on 4 TPUs, where rendering takes about 20.5 seconds per <math alttext="1024\times 1024" class="ltx_Math" display="inline" id="A1.SS3.SSS0.Px5.p1.1.m1.1"><semantics id="A1.SS3.SSS0.Px5.p1.1.m1.1a"><mrow id="A1.SS3.SSS0.Px5.p1.1.m1.1.1" xref="A1.SS3.SSS0.Px5.p1.1.m1.1.1.cmml"><mn id="A1.SS3.SSS0.Px5.p1.1.m1.1.1.2" xref="A1.SS3.SSS0.Px5.p1.1.m1.1.1.2.cmml">1024</mn><mo id="A1.SS3.SSS0.Px5.p1.1.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="A1.SS3.SSS0.Px5.p1.1.m1.1.1.1.cmml">×</mo><mn id="A1.SS3.SSS0.Px5.p1.1.m1.1.1.3" xref="A1.SS3.SSS0.Px5.p1.1.m1.1.1.3.cmml">1024</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.SS3.SSS0.Px5.p1.1.m1.1b"><apply id="A1.SS3.SSS0.Px5.p1.1.m1.1.1.cmml" xref="A1.SS3.SSS0.Px5.p1.1.m1.1.1"><times id="A1.SS3.SSS0.Px5.p1.1.m1.1.1.1.cmml" xref="A1.SS3.SSS0.Px5.p1.1.m1.1.1.1"></times><cn id="A1.SS3.SSS0.Px5.p1.1.m1.1.1.2.cmml" type="integer" xref="A1.SS3.SSS0.Px5.p1.1.m1.1.1.2">1024</cn><cn id="A1.SS3.SSS0.Px5.p1.1.m1.1.1.3.cmml" type="integer" xref="A1.SS3.SSS0.Px5.p1.1.m1.1.1.3">1024</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS3.SSS0.Px5.p1.1.m1.1c">1024\times 1024</annotation><annotation encoding="application/x-llamapun" id="A1.SS3.SSS0.Px5.p1.1.m1.1d">1024 × 1024</annotation></semantics></math> frame.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="A1.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.4. </span>Experimental Details</h3>
<section class="ltx_subsubsection" id="A1.SS4.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">A.4.1. </span>Multiface Dataset</h4>
<div class="ltx_para" id="A1.SS4.SSS1.p1">
<p class="ltx_p" id="A1.SS4.SSS1.p1.1">We quantitatively compare and ablate on a subset of the Multiface dataset <cite class="ltx_cite ltx_citemacro_citep">(Wuu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib75" title="">2022</a>)</cite>. Metrics are computed on three expressions from three identities—nine scenes in total. For each scene, we select three views for training: One frontal and two side views. For evaluation, we compute metrics on all holdout views where the cameras are not located on the back of the head. Please see Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#A1.F11" title="Figure 11 ‣ A.4.1. Multiface Dataset ‣ A.4. Experimental Details ‣ Appendix A Supplementary ‣ Cafca: High-quality Novel View Synthesis of Expressive Faces from Casual Few-shot Captures"><span class="ltx_text ltx_ref_tag">11</span></a> for a visualization.</p>
</div>
<figure class="ltx_figure" id="A1.F11"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="448" id="A1.F11.g1" src="extracted/5891401/figures/dataset/multiface_cameras.png" width="419"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 11. </span>Multiface cameras used for evaluation are highlighted in red. Blue cameras are discarded. The face (green) is looking along the z axis.</figcaption>
</figure>
</section>
<section class="ltx_subsubsection" id="A1.SS4.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">A.4.2. </span>Preface Dataset</h4>
<div class="ltx_para" id="A1.SS4.SSS2.p1">
<p class="ltx_p" id="A1.SS4.SSS2.p1.1">Our ablation study that trains on real data uses the Preface dataset <cite class="ltx_cite ltx_citemacro_citep">(Buehler et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib9" title="">2023</a>)</cite>. It contains multi-view captures of 1,500 identities. Each identity is captured for 13 facial expressions and from 12 views. Please see <cite class="ltx_cite ltx_citemacro_citep">(Buehler et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib9" title="">2023</a>)</cite> for more details and a breakdown of demographics.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="A1.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.5. </span>Supplementary Results</h3>
<section class="ltx_subsubsection" id="A1.SS5.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">A.5.1. </span>In-the-wild Results</h4>
<div class="ltx_para" id="A1.SS5.SSS1.p1">
<p class="ltx_p" id="A1.SS5.SSS1.p1.1">We provide extensive results for high-resolution in-the-wild captures on the supplementary HTML page and video.</p>
</div>
</section>
<section class="ltx_subsubsection" id="A1.SS5.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">A.5.2. </span>Supplementary Ablations and Comparisons</h4>
<figure class="ltx_table" id="A1.T3">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="A1.T3.3.3">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A1.T3.3.3.3">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r" id="A1.T3.3.3.3.4"><span class="ltx_text ltx_font_bold" id="A1.T3.3.3.3.4.1" style="font-size:90%;"># Views</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="A1.T3.1.1.1.1">
<span class="ltx_text ltx_font_bold" id="A1.T3.1.1.1.1.1" style="font-size:90%;">PSNR</span><span class="ltx_text" id="A1.T3.1.1.1.1.2" style="font-size:90%;"> </span><math alttext="\uparrow" class="ltx_Math" display="inline" id="A1.T3.1.1.1.1.m1.1"><semantics id="A1.T3.1.1.1.1.m1.1a"><mo id="A1.T3.1.1.1.1.m1.1.1" mathsize="90%" stretchy="false" xref="A1.T3.1.1.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="A1.T3.1.1.1.1.m1.1b"><ci id="A1.T3.1.1.1.1.m1.1.1.cmml" xref="A1.T3.1.1.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.1.1.1.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="A1.T3.1.1.1.1.m1.1d">↑</annotation></semantics></math>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="A1.T3.2.2.2.2">
<span class="ltx_text ltx_font_bold" id="A1.T3.2.2.2.2.1" style="font-size:90%;">SSIM</span><span class="ltx_text" id="A1.T3.2.2.2.2.2" style="font-size:90%;"> </span><math alttext="\uparrow" class="ltx_Math" display="inline" id="A1.T3.2.2.2.2.m1.1"><semantics id="A1.T3.2.2.2.2.m1.1a"><mo id="A1.T3.2.2.2.2.m1.1.1" mathsize="90%" stretchy="false" xref="A1.T3.2.2.2.2.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="A1.T3.2.2.2.2.m1.1b"><ci id="A1.T3.2.2.2.2.m1.1.1.cmml" xref="A1.T3.2.2.2.2.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.2.2.2.2.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="A1.T3.2.2.2.2.m1.1d">↑</annotation></semantics></math>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="A1.T3.3.3.3.3">
<span class="ltx_text ltx_font_bold" id="A1.T3.3.3.3.3.1" style="font-size:90%;">LPIPS</span><span class="ltx_text" id="A1.T3.3.3.3.3.2" style="font-size:90%;"> </span><math alttext="\downarrow" class="ltx_Math" display="inline" id="A1.T3.3.3.3.3.m1.1"><semantics id="A1.T3.3.3.3.3.m1.1a"><mo id="A1.T3.3.3.3.3.m1.1.1" mathsize="90%" stretchy="false" xref="A1.T3.3.3.3.3.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="A1.T3.3.3.3.3.m1.1b"><ci id="A1.T3.3.3.3.3.m1.1.1.cmml" xref="A1.T3.3.3.3.3.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.3.3.3.3.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="A1.T3.3.3.3.3.m1.1d">↓</annotation></semantics></math>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A1.T3.3.3.4.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A1.T3.3.3.4.1.1"><span class="ltx_text" id="A1.T3.3.3.4.1.1.1" style="font-size:90%;">1</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.3.3.4.1.2"><span class="ltx_text" id="A1.T3.3.3.4.1.2.1" style="font-size:90%;">23.79</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.3.3.4.1.3"><span class="ltx_text" id="A1.T3.3.3.4.1.3.1" style="font-size:90%;">0.7323</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.3.3.4.1.4"><span class="ltx_text" id="A1.T3.3.3.4.1.4.1" style="font-size:90%;">0.3139</span></td>
</tr>
<tr class="ltx_tr" id="A1.T3.3.3.5.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="A1.T3.3.3.5.2.1"><span class="ltx_text" id="A1.T3.3.3.5.2.1.1" style="font-size:90%;">2</span></th>
<td class="ltx_td ltx_align_center" id="A1.T3.3.3.5.2.2"><span class="ltx_text" id="A1.T3.3.3.5.2.2.1" style="font-size:90%;">24.29</span></td>
<td class="ltx_td ltx_align_center" id="A1.T3.3.3.5.2.3"><span class="ltx_text" id="A1.T3.3.3.5.2.3.1" style="font-size:90%;">0.7409</span></td>
<td class="ltx_td ltx_align_center" id="A1.T3.3.3.5.2.4"><span class="ltx_text" id="A1.T3.3.3.5.2.4.1" style="font-size:90%;">0.3184</span></td>
</tr>
<tr class="ltx_tr" id="A1.T3.3.3.6.3">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="A1.T3.3.3.6.3.1"><span class="ltx_text" id="A1.T3.3.3.6.3.1.1" style="font-size:90%;">3</span></th>
<td class="ltx_td ltx_align_center" id="A1.T3.3.3.6.3.2"><span class="ltx_text" id="A1.T3.3.3.6.3.2.1" style="font-size:90%;">26.54</span></td>
<td class="ltx_td ltx_align_center" id="A1.T3.3.3.6.3.3"><span class="ltx_text" id="A1.T3.3.3.6.3.3.1" style="font-size:90%;">0.7750</span></td>
<td class="ltx_td ltx_align_center" id="A1.T3.3.3.6.3.4"><span class="ltx_text" id="A1.T3.3.3.6.3.4.1" style="font-size:90%;">0.3144</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 3. </span>Number of Input Views. Our method can produce good-quality frontal views from a single frontal image. However, the quality suffers from side views, where the input image doesn’t provide any information. Please see the supplementary HTML page for visuals.
</figcaption>
</figure>
<figure class="ltx_table" id="A1.T4">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 4. </span>
Additional ablations.
Training a prior model with a background leads to more floating artifacts during fine-tuning.
</figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="A1.T4.3.3">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A1.T4.3.3.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t" id="A1.T4.3.3.3.4"><span class="ltx_text ltx_font_bold" id="A1.T4.3.3.3.4.1" style="font-size:90%;">Variant</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A1.T4.1.1.1.1">
<span class="ltx_text ltx_font_bold" id="A1.T4.1.1.1.1.1" style="font-size:90%;">PSNR</span><span class="ltx_text" id="A1.T4.1.1.1.1.2" style="font-size:90%;"> </span><math alttext="\uparrow" class="ltx_Math" display="inline" id="A1.T4.1.1.1.1.m1.1"><semantics id="A1.T4.1.1.1.1.m1.1a"><mo id="A1.T4.1.1.1.1.m1.1.1" mathsize="90%" stretchy="false" xref="A1.T4.1.1.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="A1.T4.1.1.1.1.m1.1b"><ci id="A1.T4.1.1.1.1.m1.1.1.cmml" xref="A1.T4.1.1.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.T4.1.1.1.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="A1.T4.1.1.1.1.m1.1d">↑</annotation></semantics></math>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A1.T4.2.2.2.2">
<span class="ltx_text ltx_font_bold" id="A1.T4.2.2.2.2.1" style="font-size:90%;">SSIM</span><span class="ltx_text" id="A1.T4.2.2.2.2.2" style="font-size:90%;"> </span><math alttext="\uparrow" class="ltx_Math" display="inline" id="A1.T4.2.2.2.2.m1.1"><semantics id="A1.T4.2.2.2.2.m1.1a"><mo id="A1.T4.2.2.2.2.m1.1.1" mathsize="90%" stretchy="false" xref="A1.T4.2.2.2.2.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="A1.T4.2.2.2.2.m1.1b"><ci id="A1.T4.2.2.2.2.m1.1.1.cmml" xref="A1.T4.2.2.2.2.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.T4.2.2.2.2.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="A1.T4.2.2.2.2.m1.1d">↑</annotation></semantics></math>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A1.T4.3.3.3.3">
<span class="ltx_text ltx_font_bold" id="A1.T4.3.3.3.3.1" style="font-size:90%;">LPIPS</span><span class="ltx_text" id="A1.T4.3.3.3.3.2" style="font-size:90%;"> </span><math alttext="\downarrow" class="ltx_Math" display="inline" id="A1.T4.3.3.3.3.m1.1"><semantics id="A1.T4.3.3.3.3.m1.1a"><mo id="A1.T4.3.3.3.3.m1.1.1" mathsize="90%" stretchy="false" xref="A1.T4.3.3.3.3.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="A1.T4.3.3.3.3.m1.1b"><ci id="A1.T4.3.3.3.3.m1.1.1.cmml" xref="A1.T4.3.3.3.3.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.T4.3.3.3.3.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="A1.T4.3.3.3.3.m1.1d">↓</annotation></semantics></math>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A1.T4.3.3.4.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="A1.T4.3.3.4.1.1"><span class="ltx_text" id="A1.T4.3.3.4.1.1.1" style="font-size:90%;">Prior with background</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T4.3.3.4.1.2"><span class="ltx_text" id="A1.T4.3.3.4.1.2.1" style="font-size:90%;">24.51</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T4.3.3.4.1.3"><span class="ltx_text" id="A1.T4.3.3.4.1.3.1" style="font-size:90%;">0.7313</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T4.3.3.4.1.4"><span class="ltx_text" id="A1.T4.3.3.4.1.4.1" style="font-size:90%;">0.3244</span></td>
</tr>
<tr class="ltx_tr" id="A1.T4.3.3.5.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A1.T4.3.3.5.2.1"><span class="ltx_text" id="A1.T4.3.3.5.2.1.1" style="font-size:90%;">Prior without background</span></th>
<td class="ltx_td ltx_align_center" id="A1.T4.3.3.5.2.2"><span class="ltx_text" id="A1.T4.3.3.5.2.2.1" style="font-size:90%;">26.54</span></td>
<td class="ltx_td ltx_align_center" id="A1.T4.3.3.5.2.3"><span class="ltx_text" id="A1.T4.3.3.5.2.3.1" style="font-size:90%;">0.7750</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T4.3.3.5.2.4"><span class="ltx_text" id="A1.T4.3.3.5.2.4.1" style="font-size:90%;">0.3144</span></td>
</tr>
</tbody>
</table>
</figure>
<div class="ltx_para" id="A1.SS5.SSS2.p1">
<p class="ltx_p" id="A1.SS5.SSS2.p1.1">We extend our ablations from the main paper with metrics computed on different variants of our prior model in Tables <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#A1.T3" title="Table 3 ‣ A.5.2. Supplementary Ablations and Comparisons ‣ A.5. Supplementary Results ‣ Appendix A Supplementary ‣ Cafca: High-quality Novel View Synthesis of Expressive Faces from Casual Few-shot Captures"><span class="ltx_text ltx_ref_tag">3</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#A1.T4" title="Table 4 ‣ A.5.2. Supplementary Ablations and Comparisons ‣ A.5. Supplementary Results ‣ Appendix A Supplementary ‣ Cafca: High-quality Novel View Synthesis of Expressive Faces from Casual Few-shot Captures"><span class="ltx_text ltx_ref_tag">4</span></a>. The metrics are computed on the Multiface dataset <cite class="ltx_cite ltx_citemacro_citep">(Wuu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#bib.bib75" title="">2022</a>)</cite>, as described in the main paper.</p>
</div>
<div class="ltx_para" id="A1.SS5.SSS2.p2">
<p class="ltx_p" id="A1.SS5.SSS2.p2.1">We ablate fine-tuning results when a different number of views are available in Tbl. <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#A1.T3" title="Table 3 ‣ A.5.2. Supplementary Ablations and Comparisons ‣ A.5. Supplementary Results ‣ Appendix A Supplementary ‣ Cafca: High-quality Novel View Synthesis of Expressive Faces from Casual Few-shot Captures"><span class="ltx_text ltx_ref_tag">3</span></a>. We find that our method produces pleasing front-view faces even for a single input view. However, the quality quickly degrades for side views, where the input views do not provide any signal.
Table <a class="ltx_ref" href="https://arxiv.org/html/2410.00630v1#A1.T4" title="Table 4 ‣ A.5.2. Supplementary Ablations and Comparisons ‣ A.5. Supplementary Results ‣ Appendix A Supplementary ‣ Cafca: High-quality Novel View Synthesis of Expressive Faces from Casual Few-shot Captures"><span class="ltx_text ltx_ref_tag">4</span></a> ablates a prior model trained without background removal. Keeping the background (i) yields more floaters during model fitting.</p>
</div>
<div class="ltx_para" id="A1.SS5.SSS2.p3">
<p class="ltx_p" id="A1.SS5.SSS2.p3.1">For visuals and additional results for single image inputs, please see the main paper and the supplementary HTML page.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="A1.SS6">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.6. </span>Ethics</h3>
<div class="ltx_para" id="A1.SS6.p1">
<p class="ltx_p" id="A1.SS6.p1.1">The content of this paper follows the SIGGRAPH Asia policies for data privacy. In particular, all in-the-wild subjects have signed an agreement to be captured and reconstructed for research purposes. This approach inhibits the same risks and dangers as other face reconstruction methods.</p>
</div>
</section>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Tue Oct  1 01:46:15 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
