<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>MedUniSeg: 2D and 3D Medical Image Segmentation via a Prompt-driven Universal Model</title>
<!--Generated on Tue Oct  8 10:58:29 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<meta content="
Medical image segmentation,  Universal model,  Prompt learning,  Multi-modal learning
" lang="en" name="keywords"/>
<base href="/html/2410.05905v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#S1" title="In MedUniSeg: 2D and 3D Medical Image Segmentation via a Prompt-driven Universal Model"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span><span class="ltx_text ltx_font_smallcaps">Introduction</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#S2" title="In MedUniSeg: 2D and 3D Medical Image Segmentation via a Prompt-driven Universal Model"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span><span class="ltx_text ltx_font_smallcaps">Related Work</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#S2.SS1" title="In 2 Related Work ‣ MedUniSeg: 2D and 3D Medical Image Segmentation via a Prompt-driven Universal Model"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span><span class="ltx_text ltx_font_italic">Universal Model for Medical Image Segmentation</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#S2.SS2" title="In 2 Related Work ‣ MedUniSeg: 2D and 3D Medical Image Segmentation via a Prompt-driven Universal Model"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span><span class="ltx_text ltx_font_italic">Learning from Multi-modal Medical Data</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#S2.SS3" title="In 2 Related Work ‣ MedUniSeg: 2D and 3D Medical Image Segmentation via a Prompt-driven Universal Model"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.3 </span><span class="ltx_text ltx_font_italic">Prompt Learning</span></span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#S3" title="In MedUniSeg: 2D and 3D Medical Image Segmentation via a Prompt-driven Universal Model"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span><span class="ltx_text ltx_font_smallcaps">Method</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#S3.SS1" title="In 3 Method ‣ MedUniSeg: 2D and 3D Medical Image Segmentation via a Prompt-driven Universal Model"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span><span class="ltx_text ltx_font_italic">Problem Deﬁnition</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#S3.SS2" title="In 3 Method ‣ MedUniSeg: 2D and 3D Medical Image Segmentation via a Prompt-driven Universal Model"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span><span class="ltx_text ltx_font_italic">Encoder-decoder backbone</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#S3.SS3" title="In 3 Method ‣ MedUniSeg: 2D and 3D Medical Image Segmentation via a Prompt-driven Universal Model"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span><span class="ltx_text ltx_font_italic">Universal Task Prompt for Dynamic Task Priors</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#S3.SS4" title="In 3 Method ‣ MedUniSeg: 2D and 3D Medical Image Segmentation via a Prompt-driven Universal Model"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.4 </span><span class="ltx_text ltx_font_italic">Modal-specific Prompts for Modal Priors</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#S3.SS5" title="In 3 Method ‣ MedUniSeg: 2D and 3D Medical Image Segmentation via a Prompt-driven Universal Model"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.5 </span><span class="ltx_text ltx_font_italic">Transfer Learning</span></span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#S4" title="In MedUniSeg: 2D and 3D Medical Image Segmentation via a Prompt-driven Universal Model"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span><span class="ltx_text ltx_font_smallcaps">Datasets</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#S5" title="In MedUniSeg: 2D and 3D Medical Image Segmentation via a Prompt-driven Universal Model"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span><span class="ltx_text ltx_font_smallcaps">Experiments</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#S5.SS1" title="In 5 Experiments ‣ MedUniSeg: 2D and 3D Medical Image Segmentation via a Prompt-driven Universal Model"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1 </span><span class="ltx_text ltx_font_italic">Implementations</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#S5.SS2" title="In 5 Experiments ‣ MedUniSeg: 2D and 3D Medical Image Segmentation via a Prompt-driven Universal Model"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2 </span><span class="ltx_text ltx_font_italic">Evaluation Metrics</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#S5.SS3" title="In 5 Experiments ‣ MedUniSeg: 2D and 3D Medical Image Segmentation via a Prompt-driven Universal Model"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.3 </span><span class="ltx_text ltx_font_italic">Comparing to Single-task and Universal Models</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#S5.SS4" title="In 5 Experiments ‣ MedUniSeg: 2D and 3D Medical Image Segmentation via a Prompt-driven Universal Model"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.4 </span><span class="ltx_text ltx_font_italic">Performance Improvement using LoRA</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#S5.SS5" title="In 5 Experiments ‣ MedUniSeg: 2D and 3D Medical Image Segmentation via a Prompt-driven Universal Model"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.5 </span><span class="ltx_text ltx_font_italic">Comparing to Other Pre-trained Models</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#S5.SS6" title="In 5 Experiments ‣ MedUniSeg: 2D and 3D Medical Image Segmentation via a Prompt-driven Universal Model"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.6 </span><span class="ltx_text ltx_font_italic">Ablation Studies</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#S5.SS7" title="In 5 Experiments ‣ MedUniSeg: 2D and 3D Medical Image Segmentation via a Prompt-driven Universal Model"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.7 </span><span class="ltx_text ltx_font_italic">Block and Channel Numbers of FUSE Module</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#S5.SS8" title="In 5 Experiments ‣ MedUniSeg: 2D and 3D Medical Image Segmentation via a Prompt-driven Universal Model"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.8 </span><span class="ltx_text ltx_font_italic">Shapes of Modal-specific Prompts and Universal Task Prompt</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#S5.SS9" title="In 5 Experiments ‣ MedUniSeg: 2D and 3D Medical Image Segmentation via a Prompt-driven Universal Model"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.9 </span><span class="ltx_text ltx_font_italic">Visualization of Segmentation Results</span></span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#S5.SS9.SSS1" title="In 5.9 Visualization of Segmentation Results ‣ 5 Experiments ‣ MedUniSeg: 2D and 3D Medical Image Segmentation via a Prompt-driven Universal Model"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.9.1 </span>Upstream dataset</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#S5.SS9.SSS2" title="In 5.9 Visualization of Segmentation Results ‣ 5 Experiments ‣ MedUniSeg: 2D and 3D Medical Image Segmentation via a Prompt-driven Universal Model"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.9.2 </span>Downstream datasets</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#S6" title="In MedUniSeg: 2D and 3D Medical Image Segmentation via a Prompt-driven Universal Model"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span><span class="ltx_text ltx_font_smallcaps">Discussion</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#S6.SS1" title="In 6 Discussion ‣ MedUniSeg: 2D and 3D Medical Image Segmentation via a Prompt-driven Universal Model"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.1 </span><span class="ltx_text ltx_font_italic">Visualization of Task-specific Prior</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#S6.SS2" title="In 6 Discussion ‣ MedUniSeg: 2D and 3D Medical Image Segmentation via a Prompt-driven Universal Model"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.2 </span><span class="ltx_text ltx_font_italic">Correlation between Upstream and Downstream Learning</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#S6.SS3" title="In 6 Discussion ‣ MedUniSeg: 2D and 3D Medical Image Segmentation via a Prompt-driven Universal Model"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.3 </span><span class="ltx_text ltx_font_italic">Resource Requirements for Inference</span></span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#S7" title="In MedUniSeg: 2D and 3D Medical Image Segmentation via a Prompt-driven Universal Model"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7 </span><span class="ltx_text ltx_font_smallcaps">Conclusion</span></span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">MedUniSeg: 2D and 3D Medical Image Segmentation via a Prompt-driven Universal Model</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Yiwen Ye,
Ziyang Chen,
Jianpeng Zhang,
Yutong Xie,
and
Yong Xia
</span><span class="ltx_author_notes">This work was supported in part by the National Natural Science Foundation of China under Grants 62171377. (<span class="ltx_text ltx_font_italic" id="id7.1.id1">Corresponding authors: Y. Xie and Y. Xia</span>).
Y. Ye and Z. Chen are with the National Engineering Laboratory for Integrated Aero-Space-Ground-Ocean Big Data Application Technology, School of Computer Science and Engineering, Northwestern Polytechnical University, Xi’an 710072, China. 
<br class="ltx_break"/>E-mail: {ywye, zychen}@mail.nwpu.edu.cn.
J. Zhang is with the College of Computer Science and Technology, Zhejiang University, Zhejiang, China. 
<br class="ltx_break"/>E-mail: jianpeng.zhang0@gmail.com.
Y. Xie is with the Australian Institute for Machine Learning (AIML), The University of Adelaide, Australia. 
<br class="ltx_break"/>E-mail: yutong.xie678@gmail.com.
Y. Xia is with the National Engineering Laboratory for Integrated Aero-Space-Ground-Ocean Big Data Application Technology, School of Computer Science and Engineering, Northwestern Polytechnical University, Xi’an 710072, China, with Research &amp; Development Institute of Northwestern Polytechnical University in Shenzhen, Shenzhen 518057, China, and also with the Ningbo Institute of Northwestern Polytechnical University, Ningbo 315048, China. 
<br class="ltx_break"/>E-mail: yxia@nwpu.edu.cn.
</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id1.1">Universal segmentation models offer significant potential in addressing a wide range of tasks by effectively leveraging discrete annotations. As the scope of tasks and modalities expands, it becomes increasingly important to generate and strategically position task- and modal-specific priors within the universal model. However, existing universal models often overlook the correlations between different priors, and the optimal placement and frequency of these priors remain underexplored.
In this paper, we introduce MedUniSeg, a prompt-driven universal segmentation model designed for 2D and 3D multi-task segmentation across diverse modalities and domains. MedUniSeg employs multiple modal-specific prompts alongside a universal task prompt to accurately characterize the modalities and tasks. To generate the related priors, we propose the modal map (MMap) and the fusion and selection (FUSE) modules, which transform modal and task prompts into corresponding priors. These modal and task priors are systematically introduced at the start and end of the encoding process.
We evaluate MedUniSeg on a comprehensive multi-modal upstream dataset consisting of 17 sub-datasets. The results demonstrate that MedUniSeg achieves superior multi-task segmentation performance, attaining a 1.2% improvement in the mean Dice score across the 17 upstream tasks compared to nnUNet baselines, while using less than <math alttext="1/10" class="ltx_Math" display="inline" id="id1.1.m1.1"><semantics id="id1.1.m1.1a"><mrow id="id1.1.m1.1.1" xref="id1.1.m1.1.1.cmml"><mn id="id1.1.m1.1.1.2" xref="id1.1.m1.1.1.2.cmml">1</mn><mo id="id1.1.m1.1.1.1" xref="id1.1.m1.1.1.1.cmml">/</mo><mn id="id1.1.m1.1.1.3" xref="id1.1.m1.1.1.3.cmml">10</mn></mrow><annotation-xml encoding="MathML-Content" id="id1.1.m1.1b"><apply id="id1.1.m1.1.1.cmml" xref="id1.1.m1.1.1"><divide id="id1.1.m1.1.1.1.cmml" xref="id1.1.m1.1.1.1"></divide><cn id="id1.1.m1.1.1.2.cmml" type="integer" xref="id1.1.m1.1.1.2">1</cn><cn id="id1.1.m1.1.1.3.cmml" type="integer" xref="id1.1.m1.1.1.3">10</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="id1.1.m1.1c">1/10</annotation><annotation encoding="application/x-llamapun" id="id1.1.m1.1d">1 / 10</annotation></semantics></math> of the parameters. For tasks that underperform during the initial multi-task joint training, we freeze MedUniSeg and introduce new modules to re-learn these tasks. This approach yields an enhanced version, MedUniSeg*, which consistently outperforms MedUniSeg across all tasks. Moreover, MedUniSeg surpasses advanced self-supervised and supervised pre-trained models on six downstream tasks, establishing itself as a high-quality, highly generalizable pre-trained segmentation model.
The code and model will be available at <a class="ltx_ref ltx_href" href="https://github.com/yeerwen/UniSeg" title="">https://github.com/yeerwen/UniSeg</a>.</p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Index Terms: </h6>
Medical image segmentation, Universal model, Prompt learning, Multi-modal learning

</div>
<figure class="ltx_figure" id="S0.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="739" id="S0.F1.g1" src="x1.png" width="789"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>
(a) Comparison between the mainstream solution and our solution. The mainstream solution treats both 2D and 3D data as 1D tokens and utilizes a Transformer-based model for processing. In contrast, our solution interprets 2D data as pseudo-3D data and employs a 3D CNN-based model for processing.
(b) Performance and parameter comparisons between nnUNet and MedUniSeg* across 17 upstream datasets. To achieve the same tasks, nnUNet requires 17 individual models, comprising 11 3D models and 6 2D models, while our MedUniSeg* needs only a single model.
</figcaption>
</figure>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span><span class="ltx_text ltx_font_smallcaps" id="S1.1.1">Introduction</span>
</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Medical image segmentation is essential for delineating lesions, diagnosing diseases, analyzing pathology, and planning treatments. With the diversification of imaging techniques and targets, many segmentation tasks now involve various data modalities and anatomical regions, covering both 2D and 3D data. The advent of deep learning has facilitated automated methods to address these tasks effectively. However, two main challenges remain: (1) the tendency to create specialized models for specific tasks, which leads to fragmented research efforts, and (2) the limitation of small labeled datasets, particularly for 3D segmentation, due to the labor-intensive nature of voxel-wise annotations.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">Universal models that can tackle multiple segmentation tasks through a single training process have emerged as a promising solution. These models utilize extensive data from various datasets to enhance learning. A key aspect of their design is determining the task-related priors to incorporate and their optimal placement in the model for effective task awareness. One intuitive approach employs a shared encoder with multiple task-specific decoders <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib1" title="">1</a>]</cite>, but this can result in structural redundancy and parameter inefficiency due to the multiple branches needed, especially when integrating numerous tasks. To streamline the model structure, some universal models transform multi-dataset training into multi-class training by assigning each target a unique output channel <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib2" title="">2</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib3" title="">3</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib4" title="">4</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib5" title="">5</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib6" title="">6</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib7" title="">7</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib8" title="">8</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib9" title="">9</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib10" title="">10</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib11" title="">11</a>]</cite>. These models derive task-related priors by selecting the corresponding segmentation head for each task. Additionally, some prompt-based universal models utilize fixed task-specific prompts <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib12" title="">12</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib13" title="">13</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib14" title="">14</a>]</cite>, such as one-hot encoding, or learnable task-specific prompts <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib15" title="">15</a>]</cite>, to introduce task-related priors at the end of the decoder stage. These models, however, often struggle in complex and varied segmentation scenarios, as only a few parameters are aware of the current task; thus, task-related priors are integrated too late in the process. In our previous work, UniSeg <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib16" title="">16</a>]</cite>, we addressed this challenge by adding task-related prior to the end of the encoding process, enabling the whole decoder to be aware of tasks.
Recently, models like CCQ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib17" title="">17</a>]</cite> and Hermes <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib18" title="">18</a>]</cite> have sought to enhance task-related information by introducing learnable prompts at multiple stages throughout the model. Despite these advancements, the relationships between different tasks remain less explored, and the optimal locations and frequencies for introducing these priors require further refinement.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">Moreover, current universal segmentation methods primarily focus on either single-modal segmentation <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib19" title="">19</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib12" title="">12</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib14" title="">14</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib13" title="">13</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib15" title="">15</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib17" title="">17</a>]</cite> or single-dimensional segmentation <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib19" title="">19</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib12" title="">12</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib14" title="">14</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib13" title="">13</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib15" title="">15</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib18" title="">18</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib17" title="">17</a>]</cite>, failing to meet the multi-modal and multi-dimensional requirements of medical image segmentation. Therefore, developing a generalized universal model capable of processing multi-modal and multi-dimensional data is essential. Constructing such a model faces two primary challenges: first, a backbone is needed that delivers superior segmentation performance while accommodating inputs of varying dimensions, including both 2D and 3D data. Second, the significant differences between modalities pose a risk of optimization conflicts during joint training <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib20" title="">20</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib21" title="">21</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib22" title="">22</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">To address these limitations, we propose a prompt-driven <span class="ltx_text ltx_font_bold" id="S1.p4.1.1">Med</span>ical <span class="ltx_text ltx_font_bold" id="S1.p4.1.2">Uni</span>versal <span class="ltx_text ltx_font_bold" id="S1.p4.1.3">Seg</span>mentation model (MedUniSeg). This model is designed to segment multiple organs, tissues, vertebrae, tumors, and lesions in 2D and 3D medical images across various modalities and domains. The architecture of MedUniSeg comprises several components: a modal map (MMap) module, a vision encoder, a fusion and selection (FUSE) module, and a prompt-driven decoder. The MMap and FUSE modules leverage prompt learning to provide modal-specific and task-specific priors, respectively, thereby alleviating optimization conflicts between modalities and enhancing task-related progress. Specifically, the MMap module maps learnable modal-specific prompts to align with the shape of the input image, enriching the input data with modal-specific priors. The FUSE module integrates a learnable universal task prompt, which describes the correlations between tasks, and the features from the vision encoder to generate task-specific priors. We employ multiple modal-specific prompts and a universal task prompt based on the premise that <span class="ltx_text ltx_font_italic" id="S1.p4.1.4">potential correlations exist between different tasks, while correlations among modalities are negligible, primarily due to the use of unpaired multi-modal data <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib23" title="">23</a>]</cite>.</span>
Furthermore, we carefully consider the integration locations for modal-specific and task-specific priors. Modal-specific priors are introduced at the start of the encoding process to guide different modality data, while task-specific priors are introduced at the end of the encoding process to meet the specific needs of distinct segmentation tasks. <span class="ltx_text ltx_font_italic" id="S1.p4.1.5">The differing locations depend on when discrepancies between modalities or tasks begin to emerge.</span> Since different modalities necessitate distinct feature extraction procedures, the model must address these variations early in the encoding process. After extracting high-level semantic features, different tasks correspond to specific decoding processes; thus, the model must be informed of the task priors at the onset of this stage.</p>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">To effectively handle most segmentation tasks, our model must accept both 2D and 3D input data. Unlike the prevailing trend of using Transformer-based models that process data in a sequence-to-sequence manner, MedUniSeg adopts a novel perspective by treating 2D data as pseudo-3D data with a depth of one and employing a pruned 3D CNN-based UNet to manage both 2D and 3D data (see Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#S0.F1" title="Figure 1 ‣ MedUniSeg: 2D and 3D Medical Image Segmentation via a Prompt-driven Universal Model"><span class="ltx_text ltx_ref_tag">1</span></a>(a)). Although this approach demands more resources than its 2D-only counterparts for predicting 2D segmentation maps, MedUniSeg still surpasses Transformer-based models like UniMiSS in terms of inference time and performance (see Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#S6.SS3" title="6.3 Resource Requirements for Inference ‣ 6 Discussion ‣ MedUniSeg: 2D and 3D Medical Image Segmentation via a Prompt-driven Universal Model"><span class="ltx_text ltx_ref_tag">6.3</span></a>).</p>
</div>
<div class="ltx_para" id="S1.p6">
<p class="ltx_p" id="S1.p6.1">For evaluation, we compiled a comprehensive dataset comprising 21,382 3D/2D samples across nine modalities (CT, MRI, PET, dermoscopy, fundus imaging, pathological imaging, ultrasound, X-ray, and endoscopy) and 24 targets from 17 datasets, referred to as upstream datasets. We benchmarked MedUniSeg against other universal models like DoDNet <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib12" title="">12</a>]</cite> and Hermes <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib18" title="">18</a>]</cite>, as well as leading single-task models like nnUNet <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib24" title="">24</a>]</cite>, U-Mamba <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib25" title="">25</a>]</cite>, and UKAN <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib26" title="">26</a>]</cite>, each trained independently on their respective datasets. The results demonstrate that MedUniSeg achieves superior generalization performance across all upstream tasks, with only a few tasks slightly underperforming compared to nnUNet models, which serve as our baselines. To further enhance performance, we froze the trained model and integrated new LoRA <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib27" title="">27</a>]</cite>, deconvolutional layers, and segmentation heads to re-learn these tasks, resulting in an enhanced version, MedUniSeg*. Performance and parameter comparisons between nnUNet and MedUniSeg* are illustrated in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#S0.F1" title="Figure 1 ‣ MedUniSeg: 2D and 3D Medical Image Segmentation via a Prompt-driven Universal Model"><span class="ltx_text ltx_ref_tag">1</span></a>(b). The visualization indicates that MedUniSeg* outperforms nnUNet on 14 tasks, with only marginally lower performance on two tasks, while utilizing less than <math alttext="1/10" class="ltx_Math" display="inline" id="S1.p6.1.m1.1"><semantics id="S1.p6.1.m1.1a"><mrow id="S1.p6.1.m1.1.1" xref="S1.p6.1.m1.1.1.cmml"><mn id="S1.p6.1.m1.1.1.2" xref="S1.p6.1.m1.1.1.2.cmml">1</mn><mo id="S1.p6.1.m1.1.1.1" xref="S1.p6.1.m1.1.1.1.cmml">/</mo><mn id="S1.p6.1.m1.1.1.3" xref="S1.p6.1.m1.1.1.3.cmml">10</mn></mrow><annotation-xml encoding="MathML-Content" id="S1.p6.1.m1.1b"><apply id="S1.p6.1.m1.1.1.cmml" xref="S1.p6.1.m1.1.1"><divide id="S1.p6.1.m1.1.1.1.cmml" xref="S1.p6.1.m1.1.1.1"></divide><cn id="S1.p6.1.m1.1.1.2.cmml" type="integer" xref="S1.p6.1.m1.1.1.2">1</cn><cn id="S1.p6.1.m1.1.1.3.cmml" type="integer" xref="S1.p6.1.m1.1.1.3">10</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.p6.1.m1.1c">1/10</annotation><annotation encoding="application/x-llamapun" id="S1.p6.1.m1.1d">1 / 10</annotation></semantics></math> of the parameters. To assess the transfer capability of MedUniSeg, we fine-tuned it on six downstream datasets and conducted comparative analyses against other universal models and self-supervised models such as VoCo <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib28" title="">28</a>]</cite> and MedKLIP <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib29" title="">29</a>]</cite>. The results reveal that MedUniSeg outperforms all competitors regarding generalization performance across the 17 upstream tasks and six downstream tasks.</p>
</div>
<div class="ltx_para" id="S1.p7">
<p class="ltx_p" id="S1.p7.1">The contributions of this work are four-fold:
</p>
<ul class="ltx_itemize" id="S1.I1">
<li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i1.p1">
<p class="ltx_p" id="S1.I1.i1.p1.1">We further explore the universal medical segmentation model, enhancing its capability across different modalities and data dimensions. Our model can simultaneously address 17 segmentation tasks spanning nine modalities, various domains, and both 2D and 3D dimensions, using a single model built upon UNet.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i2.p1">
<p class="ltx_p" id="S1.I1.i2.p1.1">We design two types of learnable prompts to generate specific priors tailored to the modality and task of the ongoing image. Additionally, we customize the introduction locations of the proposed priors to mitigate modal collisions and facilitate task learning.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i3.p1">
<p class="ltx_p" id="S1.I1.i3.p1.1">We introduce LoRA to improve the performance of tasks that do not benefit from joint training, thereby contributing to a more comprehensive and versatile universal segmentation model.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i4.p1">
<p class="ltx_p" id="S1.I1.i4.p1.1">MedUniSeg serves as a high-performance pre-trained model for both 2D and 3D medical image segmentation, demonstrating strong generalization and high-quality representation capabilities.</p>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span><span class="ltx_text ltx_font_smallcaps" id="S2.1.1">Related Work</span>
</h2>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span><span class="ltx_text ltx_font_italic" id="S2.SS1.1.1">Universal Model for Medical Image Segmentation</span>
</h3>
<div class="ltx_para" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.1">The diverse modalities in medical imaging, coupled with labor-intensive annotation processes and disease-specific variations, often lead to fragmented annotation efforts across multiple segmentation datasets. Traditionally, each dataset is managed by a separate model, which results in distributed research efforts. To counter this fragmentation, the development of universal models capable of handling multiple datasets or tasks has gained traction and shown considerable promise. These universal models are typically categorized into three groups: multi-head models, multi-class models, and prompt-based models.</p>
</div>
<div class="ltx_para" id="S2.SS1.p2">
<p class="ltx_p" id="S2.SS1.p2.1"><span class="ltx_text ltx_font_bold" id="S2.SS1.p2.1.1">Multi-head models</span> generally utilize a shared encoder combined with multiple task-specific decoders <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib1" title="">1</a>]</cite>. While this architecture facilitates task integration to optimize parameter utilization, it also introduces redundancy and increases model complexity.
<span class="ltx_text ltx_font_bold" id="S2.SS1.p2.1.2">Multi-class models</span> consolidate multiple tasks into a single multi-class task, assigning each task to a specific channel within the output segmentation maps. Techniques such as generating pseudo labels <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib3" title="">3</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib5" title="">5</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib6" title="">6</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib7" title="">7</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib8" title="">8</a>]</cite>, self-disambiguation learning <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib9" title="">9</a>]</cite>, target adaptive loss <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib4" title="">4</a>]</cite>, and masked back-propagation <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib10" title="">10</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib11" title="">11</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib2" title="">2</a>]</cite> are employed to integrate tasks and leverage their joint learning. For instance, the Universal Model <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib10" title="">10</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib11" title="">11</a>]</cite> employs a language-driven parameter generator to derive rich semantic encodings for each foreground category and incorporates a masked back-propagation strategy for improved learning from available annotations. However, task-related priors are primarily introduced at the segmentation heads, resulting in a limited number of parameters being ‘aware’ of the ongoing task. This limitation hinders the model’s ability to handle numerous segmentation tasks, especially in complex scenarios.
<span class="ltx_text ltx_font_bold" id="S2.SS1.p2.1.3">Prompt-based models</span> leverage well-designed prompts to inform the model about the current task, thereby enhancing segmentation accuracy. Prompts can be fixed features associated with the target task <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib19" title="">19</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib12" title="">12</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib14" title="">14</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib13" title="">13</a>]</cite> or learnable task-specific features <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib15" title="">15</a>]</cite>. For instance, DoDNet <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib12" title="">12</a>]</cite> utilizes one-hot encoding for each task as a prior, along with a dynamically generated convolutional block tailored to the ongoing task and image. TransDoDNet <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib15" title="">15</a>]</cite> employs learnable task-specific organ embeddings and a filters prediction head to produce task-specific filters for dynamic segmentation. Similar to multi-class models, prompt-based models introduce task-related prior information at the end of the decoder, which can hinder their performance in complex segmentation scenarios, especially as the number of modalities and tasks increases. Recently, CCQ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib17" title="">17</a>]</cite> developed a cross-class query learning module to generate class-relevant features for segmentation, introducing task-related priors at both the start and end of the decoding process. Hermes <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib18" title="">18</a>]</cite> employs a context-prior pool to apply task- and modal-specific priors based on the input image, incorporating priors at multiple stages. However, despite the earlier introduction of task-related priors, the optimal locations and frequency of these priors remain to be refined.</p>
</div>
<div class="ltx_para" id="S2.SS1.p3">
<p class="ltx_p" id="S2.SS1.p3.1">In our pilot study <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib16" title="">16</a>]</cite>, we introduced UniSeg, a prompt-driven model that incorporates task priors at the end of the encoding process to enhance decoder performance. Nonetheless, UniSeg has notable limitations: it overlooks the risk of modal collision during multi-modal learning and is confined to 3D segmentation tasks, which restricts its applicability. To address these limitations, we propose MedUniSeg, which incorporates modal-specific prompts to generate modal priors and extends the model’s capabilities to efficiently handle both 2D and 3D segmentation tasks under a single framework.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span><span class="ltx_text ltx_font_italic" id="S2.SS2.1.1">Learning from Multi-modal Medical Data</span>
</h3>
<div class="ltx_para" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.1">Multi-modal learning enables models to learn from diverse paired or unpaired multi-modal data and has garnered significant interest in the research community. A wide range of applications has been explored, such as multi-modal pre-training <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib30" title="">30</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib31" title="">31</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib32" title="">32</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib33" title="">33</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib34" title="">34</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib20" title="">20</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib35" title="">35</a>]</cite>, multi-modal segmentation <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib36" title="">36</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib37" title="">37</a>]</cite>, and multi-modal classification <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib38" title="">38</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib39" title="">39</a>]</cite>.
As research on multi-modal learning deepens, issues such as modal data collision or modality competition <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib20" title="">20</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib21" title="">21</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib22" title="">22</a>]</cite> arise due to significant gaps between modalities and inconsistent optimization strategies, hindering the performance of joint training. A multiway strategy, which assigns dedicated modules for each modality, effectively mitigates optimization inconsistency. For instance, BEiT-3 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib40" title="">40</a>]</cite> employs both vision and language expert modules across multiple transformer layers to capture vision- and language-specific features, respectively. However, this approach can lead to uncontrolled parameter growth as the number of modalities increases.
An alternative strategy involves separating the training process for each modality. For example, MedCoSS <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib20" title="">20</a>]</cite> shifts from joint pre-training to a multi-stage pre-training approach, designating each stage for specific modal data. Although this method effectively mitigates catastrophic forgetting using continual-based techniques, it may still result in some degree of forgetting, yielding performance comparable to single-modal pre-training. In this study, we employ prompt learning to provide modal priors for the model, offering a novel perspective to address modal data collision.</p>
</div>
<div class="ltx_para" id="S2.SS2.p2">
<p class="ltx_p" id="S2.SS2.p2.1">Furthermore, it is crucial for models to handle both 2D and 3D data, as these encompass the majority of medical image segmentation tasks. Current methods primarily utilize Transformer-based architectures <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib20" title="">20</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib35" title="">35</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib41" title="">41</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib42" title="">42</a>]</cite>, which are favored for their ability to process data in a sequence-to-sequence manner. In this study, we propose treating 2D data as pseudo-3D by considering the depth dimension as one, allowing a 3D model to accommodate both 2D and 3D data. This unified approach simplifies the model structure while maintaining high performance.</p>
</div>
<figure class="ltx_figure" id="S2.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="372" id="S2.F2.g1" src="x2.png" width="789"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Technical pipeline of our MedUniSeg, including the MMap module, a vision encoder, the FUSE module, and a prompt-driven decoder. For an input image, we identify its modality ID and task ID. Based on these identifiers, the MMap module generates modal-specific priors, while the FUSE module produces task-specific priors. These priors are integrated at the start and end of the encoding process, enabling MedUniSeg to effectively handle multiple modalities and tasks.</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S2.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span><span class="ltx_text ltx_font_italic" id="S2.SS3.1.1">Prompt Learning</span>
</h3>
<div class="ltx_para" id="S2.SS3.p1">
<p class="ltx_p" id="S2.SS3.p1.1">Prompt learning has emerged as an effective strategy for enhancing model adaptability to specific tasks by integrating prior knowledge into the model. This technique has been widely applied across various fields, including the efficient fine-tuning of large models <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib43" title="">43</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib44" title="">44</a>]</cite>, domain adaptation <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib45" title="">45</a>]</cite>, continual learning <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib46" title="">46</a>]</cite>, self-supervised learning <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib47" title="">47</a>]</cite>, and federated learning <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib48" title="">48</a>]</cite>.
The effectiveness of prompt learning is particularly evident in the development of universal segmentation models, where it ensures that the model remains acutely ‘aware’ of the current task and modality. For instance, models like DoDNet <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib12" title="">12</a>]</cite> and its variants <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib13" title="">13</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib14" title="">14</a>]</cite> employ one-hot encoding as a fixed prompt. In contrast, TransDoDNet <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib15" title="">15</a>]</cite>, Hermes <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib18" title="">18</a>]</cite>, and CCQ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib17" title="">17</a>]</cite> utilize learnable vectors as learnable prompts to indicate the ongoing task.
Distinct from these existing methods, this study tailors both task and modal prompts, carefully determining their introduction locations within the model’s architecture. Our approach, therefore, establishes a coherent framework for multi-modal universal segmentation, significantly enhancing the model’s ability to integrate and process diverse data types and tasks.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span><span class="ltx_text ltx_font_smallcaps" id="S3.1.1">Method</span>
</h2>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span><span class="ltx_text ltx_font_italic" id="S3.SS1.1.1">Problem Deﬁnition</span>
</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.11">Consider the set <math alttext="\{S^{1}_{1},S^{1}_{2},...,S^{M}_{N}\}" class="ltx_Math" display="inline" id="S3.SS1.p1.1.m1.4"><semantics id="S3.SS1.p1.1.m1.4a"><mrow id="S3.SS1.p1.1.m1.4.4.3" xref="S3.SS1.p1.1.m1.4.4.4.cmml"><mo id="S3.SS1.p1.1.m1.4.4.3.4" stretchy="false" xref="S3.SS1.p1.1.m1.4.4.4.cmml">{</mo><msubsup id="S3.SS1.p1.1.m1.2.2.1.1" xref="S3.SS1.p1.1.m1.2.2.1.1.cmml"><mi id="S3.SS1.p1.1.m1.2.2.1.1.2.2" xref="S3.SS1.p1.1.m1.2.2.1.1.2.2.cmml">S</mi><mn id="S3.SS1.p1.1.m1.2.2.1.1.3" xref="S3.SS1.p1.1.m1.2.2.1.1.3.cmml">1</mn><mn id="S3.SS1.p1.1.m1.2.2.1.1.2.3" xref="S3.SS1.p1.1.m1.2.2.1.1.2.3.cmml">1</mn></msubsup><mo id="S3.SS1.p1.1.m1.4.4.3.5" xref="S3.SS1.p1.1.m1.4.4.4.cmml">,</mo><msubsup id="S3.SS1.p1.1.m1.3.3.2.2" xref="S3.SS1.p1.1.m1.3.3.2.2.cmml"><mi id="S3.SS1.p1.1.m1.3.3.2.2.2.2" xref="S3.SS1.p1.1.m1.3.3.2.2.2.2.cmml">S</mi><mn id="S3.SS1.p1.1.m1.3.3.2.2.3" xref="S3.SS1.p1.1.m1.3.3.2.2.3.cmml">2</mn><mn id="S3.SS1.p1.1.m1.3.3.2.2.2.3" xref="S3.SS1.p1.1.m1.3.3.2.2.2.3.cmml">1</mn></msubsup><mo id="S3.SS1.p1.1.m1.4.4.3.6" xref="S3.SS1.p1.1.m1.4.4.4.cmml">,</mo><mi id="S3.SS1.p1.1.m1.1.1" mathvariant="normal" xref="S3.SS1.p1.1.m1.1.1.cmml">…</mi><mo id="S3.SS1.p1.1.m1.4.4.3.7" xref="S3.SS1.p1.1.m1.4.4.4.cmml">,</mo><msubsup id="S3.SS1.p1.1.m1.4.4.3.3" xref="S3.SS1.p1.1.m1.4.4.3.3.cmml"><mi id="S3.SS1.p1.1.m1.4.4.3.3.2.2" xref="S3.SS1.p1.1.m1.4.4.3.3.2.2.cmml">S</mi><mi id="S3.SS1.p1.1.m1.4.4.3.3.3" xref="S3.SS1.p1.1.m1.4.4.3.3.3.cmml">N</mi><mi id="S3.SS1.p1.1.m1.4.4.3.3.2.3" xref="S3.SS1.p1.1.m1.4.4.3.3.2.3.cmml">M</mi></msubsup><mo id="S3.SS1.p1.1.m1.4.4.3.8" stretchy="false" xref="S3.SS1.p1.1.m1.4.4.4.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.4b"><set id="S3.SS1.p1.1.m1.4.4.4.cmml" xref="S3.SS1.p1.1.m1.4.4.3"><apply id="S3.SS1.p1.1.m1.2.2.1.1.cmml" xref="S3.SS1.p1.1.m1.2.2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.1.m1.2.2.1.1.1.cmml" xref="S3.SS1.p1.1.m1.2.2.1.1">subscript</csymbol><apply id="S3.SS1.p1.1.m1.2.2.1.1.2.cmml" xref="S3.SS1.p1.1.m1.2.2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.1.m1.2.2.1.1.2.1.cmml" xref="S3.SS1.p1.1.m1.2.2.1.1">superscript</csymbol><ci id="S3.SS1.p1.1.m1.2.2.1.1.2.2.cmml" xref="S3.SS1.p1.1.m1.2.2.1.1.2.2">𝑆</ci><cn id="S3.SS1.p1.1.m1.2.2.1.1.2.3.cmml" type="integer" xref="S3.SS1.p1.1.m1.2.2.1.1.2.3">1</cn></apply><cn id="S3.SS1.p1.1.m1.2.2.1.1.3.cmml" type="integer" xref="S3.SS1.p1.1.m1.2.2.1.1.3">1</cn></apply><apply id="S3.SS1.p1.1.m1.3.3.2.2.cmml" xref="S3.SS1.p1.1.m1.3.3.2.2"><csymbol cd="ambiguous" id="S3.SS1.p1.1.m1.3.3.2.2.1.cmml" xref="S3.SS1.p1.1.m1.3.3.2.2">subscript</csymbol><apply id="S3.SS1.p1.1.m1.3.3.2.2.2.cmml" xref="S3.SS1.p1.1.m1.3.3.2.2"><csymbol cd="ambiguous" id="S3.SS1.p1.1.m1.3.3.2.2.2.1.cmml" xref="S3.SS1.p1.1.m1.3.3.2.2">superscript</csymbol><ci id="S3.SS1.p1.1.m1.3.3.2.2.2.2.cmml" xref="S3.SS1.p1.1.m1.3.3.2.2.2.2">𝑆</ci><cn id="S3.SS1.p1.1.m1.3.3.2.2.2.3.cmml" type="integer" xref="S3.SS1.p1.1.m1.3.3.2.2.2.3">1</cn></apply><cn id="S3.SS1.p1.1.m1.3.3.2.2.3.cmml" type="integer" xref="S3.SS1.p1.1.m1.3.3.2.2.3">2</cn></apply><ci id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1">…</ci><apply id="S3.SS1.p1.1.m1.4.4.3.3.cmml" xref="S3.SS1.p1.1.m1.4.4.3.3"><csymbol cd="ambiguous" id="S3.SS1.p1.1.m1.4.4.3.3.1.cmml" xref="S3.SS1.p1.1.m1.4.4.3.3">subscript</csymbol><apply id="S3.SS1.p1.1.m1.4.4.3.3.2.cmml" xref="S3.SS1.p1.1.m1.4.4.3.3"><csymbol cd="ambiguous" id="S3.SS1.p1.1.m1.4.4.3.3.2.1.cmml" xref="S3.SS1.p1.1.m1.4.4.3.3">superscript</csymbol><ci id="S3.SS1.p1.1.m1.4.4.3.3.2.2.cmml" xref="S3.SS1.p1.1.m1.4.4.3.3.2.2">𝑆</ci><ci id="S3.SS1.p1.1.m1.4.4.3.3.2.3.cmml" xref="S3.SS1.p1.1.m1.4.4.3.3.2.3">𝑀</ci></apply><ci id="S3.SS1.p1.1.m1.4.4.3.3.3.cmml" xref="S3.SS1.p1.1.m1.4.4.3.3.3">𝑁</ci></apply></set></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.4c">\{S^{1}_{1},S^{1}_{2},...,S^{M}_{N}\}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.1.m1.4d">{ italic_S start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_S start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , … , italic_S start_POSTSUPERSCRIPT italic_M end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT }</annotation></semantics></math>, where <math alttext="N" class="ltx_Math" display="inline" id="S3.SS1.p1.2.m2.1"><semantics id="S3.SS1.p1.2.m2.1a"><mi id="S3.SS1.p1.2.m2.1.1" xref="S3.SS1.p1.2.m2.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.2.m2.1b"><ci id="S3.SS1.p1.2.m2.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.2.m2.1c">N</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.2.m2.1d">italic_N</annotation></semantics></math> datasets contain <math alttext="M" class="ltx_Math" display="inline" id="S3.SS1.p1.3.m3.1"><semantics id="S3.SS1.p1.3.m3.1a"><mi id="S3.SS1.p1.3.m3.1.1" xref="S3.SS1.p1.3.m3.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.3.m3.1b"><ci id="S3.SS1.p1.3.m3.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.3.m3.1c">M</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.3.m3.1d">italic_M</annotation></semantics></math> modalities. Here, <math alttext="S^{m}_{i}=\{X_{ij}^{m},Y_{ij}\}^{n_{i}}_{j=1}" class="ltx_Math" display="inline" id="S3.SS1.p1.4.m4.2"><semantics id="S3.SS1.p1.4.m4.2a"><mrow id="S3.SS1.p1.4.m4.2.2" xref="S3.SS1.p1.4.m4.2.2.cmml"><msubsup id="S3.SS1.p1.4.m4.2.2.4" xref="S3.SS1.p1.4.m4.2.2.4.cmml"><mi id="S3.SS1.p1.4.m4.2.2.4.2.2" xref="S3.SS1.p1.4.m4.2.2.4.2.2.cmml">S</mi><mi id="S3.SS1.p1.4.m4.2.2.4.3" xref="S3.SS1.p1.4.m4.2.2.4.3.cmml">i</mi><mi id="S3.SS1.p1.4.m4.2.2.4.2.3" xref="S3.SS1.p1.4.m4.2.2.4.2.3.cmml">m</mi></msubsup><mo id="S3.SS1.p1.4.m4.2.2.3" xref="S3.SS1.p1.4.m4.2.2.3.cmml">=</mo><msubsup id="S3.SS1.p1.4.m4.2.2.2" xref="S3.SS1.p1.4.m4.2.2.2.cmml"><mrow id="S3.SS1.p1.4.m4.2.2.2.2.2.2" xref="S3.SS1.p1.4.m4.2.2.2.2.2.3.cmml"><mo id="S3.SS1.p1.4.m4.2.2.2.2.2.2.3" stretchy="false" xref="S3.SS1.p1.4.m4.2.2.2.2.2.3.cmml">{</mo><msubsup id="S3.SS1.p1.4.m4.1.1.1.1.1.1.1" xref="S3.SS1.p1.4.m4.1.1.1.1.1.1.1.cmml"><mi id="S3.SS1.p1.4.m4.1.1.1.1.1.1.1.2.2" xref="S3.SS1.p1.4.m4.1.1.1.1.1.1.1.2.2.cmml">X</mi><mrow id="S3.SS1.p1.4.m4.1.1.1.1.1.1.1.2.3" xref="S3.SS1.p1.4.m4.1.1.1.1.1.1.1.2.3.cmml"><mi id="S3.SS1.p1.4.m4.1.1.1.1.1.1.1.2.3.2" xref="S3.SS1.p1.4.m4.1.1.1.1.1.1.1.2.3.2.cmml">i</mi><mo id="S3.SS1.p1.4.m4.1.1.1.1.1.1.1.2.3.1" xref="S3.SS1.p1.4.m4.1.1.1.1.1.1.1.2.3.1.cmml">⁢</mo><mi id="S3.SS1.p1.4.m4.1.1.1.1.1.1.1.2.3.3" xref="S3.SS1.p1.4.m4.1.1.1.1.1.1.1.2.3.3.cmml">j</mi></mrow><mi id="S3.SS1.p1.4.m4.1.1.1.1.1.1.1.3" xref="S3.SS1.p1.4.m4.1.1.1.1.1.1.1.3.cmml">m</mi></msubsup><mo id="S3.SS1.p1.4.m4.2.2.2.2.2.2.4" xref="S3.SS1.p1.4.m4.2.2.2.2.2.3.cmml">,</mo><msub id="S3.SS1.p1.4.m4.2.2.2.2.2.2.2" xref="S3.SS1.p1.4.m4.2.2.2.2.2.2.2.cmml"><mi id="S3.SS1.p1.4.m4.2.2.2.2.2.2.2.2" xref="S3.SS1.p1.4.m4.2.2.2.2.2.2.2.2.cmml">Y</mi><mrow id="S3.SS1.p1.4.m4.2.2.2.2.2.2.2.3" xref="S3.SS1.p1.4.m4.2.2.2.2.2.2.2.3.cmml"><mi id="S3.SS1.p1.4.m4.2.2.2.2.2.2.2.3.2" xref="S3.SS1.p1.4.m4.2.2.2.2.2.2.2.3.2.cmml">i</mi><mo id="S3.SS1.p1.4.m4.2.2.2.2.2.2.2.3.1" xref="S3.SS1.p1.4.m4.2.2.2.2.2.2.2.3.1.cmml">⁢</mo><mi id="S3.SS1.p1.4.m4.2.2.2.2.2.2.2.3.3" xref="S3.SS1.p1.4.m4.2.2.2.2.2.2.2.3.3.cmml">j</mi></mrow></msub><mo id="S3.SS1.p1.4.m4.2.2.2.2.2.2.5" stretchy="false" xref="S3.SS1.p1.4.m4.2.2.2.2.2.3.cmml">}</mo></mrow><mrow id="S3.SS1.p1.4.m4.2.2.2.4" xref="S3.SS1.p1.4.m4.2.2.2.4.cmml"><mi id="S3.SS1.p1.4.m4.2.2.2.4.2" xref="S3.SS1.p1.4.m4.2.2.2.4.2.cmml">j</mi><mo id="S3.SS1.p1.4.m4.2.2.2.4.1" xref="S3.SS1.p1.4.m4.2.2.2.4.1.cmml">=</mo><mn id="S3.SS1.p1.4.m4.2.2.2.4.3" xref="S3.SS1.p1.4.m4.2.2.2.4.3.cmml">1</mn></mrow><msub id="S3.SS1.p1.4.m4.2.2.2.2.4" xref="S3.SS1.p1.4.m4.2.2.2.2.4.cmml"><mi id="S3.SS1.p1.4.m4.2.2.2.2.4.2" xref="S3.SS1.p1.4.m4.2.2.2.2.4.2.cmml">n</mi><mi id="S3.SS1.p1.4.m4.2.2.2.2.4.3" xref="S3.SS1.p1.4.m4.2.2.2.2.4.3.cmml">i</mi></msub></msubsup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.4.m4.2b"><apply id="S3.SS1.p1.4.m4.2.2.cmml" xref="S3.SS1.p1.4.m4.2.2"><eq id="S3.SS1.p1.4.m4.2.2.3.cmml" xref="S3.SS1.p1.4.m4.2.2.3"></eq><apply id="S3.SS1.p1.4.m4.2.2.4.cmml" xref="S3.SS1.p1.4.m4.2.2.4"><csymbol cd="ambiguous" id="S3.SS1.p1.4.m4.2.2.4.1.cmml" xref="S3.SS1.p1.4.m4.2.2.4">subscript</csymbol><apply id="S3.SS1.p1.4.m4.2.2.4.2.cmml" xref="S3.SS1.p1.4.m4.2.2.4"><csymbol cd="ambiguous" id="S3.SS1.p1.4.m4.2.2.4.2.1.cmml" xref="S3.SS1.p1.4.m4.2.2.4">superscript</csymbol><ci id="S3.SS1.p1.4.m4.2.2.4.2.2.cmml" xref="S3.SS1.p1.4.m4.2.2.4.2.2">𝑆</ci><ci id="S3.SS1.p1.4.m4.2.2.4.2.3.cmml" xref="S3.SS1.p1.4.m4.2.2.4.2.3">𝑚</ci></apply><ci id="S3.SS1.p1.4.m4.2.2.4.3.cmml" xref="S3.SS1.p1.4.m4.2.2.4.3">𝑖</ci></apply><apply id="S3.SS1.p1.4.m4.2.2.2.cmml" xref="S3.SS1.p1.4.m4.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p1.4.m4.2.2.2.3.cmml" xref="S3.SS1.p1.4.m4.2.2.2">subscript</csymbol><apply id="S3.SS1.p1.4.m4.2.2.2.2.cmml" xref="S3.SS1.p1.4.m4.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p1.4.m4.2.2.2.2.3.cmml" xref="S3.SS1.p1.4.m4.2.2.2">superscript</csymbol><set id="S3.SS1.p1.4.m4.2.2.2.2.2.3.cmml" xref="S3.SS1.p1.4.m4.2.2.2.2.2.2"><apply id="S3.SS1.p1.4.m4.1.1.1.1.1.1.1.cmml" xref="S3.SS1.p1.4.m4.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.4.m4.1.1.1.1.1.1.1.1.cmml" xref="S3.SS1.p1.4.m4.1.1.1.1.1.1.1">superscript</csymbol><apply id="S3.SS1.p1.4.m4.1.1.1.1.1.1.1.2.cmml" xref="S3.SS1.p1.4.m4.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.4.m4.1.1.1.1.1.1.1.2.1.cmml" xref="S3.SS1.p1.4.m4.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.SS1.p1.4.m4.1.1.1.1.1.1.1.2.2.cmml" xref="S3.SS1.p1.4.m4.1.1.1.1.1.1.1.2.2">𝑋</ci><apply id="S3.SS1.p1.4.m4.1.1.1.1.1.1.1.2.3.cmml" xref="S3.SS1.p1.4.m4.1.1.1.1.1.1.1.2.3"><times id="S3.SS1.p1.4.m4.1.1.1.1.1.1.1.2.3.1.cmml" xref="S3.SS1.p1.4.m4.1.1.1.1.1.1.1.2.3.1"></times><ci id="S3.SS1.p1.4.m4.1.1.1.1.1.1.1.2.3.2.cmml" xref="S3.SS1.p1.4.m4.1.1.1.1.1.1.1.2.3.2">𝑖</ci><ci id="S3.SS1.p1.4.m4.1.1.1.1.1.1.1.2.3.3.cmml" xref="S3.SS1.p1.4.m4.1.1.1.1.1.1.1.2.3.3">𝑗</ci></apply></apply><ci id="S3.SS1.p1.4.m4.1.1.1.1.1.1.1.3.cmml" xref="S3.SS1.p1.4.m4.1.1.1.1.1.1.1.3">𝑚</ci></apply><apply id="S3.SS1.p1.4.m4.2.2.2.2.2.2.2.cmml" xref="S3.SS1.p1.4.m4.2.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p1.4.m4.2.2.2.2.2.2.2.1.cmml" xref="S3.SS1.p1.4.m4.2.2.2.2.2.2.2">subscript</csymbol><ci id="S3.SS1.p1.4.m4.2.2.2.2.2.2.2.2.cmml" xref="S3.SS1.p1.4.m4.2.2.2.2.2.2.2.2">𝑌</ci><apply id="S3.SS1.p1.4.m4.2.2.2.2.2.2.2.3.cmml" xref="S3.SS1.p1.4.m4.2.2.2.2.2.2.2.3"><times id="S3.SS1.p1.4.m4.2.2.2.2.2.2.2.3.1.cmml" xref="S3.SS1.p1.4.m4.2.2.2.2.2.2.2.3.1"></times><ci id="S3.SS1.p1.4.m4.2.2.2.2.2.2.2.3.2.cmml" xref="S3.SS1.p1.4.m4.2.2.2.2.2.2.2.3.2">𝑖</ci><ci id="S3.SS1.p1.4.m4.2.2.2.2.2.2.2.3.3.cmml" xref="S3.SS1.p1.4.m4.2.2.2.2.2.2.2.3.3">𝑗</ci></apply></apply></set><apply id="S3.SS1.p1.4.m4.2.2.2.2.4.cmml" xref="S3.SS1.p1.4.m4.2.2.2.2.4"><csymbol cd="ambiguous" id="S3.SS1.p1.4.m4.2.2.2.2.4.1.cmml" xref="S3.SS1.p1.4.m4.2.2.2.2.4">subscript</csymbol><ci id="S3.SS1.p1.4.m4.2.2.2.2.4.2.cmml" xref="S3.SS1.p1.4.m4.2.2.2.2.4.2">𝑛</ci><ci id="S3.SS1.p1.4.m4.2.2.2.2.4.3.cmml" xref="S3.SS1.p1.4.m4.2.2.2.2.4.3">𝑖</ci></apply></apply><apply id="S3.SS1.p1.4.m4.2.2.2.4.cmml" xref="S3.SS1.p1.4.m4.2.2.2.4"><eq id="S3.SS1.p1.4.m4.2.2.2.4.1.cmml" xref="S3.SS1.p1.4.m4.2.2.2.4.1"></eq><ci id="S3.SS1.p1.4.m4.2.2.2.4.2.cmml" xref="S3.SS1.p1.4.m4.2.2.2.4.2">𝑗</ci><cn id="S3.SS1.p1.4.m4.2.2.2.4.3.cmml" type="integer" xref="S3.SS1.p1.4.m4.2.2.2.4.3">1</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.4.m4.2c">S^{m}_{i}=\{X_{ij}^{m},Y_{ij}\}^{n_{i}}_{j=1}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.4.m4.2d">italic_S start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = { italic_X start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT , italic_Y start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT } start_POSTSUPERSCRIPT italic_n start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_j = 1 end_POSTSUBSCRIPT</annotation></semantics></math> denotes that the <math alttext="i" class="ltx_Math" display="inline" id="S3.SS1.p1.5.m5.1"><semantics id="S3.SS1.p1.5.m5.1a"><mi id="S3.SS1.p1.5.m5.1.1" xref="S3.SS1.p1.5.m5.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.5.m5.1b"><ci id="S3.SS1.p1.5.m5.1.1.cmml" xref="S3.SS1.p1.5.m5.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.5.m5.1c">i</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.5.m5.1d">italic_i</annotation></semantics></math>-th dataset corresponds to the <math alttext="m" class="ltx_Math" display="inline" id="S3.SS1.p1.6.m6.1"><semantics id="S3.SS1.p1.6.m6.1a"><mi id="S3.SS1.p1.6.m6.1.1" xref="S3.SS1.p1.6.m6.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.6.m6.1b"><ci id="S3.SS1.p1.6.m6.1.1.cmml" xref="S3.SS1.p1.6.m6.1.1">𝑚</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.6.m6.1c">m</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.6.m6.1d">italic_m</annotation></semantics></math>-th modality and comprises <math alttext="n_{i}" class="ltx_Math" display="inline" id="S3.SS1.p1.7.m7.1"><semantics id="S3.SS1.p1.7.m7.1a"><msub id="S3.SS1.p1.7.m7.1.1" xref="S3.SS1.p1.7.m7.1.1.cmml"><mi id="S3.SS1.p1.7.m7.1.1.2" xref="S3.SS1.p1.7.m7.1.1.2.cmml">n</mi><mi id="S3.SS1.p1.7.m7.1.1.3" xref="S3.SS1.p1.7.m7.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.7.m7.1b"><apply id="S3.SS1.p1.7.m7.1.1.cmml" xref="S3.SS1.p1.7.m7.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.7.m7.1.1.1.cmml" xref="S3.SS1.p1.7.m7.1.1">subscript</csymbol><ci id="S3.SS1.p1.7.m7.1.1.2.cmml" xref="S3.SS1.p1.7.m7.1.1.2">𝑛</ci><ci id="S3.SS1.p1.7.m7.1.1.3.cmml" xref="S3.SS1.p1.7.m7.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.7.m7.1c">n_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.7.m7.1d">italic_n start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> image-annotation pairs, with <math alttext="X_{ij}^{m}" class="ltx_Math" display="inline" id="S3.SS1.p1.8.m8.1"><semantics id="S3.SS1.p1.8.m8.1a"><msubsup id="S3.SS1.p1.8.m8.1.1" xref="S3.SS1.p1.8.m8.1.1.cmml"><mi id="S3.SS1.p1.8.m8.1.1.2.2" xref="S3.SS1.p1.8.m8.1.1.2.2.cmml">X</mi><mrow id="S3.SS1.p1.8.m8.1.1.2.3" xref="S3.SS1.p1.8.m8.1.1.2.3.cmml"><mi id="S3.SS1.p1.8.m8.1.1.2.3.2" xref="S3.SS1.p1.8.m8.1.1.2.3.2.cmml">i</mi><mo id="S3.SS1.p1.8.m8.1.1.2.3.1" xref="S3.SS1.p1.8.m8.1.1.2.3.1.cmml">⁢</mo><mi id="S3.SS1.p1.8.m8.1.1.2.3.3" xref="S3.SS1.p1.8.m8.1.1.2.3.3.cmml">j</mi></mrow><mi id="S3.SS1.p1.8.m8.1.1.3" xref="S3.SS1.p1.8.m8.1.1.3.cmml">m</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.8.m8.1b"><apply id="S3.SS1.p1.8.m8.1.1.cmml" xref="S3.SS1.p1.8.m8.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.8.m8.1.1.1.cmml" xref="S3.SS1.p1.8.m8.1.1">superscript</csymbol><apply id="S3.SS1.p1.8.m8.1.1.2.cmml" xref="S3.SS1.p1.8.m8.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.8.m8.1.1.2.1.cmml" xref="S3.SS1.p1.8.m8.1.1">subscript</csymbol><ci id="S3.SS1.p1.8.m8.1.1.2.2.cmml" xref="S3.SS1.p1.8.m8.1.1.2.2">𝑋</ci><apply id="S3.SS1.p1.8.m8.1.1.2.3.cmml" xref="S3.SS1.p1.8.m8.1.1.2.3"><times id="S3.SS1.p1.8.m8.1.1.2.3.1.cmml" xref="S3.SS1.p1.8.m8.1.1.2.3.1"></times><ci id="S3.SS1.p1.8.m8.1.1.2.3.2.cmml" xref="S3.SS1.p1.8.m8.1.1.2.3.2">𝑖</ci><ci id="S3.SS1.p1.8.m8.1.1.2.3.3.cmml" xref="S3.SS1.p1.8.m8.1.1.2.3.3">𝑗</ci></apply></apply><ci id="S3.SS1.p1.8.m8.1.1.3.cmml" xref="S3.SS1.p1.8.m8.1.1.3">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.8.m8.1c">X_{ij}^{m}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.8.m8.1d">italic_X start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT</annotation></semantics></math> representing the image and <math alttext="Y_{ij}" class="ltx_Math" display="inline" id="S3.SS1.p1.9.m9.1"><semantics id="S3.SS1.p1.9.m9.1a"><msub id="S3.SS1.p1.9.m9.1.1" xref="S3.SS1.p1.9.m9.1.1.cmml"><mi id="S3.SS1.p1.9.m9.1.1.2" xref="S3.SS1.p1.9.m9.1.1.2.cmml">Y</mi><mrow id="S3.SS1.p1.9.m9.1.1.3" xref="S3.SS1.p1.9.m9.1.1.3.cmml"><mi id="S3.SS1.p1.9.m9.1.1.3.2" xref="S3.SS1.p1.9.m9.1.1.3.2.cmml">i</mi><mo id="S3.SS1.p1.9.m9.1.1.3.1" xref="S3.SS1.p1.9.m9.1.1.3.1.cmml">⁢</mo><mi id="S3.SS1.p1.9.m9.1.1.3.3" xref="S3.SS1.p1.9.m9.1.1.3.3.cmml">j</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.9.m9.1b"><apply id="S3.SS1.p1.9.m9.1.1.cmml" xref="S3.SS1.p1.9.m9.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.9.m9.1.1.1.cmml" xref="S3.SS1.p1.9.m9.1.1">subscript</csymbol><ci id="S3.SS1.p1.9.m9.1.1.2.cmml" xref="S3.SS1.p1.9.m9.1.1.2">𝑌</ci><apply id="S3.SS1.p1.9.m9.1.1.3.cmml" xref="S3.SS1.p1.9.m9.1.1.3"><times id="S3.SS1.p1.9.m9.1.1.3.1.cmml" xref="S3.SS1.p1.9.m9.1.1.3.1"></times><ci id="S3.SS1.p1.9.m9.1.1.3.2.cmml" xref="S3.SS1.p1.9.m9.1.1.3.2">𝑖</ci><ci id="S3.SS1.p1.9.m9.1.1.3.3.cmml" xref="S3.SS1.p1.9.m9.1.1.3.3">𝑗</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.9.m9.1c">Y_{ij}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.9.m9.1d">italic_Y start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT</annotation></semantics></math> the corresponding ground truth annotation.
Traditionally, addressing these <math alttext="N" class="ltx_Math" display="inline" id="S3.SS1.p1.10.m10.1"><semantics id="S3.SS1.p1.10.m10.1a"><mi id="S3.SS1.p1.10.m10.1.1" xref="S3.SS1.p1.10.m10.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.10.m10.1b"><ci id="S3.SS1.p1.10.m10.1.1.cmml" xref="S3.SS1.p1.10.m10.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.10.m10.1c">N</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.10.m10.1d">italic_N</annotation></semantics></math> datasets necessitates training <math alttext="N" class="ltx_Math" display="inline" id="S3.SS1.p1.11.m11.1"><semantics id="S3.SS1.p1.11.m11.1a"><mi id="S3.SS1.p1.11.m11.1.1" xref="S3.SS1.p1.11.m11.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.11.m11.1b"><ci id="S3.SS1.p1.11.m11.1.1.cmml" xref="S3.SS1.p1.11.m11.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.11.m11.1c">N</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.11.m11.1d">italic_N</annotation></semantics></math> separate models, each tailored to a specific dataset. This conventional approach has significant drawbacks: (1) it disperses research efforts across multiple individual tasks, and (2) it fails to utilize the rich and diverse information available across different datasets. To overcome these limitations, we propose MedUniSeg, a universal segmentation model designed to manage multiple tasks across various modalities under a single framework. An overview of MedUniSeg is presented in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#S2.F2" title="Figure 2 ‣ 2.2 Learning from Multi-modal Medical Data ‣ 2 Related Work ‣ MedUniSeg: 2D and 3D Medical Image Segmentation via a Prompt-driven Universal Model"><span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span><span class="ltx_text ltx_font_italic" id="S3.SS2.1.1">Encoder-decoder backbone</span>
</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.6">The core architecture of MedUniSeg is based on nnUNet <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib24" title="">24</a>]</cite> and comprises a vision encoder, a decoder, and a segmentation head, all shared across different tasks. The encoder includes six stages, each featuring two convolutional blocks to extract features while progressively reducing the resolution of the feature map. Each convolutional block consists of a convolutional layer, followed by instance normalization and a LeakyReLU activation. Notably, the first convolutional layer in each stage, except the initial one, employs a stride of 2 to decrease resolution.
To accommodate multi-modality inputs, we modify the first convolutional layer of the model by incorporating four specific convolutional layers tailored to handle inputs with one, two, three, or four channels, respectively. The outputs from the encoder are sample-specific features, denoted as <math alttext="F\in\mathbb{R}^{C_{1}\times\frac{D}{16}\times\frac{H}{32}\times\frac{W}{32}}" class="ltx_Math" display="inline" id="S3.SS2.p1.1.m1.1"><semantics id="S3.SS2.p1.1.m1.1a"><mrow id="S3.SS2.p1.1.m1.1.1" xref="S3.SS2.p1.1.m1.1.1.cmml"><mi id="S3.SS2.p1.1.m1.1.1.2" xref="S3.SS2.p1.1.m1.1.1.2.cmml">F</mi><mo id="S3.SS2.p1.1.m1.1.1.1" xref="S3.SS2.p1.1.m1.1.1.1.cmml">∈</mo><msup id="S3.SS2.p1.1.m1.1.1.3" xref="S3.SS2.p1.1.m1.1.1.3.cmml"><mi id="S3.SS2.p1.1.m1.1.1.3.2" xref="S3.SS2.p1.1.m1.1.1.3.2.cmml">ℝ</mi><mrow id="S3.SS2.p1.1.m1.1.1.3.3" xref="S3.SS2.p1.1.m1.1.1.3.3.cmml"><msub id="S3.SS2.p1.1.m1.1.1.3.3.2" xref="S3.SS2.p1.1.m1.1.1.3.3.2.cmml"><mi id="S3.SS2.p1.1.m1.1.1.3.3.2.2" xref="S3.SS2.p1.1.m1.1.1.3.3.2.2.cmml">C</mi><mn id="S3.SS2.p1.1.m1.1.1.3.3.2.3" xref="S3.SS2.p1.1.m1.1.1.3.3.2.3.cmml">1</mn></msub><mo id="S3.SS2.p1.1.m1.1.1.3.3.1" lspace="0.222em" rspace="0.222em" xref="S3.SS2.p1.1.m1.1.1.3.3.1.cmml">×</mo><mfrac id="S3.SS2.p1.1.m1.1.1.3.3.3" xref="S3.SS2.p1.1.m1.1.1.3.3.3.cmml"><mi id="S3.SS2.p1.1.m1.1.1.3.3.3.2" xref="S3.SS2.p1.1.m1.1.1.3.3.3.2.cmml">D</mi><mn id="S3.SS2.p1.1.m1.1.1.3.3.3.3" xref="S3.SS2.p1.1.m1.1.1.3.3.3.3.cmml">16</mn></mfrac><mo id="S3.SS2.p1.1.m1.1.1.3.3.1a" lspace="0.222em" rspace="0.222em" xref="S3.SS2.p1.1.m1.1.1.3.3.1.cmml">×</mo><mfrac id="S3.SS2.p1.1.m1.1.1.3.3.4" xref="S3.SS2.p1.1.m1.1.1.3.3.4.cmml"><mi id="S3.SS2.p1.1.m1.1.1.3.3.4.2" xref="S3.SS2.p1.1.m1.1.1.3.3.4.2.cmml">H</mi><mn id="S3.SS2.p1.1.m1.1.1.3.3.4.3" xref="S3.SS2.p1.1.m1.1.1.3.3.4.3.cmml">32</mn></mfrac><mo id="S3.SS2.p1.1.m1.1.1.3.3.1b" lspace="0.222em" rspace="0.222em" xref="S3.SS2.p1.1.m1.1.1.3.3.1.cmml">×</mo><mfrac id="S3.SS2.p1.1.m1.1.1.3.3.5" xref="S3.SS2.p1.1.m1.1.1.3.3.5.cmml"><mi id="S3.SS2.p1.1.m1.1.1.3.3.5.2" xref="S3.SS2.p1.1.m1.1.1.3.3.5.2.cmml">W</mi><mn id="S3.SS2.p1.1.m1.1.1.3.3.5.3" xref="S3.SS2.p1.1.m1.1.1.3.3.5.3.cmml">32</mn></mfrac></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.m1.1b"><apply id="S3.SS2.p1.1.m1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1"><in id="S3.SS2.p1.1.m1.1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1.1"></in><ci id="S3.SS2.p1.1.m1.1.1.2.cmml" xref="S3.SS2.p1.1.m1.1.1.2">𝐹</ci><apply id="S3.SS2.p1.1.m1.1.1.3.cmml" xref="S3.SS2.p1.1.m1.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.p1.1.m1.1.1.3.1.cmml" xref="S3.SS2.p1.1.m1.1.1.3">superscript</csymbol><ci id="S3.SS2.p1.1.m1.1.1.3.2.cmml" xref="S3.SS2.p1.1.m1.1.1.3.2">ℝ</ci><apply id="S3.SS2.p1.1.m1.1.1.3.3.cmml" xref="S3.SS2.p1.1.m1.1.1.3.3"><times id="S3.SS2.p1.1.m1.1.1.3.3.1.cmml" xref="S3.SS2.p1.1.m1.1.1.3.3.1"></times><apply id="S3.SS2.p1.1.m1.1.1.3.3.2.cmml" xref="S3.SS2.p1.1.m1.1.1.3.3.2"><csymbol cd="ambiguous" id="S3.SS2.p1.1.m1.1.1.3.3.2.1.cmml" xref="S3.SS2.p1.1.m1.1.1.3.3.2">subscript</csymbol><ci id="S3.SS2.p1.1.m1.1.1.3.3.2.2.cmml" xref="S3.SS2.p1.1.m1.1.1.3.3.2.2">𝐶</ci><cn id="S3.SS2.p1.1.m1.1.1.3.3.2.3.cmml" type="integer" xref="S3.SS2.p1.1.m1.1.1.3.3.2.3">1</cn></apply><apply id="S3.SS2.p1.1.m1.1.1.3.3.3.cmml" xref="S3.SS2.p1.1.m1.1.1.3.3.3"><divide id="S3.SS2.p1.1.m1.1.1.3.3.3.1.cmml" xref="S3.SS2.p1.1.m1.1.1.3.3.3"></divide><ci id="S3.SS2.p1.1.m1.1.1.3.3.3.2.cmml" xref="S3.SS2.p1.1.m1.1.1.3.3.3.2">𝐷</ci><cn id="S3.SS2.p1.1.m1.1.1.3.3.3.3.cmml" type="integer" xref="S3.SS2.p1.1.m1.1.1.3.3.3.3">16</cn></apply><apply id="S3.SS2.p1.1.m1.1.1.3.3.4.cmml" xref="S3.SS2.p1.1.m1.1.1.3.3.4"><divide id="S3.SS2.p1.1.m1.1.1.3.3.4.1.cmml" xref="S3.SS2.p1.1.m1.1.1.3.3.4"></divide><ci id="S3.SS2.p1.1.m1.1.1.3.3.4.2.cmml" xref="S3.SS2.p1.1.m1.1.1.3.3.4.2">𝐻</ci><cn id="S3.SS2.p1.1.m1.1.1.3.3.4.3.cmml" type="integer" xref="S3.SS2.p1.1.m1.1.1.3.3.4.3">32</cn></apply><apply id="S3.SS2.p1.1.m1.1.1.3.3.5.cmml" xref="S3.SS2.p1.1.m1.1.1.3.3.5"><divide id="S3.SS2.p1.1.m1.1.1.3.3.5.1.cmml" xref="S3.SS2.p1.1.m1.1.1.3.3.5"></divide><ci id="S3.SS2.p1.1.m1.1.1.3.3.5.2.cmml" xref="S3.SS2.p1.1.m1.1.1.3.3.5.2">𝑊</ci><cn id="S3.SS2.p1.1.m1.1.1.3.3.5.3.cmml" type="integer" xref="S3.SS2.p1.1.m1.1.1.3.3.5.3">32</cn></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.1.m1.1c">F\in\mathbb{R}^{C_{1}\times\frac{D}{16}\times\frac{H}{32}\times\frac{W}{32}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.1.m1.1d">italic_F ∈ blackboard_R start_POSTSUPERSCRIPT italic_C start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT × divide start_ARG italic_D end_ARG start_ARG 16 end_ARG × divide start_ARG italic_H end_ARG start_ARG 32 end_ARG × divide start_ARG italic_W end_ARG start_ARG 32 end_ARG end_POSTSUPERSCRIPT</annotation></semantics></math>, where <math alttext="C_{1}" class="ltx_Math" display="inline" id="S3.SS2.p1.2.m2.1"><semantics id="S3.SS2.p1.2.m2.1a"><msub id="S3.SS2.p1.2.m2.1.1" xref="S3.SS2.p1.2.m2.1.1.cmml"><mi id="S3.SS2.p1.2.m2.1.1.2" xref="S3.SS2.p1.2.m2.1.1.2.cmml">C</mi><mn id="S3.SS2.p1.2.m2.1.1.3" xref="S3.SS2.p1.2.m2.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.2.m2.1b"><apply id="S3.SS2.p1.2.m2.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.2.m2.1.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1">subscript</csymbol><ci id="S3.SS2.p1.2.m2.1.1.2.cmml" xref="S3.SS2.p1.2.m2.1.1.2">𝐶</ci><cn id="S3.SS2.p1.2.m2.1.1.3.cmml" type="integer" xref="S3.SS2.p1.2.m2.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.2.m2.1c">C_{1}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.2.m2.1d">italic_C start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math> is the number of channels, and <math alttext="D" class="ltx_Math" display="inline" id="S3.SS2.p1.3.m3.1"><semantics id="S3.SS2.p1.3.m3.1a"><mi id="S3.SS2.p1.3.m3.1.1" xref="S3.SS2.p1.3.m3.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.3.m3.1b"><ci id="S3.SS2.p1.3.m3.1.1.cmml" xref="S3.SS2.p1.3.m3.1.1">𝐷</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.3.m3.1c">D</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.3.m3.1d">italic_D</annotation></semantics></math>, <math alttext="H" class="ltx_Math" display="inline" id="S3.SS2.p1.4.m4.1"><semantics id="S3.SS2.p1.4.m4.1a"><mi id="S3.SS2.p1.4.m4.1.1" xref="S3.SS2.p1.4.m4.1.1.cmml">H</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.4.m4.1b"><ci id="S3.SS2.p1.4.m4.1.1.cmml" xref="S3.SS2.p1.4.m4.1.1">𝐻</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.4.m4.1c">H</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.4.m4.1d">italic_H</annotation></semantics></math>, and <math alttext="W" class="ltx_Math" display="inline" id="S3.SS2.p1.5.m5.1"><semantics id="S3.SS2.p1.5.m5.1a"><mi id="S3.SS2.p1.5.m5.1.1" xref="S3.SS2.p1.5.m5.1.1.cmml">W</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.5.m5.1b"><ci id="S3.SS2.p1.5.m5.1.1.cmml" xref="S3.SS2.p1.5.m5.1.1">𝑊</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.5.m5.1c">W</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.5.m5.1d">italic_W</annotation></semantics></math> indicate the depth, height, and width of the input, respectively.
In the decoder, each stage begins with an upsampling operation using a transposed convolution layer to gradually recover resolution while reducing the number of channels. The upsampled features are then concatenated with the corresponding outputs from the encoder and processed through two convolutional blocks. After the decoder stages, the output feature maps are passed through a segmentation head to produce segmentation maps, guided by a deep supervision strategy. The supervision signals are derived from a combination of Dice loss and cross-entropy loss to refine the training process.
The channel number for the multi-scale segmentation maps is set to the maximum number of classes across all tasks. For instance, in a scenario with datasets <math alttext="S^{1}_{1},S^{1}_{2},S^{2}_{3}" class="ltx_Math" display="inline" id="S3.SS2.p1.6.m6.3"><semantics id="S3.SS2.p1.6.m6.3a"><mrow id="S3.SS2.p1.6.m6.3.3.3" xref="S3.SS2.p1.6.m6.3.3.4.cmml"><msubsup id="S3.SS2.p1.6.m6.1.1.1.1" xref="S3.SS2.p1.6.m6.1.1.1.1.cmml"><mi id="S3.SS2.p1.6.m6.1.1.1.1.2.2" xref="S3.SS2.p1.6.m6.1.1.1.1.2.2.cmml">S</mi><mn id="S3.SS2.p1.6.m6.1.1.1.1.3" xref="S3.SS2.p1.6.m6.1.1.1.1.3.cmml">1</mn><mn id="S3.SS2.p1.6.m6.1.1.1.1.2.3" xref="S3.SS2.p1.6.m6.1.1.1.1.2.3.cmml">1</mn></msubsup><mo id="S3.SS2.p1.6.m6.3.3.3.4" xref="S3.SS2.p1.6.m6.3.3.4.cmml">,</mo><msubsup id="S3.SS2.p1.6.m6.2.2.2.2" xref="S3.SS2.p1.6.m6.2.2.2.2.cmml"><mi id="S3.SS2.p1.6.m6.2.2.2.2.2.2" xref="S3.SS2.p1.6.m6.2.2.2.2.2.2.cmml">S</mi><mn id="S3.SS2.p1.6.m6.2.2.2.2.3" xref="S3.SS2.p1.6.m6.2.2.2.2.3.cmml">2</mn><mn id="S3.SS2.p1.6.m6.2.2.2.2.2.3" xref="S3.SS2.p1.6.m6.2.2.2.2.2.3.cmml">1</mn></msubsup><mo id="S3.SS2.p1.6.m6.3.3.3.5" xref="S3.SS2.p1.6.m6.3.3.4.cmml">,</mo><msubsup id="S3.SS2.p1.6.m6.3.3.3.3" xref="S3.SS2.p1.6.m6.3.3.3.3.cmml"><mi id="S3.SS2.p1.6.m6.3.3.3.3.2.2" xref="S3.SS2.p1.6.m6.3.3.3.3.2.2.cmml">S</mi><mn id="S3.SS2.p1.6.m6.3.3.3.3.3" xref="S3.SS2.p1.6.m6.3.3.3.3.3.cmml">3</mn><mn id="S3.SS2.p1.6.m6.3.3.3.3.2.3" xref="S3.SS2.p1.6.m6.3.3.3.3.2.3.cmml">2</mn></msubsup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.6.m6.3b"><list id="S3.SS2.p1.6.m6.3.3.4.cmml" xref="S3.SS2.p1.6.m6.3.3.3"><apply id="S3.SS2.p1.6.m6.1.1.1.1.cmml" xref="S3.SS2.p1.6.m6.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.6.m6.1.1.1.1.1.cmml" xref="S3.SS2.p1.6.m6.1.1.1.1">subscript</csymbol><apply id="S3.SS2.p1.6.m6.1.1.1.1.2.cmml" xref="S3.SS2.p1.6.m6.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.6.m6.1.1.1.1.2.1.cmml" xref="S3.SS2.p1.6.m6.1.1.1.1">superscript</csymbol><ci id="S3.SS2.p1.6.m6.1.1.1.1.2.2.cmml" xref="S3.SS2.p1.6.m6.1.1.1.1.2.2">𝑆</ci><cn id="S3.SS2.p1.6.m6.1.1.1.1.2.3.cmml" type="integer" xref="S3.SS2.p1.6.m6.1.1.1.1.2.3">1</cn></apply><cn id="S3.SS2.p1.6.m6.1.1.1.1.3.cmml" type="integer" xref="S3.SS2.p1.6.m6.1.1.1.1.3">1</cn></apply><apply id="S3.SS2.p1.6.m6.2.2.2.2.cmml" xref="S3.SS2.p1.6.m6.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.p1.6.m6.2.2.2.2.1.cmml" xref="S3.SS2.p1.6.m6.2.2.2.2">subscript</csymbol><apply id="S3.SS2.p1.6.m6.2.2.2.2.2.cmml" xref="S3.SS2.p1.6.m6.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.p1.6.m6.2.2.2.2.2.1.cmml" xref="S3.SS2.p1.6.m6.2.2.2.2">superscript</csymbol><ci id="S3.SS2.p1.6.m6.2.2.2.2.2.2.cmml" xref="S3.SS2.p1.6.m6.2.2.2.2.2.2">𝑆</ci><cn id="S3.SS2.p1.6.m6.2.2.2.2.2.3.cmml" type="integer" xref="S3.SS2.p1.6.m6.2.2.2.2.2.3">1</cn></apply><cn id="S3.SS2.p1.6.m6.2.2.2.2.3.cmml" type="integer" xref="S3.SS2.p1.6.m6.2.2.2.2.3">2</cn></apply><apply id="S3.SS2.p1.6.m6.3.3.3.3.cmml" xref="S3.SS2.p1.6.m6.3.3.3.3"><csymbol cd="ambiguous" id="S3.SS2.p1.6.m6.3.3.3.3.1.cmml" xref="S3.SS2.p1.6.m6.3.3.3.3">subscript</csymbol><apply id="S3.SS2.p1.6.m6.3.3.3.3.2.cmml" xref="S3.SS2.p1.6.m6.3.3.3.3"><csymbol cd="ambiguous" id="S3.SS2.p1.6.m6.3.3.3.3.2.1.cmml" xref="S3.SS2.p1.6.m6.3.3.3.3">superscript</csymbol><ci id="S3.SS2.p1.6.m6.3.3.3.3.2.2.cmml" xref="S3.SS2.p1.6.m6.3.3.3.3.2.2">𝑆</ci><cn id="S3.SS2.p1.6.m6.3.3.3.3.2.3.cmml" type="integer" xref="S3.SS2.p1.6.m6.3.3.3.3.2.3">2</cn></apply><cn id="S3.SS2.p1.6.m6.3.3.3.3.3.cmml" type="integer" xref="S3.SS2.p1.6.m6.3.3.3.3.3">3</cn></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.6.m6.3c">S^{1}_{1},S^{1}_{2},S^{2}_{3}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.6.m6.3d">italic_S start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_S start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_S start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT</annotation></semantics></math> having class numbers of 5, 6, and 7 (including background classes), respectively, the output channel number is set to 7. Thanks to the prompt-based design (see Sections <a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#S3.SS3" title="3.3 Universal Task Prompt for Dynamic Task Priors ‣ 3 Method ‣ MedUniSeg: 2D and 3D Medical Image Segmentation via a Prompt-driven Universal Model"><span class="ltx_text ltx_ref_tag">3.3</span></a>), our method provides a significant advantage over multi-class models, which typically require up to 15 channels (<span class="ltx_text ltx_font_italic" id="S3.SS2.p1.6.1">i.e.</span>, 4+5+6), as these models often utilize binary cross-entropy loss, excluding the background class from the count.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span><span class="ltx_text ltx_font_italic" id="S3.SS3.1.1">Universal Task Prompt for Dynamic Task Priors</span>
</h3>
<div class="ltx_para" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.5">We posit that there exist correlations among different segmentation tasks<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib23" title="">23</a>]</cite>.
Recognizing the complexity of manually crafting these correlations, we introduce a learnable prompt, termed the universal task prompt, to effectively describe them, promoting interaction and fusion among various task priors. The universal task prompt is defined as <math alttext="F_{uni}\in\mathbb{R}^{K\times\frac{D_{3d}}{16}\times\frac{H_{3d}}{32}\times%
\frac{W_{3d}}{32}}" class="ltx_Math" display="inline" id="S3.SS3.p1.1.m1.1"><semantics id="S3.SS3.p1.1.m1.1a"><mrow id="S3.SS3.p1.1.m1.1.1" xref="S3.SS3.p1.1.m1.1.1.cmml"><msub id="S3.SS3.p1.1.m1.1.1.2" xref="S3.SS3.p1.1.m1.1.1.2.cmml"><mi id="S3.SS3.p1.1.m1.1.1.2.2" xref="S3.SS3.p1.1.m1.1.1.2.2.cmml">F</mi><mrow id="S3.SS3.p1.1.m1.1.1.2.3" xref="S3.SS3.p1.1.m1.1.1.2.3.cmml"><mi id="S3.SS3.p1.1.m1.1.1.2.3.2" xref="S3.SS3.p1.1.m1.1.1.2.3.2.cmml">u</mi><mo id="S3.SS3.p1.1.m1.1.1.2.3.1" xref="S3.SS3.p1.1.m1.1.1.2.3.1.cmml">⁢</mo><mi id="S3.SS3.p1.1.m1.1.1.2.3.3" xref="S3.SS3.p1.1.m1.1.1.2.3.3.cmml">n</mi><mo id="S3.SS3.p1.1.m1.1.1.2.3.1a" xref="S3.SS3.p1.1.m1.1.1.2.3.1.cmml">⁢</mo><mi id="S3.SS3.p1.1.m1.1.1.2.3.4" xref="S3.SS3.p1.1.m1.1.1.2.3.4.cmml">i</mi></mrow></msub><mo id="S3.SS3.p1.1.m1.1.1.1" xref="S3.SS3.p1.1.m1.1.1.1.cmml">∈</mo><msup id="S3.SS3.p1.1.m1.1.1.3" xref="S3.SS3.p1.1.m1.1.1.3.cmml"><mi id="S3.SS3.p1.1.m1.1.1.3.2" xref="S3.SS3.p1.1.m1.1.1.3.2.cmml">ℝ</mi><mrow id="S3.SS3.p1.1.m1.1.1.3.3" xref="S3.SS3.p1.1.m1.1.1.3.3.cmml"><mi id="S3.SS3.p1.1.m1.1.1.3.3.2" xref="S3.SS3.p1.1.m1.1.1.3.3.2.cmml">K</mi><mo id="S3.SS3.p1.1.m1.1.1.3.3.1" lspace="0.222em" rspace="0.222em" xref="S3.SS3.p1.1.m1.1.1.3.3.1.cmml">×</mo><mfrac id="S3.SS3.p1.1.m1.1.1.3.3.3" xref="S3.SS3.p1.1.m1.1.1.3.3.3.cmml"><msub id="S3.SS3.p1.1.m1.1.1.3.3.3.2" xref="S3.SS3.p1.1.m1.1.1.3.3.3.2.cmml"><mi id="S3.SS3.p1.1.m1.1.1.3.3.3.2.2" xref="S3.SS3.p1.1.m1.1.1.3.3.3.2.2.cmml">D</mi><mrow id="S3.SS3.p1.1.m1.1.1.3.3.3.2.3" xref="S3.SS3.p1.1.m1.1.1.3.3.3.2.3.cmml"><mn id="S3.SS3.p1.1.m1.1.1.3.3.3.2.3.2" xref="S3.SS3.p1.1.m1.1.1.3.3.3.2.3.2.cmml">3</mn><mo id="S3.SS3.p1.1.m1.1.1.3.3.3.2.3.1" xref="S3.SS3.p1.1.m1.1.1.3.3.3.2.3.1.cmml">⁢</mo><mi id="S3.SS3.p1.1.m1.1.1.3.3.3.2.3.3" xref="S3.SS3.p1.1.m1.1.1.3.3.3.2.3.3.cmml">d</mi></mrow></msub><mn id="S3.SS3.p1.1.m1.1.1.3.3.3.3" xref="S3.SS3.p1.1.m1.1.1.3.3.3.3.cmml">16</mn></mfrac><mo id="S3.SS3.p1.1.m1.1.1.3.3.1a" lspace="0.222em" rspace="0.222em" xref="S3.SS3.p1.1.m1.1.1.3.3.1.cmml">×</mo><mfrac id="S3.SS3.p1.1.m1.1.1.3.3.4" xref="S3.SS3.p1.1.m1.1.1.3.3.4.cmml"><msub id="S3.SS3.p1.1.m1.1.1.3.3.4.2" xref="S3.SS3.p1.1.m1.1.1.3.3.4.2.cmml"><mi id="S3.SS3.p1.1.m1.1.1.3.3.4.2.2" xref="S3.SS3.p1.1.m1.1.1.3.3.4.2.2.cmml">H</mi><mrow id="S3.SS3.p1.1.m1.1.1.3.3.4.2.3" xref="S3.SS3.p1.1.m1.1.1.3.3.4.2.3.cmml"><mn id="S3.SS3.p1.1.m1.1.1.3.3.4.2.3.2" xref="S3.SS3.p1.1.m1.1.1.3.3.4.2.3.2.cmml">3</mn><mo id="S3.SS3.p1.1.m1.1.1.3.3.4.2.3.1" xref="S3.SS3.p1.1.m1.1.1.3.3.4.2.3.1.cmml">⁢</mo><mi id="S3.SS3.p1.1.m1.1.1.3.3.4.2.3.3" xref="S3.SS3.p1.1.m1.1.1.3.3.4.2.3.3.cmml">d</mi></mrow></msub><mn id="S3.SS3.p1.1.m1.1.1.3.3.4.3" xref="S3.SS3.p1.1.m1.1.1.3.3.4.3.cmml">32</mn></mfrac><mo id="S3.SS3.p1.1.m1.1.1.3.3.1b" lspace="0.222em" rspace="0.222em" xref="S3.SS3.p1.1.m1.1.1.3.3.1.cmml">×</mo><mfrac id="S3.SS3.p1.1.m1.1.1.3.3.5" xref="S3.SS3.p1.1.m1.1.1.3.3.5.cmml"><msub id="S3.SS3.p1.1.m1.1.1.3.3.5.2" xref="S3.SS3.p1.1.m1.1.1.3.3.5.2.cmml"><mi id="S3.SS3.p1.1.m1.1.1.3.3.5.2.2" xref="S3.SS3.p1.1.m1.1.1.3.3.5.2.2.cmml">W</mi><mrow id="S3.SS3.p1.1.m1.1.1.3.3.5.2.3" xref="S3.SS3.p1.1.m1.1.1.3.3.5.2.3.cmml"><mn id="S3.SS3.p1.1.m1.1.1.3.3.5.2.3.2" xref="S3.SS3.p1.1.m1.1.1.3.3.5.2.3.2.cmml">3</mn><mo id="S3.SS3.p1.1.m1.1.1.3.3.5.2.3.1" xref="S3.SS3.p1.1.m1.1.1.3.3.5.2.3.1.cmml">⁢</mo><mi id="S3.SS3.p1.1.m1.1.1.3.3.5.2.3.3" xref="S3.SS3.p1.1.m1.1.1.3.3.5.2.3.3.cmml">d</mi></mrow></msub><mn id="S3.SS3.p1.1.m1.1.1.3.3.5.3" xref="S3.SS3.p1.1.m1.1.1.3.3.5.3.cmml">32</mn></mfrac></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.1.m1.1b"><apply id="S3.SS3.p1.1.m1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1"><in id="S3.SS3.p1.1.m1.1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1.1"></in><apply id="S3.SS3.p1.1.m1.1.1.2.cmml" xref="S3.SS3.p1.1.m1.1.1.2"><csymbol cd="ambiguous" id="S3.SS3.p1.1.m1.1.1.2.1.cmml" xref="S3.SS3.p1.1.m1.1.1.2">subscript</csymbol><ci id="S3.SS3.p1.1.m1.1.1.2.2.cmml" xref="S3.SS3.p1.1.m1.1.1.2.2">𝐹</ci><apply id="S3.SS3.p1.1.m1.1.1.2.3.cmml" xref="S3.SS3.p1.1.m1.1.1.2.3"><times id="S3.SS3.p1.1.m1.1.1.2.3.1.cmml" xref="S3.SS3.p1.1.m1.1.1.2.3.1"></times><ci id="S3.SS3.p1.1.m1.1.1.2.3.2.cmml" xref="S3.SS3.p1.1.m1.1.1.2.3.2">𝑢</ci><ci id="S3.SS3.p1.1.m1.1.1.2.3.3.cmml" xref="S3.SS3.p1.1.m1.1.1.2.3.3">𝑛</ci><ci id="S3.SS3.p1.1.m1.1.1.2.3.4.cmml" xref="S3.SS3.p1.1.m1.1.1.2.3.4">𝑖</ci></apply></apply><apply id="S3.SS3.p1.1.m1.1.1.3.cmml" xref="S3.SS3.p1.1.m1.1.1.3"><csymbol cd="ambiguous" id="S3.SS3.p1.1.m1.1.1.3.1.cmml" xref="S3.SS3.p1.1.m1.1.1.3">superscript</csymbol><ci id="S3.SS3.p1.1.m1.1.1.3.2.cmml" xref="S3.SS3.p1.1.m1.1.1.3.2">ℝ</ci><apply id="S3.SS3.p1.1.m1.1.1.3.3.cmml" xref="S3.SS3.p1.1.m1.1.1.3.3"><times id="S3.SS3.p1.1.m1.1.1.3.3.1.cmml" xref="S3.SS3.p1.1.m1.1.1.3.3.1"></times><ci id="S3.SS3.p1.1.m1.1.1.3.3.2.cmml" xref="S3.SS3.p1.1.m1.1.1.3.3.2">𝐾</ci><apply id="S3.SS3.p1.1.m1.1.1.3.3.3.cmml" xref="S3.SS3.p1.1.m1.1.1.3.3.3"><divide id="S3.SS3.p1.1.m1.1.1.3.3.3.1.cmml" xref="S3.SS3.p1.1.m1.1.1.3.3.3"></divide><apply id="S3.SS3.p1.1.m1.1.1.3.3.3.2.cmml" xref="S3.SS3.p1.1.m1.1.1.3.3.3.2"><csymbol cd="ambiguous" id="S3.SS3.p1.1.m1.1.1.3.3.3.2.1.cmml" xref="S3.SS3.p1.1.m1.1.1.3.3.3.2">subscript</csymbol><ci id="S3.SS3.p1.1.m1.1.1.3.3.3.2.2.cmml" xref="S3.SS3.p1.1.m1.1.1.3.3.3.2.2">𝐷</ci><apply id="S3.SS3.p1.1.m1.1.1.3.3.3.2.3.cmml" xref="S3.SS3.p1.1.m1.1.1.3.3.3.2.3"><times id="S3.SS3.p1.1.m1.1.1.3.3.3.2.3.1.cmml" xref="S3.SS3.p1.1.m1.1.1.3.3.3.2.3.1"></times><cn id="S3.SS3.p1.1.m1.1.1.3.3.3.2.3.2.cmml" type="integer" xref="S3.SS3.p1.1.m1.1.1.3.3.3.2.3.2">3</cn><ci id="S3.SS3.p1.1.m1.1.1.3.3.3.2.3.3.cmml" xref="S3.SS3.p1.1.m1.1.1.3.3.3.2.3.3">𝑑</ci></apply></apply><cn id="S3.SS3.p1.1.m1.1.1.3.3.3.3.cmml" type="integer" xref="S3.SS3.p1.1.m1.1.1.3.3.3.3">16</cn></apply><apply id="S3.SS3.p1.1.m1.1.1.3.3.4.cmml" xref="S3.SS3.p1.1.m1.1.1.3.3.4"><divide id="S3.SS3.p1.1.m1.1.1.3.3.4.1.cmml" xref="S3.SS3.p1.1.m1.1.1.3.3.4"></divide><apply id="S3.SS3.p1.1.m1.1.1.3.3.4.2.cmml" xref="S3.SS3.p1.1.m1.1.1.3.3.4.2"><csymbol cd="ambiguous" id="S3.SS3.p1.1.m1.1.1.3.3.4.2.1.cmml" xref="S3.SS3.p1.1.m1.1.1.3.3.4.2">subscript</csymbol><ci id="S3.SS3.p1.1.m1.1.1.3.3.4.2.2.cmml" xref="S3.SS3.p1.1.m1.1.1.3.3.4.2.2">𝐻</ci><apply id="S3.SS3.p1.1.m1.1.1.3.3.4.2.3.cmml" xref="S3.SS3.p1.1.m1.1.1.3.3.4.2.3"><times id="S3.SS3.p1.1.m1.1.1.3.3.4.2.3.1.cmml" xref="S3.SS3.p1.1.m1.1.1.3.3.4.2.3.1"></times><cn id="S3.SS3.p1.1.m1.1.1.3.3.4.2.3.2.cmml" type="integer" xref="S3.SS3.p1.1.m1.1.1.3.3.4.2.3.2">3</cn><ci id="S3.SS3.p1.1.m1.1.1.3.3.4.2.3.3.cmml" xref="S3.SS3.p1.1.m1.1.1.3.3.4.2.3.3">𝑑</ci></apply></apply><cn id="S3.SS3.p1.1.m1.1.1.3.3.4.3.cmml" type="integer" xref="S3.SS3.p1.1.m1.1.1.3.3.4.3">32</cn></apply><apply id="S3.SS3.p1.1.m1.1.1.3.3.5.cmml" xref="S3.SS3.p1.1.m1.1.1.3.3.5"><divide id="S3.SS3.p1.1.m1.1.1.3.3.5.1.cmml" xref="S3.SS3.p1.1.m1.1.1.3.3.5"></divide><apply id="S3.SS3.p1.1.m1.1.1.3.3.5.2.cmml" xref="S3.SS3.p1.1.m1.1.1.3.3.5.2"><csymbol cd="ambiguous" id="S3.SS3.p1.1.m1.1.1.3.3.5.2.1.cmml" xref="S3.SS3.p1.1.m1.1.1.3.3.5.2">subscript</csymbol><ci id="S3.SS3.p1.1.m1.1.1.3.3.5.2.2.cmml" xref="S3.SS3.p1.1.m1.1.1.3.3.5.2.2">𝑊</ci><apply id="S3.SS3.p1.1.m1.1.1.3.3.5.2.3.cmml" xref="S3.SS3.p1.1.m1.1.1.3.3.5.2.3"><times id="S3.SS3.p1.1.m1.1.1.3.3.5.2.3.1.cmml" xref="S3.SS3.p1.1.m1.1.1.3.3.5.2.3.1"></times><cn id="S3.SS3.p1.1.m1.1.1.3.3.5.2.3.2.cmml" type="integer" xref="S3.SS3.p1.1.m1.1.1.3.3.5.2.3.2">3</cn><ci id="S3.SS3.p1.1.m1.1.1.3.3.5.2.3.3.cmml" xref="S3.SS3.p1.1.m1.1.1.3.3.5.2.3.3">𝑑</ci></apply></apply><cn id="S3.SS3.p1.1.m1.1.1.3.3.5.3.cmml" type="integer" xref="S3.SS3.p1.1.m1.1.1.3.3.5.3">32</cn></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.1.m1.1c">F_{uni}\in\mathbb{R}^{K\times\frac{D_{3d}}{16}\times\frac{H_{3d}}{32}\times%
\frac{W_{3d}}{32}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.1.m1.1d">italic_F start_POSTSUBSCRIPT italic_u italic_n italic_i end_POSTSUBSCRIPT ∈ blackboard_R start_POSTSUPERSCRIPT italic_K × divide start_ARG italic_D start_POSTSUBSCRIPT 3 italic_d end_POSTSUBSCRIPT end_ARG start_ARG 16 end_ARG × divide start_ARG italic_H start_POSTSUBSCRIPT 3 italic_d end_POSTSUBSCRIPT end_ARG start_ARG 32 end_ARG × divide start_ARG italic_W start_POSTSUBSCRIPT 3 italic_d end_POSTSUBSCRIPT end_ARG start_ARG 32 end_ARG end_POSTSUPERSCRIPT</annotation></semantics></math>, where <math alttext="K" class="ltx_Math" display="inline" id="S3.SS3.p1.2.m2.1"><semantics id="S3.SS3.p1.2.m2.1a"><mi id="S3.SS3.p1.2.m2.1.1" xref="S3.SS3.p1.2.m2.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.2.m2.1b"><ci id="S3.SS3.p1.2.m2.1.1.cmml" xref="S3.SS3.p1.2.m2.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.2.m2.1c">K</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.2.m2.1d">italic_K</annotation></semantics></math> is a hyperparameter, and <math alttext="D_{3d}" class="ltx_Math" display="inline" id="S3.SS3.p1.3.m3.1"><semantics id="S3.SS3.p1.3.m3.1a"><msub id="S3.SS3.p1.3.m3.1.1" xref="S3.SS3.p1.3.m3.1.1.cmml"><mi id="S3.SS3.p1.3.m3.1.1.2" xref="S3.SS3.p1.3.m3.1.1.2.cmml">D</mi><mrow id="S3.SS3.p1.3.m3.1.1.3" xref="S3.SS3.p1.3.m3.1.1.3.cmml"><mn id="S3.SS3.p1.3.m3.1.1.3.2" xref="S3.SS3.p1.3.m3.1.1.3.2.cmml">3</mn><mo id="S3.SS3.p1.3.m3.1.1.3.1" xref="S3.SS3.p1.3.m3.1.1.3.1.cmml">⁢</mo><mi id="S3.SS3.p1.3.m3.1.1.3.3" xref="S3.SS3.p1.3.m3.1.1.3.3.cmml">d</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.3.m3.1b"><apply id="S3.SS3.p1.3.m3.1.1.cmml" xref="S3.SS3.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.3.m3.1.1.1.cmml" xref="S3.SS3.p1.3.m3.1.1">subscript</csymbol><ci id="S3.SS3.p1.3.m3.1.1.2.cmml" xref="S3.SS3.p1.3.m3.1.1.2">𝐷</ci><apply id="S3.SS3.p1.3.m3.1.1.3.cmml" xref="S3.SS3.p1.3.m3.1.1.3"><times id="S3.SS3.p1.3.m3.1.1.3.1.cmml" xref="S3.SS3.p1.3.m3.1.1.3.1"></times><cn id="S3.SS3.p1.3.m3.1.1.3.2.cmml" type="integer" xref="S3.SS3.p1.3.m3.1.1.3.2">3</cn><ci id="S3.SS3.p1.3.m3.1.1.3.3.cmml" xref="S3.SS3.p1.3.m3.1.1.3.3">𝑑</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.3.m3.1c">D_{3d}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.3.m3.1d">italic_D start_POSTSUBSCRIPT 3 italic_d end_POSTSUBSCRIPT</annotation></semantics></math>, <math alttext="H_{3d}" class="ltx_Math" display="inline" id="S3.SS3.p1.4.m4.1"><semantics id="S3.SS3.p1.4.m4.1a"><msub id="S3.SS3.p1.4.m4.1.1" xref="S3.SS3.p1.4.m4.1.1.cmml"><mi id="S3.SS3.p1.4.m4.1.1.2" xref="S3.SS3.p1.4.m4.1.1.2.cmml">H</mi><mrow id="S3.SS3.p1.4.m4.1.1.3" xref="S3.SS3.p1.4.m4.1.1.3.cmml"><mn id="S3.SS3.p1.4.m4.1.1.3.2" xref="S3.SS3.p1.4.m4.1.1.3.2.cmml">3</mn><mo id="S3.SS3.p1.4.m4.1.1.3.1" xref="S3.SS3.p1.4.m4.1.1.3.1.cmml">⁢</mo><mi id="S3.SS3.p1.4.m4.1.1.3.3" xref="S3.SS3.p1.4.m4.1.1.3.3.cmml">d</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.4.m4.1b"><apply id="S3.SS3.p1.4.m4.1.1.cmml" xref="S3.SS3.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.4.m4.1.1.1.cmml" xref="S3.SS3.p1.4.m4.1.1">subscript</csymbol><ci id="S3.SS3.p1.4.m4.1.1.2.cmml" xref="S3.SS3.p1.4.m4.1.1.2">𝐻</ci><apply id="S3.SS3.p1.4.m4.1.1.3.cmml" xref="S3.SS3.p1.4.m4.1.1.3"><times id="S3.SS3.p1.4.m4.1.1.3.1.cmml" xref="S3.SS3.p1.4.m4.1.1.3.1"></times><cn id="S3.SS3.p1.4.m4.1.1.3.2.cmml" type="integer" xref="S3.SS3.p1.4.m4.1.1.3.2">3</cn><ci id="S3.SS3.p1.4.m4.1.1.3.3.cmml" xref="S3.SS3.p1.4.m4.1.1.3.3">𝑑</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.4.m4.1c">H_{3d}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.4.m4.1d">italic_H start_POSTSUBSCRIPT 3 italic_d end_POSTSUBSCRIPT</annotation></semantics></math>, and <math alttext="W_{3d}" class="ltx_Math" display="inline" id="S3.SS3.p1.5.m5.1"><semantics id="S3.SS3.p1.5.m5.1a"><msub id="S3.SS3.p1.5.m5.1.1" xref="S3.SS3.p1.5.m5.1.1.cmml"><mi id="S3.SS3.p1.5.m5.1.1.2" xref="S3.SS3.p1.5.m5.1.1.2.cmml">W</mi><mrow id="S3.SS3.p1.5.m5.1.1.3" xref="S3.SS3.p1.5.m5.1.1.3.cmml"><mn id="S3.SS3.p1.5.m5.1.1.3.2" xref="S3.SS3.p1.5.m5.1.1.3.2.cmml">3</mn><mo id="S3.SS3.p1.5.m5.1.1.3.1" xref="S3.SS3.p1.5.m5.1.1.3.1.cmml">⁢</mo><mi id="S3.SS3.p1.5.m5.1.1.3.3" xref="S3.SS3.p1.5.m5.1.1.3.3.cmml">d</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.5.m5.1b"><apply id="S3.SS3.p1.5.m5.1.1.cmml" xref="S3.SS3.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.5.m5.1.1.1.cmml" xref="S3.SS3.p1.5.m5.1.1">subscript</csymbol><ci id="S3.SS3.p1.5.m5.1.1.2.cmml" xref="S3.SS3.p1.5.m5.1.1.2">𝑊</ci><apply id="S3.SS3.p1.5.m5.1.1.3.cmml" xref="S3.SS3.p1.5.m5.1.1.3"><times id="S3.SS3.p1.5.m5.1.1.3.1.cmml" xref="S3.SS3.p1.5.m5.1.1.3.1"></times><cn id="S3.SS3.p1.5.m5.1.1.3.2.cmml" type="integer" xref="S3.SS3.p1.5.m5.1.1.3.2">3</cn><ci id="S3.SS3.p1.5.m5.1.1.3.3.cmml" xref="S3.SS3.p1.5.m5.1.1.3.3">𝑑</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.5.m5.1c">W_{3d}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.5.m5.1d">italic_W start_POSTSUBSCRIPT 3 italic_d end_POSTSUBSCRIPT</annotation></semantics></math> represent the depth, height, and width of 3D input data, respectively.
A crucial aspect of training a universal network is ensuring the model is ‘aware’ of the ongoing task during the feed-forward process. As a prompt-based model, MedUniSeg generates task-specific priors in a new manner (see Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#S2.F2" title="Figure 2 ‣ 2.2 Learning from Multi-modal Medical Data ‣ 2 Related Work ‣ MedUniSeg: 2D and 3D Medical Image Segmentation via a Prompt-driven Universal Model"><span class="ltx_text ltx_ref_tag">2</span></a>).</p>
</div>
<div class="ltx_para" id="S3.SS3.p2">
<p class="ltx_p" id="S3.SS3.p2.3">Initially, it generates <math alttext="N" class="ltx_Math" display="inline" id="S3.SS3.p2.1.m1.1"><semantics id="S3.SS3.p2.1.m1.1a"><mi id="S3.SS3.p2.1.m1.1.1" xref="S3.SS3.p2.1.m1.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.1.m1.1b"><ci id="S3.SS3.p2.1.m1.1.1.cmml" xref="S3.SS3.p2.1.m1.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.1.m1.1c">N</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p2.1.m1.1d">italic_N</annotation></semantics></math> features by passing the concatenation of <math alttext="F_{uni}" class="ltx_Math" display="inline" id="S3.SS3.p2.2.m2.1"><semantics id="S3.SS3.p2.2.m2.1a"><msub id="S3.SS3.p2.2.m2.1.1" xref="S3.SS3.p2.2.m2.1.1.cmml"><mi id="S3.SS3.p2.2.m2.1.1.2" xref="S3.SS3.p2.2.m2.1.1.2.cmml">F</mi><mrow id="S3.SS3.p2.2.m2.1.1.3" xref="S3.SS3.p2.2.m2.1.1.3.cmml"><mi id="S3.SS3.p2.2.m2.1.1.3.2" xref="S3.SS3.p2.2.m2.1.1.3.2.cmml">u</mi><mo id="S3.SS3.p2.2.m2.1.1.3.1" xref="S3.SS3.p2.2.m2.1.1.3.1.cmml">⁢</mo><mi id="S3.SS3.p2.2.m2.1.1.3.3" xref="S3.SS3.p2.2.m2.1.1.3.3.cmml">n</mi><mo id="S3.SS3.p2.2.m2.1.1.3.1a" xref="S3.SS3.p2.2.m2.1.1.3.1.cmml">⁢</mo><mi id="S3.SS3.p2.2.m2.1.1.3.4" xref="S3.SS3.p2.2.m2.1.1.3.4.cmml">i</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.2.m2.1b"><apply id="S3.SS3.p2.2.m2.1.1.cmml" xref="S3.SS3.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.2.m2.1.1.1.cmml" xref="S3.SS3.p2.2.m2.1.1">subscript</csymbol><ci id="S3.SS3.p2.2.m2.1.1.2.cmml" xref="S3.SS3.p2.2.m2.1.1.2">𝐹</ci><apply id="S3.SS3.p2.2.m2.1.1.3.cmml" xref="S3.SS3.p2.2.m2.1.1.3"><times id="S3.SS3.p2.2.m2.1.1.3.1.cmml" xref="S3.SS3.p2.2.m2.1.1.3.1"></times><ci id="S3.SS3.p2.2.m2.1.1.3.2.cmml" xref="S3.SS3.p2.2.m2.1.1.3.2">𝑢</ci><ci id="S3.SS3.p2.2.m2.1.1.3.3.cmml" xref="S3.SS3.p2.2.m2.1.1.3.3">𝑛</ci><ci id="S3.SS3.p2.2.m2.1.1.3.4.cmml" xref="S3.SS3.p2.2.m2.1.1.3.4">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.2.m2.1c">F_{uni}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p2.2.m2.1d">italic_F start_POSTSUBSCRIPT italic_u italic_n italic_i end_POSTSUBSCRIPT</annotation></semantics></math> and <math alttext="F" class="ltx_Math" display="inline" id="S3.SS3.p2.3.m3.1"><semantics id="S3.SS3.p2.3.m3.1a"><mi id="S3.SS3.p2.3.m3.1.1" xref="S3.SS3.p2.3.m3.1.1.cmml">F</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.3.m3.1b"><ci id="S3.SS3.p2.3.m3.1.1.cmml" xref="S3.SS3.p2.3.m3.1.1">𝐹</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.3.m3.1c">F</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p2.3.m3.1d">italic_F</annotation></semantics></math> (the sample-specific features) through three convolutional blocks and splitting it along the channel dimension. This can be formally expressed as</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\{F_{task1},F_{task2},...,F_{taskN}\}=split(f(cat(F_{uni},F)))^{N}," class="ltx_Math" display="block" id="S3.E1.m1.3"><semantics id="S3.E1.m1.3a"><mrow id="S3.E1.m1.3.3.1" xref="S3.E1.m1.3.3.1.1.cmml"><mrow id="S3.E1.m1.3.3.1.1" xref="S3.E1.m1.3.3.1.1.cmml"><mrow id="S3.E1.m1.3.3.1.1.3.3" xref="S3.E1.m1.3.3.1.1.3.4.cmml"><mo id="S3.E1.m1.3.3.1.1.3.3.4" stretchy="false" xref="S3.E1.m1.3.3.1.1.3.4.cmml">{</mo><msub id="S3.E1.m1.3.3.1.1.1.1.1" xref="S3.E1.m1.3.3.1.1.1.1.1.cmml"><mi id="S3.E1.m1.3.3.1.1.1.1.1.2" xref="S3.E1.m1.3.3.1.1.1.1.1.2.cmml">F</mi><mrow id="S3.E1.m1.3.3.1.1.1.1.1.3" xref="S3.E1.m1.3.3.1.1.1.1.1.3.cmml"><mi id="S3.E1.m1.3.3.1.1.1.1.1.3.2" xref="S3.E1.m1.3.3.1.1.1.1.1.3.2.cmml">t</mi><mo id="S3.E1.m1.3.3.1.1.1.1.1.3.1" xref="S3.E1.m1.3.3.1.1.1.1.1.3.1.cmml">⁢</mo><mi id="S3.E1.m1.3.3.1.1.1.1.1.3.3" xref="S3.E1.m1.3.3.1.1.1.1.1.3.3.cmml">a</mi><mo id="S3.E1.m1.3.3.1.1.1.1.1.3.1a" xref="S3.E1.m1.3.3.1.1.1.1.1.3.1.cmml">⁢</mo><mi id="S3.E1.m1.3.3.1.1.1.1.1.3.4" xref="S3.E1.m1.3.3.1.1.1.1.1.3.4.cmml">s</mi><mo id="S3.E1.m1.3.3.1.1.1.1.1.3.1b" xref="S3.E1.m1.3.3.1.1.1.1.1.3.1.cmml">⁢</mo><mi id="S3.E1.m1.3.3.1.1.1.1.1.3.5" xref="S3.E1.m1.3.3.1.1.1.1.1.3.5.cmml">k</mi><mo id="S3.E1.m1.3.3.1.1.1.1.1.3.1c" xref="S3.E1.m1.3.3.1.1.1.1.1.3.1.cmml">⁢</mo><mn id="S3.E1.m1.3.3.1.1.1.1.1.3.6" xref="S3.E1.m1.3.3.1.1.1.1.1.3.6.cmml">1</mn></mrow></msub><mo id="S3.E1.m1.3.3.1.1.3.3.5" xref="S3.E1.m1.3.3.1.1.3.4.cmml">,</mo><msub id="S3.E1.m1.3.3.1.1.2.2.2" xref="S3.E1.m1.3.3.1.1.2.2.2.cmml"><mi id="S3.E1.m1.3.3.1.1.2.2.2.2" xref="S3.E1.m1.3.3.1.1.2.2.2.2.cmml">F</mi><mrow id="S3.E1.m1.3.3.1.1.2.2.2.3" xref="S3.E1.m1.3.3.1.1.2.2.2.3.cmml"><mi id="S3.E1.m1.3.3.1.1.2.2.2.3.2" xref="S3.E1.m1.3.3.1.1.2.2.2.3.2.cmml">t</mi><mo id="S3.E1.m1.3.3.1.1.2.2.2.3.1" xref="S3.E1.m1.3.3.1.1.2.2.2.3.1.cmml">⁢</mo><mi id="S3.E1.m1.3.3.1.1.2.2.2.3.3" xref="S3.E1.m1.3.3.1.1.2.2.2.3.3.cmml">a</mi><mo id="S3.E1.m1.3.3.1.1.2.2.2.3.1a" xref="S3.E1.m1.3.3.1.1.2.2.2.3.1.cmml">⁢</mo><mi id="S3.E1.m1.3.3.1.1.2.2.2.3.4" xref="S3.E1.m1.3.3.1.1.2.2.2.3.4.cmml">s</mi><mo id="S3.E1.m1.3.3.1.1.2.2.2.3.1b" xref="S3.E1.m1.3.3.1.1.2.2.2.3.1.cmml">⁢</mo><mi id="S3.E1.m1.3.3.1.1.2.2.2.3.5" xref="S3.E1.m1.3.3.1.1.2.2.2.3.5.cmml">k</mi><mo id="S3.E1.m1.3.3.1.1.2.2.2.3.1c" xref="S3.E1.m1.3.3.1.1.2.2.2.3.1.cmml">⁢</mo><mn id="S3.E1.m1.3.3.1.1.2.2.2.3.6" xref="S3.E1.m1.3.3.1.1.2.2.2.3.6.cmml">2</mn></mrow></msub><mo id="S3.E1.m1.3.3.1.1.3.3.6" xref="S3.E1.m1.3.3.1.1.3.4.cmml">,</mo><mi id="S3.E1.m1.1.1" mathvariant="normal" xref="S3.E1.m1.1.1.cmml">…</mi><mo id="S3.E1.m1.3.3.1.1.3.3.7" xref="S3.E1.m1.3.3.1.1.3.4.cmml">,</mo><msub id="S3.E1.m1.3.3.1.1.3.3.3" xref="S3.E1.m1.3.3.1.1.3.3.3.cmml"><mi id="S3.E1.m1.3.3.1.1.3.3.3.2" xref="S3.E1.m1.3.3.1.1.3.3.3.2.cmml">F</mi><mrow id="S3.E1.m1.3.3.1.1.3.3.3.3" xref="S3.E1.m1.3.3.1.1.3.3.3.3.cmml"><mi id="S3.E1.m1.3.3.1.1.3.3.3.3.2" xref="S3.E1.m1.3.3.1.1.3.3.3.3.2.cmml">t</mi><mo id="S3.E1.m1.3.3.1.1.3.3.3.3.1" xref="S3.E1.m1.3.3.1.1.3.3.3.3.1.cmml">⁢</mo><mi id="S3.E1.m1.3.3.1.1.3.3.3.3.3" xref="S3.E1.m1.3.3.1.1.3.3.3.3.3.cmml">a</mi><mo id="S3.E1.m1.3.3.1.1.3.3.3.3.1a" xref="S3.E1.m1.3.3.1.1.3.3.3.3.1.cmml">⁢</mo><mi id="S3.E1.m1.3.3.1.1.3.3.3.3.4" xref="S3.E1.m1.3.3.1.1.3.3.3.3.4.cmml">s</mi><mo id="S3.E1.m1.3.3.1.1.3.3.3.3.1b" xref="S3.E1.m1.3.3.1.1.3.3.3.3.1.cmml">⁢</mo><mi id="S3.E1.m1.3.3.1.1.3.3.3.3.5" xref="S3.E1.m1.3.3.1.1.3.3.3.3.5.cmml">k</mi><mo id="S3.E1.m1.3.3.1.1.3.3.3.3.1c" xref="S3.E1.m1.3.3.1.1.3.3.3.3.1.cmml">⁢</mo><mi id="S3.E1.m1.3.3.1.1.3.3.3.3.6" xref="S3.E1.m1.3.3.1.1.3.3.3.3.6.cmml">N</mi></mrow></msub><mo id="S3.E1.m1.3.3.1.1.3.3.8" stretchy="false" xref="S3.E1.m1.3.3.1.1.3.4.cmml">}</mo></mrow><mo id="S3.E1.m1.3.3.1.1.5" xref="S3.E1.m1.3.3.1.1.5.cmml">=</mo><mrow id="S3.E1.m1.3.3.1.1.4" xref="S3.E1.m1.3.3.1.1.4.cmml"><mi id="S3.E1.m1.3.3.1.1.4.3" xref="S3.E1.m1.3.3.1.1.4.3.cmml">s</mi><mo id="S3.E1.m1.3.3.1.1.4.2" xref="S3.E1.m1.3.3.1.1.4.2.cmml">⁢</mo><mi id="S3.E1.m1.3.3.1.1.4.4" xref="S3.E1.m1.3.3.1.1.4.4.cmml">p</mi><mo id="S3.E1.m1.3.3.1.1.4.2a" xref="S3.E1.m1.3.3.1.1.4.2.cmml">⁢</mo><mi id="S3.E1.m1.3.3.1.1.4.5" xref="S3.E1.m1.3.3.1.1.4.5.cmml">l</mi><mo id="S3.E1.m1.3.3.1.1.4.2b" xref="S3.E1.m1.3.3.1.1.4.2.cmml">⁢</mo><mi id="S3.E1.m1.3.3.1.1.4.6" xref="S3.E1.m1.3.3.1.1.4.6.cmml">i</mi><mo id="S3.E1.m1.3.3.1.1.4.2c" xref="S3.E1.m1.3.3.1.1.4.2.cmml">⁢</mo><mi id="S3.E1.m1.3.3.1.1.4.7" xref="S3.E1.m1.3.3.1.1.4.7.cmml">t</mi><mo id="S3.E1.m1.3.3.1.1.4.2d" xref="S3.E1.m1.3.3.1.1.4.2.cmml">⁢</mo><msup id="S3.E1.m1.3.3.1.1.4.1" xref="S3.E1.m1.3.3.1.1.4.1.cmml"><mrow id="S3.E1.m1.3.3.1.1.4.1.1.1" xref="S3.E1.m1.3.3.1.1.4.1.1.1.1.cmml"><mo id="S3.E1.m1.3.3.1.1.4.1.1.1.2" stretchy="false" xref="S3.E1.m1.3.3.1.1.4.1.1.1.1.cmml">(</mo><mrow id="S3.E1.m1.3.3.1.1.4.1.1.1.1" xref="S3.E1.m1.3.3.1.1.4.1.1.1.1.cmml"><mi id="S3.E1.m1.3.3.1.1.4.1.1.1.1.3" xref="S3.E1.m1.3.3.1.1.4.1.1.1.1.3.cmml">f</mi><mo id="S3.E1.m1.3.3.1.1.4.1.1.1.1.2" xref="S3.E1.m1.3.3.1.1.4.1.1.1.1.2.cmml">⁢</mo><mrow id="S3.E1.m1.3.3.1.1.4.1.1.1.1.1.1" xref="S3.E1.m1.3.3.1.1.4.1.1.1.1.1.1.1.cmml"><mo id="S3.E1.m1.3.3.1.1.4.1.1.1.1.1.1.2" stretchy="false" xref="S3.E1.m1.3.3.1.1.4.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E1.m1.3.3.1.1.4.1.1.1.1.1.1.1" xref="S3.E1.m1.3.3.1.1.4.1.1.1.1.1.1.1.cmml"><mi id="S3.E1.m1.3.3.1.1.4.1.1.1.1.1.1.1.3" xref="S3.E1.m1.3.3.1.1.4.1.1.1.1.1.1.1.3.cmml">c</mi><mo id="S3.E1.m1.3.3.1.1.4.1.1.1.1.1.1.1.2" xref="S3.E1.m1.3.3.1.1.4.1.1.1.1.1.1.1.2.cmml">⁢</mo><mi id="S3.E1.m1.3.3.1.1.4.1.1.1.1.1.1.1.4" xref="S3.E1.m1.3.3.1.1.4.1.1.1.1.1.1.1.4.cmml">a</mi><mo id="S3.E1.m1.3.3.1.1.4.1.1.1.1.1.1.1.2a" xref="S3.E1.m1.3.3.1.1.4.1.1.1.1.1.1.1.2.cmml">⁢</mo><mi id="S3.E1.m1.3.3.1.1.4.1.1.1.1.1.1.1.5" xref="S3.E1.m1.3.3.1.1.4.1.1.1.1.1.1.1.5.cmml">t</mi><mo id="S3.E1.m1.3.3.1.1.4.1.1.1.1.1.1.1.2b" xref="S3.E1.m1.3.3.1.1.4.1.1.1.1.1.1.1.2.cmml">⁢</mo><mrow id="S3.E1.m1.3.3.1.1.4.1.1.1.1.1.1.1.1.1" xref="S3.E1.m1.3.3.1.1.4.1.1.1.1.1.1.1.1.2.cmml"><mo id="S3.E1.m1.3.3.1.1.4.1.1.1.1.1.1.1.1.1.2" stretchy="false" xref="S3.E1.m1.3.3.1.1.4.1.1.1.1.1.1.1.1.2.cmml">(</mo><msub id="S3.E1.m1.3.3.1.1.4.1.1.1.1.1.1.1.1.1.1" xref="S3.E1.m1.3.3.1.1.4.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E1.m1.3.3.1.1.4.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E1.m1.3.3.1.1.4.1.1.1.1.1.1.1.1.1.1.2.cmml">F</mi><mrow id="S3.E1.m1.3.3.1.1.4.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E1.m1.3.3.1.1.4.1.1.1.1.1.1.1.1.1.1.3.cmml"><mi id="S3.E1.m1.3.3.1.1.4.1.1.1.1.1.1.1.1.1.1.3.2" xref="S3.E1.m1.3.3.1.1.4.1.1.1.1.1.1.1.1.1.1.3.2.cmml">u</mi><mo id="S3.E1.m1.3.3.1.1.4.1.1.1.1.1.1.1.1.1.1.3.1" xref="S3.E1.m1.3.3.1.1.4.1.1.1.1.1.1.1.1.1.1.3.1.cmml">⁢</mo><mi id="S3.E1.m1.3.3.1.1.4.1.1.1.1.1.1.1.1.1.1.3.3" xref="S3.E1.m1.3.3.1.1.4.1.1.1.1.1.1.1.1.1.1.3.3.cmml">n</mi><mo id="S3.E1.m1.3.3.1.1.4.1.1.1.1.1.1.1.1.1.1.3.1a" xref="S3.E1.m1.3.3.1.1.4.1.1.1.1.1.1.1.1.1.1.3.1.cmml">⁢</mo><mi id="S3.E1.m1.3.3.1.1.4.1.1.1.1.1.1.1.1.1.1.3.4" xref="S3.E1.m1.3.3.1.1.4.1.1.1.1.1.1.1.1.1.1.3.4.cmml">i</mi></mrow></msub><mo id="S3.E1.m1.3.3.1.1.4.1.1.1.1.1.1.1.1.1.3" xref="S3.E1.m1.3.3.1.1.4.1.1.1.1.1.1.1.1.2.cmml">,</mo><mi id="S3.E1.m1.2.2" xref="S3.E1.m1.2.2.cmml">F</mi><mo id="S3.E1.m1.3.3.1.1.4.1.1.1.1.1.1.1.1.1.4" stretchy="false" xref="S3.E1.m1.3.3.1.1.4.1.1.1.1.1.1.1.1.2.cmml">)</mo></mrow></mrow><mo id="S3.E1.m1.3.3.1.1.4.1.1.1.1.1.1.3" stretchy="false" xref="S3.E1.m1.3.3.1.1.4.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E1.m1.3.3.1.1.4.1.1.1.3" stretchy="false" xref="S3.E1.m1.3.3.1.1.4.1.1.1.1.cmml">)</mo></mrow><mi id="S3.E1.m1.3.3.1.1.4.1.3" xref="S3.E1.m1.3.3.1.1.4.1.3.cmml">N</mi></msup></mrow></mrow><mo id="S3.E1.m1.3.3.1.2" xref="S3.E1.m1.3.3.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.3b"><apply id="S3.E1.m1.3.3.1.1.cmml" xref="S3.E1.m1.3.3.1"><eq id="S3.E1.m1.3.3.1.1.5.cmml" xref="S3.E1.m1.3.3.1.1.5"></eq><set id="S3.E1.m1.3.3.1.1.3.4.cmml" xref="S3.E1.m1.3.3.1.1.3.3"><apply id="S3.E1.m1.3.3.1.1.1.1.1.cmml" xref="S3.E1.m1.3.3.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.3.3.1.1.1.1.1.1.cmml" xref="S3.E1.m1.3.3.1.1.1.1.1">subscript</csymbol><ci id="S3.E1.m1.3.3.1.1.1.1.1.2.cmml" xref="S3.E1.m1.3.3.1.1.1.1.1.2">𝐹</ci><apply id="S3.E1.m1.3.3.1.1.1.1.1.3.cmml" xref="S3.E1.m1.3.3.1.1.1.1.1.3"><times id="S3.E1.m1.3.3.1.1.1.1.1.3.1.cmml" xref="S3.E1.m1.3.3.1.1.1.1.1.3.1"></times><ci id="S3.E1.m1.3.3.1.1.1.1.1.3.2.cmml" xref="S3.E1.m1.3.3.1.1.1.1.1.3.2">𝑡</ci><ci id="S3.E1.m1.3.3.1.1.1.1.1.3.3.cmml" xref="S3.E1.m1.3.3.1.1.1.1.1.3.3">𝑎</ci><ci id="S3.E1.m1.3.3.1.1.1.1.1.3.4.cmml" xref="S3.E1.m1.3.3.1.1.1.1.1.3.4">𝑠</ci><ci id="S3.E1.m1.3.3.1.1.1.1.1.3.5.cmml" xref="S3.E1.m1.3.3.1.1.1.1.1.3.5">𝑘</ci><cn id="S3.E1.m1.3.3.1.1.1.1.1.3.6.cmml" type="integer" xref="S3.E1.m1.3.3.1.1.1.1.1.3.6">1</cn></apply></apply><apply id="S3.E1.m1.3.3.1.1.2.2.2.cmml" xref="S3.E1.m1.3.3.1.1.2.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.3.3.1.1.2.2.2.1.cmml" xref="S3.E1.m1.3.3.1.1.2.2.2">subscript</csymbol><ci id="S3.E1.m1.3.3.1.1.2.2.2.2.cmml" xref="S3.E1.m1.3.3.1.1.2.2.2.2">𝐹</ci><apply id="S3.E1.m1.3.3.1.1.2.2.2.3.cmml" xref="S3.E1.m1.3.3.1.1.2.2.2.3"><times id="S3.E1.m1.3.3.1.1.2.2.2.3.1.cmml" xref="S3.E1.m1.3.3.1.1.2.2.2.3.1"></times><ci id="S3.E1.m1.3.3.1.1.2.2.2.3.2.cmml" xref="S3.E1.m1.3.3.1.1.2.2.2.3.2">𝑡</ci><ci id="S3.E1.m1.3.3.1.1.2.2.2.3.3.cmml" xref="S3.E1.m1.3.3.1.1.2.2.2.3.3">𝑎</ci><ci id="S3.E1.m1.3.3.1.1.2.2.2.3.4.cmml" xref="S3.E1.m1.3.3.1.1.2.2.2.3.4">𝑠</ci><ci id="S3.E1.m1.3.3.1.1.2.2.2.3.5.cmml" xref="S3.E1.m1.3.3.1.1.2.2.2.3.5">𝑘</ci><cn id="S3.E1.m1.3.3.1.1.2.2.2.3.6.cmml" type="integer" xref="S3.E1.m1.3.3.1.1.2.2.2.3.6">2</cn></apply></apply><ci id="S3.E1.m1.1.1.cmml" xref="S3.E1.m1.1.1">…</ci><apply id="S3.E1.m1.3.3.1.1.3.3.3.cmml" xref="S3.E1.m1.3.3.1.1.3.3.3"><csymbol cd="ambiguous" id="S3.E1.m1.3.3.1.1.3.3.3.1.cmml" xref="S3.E1.m1.3.3.1.1.3.3.3">subscript</csymbol><ci id="S3.E1.m1.3.3.1.1.3.3.3.2.cmml" xref="S3.E1.m1.3.3.1.1.3.3.3.2">𝐹</ci><apply id="S3.E1.m1.3.3.1.1.3.3.3.3.cmml" xref="S3.E1.m1.3.3.1.1.3.3.3.3"><times id="S3.E1.m1.3.3.1.1.3.3.3.3.1.cmml" xref="S3.E1.m1.3.3.1.1.3.3.3.3.1"></times><ci id="S3.E1.m1.3.3.1.1.3.3.3.3.2.cmml" xref="S3.E1.m1.3.3.1.1.3.3.3.3.2">𝑡</ci><ci id="S3.E1.m1.3.3.1.1.3.3.3.3.3.cmml" xref="S3.E1.m1.3.3.1.1.3.3.3.3.3">𝑎</ci><ci id="S3.E1.m1.3.3.1.1.3.3.3.3.4.cmml" xref="S3.E1.m1.3.3.1.1.3.3.3.3.4">𝑠</ci><ci id="S3.E1.m1.3.3.1.1.3.3.3.3.5.cmml" xref="S3.E1.m1.3.3.1.1.3.3.3.3.5">𝑘</ci><ci id="S3.E1.m1.3.3.1.1.3.3.3.3.6.cmml" xref="S3.E1.m1.3.3.1.1.3.3.3.3.6">𝑁</ci></apply></apply></set><apply id="S3.E1.m1.3.3.1.1.4.cmml" xref="S3.E1.m1.3.3.1.1.4"><times id="S3.E1.m1.3.3.1.1.4.2.cmml" xref="S3.E1.m1.3.3.1.1.4.2"></times><ci id="S3.E1.m1.3.3.1.1.4.3.cmml" xref="S3.E1.m1.3.3.1.1.4.3">𝑠</ci><ci id="S3.E1.m1.3.3.1.1.4.4.cmml" xref="S3.E1.m1.3.3.1.1.4.4">𝑝</ci><ci id="S3.E1.m1.3.3.1.1.4.5.cmml" xref="S3.E1.m1.3.3.1.1.4.5">𝑙</ci><ci id="S3.E1.m1.3.3.1.1.4.6.cmml" xref="S3.E1.m1.3.3.1.1.4.6">𝑖</ci><ci id="S3.E1.m1.3.3.1.1.4.7.cmml" xref="S3.E1.m1.3.3.1.1.4.7">𝑡</ci><apply id="S3.E1.m1.3.3.1.1.4.1.cmml" xref="S3.E1.m1.3.3.1.1.4.1"><csymbol cd="ambiguous" id="S3.E1.m1.3.3.1.1.4.1.2.cmml" xref="S3.E1.m1.3.3.1.1.4.1">superscript</csymbol><apply id="S3.E1.m1.3.3.1.1.4.1.1.1.1.cmml" xref="S3.E1.m1.3.3.1.1.4.1.1.1"><times id="S3.E1.m1.3.3.1.1.4.1.1.1.1.2.cmml" xref="S3.E1.m1.3.3.1.1.4.1.1.1.1.2"></times><ci id="S3.E1.m1.3.3.1.1.4.1.1.1.1.3.cmml" xref="S3.E1.m1.3.3.1.1.4.1.1.1.1.3">𝑓</ci><apply id="S3.E1.m1.3.3.1.1.4.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.3.3.1.1.4.1.1.1.1.1.1"><times id="S3.E1.m1.3.3.1.1.4.1.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.3.3.1.1.4.1.1.1.1.1.1.1.2"></times><ci id="S3.E1.m1.3.3.1.1.4.1.1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.3.3.1.1.4.1.1.1.1.1.1.1.3">𝑐</ci><ci id="S3.E1.m1.3.3.1.1.4.1.1.1.1.1.1.1.4.cmml" xref="S3.E1.m1.3.3.1.1.4.1.1.1.1.1.1.1.4">𝑎</ci><ci id="S3.E1.m1.3.3.1.1.4.1.1.1.1.1.1.1.5.cmml" xref="S3.E1.m1.3.3.1.1.4.1.1.1.1.1.1.1.5">𝑡</ci><interval closure="open" id="S3.E1.m1.3.3.1.1.4.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.3.3.1.1.4.1.1.1.1.1.1.1.1.1"><apply id="S3.E1.m1.3.3.1.1.4.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.3.3.1.1.4.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.3.3.1.1.4.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.3.3.1.1.4.1.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E1.m1.3.3.1.1.4.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.3.3.1.1.4.1.1.1.1.1.1.1.1.1.1.2">𝐹</ci><apply id="S3.E1.m1.3.3.1.1.4.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.3.3.1.1.4.1.1.1.1.1.1.1.1.1.1.3"><times id="S3.E1.m1.3.3.1.1.4.1.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E1.m1.3.3.1.1.4.1.1.1.1.1.1.1.1.1.1.3.1"></times><ci id="S3.E1.m1.3.3.1.1.4.1.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E1.m1.3.3.1.1.4.1.1.1.1.1.1.1.1.1.1.3.2">𝑢</ci><ci id="S3.E1.m1.3.3.1.1.4.1.1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S3.E1.m1.3.3.1.1.4.1.1.1.1.1.1.1.1.1.1.3.3">𝑛</ci><ci id="S3.E1.m1.3.3.1.1.4.1.1.1.1.1.1.1.1.1.1.3.4.cmml" xref="S3.E1.m1.3.3.1.1.4.1.1.1.1.1.1.1.1.1.1.3.4">𝑖</ci></apply></apply><ci id="S3.E1.m1.2.2.cmml" xref="S3.E1.m1.2.2">𝐹</ci></interval></apply></apply><ci id="S3.E1.m1.3.3.1.1.4.1.3.cmml" xref="S3.E1.m1.3.3.1.1.4.1.3">𝑁</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.3c">\{F_{task1},F_{task2},...,F_{taskN}\}=split(f(cat(F_{uni},F)))^{N},</annotation><annotation encoding="application/x-llamapun" id="S3.E1.m1.3d">{ italic_F start_POSTSUBSCRIPT italic_t italic_a italic_s italic_k 1 end_POSTSUBSCRIPT , italic_F start_POSTSUBSCRIPT italic_t italic_a italic_s italic_k 2 end_POSTSUBSCRIPT , … , italic_F start_POSTSUBSCRIPT italic_t italic_a italic_s italic_k italic_N end_POSTSUBSCRIPT } = italic_s italic_p italic_l italic_i italic_t ( italic_f ( italic_c italic_a italic_t ( italic_F start_POSTSUBSCRIPT italic_u italic_n italic_i end_POSTSUBSCRIPT , italic_F ) ) ) start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS3.p2.9">where <math alttext="F_{taski}" class="ltx_Math" display="inline" id="S3.SS3.p2.4.m1.1"><semantics id="S3.SS3.p2.4.m1.1a"><msub id="S3.SS3.p2.4.m1.1.1" xref="S3.SS3.p2.4.m1.1.1.cmml"><mi id="S3.SS3.p2.4.m1.1.1.2" xref="S3.SS3.p2.4.m1.1.1.2.cmml">F</mi><mrow id="S3.SS3.p2.4.m1.1.1.3" xref="S3.SS3.p2.4.m1.1.1.3.cmml"><mi id="S3.SS3.p2.4.m1.1.1.3.2" xref="S3.SS3.p2.4.m1.1.1.3.2.cmml">t</mi><mo id="S3.SS3.p2.4.m1.1.1.3.1" xref="S3.SS3.p2.4.m1.1.1.3.1.cmml">⁢</mo><mi id="S3.SS3.p2.4.m1.1.1.3.3" xref="S3.SS3.p2.4.m1.1.1.3.3.cmml">a</mi><mo id="S3.SS3.p2.4.m1.1.1.3.1a" xref="S3.SS3.p2.4.m1.1.1.3.1.cmml">⁢</mo><mi id="S3.SS3.p2.4.m1.1.1.3.4" xref="S3.SS3.p2.4.m1.1.1.3.4.cmml">s</mi><mo id="S3.SS3.p2.4.m1.1.1.3.1b" xref="S3.SS3.p2.4.m1.1.1.3.1.cmml">⁢</mo><mi id="S3.SS3.p2.4.m1.1.1.3.5" xref="S3.SS3.p2.4.m1.1.1.3.5.cmml">k</mi><mo id="S3.SS3.p2.4.m1.1.1.3.1c" xref="S3.SS3.p2.4.m1.1.1.3.1.cmml">⁢</mo><mi id="S3.SS3.p2.4.m1.1.1.3.6" xref="S3.SS3.p2.4.m1.1.1.3.6.cmml">i</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.4.m1.1b"><apply id="S3.SS3.p2.4.m1.1.1.cmml" xref="S3.SS3.p2.4.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.4.m1.1.1.1.cmml" xref="S3.SS3.p2.4.m1.1.1">subscript</csymbol><ci id="S3.SS3.p2.4.m1.1.1.2.cmml" xref="S3.SS3.p2.4.m1.1.1.2">𝐹</ci><apply id="S3.SS3.p2.4.m1.1.1.3.cmml" xref="S3.SS3.p2.4.m1.1.1.3"><times id="S3.SS3.p2.4.m1.1.1.3.1.cmml" xref="S3.SS3.p2.4.m1.1.1.3.1"></times><ci id="S3.SS3.p2.4.m1.1.1.3.2.cmml" xref="S3.SS3.p2.4.m1.1.1.3.2">𝑡</ci><ci id="S3.SS3.p2.4.m1.1.1.3.3.cmml" xref="S3.SS3.p2.4.m1.1.1.3.3">𝑎</ci><ci id="S3.SS3.p2.4.m1.1.1.3.4.cmml" xref="S3.SS3.p2.4.m1.1.1.3.4">𝑠</ci><ci id="S3.SS3.p2.4.m1.1.1.3.5.cmml" xref="S3.SS3.p2.4.m1.1.1.3.5">𝑘</ci><ci id="S3.SS3.p2.4.m1.1.1.3.6.cmml" xref="S3.SS3.p2.4.m1.1.1.3.6">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.4.m1.1c">F_{taski}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p2.4.m1.1d">italic_F start_POSTSUBSCRIPT italic_t italic_a italic_s italic_k italic_i end_POSTSUBSCRIPT</annotation></semantics></math> denotes the prompt features corresponding to the <math alttext="i" class="ltx_Math" display="inline" id="S3.SS3.p2.5.m2.1"><semantics id="S3.SS3.p2.5.m2.1a"><mi id="S3.SS3.p2.5.m2.1.1" xref="S3.SS3.p2.5.m2.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.5.m2.1b"><ci id="S3.SS3.p2.5.m2.1.1.cmml" xref="S3.SS3.p2.5.m2.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.5.m2.1c">i</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p2.5.m2.1d">italic_i</annotation></semantics></math>-th task, <math alttext="cat(\cdot,\cdot)" class="ltx_Math" display="inline" id="S3.SS3.p2.6.m3.2"><semantics id="S3.SS3.p2.6.m3.2a"><mrow id="S3.SS3.p2.6.m3.2.3" xref="S3.SS3.p2.6.m3.2.3.cmml"><mi id="S3.SS3.p2.6.m3.2.3.2" xref="S3.SS3.p2.6.m3.2.3.2.cmml">c</mi><mo id="S3.SS3.p2.6.m3.2.3.1" xref="S3.SS3.p2.6.m3.2.3.1.cmml">⁢</mo><mi id="S3.SS3.p2.6.m3.2.3.3" xref="S3.SS3.p2.6.m3.2.3.3.cmml">a</mi><mo id="S3.SS3.p2.6.m3.2.3.1a" xref="S3.SS3.p2.6.m3.2.3.1.cmml">⁢</mo><mi id="S3.SS3.p2.6.m3.2.3.4" xref="S3.SS3.p2.6.m3.2.3.4.cmml">t</mi><mo id="S3.SS3.p2.6.m3.2.3.1b" xref="S3.SS3.p2.6.m3.2.3.1.cmml">⁢</mo><mrow id="S3.SS3.p2.6.m3.2.3.5.2" xref="S3.SS3.p2.6.m3.2.3.5.1.cmml"><mo id="S3.SS3.p2.6.m3.2.3.5.2.1" stretchy="false" xref="S3.SS3.p2.6.m3.2.3.5.1.cmml">(</mo><mo id="S3.SS3.p2.6.m3.1.1" lspace="0em" rspace="0em" xref="S3.SS3.p2.6.m3.1.1.cmml">⋅</mo><mo id="S3.SS3.p2.6.m3.2.3.5.2.2" rspace="0em" xref="S3.SS3.p2.6.m3.2.3.5.1.cmml">,</mo><mo id="S3.SS3.p2.6.m3.2.2" lspace="0em" rspace="0em" xref="S3.SS3.p2.6.m3.2.2.cmml">⋅</mo><mo id="S3.SS3.p2.6.m3.2.3.5.2.3" stretchy="false" xref="S3.SS3.p2.6.m3.2.3.5.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.6.m3.2b"><apply id="S3.SS3.p2.6.m3.2.3.cmml" xref="S3.SS3.p2.6.m3.2.3"><times id="S3.SS3.p2.6.m3.2.3.1.cmml" xref="S3.SS3.p2.6.m3.2.3.1"></times><ci id="S3.SS3.p2.6.m3.2.3.2.cmml" xref="S3.SS3.p2.6.m3.2.3.2">𝑐</ci><ci id="S3.SS3.p2.6.m3.2.3.3.cmml" xref="S3.SS3.p2.6.m3.2.3.3">𝑎</ci><ci id="S3.SS3.p2.6.m3.2.3.4.cmml" xref="S3.SS3.p2.6.m3.2.3.4">𝑡</ci><interval closure="open" id="S3.SS3.p2.6.m3.2.3.5.1.cmml" xref="S3.SS3.p2.6.m3.2.3.5.2"><ci id="S3.SS3.p2.6.m3.1.1.cmml" xref="S3.SS3.p2.6.m3.1.1">⋅</ci><ci id="S3.SS3.p2.6.m3.2.2.cmml" xref="S3.SS3.p2.6.m3.2.2">⋅</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.6.m3.2c">cat(\cdot,\cdot)</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p2.6.m3.2d">italic_c italic_a italic_t ( ⋅ , ⋅ )</annotation></semantics></math> represents the concatenation operation, <math alttext="f(\cdot)" class="ltx_Math" display="inline" id="S3.SS3.p2.7.m4.1"><semantics id="S3.SS3.p2.7.m4.1a"><mrow id="S3.SS3.p2.7.m4.1.2" xref="S3.SS3.p2.7.m4.1.2.cmml"><mi id="S3.SS3.p2.7.m4.1.2.2" xref="S3.SS3.p2.7.m4.1.2.2.cmml">f</mi><mo id="S3.SS3.p2.7.m4.1.2.1" xref="S3.SS3.p2.7.m4.1.2.1.cmml">⁢</mo><mrow id="S3.SS3.p2.7.m4.1.2.3.2" xref="S3.SS3.p2.7.m4.1.2.cmml"><mo id="S3.SS3.p2.7.m4.1.2.3.2.1" stretchy="false" xref="S3.SS3.p2.7.m4.1.2.cmml">(</mo><mo id="S3.SS3.p2.7.m4.1.1" lspace="0em" rspace="0em" xref="S3.SS3.p2.7.m4.1.1.cmml">⋅</mo><mo id="S3.SS3.p2.7.m4.1.2.3.2.2" stretchy="false" xref="S3.SS3.p2.7.m4.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.7.m4.1b"><apply id="S3.SS3.p2.7.m4.1.2.cmml" xref="S3.SS3.p2.7.m4.1.2"><times id="S3.SS3.p2.7.m4.1.2.1.cmml" xref="S3.SS3.p2.7.m4.1.2.1"></times><ci id="S3.SS3.p2.7.m4.1.2.2.cmml" xref="S3.SS3.p2.7.m4.1.2.2">𝑓</ci><ci id="S3.SS3.p2.7.m4.1.1.cmml" xref="S3.SS3.p2.7.m4.1.1">⋅</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.7.m4.1c">f(\cdot)</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p2.7.m4.1d">italic_f ( ⋅ )</annotation></semantics></math> denotes the feed-forward process, and <math alttext="split(\cdot)^{N}" class="ltx_Math" display="inline" id="S3.SS3.p2.8.m5.1"><semantics id="S3.SS3.p2.8.m5.1a"><mrow id="S3.SS3.p2.8.m5.1.2" xref="S3.SS3.p2.8.m5.1.2.cmml"><mi id="S3.SS3.p2.8.m5.1.2.2" xref="S3.SS3.p2.8.m5.1.2.2.cmml">s</mi><mo id="S3.SS3.p2.8.m5.1.2.1" xref="S3.SS3.p2.8.m5.1.2.1.cmml">⁢</mo><mi id="S3.SS3.p2.8.m5.1.2.3" xref="S3.SS3.p2.8.m5.1.2.3.cmml">p</mi><mo id="S3.SS3.p2.8.m5.1.2.1a" xref="S3.SS3.p2.8.m5.1.2.1.cmml">⁢</mo><mi id="S3.SS3.p2.8.m5.1.2.4" xref="S3.SS3.p2.8.m5.1.2.4.cmml">l</mi><mo id="S3.SS3.p2.8.m5.1.2.1b" xref="S3.SS3.p2.8.m5.1.2.1.cmml">⁢</mo><mi id="S3.SS3.p2.8.m5.1.2.5" xref="S3.SS3.p2.8.m5.1.2.5.cmml">i</mi><mo id="S3.SS3.p2.8.m5.1.2.1c" xref="S3.SS3.p2.8.m5.1.2.1.cmml">⁢</mo><mi id="S3.SS3.p2.8.m5.1.2.6" xref="S3.SS3.p2.8.m5.1.2.6.cmml">t</mi><mo id="S3.SS3.p2.8.m5.1.2.1d" xref="S3.SS3.p2.8.m5.1.2.1.cmml">⁢</mo><msup id="S3.SS3.p2.8.m5.1.2.7" xref="S3.SS3.p2.8.m5.1.2.7.cmml"><mrow id="S3.SS3.p2.8.m5.1.2.7.2.2" xref="S3.SS3.p2.8.m5.1.2.7.cmml"><mo id="S3.SS3.p2.8.m5.1.2.7.2.2.1" stretchy="false" xref="S3.SS3.p2.8.m5.1.2.7.cmml">(</mo><mo id="S3.SS3.p2.8.m5.1.1" lspace="0em" rspace="0em" xref="S3.SS3.p2.8.m5.1.1.cmml">⋅</mo><mo id="S3.SS3.p2.8.m5.1.2.7.2.2.2" stretchy="false" xref="S3.SS3.p2.8.m5.1.2.7.cmml">)</mo></mrow><mi id="S3.SS3.p2.8.m5.1.2.7.3" xref="S3.SS3.p2.8.m5.1.2.7.3.cmml">N</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.8.m5.1b"><apply id="S3.SS3.p2.8.m5.1.2.cmml" xref="S3.SS3.p2.8.m5.1.2"><times id="S3.SS3.p2.8.m5.1.2.1.cmml" xref="S3.SS3.p2.8.m5.1.2.1"></times><ci id="S3.SS3.p2.8.m5.1.2.2.cmml" xref="S3.SS3.p2.8.m5.1.2.2">𝑠</ci><ci id="S3.SS3.p2.8.m5.1.2.3.cmml" xref="S3.SS3.p2.8.m5.1.2.3">𝑝</ci><ci id="S3.SS3.p2.8.m5.1.2.4.cmml" xref="S3.SS3.p2.8.m5.1.2.4">𝑙</ci><ci id="S3.SS3.p2.8.m5.1.2.5.cmml" xref="S3.SS3.p2.8.m5.1.2.5">𝑖</ci><ci id="S3.SS3.p2.8.m5.1.2.6.cmml" xref="S3.SS3.p2.8.m5.1.2.6">𝑡</ci><apply id="S3.SS3.p2.8.m5.1.2.7.cmml" xref="S3.SS3.p2.8.m5.1.2.7"><csymbol cd="ambiguous" id="S3.SS3.p2.8.m5.1.2.7.1.cmml" xref="S3.SS3.p2.8.m5.1.2.7">superscript</csymbol><ci id="S3.SS3.p2.8.m5.1.1.cmml" xref="S3.SS3.p2.8.m5.1.1">⋅</ci><ci id="S3.SS3.p2.8.m5.1.2.7.3.cmml" xref="S3.SS3.p2.8.m5.1.2.7.3">𝑁</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.8.m5.1c">split(\cdot)^{N}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p2.8.m5.1d">italic_s italic_p italic_l italic_i italic_t ( ⋅ ) start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT</annotation></semantics></math> divides the features along the channel dimension to yield <math alttext="N" class="ltx_Math" display="inline" id="S3.SS3.p2.9.m6.1"><semantics id="S3.SS3.p2.9.m6.1a"><mi id="S3.SS3.p2.9.m6.1.1" xref="S3.SS3.p2.9.m6.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.9.m6.1b"><ci id="S3.SS3.p2.9.m6.1.1.cmml" xref="S3.SS3.p2.9.m6.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.9.m6.1c">N</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p2.9.m6.1d">italic_N</annotation></semantics></math> features of identical shape.</p>
</div>
<div class="ltx_para" id="S3.SS3.p3">
<p class="ltx_p" id="S3.SS3.p3.4">Subsequently, we select the task-specific prior <math alttext="F_{tp}" class="ltx_Math" display="inline" id="S3.SS3.p3.1.m1.1"><semantics id="S3.SS3.p3.1.m1.1a"><msub id="S3.SS3.p3.1.m1.1.1" xref="S3.SS3.p3.1.m1.1.1.cmml"><mi id="S3.SS3.p3.1.m1.1.1.2" xref="S3.SS3.p3.1.m1.1.1.2.cmml">F</mi><mrow id="S3.SS3.p3.1.m1.1.1.3" xref="S3.SS3.p3.1.m1.1.1.3.cmml"><mi id="S3.SS3.p3.1.m1.1.1.3.2" xref="S3.SS3.p3.1.m1.1.1.3.2.cmml">t</mi><mo id="S3.SS3.p3.1.m1.1.1.3.1" xref="S3.SS3.p3.1.m1.1.1.3.1.cmml">⁢</mo><mi id="S3.SS3.p3.1.m1.1.1.3.3" xref="S3.SS3.p3.1.m1.1.1.3.3.cmml">p</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.1.m1.1b"><apply id="S3.SS3.p3.1.m1.1.1.cmml" xref="S3.SS3.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p3.1.m1.1.1.1.cmml" xref="S3.SS3.p3.1.m1.1.1">subscript</csymbol><ci id="S3.SS3.p3.1.m1.1.1.2.cmml" xref="S3.SS3.p3.1.m1.1.1.2">𝐹</ci><apply id="S3.SS3.p3.1.m1.1.1.3.cmml" xref="S3.SS3.p3.1.m1.1.1.3"><times id="S3.SS3.p3.1.m1.1.1.3.1.cmml" xref="S3.SS3.p3.1.m1.1.1.3.1"></times><ci id="S3.SS3.p3.1.m1.1.1.3.2.cmml" xref="S3.SS3.p3.1.m1.1.1.3.2">𝑡</ci><ci id="S3.SS3.p3.1.m1.1.1.3.3.cmml" xref="S3.SS3.p3.1.m1.1.1.3.3">𝑝</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.1.m1.1c">F_{tp}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p3.1.m1.1d">italic_F start_POSTSUBSCRIPT italic_t italic_p end_POSTSUBSCRIPT</annotation></semantics></math> from <math alttext="\{F_{task1},F_{task2},...,F_{taskN}\}" class="ltx_Math" display="inline" id="S3.SS3.p3.2.m2.4"><semantics id="S3.SS3.p3.2.m2.4a"><mrow id="S3.SS3.p3.2.m2.4.4.3" xref="S3.SS3.p3.2.m2.4.4.4.cmml"><mo id="S3.SS3.p3.2.m2.4.4.3.4" stretchy="false" xref="S3.SS3.p3.2.m2.4.4.4.cmml">{</mo><msub id="S3.SS3.p3.2.m2.2.2.1.1" xref="S3.SS3.p3.2.m2.2.2.1.1.cmml"><mi id="S3.SS3.p3.2.m2.2.2.1.1.2" xref="S3.SS3.p3.2.m2.2.2.1.1.2.cmml">F</mi><mrow id="S3.SS3.p3.2.m2.2.2.1.1.3" xref="S3.SS3.p3.2.m2.2.2.1.1.3.cmml"><mi id="S3.SS3.p3.2.m2.2.2.1.1.3.2" xref="S3.SS3.p3.2.m2.2.2.1.1.3.2.cmml">t</mi><mo id="S3.SS3.p3.2.m2.2.2.1.1.3.1" xref="S3.SS3.p3.2.m2.2.2.1.1.3.1.cmml">⁢</mo><mi id="S3.SS3.p3.2.m2.2.2.1.1.3.3" xref="S3.SS3.p3.2.m2.2.2.1.1.3.3.cmml">a</mi><mo id="S3.SS3.p3.2.m2.2.2.1.1.3.1a" xref="S3.SS3.p3.2.m2.2.2.1.1.3.1.cmml">⁢</mo><mi id="S3.SS3.p3.2.m2.2.2.1.1.3.4" xref="S3.SS3.p3.2.m2.2.2.1.1.3.4.cmml">s</mi><mo id="S3.SS3.p3.2.m2.2.2.1.1.3.1b" xref="S3.SS3.p3.2.m2.2.2.1.1.3.1.cmml">⁢</mo><mi id="S3.SS3.p3.2.m2.2.2.1.1.3.5" xref="S3.SS3.p3.2.m2.2.2.1.1.3.5.cmml">k</mi><mo id="S3.SS3.p3.2.m2.2.2.1.1.3.1c" xref="S3.SS3.p3.2.m2.2.2.1.1.3.1.cmml">⁢</mo><mn id="S3.SS3.p3.2.m2.2.2.1.1.3.6" xref="S3.SS3.p3.2.m2.2.2.1.1.3.6.cmml">1</mn></mrow></msub><mo id="S3.SS3.p3.2.m2.4.4.3.5" xref="S3.SS3.p3.2.m2.4.4.4.cmml">,</mo><msub id="S3.SS3.p3.2.m2.3.3.2.2" xref="S3.SS3.p3.2.m2.3.3.2.2.cmml"><mi id="S3.SS3.p3.2.m2.3.3.2.2.2" xref="S3.SS3.p3.2.m2.3.3.2.2.2.cmml">F</mi><mrow id="S3.SS3.p3.2.m2.3.3.2.2.3" xref="S3.SS3.p3.2.m2.3.3.2.2.3.cmml"><mi id="S3.SS3.p3.2.m2.3.3.2.2.3.2" xref="S3.SS3.p3.2.m2.3.3.2.2.3.2.cmml">t</mi><mo id="S3.SS3.p3.2.m2.3.3.2.2.3.1" xref="S3.SS3.p3.2.m2.3.3.2.2.3.1.cmml">⁢</mo><mi id="S3.SS3.p3.2.m2.3.3.2.2.3.3" xref="S3.SS3.p3.2.m2.3.3.2.2.3.3.cmml">a</mi><mo id="S3.SS3.p3.2.m2.3.3.2.2.3.1a" xref="S3.SS3.p3.2.m2.3.3.2.2.3.1.cmml">⁢</mo><mi id="S3.SS3.p3.2.m2.3.3.2.2.3.4" xref="S3.SS3.p3.2.m2.3.3.2.2.3.4.cmml">s</mi><mo id="S3.SS3.p3.2.m2.3.3.2.2.3.1b" xref="S3.SS3.p3.2.m2.3.3.2.2.3.1.cmml">⁢</mo><mi id="S3.SS3.p3.2.m2.3.3.2.2.3.5" xref="S3.SS3.p3.2.m2.3.3.2.2.3.5.cmml">k</mi><mo id="S3.SS3.p3.2.m2.3.3.2.2.3.1c" xref="S3.SS3.p3.2.m2.3.3.2.2.3.1.cmml">⁢</mo><mn id="S3.SS3.p3.2.m2.3.3.2.2.3.6" xref="S3.SS3.p3.2.m2.3.3.2.2.3.6.cmml">2</mn></mrow></msub><mo id="S3.SS3.p3.2.m2.4.4.3.6" xref="S3.SS3.p3.2.m2.4.4.4.cmml">,</mo><mi id="S3.SS3.p3.2.m2.1.1" mathvariant="normal" xref="S3.SS3.p3.2.m2.1.1.cmml">…</mi><mo id="S3.SS3.p3.2.m2.4.4.3.7" xref="S3.SS3.p3.2.m2.4.4.4.cmml">,</mo><msub id="S3.SS3.p3.2.m2.4.4.3.3" xref="S3.SS3.p3.2.m2.4.4.3.3.cmml"><mi id="S3.SS3.p3.2.m2.4.4.3.3.2" xref="S3.SS3.p3.2.m2.4.4.3.3.2.cmml">F</mi><mrow id="S3.SS3.p3.2.m2.4.4.3.3.3" xref="S3.SS3.p3.2.m2.4.4.3.3.3.cmml"><mi id="S3.SS3.p3.2.m2.4.4.3.3.3.2" xref="S3.SS3.p3.2.m2.4.4.3.3.3.2.cmml">t</mi><mo id="S3.SS3.p3.2.m2.4.4.3.3.3.1" xref="S3.SS3.p3.2.m2.4.4.3.3.3.1.cmml">⁢</mo><mi id="S3.SS3.p3.2.m2.4.4.3.3.3.3" xref="S3.SS3.p3.2.m2.4.4.3.3.3.3.cmml">a</mi><mo id="S3.SS3.p3.2.m2.4.4.3.3.3.1a" xref="S3.SS3.p3.2.m2.4.4.3.3.3.1.cmml">⁢</mo><mi id="S3.SS3.p3.2.m2.4.4.3.3.3.4" xref="S3.SS3.p3.2.m2.4.4.3.3.3.4.cmml">s</mi><mo id="S3.SS3.p3.2.m2.4.4.3.3.3.1b" xref="S3.SS3.p3.2.m2.4.4.3.3.3.1.cmml">⁢</mo><mi id="S3.SS3.p3.2.m2.4.4.3.3.3.5" xref="S3.SS3.p3.2.m2.4.4.3.3.3.5.cmml">k</mi><mo id="S3.SS3.p3.2.m2.4.4.3.3.3.1c" xref="S3.SS3.p3.2.m2.4.4.3.3.3.1.cmml">⁢</mo><mi id="S3.SS3.p3.2.m2.4.4.3.3.3.6" xref="S3.SS3.p3.2.m2.4.4.3.3.3.6.cmml">N</mi></mrow></msub><mo id="S3.SS3.p3.2.m2.4.4.3.8" stretchy="false" xref="S3.SS3.p3.2.m2.4.4.4.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.2.m2.4b"><set id="S3.SS3.p3.2.m2.4.4.4.cmml" xref="S3.SS3.p3.2.m2.4.4.3"><apply id="S3.SS3.p3.2.m2.2.2.1.1.cmml" xref="S3.SS3.p3.2.m2.2.2.1.1"><csymbol cd="ambiguous" id="S3.SS3.p3.2.m2.2.2.1.1.1.cmml" xref="S3.SS3.p3.2.m2.2.2.1.1">subscript</csymbol><ci id="S3.SS3.p3.2.m2.2.2.1.1.2.cmml" xref="S3.SS3.p3.2.m2.2.2.1.1.2">𝐹</ci><apply id="S3.SS3.p3.2.m2.2.2.1.1.3.cmml" xref="S3.SS3.p3.2.m2.2.2.1.1.3"><times id="S3.SS3.p3.2.m2.2.2.1.1.3.1.cmml" xref="S3.SS3.p3.2.m2.2.2.1.1.3.1"></times><ci id="S3.SS3.p3.2.m2.2.2.1.1.3.2.cmml" xref="S3.SS3.p3.2.m2.2.2.1.1.3.2">𝑡</ci><ci id="S3.SS3.p3.2.m2.2.2.1.1.3.3.cmml" xref="S3.SS3.p3.2.m2.2.2.1.1.3.3">𝑎</ci><ci id="S3.SS3.p3.2.m2.2.2.1.1.3.4.cmml" xref="S3.SS3.p3.2.m2.2.2.1.1.3.4">𝑠</ci><ci id="S3.SS3.p3.2.m2.2.2.1.1.3.5.cmml" xref="S3.SS3.p3.2.m2.2.2.1.1.3.5">𝑘</ci><cn id="S3.SS3.p3.2.m2.2.2.1.1.3.6.cmml" type="integer" xref="S3.SS3.p3.2.m2.2.2.1.1.3.6">1</cn></apply></apply><apply id="S3.SS3.p3.2.m2.3.3.2.2.cmml" xref="S3.SS3.p3.2.m2.3.3.2.2"><csymbol cd="ambiguous" id="S3.SS3.p3.2.m2.3.3.2.2.1.cmml" xref="S3.SS3.p3.2.m2.3.3.2.2">subscript</csymbol><ci id="S3.SS3.p3.2.m2.3.3.2.2.2.cmml" xref="S3.SS3.p3.2.m2.3.3.2.2.2">𝐹</ci><apply id="S3.SS3.p3.2.m2.3.3.2.2.3.cmml" xref="S3.SS3.p3.2.m2.3.3.2.2.3"><times id="S3.SS3.p3.2.m2.3.3.2.2.3.1.cmml" xref="S3.SS3.p3.2.m2.3.3.2.2.3.1"></times><ci id="S3.SS3.p3.2.m2.3.3.2.2.3.2.cmml" xref="S3.SS3.p3.2.m2.3.3.2.2.3.2">𝑡</ci><ci id="S3.SS3.p3.2.m2.3.3.2.2.3.3.cmml" xref="S3.SS3.p3.2.m2.3.3.2.2.3.3">𝑎</ci><ci id="S3.SS3.p3.2.m2.3.3.2.2.3.4.cmml" xref="S3.SS3.p3.2.m2.3.3.2.2.3.4">𝑠</ci><ci id="S3.SS3.p3.2.m2.3.3.2.2.3.5.cmml" xref="S3.SS3.p3.2.m2.3.3.2.2.3.5">𝑘</ci><cn id="S3.SS3.p3.2.m2.3.3.2.2.3.6.cmml" type="integer" xref="S3.SS3.p3.2.m2.3.3.2.2.3.6">2</cn></apply></apply><ci id="S3.SS3.p3.2.m2.1.1.cmml" xref="S3.SS3.p3.2.m2.1.1">…</ci><apply id="S3.SS3.p3.2.m2.4.4.3.3.cmml" xref="S3.SS3.p3.2.m2.4.4.3.3"><csymbol cd="ambiguous" id="S3.SS3.p3.2.m2.4.4.3.3.1.cmml" xref="S3.SS3.p3.2.m2.4.4.3.3">subscript</csymbol><ci id="S3.SS3.p3.2.m2.4.4.3.3.2.cmml" xref="S3.SS3.p3.2.m2.4.4.3.3.2">𝐹</ci><apply id="S3.SS3.p3.2.m2.4.4.3.3.3.cmml" xref="S3.SS3.p3.2.m2.4.4.3.3.3"><times id="S3.SS3.p3.2.m2.4.4.3.3.3.1.cmml" xref="S3.SS3.p3.2.m2.4.4.3.3.3.1"></times><ci id="S3.SS3.p3.2.m2.4.4.3.3.3.2.cmml" xref="S3.SS3.p3.2.m2.4.4.3.3.3.2">𝑡</ci><ci id="S3.SS3.p3.2.m2.4.4.3.3.3.3.cmml" xref="S3.SS3.p3.2.m2.4.4.3.3.3.3">𝑎</ci><ci id="S3.SS3.p3.2.m2.4.4.3.3.3.4.cmml" xref="S3.SS3.p3.2.m2.4.4.3.3.3.4">𝑠</ci><ci id="S3.SS3.p3.2.m2.4.4.3.3.3.5.cmml" xref="S3.SS3.p3.2.m2.4.4.3.3.3.5">𝑘</ci><ci id="S3.SS3.p3.2.m2.4.4.3.3.3.6.cmml" xref="S3.SS3.p3.2.m2.4.4.3.3.3.6">𝑁</ci></apply></apply></set></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.2.m2.4c">\{F_{task1},F_{task2},...,F_{taskN}\}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p3.2.m2.4d">{ italic_F start_POSTSUBSCRIPT italic_t italic_a italic_s italic_k 1 end_POSTSUBSCRIPT , italic_F start_POSTSUBSCRIPT italic_t italic_a italic_s italic_k 2 end_POSTSUBSCRIPT , … , italic_F start_POSTSUBSCRIPT italic_t italic_a italic_s italic_k italic_N end_POSTSUBSCRIPT }</annotation></semantics></math> based on the Task ID of the current task. This selected feature <math alttext="F_{tp}" class="ltx_Math" display="inline" id="S3.SS3.p3.3.m3.1"><semantics id="S3.SS3.p3.3.m3.1a"><msub id="S3.SS3.p3.3.m3.1.1" xref="S3.SS3.p3.3.m3.1.1.cmml"><mi id="S3.SS3.p3.3.m3.1.1.2" xref="S3.SS3.p3.3.m3.1.1.2.cmml">F</mi><mrow id="S3.SS3.p3.3.m3.1.1.3" xref="S3.SS3.p3.3.m3.1.1.3.cmml"><mi id="S3.SS3.p3.3.m3.1.1.3.2" xref="S3.SS3.p3.3.m3.1.1.3.2.cmml">t</mi><mo id="S3.SS3.p3.3.m3.1.1.3.1" xref="S3.SS3.p3.3.m3.1.1.3.1.cmml">⁢</mo><mi id="S3.SS3.p3.3.m3.1.1.3.3" xref="S3.SS3.p3.3.m3.1.1.3.3.cmml">p</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.3.m3.1b"><apply id="S3.SS3.p3.3.m3.1.1.cmml" xref="S3.SS3.p3.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS3.p3.3.m3.1.1.1.cmml" xref="S3.SS3.p3.3.m3.1.1">subscript</csymbol><ci id="S3.SS3.p3.3.m3.1.1.2.cmml" xref="S3.SS3.p3.3.m3.1.1.2">𝐹</ci><apply id="S3.SS3.p3.3.m3.1.1.3.cmml" xref="S3.SS3.p3.3.m3.1.1.3"><times id="S3.SS3.p3.3.m3.1.1.3.1.cmml" xref="S3.SS3.p3.3.m3.1.1.3.1"></times><ci id="S3.SS3.p3.3.m3.1.1.3.2.cmml" xref="S3.SS3.p3.3.m3.1.1.3.2">𝑡</ci><ci id="S3.SS3.p3.3.m3.1.1.3.3.cmml" xref="S3.SS3.p3.3.m3.1.1.3.3">𝑝</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.3.m3.1c">F_{tp}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p3.3.m3.1d">italic_F start_POSTSUBSCRIPT italic_t italic_p end_POSTSUBSCRIPT</annotation></semantics></math> is concatenated with <math alttext="F" class="ltx_Math" display="inline" id="S3.SS3.p3.4.m4.1"><semantics id="S3.SS3.p3.4.m4.1a"><mi id="S3.SS3.p3.4.m4.1.1" xref="S3.SS3.p3.4.m4.1.1.cmml">F</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.4.m4.1b"><ci id="S3.SS3.p3.4.m4.1.1.cmml" xref="S3.SS3.p3.4.m4.1.1">𝐹</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.4.m4.1c">F</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p3.4.m4.1d">italic_F</annotation></semantics></math> to form the input for the decoder. Notably, for 2D data, we perform interpolation on the sample-specific features and task-specific prior to ensure alignment with the shapes of the universal task prompt and sample-specific features, respectively. This method introduces task-related priors into the model at the end of the encoding process, enhancing the task-specific training of the entire decoder rather than limiting it to the final convolutional layers or the entire feed-forward process.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4 </span><span class="ltx_text ltx_font_italic" id="S3.SS4.1.1">Modal-specific Prompts for Modal Priors</span>
</h3>
<div class="ltx_para" id="S3.SS4.p1">
<p class="ltx_p" id="S3.SS4.p1.9">As the number of modalities increases, optimization challenges arising from significant gaps among these modalities can hinder effective learning <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib20" title="">20</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib21" title="">21</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib22" title="">22</a>]</cite>. To address this issue, we introduce a strategy that enhances the model’s ability to ‘aware’ these modal gaps by incorporating modal-specific priors. This is achieved through a set of learnable modal prompts, denoted by <math alttext="F_{mod}=\{F_{mod_{1}},F_{mod_{2}},...,F_{mod_{M}}\}" class="ltx_Math" display="inline" id="S3.SS4.p1.1.m1.4"><semantics id="S3.SS4.p1.1.m1.4a"><mrow id="S3.SS4.p1.1.m1.4.4" xref="S3.SS4.p1.1.m1.4.4.cmml"><msub id="S3.SS4.p1.1.m1.4.4.5" xref="S3.SS4.p1.1.m1.4.4.5.cmml"><mi id="S3.SS4.p1.1.m1.4.4.5.2" xref="S3.SS4.p1.1.m1.4.4.5.2.cmml">F</mi><mrow id="S3.SS4.p1.1.m1.4.4.5.3" xref="S3.SS4.p1.1.m1.4.4.5.3.cmml"><mi id="S3.SS4.p1.1.m1.4.4.5.3.2" xref="S3.SS4.p1.1.m1.4.4.5.3.2.cmml">m</mi><mo id="S3.SS4.p1.1.m1.4.4.5.3.1" xref="S3.SS4.p1.1.m1.4.4.5.3.1.cmml">⁢</mo><mi id="S3.SS4.p1.1.m1.4.4.5.3.3" xref="S3.SS4.p1.1.m1.4.4.5.3.3.cmml">o</mi><mo id="S3.SS4.p1.1.m1.4.4.5.3.1a" xref="S3.SS4.p1.1.m1.4.4.5.3.1.cmml">⁢</mo><mi id="S3.SS4.p1.1.m1.4.4.5.3.4" xref="S3.SS4.p1.1.m1.4.4.5.3.4.cmml">d</mi></mrow></msub><mo id="S3.SS4.p1.1.m1.4.4.4" xref="S3.SS4.p1.1.m1.4.4.4.cmml">=</mo><mrow id="S3.SS4.p1.1.m1.4.4.3.3" xref="S3.SS4.p1.1.m1.4.4.3.4.cmml"><mo id="S3.SS4.p1.1.m1.4.4.3.3.4" stretchy="false" xref="S3.SS4.p1.1.m1.4.4.3.4.cmml">{</mo><msub id="S3.SS4.p1.1.m1.2.2.1.1.1" xref="S3.SS4.p1.1.m1.2.2.1.1.1.cmml"><mi id="S3.SS4.p1.1.m1.2.2.1.1.1.2" xref="S3.SS4.p1.1.m1.2.2.1.1.1.2.cmml">F</mi><mrow id="S3.SS4.p1.1.m1.2.2.1.1.1.3" xref="S3.SS4.p1.1.m1.2.2.1.1.1.3.cmml"><mi id="S3.SS4.p1.1.m1.2.2.1.1.1.3.2" xref="S3.SS4.p1.1.m1.2.2.1.1.1.3.2.cmml">m</mi><mo id="S3.SS4.p1.1.m1.2.2.1.1.1.3.1" xref="S3.SS4.p1.1.m1.2.2.1.1.1.3.1.cmml">⁢</mo><mi id="S3.SS4.p1.1.m1.2.2.1.1.1.3.3" xref="S3.SS4.p1.1.m1.2.2.1.1.1.3.3.cmml">o</mi><mo id="S3.SS4.p1.1.m1.2.2.1.1.1.3.1a" xref="S3.SS4.p1.1.m1.2.2.1.1.1.3.1.cmml">⁢</mo><msub id="S3.SS4.p1.1.m1.2.2.1.1.1.3.4" xref="S3.SS4.p1.1.m1.2.2.1.1.1.3.4.cmml"><mi id="S3.SS4.p1.1.m1.2.2.1.1.1.3.4.2" xref="S3.SS4.p1.1.m1.2.2.1.1.1.3.4.2.cmml">d</mi><mn id="S3.SS4.p1.1.m1.2.2.1.1.1.3.4.3" xref="S3.SS4.p1.1.m1.2.2.1.1.1.3.4.3.cmml">1</mn></msub></mrow></msub><mo id="S3.SS4.p1.1.m1.4.4.3.3.5" xref="S3.SS4.p1.1.m1.4.4.3.4.cmml">,</mo><msub id="S3.SS4.p1.1.m1.3.3.2.2.2" xref="S3.SS4.p1.1.m1.3.3.2.2.2.cmml"><mi id="S3.SS4.p1.1.m1.3.3.2.2.2.2" xref="S3.SS4.p1.1.m1.3.3.2.2.2.2.cmml">F</mi><mrow id="S3.SS4.p1.1.m1.3.3.2.2.2.3" xref="S3.SS4.p1.1.m1.3.3.2.2.2.3.cmml"><mi id="S3.SS4.p1.1.m1.3.3.2.2.2.3.2" xref="S3.SS4.p1.1.m1.3.3.2.2.2.3.2.cmml">m</mi><mo id="S3.SS4.p1.1.m1.3.3.2.2.2.3.1" xref="S3.SS4.p1.1.m1.3.3.2.2.2.3.1.cmml">⁢</mo><mi id="S3.SS4.p1.1.m1.3.3.2.2.2.3.3" xref="S3.SS4.p1.1.m1.3.3.2.2.2.3.3.cmml">o</mi><mo id="S3.SS4.p1.1.m1.3.3.2.2.2.3.1a" xref="S3.SS4.p1.1.m1.3.3.2.2.2.3.1.cmml">⁢</mo><msub id="S3.SS4.p1.1.m1.3.3.2.2.2.3.4" xref="S3.SS4.p1.1.m1.3.3.2.2.2.3.4.cmml"><mi id="S3.SS4.p1.1.m1.3.3.2.2.2.3.4.2" xref="S3.SS4.p1.1.m1.3.3.2.2.2.3.4.2.cmml">d</mi><mn id="S3.SS4.p1.1.m1.3.3.2.2.2.3.4.3" xref="S3.SS4.p1.1.m1.3.3.2.2.2.3.4.3.cmml">2</mn></msub></mrow></msub><mo id="S3.SS4.p1.1.m1.4.4.3.3.6" xref="S3.SS4.p1.1.m1.4.4.3.4.cmml">,</mo><mi id="S3.SS4.p1.1.m1.1.1" mathvariant="normal" xref="S3.SS4.p1.1.m1.1.1.cmml">…</mi><mo id="S3.SS4.p1.1.m1.4.4.3.3.7" xref="S3.SS4.p1.1.m1.4.4.3.4.cmml">,</mo><msub id="S3.SS4.p1.1.m1.4.4.3.3.3" xref="S3.SS4.p1.1.m1.4.4.3.3.3.cmml"><mi id="S3.SS4.p1.1.m1.4.4.3.3.3.2" xref="S3.SS4.p1.1.m1.4.4.3.3.3.2.cmml">F</mi><mrow id="S3.SS4.p1.1.m1.4.4.3.3.3.3" xref="S3.SS4.p1.1.m1.4.4.3.3.3.3.cmml"><mi id="S3.SS4.p1.1.m1.4.4.3.3.3.3.2" xref="S3.SS4.p1.1.m1.4.4.3.3.3.3.2.cmml">m</mi><mo id="S3.SS4.p1.1.m1.4.4.3.3.3.3.1" xref="S3.SS4.p1.1.m1.4.4.3.3.3.3.1.cmml">⁢</mo><mi id="S3.SS4.p1.1.m1.4.4.3.3.3.3.3" xref="S3.SS4.p1.1.m1.4.4.3.3.3.3.3.cmml">o</mi><mo id="S3.SS4.p1.1.m1.4.4.3.3.3.3.1a" xref="S3.SS4.p1.1.m1.4.4.3.3.3.3.1.cmml">⁢</mo><msub id="S3.SS4.p1.1.m1.4.4.3.3.3.3.4" xref="S3.SS4.p1.1.m1.4.4.3.3.3.3.4.cmml"><mi id="S3.SS4.p1.1.m1.4.4.3.3.3.3.4.2" xref="S3.SS4.p1.1.m1.4.4.3.3.3.3.4.2.cmml">d</mi><mi id="S3.SS4.p1.1.m1.4.4.3.3.3.3.4.3" xref="S3.SS4.p1.1.m1.4.4.3.3.3.3.4.3.cmml">M</mi></msub></mrow></msub><mo id="S3.SS4.p1.1.m1.4.4.3.3.8" stretchy="false" xref="S3.SS4.p1.1.m1.4.4.3.4.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.1.m1.4b"><apply id="S3.SS4.p1.1.m1.4.4.cmml" xref="S3.SS4.p1.1.m1.4.4"><eq id="S3.SS4.p1.1.m1.4.4.4.cmml" xref="S3.SS4.p1.1.m1.4.4.4"></eq><apply id="S3.SS4.p1.1.m1.4.4.5.cmml" xref="S3.SS4.p1.1.m1.4.4.5"><csymbol cd="ambiguous" id="S3.SS4.p1.1.m1.4.4.5.1.cmml" xref="S3.SS4.p1.1.m1.4.4.5">subscript</csymbol><ci id="S3.SS4.p1.1.m1.4.4.5.2.cmml" xref="S3.SS4.p1.1.m1.4.4.5.2">𝐹</ci><apply id="S3.SS4.p1.1.m1.4.4.5.3.cmml" xref="S3.SS4.p1.1.m1.4.4.5.3"><times id="S3.SS4.p1.1.m1.4.4.5.3.1.cmml" xref="S3.SS4.p1.1.m1.4.4.5.3.1"></times><ci id="S3.SS4.p1.1.m1.4.4.5.3.2.cmml" xref="S3.SS4.p1.1.m1.4.4.5.3.2">𝑚</ci><ci id="S3.SS4.p1.1.m1.4.4.5.3.3.cmml" xref="S3.SS4.p1.1.m1.4.4.5.3.3">𝑜</ci><ci id="S3.SS4.p1.1.m1.4.4.5.3.4.cmml" xref="S3.SS4.p1.1.m1.4.4.5.3.4">𝑑</ci></apply></apply><set id="S3.SS4.p1.1.m1.4.4.3.4.cmml" xref="S3.SS4.p1.1.m1.4.4.3.3"><apply id="S3.SS4.p1.1.m1.2.2.1.1.1.cmml" xref="S3.SS4.p1.1.m1.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.SS4.p1.1.m1.2.2.1.1.1.1.cmml" xref="S3.SS4.p1.1.m1.2.2.1.1.1">subscript</csymbol><ci id="S3.SS4.p1.1.m1.2.2.1.1.1.2.cmml" xref="S3.SS4.p1.1.m1.2.2.1.1.1.2">𝐹</ci><apply id="S3.SS4.p1.1.m1.2.2.1.1.1.3.cmml" xref="S3.SS4.p1.1.m1.2.2.1.1.1.3"><times id="S3.SS4.p1.1.m1.2.2.1.1.1.3.1.cmml" xref="S3.SS4.p1.1.m1.2.2.1.1.1.3.1"></times><ci id="S3.SS4.p1.1.m1.2.2.1.1.1.3.2.cmml" xref="S3.SS4.p1.1.m1.2.2.1.1.1.3.2">𝑚</ci><ci id="S3.SS4.p1.1.m1.2.2.1.1.1.3.3.cmml" xref="S3.SS4.p1.1.m1.2.2.1.1.1.3.3">𝑜</ci><apply id="S3.SS4.p1.1.m1.2.2.1.1.1.3.4.cmml" xref="S3.SS4.p1.1.m1.2.2.1.1.1.3.4"><csymbol cd="ambiguous" id="S3.SS4.p1.1.m1.2.2.1.1.1.3.4.1.cmml" xref="S3.SS4.p1.1.m1.2.2.1.1.1.3.4">subscript</csymbol><ci id="S3.SS4.p1.1.m1.2.2.1.1.1.3.4.2.cmml" xref="S3.SS4.p1.1.m1.2.2.1.1.1.3.4.2">𝑑</ci><cn id="S3.SS4.p1.1.m1.2.2.1.1.1.3.4.3.cmml" type="integer" xref="S3.SS4.p1.1.m1.2.2.1.1.1.3.4.3">1</cn></apply></apply></apply><apply id="S3.SS4.p1.1.m1.3.3.2.2.2.cmml" xref="S3.SS4.p1.1.m1.3.3.2.2.2"><csymbol cd="ambiguous" id="S3.SS4.p1.1.m1.3.3.2.2.2.1.cmml" xref="S3.SS4.p1.1.m1.3.3.2.2.2">subscript</csymbol><ci id="S3.SS4.p1.1.m1.3.3.2.2.2.2.cmml" xref="S3.SS4.p1.1.m1.3.3.2.2.2.2">𝐹</ci><apply id="S3.SS4.p1.1.m1.3.3.2.2.2.3.cmml" xref="S3.SS4.p1.1.m1.3.3.2.2.2.3"><times id="S3.SS4.p1.1.m1.3.3.2.2.2.3.1.cmml" xref="S3.SS4.p1.1.m1.3.3.2.2.2.3.1"></times><ci id="S3.SS4.p1.1.m1.3.3.2.2.2.3.2.cmml" xref="S3.SS4.p1.1.m1.3.3.2.2.2.3.2">𝑚</ci><ci id="S3.SS4.p1.1.m1.3.3.2.2.2.3.3.cmml" xref="S3.SS4.p1.1.m1.3.3.2.2.2.3.3">𝑜</ci><apply id="S3.SS4.p1.1.m1.3.3.2.2.2.3.4.cmml" xref="S3.SS4.p1.1.m1.3.3.2.2.2.3.4"><csymbol cd="ambiguous" id="S3.SS4.p1.1.m1.3.3.2.2.2.3.4.1.cmml" xref="S3.SS4.p1.1.m1.3.3.2.2.2.3.4">subscript</csymbol><ci id="S3.SS4.p1.1.m1.3.3.2.2.2.3.4.2.cmml" xref="S3.SS4.p1.1.m1.3.3.2.2.2.3.4.2">𝑑</ci><cn id="S3.SS4.p1.1.m1.3.3.2.2.2.3.4.3.cmml" type="integer" xref="S3.SS4.p1.1.m1.3.3.2.2.2.3.4.3">2</cn></apply></apply></apply><ci id="S3.SS4.p1.1.m1.1.1.cmml" xref="S3.SS4.p1.1.m1.1.1">…</ci><apply id="S3.SS4.p1.1.m1.4.4.3.3.3.cmml" xref="S3.SS4.p1.1.m1.4.4.3.3.3"><csymbol cd="ambiguous" id="S3.SS4.p1.1.m1.4.4.3.3.3.1.cmml" xref="S3.SS4.p1.1.m1.4.4.3.3.3">subscript</csymbol><ci id="S3.SS4.p1.1.m1.4.4.3.3.3.2.cmml" xref="S3.SS4.p1.1.m1.4.4.3.3.3.2">𝐹</ci><apply id="S3.SS4.p1.1.m1.4.4.3.3.3.3.cmml" xref="S3.SS4.p1.1.m1.4.4.3.3.3.3"><times id="S3.SS4.p1.1.m1.4.4.3.3.3.3.1.cmml" xref="S3.SS4.p1.1.m1.4.4.3.3.3.3.1"></times><ci id="S3.SS4.p1.1.m1.4.4.3.3.3.3.2.cmml" xref="S3.SS4.p1.1.m1.4.4.3.3.3.3.2">𝑚</ci><ci id="S3.SS4.p1.1.m1.4.4.3.3.3.3.3.cmml" xref="S3.SS4.p1.1.m1.4.4.3.3.3.3.3">𝑜</ci><apply id="S3.SS4.p1.1.m1.4.4.3.3.3.3.4.cmml" xref="S3.SS4.p1.1.m1.4.4.3.3.3.3.4"><csymbol cd="ambiguous" id="S3.SS4.p1.1.m1.4.4.3.3.3.3.4.1.cmml" xref="S3.SS4.p1.1.m1.4.4.3.3.3.3.4">subscript</csymbol><ci id="S3.SS4.p1.1.m1.4.4.3.3.3.3.4.2.cmml" xref="S3.SS4.p1.1.m1.4.4.3.3.3.3.4.2">𝑑</ci><ci id="S3.SS4.p1.1.m1.4.4.3.3.3.3.4.3.cmml" xref="S3.SS4.p1.1.m1.4.4.3.3.3.3.4.3">𝑀</ci></apply></apply></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.1.m1.4c">F_{mod}=\{F_{mod_{1}},F_{mod_{2}},...,F_{mod_{M}}\}</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p1.1.m1.4d">italic_F start_POSTSUBSCRIPT italic_m italic_o italic_d end_POSTSUBSCRIPT = { italic_F start_POSTSUBSCRIPT italic_m italic_o italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT , italic_F start_POSTSUBSCRIPT italic_m italic_o italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_POSTSUBSCRIPT , … , italic_F start_POSTSUBSCRIPT italic_m italic_o italic_d start_POSTSUBSCRIPT italic_M end_POSTSUBSCRIPT end_POSTSUBSCRIPT }</annotation></semantics></math>, where <math alttext="F_{mod_{M}}\in\mathbb{R}^{l}" class="ltx_Math" display="inline" id="S3.SS4.p1.2.m2.1"><semantics id="S3.SS4.p1.2.m2.1a"><mrow id="S3.SS4.p1.2.m2.1.1" xref="S3.SS4.p1.2.m2.1.1.cmml"><msub id="S3.SS4.p1.2.m2.1.1.2" xref="S3.SS4.p1.2.m2.1.1.2.cmml"><mi id="S3.SS4.p1.2.m2.1.1.2.2" xref="S3.SS4.p1.2.m2.1.1.2.2.cmml">F</mi><mrow id="S3.SS4.p1.2.m2.1.1.2.3" xref="S3.SS4.p1.2.m2.1.1.2.3.cmml"><mi id="S3.SS4.p1.2.m2.1.1.2.3.2" xref="S3.SS4.p1.2.m2.1.1.2.3.2.cmml">m</mi><mo id="S3.SS4.p1.2.m2.1.1.2.3.1" xref="S3.SS4.p1.2.m2.1.1.2.3.1.cmml">⁢</mo><mi id="S3.SS4.p1.2.m2.1.1.2.3.3" xref="S3.SS4.p1.2.m2.1.1.2.3.3.cmml">o</mi><mo id="S3.SS4.p1.2.m2.1.1.2.3.1a" xref="S3.SS4.p1.2.m2.1.1.2.3.1.cmml">⁢</mo><msub id="S3.SS4.p1.2.m2.1.1.2.3.4" xref="S3.SS4.p1.2.m2.1.1.2.3.4.cmml"><mi id="S3.SS4.p1.2.m2.1.1.2.3.4.2" xref="S3.SS4.p1.2.m2.1.1.2.3.4.2.cmml">d</mi><mi id="S3.SS4.p1.2.m2.1.1.2.3.4.3" xref="S3.SS4.p1.2.m2.1.1.2.3.4.3.cmml">M</mi></msub></mrow></msub><mo id="S3.SS4.p1.2.m2.1.1.1" xref="S3.SS4.p1.2.m2.1.1.1.cmml">∈</mo><msup id="S3.SS4.p1.2.m2.1.1.3" xref="S3.SS4.p1.2.m2.1.1.3.cmml"><mi id="S3.SS4.p1.2.m2.1.1.3.2" xref="S3.SS4.p1.2.m2.1.1.3.2.cmml">ℝ</mi><mi id="S3.SS4.p1.2.m2.1.1.3.3" xref="S3.SS4.p1.2.m2.1.1.3.3.cmml">l</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.2.m2.1b"><apply id="S3.SS4.p1.2.m2.1.1.cmml" xref="S3.SS4.p1.2.m2.1.1"><in id="S3.SS4.p1.2.m2.1.1.1.cmml" xref="S3.SS4.p1.2.m2.1.1.1"></in><apply id="S3.SS4.p1.2.m2.1.1.2.cmml" xref="S3.SS4.p1.2.m2.1.1.2"><csymbol cd="ambiguous" id="S3.SS4.p1.2.m2.1.1.2.1.cmml" xref="S3.SS4.p1.2.m2.1.1.2">subscript</csymbol><ci id="S3.SS4.p1.2.m2.1.1.2.2.cmml" xref="S3.SS4.p1.2.m2.1.1.2.2">𝐹</ci><apply id="S3.SS4.p1.2.m2.1.1.2.3.cmml" xref="S3.SS4.p1.2.m2.1.1.2.3"><times id="S3.SS4.p1.2.m2.1.1.2.3.1.cmml" xref="S3.SS4.p1.2.m2.1.1.2.3.1"></times><ci id="S3.SS4.p1.2.m2.1.1.2.3.2.cmml" xref="S3.SS4.p1.2.m2.1.1.2.3.2">𝑚</ci><ci id="S3.SS4.p1.2.m2.1.1.2.3.3.cmml" xref="S3.SS4.p1.2.m2.1.1.2.3.3">𝑜</ci><apply id="S3.SS4.p1.2.m2.1.1.2.3.4.cmml" xref="S3.SS4.p1.2.m2.1.1.2.3.4"><csymbol cd="ambiguous" id="S3.SS4.p1.2.m2.1.1.2.3.4.1.cmml" xref="S3.SS4.p1.2.m2.1.1.2.3.4">subscript</csymbol><ci id="S3.SS4.p1.2.m2.1.1.2.3.4.2.cmml" xref="S3.SS4.p1.2.m2.1.1.2.3.4.2">𝑑</ci><ci id="S3.SS4.p1.2.m2.1.1.2.3.4.3.cmml" xref="S3.SS4.p1.2.m2.1.1.2.3.4.3">𝑀</ci></apply></apply></apply><apply id="S3.SS4.p1.2.m2.1.1.3.cmml" xref="S3.SS4.p1.2.m2.1.1.3"><csymbol cd="ambiguous" id="S3.SS4.p1.2.m2.1.1.3.1.cmml" xref="S3.SS4.p1.2.m2.1.1.3">superscript</csymbol><ci id="S3.SS4.p1.2.m2.1.1.3.2.cmml" xref="S3.SS4.p1.2.m2.1.1.3.2">ℝ</ci><ci id="S3.SS4.p1.2.m2.1.1.3.3.cmml" xref="S3.SS4.p1.2.m2.1.1.3.3">𝑙</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.2.m2.1c">F_{mod_{M}}\in\mathbb{R}^{l}</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p1.2.m2.1d">italic_F start_POSTSUBSCRIPT italic_m italic_o italic_d start_POSTSUBSCRIPT italic_M end_POSTSUBSCRIPT end_POSTSUBSCRIPT ∈ blackboard_R start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT</annotation></semantics></math> represents the prompt corresponding to the modality with ID <math alttext="M" class="ltx_Math" display="inline" id="S3.SS4.p1.3.m3.1"><semantics id="S3.SS4.p1.3.m3.1a"><mi id="S3.SS4.p1.3.m3.1.1" xref="S3.SS4.p1.3.m3.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.3.m3.1b"><ci id="S3.SS4.p1.3.m3.1.1.cmml" xref="S3.SS4.p1.3.m3.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.3.m3.1c">M</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p1.3.m3.1d">italic_M</annotation></semantics></math>, and <math alttext="l" class="ltx_Math" display="inline" id="S3.SS4.p1.4.m4.1"><semantics id="S3.SS4.p1.4.m4.1a"><mi id="S3.SS4.p1.4.m4.1.1" xref="S3.SS4.p1.4.m4.1.1.cmml">l</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.4.m4.1b"><ci id="S3.SS4.p1.4.m4.1.1.cmml" xref="S3.SS4.p1.4.m4.1.1">𝑙</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.4.m4.1c">l</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p1.4.m4.1d">italic_l</annotation></semantics></math> is the length of each prompt.
The process begins with selecting the modal-specific prompt based on the modality ID of the input image. The selected prompt is then processed through the MMap module, which adapts the prompt to the input data’s shape. The MMap module consists of a linear layer that maps the prompt from length <math alttext="l" class="ltx_Math" display="inline" id="S3.SS4.p1.5.m5.1"><semantics id="S3.SS4.p1.5.m5.1a"><mi id="S3.SS4.p1.5.m5.1.1" xref="S3.SS4.p1.5.m5.1.1.cmml">l</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.5.m5.1b"><ci id="S3.SS4.p1.5.m5.1.1.cmml" xref="S3.SS4.p1.5.m5.1.1">𝑙</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.5.m5.1c">l</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p1.5.m5.1d">italic_l</annotation></semantics></math> to <math alttext="144" class="ltx_Math" display="inline" id="S3.SS4.p1.6.m6.1"><semantics id="S3.SS4.p1.6.m6.1a"><mn id="S3.SS4.p1.6.m6.1.1" xref="S3.SS4.p1.6.m6.1.1.cmml">144</mn><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.6.m6.1b"><cn id="S3.SS4.p1.6.m6.1.1.cmml" type="integer" xref="S3.SS4.p1.6.m6.1.1">144</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.6.m6.1c">144</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p1.6.m6.1d">144</annotation></semantics></math>, a reshaping operation that modifies this mapped prompt from <math alttext="144" class="ltx_Math" display="inline" id="S3.SS4.p1.7.m7.1"><semantics id="S3.SS4.p1.7.m7.1a"><mn id="S3.SS4.p1.7.m7.1.1" xref="S3.SS4.p1.7.m7.1.1.cmml">144</mn><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.7.m7.1b"><cn id="S3.SS4.p1.7.m7.1.1.cmml" type="integer" xref="S3.SS4.p1.7.m7.1.1">144</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.7.m7.1c">144</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p1.7.m7.1d">144</annotation></semantics></math> to <math alttext="12\times 12" class="ltx_Math" display="inline" id="S3.SS4.p1.8.m8.1"><semantics id="S3.SS4.p1.8.m8.1a"><mrow id="S3.SS4.p1.8.m8.1.1" xref="S3.SS4.p1.8.m8.1.1.cmml"><mn id="S3.SS4.p1.8.m8.1.1.2" xref="S3.SS4.p1.8.m8.1.1.2.cmml">12</mn><mo id="S3.SS4.p1.8.m8.1.1.1" lspace="0.222em" rspace="0.222em" xref="S3.SS4.p1.8.m8.1.1.1.cmml">×</mo><mn id="S3.SS4.p1.8.m8.1.1.3" xref="S3.SS4.p1.8.m8.1.1.3.cmml">12</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.8.m8.1b"><apply id="S3.SS4.p1.8.m8.1.1.cmml" xref="S3.SS4.p1.8.m8.1.1"><times id="S3.SS4.p1.8.m8.1.1.1.cmml" xref="S3.SS4.p1.8.m8.1.1.1"></times><cn id="S3.SS4.p1.8.m8.1.1.2.cmml" type="integer" xref="S3.SS4.p1.8.m8.1.1.2">12</cn><cn id="S3.SS4.p1.8.m8.1.1.3.cmml" type="integer" xref="S3.SS4.p1.8.m8.1.1.3">12</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.8.m8.1c">12\times 12</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p1.8.m8.1d">12 × 12</annotation></semantics></math> for 2D images or <math alttext="4\times 6\times 6" class="ltx_Math" display="inline" id="S3.SS4.p1.9.m9.1"><semantics id="S3.SS4.p1.9.m9.1a"><mrow id="S3.SS4.p1.9.m9.1.1" xref="S3.SS4.p1.9.m9.1.1.cmml"><mn id="S3.SS4.p1.9.m9.1.1.2" xref="S3.SS4.p1.9.m9.1.1.2.cmml">4</mn><mo id="S3.SS4.p1.9.m9.1.1.1" lspace="0.222em" rspace="0.222em" xref="S3.SS4.p1.9.m9.1.1.1.cmml">×</mo><mn id="S3.SS4.p1.9.m9.1.1.3" xref="S3.SS4.p1.9.m9.1.1.3.cmml">6</mn><mo id="S3.SS4.p1.9.m9.1.1.1a" lspace="0.222em" rspace="0.222em" xref="S3.SS4.p1.9.m9.1.1.1.cmml">×</mo><mn id="S3.SS4.p1.9.m9.1.1.4" xref="S3.SS4.p1.9.m9.1.1.4.cmml">6</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.9.m9.1b"><apply id="S3.SS4.p1.9.m9.1.1.cmml" xref="S3.SS4.p1.9.m9.1.1"><times id="S3.SS4.p1.9.m9.1.1.1.cmml" xref="S3.SS4.p1.9.m9.1.1.1"></times><cn id="S3.SS4.p1.9.m9.1.1.2.cmml" type="integer" xref="S3.SS4.p1.9.m9.1.1.2">4</cn><cn id="S3.SS4.p1.9.m9.1.1.3.cmml" type="integer" xref="S3.SS4.p1.9.m9.1.1.3">6</cn><cn id="S3.SS4.p1.9.m9.1.1.4.cmml" type="integer" xref="S3.SS4.p1.9.m9.1.1.4">6</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.9.m9.1c">4\times 6\times 6</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p1.9.m9.1d">4 × 6 × 6</annotation></semantics></math> for 3D images, and a linear interpolation that resamples the resized prompt to match the shape of the input image.
Unlike Hermes <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib18" title="">18</a>]</cite>, which integrates the modal prior at multiple stages across the encoding and decoding processes, we introduce the prior only once at the beginning of the encoder, carefully controlling the number of parameters involved. This results in an approximate increase of 80K parameters to accommodate the prompts for nine modalities. The design principle behind the prompt’s introduction is to address differences as they arise, which is particularly crucial for modalities at the start of the encoding process.
Ultimately, the input data for the encoder are formulated by combining the input images with the modal priors, as shown below:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E2">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="Input=I+MMap(select(F_{mod},m)," class="ltx_math_unparsed" display="block" id="S3.E2.m1.1"><semantics id="S3.E2.m1.1a"><mrow id="S3.E2.m1.1b"><mi id="S3.E2.m1.1.2">I</mi><mi id="S3.E2.m1.1.3">n</mi><mi id="S3.E2.m1.1.4">p</mi><mi id="S3.E2.m1.1.5">u</mi><mi id="S3.E2.m1.1.6">t</mi><mo id="S3.E2.m1.1.7">=</mo><mi id="S3.E2.m1.1.8">I</mi><mo id="S3.E2.m1.1.9">+</mo><mi id="S3.E2.m1.1.10">M</mi><mi id="S3.E2.m1.1.11">M</mi><mi id="S3.E2.m1.1.12">a</mi><mi id="S3.E2.m1.1.13">p</mi><mrow id="S3.E2.m1.1.14"><mo id="S3.E2.m1.1.14.1" stretchy="false">(</mo><mi id="S3.E2.m1.1.14.2">s</mi><mi id="S3.E2.m1.1.14.3">e</mi><mi id="S3.E2.m1.1.14.4">l</mi><mi id="S3.E2.m1.1.14.5">e</mi><mi id="S3.E2.m1.1.14.6">c</mi><mi id="S3.E2.m1.1.14.7">t</mi><mrow id="S3.E2.m1.1.14.8"><mo id="S3.E2.m1.1.14.8.1" stretchy="false">(</mo><msub id="S3.E2.m1.1.14.8.2"><mi id="S3.E2.m1.1.14.8.2.2">F</mi><mrow id="S3.E2.m1.1.14.8.2.3"><mi id="S3.E2.m1.1.14.8.2.3.2">m</mi><mo id="S3.E2.m1.1.14.8.2.3.1">⁢</mo><mi id="S3.E2.m1.1.14.8.2.3.3">o</mi><mo id="S3.E2.m1.1.14.8.2.3.1a">⁢</mo><mi id="S3.E2.m1.1.14.8.2.3.4">d</mi></mrow></msub><mo id="S3.E2.m1.1.14.8.3">,</mo><mi id="S3.E2.m1.1.1">m</mi><mo id="S3.E2.m1.1.14.8.4" stretchy="false">)</mo></mrow><mo id="S3.E2.m1.1.14.9">,</mo></mrow></mrow><annotation encoding="application/x-tex" id="S3.E2.m1.1c">Input=I+MMap(select(F_{mod},m),</annotation><annotation encoding="application/x-llamapun" id="S3.E2.m1.1d">italic_I italic_n italic_p italic_u italic_t = italic_I + italic_M italic_M italic_a italic_p ( italic_s italic_e italic_l italic_e italic_c italic_t ( italic_F start_POSTSUBSCRIPT italic_m italic_o italic_d end_POSTSUBSCRIPT , italic_m ) ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS4.p1.15">where <math alttext="m" class="ltx_Math" display="inline" id="S3.SS4.p1.10.m1.1"><semantics id="S3.SS4.p1.10.m1.1a"><mi id="S3.SS4.p1.10.m1.1.1" xref="S3.SS4.p1.10.m1.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.10.m1.1b"><ci id="S3.SS4.p1.10.m1.1.1.cmml" xref="S3.SS4.p1.10.m1.1.1">𝑚</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.10.m1.1c">m</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p1.10.m1.1d">italic_m</annotation></semantics></math> is the modal ID of the input image <math alttext="I" class="ltx_Math" display="inline" id="S3.SS4.p1.11.m2.1"><semantics id="S3.SS4.p1.11.m2.1a"><mi id="S3.SS4.p1.11.m2.1.1" xref="S3.SS4.p1.11.m2.1.1.cmml">I</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.11.m2.1b"><ci id="S3.SS4.p1.11.m2.1.1.cmml" xref="S3.SS4.p1.11.m2.1.1">𝐼</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.11.m2.1c">I</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p1.11.m2.1d">italic_I</annotation></semantics></math>, <math alttext="select(F_{mod},m)" class="ltx_Math" display="inline" id="S3.SS4.p1.12.m3.2"><semantics id="S3.SS4.p1.12.m3.2a"><mrow id="S3.SS4.p1.12.m3.2.2" xref="S3.SS4.p1.12.m3.2.2.cmml"><mi id="S3.SS4.p1.12.m3.2.2.3" xref="S3.SS4.p1.12.m3.2.2.3.cmml">s</mi><mo id="S3.SS4.p1.12.m3.2.2.2" xref="S3.SS4.p1.12.m3.2.2.2.cmml">⁢</mo><mi id="S3.SS4.p1.12.m3.2.2.4" xref="S3.SS4.p1.12.m3.2.2.4.cmml">e</mi><mo id="S3.SS4.p1.12.m3.2.2.2a" xref="S3.SS4.p1.12.m3.2.2.2.cmml">⁢</mo><mi id="S3.SS4.p1.12.m3.2.2.5" xref="S3.SS4.p1.12.m3.2.2.5.cmml">l</mi><mo id="S3.SS4.p1.12.m3.2.2.2b" xref="S3.SS4.p1.12.m3.2.2.2.cmml">⁢</mo><mi id="S3.SS4.p1.12.m3.2.2.6" xref="S3.SS4.p1.12.m3.2.2.6.cmml">e</mi><mo id="S3.SS4.p1.12.m3.2.2.2c" xref="S3.SS4.p1.12.m3.2.2.2.cmml">⁢</mo><mi id="S3.SS4.p1.12.m3.2.2.7" xref="S3.SS4.p1.12.m3.2.2.7.cmml">c</mi><mo id="S3.SS4.p1.12.m3.2.2.2d" xref="S3.SS4.p1.12.m3.2.2.2.cmml">⁢</mo><mi id="S3.SS4.p1.12.m3.2.2.8" xref="S3.SS4.p1.12.m3.2.2.8.cmml">t</mi><mo id="S3.SS4.p1.12.m3.2.2.2e" xref="S3.SS4.p1.12.m3.2.2.2.cmml">⁢</mo><mrow id="S3.SS4.p1.12.m3.2.2.1.1" xref="S3.SS4.p1.12.m3.2.2.1.2.cmml"><mo id="S3.SS4.p1.12.m3.2.2.1.1.2" stretchy="false" xref="S3.SS4.p1.12.m3.2.2.1.2.cmml">(</mo><msub id="S3.SS4.p1.12.m3.2.2.1.1.1" xref="S3.SS4.p1.12.m3.2.2.1.1.1.cmml"><mi id="S3.SS4.p1.12.m3.2.2.1.1.1.2" xref="S3.SS4.p1.12.m3.2.2.1.1.1.2.cmml">F</mi><mrow id="S3.SS4.p1.12.m3.2.2.1.1.1.3" xref="S3.SS4.p1.12.m3.2.2.1.1.1.3.cmml"><mi id="S3.SS4.p1.12.m3.2.2.1.1.1.3.2" xref="S3.SS4.p1.12.m3.2.2.1.1.1.3.2.cmml">m</mi><mo id="S3.SS4.p1.12.m3.2.2.1.1.1.3.1" xref="S3.SS4.p1.12.m3.2.2.1.1.1.3.1.cmml">⁢</mo><mi id="S3.SS4.p1.12.m3.2.2.1.1.1.3.3" xref="S3.SS4.p1.12.m3.2.2.1.1.1.3.3.cmml">o</mi><mo id="S3.SS4.p1.12.m3.2.2.1.1.1.3.1a" xref="S3.SS4.p1.12.m3.2.2.1.1.1.3.1.cmml">⁢</mo><mi id="S3.SS4.p1.12.m3.2.2.1.1.1.3.4" xref="S3.SS4.p1.12.m3.2.2.1.1.1.3.4.cmml">d</mi></mrow></msub><mo id="S3.SS4.p1.12.m3.2.2.1.1.3" xref="S3.SS4.p1.12.m3.2.2.1.2.cmml">,</mo><mi id="S3.SS4.p1.12.m3.1.1" xref="S3.SS4.p1.12.m3.1.1.cmml">m</mi><mo id="S3.SS4.p1.12.m3.2.2.1.1.4" stretchy="false" xref="S3.SS4.p1.12.m3.2.2.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.12.m3.2b"><apply id="S3.SS4.p1.12.m3.2.2.cmml" xref="S3.SS4.p1.12.m3.2.2"><times id="S3.SS4.p1.12.m3.2.2.2.cmml" xref="S3.SS4.p1.12.m3.2.2.2"></times><ci id="S3.SS4.p1.12.m3.2.2.3.cmml" xref="S3.SS4.p1.12.m3.2.2.3">𝑠</ci><ci id="S3.SS4.p1.12.m3.2.2.4.cmml" xref="S3.SS4.p1.12.m3.2.2.4">𝑒</ci><ci id="S3.SS4.p1.12.m3.2.2.5.cmml" xref="S3.SS4.p1.12.m3.2.2.5">𝑙</ci><ci id="S3.SS4.p1.12.m3.2.2.6.cmml" xref="S3.SS4.p1.12.m3.2.2.6">𝑒</ci><ci id="S3.SS4.p1.12.m3.2.2.7.cmml" xref="S3.SS4.p1.12.m3.2.2.7">𝑐</ci><ci id="S3.SS4.p1.12.m3.2.2.8.cmml" xref="S3.SS4.p1.12.m3.2.2.8">𝑡</ci><interval closure="open" id="S3.SS4.p1.12.m3.2.2.1.2.cmml" xref="S3.SS4.p1.12.m3.2.2.1.1"><apply id="S3.SS4.p1.12.m3.2.2.1.1.1.cmml" xref="S3.SS4.p1.12.m3.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.SS4.p1.12.m3.2.2.1.1.1.1.cmml" xref="S3.SS4.p1.12.m3.2.2.1.1.1">subscript</csymbol><ci id="S3.SS4.p1.12.m3.2.2.1.1.1.2.cmml" xref="S3.SS4.p1.12.m3.2.2.1.1.1.2">𝐹</ci><apply id="S3.SS4.p1.12.m3.2.2.1.1.1.3.cmml" xref="S3.SS4.p1.12.m3.2.2.1.1.1.3"><times id="S3.SS4.p1.12.m3.2.2.1.1.1.3.1.cmml" xref="S3.SS4.p1.12.m3.2.2.1.1.1.3.1"></times><ci id="S3.SS4.p1.12.m3.2.2.1.1.1.3.2.cmml" xref="S3.SS4.p1.12.m3.2.2.1.1.1.3.2">𝑚</ci><ci id="S3.SS4.p1.12.m3.2.2.1.1.1.3.3.cmml" xref="S3.SS4.p1.12.m3.2.2.1.1.1.3.3">𝑜</ci><ci id="S3.SS4.p1.12.m3.2.2.1.1.1.3.4.cmml" xref="S3.SS4.p1.12.m3.2.2.1.1.1.3.4">𝑑</ci></apply></apply><ci id="S3.SS4.p1.12.m3.1.1.cmml" xref="S3.SS4.p1.12.m3.1.1">𝑚</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.12.m3.2c">select(F_{mod},m)</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p1.12.m3.2d">italic_s italic_e italic_l italic_e italic_c italic_t ( italic_F start_POSTSUBSCRIPT italic_m italic_o italic_d end_POSTSUBSCRIPT , italic_m )</annotation></semantics></math> selects the corresponding <math alttext="m" class="ltx_Math" display="inline" id="S3.SS4.p1.13.m4.1"><semantics id="S3.SS4.p1.13.m4.1a"><mi id="S3.SS4.p1.13.m4.1.1" xref="S3.SS4.p1.13.m4.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.13.m4.1b"><ci id="S3.SS4.p1.13.m4.1.1.cmml" xref="S3.SS4.p1.13.m4.1.1">𝑚</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.13.m4.1c">m</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p1.13.m4.1d">italic_m</annotation></semantics></math>-th modal-specific prompt from the set <math alttext="F_{mod}" class="ltx_Math" display="inline" id="S3.SS4.p1.14.m5.1"><semantics id="S3.SS4.p1.14.m5.1a"><msub id="S3.SS4.p1.14.m5.1.1" xref="S3.SS4.p1.14.m5.1.1.cmml"><mi id="S3.SS4.p1.14.m5.1.1.2" xref="S3.SS4.p1.14.m5.1.1.2.cmml">F</mi><mrow id="S3.SS4.p1.14.m5.1.1.3" xref="S3.SS4.p1.14.m5.1.1.3.cmml"><mi id="S3.SS4.p1.14.m5.1.1.3.2" xref="S3.SS4.p1.14.m5.1.1.3.2.cmml">m</mi><mo id="S3.SS4.p1.14.m5.1.1.3.1" xref="S3.SS4.p1.14.m5.1.1.3.1.cmml">⁢</mo><mi id="S3.SS4.p1.14.m5.1.1.3.3" xref="S3.SS4.p1.14.m5.1.1.3.3.cmml">o</mi><mo id="S3.SS4.p1.14.m5.1.1.3.1a" xref="S3.SS4.p1.14.m5.1.1.3.1.cmml">⁢</mo><mi id="S3.SS4.p1.14.m5.1.1.3.4" xref="S3.SS4.p1.14.m5.1.1.3.4.cmml">d</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.14.m5.1b"><apply id="S3.SS4.p1.14.m5.1.1.cmml" xref="S3.SS4.p1.14.m5.1.1"><csymbol cd="ambiguous" id="S3.SS4.p1.14.m5.1.1.1.cmml" xref="S3.SS4.p1.14.m5.1.1">subscript</csymbol><ci id="S3.SS4.p1.14.m5.1.1.2.cmml" xref="S3.SS4.p1.14.m5.1.1.2">𝐹</ci><apply id="S3.SS4.p1.14.m5.1.1.3.cmml" xref="S3.SS4.p1.14.m5.1.1.3"><times id="S3.SS4.p1.14.m5.1.1.3.1.cmml" xref="S3.SS4.p1.14.m5.1.1.3.1"></times><ci id="S3.SS4.p1.14.m5.1.1.3.2.cmml" xref="S3.SS4.p1.14.m5.1.1.3.2">𝑚</ci><ci id="S3.SS4.p1.14.m5.1.1.3.3.cmml" xref="S3.SS4.p1.14.m5.1.1.3.3">𝑜</ci><ci id="S3.SS4.p1.14.m5.1.1.3.4.cmml" xref="S3.SS4.p1.14.m5.1.1.3.4">𝑑</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.14.m5.1c">F_{mod}</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p1.14.m5.1d">italic_F start_POSTSUBSCRIPT italic_m italic_o italic_d end_POSTSUBSCRIPT</annotation></semantics></math>, and <math alttext="MMap(\cdot)" class="ltx_Math" display="inline" id="S3.SS4.p1.15.m6.1"><semantics id="S3.SS4.p1.15.m6.1a"><mrow id="S3.SS4.p1.15.m6.1.2" xref="S3.SS4.p1.15.m6.1.2.cmml"><mi id="S3.SS4.p1.15.m6.1.2.2" xref="S3.SS4.p1.15.m6.1.2.2.cmml">M</mi><mo id="S3.SS4.p1.15.m6.1.2.1" xref="S3.SS4.p1.15.m6.1.2.1.cmml">⁢</mo><mi id="S3.SS4.p1.15.m6.1.2.3" xref="S3.SS4.p1.15.m6.1.2.3.cmml">M</mi><mo id="S3.SS4.p1.15.m6.1.2.1a" xref="S3.SS4.p1.15.m6.1.2.1.cmml">⁢</mo><mi id="S3.SS4.p1.15.m6.1.2.4" xref="S3.SS4.p1.15.m6.1.2.4.cmml">a</mi><mo id="S3.SS4.p1.15.m6.1.2.1b" xref="S3.SS4.p1.15.m6.1.2.1.cmml">⁢</mo><mi id="S3.SS4.p1.15.m6.1.2.5" xref="S3.SS4.p1.15.m6.1.2.5.cmml">p</mi><mo id="S3.SS4.p1.15.m6.1.2.1c" xref="S3.SS4.p1.15.m6.1.2.1.cmml">⁢</mo><mrow id="S3.SS4.p1.15.m6.1.2.6.2" xref="S3.SS4.p1.15.m6.1.2.cmml"><mo id="S3.SS4.p1.15.m6.1.2.6.2.1" stretchy="false" xref="S3.SS4.p1.15.m6.1.2.cmml">(</mo><mo id="S3.SS4.p1.15.m6.1.1" lspace="0em" rspace="0em" xref="S3.SS4.p1.15.m6.1.1.cmml">⋅</mo><mo id="S3.SS4.p1.15.m6.1.2.6.2.2" stretchy="false" xref="S3.SS4.p1.15.m6.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.15.m6.1b"><apply id="S3.SS4.p1.15.m6.1.2.cmml" xref="S3.SS4.p1.15.m6.1.2"><times id="S3.SS4.p1.15.m6.1.2.1.cmml" xref="S3.SS4.p1.15.m6.1.2.1"></times><ci id="S3.SS4.p1.15.m6.1.2.2.cmml" xref="S3.SS4.p1.15.m6.1.2.2">𝑀</ci><ci id="S3.SS4.p1.15.m6.1.2.3.cmml" xref="S3.SS4.p1.15.m6.1.2.3">𝑀</ci><ci id="S3.SS4.p1.15.m6.1.2.4.cmml" xref="S3.SS4.p1.15.m6.1.2.4">𝑎</ci><ci id="S3.SS4.p1.15.m6.1.2.5.cmml" xref="S3.SS4.p1.15.m6.1.2.5">𝑝</ci><ci id="S3.SS4.p1.15.m6.1.1.cmml" xref="S3.SS4.p1.15.m6.1.1">⋅</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.15.m6.1c">MMap(\cdot)</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p1.15.m6.1d">italic_M italic_M italic_a italic_p ( ⋅ )</annotation></semantics></math> processes this prompt through the MMap module.</p>
</div>
<div class="ltx_para" id="S3.SS4.p2">
<p class="ltx_p" id="S3.SS4.p2.1">The reason for employing individual prompts for each modality, rather than a universal prompt as in our task prior strategy, stems from the fact that the upstream dataset is multi-modal but unpaired, leading to negligible correlations between different modal data.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.5 </span><span class="ltx_text ltx_font_italic" id="S3.SS5.1.1">Transfer Learning</span>
</h3>
<div class="ltx_para" id="S3.SS5.p1">
<p class="ltx_p" id="S3.SS5.p1.1">After training MedUniSeg on the upstream dataset, we transfer the pre-trained encoder-decoder along with the randomly initialized segmentation head to the downstream task. Additionally, the branch responsible for generating the modal prior is also transferred. We freeze the corresponding modal-specific prompt to preserve its learned characteristics, while the linear layer of the MMap module remains learnable to focus on mapping the specific modal prompt. The model is fine-tuned in a fully supervised manner to minimize the sum of the Dice loss and cross-entropy loss.</p>
</div>
<figure class="ltx_table" id="S3.T1">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE I: </span>Details of 17 upstream datasets and six downstream datasets.</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S3.T1.1" style="width:867.2pt;height:84pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-124.1pt,12.0pt) scale(0.777530711541321,0.777530711541321) ;">
<table class="ltx_tabular ltx_align_middle" id="S3.T1.1.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T1.1.1.1.1">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S3.T1.1.1.1.1.1" rowspan="3" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S3.T1.1.1.1.1.1.1">Dataset</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="17" id="S3.T1.1.1.1.1.2" style="padding-left:2.0pt;padding-right:2.0pt;">Upstream</td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="6" id="S3.T1.1.1.1.1.3" style="padding-left:2.0pt;padding-right:2.0pt;">Downstream</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.1.2.2">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="8" id="S3.T1.1.1.2.2.1" style="padding-left:2.0pt;padding-right:2.0pt;">CT</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="2" id="S3.T1.1.1.2.2.2" style="padding-left:2.0pt;padding-right:2.0pt;">MRI</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.2.2.3" style="padding-left:2.0pt;padding-right:2.0pt;">CT&amp;PET</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.2.2.4" style="padding-left:2.0pt;padding-right:2.0pt;">Dermoscopic</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.2.2.5" style="padding-left:2.0pt;padding-right:2.0pt;">Fundus</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.2.2.6" style="padding-left:2.0pt;padding-right:2.0pt;">Path.</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.2.2.7" style="padding-left:2.0pt;padding-right:2.0pt;">Ultrasound</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.2.2.8" style="padding-left:2.0pt;padding-right:2.0pt;">X-ray</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.2.2.9" style="padding-left:2.0pt;padding-right:2.0pt;">Endoscope</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="2" id="S3.T1.1.1.2.2.10" style="padding-left:2.0pt;padding-right:2.0pt;">CT</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.2.2.11" style="padding-left:2.0pt;padding-right:2.0pt;">MRI</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.2.2.12" style="padding-left:2.0pt;padding-right:2.0pt;">X-ray</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.2.2.13" style="padding-left:2.0pt;padding-right:2.0pt;">Fundus</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.1.2.2.14" style="padding-left:2.0pt;padding-right:2.0pt;">Path.</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.1.3.3">
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.1.3.3.1" style="padding-left:2.0pt;padding-right:2.0pt;">Liver</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.1.3.3.2" style="padding-left:2.0pt;padding-right:2.0pt;">Kidney</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.1.3.3.3" style="padding-left:2.0pt;padding-right:2.0pt;">HepaV</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.1.3.3.4" style="padding-left:2.0pt;padding-right:2.0pt;">Pancreas</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.1.3.3.5" style="padding-left:2.0pt;padding-right:2.0pt;">Colon</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.1.3.3.6" style="padding-left:2.0pt;padding-right:2.0pt;">Lung</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.1.3.3.7" style="padding-left:2.0pt;padding-right:2.0pt;">Spleen</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.3.3.8" style="padding-left:2.0pt;padding-right:2.0pt;">VerSe20</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.1.3.3.9" style="padding-left:2.0pt;padding-right:2.0pt;">Prostate</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.3.3.10" style="padding-left:2.0pt;padding-right:2.0pt;">BraTS21</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.3.3.11" style="padding-left:2.0pt;padding-right:2.0pt;">AutoPET22</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.3.3.12" style="padding-left:2.0pt;padding-right:2.0pt;">ISIC18</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.3.3.13" style="padding-left:2.0pt;padding-right:2.0pt;">REFUGE2</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.3.3.14" style="padding-left:2.0pt;padding-right:2.0pt;">GlaS</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.3.3.15" style="padding-left:2.0pt;padding-right:2.0pt;">BUSI</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.3.3.16" style="padding-left:2.0pt;padding-right:2.0pt;">QaTav2</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.3.3.17" style="padding-left:2.0pt;padding-right:2.0pt;">Polyp</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.1.3.3.18" style="padding-left:2.0pt;padding-right:2.0pt;">BTCV</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.3.3.19" style="padding-left:2.0pt;padding-right:2.0pt;">COVID-19-20</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.3.3.20" style="padding-left:2.0pt;padding-right:2.0pt;">VS</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.3.3.21" style="padding-left:2.0pt;padding-right:2.0pt;">SIIM</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.3.3.22" style="padding-left:2.0pt;padding-right:2.0pt;">IDRID</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.1.3.3.23" style="padding-left:2.0pt;padding-right:2.0pt;">SegPC</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.1.4.4">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.4.4.1" style="padding-left:2.0pt;padding-right:2.0pt;">Target</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.1.4.4.2" style="padding-left:2.0pt;padding-right:2.0pt;">Organ&amp;Tumor</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.1.4.4.3" style="padding-left:2.0pt;padding-right:2.0pt;">Organ&amp;Tumor</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.1.4.4.4" style="padding-left:2.0pt;padding-right:2.0pt;">Organ&amp;Tumor</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.1.4.4.5" style="padding-left:2.0pt;padding-right:2.0pt;">Organ&amp;Tumor</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.1.4.4.6" style="padding-left:2.0pt;padding-right:2.0pt;">Tumor</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.1.4.4.7" style="padding-left:2.0pt;padding-right:2.0pt;">Tumor</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.1.4.4.8" style="padding-left:2.0pt;padding-right:2.0pt;">Organ</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.4.4.9" style="padding-left:2.0pt;padding-right:2.0pt;">Vertebrae</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.1.4.4.10" style="padding-left:2.0pt;padding-right:2.0pt;">Organ</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.4.4.11" style="padding-left:2.0pt;padding-right:2.0pt;">Tumor</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.4.4.12" style="padding-left:2.0pt;padding-right:2.0pt;">Tumor</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.4.4.13" style="padding-left:2.0pt;padding-right:2.0pt;">Lesion</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.4.4.14" style="padding-left:2.0pt;padding-right:2.0pt;">Tissue</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.4.4.15" style="padding-left:2.0pt;padding-right:2.0pt;">Tissue</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.4.4.16" style="padding-left:2.0pt;padding-right:2.0pt;">Tumor</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.4.4.17" style="padding-left:2.0pt;padding-right:2.0pt;">Lesion</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.4.4.18" style="padding-left:2.0pt;padding-right:2.0pt;">Lesion</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.1.4.4.19" style="padding-left:2.0pt;padding-right:2.0pt;">Organ</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.4.4.20" style="padding-left:2.0pt;padding-right:2.0pt;">Lesion</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.4.4.21" style="padding-left:2.0pt;padding-right:2.0pt;">Tumor</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.4.4.22" style="padding-left:2.0pt;padding-right:2.0pt;">Lesion</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.4.4.23" style="padding-left:2.0pt;padding-right:2.0pt;">Lesion</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.1.4.4.24" style="padding-left:2.0pt;padding-right:2.0pt;">Cell</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.1.5.5">
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.1.1.5.5.1" style="padding-left:2.0pt;padding-right:2.0pt;">Train</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.5.5.2" style="padding-left:2.0pt;padding-right:2.0pt;">104</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.5.5.3" style="padding-left:2.0pt;padding-right:2.0pt;">168</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.5.5.4" style="padding-left:2.0pt;padding-right:2.0pt;">242</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.5.5.5" style="padding-left:2.0pt;padding-right:2.0pt;">224</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.5.5.6" style="padding-left:2.0pt;padding-right:2.0pt;">100</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.5.5.7" style="padding-left:2.0pt;padding-right:2.0pt;">50</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.5.5.8" style="padding-left:2.0pt;padding-right:2.0pt;">32</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.1.1.5.5.9" style="padding-left:2.0pt;padding-right:2.0pt;">171</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.5.5.10" style="padding-left:2.0pt;padding-right:2.0pt;">91</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.1.1.5.5.11" style="padding-left:2.0pt;padding-right:2.0pt;">1000</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.1.1.5.5.12" style="padding-left:2.0pt;padding-right:2.0pt;">400</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.1.1.5.5.13" style="padding-left:2.0pt;padding-right:2.0pt;">2694</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.1.1.5.5.14" style="padding-left:2.0pt;padding-right:2.0pt;">1600</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.1.1.5.5.15" style="padding-left:2.0pt;padding-right:2.0pt;">85</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.1.1.5.5.16" style="padding-left:2.0pt;padding-right:2.0pt;">623</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.1.1.5.5.17" style="padding-left:2.0pt;padding-right:2.0pt;">7145</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.1.1.5.5.18" style="padding-left:2.0pt;padding-right:2.0pt;">1450</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.5.5.19" style="padding-left:2.0pt;padding-right:2.0pt;">21</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.1.1.5.5.20" style="padding-left:2.0pt;padding-right:2.0pt;">159</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.1.1.5.5.21" style="padding-left:2.0pt;padding-right:2.0pt;">193</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.1.1.5.5.22" style="padding-left:2.0pt;padding-right:2.0pt;">5048</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.1.1.5.5.23" style="padding-left:2.0pt;padding-right:2.0pt;">54</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.5.5.24" style="padding-left:2.0pt;padding-right:2.0pt;">298</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.1.6.6">
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S3.T1.1.1.6.6.1" style="padding-left:2.0pt;padding-right:2.0pt;">Test</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.1.1.6.6.2" style="padding-left:2.0pt;padding-right:2.0pt;">27</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.1.1.6.6.3" style="padding-left:2.0pt;padding-right:2.0pt;">42</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.1.1.6.6.4" style="padding-left:2.0pt;padding-right:2.0pt;">61</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.1.1.6.6.5" style="padding-left:2.0pt;padding-right:2.0pt;">57</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.1.1.6.6.6" style="padding-left:2.0pt;padding-right:2.0pt;">26</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.1.1.6.6.7" style="padding-left:2.0pt;padding-right:2.0pt;">13</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.1.1.6.6.8" style="padding-left:2.0pt;padding-right:2.0pt;">9</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S3.T1.1.1.6.6.9" style="padding-left:2.0pt;padding-right:2.0pt;">43</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.1.1.6.6.10" style="padding-left:2.0pt;padding-right:2.0pt;">25</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S3.T1.1.1.6.6.11" style="padding-left:2.0pt;padding-right:2.0pt;">251</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S3.T1.1.1.6.6.12" style="padding-left:2.0pt;padding-right:2.0pt;">101</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S3.T1.1.1.6.6.13" style="padding-left:2.0pt;padding-right:2.0pt;">1000</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S3.T1.1.1.6.6.14" style="padding-left:2.0pt;padding-right:2.0pt;">400</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S3.T1.1.1.6.6.15" style="padding-left:2.0pt;padding-right:2.0pt;">80</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S3.T1.1.1.6.6.16" style="padding-left:2.0pt;padding-right:2.0pt;">157</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S3.T1.1.1.6.6.17" style="padding-left:2.0pt;padding-right:2.0pt;">2113</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S3.T1.1.1.6.6.18" style="padding-left:2.0pt;padding-right:2.0pt;">798</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.1.1.6.6.19" style="padding-left:2.0pt;padding-right:2.0pt;">9</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S3.T1.1.1.6.6.20" style="padding-left:2.0pt;padding-right:2.0pt;">40</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S3.T1.1.1.6.6.21" style="padding-left:2.0pt;padding-right:2.0pt;">49</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S3.T1.1.1.6.6.22" style="padding-left:2.0pt;padding-right:2.0pt;">1372</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S3.T1.1.1.6.6.23" style="padding-left:2.0pt;padding-right:2.0pt;">27</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.1.1.6.6.24" style="padding-left:2.0pt;padding-right:2.0pt;">199</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<figure class="ltx_table" id="S3.T2">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE II: </span>Patch sizes and batch sizes for all fine-tuning models on the six downstream datasets.</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S3.T2.18" style="width:433.6pt;height:64.2pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(34.6pt,-5.1pt) scale(1.18962687720873,1.18962687720873) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S3.T2.18.18">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S3.T2.18.18.19.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt" id="S3.T2.18.18.19.1.1" style="padding-left:2.0pt;padding-right:2.0pt;">Dataset</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T2.18.18.19.1.2" style="padding-left:2.0pt;padding-right:2.0pt;">BTCV</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T2.18.18.19.1.3" style="padding-left:2.0pt;padding-right:2.0pt;">COVID-19-20</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T2.18.18.19.1.4" style="padding-left:2.0pt;padding-right:2.0pt;">VS</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T2.18.18.19.1.5" style="padding-left:2.0pt;padding-right:2.0pt;">SIIM</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T2.18.18.19.1.6" style="padding-left:2.0pt;padding-right:2.0pt;">IDRID</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T2.18.18.19.1.7" style="padding-left:2.0pt;padding-right:2.0pt;">SegPC</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T2.18.18.20.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S3.T2.18.18.20.1.1" style="padding-left:2.0pt;padding-right:2.0pt;">Batch Size</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.18.18.20.1.2" style="padding-left:2.0pt;padding-right:2.0pt;">2</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.18.18.20.1.3" style="padding-left:2.0pt;padding-right:2.0pt;">2</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.18.18.20.1.4" style="padding-left:2.0pt;padding-right:2.0pt;">2</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.18.18.20.1.5" style="padding-left:2.0pt;padding-right:2.0pt;">12</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.18.18.20.1.6" style="padding-left:2.0pt;padding-right:2.0pt;">12</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.18.18.20.1.7" style="padding-left:2.0pt;padding-right:2.0pt;">12</td>
</tr>
<tr class="ltx_tr" id="S3.T2.18.18.18">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r" id="S3.T2.18.18.18.19" style="padding-left:2.0pt;padding-right:2.0pt;">Patch Size</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T2.3.3.3.3" style="padding-left:2.0pt;padding-right:2.0pt;">1<math alttext="\times" class="ltx_Math" display="inline" id="S3.T2.1.1.1.1.m1.1"><semantics id="S3.T2.1.1.1.1.m1.1a"><mo id="S3.T2.1.1.1.1.m1.1.1" xref="S3.T2.1.1.1.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S3.T2.1.1.1.1.m1.1b"><times id="S3.T2.1.1.1.1.m1.1.1.cmml" xref="S3.T2.1.1.1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.1.1.1.1.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S3.T2.1.1.1.1.m1.1d">×</annotation></semantics></math>48<math alttext="\times" class="ltx_Math" display="inline" id="S3.T2.2.2.2.2.m2.1"><semantics id="S3.T2.2.2.2.2.m2.1a"><mo id="S3.T2.2.2.2.2.m2.1.1" xref="S3.T2.2.2.2.2.m2.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S3.T2.2.2.2.2.m2.1b"><times id="S3.T2.2.2.2.2.m2.1.1.cmml" xref="S3.T2.2.2.2.2.m2.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.2.2.2.2.m2.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S3.T2.2.2.2.2.m2.1d">×</annotation></semantics></math>192<sup class="ltx_sup" id="S3.T2.3.3.3.3.1"><span class="ltx_text ltx_font_italic" id="S3.T2.3.3.3.3.1.1">2</span></sup>
</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T2.6.6.6.6" style="padding-left:2.0pt;padding-right:2.0pt;">1<math alttext="\times" class="ltx_Math" display="inline" id="S3.T2.4.4.4.4.m1.1"><semantics id="S3.T2.4.4.4.4.m1.1a"><mo id="S3.T2.4.4.4.4.m1.1.1" xref="S3.T2.4.4.4.4.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S3.T2.4.4.4.4.m1.1b"><times id="S3.T2.4.4.4.4.m1.1.1.cmml" xref="S3.T2.4.4.4.4.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.4.4.4.4.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S3.T2.4.4.4.4.m1.1d">×</annotation></semantics></math>64<math alttext="\times" class="ltx_Math" display="inline" id="S3.T2.5.5.5.5.m2.1"><semantics id="S3.T2.5.5.5.5.m2.1a"><mo id="S3.T2.5.5.5.5.m2.1.1" xref="S3.T2.5.5.5.5.m2.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S3.T2.5.5.5.5.m2.1b"><times id="S3.T2.5.5.5.5.m2.1.1.cmml" xref="S3.T2.5.5.5.5.m2.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.5.5.5.5.m2.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S3.T2.5.5.5.5.m2.1d">×</annotation></semantics></math>192<sup class="ltx_sup" id="S3.T2.6.6.6.6.1"><span class="ltx_text ltx_font_italic" id="S3.T2.6.6.6.6.1.1">2</span></sup>
</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T2.9.9.9.9" style="padding-left:2.0pt;padding-right:2.0pt;">1<math alttext="\times" class="ltx_Math" display="inline" id="S3.T2.7.7.7.7.m1.1"><semantics id="S3.T2.7.7.7.7.m1.1a"><mo id="S3.T2.7.7.7.7.m1.1.1" xref="S3.T2.7.7.7.7.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S3.T2.7.7.7.7.m1.1b"><times id="S3.T2.7.7.7.7.m1.1.1.cmml" xref="S3.T2.7.7.7.7.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.7.7.7.7.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S3.T2.7.7.7.7.m1.1d">×</annotation></semantics></math>48<math alttext="\times" class="ltx_Math" display="inline" id="S3.T2.8.8.8.8.m2.1"><semantics id="S3.T2.8.8.8.8.m2.1a"><mo id="S3.T2.8.8.8.8.m2.1.1" xref="S3.T2.8.8.8.8.m2.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S3.T2.8.8.8.8.m2.1b"><times id="S3.T2.8.8.8.8.m2.1.1.cmml" xref="S3.T2.8.8.8.8.m2.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.8.8.8.8.m2.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S3.T2.8.8.8.8.m2.1d">×</annotation></semantics></math>192<sup class="ltx_sup" id="S3.T2.9.9.9.9.1"><span class="ltx_text ltx_font_italic" id="S3.T2.9.9.9.9.1.1">2</span></sup>
</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T2.12.12.12.12" style="padding-left:2.0pt;padding-right:2.0pt;">3<math alttext="\times" class="ltx_Math" display="inline" id="S3.T2.10.10.10.10.m1.1"><semantics id="S3.T2.10.10.10.10.m1.1a"><mo id="S3.T2.10.10.10.10.m1.1.1" xref="S3.T2.10.10.10.10.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S3.T2.10.10.10.10.m1.1b"><times id="S3.T2.10.10.10.10.m1.1.1.cmml" xref="S3.T2.10.10.10.10.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.10.10.10.10.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S3.T2.10.10.10.10.m1.1d">×</annotation></semantics></math>1<math alttext="\times" class="ltx_Math" display="inline" id="S3.T2.11.11.11.11.m2.1"><semantics id="S3.T2.11.11.11.11.m2.1a"><mo id="S3.T2.11.11.11.11.m2.1.1" xref="S3.T2.11.11.11.11.m2.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S3.T2.11.11.11.11.m2.1b"><times id="S3.T2.11.11.11.11.m2.1.1.cmml" xref="S3.T2.11.11.11.11.m2.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.11.11.11.11.m2.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S3.T2.11.11.11.11.m2.1d">×</annotation></semantics></math>512<sup class="ltx_sup" id="S3.T2.12.12.12.12.1"><span class="ltx_text ltx_font_italic" id="S3.T2.12.12.12.12.1.1">2</span></sup>
</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T2.15.15.15.15" style="padding-left:2.0pt;padding-right:2.0pt;">3<math alttext="\times" class="ltx_Math" display="inline" id="S3.T2.13.13.13.13.m1.1"><semantics id="S3.T2.13.13.13.13.m1.1a"><mo id="S3.T2.13.13.13.13.m1.1.1" xref="S3.T2.13.13.13.13.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S3.T2.13.13.13.13.m1.1b"><times id="S3.T2.13.13.13.13.m1.1.1.cmml" xref="S3.T2.13.13.13.13.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.13.13.13.13.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S3.T2.13.13.13.13.m1.1d">×</annotation></semantics></math>1<math alttext="\times" class="ltx_Math" display="inline" id="S3.T2.14.14.14.14.m2.1"><semantics id="S3.T2.14.14.14.14.m2.1a"><mo id="S3.T2.14.14.14.14.m2.1.1" xref="S3.T2.14.14.14.14.m2.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S3.T2.14.14.14.14.m2.1b"><times id="S3.T2.14.14.14.14.m2.1.1.cmml" xref="S3.T2.14.14.14.14.m2.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.14.14.14.14.m2.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S3.T2.14.14.14.14.m2.1d">×</annotation></semantics></math>512<sup class="ltx_sup" id="S3.T2.15.15.15.15.1"><span class="ltx_text ltx_font_italic" id="S3.T2.15.15.15.15.1.1">2</span></sup>
</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T2.18.18.18.18" style="padding-left:2.0pt;padding-right:2.0pt;">3<math alttext="\times" class="ltx_Math" display="inline" id="S3.T2.16.16.16.16.m1.1"><semantics id="S3.T2.16.16.16.16.m1.1a"><mo id="S3.T2.16.16.16.16.m1.1.1" xref="S3.T2.16.16.16.16.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S3.T2.16.16.16.16.m1.1b"><times id="S3.T2.16.16.16.16.m1.1.1.cmml" xref="S3.T2.16.16.16.16.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.16.16.16.16.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S3.T2.16.16.16.16.m1.1d">×</annotation></semantics></math>1<math alttext="\times" class="ltx_Math" display="inline" id="S3.T2.17.17.17.17.m2.1"><semantics id="S3.T2.17.17.17.17.m2.1a"><mo id="S3.T2.17.17.17.17.m2.1.1" xref="S3.T2.17.17.17.17.m2.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S3.T2.17.17.17.17.m2.1b"><times id="S3.T2.17.17.17.17.m2.1.1.cmml" xref="S3.T2.17.17.17.17.m2.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.17.17.17.17.m2.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S3.T2.17.17.17.17.m2.1d">×</annotation></semantics></math>512<sup class="ltx_sup" id="S3.T2.18.18.18.18.1"><span class="ltx_text ltx_font_italic" id="S3.T2.18.18.18.18.1.1">2</span></sup>
</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span><span class="ltx_text ltx_font_smallcaps" id="S4.1.1">Datasets</span>
</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">We categorize the datasets used in this study into two groups: an upstream dataset and six downstream datasets.</p>
</div>
<div class="ltx_para" id="S4.p2">
<p class="ltx_p" id="S4.p2.1"><span class="ltx_text ltx_font_bold" id="S4.p2.1.1">Upstream Dataset.</span>
To train our MedUniSeg model and compare it against other universal and single-task models, we collected an upstream dataset comprising 17 public sub-datasets, each annotated with specific targets.
The <span class="ltx_text ltx_font_bold" id="S4.p2.1.2">Liver</span> dataset, derived from LiTS <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib49" title="">49</a>]</cite>, contains contrast-enhanced abdominal CT scans annotated with livers and liver tumors.
The <span class="ltx_text ltx_font_bold" id="S4.p2.1.3">Kidney</span> dataset, sourced from KiTS <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib50" title="">50</a>]</cite>, includes CT scans of kidney cancer patients who underwent nephrectomy, annotated with kidneys and kidney tumors.
The <span class="ltx_text ltx_font_bold" id="S4.p2.1.4">HepaV</span>, <span class="ltx_text ltx_font_bold" id="S4.p2.1.5">Pancreas</span>, <span class="ltx_text ltx_font_bold" id="S4.p2.1.6">Colon</span>, <span class="ltx_text ltx_font_bold" id="S4.p2.1.7">Lung</span>, and <span class="ltx_text ltx_font_bold" id="S4.p2.1.8">Spleen</span> datasets were taken from the Medical Segmentation Decathlon (MSD) Challenge <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib51" title="">51</a>]</cite>, covering segmentation tasks for hepatic vessels, hepatic tumors, pancreases, pancreas tumors, colon tumors, lung tumors, and spleens, respectively.
The <span class="ltx_text ltx_font_bold" id="S4.p2.1.9">VerSe20</span> dataset <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib52" title="">52</a>]</cite> provides segmentation annotations of vertebrae, and we utilized its binary form, merging all foreground classes into a single category.
The <span class="ltx_text ltx_font_bold" id="S4.p2.1.10">Prostate</span> dataset combines the NCI-ISBI 2013 dataset <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib53" title="">53</a>]</cite>, I2CVB dataset <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib54" title="">54</a>]</cite>, and PROMISE12 dataset <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib55" title="">55</a>]</cite> for multi-domain prostate segmentation.
The <span class="ltx_text ltx_font_bold" id="S4.p2.1.11">BraTS21</span> dataset <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib56" title="">56</a>]</cite> annotates brain tumors across four MRI modalities (T1, T1-weighted, T2-weighted, and T2-FLAIR), providing segmentation for peritumoral edematous/invaded tissue, the necrotic tumor core, and the Gd-enhancing tumor.
The <span class="ltx_text ltx_font_bold" id="S4.p2.1.12">AutoPET22</span> dataset <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib57" title="">57</a>]</cite> offers PET scans with whole-body tumor annotations.
The <span class="ltx_text ltx_font_bold" id="S4.p2.1.13">ISIC18</span> dataset <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib58" title="">58</a>]</cite> contains skin lesion annotations, classifying images as cancerous or non-cancerous.
The <span class="ltx_text ltx_font_bold" id="S4.p2.1.14">REFUGE2</span> dataset <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib59" title="">59</a>]</cite> provides annotations for glaucoma classification, optic disc/cup segmentation, and fovea localization; we used only the segmentation annotations.
The <span class="ltx_text ltx_font_bold" id="S4.p2.1.15">GlaS</span> dataset <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib60" title="">60</a>]</cite> labels H&amp;E-stained colon tissue images as malignant or benign.
The <span class="ltx_text ltx_font_bold" id="S4.p2.1.16">BUSI</span> dataset <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib61" title="">61</a>]</cite> includes images categorized as normal, benign, or malignant, with tumor annotations for the latter two categories.
The <span class="ltx_text ltx_font_bold" id="S4.p2.1.17">QaTav2</span> dataset <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib62" title="">62</a>]</cite> focuses on segmenting COVID-19 infected regions.
The <span class="ltx_text ltx_font_bold" id="S4.p2.1.18">Polyp</span> dataset <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib63" title="">63</a>]</cite> consists of five sub-datasets, including Kvasir <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib64" title="">64</a>]</cite>, CVC-ClinicDB <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib65" title="">65</a>]</cite>, CVC-ColonDB <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib66" title="">66</a>]</cite>, ETIS <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib67" title="">67</a>]</cite>, and CVC-300 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib68" title="">68</a>]</cite>, for polyp segmentation.</p>
</div>
<div class="ltx_para" id="S4.p3">
<p class="ltx_p" id="S4.p3.1"><span class="ltx_text ltx_font_bold" id="S4.p3.1.1">Downstream Datasets.</span>
To evaluate the transfer capabilities of well-trained universal models, supervised models, and self-supervised models, we employed six 2D or 3D segmentation datasets.
The <span class="ltx_text ltx_font_bold" id="S4.p3.1.2">BTCV</span> dataset <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib69" title="">69</a>]</cite> provides annotations for 13 abdominal organs, including the spleen, right and left kidneys, gallbladder, esophagus, liver, stomach, aorta, inferior vena cava, portal vein, splenic vein, pancreas, and adrenal glands.
The <span class="ltx_text ltx_font_bold" id="S4.p3.1.3">COVID-19-20</span> dataset includes annotations of COVID-19 lung CT lesions <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib70" title="">70</a>]</cite>.
The <span class="ltx_text ltx_font_bold" id="S4.p3.1.4">VS</span> dataset <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib71" title="">71</a>]</cite> contains annotations for vestibular schwannomas.
The <span class="ltx_text ltx_font_bold" id="S4.p3.1.5">SIIM</span> dataset <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib72" title="">72</a>]</cite> provides segmentation annotations for pneumothorax. To address the imbalance of normal and lesion training samples, we followed <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib73" title="">73</a>]</cite> and balanced the dataset by reducing the number of normal training samples until it was the same as the number of lesion training samples.
The <span class="ltx_text ltx_font_bold" id="S4.p3.1.6">IDRID</span> dataset <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib74" title="">74</a>]</cite> was used to offer annotations for hemorrhages and hard exudates.
The <span class="ltx_text ltx_font_bold" id="S4.p3.1.7">SegPC</span> dataset <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib75" title="">75</a>]</cite> includes annotations for cytoplasm and nucleus segmentation in myeloma plasma cells.</p>
</div>
<div class="ltx_para" id="S4.p4">
<p class="ltx_p" id="S4.p4.1">Detailed information about each dataset is provided in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#S3.T1" title="TABLE I ‣ 3.5 Transfer Learning ‣ 3 Method ‣ MedUniSeg: 2D and 3D Medical Image Segmentation via a Prompt-driven Universal Model"><span class="ltx_text ltx_ref_tag">I</span></a>. For data splits, we adhered to established protocols whenever available, following the official data splits for datasets like ISIC18 or widely accepted splits such as those for the BTCV dataset. For datasets lacking pre-defined splits, we randomly divided the available data using an 80:20 ratio for training and testing, respectively.</p>
</div>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span><span class="ltx_text ltx_font_smallcaps" id="S5.1.1">Experiments</span>
</h2>
<section class="ltx_subsection" id="S5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span><span class="ltx_text ltx_font_italic" id="S5.SS1.1.1">Implementations</span>
</h3>
<div class="ltx_para" id="S5.SS1.p1">
<p class="ltx_p" id="S5.SS1.p1.1">We implemented both joint training on the upstream dataset and fine-tuning on six downstream datasets using the nnUNet framework.</p>
</div>
<div class="ltx_para" id="S5.SS1.p2">
<p class="ltx_p" id="S5.SS1.p2.2"><span class="ltx_text ltx_font_bold" id="S5.SS1.p2.2.1">Universal training.</span>
The Stochastic Gradient Descent (SGD) optimizer was utilized, starting with an initial learning rate of 0.01. Batch sizes varied according to data dimensions: 12 for 2D data and 2 for 3D data. The patch sizes were set to <math alttext="3\times 1\times 512\times 512" class="ltx_Math" display="inline" id="S5.SS1.p2.1.m1.1"><semantics id="S5.SS1.p2.1.m1.1a"><mrow id="S5.SS1.p2.1.m1.1.1" xref="S5.SS1.p2.1.m1.1.1.cmml"><mn id="S5.SS1.p2.1.m1.1.1.2" xref="S5.SS1.p2.1.m1.1.1.2.cmml">3</mn><mo id="S5.SS1.p2.1.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="S5.SS1.p2.1.m1.1.1.1.cmml">×</mo><mn id="S5.SS1.p2.1.m1.1.1.3" xref="S5.SS1.p2.1.m1.1.1.3.cmml">1</mn><mo id="S5.SS1.p2.1.m1.1.1.1a" lspace="0.222em" rspace="0.222em" xref="S5.SS1.p2.1.m1.1.1.1.cmml">×</mo><mn id="S5.SS1.p2.1.m1.1.1.4" xref="S5.SS1.p2.1.m1.1.1.4.cmml">512</mn><mo id="S5.SS1.p2.1.m1.1.1.1b" lspace="0.222em" rspace="0.222em" xref="S5.SS1.p2.1.m1.1.1.1.cmml">×</mo><mn id="S5.SS1.p2.1.m1.1.1.5" xref="S5.SS1.p2.1.m1.1.1.5.cmml">512</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p2.1.m1.1b"><apply id="S5.SS1.p2.1.m1.1.1.cmml" xref="S5.SS1.p2.1.m1.1.1"><times id="S5.SS1.p2.1.m1.1.1.1.cmml" xref="S5.SS1.p2.1.m1.1.1.1"></times><cn id="S5.SS1.p2.1.m1.1.1.2.cmml" type="integer" xref="S5.SS1.p2.1.m1.1.1.2">3</cn><cn id="S5.SS1.p2.1.m1.1.1.3.cmml" type="integer" xref="S5.SS1.p2.1.m1.1.1.3">1</cn><cn id="S5.SS1.p2.1.m1.1.1.4.cmml" type="integer" xref="S5.SS1.p2.1.m1.1.1.4">512</cn><cn id="S5.SS1.p2.1.m1.1.1.5.cmml" type="integer" xref="S5.SS1.p2.1.m1.1.1.5">512</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p2.1.m1.1c">3\times 1\times 512\times 512</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p2.1.m1.1d">3 × 1 × 512 × 512</annotation></semantics></math> for 2D data and <math alttext="1\times 64\times 192\times 192" class="ltx_Math" display="inline" id="S5.SS1.p2.2.m2.1"><semantics id="S5.SS1.p2.2.m2.1a"><mrow id="S5.SS1.p2.2.m2.1.1" xref="S5.SS1.p2.2.m2.1.1.cmml"><mn id="S5.SS1.p2.2.m2.1.1.2" xref="S5.SS1.p2.2.m2.1.1.2.cmml">1</mn><mo id="S5.SS1.p2.2.m2.1.1.1" lspace="0.222em" rspace="0.222em" xref="S5.SS1.p2.2.m2.1.1.1.cmml">×</mo><mn id="S5.SS1.p2.2.m2.1.1.3" xref="S5.SS1.p2.2.m2.1.1.3.cmml">64</mn><mo id="S5.SS1.p2.2.m2.1.1.1a" lspace="0.222em" rspace="0.222em" xref="S5.SS1.p2.2.m2.1.1.1.cmml">×</mo><mn id="S5.SS1.p2.2.m2.1.1.4" xref="S5.SS1.p2.2.m2.1.1.4.cmml">192</mn><mo id="S5.SS1.p2.2.m2.1.1.1b" lspace="0.222em" rspace="0.222em" xref="S5.SS1.p2.2.m2.1.1.1.cmml">×</mo><mn id="S5.SS1.p2.2.m2.1.1.5" xref="S5.SS1.p2.2.m2.1.1.5.cmml">192</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p2.2.m2.1b"><apply id="S5.SS1.p2.2.m2.1.1.cmml" xref="S5.SS1.p2.2.m2.1.1"><times id="S5.SS1.p2.2.m2.1.1.1.cmml" xref="S5.SS1.p2.2.m2.1.1.1"></times><cn id="S5.SS1.p2.2.m2.1.1.2.cmml" type="integer" xref="S5.SS1.p2.2.m2.1.1.2">1</cn><cn id="S5.SS1.p2.2.m2.1.1.3.cmml" type="integer" xref="S5.SS1.p2.2.m2.1.1.3">64</cn><cn id="S5.SS1.p2.2.m2.1.1.4.cmml" type="integer" xref="S5.SS1.p2.2.m2.1.1.4">192</cn><cn id="S5.SS1.p2.2.m2.1.1.5.cmml" type="integer" xref="S5.SS1.p2.2.m2.1.1.5">192</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p2.2.m2.1c">1\times 64\times 192\times 192</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p2.2.m2.1d">1 × 64 × 192 × 192</annotation></semantics></math> for 3D data. The training was designed to run for a maximum of 1,000 epochs, with each dataset allocated 50 iterations per epoch, totaling 850 iterations.</p>
</div>
<div class="ltx_para" id="S5.SS1.p3">
<p class="ltx_p" id="S5.SS1.p3.1"><span class="ltx_text ltx_font_bold" id="S5.SS1.p3.1.1">Fine-tuning.</span>
For fine-tuning, we continued using the nnUNet framework. The batch size and patch size for each downstream dataset were detailed in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#S3.T2" title="TABLE II ‣ 3.5 Transfer Learning ‣ 3 Method ‣ MedUniSeg: 2D and 3D Medical Image Segmentation via a Prompt-driven Universal Model"><span class="ltx_text ltx_ref_tag">II</span></a>. The initial learning rate was remained at 0.01, with a maximum of 25,000 training iterations for most datasets. For the SIIM dataset, we extended this to 100,000 iterations to ensure convergence. Each method was executed three times for each dataset, and average results were reported.</p>
</div>
<div class="ltx_para" id="S5.SS1.p4">
<p class="ltx_p" id="S5.SS1.p4.1">Detailed pre-processing steps for each dataset were provided in our publicly accessible code.</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span><span class="ltx_text ltx_font_italic" id="S5.SS2.1.1">Evaluation Metrics</span>
</h3>
<div class="ltx_para" id="S5.SS2.p1">
<p class="ltx_p" id="S5.SS2.p1.5">The Dice similarity coefficient (Dice, %) was used as the primary metric for evaluating model performance. For datasets with multiple foreground categories, we computed the mean Dice score over these categories to reflect overall performance. In contrast, for the SIIM dataset, which exhibits significant class imbalance (290 normal vs. 1,082 lesion images), we utilized the weighted Dice (WDice) to ensure a fair evaluation. WDice is calculated as follows:</p>
<table class="ltx_equation ltx_eqn_table" id="S5.E3">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="WDice=w_{0}\times D_{0}+w_{1}\times D_{1}," class="ltx_Math" display="block" id="S5.E3.m1.1"><semantics id="S5.E3.m1.1a"><mrow id="S5.E3.m1.1.1.1" xref="S5.E3.m1.1.1.1.1.cmml"><mrow id="S5.E3.m1.1.1.1.1" xref="S5.E3.m1.1.1.1.1.cmml"><mrow id="S5.E3.m1.1.1.1.1.2" xref="S5.E3.m1.1.1.1.1.2.cmml"><mi id="S5.E3.m1.1.1.1.1.2.2" xref="S5.E3.m1.1.1.1.1.2.2.cmml">W</mi><mo id="S5.E3.m1.1.1.1.1.2.1" xref="S5.E3.m1.1.1.1.1.2.1.cmml">⁢</mo><mi id="S5.E3.m1.1.1.1.1.2.3" xref="S5.E3.m1.1.1.1.1.2.3.cmml">D</mi><mo id="S5.E3.m1.1.1.1.1.2.1a" xref="S5.E3.m1.1.1.1.1.2.1.cmml">⁢</mo><mi id="S5.E3.m1.1.1.1.1.2.4" xref="S5.E3.m1.1.1.1.1.2.4.cmml">i</mi><mo id="S5.E3.m1.1.1.1.1.2.1b" xref="S5.E3.m1.1.1.1.1.2.1.cmml">⁢</mo><mi id="S5.E3.m1.1.1.1.1.2.5" xref="S5.E3.m1.1.1.1.1.2.5.cmml">c</mi><mo id="S5.E3.m1.1.1.1.1.2.1c" xref="S5.E3.m1.1.1.1.1.2.1.cmml">⁢</mo><mi id="S5.E3.m1.1.1.1.1.2.6" xref="S5.E3.m1.1.1.1.1.2.6.cmml">e</mi></mrow><mo id="S5.E3.m1.1.1.1.1.1" xref="S5.E3.m1.1.1.1.1.1.cmml">=</mo><mrow id="S5.E3.m1.1.1.1.1.3" xref="S5.E3.m1.1.1.1.1.3.cmml"><mrow id="S5.E3.m1.1.1.1.1.3.2" xref="S5.E3.m1.1.1.1.1.3.2.cmml"><msub id="S5.E3.m1.1.1.1.1.3.2.2" xref="S5.E3.m1.1.1.1.1.3.2.2.cmml"><mi id="S5.E3.m1.1.1.1.1.3.2.2.2" xref="S5.E3.m1.1.1.1.1.3.2.2.2.cmml">w</mi><mn id="S5.E3.m1.1.1.1.1.3.2.2.3" xref="S5.E3.m1.1.1.1.1.3.2.2.3.cmml">0</mn></msub><mo id="S5.E3.m1.1.1.1.1.3.2.1" lspace="0.222em" rspace="0.222em" xref="S5.E3.m1.1.1.1.1.3.2.1.cmml">×</mo><msub id="S5.E3.m1.1.1.1.1.3.2.3" xref="S5.E3.m1.1.1.1.1.3.2.3.cmml"><mi id="S5.E3.m1.1.1.1.1.3.2.3.2" xref="S5.E3.m1.1.1.1.1.3.2.3.2.cmml">D</mi><mn id="S5.E3.m1.1.1.1.1.3.2.3.3" xref="S5.E3.m1.1.1.1.1.3.2.3.3.cmml">0</mn></msub></mrow><mo id="S5.E3.m1.1.1.1.1.3.1" xref="S5.E3.m1.1.1.1.1.3.1.cmml">+</mo><mrow id="S5.E3.m1.1.1.1.1.3.3" xref="S5.E3.m1.1.1.1.1.3.3.cmml"><msub id="S5.E3.m1.1.1.1.1.3.3.2" xref="S5.E3.m1.1.1.1.1.3.3.2.cmml"><mi id="S5.E3.m1.1.1.1.1.3.3.2.2" xref="S5.E3.m1.1.1.1.1.3.3.2.2.cmml">w</mi><mn id="S5.E3.m1.1.1.1.1.3.3.2.3" xref="S5.E3.m1.1.1.1.1.3.3.2.3.cmml">1</mn></msub><mo id="S5.E3.m1.1.1.1.1.3.3.1" lspace="0.222em" rspace="0.222em" xref="S5.E3.m1.1.1.1.1.3.3.1.cmml">×</mo><msub id="S5.E3.m1.1.1.1.1.3.3.3" xref="S5.E3.m1.1.1.1.1.3.3.3.cmml"><mi id="S5.E3.m1.1.1.1.1.3.3.3.2" xref="S5.E3.m1.1.1.1.1.3.3.3.2.cmml">D</mi><mn id="S5.E3.m1.1.1.1.1.3.3.3.3" xref="S5.E3.m1.1.1.1.1.3.3.3.3.cmml">1</mn></msub></mrow></mrow></mrow><mo id="S5.E3.m1.1.1.1.2" xref="S5.E3.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.E3.m1.1b"><apply id="S5.E3.m1.1.1.1.1.cmml" xref="S5.E3.m1.1.1.1"><eq id="S5.E3.m1.1.1.1.1.1.cmml" xref="S5.E3.m1.1.1.1.1.1"></eq><apply id="S5.E3.m1.1.1.1.1.2.cmml" xref="S5.E3.m1.1.1.1.1.2"><times id="S5.E3.m1.1.1.1.1.2.1.cmml" xref="S5.E3.m1.1.1.1.1.2.1"></times><ci id="S5.E3.m1.1.1.1.1.2.2.cmml" xref="S5.E3.m1.1.1.1.1.2.2">𝑊</ci><ci id="S5.E3.m1.1.1.1.1.2.3.cmml" xref="S5.E3.m1.1.1.1.1.2.3">𝐷</ci><ci id="S5.E3.m1.1.1.1.1.2.4.cmml" xref="S5.E3.m1.1.1.1.1.2.4">𝑖</ci><ci id="S5.E3.m1.1.1.1.1.2.5.cmml" xref="S5.E3.m1.1.1.1.1.2.5">𝑐</ci><ci id="S5.E3.m1.1.1.1.1.2.6.cmml" xref="S5.E3.m1.1.1.1.1.2.6">𝑒</ci></apply><apply id="S5.E3.m1.1.1.1.1.3.cmml" xref="S5.E3.m1.1.1.1.1.3"><plus id="S5.E3.m1.1.1.1.1.3.1.cmml" xref="S5.E3.m1.1.1.1.1.3.1"></plus><apply id="S5.E3.m1.1.1.1.1.3.2.cmml" xref="S5.E3.m1.1.1.1.1.3.2"><times id="S5.E3.m1.1.1.1.1.3.2.1.cmml" xref="S5.E3.m1.1.1.1.1.3.2.1"></times><apply id="S5.E3.m1.1.1.1.1.3.2.2.cmml" xref="S5.E3.m1.1.1.1.1.3.2.2"><csymbol cd="ambiguous" id="S5.E3.m1.1.1.1.1.3.2.2.1.cmml" xref="S5.E3.m1.1.1.1.1.3.2.2">subscript</csymbol><ci id="S5.E3.m1.1.1.1.1.3.2.2.2.cmml" xref="S5.E3.m1.1.1.1.1.3.2.2.2">𝑤</ci><cn id="S5.E3.m1.1.1.1.1.3.2.2.3.cmml" type="integer" xref="S5.E3.m1.1.1.1.1.3.2.2.3">0</cn></apply><apply id="S5.E3.m1.1.1.1.1.3.2.3.cmml" xref="S5.E3.m1.1.1.1.1.3.2.3"><csymbol cd="ambiguous" id="S5.E3.m1.1.1.1.1.3.2.3.1.cmml" xref="S5.E3.m1.1.1.1.1.3.2.3">subscript</csymbol><ci id="S5.E3.m1.1.1.1.1.3.2.3.2.cmml" xref="S5.E3.m1.1.1.1.1.3.2.3.2">𝐷</ci><cn id="S5.E3.m1.1.1.1.1.3.2.3.3.cmml" type="integer" xref="S5.E3.m1.1.1.1.1.3.2.3.3">0</cn></apply></apply><apply id="S5.E3.m1.1.1.1.1.3.3.cmml" xref="S5.E3.m1.1.1.1.1.3.3"><times id="S5.E3.m1.1.1.1.1.3.3.1.cmml" xref="S5.E3.m1.1.1.1.1.3.3.1"></times><apply id="S5.E3.m1.1.1.1.1.3.3.2.cmml" xref="S5.E3.m1.1.1.1.1.3.3.2"><csymbol cd="ambiguous" id="S5.E3.m1.1.1.1.1.3.3.2.1.cmml" xref="S5.E3.m1.1.1.1.1.3.3.2">subscript</csymbol><ci id="S5.E3.m1.1.1.1.1.3.3.2.2.cmml" xref="S5.E3.m1.1.1.1.1.3.3.2.2">𝑤</ci><cn id="S5.E3.m1.1.1.1.1.3.3.2.3.cmml" type="integer" xref="S5.E3.m1.1.1.1.1.3.3.2.3">1</cn></apply><apply id="S5.E3.m1.1.1.1.1.3.3.3.cmml" xref="S5.E3.m1.1.1.1.1.3.3.3"><csymbol cd="ambiguous" id="S5.E3.m1.1.1.1.1.3.3.3.1.cmml" xref="S5.E3.m1.1.1.1.1.3.3.3">subscript</csymbol><ci id="S5.E3.m1.1.1.1.1.3.3.3.2.cmml" xref="S5.E3.m1.1.1.1.1.3.3.3.2">𝐷</ci><cn id="S5.E3.m1.1.1.1.1.3.3.3.3.cmml" type="integer" xref="S5.E3.m1.1.1.1.1.3.3.3.3">1</cn></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.E3.m1.1c">WDice=w_{0}\times D_{0}+w_{1}\times D_{1},</annotation><annotation encoding="application/x-llamapun" id="S5.E3.m1.1d">italic_W italic_D italic_i italic_c italic_e = italic_w start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT × italic_D start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT + italic_w start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT × italic_D start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S5.SS2.p1.4">where <math alttext="w_{0}" class="ltx_Math" display="inline" id="S5.SS2.p1.1.m1.1"><semantics id="S5.SS2.p1.1.m1.1a"><msub id="S5.SS2.p1.1.m1.1.1" xref="S5.SS2.p1.1.m1.1.1.cmml"><mi id="S5.SS2.p1.1.m1.1.1.2" xref="S5.SS2.p1.1.m1.1.1.2.cmml">w</mi><mn id="S5.SS2.p1.1.m1.1.1.3" xref="S5.SS2.p1.1.m1.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.1.m1.1b"><apply id="S5.SS2.p1.1.m1.1.1.cmml" xref="S5.SS2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S5.SS2.p1.1.m1.1.1.1.cmml" xref="S5.SS2.p1.1.m1.1.1">subscript</csymbol><ci id="S5.SS2.p1.1.m1.1.1.2.cmml" xref="S5.SS2.p1.1.m1.1.1.2">𝑤</ci><cn id="S5.SS2.p1.1.m1.1.1.3.cmml" type="integer" xref="S5.SS2.p1.1.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.1.m1.1c">w_{0}</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p1.1.m1.1d">italic_w start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT</annotation></semantics></math> and <math alttext="w_{1}" class="ltx_Math" display="inline" id="S5.SS2.p1.2.m2.1"><semantics id="S5.SS2.p1.2.m2.1a"><msub id="S5.SS2.p1.2.m2.1.1" xref="S5.SS2.p1.2.m2.1.1.cmml"><mi id="S5.SS2.p1.2.m2.1.1.2" xref="S5.SS2.p1.2.m2.1.1.2.cmml">w</mi><mn id="S5.SS2.p1.2.m2.1.1.3" xref="S5.SS2.p1.2.m2.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.2.m2.1b"><apply id="S5.SS2.p1.2.m2.1.1.cmml" xref="S5.SS2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S5.SS2.p1.2.m2.1.1.1.cmml" xref="S5.SS2.p1.2.m2.1.1">subscript</csymbol><ci id="S5.SS2.p1.2.m2.1.1.2.cmml" xref="S5.SS2.p1.2.m2.1.1.2">𝑤</ci><cn id="S5.SS2.p1.2.m2.1.1.3.cmml" type="integer" xref="S5.SS2.p1.2.m2.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.2.m2.1c">w_{1}</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p1.2.m2.1d">italic_w start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math> are the weights assigned to the normal and lesion categories, respectively. Both weights are inversely proportional to the frequency of each class, ensuring equitable contribution from both categories to the evaluation metric. Here, <math alttext="D_{0}" class="ltx_Math" display="inline" id="S5.SS2.p1.3.m3.1"><semantics id="S5.SS2.p1.3.m3.1a"><msub id="S5.SS2.p1.3.m3.1.1" xref="S5.SS2.p1.3.m3.1.1.cmml"><mi id="S5.SS2.p1.3.m3.1.1.2" xref="S5.SS2.p1.3.m3.1.1.2.cmml">D</mi><mn id="S5.SS2.p1.3.m3.1.1.3" xref="S5.SS2.p1.3.m3.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.3.m3.1b"><apply id="S5.SS2.p1.3.m3.1.1.cmml" xref="S5.SS2.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S5.SS2.p1.3.m3.1.1.1.cmml" xref="S5.SS2.p1.3.m3.1.1">subscript</csymbol><ci id="S5.SS2.p1.3.m3.1.1.2.cmml" xref="S5.SS2.p1.3.m3.1.1.2">𝐷</ci><cn id="S5.SS2.p1.3.m3.1.1.3.cmml" type="integer" xref="S5.SS2.p1.3.m3.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.3.m3.1c">D_{0}</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p1.3.m3.1d">italic_D start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT</annotation></semantics></math> and <math alttext="D_{1}" class="ltx_Math" display="inline" id="S5.SS2.p1.4.m4.1"><semantics id="S5.SS2.p1.4.m4.1a"><msub id="S5.SS2.p1.4.m4.1.1" xref="S5.SS2.p1.4.m4.1.1.cmml"><mi id="S5.SS2.p1.4.m4.1.1.2" xref="S5.SS2.p1.4.m4.1.1.2.cmml">D</mi><mn id="S5.SS2.p1.4.m4.1.1.3" xref="S5.SS2.p1.4.m4.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.4.m4.1b"><apply id="S5.SS2.p1.4.m4.1.1.cmml" xref="S5.SS2.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S5.SS2.p1.4.m4.1.1.1.cmml" xref="S5.SS2.p1.4.m4.1.1">subscript</csymbol><ci id="S5.SS2.p1.4.m4.1.1.2.cmml" xref="S5.SS2.p1.4.m4.1.1.2">𝐷</ci><cn id="S5.SS2.p1.4.m4.1.1.3.cmml" type="integer" xref="S5.SS2.p1.4.m4.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.4.m4.1c">D_{1}</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p1.4.m4.1d">italic_D start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math> denote the mean Dice scores for the normal and lesion images, respectively.</p>
</div>
<figure class="ltx_table" id="S5.T3">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE III: </span>Performance of single-task models and universal models on 17 datasets. Dice scores (%) are reported for each dataset, with 3D mean Dice (%) calculated for all 3D datasets, 2D mean Dice (%) for all 2D datasets, and mean Dice (%) for all datasets. The best results for each dataset are highlighted in bold.</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S5.T3.1" style="width:867.2pt;height:335.7pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-8.1pt,3.1pt) scale(0.981717448308188,0.981717448308188) ;">
<table class="ltx_tabular ltx_align_middle" id="S5.T3.1.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T3.1.1.1.1">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S5.T3.1.1.1.1.1" style="padding-left:2.0pt;padding-right:2.0pt;">Method</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T3.1.1.1.1.2" style="padding-left:2.0pt;padding-right:2.0pt;">Liver</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T3.1.1.1.1.3" style="padding-left:2.0pt;padding-right:2.0pt;">Kidney</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T3.1.1.1.1.4" style="padding-left:2.0pt;padding-right:2.0pt;">HepaV</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T3.1.1.1.1.5" style="padding-left:2.0pt;padding-right:2.0pt;">Pancreas</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T3.1.1.1.1.6" style="padding-left:2.0pt;padding-right:2.0pt;">Colon</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T3.1.1.1.1.7" style="padding-left:2.0pt;padding-right:2.0pt;">Lung</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T3.1.1.1.1.8" style="padding-left:2.0pt;padding-right:2.0pt;">Spleen</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T3.1.1.1.1.9" style="padding-left:2.0pt;padding-right:2.0pt;">VerSe20</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T3.1.1.1.1.10" style="padding-left:2.0pt;padding-right:2.0pt;">Prostate</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T3.1.1.1.1.11" style="padding-left:2.0pt;padding-right:2.0pt;">BraTS21</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S5.T3.1.1.1.1.12" style="padding-left:2.0pt;padding-right:2.0pt;">AutoPET22</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T3.1.1.1.1.13" style="padding-left:2.0pt;padding-right:2.0pt;">ISIC18</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T3.1.1.1.1.14" style="padding-left:2.0pt;padding-right:2.0pt;">REFUGE2</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T3.1.1.1.1.15" style="padding-left:2.0pt;padding-right:2.0pt;">GlaS</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T3.1.1.1.1.16" style="padding-left:2.0pt;padding-right:2.0pt;">BUSI</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T3.1.1.1.1.17" style="padding-left:2.0pt;padding-right:2.0pt;">QaTav2</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S5.T3.1.1.1.1.18" style="padding-left:2.0pt;padding-right:2.0pt;">Polyp</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T3.1.1.1.1.19" style="padding-left:2.0pt;padding-right:2.0pt;">3D Mean</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T3.1.1.1.1.20" style="padding-left:2.0pt;padding-right:2.0pt;">2D Mean</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T3.1.1.1.1.21" style="padding-left:2.0pt;padding-right:2.0pt;">Mean</td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.1.2.2">
<td class="ltx_td ltx_align_center ltx_border_t" colspan="21" id="S5.T3.1.1.2.2.1" style="padding-left:2.0pt;padding-right:2.0pt;">Single-task Model</td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.1.3.3">
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T3.1.1.3.3.1" style="padding-left:2.0pt;padding-right:2.0pt;">nnFormer <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib76" title="">76</a>]</cite>
</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.3.3.2" style="padding-left:2.0pt;padding-right:2.0pt;">70.7</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.3.3.3" style="padding-left:2.0pt;padding-right:2.0pt;">80.0</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.3.3.4" style="padding-left:2.0pt;padding-right:2.0pt;">61.3</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.3.3.5" style="padding-left:2.0pt;padding-right:2.0pt;">57.9</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.3.3.6" style="padding-left:2.0pt;padding-right:2.0pt;">18.8</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.3.3.7" style="padding-left:2.0pt;padding-right:2.0pt;">66.8</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.3.3.8" style="padding-left:2.0pt;padding-right:2.0pt;">92.2</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.3.3.9" style="padding-left:2.0pt;padding-right:2.0pt;">84.3</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.3.3.10" style="padding-left:2.0pt;padding-right:2.0pt;">87.0</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.3.3.11" style="padding-left:2.0pt;padding-right:2.0pt;">82.0</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T3.1.1.3.3.12" style="padding-left:2.0pt;padding-right:2.0pt;">61.0</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.3.3.13" style="padding-left:2.0pt;padding-right:2.0pt;">87.8</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.3.3.14" style="padding-left:2.0pt;padding-right:2.0pt;">90.2</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.3.3.15" style="padding-left:2.0pt;padding-right:2.0pt;">90.5</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.3.3.16" style="padding-left:2.0pt;padding-right:2.0pt;">74.7</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.3.3.17" style="padding-left:2.0pt;padding-right:2.0pt;">77.8</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T3.1.1.3.3.18" style="padding-left:2.0pt;padding-right:2.0pt;">60.5</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.3.3.19" style="padding-left:2.0pt;padding-right:2.0pt;">69.3</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.3.3.20" style="padding-left:2.0pt;padding-right:2.0pt;">80.3</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.3.3.21" style="padding-left:2.0pt;padding-right:2.0pt;">73.2</td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.1.4.4">
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T3.1.1.4.4.1" style="padding-left:2.0pt;padding-right:2.0pt;">MiT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib35" title="">35</a>]</cite>
</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.4.4.2" style="padding-left:2.0pt;padding-right:2.0pt;">71.5</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.4.4.3" style="padding-left:2.0pt;padding-right:2.0pt;">76.8</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.4.4.4" style="padding-left:2.0pt;padding-right:2.0pt;">63.8</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.4.4.5" style="padding-left:2.0pt;padding-right:2.0pt;">58.1</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.4.4.6" style="padding-left:2.0pt;padding-right:2.0pt;">32.0</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.4.4.7" style="padding-left:2.0pt;padding-right:2.0pt;">60.7</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.4.4.8" style="padding-left:2.0pt;padding-right:2.0pt;">95.7</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.4.4.9" style="padding-left:2.0pt;padding-right:2.0pt;">85.3</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.4.4.10" style="padding-left:2.0pt;padding-right:2.0pt;">85.9</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.4.4.11" style="padding-left:2.0pt;padding-right:2.0pt;">82.7</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T3.1.1.4.4.12" style="padding-left:2.0pt;padding-right:2.0pt;">59.7</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.4.4.13" style="padding-left:2.0pt;padding-right:2.0pt;">88.8</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.4.4.14" style="padding-left:2.0pt;padding-right:2.0pt;">90.6</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.4.4.15" style="padding-left:2.0pt;padding-right:2.0pt;">90.5</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.4.4.16" style="padding-left:2.0pt;padding-right:2.0pt;">77.0</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.4.4.17" style="padding-left:2.0pt;padding-right:2.0pt;">79.0</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T3.1.1.4.4.18" style="padding-left:2.0pt;padding-right:2.0pt;">70.5</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.4.4.19" style="padding-left:2.0pt;padding-right:2.0pt;">70.2</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.4.4.20" style="padding-left:2.0pt;padding-right:2.0pt;">82.7</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.4.4.21" style="padding-left:2.0pt;padding-right:2.0pt;">74.6</td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.1.5.5">
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T3.1.1.5.5.1" style="padding-left:2.0pt;padding-right:2.0pt;">CoTr <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib77" title="">77</a>]</cite>
</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.5.5.2" style="padding-left:2.0pt;padding-right:2.0pt;">74.7</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.5.5.3" style="padding-left:2.0pt;padding-right:2.0pt;">85.1</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.5.5.4" style="padding-left:2.0pt;padding-right:2.0pt;">67.2</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.5.5.5" style="padding-left:2.0pt;padding-right:2.0pt;">65.8</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.5.5.6" style="padding-left:2.0pt;padding-right:2.0pt;">33.8</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.5.5.7" style="padding-left:2.0pt;padding-right:2.0pt;">66.9</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.5.5.8" style="padding-left:2.0pt;padding-right:2.0pt;">95.2</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.5.5.9" style="padding-left:2.0pt;padding-right:2.0pt;">87.1</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.5.5.10" style="padding-left:2.0pt;padding-right:2.0pt;">88.0</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.5.5.11" style="padding-left:2.0pt;padding-right:2.0pt;">82.9</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T3.1.1.5.5.12" style="padding-left:2.0pt;padding-right:2.0pt;">58.8</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.5.5.13" style="padding-left:2.0pt;padding-right:2.0pt;">88.0</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.5.5.14" style="padding-left:2.0pt;padding-right:2.0pt;">89.1</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.5.5.15" style="padding-left:2.0pt;padding-right:2.0pt;">89.9</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.5.5.16" style="padding-left:2.0pt;padding-right:2.0pt;">77.7</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.5.5.17" style="padding-left:2.0pt;padding-right:2.0pt;">79.6</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T3.1.1.5.5.18" style="padding-left:2.0pt;padding-right:2.0pt;">77.0</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.5.5.19" style="padding-left:2.0pt;padding-right:2.0pt;">73.2</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.5.5.20" style="padding-left:2.0pt;padding-right:2.0pt;">83.5</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.5.5.21" style="padding-left:2.0pt;padding-right:2.0pt;">76.9</td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.1.6.6">
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T3.1.1.6.6.1" style="padding-left:2.0pt;padding-right:2.0pt;">UXNet <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib78" title="">78</a>]</cite>
</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.6.6.2" style="padding-left:2.0pt;padding-right:2.0pt;">75.4</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.6.6.3" style="padding-left:2.0pt;padding-right:2.0pt;">82.2</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.6.6.4" style="padding-left:2.0pt;padding-right:2.0pt;">67.3</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.6.6.5" style="padding-left:2.0pt;padding-right:2.0pt;">59.4</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.6.6.6" style="padding-left:2.0pt;padding-right:2.0pt;">39.8</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.6.6.7" style="padding-left:2.0pt;padding-right:2.0pt;">59.5</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.6.6.8" style="padding-left:2.0pt;padding-right:2.0pt;">95.7</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.6.6.9" style="padding-left:2.0pt;padding-right:2.0pt;">87.1</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.6.6.10" style="padding-left:2.0pt;padding-right:2.0pt;">88.8</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.6.6.11" style="padding-left:2.0pt;padding-right:2.0pt;">84.3</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T3.1.1.6.6.12" style="padding-left:2.0pt;padding-right:2.0pt;">68.2</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.6.6.13" style="padding-left:2.0pt;padding-right:2.0pt;">88.8</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.6.6.14" style="padding-left:2.0pt;padding-right:2.0pt;">90.5</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.6.6.15" style="padding-left:2.0pt;padding-right:2.0pt;">88.9</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.6.6.16" style="padding-left:2.0pt;padding-right:2.0pt;">78.6</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.6.6.17" style="padding-left:2.0pt;padding-right:2.0pt;">79.2</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T3.1.1.6.6.18" style="padding-left:2.0pt;padding-right:2.0pt;">73.3</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.6.6.19" style="padding-left:2.0pt;padding-right:2.0pt;">73.4</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.6.6.20" style="padding-left:2.0pt;padding-right:2.0pt;">83.2</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.6.6.21" style="padding-left:2.0pt;padding-right:2.0pt;">76.9</td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.1.7.7">
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T3.1.1.7.7.1" style="padding-left:2.0pt;padding-right:2.0pt;">Swin UNETR <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib79" title="">79</a>]</cite>
</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.7.7.2" style="padding-left:2.0pt;padding-right:2.0pt;">74.8</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.7.7.3" style="padding-left:2.0pt;padding-right:2.0pt;">82.6</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.7.7.4" style="padding-left:2.0pt;padding-right:2.0pt;">68.3</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.7.7.5" style="padding-left:2.0pt;padding-right:2.0pt;">63.8</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.7.7.6" style="padding-left:2.0pt;padding-right:2.0pt;">41.1</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.7.7.7" style="padding-left:2.0pt;padding-right:2.0pt;">71.5</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.7.7.8" style="padding-left:2.0pt;padding-right:2.0pt;">96.2</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.7.7.9" style="padding-left:2.0pt;padding-right:2.0pt;">86.6</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.7.7.10" style="padding-left:2.0pt;padding-right:2.0pt;">88.7</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.7.7.11" style="padding-left:2.0pt;padding-right:2.0pt;">84.2</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T3.1.1.7.7.12" style="padding-left:2.0pt;padding-right:2.0pt;">59.2</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.7.7.13" style="padding-left:2.0pt;padding-right:2.0pt;">88.5</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.7.7.14" style="padding-left:2.0pt;padding-right:2.0pt;">91.2</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.7.7.15" style="padding-left:2.0pt;padding-right:2.0pt;">90.1</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.7.7.16" style="padding-left:2.0pt;padding-right:2.0pt;">76.4</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.7.7.17" style="padding-left:2.0pt;padding-right:2.0pt;">78.3</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T3.1.1.7.7.18" style="padding-left:2.0pt;padding-right:2.0pt;">71.7</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.7.7.19" style="padding-left:2.0pt;padding-right:2.0pt;">74.3</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.7.7.20" style="padding-left:2.0pt;padding-right:2.0pt;">82.7</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.7.7.21" style="padding-left:2.0pt;padding-right:2.0pt;">77.3</td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.1.8.8">
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T3.1.1.8.8.1" style="padding-left:2.0pt;padding-right:2.0pt;">UCI <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib80" title="">80</a>]</cite>
</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.8.8.2" style="padding-left:2.0pt;padding-right:2.0pt;">78.2</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.8.8.3" style="padding-left:2.0pt;padding-right:2.0pt;">85.0</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.8.8.4" style="padding-left:2.0pt;padding-right:2.0pt;">67.6</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.8.8.5" style="padding-left:2.0pt;padding-right:2.0pt;">63.7</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.8.8.6" style="padding-left:2.0pt;padding-right:2.0pt;">40.4</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.8.8.7" style="padding-left:2.0pt;padding-right:2.0pt;">68.1</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.8.8.8" style="padding-left:2.0pt;padding-right:2.0pt;">95.9</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.8.8.9" style="padding-left:2.0pt;padding-right:2.0pt;">86.6</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.8.8.10" style="padding-left:2.0pt;padding-right:2.0pt;">88.7</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.8.8.11" style="padding-left:2.0pt;padding-right:2.0pt;">84.1</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T3.1.1.8.8.12" style="padding-left:2.0pt;padding-right:2.0pt;">64.2</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.8.8.13" style="padding-left:2.0pt;padding-right:2.0pt;">89.1</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.8.8.14" style="padding-left:2.0pt;padding-right:2.0pt;">90.5</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.8.8.15" style="padding-left:2.0pt;padding-right:2.0pt;">90.0</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.8.8.16" style="padding-left:2.0pt;padding-right:2.0pt;">75.3</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.8.8.17" style="padding-left:2.0pt;padding-right:2.0pt;">78.5</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T3.1.1.8.8.18" style="padding-left:2.0pt;padding-right:2.0pt;">71.7</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.8.8.19" style="padding-left:2.0pt;padding-right:2.0pt;">74.8</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.8.8.20" style="padding-left:2.0pt;padding-right:2.0pt;">82.5</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.8.8.21" style="padding-left:2.0pt;padding-right:2.0pt;">77.5</td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.1.9.9">
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T3.1.1.9.9.1" style="padding-left:2.0pt;padding-right:2.0pt;">UKAN <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib26" title="">26</a>]</cite>
</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.9.9.2" style="padding-left:2.0pt;padding-right:2.0pt;">76.0</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.9.9.3" style="padding-left:2.0pt;padding-right:2.0pt;">86.6</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.9.9.4" style="padding-left:2.0pt;padding-right:2.0pt;">70.0</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.9.9.5" style="padding-left:2.0pt;padding-right:2.0pt;">65.2</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.9.9.6" style="padding-left:2.0pt;padding-right:2.0pt;">47.0</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.9.9.7" style="padding-left:2.0pt;padding-right:2.0pt;">66.1</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.9.9.8" style="padding-left:2.0pt;padding-right:2.0pt;">96.0</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.9.9.9" style="padding-left:2.0pt;padding-right:2.0pt;">86.5</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.9.9.10" style="padding-left:2.0pt;padding-right:2.0pt;">89.3</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.9.9.11" style="padding-left:2.0pt;padding-right:2.0pt;">83.8</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T3.1.1.9.9.12" style="padding-left:2.0pt;padding-right:2.0pt;">66.5</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.9.9.13" style="padding-left:2.0pt;padding-right:2.0pt;">88.4</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.9.9.14" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.9.9.14.1">91.5</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.9.9.15" style="padding-left:2.0pt;padding-right:2.0pt;">91.2</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.9.9.16" style="padding-left:2.0pt;padding-right:2.0pt;">79.1</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.9.9.17" style="padding-left:2.0pt;padding-right:2.0pt;">79.6</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T3.1.1.9.9.18" style="padding-left:2.0pt;padding-right:2.0pt;">73.6</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.9.9.19" style="padding-left:2.0pt;padding-right:2.0pt;">75.7</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.9.9.20" style="padding-left:2.0pt;padding-right:2.0pt;">83.9</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.9.9.21" style="padding-left:2.0pt;padding-right:2.0pt;">78.6</td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.1.10.10">
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T3.1.1.10.10.1" style="padding-left:2.0pt;padding-right:2.0pt;">U-Mamba <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib25" title="">25</a>]</cite>
</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.10.10.2" style="padding-left:2.0pt;padding-right:2.0pt;">77.5</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.10.10.3" style="padding-left:2.0pt;padding-right:2.0pt;">86.2</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.10.10.4" style="padding-left:2.0pt;padding-right:2.0pt;">70.4</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.10.10.5" style="padding-left:2.0pt;padding-right:2.0pt;">70.5</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.10.10.6" style="padding-left:2.0pt;padding-right:2.0pt;">47.0</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.10.10.7" style="padding-left:2.0pt;padding-right:2.0pt;">68.2</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.10.10.8" style="padding-left:2.0pt;padding-right:2.0pt;">95.8</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.10.10.9" style="padding-left:2.0pt;padding-right:2.0pt;">87.2</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.10.10.10" style="padding-left:2.0pt;padding-right:2.0pt;">88.6</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.10.10.11" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.10.10.11.1">84.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T3.1.1.10.10.12" style="padding-left:2.0pt;padding-right:2.0pt;">64.8</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.10.10.13" style="padding-left:2.0pt;padding-right:2.0pt;">88.7</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.10.10.14" style="padding-left:2.0pt;padding-right:2.0pt;">91.1</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.10.10.15" style="padding-left:2.0pt;padding-right:2.0pt;">90.8</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.10.10.16" style="padding-left:2.0pt;padding-right:2.0pt;">78.1</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.10.10.17" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.10.10.17.1">80.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T3.1.1.10.10.18" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.10.10.18.1">77.8</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.10.10.19" style="padding-left:2.0pt;padding-right:2.0pt;">76.4</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.10.10.20" style="padding-left:2.0pt;padding-right:2.0pt;">84.5</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.10.10.21" style="padding-left:2.0pt;padding-right:2.0pt;">79.3</td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.1.11.11">
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T3.1.1.11.11.1" style="padding-left:2.0pt;padding-right:2.0pt;">nnUNet <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib24" title="">24</a>]</cite>
</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.11.11.2" style="padding-left:2.0pt;padding-right:2.0pt;">77.2</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.11.11.3" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.11.11.3.1">87.5</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.11.11.4" style="padding-left:2.0pt;padding-right:2.0pt;">69.6</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.11.11.5" style="padding-left:2.0pt;padding-right:2.0pt;">68.8</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.11.11.6" style="padding-left:2.0pt;padding-right:2.0pt;">49.0</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.11.11.7" style="padding-left:2.0pt;padding-right:2.0pt;">68.4</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.11.11.8" style="padding-left:2.0pt;padding-right:2.0pt;">96.2</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.11.11.9" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.11.11.9.1">87.2</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.11.11.10" style="padding-left:2.0pt;padding-right:2.0pt;">89.4</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.11.11.11" style="padding-left:2.0pt;padding-right:2.0pt;">84.4</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T3.1.1.11.11.12" style="padding-left:2.0pt;padding-right:2.0pt;">64.6</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.11.11.13" style="padding-left:2.0pt;padding-right:2.0pt;">88.4</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.11.11.14" style="padding-left:2.0pt;padding-right:2.0pt;">90.8</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.11.11.15" style="padding-left:2.0pt;padding-right:2.0pt;">90.4</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.11.11.16" style="padding-left:2.0pt;padding-right:2.0pt;">79.1</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.11.11.17" style="padding-left:2.0pt;padding-right:2.0pt;">80.1</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T3.1.1.11.11.18" style="padding-left:2.0pt;padding-right:2.0pt;">77.6</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.11.11.19" style="padding-left:2.0pt;padding-right:2.0pt;">76.6</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.11.11.20" style="padding-left:2.0pt;padding-right:2.0pt;">84.4</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.11.11.21" style="padding-left:2.0pt;padding-right:2.0pt;">79.3</td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.1.12.12">
<td class="ltx_td ltx_align_center ltx_border_t" colspan="21" id="S5.T3.1.1.12.12.1" style="padding-left:2.0pt;padding-right:2.0pt;">Universal Model</td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.1.13.13">
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T3.1.1.13.13.1" style="padding-left:2.0pt;padding-right:2.0pt;">Universal Model <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib10" title="">10</a>]</cite>
</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.13.13.2" style="padding-left:2.0pt;padding-right:2.0pt;">75.2</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.13.13.3" style="padding-left:2.0pt;padding-right:2.0pt;">85.8</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.13.13.4" style="padding-left:2.0pt;padding-right:2.0pt;">69.5</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.13.13.5" style="padding-left:2.0pt;padding-right:2.0pt;">63.9</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.13.13.6" style="padding-left:2.0pt;padding-right:2.0pt;">49.9</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.13.13.7" style="padding-left:2.0pt;padding-right:2.0pt;">61.1</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.13.13.8" style="padding-left:2.0pt;padding-right:2.0pt;">96.3</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.13.13.9" style="padding-left:2.0pt;padding-right:2.0pt;">86.0</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.13.13.10" style="padding-left:2.0pt;padding-right:2.0pt;">89.3</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.13.13.11" style="padding-left:2.0pt;padding-right:2.0pt;">83.6</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T3.1.1.13.13.12" style="padding-left:2.0pt;padding-right:2.0pt;">67.4</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.13.13.13" style="padding-left:2.0pt;padding-right:2.0pt;">88.8</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.13.13.14" style="padding-left:2.0pt;padding-right:2.0pt;">90.7</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.13.13.15" style="padding-left:2.0pt;padding-right:2.0pt;">90.6</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.13.13.16" style="padding-left:2.0pt;padding-right:2.0pt;">79.7</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.13.13.17" style="padding-left:2.0pt;padding-right:2.0pt;">79.6</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T3.1.1.13.13.18" style="padding-left:2.0pt;padding-right:2.0pt;">74.3</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.13.13.19" style="padding-left:2.0pt;padding-right:2.0pt;">75.3</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.13.13.20" style="padding-left:2.0pt;padding-right:2.0pt;">83.9</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.13.13.21" style="padding-left:2.0pt;padding-right:2.0pt;">78.3</td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.1.14.14">
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T3.1.1.14.14.1" style="padding-left:2.0pt;padding-right:2.0pt;">Hermes <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib18" title="">18</a>]</cite>
</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.14.14.2" style="padding-left:2.0pt;padding-right:2.0pt;">75.6</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.14.14.3" style="padding-left:2.0pt;padding-right:2.0pt;">84.1</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.14.14.4" style="padding-left:2.0pt;padding-right:2.0pt;">69.1</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.14.14.5" style="padding-left:2.0pt;padding-right:2.0pt;">66.8</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.14.14.6" style="padding-left:2.0pt;padding-right:2.0pt;">48.8</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.14.14.7" style="padding-left:2.0pt;padding-right:2.0pt;">68.8</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.14.14.8" style="padding-left:2.0pt;padding-right:2.0pt;">96.4</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.14.14.9" style="padding-left:2.0pt;padding-right:2.0pt;">86.1</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.14.14.10" style="padding-left:2.0pt;padding-right:2.0pt;">88.6</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.14.14.11" style="padding-left:2.0pt;padding-right:2.0pt;">83.8</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T3.1.1.14.14.12" style="padding-left:2.0pt;padding-right:2.0pt;">67.5</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.14.14.13" style="padding-left:2.0pt;padding-right:2.0pt;">89.3</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.14.14.14" style="padding-left:2.0pt;padding-right:2.0pt;">90.3</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.14.14.15" style="padding-left:2.0pt;padding-right:2.0pt;">90.2</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.14.14.16" style="padding-left:2.0pt;padding-right:2.0pt;">77.5</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.14.14.17" style="padding-left:2.0pt;padding-right:2.0pt;">79.2</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T3.1.1.14.14.18" style="padding-left:2.0pt;padding-right:2.0pt;">73.6</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.14.14.19" style="padding-left:2.0pt;padding-right:2.0pt;">76.0</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.14.14.20" style="padding-left:2.0pt;padding-right:2.0pt;">83.4</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.14.14.21" style="padding-left:2.0pt;padding-right:2.0pt;">78.6</td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.1.15.15">
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T3.1.1.15.15.1" style="padding-left:2.0pt;padding-right:2.0pt;">DoDNet <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib12" title="">12</a>]</cite>
</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.15.15.2" style="padding-left:2.0pt;padding-right:2.0pt;">76.9</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.15.15.3" style="padding-left:2.0pt;padding-right:2.0pt;">87.3</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.15.15.4" style="padding-left:2.0pt;padding-right:2.0pt;">69.9</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.15.15.5" style="padding-left:2.0pt;padding-right:2.0pt;">69.8</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.15.15.6" style="padding-left:2.0pt;padding-right:2.0pt;">53.0</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.15.15.7" style="padding-left:2.0pt;padding-right:2.0pt;">65.8</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.15.15.8" style="padding-left:2.0pt;padding-right:2.0pt;">96.4</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.15.15.9" style="padding-left:2.0pt;padding-right:2.0pt;">86.1</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.15.15.10" style="padding-left:2.0pt;padding-right:2.0pt;">89.2</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.15.15.11" style="padding-left:2.0pt;padding-right:2.0pt;">83.0</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T3.1.1.15.15.12" style="padding-left:2.0pt;padding-right:2.0pt;">62.1</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.15.15.13" style="padding-left:2.0pt;padding-right:2.0pt;">89.3</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.15.15.14" style="padding-left:2.0pt;padding-right:2.0pt;">90.9</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.15.15.15" style="padding-left:2.0pt;padding-right:2.0pt;">90.9</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.15.15.16" style="padding-left:2.0pt;padding-right:2.0pt;">79.4</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.15.15.17" style="padding-left:2.0pt;padding-right:2.0pt;">78.3</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T3.1.1.15.15.18" style="padding-left:2.0pt;padding-right:2.0pt;">75.4</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.15.15.19" style="padding-left:2.0pt;padding-right:2.0pt;">76.3</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.15.15.20" style="padding-left:2.0pt;padding-right:2.0pt;">84.0</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.15.15.21" style="padding-left:2.0pt;padding-right:2.0pt;">79.0</td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.1.16.16">
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T3.1.1.16.16.1" style="padding-left:2.0pt;padding-right:2.0pt;">CCQ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib17" title="">17</a>]</cite>
</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.16.16.2" style="padding-left:2.0pt;padding-right:2.0pt;">76.6</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.16.16.3" style="padding-left:2.0pt;padding-right:2.0pt;">86.6</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.16.16.4" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.16.16.4.1">70.5</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.16.16.5" style="padding-left:2.0pt;padding-right:2.0pt;">68.9</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.16.16.6" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.16.16.6.1">54.8</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.16.16.7" style="padding-left:2.0pt;padding-right:2.0pt;">69.7</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.16.16.8" style="padding-left:2.0pt;padding-right:2.0pt;">96.3</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.16.16.9" style="padding-left:2.0pt;padding-right:2.0pt;">86.2</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.16.16.10" style="padding-left:2.0pt;padding-right:2.0pt;">89.4</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.16.16.11" style="padding-left:2.0pt;padding-right:2.0pt;">83.3</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T3.1.1.16.16.12" style="padding-left:2.0pt;padding-right:2.0pt;">61.8</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.16.16.13" style="padding-left:2.0pt;padding-right:2.0pt;">88.9</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.16.16.14" style="padding-left:2.0pt;padding-right:2.0pt;">90.7</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.16.16.15" style="padding-left:2.0pt;padding-right:2.0pt;">90.7</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.16.16.16" style="padding-left:2.0pt;padding-right:2.0pt;">79.1</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.16.16.17" style="padding-left:2.0pt;padding-right:2.0pt;">78.4</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T3.1.1.16.16.18" style="padding-left:2.0pt;padding-right:2.0pt;">76.3</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.16.16.19" style="padding-left:2.0pt;padding-right:2.0pt;">76.7</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.16.16.20" style="padding-left:2.0pt;padding-right:2.0pt;">84.0</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.16.16.21" style="padding-left:2.0pt;padding-right:2.0pt;">79.3</td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.1.17.17">
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T3.1.1.17.17.1" style="padding-left:2.0pt;padding-right:2.0pt;">UniSeg <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib16" title="">16</a>]</cite>
</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.17.17.2" style="padding-left:2.0pt;padding-right:2.0pt;">79.0</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.17.17.3" style="padding-left:2.0pt;padding-right:2.0pt;">87.0</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.17.17.4" style="padding-left:2.0pt;padding-right:2.0pt;">70.4</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.17.17.5" style="padding-left:2.0pt;padding-right:2.0pt;">69.8</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.17.17.6" style="padding-left:2.0pt;padding-right:2.0pt;">53.5</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.17.17.7" style="padding-left:2.0pt;padding-right:2.0pt;">69.0</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.17.17.8" style="padding-left:2.0pt;padding-right:2.0pt;">96.4</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.17.17.9" style="padding-left:2.0pt;padding-right:2.0pt;">86.1</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.17.17.10" style="padding-left:2.0pt;padding-right:2.0pt;">89.9</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.17.17.11" style="padding-left:2.0pt;padding-right:2.0pt;">83.6</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T3.1.1.17.17.12" style="padding-left:2.0pt;padding-right:2.0pt;">67.7</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.17.17.13" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.17.17.13.1">89.4</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.17.17.14" style="padding-left:2.0pt;padding-right:2.0pt;">91.3</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.17.17.15" style="padding-left:2.0pt;padding-right:2.0pt;">90.9</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.17.17.16" style="padding-left:2.0pt;padding-right:2.0pt;">79.8</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.17.17.17" style="padding-left:2.0pt;padding-right:2.0pt;">78.6</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T3.1.1.17.17.18" style="padding-left:2.0pt;padding-right:2.0pt;">76.2</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.17.17.19" style="padding-left:2.0pt;padding-right:2.0pt;">77.5</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.17.17.20" style="padding-left:2.0pt;padding-right:2.0pt;">84.3</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.17.17.21" style="padding-left:2.0pt;padding-right:2.0pt;">79.9</td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.1.18.18">
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T3.1.1.18.18.1" style="padding-left:2.0pt;padding-right:2.0pt;">MedUniSeg</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.18.18.2" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.18.18.2.1">79.9</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.18.18.3" style="padding-left:2.0pt;padding-right:2.0pt;">86.9</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.18.18.4" style="padding-left:2.0pt;padding-right:2.0pt;">70.2</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.18.18.5" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.18.18.5.1">71.0</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.18.18.6" style="padding-left:2.0pt;padding-right:2.0pt;">54.2</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.18.18.7" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.18.18.7.1">72.6</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.18.18.8" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.18.18.8.1">96.4</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.18.18.9" style="padding-left:2.0pt;padding-right:2.0pt;">86.3</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.18.18.10" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.18.18.10.1">89.9</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.18.18.11" style="padding-left:2.0pt;padding-right:2.0pt;">83.5</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T3.1.1.18.18.12" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.18.18.12.1">68.7</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.18.18.13" style="padding-left:2.0pt;padding-right:2.0pt;">89.2</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.18.18.14" style="padding-left:2.0pt;padding-right:2.0pt;">91.3</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.18.18.15" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.18.18.15.1">91.6</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.18.18.16" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.18.18.16.1">80.4</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.18.18.17" style="padding-left:2.0pt;padding-right:2.0pt;">78.8</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T3.1.1.18.18.18" style="padding-left:2.0pt;padding-right:2.0pt;">77.5</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.18.18.19" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.18.18.19.1">78.1</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.18.18.20" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.18.18.20.1">84.8</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.18.18.21" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.18.18.21.1">80.5</span></td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.1.19.19">
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" id="S5.T3.1.1.19.19.1" style="padding-left:2.0pt;padding-right:2.0pt;">MedUniSeg*</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S5.T3.1.1.19.19.2" style="padding-left:2.0pt;padding-right:2.0pt;">79.9</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S5.T3.1.1.19.19.3" style="padding-left:2.0pt;padding-right:2.0pt;">89.0</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S5.T3.1.1.19.19.4" style="padding-left:2.0pt;padding-right:2.0pt;">70.2</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S5.T3.1.1.19.19.5" style="padding-left:2.0pt;padding-right:2.0pt;">71.0</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S5.T3.1.1.19.19.6" style="padding-left:2.0pt;padding-right:2.0pt;">54.2</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S5.T3.1.1.19.19.7" style="padding-left:2.0pt;padding-right:2.0pt;">72.6</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S5.T3.1.1.19.19.8" style="padding-left:2.0pt;padding-right:2.0pt;">96.4</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S5.T3.1.1.19.19.9" style="padding-left:2.0pt;padding-right:2.0pt;">86.8</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S5.T3.1.1.19.19.10" style="padding-left:2.0pt;padding-right:2.0pt;">89.9</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S5.T3.1.1.19.19.11" style="padding-left:2.0pt;padding-right:2.0pt;">84.4</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" id="S5.T3.1.1.19.19.12" style="padding-left:2.0pt;padding-right:2.0pt;">68.7</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S5.T3.1.1.19.19.13" style="padding-left:2.0pt;padding-right:2.0pt;">89.2</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S5.T3.1.1.19.19.14" style="padding-left:2.0pt;padding-right:2.0pt;">91.3</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S5.T3.1.1.19.19.15" style="padding-left:2.0pt;padding-right:2.0pt;">91.6</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S5.T3.1.1.19.19.16" style="padding-left:2.0pt;padding-right:2.0pt;">80.4</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S5.T3.1.1.19.19.17" style="padding-left:2.0pt;padding-right:2.0pt;">79.9</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" id="S5.T3.1.1.19.19.18" style="padding-left:2.0pt;padding-right:2.0pt;">78.1</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S5.T3.1.1.19.19.19" style="padding-left:2.0pt;padding-right:2.0pt;">78.5</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S5.T3.1.1.19.19.20" style="padding-left:2.0pt;padding-right:2.0pt;">85.1</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S5.T3.1.1.19.19.21" style="padding-left:2.0pt;padding-right:2.0pt;">80.8</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<figure class="ltx_table" id="S5.T4">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE IV: </span>Performance of ten self-supervised models, five supervised models, and two training from scratch (TFS) models on six downstream datasets, utilizing 20%, 50%, and 100% of the training data. For 3D models, the 2D data are regarded as pseudo 3D data with a depth of one. A dash <math alttext="-" class="ltx_Math" display="inline" id="S5.T4.3.m1.1"><semantics id="S5.T4.3.m1.1b"><mo id="S5.T4.3.m1.1.1" xref="S5.T4.3.m1.1.1.cmml">−</mo><annotation-xml encoding="MathML-Content" id="S5.T4.3.m1.1c"><minus id="S5.T4.3.m1.1.1.cmml" xref="S5.T4.3.m1.1.1"></minus></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.3.m1.1d">-</annotation><annotation encoding="application/x-llamapun" id="S5.T4.3.m1.1e">-</annotation></semantics></math> presents that the model could not be trained on the dataset. For universal models, a dagger <math alttext="{\dagger}" class="ltx_Math" display="inline" id="S5.T4.4.m2.1"><semantics id="S5.T4.4.m2.1b"><mo id="S5.T4.4.m2.1.1" xref="S5.T4.4.m2.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="S5.T4.4.m2.1c"><ci id="S5.T4.4.m2.1.1.cmml" xref="S5.T4.4.m2.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.4.m2.1d">{\dagger}</annotation><annotation encoding="application/x-llamapun" id="S5.T4.4.m2.1e">†</annotation></semantics></math> means the use of official pre-trained weights. Dice scores (%) are reported for each dataset. All results represent the average of three independent runs, with the best performance for each dataset highlighted in bold. </figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S5.T4.6" style="width:867.2pt;height:435pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(20.9pt,-10.5pt) scale(1.05063189468955,1.05063189468955) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S5.T4.6.2">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T4.6.2.3.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_tt" id="S5.T4.6.2.3.1.1" rowspan="3" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text" id="S5.T4.6.2.3.1.1.1">Method</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_tt" id="S5.T4.6.2.3.1.2" rowspan="3" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text" id="S5.T4.6.2.3.1.2.1">Pre-training Data</span></th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="9" id="S5.T4.6.2.3.1.3" style="padding-left:4.0pt;padding-right:4.0pt;">3D</td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="9" id="S5.T4.6.2.3.1.4" style="padding-left:4.0pt;padding-right:4.0pt;">2D</td>
</tr>
<tr class="ltx_tr" id="S5.T4.6.2.4.2">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="3" id="S5.T4.6.2.4.2.1" style="padding-left:4.0pt;padding-right:4.0pt;">BTCV (CT)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="3" id="S5.T4.6.2.4.2.2" style="padding-left:4.0pt;padding-right:4.0pt;">COVID-19-20 (CT)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="3" id="S5.T4.6.2.4.2.3" style="padding-left:4.0pt;padding-right:4.0pt;">VS (MRI)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="3" id="S5.T4.6.2.4.2.4" style="padding-left:4.0pt;padding-right:4.0pt;">SIIM (X-ray)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="3" id="S5.T4.6.2.4.2.5" style="padding-left:4.0pt;padding-right:4.0pt;">IDRID (Fundus)</td>
<td class="ltx_td ltx_align_center ltx_border_t" colspan="3" id="S5.T4.6.2.4.2.6" style="padding-left:4.0pt;padding-right:4.0pt;">SegPC (Path.)</td>
</tr>
<tr class="ltx_tr" id="S5.T4.6.2.5.3">
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.6.2.5.3.1" style="padding-left:4.0pt;padding-right:4.0pt;">20%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.6.2.5.3.2" style="padding-left:4.0pt;padding-right:4.0pt;">50%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.6.2.5.3.3" style="padding-left:4.0pt;padding-right:4.0pt;">100%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.6.2.5.3.4" style="padding-left:4.0pt;padding-right:4.0pt;">20%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.6.2.5.3.5" style="padding-left:4.0pt;padding-right:4.0pt;">50%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.6.2.5.3.6" style="padding-left:4.0pt;padding-right:4.0pt;">100%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.6.2.5.3.7" style="padding-left:4.0pt;padding-right:4.0pt;">20%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.6.2.5.3.8" style="padding-left:4.0pt;padding-right:4.0pt;">50%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.6.2.5.3.9" style="padding-left:4.0pt;padding-right:4.0pt;">100%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.6.2.5.3.10" style="padding-left:4.0pt;padding-right:4.0pt;">20%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.6.2.5.3.11" style="padding-left:4.0pt;padding-right:4.0pt;">50%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.6.2.5.3.12" style="padding-left:4.0pt;padding-right:4.0pt;">100%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.6.2.5.3.13" style="padding-left:4.0pt;padding-right:4.0pt;">20%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.6.2.5.3.14" style="padding-left:4.0pt;padding-right:4.0pt;">50%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.6.2.5.3.15" style="padding-left:4.0pt;padding-right:4.0pt;">100%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.6.2.5.3.16" style="padding-left:4.0pt;padding-right:4.0pt;">20%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.6.2.5.3.17" style="padding-left:4.0pt;padding-right:4.0pt;">50%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.6.2.5.3.18" style="padding-left:4.0pt;padding-right:4.0pt;">100%</td>
</tr>
<tr class="ltx_tr" id="S5.T4.6.2.6.4">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S5.T4.6.2.6.4.1" style="padding-left:4.0pt;padding-right:4.0pt;">MG <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib81" title="">81</a>]</cite>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S5.T4.6.2.6.4.2" style="padding-left:4.0pt;padding-right:4.0pt;">3D CT</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.6.2.6.4.3" style="padding-left:4.0pt;padding-right:4.0pt;">50.2</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.6.2.6.4.4" style="padding-left:4.0pt;padding-right:4.0pt;">66.1</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.6.2.6.4.5" style="padding-left:4.0pt;padding-right:4.0pt;">77.1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.6.2.6.4.6" style="padding-left:4.0pt;padding-right:4.0pt;">59.7</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.6.2.6.4.7" style="padding-left:4.0pt;padding-right:4.0pt;">62.2</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.6.2.6.4.8" style="padding-left:4.0pt;padding-right:4.0pt;">63.3</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.6.2.6.4.9" style="padding-left:4.0pt;padding-right:4.0pt;">81.3</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.6.2.6.4.10" style="padding-left:4.0pt;padding-right:4.0pt;">88.6</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.6.2.6.4.11" style="padding-left:4.0pt;padding-right:4.0pt;">85.9</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.6.2.6.4.12" style="padding-left:4.0pt;padding-right:4.0pt;">41.1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.6.2.6.4.13" style="padding-left:4.0pt;padding-right:4.0pt;">48.8</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.6.2.6.4.14" style="padding-left:4.0pt;padding-right:4.0pt;">52.2</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.6.2.6.4.15" style="padding-left:4.0pt;padding-right:4.0pt;">24.1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.6.2.6.4.16" style="padding-left:4.0pt;padding-right:4.0pt;">29.2</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.6.2.6.4.17" style="padding-left:4.0pt;padding-right:4.0pt;">22.9</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.6.2.6.4.18" style="padding-left:4.0pt;padding-right:4.0pt;">70.8</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.6.2.6.4.19" style="padding-left:4.0pt;padding-right:4.0pt;">75.1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.6.2.6.4.20" style="padding-left:4.0pt;padding-right:4.0pt;">77.5</td>
</tr>
<tr class="ltx_tr" id="S5.T4.6.2.7.5">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S5.T4.6.2.7.5.1" style="padding-left:4.0pt;padding-right:4.0pt;">GVSL <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib82" title="">82</a>]</cite>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S5.T4.6.2.7.5.2" style="padding-left:4.0pt;padding-right:4.0pt;">3D CT</th>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.7.5.3" style="padding-left:4.0pt;padding-right:4.0pt;">31.4</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.7.5.4" style="padding-left:4.0pt;padding-right:4.0pt;">69.8</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T4.6.2.7.5.5" style="padding-left:4.0pt;padding-right:4.0pt;">79.5</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.7.5.6" style="padding-left:4.0pt;padding-right:4.0pt;">54.5</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.7.5.7" style="padding-left:4.0pt;padding-right:4.0pt;">55.4</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T4.6.2.7.5.8" style="padding-left:4.0pt;padding-right:4.0pt;">56.5</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.7.5.9" style="padding-left:4.0pt;padding-right:4.0pt;">86.9</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.7.5.10" style="padding-left:4.0pt;padding-right:4.0pt;">87.9</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T4.6.2.7.5.11" style="padding-left:4.0pt;padding-right:4.0pt;">91.0</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.7.5.12" style="padding-left:4.0pt;padding-right:4.0pt;">43.1</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.7.5.13" style="padding-left:4.0pt;padding-right:4.0pt;">49.1</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T4.6.2.7.5.14" style="padding-left:4.0pt;padding-right:4.0pt;">52.9</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.7.5.15" style="padding-left:4.0pt;padding-right:4.0pt;">39.4</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.7.5.16" style="padding-left:4.0pt;padding-right:4.0pt;">47.3</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T4.6.2.7.5.17" style="padding-left:4.0pt;padding-right:4.0pt;">49.3</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.7.5.18" style="padding-left:4.0pt;padding-right:4.0pt;">73.1</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.7.5.19" style="padding-left:4.0pt;padding-right:4.0pt;">77.2</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.7.5.20" style="padding-left:4.0pt;padding-right:4.0pt;">80.3</td>
</tr>
<tr class="ltx_tr" id="S5.T4.6.2.8.6">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S5.T4.6.2.8.6.1" style="padding-left:4.0pt;padding-right:4.0pt;">DeSD <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib83" title="">83</a>]</cite>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S5.T4.6.2.8.6.2" style="padding-left:4.0pt;padding-right:4.0pt;">3D CT</th>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.8.6.3" style="padding-left:4.0pt;padding-right:4.0pt;">69.5</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.8.6.4" style="padding-left:4.0pt;padding-right:4.0pt;">79.5</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T4.6.2.8.6.5" style="padding-left:4.0pt;padding-right:4.0pt;">83.3</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.8.6.6" style="padding-left:4.0pt;padding-right:4.0pt;">62.8</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.8.6.7" style="padding-left:4.0pt;padding-right:4.0pt;">67.1</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T4.6.2.8.6.8" style="padding-left:4.0pt;padding-right:4.0pt;">68.3</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.8.6.9" style="padding-left:4.0pt;padding-right:4.0pt;">91.1</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.8.6.10" style="padding-left:4.0pt;padding-right:4.0pt;">91.4</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T4.6.2.8.6.11" style="padding-left:4.0pt;padding-right:4.0pt;">92.2</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.8.6.12" style="padding-left:4.0pt;padding-right:4.0pt;">39.1</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.8.6.13" style="padding-left:4.0pt;padding-right:4.0pt;">42.2</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T4.6.2.8.6.14" style="padding-left:4.0pt;padding-right:4.0pt;">46.0</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.8.6.15" style="padding-left:4.0pt;padding-right:4.0pt;">47.7</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.8.6.16" style="padding-left:4.0pt;padding-right:4.0pt;">60.7</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T4.6.2.8.6.17" style="padding-left:4.0pt;padding-right:4.0pt;">59.4</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.8.6.18" style="padding-left:4.0pt;padding-right:4.0pt;">75.4</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.8.6.19" style="padding-left:4.0pt;padding-right:4.0pt;">79.3</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.8.6.20" style="padding-left:4.0pt;padding-right:4.0pt;">80.8</td>
</tr>
<tr class="ltx_tr" id="S5.T4.6.2.9.7">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S5.T4.6.2.9.7.1" style="padding-left:4.0pt;padding-right:4.0pt;">SMIT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib84" title="">84</a>]</cite>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S5.T4.6.2.9.7.2" style="padding-left:4.0pt;padding-right:4.0pt;">3D CT</th>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.9.7.3" style="padding-left:4.0pt;padding-right:4.0pt;">56.7</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.9.7.4" style="padding-left:4.0pt;padding-right:4.0pt;">72.5</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T4.6.2.9.7.5" style="padding-left:4.0pt;padding-right:4.0pt;">80.6</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.9.7.6" style="padding-left:4.0pt;padding-right:4.0pt;">57.3</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.9.7.7" style="padding-left:4.0pt;padding-right:4.0pt;">58.7</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T4.6.2.9.7.8" style="padding-left:4.0pt;padding-right:4.0pt;">62.1</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.9.7.9" style="padding-left:4.0pt;padding-right:4.0pt;">90.3</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.9.7.10" style="padding-left:4.0pt;padding-right:4.0pt;">91.5</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T4.6.2.9.7.11" style="padding-left:4.0pt;padding-right:4.0pt;">92.2</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.9.7.12" style="padding-left:4.0pt;padding-right:4.0pt;">-</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.9.7.13" style="padding-left:4.0pt;padding-right:4.0pt;">-</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T4.6.2.9.7.14" style="padding-left:4.0pt;padding-right:4.0pt;">-</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.9.7.15" style="padding-left:4.0pt;padding-right:4.0pt;">-</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.9.7.16" style="padding-left:4.0pt;padding-right:4.0pt;">-</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T4.6.2.9.7.17" style="padding-left:4.0pt;padding-right:4.0pt;">-</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.9.7.18" style="padding-left:4.0pt;padding-right:4.0pt;">-</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.9.7.19" style="padding-left:4.0pt;padding-right:4.0pt;">-</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.9.7.20" style="padding-left:4.0pt;padding-right:4.0pt;">-</td>
</tr>
<tr class="ltx_tr" id="S5.T4.6.2.10.8">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S5.T4.6.2.10.8.1" style="padding-left:4.0pt;padding-right:4.0pt;">Swin UNETR <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib79" title="">79</a>]</cite>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S5.T4.6.2.10.8.2" style="padding-left:4.0pt;padding-right:4.0pt;">3D CT</th>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.10.8.3" style="padding-left:4.0pt;padding-right:4.0pt;">58.8</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.10.8.4" style="padding-left:4.0pt;padding-right:4.0pt;">74.1</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T4.6.2.10.8.5" style="padding-left:4.0pt;padding-right:4.0pt;">80.7</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.10.8.6" style="padding-left:4.0pt;padding-right:4.0pt;">58.0</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.10.8.7" style="padding-left:4.0pt;padding-right:4.0pt;">60.6</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T4.6.2.10.8.8" style="padding-left:4.0pt;padding-right:4.0pt;">63.7</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.10.8.9" style="padding-left:4.0pt;padding-right:4.0pt;">89.6</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.10.8.10" style="padding-left:4.0pt;padding-right:4.0pt;">89.1</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T4.6.2.10.8.11" style="padding-left:4.0pt;padding-right:4.0pt;">90.0</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.10.8.12" style="padding-left:4.0pt;padding-right:4.0pt;">-</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.10.8.13" style="padding-left:4.0pt;padding-right:4.0pt;">-</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T4.6.2.10.8.14" style="padding-left:4.0pt;padding-right:4.0pt;">-</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.10.8.15" style="padding-left:4.0pt;padding-right:4.0pt;">-</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.10.8.16" style="padding-left:4.0pt;padding-right:4.0pt;">-</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T4.6.2.10.8.17" style="padding-left:4.0pt;padding-right:4.0pt;">-</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.10.8.18" style="padding-left:4.0pt;padding-right:4.0pt;">-</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.10.8.19" style="padding-left:4.0pt;padding-right:4.0pt;">-</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.10.8.20" style="padding-left:4.0pt;padding-right:4.0pt;">-</td>
</tr>
<tr class="ltx_tr" id="S5.T4.6.2.11.9">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S5.T4.6.2.11.9.1" style="padding-left:4.0pt;padding-right:4.0pt;">VoCo <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib28" title="">28</a>]</cite>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S5.T4.6.2.11.9.2" style="padding-left:4.0pt;padding-right:4.0pt;">3D CT</th>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.11.9.3" style="padding-left:4.0pt;padding-right:4.0pt;">68.9</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.11.9.4" style="padding-left:4.0pt;padding-right:4.0pt;">78.7</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T4.6.2.11.9.5" style="padding-left:4.0pt;padding-right:4.0pt;">83.4</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.11.9.6" style="padding-left:4.0pt;padding-right:4.0pt;">62.0</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.11.9.7" style="padding-left:4.0pt;padding-right:4.0pt;">64.9</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T4.6.2.11.9.8" style="padding-left:4.0pt;padding-right:4.0pt;">67.6</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.11.9.9" style="padding-left:4.0pt;padding-right:4.0pt;">91.1</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.11.9.10" style="padding-left:4.0pt;padding-right:4.0pt;">91.9</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T4.6.2.11.9.11" style="padding-left:4.0pt;padding-right:4.0pt;">92.7</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.11.9.12" style="padding-left:4.0pt;padding-right:4.0pt;">-</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.11.9.13" style="padding-left:4.0pt;padding-right:4.0pt;">-</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T4.6.2.11.9.14" style="padding-left:4.0pt;padding-right:4.0pt;">-</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.11.9.15" style="padding-left:4.0pt;padding-right:4.0pt;">-</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.11.9.16" style="padding-left:4.0pt;padding-right:4.0pt;">-</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T4.6.2.11.9.17" style="padding-left:4.0pt;padding-right:4.0pt;">-</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.11.9.18" style="padding-left:4.0pt;padding-right:4.0pt;">-</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.11.9.19" style="padding-left:4.0pt;padding-right:4.0pt;">-</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.11.9.20" style="padding-left:4.0pt;padding-right:4.0pt;">-</td>
</tr>
<tr class="ltx_tr" id="S5.T4.6.2.12.10">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S5.T4.6.2.12.10.1" style="padding-left:4.0pt;padding-right:4.0pt;">BT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib85" title="">85</a>]</cite>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S5.T4.6.2.12.10.2" style="padding-left:4.0pt;padding-right:4.0pt;">2D Path.</th>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.12.10.3" style="padding-left:4.0pt;padding-right:4.0pt;">-</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.12.10.4" style="padding-left:4.0pt;padding-right:4.0pt;">-</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T4.6.2.12.10.5" style="padding-left:4.0pt;padding-right:4.0pt;">-</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.12.10.6" style="padding-left:4.0pt;padding-right:4.0pt;">-</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.12.10.7" style="padding-left:4.0pt;padding-right:4.0pt;">-</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T4.6.2.12.10.8" style="padding-left:4.0pt;padding-right:4.0pt;">-</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.12.10.9" style="padding-left:4.0pt;padding-right:4.0pt;">-</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.12.10.10" style="padding-left:4.0pt;padding-right:4.0pt;">-</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T4.6.2.12.10.11" style="padding-left:4.0pt;padding-right:4.0pt;">-</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.12.10.12" style="padding-left:4.0pt;padding-right:4.0pt;">44.4</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.12.10.13" style="padding-left:4.0pt;padding-right:4.0pt;">51.2</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T4.6.2.12.10.14" style="padding-left:4.0pt;padding-right:4.0pt;">54.2</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.12.10.15" style="padding-left:4.0pt;padding-right:4.0pt;">49.0</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.12.10.16" style="padding-left:4.0pt;padding-right:4.0pt;">56.5</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T4.6.2.12.10.17" style="padding-left:4.0pt;padding-right:4.0pt;">58.2</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.12.10.18" style="padding-left:4.0pt;padding-right:4.0pt;">76.0</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.12.10.19" style="padding-left:4.0pt;padding-right:4.0pt;">79.7</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.12.10.20" style="padding-left:4.0pt;padding-right:4.0pt;">80.2</td>
</tr>
<tr class="ltx_tr" id="S5.T4.6.2.13.11">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S5.T4.6.2.13.11.1" style="padding-left:4.0pt;padding-right:4.0pt;">PCRLv2 (CheXpert) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib86" title="">86</a>]</cite>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S5.T4.6.2.13.11.2" style="padding-left:4.0pt;padding-right:4.0pt;">2D X-ray</th>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.13.11.3" style="padding-left:4.0pt;padding-right:4.0pt;">-</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.13.11.4" style="padding-left:4.0pt;padding-right:4.0pt;">-</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T4.6.2.13.11.5" style="padding-left:4.0pt;padding-right:4.0pt;">-</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.13.11.6" style="padding-left:4.0pt;padding-right:4.0pt;">-</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.13.11.7" style="padding-left:4.0pt;padding-right:4.0pt;">-</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T4.6.2.13.11.8" style="padding-left:4.0pt;padding-right:4.0pt;">-</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.13.11.9" style="padding-left:4.0pt;padding-right:4.0pt;">-</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.13.11.10" style="padding-left:4.0pt;padding-right:4.0pt;">-</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T4.6.2.13.11.11" style="padding-left:4.0pt;padding-right:4.0pt;">-</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.13.11.12" style="padding-left:4.0pt;padding-right:4.0pt;">38.7</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.13.11.13" style="padding-left:4.0pt;padding-right:4.0pt;">47.6</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T4.6.2.13.11.14" style="padding-left:4.0pt;padding-right:4.0pt;">49.7</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.13.11.15" style="padding-left:4.0pt;padding-right:4.0pt;">35.2</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.13.11.16" style="padding-left:4.0pt;padding-right:4.0pt;">39.1</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T4.6.2.13.11.17" style="padding-left:4.0pt;padding-right:4.0pt;">51.3</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.13.11.18" style="padding-left:4.0pt;padding-right:4.0pt;">76.0</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.13.11.19" style="padding-left:4.0pt;padding-right:4.0pt;">78.8</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.13.11.20" style="padding-left:4.0pt;padding-right:4.0pt;">79.4</td>
</tr>
<tr class="ltx_tr" id="S5.T4.6.2.14.12">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S5.T4.6.2.14.12.1" style="padding-left:4.0pt;padding-right:4.0pt;">MedKLIP <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib29" title="">29</a>]</cite>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S5.T4.6.2.14.12.2" style="padding-left:4.0pt;padding-right:4.0pt;">1D Report, 2D X-ray</th>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.14.12.3" style="padding-left:4.0pt;padding-right:4.0pt;">-</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.14.12.4" style="padding-left:4.0pt;padding-right:4.0pt;">-</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T4.6.2.14.12.5" style="padding-left:4.0pt;padding-right:4.0pt;">-</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.14.12.6" style="padding-left:4.0pt;padding-right:4.0pt;">-</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.14.12.7" style="padding-left:4.0pt;padding-right:4.0pt;">-</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T4.6.2.14.12.8" style="padding-left:4.0pt;padding-right:4.0pt;">-</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.14.12.9" style="padding-left:4.0pt;padding-right:4.0pt;">-</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.14.12.10" style="padding-left:4.0pt;padding-right:4.0pt;">-</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T4.6.2.14.12.11" style="padding-left:4.0pt;padding-right:4.0pt;">-</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.14.12.12" style="padding-left:4.0pt;padding-right:4.0pt;">48.9</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.14.12.13" style="padding-left:4.0pt;padding-right:4.0pt;">53.0</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T4.6.2.14.12.14" style="padding-left:4.0pt;padding-right:4.0pt;">54.2</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.14.12.15" style="padding-left:4.0pt;padding-right:4.0pt;">41.2</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.14.12.16" style="padding-left:4.0pt;padding-right:4.0pt;">47.5</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T4.6.2.14.12.17" style="padding-left:4.0pt;padding-right:4.0pt;">51.6</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.14.12.18" style="padding-left:4.0pt;padding-right:4.0pt;">73.0</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.14.12.19" style="padding-left:4.0pt;padding-right:4.0pt;">77.2</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.14.12.20" style="padding-left:4.0pt;padding-right:4.0pt;">78.2</td>
</tr>
<tr class="ltx_tr" id="S5.T4.6.2.15.13">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S5.T4.6.2.15.13.1" style="padding-left:4.0pt;padding-right:4.0pt;">UniMiSS <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib35" title="">35</a>]</cite>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S5.T4.6.2.15.13.2" style="padding-left:4.0pt;padding-right:4.0pt;">2D X-ray, 3D CT</th>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.15.13.3" style="padding-left:4.0pt;padding-right:4.0pt;">66.4</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.15.13.4" style="padding-left:4.0pt;padding-right:4.0pt;">76.7</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T4.6.2.15.13.5" style="padding-left:4.0pt;padding-right:4.0pt;">81.2</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.15.13.6" style="padding-left:4.0pt;padding-right:4.0pt;">60.7</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.15.13.7" style="padding-left:4.0pt;padding-right:4.0pt;">64.1</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T4.6.2.15.13.8" style="padding-left:4.0pt;padding-right:4.0pt;">65.8</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.15.13.9" style="padding-left:4.0pt;padding-right:4.0pt;">89.9</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.15.13.10" style="padding-left:4.0pt;padding-right:4.0pt;">90.8</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T4.6.2.15.13.11" style="padding-left:4.0pt;padding-right:4.0pt;">91.4</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.15.13.12" style="padding-left:4.0pt;padding-right:4.0pt;">46.0</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.15.13.13" style="padding-left:4.0pt;padding-right:4.0pt;">52.7</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T4.6.2.15.13.14" style="padding-left:4.0pt;padding-right:4.0pt;">54.8</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.15.13.15" style="padding-left:4.0pt;padding-right:4.0pt;">51.4</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.15.13.16" style="padding-left:4.0pt;padding-right:4.0pt;">61.5</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T4.6.2.15.13.17" style="padding-left:4.0pt;padding-right:4.0pt;">63.5</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.15.13.18" style="padding-left:4.0pt;padding-right:4.0pt;">73.8</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.15.13.19" style="padding-left:4.0pt;padding-right:4.0pt;">78.8</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.15.13.20" style="padding-left:4.0pt;padding-right:4.0pt;">80.7</td>
</tr>
<tr class="ltx_tr" id="S5.T4.5.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S5.T4.5.1.1.1" style="padding-left:4.0pt;padding-right:4.0pt;">UniSeg<math alttext="{\dagger}" class="ltx_Math" display="inline" id="S5.T4.5.1.1.1.m1.1"><semantics id="S5.T4.5.1.1.1.m1.1a"><mo id="S5.T4.5.1.1.1.m1.1.1" xref="S5.T4.5.1.1.1.m1.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="S5.T4.5.1.1.1.m1.1b"><ci id="S5.T4.5.1.1.1.m1.1.1.cmml" xref="S5.T4.5.1.1.1.m1.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.5.1.1.1.m1.1c">{\dagger}</annotation><annotation encoding="application/x-llamapun" id="S5.T4.5.1.1.1.m1.1d">†</annotation></semantics></math> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib16" title="">16</a>]</cite>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S5.T4.5.1.1.2" style="padding-left:4.0pt;padding-right:4.0pt;">3D CT, 3D MRI, 3D PET</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.5.1.1.3" style="padding-left:4.0pt;padding-right:4.0pt;">71.4</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.5.1.1.4" style="padding-left:4.0pt;padding-right:4.0pt;">79.7</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.5.1.1.5" style="padding-left:4.0pt;padding-right:4.0pt;">84.6</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.5.1.1.6" style="padding-left:4.0pt;padding-right:4.0pt;">68.6</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.5.1.1.7" style="padding-left:4.0pt;padding-right:4.0pt;">70.9</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.5.1.1.8" style="padding-left:4.0pt;padding-right:4.0pt;">72.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.5.1.1.9" style="padding-left:4.0pt;padding-right:4.0pt;">91.1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.5.1.1.10" style="padding-left:4.0pt;padding-right:4.0pt;">92.1</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.5.1.1.11" style="padding-left:4.0pt;padding-right:4.0pt;">92.9</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.5.1.1.12" style="padding-left:4.0pt;padding-right:4.0pt;">50.8</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.5.1.1.13" style="padding-left:4.0pt;padding-right:4.0pt;">56.2</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.5.1.1.14" style="padding-left:4.0pt;padding-right:4.0pt;">58.3</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.5.1.1.15" style="padding-left:4.0pt;padding-right:4.0pt;">53.9</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.5.1.1.16" style="padding-left:4.0pt;padding-right:4.0pt;">62.5</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.5.1.1.17" style="padding-left:4.0pt;padding-right:4.0pt;">63.9</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.5.1.1.18" style="padding-left:4.0pt;padding-right:4.0pt;">75.3</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.5.1.1.19" style="padding-left:4.0pt;padding-right:4.0pt;">80.8</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.5.1.1.20" style="padding-left:4.0pt;padding-right:4.0pt;">82.5</td>
</tr>
<tr class="ltx_tr" id="S5.T4.6.2.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S5.T4.6.2.2.1" style="padding-left:4.0pt;padding-right:4.0pt;">Universal Model<math alttext="{\dagger}" class="ltx_Math" display="inline" id="S5.T4.6.2.2.1.m1.1"><semantics id="S5.T4.6.2.2.1.m1.1a"><mo id="S5.T4.6.2.2.1.m1.1.1" xref="S5.T4.6.2.2.1.m1.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="S5.T4.6.2.2.1.m1.1b"><ci id="S5.T4.6.2.2.1.m1.1.1.cmml" xref="S5.T4.6.2.2.1.m1.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.6.2.2.1.m1.1c">{\dagger}</annotation><annotation encoding="application/x-llamapun" id="S5.T4.6.2.2.1.m1.1d">†</annotation></semantics></math> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib10" title="">10</a>]</cite>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S5.T4.6.2.2.2" style="padding-left:4.0pt;padding-right:4.0pt;">3D CT</th>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.2.3" style="padding-left:4.0pt;padding-right:4.0pt;">61.9</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.2.4" style="padding-left:4.0pt;padding-right:4.0pt;">76.1</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T4.6.2.2.5" style="padding-left:4.0pt;padding-right:4.0pt;">79.9</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.2.6" style="padding-left:4.0pt;padding-right:4.0pt;">61.0</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.2.7" style="padding-left:4.0pt;padding-right:4.0pt;">62.8</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T4.6.2.2.8" style="padding-left:4.0pt;padding-right:4.0pt;">66.1</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.2.9" style="padding-left:4.0pt;padding-right:4.0pt;">91.2</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.2.10" style="padding-left:4.0pt;padding-right:4.0pt;">91.3</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T4.6.2.2.11" style="padding-left:4.0pt;padding-right:4.0pt;">92.3</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.2.12" style="padding-left:4.0pt;padding-right:4.0pt;">-</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.2.13" style="padding-left:4.0pt;padding-right:4.0pt;">-</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T4.6.2.2.14" style="padding-left:4.0pt;padding-right:4.0pt;">-</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.2.15" style="padding-left:4.0pt;padding-right:4.0pt;">-</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.2.16" style="padding-left:4.0pt;padding-right:4.0pt;">-</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T4.6.2.2.17" style="padding-left:4.0pt;padding-right:4.0pt;">-</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.2.18" style="padding-left:4.0pt;padding-right:4.0pt;">-</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.2.19" style="padding-left:4.0pt;padding-right:4.0pt;">-</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.2.20" style="padding-left:4.0pt;padding-right:4.0pt;">-</td>
</tr>
<tr class="ltx_tr" id="S5.T4.6.2.16.14">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S5.T4.6.2.16.14.1" style="padding-left:4.0pt;padding-right:4.0pt;">2D Backbone</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S5.T4.6.2.16.14.2" style="padding-left:4.0pt;padding-right:4.0pt;">N/A</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.6.2.16.14.3" style="padding-left:4.0pt;padding-right:4.0pt;">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.6.2.16.14.4" style="padding-left:4.0pt;padding-right:4.0pt;">-</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.6.2.16.14.5" style="padding-left:4.0pt;padding-right:4.0pt;">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.6.2.16.14.6" style="padding-left:4.0pt;padding-right:4.0pt;">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.6.2.16.14.7" style="padding-left:4.0pt;padding-right:4.0pt;">-</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.6.2.16.14.8" style="padding-left:4.0pt;padding-right:4.0pt;">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.6.2.16.14.9" style="padding-left:4.0pt;padding-right:4.0pt;">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.6.2.16.14.10" style="padding-left:4.0pt;padding-right:4.0pt;">-</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.6.2.16.14.11" style="padding-left:4.0pt;padding-right:4.0pt;">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.6.2.16.14.12" style="padding-left:4.0pt;padding-right:4.0pt;">43.9</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.6.2.16.14.13" style="padding-left:4.0pt;padding-right:4.0pt;">53.2</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.6.2.16.14.14" style="padding-left:4.0pt;padding-right:4.0pt;">55.6</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.6.2.16.14.15" style="padding-left:4.0pt;padding-right:4.0pt;">53.4</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.6.2.16.14.16" style="padding-left:4.0pt;padding-right:4.0pt;">61.5</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.6.2.16.14.17" style="padding-left:4.0pt;padding-right:4.0pt;">62.8</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.6.2.16.14.18" style="padding-left:4.0pt;padding-right:4.0pt;">74.8</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.6.2.16.14.19" style="padding-left:4.0pt;padding-right:4.0pt;">79.1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.6.2.16.14.20" style="padding-left:4.0pt;padding-right:4.0pt;">82.0</td>
</tr>
<tr class="ltx_tr" id="S5.T4.6.2.17.15">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S5.T4.6.2.17.15.1" style="padding-left:4.0pt;padding-right:4.0pt;">3D Backbone</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S5.T4.6.2.17.15.2" style="padding-left:4.0pt;padding-right:4.0pt;">N/A</th>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.17.15.3" style="padding-left:4.0pt;padding-right:4.0pt;">66.2</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.17.15.4" style="padding-left:4.0pt;padding-right:4.0pt;">77.9</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T4.6.2.17.15.5" style="padding-left:4.0pt;padding-right:4.0pt;">83.1</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.17.15.6" style="padding-left:4.0pt;padding-right:4.0pt;">61.2</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.17.15.7" style="padding-left:4.0pt;padding-right:4.0pt;">61.6</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T4.6.2.17.15.8" style="padding-left:4.0pt;padding-right:4.0pt;">65.0</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.17.15.9" style="padding-left:4.0pt;padding-right:4.0pt;">89.7</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.17.15.10" style="padding-left:4.0pt;padding-right:4.0pt;">89.9</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T4.6.2.17.15.11" style="padding-left:4.0pt;padding-right:4.0pt;">90.7</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.17.15.12" style="padding-left:4.0pt;padding-right:4.0pt;">45.5</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.17.15.13" style="padding-left:4.0pt;padding-right:4.0pt;">54.2</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T4.6.2.17.15.14" style="padding-left:4.0pt;padding-right:4.0pt;">55.7</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.17.15.15" style="padding-left:4.0pt;padding-right:4.0pt;">52.9</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.17.15.16" style="padding-left:4.0pt;padding-right:4.0pt;">61.3</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T4.6.2.17.15.17" style="padding-left:4.0pt;padding-right:4.0pt;">62.8</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.17.15.18" style="padding-left:4.0pt;padding-right:4.0pt;">75.0</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.17.15.19" style="padding-left:4.0pt;padding-right:4.0pt;">79.4</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.17.15.20" style="padding-left:4.0pt;padding-right:4.0pt;">82.1</td>
</tr>
<tr class="ltx_tr" id="S5.T4.6.2.18.16">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S5.T4.6.2.18.16.1" style="padding-left:4.0pt;padding-right:4.0pt;">Universal Model <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib10" title="">10</a>]</cite>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S5.T4.6.2.18.16.2" style="padding-left:4.0pt;padding-right:4.0pt;">Nine Modalities</th>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.18.16.3" style="padding-left:4.0pt;padding-right:4.0pt;">71.0</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.18.16.4" style="padding-left:4.0pt;padding-right:4.0pt;">79.5</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T4.6.2.18.16.5" style="padding-left:4.0pt;padding-right:4.0pt;">84.2</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.18.16.6" style="padding-left:4.0pt;padding-right:4.0pt;">65.6</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.18.16.7" style="padding-left:4.0pt;padding-right:4.0pt;">66.0</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T4.6.2.18.16.8" style="padding-left:4.0pt;padding-right:4.0pt;">69.6</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.18.16.9" style="padding-left:4.0pt;padding-right:4.0pt;">90.6</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.18.16.10" style="padding-left:4.0pt;padding-right:4.0pt;">91.1</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T4.6.2.18.16.11" style="padding-left:4.0pt;padding-right:4.0pt;">91.8</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.18.16.12" style="padding-left:4.0pt;padding-right:4.0pt;">50.3</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.18.16.13" style="padding-left:4.0pt;padding-right:4.0pt;">56.7</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T4.6.2.18.16.14" style="padding-left:4.0pt;padding-right:4.0pt;">59.1</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.18.16.15" style="padding-left:4.0pt;padding-right:4.0pt;">54.8</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.18.16.16" style="padding-left:4.0pt;padding-right:4.0pt;">63.1</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T4.6.2.18.16.17" style="padding-left:4.0pt;padding-right:4.0pt;">64.3</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.18.16.18" style="padding-left:4.0pt;padding-right:4.0pt;">77.5</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.18.16.19" style="padding-left:4.0pt;padding-right:4.0pt;">82.1</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.18.16.20" style="padding-left:4.0pt;padding-right:4.0pt;">83.4</td>
</tr>
<tr class="ltx_tr" id="S5.T4.6.2.19.17">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S5.T4.6.2.19.17.1" style="padding-left:4.0pt;padding-right:4.0pt;">Hermes <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib18" title="">18</a>]</cite>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S5.T4.6.2.19.17.2" style="padding-left:4.0pt;padding-right:4.0pt;">Nine Modalities</th>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.19.17.3" style="padding-left:4.0pt;padding-right:4.0pt;">68.0</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.19.17.4" style="padding-left:4.0pt;padding-right:4.0pt;">77.6</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T4.6.2.19.17.5" style="padding-left:4.0pt;padding-right:4.0pt;">83.8</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.19.17.6" style="padding-left:4.0pt;padding-right:4.0pt;">63.9</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.19.17.7" style="padding-left:4.0pt;padding-right:4.0pt;">65.8</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T4.6.2.19.17.8" style="padding-left:4.0pt;padding-right:4.0pt;">67.2</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.19.17.9" style="padding-left:4.0pt;padding-right:4.0pt;">90.2</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.19.17.10" style="padding-left:4.0pt;padding-right:4.0pt;">91.4</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T4.6.2.19.17.11" style="padding-left:4.0pt;padding-right:4.0pt;">91.8</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.19.17.12" style="padding-left:4.0pt;padding-right:4.0pt;">50.0</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.19.17.13" style="padding-left:4.0pt;padding-right:4.0pt;">56.6</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T4.6.2.19.17.14" style="padding-left:4.0pt;padding-right:4.0pt;">58.6</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.19.17.15" style="padding-left:4.0pt;padding-right:4.0pt;">54.6</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.19.17.16" style="padding-left:4.0pt;padding-right:4.0pt;">63.0</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T4.6.2.19.17.17" style="padding-left:4.0pt;padding-right:4.0pt;">64.5</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.19.17.18" style="padding-left:4.0pt;padding-right:4.0pt;">76.3</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.19.17.19" style="padding-left:4.0pt;padding-right:4.0pt;">81.3</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.19.17.20" style="padding-left:4.0pt;padding-right:4.0pt;">82.9</td>
</tr>
<tr class="ltx_tr" id="S5.T4.6.2.20.18">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S5.T4.6.2.20.18.1" style="padding-left:4.0pt;padding-right:4.0pt;">DoDNet <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib12" title="">12</a>]</cite>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S5.T4.6.2.20.18.2" style="padding-left:4.0pt;padding-right:4.0pt;">Nine Modalities</th>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.20.18.3" style="padding-left:4.0pt;padding-right:4.0pt;">70.9</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.20.18.4" style="padding-left:4.0pt;padding-right:4.0pt;">78.9</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T4.6.2.20.18.5" style="padding-left:4.0pt;padding-right:4.0pt;">83.8</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.20.18.6" style="padding-left:4.0pt;padding-right:4.0pt;">67.9</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.20.18.7" style="padding-left:4.0pt;padding-right:4.0pt;">71.3</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T4.6.2.20.18.8" style="padding-left:4.0pt;padding-right:4.0pt;">71.9</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.20.18.9" style="padding-left:4.0pt;padding-right:4.0pt;">91.7</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.20.18.10" style="padding-left:4.0pt;padding-right:4.0pt;">92.1</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T4.6.2.20.18.11" style="padding-left:4.0pt;padding-right:4.0pt;">93.0</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.20.18.12" style="padding-left:4.0pt;padding-right:4.0pt;">48.8</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.20.18.13" style="padding-left:4.0pt;padding-right:4.0pt;">56.3</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T4.6.2.20.18.14" style="padding-left:4.0pt;padding-right:4.0pt;">58.8</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.20.18.15" style="padding-left:4.0pt;padding-right:4.0pt;">54.6</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.20.18.16" style="padding-left:4.0pt;padding-right:4.0pt;">62.8</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T4.6.2.20.18.17" style="padding-left:4.0pt;padding-right:4.0pt;">64.2</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.20.18.18" style="padding-left:4.0pt;padding-right:4.0pt;">77.3</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.20.18.19" style="padding-left:4.0pt;padding-right:4.0pt;">81.8</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.20.18.20" style="padding-left:4.0pt;padding-right:4.0pt;">83.0</td>
</tr>
<tr class="ltx_tr" id="S5.T4.6.2.21.19">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S5.T4.6.2.21.19.1" style="padding-left:4.0pt;padding-right:4.0pt;">CCQ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib17" title="">17</a>]</cite>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S5.T4.6.2.21.19.2" style="padding-left:4.0pt;padding-right:4.0pt;">Nine Modalities</th>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.21.19.3" style="padding-left:4.0pt;padding-right:4.0pt;">70.9</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.21.19.4" style="padding-left:4.0pt;padding-right:4.0pt;">79.4</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T4.6.2.21.19.5" style="padding-left:4.0pt;padding-right:4.0pt;">84.1</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.21.19.6" style="padding-left:4.0pt;padding-right:4.0pt;">67.5</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.21.19.7" style="padding-left:4.0pt;padding-right:4.0pt;">69.1</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T4.6.2.21.19.8" style="padding-left:4.0pt;padding-right:4.0pt;">71.9</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.21.19.9" style="padding-left:4.0pt;padding-right:4.0pt;">91.6</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.21.19.10" style="padding-left:4.0pt;padding-right:4.0pt;">92.0</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T4.6.2.21.19.11" style="padding-left:4.0pt;padding-right:4.0pt;">92.2</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.21.19.12" style="padding-left:4.0pt;padding-right:4.0pt;">49.8</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.21.19.13" style="padding-left:4.0pt;padding-right:4.0pt;">56.6</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T4.6.2.21.19.14" style="padding-left:4.0pt;padding-right:4.0pt;">58.9</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.21.19.15" style="padding-left:4.0pt;padding-right:4.0pt;">54.0</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.21.19.16" style="padding-left:4.0pt;padding-right:4.0pt;">62.8</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T4.6.2.21.19.17" style="padding-left:4.0pt;padding-right:4.0pt;">64.1</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.21.19.18" style="padding-left:4.0pt;padding-right:4.0pt;">77.6</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.21.19.19" style="padding-left:4.0pt;padding-right:4.0pt;">81.9</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.21.19.20" style="padding-left:4.0pt;padding-right:4.0pt;">83.1</td>
</tr>
<tr class="ltx_tr" id="S5.T4.6.2.22.20">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S5.T4.6.2.22.20.1" style="padding-left:4.0pt;padding-right:4.0pt;">UniSeg <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib16" title="">16</a>]</cite>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S5.T4.6.2.22.20.2" style="padding-left:4.0pt;padding-right:4.0pt;">Nine Modalities</th>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.22.20.3" style="padding-left:4.0pt;padding-right:4.0pt;">71.4</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.22.20.4" style="padding-left:4.0pt;padding-right:4.0pt;">79.5</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T4.6.2.22.20.5" style="padding-left:4.0pt;padding-right:4.0pt;">84.4</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.22.20.6" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="S5.T4.6.2.22.20.6.1">69.1</span></td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.22.20.7" style="padding-left:4.0pt;padding-right:4.0pt;">71.5</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T4.6.2.22.20.8" style="padding-left:4.0pt;padding-right:4.0pt;">72.3</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.22.20.9" style="padding-left:4.0pt;padding-right:4.0pt;">91.7</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.22.20.10" style="padding-left:4.0pt;padding-right:4.0pt;">92.6</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T4.6.2.22.20.11" style="padding-left:4.0pt;padding-right:4.0pt;">92.8</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.22.20.12" style="padding-left:4.0pt;padding-right:4.0pt;">51.5</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.22.20.13" style="padding-left:4.0pt;padding-right:4.0pt;">56.7</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T4.6.2.22.20.14" style="padding-left:4.0pt;padding-right:4.0pt;">58.7</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.22.20.15" style="padding-left:4.0pt;padding-right:4.0pt;">55.4</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.22.20.16" style="padding-left:4.0pt;padding-right:4.0pt;">63.2</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T4.6.2.22.20.17" style="padding-left:4.0pt;padding-right:4.0pt;">64.5</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.22.20.18" style="padding-left:4.0pt;padding-right:4.0pt;">78.2</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.22.20.19" style="padding-left:4.0pt;padding-right:4.0pt;">82.3</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.2.22.20.20" style="padding-left:4.0pt;padding-right:4.0pt;">83.3</td>
</tr>
<tr class="ltx_tr" id="S5.T4.6.2.23.21">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r" id="S5.T4.6.2.23.21.1" style="padding-left:4.0pt;padding-right:4.0pt;">MedUniSeg</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r" id="S5.T4.6.2.23.21.2" style="padding-left:4.0pt;padding-right:4.0pt;">Nine Modalities</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T4.6.2.23.21.3" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="S5.T4.6.2.23.21.3.1">71.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T4.6.2.23.21.4" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="S5.T4.6.2.23.21.4.1">80.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S5.T4.6.2.23.21.5" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="S5.T4.6.2.23.21.5.1">84.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T4.6.2.23.21.6" style="padding-left:4.0pt;padding-right:4.0pt;">68.8</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T4.6.2.23.21.7" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="S5.T4.6.2.23.21.7.1">71.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S5.T4.6.2.23.21.8" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="S5.T4.6.2.23.21.8.1">72.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T4.6.2.23.21.9" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="S5.T4.6.2.23.21.9.1">92.3</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T4.6.2.23.21.10" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="S5.T4.6.2.23.21.10.1">93.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S5.T4.6.2.23.21.11" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="S5.T4.6.2.23.21.11.1">94.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T4.6.2.23.21.12" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="S5.T4.6.2.23.21.12.1">52.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T4.6.2.23.21.13" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="S5.T4.6.2.23.21.13.1">57.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S5.T4.6.2.23.21.14" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="S5.T4.6.2.23.21.14.1">59.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T4.6.2.23.21.15" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="S5.T4.6.2.23.21.15.1">55.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T4.6.2.23.21.16" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="S5.T4.6.2.23.21.16.1">63.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S5.T4.6.2.23.21.17" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="S5.T4.6.2.23.21.17.1">64.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T4.6.2.23.21.18" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="S5.T4.6.2.23.21.18.1">78.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T4.6.2.23.21.19" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="S5.T4.6.2.23.21.19.1">82.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T4.6.2.23.21.20" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="S5.T4.6.2.23.21.20.1">83.7</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
<section class="ltx_subsection" id="S5.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3 </span><span class="ltx_text ltx_font_italic" id="S5.SS3.1.1">Comparing to Single-task and Universal Models</span>
</h3>
<div class="ltx_para" id="S5.SS3.p1">
<p class="ltx_p" id="S5.SS3.p1.2">We compared our MedUniSeg with nine single-task models and five universal models. The single-task models include nnFormer <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib76" title="">76</a>]</cite>, MiT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib35" title="">35</a>]</cite>, CoTr <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib77" title="">77</a>]</cite>,Swin UNETR <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib79" title="">79</a>]</cite>, UXNet <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib78" title="">78</a>]</cite>, UCI <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib80" title="">80</a>]</cite>, UKAN <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib26" title="">26</a>]</cite>, U-Mamba (U-Mamba_Bot) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib25" title="">25</a>]</cite>, and nnUNet <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib24" title="">24</a>]</cite>. The universal models consist of Universal Model <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib10" title="">10</a>]</cite>, Hermes <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib18" title="">18</a>]</cite>, DoDNet <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib12" title="">12</a>]</cite>, CCQ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib17" title="">17</a>]</cite>, and UniSeg <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib16" title="">16</a>]</cite>. For single-task models, each dataset was used for individual model training, employing both 3D and 2D versions to address corresponding tasks. To ensure a fair comparison, all single-task models were trained for a maximum of 1,000 epochs, each containing 50 iterations. The patch size for these models was <math alttext="64\times 192\times 192" class="ltx_Math" display="inline" id="S5.SS3.p1.1.m1.1"><semantics id="S5.SS3.p1.1.m1.1a"><mrow id="S5.SS3.p1.1.m1.1.1" xref="S5.SS3.p1.1.m1.1.1.cmml"><mn id="S5.SS3.p1.1.m1.1.1.2" xref="S5.SS3.p1.1.m1.1.1.2.cmml">64</mn><mo id="S5.SS3.p1.1.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="S5.SS3.p1.1.m1.1.1.1.cmml">×</mo><mn id="S5.SS3.p1.1.m1.1.1.3" xref="S5.SS3.p1.1.m1.1.1.3.cmml">192</mn><mo id="S5.SS3.p1.1.m1.1.1.1a" lspace="0.222em" rspace="0.222em" xref="S5.SS3.p1.1.m1.1.1.1.cmml">×</mo><mn id="S5.SS3.p1.1.m1.1.1.4" xref="S5.SS3.p1.1.m1.1.1.4.cmml">192</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.p1.1.m1.1b"><apply id="S5.SS3.p1.1.m1.1.1.cmml" xref="S5.SS3.p1.1.m1.1.1"><times id="S5.SS3.p1.1.m1.1.1.1.cmml" xref="S5.SS3.p1.1.m1.1.1.1"></times><cn id="S5.SS3.p1.1.m1.1.1.2.cmml" type="integer" xref="S5.SS3.p1.1.m1.1.1.2">64</cn><cn id="S5.SS3.p1.1.m1.1.1.3.cmml" type="integer" xref="S5.SS3.p1.1.m1.1.1.3">192</cn><cn id="S5.SS3.p1.1.m1.1.1.4.cmml" type="integer" xref="S5.SS3.p1.1.m1.1.1.4">192</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p1.1.m1.1c">64\times 192\times 192</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.p1.1.m1.1d">64 × 192 × 192</annotation></semantics></math> for 3D data and <math alttext="512\times 512" class="ltx_Math" display="inline" id="S5.SS3.p1.2.m2.1"><semantics id="S5.SS3.p1.2.m2.1a"><mrow id="S5.SS3.p1.2.m2.1.1" xref="S5.SS3.p1.2.m2.1.1.cmml"><mn id="S5.SS3.p1.2.m2.1.1.2" xref="S5.SS3.p1.2.m2.1.1.2.cmml">512</mn><mo id="S5.SS3.p1.2.m2.1.1.1" lspace="0.222em" rspace="0.222em" xref="S5.SS3.p1.2.m2.1.1.1.cmml">×</mo><mn id="S5.SS3.p1.2.m2.1.1.3" xref="S5.SS3.p1.2.m2.1.1.3.cmml">512</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.p1.2.m2.1b"><apply id="S5.SS3.p1.2.m2.1.1.cmml" xref="S5.SS3.p1.2.m2.1.1"><times id="S5.SS3.p1.2.m2.1.1.1.cmml" xref="S5.SS3.p1.2.m2.1.1.1"></times><cn id="S5.SS3.p1.2.m2.1.1.2.cmml" type="integer" xref="S5.SS3.p1.2.m2.1.1.2">512</cn><cn id="S5.SS3.p1.2.m2.1.1.3.cmml" type="integer" xref="S5.SS3.p1.2.m2.1.1.3">512</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p1.2.m2.1c">512\times 512</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.p1.2.m2.1d">512 × 512</annotation></semantics></math> for 2D data. The backbones of the competing universal models and our MedUniSeg remained consistent across comparisons. All models were trained from scratch.</p>
</div>
<figure class="ltx_figure" id="S5.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="134" id="S5.F3.g1" src="x3.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Schematic representation of MedUniSeg, UniSeg, Multiple Prompts, Universal Prompts, Fixed Prompts, Bottleneck Prompts, and MedUniSeg-T. Multiple Prompts utilizes multiple task-specific and modal-specific prompts. Universal Prompts adopts a universal modal prompt and a universal task prompt. Fixed Prompts initializes with zero prompts, remaining unchanged. Bottleneck Prompts incorporates both priors at the bottleneck of the encoder. MedUniSeg-T introduces the task-related prompt at the end of the decoder. The selection and fusion (SEFU) module first selects a modal-specific prompt and then fuses the features with the prompt. The <math alttext="Sel." class="ltx_Math" display="inline" id="S5.F3.2.m1.1"><semantics id="S5.F3.2.m1.1b"><mrow id="S5.F3.2.m1.1.1.1" xref="S5.F3.2.m1.1.1.1.1.cmml"><mrow id="S5.F3.2.m1.1.1.1.1" xref="S5.F3.2.m1.1.1.1.1.cmml"><mi id="S5.F3.2.m1.1.1.1.1.2" xref="S5.F3.2.m1.1.1.1.1.2.cmml">S</mi><mo id="S5.F3.2.m1.1.1.1.1.1" xref="S5.F3.2.m1.1.1.1.1.1.cmml">⁢</mo><mi id="S5.F3.2.m1.1.1.1.1.3" xref="S5.F3.2.m1.1.1.1.1.3.cmml">e</mi><mo id="S5.F3.2.m1.1.1.1.1.1b" xref="S5.F3.2.m1.1.1.1.1.1.cmml">⁢</mo><mi id="S5.F3.2.m1.1.1.1.1.4" xref="S5.F3.2.m1.1.1.1.1.4.cmml">l</mi></mrow><mo id="S5.F3.2.m1.1.1.1.2" lspace="0em" xref="S5.F3.2.m1.1.1.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.F3.2.m1.1c"><apply id="S5.F3.2.m1.1.1.1.1.cmml" xref="S5.F3.2.m1.1.1.1"><times id="S5.F3.2.m1.1.1.1.1.1.cmml" xref="S5.F3.2.m1.1.1.1.1.1"></times><ci id="S5.F3.2.m1.1.1.1.1.2.cmml" xref="S5.F3.2.m1.1.1.1.1.2">𝑆</ci><ci id="S5.F3.2.m1.1.1.1.1.3.cmml" xref="S5.F3.2.m1.1.1.1.1.3">𝑒</ci><ci id="S5.F3.2.m1.1.1.1.1.4.cmml" xref="S5.F3.2.m1.1.1.1.1.4">𝑙</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.F3.2.m1.1d">Sel.</annotation><annotation encoding="application/x-llamapun" id="S5.F3.2.m1.1e">italic_S italic_e italic_l .</annotation></semantics></math> operation is used to extract the modal-specific prior from the universal prompt generated by the MMap module. Task-related information is highlighted in purple, while modal-related information is highlighted in green.
</figcaption>
</figure>
<figure class="ltx_table" id="S5.T5">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE V: </span>Performance of baseline, six variants, and our MedUniSeg. The baseline refers to our encoder-decoder backbone trained independently on each dataset. We compare the 3D mean Dice (%), 2D mean Dice (%), and mean Dice (%) across all models.</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S5.T5.1" style="width:867.2pt;height:103.2pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(131.1pt,-15.6pt) scale(1.43351772816527,1.43351772816527) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S5.T5.1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S5.T5.1.1.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T5.1.1.1.1.1" style="padding-left:4.0pt;padding-right:4.0pt;">Method</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T5.1.1.1.1.2" style="padding-left:4.0pt;padding-right:4.0pt;">Baseline</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T5.1.1.1.1.3" style="padding-left:4.0pt;padding-right:4.0pt;">UniSeg</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T5.1.1.1.1.4" style="padding-left:4.0pt;padding-right:4.0pt;">Multiple Prompts</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T5.1.1.1.1.5" style="padding-left:4.0pt;padding-right:4.0pt;">Universal Prompts</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T5.1.1.1.1.6" style="padding-left:4.0pt;padding-right:4.0pt;">Fixed Prompts</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T5.1.1.1.1.7" style="padding-left:4.0pt;padding-right:4.0pt;">Bottleneck Prompts</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T5.1.1.1.1.8" style="padding-left:4.0pt;padding-right:4.0pt;">MedUniSeg-T</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T5.1.1.1.1.9" style="padding-left:4.0pt;padding-right:4.0pt;">MedUniSeg</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T5.1.1.2.1">
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T5.1.1.2.1.1" style="padding-left:4.0pt;padding-right:4.0pt;">3D Mean</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T5.1.1.2.1.2" style="padding-left:4.0pt;padding-right:4.0pt;">76.6</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T5.1.1.2.1.3" style="padding-left:4.0pt;padding-right:4.0pt;">77.5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T5.1.1.2.1.4" style="padding-left:4.0pt;padding-right:4.0pt;">77.1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T5.1.1.2.1.5" style="padding-left:4.0pt;padding-right:4.0pt;">76.6</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T5.1.1.2.1.6" style="padding-left:4.0pt;padding-right:4.0pt;">77.5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T5.1.1.2.1.7" style="padding-left:4.0pt;padding-right:4.0pt;">77.7</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T5.1.1.2.1.8" style="padding-left:4.0pt;padding-right:4.0pt;">77.2</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T5.1.1.2.1.9" style="padding-left:4.0pt;padding-right:4.0pt;">78.1</td>
</tr>
<tr class="ltx_tr" id="S5.T5.1.1.3.2">
<td class="ltx_td ltx_align_center" id="S5.T5.1.1.3.2.1" style="padding-left:4.0pt;padding-right:4.0pt;">2D Mean</td>
<td class="ltx_td ltx_align_center" id="S5.T5.1.1.3.2.2" style="padding-left:4.0pt;padding-right:4.0pt;">84.4</td>
<td class="ltx_td ltx_align_center" id="S5.T5.1.1.3.2.3" style="padding-left:4.0pt;padding-right:4.0pt;">84.3</td>
<td class="ltx_td ltx_align_center" id="S5.T5.1.1.3.2.4" style="padding-left:4.0pt;padding-right:4.0pt;">84.8</td>
<td class="ltx_td ltx_align_center" id="S5.T5.1.1.3.2.5" style="padding-left:4.0pt;padding-right:4.0pt;">84.9</td>
<td class="ltx_td ltx_align_center" id="S5.T5.1.1.3.2.6" style="padding-left:4.0pt;padding-right:4.0pt;">84.4</td>
<td class="ltx_td ltx_align_center" id="S5.T5.1.1.3.2.7" style="padding-left:4.0pt;padding-right:4.0pt;">84.4</td>
<td class="ltx_td ltx_align_center" id="S5.T5.1.1.3.2.8" style="padding-left:4.0pt;padding-right:4.0pt;">84.4</td>
<td class="ltx_td ltx_align_center" id="S5.T5.1.1.3.2.9" style="padding-left:4.0pt;padding-right:4.0pt;">84.8</td>
</tr>
<tr class="ltx_tr" id="S5.T5.1.1.4.3">
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T5.1.1.4.3.1" style="padding-left:4.0pt;padding-right:4.0pt;">Mean</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T5.1.1.4.3.2" style="padding-left:4.0pt;padding-right:4.0pt;">79.3</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T5.1.1.4.3.3" style="padding-left:4.0pt;padding-right:4.0pt;">79.9</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T5.1.1.4.3.4" style="padding-left:4.0pt;padding-right:4.0pt;">79.8</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T5.1.1.4.3.5" style="padding-left:4.0pt;padding-right:4.0pt;">79.5</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T5.1.1.4.3.6" style="padding-left:4.0pt;padding-right:4.0pt;">79.9</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T5.1.1.4.3.7" style="padding-left:4.0pt;padding-right:4.0pt;">80.1</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T5.1.1.4.3.8" style="padding-left:4.0pt;padding-right:4.0pt;">79.7</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T5.1.1.4.3.9" style="padding-left:4.0pt;padding-right:4.0pt;">80.5</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div class="ltx_para" id="S5.SS3.p2">
<p class="ltx_p" id="S5.SS3.p2.2">The results presented in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#S5.T3" title="TABLE III ‣ 5.2 Evaluation Metrics ‣ 5 Experiments ‣ MedUniSeg: 2D and 3D Medical Image Segmentation via a Prompt-driven Universal Model"><span class="ltx_text ltx_ref_tag">III</span></a> lead to two main conclusions:
First, Transformer-based methods, such as nnFormer, MiT, Swin UNETR, UXNet, and UCI, generally underperform compared to CNN-based methods like nnUNet in segmentation tasks, particularly for 3D data. This observation prompted us to favor a pure CNN-based model for both 2D and 3D universal segmentation over Transformer-based models.
Additionally, nnUNet and U-Mamba demonstrated superior generalization performance compared to other single-task models, with a 0.7% improvement in average performance over the third-best model, UKAN. Considering both performance and model size (U-Mamba: <math alttext="\sim" class="ltx_Math" display="inline" id="S5.SS3.p2.1.m1.1"><semantics id="S5.SS3.p2.1.m1.1a"><mo id="S5.SS3.p2.1.m1.1.1" xref="S5.SS3.p2.1.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S5.SS3.p2.1.m1.1b"><csymbol cd="latexml" id="S5.SS3.p2.1.m1.1.1.cmml" xref="S5.SS3.p2.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p2.1.m1.1c">\sim</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.p2.1.m1.1d">∼</annotation></semantics></math>48.2M vs. nnUNet: <math alttext="\sim" class="ltx_Math" display="inline" id="S5.SS3.p2.2.m2.1"><semantics id="S5.SS3.p2.2.m2.1a"><mo id="S5.SS3.p2.2.m2.1.1" xref="S5.SS3.p2.2.m2.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S5.SS3.p2.2.m2.1b"><csymbol cd="latexml" id="S5.SS3.p2.2.m2.1.1.cmml" xref="S5.SS3.p2.2.m2.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p2.2.m2.1c">\sim</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.p2.2.m2.1d">∼</annotation></semantics></math>31.2M), nnUNet was selected as the backbone for the universal models.
Second, the increasing challenge of addressing segmentation tasks over various modalities, regions, and domains revealed that recent advanced universal models often struggle to achieve satisfactory performance, typically scoring lower average Dice scores than the baseline, <span class="ltx_text ltx_font_italic" id="S5.SS3.p2.2.1">i.e.</span>, nnUNet.
In contrast, our UniSeg and MedUniSeg models demonstrate improved performance, achieving mean Dice score increases of 0.6% and 1.2% over the baseline, respectively. Furthermore, MedUniSeg attains a 1.5% improvement for 3D tasks and 0.4% for 2D tasks.
In summary, our MedUniSeg achieves the best generalization performance across 17 segmentation tasks, effectively addressing multiple tasks with a single model while consistently outperforming its baseline on most tasks.</p>
</div>
<figure class="ltx_figure" id="S5.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="587" id="S5.F4.g1" src="x4.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Visualization of segmentation results obtained from UKAN, UMamba, nnUNet, Universal Model, Hermes, DoDNet, CCQ, UniSeg, and MedUniSeg, along with the ground truths (GTs) on seven datasets. Organs are depicted in red, while tumors and lesions are shown in green. Blue rectangles highlight the differences among the models.
</figcaption>
</figure>
<figure class="ltx_figure" id="S5.F5"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="547" id="S5.F5.g1" src="x5.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Visualization of segmentation results obtained from Swin UNETR, BT, UniMiSS, DeSD, Universal Model, Universal Model<math alttext="{\dagger}" class="ltx_Math" display="inline" id="S5.F5.2.m1.1"><semantics id="S5.F5.2.m1.1b"><mo id="S5.F5.2.m1.1.1" xref="S5.F5.2.m1.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="S5.F5.2.m1.1c"><ci id="S5.F5.2.m1.1.1.cmml" xref="S5.F5.2.m1.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.F5.2.m1.1d">{\dagger}</annotation><annotation encoding="application/x-llamapun" id="S5.F5.2.m1.1e">†</annotation></semantics></math>, Hermes, DoDNet, CCQ, UniSeg, and MedUniSeg, along with the ground truths (GTs) on six datasets. Blue rectangles highlight the differences among the models.
</figcaption>
</figure>
<figure class="ltx_figure" id="S5.F6"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="744" id="S5.F6.g1" src="x6.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>T-SNE of 17 task-specific priors, illustrating the distributions among the tasks.
</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S5.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.4 </span><span class="ltx_text ltx_font_italic" id="S5.SS4.1.1">Performance Improvement using LoRA</span>
</h3>
<div class="ltx_para" id="S5.SS4.p1">
<p class="ltx_p" id="S5.SS4.p1.1">Table <a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#S5.T3" title="TABLE III ‣ 5.2 Evaluation Metrics ‣ 5 Experiments ‣ MedUniSeg: 2D and 3D Medical Image Segmentation via a Prompt-driven Universal Model"><span class="ltx_text ltx_ref_tag">III</span></a> shows that MedUniSeg generally outperforms the baseline nnUNet but slightly underperforms on five tasks: Kidney, VerSe20, BraTS21, QaTav2, and Polyp.
To address these performance gaps, we enhanced MedUniSeg by freezing the trained models and integrating learnable LoRA modules into convolutional layers. The rank and alpha were set to 32 and 64, respectively.
Moreover, we introduced new deconvolutional layers and segmentation heads to produce residual outputs. This modified model, referred to as MedUniSeg*, was retrained on the five under-performing tasks, updating only the newly added modules. All other configurations, such as 1000 epochs and 50 iterations per epoch, remain consistent with the upstream training. As shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#S5.T3" title="TABLE III ‣ 5.2 Evaluation Metrics ‣ 5 Experiments ‣ MedUniSeg: 2D and 3D Medical Image Segmentation via a Prompt-driven Universal Model"><span class="ltx_text ltx_ref_tag">III</span></a>, MedUniSeg* demonstrates performance improvements over MedUniSeg on all five tasks, with Dice score gains of 2.1%, 0.5%, 0.9%, 1.1%, and 0.6%, respectively, while increasing the parameter count by approximately 6.8M. Furthermore, when comparing MedUniSeg* to nnUNet, MedUniSeg* outperforms nnUNet on 14 tasks, matches its performance on one task, and shows slightly lower performance on only two tasks.</p>
</div>
<figure class="ltx_table" id="S5.T6">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE VI: </span>Results of the FUSE module with varying block numbers and channel numbers. Here, <math alttext="\#Bi" class="ltx_Math" display="inline" id="S5.T6.5.m1.1"><semantics id="S5.T6.5.m1.1b"><mrow id="S5.T6.5.m1.1.1" xref="S5.T6.5.m1.1.1.cmml"><mi id="S5.T6.5.m1.1.1.2" mathvariant="normal" xref="S5.T6.5.m1.1.1.2.cmml">#</mi><mo id="S5.T6.5.m1.1.1.1" xref="S5.T6.5.m1.1.1.1.cmml">⁢</mo><mi id="S5.T6.5.m1.1.1.3" xref="S5.T6.5.m1.1.1.3.cmml">B</mi><mo id="S5.T6.5.m1.1.1.1b" xref="S5.T6.5.m1.1.1.1.cmml">⁢</mo><mi id="S5.T6.5.m1.1.1.4" xref="S5.T6.5.m1.1.1.4.cmml">i</mi></mrow><annotation-xml encoding="MathML-Content" id="S5.T6.5.m1.1c"><apply id="S5.T6.5.m1.1.1.cmml" xref="S5.T6.5.m1.1.1"><times id="S5.T6.5.m1.1.1.1.cmml" xref="S5.T6.5.m1.1.1.1"></times><ci id="S5.T6.5.m1.1.1.2.cmml" xref="S5.T6.5.m1.1.1.2">#</ci><ci id="S5.T6.5.m1.1.1.3.cmml" xref="S5.T6.5.m1.1.1.3">𝐵</ci><ci id="S5.T6.5.m1.1.1.4.cmml" xref="S5.T6.5.m1.1.1.4">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T6.5.m1.1d">\#Bi</annotation><annotation encoding="application/x-llamapun" id="S5.T6.5.m1.1e"># italic_B italic_i</annotation></semantics></math> means the FUSE module with <math alttext="i" class="ltx_Math" display="inline" id="S5.T6.6.m2.1"><semantics id="S5.T6.6.m2.1b"><mi id="S5.T6.6.m2.1.1" xref="S5.T6.6.m2.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S5.T6.6.m2.1c"><ci id="S5.T6.6.m2.1.1.cmml" xref="S5.T6.6.m2.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T6.6.m2.1d">i</annotation><annotation encoding="application/x-llamapun" id="S5.T6.6.m2.1e">italic_i</annotation></semantics></math> blocks, while <math alttext="Ci" class="ltx_Math" display="inline" id="S5.T6.7.m3.1"><semantics id="S5.T6.7.m3.1b"><mrow id="S5.T6.7.m3.1.1" xref="S5.T6.7.m3.1.1.cmml"><mi id="S5.T6.7.m3.1.1.2" xref="S5.T6.7.m3.1.1.2.cmml">C</mi><mo id="S5.T6.7.m3.1.1.1" xref="S5.T6.7.m3.1.1.1.cmml">⁢</mo><mi id="S5.T6.7.m3.1.1.3" xref="S5.T6.7.m3.1.1.3.cmml">i</mi></mrow><annotation-xml encoding="MathML-Content" id="S5.T6.7.m3.1c"><apply id="S5.T6.7.m3.1.1.cmml" xref="S5.T6.7.m3.1.1"><times id="S5.T6.7.m3.1.1.1.cmml" xref="S5.T6.7.m3.1.1.1"></times><ci id="S5.T6.7.m3.1.1.2.cmml" xref="S5.T6.7.m3.1.1.2">𝐶</ci><ci id="S5.T6.7.m3.1.1.3.cmml" xref="S5.T6.7.m3.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T6.7.m3.1d">Ci</annotation><annotation encoding="application/x-llamapun" id="S5.T6.7.m3.1e">italic_C italic_i</annotation></semantics></math> indicates that the middle layer of the FUSE module reduces the channel count to <math alttext="1/i" class="ltx_Math" display="inline" id="S5.T6.8.m4.1"><semantics id="S5.T6.8.m4.1b"><mrow id="S5.T6.8.m4.1.1" xref="S5.T6.8.m4.1.1.cmml"><mn id="S5.T6.8.m4.1.1.2" xref="S5.T6.8.m4.1.1.2.cmml">1</mn><mo id="S5.T6.8.m4.1.1.1" xref="S5.T6.8.m4.1.1.1.cmml">/</mo><mi id="S5.T6.8.m4.1.1.3" xref="S5.T6.8.m4.1.1.3.cmml">i</mi></mrow><annotation-xml encoding="MathML-Content" id="S5.T6.8.m4.1c"><apply id="S5.T6.8.m4.1.1.cmml" xref="S5.T6.8.m4.1.1"><divide id="S5.T6.8.m4.1.1.1.cmml" xref="S5.T6.8.m4.1.1.1"></divide><cn id="S5.T6.8.m4.1.1.2.cmml" type="integer" xref="S5.T6.8.m4.1.1.2">1</cn><ci id="S5.T6.8.m4.1.1.3.cmml" xref="S5.T6.8.m4.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T6.8.m4.1d">1/i</annotation><annotation encoding="application/x-llamapun" id="S5.T6.8.m4.1e">1 / italic_i</annotation></semantics></math> of the original. The best results are highlighted in bold.</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S5.T6.9" style="width:867.2pt;height:114.6pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(161.3pt,-21.3pt) scale(1.59231829130203,1.59231829130203) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S5.T6.9.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S5.T6.9.1.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T6.9.1.1.1.1">Method</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T6.9.1.1.1.2">#B1</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T6.9.1.1.1.3">#B2, C4</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T6.9.1.1.1.4">#B3, C4</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T6.9.1.1.1.5">#B4, C4</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="S5.T6.9.1.1.1.6">#B5, C4</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T6.9.1.1.1.7">#B3, C1</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T6.9.1.1.1.8">#B3, C2</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T6.9.1.1.1.9">#B3, C3</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T6.9.1.1.1.10">#B3, C4</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T6.9.1.1.1.11">#B3, C5</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T6.9.1.2.1">
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T6.9.1.2.1.1">3D Mean</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T6.9.1.2.1.2">76.8</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T6.9.1.2.1.3">77.4</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T6.9.1.2.1.4"><span class="ltx_text ltx_font_bold" id="S5.T6.9.1.2.1.4.1">78.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T6.9.1.2.1.5">76.6</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T6.9.1.2.1.6">77.6</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T6.9.1.2.1.7">77.6</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T6.9.1.2.1.8">78.2</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T6.9.1.2.1.9">77.1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T6.9.1.2.1.10"><span class="ltx_text ltx_font_bold" id="S5.T6.9.1.2.1.10.1">78.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T6.9.1.2.1.11">76.8</td>
</tr>
<tr class="ltx_tr" id="S5.T6.9.1.3.2">
<td class="ltx_td ltx_align_center" id="S5.T6.9.1.3.2.1">2D Mean</td>
<td class="ltx_td ltx_align_center" id="S5.T6.9.1.3.2.2">85.0</td>
<td class="ltx_td ltx_align_center" id="S5.T6.9.1.3.2.3">85.0</td>
<td class="ltx_td ltx_align_center" id="S5.T6.9.1.3.2.4">84.8</td>
<td class="ltx_td ltx_align_center" id="S5.T6.9.1.3.2.5">84.7</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T6.9.1.3.2.6">84.9</td>
<td class="ltx_td ltx_align_center" id="S5.T6.9.1.3.2.7">84.5</td>
<td class="ltx_td ltx_align_center" id="S5.T6.9.1.3.2.8">84.6</td>
<td class="ltx_td ltx_align_center" id="S5.T6.9.1.3.2.9"><span class="ltx_text ltx_font_bold" id="S5.T6.9.1.3.2.9.1">85.1</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.9.1.3.2.10">84.8</td>
<td class="ltx_td ltx_align_center" id="S5.T6.9.1.3.2.11">84.5</td>
</tr>
<tr class="ltx_tr" id="S5.T6.9.1.4.3">
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T6.9.1.4.3.1">Mean</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T6.9.1.4.3.2">79.7</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T6.9.1.4.3.3">80.1</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T6.9.1.4.3.4"><span class="ltx_text ltx_font_bold" id="S5.T6.9.1.4.3.4.1">80.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T6.9.1.4.3.5">79.5</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S5.T6.9.1.4.3.6">80.2</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T6.9.1.4.3.7">80.0</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T6.9.1.4.3.8">80.5</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T6.9.1.4.3.9">79.9</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T6.9.1.4.3.10"><span class="ltx_text ltx_font_bold" id="S5.T6.9.1.4.3.10.1">80.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T6.9.1.4.3.11">79.5</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<figure class="ltx_table" id="S5.T7">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">TABLE VII: </span>Results of the modal-specific and universal task prompts with varying shapes. The best results are highlighted in bold.</figcaption>
<div class="ltx_inline-block ltx_transformed_outer" id="S5.T7.2" style="width:433.6pt;height:91.7pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(4.0pt,-0.8pt) scale(1.01859380338458,1.01859380338458) ;">
<table class="ltx_tabular ltx_align_middle" id="S5.T7.2.2">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T7.2.2.2">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S5.T7.2.2.2.3" rowspan="2"><span class="ltx_text" id="S5.T7.2.2.2.3.1">Prompt Shape</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="6" id="S5.T7.1.1.1.1">Modal Prompts (<math alttext="l" class="ltx_Math" display="inline" id="S5.T7.1.1.1.1.m1.1"><semantics id="S5.T7.1.1.1.1.m1.1a"><mi id="S5.T7.1.1.1.1.m1.1.1" xref="S5.T7.1.1.1.1.m1.1.1.cmml">l</mi><annotation-xml encoding="MathML-Content" id="S5.T7.1.1.1.1.m1.1b"><ci id="S5.T7.1.1.1.1.m1.1.1.cmml" xref="S5.T7.1.1.1.1.m1.1.1">𝑙</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T7.1.1.1.1.m1.1c">l</annotation><annotation encoding="application/x-llamapun" id="S5.T7.1.1.1.1.m1.1d">italic_l</annotation></semantics></math>)</td>
<td class="ltx_td ltx_align_center ltx_align_top ltx_border_tt" colspan="3" id="S5.T7.2.2.2.2">Universal Task Prompt (<math alttext="K\times 4\times 6\times 6" class="ltx_Math" display="inline" id="S5.T7.2.2.2.2.m1.1"><semantics id="S5.T7.2.2.2.2.m1.1a"><mrow id="S5.T7.2.2.2.2.m1.1.1" xref="S5.T7.2.2.2.2.m1.1.1.cmml"><mi id="S5.T7.2.2.2.2.m1.1.1.2" xref="S5.T7.2.2.2.2.m1.1.1.2.cmml">K</mi><mo id="S5.T7.2.2.2.2.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="S5.T7.2.2.2.2.m1.1.1.1.cmml">×</mo><mn id="S5.T7.2.2.2.2.m1.1.1.3" xref="S5.T7.2.2.2.2.m1.1.1.3.cmml">4</mn><mo id="S5.T7.2.2.2.2.m1.1.1.1a" lspace="0.222em" rspace="0.222em" xref="S5.T7.2.2.2.2.m1.1.1.1.cmml">×</mo><mn id="S5.T7.2.2.2.2.m1.1.1.4" xref="S5.T7.2.2.2.2.m1.1.1.4.cmml">6</mn><mo id="S5.T7.2.2.2.2.m1.1.1.1b" lspace="0.222em" rspace="0.222em" xref="S5.T7.2.2.2.2.m1.1.1.1.cmml">×</mo><mn id="S5.T7.2.2.2.2.m1.1.1.5" xref="S5.T7.2.2.2.2.m1.1.1.5.cmml">6</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T7.2.2.2.2.m1.1b"><apply id="S5.T7.2.2.2.2.m1.1.1.cmml" xref="S5.T7.2.2.2.2.m1.1.1"><times id="S5.T7.2.2.2.2.m1.1.1.1.cmml" xref="S5.T7.2.2.2.2.m1.1.1.1"></times><ci id="S5.T7.2.2.2.2.m1.1.1.2.cmml" xref="S5.T7.2.2.2.2.m1.1.1.2">𝐾</ci><cn id="S5.T7.2.2.2.2.m1.1.1.3.cmml" type="integer" xref="S5.T7.2.2.2.2.m1.1.1.3">4</cn><cn id="S5.T7.2.2.2.2.m1.1.1.4.cmml" type="integer" xref="S5.T7.2.2.2.2.m1.1.1.4">6</cn><cn id="S5.T7.2.2.2.2.m1.1.1.5.cmml" type="integer" xref="S5.T7.2.2.2.2.m1.1.1.5">6</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T7.2.2.2.2.m1.1c">K\times 4\times 6\times 6</annotation><annotation encoding="application/x-llamapun" id="S5.T7.2.2.2.2.m1.1d">italic_K × 4 × 6 × 6</annotation></semantics></math>)</td>
</tr>
<tr class="ltx_tr" id="S5.T7.2.2.3.1">
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T7.2.2.3.1.1">256</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T7.2.2.3.1.2">320</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T7.2.2.3.1.3">384</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T7.2.2.3.1.4">512</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T7.2.2.3.1.5">1024</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T7.2.2.3.1.6">2048</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S5.T7.2.2.3.1.7">
<span class="ltx_inline-block ltx_align_top" id="S5.T7.2.2.3.1.7.1">
<span class="ltx_p" id="S5.T7.2.2.3.1.7.1.1" style="width:42.7pt;">50</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S5.T7.2.2.3.1.8">
<span class="ltx_inline-block ltx_align_top" id="S5.T7.2.2.3.1.8.1">
<span class="ltx_p" id="S5.T7.2.2.3.1.8.1.1" style="width:42.7pt;">100</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S5.T7.2.2.3.1.9">
<span class="ltx_inline-block ltx_align_top" id="S5.T7.2.2.3.1.9.1">
<span class="ltx_p" id="S5.T7.2.2.3.1.9.1.1" style="width:42.7pt;">200</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S5.T7.2.2.4.2">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T7.2.2.4.2.1">3D Mean</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T7.2.2.4.2.2">77.4</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T7.2.2.4.2.3">76.9</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T7.2.2.4.2.4">77.4</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T7.2.2.4.2.5"><span class="ltx_text ltx_font_bold" id="S5.T7.2.2.4.2.5.1">78.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T7.2.2.4.2.6">77.9</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T7.2.2.4.2.7">77.9</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S5.T7.2.2.4.2.8">
<span class="ltx_inline-block ltx_align_top" id="S5.T7.2.2.4.2.8.1">
<span class="ltx_p" id="S5.T7.2.2.4.2.8.1.1" style="width:42.7pt;">77.5</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S5.T7.2.2.4.2.9">
<span class="ltx_inline-block ltx_align_top" id="S5.T7.2.2.4.2.9.1">
<span class="ltx_p" id="S5.T7.2.2.4.2.9.1.1" style="width:42.7pt;"><span class="ltx_text ltx_font_bold" id="S5.T7.2.2.4.2.9.1.1.1">78.1</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S5.T7.2.2.4.2.10">
<span class="ltx_inline-block ltx_align_top" id="S5.T7.2.2.4.2.10.1">
<span class="ltx_p" id="S5.T7.2.2.4.2.10.1.1" style="width:42.7pt;">77.6</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S5.T7.2.2.5.3">
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T7.2.2.5.3.1">2D Mean</td>
<td class="ltx_td ltx_align_center" id="S5.T7.2.2.5.3.2"><span class="ltx_text ltx_font_bold" id="S5.T7.2.2.5.3.2.1">85.1</span></td>
<td class="ltx_td ltx_align_center" id="S5.T7.2.2.5.3.3">84.8</td>
<td class="ltx_td ltx_align_center" id="S5.T7.2.2.5.3.4">84.7</td>
<td class="ltx_td ltx_align_center" id="S5.T7.2.2.5.3.5">84.8</td>
<td class="ltx_td ltx_align_center" id="S5.T7.2.2.5.3.6">84.8</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T7.2.2.5.3.7">84.5</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S5.T7.2.2.5.3.8">
<span class="ltx_inline-block ltx_align_top" id="S5.T7.2.2.5.3.8.1">
<span class="ltx_p" id="S5.T7.2.2.5.3.8.1.1" style="width:42.7pt;">84.6</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S5.T7.2.2.5.3.9">
<span class="ltx_inline-block ltx_align_top" id="S5.T7.2.2.5.3.9.1">
<span class="ltx_p" id="S5.T7.2.2.5.3.9.1.1" style="width:42.7pt;">84.8</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S5.T7.2.2.5.3.10">
<span class="ltx_inline-block ltx_align_top" id="S5.T7.2.2.5.3.10.1">
<span class="ltx_p" id="S5.T7.2.2.5.3.10.1.1" style="width:42.7pt;">84.6</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S5.T7.2.2.6.4">
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S5.T7.2.2.6.4.1">Mean</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T7.2.2.6.4.2">80.2</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T7.2.2.6.4.3">79.7</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T7.2.2.6.4.4">80.0</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T7.2.2.6.4.5"><span class="ltx_text ltx_font_bold" id="S5.T7.2.2.6.4.5.1">80.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T7.2.2.6.4.6">80.4</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S5.T7.2.2.6.4.7">80.2</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" id="S5.T7.2.2.6.4.8">
<span class="ltx_inline-block ltx_align_top" id="S5.T7.2.2.6.4.8.1">
<span class="ltx_p" id="S5.T7.2.2.6.4.8.1.1" style="width:42.7pt;">80.0</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" id="S5.T7.2.2.6.4.9">
<span class="ltx_inline-block ltx_align_top" id="S5.T7.2.2.6.4.9.1">
<span class="ltx_p" id="S5.T7.2.2.6.4.9.1.1" style="width:42.7pt;"><span class="ltx_text ltx_font_bold" id="S5.T7.2.2.6.4.9.1.1.1">80.5</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" id="S5.T7.2.2.6.4.10">
<span class="ltx_inline-block ltx_align_top" id="S5.T7.2.2.6.4.10.1">
<span class="ltx_p" id="S5.T7.2.2.6.4.10.1.1" style="width:42.7pt;">80.0</span>
</span>
</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<figure class="ltx_table" id="S5.T8">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE VIII: </span>Performance of 2D models (<span class="ltx_text ltx_font_italic" id="S5.T8.3.1">i.e.</span>, 2D UniMiSS and 2D Backbone) and 3D models (<span class="ltx_text ltx_font_italic" id="S5.T8.4.2">i.e.</span>, 3D Backbone and MedUniSeg) on the SIIM dataset.</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S5.T8.5" style="width:433.6pt;height:101.7pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(25.0pt,-5.9pt) scale(1.13023899552271,1.13023899552271) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S5.T8.5.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S5.T8.5.1.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="S5.T8.5.1.1.1.1">Method</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T8.5.1.1.1.2">#Param. (M)</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T8.5.1.1.1.3">GPU Mem. (M)</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T8.5.1.1.1.4">Inference Time (s/Image)</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T8.5.1.1.1.5">Dice</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T8.5.1.2.1">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T8.5.1.2.1.1">UniMiSS</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T8.5.1.2.1.2">26.47</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T8.5.1.2.1.3">690</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T8.5.1.2.1.4">0.298</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T8.5.1.2.1.5">54.8</td>
</tr>
<tr class="ltx_tr" id="S5.T8.5.1.3.2">
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T8.5.1.3.2.1">2D Backbone</td>
<td class="ltx_td ltx_align_center" id="S5.T8.5.1.3.2.2">10.71</td>
<td class="ltx_td ltx_align_center" id="S5.T8.5.1.3.2.3">614</td>
<td class="ltx_td ltx_align_center" id="S5.T8.5.1.3.2.4">0.093</td>
<td class="ltx_td ltx_align_center" id="S5.T8.5.1.3.2.5">55.6</td>
</tr>
<tr class="ltx_tr" id="S5.T8.5.1.4.3">
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T8.5.1.4.3.1">3D Backbone</td>
<td class="ltx_td ltx_align_center" id="S5.T8.5.1.4.3.2">31.17</td>
<td class="ltx_td ltx_align_center" id="S5.T8.5.1.4.3.3">880</td>
<td class="ltx_td ltx_align_center" id="S5.T8.5.1.4.3.4">0.171</td>
<td class="ltx_td ltx_align_center" id="S5.T8.5.1.4.3.5">55.7</td>
</tr>
<tr class="ltx_tr" id="S5.T8.5.1.5.4">
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S5.T8.5.1.5.4.1">MedUniSeg</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T8.5.1.5.4.2">31.24</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T8.5.1.5.4.3">938</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T8.5.1.5.4.4">0.173</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T8.5.1.5.4.5">59.8</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
<section class="ltx_subsection" id="S5.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.5 </span><span class="ltx_text ltx_font_italic" id="S5.SS5.1.1">Comparing to Other Pre-trained Models</span>
</h3>
<div class="ltx_para" id="S5.SS5.p1">
<p class="ltx_p" id="S5.SS5.p1.3">To verify the transfer ability of our MedUniSeg, we compared it with recent advanced models, including both self-supervised and supervised models. The self-supervised models include single-modal pre-trained models such as MG <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib81" title="">81</a>]</cite>, GVSL <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib82" title="">82</a>]</cite>, DeSD <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib83" title="">83</a>]</cite>, SMIT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib84" title="">84</a>]</cite>, Swin UNETR <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib79" title="">79</a>]</cite>, VoCo <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib28" title="">28</a>]</cite>, BT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib85" title="">85</a>]</cite>, PCRLv2 (CheXpert) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib86" title="">86</a>]</cite>, and multi-modal pre-trained models like MedKLIP <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib29" title="">29</a>]</cite>, and UniMiSS <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib35" title="">35</a>]</cite>. The supervised models include Universal Model <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib10" title="">10</a>]</cite>, Hermes <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib18" title="">18</a>]</cite>, DoDNet <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib12" title="">12</a>]</cite>, CCQ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib17" title="">17</a>]</cite>, and UniSeg <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib16" title="">16</a>]</cite>. Moreover, we introduced two nnUNet models trained from scratch, one with a 3D backbone (representing MedUniSeg without pre-trained weights) and the other with a 2D backbone, highlighting the improvements gained from pre-training. The 2D backbone was derived from the 3D one by replacing 3D modules with 2D counterparts.
For employing 3D pre-trained models on 2D tasks, similar to upstream training, we treated 2D data as pseudo 3D data.
Models such as SMIT, Swin UNETR, VoCo, and Universal models<math alttext="{\dagger}" class="ltx_Math" display="inline" id="S5.SS5.p1.1.m1.1"><semantics id="S5.SS5.p1.1.m1.1a"><mo id="S5.SS5.p1.1.m1.1.1" xref="S5.SS5.p1.1.m1.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="S5.SS5.p1.1.m1.1b"><ci id="S5.SS5.p1.1.m1.1.1.cmml" xref="S5.SS5.p1.1.m1.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS5.p1.1.m1.1c">{\dagger}</annotation><annotation encoding="application/x-llamapun" id="S5.SS5.p1.1.m1.1d">†</annotation></semantics></math>, implemented based on the Swin Transformer <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#bib.bib87" title="">87</a>]</cite>, cannot be directly applied to 2D tasks, since the depth length of the Swin Transformer must be greater than 1. Furthermore, these models are also unsuitable for the <math alttext="48\times 192\times 192" class="ltx_Math" display="inline" id="S5.SS5.p1.2.m2.1"><semantics id="S5.SS5.p1.2.m2.1a"><mrow id="S5.SS5.p1.2.m2.1.1" xref="S5.SS5.p1.2.m2.1.1.cmml"><mn id="S5.SS5.p1.2.m2.1.1.2" xref="S5.SS5.p1.2.m2.1.1.2.cmml">48</mn><mo id="S5.SS5.p1.2.m2.1.1.1" lspace="0.222em" rspace="0.222em" xref="S5.SS5.p1.2.m2.1.1.1.cmml">×</mo><mn id="S5.SS5.p1.2.m2.1.1.3" xref="S5.SS5.p1.2.m2.1.1.3.cmml">192</mn><mo id="S5.SS5.p1.2.m2.1.1.1a" lspace="0.222em" rspace="0.222em" xref="S5.SS5.p1.2.m2.1.1.1.cmml">×</mo><mn id="S5.SS5.p1.2.m2.1.1.4" xref="S5.SS5.p1.2.m2.1.1.4.cmml">192</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS5.p1.2.m2.1b"><apply id="S5.SS5.p1.2.m2.1.1.cmml" xref="S5.SS5.p1.2.m2.1.1"><times id="S5.SS5.p1.2.m2.1.1.1.cmml" xref="S5.SS5.p1.2.m2.1.1.1"></times><cn id="S5.SS5.p1.2.m2.1.1.2.cmml" type="integer" xref="S5.SS5.p1.2.m2.1.1.2">48</cn><cn id="S5.SS5.p1.2.m2.1.1.3.cmml" type="integer" xref="S5.SS5.p1.2.m2.1.1.3">192</cn><cn id="S5.SS5.p1.2.m2.1.1.4.cmml" type="integer" xref="S5.SS5.p1.2.m2.1.1.4">192</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS5.p1.2.m2.1c">48\times 192\times 192</annotation><annotation encoding="application/x-llamapun" id="S5.SS5.p1.2.m2.1d">48 × 192 × 192</annotation></semantics></math> patch size used on the BTCV and VS datasets due to depth requirements. Consequently, we adopted a patch size of <math alttext="64\times 192\times 192" class="ltx_Math" display="inline" id="S5.SS5.p1.3.m3.1"><semantics id="S5.SS5.p1.3.m3.1a"><mrow id="S5.SS5.p1.3.m3.1.1" xref="S5.SS5.p1.3.m3.1.1.cmml"><mn id="S5.SS5.p1.3.m3.1.1.2" xref="S5.SS5.p1.3.m3.1.1.2.cmml">64</mn><mo id="S5.SS5.p1.3.m3.1.1.1" lspace="0.222em" rspace="0.222em" xref="S5.SS5.p1.3.m3.1.1.1.cmml">×</mo><mn id="S5.SS5.p1.3.m3.1.1.3" xref="S5.SS5.p1.3.m3.1.1.3.cmml">192</mn><mo id="S5.SS5.p1.3.m3.1.1.1a" lspace="0.222em" rspace="0.222em" xref="S5.SS5.p1.3.m3.1.1.1.cmml">×</mo><mn id="S5.SS5.p1.3.m3.1.1.4" xref="S5.SS5.p1.3.m3.1.1.4.cmml">192</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS5.p1.3.m3.1b"><apply id="S5.SS5.p1.3.m3.1.1.cmml" xref="S5.SS5.p1.3.m3.1.1"><times id="S5.SS5.p1.3.m3.1.1.1.cmml" xref="S5.SS5.p1.3.m3.1.1.1"></times><cn id="S5.SS5.p1.3.m3.1.1.2.cmml" type="integer" xref="S5.SS5.p1.3.m3.1.1.2">64</cn><cn id="S5.SS5.p1.3.m3.1.1.3.cmml" type="integer" xref="S5.SS5.p1.3.m3.1.1.3">192</cn><cn id="S5.SS5.p1.3.m3.1.1.4.cmml" type="integer" xref="S5.SS5.p1.3.m3.1.1.4">192</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS5.p1.3.m3.1c">64\times 192\times 192</annotation><annotation encoding="application/x-llamapun" id="S5.SS5.p1.3.m3.1d">64 × 192 × 192</annotation></semantics></math> for these models. For UniMiSS, we followed the official strategy of forming two models to address 2D and 3D tasks, respectively. All results are averaged over three runs to ensure robustness.</p>
</div>
<div class="ltx_para" id="S5.SS5.p2">
<p class="ltx_p" id="S5.SS5.p2.1">The results in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#S5.T4" title="TABLE IV ‣ 5.2 Evaluation Metrics ‣ 5 Experiments ‣ MedUniSeg: 2D and 3D Medical Image Segmentation via a Prompt-driven Universal Model"><span class="ltx_text ltx_ref_tag">IV</span></a> reveal several findings:
(1) Our MedUniSeg significantly outperforms its baseline, the 3D backbone, across all downstream datasets, regardless of whether 20%, 50%, and 100% training data is used. This indicates that universal learning enables MedUniSeg to acquire high-quality representations, boosting downstream task performance.
(2) Compared to other pre-trained models, MedUniSeg exhibits the best performance across all datasets, except for the COVID-19-20 dataset with 20% training data, where it secures the second-best performance. This performance advantage stems from MedUniSeg’s robust representation capability, allowing it to outperform most self-supervised and supervised models.
(3) When compared to UniSeg, which was pre-trained on three modalities, MedUniSeg, pre-trained on nine modalities, shows consistent improvement across all datasets. This underscores the benefits of learning from a broader range of modalities and richer data.
(4) Although the parameters of the 3D backbone are approximately three times larger than those of the 2D backbone, it achieves comparable performance. Nevertheless, using a 3D backbone to address both 2D and 3D tasks remains superior to employing a Transformer backbone. Further discussion is provided in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#S6.SS3" title="6.3 Resource Requirements for Inference ‣ 6 Discussion ‣ MedUniSeg: 2D and 3D Medical Image Segmentation via a Prompt-driven Universal Model"><span class="ltx_text ltx_ref_tag">6.3</span></a>.</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS6">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.6 </span><span class="ltx_text ltx_font_italic" id="S5.SS6.1.1">Ablation Studies</span>
</h3>
<div class="ltx_para" id="S5.SS6.p1">
<p class="ltx_p" id="S5.SS6.p1.1">We evaluated six variants of MedUniSeg, including UniSeg, Multiple Prompts, Universal Prompts, Fixed Prompts, Bottleneck Prompts, and MedUniSeg-T.
Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#S5.F3" title="Figure 3 ‣ 5.3 Comparing to Single-task and Universal Models ‣ 5 Experiments ‣ MedUniSeg: 2D and 3D Medical Image Segmentation via a Prompt-driven Universal Model"><span class="ltx_text ltx_ref_tag">3</span></a> illustrates the structures of MedUniSeg and its variants. The differences between MedUniSeg and these variants are as follows:
UniSeg is regarded as MedUniSeg without modal priors.
Multiple Prompts employs modal- and task-specific prompts to generate corresponding priors.
Universal Prompts uses universal modal and task prompts to generate modal and task priors, respectively.
Fixed Prompts functions as MedUniSeg with fixed prompts.
Bottleneck Prompts incorporates both modal and task priors at the end of the encoding process.
MedUniSeg-T includes task priors at the end of the decoding process.</p>
</div>
<div class="ltx_para" id="S5.SS6.p2">
<p class="ltx_p" id="S5.SS6.p2.1">The results, presented in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#S5.T5" title="TABLE V ‣ 5.3 Comparing to Single-task and Universal Models ‣ 5 Experiments ‣ MedUniSeg: 2D and 3D Medical Image Segmentation via a Prompt-driven Universal Model"><span class="ltx_text ltx_ref_tag">V</span></a>, demonstrate the superior performance of our MedUniSeg in 3D mean Dice, 2D mean Dice, and overall mean Dice.
More importantly, we validated the motivations behind this study by comparing MedUniSeg with these variants.
Compared to UniSeg, our findings confirm the effectiveness of the proposed modal prior.
Comparisons with Multiple Prompts and Universal Prompts reveal that combining modal-specific prompts with a universal task prompt is the most effective strategy for capturing correlations and providing priors for modalities and tasks.
Additionally, the comparison with Fixed Prompts highlights the advantage of using learnable prompts over fixed alternatives.
Further comparisons with Bottleneck Prompts and MedUniSeg-T confirm the optimal positions for integrating modal and task priors.
In summary, MedUniSeg exemplifies the optimal configuration of modal and task priors, validated in terms of both their introduction and positioning.</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS7">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.7 </span><span class="ltx_text ltx_font_italic" id="S5.SS7.1.1">Block and Channel Numbers of FUSE Module</span>
</h3>
<div class="ltx_para" id="S5.SS7.p1">
<p class="ltx_p" id="S5.SS7.p1.12">Our FUSE module consists of multiple convolutional blocks designed to reduce input feature channels from <math alttext="C" class="ltx_Math" display="inline" id="S5.SS7.p1.1.m1.1"><semantics id="S5.SS7.p1.1.m1.1a"><mi id="S5.SS7.p1.1.m1.1.1" xref="S5.SS7.p1.1.m1.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S5.SS7.p1.1.m1.1b"><ci id="S5.SS7.p1.1.m1.1.1.cmml" xref="S5.SS7.p1.1.m1.1.1">𝐶</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS7.p1.1.m1.1c">C</annotation><annotation encoding="application/x-llamapun" id="S5.SS7.p1.1.m1.1d">italic_C</annotation></semantics></math> to <math alttext="C/m" class="ltx_Math" display="inline" id="S5.SS7.p1.2.m2.1"><semantics id="S5.SS7.p1.2.m2.1a"><mrow id="S5.SS7.p1.2.m2.1.1" xref="S5.SS7.p1.2.m2.1.1.cmml"><mi id="S5.SS7.p1.2.m2.1.1.2" xref="S5.SS7.p1.2.m2.1.1.2.cmml">C</mi><mo id="S5.SS7.p1.2.m2.1.1.1" xref="S5.SS7.p1.2.m2.1.1.1.cmml">/</mo><mi id="S5.SS7.p1.2.m2.1.1.3" xref="S5.SS7.p1.2.m2.1.1.3.cmml">m</mi></mrow><annotation-xml encoding="MathML-Content" id="S5.SS7.p1.2.m2.1b"><apply id="S5.SS7.p1.2.m2.1.1.cmml" xref="S5.SS7.p1.2.m2.1.1"><divide id="S5.SS7.p1.2.m2.1.1.1.cmml" xref="S5.SS7.p1.2.m2.1.1.1"></divide><ci id="S5.SS7.p1.2.m2.1.1.2.cmml" xref="S5.SS7.p1.2.m2.1.1.2">𝐶</ci><ci id="S5.SS7.p1.2.m2.1.1.3.cmml" xref="S5.SS7.p1.2.m2.1.1.3">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS7.p1.2.m2.1c">C/m</annotation><annotation encoding="application/x-llamapun" id="S5.SS7.p1.2.m2.1d">italic_C / italic_m</annotation></semantics></math> in the first block, ultimately outputting <math alttext="N" class="ltx_Math" display="inline" id="S5.SS7.p1.3.m3.1"><semantics id="S5.SS7.p1.3.m3.1a"><mi id="S5.SS7.p1.3.m3.1.1" xref="S5.SS7.p1.3.m3.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S5.SS7.p1.3.m3.1b"><ci id="S5.SS7.p1.3.m3.1.1.cmml" xref="S5.SS7.p1.3.m3.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS7.p1.3.m3.1c">N</annotation><annotation encoding="application/x-llamapun" id="S5.SS7.p1.3.m3.1d">italic_N</annotation></semantics></math> channels, each corresponding to a specific task.
Here, <math alttext="C" class="ltx_Math" display="inline" id="S5.SS7.p1.4.m4.1"><semantics id="S5.SS7.p1.4.m4.1a"><mi id="S5.SS7.p1.4.m4.1.1" xref="S5.SS7.p1.4.m4.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S5.SS7.p1.4.m4.1b"><ci id="S5.SS7.p1.4.m4.1.1.cmml" xref="S5.SS7.p1.4.m4.1.1">𝐶</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS7.p1.4.m4.1c">C</annotation><annotation encoding="application/x-llamapun" id="S5.SS7.p1.4.m4.1d">italic_C</annotation></semantics></math> is the sum of the channels from the universal task prompt and the sample-specific features.
We conducted a detailed assessment of the module’s design, focusing on the number of blocks (<math alttext="\#B" class="ltx_Math" display="inline" id="S5.SS7.p1.5.m5.1"><semantics id="S5.SS7.p1.5.m5.1a"><mrow id="S5.SS7.p1.5.m5.1.1" xref="S5.SS7.p1.5.m5.1.1.cmml"><mi id="S5.SS7.p1.5.m5.1.1.2" mathvariant="normal" xref="S5.SS7.p1.5.m5.1.1.2.cmml">#</mi><mo id="S5.SS7.p1.5.m5.1.1.1" xref="S5.SS7.p1.5.m5.1.1.1.cmml">⁢</mo><mi id="S5.SS7.p1.5.m5.1.1.3" xref="S5.SS7.p1.5.m5.1.1.3.cmml">B</mi></mrow><annotation-xml encoding="MathML-Content" id="S5.SS7.p1.5.m5.1b"><apply id="S5.SS7.p1.5.m5.1.1.cmml" xref="S5.SS7.p1.5.m5.1.1"><times id="S5.SS7.p1.5.m5.1.1.1.cmml" xref="S5.SS7.p1.5.m5.1.1.1"></times><ci id="S5.SS7.p1.5.m5.1.1.2.cmml" xref="S5.SS7.p1.5.m5.1.1.2">#</ci><ci id="S5.SS7.p1.5.m5.1.1.3.cmml" xref="S5.SS7.p1.5.m5.1.1.3">𝐵</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS7.p1.5.m5.1c">\#B</annotation><annotation encoding="application/x-llamapun" id="S5.SS7.p1.5.m5.1d"># italic_B</annotation></semantics></math>) and the channel (<math alttext="C/m" class="ltx_Math" display="inline" id="S5.SS7.p1.6.m6.1"><semantics id="S5.SS7.p1.6.m6.1a"><mrow id="S5.SS7.p1.6.m6.1.1" xref="S5.SS7.p1.6.m6.1.1.cmml"><mi id="S5.SS7.p1.6.m6.1.1.2" xref="S5.SS7.p1.6.m6.1.1.2.cmml">C</mi><mo id="S5.SS7.p1.6.m6.1.1.1" xref="S5.SS7.p1.6.m6.1.1.1.cmml">/</mo><mi id="S5.SS7.p1.6.m6.1.1.3" xref="S5.SS7.p1.6.m6.1.1.3.cmml">m</mi></mrow><annotation-xml encoding="MathML-Content" id="S5.SS7.p1.6.m6.1b"><apply id="S5.SS7.p1.6.m6.1.1.cmml" xref="S5.SS7.p1.6.m6.1.1"><divide id="S5.SS7.p1.6.m6.1.1.1.cmml" xref="S5.SS7.p1.6.m6.1.1.1"></divide><ci id="S5.SS7.p1.6.m6.1.1.2.cmml" xref="S5.SS7.p1.6.m6.1.1.2">𝐶</ci><ci id="S5.SS7.p1.6.m6.1.1.3.cmml" xref="S5.SS7.p1.6.m6.1.1.3">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS7.p1.6.m6.1c">C/m</annotation><annotation encoding="application/x-llamapun" id="S5.SS7.p1.6.m6.1d">italic_C / italic_m</annotation></semantics></math>). With <math alttext="C" class="ltx_Math" display="inline" id="S5.SS7.p1.7.m7.1"><semantics id="S5.SS7.p1.7.m7.1a"><mi id="S5.SS7.p1.7.m7.1.1" xref="S5.SS7.p1.7.m7.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S5.SS7.p1.7.m7.1b"><ci id="S5.SS7.p1.7.m7.1.1.cmml" xref="S5.SS7.p1.7.m7.1.1">𝐶</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS7.p1.7.m7.1c">C</annotation><annotation encoding="application/x-llamapun" id="S5.SS7.p1.7.m7.1d">italic_C</annotation></semantics></math> fixed, we examined the impact of varying the reduction ratio <math alttext="m" class="ltx_Math" display="inline" id="S5.SS7.p1.8.m8.1"><semantics id="S5.SS7.p1.8.m8.1a"><mi id="S5.SS7.p1.8.m8.1.1" xref="S5.SS7.p1.8.m8.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="S5.SS7.p1.8.m8.1b"><ci id="S5.SS7.p1.8.m8.1.1.cmml" xref="S5.SS7.p1.8.m8.1.1">𝑚</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS7.p1.8.m8.1c">m</annotation><annotation encoding="application/x-llamapun" id="S5.SS7.p1.8.m8.1d">italic_m</annotation></semantics></math>.
The results in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#S5.T6" title="TABLE VI ‣ 5.4 Performance Improvement using LoRA ‣ 5 Experiments ‣ MedUniSeg: 2D and 3D Medical Image Segmentation via a Prompt-driven Universal Model"><span class="ltx_text ltx_ref_tag">VI</span></a> indicate that with <math alttext="m" class="ltx_Math" display="inline" id="S5.SS7.p1.9.m9.1"><semantics id="S5.SS7.p1.9.m9.1a"><mi id="S5.SS7.p1.9.m9.1.1" xref="S5.SS7.p1.9.m9.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="S5.SS7.p1.9.m9.1b"><ci id="S5.SS7.p1.9.m9.1.1.cmml" xref="S5.SS7.p1.9.m9.1.1">𝑚</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS7.p1.9.m9.1c">m</annotation><annotation encoding="application/x-llamapun" id="S5.SS7.p1.9.m9.1d">italic_m</annotation></semantics></math> fixed at four, MedUniSeg achieves the highest mean Dice score when using three blocks. Conversely, with <math alttext="\#B" class="ltx_Math" display="inline" id="S5.SS7.p1.10.m10.1"><semantics id="S5.SS7.p1.10.m10.1a"><mrow id="S5.SS7.p1.10.m10.1.1" xref="S5.SS7.p1.10.m10.1.1.cmml"><mi id="S5.SS7.p1.10.m10.1.1.2" mathvariant="normal" xref="S5.SS7.p1.10.m10.1.1.2.cmml">#</mi><mo id="S5.SS7.p1.10.m10.1.1.1" xref="S5.SS7.p1.10.m10.1.1.1.cmml">⁢</mo><mi id="S5.SS7.p1.10.m10.1.1.3" xref="S5.SS7.p1.10.m10.1.1.3.cmml">B</mi></mrow><annotation-xml encoding="MathML-Content" id="S5.SS7.p1.10.m10.1b"><apply id="S5.SS7.p1.10.m10.1.1.cmml" xref="S5.SS7.p1.10.m10.1.1"><times id="S5.SS7.p1.10.m10.1.1.1.cmml" xref="S5.SS7.p1.10.m10.1.1.1"></times><ci id="S5.SS7.p1.10.m10.1.1.2.cmml" xref="S5.SS7.p1.10.m10.1.1.2">#</ci><ci id="S5.SS7.p1.10.m10.1.1.3.cmml" xref="S5.SS7.p1.10.m10.1.1.3">𝐵</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS7.p1.10.m10.1c">\#B</annotation><annotation encoding="application/x-llamapun" id="S5.SS7.p1.10.m10.1d"># italic_B</annotation></semantics></math> fixed at three, the optimal mean Dice score is obtained by setting <math alttext="m" class="ltx_Math" display="inline" id="S5.SS7.p1.11.m11.1"><semantics id="S5.SS7.p1.11.m11.1a"><mi id="S5.SS7.p1.11.m11.1.1" xref="S5.SS7.p1.11.m11.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="S5.SS7.p1.11.m11.1b"><ci id="S5.SS7.p1.11.m11.1.1.cmml" xref="S5.SS7.p1.11.m11.1.1">𝑚</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS7.p1.11.m11.1c">m</annotation><annotation encoding="application/x-llamapun" id="S5.SS7.p1.11.m11.1d">italic_m</annotation></semantics></math> to four. Thus, the combination of three blocks and a <math alttext="C/4" class="ltx_Math" display="inline" id="S5.SS7.p1.12.m12.1"><semantics id="S5.SS7.p1.12.m12.1a"><mrow id="S5.SS7.p1.12.m12.1.1" xref="S5.SS7.p1.12.m12.1.1.cmml"><mi id="S5.SS7.p1.12.m12.1.1.2" xref="S5.SS7.p1.12.m12.1.1.2.cmml">C</mi><mo id="S5.SS7.p1.12.m12.1.1.1" xref="S5.SS7.p1.12.m12.1.1.1.cmml">/</mo><mn id="S5.SS7.p1.12.m12.1.1.3" xref="S5.SS7.p1.12.m12.1.1.3.cmml">4</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS7.p1.12.m12.1b"><apply id="S5.SS7.p1.12.m12.1.1.cmml" xref="S5.SS7.p1.12.m12.1.1"><divide id="S5.SS7.p1.12.m12.1.1.1.cmml" xref="S5.SS7.p1.12.m12.1.1.1"></divide><ci id="S5.SS7.p1.12.m12.1.1.2.cmml" xref="S5.SS7.p1.12.m12.1.1.2">𝐶</ci><cn id="S5.SS7.p1.12.m12.1.1.3.cmml" type="integer" xref="S5.SS7.p1.12.m12.1.1.3">4</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS7.p1.12.m12.1c">C/4</annotation><annotation encoding="application/x-llamapun" id="S5.SS7.p1.12.m12.1d">italic_C / 4</annotation></semantics></math> channel configuration offers the most effective task-specific priors, leading to superior generalization performance.</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS8">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.8 </span><span class="ltx_text ltx_font_italic" id="S5.SS8.1.1">Shapes of Modal-specific Prompts and Universal Task Prompt</span>
</h3>
<div class="ltx_para" id="S5.SS8.p1">
<p class="ltx_p" id="S5.SS8.p1.8">We conducted experiments to vary the length of the modal-specific prompt (<math alttext="l" class="ltx_Math" display="inline" id="S5.SS8.p1.1.m1.1"><semantics id="S5.SS8.p1.1.m1.1a"><mi id="S5.SS8.p1.1.m1.1.1" xref="S5.SS8.p1.1.m1.1.1.cmml">l</mi><annotation-xml encoding="MathML-Content" id="S5.SS8.p1.1.m1.1b"><ci id="S5.SS8.p1.1.m1.1.1.cmml" xref="S5.SS8.p1.1.m1.1.1">𝑙</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS8.p1.1.m1.1c">l</annotation><annotation encoding="application/x-llamapun" id="S5.SS8.p1.1.m1.1d">italic_l</annotation></semantics></math>) and the channel number of the universal task prompt (<math alttext="K" class="ltx_Math" display="inline" id="S5.SS8.p1.2.m2.1"><semantics id="S5.SS8.p1.2.m2.1a"><mi id="S5.SS8.p1.2.m2.1.1" xref="S5.SS8.p1.2.m2.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S5.SS8.p1.2.m2.1b"><ci id="S5.SS8.p1.2.m2.1.1.cmml" xref="S5.SS8.p1.2.m2.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS8.p1.2.m2.1c">K</annotation><annotation encoding="application/x-llamapun" id="S5.SS8.p1.2.m2.1d">italic_K</annotation></semantics></math>), with the results summarized in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#S5.T7" title="TABLE VII ‣ 5.4 Performance Improvement using LoRA ‣ 5 Experiments ‣ MedUniSeg: 2D and 3D Medical Image Segmentation via a Prompt-driven Universal Model"><span class="ltx_text ltx_ref_tag">VII</span></a>. For <math alttext="l" class="ltx_Math" display="inline" id="S5.SS8.p1.3.m3.1"><semantics id="S5.SS8.p1.3.m3.1a"><mi id="S5.SS8.p1.3.m3.1.1" xref="S5.SS8.p1.3.m3.1.1.cmml">l</mi><annotation-xml encoding="MathML-Content" id="S5.SS8.p1.3.m3.1b"><ci id="S5.SS8.p1.3.m3.1.1.cmml" xref="S5.SS8.p1.3.m3.1.1">𝑙</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS8.p1.3.m3.1c">l</annotation><annotation encoding="application/x-llamapun" id="S5.SS8.p1.3.m3.1d">italic_l</annotation></semantics></math>, we tested six variants, gradually increasing its value from 256 to 2048. Among these, setting <math alttext="l" class="ltx_Math" display="inline" id="S5.SS8.p1.4.m4.1"><semantics id="S5.SS8.p1.4.m4.1a"><mi id="S5.SS8.p1.4.m4.1.1" xref="S5.SS8.p1.4.m4.1.1.cmml">l</mi><annotation-xml encoding="MathML-Content" id="S5.SS8.p1.4.m4.1b"><ci id="S5.SS8.p1.4.m4.1.1.cmml" xref="S5.SS8.p1.4.m4.1.1">𝑙</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS8.p1.4.m4.1c">l</annotation><annotation encoding="application/x-llamapun" id="S5.SS8.p1.4.m4.1d">italic_l</annotation></semantics></math> to 512 yielded the highest mean Dice score and 3D mean Dice. Similarly, for <math alttext="K" class="ltx_Math" display="inline" id="S5.SS8.p1.5.m5.1"><semantics id="S5.SS8.p1.5.m5.1a"><mi id="S5.SS8.p1.5.m5.1.1" xref="S5.SS8.p1.5.m5.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S5.SS8.p1.5.m5.1b"><ci id="S5.SS8.p1.5.m5.1.1.cmml" xref="S5.SS8.p1.5.m5.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS8.p1.5.m5.1c">K</annotation><annotation encoding="application/x-llamapun" id="S5.SS8.p1.5.m5.1d">italic_K</annotation></semantics></math>, we evaluated values of 50, 100, and 200, determining that <math alttext="K=100" class="ltx_Math" display="inline" id="S5.SS8.p1.6.m6.1"><semantics id="S5.SS8.p1.6.m6.1a"><mrow id="S5.SS8.p1.6.m6.1.1" xref="S5.SS8.p1.6.m6.1.1.cmml"><mi id="S5.SS8.p1.6.m6.1.1.2" xref="S5.SS8.p1.6.m6.1.1.2.cmml">K</mi><mo id="S5.SS8.p1.6.m6.1.1.1" xref="S5.SS8.p1.6.m6.1.1.1.cmml">=</mo><mn id="S5.SS8.p1.6.m6.1.1.3" xref="S5.SS8.p1.6.m6.1.1.3.cmml">100</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS8.p1.6.m6.1b"><apply id="S5.SS8.p1.6.m6.1.1.cmml" xref="S5.SS8.p1.6.m6.1.1"><eq id="S5.SS8.p1.6.m6.1.1.1.cmml" xref="S5.SS8.p1.6.m6.1.1.1"></eq><ci id="S5.SS8.p1.6.m6.1.1.2.cmml" xref="S5.SS8.p1.6.m6.1.1.2">𝐾</ci><cn id="S5.SS8.p1.6.m6.1.1.3.cmml" type="integer" xref="S5.SS8.p1.6.m6.1.1.3">100</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS8.p1.6.m6.1c">K=100</annotation><annotation encoding="application/x-llamapun" id="S5.SS8.p1.6.m6.1d">italic_K = 100</annotation></semantics></math> is optimal. Consequently, in our MedUniSeg, we set <math alttext="l" class="ltx_Math" display="inline" id="S5.SS8.p1.7.m7.1"><semantics id="S5.SS8.p1.7.m7.1a"><mi id="S5.SS8.p1.7.m7.1.1" xref="S5.SS8.p1.7.m7.1.1.cmml">l</mi><annotation-xml encoding="MathML-Content" id="S5.SS8.p1.7.m7.1b"><ci id="S5.SS8.p1.7.m7.1.1.cmml" xref="S5.SS8.p1.7.m7.1.1">𝑙</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS8.p1.7.m7.1c">l</annotation><annotation encoding="application/x-llamapun" id="S5.SS8.p1.7.m7.1d">italic_l</annotation></semantics></math> to 512 and <math alttext="K" class="ltx_Math" display="inline" id="S5.SS8.p1.8.m8.1"><semantics id="S5.SS8.p1.8.m8.1a"><mi id="S5.SS8.p1.8.m8.1.1" xref="S5.SS8.p1.8.m8.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S5.SS8.p1.8.m8.1b"><ci id="S5.SS8.p1.8.m8.1.1.cmml" xref="S5.SS8.p1.8.m8.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS8.p1.8.m8.1c">K</annotation><annotation encoding="application/x-llamapun" id="S5.SS8.p1.8.m8.1d">italic_K</annotation></semantics></math> to 100.</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS9">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.9 </span><span class="ltx_text ltx_font_italic" id="S5.SS9.1.1">Visualization of Segmentation Results</span>
</h3>
<section class="ltx_subsubsection" id="S5.SS9.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.9.1 </span>Upstream dataset</h4>
<div class="ltx_para" id="S5.SS9.SSS1.p1">
<p class="ltx_p" id="S5.SS9.SSS1.p1.1">We visualized segmentation results obtained from UKAN, UMamba, nnUNet, Universal Model, Hermes, DoDNet, CCQ, UniSeg, and MedUniSeg across seven datasets, as illustrated in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#S5.F4" title="Figure 4 ‣ 5.3 Comparing to Single-task and Universal Models ‣ 5 Experiments ‣ MedUniSeg: 2D and 3D Medical Image Segmentation via a Prompt-driven Universal Model"><span class="ltx_text ltx_ref_tag">4</span></a>. The visualizations demonstrate that MedUniSeg’s segmentation results closely align with the ground truths (GTs), effectively mitigating under-segmentation (see the first row of Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#S5.F4" title="Figure 4 ‣ 5.3 Comparing to Single-task and Universal Models ‣ 5 Experiments ‣ MedUniSeg: 2D and 3D Medical Image Segmentation via a Prompt-driven Universal Model"><span class="ltx_text ltx_ref_tag">4</span></a>) and over-segmentation (see the third row of Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#S5.F4" title="Figure 4 ‣ 5.3 Comparing to Single-task and Universal Models ‣ 5 Experiments ‣ MedUniSeg: 2D and 3D Medical Image Segmentation via a Prompt-driven Universal Model"><span class="ltx_text ltx_ref_tag">4</span></a>). Moreover, compared to UniSeg (our previous work), MedUniSeg consistently delivers more accurate results across all images, highlighting the advancements achieved in this version.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S5.SS9.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.9.2 </span>Downstream datasets</h4>
<div class="ltx_para" id="S5.SS9.SSS2.p1">
<p class="ltx_p" id="S5.SS9.SSS2.p1.1">We visualized the segmentation results of several models, including Swin UNETR, UniMiSS, DeSD, Universal Model, Universal Model<math alttext="{\dagger}" class="ltx_Math" display="inline" id="S5.SS9.SSS2.p1.1.m1.1"><semantics id="S5.SS9.SSS2.p1.1.m1.1a"><mo id="S5.SS9.SSS2.p1.1.m1.1.1" xref="S5.SS9.SSS2.p1.1.m1.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="S5.SS9.SSS2.p1.1.m1.1b"><ci id="S5.SS9.SSS2.p1.1.m1.1.1.cmml" xref="S5.SS9.SSS2.p1.1.m1.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS9.SSS2.p1.1.m1.1c">{\dagger}</annotation><annotation encoding="application/x-llamapun" id="S5.SS9.SSS2.p1.1.m1.1d">†</annotation></semantics></math>, Hermes, DoDNet, CCQ, UniSeg, and MedUniSeg, across six downstream datasets. A representative sample from each dataset was presented in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#S5.F5" title="Figure 5 ‣ 5.3 Comparing to Single-task and Universal Models ‣ 5 Experiments ‣ MedUniSeg: 2D and 3D Medical Image Segmentation via a Prompt-driven Universal Model"><span class="ltx_text ltx_ref_tag">5</span></a>. The visualizations clearly demonstrate that MedUniSeg consistently outperforms competing methods in terms of accuracy across five modalities and both 2D and 3D segmentation tasks. For instance, in images from the SIIM and SegPC datasets, MedUniSeg not only provides the most complete segmentation but also minimizes over-segmentation compared to other methods.</p>
</div>
</section>
</section>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span><span class="ltx_text ltx_font_smallcaps" id="S6.1.1">Discussion</span>
</h2>
<section class="ltx_subsection" id="S6.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.1 </span><span class="ltx_text ltx_font_italic" id="S6.SS1.1.1">Visualization of Task-specific Prior</span>
</h3>
<div class="ltx_para" id="S6.SS1.p1">
<p class="ltx_p" id="S6.SS1.p1.1">To investigate the features learned by the universal task prompt, we visualized the task-specific priors using t-SNE. These task-specific priors were derived from all training and test data. Due to imbalanced sample sizes across tasks, we randomly selected 1,000 samples from each task for the t-SNE visualization. For tasks with fewer than 1,000 samples, we employed a resampling strategy to augment the data to this threshold. The resulting visualizations are presented in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#S5.F6" title="Figure 6 ‣ 5.3 Comparing to Single-task and Universal Models ‣ 5 Experiments ‣ MedUniSeg: 2D and 3D Medical Image Segmentation via a Prompt-driven Universal Model"><span class="ltx_text ltx_ref_tag">6</span></a>. The t-SNE visualization reveals that the distributions of different tasks are well-clustered and exhibit clear classification boundaries. This indicates that the task-specific priors learned through the self-learn universal task prompt can effectively distinguish and describe the unique characteristics of each task, thereby minimizing prompt confusion within the model. For instance, despite tasks like Liver, Kidney, HepaV, Pancreas, Colon, Lung, and Spleen segmentation sharing similar input images, their task priors display significant distributional differences.</p>
</div>
</section>
<section class="ltx_subsection" id="S6.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.2 </span><span class="ltx_text ltx_font_italic" id="S6.SS2.1.1">Correlation between Upstream and Downstream Learning</span>
</h3>
<div class="ltx_para" id="S6.SS2.p1">
<p class="ltx_p" id="S6.SS2.p1.1">A limitation of self-supervised learning is the challenge of evaluating the transferability of a pre-trained model using upstream metrics, such as loss value. Importantly, lower loss values do not necessarily correlate with better downstream performance. In the context of supervised pre-training, we investigated whether upstream performance metrics could serve as reliable predictors for downstream performance. To this end, we calculated the correlation between upstream and downstream performance. Specifically, for each universal model, we recorded the mean Dice score across 17 upstream datasets and the Dice scores on six downstream datasets with 100% training data. We then computed Pearson correlation coefficients for each dataset. The Pearson correlation coefficients between upstream performance and the BTCV, COVID-19-20, VS, SIIM, IDRID, and SegPC datasets were 0.75, 0.74, 0.87, 0.57, 0.64, and 0.61, respectively, indicating positive correlations in most cases. Therefore, we conclude that the transferability of a supervised pre-trained model can generally be assessed by its upstream performance.</p>
</div>
</section>
<section class="ltx_subsection" id="S6.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.3 </span><span class="ltx_text ltx_font_italic" id="S6.SS3.1.1">Resource Requirements for Inference</span>
</h3>
<div class="ltx_para" id="S6.SS3.p1">
<p class="ltx_p" id="S6.SS3.p1.1">In this study, we utilized a 3D UNet architecture to handle both 3D and 2D segmentation tasks, treating 2D data as pseudo-3D data with a depth of one. However, this approach inherently leads to inefficiencies for 2D tasks, as parameters assigned to the depth dimension have minimal impact. We recorded the number of parameters, GPU memory usage, inference times per image, and Dice scores for UniMiSS, 2D backbone, 3D backbone, and MedUniSeg, as summarized in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.05905v1#S5.T8" title="TABLE VIII ‣ 5.4 Performance Improvement using LoRA ‣ 5 Experiments ‣ MedUniSeg: 2D and 3D Medical Image Segmentation via a Prompt-driven Universal Model"><span class="ltx_text ltx_ref_tag">VIII</span></a>. All models were tested on an RTX 3090 with a batch size of 1 and patch size of <math alttext="512\times 512" class="ltx_Math" display="inline" id="S6.SS3.p1.1.m1.1"><semantics id="S6.SS3.p1.1.m1.1a"><mrow id="S6.SS3.p1.1.m1.1.1" xref="S6.SS3.p1.1.m1.1.1.cmml"><mn id="S6.SS3.p1.1.m1.1.1.2" xref="S6.SS3.p1.1.m1.1.1.2.cmml">512</mn><mo id="S6.SS3.p1.1.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="S6.SS3.p1.1.m1.1.1.1.cmml">×</mo><mn id="S6.SS3.p1.1.m1.1.1.3" xref="S6.SS3.p1.1.m1.1.1.3.cmml">512</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.SS3.p1.1.m1.1b"><apply id="S6.SS3.p1.1.m1.1.1.cmml" xref="S6.SS3.p1.1.m1.1.1"><times id="S6.SS3.p1.1.m1.1.1.1.cmml" xref="S6.SS3.p1.1.m1.1.1.1"></times><cn id="S6.SS3.p1.1.m1.1.1.2.cmml" type="integer" xref="S6.SS3.p1.1.m1.1.1.2">512</cn><cn id="S6.SS3.p1.1.m1.1.1.3.cmml" type="integer" xref="S6.SS3.p1.1.m1.1.1.3">512</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS3.p1.1.m1.1c">512\times 512</annotation><annotation encoding="application/x-llamapun" id="S6.SS3.p1.1.m1.1d">512 × 512</annotation></semantics></math> using the nnUNet framework. The results indicate that although MedUniSeg requires approximately twice the inference time and 1.5 times the GPU memory compared to the 2D version, it achieves a 4.2% improvement in Dice scores. More importantly, when compared to the Transformer-based model UniMiSS, which also supports both 2D and 3D input, MedUniSeg outperforms it in both Dice scores and inference times.</p>
</div>
<div class="ltx_para" id="S6.SS3.p2">
<p class="ltx_p" id="S6.SS3.p2.1">In summary, MedUniSeg offers a superior solution for both 2D and 3D segmentation, achieving better performance and lower inference times compared to UniMiSS.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S7">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span><span class="ltx_text ltx_font_smallcaps" id="S7.1.1">Conclusion</span>
</h2>
<div class="ltx_para" id="S7.p1">
<p class="ltx_p" id="S7.p1.1">In this paper, we present MedUniSeg, a prompt-driven universal model specifically designed for 2D and 3D medical image segmentation across diverse targets, modalities, and domains. Our approach integrates modal-specific prompts and a universal task prompt to effectively characterize both the modalities and tasks. Utilizing these prompts, we develop the MMap and FUSE modules to generate modal- and task-specific priors, which are strategically incorporated at the start and end of the encoding process, respectively.
We evaluate MedUniSeg on a large-scale multi-modal segmentation upstream dataset and six downstream segmentation datasets. The results demonstrate its superior performance in both universal learning and transfer learning.
For tasks that exhibit suboptimal performance during the initial multi-task joint training, we freeze MedUniSeg and introduce new LoRA modules, deconvolutional layers, and segmentation heads to re-learn these tasks, resulting in an enhanced version called MedUniSeg*. This strategy consistently improves task performance compared to the original MedUniSeg.
In the future, we plan to integrate MedUniSeg to address medical image classification and detection tasks, further enhancing its universality.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
S. Chen, K. Ma, and Y. Zheng, “Med3d: Transfer learning for 3d medical image analysis,” <em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">arXiv preprint arXiv:1904.00625</em>, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
C. Ulrich, F. Isensee, T. Wald, M. Zenk, M. Baumgartner, and K. H. Maier-Hein, “Multitalent: A multi-dataset approach to medical image segmentation,” in <em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">International Conference on Medical Image Computing and Computer-Assisted Intervention</em>.   Springer, 2023, pp. 648–658.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
Y. Zhou, Z. Li, S. Bai, C. Wang, X. Chen, M. Han, E. Fishman, and A. L. Yuille, “Prior-aware neural network for partially-supervised multi-organ segmentation,” in <em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">Proceedings of the IEEE/CVF international conference on computer vision</em>, 2019, pp. 10 672–10 681.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
X. Fang and P. Yan, “Multi-organ segmentation over partially labeled datasets with multi-scale feature abstraction,” <em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">IEEE Transactions on Medical Imaging</em>, vol. 39, no. 11, pp. 3619–3629, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
R. Huang, Y. Zheng, Z. Hu, S. Zhang, and H. Li, “Multi-organ segmentation via co-training weight-averaged models from few-organ datasets,” in <em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">Medical Image Computing and Computer Assisted Intervention–MICCAI 2020: 23rd International Conference, Lima, Peru, October 4–8, 2020, Proceedings, Part IV 23</em>.   Springer, 2020, pp. 146–155.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
P. Liu, Y. Deng, C. Wang, Y. Hui, Q. Li, J. Li, S. Luo, M. Sun, Q. Quan, S. Yang <em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">et al.</em>, “Universal segmentation of 33 anatomies,” <em class="ltx_emph ltx_font_italic" id="bib.bib6.2.2">arXiv preprint arXiv:2203.02098</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
W. Zhang, J. Zhang, X. Wang, S. Yang, J. Huang, W. Yang, W. Wang, and X. Han, “Merging nucleus datasets by correlation-based cross-training,” <em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">Medical Image Analysis</em>, vol. 84, p. 102705, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
H. Liu, Z. Xu, R. Gao, H. Li, J. Wang, G. Chabin, I. Oguz, and S. Grbic, “Cosst: Multi-organ segmentation with partially labeled datasets using comprehensive supervisions and self-training,” <em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">IEEE Transactions on Medical Imaging</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
X. Chen, H. Zheng, Y. Li, Y. Ma, L. Ma, H. Li, and Y. Fan, “Versatile medical image segmentation learned from multi-source datasets via model self-disambiguation,” in <em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>, 2024, pp. 11 747–11 756.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
J. Liu, Y. Zhang, J.-N. Chen, J. Xiao, Y. Lu, B. A Landman, Y. Yuan, A. Yuille, Y. Tang, and Z. Zhou, “Clip-driven universal model for organ segmentation and tumor detection,” in <em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">Proceedings of the IEEE/CVF International Conference on Computer Vision</em>, 2023, pp. 21 152–21 164.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
J. Liu, Y. Zhang, K. Wang, M. C. Yavuz, X. Chen, Y. Yuan, H. Li, Y. Yang, A. Yuille, Y. Tang <em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">et al.</em>, “Universal and extensible language-vision models for organ segmentation and tumor detection from abdominal computed tomography,” <em class="ltx_emph ltx_font_italic" id="bib.bib11.2.2">Medical Image Analysis</em>, p. 103226, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
J. Zhang, Y. Xie, Y. Xia, and C. Shen, “Dodnet: Learning to segment multi-organ and tumors from multiple partially labeled datasets,” in <em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</em>, 2021, pp. 1195–1204.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
H. Wu, S. Pang, and A. Sowmya, “Tgnet: A task-guided network architecture for multi-organ and tumour segmentation from partially labelled datasets,” in <em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">2022 IEEE 19th International Symposium on Biomedical Imaging (ISBI)</em>.   IEEE, 2022, pp. 1–5.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
R. Deng, Q. Liu, C. Cui, T. Yao, J. Long, Z. Asad, R. M. Womick, Z. Zhu, A. B. Fogo, S. Zhao <em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">et al.</em>, “Omni-seg: A scale-aware dynamic network for renal pathological image segmentation,” <em class="ltx_emph ltx_font_italic" id="bib.bib14.2.2">IEEE Transactions on Biomedical Engineering</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
Y. Xie, J. Zhang, Y. Xia, and C. Shen, “Learning from partially labeled data for multi-organ and tumor segmentation,” <em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">IEEE Transactions on Pattern Analysis and Machine Intelligence</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
Y. Ye, Y. Xie, J. Zhang, Z. Chen, and Y. Xia, “Uniseg: A prompt-driven universal segmentation model as well as a strong representation learner,” <em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">arXiv preprint arXiv:2304.03493</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
X. Liu, B. Wen, and S. Yang, “Ccq: cross-class query network for partially labeled organ segmentation,” in <em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">Proceedings of the AAAI Conference on Artificial Intelligence</em>, vol. 37, no. 2, 2023, pp. 1755–1763.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
Y. Gao, “Training like a medical resident: Context-prior learning toward universal medical image segmentation,” in <em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>, 2024, pp. 11 194–11 204.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
K. Dmitriev and A. E. Kaufman, “Learning multi-class segmentations from single-class datasets,” in <em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>, 2019, pp. 9501–9511.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
Y. Ye, Y. Xie, J. Zhang, Z. Chen, Q. Wu, and Y. Xia, “Continual self-supervised learning: Towards universal multi-modal medical data representation learning,” in <em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>, 2024, pp. 11 114–11 124.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
Y. Huang, J. Lin, C. Zhou, H. Yang, and L. Huang, “Modality competition: What makes joint training of multi-modal network fail in deep learning?(provably),” in <em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">International conference on machine learning</em>.   PMLR, 2022, pp. 9226–9259.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
W. Wang, D. Tran, and M. Feiszli, “What makes training multi-modal classification networks hard?” in <em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</em>, 2020, pp. 12 695–12 705.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
P. Godau and L. Maier-Hein, “Task fingerprinting for meta learning inbiomedical image analysis,” in <em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">Medical Image Computing and Computer Assisted Intervention–MICCAI 2021: 24th International Conference, Strasbourg, France, September 27–October 1, 2021, Proceedings, Part IV 24</em>.   Springer, 2021, pp. 436–446.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
F. Isensee, P. F. Jaeger, S. A. Kohl, J. Petersen, and K. H. Maier-Hein, “nnu-net: a self-configuring method for deep learning-based biomedical image segmentation,” <em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">Nature methods</em>, vol. 18, no. 2, pp. 203–211, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
J. Ma, F. Li, and B. Wang, “U-mamba: Enhancing long-range dependency for biomedical image segmentation,” <em class="ltx_emph ltx_font_italic" id="bib.bib25.1.1">arXiv preprint arXiv:2401.04722</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
C. Li, X. Liu, W. Li, C. Wang, H. Liu, and Y. Yuan, “U-kan makes strong backbone for medical image segmentation and generation,” <em class="ltx_emph ltx_font_italic" id="bib.bib26.1.1">arXiv preprint arXiv:2406.02918</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
E. J. Hu, Y. Shen, P. Wallis, Z. Allen-Zhu, Y. Li, S. Wang, L. Wang, and W. Chen, “Lora: Low-rank adaptation of large language models,” <em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">arXiv preprint arXiv:2106.09685</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
L. Wu, J. Zhuang, and H. Chen, “Voco: A simple-yet-effective volume contrastive learning framework for 3d medical image analysis,” in <em class="ltx_emph ltx_font_italic" id="bib.bib28.1.1">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>, 2024, pp. 22 873–22 882.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
C. Wu, X. Zhang, Y. Zhang, Y. Wang, and W. Xie, “Medklip: Medical knowledge enhanced language-image pre-training for x-ray diagnosis,” in <em class="ltx_emph ltx_font_italic" id="bib.bib29.1.1">Proceedings of the IEEE/CVF International Conference on Computer Vision</em>, 2023, pp. 21 372–21 383.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
Y. Xie, Q. Chen, S. Wang, M.-S. To, I. Lee, E. W. Khoo, K. Hendy, D. Koh, Y. Xia, and Q. Wu, “Pairaug: What can augmented image-text pairs do for radiology?” in <em class="ltx_emph ltx_font_italic" id="bib.bib30.1.1">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>, 2024, pp. 11 652–11 661.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
B. Liu, D. Lu, D. Wei, X. Wu, Y. Wang, Y. Zhang, and Y. Zheng, “Improving medical vision-language contrastive pretraining with semantics-aware triage,” <em class="ltx_emph ltx_font_italic" id="bib.bib31.1.1">IEEE Transactions on Medical Imaging</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
C. Liu, S. Cheng, C. Chen, M. Qiao, W. Zhang, A. Shah, W. Bai, and R. Arcucci, “M-flag: Medical vision-language pre-training with frozen language models and latent space geometry optimization,” in <em class="ltx_emph ltx_font_italic" id="bib.bib32.1.1">International Conference on Medical Image Computing and Computer-Assisted Intervention</em>.   Springer, 2023, pp. 637–647.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
X. Zhang, C. Wu, Y. Zhang, W. Xie, and Y. Wang, “Knowledge-enhanced visual-language pre-training on chest radiology images,” <em class="ltx_emph ltx_font_italic" id="bib.bib33.1.1">Nature Communications</em>, vol. 14, no. 1, p. 4542, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
T. Jin, X. Xie, R. Wan, Q. Li, and Y. Wang, “Gene-induced multimodal pre-training for image-omic classification,” in <em class="ltx_emph ltx_font_italic" id="bib.bib34.1.1">International Conference on Medical Image Computing and Computer-Assisted Intervention</em>.   Springer, 2023, pp. 508–517.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
Y. Xie, J. Zhang, Y. Xia, and Q. Wu, “Unimiss: Universal medical self-supervised learning via breaking dimensionality barrier,” in <em class="ltx_emph ltx_font_italic" id="bib.bib35.1.1">European Conference on Computer Vision</em>.   Springer, 2022, pp. 558–575.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock">
Y. Zhang, J. Yang, J. Tian, Z. Shi, C. Zhong, Y. Zhang, and Z. He, “Modality-aware mutual learning for multi-modal medical image segmentation,” in <em class="ltx_emph ltx_font_italic" id="bib.bib36.1.1">Medical Image Computing and Computer Assisted Intervention–MICCAI 2021: 24th International Conference, Strasbourg, France, September 27–October 1, 2021, Proceedings, Part I 24</em>.   Springer, 2021, pp. 589–599.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock">
H. Yang, T. Zhou, Y. Zhou, Y. Zhang, and H. Fu, “Flexible fusion network for multi-modal brain tumor segmentation,” <em class="ltx_emph ltx_font_italic" id="bib.bib37.1.1">IEEE Journal of Biomedical and Health Informatics</em>, vol. 27, no. 7, pp. 3349–3359, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock">
W. Shao, T. Wang, L. Sun, T. Dong, Z. Han, Z. Huang, J. Zhang, D. Zhang, and K. Huang, “Multi-task multi-modal learning for joint diagnosis and prognosis of human cancers,” <em class="ltx_emph ltx_font_italic" id="bib.bib38.1.1">Medical image analysis</em>, vol. 65, p. 101795, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock">
P. Tang, X. Yan, Y. Nan, S. Xiang, S. Krammer, and T. Lasser, “Fusionm4net: A multi-stage multi-modal learning algorithm for multi-label skin lesion classification,” <em class="ltx_emph ltx_font_italic" id="bib.bib39.1.1">Medical Image Analysis</em>, vol. 76, p. 102307, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock">
W. Wang, H. Bao, L. Dong, J. Bjorck, Z. Peng, Q. Liu, K. Aggarwal, O. K. Mohammed, S. Singhal, S. Som <em class="ltx_emph ltx_font_italic" id="bib.bib40.1.1">et al.</em>, “Image as a foreign language: Beit pretraining for vision and vision-language tasks,” in <em class="ltx_emph ltx_font_italic" id="bib.bib40.2.2">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>, 2023, pp. 19 175–19 186.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock">
Z. Cai, L. Lin, H. He, and X. Tang, “Uni4eye: unified 2d and 3d self-supervised pre-training via masked image modeling transformer for ophthalmic image classification,” in <em class="ltx_emph ltx_font_italic" id="bib.bib41.1.1">International Conference on Medical Image Computing and Computer-Assisted Intervention</em>.   Springer, 2022, pp. 88–98.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock">
J. Chen, J. Mei, X. Li, Y. Lu, Q. Yu, Q. Wei, X. Luo, Y. Xie, E. Adeli, Y. Wang <em class="ltx_emph ltx_font_italic" id="bib.bib42.1.1">et al.</em>, “Transunet: Rethinking the u-net architecture design for medical image segmentation through the lens of transformers,” <em class="ltx_emph ltx_font_italic" id="bib.bib42.2.2">Medical Image Analysis</em>, p. 103280, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock">
J. Wei, M. Bosma, V. Zhao, K. Guu, A. W. Yu, B. Lester, N. Du, A. M. Dai, and Q. V. Le, “Finetuned language models are zero-shot learners,” in <em class="ltx_emph ltx_font_italic" id="bib.bib43.1.1">International Conference on Learning Representations</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_tag_bibitem">[44]</span>
<span class="ltx_bibblock">
K. Zhou, J. Yang, C. C. Loy, and Z. Liu, “Conditional prompt learning for vision-language models,” in <em class="ltx_emph ltx_font_italic" id="bib.bib44.1.1">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</em>, 2022, pp. 16 816–16 825.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_tag_bibitem">[45]</span>
<span class="ltx_bibblock">
C. Ge, R. Huang, M. Xie, Z. Lai, S. Song, S. Li, and G. Huang, “Domain adaptation via prompt learning,” <em class="ltx_emph ltx_font_italic" id="bib.bib45.1.1">IEEE Transactions on Neural Networks and Learning Systems</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib46">
<span class="ltx_tag ltx_tag_bibitem">[46]</span>
<span class="ltx_bibblock">
Z. Wang, Z. Zhang, C.-Y. Lee, H. Zhang, R. Sun, X. Ren, G. Su, V. Perot, J. Dy, and T. Pfister, “Learning to prompt for continual learning,” in <em class="ltx_emph ltx_font_italic" id="bib.bib46.1.1">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>, 2022, pp. 139–149.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib47">
<span class="ltx_tag ltx_tag_bibitem">[47]</span>
<span class="ltx_bibblock">
J. Wang, P. Zhou, M. Z. Shou, and S. Yan, “Position-guided text prompt for vision-language pre-training,” in <em class="ltx_emph ltx_font_italic" id="bib.bib47.1.1">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>, 2023, pp. 23 242–23 251.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib48">
<span class="ltx_tag ltx_tag_bibitem">[48]</span>
<span class="ltx_bibblock">
C.-M. Feng, B. Li, X. Xu, Y. Liu, H. Fu, and W. Zuo, “Learning federated visual prompt in null space for mri reconstruction,” in <em class="ltx_emph ltx_font_italic" id="bib.bib48.1.1">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>, 2023, pp. 8064–8073.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib49">
<span class="ltx_tag ltx_tag_bibitem">[49]</span>
<span class="ltx_bibblock">
P. Bilic, P. Christ, H. B. Li, E. Vorontsov, A. Ben-Cohen, G. Kaissis, A. Szeskin, C. Jacobs, G. E. H. Mamani, G. Chartrand <em class="ltx_emph ltx_font_italic" id="bib.bib49.1.1">et al.</em>, “The liver tumor segmentation benchmark (lits),” <em class="ltx_emph ltx_font_italic" id="bib.bib49.2.2">Medical Image Analysis</em>, vol. 84, p. 102680, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib50">
<span class="ltx_tag ltx_tag_bibitem">[50]</span>
<span class="ltx_bibblock">
N. Heller, F. Isensee, K. H. Maier-Hein, X. Hou, C. Xie, F. Li, Y. Nan, G. Mu, Z. Lin, M. Han <em class="ltx_emph ltx_font_italic" id="bib.bib50.1.1">et al.</em>, “The state of the art in kidney and kidney tumor segmentation in contrast-enhanced ct imaging: Results of the kits19 challenge,” <em class="ltx_emph ltx_font_italic" id="bib.bib50.2.2">Medical image analysis</em>, vol. 67, p. 101821, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib51">
<span class="ltx_tag ltx_tag_bibitem">[51]</span>
<span class="ltx_bibblock">
M. Antonelli, A. Reinke, S. Bakas, K. Farahani, A. Kopp-Schneider, B. A. Landman, G. Litjens, B. Menze, O. Ronneberger, R. M. Summers <em class="ltx_emph ltx_font_italic" id="bib.bib51.1.1">et al.</em>, “The medical segmentation decathlon,” <em class="ltx_emph ltx_font_italic" id="bib.bib51.2.2">Nature communications</em>, vol. 13, no. 1, p. 4128, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib52">
<span class="ltx_tag ltx_tag_bibitem">[52]</span>
<span class="ltx_bibblock">
A. Sekuboyina, M. E. Husseini, A. Bayat, M. Löffler, H. Liebl, H. Li, G. Tetteh, J. Kukačka, C. Payer, D. Štern <em class="ltx_emph ltx_font_italic" id="bib.bib52.1.1">et al.</em>, “Verse: A vertebrae labelling and segmentation benchmark for multi-detector ct images,” <em class="ltx_emph ltx_font_italic" id="bib.bib52.2.2">Medical image analysis</em>, vol. 73, p. 102166, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib53">
<span class="ltx_tag ltx_tag_bibitem">[53]</span>
<span class="ltx_bibblock">
B. Nicholas, M. Anant, H. Henkjan, F. John, K. Justin <em class="ltx_emph ltx_font_italic" id="bib.bib53.1.1">et al.</em>, “Nci-proc. ieee-isbi conf. 2013 challenge: Automated segmentation of prostate structures,” <em class="ltx_emph ltx_font_italic" id="bib.bib53.2.2">The Cancer Imaging Archive</em>, vol. 5, 2015.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib54">
<span class="ltx_tag ltx_tag_bibitem">[54]</span>
<span class="ltx_bibblock">
G. Lemaître, R. Martí, J. Freixenet, J. C. Vilanova, P. M. Walker, and F. Meriaudeau, “Computer-aided detection and diagnosis for prostate cancer based on mono and multi-parametric mri: a review,” <em class="ltx_emph ltx_font_italic" id="bib.bib54.1.1">Computers in biology and medicine</em>, vol. 60, pp. 8–31, 2015.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib55">
<span class="ltx_tag ltx_tag_bibitem">[55]</span>
<span class="ltx_bibblock">
G. Litjens, R. Toth, W. Van De Ven, C. Hoeks, S. Kerkstra, B. Van Ginneken, G. Vincent, G. Guillard, N. Birbeck, J. Zhang <em class="ltx_emph ltx_font_italic" id="bib.bib55.1.1">et al.</em>, “Evaluation of prostate segmentation algorithms for mri: the promise12 challenge,” <em class="ltx_emph ltx_font_italic" id="bib.bib55.2.2">Medical image analysis</em>, vol. 18, no. 2, pp. 359–373, 2014.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib56">
<span class="ltx_tag ltx_tag_bibitem">[56]</span>
<span class="ltx_bibblock">
U. Baid, S. Ghodasara, S. Mohan, M. Bilello, E. Calabrese, E. Colak, K. Farahani, J. Kalpathy-Cramer, F. C. Kitamura, S. Pati <em class="ltx_emph ltx_font_italic" id="bib.bib56.1.1">et al.</em>, “The rsna-asnr-miccai brats 2021 benchmark on brain tumor segmentation and radiogenomic classification,” <em class="ltx_emph ltx_font_italic" id="bib.bib56.2.2">arXiv preprint arXiv:2107.02314</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib57">
<span class="ltx_tag ltx_tag_bibitem">[57]</span>
<span class="ltx_bibblock">
S. Gatidis, T. Hepp, M. Früh, C. La Fougère, K. Nikolaou, C. Pfannenberg, B. Schölkopf, T. Küstner, C. Cyran, and D. Rubin, “A whole-body fdg-pet/ct dataset with manually annotated tumor lesions,” <em class="ltx_emph ltx_font_italic" id="bib.bib57.1.1">Scientific Data</em>, vol. 9, no. 1, p. 601, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib58">
<span class="ltx_tag ltx_tag_bibitem">[58]</span>
<span class="ltx_bibblock">
N. Codella, V. Rotemberg, P. Tschandl, M. E. Celebi, S. Dusza, D. Gutman, B. Helba, A. Kalloo, K. Liopyris, M. Marchetti <em class="ltx_emph ltx_font_italic" id="bib.bib58.1.1">et al.</em>, “Skin lesion analysis toward melanoma detection 2018: A challenge hosted by the international skin imaging collaboration (isic),” <em class="ltx_emph ltx_font_italic" id="bib.bib58.2.2">arXiv preprint arXiv:1902.03368</em>, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib59">
<span class="ltx_tag ltx_tag_bibitem">[59]</span>
<span class="ltx_bibblock">
H. Fang, F. Li, J. Wu, H. Fu, X. Sun, J. Son, S. Yu, M. Zhang, C. Yuan, C. Bian <em class="ltx_emph ltx_font_italic" id="bib.bib59.1.1">et al.</em>, “Refuge2 challenge: A treasure trove for multi-dimension analysis and evaluation in glaucoma screening,” <em class="ltx_emph ltx_font_italic" id="bib.bib59.2.2">arXiv preprint arXiv:2202.08994</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib60">
<span class="ltx_tag ltx_tag_bibitem">[60]</span>
<span class="ltx_bibblock">
K. Sirinukunwattana, J. P. Pluim, H. Chen, X. Qi, P.-A. Heng, Y. B. Guo, L. Y. Wang, B. J. Matuszewski, E. Bruni, U. Sanchez <em class="ltx_emph ltx_font_italic" id="bib.bib60.1.1">et al.</em>, “Gland segmentation in colon histology images: The glas challenge contest,” <em class="ltx_emph ltx_font_italic" id="bib.bib60.2.2">Medical image analysis</em>, vol. 35, pp. 489–502, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib61">
<span class="ltx_tag ltx_tag_bibitem">[61]</span>
<span class="ltx_bibblock">
W. Al-Dhabyani, M. Gomaa, H. Khaled, and A. Fahmy, “Dataset of breast ultrasound images,” <em class="ltx_emph ltx_font_italic" id="bib.bib61.1.1">Data in brief</em>, vol. 28, p. 104863, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib62">
<span class="ltx_tag ltx_tag_bibitem">[62]</span>
<span class="ltx_bibblock">
A. Degerli, S. Kiranyaz, M. E. Chowdhury, and M. Gabbouj, “Osegnet: Operational segmentation network for covid-19 detection using chest x-ray images,” in <em class="ltx_emph ltx_font_italic" id="bib.bib62.1.1">ICIP</em>.   IEEE, 2022, pp. 2306–2310.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib63">
<span class="ltx_tag ltx_tag_bibitem">[63]</span>
<span class="ltx_bibblock">
D.-P. Fan, G.-P. Ji, T. Zhou, G. Chen, H. Fu, J. Shen, and L. Shao, “Pranet: Parallel reverse attention network for polyp segmentation,” in <em class="ltx_emph ltx_font_italic" id="bib.bib63.1.1">International conference on medical image computing and computer-assisted intervention</em>.   Springer, 2020, pp. 263–273.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib64">
<span class="ltx_tag ltx_tag_bibitem">[64]</span>
<span class="ltx_bibblock">
D. Jha, P. H. Smedsrud, M. A. Riegler, P. Halvorsen, T. De Lange, D. Johansen, and H. D. Johansen, “Kvasir-seg: A segmented polyp dataset,” in <em class="ltx_emph ltx_font_italic" id="bib.bib64.1.1">MultiMedia Modeling: 26th International Conference, MMM 2020, Daejeon, South Korea, January 5–8, 2020, Proceedings, Part II 26</em>.   Springer, 2020, pp. 451–462.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib65">
<span class="ltx_tag ltx_tag_bibitem">[65]</span>
<span class="ltx_bibblock">
J. Bernal, F. J. Sánchez, G. Fernández-Esparrach, D. Gil, C. Rodríguez, and F. Vilariño, “Wm-dova maps for accurate polyp highlighting in colonoscopy: Validation vs. saliency maps from physicians,” <em class="ltx_emph ltx_font_italic" id="bib.bib65.1.1">Computerized medical imaging and graphics</em>, vol. 43, pp. 99–111, 2015.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib66">
<span class="ltx_tag ltx_tag_bibitem">[66]</span>
<span class="ltx_bibblock">
N. Tajbakhsh, S. R. Gurudu, and J. Liang, “Automated polyp detection in colonoscopy videos using shape and context information,” <em class="ltx_emph ltx_font_italic" id="bib.bib66.1.1">IEEE transactions on medical imaging</em>, vol. 35, no. 2, pp. 630–644, 2015.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib67">
<span class="ltx_tag ltx_tag_bibitem">[67]</span>
<span class="ltx_bibblock">
J. Silva, A. Histace, O. Romain, X. Dray, and B. Granado, “Toward embedded detection of polyps in wce images for early diagnosis of colorectal cancer,” <em class="ltx_emph ltx_font_italic" id="bib.bib67.1.1">International journal of computer assisted radiology and surgery</em>, vol. 9, pp. 283–293, 2014.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib68">
<span class="ltx_tag ltx_tag_bibitem">[68]</span>
<span class="ltx_bibblock">
J. Bernal, J. Sánchez, and F. Vilarino, “Towards automatic polyp detection with a polyp appearance model,” <em class="ltx_emph ltx_font_italic" id="bib.bib68.1.1">Pattern Recognition</em>, vol. 45, no. 9, pp. 3166–3182, 2012.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib69">
<span class="ltx_tag ltx_tag_bibitem">[69]</span>
<span class="ltx_bibblock">
B. Landman, Z. Xu, J. Igelsias, M. Styner, T. Langerak, and A. Klein, “Miccai multi-atlas labeling beyond the cranial vault–workshop and challenge,” in <em class="ltx_emph ltx_font_italic" id="bib.bib69.1.1">Proc. MICCAI Multi-Atlas Labeling Beyond Cranial Vault—Workshop Challenge</em>, vol. 5, 2015, p. 12.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib70">
<span class="ltx_tag ltx_tag_bibitem">[70]</span>
<span class="ltx_bibblock">
H. R. Roth, Z. Xu, C. Tor-Díez, R. S. Jacob, J. Zember, J. Molto, W. Li, S. Xu, B. Turkbey, E. Turkbey <em class="ltx_emph ltx_font_italic" id="bib.bib70.1.1">et al.</em>, “Rapid artificial intelligence solutions in a pandemic—the covid-19-20 lung ct lesion segmentation challenge,” <em class="ltx_emph ltx_font_italic" id="bib.bib70.2.2">Medical image analysis</em>, vol. 82, p. 102605, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib71">
<span class="ltx_tag ltx_tag_bibitem">[71]</span>
<span class="ltx_bibblock">
J. Shapey, A. Kujawa, R. Dorent, G. Wang, A. Dimitriadis, D. Grishchuk, I. Paddick, N. Kitchen, R. Bradford, S. R. Saeed <em class="ltx_emph ltx_font_italic" id="bib.bib71.1.1">et al.</em>, “Segmentation of vestibular schwannoma from mri, an open annotated dataset and baseline algorithm,” <em class="ltx_emph ltx_font_italic" id="bib.bib71.2.2">Scientific Data</em>, vol. 8, no. 1, p. 286, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib72">
<span class="ltx_tag ltx_tag_bibitem">[72]</span>
<span class="ltx_bibblock">
A. Z. et al., “Siim-acr pneumothorax segmentation,” 2019. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://kaggle.com/competitions/siim-acr-pneumothorax-segmentation" title="">https://kaggle.com/competitions/siim-acr-pneumothorax-segmentation</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib73">
<span class="ltx_tag ltx_tag_bibitem">[73]</span>
<span class="ltx_bibblock">
S.-C. Huang, L. Shen, M. P. Lungren, and S. Yeung, “Gloria: A multimodal global-local representation learning framework for label-efficient medical image recognition,” in <em class="ltx_emph ltx_font_italic" id="bib.bib73.1.1">Proceedings of the IEEE/CVF International Conference on Computer Vision</em>, 2021, pp. 3942–3951.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib74">
<span class="ltx_tag ltx_tag_bibitem">[74]</span>
<span class="ltx_bibblock">
P. Porwal, S. Pachade, R. Kamble, M. Kokare, G. Deshmukh, V. Sahasrabuddhe, and F. Meriaudeau, “Indian diabetic retinopathy image dataset (idrid): a database for diabetic retinopathy screening research,” <em class="ltx_emph ltx_font_italic" id="bib.bib74.1.1">Data</em>, vol. 3, no. 3, p. 25, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib75">
<span class="ltx_tag ltx_tag_bibitem">[75]</span>
<span class="ltx_bibblock">
A. Bozorgpour, R. Azad, E. Showkatian, and A. Sulaiman, “Multi-scale regional attention deeplab3+: Multiple myeloma plasma cells segmentation in microscopic images,” <em class="ltx_emph ltx_font_italic" id="bib.bib75.1.1">arXiv preprint arXiv:2105.06238</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib76">
<span class="ltx_tag ltx_tag_bibitem">[76]</span>
<span class="ltx_bibblock">
H.-Y. Zhou, J. Guo, Y. Zhang, X. Han, L. Yu, L. Wang, and Y. Yu, “nnformer: Volumetric medical image segmentation via a 3d transformer,” <em class="ltx_emph ltx_font_italic" id="bib.bib76.1.1">IEEE Transactions on Image Processing</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib77">
<span class="ltx_tag ltx_tag_bibitem">[77]</span>
<span class="ltx_bibblock">
Y. Xie, J. Zhang, C. Shen, and Y. Xia, “Cotr: Efficiently bridging cnn and transformer for 3d medical image segmentation,” in <em class="ltx_emph ltx_font_italic" id="bib.bib77.1.1">Medical Image Computing and Computer Assisted Intervention–MICCAI 2021: 24th International Conference, Strasbourg, France, September 27–October 1, 2021, Proceedings, Part III 24</em>.   Springer, 2021, pp. 171–180.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib78">
<span class="ltx_tag ltx_tag_bibitem">[78]</span>
<span class="ltx_bibblock">
H. H. Lee, S. Bao, Y. Huo, and B. A. Landman, “3d UX-net: A large kernel volumetric convnet modernizing hierarchical transformer for medical image segmentation,” in <em class="ltx_emph ltx_font_italic" id="bib.bib78.1.1">The Eleventh International Conference on Learning Representations</em>, 2023. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://openreview.net/forum?id=wsZsjOSytRA" title="">https://openreview.net/forum?id=wsZsjOSytRA</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib79">
<span class="ltx_tag ltx_tag_bibitem">[79]</span>
<span class="ltx_bibblock">
Y. Tang, D. Yang, W. Li, H. R. Roth, B. Landman, D. Xu, V. Nath, and A. Hatamizadeh, “Self-supervised pre-training of swin transformers for 3d medical image analysis,” in <em class="ltx_emph ltx_font_italic" id="bib.bib79.1.1">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</em>, 2022, pp. 20 730–20 740.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib80">
<span class="ltx_tag ltx_tag_bibitem">[80]</span>
<span class="ltx_bibblock">
Q. Guan, Y. Xie, B. Yang, J. Zhang, Z. Liao, Q. Wu, and Y. Xia, “Unpaired cross-modal interaction learning for covid-19 segmentation on limited ct images,” in <em class="ltx_emph ltx_font_italic" id="bib.bib80.1.1">International Conference on Medical Image Computing and Computer-Assisted Intervention</em>.   Springer, 2023, pp. 603–613.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib81">
<span class="ltx_tag ltx_tag_bibitem">[81]</span>
<span class="ltx_bibblock">
Z. Zhou, V. Sodha, J. Pang, M. B. Gotway, and J. Liang, “Models genesis,” <em class="ltx_emph ltx_font_italic" id="bib.bib81.1.1">Medical image analysis</em>, vol. 67, p. 101840, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib82">
<span class="ltx_tag ltx_tag_bibitem">[82]</span>
<span class="ltx_bibblock">
Y. He, G. Yang, R. Ge, Y. Chen, J.-L. Coatrieux, B. Wang, and S. Li, “Geometric visual similarity learning in 3d medical image self-supervised pre-training,” in <em class="ltx_emph ltx_font_italic" id="bib.bib82.1.1">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>, 2023, pp. 9538–9547.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib83">
<span class="ltx_tag ltx_tag_bibitem">[83]</span>
<span class="ltx_bibblock">
Y. Ye, J. Zhang, Z. Chen, and Y. Xia, “Desd: self-supervised learning with deep self-distillation for 3d medical image segmentation,” in <em class="ltx_emph ltx_font_italic" id="bib.bib83.1.1">International Conference on Medical Image Computing and Computer-Assisted Intervention</em>.   Springer, 2022, pp. 545–555.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib84">
<span class="ltx_tag ltx_tag_bibitem">[84]</span>
<span class="ltx_bibblock">
J. Jiang, N. Tyagi, K. Tringale, C. Crane, and H. Veeraraghavan, “Self-supervised 3d anatomy segmentation using self-distilled masked image transformer (smit),” in <em class="ltx_emph ltx_font_italic" id="bib.bib84.1.1">International Conference on Medical Image Computing and Computer-Assisted Intervention</em>.   Springer, 2022, pp. 556–566.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib85">
<span class="ltx_tag ltx_tag_bibitem">[85]</span>
<span class="ltx_bibblock">
M. Kang, H. Song, S. Park, D. Yoo, and S. Pereira, “Benchmarking self-supervised learning on diverse pathology datasets,” in <em class="ltx_emph ltx_font_italic" id="bib.bib85.1.1">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>, 2023, pp. 3344–3354.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib86">
<span class="ltx_tag ltx_tag_bibitem">[86]</span>
<span class="ltx_bibblock">
H.-Y. Zhou, C. Lu, C. Chen, S. Yang, and Y. Yu, “A unified visual information preservation framework for self-supervised pre-training in medical image analysis,” <em class="ltx_emph ltx_font_italic" id="bib.bib86.1.1">IEEE Transactions on Pattern Analysis and Machine Intelligence</em>, vol. 45, no. 7, pp. 8020–8035, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib87">
<span class="ltx_tag ltx_tag_bibitem">[87]</span>
<span class="ltx_bibblock">
Z. Liu, Y. Lin, Y. Cao, H. Hu, Y. Wei, Z. Zhang, S. Lin, and B. Guo, “Swin transformer: Hierarchical vision transformer using shifted windows,” in <em class="ltx_emph ltx_font_italic" id="bib.bib87.1.1">Proceedings of the IEEE/CVF international conference on computer vision</em>, 2021, pp. 10 012–10 022.

</span>
</li>
</ul>
</section>
<figure class="ltx_float biography" id="id2">
<table class="ltx_tabular" id="id2.1">
<tr class="ltx_tr" id="id2.1.1">
<td class="ltx_td" id="id2.1.1.1"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_portrait" height="125" id="id2.1.1.1.g1" src="extracted/5910197/Image/Yiwen_Ye.jpg" width="90"/></td>
<td class="ltx_td" id="id2.1.1.2">
<span class="ltx_inline-block" id="id2.1.1.2.1">
<span class="ltx_p" id="id2.1.1.2.1.1"><span class="ltx_text ltx_font_bold" id="id2.1.1.2.1.1.1">Yiwen Ye</span> 
received his B.E. degree in computer science and technology in 2021 from Hebei University of Technology, Tianjin, China. He is currently working toward the Ph.D. degree at the School of Computer Science and Engineering, Northwestern Polytechnical University (NPU), Xi’an, China. His research interests include universal segmentation models and representation learning.
Biography text here.</span>
</span>
</td>
</tr>
</table>
</figure>
<figure class="ltx_float biography" id="id3">
<table class="ltx_tabular" id="id3.1">
<tr class="ltx_tr" id="id3.1.1">
<td class="ltx_td" id="id3.1.1.1"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_portrait" height="125" id="id3.1.1.1.g1" src="extracted/5910197/Image/zychen.jpg" width="88"/></td>
<td class="ltx_td" id="id3.1.1.2">
<span class="ltx_inline-block" id="id3.1.1.2.1">
<span class="ltx_p" id="id3.1.1.2.1.1"><span class="ltx_text ltx_font_bold" id="id3.1.1.2.1.1.1">Ziyang Chen</span> 
received his B.E. degree in biological technology in 2021 from Northwestern Polytechnical University, Xi’an, China. He is currently working toward the Ph.D. degree at the School of Computer Science and Engineering, Northwestern Polytechnical University, Xi’an, China. His research interests include domain adaptation and domain generalization.</span>
</span>
</td>
</tr>
</table>
</figure>
<figure class="ltx_float biography" id="id4">
<table class="ltx_tabular" id="id4.1">
<tr class="ltx_tr" id="id4.1.1">
<td class="ltx_td" id="id4.1.1.1"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="113" id="id4.1.1.1.g1" src="extracted/5910197/Image/jpzhang.png" width="100"/></td>
<td class="ltx_td" id="id4.1.1.2">
<span class="ltx_inline-block" id="id4.1.1.2.1">
<span class="ltx_p" id="id4.1.1.2.1.1"><span class="ltx_text ltx_font_bold" id="id4.1.1.2.1.1.1">Jianpeng Zhang</span> 
received the PhD degree in Computer Science and Technology from Northwestern Polytechnical University, China, in 2022. His research interests mainly focus on deep learning technologies for intelligent medical image analysis, especially medical vision-language learning, self-supervised learning, partial label learning, and weakly supervised learning.</span>
</span>
</td>
</tr>
</table>
</figure>
<figure class="ltx_float biography" id="id5">
<table class="ltx_tabular" id="id5.1">
<tr class="ltx_tr" id="id5.1.1">
<td class="ltx_td" id="id5.1.1.1"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="117" id="id5.1.1.1.g1" src="extracted/5910197/Image/ytxie.jpg" width="100"/></td>
<td class="ltx_td" id="id5.1.1.2">
<span class="ltx_inline-block" id="id5.1.1.2.1">
<span class="ltx_p" id="id5.1.1.2.1.1"><span class="ltx_text ltx_font_bold" id="id5.1.1.2.1.1.1">Yutong Xie</span> 
received her B.E. degree in 2016 and her Ph.D. in 2021 from Northwestern Polytechnical University (NPU), Xi’an, China. She is currently a Senior Research Fellow at the University of Adelaide (UoA) and a member of the Australian Institute for Machine Learning (AIML). Her research primarily focuses on computer vision and data analytics within the healthcare sector, aiming to develop intelligent solutions to assist healthcare professionals in anatomical structure segmentation, disease diagnosis, and therapy.</span>
</span>
</td>
</tr>
</table>
</figure>
<figure class="ltx_float biography" id="id6">
<table class="ltx_tabular" id="id6.1">
<tr class="ltx_tr" id="id6.1.1">
<td class="ltx_td" id="id6.1.1.1"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="123" id="id6.1.1.1.g1" src="extracted/5910197/Image/yxia.jpg" width="100"/></td>
<td class="ltx_td" id="id6.1.1.2">
<span class="ltx_inline-block" id="id6.1.1.2.1">
<span class="ltx_p" id="id6.1.1.2.1.1"><span class="ltx_text ltx_font_bold" id="id6.1.1.2.1.1.1">Yong Xia</span> (S’05-M’08) received his B.E., M.E., and Ph.D. degrees in computer science and technology from Northwestern Polytechnical University (NPU), Xi’an, China, in 2001, 2004, and 2007, respectively. He is currently a Professor at the School of Computer Science and Engineering, NPU. His research interests include medical image analysis, computer-aided diagnosis, pattern recognition, machine learning, and data mining.</span>
</span>
</td>
</tr>
</table>
</figure>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Tue Oct  8 10:58:29 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
