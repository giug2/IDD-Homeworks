<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2403.15855] Initialisation and Topology Effects in Decentralised Federated Learning</title><meta property="og:description" content="Fully decentralised federated learning enables collaborative training of individual machine learning models on distributed devices on a network while keeping the training data localised. This approach enhances data pri…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Initialisation and Topology Effects in Decentralised Federated Learning">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Initialisation and Topology Effects in Decentralised Federated Learning">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2403.15855">

<!--Generated on Fri Apr  5 16:46:46 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content="Decentralised Federated learning,  Distributed Machine Learning,  Complex Networks">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_pruned_first">
<h1 class="ltx_title ltx_title_document">Initialisation and Topology Effects in Decentralised Federated Learning</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Arash Badie-Modiri
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Chiara Boldrini
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Lorenzo Valerio
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">János Kertész
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Márton Karsai
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id1.id1" class="ltx_p">Fully decentralised federated learning enables collaborative training of individual machine learning models on distributed devices on a network while keeping the training data localised. This approach enhances data privacy and eliminates both the single point of failure and the necessity for central coordination. Our research highlights that the effectiveness of decentralised federated learning is significantly influenced by the network topology of connected devices. A simplified numerical model for studying the early behaviour of these systems leads us to an improved artificial neural network initialisation strategy, which leverages the distribution of eigenvector centralities of the nodes of the underlying network, leading to a radically improved training efficiency. Additionally, our study explores the scaling behaviour and choice of environmental parameters under our proposed initialisation strategy. This work paves the way for more efficient and scalable artificial neural network training in a distributed and uncoordinated environment, offering a deeper understanding of the intertwining roles of network structure and learning dynamics.</p>
</div>
<div class="ltx_keywords">Decentralised Federated learning, Distributed Machine Learning, Complex Networks
</div>
<div id="p2" class="ltx_para">
<br class="ltx_break">
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">The traditional centralised approach to machine learning has shown great promise and has seen considerable progress in the last few decades. This approach, while practical, comes at a cost in terms of systemic data privacy risks and centralisation overhead <cite class="ltx_cite ltx_citemacro_citep">(McMahan et al., <a href="#bib.bib26" title="" class="ltx_ref">2017</a>; Kairouz et al., <a href="#bib.bib18" title="" class="ltx_ref">2021</a>; Rieke et al., <a href="#bib.bib35" title="" class="ltx_ref">2020</a>)</cite>. To alleviate these issues, the <em id="S1.p1.1.1" class="ltx_emph ltx_font_italic">federated learning</em> framework was proposed where each node (client) updates a local machine learning model using local data and only shares its model parameters with a centralised server, which in turn aggregates these individual models into one model and redistributes it to each node <cite class="ltx_cite ltx_citemacro_citep">(McMahan et al., <a href="#bib.bib26" title="" class="ltx_ref">2017</a>)</cite>.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">While this approach reduces the data privacy risk by eliminating data sharing with the centralised server, it still maintains a singular point of failure and puts a heavy communication burden on the central server node <cite class="ltx_cite ltx_citemacro_citep">(Beltrán et al., <a href="#bib.bib5" title="" class="ltx_ref">2023</a>; Lalitha et al., <a href="#bib.bib20" title="" class="ltx_ref">2018</a>)</cite>. <em id="S1.p2.1.1" class="ltx_emph ltx_font_italic">Decentralised federated learning</em> aims to provide an alternative approach that maintains data privacy but removes the need for a centralised server. This involves the set of nodes (clients) updating their local models based on the local data, but directly communicating with one another through a communication network. Each node then updates its local model by aggregating those of the neighbourhood <cite class="ltx_cite ltx_citemacro_citep">(Beltrán et al., <a href="#bib.bib5" title="" class="ltx_ref">2023</a>; Valerio et al., <a href="#bib.bib40" title="" class="ltx_ref">2023</a>)</cite>. The efficiency of this approach is impacted by several kinds of inhomogeneities <cite class="ltx_cite ltx_citemacro_citep">(Valerio et al., <a href="#bib.bib40" title="" class="ltx_ref">2023</a>)</cite> characterising the network structure, initial conditions, learning data, and temporal irregularities. In this paper, we focus on the first two of these.</p>
</div>
<section id="S1.SS0.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Motivation.</h4>

<div id="S1.SS0.SSS0.Px1.p1" class="ltx_para">
<p id="S1.SS0.SSS0.Px1.p1.1" class="ltx_p">Decentralised federated learning immediately raises two distinct new issues compared to the centralised federated learning approach. First, <span id="S1.SS0.SSS0.Px1.p1.1.1" class="ltx_text ltx_font_bold">that the initialisation and operations of the nodes have to be performed in an uncoordinated manner</span>, as the role of coordination previously lay with the server.
Second, <span id="S1.SS0.SSS0.Px1.p1.1.2" class="ltx_text ltx_font_bold">that the effect of structure and possible heterogeneities in the communication network structure is poorly understood</span>. In the case of centralised federated learning, the communication network is organised as a simple star graph. In a decentralised setting, however, the network might be an emergent result of, e.g., the social network of the users of the devices, a distributed peer-discovery protocol or a hand-engineered topology comprising of IoT devices. Each of these assumptions leads to a different network topology with wildly different characteristics. Many network topologies modelling real-world phenomena, unlike a star graph, have diameters that monotonically scale up with the number of nodes, inducing an inherent latency in the communication of information between nodes that are not directly connected. Structural heterogeneities, e.g., the dimensionality of the network, degree heterogeneity and heterogeneities in other centrality measures also play important roles in the evolution of the information-sharing processes on networks. This makes network heterogeneities primary candidates for analysis of any decentralised system.</p>
</div>
</section>
<section id="S1.SS0.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Contribution.</h4>

<div id="S1.SS0.SSS0.Px2.p1" class="ltx_para">
<p id="S1.SS0.SSS0.Px2.p1.1" class="ltx_p">In this manuscript, we focus on these two issues: we show that without prior coordination the standard method of artificial neural network initialisation results in subpar performance when training deep neural networks, and propose an alternative uncoordinated neural network initialisation method to resolve this issue. We then present an analysis of the effect of network topology on the proposed initialisation process and demonstrate how it affects the scaling properties of the system.</p>
</div>
</section>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related works</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">Decentralised federated learning <cite class="ltx_cite ltx_citemacro_citep">(Beltrán et al., <a href="#bib.bib5" title="" class="ltx_ref">2023</a>)</cite> comes as a natural next step in the development of the field of federated learning since the introduction of this method <cite class="ltx_cite ltx_citemacro_citep">(McMahan et al., <a href="#bib.bib26" title="" class="ltx_ref">2017</a>)</cite>. This approach has been used in application areas such as object recognition in medical images <cite class="ltx_cite ltx_citemacro_citep">(Roy et al., <a href="#bib.bib36" title="" class="ltx_ref">2019</a>; Tedeschini et al., <a href="#bib.bib39" title="" class="ltx_ref">2022</a>)</cite> and other industrial settings <cite class="ltx_cite ltx_citemacro_citep">(Savazzi et al., <a href="#bib.bib37" title="" class="ltx_ref">2021</a>; Qu et al., <a href="#bib.bib33" title="" class="ltx_ref">2020</a>)</cite>. It also has been extended with novel optimisation and aggregation methods <cite class="ltx_cite ltx_citemacro_citep">(Sun et al., <a href="#bib.bib38" title="" class="ltx_ref">2022</a>; Lalitha et al., <a href="#bib.bib20" title="" class="ltx_ref">2018</a>)</cite>.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p">The structure of complex networks, central to federated learning by coding the communication structure between connected devices, can embody various heterogeneities. They have been found to be a crucial factor in understanding a variety of <em id="S2.p2.1.1" class="ltx_emph ltx_font_italic">complex systems</em> that involve many entities communicating or interacting together. For example, the role of degree distribution <cite class="ltx_cite ltx_citemacro_citep">(Jennings, <a href="#bib.bib17" title="" class="ltx_ref">1937</a>; Albert et al., <a href="#bib.bib1" title="" class="ltx_ref">2000</a>)</cite>, high clustering <cite class="ltx_cite ltx_citemacro_citep">(Watts &amp; Strogatz, <a href="#bib.bib42" title="" class="ltx_ref">1998</a>; Luce &amp; Perry, <a href="#bib.bib25" title="" class="ltx_ref">1949</a>)</cite> or existence of flat or hierarchical community structures <cite class="ltx_cite ltx_citemacro_citep">(Rice, <a href="#bib.bib34" title="" class="ltx_ref">1927</a>; Fortunato &amp; Hric, <a href="#bib.bib9" title="" class="ltx_ref">2016</a>)</cite> in networks of real-world phenomena has been understood and analysed for decades. Recent advances in network modelling have extended heterogeneities in networks from structural to incorporate spatial <cite class="ltx_cite ltx_citemacro_citep">(Orsini et al., <a href="#bib.bib29" title="" class="ltx_ref">2015</a>)</cite> and also temporal heterogeneities, induced by patterns of, e.g., spatial constraints or bursty or self-exciting activity of the nodes <cite class="ltx_cite ltx_citemacro_citep">(Karsai et al., <a href="#bib.bib19" title="" class="ltx_ref">2011</a>; Gauvin et al., <a href="#bib.bib11" title="" class="ltx_ref">2022</a>; Badie-Modiri et al., <a href="#bib.bib2" title="" class="ltx_ref">2022a</a>, <a href="#bib.bib3" title="" class="ltx_ref">b</a>)</cite>. In the decentralised federated learning settings, the matter of structural heterogeneities of the underlying communication network has only been very recently subjected to systemic studies. Notably, <cite class="ltx_cite ltx_citemacro_citet">Vogels et al. (<a href="#bib.bib41" title="" class="ltx_ref">2022</a>)</cite> analyse the effect of topology on optimal learning rate and <cite class="ltx_cite ltx_citemacro_citet">Palmieri et al. (<a href="#bib.bib30" title="" class="ltx_ref">2023</a>)</cite> analyse the differences among individual training curves of specific nodes (e.g., high-degree hubs versus peripheries) for Barabási–Albert networks and stochastic block models with two blocks <cite class="ltx_cite ltx_citemacro_citep">(Newman, <a href="#bib.bib27" title="" class="ltx_ref">2010</a>)</cite>.</p>
</div>
<div id="S2.p3" class="ltx_para">
<p id="S2.p3.1" class="ltx_p">On the matter of parameter initialisation in federated learning, recent studies have focused on the effect of starting all nodes from a homogeneous set of parameters <cite class="ltx_cite ltx_citemacro_citep">(Valerio et al., <a href="#bib.bib40" title="" class="ltx_ref">2023</a>)</cite> or the parameters of an independently pre-trained model <cite class="ltx_cite ltx_citemacro_citep">(Nguyen et al., <a href="#bib.bib28" title="" class="ltx_ref">2022</a>)</cite>. Historically, artificial neural networks were initialised from random uniform or Gaussian distribution with scales set based on heuristics and trial and error <cite class="ltx_cite ltx_citemacro_citep">(Goodfellow et al., <a href="#bib.bib13" title="" class="ltx_ref">2016</a>)</cite> or for specific activation functions <cite class="ltx_cite ltx_citemacro_citep">(LeCun et al., <a href="#bib.bib22" title="" class="ltx_ref">2002</a>)</cite>. The advent of much deeper architectures and widespread use of non-linear activation functions such as ReLU or Tanh led to a methodical understanding of the role of initial parameters to avoid exploding or diminishing activations and gradients. <cite class="ltx_cite ltx_citemacro_citet">Glorot &amp; Bengio (<a href="#bib.bib12" title="" class="ltx_ref">2010</a>)</cite> proposed a method based on certain simplifying assumptions about the non-linearities used. Later, <cite class="ltx_cite ltx_citemacro_citet">He et al. (<a href="#bib.bib14" title="" class="ltx_ref">2015</a>)</cite> defined a more general framework for use with a wider variety of non-linearities, which was used for training the ResNet image recognition model <cite class="ltx_cite ltx_citemacro_citep">(He et al., <a href="#bib.bib15" title="" class="ltx_ref">2016</a>)</cite>.</p>
</div>
<div id="S2.p4" class="ltx_para">
<p id="S2.p4.1" class="ltx_p">In this work, we will be extending the same approach for effective initialisation of artificial neural network parameters to the decentralised setting, where the parameters are not only affected by the optimisation based on the training data but also due to interactions with other nodes of the communication network.</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Preliminaries</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">In our setup, we used a simple decentralised federated learning system with an iterative process. All nodes use the same artificial neural network architecture. Nodes are connected through a predetermined static, undirected communication network <math id="S3.p1.1.m1.1" class="ltx_Math" alttext="G" display="inline"><semantics id="S3.p1.1.m1.1a"><mi id="S3.p1.1.m1.1.1" xref="S3.p1.1.m1.1.1.cmml">G</mi><annotation-xml encoding="MathML-Content" id="S3.p1.1.m1.1b"><ci id="S3.p1.1.m1.1.1.cmml" xref="S3.p1.1.m1.1.1">𝐺</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.1.m1.1c">G</annotation></semantics></math>. Nodes initialise their local model parameters based on one of the following strategies: (1) homogeneous initialisation, a coordinated approach where all nodes use the same set of predetermined parameters, (2) random initialisation with no gain correction, an uncoordinated approach where each node draws their initial parameters independently based on a strategy optimised for isolated centralised training, e.g., from <cite class="ltx_cite ltx_citemacro_citet">He et al. (<a href="#bib.bib14" title="" class="ltx_ref">2015</a>)</cite>, or (3) random initialisation with gain correction, which is our proposed initialisation strategy that re-scales initial parameter distributions from (2) based on the topology of the communication network of nodes. This approach will be explored in detail in <a href="#S4" title="4 Uncoordinated artificial neural network initialisation ‣ Initialisation and Topology Effects in Decentralised Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">4</span></a>.</p>
</div>
<div id="S3.p2" class="ltx_para">
<p id="S3.p2.1" class="ltx_p">Additionally, each node is assigned a specific exclusive set of labelled items as its private training data. Each node can access its private data but not those of other nodes. The data each node has access to does not change over time and no two nodes get access to the same item. In this work, each node gets access to an equal subset of items belonging to each class, randomly selected at the beginning of the simulation. For measuring the performance of the system, a subset of data not assigned to any node is reserved for testing.<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>The same test set, the 10 000 samples from the MNIST test set, was used for testing all nodes.</span></span></span>
To isolate the network effects from data effects, we chose a simple setting where the data is iid among nodes and balanced across labels. It is likely that the non-iid data would be correlated with network features, which would make it difficult to isolate the network effects. We believe that the interactions between data and label distribution and the network features and topology would prove an important line of future research on this topic.</p>
</div>
<div id="S3.p3" class="ltx_para">
<p id="S3.p3.1" class="ltx_p">At each iteration, called here a <em id="S3.p3.1.1" class="ltx_emph ltx_font_italic">communication round</em>, nodes update their parameters (weights and biases) to the mean value calculated across their neighbourhood. They then perform one <em id="S3.p3.1.2" class="ltx_emph ltx_font_italic">unit</em> of local training, performing a set number of epochs of training on their local data using a simple stochastic gradient descent optimiser. The artificial neural network architecture employed in this manuscript is a simple feedforward neural network with four fully connected layers, consisting of 512, 256, and 128 neurons in three hidden layers, followed by an output layer of size 10, and employs ReLU activation functions after each layer except the output layer. Our experiments will be performed on subsets of the MNIST digit classification task <cite class="ltx_cite ltx_citemacro_citep">(LeCun et al., <a href="#bib.bib21" title="" class="ltx_ref">1998</a>)</cite>, distributed equally between the nodes. Of course, the effects of the initialisation method would be even more visible in deeper neural network architectures <cite class="ltx_cite ltx_citemacro_citep">(He et al., <a href="#bib.bib14" title="" class="ltx_ref">2015</a>; Glorot &amp; Bengio, <a href="#bib.bib12" title="" class="ltx_ref">2010</a>)</cite>.</p>
</div>
<div id="S3.p4" class="ltx_para">
<p id="S3.p4.1" class="ltx_p">Note that the centralised federated learning using the simple parameter averaging aggregation method (<span id="S3.p4.1.1" class="ltx_text ltx_font_smallcaps">FedAvg</span>) can be viewed as a special case of the decentralised federated learning using the simple averaging aggregation (<span id="S3.p4.1.2" class="ltx_text ltx_font_smallcaps">DecAvg</span>) on a fully connected network, as at each step each node concurrently plays the role of the central server, setting its parameters to the average parameters of all other nodes. This means that to the extent that the results presented in this manuscript apply to fully connected networks, they can be utilised to understand the behaviour of this configuration of a centralised federated learning process as well.</p>
</div>
<div id="S3.p5" class="ltx_para">
<p id="S3.p5.8" class="ltx_p">Here is a brief description of the notation used in this manuscript: When referring to the communication network (graph), <math id="S3.p5.1.m1.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S3.p5.1.m1.1a"><mi id="S3.p5.1.m1.1.1" xref="S3.p5.1.m1.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.p5.1.m1.1b"><ci id="S3.p5.1.m1.1.1.cmml" xref="S3.p5.1.m1.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p5.1.m1.1c">n</annotation></semantics></math> indicates the number of nodes (sometimes referred to as the system size), while <math id="S3.p5.2.m2.1" class="ltx_Math" alttext="k_{i}" display="inline"><semantics id="S3.p5.2.m2.1a"><msub id="S3.p5.2.m2.1.1" xref="S3.p5.2.m2.1.1.cmml"><mi id="S3.p5.2.m2.1.1.2" xref="S3.p5.2.m2.1.1.2.cmml">k</mi><mi id="S3.p5.2.m2.1.1.3" xref="S3.p5.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.p5.2.m2.1b"><apply id="S3.p5.2.m2.1.1.cmml" xref="S3.p5.2.m2.1.1"><csymbol cd="ambiguous" id="S3.p5.2.m2.1.1.1.cmml" xref="S3.p5.2.m2.1.1">subscript</csymbol><ci id="S3.p5.2.m2.1.1.2.cmml" xref="S3.p5.2.m2.1.1.2">𝑘</ci><ci id="S3.p5.2.m2.1.1.3.cmml" xref="S3.p5.2.m2.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p5.2.m2.1c">k_{i}</annotation></semantics></math> indicates the degree of a node <math id="S3.p5.3.m3.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S3.p5.3.m3.1a"><mi id="S3.p5.3.m3.1.1" xref="S3.p5.3.m3.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.p5.3.m3.1b"><ci id="S3.p5.3.m3.1.1.cmml" xref="S3.p5.3.m3.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p5.3.m3.1c">i</annotation></semantics></math> defined as the number of its neighbours, and <math id="S3.p5.4.m4.1" class="ltx_Math" alttext="p(k)" display="inline"><semantics id="S3.p5.4.m4.1a"><mrow id="S3.p5.4.m4.1.2" xref="S3.p5.4.m4.1.2.cmml"><mi id="S3.p5.4.m4.1.2.2" xref="S3.p5.4.m4.1.2.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.p5.4.m4.1.2.1" xref="S3.p5.4.m4.1.2.1.cmml">​</mo><mrow id="S3.p5.4.m4.1.2.3.2" xref="S3.p5.4.m4.1.2.cmml"><mo stretchy="false" id="S3.p5.4.m4.1.2.3.2.1" xref="S3.p5.4.m4.1.2.cmml">(</mo><mi id="S3.p5.4.m4.1.1" xref="S3.p5.4.m4.1.1.cmml">k</mi><mo stretchy="false" id="S3.p5.4.m4.1.2.3.2.2" xref="S3.p5.4.m4.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.p5.4.m4.1b"><apply id="S3.p5.4.m4.1.2.cmml" xref="S3.p5.4.m4.1.2"><times id="S3.p5.4.m4.1.2.1.cmml" xref="S3.p5.4.m4.1.2.1"></times><ci id="S3.p5.4.m4.1.2.2.cmml" xref="S3.p5.4.m4.1.2.2">𝑝</ci><ci id="S3.p5.4.m4.1.1.cmml" xref="S3.p5.4.m4.1.1">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p5.4.m4.1c">p(k)</annotation></semantics></math> is the degree distribution. For a node that is reached by following a random link, <math id="S3.p5.5.m5.1" class="ltx_Math" alttext="q(k)" display="inline"><semantics id="S3.p5.5.m5.1a"><mrow id="S3.p5.5.m5.1.2" xref="S3.p5.5.m5.1.2.cmml"><mi id="S3.p5.5.m5.1.2.2" xref="S3.p5.5.m5.1.2.2.cmml">q</mi><mo lspace="0em" rspace="0em" id="S3.p5.5.m5.1.2.1" xref="S3.p5.5.m5.1.2.1.cmml">​</mo><mrow id="S3.p5.5.m5.1.2.3.2" xref="S3.p5.5.m5.1.2.cmml"><mo stretchy="false" id="S3.p5.5.m5.1.2.3.2.1" xref="S3.p5.5.m5.1.2.cmml">(</mo><mi id="S3.p5.5.m5.1.1" xref="S3.p5.5.m5.1.1.cmml">k</mi><mo stretchy="false" id="S3.p5.5.m5.1.2.3.2.2" xref="S3.p5.5.m5.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.p5.5.m5.1b"><apply id="S3.p5.5.m5.1.2.cmml" xref="S3.p5.5.m5.1.2"><times id="S3.p5.5.m5.1.2.1.cmml" xref="S3.p5.5.m5.1.2.1"></times><ci id="S3.p5.5.m5.1.2.2.cmml" xref="S3.p5.5.m5.1.2.2">𝑞</ci><ci id="S3.p5.5.m5.1.1.cmml" xref="S3.p5.5.m5.1.1">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p5.5.m5.1c">q(k)</annotation></semantics></math> is the distribution of the number of other links to that node, known as the excess degree distribution of the graph. The adjacency matrix is indicated by <math id="S3.p5.6.m6.1" class="ltx_Math" alttext="A" display="inline"><semantics id="S3.p5.6.m6.1a"><mi id="S3.p5.6.m6.1.1" xref="S3.p5.6.m6.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S3.p5.6.m6.1b"><ci id="S3.p5.6.m6.1.1.cmml" xref="S3.p5.6.m6.1.1">𝐴</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p5.6.m6.1c">A</annotation></semantics></math>. <math id="S3.p5.7.m7.1" class="ltx_Math" alttext="d" display="inline"><semantics id="S3.p5.7.m7.1a"><mi id="S3.p5.7.m7.1.1" xref="S3.p5.7.m7.1.1.cmml">d</mi><annotation-xml encoding="MathML-Content" id="S3.p5.7.m7.1b"><ci id="S3.p5.7.m7.1.1.cmml" xref="S3.p5.7.m7.1.1">𝑑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p5.7.m7.1c">d</annotation></semantics></math> shows the number of dimensions of <math id="S3.p5.8.m8.1" class="ltx_Math" alttext="d" display="inline"><semantics id="S3.p5.8.m8.1a"><mi id="S3.p5.8.m8.1.1" xref="S3.p5.8.m8.1.1.cmml">d</mi><annotation-xml encoding="MathML-Content" id="S3.p5.8.m8.1b"><ci id="S3.p5.8.m8.1.1.cmml" xref="S3.p5.8.m8.1.1">𝑑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p5.8.m8.1c">d</annotation></semantics></math>-dimensional tori.</p>
</div>
<div id="S3.p6" class="ltx_para">
<p id="S3.p6.13" class="ltx_p">Expected values are indicated using the brackets around the random variable, e.g., <math id="S3.p6.1.m1.1" class="ltx_Math" alttext="\langle k\rangle" display="inline"><semantics id="S3.p6.1.m1.1a"><mrow id="S3.p6.1.m1.1.2.2" xref="S3.p6.1.m1.1.2.1.cmml"><mo stretchy="false" id="S3.p6.1.m1.1.2.2.1" xref="S3.p6.1.m1.1.2.1.1.cmml">⟨</mo><mi id="S3.p6.1.m1.1.1" xref="S3.p6.1.m1.1.1.cmml">k</mi><mo stretchy="false" id="S3.p6.1.m1.1.2.2.2" xref="S3.p6.1.m1.1.2.1.1.cmml">⟩</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.p6.1.m1.1b"><apply id="S3.p6.1.m1.1.2.1.cmml" xref="S3.p6.1.m1.1.2.2"><csymbol cd="latexml" id="S3.p6.1.m1.1.2.1.1.cmml" xref="S3.p6.1.m1.1.2.2.1">delimited-⟨⟩</csymbol><ci id="S3.p6.1.m1.1.1.cmml" xref="S3.p6.1.m1.1.1">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p6.1.m1.1c">\langle k\rangle</annotation></semantics></math> is the mean degree. Standard deviation is shown using <math id="S3.p6.2.m2.1" class="ltx_Math" alttext="\sigma(...)" display="inline"><semantics id="S3.p6.2.m2.1a"><mrow id="S3.p6.2.m2.1.2" xref="S3.p6.2.m2.1.2.cmml"><mi id="S3.p6.2.m2.1.2.2" xref="S3.p6.2.m2.1.2.2.cmml">σ</mi><mo lspace="0em" rspace="0em" id="S3.p6.2.m2.1.2.1" xref="S3.p6.2.m2.1.2.1.cmml">​</mo><mrow id="S3.p6.2.m2.1.2.3.2" xref="S3.p6.2.m2.1.2.cmml"><mo stretchy="false" id="S3.p6.2.m2.1.2.3.2.1" xref="S3.p6.2.m2.1.2.cmml">(</mo><mi mathvariant="normal" id="S3.p6.2.m2.1.1" xref="S3.p6.2.m2.1.1.cmml">…</mi><mo stretchy="false" id="S3.p6.2.m2.1.2.3.2.2" xref="S3.p6.2.m2.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.p6.2.m2.1b"><apply id="S3.p6.2.m2.1.2.cmml" xref="S3.p6.2.m2.1.2"><times id="S3.p6.2.m2.1.2.1.cmml" xref="S3.p6.2.m2.1.2.1"></times><ci id="S3.p6.2.m2.1.2.2.cmml" xref="S3.p6.2.m2.1.2.2">𝜎</ci><ci id="S3.p6.2.m2.1.1.cmml" xref="S3.p6.2.m2.1.1">…</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p6.2.m2.1c">\sigma(...)</annotation></semantics></math>. The <math id="S3.p6.3.m3.1" class="ltx_Math" alttext="p" display="inline"><semantics id="S3.p6.3.m3.1a"><mi id="S3.p6.3.m3.1.1" xref="S3.p6.3.m3.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="S3.p6.3.m3.1b"><ci id="S3.p6.3.m3.1.1.cmml" xref="S3.p6.3.m3.1.1">𝑝</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p6.3.m3.1c">p</annotation></semantics></math> parameters of node <math id="S3.p6.4.m4.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S3.p6.4.m4.1a"><mi id="S3.p6.4.m4.1.1" xref="S3.p6.4.m4.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.p6.4.m4.1b"><ci id="S3.p6.4.m4.1.1.cmml" xref="S3.p6.4.m4.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p6.4.m4.1c">i</annotation></semantics></math> are indicated by vector <math id="S3.p6.5.m5.1" class="ltx_Math" alttext="w_{i}" display="inline"><semantics id="S3.p6.5.m5.1a"><msub id="S3.p6.5.m5.1.1" xref="S3.p6.5.m5.1.1.cmml"><mi id="S3.p6.5.m5.1.1.2" xref="S3.p6.5.m5.1.1.2.cmml">w</mi><mi id="S3.p6.5.m5.1.1.3" xref="S3.p6.5.m5.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.p6.5.m5.1b"><apply id="S3.p6.5.m5.1.1.cmml" xref="S3.p6.5.m5.1.1"><csymbol cd="ambiguous" id="S3.p6.5.m5.1.1.1.cmml" xref="S3.p6.5.m5.1.1">subscript</csymbol><ci id="S3.p6.5.m5.1.1.2.cmml" xref="S3.p6.5.m5.1.1.2">𝑤</ci><ci id="S3.p6.5.m5.1.1.3.cmml" xref="S3.p6.5.m5.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p6.5.m5.1c">w_{i}</annotation></semantics></math> of size <math id="S3.p6.6.m6.1" class="ltx_Math" alttext="p" display="inline"><semantics id="S3.p6.6.m6.1a"><mi id="S3.p6.6.m6.1.1" xref="S3.p6.6.m6.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="S3.p6.6.m6.1b"><ci id="S3.p6.6.m6.1.1.cmml" xref="S3.p6.6.m6.1.1">𝑝</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p6.6.m6.1c">p</annotation></semantics></math>, sometimes arranged in a <math id="S3.p6.7.m7.1" class="ltx_Math" alttext="p\times n" display="inline"><semantics id="S3.p6.7.m7.1a"><mrow id="S3.p6.7.m7.1.1" xref="S3.p6.7.m7.1.1.cmml"><mi id="S3.p6.7.m7.1.1.2" xref="S3.p6.7.m7.1.1.2.cmml">p</mi><mo lspace="0.222em" rspace="0.222em" id="S3.p6.7.m7.1.1.1" xref="S3.p6.7.m7.1.1.1.cmml">×</mo><mi id="S3.p6.7.m7.1.1.3" xref="S3.p6.7.m7.1.1.3.cmml">n</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.p6.7.m7.1b"><apply id="S3.p6.7.m7.1.1.cmml" xref="S3.p6.7.m7.1.1"><times id="S3.p6.7.m7.1.1.1.cmml" xref="S3.p6.7.m7.1.1.1"></times><ci id="S3.p6.7.m7.1.1.2.cmml" xref="S3.p6.7.m7.1.1.2">𝑝</ci><ci id="S3.p6.7.m7.1.1.3.cmml" xref="S3.p6.7.m7.1.1.3">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p6.7.m7.1c">p\times n</annotation></semantics></math> matrix <math id="S3.p6.8.m8.1" class="ltx_Math" alttext="W" display="inline"><semantics id="S3.p6.8.m8.1a"><mi id="S3.p6.8.m8.1.1" xref="S3.p6.8.m8.1.1.cmml">W</mi><annotation-xml encoding="MathML-Content" id="S3.p6.8.m8.1b"><ci id="S3.p6.8.m8.1.1.cmml" xref="S3.p6.8.m8.1.1">𝑊</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p6.8.m8.1c">W</annotation></semantics></math>. <math id="S3.p6.9.m9.1" class="ltx_Math" alttext="\sigma_{ap}" display="inline"><semantics id="S3.p6.9.m9.1a"><msub id="S3.p6.9.m9.1.1" xref="S3.p6.9.m9.1.1.cmml"><mi id="S3.p6.9.m9.1.1.2" xref="S3.p6.9.m9.1.1.2.cmml">σ</mi><mrow id="S3.p6.9.m9.1.1.3" xref="S3.p6.9.m9.1.1.3.cmml"><mi id="S3.p6.9.m9.1.1.3.2" xref="S3.p6.9.m9.1.1.3.2.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.p6.9.m9.1.1.3.1" xref="S3.p6.9.m9.1.1.3.1.cmml">​</mo><mi id="S3.p6.9.m9.1.1.3.3" xref="S3.p6.9.m9.1.1.3.3.cmml">p</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.p6.9.m9.1b"><apply id="S3.p6.9.m9.1.1.cmml" xref="S3.p6.9.m9.1.1"><csymbol cd="ambiguous" id="S3.p6.9.m9.1.1.1.cmml" xref="S3.p6.9.m9.1.1">subscript</csymbol><ci id="S3.p6.9.m9.1.1.2.cmml" xref="S3.p6.9.m9.1.1.2">𝜎</ci><apply id="S3.p6.9.m9.1.1.3.cmml" xref="S3.p6.9.m9.1.1.3"><times id="S3.p6.9.m9.1.1.3.1.cmml" xref="S3.p6.9.m9.1.1.3.1"></times><ci id="S3.p6.9.m9.1.1.3.2.cmml" xref="S3.p6.9.m9.1.1.3.2">𝑎</ci><ci id="S3.p6.9.m9.1.1.3.3.cmml" xref="S3.p6.9.m9.1.1.3.3">𝑝</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p6.9.m9.1c">\sigma_{ap}</annotation></semantics></math> indicates mean standard deviation across columns of <math id="S3.p6.10.m10.1" class="ltx_Math" alttext="W" display="inline"><semantics id="S3.p6.10.m10.1a"><mi id="S3.p6.10.m10.1.1" xref="S3.p6.10.m10.1.1.cmml">W</mi><annotation-xml encoding="MathML-Content" id="S3.p6.10.m10.1b"><ci id="S3.p6.10.m10.1.1.cmml" xref="S3.p6.10.m10.1.1">𝑊</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p6.10.m10.1c">W</annotation></semantics></math>, i.e. expected value of standard deviation of parameters of the same node, while <math id="S3.p6.11.m11.1" class="ltx_Math" alttext="\sigma_{an}" display="inline"><semantics id="S3.p6.11.m11.1a"><msub id="S3.p6.11.m11.1.1" xref="S3.p6.11.m11.1.1.cmml"><mi id="S3.p6.11.m11.1.1.2" xref="S3.p6.11.m11.1.1.2.cmml">σ</mi><mrow id="S3.p6.11.m11.1.1.3" xref="S3.p6.11.m11.1.1.3.cmml"><mi id="S3.p6.11.m11.1.1.3.2" xref="S3.p6.11.m11.1.1.3.2.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.p6.11.m11.1.1.3.1" xref="S3.p6.11.m11.1.1.3.1.cmml">​</mo><mi id="S3.p6.11.m11.1.1.3.3" xref="S3.p6.11.m11.1.1.3.3.cmml">n</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.p6.11.m11.1b"><apply id="S3.p6.11.m11.1.1.cmml" xref="S3.p6.11.m11.1.1"><csymbol cd="ambiguous" id="S3.p6.11.m11.1.1.1.cmml" xref="S3.p6.11.m11.1.1">subscript</csymbol><ci id="S3.p6.11.m11.1.1.2.cmml" xref="S3.p6.11.m11.1.1.2">𝜎</ci><apply id="S3.p6.11.m11.1.1.3.cmml" xref="S3.p6.11.m11.1.1.3"><times id="S3.p6.11.m11.1.1.3.1.cmml" xref="S3.p6.11.m11.1.1.3.1"></times><ci id="S3.p6.11.m11.1.1.3.2.cmml" xref="S3.p6.11.m11.1.1.3.2">𝑎</ci><ci id="S3.p6.11.m11.1.1.3.3.cmml" xref="S3.p6.11.m11.1.1.3.3">𝑛</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p6.11.m11.1c">\sigma_{an}</annotation></semantics></math> indicates mean standard deviation across rows, which is the expected standard deviation of the same parameter between nodes. Artificial neural networks are usually initialised with parameters that are drawn from different sets of distribution, e.g., weights of each layer are drawn from a separate distribution. In this case, a vector <math id="S3.p6.12.m12.1" class="ltx_Math" alttext="w_{i}" display="inline"><semantics id="S3.p6.12.m12.1a"><msub id="S3.p6.12.m12.1.1" xref="S3.p6.12.m12.1.1.cmml"><mi id="S3.p6.12.m12.1.1.2" xref="S3.p6.12.m12.1.1.2.cmml">w</mi><mi id="S3.p6.12.m12.1.1.3" xref="S3.p6.12.m12.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.p6.12.m12.1b"><apply id="S3.p6.12.m12.1.1.cmml" xref="S3.p6.12.m12.1.1"><csymbol cd="ambiguous" id="S3.p6.12.m12.1.1.1.cmml" xref="S3.p6.12.m12.1.1">subscript</csymbol><ci id="S3.p6.12.m12.1.1.2.cmml" xref="S3.p6.12.m12.1.1.2">𝑤</ci><ci id="S3.p6.12.m12.1.1.3.cmml" xref="S3.p6.12.m12.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p6.12.m12.1c">w_{i}</annotation></semantics></math> can be formed for one specific set of parameters, drawn from a distribution with standard deviation <math id="S3.p6.13.m13.1" class="ltx_Math" alttext="\sigma_{init}" display="inline"><semantics id="S3.p6.13.m13.1a"><msub id="S3.p6.13.m13.1.1" xref="S3.p6.13.m13.1.1.cmml"><mi id="S3.p6.13.m13.1.1.2" xref="S3.p6.13.m13.1.1.2.cmml">σ</mi><mrow id="S3.p6.13.m13.1.1.3" xref="S3.p6.13.m13.1.1.3.cmml"><mi id="S3.p6.13.m13.1.1.3.2" xref="S3.p6.13.m13.1.1.3.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.p6.13.m13.1.1.3.1" xref="S3.p6.13.m13.1.1.3.1.cmml">​</mo><mi id="S3.p6.13.m13.1.1.3.3" xref="S3.p6.13.m13.1.1.3.3.cmml">n</mi><mo lspace="0em" rspace="0em" id="S3.p6.13.m13.1.1.3.1a" xref="S3.p6.13.m13.1.1.3.1.cmml">​</mo><mi id="S3.p6.13.m13.1.1.3.4" xref="S3.p6.13.m13.1.1.3.4.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.p6.13.m13.1.1.3.1b" xref="S3.p6.13.m13.1.1.3.1.cmml">​</mo><mi id="S3.p6.13.m13.1.1.3.5" xref="S3.p6.13.m13.1.1.3.5.cmml">t</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.p6.13.m13.1b"><apply id="S3.p6.13.m13.1.1.cmml" xref="S3.p6.13.m13.1.1"><csymbol cd="ambiguous" id="S3.p6.13.m13.1.1.1.cmml" xref="S3.p6.13.m13.1.1">subscript</csymbol><ci id="S3.p6.13.m13.1.1.2.cmml" xref="S3.p6.13.m13.1.1.2">𝜎</ci><apply id="S3.p6.13.m13.1.1.3.cmml" xref="S3.p6.13.m13.1.1.3"><times id="S3.p6.13.m13.1.1.3.1.cmml" xref="S3.p6.13.m13.1.1.3.1"></times><ci id="S3.p6.13.m13.1.1.3.2.cmml" xref="S3.p6.13.m13.1.1.3.2">𝑖</ci><ci id="S3.p6.13.m13.1.1.3.3.cmml" xref="S3.p6.13.m13.1.1.3.3">𝑛</ci><ci id="S3.p6.13.m13.1.1.3.4.cmml" xref="S3.p6.13.m13.1.1.3.4">𝑖</ci><ci id="S3.p6.13.m13.1.1.3.5.cmml" xref="S3.p6.13.m13.1.1.3.5">𝑡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p6.13.m13.1c">\sigma_{init}</annotation></semantics></math>.</p>
</div>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Uncoordinated artificial neural network initialisation</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">Unlike in centralised federated learning, it is unwarranted to assume that in a massive decentralised federated learning setup, all nodes can negotiate and agree on initial values for model parameters. A fully uncoordinated method for selecting initial values for the model parameters means that each node should be able to draw initial values for their model parameters independently with no communication.</p>
</div>
<div id="S4.p2" class="ltx_para">
<p id="S4.p2.1" class="ltx_p">It has been shown that judicious choice of initialisation strategy can enable training of much deeper artificial neural networks <cite class="ltx_cite ltx_citemacro_citep">(Glorot &amp; Bengio, <a href="#bib.bib12" title="" class="ltx_ref">2010</a>; He et al., <a href="#bib.bib14" title="" class="ltx_ref">2015</a>, <a href="#bib.bib15" title="" class="ltx_ref">2016</a>)</cite>. Specifically, a good parameter initialisation method leads to initial parameters that neither increase nor decrease activation values for consecutive layers exponentially <cite class="ltx_cite ltx_citemacro_citep">(He et al., <a href="#bib.bib14" title="" class="ltx_ref">2015</a>; Glorot &amp; Bengio, <a href="#bib.bib12" title="" class="ltx_ref">2010</a>)</cite>. In the case of decentralised federated learning, this proves more challenging, as the aggregation step changes the distribution of parameters, meaning that the optimal initial value distributions are not only a function of the machine learning model architecture, but also affected by the communication network structure.</p>
</div>
<div id="S4.p3" class="ltx_para">
<p id="S4.p3.1" class="ltx_p">Empirically, we observe (<a href="#S4.F1" title="In 4 Uncoordinated artificial neural network initialisation ‣ Initialisation and Topology Effects in Decentralised Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Figure</span> <span class="ltx_text ltx_ref_tag">1</span></a>(a) dashed lines) that the decentralised, uncoordinated initialisation of nodes using the method proposed by  <cite class="ltx_cite ltx_citemacro_citet">He et al. (<a href="#bib.bib14" title="" class="ltx_ref">2015</a>)</cite> results in progressively poorer performance in the federated setting as the number of nodes grows, while the proposed uncoordinated initialisation performs similarly to the coordinated homogeneous strategy. <a href="#S4.F1" title="In 4 Uncoordinated artificial neural network initialisation ‣ Initialisation and Topology Effects in Decentralised Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Figure</span> <span class="ltx_text ltx_ref_tag">1</span></a>(b) shows this as a linear scaling of the loss trajectory as a function of communication rounds with the number of nodes.</p>
</div>
<figure id="S4.F1" class="ltx_figure"><img src="/html/2403.15855/assets/x1.png" id="S4.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="433" height="196" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Mean test cross-entropy loss with the proposed initialisation compared to coordinated homogeneous initialisation and the initialisation method proposed in <cite class="ltx_cite ltx_citemacro_citet">He et al. (<a href="#bib.bib14" title="" class="ltx_ref">2015</a>)</cite> without re-scaling. The decentralised federated learning process on nodes connected through a fully-connected (complete) network of various sizes, with 8 training samples of each digit per node, 1 epoch per communication round. The results show that without the proposed re-scaling of the parameters, the mean test loss has a plateau lasting a number of rounds linear to the system size, while our uncoordinated proposed initialisation method performs on par with the coordinated homogeneous initialisation. Panel (b) shows the linear scaling of the test loss time trajectory of the independent <cite class="ltx_cite ltx_citemacro_citep">(He et al., <a href="#bib.bib14" title="" class="ltx_ref">2015</a>)</cite> method initialisation with system size. Error bars represent 95% confidence intervals.</figcaption>
</figure>
<div id="S4.p4" class="ltx_para">
<p id="S4.p4.4" class="ltx_p">To understand the general characteristics of the learning process we propose a simplified numerical model: an iterative process, where each of the <math id="S4.p4.1.m1.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S4.p4.1.m1.1a"><mi id="S4.p4.1.m1.1.1" xref="S4.p4.1.m1.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S4.p4.1.m1.1b"><ci id="S4.p4.1.m1.1.1.cmml" xref="S4.p4.1.m1.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p4.1.m1.1c">n</annotation></semantics></math> network nodes has a vector of <math id="S4.p4.2.m2.1" class="ltx_Math" alttext="p" display="inline"><semantics id="S4.p4.2.m2.1a"><mi id="S4.p4.2.m2.1.1" xref="S4.p4.2.m2.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="S4.p4.2.m2.1b"><ci id="S4.p4.2.m2.1.1.cmml" xref="S4.p4.2.m2.1.1">𝑝</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p4.2.m2.1c">p</annotation></semantics></math> parameters drawn from a normal distribution with standard deviation <math id="S4.p4.3.m3.1" class="ltx_Math" alttext="\sigma_{\text{init}}" display="inline"><semantics id="S4.p4.3.m3.1a"><msub id="S4.p4.3.m3.1.1" xref="S4.p4.3.m3.1.1.cmml"><mi id="S4.p4.3.m3.1.1.2" xref="S4.p4.3.m3.1.1.2.cmml">σ</mi><mtext id="S4.p4.3.m3.1.1.3" xref="S4.p4.3.m3.1.1.3a.cmml">init</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.p4.3.m3.1b"><apply id="S4.p4.3.m3.1.1.cmml" xref="S4.p4.3.m3.1.1"><csymbol cd="ambiguous" id="S4.p4.3.m3.1.1.1.cmml" xref="S4.p4.3.m3.1.1">subscript</csymbol><ci id="S4.p4.3.m3.1.1.2.cmml" xref="S4.p4.3.m3.1.1.2">𝜎</ci><ci id="S4.p4.3.m3.1.1.3a.cmml" xref="S4.p4.3.m3.1.1.3"><mtext mathsize="70%" id="S4.p4.3.m3.1.1.3.cmml" xref="S4.p4.3.m3.1.1.3">init</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p4.3.m3.1c">\sigma_{\text{init}}</annotation></semantics></math>. At each iteration, similar to the federated averaging step, each node updates its parameter vector by averaging its immediate neighbourhood, then, to mimic the effects of the local training step all node parameters are updated by adding a normally distributed noise with standard deviation <math id="S4.p4.4.m4.1" class="ltx_Math" alttext="\sigma_{\text{noise}}" display="inline"><semantics id="S4.p4.4.m4.1a"><msub id="S4.p4.4.m4.1.1" xref="S4.p4.4.m4.1.1.cmml"><mi id="S4.p4.4.m4.1.1.2" xref="S4.p4.4.m4.1.1.2.cmml">σ</mi><mtext id="S4.p4.4.m4.1.1.3" xref="S4.p4.4.m4.1.1.3a.cmml">noise</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.p4.4.m4.1b"><apply id="S4.p4.4.m4.1.1.cmml" xref="S4.p4.4.m4.1.1"><csymbol cd="ambiguous" id="S4.p4.4.m4.1.1.1.cmml" xref="S4.p4.4.m4.1.1">subscript</csymbol><ci id="S4.p4.4.m4.1.1.2.cmml" xref="S4.p4.4.m4.1.1.2">𝜎</ci><ci id="S4.p4.4.m4.1.1.3a.cmml" xref="S4.p4.4.m4.1.1.3"><mtext mathsize="70%" id="S4.p4.4.m4.1.1.3.cmml" xref="S4.p4.4.m4.1.1.3">noise</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p4.4.m4.1c">\sigma_{\text{noise}}</annotation></semantics></math>.</p>
</div>
<div id="S4.p5" class="ltx_para">
<p id="S4.p5.1" class="ltx_p">This model mimics the general behaviour of the decentralised learning system at the early stages of the process, since we can assume that the changes to the parameters as a result of the local learning process are generally negligible compared to the changes in parameters due to the aggregation steps. Simulations of the decentralised federated learning process (<a href="#S4.F2" title="In 4 Uncoordinated artificial neural network initialisation ‣ Initialisation and Topology Effects in Decentralised Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Figure</span> <span class="ltx_text ltx_ref_tag">2</span></a>) can provide evidence for this assumption. The implementation of the simulated decentralised federated learning system is available for the purposes of reproduction under the MIT open-source license at <a target="_blank" href="https://github.com/arashbm/gossip_training" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/arashbm/gossip_training</a>.</p>
</div>
<figure id="S4.F2" class="ltx_figure"><img src="/html/2403.15855/assets/x2.png" id="S4.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="415" height="178" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Mean magnitude of change in parameters due to the training and aggregation independently as well as the total change. In the early rounds of the iterative process, the vector of change due to the aggregation is several orders of magnitude larger than that of the training. This, combined with the cosine similarity plot from <a href="#S4.F4" title="In 4 Uncoordinated artificial neural network initialisation ‣ Initialisation and Topology Effects in Decentralised Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Figure</span> <span class="ltx_text ltx_ref_tag">4</span></a>(b) showing the orthogonality of these vectors in the early rounds, supports the numeric model assumption that the early evolution of the system is dominated by the aggregation step. Changes were calculated by simulating the decentralised federated learning process on 256 nodes, connected through a random 32-regular network, with 8 training samples of each digit per node, 1 epoch per communication round. Error bars represent 95% confidence intervals.</figcaption>
</figure>
<div id="S4.p6" class="ltx_para">
<p id="S4.p6.8" class="ltx_p">The results from the simplified numeric model for random <math id="S4.p6.1.m1.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S4.p6.1.m1.1a"><mi id="S4.p6.1.m1.1.1" xref="S4.p6.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.p6.1.m1.1b"><ci id="S4.p6.1.m1.1.1.cmml" xref="S4.p6.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p6.1.m1.1c">k</annotation></semantics></math>-regular graphs<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>Random <math id="footnote2.m1.1" class="ltx_Math" alttext="k" display="inline"><semantics id="footnote2.m1.1b"><mi id="footnote2.m1.1.1" xref="footnote2.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="footnote2.m1.1c"><ci id="footnote2.m1.1.1.cmml" xref="footnote2.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="footnote2.m1.1d">k</annotation></semantics></math>-regular graphs are random graphs where each node has degree <math id="footnote2.m2.1" class="ltx_Math" alttext="k" display="inline"><semantics id="footnote2.m2.1b"><mi id="footnote2.m2.1.1" xref="footnote2.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="footnote2.m2.1c"><ci id="footnote2.m2.1.1.cmml" xref="footnote2.m2.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="footnote2.m2.1d">k</annotation></semantics></math>.</span></span></span> predict, as shown in <a href="#S4.F4" title="In 4 Uncoordinated artificial neural network initialisation ‣ Initialisation and Topology Effects in Decentralised Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Figure</span> <span class="ltx_text ltx_ref_tag">4</span></a>, that the standard deviation of the value of the same parameter across nodes averaged for all parameters, which we call <math id="S4.p6.2.m2.1" class="ltx_Math" alttext="\sigma_{an}" display="inline"><semantics id="S4.p6.2.m2.1a"><msub id="S4.p6.2.m2.1.1" xref="S4.p6.2.m2.1.1.cmml"><mi id="S4.p6.2.m2.1.1.2" xref="S4.p6.2.m2.1.1.2.cmml">σ</mi><mrow id="S4.p6.2.m2.1.1.3" xref="S4.p6.2.m2.1.1.3.cmml"><mi id="S4.p6.2.m2.1.1.3.2" xref="S4.p6.2.m2.1.1.3.2.cmml">a</mi><mo lspace="0em" rspace="0em" id="S4.p6.2.m2.1.1.3.1" xref="S4.p6.2.m2.1.1.3.1.cmml">​</mo><mi id="S4.p6.2.m2.1.1.3.3" xref="S4.p6.2.m2.1.1.3.3.cmml">n</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.p6.2.m2.1b"><apply id="S4.p6.2.m2.1.1.cmml" xref="S4.p6.2.m2.1.1"><csymbol cd="ambiguous" id="S4.p6.2.m2.1.1.1.cmml" xref="S4.p6.2.m2.1.1">subscript</csymbol><ci id="S4.p6.2.m2.1.1.2.cmml" xref="S4.p6.2.m2.1.1.2">𝜎</ci><apply id="S4.p6.2.m2.1.1.3.cmml" xref="S4.p6.2.m2.1.1.3"><times id="S4.p6.2.m2.1.1.3.1.cmml" xref="S4.p6.2.m2.1.1.3.1"></times><ci id="S4.p6.2.m2.1.1.3.2.cmml" xref="S4.p6.2.m2.1.1.3.2">𝑎</ci><ci id="S4.p6.2.m2.1.1.3.3.cmml" xref="S4.p6.2.m2.1.1.3.3">𝑛</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p6.2.m2.1c">\sigma_{an}</annotation></semantics></math>, will decrease to some value close to the standard deviation of noise (simulating changes due to local training). Meanwhile the standard deviation of the parameters of the same node average across all nodes, <math id="S4.p6.3.m3.1" class="ltx_Math" alttext="\sigma_{ap}" display="inline"><semantics id="S4.p6.3.m3.1a"><msub id="S4.p6.3.m3.1.1" xref="S4.p6.3.m3.1.1.cmml"><mi id="S4.p6.3.m3.1.1.2" xref="S4.p6.3.m3.1.1.2.cmml">σ</mi><mrow id="S4.p6.3.m3.1.1.3" xref="S4.p6.3.m3.1.1.3.cmml"><mi id="S4.p6.3.m3.1.1.3.2" xref="S4.p6.3.m3.1.1.3.2.cmml">a</mi><mo lspace="0em" rspace="0em" id="S4.p6.3.m3.1.1.3.1" xref="S4.p6.3.m3.1.1.3.1.cmml">​</mo><mi id="S4.p6.3.m3.1.1.3.3" xref="S4.p6.3.m3.1.1.3.3.cmml">p</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.p6.3.m3.1b"><apply id="S4.p6.3.m3.1.1.cmml" xref="S4.p6.3.m3.1.1"><csymbol cd="ambiguous" id="S4.p6.3.m3.1.1.1.cmml" xref="S4.p6.3.m3.1.1">subscript</csymbol><ci id="S4.p6.3.m3.1.1.2.cmml" xref="S4.p6.3.m3.1.1.2">𝜎</ci><apply id="S4.p6.3.m3.1.1.3.cmml" xref="S4.p6.3.m3.1.1.3"><times id="S4.p6.3.m3.1.1.3.1.cmml" xref="S4.p6.3.m3.1.1.3.1"></times><ci id="S4.p6.3.m3.1.1.3.2.cmml" xref="S4.p6.3.m3.1.1.3.2">𝑎</ci><ci id="S4.p6.3.m3.1.1.3.3.cmml" xref="S4.p6.3.m3.1.1.3.3">𝑝</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p6.3.m3.1c">\sigma_{ap}</annotation></semantics></math>, will decrease only to a factor of <math id="S4.p6.4.m4.1" class="ltx_Math" alttext="1/\sqrt{n}" display="inline"><semantics id="S4.p6.4.m4.1a"><mrow id="S4.p6.4.m4.1.1" xref="S4.p6.4.m4.1.1.cmml"><mn id="S4.p6.4.m4.1.1.2" xref="S4.p6.4.m4.1.1.2.cmml">1</mn><mo id="S4.p6.4.m4.1.1.1" xref="S4.p6.4.m4.1.1.1.cmml">/</mo><msqrt id="S4.p6.4.m4.1.1.3" xref="S4.p6.4.m4.1.1.3.cmml"><mi id="S4.p6.4.m4.1.1.3.2" xref="S4.p6.4.m4.1.1.3.2.cmml">n</mi></msqrt></mrow><annotation-xml encoding="MathML-Content" id="S4.p6.4.m4.1b"><apply id="S4.p6.4.m4.1.1.cmml" xref="S4.p6.4.m4.1.1"><divide id="S4.p6.4.m4.1.1.1.cmml" xref="S4.p6.4.m4.1.1.1"></divide><cn type="integer" id="S4.p6.4.m4.1.1.2.cmml" xref="S4.p6.4.m4.1.1.2">1</cn><apply id="S4.p6.4.m4.1.1.3.cmml" xref="S4.p6.4.m4.1.1.3"><root id="S4.p6.4.m4.1.1.3a.cmml" xref="S4.p6.4.m4.1.1.3"></root><ci id="S4.p6.4.m4.1.1.3.2.cmml" xref="S4.p6.4.m4.1.1.3.2">𝑛</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p6.4.m4.1c">1/\sqrt{n}</annotation></semantics></math> of the original standard deviation <math id="S4.p6.5.m5.1" class="ltx_Math" alttext="\sigma_{\text{init}}" display="inline"><semantics id="S4.p6.5.m5.1a"><msub id="S4.p6.5.m5.1.1" xref="S4.p6.5.m5.1.1.cmml"><mi id="S4.p6.5.m5.1.1.2" xref="S4.p6.5.m5.1.1.2.cmml">σ</mi><mtext id="S4.p6.5.m5.1.1.3" xref="S4.p6.5.m5.1.1.3a.cmml">init</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.p6.5.m5.1b"><apply id="S4.p6.5.m5.1.1.cmml" xref="S4.p6.5.m5.1.1"><csymbol cd="ambiguous" id="S4.p6.5.m5.1.1.1.cmml" xref="S4.p6.5.m5.1.1">subscript</csymbol><ci id="S4.p6.5.m5.1.1.2.cmml" xref="S4.p6.5.m5.1.1.2">𝜎</ci><ci id="S4.p6.5.m5.1.1.3a.cmml" xref="S4.p6.5.m5.1.1.3"><mtext mathsize="70%" id="S4.p6.5.m5.1.1.3.cmml" xref="S4.p6.5.m5.1.1.3">init</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p6.5.m5.1c">\sigma_{\text{init}}</annotation></semantics></math>. Note that for artificial neural networks each layer’s initial weights and biases are usually drawn from distributions with different values of <math id="S4.p6.6.m6.1" class="ltx_Math" alttext="\sigma_{\text{init}}" display="inline"><semantics id="S4.p6.6.m6.1a"><msub id="S4.p6.6.m6.1.1" xref="S4.p6.6.m6.1.1.cmml"><mi id="S4.p6.6.m6.1.1.2" xref="S4.p6.6.m6.1.1.2.cmml">σ</mi><mtext id="S4.p6.6.m6.1.1.3" xref="S4.p6.6.m6.1.1.3a.cmml">init</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.p6.6.m6.1b"><apply id="S4.p6.6.m6.1.1.cmml" xref="S4.p6.6.m6.1.1"><csymbol cd="ambiguous" id="S4.p6.6.m6.1.1.1.cmml" xref="S4.p6.6.m6.1.1">subscript</csymbol><ci id="S4.p6.6.m6.1.1.2.cmml" xref="S4.p6.6.m6.1.1.2">𝜎</ci><ci id="S4.p6.6.m6.1.1.3a.cmml" xref="S4.p6.6.m6.1.1.3"><mtext mathsize="70%" id="S4.p6.6.m6.1.1.3.cmml" xref="S4.p6.6.m6.1.1.3">init</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p6.6.m6.1c">\sigma_{\text{init}}</annotation></semantics></math>, based on the number of inputs and outputs of each layer and other considerations. The analysis here can be applied to each batch of parameters drawn from the same distribution, e.g., to weights of the same layer, independently. A schematic visualisation of the aggregation process with definitions of <math id="S4.p6.7.m7.1" class="ltx_Math" alttext="\sigma_{an}" display="inline"><semantics id="S4.p6.7.m7.1a"><msub id="S4.p6.7.m7.1.1" xref="S4.p6.7.m7.1.1.cmml"><mi id="S4.p6.7.m7.1.1.2" xref="S4.p6.7.m7.1.1.2.cmml">σ</mi><mrow id="S4.p6.7.m7.1.1.3" xref="S4.p6.7.m7.1.1.3.cmml"><mi id="S4.p6.7.m7.1.1.3.2" xref="S4.p6.7.m7.1.1.3.2.cmml">a</mi><mo lspace="0em" rspace="0em" id="S4.p6.7.m7.1.1.3.1" xref="S4.p6.7.m7.1.1.3.1.cmml">​</mo><mi id="S4.p6.7.m7.1.1.3.3" xref="S4.p6.7.m7.1.1.3.3.cmml">n</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.p6.7.m7.1b"><apply id="S4.p6.7.m7.1.1.cmml" xref="S4.p6.7.m7.1.1"><csymbol cd="ambiguous" id="S4.p6.7.m7.1.1.1.cmml" xref="S4.p6.7.m7.1.1">subscript</csymbol><ci id="S4.p6.7.m7.1.1.2.cmml" xref="S4.p6.7.m7.1.1.2">𝜎</ci><apply id="S4.p6.7.m7.1.1.3.cmml" xref="S4.p6.7.m7.1.1.3"><times id="S4.p6.7.m7.1.1.3.1.cmml" xref="S4.p6.7.m7.1.1.3.1"></times><ci id="S4.p6.7.m7.1.1.3.2.cmml" xref="S4.p6.7.m7.1.1.3.2">𝑎</ci><ci id="S4.p6.7.m7.1.1.3.3.cmml" xref="S4.p6.7.m7.1.1.3.3">𝑛</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p6.7.m7.1c">\sigma_{an}</annotation></semantics></math> and <math id="S4.p6.8.m8.1" class="ltx_Math" alttext="\sigma_{ap}" display="inline"><semantics id="S4.p6.8.m8.1a"><msub id="S4.p6.8.m8.1.1" xref="S4.p6.8.m8.1.1.cmml"><mi id="S4.p6.8.m8.1.1.2" xref="S4.p6.8.m8.1.1.2.cmml">σ</mi><mrow id="S4.p6.8.m8.1.1.3" xref="S4.p6.8.m8.1.1.3.cmml"><mi id="S4.p6.8.m8.1.1.3.2" xref="S4.p6.8.m8.1.1.3.2.cmml">a</mi><mo lspace="0em" rspace="0em" id="S4.p6.8.m8.1.1.3.1" xref="S4.p6.8.m8.1.1.3.1.cmml">​</mo><mi id="S4.p6.8.m8.1.1.3.3" xref="S4.p6.8.m8.1.1.3.3.cmml">p</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.p6.8.m8.1b"><apply id="S4.p6.8.m8.1.1.cmml" xref="S4.p6.8.m8.1.1"><csymbol cd="ambiguous" id="S4.p6.8.m8.1.1.1.cmml" xref="S4.p6.8.m8.1.1">subscript</csymbol><ci id="S4.p6.8.m8.1.1.2.cmml" xref="S4.p6.8.m8.1.1.2">𝜎</ci><apply id="S4.p6.8.m8.1.1.3.cmml" xref="S4.p6.8.m8.1.1.3"><times id="S4.p6.8.m8.1.1.3.1.cmml" xref="S4.p6.8.m8.1.1.3.1"></times><ci id="S4.p6.8.m8.1.1.3.2.cmml" xref="S4.p6.8.m8.1.1.3.2">𝑎</ci><ci id="S4.p6.8.m8.1.1.3.3.cmml" xref="S4.p6.8.m8.1.1.3.3">𝑝</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p6.8.m8.1c">\sigma_{ap}</annotation></semantics></math> is provided in <a href="#S4.F3" title="In 4 Uncoordinated artificial neural network initialisation ‣ Initialisation and Topology Effects in Decentralised Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Figure</span> <span class="ltx_text ltx_ref_tag">3</span></a>.</p>
</div>
<figure id="S4.F3" class="ltx_figure"><img src="/html/2403.15855/assets/x3.png" id="S4.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="248" height="195" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Schematic representation of the decentralised federated learning as presented in this work, as well as the numeric model used in <a href="#S4" title="4 Uncoordinated artificial neural network initialisation ‣ Initialisation and Topology Effects in Decentralised Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">4</span></a>. At each step, each node individually updates its parameters based on performing optimisation on local training data in case of the real decentralised federated learning process or by simply adding a random noise vector drawn from a Gaussian distribution with standard deviation <math id="S4.F3.8.m1.1" class="ltx_Math" alttext="\sigma_{\text{noise}}" display="inline"><semantics id="S4.F3.8.m1.1b"><msub id="S4.F3.8.m1.1.1" xref="S4.F3.8.m1.1.1.cmml"><mi id="S4.F3.8.m1.1.1.2" xref="S4.F3.8.m1.1.1.2.cmml">σ</mi><mtext id="S4.F3.8.m1.1.1.3" xref="S4.F3.8.m1.1.1.3a.cmml">noise</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.F3.8.m1.1c"><apply id="S4.F3.8.m1.1.1.cmml" xref="S4.F3.8.m1.1.1"><csymbol cd="ambiguous" id="S4.F3.8.m1.1.1.1.cmml" xref="S4.F3.8.m1.1.1">subscript</csymbol><ci id="S4.F3.8.m1.1.1.2.cmml" xref="S4.F3.8.m1.1.1.2">𝜎</ci><ci id="S4.F3.8.m1.1.1.3a.cmml" xref="S4.F3.8.m1.1.1.3"><mtext mathsize="70%" id="S4.F3.8.m1.1.1.3.cmml" xref="S4.F3.8.m1.1.1.3">noise</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F3.8.m1.1d">\sigma_{\text{noise}}</annotation></semantics></math> for the numerical model. Each node then aggregates all parameters from its neighbourhood through simple averaging, i.e., <math id="S4.F3.9.m2.3" class="ltx_Math" alttext="w_{u}\leftarrow\sum_{v\in N(u)}w_{v}/|N(u)|" display="inline"><semantics id="S4.F3.9.m2.3b"><mrow id="S4.F3.9.m2.3.3" xref="S4.F3.9.m2.3.3.cmml"><msub id="S4.F3.9.m2.3.3.3" xref="S4.F3.9.m2.3.3.3.cmml"><mi id="S4.F3.9.m2.3.3.3.2" xref="S4.F3.9.m2.3.3.3.2.cmml">w</mi><mi id="S4.F3.9.m2.3.3.3.3" xref="S4.F3.9.m2.3.3.3.3.cmml">u</mi></msub><mo rspace="0.111em" stretchy="false" id="S4.F3.9.m2.3.3.2" xref="S4.F3.9.m2.3.3.2.cmml">←</mo><mrow id="S4.F3.9.m2.3.3.1" xref="S4.F3.9.m2.3.3.1.cmml"><msub id="S4.F3.9.m2.3.3.1.2" xref="S4.F3.9.m2.3.3.1.2.cmml"><mo id="S4.F3.9.m2.3.3.1.2.2" xref="S4.F3.9.m2.3.3.1.2.2.cmml">∑</mo><mrow id="S4.F3.9.m2.1.1.1" xref="S4.F3.9.m2.1.1.1.cmml"><mi id="S4.F3.9.m2.1.1.1.3" xref="S4.F3.9.m2.1.1.1.3.cmml">v</mi><mo id="S4.F3.9.m2.1.1.1.2" xref="S4.F3.9.m2.1.1.1.2.cmml">∈</mo><mrow id="S4.F3.9.m2.1.1.1.4" xref="S4.F3.9.m2.1.1.1.4.cmml"><mi id="S4.F3.9.m2.1.1.1.4.2" xref="S4.F3.9.m2.1.1.1.4.2.cmml">N</mi><mo lspace="0em" rspace="0em" id="S4.F3.9.m2.1.1.1.4.1" xref="S4.F3.9.m2.1.1.1.4.1.cmml">​</mo><mrow id="S4.F3.9.m2.1.1.1.4.3.2" xref="S4.F3.9.m2.1.1.1.4.cmml"><mo stretchy="false" id="S4.F3.9.m2.1.1.1.4.3.2.1" xref="S4.F3.9.m2.1.1.1.4.cmml">(</mo><mi id="S4.F3.9.m2.1.1.1.1" xref="S4.F3.9.m2.1.1.1.1.cmml">u</mi><mo stretchy="false" id="S4.F3.9.m2.1.1.1.4.3.2.2" xref="S4.F3.9.m2.1.1.1.4.cmml">)</mo></mrow></mrow></mrow></msub><mrow id="S4.F3.9.m2.3.3.1.1" xref="S4.F3.9.m2.3.3.1.1.cmml"><msub id="S4.F3.9.m2.3.3.1.1.3" xref="S4.F3.9.m2.3.3.1.1.3.cmml"><mi id="S4.F3.9.m2.3.3.1.1.3.2" xref="S4.F3.9.m2.3.3.1.1.3.2.cmml">w</mi><mi id="S4.F3.9.m2.3.3.1.1.3.3" xref="S4.F3.9.m2.3.3.1.1.3.3.cmml">v</mi></msub><mo id="S4.F3.9.m2.3.3.1.1.2" xref="S4.F3.9.m2.3.3.1.1.2.cmml">/</mo><mrow id="S4.F3.9.m2.3.3.1.1.1.1" xref="S4.F3.9.m2.3.3.1.1.1.2.cmml"><mo stretchy="false" id="S4.F3.9.m2.3.3.1.1.1.1.2" xref="S4.F3.9.m2.3.3.1.1.1.2.1.cmml">|</mo><mrow id="S4.F3.9.m2.3.3.1.1.1.1.1" xref="S4.F3.9.m2.3.3.1.1.1.1.1.cmml"><mi id="S4.F3.9.m2.3.3.1.1.1.1.1.2" xref="S4.F3.9.m2.3.3.1.1.1.1.1.2.cmml">N</mi><mo lspace="0em" rspace="0em" id="S4.F3.9.m2.3.3.1.1.1.1.1.1" xref="S4.F3.9.m2.3.3.1.1.1.1.1.1.cmml">​</mo><mrow id="S4.F3.9.m2.3.3.1.1.1.1.1.3.2" xref="S4.F3.9.m2.3.3.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.F3.9.m2.3.3.1.1.1.1.1.3.2.1" xref="S4.F3.9.m2.3.3.1.1.1.1.1.cmml">(</mo><mi id="S4.F3.9.m2.2.2" xref="S4.F3.9.m2.2.2.cmml">u</mi><mo stretchy="false" id="S4.F3.9.m2.3.3.1.1.1.1.1.3.2.2" xref="S4.F3.9.m2.3.3.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S4.F3.9.m2.3.3.1.1.1.1.3" xref="S4.F3.9.m2.3.3.1.1.1.2.1.cmml">|</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.F3.9.m2.3c"><apply id="S4.F3.9.m2.3.3.cmml" xref="S4.F3.9.m2.3.3"><ci id="S4.F3.9.m2.3.3.2.cmml" xref="S4.F3.9.m2.3.3.2">←</ci><apply id="S4.F3.9.m2.3.3.3.cmml" xref="S4.F3.9.m2.3.3.3"><csymbol cd="ambiguous" id="S4.F3.9.m2.3.3.3.1.cmml" xref="S4.F3.9.m2.3.3.3">subscript</csymbol><ci id="S4.F3.9.m2.3.3.3.2.cmml" xref="S4.F3.9.m2.3.3.3.2">𝑤</ci><ci id="S4.F3.9.m2.3.3.3.3.cmml" xref="S4.F3.9.m2.3.3.3.3">𝑢</ci></apply><apply id="S4.F3.9.m2.3.3.1.cmml" xref="S4.F3.9.m2.3.3.1"><apply id="S4.F3.9.m2.3.3.1.2.cmml" xref="S4.F3.9.m2.3.3.1.2"><csymbol cd="ambiguous" id="S4.F3.9.m2.3.3.1.2.1.cmml" xref="S4.F3.9.m2.3.3.1.2">subscript</csymbol><sum id="S4.F3.9.m2.3.3.1.2.2.cmml" xref="S4.F3.9.m2.3.3.1.2.2"></sum><apply id="S4.F3.9.m2.1.1.1.cmml" xref="S4.F3.9.m2.1.1.1"><in id="S4.F3.9.m2.1.1.1.2.cmml" xref="S4.F3.9.m2.1.1.1.2"></in><ci id="S4.F3.9.m2.1.1.1.3.cmml" xref="S4.F3.9.m2.1.1.1.3">𝑣</ci><apply id="S4.F3.9.m2.1.1.1.4.cmml" xref="S4.F3.9.m2.1.1.1.4"><times id="S4.F3.9.m2.1.1.1.4.1.cmml" xref="S4.F3.9.m2.1.1.1.4.1"></times><ci id="S4.F3.9.m2.1.1.1.4.2.cmml" xref="S4.F3.9.m2.1.1.1.4.2">𝑁</ci><ci id="S4.F3.9.m2.1.1.1.1.cmml" xref="S4.F3.9.m2.1.1.1.1">𝑢</ci></apply></apply></apply><apply id="S4.F3.9.m2.3.3.1.1.cmml" xref="S4.F3.9.m2.3.3.1.1"><divide id="S4.F3.9.m2.3.3.1.1.2.cmml" xref="S4.F3.9.m2.3.3.1.1.2"></divide><apply id="S4.F3.9.m2.3.3.1.1.3.cmml" xref="S4.F3.9.m2.3.3.1.1.3"><csymbol cd="ambiguous" id="S4.F3.9.m2.3.3.1.1.3.1.cmml" xref="S4.F3.9.m2.3.3.1.1.3">subscript</csymbol><ci id="S4.F3.9.m2.3.3.1.1.3.2.cmml" xref="S4.F3.9.m2.3.3.1.1.3.2">𝑤</ci><ci id="S4.F3.9.m2.3.3.1.1.3.3.cmml" xref="S4.F3.9.m2.3.3.1.1.3.3">𝑣</ci></apply><apply id="S4.F3.9.m2.3.3.1.1.1.2.cmml" xref="S4.F3.9.m2.3.3.1.1.1.1"><abs id="S4.F3.9.m2.3.3.1.1.1.2.1.cmml" xref="S4.F3.9.m2.3.3.1.1.1.1.2"></abs><apply id="S4.F3.9.m2.3.3.1.1.1.1.1.cmml" xref="S4.F3.9.m2.3.3.1.1.1.1.1"><times id="S4.F3.9.m2.3.3.1.1.1.1.1.1.cmml" xref="S4.F3.9.m2.3.3.1.1.1.1.1.1"></times><ci id="S4.F3.9.m2.3.3.1.1.1.1.1.2.cmml" xref="S4.F3.9.m2.3.3.1.1.1.1.1.2">𝑁</ci><ci id="S4.F3.9.m2.2.2.cmml" xref="S4.F3.9.m2.2.2">𝑢</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F3.9.m2.3d">w_{u}\leftarrow\sum_{v\in N(u)}w_{v}/|N(u)|</annotation></semantics></math> where <math id="S4.F3.10.m3.1" class="ltx_Math" alttext="N(i)" display="inline"><semantics id="S4.F3.10.m3.1b"><mrow id="S4.F3.10.m3.1.2" xref="S4.F3.10.m3.1.2.cmml"><mi id="S4.F3.10.m3.1.2.2" xref="S4.F3.10.m3.1.2.2.cmml">N</mi><mo lspace="0em" rspace="0em" id="S4.F3.10.m3.1.2.1" xref="S4.F3.10.m3.1.2.1.cmml">​</mo><mrow id="S4.F3.10.m3.1.2.3.2" xref="S4.F3.10.m3.1.2.cmml"><mo stretchy="false" id="S4.F3.10.m3.1.2.3.2.1" xref="S4.F3.10.m3.1.2.cmml">(</mo><mi id="S4.F3.10.m3.1.1" xref="S4.F3.10.m3.1.1.cmml">i</mi><mo stretchy="false" id="S4.F3.10.m3.1.2.3.2.2" xref="S4.F3.10.m3.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.F3.10.m3.1c"><apply id="S4.F3.10.m3.1.2.cmml" xref="S4.F3.10.m3.1.2"><times id="S4.F3.10.m3.1.2.1.cmml" xref="S4.F3.10.m3.1.2.1"></times><ci id="S4.F3.10.m3.1.2.2.cmml" xref="S4.F3.10.m3.1.2.2">𝑁</ci><ci id="S4.F3.10.m3.1.1.cmml" xref="S4.F3.10.m3.1.1">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F3.10.m3.1d">N(i)</annotation></semantics></math> is the immediate neighbourhood of node <math id="S4.F3.11.m4.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S4.F3.11.m4.1b"><mi id="S4.F3.11.m4.1.1" xref="S4.F3.11.m4.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S4.F3.11.m4.1c"><ci id="S4.F3.11.m4.1.1.cmml" xref="S4.F3.11.m4.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.F3.11.m4.1d">i</annotation></semantics></math>, including <math id="S4.F3.12.m5.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S4.F3.12.m5.1b"><mi id="S4.F3.12.m5.1.1" xref="S4.F3.12.m5.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S4.F3.12.m5.1c"><ci id="S4.F3.12.m5.1.1.cmml" xref="S4.F3.12.m5.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.F3.12.m5.1d">i</annotation></semantics></math> itself. The characteristic standard deviations are defined as <math id="S4.F3.13.m6.1" class="ltx_Math" alttext="\sigma_{ap}=\sum_{v\in G}\sigma(w_{v})/n" display="inline"><semantics id="S4.F3.13.m6.1b"><mrow id="S4.F3.13.m6.1.1" xref="S4.F3.13.m6.1.1.cmml"><msub id="S4.F3.13.m6.1.1.3" xref="S4.F3.13.m6.1.1.3.cmml"><mi id="S4.F3.13.m6.1.1.3.2" xref="S4.F3.13.m6.1.1.3.2.cmml">σ</mi><mrow id="S4.F3.13.m6.1.1.3.3" xref="S4.F3.13.m6.1.1.3.3.cmml"><mi id="S4.F3.13.m6.1.1.3.3.2" xref="S4.F3.13.m6.1.1.3.3.2.cmml">a</mi><mo lspace="0em" rspace="0em" id="S4.F3.13.m6.1.1.3.3.1" xref="S4.F3.13.m6.1.1.3.3.1.cmml">​</mo><mi id="S4.F3.13.m6.1.1.3.3.3" xref="S4.F3.13.m6.1.1.3.3.3.cmml">p</mi></mrow></msub><mo rspace="0.111em" id="S4.F3.13.m6.1.1.2" xref="S4.F3.13.m6.1.1.2.cmml">=</mo><mrow id="S4.F3.13.m6.1.1.1" xref="S4.F3.13.m6.1.1.1.cmml"><msub id="S4.F3.13.m6.1.1.1.2" xref="S4.F3.13.m6.1.1.1.2.cmml"><mo id="S4.F3.13.m6.1.1.1.2.2" xref="S4.F3.13.m6.1.1.1.2.2.cmml">∑</mo><mrow id="S4.F3.13.m6.1.1.1.2.3" xref="S4.F3.13.m6.1.1.1.2.3.cmml"><mi id="S4.F3.13.m6.1.1.1.2.3.2" xref="S4.F3.13.m6.1.1.1.2.3.2.cmml">v</mi><mo id="S4.F3.13.m6.1.1.1.2.3.1" xref="S4.F3.13.m6.1.1.1.2.3.1.cmml">∈</mo><mi id="S4.F3.13.m6.1.1.1.2.3.3" xref="S4.F3.13.m6.1.1.1.2.3.3.cmml">G</mi></mrow></msub><mrow id="S4.F3.13.m6.1.1.1.1" xref="S4.F3.13.m6.1.1.1.1.cmml"><mrow id="S4.F3.13.m6.1.1.1.1.1" xref="S4.F3.13.m6.1.1.1.1.1.cmml"><mi id="S4.F3.13.m6.1.1.1.1.1.3" xref="S4.F3.13.m6.1.1.1.1.1.3.cmml">σ</mi><mo lspace="0em" rspace="0em" id="S4.F3.13.m6.1.1.1.1.1.2" xref="S4.F3.13.m6.1.1.1.1.1.2.cmml">​</mo><mrow id="S4.F3.13.m6.1.1.1.1.1.1.1" xref="S4.F3.13.m6.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.F3.13.m6.1.1.1.1.1.1.1.2" xref="S4.F3.13.m6.1.1.1.1.1.1.1.1.cmml">(</mo><msub id="S4.F3.13.m6.1.1.1.1.1.1.1.1" xref="S4.F3.13.m6.1.1.1.1.1.1.1.1.cmml"><mi id="S4.F3.13.m6.1.1.1.1.1.1.1.1.2" xref="S4.F3.13.m6.1.1.1.1.1.1.1.1.2.cmml">w</mi><mi id="S4.F3.13.m6.1.1.1.1.1.1.1.1.3" xref="S4.F3.13.m6.1.1.1.1.1.1.1.1.3.cmml">v</mi></msub><mo stretchy="false" id="S4.F3.13.m6.1.1.1.1.1.1.1.3" xref="S4.F3.13.m6.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S4.F3.13.m6.1.1.1.1.2" xref="S4.F3.13.m6.1.1.1.1.2.cmml">/</mo><mi id="S4.F3.13.m6.1.1.1.1.3" xref="S4.F3.13.m6.1.1.1.1.3.cmml">n</mi></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.F3.13.m6.1c"><apply id="S4.F3.13.m6.1.1.cmml" xref="S4.F3.13.m6.1.1"><eq id="S4.F3.13.m6.1.1.2.cmml" xref="S4.F3.13.m6.1.1.2"></eq><apply id="S4.F3.13.m6.1.1.3.cmml" xref="S4.F3.13.m6.1.1.3"><csymbol cd="ambiguous" id="S4.F3.13.m6.1.1.3.1.cmml" xref="S4.F3.13.m6.1.1.3">subscript</csymbol><ci id="S4.F3.13.m6.1.1.3.2.cmml" xref="S4.F3.13.m6.1.1.3.2">𝜎</ci><apply id="S4.F3.13.m6.1.1.3.3.cmml" xref="S4.F3.13.m6.1.1.3.3"><times id="S4.F3.13.m6.1.1.3.3.1.cmml" xref="S4.F3.13.m6.1.1.3.3.1"></times><ci id="S4.F3.13.m6.1.1.3.3.2.cmml" xref="S4.F3.13.m6.1.1.3.3.2">𝑎</ci><ci id="S4.F3.13.m6.1.1.3.3.3.cmml" xref="S4.F3.13.m6.1.1.3.3.3">𝑝</ci></apply></apply><apply id="S4.F3.13.m6.1.1.1.cmml" xref="S4.F3.13.m6.1.1.1"><apply id="S4.F3.13.m6.1.1.1.2.cmml" xref="S4.F3.13.m6.1.1.1.2"><csymbol cd="ambiguous" id="S4.F3.13.m6.1.1.1.2.1.cmml" xref="S4.F3.13.m6.1.1.1.2">subscript</csymbol><sum id="S4.F3.13.m6.1.1.1.2.2.cmml" xref="S4.F3.13.m6.1.1.1.2.2"></sum><apply id="S4.F3.13.m6.1.1.1.2.3.cmml" xref="S4.F3.13.m6.1.1.1.2.3"><in id="S4.F3.13.m6.1.1.1.2.3.1.cmml" xref="S4.F3.13.m6.1.1.1.2.3.1"></in><ci id="S4.F3.13.m6.1.1.1.2.3.2.cmml" xref="S4.F3.13.m6.1.1.1.2.3.2">𝑣</ci><ci id="S4.F3.13.m6.1.1.1.2.3.3.cmml" xref="S4.F3.13.m6.1.1.1.2.3.3">𝐺</ci></apply></apply><apply id="S4.F3.13.m6.1.1.1.1.cmml" xref="S4.F3.13.m6.1.1.1.1"><divide id="S4.F3.13.m6.1.1.1.1.2.cmml" xref="S4.F3.13.m6.1.1.1.1.2"></divide><apply id="S4.F3.13.m6.1.1.1.1.1.cmml" xref="S4.F3.13.m6.1.1.1.1.1"><times id="S4.F3.13.m6.1.1.1.1.1.2.cmml" xref="S4.F3.13.m6.1.1.1.1.1.2"></times><ci id="S4.F3.13.m6.1.1.1.1.1.3.cmml" xref="S4.F3.13.m6.1.1.1.1.1.3">𝜎</ci><apply id="S4.F3.13.m6.1.1.1.1.1.1.1.1.cmml" xref="S4.F3.13.m6.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.F3.13.m6.1.1.1.1.1.1.1.1.1.cmml" xref="S4.F3.13.m6.1.1.1.1.1.1.1">subscript</csymbol><ci id="S4.F3.13.m6.1.1.1.1.1.1.1.1.2.cmml" xref="S4.F3.13.m6.1.1.1.1.1.1.1.1.2">𝑤</ci><ci id="S4.F3.13.m6.1.1.1.1.1.1.1.1.3.cmml" xref="S4.F3.13.m6.1.1.1.1.1.1.1.1.3">𝑣</ci></apply></apply><ci id="S4.F3.13.m6.1.1.1.1.3.cmml" xref="S4.F3.13.m6.1.1.1.1.3">𝑛</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F3.13.m6.1d">\sigma_{ap}=\sum_{v\in G}\sigma(w_{v})/n</annotation></semantics></math> and <math id="S4.F3.14.m7.3" class="ltx_Math" alttext="\sigma_{an}=\sum_{q=1}^{p}\sigma(W_{q*})/p" display="inline"><semantics id="S4.F3.14.m7.3b"><mrow id="S4.F3.14.m7.3.3" xref="S4.F3.14.m7.3.3.cmml"><msub id="S4.F3.14.m7.3.3.3" xref="S4.F3.14.m7.3.3.3.cmml"><mi id="S4.F3.14.m7.3.3.3.2" xref="S4.F3.14.m7.3.3.3.2.cmml">σ</mi><mrow id="S4.F3.14.m7.3.3.3.3" xref="S4.F3.14.m7.3.3.3.3.cmml"><mi id="S4.F3.14.m7.3.3.3.3.2" xref="S4.F3.14.m7.3.3.3.3.2.cmml">a</mi><mo lspace="0em" rspace="0em" id="S4.F3.14.m7.3.3.3.3.1" xref="S4.F3.14.m7.3.3.3.3.1.cmml">​</mo><mi id="S4.F3.14.m7.3.3.3.3.3" xref="S4.F3.14.m7.3.3.3.3.3.cmml">n</mi></mrow></msub><mo rspace="0.111em" id="S4.F3.14.m7.3.3.2" xref="S4.F3.14.m7.3.3.2.cmml">=</mo><mrow id="S4.F3.14.m7.3.3.1" xref="S4.F3.14.m7.3.3.1.cmml"><msubsup id="S4.F3.14.m7.3.3.1.2" xref="S4.F3.14.m7.3.3.1.2.cmml"><mo id="S4.F3.14.m7.3.3.1.2.2.2" xref="S4.F3.14.m7.3.3.1.2.2.2.cmml">∑</mo><mrow id="S4.F3.14.m7.3.3.1.2.2.3" xref="S4.F3.14.m7.3.3.1.2.2.3.cmml"><mi id="S4.F3.14.m7.3.3.1.2.2.3.2" xref="S4.F3.14.m7.3.3.1.2.2.3.2.cmml">q</mi><mo id="S4.F3.14.m7.3.3.1.2.2.3.1" xref="S4.F3.14.m7.3.3.1.2.2.3.1.cmml">=</mo><mn id="S4.F3.14.m7.3.3.1.2.2.3.3" xref="S4.F3.14.m7.3.3.1.2.2.3.3.cmml">1</mn></mrow><mi id="S4.F3.14.m7.3.3.1.2.3" xref="S4.F3.14.m7.3.3.1.2.3.cmml">p</mi></msubsup><mrow id="S4.F3.14.m7.3.3.1.1" xref="S4.F3.14.m7.3.3.1.1.cmml"><mrow id="S4.F3.14.m7.3.3.1.1.1" xref="S4.F3.14.m7.3.3.1.1.1.cmml"><mi id="S4.F3.14.m7.3.3.1.1.1.3" xref="S4.F3.14.m7.3.3.1.1.1.3.cmml">σ</mi><mo lspace="0em" rspace="0em" id="S4.F3.14.m7.3.3.1.1.1.2" xref="S4.F3.14.m7.3.3.1.1.1.2.cmml">​</mo><mrow id="S4.F3.14.m7.3.3.1.1.1.1.1" xref="S4.F3.14.m7.3.3.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.F3.14.m7.3.3.1.1.1.1.1.2" xref="S4.F3.14.m7.3.3.1.1.1.1.1.1.cmml">(</mo><msub id="S4.F3.14.m7.3.3.1.1.1.1.1.1" xref="S4.F3.14.m7.3.3.1.1.1.1.1.1.cmml"><mi id="S4.F3.14.m7.3.3.1.1.1.1.1.1.2" xref="S4.F3.14.m7.3.3.1.1.1.1.1.1.2.cmml">W</mi><mrow id="S4.F3.14.m7.2.2.2.4" xref="S4.F3.14.m7.2.2.2.3.cmml"><mi id="S4.F3.14.m7.1.1.1.1" xref="S4.F3.14.m7.1.1.1.1.cmml">q</mi><mo lspace="0.222em" id="S4.F3.14.m7.2.2.2.4.1" xref="S4.F3.14.m7.2.2.2.3.cmml">⁣</mo><mo id="S4.F3.14.m7.2.2.2.2" xref="S4.F3.14.m7.2.2.2.2.cmml">∗</mo></mrow></msub><mo stretchy="false" id="S4.F3.14.m7.3.3.1.1.1.1.1.3" xref="S4.F3.14.m7.3.3.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S4.F3.14.m7.3.3.1.1.2" xref="S4.F3.14.m7.3.3.1.1.2.cmml">/</mo><mi id="S4.F3.14.m7.3.3.1.1.3" xref="S4.F3.14.m7.3.3.1.1.3.cmml">p</mi></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.F3.14.m7.3c"><apply id="S4.F3.14.m7.3.3.cmml" xref="S4.F3.14.m7.3.3"><eq id="S4.F3.14.m7.3.3.2.cmml" xref="S4.F3.14.m7.3.3.2"></eq><apply id="S4.F3.14.m7.3.3.3.cmml" xref="S4.F3.14.m7.3.3.3"><csymbol cd="ambiguous" id="S4.F3.14.m7.3.3.3.1.cmml" xref="S4.F3.14.m7.3.3.3">subscript</csymbol><ci id="S4.F3.14.m7.3.3.3.2.cmml" xref="S4.F3.14.m7.3.3.3.2">𝜎</ci><apply id="S4.F3.14.m7.3.3.3.3.cmml" xref="S4.F3.14.m7.3.3.3.3"><times id="S4.F3.14.m7.3.3.3.3.1.cmml" xref="S4.F3.14.m7.3.3.3.3.1"></times><ci id="S4.F3.14.m7.3.3.3.3.2.cmml" xref="S4.F3.14.m7.3.3.3.3.2">𝑎</ci><ci id="S4.F3.14.m7.3.3.3.3.3.cmml" xref="S4.F3.14.m7.3.3.3.3.3">𝑛</ci></apply></apply><apply id="S4.F3.14.m7.3.3.1.cmml" xref="S4.F3.14.m7.3.3.1"><apply id="S4.F3.14.m7.3.3.1.2.cmml" xref="S4.F3.14.m7.3.3.1.2"><csymbol cd="ambiguous" id="S4.F3.14.m7.3.3.1.2.1.cmml" xref="S4.F3.14.m7.3.3.1.2">superscript</csymbol><apply id="S4.F3.14.m7.3.3.1.2.2.cmml" xref="S4.F3.14.m7.3.3.1.2"><csymbol cd="ambiguous" id="S4.F3.14.m7.3.3.1.2.2.1.cmml" xref="S4.F3.14.m7.3.3.1.2">subscript</csymbol><sum id="S4.F3.14.m7.3.3.1.2.2.2.cmml" xref="S4.F3.14.m7.3.3.1.2.2.2"></sum><apply id="S4.F3.14.m7.3.3.1.2.2.3.cmml" xref="S4.F3.14.m7.3.3.1.2.2.3"><eq id="S4.F3.14.m7.3.3.1.2.2.3.1.cmml" xref="S4.F3.14.m7.3.3.1.2.2.3.1"></eq><ci id="S4.F3.14.m7.3.3.1.2.2.3.2.cmml" xref="S4.F3.14.m7.3.3.1.2.2.3.2">𝑞</ci><cn type="integer" id="S4.F3.14.m7.3.3.1.2.2.3.3.cmml" xref="S4.F3.14.m7.3.3.1.2.2.3.3">1</cn></apply></apply><ci id="S4.F3.14.m7.3.3.1.2.3.cmml" xref="S4.F3.14.m7.3.3.1.2.3">𝑝</ci></apply><apply id="S4.F3.14.m7.3.3.1.1.cmml" xref="S4.F3.14.m7.3.3.1.1"><divide id="S4.F3.14.m7.3.3.1.1.2.cmml" xref="S4.F3.14.m7.3.3.1.1.2"></divide><apply id="S4.F3.14.m7.3.3.1.1.1.cmml" xref="S4.F3.14.m7.3.3.1.1.1"><times id="S4.F3.14.m7.3.3.1.1.1.2.cmml" xref="S4.F3.14.m7.3.3.1.1.1.2"></times><ci id="S4.F3.14.m7.3.3.1.1.1.3.cmml" xref="S4.F3.14.m7.3.3.1.1.1.3">𝜎</ci><apply id="S4.F3.14.m7.3.3.1.1.1.1.1.1.cmml" xref="S4.F3.14.m7.3.3.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.F3.14.m7.3.3.1.1.1.1.1.1.1.cmml" xref="S4.F3.14.m7.3.3.1.1.1.1.1">subscript</csymbol><ci id="S4.F3.14.m7.3.3.1.1.1.1.1.1.2.cmml" xref="S4.F3.14.m7.3.3.1.1.1.1.1.1.2">𝑊</ci><list id="S4.F3.14.m7.2.2.2.3.cmml" xref="S4.F3.14.m7.2.2.2.4"><ci id="S4.F3.14.m7.1.1.1.1.cmml" xref="S4.F3.14.m7.1.1.1.1">𝑞</ci><times id="S4.F3.14.m7.2.2.2.2.cmml" xref="S4.F3.14.m7.2.2.2.2"></times></list></apply></apply><ci id="S4.F3.14.m7.3.3.1.1.3.cmml" xref="S4.F3.14.m7.3.3.1.1.3">𝑝</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F3.14.m7.3d">\sigma_{an}=\sum_{q=1}^{p}\sigma(W_{q*})/p</annotation></semantics></math>.</figcaption>
</figure>
<figure id="S4.F4" class="ltx_figure"><img src="/html/2403.15855/assets/x4.png" id="S4.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="424" height="179" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Evolution of standard deviation of a single parameter across all nodes <math id="S4.F4.6.m1.1" class="ltx_Math" alttext="\sigma_{an}" display="inline"><semantics id="S4.F4.6.m1.1b"><msub id="S4.F4.6.m1.1.1" xref="S4.F4.6.m1.1.1.cmml"><mi id="S4.F4.6.m1.1.1.2" xref="S4.F4.6.m1.1.1.2.cmml">σ</mi><mrow id="S4.F4.6.m1.1.1.3" xref="S4.F4.6.m1.1.1.3.cmml"><mi id="S4.F4.6.m1.1.1.3.2" xref="S4.F4.6.m1.1.1.3.2.cmml">a</mi><mo lspace="0em" rspace="0em" id="S4.F4.6.m1.1.1.3.1" xref="S4.F4.6.m1.1.1.3.1.cmml">​</mo><mi id="S4.F4.6.m1.1.1.3.3" xref="S4.F4.6.m1.1.1.3.3.cmml">n</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.F4.6.m1.1c"><apply id="S4.F4.6.m1.1.1.cmml" xref="S4.F4.6.m1.1.1"><csymbol cd="ambiguous" id="S4.F4.6.m1.1.1.1.cmml" xref="S4.F4.6.m1.1.1">subscript</csymbol><ci id="S4.F4.6.m1.1.1.2.cmml" xref="S4.F4.6.m1.1.1.2">𝜎</ci><apply id="S4.F4.6.m1.1.1.3.cmml" xref="S4.F4.6.m1.1.1.3"><times id="S4.F4.6.m1.1.1.3.1.cmml" xref="S4.F4.6.m1.1.1.3.1"></times><ci id="S4.F4.6.m1.1.1.3.2.cmml" xref="S4.F4.6.m1.1.1.3.2">𝑎</ci><ci id="S4.F4.6.m1.1.1.3.3.cmml" xref="S4.F4.6.m1.1.1.3.3">𝑛</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F4.6.m1.1d">\sigma_{an}</annotation></semantics></math> as well the mean standard deviation of parameters in each node <math id="S4.F4.7.m2.1" class="ltx_Math" alttext="\sigma_{ap}" display="inline"><semantics id="S4.F4.7.m2.1b"><msub id="S4.F4.7.m2.1.1" xref="S4.F4.7.m2.1.1.cmml"><mi id="S4.F4.7.m2.1.1.2" xref="S4.F4.7.m2.1.1.2.cmml">σ</mi><mrow id="S4.F4.7.m2.1.1.3" xref="S4.F4.7.m2.1.1.3.cmml"><mi id="S4.F4.7.m2.1.1.3.2" xref="S4.F4.7.m2.1.1.3.2.cmml">a</mi><mo lspace="0em" rspace="0em" id="S4.F4.7.m2.1.1.3.1" xref="S4.F4.7.m2.1.1.3.1.cmml">​</mo><mi id="S4.F4.7.m2.1.1.3.3" xref="S4.F4.7.m2.1.1.3.3.cmml">p</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.F4.7.m2.1c"><apply id="S4.F4.7.m2.1.1.cmml" xref="S4.F4.7.m2.1.1"><csymbol cd="ambiguous" id="S4.F4.7.m2.1.1.1.cmml" xref="S4.F4.7.m2.1.1">subscript</csymbol><ci id="S4.F4.7.m2.1.1.2.cmml" xref="S4.F4.7.m2.1.1.2">𝜎</ci><apply id="S4.F4.7.m2.1.1.3.cmml" xref="S4.F4.7.m2.1.1.3"><times id="S4.F4.7.m2.1.1.3.1.cmml" xref="S4.F4.7.m2.1.1.3.1"></times><ci id="S4.F4.7.m2.1.1.3.2.cmml" xref="S4.F4.7.m2.1.1.3.2">𝑎</ci><ci id="S4.F4.7.m2.1.1.3.3.cmml" xref="S4.F4.7.m2.1.1.3.3">𝑝</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F4.7.m2.1d">\sigma_{ap}</annotation></semantics></math> from (a) the numerical simplified model and (b) simulation of the distributed learning process. Both were carried out on a random 32-regular network with <math id="S4.F4.8.m3.1" class="ltx_Math" alttext="n=512" display="inline"><semantics id="S4.F4.8.m3.1b"><mrow id="S4.F4.8.m3.1.1" xref="S4.F4.8.m3.1.1.cmml"><mi id="S4.F4.8.m3.1.1.2" xref="S4.F4.8.m3.1.1.2.cmml">n</mi><mo id="S4.F4.8.m3.1.1.1" xref="S4.F4.8.m3.1.1.1.cmml">=</mo><mn id="S4.F4.8.m3.1.1.3" xref="S4.F4.8.m3.1.1.3.cmml">512</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.F4.8.m3.1c"><apply id="S4.F4.8.m3.1.1.cmml" xref="S4.F4.8.m3.1.1"><eq id="S4.F4.8.m3.1.1.1.cmml" xref="S4.F4.8.m3.1.1.1"></eq><ci id="S4.F4.8.m3.1.1.2.cmml" xref="S4.F4.8.m3.1.1.2">𝑛</ci><cn type="integer" id="S4.F4.8.m3.1.1.3.cmml" xref="S4.F4.8.m3.1.1.3">512</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F4.8.m3.1d">n=512</annotation></semantics></math>. The simplified numerical model uses <math id="S4.F4.9.m4.1" class="ltx_Math" alttext="p=200" display="inline"><semantics id="S4.F4.9.m4.1b"><mrow id="S4.F4.9.m4.1.1" xref="S4.F4.9.m4.1.1.cmml"><mi id="S4.F4.9.m4.1.1.2" xref="S4.F4.9.m4.1.1.2.cmml">p</mi><mo id="S4.F4.9.m4.1.1.1" xref="S4.F4.9.m4.1.1.1.cmml">=</mo><mn id="S4.F4.9.m4.1.1.3" xref="S4.F4.9.m4.1.1.3.cmml">200</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.F4.9.m4.1c"><apply id="S4.F4.9.m4.1.1.cmml" xref="S4.F4.9.m4.1.1"><eq id="S4.F4.9.m4.1.1.1.cmml" xref="S4.F4.9.m4.1.1.1"></eq><ci id="S4.F4.9.m4.1.1.2.cmml" xref="S4.F4.9.m4.1.1.2">𝑝</ci><cn type="integer" id="S4.F4.9.m4.1.1.3.cmml" xref="S4.F4.9.m4.1.1.3">200</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F4.9.m4.1d">p=200</annotation></semantics></math> parameters per node and the distributed learning models use a sample of the second linear layer weights. The simulations were run with 8 instances of each digit per node as training data. Furthermore, the trajectory of cosine similarity of the vectors of change in parameters due to training and aggregation <math id="S4.F4.10.m5.2" class="ltx_Math" alttext="S_{c}(\delta_{\text{train.}},\delta_{\text{agg.}})" display="inline"><semantics id="S4.F4.10.m5.2b"><mrow id="S4.F4.10.m5.2.2" xref="S4.F4.10.m5.2.2.cmml"><msub id="S4.F4.10.m5.2.2.4" xref="S4.F4.10.m5.2.2.4.cmml"><mi id="S4.F4.10.m5.2.2.4.2" xref="S4.F4.10.m5.2.2.4.2.cmml">S</mi><mi id="S4.F4.10.m5.2.2.4.3" xref="S4.F4.10.m5.2.2.4.3.cmml">c</mi></msub><mo lspace="0em" rspace="0em" id="S4.F4.10.m5.2.2.3" xref="S4.F4.10.m5.2.2.3.cmml">​</mo><mrow id="S4.F4.10.m5.2.2.2.2" xref="S4.F4.10.m5.2.2.2.3.cmml"><mo stretchy="false" id="S4.F4.10.m5.2.2.2.2.3" xref="S4.F4.10.m5.2.2.2.3.cmml">(</mo><msub id="S4.F4.10.m5.1.1.1.1.1" xref="S4.F4.10.m5.1.1.1.1.1.cmml"><mi id="S4.F4.10.m5.1.1.1.1.1.2" xref="S4.F4.10.m5.1.1.1.1.1.2.cmml">δ</mi><mtext id="S4.F4.10.m5.1.1.1.1.1.3" xref="S4.F4.10.m5.1.1.1.1.1.3a.cmml">train.</mtext></msub><mo id="S4.F4.10.m5.2.2.2.2.4" xref="S4.F4.10.m5.2.2.2.3.cmml">,</mo><msub id="S4.F4.10.m5.2.2.2.2.2" xref="S4.F4.10.m5.2.2.2.2.2.cmml"><mi id="S4.F4.10.m5.2.2.2.2.2.2" xref="S4.F4.10.m5.2.2.2.2.2.2.cmml">δ</mi><mtext id="S4.F4.10.m5.2.2.2.2.2.3" xref="S4.F4.10.m5.2.2.2.2.2.3a.cmml">agg.</mtext></msub><mo stretchy="false" id="S4.F4.10.m5.2.2.2.2.5" xref="S4.F4.10.m5.2.2.2.3.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.F4.10.m5.2c"><apply id="S4.F4.10.m5.2.2.cmml" xref="S4.F4.10.m5.2.2"><times id="S4.F4.10.m5.2.2.3.cmml" xref="S4.F4.10.m5.2.2.3"></times><apply id="S4.F4.10.m5.2.2.4.cmml" xref="S4.F4.10.m5.2.2.4"><csymbol cd="ambiguous" id="S4.F4.10.m5.2.2.4.1.cmml" xref="S4.F4.10.m5.2.2.4">subscript</csymbol><ci id="S4.F4.10.m5.2.2.4.2.cmml" xref="S4.F4.10.m5.2.2.4.2">𝑆</ci><ci id="S4.F4.10.m5.2.2.4.3.cmml" xref="S4.F4.10.m5.2.2.4.3">𝑐</ci></apply><interval closure="open" id="S4.F4.10.m5.2.2.2.3.cmml" xref="S4.F4.10.m5.2.2.2.2"><apply id="S4.F4.10.m5.1.1.1.1.1.cmml" xref="S4.F4.10.m5.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.F4.10.m5.1.1.1.1.1.1.cmml" xref="S4.F4.10.m5.1.1.1.1.1">subscript</csymbol><ci id="S4.F4.10.m5.1.1.1.1.1.2.cmml" xref="S4.F4.10.m5.1.1.1.1.1.2">𝛿</ci><ci id="S4.F4.10.m5.1.1.1.1.1.3a.cmml" xref="S4.F4.10.m5.1.1.1.1.1.3"><mtext mathsize="70%" id="S4.F4.10.m5.1.1.1.1.1.3.cmml" xref="S4.F4.10.m5.1.1.1.1.1.3">train.</mtext></ci></apply><apply id="S4.F4.10.m5.2.2.2.2.2.cmml" xref="S4.F4.10.m5.2.2.2.2.2"><csymbol cd="ambiguous" id="S4.F4.10.m5.2.2.2.2.2.1.cmml" xref="S4.F4.10.m5.2.2.2.2.2">subscript</csymbol><ci id="S4.F4.10.m5.2.2.2.2.2.2.cmml" xref="S4.F4.10.m5.2.2.2.2.2.2">𝛿</ci><ci id="S4.F4.10.m5.2.2.2.2.2.3a.cmml" xref="S4.F4.10.m5.2.2.2.2.2.3"><mtext mathsize="70%" id="S4.F4.10.m5.2.2.2.2.2.3.cmml" xref="S4.F4.10.m5.2.2.2.2.2.3">agg.</mtext></ci></apply></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F4.10.m5.2d">S_{c}(\delta_{\text{train.}},\delta_{\text{agg.}})</annotation></semantics></math> indicates that for the duration of the stabilisation phase, the two vectors are mostly orthogonal. Error bars in panel (b) represent 95% confidence intervals.</figcaption>
</figure>
<div id="S4.p7" class="ltx_para">
<p id="S4.p7.5" class="ltx_p">From the dynamics visualised in <a href="#S4.F4" title="In 4 Uncoordinated artificial neural network initialisation ‣ Initialisation and Topology Effects in Decentralised Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Figure</span> <span class="ltx_text ltx_ref_tag">4</span></a>, two in particular stand out due to their important role in understanding and exploiting the decentralised system. First, the value to which <math id="S4.p7.1.m1.1" class="ltx_Math" alttext="\sigma_{ap}" display="inline"><semantics id="S4.p7.1.m1.1a"><msub id="S4.p7.1.m1.1.1" xref="S4.p7.1.m1.1.1.cmml"><mi id="S4.p7.1.m1.1.1.2" xref="S4.p7.1.m1.1.1.2.cmml">σ</mi><mrow id="S4.p7.1.m1.1.1.3" xref="S4.p7.1.m1.1.1.3.cmml"><mi id="S4.p7.1.m1.1.1.3.2" xref="S4.p7.1.m1.1.1.3.2.cmml">a</mi><mo lspace="0em" rspace="0em" id="S4.p7.1.m1.1.1.3.1" xref="S4.p7.1.m1.1.1.3.1.cmml">​</mo><mi id="S4.p7.1.m1.1.1.3.3" xref="S4.p7.1.m1.1.1.3.3.cmml">p</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.p7.1.m1.1b"><apply id="S4.p7.1.m1.1.1.cmml" xref="S4.p7.1.m1.1.1"><csymbol cd="ambiguous" id="S4.p7.1.m1.1.1.1.cmml" xref="S4.p7.1.m1.1.1">subscript</csymbol><ci id="S4.p7.1.m1.1.1.2.cmml" xref="S4.p7.1.m1.1.1.2">𝜎</ci><apply id="S4.p7.1.m1.1.1.3.cmml" xref="S4.p7.1.m1.1.1.3"><times id="S4.p7.1.m1.1.1.3.1.cmml" xref="S4.p7.1.m1.1.1.3.1"></times><ci id="S4.p7.1.m1.1.1.3.2.cmml" xref="S4.p7.1.m1.1.1.3.2">𝑎</ci><ci id="S4.p7.1.m1.1.1.3.3.cmml" xref="S4.p7.1.m1.1.1.3.3">𝑝</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p7.1.m1.1c">\sigma_{ap}</annotation></semantics></math> approaches towards can allow us to select the initial distribution of parameters <math id="S4.p7.2.m2.1" class="ltx_Math" alttext="\sigma_{\text{init.}}" display="inline"><semantics id="S4.p7.2.m2.1a"><msub id="S4.p7.2.m2.1.1" xref="S4.p7.2.m2.1.1.cmml"><mi id="S4.p7.2.m2.1.1.2" xref="S4.p7.2.m2.1.1.2.cmml">σ</mi><mtext id="S4.p7.2.m2.1.1.3" xref="S4.p7.2.m2.1.1.3a.cmml">init.</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.p7.2.m2.1b"><apply id="S4.p7.2.m2.1.1.cmml" xref="S4.p7.2.m2.1.1"><csymbol cd="ambiguous" id="S4.p7.2.m2.1.1.1.cmml" xref="S4.p7.2.m2.1.1">subscript</csymbol><ci id="S4.p7.2.m2.1.1.2.cmml" xref="S4.p7.2.m2.1.1.2">𝜎</ci><ci id="S4.p7.2.m2.1.1.3a.cmml" xref="S4.p7.2.m2.1.1.3"><mtext mathsize="70%" id="S4.p7.2.m2.1.1.3.cmml" xref="S4.p7.2.m2.1.1.3">init.</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p7.2.m2.1c">\sigma_{\text{init.}}</annotation></semantics></math> in a way that after stabilisation of <math id="S4.p7.3.m3.1" class="ltx_Math" alttext="\sigma_{ap}" display="inline"><semantics id="S4.p7.3.m3.1a"><msub id="S4.p7.3.m3.1.1" xref="S4.p7.3.m3.1.1.cmml"><mi id="S4.p7.3.m3.1.1.2" xref="S4.p7.3.m3.1.1.2.cmml">σ</mi><mrow id="S4.p7.3.m3.1.1.3" xref="S4.p7.3.m3.1.1.3.cmml"><mi id="S4.p7.3.m3.1.1.3.2" xref="S4.p7.3.m3.1.1.3.2.cmml">a</mi><mo lspace="0em" rspace="0em" id="S4.p7.3.m3.1.1.3.1" xref="S4.p7.3.m3.1.1.3.1.cmml">​</mo><mi id="S4.p7.3.m3.1.1.3.3" xref="S4.p7.3.m3.1.1.3.3.cmml">p</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.p7.3.m3.1b"><apply id="S4.p7.3.m3.1.1.cmml" xref="S4.p7.3.m3.1.1"><csymbol cd="ambiguous" id="S4.p7.3.m3.1.1.1.cmml" xref="S4.p7.3.m3.1.1">subscript</csymbol><ci id="S4.p7.3.m3.1.1.2.cmml" xref="S4.p7.3.m3.1.1.2">𝜎</ci><apply id="S4.p7.3.m3.1.1.3.cmml" xref="S4.p7.3.m3.1.1.3"><times id="S4.p7.3.m3.1.1.3.1.cmml" xref="S4.p7.3.m3.1.1.3.1"></times><ci id="S4.p7.3.m3.1.1.3.2.cmml" xref="S4.p7.3.m3.1.1.3.2">𝑎</ci><ci id="S4.p7.3.m3.1.1.3.3.cmml" xref="S4.p7.3.m3.1.1.3.3">𝑝</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p7.3.m3.1c">\sigma_{ap}</annotation></semantics></math>, the neural network models would on expectation have an optimal parameter distribution. In <a href="#S4.SS1" title="4.1 The compression of node parameters ‣ 4 Uncoordinated artificial neural network initialisation ‣ Initialisation and Topology Effects in Decentralised Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">4.1</span></a>, we show that this compression can be calculated for any graph based on the distribution of eigenvector centralities of the nodes <cite class="ltx_cite ltx_citemacro_citep">(Newman, <a href="#bib.bib27" title="" class="ltx_ref">2010</a>)</cite>, with the case of graphs with uniform centralities giving a factor of <math id="S4.p7.4.m4.1" class="ltx_Math" alttext="1/\sqrt{n}" display="inline"><semantics id="S4.p7.4.m4.1a"><mrow id="S4.p7.4.m4.1.1" xref="S4.p7.4.m4.1.1.cmml"><mn id="S4.p7.4.m4.1.1.2" xref="S4.p7.4.m4.1.1.2.cmml">1</mn><mo id="S4.p7.4.m4.1.1.1" xref="S4.p7.4.m4.1.1.1.cmml">/</mo><msqrt id="S4.p7.4.m4.1.1.3" xref="S4.p7.4.m4.1.1.3.cmml"><mi id="S4.p7.4.m4.1.1.3.2" xref="S4.p7.4.m4.1.1.3.2.cmml">n</mi></msqrt></mrow><annotation-xml encoding="MathML-Content" id="S4.p7.4.m4.1b"><apply id="S4.p7.4.m4.1.1.cmml" xref="S4.p7.4.m4.1.1"><divide id="S4.p7.4.m4.1.1.1.cmml" xref="S4.p7.4.m4.1.1.1"></divide><cn type="integer" id="S4.p7.4.m4.1.1.2.cmml" xref="S4.p7.4.m4.1.1.2">1</cn><apply id="S4.p7.4.m4.1.1.3.cmml" xref="S4.p7.4.m4.1.1.3"><root id="S4.p7.4.m4.1.1.3a.cmml" xref="S4.p7.4.m4.1.1.3"></root><ci id="S4.p7.4.m4.1.1.3.2.cmml" xref="S4.p7.4.m4.1.1.3.2">𝑛</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p7.4.m4.1c">1/\sqrt{n}</annotation></semantics></math>. Second, the time to reach the steady state for <math id="S4.p7.5.m5.1" class="ltx_Math" alttext="\sigma_{an}" display="inline"><semantics id="S4.p7.5.m5.1a"><msub id="S4.p7.5.m5.1.1" xref="S4.p7.5.m5.1.1.cmml"><mi id="S4.p7.5.m5.1.1.2" xref="S4.p7.5.m5.1.1.2.cmml">σ</mi><mrow id="S4.p7.5.m5.1.1.3" xref="S4.p7.5.m5.1.1.3.cmml"><mi id="S4.p7.5.m5.1.1.3.2" xref="S4.p7.5.m5.1.1.3.2.cmml">a</mi><mo lspace="0em" rspace="0em" id="S4.p7.5.m5.1.1.3.1" xref="S4.p7.5.m5.1.1.3.1.cmml">​</mo><mi id="S4.p7.5.m5.1.1.3.3" xref="S4.p7.5.m5.1.1.3.3.cmml">n</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.p7.5.m5.1b"><apply id="S4.p7.5.m5.1.1.cmml" xref="S4.p7.5.m5.1.1"><csymbol cd="ambiguous" id="S4.p7.5.m5.1.1.1.cmml" xref="S4.p7.5.m5.1.1">subscript</csymbol><ci id="S4.p7.5.m5.1.1.2.cmml" xref="S4.p7.5.m5.1.1.2">𝜎</ci><apply id="S4.p7.5.m5.1.1.3.cmml" xref="S4.p7.5.m5.1.1.3"><times id="S4.p7.5.m5.1.1.3.1.cmml" xref="S4.p7.5.m5.1.1.3.1"></times><ci id="S4.p7.5.m5.1.1.3.2.cmml" xref="S4.p7.5.m5.1.1.3.2">𝑎</ci><ci id="S4.p7.5.m5.1.1.3.3.cmml" xref="S4.p7.5.m5.1.1.3.3">𝑛</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p7.5.m5.1c">\sigma_{an}</annotation></semantics></math> plays an important role since this determines the number of rounds required for the heterogeneous initial condition before the improvements of the learning process start in earnest. This is because the magnitude of the changes to parameters due to the learning process (modelled by noise in the numerical model) becomes comparable to those of the aggregation process. In <a href="#S4.SS2" title="4.2 Initial stabilisation time ‣ 4 Uncoordinated artificial neural network initialisation ‣ Initialisation and Topology Effects in Decentralised Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">4.2</span></a> we show that this “stabilisation” time scales similar, up to a constant factor, to the mixing time of lazy random walks on the graph.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>The compression of node parameters</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.5" class="ltx_p">We can analytically estimate the steady state values for <math id="S4.SS1.p1.1.m1.1" class="ltx_Math" alttext="\sigma_{an}" display="inline"><semantics id="S4.SS1.p1.1.m1.1a"><msub id="S4.SS1.p1.1.m1.1.1" xref="S4.SS1.p1.1.m1.1.1.cmml"><mi id="S4.SS1.p1.1.m1.1.1.2" xref="S4.SS1.p1.1.m1.1.1.2.cmml">σ</mi><mrow id="S4.SS1.p1.1.m1.1.1.3" xref="S4.SS1.p1.1.m1.1.1.3.cmml"><mi id="S4.SS1.p1.1.m1.1.1.3.2" xref="S4.SS1.p1.1.m1.1.1.3.2.cmml">a</mi><mo lspace="0em" rspace="0em" id="S4.SS1.p1.1.m1.1.1.3.1" xref="S4.SS1.p1.1.m1.1.1.3.1.cmml">​</mo><mi id="S4.SS1.p1.1.m1.1.1.3.3" xref="S4.SS1.p1.1.m1.1.1.3.3.cmml">n</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.1.m1.1b"><apply id="S4.SS1.p1.1.m1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS1.p1.1.m1.1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1">subscript</csymbol><ci id="S4.SS1.p1.1.m1.1.1.2.cmml" xref="S4.SS1.p1.1.m1.1.1.2">𝜎</ci><apply id="S4.SS1.p1.1.m1.1.1.3.cmml" xref="S4.SS1.p1.1.m1.1.1.3"><times id="S4.SS1.p1.1.m1.1.1.3.1.cmml" xref="S4.SS1.p1.1.m1.1.1.3.1"></times><ci id="S4.SS1.p1.1.m1.1.1.3.2.cmml" xref="S4.SS1.p1.1.m1.1.1.3.2">𝑎</ci><ci id="S4.SS1.p1.1.m1.1.1.3.3.cmml" xref="S4.SS1.p1.1.m1.1.1.3.3">𝑛</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.1.m1.1c">\sigma_{an}</annotation></semantics></math> and <math id="S4.SS1.p1.2.m2.1" class="ltx_Math" alttext="\sigma_{ap}" display="inline"><semantics id="S4.SS1.p1.2.m2.1a"><msub id="S4.SS1.p1.2.m2.1.1" xref="S4.SS1.p1.2.m2.1.1.cmml"><mi id="S4.SS1.p1.2.m2.1.1.2" xref="S4.SS1.p1.2.m2.1.1.2.cmml">σ</mi><mrow id="S4.SS1.p1.2.m2.1.1.3" xref="S4.SS1.p1.2.m2.1.1.3.cmml"><mi id="S4.SS1.p1.2.m2.1.1.3.2" xref="S4.SS1.p1.2.m2.1.1.3.2.cmml">a</mi><mo lspace="0em" rspace="0em" id="S4.SS1.p1.2.m2.1.1.3.1" xref="S4.SS1.p1.2.m2.1.1.3.1.cmml">​</mo><mi id="S4.SS1.p1.2.m2.1.1.3.3" xref="S4.SS1.p1.2.m2.1.1.3.3.cmml">p</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.2.m2.1b"><apply id="S4.SS1.p1.2.m2.1.1.cmml" xref="S4.SS1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS1.p1.2.m2.1.1.1.cmml" xref="S4.SS1.p1.2.m2.1.1">subscript</csymbol><ci id="S4.SS1.p1.2.m2.1.1.2.cmml" xref="S4.SS1.p1.2.m2.1.1.2">𝜎</ci><apply id="S4.SS1.p1.2.m2.1.1.3.cmml" xref="S4.SS1.p1.2.m2.1.1.3"><times id="S4.SS1.p1.2.m2.1.1.3.1.cmml" xref="S4.SS1.p1.2.m2.1.1.3.1"></times><ci id="S4.SS1.p1.2.m2.1.1.3.2.cmml" xref="S4.SS1.p1.2.m2.1.1.3.2">𝑎</ci><ci id="S4.SS1.p1.2.m2.1.1.3.3.cmml" xref="S4.SS1.p1.2.m2.1.1.3.3">𝑝</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.2.m2.1c">\sigma_{ap}</annotation></semantics></math>, as well as the scaling of the number of rounds to arrive at these values using methods from finite-state discrete-time Markov chains. Let <math id="S4.SS1.p1.3.m3.1" class="ltx_Math" alttext="A" display="inline"><semantics id="S4.SS1.p1.3.m3.1a"><mi id="S4.SS1.p1.3.m3.1.1" xref="S4.SS1.p1.3.m3.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.3.m3.1b"><ci id="S4.SS1.p1.3.m3.1.1.cmml" xref="S4.SS1.p1.3.m3.1.1">𝐴</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.3.m3.1c">A</annotation></semantics></math> be the adjacency matrix of our underlying graph <math id="S4.SS1.p1.4.m4.1" class="ltx_Math" alttext="G" display="inline"><semantics id="S4.SS1.p1.4.m4.1a"><mi id="S4.SS1.p1.4.m4.1.1" xref="S4.SS1.p1.4.m4.1.1.cmml">G</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.4.m4.1b"><ci id="S4.SS1.p1.4.m4.1.1.cmml" xref="S4.SS1.p1.4.m4.1.1">𝐺</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.4.m4.1c">G</annotation></semantics></math>. We construct a right stochastic matrix <math id="S4.SS1.p1.5.m5.1" class="ltx_Math" alttext="A^{\prime}" display="inline"><semantics id="S4.SS1.p1.5.m5.1a"><msup id="S4.SS1.p1.5.m5.1.1" xref="S4.SS1.p1.5.m5.1.1.cmml"><mi id="S4.SS1.p1.5.m5.1.1.2" xref="S4.SS1.p1.5.m5.1.1.2.cmml">A</mi><mo id="S4.SS1.p1.5.m5.1.1.3" xref="S4.SS1.p1.5.m5.1.1.3.cmml">′</mo></msup><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.5.m5.1b"><apply id="S4.SS1.p1.5.m5.1.1.cmml" xref="S4.SS1.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S4.SS1.p1.5.m5.1.1.1.cmml" xref="S4.SS1.p1.5.m5.1.1">superscript</csymbol><ci id="S4.SS1.p1.5.m5.1.1.2.cmml" xref="S4.SS1.p1.5.m5.1.1.2">𝐴</ci><ci id="S4.SS1.p1.5.m5.1.1.3.cmml" xref="S4.SS1.p1.5.m5.1.1.3">′</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.5.m5.1c">A^{\prime}</annotation></semantics></math> where</p>
<table id="S4.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.E1.m1.1" class="ltx_Math" alttext="A^{\prime}_{ij}=\frac{A_{ij}+I_{ij}}{\sum_{k}A_{kj}+I_{kj}}\,," display="block"><semantics id="S4.E1.m1.1a"><mrow id="S4.E1.m1.1.1.1" xref="S4.E1.m1.1.1.1.1.cmml"><mrow id="S4.E1.m1.1.1.1.1" xref="S4.E1.m1.1.1.1.1.cmml"><msubsup id="S4.E1.m1.1.1.1.1.2" xref="S4.E1.m1.1.1.1.1.2.cmml"><mi id="S4.E1.m1.1.1.1.1.2.2.2" xref="S4.E1.m1.1.1.1.1.2.2.2.cmml">A</mi><mrow id="S4.E1.m1.1.1.1.1.2.3" xref="S4.E1.m1.1.1.1.1.2.3.cmml"><mi id="S4.E1.m1.1.1.1.1.2.3.2" xref="S4.E1.m1.1.1.1.1.2.3.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.E1.m1.1.1.1.1.2.3.1" xref="S4.E1.m1.1.1.1.1.2.3.1.cmml">​</mo><mi id="S4.E1.m1.1.1.1.1.2.3.3" xref="S4.E1.m1.1.1.1.1.2.3.3.cmml">j</mi></mrow><mo id="S4.E1.m1.1.1.1.1.2.2.3" xref="S4.E1.m1.1.1.1.1.2.2.3.cmml">′</mo></msubsup><mo id="S4.E1.m1.1.1.1.1.1" xref="S4.E1.m1.1.1.1.1.1.cmml">=</mo><mfrac id="S4.E1.m1.1.1.1.1.3" xref="S4.E1.m1.1.1.1.1.3.cmml"><mrow id="S4.E1.m1.1.1.1.1.3.2" xref="S4.E1.m1.1.1.1.1.3.2.cmml"><msub id="S4.E1.m1.1.1.1.1.3.2.2" xref="S4.E1.m1.1.1.1.1.3.2.2.cmml"><mi id="S4.E1.m1.1.1.1.1.3.2.2.2" xref="S4.E1.m1.1.1.1.1.3.2.2.2.cmml">A</mi><mrow id="S4.E1.m1.1.1.1.1.3.2.2.3" xref="S4.E1.m1.1.1.1.1.3.2.2.3.cmml"><mi id="S4.E1.m1.1.1.1.1.3.2.2.3.2" xref="S4.E1.m1.1.1.1.1.3.2.2.3.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.E1.m1.1.1.1.1.3.2.2.3.1" xref="S4.E1.m1.1.1.1.1.3.2.2.3.1.cmml">​</mo><mi id="S4.E1.m1.1.1.1.1.3.2.2.3.3" xref="S4.E1.m1.1.1.1.1.3.2.2.3.3.cmml">j</mi></mrow></msub><mo id="S4.E1.m1.1.1.1.1.3.2.1" xref="S4.E1.m1.1.1.1.1.3.2.1.cmml">+</mo><msub id="S4.E1.m1.1.1.1.1.3.2.3" xref="S4.E1.m1.1.1.1.1.3.2.3.cmml"><mi id="S4.E1.m1.1.1.1.1.3.2.3.2" xref="S4.E1.m1.1.1.1.1.3.2.3.2.cmml">I</mi><mrow id="S4.E1.m1.1.1.1.1.3.2.3.3" xref="S4.E1.m1.1.1.1.1.3.2.3.3.cmml"><mi id="S4.E1.m1.1.1.1.1.3.2.3.3.2" xref="S4.E1.m1.1.1.1.1.3.2.3.3.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.E1.m1.1.1.1.1.3.2.3.3.1" xref="S4.E1.m1.1.1.1.1.3.2.3.3.1.cmml">​</mo><mi id="S4.E1.m1.1.1.1.1.3.2.3.3.3" xref="S4.E1.m1.1.1.1.1.3.2.3.3.3.cmml">j</mi></mrow></msub></mrow><mrow id="S4.E1.m1.1.1.1.1.3.3" xref="S4.E1.m1.1.1.1.1.3.3.cmml"><mrow id="S4.E1.m1.1.1.1.1.3.3.2" xref="S4.E1.m1.1.1.1.1.3.3.2.cmml"><msub id="S4.E1.m1.1.1.1.1.3.3.2.1" xref="S4.E1.m1.1.1.1.1.3.3.2.1.cmml"><mo id="S4.E1.m1.1.1.1.1.3.3.2.1.2" xref="S4.E1.m1.1.1.1.1.3.3.2.1.2.cmml">∑</mo><mi id="S4.E1.m1.1.1.1.1.3.3.2.1.3" xref="S4.E1.m1.1.1.1.1.3.3.2.1.3.cmml">k</mi></msub><msub id="S4.E1.m1.1.1.1.1.3.3.2.2" xref="S4.E1.m1.1.1.1.1.3.3.2.2.cmml"><mi id="S4.E1.m1.1.1.1.1.3.3.2.2.2" xref="S4.E1.m1.1.1.1.1.3.3.2.2.2.cmml">A</mi><mrow id="S4.E1.m1.1.1.1.1.3.3.2.2.3" xref="S4.E1.m1.1.1.1.1.3.3.2.2.3.cmml"><mi id="S4.E1.m1.1.1.1.1.3.3.2.2.3.2" xref="S4.E1.m1.1.1.1.1.3.3.2.2.3.2.cmml">k</mi><mo lspace="0em" rspace="0em" id="S4.E1.m1.1.1.1.1.3.3.2.2.3.1" xref="S4.E1.m1.1.1.1.1.3.3.2.2.3.1.cmml">​</mo><mi id="S4.E1.m1.1.1.1.1.3.3.2.2.3.3" xref="S4.E1.m1.1.1.1.1.3.3.2.2.3.3.cmml">j</mi></mrow></msub></mrow><mo id="S4.E1.m1.1.1.1.1.3.3.1" xref="S4.E1.m1.1.1.1.1.3.3.1.cmml">+</mo><msub id="S4.E1.m1.1.1.1.1.3.3.3" xref="S4.E1.m1.1.1.1.1.3.3.3.cmml"><mi id="S4.E1.m1.1.1.1.1.3.3.3.2" xref="S4.E1.m1.1.1.1.1.3.3.3.2.cmml">I</mi><mrow id="S4.E1.m1.1.1.1.1.3.3.3.3" xref="S4.E1.m1.1.1.1.1.3.3.3.3.cmml"><mi id="S4.E1.m1.1.1.1.1.3.3.3.3.2" xref="S4.E1.m1.1.1.1.1.3.3.3.3.2.cmml">k</mi><mo lspace="0em" rspace="0em" id="S4.E1.m1.1.1.1.1.3.3.3.3.1" xref="S4.E1.m1.1.1.1.1.3.3.3.3.1.cmml">​</mo><mi id="S4.E1.m1.1.1.1.1.3.3.3.3.3" xref="S4.E1.m1.1.1.1.1.3.3.3.3.3.cmml">j</mi></mrow></msub></mrow></mfrac></mrow><mo lspace="0.170em" id="S4.E1.m1.1.1.1.2" xref="S4.E1.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.E1.m1.1b"><apply id="S4.E1.m1.1.1.1.1.cmml" xref="S4.E1.m1.1.1.1"><eq id="S4.E1.m1.1.1.1.1.1.cmml" xref="S4.E1.m1.1.1.1.1.1"></eq><apply id="S4.E1.m1.1.1.1.1.2.cmml" xref="S4.E1.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="S4.E1.m1.1.1.1.1.2.1.cmml" xref="S4.E1.m1.1.1.1.1.2">subscript</csymbol><apply id="S4.E1.m1.1.1.1.1.2.2.cmml" xref="S4.E1.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="S4.E1.m1.1.1.1.1.2.2.1.cmml" xref="S4.E1.m1.1.1.1.1.2">superscript</csymbol><ci id="S4.E1.m1.1.1.1.1.2.2.2.cmml" xref="S4.E1.m1.1.1.1.1.2.2.2">𝐴</ci><ci id="S4.E1.m1.1.1.1.1.2.2.3.cmml" xref="S4.E1.m1.1.1.1.1.2.2.3">′</ci></apply><apply id="S4.E1.m1.1.1.1.1.2.3.cmml" xref="S4.E1.m1.1.1.1.1.2.3"><times id="S4.E1.m1.1.1.1.1.2.3.1.cmml" xref="S4.E1.m1.1.1.1.1.2.3.1"></times><ci id="S4.E1.m1.1.1.1.1.2.3.2.cmml" xref="S4.E1.m1.1.1.1.1.2.3.2">𝑖</ci><ci id="S4.E1.m1.1.1.1.1.2.3.3.cmml" xref="S4.E1.m1.1.1.1.1.2.3.3">𝑗</ci></apply></apply><apply id="S4.E1.m1.1.1.1.1.3.cmml" xref="S4.E1.m1.1.1.1.1.3"><divide id="S4.E1.m1.1.1.1.1.3.1.cmml" xref="S4.E1.m1.1.1.1.1.3"></divide><apply id="S4.E1.m1.1.1.1.1.3.2.cmml" xref="S4.E1.m1.1.1.1.1.3.2"><plus id="S4.E1.m1.1.1.1.1.3.2.1.cmml" xref="S4.E1.m1.1.1.1.1.3.2.1"></plus><apply id="S4.E1.m1.1.1.1.1.3.2.2.cmml" xref="S4.E1.m1.1.1.1.1.3.2.2"><csymbol cd="ambiguous" id="S4.E1.m1.1.1.1.1.3.2.2.1.cmml" xref="S4.E1.m1.1.1.1.1.3.2.2">subscript</csymbol><ci id="S4.E1.m1.1.1.1.1.3.2.2.2.cmml" xref="S4.E1.m1.1.1.1.1.3.2.2.2">𝐴</ci><apply id="S4.E1.m1.1.1.1.1.3.2.2.3.cmml" xref="S4.E1.m1.1.1.1.1.3.2.2.3"><times id="S4.E1.m1.1.1.1.1.3.2.2.3.1.cmml" xref="S4.E1.m1.1.1.1.1.3.2.2.3.1"></times><ci id="S4.E1.m1.1.1.1.1.3.2.2.3.2.cmml" xref="S4.E1.m1.1.1.1.1.3.2.2.3.2">𝑖</ci><ci id="S4.E1.m1.1.1.1.1.3.2.2.3.3.cmml" xref="S4.E1.m1.1.1.1.1.3.2.2.3.3">𝑗</ci></apply></apply><apply id="S4.E1.m1.1.1.1.1.3.2.3.cmml" xref="S4.E1.m1.1.1.1.1.3.2.3"><csymbol cd="ambiguous" id="S4.E1.m1.1.1.1.1.3.2.3.1.cmml" xref="S4.E1.m1.1.1.1.1.3.2.3">subscript</csymbol><ci id="S4.E1.m1.1.1.1.1.3.2.3.2.cmml" xref="S4.E1.m1.1.1.1.1.3.2.3.2">𝐼</ci><apply id="S4.E1.m1.1.1.1.1.3.2.3.3.cmml" xref="S4.E1.m1.1.1.1.1.3.2.3.3"><times id="S4.E1.m1.1.1.1.1.3.2.3.3.1.cmml" xref="S4.E1.m1.1.1.1.1.3.2.3.3.1"></times><ci id="S4.E1.m1.1.1.1.1.3.2.3.3.2.cmml" xref="S4.E1.m1.1.1.1.1.3.2.3.3.2">𝑖</ci><ci id="S4.E1.m1.1.1.1.1.3.2.3.3.3.cmml" xref="S4.E1.m1.1.1.1.1.3.2.3.3.3">𝑗</ci></apply></apply></apply><apply id="S4.E1.m1.1.1.1.1.3.3.cmml" xref="S4.E1.m1.1.1.1.1.3.3"><plus id="S4.E1.m1.1.1.1.1.3.3.1.cmml" xref="S4.E1.m1.1.1.1.1.3.3.1"></plus><apply id="S4.E1.m1.1.1.1.1.3.3.2.cmml" xref="S4.E1.m1.1.1.1.1.3.3.2"><apply id="S4.E1.m1.1.1.1.1.3.3.2.1.cmml" xref="S4.E1.m1.1.1.1.1.3.3.2.1"><csymbol cd="ambiguous" id="S4.E1.m1.1.1.1.1.3.3.2.1.1.cmml" xref="S4.E1.m1.1.1.1.1.3.3.2.1">subscript</csymbol><sum id="S4.E1.m1.1.1.1.1.3.3.2.1.2.cmml" xref="S4.E1.m1.1.1.1.1.3.3.2.1.2"></sum><ci id="S4.E1.m1.1.1.1.1.3.3.2.1.3.cmml" xref="S4.E1.m1.1.1.1.1.3.3.2.1.3">𝑘</ci></apply><apply id="S4.E1.m1.1.1.1.1.3.3.2.2.cmml" xref="S4.E1.m1.1.1.1.1.3.3.2.2"><csymbol cd="ambiguous" id="S4.E1.m1.1.1.1.1.3.3.2.2.1.cmml" xref="S4.E1.m1.1.1.1.1.3.3.2.2">subscript</csymbol><ci id="S4.E1.m1.1.1.1.1.3.3.2.2.2.cmml" xref="S4.E1.m1.1.1.1.1.3.3.2.2.2">𝐴</ci><apply id="S4.E1.m1.1.1.1.1.3.3.2.2.3.cmml" xref="S4.E1.m1.1.1.1.1.3.3.2.2.3"><times id="S4.E1.m1.1.1.1.1.3.3.2.2.3.1.cmml" xref="S4.E1.m1.1.1.1.1.3.3.2.2.3.1"></times><ci id="S4.E1.m1.1.1.1.1.3.3.2.2.3.2.cmml" xref="S4.E1.m1.1.1.1.1.3.3.2.2.3.2">𝑘</ci><ci id="S4.E1.m1.1.1.1.1.3.3.2.2.3.3.cmml" xref="S4.E1.m1.1.1.1.1.3.3.2.2.3.3">𝑗</ci></apply></apply></apply><apply id="S4.E1.m1.1.1.1.1.3.3.3.cmml" xref="S4.E1.m1.1.1.1.1.3.3.3"><csymbol cd="ambiguous" id="S4.E1.m1.1.1.1.1.3.3.3.1.cmml" xref="S4.E1.m1.1.1.1.1.3.3.3">subscript</csymbol><ci id="S4.E1.m1.1.1.1.1.3.3.3.2.cmml" xref="S4.E1.m1.1.1.1.1.3.3.3.2">𝐼</ci><apply id="S4.E1.m1.1.1.1.1.3.3.3.3.cmml" xref="S4.E1.m1.1.1.1.1.3.3.3.3"><times id="S4.E1.m1.1.1.1.1.3.3.3.3.1.cmml" xref="S4.E1.m1.1.1.1.1.3.3.3.3.1"></times><ci id="S4.E1.m1.1.1.1.1.3.3.3.3.2.cmml" xref="S4.E1.m1.1.1.1.1.3.3.3.3.2">𝑘</ci><ci id="S4.E1.m1.1.1.1.1.3.3.3.3.3.cmml" xref="S4.E1.m1.1.1.1.1.3.3.3.3.3">𝑗</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E1.m1.1c">A^{\prime}_{ij}=\frac{A_{ij}+I_{ij}}{\sum_{k}A_{kj}+I_{kj}}\,,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p id="S4.SS1.p1.15" class="ltx_p">where <math id="S4.SS1.p1.6.m1.1" class="ltx_Math" alttext="I_{kj}=\delta_{kj}" display="inline"><semantics id="S4.SS1.p1.6.m1.1a"><mrow id="S4.SS1.p1.6.m1.1.1" xref="S4.SS1.p1.6.m1.1.1.cmml"><msub id="S4.SS1.p1.6.m1.1.1.2" xref="S4.SS1.p1.6.m1.1.1.2.cmml"><mi id="S4.SS1.p1.6.m1.1.1.2.2" xref="S4.SS1.p1.6.m1.1.1.2.2.cmml">I</mi><mrow id="S4.SS1.p1.6.m1.1.1.2.3" xref="S4.SS1.p1.6.m1.1.1.2.3.cmml"><mi id="S4.SS1.p1.6.m1.1.1.2.3.2" xref="S4.SS1.p1.6.m1.1.1.2.3.2.cmml">k</mi><mo lspace="0em" rspace="0em" id="S4.SS1.p1.6.m1.1.1.2.3.1" xref="S4.SS1.p1.6.m1.1.1.2.3.1.cmml">​</mo><mi id="S4.SS1.p1.6.m1.1.1.2.3.3" xref="S4.SS1.p1.6.m1.1.1.2.3.3.cmml">j</mi></mrow></msub><mo id="S4.SS1.p1.6.m1.1.1.1" xref="S4.SS1.p1.6.m1.1.1.1.cmml">=</mo><msub id="S4.SS1.p1.6.m1.1.1.3" xref="S4.SS1.p1.6.m1.1.1.3.cmml"><mi id="S4.SS1.p1.6.m1.1.1.3.2" xref="S4.SS1.p1.6.m1.1.1.3.2.cmml">δ</mi><mrow id="S4.SS1.p1.6.m1.1.1.3.3" xref="S4.SS1.p1.6.m1.1.1.3.3.cmml"><mi id="S4.SS1.p1.6.m1.1.1.3.3.2" xref="S4.SS1.p1.6.m1.1.1.3.3.2.cmml">k</mi><mo lspace="0em" rspace="0em" id="S4.SS1.p1.6.m1.1.1.3.3.1" xref="S4.SS1.p1.6.m1.1.1.3.3.1.cmml">​</mo><mi id="S4.SS1.p1.6.m1.1.1.3.3.3" xref="S4.SS1.p1.6.m1.1.1.3.3.3.cmml">j</mi></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.6.m1.1b"><apply id="S4.SS1.p1.6.m1.1.1.cmml" xref="S4.SS1.p1.6.m1.1.1"><eq id="S4.SS1.p1.6.m1.1.1.1.cmml" xref="S4.SS1.p1.6.m1.1.1.1"></eq><apply id="S4.SS1.p1.6.m1.1.1.2.cmml" xref="S4.SS1.p1.6.m1.1.1.2"><csymbol cd="ambiguous" id="S4.SS1.p1.6.m1.1.1.2.1.cmml" xref="S4.SS1.p1.6.m1.1.1.2">subscript</csymbol><ci id="S4.SS1.p1.6.m1.1.1.2.2.cmml" xref="S4.SS1.p1.6.m1.1.1.2.2">𝐼</ci><apply id="S4.SS1.p1.6.m1.1.1.2.3.cmml" xref="S4.SS1.p1.6.m1.1.1.2.3"><times id="S4.SS1.p1.6.m1.1.1.2.3.1.cmml" xref="S4.SS1.p1.6.m1.1.1.2.3.1"></times><ci id="S4.SS1.p1.6.m1.1.1.2.3.2.cmml" xref="S4.SS1.p1.6.m1.1.1.2.3.2">𝑘</ci><ci id="S4.SS1.p1.6.m1.1.1.2.3.3.cmml" xref="S4.SS1.p1.6.m1.1.1.2.3.3">𝑗</ci></apply></apply><apply id="S4.SS1.p1.6.m1.1.1.3.cmml" xref="S4.SS1.p1.6.m1.1.1.3"><csymbol cd="ambiguous" id="S4.SS1.p1.6.m1.1.1.3.1.cmml" xref="S4.SS1.p1.6.m1.1.1.3">subscript</csymbol><ci id="S4.SS1.p1.6.m1.1.1.3.2.cmml" xref="S4.SS1.p1.6.m1.1.1.3.2">𝛿</ci><apply id="S4.SS1.p1.6.m1.1.1.3.3.cmml" xref="S4.SS1.p1.6.m1.1.1.3.3"><times id="S4.SS1.p1.6.m1.1.1.3.3.1.cmml" xref="S4.SS1.p1.6.m1.1.1.3.3.1"></times><ci id="S4.SS1.p1.6.m1.1.1.3.3.2.cmml" xref="S4.SS1.p1.6.m1.1.1.3.3.2">𝑘</ci><ci id="S4.SS1.p1.6.m1.1.1.3.3.3.cmml" xref="S4.SS1.p1.6.m1.1.1.3.3.3">𝑗</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.6.m1.1c">I_{kj}=\delta_{kj}</annotation></semantics></math> are the elements of an identity matrix <math id="S4.SS1.p1.7.m2.1" class="ltx_Math" alttext="I" display="inline"><semantics id="S4.SS1.p1.7.m2.1a"><mi id="S4.SS1.p1.7.m2.1.1" xref="S4.SS1.p1.7.m2.1.1.cmml">I</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.7.m2.1b"><ci id="S4.SS1.p1.7.m2.1.1.cmml" xref="S4.SS1.p1.7.m2.1.1">𝐼</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.7.m2.1c">I</annotation></semantics></math>. This corresponds to the Markov transition matrix of random walks on graph <math id="S4.SS1.p1.8.m3.1" class="ltx_Math" alttext="G" display="inline"><semantics id="S4.SS1.p1.8.m3.1a"><mi id="S4.SS1.p1.8.m3.1.1" xref="S4.SS1.p1.8.m3.1.1.cmml">G</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.8.m3.1b"><ci id="S4.SS1.p1.8.m3.1.1.cmml" xref="S4.SS1.p1.8.m3.1.1">𝐺</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.8.m3.1c">G</annotation></semantics></math>, if the random walker can stay at the same node or take one of the links connected to that node with equal probability for each possible action. If we arrange all initial node parameters in a <math id="S4.SS1.p1.9.m4.1" class="ltx_Math" alttext="p\times n" display="inline"><semantics id="S4.SS1.p1.9.m4.1a"><mrow id="S4.SS1.p1.9.m4.1.1" xref="S4.SS1.p1.9.m4.1.1.cmml"><mi id="S4.SS1.p1.9.m4.1.1.2" xref="S4.SS1.p1.9.m4.1.1.2.cmml">p</mi><mo lspace="0.222em" rspace="0.222em" id="S4.SS1.p1.9.m4.1.1.1" xref="S4.SS1.p1.9.m4.1.1.1.cmml">×</mo><mi id="S4.SS1.p1.9.m4.1.1.3" xref="S4.SS1.p1.9.m4.1.1.3.cmml">n</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.9.m4.1b"><apply id="S4.SS1.p1.9.m4.1.1.cmml" xref="S4.SS1.p1.9.m4.1.1"><times id="S4.SS1.p1.9.m4.1.1.1.cmml" xref="S4.SS1.p1.9.m4.1.1.1"></times><ci id="S4.SS1.p1.9.m4.1.1.2.cmml" xref="S4.SS1.p1.9.m4.1.1.2">𝑝</ci><ci id="S4.SS1.p1.9.m4.1.1.3.cmml" xref="S4.SS1.p1.9.m4.1.1.3">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.9.m4.1c">p\times n</annotation></semantics></math> matrix <math id="S4.SS1.p1.10.m5.1" class="ltx_Math" alttext="W_{\text{init}}" display="inline"><semantics id="S4.SS1.p1.10.m5.1a"><msub id="S4.SS1.p1.10.m5.1.1" xref="S4.SS1.p1.10.m5.1.1.cmml"><mi id="S4.SS1.p1.10.m5.1.1.2" xref="S4.SS1.p1.10.m5.1.1.2.cmml">W</mi><mtext id="S4.SS1.p1.10.m5.1.1.3" xref="S4.SS1.p1.10.m5.1.1.3a.cmml">init</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.10.m5.1b"><apply id="S4.SS1.p1.10.m5.1.1.cmml" xref="S4.SS1.p1.10.m5.1.1"><csymbol cd="ambiguous" id="S4.SS1.p1.10.m5.1.1.1.cmml" xref="S4.SS1.p1.10.m5.1.1">subscript</csymbol><ci id="S4.SS1.p1.10.m5.1.1.2.cmml" xref="S4.SS1.p1.10.m5.1.1.2">𝑊</ci><ci id="S4.SS1.p1.10.m5.1.1.3a.cmml" xref="S4.SS1.p1.10.m5.1.1.3"><mtext mathsize="70%" id="S4.SS1.p1.10.m5.1.1.3.cmml" xref="S4.SS1.p1.10.m5.1.1.3">init</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.10.m5.1c">W_{\text{init}}</annotation></semantics></math>, the parameters at round <math id="S4.SS1.p1.11.m6.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S4.SS1.p1.11.m6.1a"><mi id="S4.SS1.p1.11.m6.1.1" xref="S4.SS1.p1.11.m6.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.11.m6.1b"><ci id="S4.SS1.p1.11.m6.1.1.cmml" xref="S4.SS1.p1.11.m6.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.11.m6.1c">t</annotation></semantics></math> are determined by <math id="S4.SS1.p1.12.m7.4" class="ltx_Math" alttext="W_{\text{init}}A^{\prime t}+\sum^{t-1}_{i=0}N_{i}A^{\prime i}" display="inline"><semantics id="S4.SS1.p1.12.m7.4a"><mrow id="S4.SS1.p1.12.m7.4.5" xref="S4.SS1.p1.12.m7.4.5.cmml"><mrow id="S4.SS1.p1.12.m7.4.5.2" xref="S4.SS1.p1.12.m7.4.5.2.cmml"><msub id="S4.SS1.p1.12.m7.4.5.2.2" xref="S4.SS1.p1.12.m7.4.5.2.2.cmml"><mi id="S4.SS1.p1.12.m7.4.5.2.2.2" xref="S4.SS1.p1.12.m7.4.5.2.2.2.cmml">W</mi><mtext id="S4.SS1.p1.12.m7.4.5.2.2.3" xref="S4.SS1.p1.12.m7.4.5.2.2.3a.cmml">init</mtext></msub><mo lspace="0em" rspace="0em" id="S4.SS1.p1.12.m7.4.5.2.1" xref="S4.SS1.p1.12.m7.4.5.2.1.cmml">​</mo><msup id="S4.SS1.p1.12.m7.4.5.2.3" xref="S4.SS1.p1.12.m7.4.5.2.3.cmml"><mi id="S4.SS1.p1.12.m7.4.5.2.3.2" xref="S4.SS1.p1.12.m7.4.5.2.3.2.cmml">A</mi><mrow id="S4.SS1.p1.12.m7.2.2.2.2" xref="S4.SS1.p1.12.m7.2.2.2.3.cmml"><mo mathsize="142%" id="S4.SS1.p1.12.m7.2.2.2.2.1" xref="S4.SS1.p1.12.m7.2.2.2.2.1.cmml">′</mo><mo lspace="0em" id="S4.SS1.p1.12.m7.2.2.2.2.2" xref="S4.SS1.p1.12.m7.2.2.2.3.cmml">⁣</mo><mi id="S4.SS1.p1.12.m7.1.1.1.1" xref="S4.SS1.p1.12.m7.1.1.1.1.cmml">t</mi></mrow></msup></mrow><mo rspace="0.055em" id="S4.SS1.p1.12.m7.4.5.1" xref="S4.SS1.p1.12.m7.4.5.1.cmml">+</mo><mrow id="S4.SS1.p1.12.m7.4.5.3" xref="S4.SS1.p1.12.m7.4.5.3.cmml"><msubsup id="S4.SS1.p1.12.m7.4.5.3.1" xref="S4.SS1.p1.12.m7.4.5.3.1.cmml"><mo id="S4.SS1.p1.12.m7.4.5.3.1.2.2" xref="S4.SS1.p1.12.m7.4.5.3.1.2.2.cmml">∑</mo><mrow id="S4.SS1.p1.12.m7.4.5.3.1.3" xref="S4.SS1.p1.12.m7.4.5.3.1.3.cmml"><mi id="S4.SS1.p1.12.m7.4.5.3.1.3.2" xref="S4.SS1.p1.12.m7.4.5.3.1.3.2.cmml">i</mi><mo id="S4.SS1.p1.12.m7.4.5.3.1.3.1" xref="S4.SS1.p1.12.m7.4.5.3.1.3.1.cmml">=</mo><mn id="S4.SS1.p1.12.m7.4.5.3.1.3.3" xref="S4.SS1.p1.12.m7.4.5.3.1.3.3.cmml">0</mn></mrow><mrow id="S4.SS1.p1.12.m7.4.5.3.1.2.3" xref="S4.SS1.p1.12.m7.4.5.3.1.2.3.cmml"><mi id="S4.SS1.p1.12.m7.4.5.3.1.2.3.2" xref="S4.SS1.p1.12.m7.4.5.3.1.2.3.2.cmml">t</mi><mo id="S4.SS1.p1.12.m7.4.5.3.1.2.3.1" xref="S4.SS1.p1.12.m7.4.5.3.1.2.3.1.cmml">−</mo><mn id="S4.SS1.p1.12.m7.4.5.3.1.2.3.3" xref="S4.SS1.p1.12.m7.4.5.3.1.2.3.3.cmml">1</mn></mrow></msubsup><mrow id="S4.SS1.p1.12.m7.4.5.3.2" xref="S4.SS1.p1.12.m7.4.5.3.2.cmml"><msub id="S4.SS1.p1.12.m7.4.5.3.2.2" xref="S4.SS1.p1.12.m7.4.5.3.2.2.cmml"><mi id="S4.SS1.p1.12.m7.4.5.3.2.2.2" xref="S4.SS1.p1.12.m7.4.5.3.2.2.2.cmml">N</mi><mi id="S4.SS1.p1.12.m7.4.5.3.2.2.3" xref="S4.SS1.p1.12.m7.4.5.3.2.2.3.cmml">i</mi></msub><mo lspace="0em" rspace="0em" id="S4.SS1.p1.12.m7.4.5.3.2.1" xref="S4.SS1.p1.12.m7.4.5.3.2.1.cmml">​</mo><msup id="S4.SS1.p1.12.m7.4.5.3.2.3" xref="S4.SS1.p1.12.m7.4.5.3.2.3.cmml"><mi id="S4.SS1.p1.12.m7.4.5.3.2.3.2" xref="S4.SS1.p1.12.m7.4.5.3.2.3.2.cmml">A</mi><mrow id="S4.SS1.p1.12.m7.4.4.2.2" xref="S4.SS1.p1.12.m7.4.4.2.3.cmml"><mo mathsize="142%" id="S4.SS1.p1.12.m7.4.4.2.2.1" xref="S4.SS1.p1.12.m7.4.4.2.2.1.cmml">′</mo><mo lspace="0em" id="S4.SS1.p1.12.m7.4.4.2.2.2" xref="S4.SS1.p1.12.m7.4.4.2.3.cmml">⁣</mo><mi id="S4.SS1.p1.12.m7.3.3.1.1" xref="S4.SS1.p1.12.m7.3.3.1.1.cmml">i</mi></mrow></msup></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.12.m7.4b"><apply id="S4.SS1.p1.12.m7.4.5.cmml" xref="S4.SS1.p1.12.m7.4.5"><plus id="S4.SS1.p1.12.m7.4.5.1.cmml" xref="S4.SS1.p1.12.m7.4.5.1"></plus><apply id="S4.SS1.p1.12.m7.4.5.2.cmml" xref="S4.SS1.p1.12.m7.4.5.2"><times id="S4.SS1.p1.12.m7.4.5.2.1.cmml" xref="S4.SS1.p1.12.m7.4.5.2.1"></times><apply id="S4.SS1.p1.12.m7.4.5.2.2.cmml" xref="S4.SS1.p1.12.m7.4.5.2.2"><csymbol cd="ambiguous" id="S4.SS1.p1.12.m7.4.5.2.2.1.cmml" xref="S4.SS1.p1.12.m7.4.5.2.2">subscript</csymbol><ci id="S4.SS1.p1.12.m7.4.5.2.2.2.cmml" xref="S4.SS1.p1.12.m7.4.5.2.2.2">𝑊</ci><ci id="S4.SS1.p1.12.m7.4.5.2.2.3a.cmml" xref="S4.SS1.p1.12.m7.4.5.2.2.3"><mtext mathsize="70%" id="S4.SS1.p1.12.m7.4.5.2.2.3.cmml" xref="S4.SS1.p1.12.m7.4.5.2.2.3">init</mtext></ci></apply><apply id="S4.SS1.p1.12.m7.4.5.2.3.cmml" xref="S4.SS1.p1.12.m7.4.5.2.3"><csymbol cd="ambiguous" id="S4.SS1.p1.12.m7.4.5.2.3.1.cmml" xref="S4.SS1.p1.12.m7.4.5.2.3">superscript</csymbol><ci id="S4.SS1.p1.12.m7.4.5.2.3.2.cmml" xref="S4.SS1.p1.12.m7.4.5.2.3.2">𝐴</ci><list id="S4.SS1.p1.12.m7.2.2.2.3.cmml" xref="S4.SS1.p1.12.m7.2.2.2.2"><ci id="S4.SS1.p1.12.m7.2.2.2.2.1.cmml" xref="S4.SS1.p1.12.m7.2.2.2.2.1">′</ci><ci id="S4.SS1.p1.12.m7.1.1.1.1.cmml" xref="S4.SS1.p1.12.m7.1.1.1.1">𝑡</ci></list></apply></apply><apply id="S4.SS1.p1.12.m7.4.5.3.cmml" xref="S4.SS1.p1.12.m7.4.5.3"><apply id="S4.SS1.p1.12.m7.4.5.3.1.cmml" xref="S4.SS1.p1.12.m7.4.5.3.1"><csymbol cd="ambiguous" id="S4.SS1.p1.12.m7.4.5.3.1.1.cmml" xref="S4.SS1.p1.12.m7.4.5.3.1">subscript</csymbol><apply id="S4.SS1.p1.12.m7.4.5.3.1.2.cmml" xref="S4.SS1.p1.12.m7.4.5.3.1"><csymbol cd="ambiguous" id="S4.SS1.p1.12.m7.4.5.3.1.2.1.cmml" xref="S4.SS1.p1.12.m7.4.5.3.1">superscript</csymbol><sum id="S4.SS1.p1.12.m7.4.5.3.1.2.2.cmml" xref="S4.SS1.p1.12.m7.4.5.3.1.2.2"></sum><apply id="S4.SS1.p1.12.m7.4.5.3.1.2.3.cmml" xref="S4.SS1.p1.12.m7.4.5.3.1.2.3"><minus id="S4.SS1.p1.12.m7.4.5.3.1.2.3.1.cmml" xref="S4.SS1.p1.12.m7.4.5.3.1.2.3.1"></minus><ci id="S4.SS1.p1.12.m7.4.5.3.1.2.3.2.cmml" xref="S4.SS1.p1.12.m7.4.5.3.1.2.3.2">𝑡</ci><cn type="integer" id="S4.SS1.p1.12.m7.4.5.3.1.2.3.3.cmml" xref="S4.SS1.p1.12.m7.4.5.3.1.2.3.3">1</cn></apply></apply><apply id="S4.SS1.p1.12.m7.4.5.3.1.3.cmml" xref="S4.SS1.p1.12.m7.4.5.3.1.3"><eq id="S4.SS1.p1.12.m7.4.5.3.1.3.1.cmml" xref="S4.SS1.p1.12.m7.4.5.3.1.3.1"></eq><ci id="S4.SS1.p1.12.m7.4.5.3.1.3.2.cmml" xref="S4.SS1.p1.12.m7.4.5.3.1.3.2">𝑖</ci><cn type="integer" id="S4.SS1.p1.12.m7.4.5.3.1.3.3.cmml" xref="S4.SS1.p1.12.m7.4.5.3.1.3.3">0</cn></apply></apply><apply id="S4.SS1.p1.12.m7.4.5.3.2.cmml" xref="S4.SS1.p1.12.m7.4.5.3.2"><times id="S4.SS1.p1.12.m7.4.5.3.2.1.cmml" xref="S4.SS1.p1.12.m7.4.5.3.2.1"></times><apply id="S4.SS1.p1.12.m7.4.5.3.2.2.cmml" xref="S4.SS1.p1.12.m7.4.5.3.2.2"><csymbol cd="ambiguous" id="S4.SS1.p1.12.m7.4.5.3.2.2.1.cmml" xref="S4.SS1.p1.12.m7.4.5.3.2.2">subscript</csymbol><ci id="S4.SS1.p1.12.m7.4.5.3.2.2.2.cmml" xref="S4.SS1.p1.12.m7.4.5.3.2.2.2">𝑁</ci><ci id="S4.SS1.p1.12.m7.4.5.3.2.2.3.cmml" xref="S4.SS1.p1.12.m7.4.5.3.2.2.3">𝑖</ci></apply><apply id="S4.SS1.p1.12.m7.4.5.3.2.3.cmml" xref="S4.SS1.p1.12.m7.4.5.3.2.3"><csymbol cd="ambiguous" id="S4.SS1.p1.12.m7.4.5.3.2.3.1.cmml" xref="S4.SS1.p1.12.m7.4.5.3.2.3">superscript</csymbol><ci id="S4.SS1.p1.12.m7.4.5.3.2.3.2.cmml" xref="S4.SS1.p1.12.m7.4.5.3.2.3.2">𝐴</ci><list id="S4.SS1.p1.12.m7.4.4.2.3.cmml" xref="S4.SS1.p1.12.m7.4.4.2.2"><ci id="S4.SS1.p1.12.m7.4.4.2.2.1.cmml" xref="S4.SS1.p1.12.m7.4.4.2.2.1">′</ci><ci id="S4.SS1.p1.12.m7.3.3.1.1.cmml" xref="S4.SS1.p1.12.m7.3.3.1.1">𝑖</ci></list></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.12.m7.4c">W_{\text{init}}A^{\prime t}+\sum^{t-1}_{i=0}N_{i}A^{\prime i}</annotation></semantics></math>, where <math id="S4.SS1.p1.13.m8.1" class="ltx_Math" alttext="N_{i}" display="inline"><semantics id="S4.SS1.p1.13.m8.1a"><msub id="S4.SS1.p1.13.m8.1.1" xref="S4.SS1.p1.13.m8.1.1.cmml"><mi id="S4.SS1.p1.13.m8.1.1.2" xref="S4.SS1.p1.13.m8.1.1.2.cmml">N</mi><mi id="S4.SS1.p1.13.m8.1.1.3" xref="S4.SS1.p1.13.m8.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.13.m8.1b"><apply id="S4.SS1.p1.13.m8.1.1.cmml" xref="S4.SS1.p1.13.m8.1.1"><csymbol cd="ambiguous" id="S4.SS1.p1.13.m8.1.1.1.cmml" xref="S4.SS1.p1.13.m8.1.1">subscript</csymbol><ci id="S4.SS1.p1.13.m8.1.1.2.cmml" xref="S4.SS1.p1.13.m8.1.1.2">𝑁</ci><ci id="S4.SS1.p1.13.m8.1.1.3.cmml" xref="S4.SS1.p1.13.m8.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.13.m8.1c">N_{i}</annotation></semantics></math> is a random <math id="S4.SS1.p1.14.m9.1" class="ltx_Math" alttext="p\times n" display="inline"><semantics id="S4.SS1.p1.14.m9.1a"><mrow id="S4.SS1.p1.14.m9.1.1" xref="S4.SS1.p1.14.m9.1.1.cmml"><mi id="S4.SS1.p1.14.m9.1.1.2" xref="S4.SS1.p1.14.m9.1.1.2.cmml">p</mi><mo lspace="0.222em" rspace="0.222em" id="S4.SS1.p1.14.m9.1.1.1" xref="S4.SS1.p1.14.m9.1.1.1.cmml">×</mo><mi id="S4.SS1.p1.14.m9.1.1.3" xref="S4.SS1.p1.14.m9.1.1.3.cmml">n</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.14.m9.1b"><apply id="S4.SS1.p1.14.m9.1.1.cmml" xref="S4.SS1.p1.14.m9.1.1"><times id="S4.SS1.p1.14.m9.1.1.1.cmml" xref="S4.SS1.p1.14.m9.1.1.1"></times><ci id="S4.SS1.p1.14.m9.1.1.2.cmml" xref="S4.SS1.p1.14.m9.1.1.2">𝑝</ci><ci id="S4.SS1.p1.14.m9.1.1.3.cmml" xref="S4.SS1.p1.14.m9.1.1.3">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.14.m9.1c">p\times n</annotation></semantics></math> noise matrix with each index drawn from <math id="S4.SS1.p1.15.m10.2" class="ltx_Math" alttext="\mathcal{N}(0,\sigma_{\text{noise}}^{2})" display="inline"><semantics id="S4.SS1.p1.15.m10.2a"><mrow id="S4.SS1.p1.15.m10.2.2" xref="S4.SS1.p1.15.m10.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS1.p1.15.m10.2.2.3" xref="S4.SS1.p1.15.m10.2.2.3.cmml">𝒩</mi><mo lspace="0em" rspace="0em" id="S4.SS1.p1.15.m10.2.2.2" xref="S4.SS1.p1.15.m10.2.2.2.cmml">​</mo><mrow id="S4.SS1.p1.15.m10.2.2.1.1" xref="S4.SS1.p1.15.m10.2.2.1.2.cmml"><mo stretchy="false" id="S4.SS1.p1.15.m10.2.2.1.1.2" xref="S4.SS1.p1.15.m10.2.2.1.2.cmml">(</mo><mn id="S4.SS1.p1.15.m10.1.1" xref="S4.SS1.p1.15.m10.1.1.cmml">0</mn><mo id="S4.SS1.p1.15.m10.2.2.1.1.3" xref="S4.SS1.p1.15.m10.2.2.1.2.cmml">,</mo><msubsup id="S4.SS1.p1.15.m10.2.2.1.1.1" xref="S4.SS1.p1.15.m10.2.2.1.1.1.cmml"><mi id="S4.SS1.p1.15.m10.2.2.1.1.1.2.2" xref="S4.SS1.p1.15.m10.2.2.1.1.1.2.2.cmml">σ</mi><mtext id="S4.SS1.p1.15.m10.2.2.1.1.1.2.3" xref="S4.SS1.p1.15.m10.2.2.1.1.1.2.3a.cmml">noise</mtext><mn id="S4.SS1.p1.15.m10.2.2.1.1.1.3" xref="S4.SS1.p1.15.m10.2.2.1.1.1.3.cmml">2</mn></msubsup><mo stretchy="false" id="S4.SS1.p1.15.m10.2.2.1.1.4" xref="S4.SS1.p1.15.m10.2.2.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.15.m10.2b"><apply id="S4.SS1.p1.15.m10.2.2.cmml" xref="S4.SS1.p1.15.m10.2.2"><times id="S4.SS1.p1.15.m10.2.2.2.cmml" xref="S4.SS1.p1.15.m10.2.2.2"></times><ci id="S4.SS1.p1.15.m10.2.2.3.cmml" xref="S4.SS1.p1.15.m10.2.2.3">𝒩</ci><interval closure="open" id="S4.SS1.p1.15.m10.2.2.1.2.cmml" xref="S4.SS1.p1.15.m10.2.2.1.1"><cn type="integer" id="S4.SS1.p1.15.m10.1.1.cmml" xref="S4.SS1.p1.15.m10.1.1">0</cn><apply id="S4.SS1.p1.15.m10.2.2.1.1.1.cmml" xref="S4.SS1.p1.15.m10.2.2.1.1.1"><csymbol cd="ambiguous" id="S4.SS1.p1.15.m10.2.2.1.1.1.1.cmml" xref="S4.SS1.p1.15.m10.2.2.1.1.1">superscript</csymbol><apply id="S4.SS1.p1.15.m10.2.2.1.1.1.2.cmml" xref="S4.SS1.p1.15.m10.2.2.1.1.1"><csymbol cd="ambiguous" id="S4.SS1.p1.15.m10.2.2.1.1.1.2.1.cmml" xref="S4.SS1.p1.15.m10.2.2.1.1.1">subscript</csymbol><ci id="S4.SS1.p1.15.m10.2.2.1.1.1.2.2.cmml" xref="S4.SS1.p1.15.m10.2.2.1.1.1.2.2">𝜎</ci><ci id="S4.SS1.p1.15.m10.2.2.1.1.1.2.3a.cmml" xref="S4.SS1.p1.15.m10.2.2.1.1.1.2.3"><mtext mathsize="70%" id="S4.SS1.p1.15.m10.2.2.1.1.1.2.3.cmml" xref="S4.SS1.p1.15.m10.2.2.1.1.1.2.3">noise</mtext></ci></apply><cn type="integer" id="S4.SS1.p1.15.m10.2.2.1.1.1.3.cmml" xref="S4.SS1.p1.15.m10.2.2.1.1.1.3">2</cn></apply></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.15.m10.2c">\mathcal{N}(0,\sigma_{\text{noise}}^{2})</annotation></semantics></math>.</p>
</div>
<div id="S4.SS1.p2" class="ltx_para">
<p id="S4.SS1.p2.6" class="ltx_p">Assuming that the graph <math id="S4.SS1.p2.1.m1.1" class="ltx_Math" alttext="G" display="inline"><semantics id="S4.SS1.p2.1.m1.1a"><mi id="S4.SS1.p2.1.m1.1.1" xref="S4.SS1.p2.1.m1.1.1.cmml">G</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.1.m1.1b"><ci id="S4.SS1.p2.1.m1.1.1.cmml" xref="S4.SS1.p2.1.m1.1.1">𝐺</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.1.m1.1c">G</annotation></semantics></math> is connected, the matrix <math id="S4.SS1.p2.2.m2.2" class="ltx_Math" alttext="A^{\prime t}" display="inline"><semantics id="S4.SS1.p2.2.m2.2a"><msup id="S4.SS1.p2.2.m2.2.3" xref="S4.SS1.p2.2.m2.2.3.cmml"><mi id="S4.SS1.p2.2.m2.2.3.2" xref="S4.SS1.p2.2.m2.2.3.2.cmml">A</mi><mrow id="S4.SS1.p2.2.m2.2.2.2.2" xref="S4.SS1.p2.2.m2.2.2.2.3.cmml"><mo mathsize="142%" id="S4.SS1.p2.2.m2.2.2.2.2.1" xref="S4.SS1.p2.2.m2.2.2.2.2.1.cmml">′</mo><mo lspace="0em" id="S4.SS1.p2.2.m2.2.2.2.2.2" xref="S4.SS1.p2.2.m2.2.2.2.3.cmml">⁣</mo><mi id="S4.SS1.p2.2.m2.1.1.1.1" xref="S4.SS1.p2.2.m2.1.1.1.1.cmml">t</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.2.m2.2b"><apply id="S4.SS1.p2.2.m2.2.3.cmml" xref="S4.SS1.p2.2.m2.2.3"><csymbol cd="ambiguous" id="S4.SS1.p2.2.m2.2.3.1.cmml" xref="S4.SS1.p2.2.m2.2.3">superscript</csymbol><ci id="S4.SS1.p2.2.m2.2.3.2.cmml" xref="S4.SS1.p2.2.m2.2.3.2">𝐴</ci><list id="S4.SS1.p2.2.m2.2.2.2.3.cmml" xref="S4.SS1.p2.2.m2.2.2.2.2"><ci id="S4.SS1.p2.2.m2.2.2.2.2.1.cmml" xref="S4.SS1.p2.2.m2.2.2.2.2.1">′</ci><ci id="S4.SS1.p2.2.m2.1.1.1.1.cmml" xref="S4.SS1.p2.2.m2.1.1.1.1">𝑡</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.2.m2.2c">A^{\prime t}</annotation></semantics></math> would converge to a matrix where each row is the steady state vector of the Markov matrix <math id="S4.SS1.p2.3.m3.1" class="ltx_Math" alttext="A^{\prime}" display="inline"><semantics id="S4.SS1.p2.3.m3.1a"><msup id="S4.SS1.p2.3.m3.1.1" xref="S4.SS1.p2.3.m3.1.1.cmml"><mi id="S4.SS1.p2.3.m3.1.1.2" xref="S4.SS1.p2.3.m3.1.1.2.cmml">A</mi><mo id="S4.SS1.p2.3.m3.1.1.3" xref="S4.SS1.p2.3.m3.1.1.3.cmml">′</mo></msup><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.3.m3.1b"><apply id="S4.SS1.p2.3.m3.1.1.cmml" xref="S4.SS1.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S4.SS1.p2.3.m3.1.1.1.cmml" xref="S4.SS1.p2.3.m3.1.1">superscript</csymbol><ci id="S4.SS1.p2.3.m3.1.1.2.cmml" xref="S4.SS1.p2.3.m3.1.1.2">𝐴</ci><ci id="S4.SS1.p2.3.m3.1.1.3.cmml" xref="S4.SS1.p2.3.m3.1.1.3">′</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.3.m3.1c">A^{\prime}</annotation></semantics></math>, the eigenvector corresponding to the largest eigenvalue 1, normalised to sum to 1. If the steady state vector is given as <math id="S4.SS1.p2.4.m4.1" class="ltx_Math" alttext="v_{\text{steady}}" display="inline"><semantics id="S4.SS1.p2.4.m4.1a"><msub id="S4.SS1.p2.4.m4.1.1" xref="S4.SS1.p2.4.m4.1.1.cmml"><mi id="S4.SS1.p2.4.m4.1.1.2" xref="S4.SS1.p2.4.m4.1.1.2.cmml">v</mi><mtext id="S4.SS1.p2.4.m4.1.1.3" xref="S4.SS1.p2.4.m4.1.1.3a.cmml">steady</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.4.m4.1b"><apply id="S4.SS1.p2.4.m4.1.1.cmml" xref="S4.SS1.p2.4.m4.1.1"><csymbol cd="ambiguous" id="S4.SS1.p2.4.m4.1.1.1.cmml" xref="S4.SS1.p2.4.m4.1.1">subscript</csymbol><ci id="S4.SS1.p2.4.m4.1.1.2.cmml" xref="S4.SS1.p2.4.m4.1.1.2">𝑣</ci><ci id="S4.SS1.p2.4.m4.1.1.3a.cmml" xref="S4.SS1.p2.4.m4.1.1.3"><mtext mathsize="70%" id="S4.SS1.p2.4.m4.1.1.3.cmml" xref="S4.SS1.p2.4.m4.1.1.3">steady</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.4.m4.1c">v_{\text{steady}}</annotation></semantics></math> the variance contribution of the term <math id="S4.SS1.p2.5.m5.2" class="ltx_Math" alttext="W_{\text{init}}A^{\prime t}" display="inline"><semantics id="S4.SS1.p2.5.m5.2a"><mrow id="S4.SS1.p2.5.m5.2.3" xref="S4.SS1.p2.5.m5.2.3.cmml"><msub id="S4.SS1.p2.5.m5.2.3.2" xref="S4.SS1.p2.5.m5.2.3.2.cmml"><mi id="S4.SS1.p2.5.m5.2.3.2.2" xref="S4.SS1.p2.5.m5.2.3.2.2.cmml">W</mi><mtext id="S4.SS1.p2.5.m5.2.3.2.3" xref="S4.SS1.p2.5.m5.2.3.2.3a.cmml">init</mtext></msub><mo lspace="0em" rspace="0em" id="S4.SS1.p2.5.m5.2.3.1" xref="S4.SS1.p2.5.m5.2.3.1.cmml">​</mo><msup id="S4.SS1.p2.5.m5.2.3.3" xref="S4.SS1.p2.5.m5.2.3.3.cmml"><mi id="S4.SS1.p2.5.m5.2.3.3.2" xref="S4.SS1.p2.5.m5.2.3.3.2.cmml">A</mi><mrow id="S4.SS1.p2.5.m5.2.2.2.2" xref="S4.SS1.p2.5.m5.2.2.2.3.cmml"><mo mathsize="142%" id="S4.SS1.p2.5.m5.2.2.2.2.1" xref="S4.SS1.p2.5.m5.2.2.2.2.1.cmml">′</mo><mo lspace="0em" id="S4.SS1.p2.5.m5.2.2.2.2.2" xref="S4.SS1.p2.5.m5.2.2.2.3.cmml">⁣</mo><mi id="S4.SS1.p2.5.m5.1.1.1.1" xref="S4.SS1.p2.5.m5.1.1.1.1.cmml">t</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.5.m5.2b"><apply id="S4.SS1.p2.5.m5.2.3.cmml" xref="S4.SS1.p2.5.m5.2.3"><times id="S4.SS1.p2.5.m5.2.3.1.cmml" xref="S4.SS1.p2.5.m5.2.3.1"></times><apply id="S4.SS1.p2.5.m5.2.3.2.cmml" xref="S4.SS1.p2.5.m5.2.3.2"><csymbol cd="ambiguous" id="S4.SS1.p2.5.m5.2.3.2.1.cmml" xref="S4.SS1.p2.5.m5.2.3.2">subscript</csymbol><ci id="S4.SS1.p2.5.m5.2.3.2.2.cmml" xref="S4.SS1.p2.5.m5.2.3.2.2">𝑊</ci><ci id="S4.SS1.p2.5.m5.2.3.2.3a.cmml" xref="S4.SS1.p2.5.m5.2.3.2.3"><mtext mathsize="70%" id="S4.SS1.p2.5.m5.2.3.2.3.cmml" xref="S4.SS1.p2.5.m5.2.3.2.3">init</mtext></ci></apply><apply id="S4.SS1.p2.5.m5.2.3.3.cmml" xref="S4.SS1.p2.5.m5.2.3.3"><csymbol cd="ambiguous" id="S4.SS1.p2.5.m5.2.3.3.1.cmml" xref="S4.SS1.p2.5.m5.2.3.3">superscript</csymbol><ci id="S4.SS1.p2.5.m5.2.3.3.2.cmml" xref="S4.SS1.p2.5.m5.2.3.3.2">𝐴</ci><list id="S4.SS1.p2.5.m5.2.2.2.3.cmml" xref="S4.SS1.p2.5.m5.2.2.2.2"><ci id="S4.SS1.p2.5.m5.2.2.2.2.1.cmml" xref="S4.SS1.p2.5.m5.2.2.2.2.1">′</ci><ci id="S4.SS1.p2.5.m5.1.1.1.1.cmml" xref="S4.SS1.p2.5.m5.1.1.1.1">𝑡</ci></list></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.5.m5.2c">W_{\text{init}}A^{\prime t}</annotation></semantics></math> along each row (i.e., expected variance of parameters of each node) is given as <math id="S4.SS1.p2.6.m6.1" class="ltx_Math" alttext="\sigma_{\text{init}}^{2}\left\|v_{\text{steady}}\right\|^{2}" display="inline"><semantics id="S4.SS1.p2.6.m6.1a"><mrow id="S4.SS1.p2.6.m6.1.1" xref="S4.SS1.p2.6.m6.1.1.cmml"><msubsup id="S4.SS1.p2.6.m6.1.1.3" xref="S4.SS1.p2.6.m6.1.1.3.cmml"><mi id="S4.SS1.p2.6.m6.1.1.3.2.2" xref="S4.SS1.p2.6.m6.1.1.3.2.2.cmml">σ</mi><mtext id="S4.SS1.p2.6.m6.1.1.3.2.3" xref="S4.SS1.p2.6.m6.1.1.3.2.3a.cmml">init</mtext><mn id="S4.SS1.p2.6.m6.1.1.3.3" xref="S4.SS1.p2.6.m6.1.1.3.3.cmml">2</mn></msubsup><mo lspace="0em" rspace="0em" id="S4.SS1.p2.6.m6.1.1.2" xref="S4.SS1.p2.6.m6.1.1.2.cmml">​</mo><msup id="S4.SS1.p2.6.m6.1.1.1" xref="S4.SS1.p2.6.m6.1.1.1.cmml"><mrow id="S4.SS1.p2.6.m6.1.1.1.1.1" xref="S4.SS1.p2.6.m6.1.1.1.1.2.cmml"><mo id="S4.SS1.p2.6.m6.1.1.1.1.1.2" xref="S4.SS1.p2.6.m6.1.1.1.1.2.1.cmml">‖</mo><msub id="S4.SS1.p2.6.m6.1.1.1.1.1.1" xref="S4.SS1.p2.6.m6.1.1.1.1.1.1.cmml"><mi id="S4.SS1.p2.6.m6.1.1.1.1.1.1.2" xref="S4.SS1.p2.6.m6.1.1.1.1.1.1.2.cmml">v</mi><mtext id="S4.SS1.p2.6.m6.1.1.1.1.1.1.3" xref="S4.SS1.p2.6.m6.1.1.1.1.1.1.3a.cmml">steady</mtext></msub><mo id="S4.SS1.p2.6.m6.1.1.1.1.1.3" xref="S4.SS1.p2.6.m6.1.1.1.1.2.1.cmml">‖</mo></mrow><mn id="S4.SS1.p2.6.m6.1.1.1.3" xref="S4.SS1.p2.6.m6.1.1.1.3.cmml">2</mn></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.6.m6.1b"><apply id="S4.SS1.p2.6.m6.1.1.cmml" xref="S4.SS1.p2.6.m6.1.1"><times id="S4.SS1.p2.6.m6.1.1.2.cmml" xref="S4.SS1.p2.6.m6.1.1.2"></times><apply id="S4.SS1.p2.6.m6.1.1.3.cmml" xref="S4.SS1.p2.6.m6.1.1.3"><csymbol cd="ambiguous" id="S4.SS1.p2.6.m6.1.1.3.1.cmml" xref="S4.SS1.p2.6.m6.1.1.3">superscript</csymbol><apply id="S4.SS1.p2.6.m6.1.1.3.2.cmml" xref="S4.SS1.p2.6.m6.1.1.3"><csymbol cd="ambiguous" id="S4.SS1.p2.6.m6.1.1.3.2.1.cmml" xref="S4.SS1.p2.6.m6.1.1.3">subscript</csymbol><ci id="S4.SS1.p2.6.m6.1.1.3.2.2.cmml" xref="S4.SS1.p2.6.m6.1.1.3.2.2">𝜎</ci><ci id="S4.SS1.p2.6.m6.1.1.3.2.3a.cmml" xref="S4.SS1.p2.6.m6.1.1.3.2.3"><mtext mathsize="70%" id="S4.SS1.p2.6.m6.1.1.3.2.3.cmml" xref="S4.SS1.p2.6.m6.1.1.3.2.3">init</mtext></ci></apply><cn type="integer" id="S4.SS1.p2.6.m6.1.1.3.3.cmml" xref="S4.SS1.p2.6.m6.1.1.3.3">2</cn></apply><apply id="S4.SS1.p2.6.m6.1.1.1.cmml" xref="S4.SS1.p2.6.m6.1.1.1"><csymbol cd="ambiguous" id="S4.SS1.p2.6.m6.1.1.1.2.cmml" xref="S4.SS1.p2.6.m6.1.1.1">superscript</csymbol><apply id="S4.SS1.p2.6.m6.1.1.1.1.2.cmml" xref="S4.SS1.p2.6.m6.1.1.1.1.1"><csymbol cd="latexml" id="S4.SS1.p2.6.m6.1.1.1.1.2.1.cmml" xref="S4.SS1.p2.6.m6.1.1.1.1.1.2">norm</csymbol><apply id="S4.SS1.p2.6.m6.1.1.1.1.1.1.cmml" xref="S4.SS1.p2.6.m6.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.SS1.p2.6.m6.1.1.1.1.1.1.1.cmml" xref="S4.SS1.p2.6.m6.1.1.1.1.1.1">subscript</csymbol><ci id="S4.SS1.p2.6.m6.1.1.1.1.1.1.2.cmml" xref="S4.SS1.p2.6.m6.1.1.1.1.1.1.2">𝑣</ci><ci id="S4.SS1.p2.6.m6.1.1.1.1.1.1.3a.cmml" xref="S4.SS1.p2.6.m6.1.1.1.1.1.1.3"><mtext mathsize="70%" id="S4.SS1.p2.6.m6.1.1.1.1.1.1.3.cmml" xref="S4.SS1.p2.6.m6.1.1.1.1.1.1.3">steady</mtext></ci></apply></apply><cn type="integer" id="S4.SS1.p2.6.m6.1.1.1.3.cmml" xref="S4.SS1.p2.6.m6.1.1.1.3">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.6.m6.1c">\sigma_{\text{init}}^{2}\left\|v_{\text{steady}}\right\|^{2}</annotation></semantics></math>. It can be trivially shown, from a direct application of the Cauchy–Schwarz inequality:</p>
<table id="S4.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.E2.m1.3" class="ltx_Math" alttext="|\langle\vec{1},v_{\text{steady}}\rangle|\leq\|\vec{1}\|\|v_{\text{steady}}\|\,," display="block"><semantics id="S4.E2.m1.3a"><mrow id="S4.E2.m1.3.3.1" xref="S4.E2.m1.3.3.1.1.cmml"><mrow id="S4.E2.m1.3.3.1.1" xref="S4.E2.m1.3.3.1.1.cmml"><mrow id="S4.E2.m1.3.3.1.1.1.1" xref="S4.E2.m1.3.3.1.1.1.2.cmml"><mo stretchy="false" id="S4.E2.m1.3.3.1.1.1.1.2" xref="S4.E2.m1.3.3.1.1.1.2.1.cmml">|</mo><mrow id="S4.E2.m1.3.3.1.1.1.1.1.1" xref="S4.E2.m1.3.3.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S4.E2.m1.3.3.1.1.1.1.1.1.2" xref="S4.E2.m1.3.3.1.1.1.1.1.2.cmml">⟨</mo><mover accent="true" id="S4.E2.m1.1.1" xref="S4.E2.m1.1.1.cmml"><mn id="S4.E2.m1.1.1.2" xref="S4.E2.m1.1.1.2.cmml">1</mn><mo stretchy="false" id="S4.E2.m1.1.1.1" xref="S4.E2.m1.1.1.1.cmml">→</mo></mover><mo id="S4.E2.m1.3.3.1.1.1.1.1.1.3" xref="S4.E2.m1.3.3.1.1.1.1.1.2.cmml">,</mo><msub id="S4.E2.m1.3.3.1.1.1.1.1.1.1" xref="S4.E2.m1.3.3.1.1.1.1.1.1.1.cmml"><mi id="S4.E2.m1.3.3.1.1.1.1.1.1.1.2" xref="S4.E2.m1.3.3.1.1.1.1.1.1.1.2.cmml">v</mi><mtext id="S4.E2.m1.3.3.1.1.1.1.1.1.1.3" xref="S4.E2.m1.3.3.1.1.1.1.1.1.1.3a.cmml">steady</mtext></msub><mo stretchy="false" id="S4.E2.m1.3.3.1.1.1.1.1.1.4" xref="S4.E2.m1.3.3.1.1.1.1.1.2.cmml">⟩</mo></mrow><mo stretchy="false" id="S4.E2.m1.3.3.1.1.1.1.3" xref="S4.E2.m1.3.3.1.1.1.2.1.cmml">|</mo></mrow><mo id="S4.E2.m1.3.3.1.1.3" xref="S4.E2.m1.3.3.1.1.3.cmml">≤</mo><mrow id="S4.E2.m1.3.3.1.1.2" xref="S4.E2.m1.3.3.1.1.2.cmml"><mrow id="S4.E2.m1.3.3.1.1.2.3.2" xref="S4.E2.m1.3.3.1.1.2.3.1.cmml"><mo stretchy="false" id="S4.E2.m1.3.3.1.1.2.3.2.1" xref="S4.E2.m1.3.3.1.1.2.3.1.1.cmml">‖</mo><mover accent="true" id="S4.E2.m1.2.2" xref="S4.E2.m1.2.2.cmml"><mn id="S4.E2.m1.2.2.2" xref="S4.E2.m1.2.2.2.cmml">1</mn><mo stretchy="false" id="S4.E2.m1.2.2.1" xref="S4.E2.m1.2.2.1.cmml">→</mo></mover><mo stretchy="false" id="S4.E2.m1.3.3.1.1.2.3.2.2" xref="S4.E2.m1.3.3.1.1.2.3.1.1.cmml">‖</mo></mrow><mo lspace="0em" rspace="0em" id="S4.E2.m1.3.3.1.1.2.2" xref="S4.E2.m1.3.3.1.1.2.2.cmml">​</mo><mrow id="S4.E2.m1.3.3.1.1.2.1.1" xref="S4.E2.m1.3.3.1.1.2.1.2.cmml"><mo stretchy="false" id="S4.E2.m1.3.3.1.1.2.1.1.2" xref="S4.E2.m1.3.3.1.1.2.1.2.1.cmml">‖</mo><msub id="S4.E2.m1.3.3.1.1.2.1.1.1" xref="S4.E2.m1.3.3.1.1.2.1.1.1.cmml"><mi id="S4.E2.m1.3.3.1.1.2.1.1.1.2" xref="S4.E2.m1.3.3.1.1.2.1.1.1.2.cmml">v</mi><mtext id="S4.E2.m1.3.3.1.1.2.1.1.1.3" xref="S4.E2.m1.3.3.1.1.2.1.1.1.3a.cmml">steady</mtext></msub><mo rspace="0.170em" stretchy="false" id="S4.E2.m1.3.3.1.1.2.1.1.3" xref="S4.E2.m1.3.3.1.1.2.1.2.1.cmml">‖</mo></mrow></mrow></mrow><mo id="S4.E2.m1.3.3.1.2" xref="S4.E2.m1.3.3.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.E2.m1.3b"><apply id="S4.E2.m1.3.3.1.1.cmml" xref="S4.E2.m1.3.3.1"><leq id="S4.E2.m1.3.3.1.1.3.cmml" xref="S4.E2.m1.3.3.1.1.3"></leq><apply id="S4.E2.m1.3.3.1.1.1.2.cmml" xref="S4.E2.m1.3.3.1.1.1.1"><abs id="S4.E2.m1.3.3.1.1.1.2.1.cmml" xref="S4.E2.m1.3.3.1.1.1.1.2"></abs><list id="S4.E2.m1.3.3.1.1.1.1.1.2.cmml" xref="S4.E2.m1.3.3.1.1.1.1.1.1"><apply id="S4.E2.m1.1.1.cmml" xref="S4.E2.m1.1.1"><ci id="S4.E2.m1.1.1.1.cmml" xref="S4.E2.m1.1.1.1">→</ci><cn type="integer" id="S4.E2.m1.1.1.2.cmml" xref="S4.E2.m1.1.1.2">1</cn></apply><apply id="S4.E2.m1.3.3.1.1.1.1.1.1.1.cmml" xref="S4.E2.m1.3.3.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.E2.m1.3.3.1.1.1.1.1.1.1.1.cmml" xref="S4.E2.m1.3.3.1.1.1.1.1.1.1">subscript</csymbol><ci id="S4.E2.m1.3.3.1.1.1.1.1.1.1.2.cmml" xref="S4.E2.m1.3.3.1.1.1.1.1.1.1.2">𝑣</ci><ci id="S4.E2.m1.3.3.1.1.1.1.1.1.1.3a.cmml" xref="S4.E2.m1.3.3.1.1.1.1.1.1.1.3"><mtext mathsize="70%" id="S4.E2.m1.3.3.1.1.1.1.1.1.1.3.cmml" xref="S4.E2.m1.3.3.1.1.1.1.1.1.1.3">steady</mtext></ci></apply></list></apply><apply id="S4.E2.m1.3.3.1.1.2.cmml" xref="S4.E2.m1.3.3.1.1.2"><times id="S4.E2.m1.3.3.1.1.2.2.cmml" xref="S4.E2.m1.3.3.1.1.2.2"></times><apply id="S4.E2.m1.3.3.1.1.2.3.1.cmml" xref="S4.E2.m1.3.3.1.1.2.3.2"><csymbol cd="latexml" id="S4.E2.m1.3.3.1.1.2.3.1.1.cmml" xref="S4.E2.m1.3.3.1.1.2.3.2.1">norm</csymbol><apply id="S4.E2.m1.2.2.cmml" xref="S4.E2.m1.2.2"><ci id="S4.E2.m1.2.2.1.cmml" xref="S4.E2.m1.2.2.1">→</ci><cn type="integer" id="S4.E2.m1.2.2.2.cmml" xref="S4.E2.m1.2.2.2">1</cn></apply></apply><apply id="S4.E2.m1.3.3.1.1.2.1.2.cmml" xref="S4.E2.m1.3.3.1.1.2.1.1"><csymbol cd="latexml" id="S4.E2.m1.3.3.1.1.2.1.2.1.cmml" xref="S4.E2.m1.3.3.1.1.2.1.1.2">norm</csymbol><apply id="S4.E2.m1.3.3.1.1.2.1.1.1.cmml" xref="S4.E2.m1.3.3.1.1.2.1.1.1"><csymbol cd="ambiguous" id="S4.E2.m1.3.3.1.1.2.1.1.1.1.cmml" xref="S4.E2.m1.3.3.1.1.2.1.1.1">subscript</csymbol><ci id="S4.E2.m1.3.3.1.1.2.1.1.1.2.cmml" xref="S4.E2.m1.3.3.1.1.2.1.1.1.2">𝑣</ci><ci id="S4.E2.m1.3.3.1.1.2.1.1.1.3a.cmml" xref="S4.E2.m1.3.3.1.1.2.1.1.1.3"><mtext mathsize="70%" id="S4.E2.m1.3.3.1.1.2.1.1.1.3.cmml" xref="S4.E2.m1.3.3.1.1.2.1.1.1.3">steady</mtext></ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E2.m1.3c">|\langle\vec{1},v_{\text{steady}}\rangle|\leq\|\vec{1}\|\|v_{\text{steady}}\|\,,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p id="S4.SS1.p2.10" class="ltx_p">that given that for connected networks <math id="S4.SS1.p2.7.m1.2" class="ltx_Math" alttext="\langle\vec{1},v_{\text{steady}}\rangle=\sum v_{\text{steady}}=1" display="inline"><semantics id="S4.SS1.p2.7.m1.2a"><mrow id="S4.SS1.p2.7.m1.2.2" xref="S4.SS1.p2.7.m1.2.2.cmml"><mrow id="S4.SS1.p2.7.m1.2.2.1.1" xref="S4.SS1.p2.7.m1.2.2.1.2.cmml"><mo stretchy="false" id="S4.SS1.p2.7.m1.2.2.1.1.2" xref="S4.SS1.p2.7.m1.2.2.1.2.cmml">⟨</mo><mover accent="true" id="S4.SS1.p2.7.m1.1.1" xref="S4.SS1.p2.7.m1.1.1.cmml"><mn id="S4.SS1.p2.7.m1.1.1.2" xref="S4.SS1.p2.7.m1.1.1.2.cmml">1</mn><mo stretchy="false" id="S4.SS1.p2.7.m1.1.1.1" xref="S4.SS1.p2.7.m1.1.1.1.cmml">→</mo></mover><mo id="S4.SS1.p2.7.m1.2.2.1.1.3" xref="S4.SS1.p2.7.m1.2.2.1.2.cmml">,</mo><msub id="S4.SS1.p2.7.m1.2.2.1.1.1" xref="S4.SS1.p2.7.m1.2.2.1.1.1.cmml"><mi id="S4.SS1.p2.7.m1.2.2.1.1.1.2" xref="S4.SS1.p2.7.m1.2.2.1.1.1.2.cmml">v</mi><mtext id="S4.SS1.p2.7.m1.2.2.1.1.1.3" xref="S4.SS1.p2.7.m1.2.2.1.1.1.3a.cmml">steady</mtext></msub><mo stretchy="false" id="S4.SS1.p2.7.m1.2.2.1.1.4" xref="S4.SS1.p2.7.m1.2.2.1.2.cmml">⟩</mo></mrow><mo rspace="0.111em" id="S4.SS1.p2.7.m1.2.2.3" xref="S4.SS1.p2.7.m1.2.2.3.cmml">=</mo><mrow id="S4.SS1.p2.7.m1.2.2.4" xref="S4.SS1.p2.7.m1.2.2.4.cmml"><mo id="S4.SS1.p2.7.m1.2.2.4.1" xref="S4.SS1.p2.7.m1.2.2.4.1.cmml">∑</mo><msub id="S4.SS1.p2.7.m1.2.2.4.2" xref="S4.SS1.p2.7.m1.2.2.4.2.cmml"><mi id="S4.SS1.p2.7.m1.2.2.4.2.2" xref="S4.SS1.p2.7.m1.2.2.4.2.2.cmml">v</mi><mtext id="S4.SS1.p2.7.m1.2.2.4.2.3" xref="S4.SS1.p2.7.m1.2.2.4.2.3a.cmml">steady</mtext></msub></mrow><mo id="S4.SS1.p2.7.m1.2.2.5" xref="S4.SS1.p2.7.m1.2.2.5.cmml">=</mo><mn id="S4.SS1.p2.7.m1.2.2.6" xref="S4.SS1.p2.7.m1.2.2.6.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.7.m1.2b"><apply id="S4.SS1.p2.7.m1.2.2.cmml" xref="S4.SS1.p2.7.m1.2.2"><and id="S4.SS1.p2.7.m1.2.2a.cmml" xref="S4.SS1.p2.7.m1.2.2"></and><apply id="S4.SS1.p2.7.m1.2.2b.cmml" xref="S4.SS1.p2.7.m1.2.2"><eq id="S4.SS1.p2.7.m1.2.2.3.cmml" xref="S4.SS1.p2.7.m1.2.2.3"></eq><list id="S4.SS1.p2.7.m1.2.2.1.2.cmml" xref="S4.SS1.p2.7.m1.2.2.1.1"><apply id="S4.SS1.p2.7.m1.1.1.cmml" xref="S4.SS1.p2.7.m1.1.1"><ci id="S4.SS1.p2.7.m1.1.1.1.cmml" xref="S4.SS1.p2.7.m1.1.1.1">→</ci><cn type="integer" id="S4.SS1.p2.7.m1.1.1.2.cmml" xref="S4.SS1.p2.7.m1.1.1.2">1</cn></apply><apply id="S4.SS1.p2.7.m1.2.2.1.1.1.cmml" xref="S4.SS1.p2.7.m1.2.2.1.1.1"><csymbol cd="ambiguous" id="S4.SS1.p2.7.m1.2.2.1.1.1.1.cmml" xref="S4.SS1.p2.7.m1.2.2.1.1.1">subscript</csymbol><ci id="S4.SS1.p2.7.m1.2.2.1.1.1.2.cmml" xref="S4.SS1.p2.7.m1.2.2.1.1.1.2">𝑣</ci><ci id="S4.SS1.p2.7.m1.2.2.1.1.1.3a.cmml" xref="S4.SS1.p2.7.m1.2.2.1.1.1.3"><mtext mathsize="70%" id="S4.SS1.p2.7.m1.2.2.1.1.1.3.cmml" xref="S4.SS1.p2.7.m1.2.2.1.1.1.3">steady</mtext></ci></apply></list><apply id="S4.SS1.p2.7.m1.2.2.4.cmml" xref="S4.SS1.p2.7.m1.2.2.4"><sum id="S4.SS1.p2.7.m1.2.2.4.1.cmml" xref="S4.SS1.p2.7.m1.2.2.4.1"></sum><apply id="S4.SS1.p2.7.m1.2.2.4.2.cmml" xref="S4.SS1.p2.7.m1.2.2.4.2"><csymbol cd="ambiguous" id="S4.SS1.p2.7.m1.2.2.4.2.1.cmml" xref="S4.SS1.p2.7.m1.2.2.4.2">subscript</csymbol><ci id="S4.SS1.p2.7.m1.2.2.4.2.2.cmml" xref="S4.SS1.p2.7.m1.2.2.4.2.2">𝑣</ci><ci id="S4.SS1.p2.7.m1.2.2.4.2.3a.cmml" xref="S4.SS1.p2.7.m1.2.2.4.2.3"><mtext mathsize="70%" id="S4.SS1.p2.7.m1.2.2.4.2.3.cmml" xref="S4.SS1.p2.7.m1.2.2.4.2.3">steady</mtext></ci></apply></apply></apply><apply id="S4.SS1.p2.7.m1.2.2c.cmml" xref="S4.SS1.p2.7.m1.2.2"><eq id="S4.SS1.p2.7.m1.2.2.5.cmml" xref="S4.SS1.p2.7.m1.2.2.5"></eq><share href="#S4.SS1.p2.7.m1.2.2.4.cmml" id="S4.SS1.p2.7.m1.2.2d.cmml" xref="S4.SS1.p2.7.m1.2.2"></share><cn type="integer" id="S4.SS1.p2.7.m1.2.2.6.cmml" xref="S4.SS1.p2.7.m1.2.2.6">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.7.m1.2c">\langle\vec{1},v_{\text{steady}}\rangle=\sum v_{\text{steady}}=1</annotation></semantics></math>, the <math id="S4.SS1.p2.8.m2.1" class="ltx_Math" alttext="\left\|v_{\text{steady}}\right\|^{2}" display="inline"><semantics id="S4.SS1.p2.8.m2.1a"><msup id="S4.SS1.p2.8.m2.1.1" xref="S4.SS1.p2.8.m2.1.1.cmml"><mrow id="S4.SS1.p2.8.m2.1.1.1.1" xref="S4.SS1.p2.8.m2.1.1.1.2.cmml"><mo id="S4.SS1.p2.8.m2.1.1.1.1.2" xref="S4.SS1.p2.8.m2.1.1.1.2.1.cmml">‖</mo><msub id="S4.SS1.p2.8.m2.1.1.1.1.1" xref="S4.SS1.p2.8.m2.1.1.1.1.1.cmml"><mi id="S4.SS1.p2.8.m2.1.1.1.1.1.2" xref="S4.SS1.p2.8.m2.1.1.1.1.1.2.cmml">v</mi><mtext id="S4.SS1.p2.8.m2.1.1.1.1.1.3" xref="S4.SS1.p2.8.m2.1.1.1.1.1.3a.cmml">steady</mtext></msub><mo id="S4.SS1.p2.8.m2.1.1.1.1.3" xref="S4.SS1.p2.8.m2.1.1.1.2.1.cmml">‖</mo></mrow><mn id="S4.SS1.p2.8.m2.1.1.3" xref="S4.SS1.p2.8.m2.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.8.m2.1b"><apply id="S4.SS1.p2.8.m2.1.1.cmml" xref="S4.SS1.p2.8.m2.1.1"><csymbol cd="ambiguous" id="S4.SS1.p2.8.m2.1.1.2.cmml" xref="S4.SS1.p2.8.m2.1.1">superscript</csymbol><apply id="S4.SS1.p2.8.m2.1.1.1.2.cmml" xref="S4.SS1.p2.8.m2.1.1.1.1"><csymbol cd="latexml" id="S4.SS1.p2.8.m2.1.1.1.2.1.cmml" xref="S4.SS1.p2.8.m2.1.1.1.1.2">norm</csymbol><apply id="S4.SS1.p2.8.m2.1.1.1.1.1.cmml" xref="S4.SS1.p2.8.m2.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.SS1.p2.8.m2.1.1.1.1.1.1.cmml" xref="S4.SS1.p2.8.m2.1.1.1.1.1">subscript</csymbol><ci id="S4.SS1.p2.8.m2.1.1.1.1.1.2.cmml" xref="S4.SS1.p2.8.m2.1.1.1.1.1.2">𝑣</ci><ci id="S4.SS1.p2.8.m2.1.1.1.1.1.3a.cmml" xref="S4.SS1.p2.8.m2.1.1.1.1.1.3"><mtext mathsize="70%" id="S4.SS1.p2.8.m2.1.1.1.1.1.3.cmml" xref="S4.SS1.p2.8.m2.1.1.1.1.1.3">steady</mtext></ci></apply></apply><cn type="integer" id="S4.SS1.p2.8.m2.1.1.3.cmml" xref="S4.SS1.p2.8.m2.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.8.m2.1c">\left\|v_{\text{steady}}\right\|^{2}</annotation></semantics></math> term has a minimum value of <math id="S4.SS1.p2.9.m3.1" class="ltx_Math" alttext="1/n" display="inline"><semantics id="S4.SS1.p2.9.m3.1a"><mrow id="S4.SS1.p2.9.m3.1.1" xref="S4.SS1.p2.9.m3.1.1.cmml"><mn id="S4.SS1.p2.9.m3.1.1.2" xref="S4.SS1.p2.9.m3.1.1.2.cmml">1</mn><mo id="S4.SS1.p2.9.m3.1.1.1" xref="S4.SS1.p2.9.m3.1.1.1.cmml">/</mo><mi id="S4.SS1.p2.9.m3.1.1.3" xref="S4.SS1.p2.9.m3.1.1.3.cmml">n</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.9.m3.1b"><apply id="S4.SS1.p2.9.m3.1.1.cmml" xref="S4.SS1.p2.9.m3.1.1"><divide id="S4.SS1.p2.9.m3.1.1.1.cmml" xref="S4.SS1.p2.9.m3.1.1.1"></divide><cn type="integer" id="S4.SS1.p2.9.m3.1.1.2.cmml" xref="S4.SS1.p2.9.m3.1.1.2">1</cn><ci id="S4.SS1.p2.9.m3.1.1.3.cmml" xref="S4.SS1.p2.9.m3.1.1.3">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.9.m3.1c">1/n</annotation></semantics></math>. This is achieved for random regular networks and other network models where nodes have uniformly distributed eigenvector centralities, such as Erdős–Rényi networks and lattices on <math id="S4.SS1.p2.10.m4.1" class="ltx_Math" alttext="d" display="inline"><semantics id="S4.SS1.p2.10.m4.1a"><mi id="S4.SS1.p2.10.m4.1.1" xref="S4.SS1.p2.10.m4.1.1.cmml">d</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.10.m4.1b"><ci id="S4.SS1.p2.10.m4.1.1.cmml" xref="S4.SS1.p2.10.m4.1.1">𝑑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.10.m4.1c">d</annotation></semantics></math>-dimensional tori.</p>
</div>
<div id="S4.SS1.p3" class="ltx_para">
<p id="S4.SS1.p3.4" class="ltx_p">Given that the noise values are drawn independently, the variance contribution of the noise term <math id="S4.SS1.p3.1.m1.2" class="ltx_Math" alttext="\sum_{i=0}^{t-1}N_{i}A^{\prime i}" display="inline"><semantics id="S4.SS1.p3.1.m1.2a"><mrow id="S4.SS1.p3.1.m1.2.3" xref="S4.SS1.p3.1.m1.2.3.cmml"><msubsup id="S4.SS1.p3.1.m1.2.3.1" xref="S4.SS1.p3.1.m1.2.3.1.cmml"><mo id="S4.SS1.p3.1.m1.2.3.1.2.2" xref="S4.SS1.p3.1.m1.2.3.1.2.2.cmml">∑</mo><mrow id="S4.SS1.p3.1.m1.2.3.1.2.3" xref="S4.SS1.p3.1.m1.2.3.1.2.3.cmml"><mi id="S4.SS1.p3.1.m1.2.3.1.2.3.2" xref="S4.SS1.p3.1.m1.2.3.1.2.3.2.cmml">i</mi><mo id="S4.SS1.p3.1.m1.2.3.1.2.3.1" xref="S4.SS1.p3.1.m1.2.3.1.2.3.1.cmml">=</mo><mn id="S4.SS1.p3.1.m1.2.3.1.2.3.3" xref="S4.SS1.p3.1.m1.2.3.1.2.3.3.cmml">0</mn></mrow><mrow id="S4.SS1.p3.1.m1.2.3.1.3" xref="S4.SS1.p3.1.m1.2.3.1.3.cmml"><mi id="S4.SS1.p3.1.m1.2.3.1.3.2" xref="S4.SS1.p3.1.m1.2.3.1.3.2.cmml">t</mi><mo id="S4.SS1.p3.1.m1.2.3.1.3.1" xref="S4.SS1.p3.1.m1.2.3.1.3.1.cmml">−</mo><mn id="S4.SS1.p3.1.m1.2.3.1.3.3" xref="S4.SS1.p3.1.m1.2.3.1.3.3.cmml">1</mn></mrow></msubsup><mrow id="S4.SS1.p3.1.m1.2.3.2" xref="S4.SS1.p3.1.m1.2.3.2.cmml"><msub id="S4.SS1.p3.1.m1.2.3.2.2" xref="S4.SS1.p3.1.m1.2.3.2.2.cmml"><mi id="S4.SS1.p3.1.m1.2.3.2.2.2" xref="S4.SS1.p3.1.m1.2.3.2.2.2.cmml">N</mi><mi id="S4.SS1.p3.1.m1.2.3.2.2.3" xref="S4.SS1.p3.1.m1.2.3.2.2.3.cmml">i</mi></msub><mo lspace="0em" rspace="0em" id="S4.SS1.p3.1.m1.2.3.2.1" xref="S4.SS1.p3.1.m1.2.3.2.1.cmml">​</mo><msup id="S4.SS1.p3.1.m1.2.3.2.3" xref="S4.SS1.p3.1.m1.2.3.2.3.cmml"><mi id="S4.SS1.p3.1.m1.2.3.2.3.2" xref="S4.SS1.p3.1.m1.2.3.2.3.2.cmml">A</mi><mrow id="S4.SS1.p3.1.m1.2.2.2.2" xref="S4.SS1.p3.1.m1.2.2.2.3.cmml"><mo mathsize="142%" id="S4.SS1.p3.1.m1.2.2.2.2.1" xref="S4.SS1.p3.1.m1.2.2.2.2.1.cmml">′</mo><mo lspace="0em" id="S4.SS1.p3.1.m1.2.2.2.2.2" xref="S4.SS1.p3.1.m1.2.2.2.3.cmml">⁣</mo><mi id="S4.SS1.p3.1.m1.1.1.1.1" xref="S4.SS1.p3.1.m1.1.1.1.1.cmml">i</mi></mrow></msup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.1.m1.2b"><apply id="S4.SS1.p3.1.m1.2.3.cmml" xref="S4.SS1.p3.1.m1.2.3"><apply id="S4.SS1.p3.1.m1.2.3.1.cmml" xref="S4.SS1.p3.1.m1.2.3.1"><csymbol cd="ambiguous" id="S4.SS1.p3.1.m1.2.3.1.1.cmml" xref="S4.SS1.p3.1.m1.2.3.1">superscript</csymbol><apply id="S4.SS1.p3.1.m1.2.3.1.2.cmml" xref="S4.SS1.p3.1.m1.2.3.1"><csymbol cd="ambiguous" id="S4.SS1.p3.1.m1.2.3.1.2.1.cmml" xref="S4.SS1.p3.1.m1.2.3.1">subscript</csymbol><sum id="S4.SS1.p3.1.m1.2.3.1.2.2.cmml" xref="S4.SS1.p3.1.m1.2.3.1.2.2"></sum><apply id="S4.SS1.p3.1.m1.2.3.1.2.3.cmml" xref="S4.SS1.p3.1.m1.2.3.1.2.3"><eq id="S4.SS1.p3.1.m1.2.3.1.2.3.1.cmml" xref="S4.SS1.p3.1.m1.2.3.1.2.3.1"></eq><ci id="S4.SS1.p3.1.m1.2.3.1.2.3.2.cmml" xref="S4.SS1.p3.1.m1.2.3.1.2.3.2">𝑖</ci><cn type="integer" id="S4.SS1.p3.1.m1.2.3.1.2.3.3.cmml" xref="S4.SS1.p3.1.m1.2.3.1.2.3.3">0</cn></apply></apply><apply id="S4.SS1.p3.1.m1.2.3.1.3.cmml" xref="S4.SS1.p3.1.m1.2.3.1.3"><minus id="S4.SS1.p3.1.m1.2.3.1.3.1.cmml" xref="S4.SS1.p3.1.m1.2.3.1.3.1"></minus><ci id="S4.SS1.p3.1.m1.2.3.1.3.2.cmml" xref="S4.SS1.p3.1.m1.2.3.1.3.2">𝑡</ci><cn type="integer" id="S4.SS1.p3.1.m1.2.3.1.3.3.cmml" xref="S4.SS1.p3.1.m1.2.3.1.3.3">1</cn></apply></apply><apply id="S4.SS1.p3.1.m1.2.3.2.cmml" xref="S4.SS1.p3.1.m1.2.3.2"><times id="S4.SS1.p3.1.m1.2.3.2.1.cmml" xref="S4.SS1.p3.1.m1.2.3.2.1"></times><apply id="S4.SS1.p3.1.m1.2.3.2.2.cmml" xref="S4.SS1.p3.1.m1.2.3.2.2"><csymbol cd="ambiguous" id="S4.SS1.p3.1.m1.2.3.2.2.1.cmml" xref="S4.SS1.p3.1.m1.2.3.2.2">subscript</csymbol><ci id="S4.SS1.p3.1.m1.2.3.2.2.2.cmml" xref="S4.SS1.p3.1.m1.2.3.2.2.2">𝑁</ci><ci id="S4.SS1.p3.1.m1.2.3.2.2.3.cmml" xref="S4.SS1.p3.1.m1.2.3.2.2.3">𝑖</ci></apply><apply id="S4.SS1.p3.1.m1.2.3.2.3.cmml" xref="S4.SS1.p3.1.m1.2.3.2.3"><csymbol cd="ambiguous" id="S4.SS1.p3.1.m1.2.3.2.3.1.cmml" xref="S4.SS1.p3.1.m1.2.3.2.3">superscript</csymbol><ci id="S4.SS1.p3.1.m1.2.3.2.3.2.cmml" xref="S4.SS1.p3.1.m1.2.3.2.3.2">𝐴</ci><list id="S4.SS1.p3.1.m1.2.2.2.3.cmml" xref="S4.SS1.p3.1.m1.2.2.2.2"><ci id="S4.SS1.p3.1.m1.2.2.2.2.1.cmml" xref="S4.SS1.p3.1.m1.2.2.2.2.1">′</ci><ci id="S4.SS1.p3.1.m1.1.1.1.1.cmml" xref="S4.SS1.p3.1.m1.1.1.1.1">𝑖</ci></list></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.1.m1.2c">\sum_{i=0}^{t-1}N_{i}A^{\prime i}</annotation></semantics></math> has an upper-bound of <math id="S4.SS1.p3.2.m2.1" class="ltx_Math" alttext="t\sigma^{2}_{\text{noise}}" display="inline"><semantics id="S4.SS1.p3.2.m2.1a"><mrow id="S4.SS1.p3.2.m2.1.1" xref="S4.SS1.p3.2.m2.1.1.cmml"><mi id="S4.SS1.p3.2.m2.1.1.2" xref="S4.SS1.p3.2.m2.1.1.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="S4.SS1.p3.2.m2.1.1.1" xref="S4.SS1.p3.2.m2.1.1.1.cmml">​</mo><msubsup id="S4.SS1.p3.2.m2.1.1.3" xref="S4.SS1.p3.2.m2.1.1.3.cmml"><mi id="S4.SS1.p3.2.m2.1.1.3.2.2" xref="S4.SS1.p3.2.m2.1.1.3.2.2.cmml">σ</mi><mtext id="S4.SS1.p3.2.m2.1.1.3.3" xref="S4.SS1.p3.2.m2.1.1.3.3a.cmml">noise</mtext><mn id="S4.SS1.p3.2.m2.1.1.3.2.3" xref="S4.SS1.p3.2.m2.1.1.3.2.3.cmml">2</mn></msubsup></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.2.m2.1b"><apply id="S4.SS1.p3.2.m2.1.1.cmml" xref="S4.SS1.p3.2.m2.1.1"><times id="S4.SS1.p3.2.m2.1.1.1.cmml" xref="S4.SS1.p3.2.m2.1.1.1"></times><ci id="S4.SS1.p3.2.m2.1.1.2.cmml" xref="S4.SS1.p3.2.m2.1.1.2">𝑡</ci><apply id="S4.SS1.p3.2.m2.1.1.3.cmml" xref="S4.SS1.p3.2.m2.1.1.3"><csymbol cd="ambiguous" id="S4.SS1.p3.2.m2.1.1.3.1.cmml" xref="S4.SS1.p3.2.m2.1.1.3">subscript</csymbol><apply id="S4.SS1.p3.2.m2.1.1.3.2.cmml" xref="S4.SS1.p3.2.m2.1.1.3"><csymbol cd="ambiguous" id="S4.SS1.p3.2.m2.1.1.3.2.1.cmml" xref="S4.SS1.p3.2.m2.1.1.3">superscript</csymbol><ci id="S4.SS1.p3.2.m2.1.1.3.2.2.cmml" xref="S4.SS1.p3.2.m2.1.1.3.2.2">𝜎</ci><cn type="integer" id="S4.SS1.p3.2.m2.1.1.3.2.3.cmml" xref="S4.SS1.p3.2.m2.1.1.3.2.3">2</cn></apply><ci id="S4.SS1.p3.2.m2.1.1.3.3a.cmml" xref="S4.SS1.p3.2.m2.1.1.3.3"><mtext mathsize="70%" id="S4.SS1.p3.2.m2.1.1.3.3.cmml" xref="S4.SS1.p3.2.m2.1.1.3.3">noise</mtext></ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.2.m2.1c">t\sigma^{2}_{\text{noise}}</annotation></semantics></math>. If <math id="S4.SS1.p3.3.m3.1" class="ltx_Math" alttext="t\sigma^{2}_{\text{noise}}\ll\sigma^{2}_{\text{init}}/n" display="inline"><semantics id="S4.SS1.p3.3.m3.1a"><mrow id="S4.SS1.p3.3.m3.1.1" xref="S4.SS1.p3.3.m3.1.1.cmml"><mrow id="S4.SS1.p3.3.m3.1.1.2" xref="S4.SS1.p3.3.m3.1.1.2.cmml"><mi id="S4.SS1.p3.3.m3.1.1.2.2" xref="S4.SS1.p3.3.m3.1.1.2.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="S4.SS1.p3.3.m3.1.1.2.1" xref="S4.SS1.p3.3.m3.1.1.2.1.cmml">​</mo><msubsup id="S4.SS1.p3.3.m3.1.1.2.3" xref="S4.SS1.p3.3.m3.1.1.2.3.cmml"><mi id="S4.SS1.p3.3.m3.1.1.2.3.2.2" xref="S4.SS1.p3.3.m3.1.1.2.3.2.2.cmml">σ</mi><mtext id="S4.SS1.p3.3.m3.1.1.2.3.3" xref="S4.SS1.p3.3.m3.1.1.2.3.3a.cmml">noise</mtext><mn id="S4.SS1.p3.3.m3.1.1.2.3.2.3" xref="S4.SS1.p3.3.m3.1.1.2.3.2.3.cmml">2</mn></msubsup></mrow><mo id="S4.SS1.p3.3.m3.1.1.1" xref="S4.SS1.p3.3.m3.1.1.1.cmml">≪</mo><mrow id="S4.SS1.p3.3.m3.1.1.3" xref="S4.SS1.p3.3.m3.1.1.3.cmml"><msubsup id="S4.SS1.p3.3.m3.1.1.3.2" xref="S4.SS1.p3.3.m3.1.1.3.2.cmml"><mi id="S4.SS1.p3.3.m3.1.1.3.2.2.2" xref="S4.SS1.p3.3.m3.1.1.3.2.2.2.cmml">σ</mi><mtext id="S4.SS1.p3.3.m3.1.1.3.2.3" xref="S4.SS1.p3.3.m3.1.1.3.2.3a.cmml">init</mtext><mn id="S4.SS1.p3.3.m3.1.1.3.2.2.3" xref="S4.SS1.p3.3.m3.1.1.3.2.2.3.cmml">2</mn></msubsup><mo id="S4.SS1.p3.3.m3.1.1.3.1" xref="S4.SS1.p3.3.m3.1.1.3.1.cmml">/</mo><mi id="S4.SS1.p3.3.m3.1.1.3.3" xref="S4.SS1.p3.3.m3.1.1.3.3.cmml">n</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.3.m3.1b"><apply id="S4.SS1.p3.3.m3.1.1.cmml" xref="S4.SS1.p3.3.m3.1.1"><csymbol cd="latexml" id="S4.SS1.p3.3.m3.1.1.1.cmml" xref="S4.SS1.p3.3.m3.1.1.1">much-less-than</csymbol><apply id="S4.SS1.p3.3.m3.1.1.2.cmml" xref="S4.SS1.p3.3.m3.1.1.2"><times id="S4.SS1.p3.3.m3.1.1.2.1.cmml" xref="S4.SS1.p3.3.m3.1.1.2.1"></times><ci id="S4.SS1.p3.3.m3.1.1.2.2.cmml" xref="S4.SS1.p3.3.m3.1.1.2.2">𝑡</ci><apply id="S4.SS1.p3.3.m3.1.1.2.3.cmml" xref="S4.SS1.p3.3.m3.1.1.2.3"><csymbol cd="ambiguous" id="S4.SS1.p3.3.m3.1.1.2.3.1.cmml" xref="S4.SS1.p3.3.m3.1.1.2.3">subscript</csymbol><apply id="S4.SS1.p3.3.m3.1.1.2.3.2.cmml" xref="S4.SS1.p3.3.m3.1.1.2.3"><csymbol cd="ambiguous" id="S4.SS1.p3.3.m3.1.1.2.3.2.1.cmml" xref="S4.SS1.p3.3.m3.1.1.2.3">superscript</csymbol><ci id="S4.SS1.p3.3.m3.1.1.2.3.2.2.cmml" xref="S4.SS1.p3.3.m3.1.1.2.3.2.2">𝜎</ci><cn type="integer" id="S4.SS1.p3.3.m3.1.1.2.3.2.3.cmml" xref="S4.SS1.p3.3.m3.1.1.2.3.2.3">2</cn></apply><ci id="S4.SS1.p3.3.m3.1.1.2.3.3a.cmml" xref="S4.SS1.p3.3.m3.1.1.2.3.3"><mtext mathsize="70%" id="S4.SS1.p3.3.m3.1.1.2.3.3.cmml" xref="S4.SS1.p3.3.m3.1.1.2.3.3">noise</mtext></ci></apply></apply><apply id="S4.SS1.p3.3.m3.1.1.3.cmml" xref="S4.SS1.p3.3.m3.1.1.3"><divide id="S4.SS1.p3.3.m3.1.1.3.1.cmml" xref="S4.SS1.p3.3.m3.1.1.3.1"></divide><apply id="S4.SS1.p3.3.m3.1.1.3.2.cmml" xref="S4.SS1.p3.3.m3.1.1.3.2"><csymbol cd="ambiguous" id="S4.SS1.p3.3.m3.1.1.3.2.1.cmml" xref="S4.SS1.p3.3.m3.1.1.3.2">subscript</csymbol><apply id="S4.SS1.p3.3.m3.1.1.3.2.2.cmml" xref="S4.SS1.p3.3.m3.1.1.3.2"><csymbol cd="ambiguous" id="S4.SS1.p3.3.m3.1.1.3.2.2.1.cmml" xref="S4.SS1.p3.3.m3.1.1.3.2">superscript</csymbol><ci id="S4.SS1.p3.3.m3.1.1.3.2.2.2.cmml" xref="S4.SS1.p3.3.m3.1.1.3.2.2.2">𝜎</ci><cn type="integer" id="S4.SS1.p3.3.m3.1.1.3.2.2.3.cmml" xref="S4.SS1.p3.3.m3.1.1.3.2.2.3">2</cn></apply><ci id="S4.SS1.p3.3.m3.1.1.3.2.3a.cmml" xref="S4.SS1.p3.3.m3.1.1.3.2.3"><mtext mathsize="70%" id="S4.SS1.p3.3.m3.1.1.3.2.3.cmml" xref="S4.SS1.p3.3.m3.1.1.3.2.3">init</mtext></ci></apply><ci id="S4.SS1.p3.3.m3.1.1.3.3.cmml" xref="S4.SS1.p3.3.m3.1.1.3.3">𝑛</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.3.m3.1c">t\sigma^{2}_{\text{noise}}\ll\sigma^{2}_{\text{init}}/n</annotation></semantics></math>, then the standard deviation across parameters at round <math id="S4.SS1.p3.4.m4.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S4.SS1.p3.4.m4.1a"><mi id="S4.SS1.p3.4.m4.1.1" xref="S4.SS1.p3.4.m4.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.4.m4.1b"><ci id="S4.SS1.p3.4.m4.1.1.cmml" xref="S4.SS1.p3.4.m4.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.4.m4.1c">t</annotation></semantics></math> can be approximated by</p>
<table id="S4.E3" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.E3.m1.1" class="ltx_Math" alttext="\lim_{t\rightarrow\infty}\sigma_{ap}\approx\sigma_{\text{init}}\left\|v_{\text{steady}}\right\|\,." display="block"><semantics id="S4.E3.m1.1a"><mrow id="S4.E3.m1.1.1.1" xref="S4.E3.m1.1.1.1.1.cmml"><mrow id="S4.E3.m1.1.1.1.1" xref="S4.E3.m1.1.1.1.1.cmml"><mrow id="S4.E3.m1.1.1.1.1.3" xref="S4.E3.m1.1.1.1.1.3.cmml"><munder id="S4.E3.m1.1.1.1.1.3.1" xref="S4.E3.m1.1.1.1.1.3.1.cmml"><mo movablelimits="false" id="S4.E3.m1.1.1.1.1.3.1.2" xref="S4.E3.m1.1.1.1.1.3.1.2.cmml">lim</mo><mrow id="S4.E3.m1.1.1.1.1.3.1.3" xref="S4.E3.m1.1.1.1.1.3.1.3.cmml"><mi id="S4.E3.m1.1.1.1.1.3.1.3.2" xref="S4.E3.m1.1.1.1.1.3.1.3.2.cmml">t</mi><mo stretchy="false" id="S4.E3.m1.1.1.1.1.3.1.3.1" xref="S4.E3.m1.1.1.1.1.3.1.3.1.cmml">→</mo><mi mathvariant="normal" id="S4.E3.m1.1.1.1.1.3.1.3.3" xref="S4.E3.m1.1.1.1.1.3.1.3.3.cmml">∞</mi></mrow></munder><msub id="S4.E3.m1.1.1.1.1.3.2" xref="S4.E3.m1.1.1.1.1.3.2.cmml"><mi id="S4.E3.m1.1.1.1.1.3.2.2" xref="S4.E3.m1.1.1.1.1.3.2.2.cmml">σ</mi><mrow id="S4.E3.m1.1.1.1.1.3.2.3" xref="S4.E3.m1.1.1.1.1.3.2.3.cmml"><mi id="S4.E3.m1.1.1.1.1.3.2.3.2" xref="S4.E3.m1.1.1.1.1.3.2.3.2.cmml">a</mi><mo lspace="0em" rspace="0em" id="S4.E3.m1.1.1.1.1.3.2.3.1" xref="S4.E3.m1.1.1.1.1.3.2.3.1.cmml">​</mo><mi id="S4.E3.m1.1.1.1.1.3.2.3.3" xref="S4.E3.m1.1.1.1.1.3.2.3.3.cmml">p</mi></mrow></msub></mrow><mo id="S4.E3.m1.1.1.1.1.2" xref="S4.E3.m1.1.1.1.1.2.cmml">≈</mo><mrow id="S4.E3.m1.1.1.1.1.1" xref="S4.E3.m1.1.1.1.1.1.cmml"><msub id="S4.E3.m1.1.1.1.1.1.3" xref="S4.E3.m1.1.1.1.1.1.3.cmml"><mi id="S4.E3.m1.1.1.1.1.1.3.2" xref="S4.E3.m1.1.1.1.1.1.3.2.cmml">σ</mi><mtext id="S4.E3.m1.1.1.1.1.1.3.3" xref="S4.E3.m1.1.1.1.1.1.3.3a.cmml">init</mtext></msub><mo lspace="0em" rspace="0em" id="S4.E3.m1.1.1.1.1.1.2" xref="S4.E3.m1.1.1.1.1.1.2.cmml">​</mo><mrow id="S4.E3.m1.1.1.1.1.1.1.1" xref="S4.E3.m1.1.1.1.1.1.1.2.cmml"><mo id="S4.E3.m1.1.1.1.1.1.1.1.2" xref="S4.E3.m1.1.1.1.1.1.1.2.1.cmml">‖</mo><msub id="S4.E3.m1.1.1.1.1.1.1.1.1" xref="S4.E3.m1.1.1.1.1.1.1.1.1.cmml"><mi id="S4.E3.m1.1.1.1.1.1.1.1.1.2" xref="S4.E3.m1.1.1.1.1.1.1.1.1.2.cmml">v</mi><mtext id="S4.E3.m1.1.1.1.1.1.1.1.1.3" xref="S4.E3.m1.1.1.1.1.1.1.1.1.3a.cmml">steady</mtext></msub><mo id="S4.E3.m1.1.1.1.1.1.1.1.3" xref="S4.E3.m1.1.1.1.1.1.1.2.1.cmml">‖</mo></mrow></mrow></mrow><mo lspace="0.170em" id="S4.E3.m1.1.1.1.2" xref="S4.E3.m1.1.1.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.E3.m1.1b"><apply id="S4.E3.m1.1.1.1.1.cmml" xref="S4.E3.m1.1.1.1"><approx id="S4.E3.m1.1.1.1.1.2.cmml" xref="S4.E3.m1.1.1.1.1.2"></approx><apply id="S4.E3.m1.1.1.1.1.3.cmml" xref="S4.E3.m1.1.1.1.1.3"><apply id="S4.E3.m1.1.1.1.1.3.1.cmml" xref="S4.E3.m1.1.1.1.1.3.1"><csymbol cd="ambiguous" id="S4.E3.m1.1.1.1.1.3.1.1.cmml" xref="S4.E3.m1.1.1.1.1.3.1">subscript</csymbol><limit id="S4.E3.m1.1.1.1.1.3.1.2.cmml" xref="S4.E3.m1.1.1.1.1.3.1.2"></limit><apply id="S4.E3.m1.1.1.1.1.3.1.3.cmml" xref="S4.E3.m1.1.1.1.1.3.1.3"><ci id="S4.E3.m1.1.1.1.1.3.1.3.1.cmml" xref="S4.E3.m1.1.1.1.1.3.1.3.1">→</ci><ci id="S4.E3.m1.1.1.1.1.3.1.3.2.cmml" xref="S4.E3.m1.1.1.1.1.3.1.3.2">𝑡</ci><infinity id="S4.E3.m1.1.1.1.1.3.1.3.3.cmml" xref="S4.E3.m1.1.1.1.1.3.1.3.3"></infinity></apply></apply><apply id="S4.E3.m1.1.1.1.1.3.2.cmml" xref="S4.E3.m1.1.1.1.1.3.2"><csymbol cd="ambiguous" id="S4.E3.m1.1.1.1.1.3.2.1.cmml" xref="S4.E3.m1.1.1.1.1.3.2">subscript</csymbol><ci id="S4.E3.m1.1.1.1.1.3.2.2.cmml" xref="S4.E3.m1.1.1.1.1.3.2.2">𝜎</ci><apply id="S4.E3.m1.1.1.1.1.3.2.3.cmml" xref="S4.E3.m1.1.1.1.1.3.2.3"><times id="S4.E3.m1.1.1.1.1.3.2.3.1.cmml" xref="S4.E3.m1.1.1.1.1.3.2.3.1"></times><ci id="S4.E3.m1.1.1.1.1.3.2.3.2.cmml" xref="S4.E3.m1.1.1.1.1.3.2.3.2">𝑎</ci><ci id="S4.E3.m1.1.1.1.1.3.2.3.3.cmml" xref="S4.E3.m1.1.1.1.1.3.2.3.3">𝑝</ci></apply></apply></apply><apply id="S4.E3.m1.1.1.1.1.1.cmml" xref="S4.E3.m1.1.1.1.1.1"><times id="S4.E3.m1.1.1.1.1.1.2.cmml" xref="S4.E3.m1.1.1.1.1.1.2"></times><apply id="S4.E3.m1.1.1.1.1.1.3.cmml" xref="S4.E3.m1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S4.E3.m1.1.1.1.1.1.3.1.cmml" xref="S4.E3.m1.1.1.1.1.1.3">subscript</csymbol><ci id="S4.E3.m1.1.1.1.1.1.3.2.cmml" xref="S4.E3.m1.1.1.1.1.1.3.2">𝜎</ci><ci id="S4.E3.m1.1.1.1.1.1.3.3a.cmml" xref="S4.E3.m1.1.1.1.1.1.3.3"><mtext mathsize="70%" id="S4.E3.m1.1.1.1.1.1.3.3.cmml" xref="S4.E3.m1.1.1.1.1.1.3.3">init</mtext></ci></apply><apply id="S4.E3.m1.1.1.1.1.1.1.2.cmml" xref="S4.E3.m1.1.1.1.1.1.1.1"><csymbol cd="latexml" id="S4.E3.m1.1.1.1.1.1.1.2.1.cmml" xref="S4.E3.m1.1.1.1.1.1.1.1.2">norm</csymbol><apply id="S4.E3.m1.1.1.1.1.1.1.1.1.cmml" xref="S4.E3.m1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.E3.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S4.E3.m1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S4.E3.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S4.E3.m1.1.1.1.1.1.1.1.1.2">𝑣</ci><ci id="S4.E3.m1.1.1.1.1.1.1.1.1.3a.cmml" xref="S4.E3.m1.1.1.1.1.1.1.1.1.3"><mtext mathsize="70%" id="S4.E3.m1.1.1.1.1.1.1.1.1.3.cmml" xref="S4.E3.m1.1.1.1.1.1.1.1.1.3">steady</mtext></ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E3.m1.1c">\lim_{t\rightarrow\infty}\sigma_{ap}\approx\sigma_{\text{init}}\left\|v_{\text{steady}}\right\|\,.</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<p id="S4.SS1.p3.7" class="ltx_p">For a large connected random <math id="S4.SS1.p3.5.m1.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S4.SS1.p3.5.m1.1a"><mi id="S4.SS1.p3.5.m1.1.1" xref="S4.SS1.p3.5.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.5.m1.1b"><ci id="S4.SS1.p3.5.m1.1.1.cmml" xref="S4.SS1.p3.5.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.5.m1.1c">k</annotation></semantics></math>-regular network, this reduces to <math id="S4.SS1.p3.6.m2.1" class="ltx_Math" alttext="\lim_{t\rightarrow\infty}\sigma_{ap}=\sigma_{\text{init}}/\sqrt{n}" display="inline"><semantics id="S4.SS1.p3.6.m2.1a"><mrow id="S4.SS1.p3.6.m2.1.1" xref="S4.SS1.p3.6.m2.1.1.cmml"><mrow id="S4.SS1.p3.6.m2.1.1.2" xref="S4.SS1.p3.6.m2.1.1.2.cmml"><msub id="S4.SS1.p3.6.m2.1.1.2.1" xref="S4.SS1.p3.6.m2.1.1.2.1.cmml"><mo id="S4.SS1.p3.6.m2.1.1.2.1.2" xref="S4.SS1.p3.6.m2.1.1.2.1.2.cmml">lim</mo><mrow id="S4.SS1.p3.6.m2.1.1.2.1.3" xref="S4.SS1.p3.6.m2.1.1.2.1.3.cmml"><mi id="S4.SS1.p3.6.m2.1.1.2.1.3.2" xref="S4.SS1.p3.6.m2.1.1.2.1.3.2.cmml">t</mi><mo stretchy="false" id="S4.SS1.p3.6.m2.1.1.2.1.3.1" xref="S4.SS1.p3.6.m2.1.1.2.1.3.1.cmml">→</mo><mi mathvariant="normal" id="S4.SS1.p3.6.m2.1.1.2.1.3.3" xref="S4.SS1.p3.6.m2.1.1.2.1.3.3.cmml">∞</mi></mrow></msub><msub id="S4.SS1.p3.6.m2.1.1.2.2" xref="S4.SS1.p3.6.m2.1.1.2.2.cmml"><mi id="S4.SS1.p3.6.m2.1.1.2.2.2" xref="S4.SS1.p3.6.m2.1.1.2.2.2.cmml">σ</mi><mrow id="S4.SS1.p3.6.m2.1.1.2.2.3" xref="S4.SS1.p3.6.m2.1.1.2.2.3.cmml"><mi id="S4.SS1.p3.6.m2.1.1.2.2.3.2" xref="S4.SS1.p3.6.m2.1.1.2.2.3.2.cmml">a</mi><mo lspace="0em" rspace="0em" id="S4.SS1.p3.6.m2.1.1.2.2.3.1" xref="S4.SS1.p3.6.m2.1.1.2.2.3.1.cmml">​</mo><mi id="S4.SS1.p3.6.m2.1.1.2.2.3.3" xref="S4.SS1.p3.6.m2.1.1.2.2.3.3.cmml">p</mi></mrow></msub></mrow><mo id="S4.SS1.p3.6.m2.1.1.1" xref="S4.SS1.p3.6.m2.1.1.1.cmml">=</mo><mrow id="S4.SS1.p3.6.m2.1.1.3" xref="S4.SS1.p3.6.m2.1.1.3.cmml"><msub id="S4.SS1.p3.6.m2.1.1.3.2" xref="S4.SS1.p3.6.m2.1.1.3.2.cmml"><mi id="S4.SS1.p3.6.m2.1.1.3.2.2" xref="S4.SS1.p3.6.m2.1.1.3.2.2.cmml">σ</mi><mtext id="S4.SS1.p3.6.m2.1.1.3.2.3" xref="S4.SS1.p3.6.m2.1.1.3.2.3a.cmml">init</mtext></msub><mo id="S4.SS1.p3.6.m2.1.1.3.1" xref="S4.SS1.p3.6.m2.1.1.3.1.cmml">/</mo><msqrt id="S4.SS1.p3.6.m2.1.1.3.3" xref="S4.SS1.p3.6.m2.1.1.3.3.cmml"><mi id="S4.SS1.p3.6.m2.1.1.3.3.2" xref="S4.SS1.p3.6.m2.1.1.3.3.2.cmml">n</mi></msqrt></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.6.m2.1b"><apply id="S4.SS1.p3.6.m2.1.1.cmml" xref="S4.SS1.p3.6.m2.1.1"><eq id="S4.SS1.p3.6.m2.1.1.1.cmml" xref="S4.SS1.p3.6.m2.1.1.1"></eq><apply id="S4.SS1.p3.6.m2.1.1.2.cmml" xref="S4.SS1.p3.6.m2.1.1.2"><apply id="S4.SS1.p3.6.m2.1.1.2.1.cmml" xref="S4.SS1.p3.6.m2.1.1.2.1"><csymbol cd="ambiguous" id="S4.SS1.p3.6.m2.1.1.2.1.1.cmml" xref="S4.SS1.p3.6.m2.1.1.2.1">subscript</csymbol><limit id="S4.SS1.p3.6.m2.1.1.2.1.2.cmml" xref="S4.SS1.p3.6.m2.1.1.2.1.2"></limit><apply id="S4.SS1.p3.6.m2.1.1.2.1.3.cmml" xref="S4.SS1.p3.6.m2.1.1.2.1.3"><ci id="S4.SS1.p3.6.m2.1.1.2.1.3.1.cmml" xref="S4.SS1.p3.6.m2.1.1.2.1.3.1">→</ci><ci id="S4.SS1.p3.6.m2.1.1.2.1.3.2.cmml" xref="S4.SS1.p3.6.m2.1.1.2.1.3.2">𝑡</ci><infinity id="S4.SS1.p3.6.m2.1.1.2.1.3.3.cmml" xref="S4.SS1.p3.6.m2.1.1.2.1.3.3"></infinity></apply></apply><apply id="S4.SS1.p3.6.m2.1.1.2.2.cmml" xref="S4.SS1.p3.6.m2.1.1.2.2"><csymbol cd="ambiguous" id="S4.SS1.p3.6.m2.1.1.2.2.1.cmml" xref="S4.SS1.p3.6.m2.1.1.2.2">subscript</csymbol><ci id="S4.SS1.p3.6.m2.1.1.2.2.2.cmml" xref="S4.SS1.p3.6.m2.1.1.2.2.2">𝜎</ci><apply id="S4.SS1.p3.6.m2.1.1.2.2.3.cmml" xref="S4.SS1.p3.6.m2.1.1.2.2.3"><times id="S4.SS1.p3.6.m2.1.1.2.2.3.1.cmml" xref="S4.SS1.p3.6.m2.1.1.2.2.3.1"></times><ci id="S4.SS1.p3.6.m2.1.1.2.2.3.2.cmml" xref="S4.SS1.p3.6.m2.1.1.2.2.3.2">𝑎</ci><ci id="S4.SS1.p3.6.m2.1.1.2.2.3.3.cmml" xref="S4.SS1.p3.6.m2.1.1.2.2.3.3">𝑝</ci></apply></apply></apply><apply id="S4.SS1.p3.6.m2.1.1.3.cmml" xref="S4.SS1.p3.6.m2.1.1.3"><divide id="S4.SS1.p3.6.m2.1.1.3.1.cmml" xref="S4.SS1.p3.6.m2.1.1.3.1"></divide><apply id="S4.SS1.p3.6.m2.1.1.3.2.cmml" xref="S4.SS1.p3.6.m2.1.1.3.2"><csymbol cd="ambiguous" id="S4.SS1.p3.6.m2.1.1.3.2.1.cmml" xref="S4.SS1.p3.6.m2.1.1.3.2">subscript</csymbol><ci id="S4.SS1.p3.6.m2.1.1.3.2.2.cmml" xref="S4.SS1.p3.6.m2.1.1.3.2.2">𝜎</ci><ci id="S4.SS1.p3.6.m2.1.1.3.2.3a.cmml" xref="S4.SS1.p3.6.m2.1.1.3.2.3"><mtext mathsize="70%" id="S4.SS1.p3.6.m2.1.1.3.2.3.cmml" xref="S4.SS1.p3.6.m2.1.1.3.2.3">init</mtext></ci></apply><apply id="S4.SS1.p3.6.m2.1.1.3.3.cmml" xref="S4.SS1.p3.6.m2.1.1.3.3"><root id="S4.SS1.p3.6.m2.1.1.3.3a.cmml" xref="S4.SS1.p3.6.m2.1.1.3.3"></root><ci id="S4.SS1.p3.6.m2.1.1.3.3.2.cmml" xref="S4.SS1.p3.6.m2.1.1.3.3.2">𝑛</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.6.m2.1c">\lim_{t\rightarrow\infty}\sigma_{ap}=\sigma_{\text{init}}/\sqrt{n}</annotation></semantics></math>.
Generally for other networks, numerical solution for <math id="S4.SS1.p3.7.m3.1" class="ltx_Math" alttext="\left\|v_{\text{steady}}\right\|" display="inline"><semantics id="S4.SS1.p3.7.m3.1a"><mrow id="S4.SS1.p3.7.m3.1.1.1" xref="S4.SS1.p3.7.m3.1.1.2.cmml"><mo id="S4.SS1.p3.7.m3.1.1.1.2" xref="S4.SS1.p3.7.m3.1.1.2.1.cmml">‖</mo><msub id="S4.SS1.p3.7.m3.1.1.1.1" xref="S4.SS1.p3.7.m3.1.1.1.1.cmml"><mi id="S4.SS1.p3.7.m3.1.1.1.1.2" xref="S4.SS1.p3.7.m3.1.1.1.1.2.cmml">v</mi><mtext id="S4.SS1.p3.7.m3.1.1.1.1.3" xref="S4.SS1.p3.7.m3.1.1.1.1.3a.cmml">steady</mtext></msub><mo id="S4.SS1.p3.7.m3.1.1.1.3" xref="S4.SS1.p3.7.m3.1.1.2.1.cmml">‖</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.7.m3.1b"><apply id="S4.SS1.p3.7.m3.1.1.2.cmml" xref="S4.SS1.p3.7.m3.1.1.1"><csymbol cd="latexml" id="S4.SS1.p3.7.m3.1.1.2.1.cmml" xref="S4.SS1.p3.7.m3.1.1.1.2">norm</csymbol><apply id="S4.SS1.p3.7.m3.1.1.1.1.cmml" xref="S4.SS1.p3.7.m3.1.1.1.1"><csymbol cd="ambiguous" id="S4.SS1.p3.7.m3.1.1.1.1.1.cmml" xref="S4.SS1.p3.7.m3.1.1.1.1">subscript</csymbol><ci id="S4.SS1.p3.7.m3.1.1.1.1.2.cmml" xref="S4.SS1.p3.7.m3.1.1.1.1.2">𝑣</ci><ci id="S4.SS1.p3.7.m3.1.1.1.1.3a.cmml" xref="S4.SS1.p3.7.m3.1.1.1.1.3"><mtext mathsize="70%" id="S4.SS1.p3.7.m3.1.1.1.1.3.cmml" xref="S4.SS1.p3.7.m3.1.1.1.1.3">steady</mtext></ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.7.m3.1c">\left\|v_{\text{steady}}\right\|</annotation></semantics></math> can be obtained by calculating eigenvector centralities of the original network after adding self-loops to all nodes.</p>
</div>
<div id="S4.SS1.p4" class="ltx_para">
<p id="S4.SS1.p4.2" class="ltx_p">These results, combined with the existing analyses on the role of artificial neural network parameters and their effect on diminishing or exploding gradients <cite class="ltx_cite ltx_citemacro_citep">(He et al., <a href="#bib.bib14" title="" class="ltx_ref">2015</a>)</cite> suggest that it is reasonable to take into account the compression of the node parameters (e.g., the <math id="S4.SS1.p4.1.m1.1" class="ltx_Math" alttext="1/\sqrt{n}" display="inline"><semantics id="S4.SS1.p4.1.m1.1a"><mrow id="S4.SS1.p4.1.m1.1.1" xref="S4.SS1.p4.1.m1.1.1.cmml"><mn id="S4.SS1.p4.1.m1.1.1.2" xref="S4.SS1.p4.1.m1.1.1.2.cmml">1</mn><mo id="S4.SS1.p4.1.m1.1.1.1" xref="S4.SS1.p4.1.m1.1.1.1.cmml">/</mo><msqrt id="S4.SS1.p4.1.m1.1.1.3" xref="S4.SS1.p4.1.m1.1.1.3.cmml"><mi id="S4.SS1.p4.1.m1.1.1.3.2" xref="S4.SS1.p4.1.m1.1.1.3.2.cmml">n</mi></msqrt></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p4.1.m1.1b"><apply id="S4.SS1.p4.1.m1.1.1.cmml" xref="S4.SS1.p4.1.m1.1.1"><divide id="S4.SS1.p4.1.m1.1.1.1.cmml" xref="S4.SS1.p4.1.m1.1.1.1"></divide><cn type="integer" id="S4.SS1.p4.1.m1.1.1.2.cmml" xref="S4.SS1.p4.1.m1.1.1.2">1</cn><apply id="S4.SS1.p4.1.m1.1.1.3.cmml" xref="S4.SS1.p4.1.m1.1.1.3"><root id="S4.SS1.p4.1.m1.1.1.3a.cmml" xref="S4.SS1.p4.1.m1.1.1.3"></root><ci id="S4.SS1.p4.1.m1.1.1.3.2.cmml" xref="S4.SS1.p4.1.m1.1.1.3.2">𝑛</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p4.1.m1.1c">1/\sqrt{n}</annotation></semantics></math> factor for random regular networks) when initialising the parameters<span id="footnote3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>As we showed, the reciprocal of this compression factor grows sub-linearly, at most <math id="footnote3.m1.1" class="ltx_Math" alttext="O(\sqrt{n})" display="inline"><semantics id="footnote3.m1.1b"><mrow id="footnote3.m1.1.2" xref="footnote3.m1.1.2.cmml"><mi id="footnote3.m1.1.2.2" xref="footnote3.m1.1.2.2.cmml">O</mi><mo lspace="0em" rspace="0em" id="footnote3.m1.1.2.1" xref="footnote3.m1.1.2.1.cmml">​</mo><mrow id="footnote3.m1.1.2.3.2" xref="footnote3.m1.1.1.cmml"><mo stretchy="false" id="footnote3.m1.1.2.3.2.1" xref="footnote3.m1.1.1.cmml">(</mo><msqrt id="footnote3.m1.1.1" xref="footnote3.m1.1.1.cmml"><mi id="footnote3.m1.1.1.2" xref="footnote3.m1.1.1.2.cmml">n</mi></msqrt><mo stretchy="false" id="footnote3.m1.1.2.3.2.2" xref="footnote3.m1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="footnote3.m1.1c"><apply id="footnote3.m1.1.2.cmml" xref="footnote3.m1.1.2"><times id="footnote3.m1.1.2.1.cmml" xref="footnote3.m1.1.2.1"></times><ci id="footnote3.m1.1.2.2.cmml" xref="footnote3.m1.1.2.2">𝑂</ci><apply id="footnote3.m1.1.1.cmml" xref="footnote3.m1.1.2.3.2"><root id="footnote3.m1.1.1a.cmml" xref="footnote3.m1.1.2.3.2"></root><ci id="footnote3.m1.1.1.2.cmml" xref="footnote3.m1.1.1.2">𝑛</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="footnote3.m1.1d">O(\sqrt{n})</annotation></semantics></math>, with size, meaning that using an estimate of the value of <math id="footnote3.m2.1" class="ltx_Math" alttext="n" display="inline"><semantics id="footnote3.m2.1b"><mi id="footnote3.m2.1.1" xref="footnote3.m2.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="footnote3.m2.1c"><ci id="footnote3.m2.1.1.cmml" xref="footnote3.m2.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="footnote3.m2.1d">n</annotation></semantics></math> would still be quite effective if the exact number is not known.</span></span></span>. Depending on the choice of architecture and optimiser, and especially for large networks with hundreds of nodes, this optimal selection of initial parameters can play a sizeable role in the efficacy of the training process. In our experiments, we took this into account by multiplying a gain factor of <math id="S4.SS1.p4.2.m2.1" class="ltx_Math" alttext="\sqrt{n}" display="inline"><semantics id="S4.SS1.p4.2.m2.1a"><msqrt id="S4.SS1.p4.2.m2.1.1" xref="S4.SS1.p4.2.m2.1.1.cmml"><mi id="S4.SS1.p4.2.m2.1.1.2" xref="S4.SS1.p4.2.m2.1.1.2.cmml">n</mi></msqrt><annotation-xml encoding="MathML-Content" id="S4.SS1.p4.2.m2.1b"><apply id="S4.SS1.p4.2.m2.1.1.cmml" xref="S4.SS1.p4.2.m2.1.1"><root id="S4.SS1.p4.2.m2.1.1a.cmml" xref="S4.SS1.p4.2.m2.1.1"></root><ci id="S4.SS1.p4.2.m2.1.1.2.cmml" xref="S4.SS1.p4.2.m2.1.1.2">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p4.2.m2.1c">\sqrt{n}</annotation></semantics></math> in the standard deviation of layer weights suggested by  <cite class="ltx_cite ltx_citemacro_citet">He et al. (<a href="#bib.bib14" title="" class="ltx_ref">2015</a>)</cite>.</p>
</div>
<div id="S4.SS1.p5" class="ltx_para">
<p id="S4.SS1.p5.4" class="ltx_p">Note that the vector <math id="S4.SS1.p5.1.m1.1" class="ltx_Math" alttext="v_{\text{steady}}" display="inline"><semantics id="S4.SS1.p5.1.m1.1a"><msub id="S4.SS1.p5.1.m1.1.1" xref="S4.SS1.p5.1.m1.1.1.cmml"><mi id="S4.SS1.p5.1.m1.1.1.2" xref="S4.SS1.p5.1.m1.1.1.2.cmml">v</mi><mtext id="S4.SS1.p5.1.m1.1.1.3" xref="S4.SS1.p5.1.m1.1.1.3a.cmml">steady</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p5.1.m1.1b"><apply id="S4.SS1.p5.1.m1.1.1.cmml" xref="S4.SS1.p5.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS1.p5.1.m1.1.1.1.cmml" xref="S4.SS1.p5.1.m1.1.1">subscript</csymbol><ci id="S4.SS1.p5.1.m1.1.1.2.cmml" xref="S4.SS1.p5.1.m1.1.1.2">𝑣</ci><ci id="S4.SS1.p5.1.m1.1.1.3a.cmml" xref="S4.SS1.p5.1.m1.1.1.3"><mtext mathsize="70%" id="S4.SS1.p5.1.m1.1.1.3.cmml" xref="S4.SS1.p5.1.m1.1.1.3">steady</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p5.1.m1.1c">v_{\text{steady}}</annotation></semantics></math> is simply the sum-normalised vector of eigenvector centralities of the communication network nodes with a self-loop added to all nodes, i.e. each element specifies the probability of a random walk to end up on that specific node, if the random walk process has equal probability of taking any of the edges or staying on the node. This means that the value of this gain is a factor of the system size and the distribution of network centralities. This is illustrated in <a href="#S4.F5" title="In 4.1 The compression of node parameters ‣ 4 Uncoordinated artificial neural network initialisation ‣ Initialisation and Topology Effects in Decentralised Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Figure</span> <span class="ltx_text ltx_ref_tag">5</span></a> where the value of the scaling factor <math id="S4.SS1.p5.2.m2.1" class="ltx_Math" alttext="\left\|v_{\text{steady}}\right\|" display="inline"><semantics id="S4.SS1.p5.2.m2.1a"><mrow id="S4.SS1.p5.2.m2.1.1.1" xref="S4.SS1.p5.2.m2.1.1.2.cmml"><mo id="S4.SS1.p5.2.m2.1.1.1.2" xref="S4.SS1.p5.2.m2.1.1.2.1.cmml">‖</mo><msub id="S4.SS1.p5.2.m2.1.1.1.1" xref="S4.SS1.p5.2.m2.1.1.1.1.cmml"><mi id="S4.SS1.p5.2.m2.1.1.1.1.2" xref="S4.SS1.p5.2.m2.1.1.1.1.2.cmml">v</mi><mtext id="S4.SS1.p5.2.m2.1.1.1.1.3" xref="S4.SS1.p5.2.m2.1.1.1.1.3a.cmml">steady</mtext></msub><mo id="S4.SS1.p5.2.m2.1.1.1.3" xref="S4.SS1.p5.2.m2.1.1.2.1.cmml">‖</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p5.2.m2.1b"><apply id="S4.SS1.p5.2.m2.1.1.2.cmml" xref="S4.SS1.p5.2.m2.1.1.1"><csymbol cd="latexml" id="S4.SS1.p5.2.m2.1.1.2.1.cmml" xref="S4.SS1.p5.2.m2.1.1.1.2">norm</csymbol><apply id="S4.SS1.p5.2.m2.1.1.1.1.cmml" xref="S4.SS1.p5.2.m2.1.1.1.1"><csymbol cd="ambiguous" id="S4.SS1.p5.2.m2.1.1.1.1.1.cmml" xref="S4.SS1.p5.2.m2.1.1.1.1">subscript</csymbol><ci id="S4.SS1.p5.2.m2.1.1.1.1.2.cmml" xref="S4.SS1.p5.2.m2.1.1.1.1.2">𝑣</ci><ci id="S4.SS1.p5.2.m2.1.1.1.1.3a.cmml" xref="S4.SS1.p5.2.m2.1.1.1.1.3"><mtext mathsize="70%" id="S4.SS1.p5.2.m2.1.1.1.1.3.cmml" xref="S4.SS1.p5.2.m2.1.1.1.1.3">steady</mtext></ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p5.2.m2.1c">\left\|v_{\text{steady}}\right\|</annotation></semantics></math> is shown for Erdős–Rényi, <math id="S4.SS1.p5.3.m3.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S4.SS1.p5.3.m3.1a"><mi id="S4.SS1.p5.3.m3.1.1" xref="S4.SS1.p5.3.m3.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p5.3.m3.1b"><ci id="S4.SS1.p5.3.m3.1.1.cmml" xref="S4.SS1.p5.3.m3.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p5.3.m3.1c">k</annotation></semantics></math>-regular, Barabási–Albert and heavy-tail (<math id="S4.SS1.p5.4.m4.1" class="ltx_Math" alttext="\gamma=-3" display="inline"><semantics id="S4.SS1.p5.4.m4.1a"><mrow id="S4.SS1.p5.4.m4.1.1" xref="S4.SS1.p5.4.m4.1.1.cmml"><mi id="S4.SS1.p5.4.m4.1.1.2" xref="S4.SS1.p5.4.m4.1.1.2.cmml">γ</mi><mo id="S4.SS1.p5.4.m4.1.1.1" xref="S4.SS1.p5.4.m4.1.1.1.cmml">=</mo><mrow id="S4.SS1.p5.4.m4.1.1.3" xref="S4.SS1.p5.4.m4.1.1.3.cmml"><mo id="S4.SS1.p5.4.m4.1.1.3a" xref="S4.SS1.p5.4.m4.1.1.3.cmml">−</mo><mn id="S4.SS1.p5.4.m4.1.1.3.2" xref="S4.SS1.p5.4.m4.1.1.3.2.cmml">3</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p5.4.m4.1b"><apply id="S4.SS1.p5.4.m4.1.1.cmml" xref="S4.SS1.p5.4.m4.1.1"><eq id="S4.SS1.p5.4.m4.1.1.1.cmml" xref="S4.SS1.p5.4.m4.1.1.1"></eq><ci id="S4.SS1.p5.4.m4.1.1.2.cmml" xref="S4.SS1.p5.4.m4.1.1.2">𝛾</ci><apply id="S4.SS1.p5.4.m4.1.1.3.cmml" xref="S4.SS1.p5.4.m4.1.1.3"><minus id="S4.SS1.p5.4.m4.1.1.3.1.cmml" xref="S4.SS1.p5.4.m4.1.1.3"></minus><cn type="integer" id="S4.SS1.p5.4.m4.1.1.3.2.cmml" xref="S4.SS1.p5.4.m4.1.1.3.2">3</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p5.4.m4.1c">\gamma=-3</annotation></semantics></math>) degree distribution configuration model random networks with the same size and (on expectation) the same number of links.</p>
</div>
<figure id="S4.F5" class="ltx_figure"><img src="/html/2403.15855/assets/x5.png" id="S4.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="346" height="216" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>The effect of heterogeneous distribution of centralities in the scaling factor <math id="S4.F5.6.m1.1" class="ltx_Math" alttext="\left\|v_{\text{steady}}\right\|" display="inline"><semantics id="S4.F5.6.m1.1b"><mrow id="S4.F5.6.m1.1.1.1" xref="S4.F5.6.m1.1.1.2.cmml"><mo id="S4.F5.6.m1.1.1.1.2" xref="S4.F5.6.m1.1.1.2.1.cmml">‖</mo><msub id="S4.F5.6.m1.1.1.1.1" xref="S4.F5.6.m1.1.1.1.1.cmml"><mi id="S4.F5.6.m1.1.1.1.1.2" xref="S4.F5.6.m1.1.1.1.1.2.cmml">v</mi><mtext id="S4.F5.6.m1.1.1.1.1.3" xref="S4.F5.6.m1.1.1.1.1.3a.cmml">steady</mtext></msub><mo id="S4.F5.6.m1.1.1.1.3" xref="S4.F5.6.m1.1.1.2.1.cmml">‖</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.F5.6.m1.1c"><apply id="S4.F5.6.m1.1.1.2.cmml" xref="S4.F5.6.m1.1.1.1"><csymbol cd="latexml" id="S4.F5.6.m1.1.1.2.1.cmml" xref="S4.F5.6.m1.1.1.1.2">norm</csymbol><apply id="S4.F5.6.m1.1.1.1.1.cmml" xref="S4.F5.6.m1.1.1.1.1"><csymbol cd="ambiguous" id="S4.F5.6.m1.1.1.1.1.1.cmml" xref="S4.F5.6.m1.1.1.1.1">subscript</csymbol><ci id="S4.F5.6.m1.1.1.1.1.2.cmml" xref="S4.F5.6.m1.1.1.1.1.2">𝑣</ci><ci id="S4.F5.6.m1.1.1.1.1.3a.cmml" xref="S4.F5.6.m1.1.1.1.1.3"><mtext mathsize="70%" id="S4.F5.6.m1.1.1.1.1.3.cmml" xref="S4.F5.6.m1.1.1.1.1.3">steady</mtext></ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F5.6.m1.1d">\left\|v_{\text{steady}}\right\|</annotation></semantics></math> from the simplified numerical model. Homogeneous random networks (Erdős–Rényi <math id="S4.F5.7.m2.2" class="ltx_Math" alttext="G(n,p)" display="inline"><semantics id="S4.F5.7.m2.2b"><mrow id="S4.F5.7.m2.2.3" xref="S4.F5.7.m2.2.3.cmml"><mi id="S4.F5.7.m2.2.3.2" xref="S4.F5.7.m2.2.3.2.cmml">G</mi><mo lspace="0em" rspace="0em" id="S4.F5.7.m2.2.3.1" xref="S4.F5.7.m2.2.3.1.cmml">​</mo><mrow id="S4.F5.7.m2.2.3.3.2" xref="S4.F5.7.m2.2.3.3.1.cmml"><mo stretchy="false" id="S4.F5.7.m2.2.3.3.2.1" xref="S4.F5.7.m2.2.3.3.1.cmml">(</mo><mi id="S4.F5.7.m2.1.1" xref="S4.F5.7.m2.1.1.cmml">n</mi><mo id="S4.F5.7.m2.2.3.3.2.2" xref="S4.F5.7.m2.2.3.3.1.cmml">,</mo><mi id="S4.F5.7.m2.2.2" xref="S4.F5.7.m2.2.2.cmml">p</mi><mo stretchy="false" id="S4.F5.7.m2.2.3.3.2.3" xref="S4.F5.7.m2.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.F5.7.m2.2c"><apply id="S4.F5.7.m2.2.3.cmml" xref="S4.F5.7.m2.2.3"><times id="S4.F5.7.m2.2.3.1.cmml" xref="S4.F5.7.m2.2.3.1"></times><ci id="S4.F5.7.m2.2.3.2.cmml" xref="S4.F5.7.m2.2.3.2">𝐺</ci><interval closure="open" id="S4.F5.7.m2.2.3.3.1.cmml" xref="S4.F5.7.m2.2.3.3.2"><ci id="S4.F5.7.m2.1.1.cmml" xref="S4.F5.7.m2.1.1">𝑛</ci><ci id="S4.F5.7.m2.2.2.cmml" xref="S4.F5.7.m2.2.2">𝑝</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F5.7.m2.2d">G(n,p)</annotation></semantics></math> networks and random <math id="S4.F5.8.m3.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S4.F5.8.m3.1b"><mi id="S4.F5.8.m3.1.1" xref="S4.F5.8.m3.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.F5.8.m3.1c"><ci id="S4.F5.8.m3.1.1.cmml" xref="S4.F5.8.m3.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.F5.8.m3.1d">k</annotation></semantics></math>-regular networks) display <math id="S4.F5.9.m4.1" class="ltx_Math" alttext="\left\|v_{\text{steady}}\right\|=1/\sqrt{n}" display="inline"><semantics id="S4.F5.9.m4.1b"><mrow id="S4.F5.9.m4.1.1" xref="S4.F5.9.m4.1.1.cmml"><mrow id="S4.F5.9.m4.1.1.1.1" xref="S4.F5.9.m4.1.1.1.2.cmml"><mo id="S4.F5.9.m4.1.1.1.1.2" xref="S4.F5.9.m4.1.1.1.2.1.cmml">‖</mo><msub id="S4.F5.9.m4.1.1.1.1.1" xref="S4.F5.9.m4.1.1.1.1.1.cmml"><mi id="S4.F5.9.m4.1.1.1.1.1.2" xref="S4.F5.9.m4.1.1.1.1.1.2.cmml">v</mi><mtext id="S4.F5.9.m4.1.1.1.1.1.3" xref="S4.F5.9.m4.1.1.1.1.1.3a.cmml">steady</mtext></msub><mo id="S4.F5.9.m4.1.1.1.1.3" xref="S4.F5.9.m4.1.1.1.2.1.cmml">‖</mo></mrow><mo id="S4.F5.9.m4.1.1.2" xref="S4.F5.9.m4.1.1.2.cmml">=</mo><mrow id="S4.F5.9.m4.1.1.3" xref="S4.F5.9.m4.1.1.3.cmml"><mn id="S4.F5.9.m4.1.1.3.2" xref="S4.F5.9.m4.1.1.3.2.cmml">1</mn><mo id="S4.F5.9.m4.1.1.3.1" xref="S4.F5.9.m4.1.1.3.1.cmml">/</mo><msqrt id="S4.F5.9.m4.1.1.3.3" xref="S4.F5.9.m4.1.1.3.3.cmml"><mi id="S4.F5.9.m4.1.1.3.3.2" xref="S4.F5.9.m4.1.1.3.3.2.cmml">n</mi></msqrt></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.F5.9.m4.1c"><apply id="S4.F5.9.m4.1.1.cmml" xref="S4.F5.9.m4.1.1"><eq id="S4.F5.9.m4.1.1.2.cmml" xref="S4.F5.9.m4.1.1.2"></eq><apply id="S4.F5.9.m4.1.1.1.2.cmml" xref="S4.F5.9.m4.1.1.1.1"><csymbol cd="latexml" id="S4.F5.9.m4.1.1.1.2.1.cmml" xref="S4.F5.9.m4.1.1.1.1.2">norm</csymbol><apply id="S4.F5.9.m4.1.1.1.1.1.cmml" xref="S4.F5.9.m4.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.F5.9.m4.1.1.1.1.1.1.cmml" xref="S4.F5.9.m4.1.1.1.1.1">subscript</csymbol><ci id="S4.F5.9.m4.1.1.1.1.1.2.cmml" xref="S4.F5.9.m4.1.1.1.1.1.2">𝑣</ci><ci id="S4.F5.9.m4.1.1.1.1.1.3a.cmml" xref="S4.F5.9.m4.1.1.1.1.1.3"><mtext mathsize="70%" id="S4.F5.9.m4.1.1.1.1.1.3.cmml" xref="S4.F5.9.m4.1.1.1.1.1.3">steady</mtext></ci></apply></apply><apply id="S4.F5.9.m4.1.1.3.cmml" xref="S4.F5.9.m4.1.1.3"><divide id="S4.F5.9.m4.1.1.3.1.cmml" xref="S4.F5.9.m4.1.1.3.1"></divide><cn type="integer" id="S4.F5.9.m4.1.1.3.2.cmml" xref="S4.F5.9.m4.1.1.3.2">1</cn><apply id="S4.F5.9.m4.1.1.3.3.cmml" xref="S4.F5.9.m4.1.1.3.3"><root id="S4.F5.9.m4.1.1.3.3a.cmml" xref="S4.F5.9.m4.1.1.3.3"></root><ci id="S4.F5.9.m4.1.1.3.3.2.cmml" xref="S4.F5.9.m4.1.1.3.3.2">𝑛</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F5.9.m4.1d">\left\|v_{\text{steady}}\right\|=1/\sqrt{n}</annotation></semantics></math>, while Barabási–Albert networks and configuration model heavy-tail degree distribution networks (<math id="S4.F5.10.m5.1" class="ltx_Math" alttext="\gamma=-3" display="inline"><semantics id="S4.F5.10.m5.1b"><mrow id="S4.F5.10.m5.1.1" xref="S4.F5.10.m5.1.1.cmml"><mi id="S4.F5.10.m5.1.1.2" xref="S4.F5.10.m5.1.1.2.cmml">γ</mi><mo id="S4.F5.10.m5.1.1.1" xref="S4.F5.10.m5.1.1.1.cmml">=</mo><mrow id="S4.F5.10.m5.1.1.3" xref="S4.F5.10.m5.1.1.3.cmml"><mo id="S4.F5.10.m5.1.1.3b" xref="S4.F5.10.m5.1.1.3.cmml">−</mo><mn id="S4.F5.10.m5.1.1.3.2" xref="S4.F5.10.m5.1.1.3.2.cmml">3</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.F5.10.m5.1c"><apply id="S4.F5.10.m5.1.1.cmml" xref="S4.F5.10.m5.1.1"><eq id="S4.F5.10.m5.1.1.1.cmml" xref="S4.F5.10.m5.1.1.1"></eq><ci id="S4.F5.10.m5.1.1.2.cmml" xref="S4.F5.10.m5.1.1.2">𝛾</ci><apply id="S4.F5.10.m5.1.1.3.cmml" xref="S4.F5.10.m5.1.1.3"><minus id="S4.F5.10.m5.1.1.3.1.cmml" xref="S4.F5.10.m5.1.1.3"></minus><cn type="integer" id="S4.F5.10.m5.1.1.3.2.cmml" xref="S4.F5.10.m5.1.1.3.2">3</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F5.10.m5.1d">\gamma=-3</annotation></semantics></math>) show this factor scaling exponentially with the number of nodes with a different exponent. Fitted dashed lines are slightly shifted vertically for visibility.</figcaption>
</figure>
<div id="S4.SS1.p6" class="ltx_para">
<p id="S4.SS1.p6.3" class="ltx_p">The numeric model applies with minimal changes to directed and weighted communication networks. similar to connected undirected networks. In the case of a strongly connected directed network, the convergence is guaranteed since the stochastic matrix <math id="S4.SS1.p6.1.m1.1" class="ltx_Math" alttext="A^{\prime}" display="inline"><semantics id="S4.SS1.p6.1.m1.1a"><msup id="S4.SS1.p6.1.m1.1.1" xref="S4.SS1.p6.1.m1.1.1.cmml"><mi id="S4.SS1.p6.1.m1.1.1.2" xref="S4.SS1.p6.1.m1.1.1.2.cmml">A</mi><mo id="S4.SS1.p6.1.m1.1.1.3" xref="S4.SS1.p6.1.m1.1.1.3.cmml">′</mo></msup><annotation-xml encoding="MathML-Content" id="S4.SS1.p6.1.m1.1b"><apply id="S4.SS1.p6.1.m1.1.1.cmml" xref="S4.SS1.p6.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS1.p6.1.m1.1.1.1.cmml" xref="S4.SS1.p6.1.m1.1.1">superscript</csymbol><ci id="S4.SS1.p6.1.m1.1.1.2.cmml" xref="S4.SS1.p6.1.m1.1.1.2">𝐴</ci><ci id="S4.SS1.p6.1.m1.1.1.3.cmml" xref="S4.SS1.p6.1.m1.1.1.3">′</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p6.1.m1.1c">A^{\prime}</annotation></semantics></math> is aperiodic due to the existence of the self-loops. For the case of a weighted communication network, the weights are reflected in the graph adjacency matrix <math id="S4.SS1.p6.2.m2.1" class="ltx_Math" alttext="A" display="inline"><semantics id="S4.SS1.p6.2.m2.1a"><mi id="S4.SS1.p6.2.m2.1.1" xref="S4.SS1.p6.2.m2.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p6.2.m2.1b"><ci id="S4.SS1.p6.2.m2.1.1.cmml" xref="S4.SS1.p6.2.m2.1.1">𝐴</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p6.2.m2.1c">A</annotation></semantics></math>, with the provision that a diagonal matrix of the weights each node assigns to its own weights should be used in <a href="#S4.E1" title="In 4.1 The compression of node parameters ‣ 4 Uncoordinated artificial neural network initialisation ‣ Initialisation and Topology Effects in Decentralised Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Equation</span> <span class="ltx_text ltx_ref_tag">1</span></a> instead of the identity matrix <math id="S4.SS1.p6.3.m3.1" class="ltx_Math" alttext="I" display="inline"><semantics id="S4.SS1.p6.3.m3.1a"><mi id="S4.SS1.p6.3.m3.1.1" xref="S4.SS1.p6.3.m3.1.1.cmml">I</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p6.3.m3.1b"><ci id="S4.SS1.p6.3.m3.1.1.cmml" xref="S4.SS1.p6.3.m3.1.1">𝐼</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p6.3.m3.1c">I</annotation></semantics></math>.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Initial stabilisation time</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">The stabilisation time of <math id="S4.SS2.p1.1.m1.1" class="ltx_Math" alttext="\sigma_{an}" display="inline"><semantics id="S4.SS2.p1.1.m1.1a"><msub id="S4.SS2.p1.1.m1.1.1" xref="S4.SS2.p1.1.m1.1.1.cmml"><mi id="S4.SS2.p1.1.m1.1.1.2" xref="S4.SS2.p1.1.m1.1.1.2.cmml">σ</mi><mrow id="S4.SS2.p1.1.m1.1.1.3" xref="S4.SS2.p1.1.m1.1.1.3.cmml"><mi id="S4.SS2.p1.1.m1.1.1.3.2" xref="S4.SS2.p1.1.m1.1.1.3.2.cmml">a</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p1.1.m1.1.1.3.1" xref="S4.SS2.p1.1.m1.1.1.3.1.cmml">​</mo><mi id="S4.SS2.p1.1.m1.1.1.3.3" xref="S4.SS2.p1.1.m1.1.1.3.3.cmml">n</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.1.m1.1b"><apply id="S4.SS2.p1.1.m1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS2.p1.1.m1.1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1">subscript</csymbol><ci id="S4.SS2.p1.1.m1.1.1.2.cmml" xref="S4.SS2.p1.1.m1.1.1.2">𝜎</ci><apply id="S4.SS2.p1.1.m1.1.1.3.cmml" xref="S4.SS2.p1.1.m1.1.1.3"><times id="S4.SS2.p1.1.m1.1.1.3.1.cmml" xref="S4.SS2.p1.1.m1.1.1.3.1"></times><ci id="S4.SS2.p1.1.m1.1.1.3.2.cmml" xref="S4.SS2.p1.1.m1.1.1.3.2">𝑎</ci><ci id="S4.SS2.p1.1.m1.1.1.3.3.cmml" xref="S4.SS2.p1.1.m1.1.1.3.3">𝑛</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.1.m1.1c">\sigma_{an}</annotation></semantics></math>, the number of communication rounds until the blue curve in <a href="#S4.F4" title="In 4 Uncoordinated artificial neural network initialisation ‣ Initialisation and Topology Effects in Decentralised Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Figure</span> <span class="ltx_text ltx_ref_tag">4</span></a> flattens out, determines the number of rounds where local training has a negligible effect on the parameters. Understanding the scaling of this stabilisation time with the number of nodes and other environmental parameters is important, insofar as before this stabilisation the aggregation process dominates the local training process by several orders of magnitude (<a href="#S4.F2" title="In 4 Uncoordinated artificial neural network initialisation ‣ Initialisation and Topology Effects in Decentralised Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Figure</span> <span class="ltx_text ltx_ref_tag">2</span></a>), inhibiting effective training.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.7" class="ltx_p">Deriving the scaling of number of stabilisation rounds with number of nodes <math id="S4.SS2.p2.1.m1.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S4.SS2.p2.1.m1.1a"><mi id="S4.SS2.p2.1.m1.1.1" xref="S4.SS2.p2.1.m1.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.1.m1.1b"><ci id="S4.SS2.p2.1.m1.1.1.cmml" xref="S4.SS2.p2.1.m1.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.1.m1.1c">n</annotation></semantics></math> is a matter of calculating the mixing time of the Markov matrix <math id="S4.SS2.p2.2.m2.1" class="ltx_Math" alttext="A^{\prime}" display="inline"><semantics id="S4.SS2.p2.2.m2.1a"><msup id="S4.SS2.p2.2.m2.1.1" xref="S4.SS2.p2.2.m2.1.1.cmml"><mi id="S4.SS2.p2.2.m2.1.1.2" xref="S4.SS2.p2.2.m2.1.1.2.cmml">A</mi><mo id="S4.SS2.p2.2.m2.1.1.3" xref="S4.SS2.p2.2.m2.1.1.3.cmml">′</mo></msup><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.2.m2.1b"><apply id="S4.SS2.p2.2.m2.1.1.cmml" xref="S4.SS2.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS2.p2.2.m2.1.1.1.cmml" xref="S4.SS2.p2.2.m2.1.1">superscript</csymbol><ci id="S4.SS2.p2.2.m2.1.1.2.cmml" xref="S4.SS2.p2.2.m2.1.1.2">𝐴</ci><ci id="S4.SS2.p2.2.m2.1.1.3.cmml" xref="S4.SS2.p2.2.m2.1.1.3">′</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.2.m2.1c">A^{\prime}</annotation></semantics></math>. The problem is remarkably close to a lazy random walk setting, where at each step the walker might stay on the node with probability <math id="S4.SS2.p2.3.m3.1" class="ltx_Math" alttext="1/2" display="inline"><semantics id="S4.SS2.p2.3.m3.1a"><mrow id="S4.SS2.p2.3.m3.1.1" xref="S4.SS2.p2.3.m3.1.1.cmml"><mn id="S4.SS2.p2.3.m3.1.1.2" xref="S4.SS2.p2.3.m3.1.1.2.cmml">1</mn><mo id="S4.SS2.p2.3.m3.1.1.1" xref="S4.SS2.p2.3.m3.1.1.1.cmml">/</mo><mn id="S4.SS2.p2.3.m3.1.1.3" xref="S4.SS2.p2.3.m3.1.1.3.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.3.m3.1b"><apply id="S4.SS2.p2.3.m3.1.1.cmml" xref="S4.SS2.p2.3.m3.1.1"><divide id="S4.SS2.p2.3.m3.1.1.1.cmml" xref="S4.SS2.p2.3.m3.1.1.1"></divide><cn type="integer" id="S4.SS2.p2.3.m3.1.1.2.cmml" xref="S4.SS2.p2.3.m3.1.1.2">1</cn><cn type="integer" id="S4.SS2.p2.3.m3.1.1.3.cmml" xref="S4.SS2.p2.3.m3.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.3.m3.1c">1/2</annotation></semantics></math> or select one of the links for the next transition. However, in our case this staying probability is lower or equal to that of lazy random walk, being equal to <math id="S4.SS2.p2.4.m4.1" class="ltx_Math" alttext="1/(k_{i}+1)" display="inline"><semantics id="S4.SS2.p2.4.m4.1a"><mrow id="S4.SS2.p2.4.m4.1.1" xref="S4.SS2.p2.4.m4.1.1.cmml"><mn id="S4.SS2.p2.4.m4.1.1.3" xref="S4.SS2.p2.4.m4.1.1.3.cmml">1</mn><mo id="S4.SS2.p2.4.m4.1.1.2" xref="S4.SS2.p2.4.m4.1.1.2.cmml">/</mo><mrow id="S4.SS2.p2.4.m4.1.1.1.1" xref="S4.SS2.p2.4.m4.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.SS2.p2.4.m4.1.1.1.1.2" xref="S4.SS2.p2.4.m4.1.1.1.1.1.cmml">(</mo><mrow id="S4.SS2.p2.4.m4.1.1.1.1.1" xref="S4.SS2.p2.4.m4.1.1.1.1.1.cmml"><msub id="S4.SS2.p2.4.m4.1.1.1.1.1.2" xref="S4.SS2.p2.4.m4.1.1.1.1.1.2.cmml"><mi id="S4.SS2.p2.4.m4.1.1.1.1.1.2.2" xref="S4.SS2.p2.4.m4.1.1.1.1.1.2.2.cmml">k</mi><mi id="S4.SS2.p2.4.m4.1.1.1.1.1.2.3" xref="S4.SS2.p2.4.m4.1.1.1.1.1.2.3.cmml">i</mi></msub><mo id="S4.SS2.p2.4.m4.1.1.1.1.1.1" xref="S4.SS2.p2.4.m4.1.1.1.1.1.1.cmml">+</mo><mn id="S4.SS2.p2.4.m4.1.1.1.1.1.3" xref="S4.SS2.p2.4.m4.1.1.1.1.1.3.cmml">1</mn></mrow><mo stretchy="false" id="S4.SS2.p2.4.m4.1.1.1.1.3" xref="S4.SS2.p2.4.m4.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.4.m4.1b"><apply id="S4.SS2.p2.4.m4.1.1.cmml" xref="S4.SS2.p2.4.m4.1.1"><divide id="S4.SS2.p2.4.m4.1.1.2.cmml" xref="S4.SS2.p2.4.m4.1.1.2"></divide><cn type="integer" id="S4.SS2.p2.4.m4.1.1.3.cmml" xref="S4.SS2.p2.4.m4.1.1.3">1</cn><apply id="S4.SS2.p2.4.m4.1.1.1.1.1.cmml" xref="S4.SS2.p2.4.m4.1.1.1.1"><plus id="S4.SS2.p2.4.m4.1.1.1.1.1.1.cmml" xref="S4.SS2.p2.4.m4.1.1.1.1.1.1"></plus><apply id="S4.SS2.p2.4.m4.1.1.1.1.1.2.cmml" xref="S4.SS2.p2.4.m4.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S4.SS2.p2.4.m4.1.1.1.1.1.2.1.cmml" xref="S4.SS2.p2.4.m4.1.1.1.1.1.2">subscript</csymbol><ci id="S4.SS2.p2.4.m4.1.1.1.1.1.2.2.cmml" xref="S4.SS2.p2.4.m4.1.1.1.1.1.2.2">𝑘</ci><ci id="S4.SS2.p2.4.m4.1.1.1.1.1.2.3.cmml" xref="S4.SS2.p2.4.m4.1.1.1.1.1.2.3">𝑖</ci></apply><cn type="integer" id="S4.SS2.p2.4.m4.1.1.1.1.1.3.cmml" xref="S4.SS2.p2.4.m4.1.1.1.1.1.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.4.m4.1c">1/(k_{i}+1)</annotation></semantics></math> where <math id="S4.SS2.p2.5.m5.1" class="ltx_Math" alttext="k_{i}" display="inline"><semantics id="S4.SS2.p2.5.m5.1a"><msub id="S4.SS2.p2.5.m5.1.1" xref="S4.SS2.p2.5.m5.1.1.cmml"><mi id="S4.SS2.p2.5.m5.1.1.2" xref="S4.SS2.p2.5.m5.1.1.2.cmml">k</mi><mi id="S4.SS2.p2.5.m5.1.1.3" xref="S4.SS2.p2.5.m5.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.5.m5.1b"><apply id="S4.SS2.p2.5.m5.1.1.cmml" xref="S4.SS2.p2.5.m5.1.1"><csymbol cd="ambiguous" id="S4.SS2.p2.5.m5.1.1.1.cmml" xref="S4.SS2.p2.5.m5.1.1">subscript</csymbol><ci id="S4.SS2.p2.5.m5.1.1.2.cmml" xref="S4.SS2.p2.5.m5.1.1.2">𝑘</ci><ci id="S4.SS2.p2.5.m5.1.1.3.cmml" xref="S4.SS2.p2.5.m5.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.5.m5.1c">k_{i}</annotation></semantics></math> is the degree of node <math id="S4.SS2.p2.6.m6.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S4.SS2.p2.6.m6.1a"><mi id="S4.SS2.p2.6.m6.1.1" xref="S4.SS2.p2.6.m6.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.6.m6.1b"><ci id="S4.SS2.p2.6.m6.1.1.cmml" xref="S4.SS2.p2.6.m6.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.6.m6.1c">i</annotation></semantics></math>. It has been shown that, since the staying probabilities are bounded in <math id="S4.SS2.p2.7.m7.2" class="ltx_Math" alttext="(0,1)" display="inline"><semantics id="S4.SS2.p2.7.m7.2a"><mrow id="S4.SS2.p2.7.m7.2.3.2" xref="S4.SS2.p2.7.m7.2.3.1.cmml"><mo stretchy="false" id="S4.SS2.p2.7.m7.2.3.2.1" xref="S4.SS2.p2.7.m7.2.3.1.cmml">(</mo><mn id="S4.SS2.p2.7.m7.1.1" xref="S4.SS2.p2.7.m7.1.1.cmml">0</mn><mo id="S4.SS2.p2.7.m7.2.3.2.2" xref="S4.SS2.p2.7.m7.2.3.1.cmml">,</mo><mn id="S4.SS2.p2.7.m7.2.2" xref="S4.SS2.p2.7.m7.2.2.cmml">1</mn><mo stretchy="false" id="S4.SS2.p2.7.m7.2.3.2.3" xref="S4.SS2.p2.7.m7.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.7.m7.2b"><interval closure="open" id="S4.SS2.p2.7.m7.2.3.1.cmml" xref="S4.SS2.p2.7.m7.2.3.2"><cn type="integer" id="S4.SS2.p2.7.m7.1.1.cmml" xref="S4.SS2.p2.7.m7.1.1">0</cn><cn type="integer" id="S4.SS2.p2.7.m7.2.2.cmml" xref="S4.SS2.p2.7.m7.2.2">1</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.7.m7.2c">(0,1)</annotation></semantics></math>, the mixing time of the random walk process described here grows asymptotically with that of lazy random walk up to a constant factor <cite class="ltx_cite ltx_citemacro_citep">(Peres &amp; Sousi, <a href="#bib.bib31" title="" class="ltx_ref">2015</a>, Corollary 9.5)</cite>.</p>
</div>
<div id="S4.SS2.p3" class="ltx_para">
<p id="S4.SS2.p3.7" class="ltx_p">Mixing time of lazy random-walks on graphs is a subject of active study. Lattices on d-dimensional tori, have a mixing time with an upper bound at <math id="S4.SS2.p3.1.m1.1" class="ltx_Math" alttext="d^{2}l^{2}" display="inline"><semantics id="S4.SS2.p3.1.m1.1a"><mrow id="S4.SS2.p3.1.m1.1.1" xref="S4.SS2.p3.1.m1.1.1.cmml"><msup id="S4.SS2.p3.1.m1.1.1.2" xref="S4.SS2.p3.1.m1.1.1.2.cmml"><mi id="S4.SS2.p3.1.m1.1.1.2.2" xref="S4.SS2.p3.1.m1.1.1.2.2.cmml">d</mi><mn id="S4.SS2.p3.1.m1.1.1.2.3" xref="S4.SS2.p3.1.m1.1.1.2.3.cmml">2</mn></msup><mo lspace="0em" rspace="0em" id="S4.SS2.p3.1.m1.1.1.1" xref="S4.SS2.p3.1.m1.1.1.1.cmml">​</mo><msup id="S4.SS2.p3.1.m1.1.1.3" xref="S4.SS2.p3.1.m1.1.1.3.cmml"><mi id="S4.SS2.p3.1.m1.1.1.3.2" xref="S4.SS2.p3.1.m1.1.1.3.2.cmml">l</mi><mn id="S4.SS2.p3.1.m1.1.1.3.3" xref="S4.SS2.p3.1.m1.1.1.3.3.cmml">2</mn></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.1.m1.1b"><apply id="S4.SS2.p3.1.m1.1.1.cmml" xref="S4.SS2.p3.1.m1.1.1"><times id="S4.SS2.p3.1.m1.1.1.1.cmml" xref="S4.SS2.p3.1.m1.1.1.1"></times><apply id="S4.SS2.p3.1.m1.1.1.2.cmml" xref="S4.SS2.p3.1.m1.1.1.2"><csymbol cd="ambiguous" id="S4.SS2.p3.1.m1.1.1.2.1.cmml" xref="S4.SS2.p3.1.m1.1.1.2">superscript</csymbol><ci id="S4.SS2.p3.1.m1.1.1.2.2.cmml" xref="S4.SS2.p3.1.m1.1.1.2.2">𝑑</ci><cn type="integer" id="S4.SS2.p3.1.m1.1.1.2.3.cmml" xref="S4.SS2.p3.1.m1.1.1.2.3">2</cn></apply><apply id="S4.SS2.p3.1.m1.1.1.3.cmml" xref="S4.SS2.p3.1.m1.1.1.3"><csymbol cd="ambiguous" id="S4.SS2.p3.1.m1.1.1.3.1.cmml" xref="S4.SS2.p3.1.m1.1.1.3">superscript</csymbol><ci id="S4.SS2.p3.1.m1.1.1.3.2.cmml" xref="S4.SS2.p3.1.m1.1.1.3.2">𝑙</ci><cn type="integer" id="S4.SS2.p3.1.m1.1.1.3.3.cmml" xref="S4.SS2.p3.1.m1.1.1.3.3">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.1.m1.1c">d^{2}l^{2}</annotation></semantics></math> <cite class="ltx_cite ltx_citemacro_citep">(Levin &amp; Peres, <a href="#bib.bib23" title="" class="ltx_ref">2017</a>, Theorem 5.5)</cite> where <math id="S4.SS2.p3.2.m2.1" class="ltx_Math" alttext="l\propto n^{1/d}" display="inline"><semantics id="S4.SS2.p3.2.m2.1a"><mrow id="S4.SS2.p3.2.m2.1.1" xref="S4.SS2.p3.2.m2.1.1.cmml"><mi id="S4.SS2.p3.2.m2.1.1.2" xref="S4.SS2.p3.2.m2.1.1.2.cmml">l</mi><mo id="S4.SS2.p3.2.m2.1.1.1" xref="S4.SS2.p3.2.m2.1.1.1.cmml">∝</mo><msup id="S4.SS2.p3.2.m2.1.1.3" xref="S4.SS2.p3.2.m2.1.1.3.cmml"><mi id="S4.SS2.p3.2.m2.1.1.3.2" xref="S4.SS2.p3.2.m2.1.1.3.2.cmml">n</mi><mrow id="S4.SS2.p3.2.m2.1.1.3.3" xref="S4.SS2.p3.2.m2.1.1.3.3.cmml"><mn id="S4.SS2.p3.2.m2.1.1.3.3.2" xref="S4.SS2.p3.2.m2.1.1.3.3.2.cmml">1</mn><mo id="S4.SS2.p3.2.m2.1.1.3.3.1" xref="S4.SS2.p3.2.m2.1.1.3.3.1.cmml">/</mo><mi id="S4.SS2.p3.2.m2.1.1.3.3.3" xref="S4.SS2.p3.2.m2.1.1.3.3.3.cmml">d</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.2.m2.1b"><apply id="S4.SS2.p3.2.m2.1.1.cmml" xref="S4.SS2.p3.2.m2.1.1"><csymbol cd="latexml" id="S4.SS2.p3.2.m2.1.1.1.cmml" xref="S4.SS2.p3.2.m2.1.1.1">proportional-to</csymbol><ci id="S4.SS2.p3.2.m2.1.1.2.cmml" xref="S4.SS2.p3.2.m2.1.1.2">𝑙</ci><apply id="S4.SS2.p3.2.m2.1.1.3.cmml" xref="S4.SS2.p3.2.m2.1.1.3"><csymbol cd="ambiguous" id="S4.SS2.p3.2.m2.1.1.3.1.cmml" xref="S4.SS2.p3.2.m2.1.1.3">superscript</csymbol><ci id="S4.SS2.p3.2.m2.1.1.3.2.cmml" xref="S4.SS2.p3.2.m2.1.1.3.2">𝑛</ci><apply id="S4.SS2.p3.2.m2.1.1.3.3.cmml" xref="S4.SS2.p3.2.m2.1.1.3.3"><divide id="S4.SS2.p3.2.m2.1.1.3.3.1.cmml" xref="S4.SS2.p3.2.m2.1.1.3.3.1"></divide><cn type="integer" id="S4.SS2.p3.2.m2.1.1.3.3.2.cmml" xref="S4.SS2.p3.2.m2.1.1.3.3.2">1</cn><ci id="S4.SS2.p3.2.m2.1.1.3.3.3.cmml" xref="S4.SS2.p3.2.m2.1.1.3.3.3">𝑑</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.2.m2.1c">l\propto n^{1/d}</annotation></semantics></math> is the linear size of the system. It has also been shown that connected random <math id="S4.SS2.p3.3.m3.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S4.SS2.p3.3.m3.1a"><mi id="S4.SS2.p3.3.m3.1.1" xref="S4.SS2.p3.3.m3.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.3.m3.1b"><ci id="S4.SS2.p3.3.m3.1.1.cmml" xref="S4.SS2.p3.3.m3.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.3.m3.1c">k</annotation></semantics></math>-regular networks, as examples of expander graphs, have a mixing time of <math id="S4.SS2.p3.4.m4.1" class="ltx_Math" alttext="O(\log n)" display="inline"><semantics id="S4.SS2.p3.4.m4.1a"><mrow id="S4.SS2.p3.4.m4.1.1" xref="S4.SS2.p3.4.m4.1.1.cmml"><mi id="S4.SS2.p3.4.m4.1.1.3" xref="S4.SS2.p3.4.m4.1.1.3.cmml">O</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p3.4.m4.1.1.2" xref="S4.SS2.p3.4.m4.1.1.2.cmml">​</mo><mrow id="S4.SS2.p3.4.m4.1.1.1.1" xref="S4.SS2.p3.4.m4.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.SS2.p3.4.m4.1.1.1.1.2" xref="S4.SS2.p3.4.m4.1.1.1.1.1.cmml">(</mo><mrow id="S4.SS2.p3.4.m4.1.1.1.1.1" xref="S4.SS2.p3.4.m4.1.1.1.1.1.cmml"><mi id="S4.SS2.p3.4.m4.1.1.1.1.1.1" xref="S4.SS2.p3.4.m4.1.1.1.1.1.1.cmml">log</mi><mo lspace="0.167em" id="S4.SS2.p3.4.m4.1.1.1.1.1a" xref="S4.SS2.p3.4.m4.1.1.1.1.1.cmml">⁡</mo><mi id="S4.SS2.p3.4.m4.1.1.1.1.1.2" xref="S4.SS2.p3.4.m4.1.1.1.1.1.2.cmml">n</mi></mrow><mo stretchy="false" id="S4.SS2.p3.4.m4.1.1.1.1.3" xref="S4.SS2.p3.4.m4.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.4.m4.1b"><apply id="S4.SS2.p3.4.m4.1.1.cmml" xref="S4.SS2.p3.4.m4.1.1"><times id="S4.SS2.p3.4.m4.1.1.2.cmml" xref="S4.SS2.p3.4.m4.1.1.2"></times><ci id="S4.SS2.p3.4.m4.1.1.3.cmml" xref="S4.SS2.p3.4.m4.1.1.3">𝑂</ci><apply id="S4.SS2.p3.4.m4.1.1.1.1.1.cmml" xref="S4.SS2.p3.4.m4.1.1.1.1"><log id="S4.SS2.p3.4.m4.1.1.1.1.1.1.cmml" xref="S4.SS2.p3.4.m4.1.1.1.1.1.1"></log><ci id="S4.SS2.p3.4.m4.1.1.1.1.1.2.cmml" xref="S4.SS2.p3.4.m4.1.1.1.1.1.2">𝑛</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.4.m4.1c">O(\log n)</annotation></semantics></math> <cite class="ltx_cite ltx_citemacro_citep">(Barzdin, <a href="#bib.bib4" title="" class="ltx_ref">1993</a>; Pinsker, <a href="#bib.bib32" title="" class="ltx_ref">1973</a>)</cite>, while connected supercritical Erdős–Rényi (both <math id="S4.SS2.p3.5.m5.2" class="ltx_Math" alttext="G(n,m)" display="inline"><semantics id="S4.SS2.p3.5.m5.2a"><mrow id="S4.SS2.p3.5.m5.2.3" xref="S4.SS2.p3.5.m5.2.3.cmml"><mi id="S4.SS2.p3.5.m5.2.3.2" xref="S4.SS2.p3.5.m5.2.3.2.cmml">G</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p3.5.m5.2.3.1" xref="S4.SS2.p3.5.m5.2.3.1.cmml">​</mo><mrow id="S4.SS2.p3.5.m5.2.3.3.2" xref="S4.SS2.p3.5.m5.2.3.3.1.cmml"><mo stretchy="false" id="S4.SS2.p3.5.m5.2.3.3.2.1" xref="S4.SS2.p3.5.m5.2.3.3.1.cmml">(</mo><mi id="S4.SS2.p3.5.m5.1.1" xref="S4.SS2.p3.5.m5.1.1.cmml">n</mi><mo id="S4.SS2.p3.5.m5.2.3.3.2.2" xref="S4.SS2.p3.5.m5.2.3.3.1.cmml">,</mo><mi id="S4.SS2.p3.5.m5.2.2" xref="S4.SS2.p3.5.m5.2.2.cmml">m</mi><mo stretchy="false" id="S4.SS2.p3.5.m5.2.3.3.2.3" xref="S4.SS2.p3.5.m5.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.5.m5.2b"><apply id="S4.SS2.p3.5.m5.2.3.cmml" xref="S4.SS2.p3.5.m5.2.3"><times id="S4.SS2.p3.5.m5.2.3.1.cmml" xref="S4.SS2.p3.5.m5.2.3.1"></times><ci id="S4.SS2.p3.5.m5.2.3.2.cmml" xref="S4.SS2.p3.5.m5.2.3.2">𝐺</ci><interval closure="open" id="S4.SS2.p3.5.m5.2.3.3.1.cmml" xref="S4.SS2.p3.5.m5.2.3.3.2"><ci id="S4.SS2.p3.5.m5.1.1.cmml" xref="S4.SS2.p3.5.m5.1.1">𝑛</ci><ci id="S4.SS2.p3.5.m5.2.2.cmml" xref="S4.SS2.p3.5.m5.2.2">𝑚</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.5.m5.2c">G(n,m)</annotation></semantics></math> and <math id="S4.SS2.p3.6.m6.2" class="ltx_Math" alttext="G(n,p)" display="inline"><semantics id="S4.SS2.p3.6.m6.2a"><mrow id="S4.SS2.p3.6.m6.2.3" xref="S4.SS2.p3.6.m6.2.3.cmml"><mi id="S4.SS2.p3.6.m6.2.3.2" xref="S4.SS2.p3.6.m6.2.3.2.cmml">G</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p3.6.m6.2.3.1" xref="S4.SS2.p3.6.m6.2.3.1.cmml">​</mo><mrow id="S4.SS2.p3.6.m6.2.3.3.2" xref="S4.SS2.p3.6.m6.2.3.3.1.cmml"><mo stretchy="false" id="S4.SS2.p3.6.m6.2.3.3.2.1" xref="S4.SS2.p3.6.m6.2.3.3.1.cmml">(</mo><mi id="S4.SS2.p3.6.m6.1.1" xref="S4.SS2.p3.6.m6.1.1.cmml">n</mi><mo id="S4.SS2.p3.6.m6.2.3.3.2.2" xref="S4.SS2.p3.6.m6.2.3.3.1.cmml">,</mo><mi id="S4.SS2.p3.6.m6.2.2" xref="S4.SS2.p3.6.m6.2.2.cmml">p</mi><mo stretchy="false" id="S4.SS2.p3.6.m6.2.3.3.2.3" xref="S4.SS2.p3.6.m6.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.6.m6.2b"><apply id="S4.SS2.p3.6.m6.2.3.cmml" xref="S4.SS2.p3.6.m6.2.3"><times id="S4.SS2.p3.6.m6.2.3.1.cmml" xref="S4.SS2.p3.6.m6.2.3.1"></times><ci id="S4.SS2.p3.6.m6.2.3.2.cmml" xref="S4.SS2.p3.6.m6.2.3.2">𝐺</ci><interval closure="open" id="S4.SS2.p3.6.m6.2.3.3.1.cmml" xref="S4.SS2.p3.6.m6.2.3.3.2"><ci id="S4.SS2.p3.6.m6.1.1.cmml" xref="S4.SS2.p3.6.m6.1.1">𝑛</ci><ci id="S4.SS2.p3.6.m6.2.2.cmml" xref="S4.SS2.p3.6.m6.2.2">𝑝</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.6.m6.2c">G(n,p)</annotation></semantics></math>) graphs (with average degree larger than 1) have lazy random walk mixing times of <math id="S4.SS2.p3.7.m7.1" class="ltx_Math" alttext="O(\log^{2}n)" display="inline"><semantics id="S4.SS2.p3.7.m7.1a"><mrow id="S4.SS2.p3.7.m7.1.1" xref="S4.SS2.p3.7.m7.1.1.cmml"><mi id="S4.SS2.p3.7.m7.1.1.3" xref="S4.SS2.p3.7.m7.1.1.3.cmml">O</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p3.7.m7.1.1.2" xref="S4.SS2.p3.7.m7.1.1.2.cmml">​</mo><mrow id="S4.SS2.p3.7.m7.1.1.1.1" xref="S4.SS2.p3.7.m7.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.SS2.p3.7.m7.1.1.1.1.2" xref="S4.SS2.p3.7.m7.1.1.1.1.1.cmml">(</mo><mrow id="S4.SS2.p3.7.m7.1.1.1.1.1" xref="S4.SS2.p3.7.m7.1.1.1.1.1.cmml"><msup id="S4.SS2.p3.7.m7.1.1.1.1.1.1" xref="S4.SS2.p3.7.m7.1.1.1.1.1.1.cmml"><mi id="S4.SS2.p3.7.m7.1.1.1.1.1.1.2" xref="S4.SS2.p3.7.m7.1.1.1.1.1.1.2.cmml">log</mi><mn id="S4.SS2.p3.7.m7.1.1.1.1.1.1.3" xref="S4.SS2.p3.7.m7.1.1.1.1.1.1.3.cmml">2</mn></msup><mo lspace="0.167em" id="S4.SS2.p3.7.m7.1.1.1.1.1a" xref="S4.SS2.p3.7.m7.1.1.1.1.1.cmml">⁡</mo><mi id="S4.SS2.p3.7.m7.1.1.1.1.1.2" xref="S4.SS2.p3.7.m7.1.1.1.1.1.2.cmml">n</mi></mrow><mo stretchy="false" id="S4.SS2.p3.7.m7.1.1.1.1.3" xref="S4.SS2.p3.7.m7.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.7.m7.1b"><apply id="S4.SS2.p3.7.m7.1.1.cmml" xref="S4.SS2.p3.7.m7.1.1"><times id="S4.SS2.p3.7.m7.1.1.2.cmml" xref="S4.SS2.p3.7.m7.1.1.2"></times><ci id="S4.SS2.p3.7.m7.1.1.3.cmml" xref="S4.SS2.p3.7.m7.1.1.3">𝑂</ci><apply id="S4.SS2.p3.7.m7.1.1.1.1.1.cmml" xref="S4.SS2.p3.7.m7.1.1.1.1"><apply id="S4.SS2.p3.7.m7.1.1.1.1.1.1.cmml" xref="S4.SS2.p3.7.m7.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.SS2.p3.7.m7.1.1.1.1.1.1.1.cmml" xref="S4.SS2.p3.7.m7.1.1.1.1.1.1">superscript</csymbol><log id="S4.SS2.p3.7.m7.1.1.1.1.1.1.2.cmml" xref="S4.SS2.p3.7.m7.1.1.1.1.1.1.2"></log><cn type="integer" id="S4.SS2.p3.7.m7.1.1.1.1.1.1.3.cmml" xref="S4.SS2.p3.7.m7.1.1.1.1.1.1.3">2</cn></apply><ci id="S4.SS2.p3.7.m7.1.1.1.1.1.2.cmml" xref="S4.SS2.p3.7.m7.1.1.1.1.1.2">𝑛</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.7.m7.1c">O(\log^{2}n)</annotation></semantics></math> <cite class="ltx_cite ltx_citemacro_citep">(Fountoulakis &amp; Reed, <a href="#bib.bib10" title="" class="ltx_ref">2008</a>; Benjamini et al., <a href="#bib.bib6" title="" class="ltx_ref">2014</a>)</cite>.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Scalability and the role of exogenous and endogenous decentralised federated learning parameters</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">As shown before in <a href="#S4.F1" title="In 4 Uncoordinated artificial neural network initialisation ‣ Initialisation and Topology Effects in Decentralised Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Figure</span> <span class="ltx_text ltx_ref_tag">1</span></a>, the choice of initialisation strategy significantly affects the behaviour of the system when varying the environment parameter such as the number of nodes. In this section, we will briefly discuss the effect of network topology on the learning trajectory of the system, then systematically analyse the role of different environmental parameters such as the system size (number of nodes), the communication network density, the training sample size and the frequency of communication between nodes in the trajectory of the decentralised federated learning, when using the initialisation method proposed in <a href="#S4" title="4 Uncoordinated artificial neural network initialisation ‣ Initialisation and Topology Effects in Decentralised Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">4</span></a>. As most of these quantities are involved in some form of cost–benefit trade-off, understanding the changes in behaviour due to each one can allow a better grasp of the system behaviour at larger scales.</p>
</div>
<div id="S5.p2" class="ltx_para">
<p id="S5.p2.1" class="ltx_p">For the rest of this section, however, we limited the analysis to a single topology, random <math id="S5.p2.1.m1.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S5.p2.1.m1.1a"><mi id="S5.p2.1.m1.1.1" xref="S5.p2.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S5.p2.1.m1.1b"><ci id="S5.p2.1.m1.1.1.cmml" xref="S5.p2.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.p2.1.m1.1c">k</annotation></semantics></math>-regular networks, to focus on a more in-depth analysis of the role of environmental parameters other than the network topology, such as the system size, frequency of communication, and network density.</p>
</div>
<div id="S5.p3" class="ltx_para">
<p id="S5.p3.2" class="ltx_p">For the purposes of this section, we make the simplifying assumption that the training process is heavily bound by the processing time on the nodes, meaning that each node can optimise their local model only through a certain constant number of mini-batches per unit of time and that the communication time is negligible compared to the training time. In some cases, we introduce “wall-clock equivalent” values, indicating the computation time spent by an individual node up to communication round <math id="S5.p3.1.m1.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S5.p3.1.m1.1a"><mi id="S5.p3.1.m1.1.1" xref="S5.p3.1.m1.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S5.p3.1.m1.1b"><ci id="S5.p3.1.m1.1.1.cmml" xref="S5.p3.1.m1.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.p3.1.m1.1c">t</annotation></semantics></math>, multiplied by the number of training mini-batches of training between two rounds of communication. This “wall-clock equivalent” can be seen as a linear scaling of the communication rounds <math id="S5.p3.2.m2.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S5.p3.2.m2.1a"><mi id="S5.p3.2.m2.1.1" xref="S5.p3.2.m2.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S5.p3.2.m2.1b"><ci id="S5.p3.2.m2.1.1.cmml" xref="S5.p3.2.m2.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.p3.2.m2.1c">t</annotation></semantics></math>.</p>
</div>
<figure id="S5.F6" class="ltx_figure"><img src="/html/2403.15855/assets/x6.png" id="S5.F6.g1" class="ltx_graphics ltx_centering ltx_img_square" width="415" height="376" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>Trajectory of mean test cross-entropy loss over communication rounds for (a) connected random <math id="S5.F6.5.m1.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S5.F6.5.m1.1b"><mi id="S5.F6.5.m1.1.1" xref="S5.F6.5.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S5.F6.5.m1.1c"><ci id="S5.F6.5.m1.1.1.cmml" xref="S5.F6.5.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.F6.5.m1.1d">k</annotation></semantics></math>-regular networks with <math id="S5.F6.6.m2.1" class="ltx_Math" alttext="n=64" display="inline"><semantics id="S5.F6.6.m2.1b"><mrow id="S5.F6.6.m2.1.1" xref="S5.F6.6.m2.1.1.cmml"><mi id="S5.F6.6.m2.1.1.2" xref="S5.F6.6.m2.1.1.2.cmml">n</mi><mo id="S5.F6.6.m2.1.1.1" xref="S5.F6.6.m2.1.1.1.cmml">=</mo><mn id="S5.F6.6.m2.1.1.3" xref="S5.F6.6.m2.1.1.3.cmml">64</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.F6.6.m2.1c"><apply id="S5.F6.6.m2.1.1.cmml" xref="S5.F6.6.m2.1.1"><eq id="S5.F6.6.m2.1.1.1.cmml" xref="S5.F6.6.m2.1.1.1"></eq><ci id="S5.F6.6.m2.1.1.2.cmml" xref="S5.F6.6.m2.1.1.2">𝑛</ci><cn type="integer" id="S5.F6.6.m2.1.1.3.cmml" xref="S5.F6.6.m2.1.1.3">64</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.F6.6.m2.1d">n=64</annotation></semantics></math> nodes and different values for degree <math id="S5.F6.7.m3.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S5.F6.7.m3.1b"><mi id="S5.F6.7.m3.1.1" xref="S5.F6.7.m3.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S5.F6.7.m3.1c"><ci id="S5.F6.7.m3.1.1.cmml" xref="S5.F6.7.m3.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.F6.7.m3.1d">k</annotation></semantics></math>, with 80 balanced training samples per node, (b) 32-regular random network with different number of total labelled training samples, balanced across classes, assigned to each item, (c) with different number of nodes and (d) with different number of local epochs between communications. In all panels, the horizontal dashed lines correspond to the best test loss of a central system with the same amount of the total number of training samples as the entire decentralised federated learning system simulated. Error bars represent 95% confidence intervals. The horizontal axes in (b,d) are scaled to show the “wall-clock equivalent”, a value linearly comparable to the total computation cost of a single node until round <math id="S5.F6.8.m4.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S5.F6.8.m4.1b"><mi id="S5.F6.8.m4.1.1" xref="S5.F6.8.m4.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S5.F6.8.m4.1c"><ci id="S5.F6.8.m4.1.1.cmml" xref="S5.F6.8.m4.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.F6.8.m4.1d">t</annotation></semantics></math>.
</figcaption>
</figure>
<section id="S5.SS0.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Network density.</h4>

<div id="S5.SS0.SSS0.Px1.p1" class="ltx_para">
<p id="S5.SS0.SSS0.Px1.p1.1" class="ltx_p">The number of links in the communication network directly increases the communication burden on the nodes. Our results (<a href="#S5.F6" title="In 5 Scalability and the role of exogenous and endogenous decentralised federated learning parameters ‣ Initialisation and Topology Effects in Decentralised Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Figure</span> <span class="ltx_text ltx_ref_tag">6</span></a>(a) show that while a very small value for the average degree affects the rapidity of the training convergence disproportionately, as long as the average degree is significantly larger than the critical threshold for connectivity, i.e., for random network models with average excess degree <math id="S5.SS0.SSS0.Px1.p1.1.m1.2" class="ltx_Math" alttext="\langle q(k)\rangle\gg 1" display="inline"><semantics id="S5.SS0.SSS0.Px1.p1.1.m1.2a"><mrow id="S5.SS0.SSS0.Px1.p1.1.m1.2.2" xref="S5.SS0.SSS0.Px1.p1.1.m1.2.2.cmml"><mrow id="S5.SS0.SSS0.Px1.p1.1.m1.2.2.1.1" xref="S5.SS0.SSS0.Px1.p1.1.m1.2.2.1.2.cmml"><mo stretchy="false" id="S5.SS0.SSS0.Px1.p1.1.m1.2.2.1.1.2" xref="S5.SS0.SSS0.Px1.p1.1.m1.2.2.1.2.1.cmml">⟨</mo><mrow id="S5.SS0.SSS0.Px1.p1.1.m1.2.2.1.1.1" xref="S5.SS0.SSS0.Px1.p1.1.m1.2.2.1.1.1.cmml"><mi id="S5.SS0.SSS0.Px1.p1.1.m1.2.2.1.1.1.2" xref="S5.SS0.SSS0.Px1.p1.1.m1.2.2.1.1.1.2.cmml">q</mi><mo lspace="0em" rspace="0em" id="S5.SS0.SSS0.Px1.p1.1.m1.2.2.1.1.1.1" xref="S5.SS0.SSS0.Px1.p1.1.m1.2.2.1.1.1.1.cmml">​</mo><mrow id="S5.SS0.SSS0.Px1.p1.1.m1.2.2.1.1.1.3.2" xref="S5.SS0.SSS0.Px1.p1.1.m1.2.2.1.1.1.cmml"><mo stretchy="false" id="S5.SS0.SSS0.Px1.p1.1.m1.2.2.1.1.1.3.2.1" xref="S5.SS0.SSS0.Px1.p1.1.m1.2.2.1.1.1.cmml">(</mo><mi id="S5.SS0.SSS0.Px1.p1.1.m1.1.1" xref="S5.SS0.SSS0.Px1.p1.1.m1.1.1.cmml">k</mi><mo stretchy="false" id="S5.SS0.SSS0.Px1.p1.1.m1.2.2.1.1.1.3.2.2" xref="S5.SS0.SSS0.Px1.p1.1.m1.2.2.1.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S5.SS0.SSS0.Px1.p1.1.m1.2.2.1.1.3" xref="S5.SS0.SSS0.Px1.p1.1.m1.2.2.1.2.1.cmml">⟩</mo></mrow><mo id="S5.SS0.SSS0.Px1.p1.1.m1.2.2.2" xref="S5.SS0.SSS0.Px1.p1.1.m1.2.2.2.cmml">≫</mo><mn id="S5.SS0.SSS0.Px1.p1.1.m1.2.2.3" xref="S5.SS0.SSS0.Px1.p1.1.m1.2.2.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS0.SSS0.Px1.p1.1.m1.2b"><apply id="S5.SS0.SSS0.Px1.p1.1.m1.2.2.cmml" xref="S5.SS0.SSS0.Px1.p1.1.m1.2.2"><csymbol cd="latexml" id="S5.SS0.SSS0.Px1.p1.1.m1.2.2.2.cmml" xref="S5.SS0.SSS0.Px1.p1.1.m1.2.2.2">much-greater-than</csymbol><apply id="S5.SS0.SSS0.Px1.p1.1.m1.2.2.1.2.cmml" xref="S5.SS0.SSS0.Px1.p1.1.m1.2.2.1.1"><csymbol cd="latexml" id="S5.SS0.SSS0.Px1.p1.1.m1.2.2.1.2.1.cmml" xref="S5.SS0.SSS0.Px1.p1.1.m1.2.2.1.1.2">delimited-⟨⟩</csymbol><apply id="S5.SS0.SSS0.Px1.p1.1.m1.2.2.1.1.1.cmml" xref="S5.SS0.SSS0.Px1.p1.1.m1.2.2.1.1.1"><times id="S5.SS0.SSS0.Px1.p1.1.m1.2.2.1.1.1.1.cmml" xref="S5.SS0.SSS0.Px1.p1.1.m1.2.2.1.1.1.1"></times><ci id="S5.SS0.SSS0.Px1.p1.1.m1.2.2.1.1.1.2.cmml" xref="S5.SS0.SSS0.Px1.p1.1.m1.2.2.1.1.1.2">𝑞</ci><ci id="S5.SS0.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S5.SS0.SSS0.Px1.p1.1.m1.1.1">𝑘</ci></apply></apply><cn type="integer" id="S5.SS0.SSS0.Px1.p1.1.m1.2.2.3.cmml" xref="S5.SS0.SSS0.Px1.p1.1.m1.2.2.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS0.SSS0.Px1.p1.1.m1.2c">\langle q(k)\rangle\gg 1</annotation></semantics></math>, the trajectory will be quite consistent across different network densities. Note that, although in <a href="#S4.SS2" title="4.2 Initial stabilisation time ‣ 4 Uncoordinated artificial neural network initialisation ‣ Initialisation and Topology Effects in Decentralised Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">4.2</span></a> we were mostly concerned with the scaling of the initial mixing time with the number of nodes, in many cases this would also benefit from a higher average degree. Also note that average degrees close to the critical threshold might not prove practical or desirable for the communication network in the first place, as the network close to the critical threshold is highly susceptible to fragmentation with the cutting off of even very few links.</p>
</div>
</section>
<section id="S5.SS0.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Training samples per node.</h4>

<div id="S5.SS0.SSS0.Px2.p1" class="ltx_para">
<p id="S5.SS0.SSS0.Px2.p1.1" class="ltx_p">Assuming that each device is capable of performing training on a constant rate of mini-batches per unit of time, more training samples per node increase the total amount of training data, while also linearly increasing the training time for every epoch. Our results (<a href="#S5.F6" title="In 5 Scalability and the role of exogenous and endogenous decentralised federated learning parameters ‣ Initialisation and Topology Effects in Decentralised Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Figure</span> <span class="ltx_text ltx_ref_tag">6</span></a>(b)) show that (1) the test loss approaches that of a centralised system with the same number of total training samples, and (2) that the trajectory of test loss with effective wall-clock time remains consistent.</p>
</div>
</section>
<section id="S5.SS0.SSS0.Px3" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">System size and total computation cost.</h4>

<div id="S5.SS0.SSS0.Px3.p1" class="ltx_para">
<p id="S5.SS0.SSS0.Px3.p1.1" class="ltx_p">The number of nodes in the network affects the training process in multiple ways. If a larger system size is synonymous with a proportionate increase in the total number of training samples available to the system as a whole, it is interesting to see if the system is capable of utilising those in the same way as an increase in the number of items per node would. Our results (<a href="#S5.F6" title="In 5 Scalability and the role of exogenous and endogenous decentralised federated learning parameters ‣ Initialisation and Topology Effects in Decentralised Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Figure</span> <span class="ltx_text ltx_ref_tag">6</span></a>(c)) show that if the increase in size coincides with an increase in the total number of items, the system is able to effectively utilise these, always approaching the test loss limit of a centralised system with the same total data.</p>
</div>
<div id="S5.SS0.SSS0.Px3.p2" class="ltx_para">
<p id="S5.SS0.SSS0.Px3.p2.1" class="ltx_p">Another aspect is that an increase in the number of nodes would mean an increase in the total computation cost, so it would be interesting to analyse if this increase (without a corresponding increase in the total amount of data) would result in any improvements in the learning trajectory. In short, our results in <a href="#S5.F7" title="In System size and total computation cost. ‣ 5 Scalability and the role of exogenous and endogenous decentralised federated learning parameters ‣ Initialisation and Topology Effects in Decentralised Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Figure</span> <span class="ltx_text ltx_ref_tag">7</span></a> show that if the same amount of data is spread across more nodes, each node will have to train on roughly the same number of minibatches to arrive at a similar test loss, and that this result is even consistent with the learning trajectory of the centralised 1 node scenario.</p>
</div>
<figure id="S5.F7" class="ltx_figure"><img src="/html/2403.15855/assets/x7.png" id="S5.F7.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="424" height="204" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7: </span>(a) Trajectory of mean test cross-entropy loss over wall-clock time equivalent over 32-regular random graphs and for an isolated node while keeping the total number of training samples across the whole system constant. Each node was assigned training samples balanced across 10 classes, with a total of 40 960 training samples divided equally across the nodes. Error bars represent 95% confidence intervals. The horizontal dashed line corresponds to the best test loss of a central system with the same total amount of training samples as the entire decentralised federated learning system simulated. The sloped dashed line shows the power-law trajectory of loss with equivalent to wall-clock time consistent with results from <cite class="ltx_cite ltx_citemacro_citet">Henighan et al. (<a href="#bib.bib16" title="" class="ltx_ref">2020</a>)</cite>. (b) “Slowdown” as a result of splitting the same total amount of training samples across more nodes. Values are calculated as <math id="S5.F7.5.m1.2" class="ltx_Math" alttext="\tau_{1}(0.11)/\tau_{n}(0.11)" display="inline"><semantics id="S5.F7.5.m1.2b"><mrow id="S5.F7.5.m1.2.3" xref="S5.F7.5.m1.2.3.cmml"><mrow id="S5.F7.5.m1.2.3.2" xref="S5.F7.5.m1.2.3.2.cmml"><mrow id="S5.F7.5.m1.2.3.2.2" xref="S5.F7.5.m1.2.3.2.2.cmml"><msub id="S5.F7.5.m1.2.3.2.2.2" xref="S5.F7.5.m1.2.3.2.2.2.cmml"><mi id="S5.F7.5.m1.2.3.2.2.2.2" xref="S5.F7.5.m1.2.3.2.2.2.2.cmml">τ</mi><mn id="S5.F7.5.m1.2.3.2.2.2.3" xref="S5.F7.5.m1.2.3.2.2.2.3.cmml">1</mn></msub><mo lspace="0em" rspace="0em" id="S5.F7.5.m1.2.3.2.2.1" xref="S5.F7.5.m1.2.3.2.2.1.cmml">​</mo><mrow id="S5.F7.5.m1.2.3.2.2.3.2" xref="S5.F7.5.m1.2.3.2.2.cmml"><mo stretchy="false" id="S5.F7.5.m1.2.3.2.2.3.2.1" xref="S5.F7.5.m1.2.3.2.2.cmml">(</mo><mn id="S5.F7.5.m1.1.1" xref="S5.F7.5.m1.1.1.cmml">0.11</mn><mo stretchy="false" id="S5.F7.5.m1.2.3.2.2.3.2.2" xref="S5.F7.5.m1.2.3.2.2.cmml">)</mo></mrow></mrow><mo id="S5.F7.5.m1.2.3.2.1" xref="S5.F7.5.m1.2.3.2.1.cmml">/</mo><msub id="S5.F7.5.m1.2.3.2.3" xref="S5.F7.5.m1.2.3.2.3.cmml"><mi id="S5.F7.5.m1.2.3.2.3.2" xref="S5.F7.5.m1.2.3.2.3.2.cmml">τ</mi><mi id="S5.F7.5.m1.2.3.2.3.3" xref="S5.F7.5.m1.2.3.2.3.3.cmml">n</mi></msub></mrow><mo lspace="0em" rspace="0em" id="S5.F7.5.m1.2.3.1" xref="S5.F7.5.m1.2.3.1.cmml">​</mo><mrow id="S5.F7.5.m1.2.3.3.2" xref="S5.F7.5.m1.2.3.cmml"><mo stretchy="false" id="S5.F7.5.m1.2.3.3.2.1" xref="S5.F7.5.m1.2.3.cmml">(</mo><mn id="S5.F7.5.m1.2.2" xref="S5.F7.5.m1.2.2.cmml">0.11</mn><mo stretchy="false" id="S5.F7.5.m1.2.3.3.2.2" xref="S5.F7.5.m1.2.3.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.F7.5.m1.2c"><apply id="S5.F7.5.m1.2.3.cmml" xref="S5.F7.5.m1.2.3"><times id="S5.F7.5.m1.2.3.1.cmml" xref="S5.F7.5.m1.2.3.1"></times><apply id="S5.F7.5.m1.2.3.2.cmml" xref="S5.F7.5.m1.2.3.2"><divide id="S5.F7.5.m1.2.3.2.1.cmml" xref="S5.F7.5.m1.2.3.2.1"></divide><apply id="S5.F7.5.m1.2.3.2.2.cmml" xref="S5.F7.5.m1.2.3.2.2"><times id="S5.F7.5.m1.2.3.2.2.1.cmml" xref="S5.F7.5.m1.2.3.2.2.1"></times><apply id="S5.F7.5.m1.2.3.2.2.2.cmml" xref="S5.F7.5.m1.2.3.2.2.2"><csymbol cd="ambiguous" id="S5.F7.5.m1.2.3.2.2.2.1.cmml" xref="S5.F7.5.m1.2.3.2.2.2">subscript</csymbol><ci id="S5.F7.5.m1.2.3.2.2.2.2.cmml" xref="S5.F7.5.m1.2.3.2.2.2.2">𝜏</ci><cn type="integer" id="S5.F7.5.m1.2.3.2.2.2.3.cmml" xref="S5.F7.5.m1.2.3.2.2.2.3">1</cn></apply><cn type="float" id="S5.F7.5.m1.1.1.cmml" xref="S5.F7.5.m1.1.1">0.11</cn></apply><apply id="S5.F7.5.m1.2.3.2.3.cmml" xref="S5.F7.5.m1.2.3.2.3"><csymbol cd="ambiguous" id="S5.F7.5.m1.2.3.2.3.1.cmml" xref="S5.F7.5.m1.2.3.2.3">subscript</csymbol><ci id="S5.F7.5.m1.2.3.2.3.2.cmml" xref="S5.F7.5.m1.2.3.2.3.2">𝜏</ci><ci id="S5.F7.5.m1.2.3.2.3.3.cmml" xref="S5.F7.5.m1.2.3.2.3.3">𝑛</ci></apply></apply><cn type="float" id="S5.F7.5.m1.2.2.cmml" xref="S5.F7.5.m1.2.2">0.11</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.F7.5.m1.2d">\tau_{1}(0.11)/\tau_{n}(0.11)</annotation></semantics></math> where <math id="S5.F7.6.m2.1" class="ltx_Math" alttext="\tau_{n}(l)" display="inline"><semantics id="S5.F7.6.m2.1b"><mrow id="S5.F7.6.m2.1.2" xref="S5.F7.6.m2.1.2.cmml"><msub id="S5.F7.6.m2.1.2.2" xref="S5.F7.6.m2.1.2.2.cmml"><mi id="S5.F7.6.m2.1.2.2.2" xref="S5.F7.6.m2.1.2.2.2.cmml">τ</mi><mi id="S5.F7.6.m2.1.2.2.3" xref="S5.F7.6.m2.1.2.2.3.cmml">n</mi></msub><mo lspace="0em" rspace="0em" id="S5.F7.6.m2.1.2.1" xref="S5.F7.6.m2.1.2.1.cmml">​</mo><mrow id="S5.F7.6.m2.1.2.3.2" xref="S5.F7.6.m2.1.2.cmml"><mo stretchy="false" id="S5.F7.6.m2.1.2.3.2.1" xref="S5.F7.6.m2.1.2.cmml">(</mo><mi id="S5.F7.6.m2.1.1" xref="S5.F7.6.m2.1.1.cmml">l</mi><mo stretchy="false" id="S5.F7.6.m2.1.2.3.2.2" xref="S5.F7.6.m2.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.F7.6.m2.1c"><apply id="S5.F7.6.m2.1.2.cmml" xref="S5.F7.6.m2.1.2"><times id="S5.F7.6.m2.1.2.1.cmml" xref="S5.F7.6.m2.1.2.1"></times><apply id="S5.F7.6.m2.1.2.2.cmml" xref="S5.F7.6.m2.1.2.2"><csymbol cd="ambiguous" id="S5.F7.6.m2.1.2.2.1.cmml" xref="S5.F7.6.m2.1.2.2">subscript</csymbol><ci id="S5.F7.6.m2.1.2.2.2.cmml" xref="S5.F7.6.m2.1.2.2.2">𝜏</ci><ci id="S5.F7.6.m2.1.2.2.3.cmml" xref="S5.F7.6.m2.1.2.2.3">𝑛</ci></apply><ci id="S5.F7.6.m2.1.1.cmml" xref="S5.F7.6.m2.1.1">𝑙</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.F7.6.m2.1d">\tau_{n}(l)</annotation></semantics></math> is the wall-clock time equivalent (values of horizontal axis from panel (a)) required for a system with <math id="S5.F7.7.m3.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S5.F7.7.m3.1b"><mi id="S5.F7.7.m3.1.1" xref="S5.F7.7.m3.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S5.F7.7.m3.1c"><ci id="S5.F7.7.m3.1.1.cmml" xref="S5.F7.7.m3.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.F7.7.m3.1d">n</annotation></semantics></math> nodes to reach cross-entropy loss value <math id="S5.F7.8.m4.1" class="ltx_Math" alttext="l" display="inline"><semantics id="S5.F7.8.m4.1b"><mi id="S5.F7.8.m4.1.1" xref="S5.F7.8.m4.1.1.cmml">l</mi><annotation-xml encoding="MathML-Content" id="S5.F7.8.m4.1c"><ci id="S5.F7.8.m4.1.1.cmml" xref="S5.F7.8.m4.1.1">𝑙</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.F7.8.m4.1d">l</annotation></semantics></math>.</figcaption>
</figure>
</section>
<section id="S5.SS0.SSS0.Px4" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Communication frequency.</h4>

<div id="S5.SS0.SSS0.Px4.p1" class="ltx_para">
<p id="S5.SS0.SSS0.Px4.p1.1" class="ltx_p">Finally, we consider the role of frequency of communication in the trajectory of loss, manifested as the number of local training epochs between communications. It has been shown in the context of decentralised parallel stochastic gradient descent that a higher frequency of communications increases the efficacy of the training process, as it prevents a larger drift <cite class="ltx_cite ltx_citemacro_citep">(Lian et al., <a href="#bib.bib24" title="" class="ltx_ref">2017</a>)</cite>. While a similar phenomenon in the context of an uncoordinated decentralised federated learning seems plausible, showing this relationship empirically on a system of reasonable size was fraught with difficulties due to the issues discussed in <a href="#S4.F1" title="In 4 Uncoordinated artificial neural network initialisation ‣ Initialisation and Topology Effects in Decentralised Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Figure</span> <span class="ltx_text ltx_ref_tag">1</span></a>. Utilising the proposed initialisation method enables this and allows us to confirm (<a href="#S5.F6" title="In 5 Scalability and the role of exogenous and endogenous decentralised federated learning parameters ‣ Initialisation and Topology Effects in Decentralised Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Figure</span> <span class="ltx_text ltx_ref_tag">6</span></a>(d)) that while more frequent communication increases the communication burden on the entire network, more frequent communication translates to both a lower final test loss as well as faster convergence.</p>
</div>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusion</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">Here we introduced a fully uncoordinated, decentralised artificial neural network initialisation method that provides a significantly improved training trajectory on par with coordinated homogeneous initialisation while solely relying on the macroscopic properties of the communication network. We also showed that the initial stages of the uncoordinated decentralised federated learning process are governed by dynamics similar to those of the lazy random walk on graphs. We also discussed preliminary empirical evidence showing that the topology of the communication network might significantly affect the scaling of the training curve, quantified by different exponents for a power-law relationship between test loss and the number of communication rounds for different network models. Furthermore, we also showed empirically that when using the proposed initialisation method, the test loss of the decentralised federated learning system can approach that of a centralised system with the same total number of training samples. We showed the final outcome, in terms of the best test loss achieved, is fairly robust to different values of network density as long as the network is supercritical, and it can benefit from more frequent communication between the nodes.</p>
</div>
<section id="S6.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.1 </span>Limitations and future works</h3>

<div id="S6.SS1.p1" class="ltx_para">
<p id="S6.SS1.p1.1" class="ltx_p">In this work, we have not considered the non-iid labels or unequal allocation of samples, which is frequently studied in other works on this subject, nor did we consider an unequal allocation of computation power among the nodes to focus solely on the role of the initialisation and the network. These can be, and often
In real-world settings, these are often combined or correlated with network properties such as the degree or other centrality measures, which might affect the efficacy of the decentralised federated learning process. Understanding the combination and interactions of these aforementioned properties with network features adds another layer of interdependency and complexity to the problem, which most certainly was not addressable without first studying the simpler case presented here. The prospect of extending this work to these more complex settings is interesting to consider.</p>
</div>
<div id="S6.SS1.p2" class="ltx_para">
<p id="S6.SS1.p2.1" class="ltx_p">The federated learning process presented here also does not support heterogeneous machine learning model architectures between nodes. We expect this to become more and more important with the advances in manufacturing, edge computing and device availability. We also did not consider possible heterogeneities in node-to-node communication patterns, such as burstiness or diurnal pattern, which has been shown to affect the rapidity of other network dynamics like spreading and percolation processes <cite class="ltx_cite ltx_citemacro_citep">(Karsai et al., <a href="#bib.bib19" title="" class="ltx_ref">2011</a>; Badie-Modiri et al., <a href="#bib.bib2" title="" class="ltx_ref">2022a</a>, <a href="#bib.bib3" title="" class="ltx_ref">b</a>)</cite>.</p>
</div>
<div id="S6.SS1.p3" class="ltx_para">
<p id="S6.SS1.p3.1" class="ltx_p">Our work enables uncoordinated decentralised federated learning that can efficiently train a model using all the data available to all nodes without having the nodes share data directly with a centralised server or with each other. While this enables or streamlines some use cases that were not feasible before, it is important to note that trained machine learning models themselves could be used to extract some information about the training data <cite class="ltx_cite ltx_citemacro_citep">(Carlini et al., <a href="#bib.bib7" title="" class="ltx_ref">2021</a>, <a href="#bib.bib8" title="" class="ltx_ref">2023</a>)</cite>. It is therefore important to not view federated learning as a panacea for data privacy issues but to view direct data sharing as the weakest link in data privacy.</p>
</div>
</section>
</section>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Impact statement</h2>

<div id="Sx1.p1" class="ltx_para">
<p id="Sx1.p1.1" class="ltx_p">This paper presents work whose goal is to advance the field of Machine Learning. There are many potential societal consequences of our work, none of which we feel must be specifically highlighted here.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Albert et al. (2000)</span>
<span class="ltx_bibblock">
Albert, R., Jeong, H., and Barabási, A.-L.

</span>
<span class="ltx_bibblock">Error and attack tolerance of complex networks.

</span>
<span class="ltx_bibblock"><em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">nature</em>, 406(6794):378–382, 2000.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1038/35019019</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://doi.org/10.1038/35019019" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1038/35019019</a>.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Badie-Modiri et al. (2022a)</span>
<span class="ltx_bibblock">
Badie-Modiri, A., Rizi, A. K., Karsai, M., and Kivelä, M.

</span>
<span class="ltx_bibblock">Directed percolation in random temporal network models with heterogeneities.

</span>
<span class="ltx_bibblock"><em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">Physical Review E</em>, 105(5):054313, 2022a.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1103/PhysRevE.105.054313</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://doi.org/10.1103/PhysRevE.105.054313" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1103/PhysRevE.105.054313</a>.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Badie-Modiri et al. (2022b)</span>
<span class="ltx_bibblock">
Badie-Modiri, A., Rizi, A. K., Karsai, M., and Kivelä, M.

</span>
<span class="ltx_bibblock">Directed percolation in temporal networks.

</span>
<span class="ltx_bibblock"><em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">Physical Review Research</em>, 4(2):L022047, 2022b.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1103/PhysRevResearch.4.L022047</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://doi.org/10.1103/PhysRevResearch.4.L022047" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1103/PhysRevResearch.4.L022047</a>.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Barzdin (1993)</span>
<span class="ltx_bibblock">
Barzdin, Y. M.

</span>
<span class="ltx_bibblock">On the realization of networks in three-dimensional space.

</span>
<span class="ltx_bibblock"><em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">Selected Works of AN Kolmogorov: Volume III: Information Theory and the Theory of Algorithms</em>, pp.  194–202, 1993.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1007/978-94-017-2973-4˙11</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://doi.org/10.1007/978-94-017-2973-4_11" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1007/978-94-017-2973-4_11</a>.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Beltrán et al. (2023)</span>
<span class="ltx_bibblock">
Beltrán, E. T. M., Pérez, M. Q., Sánchez, P. M. S., Bernal, S. L., Bovet, G., Pérez, M. G., Pérez, G. M., and Celdrán, A. H.

</span>
<span class="ltx_bibblock">Decentralized federated learning: Fundamentals, state of the art, frameworks, trends, and challenges.

</span>
<span class="ltx_bibblock"><em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">IEEE Commun. Surv. Tutorials</em>, 25(4):2983–3013, 2023.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1109/COMST.2023.3315746</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://doi.org/10.1109/COMST.2023.3315746" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/COMST.2023.3315746</a>.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Benjamini et al. (2014)</span>
<span class="ltx_bibblock">
Benjamini, I., Kozma, G., and Wormald, N.

</span>
<span class="ltx_bibblock">The mixing time of the giant component of a random graph.

</span>
<span class="ltx_bibblock"><em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">Random Structures &amp; Algorithms</em>, 45(3):383–407, 2014.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1002/rsa.20539</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://doi.org/10.1002/rsa.20539" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1002/rsa.20539</a>.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Carlini et al. (2021)</span>
<span class="ltx_bibblock">
Carlini, N., Tramer, F., Wallace, E., Jagielski, M., Herbert-Voss, A., Lee, K., Roberts, A., Brown, T., Song, D., Erlingsson, U., et al.

</span>
<span class="ltx_bibblock">Extracting training data from large language models.

</span>
<span class="ltx_bibblock">In <em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">30th USENIX Security Symposium (USENIX Security 21)</em>, pp.  2633–2650, 2021.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.usenix.org/conference/usenixsecurity21/presentation/carlini-extracting" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.usenix.org/conference/usenixsecurity21/presentation/carlini-extracting</a>.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Carlini et al. (2023)</span>
<span class="ltx_bibblock">
Carlini, N., Hayes, J., Nasr, M., Jagielski, M., Sehwag, V., Tramer, F., Balle, B., Ippolito, D., and Wallace, E.

</span>
<span class="ltx_bibblock">Extracting training data from diffusion models.

</span>
<span class="ltx_bibblock">In <em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">32nd USENIX Security Symposium (USENIX Security 23)</em>, pp.  5253–5270, 2023.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.usenix.org/conference/usenixsecurity23/presentation/carlini" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.usenix.org/conference/usenixsecurity23/presentation/carlini</a>.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fortunato &amp; Hric (2016)</span>
<span class="ltx_bibblock">
Fortunato, S. and Hric, D.

</span>
<span class="ltx_bibblock">Community detection in networks: A user guide.

</span>
<span class="ltx_bibblock"><em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">Physics reports</em>, 659:1–44, 2016.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1016/j.physrep.2016.09.002</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://doi.org/10.1016/j.physrep.2016.09.002" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1016/j.physrep.2016.09.002</a>.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fountoulakis &amp; Reed (2008)</span>
<span class="ltx_bibblock">
Fountoulakis, N. and Reed, B. A.

</span>
<span class="ltx_bibblock">The evolution of the mixing rate of a simple random walk on the giant component of a random graph.

</span>
<span class="ltx_bibblock"><em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">Random Structures &amp; Algorithms</em>, 33(1):68–86, 2008.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1002/rsa.20210</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://doi.org/10.1002/rsa.20210" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1002/rsa.20210</a>.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gauvin et al. (2022)</span>
<span class="ltx_bibblock">
Gauvin, L., Génois, M., Karsai, M., Kivelä, M., Takaguchi, T., Valdano, E., and Vestergaard, C. L.

</span>
<span class="ltx_bibblock">Randomized reference models for temporal networks.

</span>
<span class="ltx_bibblock"><em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">SIAM Review</em>, 64(4):763–830, 2022.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1137/19M1242252</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://doi.org/10.1137/19M1242252" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1137/19M1242252</a>.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Glorot &amp; Bengio (2010)</span>
<span class="ltx_bibblock">
Glorot, X. and Bengio, Y.

</span>
<span class="ltx_bibblock">Understanding the difficulty of training deep feedforward neural networks.

</span>
<span class="ltx_bibblock">In <em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">Proceedings of the thirteenth international conference on artificial intelligence and statistics</em>, pp.  249–256. JMLR Workshop and Conference Proceedings, 2010.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://proceedings.mlr.press/v9/glorot10a.html" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://proceedings.mlr.press/v9/glorot10a.html</a>.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Goodfellow et al. (2016)</span>
<span class="ltx_bibblock">
Goodfellow, I., Bengio, Y., and Courville, A.

</span>
<span class="ltx_bibblock"><em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">Deep learning</em>.

</span>
<span class="ltx_bibblock">MIT press, 2016.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1038/nature14539</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://doi.org/10.1038/nature14539" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1038/nature14539</a>.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He et al. (2015)</span>
<span class="ltx_bibblock">
He, K., Zhang, X., Ren, S., and Sun, J.

</span>
<span class="ltx_bibblock">Delving deep into rectifiers: Surpassing human-level performance on imagenet classification.

</span>
<span class="ltx_bibblock">In <em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE international conference on computer vision</em>, pp.  1026–1034, 2015.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1109/ICCV.2015.123</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://doi.org/10.1109/ICCV.2015.123" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/ICCV.2015.123</a>.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He et al. (2016)</span>
<span class="ltx_bibblock">
He, K., Zhang, X., Ren, S., and Sun, J.

</span>
<span class="ltx_bibblock">Deep residual learning for image recognition.

</span>
<span class="ltx_bibblock">In <em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE conference on computer vision and pattern recognition</em>, pp.  770–778, 2016.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1109/CVPR.2016.90</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://doi.org/10.1109/CVPR.2016.90" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/CVPR.2016.90</a>.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Henighan et al. (2020)</span>
<span class="ltx_bibblock">
Henighan, T., Kaplan, J., Katz, M., Chen, M., Hesse, C., Jackson, J., Jun, H., Brown, T. B., Dhariwal, P., Gray, S., et al.

</span>
<span class="ltx_bibblock">Scaling laws for autoregressive generative modeling.

</span>
<span class="ltx_bibblock"><em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">arXiv preprint 2010.14701</em>, 2020.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://arxiv.org/abs/2010.14701" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/abs/2010.14701</a>.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jennings (1937)</span>
<span class="ltx_bibblock">
Jennings, H.

</span>
<span class="ltx_bibblock">Structure of leadership-development and sphere of influence.

</span>
<span class="ltx_bibblock"><em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">Sociometry</em>, 1(1/2):99–143, 1937.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">0.2307/2785262</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://doi.org/0.2307/2785262" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/0.2307/2785262</a>.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kairouz et al. (2021)</span>
<span class="ltx_bibblock">
Kairouz, P., McMahan, H. B., Avent, B., Bellet, A., Bennis, M., Bhagoji, A. N., Bonawitz, K., Charles, Z., Cormode, G., Cummings, R., et al.

</span>
<span class="ltx_bibblock">Advances and open problems in federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">Foundations and Trends® in Machine Learning</em>, 14(1–2):1–210, 2021.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1561/2200000083</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://doi.org/10.1561/2200000083" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1561/2200000083</a>.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Karsai et al. (2011)</span>
<span class="ltx_bibblock">
Karsai, M., Kivelä, M., Pan, R. K., Kaski, K., Kertész, J., Barabási, A.-L., and Saramäki, J.

</span>
<span class="ltx_bibblock">Small but slow world: How network topology and burstiness slow down spreading.

</span>
<span class="ltx_bibblock"><em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">Physical Review E</em>, 83(2):025102, 2011.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1103/PhysRevE.83.025102</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://doi.org/10.1103/PhysRevE.83.025102" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1103/PhysRevE.83.025102</a>.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lalitha et al. (2018)</span>
<span class="ltx_bibblock">
Lalitha, A., Shekhar, S., Javidi, T., and Koushanfar, F.

</span>
<span class="ltx_bibblock">Fully decentralized federated learning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">Third workshop on bayesian deep learning (NeurIPS)</em>, volume 2, 2018.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="http://bayesiandeeplearning.org/2018/papers/140.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://bayesiandeeplearning.org/2018/papers/140.pdf</a>.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">LeCun et al. (1998)</span>
<span class="ltx_bibblock">
LeCun, Y., Bottou, L., Bengio, Y., and Haffner, P.

</span>
<span class="ltx_bibblock">Gradient-based learning applied to document recognition.

</span>
<span class="ltx_bibblock"><em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE</em>, 86(11):2278–2324, 1998.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1109/5.726791</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://doi.org/10.1109/5.726791" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/5.726791</a>.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">LeCun et al. (2002)</span>
<span class="ltx_bibblock">
LeCun, Y., Bottou, L., Orr, G. B., and Müller, K.-R.

</span>
<span class="ltx_bibblock">Efficient backprop.

</span>
<span class="ltx_bibblock">In <em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">Neural networks: Tricks of the trade</em>, pp.  9–50. Springer, 2002.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1007/978-3-642-35289-8˙3</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://doi.org/10.1007/978-3-642-35289-8_3" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1007/978-3-642-35289-8_3</a>.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Levin &amp; Peres (2017)</span>
<span class="ltx_bibblock">
Levin, D. A. and Peres, Y.

</span>
<span class="ltx_bibblock"><em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">Markov chains and mixing times</em>, volume 107.

</span>
<span class="ltx_bibblock">American Mathematical Soc., 2017.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lian et al. (2017)</span>
<span class="ltx_bibblock">
Lian, X., Zhang, C., Zhang, H., Hsieh, C.-J., Zhang, W., and Liu, J.

</span>
<span class="ltx_bibblock">Can decentralized algorithms outperform centralized algorithms? a case study for decentralized parallel stochastic gradient descent.

</span>
<span class="ltx_bibblock">In <em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>, volume 30, 2017.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://proceedings.neurips.cc/paper_files/paper/2017/file/f75526659f31040afeb61cb7133e4e6d-Paper.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://proceedings.neurips.cc/paper_files/paper/2017/file/f75526659f31040afeb61cb7133e4e6d-Paper.pdf</a>.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Luce &amp; Perry (1949)</span>
<span class="ltx_bibblock">
Luce, R. D. and Perry, A. D.

</span>
<span class="ltx_bibblock">A method of matrix analysis of group structure.

</span>
<span class="ltx_bibblock"><em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">Psychometrika</em>, 14(2):95–116, 1949.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1007/BF02289146</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://doi.org/10.1007/BF02289146" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1007/BF02289146</a>.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">McMahan et al. (2017)</span>
<span class="ltx_bibblock">
McMahan, B., Moore, E., Ramage, D., Hampson, S., and y Arcas, B. A.

</span>
<span class="ltx_bibblock">Communication-efficient learning of deep networks from decentralized data.

</span>
<span class="ltx_bibblock">In <em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">Artificial intelligence and statistics</em>, pp.  1273–1282. PMLR, 2017.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="http://proceedings.mlr.press/v54/mcmahan17a.html" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://proceedings.mlr.press/v54/mcmahan17a.html</a>.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Newman (2010)</span>
<span class="ltx_bibblock">
Newman, M. E. J.

</span>
<span class="ltx_bibblock"><em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">Networks: An introduction</em>.

</span>
<span class="ltx_bibblock">Oxford UP, 2010.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1093/acprof:oso/9780199206650.001.0001</span>.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nguyen et al. (2022)</span>
<span class="ltx_bibblock">
Nguyen, J., Malik, K., Sanjabi, M., and Rabbat, M.

</span>
<span class="ltx_bibblock">Where to begin? exploring the impact of pre-training and initialization in federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">arXiv preprint 2206.15387</em>, 2022.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://arxiv.org/abs/2206.15387" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/abs/2206.15387</a>.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Orsini et al. (2015)</span>
<span class="ltx_bibblock">
Orsini, C., Dankulov, M. M., Colomer-de Simón, P., Jamakovic, A., Mahadevan, P., Vahdat, A., Bassler, K. E., Toroczkai, Z., Boguná, M., Caldarelli, G., et al.

</span>
<span class="ltx_bibblock">Quantifying randomness in real networks.

</span>
<span class="ltx_bibblock"><em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">Nature communications</em>, 6(1):8627, 2015.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1038/ncomms9627</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://doi.org/10.1038/ncomms9627" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1038/ncomms9627</a>.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Palmieri et al. (2023)</span>
<span class="ltx_bibblock">
Palmieri, L., Valerio, L., Boldrini, C., and Passarella, A.

</span>
<span class="ltx_bibblock">The effect of network topologies on fully decentralized learning: a preliminary investigation.

</span>
<span class="ltx_bibblock">In <em id="bib.bib30.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 1st International Workshop on Networked AI Systems</em>, pp.  1–6, 2023.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1145/3597062.3597280</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://doi.org/10.1145/3597062.3597280" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3597062.3597280</a>.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Peres &amp; Sousi (2015)</span>
<span class="ltx_bibblock">
Peres, Y. and Sousi, P.

</span>
<span class="ltx_bibblock">Mixing times are hitting times of large sets.

</span>
<span class="ltx_bibblock"><em id="bib.bib31.1.1" class="ltx_emph ltx_font_italic">Journal of Theoretical Probability</em>, 28(2):488–519, 2015.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1007/s10959-013-0497-9</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://doi.org/10.1007/s10959-013-0497-9" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1007/s10959-013-0497-9</a>.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pinsker (1973)</span>
<span class="ltx_bibblock">
Pinsker, M. S.

</span>
<span class="ltx_bibblock">On the complexity of a concentrator.

</span>
<span class="ltx_bibblock">In <em id="bib.bib32.1.1" class="ltx_emph ltx_font_italic">7th International Telegraffic Conference</em>, volume 4, pp.  1–318. Citeseer, 1973.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://citeseerx.ist.psu.edu/document?repid=rep1&amp;type=pdf&amp;doi=71c9fd11ff75889aaa903b027af3a06e750e8add" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://citeseerx.ist.psu.edu/document?repid=rep1&amp;type=pdf&amp;doi=71c9fd11ff75889aaa903b027af3a06e750e8add</a>.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Qu et al. (2020)</span>
<span class="ltx_bibblock">
Qu, Y., Pokhrel, S. R., Garg, S., Gao, L., and Xiang, Y.

</span>
<span class="ltx_bibblock">A blockchained federated learning framework for cognitive computing in industry 4.0 networks.

</span>
<span class="ltx_bibblock"><em id="bib.bib33.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Industrial Informatics</em>, 17(4):2964–2973, 2020.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1109/TII.2020.3007817</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://doi.org/10.1109/TII.2020.3007817" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/TII.2020.3007817</a>.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rice (1927)</span>
<span class="ltx_bibblock">
Rice, S. A.

</span>
<span class="ltx_bibblock">The identification of blocs in small political bodies.

</span>
<span class="ltx_bibblock"><em id="bib.bib34.1.1" class="ltx_emph ltx_font_italic">American Political Science Review</em>, 21(3):619–627, 1927.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.2307/1945514</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://doi.org/10.2307/1945514" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.2307/1945514</a>.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rieke et al. (2020)</span>
<span class="ltx_bibblock">
Rieke, N., Hancox, J., Li, W., Milletari, F., Roth, H. R., Albarqouni, S., Bakas, S., Galtier, M. N., Landman, B. A., Maier-Hein, K., et al.

</span>
<span class="ltx_bibblock">The future of digital health with federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib35.1.1" class="ltx_emph ltx_font_italic">NPJ digital medicine</em>, 3(1):119, 2020.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1038/S41746-020-00323-1</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://doi.org/10.1038/S41746-020-00323-1" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1038/S41746-020-00323-1</a>.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Roy et al. (2019)</span>
<span class="ltx_bibblock">
Roy, A. G., Siddiqui, S., Pölsterl, S., Navab, N., and Wachinger, C.

</span>
<span class="ltx_bibblock">Braintorrent: A peer-to-peer environment for decentralized federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib36.1.1" class="ltx_emph ltx_font_italic">arXiv preprint 1905.06731</em>, 2019.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://arxiv.org/abs/1905.06731" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/abs/1905.06731</a>.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Savazzi et al. (2021)</span>
<span class="ltx_bibblock">
Savazzi, S., Nicoli, M., Bennis, M., Kianoush, S., and Barbieri, L.

</span>
<span class="ltx_bibblock">Opportunities of federated learning in connected, cooperative, and automated industrial systems.

</span>
<span class="ltx_bibblock"><em id="bib.bib37.1.1" class="ltx_emph ltx_font_italic">IEEE Communications Magazine</em>, 59(2):16–21, 2021.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1109/MCOM.001.2000200</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://doi.org/10.1109/10.1109/MCOM.001.2000200" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/10.1109/MCOM.001.2000200</a>.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sun et al. (2022)</span>
<span class="ltx_bibblock">
Sun, T., Li, D., and Wang, B.

</span>
<span class="ltx_bibblock">Decentralized federated averaging.

</span>
<span class="ltx_bibblock"><em id="bib.bib38.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Pattern Analysis and Machine Intelligence</em>, 45(4):4289–4301, 2022.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1109/TPAMI.2022.3196503</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://doi.org/10.1109/TPAMI.2022.3196503" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/TPAMI.2022.3196503</a>.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tedeschini et al. (2022)</span>
<span class="ltx_bibblock">
Tedeschini, B. C., Savazzi, S., Stoklasa, R., Barbieri, L., Stathopoulos, I., Nicoli, M., and Serio, L.

</span>
<span class="ltx_bibblock">Decentralized federated learning for healthcare networks: A case study on tumor segmentation.

</span>
<span class="ltx_bibblock"><em id="bib.bib39.1.1" class="ltx_emph ltx_font_italic">IEEE Access</em>, 10:8693–8708, 2022.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1109/ACCESS.2022.3141913</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://doi.org/10.1109/ACCESS.2022.3141913" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/ACCESS.2022.3141913</a>.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Valerio et al. (2023)</span>
<span class="ltx_bibblock">
Valerio, L., Boldrini, C., Passarella, A., Kertész, J., Karsai, M., and Iñiguez, G.

</span>
<span class="ltx_bibblock">Coordination-free decentralised federated learning on complex networks: Overcoming heterogeneity.

</span>
<span class="ltx_bibblock"><em id="bib.bib40.1.1" class="ltx_emph ltx_font_italic">arXiv preprint 2312.04504</em>, 2023.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://arxiv.org/abs/2312.04504" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/abs/2312.04504</a>.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vogels et al. (2022)</span>
<span class="ltx_bibblock">
Vogels, T., Hendrikx, H., and Jaggi, M.

</span>
<span class="ltx_bibblock">Beyond spectral gap: The role of the topology in decentralized learning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib41.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>, volume 35, pp.  15039–15050, 2022.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://proceedings.neurips.cc/paper_files/paper/2022/file/61162d94822d468ee6e92803340f2040-Paper-Conference.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://proceedings.neurips.cc/paper_files/paper/2022/file/61162d94822d468ee6e92803340f2040-Paper-Conference.pdf</a>.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Watts &amp; Strogatz (1998)</span>
<span class="ltx_bibblock">
Watts, D. J. and Strogatz, S. H.

</span>
<span class="ltx_bibblock">Collective dynamics of ‘small-world’ networks.

</span>
<span class="ltx_bibblock"><em id="bib.bib42.1.1" class="ltx_emph ltx_font_italic">nature</em>, 393(6684):440–442, 1998.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1038/30918</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://doi.org/10.1038/30918" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1038/30918</a>.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2403.15854" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2403.15855" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2403.15855">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2403.15855" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2403.15856" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Fri Apr  5 16:46:46 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
