<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2402.07295] Training Heterogeneous Client Models using Knowledge Distillation in Serverless Federated Learning</title><meta property="og:description" content="Federated Learning (FL) is an emerging machine learning paradigm that enables the collaborative training of a shared global model across distributed clients while keeping the data decentralized. Recent works on designi…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Training Heterogeneous Client Models using Knowledge Distillation in Serverless Federated Learning">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Training Heterogeneous Client Models using Knowledge Distillation in Serverless Federated Learning">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2402.07295">

<!--Generated on Tue Mar  5 18:35:27 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content="Federated Learning,  Serverless Computing,  FaaS,  Deep Learning,  Scalability of learning algorithms,  Knowledge Distillation">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line ltx_leqno">
<h1 class="ltx_title ltx_title_document">Training Heterogeneous Client Models using Knowledge Distillation in Serverless Federated Learning</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Mohak Chadha<sup id="id10.8.id1" class="ltx_sup"><span id="id10.8.id1.1" class="ltx_text ltx_font_italic">1</span></sup>, Pulkit Khera<sup id="id11.9.id2" class="ltx_sup"><span id="id11.9.id2.1" class="ltx_text ltx_font_italic">1</span></sup>, Jianfeng Gu<sup id="id12.10.id3" class="ltx_sup"><span id="id12.10.id3.1" class="ltx_text ltx_font_italic">1</span></sup>, Osama Abboud<sup id="id13.11.id4" class="ltx_sup"><span id="id13.11.id4.1" class="ltx_text ltx_font_italic">2</span></sup>, Michael Gerndt<sup id="id14.12.id5" class="ltx_sup"><span id="id14.12.id5.1" class="ltx_text ltx_font_italic">1</span></sup>
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id6.6.1" class="ltx_text ltx_affiliation_institution"><sup id="id6.6.1.1" class="ltx_sup">1</sup>{firstname.lastname}@tum.de, Technische Universität München
<span id="id6.6.1.2" class="ltx_text ltx_affiliation_country">Germany</span></span>
</span>
<span class="ltx_contact ltx_role_affiliation"><span id="id7.7.1" class="ltx_text ltx_affiliation_institution"><sup id="id7.7.1.1" class="ltx_sup">2</sup>{firstname.lastname}@huawei.com, Huawei Technologies
<span id="id7.7.1.2" class="ltx_text ltx_affiliation_country">Germany</span></span>
</span></span></span>
</div>
<div class="ltx_dates">(2024)</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract.</h6>
<p id="id9.2" class="ltx_p">Federated Learning (FL) is an emerging machine learning paradigm that enables the collaborative training of a shared global model across distributed clients while keeping the data decentralized. Recent works on designing systems for efficient FL have shown that utilizing serverless computing technologies, particularly Function-as-a-Service (FaaS) for FL, can enhance resource efficiency, reduce training costs, and alleviate the complex infrastructure management burden on data holders. However, existing serverless FL systems implicitly assume a uniform global model architecture across all participating clients during training. This assumption fails to address fundamental challenges in practical FL due to the resource and statistical data heterogeneity among FL clients. To address these challenges and enable heterogeneous client models in serverless FL, we utilize Knowledge Distillation (KD) in this paper. Towards this, we propose novel optimized serverless workflows for two popular conventional federated KD techniques, i.e., <span id="id9.2.1" class="ltx_text ltx_font_typewriter">FedMD</span> and <span id="id9.2.2" class="ltx_text ltx_font_typewriter">FedDF</span>. We implement these workflows by introducing several extensions to an open-source serverless FL system called <em id="id9.2.3" class="ltx_emph ltx_font_italic">FedLess</em>. Moreover, we comprehensively evaluate the two strategies on multiple datasets across varying levels of client data heterogeneity using heterogeneous client models with respect to accuracy, fine-grained training times, and costs. Results from our experiments demonstrate that serverless <span id="id9.2.4" class="ltx_text ltx_font_typewriter">FedDF</span> is more robust to extreme non-IID data distributions, is faster, and leads to lower costs than serverless <span id="id9.2.5" class="ltx_text ltx_font_typewriter">FedMD</span>. In addition, compared to the original implementation, our optimizations for particular steps in <span id="id9.2.6" class="ltx_text ltx_font_typewriter">FedMD</span> and <span id="id9.2.7" class="ltx_text ltx_font_typewriter">FedDF</span> lead to an average speedup of <math id="id8.1.m1.1" class="ltx_Math" alttext="3.5" display="inline"><semantics id="id8.1.m1.1a"><mn id="id8.1.m1.1.1" xref="id8.1.m1.1.1.cmml">3.5</mn><annotation-xml encoding="MathML-Content" id="id8.1.m1.1b"><cn type="float" id="id8.1.m1.1.1.cmml" xref="id8.1.m1.1.1">3.5</cn></annotation-xml><annotation encoding="application/x-tex" id="id8.1.m1.1c">3.5</annotation></semantics></math>x and <math id="id9.2.m2.1" class="ltx_Math" alttext="1.76" display="inline"><semantics id="id9.2.m2.1a"><mn id="id9.2.m2.1.1" xref="id9.2.m2.1.1.cmml">1.76</mn><annotation-xml encoding="MathML-Content" id="id9.2.m2.1b"><cn type="float" id="id9.2.m2.1.1.cmml" xref="id9.2.m2.1.1">1.76</cn></annotation-xml><annotation encoding="application/x-tex" id="id9.2.m2.1c">1.76</annotation></semantics></math>x across all datasets.</p>
</div>
<div class="ltx_keywords">Federated Learning, Serverless Computing, FaaS, Deep Learning, Scalability of learning algorithms, Knowledge Distillation
</div>
<span id="id1" class="ltx_note ltx_note_frontmatter ltx_role_journalyear"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">journalyear: </span>2024</span></span></span><span id="id2" class="ltx_note ltx_note_frontmatter ltx_role_copyright"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">copyright: </span>acmlicensed</span></span></span><span id="id3" class="ltx_note ltx_note_frontmatter ltx_role_conference"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">conference: </span>The 39th ACM/SIGAPP Symposium on Applied Computing; April 8–12, 2024; Avila, Spain</span></span></span><span id="id4" class="ltx_note ltx_note_frontmatter ltx_role_booktitle"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">booktitle: </span>The 39th ACM/SIGAPP Symposium on Applied Computing (SAC ’24), April 8–12, 2024, Avila, Spain</span></span></span><span id="id5" class="ltx_note ltx_note_frontmatter ltx_role_price"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">price: </span>15.00</span></span></span><span id="id6" class="ltx_note ltx_note_frontmatter ltx_role_doi"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">doi: </span>10.1145/3605098.3636015</span></span></span><span id="id7" class="ltx_note ltx_note_frontmatter ltx_role_isbn"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">isbn: </span>979-8-4007-0243-3/24/04</span></span></span><span id="id8" class="ltx_note ltx_note_frontmatter ltx_role_ccs"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">ccs: </span>Computer systems organization Cloud computing</span></span></span><span id="id9" class="ltx_note ltx_note_frontmatter ltx_role_ccs"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">ccs: </span>Computing methodologies Distributed artificial intelligence</span></span></span>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1. </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Increasing concerns about data privacy and recent legislations such as the Consumer Privacy Bill of Rights in the U.S. <cite class="ltx_cite ltx_citemacro_citep">(Gaff et al<span class="ltx_text">.</span>, <a href="#bib.bib16" title="" class="ltx_ref">2014</a>)</cite> prevent the training of ML models using the traditional centralized learning approach <cite class="ltx_cite ltx_citemacro_citep">(LeCun et al<span class="ltx_text">.</span>, <a href="#bib.bib35" title="" class="ltx_ref">2015</a>)</cite>. With the goal of not exposing raw data as in centralized learning, an emerging distributed training paradigm called Federated Learning (FL) <cite class="ltx_cite ltx_citemacro_citep">(McMahan et al<span class="ltx_text">.</span>, <a href="#bib.bib40" title="" class="ltx_ref">2017</a>)</cite> has gained significant popularity in various application domains, such as banking <cite class="ltx_cite ltx_citemacro_citep">(Ludwig et al<span class="ltx_text">.</span>, <a href="#bib.bib39" title="" class="ltx_ref">2020</a>)</cite> and mobile services <cite class="ltx_cite ltx_citemacro_citep">(Huba et al<span class="ltx_text">.</span>, <a href="#bib.bib24" title="" class="ltx_ref">2022</a>)</cite>.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">FL enables the collaborative training of a shared global ML model across remote devices or <span id="S1.p2.1.1" class="ltx_text ltx_font_typewriter">clients</span> while keeping the training data decentralized. The traditional FL training process <cite class="ltx_cite ltx_citemacro_citep">(McMahan et al<span class="ltx_text">.</span>, <a href="#bib.bib40" title="" class="ltx_ref">2017</a>)</cite> is <span id="S1.p2.1.2" class="ltx_text ltx_font_italic">synchronous</span> and occurs in multiple rounds. A main component called the <span id="S1.p2.1.3" class="ltx_text ltx_font_typewriter">central</span> <span id="S1.p2.1.4" class="ltx_text ltx_font_typewriter">server</span> organizes the training process and decides which clients contribute in a new round. During each round, clients improve the shared global model by optimizing it on their local datasets and sending back only the updated model parameters to the central server. Following this, the local model updates from all participating clients are collected and aggregated to form the updated consensus model. Recent works on designing systems for efficient FL have shown that both components in an FL system, i.e., the <span id="S1.p2.1.5" class="ltx_text ltx_font_typewriter">clients</span> and the <span id="S1.p2.1.6" class="ltx_text ltx_font_typewriter">central</span> <span id="S1.p2.1.7" class="ltx_text ltx_font_typewriter">server</span>, can immensely benefit from an emerging cloud computing paradigm called <span id="S1.p2.1.8" class="ltx_text ltx_font_italic">serverless computing</span> <cite class="ltx_cite ltx_citemacro_citep">(Chadha et al<span class="ltx_text">.</span>, <a href="#bib.bib9" title="" class="ltx_ref">2020</a>; Grafberger et al<span class="ltx_text">.</span>, <a href="#bib.bib18" title="" class="ltx_ref">2021</a>; Elzohairy et al<span class="ltx_text">.</span>, <a href="#bib.bib14" title="" class="ltx_ref">2022</a>; Jayaram et al<span class="ltx_text">.</span>, <a href="#bib.bib26" title="" class="ltx_ref">2022b</a>, <a href="#bib.bib27" title="" class="ltx_ref">c</a>, <a href="#bib.bib25" title="" class="ltx_ref">a</a>; Kotsehub et al<span class="ltx_text">.</span>, <a href="#bib.bib33" title="" class="ltx_ref">2022</a>)</cite>.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">Function-as-a-Service (FaaS) is the computational concept of serverless computing and has gained significant popularity and widespread adoption in various application domains such as machine learning <cite class="ltx_cite ltx_citemacro_citep">(Grafberger et al<span class="ltx_text">.</span>, <a href="#bib.bib18" title="" class="ltx_ref">2021</a>; Elzohairy et al<span class="ltx_text">.</span>, <a href="#bib.bib14" title="" class="ltx_ref">2022</a>; Chadha et al<span class="ltx_text">.</span>, <a href="#bib.bib9" title="" class="ltx_ref">2020</a>; Gu et al<span class="ltx_text">.</span>, <a href="#bib.bib19" title="" class="ltx_ref">2023</a>)</cite>, edge computing <cite class="ltx_cite ltx_citemacro_citep">(Smith et al<span class="ltx_text">.</span>, <a href="#bib.bib45" title="" class="ltx_ref">2022</a>)</cite>, heterogeneous computing <cite class="ltx_cite ltx_citemacro_citep">(Jindal et al<span class="ltx_text">.</span>, <a href="#bib.bib28" title="" class="ltx_ref">2022</a>, <a href="#bib.bib31" title="" class="ltx_ref">2021c</a>, <a href="#bib.bib30" title="" class="ltx_ref">2021b</a>, <a href="#bib.bib29" title="" class="ltx_ref">2021a</a>)</cite>, and scientific computing <cite class="ltx_cite ltx_citemacro_citep">(Chadha et al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2021</a>; Kiener et al<span class="ltx_text">.</span>, <a href="#bib.bib32" title="" class="ltx_ref">2021</a>)</cite>. In FaaS, developers implement fine-grained pieces of code called <span id="S1.p3.1.1" class="ltx_text ltx_font_italic">functions</span> that are packaged independently in containers and uploaded to a FaaS platform. These functions are <span id="S1.p3.1.2" class="ltx_text ltx_font_italic">ephemeral</span>, i.e., short-lived, and <span id="S1.p3.1.3" class="ltx_text ltx_font_italic">event-driven</span>, i.e., these functions only get executed in response to external triggers such as HTTP requests. Moreover, these functions are <span id="S1.p3.1.4" class="ltx_text ltx_font_italic">stateless</span>, i.e., any application state needs to be persisted in external storage. Several open-source and commercial FaaS platforms, such as OpenFaaS <cite class="ltx_cite ltx_citemacro_citep">(OpenFaaS, <a href="#bib.bib44" title="" class="ltx_ref">2019</a>)</cite> and Google Cloud Functions (GCF) <cite class="ltx_cite ltx_citemacro_citep">(Google Cloud, <a href="#bib.bib17" title="" class="ltx_ref">2022</a>)</cite>, are currently available. In serverless FL, clients are independent functions deployed onto a FaaS platform and capable of performing their model updates.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">Most standard stateful FL systems <cite class="ltx_cite ltx_citemacro_citep">(Beutel et al<span class="ltx_text">.</span>, <a href="#bib.bib5" title="" class="ltx_ref">2020</a>; Lai et al<span class="ltx_text">.</span>, <a href="#bib.bib34" title="" class="ltx_ref">2020</a>)</cite> and all current serverless FL systems implicitly assume that all FL clients must have a uniform ML model architecture to train a global consensus model. However, a practical FL system is affected by different fundamental client-level challenges that are difficult to address with this assumption. These include computational heterogeneity and statistical data heterogeneity. FL clients in the wild <cite class="ltx_cite ltx_citemacro_citep">(Huba et al<span class="ltx_text">.</span>, <a href="#bib.bib24" title="" class="ltx_ref">2022</a>)</cite> can vary from small edge devices to high-performant GPU-enabled systems with varying memory, compute, and storage capacities. Therefore, it is not always feasible for each participating client to agree on a single global model architecture. Opting for a simple architecture may restrict the capacity of the collaboratively trained global model, whereas selecting a large and complex model architecture can substantially increase the duration required for FL training <cite class="ltx_cite ltx_citemacro_citep">(Elzohairy et al<span class="ltx_text">.</span>, <a href="#bib.bib14" title="" class="ltx_ref">2022</a>)</cite>. In addition, clients in practical FL systems have <span id="S1.p4.1.1" class="ltx_text ltx_font_italic">unbalanced non-IID</span> data distributions, i.e., the private data samples held by individual clients exhibit variations in their statistical properties, such as feature distributions, class imbalances, or data biases <cite class="ltx_cite ltx_citemacro_citep">(Hsieh et al<span class="ltx_text">.</span>, <a href="#bib.bib21" title="" class="ltx_ref">2020</a>)</cite>. As a result, in extreme non-IID scenarios, the uniform global model may lead to poor generalization performance following the model aggregation process due to high variance among the trained client models. Figure <a href="#S1.F1" title="Figure 1 ‣ 1. Introduction ‣ Training Heterogeneous Client Models using Knowledge Distillation in Serverless Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> shows the impact of non-IID data distribution among FL clients on the accuracy of the trained global model on the CIFAR-10 dataset. Across all model architectures, we observe a <math id="S1.p4.1.m1.1" class="ltx_Math" alttext="27.1" display="inline"><semantics id="S1.p4.1.m1.1a"><mn id="S1.p4.1.m1.1.1" xref="S1.p4.1.m1.1.1.cmml">27.1</mn><annotation-xml encoding="MathML-Content" id="S1.p4.1.m1.1b"><cn type="float" id="S1.p4.1.m1.1.1.cmml" xref="S1.p4.1.m1.1.1">27.1</cn></annotation-xml><annotation encoding="application/x-tex" id="S1.p4.1.m1.1c">27.1</annotation></semantics></math>% average decrease in the accuracy of the trained global model with <span id="S1.p4.1.2" class="ltx_text ltx_font_typewriter">FedAvg</span> <cite class="ltx_cite ltx_citemacro_citep">(McMahan et al<span class="ltx_text">.</span>, <a href="#bib.bib40" title="" class="ltx_ref">2017</a>)</cite>. To this end, each FL client needs to have the flexibility to choose their own model architecture personalized to their private data distribution while simultaneously benefiting from other collaborating clients.</p>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/2402.07295/assets/x1.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="322" height="151" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S1.F1.6.2.1" class="ltx_text" style="font-size:90%;">Figure 1</span>. </span><span id="S1.F1.2.1" class="ltx_text" style="font-size:90%;">Global model accuracy across different model architectures on the CIFAR-10 dataset with <span id="S1.F1.2.1.1" class="ltx_text ltx_font_typewriter">FedAvg</span> <cite class="ltx_cite ltx_citemacro_citep">(McMahan et al<span class="ltx_text">.</span>, <a href="#bib.bib40" title="" class="ltx_ref">2017</a>)</cite> for both IID and non-IID data distributions. The models are trained with <em id="S1.F1.2.1.2" class="ltx_emph ltx_font_italic">FedLess</em> <cite class="ltx_cite ltx_citemacro_citep">(Grafberger et al<span class="ltx_text">.</span>, <a href="#bib.bib18" title="" class="ltx_ref">2021</a>)</cite> for <math id="S1.F1.2.1.m1.1" class="ltx_Math" alttext="100" display="inline"><semantics id="S1.F1.2.1.m1.1b"><mn id="S1.F1.2.1.m1.1.1" xref="S1.F1.2.1.m1.1.1.cmml">100</mn><annotation-xml encoding="MathML-Content" id="S1.F1.2.1.m1.1c"><cn type="integer" id="S1.F1.2.1.m1.1.1.cmml" xref="S1.F1.2.1.m1.1.1">100</cn></annotation-xml><annotation encoding="application/x-tex" id="S1.F1.2.1.m1.1d">100</annotation></semantics></math> clients.</span></figcaption>
</figure>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">To address these challenges in practical FL systems, we utilize Knowledge Distillation (KD) <cite class="ltx_cite ltx_citemacro_citep">(Hinton et al<span class="ltx_text">.</span>, <a href="#bib.bib20" title="" class="ltx_ref">2015</a>)</cite> in this paper. KD is a popular technique used in ML that facilitates the transfer of knowledge from a large and complex model, known as the <span id="S1.p5.1.1" class="ltx_text ltx_font_italic">teacher model</span>, to a smaller and more efficient model, referred to as the <span id="S1.p5.1.2" class="ltx_text ltx_font_italic">student model</span>. KD enables heterogeneous client models in FL since knowledge transfer is achieved by distilling model prediction probabilities or <span id="S1.p5.1.3" class="ltx_text ltx_font_typewriter">logits</span> instead of directly exchanging model parameters between the student and teacher models.
In addition, KD supports a high level of flexibility in the choice of client model architectures in contrast to other approaches like parameter decoupling <cite class="ltx_cite ltx_citemacro_citep">(Arivazhagan et al<span class="ltx_text">.</span>, <a href="#bib.bib4" title="" class="ltx_ref">2019</a>)</cite> that tolerate flexibility in only particular layers of the overall model architecture.</p>
</div>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.1" class="ltx_p">Most KD strategies in FL, such as <span id="S1.p6.1.1" class="ltx_text ltx_font_typewriter">FedMD</span> <cite class="ltx_cite ltx_citemacro_citep">(Li and Wang, <a href="#bib.bib36" title="" class="ltx_ref">2019</a>)</cite> and <span id="S1.p6.1.2" class="ltx_text ltx_font_typewriter">MHAT</span> <cite class="ltx_cite ltx_citemacro_citep">(Hu et al<span class="ltx_text">.</span>, <a href="#bib.bib23" title="" class="ltx_ref">2021</a>)</cite>, typically involve a series of steps, such as private training, prediction on public datasets, and aligning the local client models to the obtained logits. However, the synchronous nature of these algorithms introduces inefficiencies where the central server must wait for all the participating clients to complete a particular step before moving on to the subsequent steps. Due to the statistical and resource heterogeneity in FL, most clients in conventional KD-based FL systems remain idle, leading to resource wastage and unnecessary costs (Figure <a href="#S1.F2" title="Figure 2 ‣ 1. Introduction ‣ Training Heterogeneous Client Models using Knowledge Distillation in Serverless Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>). Moreover, managing complex infrastructure for clients can be overwhelming for all data administrators. The FaaS computing model offers several advantages, such as no infrastructure management, automatic scaling to zero when resources are unused, and an attractive fine-grained <span id="S1.p6.1.3" class="ltx_text ltx_font_italic">pay-per-use</span> billing policy <cite class="ltx_cite ltx_citemacro_citep">(Castro et al<span class="ltx_text">.</span>, <a href="#bib.bib8" title="" class="ltx_ref">2019</a>)</cite>. Adapting and optimizing existing conventional KD-based FL techniques to utilize stateless FaaS technologies in both entities of an FL system can improve resource efficiency, reduce training costs, and address practical challenges in FL systems (Figure <a href="#S1.F2" title="Figure 2 ‣ 1. Introduction ‣ Training Heterogeneous Client Models using Knowledge Distillation in Serverless Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>). To this end, our key contributions are:</p>
</div>
<figure id="S1.F2" class="ltx_figure"><img src="/html/2402.07295/assets/x2.png" id="S1.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="346" height="242" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S1.F2.2.1.1" class="ltx_text" style="font-size:90%;">Figure 2</span>. </span><span id="S1.F2.3.2" class="ltx_text" style="font-size:90%;">Synchronous conventional KD and serverless KD.</span></figcaption>
</figure>
<div id="S1.p7" class="ltx_para">
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">We propose novel optimized serverless workflows for two popular conventional KD-based FL strategies, i.e., <span id="S1.I1.i1.p1.1.1" class="ltx_text ltx_font_typewriter">FedMD</span> and <span id="S1.I1.i1.p1.1.2" class="ltx_text ltx_font_typewriter">FedDF</span>.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">We implement the two workflows by introducing several extensions to an open-source serverless FL system called <em id="S1.I1.i2.p1.1.1" class="ltx_emph ltx_font_italic">FedLess</em> <cite class="ltx_cite ltx_citemacro_citep">(Grafberger et al<span class="ltx_text">.</span>, <a href="#bib.bib18" title="" class="ltx_ref">2021</a>)</cite><span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>Our implementation can be found here: <a target="_blank" href="https://github.com/Serverless-Federated-Learning/FedLess/tree/serverless-knowledge-distillation" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/Serverless-Federated-Learning/FedLess/tree/serverless-knowledge-distillation</a>.</span></span></span>. To the best of our knowledge, this represents the first system in the literature that supports training heterogeneous client models using serverless KD.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p">We comprehensively evaluate the implemented strategies on multiple datasets across varying levels of client data heterogeneity using heterogeneous client model architectures wrt accuracy, fine-grained training times, and costs.
</p>
</div>
</li>
</ul>
</div>
<div id="S1.p8" class="ltx_para">
<p id="S1.p8.1" class="ltx_p">The rest of the paper is structured as follows. §<a href="#S2" title="2. Background ‣ Training Heterogeneous Client Models using Knowledge Distillation in Serverless Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> provides an overview of KD in FL. In §<a href="#S3" title="3. Related Work ‣ Training Heterogeneous Client Models using Knowledge Distillation in Serverless Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, we describe the previous approaches related to our work. §<a href="#S4" title="4. System Design ‣ Training Heterogeneous Client Models using Knowledge Distillation in Serverless Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> describes our extensions to <em id="S1.p8.1.1" class="ltx_emph ltx_font_italic">FedLess</em>. In §<a href="#S5" title="5. Serverless Knowledge Distillation ‣ Training Heterogeneous Client Models using Knowledge Distillation in Serverless Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>, we describe the workflow of the serverless implementations of the two algorithms. §<a href="#S6" title="6. Experimental Setup ‣ Training Heterogeneous Client Models using Knowledge Distillation in Serverless Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> describes our experimental setup, while in §<a href="#S7" title="7. Experimental Results ‣ Training Heterogeneous Client Models using Knowledge Distillation in Serverless Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> our experimental results are presented. Finally, §<a href="#S8" title="8. Conclusion and Future Work ‣ Training Heterogeneous Client Models using Knowledge Distillation in Serverless Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a> concludes the paper and presents an outlook.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2. </span>Background</h2>

<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1. </span>Knowledge Distillation in FL</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.4" class="ltx_p">When applied to FL, KD offers several advantages. These include model compression, heterogeneous and personalized client models, reduced communication overhead, and increased client privacy <cite class="ltx_cite ltx_citemacro_citep">(Mora et al<span class="ltx_text">.</span>, <a href="#bib.bib41" title="" class="ltx_ref">2022</a>)</cite>. Unlike traditional FL approaches <cite class="ltx_cite ltx_citemacro_citep">(McMahan et al<span class="ltx_text">.</span>, <a href="#bib.bib40" title="" class="ltx_ref">2017</a>)</cite> that require exchanging the entire model parameters, most KD-based techniques typically only involve the transmission of class scores. This reduces the communication overhead and minimizes the data transferred between clients and the server during model aggregation. In addition, this prevents <span id="S2.SS1.p1.4.1" class="ltx_text ltx_font_italic">model inferencing attacks</span> <cite class="ltx_cite ltx_citemacro_citep">(Enthoven and Al-Ars, <a href="#bib.bib15" title="" class="ltx_ref">2021</a>)</cite> in FL. Towards this, several strategies that leverage KD in FL have been proposed. These strategies can be classified into four categories:  <svg id="S2.SS1.p1.1.pic1" class="ltx_picture" height="14.77" overflow="visible" version="1.1" width="14.77"><g transform="translate(0,14.77) matrix(1 0 0 -1 0 0) translate(7.38,0) translate(0,7.38)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill="#FFFFFF"><path d="M 7.11 0 C 7.11 3.92 3.92 7.11 0 7.11 C -3.92 7.11 -7.11 3.92 -7.11 0 C -7.11 -3.92 -3.92 -7.11 0 -7.11 C 3.92 -7.11 7.11 -3.92 7.11 0 Z M 0 0"></path></g><g transform="matrix(1.0 0.0 0.0 1.0 -3.46 -4.46)" fill="#000000" stroke="#000000"><foreignObject width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000"><span id="S2.SS1.p1.1.pic1.1.1.1.1.1" class="ltx_text">1</span></foreignObject></g></g></svg> distillation of knowledge to each FL <span id="S2.SS1.p1.4.2" class="ltx_text ltx_font_typewriter">client</span> to learn stronger personalized models,  <svg id="S2.SS1.p1.2.pic2" class="ltx_picture" height="14.77" overflow="visible" version="1.1" width="14.77"><g transform="translate(0,14.77) matrix(1 0 0 -1 0 0) translate(7.38,0) translate(0,7.38)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill="#FFFFFF"><path d="M 7.11 0 C 7.11 3.92 3.92 7.11 0 7.11 C -3.92 7.11 -7.11 3.92 -7.11 0 C -7.11 -3.92 -3.92 -7.11 0 -7.11 C 3.92 -7.11 7.11 -3.92 7.11 0 Z M 0 0"></path></g><g transform="matrix(1.0 0.0 0.0 1.0 -3.46 -4.46)" fill="#000000" stroke="#000000"><foreignObject width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000"><span id="S2.SS1.p1.2.pic2.1.1.1.1.1" class="ltx_text">2</span></foreignObject></g></g></svg> distillation of knowledge to the <span id="S2.SS1.p1.4.3" class="ltx_text ltx_font_typewriter">central server</span> to learn stronger server models,  <svg id="S2.SS1.p1.3.pic3" class="ltx_picture" height="14.77" overflow="visible" version="1.1" width="14.77"><g transform="translate(0,14.77) matrix(1 0 0 -1 0 0) translate(7.38,0) translate(0,7.38)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill="#FFFFFF"><path d="M 7.11 0 C 7.11 3.92 3.92 7.11 0 7.11 C -3.92 7.11 -7.11 3.92 -7.11 0 C -7.11 -3.92 -3.92 -7.11 0 -7.11 C 3.92 -7.11 7.11 -3.92 7.11 0 Z M 0 0"></path></g><g transform="matrix(1.0 0.0 0.0 1.0 -3.46 -4.46)" fill="#000000" stroke="#000000"><foreignObject width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000"><span id="S2.SS1.p1.3.pic3.1.1.1.1.1" class="ltx_text">3</span></foreignObject></g></g></svg> bidirectional distillation to both the FL <span id="S2.SS1.p1.4.4" class="ltx_text ltx_font_typewriter">clients</span> and the <span id="S2.SS1.p1.4.5" class="ltx_text ltx_font_typewriter">server</span>, and  <svg id="S2.SS1.p1.4.pic4" class="ltx_picture" height="14.77" overflow="visible" version="1.1" width="14.77"><g transform="translate(0,14.77) matrix(1 0 0 -1 0 0) translate(7.38,0) translate(0,7.38)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill="#FFFFFF"><path d="M 7.11 0 C 7.11 3.92 3.92 7.11 0 7.11 C -3.92 7.11 -7.11 3.92 -7.11 0 C -7.11 -3.92 -3.92 -7.11 0 -7.11 C 3.92 -7.11 7.11 -3.92 7.11 0 Z M 0 0"></path></g><g transform="matrix(1.0 0.0 0.0 1.0 -3.46 -4.46)" fill="#000000" stroke="#000000"><foreignObject width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000"><span id="S2.SS1.p1.4.pic4.1.1.1.1.1" class="ltx_text">4</span></foreignObject></g></g></svg> <span id="S2.SS1.p1.4.6" class="ltx_text ltx_font_typewriter">inter-client</span> distillation.</p>
</div>
<div id="S2.SS1.p2" class="ltx_para">
<p id="S2.SS1.p2.1" class="ltx_p"><span id="S2.SS1.p2.1.1" class="ltx_text ltx_font_typewriter">FedMD</span> <cite class="ltx_cite ltx_citemacro_citep">(Li and Wang, <a href="#bib.bib36" title="" class="ltx_ref">2019</a>)</cite> belongs to the first category of KD algorithms, focusing on strengthening personalized models for each FL client. It requires a carefully selected labeled public dataset and offers flexibility in various learning tasks, including image and text data applications. In the second category of KD strategies, we considered two specific approaches, i.e., <span id="S2.SS1.p2.1.2" class="ltx_text ltx_font_typewriter">MHAT</span> <cite class="ltx_cite ltx_citemacro_citep">(Hu et al<span class="ltx_text">.</span>, <a href="#bib.bib23" title="" class="ltx_ref">2021</a>)</cite> and <span id="S2.SS1.p2.1.3" class="ltx_text ltx_font_typewriter">FedDF</span> <cite class="ltx_cite ltx_citemacro_citep">(Lin et al<span class="ltx_text">.</span>, <a href="#bib.bib38" title="" class="ltx_ref">2020</a>)</cite>. Both strategies focus on learning stronger (student) server models with the help of several (<em id="S2.SS1.p2.1.4" class="ltx_emph ltx_font_italic">ensemble</em>) candidate (teacher) client models. For distilling knowledge to the server models, <span id="S2.SS1.p2.1.5" class="ltx_text ltx_font_typewriter">MHAT</span> requires a labeled public dataset, while <span id="S2.SS1.p2.1.6" class="ltx_text ltx_font_typewriter">FedDF</span> does not impose this restriction. <span id="S2.SS1.p2.1.7" class="ltx_text ltx_font_typewriter">FedET</span> <cite class="ltx_cite ltx_citemacro_citep">(Cho et al<span class="ltx_text">.</span>, <a href="#bib.bib12" title="" class="ltx_ref">2022</a>)</cite> is a bidirectional distillation technique that uses a weighted consensus algorithm with diversity regularization to train small client models and a large server model. Distributed distillation (<span id="S2.SS1.p2.1.8" class="ltx_text ltx_font_typewriter">DD</span>) <cite class="ltx_cite ltx_citemacro_citep">(Bistritz et al<span class="ltx_text">.</span>, <a href="#bib.bib6" title="" class="ltx_ref">2020</a>)</cite> is a semi-supervised FL strategy where knowledge is transferred amongst all neighboring clients in a network. In each communication round, clients exchange soft targets with all their neighbors and update their own targets using a consensus algorithm. Following this, the updated soft targets are used by each client to update its private model weights.</p>
</div>
<div id="S2.SS1.p3" class="ltx_para">
<p id="S2.SS1.p3.1" class="ltx_p">Strategies belonging to categories three and four either require frequent communication between the server and the clients or amongst clients leading to significantly high communication costs. Therefore, we don’t consider any distillation strategies from these categories for our serverless implementation. In this paper, we adapt and optimize the strategies <span id="S2.SS1.p3.1.1" class="ltx_text ltx_font_typewriter">FedMD</span> and <span id="S2.SS1.p3.1.2" class="ltx_text ltx_font_typewriter">FedDF</span> using FaaS functions. We choose <span id="S2.SS1.p3.1.3" class="ltx_text ltx_font_typewriter">FedDF</span> over <span id="S2.SS1.p3.1.4" class="ltx_text ltx_font_typewriter">MHAT</span> due to its superior robustness in handling heterogeneous data distributions and its flexibility regarding the type of public dataset required <cite class="ltx_cite ltx_citemacro_citep">(Lin et al<span class="ltx_text">.</span>, <a href="#bib.bib38" title="" class="ltx_ref">2020</a>)</cite>.</p>
</div>
<figure id="S2.F3" class="ltx_figure"><img src="/html/2402.07295/assets/x3.png" id="S2.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="392" height="162" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S2.F3.3.1.1" class="ltx_text" style="font-size:90%;">Figure 3</span>. </span><span id="S2.F3.4.2" class="ltx_text" style="font-size:90%;">Different steps in the <span id="S2.F3.4.2.1" class="ltx_text ltx_font_typewriter">FedMD</span> <cite class="ltx_cite ltx_citemacro_citep">(Li and Wang, <a href="#bib.bib36" title="" class="ltx_ref">2019</a>)</cite> algorithm.</span></figcaption>
</figure>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2. </span>FedMD</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.10" class="ltx_p">The <span id="S2.SS2.p1.10.1" class="ltx_text ltx_font_typewriter">FedMD</span> <cite class="ltx_cite ltx_citemacro_citep">(Li and Wang, <a href="#bib.bib36" title="" class="ltx_ref">2019</a>)</cite> algorithm supports a unique model architecture for each participating client. In this strategy, the central server does not require any information about the client models and treats them as a black box. Furthermore, in addition to their private datasets, each client has access to a labeled public dataset. The collaborative training process in <span id="S2.SS2.p1.10.2" class="ltx_text ltx_font_typewriter">FedMD</span>
consists of seven synchronous steps, each of which is shown in Figure <a href="#S2.F3" title="Figure 3 ‣ 2.1. Knowledge Distillation in FL ‣ 2. Background ‣ Training Heterogeneous Client Models using Knowledge Distillation in Serverless Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>. In the first step ( <svg id="S2.SS2.p1.1.pic1" class="ltx_picture" height="14.77" overflow="visible" version="1.1" width="14.77"><g transform="translate(0,14.77) matrix(1 0 0 -1 0 0) translate(7.38,0) translate(0,7.38)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill="#000000"><path d="M 7.11 0 C 7.11 3.92 3.92 7.11 0 7.11 C -3.92 7.11 -7.11 3.92 -7.11 0 C -7.11 -3.92 -3.92 -7.11 0 -7.11 C 3.92 -7.11 7.11 -3.92 7.11 0 Z M 0 0"></path></g><g transform="matrix(1.0 0.0 0.0 1.0 -3.46 -4.46)" fill="#FFFFFF" stroke="#FFFFFF"><foreignObject width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#FFFFFF"><span id="S2.SS2.p1.1.pic1.1.1.1.1.1" class="ltx_text">1</span></foreignObject></g></g></svg>), each participating client trains on the labeled public dataset until convergence and then on its private dataset for a few epochs. Following this, each participating client performs a forward-pass inference on the public dataset and sends the generated class logits to the central server ( <svg id="S2.SS2.p1.2.pic2" class="ltx_picture" height="14.77" overflow="visible" version="1.1" width="14.77"><g transform="translate(0,14.77) matrix(1 0 0 -1 0 0) translate(7.38,0) translate(0,7.38)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill="#000000"><path d="M 7.11 0 C 7.11 3.92 3.92 7.11 0 7.11 C -3.92 7.11 -7.11 3.92 -7.11 0 C -7.11 -3.92 -3.92 -7.11 0 -7.11 C 3.92 -7.11 7.11 -3.92 7.11 0 Z M 0 0"></path></g><g transform="matrix(1.0 0.0 0.0 1.0 -3.46 -4.46)" fill="#FFFFFF" stroke="#FFFFFF"><foreignObject width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#FFFFFF"><span id="S2.SS2.p1.2.pic2.1.1.1.1.1" class="ltx_text">2</span></foreignObject></g></g></svg>- <svg id="S2.SS2.p1.3.pic3" class="ltx_picture" height="14.77" overflow="visible" version="1.1" width="14.77"><g transform="translate(0,14.77) matrix(1 0 0 -1 0 0) translate(7.38,0) translate(0,7.38)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill="#000000"><path d="M 7.11 0 C 7.11 3.92 3.92 7.11 0 7.11 C -3.92 7.11 -7.11 3.92 -7.11 0 C -7.11 -3.92 -3.92 -7.11 0 -7.11 C 3.92 -7.11 7.11 -3.92 7.11 0 Z M 0 0"></path></g><g transform="matrix(1.0 0.0 0.0 1.0 -3.46 -4.46)" fill="#FFFFFF" stroke="#FFFFFF"><foreignObject width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#FFFFFF"><span id="S2.SS2.p1.3.pic3.1.1.1.1.1" class="ltx_text">3</span></foreignObject></g></g></svg>). The central server aggregates the obtained class logits ( <svg id="S2.SS2.p1.4.pic4" class="ltx_picture" height="14.77" overflow="visible" version="1.1" width="14.77"><g transform="translate(0,14.77) matrix(1 0 0 -1 0 0) translate(7.38,0) translate(0,7.38)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill="#000000"><path d="M 7.11 0 C 7.11 3.92 3.92 7.11 0 7.11 C -3.92 7.11 -7.11 3.92 -7.11 0 C -7.11 -3.92 -3.92 -7.11 0 -7.11 C 3.92 -7.11 7.11 -3.92 7.11 0 Z M 0 0"></path></g><g transform="matrix(1.0 0.0 0.0 1.0 -3.46 -4.46)" fill="#FFFFFF" stroke="#FFFFFF"><foreignObject width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#FFFFFF"><span id="S2.SS2.p1.4.pic4.1.1.1.1.1" class="ltx_text">4</span></foreignObject></g></g></svg>) and sends them back to the participating clients ( <svg id="S2.SS2.p1.5.pic5" class="ltx_picture" height="14.77" overflow="visible" version="1.1" width="14.77"><g transform="translate(0,14.77) matrix(1 0 0 -1 0 0) translate(7.38,0) translate(0,7.38)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill="#000000"><path d="M 7.11 0 C 7.11 3.92 3.92 7.11 0 7.11 C -3.92 7.11 -7.11 3.92 -7.11 0 C -7.11 -3.92 -3.92 -7.11 0 -7.11 C 3.92 -7.11 7.11 -3.92 7.11 0 Z M 0 0"></path></g><g transform="matrix(1.0 0.0 0.0 1.0 -3.46 -4.46)" fill="#FFFFFF" stroke="#FFFFFF"><foreignObject width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#FFFFFF"><span id="S2.SS2.p1.5.pic5.1.1.1.1.1" class="ltx_text">5</span></foreignObject></g></g></svg>). After this, each participating client trains its model using the aggregated logits as soft targets on the public dataset ( <svg id="S2.SS2.p1.6.pic6" class="ltx_picture" height="14.77" overflow="visible" version="1.1" width="14.77"><g transform="translate(0,14.77) matrix(1 0 0 -1 0 0) translate(7.38,0) translate(0,7.38)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill="#000000"><path d="M 7.11 0 C 7.11 3.92 3.92 7.11 0 7.11 C -3.92 7.11 -7.11 3.92 -7.11 0 C -7.11 -3.92 -3.92 -7.11 0 -7.11 C 3.92 -7.11 7.11 -3.92 7.11 0 Z M 0 0"></path></g><g transform="matrix(1.0 0.0 0.0 1.0 -3.46 -4.46)" fill="#FFFFFF" stroke="#FFFFFF"><foreignObject width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#FFFFFF"><span id="S2.SS2.p1.6.pic6.1.1.1.1.1" class="ltx_text">6</span></foreignObject></g></g></svg>). Finally, each participating client trains the model on its private dataset for a few epochs for personalization ( <svg id="S2.SS2.p1.7.pic7" class="ltx_picture" height="14.77" overflow="visible" version="1.1" width="14.77"><g transform="translate(0,14.77) matrix(1 0 0 -1 0 0) translate(7.38,0) translate(0,7.38)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill="#000000"><path d="M 7.11 0 C 7.11 3.92 3.92 7.11 0 7.11 C -3.92 7.11 -7.11 3.92 -7.11 0 C -7.11 -3.92 -3.92 -7.11 0 -7.11 C 3.92 -7.11 7.11 -3.92 7.11 0 Z M 0 0"></path></g><g transform="matrix(1.0 0.0 0.0 1.0 -3.46 -4.46)" fill="#FFFFFF" stroke="#FFFFFF"><foreignObject width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#FFFFFF"><span id="S2.SS2.p1.7.pic7.1.1.1.1.1" class="ltx_text">7</span></foreignObject></g></g></svg>). While step  <svg id="S2.SS2.p1.8.pic8" class="ltx_picture" height="14.77" overflow="visible" version="1.1" width="14.77"><g transform="translate(0,14.77) matrix(1 0 0 -1 0 0) translate(7.38,0) translate(0,7.38)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill="#000000"><path d="M 7.11 0 C 7.11 3.92 3.92 7.11 0 7.11 C -3.92 7.11 -7.11 3.92 -7.11 0 C -7.11 -3.92 -3.92 -7.11 0 -7.11 C 3.92 -7.11 7.11 -3.92 7.11 0 Z M 0 0"></path></g><g transform="matrix(1.0 0.0 0.0 1.0 -3.46 -4.46)" fill="#FFFFFF" stroke="#FFFFFF"><foreignObject width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#FFFFFF"><span id="S2.SS2.p1.8.pic8.1.1.1.1.1" class="ltx_text">1</span></foreignObject></g></g></svg> only occurs during the start of the training process, steps  <svg id="S2.SS2.p1.9.pic9" class="ltx_picture" height="14.77" overflow="visible" version="1.1" width="14.77"><g transform="translate(0,14.77) matrix(1 0 0 -1 0 0) translate(7.38,0) translate(0,7.38)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill="#000000"><path d="M 7.11 0 C 7.11 3.92 3.92 7.11 0 7.11 C -3.92 7.11 -7.11 3.92 -7.11 0 C -7.11 -3.92 -3.92 -7.11 0 -7.11 C 3.92 -7.11 7.11 -3.92 7.11 0 Z M 0 0"></path></g><g transform="matrix(1.0 0.0 0.0 1.0 -3.46 -4.46)" fill="#FFFFFF" stroke="#FFFFFF"><foreignObject width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#FFFFFF"><span id="S2.SS2.p1.9.pic9.1.1.1.1.1" class="ltx_text">2</span></foreignObject></g></g></svg>- <svg id="S2.SS2.p1.10.pic10" class="ltx_picture" height="14.77" overflow="visible" version="1.1" width="14.77"><g transform="translate(0,14.77) matrix(1 0 0 -1 0 0) translate(7.38,0) translate(0,7.38)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill="#000000"><path d="M 7.11 0 C 7.11 3.92 3.92 7.11 0 7.11 C -3.92 7.11 -7.11 3.92 -7.11 0 C -7.11 -3.92 -3.92 -7.11 0 -7.11 C 3.92 -7.11 7.11 -3.92 7.11 0 Z M 0 0"></path></g><g transform="matrix(1.0 0.0 0.0 1.0 -3.46 -4.46)" fill="#FFFFFF" stroke="#FFFFFF"><foreignObject width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#FFFFFF"><span id="S2.SS2.p1.10.pic10.1.1.1.1.1" class="ltx_text">7</span></foreignObject></g></g></svg> are repeated until the required client model accuracy is reached. The final output layer of the client model architecture must have a total number of output neurons equal to the sum of the number of classes in the private dataset and the number of classes in the public dataset. This is because the model is trained on both datasets during the complete training process, and in most cases, the classes in the two datasets are mutually exclusive. Therefore, a good public dataset (§<a href="#S2.SS1" title="2.1. Knowledge Distillation in FL ‣ 2. Background ‣ Training Heterogeneous Client Models using Knowledge Distillation in Serverless Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.1</span></a>) minimizes the total number of output classes while maximizing the amount of available data.</p>
</div>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3. </span>FedDF</h3>

<div id="S2.SS3.p1" class="ltx_para">
<p id="S2.SS3.p1.6" class="ltx_p">The <span id="S2.SS3.p1.6.1" class="ltx_text ltx_font_typewriter">FedDF</span> <cite class="ltx_cite ltx_citemacro_citep">(Lin et al<span class="ltx_text">.</span>, <a href="#bib.bib38" title="" class="ltx_ref">2020</a>)</cite> algorithm proposes an ensemble distillation approach for model fusion that supports heterogeneous FL client model architectures. In contrast to <span id="S2.SS3.p1.6.2" class="ltx_text ltx_font_typewriter">FedMD</span> (§<a href="#S2.SS2" title="2.2. FedMD ‣ 2. Background ‣ Training Heterogeneous Client Models using Knowledge Distillation in Serverless Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.2</span></a>), it supports distillation with an unlabelled public dataset that can also be generated using Generative adversarial networks. As a result, it does not require any changes to the client training process. The different synchronous steps involved in the <span id="S2.SS3.p1.6.3" class="ltx_text ltx_font_typewriter">FedDF</span> strategy are shown in Figure <a href="#S2.F4" title="Figure 4 ‣ 2.3. FedDF ‣ 2. Background ‣ Training Heterogeneous Client Models using Knowledge Distillation in Serverless Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>. At the start of each training round, the central server randomly selects a group of clients to participate in that round. Following this, the randomly selected clients train their local teacher models for a specified number of epochs ( <svg id="S2.SS3.p1.1.pic1" class="ltx_picture" height="14.77" overflow="visible" version="1.1" width="14.77"><g transform="translate(0,14.77) matrix(1 0 0 -1 0 0) translate(7.38,0) translate(0,7.38)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill="#000000"><path d="M 7.11 0 C 7.11 3.92 3.92 7.11 0 7.11 C -3.92 7.11 -7.11 3.92 -7.11 0 C -7.11 -3.92 -3.92 -7.11 0 -7.11 C 3.92 -7.11 7.11 -3.92 7.11 0 Z M 0 0"></path></g><g transform="matrix(1.0 0.0 0.0 1.0 -3.46 -4.46)" fill="#FFFFFF" stroke="#FFFFFF"><foreignObject width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#FFFFFF"><span id="S2.SS3.p1.1.pic1.1.1.1.1.1" class="ltx_text">1</span></foreignObject></g></g></svg>). After local training, each participating client sends the updated model weights to the central server ( <svg id="S2.SS3.p1.2.pic2" class="ltx_picture" height="14.77" overflow="visible" version="1.1" width="14.77"><g transform="translate(0,14.77) matrix(1 0 0 -1 0 0) translate(7.38,0) translate(0,7.38)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill="#000000"><path d="M 7.11 0 C 7.11 3.92 3.92 7.11 0 7.11 C -3.92 7.11 -7.11 3.92 -7.11 0 C -7.11 -3.92 -3.92 -7.11 0 -7.11 C 3.92 -7.11 7.11 -3.92 7.11 0 Z M 0 0"></path></g><g transform="matrix(1.0 0.0 0.0 1.0 -3.46 -4.46)" fill="#FFFFFF" stroke="#FFFFFF"><foreignObject width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#FFFFFF"><span id="S2.SS3.p1.2.pic2.1.1.1.1.1" class="ltx_text">2</span></foreignObject></g></g></svg>). For each unique client model architecture, the central server aggregates the received model weights to initialize a student server model. To distill knowledge to the initialized server model, each teacher client model is evaluated on mini-batches of the public dataset, and their generated logit outputs are used to train the student server model using a custom loss function <cite class="ltx_cite ltx_citemacro_citep">(Lin et al<span class="ltx_text">.</span>, <a href="#bib.bib38" title="" class="ltx_ref">2020</a>)</cite>. This training process continues until a stable validation loss is reached for the student server model ( <svg id="S2.SS3.p1.3.pic3" class="ltx_picture" height="14.77" overflow="visible" version="1.1" width="14.77"><g transform="translate(0,14.77) matrix(1 0 0 -1 0 0) translate(7.38,0) translate(0,7.38)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill="#000000"><path d="M 7.11 0 C 7.11 3.92 3.92 7.11 0 7.11 C -3.92 7.11 -7.11 3.92 -7.11 0 C -7.11 -3.92 -3.92 -7.11 0 -7.11 C 3.92 -7.11 7.11 -3.92 7.11 0 Z M 0 0"></path></g><g transform="matrix(1.0 0.0 0.0 1.0 -3.46 -4.46)" fill="#FFFFFF" stroke="#FFFFFF"><foreignObject width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#FFFFFF"><span id="S2.SS3.p1.3.pic3.1.1.1.1.1" class="ltx_text">3</span></foreignObject></g></g></svg>). After the ensemble distillation process, we obtain distilled server models for each unique model architecture that contains collaborative knowledge from all the participating clients across all model architectures. The weights from these distilled server models are then distributed back to the clients based on their respective model architectures for the next training round ( <svg id="S2.SS3.p1.4.pic4" class="ltx_picture" height="14.77" overflow="visible" version="1.1" width="14.77"><g transform="translate(0,14.77) matrix(1 0 0 -1 0 0) translate(7.38,0) translate(0,7.38)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill="#000000"><path d="M 7.11 0 C 7.11 3.92 3.92 7.11 0 7.11 C -3.92 7.11 -7.11 3.92 -7.11 0 C -7.11 -3.92 -3.92 -7.11 0 -7.11 C 3.92 -7.11 7.11 -3.92 7.11 0 Z M 0 0"></path></g><g transform="matrix(1.0 0.0 0.0 1.0 -3.46 -4.46)" fill="#FFFFFF" stroke="#FFFFFF"><foreignObject width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#FFFFFF"><span id="S2.SS3.p1.4.pic4.1.1.1.1.1" class="ltx_text">4</span></foreignObject></g></g></svg>). Steps  <svg id="S2.SS3.p1.5.pic5" class="ltx_picture" height="14.77" overflow="visible" version="1.1" width="14.77"><g transform="translate(0,14.77) matrix(1 0 0 -1 0 0) translate(7.38,0) translate(0,7.38)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill="#000000"><path d="M 7.11 0 C 7.11 3.92 3.92 7.11 0 7.11 C -3.92 7.11 -7.11 3.92 -7.11 0 C -7.11 -3.92 -3.92 -7.11 0 -7.11 C 3.92 -7.11 7.11 -3.92 7.11 0 Z M 0 0"></path></g><g transform="matrix(1.0 0.0 0.0 1.0 -3.46 -4.46)" fill="#FFFFFF" stroke="#FFFFFF"><foreignObject width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#FFFFFF"><span id="S2.SS3.p1.5.pic5.1.1.1.1.1" class="ltx_text">1</span></foreignObject></g></g></svg>- <svg id="S2.SS3.p1.6.pic6" class="ltx_picture" height="14.77" overflow="visible" version="1.1" width="14.77"><g transform="translate(0,14.77) matrix(1 0 0 -1 0 0) translate(7.38,0) translate(0,7.38)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill="#000000"><path d="M 7.11 0 C 7.11 3.92 3.92 7.11 0 7.11 C -3.92 7.11 -7.11 3.92 -7.11 0 C -7.11 -3.92 -3.92 -7.11 0 -7.11 C 3.92 -7.11 7.11 -3.92 7.11 0 Z M 0 0"></path></g><g transform="matrix(1.0 0.0 0.0 1.0 -3.46 -4.46)" fill="#FFFFFF" stroke="#FFFFFF"><foreignObject width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#FFFFFF"><span id="S2.SS3.p1.6.pic6.1.1.1.1.1" class="ltx_text">4</span></foreignObject></g></g></svg> are repeated until the desired accuracy is reached for each model architecture.</p>
</div>
<figure id="S2.F4" class="ltx_figure"><img src="/html/2402.07295/assets/x4.png" id="S2.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="118" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S2.F4.3.1.1" class="ltx_text" style="font-size:90%;">Figure 4</span>. </span><span id="S2.F4.4.2" class="ltx_text" style="font-size:90%;">Different steps in the <span id="S2.F4.4.2.1" class="ltx_text ltx_font_typewriter">FedDF</span> <cite class="ltx_cite ltx_citemacro_citep">(Lin et al<span class="ltx_text">.</span>, <a href="#bib.bib38" title="" class="ltx_ref">2020</a>)</cite> algorithm.</span></figcaption>
</figure>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3. </span>Related Work</h2>

<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1. </span>Serverless Federated Learning</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">Using serverless computing technologies, particularly FaaS, for designing efficient systems for FL is a relatively new research direction. Existing works in this domain can be categorized into two groups: (i) systems that employ serverless functions exclusively in the <span id="S3.SS1.p1.1.1" class="ltx_text ltx_font_typewriter">central server</span>  <cite class="ltx_cite ltx_citemacro_citep">(Jayaram et al<span class="ltx_text">.</span>, <a href="#bib.bib26" title="" class="ltx_ref">2022b</a>, <a href="#bib.bib27" title="" class="ltx_ref">c</a>, <a href="#bib.bib25" title="" class="ltx_ref">a</a>)</cite> and (ii) systems that leverage serverless functions in both entities of an FL system <cite class="ltx_cite ltx_citemacro_citep">(Kotsehub et al<span class="ltx_text">.</span>, <a href="#bib.bib33" title="" class="ltx_ref">2022</a>; Chadha et al<span class="ltx_text">.</span>, <a href="#bib.bib9" title="" class="ltx_ref">2020</a>; Grafberger et al<span class="ltx_text">.</span>, <a href="#bib.bib18" title="" class="ltx_ref">2021</a>)</cite> (§<a href="#S1" title="1. Introduction ‣ Training Heterogeneous Client Models using Knowledge Distillation in Serverless Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>). In <cite class="ltx_cite ltx_citemacro_citep">(Jayaram et al<span class="ltx_text">.</span>, <a href="#bib.bib26" title="" class="ltx_ref">2022b</a>)</cite>, Jayaram et al. propose <math id="S3.SS1.p1.1.m1.1" class="ltx_Math" alttext="\lambda" display="inline"><semantics id="S3.SS1.p1.1.m1.1a"><mi id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml">λ</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.1b"><ci id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1">𝜆</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.1c">\lambda</annotation></semantics></math>-FL, a serverless aggregation strategy for FL to improve fault tolerance and reduce resource wastage. The authors use serverless functions as aggregators to optimize the aggregation of model parameters in conventional <span id="S3.SS1.p1.1.2" class="ltx_text ltx_font_typewriter">FedAvg</span> <cite class="ltx_cite ltx_citemacro_citep">(McMahan et al<span class="ltx_text">.</span>, <a href="#bib.bib40" title="" class="ltx_ref">2017</a>)</cite> over several steps. They implement their prototype using message queues, <span id="S3.SS1.p1.1.3" class="ltx_text ltx_font_typewriter">Kafka</span>, and use <span id="S3.SS1.p1.1.4" class="ltx_text ltx_font_typewriter">Ray</span> <cite class="ltx_cite ltx_citemacro_citep">(Moritz et al<span class="ltx_text">.</span>, <a href="#bib.bib42" title="" class="ltx_ref">2018</a>)</cite> as the serverless platform. In <cite class="ltx_cite ltx_citemacro_citep">(Jayaram et al<span class="ltx_text">.</span>, <a href="#bib.bib27" title="" class="ltx_ref">2022c</a>)</cite> and <cite class="ltx_cite ltx_citemacro_citep">(Jayaram et al<span class="ltx_text">.</span>, <a href="#bib.bib25" title="" class="ltx_ref">2022a</a>)</cite>, the authors extend their previous strategy to enable adaptive and just-in-time aggregation of client model updates using serverless functions. In the second group, <em id="S3.SS1.p1.1.5" class="ltx_emph ltx_font_italic">FedKeeper</em> <cite class="ltx_cite ltx_citemacro_citep">(Chadha et al<span class="ltx_text">.</span>, <a href="#bib.bib9" title="" class="ltx_ref">2020</a>)</cite> was the first serverless FL system that enabled the training of Deep Neural Network (DNN) models using FL for clients distributed across a combination of heterogeneous FaaS platforms. However, it lacked crucial features required for practical FL systems, such as security and support for large DNN models. To address these drawbacks, <em id="S3.SS1.p1.1.6" class="ltx_emph ltx_font_italic">FedLess</em> <cite class="ltx_cite ltx_citemacro_citep">(Grafberger et al<span class="ltx_text">.</span>, <a href="#bib.bib18" title="" class="ltx_ref">2021</a>)</cite> was introduced as an evolution of <em id="S3.SS1.p1.1.7" class="ltx_emph ltx_font_italic">FedKeeper</em> with multiple new enhancements. These include: (i) support for multiple open-source and commercial FaaS platforms, (ii) authentication/authorization of client functions using AWS Cognito, (iii) training of arbitrary homogeneous DNN models using the <span id="S3.SS1.p1.1.8" class="ltx_text ltx_font_typewriter">Tensorflow</span> library, and (iv) the privacy-preserving FL training of models using Differential Privacy <cite class="ltx_cite ltx_citemacro_citep">(Mothukuri et al<span class="ltx_text">.</span>, <a href="#bib.bib43" title="" class="ltx_ref">2021</a>)</cite>. In addition, <em id="S3.SS1.p1.1.9" class="ltx_emph ltx_font_italic">FedLess</em> incorporates several optimizations for serverless environments, such as global namespace caching, running average model aggregation, and federated evaluation. A more recent work by Kotsehub et al. <cite class="ltx_cite ltx_citemacro_citep">(Kotsehub et al<span class="ltx_text">.</span>, <a href="#bib.bib33" title="" class="ltx_ref">2022</a>)</cite> introduces <em id="S3.SS1.p1.1.10" class="ltx_emph ltx_font_italic">Flox</em>, a system built on the <span id="S3.SS1.p1.1.11" class="ltx_text ltx_font_typewriter">funcX</span> <cite class="ltx_cite ltx_citemacro_citep">(Chard et al<span class="ltx_text">.</span>, <a href="#bib.bib11" title="" class="ltx_ref">2020</a>)</cite> serverless platform. <em id="S3.SS1.p1.1.12" class="ltx_emph ltx_font_italic">Flox</em> aims to separate FL model training/inference from infrastructure management, providing users with a convenient way to deploy FL models on heterogeneous distributed compute endpoints. However, its tight integration with <span id="S3.SS1.p1.1.13" class="ltx_text ltx_font_typewriter">funcX</span> restricts its compatibility with other open-source or commercial FaaS platforms, limiting its applicability and generality. As a result, in this paper, we use <em id="S3.SS1.p1.1.14" class="ltx_emph ltx_font_italic">FedLess</em> as the serverless FL system.</p>
</div>
<figure id="LST1" class="ltx_float ltx_lstlisting">
<div id="LST1.1" class="ltx_listing ltx_lst_language_yaml ltx_lst_numbers_left ltx_lstlisting ltx_framed ltx_framed_rectangle ltx_listing">
<div class="ltx_listing_data"><a href="data:text/plain;base64,bW9kZWw6CiAgbmFtZTogIm15IG5ldHdvcmsiCiAgZGF0YXNldDoKICAgIG5hbWU6ICJtbmlzdCIKICBpbnB1dF9zaGFwZTogWzMyLCAzMiwgM10KICBibG9jazoKICAgIGxheWVyczogJnJlZl9ibG9jawogICAgICAtIG5hbWU6ICZsYXlfMV9yZWYgImxheWVyXzEiCiAgICAgICAgdHlwZTogQ29udjJECiAgICAgICAgaW5wdXQ6IFthdXRvXQogICAgICAgIHBhcmFtczogWy4uLl0KICAgICAgLSBuYW1lOiAmbGF5XzJfcmVmICJsYXllcl8yIgogICAgICAgIHR5cGU6IERlbnNlCiAgICAgICAgaW5wdXQ6IFsqbGF5XzJfcmVmXQogICAgICAgIHBhcmFtczoKICAgICAgICAgIHVuaXRzOiAxMAogICAgICAgICAgYWN0aXZhdGlvbjogInNvZnRtYXgiCiAgbGF5ZXJzOgogICAgLSBuYW1lOiAmbGF5ZXJfMSAibGF5ZXJfMSIKICAgICAgdHlwZTogQ29udjJECiAgICAgIGlucHV0OiBbYXV0b10KICAgICAgcGFyYW1zOiBbLi4uXQogICAgLSBuYW1lOiAmbGF5ZXJfMiAibGF5ZXJfMiIKICAgICAgdHlwZTogIlJlZmVyZW5jZUJsb2NrIgogICAgICBpbnB1dDogWypsYXllcl8xXQogICAgICBsYXllcnM6ICpyZWZfYmxvY2sKICBvdXRwdXRzOiBbKmxheWVyXzEsICpsYXllcl8yXQo=" download="code/model.yaml">⬇</a></div>
<div id="lstnumberx1" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">1</span><span id="lstnumberx1.1" class="ltx_text ltx_lst_identifier ltx_font_bold" style="font-size:50%;color:#000000;">model</span><span id="lstnumberx1.2" class="ltx_text"></span>
</div>
<div id="lstnumberx2" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">2</span><span id="lstnumberx2.1" class="ltx_text ltx_lst_space ltx_font_bold" style="font-size:50%;color:#000000;">  </span><span id="lstnumberx2.2" class="ltx_text ltx_lst_identifier ltx_font_bold" style="font-size:50%;color:#000000;">name</span><span id="lstnumberx2.3" class="ltx_text ltx_font_bold" style="font-size:50%;color:#000000;"><span id="lstnumberx2.3.1" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx2.3.2" class="ltx_text ltx_lst_string ltx_font_typewriter ltx_font_medium" style="color:#0000FF;">"my<span id="lstnumberx2.3.2.1" class="ltx_text ltx_lst_space">␣</span>network"</span></span>
</div>
<div id="lstnumberx3" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">3</span><span id="lstnumberx3.1" class="ltx_text ltx_lst_space ltx_font_bold" style="font-size:50%;color:#000000;">  </span><span id="lstnumberx3.2" class="ltx_text ltx_lst_identifier ltx_font_bold" style="font-size:50%;color:#000000;">dataset</span><span id="lstnumberx3.3" class="ltx_text"></span>
</div>
<div id="lstnumberx4" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">4</span><span id="lstnumberx4.1" class="ltx_text ltx_lst_space ltx_font_bold" style="font-size:50%;color:#000000;">    </span><span id="lstnumberx4.2" class="ltx_text ltx_lst_identifier ltx_font_bold" style="font-size:50%;color:#000000;">name</span><span id="lstnumberx4.3" class="ltx_text ltx_font_bold" style="font-size:50%;color:#000000;"><span id="lstnumberx4.3.1" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx4.3.2" class="ltx_text ltx_lst_string ltx_font_typewriter ltx_font_medium" style="color:#0000FF;">"mnist"</span></span>
</div>
<div id="lstnumberx5" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">5</span><span id="lstnumberx5.1" class="ltx_text ltx_lst_space ltx_font_bold" style="font-size:50%;color:#000000;">  </span><span id="lstnumberx5.2" class="ltx_text ltx_lst_identifier ltx_font_bold" style="font-size:50%;color:#000000;">input_shape</span><span id="lstnumberx5.3" class="ltx_text ltx_font_bold" style="font-size:50%;color:#000000;"><span id="lstnumberx5.3.1" class="ltx_text ltx_lst_space"> </span>[32,<span id="lstnumberx5.3.2" class="ltx_text ltx_lst_space"> </span>32,<span id="lstnumberx5.3.3" class="ltx_text ltx_lst_space"> </span>3]</span>
</div>
<div id="lstnumberx6" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">6</span><span id="lstnumberx6.1" class="ltx_text ltx_lst_space ltx_font_bold" style="font-size:50%;color:#000000;">  </span><span id="lstnumberx6.2" class="ltx_text ltx_lst_identifier ltx_font_bold" style="font-size:50%;color:#000000;">block</span><span id="lstnumberx6.3" class="ltx_text"></span>
</div>
<div id="lstnumberx7" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">7</span><span id="lstnumberx7.1" class="ltx_text ltx_lst_space ltx_font_bold" style="font-size:50%;color:#000000;">    </span><span id="lstnumberx7.2" class="ltx_text ltx_lst_identifier ltx_font_bold" style="font-size:50%;color:#000000;">layers</span><span id="lstnumberx7.3" class="ltx_text ltx_font_bold" style="font-size:50%;color:#000000;"><span id="lstnumberx7.3.1" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx7.3.2" class="ltx_text" style="color:#FF8000;">&amp;ref_block</span></span>
</div>
<div id="lstnumberx8" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">8</span><span id="lstnumberx8.1" class="ltx_text ltx_lst_space ltx_font_bold" style="font-size:50%;color:#000000;">      </span><span id="lstnumberx8.2" class="ltx_text ltx_font_bold" style="font-size:50%;color:#000000;">-</span><span id="lstnumberx8.3" class="ltx_text ltx_lst_space ltx_font_bold" style="font-size:50%;color:#000000;"> </span><span id="lstnumberx8.4" class="ltx_text ltx_lst_identifier ltx_font_bold" style="font-size:50%;color:#000000;">name</span><span id="lstnumberx8.5" class="ltx_text ltx_font_bold" style="font-size:50%;color:#000000;"><span id="lstnumberx8.5.1" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx8.5.2" class="ltx_text" style="color:#FF8000;">&amp;lay_1_ref<span id="lstnumberx8.5.2.1" class="ltx_text ltx_lst_space"> </span>”layer_1”</span></span>
</div>
<div id="lstnumberx9" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">9</span><span id="lstnumberx9.1" class="ltx_text ltx_lst_space ltx_font_bold" style="font-size:50%;color:#000000;">        </span><span id="lstnumberx9.2" class="ltx_text ltx_lst_identifier ltx_font_bold" style="font-size:50%;color:#000000;">type</span><span id="lstnumberx9.3" class="ltx_text ltx_font_bold" style="font-size:50%;color:#000000;"><span id="lstnumberx9.3.1" class="ltx_text ltx_lst_space"> </span>Conv2D</span>
</div>
<div id="lstnumberx10" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">10</span><span id="lstnumberx10.1" class="ltx_text ltx_lst_space ltx_font_bold" style="font-size:50%;color:#000000;">        </span><span id="lstnumberx10.2" class="ltx_text ltx_lst_identifier ltx_font_bold" style="font-size:50%;color:#000000;">input</span><span id="lstnumberx10.3" class="ltx_text ltx_font_bold" style="font-size:50%;color:#000000;"><span id="lstnumberx10.3.1" class="ltx_text ltx_lst_space"> </span>[auto]</span>
</div>
<div id="lstnumberx11" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">11</span><span id="lstnumberx11.1" class="ltx_text ltx_lst_space ltx_font_bold" style="font-size:50%;color:#000000;">        </span><span id="lstnumberx11.2" class="ltx_text ltx_lst_identifier ltx_font_bold" style="font-size:50%;color:#000000;">params</span><span id="lstnumberx11.3" class="ltx_text ltx_font_bold" style="font-size:50%;color:#000000;"><span id="lstnumberx11.3.1" class="ltx_text ltx_lst_space"> </span>[…]</span>
</div>
<div id="lstnumberx12" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">12</span><span id="lstnumberx12.1" class="ltx_text ltx_lst_space ltx_font_bold" style="font-size:50%;color:#000000;">      </span><span id="lstnumberx12.2" class="ltx_text ltx_font_bold" style="font-size:50%;color:#000000;">-</span><span id="lstnumberx12.3" class="ltx_text ltx_lst_space ltx_font_bold" style="font-size:50%;color:#000000;"> </span><span id="lstnumberx12.4" class="ltx_text ltx_lst_identifier ltx_font_bold" style="font-size:50%;color:#000000;">name</span><span id="lstnumberx12.5" class="ltx_text ltx_font_bold" style="font-size:50%;color:#000000;"><span id="lstnumberx12.5.1" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx12.5.2" class="ltx_text" style="color:#FF8000;">&amp;lay_2_ref<span id="lstnumberx12.5.2.1" class="ltx_text ltx_lst_space"> </span>”layer_2”</span></span>
</div>
<div id="lstnumberx13" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">13</span><span id="lstnumberx13.1" class="ltx_text ltx_lst_space ltx_font_bold" style="font-size:50%;color:#000000;">        </span><span id="lstnumberx13.2" class="ltx_text ltx_lst_identifier ltx_font_bold" style="font-size:50%;color:#000000;">type</span><span id="lstnumberx13.3" class="ltx_text ltx_font_bold" style="font-size:50%;color:#000000;"><span id="lstnumberx13.3.1" class="ltx_text ltx_lst_space"> </span>Dense</span>
</div>
<div id="lstnumberx14" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">14</span><span id="lstnumberx14.1" class="ltx_text ltx_lst_space ltx_font_bold" style="font-size:50%;color:#000000;">        </span><span id="lstnumberx14.2" class="ltx_text ltx_lst_identifier ltx_font_bold" style="font-size:50%;color:#000000;">input</span><span id="lstnumberx14.3" class="ltx_text ltx_font_bold" style="font-size:50%;color:#000000;"><span id="lstnumberx14.3.1" class="ltx_text ltx_lst_space"> </span>[<span id="lstnumberx14.3.2" class="ltx_text" style="color:#FF00FF;">*lay_2_ref]</span></span>
</div>
<div id="lstnumberx15" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">15</span><span id="lstnumberx15.1" class="ltx_text ltx_lst_space ltx_font_bold" style="font-size:50%;color:#000000;">        </span><span id="lstnumberx15.2" class="ltx_text ltx_lst_identifier ltx_font_bold" style="font-size:50%;color:#000000;">params</span><span id="lstnumberx15.3" class="ltx_text"></span>
</div>
<div id="lstnumberx16" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">16</span><span id="lstnumberx16.1" class="ltx_text ltx_lst_space ltx_font_bold" style="font-size:50%;color:#000000;">          </span><span id="lstnumberx16.2" class="ltx_text ltx_lst_identifier ltx_font_bold" style="font-size:50%;color:#000000;">units</span><span id="lstnumberx16.3" class="ltx_text ltx_font_bold" style="font-size:50%;color:#000000;"><span id="lstnumberx16.3.1" class="ltx_text ltx_lst_space"> </span>10</span>
</div>
<div id="lstnumberx17" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">17</span><span id="lstnumberx17.1" class="ltx_text ltx_lst_space ltx_font_bold" style="font-size:50%;color:#000000;">          </span><span id="lstnumberx17.2" class="ltx_text ltx_lst_identifier ltx_font_bold" style="font-size:50%;color:#000000;">activation</span><span id="lstnumberx17.3" class="ltx_text ltx_font_bold" style="font-size:50%;color:#000000;"><span id="lstnumberx17.3.1" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx17.3.2" class="ltx_text ltx_lst_string ltx_font_typewriter ltx_font_medium" style="color:#0000FF;">"softmax"</span></span>
</div>
<div id="lstnumberx18" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">18</span><span id="lstnumberx18.1" class="ltx_text ltx_lst_space ltx_font_bold" style="font-size:50%;color:#000000;">  </span><span id="lstnumberx18.2" class="ltx_text ltx_lst_identifier ltx_font_bold" style="font-size:50%;color:#000000;">layers</span><span id="lstnumberx18.3" class="ltx_text"></span>
</div>
<div id="lstnumberx19" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">19</span><span id="lstnumberx19.1" class="ltx_text ltx_lst_space ltx_font_bold" style="font-size:50%;color:#000000;">    </span><span id="lstnumberx19.2" class="ltx_text ltx_font_bold" style="font-size:50%;color:#000000;">-</span><span id="lstnumberx19.3" class="ltx_text ltx_lst_space ltx_font_bold" style="font-size:50%;color:#000000;"> </span><span id="lstnumberx19.4" class="ltx_text ltx_lst_identifier ltx_font_bold" style="font-size:50%;color:#000000;">name</span><span id="lstnumberx19.5" class="ltx_text ltx_font_bold" style="font-size:50%;color:#000000;"><span id="lstnumberx19.5.1" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx19.5.2" class="ltx_text" style="color:#FF8000;">&amp;layer_1<span id="lstnumberx19.5.2.1" class="ltx_text ltx_lst_space"> </span>”layer_1”</span></span>
</div>
<div id="lstnumberx20" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">20</span><span id="lstnumberx20.1" class="ltx_text ltx_lst_space ltx_font_bold" style="font-size:50%;color:#000000;">      </span><span id="lstnumberx20.2" class="ltx_text ltx_lst_identifier ltx_font_bold" style="font-size:50%;color:#000000;">type</span><span id="lstnumberx20.3" class="ltx_text ltx_font_bold" style="font-size:50%;color:#000000;"><span id="lstnumberx20.3.1" class="ltx_text ltx_lst_space"> </span>Conv2D</span>
</div>
<div id="lstnumberx21" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">21</span><span id="lstnumberx21.1" class="ltx_text ltx_lst_space ltx_font_bold" style="font-size:50%;color:#000000;">      </span><span id="lstnumberx21.2" class="ltx_text ltx_lst_identifier ltx_font_bold" style="font-size:50%;color:#000000;">input</span><span id="lstnumberx21.3" class="ltx_text ltx_font_bold" style="font-size:50%;color:#000000;"><span id="lstnumberx21.3.1" class="ltx_text ltx_lst_space"> </span>[auto]</span>
</div>
<div id="lstnumberx22" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">22</span><span id="lstnumberx22.1" class="ltx_text ltx_lst_space ltx_font_bold" style="font-size:50%;color:#000000;">      </span><span id="lstnumberx22.2" class="ltx_text ltx_lst_identifier ltx_font_bold" style="font-size:50%;color:#000000;">params</span><span id="lstnumberx22.3" class="ltx_text ltx_font_bold" style="font-size:50%;color:#000000;"><span id="lstnumberx22.3.1" class="ltx_text ltx_lst_space"> </span>[…]</span>
</div>
<div id="lstnumberx23" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">23</span><span id="lstnumberx23.1" class="ltx_text ltx_lst_space ltx_font_bold" style="font-size:50%;color:#000000;">    </span><span id="lstnumberx23.2" class="ltx_text ltx_font_bold" style="font-size:50%;color:#000000;">-</span><span id="lstnumberx23.3" class="ltx_text ltx_lst_space ltx_font_bold" style="font-size:50%;color:#000000;"> </span><span id="lstnumberx23.4" class="ltx_text ltx_lst_identifier ltx_font_bold" style="font-size:50%;color:#000000;">name</span><span id="lstnumberx23.5" class="ltx_text ltx_font_bold" style="font-size:50%;color:#000000;"><span id="lstnumberx23.5.1" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx23.5.2" class="ltx_text" style="color:#FF8000;">&amp;layer_2<span id="lstnumberx23.5.2.1" class="ltx_text ltx_lst_space"> </span>”layer_2”</span></span>
</div>
<div id="lstnumberx24" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">24</span><span id="lstnumberx24.1" class="ltx_text ltx_lst_space ltx_font_bold" style="font-size:50%;color:#000000;">      </span><span id="lstnumberx24.2" class="ltx_text ltx_lst_identifier ltx_font_bold" style="font-size:50%;color:#000000;">type</span><span id="lstnumberx24.3" class="ltx_text ltx_font_bold" style="font-size:50%;color:#000000;"><span id="lstnumberx24.3.1" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx24.3.2" class="ltx_text ltx_lst_string ltx_font_typewriter ltx_font_medium" style="color:#0000FF;">"ReferenceBlock"</span></span>
</div>
<div id="lstnumberx25" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">25</span><span id="lstnumberx25.1" class="ltx_text ltx_lst_space ltx_font_bold" style="font-size:50%;color:#000000;">      </span><span id="lstnumberx25.2" class="ltx_text ltx_lst_identifier ltx_font_bold" style="font-size:50%;color:#000000;">input</span><span id="lstnumberx25.3" class="ltx_text ltx_font_bold" style="font-size:50%;color:#000000;"><span id="lstnumberx25.3.1" class="ltx_text ltx_lst_space"> </span>[<span id="lstnumberx25.3.2" class="ltx_text" style="color:#FF00FF;">*layer_1]</span></span>
</div>
<div id="lstnumberx26" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">26</span><span id="lstnumberx26.1" class="ltx_text ltx_lst_space ltx_font_bold" style="font-size:50%;color:#000000;">      </span><span id="lstnumberx26.2" class="ltx_text ltx_lst_identifier ltx_font_bold" style="font-size:50%;color:#000000;">layers</span><span id="lstnumberx26.3" class="ltx_text ltx_font_bold" style="font-size:50%;color:#000000;"><span id="lstnumberx26.3.1" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx26.3.2" class="ltx_text" style="color:#FF00FF;">*ref_block</span></span>
</div>
<div id="lstnumberx27" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">27</span><span id="lstnumberx27.1" class="ltx_text ltx_lst_space ltx_font_bold" style="font-size:50%;color:#000000;">  </span><span id="lstnumberx27.2" class="ltx_text ltx_lst_identifier ltx_font_bold" style="font-size:50%;color:#000000;">outputs</span><span id="lstnumberx27.3" class="ltx_text ltx_font_bold" style="font-size:50%;color:#000000;"><span id="lstnumberx27.3.1" class="ltx_text ltx_lst_space"> </span>[<span id="lstnumberx27.3.2" class="ltx_text" style="color:#FF00FF;">*layer_1,<span id="lstnumberx27.3.2.1" class="ltx_text ltx_lst_space"> </span>*layer_2]</span></span>
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_float">Listing 1: </span>Example model description representing a 3-layer CNN in <span id="LST1.3.1" class="ltx_text ltx_font_typewriter">YAML</span>. Ellipses signify parameters that are omitted for brevity.</figcaption>
</figure>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2. </span>Model-agnostic Serverless FL</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">Existing research on model-agnostic KD is limited to conventional Infrastructure-as-a-Service (IaaS) based FL systems (§<a href="#S2.SS1" title="2.1. Knowledge Distillation in FL ‣ 2. Background ‣ Training Heterogeneous Client Models using Knowledge Distillation in Serverless Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.1</span></a>). In addition, the experiments performed for <span id="S3.SS2.p1.1.1" class="ltx_text ltx_font_typewriter">FedMD</span> <cite class="ltx_cite ltx_citemacro_citep">(Li and Wang, <a href="#bib.bib36" title="" class="ltx_ref">2019</a>)</cite> are simulated locally with only <math id="S3.SS2.p1.1.m1.1" class="ltx_Math" alttext="10" display="inline"><semantics id="S3.SS2.p1.1.m1.1a"><mn id="S3.SS2.p1.1.m1.1.1" xref="S3.SS2.p1.1.m1.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.m1.1b"><cn type="integer" id="S3.SS2.p1.1.m1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.1.m1.1c">10</annotation></semantics></math> participating clients and overlook crucial infrastructure components. As a result, they fail to provide a comprehensive understanding of the algorithm performance in distributed settings, which involves factors such as system heterogeneity and stragglers <cite class="ltx_cite ltx_citemacro_citep">(Huba et al<span class="ltx_text">.</span>, <a href="#bib.bib24" title="" class="ltx_ref">2022</a>)</cite>. Moreover, the performed experiments do not account for varying levels of data heterogeneity among FL clients. Similarly, for <span id="S3.SS2.p1.1.2" class="ltx_text ltx_font_typewriter">FedDF</span> <cite class="ltx_cite ltx_citemacro_citep">(Lin et al<span class="ltx_text">.</span>, <a href="#bib.bib38" title="" class="ltx_ref">2020</a>)</cite>, little emphasis has been placed on the distributed infrastructure, its optimization, and execution time in such settings, leaving these aspects as future work.
To the best of our knowledge, this work represents the first implementations of multiple KD algorithms within the serverless FL paradigm. Furthermore, we comprehensively analyze the performance and cost of the two algorithms in a distributed setting with 100 participating clients for multiple ML tasks.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4. </span>System Design</h2>

<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1. </span>Supporting Heterogeneous Client Model Architectures</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">The initial version of <em id="S4.SS1.p1.1.1" class="ltx_emph ltx_font_italic">FedLess</em> <cite class="ltx_cite ltx_citemacro_citep">(Grafberger et al<span class="ltx_text">.</span>, <a href="#bib.bib18" title="" class="ltx_ref">2021</a>)</cite> only supports FL with homogenous client model architectures managed by the controller (Figure <a href="#S4.F5" title="Figure 5 ‣ 4.1. Supporting Heterogeneous Client Model Architectures ‣ 4. System Design ‣ Training Heterogeneous Client Models using Knowledge Distillation in Serverless Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>). To enable heterogeneous model training, we extend <em id="S4.SS1.p1.1.2" class="ltx_emph ltx_font_italic">FedLess</em> to create and initialize diverse model architectures for each FL <span id="S4.SS1.p1.1.3" class="ltx_text ltx_font_typewriter">client</span> based on the input configuration. Towards this, we implement a <span id="S4.SS1.p1.1.4" class="ltx_text ltx_font_typewriter">Model Loader</span> module that parses a human-readable network configuration <span id="S4.SS1.p1.1.5" class="ltx_text ltx_font_typewriter">YAML</span> file to generate and train arbitrary DNN models.
Our module generates a directed acyclic graph (DAG) representing the DNN model from the input file that can be used directly to initialize a model in <span id="S4.SS1.p1.1.6" class="ltx_text ltx_font_typewriter">TensorFlow</span>.</p>
</div>
<div id="S4.SS1.p2" class="ltx_para">
<p id="S4.SS1.p2.1" class="ltx_p">Listing <a href="#LST1" title="Listing 1 ‣ 3.1. Serverless Federated Learning ‣ 3. Related Work ‣ Training Heterogeneous Client Models using Knowledge Distillation in Serverless Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> shows an example DNN model description written in <span id="S4.SS1.p2.1.1" class="ltx_text ltx_font_typewriter">YAML</span>. Each element under the key <span id="S4.SS1.p2.1.2" class="ltx_text ltx_font_typewriter">layers</span> describes a neural network unit where its inputs, parameters, and layer type are specified. Our module currently supports all layer types present till Keras version <span id="S4.SS1.p2.1.3" class="ltx_text ltx_font_typewriter">2.7</span>. A <span id="S4.SS1.p2.1.4" class="ltx_text ltx_font_typewriter">block</span> represents a repeatable collection of layers that can be defined once and re-used throughout the configuration file to define a network. To resolve dependencies between layers, our module relies on the key <span id="S4.SS1.p2.1.5" class="ltx_text ltx_font_typewriter">name</span> for each layer. In addition, we use the anchor-alias (<span id="S4.SS1.p2.1.6" class="ltx_text ltx_font_typewriter">&amp;,*</span>) syntax from the <span id="S4.SS1.p2.1.7" class="ltx_text ltx_font_typewriter">YAML</span> standard to enable easy referencing and dereferencing of elements. For instance, the <span id="S4.SS1.p2.1.8" class="ltx_text ltx_font_typewriter">layers</span> elements in the block are referred to as <span id="S4.SS1.p2.1.9" class="ltx_text ltx_font_typewriter">&amp;ref_block</span> in Line 7. After the file is parsed, those elements will appear as layers in the second layer (Line 26) due to the alias <span id="S4.SS1.p2.1.10" class="ltx_text ltx_font_typewriter">*ref_block</span>. However, due to the dynamic nature of
referenceable blocks, defining inputs may lead to duplicating keys in the configuration file. To avoid this, our module uses the keyword <span id="S4.SS1.p2.1.11" class="ltx_text ltx_font_typewriter">auto</span> to support automatic input interpretation. If a layer sets its input as <span id="S4.SS1.p2.1.12" class="ltx_text ltx_font_typewriter">auto</span> then our module uses its parent to resolve its inputs. For instance, <span id="S4.SS1.p2.1.13" class="ltx_text ltx_font_typewriter">&amp;lay_1_ref</span> (Line 8) will take its input from the input value described in Line 25. This relation between referenced blocks and the parent’s inputs enables nested blocks beyond the first-level nesting shown in Listing <a href="#LST1" title="Listing 1 ‣ 3.1. Serverless Federated Learning ‣ 3. Related Work ‣ Training Heterogeneous Client Models using Knowledge Distillation in Serverless Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. To this end, our implemented module offers data holders the flexibility to select any model architecture for their clients.</p>
</div>
<figure id="S4.F5" class="ltx_figure"><img src="/html/2402.07295/assets/x5.png" id="S4.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="415" height="316" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F5.3.1.1" class="ltx_text" style="font-size:90%;">Figure 5</span>. </span><span id="S4.F5.4.2" class="ltx_text" style="font-size:90%;">Proposed extensions (green) to <span id="S4.F5.4.2.1" class="ltx_text ltx_font_typewriter">FedLess</span> <cite class="ltx_cite ltx_citemacro_citep">(Grafberger et al<span class="ltx_text">.</span>, <a href="#bib.bib18" title="" class="ltx_ref">2021</a>)</cite>.</span></figcaption>
</figure>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2. </span>Extending FedLess</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">Figure <a href="#S4.F5" title="Figure 5 ‣ 4.1. Supporting Heterogeneous Client Model Architectures ‣ 4. System Design ‣ Training Heterogeneous Client Models using Knowledge Distillation in Serverless Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> presents an overview of the enhanced system architecture of <em id="S4.SS2.p1.1.1" class="ltx_emph ltx_font_italic">FedLess</em>. The highlighted components in green represent our specific extensions to enable serverless KD with the system. To support unique model architectures for each FL client, we added a <em id="S4.SS2.p1.1.2" class="ltx_emph ltx_font_italic">Client Parameter Server</em>. This parameter server is a <span id="S4.SS2.p1.1.3" class="ltx_text ltx_font_typewriter">MongoDB</span> instance responsible for storing the model architecture and its hyperparameters for each client. To optimize certain steps in the workflow of the two individual algorithms, we made two major changes to the system. These changes are described in the following two aspects.</p>
</div>
<section id="S4.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.1. </span>Serverless Parallel Transfer Learning for <span id="S4.SS2.SSS1.1.1" class="ltx_text ltx_font_typewriter">FedMD</span>
</h4>

<div id="S4.SS2.SSS1.p1" class="ltx_para">
<p id="S4.SS2.SSS1.p1.1" class="ltx_p">Prior to the distillation process, the <span id="S4.SS2.SSS1.p1.1.1" class="ltx_text ltx_font_typewriter">FedMD</span> algorithm requires an initial pre-training phase where all heterogeneous client models are trained on the public dataset until convergence (§<a href="#S2.SS2" title="2.2. FedMD ‣ 2. Background ‣ Training Heterogeneous Client Models using Knowledge Distillation in Serverless Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.2</span></a>). However, the time-intensive nature of this training process prevents its execution directly within the FaaS-based FL clients due to function time limitations imposed by most commercial FaaS platforms. For instance, AWS Lambda restricts the maximum function execution time to <math id="S4.SS2.SSS1.p1.1.m1.1" class="ltx_Math" alttext="15" display="inline"><semantics id="S4.SS2.SSS1.p1.1.m1.1a"><mn id="S4.SS2.SSS1.p1.1.m1.1.1" xref="S4.SS2.SSS1.p1.1.m1.1.1.cmml">15</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS1.p1.1.m1.1b"><cn type="integer" id="S4.SS2.SSS1.p1.1.m1.1.1.cmml" xref="S4.SS2.SSS1.p1.1.m1.1.1">15</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS1.p1.1.m1.1c">15</annotation></semantics></math> minutes <cite class="ltx_cite ltx_citemacro_citep">(lam, <a href="#bib.bib2" title="" class="ltx_ref">2023</a>)</cite>. Towards this, we extend <em id="S4.SS2.SSS1.p1.1.2" class="ltx_emph ltx_font_italic">FedLess</em> with the popular <span id="S4.SS2.SSS1.p1.1.3" class="ltx_text ltx_font_typewriter">Ray</span> <cite class="ltx_cite ltx_citemacro_citep">(Moritz et al<span class="ltx_text">.</span>, <a href="#bib.bib42" title="" class="ltx_ref">2018</a>)</cite> distributed computing platform. We chose <span id="S4.SS2.SSS1.p1.1.4" class="ltx_text ltx_font_typewriter">Ray</span> due to its several advantages, such as arbitrarily long serverless functions, support for accelerators such as GPUs, seamless integration with popular Python libraries such as <span id="S4.SS2.SSS1.p1.1.5" class="ltx_text ltx_font_typewriter">numpy</span> and <span id="S4.SS2.SSS1.p1.1.6" class="ltx_text ltx_font_typewriter">Tensorflow</span>, and its elastic autoscaling capabilities. We deploy <span id="S4.SS2.SSS1.p1.1.7" class="ltx_text ltx_font_typewriter">Ray</span> on top of Kubernetes (k8s) using the <span id="S4.SS2.SSS1.p1.1.8" class="ltx_text ltx_font_typewriter">KubeRay</span> operator. In addition, we utilize the Ray tune <cite class="ltx_cite ltx_citemacro_citep">(Liaw et al<span class="ltx_text">.</span>, <a href="#bib.bib37" title="" class="ltx_ref">2018</a>)</cite> feature that enables seamless distributed parallel training of individual client models. The <em id="S4.SS2.SSS1.p1.1.9" class="ltx_emph ltx_font_italic">FedLess</em> controller can directly invoke client function instances for model training on the <span id="S4.SS2.SSS1.p1.1.10" class="ltx_text ltx_font_typewriter">Ray</span> cluster. On invocation, Ray creates <span id="S4.SS2.SSS1.p1.1.11" class="ltx_text ltx_font_italic">actors</span> for each client function instance <cite class="ltx_cite ltx_citemacro_citep">(Moritz et al<span class="ltx_text">.</span>, <a href="#bib.bib42" title="" class="ltx_ref">2018</a>)</cite>. These actors are independent Python processes that execute in a distributed and parallel manner across the cluster.
Depending on the number of function invocations, Ray’s autoscaler can request additional k8s pods to execute the client functions in parallel. Moreover, the autoscaler can also aggressively scale the number of pods to zero when resources are unused. By leveraging <span id="S4.SS2.SSS1.p1.1.12" class="ltx_text ltx_font_typewriter">Ray</span> in <em id="S4.SS2.SSS1.p1.1.13" class="ltx_emph ltx_font_italic">FedLess</em>, we can parallelize the initial transfer learning process using functions, support a large number of FL clients, and optimize resource utilization. To facilitate ease of use, we provide scripts to setup and configure <span id="S4.SS2.SSS1.p1.1.14" class="ltx_text ltx_font_typewriter">Ray</span> with <em id="S4.SS2.SSS1.p1.1.15" class="ltx_emph ltx_font_italic">FedLess</em>.</p>
</div>
</section>
<section id="S4.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.2. </span>Serverless Parallel Ensemble Distillation for <span id="S4.SS2.SSS2.1.1" class="ltx_text ltx_font_typewriter">FedDF</span>
</h4>

<div id="S4.SS2.SSS2.p1" class="ltx_para">
<p id="S4.SS2.SSS2.p1.1" class="ltx_p">The <span id="S4.SS2.SSS2.p1.1.1" class="ltx_text ltx_font_typewriter">FedDF</span> algorithm incorporates an ensemble distillation process, where knowledge is transferred from multiple teacher client models with heterogeneous architectures to a student server model (§<a href="#S2.SS3" title="2.3. FedDF ‣ 2. Background ‣ Training Heterogeneous Client Models using Knowledge Distillation in Serverless Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.3</span></a>). In the original <span id="S4.SS2.SSS2.p1.1.2" class="ltx_text ltx_font_typewriter">FedDF</span> implementation <cite class="ltx_cite ltx_citemacro_citep">(Lin et al<span class="ltx_text">.</span>, <a href="#bib.bib38" title="" class="ltx_ref">2020</a>)</cite>, this process is performed sequentially for each unique model architecture. However, since there are no dependencies across model architectures, this step can be easily parallelized. Towards this, we extend <em id="S4.SS2.SSS2.p1.1.3" class="ltx_emph ltx_font_italic">FedLess</em> to support multiple aggregator functions. Each aggregator function is responsible for performing the ensemble distillation process for a specific model architecture. These functions are triggered in parallel as soon as the distillation process begins. Moreover, these functions are generic and can be implemented using any FaaS platform. This design choice provides developers greater flexibility and prevents vendor/platform lock-in. To enable ease of development, we provide reference implementations of these functions for <span id="S4.SS2.SSS2.p1.1.4" class="ltx_text ltx_font_typewriter">OpenFaaS</span> <cite class="ltx_cite ltx_citemacro_citep">(OpenFaaS, <a href="#bib.bib44" title="" class="ltx_ref">2019</a>)</cite> and <span id="S4.SS2.SSS2.p1.1.5" class="ltx_text ltx_font_typewriter">Knative</span> platforms. By parallelizing ensemble distillation across model architectures in <em id="S4.SS2.SSS2.p1.1.6" class="ltx_emph ltx_font_italic">FedLess</em>, we can significantly decrease training times in practical FL systems, as demonstrated in our evaluation.</p>
</div>
<figure id="S4.F6" class="ltx_figure"><img src="/html/2402.07295/assets/x6.png" id="S4.F6.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="298" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F6.3.1.1" class="ltx_text" style="font-size:90%;">Figure 6</span>. </span><span id="S4.F6.4.2" class="ltx_text" style="font-size:90%;">Serverless <span id="S4.F6.4.2.1" class="ltx_text ltx_font_typewriter">FedMD</span> workflow.</span></figcaption>
</figure>
</section>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5. </span>Serverless Knowledge Distillation</h2>

<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1. </span>Serverless FedMD</h3>

<div id="S5.SS1.p1" class="ltx_para">
<p id="S5.SS1.p1.1" class="ltx_p">The training workflow for <span id="S5.SS1.p1.1.1" class="ltx_text ltx_font_typewriter">FedMD</span> in the serverless paradigm with <em id="S5.SS1.p1.1.2" class="ltx_emph ltx_font_italic">FedLess</em> is shown in Figure <a href="#S4.F6" title="Figure 6 ‣ 4.2.2. Serverless Parallel Ensemble Distillation for FedDF ‣ 4.2. Extending FedLess ‣ 4. System Design ‣ Training Heterogeneous Client Models using Knowledge Distillation in Serverless Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>. For simplicity, we omit some technical details related to the authentication/authorization of client functions, as well as some other minor interactions with the parameter server. Initially, the FL admin configures the client models, datasets, and the required client and <span id="S5.SS1.p1.1.3" class="ltx_text ltx_font_typewriter">FedMD</span>-specific hyperparameters before starting the training process. Following this, the <em id="S5.SS1.p1.1.4" class="ltx_emph ltx_font_italic">FedLess</em> controller (§<a href="#S4" title="4. System Design ‣ Training Heterogeneous Client Models using Knowledge Distillation in Serverless Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>) initializes the heterogeneous client models according to the provided configuration files (§<a href="#S4.SS1" title="4.1. Supporting Heterogeneous Client Model Architectures ‣ 4. System Design ‣ Training Heterogeneous Client Models using Knowledge Distillation in Serverless Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.1</span></a>) and creates the required data loaders for each client. In <span id="S5.SS1.p1.1.5" class="ltx_text ltx_font_typewriter">FedMD</span>, each FL client has access to three datasets: (i) a private training dataset, (ii) a private testing dataset, and a (iii) public training dataset (§<a href="#S2.SS2" title="2.2. FedMD ‣ 2. Background ‣ Training Heterogeneous Client Models using Knowledge Distillation in Serverless Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.2</span></a>). After this, we perform a one-time initial transfer learning process for all the individual client models before starting the collaboration phase (§<a href="#S2.SS2" title="2.2. FedMD ‣ 2. Background ‣ Training Heterogeneous Client Models using Knowledge Distillation in Serverless Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.2</span></a>). To optimize this process, we divide it into two consecutive steps. In the initial step, we leverage <span id="S5.SS1.p1.1.6" class="ltx_text ltx_font_typewriter">Ray</span> (§<a href="#S4.SS2.SSS1" title="4.2.1. Serverless Parallel Transfer Learning for FedMD ‣ 4.2. Extending FedLess ‣ 4. System Design ‣ Training Heterogeneous Client Models using Knowledge Distillation in Serverless Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.2.1</span></a>) to simultaneously train all client models on the public dataset until convergence. In the second step, the controller triggers individual FL clients to perform additional training of their models on their private datasets. Following the initial transfer learning phase, we proceed to the collaborative training rounds, where the clients engage in knowledge distillation to collectively improve overall test accuracies. Each collaborative training round consists of five steps, which are executed as individual invocations of FL clients and the aggregator. In the communication step, all FL clients generate predictions on a random subset of the public dataset and store the corresponding prediction logits in <span id="S5.SS1.p1.1.7" class="ltx_text ltx_font_typewriter">MongoDB</span>. Following this, the controller invokes the aggregator function, which aggregates the prediction logits from all the FL clients. In the digest step, each client trains its model to approach the aggregated prediction logits. The objective is to achieve logit alignment, thereby facilitating knowledge distillation among the clients. Following this, each client fine-tunes their model on their private dataset for a few epochs for model personalization. Finally, in the evaluation step, the controller performs an evaluation invocation to obtain the performance of each client model on the public test dataset. The five different steps continue until the desired accuracy is reached on the individual client models.</p>
</div>
<figure id="S5.F7" class="ltx_figure"><img src="/html/2402.07295/assets/x7.png" id="S5.F7.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="260" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F7.3.1.1" class="ltx_text" style="font-size:90%;">Figure 7</span>. </span><span id="S5.F7.4.2" class="ltx_text" style="font-size:90%;">Serverless <span id="S5.F7.4.2.1" class="ltx_text ltx_font_typewriter">FedDF</span> workflow.</span></figcaption>
</figure>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2. </span>Serverless FedDF</h3>

<div id="S5.SS2.p1" class="ltx_para">
<p id="S5.SS2.p1.1" class="ltx_p">Figure <a href="#S5.F7" title="Figure 7 ‣ 5.1. Serverless FedMD ‣ 5. Serverless Knowledge Distillation ‣ Training Heterogeneous Client Models using Knowledge Distillation in Serverless Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> shows the training workflow for the server-side distillation algorithm <span id="S5.SS2.p1.1.1" class="ltx_text ltx_font_typewriter">FedDF</span> with <em id="S5.SS2.p1.1.2" class="ltx_emph ltx_font_italic">FedLess</em>. Similar to <span id="S5.SS2.p1.1.3" class="ltx_text ltx_font_typewriter">FedMD</span> (<a href="#S5.SS1" title="5.1. Serverless FedMD ‣ 5. Serverless Knowledge Distillation ‣ Training Heterogeneous Client Models using Knowledge Distillation in Serverless Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.1</span></a>), the FL admin first configures the client models, datasets, as well as the required client and <span id="S5.SS2.p1.1.4" class="ltx_text ltx_font_typewriter">FedDF</span>-specific hyperparameters before starting the training process. After this, the iterative training process in <span id="S5.SS2.p1.1.5" class="ltx_text ltx_font_typewriter">FedDF</span> is initiated. In the original <span id="S5.SS2.p1.1.6" class="ltx_text ltx_font_typewriter">FedDF</span> <cite class="ltx_cite ltx_citemacro_citep">(Lin et al<span class="ltx_text">.</span>, <a href="#bib.bib38" title="" class="ltx_ref">2020</a>)</cite> algorithm (§<a href="#S2.SS3" title="2.3. FedDF ‣ 2. Background ‣ Training Heterogeneous Client Models using Knowledge Distillation in Serverless Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.3</span></a>), a random subset of clients is selected to participate in each training round. However, due to resource and statistical heterogeneity of clients in FL, random selection can often lead to significantly higher training times because of <span id="S5.SS2.p1.1.7" class="ltx_text ltx_font_italic">stragglers</span>, i.e., slow clients <cite class="ltx_cite ltx_citemacro_citep">(Lai et al<span class="ltx_text">.</span>, <a href="#bib.bib34" title="" class="ltx_ref">2020</a>)</cite>. To mitigate this, we adapt the intelligent clustering-based client selection algorithm in <span id="S5.SS2.p1.1.8" class="ltx_text ltx_font_typewriter">FedLesScan</span> <cite class="ltx_cite ltx_citemacro_citep">(Elzohairy et al<span class="ltx_text">.</span>, <a href="#bib.bib14" title="" class="ltx_ref">2022</a>)</cite> and integrate it with <span id="S5.SS2.p1.1.9" class="ltx_text ltx_font_typewriter">FedDF</span>. <span id="S5.SS2.p1.1.10" class="ltx_text ltx_font_typewriter">FedLesScan</span> is a training strategy designed to facilitate efficient FL in serverless environments. It incorporates an adaptive clustering-based client selection algorithm that selects a subset of clients for
training based on their behavior in previous training rounds. However, the original clustering process in <span id="S5.SS2.p1.1.11" class="ltx_text ltx_font_typewriter">FedLesScan</span> does not account for the heterogeneous client model architectures. This is important because clustering metrics such as training times can vary based on the complexity of different model architectures. In the extended version of <span id="S5.SS2.p1.1.12" class="ltx_text ltx_font_typewriter">FedLesScan</span>, we first perform clustering among clients having the same model architecture. Following this, we perform a round-robin selection of the <span id="S5.SS2.p1.1.13" class="ltx_text ltx_font_italic">sorted clients</span> <cite class="ltx_cite ltx_citemacro_citep">(Elzohairy et al<span class="ltx_text">.</span>, <a href="#bib.bib14" title="" class="ltx_ref">2022</a>)</cite> from each client model architecture group until the desired number of clients is selected. For sorting clients, we use the metric exponential moving average that relies on the training duration of clients.</p>
</div>
<div id="S5.SS2.p2" class="ltx_para">
<p id="S5.SS2.p2.1" class="ltx_p">In the initial step of the iterative training process, the controller uses our adapted <span id="S5.SS2.p2.1.1" class="ltx_text ltx_font_typewriter">FedLesScan</span> algorithm to intelligently select a subset of clients from the client pool. Following this, the chosen clients are invoked to perform training on their private datasets. After training, the clients store the updated models back in the <span id="S5.SS2.p2.1.2" class="ltx_text ltx_font_typewriter">MongoDB</span> database. Once all clients have finished training, the controller invokes the different aggregator functions for the ensemble distillation process (§<a href="#S4.SS2.SSS2" title="4.2.2. Serverless Parallel Ensemble Distillation for FedDF ‣ 4.2. Extending FedLess ‣ 4. System Design ‣ Training Heterogeneous Client Models using Knowledge Distillation in Serverless Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.2.2</span></a>,§<a href="#S2.SS3" title="2.3. FedDF ‣ 2. Background ‣ Training Heterogeneous Client Models using Knowledge Distillation in Serverless Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.3</span></a>). These aggregator functions are invoked in parallel for each unique client model architecture. After completion, each aggregator function updates the weights of clients associated with their particular model architecture with the obtained new distilled weights. The iterative training process continues until a desired test accuracy is reached for each model architecture.</p>
</div>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6. </span>Experimental Setup</h2>

<section id="S6.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.1. </span>Datasets</h3>

<div id="S6.SS1.p1" class="ltx_para">
<p id="S6.SS1.p1.1" class="ltx_p">In our experiments, we evaluate the implemented serverless KD algorithms (§<a href="#S5" title="5. Serverless Knowledge Distillation ‣ Training Heterogeneous Client Models using Knowledge Distillation in Serverless Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>) for a variety of tasks. Table <a href="#S6.T1" title="Table 1 ‣ 6.1. Datasets ‣ 6. Experimental Setup ‣ Training Heterogeneous Client Models using Knowledge Distillation in Serverless Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> shows the different public/private datasets for the two algorithms.</p>
</div>
<div id="S6.SS1.p2" class="ltx_para">
<p id="S6.SS1.p2.9" class="ltx_p">MNIST is a handwritten digit dataset comprising of <math id="S6.SS1.p2.1.m1.2" class="ltx_Math" alttext="60,000" display="inline"><semantics id="S6.SS1.p2.1.m1.2a"><mrow id="S6.SS1.p2.1.m1.2.3.2" xref="S6.SS1.p2.1.m1.2.3.1.cmml"><mn id="S6.SS1.p2.1.m1.1.1" xref="S6.SS1.p2.1.m1.1.1.cmml">60</mn><mo id="S6.SS1.p2.1.m1.2.3.2.1" xref="S6.SS1.p2.1.m1.2.3.1.cmml">,</mo><mn id="S6.SS1.p2.1.m1.2.2" xref="S6.SS1.p2.1.m1.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.SS1.p2.1.m1.2b"><list id="S6.SS1.p2.1.m1.2.3.1.cmml" xref="S6.SS1.p2.1.m1.2.3.2"><cn type="integer" id="S6.SS1.p2.1.m1.1.1.cmml" xref="S6.SS1.p2.1.m1.1.1">60</cn><cn type="integer" id="S6.SS1.p2.1.m1.2.2.cmml" xref="S6.SS1.p2.1.m1.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.p2.1.m1.2c">60,000</annotation></semantics></math> training images and <math id="S6.SS1.p2.2.m2.2" class="ltx_Math" alttext="10,000" display="inline"><semantics id="S6.SS1.p2.2.m2.2a"><mrow id="S6.SS1.p2.2.m2.2.3.2" xref="S6.SS1.p2.2.m2.2.3.1.cmml"><mn id="S6.SS1.p2.2.m2.1.1" xref="S6.SS1.p2.2.m2.1.1.cmml">10</mn><mo id="S6.SS1.p2.2.m2.2.3.2.1" xref="S6.SS1.p2.2.m2.2.3.1.cmml">,</mo><mn id="S6.SS1.p2.2.m2.2.2" xref="S6.SS1.p2.2.m2.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.SS1.p2.2.m2.2b"><list id="S6.SS1.p2.2.m2.2.3.1.cmml" xref="S6.SS1.p2.2.m2.2.3.2"><cn type="integer" id="S6.SS1.p2.2.m2.1.1.cmml" xref="S6.SS1.p2.2.m2.1.1">10</cn><cn type="integer" id="S6.SS1.p2.2.m2.2.2.cmml" xref="S6.SS1.p2.2.m2.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.p2.2.m2.2c">10,000</annotation></semantics></math> testing images. It has ten classes corresponding to the respective digits. On the other hand, EMNIST Letters consists of handwritten letters from the English language, comprising 145,600 characters distributed evenly among 26 classes. For more complex image classification tasks, we use the CIFAR-10 and CIFAR-100 datasets. Both datasets have <math id="S6.SS1.p2.3.m3.2" class="ltx_Math" alttext="60,000" display="inline"><semantics id="S6.SS1.p2.3.m3.2a"><mrow id="S6.SS1.p2.3.m3.2.3.2" xref="S6.SS1.p2.3.m3.2.3.1.cmml"><mn id="S6.SS1.p2.3.m3.1.1" xref="S6.SS1.p2.3.m3.1.1.cmml">60</mn><mo id="S6.SS1.p2.3.m3.2.3.2.1" xref="S6.SS1.p2.3.m3.2.3.1.cmml">,</mo><mn id="S6.SS1.p2.3.m3.2.2" xref="S6.SS1.p2.3.m3.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.SS1.p2.3.m3.2b"><list id="S6.SS1.p2.3.m3.2.3.1.cmml" xref="S6.SS1.p2.3.m3.2.3.2"><cn type="integer" id="S6.SS1.p2.3.m3.1.1.cmml" xref="S6.SS1.p2.3.m3.1.1">60</cn><cn type="integer" id="S6.SS1.p2.3.m3.2.2.cmml" xref="S6.SS1.p2.3.m3.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.p2.3.m3.2c">60,000</annotation></semantics></math> color images divided uniformly into ten and <math id="S6.SS1.p2.4.m4.1" class="ltx_Math" alttext="100" display="inline"><semantics id="S6.SS1.p2.4.m4.1a"><mn id="S6.SS1.p2.4.m4.1.1" xref="S6.SS1.p2.4.m4.1.1.cmml">100</mn><annotation-xml encoding="MathML-Content" id="S6.SS1.p2.4.m4.1b"><cn type="integer" id="S6.SS1.p2.4.m4.1.1.cmml" xref="S6.SS1.p2.4.m4.1.1">100</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.p2.4.m4.1c">100</annotation></semantics></math> mutually exclusive classes, respectively. For the language modeling domain, we use the Shakespeare dataset from the <span id="S6.SS1.p2.9.1" class="ltx_text ltx_font_typewriter">LEAF</span> <cite class="ltx_cite ltx_citemacro_citep">(Caldas et al<span class="ltx_text">.</span>, <a href="#bib.bib7" title="" class="ltx_ref">2018</a>)</cite> FL benchmark suite and the openly available Nietzsche text corpus <cite class="ltx_cite ltx_citemacro_citep">(nie, <a href="#bib.bib3" title="" class="ltx_ref">2023</a>)</cite>. The Shakespeare dataset consists of <math id="S6.SS1.p2.5.m5.3" class="ltx_Math" alttext="4,226,158" display="inline"><semantics id="S6.SS1.p2.5.m5.3a"><mrow id="S6.SS1.p2.5.m5.3.4.2" xref="S6.SS1.p2.5.m5.3.4.1.cmml"><mn id="S6.SS1.p2.5.m5.1.1" xref="S6.SS1.p2.5.m5.1.1.cmml">4</mn><mo id="S6.SS1.p2.5.m5.3.4.2.1" xref="S6.SS1.p2.5.m5.3.4.1.cmml">,</mo><mn id="S6.SS1.p2.5.m5.2.2" xref="S6.SS1.p2.5.m5.2.2.cmml">226</mn><mo id="S6.SS1.p2.5.m5.3.4.2.2" xref="S6.SS1.p2.5.m5.3.4.1.cmml">,</mo><mn id="S6.SS1.p2.5.m5.3.3" xref="S6.SS1.p2.5.m5.3.3.cmml">158</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.SS1.p2.5.m5.3b"><list id="S6.SS1.p2.5.m5.3.4.1.cmml" xref="S6.SS1.p2.5.m5.3.4.2"><cn type="integer" id="S6.SS1.p2.5.m5.1.1.cmml" xref="S6.SS1.p2.5.m5.1.1">4</cn><cn type="integer" id="S6.SS1.p2.5.m5.2.2.cmml" xref="S6.SS1.p2.5.m5.2.2">226</cn><cn type="integer" id="S6.SS1.p2.5.m5.3.3.cmml" xref="S6.SS1.p2.5.m5.3.3">158</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.p2.5.m5.3c">4,226,158</annotation></semantics></math> sequences of length <math id="S6.SS1.p2.6.m6.1" class="ltx_Math" alttext="80" display="inline"><semantics id="S6.SS1.p2.6.m6.1a"><mn id="S6.SS1.p2.6.m6.1.1" xref="S6.SS1.p2.6.m6.1.1.cmml">80</mn><annotation-xml encoding="MathML-Content" id="S6.SS1.p2.6.m6.1b"><cn type="integer" id="S6.SS1.p2.6.m6.1.1.cmml" xref="S6.SS1.p2.6.m6.1.1">80</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.p2.6.m6.1c">80</annotation></semantics></math> across <math id="S6.SS1.p2.7.m7.2" class="ltx_Math" alttext="1,129" display="inline"><semantics id="S6.SS1.p2.7.m7.2a"><mrow id="S6.SS1.p2.7.m7.2.3.2" xref="S6.SS1.p2.7.m7.2.3.1.cmml"><mn id="S6.SS1.p2.7.m7.1.1" xref="S6.SS1.p2.7.m7.1.1.cmml">1</mn><mo id="S6.SS1.p2.7.m7.2.3.2.1" xref="S6.SS1.p2.7.m7.2.3.1.cmml">,</mo><mn id="S6.SS1.p2.7.m7.2.2" xref="S6.SS1.p2.7.m7.2.2.cmml">129</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.SS1.p2.7.m7.2b"><list id="S6.SS1.p2.7.m7.2.3.1.cmml" xref="S6.SS1.p2.7.m7.2.3.2"><cn type="integer" id="S6.SS1.p2.7.m7.1.1.cmml" xref="S6.SS1.p2.7.m7.1.1">1</cn><cn type="integer" id="S6.SS1.p2.7.m7.2.2.cmml" xref="S6.SS1.p2.7.m7.2.2">129</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.p2.7.m7.2c">1,129</annotation></semantics></math> different users, while the Nietzsche dataset consists of <math id="S6.SS1.p2.8.m8.2" class="ltx_Math" alttext="200,271" display="inline"><semantics id="S6.SS1.p2.8.m8.2a"><mrow id="S6.SS1.p2.8.m8.2.3.2" xref="S6.SS1.p2.8.m8.2.3.1.cmml"><mn id="S6.SS1.p2.8.m8.1.1" xref="S6.SS1.p2.8.m8.1.1.cmml">200</mn><mo id="S6.SS1.p2.8.m8.2.3.2.1" xref="S6.SS1.p2.8.m8.2.3.1.cmml">,</mo><mn id="S6.SS1.p2.8.m8.2.2" xref="S6.SS1.p2.8.m8.2.2.cmml">271</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.SS1.p2.8.m8.2b"><list id="S6.SS1.p2.8.m8.2.3.1.cmml" xref="S6.SS1.p2.8.m8.2.3.2"><cn type="integer" id="S6.SS1.p2.8.m8.1.1.cmml" xref="S6.SS1.p2.8.m8.1.1">200</cn><cn type="integer" id="S6.SS1.p2.8.m8.2.2.cmml" xref="S6.SS1.p2.8.m8.2.2">271</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.p2.8.m8.2c">200,271</annotation></semantics></math> sequences of length <math id="S6.SS1.p2.9.m9.1" class="ltx_Math" alttext="80" display="inline"><semantics id="S6.SS1.p2.9.m9.1a"><mn id="S6.SS1.p2.9.m9.1.1" xref="S6.SS1.p2.9.m9.1.1.cmml">80</mn><annotation-xml encoding="MathML-Content" id="S6.SS1.p2.9.m9.1b"><cn type="integer" id="S6.SS1.p2.9.m9.1.1.cmml" xref="S6.SS1.p2.9.m9.1.1">80</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.p2.9.m9.1c">80</annotation></semantics></math>. In Shakespeare, each user has their own training and testing dataset. For both datasets, the task is to predict the next character given a sequence.</p>
</div>
<figure id="S6.T1" class="ltx_table">
<p id="S6.T1.2" class="ltx_p ltx_align_center"><span id="S6.T1.2.1" class="ltx_text ltx_inline-block" style="width:433.6pt;">
<span id="S6.T1.2.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:508.0pt;height:91pt;vertical-align:-1.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<span id="S6.T1.2.1.1.1" class="ltx_p"><span id="S6.T1.2.1.1.1.1" class="ltx_text">
<span id="S6.T1.2.1.1.1.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<span class="ltx_tbody">
<span id="S6.T1.2.1.1.1.1.1.1.1" class="ltx_tr">
<span id="S6.T1.2.1.1.1.1.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t ltx_rowspan ltx_rowspan_2"><span id="S6.T1.2.1.1.1.1.1.1.1.1.1" class="ltx_text">No.</span></span>
<span id="S6.T1.2.1.1.1.1.1.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t ltx_rowspan ltx_rowspan_2"><span id="S6.T1.2.1.1.1.1.1.1.1.2.1" class="ltx_text">Task</span></span>
<span id="S6.T1.2.1.1.1.1.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t ltx_rowspan ltx_rowspan_2"><span id="S6.T1.2.1.1.1.1.1.1.1.3.1" class="ltx_text">Type</span></span>
<span id="S6.T1.2.1.1.1.1.1.1.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t ltx_colspan ltx_colspan_2">FedMD</span>
<span id="S6.T1.2.1.1.1.1.1.1.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t ltx_colspan ltx_colspan_2">FedDF</span></span>
<span id="S6.T1.2.1.1.1.1.1.2.2" class="ltx_tr">
<span id="S6.T1.2.1.1.1.1.1.2.2.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Private</span>
<span id="S6.T1.2.1.1.1.1.1.2.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Public</span>
<span id="S6.T1.2.1.1.1.1.1.2.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Private</span>
<span id="S6.T1.2.1.1.1.1.1.2.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Public (Unlabeled)</span></span>
<span id="S6.T1.2.1.1.1.1.1.3.3" class="ltx_tr">
<span id="S6.T1.2.1.1.1.1.1.3.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">1</span>
<span id="S6.T1.2.1.1.1.1.1.3.3.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">CV</span>
<span id="S6.T1.2.1.1.1.1.1.3.3.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">Classification</span>
<span id="S6.T1.2.1.1.1.1.1.3.3.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">MNIST</span>
<span id="S6.T1.2.1.1.1.1.1.3.3.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">EMNIST Letters</span>
<span id="S6.T1.2.1.1.1.1.1.3.3.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">MNIST</span>
<span id="S6.T1.2.1.1.1.1.1.3.3.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">EMNIST Letters</span></span>
<span id="S6.T1.2.1.1.1.1.1.4.4" class="ltx_tr">
<span id="S6.T1.2.1.1.1.1.1.4.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">2</span>
<span id="S6.T1.2.1.1.1.1.1.4.4.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">CV</span>
<span id="S6.T1.2.1.1.1.1.1.4.4.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">Classification</span>
<span id="S6.T1.2.1.1.1.1.1.4.4.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">CIFAR100 (Subset)</span>
<span id="S6.T1.2.1.1.1.1.1.4.4.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">CIFAR10</span>
<span id="S6.T1.2.1.1.1.1.1.4.4.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">CIFAR10</span>
<span id="S6.T1.2.1.1.1.1.1.4.4.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">CIFAR100</span></span>
<span id="S6.T1.2.1.1.1.1.1.5.5" class="ltx_tr">
<span id="S6.T1.2.1.1.1.1.1.5.5.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r ltx_border_t">3</span>
<span id="S6.T1.2.1.1.1.1.1.5.5.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t">NLP</span>
<span id="S6.T1.2.1.1.1.1.1.5.5.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t">Character Prediction</span>
<span id="S6.T1.2.1.1.1.1.1.5.5.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">Shakespeare</span>
<span id="S6.T1.2.1.1.1.1.1.5.5.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">Nietzsche</span>
<span id="S6.T1.2.1.1.1.1.1.5.5.6" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">Shakespeare</span>
<span id="S6.T1.2.1.1.1.1.1.5.5.7" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">Nietzsche</span></span>
</span>
</span></span></span>
</span></span></span></p>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S6.T1.5.1.1" class="ltx_text" style="font-size:90%;">Table 1</span>. </span><span id="S6.T1.6.2" class="ltx_text" style="font-size:90%;">Evaluation tasks and datasets for serverless <span id="S6.T1.6.2.1" class="ltx_text ltx_font_typewriter">FedMD</span> and <span id="S6.T1.6.2.2" class="ltx_text ltx_font_typewriter">FedDF</span>.</span></figcaption>
</figure>
<figure id="S6.F8" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S6.F8.sf1" class="ltx_figure ltx_figure_panel"><img src="/html/2402.07295/assets/x8.png" id="S6.F8.sf1.g1" class="ltx_graphics ltx_centering ltx_img_square" width="300" height="310" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S6.F8.sf1.4.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S6.F8.sf1.5.2" class="ltx_text ltx_font_typewriter" style="font-size:90%;">FedMD<span id="S6.F8.sf1.5.2.1" class="ltx_text ltx_font_serif">/</span>FedDF<span id="S6.F8.sf1.5.2.2" class="ltx_text ltx_font_serif"> with MNIST.</span></span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S6.F8.sf2" class="ltx_figure ltx_figure_panel"><img src="/html/2402.07295/assets/x9.png" id="S6.F8.sf2.g1" class="ltx_graphics ltx_centering ltx_img_square" width="300" height="307" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S6.F8.sf2.3.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S6.F8.sf2.4.2" class="ltx_text ltx_font_typewriter" style="font-size:90%;">FedMD<span id="S6.F8.sf2.4.2.1" class="ltx_text ltx_font_serif"> with CIFAR-100 (Subset).</span></span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S6.F8.sf3" class="ltx_figure ltx_figure_panel"><img src="/html/2402.07295/assets/x10.png" id="S6.F8.sf3.g1" class="ltx_graphics ltx_centering ltx_img_square" width="300" height="310" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S6.F8.sf3.3.1.1" class="ltx_text" style="font-size:90%;">(c)</span> </span><span id="S6.F8.sf3.4.2" class="ltx_text ltx_font_typewriter" style="font-size:90%;">FedDF<span id="S6.F8.sf3.4.2.1" class="ltx_text ltx_font_serif"> with CIFAR-10.</span></span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S6.F8.4.2.1" class="ltx_text" style="font-size:90%;">Figure 8</span>. </span><span id="S6.F8.2.1" class="ltx_text" style="font-size:90%;">Private client training data distributions for the different algorithms and datasets for varying values of <math id="S6.F8.2.1.m1.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S6.F8.2.1.m1.1b"><mi id="S6.F8.2.1.m1.1.1" xref="S6.F8.2.1.m1.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S6.F8.2.1.m1.1c"><ci id="S6.F8.2.1.m1.1.1.cmml" xref="S6.F8.2.1.m1.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.F8.2.1.m1.1d">\alpha</annotation></semantics></math>. For a particular client ID, the size of each data point represents the number of samples belonging to a particular class.</span></figcaption>
</figure>
</section>
<section id="S6.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.2. </span>Heterogeneous Client Data Distribution</h3>

<div id="S6.SS2.p1" class="ltx_para">
<p id="S6.SS2.p1.2" class="ltx_p">One of the major challenges in FL is the non-independent and identical (non-IID) data distribution among the participating clients <cite class="ltx_cite ltx_citemacro_citep">(Hsieh et al<span class="ltx_text">.</span>, <a href="#bib.bib21" title="" class="ltx_ref">2020</a>)</cite> (§<a href="#S1" title="1. Introduction ‣ Training Heterogeneous Client Models using Knowledge Distillation in Serverless Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>). To analyze the behavior and robustness of the two serverless KD strategies toward different degrees of data heterogeneity, we use the Dirichlet distribution as in <cite class="ltx_cite ltx_citemacro_citep">(Hsu et al<span class="ltx_text">.</span>, <a href="#bib.bib22" title="" class="ltx_ref">2019</a>)</cite> to create disjoint non-IID client training data partitions. A parameter <math id="S6.SS2.p1.1.m1.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S6.SS2.p1.1.m1.1a"><mi id="S6.SS2.p1.1.m1.1.1" xref="S6.SS2.p1.1.m1.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S6.SS2.p1.1.m1.1b"><ci id="S6.SS2.p1.1.m1.1.1.cmml" xref="S6.SS2.p1.1.m1.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.p1.1.m1.1c">\alpha</annotation></semantics></math> controls the degree of non-IID data distribution, where a smaller <math id="S6.SS2.p1.2.m2.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S6.SS2.p1.2.m2.1a"><mi id="S6.SS2.p1.2.m2.1.1" xref="S6.SS2.p1.2.m2.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S6.SS2.p1.2.m2.1b"><ci id="S6.SS2.p1.2.m2.1.1.cmml" xref="S6.SS2.p1.2.m2.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.p1.2.m2.1c">\alpha</annotation></semantics></math> value increases the probability of clients holding training samples from only one class and vice-versa.</p>
</div>
<figure id="S6.T2" class="ltx_table">
<p id="S6.T2.2" class="ltx_p ltx_align_center"><span id="S6.T2.2.1" class="ltx_text ltx_inline-block" style="width:433.6pt;">
<span id="S6.T2.2.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:559.5pt;height:127pt;vertical-align:-1.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<span id="S6.T2.2.1.1.1" class="ltx_p"><span id="S6.T2.2.1.1.1.1" class="ltx_text">
<span id="S6.T2.2.1.1.1.1.1" class="ltx_tabular ltx_align_middle">
<span class="ltx_tbody">
<span id="S6.T2.2.1.1.1.1.1.1.1" class="ltx_tr">
<span id="S6.T2.2.1.1.1.1.1.1.1.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">Model ID</span>
<span id="S6.T2.2.1.1.1.1.1.1.1.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">#Clients</span>
<span id="S6.T2.2.1.1.1.1.1.1.1.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">#Layer 1 Conv. Filters</span>
<span id="S6.T2.2.1.1.1.1.1.1.1.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">#Layer 2 Conv. Filters</span>
<span id="S6.T2.2.1.1.1.1.1.1.1.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">#Layer 3 Conv. Filters</span>
<span id="S6.T2.2.1.1.1.1.1.1.1.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">#Trainable Parameters</span></span>
<span id="S6.T2.2.1.1.1.1.1.2.2" class="ltx_tr">
<span id="S6.T2.2.1.1.1.1.1.2.2.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">0</span>
<span id="S6.T2.2.1.1.1.1.1.2.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">10</span>
<span id="S6.T2.2.1.1.1.1.1.2.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">128</span>
<span id="S6.T2.2.1.1.1.1.1.2.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">256</span>
<span id="S6.T2.2.1.1.1.1.1.2.2.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">-</span>
<span id="S6.T2.2.1.1.1.1.1.2.2.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">729,856</span></span>
<span id="S6.T2.2.1.1.1.1.1.3.3" class="ltx_tr">
<span id="S6.T2.2.1.1.1.1.1.3.3.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">1</span>
<span id="S6.T2.2.1.1.1.1.1.3.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">30</span>
<span id="S6.T2.2.1.1.1.1.1.3.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">128</span>
<span id="S6.T2.2.1.1.1.1.1.3.3.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">512</span>
<span id="S6.T2.2.1.1.1.1.1.3.3.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">-</span>
<span id="S6.T2.2.1.1.1.1.1.3.3.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">1,458,176</span></span>
<span id="S6.T2.2.1.1.1.1.1.4.4" class="ltx_tr">
<span id="S6.T2.2.1.1.1.1.1.4.4.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">2</span>
<span id="S6.T2.2.1.1.1.1.1.4.4.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">20</span>
<span id="S6.T2.2.1.1.1.1.1.4.4.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">64</span>
<span id="S6.T2.2.1.1.1.1.1.4.4.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">128</span>
<span id="S6.T2.2.1.1.1.1.1.4.4.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">128</span>
<span id="S6.T2.2.1.1.1.1.1.4.4.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">193,280</span></span>
<span id="S6.T2.2.1.1.1.1.1.5.5" class="ltx_tr">
<span id="S6.T2.2.1.1.1.1.1.5.5.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">3</span>
<span id="S6.T2.2.1.1.1.1.1.5.5.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">20</span>
<span id="S6.T2.2.1.1.1.1.1.5.5.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">64</span>
<span id="S6.T2.2.1.1.1.1.1.5.5.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">128</span>
<span id="S6.T2.2.1.1.1.1.1.5.5.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">256</span>
<span id="S6.T2.2.1.1.1.1.1.5.5.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">352,640</span></span>
<span id="S6.T2.2.1.1.1.1.1.6.6" class="ltx_tr">
<span id="S6.T2.2.1.1.1.1.1.6.6.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">4</span>
<span id="S6.T2.2.1.1.1.1.1.6.6.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">10</span>
<span id="S6.T2.2.1.1.1.1.1.6.6.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">128</span>
<span id="S6.T2.2.1.1.1.1.1.6.6.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">128</span>
<span id="S6.T2.2.1.1.1.1.1.6.6.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">128</span>
<span id="S6.T2.2.1.1.1.1.1.6.6.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">226,816</span></span>
<span id="S6.T2.2.1.1.1.1.1.7.7" class="ltx_tr">
<span id="S6.T2.2.1.1.1.1.1.7.7.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t">5</span>
<span id="S6.T2.2.1.1.1.1.1.7.7.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">10</span>
<span id="S6.T2.2.1.1.1.1.1.7.7.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">128</span>
<span id="S6.T2.2.1.1.1.1.1.7.7.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">128</span>
<span id="S6.T2.2.1.1.1.1.1.7.7.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">256</span>
<span id="S6.T2.2.1.1.1.1.1.7.7.6" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">386,176</span></span>
</span>
</span></span></span>
</span></span></span></p>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S6.T2.5.1.1" class="ltx_text" style="font-size:90%;">Table 2</span>. </span><span id="S6.T2.6.2" class="ltx_text" style="font-size:90%;">Different client CNN models for <span id="S6.T2.6.2.1" class="ltx_text ltx_font_typewriter">FedMD</span>/<span id="S6.T2.6.2.2" class="ltx_text ltx_font_typewriter">FedDF</span> in task one (Table <a href="#S6.T1" title="Table 1 ‣ 6.1. Datasets ‣ 6. Experimental Setup ‣ Training Heterogeneous Client Models using Knowledge Distillation in Serverless Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>).</span></figcaption>
</figure>
<figure id="S6.T3" class="ltx_table">
<p id="S6.T3.2" class="ltx_p ltx_align_center"><span id="S6.T3.2.1" class="ltx_text ltx_inline-block" style="width:433.6pt;">
<span id="S6.T3.2.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:559.5pt;height:109pt;vertical-align:-1.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<span id="S6.T3.2.1.1.1" class="ltx_p"><span id="S6.T3.2.1.1.1.1" class="ltx_text">
<span id="S6.T3.2.1.1.1.1.1" class="ltx_tabular ltx_align_middle">
<span class="ltx_tbody">
<span id="S6.T3.2.1.1.1.1.1.1.1" class="ltx_tr">
<span id="S6.T3.2.1.1.1.1.1.1.1.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">Model ID</span>
<span id="S6.T3.2.1.1.1.1.1.1.1.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">#Clients</span>
<span id="S6.T3.2.1.1.1.1.1.1.1.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">#Layer 1 Conv. Filters</span>
<span id="S6.T3.2.1.1.1.1.1.1.1.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">#Layer 2 Conv. Filters</span>
<span id="S6.T3.2.1.1.1.1.1.1.1.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">#Layer 3 Conv. Filters</span>
<span id="S6.T3.2.1.1.1.1.1.1.1.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">#Trainable Parameters</span></span>
<span id="S6.T3.2.1.1.1.1.1.2.2" class="ltx_tr">
<span id="S6.T3.2.1.1.1.1.1.2.2.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">0</span>
<span id="S6.T3.2.1.1.1.1.1.2.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">10</span>
<span id="S6.T3.2.1.1.1.1.1.2.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">128</span>
<span id="S6.T3.2.1.1.1.1.1.2.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">256</span>
<span id="S6.T3.2.1.1.1.1.1.2.2.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">-</span>
<span id="S6.T3.2.1.1.1.1.1.2.2.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">729,856</span></span>
<span id="S6.T3.2.1.1.1.1.1.3.3" class="ltx_tr">
<span id="S6.T3.2.1.1.1.1.1.3.3.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">1</span>
<span id="S6.T3.2.1.1.1.1.1.3.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">10</span>
<span id="S6.T3.2.1.1.1.1.1.3.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">64</span>
<span id="S6.T3.2.1.1.1.1.1.3.3.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">128</span>
<span id="S6.T3.2.1.1.1.1.1.3.3.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">192</span>
<span id="S6.T3.2.1.1.1.1.1.3.3.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">274,112</span></span>
<span id="S6.T3.2.1.1.1.1.1.4.4" class="ltx_tr">
<span id="S6.T3.2.1.1.1.1.1.4.4.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">2</span>
<span id="S6.T3.2.1.1.1.1.1.4.4.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">30</span>
<span id="S6.T3.2.1.1.1.1.1.4.4.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">64</span>
<span id="S6.T3.2.1.1.1.1.1.4.4.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">64</span>
<span id="S6.T3.2.1.1.1.1.1.4.4.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">128</span>
<span id="S6.T3.2.1.1.1.1.1.4.4.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">104,128</span></span>
<span id="S6.T3.2.1.1.1.1.1.5.5" class="ltx_tr">
<span id="S6.T3.2.1.1.1.1.1.5.5.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">3</span>
<span id="S6.T3.2.1.1.1.1.1.5.5.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">30</span>
<span id="S6.T3.2.1.1.1.1.1.5.5.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">64</span>
<span id="S6.T3.2.1.1.1.1.1.5.5.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">128</span>
<span id="S6.T3.2.1.1.1.1.1.5.5.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">256</span>
<span id="S6.T3.2.1.1.1.1.1.5.5.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">352,640</span></span>
<span id="S6.T3.2.1.1.1.1.1.6.6" class="ltx_tr">
<span id="S6.T3.2.1.1.1.1.1.6.6.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t">4</span>
<span id="S6.T3.2.1.1.1.1.1.6.6.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">20</span>
<span id="S6.T3.2.1.1.1.1.1.6.6.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">128</span>
<span id="S6.T3.2.1.1.1.1.1.6.6.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">128</span>
<span id="S6.T3.2.1.1.1.1.1.6.6.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">128</span>
<span id="S6.T3.2.1.1.1.1.1.6.6.6" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">226,816</span></span>
</span>
</span></span></span>
</span></span></span></p>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S6.T3.5.1.1" class="ltx_text" style="font-size:90%;">Table 3</span>. </span><span id="S6.T3.6.2" class="ltx_text" style="font-size:90%;">Different client CNN models for <span id="S6.T3.6.2.1" class="ltx_text ltx_font_typewriter">FedMD</span>/<span id="S6.T3.6.2.2" class="ltx_text ltx_font_typewriter">FedDF</span> in task two (Table <a href="#S6.T1" title="Table 1 ‣ 6.1. Datasets ‣ 6. Experimental Setup ‣ Training Heterogeneous Client Models using Knowledge Distillation in Serverless Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>).</span></figcaption>
</figure>
<div id="S6.SS2.p2" class="ltx_para">
<p id="S6.SS2.p2.7" class="ltx_p">Figure <a href="#S6.F8.sf1" title="In Figure 8 ‣ 6.1. Datasets ‣ 6. Experimental Setup ‣ Training Heterogeneous Client Models using Knowledge Distillation in Serverless Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8(a)</span></a> visualizes the private client training data distributions for the MNIST dataset for <math id="S6.SS2.p2.1.m1.1" class="ltx_Math" alttext="100" display="inline"><semantics id="S6.SS2.p2.1.m1.1a"><mn id="S6.SS2.p2.1.m1.1.1" xref="S6.SS2.p2.1.m1.1.1.cmml">100</mn><annotation-xml encoding="MathML-Content" id="S6.SS2.p2.1.m1.1b"><cn type="integer" id="S6.SS2.p2.1.m1.1.1.cmml" xref="S6.SS2.p2.1.m1.1.1">100</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.p2.1.m1.1c">100</annotation></semantics></math> clients and different values of <math id="S6.SS2.p2.2.m2.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S6.SS2.p2.2.m2.1a"><mi id="S6.SS2.p2.2.m2.1.1" xref="S6.SS2.p2.2.m2.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S6.SS2.p2.2.m2.1b"><ci id="S6.SS2.p2.2.m2.1.1.cmml" xref="S6.SS2.p2.2.m2.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.p2.2.m2.1c">\alpha</annotation></semantics></math>. A value of <math id="S6.SS2.p2.3.m3.1" class="ltx_Math" alttext="\alpha=100" display="inline"><semantics id="S6.SS2.p2.3.m3.1a"><mrow id="S6.SS2.p2.3.m3.1.1" xref="S6.SS2.p2.3.m3.1.1.cmml"><mi id="S6.SS2.p2.3.m3.1.1.2" xref="S6.SS2.p2.3.m3.1.1.2.cmml">α</mi><mo id="S6.SS2.p2.3.m3.1.1.1" xref="S6.SS2.p2.3.m3.1.1.1.cmml">=</mo><mn id="S6.SS2.p2.3.m3.1.1.3" xref="S6.SS2.p2.3.m3.1.1.3.cmml">100</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.SS2.p2.3.m3.1b"><apply id="S6.SS2.p2.3.m3.1.1.cmml" xref="S6.SS2.p2.3.m3.1.1"><eq id="S6.SS2.p2.3.m3.1.1.1.cmml" xref="S6.SS2.p2.3.m3.1.1.1"></eq><ci id="S6.SS2.p2.3.m3.1.1.2.cmml" xref="S6.SS2.p2.3.m3.1.1.2">𝛼</ci><cn type="integer" id="S6.SS2.p2.3.m3.1.1.3.cmml" xref="S6.SS2.p2.3.m3.1.1.3">100</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.p2.3.m3.1c">\alpha=100</annotation></semantics></math> represents uniform data distribution, while a value of <math id="S6.SS2.p2.4.m4.1" class="ltx_Math" alttext="\alpha=0.1" display="inline"><semantics id="S6.SS2.p2.4.m4.1a"><mrow id="S6.SS2.p2.4.m4.1.1" xref="S6.SS2.p2.4.m4.1.1.cmml"><mi id="S6.SS2.p2.4.m4.1.1.2" xref="S6.SS2.p2.4.m4.1.1.2.cmml">α</mi><mo id="S6.SS2.p2.4.m4.1.1.1" xref="S6.SS2.p2.4.m4.1.1.1.cmml">=</mo><mn id="S6.SS2.p2.4.m4.1.1.3" xref="S6.SS2.p2.4.m4.1.1.3.cmml">0.1</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.SS2.p2.4.m4.1b"><apply id="S6.SS2.p2.4.m4.1.1.cmml" xref="S6.SS2.p2.4.m4.1.1"><eq id="S6.SS2.p2.4.m4.1.1.1.cmml" xref="S6.SS2.p2.4.m4.1.1.1"></eq><ci id="S6.SS2.p2.4.m4.1.1.2.cmml" xref="S6.SS2.p2.4.m4.1.1.2">𝛼</ci><cn type="float" id="S6.SS2.p2.4.m4.1.1.3.cmml" xref="S6.SS2.p2.4.m4.1.1.3">0.1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.p2.4.m4.1c">\alpha=0.1</annotation></semantics></math> represents an extreme non-IID scenario. For task one (Table <a href="#S6.T1" title="Table 1 ‣ 6.1. Datasets ‣ 6. Experimental Setup ‣ Training Heterogeneous Client Models using Knowledge Distillation in Serverless Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>), we use the same public and private data distributions for <span id="S6.SS2.p2.7.1" class="ltx_text ltx_font_typewriter">FedMD</span> and <span id="S6.SS2.p2.7.2" class="ltx_text ltx_font_typewriter">FedDF</span>. However, in <span id="S6.SS2.p2.7.3" class="ltx_text ltx_font_typewriter">FedDF</span>, only the image features and no labels are utilized for the distillation process. Each client model gets evaluated on the complete MNIST test dataset comprising <math id="S6.SS2.p2.5.m5.1" class="ltx_Math" alttext="10000" display="inline"><semantics id="S6.SS2.p2.5.m5.1a"><mn id="S6.SS2.p2.5.m5.1.1" xref="S6.SS2.p2.5.m5.1.1.cmml">10000</mn><annotation-xml encoding="MathML-Content" id="S6.SS2.p2.5.m5.1b"><cn type="integer" id="S6.SS2.p2.5.m5.1.1.cmml" xref="S6.SS2.p2.5.m5.1.1">10000</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.p2.5.m5.1c">10000</annotation></semantics></math> testing images (§<a href="#S6.SS1" title="6.1. Datasets ‣ 6. Experimental Setup ‣ Training Heterogeneous Client Models using Knowledge Distillation in Serverless Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6.1</span></a>). In task two for <span id="S6.SS2.p2.7.4" class="ltx_text ltx_font_typewriter">FedMD</span>, we use a subset of six classes from the CIFAR-100 dataset as in <cite class="ltx_cite ltx_citemacro_citep">(Li and Wang, <a href="#bib.bib36" title="" class="ltx_ref">2019</a>)</cite> for the main learning task. Figure <a href="#S6.F8.sf2" title="In Figure 8 ‣ 6.1. Datasets ‣ 6. Experimental Setup ‣ Training Heterogeneous Client Models using Knowledge Distillation in Serverless Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8(b)</span></a> shows the private client data distribution in this scenario for various values of <math id="S6.SS2.p2.6.m6.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S6.SS2.p2.6.m6.1a"><mi id="S6.SS2.p2.6.m6.1.1" xref="S6.SS2.p2.6.m6.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S6.SS2.p2.6.m6.1b"><ci id="S6.SS2.p2.6.m6.1.1.cmml" xref="S6.SS2.p2.6.m6.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.p2.6.m6.1c">\alpha</annotation></semantics></math>. The complete CIFAR-10 dataset is employed as the public distillation dataset for this task (§<a href="#S2.SS2" title="2.2. FedMD ‣ 2. Background ‣ Training Heterogeneous Client Models using Knowledge Distillation in Serverless Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.2</span></a>). During testing, each client’s performance is evaluated on the complete global CIFAR-100 test dataset subsetted for the six classes. On the other hand, for <span id="S6.SS2.p2.7.5" class="ltx_text ltx_font_typewriter">FedDF</span> in task two, we use CIFAR-10 as the private dataset and CIFAR-100 as the public dataset. The private training data distribution for <span id="S6.SS2.p2.7.6" class="ltx_text ltx_font_typewriter">FedDF</span> with CIFAR-10 is shown in Figure <a href="#S6.F8.sf3" title="In Figure 8 ‣ 6.1. Datasets ‣ 6. Experimental Setup ‣ Training Heterogeneous Client Models using Knowledge Distillation in Serverless Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8(c)</span></a>. For evaluating individual client models, we use the complete CIFAR-10 test dataset comprising <math id="S6.SS2.p2.7.m7.1" class="ltx_Math" alttext="10000" display="inline"><semantics id="S6.SS2.p2.7.m7.1a"><mn id="S6.SS2.p2.7.m7.1.1" xref="S6.SS2.p2.7.m7.1.1.cmml">10000</mn><annotation-xml encoding="MathML-Content" id="S6.SS2.p2.7.m7.1b"><cn type="integer" id="S6.SS2.p2.7.m7.1.1.cmml" xref="S6.SS2.p2.7.m7.1.1">10000</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.p2.7.m7.1c">10000</annotation></semantics></math> images. Similar to task one, we use the same public and private dataset distributions for the two algorithms in task three, as shown in Table <a href="#S6.T1" title="Table 1 ‣ 6.1. Datasets ‣ 6. Experimental Setup ‣ Training Heterogeneous Client Models using Knowledge Distillation in Serverless Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. For the non-IID scenario, we use the pre-provided non-IID partitions for the Shakespeare dataset from the <span id="S6.SS2.p2.7.7" class="ltx_text ltx_font_typewriter">LEAF</span> FL benchmark suite <cite class="ltx_cite ltx_citemacro_citep">(Caldas et al<span class="ltx_text">.</span>, <a href="#bib.bib7" title="" class="ltx_ref">2018</a>)</cite>. We don’t use the Dirichlet distribution for creating non-IID partitions for Shakespeare since that is only suitable for classification tasks. Note that for all tasks, the public dataset is uniformly distributed.</p>
</div>
</section>
<section id="S6.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.3. </span>Heterogeneous Client Model Architectures</h3>

<div id="S6.SS3.p1" class="ltx_para">
<p id="S6.SS3.p1.1" class="ltx_p">In our experiments, we use multiple model architectures distributed among 100 participating clients based on the machine learning task (Table <a href="#S6.T1" title="Table 1 ‣ 6.1. Datasets ‣ 6. Experimental Setup ‣ Training Heterogeneous Client Models using Knowledge Distillation in Serverless Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>). For tasks one and two, we utilize 2-layer and 3-layer convolutional neural networks (CNNs). These model architectures are unevenly distributed among the clients to simulate real-world scenarios, as shown in Tables <a href="#S6.T2" title="Table 2 ‣ 6.2. Heterogeneous Client Data Distribution ‣ 6. Experimental Setup ‣ Training Heterogeneous Client Models using Knowledge Distillation in Serverless Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> and <a href="#S6.T3" title="Table 3 ‣ 6.2. Heterogeneous Client Data Distribution ‣ 6. Experimental Setup ‣ Training Heterogeneous Client Models using Knowledge Distillation in Serverless Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>. Each convolution filter layer is followed by batch normalization, ReLU activation, and a dropout of <math id="S6.SS3.p1.1.m1.1" class="ltx_Math" alttext="0.2" display="inline"><semantics id="S6.SS3.p1.1.m1.1a"><mn id="S6.SS3.p1.1.m1.1.1" xref="S6.SS3.p1.1.m1.1.1.cmml">0.2</mn><annotation-xml encoding="MathML-Content" id="S6.SS3.p1.1.m1.1b"><cn type="float" id="S6.SS3.p1.1.m1.1.1.cmml" xref="S6.SS3.p1.1.m1.1.1">0.2</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS3.p1.1.m1.1c">0.2</annotation></semantics></math>. Dropout enables regularization and prevents client models from overfitting on small amounts of private local data. To ensure a fair comparison between the performance of <span id="S6.SS3.p1.1.1" class="ltx_text ltx_font_typewriter">FedMD</span> and <span id="S6.SS3.p1.1.2" class="ltx_text ltx_font_typewriter">FedDF</span> in the serverless paradigm, we use the same client model distributions for both algorithms. For task three, we utilize LSTM Recurrent Neural Networks with a single layer and a varying number of units, as shown in Table <a href="#S6.T4" title="Table 4 ‣ 6.3. Heterogeneous Client Model Architectures ‣ 6. Experimental Setup ‣ Training Heterogeneous Client Models using Knowledge Distillation in Serverless Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>. Every network takes an input sequence length of 80, followed by an initial embedding size of 8 and then a single LSTM layer. For all tasks, we chose the model architectures that have been used previously in this domain <cite class="ltx_cite ltx_citemacro_citep">(Li and Wang, <a href="#bib.bib36" title="" class="ltx_ref">2019</a>; Elzohairy et al<span class="ltx_text">.</span>, <a href="#bib.bib14" title="" class="ltx_ref">2022</a>; Lin et al<span class="ltx_text">.</span>, <a href="#bib.bib38" title="" class="ltx_ref">2020</a>; Chadha et al<span class="ltx_text">.</span>, <a href="#bib.bib9" title="" class="ltx_ref">2020</a>)</cite>. Due to space limitations, we omit the specific hyperparameters used for the two algorithms but will describe them in detail in our code repository.</p>
</div>
<figure id="S6.T4" class="ltx_table">
<p id="S6.T4.2" class="ltx_p ltx_align_center"><span id="S6.T4.2.1" class="ltx_text ltx_inline-block" style="width:433.6pt;">
<span id="S6.T4.2.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:350.0pt;height:72pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<span id="S6.T4.2.1.1.1" class="ltx_p"><span id="S6.T4.2.1.1.1.1" class="ltx_text">
<span id="S6.T4.2.1.1.1.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<span class="ltx_thead">
<span id="S6.T4.2.1.1.1.1.1.1.1" class="ltx_tr">
<span id="S6.T4.2.1.1.1.1.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t">Model ID</span>
<span id="S6.T4.2.1.1.1.1.1.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">#Clients</span>
<span id="S6.T4.2.1.1.1.1.1.1.1.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">#Units</span>
<span id="S6.T4.2.1.1.1.1.1.1.1.4" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">Embedding Dim</span>
<span id="S6.T4.2.1.1.1.1.1.1.1.5" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">#Trainable Parameters</span></span>
</span>
<span class="ltx_tbody">
<span id="S6.T4.2.1.1.1.1.1.2.1" class="ltx_tr">
<span id="S6.T4.2.1.1.1.1.1.2.1.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">0</span>
<span id="S6.T4.2.1.1.1.1.1.2.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">60</span>
<span id="S6.T4.2.1.1.1.1.1.2.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">128</span>
<span id="S6.T4.2.1.1.1.1.1.2.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">8</span>
<span id="S6.T4.2.1.1.1.1.1.2.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">81,378</span></span>
<span id="S6.T4.2.1.1.1.1.1.3.2" class="ltx_tr">
<span id="S6.T4.2.1.1.1.1.1.3.2.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">1</span>
<span id="S6.T4.2.1.1.1.1.1.3.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">10</span>
<span id="S6.T4.2.1.1.1.1.1.3.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">64</span>
<span id="S6.T4.2.1.1.1.1.1.3.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">8</span>
<span id="S6.T4.2.1.1.1.1.1.3.2.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">24,674</span></span>
<span id="S6.T4.2.1.1.1.1.1.4.3" class="ltx_tr">
<span id="S6.T4.2.1.1.1.1.1.4.3.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t">2</span>
<span id="S6.T4.2.1.1.1.1.1.4.3.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">30</span>
<span id="S6.T4.2.1.1.1.1.1.4.3.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">256</span>
<span id="S6.T4.2.1.1.1.1.1.4.3.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">8</span>
<span id="S6.T4.2.1.1.1.1.1.4.3.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">293,090</span></span>
</span>
</span></span></span>
</span></span></span></p>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S6.T4.5.1.1" class="ltx_text" style="font-size:90%;">Table 4</span>. </span><span id="S6.T4.6.2" class="ltx_text" style="font-size:90%;">Different client LSTM models for <span id="S6.T4.6.2.1" class="ltx_text ltx_font_typewriter">FedMD</span>/<span id="S6.T4.6.2.2" class="ltx_text ltx_font_typewriter">FedDF</span> in task three (Table <a href="#S6.T1" title="Table 1 ‣ 6.1. Datasets ‣ 6. Experimental Setup ‣ Training Heterogeneous Client Models using Knowledge Distillation in Serverless Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>).</span></figcaption>
</figure>
<figure id="S6.F9" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S6.F9.sf1" class="ltx_figure ltx_figure_panel"><img src="/html/2402.07295/assets/x11.png" id="S6.F9.sf1.g1" class="ltx_graphics ltx_centering ltx_img_square" width="461" height="492" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S6.F9.sf1.3.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S6.F9.sf1.4.2" class="ltx_text ltx_font_typewriter" style="font-size:90%;">FedMD<span id="S6.F9.sf1.4.2.1" class="ltx_text ltx_font_serif"> with MNIST.</span></span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S6.F9.sf2" class="ltx_figure ltx_figure_panel"><img src="/html/2402.07295/assets/x12.png" id="S6.F9.sf2.g1" class="ltx_graphics ltx_centering ltx_img_square" width="461" height="491" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S6.F9.sf2.3.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S6.F9.sf2.4.2" class="ltx_text ltx_font_typewriter" style="font-size:90%;">FedMD<span id="S6.F9.sf2.4.2.1" class="ltx_text ltx_font_serif"> with CIFAR.</span></span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S6.F9.sf3" class="ltx_figure ltx_figure_panel"><img src="/html/2402.07295/assets/x13.png" id="S6.F9.sf3.g1" class="ltx_graphics ltx_centering ltx_img_square" width="461" height="497" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S6.F9.sf3.3.1.1" class="ltx_text" style="font-size:90%;">(c)</span> </span><span id="S6.F9.sf3.4.2" class="ltx_text ltx_font_typewriter" style="font-size:90%;">FedDF<span id="S6.F9.sf3.4.2.1" class="ltx_text ltx_font_serif"> with MNIST.</span></span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S6.F9.sf4" class="ltx_figure ltx_figure_panel"><img src="/html/2402.07295/assets/x14.png" id="S6.F9.sf4.g1" class="ltx_graphics ltx_centering ltx_img_square" width="461" height="495" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S6.F9.sf4.3.1.1" class="ltx_text" style="font-size:90%;">(d)</span> </span><span id="S6.F9.sf4.4.2" class="ltx_text ltx_font_typewriter" style="font-size:90%;">FedDF<span id="S6.F9.sf4.4.2.1" class="ltx_text ltx_font_serif"> with CIFAR.</span></span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S6.F9.sf5" class="ltx_figure ltx_figure_panel">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2402.07295/assets/x15.png" id="S6.F9.sf5.g1" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="461" height="246" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2402.07295/assets/x16.png" id="S6.F9.sf5.g2" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="461" height="248" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S6.F9.sf5.2.1.1" class="ltx_text" style="font-size:90%;">(e)</span> </span><span id="S6.F9.sf5.3.2" class="ltx_text" style="font-size:90%;">Shakespeare dataset.</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S6.F9.4.1.1" class="ltx_text" style="font-size:90%;">Figure 9</span>. </span><span id="S6.F9.5.2" class="ltx_text" style="font-size:90%;">Comparing Top-1 model accuracies across heterogeneous model architectures for the serverless implementations of <span id="S6.F9.5.2.1" class="ltx_text ltx_font_typewriter">FedMD</span> and <span id="S6.F9.5.2.2" class="ltx_text ltx_font_typewriter">FedDF</span>.</span></figcaption>
</figure>
</section>
<section id="S6.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.4. </span>Infrastructure Setup</h3>

<div id="S6.SS4.p1" class="ltx_para">
<p id="S6.SS4.p1.2" class="ltx_p">For our experiments, we deployed <em id="S6.SS4.p1.2.1" class="ltx_emph ltx_font_italic">FedLess</em> (§<a href="#S4.SS2" title="4.2. Extending FedLess ‣ 4. System Design ‣ Training Heterogeneous Client Models using Knowledge Distillation in Serverless Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.2</span></a>) on a virtual machine hosted on our institute’s compute cloud. The VM was configured with <math id="S6.SS4.p1.1.m1.1" class="ltx_Math" alttext="40" display="inline"><semantics id="S6.SS4.p1.1.m1.1a"><mn id="S6.SS4.p1.1.m1.1.1" xref="S6.SS4.p1.1.m1.1.1.cmml">40</mn><annotation-xml encoding="MathML-Content" id="S6.SS4.p1.1.m1.1b"><cn type="integer" id="S6.SS4.p1.1.m1.1.1.cmml" xref="S6.SS4.p1.1.m1.1.1">40</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS4.p1.1.m1.1c">40</annotation></semantics></math>vCPUs and <math id="S6.SS4.p1.2.m2.1" class="ltx_Math" alttext="177" display="inline"><semantics id="S6.SS4.p1.2.m2.1a"><mn id="S6.SS4.p1.2.m2.1.1" xref="S6.SS4.p1.2.m2.1.1.cmml">177</mn><annotation-xml encoding="MathML-Content" id="S6.SS4.p1.2.m2.1b"><cn type="integer" id="S6.SS4.p1.2.m2.1.1.cmml" xref="S6.SS4.p1.2.m2.1.1">177</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS4.p1.2.m2.1c">177</annotation></semantics></math>GiB of RAM. For the training cluster utilizing <span id="S6.SS4.p1.2.2" class="ltx_text ltx_font_typewriter">Ray</span> (§<a href="#S4.SS2.SSS1" title="4.2.1. Serverless Parallel Transfer Learning for FedMD ‣ 4.2. Extending FedLess ‣ 4. System Design ‣ Training Heterogeneous Client Models using Knowledge Distillation in Serverless Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.2.1</span></a>), we assigned each function instance with 4 vCPUs and 16 GiB of RAM. Moreover, we set the maximum number of function instances to eight in the
<span id="S6.SS4.p1.2.3" class="ltx_text ltx_font_typewriter">Ray</span> autoscaler. Furthermore, for hosting our datasets, we used a nginx store running on a VM with 10vCPUs and 45GiB of RAM.</p>
</div>
<div id="S6.SS4.p2" class="ltx_para">
<p id="S6.SS4.p2.8" class="ltx_p">For FaaS-based FL clients and the different aggregator functions, we used OpenFaaS <cite class="ltx_cite ltx_citemacro_citep">(OpenFaaS, <a href="#bib.bib44" title="" class="ltx_ref">2019</a>)</cite> as the FaaS platform. We used <math id="S6.SS4.p2.1.m1.1" class="ltx_Math" alttext="100" display="inline"><semantics id="S6.SS4.p2.1.m1.1a"><mn id="S6.SS4.p2.1.m1.1.1" xref="S6.SS4.p2.1.m1.1.1.cmml">100</mn><annotation-xml encoding="MathML-Content" id="S6.SS4.p2.1.m1.1b"><cn type="integer" id="S6.SS4.p2.1.m1.1.1.cmml" xref="S6.SS4.p2.1.m1.1.1">100</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS4.p2.1.m1.1c">100</annotation></semantics></math> client functions for our experiments. Each client had a limit of <math id="S6.SS4.p2.2.m2.1" class="ltx_Math" alttext="2" display="inline"><semantics id="S6.SS4.p2.2.m2.1a"><mn id="S6.SS4.p2.2.m2.1.1" xref="S6.SS4.p2.2.m2.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="S6.SS4.p2.2.m2.1b"><cn type="integer" id="S6.SS4.p2.2.m2.1.1.cmml" xref="S6.SS4.p2.2.m2.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS4.p2.2.m2.1c">2</annotation></semantics></math>vCPUs and <math id="S6.SS4.p2.3.m3.1" class="ltx_Math" alttext="4" display="inline"><semantics id="S6.SS4.p2.3.m3.1a"><mn id="S6.SS4.p2.3.m3.1.1" xref="S6.SS4.p2.3.m3.1.1.cmml">4</mn><annotation-xml encoding="MathML-Content" id="S6.SS4.p2.3.m3.1b"><cn type="integer" id="S6.SS4.p2.3.m3.1.1.cmml" xref="S6.SS4.p2.3.m3.1.1">4</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS4.p2.3.m3.1c">4</annotation></semantics></math>GiB of RAM. For <span id="S6.SS4.p2.8.1" class="ltx_text ltx_font_typewriter">FedMD</span>, we sample <math id="S6.SS4.p2.4.m4.1" class="ltx_Math" alttext="100" display="inline"><semantics id="S6.SS4.p2.4.m4.1a"><mn id="S6.SS4.p2.4.m4.1.1" xref="S6.SS4.p2.4.m4.1.1.cmml">100</mn><annotation-xml encoding="MathML-Content" id="S6.SS4.p2.4.m4.1b"><cn type="integer" id="S6.SS4.p2.4.m4.1.1.cmml" xref="S6.SS4.p2.4.m4.1.1">100</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS4.p2.4.m4.1c">100</annotation></semantics></math> clients per round while limiting the number of clients per round to ten for <span id="S6.SS4.p2.8.2" class="ltx_text ltx_font_typewriter">FedDF</span>. We deployed a single aggregator function for <span id="S6.SS4.p2.8.3" class="ltx_text ltx_font_typewriter">FedMD</span> with <math id="S6.SS4.p2.5.m5.1" class="ltx_Math" alttext="4" display="inline"><semantics id="S6.SS4.p2.5.m5.1a"><mn id="S6.SS4.p2.5.m5.1.1" xref="S6.SS4.p2.5.m5.1.1.cmml">4</mn><annotation-xml encoding="MathML-Content" id="S6.SS4.p2.5.m5.1b"><cn type="integer" id="S6.SS4.p2.5.m5.1.1.cmml" xref="S6.SS4.p2.5.m5.1.1">4</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS4.p2.5.m5.1c">4</annotation></semantics></math>vCPUs and <math id="S6.SS4.p2.6.m6.1" class="ltx_Math" alttext="8" display="inline"><semantics id="S6.SS4.p2.6.m6.1a"><mn id="S6.SS4.p2.6.m6.1.1" xref="S6.SS4.p2.6.m6.1.1.cmml">8</mn><annotation-xml encoding="MathML-Content" id="S6.SS4.p2.6.m6.1b"><cn type="integer" id="S6.SS4.p2.6.m6.1.1.cmml" xref="S6.SS4.p2.6.m6.1.1">8</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS4.p2.6.m6.1c">8</annotation></semantics></math>GiB of RAM. In contrast, for <span id="S6.SS4.p2.8.4" class="ltx_text ltx_font_typewriter">FeDF</span>, we used six aggregator functions (§<a href="#S4.SS2.SSS2" title="4.2.2. Serverless Parallel Ensemble Distillation for FedDF ‣ 4.2. Extending FedLess ‣ 4. System Design ‣ Training Heterogeneous Client Models using Knowledge Distillation in Serverless Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.2.2</span></a>). Each aggregator function had a limit of <math id="S6.SS4.p2.7.m7.1" class="ltx_Math" alttext="6" display="inline"><semantics id="S6.SS4.p2.7.m7.1a"><mn id="S6.SS4.p2.7.m7.1.1" xref="S6.SS4.p2.7.m7.1.1.cmml">6</mn><annotation-xml encoding="MathML-Content" id="S6.SS4.p2.7.m7.1b"><cn type="integer" id="S6.SS4.p2.7.m7.1.1.cmml" xref="S6.SS4.p2.7.m7.1.1">6</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS4.p2.7.m7.1c">6</annotation></semantics></math>vCPUs and <math id="S6.SS4.p2.8.m8.1" class="ltx_Math" alttext="16" display="inline"><semantics id="S6.SS4.p2.8.m8.1a"><mn id="S6.SS4.p2.8.m8.1.1" xref="S6.SS4.p2.8.m8.1.1.cmml">16</mn><annotation-xml encoding="MathML-Content" id="S6.SS4.p2.8.m8.1b"><cn type="integer" id="S6.SS4.p2.8.m8.1.1.cmml" xref="S6.SS4.p2.8.m8.1.1">16</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS4.p2.8.m8.1c">16</annotation></semantics></math>GiB of RAM.</p>
</div>
</section>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7. </span>Experimental Results</h2>

<div id="S7.p1" class="ltx_para">
<p id="S7.p1.1" class="ltx_p">For all our experiments, we follow best practices while reporting results and repeat them three times.
</p>
</div>
<section id="S7.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">7.1. </span>Comparing Accuracy</h3>

<div id="S7.SS1.p1" class="ltx_para">
<p id="S7.SS1.p1.19" class="ltx_p">In this subsection, we focus on demonstrating the convergence and improved accuracy obtained through serverless knowledge distillation among heterogeneous client models rather than pursuing state-of-the-art accuracies on these tasks. Towards this, we limit our experiments to <math id="S7.SS1.p1.1.m1.1" class="ltx_Math" alttext="20" display="inline"><semantics id="S7.SS1.p1.1.m1.1a"><mn id="S7.SS1.p1.1.m1.1.1" xref="S7.SS1.p1.1.m1.1.1.cmml">20</mn><annotation-xml encoding="MathML-Content" id="S7.SS1.p1.1.m1.1b"><cn type="integer" id="S7.SS1.p1.1.m1.1.1.cmml" xref="S7.SS1.p1.1.m1.1.1">20</cn></annotation-xml><annotation encoding="application/x-tex" id="S7.SS1.p1.1.m1.1c">20</annotation></semantics></math> communication rounds for the two algorithms across all datasets and levels of data heterogeneity (§<a href="#S6.SS1" title="6.1. Datasets ‣ 6. Experimental Setup ‣ Training Heterogeneous Client Models using Knowledge Distillation in Serverless Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6.1</span></a>,§<a href="#S6.SS2" title="6.2. Heterogeneous Client Data Distribution ‣ 6. Experimental Setup ‣ Training Heterogeneous Client Models using Knowledge Distillation in Serverless Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6.2</span></a>). Figure <a href="#S6.F9" title="Figure 9 ‣ 6.3. Heterogeneous Client Model Architectures ‣ 6. Experimental Setup ‣ Training Heterogeneous Client Models using Knowledge Distillation in Serverless Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a> presents the top-1 model accuracies for <span id="S7.SS1.p1.19.1" class="ltx_text ltx_font_typewriter">FedMD</span> and <span id="S7.SS1.p1.19.2" class="ltx_text ltx_font_typewriter">FedDF</span> across the different datasets. Top-1 model accuracy is a common evaluation metric and represents the accuracy of a model in correctly predicting the most probable class label for a given input out of all possible class labels. For <span id="S7.SS1.p1.19.3" class="ltx_text ltx_font_typewriter">FedMD</span>, each line in Figures <a href="#S6.F9.sf1" title="In Figure 9 ‣ 6.3. Heterogeneous Client Model Architectures ‣ 6. Experimental Setup ‣ Training Heterogeneous Client Models using Knowledge Distillation in Serverless Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9(a)</span></a>, <a href="#S6.F9.sf2" title="In Figure 9 ‣ 6.3. Heterogeneous Client Model Architectures ‣ 6. Experimental Setup ‣ Training Heterogeneous Client Models using Knowledge Distillation in Serverless Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9(b)</span></a>, and <a href="#S6.F9.sf5" title="In Figure 9 ‣ 6.3. Heterogeneous Client Model Architectures ‣ 6. Experimental Setup ‣ Training Heterogeneous Client Models using Knowledge Distillation in Serverless Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9(e)</span></a> represents the average model accuracy across all clients belonging to a particular unique model architecture group (§<a href="#S6.SS3" title="6.3. Heterogeneous Client Model Architectures ‣ 6. Experimental Setup ‣ Training Heterogeneous Client Models using Knowledge Distillation in Serverless Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6.3</span></a>). On the other hand, for <span id="S7.SS1.p1.19.4" class="ltx_text ltx_font_typewriter">FedDF</span>, each line in Figures <a href="#S6.F9.sf3" title="In Figure 9 ‣ 6.3. Heterogeneous Client Model Architectures ‣ 6. Experimental Setup ‣ Training Heterogeneous Client Models using Knowledge Distillation in Serverless Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9(c)</span></a>, <a href="#S6.F9.sf4" title="In Figure 9 ‣ 6.3. Heterogeneous Client Model Architectures ‣ 6. Experimental Setup ‣ Training Heterogeneous Client Models using Knowledge Distillation in Serverless Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9(d)</span></a>, and <a href="#S6.F9.sf5" title="In Figure 9 ‣ 6.3. Heterogeneous Client Model Architectures ‣ 6. Experimental Setup ‣ Training Heterogeneous Client Models using Knowledge Distillation in Serverless Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9(e)</span></a> corresponds to the accuracy of the global server model for that particular unique model architecture group. For the MNIST dataset with <span id="S7.SS1.p1.19.5" class="ltx_text ltx_font_typewriter">FedMD</span>, we observe that the KD process is predominantly concentrated in the initial collaboration rounds. Following this, the accuracy curve stabilizes, indicating a plateau in performance improvement. For the scenario with uniform data distribution (§<a href="#S6.SS2" title="6.2. Heterogeneous Client Data Distribution ‣ 6. Experimental Setup ‣ Training Heterogeneous Client Models using Knowledge Distillation in Serverless Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6.2</span></a>), we observed a maximum accuracy of <math id="S7.SS1.p1.2.m2.1" class="ltx_Math" alttext="96" display="inline"><semantics id="S7.SS1.p1.2.m2.1a"><mn id="S7.SS1.p1.2.m2.1.1" xref="S7.SS1.p1.2.m2.1.1.cmml">96</mn><annotation-xml encoding="MathML-Content" id="S7.SS1.p1.2.m2.1b"><cn type="integer" id="S7.SS1.p1.2.m2.1.1.cmml" xref="S7.SS1.p1.2.m2.1.1">96</cn></annotation-xml><annotation encoding="application/x-tex" id="S7.SS1.p1.2.m2.1c">96</annotation></semantics></math>% for model 4 as shown in Figure <a href="#S6.F9.sf1" title="In Figure 9 ‣ 6.3. Heterogeneous Client Model Architectures ‣ 6. Experimental Setup ‣ Training Heterogeneous Client Models using Knowledge Distillation in Serverless Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9(a)</span></a>. In contrast, for <math id="S7.SS1.p1.3.m3.1" class="ltx_Math" alttext="\alpha=0.1" display="inline"><semantics id="S7.SS1.p1.3.m3.1a"><mrow id="S7.SS1.p1.3.m3.1.1" xref="S7.SS1.p1.3.m3.1.1.cmml"><mi id="S7.SS1.p1.3.m3.1.1.2" xref="S7.SS1.p1.3.m3.1.1.2.cmml">α</mi><mo id="S7.SS1.p1.3.m3.1.1.1" xref="S7.SS1.p1.3.m3.1.1.1.cmml">=</mo><mn id="S7.SS1.p1.3.m3.1.1.3" xref="S7.SS1.p1.3.m3.1.1.3.cmml">0.1</mn></mrow><annotation-xml encoding="MathML-Content" id="S7.SS1.p1.3.m3.1b"><apply id="S7.SS1.p1.3.m3.1.1.cmml" xref="S7.SS1.p1.3.m3.1.1"><eq id="S7.SS1.p1.3.m3.1.1.1.cmml" xref="S7.SS1.p1.3.m3.1.1.1"></eq><ci id="S7.SS1.p1.3.m3.1.1.2.cmml" xref="S7.SS1.p1.3.m3.1.1.2">𝛼</ci><cn type="float" id="S7.SS1.p1.3.m3.1.1.3.cmml" xref="S7.SS1.p1.3.m3.1.1.3">0.1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.SS1.p1.3.m3.1c">\alpha=0.1</annotation></semantics></math>, we observed a <math id="S7.SS1.p1.4.m4.1" class="ltx_Math" alttext="46.5" display="inline"><semantics id="S7.SS1.p1.4.m4.1a"><mn id="S7.SS1.p1.4.m4.1.1" xref="S7.SS1.p1.4.m4.1.1.cmml">46.5</mn><annotation-xml encoding="MathML-Content" id="S7.SS1.p1.4.m4.1b"><cn type="float" id="S7.SS1.p1.4.m4.1.1.cmml" xref="S7.SS1.p1.4.m4.1.1">46.5</cn></annotation-xml><annotation encoding="application/x-tex" id="S7.SS1.p1.4.m4.1c">46.5</annotation></semantics></math>% average accuracy drop across all model architectures as compared to the IID scenario with <math id="S7.SS1.p1.5.m5.1" class="ltx_Math" alttext="\alpha=100" display="inline"><semantics id="S7.SS1.p1.5.m5.1a"><mrow id="S7.SS1.p1.5.m5.1.1" xref="S7.SS1.p1.5.m5.1.1.cmml"><mi id="S7.SS1.p1.5.m5.1.1.2" xref="S7.SS1.p1.5.m5.1.1.2.cmml">α</mi><mo id="S7.SS1.p1.5.m5.1.1.1" xref="S7.SS1.p1.5.m5.1.1.1.cmml">=</mo><mn id="S7.SS1.p1.5.m5.1.1.3" xref="S7.SS1.p1.5.m5.1.1.3.cmml">100</mn></mrow><annotation-xml encoding="MathML-Content" id="S7.SS1.p1.5.m5.1b"><apply id="S7.SS1.p1.5.m5.1.1.cmml" xref="S7.SS1.p1.5.m5.1.1"><eq id="S7.SS1.p1.5.m5.1.1.1.cmml" xref="S7.SS1.p1.5.m5.1.1.1"></eq><ci id="S7.SS1.p1.5.m5.1.1.2.cmml" xref="S7.SS1.p1.5.m5.1.1.2">𝛼</ci><cn type="integer" id="S7.SS1.p1.5.m5.1.1.3.cmml" xref="S7.SS1.p1.5.m5.1.1.3">100</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.SS1.p1.5.m5.1c">\alpha=100</annotation></semantics></math>. This can be attributed to the divergence of the globally aggregated logits due to the significantly high variance in the private data distribution among the FL clients <cite class="ltx_cite ltx_citemacro_citep">(Hsieh et al<span class="ltx_text">.</span>, <a href="#bib.bib21" title="" class="ltx_ref">2020</a>)</cite>(§<a href="#S2.SS2" title="2.2. FedMD ‣ 2. Background ‣ Training Heterogeneous Client Models using Knowledge Distillation in Serverless Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.2</span></a>,§<a href="#S5.SS1" title="5.1. Serverless FedMD ‣ 5. Serverless Knowledge Distillation ‣ Training Heterogeneous Client Models using Knowledge Distillation in Serverless Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.1</span></a>). In contrast to the MNIST dataset, we observe a more gradual increase in accuracy with collaboration rounds for the CIFAR dataset with <span id="S7.SS1.p1.19.6" class="ltx_text ltx_font_typewriter">FedMD</span>. For the i.i.d. scenario, we observe a maximum test accuracy of <math id="S7.SS1.p1.6.m6.1" class="ltx_Math" alttext="66.4" display="inline"><semantics id="S7.SS1.p1.6.m6.1a"><mn id="S7.SS1.p1.6.m6.1.1" xref="S7.SS1.p1.6.m6.1.1.cmml">66.4</mn><annotation-xml encoding="MathML-Content" id="S7.SS1.p1.6.m6.1b"><cn type="float" id="S7.SS1.p1.6.m6.1.1.cmml" xref="S7.SS1.p1.6.m6.1.1">66.4</cn></annotation-xml><annotation encoding="application/x-tex" id="S7.SS1.p1.6.m6.1c">66.4</annotation></semantics></math>% with model two as shown in Figure <a href="#S6.F9.sf2" title="In Figure 9 ‣ 6.3. Heterogeneous Client Model Architectures ‣ 6. Experimental Setup ‣ Training Heterogeneous Client Models using Knowledge Distillation in Serverless Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9(b)</span></a>. Furthermore, we observe a <math id="S7.SS1.p1.7.m7.1" class="ltx_Math" alttext="13" display="inline"><semantics id="S7.SS1.p1.7.m7.1a"><mn id="S7.SS1.p1.7.m7.1.1" xref="S7.SS1.p1.7.m7.1.1.cmml">13</mn><annotation-xml encoding="MathML-Content" id="S7.SS1.p1.7.m7.1b"><cn type="integer" id="S7.SS1.p1.7.m7.1.1.cmml" xref="S7.SS1.p1.7.m7.1.1">13</cn></annotation-xml><annotation encoding="application/x-tex" id="S7.SS1.p1.7.m7.1c">13</annotation></semantics></math>% average drop in accuracy for <math id="S7.SS1.p1.8.m8.1" class="ltx_Math" alttext="\alpha=0.1" display="inline"><semantics id="S7.SS1.p1.8.m8.1a"><mrow id="S7.SS1.p1.8.m8.1.1" xref="S7.SS1.p1.8.m8.1.1.cmml"><mi id="S7.SS1.p1.8.m8.1.1.2" xref="S7.SS1.p1.8.m8.1.1.2.cmml">α</mi><mo id="S7.SS1.p1.8.m8.1.1.1" xref="S7.SS1.p1.8.m8.1.1.1.cmml">=</mo><mn id="S7.SS1.p1.8.m8.1.1.3" xref="S7.SS1.p1.8.m8.1.1.3.cmml">0.1</mn></mrow><annotation-xml encoding="MathML-Content" id="S7.SS1.p1.8.m8.1b"><apply id="S7.SS1.p1.8.m8.1.1.cmml" xref="S7.SS1.p1.8.m8.1.1"><eq id="S7.SS1.p1.8.m8.1.1.1.cmml" xref="S7.SS1.p1.8.m8.1.1.1"></eq><ci id="S7.SS1.p1.8.m8.1.1.2.cmml" xref="S7.SS1.p1.8.m8.1.1.2">𝛼</ci><cn type="float" id="S7.SS1.p1.8.m8.1.1.3.cmml" xref="S7.SS1.p1.8.m8.1.1.3">0.1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.SS1.p1.8.m8.1c">\alpha=0.1</annotation></semantics></math> as compared to the scenario with uniform data distribution. Figure <a href="#S6.F9.sf5" title="In Figure 9 ‣ 6.3. Heterogeneous Client Model Architectures ‣ 6. Experimental Setup ‣ Training Heterogeneous Client Models using Knowledge Distillation in Serverless Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9(e)</span></a> shows the performance of <span id="S7.SS1.p1.19.7" class="ltx_text ltx_font_typewriter">FedMD</span> on the Shakespeare dataset for the IID and non-IID scenarios. For both scenarios, model one achieved the maximum accuracy of <math id="S7.SS1.p1.9.m9.1" class="ltx_Math" alttext="36" display="inline"><semantics id="S7.SS1.p1.9.m9.1a"><mn id="S7.SS1.p1.9.m9.1.1" xref="S7.SS1.p1.9.m9.1.1.cmml">36</mn><annotation-xml encoding="MathML-Content" id="S7.SS1.p1.9.m9.1b"><cn type="integer" id="S7.SS1.p1.9.m9.1.1.cmml" xref="S7.SS1.p1.9.m9.1.1">36</cn></annotation-xml><annotation encoding="application/x-tex" id="S7.SS1.p1.9.m9.1c">36</annotation></semantics></math>% and <math id="S7.SS1.p1.10.m10.1" class="ltx_Math" alttext="37.8" display="inline"><semantics id="S7.SS1.p1.10.m10.1a"><mn id="S7.SS1.p1.10.m10.1.1" xref="S7.SS1.p1.10.m10.1.1.cmml">37.8</mn><annotation-xml encoding="MathML-Content" id="S7.SS1.p1.10.m10.1b"><cn type="float" id="S7.SS1.p1.10.m10.1.1.cmml" xref="S7.SS1.p1.10.m10.1.1">37.8</cn></annotation-xml><annotation encoding="application/x-tex" id="S7.SS1.p1.10.m10.1c">37.8</annotation></semantics></math>%, respectively. We observe faster convergence for the different model architectures in the IID scenario but do not observe any significant difference in the highest achieved accuracy between the two scenarios. This is because in <span id="S7.SS1.p1.19.8" class="ltx_text ltx_font_typewriter">FedMD</span>, the transfer learning step was performed on the Nietzsche dataset (§<a href="#S6.SS1" title="6.1. Datasets ‣ 6. Experimental Setup ‣ Training Heterogeneous Client Models using Knowledge Distillation in Serverless Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6.1</span></a>) that predicts the same set of classes as the Shakespeare dataset. Hence, the initial models after the transfer learning process were already strong in character prediction, and the subsequent collaborative fine-tuning among the FL clients only involved adapting the models to the specific characteristics of the Shakespeare dataset. Figure <a href="#S6.F9.sf3" title="In Figure 9 ‣ 6.3. Heterogeneous Client Model Architectures ‣ 6. Experimental Setup ‣ Training Heterogeneous Client Models using Knowledge Distillation in Serverless Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9(c)</span></a> shows the performance of the <span id="S7.SS1.p1.19.9" class="ltx_text ltx_font_typewriter">FedDF</span> algorithm with the MNIST dataset for varying levels of data heterogeneity. We observe a maximum accuracy of <math id="S7.SS1.p1.11.m11.1" class="ltx_Math" alttext="97" display="inline"><semantics id="S7.SS1.p1.11.m11.1a"><mn id="S7.SS1.p1.11.m11.1.1" xref="S7.SS1.p1.11.m11.1.1.cmml">97</mn><annotation-xml encoding="MathML-Content" id="S7.SS1.p1.11.m11.1b"><cn type="integer" id="S7.SS1.p1.11.m11.1.1.cmml" xref="S7.SS1.p1.11.m11.1.1">97</cn></annotation-xml><annotation encoding="application/x-tex" id="S7.SS1.p1.11.m11.1c">97</annotation></semantics></math>% with <math id="S7.SS1.p1.12.m12.1" class="ltx_Math" alttext="\alpha=100" display="inline"><semantics id="S7.SS1.p1.12.m12.1a"><mrow id="S7.SS1.p1.12.m12.1.1" xref="S7.SS1.p1.12.m12.1.1.cmml"><mi id="S7.SS1.p1.12.m12.1.1.2" xref="S7.SS1.p1.12.m12.1.1.2.cmml">α</mi><mo id="S7.SS1.p1.12.m12.1.1.1" xref="S7.SS1.p1.12.m12.1.1.1.cmml">=</mo><mn id="S7.SS1.p1.12.m12.1.1.3" xref="S7.SS1.p1.12.m12.1.1.3.cmml">100</mn></mrow><annotation-xml encoding="MathML-Content" id="S7.SS1.p1.12.m12.1b"><apply id="S7.SS1.p1.12.m12.1.1.cmml" xref="S7.SS1.p1.12.m12.1.1"><eq id="S7.SS1.p1.12.m12.1.1.1.cmml" xref="S7.SS1.p1.12.m12.1.1.1"></eq><ci id="S7.SS1.p1.12.m12.1.1.2.cmml" xref="S7.SS1.p1.12.m12.1.1.2">𝛼</ci><cn type="integer" id="S7.SS1.p1.12.m12.1.1.3.cmml" xref="S7.SS1.p1.12.m12.1.1.3">100</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.SS1.p1.12.m12.1c">\alpha=100</annotation></semantics></math> and a accuracy of <math id="S7.SS1.p1.13.m13.1" class="ltx_Math" alttext="94.8" display="inline"><semantics id="S7.SS1.p1.13.m13.1a"><mn id="S7.SS1.p1.13.m13.1.1" xref="S7.SS1.p1.13.m13.1.1.cmml">94.8</mn><annotation-xml encoding="MathML-Content" id="S7.SS1.p1.13.m13.1b"><cn type="float" id="S7.SS1.p1.13.m13.1.1.cmml" xref="S7.SS1.p1.13.m13.1.1">94.8</cn></annotation-xml><annotation encoding="application/x-tex" id="S7.SS1.p1.13.m13.1c">94.8</annotation></semantics></math>% with <math id="S7.SS1.p1.14.m14.1" class="ltx_Math" alttext="\alpha=0.1" display="inline"><semantics id="S7.SS1.p1.14.m14.1a"><mrow id="S7.SS1.p1.14.m14.1.1" xref="S7.SS1.p1.14.m14.1.1.cmml"><mi id="S7.SS1.p1.14.m14.1.1.2" xref="S7.SS1.p1.14.m14.1.1.2.cmml">α</mi><mo id="S7.SS1.p1.14.m14.1.1.1" xref="S7.SS1.p1.14.m14.1.1.1.cmml">=</mo><mn id="S7.SS1.p1.14.m14.1.1.3" xref="S7.SS1.p1.14.m14.1.1.3.cmml">0.1</mn></mrow><annotation-xml encoding="MathML-Content" id="S7.SS1.p1.14.m14.1b"><apply id="S7.SS1.p1.14.m14.1.1.cmml" xref="S7.SS1.p1.14.m14.1.1"><eq id="S7.SS1.p1.14.m14.1.1.1.cmml" xref="S7.SS1.p1.14.m14.1.1.1"></eq><ci id="S7.SS1.p1.14.m14.1.1.2.cmml" xref="S7.SS1.p1.14.m14.1.1.2">𝛼</ci><cn type="float" id="S7.SS1.p1.14.m14.1.1.3.cmml" xref="S7.SS1.p1.14.m14.1.1.3">0.1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.SS1.p1.14.m14.1c">\alpha=0.1</annotation></semantics></math>. Figures <a href="#S6.F9.sf4" title="In Figure 9 ‣ 6.3. Heterogeneous Client Model Architectures ‣ 6. Experimental Setup ‣ Training Heterogeneous Client Models using Knowledge Distillation in Serverless Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9(d)</span></a> and <a href="#S6.F9.sf5" title="In Figure 9 ‣ 6.3. Heterogeneous Client Model Architectures ‣ 6. Experimental Setup ‣ Training Heterogeneous Client Models using Knowledge Distillation in Serverless Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9(e)</span></a> show the performance of the <span id="S7.SS1.p1.19.10" class="ltx_text ltx_font_typewriter">FedDF</span> algorithm with the CIFAR and the Shakespeare datasets, respectively. In the IID scenario, we observed maximum model accuracies of <math id="S7.SS1.p1.15.m15.1" class="ltx_Math" alttext="57.5" display="inline"><semantics id="S7.SS1.p1.15.m15.1a"><mn id="S7.SS1.p1.15.m15.1.1" xref="S7.SS1.p1.15.m15.1.1.cmml">57.5</mn><annotation-xml encoding="MathML-Content" id="S7.SS1.p1.15.m15.1b"><cn type="float" id="S7.SS1.p1.15.m15.1.1.cmml" xref="S7.SS1.p1.15.m15.1.1">57.5</cn></annotation-xml><annotation encoding="application/x-tex" id="S7.SS1.p1.15.m15.1c">57.5</annotation></semantics></math>% and <math id="S7.SS1.p1.16.m16.1" class="ltx_Math" alttext="40" display="inline"><semantics id="S7.SS1.p1.16.m16.1a"><mn id="S7.SS1.p1.16.m16.1.1" xref="S7.SS1.p1.16.m16.1.1.cmml">40</mn><annotation-xml encoding="MathML-Content" id="S7.SS1.p1.16.m16.1b"><cn type="integer" id="S7.SS1.p1.16.m16.1.1.cmml" xref="S7.SS1.p1.16.m16.1.1">40</cn></annotation-xml><annotation encoding="application/x-tex" id="S7.SS1.p1.16.m16.1c">40</annotation></semantics></math>% for the two datasets. On the other hand, in the non-IID scenario, we observed maximum accuracies of <math id="S7.SS1.p1.17.m17.1" class="ltx_Math" alttext="55" display="inline"><semantics id="S7.SS1.p1.17.m17.1a"><mn id="S7.SS1.p1.17.m17.1.1" xref="S7.SS1.p1.17.m17.1.1.cmml">55</mn><annotation-xml encoding="MathML-Content" id="S7.SS1.p1.17.m17.1b"><cn type="integer" id="S7.SS1.p1.17.m17.1.1.cmml" xref="S7.SS1.p1.17.m17.1.1">55</cn></annotation-xml><annotation encoding="application/x-tex" id="S7.SS1.p1.17.m17.1c">55</annotation></semantics></math>% and <math id="S7.SS1.p1.18.m18.1" class="ltx_Math" alttext="43" display="inline"><semantics id="S7.SS1.p1.18.m18.1a"><mn id="S7.SS1.p1.18.m18.1.1" xref="S7.SS1.p1.18.m18.1.1.cmml">43</mn><annotation-xml encoding="MathML-Content" id="S7.SS1.p1.18.m18.1b"><cn type="integer" id="S7.SS1.p1.18.m18.1.1.cmml" xref="S7.SS1.p1.18.m18.1.1">43</cn></annotation-xml><annotation encoding="application/x-tex" id="S7.SS1.p1.18.m18.1c">43</annotation></semantics></math>% for the two datasets. We observe that <span id="S7.SS1.p1.19.11" class="ltx_text ltx_font_typewriter">FedDF</span> demonstrates greater robustness to higher non-IID data distributions compared to <span id="S7.SS1.p1.19.12" class="ltx_text ltx_font_typewriter">FedMD</span>, as it maintains higher model accuracies even for lower values of <math id="S7.SS1.p1.19.m19.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S7.SS1.p1.19.m19.1a"><mi id="S7.SS1.p1.19.m19.1.1" xref="S7.SS1.p1.19.m19.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S7.SS1.p1.19.m19.1b"><ci id="S7.SS1.p1.19.m19.1.1.cmml" xref="S7.SS1.p1.19.m19.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.SS1.p1.19.m19.1c">\alpha</annotation></semantics></math>. This can be attributed to two reasons. First, the usage of ensemble distillation in <span id="S7.SS1.p1.19.13" class="ltx_text ltx_font_typewriter">FedDF</span> enhances the robustness of the global model to noise and outliers. Second, <span id="S7.SS1.p1.19.14" class="ltx_text ltx_font_typewriter">FedDF</span> leverages unlabeled data in the distillation process, thereby enhancing its capacity to generalize to unseen data.</p>
</div>
</section>
<section id="S7.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">7.2. </span>Comparing Performance and Cost</h3>

<figure id="S7.F10" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S7.F10.sf1" class="ltx_figure ltx_figure_panel"><img src="/html/2402.07295/assets/x17.png" id="S7.F10.sf1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="203" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S7.F10.sf1.3.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S7.F10.sf1.4.2" class="ltx_text ltx_font_typewriter" style="font-size:90%;">FedMD<span id="S7.F10.sf1.4.2.1" class="ltx_text ltx_font_serif"> with MNIST.</span></span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S7.F10.sf2" class="ltx_figure ltx_figure_panel"><img src="/html/2402.07295/assets/x18.png" id="S7.F10.sf2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="204" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S7.F10.sf2.3.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S7.F10.sf2.4.2" class="ltx_text ltx_font_typewriter" style="font-size:90%;">FedMD<span id="S7.F10.sf2.4.2.1" class="ltx_text ltx_font_serif"> with CIFAR.</span></span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S7.F10.sf3" class="ltx_figure ltx_figure_panel"><img src="/html/2402.07295/assets/x19.png" id="S7.F10.sf3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="203" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S7.F10.sf3.3.1.1" class="ltx_text" style="font-size:90%;">(c)</span> </span><span id="S7.F10.sf3.4.2" class="ltx_text ltx_font_typewriter" style="font-size:90%;">FedMD<span id="S7.F10.sf3.4.2.1" class="ltx_text ltx_font_serif"> with Shakespeare.</span></span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S7.F10.sf4" class="ltx_figure ltx_figure_panel"><img src="/html/2402.07295/assets/x20.png" id="S7.F10.sf4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="462" height="225" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S7.F10.sf4.3.1.1" class="ltx_text" style="font-size:90%;">(d)</span> </span><span id="S7.F10.sf4.4.2" class="ltx_text ltx_font_typewriter" style="font-size:90%;">FedDF<span id="S7.F10.sf4.4.2.1" class="ltx_text ltx_font_serif"> with MNIST.</span></span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S7.F10.sf5" class="ltx_figure ltx_figure_panel"><img src="/html/2402.07295/assets/x21.png" id="S7.F10.sf5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="462" height="226" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S7.F10.sf5.3.1.1" class="ltx_text" style="font-size:90%;">(e)</span> </span><span id="S7.F10.sf5.4.2" class="ltx_text ltx_font_typewriter" style="font-size:90%;">FedDF<span id="S7.F10.sf5.4.2.1" class="ltx_text ltx_font_serif"> with CIFAR.</span></span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S7.F10.sf6" class="ltx_figure ltx_figure_panel"><img src="/html/2402.07295/assets/x22.png" id="S7.F10.sf6.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="223" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S7.F10.sf6.3.1.1" class="ltx_text" style="font-size:90%;">(f)</span> </span><span id="S7.F10.sf6.4.2" class="ltx_text ltx_font_typewriter" style="font-size:90%;">FedDF<span id="S7.F10.sf6.4.2.1" class="ltx_text ltx_font_serif"> with Shakespeare.</span></span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S7.F10.4.1.1" class="ltx_text" style="font-size:90%;">Figure 10</span>. </span><span id="S7.F10.5.2" class="ltx_text" style="font-size:90%;">Comparing individual training steps and collaborative round durations for the serverless implementations of <span id="S7.F10.5.2.1" class="ltx_text ltx_font_typewriter">FedMD</span> and <span id="S7.F10.5.2.2" class="ltx_text ltx_font_typewriter">FedDF</span> across different datasets (§<a href="#S6.SS1" title="6.1. Datasets ‣ 6. Experimental Setup ‣ Training Heterogeneous Client Models using Knowledge Distillation in Serverless Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6.1</span></a>).</span></figcaption>
</figure>
<div id="S7.SS2.p1" class="ltx_para">
<p id="S7.SS2.p1.1" class="ltx_p">Analyzing FL systems involves considering important factors such as the time and the cost required to complete different training tasks. This is particularly relevant in our case, as we utilize FaaS, in which users are only billed for the execution time of functions <cite class="ltx_cite ltx_citemacro_citep">(Castro et al<span class="ltx_text">.</span>, <a href="#bib.bib8" title="" class="ltx_ref">2019</a>)</cite>. To present summarized results, we aggregate the timings and costs across all clients for the different levels of data heterogeneity. For computing training costs, we use the cost computation model <cite class="ltx_cite ltx_citemacro_citep">(Cloud, <a href="#bib.bib13" title="" class="ltx_ref">2022</a>)</cite> used by Google to estimate the cost for each function based on the number of invocations, allocated memory, and execution duration (§<a href="#S6.SS4" title="6.4. Infrastructure Setup ‣ 6. Experimental Setup ‣ Training Heterogeneous Client Models using Knowledge Distillation in Serverless Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6.4</span></a>).</p>
</div>
<figure id="S7.T5" class="ltx_table">
<p id="S7.T5.2" class="ltx_p ltx_align_center"><span id="S7.T5.2.1" class="ltx_text ltx_inline-block" style="width:433.6pt;">
<span id="S7.T5.2.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:494.7pt;height:150.4pt;vertical-align:-1.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<span id="S7.T5.2.1.1.1" class="ltx_p"><span id="S7.T5.2.1.1.1.1" class="ltx_text">
<span id="S7.T5.2.1.1.1.1.1" class="ltx_tabular ltx_align_middle">
<span class="ltx_tbody">
<span id="S7.T5.2.1.1.1.1.1.1.1" class="ltx_tr">
<span id="S7.T5.2.1.1.1.1.1.1.1.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">Dataset</span>
<span id="S7.T5.2.1.1.1.1.1.1.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Metric</span>
<span id="S7.T5.2.1.1.1.1.1.1.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Aggregate</span>
<span id="S7.T5.2.1.1.1.1.1.1.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Communicate</span>
<span id="S7.T5.2.1.1.1.1.1.1.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Revisit</span>
<span id="S7.T5.2.1.1.1.1.1.1.1.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="S7.T5.2.1.1.1.1.1.1.1.6.1" class="ltx_tabular ltx_align_middle">
<span id="S7.T5.2.1.1.1.1.1.1.1.6.1.1" class="ltx_tr">
<span id="S7.T5.2.1.1.1.1.1.1.1.6.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Transfer Learning</span></span>
<span id="S7.T5.2.1.1.1.1.1.1.1.6.1.2" class="ltx_tr">
<span id="S7.T5.2.1.1.1.1.1.1.1.6.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">(Private)</span></span>
</span></span>
<span id="S7.T5.2.1.1.1.1.1.1.1.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Digest</span>
<span id="S7.T5.2.1.1.1.1.1.1.1.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Overall</span></span>
<span id="S7.T5.2.1.1.1.1.1.2.2" class="ltx_tr">
<span id="S7.T5.2.1.1.1.1.1.2.2.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t ltx_rowspan ltx_rowspan_2"><span id="S7.T5.2.1.1.1.1.1.2.2.1.1" class="ltx_text">MNIST</span></span>
<span id="S7.T5.2.1.1.1.1.1.2.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Duration (min)</span>
<span id="S7.T5.2.1.1.1.1.1.2.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">55.2</span>
<span id="S7.T5.2.1.1.1.1.1.2.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">378.4</span>
<span id="S7.T5.2.1.1.1.1.1.2.2.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">867</span>
<span id="S7.T5.2.1.1.1.1.1.2.2.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">42.5</span>
<span id="S7.T5.2.1.1.1.1.1.2.2.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">1329.8</span>
<span id="S7.T5.2.1.1.1.1.1.2.2.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S7.T5.2.1.1.1.1.1.2.2.8.1" class="ltx_text ltx_font_bold">2672.9</span></span></span>
<span id="S7.T5.2.1.1.1.1.1.3.3" class="ltx_tr">
<span id="S7.T5.2.1.1.1.1.1.3.3.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Cost (USD)</span>
<span id="S7.T5.2.1.1.1.1.1.3.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.37</span>
<span id="S7.T5.2.1.1.1.1.1.3.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">1.32</span>
<span id="S7.T5.2.1.1.1.1.1.3.3.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">3.02</span>
<span id="S7.T5.2.1.1.1.1.1.3.3.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.15</span>
<span id="S7.T5.2.1.1.1.1.1.3.3.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">4.63</span>
<span id="S7.T5.2.1.1.1.1.1.3.3.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S7.T5.2.1.1.1.1.1.3.3.7.1" class="ltx_text ltx_font_bold">9.49</span></span></span>
<span id="S7.T5.2.1.1.1.1.1.4.4" class="ltx_tr">
<span id="S7.T5.2.1.1.1.1.1.4.4.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t ltx_rowspan ltx_rowspan_2"><span id="S7.T5.2.1.1.1.1.1.4.4.1.1" class="ltx_text">CIFAR</span></span>
<span id="S7.T5.2.1.1.1.1.1.4.4.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Duration (min)</span>
<span id="S7.T5.2.1.1.1.1.1.4.4.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">47.7</span>
<span id="S7.T5.2.1.1.1.1.1.4.4.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">579.4</span>
<span id="S7.T5.2.1.1.1.1.1.4.4.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">111.6</span>
<span id="S7.T5.2.1.1.1.1.1.4.4.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">6.5</span>
<span id="S7.T5.2.1.1.1.1.1.4.4.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">746.4</span>
<span id="S7.T5.2.1.1.1.1.1.4.4.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S7.T5.2.1.1.1.1.1.4.4.8.1" class="ltx_text ltx_font_bold">1491.6</span></span></span>
<span id="S7.T5.2.1.1.1.1.1.5.5" class="ltx_tr">
<span id="S7.T5.2.1.1.1.1.1.5.5.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Cost (USD)</span>
<span id="S7.T5.2.1.1.1.1.1.5.5.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.32</span>
<span id="S7.T5.2.1.1.1.1.1.5.5.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">2.02</span>
<span id="S7.T5.2.1.1.1.1.1.5.5.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.39</span>
<span id="S7.T5.2.1.1.1.1.1.5.5.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.02</span>
<span id="S7.T5.2.1.1.1.1.1.5.5.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">2.6</span>
<span id="S7.T5.2.1.1.1.1.1.5.5.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S7.T5.2.1.1.1.1.1.5.5.7.1" class="ltx_text ltx_font_bold">5.35</span></span></span>
<span id="S7.T5.2.1.1.1.1.1.6.6" class="ltx_tr">
<span id="S7.T5.2.1.1.1.1.1.6.6.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t ltx_rowspan ltx_rowspan_2"><span id="S7.T5.2.1.1.1.1.1.6.6.1.1" class="ltx_text">Shakespeare</span></span>
<span id="S7.T5.2.1.1.1.1.1.6.6.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Duration (min)</span>
<span id="S7.T5.2.1.1.1.1.1.6.6.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">64.5</span>
<span id="S7.T5.2.1.1.1.1.1.6.6.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">300.8</span>
<span id="S7.T5.2.1.1.1.1.1.6.6.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">5945.2</span>
<span id="S7.T5.2.1.1.1.1.1.6.6.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">122.7</span>
<span id="S7.T5.2.1.1.1.1.1.6.6.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">656.3</span>
<span id="S7.T5.2.1.1.1.1.1.6.6.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S7.T5.2.1.1.1.1.1.6.6.8.1" class="ltx_text ltx_font_bold">7089.5</span></span></span>
<span id="S7.T5.2.1.1.1.1.1.7.7" class="ltx_tr">
<span id="S7.T5.2.1.1.1.1.1.7.7.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">Cost (USD)</span>
<span id="S7.T5.2.1.1.1.1.1.7.7.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">0.43</span>
<span id="S7.T5.2.1.1.1.1.1.7.7.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">1.05</span>
<span id="S7.T5.2.1.1.1.1.1.7.7.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">20.69</span>
<span id="S7.T5.2.1.1.1.1.1.7.7.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">0.43</span>
<span id="S7.T5.2.1.1.1.1.1.7.7.6" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">2.28</span>
<span id="S7.T5.2.1.1.1.1.1.7.7.7" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S7.T5.2.1.1.1.1.1.7.7.7.1" class="ltx_text ltx_font_bold">24.88</span></span></span>
</span>
</span></span></span>
</span></span></span></p>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S7.T5.4.1.1" class="ltx_text" style="font-size:90%;">Table 5</span>. </span><span id="S7.T5.5.2" class="ltx_text" style="font-size:90%;">Comparing total execution time and cost for serverless <span id="S7.T5.5.2.1" class="ltx_text ltx_font_typewriter">FedMD</span> across the different datasets.</span></figcaption>
</figure>
<figure id="S7.T6" class="ltx_table">
<p id="S7.T6.2" class="ltx_p ltx_align_center"><span id="S7.T6.2.1" class="ltx_text ltx_inline-block" style="width:433.6pt;">
<span id="S7.T6.2.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:298.2pt;height:126pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<span id="S7.T6.2.1.1.1" class="ltx_p"><span id="S7.T6.2.1.1.1.1" class="ltx_text">
<span id="S7.T6.2.1.1.1.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<span class="ltx_thead">
<span id="S7.T6.2.1.1.1.1.1.1.1" class="ltx_tr">
<span id="S7.T6.2.1.1.1.1.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t">Dataset</span>
<span id="S7.T6.2.1.1.1.1.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">Metric</span>
<span id="S7.T6.2.1.1.1.1.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">Aggregators</span>
<span id="S7.T6.2.1.1.1.1.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">Clients</span>
<span id="S7.T6.2.1.1.1.1.1.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">Overall</span></span>
</span>
<span class="ltx_tbody">
<span id="S7.T6.2.1.1.1.1.1.2.1" class="ltx_tr">
<span id="S7.T6.2.1.1.1.1.1.2.1.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t ltx_rowspan ltx_rowspan_2"><span id="S7.T6.2.1.1.1.1.1.2.1.1.1" class="ltx_text">MNIST</span></span>
<span id="S7.T6.2.1.1.1.1.1.2.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Duration (min)</span>
<span id="S7.T6.2.1.1.1.1.1.2.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">152</span>
<span id="S7.T6.2.1.1.1.1.1.2.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">56.4</span>
<span id="S7.T6.2.1.1.1.1.1.2.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S7.T6.2.1.1.1.1.1.2.1.5.1" class="ltx_text ltx_font_bold">208.4</span></span></span>
<span id="S7.T6.2.1.1.1.1.1.3.2" class="ltx_tr">
<span id="S7.T6.2.1.1.1.1.1.3.2.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Cost (USD)</span>
<span id="S7.T6.2.1.1.1.1.1.3.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">6.07</span>
<span id="S7.T6.2.1.1.1.1.1.3.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.2</span>
<span id="S7.T6.2.1.1.1.1.1.3.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S7.T6.2.1.1.1.1.1.3.2.4.1" class="ltx_text ltx_font_bold">6.27</span></span></span>
<span id="S7.T6.2.1.1.1.1.1.4.3" class="ltx_tr">
<span id="S7.T6.2.1.1.1.1.1.4.3.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t ltx_rowspan ltx_rowspan_2"><span id="S7.T6.2.1.1.1.1.1.4.3.1.1" class="ltx_text">CIFAR</span></span>
<span id="S7.T6.2.1.1.1.1.1.4.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Duration (min)</span>
<span id="S7.T6.2.1.1.1.1.1.4.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">163.87</span>
<span id="S7.T6.2.1.1.1.1.1.4.3.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">213.55</span>
<span id="S7.T6.2.1.1.1.1.1.4.3.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S7.T6.2.1.1.1.1.1.4.3.5.1" class="ltx_text ltx_font_bold">377.42</span></span></span>
<span id="S7.T6.2.1.1.1.1.1.5.4" class="ltx_tr">
<span id="S7.T6.2.1.1.1.1.1.5.4.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Cost (USD)</span>
<span id="S7.T6.2.1.1.1.1.1.5.4.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">5.46</span>
<span id="S7.T6.2.1.1.1.1.1.5.4.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.74</span>
<span id="S7.T6.2.1.1.1.1.1.5.4.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S7.T6.2.1.1.1.1.1.5.4.4.1" class="ltx_text ltx_font_bold">6.2</span></span></span>
<span id="S7.T6.2.1.1.1.1.1.6.5" class="ltx_tr">
<span id="S7.T6.2.1.1.1.1.1.6.5.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t ltx_rowspan ltx_rowspan_2"><span id="S7.T6.2.1.1.1.1.1.6.5.1.1" class="ltx_text">Shakespeare</span></span>
<span id="S7.T6.2.1.1.1.1.1.6.5.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Duration (min)</span>
<span id="S7.T6.2.1.1.1.1.1.6.5.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">134.4</span>
<span id="S7.T6.2.1.1.1.1.1.6.5.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">466.9</span>
<span id="S7.T6.2.1.1.1.1.1.6.5.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S7.T6.2.1.1.1.1.1.6.5.5.1" class="ltx_text ltx_font_bold">601.3</span></span></span>
<span id="S7.T6.2.1.1.1.1.1.7.6" class="ltx_tr">
<span id="S7.T6.2.1.1.1.1.1.7.6.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">Cost (USD)</span>
<span id="S7.T6.2.1.1.1.1.1.7.6.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">2.68</span>
<span id="S7.T6.2.1.1.1.1.1.7.6.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">1.62</span>
<span id="S7.T6.2.1.1.1.1.1.7.6.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S7.T6.2.1.1.1.1.1.7.6.4.1" class="ltx_text ltx_font_bold">4.3</span></span></span>
</span>
</span></span></span>
</span></span></span></p>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S7.T6.4.1.1" class="ltx_text" style="font-size:90%;">Table 6</span>. </span><span id="S7.T6.5.2" class="ltx_text" style="font-size:90%;">Comparing total execution time and cost for serverless <span id="S7.T6.5.2.1" class="ltx_text ltx_font_typewriter">FedDF</span> across the different datasets.</span></figcaption>
</figure>
<div id="S7.SS2.p2" class="ltx_para">
<p id="S7.SS2.p2.7" class="ltx_p">To offer detailed insights into the serverless KD training process, Figure <a href="#S7.F10" title="Figure 10 ‣ 7.2. Comparing Performance and Cost ‣ 7. Experimental Results ‣ Training Heterogeneous Client Models using Knowledge Distillation in Serverless Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10</span></a> shows the timings of the individual training steps and the collaborative round durations for the two algorithms. For relevance, we omit the timings for the initial one-time pre-training process in <span id="S7.SS2.p2.7.1" class="ltx_text ltx_font_typewriter">FedMD</span> (§<a href="#S5.SS1" title="5.1. Serverless FedMD ‣ 5. Serverless Knowledge Distillation ‣ Training Heterogeneous Client Models using Knowledge Distillation in Serverless Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.1</span></a>). For the MNIST dataset with <span id="S7.SS2.p2.7.2" class="ltx_text ltx_font_typewriter">FedMD</span>, we observe that each collaborative training round takes between <math id="S7.SS2.p2.1.m1.1" class="ltx_Math" alttext="360" display="inline"><semantics id="S7.SS2.p2.1.m1.1a"><mn id="S7.SS2.p2.1.m1.1.1" xref="S7.SS2.p2.1.m1.1.1.cmml">360</mn><annotation-xml encoding="MathML-Content" id="S7.SS2.p2.1.m1.1b"><cn type="integer" id="S7.SS2.p2.1.m1.1.1.cmml" xref="S7.SS2.p2.1.m1.1.1">360</cn></annotation-xml><annotation encoding="application/x-tex" id="S7.SS2.p2.1.m1.1c">360</annotation></semantics></math> to <math id="S7.SS2.p2.2.m2.1" class="ltx_Math" alttext="390" display="inline"><semantics id="S7.SS2.p2.2.m2.1a"><mn id="S7.SS2.p2.2.m2.1.1" xref="S7.SS2.p2.2.m2.1.1.cmml">390</mn><annotation-xml encoding="MathML-Content" id="S7.SS2.p2.2.m2.1b"><cn type="integer" id="S7.SS2.p2.2.m2.1.1.cmml" xref="S7.SS2.p2.2.m2.1.1">390</cn></annotation-xml><annotation encoding="application/x-tex" id="S7.SS2.p2.2.m2.1c">390</annotation></semantics></math> seconds, as shown in Figure <a href="#S7.F10.sf1" title="In Figure 10 ‣ 7.2. Comparing Performance and Cost ‣ 7. Experimental Results ‣ Training Heterogeneous Client Models using Knowledge Distillation in Serverless Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10(a)</span></a>. A significant portion of this time (<math id="S7.SS2.p2.3.m3.1" class="ltx_Math" alttext="40" display="inline"><semantics id="S7.SS2.p2.3.m3.1a"><mn id="S7.SS2.p2.3.m3.1.1" xref="S7.SS2.p2.3.m3.1.1.cmml">40</mn><annotation-xml encoding="MathML-Content" id="S7.SS2.p2.3.m3.1b"><cn type="integer" id="S7.SS2.p2.3.m3.1.1.cmml" xref="S7.SS2.p2.3.m3.1.1">40</cn></annotation-xml><annotation encoding="application/x-tex" id="S7.SS2.p2.3.m3.1c">40</annotation></semantics></math>%) is spent within the single aggregator function for aggregating prediction logits from all <math id="S7.SS2.p2.4.m4.1" class="ltx_Math" alttext="100" display="inline"><semantics id="S7.SS2.p2.4.m4.1a"><mn id="S7.SS2.p2.4.m4.1.1" xref="S7.SS2.p2.4.m4.1.1.cmml">100</mn><annotation-xml encoding="MathML-Content" id="S7.SS2.p2.4.m4.1b"><cn type="integer" id="S7.SS2.p2.4.m4.1.1.cmml" xref="S7.SS2.p2.4.m4.1.1">100</cn></annotation-xml><annotation encoding="application/x-tex" id="S7.SS2.p2.4.m4.1c">100</annotation></semantics></math> participating clients. The digest and revisit steps take a comparable amount of time, while the communicate step is the fastest as it involves only a forward pass inference on the public dataset by all clients (§<a href="#S5.SS1" title="5.1. Serverless FedMD ‣ 5. Serverless Knowledge Distillation ‣ Training Heterogeneous Client Models using Knowledge Distillation in Serverless Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.1</span></a>). We observe relatively shorter round durations for the CIFAR dataset with <span id="S7.SS2.p2.7.3" class="ltx_text ltx_font_typewriter">FedMD</span> compared to MNIST, as shown in Figure <a href="#S7.F10.sf2" title="In Figure 10 ‣ 7.2. Comparing Performance and Cost ‣ 7. Experimental Results ‣ Training Heterogeneous Client Models using Knowledge Distillation in Serverless Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10(b)</span></a>. This can be attributed to the shorter revisit step due to the smaller private client dataset as described in §<a href="#S6.SS2" title="6.2. Heterogeneous Client Data Distribution ‣ 6. Experimental Setup ‣ Training Heterogeneous Client Models using Knowledge Distillation in Serverless Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6.2</span></a>. For the Shakespeare dataset with <span id="S7.SS2.p2.7.4" class="ltx_text ltx_font_typewriter">FedMD</span>, a majority of the time (<math id="S7.SS2.p2.5.m5.1" class="ltx_Math" alttext="90" display="inline"><semantics id="S7.SS2.p2.5.m5.1a"><mn id="S7.SS2.p2.5.m5.1.1" xref="S7.SS2.p2.5.m5.1.1.cmml">90</mn><annotation-xml encoding="MathML-Content" id="S7.SS2.p2.5.m5.1b"><cn type="integer" id="S7.SS2.p2.5.m5.1.1.cmml" xref="S7.SS2.p2.5.m5.1.1">90</cn></annotation-xml><annotation encoding="application/x-tex" id="S7.SS2.p2.5.m5.1c">90</annotation></semantics></math>%) is spent in the revisit step, as shown in Figure <a href="#S7.F10.sf3" title="In Figure 10 ‣ 7.2. Comparing Performance and Cost ‣ 7. Experimental Results ‣ Training Heterogeneous Client Models using Knowledge Distillation in Serverless Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10(c)</span></a>. This can be attributed to the significantly large number of epochs required by the LSTM text models for this training step as compared to the CNN models for image tasks (§<a href="#S6.SS3" title="6.3. Heterogeneous Client Model Architectures ‣ 6. Experimental Setup ‣ Training Heterogeneous Client Models using Knowledge Distillation in Serverless Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6.3</span></a>). Figures <a href="#S7.F10.sf4" title="In Figure 10 ‣ 7.2. Comparing Performance and Cost ‣ 7. Experimental Results ‣ Training Heterogeneous Client Models using Knowledge Distillation in Serverless Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10(d)</span></a>, <a href="#S7.F10.sf5" title="In Figure 10 ‣ 7.2. Comparing Performance and Cost ‣ 7. Experimental Results ‣ Training Heterogeneous Client Models using Knowledge Distillation in Serverless Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10(e)</span></a>, and <a href="#S7.F10.sf6" title="In Figure 10 ‣ 7.2. Comparing Performance and Cost ‣ 7. Experimental Results ‣ Training Heterogeneous Client Models using Knowledge Distillation in Serverless Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10(f)</span></a> present the total collaborative round duration along with the timings for private client training and ensemble distillation for the different datasets with <span id="S7.SS2.p2.7.5" class="ltx_text ltx_font_typewriter">FedDF</span>. The highlighted area in these plots represents the variability observed for multiple runs across different data heterogeneity levels (§<a href="#S6.SS2" title="6.2. Heterogeneous Client Data Distribution ‣ 6. Experimental Setup ‣ Training Heterogeneous Client Models using Knowledge Distillation in Serverless Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6.2</span></a>). For the MNIST and CIFAR datasets, we observe that the majority of the round duration (<math id="S7.SS2.p2.6.m6.1" class="ltx_Math" alttext="&gt;" display="inline"><semantics id="S7.SS2.p2.6.m6.1a"><mo id="S7.SS2.p2.6.m6.1.1" xref="S7.SS2.p2.6.m6.1.1.cmml">&gt;</mo><annotation-xml encoding="MathML-Content" id="S7.SS2.p2.6.m6.1b"><gt id="S7.SS2.p2.6.m6.1.1.cmml" xref="S7.SS2.p2.6.m6.1.1"></gt></annotation-xml><annotation encoding="application/x-tex" id="S7.SS2.p2.6.m6.1c">&gt;</annotation></semantics></math><math id="S7.SS2.p2.7.m7.1" class="ltx_Math" alttext="90" display="inline"><semantics id="S7.SS2.p2.7.m7.1a"><mn id="S7.SS2.p2.7.m7.1.1" xref="S7.SS2.p2.7.m7.1.1.cmml">90</mn><annotation-xml encoding="MathML-Content" id="S7.SS2.p2.7.m7.1b"><cn type="integer" id="S7.SS2.p2.7.m7.1.1.cmml" xref="S7.SS2.p2.7.m7.1.1">90</cn></annotation-xml><annotation encoding="application/x-tex" id="S7.SS2.p2.7.m7.1c">90</annotation></semantics></math>%) is spent in the ensemble distillation process that occurs in the aggregator functions for each unique model architecture (§<a href="#S5.SS2" title="5.2. Serverless FedDF ‣ 5. Serverless Knowledge Distillation ‣ Training Heterogeneous Client Models using Knowledge Distillation in Serverless Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.2</span></a>). On the other hand, for the Shakespeare dataset, we observe similar durations for the ensemble distillation and private client training process. This can again be attributed to the higher number of local epochs required in private client training for LSTM networks.</p>
</div>
<figure id="S7.T7" class="ltx_table">
<p id="S7.T7.2" class="ltx_p ltx_align_center"><span id="S7.T7.2.2" class="ltx_text ltx_inline-block" style="width:433.6pt;">
<span id="S7.T7.2.2.2.2" class="ltx_inline-block ltx_transformed_outer" style="width:316.2pt;height:162pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<span id="S7.T7.2.2.2.2.2" class="ltx_p"><span id="S7.T7.2.2.2.2.2.2" class="ltx_text">
<span id="S7.T7.2.2.2.2.2.2.2" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<span class="ltx_tbody">
<span id="S7.T7.2.2.2.2.2.2.2.3.1" class="ltx_tr">
<span id="S7.T7.2.2.2.2.2.2.2.3.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t ltx_rowspan ltx_rowspan_3"><span id="S7.T7.2.2.2.2.2.2.2.3.1.1.1" class="ltx_text">Model ID</span></span>
<span id="S7.T7.2.2.2.2.2.2.2.3.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t ltx_colspan ltx_colspan_6">Maximum Top-1 accuracy (%)</span></span>
<span id="S7.T7.2.2.2.2.2.2.2.2" class="ltx_tr">
<span id="S7.T7.1.1.1.1.1.1.1.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t ltx_colspan ltx_colspan_2">MNIST <math id="S7.T7.1.1.1.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\alpha=1" display="inline"><semantics id="S7.T7.1.1.1.1.1.1.1.1.1.m1.1a"><mrow id="S7.T7.1.1.1.1.1.1.1.1.1.m1.1.1" xref="S7.T7.1.1.1.1.1.1.1.1.1.m1.1.1.cmml"><mi id="S7.T7.1.1.1.1.1.1.1.1.1.m1.1.1.2" xref="S7.T7.1.1.1.1.1.1.1.1.1.m1.1.1.2.cmml">α</mi><mo id="S7.T7.1.1.1.1.1.1.1.1.1.m1.1.1.1" xref="S7.T7.1.1.1.1.1.1.1.1.1.m1.1.1.1.cmml">=</mo><mn id="S7.T7.1.1.1.1.1.1.1.1.1.m1.1.1.3" xref="S7.T7.1.1.1.1.1.1.1.1.1.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S7.T7.1.1.1.1.1.1.1.1.1.m1.1b"><apply id="S7.T7.1.1.1.1.1.1.1.1.1.m1.1.1.cmml" xref="S7.T7.1.1.1.1.1.1.1.1.1.m1.1.1"><eq id="S7.T7.1.1.1.1.1.1.1.1.1.m1.1.1.1.cmml" xref="S7.T7.1.1.1.1.1.1.1.1.1.m1.1.1.1"></eq><ci id="S7.T7.1.1.1.1.1.1.1.1.1.m1.1.1.2.cmml" xref="S7.T7.1.1.1.1.1.1.1.1.1.m1.1.1.2">𝛼</ci><cn type="integer" id="S7.T7.1.1.1.1.1.1.1.1.1.m1.1.1.3.cmml" xref="S7.T7.1.1.1.1.1.1.1.1.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.T7.1.1.1.1.1.1.1.1.1.m1.1c">\alpha=1</annotation></semantics></math></span>
<span id="S7.T7.2.2.2.2.2.2.2.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t ltx_colspan ltx_colspan_2">CIFAR <math id="S7.T7.2.2.2.2.2.2.2.2.2.m1.1" class="ltx_Math" alttext="\alpha=1" display="inline"><semantics id="S7.T7.2.2.2.2.2.2.2.2.2.m1.1a"><mrow id="S7.T7.2.2.2.2.2.2.2.2.2.m1.1.1" xref="S7.T7.2.2.2.2.2.2.2.2.2.m1.1.1.cmml"><mi id="S7.T7.2.2.2.2.2.2.2.2.2.m1.1.1.2" xref="S7.T7.2.2.2.2.2.2.2.2.2.m1.1.1.2.cmml">α</mi><mo id="S7.T7.2.2.2.2.2.2.2.2.2.m1.1.1.1" xref="S7.T7.2.2.2.2.2.2.2.2.2.m1.1.1.1.cmml">=</mo><mn id="S7.T7.2.2.2.2.2.2.2.2.2.m1.1.1.3" xref="S7.T7.2.2.2.2.2.2.2.2.2.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S7.T7.2.2.2.2.2.2.2.2.2.m1.1b"><apply id="S7.T7.2.2.2.2.2.2.2.2.2.m1.1.1.cmml" xref="S7.T7.2.2.2.2.2.2.2.2.2.m1.1.1"><eq id="S7.T7.2.2.2.2.2.2.2.2.2.m1.1.1.1.cmml" xref="S7.T7.2.2.2.2.2.2.2.2.2.m1.1.1.1"></eq><ci id="S7.T7.2.2.2.2.2.2.2.2.2.m1.1.1.2.cmml" xref="S7.T7.2.2.2.2.2.2.2.2.2.m1.1.1.2">𝛼</ci><cn type="integer" id="S7.T7.2.2.2.2.2.2.2.2.2.m1.1.1.3.cmml" xref="S7.T7.2.2.2.2.2.2.2.2.2.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.T7.2.2.2.2.2.2.2.2.2.m1.1c">\alpha=1</annotation></semantics></math></span>
<span id="S7.T7.2.2.2.2.2.2.2.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t ltx_colspan ltx_colspan_2">Shakespeare (non-IID)</span></span>
<span id="S7.T7.2.2.2.2.2.2.2.4.2" class="ltx_tr">
<span id="S7.T7.2.2.2.2.2.2.2.4.2.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">FedMD</span>
<span id="S7.T7.2.2.2.2.2.2.2.4.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">FedDF</span>
<span id="S7.T7.2.2.2.2.2.2.2.4.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">FedMD</span>
<span id="S7.T7.2.2.2.2.2.2.2.4.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">FedDF</span>
<span id="S7.T7.2.2.2.2.2.2.2.4.2.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">FedMD</span>
<span id="S7.T7.2.2.2.2.2.2.2.4.2.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">FedDF</span></span>
<span id="S7.T7.2.2.2.2.2.2.2.5.3" class="ltx_tr">
<span id="S7.T7.2.2.2.2.2.2.2.5.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">0</span>
<span id="S7.T7.2.2.2.2.2.2.2.5.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.86</span>
<span id="S7.T7.2.2.2.2.2.2.2.5.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S7.T7.2.2.2.2.2.2.2.5.3.3.1" class="ltx_text ltx_font_bold">0.90</span></span>
<span id="S7.T7.2.2.2.2.2.2.2.5.3.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.40</span>
<span id="S7.T7.2.2.2.2.2.2.2.5.3.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S7.T7.2.2.2.2.2.2.2.5.3.5.1" class="ltx_text ltx_font_bold">0.52</span></span>
<span id="S7.T7.2.2.2.2.2.2.2.5.3.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.33</span>
<span id="S7.T7.2.2.2.2.2.2.2.5.3.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S7.T7.2.2.2.2.2.2.2.5.3.7.1" class="ltx_text ltx_font_bold">0.43</span></span></span>
<span id="S7.T7.2.2.2.2.2.2.2.6.4" class="ltx_tr">
<span id="S7.T7.2.2.2.2.2.2.2.6.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">1</span>
<span id="S7.T7.2.2.2.2.2.2.2.6.4.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.86</span>
<span id="S7.T7.2.2.2.2.2.2.2.6.4.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S7.T7.2.2.2.2.2.2.2.6.4.3.1" class="ltx_text ltx_font_bold">0.93</span></span>
<span id="S7.T7.2.2.2.2.2.2.2.6.4.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S7.T7.2.2.2.2.2.2.2.6.4.4.1" class="ltx_text ltx_font_bold">0.58</span></span>
<span id="S7.T7.2.2.2.2.2.2.2.6.4.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.52</span>
<span id="S7.T7.2.2.2.2.2.2.2.6.4.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S7.T7.2.2.2.2.2.2.2.6.4.6.1" class="ltx_text ltx_font_bold">0.38</span></span>
<span id="S7.T7.2.2.2.2.2.2.2.6.4.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.37</span></span>
<span id="S7.T7.2.2.2.2.2.2.2.7.5" class="ltx_tr">
<span id="S7.T7.2.2.2.2.2.2.2.7.5.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">2</span>
<span id="S7.T7.2.2.2.2.2.2.2.7.5.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.90</span>
<span id="S7.T7.2.2.2.2.2.2.2.7.5.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S7.T7.2.2.2.2.2.2.2.7.5.3.1" class="ltx_text ltx_font_bold">0.96</span></span>
<span id="S7.T7.2.2.2.2.2.2.2.7.5.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.54</span>
<span id="S7.T7.2.2.2.2.2.2.2.7.5.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S7.T7.2.2.2.2.2.2.2.7.5.5.1" class="ltx_text ltx_font_bold">0.55</span></span>
<span id="S7.T7.2.2.2.2.2.2.2.7.5.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.34</span>
<span id="S7.T7.2.2.2.2.2.2.2.7.5.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S7.T7.2.2.2.2.2.2.2.7.5.7.1" class="ltx_text ltx_font_bold">0.40</span></span></span>
<span id="S7.T7.2.2.2.2.2.2.2.8.6" class="ltx_tr">
<span id="S7.T7.2.2.2.2.2.2.2.8.6.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">3</span>
<span id="S7.T7.2.2.2.2.2.2.2.8.6.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.89</span>
<span id="S7.T7.2.2.2.2.2.2.2.8.6.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S7.T7.2.2.2.2.2.2.2.8.6.3.1" class="ltx_text ltx_font_bold">0.96</span></span>
<span id="S7.T7.2.2.2.2.2.2.2.8.6.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.51</span>
<span id="S7.T7.2.2.2.2.2.2.2.8.6.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S7.T7.2.2.2.2.2.2.2.8.6.5.1" class="ltx_text ltx_font_bold">0.55</span></span>
<span id="S7.T7.2.2.2.2.2.2.2.8.6.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">-</span>
<span id="S7.T7.2.2.2.2.2.2.2.8.6.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">-</span></span>
<span id="S7.T7.2.2.2.2.2.2.2.9.7" class="ltx_tr">
<span id="S7.T7.2.2.2.2.2.2.2.9.7.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">4</span>
<span id="S7.T7.2.2.2.2.2.2.2.9.7.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.92</span>
<span id="S7.T7.2.2.2.2.2.2.2.9.7.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S7.T7.2.2.2.2.2.2.2.9.7.3.1" class="ltx_text ltx_font_bold">0.93</span></span>
<span id="S7.T7.2.2.2.2.2.2.2.9.7.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.51</span>
<span id="S7.T7.2.2.2.2.2.2.2.9.7.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S7.T7.2.2.2.2.2.2.2.9.7.5.1" class="ltx_text ltx_font_bold">0.56</span></span>
<span id="S7.T7.2.2.2.2.2.2.2.9.7.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">-</span>
<span id="S7.T7.2.2.2.2.2.2.2.9.7.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">-</span></span>
<span id="S7.T7.2.2.2.2.2.2.2.10.8" class="ltx_tr">
<span id="S7.T7.2.2.2.2.2.2.2.10.8.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r ltx_border_t">5</span>
<span id="S7.T7.2.2.2.2.2.2.2.10.8.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">0.91</span>
<span id="S7.T7.2.2.2.2.2.2.2.10.8.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S7.T7.2.2.2.2.2.2.2.10.8.3.1" class="ltx_text ltx_font_bold">0.96</span></span>
<span id="S7.T7.2.2.2.2.2.2.2.10.8.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">-</span>
<span id="S7.T7.2.2.2.2.2.2.2.10.8.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">-</span>
<span id="S7.T7.2.2.2.2.2.2.2.10.8.6" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">-</span>
<span id="S7.T7.2.2.2.2.2.2.2.10.8.7" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">-</span></span>
</span>
</span></span></span>
</span></span></span></p>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S7.T7.6.1.1" class="ltx_text" style="font-size:90%;">Table 7</span>. </span><span id="S7.T7.7.2" class="ltx_text" style="font-size:90%;">Comparing maximum Top-1 accuracy for <span id="S7.T7.7.2.1" class="ltx_text ltx_font_typewriter">FedMD</span> and <span id="S7.T7.7.2.2" class="ltx_text ltx_font_typewriter">FedDF</span> across all datasets and heterogeneous client model architectures.</span></figcaption>
</figure>
<figure id="S7.T8" class="ltx_table">
<p id="S7.T8.2" class="ltx_p ltx_align_center"><span id="S7.T8.2.1" class="ltx_text ltx_inline-block" style="width:433.6pt;">
<span id="S7.T8.2.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:298.9pt;height:54pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<span id="S7.T8.2.1.1.1" class="ltx_p"><span id="S7.T8.2.1.1.1.1" class="ltx_text">
<span id="S7.T8.2.1.1.1.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<span class="ltx_thead">
<span id="S7.T8.2.1.1.1.1.1.1.1" class="ltx_tr">
<span id="S7.T8.2.1.1.1.1.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t">Optimizations</span>
<span id="S7.T8.2.1.1.1.1.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">MNIST</span>
<span id="S7.T8.2.1.1.1.1.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">CIFAR</span>
<span id="S7.T8.2.1.1.1.1.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">Shakespeare</span></span>
</span>
<span class="ltx_tbody">
<span id="S7.T8.2.1.1.1.1.1.2.1" class="ltx_tr">
<span id="S7.T8.2.1.1.1.1.1.2.1.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">Transfer Learning with <span id="S7.T8.2.1.1.1.1.1.2.1.1.1" class="ltx_text ltx_font_typewriter">Ray</span></span>
<span id="S7.T8.2.1.1.1.1.1.2.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">3.2x</span>
<span id="S7.T8.2.1.1.1.1.1.2.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">3.7x</span>
<span id="S7.T8.2.1.1.1.1.1.2.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">3.6x</span></span>
<span id="S7.T8.2.1.1.1.1.1.3.2" class="ltx_tr">
<span id="S7.T8.2.1.1.1.1.1.3.2.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t">Parallel Ensemble Distillation</span>
<span id="S7.T8.2.1.1.1.1.1.3.2.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">1.83x</span>
<span id="S7.T8.2.1.1.1.1.1.3.2.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">1.8x</span>
<span id="S7.T8.2.1.1.1.1.1.3.2.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">1.67x</span></span>
</span>
</span></span></span>
</span></span></span></p>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S7.T8.4.1.1" class="ltx_text" style="font-size:90%;">Table 8</span>. </span><span id="S7.T8.5.2" class="ltx_text" style="font-size:90%;">Summary of speedups obtained with our extensions to <em id="S7.T8.5.2.1" class="ltx_emph ltx_font_italic">FedLess</em> (§<a href="#S4.SS2" title="4.2. Extending FedLess ‣ 4. System Design ‣ Training Heterogeneous Client Models using Knowledge Distillation in Serverless Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.2</span></a>) for the different datasets.</span></figcaption>
</figure>
<div id="S7.SS2.p3" class="ltx_para">
<p id="S7.SS2.p3.2" class="ltx_p">Tables <a href="#S7.T5" title="Table 5 ‣ 7.2. Comparing Performance and Cost ‣ 7. Experimental Results ‣ Training Heterogeneous Client Models using Knowledge Distillation in Serverless Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> and <a href="#S7.T6" title="Table 6 ‣ 7.2. Comparing Performance and Cost ‣ 7. Experimental Results ‣ Training Heterogeneous Client Models using Knowledge Distillation in Serverless Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> present the total execution times and costs for the serverless implementations of the two algorithms. For the MNIST and CIFAR datasets with <span id="S7.SS2.p3.2.1" class="ltx_text ltx_font_typewriter">FedMD</span>, we observe that most of the total costs are due to the digest step, which is executed on each client for every round. For the Shakespeare dataset, we observe a significant increase in costs primarily driven by the longer training duration in the revisit step. In contrast to <span id="S7.SS2.p3.2.2" class="ltx_text ltx_font_typewriter">FedMD</span>, we observe comparatively lower costs for <span id="S7.SS2.p3.2.3" class="ltx_text ltx_font_typewriter">FedDF</span>. This is because we only select a fraction of clients, i.e., ten, to participate in each training round using our intelligent selection algorithm (§<a href="#S6.SS4" title="6.4. Infrastructure Setup ‣ 6. Experimental Setup ‣ Training Heterogeneous Client Models using Knowledge Distillation in Serverless Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6.4</span></a>,§<a href="#S5.SS2" title="5.2. Serverless FedDF ‣ 5. Serverless Knowledge Distillation ‣ Training Heterogeneous Client Models using Knowledge Distillation in Serverless Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.2</span></a>). To summarize, <span id="S7.SS2.p3.2.4" class="ltx_text ltx_font_typewriter">FedDF</span> demonstrates cost savings of <math id="S7.SS2.p3.1.m1.1" class="ltx_Math" alttext="34" display="inline"><semantics id="S7.SS2.p3.1.m1.1a"><mn id="S7.SS2.p3.1.m1.1.1" xref="S7.SS2.p3.1.m1.1.1.cmml">34</mn><annotation-xml encoding="MathML-Content" id="S7.SS2.p3.1.m1.1b"><cn type="integer" id="S7.SS2.p3.1.m1.1.1.cmml" xref="S7.SS2.p3.1.m1.1.1">34</cn></annotation-xml><annotation encoding="application/x-tex" id="S7.SS2.p3.1.m1.1c">34</annotation></semantics></math>% and <math id="S7.SS2.p3.2.m2.1" class="ltx_Math" alttext="82.7" display="inline"><semantics id="S7.SS2.p3.2.m2.1a"><mn id="S7.SS2.p3.2.m2.1.1" xref="S7.SS2.p3.2.m2.1.1.cmml">82.7</mn><annotation-xml encoding="MathML-Content" id="S7.SS2.p3.2.m2.1b"><cn type="float" id="S7.SS2.p3.2.m2.1.1.cmml" xref="S7.SS2.p3.2.m2.1.1">82.7</cn></annotation-xml><annotation encoding="application/x-tex" id="S7.SS2.p3.2.m2.1c">82.7</annotation></semantics></math>% compared to <span id="S7.SS2.p3.2.5" class="ltx_text ltx_font_typewriter">FedMD</span> for the MNIST and Shakespeare datasets, respectively, while incurring approximately 16% higher costs for the CIFAR dataset.
The higher costs associated with the CIFAR dataset in <span id="S7.SS2.p3.2.6" class="ltx_text ltx_font_typewriter">FedDF</span> can be attributed to the utilization of the entire CIFAR-100 dataset for the ensemble distillation process leading to a higher number of local knowledge distillation steps in every communication round, in contrast to the use of a subset in <span id="S7.SS2.p3.2.7" class="ltx_text ltx_font_typewriter">FedMD</span> (§<a href="#S6.SS2" title="6.2. Heterogeneous Client Data Distribution ‣ 6. Experimental Setup ‣ Training Heterogeneous Client Models using Knowledge Distillation in Serverless Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6.2</span></a>).</p>
</div>
</section>
<section id="S7.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">7.3. </span>Comparing <span id="S7.SS3.1.1" class="ltx_text ltx_font_typewriter">FedDF</span> and <span id="S7.SS3.2.2" class="ltx_text ltx_font_typewriter">FedMD</span>
</h3>

<div id="S7.SS3.p1" class="ltx_para">
<p id="S7.SS3.p1.5" class="ltx_p">Table <a href="#S7.T7" title="Table 7 ‣ 7.2. Comparing Performance and Cost ‣ 7. Experimental Results ‣ Training Heterogeneous Client Models using Knowledge Distillation in Serverless Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> shows the maximum Top-1 model accuracy for the two algorithms across all datasets and heterogeneous client model architectures. For the MNIST and CIFAR datasets, we present results with <math id="S7.SS3.p1.1.m1.1" class="ltx_Math" alttext="\alpha=1" display="inline"><semantics id="S7.SS3.p1.1.m1.1a"><mrow id="S7.SS3.p1.1.m1.1.1" xref="S7.SS3.p1.1.m1.1.1.cmml"><mi id="S7.SS3.p1.1.m1.1.1.2" xref="S7.SS3.p1.1.m1.1.1.2.cmml">α</mi><mo id="S7.SS3.p1.1.m1.1.1.1" xref="S7.SS3.p1.1.m1.1.1.1.cmml">=</mo><mn id="S7.SS3.p1.1.m1.1.1.3" xref="S7.SS3.p1.1.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S7.SS3.p1.1.m1.1b"><apply id="S7.SS3.p1.1.m1.1.1.cmml" xref="S7.SS3.p1.1.m1.1.1"><eq id="S7.SS3.p1.1.m1.1.1.1.cmml" xref="S7.SS3.p1.1.m1.1.1.1"></eq><ci id="S7.SS3.p1.1.m1.1.1.2.cmml" xref="S7.SS3.p1.1.m1.1.1.2">𝛼</ci><cn type="integer" id="S7.SS3.p1.1.m1.1.1.3.cmml" xref="S7.SS3.p1.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.SS3.p1.1.m1.1c">\alpha=1</annotation></semantics></math>, while for the Shakespeare dataset, we present results for the non-IID data partition. We chose <math id="S7.SS3.p1.2.m2.1" class="ltx_Math" alttext="\alpha=1" display="inline"><semantics id="S7.SS3.p1.2.m2.1a"><mrow id="S7.SS3.p1.2.m2.1.1" xref="S7.SS3.p1.2.m2.1.1.cmml"><mi id="S7.SS3.p1.2.m2.1.1.2" xref="S7.SS3.p1.2.m2.1.1.2.cmml">α</mi><mo id="S7.SS3.p1.2.m2.1.1.1" xref="S7.SS3.p1.2.m2.1.1.1.cmml">=</mo><mn id="S7.SS3.p1.2.m2.1.1.3" xref="S7.SS3.p1.2.m2.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S7.SS3.p1.2.m2.1b"><apply id="S7.SS3.p1.2.m2.1.1.cmml" xref="S7.SS3.p1.2.m2.1.1"><eq id="S7.SS3.p1.2.m2.1.1.1.cmml" xref="S7.SS3.p1.2.m2.1.1.1"></eq><ci id="S7.SS3.p1.2.m2.1.1.2.cmml" xref="S7.SS3.p1.2.m2.1.1.2">𝛼</ci><cn type="integer" id="S7.SS3.p1.2.m2.1.1.3.cmml" xref="S7.SS3.p1.2.m2.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.SS3.p1.2.m2.1c">\alpha=1</annotation></semantics></math> since it represents a standard non-IID scenario and enables us to compare the robustness of the algorithms toward data heterogeneity. The model architecture level comparison is fair since we use the same architectures for both algorithms. For MNIST, <span id="S7.SS3.p1.5.1" class="ltx_text ltx_font_typewriter">FedDF</span> exhibits higher accuracy levels across all model types compared to <span id="S7.SS3.p1.5.2" class="ltx_text ltx_font_typewriter">FedMD</span>, with an average performance improvement of <math id="S7.SS3.p1.3.m3.1" class="ltx_Math" alttext="5" display="inline"><semantics id="S7.SS3.p1.3.m3.1a"><mn id="S7.SS3.p1.3.m3.1.1" xref="S7.SS3.p1.3.m3.1.1.cmml">5</mn><annotation-xml encoding="MathML-Content" id="S7.SS3.p1.3.m3.1b"><cn type="integer" id="S7.SS3.p1.3.m3.1.1.cmml" xref="S7.SS3.p1.3.m3.1.1">5</cn></annotation-xml><annotation encoding="application/x-tex" id="S7.SS3.p1.3.m3.1c">5</annotation></semantics></math>% across the six unique model architectures. Similarly, for the CIFAR dataset, <span id="S7.SS3.p1.5.3" class="ltx_text ltx_font_typewriter">FedDF</span> generally outperforms <span id="S7.SS3.p1.5.4" class="ltx_text ltx_font_typewriter">FedMD</span>, except for model 1, where <span id="S7.SS3.p1.5.5" class="ltx_text ltx_font_typewriter">FedMD</span> exhibits better performance. However, on average, across the five unique model architectures, <span id="S7.SS3.p1.5.6" class="ltx_text ltx_font_typewriter">FedDF</span> leads to <math id="S7.SS3.p1.4.m4.1" class="ltx_Math" alttext="3.2" display="inline"><semantics id="S7.SS3.p1.4.m4.1a"><mn id="S7.SS3.p1.4.m4.1.1" xref="S7.SS3.p1.4.m4.1.1.cmml">3.2</mn><annotation-xml encoding="MathML-Content" id="S7.SS3.p1.4.m4.1b"><cn type="float" id="S7.SS3.p1.4.m4.1.1.cmml" xref="S7.SS3.p1.4.m4.1.1">3.2</cn></annotation-xml><annotation encoding="application/x-tex" id="S7.SS3.p1.4.m4.1c">3.2</annotation></semantics></math>% better accuracy. Finally, for Shakespeare, <span id="S7.SS3.p1.5.7" class="ltx_text ltx_font_typewriter">FedDF</span> consistently outperforms <span id="S7.SS3.p1.5.8" class="ltx_text ltx_font_typewriter">FedMD</span> by an average of <math id="S7.SS3.p1.5.m5.1" class="ltx_Math" alttext="5" display="inline"><semantics id="S7.SS3.p1.5.m5.1a"><mn id="S7.SS3.p1.5.m5.1.1" xref="S7.SS3.p1.5.m5.1.1.cmml">5</mn><annotation-xml encoding="MathML-Content" id="S7.SS3.p1.5.m5.1b"><cn type="integer" id="S7.SS3.p1.5.m5.1.1.cmml" xref="S7.SS3.p1.5.m5.1.1">5</cn></annotation-xml><annotation encoding="application/x-tex" id="S7.SS3.p1.5.m5.1c">5</annotation></semantics></math>% across the three unique model architectures.</p>
</div>
</section>
<section id="S7.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">7.4. </span>Effect of performance optimizations</h3>

<div id="S7.SS4.p1" class="ltx_para">
<p id="S7.SS4.p1.2" class="ltx_p">Table <a href="#S7.T8" title="Table 8 ‣ 7.2. Comparing Performance and Cost ‣ 7. Experimental Results ‣ Training Heterogeneous Client Models using Knowledge Distillation in Serverless Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a> presents summarized results for speedups obtained with our optimizations compared to the original sequential implementation of the two algorithms (§<a href="#S4.SS2" title="4.2. Extending FedLess ‣ 4. System Design ‣ Training Heterogeneous Client Models using Knowledge Distillation in Serverless Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.2</span></a>,§<a href="#S2.SS2" title="2.2. FedMD ‣ 2. Background ‣ Training Heterogeneous Client Models using Knowledge Distillation in Serverless Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.2</span></a>,§<a href="#S2.SS3" title="2.3. FedDF ‣ 2. Background ‣ Training Heterogeneous Client Models using Knowledge Distillation in Serverless Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.3</span></a>). To ensure a fair comparison, we execute the original algorithms after migrating them to the serverless paradigm. For the initial transfer learning process in <span id="S7.SS4.p1.2.1" class="ltx_text ltx_font_typewriter">FedMD</span> (§<a href="#S5.SS1" title="5.1. Serverless FedMD ‣ 5. Serverless Knowledge Distillation ‣ Training Heterogeneous Client Models using Knowledge Distillation in Serverless Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.1</span></a>), we obtain an average speedup of <math id="S7.SS4.p1.1.m1.1" class="ltx_Math" alttext="3.5" display="inline"><semantics id="S7.SS4.p1.1.m1.1a"><mn id="S7.SS4.p1.1.m1.1.1" xref="S7.SS4.p1.1.m1.1.1.cmml">3.5</mn><annotation-xml encoding="MathML-Content" id="S7.SS4.p1.1.m1.1b"><cn type="float" id="S7.SS4.p1.1.m1.1.1.cmml" xref="S7.SS4.p1.1.m1.1.1">3.5</cn></annotation-xml><annotation encoding="application/x-tex" id="S7.SS4.p1.1.m1.1c">3.5</annotation></semantics></math>x across all datasets with our implementation using <span id="S7.SS4.p1.2.2" class="ltx_text ltx_font_typewriter">Ray</span>. On the other hand, for the ensemble distillation process using multiple aggregators in <span id="S7.SS4.p1.2.3" class="ltx_text ltx_font_typewriter">FedDF</span> (§<a href="#S5.SS2" title="5.2. Serverless FedDF ‣ 5. Serverless Knowledge Distillation ‣ Training Heterogeneous Client Models using Knowledge Distillation in Serverless Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.2</span></a>), we observe an average speedup of <math id="S7.SS4.p1.2.m2.1" class="ltx_Math" alttext="1.76" display="inline"><semantics id="S7.SS4.p1.2.m2.1a"><mn id="S7.SS4.p1.2.m2.1.1" xref="S7.SS4.p1.2.m2.1.1.cmml">1.76</mn><annotation-xml encoding="MathML-Content" id="S7.SS4.p1.2.m2.1b"><cn type="float" id="S7.SS4.p1.2.m2.1.1.cmml" xref="S7.SS4.p1.2.m2.1.1">1.76</cn></annotation-xml><annotation encoding="application/x-tex" id="S7.SS4.p1.2.m2.1c">1.76</annotation></semantics></math>x across all datasets.</p>
</div>
</section>
</section>
<section id="S8" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">8. </span>Conclusion and Future Work</h2>

<div id="S8.p1" class="ltx_para">
<p id="S8.p1.1" class="ltx_p">In this paper, we took the first step towards training heterogeneous client models in FL via KD using the serverless paradigm. Towards this, we proposed novel optimized serverless workflows for two popular conventional KD techniques, i.e., <span id="S8.p1.1.1" class="ltx_text ltx_font_typewriter">FedMD</span> and <span id="S8.p1.1.2" class="ltx_text ltx_font_typewriter">FedDF</span>. To enable adoption, we integrated the two strategies into an open-source serverless FL system called <em id="S8.p1.1.3" class="ltx_emph ltx_font_italic">FedLess</em> by extending it. With our experiments, we successfully demonstrated that the serverless implementations of the two strategies converge for heterogeneous model architectures across multiple datasets. In the future, we plan to explore the suitability of more advanced data-free knowledge distillation algorithms that do not require a separate public transfer dataset in serverless environments.</p>
</div>
</section>
<section id="S9" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">9. </span>Acknowledgement</h2>

<div id="S9.p1" class="ltx_para">
<p id="S9.p1.1" class="ltx_p">The research leading to these results was funded by the German Federal Ministry of Education and Research (BMBF) in the scope of the Software Campus program under the grant agreement 01IS17049.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(1)</span>
<span class="ltx_bibblock">        




</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">lam (2023)</span>
<span class="ltx_bibblock">
2023.

</span>
<span class="ltx_bibblock"><em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">AWS Lambda Limits</em>.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://docs.aws.amazon.com/lambda/latest/dg/gettingstarted-limits.html" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://docs.aws.amazon.com/lambda/latest/dg/gettingstarted-limits.html</a>

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">nie (2023)</span>
<span class="ltx_bibblock">
2023.

</span>
<span class="ltx_bibblock">Nietsche Text corpus.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://s3.amazonaws.com/text-datasets/nietzsche.txt" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://s3.amazonaws.com/text-datasets/nietzsche.txt</a>

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Arivazhagan et al<span id="bib.bib4.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Manoj Ghuhan Arivazhagan et al<span id="bib.bib4.3.1" class="ltx_text">.</span>
2019.

</span>
<span class="ltx_bibblock">Federated Learning with Personalization Layers.

</span>
<span class="ltx_bibblock"><em id="bib.bib4.4.1" class="ltx_emph ltx_font_italic">CoRR</em> abs/1912.00818
(2019).

</span>
<span class="ltx_bibblock">arXiv:1912.00818

<a target="_blank" href="http://arxiv.org/abs/1912.00818" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://arxiv.org/abs/1912.00818</a>

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Beutel et al<span id="bib.bib5.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Daniel J. Beutel et al<span id="bib.bib5.3.1" class="ltx_text">.</span>
2020.

</span>
<span class="ltx_bibblock">Flower: A Friendly Federated Learning Research
Framework.

</span>
<span class="ltx_bibblock"><em id="bib.bib5.4.1" class="ltx_emph ltx_font_italic">arXiv</em> (jul
2020), 1–22.

</span>
<span class="ltx_bibblock">
arXiv:2007.14390

<a target="_blank" href="http://arxiv.org/abs/2007.14390" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://arxiv.org/abs/2007.14390</a>

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bistritz et al<span id="bib.bib6.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Ilai Bistritz et al<span id="bib.bib6.3.1" class="ltx_text">.</span>
2020.

</span>
<span class="ltx_bibblock">Distributed Distillation for On-Device Learning.
In <em id="bib.bib6.4.1" class="ltx_emph ltx_font_italic">Proceedings of the 34th International Conference
on Neural Information Processing Systems</em> (Vancouver, BC, Canada)
<em id="bib.bib6.5.2" class="ltx_emph ltx_font_italic">(NIPS’20)</em>. Curran Associates
Inc., Red Hook, NY, USA, Article
1894, 12 pages.

</span>
<span class="ltx_bibblock">

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Caldas et al<span id="bib.bib7.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Sebastian Caldas et al<span id="bib.bib7.3.1" class="ltx_text">.</span>
2018.

</span>
<span class="ltx_bibblock">LEAF: A Benchmark for Federated Settings. In
<em id="bib.bib7.4.1" class="ltx_emph ltx_font_italic">Workshop on Federated Learning for Data Privacy and
Confidentiality, NeurIPS</em>. 1–9.

</span>
<span class="ltx_bibblock">arXiv:1812.01097

<a target="_blank" href="http://arxiv.org/abs/1812.01097" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://arxiv.org/abs/1812.01097</a>

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Castro et al<span id="bib.bib8.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Paul Castro, Vatche
Ishakian, Vinod Muthusamy, and
Aleksander Slominski. 2019.

</span>
<span class="ltx_bibblock">The Rise of Serverless Computing.

</span>
<span class="ltx_bibblock"><em id="bib.bib8.3.1" class="ltx_emph ltx_font_italic">Commun. ACM</em> 62,
12 (Nov. 2019),
44–54.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/3368454" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3368454</a>

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chadha et al<span id="bib.bib9.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Mohak Chadha, Anshul
Jindal, and Michael Gerndt.
2020.

</span>
<span class="ltx_bibblock">Towards Federated Learning Using FaaS Fabric. In
<em id="bib.bib9.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 2020 Sixth International
Workshop on Serverless Computing</em> (Delft, Netherlands)
<em id="bib.bib9.4.2" class="ltx_emph ltx_font_italic">(WoSC’20)</em>. Association for
Computing Machinery, New York, NY, USA,
49–54.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/3429880.3430100" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3429880.3430100</a>

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chadha et al<span id="bib.bib10.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Mohak Chadha, Anshul
Jindal, and Michael Gerndt.
2021.

</span>
<span class="ltx_bibblock">Architecture-Specific Performance Optimization of
Compute-Intensive FaaS Functions. In <em id="bib.bib10.3.1" class="ltx_emph ltx_font_italic">2021 IEEE
14th International Conference on Cloud Computing (CLOUD)</em>.
478–483.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1109/CLOUD53861.2021.00062" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/CLOUD53861.2021.00062</a>

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chard et al<span id="bib.bib11.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Ryan Chard et al<span id="bib.bib11.3.1" class="ltx_text">.</span>
2020.

</span>
<span class="ltx_bibblock">FuncX: A Federated Function Serving Fabric for
Science. In <em id="bib.bib11.4.1" class="ltx_emph ltx_font_italic">Proceedings of the 29th International
Symposium on High-Performance Parallel and Distributed Computing</em>
(Stockholm, Sweden) <em id="bib.bib11.5.2" class="ltx_emph ltx_font_italic">(HPDC ’20)</em>.
Association for Computing Machinery,
New York, NY, USA, 65–76.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/3369583.3392683" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3369583.3392683</a>

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cho et al<span id="bib.bib12.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Yae Jee Cho et al<span id="bib.bib12.3.1" class="ltx_text">.</span>
2022.

</span>
<span class="ltx_bibblock">Heterogeneous Ensemble Knowledge Transfer for
Training Large Models in Federated Learning.

</span>
<span class="ltx_bibblock">(2022).

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.48550/ARXIV.2204.12703" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.48550/ARXIV.2204.12703</a>

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cloud (2022)</span>
<span class="ltx_bibblock">
Google Cloud.
2022.

</span>
<span class="ltx_bibblock">Cloud Functions pricing.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://cloud.google.com/functions/pricing" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://cloud.google.com/functions/pricing</a>

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Elzohairy et al<span id="bib.bib14.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Mohamed Elzohairy, Mohak
Chadha, Anshul Jindal, Andreas
Grafberger, Jianfeng Gu, Michael Gerndt,
and Osama Abboud. 2022.

</span>
<span class="ltx_bibblock">FedLesScan: Mitigating Stragglers in Serverless
Federated Learning. In <em id="bib.bib14.3.1" class="ltx_emph ltx_font_italic">2022 IEEE International
Conference on Big Data (Big Data)</em>. 1230–1237.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1109/BigData55660.2022.10021037" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/BigData55660.2022.10021037</a>

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Enthoven and Al-Ars (2021)</span>
<span class="ltx_bibblock">
David Enthoven and Zaid
Al-Ars. 2021.

</span>
<span class="ltx_bibblock">An overview of federated deep learning privacy
attacks and defensive strategies.

</span>
<span class="ltx_bibblock"><em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">Federated Learning Systems: Towards
Next-Generation AI</em> (2021), 173–196.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gaff et al<span id="bib.bib16.2.2.1" class="ltx_text">.</span> (2014)</span>
<span class="ltx_bibblock">
Brian M. Gaff et al<span id="bib.bib16.3.1" class="ltx_text">.</span>
2014.

</span>
<span class="ltx_bibblock">Privacy and Big Data.

</span>
<span class="ltx_bibblock"><em id="bib.bib16.4.1" class="ltx_emph ltx_font_italic">Computer</em> 47,
6 (2014), 7–9.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1109/MC.2014.161" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/MC.2014.161</a>

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Google Cloud (2022)</span>
<span class="ltx_bibblock">
Google Cloud.
2022.

</span>
<span class="ltx_bibblock">Cloud Functions Second Generation— Google Cloud.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://cloud.google.com/functions/docs/2nd-gen/overview" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://cloud.google.com/functions/docs/2nd-gen/overview</a>

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Grafberger et al<span id="bib.bib18.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Andreas Grafberger, Mohak
Chadha, Anshul Jindal, Jianfeng Gu,
and Michael Gerndt. 2021.

</span>
<span class="ltx_bibblock">FedLess: Secure and Scalable Federated Learning
Using Serverless Computing. In <em id="bib.bib18.3.1" class="ltx_emph ltx_font_italic">2021 IEEE
International Conference on Big Data (Big Data)</em>. 164–173.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1109/BigData52589.2021.9672067" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/BigData52589.2021.9672067</a>

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gu et al<span id="bib.bib19.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Jianfeng Gu, Yichao Zhu,
Puxuan Wang, Mohak Chadha, and
Michael Gerndt. 2023.

</span>
<span class="ltx_bibblock">FaST-GShare: Enabling Efficient Spatio-Temporal GPU
Sharing in Serverless Computing for Deep Learning Inference. In
<em id="bib.bib19.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 52nd International Conference on
Parallel Processing</em> (Salt Lake City, UT, USA) <em id="bib.bib19.4.2" class="ltx_emph ltx_font_italic">(ICPP
’23)</em>. Association for Computing Machinery,
New York, NY, USA, 635–644.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/3605573.3605638" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3605573.3605638</a>

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hinton et al<span id="bib.bib20.2.2.1" class="ltx_text">.</span> (2015)</span>
<span class="ltx_bibblock">
Geoffrey Hinton, Oriol
Vinyals, and Jeff Dean.
2015.

</span>
<span class="ltx_bibblock">Distilling the Knowledge in a Neural Network.

</span>
<span class="ltx_bibblock">(2015).

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.48550/ARXIV.1503.02531" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.48550/ARXIV.1503.02531</a>

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hsieh et al<span id="bib.bib21.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Kevin Hsieh et al<span id="bib.bib21.3.1" class="ltx_text">.</span>
2020.

</span>
<span class="ltx_bibblock">The non-iid data quagmire of decentralized machine
learning. In <em id="bib.bib21.4.1" class="ltx_emph ltx_font_italic">International Conference on Machine
Learning</em>. PMLR, 4387–4398.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hsu et al<span id="bib.bib22.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Tzu-Ming Harry Hsu, Hang
Qi, and Matthew Brown. 2019.

</span>
<span class="ltx_bibblock">Measuring the effects of non-identical data
distribution for federated visual classification.

</span>
<span class="ltx_bibblock"><em id="bib.bib22.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1909.06335</em>
(2019).

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.48550/arXiv.1909.06335" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.48550/arXiv.1909.06335</a>

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hu et al<span id="bib.bib23.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Li Hu et al<span id="bib.bib23.3.1" class="ltx_text">.</span>
2021.

</span>
<span class="ltx_bibblock">MHAT: An efficient model-heterogenous aggregation
training scheme for federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib23.4.1" class="ltx_emph ltx_font_italic">Information Sciences</em> 560
(2021), 493–503.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1016/j.ins.2021.01.046" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1016/j.ins.2021.01.046</a>

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huba et al<span id="bib.bib24.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Dzmitry Huba et al<span id="bib.bib24.3.1" class="ltx_text">.</span>
2022.

</span>
<span class="ltx_bibblock">Papaya: Practical, private, and scalable federated
learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib24.4.1" class="ltx_emph ltx_font_italic">Proceedings of Machine Learning and Systems</em>
4 (2022), 814–832.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jayaram et al<span id="bib.bib25.2.2.1" class="ltx_text">.</span> (2022a)</span>
<span class="ltx_bibblock">
KR Jayaram et al<span id="bib.bib25.3.1" class="ltx_text">.</span>
2022a.

</span>
<span class="ltx_bibblock">Adaptive Aggregation For Federated Learning. In
<em id="bib.bib25.4.1" class="ltx_emph ltx_font_italic">2022 IEEE International Conference on Big Data (Big
Data)</em>. 180–185.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1109/BigData55660.2022.10021119" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/BigData55660.2022.10021119</a>

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jayaram et al<span id="bib.bib26.2.2.1" class="ltx_text">.</span> (2022b)</span>
<span class="ltx_bibblock">
KR Jayaram et al<span id="bib.bib26.3.1" class="ltx_text">.</span>
2022b.

</span>
<span class="ltx_bibblock">Lambda FL: Serverless Aggregation For Federated
Learning. In <em id="bib.bib26.4.1" class="ltx_emph ltx_font_italic">International Workshop on Trustable,
Verifiable and Auditable Federated Learning</em>. 9.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jayaram et al<span id="bib.bib27.2.2.1" class="ltx_text">.</span> (2022c)</span>
<span class="ltx_bibblock">
K. R. Jayaram et al<span id="bib.bib27.3.1" class="ltx_text">.</span>
2022c.

</span>
<span class="ltx_bibblock">Just-in-Time Aggregation for Federated Learning.
In <em id="bib.bib27.4.1" class="ltx_emph ltx_font_italic">2022 30th International Symposium on Modeling,
Analysis, and Simulation of Computer and Telecommunication Systems
(MASCOTS)</em>. 1–8.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1109/MASCOTS56607.2022.00009" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/MASCOTS56607.2022.00009</a>

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jindal et al<span id="bib.bib28.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Anshul Jindal, Mohak
Chadha, Shajulin Benedict, and Michael
Gerndt. 2022.

</span>
<span class="ltx_bibblock">Estimating the Capacities of Function-as-a-Service
Functions. In <em id="bib.bib28.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 14th IEEE/ACM
International Conference on Utility and Cloud Computing Companion</em>
(Leicester, United Kingdom) <em id="bib.bib28.4.2" class="ltx_emph ltx_font_italic">(UCC ’21)</em>.
Association for Computing Machinery,
New York, NY, USA, Article 19,
8 pages.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/3492323.3495628" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3492323.3495628</a>

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jindal et al<span id="bib.bib29.2.2.1" class="ltx_text">.</span> (2021a)</span>
<span class="ltx_bibblock">
Anshul Jindal, Mohak
Chadha, Michael Gerndt, Julian
Frielinghaus, Vladimir Podolskiy, and
Pengfei Chen. 2021a.

</span>
<span class="ltx_bibblock">Poster: Function Delivery Network: Extending
Serverless to Heterogeneous Computing. In <em id="bib.bib29.3.1" class="ltx_emph ltx_font_italic">2021
IEEE 41st International Conference on Distributed Computing Systems
(ICDCS)</em>. 1128–1129.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1109/ICDCS51616.2021.00120" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/ICDCS51616.2021.00120</a>

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jindal et al<span id="bib.bib30.2.2.1" class="ltx_text">.</span> (2021b)</span>
<span class="ltx_bibblock">
Anshul Jindal, Julian
Frielinghaus, Mohak Chadha, and Michael
Gerndt. 2021b.

</span>
<span class="ltx_bibblock">Courier: Delivering Serverless Functions Within
Heterogeneous FaaS Deployments. In <em id="bib.bib30.3.1" class="ltx_emph ltx_font_italic">2021 IEEE/ACM
14th International Conference on Utility and Cloud Computing (UCC’21)</em>
(Leicester, United Kingdom) <em id="bib.bib30.4.2" class="ltx_emph ltx_font_italic">(UCC ’21)</em>.
Association for Computing Machinery,
New York, NY, USA, 10 pages.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/3468737.3494097" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3468737.3494097</a>

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jindal et al<span id="bib.bib31.2.2.1" class="ltx_text">.</span> (2021c)</span>
<span class="ltx_bibblock">
Anshul Jindal, Michael
Gerndt, Mohak Chadha, Vladimir
Podolskiy, and Pengfei Chen.
2021c.

</span>
<span class="ltx_bibblock">Function delivery network: Extending serverless
computing for heterogeneous platforms.

</span>
<span class="ltx_bibblock"><em id="bib.bib31.3.1" class="ltx_emph ltx_font_italic">Software: Practice and Experience</em>
51, 9 (2021),
1936–1963.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1002/spe.2966" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1002/spe.2966</a>

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kiener et al<span id="bib.bib32.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Michael Kiener, Mohak
Chadha, and Michael Gerndt.
2021.

</span>
<span class="ltx_bibblock">Towards Demystifying Intra-Function Parallelism in
Serverless Computing. In <em id="bib.bib32.3.1" class="ltx_emph ltx_font_italic">Proceedings of the
Seventh International Workshop on Serverless Computing (WoSC7) 2021</em>
(Virtual Event, Canada) <em id="bib.bib32.4.2" class="ltx_emph ltx_font_italic">(WoSC ’21)</em>.
Association for Computing Machinery,
New York, NY, USA, 42–49.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/3493651.3493672" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3493651.3493672</a>

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kotsehub et al<span id="bib.bib33.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Nikita Kotsehub et al<span id="bib.bib33.3.1" class="ltx_text">.</span>
2022.

</span>
<span class="ltx_bibblock">FLoX: Federated Learning with FaaS at the Edge. In
<em id="bib.bib33.4.1" class="ltx_emph ltx_font_italic">2022 IEEE 18th International Conference on
e-Science (e-Science)</em>. 11–20.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1109/eScience55777.2022.00016" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/eScience55777.2022.00016</a>

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lai et al<span id="bib.bib34.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Fan Lai et al<span id="bib.bib34.3.1" class="ltx_text">.</span>
2020.

</span>
<span class="ltx_bibblock">Oort: Informed Participant Selection for Scalable
Federated Learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib34.4.1" class="ltx_emph ltx_font_italic">CoRR</em> abs/2010.06081
(2020).

</span>
<span class="ltx_bibblock">arXiv:2010.06081

<a target="_blank" href="https://arxiv.org/abs/2010.06081" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/abs/2010.06081</a>

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">LeCun et al<span id="bib.bib35.2.2.1" class="ltx_text">.</span> (2015)</span>
<span class="ltx_bibblock">
Yann LeCun, Yoshua
Bengio, and Geoffrey Hinton.
2015.

</span>
<span class="ltx_bibblock">Deep learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib35.3.1" class="ltx_emph ltx_font_italic">nature</em> 521,
7553 (2015), 436–444.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li and Wang (2019)</span>
<span class="ltx_bibblock">
Daliang Li and Junpu
Wang. 2019.

</span>
<span class="ltx_bibblock">FedMD: Heterogenous Federated Learning via Model
Distillation.

</span>
<span class="ltx_bibblock">(2019).

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.48550/ARXIV.1910.03581" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.48550/ARXIV.1910.03581</a>

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liaw et al<span id="bib.bib37.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Richard Liaw, Eric Liang,
Robert Nishihara, Philipp Moritz,
Joseph E Gonzalez, and Ion Stoica.
2018.

</span>
<span class="ltx_bibblock">Tune: A Research Platform for Distributed Model
Selection and Training.

</span>
<span class="ltx_bibblock"><em id="bib.bib37.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1807.05118</em>
(2018).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin et al<span id="bib.bib38.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Tao Lin et al<span id="bib.bib38.3.1" class="ltx_text">.</span>
2020.

</span>
<span class="ltx_bibblock">Ensemble Distillation for Robust Model Fusion in
Federated Learning.

</span>
<span class="ltx_bibblock">33 (2020),
2351–2363.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://proceedings.neurips.cc/paper/2020/file/18df51b97ccd68128e994804f3eccc87-Paper.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://proceedings.neurips.cc/paper/2020/file/18df51b97ccd68128e994804f3eccc87-Paper.pdf</a>

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ludwig et al<span id="bib.bib39.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Heiko Ludwig et al<span id="bib.bib39.3.1" class="ltx_text">.</span>
2020.

</span>
<span class="ltx_bibblock">Ibm federated learning: an enterprise framework
white paper v0. 1.

</span>
<span class="ltx_bibblock"><em id="bib.bib39.4.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2007.10987</em>
(2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">McMahan et al<span id="bib.bib40.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Brendan McMahan et al<span id="bib.bib40.3.1" class="ltx_text">.</span>
2017.

</span>
<span class="ltx_bibblock">Communication-efficient learning of deep networks
from decentralized data. In <em id="bib.bib40.4.1" class="ltx_emph ltx_font_italic">Artificial
Intelligence and Statistics</em>. PMLR, 1273–1282.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mora et al<span id="bib.bib41.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Alessio Mora et al<span id="bib.bib41.3.1" class="ltx_text">.</span>
2022.

</span>
<span class="ltx_bibblock">Knowledge distillation for federated learning: a
practical guide.

</span>
<span class="ltx_bibblock"><em id="bib.bib41.4.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2211.04742</em>
(2022).

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.48550/arXiv.2211.04742" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.48550/arXiv.2211.04742</a>

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Moritz et al<span id="bib.bib42.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Philipp Moritz et al<span id="bib.bib42.3.1" class="ltx_text">.</span>
2018.

</span>
<span class="ltx_bibblock">Ray: A Distributed Framework for Emerging AI
Applications. In <em id="bib.bib42.4.1" class="ltx_emph ltx_font_italic">13th USENIX Symposium on
Operating Systems Design and Implementation (OSDI 18)</em>.
USENIX Association, Carlsbad, CA,
561–577.

</span>
<span class="ltx_bibblock">

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mothukuri et al<span id="bib.bib43.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Viraaji Mothukuri et al<span id="bib.bib43.3.1" class="ltx_text">.</span>
2021.

</span>
<span class="ltx_bibblock">A survey on security and privacy of federated
learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib43.4.1" class="ltx_emph ltx_font_italic">Future Generation Computer Systems</em>
115 (feb 2021),
619–640.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1016/j.future.2020.10.007" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1016/j.future.2020.10.007</a>

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">OpenFaaS (2019)</span>
<span class="ltx_bibblock">
OpenFaaS. 2019.

</span>
<span class="ltx_bibblock">OpenFaaS - Serverless Functions Made Simple.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://www.openfaas.com/https://docs.openfaas.com/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.openfaas.com/https://docs.openfaas.com/</a>

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Smith et al<span id="bib.bib45.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Christopher Peter Smith,
Anshul Jindal, Mohak Chadha,
Michael Gerndt, and Shajulin Benedict.
2022.

</span>
<span class="ltx_bibblock">FaDO: FaaS Functions and Data Orchestrator for
Multiple Serverless Edge-Cloud Clusters. In <em id="bib.bib45.3.1" class="ltx_emph ltx_font_italic">2022
IEEE 6th International Conference on Fog and Edge Computing (ICFEC)</em>.
17–25.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1109/ICFEC54809.2022.00010" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/ICFEC54809.2022.00010</a>

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2402.07294" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2402.07295" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2402.07295">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2402.07295" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2402.07296" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Tue Mar  5 18:35:27 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
