<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>On the challenges of studying bias in Recommender Systems: A UserKNN case study</title>
<!--Generated on Thu Sep 12 13:45:01 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<meta content="Recommender Systems,  Bias,  Data Synthesis,  Reproducibility" lang="en" name="keywords"/>
<base href="/html/2409.08046v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.08046v1#S1" title="In On the challenges of studying bias in Recommender Systems: A UserKNN case study"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.08046v1#S1.SS0.SSS0.Px1" title="In 1. Introduction ‣ On the challenges of studying bias in Recommender Systems: A UserKNN case study"><span class="ltx_text ltx_ref_title">Data characteristics</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.08046v1#S1.SS0.SSS0.Px2" title="In 1. Introduction ‣ On the challenges of studying bias in Recommender Systems: A UserKNN case study"><span class="ltx_text ltx_ref_title">Algorithm configuration</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.08046v1#S2" title="In On the challenges of studying bias in Recommender Systems: A UserKNN case study"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Related Work</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.08046v1#S2.SS1" title="In 2. Related Work ‣ On the challenges of studying bias in Recommender Systems: A UserKNN case study"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>Bias in Recommender Systems</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.08046v1#S2.SS2" title="In 2. Related Work ‣ On the challenges of studying bias in Recommender Systems: A UserKNN case study"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>Datasets and Reproducibility</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.08046v1#S3" title="In On the challenges of studying bias in Recommender Systems: A UserKNN case study"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Identifying Data Characteristics and Algorithm Configurations</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2409.08046v1#S3.SS1" title="In 3. Identifying Data Characteristics and Algorithm Configurations ‣ On the challenges of studying bias in Recommender Systems: A UserKNN case study"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Data Characteristics</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.08046v1#S3.SS1.SSS0.Px1" title="In 3.1. Data Characteristics ‣ 3. Identifying Data Characteristics and Algorithm Configurations ‣ On the challenges of studying bias in Recommender Systems: A UserKNN case study"><span class="ltx_text ltx_ref_title">Relation Between Rating and Popularity</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.08046v1#S3.SS1.SSS0.Px2" title="In 3.1. Data Characteristics ‣ 3. Identifying Data Characteristics and Algorithm Configurations ‣ On the challenges of studying bias in Recommender Systems: A UserKNN case study"><span class="ltx_text ltx_ref_title">Influential Users</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.08046v1#S3.SS1.SSS0.Px3" title="In 3.1. Data Characteristics ‣ 3. Identifying Data Characteristics and Algorithm Configurations ‣ On the challenges of studying bias in Recommender Systems: A UserKNN case study"><span class="ltx_text ltx_ref_title">Data Scenarios</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2409.08046v1#S3.SS2" title="In 3. Identifying Data Characteristics and Algorithm Configurations ‣ On the challenges of studying bias in Recommender Systems: A UserKNN case study"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Algorithm Configurations</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection">
<a class="ltx_ref" href="https://arxiv.org/html/2409.08046v1#S3.SS2.SSS1" title="In 3.2. Algorithm Configurations ‣ 3. Identifying Data Characteristics and Algorithm Configurations ‣ On the challenges of studying bias in Recommender Systems: A UserKNN case study"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2.1 </span>UserKNN</span></a>
<ol class="ltx_toclist ltx_toclist_subsubsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.08046v1#S3.SS2.SSS1.Px1" title="In 3.2.1. UserKNN ‣ 3.2. Algorithm Configurations ‣ 3. Identifying Data Characteristics and Algorithm Configurations ‣ On the challenges of studying bias in Recommender Systems: A UserKNN case study"><span class="ltx_text ltx_ref_title">Minimum Similarity</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.08046v1#S3.SS2.SSS1.Px2" title="In 3.2.1. UserKNN ‣ 3.2. Algorithm Configurations ‣ 3. Identifying Data Characteristics and Algorithm Configurations ‣ On the challenges of studying bias in Recommender Systems: A UserKNN case study"><span class="ltx_text ltx_ref_title">Items for Similarity</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.08046v1#S3.SS2.SSS1.Px3" title="In 3.2.1. UserKNN ‣ 3.2. Algorithm Configurations ‣ 3. Identifying Data Characteristics and Algorithm Configurations ‣ On the challenges of studying bias in Recommender Systems: A UserKNN case study"><span class="ltx_text ltx_ref_title">Minimum Neighbours</span></a></li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.08046v1#S4" title="In On the challenges of studying bias in Recommender Systems: A UserKNN case study"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Experimental Setup</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.08046v1#S5" title="In On the challenges of studying bias in Recommender Systems: A UserKNN case study"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Results</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.08046v1#S6" title="In On the challenges of studying bias in Recommender Systems: A UserKNN case study"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Discussion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.08046v1#S7" title="In On the challenges of studying bias in Recommender Systems: A UserKNN case study"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7 </span>Conclusion</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line ltx_leqno">
<h1 class="ltx_title ltx_title_document">On the challenges of studying bias in Recommender Systems: A UserKNN case study</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Savvina Daniil
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:s.daniil@cwi.nl">s.daniil@cwi.nl</a>
</span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id1.1.id1">Centrum Wiskunde &amp; Informatica</span><span class="ltx_text ltx_affiliation_country" id="id2.2.id2">Amsterdam, The Netherlands</span>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Manel Slokom
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:m.slokom@cwi.nl">m.slokom@cwi.nl</a>
</span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id3.1.id1">Centrum Wiskunde &amp; Informatica</span><span class="ltx_text ltx_affiliation_country" id="id4.2.id2">Amsterdam, The Netherlands</span>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Mirjam Cuper
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:mirjam.cuper@kb.nl">mirjam.cuper@kb.nl</a>
</span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id5.1.id1">National Library of the Netherlands</span><span class="ltx_text ltx_affiliation_country" id="id6.2.id2">The Hague, The Netherlands</span>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Cynthia C. S. Liem
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:c.c.s.liem@tudelft.nl">c.c.s.liem@tudelft.nl</a>
</span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id7.1.id1">Delft University of Technology</span><span class="ltx_text ltx_affiliation_country" id="id8.2.id2">Delft, The Netherlands</span>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Jacco van Ossenbruggen
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:jacco.van.ossenbruggen@cwi.nl">jacco.van.ossenbruggen@cwi.nl</a>
</span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id9.1.id1">Vrije Universiteit Amsterdam</span><span class="ltx_text ltx_affiliation_country" id="id10.2.id2">Amsterdam, The Netherlands</span>
</span></span></span>
<span class="ltx_author_before"> and </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Laura Hollink
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:l.hollink@cwi.nl">l.hollink@cwi.nl</a>
</span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id11.1.id1">Centrum Wiskunde &amp; Informatica</span><span class="ltx_text ltx_affiliation_country" id="id12.2.id2">Amsterdam, The Netherlands</span>
</span></span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract.</h6>
<p class="ltx_p" id="id13.id1">Statements on the propagation of bias by recommender systems are often hard to verify or falsify.
Research on bias tends to draw from a small pool of publicly available datasets and is therefore bound by their specific properties.
Additionally, implementation choices are often not explicitly described or motivated in research, while they may have an effect on bias propagation.
In this paper, we explore the challenges of measuring and reporting popularity bias.
We showcase the impact of data properties and algorithm configurations on popularity bias by combining synthetic data with well known recommender systems frameworks that implement UserKNN.
First, we identify data characteristics that might impact popularity bias, based on the functionality of UserKNN.
Accordingly, we generate various datasets that combine these characteristics.
Second, we locate UserKNN configurations that vary across implementations in literature.
We evaluate popularity bias for five synthetic datasets and five UserKNN configurations, and offer insights on their joint effect.
We find that, depending on the data characteristics, various UserKNN configurations can lead to different conclusions regarding the propagation of popularity bias.
These results motivate the need for explicitly addressing algorithmic configuration and data properties when reporting and interpreting bias in recommender systems.</p>
</div>
<div class="ltx_keywords">Recommender Systems, Bias, Data Synthesis, Reproducibility
</div>
<span class="ltx_note ltx_note_frontmatter ltx_role_copyright" id="id1"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">copyright: </span>none</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_ccs" id="id2"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">ccs: </span>Information systems Recommender systems</span></span></span>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1. </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Recommender systems are commonly used as a tool to encode taste based on the information available, be it user history or metadata.
The wide use of recommender systems necessitates critical reflection on the issues that may arise when we allow automation to dictate our exposure to information.
Specifically, bias in recommender systems is a topic of interest within the scholarly community.
Bias is a complex term that can refer to various types of biases associated with interactions between users and items in a given system <cite class="ltx_cite ltx_citemacro_citep">(Chen et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08046v1#bib.bib13" title="">2023</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">Many studies have focused on specifically measuring the phenomenon of <span class="ltx_text ltx_font_italic" id="S1.p2.1.1">popularity bias</span> in collaborative filtering systems <cite class="ltx_cite ltx_citemacro_citep">(Ahanger et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08046v1#bib.bib9" title="">2022</a>; Elahi et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08046v1#bib.bib18" title="">2021</a>; Yalcin, <a class="ltx_ref" href="https://arxiv.org/html/2409.08046v1#bib.bib29" title="">2021</a>; Abdollahpouri, <a class="ltx_ref" href="https://arxiv.org/html/2409.08046v1#bib.bib2" title="">2020</a>; Zhao et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08046v1#bib.bib31" title="">2022</a>)</cite>.
Despite this large research effort to track and mitigate popularity bias, there is no univocal message regarding why and when it occurs.
Studies that measure popularity bias propagated by commonly used algorithms on benchmark datasets report varying, sometimes contradicting results <cite class="ltx_cite ltx_citemacro_citep">(Daniil et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08046v1#bib.bib15" title="">2024</a>)</cite>.
This observation raises questions; is popularity bias sensitive to properties of the system that do not receive sufficient attention?
Why is a seemingly simple phenomenon so hard to study?
We hypothesize that two factors complicate bias measuring and reporting, namely data characteristics and algorithm configurations.</p>
</div>
<section class="ltx_paragraph" id="S1.SS0.SSS0.Px1">
<h5 class="ltx_title ltx_title_paragraph">Data characteristics</h5>
<div class="ltx_para" id="S1.SS0.SSS0.Px1.p1">
<p class="ltx_p" id="S1.SS0.SSS0.Px1.p1.1">Benchmark datasets are very useful for academic research, as they allow researchers to evaluate their hypotheses and benchmark their proposed debiasing methods.
However, their consistent use raises concerns that relate to the dependence on the domain and source they were constructed from, and the potentiality for blind spots that stem from outdated rating behaviour.
Most importantly, by reporting on different types of bias such as popularity bias on only a small set of publicly available datasets <cite class="ltx_cite ltx_citemacro_citep">(Wang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08046v1#bib.bib28" title="">2023</a>)</cite>, researchers are restricted by their specific characteristics.
This specificity limits the scope of research <cite class="ltx_cite ltx_citemacro_citep">(Cremonesi and Jannach, <a class="ltx_ref" href="https://arxiv.org/html/2409.08046v1#bib.bib14" title="">2021</a>)</cite>, and obfuscates the process of examining causality.
In other words, it is not trivial to conclude whether the propagation of bias or lack thereof is a result of the respective algorithm’s functionality, or of certain intricate details of the user-item interactions within these datasets.
Informed data synthesis can potentially assist with overcoming this barrier and gaining a holistic view of bias propagation by recommender systems.</p>
</div>
</section>
<section class="ltx_paragraph" id="S1.SS0.SSS0.Px2">
<h5 class="ltx_title ltx_title_paragraph">Algorithm configuration</h5>
<div class="ltx_para" id="S1.SS0.SSS0.Px2.p1">
<p class="ltx_p" id="S1.SS0.SSS0.Px2.p1.1">Insufficient reporting of algorithm configurations leads to a reproducibility problem within research on recommender systems.
Studies have shown that papers published in top-tier conferences often do not disclose sufficient information for replication and verification <cite class="ltx_cite ltx_citemacro_citep">(Ferrari Dacrema et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08046v1#bib.bib19" title="">2021</a>)</cite>.
This issue is also relevant in the bias discussion.
Even relatively simple algorithmic approaches, such as neighbour-based ones, are constructed using hyperparameters and implementation choices that might affect whether bias propagation is observed.
The RecSys community proposes a set of evaluation frameworks to promote reproducibility<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/ACMRecSys/recsys-evaluation-frameworks" title="">https://github.com/ACMRecSys/recsys-evaluation-frameworks</a></span></span></span>, but we found that there are important differences between them that often go unmentioned.
Testing the effect of algorithm configuration can be a means of reporting on bias in a comprehensive manner.</p>
</div>
<div class="ltx_para" id="S1.SS0.SSS0.Px2.p2">
<p class="ltx_p" id="S1.SS0.SSS0.Px2.p2.1">In this paper, we experiment with data characteristics and algorithm configurations and observe the effect on popularity bias, with a focus on UserKNN.
First, we look into data characteristics that might have an impact on popularity bias given a rating prediction and top-10 recommendation task, a common setup among recent studies on popularity bias <cite class="ltx_cite ltx_citemacro_citep">(Abdollahpouri et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08046v1#bib.bib6" title="">2019b</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08046v1#bib.bib7" title="">2020</a>; Kowald et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08046v1#bib.bib22" title="">2020</a>)</cite>.
Specifically, we delve into the relation between popularity and rating, as well as the preferences of users with large profiles.
We form a set of data scenarios by tweaking and combining these characteristics.
For each scenario, we generate a corresponding synthetic dataset of ratings, based on the interactions from a subset of Book-Crossing <cite class="ltx_cite ltx_citemacro_citep">(Ziegler et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08046v1#bib.bib32" title="">2005</a>)</cite> constructed by <cite class="ltx_cite ltx_citemacro_citep">(Naghiaei et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08046v1#bib.bib23" title="">2022</a>)</cite>.
Second, for UserKNN we identify configuration choices that may impact whether or not popularity bias is observed, and often differ across implementations in frameworks recommended by ACM RecSys, with LensKit <cite class="ltx_cite ltx_citemacro_citep">(Ekstrand, <a class="ltx_ref" href="https://arxiv.org/html/2409.08046v1#bib.bib17" title="">2020</a>)</cite> and Cornac <cite class="ltx_cite ltx_citemacro_citep">(Salah et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08046v1#bib.bib25" title="">2020</a>)</cite> being tested in this paper.
Despite the simplicity of UserKNN, there are certain configuration choices that can potentially greatly influence the result.
We perform the recommendation process for each synthetic dataset with varied UserKNN configuration choices.
We apply commonly used popularity bias metrics to evaluate the recommended lists, as well as RMSE and NDCG@10 to estimate the performance when it comes to rating prediction and ranking.</p>
</div>
<div class="ltx_para" id="S1.SS0.SSS0.Px2.p3">
<p class="ltx_p" id="S1.SS0.SSS0.Px2.p3.1">Our results show that popularity bias is not always present in the recommended lists.
Whether popularity bias is observed, and to what extent, depends on the characteristics of the dataset and configuration choices of UserKNN, which also relate to the framework implementation.
The relationship between rating and popularity, as well as the preferences of users with large profiles are crucial when it comes to popularity bias propagation.
Additionally, UserKNN configurations such as minimum similarity and minimum neighbours largely impact the intensity of popularity bias.</p>
</div>
<div class="ltx_para" id="S1.SS0.SSS0.Px2.p4">
<p class="ltx_p" id="S1.SS0.SSS0.Px2.p4.1">The contributions of this paper are as follows:</p>
<ul class="ltx_itemize" id="S1.I1">
<li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i1.p1">
<p class="ltx_p" id="S1.I1.i1.p1.1">a systematic investigation into the effect of data characteristics on popularity bias, by comparing results on five synthetic datasets for which we control the properties.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i2.p1">
<p class="ltx_p" id="S1.I1.i2.p1.1">a systematic investigation into the effect of implementation differences, by comparing results of UserKNN configurations as well as non-configurable implementation differences in well known frameworks.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i3.p1">
<p class="ltx_p" id="S1.I1.i3.p1.1">we highlight standout results among the many, to give insights into why certain combinations of dataset characteristics and UserKNN configurations lead to popularity bias.</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="S1.SS0.SSS0.Px2.p5">
<p class="ltx_p" id="S1.SS0.SSS0.Px2.p5.1">With this work, we wish to contribute to the field by highlighting and disentangling the challenges in studying popularity bias in recommender systems.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2. </span>Related Work</h2>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">In this section, we provide a brief overview of existing work on bias in recommender systems and datasets and reproducibility.</p>
</div>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1. </span>Bias in Recommender Systems</h3>
<div class="ltx_para" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.1">Recommender systems are not immune to bias, even when only user consumption history is fed to the model and not other information about the users or items.
<cite class="ltx_cite ltx_citemacro_citep">(Edizel et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08046v1#bib.bib16" title="">2019</a>)</cite> discuss that a model might learn sensitive information like the gender of the user in the latent space, and produce recommendations that are gender-dependent, even more so than the interactions observed in the training set itself.
In a survey on the topic of bias and debias in recommender systems research, <cite class="ltx_cite ltx_citemacro_citep">(Chen et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08046v1#bib.bib13" title="">2023</a>)</cite> identify three factors that contribute to bias: user behavior’s dependence on the exposure mechanism of the system, imbalanced presence of items (and users) in the data, and the effect of feedback loops.
One type of bias that arises from the interaction between an algorithm and imbalanced data is popularity bias.</p>
</div>
<div class="ltx_para" id="S2.SS1.p2">
<p class="ltx_p" id="S2.SS1.p2.1">Popularity bias is the phenomenon where popular items (i.e., items that are frequently interacted with in the dataset) are recommended even more frequently than their popularity would warrant <cite class="ltx_cite ltx_citemacro_citep">(Abdollahpouri and Mansoury, <a class="ltx_ref" href="https://arxiv.org/html/2409.08046v1#bib.bib5" title="">2020</a>)</cite>.
It is commonly believed to be caused by the long-tail distribution that often characterizes user-item interactions: most items have been rated by only a few users, and a few items have been rated by many users <cite class="ltx_cite ltx_citemacro_citep">(Brynjolfsson et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08046v1#bib.bib11" title="">2006</a>)</cite>.
Various studies have reported that frequently used recommender systems algorithms are prone to propagating popularity bias existing in the dataset they were trained on <cite class="ltx_cite ltx_citemacro_citep">(Abdollahpouri et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08046v1#bib.bib6" title="">2019b</a>; Kowald et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08046v1#bib.bib22" title="">2020</a>; Naghiaei et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08046v1#bib.bib23" title="">2022</a>)</cite>.
Different metrics have been proposed to quantify popularity bias <cite class="ltx_cite ltx_citemacro_citep">(Abdollahpouri et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08046v1#bib.bib6" title="">2019b</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08046v1#bib.bib3" title="">2017</a>)</cite>.
Despite the extensive literature, our understanding of why certain algorithms and datasets are more or less prone to popularity bias is limited.
Additionally, studies that measure popularity bias on the same algorithms and datasets sometimes report conflicting results <cite class="ltx_cite ltx_citemacro_citep">(Daniil et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08046v1#bib.bib15" title="">2024</a>)</cite>.
In this paper, we describe specific scenarios of data-algorithm interaction and report the results of different metrics associated with popularity bias.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2. </span>Datasets and Reproducibility</h3>
<div class="ltx_para" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.1">The way that recommender systems researchers usually test their hypotheses, novel algorithms, and metrics is by conducting experiments on one or more publicly available datasets of user-item interactions.
Surveys on the topic of recommender systems research show that the pool of datasets used is small <cite class="ltx_cite ltx_citemacro_citep">(Bobadilla et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08046v1#bib.bib10" title="">2013</a>)</cite>; user behavior data from real-world applications such as media platforms is often proprietary and therefore cannot be used for benchmarking <cite class="ltx_cite ltx_citemacro_citep">(Khusro et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08046v1#bib.bib21" title="">2016</a>)</cite>.
In popularity bias studies, the use of different versions of MovieLens is exceedingly common <cite class="ltx_cite ltx_citemacro_citep">(Wang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08046v1#bib.bib28" title="">2023</a>)</cite>, which leads us to wonder whether studies can be conclusive when they are solely carried out on a few datasets.
In our approach, we include a data synthesis step that allows us to experiment with different data distributions and observe the result.
Data synthesis is a much-discussed topic in recommender systems research, though it is usually discussed in the context of privacy <cite class="ltx_cite ltx_citemacro_citep">(Slokom, <a class="ltx_ref" href="https://arxiv.org/html/2409.08046v1#bib.bib26" title="">2018</a>; Tso and Schmidt-Thieme, <a class="ltx_ref" href="https://arxiv.org/html/2409.08046v1#bib.bib27" title="">2006</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S2.SS2.p2">
<p class="ltx_p" id="S2.SS2.p2.1">The existence of datasets for training and testing is valuable for the recommender systems community; research on publicly available data is necessary in order to ensure reproducibility <cite class="ltx_cite ltx_citemacro_citep">(Said and Bellogín, <a class="ltx_ref" href="https://arxiv.org/html/2409.08046v1#bib.bib24" title="">2014</a>)</cite>.
However, as noted by <cite class="ltx_cite ltx_citemacro_citep">(Cremonesi and Jannach, <a class="ltx_ref" href="https://arxiv.org/html/2409.08046v1#bib.bib14" title="">2021</a>)</cite>, sharing the used data is not always sufficient to ensure basic reproducibility.
Studies showed that in most cases recommender systems papers presented at big conferences did not provide code for their data preprocessing or hyperparameter tuning <cite class="ltx_cite ltx_citemacro_citep">(Ferrari Dacrema et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08046v1#bib.bib19" title="">2021</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08046v1#bib.bib20" title="">2019</a>)</cite>.
This is also the case in popularity bias research; studies are often not accompanied by code, and sometimes do not describe the data filtering or hyperparameter setting <cite class="ltx_cite ltx_citemacro_citep">(Abdollahpouri et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08046v1#bib.bib6" title="">2019b</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08046v1#bib.bib7" title="">2020</a>)</cite>.
Therefore, concluding that an algorithm or a dataset is prone to popularity bias becomes challenging, as it is not possible to verify or falsify the claims <cite class="ltx_cite ltx_citemacro_citep">(Cremonesi and Jannach, <a class="ltx_ref" href="https://arxiv.org/html/2409.08046v1#bib.bib14" title="">2021</a>)</cite>.
To showcase this issue, we experiment with algorithms implemented in different libraries and with different parameter configurations.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3. </span>Identifying Data Characteristics and Algorithm Configurations</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">In this section, we identify data characteristics and algorithm configurations that can influence popularity bias propagation in the context of a rating prediction and top-10 recommendation task.
First, we locate data characteristics that can have an effect on whether popularity bias is propagated, inspired by the functionality of UserKNN.
UserKNN is a relatively simple algorithmic approach that simulates a ‘word-of-mouth’ setting and has lower dependence on non-intuitive parameters that impact optimization (e.g., learning rate).
Accordingly, we form a set of data scenarios that combine the located characteristics.
Second, we inspect UserKNN and locate configurations that can be potentially impactful for popularity bias propagation.</p>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1. </span>Data Characteristics</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">Whether or not popularity bias is propagated depends on how popularity manifests in the dataset at hand.
We discuss the relation between rating and popularity and the preferences of influential users.</p>
</div>
<section class="ltx_paragraph" id="S3.SS1.SSS0.Px1">
<h5 class="ltx_title ltx_title_paragraph">Relation Between Rating and Popularity</h5>
<div class="ltx_para" id="S3.SS1.SSS0.Px1.p1">
<p class="ltx_p" id="S3.SS1.SSS0.Px1.p1.1">In the context of a rating prediction task, an algorithm aims to predict a future rating for every user of every item they have not already consumed.
Given that this is done by considering the other users’ ratings, it may be that items with high average rating will be prioritized by the system.
Popularity bias studies often do not disclose whether the popular items in the dataset<span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>Note that item popularity in this context is equivalent to how many users have interacted with the item in a given dataset.</span></span></span> also have high ratings, but instead assume that their frequent recommendation is solely due to their popularity.</p>
</div>
</section>
<section class="ltx_paragraph" id="S3.SS1.SSS0.Px2">
<h5 class="ltx_title ltx_title_paragraph">Influential Users</h5>
<div class="ltx_para" id="S3.SS1.SSS0.Px2.p1">
<p class="ltx_p" id="S3.SS1.SSS0.Px2.p1.1">In the context of UserKNN, certain users may be influential because they neighbour with many other users.
For example, if only two users have rated an item and they have not rated any other items, then this item will not be recommended to anyone, because the two users are not influential at all within the system.
Consequently, it is interesting to investigate the notion of user influence and whether the result is dominated by the preferences of users who, because of their large profile size, are more likely to have many neighbours.</p>
</div>
</section>
<section class="ltx_paragraph" id="S3.SS1.SSS0.Px3">
<h5 class="ltx_title ltx_title_paragraph">Data Scenarios</h5>
<div class="ltx_para" id="S3.SS1.SSS0.Px3.p1">
<p class="ltx_p" id="S3.SS1.SSS0.Px3.p1.1">We synthesize data that follows a long-tail distribution for items and users, as it is discussed as a prerequisite for popularity bias to occur <cite class="ltx_cite ltx_citemacro_citep">(Brynjolfsson et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08046v1#bib.bib11" title="">2006</a>; Celma and Cano, <a class="ltx_ref" href="https://arxiv.org/html/2409.08046v1#bib.bib12" title="">2008</a>)</cite>.
Specifically, we choose the interactions in a subset of the Book-Crossing dataset <cite class="ltx_cite ltx_citemacro_citep">(Naghiaei et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08046v1#bib.bib23" title="">2022</a>; Ziegler et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08046v1#bib.bib32" title="">2005</a>)</cite> as a baseline, but remove the rating values.
To reflect on the observations above, we form a set of scenarios around the relationship between popularity, rating and user influence to assign a synthesized rating to each interaction.
This approach allows us to simulate a real-world scenario where consumption is long-tail, while still experimenting with data properties relevant for popularity bias.
We recognize that the scenarios are not necessarily realistic.
User tendencies are likely to be more subtle in real world situations.
However, we believe that experimenting with extreme behaviors can help us showcase the effect that we are investigating, and lead the way for more nuanced experimentation.</p>
</div>
<div class="ltx_para" id="S3.SS1.SSS0.Px3.p2">
<p class="ltx_p" id="S3.SS1.SSS0.Px3.p2.1">The scenarios, as well as the process we followed to generate each of them are as follows:</p>
<ol class="ltx_enumerate" id="S3.I1">
<li class="ltx_item" id="S3.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(1)</span>
<div class="ltx_para" id="S3.I1.i1.p1">
<p class="ltx_p" id="S3.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I1.i1.p1.1.1">Scenario 1: There is no relation between popularity and rating</span>: For each interaction, draw a rating value between 1 and 10 uniformly at random.</p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(2)</span>
<div class="ltx_para" id="S3.I1.i2.p1">
<p class="ltx_p" id="S3.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I1.i2.p1.1.1">Scenario 2: Popular items are generally rated higher by the users</span>: For each interaction, draw a rating value between 1 and 10 from a normal distribution, where the mean is the popularity of the item normalized between 1 and 10.</p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(3)</span>
<div class="ltx_para" id="S3.I1.i3.p1">
<p class="ltx_p" id="S3.I1.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I1.i3.p1.1.1">Scenario 3: Popular items are generally rated lower by the users</span>: For each interaction, draw a rating value between 1 and 10 from a normal distribution, where the mean is the opposite of the popularity of the item normalized between 1 and 10.</p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(4)</span>
<div class="ltx_para" id="S3.I1.i4.p1">
<p class="ltx_p" id="S3.I1.i4.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I1.i4.p1.1.1">Scenario 4: Only users with big profiles rate popular items higher</span>: For each interaction, draw a rating value between 1 and 10 uniformly at random. For the users with the 20% largest profiles, replace by drawing from a Poisson distribution where the mean is the popularity of the item normalized between 1 and 10.</p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(5)</span>
<div class="ltx_para" id="S3.I1.i5.p1">
<p class="ltx_p" id="S3.I1.i5.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I1.i5.p1.1.1">Scenario 5: Only users with big profiles rate popular items lower</span>: For each interaction, draw a rating value between 1 and 10 uniformly at random. For the users with the 20% largest profiles, replace by drawing from a Poisson distribution where the mean is the opposite of the popularity of the item normalized between 1 and 10.</p>
</div>
</li>
</ol>
</div>
<div class="ltx_para" id="S3.SS1.SSS0.Px3.p3">
<p class="ltx_p" id="S3.SS1.SSS0.Px3.p3.1">Figures <a class="ltx_ref" href="https://arxiv.org/html/2409.08046v1#S3.F1.sf1" title="In Figure 1 ‣ Data Scenarios ‣ 3.1. Data Characteristics ‣ 3. Identifying Data Characteristics and Algorithm Configurations ‣ On the challenges of studying bias in Recommender Systems: A UserKNN case study"><span class="ltx_text ltx_ref_tag">1a</span></a> to <a class="ltx_ref" href="https://arxiv.org/html/2409.08046v1#S3.F1.sf5" title="In Figure 1 ‣ Data Scenarios ‣ 3.1. Data Characteristics ‣ 3. Identifying Data Characteristics and Algorithm Configurations ‣ On the challenges of studying bias in Recommender Systems: A UserKNN case study"><span class="ltx_text ltx_ref_tag">1e</span></a> show the correlation between item average rating and item popularity within the five synthetic datasets.
There is a noticeable effect of the data characteristics discussed in this study, given that the synthetic datasets were constructed with them in mind.
Specifically, scenario 1 shows no relation between average rating and popularity, as the ratings were drawn uniformly at random.
Scenarios 2 and 3 showcase a very positive and a very negative correlation, respectively.
For scenario 4, we see a positive correlation, which is higher for users with large profiles, and for scenario 5 a negative correlation, even lower for users with large profiles.</p>
</div>
<figure class="ltx_figure" id="S3.F1">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S3.F1.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="139" id="S3.F1.sf1.g1" src="extracted/5850535/plots/data_analysis/data_analysis_Scenario_1.png" width="180"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(a) </span>Scenario 1</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S3.F1.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="142" id="S3.F1.sf2.g1" src="extracted/5850535/plots/data_analysis/data_analysis_Scenario_2.png" width="180"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(b) </span>Scenario 2</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S3.F1.sf3"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="139" id="S3.F1.sf3.g1" src="extracted/5850535/plots/data_analysis/data_analysis_Scenario_3.png" width="180"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(c) </span>Scenario 3</figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S3.F1.sf4"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="142" id="S3.F1.sf4.g1" src="extracted/5850535/plots/data_analysis/data_analysis_Scenario_4.png" width="180"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(d) </span>Scenario 4</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S3.F1.sf5"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="139" id="S3.F1.sf5.g1" src="extracted/5850535/plots/data_analysis/data_analysis_Scenario_5.png" width="180"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(e) </span>Scenario 5</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1. </span>Relation between item average rating and item popularity among all users and among users with the 20% largest profiles given five synthetic datasets.</figcaption>
</figure>
</section>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2. </span>Algorithm Configurations</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">In this section, we describe the UserKNN configurations examined.</p>
</div>
<section class="ltx_subsubsection" id="S3.SS2.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.1. </span>UserKNN</h4>
<div class="ltx_para" id="S3.SS2.SSS1.p1">
<p class="ltx_p" id="S3.SS2.SSS1.p1.1">Despite UserKNN’s simplicity, there are configuration choices that can potentially greatly influence the result.
We identified the following: minimum similarity, the items considered for similarity, and minimum neighbours.</p>
</div>
<section class="ltx_paragraph" id="S3.SS2.SSS1.Px1">
<h5 class="ltx_title ltx_title_paragraph">Minimum Similarity</h5>
<div class="ltx_para" id="S3.SS2.SSS1.Px1.p1">
<p class="ltx_p" id="S3.SS2.SSS1.Px1.p1.1">It is common in UserKNN implementations that not all users who rated an item are considered.
Instead, the notion of neighbourhood is introduced; only the users most similar to the target user are taken into account when producing a predicted score.
The filtering can be done by introducing a cut off value of minimum similarity for consideration, among other techniques.</p>
</div>
</section>
<section class="ltx_paragraph" id="S3.SS2.SSS1.Px2">
<h5 class="ltx_title ltx_title_paragraph">Items for Similarity</h5>
<div class="ltx_para" id="S3.SS2.SSS1.Px2.p1">
<p class="ltx_p" id="S3.SS2.SSS1.Px2.p1.1">Given a similarity metric (e.g., cosine similarity), a design choice still has to be made on whether similarity between two users will be calculated for their full rating vectors, or only for ratings on items these two users have in common.
See section 2.3.1.1 in <cite class="ltx_cite ltx_citemacro_citet">Aggarwal et al<span class="ltx_text">.</span> (<a class="ltx_ref" href="https://arxiv.org/html/2409.08046v1#bib.bib8" title="">2016</a>)</cite> for clarification.</p>
</div>
</section>
<section class="ltx_paragraph" id="S3.SS2.SSS1.Px3">
<h5 class="ltx_title ltx_title_paragraph">Minimum Neighbours</h5>
<div class="ltx_para" id="S3.SS2.SSS1.Px3.p1">
<p class="ltx_p" id="S3.SS2.SSS1.Px3.p1.1">When the neighbourhood is constructed for a given user, then a score is predicted for each item in a list of candidates.
In some implementations, the predicted score is not calculated for all potential items.
Instead, the algorithm focuses on items that have been rated by at least a minimum number of neighbours of the current user.</p>
</div>
<div class="ltx_para" id="S3.SS2.SSS1.Px3.p2">
<p class="ltx_p" id="S3.SS2.SSS1.Px3.p2.1">It is worth noting that LensKit and Cornac differ when it comes to these choices as seen in Table <a class="ltx_ref" href="https://arxiv.org/html/2409.08046v1#S3.T1" title="Table 1 ‣ Minimum Neighbours ‣ 3.2.1. UserKNN ‣ 3.2. Algorithm Configurations ‣ 3. Identifying Data Characteristics and Algorithm Configurations ‣ On the challenges of studying bias in Recommender Systems: A UserKNN case study"><span class="ltx_text ltx_ref_tag">1</span></a>. Two of the parameters tested are not configurable in Cornac, while the third is not configurable in either frameworks.</p>
</div>
<figure class="ltx_table" id="S3.T1">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1. </span>Configuration choices related to UserKNN made by LensKit for Python and Cornac.</figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S3.T1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S3.T1.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t" id="S3.T1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.1.1.1">Configuration choice</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S3.T1.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.1.2.1">LensKit for Python</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S3.T1.1.1.1.3"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.1.3.1">Cornac</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T1.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S3.T1.1.2.1.1">Minimum similarity</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.2.1.2">Configurable (default: 0)</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.2.1.3">-1</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T1.1.3.2.1">Items for similarity</th>
<td class="ltx_td ltx_align_center" id="S3.T1.1.3.2.2">All items</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.3.2.3">Common items</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b" id="S3.T1.1.4.3.1">Minimum neighbours</th>
<td class="ltx_td ltx_align_center ltx_border_b" id="S3.T1.1.4.3.2">Configurable (default: 1)</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S3.T1.1.4.3.3">1</td>
</tr>
</tbody>
</table>
</figure>
</section>
</section>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4. </span>Experimental Setup</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">In this section, we describe the experiments that we run in order to determine the effect of data characteristics and algorithm configuration on the propagation of popularity bias.
The Jupyter notebooks that contain the experiments<span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/SavvinaDaniil/DiagnosingBiasRecSys/" title="">https://github.com/SavvinaDaniil/DiagnosingBiasRecSys/</a></span></span></span> have been made open source.
For every synthetic data scenario, we perform a recommendation process given every version of UserKNN.
Specifically, we test the following versions given the configurations discussed in section <a class="ltx_ref" href="https://arxiv.org/html/2409.08046v1#S3.SS2.SSS1" title="3.2.1. UserKNN ‣ 3.2. Algorithm Configurations ‣ 3. Identifying Data Characteristics and Algorithm Configurations ‣ On the challenges of studying bias in Recommender Systems: A UserKNN case study"><span class="ltx_text ltx_ref_tag">3.2.1</span></a>:</p>
<ul class="ltx_itemize" id="S4.I1">
<li class="ltx_item" id="S4.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i1.p1">
<p class="ltx_p" id="S4.I1.i1.p1.1">Min. similarity 0, over all items, 1 min. neighbour.</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i2.p1">
<p class="ltx_p" id="S4.I1.i2.p1.1">Min. similarity 0, over all items, 2 min. neighbours.</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i3.p1">
<p class="ltx_p" id="S4.I1.i3.p1.1">Min. similarity -1, over all items, 1 min. neighbour.</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i4.p1">
<p class="ltx_p" id="S4.I1.i4.p1.1">Min. similarity -1, over all items, 2 min. neighbours.</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i5.p1">
<p class="ltx_p" id="S4.I1.i5.p1.1">Min. similarity -1, over common items, 1 min. neighbour.</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="S4.p2">
<p class="ltx_p" id="S4.p2.1">For each UserKNN version and each dataset, we perform optimization based on RMSE to find the best values for some of the non-fixed hyperparameters of the respective version.
The resulting hyperparameters can be seen in our repository.
Afterwards, we divide the users into training and test users in a 5-fold cross validated way.
We make sure to use the same splits for all algorithms and all versions.
For every test user, we use 80% of their ratings for training and the remaining 20% for testing, which is an option in LensKit.
We train the model on the training set.
For each user in the test set, we predict a rating for every item they have not rated in the training set, rank the items based on the predicted score and recommend the top-10 items, in line with recent studies on popularity bias.</p>
</div>
<div class="ltx_para" id="S4.p3">
<p class="ltx_p" id="S4.p3.1">We report on RMSE and NDCG@10 to estimate the effectiveness of the rating prediction and ranking, respectively.
We also calculate the following widely used metrics on the recommended lists to estimate popularity bias propagation:</p>
</div>
<div class="ltx_para" id="S4.p4">
<ol class="ltx_enumerate" id="S4.I2">
<li class="ltx_item" id="S4.I2.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(1)</span>
<div class="ltx_para" id="S4.I2.i1.p1">
<p class="ltx_p" id="S4.I2.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I2.i1.p1.1.1">Popularity Correlation (PopCorr)</span>: The correlation between popularity in training set and recommendation frequency for every item.</p>
</div>
</li>
<li class="ltx_item" id="S4.I2.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(2)</span>
<div class="ltx_para" id="S4.I2.i2.p1">
<p class="ltx_p" id="S4.I2.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I2.i2.p1.1.1">Average Recommendation Popularity (ARP)</span>: The average popularity of the items in the recommended lists <cite class="ltx_cite ltx_citemacro_citep">(Yin et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08046v1#bib.bib30" title="">2012</a>; Abdollahpouri et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08046v1#bib.bib4" title="">2019a</a>)</cite>.</p>
</div>
</li>
<li class="ltx_item" id="S4.I2.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(3)</span>
<div class="ltx_para" id="S4.I2.i3.p1">
<p class="ltx_p" id="S4.I2.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I2.i3.p1.1.1">Popularity Lift (PL)</span>: The average relative difference in popularity between the recommended items and the items in the users’ profiles <cite class="ltx_cite ltx_citemacro_citep">(Abdollahpouri et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08046v1#bib.bib7" title="">2020</a>)</cite>.</p>
</div>
</li>
</ol>
</div>
<div class="ltx_para" id="S4.p5">
<p class="ltx_p" id="S4.p5.1">Finally, for every dataset we perform a Mann–Whitney <math alttext="U" class="ltx_Math" display="inline" id="S4.p5.1.m1.1"><semantics id="S4.p5.1.m1.1a"><mi id="S4.p5.1.m1.1.1" xref="S4.p5.1.m1.1.1.cmml">U</mi><annotation-xml encoding="MathML-Content" id="S4.p5.1.m1.1b"><ci id="S4.p5.1.m1.1.1.cmml" xref="S4.p5.1.m1.1.1">𝑈</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p5.1.m1.1c">U</annotation><annotation encoding="application/x-llamapun" id="S4.p5.1.m1.1d">italic_U</annotation></semantics></math> test to observe whether there is a significant difference among configurations for ARP and PL, and include the result in the respective tables.</p>
</div>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5. </span>Results</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">In this section, we provide insights into how UserKNN configurations impact popularity bias and performance for the different datasets by presenting the results across the set of metrics listed in section <a class="ltx_ref" href="https://arxiv.org/html/2409.08046v1#S4" title="4. Experimental Setup ‣ On the challenges of studying bias in Recommender Systems: A UserKNN case study"><span class="ltx_text ltx_ref_tag">4</span></a> in table <a class="ltx_ref" href="https://arxiv.org/html/2409.08046v1#S5.T2" title="Table 2 ‣ 5. Results ‣ On the challenges of studying bias in Recommender Systems: A UserKNN case study"><span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
<figure class="ltx_table" id="S5.T2">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2. </span>Popularity bias and performance of different UserKNN configurations given different data scenarios. OverCommon set to True corresponds to the Cornac implementation, and set to False to the LensKit implementation. For the popularity bias metrics, we embolden the highest value among configurations. For ARP and PL, we use the asterisk (*) to signify which values are significantly lower than the highest one according to a Mann–Whitney <math alttext="U" class="ltx_Math" display="inline" id="S5.T2.3.m1.1"><semantics id="S5.T2.3.m1.1b"><mi id="S5.T2.3.m1.1.1" xref="S5.T2.3.m1.1.1.cmml">U</mi><annotation-xml encoding="MathML-Content" id="S5.T2.3.m1.1c"><ci id="S5.T2.3.m1.1.1.cmml" xref="S5.T2.3.m1.1.1">𝑈</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.3.m1.1d">U</annotation><annotation encoding="application/x-llamapun" id="S5.T2.3.m1.1e">italic_U</annotation></semantics></math> test with <math alttext="p&lt;0.005" class="ltx_Math" display="inline" id="S5.T2.4.m2.1"><semantics id="S5.T2.4.m2.1b"><mrow id="S5.T2.4.m2.1.1" xref="S5.T2.4.m2.1.1.cmml"><mi id="S5.T2.4.m2.1.1.2" xref="S5.T2.4.m2.1.1.2.cmml">p</mi><mo id="S5.T2.4.m2.1.1.1" xref="S5.T2.4.m2.1.1.1.cmml">&lt;</mo><mn id="S5.T2.4.m2.1.1.3" xref="S5.T2.4.m2.1.1.3.cmml">0.005</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T2.4.m2.1c"><apply id="S5.T2.4.m2.1.1.cmml" xref="S5.T2.4.m2.1.1"><lt id="S5.T2.4.m2.1.1.1.cmml" xref="S5.T2.4.m2.1.1.1"></lt><ci id="S5.T2.4.m2.1.1.2.cmml" xref="S5.T2.4.m2.1.1.2">𝑝</ci><cn id="S5.T2.4.m2.1.1.3.cmml" type="float" xref="S5.T2.4.m2.1.1.3">0.005</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.4.m2.1d">p&lt;0.005</annotation><annotation encoding="application/x-llamapun" id="S5.T2.4.m2.1e">italic_p &lt; 0.005</annotation></semantics></math>.</figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S5.T2.9">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T2.7.3">
<td class="ltx_td ltx_border_tt" id="S5.T2.7.3.4"></td>
<th class="ltx_td ltx_th ltx_th_column ltx_border_tt" id="S5.T2.7.3.5"></th>
<th class="ltx_td ltx_th ltx_th_column ltx_border_tt" id="S5.T2.7.3.6"></th>
<th class="ltx_td ltx_th ltx_th_column ltx_border_tt" id="S5.T2.7.3.7"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S5.T2.7.3.8">Pop</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" id="S5.T2.5.1.1">ARP<math alttext="\uparrow" class="ltx_Math" display="inline" id="S5.T2.5.1.1.m1.1"><semantics id="S5.T2.5.1.1.m1.1a"><mo id="S5.T2.5.1.1.m1.1.1" stretchy="false" xref="S5.T2.5.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S5.T2.5.1.1.m1.1b"><ci id="S5.T2.5.1.1.m1.1.1.cmml" xref="S5.T2.5.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.5.1.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S5.T2.5.1.1.m1.1d">↑</annotation></semantics></math>
</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" id="S5.T2.6.2.2">PL<math alttext="\uparrow" class="ltx_Math" display="inline" id="S5.T2.6.2.2.m1.1"><semantics id="S5.T2.6.2.2.m1.1a"><mo id="S5.T2.6.2.2.m1.1.1" stretchy="false" xref="S5.T2.6.2.2.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S5.T2.6.2.2.m1.1b"><ci id="S5.T2.6.2.2.m1.1.1.cmml" xref="S5.T2.6.2.2.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.6.2.2.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S5.T2.6.2.2.m1.1d">↑</annotation></semantics></math>
</th>
<th class="ltx_td ltx_nopad_r ltx_th ltx_th_column ltx_border_tt" id="S5.T2.7.3.9"></th>
<th class="ltx_td ltx_nopad_l ltx_align_right ltx_th ltx_th_column ltx_border_tt" id="S5.T2.7.3.3">RMSE<math alttext="\downarrow" class="ltx_Math" display="inline" id="S5.T2.7.3.3.m1.1"><semantics id="S5.T2.7.3.3.m1.1a"><mo id="S5.T2.7.3.3.m1.1.1" stretchy="false" xref="S5.T2.7.3.3.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S5.T2.7.3.3.m1.1b"><ci id="S5.T2.7.3.3.m1.1.1.cmml" xref="S5.T2.7.3.3.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.7.3.3.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T2.7.3.3.m1.1d">↓</annotation></semantics></math>
</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" id="S5.T2.7.3.10">NDCG</th>
</tr>
<tr class="ltx_tr" id="S5.T2.9.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column" id="S5.T2.9.5.3">Data</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column" id="S5.T2.9.5.4">Min</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column" id="S5.T2.9.5.5">Over</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column" id="S5.T2.9.5.6">Min</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column" id="S5.T2.8.4.1">Corr<math alttext="\uparrow" class="ltx_Math" display="inline" id="S5.T2.8.4.1.m1.1"><semantics id="S5.T2.8.4.1.m1.1a"><mo id="S5.T2.8.4.1.m1.1.1" stretchy="false" xref="S5.T2.8.4.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S5.T2.8.4.1.m1.1b"><ci id="S5.T2.8.4.1.m1.1.1.cmml" xref="S5.T2.8.4.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.8.4.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S5.T2.8.4.1.m1.1d">↑</annotation></semantics></math>
</th>
<th class="ltx_td ltx_th ltx_th_column" id="S5.T2.9.5.7"></th>
<th class="ltx_td ltx_th ltx_th_column" id="S5.T2.9.5.8"></th>
<th class="ltx_td ltx_nopad_r ltx_th ltx_th_column" id="S5.T2.9.5.9"></th>
<th class="ltx_td ltx_nopad_l ltx_th ltx_th_column" id="S5.T2.9.5.10"></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column" id="S5.T2.9.5.2">@10<math alttext="\uparrow" class="ltx_Math" display="inline" id="S5.T2.9.5.2.m1.1"><semantics id="S5.T2.9.5.2.m1.1a"><mo id="S5.T2.9.5.2.m1.1.1" stretchy="false" xref="S5.T2.9.5.2.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S5.T2.9.5.2.m1.1b"><ci id="S5.T2.9.5.2.m1.1.1.cmml" xref="S5.T2.9.5.2.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.9.5.2.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S5.T2.9.5.2.m1.1d">↑</annotation></semantics></math>
</th>
</tr>
<tr class="ltx_tr" id="S5.T2.9.6.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column" id="S5.T2.9.6.1.1">Scenario</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column" id="S5.T2.9.6.1.2">Sim</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column" id="S5.T2.9.6.1.3">Common</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column" id="S5.T2.9.6.1.4">Nbrs</th>
<th class="ltx_td ltx_th ltx_th_column" id="S5.T2.9.6.1.5"></th>
<th class="ltx_td ltx_th ltx_th_column" id="S5.T2.9.6.1.6"></th>
<th class="ltx_td ltx_th ltx_th_column" id="S5.T2.9.6.1.7"></th>
<th class="ltx_td ltx_nopad_r ltx_th ltx_th_column" id="S5.T2.9.6.1.8"></th>
<th class="ltx_td ltx_nopad_l ltx_th ltx_th_column" id="S5.T2.9.6.1.9"></th>
<td class="ltx_td" id="S5.T2.9.6.1.10"></td>
</tr>
<tr class="ltx_tr" id="S5.T2.9.7.2">
<td class="ltx_td ltx_align_left ltx_border_tt" id="S5.T2.9.7.2.1">Scenario 1</td>
<td class="ltx_td ltx_align_left ltx_border_tt" id="S5.T2.9.7.2.2">-1</td>
<td class="ltx_td ltx_align_left ltx_border_tt" id="S5.T2.9.7.2.3">False</td>
<td class="ltx_td ltx_align_left ltx_border_tt" id="S5.T2.9.7.2.4">1</td>
<td class="ltx_td ltx_align_left ltx_border_tt" id="S5.T2.9.7.2.5">0.018</td>
<td class="ltx_td ltx_align_right ltx_border_tt" id="S5.T2.9.7.2.6">0.002*</td>
<td class="ltx_td ltx_align_right ltx_border_tt" id="S5.T2.9.7.2.7">-32.285*</td>
<td class="ltx_td ltx_nopad_r ltx_border_tt" id="S5.T2.9.7.2.8"></td>
<td class="ltx_td ltx_nopad_l ltx_align_right ltx_border_tt" id="S5.T2.9.7.2.9">3.502</td>
<td class="ltx_td ltx_align_right ltx_border_tt" id="S5.T2.9.7.2.10">0.001</td>
</tr>
<tr class="ltx_tr" id="S5.T2.9.8.3">
<td class="ltx_td" id="S5.T2.9.8.3.1"></td>
<td class="ltx_td" id="S5.T2.9.8.3.2"></td>
<td class="ltx_td" id="S5.T2.9.8.3.3"></td>
<td class="ltx_td ltx_align_left" id="S5.T2.9.8.3.4">2</td>
<td class="ltx_td ltx_align_left" id="S5.T2.9.8.3.5">0.418</td>
<td class="ltx_td ltx_align_right" id="S5.T2.9.8.3.6">0.004*</td>
<td class="ltx_td ltx_align_right" id="S5.T2.9.8.3.7">21.252*</td>
<td class="ltx_td ltx_nopad_r" id="S5.T2.9.8.3.8"></td>
<td class="ltx_td ltx_nopad_l ltx_align_right" id="S5.T2.9.8.3.9">3.352</td>
<td class="ltx_td ltx_align_right" id="S5.T2.9.8.3.10">0.003</td>
</tr>
<tr class="ltx_tr" id="S5.T2.9.9.4">
<td class="ltx_td" id="S5.T2.9.9.4.1"></td>
<td class="ltx_td" id="S5.T2.9.9.4.2"></td>
<td class="ltx_td ltx_align_left" id="S5.T2.9.9.4.3">True</td>
<td class="ltx_td ltx_align_left" id="S5.T2.9.9.4.4">1</td>
<td class="ltx_td ltx_align_left" id="S5.T2.9.9.4.5">0.004</td>
<td class="ltx_td ltx_align_right" id="S5.T2.9.9.4.6">0.002*</td>
<td class="ltx_td ltx_align_right" id="S5.T2.9.9.4.7">-35.746*</td>
<td class="ltx_td ltx_nopad_r" id="S5.T2.9.9.4.8"></td>
<td class="ltx_td ltx_nopad_l ltx_align_right" id="S5.T2.9.9.4.9">3.337</td>
<td class="ltx_td ltx_align_right" id="S5.T2.9.9.4.10">0.001</td>
</tr>
<tr class="ltx_tr" id="S5.T2.9.10.5">
<td class="ltx_td" id="S5.T2.9.10.5.1"></td>
<td class="ltx_td ltx_align_left" id="S5.T2.9.10.5.2">0</td>
<td class="ltx_td ltx_align_left" id="S5.T2.9.10.5.3">False</td>
<td class="ltx_td ltx_align_left" id="S5.T2.9.10.5.4">1</td>
<td class="ltx_td ltx_align_left" id="S5.T2.9.10.5.5">0.101</td>
<td class="ltx_td ltx_align_right" id="S5.T2.9.10.5.6">0.003*</td>
<td class="ltx_td ltx_align_right" id="S5.T2.9.10.5.7">-12.827*</td>
<td class="ltx_td ltx_nopad_r" id="S5.T2.9.10.5.8"></td>
<td class="ltx_td ltx_nopad_l ltx_align_right" id="S5.T2.9.10.5.9">3.624</td>
<td class="ltx_td ltx_align_right" id="S5.T2.9.10.5.10">0.002</td>
</tr>
<tr class="ltx_tr" id="S5.T2.9.11.6">
<td class="ltx_td" id="S5.T2.9.11.6.1"></td>
<td class="ltx_td" id="S5.T2.9.11.6.2"></td>
<td class="ltx_td" id="S5.T2.9.11.6.3"></td>
<td class="ltx_td ltx_align_left" id="S5.T2.9.11.6.4">2</td>
<td class="ltx_td ltx_align_left" id="S5.T2.9.11.6.5"><span class="ltx_text ltx_font_bold" id="S5.T2.9.11.6.5.1">0.615</span></td>
<td class="ltx_td ltx_align_right" id="S5.T2.9.11.6.6"><span class="ltx_text ltx_font_bold" id="S5.T2.9.11.6.6.1">0.005</span></td>
<td class="ltx_td ltx_align_right" id="S5.T2.9.11.6.7"><span class="ltx_text ltx_font_bold" id="S5.T2.9.11.6.7.1">65.440</span></td>
<td class="ltx_td ltx_nopad_r" id="S5.T2.9.11.6.8"></td>
<td class="ltx_td ltx_nopad_l ltx_align_right" id="S5.T2.9.11.6.9">3.464</td>
<td class="ltx_td ltx_align_right" id="S5.T2.9.11.6.10">0.005</td>
</tr>
<tr class="ltx_tr" id="S5.T2.9.12.7">
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T2.9.12.7.1">Scenario 2</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T2.9.12.7.2">-1</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T2.9.12.7.3">False</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T2.9.12.7.4">1</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T2.9.12.7.5">0.596</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T2.9.12.7.6">0.021*</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T2.9.12.7.7">426.621*</td>
<td class="ltx_td ltx_nopad_r ltx_border_t" id="S5.T2.9.12.7.8"></td>
<td class="ltx_td ltx_nopad_l ltx_align_right ltx_border_t" id="S5.T2.9.12.7.9">1.188</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T2.9.12.7.10">0.019</td>
</tr>
<tr class="ltx_tr" id="S5.T2.9.13.8">
<td class="ltx_td" id="S5.T2.9.13.8.1"></td>
<td class="ltx_td" id="S5.T2.9.13.8.2"></td>
<td class="ltx_td" id="S5.T2.9.13.8.3"></td>
<td class="ltx_td ltx_align_left" id="S5.T2.9.13.8.4">2</td>
<td class="ltx_td ltx_align_left" id="S5.T2.9.13.8.5"><span class="ltx_text ltx_font_bold" id="S5.T2.9.13.8.5.1">0.614</span></td>
<td class="ltx_td ltx_align_right" id="S5.T2.9.13.8.6">0.022*</td>
<td class="ltx_td ltx_align_right" id="S5.T2.9.13.8.7">447.618*</td>
<td class="ltx_td ltx_nopad_r" id="S5.T2.9.13.8.8"></td>
<td class="ltx_td ltx_nopad_l ltx_align_right" id="S5.T2.9.13.8.9">1.190</td>
<td class="ltx_td ltx_align_right" id="S5.T2.9.13.8.10">0.021</td>
</tr>
<tr class="ltx_tr" id="S5.T2.9.14.9">
<td class="ltx_td" id="S5.T2.9.14.9.1"></td>
<td class="ltx_td" id="S5.T2.9.14.9.2"></td>
<td class="ltx_td ltx_align_left" id="S5.T2.9.14.9.3">True</td>
<td class="ltx_td ltx_align_left" id="S5.T2.9.14.9.4">1</td>
<td class="ltx_td ltx_align_left" id="S5.T2.9.14.9.5">0.604</td>
<td class="ltx_td ltx_align_right" id="S5.T2.9.14.9.6">0.015*</td>
<td class="ltx_td ltx_align_right" id="S5.T2.9.14.9.7">305.197*</td>
<td class="ltx_td ltx_nopad_r" id="S5.T2.9.14.9.8"></td>
<td class="ltx_td ltx_nopad_l ltx_align_right" id="S5.T2.9.14.9.9">1.150</td>
<td class="ltx_td ltx_align_right" id="S5.T2.9.14.9.10">0.013</td>
</tr>
<tr class="ltx_tr" id="S5.T2.9.15.10">
<td class="ltx_td" id="S5.T2.9.15.10.1"></td>
<td class="ltx_td ltx_align_left" id="S5.T2.9.15.10.2">0</td>
<td class="ltx_td ltx_align_left" id="S5.T2.9.15.10.3">False</td>
<td class="ltx_td ltx_align_left" id="S5.T2.9.15.10.4">1</td>
<td class="ltx_td ltx_align_left" id="S5.T2.9.15.10.5">0.552</td>
<td class="ltx_td ltx_align_right" id="S5.T2.9.15.10.6"><span class="ltx_text ltx_font_bold" id="S5.T2.9.15.10.6.1">0.027</span></td>
<td class="ltx_td ltx_align_right" id="S5.T2.9.15.10.7"><span class="ltx_text ltx_font_bold" id="S5.T2.9.15.10.7.1">632.300</span></td>
<td class="ltx_td ltx_nopad_r" id="S5.T2.9.15.10.8"></td>
<td class="ltx_td ltx_nopad_l ltx_align_right" id="S5.T2.9.15.10.9">1.040</td>
<td class="ltx_td ltx_align_right" id="S5.T2.9.15.10.10">0.023</td>
</tr>
<tr class="ltx_tr" id="S5.T2.9.16.11">
<td class="ltx_td" id="S5.T2.9.16.11.1"></td>
<td class="ltx_td" id="S5.T2.9.16.11.2"></td>
<td class="ltx_td" id="S5.T2.9.16.11.3"></td>
<td class="ltx_td ltx_align_left" id="S5.T2.9.16.11.4">2</td>
<td class="ltx_td ltx_align_left" id="S5.T2.9.16.11.5">0.562</td>
<td class="ltx_td ltx_align_right" id="S5.T2.9.16.11.6">0.027</td>
<td class="ltx_td ltx_align_right" id="S5.T2.9.16.11.7">591.966</td>
<td class="ltx_td ltx_nopad_r" id="S5.T2.9.16.11.8"></td>
<td class="ltx_td ltx_nopad_l ltx_align_right" id="S5.T2.9.16.11.9">1.026</td>
<td class="ltx_td ltx_align_right" id="S5.T2.9.16.11.10">0.025</td>
</tr>
<tr class="ltx_tr" id="S5.T2.9.17.12">
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T2.9.17.12.1">Scenario 3</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T2.9.17.12.2">-1</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T2.9.17.12.3">False</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T2.9.17.12.4">1</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T2.9.17.12.5">0.559</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T2.9.17.12.6">0.008*</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T2.9.17.12.7">187.197*</td>
<td class="ltx_td ltx_nopad_r ltx_border_t" id="S5.T2.9.17.12.8"></td>
<td class="ltx_td ltx_nopad_l ltx_align_right ltx_border_t" id="S5.T2.9.17.12.9">1.182</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T2.9.17.12.10">0.002</td>
</tr>
<tr class="ltx_tr" id="S5.T2.9.18.13">
<td class="ltx_td" id="S5.T2.9.18.13.1"></td>
<td class="ltx_td" id="S5.T2.9.18.13.2"></td>
<td class="ltx_td" id="S5.T2.9.18.13.3"></td>
<td class="ltx_td ltx_align_left" id="S5.T2.9.18.13.4">2</td>
<td class="ltx_td ltx_align_left" id="S5.T2.9.18.13.5"><span class="ltx_text ltx_font_bold" id="S5.T2.9.18.13.5.1">0.728</span></td>
<td class="ltx_td ltx_align_right" id="S5.T2.9.18.13.6"><span class="ltx_text ltx_font_bold" id="S5.T2.9.18.13.6.1">0.008</span></td>
<td class="ltx_td ltx_align_right" id="S5.T2.9.18.13.7"><span class="ltx_text ltx_font_bold" id="S5.T2.9.18.13.7.1">192.127</span></td>
<td class="ltx_td ltx_nopad_r" id="S5.T2.9.18.13.8"></td>
<td class="ltx_td ltx_nopad_l ltx_align_right" id="S5.T2.9.18.13.9">1.182</td>
<td class="ltx_td ltx_align_right" id="S5.T2.9.18.13.10">0.002</td>
</tr>
<tr class="ltx_tr" id="S5.T2.9.19.14">
<td class="ltx_td" id="S5.T2.9.19.14.1"></td>
<td class="ltx_td" id="S5.T2.9.19.14.2"></td>
<td class="ltx_td ltx_align_left" id="S5.T2.9.19.14.3">True</td>
<td class="ltx_td ltx_align_left" id="S5.T2.9.19.14.4">1</td>
<td class="ltx_td ltx_align_left" id="S5.T2.9.19.14.5">0.522</td>
<td class="ltx_td ltx_align_right" id="S5.T2.9.19.14.6">0.006*</td>
<td class="ltx_td ltx_align_right" id="S5.T2.9.19.14.7">151.686*</td>
<td class="ltx_td ltx_nopad_r" id="S5.T2.9.19.14.8"></td>
<td class="ltx_td ltx_nopad_l ltx_align_right" id="S5.T2.9.19.14.9">1.151</td>
<td class="ltx_td ltx_align_right" id="S5.T2.9.19.14.10">0.001</td>
</tr>
<tr class="ltx_tr" id="S5.T2.9.20.15">
<td class="ltx_td" id="S5.T2.9.20.15.1"></td>
<td class="ltx_td ltx_align_left" id="S5.T2.9.20.15.2">0</td>
<td class="ltx_td ltx_align_left" id="S5.T2.9.20.15.3">False</td>
<td class="ltx_td ltx_align_left" id="S5.T2.9.20.15.4">1</td>
<td class="ltx_td ltx_align_left" id="S5.T2.9.20.15.5">0.025</td>
<td class="ltx_td ltx_align_right" id="S5.T2.9.20.15.6">0.002*</td>
<td class="ltx_td ltx_align_right" id="S5.T2.9.20.15.7">-35.765*</td>
<td class="ltx_td ltx_nopad_r" id="S5.T2.9.20.15.8"></td>
<td class="ltx_td ltx_nopad_l ltx_align_right" id="S5.T2.9.20.15.9">1.044</td>
<td class="ltx_td ltx_align_right" id="S5.T2.9.20.15.10">0.001</td>
</tr>
<tr class="ltx_tr" id="S5.T2.9.21.16">
<td class="ltx_td" id="S5.T2.9.21.16.1"></td>
<td class="ltx_td" id="S5.T2.9.21.16.2"></td>
<td class="ltx_td" id="S5.T2.9.21.16.3"></td>
<td class="ltx_td ltx_align_left" id="S5.T2.9.21.16.4">2</td>
<td class="ltx_td ltx_align_left" id="S5.T2.9.21.16.5">0.161</td>
<td class="ltx_td ltx_align_right" id="S5.T2.9.21.16.6">0.003*</td>
<td class="ltx_td ltx_align_right" id="S5.T2.9.21.16.7">-13.100*</td>
<td class="ltx_td ltx_nopad_r" id="S5.T2.9.21.16.8"></td>
<td class="ltx_td ltx_nopad_l ltx_align_right" id="S5.T2.9.21.16.9">1.034</td>
<td class="ltx_td ltx_align_right" id="S5.T2.9.21.16.10">0.004</td>
</tr>
<tr class="ltx_tr" id="S5.T2.9.22.17">
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T2.9.22.17.1">Scenario 4</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T2.9.22.17.2">-1</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T2.9.22.17.3">False</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T2.9.22.17.4">1</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T2.9.22.17.5">0.253</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T2.9.22.17.6">0.003*</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T2.9.22.17.7">23.063*</td>
<td class="ltx_td ltx_nopad_r ltx_border_t" id="S5.T2.9.22.17.8"></td>
<td class="ltx_td ltx_nopad_l ltx_align_right ltx_border_t" id="S5.T2.9.22.17.9">2.502</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T2.9.22.17.10">0.001</td>
</tr>
<tr class="ltx_tr" id="S5.T2.9.23.18">
<td class="ltx_td" id="S5.T2.9.23.18.1"></td>
<td class="ltx_td" id="S5.T2.9.23.18.2"></td>
<td class="ltx_td" id="S5.T2.9.23.18.3"></td>
<td class="ltx_td ltx_align_left" id="S5.T2.9.23.18.4">2</td>
<td class="ltx_td ltx_align_left" id="S5.T2.9.23.18.5"><span class="ltx_text ltx_font_bold" id="S5.T2.9.23.18.5.1">0.772</span></td>
<td class="ltx_td ltx_align_right" id="S5.T2.9.23.18.6">0.006*</td>
<td class="ltx_td ltx_align_right" id="S5.T2.9.23.18.7">97.490*</td>
<td class="ltx_td ltx_nopad_r" id="S5.T2.9.23.18.8"></td>
<td class="ltx_td ltx_nopad_l ltx_align_right" id="S5.T2.9.23.18.9">2.404</td>
<td class="ltx_td ltx_align_right" id="S5.T2.9.23.18.10">0.004</td>
</tr>
<tr class="ltx_tr" id="S5.T2.9.24.19">
<td class="ltx_td" id="S5.T2.9.24.19.1"></td>
<td class="ltx_td" id="S5.T2.9.24.19.2"></td>
<td class="ltx_td ltx_align_left" id="S5.T2.9.24.19.3">True</td>
<td class="ltx_td ltx_align_left" id="S5.T2.9.24.19.4">1</td>
<td class="ltx_td ltx_align_left" id="S5.T2.9.24.19.5">0.184</td>
<td class="ltx_td ltx_align_right" id="S5.T2.9.24.19.6">0.003*</td>
<td class="ltx_td ltx_align_right" id="S5.T2.9.24.19.7">8.669*</td>
<td class="ltx_td ltx_nopad_r" id="S5.T2.9.24.19.8"></td>
<td class="ltx_td ltx_nopad_l ltx_align_right" id="S5.T2.9.24.19.9">2.458</td>
<td class="ltx_td ltx_align_right" id="S5.T2.9.24.19.10">0.001</td>
</tr>
<tr class="ltx_tr" id="S5.T2.9.25.20">
<td class="ltx_td" id="S5.T2.9.25.20.1"></td>
<td class="ltx_td ltx_align_left" id="S5.T2.9.25.20.2">0</td>
<td class="ltx_td ltx_align_left" id="S5.T2.9.25.20.3">False</td>
<td class="ltx_td ltx_align_left" id="S5.T2.9.25.20.4">1</td>
<td class="ltx_td ltx_align_left" id="S5.T2.9.25.20.5">0.588</td>
<td class="ltx_td ltx_align_right" id="S5.T2.9.25.20.6">0.008*</td>
<td class="ltx_td ltx_align_right" id="S5.T2.9.25.20.7">164.549*</td>
<td class="ltx_td ltx_nopad_r" id="S5.T2.9.25.20.8"></td>
<td class="ltx_td ltx_nopad_l ltx_align_right" id="S5.T2.9.25.20.9">2.500</td>
<td class="ltx_td ltx_align_right" id="S5.T2.9.25.20.10">0.004</td>
</tr>
<tr class="ltx_tr" id="S5.T2.9.26.21">
<td class="ltx_td" id="S5.T2.9.26.21.1"></td>
<td class="ltx_td" id="S5.T2.9.26.21.2"></td>
<td class="ltx_td" id="S5.T2.9.26.21.3"></td>
<td class="ltx_td ltx_align_left" id="S5.T2.9.26.21.4">2</td>
<td class="ltx_td ltx_align_left" id="S5.T2.9.26.21.5">0.701</td>
<td class="ltx_td ltx_align_right" id="S5.T2.9.26.21.6"><span class="ltx_text ltx_font_bold" id="S5.T2.9.26.21.6.1">0.014</span></td>
<td class="ltx_td ltx_align_right" id="S5.T2.9.26.21.7"><span class="ltx_text ltx_font_bold" id="S5.T2.9.26.21.7.1">297.047</span></td>
<td class="ltx_td ltx_nopad_r" id="S5.T2.9.26.21.8"></td>
<td class="ltx_td ltx_nopad_l ltx_align_right" id="S5.T2.9.26.21.9">2.386</td>
<td class="ltx_td ltx_align_right" id="S5.T2.9.26.21.10">0.010</td>
</tr>
<tr class="ltx_tr" id="S5.T2.9.27.22">
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T2.9.27.22.1">Scenario 5</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T2.9.27.22.2">-1</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T2.9.27.22.3">False</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T2.9.27.22.4">1</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T2.9.27.22.5">0.087</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T2.9.27.22.6">0.003*</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T2.9.27.22.7">-7.924*</td>
<td class="ltx_td ltx_nopad_r ltx_border_t" id="S5.T2.9.27.22.8"></td>
<td class="ltx_td ltx_nopad_l ltx_align_right ltx_border_t" id="S5.T2.9.27.22.9">2.880</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T2.9.27.22.10">0.001</td>
</tr>
<tr class="ltx_tr" id="S5.T2.9.28.23">
<td class="ltx_td" id="S5.T2.9.28.23.1"></td>
<td class="ltx_td" id="S5.T2.9.28.23.2"></td>
<td class="ltx_td" id="S5.T2.9.28.23.3"></td>
<td class="ltx_td ltx_align_left" id="S5.T2.9.28.23.4">2</td>
<td class="ltx_td ltx_align_left" id="S5.T2.9.28.23.5"><span class="ltx_text ltx_font_bold" id="S5.T2.9.28.23.5.1">0.623</span></td>
<td class="ltx_td ltx_align_right" id="S5.T2.9.28.23.6">0.005*</td>
<td class="ltx_td ltx_align_right" id="S5.T2.9.28.23.7"><span class="ltx_text ltx_font_bold" id="S5.T2.9.28.23.7.1">57.969</span></td>
<td class="ltx_td ltx_nopad_r" id="S5.T2.9.28.23.8"></td>
<td class="ltx_td ltx_nopad_l ltx_align_right" id="S5.T2.9.28.23.9">2.776</td>
<td class="ltx_td ltx_align_right" id="S5.T2.9.28.23.10">0.003</td>
</tr>
<tr class="ltx_tr" id="S5.T2.9.29.24">
<td class="ltx_td" id="S5.T2.9.29.24.1"></td>
<td class="ltx_td" id="S5.T2.9.29.24.2"></td>
<td class="ltx_td ltx_align_left" id="S5.T2.9.29.24.3">True</td>
<td class="ltx_td ltx_align_left" id="S5.T2.9.29.24.4">1</td>
<td class="ltx_td ltx_align_left" id="S5.T2.9.29.24.5">0.057</td>
<td class="ltx_td ltx_align_right" id="S5.T2.9.29.24.6">0.002*</td>
<td class="ltx_td ltx_align_right" id="S5.T2.9.29.24.7">-16.243*</td>
<td class="ltx_td ltx_nopad_r" id="S5.T2.9.29.24.8"></td>
<td class="ltx_td ltx_nopad_l ltx_align_right" id="S5.T2.9.29.24.9">2.783</td>
<td class="ltx_td ltx_align_right" id="S5.T2.9.29.24.10">0.001</td>
</tr>
<tr class="ltx_tr" id="S5.T2.9.30.25">
<td class="ltx_td" id="S5.T2.9.30.25.1"></td>
<td class="ltx_td ltx_align_left" id="S5.T2.9.30.25.2">0</td>
<td class="ltx_td ltx_align_left" id="S5.T2.9.30.25.3">False</td>
<td class="ltx_td ltx_align_left" id="S5.T2.9.30.25.4">1</td>
<td class="ltx_td ltx_align_left" id="S5.T2.9.30.25.5">0.136</td>
<td class="ltx_td ltx_align_right" id="S5.T2.9.30.25.6">0.003*</td>
<td class="ltx_td ltx_align_right" id="S5.T2.9.30.25.7">-16.122*</td>
<td class="ltx_td ltx_nopad_r" id="S5.T2.9.30.25.8"></td>
<td class="ltx_td ltx_nopad_l ltx_align_right" id="S5.T2.9.30.25.9">2.914</td>
<td class="ltx_td ltx_align_right" id="S5.T2.9.30.25.10">0.003</td>
</tr>
<tr class="ltx_tr" id="S5.T2.9.31.26">
<td class="ltx_td ltx_border_bb ltx_border_bb" id="S5.T2.9.31.26.1"></td>
<td class="ltx_td ltx_border_bb ltx_border_bb" id="S5.T2.9.31.26.2"></td>
<td class="ltx_td ltx_border_bb ltx_border_bb" id="S5.T2.9.31.26.3"></td>
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_bb" id="S5.T2.9.31.26.4">2</td>
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_bb" id="S5.T2.9.31.26.5">0.612</td>
<td class="ltx_td ltx_align_right ltx_border_bb ltx_border_bb" id="S5.T2.9.31.26.6"><span class="ltx_text ltx_font_bold" id="S5.T2.9.31.26.6.1">0.005</span></td>
<td class="ltx_td ltx_align_right ltx_border_bb ltx_border_bb" id="S5.T2.9.31.26.7">42.849</td>
<td class="ltx_td ltx_nopad_r ltx_border_bb ltx_border_bb" id="S5.T2.9.31.26.8"></td>
<td class="ltx_td ltx_nopad_l ltx_align_right ltx_border_bb ltx_border_bb" id="S5.T2.9.31.26.9">2.794</td>
<td class="ltx_td ltx_align_right ltx_border_bb ltx_border_bb" id="S5.T2.9.31.26.10">0.006</td>
</tr>
</tbody>
</table>
</figure>
<div class="ltx_para" id="S5.p2">
<p class="ltx_p" id="S5.p2.1">Performance varies across the data scenarios.
RMSE specifically is lower for scenarios <a class="ltx_ref" href="https://arxiv.org/html/2409.08046v1#S3.I1.i2" title="item 2 ‣ Data Scenarios ‣ 3.1. Data Characteristics ‣ 3. Identifying Data Characteristics and Algorithm Configurations ‣ On the challenges of studying bias in Recommender Systems: A UserKNN case study"><span class="ltx_text ltx_ref_tag">2</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2409.08046v1#S3.I1.i3" title="item 3 ‣ Data Scenarios ‣ 3.1. Data Characteristics ‣ 3. Identifying Data Characteristics and Algorithm Configurations ‣ On the challenges of studying bias in Recommender Systems: A UserKNN case study"><span class="ltx_text ltx_ref_tag">3</span></a> compared to the other three.
In these two scenarios, users tend to agree between them on whether they like popular items or not, which facilitates the rating prediction task.
NDCG@10 is the highest for scenario <a class="ltx_ref" href="https://arxiv.org/html/2409.08046v1#S3.I1.i2" title="item 2 ‣ Data Scenarios ‣ 3.1. Data Characteristics ‣ 3. Identifying Data Characteristics and Algorithm Configurations ‣ On the challenges of studying bias in Recommender Systems: A UserKNN case study"><span class="ltx_text ltx_ref_tag">2</span></a>, where popular items are highly rated by the users.
In this case, the rating prediction and ranking tasks are linked, since the highest ranked (i.e., popular items) are also highly rated.</p>
</div>
<div class="ltx_para" id="S5.p3">
<p class="ltx_p" id="S5.p3.1">Popularity bias also varies across the data scenarios, and the effect depends on the algorithm configuration.
In the following paragraphs, we describe and reflect on the most impactful effects of the interaction between data and configuration.</p>
</div>
<div class="ltx_para" id="S5.p4">
<p class="ltx_p" id="S5.p4.1">For scenario <a class="ltx_ref" href="https://arxiv.org/html/2409.08046v1#S3.I1.i1" title="item 1 ‣ Data Scenarios ‣ 3.1. Data Characteristics ‣ 3. Identifying Data Characteristics and Algorithm Configurations ‣ On the challenges of studying bias in Recommender Systems: A UserKNN case study"><span class="ltx_text ltx_ref_tag">1</span></a> where ratings are uniformly at random generated, there is no notable popularity bias propagation observed when minimum neighbours are set to 1, while there is bias when minimum neighbours is set to 2.
Increasing minimum neighbours results in higher popularity bias for all datasets and metrics.</p>
</div>
<div class="ltx_para" id="S5.p5">
<p class="ltx_p" id="S5.p5.1">In scenario <a class="ltx_ref" href="https://arxiv.org/html/2409.08046v1#S3.I1.i3" title="item 3 ‣ Data Scenarios ‣ 3.1. Data Characteristics ‣ 3. Identifying Data Characteristics and Algorithm Configurations ‣ On the challenges of studying bias in Recommender Systems: A UserKNN case study"><span class="ltx_text ltx_ref_tag">3</span></a> where all users agree that popular items are bad, popularity bias is not propagated when minimum similarity is set to 0.
However, when setting minimum similarity to -1, we can observe popularity bias propagation across all metrics.
The reason is that users with completely different opinions are considered and their opinions count negatively.
Therefore, popular items still get recommended since everyone’s “negative” neighbours dislike them, and we can observe popularity bias propagation across all metrics.</p>
</div>
<div class="ltx_para" id="S5.p6">
<p class="ltx_p" id="S5.p6.1">When considering only common items to calculate similarity, users with smaller profiles have a larger influence.
This is relevant in scenario <a class="ltx_ref" href="https://arxiv.org/html/2409.08046v1#S3.I1.i4" title="item 4 ‣ Data Scenarios ‣ 3.1. Data Characteristics ‣ 3. Identifying Data Characteristics and Algorithm Configurations ‣ On the challenges of studying bias in Recommender Systems: A UserKNN case study"><span class="ltx_text ltx_ref_tag">4</span></a> where users with large profiles like popular items.
Table <a class="ltx_ref" href="https://arxiv.org/html/2409.08046v1#S5.T2" title="Table 2 ‣ 5. Results ‣ On the challenges of studying bias in Recommender Systems: A UserKNN case study"><span class="ltx_text ltx_ref_tag">2</span></a> shows that even though scenario <a class="ltx_ref" href="https://arxiv.org/html/2409.08046v1#S3.I1.i4" title="item 4 ‣ Data Scenarios ‣ 3.1. Data Characteristics ‣ 3. Identifying Data Characteristics and Algorithm Configurations ‣ On the challenges of studying bias in Recommender Systems: A UserKNN case study"><span class="ltx_text ltx_ref_tag">4</span></a> still leads to popularity bias, considering only common items reduces it across all metrics.
Therefore, this implementation choice can have a big impact on whether popularity bias is propagated and to what extent.</p>
</div>
<div class="ltx_para" id="S5.p7">
<p class="ltx_p" id="S5.p7.1">Finally, the value for minimum neighbours largely influences popularity bias.
Across almost all scenarios and metrics, increasing minimum neighbours from 1 to 2 leads to increased popularity bias.
By setting a higher neighbour barrier for considering an item for recommendation, it follows that less popular items will be disadvantaged.
This result is particularly relevant given that the parameter of minimum neighbours could only be tweaked
in one of the considered frameworks.
Thus,
studies that use Cornac or LensKit might reach different conclusions on the extent of popularity bias propagated by UserKNN.</p>
</div>
<div class="ltx_para" id="S5.p8">
<p class="ltx_p" id="S5.p8.1"><em class="ltx_emph ltx_font_italic" id="S5.p8.1.1">The above results show that configuration has a significant effect on whether or not popularity bias is observed. All three UserKNN configuration choices affect the observed bias. This effect is different for different data scenarios, with some configurations leading to low popularity bias on one dataset while leading to high popularity bias on another dataset. </em></p>
</div>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6. </span>Discussion</h2>
<section class="ltx_subsubsection" id="S6.SS0.SSSx1">
<h4 class="ltx_title ltx_title_subsubsection">Implications of the present study</h4>
<div class="ltx_para" id="S6.SS0.SSSx1.p1">
<p class="ltx_p" id="S6.SS0.SSSx1.p1.1">Our research shows that multiple data and configuration factors can have an effect on whether bias is propagated.
Relying on frameworks readily available to researchers is convenient and a concrete step towards reproducibility, but requires being aware and detailed about the limitations.
When simple parameters, such as minimum neighbours in UserKNN, are so influential, it raises questions on how generalizable research on recommender systems bias can be.
Our results indicate that bias studies can only draw conclusions within the limits of their specific research and not further than that.
It follows that being explicit about the context within which a type of bias is studied is crucial, both in terms of data characteristics and implementation.
It is a known issue in recommender systems literature that implementation details are often not disclosed by studies.
Even in cases where they are, guessing the effect of different hyperparameters that are not present in an implementation or experimented with is not trivial.
Bias reporting is definitely not complete if it is not accompanied by clarity around the characteristics, goals and limitations of the system that is being studied.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S6.SS0.SSSx2">
<h4 class="ltx_title ltx_title_subsubsection">Recommendations of the present study</h4>
<div class="ltx_para" id="S6.SS0.SSSx2.p1">
<p class="ltx_p" id="S6.SS0.SSSx2.p1.1">Based on the results of the present study, we have come up with two recommendations towards researchers who study bias in recommender systems.</p>
</div>
<div class="ltx_para" id="S6.SS0.SSSx2.p2">
<p class="ltx_p" id="S6.SS0.SSSx2.p2.1">First, researchers should analyze and report on the dataset characteristics that might impact the type of bias they are concerned with.
For UserKNN, the relationship between rating and popularity, as well as the preferences of users with large profiles impact popularity bias and should be taken into account in relevant studies.
For other algorithms and types of bias, there could be other relevant characteristics.
Such analysis will help the reader understand the extent to which the results are a result of the dataset characteristics.</p>
</div>
<div class="ltx_para" id="S6.SS0.SSSx2.p3">
<p class="ltx_p" id="S6.SS0.SSSx2.p3.1">Second, researchers should test multiple algorithm configurations when measuring bias propagation.
In a similar way that the community expects x-fold cross validation, since presenting the results of only one run may not be reliable, we could expect to see results on multiple algorithm configurations as well.
If the conclusions are only valid for one specific configuration of the algorithm at hand, then that should be clear in the limitations of the study.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S6.SS0.SSSx3">
<h4 class="ltx_title ltx_title_subsubsection">Limitations of the present study</h4>
<div class="ltx_para" id="S6.SS0.SSSx3.p1">
<p class="ltx_p" id="S6.SS0.SSSx3.p1.1">Despite our extensive testing, the results are potentially sensitive to our own experimental design, such as the method for train-test splitting or randomness in the data generation process.
Similarly, instantiating the two UserKNN implementations with the exact same configuration choices is not possible due to some of the parameters not being configurable.
As a result, there might be implementation differences between the frameworks that we are not aware of and cause part of the variation in results, irrespectively of the configurations tested.
However, these observations highlight the importance of this line of research instead of hindering it, since they hint that data and implementation dependence might be present more often than we think.
Additionally, we recognize that the scholar community has generally moved on from explicit user preferences.
We do not focus on implicit feedback given that recent studies on popularity bias are often performed on datasets with explicit ratings in the context of rating prediction tasks <cite class="ltx_cite ltx_citemacro_citep">(Abdollahpouri et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08046v1#bib.bib6" title="">2019b</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08046v1#bib.bib7" title="">2020</a>; Kowald et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08046v1#bib.bib22" title="">2020</a>)</cite>.
Our goal is to show that conclusions in literature on the topic of popularity bias propagation can be volatile and require further scrutiny when it comes to their dependence on implementation and data domain.
Future work can focus on components that we chose not to investigate in this study, such as more advanced algorithms and other open libraries for implementation.
Further nuance can be introduced in the data synthesis part, by allowing for more complex relationships between popularity, rating and user influence.
Finally, a similar approach could be used to investigate other known biases in recommender systems.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S7">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7. </span>Conclusion</h2>
<div class="ltx_para" id="S7.p1">
<p class="ltx_p" id="S7.p1.1">In this study, we reflected on the need for fundamental understanding of the relationship between data, algorithms and bias in recommender systems.
We focused on reporting on popularity bias propagated by UserKNN , and tracked configurations and data characteristics that are of importance in its propagation.
Accordingly, we generated a set of synthetic datasets, experimented with performing a recommendation process on them using different configurations of UserKNN, and evaluated popularity bias using well-known metrics.
We found that even when the distribution of popularity in the dataset is long-tail, popularity bias is not unavoidable.
We showed that the relationship between popularity and rating, as well as the preferences of users with big profiles largely impacts bias.
We highlighted the sensitivity of bias propagation to algorithm configuration and, by extension, framework implementation.
Our observations point to methodology and reproducibility issues that extend further than a specific use case, to the recommender systems field at large.</p>
</div>
<div class="ltx_para" id="S7.p2">
<p class="ltx_p" id="S7.p2.1">Recommender systems are widely used in our online lives, and bias propagation by such systems can have serious societal impact.
With this work, we hope to have called attention to the ambiguity in bias reporting and motivated researchers to strive for reproducibility and highlight specificity when appropriate.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(1)</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Abdollahpouri (2020)</span>
<span class="ltx_bibblock">
Himan Abdollahpouri. 2020.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">Popularity bias in recommendation: a multi-stakeholder perspective</em>.

</span>
<span class="ltx_bibblock">Ph. D. Dissertation. University of Colorado at Boulder.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Abdollahpouri et al<span class="ltx_text" id="bib.bib3.2.2.1">.</span> (2017)</span>
<span class="ltx_bibblock">
Himan Abdollahpouri, Robin Burke, and Bamshad Mobasher. 2017.

</span>
<span class="ltx_bibblock">Controlling popularity bias in learning-to-rank recommendation. In <em class="ltx_emph ltx_font_italic" id="bib.bib3.3.1">Proceedings of the 11th ACM conference on recommender systems</em>. 42–46.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Abdollahpouri et al<span class="ltx_text" id="bib.bib4.2.2.1">.</span> (2019a)</span>
<span class="ltx_bibblock">
Himan Abdollahpouri, Robin Burke, and Bamshad Mobasher. 2019a.

</span>
<span class="ltx_bibblock">Managing popularity bias in recommender systems with personalized re-ranking.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib4.3.1">arXiv preprint arXiv:1901.07555</em> (2019).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Abdollahpouri and Mansoury (2020)</span>
<span class="ltx_bibblock">
Himan Abdollahpouri and Masoud Mansoury. 2020.

</span>
<span class="ltx_bibblock">Multi-sided Exposure Bias in Recommendation.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:2006.15772 [cs.IR]

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Abdollahpouri et al<span class="ltx_text" id="bib.bib6.2.2.1">.</span> (2019b)</span>
<span class="ltx_bibblock">
Himan Abdollahpouri, Masoud Mansoury, Robin Burke, and Bamshad Mobasher. 2019b.

</span>
<span class="ltx_bibblock">The Unfairness of Popularity Bias in Recommendation. In <em class="ltx_emph ltx_font_italic" id="bib.bib6.3.1">Recommendation in Multi-stakeholder Environments (RMSE), in conjunction with the 13th ACM Conference on Recommender Systems</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Abdollahpouri et al<span class="ltx_text" id="bib.bib7.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Himan Abdollahpouri, Masoud Mansoury, Robin Burke, and Bamshad Mobasher. 2020.

</span>
<span class="ltx_bibblock">The connection between popularity bias, calibration, and fairness in recommendation. In <em class="ltx_emph ltx_font_italic" id="bib.bib7.3.1">Proceedings of the 14th ACM Conference on Recommender Systems</em>. 726–731.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Aggarwal et al<span class="ltx_text" id="bib.bib8.2.2.1">.</span> (2016)</span>
<span class="ltx_bibblock">
Charu C Aggarwal et al<span class="ltx_text" id="bib.bib8.3.1">.</span> 2016.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib8.4.1">Recommender systems</em>. Vol. 1.

</span>
<span class="ltx_bibblock">Springer.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ahanger et al<span class="ltx_text" id="bib.bib9.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Abdul Basit Ahanger, Syed Wajid Aalam, Muzafar Rasool Bhat, and Assif Assad. 2022.

</span>
<span class="ltx_bibblock">Popularity bias in recommender systems-a review. In <em class="ltx_emph ltx_font_italic" id="bib.bib9.3.1">International Conference on Emerging Technologies in Computer Engineering</em>. Springer, 431–444.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bobadilla et al<span class="ltx_text" id="bib.bib10.2.2.1">.</span> (2013)</span>
<span class="ltx_bibblock">
Jesús Bobadilla, Fernando Ortega, Antonio Hernando, and Abraham Gutiérrez. 2013.

</span>
<span class="ltx_bibblock">Recommender systems survey.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib10.3.1">Knowledge-based systems</em> 46 (2013), 109–132.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brynjolfsson et al<span class="ltx_text" id="bib.bib11.2.2.1">.</span> (2006)</span>
<span class="ltx_bibblock">
Erik Brynjolfsson, Yu Jeffrey Hu, and Michael D Smith. 2006.

</span>
<span class="ltx_bibblock">From niches to riches: Anatomy of the long tail.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib11.3.1">Sloan management review</em> 47, 4 (2006), 67–71.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Celma and Cano (2008)</span>
<span class="ltx_bibblock">
Òscar Celma and Pedro Cano. 2008.

</span>
<span class="ltx_bibblock">From hits to niches? or how popular artists can bias music recommendation and discovery. In <em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">Proceedings of the 2nd KDD Workshop on Large-Scale Recommender Systems and the Netflix Prize Competition</em>. 1–8.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al<span class="ltx_text" id="bib.bib13.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Jiawei Chen, Hande Dong, Xiang Wang, Fuli Feng, Meng Wang, and Xiangnan He. 2023.

</span>
<span class="ltx_bibblock">Bias and Debias in Recommender System: A Survey and Future Directions.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib13.3.1">ACM Transaction on Information System</em> 41, 3, Article 67 (2023), 39 pages.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cremonesi and Jannach (2021)</span>
<span class="ltx_bibblock">
Paolo Cremonesi and Dietmar Jannach. 2021.

</span>
<span class="ltx_bibblock">Progress in recommender systems research: Crisis? What crisis?

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">AI Magazine</em> 42, 3 (2021), 43–54.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Daniil et al<span class="ltx_text" id="bib.bib15.2.2.1">.</span> (2024)</span>
<span class="ltx_bibblock">
Savvina Daniil, Mirjam Cuper, Cynthia CS Liem, Jacco van Ossenbruggen, and Laura Hollink. 2024.

</span>
<span class="ltx_bibblock">Reproducing popularity bias in recommendation: The effect of evaluation strategies.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib15.3.1">ACM Transactions on Recommender Systems</em> 2, 1 (2024), 1–39.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Edizel et al<span class="ltx_text" id="bib.bib16.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Bora Edizel, Francesco Bonchi, Sara Hajian, André Panisson, and Tamir Tassa. 2019.

</span>
<span class="ltx_bibblock">FaiRecSys: Mitigating algorithmic bias in Recommender Systems.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib16.3.1">International Journal of Data Science and Analytics</em> 9, 2 (2019), 197–213.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ekstrand (2020)</span>
<span class="ltx_bibblock">
Michael D Ekstrand. 2020.

</span>
<span class="ltx_bibblock">Lenskit for python: Next-generation software for recommender systems experiments. In <em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">Proceedings of the 29th ACM international conference on information &amp; knowledge management</em>. 2999–3006.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Elahi et al<span class="ltx_text" id="bib.bib18.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Mehdi Elahi, Danial Khosh Kholgh, Mohammad Sina Kiarostami, Sorush Saghari, Shiva Parsa Rad, and Marko Tkalčič. 2021.

</span>
<span class="ltx_bibblock">Investigating the impact of recommender systems on user-based and item-based popularity bias.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib18.3.1">Information Processing &amp; Management</em> 58, 5 (2021), 102655.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ferrari Dacrema et al<span class="ltx_text" id="bib.bib19.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Maurizio Ferrari Dacrema, Simone Boglio, Paolo Cremonesi, and Dietmar Jannach. 2021.

</span>
<span class="ltx_bibblock">A troubling analysis of reproducibility and progress in recommender systems research.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib19.3.1">ACM Transactions on Information Systems (TOIS)</em> 39, 2 (2021), 1–49.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ferrari Dacrema et al<span class="ltx_text" id="bib.bib20.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Maurizio Ferrari Dacrema, Paolo Cremonesi, and Dietmar Jannach. 2019.

</span>
<span class="ltx_bibblock">Are we really making much progress? A worrying analysis of recent neural recommendation approaches. In <em class="ltx_emph ltx_font_italic" id="bib.bib20.3.1">Proceedings of the 13th ACM conference on recommender systems</em>. 101–109.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Khusro et al<span class="ltx_text" id="bib.bib21.2.2.1">.</span> (2016)</span>
<span class="ltx_bibblock">
Shah Khusro, Zafar Ali, and Irfan Ullah. 2016.

</span>
<span class="ltx_bibblock">Recommender systems: issues, challenges, and research opportunities. In <em class="ltx_emph ltx_font_italic" id="bib.bib21.3.1">Information science and applications</em>. Springer, 1179–1189.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kowald et al<span class="ltx_text" id="bib.bib22.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Dominik Kowald, Markus Schedl, and Elisabeth Lex. 2020.

</span>
<span class="ltx_bibblock">The unfairness of popularity bias in music recommendation: A reproducibility study. In <em class="ltx_emph ltx_font_italic" id="bib.bib22.3.1">Advances in Information Retrieval: 42nd European Conference on IR Research, ECIR, Lisbon, Portugal, Proceedings, Part II 42</em>. Springer, 35–42.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Naghiaei et al<span class="ltx_text" id="bib.bib23.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Mohammadmehdi Naghiaei, Hossein A Rahmani, and Mahdi Dehghan. 2022.

</span>
<span class="ltx_bibblock">The unfairness of popularity bias in book recommendation. In <em class="ltx_emph ltx_font_italic" id="bib.bib23.3.1">Advances in Bias and Fairness in Information Retrieval: Third International Workshop, BIAS 2022, Stavanger, Norway, Revised Selected Papers</em>. Springer, 69–81.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Said and Bellogín (2014)</span>
<span class="ltx_bibblock">
Alan Said and Alejandro Bellogín. 2014.

</span>
<span class="ltx_bibblock">Comparative recommender system evaluation: benchmarking recommendation frameworks. In <em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">Proceedings of the 8th ACM Conference on Recommender systems</em>. 129–136.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Salah et al<span class="ltx_text" id="bib.bib25.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Aghiles Salah, Quoc-Tuan Truong, and Hady W Lauw. 2020.

</span>
<span class="ltx_bibblock">Cornac: A comparative framework for multimodal recommender systems.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib25.3.1">The Journal of Machine Learning Research</em> 21, 1 (2020), 3803–3807.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Slokom (2018)</span>
<span class="ltx_bibblock">
Manel Slokom. 2018.

</span>
<span class="ltx_bibblock">Comparing recommender systems using synthetic data. In <em class="ltx_emph ltx_font_italic" id="bib.bib26.1.1">Proceedings of the 12th ACM Conference on Recommender Systems</em>. 548–552.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tso and Schmidt-Thieme (2006)</span>
<span class="ltx_bibblock">
Karen HL Tso and Lars Schmidt-Thieme. 2006.

</span>
<span class="ltx_bibblock">Empirical analysis of attribute-aware recommender system algorithms using synthetic data.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">Journal of Computers</em> 1, 4 (2006), 18–29.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al<span class="ltx_text" id="bib.bib28.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Yifan Wang, Weizhi Ma, Min Zhang, Yiqun Liu, and Shaoping Ma. 2023.

</span>
<span class="ltx_bibblock">A survey on the fairness of recommender systems.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib28.3.1">ACM Transactions on Information Systems</em> 41, 3 (2023), 1–43.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yalcin (2021)</span>
<span class="ltx_bibblock">
Emre Yalcin. 2021.

</span>
<span class="ltx_bibblock">Blockbuster: A new perspective on popularity-bias in recommender systems. In <em class="ltx_emph ltx_font_italic" id="bib.bib29.1.1">2021 6th International Conference on Computer Science and Engineering (UBMK)</em>. IEEE, 107–112.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yin et al<span class="ltx_text" id="bib.bib30.2.2.1">.</span> (2012)</span>
<span class="ltx_bibblock">
Hongzhi Yin, Bin Cui, Jing Li, Junjie Yao, and Chen Chen. 2012.

</span>
<span class="ltx_bibblock">Challenging the long tail recommendation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib30.3.1">Proceedings of the 38th International Conference on Very Large Data Bases (VLDB Endowment)</em> 5, 9 (2012), 896–907.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao et al<span class="ltx_text" id="bib.bib31.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Zihao Zhao, Jiawei Chen, Sheng Zhou, Xiangnan He, Xuezhi Cao, Fuzheng Zhang, and Wei Wu. 2022.

</span>
<span class="ltx_bibblock">Popularity bias is not always evil: Disentangling benign and harmful bias for recommendation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib31.3.1">IEEE Transactions on Knowledge and Data Engineering</em> (2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ziegler et al<span class="ltx_text" id="bib.bib32.2.2.1">.</span> (2005)</span>
<span class="ltx_bibblock">
Cai-Nicolas Ziegler, Sean M McNee, Joseph A Konstan, and Georg Lausen. 2005.

</span>
<span class="ltx_bibblock">Improving recommendation lists through topic diversification. In <em class="ltx_emph ltx_font_italic" id="bib.bib32.3.1">Proceedings of the 14th international conference on World Wide Web</em>. 22–32.

</span>
<span class="ltx_bibblock">
</span>
</li>
</ul>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Thu Sep 12 13:45:01 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
