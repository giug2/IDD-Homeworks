<article class="ltx_document ltx_authors_1line">
 <h1 class="ltx_title ltx_title_document">
  DriveMLM: Aligning Multi-Modal Large Language Models with
  <br class="ltx_break"/>
  Behavioral Planning States for Autonomous Driving
 </h1>
 <div class="ltx_authors">
  <span class="ltx_creator ltx_role_author">
   <span class="ltx_personname">
    Wenhai Wang
    <sup class="ltx_sup" id="id23.23.id1">
     <span class="ltx_text ltx_font_italic" id="id23.23.id1.1">
      2,1∗
     </span>
    </sup>
    , Jiangwei Xie
    <sup class="ltx_sup" id="id24.24.id2">
     <span class="ltx_text ltx_font_italic" id="id24.24.id2.1">
      3∗
     </span>
    </sup>
    , ChuanYang Hu
    <sup class="ltx_sup" id="id25.25.id3">
     <span class="ltx_text ltx_font_italic" id="id25.25.id3.1">
      3∗
     </span>
    </sup>
    , Haoming Zou
    <sup class="ltx_sup" id="id26.26.id4">
     <span class="ltx_text ltx_font_italic" id="id26.26.id4.1">
      4∗
     </span>
    </sup>
    , Jianan Fan
    <sup class="ltx_sup" id="id27.27.id5">
     <span class="ltx_text ltx_font_italic" id="id27.27.id5.1">
      3∗
     </span>
    </sup>
    ,
Wenwen Tong
    <sup class="ltx_sup" id="id28.28.id6">
     <span class="ltx_text ltx_font_italic" id="id28.28.id6.1">
      3∗
     </span>
    </sup>
    ,
    <br class="ltx_break"/>
    Yang Wen
    <sup class="ltx_sup" id="id29.29.id7">
     <span class="ltx_text ltx_font_italic" id="id29.29.id7.1">
      3∗
     </span>
    </sup>
    , Silei Wu
    <sup class="ltx_sup" id="id30.30.id8">
     <span class="ltx_text ltx_font_italic" id="id30.30.id8.1">
      3∗
     </span>
    </sup>
    , Hanming Deng
    <sup class="ltx_sup" id="id31.31.id9">
     <span class="ltx_text ltx_font_italic" id="id31.31.id9.1">
      3∗
     </span>
    </sup>
    , Zhiqi Li
    <sup class="ltx_sup" id="id32.32.id10">
     <span class="ltx_text ltx_font_italic" id="id32.32.id10.1">
      5,1∗
     </span>
    </sup>
    , Hao Tian
    <sup class="ltx_sup" id="id33.33.id11">
     <span class="ltx_text ltx_font_italic" id="id33.33.id11.1">
      3
     </span>
    </sup>
    , Lewei Lu
    <sup class="ltx_sup" id="id34.34.id12">
     <span class="ltx_text ltx_font_italic" id="id34.34.id12.1">
      3
     </span>
    </sup>
    , Xizhou Zhu
    <sup class="ltx_sup" id="id35.35.id13">
     <span class="ltx_text ltx_font_italic" id="id35.35.id13.1">
      6,3
     </span>
    </sup>
    ,
    <br class="ltx_break"/>
    Xiaogang Wang
    <sup class="ltx_sup" id="id36.36.id14">
     <span class="ltx_text ltx_font_italic" id="id36.36.id14.1">
      2,3
     </span>
    </sup>
    , Yu Qiao
    <sup class="ltx_sup" id="id37.37.id15">
     <span class="ltx_text ltx_font_italic" id="id37.37.id15.1">
      1
     </span>
    </sup>
    , Jifeng Dai
    <sup class="ltx_sup" id="id38.38.id16">
     <span class="ltx_text ltx_font_italic" id="id38.38.id16.1">
      6,1
     </span>
    </sup>
    <sup class="ltx_sup" id="id39.39.id17">
     🖂
    </sup>
    <br class="ltx_break"/>
    <sup class="ltx_sup" id="id40.40.id18">
     1
    </sup>
    OpenGVLab, Shanghai AI Laboratory
    <sup class="ltx_sup" id="id41.41.id19">
     2
    </sup>
    The Chinese University of Hong Kong
    <br class="ltx_break"/>
    <sup class="ltx_sup" id="id42.42.id20">
     3
    </sup>
    SenseTime Research
    <sup class="ltx_sup" id="id43.43.id21">
     4
    </sup>
    Stanford University
    <sup class="ltx_sup" id="id44.44.id22">
     5
    </sup>
    Nanjing University
    <sup class="ltx_sup" id="id45.45.id23">
     6
    </sup>
    Tsinghua University
    <br class="ltx_break"/>
    <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/OpenGVLab/DriveMLM" style="font-size:90%;" target="_blank" title="">
     https://github.com/OpenGVLab/DriveMLM
    </a>
    <br class="ltx_break"/>
   </span>
  </span>
 </div>
 <div class="ltx_abstract">
  <h6 class="ltx_title ltx_title_abstract">
   Abstract
  </h6>
  <p class="ltx_p" id="id46.id1">
   Large language models (LLMs) have opened up new possibilities for intelligent agents, endowing them with human-like thinking and cognitive abilities.
In this work, we delve into the potential of large language models (LLMs) in autonomous driving (AD). We introduce DriveMLM, an LLM-based AD framework that can perform close-loop autonomous driving in realistic simulators.
To this end, (1) we bridge the gap between the language decisions and the vehicle control commands by standardizing the decision states according to the off-the-shelf motion planning module. (2) We employ a multi-modal LLM (MLLM) to model the behavior planning module of a module AD system, which uses driving rules, user commands, and inputs from various sensors (
   <em class="ltx_emph ltx_font_italic" id="id46.id1.1">
    e.g
   </em>
   .
   <span class="ltx_text" id="id46.id1.2">
   </span>
   , camera, lidar) as input and makes driving decisions and provide explanations; This model can plug-and-play in existing AD systems such as Apollo for close-loop driving. (3) We design an effective data engine to collect a dataset that includes decision state and corresponding explanation annotation for model training and evaluation. We conduct extensive experiments and show that our model achieves 76.1 driving score on the CARLA Town05 Long, and surpasses the Apollo baseline by 4.7 points under the same settings, demonstrating the effectiveness of our model. We hope this work can serve as a baseline for autonomous driving with LLMs.
  </p>
 </div>
 <section class="ltx_section" id="S1">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    1
   </span>
   Introduction
  </h2>
  <figure class="ltx_figure" id="S1.F1">
   <div class="ltx_flex_figure">
    <div class="ltx_flex_cell ltx_flex_size_1">
     <figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S1.F1.sf1">
      <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="139" id="S1.F1.sf1.g1" src="/html/2312.09245/assets/x1.png" width="528"/>
      <figcaption class="ltx_caption ltx_centering">
       <span class="ltx_tag ltx_tag_figure">
        <span class="ltx_text" id="S1.F1.sf1.2.1.1" style="font-size:90%;">
         (a)
        </span>
       </span>
       <span class="ltx_text" id="S1.F1.sf1.3.2" style="font-size:90%;">
        Rule-Based Autonomous Driving System
        <cite class="ltx_cite ltx_citemacro_cite">
         [
         <a class="ltx_ref" href="#bib.bib3" title="">
          <span class="ltx_text" style="font-size:90%;">
           3
          </span>
         </a>
         ]
        </cite>
       </span>
      </figcaption>
     </figure>
    </div>
    <div class="ltx_flex_break">
    </div>
    <div class="ltx_flex_cell ltx_flex_size_1">
     <figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S1.F1.sf2">
      <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="115" id="S1.F1.sf2.g1" src="/html/2312.09245/assets/x2.png" width="528"/>
      <figcaption class="ltx_caption ltx_centering">
       <span class="ltx_tag ltx_tag_figure">
        <span class="ltx_text" id="S1.F1.sf2.2.1.1" style="font-size:90%;">
         (b)
        </span>
       </span>
       <span class="ltx_text" id="S1.F1.sf2.3.2" style="font-size:90%;">
        End-to-End Autonomous Driving System
        <cite class="ltx_cite ltx_citemacro_cite">
         [
         <a class="ltx_ref" href="#bib.bib25" title="">
          <span class="ltx_text" style="font-size:90%;">
           25
          </span>
         </a>
         ,
         <a class="ltx_ref" href="#bib.bib27" title="">
          <span class="ltx_text" style="font-size:90%;">
           27
          </span>
         </a>
         ,
         <a class="ltx_ref" href="#bib.bib57" title="">
          <span class="ltx_text" style="font-size:90%;">
           57
          </span>
         </a>
         ]
        </cite>
       </span>
      </figcaption>
     </figure>
    </div>
    <div class="ltx_flex_break">
    </div>
    <div class="ltx_flex_cell ltx_flex_size_1">
     <figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S1.F1.sf3">
      <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="146" id="S1.F1.sf3.g1" src="/html/2312.09245/assets/x3.png" width="528"/>
      <figcaption class="ltx_caption ltx_centering">
       <span class="ltx_tag ltx_tag_figure">
        <span class="ltx_text" id="S1.F1.sf3.2.1.1" style="font-size:90%;">
         (c)
        </span>
       </span>
       <span class="ltx_text" id="S1.F1.sf3.3.2" style="font-size:90%;">
        Autonomous Driving System with Large Language Model (Ours)
       </span>
      </figcaption>
     </figure>
    </div>
   </div>
   <figcaption class="ltx_caption ltx_centering">
    <span class="ltx_tag ltx_tag_figure">
     <span class="ltx_text" id="S1.F1.3.1.1" style="font-size:90%;">
      Figure 1
     </span>
     :
    </span>
    <span class="ltx_text ltx_font_bold" id="S1.F1.4.2" style="font-size:90%;">
     Comparison of different AD systems.
     <span class="ltx_text ltx_font_medium" id="S1.F1.4.2.1">
      (a) is the rule-based system constrained by the limitation of pre-defined and manual rules, (b) is a data-driven system restricted by the diversity of generated data,
(c) we apply the capability of LLMs to the AD system and align the decision state with the planner to achieve closed-loop driving.
     </span>
    </span>
   </figcaption>
  </figure>
  <span class="ltx_note ltx_role_footnote" id="footnote1">
   <sup class="ltx_note_mark">
    †
   </sup>
   <span class="ltx_note_outer">
    <span class="ltx_note_content">
     <sup class="ltx_note_mark">
      †
     </sup>
     <math alttext="*" class="ltx_Math" display="inline" id="footnote1.m1.1">
      <semantics id="footnote1.m1.1b">
       <mo id="footnote1.m1.1.1" xref="footnote1.m1.1.1.cmml">
        ∗
       </mo>
       <annotation-xml encoding="MathML-Content" id="footnote1.m1.1c">
        <times id="footnote1.m1.1.1.cmml" xref="footnote1.m1.1.1">
        </times>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="footnote1.m1.1d">
        *
       </annotation>
      </semantics>
     </math>
     equal contribution, 🖂 corresponding author (daijifeng@tsinghua.
     <br class="ltx_break"/>
     edu.cn)
    </span>
   </span>
  </span>
  <div class="ltx_para" id="S1.p1">
   <p class="ltx_p" id="S1.p1.1">
    Autonomous driving (AD) has undergone significant advancements in recent years, evolving from traditional rule-based systems, which rely on a predefined set of rules informed by prior knowledge (see Figure
    <a class="ltx_ref" href="#S1.F1.sf1" title="Figure 1(a) ‣ Figure 1 ‣ 1 Introduction ‣ DriveMLM: Aligning Multi-Modal Large Language Models with Behavioral Planning States for Autonomous Driving">
     <span class="ltx_text ltx_ref_tag">
      1(a)
     </span>
    </a>
    ), to data-driven, end-to-end systems, as demonstrated in Figure
    <a class="ltx_ref" href="#S1.F1.sf2" title="Figure 1(b) ‣ Figure 1 ‣ 1 Introduction ‣ DriveMLM: Aligning Multi-Modal Large Language Models with Behavioral Planning States for Autonomous Driving">
     <span class="ltx_text ltx_ref_tag">
      1(b)
     </span>
    </a>
    . Despite their advancements, these systems have encountered limitations due to the constraints of expert knowledge or the diversity of training data. This has made it challenging for them to handle corner-case situations, even though human drivers might find them intuitive to deal with.
In contrast to these traditional rule-based or data-driven AD planners,
Large language models (LLMs) trained with web-scale text corpus, are equipped with extensive world knowledge, robust logical reasoning, and advanced cognitive capabilities. These features position them as potential planners in AD systems, providing a human-like approach to autonomous driving.
   </p>
  </div>
  <div class="ltx_para" id="S1.p2">
   <p class="ltx_p" id="S1.p2.1">
    Some recent studies
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib16" title="">
      <span class="ltx_text" style="font-size:90%;">
       16
      </span>
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib72" title="">
      <span class="ltx_text" style="font-size:90%;">
       72
      </span>
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib68" title="">
      <span class="ltx_text" style="font-size:90%;">
       68
      </span>
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib39" title="">
      <span class="ltx_text" style="font-size:90%;">
       39
      </span>
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib24" title="">
      <span class="ltx_text" style="font-size:90%;">
       24
      </span>
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib13" title="">
      <span class="ltx_text" style="font-size:90%;">
       13
      </span>
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib56" title="">
      <span class="ltx_text" style="font-size:90%;">
       56
      </span>
     </a>
     ]
    </cite>
    have been made to integrate LLMs into AD systems, focusing on generating language-based decisions in response to driving scenarios.
However, these approaches have limitations when it comes to performing closed-loop driving in real-world environments or realistic simulators. This is because the outputs of LLMs are mainly linguistic and conceptual, which cannot be used for vehicle control.
In traditional modular AD systems
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib3" title="">
      <span class="ltx_text" style="font-size:90%;">
       3
      </span>
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib22" title="">
      <span class="ltx_text" style="font-size:90%;">
       22
      </span>
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib21" title="">
      <span class="ltx_text" style="font-size:90%;">
       21
      </span>
     </a>
     ]
    </cite>
    , the gap between high-level strategic goals and low-level operational actions is connected by a behavioral planning module, whose decision states can be easily transformed into vehicle control signals by follow-up motion planning and control.
This motivates us to
    <em class="ltx_emph ltx_font_italic" id="S1.p2.1.1">
     align the LLM with the decision state of the behavioral planning module, and further design an LLM-based close-loop AD system that can run on real-world environments or realistic simulators by using the aligned LLM for behavioral planning
    </em>
    .
   </p>
  </div>
  <div class="ltx_para" id="S1.p3">
   <p class="ltx_p" id="S1.p3.1">
    Based on this point, we propose DriveMLM, the first LLM-based AD framework that can perform close-loop autonomous driving in realistic simulators.
To achieve this, we have three key designs: (1) We investigate the decision states of the behavioral planning module of the well-developed Apollo system
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib3" title="">
      <span class="ltx_text" style="font-size:90%;">
       3
      </span>
     </a>
     ]
    </cite>
    , and transform them into forms that can be easily processed by LLMs. (2) We develop a multi-modal LLM (MLLM) planner that can accept the current multi-modal inputs including multi-view images, LiDAR point clouds, traffic rules, system messages, and user instructions, and predict the decision state; (3) To obtain enough training data for behavioral planning state alignment, we manually collect 280 hours of driving data on CARLA, and convert them into decision state and corresponding explanation annotations by an efficient data engine.
With these designs, we can obtain an MLLM planner that can make decisions based on the driving scenes and user requirements, and its decisions can be easily converted into vehicle control signals for closed-loop driving.
   </p>
  </div>
  <div class="ltx_para" id="S1.p4">
   <p class="ltx_p" id="S1.p4.1">
    Our work has the following advantages: (1) Benefiting from the aligned decision states, our MLLM planner can be easily integrated with existing modular AD systems, such as Apollo, to achieve closed-loop driving without requiring any major changes or modifications.
(2) By taking language instruction as input, our model can handle both user needs (
    <em class="ltx_emph ltx_font_italic" id="S1.p4.1.1">
     e.g
    </em>
    .
    <span class="ltx_text" id="S1.p4.1.2">
    </span>
    , overtaking a car) and high-level system messages (
    <em class="ltx_emph ltx_font_italic" id="S1.p4.1.3">
     e.g
    </em>
    .
    <span class="ltx_text" id="S1.p4.1.4">
    </span>
    , defining basic driving logic). This makes our model more flexible and adaptable to different driving situations and corner cases.
(3) It can provide interpretability and explain different decisions. This enhances the transparency and trustworthiness of our model, as it can explain its actions and choices to the user.
   </p>
  </div>
  <div class="ltx_para" id="S1.p5">
   <p class="ltx_p" id="S1.p5.1">
    In summary, the contribution of this work is three folds:
   </p>
  </div>
  <div class="ltx_para" id="S1.p6">
   <p class="ltx_p" id="S1.p6.1">
    (1) We propose an LLM-based AD framework that bridges the gap between LLM and closed-loop driving by aligning the output of LLMs with
the decision states of behavioral planning modules.
   </p>
  </div>
  <div class="ltx_para" id="S1.p7">
   <p class="ltx_p" id="S1.p7.1">
    (2) To implement this framework, we tailor a set of decision states with forms that can be easily processed by LLMs, design an MLLM planner for decision prediction, and develop a data engine that can effectively generate decision states and corresponding explanation annotation for model training and evaluation.
   </p>
  </div>
  <div class="ltx_para" id="S1.p8">
   <p class="ltx_p" id="S1.p8.1">
    (3) To validate the effectiveness of our method, we not only evaluate our method on the closed-loop driving metrics including driving score (DS) and miles per intervention (MPI), but also use understanding metrics including accuracy, F1-measure for decision state, BLEU-4, CIDEr and METEOR for decision explanation to evaluate the driving understanding capability of our model. Notably, our method achieves 76.1 DS, 0.955 MPI results on CARLA Town05 Long, which is 4.7 points, 1.25 times better than Apollo. Moreover, we can change the decision of the MLLM planner by describing special requirements with language instructions such as yielding for ambulance or traffic rules, as shown in Figure
    <a class="ltx_ref" href="#S1.F2" title="Figure 2 ‣ 1 Introduction ‣ DriveMLM: Aligning Multi-Modal Large Language Models with Behavioral Planning States for Autonomous Driving">
     <span class="ltx_text ltx_ref_tag">
      2
     </span>
    </a>
    .
   </p>
  </div>
  <figure class="ltx_figure" id="S1.F2">
   <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="252" id="S1.F2.g1" src="/html/2312.09245/assets/x4.png" width="207"/>
   <figcaption class="ltx_caption ltx_centering">
    <span class="ltx_tag ltx_tag_figure">
     <span class="ltx_text" id="S1.F2.5.1.1" style="font-size:90%;">
      Figure 2
     </span>
     :
    </span>
    <span class="ltx_text ltx_font_bold" id="S1.F2.6.2" style="font-size:90%;">
     Decision preferences altered by customized language instructions.
     <span class="ltx_text ltx_font_medium" id="S1.F2.6.2.1">
     </span>
     TOP:
     <span class="ltx_text ltx_font_medium" id="S1.F2.6.2.2">
      DriveMLM is instructed to yield when an emergency vehicle emerges from behind, leading to a lane change.
     </span>
     BOTTOM:
     <span class="ltx_text ltx_font_medium" id="S1.F2.6.2.3">
      DriveMLM is instructed to proceed through a red light, causing a deviation from common traffic rules. In these scenarios, the driving system is influenced by modified driving preferences, resulting in unconventional control decisions.
     </span>
    </span>
   </figcaption>
  </figure>
 </section>
 <section class="ltx_section" id="S2">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    2
   </span>
   Related Work
  </h2>
  <section class="ltx_subsection" id="S2.SS1">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     2.1
    </span>
    Multi-Modal Large Language Models
   </h3>
   <div class="ltx_para" id="S2.SS1.p1">
    <p class="ltx_p" id="S2.SS1.p1.1">
     The swift evolution of Large Language Models (LLMs)
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib53" title="">
       <span class="ltx_text" style="font-size:90%;">
        53
       </span>
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib54" title="">
       <span class="ltx_text" style="font-size:90%;">
        54
       </span>
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib7" title="">
       <span class="ltx_text" style="font-size:90%;">
        7
       </span>
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib47" title="">
       <span class="ltx_text" style="font-size:90%;">
        47
       </span>
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib46" title="">
       <span class="ltx_text" style="font-size:90%;">
        46
       </span>
      </a>
      ]
     </cite>
     has recently given rise to the emergence of multi-modal LLMs (MLLMs)
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib1" title="">
       <span class="ltx_text" style="font-size:90%;">
        1
       </span>
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib26" title="">
       <span class="ltx_text" style="font-size:90%;">
        26
       </span>
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib38" title="">
       <span class="ltx_text" style="font-size:90%;">
        38
       </span>
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib37" title="">
       <span class="ltx_text" style="font-size:90%;">
        37
       </span>
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib83" title="">
       <span class="ltx_text" style="font-size:90%;">
        83
       </span>
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib17" title="">
       <span class="ltx_text" style="font-size:90%;">
        17
       </span>
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib78" title="">
       <span class="ltx_text" style="font-size:90%;">
        78
       </span>
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib12" title="">
       <span class="ltx_text" style="font-size:90%;">
        12
       </span>
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib67" title="">
       <span class="ltx_text" style="font-size:90%;">
        67
       </span>
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib51" title="">
       <span class="ltx_text" style="font-size:90%;">
        51
       </span>
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib30" title="">
       <span class="ltx_text" style="font-size:90%;">
        30
       </span>
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib2" title="">
       <span class="ltx_text" style="font-size:90%;">
        2
       </span>
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib23" title="">
       <span class="ltx_text" style="font-size:90%;">
        23
       </span>
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib33" title="">
       <span class="ltx_text" style="font-size:90%;">
        33
       </span>
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib79" title="">
       <span class="ltx_text" style="font-size:90%;">
        79
       </span>
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib71" title="">
       <span class="ltx_text" style="font-size:90%;">
        71
       </span>
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib29" title="">
       <span class="ltx_text" style="font-size:90%;">
        29
       </span>
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib80" title="">
       <span class="ltx_text" style="font-size:90%;">
        80
       </span>
      </a>
      ]
     </cite>
     , which augment language models with the capacity to analyze and comprehend information from diverse modalities.
Prominent instances of such advancements include GPT-4
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib46" title="">
       <span class="ltx_text" style="font-size:90%;">
        46
       </span>
      </a>
      ]
     </cite>
     , Flamingo
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib1" title="">
       <span class="ltx_text" style="font-size:90%;">
        1
       </span>
      </a>
      ]
     </cite>
     , KOSMOS-1
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib26" title="">
       <span class="ltx_text" style="font-size:90%;">
        26
       </span>
      </a>
      ]
     </cite>
     , LLaVA series
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib38" title="">
       <span class="ltx_text" style="font-size:90%;">
        38
       </span>
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib37" title="">
       <span class="ltx_text" style="font-size:90%;">
        37
       </span>
      </a>
      ]
     </cite>
     , and MiniGPT-4
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib83" title="">
       <span class="ltx_text" style="font-size:90%;">
        83
       </span>
      </a>
      ]
     </cite>
     , as well as InstructBLIP
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib17" title="">
       <span class="ltx_text" style="font-size:90%;">
        17
       </span>
      </a>
      ]
     </cite>
     . These models have integrated visual instruction tuning methodologies to enhance the MLLMs’ ability to adhere to prescribed instructions.
Furthermore, mPLUG-DocOwl
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib78" title="">
       <span class="ltx_text" style="font-size:90%;">
        78
       </span>
      </a>
      ]
     </cite>
     has broadened the document comprehension capabilities of MLLMs by incorporating digital document datasets. Concurrently, Shikra
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib12" title="">
       <span class="ltx_text" style="font-size:90%;">
        12
       </span>
      </a>
      ]
     </cite>
     , VisionLLM
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib67" title="">
       <span class="ltx_text" style="font-size:90%;">
        67
       </span>
      </a>
      ]
     </cite>
     , KOSMOS-2
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib51" title="">
       <span class="ltx_text" style="font-size:90%;">
        51
       </span>
      </a>
      ]
     </cite>
     , LISA
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib30" title="">
       <span class="ltx_text" style="font-size:90%;">
        30
       </span>
      </a>
      ]
     </cite>
     , and Qwen-VL
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib2" title="">
       <span class="ltx_text" style="font-size:90%;">
        2
       </span>
      </a>
      ]
     </cite>
     have augmented MLLMs with visual grounding capabilities, empowering them to detect or segment objects in accordance with user prompts.
The introduction of VideoChat
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib33" title="">
       <span class="ltx_text" style="font-size:90%;">
        33
       </span>
      </a>
      ]
     </cite>
     and VideoLLaMA
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib79" title="">
       <span class="ltx_text" style="font-size:90%;">
        79
       </span>
      </a>
      ]
     </cite>
     has ushered in the integration of video processing capabilities into LLMs. Additionally, NExT-GPT
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib71" title="">
       <span class="ltx_text" style="font-size:90%;">
        71
       </span>
      </a>
      ]
     </cite>
     has introduced a modality-switching instruction tuning technique for multi-modal prompt tuning, facilitating the handling of inputs and outputs in any combination of text, images, videos, and audio.
ASM
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib29" title="">
       <span class="ltx_text" style="font-size:90%;">
        29
       </span>
      </a>
      ]
     </cite>
     and GPT4RoI
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib80" title="">
       <span class="ltx_text" style="font-size:90%;">
        80
       </span>
      </a>
      ]
     </cite>
     introduce region-level recognition and understanding capability into LLMs. These endeavors demonstrate the effectiveness and generalizability of LLMs, establishing a foundation for open-world tasks.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S2.SS2">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     2.2
    </span>
    Intelligent Agents with Large Language Models
   </h3>
   <div class="ltx_para" id="S2.SS2.p1">
    <p class="ltx_p" id="S2.SS2.p1.1">
     A burgeoning application of LLMs is their role in facilitating interaction and communication among intelligent agents (e.g., robots, virtual assistants, or game characters) and various entities, including humans, the environment, or even the intelligent agents themselves. Several API-based methods, including Visual ChatGPT
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib69" title="">
       <span class="ltx_text" style="font-size:90%;">
        69
       </span>
      </a>
      ]
     </cite>
     , MM-REACT
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib77" title="">
       <span class="ltx_text" style="font-size:90%;">
        77
       </span>
      </a>
      ]
     </cite>
     , HuggingGPT
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib59" title="">
       <span class="ltx_text" style="font-size:90%;">
        59
       </span>
      </a>
      ]
     </cite>
     , InternGPT
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib40" title="">
       <span class="ltx_text" style="font-size:90%;">
        40
       </span>
      </a>
      ]
     </cite>
     , ViperGPT
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib62" title="">
       <span class="ltx_text" style="font-size:90%;">
        62
       </span>
      </a>
      ]
     </cite>
     , ControlLLM
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib41" title="">
       <span class="ltx_text" style="font-size:90%;">
        41
       </span>
      </a>
      ]
     </cite>
     , and GPT4Tool
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib76" title="">
       <span class="ltx_text" style="font-size:90%;">
        76
       </span>
      </a>
      ]
     </cite>
     have attempted to integrate diverse modal APIs with LLMs to accomplish complex tasks in the open world, such as image editing, video processing, and audio synthesis. These methods allow language models to perform complex real-world tasks by following natural language instructions. In parallel, alternative research initiatives, such as Camel
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib31" title="">
       <span class="ltx_text" style="font-size:90%;">
        31
       </span>
      </a>
      ]
     </cite>
     , AutoGPT
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib75" title="">
       <span class="ltx_text" style="font-size:90%;">
        75
       </span>
      </a>
      ]
     </cite>
     , MetaGPT
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib24" title="">
       <span class="ltx_text" style="font-size:90%;">
        24
       </span>
      </a>
      ]
     </cite>
     and Smallville
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib50" title="">
       <span class="ltx_text" style="font-size:90%;">
        50
       </span>
      </a>
      ]
     </cite>
     , investigate the utility of LLMs in the context of role-playing conversations or communication games. Additionally, within the domain of embodied AI, works such as PaLM-E
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib19" title="">
       <span class="ltx_text" style="font-size:90%;">
        19
       </span>
      </a>
      ]
     </cite>
     , EmbodiedGPT
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib45" title="">
       <span class="ltx_text" style="font-size:90%;">
        45
       </span>
      </a>
      ]
     </cite>
     , and the RT series
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib5" title="">
       <span class="ltx_text" style="font-size:90%;">
        5
       </span>
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib6" title="">
       <span class="ltx_text" style="font-size:90%;">
        6
       </span>
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib48" title="">
       <span class="ltx_text" style="font-size:90%;">
        48
       </span>
      </a>
      ]
     </cite>
     leverage LLMs to generate natural language actions, thereby controlling embodied agents proficient in executing navigation, manipulation, and interaction tasks within real or 3D environments. These works demonstrate the notable advancements achieved by LLMs in the realm of intelligent agent control.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S2.SS3">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     2.3
    </span>
    Autonomous Driving Models
   </h3>
   <div class="ltx_para" id="S2.SS3.p1">
    <p class="ltx_p" id="S2.SS3.p1.1">
     The development of autonomous driving (AD) models has accelerated rapidly in recent years, giving rise to many disruptive and groundbreaking technologies. Notably, the open-source frameworks, such as Apollo
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib3" title="">
       <span class="ltx_text" style="font-size:90%;">
        3
       </span>
      </a>
      ]
     </cite>
     and Autoware
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib22" title="">
       <span class="ltx_text" style="font-size:90%;">
        22
       </span>
      </a>
      ]
     </cite>
     , have played pivotal roles by furnishing robust tools and resources, thereby facilitating the development of autonomous driving technology and contributing to its widespread adoption and progression.
In terms of AD perception, BEV (Bird’s Eye View)
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib34" title="">
       <span class="ltx_text" style="font-size:90%;">
        34
       </span>
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib73" title="">
       <span class="ltx_text" style="font-size:90%;">
        73
       </span>
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib36" title="">
       <span class="ltx_text" style="font-size:90%;">
        36
       </span>
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib61" title="">
       <span class="ltx_text" style="font-size:90%;">
        61
       </span>
      </a>
      ]
     </cite>
     and Occupancy Network
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib63" title="">
       <span class="ltx_text" style="font-size:90%;">
        63
       </span>
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib60" title="">
       <span class="ltx_text" style="font-size:90%;">
        60
       </span>
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib35" title="">
       <span class="ltx_text" style="font-size:90%;">
        35
       </span>
      </a>
      ]
     </cite>
     have become essential components of autonomous vehicles, helping them better understand the surrounding environment and make corresponding decisions.
The decision-making process in conventional autonomous driving systems typically relies on finite state machines
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib14" title="">
       <span class="ltx_text" style="font-size:90%;">
        14
       </span>
      </a>
      ]
     </cite>
     . These systems often require the manual creation of numerous rules to determine the states and conditions for transitioning between them. However, considering the ever-changing nature of the world, this is usually laborious to design rules to cover all the scenarios for the real world.
In recent years, end-to-end autonomous driving models have also made remarkable progress, such as UniAD
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib25" title="">
       <span class="ltx_text" style="font-size:90%;">
        25
       </span>
      </a>
      ]
     </cite>
     , which adopts a novel end-to-end approach, directly integrating perception, prediction, and planning, avoiding information loss and efficiency issues in the traditional modular design method.
Recently, open-sourced simulators
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib18" title="">
       <span class="ltx_text" style="font-size:90%;">
        18
       </span>
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib66" title="">
       <span class="ltx_text" style="font-size:90%;">
        66
       </span>
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib82" title="">
       <span class="ltx_text" style="font-size:90%;">
        82
       </span>
      </a>
      ]
     </cite>
     have been proposed to bridge the gap between model prediction and closed-loop control. Among them, CARLA
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib18" title="">
       <span class="ltx_text" style="font-size:90%;">
        18
       </span>
      </a>
      ]
     </cite>
     , featuring comprehensive sensor simulations and realistic environments, is the most widely used benchmark for evaluating closed-loop performance by many state-of-the-art methods
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib27" title="">
       <span class="ltx_text" style="font-size:90%;">
        27
       </span>
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib58" title="">
       <span class="ltx_text" style="font-size:90%;">
        58
       </span>
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib57" title="">
       <span class="ltx_text" style="font-size:90%;">
        57
       </span>
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib28" title="">
       <span class="ltx_text" style="font-size:90%;">
        28
       </span>
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib15" title="">
       <span class="ltx_text" style="font-size:90%;">
        15
       </span>
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib10" title="">
       <span class="ltx_text" style="font-size:90%;">
        10
       </span>
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib11" title="">
       <span class="ltx_text" style="font-size:90%;">
        11
       </span>
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib9" title="">
       <span class="ltx_text" style="font-size:90%;">
        9
       </span>
      </a>
      ]
     </cite>
     .
    </p>
   </div>
   <div class="ltx_para" id="S2.SS3.p2">
    <p class="ltx_p" id="S2.SS3.p2.1">
     Recent works
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib16" title="">
       <span class="ltx_text" style="font-size:90%;">
        16
       </span>
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib72" title="">
       <span class="ltx_text" style="font-size:90%;">
        72
       </span>
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib43" title="">
       <span class="ltx_text" style="font-size:90%;">
        43
       </span>
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib68" title="">
       <span class="ltx_text" style="font-size:90%;">
        68
       </span>
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib39" title="">
       <span class="ltx_text" style="font-size:90%;">
        39
       </span>
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib13" title="">
       <span class="ltx_text" style="font-size:90%;">
        13
       </span>
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib56" title="">
       <span class="ltx_text" style="font-size:90%;">
        56
       </span>
      </a>
      ]
     </cite>
     changes our perception by introducing LLM for driving planning, opening up a new direction for the autonomous driving field.
As early explorations, some
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib68" title="">
       <span class="ltx_text" style="font-size:90%;">
        68
       </span>
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib56" title="">
       <span class="ltx_text" style="font-size:90%;">
        56
       </span>
      </a>
      ]
     </cite>
     use ChatGPT and GPT-4 to predict driving decisions.
Following works fine-tune LLM models to predict driving signal
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib13" title="">
       <span class="ltx_text" style="font-size:90%;">
        13
       </span>
      </a>
      ]
     </cite>
     , trajectory
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib43" title="">
       <span class="ltx_text" style="font-size:90%;">
        43
       </span>
      </a>
      ]
     </cite>
     or designed decision space
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib39" title="">
       <span class="ltx_text" style="font-size:90%;">
        39
       </span>
      </a>
      ]
     </cite>
     , conditioned only on language as input.
DriveGPT4
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib72" title="">
       <span class="ltx_text" style="font-size:90%;">
        72
       </span>
      </a>
      ]
     </cite>
     finetunes Multimodal LLM to
predict control signal.
However, DriveGPT4 is constrained by the input from a monocular camera, limiting its ability to construct comprehensive scene information.
All LLM-based works above are not evaluated on realistic simulators in closed-loop driving, because either linguistic decisions of LLMs are hard to transform to actually reliable control signals, or the direct prediction of control signal by LLM remains a large gap to real-time closed-loop driving.
    </p>
   </div>
  </section>
 </section>
 <section class="ltx_section" id="S3">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    3
   </span>
   Proposed Method
  </h2>
  <section class="ltx_subsection" id="S3.SS1">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     3.1
    </span>
    System Overview
   </h3>
   <figure class="ltx_figure" id="S3.F3">
    <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="201" id="S3.F3.g1" src="/html/2312.09245/assets/x5.png" width="502"/>
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_figure">
      <span class="ltx_text" id="S3.F3.9.4.1" style="font-size:90%;">
       Figure 3
      </span>
      :
     </span>
     <span class="ltx_text ltx_font_bold" id="S3.F3.6.3" style="font-size:90%;">
      DriveMLM framework
      <span class="ltx_text ltx_font_medium" id="S3.F3.6.3.3">
       consists of three parts: (1) behavioral planning states alignment, which aligns linguistic output to executable decisions for vehicle control. (2) MLLM planner, consisting of multi-model tokenizer and MLLM decoder. It transforms multi-modality sensor input
       <math alttext="I,L" class="ltx_Math" display="inline" id="S3.F3.4.1.1.m1.2">
        <semantics id="S3.F3.4.1.1.m1.2b">
         <mrow id="S3.F3.4.1.1.m1.2.3.2" xref="S3.F3.4.1.1.m1.2.3.1.cmml">
          <mi id="S3.F3.4.1.1.m1.1.1" xref="S3.F3.4.1.1.m1.1.1.cmml">
           I
          </mi>
          <mo id="S3.F3.4.1.1.m1.2.3.2.1" xref="S3.F3.4.1.1.m1.2.3.1.cmml">
           ,
          </mo>
          <mi id="S3.F3.4.1.1.m1.2.2" xref="S3.F3.4.1.1.m1.2.2.cmml">
           L
          </mi>
         </mrow>
         <annotation-xml encoding="MathML-Content" id="S3.F3.4.1.1.m1.2c">
          <list id="S3.F3.4.1.1.m1.2.3.1.cmml" xref="S3.F3.4.1.1.m1.2.3.2">
           <ci id="S3.F3.4.1.1.m1.1.1.cmml" xref="S3.F3.4.1.1.m1.1.1">
            𝐼
           </ci>
           <ci id="S3.F3.4.1.1.m1.2.2.cmml" xref="S3.F3.4.1.1.m1.2.2">
            𝐿
           </ci>
          </list>
         </annotation-xml>
         <annotation encoding="application/x-tex" id="S3.F3.4.1.1.m1.2d">
          I,L
         </annotation>
        </semantics>
       </math>
       , system message
       <math alttext="M" class="ltx_Math" display="inline" id="S3.F3.5.2.2.m2.1">
        <semantics id="S3.F3.5.2.2.m2.1b">
         <mi id="S3.F3.5.2.2.m2.1.1" xref="S3.F3.5.2.2.m2.1.1.cmml">
          M
         </mi>
         <annotation-xml encoding="MathML-Content" id="S3.F3.5.2.2.m2.1c">
          <ci id="S3.F3.5.2.2.m2.1.1.cmml" xref="S3.F3.5.2.2.m2.1.1">
           𝑀
          </ci>
         </annotation-xml>
         <annotation encoding="application/x-tex" id="S3.F3.5.2.2.m2.1d">
          M
         </annotation>
        </semantics>
       </math>
       , and user instructions
       <math alttext="U" class="ltx_Math" display="inline" id="S3.F3.6.3.3.m3.1">
        <semantics id="S3.F3.6.3.3.m3.1b">
         <mi id="S3.F3.6.3.3.m3.1.1" xref="S3.F3.6.3.3.m3.1.1.cmml">
          U
         </mi>
         <annotation-xml encoding="MathML-Content" id="S3.F3.6.3.3.m3.1c">
          <ci id="S3.F3.6.3.3.m3.1.1.cmml" xref="S3.F3.6.3.3.m3.1.1">
           𝑈
          </ci>
         </annotation-xml>
         <annotation encoding="application/x-tex" id="S3.F3.6.3.3.m3.1d">
          U
         </annotation>
        </semantics>
       </math>
       to drive explanation and aligned decisions. (3) Efficient data collection strategy, which generates rich driving explanations and aligned decisions at low cost. SPT stands for sparse pyramid transformer.
      </span>
     </span>
    </figcaption>
   </figure>
   <div class="ltx_para" id="S3.SS1.p1">
    <p class="ltx_p" id="S3.SS1.p1.1">
     The DriveMLM framework integrates the world knowledge and reasoning capabilities of large language models (LLMs) into an autonomous driving (AD) system, achieving closed-loop driving in realistic simulators. As illustrated in Figure
     <a class="ltx_ref" href="#S3.F3" title="Figure 3 ‣ 3.1 System Overview ‣ 3 Proposed Method ‣ DriveMLM: Aligning Multi-Modal Large Language Models with Behavioral Planning States for Autonomous Driving">
      <span class="ltx_text ltx_ref_tag">
       3
      </span>
     </a>
     , this framework has three key designs:
(1)
     <em class="ltx_emph ltx_font_italic" id="S3.SS1.p1.1.1">
      Behavioral Planning States Alignment.
     </em>
     This part aligns LLM’s linguistic decision outputs with the behavioral planning module of a well-established modular AD system like Apollo
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib3" title="">
       <span class="ltx_text" style="font-size:90%;">
        3
       </span>
      </a>
      ]
     </cite>
     . In this way, the output of LLM can be easily transformed into vehicle control signals.
(2)
     <em class="ltx_emph ltx_font_italic" id="S3.SS1.p1.1.2">
      MLLM Planner.
     </em>
     It is a combination of a multi-modal tokenizer and a multi-modal LLM (MLLM) decoder. The multi-modal tokenizer transforms diverse inputs like multi-view images, LiDAR, traffic rules, and user requirements into unified tokens, and the MLLM decoder makes decisions based on the unified tokens. (3)
     <em class="ltx_emph ltx_font_italic" id="S3.SS1.p1.1.3">
      Efficient Data Collection Strategy.
     </em>
     It introduces a tailored data collection method for LLM-based autonomous driving, ensuring a comprehensive dataset encompassing decision states, decision explanations, and user commands.
    </p>
   </div>
   <div class="ltx_para" id="S3.SS1.p2">
    <p class="ltx_p" id="S3.SS1.p2.20">
     During inference, the DriveMLM framework leverages multi-modal data to make driving decisions. These data include: multi-view images
     <math alttext="I\!\in\!\mathbb{R}^{T\times N_{I}\times H\times W\times 3}" class="ltx_Math" display="inline" id="S3.SS1.p2.1.m1.1">
      <semantics id="S3.SS1.p2.1.m1.1a">
       <mrow id="S3.SS1.p2.1.m1.1.1" xref="S3.SS1.p2.1.m1.1.1.cmml">
        <mi id="S3.SS1.p2.1.m1.1.1.2" xref="S3.SS1.p2.1.m1.1.1.2.cmml">
         I
        </mi>
        <mo id="S3.SS1.p2.1.m1.1.1.1" lspace="0.108em" rspace="0.108em" xref="S3.SS1.p2.1.m1.1.1.1.cmml">
         ∈
        </mo>
        <msup id="S3.SS1.p2.1.m1.1.1.3" xref="S3.SS1.p2.1.m1.1.1.3.cmml">
         <mi id="S3.SS1.p2.1.m1.1.1.3.2" xref="S3.SS1.p2.1.m1.1.1.3.2.cmml">
          ℝ
         </mi>
         <mrow id="S3.SS1.p2.1.m1.1.1.3.3" xref="S3.SS1.p2.1.m1.1.1.3.3.cmml">
          <mi id="S3.SS1.p2.1.m1.1.1.3.3.2" xref="S3.SS1.p2.1.m1.1.1.3.3.2.cmml">
           T
          </mi>
          <mo id="S3.SS1.p2.1.m1.1.1.3.3.1" lspace="0.222em" rspace="0.222em" xref="S3.SS1.p2.1.m1.1.1.3.3.1.cmml">
           ×
          </mo>
          <msub id="S3.SS1.p2.1.m1.1.1.3.3.3" xref="S3.SS1.p2.1.m1.1.1.3.3.3.cmml">
           <mi id="S3.SS1.p2.1.m1.1.1.3.3.3.2" xref="S3.SS1.p2.1.m1.1.1.3.3.3.2.cmml">
            N
           </mi>
           <mi id="S3.SS1.p2.1.m1.1.1.3.3.3.3" xref="S3.SS1.p2.1.m1.1.1.3.3.3.3.cmml">
            I
           </mi>
          </msub>
          <mo id="S3.SS1.p2.1.m1.1.1.3.3.1a" lspace="0.222em" rspace="0.222em" xref="S3.SS1.p2.1.m1.1.1.3.3.1.cmml">
           ×
          </mo>
          <mi id="S3.SS1.p2.1.m1.1.1.3.3.4" xref="S3.SS1.p2.1.m1.1.1.3.3.4.cmml">
           H
          </mi>
          <mo id="S3.SS1.p2.1.m1.1.1.3.3.1b" lspace="0.222em" rspace="0.222em" xref="S3.SS1.p2.1.m1.1.1.3.3.1.cmml">
           ×
          </mo>
          <mi id="S3.SS1.p2.1.m1.1.1.3.3.5" xref="S3.SS1.p2.1.m1.1.1.3.3.5.cmml">
           W
          </mi>
          <mo id="S3.SS1.p2.1.m1.1.1.3.3.1c" lspace="0.222em" rspace="0.222em" xref="S3.SS1.p2.1.m1.1.1.3.3.1.cmml">
           ×
          </mo>
          <mn id="S3.SS1.p2.1.m1.1.1.3.3.6" xref="S3.SS1.p2.1.m1.1.1.3.3.6.cmml">
           3
          </mn>
         </mrow>
        </msup>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="S3.SS1.p2.1.m1.1b">
        <apply id="S3.SS1.p2.1.m1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1">
         <in id="S3.SS1.p2.1.m1.1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1.1">
         </in>
         <ci id="S3.SS1.p2.1.m1.1.1.2.cmml" xref="S3.SS1.p2.1.m1.1.1.2">
          𝐼
         </ci>
         <apply id="S3.SS1.p2.1.m1.1.1.3.cmml" xref="S3.SS1.p2.1.m1.1.1.3">
          <csymbol cd="ambiguous" id="S3.SS1.p2.1.m1.1.1.3.1.cmml" xref="S3.SS1.p2.1.m1.1.1.3">
           superscript
          </csymbol>
          <ci id="S3.SS1.p2.1.m1.1.1.3.2.cmml" xref="S3.SS1.p2.1.m1.1.1.3.2">
           ℝ
          </ci>
          <apply id="S3.SS1.p2.1.m1.1.1.3.3.cmml" xref="S3.SS1.p2.1.m1.1.1.3.3">
           <times id="S3.SS1.p2.1.m1.1.1.3.3.1.cmml" xref="S3.SS1.p2.1.m1.1.1.3.3.1">
           </times>
           <ci id="S3.SS1.p2.1.m1.1.1.3.3.2.cmml" xref="S3.SS1.p2.1.m1.1.1.3.3.2">
            𝑇
           </ci>
           <apply id="S3.SS1.p2.1.m1.1.1.3.3.3.cmml" xref="S3.SS1.p2.1.m1.1.1.3.3.3">
            <csymbol cd="ambiguous" id="S3.SS1.p2.1.m1.1.1.3.3.3.1.cmml" xref="S3.SS1.p2.1.m1.1.1.3.3.3">
             subscript
            </csymbol>
            <ci id="S3.SS1.p2.1.m1.1.1.3.3.3.2.cmml" xref="S3.SS1.p2.1.m1.1.1.3.3.3.2">
             𝑁
            </ci>
            <ci id="S3.SS1.p2.1.m1.1.1.3.3.3.3.cmml" xref="S3.SS1.p2.1.m1.1.1.3.3.3.3">
             𝐼
            </ci>
           </apply>
           <ci id="S3.SS1.p2.1.m1.1.1.3.3.4.cmml" xref="S3.SS1.p2.1.m1.1.1.3.3.4">
            𝐻
           </ci>
           <ci id="S3.SS1.p2.1.m1.1.1.3.3.5.cmml" xref="S3.SS1.p2.1.m1.1.1.3.3.5">
            𝑊
           </ci>
           <cn id="S3.SS1.p2.1.m1.1.1.3.3.6.cmml" type="integer" xref="S3.SS1.p2.1.m1.1.1.3.3.6">
            3
           </cn>
          </apply>
         </apply>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS1.p2.1.m1.1c">
        I\!\in\!\mathbb{R}^{T\times N_{I}\times H\times W\times 3}
       </annotation>
      </semantics>
     </math>
     , where
     <math alttext="T" class="ltx_Math" display="inline" id="S3.SS1.p2.2.m2.1">
      <semantics id="S3.SS1.p2.2.m2.1a">
       <mi id="S3.SS1.p2.2.m2.1.1" xref="S3.SS1.p2.2.m2.1.1.cmml">
        T
       </mi>
       <annotation-xml encoding="MathML-Content" id="S3.SS1.p2.2.m2.1b">
        <ci id="S3.SS1.p2.2.m2.1.1.cmml" xref="S3.SS1.p2.2.m2.1.1">
         𝑇
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS1.p2.2.m2.1c">
        T
       </annotation>
      </semantics>
     </math>
     denotes the time length,
     <math alttext="N_{I}" class="ltx_Math" display="inline" id="S3.SS1.p2.3.m3.1">
      <semantics id="S3.SS1.p2.3.m3.1a">
       <msub id="S3.SS1.p2.3.m3.1.1" xref="S3.SS1.p2.3.m3.1.1.cmml">
        <mi id="S3.SS1.p2.3.m3.1.1.2" xref="S3.SS1.p2.3.m3.1.1.2.cmml">
         N
        </mi>
        <mi id="S3.SS1.p2.3.m3.1.1.3" xref="S3.SS1.p2.3.m3.1.1.3.cmml">
         I
        </mi>
       </msub>
       <annotation-xml encoding="MathML-Content" id="S3.SS1.p2.3.m3.1b">
        <apply id="S3.SS1.p2.3.m3.1.1.cmml" xref="S3.SS1.p2.3.m3.1.1">
         <csymbol cd="ambiguous" id="S3.SS1.p2.3.m3.1.1.1.cmml" xref="S3.SS1.p2.3.m3.1.1">
          subscript
         </csymbol>
         <ci id="S3.SS1.p2.3.m3.1.1.2.cmml" xref="S3.SS1.p2.3.m3.1.1.2">
          𝑁
         </ci>
         <ci id="S3.SS1.p2.3.m3.1.1.3.cmml" xref="S3.SS1.p2.3.m3.1.1.3">
          𝐼
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS1.p2.3.m3.1c">
        N_{I}
       </annotation>
      </semantics>
     </math>
     indicates the number of views, and
     <math alttext="H" class="ltx_Math" display="inline" id="S3.SS1.p2.4.m4.1">
      <semantics id="S3.SS1.p2.4.m4.1a">
       <mi id="S3.SS1.p2.4.m4.1.1" xref="S3.SS1.p2.4.m4.1.1.cmml">
        H
       </mi>
       <annotation-xml encoding="MathML-Content" id="S3.SS1.p2.4.m4.1b">
        <ci id="S3.SS1.p2.4.m4.1.1.cmml" xref="S3.SS1.p2.4.m4.1.1">
         𝐻
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS1.p2.4.m4.1c">
        H
       </annotation>
      </semantics>
     </math>
     and
     <math alttext="W" class="ltx_Math" display="inline" id="S3.SS1.p2.5.m5.1">
      <semantics id="S3.SS1.p2.5.m5.1a">
       <mi id="S3.SS1.p2.5.m5.1.1" xref="S3.SS1.p2.5.m5.1.1.cmml">
        W
       </mi>
       <annotation-xml encoding="MathML-Content" id="S3.SS1.p2.5.m5.1b">
        <ci id="S3.SS1.p2.5.m5.1.1.cmml" xref="S3.SS1.p2.5.m5.1.1">
         𝑊
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS1.p2.5.m5.1c">
        W
       </annotation>
      </semantics>
     </math>
     denotes the height and width of images.
The point clouds
     <math alttext="L\!\in\!\mathbb{R}^{K\times 4}" class="ltx_Math" display="inline" id="S3.SS1.p2.6.m6.1">
      <semantics id="S3.SS1.p2.6.m6.1a">
       <mrow id="S3.SS1.p2.6.m6.1.1" xref="S3.SS1.p2.6.m6.1.1.cmml">
        <mi id="S3.SS1.p2.6.m6.1.1.2" xref="S3.SS1.p2.6.m6.1.1.2.cmml">
         L
        </mi>
        <mo id="S3.SS1.p2.6.m6.1.1.1" lspace="0.108em" rspace="0.108em" xref="S3.SS1.p2.6.m6.1.1.1.cmml">
         ∈
        </mo>
        <msup id="S3.SS1.p2.6.m6.1.1.3" xref="S3.SS1.p2.6.m6.1.1.3.cmml">
         <mi id="S3.SS1.p2.6.m6.1.1.3.2" xref="S3.SS1.p2.6.m6.1.1.3.2.cmml">
          ℝ
         </mi>
         <mrow id="S3.SS1.p2.6.m6.1.1.3.3" xref="S3.SS1.p2.6.m6.1.1.3.3.cmml">
          <mi id="S3.SS1.p2.6.m6.1.1.3.3.2" xref="S3.SS1.p2.6.m6.1.1.3.3.2.cmml">
           K
          </mi>
          <mo id="S3.SS1.p2.6.m6.1.1.3.3.1" lspace="0.222em" rspace="0.222em" xref="S3.SS1.p2.6.m6.1.1.3.3.1.cmml">
           ×
          </mo>
          <mn id="S3.SS1.p2.6.m6.1.1.3.3.3" xref="S3.SS1.p2.6.m6.1.1.3.3.3.cmml">
           4
          </mn>
         </mrow>
        </msup>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="S3.SS1.p2.6.m6.1b">
        <apply id="S3.SS1.p2.6.m6.1.1.cmml" xref="S3.SS1.p2.6.m6.1.1">
         <in id="S3.SS1.p2.6.m6.1.1.1.cmml" xref="S3.SS1.p2.6.m6.1.1.1">
         </in>
         <ci id="S3.SS1.p2.6.m6.1.1.2.cmml" xref="S3.SS1.p2.6.m6.1.1.2">
          𝐿
         </ci>
         <apply id="S3.SS1.p2.6.m6.1.1.3.cmml" xref="S3.SS1.p2.6.m6.1.1.3">
          <csymbol cd="ambiguous" id="S3.SS1.p2.6.m6.1.1.3.1.cmml" xref="S3.SS1.p2.6.m6.1.1.3">
           superscript
          </csymbol>
          <ci id="S3.SS1.p2.6.m6.1.1.3.2.cmml" xref="S3.SS1.p2.6.m6.1.1.3.2">
           ℝ
          </ci>
          <apply id="S3.SS1.p2.6.m6.1.1.3.3.cmml" xref="S3.SS1.p2.6.m6.1.1.3.3">
           <times id="S3.SS1.p2.6.m6.1.1.3.3.1.cmml" xref="S3.SS1.p2.6.m6.1.1.3.3.1">
           </times>
           <ci id="S3.SS1.p2.6.m6.1.1.3.3.2.cmml" xref="S3.SS1.p2.6.m6.1.1.3.3.2">
            𝐾
           </ci>
           <cn id="S3.SS1.p2.6.m6.1.1.3.3.3.cmml" type="integer" xref="S3.SS1.p2.6.m6.1.1.3.3.3">
            4
           </cn>
          </apply>
         </apply>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS1.p2.6.m6.1c">
        L\!\in\!\mathbb{R}^{K\times 4}
       </annotation>
      </semantics>
     </math>
     from LiDAR point clouds, with
     <math alttext="K" class="ltx_Math" display="inline" id="S3.SS1.p2.7.m7.1">
      <semantics id="S3.SS1.p2.7.m7.1a">
       <mi id="S3.SS1.p2.7.m7.1.1" xref="S3.SS1.p2.7.m7.1.1.cmml">
        K
       </mi>
       <annotation-xml encoding="MathML-Content" id="S3.SS1.p2.7.m7.1b">
        <ci id="S3.SS1.p2.7.m7.1.1.cmml" xref="S3.SS1.p2.7.m7.1.1">
         𝐾
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS1.p2.7.m7.1c">
        K
       </annotation>
      </semantics>
     </math>
     representing the number of points. System message
     <math alttext="M\!\in\!\mathbb{R}^{N_{M}}" class="ltx_Math" display="inline" id="S3.SS1.p2.8.m8.1">
      <semantics id="S3.SS1.p2.8.m8.1a">
       <mrow id="S3.SS1.p2.8.m8.1.1" xref="S3.SS1.p2.8.m8.1.1.cmml">
        <mi id="S3.SS1.p2.8.m8.1.1.2" xref="S3.SS1.p2.8.m8.1.1.2.cmml">
         M
        </mi>
        <mo id="S3.SS1.p2.8.m8.1.1.1" lspace="0.108em" rspace="0.108em" xref="S3.SS1.p2.8.m8.1.1.1.cmml">
         ∈
        </mo>
        <msup id="S3.SS1.p2.8.m8.1.1.3" xref="S3.SS1.p2.8.m8.1.1.3.cmml">
         <mi id="S3.SS1.p2.8.m8.1.1.3.2" xref="S3.SS1.p2.8.m8.1.1.3.2.cmml">
          ℝ
         </mi>
         <msub id="S3.SS1.p2.8.m8.1.1.3.3" xref="S3.SS1.p2.8.m8.1.1.3.3.cmml">
          <mi id="S3.SS1.p2.8.m8.1.1.3.3.2" xref="S3.SS1.p2.8.m8.1.1.3.3.2.cmml">
           N
          </mi>
          <mi id="S3.SS1.p2.8.m8.1.1.3.3.3" xref="S3.SS1.p2.8.m8.1.1.3.3.3.cmml">
           M
          </mi>
         </msub>
        </msup>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="S3.SS1.p2.8.m8.1b">
        <apply id="S3.SS1.p2.8.m8.1.1.cmml" xref="S3.SS1.p2.8.m8.1.1">
         <in id="S3.SS1.p2.8.m8.1.1.1.cmml" xref="S3.SS1.p2.8.m8.1.1.1">
         </in>
         <ci id="S3.SS1.p2.8.m8.1.1.2.cmml" xref="S3.SS1.p2.8.m8.1.1.2">
          𝑀
         </ci>
         <apply id="S3.SS1.p2.8.m8.1.1.3.cmml" xref="S3.SS1.p2.8.m8.1.1.3">
          <csymbol cd="ambiguous" id="S3.SS1.p2.8.m8.1.1.3.1.cmml" xref="S3.SS1.p2.8.m8.1.1.3">
           superscript
          </csymbol>
          <ci id="S3.SS1.p2.8.m8.1.1.3.2.cmml" xref="S3.SS1.p2.8.m8.1.1.3.2">
           ℝ
          </ci>
          <apply id="S3.SS1.p2.8.m8.1.1.3.3.cmml" xref="S3.SS1.p2.8.m8.1.1.3.3">
           <csymbol cd="ambiguous" id="S3.SS1.p2.8.m8.1.1.3.3.1.cmml" xref="S3.SS1.p2.8.m8.1.1.3.3">
            subscript
           </csymbol>
           <ci id="S3.SS1.p2.8.m8.1.1.3.3.2.cmml" xref="S3.SS1.p2.8.m8.1.1.3.3.2">
            𝑁
           </ci>
           <ci id="S3.SS1.p2.8.m8.1.1.3.3.3.cmml" xref="S3.SS1.p2.8.m8.1.1.3.3.3">
            𝑀
           </ci>
          </apply>
         </apply>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS1.p2.8.m8.1c">
        M\!\in\!\mathbb{R}^{N_{M}}
       </annotation>
      </semantics>
     </math>
     , with
     <math alttext="N_{M}" class="ltx_Math" display="inline" id="S3.SS1.p2.9.m9.1">
      <semantics id="S3.SS1.p2.9.m9.1a">
       <msub id="S3.SS1.p2.9.m9.1.1" xref="S3.SS1.p2.9.m9.1.1.cmml">
        <mi id="S3.SS1.p2.9.m9.1.1.2" xref="S3.SS1.p2.9.m9.1.1.2.cmml">
         N
        </mi>
        <mi id="S3.SS1.p2.9.m9.1.1.3" xref="S3.SS1.p2.9.m9.1.1.3.cmml">
         M
        </mi>
       </msub>
       <annotation-xml encoding="MathML-Content" id="S3.SS1.p2.9.m9.1b">
        <apply id="S3.SS1.p2.9.m9.1.1.cmml" xref="S3.SS1.p2.9.m9.1.1">
         <csymbol cd="ambiguous" id="S3.SS1.p2.9.m9.1.1.1.cmml" xref="S3.SS1.p2.9.m9.1.1">
          subscript
         </csymbol>
         <ci id="S3.SS1.p2.9.m9.1.1.2.cmml" xref="S3.SS1.p2.9.m9.1.1.2">
          𝑁
         </ci>
         <ci id="S3.SS1.p2.9.m9.1.1.3.cmml" xref="S3.SS1.p2.9.m9.1.1.3">
          𝑀
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS1.p2.9.m9.1c">
        N_{M}
       </annotation>
      </semantics>
     </math>
     representing the number of system message tokens. The system message is the gathering of task definition, traffic rules, and decision state definition. User instructions
     <math alttext="U\!\in\!\mathbb{R}^{N_{U}}" class="ltx_Math" display="inline" id="S3.SS1.p2.10.m10.1">
      <semantics id="S3.SS1.p2.10.m10.1a">
       <mrow id="S3.SS1.p2.10.m10.1.1" xref="S3.SS1.p2.10.m10.1.1.cmml">
        <mi id="S3.SS1.p2.10.m10.1.1.2" xref="S3.SS1.p2.10.m10.1.1.2.cmml">
         U
        </mi>
        <mo id="S3.SS1.p2.10.m10.1.1.1" lspace="0.108em" rspace="0.108em" xref="S3.SS1.p2.10.m10.1.1.1.cmml">
         ∈
        </mo>
        <msup id="S3.SS1.p2.10.m10.1.1.3" xref="S3.SS1.p2.10.m10.1.1.3.cmml">
         <mi id="S3.SS1.p2.10.m10.1.1.3.2" xref="S3.SS1.p2.10.m10.1.1.3.2.cmml">
          ℝ
         </mi>
         <msub id="S3.SS1.p2.10.m10.1.1.3.3" xref="S3.SS1.p2.10.m10.1.1.3.3.cmml">
          <mi id="S3.SS1.p2.10.m10.1.1.3.3.2" xref="S3.SS1.p2.10.m10.1.1.3.3.2.cmml">
           N
          </mi>
          <mi id="S3.SS1.p2.10.m10.1.1.3.3.3" xref="S3.SS1.p2.10.m10.1.1.3.3.3.cmml">
           U
          </mi>
         </msub>
        </msup>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="S3.SS1.p2.10.m10.1b">
        <apply id="S3.SS1.p2.10.m10.1.1.cmml" xref="S3.SS1.p2.10.m10.1.1">
         <in id="S3.SS1.p2.10.m10.1.1.1.cmml" xref="S3.SS1.p2.10.m10.1.1.1">
         </in>
         <ci id="S3.SS1.p2.10.m10.1.1.2.cmml" xref="S3.SS1.p2.10.m10.1.1.2">
          𝑈
         </ci>
         <apply id="S3.SS1.p2.10.m10.1.1.3.cmml" xref="S3.SS1.p2.10.m10.1.1.3">
          <csymbol cd="ambiguous" id="S3.SS1.p2.10.m10.1.1.3.1.cmml" xref="S3.SS1.p2.10.m10.1.1.3">
           superscript
          </csymbol>
          <ci id="S3.SS1.p2.10.m10.1.1.3.2.cmml" xref="S3.SS1.p2.10.m10.1.1.3.2">
           ℝ
          </ci>
          <apply id="S3.SS1.p2.10.m10.1.1.3.3.cmml" xref="S3.SS1.p2.10.m10.1.1.3.3">
           <csymbol cd="ambiguous" id="S3.SS1.p2.10.m10.1.1.3.3.1.cmml" xref="S3.SS1.p2.10.m10.1.1.3.3">
            subscript
           </csymbol>
           <ci id="S3.SS1.p2.10.m10.1.1.3.3.2.cmml" xref="S3.SS1.p2.10.m10.1.1.3.3.2">
            𝑁
           </ci>
           <ci id="S3.SS1.p2.10.m10.1.1.3.3.3.cmml" xref="S3.SS1.p2.10.m10.1.1.3.3.3">
            𝑈
           </ci>
          </apply>
         </apply>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS1.p2.10.m10.1c">
        U\!\in\!\mathbb{R}^{N_{U}}
       </annotation>
      </semantics>
     </math>
     , where
     <math alttext="N_{U}" class="ltx_Math" display="inline" id="S3.SS1.p2.11.m11.1">
      <semantics id="S3.SS1.p2.11.m11.1a">
       <msub id="S3.SS1.p2.11.m11.1.1" xref="S3.SS1.p2.11.m11.1.1.cmml">
        <mi id="S3.SS1.p2.11.m11.1.1.2" xref="S3.SS1.p2.11.m11.1.1.2.cmml">
         N
        </mi>
        <mi id="S3.SS1.p2.11.m11.1.1.3" xref="S3.SS1.p2.11.m11.1.1.3.cmml">
         U
        </mi>
       </msub>
       <annotation-xml encoding="MathML-Content" id="S3.SS1.p2.11.m11.1b">
        <apply id="S3.SS1.p2.11.m11.1.1.cmml" xref="S3.SS1.p2.11.m11.1.1">
         <csymbol cd="ambiguous" id="S3.SS1.p2.11.m11.1.1.1.cmml" xref="S3.SS1.p2.11.m11.1.1">
          subscript
         </csymbol>
         <ci id="S3.SS1.p2.11.m11.1.1.2.cmml" xref="S3.SS1.p2.11.m11.1.1.2">
          𝑁
         </ci>
         <ci id="S3.SS1.p2.11.m11.1.1.3.cmml" xref="S3.SS1.p2.11.m11.1.1.3">
          𝑈
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS1.p2.11.m11.1c">
        N_{U}
       </annotation>
      </semantics>
     </math>
     stands for the number of user instruction tokens.
These inputs undergo tokenization through a multi-modal tokenizer, resulting in:
     <math alttext="X_{I}\!\in\!\mathbb{R}^{N_{I}\times N_{Q}\times D}" class="ltx_Math" display="inline" id="S3.SS1.p2.12.m12.1">
      <semantics id="S3.SS1.p2.12.m12.1a">
       <mrow id="S3.SS1.p2.12.m12.1.1" xref="S3.SS1.p2.12.m12.1.1.cmml">
        <msub id="S3.SS1.p2.12.m12.1.1.2" xref="S3.SS1.p2.12.m12.1.1.2.cmml">
         <mi id="S3.SS1.p2.12.m12.1.1.2.2" xref="S3.SS1.p2.12.m12.1.1.2.2.cmml">
          X
         </mi>
         <mi id="S3.SS1.p2.12.m12.1.1.2.3" xref="S3.SS1.p2.12.m12.1.1.2.3.cmml">
          I
         </mi>
        </msub>
        <mo id="S3.SS1.p2.12.m12.1.1.1" lspace="0.108em" rspace="0.108em" xref="S3.SS1.p2.12.m12.1.1.1.cmml">
         ∈
        </mo>
        <msup id="S3.SS1.p2.12.m12.1.1.3" xref="S3.SS1.p2.12.m12.1.1.3.cmml">
         <mi id="S3.SS1.p2.12.m12.1.1.3.2" xref="S3.SS1.p2.12.m12.1.1.3.2.cmml">
          ℝ
         </mi>
         <mrow id="S3.SS1.p2.12.m12.1.1.3.3" xref="S3.SS1.p2.12.m12.1.1.3.3.cmml">
          <msub id="S3.SS1.p2.12.m12.1.1.3.3.2" xref="S3.SS1.p2.12.m12.1.1.3.3.2.cmml">
           <mi id="S3.SS1.p2.12.m12.1.1.3.3.2.2" xref="S3.SS1.p2.12.m12.1.1.3.3.2.2.cmml">
            N
           </mi>
           <mi id="S3.SS1.p2.12.m12.1.1.3.3.2.3" xref="S3.SS1.p2.12.m12.1.1.3.3.2.3.cmml">
            I
           </mi>
          </msub>
          <mo id="S3.SS1.p2.12.m12.1.1.3.3.1" lspace="0.222em" rspace="0.222em" xref="S3.SS1.p2.12.m12.1.1.3.3.1.cmml">
           ×
          </mo>
          <msub id="S3.SS1.p2.12.m12.1.1.3.3.3" xref="S3.SS1.p2.12.m12.1.1.3.3.3.cmml">
           <mi id="S3.SS1.p2.12.m12.1.1.3.3.3.2" xref="S3.SS1.p2.12.m12.1.1.3.3.3.2.cmml">
            N
           </mi>
           <mi id="S3.SS1.p2.12.m12.1.1.3.3.3.3" xref="S3.SS1.p2.12.m12.1.1.3.3.3.3.cmml">
            Q
           </mi>
          </msub>
          <mo id="S3.SS1.p2.12.m12.1.1.3.3.1a" lspace="0.222em" rspace="0.222em" xref="S3.SS1.p2.12.m12.1.1.3.3.1.cmml">
           ×
          </mo>
          <mi id="S3.SS1.p2.12.m12.1.1.3.3.4" xref="S3.SS1.p2.12.m12.1.1.3.3.4.cmml">
           D
          </mi>
         </mrow>
        </msup>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="S3.SS1.p2.12.m12.1b">
        <apply id="S3.SS1.p2.12.m12.1.1.cmml" xref="S3.SS1.p2.12.m12.1.1">
         <in id="S3.SS1.p2.12.m12.1.1.1.cmml" xref="S3.SS1.p2.12.m12.1.1.1">
         </in>
         <apply id="S3.SS1.p2.12.m12.1.1.2.cmml" xref="S3.SS1.p2.12.m12.1.1.2">
          <csymbol cd="ambiguous" id="S3.SS1.p2.12.m12.1.1.2.1.cmml" xref="S3.SS1.p2.12.m12.1.1.2">
           subscript
          </csymbol>
          <ci id="S3.SS1.p2.12.m12.1.1.2.2.cmml" xref="S3.SS1.p2.12.m12.1.1.2.2">
           𝑋
          </ci>
          <ci id="S3.SS1.p2.12.m12.1.1.2.3.cmml" xref="S3.SS1.p2.12.m12.1.1.2.3">
           𝐼
          </ci>
         </apply>
         <apply id="S3.SS1.p2.12.m12.1.1.3.cmml" xref="S3.SS1.p2.12.m12.1.1.3">
          <csymbol cd="ambiguous" id="S3.SS1.p2.12.m12.1.1.3.1.cmml" xref="S3.SS1.p2.12.m12.1.1.3">
           superscript
          </csymbol>
          <ci id="S3.SS1.p2.12.m12.1.1.3.2.cmml" xref="S3.SS1.p2.12.m12.1.1.3.2">
           ℝ
          </ci>
          <apply id="S3.SS1.p2.12.m12.1.1.3.3.cmml" xref="S3.SS1.p2.12.m12.1.1.3.3">
           <times id="S3.SS1.p2.12.m12.1.1.3.3.1.cmml" xref="S3.SS1.p2.12.m12.1.1.3.3.1">
           </times>
           <apply id="S3.SS1.p2.12.m12.1.1.3.3.2.cmml" xref="S3.SS1.p2.12.m12.1.1.3.3.2">
            <csymbol cd="ambiguous" id="S3.SS1.p2.12.m12.1.1.3.3.2.1.cmml" xref="S3.SS1.p2.12.m12.1.1.3.3.2">
             subscript
            </csymbol>
            <ci id="S3.SS1.p2.12.m12.1.1.3.3.2.2.cmml" xref="S3.SS1.p2.12.m12.1.1.3.3.2.2">
             𝑁
            </ci>
            <ci id="S3.SS1.p2.12.m12.1.1.3.3.2.3.cmml" xref="S3.SS1.p2.12.m12.1.1.3.3.2.3">
             𝐼
            </ci>
           </apply>
           <apply id="S3.SS1.p2.12.m12.1.1.3.3.3.cmml" xref="S3.SS1.p2.12.m12.1.1.3.3.3">
            <csymbol cd="ambiguous" id="S3.SS1.p2.12.m12.1.1.3.3.3.1.cmml" xref="S3.SS1.p2.12.m12.1.1.3.3.3">
             subscript
            </csymbol>
            <ci id="S3.SS1.p2.12.m12.1.1.3.3.3.2.cmml" xref="S3.SS1.p2.12.m12.1.1.3.3.3.2">
             𝑁
            </ci>
            <ci id="S3.SS1.p2.12.m12.1.1.3.3.3.3.cmml" xref="S3.SS1.p2.12.m12.1.1.3.3.3.3">
             𝑄
            </ci>
           </apply>
           <ci id="S3.SS1.p2.12.m12.1.1.3.3.4.cmml" xref="S3.SS1.p2.12.m12.1.1.3.3.4">
            𝐷
           </ci>
          </apply>
         </apply>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS1.p2.12.m12.1c">
        X_{I}\!\in\!\mathbb{R}^{N_{I}\times N_{Q}\times D}
       </annotation>
      </semantics>
     </math>
     ,
     <math alttext="X_{L}\!\in\!\mathbb{R}^{N_{Q}\times D}" class="ltx_Math" display="inline" id="S3.SS1.p2.13.m13.1">
      <semantics id="S3.SS1.p2.13.m13.1a">
       <mrow id="S3.SS1.p2.13.m13.1.1" xref="S3.SS1.p2.13.m13.1.1.cmml">
        <msub id="S3.SS1.p2.13.m13.1.1.2" xref="S3.SS1.p2.13.m13.1.1.2.cmml">
         <mi id="S3.SS1.p2.13.m13.1.1.2.2" xref="S3.SS1.p2.13.m13.1.1.2.2.cmml">
          X
         </mi>
         <mi id="S3.SS1.p2.13.m13.1.1.2.3" xref="S3.SS1.p2.13.m13.1.1.2.3.cmml">
          L
         </mi>
        </msub>
        <mo id="S3.SS1.p2.13.m13.1.1.1" lspace="0.108em" rspace="0.108em" xref="S3.SS1.p2.13.m13.1.1.1.cmml">
         ∈
        </mo>
        <msup id="S3.SS1.p2.13.m13.1.1.3" xref="S3.SS1.p2.13.m13.1.1.3.cmml">
         <mi id="S3.SS1.p2.13.m13.1.1.3.2" xref="S3.SS1.p2.13.m13.1.1.3.2.cmml">
          ℝ
         </mi>
         <mrow id="S3.SS1.p2.13.m13.1.1.3.3" xref="S3.SS1.p2.13.m13.1.1.3.3.cmml">
          <msub id="S3.SS1.p2.13.m13.1.1.3.3.2" xref="S3.SS1.p2.13.m13.1.1.3.3.2.cmml">
           <mi id="S3.SS1.p2.13.m13.1.1.3.3.2.2" xref="S3.SS1.p2.13.m13.1.1.3.3.2.2.cmml">
            N
           </mi>
           <mi id="S3.SS1.p2.13.m13.1.1.3.3.2.3" xref="S3.SS1.p2.13.m13.1.1.3.3.2.3.cmml">
            Q
           </mi>
          </msub>
          <mo id="S3.SS1.p2.13.m13.1.1.3.3.1" lspace="0.222em" rspace="0.222em" xref="S3.SS1.p2.13.m13.1.1.3.3.1.cmml">
           ×
          </mo>
          <mi id="S3.SS1.p2.13.m13.1.1.3.3.3" xref="S3.SS1.p2.13.m13.1.1.3.3.3.cmml">
           D
          </mi>
         </mrow>
        </msup>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="S3.SS1.p2.13.m13.1b">
        <apply id="S3.SS1.p2.13.m13.1.1.cmml" xref="S3.SS1.p2.13.m13.1.1">
         <in id="S3.SS1.p2.13.m13.1.1.1.cmml" xref="S3.SS1.p2.13.m13.1.1.1">
         </in>
         <apply id="S3.SS1.p2.13.m13.1.1.2.cmml" xref="S3.SS1.p2.13.m13.1.1.2">
          <csymbol cd="ambiguous" id="S3.SS1.p2.13.m13.1.1.2.1.cmml" xref="S3.SS1.p2.13.m13.1.1.2">
           subscript
          </csymbol>
          <ci id="S3.SS1.p2.13.m13.1.1.2.2.cmml" xref="S3.SS1.p2.13.m13.1.1.2.2">
           𝑋
          </ci>
          <ci id="S3.SS1.p2.13.m13.1.1.2.3.cmml" xref="S3.SS1.p2.13.m13.1.1.2.3">
           𝐿
          </ci>
         </apply>
         <apply id="S3.SS1.p2.13.m13.1.1.3.cmml" xref="S3.SS1.p2.13.m13.1.1.3">
          <csymbol cd="ambiguous" id="S3.SS1.p2.13.m13.1.1.3.1.cmml" xref="S3.SS1.p2.13.m13.1.1.3">
           superscript
          </csymbol>
          <ci id="S3.SS1.p2.13.m13.1.1.3.2.cmml" xref="S3.SS1.p2.13.m13.1.1.3.2">
           ℝ
          </ci>
          <apply id="S3.SS1.p2.13.m13.1.1.3.3.cmml" xref="S3.SS1.p2.13.m13.1.1.3.3">
           <times id="S3.SS1.p2.13.m13.1.1.3.3.1.cmml" xref="S3.SS1.p2.13.m13.1.1.3.3.1">
           </times>
           <apply id="S3.SS1.p2.13.m13.1.1.3.3.2.cmml" xref="S3.SS1.p2.13.m13.1.1.3.3.2">
            <csymbol cd="ambiguous" id="S3.SS1.p2.13.m13.1.1.3.3.2.1.cmml" xref="S3.SS1.p2.13.m13.1.1.3.3.2">
             subscript
            </csymbol>
            <ci id="S3.SS1.p2.13.m13.1.1.3.3.2.2.cmml" xref="S3.SS1.p2.13.m13.1.1.3.3.2.2">
             𝑁
            </ci>
            <ci id="S3.SS1.p2.13.m13.1.1.3.3.2.3.cmml" xref="S3.SS1.p2.13.m13.1.1.3.3.2.3">
             𝑄
            </ci>
           </apply>
           <ci id="S3.SS1.p2.13.m13.1.1.3.3.3.cmml" xref="S3.SS1.p2.13.m13.1.1.3.3.3">
            𝐷
           </ci>
          </apply>
         </apply>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS1.p2.13.m13.1c">
        X_{L}\!\in\!\mathbb{R}^{N_{Q}\times D}
       </annotation>
      </semantics>
     </math>
     ,
     <math alttext="X_{M}\!\in\!\mathbb{R}^{N_{M}\times D}" class="ltx_Math" display="inline" id="S3.SS1.p2.14.m14.1">
      <semantics id="S3.SS1.p2.14.m14.1a">
       <mrow id="S3.SS1.p2.14.m14.1.1" xref="S3.SS1.p2.14.m14.1.1.cmml">
        <msub id="S3.SS1.p2.14.m14.1.1.2" xref="S3.SS1.p2.14.m14.1.1.2.cmml">
         <mi id="S3.SS1.p2.14.m14.1.1.2.2" xref="S3.SS1.p2.14.m14.1.1.2.2.cmml">
          X
         </mi>
         <mi id="S3.SS1.p2.14.m14.1.1.2.3" xref="S3.SS1.p2.14.m14.1.1.2.3.cmml">
          M
         </mi>
        </msub>
        <mo id="S3.SS1.p2.14.m14.1.1.1" lspace="0.108em" rspace="0.108em" xref="S3.SS1.p2.14.m14.1.1.1.cmml">
         ∈
        </mo>
        <msup id="S3.SS1.p2.14.m14.1.1.3" xref="S3.SS1.p2.14.m14.1.1.3.cmml">
         <mi id="S3.SS1.p2.14.m14.1.1.3.2" xref="S3.SS1.p2.14.m14.1.1.3.2.cmml">
          ℝ
         </mi>
         <mrow id="S3.SS1.p2.14.m14.1.1.3.3" xref="S3.SS1.p2.14.m14.1.1.3.3.cmml">
          <msub id="S3.SS1.p2.14.m14.1.1.3.3.2" xref="S3.SS1.p2.14.m14.1.1.3.3.2.cmml">
           <mi id="S3.SS1.p2.14.m14.1.1.3.3.2.2" xref="S3.SS1.p2.14.m14.1.1.3.3.2.2.cmml">
            N
           </mi>
           <mi id="S3.SS1.p2.14.m14.1.1.3.3.2.3" xref="S3.SS1.p2.14.m14.1.1.3.3.2.3.cmml">
            M
           </mi>
          </msub>
          <mo id="S3.SS1.p2.14.m14.1.1.3.3.1" lspace="0.222em" rspace="0.222em" xref="S3.SS1.p2.14.m14.1.1.3.3.1.cmml">
           ×
          </mo>
          <mi id="S3.SS1.p2.14.m14.1.1.3.3.3" xref="S3.SS1.p2.14.m14.1.1.3.3.3.cmml">
           D
          </mi>
         </mrow>
        </msup>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="S3.SS1.p2.14.m14.1b">
        <apply id="S3.SS1.p2.14.m14.1.1.cmml" xref="S3.SS1.p2.14.m14.1.1">
         <in id="S3.SS1.p2.14.m14.1.1.1.cmml" xref="S3.SS1.p2.14.m14.1.1.1">
         </in>
         <apply id="S3.SS1.p2.14.m14.1.1.2.cmml" xref="S3.SS1.p2.14.m14.1.1.2">
          <csymbol cd="ambiguous" id="S3.SS1.p2.14.m14.1.1.2.1.cmml" xref="S3.SS1.p2.14.m14.1.1.2">
           subscript
          </csymbol>
          <ci id="S3.SS1.p2.14.m14.1.1.2.2.cmml" xref="S3.SS1.p2.14.m14.1.1.2.2">
           𝑋
          </ci>
          <ci id="S3.SS1.p2.14.m14.1.1.2.3.cmml" xref="S3.SS1.p2.14.m14.1.1.2.3">
           𝑀
          </ci>
         </apply>
         <apply id="S3.SS1.p2.14.m14.1.1.3.cmml" xref="S3.SS1.p2.14.m14.1.1.3">
          <csymbol cd="ambiguous" id="S3.SS1.p2.14.m14.1.1.3.1.cmml" xref="S3.SS1.p2.14.m14.1.1.3">
           superscript
          </csymbol>
          <ci id="S3.SS1.p2.14.m14.1.1.3.2.cmml" xref="S3.SS1.p2.14.m14.1.1.3.2">
           ℝ
          </ci>
          <apply id="S3.SS1.p2.14.m14.1.1.3.3.cmml" xref="S3.SS1.p2.14.m14.1.1.3.3">
           <times id="S3.SS1.p2.14.m14.1.1.3.3.1.cmml" xref="S3.SS1.p2.14.m14.1.1.3.3.1">
           </times>
           <apply id="S3.SS1.p2.14.m14.1.1.3.3.2.cmml" xref="S3.SS1.p2.14.m14.1.1.3.3.2">
            <csymbol cd="ambiguous" id="S3.SS1.p2.14.m14.1.1.3.3.2.1.cmml" xref="S3.SS1.p2.14.m14.1.1.3.3.2">
             subscript
            </csymbol>
            <ci id="S3.SS1.p2.14.m14.1.1.3.3.2.2.cmml" xref="S3.SS1.p2.14.m14.1.1.3.3.2.2">
             𝑁
            </ci>
            <ci id="S3.SS1.p2.14.m14.1.1.3.3.2.3.cmml" xref="S3.SS1.p2.14.m14.1.1.3.3.2.3">
             𝑀
            </ci>
           </apply>
           <ci id="S3.SS1.p2.14.m14.1.1.3.3.3.cmml" xref="S3.SS1.p2.14.m14.1.1.3.3.3">
            𝐷
           </ci>
          </apply>
         </apply>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS1.p2.14.m14.1c">
        X_{M}\!\in\!\mathbb{R}^{N_{M}\times D}
       </annotation>
      </semantics>
     </math>
     ,
     <math alttext="X_{U}\!\in\!\mathbb{R}^{N_{U}\times D}" class="ltx_Math" display="inline" id="S3.SS1.p2.15.m15.1">
      <semantics id="S3.SS1.p2.15.m15.1a">
       <mrow id="S3.SS1.p2.15.m15.1.1" xref="S3.SS1.p2.15.m15.1.1.cmml">
        <msub id="S3.SS1.p2.15.m15.1.1.2" xref="S3.SS1.p2.15.m15.1.1.2.cmml">
         <mi id="S3.SS1.p2.15.m15.1.1.2.2" xref="S3.SS1.p2.15.m15.1.1.2.2.cmml">
          X
         </mi>
         <mi id="S3.SS1.p2.15.m15.1.1.2.3" xref="S3.SS1.p2.15.m15.1.1.2.3.cmml">
          U
         </mi>
        </msub>
        <mo id="S3.SS1.p2.15.m15.1.1.1" lspace="0.108em" rspace="0.108em" xref="S3.SS1.p2.15.m15.1.1.1.cmml">
         ∈
        </mo>
        <msup id="S3.SS1.p2.15.m15.1.1.3" xref="S3.SS1.p2.15.m15.1.1.3.cmml">
         <mi id="S3.SS1.p2.15.m15.1.1.3.2" xref="S3.SS1.p2.15.m15.1.1.3.2.cmml">
          ℝ
         </mi>
         <mrow id="S3.SS1.p2.15.m15.1.1.3.3" xref="S3.SS1.p2.15.m15.1.1.3.3.cmml">
          <msub id="S3.SS1.p2.15.m15.1.1.3.3.2" xref="S3.SS1.p2.15.m15.1.1.3.3.2.cmml">
           <mi id="S3.SS1.p2.15.m15.1.1.3.3.2.2" xref="S3.SS1.p2.15.m15.1.1.3.3.2.2.cmml">
            N
           </mi>
           <mi id="S3.SS1.p2.15.m15.1.1.3.3.2.3" xref="S3.SS1.p2.15.m15.1.1.3.3.2.3.cmml">
            U
           </mi>
          </msub>
          <mo id="S3.SS1.p2.15.m15.1.1.3.3.1" lspace="0.222em" rspace="0.222em" xref="S3.SS1.p2.15.m15.1.1.3.3.1.cmml">
           ×
          </mo>
          <mi id="S3.SS1.p2.15.m15.1.1.3.3.3" xref="S3.SS1.p2.15.m15.1.1.3.3.3.cmml">
           D
          </mi>
         </mrow>
        </msup>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="S3.SS1.p2.15.m15.1b">
        <apply id="S3.SS1.p2.15.m15.1.1.cmml" xref="S3.SS1.p2.15.m15.1.1">
         <in id="S3.SS1.p2.15.m15.1.1.1.cmml" xref="S3.SS1.p2.15.m15.1.1.1">
         </in>
         <apply id="S3.SS1.p2.15.m15.1.1.2.cmml" xref="S3.SS1.p2.15.m15.1.1.2">
          <csymbol cd="ambiguous" id="S3.SS1.p2.15.m15.1.1.2.1.cmml" xref="S3.SS1.p2.15.m15.1.1.2">
           subscript
          </csymbol>
          <ci id="S3.SS1.p2.15.m15.1.1.2.2.cmml" xref="S3.SS1.p2.15.m15.1.1.2.2">
           𝑋
          </ci>
          <ci id="S3.SS1.p2.15.m15.1.1.2.3.cmml" xref="S3.SS1.p2.15.m15.1.1.2.3">
           𝑈
          </ci>
         </apply>
         <apply id="S3.SS1.p2.15.m15.1.1.3.cmml" xref="S3.SS1.p2.15.m15.1.1.3">
          <csymbol cd="ambiguous" id="S3.SS1.p2.15.m15.1.1.3.1.cmml" xref="S3.SS1.p2.15.m15.1.1.3">
           superscript
          </csymbol>
          <ci id="S3.SS1.p2.15.m15.1.1.3.2.cmml" xref="S3.SS1.p2.15.m15.1.1.3.2">
           ℝ
          </ci>
          <apply id="S3.SS1.p2.15.m15.1.1.3.3.cmml" xref="S3.SS1.p2.15.m15.1.1.3.3">
           <times id="S3.SS1.p2.15.m15.1.1.3.3.1.cmml" xref="S3.SS1.p2.15.m15.1.1.3.3.1">
           </times>
           <apply id="S3.SS1.p2.15.m15.1.1.3.3.2.cmml" xref="S3.SS1.p2.15.m15.1.1.3.3.2">
            <csymbol cd="ambiguous" id="S3.SS1.p2.15.m15.1.1.3.3.2.1.cmml" xref="S3.SS1.p2.15.m15.1.1.3.3.2">
             subscript
            </csymbol>
            <ci id="S3.SS1.p2.15.m15.1.1.3.3.2.2.cmml" xref="S3.SS1.p2.15.m15.1.1.3.3.2.2">
             𝑁
            </ci>
            <ci id="S3.SS1.p2.15.m15.1.1.3.3.2.3.cmml" xref="S3.SS1.p2.15.m15.1.1.3.3.2.3">
             𝑈
            </ci>
           </apply>
           <ci id="S3.SS1.p2.15.m15.1.1.3.3.3.cmml" xref="S3.SS1.p2.15.m15.1.1.3.3.3">
            𝐷
           </ci>
          </apply>
         </apply>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS1.p2.15.m15.1c">
        X_{U}\!\in\!\mathbb{R}^{N_{U}\times D}
       </annotation>
      </semantics>
     </math>
     ,
which represent the tokens embedding of multi-view images, LiDAR point clouds, traffic rules, and user instructions, respectively.
Here,
     <math alttext="N_{Q}" class="ltx_Math" display="inline" id="S3.SS1.p2.16.m16.1">
      <semantics id="S3.SS1.p2.16.m16.1a">
       <msub id="S3.SS1.p2.16.m16.1.1" xref="S3.SS1.p2.16.m16.1.1.cmml">
        <mi id="S3.SS1.p2.16.m16.1.1.2" xref="S3.SS1.p2.16.m16.1.1.2.cmml">
         N
        </mi>
        <mi id="S3.SS1.p2.16.m16.1.1.3" xref="S3.SS1.p2.16.m16.1.1.3.cmml">
         Q
        </mi>
       </msub>
       <annotation-xml encoding="MathML-Content" id="S3.SS1.p2.16.m16.1b">
        <apply id="S3.SS1.p2.16.m16.1.1.cmml" xref="S3.SS1.p2.16.m16.1.1">
         <csymbol cd="ambiguous" id="S3.SS1.p2.16.m16.1.1.1.cmml" xref="S3.SS1.p2.16.m16.1.1">
          subscript
         </csymbol>
         <ci id="S3.SS1.p2.16.m16.1.1.2.cmml" xref="S3.SS1.p2.16.m16.1.1.2">
          𝑁
         </ci>
         <ci id="S3.SS1.p2.16.m16.1.1.3.cmml" xref="S3.SS1.p2.16.m16.1.1.3">
          𝑄
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS1.p2.16.m16.1c">
        N_{Q}
       </annotation>
      </semantics>
     </math>
     denotes the output token number which is decided by the number of queries of QFormer
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib32" title="">
       <span class="ltx_text" style="font-size:90%;">
        32
       </span>
      </a>
      ]
     </cite>
     , and each token embedding is with
     <math alttext="D" class="ltx_Math" display="inline" id="S3.SS1.p2.17.m17.1">
      <semantics id="S3.SS1.p2.17.m17.1a">
       <mi id="S3.SS1.p2.17.m17.1.1" xref="S3.SS1.p2.17.m17.1.1.cmml">
        D
       </mi>
       <annotation-xml encoding="MathML-Content" id="S3.SS1.p2.17.m17.1b">
        <ci id="S3.SS1.p2.17.m17.1.1.cmml" xref="S3.SS1.p2.17.m17.1.1">
         𝐷
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS1.p2.17.m17.1c">
        D
       </annotation>
      </semantics>
     </math>
     dimension.
Next, these tokens are inputted into the MLLM decoder, which generates the decision state token
     <math alttext="S" class="ltx_Math" display="inline" id="S3.SS1.p2.18.m18.1">
      <semantics id="S3.SS1.p2.18.m18.1a">
       <mi id="S3.SS1.p2.18.m18.1.1" xref="S3.SS1.p2.18.m18.1.1.cmml">
        S
       </mi>
       <annotation-xml encoding="MathML-Content" id="S3.SS1.p2.18.m18.1b">
        <ci id="S3.SS1.p2.18.m18.1.1.cmml" xref="S3.SS1.p2.18.m18.1.1">
         𝑆
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS1.p2.18.m18.1c">
        S
       </annotation>
      </semantics>
     </math>
     along with a corresponding explanation
     <math alttext="E" class="ltx_Math" display="inline" id="S3.SS1.p2.19.m19.1">
      <semantics id="S3.SS1.p2.19.m19.1a">
       <mi id="S3.SS1.p2.19.m19.1.1" xref="S3.SS1.p2.19.m19.1.1.cmml">
        E
       </mi>
       <annotation-xml encoding="MathML-Content" id="S3.SS1.p2.19.m19.1b">
        <ci id="S3.SS1.p2.19.m19.1.1.cmml" xref="S3.SS1.p2.19.m19.1.1">
         𝐸
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS1.p2.19.m19.1c">
        E
       </annotation>
      </semantics>
     </math>
     .
Finally, the decision state
     <math alttext="S" class="ltx_Math" display="inline" id="S3.SS1.p2.20.m20.1">
      <semantics id="S3.SS1.p2.20.m20.1a">
       <mi id="S3.SS1.p2.20.m20.1.1" xref="S3.SS1.p2.20.m20.1.1.cmml">
        S
       </mi>
       <annotation-xml encoding="MathML-Content" id="S3.SS1.p2.20.m20.1b">
        <ci id="S3.SS1.p2.20.m20.1.1.cmml" xref="S3.SS1.p2.20.m20.1.1">
         𝑆
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS1.p2.20.m20.1c">
        S
       </annotation>
      </semantics>
     </math>
     is inputted into a motion planning and control module. This module computes the final trajectory for vehicle control.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S3.SS2">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     3.2
    </span>
    Behavioral Planning States Alignment
   </h3>
   <div class="ltx_para" id="S3.SS2.p1">
    <p class="ltx_p" id="S3.SS2.p1.1">
     Transforming the linguistic choices of Large Language Models (LLMs) into actionable control signals is crucial for vehicle control. To achieve this, we align the LLM’s outputs with the decision stages of the behavioral planning module in the popular Apollo system. Following common practice
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib3" title="">
       <span class="ltx_text" style="font-size:90%;">
        3
       </span>
      </a>
      ]
     </cite>
     , we divide the decision-making process into two categories: speed decision and path decision.
Specifically, the speed decision states contain [KEEP, ACCELERATE, DECELERATE, STOP], while the path decision states include
[FOLLOW, LEFT_CHANGE, RIGHT_CHANGE, LEFT_BORROW, RIGHT_BORROW].
    </p>
   </div>
   <div class="ltx_para" id="S3.SS2.p2">
    <p class="ltx_p" id="S3.SS2.p2.1">
     To enable a language model to make precise predictions among these states, we established a comprehensive link between linguistic descriptions and decision states, as illustrated in System Massage of Table
     <a class="ltx_ref" href="#S3.T1" title="Table 1 ‣ 3.2 Behavioral Planning States Alignment ‣ 3 Proposed Method ‣ DriveMLM: Aligning Multi-Modal Large Language Models with Behavioral Planning States for Autonomous Driving">
      <span class="ltx_text ltx_ref_tag">
       1
      </span>
     </a>
     . This correlation is used as a part of the system message and is integrated into the MLLM planner. As a result, once the LLM describes certain situations, the prediction will converge into a clear decision within the decision space. At each time, one-speed decision and one path decision are mutually inferred and sent to the motion planning framework. More detailed definitions of decision states can be found in the supplementary material.
    </p>
   </div>
   <figure class="ltx_table" id="S3.T1">
    <svg class="ltx_picture ltx_centering" height="355.5" id="S3.T1.pic1" overflow="visible" version="1.1" width="600">
     <g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,355.5) matrix(1 0 0 -1 0 0)">
      <g fill="#404040" fill-opacity="1.0">
       <path d="M 0 5.91 L 0 349.59 C 0 352.85 2.64 355.5 5.91 355.5 L 594.09 355.5 C 597.36 355.5 600 352.85 600 349.59 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none">
       </path>
      </g>
      <g fill="#F2F2F2" fill-opacity="1.0">
       <path d="M 1.97 5.91 L 1.97 349.59 C 1.97 351.76 3.73 353.53 5.91 353.53 L 594.09 353.53 C 596.27 353.53 598.03 351.76 598.03 349.59 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none">
       </path>
      </g>
      <g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)">
       <foreignobject color="#000000" height="327.94" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">
        <span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="S3.T1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1" style="width:402.3pt;">
         <span class="ltx_p" id="S3.T1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1">
          <span class="ltx_text ltx_markedasmath ltx_font_bold" id="S3.T1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1" style="font-size:90%;">
           System Message
          </span>
          <span class="ltx_text" id="S3.T1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2" style="font-size:90%;">
           : You are a driving assistant to drive the car. You need to follow the navigation command and traffic rules. The traffic rule is … Path decisions include [FOLLOW, …]. Path decision definitions: ‘FOLLOW’ means …, Speed decisions include [KEEP, …]. Speed decision definitions: ‘KEEP’ means …, Given navigation command and driving scene obtained from camera or LiDAR, You should choose a path decision and a speed decision from the predefined options and give the explanation of your decision.
           <br class="ltx_break"/>
           <span class="ltx_text ltx_font_bold" id="S3.T1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.1">
            Q1(Human)
           </span>
           : Caption instruction (e.g. Describe the current driving environment.)
           <br class="ltx_break"/>
           <span class="ltx_text ltx_font_bold" id="S3.T1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.2">
            A1(DriveMLM)
           </span>
           : Caption response (e.g. It is currently daytime. A red car is driving away in front of ego.)
           <br class="ltx_break"/>
           <span class="ltx_text ltx_font_bold" id="S3.T1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.3">
            Q2(Human)
           </span>
           : Navigation instruction (e.g. The navigation command is turned right. Please choose a path decision and a speed decision.)
           <br class="ltx_break"/>
           <span class="ltx_text ltx_font_bold" id="S3.T1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.4">
            A2(DriveMLM)
           </span>
           : Speed and path decision (e.g. RIGHT_CHANGE, KEEP)
           <br class="ltx_break"/>
           <span class="ltx_text ltx_font_bold" id="S3.T1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.5">
            Q3(Human)
           </span>
           : Explanation instruction (e.g. Please explain why to choose these decisions.)
           <br class="ltx_break"/>
           <span class="ltx_text ltx_font_bold" id="S3.T1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.6">
            A3(DriveMLM)
           </span>
           : Explanation response (e.g. Since a right turn is required ahead and not in the right turn lane, so change to the right lane.)
           <br class="ltx_break"/>
           <span class="ltx_text ltx_font_bold" id="S3.T1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.7">
            Q4(Human)
           </span>
           : Instruction (e.g. I’m in a hurry. Can you overtake the front car?)
           <br class="ltx_break"/>
           <span class="ltx_text ltx_font_bold" id="S3.T1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.8">
            A4(DriveMLM)
           </span>
           : Speed and path decision (e.g. LEFT_CHANGE, ACCELERATE)
           <br class="ltx_break"/>
           <span class="ltx_text ltx_font_bold" id="S3.T1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.9">
            Q5(Human)
           </span>
           : Explanation instruction (e.g. Please explain why to choose these decisions.)
           <br class="ltx_break"/>
           <span class="ltx_text ltx_font_bold" id="S3.T1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.10">
            A5(DriveMLM)
           </span>
           : Explanation response (e.g. Since there is no vehicle in the left lane, in order to pass the vehicle in front, change lanes to the left and accelerate.)
          </span>
         </span>
        </span>
       </foreignobject>
      </g>
     </g>
    </svg>
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_table">
      <span class="ltx_text" id="S3.T1.3.1.1" style="font-size:90%;">
       Table 1
      </span>
      :
     </span>
     <span class="ltx_text ltx_font_bold" id="S3.T1.4.2" style="font-size:90%;">
      Examples of system message and interaction between user and DriveMLM system.
      <span class="ltx_text ltx_font_medium" id="S3.T1.4.2.1">
       The system message includes the description of the driving task, the traffic rules, and the definition of decision states. Given driving scenes such as images and user prompts, the driving system can infer the image caption, path, and speed decision, and additional explanation. Complete system messages and prompts are provided in the supplementary.
      </span>
     </span>
    </figcaption>
   </figure>
  </section>
  <section class="ltx_subsection" id="S3.SS3">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     3.3
    </span>
    MLLM Planner
   </h3>
   <div class="ltx_para" id="S3.SS3.p1">
    <p class="ltx_p" id="S3.SS3.p1.1">
     The MLLM planner of DriveMLM consists of two components: the multi-modal tokenizer and the MLLM decoder. The two components collaborate closely, handling a variety of inputs to accurately determine driving decisions and provide explanations for these decisions.
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S3.SS3.p2">
    <p class="ltx_p" id="S3.SS3.p2.1">
     <span class="ltx_text ltx_font_bold" id="S3.SS3.p2.1.1">
      Multi-Modal Tokenizer.
     </span>
     This tokenizer is engineered to handle various forms of input efficiently:
    </p>
   </div>
   <div class="ltx_para" id="S3.SS3.p3">
    <p class="ltx_p" id="S3.SS3.p3.10">
     (1) For temporal multi-view images: We use a temporal QFormer to process multi-view images from timestamp
     <math alttext="-T" class="ltx_Math" display="inline" id="S3.SS3.p3.1.m1.1">
      <semantics id="S3.SS3.p3.1.m1.1a">
       <mrow id="S3.SS3.p3.1.m1.1.1" xref="S3.SS3.p3.1.m1.1.1.cmml">
        <mo id="S3.SS3.p3.1.m1.1.1a" xref="S3.SS3.p3.1.m1.1.1.cmml">
         −
        </mo>
        <mi id="S3.SS3.p3.1.m1.1.1.2" xref="S3.SS3.p3.1.m1.1.1.2.cmml">
         T
        </mi>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="S3.SS3.p3.1.m1.1b">
        <apply id="S3.SS3.p3.1.m1.1.1.cmml" xref="S3.SS3.p3.1.m1.1.1">
         <minus id="S3.SS3.p3.1.m1.1.1.1.cmml" xref="S3.SS3.p3.1.m1.1.1">
         </minus>
         <ci id="S3.SS3.p3.1.m1.1.1.2.cmml" xref="S3.SS3.p3.1.m1.1.1.2">
          𝑇
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS3.p3.1.m1.1c">
        -T
       </annotation>
      </semantics>
     </math>
     to 0 (current timestamp). First, it takes each view
     <math alttext="I_{i}^{-T}" class="ltx_Math" display="inline" id="S3.SS3.p3.2.m2.1">
      <semantics id="S3.SS3.p3.2.m2.1a">
       <msubsup id="S3.SS3.p3.2.m2.1.1" xref="S3.SS3.p3.2.m2.1.1.cmml">
        <mi id="S3.SS3.p3.2.m2.1.1.2.2" xref="S3.SS3.p3.2.m2.1.1.2.2.cmml">
         I
        </mi>
        <mi id="S3.SS3.p3.2.m2.1.1.2.3" xref="S3.SS3.p3.2.m2.1.1.2.3.cmml">
         i
        </mi>
        <mrow id="S3.SS3.p3.2.m2.1.1.3" xref="S3.SS3.p3.2.m2.1.1.3.cmml">
         <mo id="S3.SS3.p3.2.m2.1.1.3a" xref="S3.SS3.p3.2.m2.1.1.3.cmml">
          −
         </mo>
         <mi id="S3.SS3.p3.2.m2.1.1.3.2" xref="S3.SS3.p3.2.m2.1.1.3.2.cmml">
          T
         </mi>
        </mrow>
       </msubsup>
       <annotation-xml encoding="MathML-Content" id="S3.SS3.p3.2.m2.1b">
        <apply id="S3.SS3.p3.2.m2.1.1.cmml" xref="S3.SS3.p3.2.m2.1.1">
         <csymbol cd="ambiguous" id="S3.SS3.p3.2.m2.1.1.1.cmml" xref="S3.SS3.p3.2.m2.1.1">
          superscript
         </csymbol>
         <apply id="S3.SS3.p3.2.m2.1.1.2.cmml" xref="S3.SS3.p3.2.m2.1.1">
          <csymbol cd="ambiguous" id="S3.SS3.p3.2.m2.1.1.2.1.cmml" xref="S3.SS3.p3.2.m2.1.1">
           subscript
          </csymbol>
          <ci id="S3.SS3.p3.2.m2.1.1.2.2.cmml" xref="S3.SS3.p3.2.m2.1.1.2.2">
           𝐼
          </ci>
          <ci id="S3.SS3.p3.2.m2.1.1.2.3.cmml" xref="S3.SS3.p3.2.m2.1.1.2.3">
           𝑖
          </ci>
         </apply>
         <apply id="S3.SS3.p3.2.m2.1.1.3.cmml" xref="S3.SS3.p3.2.m2.1.1.3">
          <minus id="S3.SS3.p3.2.m2.1.1.3.1.cmml" xref="S3.SS3.p3.2.m2.1.1.3">
          </minus>
          <ci id="S3.SS3.p3.2.m2.1.1.3.2.cmml" xref="S3.SS3.p3.2.m2.1.1.3.2">
           𝑇
          </ci>
         </apply>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS3.p3.2.m2.1c">
        I_{i}^{-T}
       </annotation>
      </semantics>
     </math>
     at timestamp
     <math alttext="-T" class="ltx_Math" display="inline" id="S3.SS3.p3.3.m3.1">
      <semantics id="S3.SS3.p3.3.m3.1a">
       <mrow id="S3.SS3.p3.3.m3.1.1" xref="S3.SS3.p3.3.m3.1.1.cmml">
        <mo id="S3.SS3.p3.3.m3.1.1a" xref="S3.SS3.p3.3.m3.1.1.cmml">
         −
        </mo>
        <mi id="S3.SS3.p3.3.m3.1.1.2" xref="S3.SS3.p3.3.m3.1.1.2.cmml">
         T
        </mi>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="S3.SS3.p3.3.m3.1b">
        <apply id="S3.SS3.p3.3.m3.1.1.cmml" xref="S3.SS3.p3.3.m3.1.1">
         <minus id="S3.SS3.p3.3.m3.1.1.1.cmml" xref="S3.SS3.p3.3.m3.1.1">
         </minus>
         <ci id="S3.SS3.p3.3.m3.1.1.2.cmml" xref="S3.SS3.p3.3.m3.1.1.2">
          𝑇
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS3.p3.3.m3.1c">
        -T
       </annotation>
      </semantics>
     </math>
     and feeds it to ViT-g and QFormer with
     <math alttext="N_{Q}" class="ltx_Math" display="inline" id="S3.SS3.p3.4.m4.1">
      <semantics id="S3.SS3.p3.4.m4.1a">
       <msub id="S3.SS3.p3.4.m4.1.1" xref="S3.SS3.p3.4.m4.1.1.cmml">
        <mi id="S3.SS3.p3.4.m4.1.1.2" xref="S3.SS3.p3.4.m4.1.1.2.cmml">
         N
        </mi>
        <mi id="S3.SS3.p3.4.m4.1.1.3" xref="S3.SS3.p3.4.m4.1.1.3.cmml">
         Q
        </mi>
       </msub>
       <annotation-xml encoding="MathML-Content" id="S3.SS3.p3.4.m4.1b">
        <apply id="S3.SS3.p3.4.m4.1.1.cmml" xref="S3.SS3.p3.4.m4.1.1">
         <csymbol cd="ambiguous" id="S3.SS3.p3.4.m4.1.1.1.cmml" xref="S3.SS3.p3.4.m4.1.1">
          subscript
         </csymbol>
         <ci id="S3.SS3.p3.4.m4.1.1.2.cmml" xref="S3.SS3.p3.4.m4.1.1.2">
          𝑁
         </ci>
         <ci id="S3.SS3.p3.4.m4.1.1.3.cmml" xref="S3.SS3.p3.4.m4.1.1.3">
          𝑄
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS3.p3.4.m4.1c">
        N_{Q}
       </annotation>
      </semantics>
     </math>
     random initialized queries of
     <math alttext="D" class="ltx_Math" display="inline" id="S3.SS3.p3.5.m5.1">
      <semantics id="S3.SS3.p3.5.m5.1a">
       <mi id="S3.SS3.p3.5.m5.1.1" xref="S3.SS3.p3.5.m5.1.1.cmml">
        D
       </mi>
       <annotation-xml encoding="MathML-Content" id="S3.SS3.p3.5.m5.1b">
        <ci id="S3.SS3.p3.5.m5.1.1.cmml" xref="S3.SS3.p3.5.m5.1.1">
         𝐷
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS3.p3.5.m5.1c">
        D
       </annotation>
      </semantics>
     </math>
     dimension. This produces image token embedding
     <math alttext="X_{I_{i}^{-T}}\!\in\!\mathbb{R}^{N_{Q}\times D}" class="ltx_Math" display="inline" id="S3.SS3.p3.6.m6.1">
      <semantics id="S3.SS3.p3.6.m6.1a">
       <mrow id="S3.SS3.p3.6.m6.1.1" xref="S3.SS3.p3.6.m6.1.1.cmml">
        <msub id="S3.SS3.p3.6.m6.1.1.2" xref="S3.SS3.p3.6.m6.1.1.2.cmml">
         <mi id="S3.SS3.p3.6.m6.1.1.2.2" xref="S3.SS3.p3.6.m6.1.1.2.2.cmml">
          X
         </mi>
         <msubsup id="S3.SS3.p3.6.m6.1.1.2.3" xref="S3.SS3.p3.6.m6.1.1.2.3.cmml">
          <mi id="S3.SS3.p3.6.m6.1.1.2.3.2.2" xref="S3.SS3.p3.6.m6.1.1.2.3.2.2.cmml">
           I
          </mi>
          <mi id="S3.SS3.p3.6.m6.1.1.2.3.2.3" xref="S3.SS3.p3.6.m6.1.1.2.3.2.3.cmml">
           i
          </mi>
          <mrow id="S3.SS3.p3.6.m6.1.1.2.3.3" xref="S3.SS3.p3.6.m6.1.1.2.3.3.cmml">
           <mo id="S3.SS3.p3.6.m6.1.1.2.3.3a" xref="S3.SS3.p3.6.m6.1.1.2.3.3.cmml">
            −
           </mo>
           <mi id="S3.SS3.p3.6.m6.1.1.2.3.3.2" xref="S3.SS3.p3.6.m6.1.1.2.3.3.2.cmml">
            T
           </mi>
          </mrow>
         </msubsup>
        </msub>
        <mo id="S3.SS3.p3.6.m6.1.1.1" lspace="0.108em" rspace="0.108em" xref="S3.SS3.p3.6.m6.1.1.1.cmml">
         ∈
        </mo>
        <msup id="S3.SS3.p3.6.m6.1.1.3" xref="S3.SS3.p3.6.m6.1.1.3.cmml">
         <mi id="S3.SS3.p3.6.m6.1.1.3.2" xref="S3.SS3.p3.6.m6.1.1.3.2.cmml">
          ℝ
         </mi>
         <mrow id="S3.SS3.p3.6.m6.1.1.3.3" xref="S3.SS3.p3.6.m6.1.1.3.3.cmml">
          <msub id="S3.SS3.p3.6.m6.1.1.3.3.2" xref="S3.SS3.p3.6.m6.1.1.3.3.2.cmml">
           <mi id="S3.SS3.p3.6.m6.1.1.3.3.2.2" xref="S3.SS3.p3.6.m6.1.1.3.3.2.2.cmml">
            N
           </mi>
           <mi id="S3.SS3.p3.6.m6.1.1.3.3.2.3" xref="S3.SS3.p3.6.m6.1.1.3.3.2.3.cmml">
            Q
           </mi>
          </msub>
          <mo id="S3.SS3.p3.6.m6.1.1.3.3.1" lspace="0.222em" rspace="0.222em" xref="S3.SS3.p3.6.m6.1.1.3.3.1.cmml">
           ×
          </mo>
          <mi id="S3.SS3.p3.6.m6.1.1.3.3.3" xref="S3.SS3.p3.6.m6.1.1.3.3.3.cmml">
           D
          </mi>
         </mrow>
        </msup>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="S3.SS3.p3.6.m6.1b">
        <apply id="S3.SS3.p3.6.m6.1.1.cmml" xref="S3.SS3.p3.6.m6.1.1">
         <in id="S3.SS3.p3.6.m6.1.1.1.cmml" xref="S3.SS3.p3.6.m6.1.1.1">
         </in>
         <apply id="S3.SS3.p3.6.m6.1.1.2.cmml" xref="S3.SS3.p3.6.m6.1.1.2">
          <csymbol cd="ambiguous" id="S3.SS3.p3.6.m6.1.1.2.1.cmml" xref="S3.SS3.p3.6.m6.1.1.2">
           subscript
          </csymbol>
          <ci id="S3.SS3.p3.6.m6.1.1.2.2.cmml" xref="S3.SS3.p3.6.m6.1.1.2.2">
           𝑋
          </ci>
          <apply id="S3.SS3.p3.6.m6.1.1.2.3.cmml" xref="S3.SS3.p3.6.m6.1.1.2.3">
           <csymbol cd="ambiguous" id="S3.SS3.p3.6.m6.1.1.2.3.1.cmml" xref="S3.SS3.p3.6.m6.1.1.2.3">
            superscript
           </csymbol>
           <apply id="S3.SS3.p3.6.m6.1.1.2.3.2.cmml" xref="S3.SS3.p3.6.m6.1.1.2.3">
            <csymbol cd="ambiguous" id="S3.SS3.p3.6.m6.1.1.2.3.2.1.cmml" xref="S3.SS3.p3.6.m6.1.1.2.3">
             subscript
            </csymbol>
            <ci id="S3.SS3.p3.6.m6.1.1.2.3.2.2.cmml" xref="S3.SS3.p3.6.m6.1.1.2.3.2.2">
             𝐼
            </ci>
            <ci id="S3.SS3.p3.6.m6.1.1.2.3.2.3.cmml" xref="S3.SS3.p3.6.m6.1.1.2.3.2.3">
             𝑖
            </ci>
           </apply>
           <apply id="S3.SS3.p3.6.m6.1.1.2.3.3.cmml" xref="S3.SS3.p3.6.m6.1.1.2.3.3">
            <minus id="S3.SS3.p3.6.m6.1.1.2.3.3.1.cmml" xref="S3.SS3.p3.6.m6.1.1.2.3.3">
            </minus>
            <ci id="S3.SS3.p3.6.m6.1.1.2.3.3.2.cmml" xref="S3.SS3.p3.6.m6.1.1.2.3.3.2">
             𝑇
            </ci>
           </apply>
          </apply>
         </apply>
         <apply id="S3.SS3.p3.6.m6.1.1.3.cmml" xref="S3.SS3.p3.6.m6.1.1.3">
          <csymbol cd="ambiguous" id="S3.SS3.p3.6.m6.1.1.3.1.cmml" xref="S3.SS3.p3.6.m6.1.1.3">
           superscript
          </csymbol>
          <ci id="S3.SS3.p3.6.m6.1.1.3.2.cmml" xref="S3.SS3.p3.6.m6.1.1.3.2">
           ℝ
          </ci>
          <apply id="S3.SS3.p3.6.m6.1.1.3.3.cmml" xref="S3.SS3.p3.6.m6.1.1.3.3">
           <times id="S3.SS3.p3.6.m6.1.1.3.3.1.cmml" xref="S3.SS3.p3.6.m6.1.1.3.3.1">
           </times>
           <apply id="S3.SS3.p3.6.m6.1.1.3.3.2.cmml" xref="S3.SS3.p3.6.m6.1.1.3.3.2">
            <csymbol cd="ambiguous" id="S3.SS3.p3.6.m6.1.1.3.3.2.1.cmml" xref="S3.SS3.p3.6.m6.1.1.3.3.2">
             subscript
            </csymbol>
            <ci id="S3.SS3.p3.6.m6.1.1.3.3.2.2.cmml" xref="S3.SS3.p3.6.m6.1.1.3.3.2.2">
             𝑁
            </ci>
            <ci id="S3.SS3.p3.6.m6.1.1.3.3.2.3.cmml" xref="S3.SS3.p3.6.m6.1.1.3.3.2.3">
             𝑄
            </ci>
           </apply>
           <ci id="S3.SS3.p3.6.m6.1.1.3.3.3.cmml" xref="S3.SS3.p3.6.m6.1.1.3.3.3">
            𝐷
           </ci>
          </apply>
         </apply>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS3.p3.6.m6.1c">
        X_{I_{i}^{-T}}\!\in\!\mathbb{R}^{N_{Q}\times D}
       </annotation>
      </semantics>
     </math>
     . Then, using the image token embedding
     <math alttext="X_{I_{i}}^{-T}" class="ltx_Math" display="inline" id="S3.SS3.p3.7.m7.1">
      <semantics id="S3.SS3.p3.7.m7.1a">
       <msubsup id="S3.SS3.p3.7.m7.1.1" xref="S3.SS3.p3.7.m7.1.1.cmml">
        <mi id="S3.SS3.p3.7.m7.1.1.2.2" xref="S3.SS3.p3.7.m7.1.1.2.2.cmml">
         X
        </mi>
        <msub id="S3.SS3.p3.7.m7.1.1.2.3" xref="S3.SS3.p3.7.m7.1.1.2.3.cmml">
         <mi id="S3.SS3.p3.7.m7.1.1.2.3.2" xref="S3.SS3.p3.7.m7.1.1.2.3.2.cmml">
          I
         </mi>
         <mi id="S3.SS3.p3.7.m7.1.1.2.3.3" xref="S3.SS3.p3.7.m7.1.1.2.3.3.cmml">
          i
         </mi>
        </msub>
        <mrow id="S3.SS3.p3.7.m7.1.1.3" xref="S3.SS3.p3.7.m7.1.1.3.cmml">
         <mo id="S3.SS3.p3.7.m7.1.1.3a" xref="S3.SS3.p3.7.m7.1.1.3.cmml">
          −
         </mo>
         <mi id="S3.SS3.p3.7.m7.1.1.3.2" xref="S3.SS3.p3.7.m7.1.1.3.2.cmml">
          T
         </mi>
        </mrow>
       </msubsup>
       <annotation-xml encoding="MathML-Content" id="S3.SS3.p3.7.m7.1b">
        <apply id="S3.SS3.p3.7.m7.1.1.cmml" xref="S3.SS3.p3.7.m7.1.1">
         <csymbol cd="ambiguous" id="S3.SS3.p3.7.m7.1.1.1.cmml" xref="S3.SS3.p3.7.m7.1.1">
          superscript
         </csymbol>
         <apply id="S3.SS3.p3.7.m7.1.1.2.cmml" xref="S3.SS3.p3.7.m7.1.1">
          <csymbol cd="ambiguous" id="S3.SS3.p3.7.m7.1.1.2.1.cmml" xref="S3.SS3.p3.7.m7.1.1">
           subscript
          </csymbol>
          <ci id="S3.SS3.p3.7.m7.1.1.2.2.cmml" xref="S3.SS3.p3.7.m7.1.1.2.2">
           𝑋
          </ci>
          <apply id="S3.SS3.p3.7.m7.1.1.2.3.cmml" xref="S3.SS3.p3.7.m7.1.1.2.3">
           <csymbol cd="ambiguous" id="S3.SS3.p3.7.m7.1.1.2.3.1.cmml" xref="S3.SS3.p3.7.m7.1.1.2.3">
            subscript
           </csymbol>
           <ci id="S3.SS3.p3.7.m7.1.1.2.3.2.cmml" xref="S3.SS3.p3.7.m7.1.1.2.3.2">
            𝐼
           </ci>
           <ci id="S3.SS3.p3.7.m7.1.1.2.3.3.cmml" xref="S3.SS3.p3.7.m7.1.1.2.3.3">
            𝑖
           </ci>
          </apply>
         </apply>
         <apply id="S3.SS3.p3.7.m7.1.1.3.cmml" xref="S3.SS3.p3.7.m7.1.1.3">
          <minus id="S3.SS3.p3.7.m7.1.1.3.1.cmml" xref="S3.SS3.p3.7.m7.1.1.3">
          </minus>
          <ci id="S3.SS3.p3.7.m7.1.1.3.2.cmml" xref="S3.SS3.p3.7.m7.1.1.3.2">
           𝑇
          </ci>
         </apply>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS3.p3.7.m7.1c">
        X_{I_{i}}^{-T}
       </annotation>
      </semantics>
     </math>
     as queries of QFormer, we get the image token embedding of the next timestamp
     <math alttext="X_{I_{i}^{-T+1}}" class="ltx_Math" display="inline" id="S3.SS3.p3.8.m8.1">
      <semantics id="S3.SS3.p3.8.m8.1a">
       <msub id="S3.SS3.p3.8.m8.1.1" xref="S3.SS3.p3.8.m8.1.1.cmml">
        <mi id="S3.SS3.p3.8.m8.1.1.2" xref="S3.SS3.p3.8.m8.1.1.2.cmml">
         X
        </mi>
        <msubsup id="S3.SS3.p3.8.m8.1.1.3" xref="S3.SS3.p3.8.m8.1.1.3.cmml">
         <mi id="S3.SS3.p3.8.m8.1.1.3.2.2" xref="S3.SS3.p3.8.m8.1.1.3.2.2.cmml">
          I
         </mi>
         <mi id="S3.SS3.p3.8.m8.1.1.3.2.3" xref="S3.SS3.p3.8.m8.1.1.3.2.3.cmml">
          i
         </mi>
         <mrow id="S3.SS3.p3.8.m8.1.1.3.3" xref="S3.SS3.p3.8.m8.1.1.3.3.cmml">
          <mrow id="S3.SS3.p3.8.m8.1.1.3.3.2" xref="S3.SS3.p3.8.m8.1.1.3.3.2.cmml">
           <mo id="S3.SS3.p3.8.m8.1.1.3.3.2a" xref="S3.SS3.p3.8.m8.1.1.3.3.2.cmml">
            −
           </mo>
           <mi id="S3.SS3.p3.8.m8.1.1.3.3.2.2" xref="S3.SS3.p3.8.m8.1.1.3.3.2.2.cmml">
            T
           </mi>
          </mrow>
          <mo id="S3.SS3.p3.8.m8.1.1.3.3.1" xref="S3.SS3.p3.8.m8.1.1.3.3.1.cmml">
           +
          </mo>
          <mn id="S3.SS3.p3.8.m8.1.1.3.3.3" xref="S3.SS3.p3.8.m8.1.1.3.3.3.cmml">
           1
          </mn>
         </mrow>
        </msubsup>
       </msub>
       <annotation-xml encoding="MathML-Content" id="S3.SS3.p3.8.m8.1b">
        <apply id="S3.SS3.p3.8.m8.1.1.cmml" xref="S3.SS3.p3.8.m8.1.1">
         <csymbol cd="ambiguous" id="S3.SS3.p3.8.m8.1.1.1.cmml" xref="S3.SS3.p3.8.m8.1.1">
          subscript
         </csymbol>
         <ci id="S3.SS3.p3.8.m8.1.1.2.cmml" xref="S3.SS3.p3.8.m8.1.1.2">
          𝑋
         </ci>
         <apply id="S3.SS3.p3.8.m8.1.1.3.cmml" xref="S3.SS3.p3.8.m8.1.1.3">
          <csymbol cd="ambiguous" id="S3.SS3.p3.8.m8.1.1.3.1.cmml" xref="S3.SS3.p3.8.m8.1.1.3">
           superscript
          </csymbol>
          <apply id="S3.SS3.p3.8.m8.1.1.3.2.cmml" xref="S3.SS3.p3.8.m8.1.1.3">
           <csymbol cd="ambiguous" id="S3.SS3.p3.8.m8.1.1.3.2.1.cmml" xref="S3.SS3.p3.8.m8.1.1.3">
            subscript
           </csymbol>
           <ci id="S3.SS3.p3.8.m8.1.1.3.2.2.cmml" xref="S3.SS3.p3.8.m8.1.1.3.2.2">
            𝐼
           </ci>
           <ci id="S3.SS3.p3.8.m8.1.1.3.2.3.cmml" xref="S3.SS3.p3.8.m8.1.1.3.2.3">
            𝑖
           </ci>
          </apply>
          <apply id="S3.SS3.p3.8.m8.1.1.3.3.cmml" xref="S3.SS3.p3.8.m8.1.1.3.3">
           <plus id="S3.SS3.p3.8.m8.1.1.3.3.1.cmml" xref="S3.SS3.p3.8.m8.1.1.3.3.1">
           </plus>
           <apply id="S3.SS3.p3.8.m8.1.1.3.3.2.cmml" xref="S3.SS3.p3.8.m8.1.1.3.3.2">
            <minus id="S3.SS3.p3.8.m8.1.1.3.3.2.1.cmml" xref="S3.SS3.p3.8.m8.1.1.3.3.2">
            </minus>
            <ci id="S3.SS3.p3.8.m8.1.1.3.3.2.2.cmml" xref="S3.SS3.p3.8.m8.1.1.3.3.2.2">
             𝑇
            </ci>
           </apply>
           <cn id="S3.SS3.p3.8.m8.1.1.3.3.3.cmml" type="integer" xref="S3.SS3.p3.8.m8.1.1.3.3.3">
            1
           </cn>
          </apply>
         </apply>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS3.p3.8.m8.1c">
        X_{I_{i}^{-T+1}}
       </annotation>
      </semantics>
     </math>
     by conducting the first step again. We repeat the two steps until we get the image token embedding of the current timestamp
     <math alttext="X_{{I_{i}}^{0}}" class="ltx_Math" display="inline" id="S3.SS3.p3.9.m9.1">
      <semantics id="S3.SS3.p3.9.m9.1a">
       <msub id="S3.SS3.p3.9.m9.1.1" xref="S3.SS3.p3.9.m9.1.1.cmml">
        <mi id="S3.SS3.p3.9.m9.1.1.2" xref="S3.SS3.p3.9.m9.1.1.2.cmml">
         X
        </mi>
        <mmultiscripts id="S3.SS3.p3.9.m9.1.1.3" xref="S3.SS3.p3.9.m9.1.1.3.cmml">
         <mi id="S3.SS3.p3.9.m9.1.1.3.2.2" xref="S3.SS3.p3.9.m9.1.1.3.2.2.cmml">
          I
         </mi>
         <mi id="S3.SS3.p3.9.m9.1.1.3.2.3" xref="S3.SS3.p3.9.m9.1.1.3.2.3.cmml">
          i
         </mi>
         <mrow id="S3.SS3.p3.9.m9.1.1.3a" xref="S3.SS3.p3.9.m9.1.1.3.cmml">
         </mrow>
         <mrow id="S3.SS3.p3.9.m9.1.1.3b" xref="S3.SS3.p3.9.m9.1.1.3.cmml">
         </mrow>
         <mn id="S3.SS3.p3.9.m9.1.1.3.3" xref="S3.SS3.p3.9.m9.1.1.3.3.cmml">
          0
         </mn>
        </mmultiscripts>
       </msub>
       <annotation-xml encoding="MathML-Content" id="S3.SS3.p3.9.m9.1b">
        <apply id="S3.SS3.p3.9.m9.1.1.cmml" xref="S3.SS3.p3.9.m9.1.1">
         <csymbol cd="ambiguous" id="S3.SS3.p3.9.m9.1.1.1.cmml" xref="S3.SS3.p3.9.m9.1.1">
          subscript
         </csymbol>
         <ci id="S3.SS3.p3.9.m9.1.1.2.cmml" xref="S3.SS3.p3.9.m9.1.1.2">
          𝑋
         </ci>
         <apply id="S3.SS3.p3.9.m9.1.1.3.cmml" xref="S3.SS3.p3.9.m9.1.1.3">
          <csymbol cd="ambiguous" id="S3.SS3.p3.9.m9.1.1.3.1.cmml" xref="S3.SS3.p3.9.m9.1.1.3">
           superscript
          </csymbol>
          <apply id="S3.SS3.p3.9.m9.1.1.3.2.cmml" xref="S3.SS3.p3.9.m9.1.1.3">
           <csymbol cd="ambiguous" id="S3.SS3.p3.9.m9.1.1.3.2.1.cmml" xref="S3.SS3.p3.9.m9.1.1.3">
            subscript
           </csymbol>
           <ci id="S3.SS3.p3.9.m9.1.1.3.2.2.cmml" xref="S3.SS3.p3.9.m9.1.1.3.2.2">
            𝐼
           </ci>
           <ci id="S3.SS3.p3.9.m9.1.1.3.2.3.cmml" xref="S3.SS3.p3.9.m9.1.1.3.2.3">
            𝑖
           </ci>
          </apply>
          <cn id="S3.SS3.p3.9.m9.1.1.3.3.cmml" type="integer" xref="S3.SS3.p3.9.m9.1.1.3.3">
           0
          </cn>
         </apply>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS3.p3.9.m9.1c">
        X_{{I_{i}}^{0}}
       </annotation>
      </semantics>
     </math>
     , which gathers all temporal information from
     <math alttext="-T" class="ltx_Math" display="inline" id="S3.SS3.p3.10.m10.1">
      <semantics id="S3.SS3.p3.10.m10.1a">
       <mrow id="S3.SS3.p3.10.m10.1.1" xref="S3.SS3.p3.10.m10.1.1.cmml">
        <mo id="S3.SS3.p3.10.m10.1.1a" xref="S3.SS3.p3.10.m10.1.1.cmml">
         −
        </mo>
        <mi id="S3.SS3.p3.10.m10.1.1.2" xref="S3.SS3.p3.10.m10.1.1.2.cmml">
         T
        </mi>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="S3.SS3.p3.10.m10.1b">
        <apply id="S3.SS3.p3.10.m10.1.1.cmml" xref="S3.SS3.p3.10.m10.1.1">
         <minus id="S3.SS3.p3.10.m10.1.1.1.cmml" xref="S3.SS3.p3.10.m10.1.1">
         </minus>
         <ci id="S3.SS3.p3.10.m10.1.1.2.cmml" xref="S3.SS3.p3.10.m10.1.1.2">
          𝑇
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS3.p3.10.m10.1c">
        -T
       </annotation>
      </semantics>
     </math>
     to 0. This approach avoids the linear increase in resources required to process time series data as the length of time increases.
    </p>
   </div>
   <div class="ltx_para" id="S3.SS3.p4">
    <p class="ltx_p" id="S3.SS3.p4.3">
     (2) For LiDAR data, we first send the point clouds as the input of the Sparse Pyramid Transformer (SPT) backbone
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib74" title="">
       <span class="ltx_text" style="font-size:90%;">
        74
       </span>
      </a>
      ]
     </cite>
     to extract the LiDAR features. Then we employ Qformer with
     <math alttext="M" class="ltx_Math" display="inline" id="S3.SS3.p4.1.m1.1">
      <semantics id="S3.SS3.p4.1.m1.1a">
       <mi id="S3.SS3.p4.1.m1.1.1" xref="S3.SS3.p4.1.m1.1.1.cmml">
        M
       </mi>
       <annotation-xml encoding="MathML-Content" id="S3.SS3.p4.1.m1.1b">
        <ci id="S3.SS3.p4.1.m1.1.1.cmml" xref="S3.SS3.p4.1.m1.1.1">
         𝑀
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS3.p4.1.m1.1c">
        M
       </annotation>
      </semantics>
     </math>
     random initialized queries of
     <math alttext="D" class="ltx_Math" display="inline" id="S3.SS3.p4.2.m2.1">
      <semantics id="S3.SS3.p4.2.m2.1a">
       <mi id="S3.SS3.p4.2.m2.1.1" xref="S3.SS3.p4.2.m2.1.1.cmml">
        D
       </mi>
       <annotation-xml encoding="MathML-Content" id="S3.SS3.p4.2.m2.1b">
        <ci id="S3.SS3.p4.2.m2.1.1.cmml" xref="S3.SS3.p4.2.m2.1.1">
         𝐷
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS3.p4.2.m2.1c">
        D
       </annotation>
      </semantics>
     </math>
     dimension to get the point cloud token embedding
     <math alttext="X_{L}\!\in\!\mathbb{R}^{N_{Q}\times D}" class="ltx_Math" display="inline" id="S3.SS3.p4.3.m3.1">
      <semantics id="S3.SS3.p4.3.m3.1a">
       <mrow id="S3.SS3.p4.3.m3.1.1" xref="S3.SS3.p4.3.m3.1.1.cmml">
        <msub id="S3.SS3.p4.3.m3.1.1.2" xref="S3.SS3.p4.3.m3.1.1.2.cmml">
         <mi id="S3.SS3.p4.3.m3.1.1.2.2" xref="S3.SS3.p4.3.m3.1.1.2.2.cmml">
          X
         </mi>
         <mi id="S3.SS3.p4.3.m3.1.1.2.3" xref="S3.SS3.p4.3.m3.1.1.2.3.cmml">
          L
         </mi>
        </msub>
        <mo id="S3.SS3.p4.3.m3.1.1.1" lspace="0.108em" rspace="0.108em" xref="S3.SS3.p4.3.m3.1.1.1.cmml">
         ∈
        </mo>
        <msup id="S3.SS3.p4.3.m3.1.1.3" xref="S3.SS3.p4.3.m3.1.1.3.cmml">
         <mi id="S3.SS3.p4.3.m3.1.1.3.2" xref="S3.SS3.p4.3.m3.1.1.3.2.cmml">
          ℝ
         </mi>
         <mrow id="S3.SS3.p4.3.m3.1.1.3.3" xref="S3.SS3.p4.3.m3.1.1.3.3.cmml">
          <msub id="S3.SS3.p4.3.m3.1.1.3.3.2" xref="S3.SS3.p4.3.m3.1.1.3.3.2.cmml">
           <mi id="S3.SS3.p4.3.m3.1.1.3.3.2.2" xref="S3.SS3.p4.3.m3.1.1.3.3.2.2.cmml">
            N
           </mi>
           <mi id="S3.SS3.p4.3.m3.1.1.3.3.2.3" xref="S3.SS3.p4.3.m3.1.1.3.3.2.3.cmml">
            Q
           </mi>
          </msub>
          <mo id="S3.SS3.p4.3.m3.1.1.3.3.1" lspace="0.222em" rspace="0.222em" xref="S3.SS3.p4.3.m3.1.1.3.3.1.cmml">
           ×
          </mo>
          <mi id="S3.SS3.p4.3.m3.1.1.3.3.3" xref="S3.SS3.p4.3.m3.1.1.3.3.3.cmml">
           D
          </mi>
         </mrow>
        </msup>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="S3.SS3.p4.3.m3.1b">
        <apply id="S3.SS3.p4.3.m3.1.1.cmml" xref="S3.SS3.p4.3.m3.1.1">
         <in id="S3.SS3.p4.3.m3.1.1.1.cmml" xref="S3.SS3.p4.3.m3.1.1.1">
         </in>
         <apply id="S3.SS3.p4.3.m3.1.1.2.cmml" xref="S3.SS3.p4.3.m3.1.1.2">
          <csymbol cd="ambiguous" id="S3.SS3.p4.3.m3.1.1.2.1.cmml" xref="S3.SS3.p4.3.m3.1.1.2">
           subscript
          </csymbol>
          <ci id="S3.SS3.p4.3.m3.1.1.2.2.cmml" xref="S3.SS3.p4.3.m3.1.1.2.2">
           𝑋
          </ci>
          <ci id="S3.SS3.p4.3.m3.1.1.2.3.cmml" xref="S3.SS3.p4.3.m3.1.1.2.3">
           𝐿
          </ci>
         </apply>
         <apply id="S3.SS3.p4.3.m3.1.1.3.cmml" xref="S3.SS3.p4.3.m3.1.1.3">
          <csymbol cd="ambiguous" id="S3.SS3.p4.3.m3.1.1.3.1.cmml" xref="S3.SS3.p4.3.m3.1.1.3">
           superscript
          </csymbol>
          <ci id="S3.SS3.p4.3.m3.1.1.3.2.cmml" xref="S3.SS3.p4.3.m3.1.1.3.2">
           ℝ
          </ci>
          <apply id="S3.SS3.p4.3.m3.1.1.3.3.cmml" xref="S3.SS3.p4.3.m3.1.1.3.3">
           <times id="S3.SS3.p4.3.m3.1.1.3.3.1.cmml" xref="S3.SS3.p4.3.m3.1.1.3.3.1">
           </times>
           <apply id="S3.SS3.p4.3.m3.1.1.3.3.2.cmml" xref="S3.SS3.p4.3.m3.1.1.3.3.2">
            <csymbol cd="ambiguous" id="S3.SS3.p4.3.m3.1.1.3.3.2.1.cmml" xref="S3.SS3.p4.3.m3.1.1.3.3.2">
             subscript
            </csymbol>
            <ci id="S3.SS3.p4.3.m3.1.1.3.3.2.2.cmml" xref="S3.SS3.p4.3.m3.1.1.3.3.2.2">
             𝑁
            </ci>
            <ci id="S3.SS3.p4.3.m3.1.1.3.3.2.3.cmml" xref="S3.SS3.p4.3.m3.1.1.3.3.2.3">
             𝑄
            </ci>
           </apply>
           <ci id="S3.SS3.p4.3.m3.1.1.3.3.3.cmml" xref="S3.SS3.p4.3.m3.1.1.3.3.3">
            𝐷
           </ci>
          </apply>
         </apply>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS3.p4.3.m3.1c">
        X_{L}\!\in\!\mathbb{R}^{N_{Q}\times D}
       </annotation>
      </semantics>
     </math>
     . We concatenate it with the image token embedding.
    </p>
   </div>
   <div class="ltx_para" id="S3.SS3.p5">
    <p class="ltx_p" id="S3.SS3.p5.2">
     (3) For system messages and user instructions, we simply treat them as normal text data and use a token embedding layer of LLM to extract their embedding,
     <math alttext="X_{M}\!\in\!\mathbb{R}^{N_{M}\times D}" class="ltx_Math" display="inline" id="S3.SS3.p5.1.m1.1">
      <semantics id="S3.SS3.p5.1.m1.1a">
       <mrow id="S3.SS3.p5.1.m1.1.1" xref="S3.SS3.p5.1.m1.1.1.cmml">
        <msub id="S3.SS3.p5.1.m1.1.1.2" xref="S3.SS3.p5.1.m1.1.1.2.cmml">
         <mi id="S3.SS3.p5.1.m1.1.1.2.2" xref="S3.SS3.p5.1.m1.1.1.2.2.cmml">
          X
         </mi>
         <mi id="S3.SS3.p5.1.m1.1.1.2.3" xref="S3.SS3.p5.1.m1.1.1.2.3.cmml">
          M
         </mi>
        </msub>
        <mo id="S3.SS3.p5.1.m1.1.1.1" lspace="0.108em" rspace="0.108em" xref="S3.SS3.p5.1.m1.1.1.1.cmml">
         ∈
        </mo>
        <msup id="S3.SS3.p5.1.m1.1.1.3" xref="S3.SS3.p5.1.m1.1.1.3.cmml">
         <mi id="S3.SS3.p5.1.m1.1.1.3.2" xref="S3.SS3.p5.1.m1.1.1.3.2.cmml">
          ℝ
         </mi>
         <mrow id="S3.SS3.p5.1.m1.1.1.3.3" xref="S3.SS3.p5.1.m1.1.1.3.3.cmml">
          <msub id="S3.SS3.p5.1.m1.1.1.3.3.2" xref="S3.SS3.p5.1.m1.1.1.3.3.2.cmml">
           <mi id="S3.SS3.p5.1.m1.1.1.3.3.2.2" xref="S3.SS3.p5.1.m1.1.1.3.3.2.2.cmml">
            N
           </mi>
           <mi id="S3.SS3.p5.1.m1.1.1.3.3.2.3" xref="S3.SS3.p5.1.m1.1.1.3.3.2.3.cmml">
            M
           </mi>
          </msub>
          <mo id="S3.SS3.p5.1.m1.1.1.3.3.1" lspace="0.222em" rspace="0.222em" xref="S3.SS3.p5.1.m1.1.1.3.3.1.cmml">
           ×
          </mo>
          <mi id="S3.SS3.p5.1.m1.1.1.3.3.3" xref="S3.SS3.p5.1.m1.1.1.3.3.3.cmml">
           D
          </mi>
         </mrow>
        </msup>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="S3.SS3.p5.1.m1.1b">
        <apply id="S3.SS3.p5.1.m1.1.1.cmml" xref="S3.SS3.p5.1.m1.1.1">
         <in id="S3.SS3.p5.1.m1.1.1.1.cmml" xref="S3.SS3.p5.1.m1.1.1.1">
         </in>
         <apply id="S3.SS3.p5.1.m1.1.1.2.cmml" xref="S3.SS3.p5.1.m1.1.1.2">
          <csymbol cd="ambiguous" id="S3.SS3.p5.1.m1.1.1.2.1.cmml" xref="S3.SS3.p5.1.m1.1.1.2">
           subscript
          </csymbol>
          <ci id="S3.SS3.p5.1.m1.1.1.2.2.cmml" xref="S3.SS3.p5.1.m1.1.1.2.2">
           𝑋
          </ci>
          <ci id="S3.SS3.p5.1.m1.1.1.2.3.cmml" xref="S3.SS3.p5.1.m1.1.1.2.3">
           𝑀
          </ci>
         </apply>
         <apply id="S3.SS3.p5.1.m1.1.1.3.cmml" xref="S3.SS3.p5.1.m1.1.1.3">
          <csymbol cd="ambiguous" id="S3.SS3.p5.1.m1.1.1.3.1.cmml" xref="S3.SS3.p5.1.m1.1.1.3">
           superscript
          </csymbol>
          <ci id="S3.SS3.p5.1.m1.1.1.3.2.cmml" xref="S3.SS3.p5.1.m1.1.1.3.2">
           ℝ
          </ci>
          <apply id="S3.SS3.p5.1.m1.1.1.3.3.cmml" xref="S3.SS3.p5.1.m1.1.1.3.3">
           <times id="S3.SS3.p5.1.m1.1.1.3.3.1.cmml" xref="S3.SS3.p5.1.m1.1.1.3.3.1">
           </times>
           <apply id="S3.SS3.p5.1.m1.1.1.3.3.2.cmml" xref="S3.SS3.p5.1.m1.1.1.3.3.2">
            <csymbol cd="ambiguous" id="S3.SS3.p5.1.m1.1.1.3.3.2.1.cmml" xref="S3.SS3.p5.1.m1.1.1.3.3.2">
             subscript
            </csymbol>
            <ci id="S3.SS3.p5.1.m1.1.1.3.3.2.2.cmml" xref="S3.SS3.p5.1.m1.1.1.3.3.2.2">
             𝑁
            </ci>
            <ci id="S3.SS3.p5.1.m1.1.1.3.3.2.3.cmml" xref="S3.SS3.p5.1.m1.1.1.3.3.2.3">
             𝑀
            </ci>
           </apply>
           <ci id="S3.SS3.p5.1.m1.1.1.3.3.3.cmml" xref="S3.SS3.p5.1.m1.1.1.3.3.3">
            𝐷
           </ci>
          </apply>
         </apply>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS3.p5.1.m1.1c">
        X_{M}\!\in\!\mathbb{R}^{N_{M}\times D}
       </annotation>
      </semantics>
     </math>
     ,
     <math alttext="X_{U}\!\in\!\mathbb{R}^{N_{U}\times D}" class="ltx_Math" display="inline" id="S3.SS3.p5.2.m2.1">
      <semantics id="S3.SS3.p5.2.m2.1a">
       <mrow id="S3.SS3.p5.2.m2.1.1" xref="S3.SS3.p5.2.m2.1.1.cmml">
        <msub id="S3.SS3.p5.2.m2.1.1.2" xref="S3.SS3.p5.2.m2.1.1.2.cmml">
         <mi id="S3.SS3.p5.2.m2.1.1.2.2" xref="S3.SS3.p5.2.m2.1.1.2.2.cmml">
          X
         </mi>
         <mi id="S3.SS3.p5.2.m2.1.1.2.3" xref="S3.SS3.p5.2.m2.1.1.2.3.cmml">
          U
         </mi>
        </msub>
        <mo id="S3.SS3.p5.2.m2.1.1.1" lspace="0.108em" rspace="0.108em" xref="S3.SS3.p5.2.m2.1.1.1.cmml">
         ∈
        </mo>
        <msup id="S3.SS3.p5.2.m2.1.1.3" xref="S3.SS3.p5.2.m2.1.1.3.cmml">
         <mi id="S3.SS3.p5.2.m2.1.1.3.2" xref="S3.SS3.p5.2.m2.1.1.3.2.cmml">
          ℝ
         </mi>
         <mrow id="S3.SS3.p5.2.m2.1.1.3.3" xref="S3.SS3.p5.2.m2.1.1.3.3.cmml">
          <msub id="S3.SS3.p5.2.m2.1.1.3.3.2" xref="S3.SS3.p5.2.m2.1.1.3.3.2.cmml">
           <mi id="S3.SS3.p5.2.m2.1.1.3.3.2.2" xref="S3.SS3.p5.2.m2.1.1.3.3.2.2.cmml">
            N
           </mi>
           <mi id="S3.SS3.p5.2.m2.1.1.3.3.2.3" xref="S3.SS3.p5.2.m2.1.1.3.3.2.3.cmml">
            U
           </mi>
          </msub>
          <mo id="S3.SS3.p5.2.m2.1.1.3.3.1" lspace="0.222em" rspace="0.222em" xref="S3.SS3.p5.2.m2.1.1.3.3.1.cmml">
           ×
          </mo>
          <mi id="S3.SS3.p5.2.m2.1.1.3.3.3" xref="S3.SS3.p5.2.m2.1.1.3.3.3.cmml">
           D
          </mi>
         </mrow>
        </msup>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="S3.SS3.p5.2.m2.1b">
        <apply id="S3.SS3.p5.2.m2.1.1.cmml" xref="S3.SS3.p5.2.m2.1.1">
         <in id="S3.SS3.p5.2.m2.1.1.1.cmml" xref="S3.SS3.p5.2.m2.1.1.1">
         </in>
         <apply id="S3.SS3.p5.2.m2.1.1.2.cmml" xref="S3.SS3.p5.2.m2.1.1.2">
          <csymbol cd="ambiguous" id="S3.SS3.p5.2.m2.1.1.2.1.cmml" xref="S3.SS3.p5.2.m2.1.1.2">
           subscript
          </csymbol>
          <ci id="S3.SS3.p5.2.m2.1.1.2.2.cmml" xref="S3.SS3.p5.2.m2.1.1.2.2">
           𝑋
          </ci>
          <ci id="S3.SS3.p5.2.m2.1.1.2.3.cmml" xref="S3.SS3.p5.2.m2.1.1.2.3">
           𝑈
          </ci>
         </apply>
         <apply id="S3.SS3.p5.2.m2.1.1.3.cmml" xref="S3.SS3.p5.2.m2.1.1.3">
          <csymbol cd="ambiguous" id="S3.SS3.p5.2.m2.1.1.3.1.cmml" xref="S3.SS3.p5.2.m2.1.1.3">
           superscript
          </csymbol>
          <ci id="S3.SS3.p5.2.m2.1.1.3.2.cmml" xref="S3.SS3.p5.2.m2.1.1.3.2">
           ℝ
          </ci>
          <apply id="S3.SS3.p5.2.m2.1.1.3.3.cmml" xref="S3.SS3.p5.2.m2.1.1.3.3">
           <times id="S3.SS3.p5.2.m2.1.1.3.3.1.cmml" xref="S3.SS3.p5.2.m2.1.1.3.3.1">
           </times>
           <apply id="S3.SS3.p5.2.m2.1.1.3.3.2.cmml" xref="S3.SS3.p5.2.m2.1.1.3.3.2">
            <csymbol cd="ambiguous" id="S3.SS3.p5.2.m2.1.1.3.3.2.1.cmml" xref="S3.SS3.p5.2.m2.1.1.3.3.2">
             subscript
            </csymbol>
            <ci id="S3.SS3.p5.2.m2.1.1.3.3.2.2.cmml" xref="S3.SS3.p5.2.m2.1.1.3.3.2.2">
             𝑁
            </ci>
            <ci id="S3.SS3.p5.2.m2.1.1.3.3.2.3.cmml" xref="S3.SS3.p5.2.m2.1.1.3.3.2.3">
             𝑈
            </ci>
           </apply>
           <ci id="S3.SS3.p5.2.m2.1.1.3.3.3.cmml" xref="S3.SS3.p5.2.m2.1.1.3.3.3">
            𝐷
           </ci>
          </apply>
         </apply>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS3.p5.2.m2.1c">
        X_{U}\!\in\!\mathbb{R}^{N_{U}\times D}
       </annotation>
      </semantics>
     </math>
     .
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S3.SS3.p6">
    <p class="ltx_p" id="S3.SS3.p6.1">
     <span class="ltx_text ltx_font_bold" id="S3.SS3.p6.1.1">
      MLLM Decoder.
     </span>
     The decoder is the core that translates the tokenized inputs into decision states and decision explanations. To this end, we design a system message template for LLM-based AD, which is shown in Table
     <a class="ltx_ref" href="#S3.T1" title="Table 1 ‣ 3.2 Behavioral Planning States Alignment ‣ 3 Proposed Method ‣ DriveMLM: Aligning Multi-Modal Large Language Models with Behavioral Planning States for Autonomous Driving">
      <span class="ltx_text ltx_ref_tag">
       1
      </span>
     </a>
     .
We see that the system messages contain a description of the AD tasks, traffic rules, the definition of decision states, and placeholders indicating where each modality’s information is incorporated. This approach ensures that inputs from various modalities and sources are seamlessly integrated.
    </p>
   </div>
   <div class="ltx_para" id="S3.SS3.p7">
    <p class="ltx_p" id="S3.SS3.p7.1">
     The output is formatted to provide decision states (see the Q2 of Table
     <a class="ltx_ref" href="#S3.T1" title="Table 1 ‣ 3.2 Behavioral Planning States Alignment ‣ 3 Proposed Method ‣ DriveMLM: Aligning Multi-Modal Large Language Models with Behavioral Planning States for Autonomous Driving">
      <span class="ltx_text ltx_ref_tag">
       1
      </span>
     </a>
     ) and an explanation of the decisions (see the Q3 of Table
     <a class="ltx_ref" href="#S3.T1" title="Table 1 ‣ 3.2 Behavioral Planning States Alignment ‣ 3 Proposed Method ‣ DriveMLM: Aligning Multi-Modal Large Language Models with Behavioral Planning States for Autonomous Driving">
      <span class="ltx_text ltx_ref_tag">
       1
      </span>
     </a>
     ), offering transparency and clarity in the decision-making process. Regarding the supervision methods, our framework uses cross-entropy loss with the next token prediction, following common practices. In this way, the MLLM planner can perform detailed understanding and processing of data from different sensors and sources, and transform it into appropriate decisions and explanations.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S3.SS4">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     3.4
    </span>
    Efficient Data Engine
   </h3>
   <div class="ltx_para" id="S3.SS4.p1">
    <p class="ltx_p" id="S3.SS4.p1.1">
     We propose a data generation pipeline that can create decision states and explanation annotations from various scenarios in the CARLA simulators. This pipeline can address the limitations of existing driving data, which lack decision states and detailed explanations for training LLM-based AD systems.
Our pipeline consists of two main components: data collection and data annotation.
    </p>
   </div>
   <div class="ltx_para" id="S3.SS4.p2">
    <p class="ltx_p" id="S3.SS4.p2.1">
     The data collection is designed to improve decision variety while staying realistic.
First, various challenging scenarios are constructed in the simulator. Complex driving behaviors are required to safely drive through.
Then, experts, either experienced human drivers or agents, are asked to safely drive through these scenarios triggered at one of its many passable locations.
Notably, interaction data is generated when the expert randomly raises driving demand and drives accordingly.
Once the expert drives safely to the destination, the data is recorded.
    </p>
   </div>
   <div class="ltx_para" id="S3.SS4.p3">
    <p class="ltx_p" id="S3.SS4.p3.1">
     The data annotation mainly focuses on decision and explanation. First, speed and path decision states are automatically annotated based on experts’ driving trajectories by using hand-crafted rules. Second, explanation annotations are first generated based on the scenario, dynamically defined by current elements nearby. Third, the generated explanation annotations are refined by human annotators, and their variety is expanded by GPT-3.5. In addition, the interaction content is also refined by human annotators, including cases that are both executing or rejecting human requests.
In this way, we avoid the costly frame-by-frame decision state annotation, as well as the costly manual writing of explanation annotation from scratch, greatly speeding up our data annotation process.
    </p>
   </div>
  </section>
 </section>
 <section class="ltx_section" id="S4">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    4
   </span>
   Experiments
  </h2>
  <section class="ltx_subsection" id="S4.SS1">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     4.1
    </span>
    Data Analysis
   </h3>
   <div class="ltx_para" id="S4.SS1.p1">
    <p class="ltx_p" id="S4.SS1.p1.1">
     We have collected
     <math alttext="280" class="ltx_Math" display="inline" id="S4.SS1.p1.1.m1.1">
      <semantics id="S4.SS1.p1.1.m1.1a">
       <mn id="S4.SS1.p1.1.m1.1.1" xref="S4.SS1.p1.1.m1.1.1.cmml">
        280
       </mn>
       <annotation-xml encoding="MathML-Content" id="S4.SS1.p1.1.m1.1b">
        <cn id="S4.SS1.p1.1.m1.1.1.cmml" type="integer" xref="S4.SS1.p1.1.m1.1.1">
         280
        </cn>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S4.SS1.p1.1.m1.1c">
        280
       </annotation>
      </semantics>
     </math>
     hours of driving data for training. These data consist of 50k routes, collected in 30 driving scenarios with different weather and lighting conditions across 8 maps (Town01, Town02, Town03, Town04, Town06, Town07, Town10HD, Town12) in CARLA. On average, each scenario has about 200 trigger points on each map to be randomly triggered. Each scenario is either a common or rare safety-critical situation in driving. Details of these scenarios are in the supplementary. For each frame, we collect images from 4 cameras on the front, rear, left, and right, and also the point clouds from a LiDAR sensor added in the center of the ego vehicle.
All data we collected have corresponding explanations and accurate decisions that successfully drive through scenarios.
    </p>
   </div>
   <div class="ltx_para" id="S4.SS1.p2">
    <p class="ltx_p" id="S4.SS1.p2.1">
     Table
     <a class="ltx_ref" href="#S4.T2" title="Table 2 ‣ 4.1 Data Analysis ‣ 4 Experiments ‣ DriveMLM: Aligning Multi-Modal Large Language Models with Behavioral Planning States for Autonomous Driving">
      <span class="ltx_text ltx_ref_tag">
       2
      </span>
     </a>
     presents the comparison with the previous datasets designed for driving understanding with natural language.
Our data has two unique features. The first is the alignment of behavioral planning states. This enables us to transform the MLLM planner’s output to control signal so that our framework can control vehicles in closed-loop driving. The second is human interaction annotation. It is characterized by natural language instructions given by humans alongside the responding decisions and explanations. The objective is to improve the ability to understand human instructions and respond accordingly.
    </p>
   </div>
   <figure class="ltx_table" id="S4.T2">
    <table class="ltx_tabular ltx_align_middle" id="S4.T2.12">
     <tr class="ltx_tr" id="S4.T2.12.13">
      <td class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" id="S4.T2.12.13.1" style="padding-left:3.0pt;padding-right:3.0pt;">
       <span class="ltx_text" id="S4.T2.12.13.1.1" style="font-size:90%;">
        Dataset
       </span>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T2.12.13.2" style="padding-left:3.0pt;padding-right:3.0pt;">
       <span class="ltx_text" id="S4.T2.12.13.2.1" style="font-size:90%;">
        Perception
       </span>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T2.12.13.3" style="padding-left:3.0pt;padding-right:3.0pt;">
       <span class="ltx_text" id="S4.T2.12.13.3.1" style="font-size:90%;">
        Reason
       </span>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T2.12.13.4" style="padding-left:3.0pt;padding-right:3.0pt;">
       <span class="ltx_text" id="S4.T2.12.13.4.1" style="font-size:90%;">
        Plan
       </span>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T2.12.13.5" style="padding-left:3.0pt;padding-right:3.0pt;">
       <span class="ltx_text" id="S4.T2.12.13.5.1" style="font-size:90%;">
        Align
       </span>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T2.12.13.6" style="padding-left:3.0pt;padding-right:3.0pt;">
       <span class="ltx_text" id="S4.T2.12.13.6.1" style="font-size:90%;">
        Interact
       </span>
      </td>
     </tr>
     <tr class="ltx_tr" id="S4.T2.1.1">
      <td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T2.1.1.2" style="padding-left:3.0pt;padding-right:3.0pt;">
       <span class="ltx_text" id="S4.T2.1.1.2.1" style="font-size:90%;">
        NuPrompt
       </span>
       <cite class="ltx_cite ltx_citemacro_cite">
        <span class="ltx_text" id="S4.T2.1.1.2.2.1" style="font-size:90%;">
         [
        </span>
        <a class="ltx_ref" href="#bib.bib70" title="">
         <span class="ltx_text" style="font-size:90%;">
          70
         </span>
        </a>
        <span class="ltx_text" id="S4.T2.1.1.2.3.2" style="font-size:90%;">
         ]
        </span>
       </cite>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.1" style="padding-left:3.0pt;padding-right:3.0pt;">
       <math alttext="\checkmark" class="ltx_Math" display="inline" id="S4.T2.1.1.1.m1.1">
        <semantics id="S4.T2.1.1.1.m1.1a">
         <mi id="S4.T2.1.1.1.m1.1.1" mathsize="90%" mathvariant="normal" xref="S4.T2.1.1.1.m1.1.1.cmml">
          ✓
         </mi>
         <annotation-xml encoding="MathML-Content" id="S4.T2.1.1.1.m1.1b">
          <ci id="S4.T2.1.1.1.m1.1.1.cmml" xref="S4.T2.1.1.1.m1.1.1">
           ✓
          </ci>
         </annotation-xml>
         <annotation encoding="application/x-tex" id="S4.T2.1.1.1.m1.1c">
          \checkmark
         </annotation>
        </semantics>
       </math>
      </td>
      <td class="ltx_td ltx_border_t" id="S4.T2.1.1.3" style="padding-left:3.0pt;padding-right:3.0pt;">
      </td>
      <td class="ltx_td ltx_border_t" id="S4.T2.1.1.4" style="padding-left:3.0pt;padding-right:3.0pt;">
      </td>
      <td class="ltx_td ltx_border_t" id="S4.T2.1.1.5" style="padding-left:3.0pt;padding-right:3.0pt;">
      </td>
      <td class="ltx_td ltx_border_t" id="S4.T2.1.1.6" style="padding-left:3.0pt;padding-right:3.0pt;">
      </td>
     </tr>
     <tr class="ltx_tr" id="S4.T2.3.3">
      <td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.3.3.3" style="padding-left:3.0pt;padding-right:3.0pt;">
       <span class="ltx_text" id="S4.T2.3.3.3.1" style="font-size:90%;">
        NuScenes-QA
       </span>
       <cite class="ltx_cite ltx_citemacro_cite">
        <span class="ltx_text" id="S4.T2.3.3.3.2.1" style="font-size:90%;">
         [
        </span>
        <a class="ltx_ref" href="#bib.bib52" title="">
         <span class="ltx_text" style="font-size:90%;">
          52
         </span>
        </a>
        <span class="ltx_text" id="S4.T2.3.3.3.3.2" style="font-size:90%;">
         ]
        </span>
       </cite>
      </td>
      <td class="ltx_td ltx_align_center" id="S4.T2.2.2.1" style="padding-left:3.0pt;padding-right:3.0pt;">
       <math alttext="\checkmark" class="ltx_Math" display="inline" id="S4.T2.2.2.1.m1.1">
        <semantics id="S4.T2.2.2.1.m1.1a">
         <mi id="S4.T2.2.2.1.m1.1.1" mathsize="90%" mathvariant="normal" xref="S4.T2.2.2.1.m1.1.1.cmml">
          ✓
         </mi>
         <annotation-xml encoding="MathML-Content" id="S4.T2.2.2.1.m1.1b">
          <ci id="S4.T2.2.2.1.m1.1.1.cmml" xref="S4.T2.2.2.1.m1.1.1">
           ✓
          </ci>
         </annotation-xml>
         <annotation encoding="application/x-tex" id="S4.T2.2.2.1.m1.1c">
          \checkmark
         </annotation>
        </semantics>
       </math>
      </td>
      <td class="ltx_td ltx_align_center" id="S4.T2.3.3.2" style="padding-left:3.0pt;padding-right:3.0pt;">
       <math alttext="\checkmark" class="ltx_Math" display="inline" id="S4.T2.3.3.2.m1.1">
        <semantics id="S4.T2.3.3.2.m1.1a">
         <mi id="S4.T2.3.3.2.m1.1.1" mathsize="90%" mathvariant="normal" xref="S4.T2.3.3.2.m1.1.1.cmml">
          ✓
         </mi>
         <annotation-xml encoding="MathML-Content" id="S4.T2.3.3.2.m1.1b">
          <ci id="S4.T2.3.3.2.m1.1.1.cmml" xref="S4.T2.3.3.2.m1.1.1">
           ✓
          </ci>
         </annotation-xml>
         <annotation encoding="application/x-tex" id="S4.T2.3.3.2.m1.1c">
          \checkmark
         </annotation>
        </semantics>
       </math>
      </td>
      <td class="ltx_td" id="S4.T2.3.3.4" style="padding-left:3.0pt;padding-right:3.0pt;">
      </td>
      <td class="ltx_td" id="S4.T2.3.3.5" style="padding-left:3.0pt;padding-right:3.0pt;">
      </td>
      <td class="ltx_td" id="S4.T2.3.3.6" style="padding-left:3.0pt;padding-right:3.0pt;">
      </td>
     </tr>
     <tr class="ltx_tr" id="S4.T2.5.5">
      <td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.5.5.3" style="padding-left:3.0pt;padding-right:3.0pt;">
       <span class="ltx_text" id="S4.T2.5.5.3.1" style="font-size:90%;">
        Rank2Tell
       </span>
       <cite class="ltx_cite ltx_citemacro_cite">
        <span class="ltx_text" id="S4.T2.5.5.3.2.1" style="font-size:90%;">
         [
        </span>
        <a class="ltx_ref" href="#bib.bib55" title="">
         <span class="ltx_text" style="font-size:90%;">
          55
         </span>
        </a>
        <span class="ltx_text" id="S4.T2.5.5.3.3.2" style="font-size:90%;">
         ]
        </span>
       </cite>
      </td>
      <td class="ltx_td ltx_align_center" id="S4.T2.4.4.1" style="padding-left:3.0pt;padding-right:3.0pt;">
       <math alttext="\checkmark" class="ltx_Math" display="inline" id="S4.T2.4.4.1.m1.1">
        <semantics id="S4.T2.4.4.1.m1.1a">
         <mi id="S4.T2.4.4.1.m1.1.1" mathsize="90%" mathvariant="normal" xref="S4.T2.4.4.1.m1.1.1.cmml">
          ✓
         </mi>
         <annotation-xml encoding="MathML-Content" id="S4.T2.4.4.1.m1.1b">
          <ci id="S4.T2.4.4.1.m1.1.1.cmml" xref="S4.T2.4.4.1.m1.1.1">
           ✓
          </ci>
         </annotation-xml>
         <annotation encoding="application/x-tex" id="S4.T2.4.4.1.m1.1c">
          \checkmark
         </annotation>
        </semantics>
       </math>
      </td>
      <td class="ltx_td ltx_align_center" id="S4.T2.5.5.2" style="padding-left:3.0pt;padding-right:3.0pt;">
       <math alttext="\checkmark" class="ltx_Math" display="inline" id="S4.T2.5.5.2.m1.1">
        <semantics id="S4.T2.5.5.2.m1.1a">
         <mi id="S4.T2.5.5.2.m1.1.1" mathsize="90%" mathvariant="normal" xref="S4.T2.5.5.2.m1.1.1.cmml">
          ✓
         </mi>
         <annotation-xml encoding="MathML-Content" id="S4.T2.5.5.2.m1.1b">
          <ci id="S4.T2.5.5.2.m1.1.1.cmml" xref="S4.T2.5.5.2.m1.1.1">
           ✓
          </ci>
         </annotation-xml>
         <annotation encoding="application/x-tex" id="S4.T2.5.5.2.m1.1c">
          \checkmark
         </annotation>
        </semantics>
       </math>
      </td>
      <td class="ltx_td" id="S4.T2.5.5.4" style="padding-left:3.0pt;padding-right:3.0pt;">
      </td>
      <td class="ltx_td" id="S4.T2.5.5.5" style="padding-left:3.0pt;padding-right:3.0pt;">
      </td>
      <td class="ltx_td" id="S4.T2.5.5.6" style="padding-left:3.0pt;padding-right:3.0pt;">
      </td>
     </tr>
     <tr class="ltx_tr" id="S4.T2.7.7">
      <td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.7.7.3" style="padding-left:3.0pt;padding-right:3.0pt;">
       <span class="ltx_text" id="S4.T2.7.7.3.1" style="font-size:90%;">
        BDD-X
       </span>
       <cite class="ltx_cite ltx_citemacro_cite">
        <span class="ltx_text" id="S4.T2.7.7.3.2.1" style="font-size:90%;">
         [
        </span>
        <a class="ltx_ref" href="#bib.bib72" title="">
         <span class="ltx_text" style="font-size:90%;">
          72
         </span>
        </a>
        <span class="ltx_text" id="S4.T2.7.7.3.3.2" style="font-size:90%;">
         ]
        </span>
       </cite>
      </td>
      <td class="ltx_td" id="S4.T2.7.7.4" style="padding-left:3.0pt;padding-right:3.0pt;">
      </td>
      <td class="ltx_td ltx_align_center" id="S4.T2.6.6.1" style="padding-left:3.0pt;padding-right:3.0pt;">
       <math alttext="\checkmark" class="ltx_Math" display="inline" id="S4.T2.6.6.1.m1.1">
        <semantics id="S4.T2.6.6.1.m1.1a">
         <mi id="S4.T2.6.6.1.m1.1.1" mathsize="90%" mathvariant="normal" xref="S4.T2.6.6.1.m1.1.1.cmml">
          ✓
         </mi>
         <annotation-xml encoding="MathML-Content" id="S4.T2.6.6.1.m1.1b">
          <ci id="S4.T2.6.6.1.m1.1.1.cmml" xref="S4.T2.6.6.1.m1.1.1">
           ✓
          </ci>
         </annotation-xml>
         <annotation encoding="application/x-tex" id="S4.T2.6.6.1.m1.1c">
          \checkmark
         </annotation>
        </semantics>
       </math>
      </td>
      <td class="ltx_td ltx_align_center" id="S4.T2.7.7.2" style="padding-left:3.0pt;padding-right:3.0pt;">
       <math alttext="\checkmark" class="ltx_Math" display="inline" id="S4.T2.7.7.2.m1.1">
        <semantics id="S4.T2.7.7.2.m1.1a">
         <mi id="S4.T2.7.7.2.m1.1.1" mathsize="90%" mathvariant="normal" xref="S4.T2.7.7.2.m1.1.1.cmml">
          ✓
         </mi>
         <annotation-xml encoding="MathML-Content" id="S4.T2.7.7.2.m1.1b">
          <ci id="S4.T2.7.7.2.m1.1.1.cmml" xref="S4.T2.7.7.2.m1.1.1">
           ✓
          </ci>
         </annotation-xml>
         <annotation encoding="application/x-tex" id="S4.T2.7.7.2.m1.1c">
          \checkmark
         </annotation>
        </semantics>
       </math>
      </td>
      <td class="ltx_td" id="S4.T2.7.7.5" style="padding-left:3.0pt;padding-right:3.0pt;">
      </td>
      <td class="ltx_td" id="S4.T2.7.7.6" style="padding-left:3.0pt;padding-right:3.0pt;">
      </td>
     </tr>
     <tr class="ltx_tr" id="S4.T2.9.9">
      <td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.9.9.3" style="padding-left:3.0pt;padding-right:3.0pt;">
       <span class="ltx_text" id="S4.T2.9.9.3.1" style="font-size:90%;">
        DRAMA
       </span>
       <cite class="ltx_cite ltx_citemacro_cite">
        <span class="ltx_text" id="S4.T2.9.9.3.2.1" style="font-size:90%;">
         [
        </span>
        <a class="ltx_ref" href="#bib.bib44" title="">
         <span class="ltx_text" style="font-size:90%;">
          44
         </span>
        </a>
        <span class="ltx_text" id="S4.T2.9.9.3.3.2" style="font-size:90%;">
         ]
        </span>
       </cite>
      </td>
      <td class="ltx_td" id="S4.T2.9.9.4" style="padding-left:3.0pt;padding-right:3.0pt;">
      </td>
      <td class="ltx_td ltx_align_center" id="S4.T2.8.8.1" style="padding-left:3.0pt;padding-right:3.0pt;">
       <math alttext="\checkmark" class="ltx_Math" display="inline" id="S4.T2.8.8.1.m1.1">
        <semantics id="S4.T2.8.8.1.m1.1a">
         <mi id="S4.T2.8.8.1.m1.1.1" mathsize="90%" mathvariant="normal" xref="S4.T2.8.8.1.m1.1.1.cmml">
          ✓
         </mi>
         <annotation-xml encoding="MathML-Content" id="S4.T2.8.8.1.m1.1b">
          <ci id="S4.T2.8.8.1.m1.1.1.cmml" xref="S4.T2.8.8.1.m1.1.1">
           ✓
          </ci>
         </annotation-xml>
         <annotation encoding="application/x-tex" id="S4.T2.8.8.1.m1.1c">
          \checkmark
         </annotation>
        </semantics>
       </math>
      </td>
      <td class="ltx_td ltx_align_center" id="S4.T2.9.9.2" style="padding-left:3.0pt;padding-right:3.0pt;">
       <math alttext="\checkmark" class="ltx_Math" display="inline" id="S4.T2.9.9.2.m1.1">
        <semantics id="S4.T2.9.9.2.m1.1a">
         <mi id="S4.T2.9.9.2.m1.1.1" mathsize="90%" mathvariant="normal" xref="S4.T2.9.9.2.m1.1.1.cmml">
          ✓
         </mi>
         <annotation-xml encoding="MathML-Content" id="S4.T2.9.9.2.m1.1b">
          <ci id="S4.T2.9.9.2.m1.1.1.cmml" xref="S4.T2.9.9.2.m1.1.1">
           ✓
          </ci>
         </annotation-xml>
         <annotation encoding="application/x-tex" id="S4.T2.9.9.2.m1.1c">
          \checkmark
         </annotation>
        </semantics>
       </math>
      </td>
      <td class="ltx_td" id="S4.T2.9.9.5" style="padding-left:3.0pt;padding-right:3.0pt;">
      </td>
      <td class="ltx_td" id="S4.T2.9.9.6" style="padding-left:3.0pt;padding-right:3.0pt;">
      </td>
     </tr>
     <tr class="ltx_tr" id="S4.T2.12.12">
      <td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.12.12.4" style="padding-left:3.0pt;padding-right:3.0pt;">
       <span class="ltx_text" id="S4.T2.12.12.4.1" style="font-size:90%;">
        DriveLM
       </span>
       <cite class="ltx_cite ltx_citemacro_cite">
        <span class="ltx_text" id="S4.T2.12.12.4.2.1" style="font-size:90%;">
         [
        </span>
        <a class="ltx_ref" href="#bib.bib16" title="">
         <span class="ltx_text" style="font-size:90%;">
          16
         </span>
        </a>
        <span class="ltx_text" id="S4.T2.12.12.4.3.2" style="font-size:90%;">
         ]
        </span>
       </cite>
      </td>
      <td class="ltx_td ltx_align_center" id="S4.T2.10.10.1" style="padding-left:3.0pt;padding-right:3.0pt;">
       <math alttext="\checkmark" class="ltx_Math" display="inline" id="S4.T2.10.10.1.m1.1">
        <semantics id="S4.T2.10.10.1.m1.1a">
         <mi id="S4.T2.10.10.1.m1.1.1" mathsize="90%" mathvariant="normal" xref="S4.T2.10.10.1.m1.1.1.cmml">
          ✓
         </mi>
         <annotation-xml encoding="MathML-Content" id="S4.T2.10.10.1.m1.1b">
          <ci id="S4.T2.10.10.1.m1.1.1.cmml" xref="S4.T2.10.10.1.m1.1.1">
           ✓
          </ci>
         </annotation-xml>
         <annotation encoding="application/x-tex" id="S4.T2.10.10.1.m1.1c">
          \checkmark
         </annotation>
        </semantics>
       </math>
      </td>
      <td class="ltx_td ltx_align_center" id="S4.T2.11.11.2" style="padding-left:3.0pt;padding-right:3.0pt;">
       <math alttext="\checkmark" class="ltx_Math" display="inline" id="S4.T2.11.11.2.m1.1">
        <semantics id="S4.T2.11.11.2.m1.1a">
         <mi id="S4.T2.11.11.2.m1.1.1" mathsize="90%" mathvariant="normal" xref="S4.T2.11.11.2.m1.1.1.cmml">
          ✓
         </mi>
         <annotation-xml encoding="MathML-Content" id="S4.T2.11.11.2.m1.1b">
          <ci id="S4.T2.11.11.2.m1.1.1.cmml" xref="S4.T2.11.11.2.m1.1.1">
           ✓
          </ci>
         </annotation-xml>
         <annotation encoding="application/x-tex" id="S4.T2.11.11.2.m1.1c">
          \checkmark
         </annotation>
        </semantics>
       </math>
      </td>
      <td class="ltx_td ltx_align_center" id="S4.T2.12.12.3" style="padding-left:3.0pt;padding-right:3.0pt;">
       <math alttext="\checkmark" class="ltx_Math" display="inline" id="S4.T2.12.12.3.m1.1">
        <semantics id="S4.T2.12.12.3.m1.1a">
         <mi id="S4.T2.12.12.3.m1.1.1" mathsize="90%" mathvariant="normal" xref="S4.T2.12.12.3.m1.1.1.cmml">
          ✓
         </mi>
         <annotation-xml encoding="MathML-Content" id="S4.T2.12.12.3.m1.1b">
          <ci id="S4.T2.12.12.3.m1.1.1.cmml" xref="S4.T2.12.12.3.m1.1.1">
           ✓
          </ci>
         </annotation-xml>
         <annotation encoding="application/x-tex" id="S4.T2.12.12.3.m1.1c">
          \checkmark
         </annotation>
        </semantics>
       </math>
      </td>
      <td class="ltx_td" id="S4.T2.12.12.5" style="padding-left:3.0pt;padding-right:3.0pt;">
      </td>
      <td class="ltx_td" id="S4.T2.12.12.6" style="padding-left:3.0pt;padding-right:3.0pt;">
      </td>
     </tr>
     <tr class="ltx_tr" id="S4.T2.12.14">
      <td class="ltx_td ltx_align_left ltx_border_bb ltx_border_r" id="S4.T2.12.14.1" style="padding-left:3.0pt;padding-right:3.0pt;">
       <span class="ltx_text" id="S4.T2.12.14.1.1" style="font-size:90%;">
        Ours
       </span>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.12.14.2" style="padding-left:3.0pt;padding-right:3.0pt;">
       <span class="ltx_text" id="S4.T2.12.14.2.1" style="font-size:90%;">
        ✓
       </span>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.12.14.3" style="padding-left:3.0pt;padding-right:3.0pt;">
       <span class="ltx_text" id="S4.T2.12.14.3.1" style="font-size:90%;">
        ✓
       </span>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.12.14.4" style="padding-left:3.0pt;padding-right:3.0pt;">
       <span class="ltx_text" id="S4.T2.12.14.4.1" style="font-size:90%;">
        ✓
       </span>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.12.14.5" style="padding-left:3.0pt;padding-right:3.0pt;">
       <span class="ltx_text" id="S4.T2.12.14.5.1" style="font-size:90%;">
        ✓
       </span>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.12.14.6" style="padding-left:3.0pt;padding-right:3.0pt;">
       <span class="ltx_text" id="S4.T2.12.14.6.1" style="font-size:90%;">
        ✓
       </span>
      </td>
     </tr>
    </table>
    <figcaption class="ltx_caption" style="font-size:90%;">
     <span class="ltx_tag ltx_tag_table">
      Table 2:
     </span>
     <span class="ltx_text ltx_font_bold" id="S4.T2.17.1">
      Comparisons of AD datasets for driving understanding
     </span>
     . The alignment of behavioral planning states enables us to transform the MLLM planner’s output to control signal for closed-loop driving. The human interaction annotation enhances the model’s understanding of customized language instruction.
    </figcaption>
   </figure>
  </section>
  <section class="ltx_subsection" id="S4.SS2">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     4.2
    </span>
    Implementation Details
   </h3>
   <div class="ltx_para" id="S4.SS2.p1">
    <p class="ltx_p" id="S4.SS2.p1.6">
     Our MLLM model is built from LLaMA
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib23" title="">
       <span class="ltx_text" style="font-size:90%;">
        23
       </span>
      </a>
      ]
     </cite>
     .
Specifically, we use ViT-g/14 from EVA-CLIP
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib20" title="">
       <span class="ltx_text" style="font-size:90%;">
        20
       </span>
      </a>
      ]
     </cite>
     as the visual encoder and LLaMA-7B
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib64" title="">
       <span class="ltx_text" style="font-size:90%;">
        64
       </span>
      </a>
      ]
     </cite>
     as the LLM. The querying transformer with
     <math alttext="N_{Q}" class="ltx_Math" display="inline" id="S4.SS2.p1.1.m1.1">
      <semantics id="S4.SS2.p1.1.m1.1a">
       <msub id="S4.SS2.p1.1.m1.1.1" xref="S4.SS2.p1.1.m1.1.1.cmml">
        <mi id="S4.SS2.p1.1.m1.1.1.2" xref="S4.SS2.p1.1.m1.1.1.2.cmml">
         N
        </mi>
        <mi id="S4.SS2.p1.1.m1.1.1.3" xref="S4.SS2.p1.1.m1.1.1.3.cmml">
         Q
        </mi>
       </msub>
       <annotation-xml encoding="MathML-Content" id="S4.SS2.p1.1.m1.1b">
        <apply id="S4.SS2.p1.1.m1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1">
         <csymbol cd="ambiguous" id="S4.SS2.p1.1.m1.1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1">
          subscript
         </csymbol>
         <ci id="S4.SS2.p1.1.m1.1.1.2.cmml" xref="S4.SS2.p1.1.m1.1.1.2">
          𝑁
         </ci>
         <ci id="S4.SS2.p1.1.m1.1.1.3.cmml" xref="S4.SS2.p1.1.m1.1.1.3">
          𝑄
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S4.SS2.p1.1.m1.1c">
        N_{Q}
       </annotation>
      </semantics>
     </math>
     queries is applied to extract image tokens from ViT, where we set
     <math alttext="N_{Q}=32" class="ltx_Math" display="inline" id="S4.SS2.p1.2.m2.1">
      <semantics id="S4.SS2.p1.2.m2.1a">
       <mrow id="S4.SS2.p1.2.m2.1.1" xref="S4.SS2.p1.2.m2.1.1.cmml">
        <msub id="S4.SS2.p1.2.m2.1.1.2" xref="S4.SS2.p1.2.m2.1.1.2.cmml">
         <mi id="S4.SS2.p1.2.m2.1.1.2.2" xref="S4.SS2.p1.2.m2.1.1.2.2.cmml">
          N
         </mi>
         <mi id="S4.SS2.p1.2.m2.1.1.2.3" xref="S4.SS2.p1.2.m2.1.1.2.3.cmml">
          Q
         </mi>
        </msub>
        <mo id="S4.SS2.p1.2.m2.1.1.1" xref="S4.SS2.p1.2.m2.1.1.1.cmml">
         =
        </mo>
        <mn id="S4.SS2.p1.2.m2.1.1.3" xref="S4.SS2.p1.2.m2.1.1.3.cmml">
         32
        </mn>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="S4.SS2.p1.2.m2.1b">
        <apply id="S4.SS2.p1.2.m2.1.1.cmml" xref="S4.SS2.p1.2.m2.1.1">
         <eq id="S4.SS2.p1.2.m2.1.1.1.cmml" xref="S4.SS2.p1.2.m2.1.1.1">
         </eq>
         <apply id="S4.SS2.p1.2.m2.1.1.2.cmml" xref="S4.SS2.p1.2.m2.1.1.2">
          <csymbol cd="ambiguous" id="S4.SS2.p1.2.m2.1.1.2.1.cmml" xref="S4.SS2.p1.2.m2.1.1.2">
           subscript
          </csymbol>
          <ci id="S4.SS2.p1.2.m2.1.1.2.2.cmml" xref="S4.SS2.p1.2.m2.1.1.2.2">
           𝑁
          </ci>
          <ci id="S4.SS2.p1.2.m2.1.1.2.3.cmml" xref="S4.SS2.p1.2.m2.1.1.2.3">
           𝑄
          </ci>
         </apply>
         <cn id="S4.SS2.p1.2.m2.1.1.3.cmml" type="integer" xref="S4.SS2.p1.2.m2.1.1.3">
          32
         </cn>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S4.SS2.p1.2.m2.1c">
        N_{Q}=32
       </annotation>
      </semantics>
     </math>
     . For the LiDAR encoder, we use the GD-MAE
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib74" title="">
       <span class="ltx_text" style="font-size:90%;">
        74
       </span>
      </a>
      ]
     </cite>
     model finetuned on ONCE
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib42" title="">
       <span class="ltx_text" style="font-size:90%;">
        42
       </span>
      </a>
      ]
     </cite>
     . Based on the pre-trained husky model, we train MLLM with instruction following data.
We employ the AdamW optimizer with
     <math alttext="\beta_{1}=0.9" class="ltx_Math" display="inline" id="S4.SS2.p1.3.m3.1">
      <semantics id="S4.SS2.p1.3.m3.1a">
       <mrow id="S4.SS2.p1.3.m3.1.1" xref="S4.SS2.p1.3.m3.1.1.cmml">
        <msub id="S4.SS2.p1.3.m3.1.1.2" xref="S4.SS2.p1.3.m3.1.1.2.cmml">
         <mi id="S4.SS2.p1.3.m3.1.1.2.2" xref="S4.SS2.p1.3.m3.1.1.2.2.cmml">
          β
         </mi>
         <mn id="S4.SS2.p1.3.m3.1.1.2.3" xref="S4.SS2.p1.3.m3.1.1.2.3.cmml">
          1
         </mn>
        </msub>
        <mo id="S4.SS2.p1.3.m3.1.1.1" xref="S4.SS2.p1.3.m3.1.1.1.cmml">
         =
        </mo>
        <mn id="S4.SS2.p1.3.m3.1.1.3" xref="S4.SS2.p1.3.m3.1.1.3.cmml">
         0.9
        </mn>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="S4.SS2.p1.3.m3.1b">
        <apply id="S4.SS2.p1.3.m3.1.1.cmml" xref="S4.SS2.p1.3.m3.1.1">
         <eq id="S4.SS2.p1.3.m3.1.1.1.cmml" xref="S4.SS2.p1.3.m3.1.1.1">
         </eq>
         <apply id="S4.SS2.p1.3.m3.1.1.2.cmml" xref="S4.SS2.p1.3.m3.1.1.2">
          <csymbol cd="ambiguous" id="S4.SS2.p1.3.m3.1.1.2.1.cmml" xref="S4.SS2.p1.3.m3.1.1.2">
           subscript
          </csymbol>
          <ci id="S4.SS2.p1.3.m3.1.1.2.2.cmml" xref="S4.SS2.p1.3.m3.1.1.2.2">
           𝛽
          </ci>
          <cn id="S4.SS2.p1.3.m3.1.1.2.3.cmml" type="integer" xref="S4.SS2.p1.3.m3.1.1.2.3">
           1
          </cn>
         </apply>
         <cn id="S4.SS2.p1.3.m3.1.1.3.cmml" type="float" xref="S4.SS2.p1.3.m3.1.1.3">
          0.9
         </cn>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S4.SS2.p1.3.m3.1c">
        \beta_{1}=0.9
       </annotation>
      </semantics>
     </math>
     ,
     <math alttext="\beta_{2}=0.95" class="ltx_Math" display="inline" id="S4.SS2.p1.4.m4.1">
      <semantics id="S4.SS2.p1.4.m4.1a">
       <mrow id="S4.SS2.p1.4.m4.1.1" xref="S4.SS2.p1.4.m4.1.1.cmml">
        <msub id="S4.SS2.p1.4.m4.1.1.2" xref="S4.SS2.p1.4.m4.1.1.2.cmml">
         <mi id="S4.SS2.p1.4.m4.1.1.2.2" xref="S4.SS2.p1.4.m4.1.1.2.2.cmml">
          β
         </mi>
         <mn id="S4.SS2.p1.4.m4.1.1.2.3" xref="S4.SS2.p1.4.m4.1.1.2.3.cmml">
          2
         </mn>
        </msub>
        <mo id="S4.SS2.p1.4.m4.1.1.1" xref="S4.SS2.p1.4.m4.1.1.1.cmml">
         =
        </mo>
        <mn id="S4.SS2.p1.4.m4.1.1.3" xref="S4.SS2.p1.4.m4.1.1.3.cmml">
         0.95
        </mn>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="S4.SS2.p1.4.m4.1b">
        <apply id="S4.SS2.p1.4.m4.1.1.cmml" xref="S4.SS2.p1.4.m4.1.1">
         <eq id="S4.SS2.p1.4.m4.1.1.1.cmml" xref="S4.SS2.p1.4.m4.1.1.1">
         </eq>
         <apply id="S4.SS2.p1.4.m4.1.1.2.cmml" xref="S4.SS2.p1.4.m4.1.1.2">
          <csymbol cd="ambiguous" id="S4.SS2.p1.4.m4.1.1.2.1.cmml" xref="S4.SS2.p1.4.m4.1.1.2">
           subscript
          </csymbol>
          <ci id="S4.SS2.p1.4.m4.1.1.2.2.cmml" xref="S4.SS2.p1.4.m4.1.1.2.2">
           𝛽
          </ci>
          <cn id="S4.SS2.p1.4.m4.1.1.2.3.cmml" type="integer" xref="S4.SS2.p1.4.m4.1.1.2.3">
           2
          </cn>
         </apply>
         <cn id="S4.SS2.p1.4.m4.1.1.3.cmml" type="float" xref="S4.SS2.p1.4.m4.1.1.3">
          0.95
         </cn>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S4.SS2.p1.4.m4.1c">
        \beta_{2}=0.95
       </annotation>
      </semantics>
     </math>
     , and a cosine learning rate decay with learning rate
     <math alttext="5e^{-5}" class="ltx_Math" display="inline" id="S4.SS2.p1.5.m5.1">
      <semantics id="S4.SS2.p1.5.m5.1a">
       <mrow id="S4.SS2.p1.5.m5.1.1" xref="S4.SS2.p1.5.m5.1.1.cmml">
        <mn id="S4.SS2.p1.5.m5.1.1.2" xref="S4.SS2.p1.5.m5.1.1.2.cmml">
         5
        </mn>
        <mo id="S4.SS2.p1.5.m5.1.1.1" lspace="0em" rspace="0em" xref="S4.SS2.p1.5.m5.1.1.1.cmml">
         ​
        </mo>
        <msup id="S4.SS2.p1.5.m5.1.1.3" xref="S4.SS2.p1.5.m5.1.1.3.cmml">
         <mi id="S4.SS2.p1.5.m5.1.1.3.2" xref="S4.SS2.p1.5.m5.1.1.3.2.cmml">
          e
         </mi>
         <mrow id="S4.SS2.p1.5.m5.1.1.3.3" xref="S4.SS2.p1.5.m5.1.1.3.3.cmml">
          <mo id="S4.SS2.p1.5.m5.1.1.3.3a" xref="S4.SS2.p1.5.m5.1.1.3.3.cmml">
           −
          </mo>
          <mn id="S4.SS2.p1.5.m5.1.1.3.3.2" xref="S4.SS2.p1.5.m5.1.1.3.3.2.cmml">
           5
          </mn>
         </mrow>
        </msup>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="S4.SS2.p1.5.m5.1b">
        <apply id="S4.SS2.p1.5.m5.1.1.cmml" xref="S4.SS2.p1.5.m5.1.1">
         <times id="S4.SS2.p1.5.m5.1.1.1.cmml" xref="S4.SS2.p1.5.m5.1.1.1">
         </times>
         <cn id="S4.SS2.p1.5.m5.1.1.2.cmml" type="integer" xref="S4.SS2.p1.5.m5.1.1.2">
          5
         </cn>
         <apply id="S4.SS2.p1.5.m5.1.1.3.cmml" xref="S4.SS2.p1.5.m5.1.1.3">
          <csymbol cd="ambiguous" id="S4.SS2.p1.5.m5.1.1.3.1.cmml" xref="S4.SS2.p1.5.m5.1.1.3">
           superscript
          </csymbol>
          <ci id="S4.SS2.p1.5.m5.1.1.3.2.cmml" xref="S4.SS2.p1.5.m5.1.1.3.2">
           𝑒
          </ci>
          <apply id="S4.SS2.p1.5.m5.1.1.3.3.cmml" xref="S4.SS2.p1.5.m5.1.1.3.3">
           <minus id="S4.SS2.p1.5.m5.1.1.3.3.1.cmml" xref="S4.SS2.p1.5.m5.1.1.3.3">
           </minus>
           <cn id="S4.SS2.p1.5.m5.1.1.3.3.2.cmml" type="integer" xref="S4.SS2.p1.5.m5.1.1.3.3.2">
            5
           </cn>
          </apply>
         </apply>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S4.SS2.p1.5.m5.1c">
        5e^{-5}
       </annotation>
      </semantics>
     </math>
     . The training epoch is 2, and the batch size is 256.
We train QFormer and LLM to ensure the instruction following ability of LLM so that we can obtain a predefined format of path decision and speed decision.
The resolution of image input to MLLM is set as
     <math alttext="448\times 448" class="ltx_Math" display="inline" id="S4.SS2.p1.6.m6.1">
      <semantics id="S4.SS2.p1.6.m6.1a">
       <mrow id="S4.SS2.p1.6.m6.1.1" xref="S4.SS2.p1.6.m6.1.1.cmml">
        <mn id="S4.SS2.p1.6.m6.1.1.2" xref="S4.SS2.p1.6.m6.1.1.2.cmml">
         448
        </mn>
        <mo id="S4.SS2.p1.6.m6.1.1.1" lspace="0.222em" rspace="0.222em" xref="S4.SS2.p1.6.m6.1.1.1.cmml">
         ×
        </mo>
        <mn id="S4.SS2.p1.6.m6.1.1.3" xref="S4.SS2.p1.6.m6.1.1.3.cmml">
         448
        </mn>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="S4.SS2.p1.6.m6.1b">
        <apply id="S4.SS2.p1.6.m6.1.1.cmml" xref="S4.SS2.p1.6.m6.1.1">
         <times id="S4.SS2.p1.6.m6.1.1.1.cmml" xref="S4.SS2.p1.6.m6.1.1.1">
         </times>
         <cn id="S4.SS2.p1.6.m6.1.1.2.cmml" type="integer" xref="S4.SS2.p1.6.m6.1.1.2">
          448
         </cn>
         <cn id="S4.SS2.p1.6.m6.1.1.3.cmml" type="integer" xref="S4.SS2.p1.6.m6.1.1.3">
          448
         </cn>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S4.SS2.p1.6.m6.1c">
        448\times 448
       </annotation>
      </semantics>
     </math>
     .
    </p>
   </div>
   <figure class="ltx_table" id="S4.T3">
    <table class="ltx_tabular ltx_centering ltx_align_middle" id="S4.T3.11">
     <tr class="ltx_tr" id="S4.T3.11.11">
      <td class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" id="S4.T3.11.11.12" rowspan="2" style="padding-left:3.0pt;padding-right:3.0pt;">
       <span class="ltx_text" id="S4.T3.11.11.12.1" style="font-size:90%;">
        Method
       </span>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S4.T3.11.11.13" rowspan="2" style="padding-left:3.0pt;padding-right:3.0pt;">
       <span class="ltx_text" id="S4.T3.11.11.13.1" style="font-size:90%;">
        Type
       </span>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S4.T3.2.2.2" rowspan="2" style="padding-left:3.0pt;padding-right:3.0pt;">
       <span class="ltx_text" id="S4.T3.2.2.2.2" style="font-size:90%;">
        Acc.
        <math alttext="(\%)" class="ltx_math_unparsed" display="inline" id="S4.T3.1.1.1.1.m1.1">
         <semantics id="S4.T3.1.1.1.1.m1.1a">
          <mrow id="S4.T3.1.1.1.1.m1.1b">
           <mo id="S4.T3.1.1.1.1.m1.1.1" stretchy="false">
            (
           </mo>
           <mo id="S4.T3.1.1.1.1.m1.1.2">
            %
           </mo>
           <mo id="S4.T3.1.1.1.1.m1.1.3" stretchy="false">
            )
           </mo>
          </mrow>
          <annotation encoding="application/x-tex" id="S4.T3.1.1.1.1.m1.1c">
           (\%)
          </annotation>
         </semantics>
        </math>
        <math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T3.2.2.2.2.m2.1">
         <semantics id="S4.T3.2.2.2.2.m2.1a">
          <mo id="S4.T3.2.2.2.2.m2.1.1" stretchy="false" xref="S4.T3.2.2.2.2.m2.1.1.cmml">
           ↑
          </mo>
          <annotation-xml encoding="MathML-Content" id="S4.T3.2.2.2.2.m2.1b">
           <ci id="S4.T3.2.2.2.2.m2.1.1.cmml" xref="S4.T3.2.2.2.2.m2.1.1">
            ↑
           </ci>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="S4.T3.2.2.2.2.m2.1c">
           \uparrow
          </annotation>
         </semantics>
        </math>
       </span>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="3" id="S4.T3.5.5.5" style="padding-left:3.0pt;padding-right:3.0pt;">
       <span class="ltx_text" id="S4.T3.5.5.5.1" style="font-size:90%;">
        Path
       </span>
       <math alttext="(" class="ltx_Math" display="inline" id="S4.T3.3.3.3.m1.1">
        <semantics id="S4.T3.3.3.3.m1.1a">
         <mo id="S4.T3.3.3.3.m1.1.1" maxsize="90%" minsize="90%" xref="S4.T3.3.3.3.m1.1.1.cmml">
          (
         </mo>
         <annotation-xml encoding="MathML-Content" id="S4.T3.3.3.3.m1.1b">
          <ci id="S4.T3.3.3.3.m1.1.1.cmml" xref="S4.T3.3.3.3.m1.1.1">
           (
          </ci>
         </annotation-xml>
         <annotation encoding="application/x-tex" id="S4.T3.3.3.3.m1.1c">
          (
         </annotation>
        </semantics>
       </math>
       <span class="ltx_text" id="S4.T3.5.5.5.2" style="font-size:90%;">
        F1
       </span>
       <math alttext=")" class="ltx_Math" display="inline" id="S4.T3.4.4.4.m2.1">
        <semantics id="S4.T3.4.4.4.m2.1a">
         <mo id="S4.T3.4.4.4.m2.1.1" maxsize="90%" minsize="90%" xref="S4.T3.4.4.4.m2.1.1.cmml">
          )
         </mo>
         <annotation-xml encoding="MathML-Content" id="S4.T3.4.4.4.m2.1b">
          <ci id="S4.T3.4.4.4.m2.1.1.cmml" xref="S4.T3.4.4.4.m2.1.1">
           )
          </ci>
         </annotation-xml>
         <annotation encoding="application/x-tex" id="S4.T3.4.4.4.m2.1c">
          )
         </annotation>
        </semantics>
       </math>
       <span class="ltx_text" id="S4.T3.5.5.5.3" style="font-size:90%;">
       </span>
       <math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T3.5.5.5.m3.1">
        <semantics id="S4.T3.5.5.5.m3.1a">
         <mo id="S4.T3.5.5.5.m3.1.1" mathsize="90%" stretchy="false" xref="S4.T3.5.5.5.m3.1.1.cmml">
          ↑
         </mo>
         <annotation-xml encoding="MathML-Content" id="S4.T3.5.5.5.m3.1b">
          <ci id="S4.T3.5.5.5.m3.1.1.cmml" xref="S4.T3.5.5.5.m3.1.1">
           ↑
          </ci>
         </annotation-xml>
         <annotation encoding="application/x-tex" id="S4.T3.5.5.5.m3.1c">
          \uparrow
         </annotation>
        </semantics>
       </math>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="4" id="S4.T3.8.8.8" style="padding-left:3.0pt;padding-right:3.0pt;">
       <span class="ltx_text" id="S4.T3.8.8.8.1" style="font-size:90%;">
        Speed
       </span>
       <math alttext="(" class="ltx_Math" display="inline" id="S4.T3.6.6.6.m1.1">
        <semantics id="S4.T3.6.6.6.m1.1a">
         <mo id="S4.T3.6.6.6.m1.1.1" maxsize="90%" minsize="90%" xref="S4.T3.6.6.6.m1.1.1.cmml">
          (
         </mo>
         <annotation-xml encoding="MathML-Content" id="S4.T3.6.6.6.m1.1b">
          <ci id="S4.T3.6.6.6.m1.1.1.cmml" xref="S4.T3.6.6.6.m1.1.1">
           (
          </ci>
         </annotation-xml>
         <annotation encoding="application/x-tex" id="S4.T3.6.6.6.m1.1c">
          (
         </annotation>
        </semantics>
       </math>
       <span class="ltx_text" id="S4.T3.8.8.8.2" style="font-size:90%;">
        F1
       </span>
       <math alttext=")" class="ltx_Math" display="inline" id="S4.T3.7.7.7.m2.1">
        <semantics id="S4.T3.7.7.7.m2.1a">
         <mo id="S4.T3.7.7.7.m2.1.1" maxsize="90%" minsize="90%" xref="S4.T3.7.7.7.m2.1.1.cmml">
          )
         </mo>
         <annotation-xml encoding="MathML-Content" id="S4.T3.7.7.7.m2.1b">
          <ci id="S4.T3.7.7.7.m2.1.1.cmml" xref="S4.T3.7.7.7.m2.1.1">
           )
          </ci>
         </annotation-xml>
         <annotation encoding="application/x-tex" id="S4.T3.7.7.7.m2.1c">
          )
         </annotation>
        </semantics>
       </math>
       <span class="ltx_text" id="S4.T3.8.8.8.3" style="font-size:90%;">
       </span>
       <math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T3.8.8.8.m3.1">
        <semantics id="S4.T3.8.8.8.m3.1a">
         <mo id="S4.T3.8.8.8.m3.1.1" mathsize="90%" stretchy="false" xref="S4.T3.8.8.8.m3.1.1.cmml">
          ↑
         </mo>
         <annotation-xml encoding="MathML-Content" id="S4.T3.8.8.8.m3.1b">
          <ci id="S4.T3.8.8.8.m3.1.1.cmml" xref="S4.T3.8.8.8.m3.1.1">
           ↑
          </ci>
         </annotation-xml>
         <annotation encoding="application/x-tex" id="S4.T3.8.8.8.m3.1c">
          \uparrow
         </annotation>
        </semantics>
       </math>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T3.9.9.9" rowspan="2" style="padding-left:3.0pt;padding-right:3.0pt;">
       <span class="ltx_text" id="S4.T3.9.9.9.1" style="font-size:90%;">
        BLEU-4
        <math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T3.9.9.9.1.m1.1">
         <semantics id="S4.T3.9.9.9.1.m1.1a">
          <mo id="S4.T3.9.9.9.1.m1.1.1" stretchy="false" xref="S4.T3.9.9.9.1.m1.1.1.cmml">
           ↑
          </mo>
          <annotation-xml encoding="MathML-Content" id="S4.T3.9.9.9.1.m1.1b">
           <ci id="S4.T3.9.9.9.1.m1.1.1.cmml" xref="S4.T3.9.9.9.1.m1.1.1">
            ↑
           </ci>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="S4.T3.9.9.9.1.m1.1c">
           \uparrow
          </annotation>
         </semantics>
        </math>
       </span>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T3.10.10.10" rowspan="2" style="padding-left:3.0pt;padding-right:3.0pt;">
       <span class="ltx_text" id="S4.T3.10.10.10.1" style="font-size:90%;">
        CIDEr
        <math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T3.10.10.10.1.m1.1">
         <semantics id="S4.T3.10.10.10.1.m1.1a">
          <mo id="S4.T3.10.10.10.1.m1.1.1" stretchy="false" xref="S4.T3.10.10.10.1.m1.1.1.cmml">
           ↑
          </mo>
          <annotation-xml encoding="MathML-Content" id="S4.T3.10.10.10.1.m1.1b">
           <ci id="S4.T3.10.10.10.1.m1.1.1.cmml" xref="S4.T3.10.10.10.1.m1.1.1">
            ↑
           </ci>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="S4.T3.10.10.10.1.m1.1c">
           \uparrow
          </annotation>
         </semantics>
        </math>
       </span>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T3.11.11.11" rowspan="2" style="padding-left:3.0pt;padding-right:3.0pt;">
       <span class="ltx_text" id="S4.T3.11.11.11.1" style="font-size:90%;">
        METEOR
        <math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T3.11.11.11.1.m1.1">
         <semantics id="S4.T3.11.11.11.1.m1.1a">
          <mo id="S4.T3.11.11.11.1.m1.1.1" stretchy="false" xref="S4.T3.11.11.11.1.m1.1.1.cmml">
           ↑
          </mo>
          <annotation-xml encoding="MathML-Content" id="S4.T3.11.11.11.1.m1.1b">
           <ci id="S4.T3.11.11.11.1.m1.1.1.cmml" xref="S4.T3.11.11.11.1.m1.1.1">
            ↑
           </ci>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="S4.T3.11.11.11.1.m1.1c">
           \uparrow
          </annotation>
         </semantics>
        </math>
       </span>
      </td>
     </tr>
     <tr class="ltx_tr" id="S4.T3.11.12">
      <td class="ltx_td ltx_align_center" id="S4.T3.11.12.1" style="padding-left:3.0pt;padding-right:3.0pt;">
       <span class="ltx_text" id="S4.T3.11.12.1.1" style="font-size:90%;">
        follow
       </span>
      </td>
      <td class="ltx_td ltx_align_center" id="S4.T3.11.12.2" style="padding-left:3.0pt;padding-right:3.0pt;">
       <span class="ltx_text" id="S4.T3.11.12.2.1" style="font-size:90%;">
        change
       </span>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_r" id="S4.T3.11.12.3" style="padding-left:3.0pt;padding-right:3.0pt;">
       <span class="ltx_text" id="S4.T3.11.12.3.1" style="font-size:90%;">
        borrow
       </span>
      </td>
      <td class="ltx_td ltx_align_center" id="S4.T3.11.12.4" style="padding-left:3.0pt;padding-right:3.0pt;">
       <span class="ltx_text" id="S4.T3.11.12.4.1" style="font-size:90%;">
        keep
       </span>
      </td>
      <td class="ltx_td ltx_align_center" id="S4.T3.11.12.5" style="padding-left:3.0pt;padding-right:3.0pt;">
       <span class="ltx_text" id="S4.T3.11.12.5.1" style="font-size:90%;">
        accelerate
       </span>
      </td>
      <td class="ltx_td ltx_align_center" id="S4.T3.11.12.6" style="padding-left:3.0pt;padding-right:3.0pt;">
       <span class="ltx_text" id="S4.T3.11.12.6.1" style="font-size:90%;">
        decelerate
       </span>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_r" id="S4.T3.11.12.7" style="padding-left:3.0pt;padding-right:3.0pt;">
       <span class="ltx_text" id="S4.T3.11.12.7.1" style="font-size:90%;">
        stop
       </span>
      </td>
     </tr>
     <tr class="ltx_tr" id="S4.T3.11.13">
      <td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T3.11.13.1" style="padding-left:3.0pt;padding-right:3.0pt;">
       <span class="ltx_text" id="S4.T3.11.13.1.1" style="font-size:90%;">
        LLaVA 1.5
       </span>
       <cite class="ltx_cite ltx_citemacro_cite">
        <span class="ltx_text" id="S4.T3.11.13.1.2.1" style="font-size:90%;">
         [
        </span>
        <a class="ltx_ref" href="#bib.bib37" title="">
         <span class="ltx_text" style="font-size:90%;">
          37
         </span>
        </a>
        <span class="ltx_text" id="S4.T3.11.13.1.3.2" style="font-size:90%;">
         ]
        </span>
       </cite>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.11.13.2" style="padding-left:3.0pt;padding-right:3.0pt;">
       <span class="ltx_text" id="S4.T3.11.13.2.1" style="font-size:90%;">
        LLM
       </span>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.11.13.3" style="padding-left:3.0pt;padding-right:3.0pt;">
       <span class="ltx_text" id="S4.T3.11.13.3.1" style="font-size:90%;">
        22.92
       </span>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.11.13.4" style="padding-left:3.0pt;padding-right:3.0pt;">
       <span class="ltx_text" id="S4.T3.11.13.4.1" style="font-size:90%;">
        0.73
       </span>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.11.13.5" style="padding-left:3.0pt;padding-right:3.0pt;">
       <span class="ltx_text" id="S4.T3.11.13.5.1" style="font-size:90%;">
        0.00
       </span>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.11.13.6" style="padding-left:3.0pt;padding-right:3.0pt;">
       <span class="ltx_text" id="S4.T3.11.13.6.1" style="font-size:90%;">
        0.00
       </span>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.11.13.7" style="padding-left:3.0pt;padding-right:3.0pt;">
       <span class="ltx_text" id="S4.T3.11.13.7.1" style="font-size:90%;">
        0.75
       </span>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.11.13.8" style="padding-left:3.0pt;padding-right:3.0pt;">
       <span class="ltx_text" id="S4.T3.11.13.8.1" style="font-size:90%;">
        0.00
       </span>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.11.13.9" style="padding-left:3.0pt;padding-right:3.0pt;">
       <span class="ltx_text" id="S4.T3.11.13.9.1" style="font-size:90%;">
        0.02
       </span>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.11.13.10" style="padding-left:3.0pt;padding-right:3.0pt;">
       <span class="ltx_text" id="S4.T3.11.13.10.1" style="font-size:90%;">
        0.00
       </span>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.11.13.11" style="padding-left:3.0pt;padding-right:3.0pt;">
       <span class="ltx_text" id="S4.T3.11.13.11.1" style="font-size:90%;">
        10.00
       </span>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.11.13.12" style="padding-left:3.0pt;padding-right:3.0pt;">
       <span class="ltx_text" id="S4.T3.11.13.12.1" style="font-size:90%;">
        18.03
       </span>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.11.13.13" style="padding-left:3.0pt;padding-right:3.0pt;">
       <span class="ltx_text" id="S4.T3.11.13.13.1" style="font-size:90%;">
        23.00
       </span>
      </td>
     </tr>
     <tr class="ltx_tr" id="S4.T3.11.14">
      <td class="ltx_td ltx_align_left ltx_border_r" id="S4.T3.11.14.1" style="padding-left:3.0pt;padding-right:3.0pt;">
       <span class="ltx_text" id="S4.T3.11.14.1.1" style="font-size:90%;">
        InstructBLIP
       </span>
       <cite class="ltx_cite ltx_citemacro_cite">
        <span class="ltx_text" id="S4.T3.11.14.1.2.1" style="font-size:90%;">
         [
        </span>
        <a class="ltx_ref" href="#bib.bib17" title="">
         <span class="ltx_text" style="font-size:90%;">
          17
         </span>
        </a>
        <span class="ltx_text" id="S4.T3.11.14.1.3.2" style="font-size:90%;">
         ]
        </span>
       </cite>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_r" id="S4.T3.11.14.2" style="padding-left:3.0pt;padding-right:3.0pt;">
       <span class="ltx_text" id="S4.T3.11.14.2.1" style="font-size:90%;">
        LLM
       </span>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_r" id="S4.T3.11.14.3" style="padding-left:3.0pt;padding-right:3.0pt;">
       <span class="ltx_text" id="S4.T3.11.14.3.1" style="font-size:90%;">
        17.92
       </span>
      </td>
      <td class="ltx_td ltx_align_center" id="S4.T3.11.14.4" style="padding-left:3.0pt;padding-right:3.0pt;">
       <span class="ltx_text" id="S4.T3.11.14.4.1" style="font-size:90%;">
        0.00
       </span>
      </td>
      <td class="ltx_td ltx_align_center" id="S4.T3.11.14.5" style="padding-left:3.0pt;padding-right:3.0pt;">
       <span class="ltx_text" id="S4.T3.11.14.5.1" style="font-size:90%;">
        0.30
       </span>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_r" id="S4.T3.11.14.6" style="padding-left:3.0pt;padding-right:3.0pt;">
       <span class="ltx_text" id="S4.T3.11.14.6.1" style="font-size:90%;">
        0.08
       </span>
      </td>
      <td class="ltx_td ltx_align_center" id="S4.T3.11.14.7" style="padding-left:3.0pt;padding-right:3.0pt;">
       <span class="ltx_text" id="S4.T3.11.14.7.1" style="font-size:90%;">
        0.23
       </span>
      </td>
      <td class="ltx_td ltx_align_center" id="S4.T3.11.14.8" style="padding-left:3.0pt;padding-right:3.0pt;">
       <span class="ltx_text" id="S4.T3.11.14.8.1" style="font-size:90%;">
        0.00
       </span>
      </td>
      <td class="ltx_td ltx_align_center" id="S4.T3.11.14.9" style="padding-left:3.0pt;padding-right:3.0pt;">
       <span class="ltx_text" id="S4.T3.11.14.9.1" style="font-size:90%;">
        0.28
       </span>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_r" id="S4.T3.11.14.10" style="padding-left:3.0pt;padding-right:3.0pt;">
       <span class="ltx_text" id="S4.T3.11.14.10.1" style="font-size:90%;">
        0.00
       </span>
      </td>
      <td class="ltx_td ltx_align_center" id="S4.T3.11.14.11" style="padding-left:3.0pt;padding-right:3.0pt;">
       <span class="ltx_text" id="S4.T3.11.14.11.1" style="font-size:90%;">
        9.81
       </span>
      </td>
      <td class="ltx_td ltx_align_center" id="S4.T3.11.14.12" style="padding-left:3.0pt;padding-right:3.0pt;">
       <span class="ltx_text" id="S4.T3.11.14.12.1" style="font-size:90%;">
        18.61
       </span>
      </td>
      <td class="ltx_td ltx_align_center" id="S4.T3.11.14.13" style="padding-left:3.0pt;padding-right:3.0pt;">
       <span class="ltx_text" id="S4.T3.11.14.13.1" style="font-size:90%;">
        22.95
       </span>
      </td>
     </tr>
     <tr class="ltx_tr" id="S4.T3.11.15">
      <td class="ltx_td ltx_align_left ltx_border_r" id="S4.T3.11.15.1" style="padding-left:3.0pt;padding-right:3.0pt;">
       <span class="ltx_text" id="S4.T3.11.15.1.1" style="font-size:90%;">
        Apollo
       </span>
       <cite class="ltx_cite ltx_citemacro_cite">
        <span class="ltx_text" id="S4.T3.11.15.1.2.1" style="font-size:90%;">
         [
        </span>
        <a class="ltx_ref" href="#bib.bib3" title="">
         <span class="ltx_text" style="font-size:90%;">
          3
         </span>
        </a>
        <span class="ltx_text" id="S4.T3.11.15.1.3.2" style="font-size:90%;">
         ]
        </span>
       </cite>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_r" id="S4.T3.11.15.2" style="padding-left:3.0pt;padding-right:3.0pt;">
       <span class="ltx_text" id="S4.T3.11.15.2.1" style="font-size:90%;">
        FSM
       </span>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_r" id="S4.T3.11.15.3" style="padding-left:3.0pt;padding-right:3.0pt;">
       <span class="ltx_text" id="S4.T3.11.15.3.1" style="font-size:90%;">
        18.53
       </span>
      </td>
      <td class="ltx_td ltx_align_center" id="S4.T3.11.15.4" style="padding-left:3.0pt;padding-right:3.0pt;">
       <span class="ltx_text" id="S4.T3.11.15.4.1" style="font-size:90%;">
        0.76
       </span>
      </td>
      <td class="ltx_td ltx_align_center" id="S4.T3.11.15.5" style="padding-left:3.0pt;padding-right:3.0pt;">
       <span class="ltx_text" id="S4.T3.11.15.5.1" style="font-size:90%;">
        0.40
       </span>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_r" id="S4.T3.11.15.6" style="padding-left:3.0pt;padding-right:3.0pt;">
       <span class="ltx_text" id="S4.T3.11.15.6.1" style="font-size:90%;">
        0.04
       </span>
      </td>
      <td class="ltx_td ltx_align_center" id="S4.T3.11.15.7" style="padding-left:3.0pt;padding-right:3.0pt;">
       <span class="ltx_text" id="S4.T3.11.15.7.1" style="font-size:90%;">
        0.54
       </span>
      </td>
      <td class="ltx_td ltx_align_center" id="S4.T3.11.15.8" style="padding-left:3.0pt;padding-right:3.0pt;">
       <span class="ltx_text" id="S4.T3.11.15.8.1" style="font-size:90%;">
        0.05
       </span>
      </td>
      <td class="ltx_td ltx_align_center" id="S4.T3.11.15.9" style="padding-left:3.0pt;padding-right:3.0pt;">
       <span class="ltx_text" id="S4.T3.11.15.9.1" style="font-size:90%;">
        0.19
       </span>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_r" id="S4.T3.11.15.10" style="padding-left:3.0pt;padding-right:3.0pt;">
       <span class="ltx_text" id="S4.T3.11.15.10.1" style="font-size:90%;">
        0.37
       </span>
      </td>
      <td class="ltx_td ltx_align_center" id="S4.T3.11.15.11" style="padding-left:3.0pt;padding-right:3.0pt;">
       <span class="ltx_text" id="S4.T3.11.15.11.1" style="font-size:90%;">
        -
       </span>
      </td>
      <td class="ltx_td ltx_align_center" id="S4.T3.11.15.12" style="padding-left:3.0pt;padding-right:3.0pt;">
       <span class="ltx_text" id="S4.T3.11.15.12.1" style="font-size:90%;">
        -
       </span>
      </td>
      <td class="ltx_td ltx_align_center" id="S4.T3.11.15.13" style="padding-left:3.0pt;padding-right:3.0pt;">
       <span class="ltx_text" id="S4.T3.11.15.13.1" style="font-size:90%;">
        -
       </span>
      </td>
     </tr>
     <tr class="ltx_tr" id="S4.T3.11.16">
      <td class="ltx_td ltx_align_left ltx_border_bb ltx_border_r ltx_border_t" id="S4.T3.11.16.1" style="padding-left:3.0pt;padding-right:3.0pt;">
       <span class="ltx_text" id="S4.T3.11.16.1.1" style="font-size:90%;">
        DriveMLM
       </span>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" id="S4.T3.11.16.2" style="padding-left:3.0pt;padding-right:3.0pt;">
       <span class="ltx_text" id="S4.T3.11.16.2.1" style="font-size:90%;">
        LLM
       </span>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" id="S4.T3.11.16.3" style="padding-left:3.0pt;padding-right:3.0pt;">
       <span class="ltx_text ltx_font_bold" id="S4.T3.11.16.3.1" style="font-size:90%;">
        75.23
       </span>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T3.11.16.4" style="padding-left:3.0pt;padding-right:3.0pt;">
       <span class="ltx_text ltx_font_bold" id="S4.T3.11.16.4.1" style="font-size:90%;">
        0.90
       </span>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T3.11.16.5" style="padding-left:3.0pt;padding-right:3.0pt;">
       <span class="ltx_text ltx_font_bold" id="S4.T3.11.16.5.1" style="font-size:90%;">
        0.52
       </span>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" id="S4.T3.11.16.6" style="padding-left:3.0pt;padding-right:3.0pt;">
       <span class="ltx_text ltx_font_bold" id="S4.T3.11.16.6.1" style="font-size:90%;">
        0.89
       </span>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T3.11.16.7" style="padding-left:3.0pt;padding-right:3.0pt;">
       <span class="ltx_text ltx_font_bold" id="S4.T3.11.16.7.1" style="font-size:90%;">
        0.91
       </span>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T3.11.16.8" style="padding-left:3.0pt;padding-right:3.0pt;">
       <span class="ltx_text ltx_font_bold" id="S4.T3.11.16.8.1" style="font-size:90%;">
        0.61
       </span>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T3.11.16.9" style="padding-left:3.0pt;padding-right:3.0pt;">
       <span class="ltx_text ltx_font_bold" id="S4.T3.11.16.9.1" style="font-size:90%;">
        0.66
       </span>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" id="S4.T3.11.16.10" style="padding-left:3.0pt;padding-right:3.0pt;">
       <span class="ltx_text ltx_font_bold" id="S4.T3.11.16.10.1" style="font-size:90%;">
        0.89
       </span>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T3.11.16.11" style="padding-left:3.0pt;padding-right:3.0pt;">
       <span class="ltx_text ltx_font_bold" id="S4.T3.11.16.11.1" style="font-size:90%;">
        40.46
       </span>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T3.11.16.12" style="padding-left:3.0pt;padding-right:3.0pt;">
       <span class="ltx_text ltx_font_bold" id="S4.T3.11.16.12.1" style="font-size:90%;">
        124.91
       </span>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T3.11.16.13" style="padding-left:3.0pt;padding-right:3.0pt;">
       <span class="ltx_text ltx_font_bold" id="S4.T3.11.16.13.1" style="font-size:90%;">
        56.54
       </span>
      </td>
     </tr>
    </table>
    <figcaption class="ltx_caption ltx_centering" style="font-size:90%;">
     <span class="ltx_tag ltx_tag_table">
      Table 3:
     </span>
     <span class="ltx_text ltx_font_bold" id="S4.T3.16.1">
      Results of open-loop evaluation on CARLA Town05.
     </span>
     Compared with previous approaches, our method can predict more precise decisions and give better explanations for the decision choice.
    </figcaption>
   </figure>
   <div class="ltx_para" id="S4.SS2.p2">
    <p class="ltx_p" id="S4.SS2.p2.2">
     For evaluating closed-loop driving performance, we use the widely used Town05Long benchmark, which follows previous work
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib15" title="">
       <span class="ltx_text" style="font-size:90%;">
        15
       </span>
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib57" title="">
       <span class="ltx_text" style="font-size:90%;">
        57
       </span>
      </a>
      ]
     </cite>
     . It is worth noting that Town05 is not in our training data. We use Driving Score (DS), Route Completion (RC), and Infraction Score (IS)
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib18" title="">
       <span class="ltx_text" style="font-size:90%;">
        18
       </span>
      </a>
      ]
     </cite>
     as the metrics. RC computes the average percentage of routes completed by an agent. IS measures the infraction penalty between
     <math alttext="0" class="ltx_Math" display="inline" id="S4.SS2.p2.1.m1.1">
      <semantics id="S4.SS2.p2.1.m1.1a">
       <mn id="S4.SS2.p2.1.m1.1.1" xref="S4.SS2.p2.1.m1.1.1.cmml">
        0
       </mn>
       <annotation-xml encoding="MathML-Content" id="S4.SS2.p2.1.m1.1b">
        <cn id="S4.SS2.p2.1.m1.1.1.cmml" type="integer" xref="S4.SS2.p2.1.m1.1.1">
         0
        </cn>
       </annotation-xml>
      </semantics>
     </math>
     and
     <math alttext="1" class="ltx_Math" display="inline" id="S4.SS2.p2.2.m2.1">
      <semantics id="S4.SS2.p2.2.m2.1a">
       <mn id="S4.SS2.p2.2.m2.1.1" xref="S4.SS2.p2.2.m2.1.1.cmml">
        1
       </mn>
       <annotation-xml encoding="MathML-Content" id="S4.SS2.p2.2.m2.1b">
        <cn id="S4.SS2.p2.2.m2.1.1.cmml" type="integer" xref="S4.SS2.p2.2.m2.1.1">
         1
        </cn>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S4.SS2.p2.2.m2.1c">
        1
       </annotation>
      </semantics>
     </math>
     , including collision and violation of traffic rules. Note that IS is only calculated on the completed part of a route. DS is the core metric among the three, which is the product of both RC and IS. We also evaluate driving performance using Miles Per Intervention (MPI), which is a widely used metric in industry.
It is computed as the total distance traveled over the total times of human takeovers. If the ego-car violates traffic rules or has a collision, it will be taken over and continue self-driving in a safe location until it reaches its destination. Unlike DS, which terminates the route under certain conditions, MPI requires the ego-car to complete the entire route.
    </p>
   </div>
   <div class="ltx_para" id="S4.SS2.p3">
    <p class="ltx_p" id="S4.SS2.p3.1">
     For the open-loop evaluation, we collect 10 routes of each scenario in Town05 obtained and annotated by human drivers as the test set. To evaluate decision prediction, we compute the accuracy of predicted decision pairs and the F1 score of each type of decision.
For the explanation prediction task, we use the commonly used metrics in the NLP community, including BLEU-4
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib49" title="">
       <span class="ltx_text" style="font-size:90%;">
        49
       </span>
      </a>
      ]
     </cite>
     , CIDEr
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib65" title="">
       <span class="ltx_text" style="font-size:90%;">
        65
       </span>
      </a>
      ]
     </cite>
     and METEOR
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib4" title="">
       <span class="ltx_text" style="font-size:90%;">
        4
       </span>
      </a>
      ]
     </cite>
     .
We compare our method with the popular Apollo, which is based on a finite state machine (FSM) and two MLLM models - LLaVA1.5
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib37" title="">
       <span class="ltx_text" style="font-size:90%;">
        37
       </span>
      </a>
      ]
     </cite>
     and InstructBLIP
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib17" title="">
       <span class="ltx_text" style="font-size:90%;">
        17
       </span>
      </a>
      ]
     </cite>
     .
These two MLLM models used for comparison were not fine-tuned but instead provided with several examples of input/decision pairs for few-shot adaptation.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S4.SS3">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     4.3
    </span>
    Evaluation in Closed-Loop Driving
   </h3>
   <figure class="ltx_table" id="S4.T4">
    <table class="ltx_tabular ltx_centering ltx_align_middle" id="S4.T4.4">
     <tr class="ltx_tr" id="S4.T4.4.4">
      <td class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" id="S4.T4.4.4.5" style="padding-left:7.0pt;padding-right:7.0pt;">
       <span class="ltx_text" id="S4.T4.4.4.5.1" style="font-size:90%;">
        Method
       </span>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S4.T4.4.4.6" style="padding-left:7.0pt;padding-right:7.0pt;">
       <span class="ltx_text" id="S4.T4.4.4.6.1" style="font-size:90%;">
        Type
       </span>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T4.1.1.1" style="padding-left:7.0pt;padding-right:7.0pt;">
       <span class="ltx_text" id="S4.T4.1.1.1.1" style="font-size:90%;">
        DS
       </span>
       <math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T4.1.1.1.m1.1">
        <semantics id="S4.T4.1.1.1.m1.1a">
         <mo id="S4.T4.1.1.1.m1.1.1" mathsize="90%" stretchy="false" xref="S4.T4.1.1.1.m1.1.1.cmml">
          ↑
         </mo>
         <annotation-xml encoding="MathML-Content" id="S4.T4.1.1.1.m1.1b">
          <ci id="S4.T4.1.1.1.m1.1.1.cmml" xref="S4.T4.1.1.1.m1.1.1">
           ↑
          </ci>
         </annotation-xml>
         <annotation encoding="application/x-tex" id="S4.T4.1.1.1.m1.1c">
          \uparrow
         </annotation>
        </semantics>
       </math>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T4.2.2.2" style="padding-left:7.0pt;padding-right:7.0pt;">
       <span class="ltx_text" id="S4.T4.2.2.2.1" style="font-size:90%;">
        RC
       </span>
       <math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T4.2.2.2.m1.1">
        <semantics id="S4.T4.2.2.2.m1.1a">
         <mo id="S4.T4.2.2.2.m1.1.1" mathsize="90%" stretchy="false" xref="S4.T4.2.2.2.m1.1.1.cmml">
          ↑
         </mo>
         <annotation-xml encoding="MathML-Content" id="S4.T4.2.2.2.m1.1b">
          <ci id="S4.T4.2.2.2.m1.1.1.cmml" xref="S4.T4.2.2.2.m1.1.1">
           ↑
          </ci>
         </annotation-xml>
         <annotation encoding="application/x-tex" id="S4.T4.2.2.2.m1.1c">
          \uparrow
         </annotation>
        </semantics>
       </math>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S4.T4.3.3.3" style="padding-left:7.0pt;padding-right:7.0pt;">
       <span class="ltx_text" id="S4.T4.3.3.3.1" style="font-size:90%;">
        IS
       </span>
       <math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T4.3.3.3.m1.1">
        <semantics id="S4.T4.3.3.3.m1.1a">
         <mo id="S4.T4.3.3.3.m1.1.1" mathsize="90%" stretchy="false" xref="S4.T4.3.3.3.m1.1.1.cmml">
          ↑
         </mo>
         <annotation-xml encoding="MathML-Content" id="S4.T4.3.3.3.m1.1b">
          <ci id="S4.T4.3.3.3.m1.1.1.cmml" xref="S4.T4.3.3.3.m1.1.1">
           ↑
          </ci>
         </annotation-xml>
         <annotation encoding="application/x-tex" id="S4.T4.3.3.3.m1.1c">
          \uparrow
         </annotation>
        </semantics>
       </math>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T4.4.4.4" style="padding-left:7.0pt;padding-right:7.0pt;">
       <span class="ltx_text" id="S4.T4.4.4.4.1" style="font-size:90%;">
        MPI
       </span>
       <math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T4.4.4.4.m1.1">
        <semantics id="S4.T4.4.4.4.m1.1a">
         <mo id="S4.T4.4.4.4.m1.1.1" mathsize="90%" stretchy="false" xref="S4.T4.4.4.4.m1.1.1.cmml">
          ↑
         </mo>
         <annotation-xml encoding="MathML-Content" id="S4.T4.4.4.4.m1.1b">
          <ci id="S4.T4.4.4.4.m1.1.1.cmml" xref="S4.T4.4.4.4.m1.1.1">
           ↑
          </ci>
         </annotation-xml>
         <annotation encoding="application/x-tex" id="S4.T4.4.4.4.m1.1c">
          \uparrow
         </annotation>
        </semantics>
       </math>
      </td>
     </tr>
     <tr class="ltx_tr" id="S4.T4.4.5">
      <td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T4.4.5.1" style="padding-left:7.0pt;padding-right:7.0pt;">
       <span class="ltx_text" id="S4.T4.4.5.1.1" style="font-size:90%;">
        Roach
       </span>
       <cite class="ltx_cite ltx_citemacro_cite">
        <span class="ltx_text" id="S4.T4.4.5.1.2.1" style="font-size:90%;">
         [
        </span>
        <a class="ltx_ref" href="#bib.bib81" title="">
         <span class="ltx_text" style="font-size:90%;">
          81
         </span>
        </a>
        <span class="ltx_text" id="S4.T4.4.5.1.3.2" style="font-size:90%;">
         ]
        </span>
       </cite>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T4.4.5.2" style="padding-left:7.0pt;padding-right:7.0pt;">
       <span class="ltx_text" id="S4.T4.4.5.2.1" style="font-size:90%;">
        DD
       </span>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.4.5.3" style="padding-left:7.0pt;padding-right:7.0pt;">
       <span class="ltx_text" id="S4.T4.4.5.3.1" style="font-size:90%;">
        43.6
       </span>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.4.5.4" style="padding-left:7.0pt;padding-right:7.0pt;">
       <span class="ltx_text" id="S4.T4.4.5.4.1" style="font-size:90%;">
        80.4
       </span>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T4.4.5.5" style="padding-left:7.0pt;padding-right:7.0pt;">
       <span class="ltx_text" id="S4.T4.4.5.5.1" style="font-size:90%;">
        0.54
       </span>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.4.5.6" style="padding-left:7.0pt;padding-right:7.0pt;">
       <span class="ltx_text" id="S4.T4.4.5.6.1" style="font-size:90%;">
        -
       </span>
      </td>
     </tr>
     <tr class="ltx_tr" id="S4.T4.4.6">
      <td class="ltx_td ltx_align_left ltx_border_r" id="S4.T4.4.6.1" style="padding-left:7.0pt;padding-right:7.0pt;">
       <span class="ltx_text" id="S4.T4.4.6.1.1" style="font-size:90%;">
        Interfuser
       </span>
       <cite class="ltx_cite ltx_citemacro_cite">
        <span class="ltx_text" id="S4.T4.4.6.1.2.1" style="font-size:90%;">
         [
        </span>
        <a class="ltx_ref" href="#bib.bib57" title="">
         <span class="ltx_text" style="font-size:90%;">
          57
         </span>
        </a>
        <span class="ltx_text" id="S4.T4.4.6.1.3.2" style="font-size:90%;">
         ]
        </span>
       </cite>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_r" id="S4.T4.4.6.2" style="padding-left:7.0pt;padding-right:7.0pt;">
       <span class="ltx_text" id="S4.T4.4.6.2.1" style="font-size:90%;">
        DD
       </span>
      </td>
      <td class="ltx_td ltx_align_center" id="S4.T4.4.6.3" style="padding-left:7.0pt;padding-right:7.0pt;">
       <span class="ltx_text" id="S4.T4.4.6.3.1" style="font-size:90%;">
        68.3
       </span>
      </td>
      <td class="ltx_td ltx_align_center" id="S4.T4.4.6.4" style="padding-left:7.0pt;padding-right:7.0pt;">
       <span class="ltx_text" id="S4.T4.4.6.4.1" style="font-size:90%;">
        95.0
       </span>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_r" id="S4.T4.4.6.5" style="padding-left:7.0pt;padding-right:7.0pt;">
       <span class="ltx_text" id="S4.T4.4.6.5.1" style="font-size:90%;">
        0.72
       </span>
      </td>
      <td class="ltx_td ltx_align_center" id="S4.T4.4.6.6" style="padding-left:7.0pt;padding-right:7.0pt;">
       <span class="ltx_text" id="S4.T4.4.6.6.1" style="font-size:90%;">
        0.70
       </span>
      </td>
     </tr>
     <tr class="ltx_tr" id="S4.T4.4.7">
      <td class="ltx_td ltx_align_left ltx_border_r" id="S4.T4.4.7.1" style="padding-left:7.0pt;padding-right:7.0pt;">
       <span class="ltx_text" id="S4.T4.4.7.1.1" style="font-size:90%;">
        ThinkTwice
       </span>
       <cite class="ltx_cite ltx_citemacro_cite">
        <span class="ltx_text" id="S4.T4.4.7.1.2.1" style="font-size:90%;">
         [
        </span>
        <a class="ltx_ref" href="#bib.bib27" title="">
         <span class="ltx_text" style="font-size:90%;">
          27
         </span>
        </a>
        <span class="ltx_text" id="S4.T4.4.7.1.3.2" style="font-size:90%;">
         ]
        </span>
       </cite>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_r" id="S4.T4.4.7.2" style="padding-left:7.0pt;padding-right:7.0pt;">
       <span class="ltx_text" id="S4.T4.4.7.2.1" style="font-size:90%;">
        DD
       </span>
      </td>
      <td class="ltx_td ltx_align_center" id="S4.T4.4.7.3" style="padding-left:7.0pt;padding-right:7.0pt;">
       <span class="ltx_text" id="S4.T4.4.7.3.1" style="font-size:90%;">
        70.9
       </span>
      </td>
      <td class="ltx_td ltx_align_center" id="S4.T4.4.7.4" style="padding-left:7.0pt;padding-right:7.0pt;">
       <span class="ltx_text" id="S4.T4.4.7.4.1" style="font-size:90%;">
        95.5
       </span>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_r" id="S4.T4.4.7.5" style="padding-left:7.0pt;padding-right:7.0pt;">
       <span class="ltx_text" id="S4.T4.4.7.5.1" style="font-size:90%;">
        0.75
       </span>
      </td>
      <td class="ltx_td ltx_align_center" id="S4.T4.4.7.6" style="padding-left:7.0pt;padding-right:7.0pt;">
       <span class="ltx_text" id="S4.T4.4.7.6.1" style="font-size:90%;">
        0.40
       </span>
      </td>
     </tr>
     <tr class="ltx_tr" id="S4.T4.4.8">
      <td class="ltx_td ltx_align_left ltx_border_r" id="S4.T4.4.8.1" style="padding-left:7.0pt;padding-right:7.0pt;">
       <span class="ltx_text" id="S4.T4.4.8.1.1" style="font-size:90%;">
        Apollo
       </span>
       <cite class="ltx_cite ltx_citemacro_cite">
        <span class="ltx_text" id="S4.T4.4.8.1.2.1" style="font-size:90%;">
         [
        </span>
        <a class="ltx_ref" href="#bib.bib3" title="">
         <span class="ltx_text" style="font-size:90%;">
          3
         </span>
        </a>
        <span class="ltx_text" id="S4.T4.4.8.1.3.2" style="font-size:90%;">
         ]
        </span>
       </cite>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_r" id="S4.T4.4.8.2" style="padding-left:7.0pt;padding-right:7.0pt;">
       <span class="ltx_text" id="S4.T4.4.8.2.1" style="font-size:90%;">
        FSM
       </span>
      </td>
      <td class="ltx_td ltx_align_center" id="S4.T4.4.8.3" style="padding-left:7.0pt;padding-right:7.0pt;">
       <span class="ltx_text" id="S4.T4.4.8.3.1" style="font-size:90%;">
        71.4
       </span>
      </td>
      <td class="ltx_td ltx_align_center" id="S4.T4.4.8.4" style="padding-left:7.0pt;padding-right:7.0pt;">
       <span class="ltx_text" id="S4.T4.4.8.4.1" style="font-size:90%;">
        92.2
       </span>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_r" id="S4.T4.4.8.5" style="padding-left:7.0pt;padding-right:7.0pt;">
       <span class="ltx_text ltx_font_bold" id="S4.T4.4.8.5.1" style="font-size:90%;">
        0.80
       </span>
      </td>
      <td class="ltx_td ltx_align_center" id="S4.T4.4.8.6" style="padding-left:7.0pt;padding-right:7.0pt;">
       <span class="ltx_text" id="S4.T4.4.8.6.1" style="font-size:90%;">
        0.76
       </span>
      </td>
     </tr>
     <tr class="ltx_tr" id="S4.T4.4.9">
      <td class="ltx_td ltx_align_left ltx_border_bb ltx_border_r ltx_border_t" id="S4.T4.4.9.1" style="padding-left:7.0pt;padding-right:7.0pt;">
       <span class="ltx_text" id="S4.T4.4.9.1.1" style="font-size:90%;">
        DriveMLM
       </span>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" id="S4.T4.4.9.2" style="padding-left:7.0pt;padding-right:7.0pt;">
       <span class="ltx_text" id="S4.T4.4.9.2.1" style="font-size:90%;">
        LLM
       </span>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T4.4.9.3" style="padding-left:7.0pt;padding-right:7.0pt;">
       <span class="ltx_text ltx_font_bold" id="S4.T4.4.9.3.1" style="font-size:90%;">
        76.1
       </span>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T4.4.9.4" style="padding-left:7.0pt;padding-right:7.0pt;">
       <span class="ltx_text ltx_font_bold" id="S4.T4.4.9.4.1" style="font-size:90%;">
        98.1
       </span>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" id="S4.T4.4.9.5" style="padding-left:7.0pt;padding-right:7.0pt;">
       <span class="ltx_text" id="S4.T4.4.9.5.1" style="font-size:90%;">
        0.78
       </span>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T4.4.9.6" style="padding-left:7.0pt;padding-right:7.0pt;">
       <span class="ltx_text ltx_font_bold" id="S4.T4.4.9.6.1" style="font-size:90%;">
        0.96
       </span>
      </td>
     </tr>
    </table>
    <figcaption class="ltx_caption ltx_centering" style="font-size:90%;">
     <span class="ltx_tag ltx_tag_table">
      Table 4:
     </span>
     <span class="ltx_text ltx_font_bold" id="S4.T4.9.1">
      Results of closed-loop driving on CARLA Town05 Long
     </span>
     . FSM denotes a Finite State Machine. DD denotes Data Driven. DS denotes Driving Score. RC denotes Route Completion. IS denotes Infraction Score. MPI denotes Miles Per Intervention. DriveMLM has a higher driving score and route completion rate and is also close to Apollo’s infraction penalty, indicating that DriveMLM can make better decisions while following the traffic rules. Meanwhile, DriveMLM also shows advantages in MPI, representing fewer human takeovers at the same mileage.
    </figcaption>
   </figure>
   <div class="ltx_para" id="S4.SS3.p1">
    <p class="ltx_p" id="S4.SS3.p1.1">
     We evaluate closed-loop driving in CARLA, the most widely used and realistic simulation benchmark publicly available. State-of-the-art methods
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib81" title="">
       <span class="ltx_text" style="font-size:90%;">
        81
       </span>
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib57" title="">
       <span class="ltx_text" style="font-size:90%;">
        57
       </span>
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib27" title="">
       <span class="ltx_text" style="font-size:90%;">
        27
       </span>
      </a>
      ]
     </cite>
     that are capable of performing closed-loop driving in CARLA are included for performance comparison.
The open-sourced Apollo
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib3" title="">
       <span class="ltx_text" style="font-size:90%;">
        3
       </span>
      </a>
      ]
     </cite>
     is also evaluated in CARLA as a baseline. No other LLM-based methods have shown the readiness to be deployed and evaluated besides ours.
All methods are evaluated on Town05 long benchmarks
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib15" title="">
       <span class="ltx_text" style="font-size:90%;">
        15
       </span>
      </a>
      ]
     </cite>
     .
    </p>
   </div>
   <div class="ltx_para" id="S4.SS3.p2">
    <p class="ltx_p" id="S4.SS3.p2.1">
     Table
     <a class="ltx_ref" href="#S4.T4" title="Table 4 ‣ 4.3 Evaluation in Closed-Loop Driving ‣ 4 Experiments ‣ DriveMLM: Aligning Multi-Modal Large Language Models with Behavioral Planning States for Autonomous Driving">
      <span class="ltx_text ltx_ref_tag">
       4
      </span>
     </a>
     presents the Driving Score, Route Completion, and Infraction Score. Note that despite being a rule-based method, Apollo achieves almost on-par performance with recent end-to-end methods. DriveMLM surpasses all other methods on Driving Score by a large margin.
This suggests that DriveMLM is better for handling state-transitions to safely drive through hard cases.
The last column in Table
     <a class="ltx_ref" href="#S4.T4" title="Table 4 ‣ 4.3 Evaluation in Closed-Loop Driving ‣ 4 Experiments ‣ DriveMLM: Aligning Multi-Modal Large Language Models with Behavioral Planning States for Autonomous Driving">
      <span class="ltx_text ltx_ref_tag">
       4
      </span>
     </a>
     presents the results of MPI evaluation. This metric shows a more holistic driving performance because an agent is required to finish all routes. In other words, all situations along all routes are encountered by the tested agents. Thinktwice achieves better DS but lower MPI than Interfuser due to frequently crossing the stop line. However, CARLA imposes minimal penalties for this behavior. By contrast, MPI takes each violation of traffic rules as one take-over. DriveMLM also achieves the highest MPI among all other methods, suggesting its ability to avoid more situations for a safer driving experience.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S4.SS4">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     4.4
    </span>
    Evaluation of Driving Knowledge
   </h3>
   <div class="ltx_para" id="S4.SS4.p1">
    <p class="ltx_p" id="S4.SS4.p1.1">
     We adopt open-loop evaluation to evaluate the driving knowledge, which includes the decision prediction and the explanation prediction task. Table
     <a class="ltx_ref" href="#S4.T3" title="Table 3 ‣ 4.2 Implementation Details ‣ 4 Experiments ‣ DriveMLM: Aligning Multi-Modal Large Language Models with Behavioral Planning States for Autonomous Driving">
      <span class="ltx_text ltx_ref_tag">
       3
      </span>
     </a>
     presents the accuracy of predicted decision pairs, F1-score of each type of decision for the decision prediction, and BLEU-4
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib49" title="">
       <span class="ltx_text" style="font-size:90%;">
        49
       </span>
      </a>
      ]
     </cite>
     , CIDEr
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib65" title="">
       <span class="ltx_text" style="font-size:90%;">
        65
       </span>
      </a>
      ]
     </cite>
     and METEOR
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib4" title="">
       <span class="ltx_text" style="font-size:90%;">
        4
       </span>
      </a>
      ]
     </cite>
     for the predicted explanation. For Apollo, manually collected scenarios on Town05 are replayed as input to models in Table
     <a class="ltx_ref" href="#S4.T3" title="Table 3 ‣ 4.2 Implementation Details ‣ 4 Experiments ‣ DriveMLM: Aligning Multi-Modal Large Language Models with Behavioral Planning States for Autonomous Driving">
      <span class="ltx_text ltx_ref_tag">
       3
      </span>
     </a>
     . The corresponding model states and outputs at every timestamp of replay are saved as predictions for metric calculation. For other methods, we give them the corresponding images as input and the proper prompts.
By comparing model prediction with our manually collected ground truth, accuracy reveals decision correctness and similarity to human behavior, and the F1-score demonstrates the decision-making capability across each individual type of path and speed decision. DriveMLM achieves the highest accuracy overall, surpassing LLaVA with an accuracy of 40.97%. Compared to the Apollo baseline, the higher F1-score of DriveMLM suggests that it is much more effective in overtaking the rule-based state machine for solving various road situations. LLaVA
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib37" title="">
       <span class="ltx_text" style="font-size:90%;">
        37
       </span>
      </a>
      ]
     </cite>
     , InstructBLIP
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib17" title="">
       <span class="ltx_text" style="font-size:90%;">
        17
       </span>
      </a>
      ]
     </cite>
     , and our proposed DriveMLM can output explanations of decisions in the form of question and answer. In terms of BLEU-4, CIDEr, and METEOR, DriveMLM can achieve the highest performance, indicating that DriveMLM can give the most reasonable explanation of the decision.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S4.SS5">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     4.5
    </span>
    Ablation Study
   </h3>
   <section class="ltx_paragraph" id="S4.SS5.SSS0.Px1">
    <h4 class="ltx_title ltx_title_paragraph">
     Sensor Modality
    </h4>
    <div class="ltx_para" id="S4.SS5.SSS0.Px1.p1">
     <p class="ltx_p" id="S4.SS5.SSS0.Px1.p1.1">
      Table
      <a class="ltx_ref" href="#S4.T5" title="Table 5 ‣ Sensor Modality ‣ 4.5 Ablation Study ‣ 4 Experiments ‣ DriveMLM: Aligning Multi-Modal Large Language Models with Behavioral Planning States for Autonomous Driving">
       <span class="ltx_text ltx_ref_tag">
        5
       </span>
      </a>
      presents the results of different impacts of input sensor modality to the DriveMLM. Multi-View (MV) images bring a substantial performance improvement in both path and speed F1-score, along with 18.19% increase in accuracy. Compared to concatenating temporal tokens directly, temporal QFormer results in a larger improvement of 7.4%, while ensuring multi-modal decision capability, which leads to 0.05 improvement in the average F1-score on speed decision. Point clouds do not show the ability to enhance performance.
     </p>
    </div>
    <figure class="ltx_table" id="S4.T5">
     <table class="ltx_tabular ltx_centering ltx_align_middle" id="S4.T5.4">
      <tr class="ltx_tr" id="S4.T5.4.4">
       <td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T5.4.4.5" style="padding-left:5.5pt;padding-right:5.5pt;">
        <span class="ltx_text" id="S4.T5.4.4.5.1" style="font-size:90%;">
         MV
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T5.4.4.6" style="padding-left:5.5pt;padding-right:5.5pt;">
        <span class="ltx_text" id="S4.T5.4.4.6.1" style="font-size:90%;">
         CT
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T5.4.4.7" style="padding-left:5.5pt;padding-right:5.5pt;">
        <span class="ltx_text" id="S4.T5.4.4.7.1" style="font-size:90%;">
         TQ
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S4.T5.4.4.8" style="padding-left:5.5pt;padding-right:5.5pt;">
        <span class="ltx_text" id="S4.T5.4.4.8.1" style="font-size:90%;">
         PC
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T5.2.2.2" style="padding-left:5.5pt;padding-right:5.5pt;">
        <span class="ltx_text" id="S4.T5.2.2.2.1" style="font-size:90%;">
         Acc.
        </span>
        <math alttext="(\%)" class="ltx_math_unparsed" display="inline" id="S4.T5.1.1.1.m1.1">
         <semantics id="S4.T5.1.1.1.m1.1a">
          <mrow id="S4.T5.1.1.1.m1.1b">
           <mo id="S4.T5.1.1.1.m1.1.1" maxsize="90%" minsize="90%">
            (
           </mo>
           <mo id="S4.T5.1.1.1.m1.1.2" mathsize="90%">
            %
           </mo>
           <mo id="S4.T5.1.1.1.m1.1.3" maxsize="90%" minsize="90%">
            )
           </mo>
          </mrow>
          <annotation encoding="application/x-tex" id="S4.T5.1.1.1.m1.1c">
           (\%)
          </annotation>
         </semantics>
        </math>
        <span class="ltx_text" id="S4.T5.2.2.2.2" style="font-size:90%;">
        </span>
        <math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T5.2.2.2.m2.1">
         <semantics id="S4.T5.2.2.2.m2.1a">
          <mo id="S4.T5.2.2.2.m2.1.1" mathsize="90%" stretchy="false" xref="S4.T5.2.2.2.m2.1.1.cmml">
           ↑
          </mo>
          <annotation-xml encoding="MathML-Content" id="S4.T5.2.2.2.m2.1b">
           <ci id="S4.T5.2.2.2.m2.1.1.cmml" xref="S4.T5.2.2.2.m2.1.1">
            ↑
           </ci>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="S4.T5.2.2.2.m2.1c">
           \uparrow
          </annotation>
         </semantics>
        </math>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T5.3.3.3" style="padding-left:5.5pt;padding-right:5.5pt;">
        <span class="ltx_text" id="S4.T5.3.3.3.2">
        </span>
        <span class="ltx_text" id="S4.T5.3.3.3.3" style="font-size:90%;">
        </span>
        <span class="ltx_text" id="S4.T5.3.3.3.1" style="font-size:90%;">
         <span class="ltx_tabular ltx_align_middle" id="S4.T5.3.3.3.1.1">
          <span class="ltx_tr" id="S4.T5.3.3.3.1.1.1">
           <span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T5.3.3.3.1.1.1.1" style="padding-left:5.5pt;padding-right:5.5pt;">
            Path
            <math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T5.3.3.3.1.1.1.1.m1.1">
             <semantics id="S4.T5.3.3.3.1.1.1.1.m1.1a">
              <mo id="S4.T5.3.3.3.1.1.1.1.m1.1.1" stretchy="false" xref="S4.T5.3.3.3.1.1.1.1.m1.1.1.cmml">
               ↑
              </mo>
              <annotation-xml encoding="MathML-Content" id="S4.T5.3.3.3.1.1.1.1.m1.1b">
               <ci id="S4.T5.3.3.3.1.1.1.1.m1.1.1.cmml" xref="S4.T5.3.3.3.1.1.1.1.m1.1.1">
                ↑
               </ci>
              </annotation-xml>
              <annotation encoding="application/x-tex" id="S4.T5.3.3.3.1.1.1.1.m1.1c">
               \uparrow
              </annotation>
             </semantics>
            </math>
           </span>
          </span>
          <span class="ltx_tr" id="S4.T5.3.3.3.1.1.2">
           <span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T5.3.3.3.1.1.2.1" style="padding-left:5.5pt;padding-right:5.5pt;">
            (F1 Avg)
           </span>
          </span>
         </span>
        </span>
        <span class="ltx_text" id="S4.T5.3.3.3.4">
        </span>
        <span class="ltx_text" id="S4.T5.3.3.3.5" style="font-size:90%;">
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T5.4.4.4" style="padding-left:5.5pt;padding-right:5.5pt;">
        <span class="ltx_text" id="S4.T5.4.4.4.2">
        </span>
        <span class="ltx_text" id="S4.T5.4.4.4.3" style="font-size:90%;">
        </span>
        <span class="ltx_text" id="S4.T5.4.4.4.1" style="font-size:90%;">
         <span class="ltx_tabular ltx_align_middle" id="S4.T5.4.4.4.1.1">
          <span class="ltx_tr" id="S4.T5.4.4.4.1.1.1">
           <span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T5.4.4.4.1.1.1.1" style="padding-left:5.5pt;padding-right:5.5pt;">
            Speed
            <math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T5.4.4.4.1.1.1.1.m1.1">
             <semantics id="S4.T5.4.4.4.1.1.1.1.m1.1a">
              <mo id="S4.T5.4.4.4.1.1.1.1.m1.1.1" stretchy="false" xref="S4.T5.4.4.4.1.1.1.1.m1.1.1.cmml">
               ↑
              </mo>
              <annotation-xml encoding="MathML-Content" id="S4.T5.4.4.4.1.1.1.1.m1.1b">
               <ci id="S4.T5.4.4.4.1.1.1.1.m1.1.1.cmml" xref="S4.T5.4.4.4.1.1.1.1.m1.1.1">
                ↑
               </ci>
              </annotation-xml>
              <annotation encoding="application/x-tex" id="S4.T5.4.4.4.1.1.1.1.m1.1c">
               \uparrow
              </annotation>
             </semantics>
            </math>
           </span>
          </span>
          <span class="ltx_tr" id="S4.T5.4.4.4.1.1.2">
           <span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T5.4.4.4.1.1.2.1" style="padding-left:5.5pt;padding-right:5.5pt;">
            (F1 Avg)
           </span>
          </span>
         </span>
        </span>
        <span class="ltx_text" id="S4.T5.4.4.4.4">
        </span>
        <span class="ltx_text" id="S4.T5.4.4.4.5" style="font-size:90%;">
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="S4.T5.4.5">
       <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.4.5.1" style="padding-left:5.5pt;padding-right:5.5pt;">
        <span class="ltx_text" id="S4.T5.4.5.1.1" style="font-size:90%;">
         -
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.4.5.2" style="padding-left:5.5pt;padding-right:5.5pt;">
        <span class="ltx_text" id="S4.T5.4.5.2.1" style="font-size:90%;">
         -
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.4.5.3" style="padding-left:5.5pt;padding-right:5.5pt;">
        <span class="ltx_text" id="S4.T5.4.5.3.1" style="font-size:90%;">
         -
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T5.4.5.4" style="padding-left:5.5pt;padding-right:5.5pt;">
        <span class="ltx_text" id="S4.T5.4.5.4.1" style="font-size:90%;">
         -
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.4.5.5" style="padding-left:5.5pt;padding-right:5.5pt;">
        <span class="ltx_text" id="S4.T5.4.5.5.1" style="font-size:90%;">
         47.83
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.4.5.6" style="padding-left:5.5pt;padding-right:5.5pt;">
        <span class="ltx_text" id="S4.T5.4.5.6.1" style="font-size:90%;">
         0.55
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.4.5.7" style="padding-left:5.5pt;padding-right:5.5pt;">
        <span class="ltx_text" id="S4.T5.4.5.7.1" style="font-size:90%;">
         0.61
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="S4.T5.4.6">
       <td class="ltx_td ltx_align_center" id="S4.T5.4.6.1" style="padding-left:5.5pt;padding-right:5.5pt;">
        <span class="ltx_text" id="S4.T5.4.6.1.1" style="font-size:90%;">
         ✓
        </span>
       </td>
       <td class="ltx_td ltx_align_center" id="S4.T5.4.6.2" style="padding-left:5.5pt;padding-right:5.5pt;">
        <span class="ltx_text" id="S4.T5.4.6.2.1" style="font-size:90%;">
         -
        </span>
       </td>
       <td class="ltx_td ltx_align_center" id="S4.T5.4.6.3" style="padding-left:5.5pt;padding-right:5.5pt;">
        <span class="ltx_text" id="S4.T5.4.6.3.1" style="font-size:90%;">
         -
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_r" id="S4.T5.4.6.4" style="padding-left:5.5pt;padding-right:5.5pt;">
        <span class="ltx_text" id="S4.T5.4.6.4.1" style="font-size:90%;">
         -
        </span>
       </td>
       <td class="ltx_td ltx_align_center" id="S4.T5.4.6.5" style="padding-left:5.5pt;padding-right:5.5pt;">
        <span class="ltx_text" id="S4.T5.4.6.5.1" style="font-size:90%;">
         64.54
        </span>
       </td>
       <td class="ltx_td ltx_align_center" id="S4.T5.4.6.6" style="padding-left:5.5pt;padding-right:5.5pt;">
        <span class="ltx_text ltx_font_bold" id="S4.T5.4.6.6.1" style="font-size:90%;">
         0.78
        </span>
       </td>
       <td class="ltx_td ltx_align_center" id="S4.T5.4.6.7" style="padding-left:5.5pt;padding-right:5.5pt;">
        <span class="ltx_text" id="S4.T5.4.6.7.1" style="font-size:90%;">
         0.70
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="S4.T5.4.7">
       <td class="ltx_td ltx_align_center" id="S4.T5.4.7.1" style="padding-left:5.5pt;padding-right:5.5pt;">
        <span class="ltx_text" id="S4.T5.4.7.1.1" style="font-size:90%;">
         ✓
        </span>
       </td>
       <td class="ltx_td ltx_align_center" id="S4.T5.4.7.2" style="padding-left:5.5pt;padding-right:5.5pt;">
        <span class="ltx_text" id="S4.T5.4.7.2.1" style="font-size:90%;">
         ✓
        </span>
       </td>
       <td class="ltx_td ltx_align_center" id="S4.T5.4.7.3" style="padding-left:5.5pt;padding-right:5.5pt;">
        <span class="ltx_text" id="S4.T5.4.7.3.1" style="font-size:90%;">
         -
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_r" id="S4.T5.4.7.4" style="padding-left:5.5pt;padding-right:5.5pt;">
        <span class="ltx_text" id="S4.T5.4.7.4.1" style="font-size:90%;">
         -
        </span>
       </td>
       <td class="ltx_td ltx_align_center" id="S4.T5.4.7.5" style="padding-left:5.5pt;padding-right:5.5pt;">
        <span class="ltx_text" id="S4.T5.4.7.5.1" style="font-size:90%;">
         67.22
        </span>
       </td>
       <td class="ltx_td ltx_align_center" id="S4.T5.4.7.6" style="padding-left:5.5pt;padding-right:5.5pt;">
        <span class="ltx_text" id="S4.T5.4.7.6.1" style="font-size:90%;">
         0.70
        </span>
       </td>
       <td class="ltx_td ltx_align_center" id="S4.T5.4.7.7" style="padding-left:5.5pt;padding-right:5.5pt;">
        <span class="ltx_text" id="S4.T5.4.7.7.1" style="font-size:90%;">
         0.68
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="S4.T5.4.8">
       <td class="ltx_td ltx_align_center" id="S4.T5.4.8.1" style="padding-left:5.5pt;padding-right:5.5pt;">
        <span class="ltx_text" id="S4.T5.4.8.1.1" style="font-size:90%;">
         ✓
        </span>
       </td>
       <td class="ltx_td ltx_align_center" id="S4.T5.4.8.2" style="padding-left:5.5pt;padding-right:5.5pt;">
        <span class="ltx_text" id="S4.T5.4.8.2.1" style="font-size:90%;">
         -
        </span>
       </td>
       <td class="ltx_td ltx_align_center" id="S4.T5.4.8.3" style="padding-left:5.5pt;padding-right:5.5pt;">
        <span class="ltx_text" id="S4.T5.4.8.3.1" style="font-size:90%;">
         ✓
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_r" id="S4.T5.4.8.4" style="padding-left:5.5pt;padding-right:5.5pt;">
        <span class="ltx_text" id="S4.T5.4.8.4.1" style="font-size:90%;">
         -
        </span>
       </td>
       <td class="ltx_td ltx_align_center" id="S4.T5.4.8.5" style="padding-left:5.5pt;padding-right:5.5pt;">
        <span class="ltx_text ltx_font_bold" id="S4.T5.4.8.5.1" style="font-size:90%;">
         75.23
        </span>
       </td>
       <td class="ltx_td ltx_align_center" id="S4.T5.4.8.6" style="padding-left:5.5pt;padding-right:5.5pt;">
        <span class="ltx_text ltx_font_bold" id="S4.T5.4.8.6.1" style="font-size:90%;">
         0.78
        </span>
       </td>
       <td class="ltx_td ltx_align_center" id="S4.T5.4.8.7" style="padding-left:5.5pt;padding-right:5.5pt;">
        <span class="ltx_text ltx_font_bold" id="S4.T5.4.8.7.1" style="font-size:90%;">
         0.75
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="S4.T5.4.9">
       <td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T5.4.9.1" style="padding-left:5.5pt;padding-right:5.5pt;">
        <span class="ltx_text" id="S4.T5.4.9.1.1" style="font-size:90%;">
         ✓
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T5.4.9.2" style="padding-left:5.5pt;padding-right:5.5pt;">
        <span class="ltx_text" id="S4.T5.4.9.2.1" style="font-size:90%;">
         -
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T5.4.9.3" style="padding-left:5.5pt;padding-right:5.5pt;">
        <span class="ltx_text" id="S4.T5.4.9.3.1" style="font-size:90%;">
         ✓
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S4.T5.4.9.4" style="padding-left:5.5pt;padding-right:5.5pt;">
        <span class="ltx_text" id="S4.T5.4.9.4.1" style="font-size:90%;">
         ✓
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T5.4.9.5" style="padding-left:5.5pt;padding-right:5.5pt;">
        <span class="ltx_text" id="S4.T5.4.9.5.1" style="font-size:90%;">
         74.99
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T5.4.9.6" style="padding-left:5.5pt;padding-right:5.5pt;">
        <span class="ltx_text" id="S4.T5.4.9.6.1" style="font-size:90%;">
         0.77
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T5.4.9.7" style="padding-left:5.5pt;padding-right:5.5pt;">
        <span class="ltx_text ltx_font_bold" id="S4.T5.4.9.7.1" style="font-size:90%;">
         0.75
        </span>
       </td>
      </tr>
     </table>
     <figcaption class="ltx_caption ltx_centering" style="font-size:90%;">
      <span class="ltx_tag ltx_tag_table">
       Table 5:
      </span>
      <span class="ltx_text ltx_font_bold" id="S4.T5.9.1">
       Ablation results of sensor modality and temporal information.
      </span>
      MV denotes multi-view images, CT denotes concatenating temporal tokens, TQ denotes temporal QFormer, and PC denotes point clouds. MV + TQ shows the best decision performance, and CT brings a small improvement in accuracy but leads to greater computational consumption. PC has little impact on DriveMLM. This might caused by the large representation gap between the sparse pyramid transformer and the MLLM Decoder.
     </figcaption>
    </figure>
   </section>
   <section class="ltx_paragraph" id="S4.SS5.SSS0.Px2">
    <h4 class="ltx_title ltx_title_paragraph">
     Temporal Module Design
    </h4>
    <div class="ltx_para" id="S4.SS5.SSS0.Px2.p1">
     <p class="ltx_p" id="S4.SS5.SSS0.Px2.p1.5">
      We propose the temporal QFormer module to process the temporal multi-view images. A simple and naive design is directly concatenating query tokens temporal to generate
      <math alttext="N_{tq}=T\times N_{I}\times N_{Q}" class="ltx_Math" display="inline" id="S4.SS5.SSS0.Px2.p1.1.m1.1">
       <semantics id="S4.SS5.SSS0.Px2.p1.1.m1.1a">
        <mrow id="S4.SS5.SSS0.Px2.p1.1.m1.1.1" xref="S4.SS5.SSS0.Px2.p1.1.m1.1.1.cmml">
         <msub id="S4.SS5.SSS0.Px2.p1.1.m1.1.1.2" xref="S4.SS5.SSS0.Px2.p1.1.m1.1.1.2.cmml">
          <mi id="S4.SS5.SSS0.Px2.p1.1.m1.1.1.2.2" xref="S4.SS5.SSS0.Px2.p1.1.m1.1.1.2.2.cmml">
           N
          </mi>
          <mrow id="S4.SS5.SSS0.Px2.p1.1.m1.1.1.2.3" xref="S4.SS5.SSS0.Px2.p1.1.m1.1.1.2.3.cmml">
           <mi id="S4.SS5.SSS0.Px2.p1.1.m1.1.1.2.3.2" xref="S4.SS5.SSS0.Px2.p1.1.m1.1.1.2.3.2.cmml">
            t
           </mi>
           <mo id="S4.SS5.SSS0.Px2.p1.1.m1.1.1.2.3.1" lspace="0em" rspace="0em" xref="S4.SS5.SSS0.Px2.p1.1.m1.1.1.2.3.1.cmml">
            ​
           </mo>
           <mi id="S4.SS5.SSS0.Px2.p1.1.m1.1.1.2.3.3" xref="S4.SS5.SSS0.Px2.p1.1.m1.1.1.2.3.3.cmml">
            q
           </mi>
          </mrow>
         </msub>
         <mo id="S4.SS5.SSS0.Px2.p1.1.m1.1.1.1" xref="S4.SS5.SSS0.Px2.p1.1.m1.1.1.1.cmml">
          =
         </mo>
         <mrow id="S4.SS5.SSS0.Px2.p1.1.m1.1.1.3" xref="S4.SS5.SSS0.Px2.p1.1.m1.1.1.3.cmml">
          <mi id="S4.SS5.SSS0.Px2.p1.1.m1.1.1.3.2" xref="S4.SS5.SSS0.Px2.p1.1.m1.1.1.3.2.cmml">
           T
          </mi>
          <mo id="S4.SS5.SSS0.Px2.p1.1.m1.1.1.3.1" lspace="0.222em" rspace="0.222em" xref="S4.SS5.SSS0.Px2.p1.1.m1.1.1.3.1.cmml">
           ×
          </mo>
          <msub id="S4.SS5.SSS0.Px2.p1.1.m1.1.1.3.3" xref="S4.SS5.SSS0.Px2.p1.1.m1.1.1.3.3.cmml">
           <mi id="S4.SS5.SSS0.Px2.p1.1.m1.1.1.3.3.2" xref="S4.SS5.SSS0.Px2.p1.1.m1.1.1.3.3.2.cmml">
            N
           </mi>
           <mi id="S4.SS5.SSS0.Px2.p1.1.m1.1.1.3.3.3" xref="S4.SS5.SSS0.Px2.p1.1.m1.1.1.3.3.3.cmml">
            I
           </mi>
          </msub>
          <mo id="S4.SS5.SSS0.Px2.p1.1.m1.1.1.3.1a" lspace="0.222em" rspace="0.222em" xref="S4.SS5.SSS0.Px2.p1.1.m1.1.1.3.1.cmml">
           ×
          </mo>
          <msub id="S4.SS5.SSS0.Px2.p1.1.m1.1.1.3.4" xref="S4.SS5.SSS0.Px2.p1.1.m1.1.1.3.4.cmml">
           <mi id="S4.SS5.SSS0.Px2.p1.1.m1.1.1.3.4.2" xref="S4.SS5.SSS0.Px2.p1.1.m1.1.1.3.4.2.cmml">
            N
           </mi>
           <mi id="S4.SS5.SSS0.Px2.p1.1.m1.1.1.3.4.3" xref="S4.SS5.SSS0.Px2.p1.1.m1.1.1.3.4.3.cmml">
            Q
           </mi>
          </msub>
         </mrow>
        </mrow>
        <annotation-xml encoding="MathML-Content" id="S4.SS5.SSS0.Px2.p1.1.m1.1b">
         <apply id="S4.SS5.SSS0.Px2.p1.1.m1.1.1.cmml" xref="S4.SS5.SSS0.Px2.p1.1.m1.1.1">
          <eq id="S4.SS5.SSS0.Px2.p1.1.m1.1.1.1.cmml" xref="S4.SS5.SSS0.Px2.p1.1.m1.1.1.1">
          </eq>
          <apply id="S4.SS5.SSS0.Px2.p1.1.m1.1.1.2.cmml" xref="S4.SS5.SSS0.Px2.p1.1.m1.1.1.2">
           <csymbol cd="ambiguous" id="S4.SS5.SSS0.Px2.p1.1.m1.1.1.2.1.cmml" xref="S4.SS5.SSS0.Px2.p1.1.m1.1.1.2">
            subscript
           </csymbol>
           <ci id="S4.SS5.SSS0.Px2.p1.1.m1.1.1.2.2.cmml" xref="S4.SS5.SSS0.Px2.p1.1.m1.1.1.2.2">
            𝑁
           </ci>
           <apply id="S4.SS5.SSS0.Px2.p1.1.m1.1.1.2.3.cmml" xref="S4.SS5.SSS0.Px2.p1.1.m1.1.1.2.3">
            <times id="S4.SS5.SSS0.Px2.p1.1.m1.1.1.2.3.1.cmml" xref="S4.SS5.SSS0.Px2.p1.1.m1.1.1.2.3.1">
            </times>
            <ci id="S4.SS5.SSS0.Px2.p1.1.m1.1.1.2.3.2.cmml" xref="S4.SS5.SSS0.Px2.p1.1.m1.1.1.2.3.2">
             𝑡
            </ci>
            <ci id="S4.SS5.SSS0.Px2.p1.1.m1.1.1.2.3.3.cmml" xref="S4.SS5.SSS0.Px2.p1.1.m1.1.1.2.3.3">
             𝑞
            </ci>
           </apply>
          </apply>
          <apply id="S4.SS5.SSS0.Px2.p1.1.m1.1.1.3.cmml" xref="S4.SS5.SSS0.Px2.p1.1.m1.1.1.3">
           <times id="S4.SS5.SSS0.Px2.p1.1.m1.1.1.3.1.cmml" xref="S4.SS5.SSS0.Px2.p1.1.m1.1.1.3.1">
           </times>
           <ci id="S4.SS5.SSS0.Px2.p1.1.m1.1.1.3.2.cmml" xref="S4.SS5.SSS0.Px2.p1.1.m1.1.1.3.2">
            𝑇
           </ci>
           <apply id="S4.SS5.SSS0.Px2.p1.1.m1.1.1.3.3.cmml" xref="S4.SS5.SSS0.Px2.p1.1.m1.1.1.3.3">
            <csymbol cd="ambiguous" id="S4.SS5.SSS0.Px2.p1.1.m1.1.1.3.3.1.cmml" xref="S4.SS5.SSS0.Px2.p1.1.m1.1.1.3.3">
             subscript
            </csymbol>
            <ci id="S4.SS5.SSS0.Px2.p1.1.m1.1.1.3.3.2.cmml" xref="S4.SS5.SSS0.Px2.p1.1.m1.1.1.3.3.2">
             𝑁
            </ci>
            <ci id="S4.SS5.SSS0.Px2.p1.1.m1.1.1.3.3.3.cmml" xref="S4.SS5.SSS0.Px2.p1.1.m1.1.1.3.3.3">
             𝐼
            </ci>
           </apply>
           <apply id="S4.SS5.SSS0.Px2.p1.1.m1.1.1.3.4.cmml" xref="S4.SS5.SSS0.Px2.p1.1.m1.1.1.3.4">
            <csymbol cd="ambiguous" id="S4.SS5.SSS0.Px2.p1.1.m1.1.1.3.4.1.cmml" xref="S4.SS5.SSS0.Px2.p1.1.m1.1.1.3.4">
             subscript
            </csymbol>
            <ci id="S4.SS5.SSS0.Px2.p1.1.m1.1.1.3.4.2.cmml" xref="S4.SS5.SSS0.Px2.p1.1.m1.1.1.3.4.2">
             𝑁
            </ci>
            <ci id="S4.SS5.SSS0.Px2.p1.1.m1.1.1.3.4.3.cmml" xref="S4.SS5.SSS0.Px2.p1.1.m1.1.1.3.4.3">
             𝑄
            </ci>
           </apply>
          </apply>
         </apply>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S4.SS5.SSS0.Px2.p1.1.m1.1c">
         N_{tq}=T\times N_{I}\times N_{Q}
        </annotation>
       </semantics>
      </math>
      tokens acting as LLM input. But
      <math alttext="N_{tq}" class="ltx_Math" display="inline" id="S4.SS5.SSS0.Px2.p1.2.m2.1">
       <semantics id="S4.SS5.SSS0.Px2.p1.2.m2.1a">
        <msub id="S4.SS5.SSS0.Px2.p1.2.m2.1.1" xref="S4.SS5.SSS0.Px2.p1.2.m2.1.1.cmml">
         <mi id="S4.SS5.SSS0.Px2.p1.2.m2.1.1.2" xref="S4.SS5.SSS0.Px2.p1.2.m2.1.1.2.cmml">
          N
         </mi>
         <mrow id="S4.SS5.SSS0.Px2.p1.2.m2.1.1.3" xref="S4.SS5.SSS0.Px2.p1.2.m2.1.1.3.cmml">
          <mi id="S4.SS5.SSS0.Px2.p1.2.m2.1.1.3.2" xref="S4.SS5.SSS0.Px2.p1.2.m2.1.1.3.2.cmml">
           t
          </mi>
          <mo id="S4.SS5.SSS0.Px2.p1.2.m2.1.1.3.1" lspace="0em" rspace="0em" xref="S4.SS5.SSS0.Px2.p1.2.m2.1.1.3.1.cmml">
           ​
          </mo>
          <mi id="S4.SS5.SSS0.Px2.p1.2.m2.1.1.3.3" xref="S4.SS5.SSS0.Px2.p1.2.m2.1.1.3.3.cmml">
           q
          </mi>
         </mrow>
        </msub>
        <annotation-xml encoding="MathML-Content" id="S4.SS5.SSS0.Px2.p1.2.m2.1b">
         <apply id="S4.SS5.SSS0.Px2.p1.2.m2.1.1.cmml" xref="S4.SS5.SSS0.Px2.p1.2.m2.1.1">
          <csymbol cd="ambiguous" id="S4.SS5.SSS0.Px2.p1.2.m2.1.1.1.cmml" xref="S4.SS5.SSS0.Px2.p1.2.m2.1.1">
           subscript
          </csymbol>
          <ci id="S4.SS5.SSS0.Px2.p1.2.m2.1.1.2.cmml" xref="S4.SS5.SSS0.Px2.p1.2.m2.1.1.2">
           𝑁
          </ci>
          <apply id="S4.SS5.SSS0.Px2.p1.2.m2.1.1.3.cmml" xref="S4.SS5.SSS0.Px2.p1.2.m2.1.1.3">
           <times id="S4.SS5.SSS0.Px2.p1.2.m2.1.1.3.1.cmml" xref="S4.SS5.SSS0.Px2.p1.2.m2.1.1.3.1">
           </times>
           <ci id="S4.SS5.SSS0.Px2.p1.2.m2.1.1.3.2.cmml" xref="S4.SS5.SSS0.Px2.p1.2.m2.1.1.3.2">
            𝑡
           </ci>
           <ci id="S4.SS5.SSS0.Px2.p1.2.m2.1.1.3.3.cmml" xref="S4.SS5.SSS0.Px2.p1.2.m2.1.1.3.3">
            𝑞
           </ci>
          </apply>
         </apply>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S4.SS5.SSS0.Px2.p1.2.m2.1c">
         N_{tq}
        </annotation>
       </semantics>
      </math>
      increases with
      <math alttext="T" class="ltx_Math" display="inline" id="S4.SS5.SSS0.Px2.p1.3.m3.1">
       <semantics id="S4.SS5.SSS0.Px2.p1.3.m3.1a">
        <mi id="S4.SS5.SSS0.Px2.p1.3.m3.1.1" xref="S4.SS5.SSS0.Px2.p1.3.m3.1.1.cmml">
         T
        </mi>
        <annotation-xml encoding="MathML-Content" id="S4.SS5.SSS0.Px2.p1.3.m3.1b">
         <ci id="S4.SS5.SSS0.Px2.p1.3.m3.1.1.cmml" xref="S4.SS5.SSS0.Px2.p1.3.m3.1.1">
          𝑇
         </ci>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S4.SS5.SSS0.Px2.p1.3.m3.1c">
         T
        </annotation>
       </semantics>
      </math>
      , contributing to large computational costs. Instead, we propose the temporal QFormer module to process temporal images for each view separately, generating
      <math alttext="N_{I}\times N_{Q}" class="ltx_Math" display="inline" id="S4.SS5.SSS0.Px2.p1.4.m4.1">
       <semantics id="S4.SS5.SSS0.Px2.p1.4.m4.1a">
        <mrow id="S4.SS5.SSS0.Px2.p1.4.m4.1.1" xref="S4.SS5.SSS0.Px2.p1.4.m4.1.1.cmml">
         <msub id="S4.SS5.SSS0.Px2.p1.4.m4.1.1.2" xref="S4.SS5.SSS0.Px2.p1.4.m4.1.1.2.cmml">
          <mi id="S4.SS5.SSS0.Px2.p1.4.m4.1.1.2.2" xref="S4.SS5.SSS0.Px2.p1.4.m4.1.1.2.2.cmml">
           N
          </mi>
          <mi id="S4.SS5.SSS0.Px2.p1.4.m4.1.1.2.3" xref="S4.SS5.SSS0.Px2.p1.4.m4.1.1.2.3.cmml">
           I
          </mi>
         </msub>
         <mo id="S4.SS5.SSS0.Px2.p1.4.m4.1.1.1" lspace="0.222em" rspace="0.222em" xref="S4.SS5.SSS0.Px2.p1.4.m4.1.1.1.cmml">
          ×
         </mo>
         <msub id="S4.SS5.SSS0.Px2.p1.4.m4.1.1.3" xref="S4.SS5.SSS0.Px2.p1.4.m4.1.1.3.cmml">
          <mi id="S4.SS5.SSS0.Px2.p1.4.m4.1.1.3.2" xref="S4.SS5.SSS0.Px2.p1.4.m4.1.1.3.2.cmml">
           N
          </mi>
          <mi id="S4.SS5.SSS0.Px2.p1.4.m4.1.1.3.3" xref="S4.SS5.SSS0.Px2.p1.4.m4.1.1.3.3.cmml">
           Q
          </mi>
         </msub>
        </mrow>
        <annotation-xml encoding="MathML-Content" id="S4.SS5.SSS0.Px2.p1.4.m4.1b">
         <apply id="S4.SS5.SSS0.Px2.p1.4.m4.1.1.cmml" xref="S4.SS5.SSS0.Px2.p1.4.m4.1.1">
          <times id="S4.SS5.SSS0.Px2.p1.4.m4.1.1.1.cmml" xref="S4.SS5.SSS0.Px2.p1.4.m4.1.1.1">
          </times>
          <apply id="S4.SS5.SSS0.Px2.p1.4.m4.1.1.2.cmml" xref="S4.SS5.SSS0.Px2.p1.4.m4.1.1.2">
           <csymbol cd="ambiguous" id="S4.SS5.SSS0.Px2.p1.4.m4.1.1.2.1.cmml" xref="S4.SS5.SSS0.Px2.p1.4.m4.1.1.2">
            subscript
           </csymbol>
           <ci id="S4.SS5.SSS0.Px2.p1.4.m4.1.1.2.2.cmml" xref="S4.SS5.SSS0.Px2.p1.4.m4.1.1.2.2">
            𝑁
           </ci>
           <ci id="S4.SS5.SSS0.Px2.p1.4.m4.1.1.2.3.cmml" xref="S4.SS5.SSS0.Px2.p1.4.m4.1.1.2.3">
            𝐼
           </ci>
          </apply>
          <apply id="S4.SS5.SSS0.Px2.p1.4.m4.1.1.3.cmml" xref="S4.SS5.SSS0.Px2.p1.4.m4.1.1.3">
           <csymbol cd="ambiguous" id="S4.SS5.SSS0.Px2.p1.4.m4.1.1.3.1.cmml" xref="S4.SS5.SSS0.Px2.p1.4.m4.1.1.3">
            subscript
           </csymbol>
           <ci id="S4.SS5.SSS0.Px2.p1.4.m4.1.1.3.2.cmml" xref="S4.SS5.SSS0.Px2.p1.4.m4.1.1.3.2">
            𝑁
           </ci>
           <ci id="S4.SS5.SSS0.Px2.p1.4.m4.1.1.3.3.cmml" xref="S4.SS5.SSS0.Px2.p1.4.m4.1.1.3.3">
            𝑄
           </ci>
          </apply>
         </apply>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S4.SS5.SSS0.Px2.p1.4.m4.1c">
         N_{I}\times N_{Q}
        </annotation>
       </semantics>
      </math>
      tokens for LLM input. The comparison of the temporal module is shown in table
      <a class="ltx_ref" href="#S4.T5" title="Table 5 ‣ Sensor Modality ‣ 4.5 Ablation Study ‣ 4 Experiments ‣ DriveMLM: Aligning Multi-Modal Large Language Models with Behavioral Planning States for Autonomous Driving">
       <span class="ltx_text ltx_ref_tag">
        5
       </span>
      </a>
      , indicating the better performance of our temporal module design with fewer image tokens. We set
      <math alttext="T=2" class="ltx_Math" display="inline" id="S4.SS5.SSS0.Px2.p1.5.m5.1">
       <semantics id="S4.SS5.SSS0.Px2.p1.5.m5.1a">
        <mrow id="S4.SS5.SSS0.Px2.p1.5.m5.1.1" xref="S4.SS5.SSS0.Px2.p1.5.m5.1.1.cmml">
         <mi id="S4.SS5.SSS0.Px2.p1.5.m5.1.1.2" xref="S4.SS5.SSS0.Px2.p1.5.m5.1.1.2.cmml">
          T
         </mi>
         <mo id="S4.SS5.SSS0.Px2.p1.5.m5.1.1.1" xref="S4.SS5.SSS0.Px2.p1.5.m5.1.1.1.cmml">
          =
         </mo>
         <mn id="S4.SS5.SSS0.Px2.p1.5.m5.1.1.3" xref="S4.SS5.SSS0.Px2.p1.5.m5.1.1.3.cmml">
          2
         </mn>
        </mrow>
        <annotation-xml encoding="MathML-Content" id="S4.SS5.SSS0.Px2.p1.5.m5.1b">
         <apply id="S4.SS5.SSS0.Px2.p1.5.m5.1.1.cmml" xref="S4.SS5.SSS0.Px2.p1.5.m5.1.1">
          <eq id="S4.SS5.SSS0.Px2.p1.5.m5.1.1.1.cmml" xref="S4.SS5.SSS0.Px2.p1.5.m5.1.1.1">
          </eq>
          <ci id="S4.SS5.SSS0.Px2.p1.5.m5.1.1.2.cmml" xref="S4.SS5.SSS0.Px2.p1.5.m5.1.1.2">
           𝑇
          </ci>
          <cn id="S4.SS5.SSS0.Px2.p1.5.m5.1.1.3.cmml" type="integer" xref="S4.SS5.SSS0.Px2.p1.5.m5.1.1.3">
           2
          </cn>
         </apply>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S4.SS5.SSS0.Px2.p1.5.m5.1c">
         T=2
        </annotation>
       </semantics>
      </math>
      by default in our experiments.
     </p>
    </div>
    <figure class="ltx_figure" id="S4.F4">
     <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="237" id="S4.F4.g1" src="/html/2312.09245/assets/x6.png" width="207"/>
     <figcaption class="ltx_caption ltx_centering">
      <span class="ltx_tag ltx_tag_figure">
       <span class="ltx_text" id="S4.F4.3.1.1" style="font-size:90%;">
        Figure 4
       </span>
       :
      </span>
      <span class="ltx_text ltx_font_bold" id="S4.F4.4.2" style="font-size:90%;">
       Visualization of human interaction with DriveMLM
       <span class="ltx_text ltx_font_medium" id="S4.F4.4.2.1">
        , featuring examples of (a) a successful overtake and (b) a failed overtake due to unreasonable demands rejected by DriveMLM. In each example, the left image captures the moment of giving instructions, while the right image represents a subsequent stage of instruction execution.
       </span>
      </span>
     </figcaption>
    </figure>
    <figure class="ltx_figure" id="S4.F5">
     <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="87" id="S4.F5.g1" src="/html/2312.09245/assets/x7.png" width="207"/>
     <figcaption class="ltx_caption ltx_centering">
      <span class="ltx_tag ltx_tag_figure">
       <span class="ltx_text" id="S4.F5.3.1.1" style="font-size:90%;">
        Figure 5
       </span>
       :
      </span>
      <span class="ltx_text ltx_font_bold" id="S4.F5.4.2" style="font-size:90%;">
       The zero-shot performance of DriveMLM on the real driving scene from nuScenes dataset.
       <span class="ltx_text ltx_font_medium" id="S4.F5.4.2.1">
        (a) DriveMLM can recognize the red light and stop (b) DriveMLM can infer the location of the intersection and slow down in advance.
       </span>
      </span>
     </figcaption>
    </figure>
   </section>
  </section>
  <section class="ltx_subsection" id="S4.SS6">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     4.6
    </span>
    Case Study &amp; Visualization
   </h3>
   <section class="ltx_paragraph" id="S4.SS6.SSS0.Px1">
    <h4 class="ltx_title ltx_title_paragraph">
     Human Interaction
    </h4>
    <div class="ltx_para" id="S4.SS6.SSS0.Px1.p1">
     <p class="ltx_p" id="S4.SS6.SSS0.Px1.p1.1">
      Figure
      <a class="ltx_ref" href="#S4.F4" title="Figure 4 ‣ Temporal Module Design ‣ 4.5 Ablation Study ‣ 4 Experiments ‣ DriveMLM: Aligning Multi-Modal Large Language Models with Behavioral Planning States for Autonomous Driving">
       <span class="ltx_text ltx_ref_tag">
        4
       </span>
      </a>
      provides an example of how vehicle control can be achieved through human instructions. The control process involves analyzing the road conditions, making decision choices, and providing explanatory statements. When given the identical instruction to “overtake”, DriveMLM exhibits varying responses based on the analysis of the current traffic conditions. In the scenario where the right lane is occupied and the left lane is available, the system opts to overtake from the left.
However, in situations where the given instruction may pose a danger, such as when all lanes are occupied, DriveMLM chooses to refrain from executing the overtaking maneuver and responds appropriately.
DriveMLM, in this context, serves as an interface for human-vehicle interaction, which evaluates the reasonableness of the instruction based on traffic dynamics and ensures its compliance with predefined rules before ultimately selecting a course of action.
     </p>
    </div>
   </section>
   <section class="ltx_paragraph" id="S4.SS6.SSS0.Px2">
    <h4 class="ltx_title ltx_title_paragraph">
     Performance in Real Scenarios
    </h4>
    <div class="ltx_para" id="S4.SS6.SSS0.Px2.p1">
     <p class="ltx_p" id="S4.SS6.SSS0.Px2.p1.1">
      We apply DriveMLM on the nuScenes dataset
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib8" title="">
        <span class="ltx_text" style="font-size:90%;">
         8
        </span>
       </a>
       ]
      </cite>
      to test the zero-shot performance of the developed driving system.
We annotate 6,019 frames on the validation set, and the zero-shot performance of decision accuracy is 0.395.
Figure
      <a class="ltx_ref" href="#S4.F5" title="Figure 5 ‣ Temporal Module Design ‣ 4.5 Ablation Study ‣ 4 Experiments ‣ DriveMLM: Aligning Multi-Modal Large Language Models with Behavioral Planning States for Autonomous Driving">
       <span class="ltx_text ltx_ref_tag">
        5
       </span>
      </a>
      presents the result on two real driving scenes, indicating the generability of DriveMLM.
     </p>
    </div>
   </section>
  </section>
 </section>
 <section class="ltx_section" id="S5">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    5
   </span>
   Conclusion
  </h2>
  <div class="ltx_para" id="S5.p1">
   <p class="ltx_p" id="S5.p1.1">
    In this work, we have presented DriveMLM, a novel framework that leverages large language models (LLMs) for autonomous driving (AD). DriveMLM can perform close-loop AD in realistic simulators by using a multi-modal LLM (MLLM) to model the behavior planning module of a modular AD system. DriveMLM can also generate natural language explanations for its driving decisions, which can enhance the transparency and trustworthiness of the AD system. We have shown that DriveMLM can outperform the Apollo baseline on the CARLA Town05 Long benchmark. We believe that our work can inspire more research on the integration of LLMs and AD.
   </p>
  </div>
  <div class="ltx_pagination ltx_role_newpage">
  </div>
  <div class="ltx_para ltx_noindent" id="S5.p2">
   <span class="ltx_ERROR undefined" id="S5.p2.1">
    \thetitle
   </span>
   <br class="ltx_break ltx_centering"/>
   <p class="ltx_p ltx_align_center" id="S5.p2.2">
    <span class="ltx_text" id="S5.p2.2.1" style="font-size:144%;">
     Supplementary Material
     <br class="ltx_break"/>
    </span>
   </p>
  </div>
 </section>
 <section class="ltx_appendix" id="A1">
  <h2 class="ltx_title ltx_title_appendix" style="font-size:144%;">
   <span class="ltx_tag ltx_tag_appendix">
    Appendix A
   </span>
   Prompt Details
  </h2>
  <div class="ltx_para" id="A1.p1">
   <p class="ltx_p" id="A1.p1.1">
    <span class="ltx_text" id="A1.p1.1.1" style="font-size:144%;">
     As illustrated in Table
    </span>
    <a class="ltx_ref" href="#A1.T1" style="font-size:144%;" title="Table A ‣ Appendix A Prompt Details ‣ DriveMLM: Aligning Multi-Modal Large Language Models with Behavioral Planning States for Autonomous Driving">
     <span class="ltx_text ltx_ref_tag">
      A
     </span>
    </a>
    <span class="ltx_text" id="A1.p1.1.2" style="font-size:144%;">
     , we provide the complete system message which includes detailed definitions of path decision states and speed decision states. Specifically, our path decision states include 5 states, which are {FOLLOW_LANE, LEFT_LANE_CHANGE, RIGHT_LANE_CHANGE, LEFT_LANE_BORROW, RIGHT_LANE_BORROW}, and our speed decision states include 4 states: {KEEP, ACCELERATE, DECELERATE, STOP}.
    </span>
   </p>
  </div>
  <div class="ltx_para" id="A1.p2">
   <p class="ltx_p" id="A1.p2.1">
    <span class="ltx_text" id="A1.p2.1.1" style="font-size:144%;">
     In Table
    </span>
    <a class="ltx_ref" href="#A1.T2" style="font-size:144%;" title="Table B ‣ Appendix A Prompt Details ‣ DriveMLM: Aligning Multi-Modal Large Language Models with Behavioral Planning States for Autonomous Driving">
     <span class="ltx_text ltx_ref_tag">
      B
     </span>
    </a>
    <span class="ltx_text" id="A1.p2.1.2" style="font-size:144%;">
     , we detail the prompts utilized for describing the surrounding environments. In Table
    </span>
    <a class="ltx_ref" href="#A1.T3" style="font-size:144%;" title="Table C ‣ Appendix A Prompt Details ‣ DriveMLM: Aligning Multi-Modal Large Language Models with Behavioral Planning States for Autonomous Driving">
     <span class="ltx_text ltx_ref_tag">
      C
     </span>
    </a>
    <span class="ltx_text" id="A1.p2.1.3" style="font-size:144%;">
     , prompts are employed to derive driving decisions based on navigation commands. The prompts listed in Table
    </span>
    <a class="ltx_ref" href="#A1.T4" style="font-size:144%;" title="Table D ‣ Appendix A Prompt Details ‣ DriveMLM: Aligning Multi-Modal Large Language Models with Behavioral Planning States for Autonomous Driving">
     <span class="ltx_text ltx_ref_tag">
      D
     </span>
    </a>
    <span class="ltx_text" id="A1.p2.1.4" style="font-size:144%;">
     are used to elicit explanations from the model regarding its decisions. Finally, in Table
    </span>
    <a class="ltx_ref" href="#A1.T5" style="font-size:144%;" title="Table E ‣ Appendix A Prompt Details ‣ DriveMLM: Aligning Multi-Modal Large Language Models with Behavioral Planning States for Autonomous Driving">
     <span class="ltx_text ltx_ref_tag">
      E
     </span>
    </a>
    <span class="ltx_text" id="A1.p2.1.5" style="font-size:144%;">
     , we present the human instructions that were used to guide the model’s decision-making process.
    </span>
   </p>
  </div>
  <figure class="ltx_table" id="A1.T1">
   <svg class="ltx_picture ltx_centering" height="409.46" id="A1.T1.pic1" overflow="visible" version="1.1" width="600">
    <g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,409.46) matrix(1 0 0 -1 0 0)">
     <g fill="#404040" fill-opacity="1.0">
      <path d="M 0 5.91 L 0 403.55 C 0 406.82 2.64 409.46 5.91 409.46 L 594.09 409.46 C 597.36 409.46 600 406.82 600 403.55 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none">
      </path>
     </g>
     <g fill="#F2F2F2" fill-opacity="1.0">
      <path d="M 1.97 5.91 L 1.97 403.55 C 1.97 405.73 3.73 407.49 5.91 407.49 L 594.09 407.49 C 596.27 407.49 598.03 405.73 598.03 403.55 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none">
      </path>
     </g>
     <g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)">
      <foreignobject color="#000000" height="381.9" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">
       <span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="A1.T1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1" style="width:402.3pt;">
        <span class="ltx_p ltx_align_left" id="A1.T1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1">
         <span class="ltx_text ltx_markedasmath ltx_font_bold" id="A1.T1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1" style="font-size:90%;">
          System Message
         </span>
         <span class="ltx_text" id="A1.T1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2" style="font-size:90%;">
          : You are a driving assistant to drive the car. You need to follow the navigation command and traffic rules. The traffic rule is 1. Traffic light indications: a. Green: Vehicles may proceed. b. Yellow: Vehicles already past the stop line can continue. c. Red: Vehicles must stop. 2. Vehicle regulations: a. Vehicles must not exceed speed limits indicated by signs or road markings. b. Vehicles must stop when they meet the stop line. 3. Drivers should note specific traffic signs/markings: - Double solid lines: Overtaking is prohibited. Adhere strictly and don’t cross to overtake. - Single solid line: Overtaking is restricted. Overtaking is allowed to provide a safe distance and clear visibility, ensuring safety. 4. If special vehicles like police or ambulances are behind, yield and allow them to pass first. 5. Collision with other moving or static objects is not allowed. Path decision definitions: ‘LEFT_LANE_CHANGE’ refers to a driver’s decision to switch from the current to the adjacent left lane. ‘RIGHT_LANE_CHANGE’ refers to a driver’s decision to switch from the current lane to the adjacent right lane. ‘LEFT_LANE_BORROW’ is when a driver temporarily uses the adjacent left lane, commonly for overtaking or avoiding obstacles. ‘RIGHT_LANE_BORROW’ is when a driver temporarily uses the adjacent right lane, commonly for overtaking or avoiding obstacles. ‘FOLLOW_LANE’ means the driver decides to continue in their current lane. Speed decision definitions: ‘ACCELERATE’ refers to a driver increasing their speed. ‘DECELERATE’ means the driver reduces their speed. ‘KEEP’ refers to a driver keeping a steady speed. ‘STOP’ means the driver completely halts the vehicle. Based on the definitions of path decision, and while adhering to traffic rules, please choose a path and speed decision from the predefined options below, considering the current scenario. Path decisions include [LEFT_LANE_BORROW, RIGHT_LANE_BORROW, LEFT_LANE_CHANGE, RIGHT_LANE_CHANGE, FOLLOW_LANE]. Speed decisions include [ACCELERATE, DECELERATE, KEEP, STOP]. Given the navigation command and driving scene obtained from the camera or LiDAR, You should choose a path decision and a speed decision from the predefined options and give an explanation of your decision.
          <br class="ltx_break"/>
         </span>
        </span>
       </span>
      </foreignobject>
     </g>
    </g>
   </svg>
   <figcaption class="ltx_caption ltx_centering" style="font-size:144%;">
    <span class="ltx_tag ltx_tag_table">
     <span class="ltx_text" id="A1.T1.5.1.1" style="font-size:63%;">
      Table A
     </span>
     :
    </span>
    <span class="ltx_text ltx_font_bold" id="A1.T1.6.2" style="font-size:63%;">
     System message.
     <span class="ltx_text ltx_font_medium" id="A1.T1.6.2.1">
      The system message includes the description of the driving task, the traffic rules, and the definition of decision states.
     </span>
    </span>
   </figcaption>
  </figure>
  <figure class="ltx_table" id="A1.T2">
   <svg class="ltx_picture ltx_centering" height="210.21" id="A1.T2.pic1" overflow="visible" version="1.1" width="600">
    <g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,210.21) matrix(1 0 0 -1 0 0)">
     <g fill="#404040" fill-opacity="1.0">
      <path d="M 0 5.91 L 0 204.3 C 0 207.56 2.64 210.21 5.91 210.21 L 594.09 210.21 C 597.36 210.21 600 207.56 600 204.3 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none">
      </path>
     </g>
     <g fill="#F2F2F2" fill-opacity="1.0">
      <path d="M 1.97 5.91 L 1.97 204.3 C 1.97 206.48 3.73 208.24 5.91 208.24 L 594.09 208.24 C 596.27 208.24 598.03 206.48 598.03 204.3 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none">
      </path>
     </g>
     <g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)">
      <foreignobject color="#000000" height="182.65" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">
       <span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="A1.T2.pic1.1.1.1.1.1" style="width:402.3pt;">
        <span class="ltx_p" id="A1.T2.pic1.1.1.1.1.1.1">
         <span class="ltx_text" id="A1.T2.pic1.1.1.1.1.1.1.1" style="font-size:90%;">
          1. This is a driving scenario. Please describe the environment. The images are provided by the front, left, right, and back cameras of a vehicle. The point cloud is generated by a LiDAR mounted on the top of the vehicle.
          <br class="ltx_break"/>
          2. Could you provide me with a description of the current surroundings? Visual information from the vehicle’s front, left, right, and back cameras provides the images, while a LiDAR sensor mounted on the top of the vehicle generates a point cloud representation of the environment.
          <br class="ltx_break"/>
          3. Would you kindly provide me with a description of the current surroundings? The vehicle’s front, left, right, and back cameras provide the visual images, while a LiDAR system, mounted on the top of the vehicle, generates a point cloud representation of the environment.
          <br class="ltx_break"/>
          4. Could you please describe the current surroundings to me?
          <br class="ltx_break"/>
          5. Could you kindly provide me with a description of the surrounding environment, please?
          <br class="ltx_break"/>
         </span>
        </span>
       </span>
      </foreignobject>
     </g>
    </g>
   </svg>
   <figcaption class="ltx_caption ltx_centering" style="font-size:144%;">
    <span class="ltx_tag ltx_tag_table">
     <span class="ltx_text" id="A1.T2.5.1.1" style="font-size:63%;">
      Table B
     </span>
     :
    </span>
    <span class="ltx_text ltx_font_bold" id="A1.T2.6.2" style="font-size:63%;">
     Prompts used to describe the surrounding environment.
     <span class="ltx_text ltx_font_medium" id="A1.T2.6.2.1">
     </span>
    </span>
   </figcaption>
  </figure>
  <figure class="ltx_table" id="A1.T3">
   <svg class="ltx_picture ltx_centering" height="193.6" id="A1.T3.pic1" overflow="visible" version="1.1" width="600">
    <g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,193.6) matrix(1 0 0 -1 0 0)">
     <g fill="#404040" fill-opacity="1.0">
      <path d="M 0 5.91 L 0 187.7 C 0 190.96 2.64 193.6 5.91 193.6 L 594.09 193.6 C 597.36 193.6 600 190.96 600 187.7 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none">
      </path>
     </g>
     <g fill="#F2F2F2" fill-opacity="1.0">
      <path d="M 1.97 5.91 L 1.97 187.7 C 1.97 189.87 3.73 191.63 5.91 191.63 L 594.09 191.63 C 596.27 191.63 598.03 189.87 598.03 187.7 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none">
      </path>
     </g>
     <g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)">
      <foreignobject color="#000000" height="166.04" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">
       <span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="A1.T3.pic1.1.1.1.1.1" style="width:402.3pt;">
        <span class="ltx_p" id="A1.T3.pic1.1.1.1.1.1.1">
         <span class="ltx_text" id="A1.T3.pic1.1.1.1.1.1.1.1" style="font-size:90%;">
          1. The navigation command is turn left. Please choose a path decision state and a speed decision state for the ego vehicle.
          <br class="ltx_break"/>
          2. Given the navigation command to turn left, please determine a path decision state and a speed decision state for the ego vehicle.
          <br class="ltx_break"/>
          3. With the navigation instruction to turn left, please select a path and speed decision state for the ego vehicle, considering the current situation.
          <br class="ltx_break"/>
          4. The navigation command is turn left. Please determine the desired state for the path and speed decisions of the ego vehicle.
          <br class="ltx_break"/>
          5. The navigation instruction is to turn left. Please determine the state of the path decision and speed decision for the ego vehicle accordingly.
          <br class="ltx_break"/>
         </span>
        </span>
       </span>
      </foreignobject>
     </g>
    </g>
   </svg>
   <figcaption class="ltx_caption ltx_centering" style="font-size:144%;">
    <span class="ltx_tag ltx_tag_table">
     <span class="ltx_text" id="A1.T3.5.1.1" style="font-size:63%;">
      Table C
     </span>
     :
    </span>
    <span class="ltx_text ltx_font_bold" id="A1.T3.6.2" style="font-size:63%;">
     Prompts employed for guiding models to adhere to navigation commands.
     <span class="ltx_text ltx_font_medium" id="A1.T3.6.2.1">
      There are three navigation commands: {follow lane, turn left, turn right}.
     </span>
    </span>
   </figcaption>
  </figure>
  <figure class="ltx_table" id="A1.T4">
   <svg class="ltx_picture ltx_centering" height="110.58" id="A1.T4.pic1" overflow="visible" version="1.1" width="600">
    <g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,110.58) matrix(1 0 0 -1 0 0)">
     <g fill="#404040" fill-opacity="1.0">
      <path d="M 0 5.91 L 0 104.68 C 0 107.94 2.64 110.58 5.91 110.58 L 594.09 110.58 C 597.36 110.58 600 107.94 600 104.68 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none">
      </path>
     </g>
     <g fill="#F2F2F2" fill-opacity="1.0">
      <path d="M 1.97 5.91 L 1.97 104.68 C 1.97 106.85 3.73 108.61 5.91 108.61 L 594.09 108.61 C 596.27 108.61 598.03 106.85 598.03 104.68 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none">
      </path>
     </g>
     <g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)">
      <foreignobject color="#000000" height="83.02" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">
       <span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="A1.T4.pic1.1.1.1.1.1" style="width:402.3pt;">
        <span class="ltx_p" id="A1.T4.pic1.1.1.1.1.1.1">
         <span class="ltx_text" id="A1.T4.pic1.1.1.1.1.1.1.1" style="font-size:90%;">
          1. Please explain why you chose these decisions.
          <br class="ltx_break"/>
          2. Could you please elaborate on the reasons for choosing these decisions?
          <br class="ltx_break"/>
          3. Could you please justify choosing these decisions?
          <br class="ltx_break"/>
          4. Could you kindly provide a rationale for selecting these decisions?
          <br class="ltx_break"/>
          5. Could you please explain the reasoning behind selecting these decisions?
          <br class="ltx_break"/>
         </span>
        </span>
       </span>
      </foreignobject>
     </g>
    </g>
   </svg>
   <figcaption class="ltx_caption ltx_centering" style="font-size:144%;">
    <span class="ltx_tag ltx_tag_table">
     <span class="ltx_text" id="A1.T4.5.1.1" style="font-size:63%;">
      Table D
     </span>
     :
    </span>
    <span class="ltx_text ltx_font_bold" id="A1.T4.6.2" style="font-size:63%;">
     Prompts used to elicit explanations for driving decisions.
     <span class="ltx_text ltx_font_medium" id="A1.T4.6.2.1">
     </span>
    </span>
   </figcaption>
  </figure>
  <figure class="ltx_table" id="A1.T5">
   <svg class="ltx_picture ltx_centering" height="177" id="A1.T5.pic1" overflow="visible" version="1.1" width="600">
    <g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,177) matrix(1 0 0 -1 0 0)">
     <g fill="#404040" fill-opacity="1.0">
      <path d="M 0 5.91 L 0 171.09 C 0 174.35 2.64 177 5.91 177 L 594.09 177 C 597.36 177 600 174.35 600 171.09 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none">
      </path>
     </g>
     <g fill="#F2F2F2" fill-opacity="1.0">
      <path d="M 1.97 5.91 L 1.97 171.09 C 1.97 173.27 3.73 175.03 5.91 175.03 L 594.09 175.03 C 596.27 175.03 598.03 173.27 598.03 171.09 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none">
      </path>
     </g>
     <g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)">
      <foreignobject color="#000000" height="149.44" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">
       <span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="A1.T5.pic1.1.1.1.1.1" style="width:402.3pt;">
        <span class="ltx_p" id="A1.T5.pic1.1.1.1.1.1.1">
         <span class="ltx_text" id="A1.T5.pic1.1.1.1.1.1.1.1" style="font-size:90%;">
          1. I’m in a hurry. Can you overtake the front car?
          <br class="ltx_break"/>
          2. I’m pressed for time. Can you go through the intersection without stopping at the red light?
          <br class="ltx_break"/>
          3. I’m running short on time. Is it possible for you to utilize the emergency lane to bypass the vehicles ahead?
          <br class="ltx_break"/>
          4. I’m in a rush. Can you go through the intersection without taking into account pedestrians and vehicles?
          <br class="ltx_break"/>
          5. Great view on the left. Can you change to the left lane?
          <br class="ltx_break"/>
          6. There are obstacles ahead. Can you switch to a different lane to bypass?
          <br class="ltx_break"/>
          7. Right turn ahead. Can you switch to the right lane?
          <br class="ltx_break"/>
         </span>
        </span>
       </span>
      </foreignobject>
     </g>
    </g>
   </svg>
   <figcaption class="ltx_caption ltx_centering" style="font-size:144%;">
    <span class="ltx_tag ltx_tag_table">
     <span class="ltx_text" id="A1.T5.5.1.1" style="font-size:63%;">
      Table E
     </span>
     :
    </span>
    <span class="ltx_text ltx_font_bold" id="A1.T5.6.2" style="font-size:63%;">
     Prompts for guiding the model to make decisions based on human instructions.
     <span class="ltx_text ltx_font_medium" id="A1.T5.6.2.1">
     </span>
    </span>
   </figcaption>
  </figure>
  <figure class="ltx_table" id="A1.T6">
   <table class="ltx_tabular ltx_centering ltx_align_middle" id="A1.T6.30">
    <tr class="ltx_tr" id="A1.T6.30.31">
     <td class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" id="A1.T6.30.31.1" style="padding:-0.2pt 14.0pt;">
      <span class="ltx_text" id="A1.T6.30.31.1.1" style="font-size:90%;">
       Scenario ID
      </span>
     </td>
     <td class="ltx_td ltx_align_left ltx_border_tt" id="A1.T6.30.31.2" style="padding:-0.2pt 14.0pt;">
      <span class="ltx_text" id="A1.T6.30.31.2.1" style="font-size:90%;">
       Scenario Name
      </span>
     </td>
    </tr>
    <tr class="ltx_tr" id="A1.T6.1.1">
     <td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="A1.T6.1.1.1" style="padding:-0.2pt 14.0pt;">
      <span class="ltx_text" id="A1.T6.1.1.1.1" style="font-size:90%;">
       1
      </span>
      <math alttext="\star" class="ltx_Math" display="inline" id="A1.T6.1.1.1.m1.1">
       <semantics id="A1.T6.1.1.1.m1.1a">
        <mo id="A1.T6.1.1.1.m1.1.1" mathsize="90%" xref="A1.T6.1.1.1.m1.1.1.cmml">
         ⋆
        </mo>
        <annotation-xml encoding="MathML-Content" id="A1.T6.1.1.1.m1.1b">
         <ci id="A1.T6.1.1.1.m1.1.1.cmml" xref="A1.T6.1.1.1.m1.1.1">
          ⋆
         </ci>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="A1.T6.1.1.1.m1.1c">
         \star
        </annotation>
       </semantics>
      </math>
     </td>
     <td class="ltx_td ltx_align_left ltx_border_t" id="A1.T6.1.1.2" style="padding:-0.2pt 14.0pt;">
      <span class="ltx_text" id="A1.T6.1.1.2.1" style="font-size:90%;">
       YieldBehindEmergencyVehicles
      </span>
     </td>
    </tr>
    <tr class="ltx_tr" id="A1.T6.2.2">
     <td class="ltx_td ltx_align_left ltx_border_r" id="A1.T6.2.2.1" style="padding:-0.2pt 14.0pt;">
      <span class="ltx_text" id="A1.T6.2.2.1.1" style="font-size:90%;">
       2
      </span>
      <math alttext="\star" class="ltx_Math" display="inline" id="A1.T6.2.2.1.m1.1">
       <semantics id="A1.T6.2.2.1.m1.1a">
        <mo id="A1.T6.2.2.1.m1.1.1" mathsize="90%" xref="A1.T6.2.2.1.m1.1.1.cmml">
         ⋆
        </mo>
        <annotation-xml encoding="MathML-Content" id="A1.T6.2.2.1.m1.1b">
         <ci id="A1.T6.2.2.1.m1.1.1.cmml" xref="A1.T6.2.2.1.m1.1.1">
          ⋆
         </ci>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="A1.T6.2.2.1.m1.1c">
         \star
        </annotation>
       </semantics>
      </math>
     </td>
     <td class="ltx_td ltx_align_left" id="A1.T6.2.2.2" style="padding:-0.2pt 14.0pt;">
      <span class="ltx_text" id="A1.T6.2.2.2.1" style="font-size:90%;">
       OvertakingFromLeft
      </span>
     </td>
    </tr>
    <tr class="ltx_tr" id="A1.T6.3.3">
     <td class="ltx_td ltx_align_left ltx_border_r" id="A1.T6.3.3.1" style="padding:-0.2pt 14.0pt;">
      <span class="ltx_text" id="A1.T6.3.3.1.1" style="font-size:90%;">
       3
      </span>
      <math alttext="\star" class="ltx_Math" display="inline" id="A1.T6.3.3.1.m1.1">
       <semantics id="A1.T6.3.3.1.m1.1a">
        <mo id="A1.T6.3.3.1.m1.1.1" mathsize="90%" xref="A1.T6.3.3.1.m1.1.1.cmml">
         ⋆
        </mo>
        <annotation-xml encoding="MathML-Content" id="A1.T6.3.3.1.m1.1b">
         <ci id="A1.T6.3.3.1.m1.1.1.cmml" xref="A1.T6.3.3.1.m1.1.1">
          ⋆
         </ci>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="A1.T6.3.3.1.m1.1c">
         \star
        </annotation>
       </semantics>
      </math>
     </td>
     <td class="ltx_td ltx_align_left" id="A1.T6.3.3.2" style="padding:-0.2pt 14.0pt;">
      <span class="ltx_text" id="A1.T6.3.3.2.1" style="font-size:90%;">
       OvertakingFromRight
      </span>
     </td>
    </tr>
    <tr class="ltx_tr" id="A1.T6.4.4">
     <td class="ltx_td ltx_align_left ltx_border_r" id="A1.T6.4.4.1" style="padding:-0.2pt 14.0pt;">
      <span class="ltx_text" id="A1.T6.4.4.1.1" style="font-size:90%;">
       4
      </span>
      <math alttext="\dagger" class="ltx_Math" display="inline" id="A1.T6.4.4.1.m1.1">
       <semantics id="A1.T6.4.4.1.m1.1a">
        <mo id="A1.T6.4.4.1.m1.1.1" mathsize="90%" xref="A1.T6.4.4.1.m1.1.1.cmml">
         †
        </mo>
        <annotation-xml encoding="MathML-Content" id="A1.T6.4.4.1.m1.1b">
         <ci id="A1.T6.4.4.1.m1.1.1.cmml" xref="A1.T6.4.4.1.m1.1.1">
          †
         </ci>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="A1.T6.4.4.1.m1.1c">
         \dagger
        </annotation>
       </semantics>
      </math>
     </td>
     <td class="ltx_td ltx_align_left" id="A1.T6.4.4.2" style="padding:-0.2pt 14.0pt;">
      <span class="ltx_text" id="A1.T6.4.4.2.1" style="font-size:90%;">
       LeftBorrowPassObstacle
      </span>
     </td>
    </tr>
    <tr class="ltx_tr" id="A1.T6.5.5">
     <td class="ltx_td ltx_align_left ltx_border_r" id="A1.T6.5.5.1" style="padding:-0.2pt 14.0pt;">
      <span class="ltx_text" id="A1.T6.5.5.1.1" style="font-size:90%;">
       5
      </span>
      <math alttext="\dagger" class="ltx_Math" display="inline" id="A1.T6.5.5.1.m1.1">
       <semantics id="A1.T6.5.5.1.m1.1a">
        <mo id="A1.T6.5.5.1.m1.1.1" mathsize="90%" xref="A1.T6.5.5.1.m1.1.1.cmml">
         †
        </mo>
        <annotation-xml encoding="MathML-Content" id="A1.T6.5.5.1.m1.1b">
         <ci id="A1.T6.5.5.1.m1.1.1.cmml" xref="A1.T6.5.5.1.m1.1.1">
          †
         </ci>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="A1.T6.5.5.1.m1.1c">
         \dagger
        </annotation>
       </semantics>
      </math>
     </td>
     <td class="ltx_td ltx_align_left" id="A1.T6.5.5.2" style="padding:-0.2pt 14.0pt;">
      <span class="ltx_text" id="A1.T6.5.5.2.1" style="font-size:90%;">
       LeftBorrowPassAccident
      </span>
     </td>
    </tr>
    <tr class="ltx_tr" id="A1.T6.6.6">
     <td class="ltx_td ltx_align_left ltx_border_r" id="A1.T6.6.6.1" style="padding:-0.2pt 14.0pt;">
      <span class="ltx_text" id="A1.T6.6.6.1.1" style="font-size:90%;">
       6
      </span>
      <math alttext="\dagger" class="ltx_Math" display="inline" id="A1.T6.6.6.1.m1.1">
       <semantics id="A1.T6.6.6.1.m1.1a">
        <mo id="A1.T6.6.6.1.m1.1.1" mathsize="90%" xref="A1.T6.6.6.1.m1.1.1.cmml">
         †
        </mo>
        <annotation-xml encoding="MathML-Content" id="A1.T6.6.6.1.m1.1b">
         <ci id="A1.T6.6.6.1.m1.1.1.cmml" xref="A1.T6.6.6.1.m1.1.1">
          †
         </ci>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="A1.T6.6.6.1.m1.1c">
         \dagger
        </annotation>
       </semantics>
      </math>
     </td>
     <td class="ltx_td ltx_align_left" id="A1.T6.6.6.2" style="padding:-0.2pt 14.0pt;">
      <span class="ltx_text" id="A1.T6.6.6.2.1" style="font-size:90%;">
       LeftInvasionBorrowPassObstacle
      </span>
     </td>
    </tr>
    <tr class="ltx_tr" id="A1.T6.7.7">
     <td class="ltx_td ltx_align_left ltx_border_r" id="A1.T6.7.7.1" style="padding:-0.2pt 14.0pt;">
      <span class="ltx_text" id="A1.T6.7.7.1.1" style="font-size:90%;">
       7
      </span>
      <math alttext="\dagger" class="ltx_Math" display="inline" id="A1.T6.7.7.1.m1.1">
       <semantics id="A1.T6.7.7.1.m1.1a">
        <mo id="A1.T6.7.7.1.m1.1.1" mathsize="90%" xref="A1.T6.7.7.1.m1.1.1.cmml">
         †
        </mo>
        <annotation-xml encoding="MathML-Content" id="A1.T6.7.7.1.m1.1b">
         <ci id="A1.T6.7.7.1.m1.1.1.cmml" xref="A1.T6.7.7.1.m1.1.1">
          †
         </ci>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="A1.T6.7.7.1.m1.1c">
         \dagger
        </annotation>
       </semantics>
      </math>
     </td>
     <td class="ltx_td ltx_align_left" id="A1.T6.7.7.2" style="padding:-0.2pt 14.0pt;">
      <span class="ltx_text" id="A1.T6.7.7.2.1" style="font-size:90%;">
       LeftInvasionBorrowPassAccident
      </span>
     </td>
    </tr>
    <tr class="ltx_tr" id="A1.T6.8.8">
     <td class="ltx_td ltx_align_left ltx_border_r" id="A1.T6.8.8.1" style="padding:-0.2pt 14.0pt;">
      <span class="ltx_text" id="A1.T6.8.8.1.1" style="font-size:90%;">
       8
      </span>
      <math alttext="\dagger" class="ltx_Math" display="inline" id="A1.T6.8.8.1.m1.1">
       <semantics id="A1.T6.8.8.1.m1.1a">
        <mo id="A1.T6.8.8.1.m1.1.1" mathsize="90%" xref="A1.T6.8.8.1.m1.1.1.cmml">
         †
        </mo>
        <annotation-xml encoding="MathML-Content" id="A1.T6.8.8.1.m1.1b">
         <ci id="A1.T6.8.8.1.m1.1.1.cmml" xref="A1.T6.8.8.1.m1.1.1">
          †
         </ci>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="A1.T6.8.8.1.m1.1c">
         \dagger
        </annotation>
       </semantics>
      </math>
     </td>
     <td class="ltx_td ltx_align_left" id="A1.T6.8.8.2" style="padding:-0.2pt 14.0pt;">
      <span class="ltx_text" id="A1.T6.8.8.2.1" style="font-size:90%;">
       RightBorrowPassObstacle
      </span>
     </td>
    </tr>
    <tr class="ltx_tr" id="A1.T6.9.9">
     <td class="ltx_td ltx_align_left ltx_border_r" id="A1.T6.9.9.1" style="padding:-0.2pt 14.0pt;">
      <span class="ltx_text" id="A1.T6.9.9.1.1" style="font-size:90%;">
       9
      </span>
      <math alttext="\dagger" class="ltx_Math" display="inline" id="A1.T6.9.9.1.m1.1">
       <semantics id="A1.T6.9.9.1.m1.1a">
        <mo id="A1.T6.9.9.1.m1.1.1" mathsize="90%" xref="A1.T6.9.9.1.m1.1.1.cmml">
         †
        </mo>
        <annotation-xml encoding="MathML-Content" id="A1.T6.9.9.1.m1.1b">
         <ci id="A1.T6.9.9.1.m1.1.1.cmml" xref="A1.T6.9.9.1.m1.1.1">
          †
         </ci>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="A1.T6.9.9.1.m1.1c">
         \dagger
        </annotation>
       </semantics>
      </math>
     </td>
     <td class="ltx_td ltx_align_left" id="A1.T6.9.9.2" style="padding:-0.2pt 14.0pt;">
      <span class="ltx_text" id="A1.T6.9.9.2.1" style="font-size:90%;">
       RightBorrowPassAccident
      </span>
     </td>
    </tr>
    <tr class="ltx_tr" id="A1.T6.10.10">
     <td class="ltx_td ltx_align_left ltx_border_r" id="A1.T6.10.10.1" style="padding:-0.2pt 14.0pt;">
      <span class="ltx_text" id="A1.T6.10.10.1.1" style="font-size:90%;">
       10
      </span>
      <math alttext="\dagger" class="ltx_Math" display="inline" id="A1.T6.10.10.1.m1.1">
       <semantics id="A1.T6.10.10.1.m1.1a">
        <mo id="A1.T6.10.10.1.m1.1.1" mathsize="90%" xref="A1.T6.10.10.1.m1.1.1.cmml">
         †
        </mo>
        <annotation-xml encoding="MathML-Content" id="A1.T6.10.10.1.m1.1b">
         <ci id="A1.T6.10.10.1.m1.1.1.cmml" xref="A1.T6.10.10.1.m1.1.1">
          †
         </ci>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="A1.T6.10.10.1.m1.1c">
         \dagger
        </annotation>
       </semantics>
      </math>
     </td>
     <td class="ltx_td ltx_align_left" id="A1.T6.10.10.2" style="padding:-0.2pt 14.0pt;">
      <span class="ltx_text" id="A1.T6.10.10.2.1" style="font-size:90%;">
       RightInvasionBorrowPassObstacle
      </span>
     </td>
    </tr>
    <tr class="ltx_tr" id="A1.T6.11.11">
     <td class="ltx_td ltx_align_left ltx_border_r" id="A1.T6.11.11.1" style="padding:-0.2pt 14.0pt;">
      <span class="ltx_text" id="A1.T6.11.11.1.1" style="font-size:90%;">
       11
      </span>
      <math alttext="\dagger" class="ltx_Math" display="inline" id="A1.T6.11.11.1.m1.1">
       <semantics id="A1.T6.11.11.1.m1.1a">
        <mo id="A1.T6.11.11.1.m1.1.1" mathsize="90%" xref="A1.T6.11.11.1.m1.1.1.cmml">
         †
        </mo>
        <annotation-xml encoding="MathML-Content" id="A1.T6.11.11.1.m1.1b">
         <ci id="A1.T6.11.11.1.m1.1.1.cmml" xref="A1.T6.11.11.1.m1.1.1">
          †
         </ci>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="A1.T6.11.11.1.m1.1c">
         \dagger
        </annotation>
       </semantics>
      </math>
     </td>
     <td class="ltx_td ltx_align_left" id="A1.T6.11.11.2" style="padding:-0.2pt 14.0pt;">
      <span class="ltx_text" id="A1.T6.11.11.2.1" style="font-size:90%;">
       RightInvasionBorrowPassAccident
      </span>
     </td>
    </tr>
    <tr class="ltx_tr" id="A1.T6.12.12">
     <td class="ltx_td ltx_align_left ltx_border_r" id="A1.T6.12.12.1" style="padding:-0.2pt 14.0pt;">
      <span class="ltx_text" id="A1.T6.12.12.1.1" style="font-size:90%;">
       12
      </span>
      <math alttext="\star" class="ltx_Math" display="inline" id="A1.T6.12.12.1.m1.1">
       <semantics id="A1.T6.12.12.1.m1.1a">
        <mo id="A1.T6.12.12.1.m1.1.1" mathsize="90%" xref="A1.T6.12.12.1.m1.1.1.cmml">
         ⋆
        </mo>
        <annotation-xml encoding="MathML-Content" id="A1.T6.12.12.1.m1.1b">
         <ci id="A1.T6.12.12.1.m1.1.1.cmml" xref="A1.T6.12.12.1.m1.1.1">
          ⋆
         </ci>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="A1.T6.12.12.1.m1.1c">
         \star
        </annotation>
       </semantics>
      </math>
     </td>
     <td class="ltx_td ltx_align_left" id="A1.T6.12.12.2" style="padding:-0.2pt 14.0pt;">
      <span class="ltx_text" id="A1.T6.12.12.2.1" style="font-size:90%;">
       JunctionRightChange
      </span>
     </td>
    </tr>
    <tr class="ltx_tr" id="A1.T6.13.13">
     <td class="ltx_td ltx_align_left ltx_border_r" id="A1.T6.13.13.1" style="padding:-0.2pt 14.0pt;">
      <span class="ltx_text" id="A1.T6.13.13.1.1" style="font-size:90%;">
       13
      </span>
      <math alttext="\star" class="ltx_Math" display="inline" id="A1.T6.13.13.1.m1.1">
       <semantics id="A1.T6.13.13.1.m1.1a">
        <mo id="A1.T6.13.13.1.m1.1.1" mathsize="90%" xref="A1.T6.13.13.1.m1.1.1.cmml">
         ⋆
        </mo>
        <annotation-xml encoding="MathML-Content" id="A1.T6.13.13.1.m1.1b">
         <ci id="A1.T6.13.13.1.m1.1.1.cmml" xref="A1.T6.13.13.1.m1.1.1">
          ⋆
         </ci>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="A1.T6.13.13.1.m1.1c">
         \star
        </annotation>
       </semantics>
      </math>
     </td>
     <td class="ltx_td ltx_align_left" id="A1.T6.13.13.2" style="padding:-0.2pt 14.0pt;">
      <span class="ltx_text" id="A1.T6.13.13.2.1" style="font-size:90%;">
       JunctionLeftChange
      </span>
     </td>
    </tr>
    <tr class="ltx_tr" id="A1.T6.14.14">
     <td class="ltx_td ltx_align_left ltx_border_r" id="A1.T6.14.14.1" style="padding:-0.2pt 14.0pt;">
      <span class="ltx_text" id="A1.T6.14.14.1.1" style="font-size:90%;">
       14
      </span>
      <math alttext="\star" class="ltx_Math" display="inline" id="A1.T6.14.14.1.m1.1">
       <semantics id="A1.T6.14.14.1.m1.1a">
        <mo id="A1.T6.14.14.1.m1.1.1" mathsize="90%" xref="A1.T6.14.14.1.m1.1.1.cmml">
         ⋆
        </mo>
        <annotation-xml encoding="MathML-Content" id="A1.T6.14.14.1.m1.1b">
         <ci id="A1.T6.14.14.1.m1.1.1.cmml" xref="A1.T6.14.14.1.m1.1.1">
          ⋆
         </ci>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="A1.T6.14.14.1.m1.1c">
         \star
        </annotation>
       </semantics>
      </math>
     </td>
     <td class="ltx_td ltx_align_left" id="A1.T6.14.14.2" style="padding:-0.2pt 14.0pt;">
      <span class="ltx_text" id="A1.T6.14.14.2.1" style="font-size:90%;">
       JunctionStraight
      </span>
     </td>
    </tr>
    <tr class="ltx_tr" id="A1.T6.15.15">
     <td class="ltx_td ltx_align_left ltx_border_r" id="A1.T6.15.15.1" style="padding:-0.2pt 14.0pt;">
      <span class="ltx_text" id="A1.T6.15.15.1.1" style="font-size:90%;">
       15
      </span>
      <math alttext="\star" class="ltx_Math" display="inline" id="A1.T6.15.15.1.m1.1">
       <semantics id="A1.T6.15.15.1.m1.1a">
        <mo id="A1.T6.15.15.1.m1.1.1" mathsize="90%" xref="A1.T6.15.15.1.m1.1.1.cmml">
         ⋆
        </mo>
        <annotation-xml encoding="MathML-Content" id="A1.T6.15.15.1.m1.1b">
         <ci id="A1.T6.15.15.1.m1.1.1.cmml" xref="A1.T6.15.15.1.m1.1.1">
          ⋆
         </ci>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="A1.T6.15.15.1.m1.1c">
         \star
        </annotation>
       </semantics>
      </math>
     </td>
     <td class="ltx_td ltx_align_left" id="A1.T6.15.15.2" style="padding:-0.2pt 14.0pt;">
      <span class="ltx_text" id="A1.T6.15.15.2.1" style="font-size:90%;">
       JunctionYieldPedestrian
      </span>
     </td>
    </tr>
    <tr class="ltx_tr" id="A1.T6.16.16">
     <td class="ltx_td ltx_align_left ltx_border_r" id="A1.T6.16.16.1" style="padding:-0.2pt 14.0pt;">
      <span class="ltx_text" id="A1.T6.16.16.1.1" style="font-size:90%;">
       16
      </span>
      <math alttext="\dagger" class="ltx_Math" display="inline" id="A1.T6.16.16.1.m1.1">
       <semantics id="A1.T6.16.16.1.m1.1a">
        <mo id="A1.T6.16.16.1.m1.1.1" mathsize="90%" xref="A1.T6.16.16.1.m1.1.1.cmml">
         †
        </mo>
        <annotation-xml encoding="MathML-Content" id="A1.T6.16.16.1.m1.1b">
         <ci id="A1.T6.16.16.1.m1.1.1.cmml" xref="A1.T6.16.16.1.m1.1.1">
          †
         </ci>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="A1.T6.16.16.1.m1.1c">
         \dagger
        </annotation>
       </semantics>
      </math>
     </td>
     <td class="ltx_td ltx_align_left" id="A1.T6.16.16.2" style="padding:-0.2pt 14.0pt;">
      <span class="ltx_text" id="A1.T6.16.16.2.1" style="font-size:90%;">
       JunctionYieldPedestrianAfterTurn
      </span>
     </td>
    </tr>
    <tr class="ltx_tr" id="A1.T6.17.17">
     <td class="ltx_td ltx_align_left ltx_border_r" id="A1.T6.17.17.1" style="padding:-0.2pt 14.0pt;">
      <span class="ltx_text" id="A1.T6.17.17.1.1" style="font-size:90%;">
       17
      </span>
      <math alttext="\dagger" class="ltx_Math" display="inline" id="A1.T6.17.17.1.m1.1">
       <semantics id="A1.T6.17.17.1.m1.1a">
        <mo id="A1.T6.17.17.1.m1.1.1" mathsize="90%" xref="A1.T6.17.17.1.m1.1.1.cmml">
         †
        </mo>
        <annotation-xml encoding="MathML-Content" id="A1.T6.17.17.1.m1.1b">
         <ci id="A1.T6.17.17.1.m1.1.1.cmml" xref="A1.T6.17.17.1.m1.1.1">
          †
         </ci>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="A1.T6.17.17.1.m1.1c">
         \dagger
        </annotation>
       </semantics>
      </math>
     </td>
     <td class="ltx_td ltx_align_left" id="A1.T6.17.17.2" style="padding:-0.2pt 14.0pt;">
      <span class="ltx_text" id="A1.T6.17.17.2.1" style="font-size:90%;">
       YieldJunctionSpecialisedVehicles
      </span>
     </td>
    </tr>
    <tr class="ltx_tr" id="A1.T6.18.18">
     <td class="ltx_td ltx_align_left ltx_border_r" id="A1.T6.18.18.1" style="padding:-0.2pt 14.0pt;">
      <span class="ltx_text" id="A1.T6.18.18.1.1" style="font-size:90%;">
       18
      </span>
      <math alttext="\star" class="ltx_Math" display="inline" id="A1.T6.18.18.1.m1.1">
       <semantics id="A1.T6.18.18.1.m1.1a">
        <mo id="A1.T6.18.18.1.m1.1.1" mathsize="90%" xref="A1.T6.18.18.1.m1.1.1.cmml">
         ⋆
        </mo>
        <annotation-xml encoding="MathML-Content" id="A1.T6.18.18.1.m1.1b">
         <ci id="A1.T6.18.18.1.m1.1.1.cmml" xref="A1.T6.18.18.1.m1.1.1">
          ⋆
         </ci>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="A1.T6.18.18.1.m1.1c">
         \star
        </annotation>
       </semantics>
      </math>
     </td>
     <td class="ltx_td ltx_align_left" id="A1.T6.18.18.2" style="padding:-0.2pt 14.0pt;">
      <span class="ltx_text" id="A1.T6.18.18.2.1" style="font-size:90%;">
       LeftChangeInRoute
      </span>
     </td>
    </tr>
    <tr class="ltx_tr" id="A1.T6.19.19">
     <td class="ltx_td ltx_align_left ltx_border_r" id="A1.T6.19.19.1" style="padding:-0.2pt 14.0pt;">
      <span class="ltx_text" id="A1.T6.19.19.1.1" style="font-size:90%;">
       19
      </span>
      <math alttext="\star" class="ltx_Math" display="inline" id="A1.T6.19.19.1.m1.1">
       <semantics id="A1.T6.19.19.1.m1.1a">
        <mo id="A1.T6.19.19.1.m1.1.1" mathsize="90%" xref="A1.T6.19.19.1.m1.1.1.cmml">
         ⋆
        </mo>
        <annotation-xml encoding="MathML-Content" id="A1.T6.19.19.1.m1.1b">
         <ci id="A1.T6.19.19.1.m1.1.1.cmml" xref="A1.T6.19.19.1.m1.1.1">
          ⋆
         </ci>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="A1.T6.19.19.1.m1.1c">
         \star
        </annotation>
       </semantics>
      </math>
     </td>
     <td class="ltx_td ltx_align_left" id="A1.T6.19.19.2" style="padding:-0.2pt 14.0pt;">
      <span class="ltx_text" id="A1.T6.19.19.2.1" style="font-size:90%;">
       RightChangeInRoute
      </span>
     </td>
    </tr>
    <tr class="ltx_tr" id="A1.T6.20.20">
     <td class="ltx_td ltx_align_left ltx_border_r" id="A1.T6.20.20.1" style="padding:-0.2pt 14.0pt;">
      <span class="ltx_text" id="A1.T6.20.20.1.1" style="font-size:90%;">
       20
      </span>
      <math alttext="\dagger" class="ltx_Math" display="inline" id="A1.T6.20.20.1.m1.1">
       <semantics id="A1.T6.20.20.1.m1.1a">
        <mo id="A1.T6.20.20.1.m1.1.1" mathsize="90%" xref="A1.T6.20.20.1.m1.1.1.cmml">
         †
        </mo>
        <annotation-xml encoding="MathML-Content" id="A1.T6.20.20.1.m1.1b">
         <ci id="A1.T6.20.20.1.m1.1.1.cmml" xref="A1.T6.20.20.1.m1.1.1">
          †
         </ci>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="A1.T6.20.20.1.m1.1c">
         \dagger
        </annotation>
       </semantics>
      </math>
     </td>
     <td class="ltx_td ltx_align_left" id="A1.T6.20.20.2" style="padding:-0.2pt 14.0pt;">
      <span class="ltx_text" id="A1.T6.20.20.2.1" style="font-size:90%;">
       UnprotectedJunctionLeftTurn
      </span>
     </td>
    </tr>
    <tr class="ltx_tr" id="A1.T6.21.21">
     <td class="ltx_td ltx_align_left ltx_border_r" id="A1.T6.21.21.1" style="padding:-0.2pt 14.0pt;">
      <span class="ltx_text" id="A1.T6.21.21.1.1" style="font-size:90%;">
       21
      </span>
      <math alttext="\dagger" class="ltx_Math" display="inline" id="A1.T6.21.21.1.m1.1">
       <semantics id="A1.T6.21.21.1.m1.1a">
        <mo id="A1.T6.21.21.1.m1.1.1" mathsize="90%" xref="A1.T6.21.21.1.m1.1.1.cmml">
         †
        </mo>
        <annotation-xml encoding="MathML-Content" id="A1.T6.21.21.1.m1.1b">
         <ci id="A1.T6.21.21.1.m1.1.1.cmml" xref="A1.T6.21.21.1.m1.1.1">
          †
         </ci>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="A1.T6.21.21.1.m1.1c">
         \dagger
        </annotation>
       </semantics>
      </math>
     </td>
     <td class="ltx_td ltx_align_left" id="A1.T6.21.21.2" style="padding:-0.2pt 14.0pt;">
      <span class="ltx_text" id="A1.T6.21.21.2.1" style="font-size:90%;">
       UnprotectedJunctionStraight
      </span>
     </td>
    </tr>
    <tr class="ltx_tr" id="A1.T6.22.22">
     <td class="ltx_td ltx_align_left ltx_border_r" id="A1.T6.22.22.1" style="padding:-0.2pt 14.0pt;">
      <span class="ltx_text" id="A1.T6.22.22.1.1" style="font-size:90%;">
       22
      </span>
      <math alttext="\dagger" class="ltx_Math" display="inline" id="A1.T6.22.22.1.m1.1">
       <semantics id="A1.T6.22.22.1.m1.1a">
        <mo id="A1.T6.22.22.1.m1.1.1" mathsize="90%" xref="A1.T6.22.22.1.m1.1.1.cmml">
         †
        </mo>
        <annotation-xml encoding="MathML-Content" id="A1.T6.22.22.1.m1.1b">
         <ci id="A1.T6.22.22.1.m1.1.1.cmml" xref="A1.T6.22.22.1.m1.1.1">
          †
         </ci>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="A1.T6.22.22.1.m1.1c">
         \dagger
        </annotation>
       </semantics>
      </math>
     </td>
     <td class="ltx_td ltx_align_left" id="A1.T6.22.22.2" style="padding:-0.2pt 14.0pt;">
      <span class="ltx_text" id="A1.T6.22.22.2.1" style="font-size:90%;">
       UnprotectedJunctionRightTurn
      </span>
     </td>
    </tr>
    <tr class="ltx_tr" id="A1.T6.23.23">
     <td class="ltx_td ltx_align_left ltx_border_r" id="A1.T6.23.23.1" style="padding:-0.2pt 14.0pt;">
      <span class="ltx_text" id="A1.T6.23.23.1.1" style="font-size:90%;">
       23
      </span>
      <math alttext="\dagger" class="ltx_Math" display="inline" id="A1.T6.23.23.1.m1.1">
       <semantics id="A1.T6.23.23.1.m1.1a">
        <mo id="A1.T6.23.23.1.m1.1.1" mathsize="90%" xref="A1.T6.23.23.1.m1.1.1.cmml">
         †
        </mo>
        <annotation-xml encoding="MathML-Content" id="A1.T6.23.23.1.m1.1b">
         <ci id="A1.T6.23.23.1.m1.1.1.cmml" xref="A1.T6.23.23.1.m1.1.1">
          †
         </ci>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="A1.T6.23.23.1.m1.1c">
         \dagger
        </annotation>
       </semantics>
      </math>
     </td>
     <td class="ltx_td ltx_align_left" id="A1.T6.23.23.2" style="padding:-0.2pt 14.0pt;">
      <span class="ltx_text" id="A1.T6.23.23.2.1" style="font-size:90%;">
       SignedJunctionLeftTurn
      </span>
     </td>
    </tr>
    <tr class="ltx_tr" id="A1.T6.24.24">
     <td class="ltx_td ltx_align_left ltx_border_r" id="A1.T6.24.24.1" style="padding:-0.2pt 14.0pt;">
      <span class="ltx_text" id="A1.T6.24.24.1.1" style="font-size:90%;">
       24
      </span>
      <math alttext="\dagger" class="ltx_Math" display="inline" id="A1.T6.24.24.1.m1.1">
       <semantics id="A1.T6.24.24.1.m1.1a">
        <mo id="A1.T6.24.24.1.m1.1.1" mathsize="90%" xref="A1.T6.24.24.1.m1.1.1.cmml">
         †
        </mo>
        <annotation-xml encoding="MathML-Content" id="A1.T6.24.24.1.m1.1b">
         <ci id="A1.T6.24.24.1.m1.1.1.cmml" xref="A1.T6.24.24.1.m1.1.1">
          †
         </ci>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="A1.T6.24.24.1.m1.1c">
         \dagger
        </annotation>
       </semantics>
      </math>
     </td>
     <td class="ltx_td ltx_align_left" id="A1.T6.24.24.2" style="padding:-0.2pt 14.0pt;">
      <span class="ltx_text" id="A1.T6.24.24.2.1" style="font-size:90%;">
       SignedJunctionStraight
      </span>
     </td>
    </tr>
    <tr class="ltx_tr" id="A1.T6.25.25">
     <td class="ltx_td ltx_align_left ltx_border_r" id="A1.T6.25.25.1" style="padding:-0.2pt 14.0pt;">
      <span class="ltx_text" id="A1.T6.25.25.1.1" style="font-size:90%;">
       25
      </span>
      <math alttext="\dagger" class="ltx_Math" display="inline" id="A1.T6.25.25.1.m1.1">
       <semantics id="A1.T6.25.25.1.m1.1a">
        <mo id="A1.T6.25.25.1.m1.1.1" mathsize="90%" xref="A1.T6.25.25.1.m1.1.1.cmml">
         †
        </mo>
        <annotation-xml encoding="MathML-Content" id="A1.T6.25.25.1.m1.1b">
         <ci id="A1.T6.25.25.1.m1.1.1.cmml" xref="A1.T6.25.25.1.m1.1.1">
          †
         </ci>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="A1.T6.25.25.1.m1.1c">
         \dagger
        </annotation>
       </semantics>
      </math>
     </td>
     <td class="ltx_td ltx_align_left" id="A1.T6.25.25.2" style="padding:-0.2pt 14.0pt;">
      <span class="ltx_text" id="A1.T6.25.25.2.1" style="font-size:90%;">
       SignedJunctionRightTurn
      </span>
     </td>
    </tr>
    <tr class="ltx_tr" id="A1.T6.26.26">
     <td class="ltx_td ltx_align_left ltx_border_r" id="A1.T6.26.26.1" style="padding:-0.2pt 14.0pt;">
      <span class="ltx_text" id="A1.T6.26.26.1.1" style="font-size:90%;">
       26
      </span>
      <math alttext="\ddagger" class="ltx_Math" display="inline" id="A1.T6.26.26.1.m1.1">
       <semantics id="A1.T6.26.26.1.m1.1a">
        <mo id="A1.T6.26.26.1.m1.1.1" mathsize="90%" xref="A1.T6.26.26.1.m1.1.1.cmml">
         ‡
        </mo>
        <annotation-xml encoding="MathML-Content" id="A1.T6.26.26.1.m1.1b">
         <ci id="A1.T6.26.26.1.m1.1.1.cmml" xref="A1.T6.26.26.1.m1.1.1">
          ‡
         </ci>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="A1.T6.26.26.1.m1.1c">
         \ddagger
        </annotation>
       </semantics>
      </math>
     </td>
     <td class="ltx_td ltx_align_left" id="A1.T6.26.26.2" style="padding:-0.2pt 14.0pt;">
      <span class="ltx_text" id="A1.T6.26.26.2.1" style="font-size:90%;">
       PedestrianBlindSpotA
      </span>
     </td>
    </tr>
    <tr class="ltx_tr" id="A1.T6.27.27">
     <td class="ltx_td ltx_align_left ltx_border_r" id="A1.T6.27.27.1" style="padding:-0.2pt 14.0pt;">
      <span class="ltx_text" id="A1.T6.27.27.1.1" style="font-size:90%;">
       27
      </span>
      <math alttext="\ddagger" class="ltx_Math" display="inline" id="A1.T6.27.27.1.m1.1">
       <semantics id="A1.T6.27.27.1.m1.1a">
        <mo id="A1.T6.27.27.1.m1.1.1" mathsize="90%" xref="A1.T6.27.27.1.m1.1.1.cmml">
         ‡
        </mo>
        <annotation-xml encoding="MathML-Content" id="A1.T6.27.27.1.m1.1b">
         <ci id="A1.T6.27.27.1.m1.1.1.cmml" xref="A1.T6.27.27.1.m1.1.1">
          ‡
         </ci>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="A1.T6.27.27.1.m1.1c">
         \ddagger
        </annotation>
       </semantics>
      </math>
     </td>
     <td class="ltx_td ltx_align_left" id="A1.T6.27.27.2" style="padding:-0.2pt 14.0pt;">
      <span class="ltx_text" id="A1.T6.27.27.2.1" style="font-size:90%;">
       PedestrianBlindSpotB
      </span>
     </td>
    </tr>
    <tr class="ltx_tr" id="A1.T6.28.28">
     <td class="ltx_td ltx_align_left ltx_border_r" id="A1.T6.28.28.1" style="padding:-0.2pt 14.0pt;">
      <span class="ltx_text" id="A1.T6.28.28.1.1" style="font-size:90%;">
       28
      </span>
      <math alttext="\ddagger" class="ltx_Math" display="inline" id="A1.T6.28.28.1.m1.1">
       <semantics id="A1.T6.28.28.1.m1.1a">
        <mo id="A1.T6.28.28.1.m1.1.1" mathsize="90%" xref="A1.T6.28.28.1.m1.1.1.cmml">
         ‡
        </mo>
        <annotation-xml encoding="MathML-Content" id="A1.T6.28.28.1.m1.1b">
         <ci id="A1.T6.28.28.1.m1.1.1.cmml" xref="A1.T6.28.28.1.m1.1.1">
          ‡
         </ci>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="A1.T6.28.28.1.m1.1c">
         \ddagger
        </annotation>
       </semantics>
      </math>
     </td>
     <td class="ltx_td ltx_align_left" id="A1.T6.28.28.2" style="padding:-0.2pt 14.0pt;">
      <span class="ltx_text" id="A1.T6.28.28.2.1" style="font-size:90%;">
       VehicleBlindSpotA
      </span>
     </td>
    </tr>
    <tr class="ltx_tr" id="A1.T6.29.29">
     <td class="ltx_td ltx_align_left ltx_border_r" id="A1.T6.29.29.1" style="padding:-0.2pt 14.0pt;">
      <span class="ltx_text" id="A1.T6.29.29.1.1" style="font-size:90%;">
       29
      </span>
      <math alttext="\ddagger" class="ltx_Math" display="inline" id="A1.T6.29.29.1.m1.1">
       <semantics id="A1.T6.29.29.1.m1.1a">
        <mo id="A1.T6.29.29.1.m1.1.1" mathsize="90%" xref="A1.T6.29.29.1.m1.1.1.cmml">
         ‡
        </mo>
        <annotation-xml encoding="MathML-Content" id="A1.T6.29.29.1.m1.1b">
         <ci id="A1.T6.29.29.1.m1.1.1.cmml" xref="A1.T6.29.29.1.m1.1.1">
          ‡
         </ci>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="A1.T6.29.29.1.m1.1c">
         \ddagger
        </annotation>
       </semantics>
      </math>
     </td>
     <td class="ltx_td ltx_align_left" id="A1.T6.29.29.2" style="padding:-0.2pt 14.0pt;">
      <span class="ltx_text" id="A1.T6.29.29.2.1" style="font-size:90%;">
       VehicleBlindSpotB
      </span>
     </td>
    </tr>
    <tr class="ltx_tr" id="A1.T6.30.30">
     <td class="ltx_td ltx_align_left ltx_border_bb ltx_border_r" id="A1.T6.30.30.1" style="padding:-0.2pt 14.0pt;">
      <span class="ltx_text" id="A1.T6.30.30.1.1" style="font-size:90%;">
       30
      </span>
      <math alttext="\dagger" class="ltx_Math" display="inline" id="A1.T6.30.30.1.m1.1">
       <semantics id="A1.T6.30.30.1.m1.1a">
        <mo id="A1.T6.30.30.1.m1.1.1" mathsize="90%" xref="A1.T6.30.30.1.m1.1.1.cmml">
         †
        </mo>
        <annotation-xml encoding="MathML-Content" id="A1.T6.30.30.1.m1.1b">
         <ci id="A1.T6.30.30.1.m1.1.1.cmml" xref="A1.T6.30.30.1.m1.1.1">
          †
         </ci>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="A1.T6.30.30.1.m1.1c">
         \dagger
        </annotation>
       </semantics>
      </math>
     </td>
     <td class="ltx_td ltx_align_left ltx_border_bb" id="A1.T6.30.30.2" style="padding:-0.2pt 14.0pt;">
      <span class="ltx_text" id="A1.T6.30.30.2.1" style="font-size:90%;">
       FollowerChange
      </span>
     </td>
    </tr>
   </table>
   <figcaption class="ltx_caption ltx_centering" style="font-size:90%;">
    <span class="ltx_tag ltx_tag_table">
     Table F:
    </span>
    <span class="ltx_text ltx_font_bold" id="A1.T6.44.1">
     Scenario list.
    </span>
    <math alttext="\star" class="ltx_Math" display="inline" id="A1.T6.33.m1.1">
     <semantics id="A1.T6.33.m1.1b">
      <mo id="A1.T6.33.m1.1.1" xref="A1.T6.33.m1.1.1.cmml">
       ⋆
      </mo>
      <annotation-xml encoding="MathML-Content" id="A1.T6.33.m1.1c">
       <ci id="A1.T6.33.m1.1.1.cmml" xref="A1.T6.33.m1.1.1">
        ⋆
       </ci>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="A1.T6.33.m1.1d">
       \star
      </annotation>
     </semantics>
    </math>
    denotes that these scenarios are constructed by ourselves.
    <math alttext="\dagger" class="ltx_Math" display="inline" id="A1.T6.34.m2.1">
     <semantics id="A1.T6.34.m2.1b">
      <mo id="A1.T6.34.m2.1.1" xref="A1.T6.34.m2.1.1.cmml">
       †
      </mo>
      <annotation-xml encoding="MathML-Content" id="A1.T6.34.m2.1c">
       <ci id="A1.T6.34.m2.1.1.cmml" xref="A1.T6.34.m2.1.1">
        †
       </ci>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="A1.T6.34.m2.1d">
       \dagger
      </annotation>
     </semantics>
    </math>
    and denotes that these scenarios are from official Carla settings. and ReasonNet
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib58" title="">
      <span class="ltx_text" style="font-size:90%;">
       58
      </span>
     </a>
     ]
    </cite>
    , respectively.
   </figcaption>
  </figure>
 </section>
 <section class="ltx_appendix" id="A2">
  <h2 class="ltx_title ltx_title_appendix" style="font-size:144%;">
   <span class="ltx_tag ltx_tag_appendix">
    Appendix B
   </span>
   Scenario Details
  </h2>
  <div class="ltx_para" id="A2.p1">
   <p class="ltx_p" id="A2.p1.2">
    <span class="ltx_text" id="A2.p1.2.1" style="font-size:144%;">
     Our training data contains 30 common or rare safety-critical scenarios, and Table
    </span>
    <a class="ltx_ref" href="#A1.T6" style="font-size:144%;" title="Table F ‣ Appendix A Prompt Details ‣ DriveMLM: Aligning Multi-Modal Large Language Models with Behavioral Planning States for Autonomous Driving">
     <span class="ltx_text ltx_ref_tag">
      F
     </span>
    </a>
    <span class="ltx_text" id="A2.p1.2.2" style="font-size:144%;">
     lists the names of all the scenarios and describes the source of the scenarios. Non-custom scenarios (marked as
    </span>
    <math alttext="\dagger\;" class="ltx_Math" display="inline" id="A2.p1.1.m1.1">
     <semantics id="A2.p1.1.m1.1a">
      <mo id="A2.p1.1.m1.1.1" mathsize="144%" xref="A2.p1.1.m1.1.1.cmml">
       †
      </mo>
      <annotation-xml encoding="MathML-Content" id="A2.p1.1.m1.1b">
       <ci id="A2.p1.1.m1.1.1.cmml" xref="A2.p1.1.m1.1.1">
        †
       </ci>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="A2.p1.1.m1.1c">
       \dagger\;
      </annotation>
     </semantics>
    </math>
    <span class="ltx_text" id="A2.p1.2.3" style="font-size:144%;">
     and
    </span>
    <math alttext="\;\ddagger" class="ltx_Math" display="inline" id="A2.p1.2.m2.1">
     <semantics id="A2.p1.2.m2.1a">
      <mo id="A2.p1.2.m2.1.1" mathsize="144%" xref="A2.p1.2.m2.1.1.cmml">
       ‡
      </mo>
      <annotation-xml encoding="MathML-Content" id="A2.p1.2.m2.1b">
       <ci id="A2.p1.2.m2.1.1.cmml" xref="A2.p1.2.m2.1.1">
        ‡
       </ci>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="A2.p1.2.m2.1c">
       \;\ddagger
      </annotation>
     </semantics>
    </math>
    <span class="ltx_text" id="A2.p1.2.4" style="font-size:144%;">
     ) are usually set by loading preset trigger points, which makes it difficult to set them in other maps. Therefore, we have dynamized the scenarios to automatically find suitable trigger points on any map in preparation for the scenario setup. It is worth noting that all scenarios in Table
    </span>
    <a class="ltx_ref" href="#A1.T6" style="font-size:144%;" title="Table F ‣ Appendix A Prompt Details ‣ DriveMLM: Aligning Multi-Modal Large Language Models with Behavioral Planning States for Autonomous Driving">
     <span class="ltx_text ltx_ref_tag">
      F
     </span>
    </a>
    <span class="ltx_text" id="A2.p1.2.5" style="font-size:144%;">
     have been dynamized.
    </span>
   </p>
  </div>
  <div class="ltx_para" id="A2.p2">
   <p class="ltx_p" id="A2.p2.1">
    <span class="ltx_text" id="A2.p2.1.1" style="font-size:144%;">
     The customized scenarios are described as follows:
    </span>
   </p>
  </div>
  <div class="ltx_para" id="A2.p3">
   <p class="ltx_p" id="A2.p3.1">
    <span class="ltx_text" id="A2.p3.1.1" style="font-size:144%;">
     (1) YieldBehindEmergencyVehicles: An emergency vehicle (police car, ambulance, firetruck) is approaching from behind at high speed, and since there are vehicles driving on the left and right side lanes behind it, the ego vehicle needs to change lanes to the left/right to yield to the emergency vehicle.
    </span>
   </p>
  </div>
  <div class="ltx_para" id="A2.p4">
   <p class="ltx_p" id="A2.p4.1">
    <span class="ltx_text" id="A2.p4.1.1" style="font-size:144%;">
     (2) OvertakingFromLeft: Overtaking from the left due to a slow-moving vehicle ahead.
    </span>
   </p>
  </div>
  <div class="ltx_para" id="A2.p5">
   <p class="ltx_p" id="A2.p5.1">
    <span class="ltx_text" id="A2.p5.1.1" style="font-size:144%;">
     (3) OvertakingFromRight: Overtaking from the right due to a slow-moving vehicle ahead.
    </span>
   </p>
  </div>
  <div class="ltx_para" id="A2.p6">
   <p class="ltx_p" id="A2.p6.1">
    <span class="ltx_text" id="A2.p6.1.1" style="font-size:144%;">
     (4) JunctionLeftChange: Turn left at the intersection ahead, but the ego vehicle is not currently in the leftmost left turn lane, so the ego vehicle changes lanes to the left and then turns left through the intersection.
    </span>
   </p>
  </div>
  <div class="ltx_para" id="A2.p7">
   <p class="ltx_p" id="A2.p7.1">
    <span class="ltx_text" id="A2.p7.1.1" style="font-size:144%;">
     (5) JunctionRightChange: Turn right at the intersection ahead, but the ego vehicle is not currently in the rightmost right turn lane, so the ego vehicle changes lanes to the right and then turns right through the intersection.
    </span>
   </p>
  </div>
  <div class="ltx_para" id="A2.p8">
   <p class="ltx_p" id="A2.p8.1">
    <span class="ltx_text" id="A2.p8.1.1" style="font-size:144%;">
     (6) JunctionStraight: Go straight ahead at intersections, follow traffic rules, and avoid collisions with other vehicles.
    </span>
   </p>
  </div>
  <div class="ltx_para" id="A2.p9">
   <p class="ltx_p" id="A2.p9.1">
    <span class="ltx_text" id="A2.p9.1.1" style="font-size:144%;">
     (7) JunctionYieldPedestrian: Pedestrians are crossing the crosswalk at the intersection ahead, so the ego vehicle yields to pedestrians.
    </span>
   </p>
  </div>
  <div class="ltx_para" id="A2.p10">
   <p class="ltx_p" id="A2.p10.1">
    <span class="ltx_text" id="A2.p10.1.1" style="font-size:144%;">
     (8) LeftChangeInRoute: The vehicle in front of the ego vehicle is moving slowly, change lanes to the left to cancel the following.
    </span>
   </p>
  </div>
  <div class="ltx_para" id="A2.p11">
   <p class="ltx_p" id="A2.p11.1">
    <span class="ltx_text" id="A2.p11.1.1" style="font-size:144%;">
     (9) RightchangeInRoute: The vehicle in front of the ego vehicle is moving slowly, change lanes to the right to cancel the following.
    </span>
   </p>
  </div>
  <figure class="ltx_figure" id="A2.F1">
   <div class="ltx_flex_figure">
    <div class="ltx_flex_cell ltx_flex_size_1">
     <figure class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_top" id="A2.F1.sf1" style="width:243.5pt;">
      <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="180" id="A2.F1.sf1.g1" src="/html/2312.09245/assets/x8.png" width="242"/>
      <figcaption class="ltx_caption ltx_centering" style="font-size:144%;">
       <span class="ltx_tag ltx_tag_figure">
        <span class="ltx_text" id="A2.F1.sf1.3.1.1" style="font-size:63%;">
         a
        </span>
       </span>
      </figcaption>
     </figure>
    </div>
    <div class="ltx_flex_break">
    </div>
    <div class="ltx_flex_cell ltx_flex_size_1">
     <figure class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_top" id="A2.F1.sf2" style="width:243.5pt;">
      <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="183" id="A2.F1.sf2.g1" src="/html/2312.09245/assets/x9.png" width="242"/>
      <figcaption class="ltx_caption ltx_centering" style="font-size:144%;">
       <span class="ltx_tag ltx_tag_figure">
        <span class="ltx_text" id="A2.F1.sf2.3.1.1" style="font-size:63%;">
         b
        </span>
       </span>
      </figcaption>
     </figure>
    </div>
   </div>
   <figcaption class="ltx_caption" style="font-size:144%;">
    <span class="ltx_tag ltx_tag_figure">
     <span class="ltx_text" id="A2.F1.5.1.1" style="font-size:63%;">
      Figure A
     </span>
     :
    </span>
    <span class="ltx_text ltx_font_bold" id="A2.F1.6.2" style="font-size:63%;">
     Comparison between Interfuser, Apollo, and DriveMLM when confronted with unknown objects (a) and an emergency vehicle behind (b).
     <span class="ltx_text ltx_font_medium" id="A2.F1.6.2.1">
      (a) Interfuser ignores the obstacles and causes a crash, Apollo stops before the unknown objects, and DriveMLM successfully bypasses the obstacles by a borrow lane decision. (b) Interfuser and Apollo do not yield to the firetruck behind, but DriveMLM successfully changes lanes to the right and yields to the firetruck.
     </span>
    </span>
   </figcaption>
  </figure>
 </section>
 <section class="ltx_appendix" id="A3">
  <h2 class="ltx_title ltx_title_appendix" style="font-size:144%;">
   <span class="ltx_tag ltx_tag_appendix">
    Appendix C
   </span>
   Comparative Analysis of Diverse Methods
  </h2>
  <div class="ltx_para" id="A3.p1">
   <p class="ltx_p" id="A3.p1.1">
    <span class="ltx_text" id="A3.p1.1.1" style="font-size:144%;">
     Compared to methods such as Interfuser
    </span>
    <cite class="ltx_cite ltx_citemacro_cite">
     <span class="ltx_text" id="A3.p1.1.2.1" style="font-size:144%;">
      [
     </span>
     <a class="ltx_ref" href="#bib.bib57" title="">
      <span class="ltx_text" style="font-size:90%;">
       57
      </span>
     </a>
     <span class="ltx_text" id="A3.p1.1.3.2" style="font-size:144%;">
      ]
     </span>
    </cite>
    <span class="ltx_text" id="A3.p1.1.4" style="font-size:144%;">
     or Apollo
    </span>
    <cite class="ltx_cite ltx_citemacro_cite">
     <span class="ltx_text" id="A3.p1.1.5.1" style="font-size:144%;">
      [
     </span>
     <a class="ltx_ref" href="#bib.bib3" title="">
      <span class="ltx_text" style="font-size:90%;">
       3
      </span>
     </a>
     <span class="ltx_text" id="A3.p1.1.6.2" style="font-size:144%;">
      ]
     </span>
    </cite>
    <span class="ltx_text" id="A3.p1.1.7" style="font-size:144%;">
     , our approach demonstrates superior performance in scenarios with unknown obstacles or those necessitating common sense. As depicted in Figure
    </span>
    <a class="ltx_ref" href="#A2.F1" style="font-size:144%;" title="Figure A ‣ Appendix B Scenario Details ‣ DriveMLM: Aligning Multi-Modal Large Language Models with Behavioral Planning States for Autonomous Driving">
     <span class="ltx_text ltx_ref_tag">
      A
     </span>
    </a>
    <span class="ltx_text" id="A3.p1.1.8" style="font-size:144%;">
     (a), when facing unknown obstacles on the road, previous methods typically either overlook them or halt the vehicle, both strategies deviating from optimal driving practices. In contrast, our method employs a more logical ’borrow lane’ decision, effectively preventing accidents. In addition, the deficiency of previous methods in embodying real-world common sense or understanding traffic rules limits their capability to manage diverse special scenarios encountered in complex driving scenarios. Illustratively, as shown in Figure
    </span>
    <a class="ltx_ref" href="#A2.F1" style="font-size:144%;" title="Figure A ‣ Appendix B Scenario Details ‣ DriveMLM: Aligning Multi-Modal Large Language Models with Behavioral Planning States for Autonomous Driving">
     <span class="ltx_text ltx_ref_tag">
      A
     </span>
    </a>
    <span class="ltx_text" id="A3.p1.1.9" style="font-size:144%;">
     (b), when emergency vehicles approaching from behind, conventional methods fail to yield, whereas our method proactively clears the path for the firetruck.
    </span>
   </p>
  </div>
  <div class="ltx_para" id="A3.p2">
   <p class="ltx_p" id="A3.p2.1">
    <span class="ltx_text" id="A3.p2.1.1" style="font-size:144%;">
     We posit that since corner cases in driving are virtually infinite, the integration of the chain of thought, augmented with pre-defined traffic knowledge, is particularly vital for decision-making in driving scenarios. Given the inherent characteristics of Large Language Models (LLMs), our DriveMLM demonstrates significant potential for adaptation to varied environments and for being tuned to distinct driving styles across diverse settings.
    </span>
   </p>
  </div>
  <figure class="ltx_figure" id="A3.F2">
   <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="270" id="A3.F2.g1" src="/html/2312.09245/assets/x10.png" width="226"/>
   <figcaption class="ltx_caption ltx_centering" style="font-size:144%;">
    <span class="ltx_tag ltx_tag_figure">
     <span class="ltx_text" id="A3.F2.5.1.1" style="font-size:63%;">
      Figure B
     </span>
     :
    </span>
    <span class="ltx_text ltx_font_bold" id="A3.F2.6.2" style="font-size:63%;">
     Visualization of human interaction with DriveMLM
     <span class="ltx_text ltx_font_medium" id="A3.F2.6.2.1">
      , featuring examples of (a) yield and (b) a successful borrow. In each example, the left image captures the moment of giving instructions, while the right image represents a subsequent stage of instruction execution.
     </span>
    </span>
   </figcaption>
  </figure>
  <figure class="ltx_figure" id="A3.F3">
   <div class="ltx_flex_figure">
    <div class="ltx_flex_cell ltx_flex_size_1">
     <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_square" height="265" id="A3.F3.g1" src="/html/2312.09245/assets/figs/llava_blip_a.png" width="269"/>
    </div>
    <div class="ltx_flex_break">
    </div>
    <div class="ltx_flex_cell ltx_flex_size_1">
     <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_square" height="268" id="A3.F3.g2" src="/html/2312.09245/assets/figs/llava_blip_b.png" width="269"/>
    </div>
   </div>
   <figcaption class="ltx_caption ltx_centering" style="font-size:144%;">
    <span class="ltx_tag ltx_tag_figure">
     <span class="ltx_text" id="A3.F3.5.1.1" style="font-size:63%;">
      Figure C
     </span>
     :
    </span>
    <span class="ltx_text ltx_font_bold" id="A3.F3.6.2" style="font-size:63%;">
     Comparison with LLaVA 1.5 and InstructBLIP
     <span class="ltx_text ltx_font_medium" id="A3.F3.6.2.1">
      .
(a) Both LLaVA 1.5 and InstructBLIP fail to provide the correct “left borrow” advice. Where there are obstacles ahead and the left lane adjacent to the ego vehicle is clear, the appropriate action would be for the ego vehicle to move into the left lane. (b) When the ego vehicle is not in the leftmost lane but needs to execute a left turn, it should ideally shift to the left lane first. In this instance, LLaVA 1.5 overlooks the left lane change, and InstructBLIP erroneously advises to stay in the lane and ignores the left turn instruction.
     </span>
    </span>
   </figcaption>
  </figure>
 </section>
 <section class="ltx_appendix" id="A4">
  <h2 class="ltx_title ltx_title_appendix" style="font-size:144%;">
   <span class="ltx_tag ltx_tag_appendix">
    Appendix D
   </span>
   Human Interaction with DriveMLM
  </h2>
  <div class="ltx_para" id="A4.p1">
   <p class="ltx_p" id="A4.p1.1">
    <span class="ltx_text" id="A4.p1.1.1" style="font-size:144%;">
     In Figure
    </span>
    <a class="ltx_ref" href="#A3.F2" style="font-size:144%;" title="Figure B ‣ Appendix C Comparative Analysis of Diverse Methods ‣ DriveMLM: Aligning Multi-Modal Large Language Models with Behavioral Planning States for Autonomous Driving">
     <span class="ltx_text ltx_ref_tag">
      B
     </span>
    </a>
    <span class="ltx_text" id="A4.p1.1.2" style="font-size:144%;">
     , we demonstrate humans can interact with DriveMLM using natural language with more examples. Humans can provide driving instructions to DriveMLM or request DriveMLM to explain its driving decisions. Leveraging the advantages of large language models, our approach offers enhanced interpretability, contributing to the development of safer autonomous driving systems.
    </span>
   </p>
  </div>
 </section>
 <section class="ltx_appendix" id="A5">
  <h2 class="ltx_title ltx_title_appendix" style="font-size:144%;">
   <span class="ltx_tag ltx_tag_appendix">
    Appendix E
   </span>
   Comparison with Other Multi-Modal Large
Language Models
  </h2>
  <div class="ltx_para" id="A5.p1">
   <p class="ltx_p" id="A5.p1.1">
    <span class="ltx_text" id="A5.p1.1.1" style="font-size:144%;">
     As shown in Figure
    </span>
    <a class="ltx_ref" href="#A3.F3" style="font-size:144%;" title="Figure C ‣ Appendix C Comparative Analysis of Diverse Methods ‣ DriveMLM: Aligning Multi-Modal Large Language Models with Behavioral Planning States for Autonomous Driving">
     <span class="ltx_text ltx_ref_tag">
      C
     </span>
    </a>
    <span class="ltx_text" id="A5.p1.1.2" style="font-size:144%;">
     , in the context of autonomous driving scenarios, LLaVA 1.5
    </span>
    <cite class="ltx_cite ltx_citemacro_cite">
     <span class="ltx_text" id="A5.p1.1.3.1" style="font-size:144%;">
      [
     </span>
     <a class="ltx_ref" href="#bib.bib38" title="">
      <span class="ltx_text" style="font-size:90%;">
       38
      </span>
     </a>
     <span class="ltx_text" id="A5.p1.1.4.2" style="font-size:144%;">
      ]
     </span>
    </cite>
    <span class="ltx_text" id="A5.p1.1.5" style="font-size:144%;">
     and InstructBLIP
    </span>
    <cite class="ltx_cite ltx_citemacro_cite">
     <span class="ltx_text" id="A5.p1.1.6.1" style="font-size:144%;">
      [
     </span>
     <a class="ltx_ref" href="#bib.bib17" title="">
      <span class="ltx_text" style="font-size:90%;">
       17
      </span>
     </a>
     <span class="ltx_text" id="A5.p1.1.7.2" style="font-size:144%;">
      ]
     </span>
    </cite>
    <span class="ltx_text" id="A5.p1.1.8" style="font-size:144%;">
     fail to adequately comprehend the driving environment, often issuing incorrect instructions and hallucinatory explanations.
    </span>
   </p>
  </div>
  <figure class="ltx_figure" id="A5.F4">
   <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="252" id="A5.F4.g1" src="/html/2312.09245/assets/x11.png" width="523"/>
   <figcaption class="ltx_caption ltx_centering" style="font-size:144%;">
    <span class="ltx_tag ltx_tag_figure">
     <span class="ltx_text" id="A5.F4.5.1.1" style="font-size:63%;">
      Figure D
     </span>
     :
    </span>
    <span class="ltx_text ltx_font_bold" id="A5.F4.6.2" style="font-size:63%;">
     Comparison with GPT-4V.
     <span class="ltx_text ltx_font_medium" id="A5.F4.6.2.1">
      (a) GPT-4V inaccurately suggests a lane change to the right, but ego is already in the rightmost lane and the traffic light is red, so ego needs to come to a stop; (b) GPT-4V mistakenly advises to follow, but there is a car blocking the way ahead, so ego need to change lanes to the left and overtake; (c) GPT-4V incorrectly instructs to follow the current lane, but there are obstacles ahead, so ego need to switch to the left lane; and (d) GPT-4V accurately instructs to follow since there are no vehicles ahead.
     </span>
    </span>
   </figcaption>
  </figure>
 </section>
 <section class="ltx_appendix" id="A6">
  <h2 class="ltx_title ltx_title_appendix" style="font-size:144%;">
   <span class="ltx_tag ltx_tag_appendix">
    Appendix F
   </span>
   Compared with GPT-4V
  </h2>
  <div class="ltx_para" id="A6.p1">
   <p class="ltx_p" id="A6.p1.1">
    <span class="ltx_text" id="A6.p1.1.1" style="font-size:144%;">
     In our comparative analysis with GPT-4V
    </span>
    <cite class="ltx_cite ltx_citemacro_cite">
     <span class="ltx_text" id="A6.p1.1.2.1" style="font-size:144%;">
      [
     </span>
     <a class="ltx_ref" href="#bib.bib46" title="">
      <span class="ltx_text" style="font-size:90%;">
       46
      </span>
     </a>
     <span class="ltx_text" id="A6.p1.1.3.2" style="font-size:144%;">
      ]
     </span>
    </cite>
    <span class="ltx_text" id="A6.p1.1.4" style="font-size:144%;">
     , as depicted in Figure
    </span>
    <a class="ltx_ref" href="#A5.F4" style="font-size:144%;" title="Figure D ‣ Appendix E Comparison with Other Multi-Modal Large Language Models ‣ DriveMLM: Aligning Multi-Modal Large Language Models with Behavioral Planning States for Autonomous Driving">
     <span class="ltx_text ltx_ref_tag">
      D
     </span>
    </a>
    <span class="ltx_text" id="A6.p1.1.5" style="font-size:144%;">
     , we noted that GPT-4V generated incorrect driving commands in three scenarios: (a), (b), and (c). Specifically, GPT-4V struggled with accurately perceiving road lanes in scenario (a), the motion status of other vehicles in scenario (b), and atypical obstacles in scenario (c). In contrast, our method not only provided sensible driving commands but also offered precise linguistic explanations for each of these scenarios
    </span>
   </p>
  </div>
 </section>
 <section class="ltx_appendix" id="A7">
  <h2 class="ltx_title ltx_title_appendix" style="font-size:144%;">
   <span class="ltx_tag ltx_tag_appendix">
    Appendix G
   </span>
   Zero-Shot Results on nuScenes
  </h2>
  <figure class="ltx_figure" id="A7.F5">
   <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="196" id="A7.F5.g1" src="/html/2312.09245/assets/x12.png" width="230"/>
   <figcaption class="ltx_caption ltx_centering" style="font-size:144%;">
    <span class="ltx_tag ltx_tag_figure">
     <span class="ltx_text" id="A7.F5.5.1.1" style="font-size:63%;">
      Figure E
     </span>
     :
    </span>
    <span class="ltx_text ltx_font_bold" id="A7.F5.6.2" style="font-size:63%;">
     More zero-shot performance of DriveMLM
     <span class="ltx_text ltx_font_medium" id="A7.F5.6.2.1">
      on the real driving scene from the nuScenes dataset.
     </span>
    </span>
   </figcaption>
  </figure>
  <div class="ltx_para" id="A7.p1">
   <p class="ltx_p" id="A7.p1.1">
    <span class="ltx_text" id="A7.p1.1.1" style="font-size:144%;">
     We provide more visualization of the zero-shot results of our model on nuScenes. As shown in Figure
    </span>
    <a class="ltx_ref" href="#A7.F5" style="font-size:144%;" title="Figure E ‣ Appendix G Zero-Shot Results on nuScenes ‣ DriveMLM: Aligning Multi-Modal Large Language Models with Behavioral Planning States for Autonomous Driving">
     <span class="ltx_text ltx_ref_tag">
      E
     </span>
    </a>
    <span class="ltx_text" id="A7.p1.1.2" style="font-size:144%;">
     , despite our model being trained solely on simulator images, it still exhibits commendable generalization capabilities on real-world data. The robust generalizability of our model significantly enhances its potential for application.
    </span>
   </p>
  </div>
 </section>
 <section class="ltx_appendix" id="A8">
  <h2 class="ltx_title ltx_title_appendix" style="font-size:144%;">
   <span class="ltx_tag ltx_tag_appendix">
    Appendix H
   </span>
   Closed Loop Ablation Studies
  </h2>
  <figure class="ltx_table" id="A8.T7">
   <table class="ltx_tabular ltx_centering ltx_align_middle" id="A8.T7.2">
    <tr class="ltx_tr" id="A8.T7.2.1">
     <td class="ltx_td ltx_align_center ltx_border_tt" id="A8.T7.2.1.1" style="padding-left:8.0pt;padding-right:8.0pt;">
      <span class="ltx_text" id="A8.T7.2.1.1.1" style="font-size:90%;">
       MV
      </span>
     </td>
     <td class="ltx_td ltx_align_center ltx_border_tt" id="A8.T7.2.1.2" style="padding-left:8.0pt;padding-right:8.0pt;">
      <span class="ltx_text" id="A8.T7.2.1.2.1" style="font-size:90%;">
       TQ
      </span>
     </td>
     <td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="A8.T7.2.1.3" style="padding-left:8.0pt;padding-right:8.0pt;">
      <span class="ltx_text" id="A8.T7.2.1.3.1" style="font-size:90%;">
       PC
      </span>
     </td>
     <td class="ltx_td ltx_align_center ltx_border_tt" id="A8.T7.2.1.4" style="padding-left:8.0pt;padding-right:8.0pt;">
      <span class="ltx_text" id="A8.T7.2.1.4.1" style="font-size:90%;">
       DS
      </span>
     </td>
     <td class="ltx_td ltx_align_center ltx_border_tt" id="A8.T7.2.1.5" style="padding-left:8.0pt;padding-right:8.0pt;">
      <span class="ltx_text" id="A8.T7.2.1.5.1">
      </span>
      <span class="ltx_text" id="A8.T7.2.1.5.2" style="font-size:90%;">
      </span>
      <span class="ltx_text" id="A8.T7.2.1.5.3" style="font-size:90%;">
       <span class="ltx_tabular ltx_align_middle" id="A8.T7.2.1.5.3.1">
        <span class="ltx_tr" id="A8.T7.2.1.5.3.1.1">
         <span class="ltx_td ltx_nopad_r ltx_align_center" id="A8.T7.2.1.5.3.1.1.1" style="padding-left:8.0pt;padding-right:8.0pt;">
          RC
         </span>
        </span>
       </span>
      </span>
      <span class="ltx_text" id="A8.T7.2.1.5.4">
      </span>
      <span class="ltx_text" id="A8.T7.2.1.5.5" style="font-size:90%;">
      </span>
     </td>
     <td class="ltx_td ltx_align_center ltx_border_tt" id="A8.T7.2.1.6" style="padding-left:8.0pt;padding-right:8.0pt;">
      <span class="ltx_text" id="A8.T7.2.1.6.1">
      </span>
      <span class="ltx_text" id="A8.T7.2.1.6.2" style="font-size:90%;">
      </span>
      <span class="ltx_text" id="A8.T7.2.1.6.3" style="font-size:90%;">
       <span class="ltx_tabular ltx_align_middle" id="A8.T7.2.1.6.3.1">
        <span class="ltx_tr" id="A8.T7.2.1.6.3.1.1">
         <span class="ltx_td ltx_nopad_r ltx_align_center" id="A8.T7.2.1.6.3.1.1.1" style="padding-left:8.0pt;padding-right:8.0pt;">
          IS
         </span>
        </span>
       </span>
      </span>
      <span class="ltx_text" id="A8.T7.2.1.6.4">
      </span>
      <span class="ltx_text" id="A8.T7.2.1.6.5" style="font-size:90%;">
      </span>
     </td>
    </tr>
    <tr class="ltx_tr" id="A8.T7.2.2">
     <td class="ltx_td ltx_align_center ltx_border_t" id="A8.T7.2.2.1" style="padding-left:8.0pt;padding-right:8.0pt;">
      <span class="ltx_text" id="A8.T7.2.2.1.1" style="font-size:90%;">
       -
      </span>
     </td>
     <td class="ltx_td ltx_align_center ltx_border_t" id="A8.T7.2.2.2" style="padding-left:8.0pt;padding-right:8.0pt;">
      <span class="ltx_text" id="A8.T7.2.2.2.1" style="font-size:90%;">
       -
      </span>
     </td>
     <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A8.T7.2.2.3" style="padding-left:8.0pt;padding-right:8.0pt;">
      <span class="ltx_text" id="A8.T7.2.2.3.1" style="font-size:90%;">
       -
      </span>
     </td>
     <td class="ltx_td ltx_align_center ltx_border_t" id="A8.T7.2.2.4" style="padding-left:8.0pt;padding-right:8.0pt;">
      <span class="ltx_text" id="A8.T7.2.2.4.1" style="font-size:90%;">
       36.7
      </span>
     </td>
     <td class="ltx_td ltx_align_center ltx_border_t" id="A8.T7.2.2.5" style="padding-left:8.0pt;padding-right:8.0pt;">
      <span class="ltx_text" id="A8.T7.2.2.5.1" style="font-size:90%;">
       70.6
      </span>
     </td>
     <td class="ltx_td ltx_align_center ltx_border_t" id="A8.T7.2.2.6" style="padding-left:8.0pt;padding-right:8.0pt;">
      <span class="ltx_text" id="A8.T7.2.2.6.1" style="font-size:90%;">
       0.52
      </span>
     </td>
    </tr>
    <tr class="ltx_tr" id="A8.T7.2.3">
     <td class="ltx_td ltx_align_center" id="A8.T7.2.3.1" style="padding-left:8.0pt;padding-right:8.0pt;">
      <span class="ltx_text" id="A8.T7.2.3.1.1" style="font-size:90%;">
       ✓
      </span>
     </td>
     <td class="ltx_td ltx_align_center" id="A8.T7.2.3.2" style="padding-left:8.0pt;padding-right:8.0pt;">
      <span class="ltx_text" id="A8.T7.2.3.2.1" style="font-size:90%;">
       -
      </span>
     </td>
     <td class="ltx_td ltx_align_center ltx_border_r" id="A8.T7.2.3.3" style="padding-left:8.0pt;padding-right:8.0pt;">
      <span class="ltx_text" id="A8.T7.2.3.3.1" style="font-size:90%;">
       -
      </span>
     </td>
     <td class="ltx_td ltx_align_center" id="A8.T7.2.3.4" style="padding-left:8.0pt;padding-right:8.0pt;">
      <span class="ltx_text" id="A8.T7.2.3.4.1" style="font-size:90%;">
       65.2
      </span>
     </td>
     <td class="ltx_td ltx_align_center" id="A8.T7.2.3.5" style="padding-left:8.0pt;padding-right:8.0pt;">
      <span class="ltx_text" id="A8.T7.2.3.5.1" style="font-size:90%;">
       90.5
      </span>
     </td>
     <td class="ltx_td ltx_align_center" id="A8.T7.2.3.6" style="padding-left:8.0pt;padding-right:8.0pt;">
      <span class="ltx_text" id="A8.T7.2.3.6.1" style="font-size:90%;">
       0.72
      </span>
     </td>
    </tr>
    <tr class="ltx_tr" id="A8.T7.2.4">
     <td class="ltx_td ltx_align_center" id="A8.T7.2.4.1" style="padding-left:8.0pt;padding-right:8.0pt;">
      <span class="ltx_text" id="A8.T7.2.4.1.1" style="font-size:90%;">
       ✓
      </span>
     </td>
     <td class="ltx_td ltx_align_center" id="A8.T7.2.4.2" style="padding-left:8.0pt;padding-right:8.0pt;">
      <span class="ltx_text" id="A8.T7.2.4.2.1" style="font-size:90%;">
       ✓
      </span>
     </td>
     <td class="ltx_td ltx_align_center ltx_border_r" id="A8.T7.2.4.3" style="padding-left:8.0pt;padding-right:8.0pt;">
      <span class="ltx_text" id="A8.T7.2.4.3.1" style="font-size:90%;">
       -
      </span>
     </td>
     <td class="ltx_td ltx_align_center" id="A8.T7.2.4.4" style="padding-left:8.0pt;padding-right:8.0pt;">
      <span class="ltx_text ltx_font_bold" id="A8.T7.2.4.4.1" style="font-size:90%;">
       76.1
      </span>
     </td>
     <td class="ltx_td ltx_align_center" id="A8.T7.2.4.5" style="padding-left:8.0pt;padding-right:8.0pt;">
      <span class="ltx_text ltx_font_bold" id="A8.T7.2.4.5.1" style="font-size:90%;">
       98.1
      </span>
     </td>
     <td class="ltx_td ltx_align_center" id="A8.T7.2.4.6" style="padding-left:8.0pt;padding-right:8.0pt;">
      <span class="ltx_text ltx_font_bold" id="A8.T7.2.4.6.1" style="font-size:90%;">
       0.78
      </span>
     </td>
    </tr>
    <tr class="ltx_tr" id="A8.T7.2.5">
     <td class="ltx_td ltx_align_center ltx_border_bb" id="A8.T7.2.5.1" style="padding-left:8.0pt;padding-right:8.0pt;">
      <span class="ltx_text" id="A8.T7.2.5.1.1" style="font-size:90%;">
       ✓
      </span>
     </td>
     <td class="ltx_td ltx_align_center ltx_border_bb" id="A8.T7.2.5.2" style="padding-left:8.0pt;padding-right:8.0pt;">
      <span class="ltx_text" id="A8.T7.2.5.2.1" style="font-size:90%;">
       ✓
      </span>
     </td>
     <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="A8.T7.2.5.3" style="padding-left:8.0pt;padding-right:8.0pt;">
      <span class="ltx_text" id="A8.T7.2.5.3.1" style="font-size:90%;">
       ✓
      </span>
     </td>
     <td class="ltx_td ltx_align_center ltx_border_bb" id="A8.T7.2.5.4" style="padding-left:8.0pt;padding-right:8.0pt;">
      <span class="ltx_text" id="A8.T7.2.5.4.1" style="font-size:90%;">
       72.2
      </span>
     </td>
     <td class="ltx_td ltx_align_center ltx_border_bb" id="A8.T7.2.5.5" style="padding-left:8.0pt;padding-right:8.0pt;">
      <span class="ltx_text" id="A8.T7.2.5.5.1" style="font-size:90%;">
       96.3
      </span>
     </td>
     <td class="ltx_td ltx_align_center ltx_border_bb" id="A8.T7.2.5.6" style="padding-left:8.0pt;padding-right:8.0pt;">
      <span class="ltx_text" id="A8.T7.2.5.6.1" style="font-size:90%;">
       0.75
      </span>
     </td>
    </tr>
   </table>
   <figcaption class="ltx_caption ltx_centering" style="font-size:90%;">
    <span class="ltx_tag ltx_tag_table">
     Table G:
    </span>
    <span class="ltx_text ltx_font_bold" id="A8.T7.6.1">
     Ablation results on Town05 Long of sensor modality and temporal information.
    </span>
    MV denotes multi-view images, TQ denotes temporal QFormer, and PC denotes point clouds.
   </figcaption>
  </figure>
  <figure class="ltx_table" id="A8.T8">
   <table class="ltx_tabular ltx_centering ltx_align_middle" id="A8.T8.4">
    <tr class="ltx_tr" id="A8.T8.4.4">
     <td class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" id="A8.T8.4.4.5" style="padding-left:5.0pt;padding-right:5.0pt;">
      <span class="ltx_text" id="A8.T8.4.4.5.1" style="font-size:90%;">
       LLM
      </span>
     </td>
     <td class="ltx_td ltx_align_center ltx_border_tt" id="A8.T8.1.1.1" style="padding-left:5.0pt;padding-right:5.0pt;">
      <span class="ltx_text" id="A8.T8.1.1.1.1" style="font-size:90%;">
       Acc.
      </span>
      <math alttext="(\%)" class="ltx_math_unparsed" display="inline" id="A8.T8.1.1.1.m1.1">
       <semantics id="A8.T8.1.1.1.m1.1a">
        <mrow id="A8.T8.1.1.1.m1.1b">
         <mo id="A8.T8.1.1.1.m1.1.1" maxsize="90%" minsize="90%">
          (
         </mo>
         <mo id="A8.T8.1.1.1.m1.1.2" mathsize="90%">
          %
         </mo>
         <mo id="A8.T8.1.1.1.m1.1.3" maxsize="90%" minsize="90%">
          )
         </mo>
        </mrow>
        <annotation encoding="application/x-tex" id="A8.T8.1.1.1.m1.1c">
         (\%)
        </annotation>
       </semantics>
      </math>
     </td>
     <td class="ltx_td ltx_align_center ltx_border_tt" id="A8.T8.2.2.2" style="padding-left:5.0pt;padding-right:5.0pt;">
      <span class="ltx_text" id="A8.T8.2.2.2.1" style="font-size:90%;">
       BLEU-4
      </span>
      <math alttext="\uparrow" class="ltx_Math" display="inline" id="A8.T8.2.2.2.m1.1">
       <semantics id="A8.T8.2.2.2.m1.1a">
        <mo id="A8.T8.2.2.2.m1.1.1" mathsize="90%" stretchy="false" xref="A8.T8.2.2.2.m1.1.1.cmml">
         ↑
        </mo>
        <annotation-xml encoding="MathML-Content" id="A8.T8.2.2.2.m1.1b">
         <ci id="A8.T8.2.2.2.m1.1.1.cmml" xref="A8.T8.2.2.2.m1.1.1">
          ↑
         </ci>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="A8.T8.2.2.2.m1.1c">
         \uparrow
        </annotation>
       </semantics>
      </math>
     </td>
     <td class="ltx_td ltx_align_center ltx_border_tt" id="A8.T8.3.3.3" style="padding-left:5.0pt;padding-right:5.0pt;">
      <span class="ltx_text" id="A8.T8.3.3.3.1" style="font-size:90%;">
       CIDEr
      </span>
      <math alttext="\uparrow" class="ltx_Math" display="inline" id="A8.T8.3.3.3.m1.1">
       <semantics id="A8.T8.3.3.3.m1.1a">
        <mo id="A8.T8.3.3.3.m1.1.1" mathsize="90%" stretchy="false" xref="A8.T8.3.3.3.m1.1.1.cmml">
         ↑
        </mo>
        <annotation-xml encoding="MathML-Content" id="A8.T8.3.3.3.m1.1b">
         <ci id="A8.T8.3.3.3.m1.1.1.cmml" xref="A8.T8.3.3.3.m1.1.1">
          ↑
         </ci>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="A8.T8.3.3.3.m1.1c">
         \uparrow
        </annotation>
       </semantics>
      </math>
     </td>
     <td class="ltx_td ltx_align_center ltx_border_tt" id="A8.T8.4.4.4" style="padding-left:5.0pt;padding-right:5.0pt;">
      <span class="ltx_text" id="A8.T8.4.4.4.1" style="font-size:90%;">
       METEOR
      </span>
      <math alttext="\uparrow" class="ltx_Math" display="inline" id="A8.T8.4.4.4.m1.1">
       <semantics id="A8.T8.4.4.4.m1.1a">
        <mo id="A8.T8.4.4.4.m1.1.1" mathsize="90%" stretchy="false" xref="A8.T8.4.4.4.m1.1.1.cmml">
         ↑
        </mo>
        <annotation-xml encoding="MathML-Content" id="A8.T8.4.4.4.m1.1b">
         <ci id="A8.T8.4.4.4.m1.1.1.cmml" xref="A8.T8.4.4.4.m1.1.1">
          ↑
         </ci>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="A8.T8.4.4.4.m1.1c">
         \uparrow
        </annotation>
       </semantics>
      </math>
     </td>
    </tr>
    <tr class="ltx_tr" id="A8.T8.4.5">
     <td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="A8.T8.4.5.1" style="padding-left:5.0pt;padding-right:5.0pt;">
      <span class="ltx_text" id="A8.T8.4.5.1.1" style="font-size:90%;">
       LLaMA-7B
      </span>
     </td>
     <td class="ltx_td ltx_align_center ltx_border_t" id="A8.T8.4.5.2" style="padding-left:5.0pt;padding-right:5.0pt;">
      <span class="ltx_text" id="A8.T8.4.5.2.1" style="font-size:90%;">
       47.83
      </span>
     </td>
     <td class="ltx_td ltx_align_center ltx_border_t" id="A8.T8.4.5.3" style="padding-left:5.0pt;padding-right:5.0pt;">
      <span class="ltx_text" id="A8.T8.4.5.3.1" style="font-size:90%;">
       22.03
      </span>
     </td>
     <td class="ltx_td ltx_align_center ltx_border_t" id="A8.T8.4.5.4" style="padding-left:5.0pt;padding-right:5.0pt;">
      <span class="ltx_text" id="A8.T8.4.5.4.1" style="font-size:90%;">
       38.85
      </span>
     </td>
     <td class="ltx_td ltx_align_center ltx_border_t" id="A8.T8.4.5.5" style="padding-left:5.0pt;padding-right:5.0pt;">
      <span class="ltx_text" id="A8.T8.4.5.5.1" style="font-size:90%;">
       40.10
      </span>
     </td>
    </tr>
    <tr class="ltx_tr" id="A8.T8.4.6">
     <td class="ltx_td ltx_align_left ltx_border_bb ltx_border_r" id="A8.T8.4.6.1" style="padding-left:5.0pt;padding-right:5.0pt;">
      <span class="ltx_text" id="A8.T8.4.6.1.1" style="font-size:90%;">
       LLaMA-13B
      </span>
     </td>
     <td class="ltx_td ltx_align_center ltx_border_bb" id="A8.T8.4.6.2" style="padding-left:5.0pt;padding-right:5.0pt;">
      <span class="ltx_text ltx_font_bold" id="A8.T8.4.6.2.1" style="font-size:90%;">
       48.92
      </span>
     </td>
     <td class="ltx_td ltx_align_center ltx_border_bb" id="A8.T8.4.6.3" style="padding-left:5.0pt;padding-right:5.0pt;">
      <span class="ltx_text ltx_font_bold" id="A8.T8.4.6.3.1" style="font-size:90%;">
       25.54
      </span>
     </td>
     <td class="ltx_td ltx_align_center ltx_border_bb" id="A8.T8.4.6.4" style="padding-left:5.0pt;padding-right:5.0pt;">
      <span class="ltx_text ltx_font_bold" id="A8.T8.4.6.4.1" style="font-size:90%;">
       75.68
      </span>
     </td>
     <td class="ltx_td ltx_align_center ltx_border_bb" id="A8.T8.4.6.5" style="padding-left:5.0pt;padding-right:5.0pt;">
      <span class="ltx_text ltx_font_bold" id="A8.T8.4.6.5.1" style="font-size:90%;">
       42.50
      </span>
     </td>
    </tr>
   </table>
   <figcaption class="ltx_caption ltx_centering" style="font-size:90%;">
    <span class="ltx_tag ltx_tag_table">
     Table H:
    </span>
    <span class="ltx_text ltx_font_bold" id="A8.T8.9.1">
     Ablation results of LLM size.
    </span>
    LLaMA-13B achieves higher decision prediction accuracy and demonstrates more reasonable explanations.
   </figcaption>
  </figure>
  <figure class="ltx_table" id="A8.T9">
   <table class="ltx_tabular ltx_centering ltx_align_middle" id="A8.T9.2">
    <tr class="ltx_tr" id="A8.T9.2.3">
     <td class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" id="A8.T9.2.3.1" style="padding-left:11.0pt;padding-right:11.0pt;">
      <span class="ltx_text" id="A8.T9.2.3.1.1" style="font-size:90%;">
       Data Size
      </span>
     </td>
     <td class="ltx_td ltx_align_center ltx_border_tt" id="A8.T9.2.3.2" style="padding-left:11.0pt;padding-right:11.0pt;">
      <span class="ltx_text" id="A8.T9.2.3.2.1" style="font-size:90%;">
       35h
      </span>
     </td>
     <td class="ltx_td ltx_align_center ltx_border_tt" id="A8.T9.2.3.3" style="padding-left:11.0pt;padding-right:11.0pt;">
      <span class="ltx_text" id="A8.T9.2.3.3.1" style="font-size:90%;">
       70h
      </span>
     </td>
     <td class="ltx_td ltx_align_center ltx_border_tt" id="A8.T9.2.3.4" style="padding-left:11.0pt;padding-right:11.0pt;">
      <span class="ltx_text" id="A8.T9.2.3.4.1" style="font-size:90%;">
       140h
      </span>
     </td>
     <td class="ltx_td ltx_align_center ltx_border_tt" id="A8.T9.2.3.5" style="padding-left:11.0pt;padding-right:11.0pt;">
      <span class="ltx_text" id="A8.T9.2.3.5.1" style="font-size:90%;">
       280h
      </span>
     </td>
    </tr>
    <tr class="ltx_tr" id="A8.T9.2.2">
     <td class="ltx_td ltx_align_left ltx_border_bb ltx_border_r ltx_border_t" id="A8.T9.2.2.2" style="padding-left:11.0pt;padding-right:11.0pt;">
      <span class="ltx_text" id="A8.T9.2.2.2.1" style="font-size:90%;">
       Acc.
      </span>
      <math alttext="(\%)" class="ltx_math_unparsed" display="inline" id="A8.T9.1.1.1.m1.1">
       <semantics id="A8.T9.1.1.1.m1.1a">
        <mrow id="A8.T9.1.1.1.m1.1b">
         <mo id="A8.T9.1.1.1.m1.1.1" maxsize="90%" minsize="90%">
          (
         </mo>
         <mo id="A8.T9.1.1.1.m1.1.2" mathsize="90%">
          %
         </mo>
         <mo id="A8.T9.1.1.1.m1.1.3" maxsize="90%" minsize="90%">
          )
         </mo>
        </mrow>
        <annotation encoding="application/x-tex" id="A8.T9.1.1.1.m1.1c">
         (\%)
        </annotation>
       </semantics>
      </math>
      <span class="ltx_text" id="A8.T9.2.2.2.2" style="font-size:90%;">
      </span>
      <math alttext="\uparrow" class="ltx_Math" display="inline" id="A8.T9.2.2.2.m2.1">
       <semantics id="A8.T9.2.2.2.m2.1a">
        <mo id="A8.T9.2.2.2.m2.1.1" mathsize="90%" stretchy="false" xref="A8.T9.2.2.2.m2.1.1.cmml">
         ↑
        </mo>
        <annotation-xml encoding="MathML-Content" id="A8.T9.2.2.2.m2.1b">
         <ci id="A8.T9.2.2.2.m2.1.1.cmml" xref="A8.T9.2.2.2.m2.1.1">
          ↑
         </ci>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="A8.T9.2.2.2.m2.1c">
         \uparrow
        </annotation>
       </semantics>
      </math>
     </td>
     <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="A8.T9.2.2.3" style="padding-left:11.0pt;padding-right:11.0pt;">
      <span class="ltx_text" id="A8.T9.2.2.3.1" style="font-size:90%;">
       41.83
      </span>
     </td>
     <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="A8.T9.2.2.4" style="padding-left:11.0pt;padding-right:11.0pt;">
      <span class="ltx_text" id="A8.T9.2.2.4.1" style="font-size:90%;">
       45.16
      </span>
     </td>
     <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="A8.T9.2.2.5" style="padding-left:11.0pt;padding-right:11.0pt;">
      <span class="ltx_text" id="A8.T9.2.2.5.1" style="font-size:90%;">
       46.12
      </span>
     </td>
     <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="A8.T9.2.2.6" style="padding-left:11.0pt;padding-right:11.0pt;">
      <span class="ltx_text ltx_font_bold" id="A8.T9.2.2.6.1" style="font-size:90%;">
       47.83
      </span>
     </td>
    </tr>
   </table>
   <figcaption class="ltx_caption ltx_centering" style="font-size:90%;">
    <span class="ltx_tag ltx_tag_table">
     Table I:
    </span>
    <span class="ltx_text ltx_font_bold" id="A8.T9.7.1">
     Ablation results of training set size.
    </span>
    As the length of the training set increases, the decision prediction accuracy can gradually improve. We see that performance can be still enhanced by increasing the training set size. Hence, we plan to further expand the collection of training data.
   </figcaption>
  </figure>
  <div class="ltx_para" id="A8.p1">
   <p class="ltx_p" id="A8.p1.1">
    <span class="ltx_text" id="A8.p1.1.1" style="font-size:144%;">
     To explore the impact of various designs in our model, we undertook comprehensive ablation studies within the closed-loop evaluation framework. As indicated in Table
    </span>
    <a class="ltx_ref" href="#A8.T7" style="font-size:144%;" title="Table G ‣ Appendix H Closed Loop Ablation Studies ‣ DriveMLM: Aligning Multi-Modal Large Language Models with Behavioral Planning States for Autonomous Driving">
     <span class="ltx_text ltx_ref_tag">
      G
     </span>
    </a>
    <span class="ltx_text" id="A8.p1.1.2" style="font-size:144%;">
     , the incorporation of multi-view input images markedly enhances driving performance compared to only using front-view images. Our proposed Temporal QFormer can further improve the driving performance by a large margin. In our method, the integration of point clouds did not result in further gains, possibly due to the increased challenge of aligning more diverse modalities.
    </span>
   </p>
  </div>
 </section>
 <section class="ltx_appendix" id="A9">
  <h2 class="ltx_title ltx_title_appendix" style="font-size:144%;">
   <span class="ltx_tag ltx_tag_appendix">
    Appendix I
   </span>
   Ablation Experiments on Model and Data Scale
  </h2>
  <div class="ltx_para ltx_noindent" id="A9.p1">
   <p class="ltx_p" id="A9.p1.1">
    <span class="ltx_text ltx_font_bold" id="A9.p1.1.1" style="font-size:144%;">
     Large Language Model Scale.
    </span>
    <span class="ltx_text" id="A9.p1.1.2" style="font-size:144%;">
     We study how the parameter scale of large Language models (LLMs) influences the results of our method with our front-view model. Table
    </span>
    <a class="ltx_ref" href="#A8.T8" style="font-size:144%;" title="Table H ‣ Appendix H Closed Loop Ablation Studies ‣ DriveMLM: Aligning Multi-Modal Large Language Models with Behavioral Planning States for Autonomous Driving">
     <span class="ltx_text ltx_ref_tag">
      H
     </span>
    </a>
    <span class="ltx_text" id="A9.p1.1.3" style="font-size:144%;">
     shows our method achieves better performance with a larger model. However, the improvement of LLaMA-13B
    </span>
    <cite class="ltx_cite ltx_citemacro_cite">
     <span class="ltx_text" id="A9.p1.1.4.1" style="font-size:144%;">
      [
     </span>
     <a class="ltx_ref" href="#bib.bib64" title="">
      <span class="ltx_text" style="font-size:90%;">
       64
      </span>
     </a>
     <span class="ltx_text" id="A9.p1.1.5.2" style="font-size:144%;">
      ]
     </span>
    </cite>
    <span class="ltx_text" id="A9.p1.1.6" style="font-size:144%;">
     is limited, so we select LLaMA-7B for other experiments due to its lower operating efficiency and memory consumption.
    </span>
   </p>
  </div>
  <div class="ltx_para ltx_noindent" id="A9.p2">
   <p class="ltx_p" id="A9.p2.1">
    <span class="ltx_text ltx_font_bold" id="A9.p2.1.1" style="font-size:144%;">
     Training Set Scale.
    </span>
    <span class="ltx_text" id="A9.p2.1.2" style="font-size:144%;">
     We also study how the training data size influences the results of our method with our front-view model. Table
    </span>
    <a class="ltx_ref" href="#A8.T9" style="font-size:144%;" title="Table I ‣ Appendix H Closed Loop Ablation Studies ‣ DriveMLM: Aligning Multi-Modal Large Language Models with Behavioral Planning States for Autonomous Driving">
     <span class="ltx_text ltx_ref_tag">
      I
     </span>
    </a>
    <span class="ltx_text" id="A9.p2.1.3" style="font-size:144%;">
     shows the performance is still enhanced by increasing the training set size, which indicates that our method can benefit from the scaling laws. Hence, we will expand the collection of training data in the future.
    </span>
   </p>
  </div>
 </section>
 <section class="ltx_bibliography" id="bib">
  <h2 class="ltx_title ltx_title_bibliography" style="font-size:90%;">
   References
  </h2>
  <ul class="ltx_biblist">
   <li class="ltx_bibitem" id="bib.bib1">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib1.5.5.1" style="font-size:90%;">
      Alayrac et al. [2022]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib1.7.1" style="font-size:90%;">
      Jean-Baptiste Alayrac, Jeff Donahue, Pauline Luc, Antoine Miech, Iain Barr,
Yana Hasson, Karel Lenc, Arthur Mensch, Katherine Millican, Malcolm Reynolds,
et al.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib1.8.1" style="font-size:90%;">
      Flamingo: a visual language model for few-shot learning.
     </span>
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib1.9.1" style="font-size:90%;">
      Advances in Neural Information Processing Systems
     </em>
     <span class="ltx_text" id="bib.bib1.10.2" style="font-size:90%;">
      ,
35:23716–23736, 2022.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib2">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib2.5.5.1" style="font-size:90%;">
      Bai et al. [2023]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib2.7.1" style="font-size:90%;">
      Jinze Bai, Shuai Bai, Shusheng Yang, Shijie Wang, Sinan Tan, Peng Wang, Junyang
Lin, Chang Zhou, and Jingren Zhou.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib2.8.1" style="font-size:90%;">
      Qwen-vl: A versatile vision-language model for understanding,
localization, text reading, and beyond.
     </span>
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib2.9.1" style="font-size:90%;">
      arXiv preprint arXiv:2308.12966
     </em>
     <span class="ltx_text" id="bib.bib2.10.2" style="font-size:90%;">
      , 1(2):3,
2023.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib3">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib3.4.4.1" style="font-size:90%;">
      Baidu [2019]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib3.6.1" style="font-size:90%;">
      Baidu.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib3.7.1" style="font-size:90%;">
      Apollo auto.
     </span>
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/ApolloAuto/apollo" style="font-size:90%;" target="_blank" title="">
      https://github.com/ApolloAuto/apollo
     </a>
     <span class="ltx_text" id="bib.bib3.8.1" style="font-size:90%;">
      , 2019.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib4">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib4.4.4.1" style="font-size:90%;">
      Banerjee and Lavie [2005]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib4.6.1" style="font-size:90%;">
      Satanjeev Banerjee and Alon Lavie.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib4.7.1" style="font-size:90%;">
      Meteor: An automatic metric for mt evaluation with improved
correlation with human judgments.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib4.8.1" style="font-size:90%;">
      In
     </span>
     <em class="ltx_emph ltx_font_italic" id="bib.bib4.9.2" style="font-size:90%;">
      Proceedings of the acl workshop on intrinsic and extrinsic
evaluation measures for machine translation and/or summarization
     </em>
     <span class="ltx_text" id="bib.bib4.10.3" style="font-size:90%;">
      , pages
65–72, 2005.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib5">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib5.5.5.1" style="font-size:90%;">
      Brohan et al. [2022]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib5.7.1" style="font-size:90%;">
      Anthony Brohan, Noah Brown, Justice Carbajal, Yevgen Chebotar, Joseph Dabis,
Chelsea Finn, Keerthana Gopalakrishnan, Karol Hausman, Alex Herzog, Jasmine
Hsu, et al.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib5.8.1" style="font-size:90%;">
      Rt-1: Robotics transformer for real-world control at scale.
     </span>
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib5.9.1" style="font-size:90%;">
      arXiv preprint arXiv:2212.06817
     </em>
     <span class="ltx_text" id="bib.bib5.10.2" style="font-size:90%;">
      , 2022.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib6">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib6.5.5.1" style="font-size:90%;">
      Brohan et al. [2023]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib6.7.1" style="font-size:90%;">
      Anthony Brohan, Noah Brown, Justice Carbajal, Yevgen Chebotar, Xi Chen,
Krzysztof Choromanski, Tianli Ding, Danny Driess, Avinava Dubey, Chelsea
Finn, et al.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib6.8.1" style="font-size:90%;">
      Rt-2: Vision-language-action models transfer web knowledge to robotic
control.
     </span>
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib6.9.1" style="font-size:90%;">
      arXiv preprint arXiv:2307.15818
     </em>
     <span class="ltx_text" id="bib.bib6.10.2" style="font-size:90%;">
      , 2023.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib7">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib7.5.5.1" style="font-size:90%;">
      Brown et al. [2020]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib7.7.1" style="font-size:90%;">
      Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla
Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell,
et al.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib7.8.1" style="font-size:90%;">
      Language models are few-shot learners.
     </span>
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib7.9.1" style="font-size:90%;">
      Advances in neural information processing systems
     </em>
     <span class="ltx_text" id="bib.bib7.10.2" style="font-size:90%;">
      ,
33:1877–1901, 2020.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib8">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib8.5.5.1" style="font-size:90%;">
      Caesar et al. [2020]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib8.7.1" style="font-size:90%;">
      Holger Caesar, Varun Bankiti, Alex H Lang, Sourabh Vora, Venice Erin Liong,
Qiang Xu, Anush Krishnan, Yu Pan, Giancarlo Baldan, and Oscar Beijbom.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib8.8.1" style="font-size:90%;">
      nuscenes: A multimodal dataset for autonomous driving.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib8.9.1" style="font-size:90%;">
      In
     </span>
     <em class="ltx_emph ltx_font_italic" id="bib.bib8.10.2" style="font-size:90%;">
      Proceedings of the IEEE/CVF conference on computer vision
and pattern recognition
     </em>
     <span class="ltx_text" id="bib.bib8.11.3" style="font-size:90%;">
      , pages 11621–11631, 2020.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib9">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib9.4.4.1" style="font-size:90%;">
      Chen and Krähenbühl [2022]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib9.6.1" style="font-size:90%;">
      Dian Chen and Philipp Krähenbühl.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib9.7.1" style="font-size:90%;">
      Learning from all vehicles.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib9.8.1" style="font-size:90%;">
      In
     </span>
     <em class="ltx_emph ltx_font_italic" id="bib.bib9.9.2" style="font-size:90%;">
      Proceedings of the IEEE/CVF Conference on Computer Vision
and Pattern Recognition
     </em>
     <span class="ltx_text" id="bib.bib9.10.3" style="font-size:90%;">
      , pages 17222–17231, 2022.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib10">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib10.5.5.1" style="font-size:90%;">
      Chen et al. [2020]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib10.7.1" style="font-size:90%;">
      Dian Chen, Brady Zhou, Vladlen Koltun, and Philipp Krähenbühl.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib10.8.1" style="font-size:90%;">
      Learning by cheating.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib10.9.1" style="font-size:90%;">
      In
     </span>
     <em class="ltx_emph ltx_font_italic" id="bib.bib10.10.2" style="font-size:90%;">
      Conference on Robot Learning
     </em>
     <span class="ltx_text" id="bib.bib10.11.3" style="font-size:90%;">
      , pages 66–75. PMLR, 2020.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib11">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib11.5.5.1" style="font-size:90%;">
      Chen et al. [2021]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib11.7.1" style="font-size:90%;">
      Dian Chen, Vladlen Koltun, and Philipp Krähenbühl.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib11.8.1" style="font-size:90%;">
      Learning to drive from a world on rails.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib11.9.1" style="font-size:90%;">
      In
     </span>
     <em class="ltx_emph ltx_font_italic" id="bib.bib11.10.2" style="font-size:90%;">
      Proceedings of the IEEE/CVF International Conference on
Computer Vision
     </em>
     <span class="ltx_text" id="bib.bib11.11.3" style="font-size:90%;">
      , pages 15590–15599, 2021.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib12">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib12.5.5.1" style="font-size:90%;">
      Chen et al. [2023a]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib12.7.1" style="font-size:90%;">
      Keqin Chen, Zhao Zhang, Weili Zeng, Richong Zhang, Feng Zhu, and Rui Zhao.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib12.8.1" style="font-size:90%;">
      Shikra: Unleashing multimodal llm’s referential dialogue magic.
     </span>
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib12.9.1" style="font-size:90%;">
      arXiv preprint arXiv:2306.15195
     </em>
     <span class="ltx_text" id="bib.bib12.10.2" style="font-size:90%;">
      , 2023a.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib13">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib13.5.5.1" style="font-size:90%;">
      Chen et al. [2023b]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib13.7.1" style="font-size:90%;">
      Long Chen, Oleg Sinavski, Jan Hünermann, Alice Karnsund, Andrew James
Willmott, Danny Birch, Daniel Maund, and Jamie Shotton.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib13.8.1" style="font-size:90%;">
      Driving with llms: Fusing object-level vector modality for
explainable autonomous driving.
     </span>
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib13.9.1" style="font-size:90%;">
      arXiv preprint arXiv:2310.01957
     </em>
     <span class="ltx_text" id="bib.bib13.10.2" style="font-size:90%;">
      , 2023b.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib14">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib14.5.5.1" style="font-size:90%;">
      Chen et al. [2019]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib14.7.1" style="font-size:90%;">
      Shitao Chen, Zhiqiang Jian, Yuhao Huang, Yu Chen, Zhuoli Zhou, and Nanning
Zheng.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib14.8.1" style="font-size:90%;">
      Autonomous driving: cognitive construction and situation
understanding.
     </span>
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib14.9.1" style="font-size:90%;">
      Science China Information Sciences
     </em>
     <span class="ltx_text" id="bib.bib14.10.2" style="font-size:90%;">
      , 62:1–27, 2019.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib15">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib15.5.5.1" style="font-size:90%;">
      Chitta et al. [2022]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib15.7.1" style="font-size:90%;">
      Kashyap Chitta, Aditya Prakash, Bernhard Jaeger, Zehao Yu, Katrin Renz, and
Andreas Geiger.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib15.8.1" style="font-size:90%;">
      Transfuser: Imitation with transformer-based sensor fusion for
autonomous driving.
     </span>
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib15.9.1" style="font-size:90%;">
      IEEE Transactions on Pattern Analysis and Machine
Intelligence
     </em>
     <span class="ltx_text" id="bib.bib15.10.2" style="font-size:90%;">
      , 2022.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib16">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib16.4.4.1" style="font-size:90%;">
      Contributors [2023]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib16.6.1" style="font-size:90%;">
      DriveLM Contributors.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib16.7.1" style="font-size:90%;">
      Drivelm: Drive on language.
     </span>
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/OpenDriveLab/DriveLM" style="font-size:90%;" target="_blank" title="">
      https://github.com/OpenDriveLab/DriveLM
     </a>
     <span class="ltx_text" id="bib.bib16.8.1" style="font-size:90%;">
      , 2023.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib17">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib17.5.5.1" style="font-size:90%;">
      Dai et al. [2023]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib17.7.1" style="font-size:90%;">
      Wenliang Dai, Junnan Li, Dongxu Li, Anthony Meng Huat Tiong, Junqi Zhao,
Weisheng Wang, Boyang Li, Pascale Fung, and Steven Hoi.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib17.8.1" style="font-size:90%;">
      Instructblip: Towards general-purpose vision-language models with
instruction tuning.
     </span>
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib17.9.1" style="font-size:90%;">
      arXiv preprint arXiv:2305.06500
     </em>
     <span class="ltx_text" id="bib.bib17.10.2" style="font-size:90%;">
      , 2023.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib18">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib18.5.5.1" style="font-size:90%;">
      Dosovitskiy et al. [2017]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib18.7.1" style="font-size:90%;">
      Alexey Dosovitskiy, German Ros, Felipe Codevilla, Antonio Lopez, and Vladlen
Koltun.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib18.8.1" style="font-size:90%;">
      Carla: An open urban driving simulator.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib18.9.1" style="font-size:90%;">
      In
     </span>
     <em class="ltx_emph ltx_font_italic" id="bib.bib18.10.2" style="font-size:90%;">
      Conference on robot learning
     </em>
     <span class="ltx_text" id="bib.bib18.11.3" style="font-size:90%;">
      , pages 1–16. PMLR, 2017.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib19">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib19.5.5.1" style="font-size:90%;">
      Driess et al. [2023]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib19.7.1" style="font-size:90%;">
      Danny Driess, Fei Xia, Mehdi SM Sajjadi, Corey Lynch, Aakanksha Chowdhery,
Brian Ichter, Ayzaan Wahid, Jonathan Tompson, Quan Vuong, Tianhe Yu, et al.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib19.8.1" style="font-size:90%;">
      Palm-e: An embodied multimodal language model.
     </span>
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib19.9.1" style="font-size:90%;">
      arXiv preprint arXiv:2303.03378
     </em>
     <span class="ltx_text" id="bib.bib19.10.2" style="font-size:90%;">
      , 2023.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib20">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib20.5.5.1" style="font-size:90%;">
      Fang et al. [2023]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib20.7.1" style="font-size:90%;">
      Yuxin Fang, Wen Wang, Binhui Xie, Quan Sun, Ledell Wu, Xinggang Wang, Tiejun
Huang, Xinlong Wang, and Yue Cao.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib20.8.1" style="font-size:90%;">
      Eva: Exploring the limits of masked visual representation learning at
scale.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib20.9.1" style="font-size:90%;">
      In
     </span>
     <em class="ltx_emph ltx_font_italic" id="bib.bib20.10.2" style="font-size:90%;">
      Proceedings of the IEEE/CVF Conference on Computer Vision
and Pattern Recognition
     </em>
     <span class="ltx_text" id="bib.bib20.11.3" style="font-size:90%;">
      , pages 19358–19369, 2023.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib21">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib21.4.4.1" style="font-size:90%;">
      FONTANA [2021]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib21.6.1" style="font-size:90%;">
      FRANCESCO FONTANA.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib21.7.1" style="font-size:90%;">
      Self-driving cars and openpilot: a complete overview of the
framework, 2021.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib22">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib22.4.4.1" style="font-size:90%;">
      Foundation [2018]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib22.6.1" style="font-size:90%;">
      The Autoware Foundation.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib22.7.1" style="font-size:90%;">
      Autoware: Open-source software for urban autonomous driving.
     </span>
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/CPFL/Autoware" style="font-size:90%;" target="_blank" title="">
      https://github.com/CPFL/Autoware
     </a>
     <span class="ltx_text" id="bib.bib22.8.1" style="font-size:90%;">
      , 2018.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib23">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib23.5.5.1" style="font-size:90%;">
      Gao et al. [2023]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib23.7.1" style="font-size:90%;">
      Peng Gao, Jiaming Han, Renrui Zhang, Ziyi Lin, Shijie Geng, Aojun Zhou, Wei
Zhang, Pan Lu, Conghui He, Xiangyu Yue, et al.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib23.8.1" style="font-size:90%;">
      Llama-adapter v2: Parameter-efficient visual instruction model.
     </span>
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib23.9.1" style="font-size:90%;">
      arXiv preprint arXiv:2304.15010
     </em>
     <span class="ltx_text" id="bib.bib23.10.2" style="font-size:90%;">
      , 2023.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib24">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib24.5.5.1" style="font-size:90%;">
      Hong et al. [2023]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib24.7.1" style="font-size:90%;">
      Sirui Hong, Xiawu Zheng, Jonathan Chen, Yuheng Cheng, Ceyao Zhang, Zili Wang,
Steven Ka Shing Yau, Zijuan Lin, Liyang Zhou, Chenyu Ran, et al.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib24.8.1" style="font-size:90%;">
      Metagpt: Meta programming for multi-agent collaborative framework.
     </span>
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib24.9.1" style="font-size:90%;">
      arXiv preprint arXiv:2308.00352
     </em>
     <span class="ltx_text" id="bib.bib24.10.2" style="font-size:90%;">
      , 2023.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib25">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib25.5.5.1" style="font-size:90%;">
      Hu et al. [2023]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib25.7.1" style="font-size:90%;">
      Yihan Hu, Jiazhi Yang, Li Chen, Keyu Li, Chonghao Sima, Xizhou Zhu, Siqi Chai,
Senyao Du, Tianwei Lin, Wenhai Wang, et al.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib25.8.1" style="font-size:90%;">
      Planning-oriented autonomous driving.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib25.9.1" style="font-size:90%;">
      In
     </span>
     <em class="ltx_emph ltx_font_italic" id="bib.bib25.10.2" style="font-size:90%;">
      Proceedings of the IEEE/CVF Conference on Computer Vision
and Pattern Recognition
     </em>
     <span class="ltx_text" id="bib.bib25.11.3" style="font-size:90%;">
      , pages 17853–17862, 2023.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib26">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib26.5.5.1" style="font-size:90%;">
      Huang et al. [2023]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib26.7.1" style="font-size:90%;">
      Shaohan Huang, Li Dong, Wenhui Wang, Yaru Hao, Saksham Singhal, Shuming Ma,
Tengchao Lv, Lei Cui, Owais Khan Mohammed, Qiang Liu, et al.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib26.8.1" style="font-size:90%;">
      Language is not all you need: Aligning perception with language
models.
     </span>
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib26.9.1" style="font-size:90%;">
      arXiv preprint arXiv:2302.14045
     </em>
     <span class="ltx_text" id="bib.bib26.10.2" style="font-size:90%;">
      , 2023.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib27">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib27.5.5.1" style="font-size:90%;">
      Jia et al. [2023]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib27.7.1" style="font-size:90%;">
      Xiaosong Jia, Penghao Wu, Li Chen, Jiangwei Xie, Conghui He, Junchi Yan, and
Hongyang Li.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib27.8.1" style="font-size:90%;">
      Think twice before driving: Towards scalable decoders for end-to-end
autonomous driving.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib27.9.1" style="font-size:90%;">
      In
     </span>
     <em class="ltx_emph ltx_font_italic" id="bib.bib27.10.2" style="font-size:90%;">
      Proceedings of the IEEE/CVF Conference on Computer Vision
and Pattern Recognition
     </em>
     <span class="ltx_text" id="bib.bib27.11.3" style="font-size:90%;">
      , pages 21983–21994, 2023.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib28">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib28.5.5.1" style="font-size:90%;">
      Jiang et al. [2023]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib28.7.1" style="font-size:90%;">
      Bo Jiang, Shaoyu Chen, Qing Xu, Bencheng Liao, Jiajie Chen, Helong Zhou, Qian
Zhang, Wenyu Liu, Chang Huang, and Xinggang Wang.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib28.8.1" style="font-size:90%;">
      Vad: Vectorized scene representation for efficient autonomous
driving.
     </span>
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib28.9.1" style="font-size:90%;">
      arXiv preprint arXiv:2303.12077
     </em>
     <span class="ltx_text" id="bib.bib28.10.2" style="font-size:90%;">
      , 2023.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib29">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib29.5.5.1" style="font-size:90%;">
      Junqing et al. [2023]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib29.7.1" style="font-size:90%;">
      He Junqing, Pan Kunhao, Dong Xiaoqun, Song Zhuoyang, Liu Yibo, Liang Yuxin,
Wang Hao, Sun Qianguo, Zhang Songxin, Xie Zejian, et al.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib29.8.1" style="font-size:90%;">
      Never lost in the middle: Improving large language models via
attention strengthening question answering.
     </span>
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib29.9.1" style="font-size:90%;">
      arXiv preprint arXiv:2311.09198
     </em>
     <span class="ltx_text" id="bib.bib29.10.2" style="font-size:90%;">
      , 2023.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib30">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib30.5.5.1" style="font-size:90%;">
      Lai et al. [2023]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib30.7.1" style="font-size:90%;">
      Xin Lai, Zhuotao Tian, Yukang Chen, Yanwei Li, Yuhui Yuan, Shu Liu, and Jiaya
Jia.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib30.8.1" style="font-size:90%;">
      Lisa: Reasoning segmentation via large language model.
     </span>
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib30.9.1" style="font-size:90%;">
      arXiv preprint arXiv:2308.00692
     </em>
     <span class="ltx_text" id="bib.bib30.10.2" style="font-size:90%;">
      , 2023.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib31">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib31.5.5.1" style="font-size:90%;">
      Li et al. [2023a]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib31.7.1" style="font-size:90%;">
      Guohao Li, Hasan Abed Al Kader Hammoud, Hani Itani, Dmitrii Khizbullin, and
Bernard Ghanem.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib31.8.1" style="font-size:90%;">
      Camel: Communicative agents for” mind” exploration of large language
model society.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib31.9.1" style="font-size:90%;">
      In
     </span>
     <em class="ltx_emph ltx_font_italic" id="bib.bib31.10.2" style="font-size:90%;">
      Thirty-seventh Conference on Neural Information Processing
Systems
     </em>
     <span class="ltx_text" id="bib.bib31.11.3" style="font-size:90%;">
      , 2023a.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib32">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib32.5.5.1" style="font-size:90%;">
      Li et al. [2023b]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib32.7.1" style="font-size:90%;">
      Junnan Li, Dongxu Li, Silvio Savarese, and Steven Hoi.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib32.8.1" style="font-size:90%;">
      Blip-2: Bootstrapping language-image pre-training with frozen image
encoders and large language models.
     </span>
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib32.9.1" style="font-size:90%;">
      arXiv preprint arXiv:2301.12597
     </em>
     <span class="ltx_text" id="bib.bib32.10.2" style="font-size:90%;">
      , 2023b.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib33">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib33.5.5.1" style="font-size:90%;">
      Li et al. [2023c]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib33.7.1" style="font-size:90%;">
      KunChang Li, Yinan He, Yi Wang, Yizhuo Li, Wenhai Wang, Ping Luo, Yali Wang,
Limin Wang, and Yu Qiao.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib33.8.1" style="font-size:90%;">
      Videochat: Chat-centric video understanding.
     </span>
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib33.9.1" style="font-size:90%;">
      arXiv preprint arXiv:2305.06355
     </em>
     <span class="ltx_text" id="bib.bib33.10.2" style="font-size:90%;">
      , 2023c.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib34">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib34.5.5.1" style="font-size:90%;">
      Li et al. [2022]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib34.7.1" style="font-size:90%;">
      Zhiqi Li, Wenhai Wang, Hongyang Li, Enze Xie, Chonghao Sima, Tong Lu, Yu Qiao,
and Jifeng Dai.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib34.8.1" style="font-size:90%;">
      Bevformer: Learning bird’s-eye-view representation from
multi-camera images via spatiotemporal transformers.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib34.9.1" style="font-size:90%;">
      In
     </span>
     <em class="ltx_emph ltx_font_italic" id="bib.bib34.10.2" style="font-size:90%;">
      European conference on computer vision
     </em>
     <span class="ltx_text" id="bib.bib34.11.3" style="font-size:90%;">
      , pages 1–18.
Springer, 2022.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib35">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib35.5.5.1" style="font-size:90%;">
      Li et al. [2023d]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib35.7.1" style="font-size:90%;">
      Zhiqi Li, Zhiding Yu, David Austin, Mingsheng Fang, Shiyi Lan, Jan Kautz, and
Jose M Alvarez.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib35.8.1" style="font-size:90%;">
      Fb-occ: 3d occupancy prediction based on forward-backward view
transformation.
     </span>
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib35.9.1" style="font-size:90%;">
      arXiv preprint arXiv:2307.01492
     </em>
     <span class="ltx_text" id="bib.bib35.10.2" style="font-size:90%;">
      , 2023d.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib36">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib36.5.5.1" style="font-size:90%;">
      Liang et al. [2022]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib36.7.1" style="font-size:90%;">
      Tingting Liang, Hongwei Xie, Kaicheng Yu, Zhongyu Xia, Zhiwei Lin, Yongtao
Wang, Tao Tang, Bing Wang, and Zhi Tang.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib36.8.1" style="font-size:90%;">
      Bevfusion: A simple and robust lidar-camera fusion framework.
     </span>
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib36.9.1" style="font-size:90%;">
      Advances in Neural Information Processing Systems
     </em>
     <span class="ltx_text" id="bib.bib36.10.2" style="font-size:90%;">
      ,
35:10421–10434, 2022.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib37">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib37.5.5.1" style="font-size:90%;">
      Liu et al. [2023a]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib37.7.1" style="font-size:90%;">
      Haotian Liu, Chunyuan Li, Yuheng Li, and Yong Jae Lee.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib37.8.1" style="font-size:90%;">
      Improved baselines with visual instruction tuning.
     </span>
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib37.9.1" style="font-size:90%;">
      arXiv preprint arXiv:2310.03744
     </em>
     <span class="ltx_text" id="bib.bib37.10.2" style="font-size:90%;">
      , 2023a.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib38">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib38.5.5.1" style="font-size:90%;">
      Liu et al. [2023b]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib38.7.1" style="font-size:90%;">
      Haotian Liu, Chunyuan Li, Qingyang Wu, and Yong Jae Lee.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib38.8.1" style="font-size:90%;">
      Visual instruction tuning.
     </span>
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib38.9.1" style="font-size:90%;">
      arXiv preprint arXiv:2304.08485
     </em>
     <span class="ltx_text" id="bib.bib38.10.2" style="font-size:90%;">
      , 2023b.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib39">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib39.5.5.1" style="font-size:90%;">
      Liu et al. [2023c]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib39.7.1" style="font-size:90%;">
      Jiaqi Liu, Peng Hang, Jianqiang Wang, Jian Sun, et al.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib39.8.1" style="font-size:90%;">
      Mtd-gpt: A multi-task decision-making gpt model for autonomous
driving at unsignalized intersections.
     </span>
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib39.9.1" style="font-size:90%;">
      arXiv preprint arXiv:2307.16118
     </em>
     <span class="ltx_text" id="bib.bib39.10.2" style="font-size:90%;">
      , 2023c.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib40">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib40.5.5.1" style="font-size:90%;">
      Liu et al. [2023d]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib40.7.1" style="font-size:90%;">
      Zhaoyang Liu, Yinan He, Wenhai Wang, Weiyun Wang, Yi Wang, Shoufa Chen,
Qinglong Zhang, Yang Yang, Qingyun Li, Jiashuo Yu, et al.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib40.8.1" style="font-size:90%;">
      Internchat: Solving vision-centric tasks by interacting with chatbots
beyond language.
     </span>
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib40.9.1" style="font-size:90%;">
      arXiv preprint arXiv:2305.05662
     </em>
     <span class="ltx_text" id="bib.bib40.10.2" style="font-size:90%;">
      , 2023d.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib41">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib41.5.5.1" style="font-size:90%;">
      Liu et al. [2023e]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib41.7.1" style="font-size:90%;">
      Zhaoyang Liu, Zeqiang Lai, Zhangwei Gao, Erfei Cui, Xizhou Zhu, Lewei Lu,
Qifeng Chen, Yu Qiao, Jifeng Dai, and Wenhai Wang.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib41.8.1" style="font-size:90%;">
      Controlllm: Augment language models with tools by searching on
graphs.
     </span>
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib41.9.1" style="font-size:90%;">
      arXiv preprint arXiv:2310.17796
     </em>
     <span class="ltx_text" id="bib.bib41.10.2" style="font-size:90%;">
      , 2023e.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib42">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib42.5.5.1" style="font-size:90%;">
      Mao et al. [2021]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib42.7.1" style="font-size:90%;">
      Jiageng Mao, Minzhe Niu, Chenhan Jiang, Hanxue Liang, Jingheng Chen, Xiaodan
Liang, Yamin Li, Chaoqiang Ye, Wei Zhang, Zhenguo Li, et al.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib42.8.1" style="font-size:90%;">
      One million scenes for autonomous driving: Once dataset.
     </span>
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib42.9.1" style="font-size:90%;">
      arXiv preprint arXiv:2106.11037
     </em>
     <span class="ltx_text" id="bib.bib42.10.2" style="font-size:90%;">
      , 2021.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib43">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib43.5.5.1" style="font-size:90%;">
      Mao et al. [2023]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib43.7.1" style="font-size:90%;">
      Jiageng Mao, Yuxi Qian, Hang Zhao, and Yue Wang.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib43.8.1" style="font-size:90%;">
      Gpt-driver: Learning to drive with gpt.
     </span>
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib43.9.1" style="font-size:90%;">
      arXiv preprint arXiv:2310.01415
     </em>
     <span class="ltx_text" id="bib.bib43.10.2" style="font-size:90%;">
      , 2023.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib44">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib44.5.5.1" style="font-size:90%;">
      Movva et al. [2023]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib44.7.1" style="font-size:90%;">
      Rajiv Movva, Sidhika Balachandar, Kenny Peng, Gabriel Agostini, Nikhil Garg,
and Emma Pierson.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib44.8.1" style="font-size:90%;">
      Large language models shape and are shaped by society: A survey of
arxiv publication patterns.
     </span>
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib44.9.1" style="font-size:90%;">
      arXiv preprint arXiv:2307.10700
     </em>
     <span class="ltx_text" id="bib.bib44.10.2" style="font-size:90%;">
      , 2023.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib45">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib45.5.5.1" style="font-size:90%;">
      Mu et al. [2023]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib45.7.1" style="font-size:90%;">
      Yao Mu, Qinglong Zhang, Mengkang Hu, Wenhai Wang, Mingyu Ding, Jun Jin, Bin
Wang, Jifeng Dai, Yu Qiao, and Ping Luo.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib45.8.1" style="font-size:90%;">
      Embodiedgpt: Vision-language pre-training via embodied chain of
thought.
     </span>
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib45.9.1" style="font-size:90%;">
      arXiv preprint arXiv:2305.15021
     </em>
     <span class="ltx_text" id="bib.bib45.10.2" style="font-size:90%;">
      , 2023.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib46">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib46.4.4.1" style="font-size:90%;">
      OpenAI [2023]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib46.6.1" style="font-size:90%;">
      OpenAI.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib46.7.1" style="font-size:90%;">
      GPT-4 Technical Report, 2023.
     </span>
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://cdn.openai.com/papers/gpt-4.pdf" style="font-size:90%;" target="_blank" title="">
      https://cdn.openai.com/papers/gpt-4.pdf
     </a>
     <span class="ltx_text" id="bib.bib46.8.1" style="font-size:90%;">
      .
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib47">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib47.5.5.1" style="font-size:90%;">
      Ouyang et al. [2022]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib47.7.1" style="font-size:90%;">
      Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela
Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib47.8.1" style="font-size:90%;">
      Training language models to follow instructions with human feedback.
     </span>
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib47.9.1" style="font-size:90%;">
      Advances in Neural Information Processing Systems
     </em>
     <span class="ltx_text" id="bib.bib47.10.2" style="font-size:90%;">
      ,
35:27730–27744, 2022.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib48">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib48.5.5.1" style="font-size:90%;">
      Padalkar et al. [2023]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib48.7.1" style="font-size:90%;">
      Abhishek Padalkar, Acorn Pooley, Ajinkya Jain, Alex Bewley, Alex Herzog, Alex
Irpan, Alexander Khazatsky, Anant Rai, Anikait Singh, Anthony Brohan, et al.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib48.8.1" style="font-size:90%;">
      Open x-embodiment: Robotic learning datasets and rt-x models.
     </span>
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib48.9.1" style="font-size:90%;">
      arXiv preprint arXiv:2310.08864
     </em>
     <span class="ltx_text" id="bib.bib48.10.2" style="font-size:90%;">
      , 2023.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib49">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib49.5.5.1" style="font-size:90%;">
      Papineni et al. [2002]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib49.7.1" style="font-size:90%;">
      Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib49.8.1" style="font-size:90%;">
      Bleu: a method for automatic evaluation of machine translation.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib49.9.1" style="font-size:90%;">
      In
     </span>
     <em class="ltx_emph ltx_font_italic" id="bib.bib49.10.2" style="font-size:90%;">
      Proceedings of the 40th annual meeting of the Association
for Computational Linguistics
     </em>
     <span class="ltx_text" id="bib.bib49.11.3" style="font-size:90%;">
      , pages 311–318, 2002.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib50">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib50.5.5.1" style="font-size:90%;">
      Park et al. [2023]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib50.7.1" style="font-size:90%;">
      Joon Sung Park, Joseph C O’Brien, Carrie J Cai, Meredith Ringel Morris, Percy
Liang, and Michael S Bernstein.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib50.8.1" style="font-size:90%;">
      Generative agents: Interactive simulacra of human behavior.
     </span>
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib50.9.1" style="font-size:90%;">
      arXiv preprint arXiv:2304.03442
     </em>
     <span class="ltx_text" id="bib.bib50.10.2" style="font-size:90%;">
      , 2023.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib51">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib51.5.5.1" style="font-size:90%;">
      Peng et al. [2023]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib51.7.1" style="font-size:90%;">
      Zhiliang Peng, Wenhui Wang, Li Dong, Yaru Hao, Shaohan Huang, Shuming Ma, and
Furu Wei.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib51.8.1" style="font-size:90%;">
      Kosmos-2: Grounding multimodal large language models to the world.
     </span>
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib51.9.1" style="font-size:90%;">
      arXiv preprint arXiv:2306.14824
     </em>
     <span class="ltx_text" id="bib.bib51.10.2" style="font-size:90%;">
      , 2023.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib52">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib52.5.5.1" style="font-size:90%;">
      Qian et al. [2023]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib52.7.1" style="font-size:90%;">
      Tianwen Qian, Jingjing Chen, Linhai Zhuo, Yang Jiao, and Yu-Gang Jiang.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib52.8.1" style="font-size:90%;">
      Nuscenes-qa: A multi-modal visual question answering benchmark for
autonomous driving scenario.
     </span>
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib52.9.1" style="font-size:90%;">
      arXiv preprint arXiv:2305.14836
     </em>
     <span class="ltx_text" id="bib.bib52.10.2" style="font-size:90%;">
      , 2023.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib53">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib53.5.5.1" style="font-size:90%;">
      Radford et al. [2018]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib53.7.1" style="font-size:90%;">
      Alec Radford, Karthik Narasimhan, Tim Salimans, Ilya Sutskever, et al.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib53.8.1" style="font-size:90%;">
      Improving language understanding by generative pre-training.
     </span>
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib53.9.1" style="font-size:90%;">
      OpenAI
     </em>
     <span class="ltx_text" id="bib.bib53.10.2" style="font-size:90%;">
      , 2018.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib54">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib54.5.5.1" style="font-size:90%;">
      Radford et al. [2019]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib54.7.1" style="font-size:90%;">
      Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya
Sutskever, et al.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib54.8.1" style="font-size:90%;">
      Language models are unsupervised multitask learners.
     </span>
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib54.9.1" style="font-size:90%;">
      OpenAI blog
     </em>
     <span class="ltx_text" id="bib.bib54.10.2" style="font-size:90%;">
      , 1(8):9, 2019.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib55">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib55.5.5.1" style="font-size:90%;">
      Sachdeva et al. [2023]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib55.7.1" style="font-size:90%;">
      Enna Sachdeva, Nakul Agarwal, Suhas Chundi, Sean Roelofs, Jiachen Li, Behzad
Dariush, Chiho Choi, and Mykel Kochenderfer.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib55.8.1" style="font-size:90%;">
      Rank2tell: A multimodal driving dataset for joint importance ranking
and reasoning.
     </span>
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib55.9.1" style="font-size:90%;">
      arXiv preprint arXiv:2309.06597
     </em>
     <span class="ltx_text" id="bib.bib55.10.2" style="font-size:90%;">
      , 2023.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib56">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib56.5.5.1" style="font-size:90%;">
      Sha et al. [2023]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib56.7.1" style="font-size:90%;">
      Hao Sha, Yao Mu, Yuxuan Jiang, Li Chen, Chenfeng Xu, Ping Luo, Shengbo Eben Li,
Masayoshi Tomizuka, Wei Zhan, and Mingyu Ding.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib56.8.1" style="font-size:90%;">
      Languagempc: Large language models as decision makers for autonomous
driving.
     </span>
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib56.9.1" style="font-size:90%;">
      arXiv preprint arXiv:2310.03026
     </em>
     <span class="ltx_text" id="bib.bib56.10.2" style="font-size:90%;">
      , 2023.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib57">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib57.5.5.1" style="font-size:90%;">
      Shao et al. [2023a]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib57.7.1" style="font-size:90%;">
      Hao Shao, Letian Wang, Ruobing Chen, Hongsheng Li, and Yu Liu.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib57.8.1" style="font-size:90%;">
      Safety-enhanced autonomous driving using interpretable sensor fusion
transformer.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib57.9.1" style="font-size:90%;">
      In
     </span>
     <em class="ltx_emph ltx_font_italic" id="bib.bib57.10.2" style="font-size:90%;">
      Conference on Robot Learning
     </em>
     <span class="ltx_text" id="bib.bib57.11.3" style="font-size:90%;">
      , pages 726–737. PMLR,
2023a.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib58">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib58.5.5.1" style="font-size:90%;">
      Shao et al. [2023b]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib58.7.1" style="font-size:90%;">
      Hao Shao, Letian Wang, Ruobing Chen, Steven L Waslander, Hongsheng Li, and Yu
Liu.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib58.8.1" style="font-size:90%;">
      Reasonnet: End-to-end driving with temporal and global reasoning.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib58.9.1" style="font-size:90%;">
      In
     </span>
     <em class="ltx_emph ltx_font_italic" id="bib.bib58.10.2" style="font-size:90%;">
      Proceedings of the IEEE/CVF Conference on Computer Vision
and Pattern Recognition
     </em>
     <span class="ltx_text" id="bib.bib58.11.3" style="font-size:90%;">
      , pages 13723–13733, 2023b.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib59">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib59.5.5.1" style="font-size:90%;">
      Shen et al. [2023]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib59.7.1" style="font-size:90%;">
      Yongliang Shen, Kaitao Song, Xu Tan, Dongsheng Li, Weiming Lu, and Yueting
Zhuang.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib59.8.1" style="font-size:90%;">
      Hugginggpt: Solving ai tasks with chatgpt and its friends in
huggingface.
     </span>
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib59.9.1" style="font-size:90%;">
      arXiv preprint arXiv:2303.17580
     </em>
     <span class="ltx_text" id="bib.bib59.10.2" style="font-size:90%;">
      , 2023.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib60">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib60.5.5.1" style="font-size:90%;">
      Shi et al. [2023]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib60.7.1" style="font-size:90%;">
      Yining Shi, Kun Jiang, Jiusi Li, Junze Wen, Zelin Qian, Mengmeng Yang, Ke Wang,
and Diange Yang.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib60.8.1" style="font-size:90%;">
      Grid-centric traffic scenario perception for autonomous driving: A
comprehensive review.
     </span>
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib60.9.1" style="font-size:90%;">
      arXiv preprint arXiv:2303.01212
     </em>
     <span class="ltx_text" id="bib.bib60.10.2" style="font-size:90%;">
      , 2023.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib61">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib61.4.4.1" style="font-size:90%;">
      Singh and Bankiti [2023]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib61.6.1" style="font-size:90%;">
      Apoorv Singh and Varun Bankiti.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib61.7.1" style="font-size:90%;">
      Surround-view vision-based 3d detection for autonomous driving: A
survey.
     </span>
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib61.8.1" style="font-size:90%;">
      arXiv preprint arXiv:2302.06650
     </em>
     <span class="ltx_text" id="bib.bib61.9.2" style="font-size:90%;">
      , 2023.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib62">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib62.5.5.1" style="font-size:90%;">
      Surís et al. [2023]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib62.7.1" style="font-size:90%;">
      Dídac Surís, Sachit Menon, and Carl Vondrick.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib62.8.1" style="font-size:90%;">
      Vipergpt: Visual inference via python execution for reasoning.
     </span>
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib62.9.1" style="font-size:90%;">
      arXiv preprint arXiv:2303.08128
     </em>
     <span class="ltx_text" id="bib.bib62.10.2" style="font-size:90%;">
      , 2023.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib63">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib63.5.5.1" style="font-size:90%;">
      Tong et al. [2023]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib63.7.1" style="font-size:90%;">
      Wenwen Tong, Chonghao Sima, Tai Wang, Li Chen, Silei Wu, Hanming Deng, Yi Gu,
Lewei Lu, Ping Luo, Dahua Lin, et al.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib63.8.1" style="font-size:90%;">
      Scene as occupancy.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib63.9.1" style="font-size:90%;">
      In
     </span>
     <em class="ltx_emph ltx_font_italic" id="bib.bib63.10.2" style="font-size:90%;">
      Proceedings of the IEEE/CVF International Conference on
Computer Vision
     </em>
     <span class="ltx_text" id="bib.bib63.11.3" style="font-size:90%;">
      , pages 8406–8415, 2023.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib64">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib64.5.5.1" style="font-size:90%;">
      Touvron et al. [2023]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib64.7.1" style="font-size:90%;">
      Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne
Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric
Hambro, Faisal Azhar, et al.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib64.8.1" style="font-size:90%;">
      Llama: Open and efficient foundation language models.
     </span>
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib64.9.1" style="font-size:90%;">
      arXiv preprint arXiv:2302.13971
     </em>
     <span class="ltx_text" id="bib.bib64.10.2" style="font-size:90%;">
      , 2023.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib65">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib65.5.5.1" style="font-size:90%;">
      Vedantam et al. [2015]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib65.7.1" style="font-size:90%;">
      Ramakrishna Vedantam, C Lawrence Zitnick, and Devi Parikh.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib65.8.1" style="font-size:90%;">
      Cider: Consensus-based image description evaluation.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib65.9.1" style="font-size:90%;">
      In
     </span>
     <em class="ltx_emph ltx_font_italic" id="bib.bib65.10.2" style="font-size:90%;">
      Proceedings of the IEEE conference on computer vision and
pattern recognition
     </em>
     <span class="ltx_text" id="bib.bib65.11.3" style="font-size:90%;">
      , pages 4566–4575, 2015.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib66">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib66.5.5.1" style="font-size:90%;">
      Vinitsky et al. [2022]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib66.7.1" style="font-size:90%;">
      Eugene Vinitsky, Nathan Lichtlé, Xiaomeng Yang, Brandon Amos, and Jakob
Foerster.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib66.8.1" style="font-size:90%;">
      Nocturne: a scalable driving benchmark for bringing multi-agent
learning one step closer to the real world.
     </span>
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib66.9.1" style="font-size:90%;">
      Advances in Neural Information Processing Systems
     </em>
     <span class="ltx_text" id="bib.bib66.10.2" style="font-size:90%;">
      ,
35:3962–3974, 2022.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib67">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib67.5.5.1" style="font-size:90%;">
      Wang et al. [2023]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib67.7.1" style="font-size:90%;">
      Wenhai Wang, Zhe Chen, Xiaokang Chen, Jiannan Wu, Xizhou Zhu, Gang Zeng, Ping
Luo, Tong Lu, Jie Zhou, Yu Qiao, et al.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib67.8.1" style="font-size:90%;">
      Visionllm: Large language model is also an open-ended decoder for
vision-centric tasks.
     </span>
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib67.9.1" style="font-size:90%;">
      arXiv preprint arXiv:2305.11175
     </em>
     <span class="ltx_text" id="bib.bib67.10.2" style="font-size:90%;">
      , 2023.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib68">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib68.5.5.1" style="font-size:90%;">
      Wen et al. [2023]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib68.7.1" style="font-size:90%;">
      Licheng Wen, Daocheng Fu, Xin Li, Xinyu Cai, Tao Ma, Pinlong Cai, Min Dou,
Botian Shi, Liang He, and Yu Qiao.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib68.8.1" style="font-size:90%;">
      Dilu: A knowledge-driven approach to autonomous driving with large
language models.
     </span>
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib68.9.1" style="font-size:90%;">
      arXiv preprint arXiv:2309.16292
     </em>
     <span class="ltx_text" id="bib.bib68.10.2" style="font-size:90%;">
      , 2023.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib69">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib69.5.5.1" style="font-size:90%;">
      Wu et al. [2023a]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib69.7.1" style="font-size:90%;">
      Chenfei Wu, Shengming Yin, Weizhen Qi, Xiaodong Wang, Zecheng Tang, and Nan
Duan.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib69.8.1" style="font-size:90%;">
      Visual chatgpt: Talking, drawing and editing with visual foundation
models.
     </span>
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib69.9.1" style="font-size:90%;">
      arXiv preprint arXiv:2303.04671
     </em>
     <span class="ltx_text" id="bib.bib69.10.2" style="font-size:90%;">
      , 2023a.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib70">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib70.5.5.1" style="font-size:90%;">
      Wu et al. [2023b]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib70.7.1" style="font-size:90%;">
      Dongming Wu, Wencheng Han, Tiancai Wang, Yingfei Liu, Xiangyu Zhang, and
Jianbing Shen.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib70.8.1" style="font-size:90%;">
      Language prompt for autonomous driving.
     </span>
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib70.9.1" style="font-size:90%;">
      arXiv preprint arXiv:2309.04379
     </em>
     <span class="ltx_text" id="bib.bib70.10.2" style="font-size:90%;">
      , 2023b.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib71">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib71.5.5.1" style="font-size:90%;">
      Wu et al. [2023c]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib71.7.1" style="font-size:90%;">
      Shengqiong Wu, Hao Fei, Leigang Qu, Wei Ji, and Tat-Seng Chua.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib71.8.1" style="font-size:90%;">
      Next-gpt: Any-to-any multimodal llm.
     </span>
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib71.9.1" style="font-size:90%;">
      arXiv preprint arXiv:2309.05519
     </em>
     <span class="ltx_text" id="bib.bib71.10.2" style="font-size:90%;">
      , 2023c.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib72">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib72.5.5.1" style="font-size:90%;">
      Xu et al. [2023]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib72.7.1" style="font-size:90%;">
      Zhenhua Xu, Yujia Zhang, Enze Xie, Zhen Zhao, Yong Guo, Kenneth KY Wong,
Zhenguo Li, and Hengshuang Zhao.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib72.8.1" style="font-size:90%;">
      Drivegpt4: Interpretable end-to-end autonomous driving via large
language model.
     </span>
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib72.9.1" style="font-size:90%;">
      arXiv preprint arXiv:2310.01412
     </em>
     <span class="ltx_text" id="bib.bib72.10.2" style="font-size:90%;">
      , 2023.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib73">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib73.5.5.1" style="font-size:90%;">
      Yang et al. [2023a]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib73.7.1" style="font-size:90%;">
      Chenyu Yang, Yuntao Chen, Hao Tian, Chenxin Tao, Xizhou Zhu, Zhaoxiang Zhang,
Gao Huang, Hongyang Li, Yu Qiao, Lewei Lu, et al.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib73.8.1" style="font-size:90%;">
      Bevformer v2: Adapting modern image backbones to bird’s-eye-view
recognition via perspective supervision.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib73.9.1" style="font-size:90%;">
      In
     </span>
     <em class="ltx_emph ltx_font_italic" id="bib.bib73.10.2" style="font-size:90%;">
      Proceedings of the IEEE/CVF Conference on Computer Vision
and Pattern Recognition
     </em>
     <span class="ltx_text" id="bib.bib73.11.3" style="font-size:90%;">
      , pages 17830–17839, 2023a.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib74">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib74.5.5.1" style="font-size:90%;">
      Yang et al. [2023b]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib74.7.1" style="font-size:90%;">
      Honghui Yang, Tong He, Jiaheng Liu, Hua Chen, Boxi Wu, Binbin Lin, Xiaofei He,
and Wanli Ouyang.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib74.8.1" style="font-size:90%;">
      Gd-mae: generative decoder for mae pre-training on lidar point
clouds.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib74.9.1" style="font-size:90%;">
      In
     </span>
     <em class="ltx_emph ltx_font_italic" id="bib.bib74.10.2" style="font-size:90%;">
      Proceedings of the IEEE/CVF Conference on Computer Vision
and Pattern Recognition
     </em>
     <span class="ltx_text" id="bib.bib74.11.3" style="font-size:90%;">
      , pages 9403–9414, 2023b.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib75">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib75.5.5.1" style="font-size:90%;">
      Yang et al. [2023c]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib75.7.1" style="font-size:90%;">
      Hui Yang, Sifu Yue, and Yunzhong He.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib75.8.1" style="font-size:90%;">
      Auto-gpt for online decision making: Benchmarks and additional
opinions.
     </span>
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib75.9.1" style="font-size:90%;">
      arXiv preprint arXiv:2306.02224
     </em>
     <span class="ltx_text" id="bib.bib75.10.2" style="font-size:90%;">
      , 2023c.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib76">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib76.5.5.1" style="font-size:90%;">
      Yang et al. [2023d]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib76.7.1" style="font-size:90%;">
      Rui Yang, Lin Song, Yanwei Li, Sijie Zhao, Yixiao Ge, Xiu Li, and Ying Shan.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib76.8.1" style="font-size:90%;">
      Gpt4tools: Teaching large language model to use tools via
self-instruction.
     </span>
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib76.9.1" style="font-size:90%;">
      arXiv preprint arXiv:2305.18752
     </em>
     <span class="ltx_text" id="bib.bib76.10.2" style="font-size:90%;">
      , 2023d.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib77">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib77.5.5.1" style="font-size:90%;">
      Yang et al. [2023e]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib77.7.1" style="font-size:90%;">
      Zhengyuan Yang, Linjie Li, Jianfeng Wang, Kevin Lin, Ehsan Azarnasab, Faisal
Ahmed, Zicheng Liu, Ce Liu, Michael Zeng, and Lijuan Wang.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib77.8.1" style="font-size:90%;">
      Mm-react: Prompting chatgpt for multimodal reasoning and action.
     </span>
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib77.9.1" style="font-size:90%;">
      arXiv preprint arXiv:2303.11381
     </em>
     <span class="ltx_text" id="bib.bib77.10.2" style="font-size:90%;">
      , 2023e.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib78">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib78.5.5.1" style="font-size:90%;">
      Ye et al. [2023]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib78.7.1" style="font-size:90%;">
      Qinghao Ye, Haiyang Xu, Guohai Xu, Jiabo Ye, Ming Yan, Yiyang Zhou, Junyang
Wang, Anwen Hu, Pengcheng Shi, Yaya Shi, et al.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib78.8.1" style="font-size:90%;">
      mplug-owl: Modularization empowers large language models with
multimodality.
     </span>
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib78.9.1" style="font-size:90%;">
      arXiv preprint arXiv:2304.14178
     </em>
     <span class="ltx_text" id="bib.bib78.10.2" style="font-size:90%;">
      , 2023.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib79">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib79.5.5.1" style="font-size:90%;">
      Zhang et al. [2023a]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib79.7.1" style="font-size:90%;">
      Hang Zhang, Xin Li, and Lidong Bing.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib79.8.1" style="font-size:90%;">
      Video-llama: An instruction-tuned audio-visual language model for
video understanding.
     </span>
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib79.9.1" style="font-size:90%;">
      arXiv preprint arXiv:2306.02858
     </em>
     <span class="ltx_text" id="bib.bib79.10.2" style="font-size:90%;">
      , 2023a.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib80">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib80.5.5.1" style="font-size:90%;">
      Zhang et al. [2023b]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib80.7.1" style="font-size:90%;">
      Shilong Zhang, Peize Sun, Shoufa Chen, Min Xiao, Wenqi Shao, Wenwei Zhang, Kai
Chen, and Ping Luo.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib80.8.1" style="font-size:90%;">
      Gpt4roi: Instruction tuning large language model on
region-of-interest.
     </span>
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib80.9.1" style="font-size:90%;">
      arXiv preprint arXiv:2307.03601
     </em>
     <span class="ltx_text" id="bib.bib80.10.2" style="font-size:90%;">
      , 2023b.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib81">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib81.5.5.1" style="font-size:90%;">
      Zhang et al. [2021]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib81.7.1" style="font-size:90%;">
      Zhejun Zhang, Alexander Liniger, Dengxin Dai, Fisher Yu, and Luc Van Gool.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib81.8.1" style="font-size:90%;">
      End-to-end urban driving by imitating a reinforcement learning coach.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib81.9.1" style="font-size:90%;">
      In
     </span>
     <em class="ltx_emph ltx_font_italic" id="bib.bib81.10.2" style="font-size:90%;">
      Proceedings of the IEEE/CVF international conference on
computer vision
     </em>
     <span class="ltx_text" id="bib.bib81.11.3" style="font-size:90%;">
      , pages 15222–15232, 2021.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib82">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib82.5.5.1" style="font-size:90%;">
      Zhou et al. [2020]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib82.7.1" style="font-size:90%;">
      Ming Zhou, Jun Luo, Julian Villella, Yaodong Yang, David Rusu, Jiayu Miao,
Weinan Zhang, Montgomery Alban, Iman Fadakar, Zheng Chen, et al.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib82.8.1" style="font-size:90%;">
      Smarts: Scalable multi-agent reinforcement learning training school
for autonomous driving.
     </span>
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib82.9.1" style="font-size:90%;">
      arXiv preprint arXiv:2010.09776
     </em>
     <span class="ltx_text" id="bib.bib82.10.2" style="font-size:90%;">
      , 2020.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib83">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib83.5.5.1" style="font-size:90%;">
      Zhu et al. [2023]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib83.7.1" style="font-size:90%;">
      Deyao Zhu, Jun Chen, Xiaoqian Shen, Xiang Li, and Mohamed Elhoseiny.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib83.8.1" style="font-size:90%;">
      Minigpt-4: Enhancing vision-language understanding with advanced
large language models.
     </span>
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib83.9.1" style="font-size:90%;">
      arXiv preprint arXiv:2304.10592
     </em>
     <span class="ltx_text" id="bib.bib83.10.2" style="font-size:90%;">
      , 2023.
     </span>
    </span>
   </li>
  </ul>
 </section>
 <div class="ltx_pagination ltx_role_newpage">
 </div>
</article>
