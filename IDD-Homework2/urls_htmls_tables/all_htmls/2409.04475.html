<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Revolutionizing Database Q&amp;A with Large Language Models: Comprehensive Benchmark and Evaluation</title>
<!--Generated on Thu Sep  5 13:44:41 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2409.04475v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#S1" title="In Revolutionizing Database Q&amp;A with Large Language Models: Comprehensive Benchmark and Evaluation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#S2" title="In Revolutionizing Database Q&amp;A with Large Language Models: Comprehensive Benchmark and Evaluation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Related Work</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#S2.SS1" title="In 2. Related Work ‣ Revolutionizing Database Q&amp;A with Large Language Models: Comprehensive Benchmark and Evaluation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>Q<span class="ltx_text" style="font-size:90%;">&amp;</span>A by Large Language Models</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#S2.SS2" title="In 2. Related Work ‣ Revolutionizing Database Q&amp;A with Large Language Models: Comprehensive Benchmark and Evaluation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>Large Language Models for Database</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#S3" title="In Revolutionizing Database Q&amp;A with Large Language Models: Comprehensive Benchmark and Evaluation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span><span class="ltx_text ltx_font_bold ltx_font_italic">DQA</span> Dataset Generation</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#S3.SS1" title="In 3. DQA Dataset Generation ‣ Revolutionizing Database Q&amp;A with Large Language Models: Comprehensive Benchmark and Evaluation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>General DB Q<span class="ltx_text" style="font-size:90%;">&amp;</span>A</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#S3.SS2" title="In 3. DQA Dataset Generation ‣ Revolutionizing Database Q&amp;A with Large Language Models: Comprehensive Benchmark and Evaluation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Product-Specific Q<span class="ltx_text" style="font-size:90%;">&amp;</span>A</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#S3.SS3" title="In 3.2. Product-Specific Q&amp;A ‣ 3. DQA Dataset Generation ‣ Revolutionizing Database Q&amp;A with Large Language Models: Comprehensive Benchmark and Evaluation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text" style="font-size:90%;">3.3</span> </span><span class="ltx_text" style="font-size:90%;">Instance-Specific Q&amp;A</span></span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#S4" title="In 3.3. Instance-Specific Q&amp;A ‣ 3.2. Product-Specific Q&amp;A ‣ 3. DQA Dataset Generation ‣ Revolutionizing Database Q&amp;A with Large Language Models: Comprehensive Benchmark and Evaluation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text" style="font-size:90%;">4</span> </span><span class="ltx_text ltx_font_bold ltx_font_italic" style="font-size:90%;">DQA</span><span class="ltx_text" style="font-size:90%;"> Testbed</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#S4.SS1" title="In 4. DQA Testbed ‣ 3.3. Instance-Specific Q&amp;A ‣ 3.2. Product-Specific Q&amp;A ‣ 3. DQA Dataset Generation ‣ Revolutionizing Database Q&amp;A with Large Language Models: Comprehensive Benchmark and Evaluation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text" style="font-size:90%;">4.1</span> </span><span class="ltx_text" style="font-size:90%;">Pre-training and Fine-tuning</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#S4.SS2" title="In 4. DQA Testbed ‣ 3.3. Instance-Specific Q&amp;A ‣ 3.2. Product-Specific Q&amp;A ‣ 3. DQA Dataset Generation ‣ Revolutionizing Database Q&amp;A with Large Language Models: Comprehensive Benchmark and Evaluation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text" style="font-size:90%;">4.2</span> </span><span class="ltx_text" style="font-size:90%;">Question Classification Routing</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#S4.SS3" title="In 4. DQA Testbed ‣ 3.3. Instance-Specific Q&amp;A ‣ 3.2. Product-Specific Q&amp;A ‣ 3. DQA Dataset Generation ‣ Revolutionizing Database Q&amp;A with Large Language Models: Comprehensive Benchmark and Evaluation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text" style="font-size:90%;">4.3</span> </span><span class="ltx_text" style="font-size:90%;">Prompt Template Engineering</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#S4.SS4" title="In 4. DQA Testbed ‣ 3.3. Instance-Specific Q&amp;A ‣ 3.2. Product-Specific Q&amp;A ‣ 3. DQA Dataset Generation ‣ Revolutionizing Database Q&amp;A with Large Language Models: Comprehensive Benchmark and Evaluation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text" style="font-size:90%;">4.4</span> </span><span class="ltx_text" style="font-size:90%;">Retrieval Augment Generation</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#S4.SS5" title="In 4. DQA Testbed ‣ 3.3. Instance-Specific Q&amp;A ‣ 3.2. Product-Specific Q&amp;A ‣ 3. DQA Dataset Generation ‣ Revolutionizing Database Q&amp;A with Large Language Models: Comprehensive Benchmark and Evaluation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text" style="font-size:90%;">4.5</span> </span><span class="ltx_text" style="font-size:90%;">Tool Invocation Generation</span></span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#S5" title="In 4.5. Tool Invocation Generation ‣ 4. DQA Testbed ‣ 3.3. Instance-Specific Q&amp;A ‣ 3.2. Product-Specific Q&amp;A ‣ 3. DQA Dataset Generation ‣ Revolutionizing Database Q&amp;A with Large Language Models: Comprehensive Benchmark and Evaluation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text" style="font-size:90%;">5</span> </span><span class="ltx_text ltx_font_bold ltx_font_italic" style="font-size:90%;">DQA</span><span class="ltx_text" style="font-size:90%;"> Evaluation Pipeline</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#S5.SS1" title="In 5. DQA Evaluation Pipeline ‣ 4.5. Tool Invocation Generation ‣ 4. DQA Testbed ‣ 3.3. Instance-Specific Q&amp;A ‣ 3.2. Product-Specific Q&amp;A ‣ 3. DQA Dataset Generation ‣ Revolutionizing Database Q&amp;A with Large Language Models: Comprehensive Benchmark and Evaluation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text" style="font-size:90%;">5.1</span> </span><span class="ltx_text" style="font-size:90%;">Modularized Evaluation</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#S5.SS2" title="In 5. DQA Evaluation Pipeline ‣ 4.5. Tool Invocation Generation ‣ 4. DQA Testbed ‣ 3.3. Instance-Specific Q&amp;A ‣ 3.2. Product-Specific Q&amp;A ‣ 3. DQA Dataset Generation ‣ Revolutionizing Database Q&amp;A with Large Language Models: Comprehensive Benchmark and Evaluation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text" style="font-size:90%;">5.2</span> </span><span class="ltx_text" style="font-size:90%;">End-to-End Evaluation</span></span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#S6" title="In 5.2. End-to-End Evaluation ‣ 5. DQA Evaluation Pipeline ‣ 4.5. Tool Invocation Generation ‣ 4. DQA Testbed ‣ 3.3. Instance-Specific Q&amp;A ‣ 3.2. Product-Specific Q&amp;A ‣ 3. DQA Dataset Generation ‣ Revolutionizing Database Q&amp;A with Large Language Models: Comprehensive Benchmark and Evaluation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text" style="font-size:90%;">6</span> </span><span class="ltx_text" style="font-size:90%;">Experiment</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#S6.SS1" title="In 6. Experiment ‣ 5.2. End-to-End Evaluation ‣ 5. DQA Evaluation Pipeline ‣ 4.5. Tool Invocation Generation ‣ 4. DQA Testbed ‣ 3.3. Instance-Specific Q&amp;A ‣ 3.2. Product-Specific Q&amp;A ‣ 3. DQA Dataset Generation ‣ Revolutionizing Database Q&amp;A with Large Language Models: Comprehensive Benchmark and Evaluation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text" style="font-size:90%;">6.1</span> </span><span class="ltx_text" style="font-size:90%;">Experimental Setup</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#S6.SS2" title="In 6. Experiment ‣ 5.2. End-to-End Evaluation ‣ 5. DQA Evaluation Pipeline ‣ 4.5. Tool Invocation Generation ‣ 4. DQA Testbed ‣ 3.3. Instance-Specific Q&amp;A ‣ 3.2. Product-Specific Q&amp;A ‣ 3. DQA Dataset Generation ‣ Revolutionizing Database Q&amp;A with Large Language Models: Comprehensive Benchmark and Evaluation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text" style="font-size:90%;">6.2</span> </span><span class="ltx_text" style="font-size:90%;">LLMs Evaluation by </span><span class="ltx_text ltx_font_bold ltx_font_italic" style="font-size:90%;">DQA</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#S6.SS3" title="In 6. Experiment ‣ 5.2. End-to-End Evaluation ‣ 5. DQA Evaluation Pipeline ‣ 4.5. Tool Invocation Generation ‣ 4. DQA Testbed ‣ 3.3. Instance-Specific Q&amp;A ‣ 3.2. Product-Specific Q&amp;A ‣ 3. DQA Dataset Generation ‣ Revolutionizing Database Q&amp;A with Large Language Models: Comprehensive Benchmark and Evaluation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text" style="font-size:90%;">6.3</span> </span><span class="ltx_text" style="font-size:90%;">In-depth Analysis of Database General Q&amp;A</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#S6.SS4" title="In 6. Experiment ‣ 5.2. End-to-End Evaluation ‣ 5. DQA Evaluation Pipeline ‣ 4.5. Tool Invocation Generation ‣ 4. DQA Testbed ‣ 3.3. Instance-Specific Q&amp;A ‣ 3.2. Product-Specific Q&amp;A ‣ 3. DQA Dataset Generation ‣ Revolutionizing Database Q&amp;A with Large Language Models: Comprehensive Benchmark and Evaluation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text" style="font-size:90%;">6.4</span> </span><span class="ltx_text" style="font-size:90%;">Question Classification Models Comparison</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#S6.SS5" title="In 6. Experiment ‣ 5.2. End-to-End Evaluation ‣ 5. DQA Evaluation Pipeline ‣ 4.5. Tool Invocation Generation ‣ 4. DQA Testbed ‣ 3.3. Instance-Specific Q&amp;A ‣ 3.2. Product-Specific Q&amp;A ‣ 3. DQA Dataset Generation ‣ Revolutionizing Database Q&amp;A with Large Language Models: Comprehensive Benchmark and Evaluation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text" style="font-size:90%;">6.5</span> </span><span class="ltx_text" style="font-size:90%;">Retrieval Augment Generation Ablation</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#S6.SS6" title="In 6. Experiment ‣ 5.2. End-to-End Evaluation ‣ 5. DQA Evaluation Pipeline ‣ 4.5. Tool Invocation Generation ‣ 4. DQA Testbed ‣ 3.3. Instance-Specific Q&amp;A ‣ 3.2. Product-Specific Q&amp;A ‣ 3. DQA Dataset Generation ‣ Revolutionizing Database Q&amp;A with Large Language Models: Comprehensive Benchmark and Evaluation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text" style="font-size:90%;">6.6</span> </span><span class="ltx_text" style="font-size:90%;">Tool Invocation Analysis</span></span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#S7" title="In 6.6. Tool Invocation Analysis ‣ 6. Experiment ‣ 5.2. End-to-End Evaluation ‣ 5. DQA Evaluation Pipeline ‣ 4.5. Tool Invocation Generation ‣ 4. DQA Testbed ‣ 3.3. Instance-Specific Q&amp;A ‣ 3.2. Product-Specific Q&amp;A ‣ 3. DQA Dataset Generation ‣ Revolutionizing Database Q&amp;A with Large Language Models: Comprehensive Benchmark and Evaluation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text" style="font-size:90%;">7</span> </span><span class="ltx_text" style="font-size:90%;">Conclusion</span></span></a></li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line ltx_leqno">
<h1 class="ltx_title ltx_title_document">Revolutionizing Database Q&amp;A with Large Language Models: Comprehensive Benchmark and Evaluation</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Yihang Zheng<sup class="ltx_sup" id="id3.1.id1">1</sup>, Bo Li<sup class="ltx_sup" id="id4.2.id2">1</sup>, Zhenghao Lin<sup class="ltx_sup" id="id5.3.id3">1</sup>, Yi Luo<sup class="ltx_sup" id="id6.4.id4">1</sup>, Xuanhe Zhou<sup class="ltx_sup" id="id7.5.id5">2</sup>
</span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Chen Lin<sup class="ltx_sup" id="id8.1.id1">1*</sup>, Jinsong Su<sup class="ltx_sup" id="id9.2.id2">1</sup>, Guoliang Li<sup class="ltx_sup" id="id10.3.id3">2</sup>, Shifu Li<sup class="ltx_sup" id="id11.4.id4">3</sup>
</span></span>
<span class="ltx_author_before"> and </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"><sup class="ltx_sup" id="id12.1.id1">1</sup> Xiamen University; <sup class="ltx_sup" id="id13.2.id2">2</sup> Tsinghua University; <sup class="ltx_sup" id="id14.3.id3">3</sup> Huawei
</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract.</h6>
<p class="ltx_p" id="id2.2">The development of Large Language Models (LLMs) has revolutionized Q<span class="ltx_text" id="id2.2.1" style="font-size:90%;">&amp;</span>A across various industries, including the database domain. However, there is still a lack of a comprehensive benchmark to evaluate the capabilities of different LLMs and their modular components in database Q<span class="ltx_text" id="id2.2.2" style="font-size:90%;">&amp;</span>A. To this end, <span class="ltx_text ltx_font_italic" id="id2.2.3">we introduce DQA, the first comprehensive database Q<span class="ltx_text" id="id2.2.3.1" style="font-size:90%;">&amp;</span>A benchmark.</span> <span class="ltx_text ltx_font_italic" id="id2.2.4">DQA</span> features an innovative LLM-based method for automating the generation, cleaning, and rewriting of database Q<span class="ltx_text" id="id2.2.5" style="font-size:90%;">&amp;</span>A, resulting in over 240,000 Q<span class="ltx_text" id="id2.2.6" style="font-size:90%;">&amp;</span>A pairs in English and Chinese. These Q<span class="ltx_text" id="id2.2.7" style="font-size:90%;">&amp;</span>A pairs cover nearly all aspects of database knowledge, including database manuals, database blogs, and database tools. This inclusion allows for additional assessment of LLMs’ Retrieval-Augmented Generation (RAG) and Tool Invocation Generation (TIG) capabilities in the database Q<span class="ltx_text" id="id2.2.8" style="font-size:90%;">&amp;</span>A task. Furthermore, <span class="ltx_text ltx_font_italic" id="id2.2.9">we propose a comprehensive LLM-based database Q<span class="ltx_text" id="id2.2.9.1" style="font-size:90%;">&amp;</span>A testbed on DQA.</span> This testbed is highly modular and scalable, with both basic and advanced components like Question Classification Routing (QCR), RAG, TIG, and Prompt Template Engineering (PTE). Besides, <span class="ltx_text ltx_font_italic" id="id2.2.10">DQA</span> provides a complete evaluation pipeline, featuring diverse metrics and a standardized evaluation process to ensure comprehensiveness, accuracy, and fairness. <span class="ltx_text ltx_font_italic" id="id2.2.11">We use DQA to evaluate the database Q<span class="ltx_text" id="id2.2.11.1" style="font-size:90%;">&amp;</span>A capabilities under the proposed testbed comprehensively.</span> The evaluation reveals findings like <math alttext="(i)" class="ltx_Math" display="inline" id="id1.1.m1.1"><semantics id="id1.1.m1.1a"><mrow id="id1.1.m1.1.2.2"><mo id="id1.1.m1.1.2.2.1" stretchy="false">(</mo><mi id="id1.1.m1.1.1" xref="id1.1.m1.1.1.cmml">i</mi><mo id="id1.1.m1.1.2.2.2" stretchy="false">)</mo></mrow><annotation-xml encoding="MathML-Content" id="id1.1.m1.1b"><ci id="id1.1.m1.1.1.cmml" xref="id1.1.m1.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="id1.1.m1.1c">(i)</annotation><annotation encoding="application/x-llamapun" id="id1.1.m1.1d">( italic_i )</annotation></semantics></math> the strengths and limitations of nine different LLM-based Q<span class="ltx_text" id="id2.2.12" style="font-size:90%;">&amp;</span>A bots and <math alttext="(ii)" class="ltx_Math" display="inline" id="id2.2.m2.1"><semantics id="id2.2.m2.1a"><mrow id="id2.2.m2.1.1.1" xref="id2.2.m2.1.1.1.1.cmml"><mo id="id2.2.m2.1.1.1.2" stretchy="false" xref="id2.2.m2.1.1.1.1.cmml">(</mo><mrow id="id2.2.m2.1.1.1.1" xref="id2.2.m2.1.1.1.1.cmml"><mi id="id2.2.m2.1.1.1.1.2" xref="id2.2.m2.1.1.1.1.2.cmml">i</mi><mo id="id2.2.m2.1.1.1.1.1" xref="id2.2.m2.1.1.1.1.1.cmml">⁢</mo><mi id="id2.2.m2.1.1.1.1.3" xref="id2.2.m2.1.1.1.1.3.cmml">i</mi></mrow><mo id="id2.2.m2.1.1.1.3" stretchy="false" xref="id2.2.m2.1.1.1.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="id2.2.m2.1b"><apply id="id2.2.m2.1.1.1.1.cmml" xref="id2.2.m2.1.1.1"><times id="id2.2.m2.1.1.1.1.1.cmml" xref="id2.2.m2.1.1.1.1.1"></times><ci id="id2.2.m2.1.1.1.1.2.cmml" xref="id2.2.m2.1.1.1.1.2">𝑖</ci><ci id="id2.2.m2.1.1.1.1.3.cmml" xref="id2.2.m2.1.1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="id2.2.m2.1c">(ii)</annotation><annotation encoding="application/x-llamapun" id="id2.2.m2.1d">( italic_i italic_i )</annotation></semantics></math> the performance impact and potential improvements of various service components (e.g., QCR, RAG, TIG). We hope our benchmark and findings will better guide the future development of LLM-based database Q<span class="ltx_text" id="id2.2.13" style="font-size:90%;">&amp;</span>A research.</p>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1. </span>Introduction</h2>
<figure class="ltx_figure" id="S1.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="233" id="S1.F1.g1" src="x1.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1. </span>Database Q<span class="ltx_text" id="S1.F1.3.1" style="font-size:90%;">&amp;</span>A Classification and Solutions. (a) Percentage of different Q<span class="ltx_text" id="S1.F1.4.2" style="font-size:90%;">&amp;</span>A types in online DB communities. (b-d) answers given for typical questions by (b) experts, (c) DB bot (vision), (d) general-purpose LLM (GPT-4). </figcaption>
</figure>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Database maintenance takes more than 20% in total database cost <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">Zhou et al</span><span class="ltx_text" style="font-size:90%;">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#bib.bib48" title=""><span class="ltx_text" style="font-size:90%;">2024a</span></a>)</cite>, and it heavily relies on human DBAs to maintain databases. However, it is tedious to configure, tune, optimize and upgrade databases, especially for millions of database instances on the cloud. Therefore, there is a need to design an intelligent database Q<span class="ltx_text" id="S1.p1.1.1" style="font-size:90%;">&amp;</span>A bot as a copilot of DBAs. As illustrated in Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#S1.F1" title="Figure 1 ‣ 1. Introduction ‣ Revolutionizing Database Q&amp;A with Large Language Models: Comprehensive Benchmark and Evaluation"><span class="ltx_text ltx_ref_tag">1</span></a> (a)<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>The distribution is calculated based on <math alttext="68,801" class="ltx_Math" display="inline" id="footnote1.m1.2"><semantics id="footnote1.m1.2b"><mrow id="footnote1.m1.2.3.2" xref="footnote1.m1.2.3.1.cmml"><mn id="footnote1.m1.1.1" xref="footnote1.m1.1.1.cmml">68</mn><mo id="footnote1.m1.2.3.2.1" xref="footnote1.m1.2.3.1.cmml">,</mo><mn id="footnote1.m1.2.2" xref="footnote1.m1.2.2.cmml">801</mn></mrow><annotation-xml encoding="MathML-Content" id="footnote1.m1.2c"><list id="footnote1.m1.2.3.1.cmml" xref="footnote1.m1.2.3.2"><cn id="footnote1.m1.1.1.cmml" type="integer" xref="footnote1.m1.1.1">68</cn><cn id="footnote1.m1.2.2.cmml" type="integer" xref="footnote1.m1.2.2">801</cn></list></annotation-xml><annotation encoding="application/x-tex" id="footnote1.m1.2d">68,801</annotation><annotation encoding="application/x-llamapun" id="footnote1.m1.2e">68 , 801</annotation></semantics></math> questions collected from StackExchange.</span></span></span>, database Q&amp;As can be generally categorized into (1) <span class="ltx_text ltx_font_italic" id="S1.p1.1.2">General DB queries</span>, which involve fundamental concepts in the database domain, e.g., SQL grammar, the definition of the E-R data model. (2) <span class="ltx_text ltx_font_italic" id="S1.p1.1.3">Product-specific queries</span>, which relate to the use of particular database products, e.g., set up a local PostgreSQL database, operational instruction for Snowflake. (3) <span class="ltx_text ltx_font_italic" id="S1.p1.1.4">Instance-specific queries</span>, which are centered on a particular database instance, e.g., fault diagnosis and data analysis for a bank’s database running on Postgres v16 with Intel i7 CPU.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.2">Traditionally, seeking solutions to these questions is challenging, often requiring users to consult a vast array of textbooks, product documents and search engines. Users also need to repeat manual operations to obtain contextual information and engage in multi-round dialogues. For example, as shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#S1.F1" title="Figure 1 ‣ 1. Introduction ‣ Revolutionizing Database Q&amp;A with Large Language Models: Comprehensive Benchmark and Evaluation"><span class="ltx_text ltx_ref_tag">1</span></a> (b), users have great trouble getting the final answer by repeatedly <math alttext="(i)" class="ltx_Math" display="inline" id="S1.p2.1.m1.1"><semantics id="S1.p2.1.m1.1a"><mrow id="S1.p2.1.m1.1.2.2"><mo id="S1.p2.1.m1.1.2.2.1" stretchy="false">(</mo><mi id="S1.p2.1.m1.1.1" xref="S1.p2.1.m1.1.1.cmml">i</mi><mo id="S1.p2.1.m1.1.2.2.2" stretchy="false">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S1.p2.1.m1.1b"><ci id="S1.p2.1.m1.1.1.cmml" xref="S1.p2.1.m1.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.p2.1.m1.1c">(i)</annotation><annotation encoding="application/x-llamapun" id="S1.p2.1.m1.1d">( italic_i )</annotation></semantics></math> searching diagnosis knowledge and then <math alttext="(ii)" class="ltx_Math" display="inline" id="S1.p2.2.m2.1"><semantics id="S1.p2.2.m2.1a"><mrow id="S1.p2.2.m2.1.1.1" xref="S1.p2.2.m2.1.1.1.1.cmml"><mo id="S1.p2.2.m2.1.1.1.2" stretchy="false" xref="S1.p2.2.m2.1.1.1.1.cmml">(</mo><mrow id="S1.p2.2.m2.1.1.1.1" xref="S1.p2.2.m2.1.1.1.1.cmml"><mi id="S1.p2.2.m2.1.1.1.1.2" xref="S1.p2.2.m2.1.1.1.1.2.cmml">i</mi><mo id="S1.p2.2.m2.1.1.1.1.1" xref="S1.p2.2.m2.1.1.1.1.1.cmml">⁢</mo><mi id="S1.p2.2.m2.1.1.1.1.3" xref="S1.p2.2.m2.1.1.1.1.3.cmml">i</mi></mrow><mo id="S1.p2.2.m2.1.1.1.3" stretchy="false" xref="S1.p2.2.m2.1.1.1.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S1.p2.2.m2.1b"><apply id="S1.p2.2.m2.1.1.1.1.cmml" xref="S1.p2.2.m2.1.1.1"><times id="S1.p2.2.m2.1.1.1.1.1.cmml" xref="S1.p2.2.m2.1.1.1.1.1"></times><ci id="S1.p2.2.m2.1.1.1.1.2.cmml" xref="S1.p2.2.m2.1.1.1.1.2">𝑖</ci><ci id="S1.p2.2.m2.1.1.1.1.3.cmml" xref="S1.p2.2.m2.1.1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.p2.2.m2.1c">(ii)</annotation><annotation encoding="application/x-llamapun" id="S1.p2.2.m2.1d">( italic_i italic_i )</annotation></semantics></math> verifying in their database environment (e.g., examine error messages or resource usage).</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">The emergence of Large Language Models (LLMs) <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">OpenAI</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#bib.bib24" title=""><span class="ltx_text" style="font-size:90%;">2022</span></a>)</cite> has revolutionized Q<span class="ltx_text" id="S1.p3.1.1" style="font-size:90%;">&amp;</span>A in various domains, such as medicine <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">Zhang et al</span><span class="ltx_text" style="font-size:90%;">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#bib.bib45" title=""><span class="ltx_text" style="font-size:90%;">2023</span></a>; <span class="ltx_text" style="font-size:90%;">Yuan et al</span><span class="ltx_text" style="font-size:90%;">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#bib.bib43" title=""><span class="ltx_text" style="font-size:90%;">2023</span></a>)</cite>, finance <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">Lee et al</span><span class="ltx_text" style="font-size:90%;">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#bib.bib17" title=""><span class="ltx_text" style="font-size:90%;">2024</span></a>)</cite>, earth science <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">Bi et al</span><span class="ltx_text" style="font-size:90%;">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#bib.bib5" title=""><span class="ltx_text" style="font-size:90%;">2023</span></a>)</cite>, law <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">Colombo et al</span><span class="ltx_text" style="font-size:90%;">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#bib.bib8" title=""><span class="ltx_text" style="font-size:90%;">2024</span></a>)</cite>, etc.
Our vision for the LLM-based DB Q<span class="ltx_text" id="S1.p3.1.2" style="font-size:90%;">&amp;</span>A bot is that, as shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#S1.F1" title="Figure 1 ‣ 1. Introduction ‣ Revolutionizing Database Q&amp;A with Large Language Models: Comprehensive Benchmark and Evaluation"><span class="ltx_text ltx_ref_tag">1</span></a> (c)<span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>Showcases are abbreviated from answers generated by Baichuan2-cpt-sft 13B, which is Baichuan2 continued-pre-trained, fine-tuned, and enhanced by various modules in our proposed testbed.</span></span></span>, the user only needs to input a query, and the bot will autonomously utilize various external sources such as DBMS manual documents and database instance information to provide a customized and accurate answer.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">However, whether the current LLMs can fully realize our vision is unclear. For example, as shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#S1.F1" title="Figure 1 ‣ 1. Introduction ‣ Revolutionizing Database Q&amp;A with Large Language Models: Comprehensive Benchmark and Evaluation"><span class="ltx_text ltx_ref_tag">1</span></a> (d)<span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>Showcases are abbreviated from answers generated by GPT-4.</span></span></span>, even the most popular and powerful LLM (GPT-4) cannot always give correct and targeted answers. There <span class="ltx_text ltx_font_italic" id="S1.p4.1.1">lacks a comprehensive evaluation of LLMs on DB-specific Q<span class="ltx_text" id="S1.p4.1.1.1" style="font-size:90%;">&amp;</span>A tasks</span> that can enable us to understand the challenges and opportunities of database QA in the era of LLMs. Although numerous research efforts have evaluated LLMs from different aspects, they have not been dedicated to database Q<span class="ltx_text" id="S1.p4.1.2" style="font-size:90%;">&amp;</span>A tasks, and face the following challenges.</p>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1"><span class="ltx_text ltx_font_bold" id="S1.p5.1.1">C1: Database Q<span class="ltx_text" id="S1.p5.1.1.1" style="font-size:90%;">&amp;</span>A Dataset</span>. To increase the scalability of manually designed datasets, current evaluations of LLMs are mostly based on data collected from the Internet <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">Rajpurkar et al</span><span class="ltx_text" style="font-size:90%;">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#bib.bib27" title=""><span class="ltx_text" style="font-size:90%;">2018</span></a>; <span class="ltx_text" style="font-size:90%;">Wikipedia</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#bib.bib35" title=""><span class="ltx_text" style="font-size:90%;">2021</span></a>; <span class="ltx_text" style="font-size:90%;">He and McAuley</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#bib.bib12" title=""><span class="ltx_text" style="font-size:90%;">2016</span></a>; <span class="ltx_text" style="font-size:90%;">Reddit</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#bib.bib28" title=""><span class="ltx_text" style="font-size:90%;">2015</span></a>)</cite>, which has the following issues in the DB domain. (1) <span class="ltx_text ltx_font_italic" id="S1.p5.1.2">Low Question Quality</span>. Online questions are too brief and lack essential contextual information. For example, a question on slow database performance without hardware (CPU, IO) or query information is impossible to diagnose. (2) <span class="ltx_text ltx_font_italic" id="S1.p5.1.3">Low Answer Quality</span>. Many online answers are factually incorrect, overly concise, or too subjective. (3) <span class="ltx_text ltx_font_italic" id="S1.p5.1.4">Limited Diversity</span>. Due to factors such as conformity bias, questions in online communities like StackOverflow tend to center on a narrow range of topics and DBMS products, e.g., users are too shy to pose “silly” questions, or most questions concern popular DBMS products.</p>
</div>
<div class="ltx_para" id="S1.p6">
<p class="ltx_p" id="S1.p6.1"><span class="ltx_text ltx_font_bold" id="S1.p6.1.1">C2: Database Q<span class="ltx_text" id="S1.p6.1.1.1" style="font-size:90%;">&amp;</span>A bot testbed</span>. Previous evaluations of LLM <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">Liu et al</span><span class="ltx_text" style="font-size:90%;">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#bib.bib21" title=""><span class="ltx_text" style="font-size:90%;">2024</span></a>)</cite> primarily focus on a standalone LLM. Unfortunately, regardless of the LLM backbone architectures, a series of components are indispensable in a DB Q<span class="ltx_text" id="S1.p6.1.2" style="font-size:90%;">&amp;</span>A bot system to answer a wide range of DB questions. These components include: <span class="ltx_text ltx_font_italic" id="S1.p6.1.3">pre-training</span> to equip the LLM with domain knowledge to answer DB general questions, <span class="ltx_text ltx_font_italic" id="S1.p6.1.4">fine-tuning</span> to enhance the LLM to follow DB-specific instructions, <span class="ltx_text ltx_font_italic" id="S1.p6.1.5">routing</span> to adopt different reasoning logics for various types of questions, <span class="ltx_text ltx_font_italic" id="S1.p6.1.6">retrieving</span> to consult an external product knowledge source to answer product-specific questions, and <span class="ltx_text ltx_font_italic" id="S1.p6.1.7">tool invocating</span> to interact with the DB environment to answer instance-specific questions. Thus, a testbed is required to support all LLMs and integrate with these components.</p>
</div>
<div class="ltx_para" id="S1.p7">
<p class="ltx_p" id="S1.p7.1"><span class="ltx_text ltx_font_bold" id="S1.p7.1.1">C3: Database Q<span class="ltx_text" id="S1.p7.1.1.1" style="font-size:90%;">&amp;</span>A evaluation pipeline</span>. Existing evaluations often rely on LLM’s final output, which is inadequate for measuring DB Q<span class="ltx_text" id="S1.p7.1.2" style="font-size:90%;">&amp;</span>A performance. On the one hand, proper evaluation protocols and metrics for intermediate steps are lacking to measure the multi-dimensional abilities of LLMs. For instance, how do we measure the ability of DB-specific planning and reasoning? A part of these abilities depends on correctly organizing and utilizing different DB tools in the step of tool invocations. On the other hand, measuring the end-to-end performance (i.e., answer quality) is far from trivial. The LLM produces an unstable final answer because there are multiple intermediate steps with unpredictable outcomes. It is imperative to adopt a standardized evaluation pipeline that minimizes the drift in the final answer and fully reflects the LLM’s abilities in the context of DB Q<span class="ltx_text" id="S1.p7.1.3" style="font-size:90%;">&amp;</span>A.</p>
</div>
<div class="ltx_para" id="S1.p8">
<p class="ltx_p" id="S1.p8.1">To address these challenges, we construct a comprehensive benchmark <span class="ltx_text ltx_font_bold ltx_font_italic" id="S1.p8.1.1">DQA</span> (Database Question-Answer) and present a thorough evaluation based on <span class="ltx_text ltx_font_bold ltx_font_italic" id="S1.p8.1.2">DQA</span>.</p>
</div>
<div class="ltx_para" id="S1.p9">
<p class="ltx_p" id="S1.p9.1">To address <span class="ltx_text ltx_font_bold" id="S1.p9.1.1">C1</span>, we construct a large Q<span class="ltx_text" id="S1.p9.1.2" style="font-size:90%;">&amp;</span>A dataset with high quality and diversity. We collect a variety of online queries from online DB courses and forums and enrich the queries with contextual details to <span class="ltx_text ltx_font_italic" id="S1.p9.1.3">enhance question qualities</span>. We collect, clean and rewrite online answers to <span class="ltx_text ltx_font_italic" id="S1.p9.1.4">improve answer qualities</span>. We propose a novel method based on few-shot learning and chain of thought to extract Q<span class="ltx_text" id="S1.p9.1.5" style="font-size:90%;">&amp;</span>A pairs from DBMS documents and instances to <span class="ltx_text ltx_font_italic" id="S1.p9.1.6">increase Q<span class="ltx_text" id="S1.p9.1.6.1" style="font-size:90%;">&amp;</span>A diversity</span> and cover more DBMS products, instances and tools.</p>
</div>
<div class="ltx_para" id="S1.p10">
<p class="ltx_p" id="S1.p10.1">To address <span class="ltx_text ltx_font_bold" id="S1.p10.1.1">C2</span>, we propose a full-chain testbed that incorporates and modularizes all necessary components of a complete DB Q<span class="ltx_text" id="S1.p10.1.2" style="font-size:90%;">&amp;</span>A bot to handle real-production DB Q<span class="ltx_text" id="S1.p10.1.3" style="font-size:90%;">&amp;</span>A scenarios, including pre-training, fine-tuning, Question-Category Routing (QCR), Prompt-Template Engineering (PTE), Retriever-Augmented Generation (RAG) and Tool-Invocation Generation (TIG). We have improved the implementation of each module to better adapt a general-purpose LLM to the DB Q<span class="ltx_text" id="S1.p10.1.4" style="font-size:90%;">&amp;</span>A task.</p>
</div>
<div class="ltx_para" id="S1.p11">
<p class="ltx_p" id="S1.p11.1">To address <span class="ltx_text ltx_font_bold" id="S1.p11.1.1">C3</span>, we develop an evaluation pipeline of modularized evaluation protocols and metrics to comprehensively validate implementations in intermediate steps, including DB document retrieval, DB tool selection and DB tool utilization. Additionally, we propose a standardized end-to-end evaluation that is stable and controlled, reducing the uncertainty in comparing unexpected answers with the ground truths, and increasing the accuracy and fairness of measurements.</p>
</div>
<div class="ltx_para" id="S1.p12">
<p class="ltx_p" id="S1.p12.1">In summary, we make the following contributions.</p>
</div>
<div class="ltx_para" id="S1.p13">
<p class="ltx_p" id="S1.p13.1">(1) We propose the first benchmark dataset <span class="ltx_text ltx_font_bold ltx_font_italic" id="S1.p13.1.1">DQA</span> in the database Q<span class="ltx_text" id="S1.p13.1.2" style="font-size:90%;">&amp;</span>A domain. To simulate real-world DB scenarios and cover a wide spectrum of questions, including questions regarding DB general knowledge and complex questions that demand assistance from external manuals and DB tools. The dataset is large-scale with 240,000 Q<span class="ltx_text" id="S1.p13.1.3" style="font-size:90%;">&amp;</span>A pairs, larger than existing instruction datasets in the IT domain <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">Liu et al</span><span class="ltx_text" style="font-size:90%;">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#bib.bib21" title=""><span class="ltx_text" style="font-size:90%;">2024</span></a>)</cite>. (Section <a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#S3" title="3. DQA Dataset Generation ‣ Revolutionizing Database Q&amp;A with Large Language Models: Comprehensive Benchmark and Evaluation"><span class="ltx_text ltx_ref_tag">3</span></a>)</p>
</div>
<div class="ltx_para" id="S1.p14">
<p class="ltx_p" id="S1.p14.1">(2) We propose a plug-and-play testbed to experiment with different LLM application strategies. The testbed encapsulates all components potentially involved in the database Q<span class="ltx_text" id="S1.p14.1.1" style="font-size:90%;">&amp;</span>A, such as Question-Categorization Routing (QCR), Prompt-Template Engineering (PTE), Retriever-Augmented Generation (RAG) and Tool-Invocation Generation (TIG). (Section <a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#S4" title="4. DQA Testbed ‣ 3.3. Instance-Specific Q&amp;A ‣ 3.2. Product-Specific Q&amp;A ‣ 3. DQA Dataset Generation ‣ Revolutionizing Database Q&amp;A with Large Language Models: Comprehensive Benchmark and Evaluation"><span class="ltx_text ltx_ref_tag">4</span></a>)</p>
</div>
<div class="ltx_para" id="S1.p15">
<p class="ltx_p" id="S1.p15.1">(3) We propose a standardized evaluation pipeline that includes modularized validation of the multi-dimensional abilities of LLMs in DB Q<span class="ltx_text" id="S1.p15.1.1" style="font-size:90%;">&amp;</span>A scenarios. Additionally, we conduct controlled end-to-end evaluations using the <span class="ltx_text ltx_font_bold ltx_font_italic" id="S1.p15.1.2">DQA</span> dataset and the proposed testbed to ensure accuracy and fairness in our assessments. (Section <a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#S5" title="5. DQA Evaluation Pipeline ‣ 4.5. Tool Invocation Generation ‣ 4. DQA Testbed ‣ 3.3. Instance-Specific Q&amp;A ‣ 3.2. Product-Specific Q&amp;A ‣ 3. DQA Dataset Generation ‣ Revolutionizing Database Q&amp;A with Large Language Models: Comprehensive Benchmark and Evaluation"><span class="ltx_text ltx_ref_tag">5</span></a>)</p>
</div>
<div class="ltx_para" id="S1.p16">
<p class="ltx_p" id="S1.p16.2">(4) We implement various LLMs and auxiliary modules on the proposed testbed and comprehensively evaluate them by <span class="ltx_text ltx_font_bold ltx_font_italic" id="S1.p16.2.1">DQA</span>. We reveal the strengths and weaknesses of different LLMs. For instance, extensively large LLMs are significantly superior to mid-sized open-accessible LLMs in terms of answering instance-specific questions, while their differences in answering DB general questions are less significant. For example, GPT-4 is 1.4<math alttext="\times" class="ltx_Math" display="inline" id="S1.p16.1.m1.1"><semantics id="S1.p16.1.m1.1a"><mo id="S1.p16.1.m1.1.1" xref="S1.p16.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S1.p16.1.m1.1b"><times id="S1.p16.1.m1.1.1.cmml" xref="S1.p16.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S1.p16.1.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S1.p16.1.m1.1d">×</annotation></semantics></math> more accurate than Llama3 8B in DB general questions and 1.9<math alttext="\times" class="ltx_Math" display="inline" id="S1.p16.2.m2.1"><semantics id="S1.p16.2.m2.1a"><mo id="S1.p16.2.m2.1.1" xref="S1.p16.2.m2.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S1.p16.2.m2.1b"><times id="S1.p16.2.m2.1.1.cmml" xref="S1.p16.2.m2.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S1.p16.2.m2.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S1.p16.2.m2.1d">×</annotation></semantics></math> more accurate in instance-specific questions. We also show that the modules in the proposed testbed can substantially improve the DB Q<span class="ltx_text" id="S1.p16.2.2" style="font-size:90%;">&amp;</span>A performance of a mid-sized open-accessible LLM. For example, Baichuan2-13B accommodated in the testbed can be comparable to GPT-4 on <span class="ltx_text ltx_font_bold ltx_font_italic" id="S1.p16.2.3">DQA</span>, after targeted pre-training and fine-tuning. We believe that these insights can strongly guide the future development of LLMs for database Q<span class="ltx_text" id="S1.p16.2.4" style="font-size:90%;">&amp;</span>A tasks. (Section <a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#S6" title="6. Experiment ‣ 5.2. End-to-End Evaluation ‣ 5. DQA Evaluation Pipeline ‣ 4.5. Tool Invocation Generation ‣ 4. DQA Testbed ‣ 3.3. Instance-Specific Q&amp;A ‣ 3.2. Product-Specific Q&amp;A ‣ 3. DQA Dataset Generation ‣ Revolutionizing Database Q&amp;A with Large Language Models: Comprehensive Benchmark and Evaluation"><span class="ltx_text ltx_ref_tag">6</span></a>)</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2. </span>Related Work</h2>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1. </span>Q<span class="ltx_text" id="S2.SS1.1.1" style="font-size:90%;">&amp;</span>A by Large Language Models</h3>
<div class="ltx_para ltx_noindent" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.1"><span class="ltx_text ltx_font_bold" id="S2.SS1.p1.1.1">Q<span class="ltx_text" id="S2.SS1.p1.1.1.1" style="font-size:90%;">&amp;</span>A with General-purpose LLMs. </span> LLMs such as GPT-3.5 <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">OpenAI</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#bib.bib24" title=""><span class="ltx_text" style="font-size:90%;">2022</span></a>)</cite>, LLaMa <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">Touvron et al</span><span class="ltx_text" style="font-size:90%;">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#bib.bib32" title=""><span class="ltx_text" style="font-size:90%;">2023a</span></a>)</cite> and PaLM <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">Anil et al</span><span class="ltx_text" style="font-size:90%;">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#bib.bib2" title=""><span class="ltx_text" style="font-size:90%;">2023</span></a>)</cite> have emerged when researchers have discovered that model performance can be enhanced by scaling up both the model and training data, in accordance with scaling laws. These models demonstrate Q<span class="ltx_text" id="S2.SS1.p1.1.2" style="font-size:90%;">&amp;</span>A capabilities far beyond traditional pre-trained language models. For instance, GPT-4 <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">OpenAI</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#bib.bib25" title=""><span class="ltx_text" style="font-size:90%;">2023</span></a>)</cite> achieves human-level performance on the majority of professional and academic examinations, ranking in the top 10% of candidates on the bar exam. Additionally, to meet the demands of edge deployment (i.e, deploy on consumer-grade GPUs), smaller yet powerful LLMs have also been developed. Examples include Llama3-7B <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">Touvron et al</span><span class="ltx_text" style="font-size:90%;">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#bib.bib32" title=""><span class="ltx_text" style="font-size:90%;">2023a</span></a>)</cite>, Mistral-7B <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">Jiang et al</span><span class="ltx_text" style="font-size:90%;">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#bib.bib16" title=""><span class="ltx_text" style="font-size:90%;">2023</span></a>)</cite>, Baichuan2-13B <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">Yang et al</span><span class="ltx_text" style="font-size:90%;">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#bib.bib39" title=""><span class="ltx_text" style="font-size:90%;">2023</span></a>)</cite> and Qwen-14B <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">Bai et al</span><span class="ltx_text" style="font-size:90%;">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#bib.bib3" title=""><span class="ltx_text" style="font-size:90%;">2023a</span></a>)</cite>. More smaller models, such as Yuan-2B <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">Wu et al</span><span class="ltx_text" style="font-size:90%;">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#bib.bib36" title=""><span class="ltx_text" style="font-size:90%;">2023</span></a>)</cite>, have also been developed. However, research indicates that the performance of these models is constrained by their size, making them suitable only for simple, singular tasks.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS1.p2">
<p class="ltx_p" id="S2.SS1.p2.1"><span class="ltx_text ltx_font_bold" id="S2.SS1.p2.1.1">Q<span class="ltx_text" id="S2.SS1.p2.1.1.1" style="font-size:90%;">&amp;</span>A with Domain-Specific LLMs.</span> In the professional domain, due to (1) the diverse language styles of questions and (2) the complexity and depth of expertise, many customized LLMs have been developed. These include models in domains such as medicine <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">Zhang et al</span><span class="ltx_text" style="font-size:90%;">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#bib.bib45" title=""><span class="ltx_text" style="font-size:90%;">2023</span></a>; <span class="ltx_text" style="font-size:90%;">Yuan et al</span><span class="ltx_text" style="font-size:90%;">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#bib.bib43" title=""><span class="ltx_text" style="font-size:90%;">2023</span></a>)</cite>, finance <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">Lee et al</span><span class="ltx_text" style="font-size:90%;">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#bib.bib17" title=""><span class="ltx_text" style="font-size:90%;">2024</span></a>)</cite>, earth science <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">Bi et al</span><span class="ltx_text" style="font-size:90%;">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#bib.bib5" title=""><span class="ltx_text" style="font-size:90%;">2023</span></a>)</cite> and law <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">Colombo et al</span><span class="ltx_text" style="font-size:90%;">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#bib.bib8" title=""><span class="ltx_text" style="font-size:90%;">2024</span></a>)</cite>. These LLMs typically possess deeper domain-specific knowledge and capabilities. Consequently, many smaller-scale models can achieve or even surpass the Q<span class="ltx_text" id="S2.SS1.p2.1.2" style="font-size:90%;">&amp;</span>A abilities of GPT-4 in their respective domains.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS1.p3">
<p class="ltx_p" id="S2.SS1.p3.1"><span class="ltx_text ltx_font_bold" id="S2.SS1.p3.1.1">Q<span class="ltx_text" id="S2.SS1.p3.1.1.1" style="font-size:90%;">&amp;</span>A with knowledge-augment to LLMs. </span> To ensure the quality of Q<span class="ltx_text" id="S2.SS1.p3.1.2" style="font-size:90%;">&amp;</span>A in LLMs, researchers have introduced external knowledge to enhance answer generation. The external knowledge can be brought as follows: (1) By retrieving documents <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">Gao et al</span><span class="ltx_text" style="font-size:90%;">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#bib.bib11" title=""><span class="ltx_text" style="font-size:90%;">2023</span></a>)</cite> or guidelines<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">Luo et al</span><span class="ltx_text" style="font-size:90%;">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#bib.bib22" title=""><span class="ltx_text" style="font-size:90%;">2024</span></a>)</cite> for questions to enhance the answer generation. (2) By using structured knowledge, such as knowledge graphs, for reliable reasoning <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">Sun et al</span><span class="ltx_text" style="font-size:90%;">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#bib.bib30" title=""><span class="ltx_text" style="font-size:90%;">2023a</span></a>)</cite>. (3) By using external tools triggered by LLMs to acquire knowledge even being an agent <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">Wang et al</span><span class="ltx_text" style="font-size:90%;">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#bib.bib34" title=""><span class="ltx_text" style="font-size:90%;">2024</span></a>)</cite>.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2. </span>Large Language Models for Database</h3>
<div class="ltx_para ltx_noindent" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.1"><span class="ltx_text ltx_font_bold" id="S2.SS2.p1.1.1">LLMs for Database Optimization. </span>Since LLMs have demonstrated outstanding capabilities in knowledge comprehension and contextual understanding, researchers in the database domain have started to explore LLMs for various database-related tasks. Raul et al. <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">Fernandez et al</span><span class="ltx_text" style="font-size:90%;">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#bib.bib10" title=""><span class="ltx_text" style="font-size:90%;">2023</span></a>)</cite> argue that LLMs can ground database tuples, schemas and queries in novel ways. Zhou et al. <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">Zhou et al</span><span class="ltx_text" style="font-size:90%;">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#bib.bib46" title=""><span class="ltx_text" style="font-size:90%;">2023a</span></a>)</cite> have proposed that LLMs can serve as Database Administrators (DBAs) by constructing LLM-based intelligent agents. The D-Bot <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">Zhou et al</span><span class="ltx_text" style="font-size:90%;">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#bib.bib47" title=""><span class="ltx_text" style="font-size:90%;">2023b</span></a>)</cite> initiative applies LLMs to intelligent database diagnosis. Additionally, Liu et al. <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">Liu and Mozafari</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#bib.bib20" title=""><span class="ltx_text" style="font-size:90%;">2024</span></a>)</cite> use LLMs for query rewriting. These advancements illustrate the expanding usage of LLMs in the database domain. However, these studies primarily focus on specific database tasks, rather than answering general user questions in our paper.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS2.p2">
<p class="ltx_p" id="S2.SS2.p2.1"><span class="ltx_text ltx_font_bold" id="S2.SS2.p2.1.1">LLMs for NL2SQL.</span> For data management tasks, databases serve as tools, requiring SQL for user-database interactions. LLMs have shown impressive capabilities in converting natural language into SQL, bringing about significant changes in simplifying user interactions with databases. Works such as Binder-SQL <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">Cheng et al</span><span class="ltx_text" style="font-size:90%;">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#bib.bib7" title=""><span class="ltx_text" style="font-size:90%;">2022</span></a>)</cite>, DIN-SQL <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">Pourreza and Rafiei</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#bib.bib26" title=""><span class="ltx_text" style="font-size:90%;">2024</span></a>)</cite> and BIRD <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">Li et al</span><span class="ltx_text" style="font-size:90%;">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#bib.bib18" title=""><span class="ltx_text" style="font-size:90%;">2024</span></a>)</cite> enable LLMs to generate corresponding SQL statements directly from natural language requirements. DB-GPT <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">Xue et al</span><span class="ltx_text" style="font-size:90%;">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#bib.bib38" title=""><span class="ltx_text" style="font-size:90%;">2023</span></a>)</cite> extends this concept by creating a more comprehensive process, allowing users to input their requirements in natural language and receive complete visualized data analysis and reports. This showcases the potential of LLMs to enhance accessibility and efficiency in data management tasks. Compared to these works, our paper considers more comprehensive questions that the database users may ask, rather than focusing solely on SQL programming and data analysis pipeline as addressed in the previous works.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3. </span><span class="ltx_text ltx_font_bold ltx_font_italic" id="S3.1.1">DQA</span> Dataset Generation</h2>
<figure class="ltx_table" id="S3.T1">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1. </span><span class="ltx_text ltx_font_bold ltx_font_italic" id="S3.T1.2.1">DQA</span> dataset statistics</figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S3.T1.3">
<tr class="ltx_tr" id="S3.T1.3.1">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.3.1.1" rowspan="2"><span class="ltx_text ltx_font_bold" id="S3.T1.3.1.1.1">Type</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.3.1.2" rowspan="2"><span class="ltx_text ltx_font_bold" id="S3.T1.3.1.2.1">Source</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.3.1.3" rowspan="2"><span class="ltx_text ltx_font_bold" id="S3.T1.3.1.3.1"># Q.</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="2" id="S3.T1.3.1.4"><span class="ltx_text ltx_font_bold" id="S3.T1.3.1.4.1">English</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="2" id="S3.T1.3.1.5"><span class="ltx_text ltx_font_bold" id="S3.T1.3.1.5.1">Chinese</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.1.6" rowspan="2"><span class="ltx_text ltx_font_bold" id="S3.T1.3.1.6.1">Annotation</span></td>
</tr>
<tr class="ltx_tr" id="S3.T1.3.2">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T1.3.2.1"><span class="ltx_text ltx_font_bold" id="S3.T1.3.2.1.1">Avg. Q. Len.</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T1.3.2.2"><span class="ltx_text ltx_font_bold" id="S3.T1.3.2.2.1">Avg. A. len.</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T1.3.2.3"><span class="ltx_text ltx_font_bold" id="S3.T1.3.2.3.1">Avg. Q. Len.</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T1.3.2.4"><span class="ltx_text ltx_font_bold" id="S3.T1.3.2.4.1">Avg. A. len.</span></td>
</tr>
<tr class="ltx_tr" id="S3.T1.3.3">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.3.3.1" rowspan="2"><span class="ltx_text ltx_font_bold" id="S3.T1.3.3.1.1">General</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.3.3.2">Exam</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S3.T1.3.3.3">2,152</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S3.T1.3.3.4">224.19</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S3.T1.3.3.5">458.61</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S3.T1.3.3.6">85.44</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S3.T1.3.3.7">124.59</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.3.8" rowspan="2"><span class="ltx_text" id="S3.T1.3.3.8.1">N/A</span></td>
</tr>
<tr class="ltx_tr" id="S3.T1.3.4">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.3.4.1">Forum</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S3.T1.3.4.2">74,893</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S3.T1.3.4.3">1205.75</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S3.T1.3.4.4">1273.16</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S3.T1.3.4.5">354.15</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S3.T1.3.4.6">790.24</td>
</tr>
<tr class="ltx_tr" id="S3.T1.3.5">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.3.5.1" rowspan="2"><span class="ltx_text ltx_font_bold" id="S3.T1.3.5.1.1">Product-Specific</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.3.5.2">OpenGauss</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S3.T1.3.5.3">21,689</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S3.T1.3.5.4">78.19</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S3.T1.3.5.5">666.26</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S3.T1.3.5.6">31.34</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S3.T1.3.5.7">267.42</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.5.8" rowspan="2"><span class="ltx_text" id="S3.T1.3.5.8.1">Retrieval Label</span></td>
</tr>
<tr class="ltx_tr" id="S3.T1.3.6">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.3.6.1">GaussDB</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S3.T1.3.6.2">4,950</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S3.T1.3.6.3">84.84</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S3.T1.3.6.4">885.67</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S3.T1.3.6.5">34.62</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S3.T1.3.6.6">394.60</td>
</tr>
<tr class="ltx_tr" id="S3.T1.3.7">
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S3.T1.3.7.1" rowspan="2"><span class="ltx_text ltx_font_bold" id="S3.T1.3.7.1.1">Instance-Specific</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.3.7.2">Common</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S3.T1.3.7.3">1,080</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S3.T1.3.7.4">86.07</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S3.T1.3.7.5">1070.21</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S3.T1.3.7.6">29.76</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S3.T1.3.7.7">757.23</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S3.T1.3.7.8" rowspan="2"><span class="ltx_text" id="S3.T1.3.7.8.1">Tool Label</span></td>
</tr>
<tr class="ltx_tr" id="S3.T1.3.8">
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S3.T1.3.8.1">Generalization</td>
<td class="ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_t" id="S3.T1.3.8.2">2,707</td>
<td class="ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_t" id="S3.T1.3.8.3">127.18</td>
<td class="ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_t" id="S3.T1.3.8.4">1019.28</td>
<td class="ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_t" id="S3.T1.3.8.5">34.81</td>
<td class="ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_t" id="S3.T1.3.8.6">515.92</td>
</tr>
</table>
</figure>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">A dataset comprising question and answer pairs is necessary to evaluate the performance of a DB Q<span class="ltx_text" id="S3.p1.1.1" style="font-size:90%;">&amp;</span>A bot. Manually constructing such a dataset is too costly. However, online resources can not provide high-quality and broad-coverage database-related questions.</p>
</div>
<div class="ltx_para" id="S3.p2">
<p class="ltx_p" id="S3.p2.1">As shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#S1.F1" title="Figure 1 ‣ 1. Introduction ‣ Revolutionizing Database Q&amp;A with Large Language Models: Comprehensive Benchmark and Evaluation"><span class="ltx_text ltx_ref_tag">1</span></a> (a), the DB queries are divided into three subsets, corresponding to three key skill sets of an LLM-based DB Q<span class="ltx_text" id="S3.p2.1.1" style="font-size:90%;">&amp;</span>A bot. <span class="ltx_text ltx_font_italic" id="S3.p2.1.2">General DB queries</span> can evaluate whether the bot grasps DB-related concepts and knowledge. <span class="ltx_text ltx_font_italic" id="S3.p2.1.3">Product-specific queries</span> can evaluate whether the bot applies knowledge and adapts to real-life DB circumstances. <span class="ltx_text ltx_font_italic" id="S3.p2.1.4">Instance-specific queries</span> can evaluate the proficiency of the bot in DB troubleshooting.</p>
</div>
<div class="ltx_para" id="S3.p3">
<p class="ltx_p" id="S3.p3.1">The three query categories are different in (1) data sources: general DB queries are publicly available, while product-specific queries and instance-specific queries are almost impossible to get complete examples online. (2) problem background: the latter two categories (i.e., product-specific queries and instance-specific queries) need supporting information, such as the product manual and instance context. (3) ground-truth answers: the latter two categories must provide retrieval results or tool invocation results to demonstrate the reasoning and produce trustworthy answers.</p>
</div>
<div class="ltx_para" id="S3.p4">
<p class="ltx_p" id="S3.p4.1"><span class="ltx_text ltx_font_bold" id="S3.p4.1.1">Data Statistics</span>. Accordingly, we propose methods to construct the dataset for each category separately. As shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#S3.T1" title="Table 1 ‣ 3. DQA Dataset Generation ‣ Revolutionizing Database Q&amp;A with Large Language Models: Comprehensive Benchmark and Evaluation"><span class="ltx_text ltx_ref_tag">1</span></a>, we construct a dataset with bi-lingual Q<span class="ltx_text" id="S3.p4.1.2" style="font-size:90%;">&amp;</span>A pairs on the three categories, translating English pairs into Chinese and vice-versa, leading to a total of over 120,000 Q<span class="ltx_text" id="S3.p4.1.3" style="font-size:90%;">&amp;</span>A pairs in each language.</p>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1. </span>General DB Q<span class="ltx_text" id="S3.SS1.1.1" style="font-size:90%;">&amp;</span>A</h3>
<figure class="ltx_table" id="S3.T2">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2. </span>Example of general DB Q<span class="ltx_text" id="S3.T2.2.1" style="font-size:90%;">&amp;</span>A</figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S3.T2.3">
<tr class="ltx_tr" id="S3.T2.3.1">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" id="S3.T2.3.1.1">
<span class="ltx_inline-block ltx_align_top" id="S3.T2.3.1.1.1">
<span class="ltx_p" id="S3.T2.3.1.1.1.1" style="width:42.7pt;"><span class="ltx_text ltx_font_bold" id="S3.T2.3.1.1.1.1.1" style="font-size:90%;">Question</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" id="S3.T2.3.1.2">
<span class="ltx_inline-block ltx_align_top" id="S3.T2.3.1.2.1">
<span class="ltx_p" id="S3.T2.3.1.2.1.1" style="width:170.7pt;"><span class="ltx_text" id="S3.T2.3.1.2.1.1.1" style="font-size:90%;">How to create ASM and install Grid for beginners confused about hard drives and disks?</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S3.T2.3.2">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S3.T2.3.2.1">
<span class="ltx_inline-block ltx_align_top" id="S3.T2.3.2.1.1">
<span class="ltx_p" id="S3.T2.3.2.1.1.1" style="width:42.7pt;"><span class="ltx_text ltx_font_bold" id="S3.T2.3.2.1.1.1.1" style="font-size:90%;">Original Answer</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S3.T2.3.2.2">
<span class="ltx_inline-block ltx_align_top" id="S3.T2.3.2.2.1">
<span class="ltx_p" id="S3.T2.3.2.2.1.1" style="width:170.7pt;"><span class="ltx_text" id="S3.T2.3.2.2.1.1.1" style="font-size:90%;">If you’re not clear on hard drives or disks, start with basic Linux knowledge first.</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S3.T2.3.3">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S3.T2.3.3.1">
<span class="ltx_inline-block ltx_align_top" id="S3.T2.3.3.1.1">
<span class="ltx_p" id="S3.T2.3.3.1.1.1" style="width:42.7pt;"><span class="ltx_text ltx_font_bold" id="S3.T2.3.3.1.1.1.1" style="font-size:90%;">Prompt</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S3.T2.3.3.2">
<span class="ltx_inline-block ltx_align_top" id="S3.T2.3.3.2.1">
<span class="ltx_p" id="S3.T2.3.3.2.1.1" style="width:170.7pt;"><span class="ltx_text" id="S3.T2.3.3.2.1.1.1" style="font-size:90%;">… convert it to a “detailed, professional and friendly” writing style.</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S3.T2.3.4">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t" id="S3.T2.3.4.1">
<span class="ltx_inline-block ltx_align_top" id="S3.T2.3.4.1.1">
<span class="ltx_p" id="S3.T2.3.4.1.1.1" style="width:42.7pt;"><span class="ltx_text ltx_font_bold" id="S3.T2.3.4.1.1.1.1" style="font-size:90%;">Rewritten Answer</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t" id="S3.T2.3.4.2">
<span class="ltx_inline-block ltx_align_top" id="S3.T2.3.4.2.1">
<span class="ltx_p" id="S3.T2.3.4.2.1.1" style="width:170.7pt;"><span class="ltx_text" id="S3.T2.3.4.2.1.1.1" style="font-size:90%;">If you‘re still not familiar with concepts like hard disks and disks, I recommend starting with some basic Linux knowledge. …. Firstly, ASM is a storage management solution… Typically, ASM requires at least two disks to create a disk…Before creating ASM, you should …</span></span>
</span>
</td>
</tr>
</table>
</figure>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1"><span class="ltx_text ltx_font_bold" id="S3.SS1.p1.1.1">Data sources</span>. We have two types of data sources. (1) As in the construction of other domain-specific evaluation datasets, exams are a good data source because exams offer objective and typically accurate ground truths. We collect 2000 unique multiple-choice questions from 4 DB university textbooks, 3 online courses and 28 online course exams. (2) To ensure that the <span class="ltx_text ltx_font_bold ltx_font_italic" id="S3.SS1.p1.1.2">DQA</span> dataset covers a wide range of daily questions asked by DB users, we collect all resolved Q<span class="ltx_text" id="S3.SS1.p1.1.3" style="font-size:90%;">&amp;</span>A entries from the largest English and Chinese online DB communities, namely the database section of StackOverflow<span class="ltx_note ltx_role_footnote" id="footnote4"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://stackoverflow.com/questions/tagged/database" title="">https://stackoverflow.com/questions/tagged/database</a></span></span></span>, the Database Administrators section of StackExchange<span class="ltx_note ltx_role_footnote" id="footnote5"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://dba.stackexchange.com/" title="">https://dba.stackexchange.com/</a></span></span></span> and MoDB<span class="ltx_note ltx_role_footnote" id="footnote6"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_tag ltx_tag_note">6</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.modb.pro/" title="">https://www.modb.pro/</a></span></span></span>.</p>
</div>
<div class="ltx_para" id="S3.SS1.p2">
<p class="ltx_p" id="S3.SS1.p2.1"><span class="ltx_text ltx_font_bold" id="S3.SS1.p2.1.1">Step 1: Filtering</span>. One major problem of online Q<span class="ltx_text" id="S3.SS1.p2.1.2" style="font-size:90%;">&amp;</span>A pairs is that the answers are not guaranteed to be factually accurate. Thus, we filter the collected content based on online feedback. First, we compute the ROUGE-1 score, which measures the overlap of unigrams between queries. Queries with a large ROUGE-1 score (<math alttext="\geq 0.8" class="ltx_Math" display="inline" id="S3.SS1.p2.1.m1.1"><semantics id="S3.SS1.p2.1.m1.1a"><mrow id="S3.SS1.p2.1.m1.1.1" xref="S3.SS1.p2.1.m1.1.1.cmml"><mi id="S3.SS1.p2.1.m1.1.1.2" xref="S3.SS1.p2.1.m1.1.1.2.cmml"></mi><mo id="S3.SS1.p2.1.m1.1.1.1" xref="S3.SS1.p2.1.m1.1.1.1.cmml">≥</mo><mn id="S3.SS1.p2.1.m1.1.1.3" xref="S3.SS1.p2.1.m1.1.1.3.cmml">0.8</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.1.m1.1b"><apply id="S3.SS1.p2.1.m1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1"><geq id="S3.SS1.p2.1.m1.1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1.1"></geq><csymbol cd="latexml" id="S3.SS1.p2.1.m1.1.1.2.cmml" xref="S3.SS1.p2.1.m1.1.1.2">absent</csymbol><cn id="S3.SS1.p2.1.m1.1.1.3.cmml" type="float" xref="S3.SS1.p2.1.m1.1.1.3">0.8</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.1.m1.1c">\geq 0.8</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.1.m1.1d">≥ 0.8</annotation></semantics></math>) are merged to de-duplicate the questions and reduce possible grammatical problems. For each question, we retain only the accepted answers and those with high upvotes to ensure the factual correctness of the responses.</p>
</div>
<div class="ltx_para" id="S3.SS1.p3">
<p class="ltx_p" id="S3.SS1.p3.1"><span class="ltx_text ltx_font_bold" id="S3.SS1.p3.1.1">Step 2: Rewriting</span>. The answers in the Q<span class="ltx_text" id="S3.SS1.p3.1.2" style="font-size:90%;">&amp;</span>A data collected are insufficient as evaluation ground truth. For example, the exam questions are only associated with letter options, and the LLMs’ generation may be too random when only generating a letter option, making the answer unstable in assessing the professional levels of LLMs. Therefore, for each exam query, we extend the answer by instructing GPT-4 to provide detailed explanations for the answer choices. Meanwhile, online responses are also often overly concise, emotional and subjective. As shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#S3.T2" title="Table 2 ‣ 3.1. General DB Q&amp;A ‣ 3. DQA Dataset Generation ‣ Revolutionizing Database Q&amp;A with Large Language Models: Comprehensive Benchmark and Evaluation"><span class="ltx_text ltx_ref_tag">2</span></a>, while the replies explicitly advise the inquirer to learn basic Linux knowledge, they do not specify a learning path or key points, and the tone is not user-friendly. For each online query, we reform the accepted response by instructing GPT-4 to convert it to a “detailed, professional and friendly” writing style. Table <a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#S3.T2" title="Table 2 ‣ 3.1. General DB Q&amp;A ‣ 3. DQA Dataset Generation ‣ Revolutionizing Database Q&amp;A with Large Language Models: Comprehensive Benchmark and Evaluation"><span class="ltx_text ltx_ref_tag">2</span></a> shows the prompts, and the rewritten results are more specific and friendly.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2. </span>Product-Specific Q<span class="ltx_text" id="S3.SS2.1.1" style="font-size:90%;">&amp;</span>A</h3>
<figure class="ltx_figure" id="S3.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="387" id="S3.F2.g1" src="x2.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2. </span>Specific Database Product Dataset Generation</figcaption>
</figure>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">Constructing product-specific Q<span class="ltx_text" id="S3.SS2.p1.1.1" style="font-size:90%;">&amp;</span>A pairs from online sources can be problematic. Because most DBMS products are constantly being updated, online queries can be outdated, and the accepted answers can be unreliable and inaccurate. Thus, it is important to ground the LLM on an external knowledge source, e.g., a certain product manual. We construct the product-specific Q<span class="ltx_text" id="S3.SS2.p1.1.2" style="font-size:90%;">&amp;</span>A pairs via the workflow illustrated in Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#S3.F2" title="Figure 2 ‣ 3.2. Product-Specific Q&amp;A ‣ 3. DQA Dataset Generation ‣ Revolutionizing Database Q&amp;A with Large Language Models: Comprehensive Benchmark and Evaluation"><span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
<div class="ltx_para" id="S3.SS2.p2">
<p class="ltx_p" id="S3.SS2.p2.1"><span class="ltx_text ltx_font_bold" id="S3.SS2.p2.1.1">Step 1: Pre-processing Manuals</span>. Most product manual documents are too lengthy for LLMs to comprehend and generate sufficiently questions. Thus, for each product manual to be pre-processed, we segment the documents, each segment contains complete paragraphs while not exceeding 8,000 tokens. This segmentation allows LLMs to process the documents at a finer granularity, thereby generating more detailed and comprehensive Q<span class="ltx_text" id="S3.SS2.p2.1.2" style="font-size:90%;">&amp;</span>A.</p>
</div>
<div class="ltx_para" id="S3.SS2.p3">
<p class="ltx_p" id="S3.SS2.p3.1"><span class="ltx_text ltx_font_bold" id="S3.SS2.p3.1.1">Step 2: Q<span class="ltx_text" id="S3.SS2.p3.1.1.1" style="font-size:90%;">&amp;</span>A Generating</span>. To reduce manual efforts, we use LLM to generate several Q<span class="ltx_text" id="S3.SS2.p3.1.2" style="font-size:90%;">&amp;</span>A pairs on each document segment. The challenge is, directly instructing the LLM to generate Q<span class="ltx_text" id="S3.SS2.p3.1.3" style="font-size:90%;">&amp;</span>A often results in low-quality outcomes. Specifically, the generated questions can overly focus on minor details of the text while neglecting the main points of the given document segment, the answers can be overly concise, and the QA pairs can be repetitive, lacking diverse coverage. Therefore, we propose a novel prompt chain to generate Q<span class="ltx_text" id="S3.SS2.p3.1.4" style="font-size:90%;">&amp;</span>A. As shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#S3.F2" title="Figure 2 ‣ 3.2. Product-Specific Q&amp;A ‣ 3. DQA Dataset Generation ‣ Revolutionizing Database Q&amp;A with Large Language Models: Comprehensive Benchmark and Evaluation"><span class="ltx_text ltx_ref_tag">2</span></a>, the prompt chain first requires LLM to summarize the document segment’s key points. Then, the prompt chain demands LLM to generate a question for each key point that can be answered based on the document segment. Next, the prompt chain asks LLM to produce a detailed, user-friendly answer for each question.</p>
</div>
<div class="ltx_para" id="S3.SS2.p4">
<p class="ltx_p" id="S3.SS2.p4.1"><span class="ltx_text ltx_font_bold" id="S3.SS2.p4.1.1">Step 3: Retrieval Label Annotating.</span> As this dataset aims to evaluate the Q<span class="ltx_text" id="S3.SS2.p4.1.2" style="font-size:90%;">&amp;</span>A bot’s intelligence in applying knowledge and adapting to different DB products in the RAG (Retrieval Augmented Generation) scenarios, in addition to providing Q<span class="ltx_text" id="S3.SS2.p4.1.3" style="font-size:90%;">&amp;</span>A pairs, we also annotate the relevant grounded document to support RAG evaluation and facilitate answer generation for each question. To more precisely locate a finer-grained passage, we segment a single document and store it in a retriever such as a vector database, using the generated question and answer as a query, we retrieve the vector database to pinpoint the text blocks containing relevant information (with retrieval similarity <math alttext="\geq" class="ltx_Math" display="inline" id="S3.SS2.p4.1.m1.1"><semantics id="S3.SS2.p4.1.m1.1a"><mo id="S3.SS2.p4.1.m1.1.1" xref="S3.SS2.p4.1.m1.1.1.cmml">≥</mo><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.1.m1.1b"><geq id="S3.SS2.p4.1.m1.1.1.cmml" xref="S3.SS2.p4.1.m1.1.1"></geq></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.1.m1.1c">\geq</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p4.1.m1.1d">≥</annotation></semantics></math> 0.8) precisely.</p>
</div>
<figure class="ltx_table" id="S3.SS2.tab1">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 3. </span>Supported types of common DB tools</figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<table class="ltx_tabular ltx_figure_panel ltx_align_middle" id="S3.SS2.tab1.1">
<tr class="ltx_tr" id="S3.SS2.tab1.1.1">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.SS2.tab1.1.1.1">
<span class="ltx_inline-block ltx_align_top" id="S3.SS2.tab1.1.1.1.1">
<span class="ltx_p" id="S3.SS2.tab1.1.1.1.1.1" style="width:42.7pt;"><span class="ltx_text ltx_font_bold" id="S3.SS2.tab1.1.1.1.1.1.1" style="font-size:90%;">Objective</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.SS2.tab1.1.1.2">
<span class="ltx_inline-block ltx_align_top" id="S3.SS2.tab1.1.1.2.1">
<span class="ltx_p" id="S3.SS2.tab1.1.1.2.1.1" style="width:28.5pt;"><span class="ltx_text ltx_font_bold" id="S3.SS2.tab1.1.1.2.1.1.1" style="font-size:90%;">Type</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S3.SS2.tab1.1.1.3">
<span class="ltx_inline-block ltx_align_top" id="S3.SS2.tab1.1.1.3.1">
<span class="ltx_p" id="S3.SS2.tab1.1.1.3.1.1" style="width:142.3pt;"><span class="ltx_text ltx_font_bold" id="S3.SS2.tab1.1.1.3.1.1.1" style="font-size:90%;">Functionality</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S3.SS2.tab1.1.2">
<td class="ltx_td ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_t" id="S3.SS2.tab1.1.2.1" rowspan="2">
<span class="ltx_inline-block ltx_align_top" id="S3.SS2.tab1.1.2.1.1">
<span class="ltx_p" id="S3.SS2.tab1.1.2.1.1.1" style="width:42.7pt;"><span class="ltx_text ltx_font_bold" id="S3.SS2.tab1.1.2.1.1.1.1" style="font-size:90%;">
Data </span><span class="ltx_text ltx_font_bold" id="S3.SS2.tab1.1.2.1.1.1.2" style="font-size:90%;">
Modeling</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.SS2.tab1.1.2.2">
<span class="ltx_inline-block ltx_align_top" id="S3.SS2.tab1.1.2.2.1">
<span class="ltx_p" id="S3.SS2.tab1.1.2.2.1.1" style="width:28.5pt;"><span class="ltx_text" id="S3.SS2.tab1.1.2.2.1.1.1" style="font-size:90%;">Schema</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S3.SS2.tab1.1.2.3">
<span class="ltx_inline-block ltx_align_top" id="S3.SS2.tab1.1.2.3.1">
<span class="ltx_p" id="S3.SS2.tab1.1.2.3.1.1" style="width:142.3pt;"><span class="ltx_text" id="S3.SS2.tab1.1.2.3.1.1.1" style="font-size:90%;">Obtain database table structure, constraints, etc.</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S3.SS2.tab1.1.3">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.SS2.tab1.1.3.1">
<span class="ltx_inline-block ltx_align_top" id="S3.SS2.tab1.1.3.1.1">
<span class="ltx_p" id="S3.SS2.tab1.1.3.1.1.1" style="width:28.5pt;"><span class="ltx_text" id="S3.SS2.tab1.1.3.1.1.1.1" style="font-size:90%;">Selection</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S3.SS2.tab1.1.3.2">
<span class="ltx_inline-block ltx_align_top" id="S3.SS2.tab1.1.3.2.1">
<span class="ltx_p" id="S3.SS2.tab1.1.3.2.1.1" style="width:142.3pt;"><span class="ltx_text" id="S3.SS2.tab1.1.3.2.1.1.1" style="font-size:90%;">Return SQL execution results of retrieving specific data from the database, computing data distribution, etc.</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S3.SS2.tab1.1.4">
<td class="ltx_td ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_t" id="S3.SS2.tab1.1.4.1" rowspan="3">
<span class="ltx_inline-block ltx_align_top" id="S3.SS2.tab1.1.4.1.1">
<span class="ltx_p" id="S3.SS2.tab1.1.4.1.1.1" style="width:42.7pt;"><span class="ltx_text ltx_font_bold" id="S3.SS2.tab1.1.4.1.1.1.1" style="font-size:90%;">
Database</span><span class="ltx_text ltx_font_bold" id="S3.SS2.tab1.1.4.1.1.1.2" style="font-size:90%;">
Monitoring</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.SS2.tab1.1.4.2">
<span class="ltx_inline-block ltx_align_top" id="S3.SS2.tab1.1.4.2.1">
<span class="ltx_p" id="S3.SS2.tab1.1.4.2.1.1" style="width:28.5pt;"><span class="ltx_text" id="S3.SS2.tab1.1.4.2.1.1.1" style="font-size:90%;">Resource</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S3.SS2.tab1.1.4.3">
<span class="ltx_inline-block ltx_align_top" id="S3.SS2.tab1.1.4.3.1">
<span class="ltx_p" id="S3.SS2.tab1.1.4.3.1.1" style="width:142.3pt;"><span class="ltx_text" id="S3.SS2.tab1.1.4.3.1.1.1" style="font-size:90%;">Obtain information about CPU usage, memory, disk IO, etc.</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S3.SS2.tab1.1.5">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.SS2.tab1.1.5.1">
<span class="ltx_inline-block ltx_align_top" id="S3.SS2.tab1.1.5.1.1">
<span class="ltx_p" id="S3.SS2.tab1.1.5.1.1.1" style="width:28.5pt;"><span class="ltx_text" id="S3.SS2.tab1.1.5.1.1.1.1" style="font-size:90%;">Workload</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S3.SS2.tab1.1.5.2">
<span class="ltx_inline-block ltx_align_top" id="S3.SS2.tab1.1.5.2.1">
<span class="ltx_p" id="S3.SS2.tab1.1.5.2.1.1" style="width:142.3pt;"><span class="ltx_text" id="S3.SS2.tab1.1.5.2.1.1.1" style="font-size:90%;">Workload analysis, slow query identification, etc.</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S3.SS2.tab1.1.6">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.SS2.tab1.1.6.1">
<span class="ltx_inline-block ltx_align_top" id="S3.SS2.tab1.1.6.1.1">
<span class="ltx_p" id="S3.SS2.tab1.1.6.1.1.1" style="width:28.5pt;"><span class="ltx_text" id="S3.SS2.tab1.1.6.1.1.1.1" style="font-size:90%;">Status</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S3.SS2.tab1.1.6.2">
<span class="ltx_inline-block ltx_align_top" id="S3.SS2.tab1.1.6.2.1">
<span class="ltx_p" id="S3.SS2.tab1.1.6.2.1.1" style="width:142.3pt;"><span class="ltx_text" id="S3.SS2.tab1.1.6.2.1.1.1" style="font-size:90%;">Detailed information about the current indexes, views, knob settings, etc.</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S3.SS2.tab1.1.7">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r ltx_border_t" id="S3.SS2.tab1.1.7.1">
<span class="ltx_inline-block ltx_align_top" id="S3.SS2.tab1.1.7.1.1">
<span class="ltx_p" id="S3.SS2.tab1.1.7.1.1.1" style="width:42.7pt;"><span class="ltx_text ltx_font_bold" id="S3.SS2.tab1.1.7.1.1.1.1" style="font-size:90%;">Optimizing</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r ltx_border_t" id="S3.SS2.tab1.1.7.2">
<span class="ltx_inline-block ltx_align_top" id="S3.SS2.tab1.1.7.2.1">
<span class="ltx_p" id="S3.SS2.tab1.1.7.2.1.1" style="width:28.5pt;"><span class="ltx_text" id="S3.SS2.tab1.1.7.2.1.1.1" style="font-size:90%;">Tuning</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_t" id="S3.SS2.tab1.1.7.3">
<span class="ltx_inline-block ltx_align_top" id="S3.SS2.tab1.1.7.3.1">
<span class="ltx_p" id="S3.SS2.tab1.1.7.3.1.1" style="width:142.3pt;"><span class="ltx_text" id="S3.SS2.tab1.1.7.3.1.1.1" style="font-size:90%;">Identify optimization opportunities by advising indexes, setting knobs, etc.</span></span>
</span>
</td>
</tr>
</table>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<section class="ltx_subsection ltx_figure_panel" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">3.3. </span>Instance-Specific Q&amp;A</h3>
<figure class="ltx_figure" id="S3.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="405" id="S3.F3.g1" src="x3.png" width="831"/>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_figure">Figure 3. </span>Specific Database Instance Dataset Generation</figcaption>
</figure>
<div class="ltx_para" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.1"><span class="ltx_text" id="S3.SS3.p1.1.1" style="font-size:90%;">It is infeasible to construct instance-specific Q&amp;A pairs from online sources. Online queries are almost always incomplete due to privacy reasons, missing necessary instance-level contextual information, such as the database’s table structures, workload information, etc. It is impractical to conduct DB interaction with the specified DB instance referred to in the online query to restore the contextual information. Therefore, we have to generate instance-specific Q&amp;A pairs by LLMs automatically.</span></p>
</div>
<div class="ltx_para" id="S3.SS3.p2">
<p class="ltx_p" id="S3.SS3.p2.1"><span class="ltx_text" id="S3.SS3.p2.1.1" style="font-size:90%;">There are numerous database </span><span class="ltx_text ltx_font_italic" id="S3.SS3.p2.1.2" style="font-size:90%;">tools</span><span class="ltx_text" id="S3.SS3.p2.1.3" style="font-size:90%;"> provided in DBMS that support database monitoring, optimizing and analyzing for DB developers, administrators and analysts. The LLM’s proficiency in answering instance-specific questions relies on whether LLMs can accurately invoke different tools to obtain the instance’s contextual information. Thus, as shown in Figure </span><a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#S3.F3" style="font-size:90%;" title="Figure 3 ‣ 3.3. Instance-Specific Q&amp;A ‣ 3.2. Product-Specific Q&amp;A ‣ 3. DQA Dataset Generation ‣ Revolutionizing Database Q&amp;A with Large Language Models: Comprehensive Benchmark and Evaluation"><span class="ltx_text ltx_ref_tag">3</span></a><span class="ltx_text" id="S3.SS3.p2.1.4" style="font-size:90%;">, our dataset construction workflow starts with building a DB tool pool.</span></p>
</div>
<div class="ltx_para" id="S3.SS3.p3">
<p class="ltx_p" id="S3.SS3.p3.1"><span class="ltx_text ltx_font_bold" id="S3.SS3.p3.1.1" style="font-size:90%;">Step 1: Constructing DB tool pool</span><span class="ltx_text" id="S3.SS3.p3.1.2" style="font-size:90%;">.
(1) We first survey the DB tools commonly used in real-production systems. As shown in Table </span><a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#S3.SS2" style="font-size:90%;" title="3.2. Product-Specific Q&amp;A ‣ 3. DQA Dataset Generation ‣ Revolutionizing Database Q&amp;A with Large Language Models: Comprehensive Benchmark and Evaluation"><span class="ltx_text ltx_ref_tag">3.2</span></a><span class="ltx_text" id="S3.SS3.p3.1.3" style="font-size:90%;">, we identify six types of </span><span class="ltx_text ltx_font_italic" id="S3.SS3.p3.1.4" style="font-size:90%;">common DB tools</span><span class="ltx_text" id="S3.SS3.p3.1.5" style="font-size:90%;"> that are frequently used for data modeling, database monitoring and performance optimization. The implementation of each tool type, including the exact tool name and the format of input and output, may vary for different DBMS products.</span><span class="ltx_note ltx_role_footnote" id="footnote7"><sup class="ltx_note_mark">7</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">7</sup><span class="ltx_tag ltx_tag_note">7</span>Implementation Details on PostgreSQL and OpenGauss are shown in <a class="ltx_ref ltx_href" href="https://github.com/XMUDM/DQABench" title="">[link]</a></span></span></span><span class="ltx_text" id="S3.SS3.p3.1.6" style="font-size:90%;"> (2) The common tools can not cover all DB tools, especially new ones developed to meet the demands of a real-production system. We expand the common tools to a set of </span><span class="ltx_text ltx_font_italic" id="S3.SS3.p3.1.7" style="font-size:90%;">generalization tools</span><span class="ltx_text" id="S3.SS3.p3.1.8" style="font-size:90%;"> to evaluate the Q&amp;A bot’s generalization ability to utilize different DB tools properly. We include scenarios such as Operations Diagnostics, Business Intelligence, Performance Monitoring and Tuning, Data Analysis, System Utilization Analysis, Deployment Issues, Operations Management, Query Optimization, Backup and Recovery, Permission Management, Index Management, and Database Tuning. We require GPT-4 to generate imaginary DB tools that can benefit the above DB scenarios.</span></p>
</div>
<div class="ltx_para" id="S3.SS3.p4">
<p class="ltx_p" id="S3.SS3.p4.1"><span class="ltx_text ltx_font_bold" id="S3.SS3.p4.1.1" style="font-size:90%;">Step 2: Generating questions</span><span class="ltx_text" id="S3.SS3.p4.1.2" style="font-size:90%;">.
For each tool, including common tools and generalization tools, we require GPT-4 to generate questions that can be solved by the target tool using the prompt in Figure </span><a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#S3.F3" style="font-size:90%;" title="Figure 3 ‣ 3.3. Instance-Specific Q&amp;A ‣ 3.2. Product-Specific Q&amp;A ‣ 3. DQA Dataset Generation ‣ Revolutionizing Database Q&amp;A with Large Language Models: Comprehensive Benchmark and Evaluation"><span class="ltx_text ltx_ref_tag">3</span></a><span class="ltx_text" id="S3.SS3.p4.1.3" style="font-size:90%;">.
Moreover, we want to effectively evaluate the Q&amp;A bot’s </span><span class="ltx_text ltx_font_italic" id="S3.SS3.p4.1.4" style="font-size:90%;">planning</span><span class="ltx_text" id="S3.SS3.p4.1.5" style="font-size:90%;"> ability, which involves adequately combining several DB tools and organizing tools with the right action order. Thus, we manually construct 3-4 questions for each common tool and scenario that demand a chain of multiple tool invocations, and we use these questions as few-shot examples to encourage GPT-4 to generate complex questions. We post-process the resulting questions to ensure that more than </span><math alttext="50\%" class="ltx_Math" display="inline" id="S3.SS3.p4.1.m1.1"><semantics id="S3.SS3.p4.1.m1.1a"><mrow id="S3.SS3.p4.1.m1.1.1" xref="S3.SS3.p4.1.m1.1.1.cmml"><mn id="S3.SS3.p4.1.m1.1.1.2" mathsize="90%" xref="S3.SS3.p4.1.m1.1.1.2.cmml">50</mn><mo id="S3.SS3.p4.1.m1.1.1.1" mathsize="90%" xref="S3.SS3.p4.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.1.m1.1b"><apply id="S3.SS3.p4.1.m1.1.1.cmml" xref="S3.SS3.p4.1.m1.1.1"><csymbol cd="latexml" id="S3.SS3.p4.1.m1.1.1.1.cmml" xref="S3.SS3.p4.1.m1.1.1.1">percent</csymbol><cn id="S3.SS3.p4.1.m1.1.1.2.cmml" type="integer" xref="S3.SS3.p4.1.m1.1.1.2">50</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.1.m1.1c">50\%</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p4.1.m1.1d">50 %</annotation></semantics></math><span class="ltx_text" id="S3.SS3.p4.1.6" style="font-size:90%;"> of the generated questions are solved by invoking at least two DB tools.</span></p>
</div>
<div class="ltx_para" id="S3.SS3.p5">
<p class="ltx_p" id="S3.SS3.p5.1"><span class="ltx_text ltx_font_bold" id="S3.SS3.p5.1.1" style="font-size:90%;">Step 3: Generating answers</span><span class="ltx_text" id="S3.SS3.p5.1.2" style="font-size:90%;">. (1) First, we manually produce </span><span class="ltx_text ltx_font_italic" id="S3.SS3.p5.1.3" style="font-size:90%;">answer cases</span><span class="ltx_text" id="S3.SS3.p5.1.4" style="font-size:90%;"> for manually constructed questions above. The DB experts compose the answer cases in the following procedure: construct a real DB instance according to the description in the question, call the DB tools when necessary, and answer the question based on real tool feedback. (2) Then we use the answer cases as few-shot learning examples to guide GPT-4 to generate answers efficiently. We adopt the Chain-Of-Thought(COT) prompting technique to generate an answer for each question.
The prompt </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S3.SS3.p5.1.5.1" style="font-size:90%;">(</span><span class="ltx_text" style="font-size:90%;">Yao et al</span><span class="ltx_text" style="font-size:90%;">.</span><span class="ltx_text" id="S3.SS3.p5.1.6.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#bib.bib41" title=""><span class="ltx_text" style="font-size:90%;">2023</span></a><span class="ltx_text" id="S3.SS3.p5.1.7.3" style="font-size:90%;">)</span></cite><span class="ltx_text" id="S3.SS3.p5.1.8" style="font-size:90%;"> encourages GPT-4 to break down the problem of answer generation into a series of intermediate reasoning steps. Each step corresponds to either tool invocation or answer generation, including “Thought”, “Action,” “Action_Input,” “Observation,” and “answer.” Here, “Thought” is the logical reasoning, “Action” and “Action_Input” are the tool name and the tool’s input, “Observation” is the instance’s information returned by calling the tool. This way, even if errors occur, e.g., GPT-4 produces incorrect actions to trigger the tool or the observation does not simulate the tool’s output, GPT-4 can switch to alternative approaches, resulting in more accurate and reliable answers.</span></p>
</div>
<div class="ltx_para" id="S3.SS3.p6">
<p class="ltx_p" id="S3.SS3.p6.1"><span class="ltx_text ltx_font_bold" id="S3.SS3.p6.1.1" style="font-size:90%;">Step 4: Polishing answers</span><span class="ltx_text" id="S3.SS3.p6.1.2" style="font-size:90%;">. Finally, we ask GPT-4 to rethink and polish the answer. This step is different for common tools and generalization tools. (1) For each answer to common tools, since the common tools are real DB tools with pre-defined formats of tool output, we ask GPT-4 to examine its output to ensure the format of the answer is correct to trigger the tool. (2) For each answer relating to generalization tools, since the generalization tools are imagined and reasonably inferred by GPT-4, they do not have a pre-defined format; we ask GPT-4 to summarize the tool’s format.</span></p>
</div>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section" style="font-size:90%;">
<span class="ltx_tag ltx_tag_section">4. </span><span class="ltx_text ltx_font_bold ltx_font_italic" id="S4.1.1">DQA</span> Testbed</h2>
<figure class="ltx_figure" id="S4.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="357" id="S4.F4.g1" src="x4.png" width="789"/>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_figure">Figure 4. </span>LLM-based Database Q&amp;A Testbed Overview</figcaption>
</figure>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1"><span class="ltx_text" id="S4.p1.1.1" style="font-size:90%;">When adopting a general-purpose LLM for DB Q&amp;A, various auxiliary modules are indispensable to leverage and adapt the LLM’s general knowledge of linguistic patterns and common senses into the DB environment. Currently, there is no complete database Q&amp;A testbed that incorporates LLM and various auxiliary modules. Table </span><a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#S4.T4" style="font-size:90%;" title="Table 4 ‣ 4. DQA Testbed ‣ 3.3. Instance-Specific Q&amp;A ‣ 3.2. Product-Specific Q&amp;A ‣ 3. DQA Dataset Generation ‣ Revolutionizing Database Q&amp;A with Large Language Models: Comprehensive Benchmark and Evaluation"><span class="ltx_text ltx_ref_tag">4</span></a><span class="ltx_text" id="S4.p1.1.2" style="font-size:90%;"> compares the completeness of the proposed testbed with recent LLM adaptation frameworks in the open domain and DB domain. Existing works overlook some important modules. Specifically, without domain continual pre-training and fine-tuning, the LLMs are not able to evolve as new domain-specific topics emerge. Without question routing, the LLMs can become trapped in incorrect logical reasoning paths, e.g., attempting to answer a product-specific problem on its own leads to hallucination while there are product manuals to provide factual groundings. Limited coverage of the DB tools can harm the LLM’s ability as a DB agent. On the contrary, our proposed testbed supports a full chain of auxiliary modules for LLM’s domain adaptation.</span></p>
</div>
<div class="ltx_para" id="S4.p2">
<p class="ltx_p" id="S4.p2.1"><span class="ltx_text" id="S4.p2.1.1" style="font-size:90%;">The workflow of the proposed testbed is shown in Figure </span><a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#S4.F4" style="font-size:90%;" title="Figure 4 ‣ 4. DQA Testbed ‣ 3.3. Instance-Specific Q&amp;A ‣ 3.2. Product-Specific Q&amp;A ‣ 3. DQA Dataset Generation ‣ Revolutionizing Database Q&amp;A with Large Language Models: Comprehensive Benchmark and Evaluation"><span class="ltx_text ltx_ref_tag">4</span></a><span class="ltx_text" id="S4.p2.1.2" style="font-size:90%;">.</span></p>
</div>
<div class="ltx_para" id="S4.p3">
<p class="ltx_p" id="S4.p3.1"><span class="ltx_text ltx_font_bold" id="S4.p3.1.1" style="font-size:90%;">Offline</span><span class="ltx_text" id="S4.p3.1.2" style="font-size:90%;">. Before deployment, the core LLM module goes through the stage of </span><span class="ltx_text ltx_font_italic" id="S4.p3.1.3" style="font-size:90%;">continual pre-training and fine-tuning</span><span class="ltx_text" id="S4.p3.1.4" style="font-size:90%;"> to acquire more specific DB concepts and skills while preserving the LLM’s general linguistic knowledge. The user can also load a knowledge source of documents (usually up-to-date materials that do not appear in the training corpus, or in-house data for privacy reasons) stored in the form of a vectorized database.</span></p>
</div>
<div class="ltx_para" id="S4.p4">
<p class="ltx_p" id="S4.p4.1"><span class="ltx_text ltx_font_bold" id="S4.p4.1.1" style="font-size:90%;">Online</span><span class="ltx_text" id="S4.p4.1.2" style="font-size:90%;">. When the user submits a query, it first goes through the </span><span class="ltx_text ltx_font_italic" id="S4.p4.1.3" style="font-size:90%;">Question Classification Routing</span><span class="ltx_text" id="S4.p4.1.4" style="font-size:90%;"> (QCR) module to determine the logical structure of reasoning an answer. Depending on the result of QCR, i.e., the type of question, it is directed to an appropriate prompt in the </span><span class="ltx_text ltx_font_italic" id="S4.p4.1.5" style="font-size:90%;">Prompt Template Engineering</span><span class="ltx_text" id="S4.p4.1.6" style="font-size:90%;"> (PTE) module. Keywords in the prompt generated by the PTE module will trigger the </span><span class="ltx_text ltx_font_italic" id="S4.p4.1.7" style="font-size:90%;">Retrieval Augmented Generation</span><span class="ltx_text" id="S4.p4.1.8" style="font-size:90%;"> (RAG) or </span><span class="ltx_text ltx_font_italic" id="S4.p4.1.9" style="font-size:90%;">Tool Invocation Generation</span><span class="ltx_text" id="S4.p4.1.10" style="font-size:90%;"> (TIG) module to append to the content of the prompt. For example, if the query is related to a certain DB product, then to mitigate hallucination, the RAG module is triggered to retrieve trusted data and generate more accurate and relevant answers. The process can iterate for a few rounds if needed. For example, if answering the query needs to perform data analysis, the schema tool is first triggered to fetch the table structure of the database. Based on the results output by the schema tool, a selection tool is triggered to execute a SQL selection query, to compute the required data statistics in the database. Finally, the LLM is instructed by the prompt to generate the answer.</span></p>
</div>
<figure class="ltx_table" id="S4.T4">
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 4. </span>Comparison of LLM-based Database QA Solutions. </figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<table class="ltx_tabular ltx_centering ltx_figure_panel ltx_align_middle" id="S4.T4.14">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T4.14.15.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt" id="S4.T4.14.15.1.1">
<span class="ltx_text" id="S4.T4.14.15.1.1.1"></span><span class="ltx_text" id="S4.T4.14.15.1.1.2" style="font-size:90%;"> </span><span class="ltx_text" id="S4.T4.14.15.1.1.3" style="font-size:90%;">
<span class="ltx_tabular ltx_align_middle" id="S4.T4.14.15.1.1.3.1">
<span class="ltx_tr" id="S4.T4.14.15.1.1.3.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T4.14.15.1.1.3.1.1.1"><span class="ltx_text ltx_font_bold" id="S4.T4.14.15.1.1.3.1.1.1.1" style="font-size:89%;">Solution</span></span></span>
</span></span><span class="ltx_text" id="S4.T4.14.15.1.1.4"></span><span class="ltx_text" id="S4.T4.14.15.1.1.5" style="font-size:90%;"></span>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt" id="S4.T4.14.15.1.2">
<span class="ltx_text" id="S4.T4.14.15.1.2.1"></span><span class="ltx_text" id="S4.T4.14.15.1.2.2" style="font-size:90%;"> </span><span class="ltx_text" id="S4.T4.14.15.1.2.3" style="font-size:90%;">
<span class="ltx_tabular ltx_align_middle" id="S4.T4.14.15.1.2.3.1">
<span class="ltx_tr" id="S4.T4.14.15.1.2.3.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T4.14.15.1.2.3.1.1.1"><span class="ltx_text ltx_font_bold" id="S4.T4.14.15.1.2.3.1.1.1.1" style="font-size:89%;">Pre-</span></span></span>
<span class="ltx_tr" id="S4.T4.14.15.1.2.3.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T4.14.15.1.2.3.1.2.1"><span class="ltx_text ltx_font_bold" id="S4.T4.14.15.1.2.3.1.2.1.1" style="font-size:89%;">training</span></span></span>
</span></span><span class="ltx_text" id="S4.T4.14.15.1.2.4"></span><span class="ltx_text" id="S4.T4.14.15.1.2.5" style="font-size:90%;"></span>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt" id="S4.T4.14.15.1.3">
<span class="ltx_text" id="S4.T4.14.15.1.3.1"></span><span class="ltx_text" id="S4.T4.14.15.1.3.2" style="font-size:90%;"> </span><span class="ltx_text" id="S4.T4.14.15.1.3.3" style="font-size:90%;">
<span class="ltx_tabular ltx_align_middle" id="S4.T4.14.15.1.3.3.1">
<span class="ltx_tr" id="S4.T4.14.15.1.3.3.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T4.14.15.1.3.3.1.1.1"><span class="ltx_text ltx_font_bold" id="S4.T4.14.15.1.3.3.1.1.1.1" style="font-size:89%;">Fine-</span></span></span>
<span class="ltx_tr" id="S4.T4.14.15.1.3.3.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T4.14.15.1.3.3.1.2.1"><span class="ltx_text ltx_font_bold" id="S4.T4.14.15.1.3.3.1.2.1.1" style="font-size:89%;">tuning</span></span></span>
</span></span><span class="ltx_text" id="S4.T4.14.15.1.3.4"></span><span class="ltx_text" id="S4.T4.14.15.1.3.5" style="font-size:90%;"></span>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt" id="S4.T4.14.15.1.4">
<span class="ltx_text" id="S4.T4.14.15.1.4.1"></span><span class="ltx_text" id="S4.T4.14.15.1.4.2" style="font-size:90%;"> </span><span class="ltx_text" id="S4.T4.14.15.1.4.3" style="font-size:90%;">
<span class="ltx_tabular ltx_align_middle" id="S4.T4.14.15.1.4.3.1">
<span class="ltx_tr" id="S4.T4.14.15.1.4.3.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T4.14.15.1.4.3.1.1.1"><span class="ltx_text ltx_font_bold" id="S4.T4.14.15.1.4.3.1.1.1.1" style="font-size:89%;">Question</span></span></span>
<span class="ltx_tr" id="S4.T4.14.15.1.4.3.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T4.14.15.1.4.3.1.2.1"><span class="ltx_text ltx_font_bold" id="S4.T4.14.15.1.4.3.1.2.1.1" style="font-size:89%;">Routing</span></span></span>
</span></span><span class="ltx_text" id="S4.T4.14.15.1.4.4"></span><span class="ltx_text" id="S4.T4.14.15.1.4.5" style="font-size:90%;"></span>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt" id="S4.T4.14.15.1.5">
<span class="ltx_text" id="S4.T4.14.15.1.5.1"></span><span class="ltx_text" id="S4.T4.14.15.1.5.2" style="font-size:90%;"> </span><span class="ltx_text" id="S4.T4.14.15.1.5.3" style="font-size:90%;">
<span class="ltx_tabular ltx_align_middle" id="S4.T4.14.15.1.5.3.1">
<span class="ltx_tr" id="S4.T4.14.15.1.5.3.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T4.14.15.1.5.3.1.1.1"><span class="ltx_text ltx_font_bold" id="S4.T4.14.15.1.5.3.1.1.1.1" style="font-size:89%;">Retrieval</span></span></span>
<span class="ltx_tr" id="S4.T4.14.15.1.5.3.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T4.14.15.1.5.3.1.2.1"><span class="ltx_text ltx_font_bold" id="S4.T4.14.15.1.5.3.1.2.1.1" style="font-size:89%;">Augment</span></span></span>
</span></span><span class="ltx_text" id="S4.T4.14.15.1.5.4"></span><span class="ltx_text" id="S4.T4.14.15.1.5.5" style="font-size:90%;"></span>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S4.T4.14.15.1.6">
<span class="ltx_text" id="S4.T4.14.15.1.6.1"></span><span class="ltx_text" id="S4.T4.14.15.1.6.2" style="font-size:90%;"> </span><span class="ltx_text" id="S4.T4.14.15.1.6.3" style="font-size:90%;">
<span class="ltx_tabular ltx_align_middle" id="S4.T4.14.15.1.6.3.1">
<span class="ltx_tr" id="S4.T4.14.15.1.6.3.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T4.14.15.1.6.3.1.1.1"><span class="ltx_text ltx_font_bold" id="S4.T4.14.15.1.6.3.1.1.1.1" style="font-size:89%;">Tool/</span></span></span>
<span class="ltx_tr" id="S4.T4.14.15.1.6.3.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T4.14.15.1.6.3.1.2.1"><span class="ltx_text ltx_font_bold" id="S4.T4.14.15.1.6.3.1.2.1.1" style="font-size:89%;">Agent</span></span></span>
</span></span><span class="ltx_text" id="S4.T4.14.15.1.6.4"></span><span class="ltx_text" id="S4.T4.14.15.1.6.5" style="font-size:90%;"></span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T4.2.2">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T4.2.2.3"><span class="ltx_text" id="S4.T4.2.2.3.1" style="font-size:90%;">LLM-only</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T4.1.1.1"><math alttext="\checkmark" class="ltx_Math" display="inline" id="S4.T4.1.1.1.m1.1"><semantics id="S4.T4.1.1.1.m1.1a"><mi id="S4.T4.1.1.1.m1.1.1" mathsize="90%" mathvariant="normal" xref="S4.T4.1.1.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S4.T4.1.1.1.m1.1b"><ci id="S4.T4.1.1.1.m1.1.1.cmml" xref="S4.T4.1.1.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.1.1.1.m1.1c">\checkmark</annotation><annotation encoding="application/x-llamapun" id="S4.T4.1.1.1.m1.1d">✓</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T4.2.2.2"><math alttext="\checkmark" class="ltx_Math" display="inline" id="S4.T4.2.2.2.m1.1"><semantics id="S4.T4.2.2.2.m1.1a"><mi id="S4.T4.2.2.2.m1.1.1" mathsize="90%" mathvariant="normal" xref="S4.T4.2.2.2.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S4.T4.2.2.2.m1.1b"><ci id="S4.T4.2.2.2.m1.1.1.cmml" xref="S4.T4.2.2.2.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.2.2.2.m1.1c">\checkmark</annotation><annotation encoding="application/x-llamapun" id="S4.T4.2.2.2.m1.1d">✓</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T4.2.2.4"><span class="ltx_text ltx_font_sansserif" id="S4.T4.2.2.4.1" style="font-size:90%;">X</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T4.2.2.5"><span class="ltx_text ltx_font_sansserif" id="S4.T4.2.2.5.1" style="font-size:90%;">X</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.2.2.6"><span class="ltx_text ltx_font_sansserif" id="S4.T4.2.2.6.1" style="font-size:90%;">X</span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.4.4">
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T4.4.4.3">
<span class="ltx_text" id="S4.T4.4.4.3.1" style="font-size:90%;">Langchain </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S4.T4.4.4.3.2.1" style="font-size:90%;">(</span><span class="ltx_text" style="font-size:90%;">Chase</span><span class="ltx_text" id="S4.T4.4.4.3.3.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#bib.bib6" title=""><span class="ltx_text" style="font-size:90%;">2022</span></a><span class="ltx_text" id="S4.T4.4.4.3.4.3" style="font-size:90%;">)</span></cite>
</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T4.4.4.4"><span class="ltx_text ltx_font_sansserif" id="S4.T4.4.4.4.1" style="font-size:90%;">X</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T4.4.4.5"><span class="ltx_text ltx_font_sansserif" id="S4.T4.4.4.5.1" style="font-size:90%;">X</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T4.4.4.6"><span class="ltx_text ltx_font_sansserif" id="S4.T4.4.4.6.1" style="font-size:90%;">X</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T4.3.3.1"><math alttext="\checkmark" class="ltx_Math" display="inline" id="S4.T4.3.3.1.m1.1"><semantics id="S4.T4.3.3.1.m1.1a"><mi id="S4.T4.3.3.1.m1.1.1" mathsize="90%" mathvariant="normal" xref="S4.T4.3.3.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S4.T4.3.3.1.m1.1b"><ci id="S4.T4.3.3.1.m1.1.1.cmml" xref="S4.T4.3.3.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.3.3.1.m1.1c">\checkmark</annotation><annotation encoding="application/x-llamapun" id="S4.T4.3.3.1.m1.1d">✓</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S4.T4.4.4.2"><span class="ltx_text ltx_font_sansserif" id="S4.T4.4.4.2.1" style="font-size:90%;">X<sup class="ltx_sup" id="S4.T4.4.4.2.1.1"><span class="ltx_text ltx_font_serif ltx_font_italic" id="S4.T4.4.4.2.1.1.1">∗</span></sup></span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.6.6">
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T4.6.6.3">
<span class="ltx_text" id="S4.T4.6.6.3.1" style="font-size:90%;">D-bot </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S4.T4.6.6.3.2.1" style="font-size:90%;">(</span><span class="ltx_text" style="font-size:90%;">Zhou et al</span><span class="ltx_text" style="font-size:90%;">.</span><span class="ltx_text" id="S4.T4.6.6.3.3.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#bib.bib48" title=""><span class="ltx_text" style="font-size:90%;">2024a</span></a><span class="ltx_text" id="S4.T4.6.6.3.4.3" style="font-size:90%;">)</span></cite>
</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T4.6.6.4"><span class="ltx_text ltx_font_sansserif" id="S4.T4.6.6.4.1" style="font-size:90%;">X</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T4.6.6.5"><span class="ltx_text ltx_font_sansserif" id="S4.T4.6.6.5.1" style="font-size:90%;">X</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T4.6.6.6"><span class="ltx_text ltx_font_sansserif" id="S4.T4.6.6.6.1" style="font-size:90%;">X</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T4.5.5.1"><math alttext="\checkmark" class="ltx_Math" display="inline" id="S4.T4.5.5.1.m1.1"><semantics id="S4.T4.5.5.1.m1.1a"><mi id="S4.T4.5.5.1.m1.1.1" mathsize="90%" mathvariant="normal" xref="S4.T4.5.5.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S4.T4.5.5.1.m1.1b"><ci id="S4.T4.5.5.1.m1.1.1.cmml" xref="S4.T4.5.5.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.5.5.1.m1.1c">\checkmark</annotation><annotation encoding="application/x-llamapun" id="S4.T4.5.5.1.m1.1d">✓</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S4.T4.6.6.2"><span class="ltx_text ltx_font_sansserif" id="S4.T4.6.6.2.1" style="font-size:90%;">X<sup class="ltx_sup" id="S4.T4.6.6.2.1.1"><span class="ltx_text ltx_font_serif ltx_font_italic" id="S4.T4.6.6.2.1.1.1">⋆</span></sup></span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.9.9">
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T4.9.9.4">
<span class="ltx_text" id="S4.T4.9.9.4.1" style="font-size:90%;">DB-GPT </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S4.T4.9.9.4.2.1" style="font-size:90%;">(</span><span class="ltx_text" style="font-size:90%;">Xue et al</span><span class="ltx_text" style="font-size:90%;">.</span><span class="ltx_text" id="S4.T4.9.9.4.3.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#bib.bib38" title=""><span class="ltx_text" style="font-size:90%;">2023</span></a><span class="ltx_text" id="S4.T4.9.9.4.4.3" style="font-size:90%;">)</span></cite>
</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T4.9.9.5"><span class="ltx_text ltx_font_sansserif" id="S4.T4.9.9.5.1" style="font-size:90%;">X</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T4.7.7.1"><math alttext="\checkmark" class="ltx_Math" display="inline" id="S4.T4.7.7.1.m1.1"><semantics id="S4.T4.7.7.1.m1.1a"><mi id="S4.T4.7.7.1.m1.1.1" mathsize="90%" mathvariant="normal" xref="S4.T4.7.7.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S4.T4.7.7.1.m1.1b"><ci id="S4.T4.7.7.1.m1.1.1.cmml" xref="S4.T4.7.7.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.7.7.1.m1.1c">\checkmark</annotation><annotation encoding="application/x-llamapun" id="S4.T4.7.7.1.m1.1d">✓</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T4.9.9.6"><span class="ltx_text ltx_font_sansserif" id="S4.T4.9.9.6.1" style="font-size:90%;">X</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T4.8.8.2"><math alttext="\checkmark" class="ltx_Math" display="inline" id="S4.T4.8.8.2.m1.1"><semantics id="S4.T4.8.8.2.m1.1a"><mi id="S4.T4.8.8.2.m1.1.1" mathsize="90%" mathvariant="normal" xref="S4.T4.8.8.2.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S4.T4.8.8.2.m1.1b"><ci id="S4.T4.8.8.2.m1.1.1.cmml" xref="S4.T4.8.8.2.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.8.8.2.m1.1c">\checkmark</annotation><annotation encoding="application/x-llamapun" id="S4.T4.8.8.2.m1.1d">✓</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S4.T4.9.9.3"><span class="ltx_text ltx_font_sansserif" id="S4.T4.9.9.3.1" style="font-size:90%;">X<sup class="ltx_sup" id="S4.T4.9.9.3.1.1"><span class="ltx_text ltx_font_serif ltx_font_italic" id="S4.T4.9.9.3.1.1.1">⋆</span></sup></span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.14.14">
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S4.T4.14.14.6"><span class="ltx_text ltx_font_bold" id="S4.T4.14.14.6.1" style="font-size:90%;">Ours</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S4.T4.10.10.1"><math alttext="\checkmark" class="ltx_Math" display="inline" id="S4.T4.10.10.1.m1.1"><semantics id="S4.T4.10.10.1.m1.1a"><mi id="S4.T4.10.10.1.m1.1.1" mathsize="90%" mathvariant="normal" xref="S4.T4.10.10.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S4.T4.10.10.1.m1.1b"><ci id="S4.T4.10.10.1.m1.1.1.cmml" xref="S4.T4.10.10.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.10.10.1.m1.1c">\checkmark</annotation><annotation encoding="application/x-llamapun" id="S4.T4.10.10.1.m1.1d">✓</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S4.T4.11.11.2"><math alttext="\checkmark" class="ltx_Math" display="inline" id="S4.T4.11.11.2.m1.1"><semantics id="S4.T4.11.11.2.m1.1a"><mi id="S4.T4.11.11.2.m1.1.1" mathsize="90%" mathvariant="normal" xref="S4.T4.11.11.2.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S4.T4.11.11.2.m1.1b"><ci id="S4.T4.11.11.2.m1.1.1.cmml" xref="S4.T4.11.11.2.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.11.11.2.m1.1c">\checkmark</annotation><annotation encoding="application/x-llamapun" id="S4.T4.11.11.2.m1.1d">✓</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S4.T4.12.12.3"><math alttext="\checkmark" class="ltx_Math" display="inline" id="S4.T4.12.12.3.m1.1"><semantics id="S4.T4.12.12.3.m1.1a"><mi id="S4.T4.12.12.3.m1.1.1" mathsize="90%" mathvariant="normal" xref="S4.T4.12.12.3.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S4.T4.12.12.3.m1.1b"><ci id="S4.T4.12.12.3.m1.1.1.cmml" xref="S4.T4.12.12.3.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.12.12.3.m1.1c">\checkmark</annotation><annotation encoding="application/x-llamapun" id="S4.T4.12.12.3.m1.1d">✓</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S4.T4.13.13.4"><math alttext="\checkmark" class="ltx_Math" display="inline" id="S4.T4.13.13.4.m1.1"><semantics id="S4.T4.13.13.4.m1.1a"><mi id="S4.T4.13.13.4.m1.1.1" mathsize="90%" mathvariant="normal" xref="S4.T4.13.13.4.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S4.T4.13.13.4.m1.1b"><ci id="S4.T4.13.13.4.m1.1.1.cmml" xref="S4.T4.13.13.4.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.13.13.4.m1.1c">\checkmark</annotation><annotation encoding="application/x-llamapun" id="S4.T4.13.13.4.m1.1d">✓</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T4.14.14.5"><math alttext="\checkmark" class="ltx_Math" display="inline" id="S4.T4.14.14.5.m1.1"><semantics id="S4.T4.14.14.5.m1.1a"><mi id="S4.T4.14.14.5.m1.1.1" mathsize="90%" mathvariant="normal" xref="S4.T4.14.14.5.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S4.T4.14.14.5.m1.1b"><ci id="S4.T4.14.14.5.m1.1.1.cmml" xref="S4.T4.14.14.5.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.14.14.5.m1.1c">\checkmark</annotation><annotation encoding="application/x-llamapun" id="S4.T4.14.14.5.m1.1d">✓</annotation></semantics></math></td>
</tr>
</tbody>
</table>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p class="ltx_p ltx_figure_panel ltx_parbox ltx_align_center ltx_align_middle" id="S4.T4.17.3" style="width:411.9pt;"><span class="ltx_text ltx_font_bold" id="S4.T4.17.3.3" style="font-size:90%;">Note:</span><span class="ltx_text" id="S4.T4.17.3.4" style="font-size:90%;"> </span><math alttext="\checkmark" class="ltx_Math" display="inline" id="S4.T4.15.1.m1.1"><semantics id="S4.T4.15.1.m1.1a"><mi id="S4.T4.15.1.m1.1.1" mathsize="90%" mathvariant="normal" xref="S4.T4.15.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S4.T4.15.1.m1.1b"><ci id="S4.T4.15.1.m1.1.1.cmml" xref="S4.T4.15.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.15.1.m1.1c">\checkmark</annotation><annotation encoding="application/x-llamapun" id="S4.T4.15.1.m1.1d">✓</annotation></semantics></math><span class="ltx_text" id="S4.T4.17.3.5" style="font-size:90%;">: fully supports the component. </span><span class="ltx_text ltx_font_sansserif" id="S4.T4.17.3.6" style="font-size:90%;">X</span><span class="ltx_text" id="S4.T4.17.3.7" style="font-size:90%;">: lacks functionality completely. </span><span class="ltx_text ltx_font_sansserif" id="S4.T4.16.2.1" style="font-size:90%;">X<sup class="ltx_sup" id="S4.T4.16.2.1.1"><span class="ltx_text ltx_font_serif ltx_font_italic" id="S4.T4.16.2.1.1.1">∗</span></sup></span><span class="ltx_text" id="S4.T4.17.3.8" style="font-size:90%;">: DB tools need to be customized in the Langchain framework. </span><span class="ltx_text ltx_font_sansserif" id="S4.T4.17.3.2" style="font-size:90%;">X<sup class="ltx_sup" id="S4.T4.17.3.2.1"><span class="ltx_text ltx_font_serif ltx_font_italic" id="S4.T4.17.3.2.1.1">⋆</span></sup></span><span class="ltx_text" id="S4.T4.17.3.9" style="font-size:90%;">: limited support, D-bot focuses on data interaction issues, and DB-GPT focuses on database operational diagnosis.</span></p>
</div>
</div>
</figure>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">4.1. </span>Pre-training and Fine-tuning</h3>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1"><span class="ltx_text ltx_font_italic" id="S4.SS1.p1.1.1" style="font-size:90%;">Pre-training</span><span class="ltx_text" id="S4.SS1.p1.1.2" style="font-size:90%;">. To enhance the model’s expertise in the database domain, we first continue the pre-training of the backbone model.
Specifically, we extensively collect pre-training corpora related to databases, comprising approximately 47,000 entries each in Chinese and English, totaling around 100 million tokens. This corpus includes major database textbooks, official documentation of various database products, and selected authoritative reports and articles on databases.
For the preparation of our pre-training, we conduct a cleaning and deduplication process on the collected pre-training data. Subsequently, we process the data into text blocks containing 4096 tokens each, which are then fed into the backbone for continual pre-training. This training phase effectively enriches the model’s knowledge in the database field and lays a solid foundation for subsequent fine-tuning.</span></p>
</div>
<div class="ltx_para" id="S4.SS1.p2">
<p class="ltx_p" id="S4.SS1.p2.1"><span class="ltx_text ltx_font_italic" id="S4.SS1.p2.1.1" style="font-size:90%;">Fine-tuning</span><span class="ltx_text" id="S4.SS1.p2.1.2" style="font-size:90%;">. To improve the LLM’s ability to follow instructions and solve DB-specific tasks, we propose a sequential fine-tuning strategy, including three stages. We prioritize the fine-tuning sequence based on the crucial abilities in DB problem-solving. For instance, the first fine-tuning stage focuses on enhancing the LLM’s NL2SQL and table understanding ability using NL2SQL data like Spider </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S4.SS1.p2.1.3.1" style="font-size:90%;">(</span><span class="ltx_text" style="font-size:90%;">Yu et al</span><span class="ltx_text" style="font-size:90%;">.</span><span class="ltx_text" id="S4.SS1.p2.1.4.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#bib.bib42" title=""><span class="ltx_text" style="font-size:90%;">2018</span></a><span class="ltx_text" id="S4.SS1.p2.1.5.3" style="font-size:90%;">)</span></cite><span class="ltx_text" id="S4.SS1.p2.1.6" style="font-size:90%;"> because it is fundamental in DB tasks. In the second fine-tuning stage, a mixture of different fine-tuning data is adopted. The fine-tuning data includes (1) general conversational datasets like Stanford Alpaca </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S4.SS1.p2.1.7.1" style="font-size:90%;">(</span><span class="ltx_text" style="font-size:90%;">Taori et al</span><span class="ltx_text" style="font-size:90%;">.</span><span class="ltx_text" id="S4.SS1.p2.1.8.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#bib.bib31" title=""><span class="ltx_text" style="font-size:90%;">2023</span></a><span class="ltx_text" id="S4.SS1.p2.1.9.3" style="font-size:90%;">)</span></cite><span class="ltx_text" id="S4.SS1.p2.1.10" style="font-size:90%;"> to mitigate the LLM’s forgetting of general dialogue skills, and (2) reformulated questions from </span><span class="ltx_text ltx_font_bold ltx_font_italic" id="S4.SS1.p2.1.11" style="font-size:90%;">DQA</span><span class="ltx_text" id="S4.SS1.p2.1.12" style="font-size:90%;"> using corresponding prompts in the PTE module to enhance the LLM’s understanding of the prompt template. The last fine-tuning stage focuses on enhancing the alignment of LLM’s final response with DB experts in terms of quality and format, by using answer cases written by DB experts in Section </span><a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#S3" style="font-size:90%;" title="3. DQA Dataset Generation ‣ Revolutionizing Database Q&amp;A with Large Language Models: Comprehensive Benchmark and Evaluation"><span class="ltx_text ltx_ref_tag">3</span></a><span class="ltx_text" id="S4.SS1.p2.1.13" style="font-size:90%;">. The specific settings will be detailed in Section </span><a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#S6" style="font-size:90%;" title="6. Experiment ‣ 5.2. End-to-End Evaluation ‣ 5. DQA Evaluation Pipeline ‣ 4.5. Tool Invocation Generation ‣ 4. DQA Testbed ‣ 3.3. Instance-Specific Q&amp;A ‣ 3.2. Product-Specific Q&amp;A ‣ 3. DQA Dataset Generation ‣ Revolutionizing Database Q&amp;A with Large Language Models: Comprehensive Benchmark and Evaluation"><span class="ltx_text ltx_ref_tag">6</span></a><span class="ltx_text" id="S4.SS1.p2.1.14" style="font-size:90%;">.</span></p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">4.2. </span>Question Classification Routing</h3>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1"><span class="ltx_text" id="S4.SS2.p1.1.1" style="font-size:90%;">The Question Classification Routing (QCR) module is designed to automatically categorize user queries and route them to different customized prompt templates. We categorize the questions into 5 categories: general database-related inquiries, product-specific inquiries, instance-specific inquiries, unsafe inquiries, and other inquiries not related to the aforementioned categories. In this paper, we implement three methods of QCR modules.</span></p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS2.p2">
<p class="ltx_p" id="S4.SS2.p2.1"><span class="ltx_text ltx_font_bold" id="S4.SS2.p2.1.1" style="font-size:90%;">(1) LLM-based Classification Method.</span><span class="ltx_text" id="S4.SS2.p2.1.2" style="font-size:90%;"> We use a prompt, which is designed to elicit a classification response from GPT-4. </span><span class="ltx_note ltx_role_footnote" id="footnote8"><sup class="ltx_note_mark">8</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">8</sup><span class="ltx_tag ltx_tag_note">8</span>The query prompt can be found on <a class="ltx_ref ltx_href" href="https://github.com/XMUDM/DQABench" title="">[link]</a></span></span></span><span class="ltx_text" id="S4.SS2.p2.1.3" style="font-size:90%;"></span></p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS2.p3">
<p class="ltx_p" id="S4.SS2.p3.1"><span class="ltx_text ltx_font_bold" id="S4.SS2.p3.1.1" style="font-size:90%;">(2) Classifier.</span><span class="ltx_text" id="S4.SS2.p3.1.2" style="font-size:90%;"> We train an XLNet-based </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S4.SS2.p3.1.3.1" style="font-size:90%;">(</span><span class="ltx_text" style="font-size:90%;">Yang et al</span><span class="ltx_text" style="font-size:90%;">.</span><span class="ltx_text" id="S4.SS2.p3.1.4.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#bib.bib40" title=""><span class="ltx_text" style="font-size:90%;">2019</span></a><span class="ltx_text" id="S4.SS2.p3.1.5.3" style="font-size:90%;">)</span></cite><span class="ltx_text" id="S4.SS2.p3.1.6" style="font-size:90%;"> classifier. We construct the training data</span><span class="ltx_note ltx_role_footnote" id="footnote9"><sup class="ltx_note_mark">9</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">9</sup><span class="ltx_tag ltx_tag_note">9</span>The sources and statistics of the dataset for these classifiers are detailed in <a class="ltx_ref ltx_href" href="https://github.com/XMUDM/DQABench" title="">[link]</a>.</span></span></span><span class="ltx_text" id="S4.SS2.p3.1.7" style="font-size:90%;"> where each question is labeled as “unsafe”, “safe but irrelevant”, “DB general”, “product-specific”, or “instance-specific”. The positive samples for the “unsafe” category are collected from Safety-Prompts </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S4.SS2.p3.1.8.1" style="font-size:90%;">(</span><span class="ltx_text" style="font-size:90%;">Sun et al</span><span class="ltx_text" style="font-size:90%;">.</span><span class="ltx_text" id="S4.SS2.p3.1.9.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#bib.bib29" title=""><span class="ltx_text" style="font-size:90%;">2023b</span></a><span class="ltx_text" id="S4.SS2.p3.1.10.3" style="font-size:90%;">)</span></cite><span class="ltx_text" id="S4.SS2.p3.1.11" style="font-size:90%;"> and BeaverTails-Evaluation </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S4.SS2.p3.1.12.1" style="font-size:90%;">(</span><span class="ltx_text" style="font-size:90%;">Ji et al</span><span class="ltx_text" style="font-size:90%;">.</span><span class="ltx_text" id="S4.SS2.p3.1.13.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#bib.bib15" title=""><span class="ltx_text" style="font-size:90%;">2023</span></a><span class="ltx_text" id="S4.SS2.p3.1.14.3" style="font-size:90%;">)</span></cite><span class="ltx_text" id="S4.SS2.p3.1.15" style="font-size:90%;">. The “safe but irrelevant” samples are collected from Alpaca </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S4.SS2.p3.1.16.1" style="font-size:90%;">(</span><span class="ltx_text" style="font-size:90%;">Taori et al</span><span class="ltx_text" style="font-size:90%;">.</span><span class="ltx_text" id="S4.SS2.p3.1.17.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#bib.bib31" title=""><span class="ltx_text" style="font-size:90%;">2023</span></a><span class="ltx_text" id="S4.SS2.p3.1.18.3" style="font-size:90%;">)</span></cite><span class="ltx_text" id="S4.SS2.p3.1.19" style="font-size:90%;"> and Longbench </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S4.SS2.p3.1.20.1" style="font-size:90%;">(</span><span class="ltx_text" style="font-size:90%;">Bai et al</span><span class="ltx_text" style="font-size:90%;">.</span><span class="ltx_text" id="S4.SS2.p3.1.21.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#bib.bib4" title=""><span class="ltx_text" style="font-size:90%;">2023b</span></a><span class="ltx_text" id="S4.SS2.p3.1.22.3" style="font-size:90%;">)</span></cite><span class="ltx_text" id="S4.SS2.p3.1.23" style="font-size:90%;">. The rest three categories are from the training set of </span><span class="ltx_text ltx_font_bold ltx_font_italic" id="S4.SS2.p3.1.24" style="font-size:90%;">DQA</span><span class="ltx_text" id="S4.SS2.p3.1.25" style="font-size:90%;"> (which does not overlap with the test set used in Section </span><a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#S6" style="font-size:90%;" title="6. Experiment ‣ 5.2. End-to-End Evaluation ‣ 5. DQA Evaluation Pipeline ‣ 4.5. Tool Invocation Generation ‣ 4. DQA Testbed ‣ 3.3. Instance-Specific Q&amp;A ‣ 3.2. Product-Specific Q&amp;A ‣ 3. DQA Dataset Generation ‣ Revolutionizing Database Q&amp;A with Large Language Models: Comprehensive Benchmark and Evaluation"><span class="ltx_text ltx_ref_tag">6</span></a><span class="ltx_text" id="S4.SS2.p3.1.26" style="font-size:90%;">).</span></p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS2.p4">
<p class="ltx_p" id="S4.SS2.p4.1"><span class="ltx_text ltx_font_bold" id="S4.SS2.p4.1.1" style="font-size:90%;">(3) Hierarchical Classifier.</span><span class="ltx_text" id="S4.SS2.p4.1.2" style="font-size:90%;"> Training a single function to predict all possible labels is more difficult. Furthermore, a “flat” classifier method requires a balanced amount of training queries for each class. Alternatively, we train a hierarchical classifier, which first classifies safe and unsafe questions and then classifies the safe questions into four sub-classes. We use an independent XLNet-based </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S4.SS2.p4.1.3.1" style="font-size:90%;">(</span><span class="ltx_text" style="font-size:90%;">Yang et al</span><span class="ltx_text" style="font-size:90%;">.</span><span class="ltx_text" id="S4.SS2.p4.1.4.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#bib.bib40" title=""><span class="ltx_text" style="font-size:90%;">2019</span></a><span class="ltx_text" id="S4.SS2.p4.1.5.3" style="font-size:90%;">)</span></cite><span class="ltx_text" id="S4.SS2.p4.1.6" style="font-size:90%;"> classifier at each level.</span></p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">4.3. </span>Prompt Template Engineering</h3>
<div class="ltx_para" id="S4.SS3.p1">
<p class="ltx_p" id="S4.SS3.p1.1"><span class="ltx_text" id="S4.SS3.p1.1.1" style="font-size:90%;">The Prompt Template Engineering (PTE) module contains customized prompt templates for various categories of queries. The template comprises with slot expressed as “{{}}” that can be appended. Keywords in the prompt templates can activate other modules to append the slot. For instance. Specifically, the used templates are as follows:</span></p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS3.p2">
<p class="ltx_p" id="S4.SS3.p2.1"><span class="ltx_text ltx_font_bold" id="S4.SS3.p2.1.1" style="font-size:90%;">(1) General Knowledge Q&amp;A.</span><span class="ltx_text" id="S4.SS3.p2.1.2" style="font-size:90%;"> Defined as follows:</span></p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS3.p3">
<svg class="ltx_picture" height="57.47" id="S4.SS3.p3.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,57.47) matrix(1 0 0 -1 0 0)"><g fill="#000000" fill-opacity="1.0"><path d="M 0 0 L 0 57.47 L 600 57.47 L 600 0 Z" style="stroke:none"></path></g><g fill="#FFFFFF" fill-opacity="1.0"><path d="M 1.97 1.97 L 1.97 55.5 L 598.03 55.5 L 598.03 1.97 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 5.91 5.91)"><foreignobject color="#000000" height="45.66" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="588.19">
<span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="S4.SS3.p3.pic1.1.1.1.1.1" style="width:425.1pt;">
<span class="ltx_p" id="S4.SS3.p3.pic1.1.1.1.1.1.1"><span class="ltx_text" id="S4.SS3.p3.pic1.1.1.1.1.1.1.1" style="font-size:90%;">You are an expert in the field of general database issues, which do not involve
specific database instances.
Do not allow any fabrications to be added to the answer. Please provide a specific
and detailed response, for example, including the exact commands or code needed by
the user.</span></span>
<span class="ltx_p" id="S4.SS3.p3.pic1.1.1.1.1.1.2"><span class="ltx_text" id="S4.SS3.p3.pic1.1.1.1.1.1.2.1" style="font-size:90%;">Question:</span><span class="ltx_text ltx_font_typewriter" id="S4.SS3.p3.pic1.1.1.1.1.1.2.2" style="font-size:90%;">{{Q}}</span><span class="ltx_text" id="S4.SS3.p3.pic1.1.1.1.1.1.2.3" style="font-size:90%;"></span></span>
</span></foreignobject></g></g></svg>
</div>
<div class="ltx_para" id="S4.SS3.p4">
<p class="ltx_p" id="S4.SS3.p4.1"><span class="ltx_text" id="S4.SS3.p4.1.1" style="font-size:90%;">Here, the slot </span><span class="ltx_text ltx_font_typewriter" id="S4.SS3.p4.1.2" style="font-size:90%;">{{Q}}</span><span class="ltx_text" id="S4.SS3.p4.1.3" style="font-size:90%;"> is to be filled by the query content.</span></p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS3.p5">
<p class="ltx_p" id="S4.SS3.p5.1"><span class="ltx_text ltx_font_bold" id="S4.SS3.p5.1.1" style="font-size:90%;">(2) Product-specific Q&amp;A.</span><span class="ltx_text" id="S4.SS3.p5.1.2" style="font-size:90%;"> Defined as follows:</span></p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS3.p6">
<svg class="ltx_picture" height="57.47" id="S4.SS3.p6.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,57.47) matrix(1 0 0 -1 0 0)"><g fill="#000000" fill-opacity="1.0"><path d="M 0 0 L 0 57.47 L 600 57.47 L 600 0 Z" style="stroke:none"></path></g><g fill="#FFFFFF" fill-opacity="1.0"><path d="M 1.97 1.97 L 1.97 55.5 L 598.03 55.5 L 598.03 1.97 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 5.91 5.91)"><foreignobject color="#000000" height="45.66" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="588.19">
<span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="S4.SS3.p6.pic1.1.1.1.1.1" style="width:425.1pt;">
<span class="ltx_p" id="S4.SS3.p6.pic1.1.1.1.1.1.1"><span class="ltx_text" id="S4.SS3.p6.pic1.1.1.1.1.1.1.1" style="font-size:90%;">You are an expert in the field of database issues, which are related to specific databases. Answer questions in a concise and professional manner based on the information in “Knowledge”, which is from database documents. Do not allow any fabrications to be added to the answer.</span></span>
<span class="ltx_p" id="S4.SS3.p6.pic1.1.1.1.1.1.2"><span class="ltx_text" id="S4.SS3.p6.pic1.1.1.1.1.1.2.1" style="font-size:90%;">Question: </span><span class="ltx_text ltx_font_typewriter" id="S4.SS3.p6.pic1.1.1.1.1.1.2.2" style="font-size:90%;">{{Q}}</span><span class="ltx_text" id="S4.SS3.p6.pic1.1.1.1.1.1.2.3" style="font-size:90%;"> ; Knowledge:</span><span class="ltx_text ltx_font_typewriter" id="S4.SS3.p6.pic1.1.1.1.1.1.2.4" style="font-size:90%;">{{K}}</span><span class="ltx_text" id="S4.SS3.p6.pic1.1.1.1.1.1.2.5" style="font-size:90%;"></span></span>
</span></foreignobject></g></g></svg>
</div>
<div class="ltx_para" id="S4.SS3.p7">
<p class="ltx_p" id="S4.SS3.p7.1"><span class="ltx_text" id="S4.SS3.p7.1.1" style="font-size:90%;">Here, the keyword “Knowledge” can trigger the RAG module, and the retrieved text block will be appended to the slot </span><span class="ltx_text ltx_font_typewriter" id="S4.SS3.p7.1.2" style="font-size:90%;">{{K}}</span><span class="ltx_text" id="S4.SS3.p7.1.3" style="font-size:90%;">.</span></p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS3.p8">
<p class="ltx_p" id="S4.SS3.p8.1"><span class="ltx_text ltx_font_bold" id="S4.SS3.p8.1.1" style="font-size:90%;">(3) Instance-specific Q&amp;A.</span><span class="ltx_text" id="S4.SS3.p8.1.2" style="font-size:90%;"> Defined as follows:</span></p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS3.p9">
<svg class="ltx_picture" height="74.08" id="S4.SS3.p9.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,74.08) matrix(1 0 0 -1 0 0)"><g fill="#000000" fill-opacity="1.0"><path d="M 0 0 L 0 74.08 L 600 74.08 L 600 0 Z" style="stroke:none"></path></g><g fill="#FFFFFF" fill-opacity="1.0"><path d="M 1.97 1.97 L 1.97 72.11 L 598.03 72.11 L 598.03 1.97 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 5.91 5.91)"><foreignobject color="#000000" height="62.27" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="588.19">
<span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="S4.SS3.p9.pic1.1.1.1.1.1" style="width:425.1pt;">
<span class="ltx_p" id="S4.SS3.p9.pic1.1.1.1.1.1.1"><span class="ltx_text" id="S4.SS3.p9.pic1.1.1.1.1.1.1.1" style="font-size:90%;">You are an expert in the specific database instance and capable of using tools to extract information from that database. Your responses should draw on your expertise in the database field and provide specific solutions.</span></span>
<span class="ltx_p" id="S4.SS3.p9.pic1.1.1.1.1.1.2"><span class="ltx_text" id="S4.SS3.p9.pic1.1.1.1.1.1.2.1" style="font-size:90%;">The tools you can use:
</span><span class="ltx_text ltx_font_typewriter" id="S4.SS3.p9.pic1.1.1.1.1.1.2.2" style="font-size:90%;">{{T}}</span><span class="ltx_text" id="S4.SS3.p9.pic1.1.1.1.1.1.2.3" style="font-size:90%;"></span></span>
<span class="ltx_p" id="S4.SS3.p9.pic1.1.1.1.1.1.3"><span class="ltx_text" id="S4.SS3.p9.pic1.1.1.1.1.1.3.1" style="font-size:90%;">Use the following format:</span></span>
<span class="ltx_p" id="S4.SS3.p9.pic1.1.1.1.1.1.4"><span class="ltx_text" id="S4.SS3.p9.pic1.1.1.1.1.1.4.1" style="font-size:90%;">Question: …;
Thought: …;
Action: …;
Action_Input: …;
Observation: …;
…;
Final_Answer: …</span></span>
<span class="ltx_p" id="S4.SS3.p9.pic1.1.1.1.1.1.5"><span class="ltx_text" id="S4.SS3.p9.pic1.1.1.1.1.1.5.1" style="font-size:90%;">Question: </span><span class="ltx_text ltx_font_typewriter" id="S4.SS3.p9.pic1.1.1.1.1.1.5.2" style="font-size:90%;">{{Q}}</span><span class="ltx_text" id="S4.SS3.p9.pic1.1.1.1.1.1.5.3" style="font-size:90%;"></span></span>
<span class="ltx_p" id="S4.SS3.p9.pic1.1.1.1.1.1.6"><span class="ltx_text ltx_font_typewriter" id="S4.SS3.p9.pic1.1.1.1.1.1.6.1" style="font-size:90%;">{{Agent_Scratchpad}}</span><span class="ltx_text" id="S4.SS3.p9.pic1.1.1.1.1.1.6.2" style="font-size:90%;"></span></span>
</span></foreignobject></g></g></svg>
</div>
<div class="ltx_para" id="S4.SS3.p10">
<p class="ltx_p" id="S4.SS3.p10.1"><span class="ltx_text" id="S4.SS3.p10.1.1" style="font-size:90%;">Here, the keyword “using tools” can trigger the TIG module. The content after “Action:” and “Action_Input:” will be used to invocate the appropriate tools correctly, and the tool’s output will be extracted, summarized and appended after ”Observation:”. More details are described in Section </span><a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#S4.SS5" style="font-size:90%;" title="4.5. Tool Invocation Generation ‣ 4. DQA Testbed ‣ 3.3. Instance-Specific Q&amp;A ‣ 3.2. Product-Specific Q&amp;A ‣ 3. DQA Dataset Generation ‣ Revolutionizing Database Q&amp;A with Large Language Models: Comprehensive Benchmark and Evaluation"><span class="ltx_text ltx_ref_tag">4.5</span></a><span class="ltx_text" id="S4.SS3.p10.1.2" style="font-size:90%;"></span></p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS3.p11">
<p class="ltx_p" id="S4.SS3.p11.1"><span class="ltx_text ltx_font_bold" id="S4.SS3.p11.1.1" style="font-size:90%;">(4) DB-irrelevant Q&amp;A.</span><span class="ltx_text" id="S4.SS3.p11.1.2" style="font-size:90%;"> We will require the system to refuse to answer all questions unrelated to databases. Defined as follows:</span></p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS3.p12">
<svg class="ltx_picture" height="57.47" id="S4.SS3.p12.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,57.47) matrix(1 0 0 -1 0 0)"><g fill="#000000" fill-opacity="1.0"><path d="M 0 0 L 0 57.47 L 600 57.47 L 600 0 Z" style="stroke:none"></path></g><g fill="#FFFFFF" fill-opacity="1.0"><path d="M 1.97 1.97 L 1.97 55.5 L 598.03 55.5 L 598.03 1.97 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 5.91 5.91)"><foreignobject color="#000000" height="45.66" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="588.19">
<span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="S4.SS3.p12.pic1.1.1.1.1.1" style="width:425.1pt;">
<span class="ltx_p" id="S4.SS3.p12.pic1.1.1.1.1.1.1"><span class="ltx_text" id="S4.SS3.p12.pic1.1.1.1.1.1.1.1" style="font-size:90%;">You are a friendly, LLM-based database Q&amp;A system, and you can only answer questions related to databases. When users ask questions unrelated to databases, please kindly refuse to answer and explain the reason.</span></span>
<span class="ltx_p" id="S4.SS3.p12.pic1.1.1.1.1.1.2"><span class="ltx_text" id="S4.SS3.p12.pic1.1.1.1.1.1.2.1" style="font-size:90%;">Question: {{Q}}</span></span>
</span></foreignobject></g></g></svg>
</div>
</section>
<section class="ltx_subsection" id="S4.SS4">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">4.4. </span>Retrieval Augment Generation</h3>
<div class="ltx_para" id="S4.SS4.p1">
<p class="ltx_p" id="S4.SS4.p1.1"><span class="ltx_text" id="S4.SS4.p1.1.1" style="font-size:90%;">The Retrieval Augment Generation (RAG) module is used to extract additional external knowledge from documents to enhance LLMs.</span></p>
</div>
<div class="ltx_para" id="S4.SS4.p2">
<p class="ltx_p" id="S4.SS4.p2.1"><span class="ltx_text" id="S4.SS4.p2.1.1" style="font-size:90%;">As shown in Figure </span><a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#S4.F4" style="font-size:90%;" title="Figure 4 ‣ 4. DQA Testbed ‣ 3.3. Instance-Specific Q&amp;A ‣ 3.2. Product-Specific Q&amp;A ‣ 3. DQA Dataset Generation ‣ Revolutionizing Database Q&amp;A with Large Language Models: Comprehensive Benchmark and Evaluation"><span class="ltx_text ltx_ref_tag">4</span></a><span class="ltx_text" id="S4.SS4.p2.1.2" style="font-size:90%;">, the module first segments texts from the knowledge base into independent text blocks. Each text block is then processed through an embedding model to be transformed into a dense vector and stored in a vector database, establishing mappings between texts and vectors. Similarly, when a user submits a query, it is also transformed into a vector using the same embedding model, which is then matched against the vectors of the text blocks in the database based on similarity computation. The system obtains the most relevant text block vector, appends it to the prompt and feeds the prompt to the core LLM module. The LLM then generates precise and relevant responses to the user’s query based on the knowledge.</span></p>
</div>
<div class="ltx_para" id="S4.SS4.p3">
<p class="ltx_p" id="S4.SS4.p3.1"><span class="ltx_text" id="S4.SS4.p3.1.1" style="font-size:90%;">We adopt Langchain-Chatchat </span><span class="ltx_note ltx_role_footnote" id="footnote10"><sup class="ltx_note_mark">10</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">10</sup><span class="ltx_tag ltx_tag_note">10</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/chatchat-space/Langchain-Chatchat" title="">https://github.com/chatchat-space/Langchain-Chatchat</a></span></span></span><span class="ltx_text" id="S4.SS4.p3.1.2" style="font-size:90%;"> to implement a vector storage and retrieval-based RAG module. We use the Faiss </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S4.SS4.p3.1.3.1" style="font-size:90%;">(</span><span class="ltx_ref ltx_missing_citation ltx_ref_self">Faiss</span><span class="ltx_text" id="S4.SS4.p3.1.5.3" style="font-size:90%;">)</span></cite><span class="ltx_text" id="S4.SS4.p3.1.6" style="font-size:90%;"> vector database to efficiently manage and retrieve large-scale embedding vectors, using Bge-large </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S4.SS4.p3.1.7.1" style="font-size:90%;">(</span><span class="ltx_text" style="font-size:90%;">Xiao et al</span><span class="ltx_text" style="font-size:90%;">.</span><span class="ltx_text" id="S4.SS4.p3.1.8.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#bib.bib37" title=""><span class="ltx_text" style="font-size:90%;">2023</span></a><span class="ltx_text" id="S4.SS4.p3.1.9.3" style="font-size:90%;">)</span></cite><span class="ltx_text" id="S4.SS4.p3.1.10" style="font-size:90%;"> as the embedding model to map text into dense vectors.</span></p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS5">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">4.5. </span>Tool Invocation Generation</h3>
<div class="ltx_para" id="S4.SS5.p1">
<p class="ltx_p" id="S4.SS5.p1.1"><span class="ltx_text" id="S4.SS5.p1.1.1" style="font-size:90%;">The Tool Invocation Generation (TIG) module is designed to extract context information regarding the database instance to tailor a customized answer.</span></p>
</div>
<div class="ltx_para" id="S4.SS5.p2">
<p class="ltx_p" id="S4.SS5.p2.1"><span class="ltx_text" id="S4.SS5.p2.1.1" style="font-size:90%;">We first implement a Chain of Thought (COT) prompt template following ReAct  </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S4.SS5.p2.1.2.1" style="font-size:90%;">(</span><span class="ltx_text" style="font-size:90%;">Yao et al</span><span class="ltx_text" style="font-size:90%;">.</span><span class="ltx_text" id="S4.SS5.p2.1.3.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#bib.bib41" title=""><span class="ltx_text" style="font-size:90%;">2023</span></a><span class="ltx_text" id="S4.SS5.p2.1.4.3" style="font-size:90%;">)</span></cite><span class="ltx_text" id="S4.SS5.p2.1.5" style="font-size:90%;">. This prompt template encourages the LLM to think in a loop according to the following chain of thought: (1) “Thought”: Think and reason based on the currently available information to determine the tools that need to be invoked. (2) “Action” and “Action Input”: Provide the name of the tool to be invoked and its input in the right format. (3) “Observation”: The tool will provide the results of the invocation.</span></p>
</div>
<div class="ltx_para" id="S4.SS5.p3">
<p class="ltx_p" id="S4.SS5.p3.1"><span class="ltx_text" id="S4.SS5.p3.1.1" style="font-size:90%;">As shown in Figure </span><a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#S4.F4" style="font-size:90%;" title="Figure 4 ‣ 4. DQA Testbed ‣ 3.3. Instance-Specific Q&amp;A ‣ 3.2. Product-Specific Q&amp;A ‣ 3. DQA Dataset Generation ‣ Revolutionizing Database Q&amp;A with Large Language Models: Comprehensive Benchmark and Evaluation"><span class="ltx_text ltx_ref_tag">4</span></a><span class="ltx_text" id="S4.SS5.p3.1.2" style="font-size:90%;">, the LLM initially outputs the COT containing the first tool it wants to invoke and the input for the tool. The tool trigger reads the output and interrupts the LLM from continuing its output. Simultaneously, the TIG module matches the tool’s name (content after “Action:”) in the tool pool, which comprises the common tools listed in Table </span><a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#S3.SS2" style="font-size:90%;" title="3.2. Product-Specific Q&amp;A ‣ 3. DQA Dataset Generation ‣ Revolutionizing Database Q&amp;A with Large Language Models: Comprehensive Benchmark and Evaluation"><span class="ltx_text ltx_ref_tag">3.2</span></a><span class="ltx_text" id="S4.SS5.p3.1.3" style="font-size:90%;">. If it finds the appropriate tool, it invokes the corresponding tool interface based on the content after “Action_Input:”.</span></p>
</div>
<div class="ltx_para" id="S4.SS5.p4">
<p class="ltx_p" id="S4.SS5.p4.1"><span class="ltx_text" id="S4.SS5.p4.1.1" style="font-size:90%;">When interacting with the database instance, the tool will output some results. The output will be organized into text form and appended to the LLM’s output after ”Observation:”. We optimize tool outputs to boost efficiency and accuracy. Enhancements involve (1) filtering highly relevant content from extensive outputs and (2) transforming structured data, like tables, into Markdown format for streamlined processing.</span></p>
</div>
<div class="ltx_para" id="S4.SS5.p5">
<p class="ltx_p" id="S4.SS5.p5.1"><span class="ltx_text" id="S4.SS5.p5.1.1" style="font-size:90%;">After the tool execution, the TIG module will end the interruption, and let the LLM continue thinking based on the results of ”Observation” to determine if additional tools need to be called. If more tools are needed, the process will iterate. Otherwise, if the LLM determines there is sufficient information to solve the problem, it will directly output the final answer.</span></p>
</div>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section" style="font-size:90%;">
<span class="ltx_tag ltx_tag_section">5. </span><span class="ltx_text ltx_font_bold ltx_font_italic" id="S5.1.1">DQA</span> Evaluation Pipeline</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1"><span class="ltx_text" id="S5.p1.1.1" style="font-size:90%;">We make two lines of effort toward building a thorough, precise and impartial evaluation of question-answering databases (DBs). (1) modularized evaluation protocols and metrics, which rigorously assess intermediate stages such as DB document retrieval, tool selection and tool utilization; and (2) a standardized end-to-end evaluation that ensures stability and control.</span></p>
</div>
<section class="ltx_subsection" id="S5.SS1">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">5.1. </span>Modularized Evaluation</h3>
<div class="ltx_para ltx_noindent" id="S5.SS1.p1">
<p class="ltx_p" id="S5.SS1.p1.8"><span class="ltx_text ltx_font_bold" id="S5.SS1.p1.8.1" style="font-size:90%;">QCR Evaluation. </span><span class="ltx_text" id="S5.SS1.p1.8.2" style="font-size:90%;">
Accuracy is the most critical metric when evaluating the QCR module. If the questions are not accurately categorized, the LLM can not provide customized responses. Given the ground truth class labels mentioned in Section </span><a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#S4.SS2" style="font-size:90%;" title="4.2. Question Classification Routing ‣ 4. DQA Testbed ‣ 3.3. Instance-Specific Q&amp;A ‣ 3.2. Product-Specific Q&amp;A ‣ 3. DQA Dataset Generation ‣ Revolutionizing Database Q&amp;A with Large Language Models: Comprehensive Benchmark and Evaluation"><span class="ltx_text ltx_ref_tag">4.2</span></a><span class="ltx_text" id="S5.SS1.p1.8.3" style="font-size:90%;">, the accuracy is defined as </span><math alttext="Acc=\sum_{i}m_{i,i}/\sum_{i}\sum_{j}m_{i,j}" class="ltx_Math" display="inline" id="S5.SS1.p1.1.m1.4"><semantics id="S5.SS1.p1.1.m1.4a"><mrow id="S5.SS1.p1.1.m1.4.5" xref="S5.SS1.p1.1.m1.4.5.cmml"><mrow id="S5.SS1.p1.1.m1.4.5.2" xref="S5.SS1.p1.1.m1.4.5.2.cmml"><mi id="S5.SS1.p1.1.m1.4.5.2.2" mathsize="90%" xref="S5.SS1.p1.1.m1.4.5.2.2.cmml">A</mi><mo id="S5.SS1.p1.1.m1.4.5.2.1" xref="S5.SS1.p1.1.m1.4.5.2.1.cmml">⁢</mo><mi id="S5.SS1.p1.1.m1.4.5.2.3" mathsize="90%" xref="S5.SS1.p1.1.m1.4.5.2.3.cmml">c</mi><mo id="S5.SS1.p1.1.m1.4.5.2.1a" xref="S5.SS1.p1.1.m1.4.5.2.1.cmml">⁢</mo><mi id="S5.SS1.p1.1.m1.4.5.2.4" mathsize="90%" xref="S5.SS1.p1.1.m1.4.5.2.4.cmml">c</mi></mrow><mo id="S5.SS1.p1.1.m1.4.5.1" mathsize="90%" rspace="0.111em" xref="S5.SS1.p1.1.m1.4.5.1.cmml">=</mo><mrow id="S5.SS1.p1.1.m1.4.5.3" xref="S5.SS1.p1.1.m1.4.5.3.cmml"><msub id="S5.SS1.p1.1.m1.4.5.3.1" xref="S5.SS1.p1.1.m1.4.5.3.1.cmml"><mo id="S5.SS1.p1.1.m1.4.5.3.1.2" maxsize="90%" minsize="90%" stretchy="true" xref="S5.SS1.p1.1.m1.4.5.3.1.2.cmml">∑</mo><mi id="S5.SS1.p1.1.m1.4.5.3.1.3" mathsize="90%" xref="S5.SS1.p1.1.m1.4.5.3.1.3.cmml">i</mi></msub><mrow id="S5.SS1.p1.1.m1.4.5.3.2" xref="S5.SS1.p1.1.m1.4.5.3.2.cmml"><msub id="S5.SS1.p1.1.m1.4.5.3.2.2" xref="S5.SS1.p1.1.m1.4.5.3.2.2.cmml"><mi id="S5.SS1.p1.1.m1.4.5.3.2.2.2" mathsize="90%" xref="S5.SS1.p1.1.m1.4.5.3.2.2.2.cmml">m</mi><mrow id="S5.SS1.p1.1.m1.2.2.2.4" xref="S5.SS1.p1.1.m1.2.2.2.3.cmml"><mi id="S5.SS1.p1.1.m1.1.1.1.1" mathsize="90%" xref="S5.SS1.p1.1.m1.1.1.1.1.cmml">i</mi><mo id="S5.SS1.p1.1.m1.2.2.2.4.1" mathsize="90%" xref="S5.SS1.p1.1.m1.2.2.2.3.cmml">,</mo><mi id="S5.SS1.p1.1.m1.2.2.2.2" mathsize="90%" xref="S5.SS1.p1.1.m1.2.2.2.2.cmml">i</mi></mrow></msub><mo id="S5.SS1.p1.1.m1.4.5.3.2.1" maxsize="90%" minsize="90%" rspace="0.055em" stretchy="true" symmetric="true" xref="S5.SS1.p1.1.m1.4.5.3.2.1.cmml">/</mo><mrow id="S5.SS1.p1.1.m1.4.5.3.2.3" xref="S5.SS1.p1.1.m1.4.5.3.2.3.cmml"><msub id="S5.SS1.p1.1.m1.4.5.3.2.3.1" xref="S5.SS1.p1.1.m1.4.5.3.2.3.1.cmml"><mo id="S5.SS1.p1.1.m1.4.5.3.2.3.1.2" maxsize="90%" minsize="90%" rspace="0em" stretchy="true" xref="S5.SS1.p1.1.m1.4.5.3.2.3.1.2.cmml">∑</mo><mi id="S5.SS1.p1.1.m1.4.5.3.2.3.1.3" mathsize="90%" xref="S5.SS1.p1.1.m1.4.5.3.2.3.1.3.cmml">i</mi></msub><mrow id="S5.SS1.p1.1.m1.4.5.3.2.3.2" xref="S5.SS1.p1.1.m1.4.5.3.2.3.2.cmml"><msub id="S5.SS1.p1.1.m1.4.5.3.2.3.2.1" xref="S5.SS1.p1.1.m1.4.5.3.2.3.2.1.cmml"><mo id="S5.SS1.p1.1.m1.4.5.3.2.3.2.1.2" maxsize="90%" minsize="90%" stretchy="true" xref="S5.SS1.p1.1.m1.4.5.3.2.3.2.1.2.cmml">∑</mo><mi id="S5.SS1.p1.1.m1.4.5.3.2.3.2.1.3" mathsize="90%" xref="S5.SS1.p1.1.m1.4.5.3.2.3.2.1.3.cmml">j</mi></msub><msub id="S5.SS1.p1.1.m1.4.5.3.2.3.2.2" xref="S5.SS1.p1.1.m1.4.5.3.2.3.2.2.cmml"><mi id="S5.SS1.p1.1.m1.4.5.3.2.3.2.2.2" mathsize="90%" xref="S5.SS1.p1.1.m1.4.5.3.2.3.2.2.2.cmml">m</mi><mrow id="S5.SS1.p1.1.m1.4.4.2.4" xref="S5.SS1.p1.1.m1.4.4.2.3.cmml"><mi id="S5.SS1.p1.1.m1.3.3.1.1" mathsize="90%" xref="S5.SS1.p1.1.m1.3.3.1.1.cmml">i</mi><mo id="S5.SS1.p1.1.m1.4.4.2.4.1" mathsize="90%" xref="S5.SS1.p1.1.m1.4.4.2.3.cmml">,</mo><mi id="S5.SS1.p1.1.m1.4.4.2.2" mathsize="90%" xref="S5.SS1.p1.1.m1.4.4.2.2.cmml">j</mi></mrow></msub></mrow></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.1.m1.4b"><apply id="S5.SS1.p1.1.m1.4.5.cmml" xref="S5.SS1.p1.1.m1.4.5"><eq id="S5.SS1.p1.1.m1.4.5.1.cmml" xref="S5.SS1.p1.1.m1.4.5.1"></eq><apply id="S5.SS1.p1.1.m1.4.5.2.cmml" xref="S5.SS1.p1.1.m1.4.5.2"><times id="S5.SS1.p1.1.m1.4.5.2.1.cmml" xref="S5.SS1.p1.1.m1.4.5.2.1"></times><ci id="S5.SS1.p1.1.m1.4.5.2.2.cmml" xref="S5.SS1.p1.1.m1.4.5.2.2">𝐴</ci><ci id="S5.SS1.p1.1.m1.4.5.2.3.cmml" xref="S5.SS1.p1.1.m1.4.5.2.3">𝑐</ci><ci id="S5.SS1.p1.1.m1.4.5.2.4.cmml" xref="S5.SS1.p1.1.m1.4.5.2.4">𝑐</ci></apply><apply id="S5.SS1.p1.1.m1.4.5.3.cmml" xref="S5.SS1.p1.1.m1.4.5.3"><apply id="S5.SS1.p1.1.m1.4.5.3.1.cmml" xref="S5.SS1.p1.1.m1.4.5.3.1"><csymbol cd="ambiguous" id="S5.SS1.p1.1.m1.4.5.3.1.1.cmml" xref="S5.SS1.p1.1.m1.4.5.3.1">subscript</csymbol><sum id="S5.SS1.p1.1.m1.4.5.3.1.2.cmml" xref="S5.SS1.p1.1.m1.4.5.3.1.2"></sum><ci id="S5.SS1.p1.1.m1.4.5.3.1.3.cmml" xref="S5.SS1.p1.1.m1.4.5.3.1.3">𝑖</ci></apply><apply id="S5.SS1.p1.1.m1.4.5.3.2.cmml" xref="S5.SS1.p1.1.m1.4.5.3.2"><divide id="S5.SS1.p1.1.m1.4.5.3.2.1.cmml" xref="S5.SS1.p1.1.m1.4.5.3.2.1"></divide><apply id="S5.SS1.p1.1.m1.4.5.3.2.2.cmml" xref="S5.SS1.p1.1.m1.4.5.3.2.2"><csymbol cd="ambiguous" id="S5.SS1.p1.1.m1.4.5.3.2.2.1.cmml" xref="S5.SS1.p1.1.m1.4.5.3.2.2">subscript</csymbol><ci id="S5.SS1.p1.1.m1.4.5.3.2.2.2.cmml" xref="S5.SS1.p1.1.m1.4.5.3.2.2.2">𝑚</ci><list id="S5.SS1.p1.1.m1.2.2.2.3.cmml" xref="S5.SS1.p1.1.m1.2.2.2.4"><ci id="S5.SS1.p1.1.m1.1.1.1.1.cmml" xref="S5.SS1.p1.1.m1.1.1.1.1">𝑖</ci><ci id="S5.SS1.p1.1.m1.2.2.2.2.cmml" xref="S5.SS1.p1.1.m1.2.2.2.2">𝑖</ci></list></apply><apply id="S5.SS1.p1.1.m1.4.5.3.2.3.cmml" xref="S5.SS1.p1.1.m1.4.5.3.2.3"><apply id="S5.SS1.p1.1.m1.4.5.3.2.3.1.cmml" xref="S5.SS1.p1.1.m1.4.5.3.2.3.1"><csymbol cd="ambiguous" id="S5.SS1.p1.1.m1.4.5.3.2.3.1.1.cmml" xref="S5.SS1.p1.1.m1.4.5.3.2.3.1">subscript</csymbol><sum id="S5.SS1.p1.1.m1.4.5.3.2.3.1.2.cmml" xref="S5.SS1.p1.1.m1.4.5.3.2.3.1.2"></sum><ci id="S5.SS1.p1.1.m1.4.5.3.2.3.1.3.cmml" xref="S5.SS1.p1.1.m1.4.5.3.2.3.1.3">𝑖</ci></apply><apply id="S5.SS1.p1.1.m1.4.5.3.2.3.2.cmml" xref="S5.SS1.p1.1.m1.4.5.3.2.3.2"><apply id="S5.SS1.p1.1.m1.4.5.3.2.3.2.1.cmml" xref="S5.SS1.p1.1.m1.4.5.3.2.3.2.1"><csymbol cd="ambiguous" id="S5.SS1.p1.1.m1.4.5.3.2.3.2.1.1.cmml" xref="S5.SS1.p1.1.m1.4.5.3.2.3.2.1">subscript</csymbol><sum id="S5.SS1.p1.1.m1.4.5.3.2.3.2.1.2.cmml" xref="S5.SS1.p1.1.m1.4.5.3.2.3.2.1.2"></sum><ci id="S5.SS1.p1.1.m1.4.5.3.2.3.2.1.3.cmml" xref="S5.SS1.p1.1.m1.4.5.3.2.3.2.1.3">𝑗</ci></apply><apply id="S5.SS1.p1.1.m1.4.5.3.2.3.2.2.cmml" xref="S5.SS1.p1.1.m1.4.5.3.2.3.2.2"><csymbol cd="ambiguous" id="S5.SS1.p1.1.m1.4.5.3.2.3.2.2.1.cmml" xref="S5.SS1.p1.1.m1.4.5.3.2.3.2.2">subscript</csymbol><ci id="S5.SS1.p1.1.m1.4.5.3.2.3.2.2.2.cmml" xref="S5.SS1.p1.1.m1.4.5.3.2.3.2.2.2">𝑚</ci><list id="S5.SS1.p1.1.m1.4.4.2.3.cmml" xref="S5.SS1.p1.1.m1.4.4.2.4"><ci id="S5.SS1.p1.1.m1.3.3.1.1.cmml" xref="S5.SS1.p1.1.m1.3.3.1.1">𝑖</ci><ci id="S5.SS1.p1.1.m1.4.4.2.2.cmml" xref="S5.SS1.p1.1.m1.4.4.2.2">𝑗</ci></list></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.1.m1.4c">Acc=\sum_{i}m_{i,i}/\sum_{i}\sum_{j}m_{i,j}</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p1.1.m1.4d">italic_A italic_c italic_c = ∑ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_m start_POSTSUBSCRIPT italic_i , italic_i end_POSTSUBSCRIPT / ∑ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ∑ start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT italic_m start_POSTSUBSCRIPT italic_i , italic_j end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="S5.SS1.p1.8.4" style="font-size:90%;">, where </span><math alttext="m_{i,j}" class="ltx_Math" display="inline" id="S5.SS1.p1.2.m2.2"><semantics id="S5.SS1.p1.2.m2.2a"><msub id="S5.SS1.p1.2.m2.2.3" xref="S5.SS1.p1.2.m2.2.3.cmml"><mi id="S5.SS1.p1.2.m2.2.3.2" mathsize="90%" xref="S5.SS1.p1.2.m2.2.3.2.cmml">m</mi><mrow id="S5.SS1.p1.2.m2.2.2.2.4" xref="S5.SS1.p1.2.m2.2.2.2.3.cmml"><mi id="S5.SS1.p1.2.m2.1.1.1.1" mathsize="90%" xref="S5.SS1.p1.2.m2.1.1.1.1.cmml">i</mi><mo id="S5.SS1.p1.2.m2.2.2.2.4.1" mathsize="90%" xref="S5.SS1.p1.2.m2.2.2.2.3.cmml">,</mo><mi id="S5.SS1.p1.2.m2.2.2.2.2" mathsize="90%" xref="S5.SS1.p1.2.m2.2.2.2.2.cmml">j</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.2.m2.2b"><apply id="S5.SS1.p1.2.m2.2.3.cmml" xref="S5.SS1.p1.2.m2.2.3"><csymbol cd="ambiguous" id="S5.SS1.p1.2.m2.2.3.1.cmml" xref="S5.SS1.p1.2.m2.2.3">subscript</csymbol><ci id="S5.SS1.p1.2.m2.2.3.2.cmml" xref="S5.SS1.p1.2.m2.2.3.2">𝑚</ci><list id="S5.SS1.p1.2.m2.2.2.2.3.cmml" xref="S5.SS1.p1.2.m2.2.2.2.4"><ci id="S5.SS1.p1.2.m2.1.1.1.1.cmml" xref="S5.SS1.p1.2.m2.1.1.1.1">𝑖</ci><ci id="S5.SS1.p1.2.m2.2.2.2.2.cmml" xref="S5.SS1.p1.2.m2.2.2.2.2">𝑗</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.2.m2.2c">m_{i,j}</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p1.2.m2.2d">italic_m start_POSTSUBSCRIPT italic_i , italic_j end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="S5.SS1.p1.8.5" style="font-size:90%;"> is the number of queries that belong to ground truth class </span><math alttext="i" class="ltx_Math" display="inline" id="S5.SS1.p1.3.m3.1"><semantics id="S5.SS1.p1.3.m3.1a"><mi id="S5.SS1.p1.3.m3.1.1" mathsize="90%" xref="S5.SS1.p1.3.m3.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.3.m3.1b"><ci id="S5.SS1.p1.3.m3.1.1.cmml" xref="S5.SS1.p1.3.m3.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.3.m3.1c">i</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p1.3.m3.1d">italic_i</annotation></semantics></math><span class="ltx_text" id="S5.SS1.p1.8.6" style="font-size:90%;"> that are classified as class </span><math alttext="j" class="ltx_Math" display="inline" id="S5.SS1.p1.4.m4.1"><semantics id="S5.SS1.p1.4.m4.1a"><mi id="S5.SS1.p1.4.m4.1.1" mathsize="90%" xref="S5.SS1.p1.4.m4.1.1.cmml">j</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.4.m4.1b"><ci id="S5.SS1.p1.4.m4.1.1.cmml" xref="S5.SS1.p1.4.m4.1.1">𝑗</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.4.m4.1c">j</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p1.4.m4.1d">italic_j</annotation></semantics></math><span class="ltx_text" id="S5.SS1.p1.8.7" style="font-size:90%;">. We will also report the F1 result of each category </span><math alttext="i" class="ltx_Math" display="inline" id="S5.SS1.p1.5.m5.1"><semantics id="S5.SS1.p1.5.m5.1a"><mi id="S5.SS1.p1.5.m5.1.1" mathsize="90%" xref="S5.SS1.p1.5.m5.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.5.m5.1b"><ci id="S5.SS1.p1.5.m5.1.1.cmml" xref="S5.SS1.p1.5.m5.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.5.m5.1c">i</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p1.5.m5.1d">italic_i</annotation></semantics></math><span class="ltx_text" id="S5.SS1.p1.8.8" style="font-size:90%;"> in the experiment as </span><math alttext="F1(i)=2(precision(i)\cdot recall(i))/(precision(i)+recall(i))" class="ltx_Math" display="inline" id="S5.SS1.p1.6.m6.7"><semantics id="S5.SS1.p1.6.m6.7a"><mrow id="S5.SS1.p1.6.m6.7.7" xref="S5.SS1.p1.6.m6.7.7.cmml"><mrow id="S5.SS1.p1.6.m6.7.7.4" xref="S5.SS1.p1.6.m6.7.7.4.cmml"><mi id="S5.SS1.p1.6.m6.7.7.4.2" mathsize="90%" xref="S5.SS1.p1.6.m6.7.7.4.2.cmml">F</mi><mo id="S5.SS1.p1.6.m6.7.7.4.1" xref="S5.SS1.p1.6.m6.7.7.4.1.cmml">⁢</mo><mn id="S5.SS1.p1.6.m6.7.7.4.3" mathsize="90%" xref="S5.SS1.p1.6.m6.7.7.4.3.cmml">1</mn><mo id="S5.SS1.p1.6.m6.7.7.4.1a" xref="S5.SS1.p1.6.m6.7.7.4.1.cmml">⁢</mo><mrow id="S5.SS1.p1.6.m6.7.7.4.4.2" xref="S5.SS1.p1.6.m6.7.7.4.cmml"><mo id="S5.SS1.p1.6.m6.7.7.4.4.2.1" maxsize="90%" minsize="90%" xref="S5.SS1.p1.6.m6.7.7.4.cmml">(</mo><mi id="S5.SS1.p1.6.m6.1.1" mathsize="90%" xref="S5.SS1.p1.6.m6.1.1.cmml">i</mi><mo id="S5.SS1.p1.6.m6.7.7.4.4.2.2" maxsize="90%" minsize="90%" xref="S5.SS1.p1.6.m6.7.7.4.cmml">)</mo></mrow></mrow><mo id="S5.SS1.p1.6.m6.7.7.3" mathsize="90%" xref="S5.SS1.p1.6.m6.7.7.3.cmml">=</mo><mrow id="S5.SS1.p1.6.m6.7.7.2" xref="S5.SS1.p1.6.m6.7.7.2.cmml"><mrow id="S5.SS1.p1.6.m6.6.6.1.1" xref="S5.SS1.p1.6.m6.6.6.1.1.cmml"><mn id="S5.SS1.p1.6.m6.6.6.1.1.3" mathsize="90%" xref="S5.SS1.p1.6.m6.6.6.1.1.3.cmml">2</mn><mo id="S5.SS1.p1.6.m6.6.6.1.1.2" xref="S5.SS1.p1.6.m6.6.6.1.1.2.cmml">⁢</mo><mrow id="S5.SS1.p1.6.m6.6.6.1.1.1.1" xref="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.cmml"><mo id="S5.SS1.p1.6.m6.6.6.1.1.1.1.2" maxsize="90%" minsize="90%" xref="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.cmml">(</mo><mrow id="S5.SS1.p1.6.m6.6.6.1.1.1.1.1" xref="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.cmml"><mrow id="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.2" xref="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.2.cmml"><mrow id="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.2.2" xref="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.2.2.cmml"><mi id="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.2.2.2" mathsize="90%" xref="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.2.2.2.cmml">p</mi><mo id="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.2.2.1" xref="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.2.2.1.cmml">⁢</mo><mi id="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.2.2.3" mathsize="90%" xref="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.2.2.3.cmml">r</mi><mo id="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.2.2.1a" xref="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.2.2.1.cmml">⁢</mo><mi id="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.2.2.4" mathsize="90%" xref="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.2.2.4.cmml">e</mi><mo id="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.2.2.1b" xref="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.2.2.1.cmml">⁢</mo><mi id="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.2.2.5" mathsize="90%" xref="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.2.2.5.cmml">c</mi><mo id="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.2.2.1c" xref="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.2.2.1.cmml">⁢</mo><mi id="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.2.2.6" mathsize="90%" xref="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.2.2.6.cmml">i</mi><mo id="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.2.2.1d" xref="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.2.2.1.cmml">⁢</mo><mi id="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.2.2.7" mathsize="90%" xref="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.2.2.7.cmml">s</mi><mo id="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.2.2.1e" xref="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.2.2.1.cmml">⁢</mo><mi id="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.2.2.8" mathsize="90%" xref="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.2.2.8.cmml">i</mi><mo id="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.2.2.1f" xref="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.2.2.1.cmml">⁢</mo><mi id="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.2.2.9" mathsize="90%" xref="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.2.2.9.cmml">o</mi><mo id="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.2.2.1g" xref="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.2.2.1.cmml">⁢</mo><mi id="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.2.2.10" mathsize="90%" xref="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.2.2.10.cmml">n</mi><mo id="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.2.2.1h" xref="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.2.2.1.cmml">⁢</mo><mrow id="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.2.2.11.2" xref="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.2.2.cmml"><mo id="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.2.2.11.2.1" maxsize="90%" minsize="90%" xref="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.2.2.cmml">(</mo><mi id="S5.SS1.p1.6.m6.2.2" mathsize="90%" xref="S5.SS1.p1.6.m6.2.2.cmml">i</mi><mo id="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.2.2.11.2.2" maxsize="90%" minsize="90%" rspace="0.055em" xref="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.2.2.cmml">)</mo></mrow></mrow><mo id="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.2.1" mathsize="90%" rspace="0.222em" xref="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.2.1.cmml">⋅</mo><mi id="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.2.3" mathsize="90%" xref="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.2.3.cmml">r</mi></mrow><mo id="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.1" xref="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.1.cmml">⁢</mo><mi id="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.3" mathsize="90%" xref="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.3.cmml">e</mi><mo id="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.1a" xref="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.1.cmml">⁢</mo><mi id="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.4" mathsize="90%" xref="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.4.cmml">c</mi><mo id="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.1b" xref="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.1.cmml">⁢</mo><mi id="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.5" mathsize="90%" xref="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.5.cmml">a</mi><mo id="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.1c" xref="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.1.cmml">⁢</mo><mi id="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.6" mathsize="90%" xref="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.6.cmml">l</mi><mo id="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.1d" xref="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.1.cmml">⁢</mo><mi id="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.7" mathsize="90%" xref="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.7.cmml">l</mi><mo id="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.1e" xref="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.1.cmml">⁢</mo><mrow id="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.8.2" xref="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.cmml"><mo id="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.8.2.1" maxsize="90%" minsize="90%" xref="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.cmml">(</mo><mi id="S5.SS1.p1.6.m6.3.3" mathsize="90%" xref="S5.SS1.p1.6.m6.3.3.cmml">i</mi><mo id="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.8.2.2" maxsize="90%" minsize="90%" xref="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S5.SS1.p1.6.m6.6.6.1.1.1.1.3" maxsize="90%" minsize="90%" xref="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S5.SS1.p1.6.m6.7.7.2.3" maxsize="90%" minsize="90%" stretchy="true" symmetric="true" xref="S5.SS1.p1.6.m6.7.7.2.3.cmml">/</mo><mrow id="S5.SS1.p1.6.m6.7.7.2.2.1" xref="S5.SS1.p1.6.m6.7.7.2.2.1.1.cmml"><mo id="S5.SS1.p1.6.m6.7.7.2.2.1.2" maxsize="90%" minsize="90%" xref="S5.SS1.p1.6.m6.7.7.2.2.1.1.cmml">(</mo><mrow id="S5.SS1.p1.6.m6.7.7.2.2.1.1" xref="S5.SS1.p1.6.m6.7.7.2.2.1.1.cmml"><mrow id="S5.SS1.p1.6.m6.7.7.2.2.1.1.2" xref="S5.SS1.p1.6.m6.7.7.2.2.1.1.2.cmml"><mi id="S5.SS1.p1.6.m6.7.7.2.2.1.1.2.2" mathsize="90%" xref="S5.SS1.p1.6.m6.7.7.2.2.1.1.2.2.cmml">p</mi><mo id="S5.SS1.p1.6.m6.7.7.2.2.1.1.2.1" xref="S5.SS1.p1.6.m6.7.7.2.2.1.1.2.1.cmml">⁢</mo><mi id="S5.SS1.p1.6.m6.7.7.2.2.1.1.2.3" mathsize="90%" xref="S5.SS1.p1.6.m6.7.7.2.2.1.1.2.3.cmml">r</mi><mo id="S5.SS1.p1.6.m6.7.7.2.2.1.1.2.1a" xref="S5.SS1.p1.6.m6.7.7.2.2.1.1.2.1.cmml">⁢</mo><mi id="S5.SS1.p1.6.m6.7.7.2.2.1.1.2.4" mathsize="90%" xref="S5.SS1.p1.6.m6.7.7.2.2.1.1.2.4.cmml">e</mi><mo id="S5.SS1.p1.6.m6.7.7.2.2.1.1.2.1b" xref="S5.SS1.p1.6.m6.7.7.2.2.1.1.2.1.cmml">⁢</mo><mi id="S5.SS1.p1.6.m6.7.7.2.2.1.1.2.5" mathsize="90%" xref="S5.SS1.p1.6.m6.7.7.2.2.1.1.2.5.cmml">c</mi><mo id="S5.SS1.p1.6.m6.7.7.2.2.1.1.2.1c" xref="S5.SS1.p1.6.m6.7.7.2.2.1.1.2.1.cmml">⁢</mo><mi id="S5.SS1.p1.6.m6.7.7.2.2.1.1.2.6" mathsize="90%" xref="S5.SS1.p1.6.m6.7.7.2.2.1.1.2.6.cmml">i</mi><mo id="S5.SS1.p1.6.m6.7.7.2.2.1.1.2.1d" xref="S5.SS1.p1.6.m6.7.7.2.2.1.1.2.1.cmml">⁢</mo><mi id="S5.SS1.p1.6.m6.7.7.2.2.1.1.2.7" mathsize="90%" xref="S5.SS1.p1.6.m6.7.7.2.2.1.1.2.7.cmml">s</mi><mo id="S5.SS1.p1.6.m6.7.7.2.2.1.1.2.1e" xref="S5.SS1.p1.6.m6.7.7.2.2.1.1.2.1.cmml">⁢</mo><mi id="S5.SS1.p1.6.m6.7.7.2.2.1.1.2.8" mathsize="90%" xref="S5.SS1.p1.6.m6.7.7.2.2.1.1.2.8.cmml">i</mi><mo id="S5.SS1.p1.6.m6.7.7.2.2.1.1.2.1f" xref="S5.SS1.p1.6.m6.7.7.2.2.1.1.2.1.cmml">⁢</mo><mi id="S5.SS1.p1.6.m6.7.7.2.2.1.1.2.9" mathsize="90%" xref="S5.SS1.p1.6.m6.7.7.2.2.1.1.2.9.cmml">o</mi><mo id="S5.SS1.p1.6.m6.7.7.2.2.1.1.2.1g" xref="S5.SS1.p1.6.m6.7.7.2.2.1.1.2.1.cmml">⁢</mo><mi id="S5.SS1.p1.6.m6.7.7.2.2.1.1.2.10" mathsize="90%" xref="S5.SS1.p1.6.m6.7.7.2.2.1.1.2.10.cmml">n</mi><mo id="S5.SS1.p1.6.m6.7.7.2.2.1.1.2.1h" xref="S5.SS1.p1.6.m6.7.7.2.2.1.1.2.1.cmml">⁢</mo><mrow id="S5.SS1.p1.6.m6.7.7.2.2.1.1.2.11.2" xref="S5.SS1.p1.6.m6.7.7.2.2.1.1.2.cmml"><mo id="S5.SS1.p1.6.m6.7.7.2.2.1.1.2.11.2.1" maxsize="90%" minsize="90%" xref="S5.SS1.p1.6.m6.7.7.2.2.1.1.2.cmml">(</mo><mi id="S5.SS1.p1.6.m6.4.4" mathsize="90%" xref="S5.SS1.p1.6.m6.4.4.cmml">i</mi><mo id="S5.SS1.p1.6.m6.7.7.2.2.1.1.2.11.2.2" maxsize="90%" minsize="90%" xref="S5.SS1.p1.6.m6.7.7.2.2.1.1.2.cmml">)</mo></mrow></mrow><mo id="S5.SS1.p1.6.m6.7.7.2.2.1.1.1" mathsize="90%" xref="S5.SS1.p1.6.m6.7.7.2.2.1.1.1.cmml">+</mo><mrow id="S5.SS1.p1.6.m6.7.7.2.2.1.1.3" xref="S5.SS1.p1.6.m6.7.7.2.2.1.1.3.cmml"><mi id="S5.SS1.p1.6.m6.7.7.2.2.1.1.3.2" mathsize="90%" xref="S5.SS1.p1.6.m6.7.7.2.2.1.1.3.2.cmml">r</mi><mo id="S5.SS1.p1.6.m6.7.7.2.2.1.1.3.1" xref="S5.SS1.p1.6.m6.7.7.2.2.1.1.3.1.cmml">⁢</mo><mi id="S5.SS1.p1.6.m6.7.7.2.2.1.1.3.3" mathsize="90%" xref="S5.SS1.p1.6.m6.7.7.2.2.1.1.3.3.cmml">e</mi><mo id="S5.SS1.p1.6.m6.7.7.2.2.1.1.3.1a" xref="S5.SS1.p1.6.m6.7.7.2.2.1.1.3.1.cmml">⁢</mo><mi id="S5.SS1.p1.6.m6.7.7.2.2.1.1.3.4" mathsize="90%" xref="S5.SS1.p1.6.m6.7.7.2.2.1.1.3.4.cmml">c</mi><mo id="S5.SS1.p1.6.m6.7.7.2.2.1.1.3.1b" xref="S5.SS1.p1.6.m6.7.7.2.2.1.1.3.1.cmml">⁢</mo><mi id="S5.SS1.p1.6.m6.7.7.2.2.1.1.3.5" mathsize="90%" xref="S5.SS1.p1.6.m6.7.7.2.2.1.1.3.5.cmml">a</mi><mo id="S5.SS1.p1.6.m6.7.7.2.2.1.1.3.1c" xref="S5.SS1.p1.6.m6.7.7.2.2.1.1.3.1.cmml">⁢</mo><mi id="S5.SS1.p1.6.m6.7.7.2.2.1.1.3.6" mathsize="90%" xref="S5.SS1.p1.6.m6.7.7.2.2.1.1.3.6.cmml">l</mi><mo id="S5.SS1.p1.6.m6.7.7.2.2.1.1.3.1d" xref="S5.SS1.p1.6.m6.7.7.2.2.1.1.3.1.cmml">⁢</mo><mi id="S5.SS1.p1.6.m6.7.7.2.2.1.1.3.7" mathsize="90%" xref="S5.SS1.p1.6.m6.7.7.2.2.1.1.3.7.cmml">l</mi><mo id="S5.SS1.p1.6.m6.7.7.2.2.1.1.3.1e" xref="S5.SS1.p1.6.m6.7.7.2.2.1.1.3.1.cmml">⁢</mo><mrow id="S5.SS1.p1.6.m6.7.7.2.2.1.1.3.8.2" xref="S5.SS1.p1.6.m6.7.7.2.2.1.1.3.cmml"><mo id="S5.SS1.p1.6.m6.7.7.2.2.1.1.3.8.2.1" maxsize="90%" minsize="90%" xref="S5.SS1.p1.6.m6.7.7.2.2.1.1.3.cmml">(</mo><mi id="S5.SS1.p1.6.m6.5.5" mathsize="90%" xref="S5.SS1.p1.6.m6.5.5.cmml">i</mi><mo id="S5.SS1.p1.6.m6.7.7.2.2.1.1.3.8.2.2" maxsize="90%" minsize="90%" xref="S5.SS1.p1.6.m6.7.7.2.2.1.1.3.cmml">)</mo></mrow></mrow></mrow><mo id="S5.SS1.p1.6.m6.7.7.2.2.1.3" maxsize="90%" minsize="90%" xref="S5.SS1.p1.6.m6.7.7.2.2.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.6.m6.7b"><apply id="S5.SS1.p1.6.m6.7.7.cmml" xref="S5.SS1.p1.6.m6.7.7"><eq id="S5.SS1.p1.6.m6.7.7.3.cmml" xref="S5.SS1.p1.6.m6.7.7.3"></eq><apply id="S5.SS1.p1.6.m6.7.7.4.cmml" xref="S5.SS1.p1.6.m6.7.7.4"><times id="S5.SS1.p1.6.m6.7.7.4.1.cmml" xref="S5.SS1.p1.6.m6.7.7.4.1"></times><ci id="S5.SS1.p1.6.m6.7.7.4.2.cmml" xref="S5.SS1.p1.6.m6.7.7.4.2">𝐹</ci><cn id="S5.SS1.p1.6.m6.7.7.4.3.cmml" type="integer" xref="S5.SS1.p1.6.m6.7.7.4.3">1</cn><ci id="S5.SS1.p1.6.m6.1.1.cmml" xref="S5.SS1.p1.6.m6.1.1">𝑖</ci></apply><apply id="S5.SS1.p1.6.m6.7.7.2.cmml" xref="S5.SS1.p1.6.m6.7.7.2"><divide id="S5.SS1.p1.6.m6.7.7.2.3.cmml" xref="S5.SS1.p1.6.m6.7.7.2.3"></divide><apply id="S5.SS1.p1.6.m6.6.6.1.1.cmml" xref="S5.SS1.p1.6.m6.6.6.1.1"><times id="S5.SS1.p1.6.m6.6.6.1.1.2.cmml" xref="S5.SS1.p1.6.m6.6.6.1.1.2"></times><cn id="S5.SS1.p1.6.m6.6.6.1.1.3.cmml" type="integer" xref="S5.SS1.p1.6.m6.6.6.1.1.3">2</cn><apply id="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.cmml" xref="S5.SS1.p1.6.m6.6.6.1.1.1.1"><times id="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.1.cmml" xref="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.1"></times><apply id="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.2.cmml" xref="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.2"><ci id="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.2.1.cmml" xref="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.2.1">⋅</ci><apply id="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.2.2.cmml" xref="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.2.2"><times id="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.2.2.1.cmml" xref="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.2.2.1"></times><ci id="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.2.2.2.cmml" xref="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.2.2.2">𝑝</ci><ci id="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.2.2.3.cmml" xref="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.2.2.3">𝑟</ci><ci id="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.2.2.4.cmml" xref="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.2.2.4">𝑒</ci><ci id="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.2.2.5.cmml" xref="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.2.2.5">𝑐</ci><ci id="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.2.2.6.cmml" xref="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.2.2.6">𝑖</ci><ci id="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.2.2.7.cmml" xref="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.2.2.7">𝑠</ci><ci id="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.2.2.8.cmml" xref="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.2.2.8">𝑖</ci><ci id="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.2.2.9.cmml" xref="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.2.2.9">𝑜</ci><ci id="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.2.2.10.cmml" xref="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.2.2.10">𝑛</ci><ci id="S5.SS1.p1.6.m6.2.2.cmml" xref="S5.SS1.p1.6.m6.2.2">𝑖</ci></apply><ci id="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.2.3.cmml" xref="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.2.3">𝑟</ci></apply><ci id="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.3.cmml" xref="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.3">𝑒</ci><ci id="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.4.cmml" xref="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.4">𝑐</ci><ci id="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.5.cmml" xref="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.5">𝑎</ci><ci id="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.6.cmml" xref="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.6">𝑙</ci><ci id="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.7.cmml" xref="S5.SS1.p1.6.m6.6.6.1.1.1.1.1.7">𝑙</ci><ci id="S5.SS1.p1.6.m6.3.3.cmml" xref="S5.SS1.p1.6.m6.3.3">𝑖</ci></apply></apply><apply id="S5.SS1.p1.6.m6.7.7.2.2.1.1.cmml" xref="S5.SS1.p1.6.m6.7.7.2.2.1"><plus id="S5.SS1.p1.6.m6.7.7.2.2.1.1.1.cmml" xref="S5.SS1.p1.6.m6.7.7.2.2.1.1.1"></plus><apply id="S5.SS1.p1.6.m6.7.7.2.2.1.1.2.cmml" xref="S5.SS1.p1.6.m6.7.7.2.2.1.1.2"><times id="S5.SS1.p1.6.m6.7.7.2.2.1.1.2.1.cmml" xref="S5.SS1.p1.6.m6.7.7.2.2.1.1.2.1"></times><ci id="S5.SS1.p1.6.m6.7.7.2.2.1.1.2.2.cmml" xref="S5.SS1.p1.6.m6.7.7.2.2.1.1.2.2">𝑝</ci><ci id="S5.SS1.p1.6.m6.7.7.2.2.1.1.2.3.cmml" xref="S5.SS1.p1.6.m6.7.7.2.2.1.1.2.3">𝑟</ci><ci id="S5.SS1.p1.6.m6.7.7.2.2.1.1.2.4.cmml" xref="S5.SS1.p1.6.m6.7.7.2.2.1.1.2.4">𝑒</ci><ci id="S5.SS1.p1.6.m6.7.7.2.2.1.1.2.5.cmml" xref="S5.SS1.p1.6.m6.7.7.2.2.1.1.2.5">𝑐</ci><ci id="S5.SS1.p1.6.m6.7.7.2.2.1.1.2.6.cmml" xref="S5.SS1.p1.6.m6.7.7.2.2.1.1.2.6">𝑖</ci><ci id="S5.SS1.p1.6.m6.7.7.2.2.1.1.2.7.cmml" xref="S5.SS1.p1.6.m6.7.7.2.2.1.1.2.7">𝑠</ci><ci id="S5.SS1.p1.6.m6.7.7.2.2.1.1.2.8.cmml" xref="S5.SS1.p1.6.m6.7.7.2.2.1.1.2.8">𝑖</ci><ci id="S5.SS1.p1.6.m6.7.7.2.2.1.1.2.9.cmml" xref="S5.SS1.p1.6.m6.7.7.2.2.1.1.2.9">𝑜</ci><ci id="S5.SS1.p1.6.m6.7.7.2.2.1.1.2.10.cmml" xref="S5.SS1.p1.6.m6.7.7.2.2.1.1.2.10">𝑛</ci><ci id="S5.SS1.p1.6.m6.4.4.cmml" xref="S5.SS1.p1.6.m6.4.4">𝑖</ci></apply><apply id="S5.SS1.p1.6.m6.7.7.2.2.1.1.3.cmml" xref="S5.SS1.p1.6.m6.7.7.2.2.1.1.3"><times id="S5.SS1.p1.6.m6.7.7.2.2.1.1.3.1.cmml" xref="S5.SS1.p1.6.m6.7.7.2.2.1.1.3.1"></times><ci id="S5.SS1.p1.6.m6.7.7.2.2.1.1.3.2.cmml" xref="S5.SS1.p1.6.m6.7.7.2.2.1.1.3.2">𝑟</ci><ci id="S5.SS1.p1.6.m6.7.7.2.2.1.1.3.3.cmml" xref="S5.SS1.p1.6.m6.7.7.2.2.1.1.3.3">𝑒</ci><ci id="S5.SS1.p1.6.m6.7.7.2.2.1.1.3.4.cmml" xref="S5.SS1.p1.6.m6.7.7.2.2.1.1.3.4">𝑐</ci><ci id="S5.SS1.p1.6.m6.7.7.2.2.1.1.3.5.cmml" xref="S5.SS1.p1.6.m6.7.7.2.2.1.1.3.5">𝑎</ci><ci id="S5.SS1.p1.6.m6.7.7.2.2.1.1.3.6.cmml" xref="S5.SS1.p1.6.m6.7.7.2.2.1.1.3.6">𝑙</ci><ci id="S5.SS1.p1.6.m6.7.7.2.2.1.1.3.7.cmml" xref="S5.SS1.p1.6.m6.7.7.2.2.1.1.3.7">𝑙</ci><ci id="S5.SS1.p1.6.m6.5.5.cmml" xref="S5.SS1.p1.6.m6.5.5">𝑖</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.6.m6.7c">F1(i)=2(precision(i)\cdot recall(i))/(precision(i)+recall(i))</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p1.6.m6.7d">italic_F 1 ( italic_i ) = 2 ( italic_p italic_r italic_e italic_c italic_i italic_s italic_i italic_o italic_n ( italic_i ) ⋅ italic_r italic_e italic_c italic_a italic_l italic_l ( italic_i ) ) / ( italic_p italic_r italic_e italic_c italic_i italic_s italic_i italic_o italic_n ( italic_i ) + italic_r italic_e italic_c italic_a italic_l italic_l ( italic_i ) )</annotation></semantics></math><span class="ltx_text" id="S5.SS1.p1.8.9" style="font-size:90%;">. where </span><math alttext="precision(i)=m_{i,i}/\sum_{j}m_{i,j}" class="ltx_Math" display="inline" id="S5.SS1.p1.7.m7.5"><semantics id="S5.SS1.p1.7.m7.5a"><mrow id="S5.SS1.p1.7.m7.5.6" xref="S5.SS1.p1.7.m7.5.6.cmml"><mrow id="S5.SS1.p1.7.m7.5.6.2" xref="S5.SS1.p1.7.m7.5.6.2.cmml"><mi id="S5.SS1.p1.7.m7.5.6.2.2" mathsize="90%" xref="S5.SS1.p1.7.m7.5.6.2.2.cmml">p</mi><mo id="S5.SS1.p1.7.m7.5.6.2.1" xref="S5.SS1.p1.7.m7.5.6.2.1.cmml">⁢</mo><mi id="S5.SS1.p1.7.m7.5.6.2.3" mathsize="90%" xref="S5.SS1.p1.7.m7.5.6.2.3.cmml">r</mi><mo id="S5.SS1.p1.7.m7.5.6.2.1a" xref="S5.SS1.p1.7.m7.5.6.2.1.cmml">⁢</mo><mi id="S5.SS1.p1.7.m7.5.6.2.4" mathsize="90%" xref="S5.SS1.p1.7.m7.5.6.2.4.cmml">e</mi><mo id="S5.SS1.p1.7.m7.5.6.2.1b" xref="S5.SS1.p1.7.m7.5.6.2.1.cmml">⁢</mo><mi id="S5.SS1.p1.7.m7.5.6.2.5" mathsize="90%" xref="S5.SS1.p1.7.m7.5.6.2.5.cmml">c</mi><mo id="S5.SS1.p1.7.m7.5.6.2.1c" xref="S5.SS1.p1.7.m7.5.6.2.1.cmml">⁢</mo><mi id="S5.SS1.p1.7.m7.5.6.2.6" mathsize="90%" xref="S5.SS1.p1.7.m7.5.6.2.6.cmml">i</mi><mo id="S5.SS1.p1.7.m7.5.6.2.1d" xref="S5.SS1.p1.7.m7.5.6.2.1.cmml">⁢</mo><mi id="S5.SS1.p1.7.m7.5.6.2.7" mathsize="90%" xref="S5.SS1.p1.7.m7.5.6.2.7.cmml">s</mi><mo id="S5.SS1.p1.7.m7.5.6.2.1e" xref="S5.SS1.p1.7.m7.5.6.2.1.cmml">⁢</mo><mi id="S5.SS1.p1.7.m7.5.6.2.8" mathsize="90%" xref="S5.SS1.p1.7.m7.5.6.2.8.cmml">i</mi><mo id="S5.SS1.p1.7.m7.5.6.2.1f" xref="S5.SS1.p1.7.m7.5.6.2.1.cmml">⁢</mo><mi id="S5.SS1.p1.7.m7.5.6.2.9" mathsize="90%" xref="S5.SS1.p1.7.m7.5.6.2.9.cmml">o</mi><mo id="S5.SS1.p1.7.m7.5.6.2.1g" xref="S5.SS1.p1.7.m7.5.6.2.1.cmml">⁢</mo><mi id="S5.SS1.p1.7.m7.5.6.2.10" mathsize="90%" xref="S5.SS1.p1.7.m7.5.6.2.10.cmml">n</mi><mo id="S5.SS1.p1.7.m7.5.6.2.1h" xref="S5.SS1.p1.7.m7.5.6.2.1.cmml">⁢</mo><mrow id="S5.SS1.p1.7.m7.5.6.2.11.2" xref="S5.SS1.p1.7.m7.5.6.2.cmml"><mo id="S5.SS1.p1.7.m7.5.6.2.11.2.1" maxsize="90%" minsize="90%" xref="S5.SS1.p1.7.m7.5.6.2.cmml">(</mo><mi id="S5.SS1.p1.7.m7.5.5" mathsize="90%" xref="S5.SS1.p1.7.m7.5.5.cmml">i</mi><mo id="S5.SS1.p1.7.m7.5.6.2.11.2.2" maxsize="90%" minsize="90%" xref="S5.SS1.p1.7.m7.5.6.2.cmml">)</mo></mrow></mrow><mo id="S5.SS1.p1.7.m7.5.6.1" mathsize="90%" xref="S5.SS1.p1.7.m7.5.6.1.cmml">=</mo><mrow id="S5.SS1.p1.7.m7.5.6.3" xref="S5.SS1.p1.7.m7.5.6.3.cmml"><msub id="S5.SS1.p1.7.m7.5.6.3.2" xref="S5.SS1.p1.7.m7.5.6.3.2.cmml"><mi id="S5.SS1.p1.7.m7.5.6.3.2.2" mathsize="90%" xref="S5.SS1.p1.7.m7.5.6.3.2.2.cmml">m</mi><mrow id="S5.SS1.p1.7.m7.2.2.2.4" xref="S5.SS1.p1.7.m7.2.2.2.3.cmml"><mi id="S5.SS1.p1.7.m7.1.1.1.1" mathsize="90%" xref="S5.SS1.p1.7.m7.1.1.1.1.cmml">i</mi><mo id="S5.SS1.p1.7.m7.2.2.2.4.1" mathsize="90%" xref="S5.SS1.p1.7.m7.2.2.2.3.cmml">,</mo><mi id="S5.SS1.p1.7.m7.2.2.2.2" mathsize="90%" xref="S5.SS1.p1.7.m7.2.2.2.2.cmml">i</mi></mrow></msub><mo id="S5.SS1.p1.7.m7.5.6.3.1" maxsize="90%" minsize="90%" rspace="0.055em" stretchy="true" symmetric="true" xref="S5.SS1.p1.7.m7.5.6.3.1.cmml">/</mo><mrow id="S5.SS1.p1.7.m7.5.6.3.3" xref="S5.SS1.p1.7.m7.5.6.3.3.cmml"><msub id="S5.SS1.p1.7.m7.5.6.3.3.1" xref="S5.SS1.p1.7.m7.5.6.3.3.1.cmml"><mo id="S5.SS1.p1.7.m7.5.6.3.3.1.2" maxsize="90%" minsize="90%" stretchy="true" xref="S5.SS1.p1.7.m7.5.6.3.3.1.2.cmml">∑</mo><mi id="S5.SS1.p1.7.m7.5.6.3.3.1.3" mathsize="90%" xref="S5.SS1.p1.7.m7.5.6.3.3.1.3.cmml">j</mi></msub><msub id="S5.SS1.p1.7.m7.5.6.3.3.2" xref="S5.SS1.p1.7.m7.5.6.3.3.2.cmml"><mi id="S5.SS1.p1.7.m7.5.6.3.3.2.2" mathsize="90%" xref="S5.SS1.p1.7.m7.5.6.3.3.2.2.cmml">m</mi><mrow id="S5.SS1.p1.7.m7.4.4.2.4" xref="S5.SS1.p1.7.m7.4.4.2.3.cmml"><mi id="S5.SS1.p1.7.m7.3.3.1.1" mathsize="90%" xref="S5.SS1.p1.7.m7.3.3.1.1.cmml">i</mi><mo id="S5.SS1.p1.7.m7.4.4.2.4.1" mathsize="90%" xref="S5.SS1.p1.7.m7.4.4.2.3.cmml">,</mo><mi id="S5.SS1.p1.7.m7.4.4.2.2" mathsize="90%" xref="S5.SS1.p1.7.m7.4.4.2.2.cmml">j</mi></mrow></msub></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.7.m7.5b"><apply id="S5.SS1.p1.7.m7.5.6.cmml" xref="S5.SS1.p1.7.m7.5.6"><eq id="S5.SS1.p1.7.m7.5.6.1.cmml" xref="S5.SS1.p1.7.m7.5.6.1"></eq><apply id="S5.SS1.p1.7.m7.5.6.2.cmml" xref="S5.SS1.p1.7.m7.5.6.2"><times id="S5.SS1.p1.7.m7.5.6.2.1.cmml" xref="S5.SS1.p1.7.m7.5.6.2.1"></times><ci id="S5.SS1.p1.7.m7.5.6.2.2.cmml" xref="S5.SS1.p1.7.m7.5.6.2.2">𝑝</ci><ci id="S5.SS1.p1.7.m7.5.6.2.3.cmml" xref="S5.SS1.p1.7.m7.5.6.2.3">𝑟</ci><ci id="S5.SS1.p1.7.m7.5.6.2.4.cmml" xref="S5.SS1.p1.7.m7.5.6.2.4">𝑒</ci><ci id="S5.SS1.p1.7.m7.5.6.2.5.cmml" xref="S5.SS1.p1.7.m7.5.6.2.5">𝑐</ci><ci id="S5.SS1.p1.7.m7.5.6.2.6.cmml" xref="S5.SS1.p1.7.m7.5.6.2.6">𝑖</ci><ci id="S5.SS1.p1.7.m7.5.6.2.7.cmml" xref="S5.SS1.p1.7.m7.5.6.2.7">𝑠</ci><ci id="S5.SS1.p1.7.m7.5.6.2.8.cmml" xref="S5.SS1.p1.7.m7.5.6.2.8">𝑖</ci><ci id="S5.SS1.p1.7.m7.5.6.2.9.cmml" xref="S5.SS1.p1.7.m7.5.6.2.9">𝑜</ci><ci id="S5.SS1.p1.7.m7.5.6.2.10.cmml" xref="S5.SS1.p1.7.m7.5.6.2.10">𝑛</ci><ci id="S5.SS1.p1.7.m7.5.5.cmml" xref="S5.SS1.p1.7.m7.5.5">𝑖</ci></apply><apply id="S5.SS1.p1.7.m7.5.6.3.cmml" xref="S5.SS1.p1.7.m7.5.6.3"><divide id="S5.SS1.p1.7.m7.5.6.3.1.cmml" xref="S5.SS1.p1.7.m7.5.6.3.1"></divide><apply id="S5.SS1.p1.7.m7.5.6.3.2.cmml" xref="S5.SS1.p1.7.m7.5.6.3.2"><csymbol cd="ambiguous" id="S5.SS1.p1.7.m7.5.6.3.2.1.cmml" xref="S5.SS1.p1.7.m7.5.6.3.2">subscript</csymbol><ci id="S5.SS1.p1.7.m7.5.6.3.2.2.cmml" xref="S5.SS1.p1.7.m7.5.6.3.2.2">𝑚</ci><list id="S5.SS1.p1.7.m7.2.2.2.3.cmml" xref="S5.SS1.p1.7.m7.2.2.2.4"><ci id="S5.SS1.p1.7.m7.1.1.1.1.cmml" xref="S5.SS1.p1.7.m7.1.1.1.1">𝑖</ci><ci id="S5.SS1.p1.7.m7.2.2.2.2.cmml" xref="S5.SS1.p1.7.m7.2.2.2.2">𝑖</ci></list></apply><apply id="S5.SS1.p1.7.m7.5.6.3.3.cmml" xref="S5.SS1.p1.7.m7.5.6.3.3"><apply id="S5.SS1.p1.7.m7.5.6.3.3.1.cmml" xref="S5.SS1.p1.7.m7.5.6.3.3.1"><csymbol cd="ambiguous" id="S5.SS1.p1.7.m7.5.6.3.3.1.1.cmml" xref="S5.SS1.p1.7.m7.5.6.3.3.1">subscript</csymbol><sum id="S5.SS1.p1.7.m7.5.6.3.3.1.2.cmml" xref="S5.SS1.p1.7.m7.5.6.3.3.1.2"></sum><ci id="S5.SS1.p1.7.m7.5.6.3.3.1.3.cmml" xref="S5.SS1.p1.7.m7.5.6.3.3.1.3">𝑗</ci></apply><apply id="S5.SS1.p1.7.m7.5.6.3.3.2.cmml" xref="S5.SS1.p1.7.m7.5.6.3.3.2"><csymbol cd="ambiguous" id="S5.SS1.p1.7.m7.5.6.3.3.2.1.cmml" xref="S5.SS1.p1.7.m7.5.6.3.3.2">subscript</csymbol><ci id="S5.SS1.p1.7.m7.5.6.3.3.2.2.cmml" xref="S5.SS1.p1.7.m7.5.6.3.3.2.2">𝑚</ci><list id="S5.SS1.p1.7.m7.4.4.2.3.cmml" xref="S5.SS1.p1.7.m7.4.4.2.4"><ci id="S5.SS1.p1.7.m7.3.3.1.1.cmml" xref="S5.SS1.p1.7.m7.3.3.1.1">𝑖</ci><ci id="S5.SS1.p1.7.m7.4.4.2.2.cmml" xref="S5.SS1.p1.7.m7.4.4.2.2">𝑗</ci></list></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.7.m7.5c">precision(i)=m_{i,i}/\sum_{j}m_{i,j}</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p1.7.m7.5d">italic_p italic_r italic_e italic_c italic_i italic_s italic_i italic_o italic_n ( italic_i ) = italic_m start_POSTSUBSCRIPT italic_i , italic_i end_POSTSUBSCRIPT / ∑ start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT italic_m start_POSTSUBSCRIPT italic_i , italic_j end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="S5.SS1.p1.8.10" style="font-size:90%;"> and </span><math alttext="recall(i)=m_{i,i}/\sum_{j}m_{j,i}" class="ltx_Math" display="inline" id="S5.SS1.p1.8.m8.5"><semantics id="S5.SS1.p1.8.m8.5a"><mrow id="S5.SS1.p1.8.m8.5.6" xref="S5.SS1.p1.8.m8.5.6.cmml"><mrow id="S5.SS1.p1.8.m8.5.6.2" xref="S5.SS1.p1.8.m8.5.6.2.cmml"><mi id="S5.SS1.p1.8.m8.5.6.2.2" mathsize="90%" xref="S5.SS1.p1.8.m8.5.6.2.2.cmml">r</mi><mo id="S5.SS1.p1.8.m8.5.6.2.1" xref="S5.SS1.p1.8.m8.5.6.2.1.cmml">⁢</mo><mi id="S5.SS1.p1.8.m8.5.6.2.3" mathsize="90%" xref="S5.SS1.p1.8.m8.5.6.2.3.cmml">e</mi><mo id="S5.SS1.p1.8.m8.5.6.2.1a" xref="S5.SS1.p1.8.m8.5.6.2.1.cmml">⁢</mo><mi id="S5.SS1.p1.8.m8.5.6.2.4" mathsize="90%" xref="S5.SS1.p1.8.m8.5.6.2.4.cmml">c</mi><mo id="S5.SS1.p1.8.m8.5.6.2.1b" xref="S5.SS1.p1.8.m8.5.6.2.1.cmml">⁢</mo><mi id="S5.SS1.p1.8.m8.5.6.2.5" mathsize="90%" xref="S5.SS1.p1.8.m8.5.6.2.5.cmml">a</mi><mo id="S5.SS1.p1.8.m8.5.6.2.1c" xref="S5.SS1.p1.8.m8.5.6.2.1.cmml">⁢</mo><mi id="S5.SS1.p1.8.m8.5.6.2.6" mathsize="90%" xref="S5.SS1.p1.8.m8.5.6.2.6.cmml">l</mi><mo id="S5.SS1.p1.8.m8.5.6.2.1d" xref="S5.SS1.p1.8.m8.5.6.2.1.cmml">⁢</mo><mi id="S5.SS1.p1.8.m8.5.6.2.7" mathsize="90%" xref="S5.SS1.p1.8.m8.5.6.2.7.cmml">l</mi><mo id="S5.SS1.p1.8.m8.5.6.2.1e" xref="S5.SS1.p1.8.m8.5.6.2.1.cmml">⁢</mo><mrow id="S5.SS1.p1.8.m8.5.6.2.8.2" xref="S5.SS1.p1.8.m8.5.6.2.cmml"><mo id="S5.SS1.p1.8.m8.5.6.2.8.2.1" maxsize="90%" minsize="90%" xref="S5.SS1.p1.8.m8.5.6.2.cmml">(</mo><mi id="S5.SS1.p1.8.m8.5.5" mathsize="90%" xref="S5.SS1.p1.8.m8.5.5.cmml">i</mi><mo id="S5.SS1.p1.8.m8.5.6.2.8.2.2" maxsize="90%" minsize="90%" xref="S5.SS1.p1.8.m8.5.6.2.cmml">)</mo></mrow></mrow><mo id="S5.SS1.p1.8.m8.5.6.1" mathsize="90%" xref="S5.SS1.p1.8.m8.5.6.1.cmml">=</mo><mrow id="S5.SS1.p1.8.m8.5.6.3" xref="S5.SS1.p1.8.m8.5.6.3.cmml"><msub id="S5.SS1.p1.8.m8.5.6.3.2" xref="S5.SS1.p1.8.m8.5.6.3.2.cmml"><mi id="S5.SS1.p1.8.m8.5.6.3.2.2" mathsize="90%" xref="S5.SS1.p1.8.m8.5.6.3.2.2.cmml">m</mi><mrow id="S5.SS1.p1.8.m8.2.2.2.4" xref="S5.SS1.p1.8.m8.2.2.2.3.cmml"><mi id="S5.SS1.p1.8.m8.1.1.1.1" mathsize="90%" xref="S5.SS1.p1.8.m8.1.1.1.1.cmml">i</mi><mo id="S5.SS1.p1.8.m8.2.2.2.4.1" mathsize="90%" xref="S5.SS1.p1.8.m8.2.2.2.3.cmml">,</mo><mi id="S5.SS1.p1.8.m8.2.2.2.2" mathsize="90%" xref="S5.SS1.p1.8.m8.2.2.2.2.cmml">i</mi></mrow></msub><mo id="S5.SS1.p1.8.m8.5.6.3.1" maxsize="90%" minsize="90%" rspace="0.055em" stretchy="true" symmetric="true" xref="S5.SS1.p1.8.m8.5.6.3.1.cmml">/</mo><mrow id="S5.SS1.p1.8.m8.5.6.3.3" xref="S5.SS1.p1.8.m8.5.6.3.3.cmml"><msub id="S5.SS1.p1.8.m8.5.6.3.3.1" xref="S5.SS1.p1.8.m8.5.6.3.3.1.cmml"><mo id="S5.SS1.p1.8.m8.5.6.3.3.1.2" maxsize="90%" minsize="90%" stretchy="true" xref="S5.SS1.p1.8.m8.5.6.3.3.1.2.cmml">∑</mo><mi id="S5.SS1.p1.8.m8.5.6.3.3.1.3" mathsize="90%" xref="S5.SS1.p1.8.m8.5.6.3.3.1.3.cmml">j</mi></msub><msub id="S5.SS1.p1.8.m8.5.6.3.3.2" xref="S5.SS1.p1.8.m8.5.6.3.3.2.cmml"><mi id="S5.SS1.p1.8.m8.5.6.3.3.2.2" mathsize="90%" xref="S5.SS1.p1.8.m8.5.6.3.3.2.2.cmml">m</mi><mrow id="S5.SS1.p1.8.m8.4.4.2.4" xref="S5.SS1.p1.8.m8.4.4.2.3.cmml"><mi id="S5.SS1.p1.8.m8.3.3.1.1" mathsize="90%" xref="S5.SS1.p1.8.m8.3.3.1.1.cmml">j</mi><mo id="S5.SS1.p1.8.m8.4.4.2.4.1" mathsize="90%" xref="S5.SS1.p1.8.m8.4.4.2.3.cmml">,</mo><mi id="S5.SS1.p1.8.m8.4.4.2.2" mathsize="90%" xref="S5.SS1.p1.8.m8.4.4.2.2.cmml">i</mi></mrow></msub></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.8.m8.5b"><apply id="S5.SS1.p1.8.m8.5.6.cmml" xref="S5.SS1.p1.8.m8.5.6"><eq id="S5.SS1.p1.8.m8.5.6.1.cmml" xref="S5.SS1.p1.8.m8.5.6.1"></eq><apply id="S5.SS1.p1.8.m8.5.6.2.cmml" xref="S5.SS1.p1.8.m8.5.6.2"><times id="S5.SS1.p1.8.m8.5.6.2.1.cmml" xref="S5.SS1.p1.8.m8.5.6.2.1"></times><ci id="S5.SS1.p1.8.m8.5.6.2.2.cmml" xref="S5.SS1.p1.8.m8.5.6.2.2">𝑟</ci><ci id="S5.SS1.p1.8.m8.5.6.2.3.cmml" xref="S5.SS1.p1.8.m8.5.6.2.3">𝑒</ci><ci id="S5.SS1.p1.8.m8.5.6.2.4.cmml" xref="S5.SS1.p1.8.m8.5.6.2.4">𝑐</ci><ci id="S5.SS1.p1.8.m8.5.6.2.5.cmml" xref="S5.SS1.p1.8.m8.5.6.2.5">𝑎</ci><ci id="S5.SS1.p1.8.m8.5.6.2.6.cmml" xref="S5.SS1.p1.8.m8.5.6.2.6">𝑙</ci><ci id="S5.SS1.p1.8.m8.5.6.2.7.cmml" xref="S5.SS1.p1.8.m8.5.6.2.7">𝑙</ci><ci id="S5.SS1.p1.8.m8.5.5.cmml" xref="S5.SS1.p1.8.m8.5.5">𝑖</ci></apply><apply id="S5.SS1.p1.8.m8.5.6.3.cmml" xref="S5.SS1.p1.8.m8.5.6.3"><divide id="S5.SS1.p1.8.m8.5.6.3.1.cmml" xref="S5.SS1.p1.8.m8.5.6.3.1"></divide><apply id="S5.SS1.p1.8.m8.5.6.3.2.cmml" xref="S5.SS1.p1.8.m8.5.6.3.2"><csymbol cd="ambiguous" id="S5.SS1.p1.8.m8.5.6.3.2.1.cmml" xref="S5.SS1.p1.8.m8.5.6.3.2">subscript</csymbol><ci id="S5.SS1.p1.8.m8.5.6.3.2.2.cmml" xref="S5.SS1.p1.8.m8.5.6.3.2.2">𝑚</ci><list id="S5.SS1.p1.8.m8.2.2.2.3.cmml" xref="S5.SS1.p1.8.m8.2.2.2.4"><ci id="S5.SS1.p1.8.m8.1.1.1.1.cmml" xref="S5.SS1.p1.8.m8.1.1.1.1">𝑖</ci><ci id="S5.SS1.p1.8.m8.2.2.2.2.cmml" xref="S5.SS1.p1.8.m8.2.2.2.2">𝑖</ci></list></apply><apply id="S5.SS1.p1.8.m8.5.6.3.3.cmml" xref="S5.SS1.p1.8.m8.5.6.3.3"><apply id="S5.SS1.p1.8.m8.5.6.3.3.1.cmml" xref="S5.SS1.p1.8.m8.5.6.3.3.1"><csymbol cd="ambiguous" id="S5.SS1.p1.8.m8.5.6.3.3.1.1.cmml" xref="S5.SS1.p1.8.m8.5.6.3.3.1">subscript</csymbol><sum id="S5.SS1.p1.8.m8.5.6.3.3.1.2.cmml" xref="S5.SS1.p1.8.m8.5.6.3.3.1.2"></sum><ci id="S5.SS1.p1.8.m8.5.6.3.3.1.3.cmml" xref="S5.SS1.p1.8.m8.5.6.3.3.1.3">𝑗</ci></apply><apply id="S5.SS1.p1.8.m8.5.6.3.3.2.cmml" xref="S5.SS1.p1.8.m8.5.6.3.3.2"><csymbol cd="ambiguous" id="S5.SS1.p1.8.m8.5.6.3.3.2.1.cmml" xref="S5.SS1.p1.8.m8.5.6.3.3.2">subscript</csymbol><ci id="S5.SS1.p1.8.m8.5.6.3.3.2.2.cmml" xref="S5.SS1.p1.8.m8.5.6.3.3.2.2">𝑚</ci><list id="S5.SS1.p1.8.m8.4.4.2.3.cmml" xref="S5.SS1.p1.8.m8.4.4.2.4"><ci id="S5.SS1.p1.8.m8.3.3.1.1.cmml" xref="S5.SS1.p1.8.m8.3.3.1.1">𝑗</ci><ci id="S5.SS1.p1.8.m8.4.4.2.2.cmml" xref="S5.SS1.p1.8.m8.4.4.2.2">𝑖</ci></list></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.8.m8.5c">recall(i)=m_{i,i}/\sum_{j}m_{j,i}</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p1.8.m8.5d">italic_r italic_e italic_c italic_a italic_l italic_l ( italic_i ) = italic_m start_POSTSUBSCRIPT italic_i , italic_i end_POSTSUBSCRIPT / ∑ start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT italic_m start_POSTSUBSCRIPT italic_j , italic_i end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="S5.SS1.p1.8.11" style="font-size:90%;">.</span></p>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS1.p2">
<p class="ltx_p" id="S5.SS1.p2.6"><span class="ltx_text ltx_font_bold" id="S5.SS1.p2.6.1" style="font-size:90%;">RAG Evaluation. </span><span class="ltx_text" id="S5.SS1.p2.6.2" style="font-size:90%;">
Firstly, the performance of RAG can be measured by how precise the retrieval is, i.e., whether the retrieval text is relevant to the question. Thus, we can use the P@n metric. In particular, given that the relevance of external knowledge is crucial to the answer quality, we consider only the top three retrieval results. The precision of the RAG module is defined as </span><math alttext="P@3=\sum_{i\leq 3}I\{r_{i,j}\}/(3\sum_{j})" class="ltx_Math" display="inline" id="S5.SS1.p2.1.m1.4"><semantics id="S5.SS1.p2.1.m1.4a"><mrow id="S5.SS1.p2.1.m1.4.4" xref="S5.SS1.p2.1.m1.4.4.cmml"><mrow id="S5.SS1.p2.1.m1.4.4.4" xref="S5.SS1.p2.1.m1.4.4.4.cmml"><mi id="S5.SS1.p2.1.m1.4.4.4.2" mathsize="90%" xref="S5.SS1.p2.1.m1.4.4.4.2.cmml">P</mi><mo id="S5.SS1.p2.1.m1.4.4.4.1" xref="S5.SS1.p2.1.m1.4.4.4.1.cmml">⁢</mo><mi id="S5.SS1.p2.1.m1.4.4.4.3" mathsize="90%" mathvariant="normal" xref="S5.SS1.p2.1.m1.4.4.4.3.cmml">@</mi><mo id="S5.SS1.p2.1.m1.4.4.4.1a" xref="S5.SS1.p2.1.m1.4.4.4.1.cmml">⁢</mo><mn id="S5.SS1.p2.1.m1.4.4.4.4" mathsize="90%" xref="S5.SS1.p2.1.m1.4.4.4.4.cmml">3</mn></mrow><mo id="S5.SS1.p2.1.m1.4.4.3" mathsize="90%" rspace="0.111em" xref="S5.SS1.p2.1.m1.4.4.3.cmml">=</mo><mrow id="S5.SS1.p2.1.m1.4.4.2" xref="S5.SS1.p2.1.m1.4.4.2.cmml"><msub id="S5.SS1.p2.1.m1.4.4.2.3" xref="S5.SS1.p2.1.m1.4.4.2.3.cmml"><mo id="S5.SS1.p2.1.m1.4.4.2.3.2" maxsize="90%" minsize="90%" stretchy="true" xref="S5.SS1.p2.1.m1.4.4.2.3.2.cmml">∑</mo><mrow id="S5.SS1.p2.1.m1.4.4.2.3.3" xref="S5.SS1.p2.1.m1.4.4.2.3.3.cmml"><mi id="S5.SS1.p2.1.m1.4.4.2.3.3.2" mathsize="90%" xref="S5.SS1.p2.1.m1.4.4.2.3.3.2.cmml">i</mi><mo id="S5.SS1.p2.1.m1.4.4.2.3.3.1" mathsize="90%" xref="S5.SS1.p2.1.m1.4.4.2.3.3.1.cmml">≤</mo><mn id="S5.SS1.p2.1.m1.4.4.2.3.3.3" mathsize="90%" xref="S5.SS1.p2.1.m1.4.4.2.3.3.3.cmml">3</mn></mrow></msub><mrow id="S5.SS1.p2.1.m1.4.4.2.2" xref="S5.SS1.p2.1.m1.4.4.2.2.cmml"><mrow id="S5.SS1.p2.1.m1.3.3.1.1.1" xref="S5.SS1.p2.1.m1.3.3.1.1.1.cmml"><mi id="S5.SS1.p2.1.m1.3.3.1.1.1.3" mathsize="90%" xref="S5.SS1.p2.1.m1.3.3.1.1.1.3.cmml">I</mi><mo id="S5.SS1.p2.1.m1.3.3.1.1.1.2" xref="S5.SS1.p2.1.m1.3.3.1.1.1.2.cmml">⁢</mo><mrow id="S5.SS1.p2.1.m1.3.3.1.1.1.1.1" xref="S5.SS1.p2.1.m1.3.3.1.1.1.1.2.cmml"><mo id="S5.SS1.p2.1.m1.3.3.1.1.1.1.1.2" maxsize="90%" minsize="90%" xref="S5.SS1.p2.1.m1.3.3.1.1.1.1.2.cmml">{</mo><msub id="S5.SS1.p2.1.m1.3.3.1.1.1.1.1.1" xref="S5.SS1.p2.1.m1.3.3.1.1.1.1.1.1.cmml"><mi id="S5.SS1.p2.1.m1.3.3.1.1.1.1.1.1.2" mathsize="90%" xref="S5.SS1.p2.1.m1.3.3.1.1.1.1.1.1.2.cmml">r</mi><mrow id="S5.SS1.p2.1.m1.2.2.2.4" xref="S5.SS1.p2.1.m1.2.2.2.3.cmml"><mi id="S5.SS1.p2.1.m1.1.1.1.1" mathsize="90%" xref="S5.SS1.p2.1.m1.1.1.1.1.cmml">i</mi><mo id="S5.SS1.p2.1.m1.2.2.2.4.1" mathsize="90%" xref="S5.SS1.p2.1.m1.2.2.2.3.cmml">,</mo><mi id="S5.SS1.p2.1.m1.2.2.2.2" mathsize="90%" xref="S5.SS1.p2.1.m1.2.2.2.2.cmml">j</mi></mrow></msub><mo id="S5.SS1.p2.1.m1.3.3.1.1.1.1.1.3" maxsize="90%" minsize="90%" xref="S5.SS1.p2.1.m1.3.3.1.1.1.1.2.cmml">}</mo></mrow></mrow><mo id="S5.SS1.p2.1.m1.4.4.2.2.3" maxsize="90%" minsize="90%" stretchy="true" symmetric="true" xref="S5.SS1.p2.1.m1.4.4.2.2.3.cmml">/</mo><mrow id="S5.SS1.p2.1.m1.4.4.2.2.2.1" xref="S5.SS1.p2.1.m1.4.4.2.2.2.1.1.cmml"><mo id="S5.SS1.p2.1.m1.4.4.2.2.2.1.2" maxsize="90%" minsize="90%" xref="S5.SS1.p2.1.m1.4.4.2.2.2.1.1.cmml">(</mo><mrow id="S5.SS1.p2.1.m1.4.4.2.2.2.1.1" xref="S5.SS1.p2.1.m1.4.4.2.2.2.1.1.cmml"><mn id="S5.SS1.p2.1.m1.4.4.2.2.2.1.1.2" mathsize="90%" xref="S5.SS1.p2.1.m1.4.4.2.2.2.1.1.2.cmml">3</mn><mo id="S5.SS1.p2.1.m1.4.4.2.2.2.1.1.1" xref="S5.SS1.p2.1.m1.4.4.2.2.2.1.1.1.cmml">⁢</mo><msub id="S5.SS1.p2.1.m1.4.4.2.2.2.1.1.3" xref="S5.SS1.p2.1.m1.4.4.2.2.2.1.1.3.cmml"><mo id="S5.SS1.p2.1.m1.4.4.2.2.2.1.1.3.2" maxsize="90%" minsize="90%" rspace="0em" stretchy="true" xref="S5.SS1.p2.1.m1.4.4.2.2.2.1.1.3.2.cmml">∑</mo><mi id="S5.SS1.p2.1.m1.4.4.2.2.2.1.1.3.3" mathsize="90%" xref="S5.SS1.p2.1.m1.4.4.2.2.2.1.1.3.3.cmml">j</mi></msub></mrow><mo id="S5.SS1.p2.1.m1.4.4.2.2.2.1.3" maxsize="90%" minsize="90%" xref="S5.SS1.p2.1.m1.4.4.2.2.2.1.1.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p2.1.m1.4b"><apply id="S5.SS1.p2.1.m1.4.4.cmml" xref="S5.SS1.p2.1.m1.4.4"><eq id="S5.SS1.p2.1.m1.4.4.3.cmml" xref="S5.SS1.p2.1.m1.4.4.3"></eq><apply id="S5.SS1.p2.1.m1.4.4.4.cmml" xref="S5.SS1.p2.1.m1.4.4.4"><times id="S5.SS1.p2.1.m1.4.4.4.1.cmml" xref="S5.SS1.p2.1.m1.4.4.4.1"></times><ci id="S5.SS1.p2.1.m1.4.4.4.2.cmml" xref="S5.SS1.p2.1.m1.4.4.4.2">𝑃</ci><ci id="S5.SS1.p2.1.m1.4.4.4.3.cmml" xref="S5.SS1.p2.1.m1.4.4.4.3">@</ci><cn id="S5.SS1.p2.1.m1.4.4.4.4.cmml" type="integer" xref="S5.SS1.p2.1.m1.4.4.4.4">3</cn></apply><apply id="S5.SS1.p2.1.m1.4.4.2.cmml" xref="S5.SS1.p2.1.m1.4.4.2"><apply id="S5.SS1.p2.1.m1.4.4.2.3.cmml" xref="S5.SS1.p2.1.m1.4.4.2.3"><csymbol cd="ambiguous" id="S5.SS1.p2.1.m1.4.4.2.3.1.cmml" xref="S5.SS1.p2.1.m1.4.4.2.3">subscript</csymbol><sum id="S5.SS1.p2.1.m1.4.4.2.3.2.cmml" xref="S5.SS1.p2.1.m1.4.4.2.3.2"></sum><apply id="S5.SS1.p2.1.m1.4.4.2.3.3.cmml" xref="S5.SS1.p2.1.m1.4.4.2.3.3"><leq id="S5.SS1.p2.1.m1.4.4.2.3.3.1.cmml" xref="S5.SS1.p2.1.m1.4.4.2.3.3.1"></leq><ci id="S5.SS1.p2.1.m1.4.4.2.3.3.2.cmml" xref="S5.SS1.p2.1.m1.4.4.2.3.3.2">𝑖</ci><cn id="S5.SS1.p2.1.m1.4.4.2.3.3.3.cmml" type="integer" xref="S5.SS1.p2.1.m1.4.4.2.3.3.3">3</cn></apply></apply><apply id="S5.SS1.p2.1.m1.4.4.2.2.cmml" xref="S5.SS1.p2.1.m1.4.4.2.2"><divide id="S5.SS1.p2.1.m1.4.4.2.2.3.cmml" xref="S5.SS1.p2.1.m1.4.4.2.2.3"></divide><apply id="S5.SS1.p2.1.m1.3.3.1.1.1.cmml" xref="S5.SS1.p2.1.m1.3.3.1.1.1"><times id="S5.SS1.p2.1.m1.3.3.1.1.1.2.cmml" xref="S5.SS1.p2.1.m1.3.3.1.1.1.2"></times><ci id="S5.SS1.p2.1.m1.3.3.1.1.1.3.cmml" xref="S5.SS1.p2.1.m1.3.3.1.1.1.3">𝐼</ci><set id="S5.SS1.p2.1.m1.3.3.1.1.1.1.2.cmml" xref="S5.SS1.p2.1.m1.3.3.1.1.1.1.1"><apply id="S5.SS1.p2.1.m1.3.3.1.1.1.1.1.1.cmml" xref="S5.SS1.p2.1.m1.3.3.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S5.SS1.p2.1.m1.3.3.1.1.1.1.1.1.1.cmml" xref="S5.SS1.p2.1.m1.3.3.1.1.1.1.1.1">subscript</csymbol><ci id="S5.SS1.p2.1.m1.3.3.1.1.1.1.1.1.2.cmml" xref="S5.SS1.p2.1.m1.3.3.1.1.1.1.1.1.2">𝑟</ci><list id="S5.SS1.p2.1.m1.2.2.2.3.cmml" xref="S5.SS1.p2.1.m1.2.2.2.4"><ci id="S5.SS1.p2.1.m1.1.1.1.1.cmml" xref="S5.SS1.p2.1.m1.1.1.1.1">𝑖</ci><ci id="S5.SS1.p2.1.m1.2.2.2.2.cmml" xref="S5.SS1.p2.1.m1.2.2.2.2">𝑗</ci></list></apply></set></apply><apply id="S5.SS1.p2.1.m1.4.4.2.2.2.1.1.cmml" xref="S5.SS1.p2.1.m1.4.4.2.2.2.1"><times id="S5.SS1.p2.1.m1.4.4.2.2.2.1.1.1.cmml" xref="S5.SS1.p2.1.m1.4.4.2.2.2.1.1.1"></times><cn id="S5.SS1.p2.1.m1.4.4.2.2.2.1.1.2.cmml" type="integer" xref="S5.SS1.p2.1.m1.4.4.2.2.2.1.1.2">3</cn><apply id="S5.SS1.p2.1.m1.4.4.2.2.2.1.1.3.cmml" xref="S5.SS1.p2.1.m1.4.4.2.2.2.1.1.3"><csymbol cd="ambiguous" id="S5.SS1.p2.1.m1.4.4.2.2.2.1.1.3.1.cmml" xref="S5.SS1.p2.1.m1.4.4.2.2.2.1.1.3">subscript</csymbol><sum id="S5.SS1.p2.1.m1.4.4.2.2.2.1.1.3.2.cmml" xref="S5.SS1.p2.1.m1.4.4.2.2.2.1.1.3.2"></sum><ci id="S5.SS1.p2.1.m1.4.4.2.2.2.1.1.3.3.cmml" xref="S5.SS1.p2.1.m1.4.4.2.2.2.1.1.3.3">𝑗</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p2.1.m1.4c">P@3=\sum_{i\leq 3}I\{r_{i,j}\}/(3\sum_{j})</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p2.1.m1.4d">italic_P @ 3 = ∑ start_POSTSUBSCRIPT italic_i ≤ 3 end_POSTSUBSCRIPT italic_I { italic_r start_POSTSUBSCRIPT italic_i , italic_j end_POSTSUBSCRIPT } / ( 3 ∑ start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT )</annotation></semantics></math><span class="ltx_text" id="S5.SS1.p2.6.3" style="font-size:90%;">, where </span><math alttext="r_{i,j}" class="ltx_Math" display="inline" id="S5.SS1.p2.2.m2.2"><semantics id="S5.SS1.p2.2.m2.2a"><msub id="S5.SS1.p2.2.m2.2.3" xref="S5.SS1.p2.2.m2.2.3.cmml"><mi id="S5.SS1.p2.2.m2.2.3.2" mathsize="90%" xref="S5.SS1.p2.2.m2.2.3.2.cmml">r</mi><mrow id="S5.SS1.p2.2.m2.2.2.2.4" xref="S5.SS1.p2.2.m2.2.2.2.3.cmml"><mi id="S5.SS1.p2.2.m2.1.1.1.1" mathsize="90%" xref="S5.SS1.p2.2.m2.1.1.1.1.cmml">i</mi><mo id="S5.SS1.p2.2.m2.2.2.2.4.1" mathsize="90%" xref="S5.SS1.p2.2.m2.2.2.2.3.cmml">,</mo><mi id="S5.SS1.p2.2.m2.2.2.2.2" mathsize="90%" xref="S5.SS1.p2.2.m2.2.2.2.2.cmml">j</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S5.SS1.p2.2.m2.2b"><apply id="S5.SS1.p2.2.m2.2.3.cmml" xref="S5.SS1.p2.2.m2.2.3"><csymbol cd="ambiguous" id="S5.SS1.p2.2.m2.2.3.1.cmml" xref="S5.SS1.p2.2.m2.2.3">subscript</csymbol><ci id="S5.SS1.p2.2.m2.2.3.2.cmml" xref="S5.SS1.p2.2.m2.2.3.2">𝑟</ci><list id="S5.SS1.p2.2.m2.2.2.2.3.cmml" xref="S5.SS1.p2.2.m2.2.2.2.4"><ci id="S5.SS1.p2.2.m2.1.1.1.1.cmml" xref="S5.SS1.p2.2.m2.1.1.1.1">𝑖</ci><ci id="S5.SS1.p2.2.m2.2.2.2.2.cmml" xref="S5.SS1.p2.2.m2.2.2.2.2">𝑗</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p2.2.m2.2c">r_{i,j}</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p2.2.m2.2d">italic_r start_POSTSUBSCRIPT italic_i , italic_j end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="S5.SS1.p2.6.4" style="font-size:90%;"> is the </span><math alttext="i-" class="ltx_Math" display="inline" id="S5.SS1.p2.3.m3.1"><semantics id="S5.SS1.p2.3.m3.1a"><mrow id="S5.SS1.p2.3.m3.1.1" xref="S5.SS1.p2.3.m3.1.1.cmml"><mi id="S5.SS1.p2.3.m3.1.1.2" mathsize="90%" xref="S5.SS1.p2.3.m3.1.1.2.cmml">i</mi><mo id="S5.SS1.p2.3.m3.1.1.3" mathsize="90%" xref="S5.SS1.p2.3.m3.1.1.3.cmml">−</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p2.3.m3.1b"><apply id="S5.SS1.p2.3.m3.1.1.cmml" xref="S5.SS1.p2.3.m3.1.1"><csymbol cd="latexml" id="S5.SS1.p2.3.m3.1.1.1.cmml" xref="S5.SS1.p2.3.m3.1.1">limit-from</csymbol><ci id="S5.SS1.p2.3.m3.1.1.2.cmml" xref="S5.SS1.p2.3.m3.1.1.2">𝑖</ci><minus id="S5.SS1.p2.3.m3.1.1.3.cmml" xref="S5.SS1.p2.3.m3.1.1.3"></minus></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p2.3.m3.1c">i-</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p2.3.m3.1d">italic_i -</annotation></semantics></math><span class="ltx_text" id="S5.SS1.p2.6.5" style="font-size:90%;">th ranked text block in the top-3 retrieval results of query </span><math alttext="j" class="ltx_Math" display="inline" id="S5.SS1.p2.4.m4.1"><semantics id="S5.SS1.p2.4.m4.1a"><mi id="S5.SS1.p2.4.m4.1.1" mathsize="90%" xref="S5.SS1.p2.4.m4.1.1.cmml">j</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.p2.4.m4.1b"><ci id="S5.SS1.p2.4.m4.1.1.cmml" xref="S5.SS1.p2.4.m4.1.1">𝑗</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p2.4.m4.1c">j</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p2.4.m4.1d">italic_j</annotation></semantics></math><span class="ltx_text" id="S5.SS1.p2.6.6" style="font-size:90%;">, and </span><math alttext="I\{\}" class="ltx_Math" display="inline" id="S5.SS1.p2.5.m5.1"><semantics id="S5.SS1.p2.5.m5.1a"><mrow id="S5.SS1.p2.5.m5.1.1" xref="S5.SS1.p2.5.m5.1.1.cmml"><mi id="S5.SS1.p2.5.m5.1.1.2" mathsize="90%" xref="S5.SS1.p2.5.m5.1.1.2.cmml">I</mi><mo id="S5.SS1.p2.5.m5.1.1.1" xref="S5.SS1.p2.5.m5.1.1.1.cmml">⁢</mo><mrow id="S5.SS1.p2.5.m5.1.1.3.2" xref="S5.SS1.p2.5.m5.1.1.cmml"><mo id="S5.SS1.p2.5.m5.1.1.3.2.1" maxsize="90%" minsize="90%" xref="S5.SS1.p2.5.m5.1.1.3.1.cmml">{</mo><mo id="S5.SS1.p2.5.m5.1.1.3.2.2" maxsize="90%" minsize="90%" xref="S5.SS1.p2.5.m5.1.1.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p2.5.m5.1b"><apply id="S5.SS1.p2.5.m5.1.1.cmml" xref="S5.SS1.p2.5.m5.1.1"><times id="S5.SS1.p2.5.m5.1.1.1.cmml" xref="S5.SS1.p2.5.m5.1.1.1"></times><ci id="S5.SS1.p2.5.m5.1.1.2.cmml" xref="S5.SS1.p2.5.m5.1.1.2">𝐼</ci><list id="S5.SS1.p2.5.m5.1.1.3.1.cmml" xref="S5.SS1.p2.5.m5.1.1.3.2.1"></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p2.5.m5.1c">I\{\}</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p2.5.m5.1d">italic_I { }</annotation></semantics></math><span class="ltx_text" id="S5.SS1.p2.6.7" style="font-size:90%;"> is an indicator function that returns whether the text block is relevant as labeled in the retrieval annotation in Section </span><a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#S3" style="font-size:90%;" title="3. DQA Dataset Generation ‣ Revolutionizing Database Q&amp;A with Large Language Models: Comprehensive Benchmark and Evaluation"><span class="ltx_text ltx_ref_tag">3</span></a><span class="ltx_text" id="S5.SS1.p2.6.8" style="font-size:90%;">, </span><math alttext="\sum_{j}" class="ltx_Math" display="inline" id="S5.SS1.p2.6.m6.1"><semantics id="S5.SS1.p2.6.m6.1a"><msub id="S5.SS1.p2.6.m6.1.1" xref="S5.SS1.p2.6.m6.1.1.cmml"><mo id="S5.SS1.p2.6.m6.1.1.2" maxsize="90%" minsize="90%" stretchy="true" xref="S5.SS1.p2.6.m6.1.1.2.cmml">∑</mo><mi id="S5.SS1.p2.6.m6.1.1.3" mathsize="90%" xref="S5.SS1.p2.6.m6.1.1.3.cmml">j</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS1.p2.6.m6.1b"><apply id="S5.SS1.p2.6.m6.1.1.cmml" xref="S5.SS1.p2.6.m6.1.1"><csymbol cd="ambiguous" id="S5.SS1.p2.6.m6.1.1.1.cmml" xref="S5.SS1.p2.6.m6.1.1">subscript</csymbol><sum id="S5.SS1.p2.6.m6.1.1.2.cmml" xref="S5.SS1.p2.6.m6.1.1.2"></sum><ci id="S5.SS1.p2.6.m6.1.1.3.cmml" xref="S5.SS1.p2.6.m6.1.1.3">𝑗</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p2.6.m6.1c">\sum_{j}</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p2.6.m6.1d">∑ start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="S5.SS1.p2.6.9" style="font-size:90%;"> means the RAG module’s performance is averaged over all queries.</span></p>
</div>
<div class="ltx_para" id="S5.SS1.p3">
<p class="ltx_p" id="S5.SS1.p3.1"><span class="ltx_text" id="S5.SS1.p3.1.1" style="font-size:90%;">Secondly, the RAG module in the testbed is optional. The LLM can properly function without RAG or with incorrect RAG results. Therefore, we can also evaluate the performance of the RAG module by comparing the end-to-end performance with and without RAG.</span></p>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS1.p4">
<p class="ltx_p" id="S5.SS1.p4.1"><span class="ltx_text ltx_font_bold" id="S5.SS1.p4.1.1" style="font-size:90%;">TIG Evaluation. </span><span class="ltx_text" id="S5.SS1.p4.1.2" style="font-size:90%;">
The TIG module enhances the LLM by calling appropriate database tools and utilizing the interaction results between the tools and database instances. Two core dimensions need to be measured: (1) Can TIG select the correct set and order of tools for the query? (2) Can TIG correctly trigger the tool, i.e., does the tool invocation adhere to the prompt and tool format requirements? Therefore, we propose TSA (Tool Selection Accuracy) and TFA (Tool Format Accuracy) to measure these two dimensions respectively.</span></p>
</div>
<div class="ltx_para" id="S5.SS1.p5">
<p class="ltx_p" id="S5.SS1.p5.6"><span class="ltx_text ltx_font_italic" id="S5.SS1.p5.6.1" style="font-size:90%;">(1) TSA:</span><span class="ltx_text" id="S5.SS1.p5.6.2" style="font-size:90%;"> This metric measures whether the correct tools are chosen to solve problems. It is important to consider the order of actions to measure the DB-specific planning ability. For example, the input of the succeeding tool is usually based on and formulated from the preceding tool’s output. Therefore, if there is an error in the current tool invocation, the subsequent tool invocations will no longer be included in the metric calculation. Specifically, the TSA (Tool Selection Accuracy) is defined as:</span></p>
<table class="ltx_equation ltx_eqn_table" id="S5.E1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_left">(1)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="TSA=\sum_{i\geq 1,j}^{i\leq\min{k_{j},I\{t_{k_{j},j}\}=0}}I\{t_{i,j}\}\big{/}%
\sum_{j}k_{j}," class="ltx_Math" display="block" id="S5.E1.m1.9"><semantics id="S5.E1.m1.9a"><mrow id="S5.E1.m1.9.9.1" xref="S5.E1.m1.9.9.1.1.cmml"><mrow id="S5.E1.m1.9.9.1.1" xref="S5.E1.m1.9.9.1.1.cmml"><mrow id="S5.E1.m1.9.9.1.1.3" xref="S5.E1.m1.9.9.1.1.3.cmml"><mi id="S5.E1.m1.9.9.1.1.3.2" mathsize="90%" xref="S5.E1.m1.9.9.1.1.3.2.cmml">T</mi><mo id="S5.E1.m1.9.9.1.1.3.1" xref="S5.E1.m1.9.9.1.1.3.1.cmml">⁢</mo><mi id="S5.E1.m1.9.9.1.1.3.3" mathsize="90%" xref="S5.E1.m1.9.9.1.1.3.3.cmml">S</mi><mo id="S5.E1.m1.9.9.1.1.3.1a" xref="S5.E1.m1.9.9.1.1.3.1.cmml">⁢</mo><mi id="S5.E1.m1.9.9.1.1.3.4" mathsize="90%" xref="S5.E1.m1.9.9.1.1.3.4.cmml">A</mi></mrow><mo id="S5.E1.m1.9.9.1.1.2" mathsize="90%" rspace="0.111em" xref="S5.E1.m1.9.9.1.1.2.cmml">=</mo><mrow id="S5.E1.m1.9.9.1.1.1" xref="S5.E1.m1.9.9.1.1.1.cmml"><munderover id="S5.E1.m1.9.9.1.1.1.2" xref="S5.E1.m1.9.9.1.1.1.2.cmml"><mo id="S5.E1.m1.9.9.1.1.1.2.2.2" maxsize="90%" minsize="90%" movablelimits="false" stretchy="true" xref="S5.E1.m1.9.9.1.1.1.2.2.2.cmml">∑</mo><mrow id="S5.E1.m1.2.2.2" xref="S5.E1.m1.2.2.2.cmml"><mi id="S5.E1.m1.2.2.2.4" mathsize="90%" xref="S5.E1.m1.2.2.2.4.cmml">i</mi><mo id="S5.E1.m1.2.2.2.3" mathsize="90%" xref="S5.E1.m1.2.2.2.3.cmml">≥</mo><mrow id="S5.E1.m1.2.2.2.5.2" xref="S5.E1.m1.2.2.2.5.1.cmml"><mn id="S5.E1.m1.1.1.1.1" mathsize="90%" xref="S5.E1.m1.1.1.1.1.cmml">1</mn><mo id="S5.E1.m1.2.2.2.5.2.1" mathsize="90%" xref="S5.E1.m1.2.2.2.5.1.cmml">,</mo><mi id="S5.E1.m1.2.2.2.2" mathsize="90%" xref="S5.E1.m1.2.2.2.2.cmml">j</mi></mrow></mrow><mrow id="S5.E1.m1.6.6.4.4" xref="S5.E1.m1.6.6.4.5.cmml"><mrow id="S5.E1.m1.5.5.3.3.1" xref="S5.E1.m1.5.5.3.3.1.cmml"><mi id="S5.E1.m1.5.5.3.3.1.2" mathsize="90%" xref="S5.E1.m1.5.5.3.3.1.2.cmml">i</mi><mo id="S5.E1.m1.5.5.3.3.1.1" mathsize="90%" xref="S5.E1.m1.5.5.3.3.1.1.cmml">≤</mo><mrow id="S5.E1.m1.5.5.3.3.1.3" xref="S5.E1.m1.5.5.3.3.1.3.cmml"><mi id="S5.E1.m1.5.5.3.3.1.3.1" mathsize="90%" xref="S5.E1.m1.5.5.3.3.1.3.1.cmml">min</mi><mo id="S5.E1.m1.5.5.3.3.1.3a" lspace="0.167em" xref="S5.E1.m1.5.5.3.3.1.3.cmml">⁡</mo><msub id="S5.E1.m1.5.5.3.3.1.3.2" xref="S5.E1.m1.5.5.3.3.1.3.2.cmml"><mi id="S5.E1.m1.5.5.3.3.1.3.2.2" mathsize="90%" xref="S5.E1.m1.5.5.3.3.1.3.2.2.cmml">k</mi><mi id="S5.E1.m1.5.5.3.3.1.3.2.3" mathsize="90%" xref="S5.E1.m1.5.5.3.3.1.3.2.3.cmml">j</mi></msub></mrow></mrow><mo id="S5.E1.m1.6.6.4.4.3" mathsize="90%" xref="S5.E1.m1.6.6.4.5a.cmml">,</mo><mrow id="S5.E1.m1.6.6.4.4.2" xref="S5.E1.m1.6.6.4.4.2.cmml"><mrow id="S5.E1.m1.6.6.4.4.2.1" xref="S5.E1.m1.6.6.4.4.2.1.cmml"><mi id="S5.E1.m1.6.6.4.4.2.1.3" mathsize="90%" xref="S5.E1.m1.6.6.4.4.2.1.3.cmml">I</mi><mo id="S5.E1.m1.6.6.4.4.2.1.2" xref="S5.E1.m1.6.6.4.4.2.1.2.cmml">⁢</mo><mrow id="S5.E1.m1.6.6.4.4.2.1.1.1" xref="S5.E1.m1.6.6.4.4.2.1.1.2.cmml"><mo id="S5.E1.m1.6.6.4.4.2.1.1.1.2" maxsize="90%" minsize="90%" xref="S5.E1.m1.6.6.4.4.2.1.1.2.cmml">{</mo><msub id="S5.E1.m1.6.6.4.4.2.1.1.1.1" xref="S5.E1.m1.6.6.4.4.2.1.1.1.1.cmml"><mi id="S5.E1.m1.6.6.4.4.2.1.1.1.1.2" mathsize="90%" xref="S5.E1.m1.6.6.4.4.2.1.1.1.1.2.cmml">t</mi><mrow id="S5.E1.m1.4.4.2.2.2.2" xref="S5.E1.m1.4.4.2.2.2.3.cmml"><msub id="S5.E1.m1.4.4.2.2.2.2.1" xref="S5.E1.m1.4.4.2.2.2.2.1.cmml"><mi id="S5.E1.m1.4.4.2.2.2.2.1.2" mathsize="90%" xref="S5.E1.m1.4.4.2.2.2.2.1.2.cmml">k</mi><mi id="S5.E1.m1.4.4.2.2.2.2.1.3" mathsize="90%" xref="S5.E1.m1.4.4.2.2.2.2.1.3.cmml">j</mi></msub><mo id="S5.E1.m1.4.4.2.2.2.2.2" mathsize="90%" xref="S5.E1.m1.4.4.2.2.2.3.cmml">,</mo><mi id="S5.E1.m1.3.3.1.1.1.1" mathsize="90%" xref="S5.E1.m1.3.3.1.1.1.1.cmml">j</mi></mrow></msub><mo id="S5.E1.m1.6.6.4.4.2.1.1.1.3" maxsize="90%" minsize="90%" xref="S5.E1.m1.6.6.4.4.2.1.1.2.cmml">}</mo></mrow></mrow><mo id="S5.E1.m1.6.6.4.4.2.2" mathsize="90%" xref="S5.E1.m1.6.6.4.4.2.2.cmml">=</mo><mn id="S5.E1.m1.6.6.4.4.2.3" mathsize="90%" xref="S5.E1.m1.6.6.4.4.2.3.cmml">0</mn></mrow></mrow></munderover><mrow id="S5.E1.m1.9.9.1.1.1.1" xref="S5.E1.m1.9.9.1.1.1.1.cmml"><mrow id="S5.E1.m1.9.9.1.1.1.1.1" xref="S5.E1.m1.9.9.1.1.1.1.1.cmml"><mi id="S5.E1.m1.9.9.1.1.1.1.1.3" mathsize="90%" xref="S5.E1.m1.9.9.1.1.1.1.1.3.cmml">I</mi><mo id="S5.E1.m1.9.9.1.1.1.1.1.2" xref="S5.E1.m1.9.9.1.1.1.1.1.2.cmml">⁢</mo><mrow id="S5.E1.m1.9.9.1.1.1.1.1.1.1" xref="S5.E1.m1.9.9.1.1.1.1.1.1.2.cmml"><mo id="S5.E1.m1.9.9.1.1.1.1.1.1.1.2" maxsize="90%" minsize="90%" xref="S5.E1.m1.9.9.1.1.1.1.1.1.2.cmml">{</mo><msub id="S5.E1.m1.9.9.1.1.1.1.1.1.1.1" xref="S5.E1.m1.9.9.1.1.1.1.1.1.1.1.cmml"><mi id="S5.E1.m1.9.9.1.1.1.1.1.1.1.1.2" mathsize="90%" xref="S5.E1.m1.9.9.1.1.1.1.1.1.1.1.2.cmml">t</mi><mrow id="S5.E1.m1.8.8.2.4" xref="S5.E1.m1.8.8.2.3.cmml"><mi id="S5.E1.m1.7.7.1.1" mathsize="90%" xref="S5.E1.m1.7.7.1.1.cmml">i</mi><mo id="S5.E1.m1.8.8.2.4.1" mathsize="90%" xref="S5.E1.m1.8.8.2.3.cmml">,</mo><mi id="S5.E1.m1.8.8.2.2" mathsize="90%" xref="S5.E1.m1.8.8.2.2.cmml">j</mi></mrow></msub><mo id="S5.E1.m1.9.9.1.1.1.1.1.1.1.3" maxsize="90%" minsize="90%" xref="S5.E1.m1.9.9.1.1.1.1.1.1.2.cmml">}</mo></mrow></mrow><mo id="S5.E1.m1.9.9.1.1.1.1.2" maxsize="120%" minsize="120%" rspace="0.055em" stretchy="true" symmetric="true" xref="S5.E1.m1.9.9.1.1.1.1.2.cmml">/</mo><mrow id="S5.E1.m1.9.9.1.1.1.1.3" xref="S5.E1.m1.9.9.1.1.1.1.3.cmml"><munder id="S5.E1.m1.9.9.1.1.1.1.3.1" xref="S5.E1.m1.9.9.1.1.1.1.3.1.cmml"><mo id="S5.E1.m1.9.9.1.1.1.1.3.1.2" maxsize="90%" minsize="90%" movablelimits="false" stretchy="true" xref="S5.E1.m1.9.9.1.1.1.1.3.1.2.cmml">∑</mo><mi id="S5.E1.m1.9.9.1.1.1.1.3.1.3" mathsize="90%" xref="S5.E1.m1.9.9.1.1.1.1.3.1.3.cmml">j</mi></munder><msub id="S5.E1.m1.9.9.1.1.1.1.3.2" xref="S5.E1.m1.9.9.1.1.1.1.3.2.cmml"><mi id="S5.E1.m1.9.9.1.1.1.1.3.2.2" mathsize="90%" xref="S5.E1.m1.9.9.1.1.1.1.3.2.2.cmml">k</mi><mi id="S5.E1.m1.9.9.1.1.1.1.3.2.3" mathsize="90%" xref="S5.E1.m1.9.9.1.1.1.1.3.2.3.cmml">j</mi></msub></mrow></mrow></mrow></mrow><mo id="S5.E1.m1.9.9.1.2" mathsize="90%" xref="S5.E1.m1.9.9.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.E1.m1.9b"><apply id="S5.E1.m1.9.9.1.1.cmml" xref="S5.E1.m1.9.9.1"><eq id="S5.E1.m1.9.9.1.1.2.cmml" xref="S5.E1.m1.9.9.1.1.2"></eq><apply id="S5.E1.m1.9.9.1.1.3.cmml" xref="S5.E1.m1.9.9.1.1.3"><times id="S5.E1.m1.9.9.1.1.3.1.cmml" xref="S5.E1.m1.9.9.1.1.3.1"></times><ci id="S5.E1.m1.9.9.1.1.3.2.cmml" xref="S5.E1.m1.9.9.1.1.3.2">𝑇</ci><ci id="S5.E1.m1.9.9.1.1.3.3.cmml" xref="S5.E1.m1.9.9.1.1.3.3">𝑆</ci><ci id="S5.E1.m1.9.9.1.1.3.4.cmml" xref="S5.E1.m1.9.9.1.1.3.4">𝐴</ci></apply><apply id="S5.E1.m1.9.9.1.1.1.cmml" xref="S5.E1.m1.9.9.1.1.1"><apply id="S5.E1.m1.9.9.1.1.1.2.cmml" xref="S5.E1.m1.9.9.1.1.1.2"><csymbol cd="ambiguous" id="S5.E1.m1.9.9.1.1.1.2.1.cmml" xref="S5.E1.m1.9.9.1.1.1.2">superscript</csymbol><apply id="S5.E1.m1.9.9.1.1.1.2.2.cmml" xref="S5.E1.m1.9.9.1.1.1.2"><csymbol cd="ambiguous" id="S5.E1.m1.9.9.1.1.1.2.2.1.cmml" xref="S5.E1.m1.9.9.1.1.1.2">subscript</csymbol><sum id="S5.E1.m1.9.9.1.1.1.2.2.2.cmml" xref="S5.E1.m1.9.9.1.1.1.2.2.2"></sum><apply id="S5.E1.m1.2.2.2.cmml" xref="S5.E1.m1.2.2.2"><geq id="S5.E1.m1.2.2.2.3.cmml" xref="S5.E1.m1.2.2.2.3"></geq><ci id="S5.E1.m1.2.2.2.4.cmml" xref="S5.E1.m1.2.2.2.4">𝑖</ci><list id="S5.E1.m1.2.2.2.5.1.cmml" xref="S5.E1.m1.2.2.2.5.2"><cn id="S5.E1.m1.1.1.1.1.cmml" type="integer" xref="S5.E1.m1.1.1.1.1">1</cn><ci id="S5.E1.m1.2.2.2.2.cmml" xref="S5.E1.m1.2.2.2.2">𝑗</ci></list></apply></apply><apply id="S5.E1.m1.6.6.4.5.cmml" xref="S5.E1.m1.6.6.4.4"><csymbol cd="ambiguous" id="S5.E1.m1.6.6.4.5a.cmml" xref="S5.E1.m1.6.6.4.4.3">formulae-sequence</csymbol><apply id="S5.E1.m1.5.5.3.3.1.cmml" xref="S5.E1.m1.5.5.3.3.1"><leq id="S5.E1.m1.5.5.3.3.1.1.cmml" xref="S5.E1.m1.5.5.3.3.1.1"></leq><ci id="S5.E1.m1.5.5.3.3.1.2.cmml" xref="S5.E1.m1.5.5.3.3.1.2">𝑖</ci><apply id="S5.E1.m1.5.5.3.3.1.3.cmml" xref="S5.E1.m1.5.5.3.3.1.3"><min id="S5.E1.m1.5.5.3.3.1.3.1.cmml" xref="S5.E1.m1.5.5.3.3.1.3.1"></min><apply id="S5.E1.m1.5.5.3.3.1.3.2.cmml" xref="S5.E1.m1.5.5.3.3.1.3.2"><csymbol cd="ambiguous" id="S5.E1.m1.5.5.3.3.1.3.2.1.cmml" xref="S5.E1.m1.5.5.3.3.1.3.2">subscript</csymbol><ci id="S5.E1.m1.5.5.3.3.1.3.2.2.cmml" xref="S5.E1.m1.5.5.3.3.1.3.2.2">𝑘</ci><ci id="S5.E1.m1.5.5.3.3.1.3.2.3.cmml" xref="S5.E1.m1.5.5.3.3.1.3.2.3">𝑗</ci></apply></apply></apply><apply id="S5.E1.m1.6.6.4.4.2.cmml" xref="S5.E1.m1.6.6.4.4.2"><eq id="S5.E1.m1.6.6.4.4.2.2.cmml" xref="S5.E1.m1.6.6.4.4.2.2"></eq><apply id="S5.E1.m1.6.6.4.4.2.1.cmml" xref="S5.E1.m1.6.6.4.4.2.1"><times id="S5.E1.m1.6.6.4.4.2.1.2.cmml" xref="S5.E1.m1.6.6.4.4.2.1.2"></times><ci id="S5.E1.m1.6.6.4.4.2.1.3.cmml" xref="S5.E1.m1.6.6.4.4.2.1.3">𝐼</ci><set id="S5.E1.m1.6.6.4.4.2.1.1.2.cmml" xref="S5.E1.m1.6.6.4.4.2.1.1.1"><apply id="S5.E1.m1.6.6.4.4.2.1.1.1.1.cmml" xref="S5.E1.m1.6.6.4.4.2.1.1.1.1"><csymbol cd="ambiguous" id="S5.E1.m1.6.6.4.4.2.1.1.1.1.1.cmml" xref="S5.E1.m1.6.6.4.4.2.1.1.1.1">subscript</csymbol><ci id="S5.E1.m1.6.6.4.4.2.1.1.1.1.2.cmml" xref="S5.E1.m1.6.6.4.4.2.1.1.1.1.2">𝑡</ci><list id="S5.E1.m1.4.4.2.2.2.3.cmml" xref="S5.E1.m1.4.4.2.2.2.2"><apply id="S5.E1.m1.4.4.2.2.2.2.1.cmml" xref="S5.E1.m1.4.4.2.2.2.2.1"><csymbol cd="ambiguous" id="S5.E1.m1.4.4.2.2.2.2.1.1.cmml" xref="S5.E1.m1.4.4.2.2.2.2.1">subscript</csymbol><ci id="S5.E1.m1.4.4.2.2.2.2.1.2.cmml" xref="S5.E1.m1.4.4.2.2.2.2.1.2">𝑘</ci><ci id="S5.E1.m1.4.4.2.2.2.2.1.3.cmml" xref="S5.E1.m1.4.4.2.2.2.2.1.3">𝑗</ci></apply><ci id="S5.E1.m1.3.3.1.1.1.1.cmml" xref="S5.E1.m1.3.3.1.1.1.1">𝑗</ci></list></apply></set></apply><cn id="S5.E1.m1.6.6.4.4.2.3.cmml" type="integer" xref="S5.E1.m1.6.6.4.4.2.3">0</cn></apply></apply></apply><apply id="S5.E1.m1.9.9.1.1.1.1.cmml" xref="S5.E1.m1.9.9.1.1.1.1"><divide id="S5.E1.m1.9.9.1.1.1.1.2.cmml" xref="S5.E1.m1.9.9.1.1.1.1.2"></divide><apply id="S5.E1.m1.9.9.1.1.1.1.1.cmml" xref="S5.E1.m1.9.9.1.1.1.1.1"><times id="S5.E1.m1.9.9.1.1.1.1.1.2.cmml" xref="S5.E1.m1.9.9.1.1.1.1.1.2"></times><ci id="S5.E1.m1.9.9.1.1.1.1.1.3.cmml" xref="S5.E1.m1.9.9.1.1.1.1.1.3">𝐼</ci><set id="S5.E1.m1.9.9.1.1.1.1.1.1.2.cmml" xref="S5.E1.m1.9.9.1.1.1.1.1.1.1"><apply id="S5.E1.m1.9.9.1.1.1.1.1.1.1.1.cmml" xref="S5.E1.m1.9.9.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S5.E1.m1.9.9.1.1.1.1.1.1.1.1.1.cmml" xref="S5.E1.m1.9.9.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S5.E1.m1.9.9.1.1.1.1.1.1.1.1.2.cmml" xref="S5.E1.m1.9.9.1.1.1.1.1.1.1.1.2">𝑡</ci><list id="S5.E1.m1.8.8.2.3.cmml" xref="S5.E1.m1.8.8.2.4"><ci id="S5.E1.m1.7.7.1.1.cmml" xref="S5.E1.m1.7.7.1.1">𝑖</ci><ci id="S5.E1.m1.8.8.2.2.cmml" xref="S5.E1.m1.8.8.2.2">𝑗</ci></list></apply></set></apply><apply id="S5.E1.m1.9.9.1.1.1.1.3.cmml" xref="S5.E1.m1.9.9.1.1.1.1.3"><apply id="S5.E1.m1.9.9.1.1.1.1.3.1.cmml" xref="S5.E1.m1.9.9.1.1.1.1.3.1"><csymbol cd="ambiguous" id="S5.E1.m1.9.9.1.1.1.1.3.1.1.cmml" xref="S5.E1.m1.9.9.1.1.1.1.3.1">subscript</csymbol><sum id="S5.E1.m1.9.9.1.1.1.1.3.1.2.cmml" xref="S5.E1.m1.9.9.1.1.1.1.3.1.2"></sum><ci id="S5.E1.m1.9.9.1.1.1.1.3.1.3.cmml" xref="S5.E1.m1.9.9.1.1.1.1.3.1.3">𝑗</ci></apply><apply id="S5.E1.m1.9.9.1.1.1.1.3.2.cmml" xref="S5.E1.m1.9.9.1.1.1.1.3.2"><csymbol cd="ambiguous" id="S5.E1.m1.9.9.1.1.1.1.3.2.1.cmml" xref="S5.E1.m1.9.9.1.1.1.1.3.2">subscript</csymbol><ci id="S5.E1.m1.9.9.1.1.1.1.3.2.2.cmml" xref="S5.E1.m1.9.9.1.1.1.1.3.2.2">𝑘</ci><ci id="S5.E1.m1.9.9.1.1.1.1.3.2.3.cmml" xref="S5.E1.m1.9.9.1.1.1.1.3.2.3">𝑗</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.E1.m1.9c">TSA=\sum_{i\geq 1,j}^{i\leq\min{k_{j},I\{t_{k_{j},j}\}=0}}I\{t_{i,j}\}\big{/}%
\sum_{j}k_{j},</annotation><annotation encoding="application/x-llamapun" id="S5.E1.m1.9d">italic_T italic_S italic_A = ∑ start_POSTSUBSCRIPT italic_i ≥ 1 , italic_j end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_i ≤ roman_min italic_k start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT , italic_I { italic_t start_POSTSUBSCRIPT italic_k start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT , italic_j end_POSTSUBSCRIPT } = 0 end_POSTSUPERSCRIPT italic_I { italic_t start_POSTSUBSCRIPT italic_i , italic_j end_POSTSUBSCRIPT } / ∑ start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT italic_k start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S5.SS1.p5.5"><span class="ltx_text" id="S5.SS1.p5.5.1" style="font-size:90%;">where </span><math alttext="t_{i,j}" class="ltx_Math" display="inline" id="S5.SS1.p5.1.m1.2"><semantics id="S5.SS1.p5.1.m1.2a"><msub id="S5.SS1.p5.1.m1.2.3" xref="S5.SS1.p5.1.m1.2.3.cmml"><mi id="S5.SS1.p5.1.m1.2.3.2" mathsize="90%" xref="S5.SS1.p5.1.m1.2.3.2.cmml">t</mi><mrow id="S5.SS1.p5.1.m1.2.2.2.4" xref="S5.SS1.p5.1.m1.2.2.2.3.cmml"><mi id="S5.SS1.p5.1.m1.1.1.1.1" mathsize="90%" xref="S5.SS1.p5.1.m1.1.1.1.1.cmml">i</mi><mo id="S5.SS1.p5.1.m1.2.2.2.4.1" mathsize="90%" xref="S5.SS1.p5.1.m1.2.2.2.3.cmml">,</mo><mi id="S5.SS1.p5.1.m1.2.2.2.2" mathsize="90%" xref="S5.SS1.p5.1.m1.2.2.2.2.cmml">j</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S5.SS1.p5.1.m1.2b"><apply id="S5.SS1.p5.1.m1.2.3.cmml" xref="S5.SS1.p5.1.m1.2.3"><csymbol cd="ambiguous" id="S5.SS1.p5.1.m1.2.3.1.cmml" xref="S5.SS1.p5.1.m1.2.3">subscript</csymbol><ci id="S5.SS1.p5.1.m1.2.3.2.cmml" xref="S5.SS1.p5.1.m1.2.3.2">𝑡</ci><list id="S5.SS1.p5.1.m1.2.2.2.3.cmml" xref="S5.SS1.p5.1.m1.2.2.2.4"><ci id="S5.SS1.p5.1.m1.1.1.1.1.cmml" xref="S5.SS1.p5.1.m1.1.1.1.1">𝑖</ci><ci id="S5.SS1.p5.1.m1.2.2.2.2.cmml" xref="S5.SS1.p5.1.m1.2.2.2.2">𝑗</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p5.1.m1.2c">t_{i,j}</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p5.1.m1.2d">italic_t start_POSTSUBSCRIPT italic_i , italic_j end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="S5.SS1.p5.5.2" style="font-size:90%;"> is </span><math alttext="i-" class="ltx_Math" display="inline" id="S5.SS1.p5.2.m2.1"><semantics id="S5.SS1.p5.2.m2.1a"><mrow id="S5.SS1.p5.2.m2.1.1" xref="S5.SS1.p5.2.m2.1.1.cmml"><mi id="S5.SS1.p5.2.m2.1.1.2" mathsize="90%" xref="S5.SS1.p5.2.m2.1.1.2.cmml">i</mi><mo id="S5.SS1.p5.2.m2.1.1.3" mathsize="90%" xref="S5.SS1.p5.2.m2.1.1.3.cmml">−</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p5.2.m2.1b"><apply id="S5.SS1.p5.2.m2.1.1.cmml" xref="S5.SS1.p5.2.m2.1.1"><csymbol cd="latexml" id="S5.SS1.p5.2.m2.1.1.1.cmml" xref="S5.SS1.p5.2.m2.1.1">limit-from</csymbol><ci id="S5.SS1.p5.2.m2.1.1.2.cmml" xref="S5.SS1.p5.2.m2.1.1.2">𝑖</ci><minus id="S5.SS1.p5.2.m2.1.1.3.cmml" xref="S5.SS1.p5.2.m2.1.1.3"></minus></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p5.2.m2.1c">i-</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p5.2.m2.1d">italic_i -</annotation></semantics></math><span class="ltx_text" id="S5.SS1.p5.5.3" style="font-size:90%;">th tool in COT for the query </span><math alttext="j" class="ltx_Math" display="inline" id="S5.SS1.p5.3.m3.1"><semantics id="S5.SS1.p5.3.m3.1a"><mi id="S5.SS1.p5.3.m3.1.1" mathsize="90%" xref="S5.SS1.p5.3.m3.1.1.cmml">j</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.p5.3.m3.1b"><ci id="S5.SS1.p5.3.m3.1.1.cmml" xref="S5.SS1.p5.3.m3.1.1">𝑗</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p5.3.m3.1c">j</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p5.3.m3.1d">italic_j</annotation></semantics></math><span class="ltx_text" id="S5.SS1.p5.5.4" style="font-size:90%;">, </span><math alttext="I\{\}" class="ltx_Math" display="inline" id="S5.SS1.p5.4.m4.1"><semantics id="S5.SS1.p5.4.m4.1a"><mrow id="S5.SS1.p5.4.m4.1.1" xref="S5.SS1.p5.4.m4.1.1.cmml"><mi id="S5.SS1.p5.4.m4.1.1.2" mathsize="90%" xref="S5.SS1.p5.4.m4.1.1.2.cmml">I</mi><mo id="S5.SS1.p5.4.m4.1.1.1" xref="S5.SS1.p5.4.m4.1.1.1.cmml">⁢</mo><mrow id="S5.SS1.p5.4.m4.1.1.3.2" xref="S5.SS1.p5.4.m4.1.1.cmml"><mo id="S5.SS1.p5.4.m4.1.1.3.2.1" maxsize="90%" minsize="90%" xref="S5.SS1.p5.4.m4.1.1.3.1.cmml">{</mo><mo id="S5.SS1.p5.4.m4.1.1.3.2.2" maxsize="90%" minsize="90%" xref="S5.SS1.p5.4.m4.1.1.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p5.4.m4.1b"><apply id="S5.SS1.p5.4.m4.1.1.cmml" xref="S5.SS1.p5.4.m4.1.1"><times id="S5.SS1.p5.4.m4.1.1.1.cmml" xref="S5.SS1.p5.4.m4.1.1.1"></times><ci id="S5.SS1.p5.4.m4.1.1.2.cmml" xref="S5.SS1.p5.4.m4.1.1.2">𝐼</ci><list id="S5.SS1.p5.4.m4.1.1.3.1.cmml" xref="S5.SS1.p5.4.m4.1.1.3.2.1"></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p5.4.m4.1c">I\{\}</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p5.4.m4.1d">italic_I { }</annotation></semantics></math><span class="ltx_text" id="S5.SS1.p5.5.5" style="font-size:90%;"> is an indicator function that returns whether the tool (the name after “Action”) is labeled in the tool annotation in Section </span><a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#S3" style="font-size:90%;" title="3. DQA Dataset Generation ‣ Revolutionizing Database Q&amp;A with Large Language Models: Comprehensive Benchmark and Evaluation"><span class="ltx_text ltx_ref_tag">3</span></a><span class="ltx_text" id="S5.SS1.p5.5.6" style="font-size:90%;">, and </span><math alttext="k_{j}" class="ltx_Math" display="inline" id="S5.SS1.p5.5.m5.1"><semantics id="S5.SS1.p5.5.m5.1a"><msub id="S5.SS1.p5.5.m5.1.1" xref="S5.SS1.p5.5.m5.1.1.cmml"><mi id="S5.SS1.p5.5.m5.1.1.2" mathsize="90%" xref="S5.SS1.p5.5.m5.1.1.2.cmml">k</mi><mi id="S5.SS1.p5.5.m5.1.1.3" mathsize="90%" xref="S5.SS1.p5.5.m5.1.1.3.cmml">j</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS1.p5.5.m5.1b"><apply id="S5.SS1.p5.5.m5.1.1.cmml" xref="S5.SS1.p5.5.m5.1.1"><csymbol cd="ambiguous" id="S5.SS1.p5.5.m5.1.1.1.cmml" xref="S5.SS1.p5.5.m5.1.1">subscript</csymbol><ci id="S5.SS1.p5.5.m5.1.1.2.cmml" xref="S5.SS1.p5.5.m5.1.1.2">𝑘</ci><ci id="S5.SS1.p5.5.m5.1.1.3.cmml" xref="S5.SS1.p5.5.m5.1.1.3">𝑗</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p5.5.m5.1c">k_{j}</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p5.5.m5.1d">italic_k start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="S5.SS1.p5.5.7" style="font-size:90%;"> means the number of LLM tool invocations.</span></p>
</div>
<div class="ltx_para" id="S5.SS1.p6">
<p class="ltx_p" id="S5.SS1.p6.6"><span class="ltx_text ltx_font_italic" id="S5.SS1.p6.6.1" style="font-size:90%;">(2) TFA:</span><span class="ltx_text" id="S5.SS1.p6.6.2" style="font-size:90%;"> This metric measures the accuracy of the tool invocation format. Due to the diversity and subjectivity of tool format requirements, particularly in the generalized tool section Q&amp;A, it is very challenging to assess format compliance using predefined rules. Therefore, we employ GPT-4 as an expert adjudicator model to judge whether tool invocations meet the format requirements. Similarly, we consider the order of tools.
Specifically, the TFA (Tool Format Accuracy) is defined as:</span></p>
<table class="ltx_equation ltx_eqn_table" id="S5.E2">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_left">(2)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="TFA=\sum_{i\geq 1,j}^{i\leq\min{k_{j},G\{t_{k_{j},j}\}=0}}G\{t_{i,j}\}\big{/}%
\sum_{j}k_{j}," class="ltx_Math" display="block" id="S5.E2.m1.9"><semantics id="S5.E2.m1.9a"><mrow id="S5.E2.m1.9.9.1" xref="S5.E2.m1.9.9.1.1.cmml"><mrow id="S5.E2.m1.9.9.1.1" xref="S5.E2.m1.9.9.1.1.cmml"><mrow id="S5.E2.m1.9.9.1.1.3" xref="S5.E2.m1.9.9.1.1.3.cmml"><mi id="S5.E2.m1.9.9.1.1.3.2" mathsize="90%" xref="S5.E2.m1.9.9.1.1.3.2.cmml">T</mi><mo id="S5.E2.m1.9.9.1.1.3.1" xref="S5.E2.m1.9.9.1.1.3.1.cmml">⁢</mo><mi id="S5.E2.m1.9.9.1.1.3.3" mathsize="90%" xref="S5.E2.m1.9.9.1.1.3.3.cmml">F</mi><mo id="S5.E2.m1.9.9.1.1.3.1a" xref="S5.E2.m1.9.9.1.1.3.1.cmml">⁢</mo><mi id="S5.E2.m1.9.9.1.1.3.4" mathsize="90%" xref="S5.E2.m1.9.9.1.1.3.4.cmml">A</mi></mrow><mo id="S5.E2.m1.9.9.1.1.2" mathsize="90%" rspace="0.111em" xref="S5.E2.m1.9.9.1.1.2.cmml">=</mo><mrow id="S5.E2.m1.9.9.1.1.1" xref="S5.E2.m1.9.9.1.1.1.cmml"><munderover id="S5.E2.m1.9.9.1.1.1.2" xref="S5.E2.m1.9.9.1.1.1.2.cmml"><mo id="S5.E2.m1.9.9.1.1.1.2.2.2" maxsize="90%" minsize="90%" movablelimits="false" stretchy="true" xref="S5.E2.m1.9.9.1.1.1.2.2.2.cmml">∑</mo><mrow id="S5.E2.m1.2.2.2" xref="S5.E2.m1.2.2.2.cmml"><mi id="S5.E2.m1.2.2.2.4" mathsize="90%" xref="S5.E2.m1.2.2.2.4.cmml">i</mi><mo id="S5.E2.m1.2.2.2.3" mathsize="90%" xref="S5.E2.m1.2.2.2.3.cmml">≥</mo><mrow id="S5.E2.m1.2.2.2.5.2" xref="S5.E2.m1.2.2.2.5.1.cmml"><mn id="S5.E2.m1.1.1.1.1" mathsize="90%" xref="S5.E2.m1.1.1.1.1.cmml">1</mn><mo id="S5.E2.m1.2.2.2.5.2.1" mathsize="90%" xref="S5.E2.m1.2.2.2.5.1.cmml">,</mo><mi id="S5.E2.m1.2.2.2.2" mathsize="90%" xref="S5.E2.m1.2.2.2.2.cmml">j</mi></mrow></mrow><mrow id="S5.E2.m1.6.6.4.4" xref="S5.E2.m1.6.6.4.5.cmml"><mrow id="S5.E2.m1.5.5.3.3.1" xref="S5.E2.m1.5.5.3.3.1.cmml"><mi id="S5.E2.m1.5.5.3.3.1.2" mathsize="90%" xref="S5.E2.m1.5.5.3.3.1.2.cmml">i</mi><mo id="S5.E2.m1.5.5.3.3.1.1" mathsize="90%" xref="S5.E2.m1.5.5.3.3.1.1.cmml">≤</mo><mrow id="S5.E2.m1.5.5.3.3.1.3" xref="S5.E2.m1.5.5.3.3.1.3.cmml"><mi id="S5.E2.m1.5.5.3.3.1.3.1" mathsize="90%" xref="S5.E2.m1.5.5.3.3.1.3.1.cmml">min</mi><mo id="S5.E2.m1.5.5.3.3.1.3a" lspace="0.167em" xref="S5.E2.m1.5.5.3.3.1.3.cmml">⁡</mo><msub id="S5.E2.m1.5.5.3.3.1.3.2" xref="S5.E2.m1.5.5.3.3.1.3.2.cmml"><mi id="S5.E2.m1.5.5.3.3.1.3.2.2" mathsize="90%" xref="S5.E2.m1.5.5.3.3.1.3.2.2.cmml">k</mi><mi id="S5.E2.m1.5.5.3.3.1.3.2.3" mathsize="90%" xref="S5.E2.m1.5.5.3.3.1.3.2.3.cmml">j</mi></msub></mrow></mrow><mo id="S5.E2.m1.6.6.4.4.3" mathsize="90%" xref="S5.E2.m1.6.6.4.5a.cmml">,</mo><mrow id="S5.E2.m1.6.6.4.4.2" xref="S5.E2.m1.6.6.4.4.2.cmml"><mrow id="S5.E2.m1.6.6.4.4.2.1" xref="S5.E2.m1.6.6.4.4.2.1.cmml"><mi id="S5.E2.m1.6.6.4.4.2.1.3" mathsize="90%" xref="S5.E2.m1.6.6.4.4.2.1.3.cmml">G</mi><mo id="S5.E2.m1.6.6.4.4.2.1.2" xref="S5.E2.m1.6.6.4.4.2.1.2.cmml">⁢</mo><mrow id="S5.E2.m1.6.6.4.4.2.1.1.1" xref="S5.E2.m1.6.6.4.4.2.1.1.2.cmml"><mo id="S5.E2.m1.6.6.4.4.2.1.1.1.2" maxsize="90%" minsize="90%" xref="S5.E2.m1.6.6.4.4.2.1.1.2.cmml">{</mo><msub id="S5.E2.m1.6.6.4.4.2.1.1.1.1" xref="S5.E2.m1.6.6.4.4.2.1.1.1.1.cmml"><mi id="S5.E2.m1.6.6.4.4.2.1.1.1.1.2" mathsize="90%" xref="S5.E2.m1.6.6.4.4.2.1.1.1.1.2.cmml">t</mi><mrow id="S5.E2.m1.4.4.2.2.2.2" xref="S5.E2.m1.4.4.2.2.2.3.cmml"><msub id="S5.E2.m1.4.4.2.2.2.2.1" xref="S5.E2.m1.4.4.2.2.2.2.1.cmml"><mi id="S5.E2.m1.4.4.2.2.2.2.1.2" mathsize="90%" xref="S5.E2.m1.4.4.2.2.2.2.1.2.cmml">k</mi><mi id="S5.E2.m1.4.4.2.2.2.2.1.3" mathsize="90%" xref="S5.E2.m1.4.4.2.2.2.2.1.3.cmml">j</mi></msub><mo id="S5.E2.m1.4.4.2.2.2.2.2" mathsize="90%" xref="S5.E2.m1.4.4.2.2.2.3.cmml">,</mo><mi id="S5.E2.m1.3.3.1.1.1.1" mathsize="90%" xref="S5.E2.m1.3.3.1.1.1.1.cmml">j</mi></mrow></msub><mo id="S5.E2.m1.6.6.4.4.2.1.1.1.3" maxsize="90%" minsize="90%" xref="S5.E2.m1.6.6.4.4.2.1.1.2.cmml">}</mo></mrow></mrow><mo id="S5.E2.m1.6.6.4.4.2.2" mathsize="90%" xref="S5.E2.m1.6.6.4.4.2.2.cmml">=</mo><mn id="S5.E2.m1.6.6.4.4.2.3" mathsize="90%" xref="S5.E2.m1.6.6.4.4.2.3.cmml">0</mn></mrow></mrow></munderover><mrow id="S5.E2.m1.9.9.1.1.1.1" xref="S5.E2.m1.9.9.1.1.1.1.cmml"><mrow id="S5.E2.m1.9.9.1.1.1.1.1" xref="S5.E2.m1.9.9.1.1.1.1.1.cmml"><mi id="S5.E2.m1.9.9.1.1.1.1.1.3" mathsize="90%" xref="S5.E2.m1.9.9.1.1.1.1.1.3.cmml">G</mi><mo id="S5.E2.m1.9.9.1.1.1.1.1.2" xref="S5.E2.m1.9.9.1.1.1.1.1.2.cmml">⁢</mo><mrow id="S5.E2.m1.9.9.1.1.1.1.1.1.1" xref="S5.E2.m1.9.9.1.1.1.1.1.1.2.cmml"><mo id="S5.E2.m1.9.9.1.1.1.1.1.1.1.2" maxsize="90%" minsize="90%" xref="S5.E2.m1.9.9.1.1.1.1.1.1.2.cmml">{</mo><msub id="S5.E2.m1.9.9.1.1.1.1.1.1.1.1" xref="S5.E2.m1.9.9.1.1.1.1.1.1.1.1.cmml"><mi id="S5.E2.m1.9.9.1.1.1.1.1.1.1.1.2" mathsize="90%" xref="S5.E2.m1.9.9.1.1.1.1.1.1.1.1.2.cmml">t</mi><mrow id="S5.E2.m1.8.8.2.4" xref="S5.E2.m1.8.8.2.3.cmml"><mi id="S5.E2.m1.7.7.1.1" mathsize="90%" xref="S5.E2.m1.7.7.1.1.cmml">i</mi><mo id="S5.E2.m1.8.8.2.4.1" mathsize="90%" xref="S5.E2.m1.8.8.2.3.cmml">,</mo><mi id="S5.E2.m1.8.8.2.2" mathsize="90%" xref="S5.E2.m1.8.8.2.2.cmml">j</mi></mrow></msub><mo id="S5.E2.m1.9.9.1.1.1.1.1.1.1.3" maxsize="90%" minsize="90%" xref="S5.E2.m1.9.9.1.1.1.1.1.1.2.cmml">}</mo></mrow></mrow><mo id="S5.E2.m1.9.9.1.1.1.1.2" maxsize="120%" minsize="120%" rspace="0.055em" stretchy="true" symmetric="true" xref="S5.E2.m1.9.9.1.1.1.1.2.cmml">/</mo><mrow id="S5.E2.m1.9.9.1.1.1.1.3" xref="S5.E2.m1.9.9.1.1.1.1.3.cmml"><munder id="S5.E2.m1.9.9.1.1.1.1.3.1" xref="S5.E2.m1.9.9.1.1.1.1.3.1.cmml"><mo id="S5.E2.m1.9.9.1.1.1.1.3.1.2" maxsize="90%" minsize="90%" movablelimits="false" stretchy="true" xref="S5.E2.m1.9.9.1.1.1.1.3.1.2.cmml">∑</mo><mi id="S5.E2.m1.9.9.1.1.1.1.3.1.3" mathsize="90%" xref="S5.E2.m1.9.9.1.1.1.1.3.1.3.cmml">j</mi></munder><msub id="S5.E2.m1.9.9.1.1.1.1.3.2" xref="S5.E2.m1.9.9.1.1.1.1.3.2.cmml"><mi id="S5.E2.m1.9.9.1.1.1.1.3.2.2" mathsize="90%" xref="S5.E2.m1.9.9.1.1.1.1.3.2.2.cmml">k</mi><mi id="S5.E2.m1.9.9.1.1.1.1.3.2.3" mathsize="90%" xref="S5.E2.m1.9.9.1.1.1.1.3.2.3.cmml">j</mi></msub></mrow></mrow></mrow></mrow><mo id="S5.E2.m1.9.9.1.2" mathsize="90%" xref="S5.E2.m1.9.9.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.E2.m1.9b"><apply id="S5.E2.m1.9.9.1.1.cmml" xref="S5.E2.m1.9.9.1"><eq id="S5.E2.m1.9.9.1.1.2.cmml" xref="S5.E2.m1.9.9.1.1.2"></eq><apply id="S5.E2.m1.9.9.1.1.3.cmml" xref="S5.E2.m1.9.9.1.1.3"><times id="S5.E2.m1.9.9.1.1.3.1.cmml" xref="S5.E2.m1.9.9.1.1.3.1"></times><ci id="S5.E2.m1.9.9.1.1.3.2.cmml" xref="S5.E2.m1.9.9.1.1.3.2">𝑇</ci><ci id="S5.E2.m1.9.9.1.1.3.3.cmml" xref="S5.E2.m1.9.9.1.1.3.3">𝐹</ci><ci id="S5.E2.m1.9.9.1.1.3.4.cmml" xref="S5.E2.m1.9.9.1.1.3.4">𝐴</ci></apply><apply id="S5.E2.m1.9.9.1.1.1.cmml" xref="S5.E2.m1.9.9.1.1.1"><apply id="S5.E2.m1.9.9.1.1.1.2.cmml" xref="S5.E2.m1.9.9.1.1.1.2"><csymbol cd="ambiguous" id="S5.E2.m1.9.9.1.1.1.2.1.cmml" xref="S5.E2.m1.9.9.1.1.1.2">superscript</csymbol><apply id="S5.E2.m1.9.9.1.1.1.2.2.cmml" xref="S5.E2.m1.9.9.1.1.1.2"><csymbol cd="ambiguous" id="S5.E2.m1.9.9.1.1.1.2.2.1.cmml" xref="S5.E2.m1.9.9.1.1.1.2">subscript</csymbol><sum id="S5.E2.m1.9.9.1.1.1.2.2.2.cmml" xref="S5.E2.m1.9.9.1.1.1.2.2.2"></sum><apply id="S5.E2.m1.2.2.2.cmml" xref="S5.E2.m1.2.2.2"><geq id="S5.E2.m1.2.2.2.3.cmml" xref="S5.E2.m1.2.2.2.3"></geq><ci id="S5.E2.m1.2.2.2.4.cmml" xref="S5.E2.m1.2.2.2.4">𝑖</ci><list id="S5.E2.m1.2.2.2.5.1.cmml" xref="S5.E2.m1.2.2.2.5.2"><cn id="S5.E2.m1.1.1.1.1.cmml" type="integer" xref="S5.E2.m1.1.1.1.1">1</cn><ci id="S5.E2.m1.2.2.2.2.cmml" xref="S5.E2.m1.2.2.2.2">𝑗</ci></list></apply></apply><apply id="S5.E2.m1.6.6.4.5.cmml" xref="S5.E2.m1.6.6.4.4"><csymbol cd="ambiguous" id="S5.E2.m1.6.6.4.5a.cmml" xref="S5.E2.m1.6.6.4.4.3">formulae-sequence</csymbol><apply id="S5.E2.m1.5.5.3.3.1.cmml" xref="S5.E2.m1.5.5.3.3.1"><leq id="S5.E2.m1.5.5.3.3.1.1.cmml" xref="S5.E2.m1.5.5.3.3.1.1"></leq><ci id="S5.E2.m1.5.5.3.3.1.2.cmml" xref="S5.E2.m1.5.5.3.3.1.2">𝑖</ci><apply id="S5.E2.m1.5.5.3.3.1.3.cmml" xref="S5.E2.m1.5.5.3.3.1.3"><min id="S5.E2.m1.5.5.3.3.1.3.1.cmml" xref="S5.E2.m1.5.5.3.3.1.3.1"></min><apply id="S5.E2.m1.5.5.3.3.1.3.2.cmml" xref="S5.E2.m1.5.5.3.3.1.3.2"><csymbol cd="ambiguous" id="S5.E2.m1.5.5.3.3.1.3.2.1.cmml" xref="S5.E2.m1.5.5.3.3.1.3.2">subscript</csymbol><ci id="S5.E2.m1.5.5.3.3.1.3.2.2.cmml" xref="S5.E2.m1.5.5.3.3.1.3.2.2">𝑘</ci><ci id="S5.E2.m1.5.5.3.3.1.3.2.3.cmml" xref="S5.E2.m1.5.5.3.3.1.3.2.3">𝑗</ci></apply></apply></apply><apply id="S5.E2.m1.6.6.4.4.2.cmml" xref="S5.E2.m1.6.6.4.4.2"><eq id="S5.E2.m1.6.6.4.4.2.2.cmml" xref="S5.E2.m1.6.6.4.4.2.2"></eq><apply id="S5.E2.m1.6.6.4.4.2.1.cmml" xref="S5.E2.m1.6.6.4.4.2.1"><times id="S5.E2.m1.6.6.4.4.2.1.2.cmml" xref="S5.E2.m1.6.6.4.4.2.1.2"></times><ci id="S5.E2.m1.6.6.4.4.2.1.3.cmml" xref="S5.E2.m1.6.6.4.4.2.1.3">𝐺</ci><set id="S5.E2.m1.6.6.4.4.2.1.1.2.cmml" xref="S5.E2.m1.6.6.4.4.2.1.1.1"><apply id="S5.E2.m1.6.6.4.4.2.1.1.1.1.cmml" xref="S5.E2.m1.6.6.4.4.2.1.1.1.1"><csymbol cd="ambiguous" id="S5.E2.m1.6.6.4.4.2.1.1.1.1.1.cmml" xref="S5.E2.m1.6.6.4.4.2.1.1.1.1">subscript</csymbol><ci id="S5.E2.m1.6.6.4.4.2.1.1.1.1.2.cmml" xref="S5.E2.m1.6.6.4.4.2.1.1.1.1.2">𝑡</ci><list id="S5.E2.m1.4.4.2.2.2.3.cmml" xref="S5.E2.m1.4.4.2.2.2.2"><apply id="S5.E2.m1.4.4.2.2.2.2.1.cmml" xref="S5.E2.m1.4.4.2.2.2.2.1"><csymbol cd="ambiguous" id="S5.E2.m1.4.4.2.2.2.2.1.1.cmml" xref="S5.E2.m1.4.4.2.2.2.2.1">subscript</csymbol><ci id="S5.E2.m1.4.4.2.2.2.2.1.2.cmml" xref="S5.E2.m1.4.4.2.2.2.2.1.2">𝑘</ci><ci id="S5.E2.m1.4.4.2.2.2.2.1.3.cmml" xref="S5.E2.m1.4.4.2.2.2.2.1.3">𝑗</ci></apply><ci id="S5.E2.m1.3.3.1.1.1.1.cmml" xref="S5.E2.m1.3.3.1.1.1.1">𝑗</ci></list></apply></set></apply><cn id="S5.E2.m1.6.6.4.4.2.3.cmml" type="integer" xref="S5.E2.m1.6.6.4.4.2.3">0</cn></apply></apply></apply><apply id="S5.E2.m1.9.9.1.1.1.1.cmml" xref="S5.E2.m1.9.9.1.1.1.1"><divide id="S5.E2.m1.9.9.1.1.1.1.2.cmml" xref="S5.E2.m1.9.9.1.1.1.1.2"></divide><apply id="S5.E2.m1.9.9.1.1.1.1.1.cmml" xref="S5.E2.m1.9.9.1.1.1.1.1"><times id="S5.E2.m1.9.9.1.1.1.1.1.2.cmml" xref="S5.E2.m1.9.9.1.1.1.1.1.2"></times><ci id="S5.E2.m1.9.9.1.1.1.1.1.3.cmml" xref="S5.E2.m1.9.9.1.1.1.1.1.3">𝐺</ci><set id="S5.E2.m1.9.9.1.1.1.1.1.1.2.cmml" xref="S5.E2.m1.9.9.1.1.1.1.1.1.1"><apply id="S5.E2.m1.9.9.1.1.1.1.1.1.1.1.cmml" xref="S5.E2.m1.9.9.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S5.E2.m1.9.9.1.1.1.1.1.1.1.1.1.cmml" xref="S5.E2.m1.9.9.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S5.E2.m1.9.9.1.1.1.1.1.1.1.1.2.cmml" xref="S5.E2.m1.9.9.1.1.1.1.1.1.1.1.2">𝑡</ci><list id="S5.E2.m1.8.8.2.3.cmml" xref="S5.E2.m1.8.8.2.4"><ci id="S5.E2.m1.7.7.1.1.cmml" xref="S5.E2.m1.7.7.1.1">𝑖</ci><ci id="S5.E2.m1.8.8.2.2.cmml" xref="S5.E2.m1.8.8.2.2">𝑗</ci></list></apply></set></apply><apply id="S5.E2.m1.9.9.1.1.1.1.3.cmml" xref="S5.E2.m1.9.9.1.1.1.1.3"><apply id="S5.E2.m1.9.9.1.1.1.1.3.1.cmml" xref="S5.E2.m1.9.9.1.1.1.1.3.1"><csymbol cd="ambiguous" id="S5.E2.m1.9.9.1.1.1.1.3.1.1.cmml" xref="S5.E2.m1.9.9.1.1.1.1.3.1">subscript</csymbol><sum id="S5.E2.m1.9.9.1.1.1.1.3.1.2.cmml" xref="S5.E2.m1.9.9.1.1.1.1.3.1.2"></sum><ci id="S5.E2.m1.9.9.1.1.1.1.3.1.3.cmml" xref="S5.E2.m1.9.9.1.1.1.1.3.1.3">𝑗</ci></apply><apply id="S5.E2.m1.9.9.1.1.1.1.3.2.cmml" xref="S5.E2.m1.9.9.1.1.1.1.3.2"><csymbol cd="ambiguous" id="S5.E2.m1.9.9.1.1.1.1.3.2.1.cmml" xref="S5.E2.m1.9.9.1.1.1.1.3.2">subscript</csymbol><ci id="S5.E2.m1.9.9.1.1.1.1.3.2.2.cmml" xref="S5.E2.m1.9.9.1.1.1.1.3.2.2">𝑘</ci><ci id="S5.E2.m1.9.9.1.1.1.1.3.2.3.cmml" xref="S5.E2.m1.9.9.1.1.1.1.3.2.3">𝑗</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.E2.m1.9c">TFA=\sum_{i\geq 1,j}^{i\leq\min{k_{j},G\{t_{k_{j},j}\}=0}}G\{t_{i,j}\}\big{/}%
\sum_{j}k_{j},</annotation><annotation encoding="application/x-llamapun" id="S5.E2.m1.9d">italic_T italic_F italic_A = ∑ start_POSTSUBSCRIPT italic_i ≥ 1 , italic_j end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_i ≤ roman_min italic_k start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT , italic_G { italic_t start_POSTSUBSCRIPT italic_k start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT , italic_j end_POSTSUBSCRIPT } = 0 end_POSTSUPERSCRIPT italic_G { italic_t start_POSTSUBSCRIPT italic_i , italic_j end_POSTSUBSCRIPT } / ∑ start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT italic_k start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S5.SS1.p6.5"><span class="ltx_text" id="S5.SS1.p6.5.1" style="font-size:90%;">where </span><math alttext="t_{i,j}" class="ltx_Math" display="inline" id="S5.SS1.p6.1.m1.2"><semantics id="S5.SS1.p6.1.m1.2a"><msub id="S5.SS1.p6.1.m1.2.3" xref="S5.SS1.p6.1.m1.2.3.cmml"><mi id="S5.SS1.p6.1.m1.2.3.2" mathsize="90%" xref="S5.SS1.p6.1.m1.2.3.2.cmml">t</mi><mrow id="S5.SS1.p6.1.m1.2.2.2.4" xref="S5.SS1.p6.1.m1.2.2.2.3.cmml"><mi id="S5.SS1.p6.1.m1.1.1.1.1" mathsize="90%" xref="S5.SS1.p6.1.m1.1.1.1.1.cmml">i</mi><mo id="S5.SS1.p6.1.m1.2.2.2.4.1" mathsize="90%" xref="S5.SS1.p6.1.m1.2.2.2.3.cmml">,</mo><mi id="S5.SS1.p6.1.m1.2.2.2.2" mathsize="90%" xref="S5.SS1.p6.1.m1.2.2.2.2.cmml">j</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S5.SS1.p6.1.m1.2b"><apply id="S5.SS1.p6.1.m1.2.3.cmml" xref="S5.SS1.p6.1.m1.2.3"><csymbol cd="ambiguous" id="S5.SS1.p6.1.m1.2.3.1.cmml" xref="S5.SS1.p6.1.m1.2.3">subscript</csymbol><ci id="S5.SS1.p6.1.m1.2.3.2.cmml" xref="S5.SS1.p6.1.m1.2.3.2">𝑡</ci><list id="S5.SS1.p6.1.m1.2.2.2.3.cmml" xref="S5.SS1.p6.1.m1.2.2.2.4"><ci id="S5.SS1.p6.1.m1.1.1.1.1.cmml" xref="S5.SS1.p6.1.m1.1.1.1.1">𝑖</ci><ci id="S5.SS1.p6.1.m1.2.2.2.2.cmml" xref="S5.SS1.p6.1.m1.2.2.2.2">𝑗</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p6.1.m1.2c">t_{i,j}</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p6.1.m1.2d">italic_t start_POSTSUBSCRIPT italic_i , italic_j end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="S5.SS1.p6.5.2" style="font-size:90%;"> is the </span><math alttext="i-" class="ltx_Math" display="inline" id="S5.SS1.p6.2.m2.1"><semantics id="S5.SS1.p6.2.m2.1a"><mrow id="S5.SS1.p6.2.m2.1.1" xref="S5.SS1.p6.2.m2.1.1.cmml"><mi id="S5.SS1.p6.2.m2.1.1.2" mathsize="90%" xref="S5.SS1.p6.2.m2.1.1.2.cmml">i</mi><mo id="S5.SS1.p6.2.m2.1.1.3" mathsize="90%" xref="S5.SS1.p6.2.m2.1.1.3.cmml">−</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p6.2.m2.1b"><apply id="S5.SS1.p6.2.m2.1.1.cmml" xref="S5.SS1.p6.2.m2.1.1"><csymbol cd="latexml" id="S5.SS1.p6.2.m2.1.1.1.cmml" xref="S5.SS1.p6.2.m2.1.1">limit-from</csymbol><ci id="S5.SS1.p6.2.m2.1.1.2.cmml" xref="S5.SS1.p6.2.m2.1.1.2">𝑖</ci><minus id="S5.SS1.p6.2.m2.1.1.3.cmml" xref="S5.SS1.p6.2.m2.1.1.3"></minus></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p6.2.m2.1c">i-</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p6.2.m2.1d">italic_i -</annotation></semantics></math><span class="ltx_text" id="S5.SS1.p6.5.3" style="font-size:90%;">th tool in COT for the query </span><math alttext="j" class="ltx_Math" display="inline" id="S5.SS1.p6.3.m3.1"><semantics id="S5.SS1.p6.3.m3.1a"><mi id="S5.SS1.p6.3.m3.1.1" mathsize="90%" xref="S5.SS1.p6.3.m3.1.1.cmml">j</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.p6.3.m3.1b"><ci id="S5.SS1.p6.3.m3.1.1.cmml" xref="S5.SS1.p6.3.m3.1.1">𝑗</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p6.3.m3.1c">j</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p6.3.m3.1d">italic_j</annotation></semantics></math><span class="ltx_text" id="S5.SS1.p6.5.4" style="font-size:90%;">, </span><math alttext="G\{\}" class="ltx_Math" display="inline" id="S5.SS1.p6.4.m4.1"><semantics id="S5.SS1.p6.4.m4.1a"><mrow id="S5.SS1.p6.4.m4.1.1" xref="S5.SS1.p6.4.m4.1.1.cmml"><mi id="S5.SS1.p6.4.m4.1.1.2" mathsize="90%" xref="S5.SS1.p6.4.m4.1.1.2.cmml">G</mi><mo id="S5.SS1.p6.4.m4.1.1.1" xref="S5.SS1.p6.4.m4.1.1.1.cmml">⁢</mo><mrow id="S5.SS1.p6.4.m4.1.1.3.2" xref="S5.SS1.p6.4.m4.1.1.cmml"><mo id="S5.SS1.p6.4.m4.1.1.3.2.1" maxsize="90%" minsize="90%" xref="S5.SS1.p6.4.m4.1.1.3.1.cmml">{</mo><mo id="S5.SS1.p6.4.m4.1.1.3.2.2" maxsize="90%" minsize="90%" xref="S5.SS1.p6.4.m4.1.1.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p6.4.m4.1b"><apply id="S5.SS1.p6.4.m4.1.1.cmml" xref="S5.SS1.p6.4.m4.1.1"><times id="S5.SS1.p6.4.m4.1.1.1.cmml" xref="S5.SS1.p6.4.m4.1.1.1"></times><ci id="S5.SS1.p6.4.m4.1.1.2.cmml" xref="S5.SS1.p6.4.m4.1.1.2">𝐺</ci><list id="S5.SS1.p6.4.m4.1.1.3.1.cmml" xref="S5.SS1.p6.4.m4.1.1.3.2.1"></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p6.4.m4.1c">G\{\}</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p6.4.m4.1d">italic_G { }</annotation></semantics></math><span class="ltx_text" id="S5.SS1.p6.5.5" style="font-size:90%;"> is the output of GPT-4 that decides whether the tool input (the content after “Action_Input”) is correct, and </span><math alttext="k_{j}" class="ltx_Math" display="inline" id="S5.SS1.p6.5.m5.1"><semantics id="S5.SS1.p6.5.m5.1a"><msub id="S5.SS1.p6.5.m5.1.1" xref="S5.SS1.p6.5.m5.1.1.cmml"><mi id="S5.SS1.p6.5.m5.1.1.2" mathsize="90%" xref="S5.SS1.p6.5.m5.1.1.2.cmml">k</mi><mi id="S5.SS1.p6.5.m5.1.1.3" mathsize="90%" xref="S5.SS1.p6.5.m5.1.1.3.cmml">j</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS1.p6.5.m5.1b"><apply id="S5.SS1.p6.5.m5.1.1.cmml" xref="S5.SS1.p6.5.m5.1.1"><csymbol cd="ambiguous" id="S5.SS1.p6.5.m5.1.1.1.cmml" xref="S5.SS1.p6.5.m5.1.1">subscript</csymbol><ci id="S5.SS1.p6.5.m5.1.1.2.cmml" xref="S5.SS1.p6.5.m5.1.1.2">𝑘</ci><ci id="S5.SS1.p6.5.m5.1.1.3.cmml" xref="S5.SS1.p6.5.m5.1.1.3">𝑗</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p6.5.m5.1c">k_{j}</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p6.5.m5.1d">italic_k start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="S5.SS1.p6.5.6" style="font-size:90%;"> means the number of LLM tool invocations.</span></p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS2">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">5.2. </span>End-to-End Evaluation</h3>
<div class="ltx_para" id="S5.SS2.p1">
<p class="ltx_p" id="S5.SS2.p1.1"><span class="ltx_text" id="S5.SS2.p1.1.1" style="font-size:90%;">LLMs are sensitive to prompt engineering. The choice of wording and structure in prompts can influence the quality of LLM’s responses. In our practice, the proposed testbed workflow in Section </span><a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#S4" style="font-size:90%;" title="4. DQA Testbed ‣ 3.3. Instance-Specific Q&amp;A ‣ 3.2. Product-Specific Q&amp;A ‣ 3. DQA Dataset Generation ‣ Revolutionizing Database Q&amp;A with Large Language Models: Comprehensive Benchmark and Evaluation"><span class="ltx_text ltx_ref_tag">4</span></a><span class="ltx_text" id="S5.SS2.p1.1.2" style="font-size:90%;"> can improve the credibility, relevance and fluency of all tested LLMs. Thus, instead of asking a simple query, we use a standard prompt pipeline to obtain the best output of various LLMs.</span></p>
</div>
<div class="ltx_para" id="S5.SS2.p2">
<p class="ltx_p" id="S5.SS2.p2.1"><span class="ltx_text ltx_font_bold" id="S5.SS2.p2.1.1" style="font-size:90%;">Standard Evaluation pipeline.</span><span class="ltx_text" id="S5.SS2.p2.1.2" style="font-size:90%;"> Since there are multiple intermediate steps in the testbed workflow, it is pivotal to fix some of the steps to reduce unexpected output. We use the ground truth labels in the QCR and RAG modules because these modules can be isolated from the LLMs. For example, correctly associating the question “Why is SQL query execution slow?” with the ‘instance-specific’ label is essential to trigger the DB tools and produce targeted answers. Nonetheless, the QCR accuracy can be boosted by utilizing a more advanced classifier trained explicitly for the QCR task. Thus, the end-to-end evaluation should not be impacted by whether the LLM to be evaluated can classify the question correctly. The retrieval precision can also be upgraded by using a more advanced retriever. On the contrary, the TIG performance is based on the LLM’s ability to plan and utilize DB tools. The problem is that the instance’s output may deviate from the ground truth, making it difficult to evaluate the personalized answer. Thus, we standardize the LLM end-to-end evaluation process as follows.</span></p>
</div>
<div class="ltx_para" id="S5.SS2.p3">
<p class="ltx_p" id="S5.SS2.p3.1"><span class="ltx_text ltx_font_italic" id="S5.SS2.p3.1.1" style="font-size:90%;">(1) Standard Question Classification</span><span class="ltx_text" id="S5.SS2.p3.1.2" style="font-size:90%;">. We use the ground truth question labels to generate the associated prompt template.</span></p>
</div>
<div class="ltx_para" id="S5.SS2.p4">
<p class="ltx_p" id="S5.SS2.p4.1"><span class="ltx_text ltx_font_italic" id="S5.SS2.p4.1.1" style="font-size:90%;">(2) Standard Retrieval Knowledge</span><span class="ltx_text" id="S5.SS2.p4.1.2" style="font-size:90%;">. For product-specific queries, we use the ground truth fine-grained retrieval text and append it to the prompt.</span></p>
</div>
<div class="ltx_para" id="S5.SS2.p5">
<p class="ltx_p" id="S5.SS2.p5.7"><span class="ltx_text ltx_font_italic" id="S5.SS2.p5.7.1" style="font-size:90%;">(3) Standard Tool Result</span><span class="ltx_text" id="S5.SS2.p5.7.2" style="font-size:90%;">. For instance-specific queries, we formulate the ‘Thought-Action-Action_Input-Observation” chain using the Algorithm </span><a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#algorithm1" style="font-size:90%;" title="In 5.2. End-to-End Evaluation ‣ 5. DQA Evaluation Pipeline ‣ 4.5. Tool Invocation Generation ‣ 4. DQA Testbed ‣ 3.3. Instance-Specific Q&amp;A ‣ 3.2. Product-Specific Q&amp;A ‣ 3. DQA Dataset Generation ‣ Revolutionizing Database Q&amp;A with Large Language Models: Comprehensive Benchmark and Evaluation"><span class="ltx_text ltx_ref_tag">1</span></a><span class="ltx_text" id="S5.SS2.p5.7.3" style="font-size:90%;">. Given the model </span><math alttext="M" class="ltx_Math" display="inline" id="S5.SS2.p5.1.m1.1"><semantics id="S5.SS2.p5.1.m1.1a"><mi id="S5.SS2.p5.1.m1.1.1" mathsize="90%" xref="S5.SS2.p5.1.m1.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S5.SS2.p5.1.m1.1b"><ci id="S5.SS2.p5.1.m1.1.1.cmml" xref="S5.SS2.p5.1.m1.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p5.1.m1.1c">M</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p5.1.m1.1d">italic_M</annotation></semantics></math><span class="ltx_text" id="S5.SS2.p5.7.4" style="font-size:90%;"> to be evaluated, the tool pool </span><math alttext="P" class="ltx_Math" display="inline" id="S5.SS2.p5.2.m2.1"><semantics id="S5.SS2.p5.2.m2.1a"><mi id="S5.SS2.p5.2.m2.1.1" mathsize="90%" xref="S5.SS2.p5.2.m2.1.1.cmml">P</mi><annotation-xml encoding="MathML-Content" id="S5.SS2.p5.2.m2.1b"><ci id="S5.SS2.p5.2.m2.1.1.cmml" xref="S5.SS2.p5.2.m2.1.1">𝑃</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p5.2.m2.1c">P</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p5.2.m2.1d">italic_P</annotation></semantics></math><span class="ltx_text" id="S5.SS2.p5.7.5" style="font-size:90%;">, the question </span><math alttext="q" class="ltx_Math" display="inline" id="S5.SS2.p5.3.m3.1"><semantics id="S5.SS2.p5.3.m3.1a"><mi id="S5.SS2.p5.3.m3.1.1" mathsize="90%" xref="S5.SS2.p5.3.m3.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S5.SS2.p5.3.m3.1b"><ci id="S5.SS2.p5.3.m3.1.1.cmml" xref="S5.SS2.p5.3.m3.1.1">𝑞</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p5.3.m3.1c">q</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p5.3.m3.1d">italic_q</annotation></semantics></math><span class="ltx_text" id="S5.SS2.p5.7.6" style="font-size:90%;">, the prompt template </span><math alttext="p_{0}" class="ltx_Math" display="inline" id="S5.SS2.p5.4.m4.1"><semantics id="S5.SS2.p5.4.m4.1a"><msub id="S5.SS2.p5.4.m4.1.1" xref="S5.SS2.p5.4.m4.1.1.cmml"><mi id="S5.SS2.p5.4.m4.1.1.2" mathsize="90%" xref="S5.SS2.p5.4.m4.1.1.2.cmml">p</mi><mn id="S5.SS2.p5.4.m4.1.1.3" mathsize="90%" xref="S5.SS2.p5.4.m4.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="S5.SS2.p5.4.m4.1b"><apply id="S5.SS2.p5.4.m4.1.1.cmml" xref="S5.SS2.p5.4.m4.1.1"><csymbol cd="ambiguous" id="S5.SS2.p5.4.m4.1.1.1.cmml" xref="S5.SS2.p5.4.m4.1.1">subscript</csymbol><ci id="S5.SS2.p5.4.m4.1.1.2.cmml" xref="S5.SS2.p5.4.m4.1.1.2">𝑝</ci><cn id="S5.SS2.p5.4.m4.1.1.3.cmml" type="integer" xref="S5.SS2.p5.4.m4.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p5.4.m4.1c">p_{0}</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p5.4.m4.1d">italic_p start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="S5.SS2.p5.7.7" style="font-size:90%;">, and the ground truth answer and tools invoked in the benchmark (line 1), the LLM’s answer is initiated as empty (line 2). We first construct the valid tool set {{T}} in the prompt to include all tools mentioned in the ground truth answer, along with four randomly selected tools from the tool pool </span><math alttext="P" class="ltx_Math" display="inline" id="S5.SS2.p5.5.m5.1"><semantics id="S5.SS2.p5.5.m5.1a"><mi id="S5.SS2.p5.5.m5.1.1" mathsize="90%" xref="S5.SS2.p5.5.m5.1.1.cmml">P</mi><annotation-xml encoding="MathML-Content" id="S5.SS2.p5.5.m5.1b"><ci id="S5.SS2.p5.5.m5.1.1.cmml" xref="S5.SS2.p5.5.m5.1.1">𝑃</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p5.5.m5.1c">P</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p5.5.m5.1d">italic_P</annotation></semantics></math><span class="ltx_text" id="S5.SS2.p5.7.8" style="font-size:90%;"> (line 3). For each tool invocation on the ground truth answer (line 4), a prompt is constructed using the template and the output of the last invoked tool (line 5), and this prompt is used to obtain an answer from the LLM to extract the next action (line 6). If the answer from the evaluated model </span><math alttext="M" class="ltx_Math" display="inline" id="S5.SS2.p5.6.m6.1"><semantics id="S5.SS2.p5.6.m6.1a"><mi id="S5.SS2.p5.6.m6.1.1" mathsize="90%" xref="S5.SS2.p5.6.m6.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S5.SS2.p5.6.m6.1b"><ci id="S5.SS2.p5.6.m6.1.1.cmml" xref="S5.SS2.p5.6.m6.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p5.6.m6.1c">M</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p5.6.m6.1d">italic_M</annotation></semantics></math><span class="ltx_text" id="S5.SS2.p5.7.9" style="font-size:90%;"> uses the same tool as the benchmark (line 7), the ‘Observation’ part of the benchmark answer is appended to the answer from model </span><math alttext="M" class="ltx_Math" display="inline" id="S5.SS2.p5.7.m7.1"><semantics id="S5.SS2.p5.7.m7.1a"><mi id="S5.SS2.p5.7.m7.1.1" mathsize="90%" xref="S5.SS2.p5.7.m7.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S5.SS2.p5.7.m7.1b"><ci id="S5.SS2.p5.7.m7.1.1.cmml" xref="S5.SS2.p5.7.m7.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p5.7.m7.1c">M</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p5.7.m7.1d">italic_M</annotation></semantics></math><span class="ltx_text" id="S5.SS2.p5.7.10" style="font-size:90%;"> (line 8). If a wrong tool is used, it outputs “Tool Invocation Failure” (line 11), and the process is terminated (line 12).</span></p>
</div>
<figure class="ltx_float ltx_algorithm" id="algorithm1">
<div class="ltx_listing ltx_lst_numbers_left ltx_listing" id="algorithm1.26">
<div class="ltx_listingline" id="algorithm1.6.6">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="algorithm1.6.6.1.1.1" style="font-size:90%;">1</span></span><span class="ltx_text" id="algorithm1.6.6.2" style="font-size:90%;">
</span><span class="ltx_text ltx_font_bold" id="algorithm1.6.6.3" style="font-size:90%;">Input: </span><span class="ltx_text" id="algorithm1.6.6.4" style="font-size:90%;">evaluated model </span><math alttext="M" class="ltx_Math" display="inline" id="algorithm1.1.1.m1.1"><semantics id="algorithm1.1.1.m1.1a"><mi id="algorithm1.1.1.m1.1.1" mathsize="90%" xref="algorithm1.1.1.m1.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="algorithm1.1.1.m1.1b"><ci id="algorithm1.1.1.m1.1.1.cmml" xref="algorithm1.1.1.m1.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.1.1.m1.1c">M</annotation><annotation encoding="application/x-llamapun" id="algorithm1.1.1.m1.1d">italic_M</annotation></semantics></math><span class="ltx_text" id="algorithm1.6.6.5" style="font-size:90%;">; tools_pool </span><math alttext="P" class="ltx_Math" display="inline" id="algorithm1.2.2.m2.1"><semantics id="algorithm1.2.2.m2.1a"><mi id="algorithm1.2.2.m2.1.1" mathsize="90%" xref="algorithm1.2.2.m2.1.1.cmml">P</mi><annotation-xml encoding="MathML-Content" id="algorithm1.2.2.m2.1b"><ci id="algorithm1.2.2.m2.1.1.cmml" xref="algorithm1.2.2.m2.1.1">𝑃</ci></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.2.2.m2.1c">P</annotation><annotation encoding="application/x-llamapun" id="algorithm1.2.2.m2.1d">italic_P</annotation></semantics></math><span class="ltx_text" id="algorithm1.6.6.6" style="font-size:90%;">; prompt template </span><math alttext="p_{0}" class="ltx_Math" display="inline" id="algorithm1.3.3.m3.1"><semantics id="algorithm1.3.3.m3.1a"><msub id="algorithm1.3.3.m3.1.1" xref="algorithm1.3.3.m3.1.1.cmml"><mi id="algorithm1.3.3.m3.1.1.2" mathsize="90%" xref="algorithm1.3.3.m3.1.1.2.cmml">p</mi><mn id="algorithm1.3.3.m3.1.1.3" mathsize="90%" xref="algorithm1.3.3.m3.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="algorithm1.3.3.m3.1b"><apply id="algorithm1.3.3.m3.1.1.cmml" xref="algorithm1.3.3.m3.1.1"><csymbol cd="ambiguous" id="algorithm1.3.3.m3.1.1.1.cmml" xref="algorithm1.3.3.m3.1.1">subscript</csymbol><ci id="algorithm1.3.3.m3.1.1.2.cmml" xref="algorithm1.3.3.m3.1.1.2">𝑝</ci><cn id="algorithm1.3.3.m3.1.1.3.cmml" type="integer" xref="algorithm1.3.3.m3.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.3.3.m3.1c">p_{0}</annotation><annotation encoding="application/x-llamapun" id="algorithm1.3.3.m3.1d">italic_p start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="algorithm1.6.6.7" style="font-size:90%;">; question </span><math alttext="q" class="ltx_Math" display="inline" id="algorithm1.4.4.m4.1"><semantics id="algorithm1.4.4.m4.1a"><mi id="algorithm1.4.4.m4.1.1" mathsize="90%" xref="algorithm1.4.4.m4.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="algorithm1.4.4.m4.1b"><ci id="algorithm1.4.4.m4.1.1.cmml" xref="algorithm1.4.4.m4.1.1">𝑞</ci></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.4.4.m4.1c">q</annotation><annotation encoding="application/x-llamapun" id="algorithm1.4.4.m4.1d">italic_q</annotation></semantics></math><span class="ltx_text" id="algorithm1.6.6.8" style="font-size:90%;">; answer ground truth </span><math alttext="\hat{a}" class="ltx_Math" display="inline" id="algorithm1.5.5.m5.1"><semantics id="algorithm1.5.5.m5.1a"><mover accent="true" id="algorithm1.5.5.m5.1.1" xref="algorithm1.5.5.m5.1.1.cmml"><mi id="algorithm1.5.5.m5.1.1.2" mathsize="90%" xref="algorithm1.5.5.m5.1.1.2.cmml">a</mi><mo id="algorithm1.5.5.m5.1.1.1" mathsize="90%" xref="algorithm1.5.5.m5.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="algorithm1.5.5.m5.1b"><apply id="algorithm1.5.5.m5.1.1.cmml" xref="algorithm1.5.5.m5.1.1"><ci id="algorithm1.5.5.m5.1.1.1.cmml" xref="algorithm1.5.5.m5.1.1.1">^</ci><ci id="algorithm1.5.5.m5.1.1.2.cmml" xref="algorithm1.5.5.m5.1.1.2">𝑎</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.5.5.m5.1c">\hat{a}</annotation><annotation encoding="application/x-llamapun" id="algorithm1.5.5.m5.1d">over^ start_ARG italic_a end_ARG</annotation></semantics></math><span class="ltx_text" id="algorithm1.6.6.9" style="font-size:90%;">; tool set ground truth </span><math alttext="\{t\}" class="ltx_Math" display="inline" id="algorithm1.6.6.m6.1"><semantics id="algorithm1.6.6.m6.1a"><mrow id="algorithm1.6.6.m6.1.2.2" xref="algorithm1.6.6.m6.1.2.1.cmml"><mo id="algorithm1.6.6.m6.1.2.2.1" maxsize="90%" minsize="90%" xref="algorithm1.6.6.m6.1.2.1.cmml">{</mo><mi id="algorithm1.6.6.m6.1.1" mathsize="90%" xref="algorithm1.6.6.m6.1.1.cmml">t</mi><mo id="algorithm1.6.6.m6.1.2.2.2" maxsize="90%" minsize="90%" xref="algorithm1.6.6.m6.1.2.1.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="algorithm1.6.6.m6.1b"><set id="algorithm1.6.6.m6.1.2.1.cmml" xref="algorithm1.6.6.m6.1.2.2"><ci id="algorithm1.6.6.m6.1.1.cmml" xref="algorithm1.6.6.m6.1.1">𝑡</ci></set></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.6.6.m6.1c">\{t\}</annotation><annotation encoding="application/x-llamapun" id="algorithm1.6.6.m6.1d">{ italic_t }</annotation></semantics></math><span class="ltx_text" id="algorithm1.6.6.10" style="font-size:90%;">;
</span>
</div>
<div class="ltx_listingline" id="algorithm1.7.7">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="algorithm1.7.7.1.1.1" style="font-size:90%;">2</span></span><math alttext="a_{0}\leftarrow\emptyset" class="ltx_Math" display="inline" id="algorithm1.7.7.m1.1"><semantics id="algorithm1.7.7.m1.1a"><mrow id="algorithm1.7.7.m1.1.1" xref="algorithm1.7.7.m1.1.1.cmml"><msub id="algorithm1.7.7.m1.1.1.2" xref="algorithm1.7.7.m1.1.1.2.cmml"><mi id="algorithm1.7.7.m1.1.1.2.2" mathsize="90%" xref="algorithm1.7.7.m1.1.1.2.2.cmml">a</mi><mn id="algorithm1.7.7.m1.1.1.2.3" mathsize="90%" xref="algorithm1.7.7.m1.1.1.2.3.cmml">0</mn></msub><mo id="algorithm1.7.7.m1.1.1.1" mathsize="90%" stretchy="false" xref="algorithm1.7.7.m1.1.1.1.cmml">←</mo><mi id="algorithm1.7.7.m1.1.1.3" mathsize="90%" mathvariant="normal" xref="algorithm1.7.7.m1.1.1.3.cmml">∅</mi></mrow><annotation-xml encoding="MathML-Content" id="algorithm1.7.7.m1.1b"><apply id="algorithm1.7.7.m1.1.1.cmml" xref="algorithm1.7.7.m1.1.1"><ci id="algorithm1.7.7.m1.1.1.1.cmml" xref="algorithm1.7.7.m1.1.1.1">←</ci><apply id="algorithm1.7.7.m1.1.1.2.cmml" xref="algorithm1.7.7.m1.1.1.2"><csymbol cd="ambiguous" id="algorithm1.7.7.m1.1.1.2.1.cmml" xref="algorithm1.7.7.m1.1.1.2">subscript</csymbol><ci id="algorithm1.7.7.m1.1.1.2.2.cmml" xref="algorithm1.7.7.m1.1.1.2.2">𝑎</ci><cn id="algorithm1.7.7.m1.1.1.2.3.cmml" type="integer" xref="algorithm1.7.7.m1.1.1.2.3">0</cn></apply><emptyset id="algorithm1.7.7.m1.1.1.3.cmml" xref="algorithm1.7.7.m1.1.1.3"></emptyset></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.7.7.m1.1c">a_{0}\leftarrow\emptyset</annotation><annotation encoding="application/x-llamapun" id="algorithm1.7.7.m1.1d">italic_a start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ← ∅</annotation></semantics></math><span class="ltx_text" id="algorithm1.7.7.2" style="font-size:90%;">;
</span>
</div>
<div class="ltx_listingline" id="algorithm1.11.11">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="algorithm1.11.11.1.1.1" style="font-size:90%;">3</span></span><math alttext="T" class="ltx_Math" display="inline" id="algorithm1.8.8.m1.1"><semantics id="algorithm1.8.8.m1.1a"><mi id="algorithm1.8.8.m1.1.1" mathsize="90%" xref="algorithm1.8.8.m1.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="algorithm1.8.8.m1.1b"><ci id="algorithm1.8.8.m1.1.1.cmml" xref="algorithm1.8.8.m1.1.1">𝑇</ci></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.8.8.m1.1c">T</annotation><annotation encoding="application/x-llamapun" id="algorithm1.8.8.m1.1d">italic_T</annotation></semantics></math><span class="ltx_text" id="algorithm1.11.11.2" style="font-size:90%;"> = {</span><math alttext="t" class="ltx_Math" display="inline" id="algorithm1.9.9.m2.1"><semantics id="algorithm1.9.9.m2.1a"><mi id="algorithm1.9.9.m2.1.1" mathsize="90%" xref="algorithm1.9.9.m2.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="algorithm1.9.9.m2.1b"><ci id="algorithm1.9.9.m2.1.1.cmml" xref="algorithm1.9.9.m2.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.9.9.m2.1c">t</annotation><annotation encoding="application/x-llamapun" id="algorithm1.9.9.m2.1d">italic_t</annotation></semantics></math><span class="ltx_text" id="algorithm1.11.11.3" style="font-size:90%;">} </span><math alttext="\cup" class="ltx_Math" display="inline" id="algorithm1.10.10.m3.1"><semantics id="algorithm1.10.10.m3.1a"><mo id="algorithm1.10.10.m3.1.1" mathsize="90%" xref="algorithm1.10.10.m3.1.1.cmml">∪</mo><annotation-xml encoding="MathML-Content" id="algorithm1.10.10.m3.1b"><union id="algorithm1.10.10.m3.1.1.cmml" xref="algorithm1.10.10.m3.1.1"></union></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.10.10.m3.1c">\cup</annotation><annotation encoding="application/x-llamapun" id="algorithm1.10.10.m3.1d">∪</annotation></semantics></math><span class="ltx_text" id="algorithm1.11.11.4" style="font-size:90%;"> Random_Select(</span><math alttext="P" class="ltx_Math" display="inline" id="algorithm1.11.11.m4.1"><semantics id="algorithm1.11.11.m4.1a"><mi id="algorithm1.11.11.m4.1.1" mathsize="90%" xref="algorithm1.11.11.m4.1.1.cmml">P</mi><annotation-xml encoding="MathML-Content" id="algorithm1.11.11.m4.1b"><ci id="algorithm1.11.11.m4.1.1.cmml" xref="algorithm1.11.11.m4.1.1">𝑃</ci></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.11.11.m4.1c">P</annotation><annotation encoding="application/x-llamapun" id="algorithm1.11.11.m4.1d">italic_P</annotation></semantics></math><span class="ltx_text" id="algorithm1.11.11.5" style="font-size:90%;">, 4);
</span>
</div>
<div class="ltx_listingline" id="algorithm1.12.12">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="algorithm1.12.12.2.1.1" style="font-size:90%;">4</span></span><span class="ltx_text ltx_font_bold" id="algorithm1.12.12.3" style="font-size:90%;">for</span><span class="ltx_text" id="algorithm1.12.12.4" style="font-size:90%;"> </span><em class="ltx_emph ltx_font_italic" id="algorithm1.12.12.1" style="font-size:90%;">i in range(count(“Action” in <math alttext="\hat{a}" class="ltx_Math" display="inline" id="algorithm1.12.12.1.m1.1"><semantics id="algorithm1.12.12.1.m1.1a"><mover accent="true" id="algorithm1.12.12.1.m1.1.1" xref="algorithm1.12.12.1.m1.1.1.cmml"><mi id="algorithm1.12.12.1.m1.1.1.2" xref="algorithm1.12.12.1.m1.1.1.2.cmml">a</mi><mo id="algorithm1.12.12.1.m1.1.1.1" xref="algorithm1.12.12.1.m1.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="algorithm1.12.12.1.m1.1b"><apply id="algorithm1.12.12.1.m1.1.1.cmml" xref="algorithm1.12.12.1.m1.1.1"><ci id="algorithm1.12.12.1.m1.1.1.1.cmml" xref="algorithm1.12.12.1.m1.1.1.1">^</ci><ci id="algorithm1.12.12.1.m1.1.1.2.cmml" xref="algorithm1.12.12.1.m1.1.1.2">𝑎</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.12.12.1.m1.1c">\hat{a}</annotation><annotation encoding="application/x-llamapun" id="algorithm1.12.12.1.m1.1d">over^ start_ARG italic_a end_ARG</annotation></semantics></math>))</em><span class="ltx_text" id="algorithm1.12.12.5" style="font-size:90%;"> </span><span class="ltx_text ltx_font_bold" id="algorithm1.12.12.6" style="font-size:90%;">do</span><span class="ltx_text" id="algorithm1.12.12.7" style="font-size:90%;"> </span>
</div>
<div class="ltx_listingline" id="algorithm1.17.17">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="algorithm1.17.17.1.1.1" style="font-size:90%;">5</span></span><span class="ltx_text" id="algorithm1.17.17.2" style="font-size:90%;">  </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span class="ltx_text" id="algorithm1.17.17.3" style="font-size:90%;">   </span><span class="ltx_text" id="algorithm1.17.17.4" style="font-size:90%;">
</span><math alttext="p_{i}" class="ltx_Math" display="inline" id="algorithm1.13.13.m1.1"><semantics id="algorithm1.13.13.m1.1a"><msub id="algorithm1.13.13.m1.1.1" xref="algorithm1.13.13.m1.1.1.cmml"><mi id="algorithm1.13.13.m1.1.1.2" mathsize="90%" xref="algorithm1.13.13.m1.1.1.2.cmml">p</mi><mi id="algorithm1.13.13.m1.1.1.3" mathsize="90%" xref="algorithm1.13.13.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="algorithm1.13.13.m1.1b"><apply id="algorithm1.13.13.m1.1.1.cmml" xref="algorithm1.13.13.m1.1.1"><csymbol cd="ambiguous" id="algorithm1.13.13.m1.1.1.1.cmml" xref="algorithm1.13.13.m1.1.1">subscript</csymbol><ci id="algorithm1.13.13.m1.1.1.2.cmml" xref="algorithm1.13.13.m1.1.1.2">𝑝</ci><ci id="algorithm1.13.13.m1.1.1.3.cmml" xref="algorithm1.13.13.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.13.13.m1.1c">p_{i}</annotation><annotation encoding="application/x-llamapun" id="algorithm1.13.13.m1.1d">italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="algorithm1.17.17.5" style="font-size:90%;"> = </span><math alttext="p_{0}" class="ltx_Math" display="inline" id="algorithm1.14.14.m2.1"><semantics id="algorithm1.14.14.m2.1a"><msub id="algorithm1.14.14.m2.1.1" xref="algorithm1.14.14.m2.1.1.cmml"><mi id="algorithm1.14.14.m2.1.1.2" mathsize="90%" xref="algorithm1.14.14.m2.1.1.2.cmml">p</mi><mn id="algorithm1.14.14.m2.1.1.3" mathsize="90%" xref="algorithm1.14.14.m2.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="algorithm1.14.14.m2.1b"><apply id="algorithm1.14.14.m2.1.1.cmml" xref="algorithm1.14.14.m2.1.1"><csymbol cd="ambiguous" id="algorithm1.14.14.m2.1.1.1.cmml" xref="algorithm1.14.14.m2.1.1">subscript</csymbol><ci id="algorithm1.14.14.m2.1.1.2.cmml" xref="algorithm1.14.14.m2.1.1.2">𝑝</ci><cn id="algorithm1.14.14.m2.1.1.3.cmml" type="integer" xref="algorithm1.14.14.m2.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.14.14.m2.1c">p_{0}</annotation><annotation encoding="application/x-llamapun" id="algorithm1.14.14.m2.1d">italic_p start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="algorithm1.17.17.6" style="font-size:90%;">(</span><math alttext="T" class="ltx_Math" display="inline" id="algorithm1.15.15.m3.1"><semantics id="algorithm1.15.15.m3.1a"><mi id="algorithm1.15.15.m3.1.1" mathsize="90%" xref="algorithm1.15.15.m3.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="algorithm1.15.15.m3.1b"><ci id="algorithm1.15.15.m3.1.1.cmml" xref="algorithm1.15.15.m3.1.1">𝑇</ci></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.15.15.m3.1c">T</annotation><annotation encoding="application/x-llamapun" id="algorithm1.15.15.m3.1d">italic_T</annotation></semantics></math><span class="ltx_text" id="algorithm1.17.17.7" style="font-size:90%;">,</span><math alttext="q" class="ltx_Math" display="inline" id="algorithm1.16.16.m4.1"><semantics id="algorithm1.16.16.m4.1a"><mi id="algorithm1.16.16.m4.1.1" mathsize="90%" xref="algorithm1.16.16.m4.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="algorithm1.16.16.m4.1b"><ci id="algorithm1.16.16.m4.1.1.cmml" xref="algorithm1.16.16.m4.1.1">𝑞</ci></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.16.16.m4.1c">q</annotation><annotation encoding="application/x-llamapun" id="algorithm1.16.16.m4.1d">italic_q</annotation></semantics></math><span class="ltx_text" id="algorithm1.17.17.8" style="font-size:90%;">,</span><math alttext="a_{i-1}" class="ltx_Math" display="inline" id="algorithm1.17.17.m5.1"><semantics id="algorithm1.17.17.m5.1a"><msub id="algorithm1.17.17.m5.1.1" xref="algorithm1.17.17.m5.1.1.cmml"><mi id="algorithm1.17.17.m5.1.1.2" mathsize="90%" xref="algorithm1.17.17.m5.1.1.2.cmml">a</mi><mrow id="algorithm1.17.17.m5.1.1.3" xref="algorithm1.17.17.m5.1.1.3.cmml"><mi id="algorithm1.17.17.m5.1.1.3.2" mathsize="90%" xref="algorithm1.17.17.m5.1.1.3.2.cmml">i</mi><mo id="algorithm1.17.17.m5.1.1.3.1" mathsize="90%" xref="algorithm1.17.17.m5.1.1.3.1.cmml">−</mo><mn id="algorithm1.17.17.m5.1.1.3.3" mathsize="90%" xref="algorithm1.17.17.m5.1.1.3.3.cmml">1</mn></mrow></msub><annotation-xml encoding="MathML-Content" id="algorithm1.17.17.m5.1b"><apply id="algorithm1.17.17.m5.1.1.cmml" xref="algorithm1.17.17.m5.1.1"><csymbol cd="ambiguous" id="algorithm1.17.17.m5.1.1.1.cmml" xref="algorithm1.17.17.m5.1.1">subscript</csymbol><ci id="algorithm1.17.17.m5.1.1.2.cmml" xref="algorithm1.17.17.m5.1.1.2">𝑎</ci><apply id="algorithm1.17.17.m5.1.1.3.cmml" xref="algorithm1.17.17.m5.1.1.3"><minus id="algorithm1.17.17.m5.1.1.3.1.cmml" xref="algorithm1.17.17.m5.1.1.3.1"></minus><ci id="algorithm1.17.17.m5.1.1.3.2.cmml" xref="algorithm1.17.17.m5.1.1.3.2">𝑖</ci><cn id="algorithm1.17.17.m5.1.1.3.3.cmml" type="integer" xref="algorithm1.17.17.m5.1.1.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.17.17.m5.1c">a_{i-1}</annotation><annotation encoding="application/x-llamapun" id="algorithm1.17.17.m5.1d">italic_a start_POSTSUBSCRIPT italic_i - 1 end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="algorithm1.17.17.9" style="font-size:90%;">);
</span>
</div>
<div class="ltx_listingline" id="algorithm1.20.20">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="algorithm1.20.20.1.1.1" style="font-size:90%;">6</span></span><span class="ltx_text" id="algorithm1.20.20.2" style="font-size:90%;">  </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span class="ltx_text" id="algorithm1.20.20.3" style="font-size:90%;">   </span><math alttext="a_{i}" class="ltx_Math" display="inline" id="algorithm1.18.18.m1.1"><semantics id="algorithm1.18.18.m1.1a"><msub id="algorithm1.18.18.m1.1.1" xref="algorithm1.18.18.m1.1.1.cmml"><mi id="algorithm1.18.18.m1.1.1.2" mathsize="90%" xref="algorithm1.18.18.m1.1.1.2.cmml">a</mi><mi id="algorithm1.18.18.m1.1.1.3" mathsize="90%" xref="algorithm1.18.18.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="algorithm1.18.18.m1.1b"><apply id="algorithm1.18.18.m1.1.1.cmml" xref="algorithm1.18.18.m1.1.1"><csymbol cd="ambiguous" id="algorithm1.18.18.m1.1.1.1.cmml" xref="algorithm1.18.18.m1.1.1">subscript</csymbol><ci id="algorithm1.18.18.m1.1.1.2.cmml" xref="algorithm1.18.18.m1.1.1.2">𝑎</ci><ci id="algorithm1.18.18.m1.1.1.3.cmml" xref="algorithm1.18.18.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.18.18.m1.1c">a_{i}</annotation><annotation encoding="application/x-llamapun" id="algorithm1.18.18.m1.1d">italic_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="algorithm1.20.20.4" style="font-size:90%;">[”Action”] = </span><math alttext="M" class="ltx_Math" display="inline" id="algorithm1.19.19.m2.1"><semantics id="algorithm1.19.19.m2.1a"><mi id="algorithm1.19.19.m2.1.1" mathsize="90%" xref="algorithm1.19.19.m2.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="algorithm1.19.19.m2.1b"><ci id="algorithm1.19.19.m2.1.1.cmml" xref="algorithm1.19.19.m2.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.19.19.m2.1c">M</annotation><annotation encoding="application/x-llamapun" id="algorithm1.19.19.m2.1d">italic_M</annotation></semantics></math><span class="ltx_text" id="algorithm1.20.20.5" style="font-size:90%;">(</span><math alttext="p_{i}" class="ltx_Math" display="inline" id="algorithm1.20.20.m3.1"><semantics id="algorithm1.20.20.m3.1a"><msub id="algorithm1.20.20.m3.1.1" xref="algorithm1.20.20.m3.1.1.cmml"><mi id="algorithm1.20.20.m3.1.1.2" mathsize="90%" xref="algorithm1.20.20.m3.1.1.2.cmml">p</mi><mi id="algorithm1.20.20.m3.1.1.3" mathsize="90%" xref="algorithm1.20.20.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="algorithm1.20.20.m3.1b"><apply id="algorithm1.20.20.m3.1.1.cmml" xref="algorithm1.20.20.m3.1.1"><csymbol cd="ambiguous" id="algorithm1.20.20.m3.1.1.1.cmml" xref="algorithm1.20.20.m3.1.1">subscript</csymbol><ci id="algorithm1.20.20.m3.1.1.2.cmml" xref="algorithm1.20.20.m3.1.1.2">𝑝</ci><ci id="algorithm1.20.20.m3.1.1.3.cmml" xref="algorithm1.20.20.m3.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.20.20.m3.1c">p_{i}</annotation><annotation encoding="application/x-llamapun" id="algorithm1.20.20.m3.1d">italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="algorithm1.20.20.6" style="font-size:90%;">).extract();
</span>
</div>
<div class="ltx_listingline" id="algorithm1.22.22">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="algorithm1.22.22.3.1.1" style="font-size:90%;">7</span></span><span class="ltx_text" id="algorithm1.22.22.4" style="font-size:90%;">  </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span class="ltx_text" id="algorithm1.22.22.5" style="font-size:90%;">   </span><span class="ltx_text ltx_font_bold" id="algorithm1.22.22.6" style="font-size:90%;">if</span><span class="ltx_text" id="algorithm1.22.22.7" style="font-size:90%;"> </span><em class="ltx_emph ltx_font_italic" id="algorithm1.22.22.2" style="font-size:90%;"><math alttext="a_{i}" class="ltx_Math" display="inline" id="algorithm1.21.21.1.m1.1"><semantics id="algorithm1.21.21.1.m1.1a"><msub id="algorithm1.21.21.1.m1.1.1" xref="algorithm1.21.21.1.m1.1.1.cmml"><mi id="algorithm1.21.21.1.m1.1.1.2" xref="algorithm1.21.21.1.m1.1.1.2.cmml">a</mi><mi id="algorithm1.21.21.1.m1.1.1.3" xref="algorithm1.21.21.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="algorithm1.21.21.1.m1.1b"><apply id="algorithm1.21.21.1.m1.1.1.cmml" xref="algorithm1.21.21.1.m1.1.1"><csymbol cd="ambiguous" id="algorithm1.21.21.1.m1.1.1.1.cmml" xref="algorithm1.21.21.1.m1.1.1">subscript</csymbol><ci id="algorithm1.21.21.1.m1.1.1.2.cmml" xref="algorithm1.21.21.1.m1.1.1.2">𝑎</ci><ci id="algorithm1.21.21.1.m1.1.1.3.cmml" xref="algorithm1.21.21.1.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.21.21.1.m1.1c">a_{i}</annotation><annotation encoding="application/x-llamapun" id="algorithm1.21.21.1.m1.1d">italic_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>[”Action”] == <math alttext="\hat{a}" class="ltx_Math" display="inline" id="algorithm1.22.22.2.m2.1"><semantics id="algorithm1.22.22.2.m2.1a"><mover accent="true" id="algorithm1.22.22.2.m2.1.1" xref="algorithm1.22.22.2.m2.1.1.cmml"><mi id="algorithm1.22.22.2.m2.1.1.2" xref="algorithm1.22.22.2.m2.1.1.2.cmml">a</mi><mo id="algorithm1.22.22.2.m2.1.1.1" xref="algorithm1.22.22.2.m2.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="algorithm1.22.22.2.m2.1b"><apply id="algorithm1.22.22.2.m2.1.1.cmml" xref="algorithm1.22.22.2.m2.1.1"><ci id="algorithm1.22.22.2.m2.1.1.1.cmml" xref="algorithm1.22.22.2.m2.1.1.1">^</ci><ci id="algorithm1.22.22.2.m2.1.1.2.cmml" xref="algorithm1.22.22.2.m2.1.1.2">𝑎</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.22.22.2.m2.1c">\hat{a}</annotation><annotation encoding="application/x-llamapun" id="algorithm1.22.22.2.m2.1d">over^ start_ARG italic_a end_ARG</annotation></semantics></math>[i][”Action”]</em><span class="ltx_text" id="algorithm1.22.22.8" style="font-size:90%;"> </span><span class="ltx_text ltx_font_bold" id="algorithm1.22.22.9" style="font-size:90%;">then</span><span class="ltx_text" id="algorithm1.22.22.10" style="font-size:90%;"> </span>
</div>
<div class="ltx_listingline" id="algorithm1.24.24">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="algorithm1.24.24.1.1.1" style="font-size:90%;">8</span></span><span class="ltx_text" id="algorithm1.24.24.2" style="font-size:90%;">  </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span class="ltx_text" id="algorithm1.24.24.3" style="font-size:90%;">     </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span class="ltx_text" id="algorithm1.24.24.4" style="font-size:90%;">   </span><span class="ltx_text" id="algorithm1.24.24.5" style="font-size:90%;">
</span><math alttext="a_{i}" class="ltx_Math" display="inline" id="algorithm1.23.23.m1.1"><semantics id="algorithm1.23.23.m1.1a"><msub id="algorithm1.23.23.m1.1.1" xref="algorithm1.23.23.m1.1.1.cmml"><mi id="algorithm1.23.23.m1.1.1.2" mathsize="90%" xref="algorithm1.23.23.m1.1.1.2.cmml">a</mi><mi id="algorithm1.23.23.m1.1.1.3" mathsize="90%" xref="algorithm1.23.23.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="algorithm1.23.23.m1.1b"><apply id="algorithm1.23.23.m1.1.1.cmml" xref="algorithm1.23.23.m1.1.1"><csymbol cd="ambiguous" id="algorithm1.23.23.m1.1.1.1.cmml" xref="algorithm1.23.23.m1.1.1">subscript</csymbol><ci id="algorithm1.23.23.m1.1.1.2.cmml" xref="algorithm1.23.23.m1.1.1.2">𝑎</ci><ci id="algorithm1.23.23.m1.1.1.3.cmml" xref="algorithm1.23.23.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.23.23.m1.1c">a_{i}</annotation><annotation encoding="application/x-llamapun" id="algorithm1.23.23.m1.1d">italic_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="algorithm1.24.24.6" style="font-size:90%;">.append(</span><math alttext="\hat{a}" class="ltx_Math" display="inline" id="algorithm1.24.24.m2.1"><semantics id="algorithm1.24.24.m2.1a"><mover accent="true" id="algorithm1.24.24.m2.1.1" xref="algorithm1.24.24.m2.1.1.cmml"><mi id="algorithm1.24.24.m2.1.1.2" mathsize="90%" xref="algorithm1.24.24.m2.1.1.2.cmml">a</mi><mo id="algorithm1.24.24.m2.1.1.1" mathsize="90%" xref="algorithm1.24.24.m2.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="algorithm1.24.24.m2.1b"><apply id="algorithm1.24.24.m2.1.1.cmml" xref="algorithm1.24.24.m2.1.1"><ci id="algorithm1.24.24.m2.1.1.1.cmml" xref="algorithm1.24.24.m2.1.1.1">^</ci><ci id="algorithm1.24.24.m2.1.1.2.cmml" xref="algorithm1.24.24.m2.1.1.2">𝑎</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.24.24.m2.1c">\hat{a}</annotation><annotation encoding="application/x-llamapun" id="algorithm1.24.24.m2.1d">over^ start_ARG italic_a end_ARG</annotation></semantics></math><span class="ltx_text" id="algorithm1.24.24.7" style="font-size:90%;">[i][”Observation”]);
</span>
</div>
<div class="ltx_listingline" id="algorithm1.26.27">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="algorithm1.26.27.1.1.1" style="font-size:90%;">9</span></span><span class="ltx_text" id="algorithm1.26.27.2" style="font-size:90%;">  </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span class="ltx_text" id="algorithm1.26.27.3" style="font-size:90%;">     </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span class="ltx_text" id="algorithm1.26.27.4" style="font-size:90%;">   </span><span class="ltx_text ltx_font_bold" id="algorithm1.26.27.5" style="font-size:90%;">Continue</span><span class="ltx_text" id="algorithm1.26.27.6" style="font-size:90%;">;
</span>
</div>
<div class="ltx_listingline" id="algorithm1.26.28">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="algorithm1.26.28.1.1.1" style="font-size:90%;">10</span></span><span class="ltx_text" id="algorithm1.26.28.2" style="font-size:90%;">  </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span class="ltx_text" id="algorithm1.26.28.3" style="font-size:90%;">   </span><span class="ltx_text" id="algorithm1.26.28.4" style="font-size:90%;"> end if</span>
</div>
<div class="ltx_listingline" id="algorithm1.25.25">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="algorithm1.25.25.1.1.1" style="font-size:90%;">11</span></span><span class="ltx_text" id="algorithm1.25.25.2" style="font-size:90%;">  </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span class="ltx_text" id="algorithm1.25.25.3" style="font-size:90%;">   </span><math alttext="a_{i}" class="ltx_Math" display="inline" id="algorithm1.25.25.m1.1"><semantics id="algorithm1.25.25.m1.1a"><msub id="algorithm1.25.25.m1.1.1" xref="algorithm1.25.25.m1.1.1.cmml"><mi id="algorithm1.25.25.m1.1.1.2" mathsize="90%" xref="algorithm1.25.25.m1.1.1.2.cmml">a</mi><mi id="algorithm1.25.25.m1.1.1.3" mathsize="90%" xref="algorithm1.25.25.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="algorithm1.25.25.m1.1b"><apply id="algorithm1.25.25.m1.1.1.cmml" xref="algorithm1.25.25.m1.1.1"><csymbol cd="ambiguous" id="algorithm1.25.25.m1.1.1.1.cmml" xref="algorithm1.25.25.m1.1.1">subscript</csymbol><ci id="algorithm1.25.25.m1.1.1.2.cmml" xref="algorithm1.25.25.m1.1.1.2">𝑎</ci><ci id="algorithm1.25.25.m1.1.1.3.cmml" xref="algorithm1.25.25.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.25.25.m1.1c">a_{i}</annotation><annotation encoding="application/x-llamapun" id="algorithm1.25.25.m1.1d">italic_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="algorithm1.25.25.4" style="font-size:90%;">.append(”Tool Invocation Failure.”);
</span>
</div>
<div class="ltx_listingline" id="algorithm1.26.29">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="algorithm1.26.29.1.1.1" style="font-size:90%;">12</span></span><span class="ltx_text" id="algorithm1.26.29.2" style="font-size:90%;">  </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span class="ltx_text" id="algorithm1.26.29.3" style="font-size:90%;">   </span><span class="ltx_text ltx_font_bold" id="algorithm1.26.29.4" style="font-size:90%;">Break</span><span class="ltx_text" id="algorithm1.26.29.5" style="font-size:90%;">;
</span>
</div>
<div class="ltx_listingline" id="algorithm1.26.30">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="algorithm1.26.30.1.1.1" style="font-size:90%;">13</span></span><span class="ltx_text" id="algorithm1.26.30.2" style="font-size:90%;"> end for</span>
</div>
<div class="ltx_listingline" id="algorithm1.26.31">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="algorithm1.26.31.1.1.1" style="font-size:90%;">14</span></span>
</div>
<div class="ltx_listingline" id="algorithm1.26.26">
<span class="ltx_text ltx_font_bold" id="algorithm1.26.26.1" style="font-size:90%;">Return <math alttext="a_{i}" class="ltx_Math" display="inline" id="algorithm1.26.26.1.m1.1"><semantics id="algorithm1.26.26.1.m1.1a"><msub id="algorithm1.26.26.1.m1.1.1" xref="algorithm1.26.26.1.m1.1.1.cmml"><mi id="algorithm1.26.26.1.m1.1.1.2" xref="algorithm1.26.26.1.m1.1.1.2.cmml">a</mi><mi id="algorithm1.26.26.1.m1.1.1.3" xref="algorithm1.26.26.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="algorithm1.26.26.1.m1.1b"><apply id="algorithm1.26.26.1.m1.1.1.cmml" xref="algorithm1.26.26.1.m1.1.1"><csymbol cd="ambiguous" id="algorithm1.26.26.1.m1.1.1.1.cmml" xref="algorithm1.26.26.1.m1.1.1">subscript</csymbol><ci id="algorithm1.26.26.1.m1.1.1.2.cmml" xref="algorithm1.26.26.1.m1.1.1.2">𝑎</ci><ci id="algorithm1.26.26.1.m1.1.1.3.cmml" xref="algorithm1.26.26.1.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.26.26.1.m1.1c">a_{i}</annotation><annotation encoding="application/x-llamapun" id="algorithm1.26.26.1.m1.1d">italic_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math></span><span class="ltx_text" id="algorithm1.26.26.2" style="font-size:90%;">
</span>
</div>
</div>
<figcaption class="ltx_caption" style="font-size:90%;"><span class="ltx_tag ltx_tag_float"><span class="ltx_text ltx_font_bold" id="algorithm1.30.1.1">Algorithm 1</span> </span>Answer Generation in Instance Q&amp;A </figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S5.SS2.p6">
<p class="ltx_p" id="S5.SS2.p6.1"><span class="ltx_text ltx_font_bold" id="S5.SS2.p6.1.1" style="font-size:90%;">Metrics.</span><span class="ltx_text" id="S5.SS2.p6.1.2" style="font-size:90%;"> To ensure a comprehensive end-to-end evaluation, we adopt two metrics, namely WinRate and MCA (Multiple Choice Accuracy), to measure the quality of end-to-end generation.</span></p>
</div>
<div class="ltx_para" id="S5.SS2.p7">
<p class="ltx_p" id="S5.SS2.p7.7"><span class="ltx_text ltx_font_italic" id="S5.SS2.p7.7.1" style="font-size:90%;">(1) MCA (Multiple-Choice Accuracy):</span><span class="ltx_text" id="S5.SS2.p7.7.2" style="font-size:90%;"> This metric measures the accuracy of all multiple-choice questions following </span><math alttext="MCA=\sum_{i}m_{i,i}/\sum_{i}" class="ltx_Math" display="inline" id="S5.SS2.p7.1.m1.2"><semantics id="S5.SS2.p7.1.m1.2a"><mrow id="S5.SS2.p7.1.m1.2.3" xref="S5.SS2.p7.1.m1.2.3.cmml"><mrow id="S5.SS2.p7.1.m1.2.3.2" xref="S5.SS2.p7.1.m1.2.3.2.cmml"><mi id="S5.SS2.p7.1.m1.2.3.2.2" mathsize="90%" xref="S5.SS2.p7.1.m1.2.3.2.2.cmml">M</mi><mo id="S5.SS2.p7.1.m1.2.3.2.1" xref="S5.SS2.p7.1.m1.2.3.2.1.cmml">⁢</mo><mi id="S5.SS2.p7.1.m1.2.3.2.3" mathsize="90%" xref="S5.SS2.p7.1.m1.2.3.2.3.cmml">C</mi><mo id="S5.SS2.p7.1.m1.2.3.2.1a" xref="S5.SS2.p7.1.m1.2.3.2.1.cmml">⁢</mo><mi id="S5.SS2.p7.1.m1.2.3.2.4" mathsize="90%" xref="S5.SS2.p7.1.m1.2.3.2.4.cmml">A</mi></mrow><mo id="S5.SS2.p7.1.m1.2.3.1" mathsize="90%" rspace="0.111em" xref="S5.SS2.p7.1.m1.2.3.1.cmml">=</mo><mrow id="S5.SS2.p7.1.m1.2.3.3" xref="S5.SS2.p7.1.m1.2.3.3.cmml"><msub id="S5.SS2.p7.1.m1.2.3.3.1" xref="S5.SS2.p7.1.m1.2.3.3.1.cmml"><mo id="S5.SS2.p7.1.m1.2.3.3.1.2" maxsize="90%" minsize="90%" stretchy="true" xref="S5.SS2.p7.1.m1.2.3.3.1.2.cmml">∑</mo><mi id="S5.SS2.p7.1.m1.2.3.3.1.3" mathsize="90%" xref="S5.SS2.p7.1.m1.2.3.3.1.3.cmml">i</mi></msub><mrow id="S5.SS2.p7.1.m1.2.3.3.2" xref="S5.SS2.p7.1.m1.2.3.3.2.cmml"><msub id="S5.SS2.p7.1.m1.2.3.3.2.2" xref="S5.SS2.p7.1.m1.2.3.3.2.2.cmml"><mi id="S5.SS2.p7.1.m1.2.3.3.2.2.2" mathsize="90%" xref="S5.SS2.p7.1.m1.2.3.3.2.2.2.cmml">m</mi><mrow id="S5.SS2.p7.1.m1.2.2.2.4" xref="S5.SS2.p7.1.m1.2.2.2.3.cmml"><mi id="S5.SS2.p7.1.m1.1.1.1.1" mathsize="90%" xref="S5.SS2.p7.1.m1.1.1.1.1.cmml">i</mi><mo id="S5.SS2.p7.1.m1.2.2.2.4.1" mathsize="90%" xref="S5.SS2.p7.1.m1.2.2.2.3.cmml">,</mo><mi id="S5.SS2.p7.1.m1.2.2.2.2" mathsize="90%" xref="S5.SS2.p7.1.m1.2.2.2.2.cmml">i</mi></mrow></msub><mo id="S5.SS2.p7.1.m1.2.3.3.2.1" maxsize="90%" minsize="90%" rspace="0.055em" stretchy="true" symmetric="true" xref="S5.SS2.p7.1.m1.2.3.3.2.1.cmml">/</mo><msub id="S5.SS2.p7.1.m1.2.3.3.2.3" xref="S5.SS2.p7.1.m1.2.3.3.2.3.cmml"><mo id="S5.SS2.p7.1.m1.2.3.3.2.3.2" maxsize="90%" minsize="90%" stretchy="true" xref="S5.SS2.p7.1.m1.2.3.3.2.3.2.cmml">∑</mo><mi id="S5.SS2.p7.1.m1.2.3.3.2.3.3" mathsize="90%" xref="S5.SS2.p7.1.m1.2.3.3.2.3.3.cmml">i</mi></msub></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.p7.1.m1.2b"><apply id="S5.SS2.p7.1.m1.2.3.cmml" xref="S5.SS2.p7.1.m1.2.3"><eq id="S5.SS2.p7.1.m1.2.3.1.cmml" xref="S5.SS2.p7.1.m1.2.3.1"></eq><apply id="S5.SS2.p7.1.m1.2.3.2.cmml" xref="S5.SS2.p7.1.m1.2.3.2"><times id="S5.SS2.p7.1.m1.2.3.2.1.cmml" xref="S5.SS2.p7.1.m1.2.3.2.1"></times><ci id="S5.SS2.p7.1.m1.2.3.2.2.cmml" xref="S5.SS2.p7.1.m1.2.3.2.2">𝑀</ci><ci id="S5.SS2.p7.1.m1.2.3.2.3.cmml" xref="S5.SS2.p7.1.m1.2.3.2.3">𝐶</ci><ci id="S5.SS2.p7.1.m1.2.3.2.4.cmml" xref="S5.SS2.p7.1.m1.2.3.2.4">𝐴</ci></apply><apply id="S5.SS2.p7.1.m1.2.3.3.cmml" xref="S5.SS2.p7.1.m1.2.3.3"><apply id="S5.SS2.p7.1.m1.2.3.3.1.cmml" xref="S5.SS2.p7.1.m1.2.3.3.1"><csymbol cd="ambiguous" id="S5.SS2.p7.1.m1.2.3.3.1.1.cmml" xref="S5.SS2.p7.1.m1.2.3.3.1">subscript</csymbol><sum id="S5.SS2.p7.1.m1.2.3.3.1.2.cmml" xref="S5.SS2.p7.1.m1.2.3.3.1.2"></sum><ci id="S5.SS2.p7.1.m1.2.3.3.1.3.cmml" xref="S5.SS2.p7.1.m1.2.3.3.1.3">𝑖</ci></apply><apply id="S5.SS2.p7.1.m1.2.3.3.2.cmml" xref="S5.SS2.p7.1.m1.2.3.3.2"><divide id="S5.SS2.p7.1.m1.2.3.3.2.1.cmml" xref="S5.SS2.p7.1.m1.2.3.3.2.1"></divide><apply id="S5.SS2.p7.1.m1.2.3.3.2.2.cmml" xref="S5.SS2.p7.1.m1.2.3.3.2.2"><csymbol cd="ambiguous" id="S5.SS2.p7.1.m1.2.3.3.2.2.1.cmml" xref="S5.SS2.p7.1.m1.2.3.3.2.2">subscript</csymbol><ci id="S5.SS2.p7.1.m1.2.3.3.2.2.2.cmml" xref="S5.SS2.p7.1.m1.2.3.3.2.2.2">𝑚</ci><list id="S5.SS2.p7.1.m1.2.2.2.3.cmml" xref="S5.SS2.p7.1.m1.2.2.2.4"><ci id="S5.SS2.p7.1.m1.1.1.1.1.cmml" xref="S5.SS2.p7.1.m1.1.1.1.1">𝑖</ci><ci id="S5.SS2.p7.1.m1.2.2.2.2.cmml" xref="S5.SS2.p7.1.m1.2.2.2.2">𝑖</ci></list></apply><apply id="S5.SS2.p7.1.m1.2.3.3.2.3.cmml" xref="S5.SS2.p7.1.m1.2.3.3.2.3"><csymbol cd="ambiguous" id="S5.SS2.p7.1.m1.2.3.3.2.3.1.cmml" xref="S5.SS2.p7.1.m1.2.3.3.2.3">subscript</csymbol><sum id="S5.SS2.p7.1.m1.2.3.3.2.3.2.cmml" xref="S5.SS2.p7.1.m1.2.3.3.2.3.2"></sum><ci id="S5.SS2.p7.1.m1.2.3.3.2.3.3.cmml" xref="S5.SS2.p7.1.m1.2.3.3.2.3.3">𝑖</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p7.1.m1.2c">MCA=\sum_{i}m_{i,i}/\sum_{i}</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p7.1.m1.2d">italic_M italic_C italic_A = ∑ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_m start_POSTSUBSCRIPT italic_i , italic_i end_POSTSUBSCRIPT / ∑ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="S5.SS2.p7.7.3" style="font-size:90%;"> </span><math alttext="\sum_{j}m_{i,j})," class="ltx_math_unparsed" display="inline" id="S5.SS2.p7.2.m2.2"><semantics id="S5.SS2.p7.2.m2.2a"><mrow id="S5.SS2.p7.2.m2.2b"><msub id="S5.SS2.p7.2.m2.2.3"><mo id="S5.SS2.p7.2.m2.2.3.2" maxsize="90%" minsize="90%" stretchy="true">∑</mo><mi id="S5.SS2.p7.2.m2.2.3.3" mathsize="90%">j</mi></msub><msub id="S5.SS2.p7.2.m2.2.4"><mi id="S5.SS2.p7.2.m2.2.4.2" mathsize="90%">m</mi><mrow id="S5.SS2.p7.2.m2.2.2.2.4"><mi id="S5.SS2.p7.2.m2.1.1.1.1" mathsize="90%">i</mi><mo id="S5.SS2.p7.2.m2.2.2.2.4.1" mathsize="90%">,</mo><mi id="S5.SS2.p7.2.m2.2.2.2.2" mathsize="90%">j</mi></mrow></msub><mo id="S5.SS2.p7.2.m2.2.5" maxsize="90%" minsize="90%">)</mo><mo id="S5.SS2.p7.2.m2.2.6" mathsize="90%">,</mo></mrow><annotation encoding="application/x-tex" id="S5.SS2.p7.2.m2.2c">\sum_{j}m_{i,j}),</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p7.2.m2.2d">∑ start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT italic_m start_POSTSUBSCRIPT italic_i , italic_j end_POSTSUBSCRIPT ) ,</annotation></semantics></math><span class="ltx_text" id="S5.SS2.p7.7.4" style="font-size:90%;"> where </span><math alttext="m_{i,j}" class="ltx_Math" display="inline" id="S5.SS2.p7.3.m3.2"><semantics id="S5.SS2.p7.3.m3.2a"><msub id="S5.SS2.p7.3.m3.2.3" xref="S5.SS2.p7.3.m3.2.3.cmml"><mi id="S5.SS2.p7.3.m3.2.3.2" mathsize="90%" xref="S5.SS2.p7.3.m3.2.3.2.cmml">m</mi><mrow id="S5.SS2.p7.3.m3.2.2.2.4" xref="S5.SS2.p7.3.m3.2.2.2.3.cmml"><mi id="S5.SS2.p7.3.m3.1.1.1.1" mathsize="90%" xref="S5.SS2.p7.3.m3.1.1.1.1.cmml">i</mi><mo id="S5.SS2.p7.3.m3.2.2.2.4.1" mathsize="90%" xref="S5.SS2.p7.3.m3.2.2.2.3.cmml">,</mo><mi id="S5.SS2.p7.3.m3.2.2.2.2" mathsize="90%" xref="S5.SS2.p7.3.m3.2.2.2.2.cmml">j</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S5.SS2.p7.3.m3.2b"><apply id="S5.SS2.p7.3.m3.2.3.cmml" xref="S5.SS2.p7.3.m3.2.3"><csymbol cd="ambiguous" id="S5.SS2.p7.3.m3.2.3.1.cmml" xref="S5.SS2.p7.3.m3.2.3">subscript</csymbol><ci id="S5.SS2.p7.3.m3.2.3.2.cmml" xref="S5.SS2.p7.3.m3.2.3.2">𝑚</ci><list id="S5.SS2.p7.3.m3.2.2.2.3.cmml" xref="S5.SS2.p7.3.m3.2.2.2.4"><ci id="S5.SS2.p7.3.m3.1.1.1.1.cmml" xref="S5.SS2.p7.3.m3.1.1.1.1">𝑖</ci><ci id="S5.SS2.p7.3.m3.2.2.2.2.cmml" xref="S5.SS2.p7.3.m3.2.2.2.2">𝑗</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p7.3.m3.2c">m_{i,j}</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p7.3.m3.2d">italic_m start_POSTSUBSCRIPT italic_i , italic_j end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="S5.SS2.p7.7.5" style="font-size:90%;"> is the number of answers that the ground truth choice is </span><math alttext="i" class="ltx_Math" display="inline" id="S5.SS2.p7.4.m4.1"><semantics id="S5.SS2.p7.4.m4.1a"><mi id="S5.SS2.p7.4.m4.1.1" mathsize="90%" xref="S5.SS2.p7.4.m4.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S5.SS2.p7.4.m4.1b"><ci id="S5.SS2.p7.4.m4.1.1.cmml" xref="S5.SS2.p7.4.m4.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p7.4.m4.1c">i</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p7.4.m4.1d">italic_i</annotation></semantics></math><span class="ltx_text" id="S5.SS2.p7.7.6" style="font-size:90%;"> and the LLM’s output is </span><math alttext="j" class="ltx_Math" display="inline" id="S5.SS2.p7.5.m5.1"><semantics id="S5.SS2.p7.5.m5.1a"><mi id="S5.SS2.p7.5.m5.1.1" mathsize="90%" xref="S5.SS2.p7.5.m5.1.1.cmml">j</mi><annotation-xml encoding="MathML-Content" id="S5.SS2.p7.5.m5.1b"><ci id="S5.SS2.p7.5.m5.1.1.cmml" xref="S5.SS2.p7.5.m5.1.1">𝑗</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p7.5.m5.1c">j</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p7.5.m5.1d">italic_j</annotation></semantics></math><span class="ltx_text" id="S5.SS2.p7.7.7" style="font-size:90%;">, </span><math alttext="i,j\in\{A,B,C,D,others\}" class="ltx_Math" display="inline" id="S5.SS2.p7.6.m6.7"><semantics id="S5.SS2.p7.6.m6.7a"><mrow id="S5.SS2.p7.6.m6.7.7" xref="S5.SS2.p7.6.m6.7.7.cmml"><mrow id="S5.SS2.p7.6.m6.7.7.3.2" xref="S5.SS2.p7.6.m6.7.7.3.1.cmml"><mi id="S5.SS2.p7.6.m6.5.5" mathsize="90%" xref="S5.SS2.p7.6.m6.5.5.cmml">i</mi><mo id="S5.SS2.p7.6.m6.7.7.3.2.1" mathsize="90%" xref="S5.SS2.p7.6.m6.7.7.3.1.cmml">,</mo><mi id="S5.SS2.p7.6.m6.6.6" mathsize="90%" xref="S5.SS2.p7.6.m6.6.6.cmml">j</mi></mrow><mo id="S5.SS2.p7.6.m6.7.7.2" mathsize="90%" xref="S5.SS2.p7.6.m6.7.7.2.cmml">∈</mo><mrow id="S5.SS2.p7.6.m6.7.7.1.1" xref="S5.SS2.p7.6.m6.7.7.1.2.cmml"><mo id="S5.SS2.p7.6.m6.7.7.1.1.2" maxsize="90%" minsize="90%" xref="S5.SS2.p7.6.m6.7.7.1.2.cmml">{</mo><mi id="S5.SS2.p7.6.m6.1.1" mathsize="90%" xref="S5.SS2.p7.6.m6.1.1.cmml">A</mi><mo id="S5.SS2.p7.6.m6.7.7.1.1.3" mathsize="90%" xref="S5.SS2.p7.6.m6.7.7.1.2.cmml">,</mo><mi id="S5.SS2.p7.6.m6.2.2" mathsize="90%" xref="S5.SS2.p7.6.m6.2.2.cmml">B</mi><mo id="S5.SS2.p7.6.m6.7.7.1.1.4" mathsize="90%" xref="S5.SS2.p7.6.m6.7.7.1.2.cmml">,</mo><mi id="S5.SS2.p7.6.m6.3.3" mathsize="90%" xref="S5.SS2.p7.6.m6.3.3.cmml">C</mi><mo id="S5.SS2.p7.6.m6.7.7.1.1.5" mathsize="90%" xref="S5.SS2.p7.6.m6.7.7.1.2.cmml">,</mo><mi id="S5.SS2.p7.6.m6.4.4" mathsize="90%" xref="S5.SS2.p7.6.m6.4.4.cmml">D</mi><mo id="S5.SS2.p7.6.m6.7.7.1.1.6" mathsize="90%" xref="S5.SS2.p7.6.m6.7.7.1.2.cmml">,</mo><mrow id="S5.SS2.p7.6.m6.7.7.1.1.1" xref="S5.SS2.p7.6.m6.7.7.1.1.1.cmml"><mi id="S5.SS2.p7.6.m6.7.7.1.1.1.2" mathsize="90%" xref="S5.SS2.p7.6.m6.7.7.1.1.1.2.cmml">o</mi><mo id="S5.SS2.p7.6.m6.7.7.1.1.1.1" xref="S5.SS2.p7.6.m6.7.7.1.1.1.1.cmml">⁢</mo><mi id="S5.SS2.p7.6.m6.7.7.1.1.1.3" mathsize="90%" xref="S5.SS2.p7.6.m6.7.7.1.1.1.3.cmml">t</mi><mo id="S5.SS2.p7.6.m6.7.7.1.1.1.1a" xref="S5.SS2.p7.6.m6.7.7.1.1.1.1.cmml">⁢</mo><mi id="S5.SS2.p7.6.m6.7.7.1.1.1.4" mathsize="90%" xref="S5.SS2.p7.6.m6.7.7.1.1.1.4.cmml">h</mi><mo id="S5.SS2.p7.6.m6.7.7.1.1.1.1b" xref="S5.SS2.p7.6.m6.7.7.1.1.1.1.cmml">⁢</mo><mi id="S5.SS2.p7.6.m6.7.7.1.1.1.5" mathsize="90%" xref="S5.SS2.p7.6.m6.7.7.1.1.1.5.cmml">e</mi><mo id="S5.SS2.p7.6.m6.7.7.1.1.1.1c" xref="S5.SS2.p7.6.m6.7.7.1.1.1.1.cmml">⁢</mo><mi id="S5.SS2.p7.6.m6.7.7.1.1.1.6" mathsize="90%" xref="S5.SS2.p7.6.m6.7.7.1.1.1.6.cmml">r</mi><mo id="S5.SS2.p7.6.m6.7.7.1.1.1.1d" xref="S5.SS2.p7.6.m6.7.7.1.1.1.1.cmml">⁢</mo><mi id="S5.SS2.p7.6.m6.7.7.1.1.1.7" mathsize="90%" xref="S5.SS2.p7.6.m6.7.7.1.1.1.7.cmml">s</mi></mrow><mo id="S5.SS2.p7.6.m6.7.7.1.1.7" maxsize="90%" minsize="90%" xref="S5.SS2.p7.6.m6.7.7.1.2.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.p7.6.m6.7b"><apply id="S5.SS2.p7.6.m6.7.7.cmml" xref="S5.SS2.p7.6.m6.7.7"><in id="S5.SS2.p7.6.m6.7.7.2.cmml" xref="S5.SS2.p7.6.m6.7.7.2"></in><list id="S5.SS2.p7.6.m6.7.7.3.1.cmml" xref="S5.SS2.p7.6.m6.7.7.3.2"><ci id="S5.SS2.p7.6.m6.5.5.cmml" xref="S5.SS2.p7.6.m6.5.5">𝑖</ci><ci id="S5.SS2.p7.6.m6.6.6.cmml" xref="S5.SS2.p7.6.m6.6.6">𝑗</ci></list><set id="S5.SS2.p7.6.m6.7.7.1.2.cmml" xref="S5.SS2.p7.6.m6.7.7.1.1"><ci id="S5.SS2.p7.6.m6.1.1.cmml" xref="S5.SS2.p7.6.m6.1.1">𝐴</ci><ci id="S5.SS2.p7.6.m6.2.2.cmml" xref="S5.SS2.p7.6.m6.2.2">𝐵</ci><ci id="S5.SS2.p7.6.m6.3.3.cmml" xref="S5.SS2.p7.6.m6.3.3">𝐶</ci><ci id="S5.SS2.p7.6.m6.4.4.cmml" xref="S5.SS2.p7.6.m6.4.4">𝐷</ci><apply id="S5.SS2.p7.6.m6.7.7.1.1.1.cmml" xref="S5.SS2.p7.6.m6.7.7.1.1.1"><times id="S5.SS2.p7.6.m6.7.7.1.1.1.1.cmml" xref="S5.SS2.p7.6.m6.7.7.1.1.1.1"></times><ci id="S5.SS2.p7.6.m6.7.7.1.1.1.2.cmml" xref="S5.SS2.p7.6.m6.7.7.1.1.1.2">𝑜</ci><ci id="S5.SS2.p7.6.m6.7.7.1.1.1.3.cmml" xref="S5.SS2.p7.6.m6.7.7.1.1.1.3">𝑡</ci><ci id="S5.SS2.p7.6.m6.7.7.1.1.1.4.cmml" xref="S5.SS2.p7.6.m6.7.7.1.1.1.4">ℎ</ci><ci id="S5.SS2.p7.6.m6.7.7.1.1.1.5.cmml" xref="S5.SS2.p7.6.m6.7.7.1.1.1.5">𝑒</ci><ci id="S5.SS2.p7.6.m6.7.7.1.1.1.6.cmml" xref="S5.SS2.p7.6.m6.7.7.1.1.1.6">𝑟</ci><ci id="S5.SS2.p7.6.m6.7.7.1.1.1.7.cmml" xref="S5.SS2.p7.6.m6.7.7.1.1.1.7">𝑠</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p7.6.m6.7c">i,j\in\{A,B,C,D,others\}</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p7.6.m6.7d">italic_i , italic_j ∈ { italic_A , italic_B , italic_C , italic_D , italic_o italic_t italic_h italic_e italic_r italic_s }</annotation></semantics></math><span class="ltx_text" id="S5.SS2.p7.7.8" style="font-size:90%;">. For MCA, we strictly require the model’s output to be one letter by prompt, any deviation is classified as </span><math alttext="`others^{\prime}" class="ltx_Math" display="inline" id="S5.SS2.p7.7.m7.1"><semantics id="S5.SS2.p7.7.m7.1a"><mrow id="S5.SS2.p7.7.m7.1.1" xref="S5.SS2.p7.7.m7.1.1.cmml"><mi id="S5.SS2.p7.7.m7.1.1.2" mathsize="90%" mathvariant="normal" xref="S5.SS2.p7.7.m7.1.1.2.cmml">`</mi><mo id="S5.SS2.p7.7.m7.1.1.1" xref="S5.SS2.p7.7.m7.1.1.1.cmml">⁢</mo><mi id="S5.SS2.p7.7.m7.1.1.3" mathsize="90%" xref="S5.SS2.p7.7.m7.1.1.3.cmml">o</mi><mo id="S5.SS2.p7.7.m7.1.1.1a" xref="S5.SS2.p7.7.m7.1.1.1.cmml">⁢</mo><mi id="S5.SS2.p7.7.m7.1.1.4" mathsize="90%" xref="S5.SS2.p7.7.m7.1.1.4.cmml">t</mi><mo id="S5.SS2.p7.7.m7.1.1.1b" xref="S5.SS2.p7.7.m7.1.1.1.cmml">⁢</mo><mi id="S5.SS2.p7.7.m7.1.1.5" mathsize="90%" xref="S5.SS2.p7.7.m7.1.1.5.cmml">h</mi><mo id="S5.SS2.p7.7.m7.1.1.1c" xref="S5.SS2.p7.7.m7.1.1.1.cmml">⁢</mo><mi id="S5.SS2.p7.7.m7.1.1.6" mathsize="90%" xref="S5.SS2.p7.7.m7.1.1.6.cmml">e</mi><mo id="S5.SS2.p7.7.m7.1.1.1d" xref="S5.SS2.p7.7.m7.1.1.1.cmml">⁢</mo><mi id="S5.SS2.p7.7.m7.1.1.7" mathsize="90%" xref="S5.SS2.p7.7.m7.1.1.7.cmml">r</mi><mo id="S5.SS2.p7.7.m7.1.1.1e" xref="S5.SS2.p7.7.m7.1.1.1.cmml">⁢</mo><msup id="S5.SS2.p7.7.m7.1.1.8" xref="S5.SS2.p7.7.m7.1.1.8.cmml"><mi id="S5.SS2.p7.7.m7.1.1.8.2" mathsize="90%" xref="S5.SS2.p7.7.m7.1.1.8.2.cmml">s</mi><mo id="S5.SS2.p7.7.m7.1.1.8.3" mathsize="90%" xref="S5.SS2.p7.7.m7.1.1.8.3.cmml">′</mo></msup></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.p7.7.m7.1b"><apply id="S5.SS2.p7.7.m7.1.1.cmml" xref="S5.SS2.p7.7.m7.1.1"><times id="S5.SS2.p7.7.m7.1.1.1.cmml" xref="S5.SS2.p7.7.m7.1.1.1"></times><ci id="S5.SS2.p7.7.m7.1.1.2.cmml" xref="S5.SS2.p7.7.m7.1.1.2">`</ci><ci id="S5.SS2.p7.7.m7.1.1.3.cmml" xref="S5.SS2.p7.7.m7.1.1.3">𝑜</ci><ci id="S5.SS2.p7.7.m7.1.1.4.cmml" xref="S5.SS2.p7.7.m7.1.1.4">𝑡</ci><ci id="S5.SS2.p7.7.m7.1.1.5.cmml" xref="S5.SS2.p7.7.m7.1.1.5">ℎ</ci><ci id="S5.SS2.p7.7.m7.1.1.6.cmml" xref="S5.SS2.p7.7.m7.1.1.6">𝑒</ci><ci id="S5.SS2.p7.7.m7.1.1.7.cmml" xref="S5.SS2.p7.7.m7.1.1.7">𝑟</ci><apply id="S5.SS2.p7.7.m7.1.1.8.cmml" xref="S5.SS2.p7.7.m7.1.1.8"><csymbol cd="ambiguous" id="S5.SS2.p7.7.m7.1.1.8.1.cmml" xref="S5.SS2.p7.7.m7.1.1.8">superscript</csymbol><ci id="S5.SS2.p7.7.m7.1.1.8.2.cmml" xref="S5.SS2.p7.7.m7.1.1.8.2">𝑠</ci><ci id="S5.SS2.p7.7.m7.1.1.8.3.cmml" xref="S5.SS2.p7.7.m7.1.1.8.3">′</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p7.7.m7.1c">`others^{\prime}</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p7.7.m7.1d">` italic_o italic_t italic_h italic_e italic_r italic_s start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text" id="S5.SS2.p7.7.9" style="font-size:90%;"> and considered a categorization error.</span></p>
</div>
<div class="ltx_para" id="S5.SS2.p8">
<p class="ltx_p" id="S5.SS2.p8.4"><span class="ltx_text ltx_font_italic" id="S5.SS2.p8.4.1" style="font-size:90%;">(2) WinRate:</span><span class="ltx_text" id="S5.SS2.p8.4.2" style="font-size:90%;"> This metric compares the quality of two different LLMs, i.e., one is the LLM to be evaluated, and the other is a competitor, using a powerful adjudicator model (such as GPT-4) </span><span class="ltx_note ltx_role_footnote" id="footnote11"><sup class="ltx_note_mark">11</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">11</sup><span class="ltx_tag ltx_tag_note">11</span>Detailed prompts for WinRate, can be found at <a class="ltx_ref ltx_href" href="https://github.com/XMUDM/DQABench" title="">[link]</a>.</span></span></span><span class="ltx_text" id="S5.SS2.p8.4.3" style="font-size:90%;">. In this study, we use the most common LLM, GPT-3.5, as the competitor for comparison. We calculate WinRate as follows:</span></p>
<table class="ltx_equation ltx_eqn_table" id="S5.E3">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_left">(3)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="WinRate=\frac{N_{r=1}}{N_{r=1}+N_{r=-1}},\quad\text{where}\left\{\begin{array}%
[]{ll}r=1&amp;\text{if }M\text{ wins},\\
r=0&amp;\text{if }M\text{ ties},\\
r=-1&amp;\text{if }M\text{ loses},\end{array}\right." class="ltx_Math" display="block" id="S5.E3.m1.5"><semantics id="S5.E3.m1.5a"><mrow id="S5.E3.m1.5.5" xref="S5.E3.m1.5.5.cmml"><mrow id="S5.E3.m1.5.5.3" xref="S5.E3.m1.5.5.3.cmml"><mi id="S5.E3.m1.5.5.3.2" mathsize="90%" xref="S5.E3.m1.5.5.3.2.cmml">W</mi><mo id="S5.E3.m1.5.5.3.1" xref="S5.E3.m1.5.5.3.1.cmml">⁢</mo><mi id="S5.E3.m1.5.5.3.3" mathsize="90%" xref="S5.E3.m1.5.5.3.3.cmml">i</mi><mo id="S5.E3.m1.5.5.3.1a" xref="S5.E3.m1.5.5.3.1.cmml">⁢</mo><mi id="S5.E3.m1.5.5.3.4" mathsize="90%" xref="S5.E3.m1.5.5.3.4.cmml">n</mi><mo id="S5.E3.m1.5.5.3.1b" xref="S5.E3.m1.5.5.3.1.cmml">⁢</mo><mi id="S5.E3.m1.5.5.3.5" mathsize="90%" xref="S5.E3.m1.5.5.3.5.cmml">R</mi><mo id="S5.E3.m1.5.5.3.1c" xref="S5.E3.m1.5.5.3.1.cmml">⁢</mo><mi id="S5.E3.m1.5.5.3.6" mathsize="90%" xref="S5.E3.m1.5.5.3.6.cmml">a</mi><mo id="S5.E3.m1.5.5.3.1d" xref="S5.E3.m1.5.5.3.1.cmml">⁢</mo><mi id="S5.E3.m1.5.5.3.7" mathsize="90%" xref="S5.E3.m1.5.5.3.7.cmml">t</mi><mo id="S5.E3.m1.5.5.3.1e" xref="S5.E3.m1.5.5.3.1.cmml">⁢</mo><mi id="S5.E3.m1.5.5.3.8" mathsize="90%" xref="S5.E3.m1.5.5.3.8.cmml">e</mi></mrow><mo id="S5.E3.m1.5.5.2" mathsize="90%" xref="S5.E3.m1.5.5.2.cmml">=</mo><mrow id="S5.E3.m1.5.5.1.1" xref="S5.E3.m1.5.5.1.2.cmml"><mfrac id="S5.E3.m1.4.4" xref="S5.E3.m1.4.4.cmml"><msub id="S5.E3.m1.4.4.2" xref="S5.E3.m1.4.4.2.cmml"><mi id="S5.E3.m1.4.4.2.2" mathsize="90%" xref="S5.E3.m1.4.4.2.2.cmml">N</mi><mrow id="S5.E3.m1.4.4.2.3" xref="S5.E3.m1.4.4.2.3.cmml"><mi id="S5.E3.m1.4.4.2.3.2" mathsize="90%" xref="S5.E3.m1.4.4.2.3.2.cmml">r</mi><mo id="S5.E3.m1.4.4.2.3.1" mathsize="90%" xref="S5.E3.m1.4.4.2.3.1.cmml">=</mo><mn id="S5.E3.m1.4.4.2.3.3" mathsize="90%" xref="S5.E3.m1.4.4.2.3.3.cmml">1</mn></mrow></msub><mrow id="S5.E3.m1.4.4.3" xref="S5.E3.m1.4.4.3.cmml"><msub id="S5.E3.m1.4.4.3.2" xref="S5.E3.m1.4.4.3.2.cmml"><mi id="S5.E3.m1.4.4.3.2.2" mathsize="90%" xref="S5.E3.m1.4.4.3.2.2.cmml">N</mi><mrow id="S5.E3.m1.4.4.3.2.3" xref="S5.E3.m1.4.4.3.2.3.cmml"><mi id="S5.E3.m1.4.4.3.2.3.2" mathsize="90%" xref="S5.E3.m1.4.4.3.2.3.2.cmml">r</mi><mo id="S5.E3.m1.4.4.3.2.3.1" mathsize="90%" xref="S5.E3.m1.4.4.3.2.3.1.cmml">=</mo><mn id="S5.E3.m1.4.4.3.2.3.3" mathsize="90%" xref="S5.E3.m1.4.4.3.2.3.3.cmml">1</mn></mrow></msub><mo id="S5.E3.m1.4.4.3.1" mathsize="90%" xref="S5.E3.m1.4.4.3.1.cmml">+</mo><msub id="S5.E3.m1.4.4.3.3" xref="S5.E3.m1.4.4.3.3.cmml"><mi id="S5.E3.m1.4.4.3.3.2" mathsize="90%" xref="S5.E3.m1.4.4.3.3.2.cmml">N</mi><mrow id="S5.E3.m1.4.4.3.3.3" xref="S5.E3.m1.4.4.3.3.3.cmml"><mi id="S5.E3.m1.4.4.3.3.3.2" mathsize="90%" xref="S5.E3.m1.4.4.3.3.3.2.cmml">r</mi><mo id="S5.E3.m1.4.4.3.3.3.1" mathsize="90%" xref="S5.E3.m1.4.4.3.3.3.1.cmml">=</mo><mrow id="S5.E3.m1.4.4.3.3.3.3" xref="S5.E3.m1.4.4.3.3.3.3.cmml"><mo id="S5.E3.m1.4.4.3.3.3.3a" mathsize="90%" xref="S5.E3.m1.4.4.3.3.3.3.cmml">−</mo><mn id="S5.E3.m1.4.4.3.3.3.3.2" mathsize="90%" xref="S5.E3.m1.4.4.3.3.3.3.2.cmml">1</mn></mrow></mrow></msub></mrow></mfrac><mo id="S5.E3.m1.5.5.1.1.2" mathsize="90%" rspace="1.067em" xref="S5.E3.m1.5.5.1.2.cmml">,</mo><mrow id="S5.E3.m1.5.5.1.1.1" xref="S5.E3.m1.5.5.1.1.1.cmml"><mtext id="S5.E3.m1.5.5.1.1.1.2" mathsize="90%" xref="S5.E3.m1.5.5.1.1.1.2a.cmml">where</mtext><mo id="S5.E3.m1.5.5.1.1.1.1" xref="S5.E3.m1.5.5.1.1.1.1.cmml">⁢</mo><mrow id="S5.E3.m1.5.5.1.1.1.3.2" xref="S5.E3.m1.5.5.1.1.1.3.1.cmml"><mo id="S5.E3.m1.5.5.1.1.1.3.2.1" xref="S5.E3.m1.5.5.1.1.1.3.1.1.cmml">{</mo><mtable columnspacing="5pt" displaystyle="true" id="S5.E3.m1.3.3" rowspacing="0pt" xref="S5.E3.m1.3.3.cmml"><mtr id="S5.E3.m1.3.3a" xref="S5.E3.m1.3.3.cmml"><mtd class="ltx_align_left" columnalign="left" id="S5.E3.m1.3.3b" xref="S5.E3.m1.3.3.cmml"><mrow id="S5.E3.m1.1.1.1.2.1" xref="S5.E3.m1.1.1.1.2.1.cmml"><mi id="S5.E3.m1.1.1.1.2.1.2" mathsize="90%" xref="S5.E3.m1.1.1.1.2.1.2.cmml">r</mi><mo id="S5.E3.m1.1.1.1.2.1.1" mathsize="90%" xref="S5.E3.m1.1.1.1.2.1.1.cmml">=</mo><mn id="S5.E3.m1.1.1.1.2.1.3" mathsize="90%" xref="S5.E3.m1.1.1.1.2.1.3.cmml">1</mn></mrow></mtd><mtd class="ltx_align_left" columnalign="left" id="S5.E3.m1.3.3c" xref="S5.E3.m1.3.3.cmml"><mrow id="S5.E3.m1.1.1.1.1.1.1" xref="S5.E3.m1.1.1.1.1.1.1.1.cmml"><mrow id="S5.E3.m1.1.1.1.1.1.1.1" xref="S5.E3.m1.1.1.1.1.1.1.1.cmml"><mtext id="S5.E3.m1.1.1.1.1.1.1.1.2" mathsize="90%" xref="S5.E3.m1.1.1.1.1.1.1.1.2a.cmml">if </mtext><mo id="S5.E3.m1.1.1.1.1.1.1.1.1" xref="S5.E3.m1.1.1.1.1.1.1.1.1.cmml">⁢</mo><mi id="S5.E3.m1.1.1.1.1.1.1.1.3" mathsize="90%" xref="S5.E3.m1.1.1.1.1.1.1.1.3.cmml">M</mi><mo id="S5.E3.m1.1.1.1.1.1.1.1.1a" xref="S5.E3.m1.1.1.1.1.1.1.1.1.cmml">⁢</mo><mtext id="S5.E3.m1.1.1.1.1.1.1.1.4" mathsize="90%" xref="S5.E3.m1.1.1.1.1.1.1.1.4a.cmml"> wins</mtext></mrow><mo id="S5.E3.m1.1.1.1.1.1.1.2" mathsize="90%" xref="S5.E3.m1.1.1.1.1.1.1.1.cmml">,</mo></mrow></mtd></mtr><mtr id="S5.E3.m1.3.3d" xref="S5.E3.m1.3.3.cmml"><mtd class="ltx_align_left" columnalign="left" id="S5.E3.m1.3.3e" xref="S5.E3.m1.3.3.cmml"><mrow id="S5.E3.m1.2.2.2.2.1" xref="S5.E3.m1.2.2.2.2.1.cmml"><mi id="S5.E3.m1.2.2.2.2.1.2" mathsize="90%" xref="S5.E3.m1.2.2.2.2.1.2.cmml">r</mi><mo id="S5.E3.m1.2.2.2.2.1.1" mathsize="90%" xref="S5.E3.m1.2.2.2.2.1.1.cmml">=</mo><mn id="S5.E3.m1.2.2.2.2.1.3" mathsize="90%" xref="S5.E3.m1.2.2.2.2.1.3.cmml">0</mn></mrow></mtd><mtd class="ltx_align_left" columnalign="left" id="S5.E3.m1.3.3f" xref="S5.E3.m1.3.3.cmml"><mrow id="S5.E3.m1.2.2.2.1.1.1" xref="S5.E3.m1.2.2.2.1.1.1.1.cmml"><mrow id="S5.E3.m1.2.2.2.1.1.1.1" xref="S5.E3.m1.2.2.2.1.1.1.1.cmml"><mtext id="S5.E3.m1.2.2.2.1.1.1.1.2" mathsize="90%" xref="S5.E3.m1.2.2.2.1.1.1.1.2a.cmml">if </mtext><mo id="S5.E3.m1.2.2.2.1.1.1.1.1" xref="S5.E3.m1.2.2.2.1.1.1.1.1.cmml">⁢</mo><mi id="S5.E3.m1.2.2.2.1.1.1.1.3" mathsize="90%" xref="S5.E3.m1.2.2.2.1.1.1.1.3.cmml">M</mi><mo id="S5.E3.m1.2.2.2.1.1.1.1.1a" xref="S5.E3.m1.2.2.2.1.1.1.1.1.cmml">⁢</mo><mtext id="S5.E3.m1.2.2.2.1.1.1.1.4" mathsize="90%" xref="S5.E3.m1.2.2.2.1.1.1.1.4a.cmml"> ties</mtext></mrow><mo id="S5.E3.m1.2.2.2.1.1.1.2" mathsize="90%" xref="S5.E3.m1.2.2.2.1.1.1.1.cmml">,</mo></mrow></mtd></mtr><mtr id="S5.E3.m1.3.3g" xref="S5.E3.m1.3.3.cmml"><mtd class="ltx_align_left" columnalign="left" id="S5.E3.m1.3.3h" xref="S5.E3.m1.3.3.cmml"><mrow id="S5.E3.m1.3.3.3.2.1" xref="S5.E3.m1.3.3.3.2.1.cmml"><mi id="S5.E3.m1.3.3.3.2.1.2" mathsize="90%" xref="S5.E3.m1.3.3.3.2.1.2.cmml">r</mi><mo id="S5.E3.m1.3.3.3.2.1.1" mathsize="90%" xref="S5.E3.m1.3.3.3.2.1.1.cmml">=</mo><mrow id="S5.E3.m1.3.3.3.2.1.3" xref="S5.E3.m1.3.3.3.2.1.3.cmml"><mo id="S5.E3.m1.3.3.3.2.1.3a" mathsize="90%" xref="S5.E3.m1.3.3.3.2.1.3.cmml">−</mo><mn id="S5.E3.m1.3.3.3.2.1.3.2" mathsize="90%" xref="S5.E3.m1.3.3.3.2.1.3.2.cmml">1</mn></mrow></mrow></mtd><mtd class="ltx_align_left" columnalign="left" id="S5.E3.m1.3.3i" xref="S5.E3.m1.3.3.cmml"><mrow id="S5.E3.m1.3.3.3.1.1.1" xref="S5.E3.m1.3.3.3.1.1.1.1.cmml"><mrow id="S5.E3.m1.3.3.3.1.1.1.1" xref="S5.E3.m1.3.3.3.1.1.1.1.cmml"><mtext id="S5.E3.m1.3.3.3.1.1.1.1.2" mathsize="90%" xref="S5.E3.m1.3.3.3.1.1.1.1.2a.cmml">if </mtext><mo id="S5.E3.m1.3.3.3.1.1.1.1.1" xref="S5.E3.m1.3.3.3.1.1.1.1.1.cmml">⁢</mo><mi id="S5.E3.m1.3.3.3.1.1.1.1.3" mathsize="90%" xref="S5.E3.m1.3.3.3.1.1.1.1.3.cmml">M</mi><mo id="S5.E3.m1.3.3.3.1.1.1.1.1a" xref="S5.E3.m1.3.3.3.1.1.1.1.1.cmml">⁢</mo><mtext id="S5.E3.m1.3.3.3.1.1.1.1.4" mathsize="90%" xref="S5.E3.m1.3.3.3.1.1.1.1.4a.cmml"> loses</mtext></mrow><mo id="S5.E3.m1.3.3.3.1.1.1.2" mathsize="90%" xref="S5.E3.m1.3.3.3.1.1.1.1.cmml">,</mo></mrow></mtd></mtr></mtable><mi id="S5.E3.m1.5.5.1.1.1.3.2.2" xref="S5.E3.m1.5.5.1.1.1.3.1.1.cmml"></mi></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.E3.m1.5b"><apply id="S5.E3.m1.5.5.cmml" xref="S5.E3.m1.5.5"><eq id="S5.E3.m1.5.5.2.cmml" xref="S5.E3.m1.5.5.2"></eq><apply id="S5.E3.m1.5.5.3.cmml" xref="S5.E3.m1.5.5.3"><times id="S5.E3.m1.5.5.3.1.cmml" xref="S5.E3.m1.5.5.3.1"></times><ci id="S5.E3.m1.5.5.3.2.cmml" xref="S5.E3.m1.5.5.3.2">𝑊</ci><ci id="S5.E3.m1.5.5.3.3.cmml" xref="S5.E3.m1.5.5.3.3">𝑖</ci><ci id="S5.E3.m1.5.5.3.4.cmml" xref="S5.E3.m1.5.5.3.4">𝑛</ci><ci id="S5.E3.m1.5.5.3.5.cmml" xref="S5.E3.m1.5.5.3.5">𝑅</ci><ci id="S5.E3.m1.5.5.3.6.cmml" xref="S5.E3.m1.5.5.3.6">𝑎</ci><ci id="S5.E3.m1.5.5.3.7.cmml" xref="S5.E3.m1.5.5.3.7">𝑡</ci><ci id="S5.E3.m1.5.5.3.8.cmml" xref="S5.E3.m1.5.5.3.8">𝑒</ci></apply><list id="S5.E3.m1.5.5.1.2.cmml" xref="S5.E3.m1.5.5.1.1"><apply id="S5.E3.m1.4.4.cmml" xref="S5.E3.m1.4.4"><divide id="S5.E3.m1.4.4.1.cmml" xref="S5.E3.m1.4.4"></divide><apply id="S5.E3.m1.4.4.2.cmml" xref="S5.E3.m1.4.4.2"><csymbol cd="ambiguous" id="S5.E3.m1.4.4.2.1.cmml" xref="S5.E3.m1.4.4.2">subscript</csymbol><ci id="S5.E3.m1.4.4.2.2.cmml" xref="S5.E3.m1.4.4.2.2">𝑁</ci><apply id="S5.E3.m1.4.4.2.3.cmml" xref="S5.E3.m1.4.4.2.3"><eq id="S5.E3.m1.4.4.2.3.1.cmml" xref="S5.E3.m1.4.4.2.3.1"></eq><ci id="S5.E3.m1.4.4.2.3.2.cmml" xref="S5.E3.m1.4.4.2.3.2">𝑟</ci><cn id="S5.E3.m1.4.4.2.3.3.cmml" type="integer" xref="S5.E3.m1.4.4.2.3.3">1</cn></apply></apply><apply id="S5.E3.m1.4.4.3.cmml" xref="S5.E3.m1.4.4.3"><plus id="S5.E3.m1.4.4.3.1.cmml" xref="S5.E3.m1.4.4.3.1"></plus><apply id="S5.E3.m1.4.4.3.2.cmml" xref="S5.E3.m1.4.4.3.2"><csymbol cd="ambiguous" id="S5.E3.m1.4.4.3.2.1.cmml" xref="S5.E3.m1.4.4.3.2">subscript</csymbol><ci id="S5.E3.m1.4.4.3.2.2.cmml" xref="S5.E3.m1.4.4.3.2.2">𝑁</ci><apply id="S5.E3.m1.4.4.3.2.3.cmml" xref="S5.E3.m1.4.4.3.2.3"><eq id="S5.E3.m1.4.4.3.2.3.1.cmml" xref="S5.E3.m1.4.4.3.2.3.1"></eq><ci id="S5.E3.m1.4.4.3.2.3.2.cmml" xref="S5.E3.m1.4.4.3.2.3.2">𝑟</ci><cn id="S5.E3.m1.4.4.3.2.3.3.cmml" type="integer" xref="S5.E3.m1.4.4.3.2.3.3">1</cn></apply></apply><apply id="S5.E3.m1.4.4.3.3.cmml" xref="S5.E3.m1.4.4.3.3"><csymbol cd="ambiguous" id="S5.E3.m1.4.4.3.3.1.cmml" xref="S5.E3.m1.4.4.3.3">subscript</csymbol><ci id="S5.E3.m1.4.4.3.3.2.cmml" xref="S5.E3.m1.4.4.3.3.2">𝑁</ci><apply id="S5.E3.m1.4.4.3.3.3.cmml" xref="S5.E3.m1.4.4.3.3.3"><eq id="S5.E3.m1.4.4.3.3.3.1.cmml" xref="S5.E3.m1.4.4.3.3.3.1"></eq><ci id="S5.E3.m1.4.4.3.3.3.2.cmml" xref="S5.E3.m1.4.4.3.3.3.2">𝑟</ci><apply id="S5.E3.m1.4.4.3.3.3.3.cmml" xref="S5.E3.m1.4.4.3.3.3.3"><minus id="S5.E3.m1.4.4.3.3.3.3.1.cmml" xref="S5.E3.m1.4.4.3.3.3.3"></minus><cn id="S5.E3.m1.4.4.3.3.3.3.2.cmml" type="integer" xref="S5.E3.m1.4.4.3.3.3.3.2">1</cn></apply></apply></apply></apply></apply><apply id="S5.E3.m1.5.5.1.1.1.cmml" xref="S5.E3.m1.5.5.1.1.1"><times id="S5.E3.m1.5.5.1.1.1.1.cmml" xref="S5.E3.m1.5.5.1.1.1.1"></times><ci id="S5.E3.m1.5.5.1.1.1.2a.cmml" xref="S5.E3.m1.5.5.1.1.1.2"><mtext id="S5.E3.m1.5.5.1.1.1.2.cmml" mathsize="90%" xref="S5.E3.m1.5.5.1.1.1.2">where</mtext></ci><apply id="S5.E3.m1.5.5.1.1.1.3.1.cmml" xref="S5.E3.m1.5.5.1.1.1.3.2"><csymbol cd="latexml" id="S5.E3.m1.5.5.1.1.1.3.1.1.cmml" xref="S5.E3.m1.5.5.1.1.1.3.2.1">cases</csymbol><matrix id="S5.E3.m1.3.3.cmml" xref="S5.E3.m1.3.3"><matrixrow id="S5.E3.m1.3.3a.cmml" xref="S5.E3.m1.3.3"><apply id="S5.E3.m1.1.1.1.2.1.cmml" xref="S5.E3.m1.1.1.1.2.1"><eq id="S5.E3.m1.1.1.1.2.1.1.cmml" xref="S5.E3.m1.1.1.1.2.1.1"></eq><ci id="S5.E3.m1.1.1.1.2.1.2.cmml" xref="S5.E3.m1.1.1.1.2.1.2">𝑟</ci><cn id="S5.E3.m1.1.1.1.2.1.3.cmml" type="integer" xref="S5.E3.m1.1.1.1.2.1.3">1</cn></apply><apply id="S5.E3.m1.1.1.1.1.1.1.1.cmml" xref="S5.E3.m1.1.1.1.1.1.1"><times id="S5.E3.m1.1.1.1.1.1.1.1.1.cmml" xref="S5.E3.m1.1.1.1.1.1.1.1.1"></times><ci id="S5.E3.m1.1.1.1.1.1.1.1.2a.cmml" xref="S5.E3.m1.1.1.1.1.1.1.1.2"><mtext id="S5.E3.m1.1.1.1.1.1.1.1.2.cmml" mathsize="90%" xref="S5.E3.m1.1.1.1.1.1.1.1.2">if </mtext></ci><ci id="S5.E3.m1.1.1.1.1.1.1.1.3.cmml" xref="S5.E3.m1.1.1.1.1.1.1.1.3">𝑀</ci><ci id="S5.E3.m1.1.1.1.1.1.1.1.4a.cmml" xref="S5.E3.m1.1.1.1.1.1.1.1.4"><mtext id="S5.E3.m1.1.1.1.1.1.1.1.4.cmml" mathsize="90%" xref="S5.E3.m1.1.1.1.1.1.1.1.4"> wins</mtext></ci></apply></matrixrow><matrixrow id="S5.E3.m1.3.3b.cmml" xref="S5.E3.m1.3.3"><apply id="S5.E3.m1.2.2.2.2.1.cmml" xref="S5.E3.m1.2.2.2.2.1"><eq id="S5.E3.m1.2.2.2.2.1.1.cmml" xref="S5.E3.m1.2.2.2.2.1.1"></eq><ci id="S5.E3.m1.2.2.2.2.1.2.cmml" xref="S5.E3.m1.2.2.2.2.1.2">𝑟</ci><cn id="S5.E3.m1.2.2.2.2.1.3.cmml" type="integer" xref="S5.E3.m1.2.2.2.2.1.3">0</cn></apply><apply id="S5.E3.m1.2.2.2.1.1.1.1.cmml" xref="S5.E3.m1.2.2.2.1.1.1"><times id="S5.E3.m1.2.2.2.1.1.1.1.1.cmml" xref="S5.E3.m1.2.2.2.1.1.1.1.1"></times><ci id="S5.E3.m1.2.2.2.1.1.1.1.2a.cmml" xref="S5.E3.m1.2.2.2.1.1.1.1.2"><mtext id="S5.E3.m1.2.2.2.1.1.1.1.2.cmml" mathsize="90%" xref="S5.E3.m1.2.2.2.1.1.1.1.2">if </mtext></ci><ci id="S5.E3.m1.2.2.2.1.1.1.1.3.cmml" xref="S5.E3.m1.2.2.2.1.1.1.1.3">𝑀</ci><ci id="S5.E3.m1.2.2.2.1.1.1.1.4a.cmml" xref="S5.E3.m1.2.2.2.1.1.1.1.4"><mtext id="S5.E3.m1.2.2.2.1.1.1.1.4.cmml" mathsize="90%" xref="S5.E3.m1.2.2.2.1.1.1.1.4"> ties</mtext></ci></apply></matrixrow><matrixrow id="S5.E3.m1.3.3c.cmml" xref="S5.E3.m1.3.3"><apply id="S5.E3.m1.3.3.3.2.1.cmml" xref="S5.E3.m1.3.3.3.2.1"><eq id="S5.E3.m1.3.3.3.2.1.1.cmml" xref="S5.E3.m1.3.3.3.2.1.1"></eq><ci id="S5.E3.m1.3.3.3.2.1.2.cmml" xref="S5.E3.m1.3.3.3.2.1.2">𝑟</ci><apply id="S5.E3.m1.3.3.3.2.1.3.cmml" xref="S5.E3.m1.3.3.3.2.1.3"><minus id="S5.E3.m1.3.3.3.2.1.3.1.cmml" xref="S5.E3.m1.3.3.3.2.1.3"></minus><cn id="S5.E3.m1.3.3.3.2.1.3.2.cmml" type="integer" xref="S5.E3.m1.3.3.3.2.1.3.2">1</cn></apply></apply><apply id="S5.E3.m1.3.3.3.1.1.1.1.cmml" xref="S5.E3.m1.3.3.3.1.1.1"><times id="S5.E3.m1.3.3.3.1.1.1.1.1.cmml" xref="S5.E3.m1.3.3.3.1.1.1.1.1"></times><ci id="S5.E3.m1.3.3.3.1.1.1.1.2a.cmml" xref="S5.E3.m1.3.3.3.1.1.1.1.2"><mtext id="S5.E3.m1.3.3.3.1.1.1.1.2.cmml" mathsize="90%" xref="S5.E3.m1.3.3.3.1.1.1.1.2">if </mtext></ci><ci id="S5.E3.m1.3.3.3.1.1.1.1.3.cmml" xref="S5.E3.m1.3.3.3.1.1.1.1.3">𝑀</ci><ci id="S5.E3.m1.3.3.3.1.1.1.1.4a.cmml" xref="S5.E3.m1.3.3.3.1.1.1.1.4"><mtext id="S5.E3.m1.3.3.3.1.1.1.1.4.cmml" mathsize="90%" xref="S5.E3.m1.3.3.3.1.1.1.1.4"> loses</mtext></ci></apply></matrixrow></matrix></apply></apply></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.E3.m1.5c">WinRate=\frac{N_{r=1}}{N_{r=1}+N_{r=-1}},\quad\text{where}\left\{\begin{array}%
[]{ll}r=1&amp;\text{if }M\text{ wins},\\
r=0&amp;\text{if }M\text{ ties},\\
r=-1&amp;\text{if }M\text{ loses},\end{array}\right.</annotation><annotation encoding="application/x-llamapun" id="S5.E3.m1.5d">italic_W italic_i italic_n italic_R italic_a italic_t italic_e = divide start_ARG italic_N start_POSTSUBSCRIPT italic_r = 1 end_POSTSUBSCRIPT end_ARG start_ARG italic_N start_POSTSUBSCRIPT italic_r = 1 end_POSTSUBSCRIPT + italic_N start_POSTSUBSCRIPT italic_r = - 1 end_POSTSUBSCRIPT end_ARG , where { start_ARRAY start_ROW start_CELL italic_r = 1 end_CELL start_CELL if italic_M wins , end_CELL end_ROW start_ROW start_CELL italic_r = 0 end_CELL start_CELL if italic_M ties , end_CELL end_ROW start_ROW start_CELL italic_r = - 1 end_CELL start_CELL if italic_M loses , end_CELL end_ROW end_ARRAY</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S5.SS2.p8.3"><span class="ltx_text" id="S5.SS2.p8.3.1" style="font-size:90%;">where </span><math alttext="N_{r}" class="ltx_Math" display="inline" id="S5.SS2.p8.1.m1.1"><semantics id="S5.SS2.p8.1.m1.1a"><msub id="S5.SS2.p8.1.m1.1.1" xref="S5.SS2.p8.1.m1.1.1.cmml"><mi id="S5.SS2.p8.1.m1.1.1.2" mathsize="90%" xref="S5.SS2.p8.1.m1.1.1.2.cmml">N</mi><mi id="S5.SS2.p8.1.m1.1.1.3" mathsize="90%" xref="S5.SS2.p8.1.m1.1.1.3.cmml">r</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS2.p8.1.m1.1b"><apply id="S5.SS2.p8.1.m1.1.1.cmml" xref="S5.SS2.p8.1.m1.1.1"><csymbol cd="ambiguous" id="S5.SS2.p8.1.m1.1.1.1.cmml" xref="S5.SS2.p8.1.m1.1.1">subscript</csymbol><ci id="S5.SS2.p8.1.m1.1.1.2.cmml" xref="S5.SS2.p8.1.m1.1.1.2">𝑁</ci><ci id="S5.SS2.p8.1.m1.1.1.3.cmml" xref="S5.SS2.p8.1.m1.1.1.3">𝑟</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p8.1.m1.1c">N_{r}</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p8.1.m1.1d">italic_N start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="S5.SS2.p8.3.2" style="font-size:90%;"> represents the number of comparisons where the judge GPT-4 considers case </span><math alttext="r" class="ltx_Math" display="inline" id="S5.SS2.p8.2.m2.1"><semantics id="S5.SS2.p8.2.m2.1a"><mi id="S5.SS2.p8.2.m2.1.1" mathsize="90%" xref="S5.SS2.p8.2.m2.1.1.cmml">r</mi><annotation-xml encoding="MathML-Content" id="S5.SS2.p8.2.m2.1b"><ci id="S5.SS2.p8.2.m2.1.1.cmml" xref="S5.SS2.p8.2.m2.1.1">𝑟</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p8.2.m2.1c">r</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p8.2.m2.1d">italic_r</annotation></semantics></math><span class="ltx_text" id="S5.SS2.p8.3.3" style="font-size:90%;">, and </span><math alttext="M" class="ltx_Math" display="inline" id="S5.SS2.p8.3.m3.1"><semantics id="S5.SS2.p8.3.m3.1a"><mi id="S5.SS2.p8.3.m3.1.1" mathsize="90%" xref="S5.SS2.p8.3.m3.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S5.SS2.p8.3.m3.1b"><ci id="S5.SS2.p8.3.m3.1.1.cmml" xref="S5.SS2.p8.3.m3.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p8.3.m3.1c">M</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p8.3.m3.1d">italic_M</annotation></semantics></math><span class="ltx_text" id="S5.SS2.p8.3.4" style="font-size:90%;"> is the model to be evaluated. We meticulously designed the judge’s prompt so that it uses the answer provided by </span><span class="ltx_text ltx_font_bold ltx_font_italic" id="S5.SS2.p8.3.5" style="font-size:90%;">DQA</span><span class="ltx_text" id="S5.SS2.p8.3.6" style="font-size:90%;"> as the ground truth and deems any response that contradicts the facts as a loser.</span></p>
</div>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section" style="font-size:90%;">
<span class="ltx_tag ltx_tag_section">6. </span>Experiment</h2>
<figure class="ltx_table" id="S6.T5">
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 5. </span>WinRate of different LLMs versus the competitor</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S6.T5.13" style="width:416.3pt;height:526.4pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(23.1pt,-29.2pt) scale(1.12469354686839,1.12469354686839) ;">
<table class="ltx_tabular ltx_align_middle" id="S6.T5.13.13">
<tr class="ltx_tr" id="S6.T5.1.1.1">
<td class="ltx_td ltx_align_left ltx_border_tt" id="S6.T5.1.1.1.2" rowspan="2" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text ltx_font_bold" id="S6.T5.1.1.1.2.1" style="font-size:90%;">Model</span></td>
<td class="ltx_td ltx_align_right ltx_border_tt" id="S6.T5.1.1.1.1" rowspan="2" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.1.1.1.1.1" style="font-size:90%;"><math alttext="|\boldsymbol{\theta}|" class="ltx_Math" display="inline" id="S6.T5.1.1.1.1.1.m1.1"><semantics id="S6.T5.1.1.1.1.1.m1.1a"><mrow id="S6.T5.1.1.1.1.1.m1.1.2.2" xref="S6.T5.1.1.1.1.1.m1.1.2.1.cmml"><mo id="S6.T5.1.1.1.1.1.m1.1.2.2.1" stretchy="false" xref="S6.T5.1.1.1.1.1.m1.1.2.1.1.cmml">|</mo><mi id="S6.T5.1.1.1.1.1.m1.1.1" xref="S6.T5.1.1.1.1.1.m1.1.1.cmml">𝜽</mi><mo id="S6.T5.1.1.1.1.1.m1.1.2.2.2" stretchy="false" xref="S6.T5.1.1.1.1.1.m1.1.2.1.1.cmml">|</mo></mrow><annotation-xml encoding="MathML-Content" id="S6.T5.1.1.1.1.1.m1.1b"><apply id="S6.T5.1.1.1.1.1.m1.1.2.1.cmml" xref="S6.T5.1.1.1.1.1.m1.1.2.2"><abs id="S6.T5.1.1.1.1.1.m1.1.2.1.1.cmml" xref="S6.T5.1.1.1.1.1.m1.1.2.2.1"></abs><ci id="S6.T5.1.1.1.1.1.m1.1.1.cmml" xref="S6.T5.1.1.1.1.1.m1.1.1">𝜽</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.T5.1.1.1.1.1.m1.1c">|\boldsymbol{\theta}|</annotation><annotation encoding="application/x-llamapun" id="S6.T5.1.1.1.1.1.m1.1d">| bold_italic_θ |</annotation></semantics></math></span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_tt" id="S6.T5.1.1.1.3" rowspan="2" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text ltx_font_bold" id="S6.T5.1.1.1.3.1" style="font-size:90%;">Deployment</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="2" id="S6.T5.1.1.1.4" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text ltx_font_bold" id="S6.T5.1.1.1.4.1" style="font-size:90%;">DB General</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="2" id="S6.T5.1.1.1.5" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text ltx_font_bold" id="S6.T5.1.1.1.5.1" style="font-size:90%;">Product-specific</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="2" id="S6.T5.1.1.1.6" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text ltx_font_bold" id="S6.T5.1.1.1.6.1" style="font-size:90%;">Instance-specific</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="S6.T5.1.1.1.7" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text ltx_font_bold" id="S6.T5.1.1.1.7.1" style="font-size:90%;">Average</span></td>
</tr>
<tr class="ltx_tr" id="S6.T5.13.13.14">
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T5.13.13.14.1" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.13.13.14.1.1" style="font-size:90%;">ZH</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S6.T5.13.13.14.2" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.13.13.14.2.1" style="font-size:90%;">EN</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T5.13.13.14.3" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.13.13.14.3.1" style="font-size:90%;">ZH</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S6.T5.13.13.14.4" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.13.13.14.4.1" style="font-size:90%;">EN</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T5.13.13.14.5" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.13.13.14.5.1" style="font-size:90%;">ZH</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S6.T5.13.13.14.6" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.13.13.14.6.1" style="font-size:90%;">EN</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T5.13.13.14.7" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.13.13.14.7.1" style="font-size:90%;">ZH</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T5.13.13.14.8" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.13.13.14.8.1" style="font-size:90%;">EN</span></td>
</tr>
<tr class="ltx_tr" id="S6.T5.13.13.15">
<td class="ltx_td ltx_align_center ltx_border_t" colspan="10" id="S6.T5.13.13.15.1" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text ltx_font_typewriter" id="S6.T5.13.13.15.1.1" style="font-size:90%;">WinRate v.s. Vanilla GPT-3.5-Turbo</span></td>
<td class="ltx_td ltx_border_t" id="S6.T5.13.13.15.2" style="padding-left:2.0pt;padding-right:2.0pt;"></td>
</tr>
<tr class="ltx_tr" id="S6.T5.13.13.16">
<td class="ltx_td ltx_align_left ltx_border_t" id="S6.T5.13.13.16.1" style="padding-left:2.0pt;padding-right:2.0pt;"><a class="ltx_ref ltx_href" href="https://platform.openai.com/docs/models/gpt-4-turbo-and-gpt-4" style="font-size:90%;" title="">GPT-4</a></td>
<td class="ltx_td ltx_border_t" id="S6.T5.13.13.16.2" style="padding-left:2.0pt;padding-right:2.0pt;"></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S6.T5.13.13.16.3" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.13.13.16.3.1" style="font-size:90%;">Centralized</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T5.13.13.16.4" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.13.13.16.4.1" style="font-size:90%;color:#BF0040;">0.85</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S6.T5.13.13.16.5" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.13.13.16.5.1" style="font-size:90%;color:#BF0040;">0.95</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T5.13.13.16.6" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.13.13.16.6.1" style="font-size:90%;">0.86</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S6.T5.13.13.16.7" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.13.13.16.7.1" style="font-size:90%;color:#BF0040;">0.86</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T5.13.13.16.8" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.13.13.16.8.1" style="font-size:90%;">0.69</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S6.T5.13.13.16.9" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.13.13.16.9.1" style="font-size:90%;">0.53</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T5.13.13.16.10" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text ltx_font_bold" id="S6.T5.13.13.16.10.1" style="font-size:90%;color:#BF0040;">0.80</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T5.13.13.16.11" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text ltx_font_bold" id="S6.T5.13.13.16.11.1" style="font-size:90%;color:#BF0040;">0.78</span></td>
</tr>
<tr class="ltx_tr" id="S6.T5.13.13.17">
<td class="ltx_td ltx_align_left" id="S6.T5.13.13.17.1" style="padding-left:2.0pt;padding-right:2.0pt;"><a class="ltx_ref ltx_href" href="https://platform.openai.com/docs/models/gpt-3-5-turbo" style="font-size:90%;" title="">GPT-3.5-Turbo</a></td>
<td class="ltx_td" id="S6.T5.13.13.17.2" style="padding-left:2.0pt;padding-right:2.0pt;"></td>
<td class="ltx_td ltx_align_right ltx_border_r" id="S6.T5.13.13.17.3" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.13.13.17.3.1" style="font-size:90%;">Centralized</span></td>
<td class="ltx_td ltx_align_center" id="S6.T5.13.13.17.4" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.13.13.17.4.1" style="font-size:90%;">0.53</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T5.13.13.17.5" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.13.13.17.5.1" style="font-size:90%;">0.56</span></td>
<td class="ltx_td ltx_align_center" id="S6.T5.13.13.17.6" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.13.13.17.6.1" style="font-size:90%;">0.60</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T5.13.13.17.7" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.13.13.17.7.1" style="font-size:90%;">0.60</span></td>
<td class="ltx_td ltx_align_center" id="S6.T5.13.13.17.8" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.13.13.17.8.1" style="font-size:90%;">0.58</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T5.13.13.17.9" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.13.13.17.9.1" style="font-size:90%;">0.57</span></td>
<td class="ltx_td ltx_align_center" id="S6.T5.13.13.17.10" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text ltx_font_bold" id="S6.T5.13.13.17.10.1" style="font-size:90%;">0.57</span></td>
<td class="ltx_td ltx_align_center" id="S6.T5.13.13.17.11" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text ltx_font_bold" id="S6.T5.13.13.17.11.1" style="font-size:90%;">0.58</span></td>
</tr>
<tr class="ltx_tr" id="S6.T5.13.13.18">
<td class="ltx_td ltx_align_left" id="S6.T5.13.13.18.1" style="padding-left:2.0pt;padding-right:2.0pt;"><a class="ltx_ref ltx_href" href="https://chatglm.cn/main/detail" style="font-size:90%;" title="">GLM-3-Turbo</a></td>
<td class="ltx_td" id="S6.T5.13.13.18.2" style="padding-left:2.0pt;padding-right:2.0pt;"></td>
<td class="ltx_td ltx_align_right ltx_border_r" id="S6.T5.13.13.18.3" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.13.13.18.3.1" style="font-size:90%;">Centralized</span></td>
<td class="ltx_td ltx_align_center" id="S6.T5.13.13.18.4" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.13.13.18.4.1" style="font-size:90%;">0.63</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T5.13.13.18.5" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.13.13.18.5.1" style="font-size:90%;">0.62</span></td>
<td class="ltx_td ltx_align_center" id="S6.T5.13.13.18.6" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.13.13.18.6.1" style="font-size:90%;">0.81</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T5.13.13.18.7" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.13.13.18.7.1" style="font-size:90%;">0.58</span></td>
<td class="ltx_td ltx_align_center" id="S6.T5.13.13.18.8" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.13.13.18.8.1" style="font-size:90%;">0.44</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T5.13.13.18.9" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.13.13.18.9.1" style="font-size:90%;">0.44</span></td>
<td class="ltx_td ltx_align_center" id="S6.T5.13.13.18.10" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text ltx_font_bold" id="S6.T5.13.13.18.10.1" style="font-size:90%;">0.63</span></td>
<td class="ltx_td ltx_align_center" id="S6.T5.13.13.18.11" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text ltx_font_bold" id="S6.T5.13.13.18.11.1" style="font-size:90%;">0.55</span></td>
</tr>
<tr class="ltx_tr" id="S6.T5.2.2.2">
<td class="ltx_td ltx_align_left" id="S6.T5.2.2.2.2" style="padding-left:2.0pt;padding-right:2.0pt;"><a class="ltx_ref ltx_href" href="https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct" style="font-size:90%;" title="">Llama3</a></td>
<td class="ltx_td ltx_align_right" id="S6.T5.2.2.2.3" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.2.2.2.3.1" style="font-size:90%;">8B</span></td>
<td class="ltx_td ltx_align_right ltx_border_r" id="S6.T5.2.2.2.1" style="padding-left:2.0pt;padding-right:2.0pt;">
<math alttext="\geq" class="ltx_Math" display="inline" id="S6.T5.2.2.2.1.m1.1"><semantics id="S6.T5.2.2.2.1.m1.1a"><mo id="S6.T5.2.2.2.1.m1.1.1" mathsize="90%" xref="S6.T5.2.2.2.1.m1.1.1.cmml">≥</mo><annotation-xml encoding="MathML-Content" id="S6.T5.2.2.2.1.m1.1b"><geq id="S6.T5.2.2.2.1.m1.1.1.cmml" xref="S6.T5.2.2.2.1.m1.1.1"></geq></annotation-xml><annotation encoding="application/x-tex" id="S6.T5.2.2.2.1.m1.1c">\geq</annotation><annotation encoding="application/x-llamapun" id="S6.T5.2.2.2.1.m1.1d">≥</annotation></semantics></math><span class="ltx_text" id="S6.T5.2.2.2.1.1" style="font-size:90%;">RTX 3090</span>
</td>
<td class="ltx_td ltx_align_center" id="S6.T5.2.2.2.4" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.2.2.2.4.1" style="font-size:90%;">0.60</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T5.2.2.2.5" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.2.2.2.5.1" style="font-size:90%;">0.67</span></td>
<td class="ltx_td ltx_align_center" id="S6.T5.2.2.2.6" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.2.2.2.6.1" style="font-size:90%;">0.79</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T5.2.2.2.7" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.2.2.2.7.1" style="font-size:90%;">0.75</span></td>
<td class="ltx_td ltx_align_center" id="S6.T5.2.2.2.8" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.2.2.2.8.1" style="font-size:90%;">0.37</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T5.2.2.2.9" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.2.2.2.9.1" style="font-size:90%;">0.40</span></td>
<td class="ltx_td ltx_align_center" id="S6.T5.2.2.2.10" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text ltx_font_bold" id="S6.T5.2.2.2.10.1" style="font-size:90%;">0.59</span></td>
<td class="ltx_td ltx_align_center" id="S6.T5.2.2.2.11" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text ltx_font_bold" id="S6.T5.2.2.2.11.1" style="font-size:90%;">0.61</span></td>
</tr>
<tr class="ltx_tr" id="S6.T5.3.3.3">
<td class="ltx_td ltx_align_left" id="S6.T5.3.3.3.2" style="padding-left:2.0pt;padding-right:2.0pt;"><a class="ltx_ref ltx_href" href="https://huggingface.co/meta-llama/Llama-2-13b-chat-hf" style="font-size:90%;" title="">Llama2</a></td>
<td class="ltx_td ltx_align_right" id="S6.T5.3.3.3.3" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.3.3.3.3.1" style="font-size:90%;">13B</span></td>
<td class="ltx_td ltx_align_right ltx_border_r" id="S6.T5.3.3.3.1" style="padding-left:2.0pt;padding-right:2.0pt;">
<math alttext="\geq" class="ltx_Math" display="inline" id="S6.T5.3.3.3.1.m1.1"><semantics id="S6.T5.3.3.3.1.m1.1a"><mo id="S6.T5.3.3.3.1.m1.1.1" mathsize="90%" xref="S6.T5.3.3.3.1.m1.1.1.cmml">≥</mo><annotation-xml encoding="MathML-Content" id="S6.T5.3.3.3.1.m1.1b"><geq id="S6.T5.3.3.3.1.m1.1.1.cmml" xref="S6.T5.3.3.3.1.m1.1.1"></geq></annotation-xml><annotation encoding="application/x-tex" id="S6.T5.3.3.3.1.m1.1c">\geq</annotation><annotation encoding="application/x-llamapun" id="S6.T5.3.3.3.1.m1.1d">≥</annotation></semantics></math><span class="ltx_text" id="S6.T5.3.3.3.1.1" style="font-size:90%;">RTX 4090</span>
</td>
<td class="ltx_td ltx_align_center" id="S6.T5.3.3.3.4" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.3.3.3.4.1" style="font-size:90%;">0.12</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T5.3.3.3.5" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.3.3.3.5.1" style="font-size:90%;">0.09</span></td>
<td class="ltx_td ltx_align_center" id="S6.T5.3.3.3.6" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.3.3.3.6.1" style="font-size:90%;">0.35</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T5.3.3.3.7" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.3.3.3.7.1" style="font-size:90%;">0.41</span></td>
<td class="ltx_td ltx_align_center" id="S6.T5.3.3.3.8" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.3.3.3.8.1" style="font-size:90%;">0</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T5.3.3.3.9" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.3.3.3.9.1" style="font-size:90%;">0</span></td>
<td class="ltx_td ltx_align_center" id="S6.T5.3.3.3.10" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text ltx_font_bold" id="S6.T5.3.3.3.10.1" style="font-size:90%;">0.16</span></td>
<td class="ltx_td ltx_align_center" id="S6.T5.3.3.3.11" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text ltx_font_bold" id="S6.T5.3.3.3.11.1" style="font-size:90%;">0.17</span></td>
</tr>
<tr class="ltx_tr" id="S6.T5.4.4.4">
<td class="ltx_td ltx_align_left" id="S6.T5.4.4.4.2" style="padding-left:2.0pt;padding-right:2.0pt;"><a class="ltx_ref ltx_href" href="https://huggingface.co/IEITYuan/Yuan2-2B-Februa-hf" style="font-size:90%;" title="">Yuan2</a></td>
<td class="ltx_td ltx_align_right" id="S6.T5.4.4.4.3" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.4.4.4.3.1" style="font-size:90%;">2B</span></td>
<td class="ltx_td ltx_align_right ltx_border_r" id="S6.T5.4.4.4.1" style="padding-left:2.0pt;padding-right:2.0pt;">
<math alttext="\geq" class="ltx_Math" display="inline" id="S6.T5.4.4.4.1.m1.1"><semantics id="S6.T5.4.4.4.1.m1.1a"><mo id="S6.T5.4.4.4.1.m1.1.1" mathsize="90%" xref="S6.T5.4.4.4.1.m1.1.1.cmml">≥</mo><annotation-xml encoding="MathML-Content" id="S6.T5.4.4.4.1.m1.1b"><geq id="S6.T5.4.4.4.1.m1.1.1.cmml" xref="S6.T5.4.4.4.1.m1.1.1"></geq></annotation-xml><annotation encoding="application/x-tex" id="S6.T5.4.4.4.1.m1.1c">\geq</annotation><annotation encoding="application/x-llamapun" id="S6.T5.4.4.4.1.m1.1d">≥</annotation></semantics></math><span class="ltx_text" id="S6.T5.4.4.4.1.1" style="font-size:90%;">RTX 3060</span>
</td>
<td class="ltx_td ltx_align_center" id="S6.T5.4.4.4.4" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.4.4.4.4.1" style="font-size:90%;">0.03</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T5.4.4.4.5" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.4.4.4.5.1" style="font-size:90%;">0.02</span></td>
<td class="ltx_td ltx_align_center" id="S6.T5.4.4.4.6" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.4.4.4.6.1" style="font-size:90%;">0.22</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T5.4.4.4.7" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.4.4.4.7.1" style="font-size:90%;">0.18</span></td>
<td class="ltx_td ltx_align_center" id="S6.T5.4.4.4.8" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.4.4.4.8.1" style="font-size:90%;">0</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T5.4.4.4.9" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.4.4.4.9.1" style="font-size:90%;">0</span></td>
<td class="ltx_td ltx_align_center" id="S6.T5.4.4.4.10" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text ltx_font_bold" id="S6.T5.4.4.4.10.1" style="font-size:90%;">0.08</span></td>
<td class="ltx_td ltx_align_center" id="S6.T5.4.4.4.11" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text ltx_font_bold" id="S6.T5.4.4.4.11.1" style="font-size:90%;">0.07</span></td>
</tr>
<tr class="ltx_tr" id="S6.T5.5.5.5">
<td class="ltx_td ltx_align_left" id="S6.T5.5.5.5.2" style="padding-left:2.0pt;padding-right:2.0pt;">
<a class="ltx_ref ltx_href" href="https://huggingface.co/baichuan-inc/Baichuan2-13B-Chat" style="font-size:90%;" title="">Baichuan2</a><span class="ltx_text" id="S6.T5.5.5.5.2.1" style="font-size:90%;">(vanilla)</span>
</td>
<td class="ltx_td ltx_align_right" id="S6.T5.5.5.5.3" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.5.5.5.3.1" style="font-size:90%;">13B</span></td>
<td class="ltx_td ltx_align_right ltx_border_r" id="S6.T5.5.5.5.1" style="padding-left:2.0pt;padding-right:2.0pt;">
<math alttext="\geq" class="ltx_Math" display="inline" id="S6.T5.5.5.5.1.m1.1"><semantics id="S6.T5.5.5.5.1.m1.1a"><mo id="S6.T5.5.5.5.1.m1.1.1" mathsize="90%" xref="S6.T5.5.5.5.1.m1.1.1.cmml">≥</mo><annotation-xml encoding="MathML-Content" id="S6.T5.5.5.5.1.m1.1b"><geq id="S6.T5.5.5.5.1.m1.1.1.cmml" xref="S6.T5.5.5.5.1.m1.1.1"></geq></annotation-xml><annotation encoding="application/x-tex" id="S6.T5.5.5.5.1.m1.1c">\geq</annotation><annotation encoding="application/x-llamapun" id="S6.T5.5.5.5.1.m1.1d">≥</annotation></semantics></math><span class="ltx_text" id="S6.T5.5.5.5.1.1" style="font-size:90%;">RTX 4090</span>
</td>
<td class="ltx_td ltx_align_center" id="S6.T5.5.5.5.4" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.5.5.5.4.1" style="font-size:90%;">0.27</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T5.5.5.5.5" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.5.5.5.5.1" style="font-size:90%;">0.29</span></td>
<td class="ltx_td ltx_align_center" id="S6.T5.5.5.5.6" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.5.5.5.6.1" style="font-size:90%;">0.56</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T5.5.5.5.7" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.5.5.5.7.1" style="font-size:90%;">0.60</span></td>
<td class="ltx_td ltx_align_center" id="S6.T5.5.5.5.8" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.5.5.5.8.1" style="font-size:90%;">0.23</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T5.5.5.5.9" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.5.5.5.9.1" style="font-size:90%;">0.15</span></td>
<td class="ltx_td ltx_align_center" id="S6.T5.5.5.5.10" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text ltx_font_bold" id="S6.T5.5.5.5.10.1" style="font-size:90%;">0.35</span></td>
<td class="ltx_td ltx_align_center" id="S6.T5.5.5.5.11" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text ltx_font_bold" id="S6.T5.5.5.5.11.1" style="font-size:90%;">0.35</span></td>
</tr>
<tr class="ltx_tr" id="S6.T5.6.6.6">
<td class="ltx_td ltx_align_left" id="S6.T5.6.6.6.2" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.6.6.6.2.1" style="font-size:90%;">Baichuan2-sft</span></td>
<td class="ltx_td ltx_align_right" id="S6.T5.6.6.6.3" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.6.6.6.3.1" style="font-size:90%;">13B</span></td>
<td class="ltx_td ltx_align_right ltx_border_r" id="S6.T5.6.6.6.1" style="padding-left:2.0pt;padding-right:2.0pt;">
<math alttext="\geq" class="ltx_Math" display="inline" id="S6.T5.6.6.6.1.m1.1"><semantics id="S6.T5.6.6.6.1.m1.1a"><mo id="S6.T5.6.6.6.1.m1.1.1" mathsize="90%" xref="S6.T5.6.6.6.1.m1.1.1.cmml">≥</mo><annotation-xml encoding="MathML-Content" id="S6.T5.6.6.6.1.m1.1b"><geq id="S6.T5.6.6.6.1.m1.1.1.cmml" xref="S6.T5.6.6.6.1.m1.1.1"></geq></annotation-xml><annotation encoding="application/x-tex" id="S6.T5.6.6.6.1.m1.1c">\geq</annotation><annotation encoding="application/x-llamapun" id="S6.T5.6.6.6.1.m1.1d">≥</annotation></semantics></math><span class="ltx_text" id="S6.T5.6.6.6.1.1" style="font-size:90%;">RTX 4090</span>
</td>
<td class="ltx_td ltx_align_center" id="S6.T5.6.6.6.4" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.6.6.6.4.1" style="font-size:90%;">0.44</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T5.6.6.6.5" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.6.6.6.5.1" style="font-size:90%;">0.31</span></td>
<td class="ltx_td ltx_align_center" id="S6.T5.6.6.6.6" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.6.6.6.6.1" style="font-size:90%;">0.88</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T5.6.6.6.7" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.6.6.6.7.1" style="font-size:90%;">0.76</span></td>
<td class="ltx_td ltx_align_center" id="S6.T5.6.6.6.8" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.6.6.6.8.1" style="font-size:90%;">0.90</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T5.6.6.6.9" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.6.6.6.9.1" style="font-size:90%;">0.82</span></td>
<td class="ltx_td ltx_align_center" id="S6.T5.6.6.6.10" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text ltx_font_bold" id="S6.T5.6.6.6.10.1" style="font-size:90%;">0.74</span></td>
<td class="ltx_td ltx_align_center" id="S6.T5.6.6.6.11" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text ltx_font_bold" id="S6.T5.6.6.6.11.1" style="font-size:90%;">0.63</span></td>
</tr>
<tr class="ltx_tr" id="S6.T5.13.13.19">
<td class="ltx_td ltx_align_left" id="S6.T5.13.13.19.1" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.13.13.19.1.1" style="font-size:90%;">Imp. w.r.t. vanilla</span></td>
<td class="ltx_td" id="S6.T5.13.13.19.2" style="padding-left:2.0pt;padding-right:2.0pt;"></td>
<td class="ltx_td ltx_border_r" id="S6.T5.13.13.19.3" style="padding-left:2.0pt;padding-right:2.0pt;"></td>
<td class="ltx_td ltx_align_center" id="S6.T5.13.13.19.4" style="background-color:#E6E6E6;padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.13.13.19.4.1" style="font-size:90%;background-color:#E6E6E6;">+0.17</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T5.13.13.19.5" style="background-color:#E6E6E6;padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.13.13.19.5.1" style="font-size:90%;background-color:#E6E6E6;">+0.02</span></td>
<td class="ltx_td ltx_align_center" id="S6.T5.13.13.19.6" style="background-color:#E6E6E6;padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.13.13.19.6.1" style="font-size:90%;background-color:#E6E6E6;">+0.32</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T5.13.13.19.7" style="background-color:#E6E6E6;padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.13.13.19.7.1" style="font-size:90%;background-color:#E6E6E6;">+0.16</span></td>
<td class="ltx_td ltx_align_center" id="S6.T5.13.13.19.8" style="background-color:#E6E6E6;padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.13.13.19.8.1" style="font-size:90%;background-color:#E6E6E6;">+0.67</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T5.13.13.19.9" style="background-color:#E6E6E6;padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.13.13.19.9.1" style="font-size:90%;background-color:#E6E6E6;">+0.67</span></td>
<td class="ltx_td ltx_align_center" id="S6.T5.13.13.19.10" style="background-color:#E6E6E6;padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.13.13.19.10.1" style="font-size:90%;background-color:#E6E6E6;">+0.39</span></td>
<td class="ltx_td ltx_align_center" id="S6.T5.13.13.19.11" style="background-color:#E6E6E6;padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.13.13.19.11.1" style="font-size:90%;background-color:#E6E6E6;">+0.28</span></td>
</tr>
<tr class="ltx_tr" id="S6.T5.7.7.7">
<td class="ltx_td ltx_align_left" id="S6.T5.7.7.7.2" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.7.7.7.2.1" style="font-size:90%;">Baichuan2-cpt-sft</span></td>
<td class="ltx_td ltx_align_right" id="S6.T5.7.7.7.3" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.7.7.7.3.1" style="font-size:90%;">13B</span></td>
<td class="ltx_td ltx_align_right ltx_border_r" id="S6.T5.7.7.7.1" style="padding-left:2.0pt;padding-right:2.0pt;">
<math alttext="\geq" class="ltx_Math" display="inline" id="S6.T5.7.7.7.1.m1.1"><semantics id="S6.T5.7.7.7.1.m1.1a"><mo id="S6.T5.7.7.7.1.m1.1.1" mathsize="90%" xref="S6.T5.7.7.7.1.m1.1.1.cmml">≥</mo><annotation-xml encoding="MathML-Content" id="S6.T5.7.7.7.1.m1.1b"><geq id="S6.T5.7.7.7.1.m1.1.1.cmml" xref="S6.T5.7.7.7.1.m1.1.1"></geq></annotation-xml><annotation encoding="application/x-tex" id="S6.T5.7.7.7.1.m1.1c">\geq</annotation><annotation encoding="application/x-llamapun" id="S6.T5.7.7.7.1.m1.1d">≥</annotation></semantics></math><span class="ltx_text" id="S6.T5.7.7.7.1.1" style="font-size:90%;">RTX 4090</span>
</td>
<td class="ltx_td ltx_align_center" id="S6.T5.7.7.7.4" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.7.7.7.4.1" style="font-size:90%;">0.57</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T5.7.7.7.5" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.7.7.7.5.1" style="font-size:90%;">0.48</span></td>
<td class="ltx_td ltx_align_center" id="S6.T5.7.7.7.6" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.7.7.7.6.1" style="font-size:90%;color:#BF0040;">0.88</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T5.7.7.7.7" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.7.7.7.7.1" style="font-size:90%;">0.74</span></td>
<td class="ltx_td ltx_align_center" id="S6.T5.7.7.7.8" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.7.7.7.8.1" style="font-size:90%;color:#BF0040;">0.91</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T5.7.7.7.9" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.7.7.7.9.1" style="font-size:90%;color:#BF0040;">0.87</span></td>
<td class="ltx_td ltx_align_center" id="S6.T5.7.7.7.10" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text ltx_font_bold" id="S6.T5.7.7.7.10.1" style="font-size:90%;">0.79</span></td>
<td class="ltx_td ltx_align_center" id="S6.T5.7.7.7.11" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text ltx_font_bold" id="S6.T5.7.7.7.11.1" style="font-size:90%;">0.70</span></td>
</tr>
<tr class="ltx_tr" id="S6.T5.13.13.20">
<td class="ltx_td ltx_align_left" id="S6.T5.13.13.20.1" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.13.13.20.1.1" style="font-size:90%;">Imp. w.r.t. vanilla</span></td>
<td class="ltx_td" id="S6.T5.13.13.20.2" style="padding-left:2.0pt;padding-right:2.0pt;"></td>
<td class="ltx_td ltx_border_r" id="S6.T5.13.13.20.3" style="padding-left:2.0pt;padding-right:2.0pt;"></td>
<td class="ltx_td ltx_align_center" id="S6.T5.13.13.20.4" style="background-color:#E6E6E6;padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.13.13.20.4.1" style="font-size:90%;background-color:#E6E6E6;">+0.30</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T5.13.13.20.5" style="background-color:#E6E6E6;padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.13.13.20.5.1" style="font-size:90%;background-color:#E6E6E6;">+0.19</span></td>
<td class="ltx_td ltx_align_center" id="S6.T5.13.13.20.6" style="background-color:#E6E6E6;padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.13.13.20.6.1" style="font-size:90%;background-color:#E6E6E6;">+0.32</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T5.13.13.20.7" style="background-color:#E6E6E6;padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.13.13.20.7.1" style="font-size:90%;background-color:#E6E6E6;">+0.14</span></td>
<td class="ltx_td ltx_align_center" id="S6.T5.13.13.20.8" style="background-color:#E6E6E6;padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.13.13.20.8.1" style="font-size:90%;background-color:#E6E6E6;">+0.68</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T5.13.13.20.9" style="background-color:#E6E6E6;padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.13.13.20.9.1" style="font-size:90%;background-color:#E6E6E6;">+0.72</span></td>
<td class="ltx_td ltx_align_center" id="S6.T5.13.13.20.10" style="background-color:#E6E6E6;padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.13.13.20.10.1" style="font-size:90%;background-color:#E6E6E6;">+0.44</span></td>
<td class="ltx_td ltx_align_center" id="S6.T5.13.13.20.11" style="background-color:#E6E6E6;padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.13.13.20.11.1" style="font-size:90%;background-color:#E6E6E6;">+0.35</span></td>
</tr>
<tr class="ltx_tr" id="S6.T5.13.13.21">
<td class="ltx_td ltx_align_center ltx_border_t" colspan="10" id="S6.T5.13.13.21.1" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text ltx_font_typewriter" id="S6.T5.13.13.21.1.1" style="font-size:90%;">WinRate v.s. GPT-3.5-Turbo (Testbed)</span></td>
<td class="ltx_td ltx_border_t" id="S6.T5.13.13.21.2" style="padding-left:2.0pt;padding-right:2.0pt;"></td>
</tr>
<tr class="ltx_tr" id="S6.T5.13.13.22">
<td class="ltx_td ltx_align_left ltx_border_t" id="S6.T5.13.13.22.1" style="padding-left:2.0pt;padding-right:2.0pt;"><a class="ltx_ref ltx_href" href="https://platform.openai.com/docs/models/gpt-4-turbo-and-gpt-4" style="font-size:90%;" title="">GPT-4</a></td>
<td class="ltx_td ltx_border_t" id="S6.T5.13.13.22.2" style="padding-left:2.0pt;padding-right:2.0pt;"></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S6.T5.13.13.22.3" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.13.13.22.3.1" style="font-size:90%;">Centralized</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T5.13.13.22.4" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.13.13.22.4.1" style="font-size:90%;color:#BF0040;">0.83</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S6.T5.13.13.22.5" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.13.13.22.5.1" style="font-size:90%;color:#BF0040;">0.95</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T5.13.13.22.6" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.13.13.22.6.1" style="font-size:90%;">0.64</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S6.T5.13.13.22.7" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.13.13.22.7.1" style="font-size:90%;">0.68</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T5.13.13.22.8" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.13.13.22.8.1" style="font-size:90%;">0.90</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S6.T5.13.13.22.9" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.13.13.22.9.1" style="font-size:90%;">0.64</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T5.13.13.22.10" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text ltx_font_bold" id="S6.T5.13.13.22.10.1" style="font-size:90%;color:#BF0040;">0.79</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T5.13.13.22.11" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text ltx_font_bold" id="S6.T5.13.13.22.11.1" style="font-size:90%;color:#BF0040;">0.76</span></td>
</tr>
<tr class="ltx_tr" id="S6.T5.13.13.23">
<td class="ltx_td ltx_align_left" id="S6.T5.13.13.23.1" style="padding-left:2.0pt;padding-right:2.0pt;"><a class="ltx_ref ltx_href" href="https://platform.openai.com/docs/models/gpt-3-5-turbo" style="font-size:90%;" title="">GPT-3.5-Turbo</a></td>
<td class="ltx_td" id="S6.T5.13.13.23.2" style="padding-left:2.0pt;padding-right:2.0pt;"></td>
<td class="ltx_td ltx_align_right ltx_border_r" id="S6.T5.13.13.23.3" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.13.13.23.3.1" style="font-size:90%;">Centralized</span></td>
<td class="ltx_td ltx_align_center" id="S6.T5.13.13.23.4" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.13.13.23.4.1" style="font-size:90%;">-</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T5.13.13.23.5" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.13.13.23.5.1" style="font-size:90%;">-</span></td>
<td class="ltx_td ltx_align_center" id="S6.T5.13.13.23.6" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.13.13.23.6.1" style="font-size:90%;">-</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T5.13.13.23.7" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.13.13.23.7.1" style="font-size:90%;">-</span></td>
<td class="ltx_td ltx_align_center" id="S6.T5.13.13.23.8" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.13.13.23.8.1" style="font-size:90%;">-</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T5.13.13.23.9" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.13.13.23.9.1" style="font-size:90%;">-</span></td>
<td class="ltx_td ltx_align_center" id="S6.T5.13.13.23.10" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.13.13.23.10.1" style="font-size:90%;">-</span></td>
<td class="ltx_td ltx_align_center" id="S6.T5.13.13.23.11" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.13.13.23.11.1" style="font-size:90%;">-</span></td>
</tr>
<tr class="ltx_tr" id="S6.T5.13.13.24">
<td class="ltx_td ltx_align_left" id="S6.T5.13.13.24.1" style="padding-left:2.0pt;padding-right:2.0pt;"><a class="ltx_ref ltx_href" href="https://chatglm.cn/main/detail" style="font-size:90%;" title="">GLM-3-Turbo</a></td>
<td class="ltx_td" id="S6.T5.13.13.24.2" style="padding-left:2.0pt;padding-right:2.0pt;"></td>
<td class="ltx_td ltx_align_right ltx_border_r" id="S6.T5.13.13.24.3" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.13.13.24.3.1" style="font-size:90%;">Centralized</span></td>
<td class="ltx_td ltx_align_center" id="S6.T5.13.13.24.4" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.13.13.24.4.1" style="font-size:90%;">0.62</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T5.13.13.24.5" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.13.13.24.5.1" style="font-size:90%;">0.65</span></td>
<td class="ltx_td ltx_align_center" id="S6.T5.13.13.24.6" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.13.13.24.6.1" style="font-size:90%;">0.66</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T5.13.13.24.7" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.13.13.24.7.1" style="font-size:90%;">0.57</span></td>
<td class="ltx_td ltx_align_center" id="S6.T5.13.13.24.8" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.13.13.24.8.1" style="font-size:90%;">0.55</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T5.13.13.24.9" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.13.13.24.9.1" style="font-size:90%;">0.49</span></td>
<td class="ltx_td ltx_align_center" id="S6.T5.13.13.24.10" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text ltx_font_bold" id="S6.T5.13.13.24.10.1" style="font-size:90%;">0.61</span></td>
<td class="ltx_td ltx_align_center" id="S6.T5.13.13.24.11" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text ltx_font_bold" id="S6.T5.13.13.24.11.1" style="font-size:90%;">0.57</span></td>
</tr>
<tr class="ltx_tr" id="S6.T5.8.8.8">
<td class="ltx_td ltx_align_left" id="S6.T5.8.8.8.2" style="padding-left:2.0pt;padding-right:2.0pt;"><a class="ltx_ref ltx_href" href="https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct" style="font-size:90%;" title="">Llama3</a></td>
<td class="ltx_td ltx_align_right" id="S6.T5.8.8.8.3" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.8.8.8.3.1" style="font-size:90%;">8B</span></td>
<td class="ltx_td ltx_align_right ltx_border_r" id="S6.T5.8.8.8.1" style="padding-left:2.0pt;padding-right:2.0pt;">
<math alttext="\geq" class="ltx_Math" display="inline" id="S6.T5.8.8.8.1.m1.1"><semantics id="S6.T5.8.8.8.1.m1.1a"><mo id="S6.T5.8.8.8.1.m1.1.1" mathsize="90%" xref="S6.T5.8.8.8.1.m1.1.1.cmml">≥</mo><annotation-xml encoding="MathML-Content" id="S6.T5.8.8.8.1.m1.1b"><geq id="S6.T5.8.8.8.1.m1.1.1.cmml" xref="S6.T5.8.8.8.1.m1.1.1"></geq></annotation-xml><annotation encoding="application/x-tex" id="S6.T5.8.8.8.1.m1.1c">\geq</annotation><annotation encoding="application/x-llamapun" id="S6.T5.8.8.8.1.m1.1d">≥</annotation></semantics></math><span class="ltx_text" id="S6.T5.8.8.8.1.1" style="font-size:90%;">RTX 3090</span>
</td>
<td class="ltx_td ltx_align_center" id="S6.T5.8.8.8.4" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.8.8.8.4.1" style="font-size:90%;">0.60</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T5.8.8.8.5" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.8.8.8.5.1" style="font-size:90%;">0.65</span></td>
<td class="ltx_td ltx_align_center" id="S6.T5.8.8.8.6" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.8.8.8.6.1" style="font-size:90%;">0.62</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T5.8.8.8.7" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.8.8.8.7.1" style="font-size:90%;">0.51</span></td>
<td class="ltx_td ltx_align_center" id="S6.T5.8.8.8.8" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.8.8.8.8.1" style="font-size:90%;">0.49</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T5.8.8.8.9" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.8.8.8.9.1" style="font-size:90%;">0.52</span></td>
<td class="ltx_td ltx_align_center" id="S6.T5.8.8.8.10" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text ltx_font_bold" id="S6.T5.8.8.8.10.1" style="font-size:90%;">0.57</span></td>
<td class="ltx_td ltx_align_center" id="S6.T5.8.8.8.11" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text ltx_font_bold" id="S6.T5.8.8.8.11.1" style="font-size:90%;">0.56</span></td>
</tr>
<tr class="ltx_tr" id="S6.T5.9.9.9">
<td class="ltx_td ltx_align_left" id="S6.T5.9.9.9.2" style="padding-left:2.0pt;padding-right:2.0pt;"><a class="ltx_ref ltx_href" href="https://huggingface.co/meta-llama/Llama-2-13b-chat-hf" style="font-size:90%;" title="">Llama2</a></td>
<td class="ltx_td ltx_align_right" id="S6.T5.9.9.9.3" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.9.9.9.3.1" style="font-size:90%;">13B</span></td>
<td class="ltx_td ltx_align_right ltx_border_r" id="S6.T5.9.9.9.1" style="padding-left:2.0pt;padding-right:2.0pt;">
<math alttext="\geq" class="ltx_Math" display="inline" id="S6.T5.9.9.9.1.m1.1"><semantics id="S6.T5.9.9.9.1.m1.1a"><mo id="S6.T5.9.9.9.1.m1.1.1" mathsize="90%" xref="S6.T5.9.9.9.1.m1.1.1.cmml">≥</mo><annotation-xml encoding="MathML-Content" id="S6.T5.9.9.9.1.m1.1b"><geq id="S6.T5.9.9.9.1.m1.1.1.cmml" xref="S6.T5.9.9.9.1.m1.1.1"></geq></annotation-xml><annotation encoding="application/x-tex" id="S6.T5.9.9.9.1.m1.1c">\geq</annotation><annotation encoding="application/x-llamapun" id="S6.T5.9.9.9.1.m1.1d">≥</annotation></semantics></math><span class="ltx_text" id="S6.T5.9.9.9.1.1" style="font-size:90%;">RTX 4090</span>
</td>
<td class="ltx_td ltx_align_center" id="S6.T5.9.9.9.4" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.9.9.9.4.1" style="font-size:90%;">0.12</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T5.9.9.9.5" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.9.9.9.5.1" style="font-size:90%;">0.06</span></td>
<td class="ltx_td ltx_align_center" id="S6.T5.9.9.9.6" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.9.9.9.6.1" style="font-size:90%;">0.36</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T5.9.9.9.7" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.9.9.9.7.1" style="font-size:90%;">0.16</span></td>
<td class="ltx_td ltx_align_center" id="S6.T5.9.9.9.8" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.9.9.9.8.1" style="font-size:90%;">0</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T5.9.9.9.9" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.9.9.9.9.1" style="font-size:90%;">0</span></td>
<td class="ltx_td ltx_align_center" id="S6.T5.9.9.9.10" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text ltx_font_bold" id="S6.T5.9.9.9.10.1" style="font-size:90%;">0.16</span></td>
<td class="ltx_td ltx_align_center" id="S6.T5.9.9.9.11" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text ltx_font_bold" id="S6.T5.9.9.9.11.1" style="font-size:90%;">0.07</span></td>
</tr>
<tr class="ltx_tr" id="S6.T5.10.10.10">
<td class="ltx_td ltx_align_left" id="S6.T5.10.10.10.2" style="padding-left:2.0pt;padding-right:2.0pt;"><a class="ltx_ref ltx_href" href="https://huggingface.co/IEITYuan/Yuan2-2B-Februa-hf" style="font-size:90%;" title="">Yuan2</a></td>
<td class="ltx_td ltx_align_right" id="S6.T5.10.10.10.3" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.10.10.10.3.1" style="font-size:90%;">2B</span></td>
<td class="ltx_td ltx_align_right ltx_border_r" id="S6.T5.10.10.10.1" style="padding-left:2.0pt;padding-right:2.0pt;">
<math alttext="\geq" class="ltx_Math" display="inline" id="S6.T5.10.10.10.1.m1.1"><semantics id="S6.T5.10.10.10.1.m1.1a"><mo id="S6.T5.10.10.10.1.m1.1.1" mathsize="90%" xref="S6.T5.10.10.10.1.m1.1.1.cmml">≥</mo><annotation-xml encoding="MathML-Content" id="S6.T5.10.10.10.1.m1.1b"><geq id="S6.T5.10.10.10.1.m1.1.1.cmml" xref="S6.T5.10.10.10.1.m1.1.1"></geq></annotation-xml><annotation encoding="application/x-tex" id="S6.T5.10.10.10.1.m1.1c">\geq</annotation><annotation encoding="application/x-llamapun" id="S6.T5.10.10.10.1.m1.1d">≥</annotation></semantics></math><span class="ltx_text" id="S6.T5.10.10.10.1.1" style="font-size:90%;">RTX 3060</span>
</td>
<td class="ltx_td ltx_align_center" id="S6.T5.10.10.10.4" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.10.10.10.4.1" style="font-size:90%;">0.03</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T5.10.10.10.5" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.10.10.10.5.1" style="font-size:90%;">0.02</span></td>
<td class="ltx_td ltx_align_center" id="S6.T5.10.10.10.6" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.10.10.10.6.1" style="font-size:90%;">0.13</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T5.10.10.10.7" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.10.10.10.7.1" style="font-size:90%;">0.07</span></td>
<td class="ltx_td ltx_align_center" id="S6.T5.10.10.10.8" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.10.10.10.8.1" style="font-size:90%;">0</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T5.10.10.10.9" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.10.10.10.9.1" style="font-size:90%;">0</span></td>
<td class="ltx_td ltx_align_center" id="S6.T5.10.10.10.10" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text ltx_font_bold" id="S6.T5.10.10.10.10.1" style="font-size:90%;">0.05</span></td>
<td class="ltx_td ltx_align_center" id="S6.T5.10.10.10.11" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text ltx_font_bold" id="S6.T5.10.10.10.11.1" style="font-size:90%;">0.03</span></td>
</tr>
<tr class="ltx_tr" id="S6.T5.11.11.11">
<td class="ltx_td ltx_align_left" id="S6.T5.11.11.11.2" style="padding-left:2.0pt;padding-right:2.0pt;"><a class="ltx_ref ltx_href" href="https://huggingface.co/baichuan-inc/Baichuan2-13B-Chat" style="font-size:90%;" title="">Baichuan2(vanilla)</a></td>
<td class="ltx_td ltx_align_right" id="S6.T5.11.11.11.3" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.11.11.11.3.1" style="font-size:90%;">13B</span></td>
<td class="ltx_td ltx_align_right ltx_border_r" id="S6.T5.11.11.11.1" style="padding-left:2.0pt;padding-right:2.0pt;">
<math alttext="\geq" class="ltx_Math" display="inline" id="S6.T5.11.11.11.1.m1.1"><semantics id="S6.T5.11.11.11.1.m1.1a"><mo id="S6.T5.11.11.11.1.m1.1.1" mathsize="90%" xref="S6.T5.11.11.11.1.m1.1.1.cmml">≥</mo><annotation-xml encoding="MathML-Content" id="S6.T5.11.11.11.1.m1.1b"><geq id="S6.T5.11.11.11.1.m1.1.1.cmml" xref="S6.T5.11.11.11.1.m1.1.1"></geq></annotation-xml><annotation encoding="application/x-tex" id="S6.T5.11.11.11.1.m1.1c">\geq</annotation><annotation encoding="application/x-llamapun" id="S6.T5.11.11.11.1.m1.1d">≥</annotation></semantics></math><span class="ltx_text" id="S6.T5.11.11.11.1.1" style="font-size:90%;">RTX 4090</span>
</td>
<td class="ltx_td ltx_align_center" id="S6.T5.11.11.11.4" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.11.11.11.4.1" style="font-size:90%;">0.26</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T5.11.11.11.5" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.11.11.11.5.1" style="font-size:90%;">0.30</span></td>
<td class="ltx_td ltx_align_center" id="S6.T5.11.11.11.6" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.11.11.11.6.1" style="font-size:90%;">0.42</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T5.11.11.11.7" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.11.11.11.7.1" style="font-size:90%;">0.40</span></td>
<td class="ltx_td ltx_align_center" id="S6.T5.11.11.11.8" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.11.11.11.8.1" style="font-size:90%;">0.16</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T5.11.11.11.9" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.11.11.11.9.1" style="font-size:90%;">0.11</span></td>
<td class="ltx_td ltx_align_center" id="S6.T5.11.11.11.10" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text ltx_font_bold" id="S6.T5.11.11.11.10.1" style="font-size:90%;">0.28</span></td>
<td class="ltx_td ltx_align_center" id="S6.T5.11.11.11.11" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text ltx_font_bold" id="S6.T5.11.11.11.11.1" style="font-size:90%;">0.27</span></td>
</tr>
<tr class="ltx_tr" id="S6.T5.12.12.12">
<td class="ltx_td ltx_align_left" id="S6.T5.12.12.12.2" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.12.12.12.2.1" style="font-size:90%;">Baichuan2-sft</span></td>
<td class="ltx_td ltx_align_right" id="S6.T5.12.12.12.3" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.12.12.12.3.1" style="font-size:90%;">13B</span></td>
<td class="ltx_td ltx_align_right ltx_border_r" id="S6.T5.12.12.12.1" style="padding-left:2.0pt;padding-right:2.0pt;">
<math alttext="\geq" class="ltx_Math" display="inline" id="S6.T5.12.12.12.1.m1.1"><semantics id="S6.T5.12.12.12.1.m1.1a"><mo id="S6.T5.12.12.12.1.m1.1.1" mathsize="90%" xref="S6.T5.12.12.12.1.m1.1.1.cmml">≥</mo><annotation-xml encoding="MathML-Content" id="S6.T5.12.12.12.1.m1.1b"><geq id="S6.T5.12.12.12.1.m1.1.1.cmml" xref="S6.T5.12.12.12.1.m1.1.1"></geq></annotation-xml><annotation encoding="application/x-tex" id="S6.T5.12.12.12.1.m1.1c">\geq</annotation><annotation encoding="application/x-llamapun" id="S6.T5.12.12.12.1.m1.1d">≥</annotation></semantics></math><span class="ltx_text" id="S6.T5.12.12.12.1.1" style="font-size:90%;">RTX 4090</span>
</td>
<td class="ltx_td ltx_align_center" id="S6.T5.12.12.12.4" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.12.12.12.4.1" style="font-size:90%;">0.44</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T5.12.12.12.5" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.12.12.12.5.1" style="font-size:90%;">0.30</span></td>
<td class="ltx_td ltx_align_center" id="S6.T5.12.12.12.6" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.12.12.12.6.1" style="font-size:90%;color:#BF0040;">0.68</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T5.12.12.12.7" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.12.12.12.7.1" style="font-size:90%;">0.66</span></td>
<td class="ltx_td ltx_align_center" id="S6.T5.12.12.12.8" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.12.12.12.8.1" style="font-size:90%;">0.85</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T5.12.12.12.9" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.12.12.12.9.1" style="font-size:90%;">0.87</span></td>
<td class="ltx_td ltx_align_center" id="S6.T5.12.12.12.10" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text ltx_font_bold" id="S6.T5.12.12.12.10.1" style="font-size:90%;">0.66</span></td>
<td class="ltx_td ltx_align_center" id="S6.T5.12.12.12.11" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text ltx_font_bold" id="S6.T5.12.12.12.11.1" style="font-size:90%;">0.61</span></td>
</tr>
<tr class="ltx_tr" id="S6.T5.13.13.25">
<td class="ltx_td ltx_align_left" id="S6.T5.13.13.25.1" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.13.13.25.1.1" style="font-size:90%;">Imp. w.r.t. vanilla</span></td>
<td class="ltx_td" id="S6.T5.13.13.25.2" style="padding-left:2.0pt;padding-right:2.0pt;"></td>
<td class="ltx_td ltx_border_r" id="S6.T5.13.13.25.3" style="padding-left:2.0pt;padding-right:2.0pt;"></td>
<td class="ltx_td ltx_align_center" id="S6.T5.13.13.25.4" style="background-color:#E6E6E6;padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.13.13.25.4.1" style="font-size:90%;background-color:#E6E6E6;">+0.18</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T5.13.13.25.5" style="background-color:#E6E6E6;padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.13.13.25.5.1" style="font-size:90%;background-color:#E6E6E6;">0</span></td>
<td class="ltx_td ltx_align_center" id="S6.T5.13.13.25.6" style="background-color:#E6E6E6;padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.13.13.25.6.1" style="font-size:90%;background-color:#E6E6E6;">+0.26</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T5.13.13.25.7" style="background-color:#E6E6E6;padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.13.13.25.7.1" style="font-size:90%;background-color:#E6E6E6;">+0.26</span></td>
<td class="ltx_td ltx_align_center" id="S6.T5.13.13.25.8" style="background-color:#E6E6E6;padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.13.13.25.8.1" style="font-size:90%;background-color:#E6E6E6;">+0.69</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T5.13.13.25.9" style="background-color:#E6E6E6;padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.13.13.25.9.1" style="font-size:90%;background-color:#E6E6E6;">+0.76</span></td>
<td class="ltx_td ltx_align_center" id="S6.T5.13.13.25.10" style="background-color:#E6E6E6;padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.13.13.25.10.1" style="font-size:90%;background-color:#E6E6E6;">+0.38</span></td>
<td class="ltx_td ltx_align_center" id="S6.T5.13.13.25.11" style="background-color:#E6E6E6;padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.13.13.25.11.1" style="font-size:90%;background-color:#E6E6E6;">+0.34</span></td>
</tr>
<tr class="ltx_tr" id="S6.T5.13.13.13">
<td class="ltx_td ltx_align_left" id="S6.T5.13.13.13.2" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.13.13.13.2.1" style="font-size:90%;">Baichuan2-cpt-sft</span></td>
<td class="ltx_td ltx_align_right" id="S6.T5.13.13.13.3" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.13.13.13.3.1" style="font-size:90%;">13B</span></td>
<td class="ltx_td ltx_align_right ltx_border_r" id="S6.T5.13.13.13.1" style="padding-left:2.0pt;padding-right:2.0pt;">
<math alttext="\geq" class="ltx_Math" display="inline" id="S6.T5.13.13.13.1.m1.1"><semantics id="S6.T5.13.13.13.1.m1.1a"><mo id="S6.T5.13.13.13.1.m1.1.1" mathsize="90%" xref="S6.T5.13.13.13.1.m1.1.1.cmml">≥</mo><annotation-xml encoding="MathML-Content" id="S6.T5.13.13.13.1.m1.1b"><geq id="S6.T5.13.13.13.1.m1.1.1.cmml" xref="S6.T5.13.13.13.1.m1.1.1"></geq></annotation-xml><annotation encoding="application/x-tex" id="S6.T5.13.13.13.1.m1.1c">\geq</annotation><annotation encoding="application/x-llamapun" id="S6.T5.13.13.13.1.m1.1d">≥</annotation></semantics></math><span class="ltx_text" id="S6.T5.13.13.13.1.1" style="font-size:90%;">RTX 4090</span>
</td>
<td class="ltx_td ltx_align_center" id="S6.T5.13.13.13.4" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.13.13.13.4.1" style="font-size:90%;">0.55</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T5.13.13.13.5" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.13.13.13.5.1" style="font-size:90%;">0.42</span></td>
<td class="ltx_td ltx_align_center" id="S6.T5.13.13.13.6" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.13.13.13.6.1" style="font-size:90%;">0.65</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T5.13.13.13.7" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.13.13.13.7.1" style="font-size:90%;color:#BF0040;">0.73</span></td>
<td class="ltx_td ltx_align_center" id="S6.T5.13.13.13.8" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.13.13.13.8.1" style="font-size:90%;color:#BF0040;">0.95</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T5.13.13.13.9" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.13.13.13.9.1" style="font-size:90%;color:#BF0040;">0.90</span></td>
<td class="ltx_td ltx_align_center" id="S6.T5.13.13.13.10" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text ltx_font_bold" id="S6.T5.13.13.13.10.1" style="font-size:90%;">0.72</span></td>
<td class="ltx_td ltx_align_center" id="S6.T5.13.13.13.11" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text ltx_font_bold" id="S6.T5.13.13.13.11.1" style="font-size:90%;">0.68</span></td>
</tr>
<tr class="ltx_tr" id="S6.T5.13.13.26">
<td class="ltx_td ltx_align_left ltx_border_bb" id="S6.T5.13.13.26.1" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.13.13.26.1.1" style="font-size:90%;">Imp. w.r.t. vanilla</span></td>
<td class="ltx_td ltx_border_bb" id="S6.T5.13.13.26.2" style="padding-left:2.0pt;padding-right:2.0pt;"></td>
<td class="ltx_td ltx_border_bb ltx_border_r" id="S6.T5.13.13.26.3" style="padding-left:2.0pt;padding-right:2.0pt;"></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S6.T5.13.13.26.4" style="background-color:#E6E6E6;padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.13.13.26.4.1" style="font-size:90%;background-color:#E6E6E6;">+0.29</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S6.T5.13.13.26.5" style="background-color:#E6E6E6;padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.13.13.26.5.1" style="font-size:90%;background-color:#E6E6E6;">+0.12</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S6.T5.13.13.26.6" style="background-color:#E6E6E6;padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.13.13.26.6.1" style="font-size:90%;background-color:#E6E6E6;">+0.23</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S6.T5.13.13.26.7" style="background-color:#E6E6E6;padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.13.13.26.7.1" style="font-size:90%;background-color:#E6E6E6;">+0.33</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S6.T5.13.13.26.8" style="background-color:#E6E6E6;padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.13.13.26.8.1" style="font-size:90%;background-color:#E6E6E6;">+0.79</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S6.T5.13.13.26.9" style="background-color:#E6E6E6;padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.13.13.26.9.1" style="font-size:90%;background-color:#E6E6E6;">+0.79</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S6.T5.13.13.26.10" style="background-color:#E6E6E6;padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.13.13.26.10.1" style="font-size:90%;background-color:#E6E6E6;">+0.44</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S6.T5.13.13.26.11" style="background-color:#E6E6E6;padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text" id="S6.T5.13.13.26.11.1" style="font-size:90%;background-color:#E6E6E6;">+0.41</span></td>
</tr>
</table>
</span></div>
</figure>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1"><span class="ltx_text" id="S6.p1.1.1" style="font-size:90%;">In this section, we focus on the following research questions:</span></p>
</div>
<div class="ltx_para ltx_noindent" id="S6.p2">
<p class="ltx_p" id="S6.p2.1"><span class="ltx_text ltx_font_bold" id="S6.p2.1.1" style="font-size:90%;">RQ1:</span><span class="ltx_text" id="S6.p2.1.2" style="font-size:90%;"> How do popular general-purpose LLMs perform on </span><span class="ltx_text ltx_font_bold ltx_font_italic" id="S6.p2.1.3" style="font-size:90%;">DQA</span><span class="ltx_text" id="S6.p2.1.4" style="font-size:90%;">?</span></p>
</div>
<div class="ltx_para ltx_noindent" id="S6.p3">
<p class="ltx_p" id="S6.p3.1"><span class="ltx_text ltx_font_bold" id="S6.p3.1.1" style="font-size:90%;">RQ2:</span><span class="ltx_text" id="S6.p3.1.2" style="font-size:90%;"> How do auxiliary modules on the testbed perform?</span></p>
</div>
<div class="ltx_para" id="S6.p4">
<p class="ltx_p" id="S6.p4.1"><span class="ltx_text" id="S6.p4.1.1" style="font-size:90%;">To answer RQ1, we comprehensively evaluate seven popular LLMs by </span><span class="ltx_text ltx_font_bold ltx_font_italic" id="S6.p4.1.2" style="font-size:90%;">DQA</span><span class="ltx_text" id="S6.p4.1.3" style="font-size:90%;"> in Section </span><a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#S6.SS2" style="font-size:90%;" title="6.2. LLMs Evaluation by DQA ‣ 6. Experiment ‣ 5.2. End-to-End Evaluation ‣ 5. DQA Evaluation Pipeline ‣ 4.5. Tool Invocation Generation ‣ 4. DQA Testbed ‣ 3.3. Instance-Specific Q&amp;A ‣ 3.2. Product-Specific Q&amp;A ‣ 3. DQA Dataset Generation ‣ Revolutionizing Database Q&amp;A with Large Language Models: Comprehensive Benchmark and Evaluation"><span class="ltx_text ltx_ref_tag">6.2</span></a><span class="ltx_text" id="S6.p4.1.4" style="font-size:90%;"> and construct fine-grained analysis in Section </span><a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#S6.SS3" style="font-size:90%;" title="6.3. In-depth Analysis of Database General Q&amp;A ‣ 6. Experiment ‣ 5.2. End-to-End Evaluation ‣ 5. DQA Evaluation Pipeline ‣ 4.5. Tool Invocation Generation ‣ 4. DQA Testbed ‣ 3.3. Instance-Specific Q&amp;A ‣ 3.2. Product-Specific Q&amp;A ‣ 3. DQA Dataset Generation ‣ Revolutionizing Database Q&amp;A with Large Language Models: Comprehensive Benchmark and Evaluation"><span class="ltx_text ltx_ref_tag">6.3</span></a><span class="ltx_text" id="S6.p4.1.5" style="font-size:90%;">. To answer RQ2, we validate pre-training and fine-tuning in Section </span><a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#S6.SS2" style="font-size:90%;" title="6.2. LLMs Evaluation by DQA ‣ 6. Experiment ‣ 5.2. End-to-End Evaluation ‣ 5. DQA Evaluation Pipeline ‣ 4.5. Tool Invocation Generation ‣ 4. DQA Testbed ‣ 3.3. Instance-Specific Q&amp;A ‣ 3.2. Product-Specific Q&amp;A ‣ 3. DQA Dataset Generation ‣ Revolutionizing Database Q&amp;A with Large Language Models: Comprehensive Benchmark and Evaluation"><span class="ltx_text ltx_ref_tag">6.2</span></a><span class="ltx_text" id="S6.p4.1.6" style="font-size:90%;">, QCR evaluation in Section </span><a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#S6.SS4" style="font-size:90%;" title="6.4. Question Classification Models Comparison ‣ 6. Experiment ‣ 5.2. End-to-End Evaluation ‣ 5. DQA Evaluation Pipeline ‣ 4.5. Tool Invocation Generation ‣ 4. DQA Testbed ‣ 3.3. Instance-Specific Q&amp;A ‣ 3.2. Product-Specific Q&amp;A ‣ 3. DQA Dataset Generation ‣ Revolutionizing Database Q&amp;A with Large Language Models: Comprehensive Benchmark and Evaluation"><span class="ltx_text ltx_ref_tag">6.4</span></a><span class="ltx_text" id="S6.p4.1.7" style="font-size:90%;">, RAG ablation in Section </span><a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#S6.SS5" style="font-size:90%;" title="6.5. Retrieval Augment Generation Ablation ‣ 6. Experiment ‣ 5.2. End-to-End Evaluation ‣ 5. DQA Evaluation Pipeline ‣ 4.5. Tool Invocation Generation ‣ 4. DQA Testbed ‣ 3.3. Instance-Specific Q&amp;A ‣ 3.2. Product-Specific Q&amp;A ‣ 3. DQA Dataset Generation ‣ Revolutionizing Database Q&amp;A with Large Language Models: Comprehensive Benchmark and Evaluation"><span class="ltx_text ltx_ref_tag">6.5</span></a><span class="ltx_text" id="S6.p4.1.8" style="font-size:90%;"> and TIG evaluation in Section </span><a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#S6.SS6" style="font-size:90%;" title="6.6. Tool Invocation Analysis ‣ 6. Experiment ‣ 5.2. End-to-End Evaluation ‣ 5. DQA Evaluation Pipeline ‣ 4.5. Tool Invocation Generation ‣ 4. DQA Testbed ‣ 3.3. Instance-Specific Q&amp;A ‣ 3.2. Product-Specific Q&amp;A ‣ 3. DQA Dataset Generation ‣ Revolutionizing Database Q&amp;A with Large Language Models: Comprehensive Benchmark and Evaluation"><span class="ltx_text ltx_ref_tag">6.6</span></a><span class="ltx_text" id="S6.p4.1.9" style="font-size:90%;">.</span></p>
</div>
<section class="ltx_subsection" id="S6.SS1">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">6.1. </span>Experimental Setup</h3>
<div class="ltx_para ltx_noindent" id="S6.SS1.p1">
<p class="ltx_p" id="S6.SS1.p1.1"><span class="ltx_text ltx_font_bold ltx_font_italic" id="S6.SS1.p1.1.1" style="font-size:90%;">DQA<span class="ltx_text ltx_font_upright" id="S6.SS1.p1.1.1.1"> details</span></span><span class="ltx_text" id="S6.SS1.p1.1.2" style="font-size:90%;">. </span><span class="ltx_text ltx_font_italic" id="S6.SS1.p1.1.3" style="font-size:90%;">(1) In product-specific subset</span><span class="ltx_text" id="S6.SS1.p1.1.4" style="font-size:90%;">, we choose the database product ‘openGauss’ and its latest documentation as of April 2024. The advantage of ’openGauss’ is that our evaluated LLMs have not shown any signs of being specifically trained on the latest detailed documentation of this product, effectively avoiding unfair evaluation due to potential data leakage. </span><span class="ltx_text ltx_font_italic" id="S6.SS1.p1.1.5" style="font-size:90%;">(2) In instance-specific subset</span><span class="ltx_text" id="S6.SS1.p1.1.6" style="font-size:90%;">, we created Q&amp;A pairs under widely recognized database benchmarks TPC-H, TPC-C and TPC-DS as examples.</span></p>
</div>
<div class="ltx_para ltx_noindent" id="S6.SS1.p2">
<p class="ltx_p" id="S6.SS1.p2.1"><span class="ltx_text ltx_font_bold" id="S6.SS1.p2.1.1" style="font-size:90%;">Testbed implementation</span><span class="ltx_text" id="S6.SS1.p2.1.2" style="font-size:90%;">. </span><span class="ltx_text ltx_font_italic" id="S6.SS1.p2.1.3" style="font-size:90%;">(1) QCR:</span><span class="ltx_text" id="S6.SS1.p2.1.4" style="font-size:90%;"> For all Chinese classifiers, pretrain model: chinese-xlnet-base, we set the batchsize as 512 and learning rate as 5e-4; for all English classifiers, pretrain model: xlnet-base-cased, we set the batchsize as 256 and learning rate as 5e-5. Each classifier trained for 30 epochs and saved the checkpoint performed best on validation sets. </span><span class="ltx_text ltx_font_italic" id="S6.SS1.p2.1.5" style="font-size:90%;">(2) RAG:</span><span class="ltx_text" id="S6.SS1.p2.1.6" style="font-size:90%;"> We set the text length to 250 characters per segment and the overlap length to 50 characters between adjacent texts in the knowledge base. For each query, up to 3 vectors from the knowledge base are matched with a similarity threshold of 0.5. We use L2 distance for similarity search and the default Flat index. </span><span class="ltx_text ltx_font_italic" id="S6.SS1.p2.1.7" style="font-size:90%;">(3) TIG:</span><span class="ltx_text" id="S6.SS1.p2.1.8" style="font-size:90%;"> We set the number of random tools in the tool pool (</span><span class="ltx_text ltx_font_typewriter" id="S6.SS1.p2.1.9" style="font-size:90%;">{{T}}</span><span class="ltx_text" id="S6.SS1.p2.1.10" style="font-size:90%;"> in prompt) to 4.</span></p>
</div>
<div class="ltx_para ltx_noindent" id="S6.SS1.p3">
<p class="ltx_p" id="S6.SS1.p3.1"><span class="ltx_text ltx_font_bold" id="S6.SS1.p3.1.1" style="font-size:90%;">LLM training</span><span class="ltx_text" id="S6.SS1.p3.1.2" style="font-size:90%;">. The LLM training server is a workstation equipped with eight A100 GPU cards. The pre-training phase comprises two epochs using the collected database-related data. The learning rate is 5e-5 and the batch size is 128. In the fine-tuning phase, General DB Q&amp;A, Product-specific Q&amp;A, Instance-specific Q&amp;A and DB-irrelevant Q&amp;A is assigned with weights 1:1.5:3:0.5, to account for their importance, data volume and training difficulty. The learning rate is 2e-5 and the batch size is 64.</span></p>
</div>
</section>
<section class="ltx_subsection" id="S6.SS2">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">6.2. </span>LLMs Evaluation by <span class="ltx_text ltx_font_bold ltx_font_italic" id="S6.SS2.1.1">DQA</span>
</h3>
<div class="ltx_para" id="S6.SS2.p1">
<p class="ltx_p" id="S6.SS2.p1.1"><span class="ltx_text" id="S6.SS2.p1.1.1" style="font-size:90%;">We implement and evaluate seven LLMs </span><span class="ltx_text ltx_font_bold" id="S6.SS2.p1.1.2" style="font-size:90%;">(1) GPT-4 <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">OpenAI</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#bib.bib25" title=""><span class="ltx_text" style="font-size:90%;">2023</span></a>)</cite></span><span class="ltx_text" id="S6.SS2.p1.1.3" style="font-size:90%;">, the most powerful large-scale LLM currently released by OpenAI, using the GPT-4-0125-preview version. </span><span class="ltx_text ltx_font_bold" id="S6.SS2.p1.1.4" style="font-size:90%;">(2) GPT-3.5 <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">OpenAI</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#bib.bib24" title=""><span class="ltx_text" style="font-size:90%;">2022</span></a>)</cite></span><span class="ltx_text" id="S6.SS2.p1.1.5" style="font-size:90%;">, the most popular large-scale LLM currently released by OpenAI, using the GPT-3.5-turbo-0125 version. </span><span class="ltx_text ltx_font_bold" id="S6.SS2.p1.1.6" style="font-size:90%;">(3) GLM-3 <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">Zeng et al</span><span class="ltx_text" style="font-size:90%;">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#bib.bib44" title=""><span class="ltx_text" style="font-size:90%;">2022</span></a>)</cite></span><span class="ltx_text" id="S6.SS2.p1.1.7" style="font-size:90%;">, a popular large-scale LLM for both Chinese and English, released by Zhipu AI. </span><span class="ltx_text ltx_font_bold" id="S6.SS2.p1.1.8" style="font-size:90%;">(4) Llama3-8B <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">Touvron et al</span><span class="ltx_text" style="font-size:90%;">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#bib.bib32" title=""><span class="ltx_text" style="font-size:90%;">2023a</span></a>)</cite></span><span class="ltx_text" id="S6.SS2.p1.1.9" style="font-size:90%;">, the latest mid-sized open-source LLM released by Meta AI, claimed to achieve state-of-the-art (SOTA) performance among mid-sized models, using the Llama3-8B-Instruct version. </span><span class="ltx_text ltx_font_bold" id="S6.SS2.p1.1.10" style="font-size:90%;">(5) Llama2-13B <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">Touvron et al</span><span class="ltx_text" style="font-size:90%;">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#bib.bib33" title=""><span class="ltx_text" style="font-size:90%;">2023b</span></a>)</cite></span><span class="ltx_text" id="S6.SS2.p1.1.11" style="font-size:90%;">, the most popular mid-sized open-source LLM released by Meta AI, using the Llama1-13B-Chat version. </span><span class="ltx_text ltx_font_bold" id="S6.SS2.p1.1.12" style="font-size:90%;">(6) Yuan2-2B <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">Wu et al</span><span class="ltx_text" style="font-size:90%;">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#bib.bib36" title=""><span class="ltx_text" style="font-size:90%;">2023</span></a>)</cite></span><span class="ltx_text" id="S6.SS2.p1.1.13" style="font-size:90%;">, a popular small-sized open-source model for both Chinese and English, released by IEIT Systems, using the Yuan2-2B-Februa version. </span><span class="ltx_text ltx_font_bold" id="S6.SS2.p1.1.14" style="font-size:90%;">(7) Baichuan2-13B <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">Yang et al</span><span class="ltx_text" style="font-size:90%;">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#bib.bib39" title=""><span class="ltx_text" style="font-size:90%;">2023</span></a>)</cite></span><span class="ltx_text" id="S6.SS2.p1.1.15" style="font-size:90%;">, a popular mid-sized open-source model for both Chinese and English, released by Baichuan Intelligence, using the Baichuan2-13B-Chat version.</span></p>
</div>
<div class="ltx_para" id="S6.SS2.p2">
<p class="ltx_p" id="S6.SS2.p2.1"><span class="ltx_text" id="S6.SS2.p2.1.1" style="font-size:90%;">The above LLMs are implemented on the proposed testbed with QCR, RAG and TIG. Limited by training time and cost, we only implement Baichuan2-13B with pre-training and fine-tuning on the testbed, leading to two additional LLM variants. </span><span class="ltx_text ltx_font_bold" id="S6.SS2.p2.1.2" style="font-size:90%;">(8) Baichuan2-13B-sft</span><span class="ltx_text" id="S6.SS2.p2.1.3" style="font-size:90%;">, which is a Baichuan2-13B variant fine-tuned as shown in Section </span><a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#S4.SS1" style="font-size:90%;" title="4.1. Pre-training and Fine-tuning ‣ 4. DQA Testbed ‣ 3.3. Instance-Specific Q&amp;A ‣ 3.2. Product-Specific Q&amp;A ‣ 3. DQA Dataset Generation ‣ Revolutionizing Database Q&amp;A with Large Language Models: Comprehensive Benchmark and Evaluation"><span class="ltx_text ltx_ref_tag">4.1</span></a><span class="ltx_text" id="S6.SS2.p2.1.4" style="font-size:90%;">. </span><span class="ltx_text ltx_font_bold" id="S6.SS2.p2.1.5" style="font-size:90%;">(9) Baichuan2-13B-cpt-sft</span><span class="ltx_text" id="S6.SS2.p2.1.6" style="font-size:90%;">, which is a Baichuan2-13B variant pre-trained and fine-tuned as shown in Section </span><a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#S4.SS1" style="font-size:90%;" title="4.1. Pre-training and Fine-tuning ‣ 4. DQA Testbed ‣ 3.3. Instance-Specific Q&amp;A ‣ 3.2. Product-Specific Q&amp;A ‣ 3. DQA Dataset Generation ‣ Revolutionizing Database Q&amp;A with Large Language Models: Comprehensive Benchmark and Evaluation"><span class="ltx_text ltx_ref_tag">4.1</span></a><span class="ltx_text" id="S6.SS2.p2.1.7" style="font-size:90%;">.</span></p>
</div>
<div class="ltx_para" id="S6.SS2.p3">
<p class="ltx_p" id="S6.SS2.p3.1"><span class="ltx_text" id="S6.SS2.p3.1.1" style="font-size:90%;">We compute the WinRate as described in Section </span><a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#S5" style="font-size:90%;" title="5. DQA Evaluation Pipeline ‣ 4.5. Tool Invocation Generation ‣ 4. DQA Testbed ‣ 3.3. Instance-Specific Q&amp;A ‣ 3.2. Product-Specific Q&amp;A ‣ 3. DQA Dataset Generation ‣ Revolutionizing Database Q&amp;A with Large Language Models: Comprehensive Benchmark and Evaluation"><span class="ltx_text ltx_ref_tag">5</span></a><span class="ltx_text" id="S6.SS2.p3.1.2" style="font-size:90%;"> of each LLM versus two competitors. </span><span class="ltx_text ltx_font_italic" id="S6.SS2.p3.1.3" style="font-size:90%;">(1) GPT-3.5-Turbo (Vanilla)</span><span class="ltx_text" id="S6.SS2.p3.1.4" style="font-size:90%;">: we input the user’s question to GPT-3.5-Turbo without employing any prompts strategy. This result focuses on demonstrating the difference between a dedicated database Q&amp;A system (the testbed) and typical LLM applications. </span><span class="ltx_text ltx_font_italic" id="S6.SS2.p3.1.5" style="font-size:90%;">(2) GPT-3.5-Turbo (Testbed)</span><span class="ltx_text" id="S6.SS2.p3.1.6" style="font-size:90%;">: we also equip GPT-3.5-Turbo on the testbed. This result emphasizes the inherent capability difference of each LLM. We have the following insights from Table </span><a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#S6.T5" style="font-size:90%;" title="Table 5 ‣ 6. Experiment ‣ 5.2. End-to-End Evaluation ‣ 5. DQA Evaluation Pipeline ‣ 4.5. Tool Invocation Generation ‣ 4. DQA Testbed ‣ 3.3. Instance-Specific Q&amp;A ‣ 3.2. Product-Specific Q&amp;A ‣ 3. DQA Dataset Generation ‣ Revolutionizing Database Q&amp;A with Large Language Models: Comprehensive Benchmark and Evaluation"><span class="ltx_text ltx_ref_tag">5</span></a><span class="ltx_text" id="S6.SS2.p3.1.7" style="font-size:90%;">.</span></p>
</div>
<div class="ltx_para ltx_noindent" id="S6.SS2.p4">
<p class="ltx_p" id="S6.SS2.p4.1"><span class="ltx_text ltx_font_bold" id="S6.SS2.p4.1.1" style="font-size:90%;">I1: Larger model sizes and richer pre-training data contribute to powerful DB general Q&amp;A. </span><span class="ltx_text" id="S6.SS2.p4.1.2" style="font-size:90%;"> GPT-4 has achieved SOTA performance on DB general questions. Generally, among LLMs proposed in the same period, larger model sizes tend to perform better. However, Llama3-8B challenges this trend. As stated in its technical report, Llama3-8B introduced an extensive amount of training data (15 trillion tokens) during pre-training, resulting in logarithmic-scale performance improvements. This enhancement is also evident on the </span><span class="ltx_text ltx_font_bold ltx_font_italic" id="S6.SS2.p4.1.3" style="font-size:90%;">DQA</span><span class="ltx_text" id="S6.SS2.p4.1.4" style="font-size:90%;"> dataset.</span></p>
</div>
<div class="ltx_para ltx_noindent" id="S6.SS2.p5">
<p class="ltx_p" id="S6.SS2.p5.1"><span class="ltx_text ltx_font_bold" id="S6.SS2.p5.1.1" style="font-size:90%;">I2: Domain-specific pre-training and fine-tuning can significantly improve model performance. </span><span class="ltx_text" id="S6.SS2.p5.1.2" style="font-size:90%;"> The testbed’s pre-training and fine-tuning have increased the performance of Baichuan2-13B on all question types. Specifically, the pretraining has increased the average performance by 0.28 to 0.39 (approximately 80% to 111%). The fine-tuning has brought significant improvements in answering all questions, with an average overall increase of 0.28 to 0.38 (approximately 80% to 136%). Notably, the fine-tuning stage targets to reinforce instruction adherence to specific prompt templates and gives the LLM a strong ability to follow specific instructions, outperforming GPT-4 on the instance-specific subset.</span></p>
</div>
<div class="ltx_para ltx_noindent" id="S6.SS2.p6">
<p class="ltx_p" id="S6.SS2.p6.1"><span class="ltx_text ltx_font_bold" id="S6.SS2.p6.1.1" style="font-size:90%;">I3: RAG and TIG on the testbed can enhance LLM performance in DB Q&amp;A.</span><span class="ltx_text" id="S6.SS2.p6.1.2" style="font-size:90%;"> Comparing the upper half with the bottom half of Table </span><a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#S6.T5" style="font-size:90%;" title="Table 5 ‣ 6. Experiment ‣ 5.2. End-to-End Evaluation ‣ 5. DQA Evaluation Pipeline ‣ 4.5. Tool Invocation Generation ‣ 4. DQA Testbed ‣ 3.3. Instance-Specific Q&amp;A ‣ 3.2. Product-Specific Q&amp;A ‣ 3. DQA Dataset Generation ‣ Revolutionizing Database Q&amp;A with Large Language Models: Comprehensive Benchmark and Evaluation"><span class="ltx_text ltx_ref_tag">5</span></a><span class="ltx_text" id="S6.SS2.p6.1.3" style="font-size:90%;">, we observe that the WinRate has generally decreased because GPT-3.5-Turbo is more competitive after being equipped with the testbed. It shows that, even for a sophisticated large-scale LLM, the RAG and TIG on the testbed can be beneficial. We will discuss the impact of the RAG and TIG modules in more detail in Section </span><a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#S6.SS5" style="font-size:90%;" title="6.5. Retrieval Augment Generation Ablation ‣ 6. Experiment ‣ 5.2. End-to-End Evaluation ‣ 5. DQA Evaluation Pipeline ‣ 4.5. Tool Invocation Generation ‣ 4. DQA Testbed ‣ 3.3. Instance-Specific Q&amp;A ‣ 3.2. Product-Specific Q&amp;A ‣ 3. DQA Dataset Generation ‣ Revolutionizing Database Q&amp;A with Large Language Models: Comprehensive Benchmark and Evaluation"><span class="ltx_text ltx_ref_tag">6.5</span></a><span class="ltx_text" id="S6.SS2.p6.1.4" style="font-size:90%;"> and </span><a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#S6.SS6" style="font-size:90%;" title="6.6. Tool Invocation Analysis ‣ 6. Experiment ‣ 5.2. End-to-End Evaluation ‣ 5. DQA Evaluation Pipeline ‣ 4.5. Tool Invocation Generation ‣ 4. DQA Testbed ‣ 3.3. Instance-Specific Q&amp;A ‣ 3.2. Product-Specific Q&amp;A ‣ 3. DQA Dataset Generation ‣ Revolutionizing Database Q&amp;A with Large Language Models: Comprehensive Benchmark and Evaluation"><span class="ltx_text ltx_ref_tag">6.6</span></a><span class="ltx_text" id="S6.SS2.p6.1.5" style="font-size:90%;">.</span></p>
</div>
<div class="ltx_para ltx_noindent" id="S6.SS2.p7">
<p class="ltx_p" id="S6.SS2.p7.1"><span class="ltx_text ltx_font_bold" id="S6.SS2.p7.1.1" style="font-size:90%;">I4: Small-size general LLM can hardly invoke DB tools</span><span class="ltx_text" id="S6.SS2.p7.1.2" style="font-size:90%;">. Among all tested models, Llama2 and Yuan2 lack pre-aligned instruction following, resulting in no tool usage capabilities. Although models like Baichuan2-13B claim to have instruction-following alignment, experimental results show that their model size still significantly limits their tool usage capabilities. This indicates that instruction enhancement for specific tool usage is necessary when deploying small to mid sized models. We will further discuss the accuracy of the TIG module in Section </span><a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#S6.SS6" style="font-size:90%;" title="6.6. Tool Invocation Analysis ‣ 6. Experiment ‣ 5.2. End-to-End Evaluation ‣ 5. DQA Evaluation Pipeline ‣ 4.5. Tool Invocation Generation ‣ 4. DQA Testbed ‣ 3.3. Instance-Specific Q&amp;A ‣ 3.2. Product-Specific Q&amp;A ‣ 3. DQA Dataset Generation ‣ Revolutionizing Database Q&amp;A with Large Language Models: Comprehensive Benchmark and Evaluation"><span class="ltx_text ltx_ref_tag">6.6</span></a><span class="ltx_text" id="S6.SS2.p7.1.3" style="font-size:90%;">.</span></p>
</div>
</section>
<section class="ltx_subsection" id="S6.SS3">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">6.3. </span>In-depth Analysis of Database General Q&amp;A</h3>
<div class="ltx_para" id="S6.SS3.p1">
<p class="ltx_p" id="S6.SS3.p1.1"><span class="ltx_text" id="S6.SS3.p1.1.1" style="font-size:90%;">In this section, we analyze the “DB general“ subset in </span><span class="ltx_text ltx_font_bold ltx_font_italic" id="S6.SS3.p1.1.2" style="font-size:90%;">DQA</span><span class="ltx_text" id="S6.SS3.p1.1.3" style="font-size:90%;"> from two perspectives. There are two types of questions in the subset, namely the subjective questions and the objective questions with multiple choices.</span></p>
</div>
<div class="ltx_para" id="S6.SS3.p2">
<p class="ltx_p" id="S6.SS3.p2.1"><span class="ltx_text" id="S6.SS3.p2.1.1" style="font-size:90%;">First, we report the WinRate of various LLMs in answering subjective questions. Specifically, we utilize GPT-4 to assign detailed labels to each question in the “DB general” subset, incorporating predefined few-shot labels from the prompt and allowing GPT-4 to generate new labels autonomously </span><span class="ltx_note ltx_role_footnote" id="footnote12"><sup class="ltx_note_mark">12</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">12</sup><span class="ltx_tag ltx_tag_note">12</span>The details of the classification prompt can be found at <a class="ltx_ref ltx_href" href="https://github.com/XMUDM/DQABench" title="">[link]</a></span></span></span><span class="ltx_text" id="S6.SS3.p2.1.2" style="font-size:90%;">. We identify eight most common labels: “Performance Monitoring and Tuning”, “Backup and Recovery”, “Query Optimization”, “Data Migration”, “Data Security”, “Database Design and Deployment”, “Data Analysis” and “SQL Programming”. These labels cover 93.79% of the questions in the “DB general” subset.</span></p>
</div>
<figure class="ltx_figure" id="S6.F5"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="323" id="S6.F5.g1" src="x5.png" width="830"/>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_figure">Figure 5. </span>(a) WinRate and (b) Multi-Choice Accuracy on “DB General” questions</figcaption>
</figure>
<div class="ltx_para" id="S6.SS3.p3">
<p class="ltx_p" id="S6.SS3.p3.1"><span class="ltx_text" id="S6.SS3.p3.1.1" style="font-size:90%;">The experimental results, illustrated in Figure </span><a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#S6.F5" style="font-size:90%;" title="Figure 5 ‣ 6.3. In-depth Analysis of Database General Q&amp;A ‣ 6. Experiment ‣ 5.2. End-to-End Evaluation ‣ 5. DQA Evaluation Pipeline ‣ 4.5. Tool Invocation Generation ‣ 4. DQA Testbed ‣ 3.3. Instance-Specific Q&amp;A ‣ 3.2. Product-Specific Q&amp;A ‣ 3. DQA Dataset Generation ‣ Revolutionizing Database Q&amp;A with Large Language Models: Comprehensive Benchmark and Evaluation"><span class="ltx_text ltx_ref_tag">5</span></a><span class="ltx_text" id="S6.SS3.p3.1.2" style="font-size:90%;"> (a)’s radar chart, lead to the following conclusions: (1) Numerically, the response capabilities of different models in each sub-field correlate positively with their model size and overall ability, with no model being highly specialized in any particular field. (2) In terms of shape proportion, the radar charts of GPT-3.5 and GPT-4 are similar, showing balanced capabilities across the eight aspects. In contrast, Llama2, Llama3, Baichuan2 and other models based on the llama architecture display a similar pattern, excelling in Performance Monitoring and Tuning but weaker in SQL Programming. This indicates that GPT series models are better at generating accurate SQL Programming instructions, while llama-based models excel in comprehensive subjective analysis.</span></p>
</div>
<div class="ltx_para" id="S6.SS3.p4">
<p class="ltx_p" id="S6.SS3.p4.1"><span class="ltx_text" id="S6.SS3.p4.1.1" style="font-size:90%;">Next, we report the Multiple-Choice Accuracy, which is measured on the objective questions. As shown in Figure </span><a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#S6.F5" style="font-size:90%;" title="Figure 5 ‣ 6.3. In-depth Analysis of Database General Q&amp;A ‣ 6. Experiment ‣ 5.2. End-to-End Evaluation ‣ 5. DQA Evaluation Pipeline ‣ 4.5. Tool Invocation Generation ‣ 4. DQA Testbed ‣ 3.3. Instance-Specific Q&amp;A ‣ 3.2. Product-Specific Q&amp;A ‣ 3. DQA Dataset Generation ‣ Revolutionizing Database Q&amp;A with Large Language Models: Comprehensive Benchmark and Evaluation"><span class="ltx_text ltx_ref_tag">5</span></a><span class="ltx_text" id="S6.SS3.p4.1.2" style="font-size:90%;"> (b), MCA aligns closely with the WinRate on subjective questions. This validates that questions in </span><span class="ltx_text ltx_font_bold ltx_font_italic" id="S6.SS3.p4.1.3" style="font-size:90%;">DQA</span><span class="ltx_text" id="S6.SS3.p4.1.4" style="font-size:90%;"> are set with an appropriate difficulty level and require a good understanding of DB knowledge to answer.</span></p>
</div>
</section>
<section class="ltx_subsection" id="S6.SS4">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">6.4. </span>Question Classification Models Comparison</h3>
<div class="ltx_para" id="S6.SS4.p1">
<p class="ltx_p" id="S6.SS4.p1.1"><span class="ltx_text" id="S6.SS4.p1.1.1" style="font-size:90%;">We use the testing data include DB-related questions from </span><span class="ltx_text ltx_font_bold ltx_font_italic" id="S6.SS4.p1.1.2" style="font-size:90%;">DQA</span><span class="ltx_text" id="S6.SS4.p1.1.3" style="font-size:90%;">, safe but DB-irrelevant questions from Alpaca </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S6.SS4.p1.1.4.1" style="font-size:90%;">(</span><span class="ltx_text" style="font-size:90%;">Taori et al</span><span class="ltx_text" style="font-size:90%;">.</span><span class="ltx_text" id="S6.SS4.p1.1.5.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#bib.bib31" title=""><span class="ltx_text" style="font-size:90%;">2023</span></a><span class="ltx_text" id="S6.SS4.p1.1.6.3" style="font-size:90%;">)</span></cite><span class="ltx_text" id="S6.SS4.p1.1.7" style="font-size:90%;"> and Longbench </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S6.SS4.p1.1.8.1" style="font-size:90%;">(</span><span class="ltx_text" style="font-size:90%;">Bai et al</span><span class="ltx_text" style="font-size:90%;">.</span><span class="ltx_text" id="S6.SS4.p1.1.9.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#bib.bib4" title=""><span class="ltx_text" style="font-size:90%;">2023b</span></a><span class="ltx_text" id="S6.SS4.p1.1.10.3" style="font-size:90%;">)</span></cite><span class="ltx_text" id="S6.SS4.p1.1.11" style="font-size:90%;"> and unsafe labeled questions from Safety-Prompts </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S6.SS4.p1.1.12.1" style="font-size:90%;">(</span><span class="ltx_text" style="font-size:90%;">Sun et al</span><span class="ltx_text" style="font-size:90%;">.</span><span class="ltx_text" id="S6.SS4.p1.1.13.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#bib.bib29" title=""><span class="ltx_text" style="font-size:90%;">2023b</span></a><span class="ltx_text" id="S6.SS4.p1.1.14.3" style="font-size:90%;">)</span></cite><span class="ltx_text" id="S6.SS4.p1.1.15" style="font-size:90%;"> and BeaverTails Evaluation </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S6.SS4.p1.1.16.1" style="font-size:90%;">(</span><span class="ltx_text" style="font-size:90%;">Ji et al</span><span class="ltx_text" style="font-size:90%;">.</span><span class="ltx_text" id="S6.SS4.p1.1.17.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#bib.bib15" title=""><span class="ltx_text" style="font-size:90%;">2023</span></a><span class="ltx_text" id="S6.SS4.p1.1.18.3" style="font-size:90%;">)</span></cite><span class="ltx_text" id="S6.SS4.p1.1.19" style="font-size:90%;"> </span><span class="ltx_note ltx_role_footnote" id="footnote13"><sup class="ltx_note_mark">13</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">13</sup><span class="ltx_tag ltx_tag_note">13</span>The sources and statistics of the dataset are detailed in <a class="ltx_ref ltx_href" href="https://github.com/XMUDM/DQABench" title="">[link]</a>.</span></span></span><span class="ltx_text" id="S6.SS4.p1.1.20" style="font-size:90%;">. The F1 score for each category, average accuracy and response latency deployed on a workstation with a RTX-3090 GPU card are shown in Table </span><a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#S6.T6" style="font-size:90%;" title="Table 6 ‣ 6.4. Question Classification Models Comparison ‣ 6. Experiment ‣ 5.2. End-to-End Evaluation ‣ 5. DQA Evaluation Pipeline ‣ 4.5. Tool Invocation Generation ‣ 4. DQA Testbed ‣ 3.3. Instance-Specific Q&amp;A ‣ 3.2. Product-Specific Q&amp;A ‣ 3. DQA Dataset Generation ‣ Revolutionizing Database Q&amp;A with Large Language Models: Comprehensive Benchmark and Evaluation"><span class="ltx_text ltx_ref_tag">6</span></a><span class="ltx_text" id="S6.SS4.p1.1.21" style="font-size:90%;">.</span></p>
</div>
<figure class="ltx_table" id="S6.T6">
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 6. </span>Classification Result by Different Methods</figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S6.T6.3">
<tr class="ltx_tr" id="S6.T6.3.1">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_r ltx_border_tt" id="S6.T6.3.1.1" rowspan="2" style="padding-left:0.9pt;padding-right:0.9pt;"><span class="ltx_text ltx_font_bold" id="S6.T6.3.1.1.1" style="font-size:90%;">Method</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_border_tt" id="S6.T6.3.1.2" style="padding-left:0.9pt;padding-right:0.9pt;"></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_border_tt" id="S6.T6.3.1.3" style="padding-left:0.9pt;padding-right:0.9pt;"></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_tt" id="S6.T6.3.1.4" style="padding-left:0.9pt;padding-right:0.9pt;"><span class="ltx_text ltx_font_bold" id="S6.T6.3.1.4.1" style="font-size:90%;">F1-score</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_border_tt" id="S6.T6.3.1.5" style="padding-left:0.9pt;padding-right:0.9pt;"></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_border_r ltx_border_tt" id="S6.T6.3.1.6" style="padding-left:0.9pt;padding-right:0.9pt;"></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_tt" id="S6.T6.3.1.7" rowspan="2" style="padding-left:0.9pt;padding-right:0.9pt;"><span class="ltx_text ltx_font_bold" id="S6.T6.3.1.7.1" style="font-size:90%;">ACC</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_tt" id="S6.T6.3.1.8" rowspan="2" style="padding-left:0.9pt;padding-right:0.9pt;"><span class="ltx_text ltx_font_bold" id="S6.T6.3.1.8.1" style="font-size:90%;">Latency</span></td>
</tr>
<tr class="ltx_tr" id="S6.T6.3.2">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S6.T6.3.2.1" style="padding-left:0.9pt;padding-right:0.9pt;"><span class="ltx_text ltx_font_bold" id="S6.T6.3.2.1.1" style="font-size:90%;">Unsafe</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S6.T6.3.2.2" style="padding-left:0.9pt;padding-right:0.9pt;"><span class="ltx_text ltx_font_bold" id="S6.T6.3.2.2.1" style="font-size:90%;">General</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S6.T6.3.2.3" style="padding-left:0.9pt;padding-right:0.9pt;"><span class="ltx_text ltx_font_bold" id="S6.T6.3.2.3.1" style="font-size:90%;">Gauss</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S6.T6.3.2.4" style="padding-left:0.9pt;padding-right:0.9pt;"><span class="ltx_text ltx_font_bold" id="S6.T6.3.2.4.1" style="font-size:90%;">Tool</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" id="S6.T6.3.2.5" style="padding-left:0.9pt;padding-right:0.9pt;"><span class="ltx_text ltx_font_bold" id="S6.T6.3.2.5.1" style="font-size:90%;">No-DB</span></td>
</tr>
<tr class="ltx_tr" id="S6.T6.3.3">
<td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t" colspan="8" id="S6.T6.3.3.1" style="padding-left:0.9pt;padding-right:0.9pt;"><span class="ltx_text ltx_font_bold" id="S6.T6.3.3.1.1" style="font-size:90%;">ZH</span></td>
</tr>
<tr class="ltx_tr" id="S6.T6.3.4">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_r ltx_border_t" id="S6.T6.3.4.1" style="padding-left:0.9pt;padding-right:0.9pt;"><span class="ltx_text" id="S6.T6.3.4.1.1" style="font-size:90%;">GPT-4</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S6.T6.3.4.2" style="padding-left:0.9pt;padding-right:0.9pt;"><span class="ltx_text" id="S6.T6.3.4.2.1" style="font-size:90%;">0.77</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S6.T6.3.4.3" style="padding-left:0.9pt;padding-right:0.9pt;"><span class="ltx_text" id="S6.T6.3.4.3.1" style="font-size:90%;">0.48</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S6.T6.3.4.4" style="padding-left:0.9pt;padding-right:0.9pt;"><span class="ltx_text" id="S6.T6.3.4.4.1" style="font-size:90%;">0.47</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S6.T6.3.4.5" style="padding-left:0.9pt;padding-right:0.9pt;"><span class="ltx_text" id="S6.T6.3.4.5.1" style="font-size:90%;">0.25</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t" id="S6.T6.3.4.6" style="padding-left:0.9pt;padding-right:0.9pt;"><span class="ltx_text" id="S6.T6.3.4.6.1" style="font-size:90%;">0.59</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t" id="S6.T6.3.4.7" style="padding-left:0.9pt;padding-right:0.9pt;"><span class="ltx_text ltx_font_bold" id="S6.T6.3.4.7.1" style="font-size:90%;">0.55</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S6.T6.3.4.8" style="padding-left:0.9pt;padding-right:0.9pt;"><span class="ltx_text ltx_font_bold" id="S6.T6.3.4.8.1" style="font-size:90%;">2.64s</span></td>
</tr>
<tr class="ltx_tr" id="S6.T6.3.5">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_r" id="S6.T6.3.5.1" style="padding-left:0.9pt;padding-right:0.9pt;"><span class="ltx_text" id="S6.T6.3.5.1.1" style="font-size:90%;">Classifier</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S6.T6.3.5.2" style="padding-left:0.9pt;padding-right:0.9pt;"><span class="ltx_text" id="S6.T6.3.5.2.1" style="font-size:90%;">0.95</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S6.T6.3.5.3" style="padding-left:0.9pt;padding-right:0.9pt;"><span class="ltx_text" id="S6.T6.3.5.3.1" style="font-size:90%;">0.89</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S6.T6.3.5.4" style="padding-left:0.9pt;padding-right:0.9pt;"><span class="ltx_text" id="S6.T6.3.5.4.1" style="font-size:90%;">0.92</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S6.T6.3.5.5" style="padding-left:0.9pt;padding-right:0.9pt;"><span class="ltx_text" id="S6.T6.3.5.5.1" style="font-size:90%;">0.91</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" id="S6.T6.3.5.6" style="padding-left:0.9pt;padding-right:0.9pt;"><span class="ltx_text" id="S6.T6.3.5.6.1" style="font-size:90%;">0.79</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" id="S6.T6.3.5.7" style="padding-left:0.9pt;padding-right:0.9pt;"><span class="ltx_text ltx_font_bold" id="S6.T6.3.5.7.1" style="font-size:90%;">0.90</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S6.T6.3.5.8" style="padding-left:0.9pt;padding-right:0.9pt;"><span class="ltx_text ltx_font_bold" id="S6.T6.3.5.8.1" style="font-size:90%;color:#BF0040;">0.39s</span></td>
</tr>
<tr class="ltx_tr" id="S6.T6.3.6">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_r" id="S6.T6.3.6.1" style="padding-left:0.9pt;padding-right:0.9pt;"><span class="ltx_text" id="S6.T6.3.6.1.1" style="font-size:90%;">Hierarchical</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S6.T6.3.6.2" style="padding-left:0.9pt;padding-right:0.9pt;"><span class="ltx_text" id="S6.T6.3.6.2.1" style="font-size:90%;">0.95</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S6.T6.3.6.3" style="padding-left:0.9pt;padding-right:0.9pt;"><span class="ltx_text" id="S6.T6.3.6.3.1" style="font-size:90%;">0.91</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S6.T6.3.6.4" style="padding-left:0.9pt;padding-right:0.9pt;"><span class="ltx_text" id="S6.T6.3.6.4.1" style="font-size:90%;">0.98</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S6.T6.3.6.5" style="padding-left:0.9pt;padding-right:0.9pt;"><span class="ltx_text" id="S6.T6.3.6.5.1" style="font-size:90%;">0.99</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" id="S6.T6.3.6.6" style="padding-left:0.9pt;padding-right:0.9pt;"><span class="ltx_text" id="S6.T6.3.6.6.1" style="font-size:90%;">0.87</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" id="S6.T6.3.6.7" style="padding-left:0.9pt;padding-right:0.9pt;"><span class="ltx_text ltx_font_bold" id="S6.T6.3.6.7.1" style="font-size:90%;color:#BF0040;">0.94</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S6.T6.3.6.8" style="padding-left:0.9pt;padding-right:0.9pt;"><span class="ltx_text ltx_font_bold" id="S6.T6.3.6.8.1" style="font-size:90%;">0.68s</span></td>
</tr>
<tr class="ltx_tr" id="S6.T6.3.7">
<td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t" colspan="8" id="S6.T6.3.7.1" style="padding-left:0.9pt;padding-right:0.9pt;"><span class="ltx_text ltx_font_bold" id="S6.T6.3.7.1.1" style="font-size:90%;">EN</span></td>
</tr>
<tr class="ltx_tr" id="S6.T6.3.8">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_r ltx_border_t" id="S6.T6.3.8.1" style="padding-left:0.9pt;padding-right:0.9pt;"><span class="ltx_text" id="S6.T6.3.8.1.1" style="font-size:90%;">GPT-4</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S6.T6.3.8.2" style="padding-left:0.9pt;padding-right:0.9pt;"><span class="ltx_text" id="S6.T6.3.8.2.1" style="font-size:90%;">0.80</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S6.T6.3.8.3" style="padding-left:0.9pt;padding-right:0.9pt;"><span class="ltx_text" id="S6.T6.3.8.3.1" style="font-size:90%;">0.57</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S6.T6.3.8.4" style="padding-left:0.9pt;padding-right:0.9pt;"><span class="ltx_text" id="S6.T6.3.8.4.1" style="font-size:90%;">0.37</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S6.T6.3.8.5" style="padding-left:0.9pt;padding-right:0.9pt;"><span class="ltx_text" id="S6.T6.3.8.5.1" style="font-size:90%;">0.49</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t" id="S6.T6.3.8.6" style="padding-left:0.9pt;padding-right:0.9pt;"><span class="ltx_text" id="S6.T6.3.8.6.1" style="font-size:90%;">0.69</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t" id="S6.T6.3.8.7" style="padding-left:0.9pt;padding-right:0.9pt;"><span class="ltx_text ltx_font_bold" id="S6.T6.3.8.7.1" style="font-size:90%;">0.63</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S6.T6.3.8.8" style="padding-left:0.9pt;padding-right:0.9pt;"><span class="ltx_text ltx_font_bold" id="S6.T6.3.8.8.1" style="font-size:90%;">2.61s</span></td>
</tr>
<tr class="ltx_tr" id="S6.T6.3.9">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_r" id="S6.T6.3.9.1" style="padding-left:0.9pt;padding-right:0.9pt;"><span class="ltx_text" id="S6.T6.3.9.1.1" style="font-size:90%;">Classifier</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S6.T6.3.9.2" style="padding-left:0.9pt;padding-right:0.9pt;"><span class="ltx_text" id="S6.T6.3.9.2.1" style="font-size:90%;">0.91</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S6.T6.3.9.3" style="padding-left:0.9pt;padding-right:0.9pt;"><span class="ltx_text" id="S6.T6.3.9.3.1" style="font-size:90%;">0.92</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S6.T6.3.9.4" style="padding-left:0.9pt;padding-right:0.9pt;"><span class="ltx_text" id="S6.T6.3.9.4.1" style="font-size:90%;">0.81</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S6.T6.3.9.5" style="padding-left:0.9pt;padding-right:0.9pt;"><span class="ltx_text" id="S6.T6.3.9.5.1" style="font-size:90%;">0.90</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" id="S6.T6.3.9.6" style="padding-left:0.9pt;padding-right:0.9pt;"><span class="ltx_text" id="S6.T6.3.9.6.1" style="font-size:90%;">0.79</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" id="S6.T6.3.9.7" style="padding-left:0.9pt;padding-right:0.9pt;"><span class="ltx_text ltx_font_bold" id="S6.T6.3.9.7.1" style="font-size:90%;">0.87</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S6.T6.3.9.8" style="padding-left:0.9pt;padding-right:0.9pt;"><span class="ltx_text ltx_font_bold" id="S6.T6.3.9.8.1" style="font-size:90%;color:#BF0040;">0.37s</span></td>
</tr>
<tr class="ltx_tr" id="S6.T6.3.10">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_bb ltx_border_r" id="S6.T6.3.10.1" style="padding-left:0.9pt;padding-right:0.9pt;"><span class="ltx_text" id="S6.T6.3.10.1.1" style="font-size:90%;">Hierarchical</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" id="S6.T6.3.10.2" style="padding-left:0.9pt;padding-right:0.9pt;"><span class="ltx_text" id="S6.T6.3.10.2.1" style="font-size:90%;">0.92</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" id="S6.T6.3.10.3" style="padding-left:0.9pt;padding-right:0.9pt;"><span class="ltx_text" id="S6.T6.3.10.3.1" style="font-size:90%;">0.97</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" id="S6.T6.3.10.4" style="padding-left:0.9pt;padding-right:0.9pt;"><span class="ltx_text" id="S6.T6.3.10.4.1" style="font-size:90%;">0.88</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" id="S6.T6.3.10.5" style="padding-left:0.9pt;padding-right:0.9pt;"><span class="ltx_text" id="S6.T6.3.10.5.1" style="font-size:90%;">0.93</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_r" id="S6.T6.3.10.6" style="padding-left:0.9pt;padding-right:0.9pt;"><span class="ltx_text" id="S6.T6.3.10.6.1" style="font-size:90%;">0.91</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_r" id="S6.T6.3.10.7" style="padding-left:0.9pt;padding-right:0.9pt;"><span class="ltx_text ltx_font_bold" id="S6.T6.3.10.7.1" style="font-size:90%;color:#BF0040;">0.92</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" id="S6.T6.3.10.8" style="padding-left:0.9pt;padding-right:0.9pt;"><span class="ltx_text ltx_font_bold" id="S6.T6.3.10.8.1" style="font-size:90%;">0.67s</span></td>
</tr>
</table>
</figure>
<div class="ltx_para" id="S6.SS4.p2">
<p class="ltx_p" id="S6.SS4.p2.1"><span class="ltx_text" id="S6.SS4.p2.1.1" style="font-size:90%;">From the experimental results, we have the following conclusions: (1) Training a dedicated model for safety filtering and classification is essential. Even with the most advanced LLM, GPT-4, the accuracy and latency in classification are inferior to those of a well-trained small model. (2) There is a trade-off between latency and performance across different small models. As shown in Table </span><a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#S6.T6" style="font-size:90%;" title="Table 6 ‣ 6.4. Question Classification Models Comparison ‣ 6. Experiment ‣ 5.2. End-to-End Evaluation ‣ 5. DQA Evaluation Pipeline ‣ 4.5. Tool Invocation Generation ‣ 4. DQA Testbed ‣ 3.3. Instance-Specific Q&amp;A ‣ 3.2. Product-Specific Q&amp;A ‣ 3. DQA Dataset Generation ‣ Revolutionizing Database Q&amp;A with Large Language Models: Comprehensive Benchmark and Evaluation"><span class="ltx_text ltx_ref_tag">6</span></a><span class="ltx_text" id="S6.SS4.p2.1.2" style="font-size:90%;">, the hierarchical classifier can achieve approximately a 0.05 performance improvement at the cost of 300ms.</span></p>
</div>
</section>
<section class="ltx_subsection" id="S6.SS5">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">6.5. </span>Retrieval Augment Generation Ablation</h3>
<div class="ltx_para" id="S6.SS5.p1">
<p class="ltx_p" id="S6.SS5.p1.1"><span class="ltx_text" id="S6.SS5.p1.1.1" style="font-size:90%;">The RAG module has achieved a P@3 result of </span><math alttext="0.82" class="ltx_Math" display="inline" id="S6.SS5.p1.1.m1.1"><semantics id="S6.SS5.p1.1.m1.1a"><mn id="S6.SS5.p1.1.m1.1.1" mathsize="90%" xref="S6.SS5.p1.1.m1.1.1.cmml">0.82</mn><annotation-xml encoding="MathML-Content" id="S6.SS5.p1.1.m1.1b"><cn id="S6.SS5.p1.1.m1.1.1.cmml" type="float" xref="S6.SS5.p1.1.m1.1.1">0.82</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS5.p1.1.m1.1c">0.82</annotation><annotation encoding="application/x-llamapun" id="S6.SS5.p1.1.m1.1d">0.82</annotation></semantics></math><span class="ltx_text" id="S6.SS5.p1.1.2" style="font-size:90%;">, and all records have at least one correct retrieval out of the top three results, demonstrating the retrieval effectiveness of the popular RAG method.</span></p>
</div>
<div class="ltx_para" id="S6.SS5.p2">
<p class="ltx_p" id="S6.SS5.p2.1"><span class="ltx_text" id="S6.SS5.p2.1.1" style="font-size:90%;">To further investigate the impact of the RAG module on DB Q&amp;A, we conduct an ablation study on the RAG module. Specifically, based on the experiments described in Section </span><a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#S6.SS2" style="font-size:90%;" title="6.2. LLMs Evaluation by DQA ‣ 6. Experiment ‣ 5.2. End-to-End Evaluation ‣ 5. DQA Evaluation Pipeline ‣ 4.5. Tool Invocation Generation ‣ 4. DQA Testbed ‣ 3.3. Instance-Specific Q&amp;A ‣ 3.2. Product-Specific Q&amp;A ‣ 3. DQA Dataset Generation ‣ Revolutionizing Database Q&amp;A with Large Language Models: Comprehensive Benchmark and Evaluation"><span class="ltx_text ltx_ref_tag">6.2</span></a><span class="ltx_text" id="S6.SS5.p2.1.2" style="font-size:90%;">, we conduct experiments for the “product-specific” sub-dataset without the external knowledge provided by the RAG module. The WinRate results are shown in Figure </span><a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#S6.F6" style="font-size:90%;" title="Figure 6 ‣ 6.5. Retrieval Augment Generation Ablation ‣ 6. Experiment ‣ 5.2. End-to-End Evaluation ‣ 5. DQA Evaluation Pipeline ‣ 4.5. Tool Invocation Generation ‣ 4. DQA Testbed ‣ 3.3. Instance-Specific Q&amp;A ‣ 3.2. Product-Specific Q&amp;A ‣ 3. DQA Dataset Generation ‣ Revolutionizing Database Q&amp;A with Large Language Models: Comprehensive Benchmark and Evaluation"><span class="ltx_text ltx_ref_tag">6</span></a><span class="ltx_text" id="S6.SS5.p2.1.3" style="font-size:90%;">.</span></p>
</div>
<figure class="ltx_figure" id="S6.F6"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="705" id="S6.F6.g1" src="x6.png" width="805"/>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_figure">Figure 6. </span>WinRate v.s. GPT-3.5 (Vanilla) with and without RAG</figcaption>
</figure>
<div class="ltx_para" id="S6.SS5.p3">
<p class="ltx_p" id="S6.SS5.p3.1"><span class="ltx_text" id="S6.SS5.p3.1.1" style="font-size:90%;">From the experimental results, we can observe the following: (1) The RAG module significantly enhances the performance of general-purpose LLMs of any model size, consistent with the analysis in Section </span><a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#S6.SS2" style="font-size:90%;" title="6.2. LLMs Evaluation by DQA ‣ 6. Experiment ‣ 5.2. End-to-End Evaluation ‣ 5. DQA Evaluation Pipeline ‣ 4.5. Tool Invocation Generation ‣ 4. DQA Testbed ‣ 3.3. Instance-Specific Q&amp;A ‣ 3.2. Product-Specific Q&amp;A ‣ 3. DQA Dataset Generation ‣ Revolutionizing Database Q&amp;A with Large Language Models: Comprehensive Benchmark and Evaluation"><span class="ltx_text ltx_ref_tag">6.2</span></a><span class="ltx_text" id="S6.SS5.p3.1.2" style="font-size:90%;">. (2) The RAG module can boost the performance of small-sized models several times (e.g., 2.4x for Llama2), demonstrating its substantial value for edge deployment models. (3) The RAG module offers smaller performance improvements for models like Baichuan2-sft fine-tuned with domain knowledge in databases. This indicates a high degree of overlap between the improvements from model fine-tuning and those from the RAG module, suggesting that deploying either one is sufficient within a limited budget.</span></p>
</div>
</section>
<section class="ltx_subsection" id="S6.SS6">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">6.6. </span>Tool Invocation Analysis</h3>
<div class="ltx_para" id="S6.SS6.p1">
<p class="ltx_p" id="S6.SS6.p1.1"><span class="ltx_text" id="S6.SS6.p1.1.1" style="font-size:90%;">In the experimental setup described in Section </span><a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#S6.SS2" style="font-size:90%;" title="6.2. LLMs Evaluation by DQA ‣ 6. Experiment ‣ 5.2. End-to-End Evaluation ‣ 5. DQA Evaluation Pipeline ‣ 4.5. Tool Invocation Generation ‣ 4. DQA Testbed ‣ 3.3. Instance-Specific Q&amp;A ‣ 3.2. Product-Specific Q&amp;A ‣ 3. DQA Dataset Generation ‣ Revolutionizing Database Q&amp;A with Large Language Models: Comprehensive Benchmark and Evaluation"><span class="ltx_text ltx_ref_tag">6.2</span></a><span class="ltx_text" id="S6.SS6.p1.1.2" style="font-size:90%;">, we further evaluated LLMs on the “instance-specific” sub-dataset for Tool Selection Accuracy (TSA) and Tool Format Accuracy (TFA). The experimental results are shown in Figure </span><a class="ltx_ref" href="https://arxiv.org/html/2409.04475v1#S6.F7" style="font-size:90%;" title="Figure 7 ‣ 6.6. Tool Invocation Analysis ‣ 6. Experiment ‣ 5.2. End-to-End Evaluation ‣ 5. DQA Evaluation Pipeline ‣ 4.5. Tool Invocation Generation ‣ 4. DQA Testbed ‣ 3.3. Instance-Specific Q&amp;A ‣ 3.2. Product-Specific Q&amp;A ‣ 3. DQA Dataset Generation ‣ Revolutionizing Database Q&amp;A with Large Language Models: Comprehensive Benchmark and Evaluation"><span class="ltx_text ltx_ref_tag">7</span></a><span class="ltx_text" id="S6.SS6.p1.1.3" style="font-size:90%;">. From the experimental results, we can observe the following: (1) For general-purpose LLMs, the ability to select and correctly format tools is strongly correlated with their overall capabilities. (2) Specific instruction-following fine-tuning is crucial. Llama-2 and Yuan-2, which have not undergone any instruction-following fine-tuning, lack any tool-invocation abilities. In contrast, the Baichuan2-sft model, fine-tuned with specific tool instruction following, achieves excellent performance. (3) The tool accuracy of Baichuan-2-sft even surpasses that of GPT-4. This suggests that in scenarios with limited tools (strong generalization in tool invocation is not required), specific tool instruction-following fine-tuning can significantly adapt LLMs to the task. (4) Further analysis reveals that in WinRate metrics, the expert evaluator GPT-4 consistently favored responses with successful tool calls as winners. This indicates a strong preference for customized answers utilizing tools, not only among humans but also in LLMs.</span></p>
</div>
<figure class="ltx_figure" id="S6.F7"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="710" id="S6.F7.g1" src="x7.png" width="789"/>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_figure">Figure 7. </span>Performance of TIG by different LLMs</figcaption>
</figure>
<section class="ltx_section" id="S7">
<h2 class="ltx_title ltx_title_section" style="font-size:90%;">
<span class="ltx_tag ltx_tag_section">7. </span>Conclusion</h2>
<div class="ltx_para" id="S7.p1">
<p class="ltx_p" id="S7.p1.1"><span class="ltx_text" id="S7.p1.1.1" style="font-size:90%;">In this paper, we proposed the first comprehensive database Q&amp;A benchmark </span><span class="ltx_text ltx_font_bold ltx_font_italic" id="S7.p1.1.2" style="font-size:90%;">DQA</span><span class="ltx_text" id="S7.p1.1.3" style="font-size:90%;">. First, we proposed a comprehensive dataset, which includes an extensive Q&amp;A dataset and corresponding generation methods. Second, we proposed a complete testbed that implements the entire database Q&amp;A workflow, incorporating various auxiliary modules for DB Q&amp;A. Third, we propose a complete evaluation pipeline to ensure comprehensiveness, accuracy and fairness of evaluation. Finally, using </span><span class="ltx_text ltx_font_bold ltx_font_italic" id="S7.p1.1.4" style="font-size:90%;">DQA</span><span class="ltx_text" id="S7.p1.1.5" style="font-size:90%;">, we conducted a comprehensive evaluation to showcase DB Q&amp;A ability of seven general-purpose LLMs and two variants based on pretraining and fine-tuning, while also assessing the impact of modules such as QCR, RAG and TIG on database Q&amp;A performance. We hope our benchmark and findings will better guide the future development of LLM-based database Q&amp;A research.</span></p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography" style="font-size:90%;">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib1.2.2.1" style="font-size:90%;">(1)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib1.3.1" style="font-size:90%;">
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib2.7.7.1" style="font-size:90%;">Anil et al</span><span class="ltx_text" id="bib.bib2.8.8.2" style="font-size:90%;">.</span><span class="ltx_text" id="bib.bib2.9.9.3" style="font-size:90%;"> (2023)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib2.11.1" style="font-size:90%;">
Rohan Anil, Andrew M Dai, Orhan Firat, Melvin Johnson, Dmitry Lepikhin, Alexandre Passos, Siamak Shakeri, Emanuel Taropa, Paige Bailey, Zhifeng Chen, et al</span><span class="ltx_text" id="bib.bib2.12.2" style="font-size:90%;">.</span><span class="ltx_text" id="bib.bib2.13.3" style="font-size:90%;"> 2023.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib2.14.1" style="font-size:90%;">Palm 2 technical report.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib2.15.1" style="font-size:90%;">arXiv preprint arXiv:2305.10403</em><span class="ltx_text" id="bib.bib2.16.2" style="font-size:90%;"> (2023).
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib3.7.7.1" style="font-size:90%;">Bai et al</span><span class="ltx_text" id="bib.bib3.8.8.2" style="font-size:90%;">.</span><span class="ltx_text" id="bib.bib3.9.9.3" style="font-size:90%;"> (2023a)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib3.11.1" style="font-size:90%;">
Jinze Bai, Shuai Bai, Yunfei Chu, Zeyu Cui, Kai Dang, Xiaodong Deng, Yang Fan, Wenbin Ge, Yu Han, Fei Huang, et al</span><span class="ltx_text" id="bib.bib3.12.2" style="font-size:90%;">.</span><span class="ltx_text" id="bib.bib3.13.3" style="font-size:90%;"> 2023a.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib3.14.1" style="font-size:90%;">Qwen technical report.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib3.15.1" style="font-size:90%;">arXiv preprint arXiv:2309.16609</em><span class="ltx_text" id="bib.bib3.16.2" style="font-size:90%;"> (2023).
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib4.6.6.1" style="font-size:90%;">Bai et al</span><span class="ltx_text" id="bib.bib4.7.7.2" style="font-size:90%;">.</span><span class="ltx_text" id="bib.bib4.8.8.3" style="font-size:90%;"> (2023b)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib4.10.1" style="font-size:90%;">
Yushi Bai, Xin Lv, Jiajie Zhang, Hongchang Lyu, Jiankai Tang, Zhidian Huang, Zhengxiao Du, Xiao Liu, Aohan Zeng, Lei Hou, Yuxiao Dong, Jie Tang, and Juanzi Li. 2023b.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib4.11.1" style="font-size:90%;">LongBench: A Bilingual, Multitask Benchmark for Long Context Understanding.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib4.12.1" style="font-size:90%;">arXiv preprint arXiv:2308.14508</em><span class="ltx_text" id="bib.bib4.13.2" style="font-size:90%;"> (2023).
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib5.6.6.1" style="font-size:90%;">Bi et al</span><span class="ltx_text" id="bib.bib5.7.7.2" style="font-size:90%;">.</span><span class="ltx_text" id="bib.bib5.8.8.3" style="font-size:90%;"> (2023)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib5.10.1" style="font-size:90%;">
Kaifeng Bi, Lingxi Xie, Hengheng Zhang, Xin Chen, Xiaotao Gu, and Qi Tian. 2023.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib5.11.1" style="font-size:90%;">Accurate medium-range global weather forecasting with 3D neural networks.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib5.12.1" style="font-size:90%;">Nature</em><span class="ltx_text" id="bib.bib5.13.2" style="font-size:90%;"> 619, 7970 (2023), 533–538.
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib6.5.5.1" style="font-size:90%;">Chase (2022)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib6.7.1" style="font-size:90%;">
Harrison Chase. 2022.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib6.8.1" style="font-size:90%;">LangChain.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib6.9.1" style="font-size:90%;">(2022).
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib6.10.1" style="font-size:90%;">
</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/hwchase17/langchain" style="font-size:90%;" title="">https://github.com/hwchase17/langchain</a><span class="ltx_text" id="bib.bib6.11.2" style="font-size:90%;">
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib7.7.7.1" style="font-size:90%;">Cheng et al</span><span class="ltx_text" id="bib.bib7.8.8.2" style="font-size:90%;">.</span><span class="ltx_text" id="bib.bib7.9.9.3" style="font-size:90%;"> (2022)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib7.11.1" style="font-size:90%;">
Zhoujun Cheng, Tianbao Xie, Peng Shi, Chengzu Li, Rahul Nadkarni, Yushi Hu, Caiming Xiong, Dragomir Radev, Mari Ostendorf, Luke Zettlemoyer, et al</span><span class="ltx_text" id="bib.bib7.12.2" style="font-size:90%;">.</span><span class="ltx_text" id="bib.bib7.13.3" style="font-size:90%;"> 2022.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib7.14.1" style="font-size:90%;">Binding language models in symbolic languages.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib7.15.1" style="font-size:90%;">arXiv preprint arXiv:2210.02875</em><span class="ltx_text" id="bib.bib7.16.2" style="font-size:90%;"> (2022).
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib8.7.7.1" style="font-size:90%;">Colombo et al</span><span class="ltx_text" id="bib.bib8.8.8.2" style="font-size:90%;">.</span><span class="ltx_text" id="bib.bib8.9.9.3" style="font-size:90%;"> (2024)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib8.11.1" style="font-size:90%;">
Pierre Colombo, Telmo Pessoa Pires, Malik Boudiaf, Dominic Culver, Rui Melo, Caio Corro, Andre FT Martins, Fabrizio Esposito, Vera Lúcia Raposo, Sofia Morgado, et al</span><span class="ltx_text" id="bib.bib8.12.2" style="font-size:90%;">.</span><span class="ltx_text" id="bib.bib8.13.3" style="font-size:90%;"> 2024.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib8.14.1" style="font-size:90%;">Saullm-7b: A pioneering large language model for law.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib8.15.1" style="font-size:90%;">arXiv preprint arXiv:2403.03883</em><span class="ltx_text" id="bib.bib8.16.2" style="font-size:90%;"> (2024).
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib9.6.6.1" style="font-size:90%;">Douze et al</span><span class="ltx_text" id="bib.bib9.7.7.2" style="font-size:90%;">.</span><span class="ltx_text" id="bib.bib9.8.8.3" style="font-size:90%;"> (2024)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib9.10.1" style="font-size:90%;">
Matthijs Douze, Alexandr Guzhva, Chengqi Deng, Jeff Johnson, Gergely Szilvasy, Pierre-Emmanuel Mazaré, Maria Lomeli, Lucas Hosseini, and Hervé Jégou. 2024.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib9.11.1" style="font-size:90%;">The Faiss library.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib9.12.1" style="font-size:90%;">(2024).
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib9.13.1" style="font-size:90%;">arXiv:2401.08281 [cs.LG]
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib10.6.6.1" style="font-size:90%;">Fernandez et al</span><span class="ltx_text" id="bib.bib10.7.7.2" style="font-size:90%;">.</span><span class="ltx_text" id="bib.bib10.8.8.3" style="font-size:90%;"> (2023)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib10.10.1" style="font-size:90%;">
Raul Castro Fernandez, Aaron J Elmore, Michael J Franklin, Sanjay Krishnan, and Chenhao Tan. 2023.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib10.11.1" style="font-size:90%;">How large language models will disrupt data management.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib10.12.1" style="font-size:90%;">Proceedings of the VLDB Endowment</em><span class="ltx_text" id="bib.bib10.13.2" style="font-size:90%;"> 16, 11 (2023), 3302–3309.
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib11.6.6.1" style="font-size:90%;">Gao et al</span><span class="ltx_text" id="bib.bib11.7.7.2" style="font-size:90%;">.</span><span class="ltx_text" id="bib.bib11.8.8.3" style="font-size:90%;"> (2023)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib11.10.1" style="font-size:90%;">
Yunfan Gao, Yun Xiong, Xinyu Gao, Kangxiang Jia, Jinliu Pan, Yuxi Bi, Yi Dai, Jiawei Sun, and Haofen Wang. 2023.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib11.11.1" style="font-size:90%;">Retrieval-augmented generation for large language models: A survey.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib11.12.1" style="font-size:90%;">arXiv preprint arXiv:2312.10997</em><span class="ltx_text" id="bib.bib11.13.2" style="font-size:90%;"> (2023).
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib12.5.5.1" style="font-size:90%;">He and McAuley (2016)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib12.7.1" style="font-size:90%;">
Ruining He and Julian McAuley. 2016.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib12.8.1" style="font-size:90%;">Ups and downs: Modeling the visual evolution of fashion trends with one-class collaborative filtering. In </span><em class="ltx_emph ltx_font_italic" id="bib.bib12.9.2" style="font-size:90%;">Proceedings of the 25th international conference on world wide web</em><span class="ltx_text" id="bib.bib12.10.3" style="font-size:90%;">. International World Wide Web Conferences Steering Committee, 507–517.
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib13.6.6.1" style="font-size:90%;">Hu et al</span><span class="ltx_text" id="bib.bib13.7.7.2" style="font-size:90%;">.</span><span class="ltx_text" id="bib.bib13.8.8.3" style="font-size:90%;"> (2023)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib13.10.1" style="font-size:90%;">
Chenxu Hu, Jie Fu, Chenzhuang Du, Simian Luo, Junbo Zhao, and Hang Zhao. 2023.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib13.11.1" style="font-size:90%;">Chatdb: Augmenting llms with databases as their symbolic memory.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib13.12.1" style="font-size:90%;">arXiv preprint arXiv:2306.03901</em><span class="ltx_text" id="bib.bib13.13.2" style="font-size:90%;"> (2023).
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib14.6.6.1" style="font-size:90%;">Huang et al</span><span class="ltx_text" id="bib.bib14.7.7.2" style="font-size:90%;">.</span><span class="ltx_text" id="bib.bib14.8.8.3" style="font-size:90%;"> (2024)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib14.10.1" style="font-size:90%;">
Hui Huang, Yingqi Qu, Jing Liu, Muyun Yang, and Tiejun Zhao. 2024.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib14.11.1" style="font-size:90%;">An empirical study of llm-as-a-judge for llm evaluation: Fine-tuned judge models are task-specific classifiers.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib14.12.1" style="font-size:90%;">arXiv preprint arXiv:2403.02839</em><span class="ltx_text" id="bib.bib14.13.2" style="font-size:90%;"> (2024).
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib15.6.6.1" style="font-size:90%;">Ji et al</span><span class="ltx_text" id="bib.bib15.7.7.2" style="font-size:90%;">.</span><span class="ltx_text" id="bib.bib15.8.8.3" style="font-size:90%;"> (2023)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib15.10.1" style="font-size:90%;">
Jiaming Ji, Mickel Liu, Juntao Dai, Xuehai Pan, Chi Zhang, Ce Bian, Chi Zhang, Ruiyang Sun, Yizhou Wang, and Yaodong Yang. 2023.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib15.11.1" style="font-size:90%;">BeaverTails: Towards Improved Safety Alignment of LLM via a Human-Preference Dataset.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib15.12.1" style="font-size:90%;">arXiv preprint arXiv:2307.04657</em><span class="ltx_text" id="bib.bib15.13.2" style="font-size:90%;"> (2023).
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib16.7.7.1" style="font-size:90%;">Jiang et al</span><span class="ltx_text" id="bib.bib16.8.8.2" style="font-size:90%;">.</span><span class="ltx_text" id="bib.bib16.9.9.3" style="font-size:90%;"> (2023)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib16.11.1" style="font-size:90%;">
Albert Q Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford, Devendra Singh Chaplot, Diego de las Casas, Florian Bressand, Gianna Lengyel, Guillaume Lample, Lucile Saulnier, et al</span><span class="ltx_text" id="bib.bib16.12.2" style="font-size:90%;">.</span><span class="ltx_text" id="bib.bib16.13.3" style="font-size:90%;"> 2023.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib16.14.1" style="font-size:90%;">Mistral 7B.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib16.15.1" style="font-size:90%;">arXiv preprint arXiv:2310.06825</em><span class="ltx_text" id="bib.bib16.16.2" style="font-size:90%;"> (2023).
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib17.6.6.1" style="font-size:90%;">Lee et al</span><span class="ltx_text" id="bib.bib17.7.7.2" style="font-size:90%;">.</span><span class="ltx_text" id="bib.bib17.8.8.3" style="font-size:90%;"> (2024)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib17.10.1" style="font-size:90%;">
Jean Lee, Nicholas Stevens, Soyeon Caren Han, and Minseok Song. 2024.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib17.11.1" style="font-size:90%;">A Survey of Large Language Models in Finance (FinLLMs).
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib17.12.1" style="font-size:90%;">arXiv preprint arXiv:2402.02315</em><span class="ltx_text" id="bib.bib17.13.2" style="font-size:90%;"> (2024).
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib18.7.7.1" style="font-size:90%;">Li et al</span><span class="ltx_text" id="bib.bib18.8.8.2" style="font-size:90%;">.</span><span class="ltx_text" id="bib.bib18.9.9.3" style="font-size:90%;"> (2024)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib18.11.1" style="font-size:90%;">
Jinyang Li, Binyuan Hui, Ge Qu, Jiaxi Yang, Binhua Li, Bowen Li, Bailin Wang, Bowen Qin, Ruiying Geng, Nan Huo, et al</span><span class="ltx_text" id="bib.bib18.12.2" style="font-size:90%;">.</span><span class="ltx_text" id="bib.bib18.13.3" style="font-size:90%;"> 2024.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib18.14.1" style="font-size:90%;">Can llm already serve as a database interface? a big bench for large-scale database grounded text-to-sqls.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib18.15.1" style="font-size:90%;">Advances in Neural Information Processing Systems</em><span class="ltx_text" id="bib.bib18.16.2" style="font-size:90%;"> 36 (2024).
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib19.6.6.1" style="font-size:90%;">Li et al</span><span class="ltx_text" id="bib.bib19.7.7.2" style="font-size:90%;">.</span><span class="ltx_text" id="bib.bib19.8.8.3" style="font-size:90%;"> (2023)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib19.10.1" style="font-size:90%;">
Peng Li, Yeye He, Dror Yashar, Weiwei Cui, Song Ge, Haidong Zhang, Danielle Rifinski Fainman, Dongmei Zhang, and Surajit Chaudhuri. 2023.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib19.11.1" style="font-size:90%;">Table-gpt: Table-tuned gpt for diverse table tasks.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib19.12.1" style="font-size:90%;">arXiv preprint arXiv:2310.09263</em><span class="ltx_text" id="bib.bib19.13.2" style="font-size:90%;"> (2023).
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib20.5.5.1" style="font-size:90%;">Liu and Mozafari (2024)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib20.7.1" style="font-size:90%;">
Jie Liu and Barzan Mozafari. 2024.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib20.8.1" style="font-size:90%;">Query Rewriting via Large Language Models.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib20.9.1" style="font-size:90%;">arXiv preprint arXiv:2403.09060</em><span class="ltx_text" id="bib.bib20.10.2" style="font-size:90%;"> (2024).
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib21.6.6.1" style="font-size:90%;">Liu et al</span><span class="ltx_text" id="bib.bib21.7.7.2" style="font-size:90%;">.</span><span class="ltx_text" id="bib.bib21.8.8.3" style="font-size:90%;"> (2024)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib21.10.1" style="font-size:90%;">
Yang Liu, Jiahuan Cao, Chongyu Liu, Kai Ding, and Lianwen Jin. 2024.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib21.11.1" style="font-size:90%;">Datasets for large language models: A comprehensive survey.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib21.12.1" style="font-size:90%;">arXiv preprint arXiv:2402.18041</em><span class="ltx_text" id="bib.bib21.13.2" style="font-size:90%;"> (2024).
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib22.6.6.1" style="font-size:90%;">Luo et al</span><span class="ltx_text" id="bib.bib22.7.7.2" style="font-size:90%;">.</span><span class="ltx_text" id="bib.bib22.8.8.3" style="font-size:90%;"> (2024)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib22.10.1" style="font-size:90%;">
Yi Luo, Zhenghao Lin, Yuhao Zhang, Jiashuo Sun, Chen Lin, Chengjin Xu, Xiangdong Su, Yelong Shen, Jian Guo, and Yeyun Gong. 2024.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib22.11.1" style="font-size:90%;">Ensuring Safe and High-Quality Outputs: A Guideline Library Approach for Language Models.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib22.12.1" style="font-size:90%;">CoRR</em><span class="ltx_text" id="bib.bib22.13.2" style="font-size:90%;"> abs/2403.11838 (2024).
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib22.14.1" style="font-size:90%;">arXiv:2403.11838
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib23.6.6.1" style="font-size:90%;">Mizrahi et al</span><span class="ltx_text" id="bib.bib23.7.7.2" style="font-size:90%;">.</span><span class="ltx_text" id="bib.bib23.8.8.3" style="font-size:90%;"> (2023)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib23.10.1" style="font-size:90%;">
Moran Mizrahi, Guy Kaplan, Dan Malkin, Rotem Dror, Dafna Shahaf, and Gabriel Stanovsky. 2023.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib23.11.1" style="font-size:90%;">State of what art? a call for multi-prompt llm evaluation.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib23.12.1" style="font-size:90%;">arXiv preprint arXiv:2401.00595</em><span class="ltx_text" id="bib.bib23.13.2" style="font-size:90%;"> (2023).
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib24.5.5.1" style="font-size:90%;">OpenAI (2022)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib24.7.1" style="font-size:90%;">
OpenAI. 2022.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib24.8.1" style="font-size:90%;">OpenAI: Introducing ChatGPT.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib24.9.1" style="font-size:90%;">(2022).
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib24.10.1" style="font-size:90%;">
</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://openai.com/blog/chatgpt" style="font-size:90%;" title="">https://openai.com/blog/chatgpt</a><span class="ltx_text" id="bib.bib24.11.2" style="font-size:90%;">
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib25.5.5.1" style="font-size:90%;">OpenAI (2023)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib25.7.1" style="font-size:90%;">
OpenAI. 2023.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib25.8.1" style="font-size:90%;">GPT-4 Technical Report.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib25.9.1" style="font-size:90%;">CoRR</em><span class="ltx_text" id="bib.bib25.10.2" style="font-size:90%;"> abs/2303.08774 (2023).
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib25.11.1" style="font-size:90%;">
</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.48550/arXiv.2303.08774" style="font-size:90%;" title="">https://doi.org/10.48550/arXiv.2303.08774</a><span class="ltx_text" id="bib.bib25.12.2" style="font-size:90%;">
arXiv:2303.08774
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib26.5.5.1" style="font-size:90%;">Pourreza and Rafiei (2024)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib26.7.1" style="font-size:90%;">
Mohammadreza Pourreza and Davood Rafiei. 2024.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib26.8.1" style="font-size:90%;">Din-sql: Decomposed in-context learning of text-to-sql with self-correction.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib26.9.1" style="font-size:90%;">Advances in Neural Information Processing Systems</em><span class="ltx_text" id="bib.bib26.10.2" style="font-size:90%;"> 36 (2024).
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib27.6.6.1" style="font-size:90%;">Rajpurkar et al</span><span class="ltx_text" id="bib.bib27.7.7.2" style="font-size:90%;">.</span><span class="ltx_text" id="bib.bib27.8.8.3" style="font-size:90%;"> (2018)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib27.10.1" style="font-size:90%;">
Pranav Rajpurkar, Robin Jia, and Percy Liang. 2018.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib27.11.1" style="font-size:90%;">Know what you don’t know: Unanswerable questions for SQuAD.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib27.12.1" style="font-size:90%;">arXiv preprint arXiv:1806.03822</em><span class="ltx_text" id="bib.bib27.13.2" style="font-size:90%;"> (2018).
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib28.5.5.1" style="font-size:90%;">Reddit (2015)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib28.7.1" style="font-size:90%;">
Reddit. 2015.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib28.8.1" style="font-size:90%;">Reddit Comments Dataset.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib28.9.1" style="font-size:90%;">https://www.reddit.com/r/datasets/.
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib29.6.6.1" style="font-size:90%;">Sun et al</span><span class="ltx_text" id="bib.bib29.7.7.2" style="font-size:90%;">.</span><span class="ltx_text" id="bib.bib29.8.8.3" style="font-size:90%;"> (2023b)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib29.10.1" style="font-size:90%;">
Hao Sun, Zhexin Zhang, Jiawen Deng, Jiale Cheng, and Minlie Huang. 2023b.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib29.11.1" style="font-size:90%;">Safety Assessment of Chinese Large Language Models.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib29.12.1" style="font-size:90%;">arXiv preprint arXiv:2304.10436</em><span class="ltx_text" id="bib.bib29.13.2" style="font-size:90%;"> (2023).
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib30.6.6.1" style="font-size:90%;">Sun et al</span><span class="ltx_text" id="bib.bib30.7.7.2" style="font-size:90%;">.</span><span class="ltx_text" id="bib.bib30.8.8.3" style="font-size:90%;"> (2023a)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib30.10.1" style="font-size:90%;">
Jiashuo Sun, Chengjin Xu, Lumingyuan Tang, Saizhuo Wang, Chen Lin, Yeyun Gong, Heung-Yeung Shum, and Jian Guo. 2023a.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib30.11.1" style="font-size:90%;">Think-on-graph: Deep and responsible reasoning of large language model with knowledge graph.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib30.12.1" style="font-size:90%;">arXiv preprint arXiv:2307.07697</em><span class="ltx_text" id="bib.bib30.13.2" style="font-size:90%;"> (2023).
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib31.6.6.1" style="font-size:90%;">Taori et al</span><span class="ltx_text" id="bib.bib31.7.7.2" style="font-size:90%;">.</span><span class="ltx_text" id="bib.bib31.8.8.3" style="font-size:90%;"> (2023)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib31.10.1" style="font-size:90%;">
Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos Guestrin, Percy Liang, and Tatsunori B. Hashimoto. 2023.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib31.11.1" style="font-size:90%;">Stanford Alpaca: An Instruction-following LLaMA model.
</span>
</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/tatsu-lab/stanford_alpaca" style="font-size:90%;" title="">https://github.com/tatsu-lab/stanford_alpaca</a><span class="ltx_text" id="bib.bib31.12.1" style="font-size:90%;">.
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib32.7.7.1" style="font-size:90%;">Touvron et al</span><span class="ltx_text" id="bib.bib32.8.8.2" style="font-size:90%;">.</span><span class="ltx_text" id="bib.bib32.9.9.3" style="font-size:90%;"> (2023a)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib32.11.1" style="font-size:90%;">
Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, et al</span><span class="ltx_text" id="bib.bib32.12.2" style="font-size:90%;">.</span><span class="ltx_text" id="bib.bib32.13.3" style="font-size:90%;"> 2023a.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib32.14.1" style="font-size:90%;">Llama: Open and efficient foundation language models.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib32.15.1" style="font-size:90%;">arXiv preprint arXiv:2302.13971</em><span class="ltx_text" id="bib.bib32.16.2" style="font-size:90%;"> (2023).
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib33.7.7.1" style="font-size:90%;">Touvron et al</span><span class="ltx_text" id="bib.bib33.8.8.2" style="font-size:90%;">.</span><span class="ltx_text" id="bib.bib33.9.9.3" style="font-size:90%;"> (2023b)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib33.11.1" style="font-size:90%;">
Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et al</span><span class="ltx_text" id="bib.bib33.12.2" style="font-size:90%;">.</span><span class="ltx_text" id="bib.bib33.13.3" style="font-size:90%;"> 2023b.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib33.14.1" style="font-size:90%;">Llama 2: Open foundation and fine-tuned chat models.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib33.15.1" style="font-size:90%;">arXiv preprint arXiv:2307.09288</em><span class="ltx_text" id="bib.bib33.16.2" style="font-size:90%;"> (2023).
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib34.7.7.1" style="font-size:90%;">Wang et al</span><span class="ltx_text" id="bib.bib34.8.8.2" style="font-size:90%;">.</span><span class="ltx_text" id="bib.bib34.9.9.3" style="font-size:90%;"> (2024)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib34.11.1" style="font-size:90%;">
Lei Wang, Chen Ma, Xueyang Feng, Zeyu Zhang, Hao Yang, Jingsen Zhang, Zhiyuan Chen, Jiakai Tang, Xu Chen, Yankai Lin, et al</span><span class="ltx_text" id="bib.bib34.12.2" style="font-size:90%;">.</span><span class="ltx_text" id="bib.bib34.13.3" style="font-size:90%;"> 2024.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib34.14.1" style="font-size:90%;">A survey on large language model based autonomous agents.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib34.15.1" style="font-size:90%;">Frontiers of Computer Science</em><span class="ltx_text" id="bib.bib34.16.2" style="font-size:90%;"> 18, 6 (2024), 1–26.
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib35.5.5.1" style="font-size:90%;">Wikipedia (2021)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib35.7.1" style="font-size:90%;">
Wikipedia. 2021.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib35.8.1" style="font-size:90%;">Wikipedia Dumps.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib35.9.1" style="font-size:90%;">https://dumps.wikimedia.org/.
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib36.7.7.1" style="font-size:90%;">Wu et al</span><span class="ltx_text" id="bib.bib36.8.8.2" style="font-size:90%;">.</span><span class="ltx_text" id="bib.bib36.9.9.3" style="font-size:90%;"> (2023)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib36.11.1" style="font-size:90%;">
Shaohua Wu, Xudong Zhao, Shenling Wang, Jiangang Luo, Lingjun Li, Xi Chen, Bing Zhao, Wei Wang, Tong Yu, Rongguo Zhang, et al</span><span class="ltx_text" id="bib.bib36.12.2" style="font-size:90%;">.</span><span class="ltx_text" id="bib.bib36.13.3" style="font-size:90%;"> 2023.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib36.14.1" style="font-size:90%;">YUAN 2.0: A Large Language Model with Localized Filtering-based Attention.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib36.15.1" style="font-size:90%;">arXiv preprint arXiv:2311.15786</em><span class="ltx_text" id="bib.bib36.16.2" style="font-size:90%;"> (2023).
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib37.6.6.1" style="font-size:90%;">Xiao et al</span><span class="ltx_text" id="bib.bib37.7.7.2" style="font-size:90%;">.</span><span class="ltx_text" id="bib.bib37.8.8.3" style="font-size:90%;"> (2023)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib37.10.1" style="font-size:90%;">
Shitao Xiao, Zheng Liu, Peitian Zhang, and Niklas Muennighoff. 2023.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib37.11.1" style="font-size:90%;">C-Pack: Packaged Resources To Advance General Chinese Embedding.
</span>
</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib37.12.1" style="font-size:90%;">arXiv:2309.07597 [cs.CL]
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib38.7.7.1" style="font-size:90%;">Xue et al</span><span class="ltx_text" id="bib.bib38.8.8.2" style="font-size:90%;">.</span><span class="ltx_text" id="bib.bib38.9.9.3" style="font-size:90%;"> (2023)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib38.11.1" style="font-size:90%;">
Siqiao Xue, Caigao Jiang, Wenhui Shi, Fangyin Cheng, Keting Chen, Hongjun Yang, Zhiping Zhang, Jianshan He, Hongyang Zhang, Ganglin Wei, et al</span><span class="ltx_text" id="bib.bib38.12.2" style="font-size:90%;">.</span><span class="ltx_text" id="bib.bib38.13.3" style="font-size:90%;"> 2023.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib38.14.1" style="font-size:90%;">Db-gpt: Empowering database interactions with private large language models.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib38.15.1" style="font-size:90%;">arXiv preprint arXiv:2312.17449</em><span class="ltx_text" id="bib.bib38.16.2" style="font-size:90%;"> (2023).
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib39.7.7.1" style="font-size:90%;">Yang et al</span><span class="ltx_text" id="bib.bib39.8.8.2" style="font-size:90%;">.</span><span class="ltx_text" id="bib.bib39.9.9.3" style="font-size:90%;"> (2023)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib39.11.1" style="font-size:90%;">
Aiyuan Yang, Bin Xiao, Bingning Wang, Borong Zhang, Ce Bian, Chao Yin, Chenxu Lv, Da Pan, Dian Wang, Dong Yan, et al</span><span class="ltx_text" id="bib.bib39.12.2" style="font-size:90%;">.</span><span class="ltx_text" id="bib.bib39.13.3" style="font-size:90%;"> 2023.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib39.14.1" style="font-size:90%;">Baichuan 2: Open large-scale language models.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib39.15.1" style="font-size:90%;">arXiv preprint arXiv:2309.10305</em><span class="ltx_text" id="bib.bib39.16.2" style="font-size:90%;"> (2023).
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib40.6.6.1" style="font-size:90%;">Yang et al</span><span class="ltx_text" id="bib.bib40.7.7.2" style="font-size:90%;">.</span><span class="ltx_text" id="bib.bib40.8.8.3" style="font-size:90%;"> (2019)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib40.10.1" style="font-size:90%;">
Zhilin Yang, Zihang Dai, Yiming Yang, Jaime G. Carbonell, Ruslan Salakhutdinov, and Quoc V. Le. 2019.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib40.11.1" style="font-size:90%;">XLNet: Generalized Autoregressive Pretraining for Language Understanding. In </span><em class="ltx_emph ltx_font_italic" id="bib.bib40.12.2" style="font-size:90%;">Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems 2019, NeurIPS 2019, December 8-14, 2019, Vancouver, BC, Canada</em><span class="ltx_text" id="bib.bib40.13.3" style="font-size:90%;">, Hanna M. Wallach, Hugo Larochelle, Alina Beygelzimer, Florence d’Alché-Buc, Emily B. Fox, and Roman Garnett (Eds.). 5754–5764.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib40.14.1" style="font-size:90%;">
</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://proceedings.neurips.cc/paper/2019/hash/dc6a7e655d7e5840e66733e9ee67cc69-Abstract.html" style="font-size:90%;" title="">https://proceedings.neurips.cc/paper/2019/hash/dc6a7e655d7e5840e66733e9ee67cc69-Abstract.html</a><span class="ltx_text" id="bib.bib40.15.2" style="font-size:90%;">
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib41.6.6.1" style="font-size:90%;">Yao et al</span><span class="ltx_text" id="bib.bib41.7.7.2" style="font-size:90%;">.</span><span class="ltx_text" id="bib.bib41.8.8.3" style="font-size:90%;"> (2023)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib41.10.1" style="font-size:90%;">
Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik R. Narasimhan, and Yuan Cao. 2023.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib41.11.1" style="font-size:90%;">ReAct: Synergizing Reasoning and Acting in Language Models. In </span><em class="ltx_emph ltx_font_italic" id="bib.bib41.12.2" style="font-size:90%;">The Eleventh International Conference on Learning Representations, ICLR 2023, Kigali, Rwanda, May 1-5, 2023</em><span class="ltx_text" id="bib.bib41.13.3" style="font-size:90%;">. OpenReview.net.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib41.14.1" style="font-size:90%;">
</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://openreview.net/pdf?id=WE_vluYUL-X" style="font-size:90%;" title="">https://openreview.net/pdf?id=WE_vluYUL-X</a><span class="ltx_text" id="bib.bib41.15.2" style="font-size:90%;">
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib42.7.7.1" style="font-size:90%;">Yu et al</span><span class="ltx_text" id="bib.bib42.8.8.2" style="font-size:90%;">.</span><span class="ltx_text" id="bib.bib42.9.9.3" style="font-size:90%;"> (2018)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib42.11.1" style="font-size:90%;">
Tao Yu, Rui Zhang, Kai Yang, Michihiro Yasunaga, Dongxu Wang, Zifan Li, James Ma, Irene Li, Qingning Yao, Shanelle Roman, et al</span><span class="ltx_text" id="bib.bib42.12.2" style="font-size:90%;">.</span><span class="ltx_text" id="bib.bib42.13.3" style="font-size:90%;"> 2018.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib42.14.1" style="font-size:90%;">Spider: A large-scale human-labeled dataset for complex and cross-domain semantic parsing and text-to-sql task.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib42.15.1" style="font-size:90%;">arXiv preprint arXiv:1809.08887</em><span class="ltx_text" id="bib.bib42.16.2" style="font-size:90%;"> (2018).
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib43.7.7.1" style="font-size:90%;">Yuan et al</span><span class="ltx_text" id="bib.bib43.8.8.2" style="font-size:90%;">.</span><span class="ltx_text" id="bib.bib43.9.9.3" style="font-size:90%;"> (2023)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib43.11.1" style="font-size:90%;">
Mingze Yuan, Peng Bao, Jiajia Yuan, Yunhao Shen, Zifan Chen, Yi Xie, Jie Zhao, Yang Chen, Li Zhang, Lin Shen, et al</span><span class="ltx_text" id="bib.bib43.12.2" style="font-size:90%;">.</span><span class="ltx_text" id="bib.bib43.13.3" style="font-size:90%;"> 2023.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib43.14.1" style="font-size:90%;">Large Language Models Illuminate a Progressive Pathway to Artificial Healthcare Assistant: A Review.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib43.15.1" style="font-size:90%;">arXiv preprint arXiv:2311.01918</em><span class="ltx_text" id="bib.bib43.16.2" style="font-size:90%;"> (2023).
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib44.7.7.1" style="font-size:90%;">Zeng et al</span><span class="ltx_text" id="bib.bib44.8.8.2" style="font-size:90%;">.</span><span class="ltx_text" id="bib.bib44.9.9.3" style="font-size:90%;"> (2022)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib44.11.1" style="font-size:90%;">
Aohan Zeng, Xiao Liu, Zhengxiao Du, Zihan Wang, Hanyu Lai, Ming Ding, Zhuoyi Yang, Yifan Xu, Wendi Zheng, Xiao Xia, et al</span><span class="ltx_text" id="bib.bib44.12.2" style="font-size:90%;">.</span><span class="ltx_text" id="bib.bib44.13.3" style="font-size:90%;"> 2022.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib44.14.1" style="font-size:90%;">Glm-130b: An open bilingual pre-trained model.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib44.15.1" style="font-size:90%;">arXiv preprint arXiv:2210.02414</em><span class="ltx_text" id="bib.bib44.16.2" style="font-size:90%;"> (2022).
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib45.7.7.1" style="font-size:90%;">Zhang et al</span><span class="ltx_text" id="bib.bib45.8.8.2" style="font-size:90%;">.</span><span class="ltx_text" id="bib.bib45.9.9.3" style="font-size:90%;"> (2023)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib45.11.1" style="font-size:90%;">
Hongbo Zhang, Junying Chen, Feng Jiang, Fei Yu, Zhihong Chen, Jianquan Li, Guiming Chen, Xiangbo Wu, Zhiyi Zhang, Qingying Xiao, et al</span><span class="ltx_text" id="bib.bib45.12.2" style="font-size:90%;">.</span><span class="ltx_text" id="bib.bib45.13.3" style="font-size:90%;"> 2023.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib45.14.1" style="font-size:90%;">Huatuogpt, towards taming language model to be a doctor.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib45.15.1" style="font-size:90%;">arXiv preprint arXiv:2305.15075</em><span class="ltx_text" id="bib.bib45.16.2" style="font-size:90%;"> (2023).
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib46">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib46.6.6.1" style="font-size:90%;">Zhou et al</span><span class="ltx_text" id="bib.bib46.7.7.2" style="font-size:90%;">.</span><span class="ltx_text" id="bib.bib46.8.8.3" style="font-size:90%;"> (2023a)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib46.10.1" style="font-size:90%;">
Xuanhe Zhou, Guoliang Li, and Zhiyuan Liu. 2023a.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib46.11.1" style="font-size:90%;">Llm as dba.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib46.12.1" style="font-size:90%;">arXiv preprint arXiv:2308.05481</em><span class="ltx_text" id="bib.bib46.13.2" style="font-size:90%;"> (2023).
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib47">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib47.6.6.1" style="font-size:90%;">Zhou et al</span><span class="ltx_text" id="bib.bib47.7.7.2" style="font-size:90%;">.</span><span class="ltx_text" id="bib.bib47.8.8.3" style="font-size:90%;"> (2023b)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib47.10.1" style="font-size:90%;">
Xuanhe Zhou, Guoliang Li, Zhaoyan Sun, Zhiyuan Liu, Weize Chen, Jianming Wu, Jiesi Liu, Ruohang Feng, and Guoyang Zeng. 2023b.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib47.11.1" style="font-size:90%;">D-bot: Database diagnosis system using large language models.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib47.12.1" style="font-size:90%;">arXiv preprint arXiv:2312.01454</em><span class="ltx_text" id="bib.bib47.13.2" style="font-size:90%;"> (2023).
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib48">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib48.6.6.1" style="font-size:90%;">Zhou et al</span><span class="ltx_text" id="bib.bib48.7.7.2" style="font-size:90%;">.</span><span class="ltx_text" id="bib.bib48.8.8.3" style="font-size:90%;"> (2024a)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib48.10.1" style="font-size:90%;">
Xuanhe Zhou, Zhaoyan Sun, and Guoliang Li. 2024a.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib48.11.1" style="font-size:90%;">DB-GPT: Large Language Model Meets Database.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib48.12.1" style="font-size:90%;">Data Science and Engineering</em><span class="ltx_text" id="bib.bib48.13.2" style="font-size:90%;"> (2024), 1–10.
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib49">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib49.6.6.1" style="font-size:90%;">Zhou et al</span><span class="ltx_text" id="bib.bib49.7.7.2" style="font-size:90%;">.</span><span class="ltx_text" id="bib.bib49.8.8.3" style="font-size:90%;"> (2024b)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib49.10.1" style="font-size:90%;">
Xuanhe Zhou, Xinyang Zhao, and Guoliang Li. 2024b.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib49.11.1" style="font-size:90%;">LLM-Enhanced Data Management.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib49.12.1" style="font-size:90%;">arXiv preprint arXiv:2402.02643</em><span class="ltx_text" id="bib.bib49.13.2" style="font-size:90%;"> (2024).
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
</section>
</section>
</section>
</section>
</section>
</section>
</div>
</div>
</figure>
</section>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Thu Sep  5 13:44:41 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
