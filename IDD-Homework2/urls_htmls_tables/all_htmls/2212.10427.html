<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2212.10427] ModularFed: Leveraging Modularity in Federated Learning Frameworks</title><meta property="og:description" content="Numerous research recently proposed integrating Federated Learning (FL) to address the privacy concerns of using machine learning in privacy-sensitive firms. However, the standards of the available frameworks can no lo…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="ModularFed: Leveraging Modularity in Federated Learning Frameworks">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="ModularFed: Leveraging Modularity in Federated Learning Frameworks">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2212.10427">

<!--Generated on Fri Mar  1 10:16:53 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_fleqn">
<h1 class="ltx_title ltx_title_document">ModularFed: Leveraging Modularity in Federated Learning Frameworks</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Mohamad Arafeh
</span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Hadi Otrok
</span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Hakima Ould-Slimane
</span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Azzam Mourad
</span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Chamseddine Talhi
</span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Ernesto Damiani
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_address">Department of Software Engineering, Ecole de Technologie Superieure (ETS), Montreal, QC, Canada
</span>
<span class="ltx_contact ltx_role_address">Department of mathematics and computer science, Universite de Quebec a Trois-Rivieres (UQTR), Canada
</span>
<span class="ltx_contact ltx_role_address">Center of Cyber-Physical Systems (C2PS), Department of EECS, Khalifa University, Abu Dhabi, UAE
</span>
<span class="ltx_contact ltx_role_address">Cyber Security Systems and Applied AI Research Center, Department of CSM, Lebanese American University, Lebanon
</span>
<span class="ltx_contact ltx_role_address">Division of Science, New York University, Abu Dhabi, United Arab Emirates
</span></span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id1.id1" class="ltx_p">Numerous research recently proposed integrating Federated Learning (FL) to address the privacy concerns of using machine learning in privacy-sensitive firms. However, the standards of the available frameworks can no longer sustain the rapid advancement and hinder the integration of FL solutions, which can be prominent in advancing the field. In this paper, we propose ModularFed, a research-focused framework that addresses the complexity of FL implementations and the lack of adaptability and extendability in the available frameworks. We provide a comprehensive architecture that assists FL approaches through well-defined protocols to cover three dominant FL paradigms: adaptable workflow, datasets distribution, and third-party application support. Within this architecture, protocols are blueprints that strictly define the framework’s components’ design, contribute to its flexibility, and strengthen its infrastructure. Further, our protocols aim to enable modularity in FL, supporting third-party plug-and-play architecture and dynamic simulators coupled with major built-in data distributors in the field. Additionally, the framework support wrapping multiple approaches in a single environment to enable consistent replication of FL issues such as clients’ deficiency, data distribution, and network latency, which entails a fair comparison of techniques outlying FL technologies. In our evaluation, we examine the applicability of our framework addressing three major FL domains, including statistical distribution and modular-based approaches for resource monitoring and client selection.</p>
</div>
<div class="ltx_classification">
<h6 class="ltx_title ltx_title_classification">keywords: </h6>
Federated Learning, Machine Learning, Non-IID, Privacy.

</div>
<span id="id1" class="ltx_note ltx_note_frontmatter ltx_role_journal"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">journal: </span>Journal</span></span></span>
<div id="p1" class="ltx_para">
<span id="p1.1" class="ltx_ERROR undefined">\floatsetup</span>
<p id="p1.2" class="ltx_p">[table]capposition=top



</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Federated learning is a distributed technique that emerged from the need for an architecture to address the increasing restriction on users’ data privacy. In FL, users train ML models locally on their devices and send them to external servers while keeping their raw data intact on their devices. Furthermore, the server, in its turn, performs a particular aggregation algorithm, which is the core of any FL approach. Aggregation algorithms have the role of combining the clients’ received models into one global model. Therefore, external parties can benefit from users’ collected data without violating their privacy.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Despite its promising rationale and the numerous recent investigations <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>, <a href="#bib.bib2" title="" class="ltx_ref">2</a>, <a href="#bib.bib3" title="" class="ltx_ref">3</a>, <a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>, FL’s trustworthiness and performance are majorly affected by statistical, security and resource concerns, restricting further development in the field. For instance, FL implies individual training from clients using their local datasets, which in most cases, is deemed biased toward the clients’ behaviours and surroundings. Such a situation signifies a non-identical and independent (Non-IID) data distribution in which data imbalance exists by either size or content (features/classes). Referring to <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>, experiments with Non-IID constitute evidence of serious drawbacks on accuracy and loss developments. Furthermore, the absence of raw data on the server precludes the cleaning and filtering procedures in the traditional Non-FL server that takes place in a centralized learning context. The eminent lack of raw data access pushes researchers to propose alternative resolutions to address the statistical problem. Approaches such as <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>, <a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite> attempted to exploit the connection between the clients and their model parameters by clustering algorithms to separate them into distinct FL contexts. Having only similar clients working together can simulate an IID environment. On the other hand, the works presented in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib11" title="" class="ltx_ref">11</a>, <a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> take advantage of the aggregation procedure to fix the model shift caused by training on Non-IID clients. Another form of solution operates on the starting parameters. For instance, in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>, <a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>, the experiments show that starting from a pre-trained model can boost the performance in a Non-IID environment. In terms of security, various defence mechanisms aim to protect against manipulation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>, <a href="#bib.bib16" title="" class="ltx_ref">16</a>, <a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>, trustworthiness <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>, <a href="#bib.bib19" title="" class="ltx_ref">19</a>, <a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>, and inference attacks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>, <a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>. Regarding resource consumption, development focuses on reducing the communication overhead as in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>, <a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite> or energy consumption as in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>, <a href="#bib.bib26" title="" class="ltx_ref">26</a>, <a href="#bib.bib27" title="" class="ltx_ref">27</a>, <a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>. Other approaches in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>, <a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite> acted on the produced clients’ model quality to reduce the communication rounds. Their experiments show a significant improvement in weight development through selection algorithms, increasing the convergence rate and reducing the total cost.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">From the aforementioned approaches, we underline essential facts which are the motivation behind this work:</p>
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">The majority of the aforementioned approaches focuses on three areas: aggregation, client selection, communication <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib11" title="" class="ltx_ref">11</a>, <a href="#bib.bib31" title="" class="ltx_ref">31</a>, <a href="#bib.bib30" title="" class="ltx_ref">30</a>, <a href="#bib.bib23" title="" class="ltx_ref">23</a>, <a href="#bib.bib24" title="" class="ltx_ref">24</a>, <a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite> that can be targeted to create a flexible environment for future solutions.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">With few modifications, it is possible to integrate existing solutions from other domains into FL to improve it. For instance, the involvement of blockchain in FL improves the underlying communication, such as robustness and availability <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref">33</a>, <a href="#bib.bib34" title="" class="ltx_ref">34</a>, <a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite>.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p">Integrating FL increases the complexity, which scales with the needs of the various mechanisms such as parallelism, data distribution, client selection, varying training engine, model analysis, data management, bandwidth and resource allocation.</p>
</div>
</li>
<li id="S1.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span> 
<div id="S1.I1.i4.p1" class="ltx_para">
<p id="S1.I1.i4.p1.1" class="ltx_p">The currently available frameworks are limited in terms of standardization and customizability, interfering with the search for new solutions to the said challenges.</p>
</div>
</li>
</ul>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">Therefore, essential details should be considered when working in a complex environment. A framework can solve these problems, but it must have the right level of abstraction; otherwise, it will not be advantageous. To this end, we propose ModularFed, a research-heavy federated learning framework in which we aim to provide a complete set of extendable tools capable of easing the integration of applications in the FL domain, reducing the implementation times while withholding future projects’ extendability and scalability.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">In summary, our main contributions are the following:</p>
</div>
<div id="S1.p6" class="ltx_para">
<ul id="S1.I2" class="ltx_itemize">
<li id="S1.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S1.I2.i1.p1" class="ltx_para">
<p id="S1.I2.i1.p1.1" class="ltx_p">A modular-based framework supporting modular swapping opens the opportunities for work conjunction or component-specific FL approach.</p>
</div>
</li>
<li id="S1.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S1.I2.i2.p1" class="ltx_para">
<p id="S1.I2.i2.p1.1" class="ltx_p">An intuitive subscription base architecture for seamless third-parties integration.</p>
</div>
</li>
<li id="S1.I2.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="S1.I2.i3.p1" class="ltx_para">
<p id="S1.I2.i3.p1.1" class="ltx_p">Central data control supporting external dataset and dynamic distributions simulations.</p>
</div>
</li>
</ul>
</div>
<div id="S1.p7" class="ltx_para">
<p id="S1.p7.1" class="ltx_p">Following the proposed architectures and addressing the aforementioned issues, we provide an exhaustive framework to orchestrate FL approaches and authorize interchanging components’ capabilities. As such, we open the opportunities for collaboration between multiple techniques while additionally easing the integration of new methodologies. Our experimental results demonstrate our framework’s capabilities in supporting various contextual FL problems and scenarios, such as data distribution diversity, client performance, and resource limitation.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">Various frameworks addressing the integration complexity have been proposed. For instance, TensorFlow Federated <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite>, by Google, the original creator of FL <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>, aims to enhance their TensorFlow engine to support distributed learning. The framework supports essential features such as a subscription to a limited set of events to monitor the execution states while making thirds party integration possible. Additionally, the framework incorporates the commonly used datasets and the necessary tools for an effortless start. However, the framework only supports TensorFlow models, making it harder for researchers to integrate FL with models built using another training engine. Another engine-specific FL framework exists, such as FedToch <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite>, which only supports PyTorch models.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p">Contrary to the mentioned frameworks, FedML authors, in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib38" title="" class="ltx_ref">38</a>]</cite>, provide an exhaustive framework that started as a fair benchmarking tool for approaches using federated learning. It integrates a complete federated workflow from client selection, aggregation, and validation. Unlike other approaches, where the tests run only locally, their framework supports message-passing interface-based (MPI) settings, which is the key for parallel client simulation in which procedure execution is within or beyond a single host. Nevertheless, enterprise solutions that embrace the concept of FL, such as Federated AI Technology Enabler (FATE) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref">39</a>]</cite> and IBM Federated Learning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite>, exist. For instance, FATE provides the required mechanism, from secure computation protocols based on homomorphic encryption and multi-party computation (MPC), for industries to integrate FL in their framework. However, the lack of the necessary benchmarking tools, the complex integration, and the limited extensibility makes it harder for researchers to integrate industrial-based frameworks for their works.</p>
</div>
<figure id="S2.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S2.T1.2.1.1" class="ltx_text" style="font-size:90%;">Table 1</span>: </span><span id="S2.T1.3.2" class="ltx_text" style="font-size:90%;">Comparison of the supported features between the available frameworks and ours</span></figcaption>
<div id="S2.T1.4" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:110.4pt;vertical-align:-0.5pt;"><span class="ltx_transformed_inner" style="transform:translate(-209.4pt,53.1pt) scale(0.508693931304663,0.508693931304663) ;">
<table id="S2.T1.4.1" class="ltx_tabular ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S2.T1.4.1.1.1" class="ltx_tr">
<td id="S2.T1.4.1.1.1.1" class="ltx_td ltx_border_l ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td id="S2.T1.4.1.1.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S2.T1.4.1.1.1.2.1" class="ltx_text ltx_font_bold">TFF<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite></span></td>
<td id="S2.T1.4.1.1.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S2.T1.4.1.1.1.3.1" class="ltx_text ltx_font_bold">FedTorch<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite></span></td>
<td id="S2.T1.4.1.1.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S2.T1.4.1.1.1.4.1" class="ltx_text ltx_font_bold">PySyft</span></td>
<td id="S2.T1.4.1.1.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S2.T1.4.1.1.1.5.1" class="ltx_text ltx_font_bold">FATE <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref">39</a>]</cite></span></td>
<td id="S2.T1.4.1.1.1.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S2.T1.4.1.1.1.6.1" class="ltx_text ltx_font_bold">IBM <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite></span></td>
<td id="S2.T1.4.1.1.1.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S2.T1.4.1.1.1.7.1" class="ltx_text ltx_font_bold">FedML<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib38" title="" class="ltx_ref">38</a>]</cite></span></td>
<td id="S2.T1.4.1.1.1.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S2.T1.4.1.1.1.8.1" class="ltx_text ltx_font_bold">Ours</span></td>
</tr>
<tr id="S2.T1.4.1.2.2" class="ltx_tr">
<td id="S2.T1.4.1.2.2.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S2.T1.4.1.2.2.1.1" class="ltx_text ltx_font_bold">Local Execution</span></td>
<td id="S2.T1.4.1.2.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S2.T1.4.1.2.2.2.1" class="ltx_text ltx_font_bold">✓</span></td>
<td id="S2.T1.4.1.2.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S2.T1.4.1.2.2.3.1" class="ltx_text ltx_font_bold">✓</span></td>
<td id="S2.T1.4.1.2.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S2.T1.4.1.2.2.4.1" class="ltx_text ltx_font_bold">✓</span></td>
<td id="S2.T1.4.1.2.2.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S2.T1.4.1.2.2.5.1" class="ltx_text ltx_font_bold">✓</span></td>
<td id="S2.T1.4.1.2.2.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S2.T1.4.1.2.2.6.1" class="ltx_text ltx_font_bold">✓</span></td>
<td id="S2.T1.4.1.2.2.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S2.T1.4.1.2.2.7.1" class="ltx_text ltx_font_bold">✓</span></td>
<td id="S2.T1.4.1.2.2.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S2.T1.4.1.2.2.8.1" class="ltx_text ltx_font_bold">✓</span></td>
</tr>
<tr id="S2.T1.4.1.3.3" class="ltx_tr">
<td id="S2.T1.4.1.3.3.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S2.T1.4.1.3.3.1.1" class="ltx_text ltx_font_bold">Distributed Execution</span></td>
<td id="S2.T1.4.1.3.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S2.T1.4.1.3.3.2.1" class="ltx_text ltx_font_bold">✓</span></td>
<td id="S2.T1.4.1.3.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S2.T1.4.1.3.3.3.1" class="ltx_text ltx_font_bold">✓</span></td>
<td id="S2.T1.4.1.3.3.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S2.T1.4.1.3.3.4.1" class="ltx_text ltx_font_bold">✓</span></td>
<td id="S2.T1.4.1.3.3.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S2.T1.4.1.3.3.5.1" class="ltx_text ltx_font_bold">✓</span></td>
<td id="S2.T1.4.1.3.3.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S2.T1.4.1.3.3.6.1" class="ltx_text ltx_font_bold">✓</span></td>
<td id="S2.T1.4.1.3.3.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S2.T1.4.1.3.3.7.1" class="ltx_text ltx_font_bold">✓</span></td>
<td id="S2.T1.4.1.3.3.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S2.T1.4.1.3.3.8.1" class="ltx_text ltx_font_bold">✓</span></td>
</tr>
<tr id="S2.T1.4.1.4.4" class="ltx_tr">
<td id="S2.T1.4.1.4.4.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S2.T1.4.1.4.4.1.1" class="ltx_text ltx_font_bold">Virtualization/Real Clients</span></td>
<td id="S2.T1.4.1.4.4.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S2.T1.4.1.4.4.2.1" class="ltx_text ltx_font_bold">✗</span></td>
<td id="S2.T1.4.1.4.4.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S2.T1.4.1.4.4.3.1" class="ltx_text ltx_font_bold">✓</span></td>
<td id="S2.T1.4.1.4.4.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S2.T1.4.1.4.4.4.1" class="ltx_text ltx_font_bold">✓</span></td>
<td id="S2.T1.4.1.4.4.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S2.T1.4.1.4.4.5.1" class="ltx_text ltx_font_bold">✓</span></td>
<td id="S2.T1.4.1.4.4.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S2.T1.4.1.4.4.6.1" class="ltx_text ltx_font_bold">✓</span></td>
<td id="S2.T1.4.1.4.4.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S2.T1.4.1.4.4.7.1" class="ltx_text ltx_font_bold">✓</span></td>
<td id="S2.T1.4.1.4.4.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S2.T1.4.1.4.4.8.1" class="ltx_text ltx_font_bold">✓</span></td>
</tr>
<tr id="S2.T1.4.1.5.5" class="ltx_tr">
<td id="S2.T1.4.1.5.5.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S2.T1.4.1.5.5.1.1" class="ltx_text ltx_font_bold">Supported Messaging Protocols</span></td>
<td id="S2.T1.4.1.5.5.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S2.T1.4.1.5.5.2.1" class="ltx_text ltx_font_bold">-</span></td>
<td id="S2.T1.4.1.5.5.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S2.T1.4.1.5.5.3.1" class="ltx_text ltx_font_bold">MPI</span></td>
<td id="S2.T1.4.1.5.5.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S2.T1.4.1.5.5.4.1" class="ltx_text ltx_font_bold">-</span></td>
<td id="S2.T1.4.1.5.5.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S2.T1.4.1.5.5.5.1" class="ltx_text ltx_font_bold">REST</span></td>
<td id="S2.T1.4.1.5.5.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S2.T1.4.1.5.5.6.1" class="ltx_text ltx_font_bold">-</span></td>
<td id="S2.T1.4.1.5.5.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S2.T1.4.1.5.5.7.1" class="ltx_text ltx_font_bold">MPI</span></td>
<td id="S2.T1.4.1.5.5.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S2.T1.4.1.5.5.8.1" class="ltx_text ltx_font_bold">Any</span></td>
</tr>
<tr id="S2.T1.4.1.6.6" class="ltx_tr">
<td id="S2.T1.4.1.6.6.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S2.T1.4.1.6.6.1.1" class="ltx_text ltx_font_bold">Secure</span></td>
<td id="S2.T1.4.1.6.6.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S2.T1.4.1.6.6.2.1" class="ltx_text ltx_font_bold">✓</span></td>
<td id="S2.T1.4.1.6.6.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S2.T1.4.1.6.6.3.1" class="ltx_text ltx_font_bold">✗</span></td>
<td id="S2.T1.4.1.6.6.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S2.T1.4.1.6.6.4.1" class="ltx_text ltx_font_bold">✓</span></td>
<td id="S2.T1.4.1.6.6.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S2.T1.4.1.6.6.5.1" class="ltx_text ltx_font_bold">✓</span></td>
<td id="S2.T1.4.1.6.6.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S2.T1.4.1.6.6.6.1" class="ltx_text ltx_font_bold">✓</span></td>
<td id="S2.T1.4.1.6.6.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S2.T1.4.1.6.6.7.1" class="ltx_text ltx_font_bold">✓</span></td>
<td id="S2.T1.4.1.6.6.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S2.T1.4.1.6.6.8.1" class="ltx_text ltx_font_bold">Any</span></td>
</tr>
<tr id="S2.T1.4.1.7.7" class="ltx_tr">
<td id="S2.T1.4.1.7.7.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S2.T1.4.1.7.7.1.1" class="ltx_text ltx_font_bold">Modular Components</span></td>
<td id="S2.T1.4.1.7.7.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S2.T1.4.1.7.7.2.1" class="ltx_text ltx_font_bold">✗</span></td>
<td id="S2.T1.4.1.7.7.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S2.T1.4.1.7.7.3.1" class="ltx_text ltx_font_bold">✗</span></td>
<td id="S2.T1.4.1.7.7.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S2.T1.4.1.7.7.4.1" class="ltx_text ltx_font_bold">✗</span></td>
<td id="S2.T1.4.1.7.7.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S2.T1.4.1.7.7.5.1" class="ltx_text ltx_font_bold">✗</span></td>
<td id="S2.T1.4.1.7.7.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S2.T1.4.1.7.7.6.1" class="ltx_text ltx_font_bold">✗</span></td>
<td id="S2.T1.4.1.7.7.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S2.T1.4.1.7.7.7.1" class="ltx_text ltx_font_bold">✗</span></td>
<td id="S2.T1.4.1.7.7.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S2.T1.4.1.7.7.8.1" class="ltx_text ltx_font_bold">✓</span></td>
</tr>
<tr id="S2.T1.4.1.8.8" class="ltx_tr">
<td id="S2.T1.4.1.8.8.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S2.T1.4.1.8.8.1.1" class="ltx_text ltx_font_bold">Built-In Monitoring Tools</span></td>
<td id="S2.T1.4.1.8.8.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S2.T1.4.1.8.8.2.1" class="ltx_text ltx_font_bold">✓</span></td>
<td id="S2.T1.4.1.8.8.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S2.T1.4.1.8.8.3.1" class="ltx_text ltx_font_bold">✗</span></td>
<td id="S2.T1.4.1.8.8.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S2.T1.4.1.8.8.4.1" class="ltx_text ltx_font_bold">✗</span></td>
<td id="S2.T1.4.1.8.8.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S2.T1.4.1.8.8.5.1" class="ltx_text ltx_font_bold">✗</span></td>
<td id="S2.T1.4.1.8.8.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S2.T1.4.1.8.8.6.1" class="ltx_text ltx_font_bold">✗</span></td>
<td id="S2.T1.4.1.8.8.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S2.T1.4.1.8.8.7.1" class="ltx_text ltx_font_bold">✗</span></td>
<td id="S2.T1.4.1.8.8.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S2.T1.4.1.8.8.8.1" class="ltx_text ltx_font_bold">✓</span></td>
</tr>
<tr id="S2.T1.4.1.9.9" class="ltx_tr">
<td id="S2.T1.4.1.9.9.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S2.T1.4.1.9.9.1.1" class="ltx_text ltx_font_bold">Third Party Support</span></td>
<td id="S2.T1.4.1.9.9.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S2.T1.4.1.9.9.2.1" class="ltx_text ltx_font_bold">✓</span></td>
<td id="S2.T1.4.1.9.9.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S2.T1.4.1.9.9.3.1" class="ltx_text ltx_font_bold">✗</span></td>
<td id="S2.T1.4.1.9.9.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S2.T1.4.1.9.9.4.1" class="ltx_text ltx_font_bold">✗</span></td>
<td id="S2.T1.4.1.9.9.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S2.T1.4.1.9.9.5.1" class="ltx_text ltx_font_bold">✗</span></td>
<td id="S2.T1.4.1.9.9.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S2.T1.4.1.9.9.6.1" class="ltx_text ltx_font_bold">✗</span></td>
<td id="S2.T1.4.1.9.9.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S2.T1.4.1.9.9.7.1" class="ltx_text ltx_font_bold">✗</span></td>
<td id="S2.T1.4.1.9.9.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S2.T1.4.1.9.9.8.1" class="ltx_text ltx_font_bold">✓</span></td>
</tr>
<tr id="S2.T1.4.1.10.10" class="ltx_tr">
<td id="S2.T1.4.1.10.10.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S2.T1.4.1.10.10.1.1" class="ltx_text ltx_font_bold">Customizable Data Center</span></td>
<td id="S2.T1.4.1.10.10.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S2.T1.4.1.10.10.2.1" class="ltx_text ltx_font_bold">✗</span></td>
<td id="S2.T1.4.1.10.10.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S2.T1.4.1.10.10.3.1" class="ltx_text ltx_font_bold">✗</span></td>
<td id="S2.T1.4.1.10.10.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S2.T1.4.1.10.10.4.1" class="ltx_text ltx_font_bold">✗</span></td>
<td id="S2.T1.4.1.10.10.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S2.T1.4.1.10.10.5.1" class="ltx_text ltx_font_bold">✗</span></td>
<td id="S2.T1.4.1.10.10.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S2.T1.4.1.10.10.6.1" class="ltx_text ltx_font_bold">✗</span></td>
<td id="S2.T1.4.1.10.10.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S2.T1.4.1.10.10.7.1" class="ltx_text ltx_font_bold">✗</span></td>
<td id="S2.T1.4.1.10.10.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S2.T1.4.1.10.10.8.1" class="ltx_text ltx_font_bold">✓</span></td>
</tr>
<tr id="S2.T1.4.1.11.11" class="ltx_tr">
<td id="S2.T1.4.1.11.11.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S2.T1.4.1.11.11.1.1" class="ltx_text ltx_font_bold">Diverse Data Distributor</span></td>
<td id="S2.T1.4.1.11.11.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S2.T1.4.1.11.11.2.1" class="ltx_text ltx_font_bold">✗</span></td>
<td id="S2.T1.4.1.11.11.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S2.T1.4.1.11.11.3.1" class="ltx_text ltx_font_bold">✗</span></td>
<td id="S2.T1.4.1.11.11.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S2.T1.4.1.11.11.4.1" class="ltx_text ltx_font_bold">✗</span></td>
<td id="S2.T1.4.1.11.11.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S2.T1.4.1.11.11.5.1" class="ltx_text ltx_font_bold">✗</span></td>
<td id="S2.T1.4.1.11.11.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S2.T1.4.1.11.11.6.1" class="ltx_text ltx_font_bold">✗</span></td>
<td id="S2.T1.4.1.11.11.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S2.T1.4.1.11.11.7.1" class="ltx_text ltx_font_bold">✗</span></td>
<td id="S2.T1.4.1.11.11.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S2.T1.4.1.11.11.8.1" class="ltx_text ltx_font_bold">✓</span></td>
</tr>
<tr id="S2.T1.4.1.12.12" class="ltx_tr">
<td id="S2.T1.4.1.12.12.1" class="ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S2.T1.4.1.12.12.1.1" class="ltx_text ltx_font_bold">Client Simulation</span></td>
<td id="S2.T1.4.1.12.12.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S2.T1.4.1.12.12.2.1" class="ltx_text ltx_font_bold">✗</span></td>
<td id="S2.T1.4.1.12.12.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S2.T1.4.1.12.12.3.1" class="ltx_text ltx_font_bold">✗</span></td>
<td id="S2.T1.4.1.12.12.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S2.T1.4.1.12.12.4.1" class="ltx_text ltx_font_bold">✗</span></td>
<td id="S2.T1.4.1.12.12.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S2.T1.4.1.12.12.5.1" class="ltx_text ltx_font_bold">✗</span></td>
<td id="S2.T1.4.1.12.12.6" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S2.T1.4.1.12.12.6.1" class="ltx_text ltx_font_bold">✗</span></td>
<td id="S2.T1.4.1.12.12.7" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S2.T1.4.1.12.12.7.1" class="ltx_text ltx_font_bold">✓</span></td>
<td id="S2.T1.4.1.12.12.8" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S2.T1.4.1.12.12.8.1" class="ltx_text ltx_font_bold">✓</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div id="S2.p3" class="ltx_para">
<p id="S2.p3.1" class="ltx_p">Table <a href="#S2.T1" title="Table 1 ‣ 2 Related Work ‣ ModularFed: Leveraging Modularity in Federated Learning Frameworks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> provides a detailed comparison between our approach and the current federated frameworks. We emphasize the limitation of the current approaches, which we aim to address using ours:</p>
</div>
<div id="S2.p4" class="ltx_para">
<p id="S2.p4.1" class="ltx_p"><span id="S2.p4.1.1" class="ltx_text ltx_font_bold">Lack of modular component support:</span> Modularity, in our case, refers to frameworks’ supporting individual building blocks with a separate role assigned for each. Together, modular components form a framework that endorses modular interchange. Due to the lack of support for such a concept, the majority tend to build their own environment instead of working within contextual frameworks with a high learning curve while risking the possibility of not supporting their works. Consequently, the experimental results might not demonstrate a fair comparison in terms of distinct implementation differences and unmanaged statistical environments. Addressing these issues, we pursue a layered architecture in our framework called the federated abstract layer (FAL). With FAL, we design our components based on carefully crafted protocols while delegating the behaviours to the following layers. Accordingly, protocols are blueprints that define the interaction between the architecture components, allowing researchers to develop flexible and extensible FL approaches. FAL enables FL to support diverse execution mechanisms, such as distributed execution in virtual containers, real devices, or local parallel execution on the same host. Additionally, FAL facilitates extending approaches with supporting features such as security and bandwidth optimization through model compression modules.</p>
</div>
<div id="S2.p5" class="ltx_para">
<p id="S2.p5.1" class="ltx_p"><span id="S2.p5.1.1" class="ltx_text ltx_font_bold">Lack of data management protocols:</span> Current frameworks only support a few well-known datasets used in FL. Built-in tools back up these datasets for easier management, such as dynamic allocation from the cloud or data distribution simulators. However, they are limited to only the supported datasets, while incorporating new ones compels designing these tools from scratch. In this regard, we integrate the data management as part of the framework and outsource the required protocols and APIs to allow further data expansion depending on the designer’s needs.</p>
</div>
<div id="S2.p6" class="ltx_para">
<p id="S2.p6.1" class="ltx_p"><span id="S2.p6.1.1" class="ltx_text ltx_font_bold">Third Party Support:</span> By third parties, we refer to any components with a role not related directly to FL workflow. For instance, external monitoring components such as Tensor-Board and Wandb are considered under this category. Additionally, components built to enhance FL architecture are considered a third party, such as model caching, models’ parameters analysis, logging, and others. These tools do not affect or are presented in the federated workflow. However, including them increases the framework’s complexity. Thus, frameworks either do not support third-party tools or only support a few well-known ones. In our case, we started our framework design with the concept of supporting third parties by incorporating an observable pattern for our components. As such, a list of third parties, called subscribers, can be attached to any federated application and receive live updates about the state of the execution employed, extending it with further applications such as monitoring, logging, or analysis.</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Federated Learning Overview</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">FL is a branch of distributed learning where multiple individual parties collaborate to train a single model. However, unlike distributed learning, FL operates without sharing private data with collaborators. Instead, it invites them to train a model locally on their devices using the same configuration and share only the trained parameters. The following properties define Federated Learning:</p>
<ul id="S3.I1" class="ltx_itemize">
<li id="S3.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S3.I1.i1.p1" class="ltx_para">
<p id="S3.I1.i1.p1.1" class="ltx_p"><span id="S3.I1.i1.p1.1.1" class="ltx_text ltx_font_bold">Global Model</span> (GM): Initialized by the server and holds its configuration and the initial parameters values. Preceding any further actions, each working client holds the latest copy of the GM shared by the server.</p>
</div>
</li>
<li id="S3.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S3.I1.i2.p1" class="ltx_para">
<p id="S3.I1.i2.p1.1" class="ltx_p"><span id="S3.I1.i2.p1.1.1" class="ltx_text ltx_font_bold">Aggregation:</span> A procedure the server executes when it receives the required updates from its clients. The received updates are combined and committed to the Global Model at the end of the procedure.</p>
</div>
</li>
<li id="S3.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="S3.I1.i3.p1" class="ltx_para">
<p id="S3.I1.i3.p1.1" class="ltx_p"><span id="S3.I1.i3.p1.1.1" class="ltx_text ltx_font_bold">Client Selection:</span> A typical FL context comprises a large pool of clients, which demands considerable computational resources and causes network congestion on the server. Additionally, it is impracticable to guarantee the availability of all the clients in every round, especially when a task might take a considerable amount of time. Thus, most FL approaches incorporate a client selection phase to filter the clients either randomly or by specified constraints <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib41" title="" class="ltx_ref">41</a>, <a href="#bib.bib31" title="" class="ltx_ref">31</a>, <a href="#bib.bib29" title="" class="ltx_ref">29</a>, <a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>, and only the selected clients will participate in the specified round.</p>
</div>
</li>
</ul>
</div>
<div id="S3.p2" class="ltx_para">
<p id="S3.p2.1" class="ltx_p">In Figure <a href="#S3.F1" title="Figure 1 ‣ 3 Federated Learning Overview ‣ ModularFed: Leveraging Modularity in Federated Learning Frameworks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, we present an overview of a standard FL workflow. The server starts with the initialization, validating the parameters and issuing the first copy of the Global Model. We follow the same initialization strategy as <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>, where the server starts by initializing the model weights and sharing them with the selected clients. Having clients start from the same initialization improves the loss reduction after weights aggregation. A federated round begins by selecting a set of clients from the available ones. The selected clients receive a copy of the Global Model and proceed with the model training from their local datasets. When the selected clients finish, each sends back the models to the server. The server aggregates the received updates and generates a new, evolved Global Model, substituting the old one. When working in a research environment, part of the dataset is kept to monitor the model evolution and validate the approach’s applicability. After each aggregation, the server infers the model metrics from the test dataset and logs them. Eventually, FL stops when reaching the stopping criteria, such as completing a specified number of rounds or achieving a predefined accuracy or loss.</p>
</div>
<figure id="S3.F1" class="ltx_figure"><img src="/html/2212.10427/assets/fl-workflow.png" id="S3.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="467" height="307" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F1.2.1.1" class="ltx_text" style="font-size:90%;">Figure 1</span>: </span><span id="S3.F1.3.2" class="ltx_text" style="font-size:90%;">Federated Learning Workflow</span></figcaption>
</figure>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Federated Learning Framework</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">Figure <a href="#S4.F2" title="Figure 2 ‣ 4 Federated Learning Framework ‣ ModularFed: Leveraging Modularity in Federated Learning Frameworks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> provides an overview of the proposed framework architecture. Three key components define our architecture from the rest: FL Abstraction Layer (FAL), FL Subscribers, and Data Control Center.</p>
</div>
<figure id="S4.F2" class="ltx_figure"><img src="/html/2212.10427/assets/fl-architecture.png" id="S4.F2.g1" class="ltx_graphics ltx_centering ltx_img_square" width="586" height="529" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F2.2.1.1" class="ltx_text" style="font-size:90%;">Figure 2</span>: </span><span id="S4.F2.3.2" class="ltx_text" style="font-size:90%;">Proposed Layered Architecture</span></figcaption>
</figure>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>FL Abstraction Layer</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">We follow a hierarchical mechanism to qualify extensions and new approaches control over the necessary component dynamically and with minimum modification to the rest of the framework. We standardize FL components through FAL as protocols defining compulsory properties and parameters while delegating the behaviour to the subsequent layers. Federated learning workflow reflects on FAL components and is separated into two higher-order components: Network Components to handle the communication and Processing Components for vital calculations such as aggregation and client selection. Moreover, the kernel is the glue that manages the FAL and advances with the ordered execution of the FL workflow while taking advantage of the FAL flexibility. Figure <a href="#S4.F3" title="Figure 3 ‣ 4.1 FL Abstraction Layer ‣ 4 Federated Learning Framework ‣ ModularFed: Leveraging Modularity in Federated Learning Frameworks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> presents UML Component Diagram of the FAL, while Figure <a href="#S4.F4" title="Figure 4 ‣ 4.1 FL Abstraction Layer ‣ 4 Federated Learning Framework ‣ ModularFed: Leveraging Modularity in Federated Learning Frameworks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> shows the entire training implementation with the FAL components highlighted.</p>
</div>
<figure id="S4.F3" class="ltx_figure"><img src="/html/2212.10427/assets/uml.png" id="S4.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="467" height="257" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F3.2.1.1" class="ltx_text" style="font-size:90%;">Figure 3</span>: </span><span id="S4.F3.3.2" class="ltx_text" style="font-size:90%;">FAL UML Components Diagram</span></figcaption>
</figure>
<figure id="S4.F4" class="ltx_figure"><img src="/html/2212.10427/assets/code1.png" id="S4.F4.g1" class="ltx_graphics ltx_centering ltx_img_square" width="449" height="410" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F4.2.1.1" class="ltx_text" style="font-size:90%;">Figure 4</span>: </span><span id="S4.F4.3.2" class="ltx_text" style="font-size:90%;">FAL Design Pattern</span></figcaption>
</figure>
<div id="S4.SS1.p2" class="ltx_para">
<p id="S4.SS1.p2.1" class="ltx_p">The Client component is an interface that enables the framework to simulate diverse training contexts allowing it to adapt to the needed scenarios. For instance, a client simulation can be straightforward, such as a PyTorch instance for model training, or more complex, such as a virtual node or a tangible IoT device. We consider the client component as a separate entity from the core module, which opens opportunities for more complex topologies where clients are free from core control while withholding only the minimum specification posed by FAL architecture.</p>
</div>
<div id="S4.SS1.p3" class="ltx_para">
<p id="S4.SS1.p3.1" class="ltx_p">On the other hand, CL-Manager is the middleware between the core and clients, responsible for managing the clients, communicating tasks, and global model updates. CL-Manager shapes the interaction between the core and the clients authorizing various behaviours such as parallelism, secure integrated network, or further network optimization such as model compression or communication over any available network protocol. Depending on the case, each client works with a distinct Client-Manager. For example, to enable parallelism in a restricted python environment, it is necessary to use MPI-supported clients coupled with a compatible MPI-based CL-Manager. Similarly, communications with the CL-Manager occur over web protocols when working with IoT clients. Thus, it is imperative to have both components’ architecture capable of adapting to diverse circumstances. In Figure <a href="#S4.F5" title="Figure 5 ‣ 4.1 FL Abstraction Layer ‣ 4 Federated Learning Framework ‣ ModularFed: Leveraging Modularity in Federated Learning Frameworks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>, we show the connection between both components and highlight the applicability of a single CL-Manager in supporting multiple types of clients simultaneously.</p>
</div>
<figure id="S4.F5" class="ltx_figure"><img src="/html/2212.10427/assets/client-manager.png" id="S4.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="389" height="103" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F5.2.1.1" class="ltx_text" style="font-size:90%;">Figure 5</span>: </span><span id="S4.F5.3.2" class="ltx_text" style="font-size:90%;">The relation between network manager and the supported clients’ types</span></figcaption>
</figure>
<div id="S4.SS1.p4" class="ltx_para">
<p id="S4.SS1.p4.1" class="ltx_p">Finally, the core controls the execution of the given interfaces following the FL workflow discussed in Section <a href="#S3" title="3 Federated Learning Overview ‣ ModularFed: Leveraging Modularity in Federated Learning Frameworks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>. It accepts any components extending the FAL protocols with additional subscriber components will discuss in Section <a href="#S4.SS2" title="4.2 FL-Subscribers ‣ 4 Federated Learning Framework ‣ ModularFed: Leveraging Modularity in Federated Learning Frameworks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.2</span></a>. To keep track of the progress, the FL core creates an FL-Context. It withholds information regarding the state of the execution, including the global model weights, round number, and metrics results after each round’s completion.</p>
</div>
<div id="S4.SS1.p5" class="ltx_para">
<p id="S4.SS1.p5.1" class="ltx_p">Regardless of what a researcher aims for, an inclusive environment is vital for running tests and obtaining results while comparing them with others. Through FAL, we provide the necessary environment for researchers to overlook the context and concentrate on their targets. Additionally, the modularity of the framework components, which originated from the layered architecture, allows module swapping, minimizes efforts, and secures a fair comparison.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>FL-Subscribers</h3>

<figure id="S4.F6" class="ltx_figure"><img src="/html/2212.10427/assets/ad-workflow.png" id="S4.F6.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="538" height="271" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F6.2.1.1" class="ltx_text" style="font-size:90%;">Figure 6</span>: </span><span id="S4.F6.3.2" class="ltx_text" style="font-size:90%;">Federated Learning Workflow Including Subscribers</span></figcaption>
</figure>
<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.2" class="ltx_p">A typical federated learning application entails different mechanisms such as logging, caching, monitoring the model evolution, drawing charts, saving results, and others. The diversity of these tools is not limited, as each project needs its own. For example, integrating model evolution to monitor the weight divergence between the clients’ parameters will eventually increase the workflow intricacy and complicate its integration with other solutions. Thus, we consider our subscription architecture to solve the mentioned challenges. We built our kernel following the observable software design pattern to achieve our objective. During the initialization step, the FL core registers a list of components subject to the FL Subscriber protocols. During the execution, each subscriber receives, in real-time, broadcasts from the core in the form of updates comprising the states of the intended events. These events have predetermined a priory, and each contains an update bound to specific events in the workflow. Figure <a href="#S4.F6" title="Figure 6 ‣ 4.2 FL-Subscribers ‣ 4 Federated Learning Framework ‣ ModularFed: Leveraging Modularity in Federated Learning Frameworks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> contains a detailed representation of the FL workflow core following the integration of the observable pattern. The events cover every step in the workflow; each provides the execution state and distinct information related to the event phase. For example, <math id="S4.SS2.p1.1.m1.1" class="ltx_Math" alttext="bct:trainers\_selected" display="inline"><semantics id="S4.SS2.p1.1.m1.1a"><mrow id="S4.SS2.p1.1.m1.1.1" xref="S4.SS2.p1.1.m1.1.1.cmml"><mrow id="S4.SS2.p1.1.m1.1.1.2" xref="S4.SS2.p1.1.m1.1.1.2.cmml"><mi id="S4.SS2.p1.1.m1.1.1.2.2" xref="S4.SS2.p1.1.m1.1.1.2.2.cmml">b</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p1.1.m1.1.1.2.1" xref="S4.SS2.p1.1.m1.1.1.2.1.cmml">​</mo><mi id="S4.SS2.p1.1.m1.1.1.2.3" xref="S4.SS2.p1.1.m1.1.1.2.3.cmml">c</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p1.1.m1.1.1.2.1a" xref="S4.SS2.p1.1.m1.1.1.2.1.cmml">​</mo><mi id="S4.SS2.p1.1.m1.1.1.2.4" xref="S4.SS2.p1.1.m1.1.1.2.4.cmml">t</mi></mrow><mo lspace="0.278em" rspace="0.278em" id="S4.SS2.p1.1.m1.1.1.1" xref="S4.SS2.p1.1.m1.1.1.1.cmml">:</mo><mrow id="S4.SS2.p1.1.m1.1.1.3" xref="S4.SS2.p1.1.m1.1.1.3.cmml"><mi id="S4.SS2.p1.1.m1.1.1.3.2" xref="S4.SS2.p1.1.m1.1.1.3.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p1.1.m1.1.1.3.1" xref="S4.SS2.p1.1.m1.1.1.3.1.cmml">​</mo><mi id="S4.SS2.p1.1.m1.1.1.3.3" xref="S4.SS2.p1.1.m1.1.1.3.3.cmml">r</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p1.1.m1.1.1.3.1a" xref="S4.SS2.p1.1.m1.1.1.3.1.cmml">​</mo><mi id="S4.SS2.p1.1.m1.1.1.3.4" xref="S4.SS2.p1.1.m1.1.1.3.4.cmml">a</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p1.1.m1.1.1.3.1b" xref="S4.SS2.p1.1.m1.1.1.3.1.cmml">​</mo><mi id="S4.SS2.p1.1.m1.1.1.3.5" xref="S4.SS2.p1.1.m1.1.1.3.5.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p1.1.m1.1.1.3.1c" xref="S4.SS2.p1.1.m1.1.1.3.1.cmml">​</mo><mi id="S4.SS2.p1.1.m1.1.1.3.6" xref="S4.SS2.p1.1.m1.1.1.3.6.cmml">n</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p1.1.m1.1.1.3.1d" xref="S4.SS2.p1.1.m1.1.1.3.1.cmml">​</mo><mi id="S4.SS2.p1.1.m1.1.1.3.7" xref="S4.SS2.p1.1.m1.1.1.3.7.cmml">e</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p1.1.m1.1.1.3.1e" xref="S4.SS2.p1.1.m1.1.1.3.1.cmml">​</mo><mi id="S4.SS2.p1.1.m1.1.1.3.8" xref="S4.SS2.p1.1.m1.1.1.3.8.cmml">r</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p1.1.m1.1.1.3.1f" xref="S4.SS2.p1.1.m1.1.1.3.1.cmml">​</mo><mi id="S4.SS2.p1.1.m1.1.1.3.9" xref="S4.SS2.p1.1.m1.1.1.3.9.cmml">s</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p1.1.m1.1.1.3.1g" xref="S4.SS2.p1.1.m1.1.1.3.1.cmml">​</mo><mi mathvariant="normal" id="S4.SS2.p1.1.m1.1.1.3.10" xref="S4.SS2.p1.1.m1.1.1.3.10.cmml">_</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p1.1.m1.1.1.3.1h" xref="S4.SS2.p1.1.m1.1.1.3.1.cmml">​</mo><mi id="S4.SS2.p1.1.m1.1.1.3.11" xref="S4.SS2.p1.1.m1.1.1.3.11.cmml">s</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p1.1.m1.1.1.3.1i" xref="S4.SS2.p1.1.m1.1.1.3.1.cmml">​</mo><mi id="S4.SS2.p1.1.m1.1.1.3.12" xref="S4.SS2.p1.1.m1.1.1.3.12.cmml">e</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p1.1.m1.1.1.3.1j" xref="S4.SS2.p1.1.m1.1.1.3.1.cmml">​</mo><mi id="S4.SS2.p1.1.m1.1.1.3.13" xref="S4.SS2.p1.1.m1.1.1.3.13.cmml">l</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p1.1.m1.1.1.3.1k" xref="S4.SS2.p1.1.m1.1.1.3.1.cmml">​</mo><mi id="S4.SS2.p1.1.m1.1.1.3.14" xref="S4.SS2.p1.1.m1.1.1.3.14.cmml">e</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p1.1.m1.1.1.3.1l" xref="S4.SS2.p1.1.m1.1.1.3.1.cmml">​</mo><mi id="S4.SS2.p1.1.m1.1.1.3.15" xref="S4.SS2.p1.1.m1.1.1.3.15.cmml">c</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p1.1.m1.1.1.3.1m" xref="S4.SS2.p1.1.m1.1.1.3.1.cmml">​</mo><mi id="S4.SS2.p1.1.m1.1.1.3.16" xref="S4.SS2.p1.1.m1.1.1.3.16.cmml">t</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p1.1.m1.1.1.3.1n" xref="S4.SS2.p1.1.m1.1.1.3.1.cmml">​</mo><mi id="S4.SS2.p1.1.m1.1.1.3.17" xref="S4.SS2.p1.1.m1.1.1.3.17.cmml">e</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p1.1.m1.1.1.3.1o" xref="S4.SS2.p1.1.m1.1.1.3.1.cmml">​</mo><mi id="S4.SS2.p1.1.m1.1.1.3.18" xref="S4.SS2.p1.1.m1.1.1.3.18.cmml">d</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.1.m1.1b"><apply id="S4.SS2.p1.1.m1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1"><ci id="S4.SS2.p1.1.m1.1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1.1">:</ci><apply id="S4.SS2.p1.1.m1.1.1.2.cmml" xref="S4.SS2.p1.1.m1.1.1.2"><times id="S4.SS2.p1.1.m1.1.1.2.1.cmml" xref="S4.SS2.p1.1.m1.1.1.2.1"></times><ci id="S4.SS2.p1.1.m1.1.1.2.2.cmml" xref="S4.SS2.p1.1.m1.1.1.2.2">𝑏</ci><ci id="S4.SS2.p1.1.m1.1.1.2.3.cmml" xref="S4.SS2.p1.1.m1.1.1.2.3">𝑐</ci><ci id="S4.SS2.p1.1.m1.1.1.2.4.cmml" xref="S4.SS2.p1.1.m1.1.1.2.4">𝑡</ci></apply><apply id="S4.SS2.p1.1.m1.1.1.3.cmml" xref="S4.SS2.p1.1.m1.1.1.3"><times id="S4.SS2.p1.1.m1.1.1.3.1.cmml" xref="S4.SS2.p1.1.m1.1.1.3.1"></times><ci id="S4.SS2.p1.1.m1.1.1.3.2.cmml" xref="S4.SS2.p1.1.m1.1.1.3.2">𝑡</ci><ci id="S4.SS2.p1.1.m1.1.1.3.3.cmml" xref="S4.SS2.p1.1.m1.1.1.3.3">𝑟</ci><ci id="S4.SS2.p1.1.m1.1.1.3.4.cmml" xref="S4.SS2.p1.1.m1.1.1.3.4">𝑎</ci><ci id="S4.SS2.p1.1.m1.1.1.3.5.cmml" xref="S4.SS2.p1.1.m1.1.1.3.5">𝑖</ci><ci id="S4.SS2.p1.1.m1.1.1.3.6.cmml" xref="S4.SS2.p1.1.m1.1.1.3.6">𝑛</ci><ci id="S4.SS2.p1.1.m1.1.1.3.7.cmml" xref="S4.SS2.p1.1.m1.1.1.3.7">𝑒</ci><ci id="S4.SS2.p1.1.m1.1.1.3.8.cmml" xref="S4.SS2.p1.1.m1.1.1.3.8">𝑟</ci><ci id="S4.SS2.p1.1.m1.1.1.3.9.cmml" xref="S4.SS2.p1.1.m1.1.1.3.9">𝑠</ci><ci id="S4.SS2.p1.1.m1.1.1.3.10.cmml" xref="S4.SS2.p1.1.m1.1.1.3.10">_</ci><ci id="S4.SS2.p1.1.m1.1.1.3.11.cmml" xref="S4.SS2.p1.1.m1.1.1.3.11">𝑠</ci><ci id="S4.SS2.p1.1.m1.1.1.3.12.cmml" xref="S4.SS2.p1.1.m1.1.1.3.12">𝑒</ci><ci id="S4.SS2.p1.1.m1.1.1.3.13.cmml" xref="S4.SS2.p1.1.m1.1.1.3.13">𝑙</ci><ci id="S4.SS2.p1.1.m1.1.1.3.14.cmml" xref="S4.SS2.p1.1.m1.1.1.3.14">𝑒</ci><ci id="S4.SS2.p1.1.m1.1.1.3.15.cmml" xref="S4.SS2.p1.1.m1.1.1.3.15">𝑐</ci><ci id="S4.SS2.p1.1.m1.1.1.3.16.cmml" xref="S4.SS2.p1.1.m1.1.1.3.16">𝑡</ci><ci id="S4.SS2.p1.1.m1.1.1.3.17.cmml" xref="S4.SS2.p1.1.m1.1.1.3.17">𝑒</ci><ci id="S4.SS2.p1.1.m1.1.1.3.18.cmml" xref="S4.SS2.p1.1.m1.1.1.3.18">𝑑</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.1.m1.1c">bct:trainers\_selected</annotation></semantics></math> provides information about the selected trainer ids, while <math id="S4.SS2.p1.2.m2.1" class="ltx_Math" alttext="bct:round\_finished" display="inline"><semantics id="S4.SS2.p1.2.m2.1a"><mrow id="S4.SS2.p1.2.m2.1.1" xref="S4.SS2.p1.2.m2.1.1.cmml"><mrow id="S4.SS2.p1.2.m2.1.1.2" xref="S4.SS2.p1.2.m2.1.1.2.cmml"><mi id="S4.SS2.p1.2.m2.1.1.2.2" xref="S4.SS2.p1.2.m2.1.1.2.2.cmml">b</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p1.2.m2.1.1.2.1" xref="S4.SS2.p1.2.m2.1.1.2.1.cmml">​</mo><mi id="S4.SS2.p1.2.m2.1.1.2.3" xref="S4.SS2.p1.2.m2.1.1.2.3.cmml">c</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p1.2.m2.1.1.2.1a" xref="S4.SS2.p1.2.m2.1.1.2.1.cmml">​</mo><mi id="S4.SS2.p1.2.m2.1.1.2.4" xref="S4.SS2.p1.2.m2.1.1.2.4.cmml">t</mi></mrow><mo lspace="0.278em" rspace="0.278em" id="S4.SS2.p1.2.m2.1.1.1" xref="S4.SS2.p1.2.m2.1.1.1.cmml">:</mo><mrow id="S4.SS2.p1.2.m2.1.1.3" xref="S4.SS2.p1.2.m2.1.1.3.cmml"><mi id="S4.SS2.p1.2.m2.1.1.3.2" xref="S4.SS2.p1.2.m2.1.1.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p1.2.m2.1.1.3.1" xref="S4.SS2.p1.2.m2.1.1.3.1.cmml">​</mo><mi id="S4.SS2.p1.2.m2.1.1.3.3" xref="S4.SS2.p1.2.m2.1.1.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p1.2.m2.1.1.3.1a" xref="S4.SS2.p1.2.m2.1.1.3.1.cmml">​</mo><mi id="S4.SS2.p1.2.m2.1.1.3.4" xref="S4.SS2.p1.2.m2.1.1.3.4.cmml">u</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p1.2.m2.1.1.3.1b" xref="S4.SS2.p1.2.m2.1.1.3.1.cmml">​</mo><mi id="S4.SS2.p1.2.m2.1.1.3.5" xref="S4.SS2.p1.2.m2.1.1.3.5.cmml">n</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p1.2.m2.1.1.3.1c" xref="S4.SS2.p1.2.m2.1.1.3.1.cmml">​</mo><mi id="S4.SS2.p1.2.m2.1.1.3.6" xref="S4.SS2.p1.2.m2.1.1.3.6.cmml">d</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p1.2.m2.1.1.3.1d" xref="S4.SS2.p1.2.m2.1.1.3.1.cmml">​</mo><mi mathvariant="normal" id="S4.SS2.p1.2.m2.1.1.3.7" xref="S4.SS2.p1.2.m2.1.1.3.7.cmml">_</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p1.2.m2.1.1.3.1e" xref="S4.SS2.p1.2.m2.1.1.3.1.cmml">​</mo><mi id="S4.SS2.p1.2.m2.1.1.3.8" xref="S4.SS2.p1.2.m2.1.1.3.8.cmml">f</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p1.2.m2.1.1.3.1f" xref="S4.SS2.p1.2.m2.1.1.3.1.cmml">​</mo><mi id="S4.SS2.p1.2.m2.1.1.3.9" xref="S4.SS2.p1.2.m2.1.1.3.9.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p1.2.m2.1.1.3.1g" xref="S4.SS2.p1.2.m2.1.1.3.1.cmml">​</mo><mi id="S4.SS2.p1.2.m2.1.1.3.10" xref="S4.SS2.p1.2.m2.1.1.3.10.cmml">n</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p1.2.m2.1.1.3.1h" xref="S4.SS2.p1.2.m2.1.1.3.1.cmml">​</mo><mi id="S4.SS2.p1.2.m2.1.1.3.11" xref="S4.SS2.p1.2.m2.1.1.3.11.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p1.2.m2.1.1.3.1i" xref="S4.SS2.p1.2.m2.1.1.3.1.cmml">​</mo><mi id="S4.SS2.p1.2.m2.1.1.3.12" xref="S4.SS2.p1.2.m2.1.1.3.12.cmml">s</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p1.2.m2.1.1.3.1j" xref="S4.SS2.p1.2.m2.1.1.3.1.cmml">​</mo><mi id="S4.SS2.p1.2.m2.1.1.3.13" xref="S4.SS2.p1.2.m2.1.1.3.13.cmml">h</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p1.2.m2.1.1.3.1k" xref="S4.SS2.p1.2.m2.1.1.3.1.cmml">​</mo><mi id="S4.SS2.p1.2.m2.1.1.3.14" xref="S4.SS2.p1.2.m2.1.1.3.14.cmml">e</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p1.2.m2.1.1.3.1l" xref="S4.SS2.p1.2.m2.1.1.3.1.cmml">​</mo><mi id="S4.SS2.p1.2.m2.1.1.3.15" xref="S4.SS2.p1.2.m2.1.1.3.15.cmml">d</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.2.m2.1b"><apply id="S4.SS2.p1.2.m2.1.1.cmml" xref="S4.SS2.p1.2.m2.1.1"><ci id="S4.SS2.p1.2.m2.1.1.1.cmml" xref="S4.SS2.p1.2.m2.1.1.1">:</ci><apply id="S4.SS2.p1.2.m2.1.1.2.cmml" xref="S4.SS2.p1.2.m2.1.1.2"><times id="S4.SS2.p1.2.m2.1.1.2.1.cmml" xref="S4.SS2.p1.2.m2.1.1.2.1"></times><ci id="S4.SS2.p1.2.m2.1.1.2.2.cmml" xref="S4.SS2.p1.2.m2.1.1.2.2">𝑏</ci><ci id="S4.SS2.p1.2.m2.1.1.2.3.cmml" xref="S4.SS2.p1.2.m2.1.1.2.3">𝑐</ci><ci id="S4.SS2.p1.2.m2.1.1.2.4.cmml" xref="S4.SS2.p1.2.m2.1.1.2.4">𝑡</ci></apply><apply id="S4.SS2.p1.2.m2.1.1.3.cmml" xref="S4.SS2.p1.2.m2.1.1.3"><times id="S4.SS2.p1.2.m2.1.1.3.1.cmml" xref="S4.SS2.p1.2.m2.1.1.3.1"></times><ci id="S4.SS2.p1.2.m2.1.1.3.2.cmml" xref="S4.SS2.p1.2.m2.1.1.3.2">𝑟</ci><ci id="S4.SS2.p1.2.m2.1.1.3.3.cmml" xref="S4.SS2.p1.2.m2.1.1.3.3">𝑜</ci><ci id="S4.SS2.p1.2.m2.1.1.3.4.cmml" xref="S4.SS2.p1.2.m2.1.1.3.4">𝑢</ci><ci id="S4.SS2.p1.2.m2.1.1.3.5.cmml" xref="S4.SS2.p1.2.m2.1.1.3.5">𝑛</ci><ci id="S4.SS2.p1.2.m2.1.1.3.6.cmml" xref="S4.SS2.p1.2.m2.1.1.3.6">𝑑</ci><ci id="S4.SS2.p1.2.m2.1.1.3.7.cmml" xref="S4.SS2.p1.2.m2.1.1.3.7">_</ci><ci id="S4.SS2.p1.2.m2.1.1.3.8.cmml" xref="S4.SS2.p1.2.m2.1.1.3.8">𝑓</ci><ci id="S4.SS2.p1.2.m2.1.1.3.9.cmml" xref="S4.SS2.p1.2.m2.1.1.3.9">𝑖</ci><ci id="S4.SS2.p1.2.m2.1.1.3.10.cmml" xref="S4.SS2.p1.2.m2.1.1.3.10">𝑛</ci><ci id="S4.SS2.p1.2.m2.1.1.3.11.cmml" xref="S4.SS2.p1.2.m2.1.1.3.11">𝑖</ci><ci id="S4.SS2.p1.2.m2.1.1.3.12.cmml" xref="S4.SS2.p1.2.m2.1.1.3.12">𝑠</ci><ci id="S4.SS2.p1.2.m2.1.1.3.13.cmml" xref="S4.SS2.p1.2.m2.1.1.3.13">ℎ</ci><ci id="S4.SS2.p1.2.m2.1.1.3.14.cmml" xref="S4.SS2.p1.2.m2.1.1.3.14">𝑒</ci><ci id="S4.SS2.p1.2.m2.1.1.3.15.cmml" xref="S4.SS2.p1.2.m2.1.1.3.15">𝑑</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.2.m2.1c">bct:round\_finished</annotation></semantics></math> includes the measured metrics of the Global Model after merging the latest updates.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.1" class="ltx_p">Figure <a href="#S4.F7" title="Figure 7 ‣ 4.2 FL-Subscribers ‣ 4 Federated Learning Framework ‣ ModularFed: Leveraging Modularity in Federated Learning Frameworks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> depicts the subscribers integration into a training procedure. The framework provides a list of subscribers, such as Logging Subscribers, to keep track of the execution progress and estimate the execution time. Caching Subscriber is capable of saving execution checkpoints, allowing the runtime to be resumable in case it shuts down due to unplanned circumstances. Metrics Logger stores the metrics result to SQL database, Markup Based Files or external third-party tools such as TensorBoard or Wandb <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib42" title="" class="ltx_ref">42</a>]</cite>. Finally, we include analysis tools as subscribers to monitor the model weights evolution or client selection shift after each federated round. Limitless functionalities can be plugged into our framework without altering the core. It is an excellent choice for researchers aiming for collaboration, extending their work or carrying out their methodologies to other approaches.</p>
</div>
<figure id="S4.F7" class="ltx_figure"><img src="/html/2212.10427/assets/code2.png" id="S4.F7.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="586" height="233" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F7.2.1.1" class="ltx_text" style="font-size:90%;">Figure 7</span>: </span><span id="S4.F7.3.2" class="ltx_text" style="font-size:90%;">Subscription Design Pattern</span></figcaption>
</figure>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Data-Center</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">Providing solutions for federated learning requires working with different datasets collected from various sources. Additionally, most experiments include working with multiple data distributions between clients to check if the solution is tolerant to the Non-IID problem. Simulating various Non-IID client behaviour is challenging when combined with the diversity of the datasets. Thus, we aim through our Data-Center to provide the necessary protocols addressing the aforementioned problems. Figure <a href="#S4.F2" title="Figure 2 ‣ 4 Federated Learning Framework ‣ ModularFed: Leveraging Modularity in Federated Learning Frameworks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> introduces our Data-Center, as an underlying methodology supporting our framework with its three key components: Containers, Distributors, and Providers.</p>
</div>
<div id="S4.SS3.p2" class="ltx_para">
<p id="S4.SS3.p2.4" class="ltx_p">Integrating data <span id="S4.SS3.p2.4.1" class="ltx_text ltx_font_bold">Containers</span> unifies the data objects under one protocol across the framework, alleviating the complexity of working with diverse sources.
Moreover, the core integrates the containers in its workflow, allowing it to handle some dataset routines such as train/test split, batching and type conversion. <span id="S4.SS3.p2.4.2" class="ltx_text ltx_font_bold">Providers</span> represent the raw dataset sources used for the client simulation. The source can be anything from cloud storage, databases, local files, and others. The protocols imply outsourcing the raw data to the framework as Containers, which can be used directly to simulate the client’s behaviours. Finally, it is essential to demonstrate the capability of any approach against the statistical difficulties caused by the federated learning architecture. With the <span id="S4.SS3.p2.4.3" class="ltx_text ltx_font_bold">Distributors</span> component, we aim to standardize the distribution strategies under one protocol capable of simulating most of the Non-IID/IID scenarios. The behaviour of the distributor varies depending on the implementation. In the following, we explain in detail the currently supported distribution while enclosing heatmaps images which present an example of the data distributed to each client following the usage of a distributor. In the images, the X-axis represents the labels, the Y-axis represents the clients, and the intersection between X and Y represents the number of records a label <math id="S4.SS3.p2.1.m1.1" class="ltx_Math" alttext="y" display="inline"><semantics id="S4.SS3.p2.1.m1.1a"><mi id="S4.SS3.p2.1.m1.1.1" xref="S4.SS3.p2.1.m1.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.1.m1.1b"><ci id="S4.SS3.p2.1.m1.1.1.cmml" xref="S4.SS3.p2.1.m1.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.1.m1.1c">y</annotation></semantics></math> a client <math id="S4.SS3.p2.2.m2.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S4.SS3.p2.2.m2.1a"><mi id="S4.SS3.p2.2.m2.1.1" xref="S4.SS3.p2.2.m2.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.2.m2.1b"><ci id="S4.SS3.p2.2.m2.1.1.cmml" xref="S4.SS3.p2.2.m2.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.2.m2.1c">x</annotation></semantics></math> container withholds. We built a dataset of records identified by <math id="S4.SS3.p2.3.m3.1" class="ltx_Math" alttext="10" display="inline"><semantics id="S4.SS3.p2.3.m3.1a"><mn id="S4.SS3.p2.3.m3.1.1" xref="S4.SS3.p2.3.m3.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.3.m3.1b"><cn type="integer" id="S4.SS3.p2.3.m3.1.1.cmml" xref="S4.SS3.p2.3.m3.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.3.m3.1c">10</annotation></semantics></math> labels distributed to <math id="S4.SS3.p2.4.m4.1" class="ltx_Math" alttext="20" display="inline"><semantics id="S4.SS3.p2.4.m4.1a"><mn id="S4.SS3.p2.4.m4.1.1" xref="S4.SS3.p2.4.m4.1.1.cmml">20</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.4.m4.1b"><cn type="integer" id="S4.SS3.p2.4.m4.1.1.cmml" xref="S4.SS3.p2.4.m4.1.1">20</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.4.m4.1c">20</annotation></semantics></math> clients for these representations.</p>
</div>
<div id="S4.SS3.p3" class="ltx_para">
<p id="S4.SS3.p3.3" class="ltx_p"><span id="S4.SS3.p3.3.1" class="ltx_text ltx_font_bold">ShardDistributor:</span>
Introduced by google <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>, such distribution allows experimenting under strict Non-IId environments. The data is split into shards <math id="S4.SS3.p3.1.m1.1" class="ltx_Math" alttext="S" display="inline"><semantics id="S4.SS3.p3.1.m1.1a"><mi id="S4.SS3.p3.1.m1.1.1" xref="S4.SS3.p3.1.m1.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.1.m1.1b"><ci id="S4.SS3.p3.1.m1.1.1.cmml" xref="S4.SS3.p3.1.m1.1.1">𝑆</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.1.m1.1c">S</annotation></semantics></math> of equal size. Each shard contains a fixed number of raw records with the same label. Afterward, the shards are distributed to clients, each receiving a predetermined number of shards selected randomly. In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite> use cases, each client receives two shards of 300 records each, indicating that each client has at most two labels in its local datasets, creating a highly Non-IID scenario. It is possible to efficiently control the IIDness severity in this case as it depends on a single value: how many shards <math id="S4.SS3.p3.2.m2.1" class="ltx_Math" alttext="S" display="inline"><semantics id="S4.SS3.p3.2.m2.1a"><mi id="S4.SS3.p3.2.m2.1.1" xref="S4.SS3.p3.2.m2.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.2.m2.1b"><ci id="S4.SS3.p3.2.m2.1.1.cmml" xref="S4.SS3.p3.2.m2.1.1">𝑆</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.2.m2.1c">S</annotation></semantics></math> each client receives. The shard distribution is represented in Figure <a href="#S4.F8.sf3" title="In Figure 8 ‣ 4.3 Data-Center ‣ 4 Federated Learning Framework ‣ ModularFed: Leveraging Modularity in Federated Learning Frameworks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8(c)</span></a>. Each shard <math id="S4.SS3.p3.3.m3.1" class="ltx_Math" alttext="S" display="inline"><semantics id="S4.SS3.p3.3.m3.1a"><mi id="S4.SS3.p3.3.m3.1.1" xref="S4.SS3.p3.3.m3.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.3.m3.1b"><ci id="S4.SS3.p3.3.m3.1.1.cmml" xref="S4.SS3.p3.3.m3.1.1">𝑆</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.3.m3.1c">S</annotation></semantics></math> is fixed with 300 records, and 2 of these shards are distributed to 20 clients.</p>
</div>
<figure id="S4.F8" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F8.sf1" class="ltx_figure ltx_figure_panel"><img src="/html/2212.10427/assets/dir05.png" id="S4.F8.sf1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="586" height="294" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F8.sf1.4.2.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S4.F8.sf1.2.1" class="ltx_text" style="font-size:90%;">Dirichlet Distribution with <math id="S4.F8.sf1.2.1.m1.1" class="ltx_Math" alttext="\alpha=0.5" display="inline"><semantics id="S4.F8.sf1.2.1.m1.1b"><mrow id="S4.F8.sf1.2.1.m1.1.1" xref="S4.F8.sf1.2.1.m1.1.1.cmml"><mi id="S4.F8.sf1.2.1.m1.1.1.2" xref="S4.F8.sf1.2.1.m1.1.1.2.cmml">α</mi><mo id="S4.F8.sf1.2.1.m1.1.1.1" xref="S4.F8.sf1.2.1.m1.1.1.1.cmml">=</mo><mn id="S4.F8.sf1.2.1.m1.1.1.3" xref="S4.F8.sf1.2.1.m1.1.1.3.cmml">0.5</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.F8.sf1.2.1.m1.1c"><apply id="S4.F8.sf1.2.1.m1.1.1.cmml" xref="S4.F8.sf1.2.1.m1.1.1"><eq id="S4.F8.sf1.2.1.m1.1.1.1.cmml" xref="S4.F8.sf1.2.1.m1.1.1.1"></eq><ci id="S4.F8.sf1.2.1.m1.1.1.2.cmml" xref="S4.F8.sf1.2.1.m1.1.1.2">𝛼</ci><cn type="float" id="S4.F8.sf1.2.1.m1.1.1.3.cmml" xref="S4.F8.sf1.2.1.m1.1.1.3">0.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F8.sf1.2.1.m1.1d">\alpha=0.5</annotation></semantics></math></span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F8.sf2" class="ltx_figure ltx_figure_panel"><img src="/html/2212.10427/assets/dir10.png" id="S4.F8.sf2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="586" height="295" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F8.sf2.4.2.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S4.F8.sf2.2.1" class="ltx_text" style="font-size:90%;">Dirichlet Distribution with <math id="S4.F8.sf2.2.1.m1.1" class="ltx_Math" alttext="\alpha=10" display="inline"><semantics id="S4.F8.sf2.2.1.m1.1b"><mrow id="S4.F8.sf2.2.1.m1.1.1" xref="S4.F8.sf2.2.1.m1.1.1.cmml"><mi id="S4.F8.sf2.2.1.m1.1.1.2" xref="S4.F8.sf2.2.1.m1.1.1.2.cmml">α</mi><mo id="S4.F8.sf2.2.1.m1.1.1.1" xref="S4.F8.sf2.2.1.m1.1.1.1.cmml">=</mo><mn id="S4.F8.sf2.2.1.m1.1.1.3" xref="S4.F8.sf2.2.1.m1.1.1.3.cmml">10</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.F8.sf2.2.1.m1.1c"><apply id="S4.F8.sf2.2.1.m1.1.1.cmml" xref="S4.F8.sf2.2.1.m1.1.1"><eq id="S4.F8.sf2.2.1.m1.1.1.1.cmml" xref="S4.F8.sf2.2.1.m1.1.1.1"></eq><ci id="S4.F8.sf2.2.1.m1.1.1.2.cmml" xref="S4.F8.sf2.2.1.m1.1.1.2">𝛼</ci><cn type="integer" id="S4.F8.sf2.2.1.m1.1.1.3.cmml" xref="S4.F8.sf2.2.1.m1.1.1.3">10</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F8.sf2.2.1.m1.1d">\alpha=10</annotation></semantics></math></span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F8.sf3" class="ltx_figure ltx_figure_panel"><img src="/html/2212.10427/assets/shard.png" id="S4.F8.sf3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="586" height="296" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F8.sf3.4.2.1" class="ltx_text" style="font-size:90%;">(c)</span> </span><span id="S4.F8.sf3.2.1" class="ltx_text" style="font-size:90%;">Shard Distribution with <math id="S4.F8.sf3.2.1.m1.1" class="ltx_Math" alttext="S=2" display="inline"><semantics id="S4.F8.sf3.2.1.m1.1b"><mrow id="S4.F8.sf3.2.1.m1.1.1" xref="S4.F8.sf3.2.1.m1.1.1.cmml"><mi id="S4.F8.sf3.2.1.m1.1.1.2" xref="S4.F8.sf3.2.1.m1.1.1.2.cmml">S</mi><mo id="S4.F8.sf3.2.1.m1.1.1.1" xref="S4.F8.sf3.2.1.m1.1.1.1.cmml">=</mo><mn id="S4.F8.sf3.2.1.m1.1.1.3" xref="S4.F8.sf3.2.1.m1.1.1.3.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.F8.sf3.2.1.m1.1c"><apply id="S4.F8.sf3.2.1.m1.1.1.cmml" xref="S4.F8.sf3.2.1.m1.1.1"><eq id="S4.F8.sf3.2.1.m1.1.1.1.cmml" xref="S4.F8.sf3.2.1.m1.1.1.1"></eq><ci id="S4.F8.sf3.2.1.m1.1.1.2.cmml" xref="S4.F8.sf3.2.1.m1.1.1.2">𝑆</ci><cn type="integer" id="S4.F8.sf3.2.1.m1.1.1.3.cmml" xref="S4.F8.sf3.2.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F8.sf3.2.1.m1.1d">S=2</annotation></semantics></math></span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F8.sf4" class="ltx_figure ltx_figure_panel"><img src="/html/2212.10427/assets/label1.png" id="S4.F8.sf4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="586" height="296" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F8.sf4.4.2.1" class="ltx_text" style="font-size:90%;">(d)</span> </span><span id="S4.F8.sf4.2.1" class="ltx_text" style="font-size:90%;">Label Distribution with <math id="S4.F8.sf4.2.1.m1.1" class="ltx_Math" alttext="L=1" display="inline"><semantics id="S4.F8.sf4.2.1.m1.1b"><mrow id="S4.F8.sf4.2.1.m1.1.1" xref="S4.F8.sf4.2.1.m1.1.1.cmml"><mi id="S4.F8.sf4.2.1.m1.1.1.2" xref="S4.F8.sf4.2.1.m1.1.1.2.cmml">L</mi><mo id="S4.F8.sf4.2.1.m1.1.1.1" xref="S4.F8.sf4.2.1.m1.1.1.1.cmml">=</mo><mn id="S4.F8.sf4.2.1.m1.1.1.3" xref="S4.F8.sf4.2.1.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.F8.sf4.2.1.m1.1c"><apply id="S4.F8.sf4.2.1.m1.1.1.cmml" xref="S4.F8.sf4.2.1.m1.1.1"><eq id="S4.F8.sf4.2.1.m1.1.1.1.cmml" xref="S4.F8.sf4.2.1.m1.1.1.1"></eq><ci id="S4.F8.sf4.2.1.m1.1.1.2.cmml" xref="S4.F8.sf4.2.1.m1.1.1.2">𝐿</ci><cn type="integer" id="S4.F8.sf4.2.1.m1.1.1.3.cmml" xref="S4.F8.sf4.2.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F8.sf4.2.1.m1.1d">L=1</annotation></semantics></math></span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F8.sf5" class="ltx_figure ltx_figure_panel"><img src="/html/2212.10427/assets/label10.png" id="S4.F8.sf5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="586" height="298" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F8.sf5.4.2.1" class="ltx_text" style="font-size:90%;">(e)</span> </span><span id="S4.F8.sf5.2.1" class="ltx_text" style="font-size:90%;">Label Distribution with <math id="S4.F8.sf5.2.1.m1.1" class="ltx_Math" alttext="L=10" display="inline"><semantics id="S4.F8.sf5.2.1.m1.1b"><mrow id="S4.F8.sf5.2.1.m1.1.1" xref="S4.F8.sf5.2.1.m1.1.1.cmml"><mi id="S4.F8.sf5.2.1.m1.1.1.2" xref="S4.F8.sf5.2.1.m1.1.1.2.cmml">L</mi><mo id="S4.F8.sf5.2.1.m1.1.1.1" xref="S4.F8.sf5.2.1.m1.1.1.1.cmml">=</mo><mn id="S4.F8.sf5.2.1.m1.1.1.3" xref="S4.F8.sf5.2.1.m1.1.1.3.cmml">10</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.F8.sf5.2.1.m1.1c"><apply id="S4.F8.sf5.2.1.m1.1.1.cmml" xref="S4.F8.sf5.2.1.m1.1.1"><eq id="S4.F8.sf5.2.1.m1.1.1.1.cmml" xref="S4.F8.sf5.2.1.m1.1.1.1"></eq><ci id="S4.F8.sf5.2.1.m1.1.1.2.cmml" xref="S4.F8.sf5.2.1.m1.1.1.2">𝐿</ci><cn type="integer" id="S4.F8.sf5.2.1.m1.1.1.3.cmml" xref="S4.F8.sf5.2.1.m1.1.1.3">10</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F8.sf5.2.1.m1.1d">L=10</annotation></semantics></math></span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F8.sf6" class="ltx_figure ltx_figure_panel"><img src="/html/2212.10427/assets/unq.png" id="S4.F8.sf6.g1" class="ltx_graphics ltx_centering ltx_img_square" width="287" height="287" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F8.sf6.2.1.1" class="ltx_text" style="font-size:90%;">(f)</span> </span><span id="S4.F8.sf6.3.2" class="ltx_text" style="font-size:90%;">Unique Distribution</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F8.2.1.1" class="ltx_text" style="font-size:90%;">Figure 8</span>: </span><span id="S4.F8.3.2" class="ltx_text" style="font-size:90%;">MNIST FL Experiments on Label, Dirichlet, Shard, and Unique Distributions</span></figcaption>
</figure>
<div id="S4.SS3.p4" class="ltx_para">
<p id="S4.SS3.p4.1" class="ltx_p"><span id="S4.SS3.p4.1.1" class="ltx_text ltx_font_bold">LabelDistributor:</span>
Similar to the shard distribution but with more control over the number of labels <math id="S4.SS3.p4.1.m1.1" class="ltx_Math" alttext="L" display="inline"><semantics id="S4.SS3.p4.1.m1.1a"><mi id="S4.SS3.p4.1.m1.1.1" xref="S4.SS3.p4.1.m1.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p4.1.m1.1b"><ci id="S4.SS3.p4.1.m1.1.1.cmml" xref="S4.SS3.p4.1.m1.1.1">𝐿</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p4.1.m1.1c">L</annotation></semantics></math> distributed to each client. Unlike Shard Distribution, each client is guaranteed to have the specified number of labels in their datasets. Additionally, it’s possible to simulate client distribution with different label sizes, which is irrelevant when using Shard Distribution. In Figure <a href="#S4.F8.sf5" title="In Figure 8 ‣ 4.3 Data-Center ‣ 4 Federated Learning Framework ‣ ModularFed: Leveraging Modularity in Federated Learning Frameworks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8(e)</span></a> and <a href="#S4.F8.sf4" title="In Figure 8 ‣ 4.3 Data-Center ‣ 4 Federated Learning Framework ‣ ModularFed: Leveraging Modularity in Federated Learning Frameworks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8(d)</span></a>, we show the results of a label distribution to 20 clients each receiving 600 records. While Figure <a href="#S4.F8.sf5" title="In Figure 8 ‣ 4.3 Data-Center ‣ 4 Federated Learning Framework ‣ ModularFed: Leveraging Modularity in Federated Learning Frameworks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8(e)</span></a> represents an IID distribution where all the clients where all clients receive an equal amount of data for each label, in Figure <a href="#S4.F8.sf4" title="In Figure 8 ‣ 4.3 Data-Center ‣ 4 Federated Learning Framework ‣ ModularFed: Leveraging Modularity in Federated Learning Frameworks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8(d)</span></a>, we show a highly Non-IID distribution where each client hold records from only one label.</p>
</div>
<div id="S4.SS3.p5" class="ltx_para">
<p id="S4.SS3.p5.1" class="ltx_p"><span id="S4.SS3.p5.1.1" class="ltx_text ltx_font_bold">UniqueDistributor:</span> Using a unique distributor, it is possible to create a particular type of severe Non-IID case in which each client have a dataset with records from a single, unique label/class. Unlike the rest of the distributors, where the same record label/class might exist on multiple client datasets, the Unique distributor guarantees that the single label in one client dataset does not exist in another. The Unique distribution is considered a serious difficulty of Non-IIDness and occurs in studies focusing on clients’ penalization, such as behavioural analysis <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>. Such a distribution is presented in Figure <a href="#S4.F8.sf6" title="In Figure 8 ‣ 4.3 Data-Center ‣ 4 Federated Learning Framework ‣ ModularFed: Leveraging Modularity in Federated Learning Frameworks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8(f)</span></a>. Different from the highly Non-IID case presented in <a href="#S4.F8.sf4" title="In Figure 8 ‣ 4.3 Data-Center ‣ 4 Federated Learning Framework ‣ ModularFed: Leveraging Modularity in Federated Learning Frameworks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8(d)</span></a> where each client holds records from only one label, in the Unique case, two clients holding the same label does not exists. As a result, it is only possible to show the data distribution to 10 clients since our dataset has only ten labels.</p>
</div>
<div id="S4.SS3.p6" class="ltx_para">
<p id="S4.SS3.p6.3" class="ltx_p"><span id="S4.SS3.p6.3.1" class="ltx_text ltx_font_bold">DirichletDistributor:</span> applied by <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib38" title="" class="ltx_ref">38</a>]</cite>, used to generate a vector of samples where each signifies the percentage of the representative label index of the total data size, which can be assigned randomly during the distribution. In this case, it is possible to create a form of data unbalancement in terms of local labels across different clients. For instance, we can use Dirichlet to create a client that possesses 10% of its total records labelled 0, and the rest labelled 1, while another client possesses 85% of records labelled 0 and the rest labelled 1. Numbers vectors: [0.1,0.9] and [0.85,0.15] are two samples drawn from the Dirichlet Distribution with predefined alpha (<math id="S4.SS3.p6.1.m1.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S4.SS3.p6.1.m1.1a"><mi id="S4.SS3.p6.1.m1.1.1" xref="S4.SS3.p6.1.m1.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p6.1.m1.1b"><ci id="S4.SS3.p6.1.m1.1.1.cmml" xref="S4.SS3.p6.1.m1.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p6.1.m1.1c">\alpha</annotation></semantics></math>) values that denote the data skewness. Such distribution can represent real-life scenarios where data differ not only in terms of general datasets size between clients but also in terms of each label size. In Figure <a href="#S4.F8.sf2" title="In Figure 8 ‣ 4.3 Data-Center ‣ 4 Federated Learning Framework ‣ ModularFed: Leveraging Modularity in Federated Learning Frameworks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8(b)</span></a> we show an IID Dirichlet Distribution with <math id="S4.SS3.p6.2.m2.1" class="ltx_Math" alttext="\alpha=10" display="inline"><semantics id="S4.SS3.p6.2.m2.1a"><mrow id="S4.SS3.p6.2.m2.1.1" xref="S4.SS3.p6.2.m2.1.1.cmml"><mi id="S4.SS3.p6.2.m2.1.1.2" xref="S4.SS3.p6.2.m2.1.1.2.cmml">α</mi><mo id="S4.SS3.p6.2.m2.1.1.1" xref="S4.SS3.p6.2.m2.1.1.1.cmml">=</mo><mn id="S4.SS3.p6.2.m2.1.1.3" xref="S4.SS3.p6.2.m2.1.1.3.cmml">10</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p6.2.m2.1b"><apply id="S4.SS3.p6.2.m2.1.1.cmml" xref="S4.SS3.p6.2.m2.1.1"><eq id="S4.SS3.p6.2.m2.1.1.1.cmml" xref="S4.SS3.p6.2.m2.1.1.1"></eq><ci id="S4.SS3.p6.2.m2.1.1.2.cmml" xref="S4.SS3.p6.2.m2.1.1.2">𝛼</ci><cn type="integer" id="S4.SS3.p6.2.m2.1.1.3.cmml" xref="S4.SS3.p6.2.m2.1.1.3">10</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p6.2.m2.1c">\alpha=10</annotation></semantics></math> where each client holds almost every label in equal size with little deviation. In Figure <a href="#S4.F8.sf1" title="In Figure 8 ‣ 4.3 Data-Center ‣ 4 Federated Learning Framework ‣ ModularFed: Leveraging Modularity in Federated Learning Frameworks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8(a)</span></a> we show a Non-IID case where <math id="S4.SS3.p6.3.m3.1" class="ltx_Math" alttext="\alpha=0.5" display="inline"><semantics id="S4.SS3.p6.3.m3.1a"><mrow id="S4.SS3.p6.3.m3.1.1" xref="S4.SS3.p6.3.m3.1.1.cmml"><mi id="S4.SS3.p6.3.m3.1.1.2" xref="S4.SS3.p6.3.m3.1.1.2.cmml">α</mi><mo id="S4.SS3.p6.3.m3.1.1.1" xref="S4.SS3.p6.3.m3.1.1.1.cmml">=</mo><mn id="S4.SS3.p6.3.m3.1.1.3" xref="S4.SS3.p6.3.m3.1.1.3.cmml">0.5</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p6.3.m3.1b"><apply id="S4.SS3.p6.3.m3.1.1.cmml" xref="S4.SS3.p6.3.m3.1.1"><eq id="S4.SS3.p6.3.m3.1.1.1.cmml" xref="S4.SS3.p6.3.m3.1.1.1"></eq><ci id="S4.SS3.p6.3.m3.1.1.2.cmml" xref="S4.SS3.p6.3.m3.1.1.2">𝛼</ci><cn type="float" id="S4.SS3.p6.3.m3.1.1.3.cmml" xref="S4.SS3.p6.3.m3.1.1.3">0.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p6.3.m3.1c">\alpha=0.5</annotation></semantics></math>. In this case, a significant number of clients with missing labels combined with a huge divergence in label size across multiple clients.</p>
</div>
<div id="S4.SS3.p7" class="ltx_para">
<p id="S4.SS3.p7.1" class="ltx_p">The combination of the aforementioned mechanics delivers a smooth and straightforward interaction between the datasets and the framework, qualifying the researchers’ complete and direct control over the data. For example, unlike other frameworks, the datasets are independent of the core, allowing researchers to take advantage of these benefits when supplementing their datasets. Moreover, the framework supports personalized distributors and providers as long as they integrate the corresponding protocols.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Datasets, Benchmarks &amp; Experiments</h2>

<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Datasets</h3>

<div id="S5.SS1.p1" class="ltx_para">
<p id="S5.SS1.p1.1" class="ltx_p">To test our framework and confirm its validity, we ran multiple tests, including working with various datasets, models, and configurations. We examine the framework performance on various datasets, including MNIST, FEMNIST, and CIFAR10, covering use cases that could exist in any classification problem. MNIST is a digit dataset which consists of written digit images of numbers from 0 to 9 in two channels. The dataset contains 70k records of 24*24 pixels. On the other hand, FEMNIST is another similar dataset to MNIST but with increased difficulty and more labels, including 28*28 pixel images of letters and digits, forming a dataset with 62 labels distributed between 671k records. The main difference between MNIST and FEMNIST is in the active pixel coverage in both dataset images. Figure <a href="#S5.F9" title="Figure 9 ‣ 5.1 Datasets ‣ 5 Datasets, Benchmarks &amp; Experiments ‣ ModularFed: Leveraging Modularity in Federated Learning Frameworks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a> shows a comparison between the same digit image. Having fewer active pixels in FEMNIST makes that dataset more challenging and requires a more capable model, which requires additional time and resources. CIFAR10 is a categorical classification dataset containing images of animals and objects in three channels. The main objective is to create a model capable of differentiating between them. The dataset contains 60k 32*32*32 images distributed into <math id="S5.SS1.p1.1.m1.1" class="ltx_Math" alttext="10" display="inline"><semantics id="S5.SS1.p1.1.m1.1a"><mn id="S5.SS1.p1.1.m1.1.1" xref="S5.SS1.p1.1.m1.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.1.m1.1b"><cn type="integer" id="S5.SS1.p1.1.m1.1.1.cmml" xref="S5.SS1.p1.1.m1.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.1.m1.1c">10</annotation></semantics></math> labels.</p>
</div>
<figure id="S5.F9" class="ltx_figure"><img src="/html/2212.10427/assets/mnvsfmn.png" id="S5.F9.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="467" height="254" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F9.2.1.1" class="ltx_text" style="font-size:90%;">Figure 9</span>: </span><span id="S5.F9.3.2" class="ltx_text" style="font-size:90%;">Comparison between MNIST and FEMNIST images.</span></figcaption>
</figure>
<div id="S5.SS1.p2" class="ltx_para">
<p id="S5.SS1.p2.1" class="ltx_p">Regarding the global model configuration, we used Logistic-Regression for MNIST, a simple and fast model with fewer parameters than others with convoluted configurations. As a result, low-end device trains model faster due to the reduced allocated resources and less bandwidth consumption at the cost of not reaching higher accuracy. It is always the decision of precision vs performance in federated learning where we sacrifice precision for a faster and lightweight model or the contrary. CNN is used for FEMNIST and CIFAR10, each with a different configuration adapting to the differences in the image size.</p>
</div>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Configuration Parameters</h3>

<div id="S5.SS2.p1" class="ltx_para">
<p id="S5.SS2.p1.1" class="ltx_p">Regarding the framework configuration, it consists of the following parameters:</p>
<ul id="S5.I1" class="ltx_itemize">
<li id="S5.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S5.I1.i1.p1" class="ltx_para">
<p id="S5.I1.i1.p1.1" class="ltx_p">Data Distributor: It defines how the data is distributed to the simulated clients. This parameter dramatically impacts the model accuracy, such as if the dataset is distributed in an IID or Non-IID manner. The latter’s impact is determined by its severity which is discussed in the previous sections.</p>
</div>
</li>
<li id="S5.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S5.I1.i2.p1" class="ltx_para">
<p id="S5.I1.i2.p1.1" class="ltx_p">CL-Manager: Affect the framework speed and portray the communication between the FL server with its clients. There are two CL-Manager used in the experiments, SequentialManager, which simulates synchronous trainers running in sequence one after another, and an MPIManager, which simulates parallel trainers running concurrently.</p>
</div>
</li>
<li id="S5.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="S5.I1.i3.p1" class="ltx_para">
<p id="S5.I1.i3.p1.1" class="ltx_p">Epoch: Have a significant impact on the framework accuracy. An important term is introduced by <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>, which calls a single epoch and no-batching federated learning FedSGD in which the trainers train their model running over all the data only once and send the model back to the server. In our experiments, we tested the model on both 1 Epoch (FedSGD) and 50 Epoch to show the impact of the parameters on the model accuracy evolution.</p>
</div>
</li>
<li id="S5.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span> 
<div id="S5.I1.i4.p1" class="ltx_para">
<p id="S5.I1.i4.p1.1" class="ltx_p">Client Selection: Throughout our experiment, we used a simple client selection procedure: selecting a predefined random number of clients for each round. This parameter simulates real-case scenarios where most clients are not simultaneously available.</p>
</div>
</li>
<li id="S5.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">5.</span> 
<div id="S5.I1.i5.p1" class="ltx_para">
<p id="S5.I1.i5.p1.1" class="ltx_p">Learning Rate: A hyper-parameter set for model training to control the rate of the model’s parameters update and how much the model accepts from the new weights through a value ranging between <math id="S5.I1.i5.p1.1.m1.1" class="ltx_Math" alttext="0^{+}and1" display="inline"><semantics id="S5.I1.i5.p1.1.m1.1a"><mrow id="S5.I1.i5.p1.1.m1.1.1" xref="S5.I1.i5.p1.1.m1.1.1.cmml"><msup id="S5.I1.i5.p1.1.m1.1.1.2" xref="S5.I1.i5.p1.1.m1.1.1.2.cmml"><mn id="S5.I1.i5.p1.1.m1.1.1.2.2" xref="S5.I1.i5.p1.1.m1.1.1.2.2.cmml">0</mn><mo id="S5.I1.i5.p1.1.m1.1.1.2.3" xref="S5.I1.i5.p1.1.m1.1.1.2.3.cmml">+</mo></msup><mo lspace="0em" rspace="0em" id="S5.I1.i5.p1.1.m1.1.1.1" xref="S5.I1.i5.p1.1.m1.1.1.1.cmml">​</mo><mi id="S5.I1.i5.p1.1.m1.1.1.3" xref="S5.I1.i5.p1.1.m1.1.1.3.cmml">a</mi><mo lspace="0em" rspace="0em" id="S5.I1.i5.p1.1.m1.1.1.1a" xref="S5.I1.i5.p1.1.m1.1.1.1.cmml">​</mo><mi id="S5.I1.i5.p1.1.m1.1.1.4" xref="S5.I1.i5.p1.1.m1.1.1.4.cmml">n</mi><mo lspace="0em" rspace="0em" id="S5.I1.i5.p1.1.m1.1.1.1b" xref="S5.I1.i5.p1.1.m1.1.1.1.cmml">​</mo><mi id="S5.I1.i5.p1.1.m1.1.1.5" xref="S5.I1.i5.p1.1.m1.1.1.5.cmml">d</mi><mo lspace="0em" rspace="0em" id="S5.I1.i5.p1.1.m1.1.1.1c" xref="S5.I1.i5.p1.1.m1.1.1.1.cmml">​</mo><mn id="S5.I1.i5.p1.1.m1.1.1.6" xref="S5.I1.i5.p1.1.m1.1.1.6.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.I1.i5.p1.1.m1.1b"><apply id="S5.I1.i5.p1.1.m1.1.1.cmml" xref="S5.I1.i5.p1.1.m1.1.1"><times id="S5.I1.i5.p1.1.m1.1.1.1.cmml" xref="S5.I1.i5.p1.1.m1.1.1.1"></times><apply id="S5.I1.i5.p1.1.m1.1.1.2.cmml" xref="S5.I1.i5.p1.1.m1.1.1.2"><csymbol cd="ambiguous" id="S5.I1.i5.p1.1.m1.1.1.2.1.cmml" xref="S5.I1.i5.p1.1.m1.1.1.2">superscript</csymbol><cn type="integer" id="S5.I1.i5.p1.1.m1.1.1.2.2.cmml" xref="S5.I1.i5.p1.1.m1.1.1.2.2">0</cn><plus id="S5.I1.i5.p1.1.m1.1.1.2.3.cmml" xref="S5.I1.i5.p1.1.m1.1.1.2.3"></plus></apply><ci id="S5.I1.i5.p1.1.m1.1.1.3.cmml" xref="S5.I1.i5.p1.1.m1.1.1.3">𝑎</ci><ci id="S5.I1.i5.p1.1.m1.1.1.4.cmml" xref="S5.I1.i5.p1.1.m1.1.1.4">𝑛</ci><ci id="S5.I1.i5.p1.1.m1.1.1.5.cmml" xref="S5.I1.i5.p1.1.m1.1.1.5">𝑑</ci><cn type="integer" id="S5.I1.i5.p1.1.m1.1.1.6.cmml" xref="S5.I1.i5.p1.1.m1.1.1.6">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.I1.i5.p1.1.m1.1c">0^{+}and1</annotation></semantics></math>. Choosing the optimal learning rate can be achieved through small tests (a few rounds) to test the model evolution under various learning rate values. We did these tests beforehand for our experiments and picked the optimal results.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S5.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3 </span>Benchmarks &amp; Experimental Results</h3>

<figure id="S5.F10" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S5.F10.sf1" class="ltx_figure ltx_figure_panel"><img src="/html/2212.10427/assets/mnist_lbl.png" id="S5.F10.sf1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="586" height="337" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F10.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S5.F10.sf1.3.2" class="ltx_text" style="font-size:90%;">Label Distribution on MNIST Dataset</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S5.F10.sf2" class="ltx_figure ltx_figure_panel"><img src="/html/2212.10427/assets/mnist_dir.png" id="S5.F10.sf2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="586" height="332" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F10.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S5.F10.sf2.3.2" class="ltx_text" style="font-size:90%;">Dirichlet Distribution on MNIST Dataset</span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S5.F10.sf3" class="ltx_figure ltx_figure_panel"><img src="/html/2212.10427/assets/mnist_shards.png" id="S5.F10.sf3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="586" height="332" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F10.sf3.2.1.1" class="ltx_text" style="font-size:90%;">(c)</span> </span><span id="S5.F10.sf3.3.2" class="ltx_text" style="font-size:90%;">Shard Distribution on MNIST Dataset</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S5.F10.sf4" class="ltx_figure ltx_figure_panel"><img src="/html/2212.10427/assets/mnist_unique.png" id="S5.F10.sf4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="586" height="332" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F10.sf4.2.1.1" class="ltx_text" style="font-size:90%;">(d)</span> </span><span id="S5.F10.sf4.3.2" class="ltx_text" style="font-size:90%;">Unique Distribution on MNIST Dataset</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S5.F10.2.1.1" class="ltx_text" style="font-size:90%;">Figure 10</span>: </span><span id="S5.F10.3.2" class="ltx_text" style="font-size:90%;">MNIST FL Experiments on Label, Dirichlet, Shard, and Unique Distributions</span></figcaption>
</figure>
<div id="S5.SS3.p1" class="ltx_para">
<p id="S5.SS3.p1.1" class="ltx_p">Our primary objective is to provide a platform capable of incorporating the huge configurations varieties in the FL environment. Additionally, we aim to effortlessly replicate the main issues in the FL context allowing researchers to solve them in a straightforward and organized manner. In the following experiments, we test and validate our FL framework under various data distributions, which are the roots of the statistical issues in FL, and client-server approaches.</p>
</div>
<div id="S5.SS3.p2" class="ltx_para">
<p id="S5.SS3.p2.11" class="ltx_p">Figures in <a href="#S5.F10" title="Figure 10 ‣ 5.3 Benchmarks &amp; Experimental Results ‣ 5 Datasets, Benchmarks &amp; Experiments ‣ ModularFed: Leveraging Modularity in Federated Learning Frameworks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10</span></a> and <a href="#S5.F11" title="Figure 11 ‣ 5.3 Benchmarks &amp; Experimental Results ‣ 5 Datasets, Benchmarks &amp; Experiments ‣ ModularFed: Leveraging Modularity in Federated Learning Frameworks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">11</span></a> present the evolution of the global model accuracy when experimenting with the impact of both data distribution and epochs. Every test includes FedSGD (single epoch/round) and FedAVG (multiple epochs/round) to show the epoch’s influence. Regarding the distribution, we experiment on MNIST using every mentioned distribution to demonstrate and highlight its influence on accuracy. Respecting the limited article length, for the subsequent datasets, we show only Dirichlet due to its capabilities of simulating real-life scenarios and Shard Distribution which is mainly used in FL works. Furthermore, each experiment includes both IID and Non-IID distributions. For Label Distribution, <math id="S5.SS3.p2.1.m1.1" class="ltx_Math" alttext="L=10" display="inline"><semantics id="S5.SS3.p2.1.m1.1a"><mrow id="S5.SS3.p2.1.m1.1.1" xref="S5.SS3.p2.1.m1.1.1.cmml"><mi id="S5.SS3.p2.1.m1.1.1.2" xref="S5.SS3.p2.1.m1.1.1.2.cmml">L</mi><mo id="S5.SS3.p2.1.m1.1.1.1" xref="S5.SS3.p2.1.m1.1.1.1.cmml">=</mo><mn id="S5.SS3.p2.1.m1.1.1.3" xref="S5.SS3.p2.1.m1.1.1.3.cmml">10</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.p2.1.m1.1b"><apply id="S5.SS3.p2.1.m1.1.1.cmml" xref="S5.SS3.p2.1.m1.1.1"><eq id="S5.SS3.p2.1.m1.1.1.1.cmml" xref="S5.SS3.p2.1.m1.1.1.1"></eq><ci id="S5.SS3.p2.1.m1.1.1.2.cmml" xref="S5.SS3.p2.1.m1.1.1.2">𝐿</ci><cn type="integer" id="S5.SS3.p2.1.m1.1.1.3.cmml" xref="S5.SS3.p2.1.m1.1.1.3">10</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p2.1.m1.1c">L=10</annotation></semantics></math> is considered IID, where each client receives data of equal size from every Label, while the <math id="S5.SS3.p2.2.m2.1" class="ltx_Math" alttext="L=1" display="inline"><semantics id="S5.SS3.p2.2.m2.1a"><mrow id="S5.SS3.p2.2.m2.1.1" xref="S5.SS3.p2.2.m2.1.1.cmml"><mi id="S5.SS3.p2.2.m2.1.1.2" xref="S5.SS3.p2.2.m2.1.1.2.cmml">L</mi><mo id="S5.SS3.p2.2.m2.1.1.1" xref="S5.SS3.p2.2.m2.1.1.1.cmml">=</mo><mn id="S5.SS3.p2.2.m2.1.1.3" xref="S5.SS3.p2.2.m2.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.p2.2.m2.1b"><apply id="S5.SS3.p2.2.m2.1.1.cmml" xref="S5.SS3.p2.2.m2.1.1"><eq id="S5.SS3.p2.2.m2.1.1.1.cmml" xref="S5.SS3.p2.2.m2.1.1.1"></eq><ci id="S5.SS3.p2.2.m2.1.1.2.cmml" xref="S5.SS3.p2.2.m2.1.1.2">𝐿</ci><cn type="integer" id="S5.SS3.p2.2.m2.1.1.3.cmml" xref="S5.SS3.p2.2.m2.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p2.2.m2.1c">L=1</annotation></semantics></math> is considered the Non-IID case, where each client receives only one Label. For Dirichlet Distribution, we act on the <math id="S5.SS3.p2.3.m3.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S5.SS3.p2.3.m3.1a"><mi id="S5.SS3.p2.3.m3.1.1" xref="S5.SS3.p2.3.m3.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S5.SS3.p2.3.m3.1b"><ci id="S5.SS3.p2.3.m3.1.1.cmml" xref="S5.SS3.p2.3.m3.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p2.3.m3.1c">\alpha</annotation></semantics></math> value, which controls the data skewness of the randomly generated float values. A higher <math id="S5.SS3.p2.4.m4.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S5.SS3.p2.4.m4.1a"><mi id="S5.SS3.p2.4.m4.1.1" xref="S5.SS3.p2.4.m4.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S5.SS3.p2.4.m4.1b"><ci id="S5.SS3.p2.4.m4.1.1.cmml" xref="S5.SS3.p2.4.m4.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p2.4.m4.1c">\alpha</annotation></semantics></math> value results in a notable data disparity between clients, which reduces the data Non-IIDness. Thus, we chose <math id="S5.SS3.p2.5.m5.1" class="ltx_Math" alttext="\alpha=10" display="inline"><semantics id="S5.SS3.p2.5.m5.1a"><mrow id="S5.SS3.p2.5.m5.1.1" xref="S5.SS3.p2.5.m5.1.1.cmml"><mi id="S5.SS3.p2.5.m5.1.1.2" xref="S5.SS3.p2.5.m5.1.1.2.cmml">α</mi><mo id="S5.SS3.p2.5.m5.1.1.1" xref="S5.SS3.p2.5.m5.1.1.1.cmml">=</mo><mn id="S5.SS3.p2.5.m5.1.1.3" xref="S5.SS3.p2.5.m5.1.1.3.cmml">10</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.p2.5.m5.1b"><apply id="S5.SS3.p2.5.m5.1.1.cmml" xref="S5.SS3.p2.5.m5.1.1"><eq id="S5.SS3.p2.5.m5.1.1.1.cmml" xref="S5.SS3.p2.5.m5.1.1.1"></eq><ci id="S5.SS3.p2.5.m5.1.1.2.cmml" xref="S5.SS3.p2.5.m5.1.1.2">𝛼</ci><cn type="integer" id="S5.SS3.p2.5.m5.1.1.3.cmml" xref="S5.SS3.p2.5.m5.1.1.3">10</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p2.5.m5.1c">\alpha=10</annotation></semantics></math> as an IID representative and <math id="S5.SS3.p2.6.m6.1" class="ltx_Math" alttext="\alpha=0.5" display="inline"><semantics id="S5.SS3.p2.6.m6.1a"><mrow id="S5.SS3.p2.6.m6.1.1" xref="S5.SS3.p2.6.m6.1.1.cmml"><mi id="S5.SS3.p2.6.m6.1.1.2" xref="S5.SS3.p2.6.m6.1.1.2.cmml">α</mi><mo id="S5.SS3.p2.6.m6.1.1.1" xref="S5.SS3.p2.6.m6.1.1.1.cmml">=</mo><mn id="S5.SS3.p2.6.m6.1.1.3" xref="S5.SS3.p2.6.m6.1.1.3.cmml">0.5</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.p2.6.m6.1b"><apply id="S5.SS3.p2.6.m6.1.1.cmml" xref="S5.SS3.p2.6.m6.1.1"><eq id="S5.SS3.p2.6.m6.1.1.1.cmml" xref="S5.SS3.p2.6.m6.1.1.1"></eq><ci id="S5.SS3.p2.6.m6.1.1.2.cmml" xref="S5.SS3.p2.6.m6.1.1.2">𝛼</ci><cn type="float" id="S5.SS3.p2.6.m6.1.1.3.cmml" xref="S5.SS3.p2.6.m6.1.1.3">0.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p2.6.m6.1c">\alpha=0.5</annotation></semantics></math> to portray a Non-IID distribution. Finally, for Shard Distribution experiments, we consider <math id="S5.SS3.p2.7.m7.1" class="ltx_Math" alttext="S=2" display="inline"><semantics id="S5.SS3.p2.7.m7.1a"><mrow id="S5.SS3.p2.7.m7.1.1" xref="S5.SS3.p2.7.m7.1.1.cmml"><mi id="S5.SS3.p2.7.m7.1.1.2" xref="S5.SS3.p2.7.m7.1.1.2.cmml">S</mi><mo id="S5.SS3.p2.7.m7.1.1.1" xref="S5.SS3.p2.7.m7.1.1.1.cmml">=</mo><mn id="S5.SS3.p2.7.m7.1.1.3" xref="S5.SS3.p2.7.m7.1.1.3.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.p2.7.m7.1b"><apply id="S5.SS3.p2.7.m7.1.1.cmml" xref="S5.SS3.p2.7.m7.1.1"><eq id="S5.SS3.p2.7.m7.1.1.1.cmml" xref="S5.SS3.p2.7.m7.1.1.1"></eq><ci id="S5.SS3.p2.7.m7.1.1.2.cmml" xref="S5.SS3.p2.7.m7.1.1.2">𝑆</ci><cn type="integer" id="S5.SS3.p2.7.m7.1.1.3.cmml" xref="S5.SS3.p2.7.m7.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p2.7.m7.1c">S=2</annotation></semantics></math> as Non-IID in which each client has at most two labels of 300 records each and <math id="S5.SS3.p2.8.m8.1" class="ltx_Math" alttext="S=5" display="inline"><semantics id="S5.SS3.p2.8.m8.1a"><mrow id="S5.SS3.p2.8.m8.1.1" xref="S5.SS3.p2.8.m8.1.1.cmml"><mi id="S5.SS3.p2.8.m8.1.1.2" xref="S5.SS3.p2.8.m8.1.1.2.cmml">S</mi><mo id="S5.SS3.p2.8.m8.1.1.1" xref="S5.SS3.p2.8.m8.1.1.1.cmml">=</mo><mn id="S5.SS3.p2.8.m8.1.1.3" xref="S5.SS3.p2.8.m8.1.1.3.cmml">5</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.p2.8.m8.1b"><apply id="S5.SS3.p2.8.m8.1.1.cmml" xref="S5.SS3.p2.8.m8.1.1"><eq id="S5.SS3.p2.8.m8.1.1.1.cmml" xref="S5.SS3.p2.8.m8.1.1.1"></eq><ci id="S5.SS3.p2.8.m8.1.1.2.cmml" xref="S5.SS3.p2.8.m8.1.1.2">𝑆</ci><cn type="integer" id="S5.SS3.p2.8.m8.1.1.3.cmml" xref="S5.SS3.p2.8.m8.1.1.3">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p2.8.m8.1c">S=5</annotation></semantics></math> an IID case where each client has at least five labels of 300 records each. The total number of clients is different depending on the subsequent distribution. For instance, working with Label and Dirichlet Distributions, we can predefine a fixed number of clients, of which we chose 100. Shard distribution depends on the number of records and the shard size. For instance, MNIST, with 60k records divided into 300 records/shards results in 200 shards. Thus, we have 100 clients when <math id="S5.SS3.p2.9.m9.1" class="ltx_Math" alttext="S=2" display="inline"><semantics id="S5.SS3.p2.9.m9.1a"><mrow id="S5.SS3.p2.9.m9.1.1" xref="S5.SS3.p2.9.m9.1.1.cmml"><mi id="S5.SS3.p2.9.m9.1.1.2" xref="S5.SS3.p2.9.m9.1.1.2.cmml">S</mi><mo id="S5.SS3.p2.9.m9.1.1.1" xref="S5.SS3.p2.9.m9.1.1.1.cmml">=</mo><mn id="S5.SS3.p2.9.m9.1.1.3" xref="S5.SS3.p2.9.m9.1.1.3.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.p2.9.m9.1b"><apply id="S5.SS3.p2.9.m9.1.1.cmml" xref="S5.SS3.p2.9.m9.1.1"><eq id="S5.SS3.p2.9.m9.1.1.1.cmml" xref="S5.SS3.p2.9.m9.1.1.1"></eq><ci id="S5.SS3.p2.9.m9.1.1.2.cmml" xref="S5.SS3.p2.9.m9.1.1.2">𝑆</ci><cn type="integer" id="S5.SS3.p2.9.m9.1.1.3.cmml" xref="S5.SS3.p2.9.m9.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p2.9.m9.1c">S=2</annotation></semantics></math> compared to 40 when <math id="S5.SS3.p2.10.m10.1" class="ltx_Math" alttext="S=5" display="inline"><semantics id="S5.SS3.p2.10.m10.1a"><mrow id="S5.SS3.p2.10.m10.1.1" xref="S5.SS3.p2.10.m10.1.1.cmml"><mi id="S5.SS3.p2.10.m10.1.1.2" xref="S5.SS3.p2.10.m10.1.1.2.cmml">S</mi><mo id="S5.SS3.p2.10.m10.1.1.1" xref="S5.SS3.p2.10.m10.1.1.1.cmml">=</mo><mn id="S5.SS3.p2.10.m10.1.1.3" xref="S5.SS3.p2.10.m10.1.1.3.cmml">5</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.p2.10.m10.1b"><apply id="S5.SS3.p2.10.m10.1.1.cmml" xref="S5.SS3.p2.10.m10.1.1"><eq id="S5.SS3.p2.10.m10.1.1.1.cmml" xref="S5.SS3.p2.10.m10.1.1.1"></eq><ci id="S5.SS3.p2.10.m10.1.1.2.cmml" xref="S5.SS3.p2.10.m10.1.1.2">𝑆</ci><cn type="integer" id="S5.SS3.p2.10.m10.1.1.3.cmml" xref="S5.SS3.p2.10.m10.1.1.3">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p2.10.m10.1c">S=5</annotation></semantics></math>. As for Unique Distribution, we are limited by the total number of Labels. For example, in MNIST, since the dataset contains only 10 Labels, we can have at most ten clients. For our experiments, we employed a random client selector in which we selected <math id="S5.SS3.p2.11.m11.1" class="ltx_Math" alttext="CR=10" display="inline"><semantics id="S5.SS3.p2.11.m11.1a"><mrow id="S5.SS3.p2.11.m11.1.1" xref="S5.SS3.p2.11.m11.1.1.cmml"><mrow id="S5.SS3.p2.11.m11.1.1.2" xref="S5.SS3.p2.11.m11.1.1.2.cmml"><mi id="S5.SS3.p2.11.m11.1.1.2.2" xref="S5.SS3.p2.11.m11.1.1.2.2.cmml">C</mi><mo lspace="0em" rspace="0em" id="S5.SS3.p2.11.m11.1.1.2.1" xref="S5.SS3.p2.11.m11.1.1.2.1.cmml">​</mo><mi id="S5.SS3.p2.11.m11.1.1.2.3" xref="S5.SS3.p2.11.m11.1.1.2.3.cmml">R</mi></mrow><mo id="S5.SS3.p2.11.m11.1.1.1" xref="S5.SS3.p2.11.m11.1.1.1.cmml">=</mo><mn id="S5.SS3.p2.11.m11.1.1.3" xref="S5.SS3.p2.11.m11.1.1.3.cmml">10</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.p2.11.m11.1b"><apply id="S5.SS3.p2.11.m11.1.1.cmml" xref="S5.SS3.p2.11.m11.1.1"><eq id="S5.SS3.p2.11.m11.1.1.1.cmml" xref="S5.SS3.p2.11.m11.1.1.1"></eq><apply id="S5.SS3.p2.11.m11.1.1.2.cmml" xref="S5.SS3.p2.11.m11.1.1.2"><times id="S5.SS3.p2.11.m11.1.1.2.1.cmml" xref="S5.SS3.p2.11.m11.1.1.2.1"></times><ci id="S5.SS3.p2.11.m11.1.1.2.2.cmml" xref="S5.SS3.p2.11.m11.1.1.2.2">𝐶</ci><ci id="S5.SS3.p2.11.m11.1.1.2.3.cmml" xref="S5.SS3.p2.11.m11.1.1.2.3">𝑅</ci></apply><cn type="integer" id="S5.SS3.p2.11.m11.1.1.3.cmml" xref="S5.SS3.p2.11.m11.1.1.3">10</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p2.11.m11.1c">CR=10</annotation></semantics></math> clients for each round.</p>
</div>
<figure id="S5.F11" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S5.F11.sf1" class="ltx_figure ltx_figure_panel"><img src="/html/2212.10427/assets/cifar_dir.png" id="S5.F11.sf1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="586" height="332" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F11.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S5.F11.sf1.3.2" class="ltx_text" style="font-size:90%;">Dirichlet Distribution on CIFAR10 Dataset</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S5.F11.sf2" class="ltx_figure ltx_figure_panel"><img src="/html/2212.10427/assets/cifar_shards.png" id="S5.F11.sf2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="586" height="337" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F11.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S5.F11.sf2.3.2" class="ltx_text" style="font-size:90%;">Shards Distribution on CIFAR10 Dataset</span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S5.F11.sf3" class="ltx_figure ltx_figure_panel"><img src="/html/2212.10427/assets/femnist_dir.png" id="S5.F11.sf3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="586" height="337" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F11.sf3.2.1.1" class="ltx_text" style="font-size:90%;">(c)</span> </span><span id="S5.F11.sf3.3.2" class="ltx_text" style="font-size:90%;">Dirichlet Distribution on FEMNIST Dataset</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S5.F11.sf4" class="ltx_figure ltx_figure_panel"><img src="/html/2212.10427/assets/femnist_shards.png" id="S5.F11.sf4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="586" height="337" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F11.sf4.2.1.1" class="ltx_text" style="font-size:90%;">(d)</span> </span><span id="S5.F11.sf4.3.2" class="ltx_text" style="font-size:90%;">Shards Distribution on FEMNIST Dataset</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S5.F11.2.1.1" class="ltx_text" style="font-size:90%;">Figure 11</span>: </span><span id="S5.F11.3.2" class="ltx_text" style="font-size:90%;">CIFAR and FEMNIST FL Experiments on Dirichlet and Shard Distributions</span></figcaption>
</figure>
<div id="S5.SS3.p3" class="ltx_para">
<p id="S5.SS3.p3.4" class="ltx_p">Figure <a href="#S5.F10.sf1" title="In Figure 10 ‣ 5.3 Benchmarks &amp; Experimental Results ‣ 5 Datasets, Benchmarks &amp; Experiments ‣ ModularFed: Leveraging Modularity in Federated Learning Frameworks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10(a)</span></a> shows the results of MNIST Label Distribution when using Logistic-Regression as the base model configuration. When working with the MNIST dataset, the impact of the distribution is negligible. It can be solved with additional rounds because the dataset is structured with simple and properly filtered images. However, there are still some noticeable differences. With <math id="S5.SS3.p3.1.m1.1" class="ltx_Math" alttext="E=50:L=1" display="inline"><semantics id="S5.SS3.p3.1.m1.1a"><mrow id="S5.SS3.p3.1.m1.1.1" xref="S5.SS3.p3.1.m1.1.1.cmml"><mrow id="S5.SS3.p3.1.m1.1.1.2" xref="S5.SS3.p3.1.m1.1.1.2.cmml"><mi id="S5.SS3.p3.1.m1.1.1.2.2" xref="S5.SS3.p3.1.m1.1.1.2.2.cmml">E</mi><mo id="S5.SS3.p3.1.m1.1.1.2.1" xref="S5.SS3.p3.1.m1.1.1.2.1.cmml">=</mo><mn id="S5.SS3.p3.1.m1.1.1.2.3" xref="S5.SS3.p3.1.m1.1.1.2.3.cmml">50</mn></mrow><mo lspace="0.278em" rspace="0.278em" id="S5.SS3.p3.1.m1.1.1.1" xref="S5.SS3.p3.1.m1.1.1.1.cmml">:</mo><mrow id="S5.SS3.p3.1.m1.1.1.3" xref="S5.SS3.p3.1.m1.1.1.3.cmml"><mi id="S5.SS3.p3.1.m1.1.1.3.2" xref="S5.SS3.p3.1.m1.1.1.3.2.cmml">L</mi><mo id="S5.SS3.p3.1.m1.1.1.3.1" xref="S5.SS3.p3.1.m1.1.1.3.1.cmml">=</mo><mn id="S5.SS3.p3.1.m1.1.1.3.3" xref="S5.SS3.p3.1.m1.1.1.3.3.cmml">1</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.p3.1.m1.1b"><apply id="S5.SS3.p3.1.m1.1.1.cmml" xref="S5.SS3.p3.1.m1.1.1"><ci id="S5.SS3.p3.1.m1.1.1.1.cmml" xref="S5.SS3.p3.1.m1.1.1.1">:</ci><apply id="S5.SS3.p3.1.m1.1.1.2.cmml" xref="S5.SS3.p3.1.m1.1.1.2"><eq id="S5.SS3.p3.1.m1.1.1.2.1.cmml" xref="S5.SS3.p3.1.m1.1.1.2.1"></eq><ci id="S5.SS3.p3.1.m1.1.1.2.2.cmml" xref="S5.SS3.p3.1.m1.1.1.2.2">𝐸</ci><cn type="integer" id="S5.SS3.p3.1.m1.1.1.2.3.cmml" xref="S5.SS3.p3.1.m1.1.1.2.3">50</cn></apply><apply id="S5.SS3.p3.1.m1.1.1.3.cmml" xref="S5.SS3.p3.1.m1.1.1.3"><eq id="S5.SS3.p3.1.m1.1.1.3.1.cmml" xref="S5.SS3.p3.1.m1.1.1.3.1"></eq><ci id="S5.SS3.p3.1.m1.1.1.3.2.cmml" xref="S5.SS3.p3.1.m1.1.1.3.2">𝐿</ci><cn type="integer" id="S5.SS3.p3.1.m1.1.1.3.3.cmml" xref="S5.SS3.p3.1.m1.1.1.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p3.1.m1.1c">E=50:L=1</annotation></semantics></math>, we notice huge spikes in the accuracies, which indicate that the model is struggling to find the optimal parameters. The intensity of spikes decreased with the subsequent rounds but did not converge even after 1000 rounds. Such a scenario led to additional computational and resource consumption compared to <math id="S5.SS3.p3.2.m2.1" class="ltx_Math" alttext="E=50:L=10" display="inline"><semantics id="S5.SS3.p3.2.m2.1a"><mrow id="S5.SS3.p3.2.m2.1.1" xref="S5.SS3.p3.2.m2.1.1.cmml"><mrow id="S5.SS3.p3.2.m2.1.1.2" xref="S5.SS3.p3.2.m2.1.1.2.cmml"><mi id="S5.SS3.p3.2.m2.1.1.2.2" xref="S5.SS3.p3.2.m2.1.1.2.2.cmml">E</mi><mo id="S5.SS3.p3.2.m2.1.1.2.1" xref="S5.SS3.p3.2.m2.1.1.2.1.cmml">=</mo><mn id="S5.SS3.p3.2.m2.1.1.2.3" xref="S5.SS3.p3.2.m2.1.1.2.3.cmml">50</mn></mrow><mo lspace="0.278em" rspace="0.278em" id="S5.SS3.p3.2.m2.1.1.1" xref="S5.SS3.p3.2.m2.1.1.1.cmml">:</mo><mrow id="S5.SS3.p3.2.m2.1.1.3" xref="S5.SS3.p3.2.m2.1.1.3.cmml"><mi id="S5.SS3.p3.2.m2.1.1.3.2" xref="S5.SS3.p3.2.m2.1.1.3.2.cmml">L</mi><mo id="S5.SS3.p3.2.m2.1.1.3.1" xref="S5.SS3.p3.2.m2.1.1.3.1.cmml">=</mo><mn id="S5.SS3.p3.2.m2.1.1.3.3" xref="S5.SS3.p3.2.m2.1.1.3.3.cmml">10</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.p3.2.m2.1b"><apply id="S5.SS3.p3.2.m2.1.1.cmml" xref="S5.SS3.p3.2.m2.1.1"><ci id="S5.SS3.p3.2.m2.1.1.1.cmml" xref="S5.SS3.p3.2.m2.1.1.1">:</ci><apply id="S5.SS3.p3.2.m2.1.1.2.cmml" xref="S5.SS3.p3.2.m2.1.1.2"><eq id="S5.SS3.p3.2.m2.1.1.2.1.cmml" xref="S5.SS3.p3.2.m2.1.1.2.1"></eq><ci id="S5.SS3.p3.2.m2.1.1.2.2.cmml" xref="S5.SS3.p3.2.m2.1.1.2.2">𝐸</ci><cn type="integer" id="S5.SS3.p3.2.m2.1.1.2.3.cmml" xref="S5.SS3.p3.2.m2.1.1.2.3">50</cn></apply><apply id="S5.SS3.p3.2.m2.1.1.3.cmml" xref="S5.SS3.p3.2.m2.1.1.3"><eq id="S5.SS3.p3.2.m2.1.1.3.1.cmml" xref="S5.SS3.p3.2.m2.1.1.3.1"></eq><ci id="S5.SS3.p3.2.m2.1.1.3.2.cmml" xref="S5.SS3.p3.2.m2.1.1.3.2">𝐿</ci><cn type="integer" id="S5.SS3.p3.2.m2.1.1.3.3.cmml" xref="S5.SS3.p3.2.m2.1.1.3.3">10</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p3.2.m2.1c">E=50:L=10</annotation></semantics></math>, which converged at 90% after 200 rounds. Nevertheless, the impact of epochs is more noticeable in the next experiment. For <math id="S5.SS3.p3.3.m3.1" class="ltx_Math" alttext="E=1" display="inline"><semantics id="S5.SS3.p3.3.m3.1a"><mrow id="S5.SS3.p3.3.m3.1.1" xref="S5.SS3.p3.3.m3.1.1.cmml"><mi id="S5.SS3.p3.3.m3.1.1.2" xref="S5.SS3.p3.3.m3.1.1.2.cmml">E</mi><mo id="S5.SS3.p3.3.m3.1.1.1" xref="S5.SS3.p3.3.m3.1.1.1.cmml">=</mo><mn id="S5.SS3.p3.3.m3.1.1.3" xref="S5.SS3.p3.3.m3.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.p3.3.m3.1b"><apply id="S5.SS3.p3.3.m3.1.1.cmml" xref="S5.SS3.p3.3.m3.1.1"><eq id="S5.SS3.p3.3.m3.1.1.1.cmml" xref="S5.SS3.p3.3.m3.1.1.1"></eq><ci id="S5.SS3.p3.3.m3.1.1.2.cmml" xref="S5.SS3.p3.3.m3.1.1.2">𝐸</ci><cn type="integer" id="S5.SS3.p3.3.m3.1.1.3.cmml" xref="S5.SS3.p3.3.m3.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p3.3.m3.1c">E=1</annotation></semantics></math>, the accuracy were lower than <math id="S5.SS3.p3.4.m4.1" class="ltx_Math" alttext="E=50" display="inline"><semantics id="S5.SS3.p3.4.m4.1a"><mrow id="S5.SS3.p3.4.m4.1.1" xref="S5.SS3.p3.4.m4.1.1.cmml"><mi id="S5.SS3.p3.4.m4.1.1.2" xref="S5.SS3.p3.4.m4.1.1.2.cmml">E</mi><mo id="S5.SS3.p3.4.m4.1.1.1" xref="S5.SS3.p3.4.m4.1.1.1.cmml">=</mo><mn id="S5.SS3.p3.4.m4.1.1.3" xref="S5.SS3.p3.4.m4.1.1.3.cmml">50</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.p3.4.m4.1b"><apply id="S5.SS3.p3.4.m4.1.1.cmml" xref="S5.SS3.p3.4.m4.1.1"><eq id="S5.SS3.p3.4.m4.1.1.1.cmml" xref="S5.SS3.p3.4.m4.1.1.1"></eq><ci id="S5.SS3.p3.4.m4.1.1.2.cmml" xref="S5.SS3.p3.4.m4.1.1.2">𝐸</ci><cn type="integer" id="S5.SS3.p3.4.m4.1.1.3.cmml" xref="S5.SS3.p3.4.m4.1.1.3">50</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p3.4.m4.1c">E=50</annotation></semantics></math>. Figure <a href="#S5.F10.sf2" title="In Figure 10 ‣ 5.3 Benchmarks &amp; Experimental Results ‣ 5 Datasets, Benchmarks &amp; Experiments ‣ ModularFed: Leveraging Modularity in Federated Learning Frameworks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10(b)</span></a> shows the results under Dirichlet Distribution while Figure <a href="#S5.F10.sf3" title="In Figure 10 ‣ 5.3 Benchmarks &amp; Experimental Results ‣ 5 Datasets, Benchmarks &amp; Experiments ‣ ModularFed: Leveraging Modularity in Federated Learning Frameworks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10(c)</span></a> show them under Shard Distribution. it is hard to notice major differences as both follow the same pattern. All of the mentioned results show that a high epoch rate follows an increase in the model performance. However, a higher epoch does not strictly reflect better accuracy in every case. In Figure <a href="#S5.F10.sf4" title="In Figure 10 ‣ 5.3 Benchmarks &amp; Experimental Results ‣ 5 Datasets, Benchmarks &amp; Experiments ‣ ModularFed: Leveraging Modularity in Federated Learning Frameworks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10(d)</span></a>, we show a severe case of Non-IIDness in which each client has a unique single label in their dataset. In this special case, FedSGD performed better than FedAVG as well as less spike, which indicates a stable improvement. However, this result is only achieved when using LogisticRegression as a model configuration on the MNIST dataset, which might vary when using other configurations.</p>
</div>
<div id="S5.SS3.p4" class="ltx_para">
<p id="S5.SS3.p4.1" class="ltx_p">In the next batch, we present our experiments using FEMNIST and CIFAR10 datasets. Unlike MNIST, the datasets under consideration contain considerably more information regarding the number of pixels and their variety. For FEMNIST, the image is smaller, while in CIFAR10, the images have three channels instead of 2 in FEMNIST and MNIST. Figure <a href="#S5.F11.sf1" title="In Figure 11 ‣ 5.3 Benchmarks &amp; Experimental Results ‣ 5 Datasets, Benchmarks &amp; Experiments ‣ ModularFed: Leveraging Modularity in Federated Learning Frameworks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">11(a)</span></a> and <a href="#S5.F11.sf2" title="In Figure 11 ‣ 5.3 Benchmarks &amp; Experimental Results ‣ 5 Datasets, Benchmarks &amp; Experiments ‣ ModularFed: Leveraging Modularity in Federated Learning Frameworks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">11(b)</span></a> show the influence of Dirchilet and Shard distribution on the accuracy of the federated learning global model using the CIFAR10 dataset. The number of Epochs has a significant impact on these experiments. Under FedSGD, the experiments under both distributions started with lower accuracy and reached a higher accuracy than the <math id="S5.SS3.p4.1.m1.1" class="ltx_Math" alttext="E=50" display="inline"><semantics id="S5.SS3.p4.1.m1.1a"><mrow id="S5.SS3.p4.1.m1.1.1" xref="S5.SS3.p4.1.m1.1.1.cmml"><mi id="S5.SS3.p4.1.m1.1.1.2" xref="S5.SS3.p4.1.m1.1.1.2.cmml">E</mi><mo id="S5.SS3.p4.1.m1.1.1.1" xref="S5.SS3.p4.1.m1.1.1.1.cmml">=</mo><mn id="S5.SS3.p4.1.m1.1.1.3" xref="S5.SS3.p4.1.m1.1.1.3.cmml">50</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.p4.1.m1.1b"><apply id="S5.SS3.p4.1.m1.1.1.cmml" xref="S5.SS3.p4.1.m1.1.1"><eq id="S5.SS3.p4.1.m1.1.1.1.cmml" xref="S5.SS3.p4.1.m1.1.1.1"></eq><ci id="S5.SS3.p4.1.m1.1.1.2.cmml" xref="S5.SS3.p4.1.m1.1.1.2">𝐸</ci><cn type="integer" id="S5.SS3.p4.1.m1.1.1.3.cmml" xref="S5.SS3.p4.1.m1.1.1.3">50</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p4.1.m1.1c">E=50</annotation></semantics></math> experiments.
Additionally, both experiments’ accuracies suffered from the Non-IID distribution. Regarding FEMNSIT dataset experiments, Figure <a href="#S5.F11.sf4" title="In Figure 11 ‣ 5.3 Benchmarks &amp; Experimental Results ‣ 5 Datasets, Benchmarks &amp; Experiments ‣ ModularFed: Leveraging Modularity in Federated Learning Frameworks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">11(d)</span></a> shows the data distribution of FEMNIST when using the Shard Distributor, while Figure <a href="#S5.F11.sf3" title="In Figure 11 ‣ 5.3 Benchmarks &amp; Experimental Results ‣ 5 Datasets, Benchmarks &amp; Experiments ‣ ModularFed: Leveraging Modularity in Federated Learning Frameworks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">11(c)</span></a> portrays the Dirichlet distributor. Under the FedSGD environment, FEMNIST suffers from an apparent problem: the accuracy did not improve in either the IID or Non-IID context. However, increasing the number of Epochs sustains the accuracy improvements. Under Dirichlet influence, the Non-IID distribution started with a worse accuracy while reaching similar results at the end of the experiments. The difference between IID and Non-IID is evident in the shard distribution, Figure <a href="#S5.F11.sf4" title="In Figure 11 ‣ 5.3 Benchmarks &amp; Experimental Results ‣ 5 Datasets, Benchmarks &amp; Experiments ‣ ModularFed: Leveraging Modularity in Federated Learning Frameworks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">11(d)</span></a>.</p>
</div>
<div id="S5.SS3.p5" class="ltx_para">
<p id="S5.SS3.p5.2" class="ltx_p">We compile all of our experimental results in Table <a href="#S5.T2" title="Table 2 ‣ 5.3 Benchmarks &amp; Experimental Results ‣ 5 Datasets, Benchmarks &amp; Experiments ‣ ModularFed: Leveraging Modularity in Federated Learning Frameworks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> showing the final accuracy and loss at the end of each experiment when using <math id="S5.SS3.p5.1.m1.1" class="ltx_Math" alttext="E=1" display="inline"><semantics id="S5.SS3.p5.1.m1.1a"><mrow id="S5.SS3.p5.1.m1.1.1" xref="S5.SS3.p5.1.m1.1.1.cmml"><mi id="S5.SS3.p5.1.m1.1.1.2" xref="S5.SS3.p5.1.m1.1.1.2.cmml">E</mi><mo id="S5.SS3.p5.1.m1.1.1.1" xref="S5.SS3.p5.1.m1.1.1.1.cmml">=</mo><mn id="S5.SS3.p5.1.m1.1.1.3" xref="S5.SS3.p5.1.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.p5.1.m1.1b"><apply id="S5.SS3.p5.1.m1.1.1.cmml" xref="S5.SS3.p5.1.m1.1.1"><eq id="S5.SS3.p5.1.m1.1.1.1.cmml" xref="S5.SS3.p5.1.m1.1.1.1"></eq><ci id="S5.SS3.p5.1.m1.1.1.2.cmml" xref="S5.SS3.p5.1.m1.1.1.2">𝐸</ci><cn type="integer" id="S5.SS3.p5.1.m1.1.1.3.cmml" xref="S5.SS3.p5.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p5.1.m1.1c">E=1</annotation></semantics></math> and <math id="S5.SS3.p5.2.m2.1" class="ltx_Math" alttext="E=50" display="inline"><semantics id="S5.SS3.p5.2.m2.1a"><mrow id="S5.SS3.p5.2.m2.1.1" xref="S5.SS3.p5.2.m2.1.1.cmml"><mi id="S5.SS3.p5.2.m2.1.1.2" xref="S5.SS3.p5.2.m2.1.1.2.cmml">E</mi><mo id="S5.SS3.p5.2.m2.1.1.1" xref="S5.SS3.p5.2.m2.1.1.1.cmml">=</mo><mn id="S5.SS3.p5.2.m2.1.1.3" xref="S5.SS3.p5.2.m2.1.1.3.cmml">50</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.p5.2.m2.1b"><apply id="S5.SS3.p5.2.m2.1.1.cmml" xref="S5.SS3.p5.2.m2.1.1"><eq id="S5.SS3.p5.2.m2.1.1.1.cmml" xref="S5.SS3.p5.2.m2.1.1.1"></eq><ci id="S5.SS3.p5.2.m2.1.1.2.cmml" xref="S5.SS3.p5.2.m2.1.1.2">𝐸</ci><cn type="integer" id="S5.SS3.p5.2.m2.1.1.3.cmml" xref="S5.SS3.p5.2.m2.1.1.3">50</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p5.2.m2.1c">E=50</annotation></semantics></math> under both IID and Non-IID distributions.</p>
</div>
<figure id="S5.T2" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S5.T2.6.3.1" class="ltx_text" style="font-size:90%;">Table 2</span>: </span><span id="S5.T2.4.2" class="ltx_text" style="font-size:90%;">Last Accuracy and Loss of federated learning experiments when using <math id="S5.T2.3.1.m1.1" class="ltx_Math" alttext="E=1" display="inline"><semantics id="S5.T2.3.1.m1.1b"><mrow id="S5.T2.3.1.m1.1.1" xref="S5.T2.3.1.m1.1.1.cmml"><mi id="S5.T2.3.1.m1.1.1.2" xref="S5.T2.3.1.m1.1.1.2.cmml">E</mi><mo id="S5.T2.3.1.m1.1.1.1" xref="S5.T2.3.1.m1.1.1.1.cmml">=</mo><mn id="S5.T2.3.1.m1.1.1.3" xref="S5.T2.3.1.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T2.3.1.m1.1c"><apply id="S5.T2.3.1.m1.1.1.cmml" xref="S5.T2.3.1.m1.1.1"><eq id="S5.T2.3.1.m1.1.1.1.cmml" xref="S5.T2.3.1.m1.1.1.1"></eq><ci id="S5.T2.3.1.m1.1.1.2.cmml" xref="S5.T2.3.1.m1.1.1.2">𝐸</ci><cn type="integer" id="S5.T2.3.1.m1.1.1.3.cmml" xref="S5.T2.3.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.3.1.m1.1d">E=1</annotation></semantics></math> and <math id="S5.T2.4.2.m2.1" class="ltx_Math" alttext="E=50" display="inline"><semantics id="S5.T2.4.2.m2.1b"><mrow id="S5.T2.4.2.m2.1.1" xref="S5.T2.4.2.m2.1.1.cmml"><mi id="S5.T2.4.2.m2.1.1.2" xref="S5.T2.4.2.m2.1.1.2.cmml">E</mi><mo id="S5.T2.4.2.m2.1.1.1" xref="S5.T2.4.2.m2.1.1.1.cmml">=</mo><mn id="S5.T2.4.2.m2.1.1.3" xref="S5.T2.4.2.m2.1.1.3.cmml">50</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T2.4.2.m2.1c"><apply id="S5.T2.4.2.m2.1.1.cmml" xref="S5.T2.4.2.m2.1.1"><eq id="S5.T2.4.2.m2.1.1.1.cmml" xref="S5.T2.4.2.m2.1.1.1"></eq><ci id="S5.T2.4.2.m2.1.1.2.cmml" xref="S5.T2.4.2.m2.1.1.2">𝐸</ci><cn type="integer" id="S5.T2.4.2.m2.1.1.3.cmml" xref="S5.T2.4.2.m2.1.1.3">50</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.4.2.m2.1d">E=50</annotation></semantics></math> under IID and Non-IID experiments</span></figcaption>
<table id="S5.T2.7" class="ltx_tabular ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S5.T2.7.1.1" class="ltx_tr">
<td id="S5.T2.7.1.1.1" class="ltx_td" style="padding-top:2.5pt;padding-bottom:2.5pt;" rowspan="3"></td>
<td id="S5.T2.7.1.1.2" class="ltx_td" style="padding-top:2.5pt;padding-bottom:2.5pt;" rowspan="3"></td>
<td id="S5.T2.7.1.1.3" class="ltx_td ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;" rowspan="3"></td>
<td id="S5.T2.7.1.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;" colspan="4"><span id="S5.T2.7.1.1.4.1" class="ltx_text ltx_font_bold">Results</span></td>
</tr>
<tr id="S5.T2.7.2.2" class="ltx_tr">
<td id="S5.T2.7.2.2.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;" colspan="2"><span id="S5.T2.7.2.2.1.1" class="ltx_text ltx_font_bold">ACC</span></td>
<td id="S5.T2.7.2.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;" colspan="2"><span id="S5.T2.7.2.2.2.1" class="ltx_text ltx_font_bold">LOSS</span></td>
</tr>
<tr id="S5.T2.7.3.3" class="ltx_tr">
<td id="S5.T2.7.3.3.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S5.T2.7.3.3.1.1" class="ltx_text ltx_font_bold">E=1</span></td>
<td id="S5.T2.7.3.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S5.T2.7.3.3.2.1" class="ltx_text ltx_font_bold">E=50</span></td>
<td id="S5.T2.7.3.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S5.T2.7.3.3.3.1" class="ltx_text ltx_font_bold">E=1</span></td>
<td id="S5.T2.7.3.3.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S5.T2.7.3.3.4.1" class="ltx_text ltx_font_bold">E=50</span></td>
</tr>
<tr id="S5.T2.7.4.4" class="ltx_tr">
<td id="S5.T2.7.4.4.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;" rowspan="7"><span id="S5.T2.7.4.4.1.1" class="ltx_text ltx_font_bold">MNIST</span></td>
<td id="S5.T2.7.4.4.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;" rowspan="2"><span id="S5.T2.7.4.4.2.1" class="ltx_text">Label</span></td>
<td id="S5.T2.7.4.4.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">IID</td>
<td id="S5.T2.7.4.4.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">0.8415</td>
<td id="S5.T2.7.4.4.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">0.899</td>
<td id="S5.T2.7.4.4.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">1.621</td>
<td id="S5.T2.7.4.4.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">1.556</td>
</tr>
<tr id="S5.T2.7.5.5" class="ltx_tr">
<td id="S5.T2.7.5.5.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">N-IID</td>
<td id="S5.T2.7.5.5.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">0.854</td>
<td id="S5.T2.7.5.5.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">0.867</td>
<td id="S5.T2.7.5.5.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">1.62</td>
<td id="S5.T2.7.5.5.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">1.637</td>
</tr>
<tr id="S5.T2.7.6.6" class="ltx_tr">
<td id="S5.T2.7.6.6.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;" rowspan="2"><span id="S5.T2.7.6.6.1.1" class="ltx_text">Shard</span></td>
<td id="S5.T2.7.6.6.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">IID</td>
<td id="S5.T2.7.6.6.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">0.859</td>
<td id="S5.T2.7.6.6.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">0.9002</td>
<td id="S5.T2.7.6.6.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">1.593</td>
<td id="S5.T2.7.6.6.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">1.555</td>
</tr>
<tr id="S5.T2.7.7.7" class="ltx_tr">
<td id="S5.T2.7.7.7.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">N-IID</td>
<td id="S5.T2.7.7.7.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">0.852</td>
<td id="S5.T2.7.7.7.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">0.911</td>
<td id="S5.T2.7.7.7.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">1.6214</td>
<td id="S5.T2.7.7.7.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">1.573</td>
</tr>
<tr id="S5.T2.7.8.8" class="ltx_tr">
<td id="S5.T2.7.8.8.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;" rowspan="2"><span id="S5.T2.7.8.8.1.1" class="ltx_text">Dirichlet</span></td>
<td id="S5.T2.7.8.8.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">IID</td>
<td id="S5.T2.7.8.8.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">0.849</td>
<td id="S5.T2.7.8.8.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">0.903</td>
<td id="S5.T2.7.8.8.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">1.612</td>
<td id="S5.T2.7.8.8.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">1.554</td>
</tr>
<tr id="S5.T2.7.9.9" class="ltx_tr">
<td id="S5.T2.7.9.9.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">N-IID</td>
<td id="S5.T2.7.9.9.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">0.845</td>
<td id="S5.T2.7.9.9.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">0.906</td>
<td id="S5.T2.7.9.9.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">1.613</td>
<td id="S5.T2.7.9.9.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">1.56</td>
</tr>
<tr id="S5.T2.7.10.10" class="ltx_tr">
<td id="S5.T2.7.10.10.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">Unique</td>
<td id="S5.T2.7.10.10.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">N-IID</td>
<td id="S5.T2.7.10.10.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">0.896</td>
<td id="S5.T2.7.10.10.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">0.784</td>
<td id="S5.T2.7.10.10.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">1.582</td>
<td id="S5.T2.7.10.10.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">1.727</td>
</tr>
<tr id="S5.T2.7.11.11" class="ltx_tr">
<td id="S5.T2.7.11.11.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;" rowspan="4"><span id="S5.T2.7.11.11.1.1" class="ltx_text ltx_font_bold">CIFAR</span></td>
<td id="S5.T2.7.11.11.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;" rowspan="2"><span id="S5.T2.7.11.11.2.1" class="ltx_text">Shard</span></td>
<td id="S5.T2.7.11.11.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">IID</td>
<td id="S5.T2.7.11.11.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">0.519</td>
<td id="S5.T2.7.11.11.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">0.438</td>
<td id="S5.T2.7.11.11.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">1.419</td>
<td id="S5.T2.7.11.11.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">5.104</td>
</tr>
<tr id="S5.T2.7.12.12" class="ltx_tr">
<td id="S5.T2.7.12.12.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">N-IID</td>
<td id="S5.T2.7.12.12.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">0.323</td>
<td id="S5.T2.7.12.12.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">0.394</td>
<td id="S5.T2.7.12.12.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">1.996</td>
<td id="S5.T2.7.12.12.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">3.175</td>
</tr>
<tr id="S5.T2.7.13.13" class="ltx_tr">
<td id="S5.T2.7.13.13.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;" rowspan="2"><span id="S5.T2.7.13.13.1.1" class="ltx_text">Dirichlet</span></td>
<td id="S5.T2.7.13.13.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">IID</td>
<td id="S5.T2.7.13.13.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">0.4946</td>
<td id="S5.T2.7.13.13.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">0.456</td>
<td id="S5.T2.7.13.13.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">1.4</td>
<td id="S5.T2.7.13.13.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">5.769</td>
</tr>
<tr id="S5.T2.7.14.14" class="ltx_tr">
<td id="S5.T2.7.14.14.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">N-IID</td>
<td id="S5.T2.7.14.14.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">0.433</td>
<td id="S5.T2.7.14.14.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">0.415</td>
<td id="S5.T2.7.14.14.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">1.584</td>
<td id="S5.T2.7.14.14.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">4.719</td>
</tr>
<tr id="S5.T2.7.15.15" class="ltx_tr">
<td id="S5.T2.7.15.15.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;" rowspan="4"><span id="S5.T2.7.15.15.1.1" class="ltx_text ltx_font_bold">FEMNIST</span></td>
<td id="S5.T2.7.15.15.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;" rowspan="2"><span id="S5.T2.7.15.15.2.1" class="ltx_text">Shard</span></td>
<td id="S5.T2.7.15.15.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">IID</td>
<td id="S5.T2.7.15.15.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">0.106</td>
<td id="S5.T2.7.15.15.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">0.585</td>
<td id="S5.T2.7.15.15.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">4.068</td>
<td id="S5.T2.7.15.15.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">3.579</td>
</tr>
<tr id="S5.T2.7.16.16" class="ltx_tr">
<td id="S5.T2.7.16.16.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">N-IID</td>
<td id="S5.T2.7.16.16.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">0.0509</td>
<td id="S5.T2.7.16.16.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">0.498</td>
<td id="S5.T2.7.16.16.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">4.094</td>
<td id="S5.T2.7.16.16.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">3.691</td>
</tr>
<tr id="S5.T2.7.17.17" class="ltx_tr">
<td id="S5.T2.7.17.17.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;" rowspan="2"><span id="S5.T2.7.17.17.1.1" class="ltx_text">Dirichlet</span></td>
<td id="S5.T2.7.17.17.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">IID</td>
<td id="S5.T2.7.17.17.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">0.326</td>
<td id="S5.T2.7.17.17.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">0.889</td>
<td id="S5.T2.7.17.17.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">3.858</td>
<td id="S5.T2.7.17.17.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">3.265</td>
</tr>
<tr id="S5.T2.7.18.18" class="ltx_tr">
<td id="S5.T2.7.18.18.1" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">N-IID</td>
<td id="S5.T2.7.18.18.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">0.203</td>
<td id="S5.T2.7.18.18.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">0.889</td>
<td id="S5.T2.7.18.18.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">3.951</td>
<td id="S5.T2.7.18.18.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">3.26</td>
</tr>
</tbody>
</table>
</figure>
<div id="S5.SS3.p6" class="ltx_para">
<p id="S5.SS3.p6.1" class="ltx_p">Different from our previous experiments, In Figure <a href="#S5.F12" title="Figure 12 ‣ 5.3 Benchmarks &amp; Experimental Results ‣ 5 Datasets, Benchmarks &amp; Experiments ‣ ModularFed: Leveraging Modularity in Federated Learning Frameworks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">12</span></a> we highlight the bandwidth cost of using different model configurations showing the impact on the model accuracy. The Figure shows the evolution of the accuracy throughout the federated learning rounds, and the accumulative bandwidth cost annotated for every 100 rounds. The model configurations in use are CNN 2 Layers and LogisticRegression. For the hyper-parameters, we used FedSGD on the MNIST dataset distributed to 100 clients using Dirichlet Distributor with <math id="S5.SS3.p6.1.m1.1" class="ltx_Math" alttext="\alpha=10" display="inline"><semantics id="S5.SS3.p6.1.m1.1a"><mrow id="S5.SS3.p6.1.m1.1.1" xref="S5.SS3.p6.1.m1.1.1.cmml"><mi id="S5.SS3.p6.1.m1.1.1.2" xref="S5.SS3.p6.1.m1.1.1.2.cmml">α</mi><mo id="S5.SS3.p6.1.m1.1.1.1" xref="S5.SS3.p6.1.m1.1.1.1.cmml">=</mo><mn id="S5.SS3.p6.1.m1.1.1.3" xref="S5.SS3.p6.1.m1.1.1.3.cmml">10</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.p6.1.m1.1b"><apply id="S5.SS3.p6.1.m1.1.1.cmml" xref="S5.SS3.p6.1.m1.1.1"><eq id="S5.SS3.p6.1.m1.1.1.1.cmml" xref="S5.SS3.p6.1.m1.1.1.1"></eq><ci id="S5.SS3.p6.1.m1.1.1.2.cmml" xref="S5.SS3.p6.1.m1.1.1.2">𝛼</ci><cn type="integer" id="S5.SS3.p6.1.m1.1.1.3.cmml" xref="S5.SS3.p6.1.m1.1.1.3">10</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p6.1.m1.1c">\alpha=10</annotation></semantics></math>. Ten clients are randomly selected to train a model using the provided configuration in each round. Since we are not using any compression algorithm, the models’ weight size is constant. In this experiment, using LogisticRegression, we achieved an accuracy of 88% after 1000 rounds which cost a total of 4.236 MB, compared to 90% accuracy reached when using CNN achieved after ten rounds with a total cost of 0.08 MB. In this case, an exemplary model configuration can reduce the total bandwidth cost, although it costs more per client per round.</p>
</div>
<figure id="S5.F12" class="ltx_figure"><img src="/html/2212.10427/assets/band.png" id="S5.F12.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="467" height="240" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F12.2.1.1" class="ltx_text" style="font-size:90%;">Figure 12</span>: </span><span id="S5.F12.3.2" class="ltx_text" style="font-size:90%;">Bandwidth transmission cost comparison between CNN and LogisticRegression (LogR) model configuration</span></figcaption>
</figure>
<div id="S5.SS3.p7" class="ltx_para">
<p id="S5.SS3.p7.3" class="ltx_p">In Figure <a href="#S5.F13" title="Figure 13 ‣ 5.3 Benchmarks &amp; Experimental Results ‣ 5 Datasets, Benchmarks &amp; Experiments ‣ ModularFed: Leveraging Modularity in Federated Learning Frameworks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">13</span></a>, we show the impact of the client selector on the global model accuracy after each round. For this experiment, we used Label Distributor with <math id="S5.SS3.p7.1.m1.1" class="ltx_Math" alttext="L=2" display="inline"><semantics id="S5.SS3.p7.1.m1.1a"><mrow id="S5.SS3.p7.1.m1.1.1" xref="S5.SS3.p7.1.m1.1.1.cmml"><mi id="S5.SS3.p7.1.m1.1.1.2" xref="S5.SS3.p7.1.m1.1.1.2.cmml">L</mi><mo id="S5.SS3.p7.1.m1.1.1.1" xref="S5.SS3.p7.1.m1.1.1.1.cmml">=</mo><mn id="S5.SS3.p7.1.m1.1.1.3" xref="S5.SS3.p7.1.m1.1.1.3.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.p7.1.m1.1b"><apply id="S5.SS3.p7.1.m1.1.1.cmml" xref="S5.SS3.p7.1.m1.1.1"><eq id="S5.SS3.p7.1.m1.1.1.1.cmml" xref="S5.SS3.p7.1.m1.1.1.1"></eq><ci id="S5.SS3.p7.1.m1.1.1.2.cmml" xref="S5.SS3.p7.1.m1.1.1.2">𝐿</ci><cn type="integer" id="S5.SS3.p7.1.m1.1.1.3.cmml" xref="S5.SS3.p7.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p7.1.m1.1c">L=2</annotation></semantics></math> to create a Non-IID data distribution between clients coupled with FedSGD configuration and a client ratio of 10. We compare between random client selector with a cluster-based client selector. In the latter, we start with an initialization round, asking each client to train a model and send it to the server. The selector will use the model as input to identify the client cluster using the K-Means algorithm with a parameter <math id="S5.SS3.p7.2.m2.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S5.SS3.p7.2.m2.1a"><mi id="S5.SS3.p7.2.m2.1.1" xref="S5.SS3.p7.2.m2.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S5.SS3.p7.2.m2.1b"><ci id="S5.SS3.p7.2.m2.1.1.cmml" xref="S5.SS3.p7.2.m2.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p7.2.m2.1c">K</annotation></semantics></math>, which refers to the number of clusters. During each round, the clustering algorithm selects a predefined number of clients from each cluster to participate. For instance, for a client ratio of ten, and <math id="S5.SS3.p7.3.m3.1" class="ltx_Math" alttext="K=5" display="inline"><semantics id="S5.SS3.p7.3.m3.1a"><mrow id="S5.SS3.p7.3.m3.1.1" xref="S5.SS3.p7.3.m3.1.1.cmml"><mi id="S5.SS3.p7.3.m3.1.1.2" xref="S5.SS3.p7.3.m3.1.1.2.cmml">K</mi><mo id="S5.SS3.p7.3.m3.1.1.1" xref="S5.SS3.p7.3.m3.1.1.1.cmml">=</mo><mn id="S5.SS3.p7.3.m3.1.1.3" xref="S5.SS3.p7.3.m3.1.1.3.cmml">5</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.p7.3.m3.1b"><apply id="S5.SS3.p7.3.m3.1.1.cmml" xref="S5.SS3.p7.3.m3.1.1"><eq id="S5.SS3.p7.3.m3.1.1.1.cmml" xref="S5.SS3.p7.3.m3.1.1.1"></eq><ci id="S5.SS3.p7.3.m3.1.1.2.cmml" xref="S5.SS3.p7.3.m3.1.1.2">𝐾</ci><cn type="integer" id="S5.SS3.p7.3.m3.1.1.3.cmml" xref="S5.SS3.p7.3.m3.1.1.3">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p7.3.m3.1c">K=5</annotation></semantics></math>, we select two clients from each cluster. Using such an approach makes it possible to have a variety of model weights for each round, which can be used to solve the Non-IID distribution issues. Overall, the results in Figure <a href="#S5.F13" title="Figure 13 ‣ 5.3 Benchmarks &amp; Experimental Results ‣ 5 Datasets, Benchmarks &amp; Experiments ‣ ModularFed: Leveraging Modularity in Federated Learning Frameworks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">13</span></a> demonstrate the capabilities of the cluster selector to achieve better and more stable results than the random selector.</p>
</div>
<figure id="S5.F13" class="ltx_figure"><img src="/html/2212.10427/assets/mnist_selector.png" id="S5.F13.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="467" height="263" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F13.2.1.1" class="ltx_text" style="font-size:90%;">Figure 13</span>: </span><span id="S5.F13.3.2" class="ltx_text" style="font-size:90%;">Comparison between Cluster Selector and Random Selector using MNIST dataset</span></figcaption>
</figure>
</section>
<section id="S5.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.4 </span>Weight Divergence Analysis Module</h3>

<div id="S5.SS4.p1" class="ltx_para">
<p id="S5.SS4.p1.1" class="ltx_p">Figures <a href="#S5.F14" title="Figure 14 ‣ 5.4 Weight Divergence Analysis Module ‣ 5 Datasets, Benchmarks &amp; Experiments ‣ ModularFed: Leveraging Modularity in Federated Learning Frameworks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">14</span></a> depict the integration of a complex weight analysis mechanism into any federated learning approach. In this experiment, the module shows the evolution of weight divergence between clients’ weights in both IID in Figures <a href="#S5.F14.sf1" title="In Figure 14 ‣ 5.4 Weight Divergence Analysis Module ‣ 5 Datasets, Benchmarks &amp; Experiments ‣ ModularFed: Leveraging Modularity in Federated Learning Frameworks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">14(a)</span></a>, <a href="#S5.F14.sf2" title="In Figure 14 ‣ 5.4 Weight Divergence Analysis Module ‣ 5 Datasets, Benchmarks &amp; Experiments ‣ ModularFed: Leveraging Modularity in Federated Learning Frameworks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">14(b)</span></a> and Non-IID in Figures <a href="#S5.F14.sf3" title="In Figure 14 ‣ 5.4 Weight Divergence Analysis Module ‣ 5 Datasets, Benchmarks &amp; Experiments ‣ ModularFed: Leveraging Modularity in Federated Learning Frameworks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">14(c)</span></a>, <a href="#S5.F14.sf4" title="In Figure 14 ‣ 5.4 Weight Divergence Analysis Module ‣ 5 Datasets, Benchmarks &amp; Experiments ‣ ModularFed: Leveraging Modularity in Federated Learning Frameworks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">14(d)</span></a>. In each figure, each plot line represents the flattened weights of an MNIST client. Due to the size of the weights, principal component analysis (PCA) is used to reduce the number of representable values.</p>
</div>
<figure id="S5.F14" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S5.F14.sf1" class="ltx_figure ltx_figure_panel"><img src="/html/2212.10427/assets/iid_wd_0.png" id="S5.F14.sf1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="449" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F14.sf1.4.2.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S5.F14.sf1.2.1" class="ltx_text" style="font-size:90%;">IID 
<br class="ltx_break">Label Distribution <math id="S5.F14.sf1.2.1.m1.1" class="ltx_Math" alttext="R=0" display="inline"><semantics id="S5.F14.sf1.2.1.m1.1b"><mrow id="S5.F14.sf1.2.1.m1.1.1" xref="S5.F14.sf1.2.1.m1.1.1.cmml"><mi id="S5.F14.sf1.2.1.m1.1.1.2" xref="S5.F14.sf1.2.1.m1.1.1.2.cmml">R</mi><mo id="S5.F14.sf1.2.1.m1.1.1.1" xref="S5.F14.sf1.2.1.m1.1.1.1.cmml">=</mo><mn id="S5.F14.sf1.2.1.m1.1.1.3" xref="S5.F14.sf1.2.1.m1.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.F14.sf1.2.1.m1.1c"><apply id="S5.F14.sf1.2.1.m1.1.1.cmml" xref="S5.F14.sf1.2.1.m1.1.1"><eq id="S5.F14.sf1.2.1.m1.1.1.1.cmml" xref="S5.F14.sf1.2.1.m1.1.1.1"></eq><ci id="S5.F14.sf1.2.1.m1.1.1.2.cmml" xref="S5.F14.sf1.2.1.m1.1.1.2">𝑅</ci><cn type="integer" id="S5.F14.sf1.2.1.m1.1.1.3.cmml" xref="S5.F14.sf1.2.1.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.F14.sf1.2.1.m1.1d">R=0</annotation></semantics></math></span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S5.F14.sf2" class="ltx_figure ltx_figure_panel"><img src="/html/2212.10427/assets/iid_wd_10.png" id="S5.F14.sf2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="449" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F14.sf2.4.2.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S5.F14.sf2.2.1" class="ltx_text" style="font-size:90%;">IID 
<br class="ltx_break">Label Distribution <math id="S5.F14.sf2.2.1.m1.1" class="ltx_Math" alttext="R=10" display="inline"><semantics id="S5.F14.sf2.2.1.m1.1b"><mrow id="S5.F14.sf2.2.1.m1.1.1" xref="S5.F14.sf2.2.1.m1.1.1.cmml"><mi id="S5.F14.sf2.2.1.m1.1.1.2" xref="S5.F14.sf2.2.1.m1.1.1.2.cmml">R</mi><mo id="S5.F14.sf2.2.1.m1.1.1.1" xref="S5.F14.sf2.2.1.m1.1.1.1.cmml">=</mo><mn id="S5.F14.sf2.2.1.m1.1.1.3" xref="S5.F14.sf2.2.1.m1.1.1.3.cmml">10</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.F14.sf2.2.1.m1.1c"><apply id="S5.F14.sf2.2.1.m1.1.1.cmml" xref="S5.F14.sf2.2.1.m1.1.1"><eq id="S5.F14.sf2.2.1.m1.1.1.1.cmml" xref="S5.F14.sf2.2.1.m1.1.1.1"></eq><ci id="S5.F14.sf2.2.1.m1.1.1.2.cmml" xref="S5.F14.sf2.2.1.m1.1.1.2">𝑅</ci><cn type="integer" id="S5.F14.sf2.2.1.m1.1.1.3.cmml" xref="S5.F14.sf2.2.1.m1.1.1.3">10</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.F14.sf2.2.1.m1.1d">R=10</annotation></semantics></math></span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S5.F14.sf3" class="ltx_figure ltx_figure_panel"><img src="/html/2212.10427/assets/noniid_wd_0.png" id="S5.F14.sf3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="449" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F14.sf3.4.2.1" class="ltx_text" style="font-size:90%;">(c)</span> </span><span id="S5.F14.sf3.2.1" class="ltx_text" style="font-size:90%;">Non-IID 
<br class="ltx_break">Label Distribution <math id="S5.F14.sf3.2.1.m1.1" class="ltx_Math" alttext="R=0" display="inline"><semantics id="S5.F14.sf3.2.1.m1.1b"><mrow id="S5.F14.sf3.2.1.m1.1.1" xref="S5.F14.sf3.2.1.m1.1.1.cmml"><mi id="S5.F14.sf3.2.1.m1.1.1.2" xref="S5.F14.sf3.2.1.m1.1.1.2.cmml">R</mi><mo id="S5.F14.sf3.2.1.m1.1.1.1" xref="S5.F14.sf3.2.1.m1.1.1.1.cmml">=</mo><mn id="S5.F14.sf3.2.1.m1.1.1.3" xref="S5.F14.sf3.2.1.m1.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.F14.sf3.2.1.m1.1c"><apply id="S5.F14.sf3.2.1.m1.1.1.cmml" xref="S5.F14.sf3.2.1.m1.1.1"><eq id="S5.F14.sf3.2.1.m1.1.1.1.cmml" xref="S5.F14.sf3.2.1.m1.1.1.1"></eq><ci id="S5.F14.sf3.2.1.m1.1.1.2.cmml" xref="S5.F14.sf3.2.1.m1.1.1.2">𝑅</ci><cn type="integer" id="S5.F14.sf3.2.1.m1.1.1.3.cmml" xref="S5.F14.sf3.2.1.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.F14.sf3.2.1.m1.1d">R=0</annotation></semantics></math></span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S5.F14.sf4" class="ltx_figure ltx_figure_panel"><img src="/html/2212.10427/assets/noniid_wd_99.png" id="S5.F14.sf4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="449" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F14.sf4.4.2.1" class="ltx_text" style="font-size:90%;">(d)</span> </span><span id="S5.F14.sf4.2.1" class="ltx_text" style="font-size:90%;">Non-IID 
<br class="ltx_break">Label Distribution <math id="S5.F14.sf4.2.1.m1.1" class="ltx_Math" alttext="R=99" display="inline"><semantics id="S5.F14.sf4.2.1.m1.1b"><mrow id="S5.F14.sf4.2.1.m1.1.1" xref="S5.F14.sf4.2.1.m1.1.1.cmml"><mi id="S5.F14.sf4.2.1.m1.1.1.2" xref="S5.F14.sf4.2.1.m1.1.1.2.cmml">R</mi><mo id="S5.F14.sf4.2.1.m1.1.1.1" xref="S5.F14.sf4.2.1.m1.1.1.1.cmml">=</mo><mn id="S5.F14.sf4.2.1.m1.1.1.3" xref="S5.F14.sf4.2.1.m1.1.1.3.cmml">99</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.F14.sf4.2.1.m1.1c"><apply id="S5.F14.sf4.2.1.m1.1.1.cmml" xref="S5.F14.sf4.2.1.m1.1.1"><eq id="S5.F14.sf4.2.1.m1.1.1.1.cmml" xref="S5.F14.sf4.2.1.m1.1.1.1"></eq><ci id="S5.F14.sf4.2.1.m1.1.1.2.cmml" xref="S5.F14.sf4.2.1.m1.1.1.2">𝑅</ci><cn type="integer" id="S5.F14.sf4.2.1.m1.1.1.3.cmml" xref="S5.F14.sf4.2.1.m1.1.1.3">99</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.F14.sf4.2.1.m1.1d">R=99</annotation></semantics></math></span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S5.F14.2.1.1" class="ltx_text" style="font-size:90%;">Figure 14</span>: </span><span id="S5.F14.3.2" class="ltx_text" style="font-size:90%;">Models’ Weights Representation of 100 IID/Non-IID Clients Using Weight Divergence Analysis Module</span></figcaption>
</figure>
<div id="S5.SS4.p2" class="ltx_para">
<p id="S5.SS4.p2.1" class="ltx_p">Comparing the IID experiment <a href="#S5.F14.sf1" title="In Figure 14 ‣ 5.4 Weight Divergence Analysis Module ‣ 5 Datasets, Benchmarks &amp; Experiments ‣ ModularFed: Leveraging Modularity in Federated Learning Frameworks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">14(a)</span></a> to the Non-IID <a href="#S5.F14.sf3" title="In Figure 14 ‣ 5.4 Weight Divergence Analysis Module ‣ 5 Datasets, Benchmarks &amp; Experiments ‣ ModularFed: Leveraging Modularity in Federated Learning Frameworks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">14(c)</span></a> at round 0, we can notice a difference in the weight divergence between the clients. When following and IID distribution between clients’ data, there tend to exist similarities between the generated models’ weights. The appearing weight divergences subside to almost identical weights after <math id="S5.SS4.p2.1.m1.1" class="ltx_Math" alttext="10" display="inline"><semantics id="S5.SS4.p2.1.m1.1a"><mn id="S5.SS4.p2.1.m1.1.1" xref="S5.SS4.p2.1.m1.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="S5.SS4.p2.1.m1.1b"><cn type="integer" id="S5.SS4.p2.1.m1.1.1.cmml" xref="S5.SS4.p2.1.m1.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p2.1.m1.1c">10</annotation></semantics></math> rounds, as shown in Figure <a href="#S5.F14.sf2" title="In Figure 14 ‣ 5.4 Weight Divergence Analysis Module ‣ 5 Datasets, Benchmarks &amp; Experiments ‣ ModularFed: Leveraging Modularity in Federated Learning Frameworks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">14(b)</span></a>.</p>
</div>
<div id="S5.SS4.p3" class="ltx_para">
<p id="S5.SS4.p3.1" class="ltx_p">On the other hand, the Non-IID clients in Figure <a href="#S5.F14.sf3" title="In Figure 14 ‣ 5.4 Weight Divergence Analysis Module ‣ 5 Datasets, Benchmarks &amp; Experiments ‣ ModularFed: Leveraging Modularity in Federated Learning Frameworks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">14(c)</span></a> show a higher weight divergence between them. The weight divergence is still evident even after <math id="S5.SS4.p3.1.m1.1" class="ltx_Math" alttext="99" display="inline"><semantics id="S5.SS4.p3.1.m1.1a"><mn id="S5.SS4.p3.1.m1.1.1" xref="S5.SS4.p3.1.m1.1.1.cmml">99</mn><annotation-xml encoding="MathML-Content" id="S5.SS4.p3.1.m1.1b"><cn type="integer" id="S5.SS4.p3.1.m1.1.1.cmml" xref="S5.SS4.p3.1.m1.1.1">99</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p3.1.m1.1c">99</annotation></semantics></math> rounds, as shown in Figure <a href="#S5.F14.sf4" title="In Figure 14 ‣ 5.4 Weight Divergence Analysis Module ‣ 5 Datasets, Benchmarks &amp; Experiments ‣ ModularFed: Leveraging Modularity in Federated Learning Frameworks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">14(d)</span></a> compared to the IID case. This weight representation can imply a direct connection between the federated learning performance and the weight divergence that exists due to the data distribution. The higher the weight divergence, the more it has adverse effects on the global model in terms of accuracy and convergence rate.</p>
</div>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusion</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">With federated learning getting acknowledged for its premise, there is a lack of fundamental conventions in available frameworks. We aim to solve this issue by introducing our protocol-based layered architecture, with modular support allowing our framework to act as a complete ecosystem. Using our modular implementation, we consider FL functionalities as separate modules that can be transferable mini-application. Such modularity entitles us to have a junction in our ideas. Additionally, our framework is built from scratch to support projects’ extendability while providing the necessary tools to replicate the majority of FL-related issues. We laid the groundwork through ModularFed, and we plan to further enhance it in the future by integrating various supporting technologies as modules. Technologies such as traceability through blockchain or components deployments and orchestration through Kubernetes microservices. Finally, we experimented with the validity and flexibility of our framework under various FL scenarios, including distribution issues, network consumption, and client quality. Our framework will be constantly maintained by introducing new features and various new modules following the latest directions.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
S. A. Rahman, H. Tout, C. Talhi, A. Mourad, Internet of things intrusion
detection: Centralized, on-device, or federated learning?, IEEE Network
34 (6) (2020) 310–317.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.1109/MNET.011.2000286" title="" class="ltx_ref ltx_href"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.1109/MNET.011.2000286</span></a>.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
O. A. Wahab, A. Mourad, H. Otrok, T. Taleb, Federated machine learning: Survey,
multi-level classification, desirable criteria and future directions in
communication and networking systems, IEEE Communications Surveys &amp;
Tutorials 23 (2) (2021) 1342–1397.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.1109/COMST.2021.3058573" title="" class="ltx_ref ltx_href"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.1109/COMST.2021.3058573</span></a>.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
S. Abdulrahman, H. Tout, H. Ould-Slimane, A. Mourad, C. Talhi, M. Guizani, A
survey on federated learning: The journey from centralized to distributed
on-site learning and beyond, IEEE Internet of Things Journal 8 (7) (2021)
5476–5497.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.1109/JIOT.2020.3030072" title="" class="ltx_ref ltx_href"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.1109/JIOT.2020.3030072</span></a>.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
S. Arisdakessian, O. A. Wahab, A. Mourad, H. Otrok, M. Guizani, A survey on iot
intrusion detection: Federated learning, game theory, social psychology and
explainable ai as future directions, IEEE Internet of Things Journal (2022)
1–1<a target="_blank" href="https://doi.org/10.1109/JIOT.2022.3203249" title="" class="ltx_ref ltx_href"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.1109/JIOT.2022.3203249</span></a>.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
H. B. McMahan, E. Moore, D. Ramage, S. Hampson, B. A. y. Arcas,
<a target="_blank" href="https://arxiv.org/abs/1602.05629" title="" class="ltx_ref ltx_href">Communication-efficient learning of
deep networks from decentralized data</a> (2016).

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/ARXIV.1602.05629" title="" class="ltx_ref ltx_href"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.48550/ARXIV.1602.05629</span></a>.

<br class="ltx_break">URL <a target="_blank" href="https://arxiv.org/abs/1602.05629" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/abs/1602.05629</a>

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
C. Briggs, Z. Fan, P. Andras, Federated learning with hierarchical clustering
of local updates to improve training on non-iid data, in: 2020 International
Joint Conference on Neural Networks (IJCNN), 2020, pp. 1–9.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.1109/IJCNN48605.2020.9207469" title="" class="ltx_ref ltx_href"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.1109/IJCNN48605.2020.9207469</span></a>.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
F. Sattler, K.-R. Müller, W. Samek, Clustered federated learning:
Model-agnostic distributed multitask optimization under privacy constraints,
IEEE Transactions on Neural Networks and Learning Systems 32 (8) (2021)
3710–3722.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.1109/TNNLS.2020.3015958" title="" class="ltx_ref ltx_href"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.1109/TNNLS.2020.3015958</span></a>.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
Y. Kim, E. A. Hakim, J. Haraldson, H. Eriksson, J. M. B. da Silva,
C. Fischione, Dynamic clustering in federated learning, in: ICC 2021 - IEEE
International Conference on Communications, 2021, pp. 1–6.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.1109/ICC42927.2021.9500877" title="" class="ltx_ref ltx_href"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.1109/ICC42927.2021.9500877</span></a>.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
C. Li, G. Li, P. K. Varshney, Federated learning with soft clustering, IEEE
Internet of Things Journal 9 (10) (2022) 7773–7782.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.1109/JIOT.2021.3113927" title="" class="ltx_ref ltx_href"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.1109/JIOT.2021.3113927</span></a>.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
H. Wang, M. Yurochkin, Y. Sun, D. S. Papailiopoulos, Y. Khazaeni,
<a target="_blank" href="https://arxiv.org/abs/2002.06440" title="" class="ltx_ref ltx_href">Federated learning with matched
averaging</a>, CoRR abs/2002.06440 (2020).

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2002.06440" title="" class="ltx_ref ltx_href"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">arXiv:2002.06440</span></a>.

<br class="ltx_break">URL <a target="_blank" href="https://arxiv.org/abs/2002.06440" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/abs/2002.06440</a>

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
S. P. Karimireddy, S. Kale, M. Mohri, S. J. Reddi, S. U. Stich, A. T. Suresh,
<a target="_blank" href="http://arxiv.org/abs/1910.06378" title="" class="ltx_ref ltx_href">SCAFFOLD: stochastic controlled
averaging for on-device federated learning</a>, CoRR abs/1910.06378 (2019).

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/1910.06378" title="" class="ltx_ref ltx_href"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">arXiv:1910.06378</span></a>.

<br class="ltx_break">URL <a target="_blank" href="http://arxiv.org/abs/1910.06378" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://arxiv.org/abs/1910.06378</a>

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
A. Reisizadeh, F. Farnia, R. Pedarsani, A. Jadbabaie,
<a target="_blank" href="https://arxiv.org/abs/2006.08907" title="" class="ltx_ref ltx_href">Robust federated learning: The case
of affine distribution shifts</a>, CoRR abs/2006.08907 (2020).

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2006.08907" title="" class="ltx_ref ltx_href"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">arXiv:2006.08907</span></a>.

<br class="ltx_break">URL <a target="_blank" href="https://arxiv.org/abs/2006.08907" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/abs/2006.08907</a>

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
W. Zhang, X. Wang, P. Zhou, W. Wu, X. Zhang, Client selection for federated
learning with non-iid data in mobile edge computing, IEEE Access 9 (2021)
24462–24474.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.1109/ACCESS.2021.3056919" title="" class="ltx_ref ltx_href"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.1109/ACCESS.2021.3056919</span></a>.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
M. Wazzeh, H. Ould-Slimane, C. Talhi, A. Mourad, M. Guizani, Privacy-preserving
continuous authentication for mobile and iot systems using warmup-based
federated learning, IEEE Network (2022) 1–7<a target="_blank" href="https://doi.org/10.1109/MNET.121.2200099" title="" class="ltx_ref ltx_href"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.1109/MNET.121.2200099</span></a>.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
G. Sun, Y. Cong, J. Dong, Q. Wang, L. Lyu, J. Liu, Data poisoning attacks on
federated machine learning, IEEE Internet of Things Journal 9 (13) (2022)
11365–11375.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.1109/JIOT.2021.3128646" title="" class="ltx_ref ltx_href"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.1109/JIOT.2021.3128646</span></a>.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
V. Tolpegin, S. Truex, M. E. Gursoy, L. Liu, Data poisoning attacks against
federated learning systems, in: L. Chen, N. Li, K. Liang, S. Schneider
(Eds.), Computer Security – ESORICS 2020, Springer International Publishing,
Cham, 2020, pp. 480–501.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
Z. Chen, P. Tian, W. Liao, W. Yu, Zero knowledge clustering based adversarial
mitigation in heterogeneous federated learning, IEEE Transactions on Network
Science and Engineering 8 (2) (2021) 1070–1083.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.1109/TNSE.2020.3002796" title="" class="ltx_ref ltx_href"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.1109/TNSE.2020.3002796</span></a>.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
S. K. Lo, Y. Liu, Q. Lu, C. Wang, X. Xu, H.-Y. Paik, L. Zhu, Towards
trustworthy ai: Blockchain-based architecture design for accountability and
fairness of federated learning systems, IEEE Internet of Things Journal
(2022) 1–1<a target="_blank" href="https://doi.org/10.1109/JIOT.2022.3144450" title="" class="ltx_ref ltx_href"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.1109/JIOT.2022.3144450</span></a>.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
S. Otoum, I. Al Ridhawi, H. T. Mouftah, Blockchain-supported federated learning
for trustworthy vehicular networks, in: GLOBECOM 2020 - 2020 IEEE Global
Communications Conference, 2020, pp. 1–6.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.1109/GLOBECOM42002.2020.9322159" title="" class="ltx_ref ltx_href"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.1109/GLOBECOM42002.2020.9322159</span></a>.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
M. H. ur Rehman, K. Salah, E. Damiani, D. Svetinovic, Towards blockchain-based
reputation-aware federated learning, in: IEEE INFOCOM 2020 - IEEE Conference
on Computer Communications Workshops (INFOCOM WKSHPS), 2020, pp. 183–188.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.1109/INFOCOMWKSHPS50562.2020.9163027" title="" class="ltx_ref ltx_href"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.1109/INFOCOMWKSHPS50562.2020.9163027</span></a>.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://www.usenix.org/conference/usenixsecurity22/presentation/fu-chong" title="" class="ltx_ref ltx_href">Label
inference attacks against vertical federated learning</a>, in: 31st USENIX
Security Symposium (USENIX Security 22), USENIX Association, Boston, MA,
2022.

<br class="ltx_break">URL <a target="_blank" href="https://www.usenix.org/conference/usenixsecurity22/presentation/fu-chong" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.usenix.org/conference/usenixsecurity22/presentation/fu-chong</a>

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
Y. Gu, Y. Bai, S. Xu,
<a target="_blank" href="https://www.sciencedirect.com/science/article/pii/S2214212622000801" title="" class="ltx_ref ltx_href">Cs-mia:
Membership inference attack based on prediction confidence series in
federated learning</a>, Journal of Information Security and Applications 67
(2022) 103201.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/https://doi.org/10.1016/j.jisa.2022.103201" title="" class="ltx_ref ltx_href"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:https://doi.org/10.1016/j.jisa.2022.103201</span></a>.

<br class="ltx_break">URL <a target="_blank" href="https://www.sciencedirect.com/science/article/pii/S2214212622000801" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.sciencedirect.com/science/article/pii/S2214212622000801</a>

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
F. Sattler, S. Wiedemann, K.-R. Müller, W. Samek, Robust and
communication-efficient federated learning from non-i.i.d. data, IEEE
Transactions on Neural Networks and Learning Systems 31 (9) (2020)
3400–3413.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.1109/TNNLS.2019.2944481" title="" class="ltx_ref ltx_href"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.1109/TNNLS.2019.2944481</span></a>.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
L. WANG, W. WANG, B. LI, Cmfl: Mitigating communication overhead for federated
learning, in: 2019 IEEE 39th International Conference on Distributed
Computing Systems (ICDCS), 2019, pp. 954–964.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.1109/ICDCS.2019.00099" title="" class="ltx_ref ltx_href"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.1109/ICDCS.2019.00099</span></a>.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
L. Liu, J. Zhang, S. Song, K. B. Letaief, Client-edge-cloud hierarchical
federated learning, in: ICC 2020 - 2020 IEEE International Conference on
Communications (ICC), 2020, pp. 1–6.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.1109/ICC40277.2020.9148862" title="" class="ltx_ref ltx_href"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.1109/ICC40277.2020.9148862</span></a>.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
B. Luo, X. Li, S. Wang, J. Huang, L. Tassiulas, Cost-effective federated
learning design, in: IEEE INFOCOM 2021 - IEEE Conference on Computer
Communications, 2021, pp. 1–10.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.1109/INFOCOM42981.2021.9488679" title="" class="ltx_ref ltx_href"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.1109/INFOCOM42981.2021.9488679</span></a>.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
Z. Yang, M. Chen, W. Saad, C. S. Hong, M. Shikh-Bahaei, Energy efficient
federated learning over wireless communication networks, IEEE Transactions on
Wireless Communications 20 (3) (2021) 1935–1949.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.1109/TWC.2020.3037554" title="" class="ltx_ref ltx_href"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.1109/TWC.2020.3037554</span></a>.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
Q. Zeng, Y. Du, K. Huang, K. K. Leung,
<a target="_blank" href="https://arxiv.org/abs/2007.07122" title="" class="ltx_ref ltx_href">Energy-efficient resource management
for federated edge learning with CPU-GPU heterogeneous computing</a>, CoRR
abs/2007.07122 (2020).

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2007.07122" title="" class="ltx_ref ltx_href"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">arXiv:2007.07122</span></a>.

<br class="ltx_break">URL <a target="_blank" href="https://arxiv.org/abs/2007.07122" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/abs/2007.07122</a>

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
S. Abdulrahman, H. Tout, A. Mourad, C. Talhi, Fedmccs: Multicriteria client
selection model for optimal iot federated learning, IEEE Internet of Things
Journal 8 (6) (2021) 4723–4735.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.1109/JIOT.2020.3028742" title="" class="ltx_ref ltx_href"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.1109/JIOT.2020.3028742</span></a>.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
H. Wang, Z. Kaplan, D. Niu, B. Li, Optimizing federated learning on non-iid
data with reinforcement learning, in: IEEE INFOCOM 2020 - IEEE Conference on
Computer Communications, 2020, pp. 1698–1707.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.1109/INFOCOM41043.2020.9155494" title="" class="ltx_ref ltx_href"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.1109/INFOCOM41043.2020.9155494</span></a>.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
Y. Zhan, P. Li, Z. Qu, D. Zeng, S. Guo, A learning-based incentive mechanism
for federated learning, IEEE Internet of Things Journal 7 (7) (2020)
6360–6368.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.1109/JIOT.2020.2967772" title="" class="ltx_ref ltx_href"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.1109/JIOT.2020.2967772</span></a>.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
A. Hammoud, H. Otrok, A. Mourad, Z. Dziong, On demand fog federations for
horizontal federated learning in iov, IEEE Transactions on Network and
Service Management (2022) 1–1<a target="_blank" href="https://doi.org/10.1109/TNSM.2022.3172370" title="" class="ltx_ref ltx_href"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.1109/TNSM.2022.3172370</span></a>.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
D. C. Nguyen, M. Ding, Q.-V. Pham, P. N. Pathirana, L. B. Le, A. Seneviratne,
J. Li, D. Niyato, H. V. Poor, Federated learning meets blockchain in edge
computing: Opportunities and challenges, IEEE Internet of Things Journal
8 (16) (2021) 12806–12825.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.1109/JIOT.2021.3072611" title="" class="ltx_ref ltx_href"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.1109/JIOT.2021.3072611</span></a>.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
H. Kim, J. Park, M. Bennis, S.-L. Kim, Blockchained on-device federated
learning, IEEE Communications Letters 24 (6) (2020) 1279–1283.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.1109/LCOMM.2019.2921755" title="" class="ltx_ref ltx_href"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.1109/LCOMM.2019.2921755</span></a>.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
S. R. Pokhrel, J. Choi, Federated learning with blockchain for autonomous
vehicles: Analysis and design challenges, IEEE Transactions on Communications
68 (8) (2020) 4734–4746.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.1109/TCOMM.2020.2990686" title="" class="ltx_ref ltx_href"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.1109/TCOMM.2020.2990686</span></a>.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock">
M. Abadi, A. Agarwal, P. Barham, E. Brevdo, Z. Chen, C. Citro, G. S. Corrado,
A. Davis, J. Dean, M. Devin, S. Ghemawat, I. Goodfellow, A. Harp, G. Irving,
M. Isard, Y. Jia, R. Jozefowicz, L. Kaiser, M. Kudlur, J. Levenberg,
D. Mané, R. Monga, S. Moore, D. Murray, C. Olah, M. Schuster, J. Shlens,
B. Steiner, I. Sutskever, K. Talwar, P. Tucker, V. Vanhoucke, V. Vasudevan,
F. Viégas, O. Vinyals, P. Warden, M. Wattenberg, M. Wicke, Y. Yu,
X. Zheng, <a target="_blank" href="https://www.tensorflow.org/" title="" class="ltx_ref ltx_href">TensorFlow: Large-scale
machine learning on heterogeneous systems</a>, software available from
tensorflow.org (2015).

<br class="ltx_break">URL <a target="_blank" href="https://www.tensorflow.org/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.tensorflow.org/</a>

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock">
F. Haddadpour, M. M. Kamani, A. Mokhtari, M. Mahdavi, Federated learning with
compression: Unified analysis and sharp guarantees, arXiv preprint
arXiv:2007.01154 (2020).

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock">
C. He, S. Li, J. So, M. Zhang, H. Wang, X. Wang, P. Vepakomma, A. Singh,
H. Qiu, L. Shen, P. Zhao, Y. Kang, Y. Liu, R. Raskar, Q. Yang, M. Annavaram,
S. Avestimehr, <a target="_blank" href="https://arxiv.org/abs/2007.13518" title="" class="ltx_ref ltx_href">Fedml: A research
library and benchmark for federated machine learning</a>, CoRR abs/2007.13518
(2020).

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2007.13518" title="" class="ltx_ref ltx_href"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">arXiv:2007.13518</span></a>.

<br class="ltx_break">URL <a target="_blank" href="https://arxiv.org/abs/2007.13518" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/abs/2007.13518</a>

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock">
I. Kholod, E. Yanaki, D. Fomichev, E. Shalugin, E. Novikova, E. Filippov,
M. Nordlund, Open-source federated learning frameworks for iot: A comparative
review and analysis, Sensors 21 (1) (2020) 167.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock">
H. Ludwig, N. Baracaldo, G. Thomas, Y. Zhou, A. Anwar, S. Rajamoni, Y. Ong,
J. Radhakrishnan, A. Verma, M. Sinn, et al., Ibm federated learning: an
enterprise framework white paper v0. 1, arXiv preprint arXiv:2007.10987
(2020).

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock">
T. Nishio, R. Yonetani, Client selection for federated learning with
heterogeneous resources in mobile edge, in: ICC 2019-2019 IEEE international
conference on communications (ICC), IEEE, 2019, pp. 1–7.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock">
L. Biewald, <a target="_blank" href="https://www.wandb.com/" title="" class="ltx_ref ltx_href">Experiment tracking with weights and
biases</a>, software available from wandb.com (2020).

<br class="ltx_break">URL <a target="_blank" href="https://www.wandb.com/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.wandb.com/</a>

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Biographies</h2>

<figure id="Sx1.1" class="ltx_figure ltx_align_floatright"><img src="/html/2212.10427/assets/ma.jpg" id="Sx1.1.g1" class="ltx_graphics ltx_img_square" width="113" height="132" alt="[Uncaptioned image]">
</figure>
<div id="Sx1.p1" class="ltx_para ltx_noindent">
<p id="Sx1.p1.1" class="ltx_p"><span id="Sx1.p1.1.1" class="ltx_text ltx_font_bold">Mohamad Arafeh</span></p>
</div>
<div id="Sx1.p2" class="ltx_para ltx_noindent">
<p id="Sx1.p2.1" class="ltx_p">Is currently pursuing the Ph.D. degree with École de Technologie Supérieure, Montreal, QC, Canada. He is working in the area of federated learning.
<br class="ltx_break">
<br class="ltx_break">
<br class="ltx_break">
<br class="ltx_break"></p>
</div>
<figure id="Sx1.2" class="ltx_figure ltx_align_floatright"><img src="/html/2212.10427/assets/ho.jpg" id="Sx1.2.g1" class="ltx_graphics ltx_img_portrait" width="75" height="113" alt="[Uncaptioned image]">
</figure>
<div id="Sx1.p3" class="ltx_para ltx_noindent">
<p id="Sx1.p3.1" class="ltx_p"><span id="Sx1.p3.1.1" class="ltx_text ltx_font_bold">Hadi Otrok</span></p>
</div>
<div id="Sx1.p4" class="ltx_para ltx_noindent">
<p id="Sx1.p4.1" class="ltx_p">Received the Ph.D. degree in computer science and software engineering from Laval University, Canada, in 2005. He is a Professor with Concordia Institute for Information Systems Engineering, Concordia University, Canada. From 2005 to 2006, he was a Postdoctoral Fellow with Laval University, and then NSERC Postdoctoral Fellow at Simon Fraser University, Canada. He is an NSERC Co-Chair for Discovery Grant for Computer Science (2016-2018). His research interests include the areas of computational logics, model checking, multi-agent systems, services computing, game theory, and deep learning.</p>
</div>
<figure id="Sx1.3" class="ltx_figure ltx_align_floatright"><img src="/html/2212.10427/assets/hos.png" id="Sx1.3.g1" class="ltx_graphics ltx_img_square" width="75" height="83" alt="[Uncaptioned image]">
</figure>
<div id="Sx1.p5" class="ltx_para ltx_noindent">
<p id="Sx1.p5.1" class="ltx_p"><span id="Sx1.p5.1.1" class="ltx_text ltx_font_bold">Hakima Ould-Slimane</span></p>
</div>
<div id="Sx1.p6" class="ltx_para ltx_noindent">
<p id="Sx1.p6.1" class="ltx_p">Obtained her Ph.D. degree in Computer Science from Laval University, Quebec, Canada. She is currently a professor at the department of mathematics and computer science at Universite de Quebec a Trois-Rivieres (UQTR, Trois-Rivieres, Canada). Her research interests include mainly: information security, cyber resilience, homomorphic encryption, federated learning, preserving data privacy in smart environments, machine learning based intrusion detection, access control, optimization of security mechanisms and security of social networks.</p>
</div>
<figure id="Sx1.4" class="ltx_figure ltx_align_floatright"><img src="/html/2212.10427/assets/am.png" id="Sx1.4.g1" class="ltx_graphics ltx_img_portrait" width="94" height="118" alt="[Uncaptioned image]">
</figure>
<div id="Sx1.p7" class="ltx_para ltx_noindent">
<p id="Sx1.p7.1" class="ltx_p"><span id="Sx1.p7.1.1" class="ltx_text ltx_font_bold">Azzam Mourad</span></p>
</div>
<div id="Sx1.p8" class="ltx_para ltx_noindent">
<p id="Sx1.p8.1" class="ltx_p">Received his M.Sc. in CS from Laval University, Canada (2003) and Ph.D. in ECE from Concordia University, Canada (2008). He is currently Professor of Computer Science and Founding Director of the Cyber Security Systems and Applied AI Research Center with the Lebanese American University, Visiting Professor of Computer Science with New York University Abu Dhabi and Affiliate Professor with the Software Engineering and IT Department, Ecole de Technologie Superieure (ETS), Montreal, Canada. His research interests include Cyber Security, Federated Machine Learning, Network and Service Optimization and Management targeting IoT and IoV, Cloud/Fog/Edge Computing, and Vehicular and Mobile Networks. He has served/serves as an associate editor for IEEE Transactions on Services Computing, IEEE Transactions on Network and Service Management, IEEE Network, IEEE Open Journal of the Communications Society, IET Quantum Communication, and IEEE Communications Letters, the General Chair of IWCMC2020, the General Co-Chair of WiMob2016, and the Track Chair, a TPC member, and a reviewer for several prestigious journals and conferences. He is an IEEE senior member.</p>
</div>
<figure id="Sx1.5" class="ltx_figure ltx_align_floatright"><img src="/html/2212.10427/assets/ct.png" id="Sx1.5.g1" class="ltx_graphics ltx_img_portrait" width="90" height="113" alt="[Uncaptioned image]">
</figure>
<div id="Sx1.p9" class="ltx_para ltx_noindent">
<p id="Sx1.p9.1" class="ltx_p"><span id="Sx1.p9.1.1" class="ltx_text ltx_font_bold">Chamseddine Talhi</span></p>
</div>
<div id="Sx1.p10" class="ltx_para ltx_noindent">
<p id="Sx1.p10.1" class="ltx_p">Received the Ph.D. degree in computer science from Laval University, Quebec, QC, Canada, in 2007. He is a Professor with the Department of Software Engineering and IT, ÉTS, University of Quebec, Montreal, QC, Canada. He is leading a research group that investigates smartphone, embedded systems, and IoT security. His research interests include cloud security and secure sharing of embedded systems.</p>
</div>
<figure id="Sx1.6" class="ltx_figure ltx_align_floatright"><img src="/html/2212.10427/assets/ed.png" id="Sx1.6.g1" class="ltx_graphics ltx_img_portrait" width="105" height="132" alt="[Uncaptioned image]">
</figure>
<div id="Sx1.p11" class="ltx_para ltx_noindent">
<p id="Sx1.p11.1" class="ltx_p"><span id="Sx1.p11.1.1" class="ltx_text ltx_font_bold">Ernesto Damiani</span></p>
</div>
<div id="Sx1.p12" class="ltx_para ltx_noindent">
<p id="Sx1.p12.1" class="ltx_p">is currently a Full Professor at the Department of Computer Science, Universita degli Studi di Milano, where he leads the Secure Service-oriented Architectures Research (SESAR) Laboratory. He is also the Founding Director of the Center for Cyber–Physical Systems, Khalifa University, United Arab Emirates. He received an Honorary Doctorate from Institute National des Sciences Appliquees de Lyon, France, in 2017, for his contributions to research and teaching on big data analytics. He is the Principal Investigator of the H2020 TOREADOR project on Big Data as a Service. He serves as Editor in Chief for IEEE Transactions on Services Computing. His research interests include cyber-security, big data, and cloud/edge processing, and he has published over 600 peer-reviewed articles and books. He is a Distinguished Scientist of ACM and was a recipient of the 2017 Stephen Yau Award.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2212.10426" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2212.10427" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2212.10427">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2212.10427" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2212.10428" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Fri Mar  1 10:16:53 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
