<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2312.09039] TAP4LLM: Table Provider on Sampling, Augmenting, and Packing Semi-structured Data for Large Language Model Reasoning</title><meta property="og:description" content="Table reasoning has shown remarkable progress in a wide range of table-based tasks. These challenging tasks require reasoning over both free-form natural language (NL) questions and semi-structured tabular data. Howeve…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="TAP4LLM: Table Provider on Sampling, Augmenting, and Packing Semi-structured Data for Large Language Model Reasoning">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="TAP4LLM: Table Provider on Sampling, Augmenting, and Packing Semi-structured Data for Large Language Model Reasoning">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2312.09039">

<!--Generated on Tue Feb 27 14:12:03 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line ltx_leqno">
<h1 class="ltx_title ltx_title_document">TAP4LLM: Table Provider on Sampling, Augmenting, and Packing Semi-structured Data for Large Language Model Reasoning</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Yuan Sui
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id2.1.id1" class="ltx_text ltx_affiliation_institution">National University of Singapore</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:yuan.sui@u.nus.edu">yuan.sui@u.nus.edu</a>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Jiaru Zou
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id3.1.id1" class="ltx_text ltx_affiliation_institution">University of Illinois Urbana-Champaign</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:jiaruz2@illinois.edu">jiaruz2@illinois.edu</a>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Mengyu Zhou
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id4.1.id1" class="ltx_text ltx_affiliation_institution">Microsoft</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:mezho@microsoft.com">mezho@microsoft.com</a>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Xinyi He
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id5.1.id1" class="ltx_text ltx_affiliation_institution">Xi’an Jiaotong University</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:hxyhxy@stu.xjtu.edu.cn">hxyhxy@stu.xjtu.edu.cn</a>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Lun Du
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id6.1.id1" class="ltx_text ltx_affiliation_institution">Microsoft</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:lun.du@microsoft.com">lun.du@microsoft.com</a>
</span></span></span>
<span class="ltx_author_before"> and </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Shi Han, Dongmei Zhang
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id7.1.id1" class="ltx_text ltx_affiliation_institution">Microsoft</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:shihan,%20dongmeiz@microsoft.com">shihan, dongmeiz@microsoft.com</a>
</span></span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract.</h6>
<p id="id8.id1" class="ltx_p">Table reasoning has shown remarkable progress in a wide range of table-based tasks. These challenging tasks require reasoning over both free-form natural language (NL) questions and semi-structured tabular data. However, previous table reasoning solutions suffer from significant performance degradation on “huge” tables. In addition, most existing methods struggle to reason over complex questions since they lack essential information or they are scattered in different places.
To alleviate these challenges, we exploit a table provider, namely TAP4LLM, on versatile sampling, augmentation, and packing methods to achieve effective semi-structured data reasoning using large language models (LLMs), which 1) decompose raw tables into sub-tables with specific rows/columns based on the rules or semantic similarity; 2) augment table information by extracting semantic and statistical metadata from raw tables while retrieving relevant knowledge from trustworthy knowledge sources (e.g., Wolfram Alpha, Wikipedia); 3) pack sampled tables with augmented knowledge into sequence prompts for LLMs reasoning while balancing the token allocation trade-off. We show that TAP4LLM allows for different components as plug-ins, enhancing LLMs’ understanding of structured data in diverse tabular tasks.
</p>
</div>
<div id="p1" class="ltx_para ltx_noindent">
<p id="p1.1" class="ltx_p"><span id="p1.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">xxx Reference Format:
<br class="ltx_break"></span><span id="p1.1.2" class="ltx_text" style="font-size:90%;">  xxx, 14(1): XXX-XXX, 2024.</span>
<br class="ltx_break"><a target="_blank" href="https://doi.org/XX.XX/XXX.XX" title="" class="ltx_ref ltx_href" style="font-size:90%;">doi:XX.XX/XXX.XX</a><span id="p1.1.3" class="ltx_text" style="font-size:90%;">
</span><span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark"></sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark"></sup><span class="ltx_tag ltx_tag_note"></span>This work is licensed under the Creative Commons BY-NC-ND 4.0 International License. Visit <a target="_blank" href="https://creativecommons.org/licenses/by-nc-nd/4.0/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://creativecommons.org/licenses/by-nc-nd/4.0/</a> to view a copy of this license. For any use beyond those covered by this license, obtain permission by emailing <a href="mailto:info@xx.org" title="" class="ltx_ref ltx_href">info@xx.org</a>. Copyright is held by the owner/author(s). Publication rights licensed to the xx Endowment. 
<br class="ltx_break">Proceedings of the xx Endowment, Vol. 14, No. 1 ISSN 2150-8097. 
<br class="ltx_break"><a target="_blank" href="https://doi.org/XX.XX/XXX.XX" title="" class="ltx_ref ltx_href">doi:XX.XX/XXX.XX</a> 
<br class="ltx_break"></span></span></span></p>
</div>
<div id="p2" class="ltx_para ltx_noindent">
<p id="p2.1" class="ltx_p"><span id="p2.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">xxx Artifact Availability:
<br class="ltx_break"></span><span id="p2.1.2" class="ltx_text" style="font-size:90%;">The source code, data, and/or other artifacts have been made available at </span><a href="%leave%20empty%20if%20no%20availability%20url%20should%20be%20sethttps://anonymous.4open.science/r/TableProvider-4CC3" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:90%;">%leave␣empty␣if␣no␣availability␣url␣should␣be␣sethttps://anonymous.4open.science/r/TableProvider-4CC3</a><span id="p2.1.3" class="ltx_text" style="font-size:90%;">.
</span><span id="p2.1.4" class="ltx_text"></span></p>
</div>
<figure id="S0.F1" class="ltx_figure"><img src="/html/2312.09039/assets/x1.png" id="S0.F1.g1" class="ltx_graphics ltx_centering ltx_img_square" width="461" height="562" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1. </span>Demonstration of the Three TAP4LLM Modules.
<br class="ltx_break">(1) Table sampling: sample most relevant content. (2) Table augmentation: retrieve and add extra information. (3) Table packing: serialize the sampled table and augmented information into a string while controlling the token allocation.</figcaption>
</figure>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1. </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">The extensive and complex characteristics of data are commonly represented in the format of structured data. It makes the data more manageable and facilitates data analysis and processing by machines.
<span id="S1.p1.1.1" class="ltx_text ltx_font_bold">Table</span> is one of those fundamental and widely used semi-structured data types in relational databases, spreadsheet applications, and programming languages that handle data for various domains, including financial analysis <cite class="ltx_cite ltx_citemacro_citep">(Zhang et al<span class="ltx_text">.</span>, <a href="#bib.bib70" title="" class="ltx_ref">2020</a>; Li et al<span class="ltx_text">.</span>, <a href="#bib.bib39" title="" class="ltx_ref">2022</a>)</cite>, risk management <cite class="ltx_cite ltx_citemacro_citep">(Babaev et al<span class="ltx_text">.</span>, <a href="#bib.bib5" title="" class="ltx_ref">2019</a>)</cite>, healthcare analytics <cite class="ltx_cite ltx_citemacro_citep">(Vamathevan et al<span class="ltx_text">.</span>, <a href="#bib.bib58" title="" class="ltx_ref">2019</a>)</cite>, <span id="S1.p1.1.2" class="ltx_text ltx_font_italic">etc</span>.
Reasoning over tabular data is a fundamental aspect of natural language understanding (NLU) and information retrieval (IR), and has several downstream tasks, such as Table-based Question Answering (TQA) <cite class="ltx_cite ltx_citemacro_citep">(Chen et al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2020b</a>; Iyyer et al<span class="ltx_text">.</span>, <a href="#bib.bib30" title="" class="ltx_ref">2017</a>; Ye et al<span class="ltx_text">.</span>, <a href="#bib.bib65" title="" class="ltx_ref">2023</a>; Cheng et al<span class="ltx_text">.</span>, <a href="#bib.bib12" title="" class="ltx_ref">2023</a>)</cite>, Table-based Fact Verification (TFV) <cite class="ltx_cite ltx_citemacro_citep">(Chen et al<span class="ltx_text">.</span>, <a href="#bib.bib9" title="" class="ltx_ref">2020a</a>; Xie et al<span class="ltx_text">.</span>, <a href="#bib.bib64" title="" class="ltx_ref">2022</a>; Günther et al<span class="ltx_text">.</span>, <a href="#bib.bib18" title="" class="ltx_ref">2021</a>)</cite>, Table-to-Text <cite class="ltx_cite ltx_citemacro_citep">(Wang et al<span class="ltx_text">.</span>, <a href="#bib.bib61" title="" class="ltx_ref">2021a</a>)</cite>, Text-to-SQL <cite class="ltx_cite ltx_citemacro_citep">(Yu et al<span class="ltx_text">.</span>, <a href="#bib.bib67" title="" class="ltx_ref">2018</a>)</cite>, Column Type &amp; Relation Classification <cite class="ltx_cite ltx_citemacro_citep">(Iida et al<span class="ltx_text">.</span>, <a href="#bib.bib28" title="" class="ltx_ref">2021</a>; Deng et al<span class="ltx_text">.</span>, <a href="#bib.bib13" title="" class="ltx_ref">2020</a>)</cite>,<span id="S1.p1.1.3" class="ltx_text ltx_font_italic">etc</span>.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">In the field of natural and programming language understanding and generation, LLMs (large language models) have demonstrated impressive abilities as few-shot reasoners with prompt engineering and in-context learning <cite class="ltx_cite ltx_citemacro_citep">(Kojima et al<span class="ltx_text">.</span>, <a href="#bib.bib34" title="" class="ltx_ref">2022a</a>, <a href="#bib.bib35" title="" class="ltx_ref">b</a>)</cite>. Their capacity to generate human-like text and human-level code <cite class="ltx_cite ltx_citemacro_citep">(Cheng et al<span class="ltx_text">.</span>, <a href="#bib.bib12" title="" class="ltx_ref">2023</a>; Ye et al<span class="ltx_text">.</span>, <a href="#bib.bib65" title="" class="ltx_ref">2023</a>; Gemmell and Dalton, <a href="#bib.bib15" title="" class="ltx_ref">2023</a>)</cite> has opened up new possibilities for reasoning over tabular data <cite class="ltx_cite ltx_citemacro_citep">(Chen, <a href="#bib.bib8" title="" class="ltx_ref">2022</a>; Gong et al<span class="ltx_text">.</span>, <a href="#bib.bib16" title="" class="ltx_ref">2020</a>)</cite>. However, it is non-trivial to directly utilize vanilla LLMs such as GPT <cite class="ltx_cite ltx_citemacro_citep">(Liu et al<span class="ltx_text">.</span>, <a href="#bib.bib41" title="" class="ltx_ref">2023</a>)</cite> to consume tables as their prompt inputs.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">First, which part of a table should be kept in the prompt? The full content of a table could be very long and noisy to be included in the prompt.
Most LLMs have a limited input context window size (<span id="S1.p3.1.1" class="ltx_text ltx_font_italic">e.g.</span>, 4k tokens) in which an overlong table cannot fit. For long tables that satisfy the length constraint, it can still lead to unnecessary computations (of LLM on long prompt) and quality regressions (generation interfered by noisy input) when placing irrelevant table content (<span id="S1.p3.1.2" class="ltx_text ltx_font_italic">w.r.t.</span> the task or query) in the prompt.
To address the challenge, some table sampling methods were proposed in ad-hoc ways. For example, truncating the input tables to contain only the first 22 rows and 8 columns <cite class="ltx_cite ltx_citemacro_citep">(Chen, <a href="#bib.bib8" title="" class="ltx_ref">2022</a>)</cite>, or filtering relevant rows based on <math id="S1.p3.1.m1.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S1.p3.1.m1.1a"><mi id="S1.p3.1.m1.1.1" xref="S1.p3.1.m1.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S1.p3.1.m1.1b"><ci id="S1.p3.1.m1.1.1.cmml" xref="S1.p3.1.m1.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.p3.1.m1.1c">n</annotation></semantics></math>-gram overlap between them and the utterance <cite class="ltx_cite ltx_citemacro_citep">(Yin et al<span class="ltx_text">.</span>, <a href="#bib.bib66" title="" class="ltx_ref">2020</a>)</cite>.
To answer the question of which part to keep, we need a more systematic study of different grounding and sampling algorithms.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">Second, what additional/external knowledge could help LLMs better understand a table?
The raw content of a table may contain ambiguous information (<span id="S1.p4.1.1" class="ltx_text ltx_font_italic">e.g.</span>, abbreviations, domain-specific terms, column type,<span id="S1.p4.1.2" class="ltx_text ltx_font_italic">etc</span>.) that requires further interpretation and clarification. As a result, direct reasoning on the raw tables may lead to misinterpretation and bias in the LLMs’ outputs. To address this, some augmentation techniques were proposed to incorporate structured knowledge <cite class="ltx_cite ltx_citemacro_citep">(Sui et al<span class="ltx_text">.</span>, <a href="#bib.bib55" title="" class="ltx_ref">2023</a>; Xie et al<span class="ltx_text">.</span>, <a href="#bib.bib64" title="" class="ltx_ref">2022</a>)</cite>, common sense knowledge <cite class="ltx_cite ltx_citemacro_citep">(Bian et al<span class="ltx_text">.</span>, <a href="#bib.bib6" title="" class="ltx_ref">2023</a>; Ogundare and Araya, <a href="#bib.bib45" title="" class="ltx_ref">2023</a>; Shen et al<span class="ltx_text">.</span>, <a href="#bib.bib53" title="" class="ltx_ref">2023</a>; Guo et al<span class="ltx_text">.</span>, <a href="#bib.bib19" title="" class="ltx_ref">2023</a>)</cite>, and analytical knowledge <cite class="ltx_cite ltx_citemacro_citep">(Jena et al<span class="ltx_text">.</span>, <a href="#bib.bib31" title="" class="ltx_ref">2022</a>; He et al<span class="ltx_text">.</span>, <a href="#bib.bib20" title="" class="ltx_ref">2023</a>)</cite> into pre-training and inference processes.
For example, <cite class="ltx_cite ltx_citemacro_citep">(Jena et al<span class="ltx_text">.</span>, <a href="#bib.bib31" title="" class="ltx_ref">2022</a>)</cite> transforms existing tabular data to create diverse natural language inference instances for better zero-shot performance.
<cite class="ltx_cite ltx_citemacro_citep">(He et al<span class="ltx_text">.</span>, <a href="#bib.bib20" title="" class="ltx_ref">2023</a>)</cite> infers implicit metadata behind raw table content through field distribution and knowledge graph information.
However, the techniques were proposed independently and there lack of comprehensive study that compares them and tries to combine them to provide useful and diverse knowledge and thoughts for LLMs.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">Third, how do we encode the table into a prompt? While sampling and grounding compress the table content, augmentation expands the prompt by adding more information. With a given token budget, one needs to find the balance to allocate available tokens between table content and augmented knowledge. Furthermore, the serialization format of the table also plays a critical role. It not only influences how well an LLM understands the table input (as discussed in our previous study  <cite class="ltx_cite ltx_citemacro_citep">(Sui et al<span class="ltx_text">.</span>, <a href="#bib.bib55" title="" class="ltx_ref">2023</a>)</cite>), but also determines the string length of the serialized table and the augmented information.
For example, as discussed in <cite class="ltx_cite ltx_citemacro_citep">(Sui et al<span class="ltx_text">.</span>, <a href="#bib.bib55" title="" class="ltx_ref">2023</a>)</cite>, table formats such as HTML <cite class="ltx_cite ltx_citemacro_citep">(Aghajanyan et al<span class="ltx_text">.</span>, <a href="#bib.bib4" title="" class="ltx_ref">2021</a>)</cite> or XML are better understood by GPT models, but they also lead to increased token consumption. To pack a table into the prompt, these problems should be addressed with trade-offs.</p>
</div>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.6" class="ltx_p">In this paper, we propose <span id="S1.p6.6.1" class="ltx_text ltx_font_bold">TAP4LLM</span> (table provider for large language models) as a versatile pre-processing toolbox to generate table prompts in LLM reasoning. TAP4LLM addresses the above challenges with three corresponding modules
(i) <span id="S1.p6.6.2" class="ltx_text ltx_framed ltx_framed_underline">Table Sampling</span>: Selecting a sub-table <math id="S1.p6.1.m1.1" class="ltx_Math" alttext="T^{\prime}" display="inline"><semantics id="S1.p6.1.m1.1a"><msup id="S1.p6.1.m1.1.1" xref="S1.p6.1.m1.1.1.cmml"><mi id="S1.p6.1.m1.1.1.2" xref="S1.p6.1.m1.1.1.2.cmml">T</mi><mo id="S1.p6.1.m1.1.1.3" xref="S1.p6.1.m1.1.1.3.cmml">′</mo></msup><annotation-xml encoding="MathML-Content" id="S1.p6.1.m1.1b"><apply id="S1.p6.1.m1.1.1.cmml" xref="S1.p6.1.m1.1.1"><csymbol cd="ambiguous" id="S1.p6.1.m1.1.1.1.cmml" xref="S1.p6.1.m1.1.1">superscript</csymbol><ci id="S1.p6.1.m1.1.1.2.cmml" xref="S1.p6.1.m1.1.1.2">𝑇</ci><ci id="S1.p6.1.m1.1.1.3.cmml" xref="S1.p6.1.m1.1.1.3">′</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.p6.1.m1.1c">T^{\prime}</annotation></semantics></math> from the raw table <math id="S1.p6.2.m2.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S1.p6.2.m2.1a"><mi id="S1.p6.2.m2.1.1" xref="S1.p6.2.m2.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S1.p6.2.m2.1b"><ci id="S1.p6.2.m2.1.1.cmml" xref="S1.p6.2.m2.1.1">𝑇</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.p6.2.m2.1c">T</annotation></semantics></math> based on the rules or semantics of the query or utterance <math id="S1.p6.3.m3.1" class="ltx_Math" alttext="Q" display="inline"><semantics id="S1.p6.3.m3.1a"><mi id="S1.p6.3.m3.1.1" xref="S1.p6.3.m3.1.1.cmml">Q</mi><annotation-xml encoding="MathML-Content" id="S1.p6.3.m3.1b"><ci id="S1.p6.3.m3.1.1.cmml" xref="S1.p6.3.m3.1.1">𝑄</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.p6.3.m3.1c">Q</annotation></semantics></math>;
(ii) <span id="S1.p6.6.3" class="ltx_text ltx_framed ltx_framed_underline">Table Augmentation</span>: Enhancing <math id="S1.p6.4.m4.1" class="ltx_Math" alttext="T^{\prime}" display="inline"><semantics id="S1.p6.4.m4.1a"><msup id="S1.p6.4.m4.1.1" xref="S1.p6.4.m4.1.1.cmml"><mi id="S1.p6.4.m4.1.1.2" xref="S1.p6.4.m4.1.1.2.cmml">T</mi><mo id="S1.p6.4.m4.1.1.3" xref="S1.p6.4.m4.1.1.3.cmml">′</mo></msup><annotation-xml encoding="MathML-Content" id="S1.p6.4.m4.1b"><apply id="S1.p6.4.m4.1.1.cmml" xref="S1.p6.4.m4.1.1"><csymbol cd="ambiguous" id="S1.p6.4.m4.1.1.1.cmml" xref="S1.p6.4.m4.1.1">superscript</csymbol><ci id="S1.p6.4.m4.1.1.2.cmml" xref="S1.p6.4.m4.1.1.2">𝑇</ci><ci id="S1.p6.4.m4.1.1.3.cmml" xref="S1.p6.4.m4.1.1.3">′</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.p6.4.m4.1c">T^{\prime}</annotation></semantics></math> by integrating relevant external knowledge, metadata, and attributes based on the raw Table <math id="S1.p6.5.m5.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S1.p6.5.m5.1a"><mi id="S1.p6.5.m5.1.1" xref="S1.p6.5.m5.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S1.p6.5.m5.1b"><ci id="S1.p6.5.m5.1.1.cmml" xref="S1.p6.5.m5.1.1">𝑇</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.p6.5.m5.1c">T</annotation></semantics></math>; and
(iii) <span id="S1.p6.6.4" class="ltx_text ltx_framed ltx_framed_underline">Table Packing</span>: Packing the sampled table <math id="S1.p6.6.m6.1" class="ltx_Math" alttext="T^{\prime}" display="inline"><semantics id="S1.p6.6.m6.1a"><msup id="S1.p6.6.m6.1.1" xref="S1.p6.6.m6.1.1.cmml"><mi id="S1.p6.6.m6.1.1.2" xref="S1.p6.6.m6.1.1.2.cmml">T</mi><mo id="S1.p6.6.m6.1.1.3" xref="S1.p6.6.m6.1.1.3.cmml">′</mo></msup><annotation-xml encoding="MathML-Content" id="S1.p6.6.m6.1b"><apply id="S1.p6.6.m6.1.1.cmml" xref="S1.p6.6.m6.1.1"><csymbol cd="ambiguous" id="S1.p6.6.m6.1.1.1.cmml" xref="S1.p6.6.m6.1.1">superscript</csymbol><ci id="S1.p6.6.m6.1.1.2.cmml" xref="S1.p6.6.m6.1.1.2">𝑇</ci><ci id="S1.p6.6.m6.1.1.3.cmml" xref="S1.p6.6.m6.1.1.3">′</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.p6.6.m6.1c">T^{\prime}</annotation></semantics></math> with the augmented knowledge into a sequence with a specified serialization format for LLMs while balancing the token allocation trade-off.
In each module, we collect and design many different methods for usage in various scenarios (<span id="S1.p6.6.5" class="ltx_text ltx_font_italic">e.g.</span>, speed over accuracy).
Across six distinct datasets, our findings demonstrate that TAP4LLM significantly improves accuracy by achieving an average enhancement of 6.02% through the table sampling module, 3.29% through the table augmentation module, and 1.38% through the table packing module. Collectively, TAP4LLM elevates accuracy by an average of 7.93% when compared to the direct input of raw tables into LLMs..
Our exploration has led us to conclude that TAP4LLM enhances the interaction between LLMs and tabular data by employing effective pre-processing.
</p>
</div>
<div id="S1.p7" class="ltx_para">
<p id="S1.p7.1" class="ltx_p">In addition, through multiple empirical studies, we develop a comprehensive guideline for the effective utilization of TAP4LLM. Our investigation reveals that the optimal performance of sampling is achieved through the query-based method. We then conducted evaluations on augmentation methods and proposed the most suitable combination of sampling and augmentation for each dataset. Ablation studies are also conducted on token allocation to identify trade-offs between model performance and resource usage.</p>
</div>
<div id="S1.p8" class="ltx_para">
<p id="S1.p8.1" class="ltx_p">In summary, our main contributions are:</p>
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">We proposed a unified pre-processor TAP4LLM to improve the effectiveness of LLMs in tabular reasoning tasks. Our framework includes three modules: table sampling, table augmentation, and table packing.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">We conducted a comprehensive survey to evaluate the effectiveness of TAP4LLM. Through various sampling, augmentation, and packing methods, TAP4LLM achieves an average of improved performance by 7.93%. We also assessed the effectiveness of different configurations inside TAP4LLM, including embedding types and statistical features.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p">We formulated a comprehensive usage guideline for our framework TAP4LLM. First, we identify the optimal combination of methods within TAP4LLM for different usage scenarios. Second, we provide a trade-off map between performance metrics and token allocation.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2. </span>Preliminaries</h2>

<figure id="S2.F2" class="ltx_figure"><img src="/html/2312.09039/assets/x2.png" id="S2.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="127" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2. </span>TAP4LLM Framework for Tabular Data. Noted that the “table sync” refers to the application (such as Excel Copilot) keeps its table data in sync with the table manager. The table manager acts as an intermediary, managing the data that is either stored locally in a cache or accessed through a database connection. This syncing process is crucial for “interactive table reasoning” and for maintaining data integrity. The implication of this syncing process is further discussed in §<a href="#S5" title="5. Implementation Details ‣ TAP4LLM: Table Provider on Sampling, Augmenting, and Packing Semi-structured Data for Large Language Model Reasoning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>.</figcaption>
</figure>
<div id="S2.p1" class="ltx_para">
<p id="S2.p1.18" class="ltx_p"><span id="S2.p1.18.1" class="ltx_text ltx_font_bold">Table Reasoning Tasks</span>.
Each instance in table-based reasoning consists of a table <math id="S2.p1.1.m1.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S2.p1.1.m1.1a"><mi id="S2.p1.1.m1.1.1" xref="S2.p1.1.m1.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S2.p1.1.m1.1b"><ci id="S2.p1.1.m1.1.1.cmml" xref="S2.p1.1.m1.1.1">𝑇</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.1.m1.1c">T</annotation></semantics></math>, a natural language question <math id="S2.p1.2.m2.1" class="ltx_Math" alttext="Q" display="inline"><semantics id="S2.p1.2.m2.1a"><mi id="S2.p1.2.m2.1.1" xref="S2.p1.2.m2.1.1.cmml">Q</mi><annotation-xml encoding="MathML-Content" id="S2.p1.2.m2.1b"><ci id="S2.p1.2.m2.1.1.cmml" xref="S2.p1.2.m2.1.1">𝑄</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.2.m2.1c">Q</annotation></semantics></math>, and an answer <math id="S2.p1.3.m3.1" class="ltx_Math" alttext="A" display="inline"><semantics id="S2.p1.3.m3.1a"><mi id="S2.p1.3.m3.1.1" xref="S2.p1.3.m3.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S2.p1.3.m3.1b"><ci id="S2.p1.3.m3.1.1.cmml" xref="S2.p1.3.m3.1.1">𝐴</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.3.m3.1c">A</annotation></semantics></math>. Specifically, table <math id="S2.p1.4.m4.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S2.p1.4.m4.1a"><mi id="S2.p1.4.m4.1.1" xref="S2.p1.4.m4.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S2.p1.4.m4.1b"><ci id="S2.p1.4.m4.1.1.cmml" xref="S2.p1.4.m4.1.1">𝑇</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.4.m4.1c">T</annotation></semantics></math> is defined as <math id="S2.p1.5.m5.4" class="ltx_Math" alttext="T=\left\{v_{i,j}\mid i\leq\operatorname{R}_{T},j\leq\operatorname{C}_{T}\right\}" display="inline"><semantics id="S2.p1.5.m5.4a"><mrow id="S2.p1.5.m5.4.4" xref="S2.p1.5.m5.4.4.cmml"><mi id="S2.p1.5.m5.4.4.4" xref="S2.p1.5.m5.4.4.4.cmml">T</mi><mo id="S2.p1.5.m5.4.4.3" xref="S2.p1.5.m5.4.4.3.cmml">=</mo><mrow id="S2.p1.5.m5.4.4.2.2" xref="S2.p1.5.m5.4.4.2.3.cmml"><mo id="S2.p1.5.m5.4.4.2.2.3" xref="S2.p1.5.m5.4.4.2.3.1.cmml">{</mo><msub id="S2.p1.5.m5.3.3.1.1.1" xref="S2.p1.5.m5.3.3.1.1.1.cmml"><mi id="S2.p1.5.m5.3.3.1.1.1.2" xref="S2.p1.5.m5.3.3.1.1.1.2.cmml">v</mi><mrow id="S2.p1.5.m5.2.2.2.4" xref="S2.p1.5.m5.2.2.2.3.cmml"><mi id="S2.p1.5.m5.1.1.1.1" xref="S2.p1.5.m5.1.1.1.1.cmml">i</mi><mo id="S2.p1.5.m5.2.2.2.4.1" xref="S2.p1.5.m5.2.2.2.3.cmml">,</mo><mi id="S2.p1.5.m5.2.2.2.2" xref="S2.p1.5.m5.2.2.2.2.cmml">j</mi></mrow></msub><mo fence="true" lspace="0em" rspace="0em" id="S2.p1.5.m5.4.4.2.2.4" xref="S2.p1.5.m5.4.4.2.3.1.cmml">∣</mo><mrow id="S2.p1.5.m5.4.4.2.2.2.2" xref="S2.p1.5.m5.4.4.2.2.2.3.cmml"><mrow id="S2.p1.5.m5.4.4.2.2.2.1.1" xref="S2.p1.5.m5.4.4.2.2.2.1.1.cmml"><mi id="S2.p1.5.m5.4.4.2.2.2.1.1.2" xref="S2.p1.5.m5.4.4.2.2.2.1.1.2.cmml">i</mi><mo id="S2.p1.5.m5.4.4.2.2.2.1.1.1" xref="S2.p1.5.m5.4.4.2.2.2.1.1.1.cmml">≤</mo><msub id="S2.p1.5.m5.4.4.2.2.2.1.1.3" xref="S2.p1.5.m5.4.4.2.2.2.1.1.3.cmml"><mi mathvariant="normal" id="S2.p1.5.m5.4.4.2.2.2.1.1.3.2" xref="S2.p1.5.m5.4.4.2.2.2.1.1.3.2.cmml">R</mi><mi id="S2.p1.5.m5.4.4.2.2.2.1.1.3.3" xref="S2.p1.5.m5.4.4.2.2.2.1.1.3.3.cmml">T</mi></msub></mrow><mo id="S2.p1.5.m5.4.4.2.2.2.2.3" xref="S2.p1.5.m5.4.4.2.2.2.3a.cmml">,</mo><mrow id="S2.p1.5.m5.4.4.2.2.2.2.2" xref="S2.p1.5.m5.4.4.2.2.2.2.2.cmml"><mi id="S2.p1.5.m5.4.4.2.2.2.2.2.2" xref="S2.p1.5.m5.4.4.2.2.2.2.2.2.cmml">j</mi><mo id="S2.p1.5.m5.4.4.2.2.2.2.2.1" xref="S2.p1.5.m5.4.4.2.2.2.2.2.1.cmml">≤</mo><msub id="S2.p1.5.m5.4.4.2.2.2.2.2.3" xref="S2.p1.5.m5.4.4.2.2.2.2.2.3.cmml"><mi mathvariant="normal" id="S2.p1.5.m5.4.4.2.2.2.2.2.3.2" xref="S2.p1.5.m5.4.4.2.2.2.2.2.3.2.cmml">C</mi><mi id="S2.p1.5.m5.4.4.2.2.2.2.2.3.3" xref="S2.p1.5.m5.4.4.2.2.2.2.2.3.3.cmml">T</mi></msub></mrow></mrow><mo id="S2.p1.5.m5.4.4.2.2.5" xref="S2.p1.5.m5.4.4.2.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.p1.5.m5.4b"><apply id="S2.p1.5.m5.4.4.cmml" xref="S2.p1.5.m5.4.4"><eq id="S2.p1.5.m5.4.4.3.cmml" xref="S2.p1.5.m5.4.4.3"></eq><ci id="S2.p1.5.m5.4.4.4.cmml" xref="S2.p1.5.m5.4.4.4">𝑇</ci><apply id="S2.p1.5.m5.4.4.2.3.cmml" xref="S2.p1.5.m5.4.4.2.2"><csymbol cd="latexml" id="S2.p1.5.m5.4.4.2.3.1.cmml" xref="S2.p1.5.m5.4.4.2.2.3">conditional-set</csymbol><apply id="S2.p1.5.m5.3.3.1.1.1.cmml" xref="S2.p1.5.m5.3.3.1.1.1"><csymbol cd="ambiguous" id="S2.p1.5.m5.3.3.1.1.1.1.cmml" xref="S2.p1.5.m5.3.3.1.1.1">subscript</csymbol><ci id="S2.p1.5.m5.3.3.1.1.1.2.cmml" xref="S2.p1.5.m5.3.3.1.1.1.2">𝑣</ci><list id="S2.p1.5.m5.2.2.2.3.cmml" xref="S2.p1.5.m5.2.2.2.4"><ci id="S2.p1.5.m5.1.1.1.1.cmml" xref="S2.p1.5.m5.1.1.1.1">𝑖</ci><ci id="S2.p1.5.m5.2.2.2.2.cmml" xref="S2.p1.5.m5.2.2.2.2">𝑗</ci></list></apply><apply id="S2.p1.5.m5.4.4.2.2.2.3.cmml" xref="S2.p1.5.m5.4.4.2.2.2.2"><csymbol cd="ambiguous" id="S2.p1.5.m5.4.4.2.2.2.3a.cmml" xref="S2.p1.5.m5.4.4.2.2.2.2.3">formulae-sequence</csymbol><apply id="S2.p1.5.m5.4.4.2.2.2.1.1.cmml" xref="S2.p1.5.m5.4.4.2.2.2.1.1"><leq id="S2.p1.5.m5.4.4.2.2.2.1.1.1.cmml" xref="S2.p1.5.m5.4.4.2.2.2.1.1.1"></leq><ci id="S2.p1.5.m5.4.4.2.2.2.1.1.2.cmml" xref="S2.p1.5.m5.4.4.2.2.2.1.1.2">𝑖</ci><apply id="S2.p1.5.m5.4.4.2.2.2.1.1.3.cmml" xref="S2.p1.5.m5.4.4.2.2.2.1.1.3"><csymbol cd="ambiguous" id="S2.p1.5.m5.4.4.2.2.2.1.1.3.1.cmml" xref="S2.p1.5.m5.4.4.2.2.2.1.1.3">subscript</csymbol><ci id="S2.p1.5.m5.4.4.2.2.2.1.1.3.2.cmml" xref="S2.p1.5.m5.4.4.2.2.2.1.1.3.2">R</ci><ci id="S2.p1.5.m5.4.4.2.2.2.1.1.3.3.cmml" xref="S2.p1.5.m5.4.4.2.2.2.1.1.3.3">𝑇</ci></apply></apply><apply id="S2.p1.5.m5.4.4.2.2.2.2.2.cmml" xref="S2.p1.5.m5.4.4.2.2.2.2.2"><leq id="S2.p1.5.m5.4.4.2.2.2.2.2.1.cmml" xref="S2.p1.5.m5.4.4.2.2.2.2.2.1"></leq><ci id="S2.p1.5.m5.4.4.2.2.2.2.2.2.cmml" xref="S2.p1.5.m5.4.4.2.2.2.2.2.2">𝑗</ci><apply id="S2.p1.5.m5.4.4.2.2.2.2.2.3.cmml" xref="S2.p1.5.m5.4.4.2.2.2.2.2.3"><csymbol cd="ambiguous" id="S2.p1.5.m5.4.4.2.2.2.2.2.3.1.cmml" xref="S2.p1.5.m5.4.4.2.2.2.2.2.3">subscript</csymbol><ci id="S2.p1.5.m5.4.4.2.2.2.2.2.3.2.cmml" xref="S2.p1.5.m5.4.4.2.2.2.2.2.3.2">C</ci><ci id="S2.p1.5.m5.4.4.2.2.2.2.2.3.3.cmml" xref="S2.p1.5.m5.4.4.2.2.2.2.2.3.3">𝑇</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.5.m5.4c">T=\left\{v_{i,j}\mid i\leq\operatorname{R}_{T},j\leq\operatorname{C}_{T}\right\}</annotation></semantics></math>, containing <math id="S2.p1.6.m6.1" class="ltx_Math" alttext="R_{T}" display="inline"><semantics id="S2.p1.6.m6.1a"><msub id="S2.p1.6.m6.1.1" xref="S2.p1.6.m6.1.1.cmml"><mi id="S2.p1.6.m6.1.1.2" xref="S2.p1.6.m6.1.1.2.cmml">R</mi><mi id="S2.p1.6.m6.1.1.3" xref="S2.p1.6.m6.1.1.3.cmml">T</mi></msub><annotation-xml encoding="MathML-Content" id="S2.p1.6.m6.1b"><apply id="S2.p1.6.m6.1.1.cmml" xref="S2.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S2.p1.6.m6.1.1.1.cmml" xref="S2.p1.6.m6.1.1">subscript</csymbol><ci id="S2.p1.6.m6.1.1.2.cmml" xref="S2.p1.6.m6.1.1.2">𝑅</ci><ci id="S2.p1.6.m6.1.1.3.cmml" xref="S2.p1.6.m6.1.1.3">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.6.m6.1c">R_{T}</annotation></semantics></math> rows and <math id="S2.p1.7.m7.1" class="ltx_Math" alttext="C_{T}" display="inline"><semantics id="S2.p1.7.m7.1a"><msub id="S2.p1.7.m7.1.1" xref="S2.p1.7.m7.1.1.cmml"><mi id="S2.p1.7.m7.1.1.2" xref="S2.p1.7.m7.1.1.2.cmml">C</mi><mi id="S2.p1.7.m7.1.1.3" xref="S2.p1.7.m7.1.1.3.cmml">T</mi></msub><annotation-xml encoding="MathML-Content" id="S2.p1.7.m7.1b"><apply id="S2.p1.7.m7.1.1.cmml" xref="S2.p1.7.m7.1.1"><csymbol cd="ambiguous" id="S2.p1.7.m7.1.1.1.cmml" xref="S2.p1.7.m7.1.1">subscript</csymbol><ci id="S2.p1.7.m7.1.1.2.cmml" xref="S2.p1.7.m7.1.1.2">𝐶</ci><ci id="S2.p1.7.m7.1.1.3.cmml" xref="S2.p1.7.m7.1.1.3">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.7.m7.1c">C_{T}</annotation></semantics></math> columns. The content of the cell in the <math id="S2.p1.8.m8.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S2.p1.8.m8.1a"><mi id="S2.p1.8.m8.1.1" xref="S2.p1.8.m8.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S2.p1.8.m8.1b"><ci id="S2.p1.8.m8.1.1.cmml" xref="S2.p1.8.m8.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.8.m8.1c">i</annotation></semantics></math>-th row and <math id="S2.p1.9.m9.1" class="ltx_Math" alttext="j" display="inline"><semantics id="S2.p1.9.m9.1a"><mi id="S2.p1.9.m9.1.1" xref="S2.p1.9.m9.1.1.cmml">j</mi><annotation-xml encoding="MathML-Content" id="S2.p1.9.m9.1b"><ci id="S2.p1.9.m9.1.1.cmml" xref="S2.p1.9.m9.1.1">𝑗</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.9.m9.1c">j</annotation></semantics></math>-th column is represented by <math id="S2.p1.10.m10.2" class="ltx_Math" alttext="v{i,j}" display="inline"><semantics id="S2.p1.10.m10.2a"><mrow id="S2.p1.10.m10.2.2.1" xref="S2.p1.10.m10.2.2.2.cmml"><mrow id="S2.p1.10.m10.2.2.1.1" xref="S2.p1.10.m10.2.2.1.1.cmml"><mi id="S2.p1.10.m10.2.2.1.1.2" xref="S2.p1.10.m10.2.2.1.1.2.cmml">v</mi><mo lspace="0em" rspace="0em" id="S2.p1.10.m10.2.2.1.1.1" xref="S2.p1.10.m10.2.2.1.1.1.cmml">​</mo><mi id="S2.p1.10.m10.2.2.1.1.3" xref="S2.p1.10.m10.2.2.1.1.3.cmml">i</mi></mrow><mo id="S2.p1.10.m10.2.2.1.2" xref="S2.p1.10.m10.2.2.2.cmml">,</mo><mi id="S2.p1.10.m10.1.1" xref="S2.p1.10.m10.1.1.cmml">j</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.p1.10.m10.2b"><list id="S2.p1.10.m10.2.2.2.cmml" xref="S2.p1.10.m10.2.2.1"><apply id="S2.p1.10.m10.2.2.1.1.cmml" xref="S2.p1.10.m10.2.2.1.1"><times id="S2.p1.10.m10.2.2.1.1.1.cmml" xref="S2.p1.10.m10.2.2.1.1.1"></times><ci id="S2.p1.10.m10.2.2.1.1.2.cmml" xref="S2.p1.10.m10.2.2.1.1.2">𝑣</ci><ci id="S2.p1.10.m10.2.2.1.1.3.cmml" xref="S2.p1.10.m10.2.2.1.1.3">𝑖</ci></apply><ci id="S2.p1.10.m10.1.1.cmml" xref="S2.p1.10.m10.1.1">𝑗</ci></list></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.10.m10.2c">v{i,j}</annotation></semantics></math>. A question <math id="S2.p1.11.m11.1" class="ltx_Math" alttext="Q" display="inline"><semantics id="S2.p1.11.m11.1a"><mi id="S2.p1.11.m11.1.1" xref="S2.p1.11.m11.1.1.cmml">Q</mi><annotation-xml encoding="MathML-Content" id="S2.p1.11.m11.1b"><ci id="S2.p1.11.m11.1.1.cmml" xref="S2.p1.11.m11.1.1">𝑄</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.11.m11.1c">Q</annotation></semantics></math> is a sequence of <math id="S2.p1.12.m12.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S2.p1.12.m12.1a"><mi id="S2.p1.12.m12.1.1" xref="S2.p1.12.m12.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S2.p1.12.m12.1b"><ci id="S2.p1.12.m12.1.1.cmml" xref="S2.p1.12.m12.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.12.m12.1c">n</annotation></semantics></math> tokens: <math id="S2.p1.13.m13.5" class="ltx_Math" alttext="Q=\{q_{1},q_{2},q_{3},\cdots,q_{n}\}" display="inline"><semantics id="S2.p1.13.m13.5a"><mrow id="S2.p1.13.m13.5.5" xref="S2.p1.13.m13.5.5.cmml"><mi id="S2.p1.13.m13.5.5.6" xref="S2.p1.13.m13.5.5.6.cmml">Q</mi><mo id="S2.p1.13.m13.5.5.5" xref="S2.p1.13.m13.5.5.5.cmml">=</mo><mrow id="S2.p1.13.m13.5.5.4.4" xref="S2.p1.13.m13.5.5.4.5.cmml"><mo stretchy="false" id="S2.p1.13.m13.5.5.4.4.5" xref="S2.p1.13.m13.5.5.4.5.cmml">{</mo><msub id="S2.p1.13.m13.2.2.1.1.1" xref="S2.p1.13.m13.2.2.1.1.1.cmml"><mi id="S2.p1.13.m13.2.2.1.1.1.2" xref="S2.p1.13.m13.2.2.1.1.1.2.cmml">q</mi><mn id="S2.p1.13.m13.2.2.1.1.1.3" xref="S2.p1.13.m13.2.2.1.1.1.3.cmml">1</mn></msub><mo id="S2.p1.13.m13.5.5.4.4.6" xref="S2.p1.13.m13.5.5.4.5.cmml">,</mo><msub id="S2.p1.13.m13.3.3.2.2.2" xref="S2.p1.13.m13.3.3.2.2.2.cmml"><mi id="S2.p1.13.m13.3.3.2.2.2.2" xref="S2.p1.13.m13.3.3.2.2.2.2.cmml">q</mi><mn id="S2.p1.13.m13.3.3.2.2.2.3" xref="S2.p1.13.m13.3.3.2.2.2.3.cmml">2</mn></msub><mo id="S2.p1.13.m13.5.5.4.4.7" xref="S2.p1.13.m13.5.5.4.5.cmml">,</mo><msub id="S2.p1.13.m13.4.4.3.3.3" xref="S2.p1.13.m13.4.4.3.3.3.cmml"><mi id="S2.p1.13.m13.4.4.3.3.3.2" xref="S2.p1.13.m13.4.4.3.3.3.2.cmml">q</mi><mn id="S2.p1.13.m13.4.4.3.3.3.3" xref="S2.p1.13.m13.4.4.3.3.3.3.cmml">3</mn></msub><mo id="S2.p1.13.m13.5.5.4.4.8" xref="S2.p1.13.m13.5.5.4.5.cmml">,</mo><mi mathvariant="normal" id="S2.p1.13.m13.1.1" xref="S2.p1.13.m13.1.1.cmml">⋯</mi><mo id="S2.p1.13.m13.5.5.4.4.9" xref="S2.p1.13.m13.5.5.4.5.cmml">,</mo><msub id="S2.p1.13.m13.5.5.4.4.4" xref="S2.p1.13.m13.5.5.4.4.4.cmml"><mi id="S2.p1.13.m13.5.5.4.4.4.2" xref="S2.p1.13.m13.5.5.4.4.4.2.cmml">q</mi><mi id="S2.p1.13.m13.5.5.4.4.4.3" xref="S2.p1.13.m13.5.5.4.4.4.3.cmml">n</mi></msub><mo stretchy="false" id="S2.p1.13.m13.5.5.4.4.10" xref="S2.p1.13.m13.5.5.4.5.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.p1.13.m13.5b"><apply id="S2.p1.13.m13.5.5.cmml" xref="S2.p1.13.m13.5.5"><eq id="S2.p1.13.m13.5.5.5.cmml" xref="S2.p1.13.m13.5.5.5"></eq><ci id="S2.p1.13.m13.5.5.6.cmml" xref="S2.p1.13.m13.5.5.6">𝑄</ci><set id="S2.p1.13.m13.5.5.4.5.cmml" xref="S2.p1.13.m13.5.5.4.4"><apply id="S2.p1.13.m13.2.2.1.1.1.cmml" xref="S2.p1.13.m13.2.2.1.1.1"><csymbol cd="ambiguous" id="S2.p1.13.m13.2.2.1.1.1.1.cmml" xref="S2.p1.13.m13.2.2.1.1.1">subscript</csymbol><ci id="S2.p1.13.m13.2.2.1.1.1.2.cmml" xref="S2.p1.13.m13.2.2.1.1.1.2">𝑞</ci><cn type="integer" id="S2.p1.13.m13.2.2.1.1.1.3.cmml" xref="S2.p1.13.m13.2.2.1.1.1.3">1</cn></apply><apply id="S2.p1.13.m13.3.3.2.2.2.cmml" xref="S2.p1.13.m13.3.3.2.2.2"><csymbol cd="ambiguous" id="S2.p1.13.m13.3.3.2.2.2.1.cmml" xref="S2.p1.13.m13.3.3.2.2.2">subscript</csymbol><ci id="S2.p1.13.m13.3.3.2.2.2.2.cmml" xref="S2.p1.13.m13.3.3.2.2.2.2">𝑞</ci><cn type="integer" id="S2.p1.13.m13.3.3.2.2.2.3.cmml" xref="S2.p1.13.m13.3.3.2.2.2.3">2</cn></apply><apply id="S2.p1.13.m13.4.4.3.3.3.cmml" xref="S2.p1.13.m13.4.4.3.3.3"><csymbol cd="ambiguous" id="S2.p1.13.m13.4.4.3.3.3.1.cmml" xref="S2.p1.13.m13.4.4.3.3.3">subscript</csymbol><ci id="S2.p1.13.m13.4.4.3.3.3.2.cmml" xref="S2.p1.13.m13.4.4.3.3.3.2">𝑞</ci><cn type="integer" id="S2.p1.13.m13.4.4.3.3.3.3.cmml" xref="S2.p1.13.m13.4.4.3.3.3.3">3</cn></apply><ci id="S2.p1.13.m13.1.1.cmml" xref="S2.p1.13.m13.1.1">⋯</ci><apply id="S2.p1.13.m13.5.5.4.4.4.cmml" xref="S2.p1.13.m13.5.5.4.4.4"><csymbol cd="ambiguous" id="S2.p1.13.m13.5.5.4.4.4.1.cmml" xref="S2.p1.13.m13.5.5.4.4.4">subscript</csymbol><ci id="S2.p1.13.m13.5.5.4.4.4.2.cmml" xref="S2.p1.13.m13.5.5.4.4.4.2">𝑞</ci><ci id="S2.p1.13.m13.5.5.4.4.4.3.cmml" xref="S2.p1.13.m13.5.5.4.4.4.3">𝑛</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.13.m13.5c">Q=\{q_{1},q_{2},q_{3},\cdots,q_{n}\}</annotation></semantics></math>.
In this paper, our primary focus is on two distinct table-based reasoning tasks, table-based fact verification (TFV) and table-based question answering (TQA). In TFV, the answer <math id="S2.p1.14.m14.1" class="ltx_Math" alttext="A" display="inline"><semantics id="S2.p1.14.m14.1a"><mi id="S2.p1.14.m14.1.1" xref="S2.p1.14.m14.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S2.p1.14.m14.1b"><ci id="S2.p1.14.m14.1.1.cmml" xref="S2.p1.14.m14.1.1">𝐴</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.14.m14.1c">A</annotation></semantics></math> is a boolean value in <math id="S2.p1.15.m15.2" class="ltx_Math" alttext="\{0,1\}" display="inline"><semantics id="S2.p1.15.m15.2a"><mrow id="S2.p1.15.m15.2.3.2" xref="S2.p1.15.m15.2.3.1.cmml"><mo stretchy="false" id="S2.p1.15.m15.2.3.2.1" xref="S2.p1.15.m15.2.3.1.cmml">{</mo><mn id="S2.p1.15.m15.1.1" xref="S2.p1.15.m15.1.1.cmml">0</mn><mo id="S2.p1.15.m15.2.3.2.2" xref="S2.p1.15.m15.2.3.1.cmml">,</mo><mn id="S2.p1.15.m15.2.2" xref="S2.p1.15.m15.2.2.cmml">1</mn><mo stretchy="false" id="S2.p1.15.m15.2.3.2.3" xref="S2.p1.15.m15.2.3.1.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.p1.15.m15.2b"><set id="S2.p1.15.m15.2.3.1.cmml" xref="S2.p1.15.m15.2.3.2"><cn type="integer" id="S2.p1.15.m15.1.1.cmml" xref="S2.p1.15.m15.1.1">0</cn><cn type="integer" id="S2.p1.15.m15.2.2.cmml" xref="S2.p1.15.m15.2.2">1</cn></set></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.15.m15.2c">\{0,1\}</annotation></semantics></math>, indicating the veracity of the input statement (where <math id="S2.p1.16.m16.1" class="ltx_Math" alttext="1" display="inline"><semantics id="S2.p1.16.m16.1a"><mn id="S2.p1.16.m16.1.1" xref="S2.p1.16.m16.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="S2.p1.16.m16.1b"><cn type="integer" id="S2.p1.16.m16.1.1.cmml" xref="S2.p1.16.m16.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.16.m16.1c">1</annotation></semantics></math> means the statement is entailed by the given table, and <math id="S2.p1.17.m17.1" class="ltx_Math" alttext="0" display="inline"><semantics id="S2.p1.17.m17.1a"><mn id="S2.p1.17.m17.1.1" xref="S2.p1.17.m17.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="S2.p1.17.m17.1b"><cn type="integer" id="S2.p1.17.m17.1.1.cmml" xref="S2.p1.17.m17.1.1">0</cn></annotation-xml></semantics></math> means the statement is refuted by the given table). In TQA, the answer is a sequence of natural language tokens represented as <math id="S2.p1.18.m18.5" class="ltx_Math" alttext="A=\{a_{1},a_{2},a_{3},\cdots,a_{n}\}" display="inline"><semantics id="S2.p1.18.m18.5a"><mrow id="S2.p1.18.m18.5.5" xref="S2.p1.18.m18.5.5.cmml"><mi id="S2.p1.18.m18.5.5.6" xref="S2.p1.18.m18.5.5.6.cmml">A</mi><mo id="S2.p1.18.m18.5.5.5" xref="S2.p1.18.m18.5.5.5.cmml">=</mo><mrow id="S2.p1.18.m18.5.5.4.4" xref="S2.p1.18.m18.5.5.4.5.cmml"><mo stretchy="false" id="S2.p1.18.m18.5.5.4.4.5" xref="S2.p1.18.m18.5.5.4.5.cmml">{</mo><msub id="S2.p1.18.m18.2.2.1.1.1" xref="S2.p1.18.m18.2.2.1.1.1.cmml"><mi id="S2.p1.18.m18.2.2.1.1.1.2" xref="S2.p1.18.m18.2.2.1.1.1.2.cmml">a</mi><mn id="S2.p1.18.m18.2.2.1.1.1.3" xref="S2.p1.18.m18.2.2.1.1.1.3.cmml">1</mn></msub><mo id="S2.p1.18.m18.5.5.4.4.6" xref="S2.p1.18.m18.5.5.4.5.cmml">,</mo><msub id="S2.p1.18.m18.3.3.2.2.2" xref="S2.p1.18.m18.3.3.2.2.2.cmml"><mi id="S2.p1.18.m18.3.3.2.2.2.2" xref="S2.p1.18.m18.3.3.2.2.2.2.cmml">a</mi><mn id="S2.p1.18.m18.3.3.2.2.2.3" xref="S2.p1.18.m18.3.3.2.2.2.3.cmml">2</mn></msub><mo id="S2.p1.18.m18.5.5.4.4.7" xref="S2.p1.18.m18.5.5.4.5.cmml">,</mo><msub id="S2.p1.18.m18.4.4.3.3.3" xref="S2.p1.18.m18.4.4.3.3.3.cmml"><mi id="S2.p1.18.m18.4.4.3.3.3.2" xref="S2.p1.18.m18.4.4.3.3.3.2.cmml">a</mi><mn id="S2.p1.18.m18.4.4.3.3.3.3" xref="S2.p1.18.m18.4.4.3.3.3.3.cmml">3</mn></msub><mo id="S2.p1.18.m18.5.5.4.4.8" xref="S2.p1.18.m18.5.5.4.5.cmml">,</mo><mi mathvariant="normal" id="S2.p1.18.m18.1.1" xref="S2.p1.18.m18.1.1.cmml">⋯</mi><mo id="S2.p1.18.m18.5.5.4.4.9" xref="S2.p1.18.m18.5.5.4.5.cmml">,</mo><msub id="S2.p1.18.m18.5.5.4.4.4" xref="S2.p1.18.m18.5.5.4.4.4.cmml"><mi id="S2.p1.18.m18.5.5.4.4.4.2" xref="S2.p1.18.m18.5.5.4.4.4.2.cmml">a</mi><mi id="S2.p1.18.m18.5.5.4.4.4.3" xref="S2.p1.18.m18.5.5.4.4.4.3.cmml">n</mi></msub><mo stretchy="false" id="S2.p1.18.m18.5.5.4.4.10" xref="S2.p1.18.m18.5.5.4.5.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.p1.18.m18.5b"><apply id="S2.p1.18.m18.5.5.cmml" xref="S2.p1.18.m18.5.5"><eq id="S2.p1.18.m18.5.5.5.cmml" xref="S2.p1.18.m18.5.5.5"></eq><ci id="S2.p1.18.m18.5.5.6.cmml" xref="S2.p1.18.m18.5.5.6">𝐴</ci><set id="S2.p1.18.m18.5.5.4.5.cmml" xref="S2.p1.18.m18.5.5.4.4"><apply id="S2.p1.18.m18.2.2.1.1.1.cmml" xref="S2.p1.18.m18.2.2.1.1.1"><csymbol cd="ambiguous" id="S2.p1.18.m18.2.2.1.1.1.1.cmml" xref="S2.p1.18.m18.2.2.1.1.1">subscript</csymbol><ci id="S2.p1.18.m18.2.2.1.1.1.2.cmml" xref="S2.p1.18.m18.2.2.1.1.1.2">𝑎</ci><cn type="integer" id="S2.p1.18.m18.2.2.1.1.1.3.cmml" xref="S2.p1.18.m18.2.2.1.1.1.3">1</cn></apply><apply id="S2.p1.18.m18.3.3.2.2.2.cmml" xref="S2.p1.18.m18.3.3.2.2.2"><csymbol cd="ambiguous" id="S2.p1.18.m18.3.3.2.2.2.1.cmml" xref="S2.p1.18.m18.3.3.2.2.2">subscript</csymbol><ci id="S2.p1.18.m18.3.3.2.2.2.2.cmml" xref="S2.p1.18.m18.3.3.2.2.2.2">𝑎</ci><cn type="integer" id="S2.p1.18.m18.3.3.2.2.2.3.cmml" xref="S2.p1.18.m18.3.3.2.2.2.3">2</cn></apply><apply id="S2.p1.18.m18.4.4.3.3.3.cmml" xref="S2.p1.18.m18.4.4.3.3.3"><csymbol cd="ambiguous" id="S2.p1.18.m18.4.4.3.3.3.1.cmml" xref="S2.p1.18.m18.4.4.3.3.3">subscript</csymbol><ci id="S2.p1.18.m18.4.4.3.3.3.2.cmml" xref="S2.p1.18.m18.4.4.3.3.3.2">𝑎</ci><cn type="integer" id="S2.p1.18.m18.4.4.3.3.3.3.cmml" xref="S2.p1.18.m18.4.4.3.3.3.3">3</cn></apply><ci id="S2.p1.18.m18.1.1.cmml" xref="S2.p1.18.m18.1.1">⋯</ci><apply id="S2.p1.18.m18.5.5.4.4.4.cmml" xref="S2.p1.18.m18.5.5.4.4.4"><csymbol cd="ambiguous" id="S2.p1.18.m18.5.5.4.4.4.1.cmml" xref="S2.p1.18.m18.5.5.4.4.4">subscript</csymbol><ci id="S2.p1.18.m18.5.5.4.4.4.2.cmml" xref="S2.p1.18.m18.5.5.4.4.4.2">𝑎</ci><ci id="S2.p1.18.m18.5.5.4.4.4.3.cmml" xref="S2.p1.18.m18.5.5.4.4.4.3">𝑛</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.18.m18.5c">A=\{a_{1},a_{2},a_{3},\cdots,a_{n}\}</annotation></semantics></math> corresponding to the posed question.
For our experiments, all tables first undergo table sampling and table augmentation by our proposed method and then are serialized into a sequence by table packing and serialization. Note that various serialization methods have already been explored in our previous work <cite class="ltx_cite ltx_citemacro_citep">(Sui et al<span class="ltx_text">.</span>, <a href="#bib.bib55" title="" class="ltx_ref">2023</a>)</cite>. Detailed implementation specifics are provided in Section §<a href="#S3.SS3" title="3.3. Table Packing ‣ 3. TAP4LLM: Table Provider for LLMs ‣ TAP4LLM: Table Provider on Sampling, Augmenting, and Packing Semi-structured Data for Large Language Model Reasoning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.3</span></a>.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p"><span id="S2.p2.1.1" class="ltx_text ltx_font_bold">Challenges with Long Sequences in LLMs</span>.
Most LLMs struggle with long sequences due to the quadratic complexity of self-attention mechanisms <cite class="ltx_cite ltx_citemacro_citep">(Vaswani et al<span class="ltx_text">.</span>, <a href="#bib.bib59" title="" class="ltx_ref">2017</a>; Tay et al<span class="ltx_text">.</span>, <a href="#bib.bib56" title="" class="ltx_ref">2022</a>)</cite>. It’s important to note that the maximum sequence length of commonly used LLMs, such as gpt-3.5-turbo-16k <cite class="ltx_cite ltx_citemacro_citep">(zot, <a href="#bib.bib3" title="" class="ltx_ref">[n.d.]</a>)</cite>, is limited to 16k tokens. This limit becomes especially problematic when dealing with structured data, which typically consists of various components and causes significant memory and computational challenges.
Solutions like Tapex <cite class="ltx_cite ltx_citemacro_citep">(Liu et al<span class="ltx_text">.</span>, <a href="#bib.bib40" title="" class="ltx_ref">2022</a>)</cite> and Tapas <cite class="ltx_cite ltx_citemacro_citep">(Herzig et al<span class="ltx_text">.</span>, <a href="#bib.bib21" title="" class="ltx_ref">2020</a>)</cite> utilize a simple truncation approach based on the table’s sequence length. However, these methods exhibit the shortcomings of excluding important data and disrupting the whole table structure.
In our work, we introduce specific constraints for the LLMs’ call requests. For example, to avoid structural disruptions from truncation, we use a <span id="S2.p2.1.2" class="ltx_text ltx_font_italic">“token allocation”</span> strategy to estimate the token capacity and initiate the sampling functions (explained in Section §<a href="#S3.SS1" title="3.1. Table Sampling ‣ 3. TAP4LLM: Table Provider for LLMs ‣ TAP4LLM: Table Provider on Sampling, Augmenting, and Packing Semi-structured Data for Large Language Model Reasoning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.1</span></a>) when the table’s token count surpasses a certain threshold.</p>
</div>
<div id="S2.p3" class="ltx_para">
<p id="S2.p3.1" class="ltx_p"><span id="S2.p3.1.1" class="ltx_text ltx_font_bold">Neuro-Symbolic Functions &amp; Metadata Analysis</span>.
Neuro-symbolic method is a specialized approach in Deep Learning (DL) that combines neural and symbolic methodologies <cite class="ltx_cite ltx_citemacro_citep">(Hitzler et al<span class="ltx_text">.</span>, <a href="#bib.bib22" title="" class="ltx_ref">2022</a>)</cite>.
In this work, we use Metadata Analysis <cite class="ltx_cite ltx_citemacro_citep">(He et al<span class="ltx_text">.</span>, <a href="#bib.bib20" title="" class="ltx_ref">2023</a>)</cite>, a neuro-symbolic method based on a transformer architecture <cite class="ltx_cite ltx_citemacro_citep">(Vaswani et al<span class="ltx_text">.</span>, <a href="#bib.bib59" title="" class="ltx_ref">2017</a>)</cite>, to generate metadata essential for table analysis.
Such metadata serves as an explicit representation of formally organized background knowledge. An example of this is the binary metadata classification for column types, known as dimension and measure<span id="footnote1a" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>A measure is a table field consisting of numerical data that you can calculate, such as ’Price’ and ’Discount’. Conversely, a dimension is a field that offers categorical information used for filtering, grouping, and labeling, such as the ’Product Name’ and ’Category’. It’s important to correctly classify fields as measures or dimensions because they dictate the operations you can perform on the data, affecting the accuracy and relevance of the analysis.</span></span></span>.
Furthermore, various LLM-centric toolsets have been developed to facilitate: (i) integration of LLMs with diverse data sources, and (ii) dynamic interactions of LLMs with their surroundings.
We select some of symbolic functions from the toolsets as our agents for table augmentation, including Langchain <cite class="ltx_cite ltx_citemacro_citep">(LangChain, <a href="#bib.bib36" title="" class="ltx_ref">2022</a>)</cite>, Semantic Kernel <cite class="ltx_cite ltx_citemacro_citep">(matthewbolanos, <a href="#bib.bib43" title="" class="ltx_ref">2023</a>)</cite>, <span id="S2.p3.1.2" class="ltx_text ltx_font_italic">etc</span>.</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3. </span>TAP4LLM: Table Provider for LLMs</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.2" class="ltx_p">The overall architecture of TAP4LLM is defined as follows (as illustrated in Figure <a href="#S2.F2" title="Figure 2 ‣ 2. Preliminaries ‣ TAP4LLM: Table Provider on Sampling, Augmenting, and Packing Semi-structured Data for Large Language Model Reasoning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>):
Given a natural language query/utterance <math id="S3.p1.1.m1.1" class="ltx_Math" alttext="Q" display="inline"><semantics id="S3.p1.1.m1.1a"><mi id="S3.p1.1.m1.1.1" xref="S3.p1.1.m1.1.1.cmml">Q</mi><annotation-xml encoding="MathML-Content" id="S3.p1.1.m1.1b"><ci id="S3.p1.1.m1.1.1.cmml" xref="S3.p1.1.m1.1.1">𝑄</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.1.m1.1c">Q</annotation></semantics></math> from applications (<span id="S3.p1.2.1" class="ltx_text ltx_font_italic">e.g.</span>, Excel Copilot) and a table <math id="S3.p1.2.m2.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S3.p1.2.m2.1a"><mi id="S3.p1.2.m2.1.1" xref="S3.p1.2.m2.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S3.p1.2.m2.1b"><ci id="S3.p1.2.m2.1.1.cmml" xref="S3.p1.2.m2.1.1">𝑇</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.2.m2.1c">T</annotation></semantics></math> from Table Manager (<span id="S3.p1.2.2" class="ltx_text ltx_font_italic">e.g.</span>, table cache or database connection), our system incorporates three core components as follows:</p>
<ul id="S3.I1" class="ltx_itemize">
<li id="S3.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i1.p1" class="ltx_para">
<p id="S3.I1.i1.p1.2" class="ltx_p"><span id="S3.I1.i1.p1.2.1" class="ltx_text ltx_font_bold">Table Sampling</span>: Decompose a large table <math id="S3.I1.i1.p1.1.m1.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S3.I1.i1.p1.1.m1.1a"><mi id="S3.I1.i1.p1.1.m1.1.1" xref="S3.I1.i1.p1.1.m1.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S3.I1.i1.p1.1.m1.1b"><ci id="S3.I1.i1.p1.1.m1.1.1.cmml" xref="S3.I1.i1.p1.1.m1.1.1">𝑇</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i1.p1.1.m1.1c">T</annotation></semantics></math> into a sub-table <math id="S3.I1.i1.p1.2.m2.1" class="ltx_Math" alttext="T^{\prime}" display="inline"><semantics id="S3.I1.i1.p1.2.m2.1a"><msup id="S3.I1.i1.p1.2.m2.1.1" xref="S3.I1.i1.p1.2.m2.1.1.cmml"><mi id="S3.I1.i1.p1.2.m2.1.1.2" xref="S3.I1.i1.p1.2.m2.1.1.2.cmml">T</mi><mo id="S3.I1.i1.p1.2.m2.1.1.3" xref="S3.I1.i1.p1.2.m2.1.1.3.cmml">′</mo></msup><annotation-xml encoding="MathML-Content" id="S3.I1.i1.p1.2.m2.1b"><apply id="S3.I1.i1.p1.2.m2.1.1.cmml" xref="S3.I1.i1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.I1.i1.p1.2.m2.1.1.1.cmml" xref="S3.I1.i1.p1.2.m2.1.1">superscript</csymbol><ci id="S3.I1.i1.p1.2.m2.1.1.2.cmml" xref="S3.I1.i1.p1.2.m2.1.1.2">𝑇</ci><ci id="S3.I1.i1.p1.2.m2.1.1.3.cmml" xref="S3.I1.i1.p1.2.m2.1.1.3">′</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i1.p1.2.m2.1c">T^{\prime}</annotation></semantics></math> with specific rows and columns.</p>
</div>
</li>
<li id="S3.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i2.p1" class="ltx_para">
<p id="S3.I1.i2.p1.1" class="ltx_p"><span id="S3.I1.i2.p1.1.1" class="ltx_text ltx_font_bold">Table Augmentation</span>: Explicitly incorporate relevant external knowledge, metadata, and attributes about the original table <math id="S3.I1.i2.p1.1.m1.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S3.I1.i2.p1.1.m1.1a"><mi id="S3.I1.i2.p1.1.m1.1.1" xref="S3.I1.i2.p1.1.m1.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S3.I1.i2.p1.1.m1.1b"><ci id="S3.I1.i2.p1.1.m1.1.1.cmml" xref="S3.I1.i2.p1.1.m1.1.1">𝑇</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i2.p1.1.m1.1c">T</annotation></semantics></math>.</p>
</div>
</li>
<li id="S3.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i3.p1" class="ltx_para">
<p id="S3.I1.i3.p1.1" class="ltx_p"><span id="S3.I1.i3.p1.1.1" class="ltx_text ltx_font_bold">Table Packing</span>: Control the token allocation for table sampling and table augmentation; Convert the structured table into a sequence (table serialization).</p>
</div>
</li>
</ul>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1. </span>Table Sampling</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">One of the primary challenges for reasoning over tabular data with LLMs is <span id="S3.SS1.p1.1.1" class="ltx_text ltx_font_italic">(1) token efficiency</span>. Due to the inherent structure of table(s), even a modest-sized table can quickly consume a significant portion of the available token budget of the LLMs.
While study<cite class="ltx_cite ltx_citemacro_citep">(Sui et al<span class="ltx_text">.</span>, <a href="#bib.bib55" title="" class="ltx_ref">2023</a>)</cite> shows that representing tables in formats like <span id="S3.SS1.p1.1.2" class="ltx_text ltx_font_italic">HTML</span> <cite class="ltx_cite ltx_citemacro_citep">(Aghajanyan et al<span class="ltx_text">.</span>, <a href="#bib.bib4" title="" class="ltx_ref">2021</a>)</cite> or <span id="S3.SS1.p1.1.3" class="ltx_text ltx_font_italic">XML</span> can improve the performance of GPT models, it also leads to increased token usage.
Furthermore, <span id="S3.SS1.p1.1.4" class="ltx_text ltx_font_italic">(2) noisy information</span> becomes an issue in large tables, especially those with over 30 rows, and becomes worse when the row count exceeds 60 <cite class="ltx_cite ltx_citemacro_citep">(Ye et al<span class="ltx_text">.</span>, <a href="#bib.bib65" title="" class="ltx_ref">2023</a>; Cheng et al<span class="ltx_text">.</span>, <a href="#bib.bib12" title="" class="ltx_ref">2023</a>)</cite>. Such noise can obscure the primary intent of a query, leading to potentially skewed or irrelevant model outputs.
Even with advancements like GPT-4<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>gpt-4-32k: maintains the same capabilities as standard GPT-4 mode but has a 4x context length, equating to 32,768 tokens. More details can be found at <a target="_blank" href="https://platform.openai.com/docs/models/gpt-4" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://platform.openai.com/docs/models/gpt-4</a>.</span></span></span>, which can handle up to 32k tokens, the challenges caused by noisy information remain <cite class="ltx_cite ltx_citemacro_citep">(Gemmell and Dalton, <a href="#bib.bib15" title="" class="ltx_ref">2023</a>)</cite>.
In this context, although more and more LLMs have been developed to handle longer sequences, the complexity of reasoning over tabular data highlights the need for sampling techniques. These approaches focus on the most relevant part of a table, providing a practical solution to bridge the gap between the nature of tables and the context boundaries of LLMs.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.10" class="ltx_p">In table sampling, a subset of top-ranked rows and columns is selected to form the sub-table. Specifically, given an original table <math id="S3.SS1.p2.1.m1.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S3.SS1.p2.1.m1.1a"><mi id="S3.SS1.p2.1.m1.1.1" xref="S3.SS1.p2.1.m1.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.1.m1.1b"><ci id="S3.SS1.p2.1.m1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1">𝑇</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.1.m1.1c">T</annotation></semantics></math> with a distinct set of rows <math id="S3.SS1.p2.2.m2.1" class="ltx_Math" alttext="R_{T}" display="inline"><semantics id="S3.SS1.p2.2.m2.1a"><msub id="S3.SS1.p2.2.m2.1.1" xref="S3.SS1.p2.2.m2.1.1.cmml"><mi id="S3.SS1.p2.2.m2.1.1.2" xref="S3.SS1.p2.2.m2.1.1.2.cmml">R</mi><mi id="S3.SS1.p2.2.m2.1.1.3" xref="S3.SS1.p2.2.m2.1.1.3.cmml">T</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.2.m2.1b"><apply id="S3.SS1.p2.2.m2.1.1.cmml" xref="S3.SS1.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.2.m2.1.1.1.cmml" xref="S3.SS1.p2.2.m2.1.1">subscript</csymbol><ci id="S3.SS1.p2.2.m2.1.1.2.cmml" xref="S3.SS1.p2.2.m2.1.1.2">𝑅</ci><ci id="S3.SS1.p2.2.m2.1.1.3.cmml" xref="S3.SS1.p2.2.m2.1.1.3">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.2.m2.1c">R_{T}</annotation></semantics></math>, columns <math id="S3.SS1.p2.3.m3.1" class="ltx_Math" alttext="C_{T}" display="inline"><semantics id="S3.SS1.p2.3.m3.1a"><msub id="S3.SS1.p2.3.m3.1.1" xref="S3.SS1.p2.3.m3.1.1.cmml"><mi id="S3.SS1.p2.3.m3.1.1.2" xref="S3.SS1.p2.3.m3.1.1.2.cmml">C</mi><mi id="S3.SS1.p2.3.m3.1.1.3" xref="S3.SS1.p2.3.m3.1.1.3.cmml">T</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.3.m3.1b"><apply id="S3.SS1.p2.3.m3.1.1.cmml" xref="S3.SS1.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.3.m3.1.1.1.cmml" xref="S3.SS1.p2.3.m3.1.1">subscript</csymbol><ci id="S3.SS1.p2.3.m3.1.1.2.cmml" xref="S3.SS1.p2.3.m3.1.1.2">𝐶</ci><ci id="S3.SS1.p2.3.m3.1.1.3.cmml" xref="S3.SS1.p2.3.m3.1.1.3">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.3.m3.1c">C_{T}</annotation></semantics></math>, and a query <math id="S3.SS1.p2.4.m4.1" class="ltx_Math" alttext="q" display="inline"><semantics id="S3.SS1.p2.4.m4.1a"><mi id="S3.SS1.p2.4.m4.1.1" xref="S3.SS1.p2.4.m4.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.4.m4.1b"><ci id="S3.SS1.p2.4.m4.1.1.cmml" xref="S3.SS1.p2.4.m4.1.1">𝑞</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.4.m4.1c">q</annotation></semantics></math>, the goal of table sampling is to produce a sub-table <math id="S3.SS1.p2.5.m5.2" class="ltx_Math" alttext="T^{\prime}=T_{r,c}" display="inline"><semantics id="S3.SS1.p2.5.m5.2a"><mrow id="S3.SS1.p2.5.m5.2.3" xref="S3.SS1.p2.5.m5.2.3.cmml"><msup id="S3.SS1.p2.5.m5.2.3.2" xref="S3.SS1.p2.5.m5.2.3.2.cmml"><mi id="S3.SS1.p2.5.m5.2.3.2.2" xref="S3.SS1.p2.5.m5.2.3.2.2.cmml">T</mi><mo id="S3.SS1.p2.5.m5.2.3.2.3" xref="S3.SS1.p2.5.m5.2.3.2.3.cmml">′</mo></msup><mo id="S3.SS1.p2.5.m5.2.3.1" xref="S3.SS1.p2.5.m5.2.3.1.cmml">=</mo><msub id="S3.SS1.p2.5.m5.2.3.3" xref="S3.SS1.p2.5.m5.2.3.3.cmml"><mi id="S3.SS1.p2.5.m5.2.3.3.2" xref="S3.SS1.p2.5.m5.2.3.3.2.cmml">T</mi><mrow id="S3.SS1.p2.5.m5.2.2.2.4" xref="S3.SS1.p2.5.m5.2.2.2.3.cmml"><mi id="S3.SS1.p2.5.m5.1.1.1.1" xref="S3.SS1.p2.5.m5.1.1.1.1.cmml">r</mi><mo id="S3.SS1.p2.5.m5.2.2.2.4.1" xref="S3.SS1.p2.5.m5.2.2.2.3.cmml">,</mo><mi id="S3.SS1.p2.5.m5.2.2.2.2" xref="S3.SS1.p2.5.m5.2.2.2.2.cmml">c</mi></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.5.m5.2b"><apply id="S3.SS1.p2.5.m5.2.3.cmml" xref="S3.SS1.p2.5.m5.2.3"><eq id="S3.SS1.p2.5.m5.2.3.1.cmml" xref="S3.SS1.p2.5.m5.2.3.1"></eq><apply id="S3.SS1.p2.5.m5.2.3.2.cmml" xref="S3.SS1.p2.5.m5.2.3.2"><csymbol cd="ambiguous" id="S3.SS1.p2.5.m5.2.3.2.1.cmml" xref="S3.SS1.p2.5.m5.2.3.2">superscript</csymbol><ci id="S3.SS1.p2.5.m5.2.3.2.2.cmml" xref="S3.SS1.p2.5.m5.2.3.2.2">𝑇</ci><ci id="S3.SS1.p2.5.m5.2.3.2.3.cmml" xref="S3.SS1.p2.5.m5.2.3.2.3">′</ci></apply><apply id="S3.SS1.p2.5.m5.2.3.3.cmml" xref="S3.SS1.p2.5.m5.2.3.3"><csymbol cd="ambiguous" id="S3.SS1.p2.5.m5.2.3.3.1.cmml" xref="S3.SS1.p2.5.m5.2.3.3">subscript</csymbol><ci id="S3.SS1.p2.5.m5.2.3.3.2.cmml" xref="S3.SS1.p2.5.m5.2.3.3.2">𝑇</ci><list id="S3.SS1.p2.5.m5.2.2.2.3.cmml" xref="S3.SS1.p2.5.m5.2.2.2.4"><ci id="S3.SS1.p2.5.m5.1.1.1.1.cmml" xref="S3.SS1.p2.5.m5.1.1.1.1">𝑟</ci><ci id="S3.SS1.p2.5.m5.2.2.2.2.cmml" xref="S3.SS1.p2.5.m5.2.2.2.2">𝑐</ci></list></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.5.m5.2c">T^{\prime}=T_{r,c}</annotation></semantics></math>, where <math id="S3.SS1.p2.6.m6.1" class="ltx_Math" alttext="r\in\mathcal{P}(R_{T})" display="inline"><semantics id="S3.SS1.p2.6.m6.1a"><mrow id="S3.SS1.p2.6.m6.1.1" xref="S3.SS1.p2.6.m6.1.1.cmml"><mi id="S3.SS1.p2.6.m6.1.1.3" xref="S3.SS1.p2.6.m6.1.1.3.cmml">r</mi><mo id="S3.SS1.p2.6.m6.1.1.2" xref="S3.SS1.p2.6.m6.1.1.2.cmml">∈</mo><mrow id="S3.SS1.p2.6.m6.1.1.1" xref="S3.SS1.p2.6.m6.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p2.6.m6.1.1.1.3" xref="S3.SS1.p2.6.m6.1.1.1.3.cmml">𝒫</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p2.6.m6.1.1.1.2" xref="S3.SS1.p2.6.m6.1.1.1.2.cmml">​</mo><mrow id="S3.SS1.p2.6.m6.1.1.1.1.1" xref="S3.SS1.p2.6.m6.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS1.p2.6.m6.1.1.1.1.1.2" xref="S3.SS1.p2.6.m6.1.1.1.1.1.1.cmml">(</mo><msub id="S3.SS1.p2.6.m6.1.1.1.1.1.1" xref="S3.SS1.p2.6.m6.1.1.1.1.1.1.cmml"><mi id="S3.SS1.p2.6.m6.1.1.1.1.1.1.2" xref="S3.SS1.p2.6.m6.1.1.1.1.1.1.2.cmml">R</mi><mi id="S3.SS1.p2.6.m6.1.1.1.1.1.1.3" xref="S3.SS1.p2.6.m6.1.1.1.1.1.1.3.cmml">T</mi></msub><mo stretchy="false" id="S3.SS1.p2.6.m6.1.1.1.1.1.3" xref="S3.SS1.p2.6.m6.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.6.m6.1b"><apply id="S3.SS1.p2.6.m6.1.1.cmml" xref="S3.SS1.p2.6.m6.1.1"><in id="S3.SS1.p2.6.m6.1.1.2.cmml" xref="S3.SS1.p2.6.m6.1.1.2"></in><ci id="S3.SS1.p2.6.m6.1.1.3.cmml" xref="S3.SS1.p2.6.m6.1.1.3">𝑟</ci><apply id="S3.SS1.p2.6.m6.1.1.1.cmml" xref="S3.SS1.p2.6.m6.1.1.1"><times id="S3.SS1.p2.6.m6.1.1.1.2.cmml" xref="S3.SS1.p2.6.m6.1.1.1.2"></times><ci id="S3.SS1.p2.6.m6.1.1.1.3.cmml" xref="S3.SS1.p2.6.m6.1.1.1.3">𝒫</ci><apply id="S3.SS1.p2.6.m6.1.1.1.1.1.1.cmml" xref="S3.SS1.p2.6.m6.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.6.m6.1.1.1.1.1.1.1.cmml" xref="S3.SS1.p2.6.m6.1.1.1.1.1">subscript</csymbol><ci id="S3.SS1.p2.6.m6.1.1.1.1.1.1.2.cmml" xref="S3.SS1.p2.6.m6.1.1.1.1.1.1.2">𝑅</ci><ci id="S3.SS1.p2.6.m6.1.1.1.1.1.1.3.cmml" xref="S3.SS1.p2.6.m6.1.1.1.1.1.1.3">𝑇</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.6.m6.1c">r\in\mathcal{P}(R_{T})</annotation></semantics></math>, <math id="S3.SS1.p2.7.m7.1" class="ltx_Math" alttext="c\in\mathcal{P}(C_{T})" display="inline"><semantics id="S3.SS1.p2.7.m7.1a"><mrow id="S3.SS1.p2.7.m7.1.1" xref="S3.SS1.p2.7.m7.1.1.cmml"><mi id="S3.SS1.p2.7.m7.1.1.3" xref="S3.SS1.p2.7.m7.1.1.3.cmml">c</mi><mo id="S3.SS1.p2.7.m7.1.1.2" xref="S3.SS1.p2.7.m7.1.1.2.cmml">∈</mo><mrow id="S3.SS1.p2.7.m7.1.1.1" xref="S3.SS1.p2.7.m7.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p2.7.m7.1.1.1.3" xref="S3.SS1.p2.7.m7.1.1.1.3.cmml">𝒫</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p2.7.m7.1.1.1.2" xref="S3.SS1.p2.7.m7.1.1.1.2.cmml">​</mo><mrow id="S3.SS1.p2.7.m7.1.1.1.1.1" xref="S3.SS1.p2.7.m7.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS1.p2.7.m7.1.1.1.1.1.2" xref="S3.SS1.p2.7.m7.1.1.1.1.1.1.cmml">(</mo><msub id="S3.SS1.p2.7.m7.1.1.1.1.1.1" xref="S3.SS1.p2.7.m7.1.1.1.1.1.1.cmml"><mi id="S3.SS1.p2.7.m7.1.1.1.1.1.1.2" xref="S3.SS1.p2.7.m7.1.1.1.1.1.1.2.cmml">C</mi><mi id="S3.SS1.p2.7.m7.1.1.1.1.1.1.3" xref="S3.SS1.p2.7.m7.1.1.1.1.1.1.3.cmml">T</mi></msub><mo stretchy="false" id="S3.SS1.p2.7.m7.1.1.1.1.1.3" xref="S3.SS1.p2.7.m7.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.7.m7.1b"><apply id="S3.SS1.p2.7.m7.1.1.cmml" xref="S3.SS1.p2.7.m7.1.1"><in id="S3.SS1.p2.7.m7.1.1.2.cmml" xref="S3.SS1.p2.7.m7.1.1.2"></in><ci id="S3.SS1.p2.7.m7.1.1.3.cmml" xref="S3.SS1.p2.7.m7.1.1.3">𝑐</ci><apply id="S3.SS1.p2.7.m7.1.1.1.cmml" xref="S3.SS1.p2.7.m7.1.1.1"><times id="S3.SS1.p2.7.m7.1.1.1.2.cmml" xref="S3.SS1.p2.7.m7.1.1.1.2"></times><ci id="S3.SS1.p2.7.m7.1.1.1.3.cmml" xref="S3.SS1.p2.7.m7.1.1.1.3">𝒫</ci><apply id="S3.SS1.p2.7.m7.1.1.1.1.1.1.cmml" xref="S3.SS1.p2.7.m7.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.7.m7.1.1.1.1.1.1.1.cmml" xref="S3.SS1.p2.7.m7.1.1.1.1.1">subscript</csymbol><ci id="S3.SS1.p2.7.m7.1.1.1.1.1.1.2.cmml" xref="S3.SS1.p2.7.m7.1.1.1.1.1.1.2">𝐶</ci><ci id="S3.SS1.p2.7.m7.1.1.1.1.1.1.3.cmml" xref="S3.SS1.p2.7.m7.1.1.1.1.1.1.3">𝑇</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.7.m7.1c">c\in\mathcal{P}(C_{T})</annotation></semantics></math>. Here <math id="S3.SS1.p2.8.m8.1" class="ltx_Math" alttext="\mathcal{P}(X)" display="inline"><semantics id="S3.SS1.p2.8.m8.1a"><mrow id="S3.SS1.p2.8.m8.1.2" xref="S3.SS1.p2.8.m8.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p2.8.m8.1.2.2" xref="S3.SS1.p2.8.m8.1.2.2.cmml">𝒫</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p2.8.m8.1.2.1" xref="S3.SS1.p2.8.m8.1.2.1.cmml">​</mo><mrow id="S3.SS1.p2.8.m8.1.2.3.2" xref="S3.SS1.p2.8.m8.1.2.cmml"><mo stretchy="false" id="S3.SS1.p2.8.m8.1.2.3.2.1" xref="S3.SS1.p2.8.m8.1.2.cmml">(</mo><mi id="S3.SS1.p2.8.m8.1.1" xref="S3.SS1.p2.8.m8.1.1.cmml">X</mi><mo stretchy="false" id="S3.SS1.p2.8.m8.1.2.3.2.2" xref="S3.SS1.p2.8.m8.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.8.m8.1b"><apply id="S3.SS1.p2.8.m8.1.2.cmml" xref="S3.SS1.p2.8.m8.1.2"><times id="S3.SS1.p2.8.m8.1.2.1.cmml" xref="S3.SS1.p2.8.m8.1.2.1"></times><ci id="S3.SS1.p2.8.m8.1.2.2.cmml" xref="S3.SS1.p2.8.m8.1.2.2">𝒫</ci><ci id="S3.SS1.p2.8.m8.1.1.cmml" xref="S3.SS1.p2.8.m8.1.1">𝑋</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.8.m8.1c">\mathcal{P}(X)</annotation></semantics></math> denotes the power set of <math id="S3.SS1.p2.9.m9.1" class="ltx_Math" alttext="X" display="inline"><semantics id="S3.SS1.p2.9.m9.1a"><mi id="S3.SS1.p2.9.m9.1.1" xref="S3.SS1.p2.9.m9.1.1.cmml">X</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.9.m9.1b"><ci id="S3.SS1.p2.9.m9.1.1.cmml" xref="S3.SS1.p2.9.m9.1.1">𝑋</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.9.m9.1c">X</annotation></semantics></math>, representing all possible subsets of <math id="S3.SS1.p2.10.m10.1" class="ltx_Math" alttext="X" display="inline"><semantics id="S3.SS1.p2.10.m10.1a"><mi id="S3.SS1.p2.10.m10.1.1" xref="S3.SS1.p2.10.m10.1.1.cmml">X</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.10.m10.1b"><ci id="S3.SS1.p2.10.m10.1.1.cmml" xref="S3.SS1.p2.10.m10.1.1">𝑋</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.10.m10.1c">X</annotation></semantics></math>. The table sampling formulation can be represented as follows:</p>
<table id="S3.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left"><span class="ltx_tag ltx_tag_equation ltx_align_left">(1)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E1.m1.6" class="ltx_Math" alttext="T^{\prime}=T_{r,c}=select(T,rank(f(T,q)))" display="block"><semantics id="S3.E1.m1.6a"><mrow id="S3.E1.m1.6.6" xref="S3.E1.m1.6.6.cmml"><msup id="S3.E1.m1.6.6.3" xref="S3.E1.m1.6.6.3.cmml"><mi id="S3.E1.m1.6.6.3.2" xref="S3.E1.m1.6.6.3.2.cmml">T</mi><mo id="S3.E1.m1.6.6.3.3" xref="S3.E1.m1.6.6.3.3.cmml">′</mo></msup><mo id="S3.E1.m1.6.6.4" xref="S3.E1.m1.6.6.4.cmml">=</mo><msub id="S3.E1.m1.6.6.5" xref="S3.E1.m1.6.6.5.cmml"><mi id="S3.E1.m1.6.6.5.2" xref="S3.E1.m1.6.6.5.2.cmml">T</mi><mrow id="S3.E1.m1.2.2.2.4" xref="S3.E1.m1.2.2.2.3.cmml"><mi id="S3.E1.m1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.cmml">r</mi><mo id="S3.E1.m1.2.2.2.4.1" xref="S3.E1.m1.2.2.2.3.cmml">,</mo><mi id="S3.E1.m1.2.2.2.2" xref="S3.E1.m1.2.2.2.2.cmml">c</mi></mrow></msub><mo id="S3.E1.m1.6.6.6" xref="S3.E1.m1.6.6.6.cmml">=</mo><mrow id="S3.E1.m1.6.6.1" xref="S3.E1.m1.6.6.1.cmml"><mi id="S3.E1.m1.6.6.1.3" xref="S3.E1.m1.6.6.1.3.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.6.6.1.2" xref="S3.E1.m1.6.6.1.2.cmml">​</mo><mi id="S3.E1.m1.6.6.1.4" xref="S3.E1.m1.6.6.1.4.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.6.6.1.2a" xref="S3.E1.m1.6.6.1.2.cmml">​</mo><mi id="S3.E1.m1.6.6.1.5" xref="S3.E1.m1.6.6.1.5.cmml">l</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.6.6.1.2b" xref="S3.E1.m1.6.6.1.2.cmml">​</mo><mi id="S3.E1.m1.6.6.1.6" xref="S3.E1.m1.6.6.1.6.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.6.6.1.2c" xref="S3.E1.m1.6.6.1.2.cmml">​</mo><mi id="S3.E1.m1.6.6.1.7" xref="S3.E1.m1.6.6.1.7.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.6.6.1.2d" xref="S3.E1.m1.6.6.1.2.cmml">​</mo><mi id="S3.E1.m1.6.6.1.8" xref="S3.E1.m1.6.6.1.8.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.6.6.1.2e" xref="S3.E1.m1.6.6.1.2.cmml">​</mo><mrow id="S3.E1.m1.6.6.1.1.1" xref="S3.E1.m1.6.6.1.1.2.cmml"><mo stretchy="false" id="S3.E1.m1.6.6.1.1.1.2" xref="S3.E1.m1.6.6.1.1.2.cmml">(</mo><mi id="S3.E1.m1.5.5" xref="S3.E1.m1.5.5.cmml">T</mi><mo id="S3.E1.m1.6.6.1.1.1.3" xref="S3.E1.m1.6.6.1.1.2.cmml">,</mo><mrow id="S3.E1.m1.6.6.1.1.1.1" xref="S3.E1.m1.6.6.1.1.1.1.cmml"><mi id="S3.E1.m1.6.6.1.1.1.1.3" xref="S3.E1.m1.6.6.1.1.1.1.3.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.6.6.1.1.1.1.2" xref="S3.E1.m1.6.6.1.1.1.1.2.cmml">​</mo><mi id="S3.E1.m1.6.6.1.1.1.1.4" xref="S3.E1.m1.6.6.1.1.1.1.4.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.6.6.1.1.1.1.2a" xref="S3.E1.m1.6.6.1.1.1.1.2.cmml">​</mo><mi id="S3.E1.m1.6.6.1.1.1.1.5" xref="S3.E1.m1.6.6.1.1.1.1.5.cmml">n</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.6.6.1.1.1.1.2b" xref="S3.E1.m1.6.6.1.1.1.1.2.cmml">​</mo><mi id="S3.E1.m1.6.6.1.1.1.1.6" xref="S3.E1.m1.6.6.1.1.1.1.6.cmml">k</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.6.6.1.1.1.1.2c" xref="S3.E1.m1.6.6.1.1.1.1.2.cmml">​</mo><mrow id="S3.E1.m1.6.6.1.1.1.1.1.1" xref="S3.E1.m1.6.6.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E1.m1.6.6.1.1.1.1.1.1.2" xref="S3.E1.m1.6.6.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E1.m1.6.6.1.1.1.1.1.1.1" xref="S3.E1.m1.6.6.1.1.1.1.1.1.1.cmml"><mi id="S3.E1.m1.6.6.1.1.1.1.1.1.1.2" xref="S3.E1.m1.6.6.1.1.1.1.1.1.1.2.cmml">f</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.6.6.1.1.1.1.1.1.1.1" xref="S3.E1.m1.6.6.1.1.1.1.1.1.1.1.cmml">​</mo><mrow id="S3.E1.m1.6.6.1.1.1.1.1.1.1.3.2" xref="S3.E1.m1.6.6.1.1.1.1.1.1.1.3.1.cmml"><mo stretchy="false" id="S3.E1.m1.6.6.1.1.1.1.1.1.1.3.2.1" xref="S3.E1.m1.6.6.1.1.1.1.1.1.1.3.1.cmml">(</mo><mi id="S3.E1.m1.3.3" xref="S3.E1.m1.3.3.cmml">T</mi><mo id="S3.E1.m1.6.6.1.1.1.1.1.1.1.3.2.2" xref="S3.E1.m1.6.6.1.1.1.1.1.1.1.3.1.cmml">,</mo><mi id="S3.E1.m1.4.4" xref="S3.E1.m1.4.4.cmml">q</mi><mo stretchy="false" id="S3.E1.m1.6.6.1.1.1.1.1.1.1.3.2.3" xref="S3.E1.m1.6.6.1.1.1.1.1.1.1.3.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S3.E1.m1.6.6.1.1.1.1.1.1.3" xref="S3.E1.m1.6.6.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S3.E1.m1.6.6.1.1.1.4" xref="S3.E1.m1.6.6.1.1.2.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.6b"><apply id="S3.E1.m1.6.6.cmml" xref="S3.E1.m1.6.6"><and id="S3.E1.m1.6.6a.cmml" xref="S3.E1.m1.6.6"></and><apply id="S3.E1.m1.6.6b.cmml" xref="S3.E1.m1.6.6"><eq id="S3.E1.m1.6.6.4.cmml" xref="S3.E1.m1.6.6.4"></eq><apply id="S3.E1.m1.6.6.3.cmml" xref="S3.E1.m1.6.6.3"><csymbol cd="ambiguous" id="S3.E1.m1.6.6.3.1.cmml" xref="S3.E1.m1.6.6.3">superscript</csymbol><ci id="S3.E1.m1.6.6.3.2.cmml" xref="S3.E1.m1.6.6.3.2">𝑇</ci><ci id="S3.E1.m1.6.6.3.3.cmml" xref="S3.E1.m1.6.6.3.3">′</ci></apply><apply id="S3.E1.m1.6.6.5.cmml" xref="S3.E1.m1.6.6.5"><csymbol cd="ambiguous" id="S3.E1.m1.6.6.5.1.cmml" xref="S3.E1.m1.6.6.5">subscript</csymbol><ci id="S3.E1.m1.6.6.5.2.cmml" xref="S3.E1.m1.6.6.5.2">𝑇</ci><list id="S3.E1.m1.2.2.2.3.cmml" xref="S3.E1.m1.2.2.2.4"><ci id="S3.E1.m1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1">𝑟</ci><ci id="S3.E1.m1.2.2.2.2.cmml" xref="S3.E1.m1.2.2.2.2">𝑐</ci></list></apply></apply><apply id="S3.E1.m1.6.6c.cmml" xref="S3.E1.m1.6.6"><eq id="S3.E1.m1.6.6.6.cmml" xref="S3.E1.m1.6.6.6"></eq><share href="#S3.E1.m1.6.6.5.cmml" id="S3.E1.m1.6.6d.cmml" xref="S3.E1.m1.6.6"></share><apply id="S3.E1.m1.6.6.1.cmml" xref="S3.E1.m1.6.6.1"><times id="S3.E1.m1.6.6.1.2.cmml" xref="S3.E1.m1.6.6.1.2"></times><ci id="S3.E1.m1.6.6.1.3.cmml" xref="S3.E1.m1.6.6.1.3">𝑠</ci><ci id="S3.E1.m1.6.6.1.4.cmml" xref="S3.E1.m1.6.6.1.4">𝑒</ci><ci id="S3.E1.m1.6.6.1.5.cmml" xref="S3.E1.m1.6.6.1.5">𝑙</ci><ci id="S3.E1.m1.6.6.1.6.cmml" xref="S3.E1.m1.6.6.1.6">𝑒</ci><ci id="S3.E1.m1.6.6.1.7.cmml" xref="S3.E1.m1.6.6.1.7">𝑐</ci><ci id="S3.E1.m1.6.6.1.8.cmml" xref="S3.E1.m1.6.6.1.8">𝑡</ci><interval closure="open" id="S3.E1.m1.6.6.1.1.2.cmml" xref="S3.E1.m1.6.6.1.1.1"><ci id="S3.E1.m1.5.5.cmml" xref="S3.E1.m1.5.5">𝑇</ci><apply id="S3.E1.m1.6.6.1.1.1.1.cmml" xref="S3.E1.m1.6.6.1.1.1.1"><times id="S3.E1.m1.6.6.1.1.1.1.2.cmml" xref="S3.E1.m1.6.6.1.1.1.1.2"></times><ci id="S3.E1.m1.6.6.1.1.1.1.3.cmml" xref="S3.E1.m1.6.6.1.1.1.1.3">𝑟</ci><ci id="S3.E1.m1.6.6.1.1.1.1.4.cmml" xref="S3.E1.m1.6.6.1.1.1.1.4">𝑎</ci><ci id="S3.E1.m1.6.6.1.1.1.1.5.cmml" xref="S3.E1.m1.6.6.1.1.1.1.5">𝑛</ci><ci id="S3.E1.m1.6.6.1.1.1.1.6.cmml" xref="S3.E1.m1.6.6.1.1.1.1.6">𝑘</ci><apply id="S3.E1.m1.6.6.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.6.6.1.1.1.1.1.1"><times id="S3.E1.m1.6.6.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.6.6.1.1.1.1.1.1.1.1"></times><ci id="S3.E1.m1.6.6.1.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.6.6.1.1.1.1.1.1.1.2">𝑓</ci><interval closure="open" id="S3.E1.m1.6.6.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E1.m1.6.6.1.1.1.1.1.1.1.3.2"><ci id="S3.E1.m1.3.3.cmml" xref="S3.E1.m1.3.3">𝑇</ci><ci id="S3.E1.m1.4.4.cmml" xref="S3.E1.m1.4.4">𝑞</ci></interval></apply></apply></interval></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.6c">T^{\prime}=T_{r,c}=select(T,rank(f(T,q)))</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p id="S3.SS1.p2.19" class="ltx_p">The <math id="S3.SS1.p2.11.m1.2" class="ltx_Math" alttext="f(T,q)" display="inline"><semantics id="S3.SS1.p2.11.m1.2a"><mrow id="S3.SS1.p2.11.m1.2.3" xref="S3.SS1.p2.11.m1.2.3.cmml"><mi id="S3.SS1.p2.11.m1.2.3.2" xref="S3.SS1.p2.11.m1.2.3.2.cmml">f</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p2.11.m1.2.3.1" xref="S3.SS1.p2.11.m1.2.3.1.cmml">​</mo><mrow id="S3.SS1.p2.11.m1.2.3.3.2" xref="S3.SS1.p2.11.m1.2.3.3.1.cmml"><mo stretchy="false" id="S3.SS1.p2.11.m1.2.3.3.2.1" xref="S3.SS1.p2.11.m1.2.3.3.1.cmml">(</mo><mi id="S3.SS1.p2.11.m1.1.1" xref="S3.SS1.p2.11.m1.1.1.cmml">T</mi><mo id="S3.SS1.p2.11.m1.2.3.3.2.2" xref="S3.SS1.p2.11.m1.2.3.3.1.cmml">,</mo><mi id="S3.SS1.p2.11.m1.2.2" xref="S3.SS1.p2.11.m1.2.2.cmml">q</mi><mo stretchy="false" id="S3.SS1.p2.11.m1.2.3.3.2.3" xref="S3.SS1.p2.11.m1.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.11.m1.2b"><apply id="S3.SS1.p2.11.m1.2.3.cmml" xref="S3.SS1.p2.11.m1.2.3"><times id="S3.SS1.p2.11.m1.2.3.1.cmml" xref="S3.SS1.p2.11.m1.2.3.1"></times><ci id="S3.SS1.p2.11.m1.2.3.2.cmml" xref="S3.SS1.p2.11.m1.2.3.2">𝑓</ci><interval closure="open" id="S3.SS1.p2.11.m1.2.3.3.1.cmml" xref="S3.SS1.p2.11.m1.2.3.3.2"><ci id="S3.SS1.p2.11.m1.1.1.cmml" xref="S3.SS1.p2.11.m1.1.1">𝑇</ci><ci id="S3.SS1.p2.11.m1.2.2.cmml" xref="S3.SS1.p2.11.m1.2.2">𝑞</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.11.m1.2c">f(T,q)</annotation></semantics></math> function represents each sampling method. For example, the query-based sampling (discussed in detail below) calculates the similarity score as <math id="S3.SS1.p2.12.m2.1" class="ltx_Math" alttext="f" display="inline"><semantics id="S3.SS1.p2.12.m2.1a"><mi id="S3.SS1.p2.12.m2.1.1" xref="S3.SS1.p2.12.m2.1.1.cmml">f</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.12.m2.1b"><ci id="S3.SS1.p2.12.m2.1.1.cmml" xref="S3.SS1.p2.12.m2.1.1">𝑓</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.12.m2.1c">f</annotation></semantics></math> between the query <math id="S3.SS1.p2.13.m3.1" class="ltx_Math" alttext="q" display="inline"><semantics id="S3.SS1.p2.13.m3.1a"><mi id="S3.SS1.p2.13.m3.1.1" xref="S3.SS1.p2.13.m3.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.13.m3.1b"><ci id="S3.SS1.p2.13.m3.1.1.cmml" xref="S3.SS1.p2.13.m3.1.1">𝑞</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.13.m3.1c">q</annotation></semantics></math> and each row/column from <math id="S3.SS1.p2.14.m4.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S3.SS1.p2.14.m4.1a"><mi id="S3.SS1.p2.14.m4.1.1" xref="S3.SS1.p2.14.m4.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.14.m4.1b"><ci id="S3.SS1.p2.14.m4.1.1.cmml" xref="S3.SS1.p2.14.m4.1.1">𝑇</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.14.m4.1c">T</annotation></semantics></math>. The <math id="S3.SS1.p2.15.m5.1" class="ltx_Math" alttext="rank()" display="inline"><semantics id="S3.SS1.p2.15.m5.1a"><mrow id="S3.SS1.p2.15.m5.1.1" xref="S3.SS1.p2.15.m5.1.1.cmml"><mi id="S3.SS1.p2.15.m5.1.1.2" xref="S3.SS1.p2.15.m5.1.1.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p2.15.m5.1.1.1" xref="S3.SS1.p2.15.m5.1.1.1.cmml">​</mo><mi id="S3.SS1.p2.15.m5.1.1.3" xref="S3.SS1.p2.15.m5.1.1.3.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p2.15.m5.1.1.1a" xref="S3.SS1.p2.15.m5.1.1.1.cmml">​</mo><mi id="S3.SS1.p2.15.m5.1.1.4" xref="S3.SS1.p2.15.m5.1.1.4.cmml">n</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p2.15.m5.1.1.1b" xref="S3.SS1.p2.15.m5.1.1.1.cmml">​</mo><mi id="S3.SS1.p2.15.m5.1.1.5" xref="S3.SS1.p2.15.m5.1.1.5.cmml">k</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p2.15.m5.1.1.1c" xref="S3.SS1.p2.15.m5.1.1.1.cmml">​</mo><mrow id="S3.SS1.p2.15.m5.1.1.6.2" xref="S3.SS1.p2.15.m5.1.1.cmml"><mo stretchy="false" id="S3.SS1.p2.15.m5.1.1.6.2.1" xref="S3.SS1.p2.15.m5.1.1.6.1.cmml">(</mo><mo stretchy="false" id="S3.SS1.p2.15.m5.1.1.6.2.2" xref="S3.SS1.p2.15.m5.1.1.6.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.15.m5.1b"><apply id="S3.SS1.p2.15.m5.1.1.cmml" xref="S3.SS1.p2.15.m5.1.1"><times id="S3.SS1.p2.15.m5.1.1.1.cmml" xref="S3.SS1.p2.15.m5.1.1.1"></times><ci id="S3.SS1.p2.15.m5.1.1.2.cmml" xref="S3.SS1.p2.15.m5.1.1.2">𝑟</ci><ci id="S3.SS1.p2.15.m5.1.1.3.cmml" xref="S3.SS1.p2.15.m5.1.1.3">𝑎</ci><ci id="S3.SS1.p2.15.m5.1.1.4.cmml" xref="S3.SS1.p2.15.m5.1.1.4">𝑛</ci><ci id="S3.SS1.p2.15.m5.1.1.5.cmml" xref="S3.SS1.p2.15.m5.1.1.5">𝑘</ci><list id="S3.SS1.p2.15.m5.1.1.6.1.cmml" xref="S3.SS1.p2.15.m5.1.1.6.2.1"></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.15.m5.1c">rank()</annotation></semantics></math> function sorts the rows and columns of <math id="S3.SS1.p2.16.m6.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S3.SS1.p2.16.m6.1a"><mi id="S3.SS1.p2.16.m6.1.1" xref="S3.SS1.p2.16.m6.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.16.m6.1b"><ci id="S3.SS1.p2.16.m6.1.1.cmml" xref="S3.SS1.p2.16.m6.1.1">𝑇</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.16.m6.1c">T</annotation></semantics></math> based on sampling methods <math id="S3.SS1.p2.17.m7.1" class="ltx_Math" alttext="f" display="inline"><semantics id="S3.SS1.p2.17.m7.1a"><mi id="S3.SS1.p2.17.m7.1.1" xref="S3.SS1.p2.17.m7.1.1.cmml">f</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.17.m7.1b"><ci id="S3.SS1.p2.17.m7.1.1.cmml" xref="S3.SS1.p2.17.m7.1.1">𝑓</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.17.m7.1c">f</annotation></semantics></math> and outputs a ranked list. The <math id="S3.SS1.p2.18.m8.1" class="ltx_Math" alttext="select()" display="inline"><semantics id="S3.SS1.p2.18.m8.1a"><mrow id="S3.SS1.p2.18.m8.1.1" xref="S3.SS1.p2.18.m8.1.1.cmml"><mi id="S3.SS1.p2.18.m8.1.1.2" xref="S3.SS1.p2.18.m8.1.1.2.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p2.18.m8.1.1.1" xref="S3.SS1.p2.18.m8.1.1.1.cmml">​</mo><mi id="S3.SS1.p2.18.m8.1.1.3" xref="S3.SS1.p2.18.m8.1.1.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p2.18.m8.1.1.1a" xref="S3.SS1.p2.18.m8.1.1.1.cmml">​</mo><mi id="S3.SS1.p2.18.m8.1.1.4" xref="S3.SS1.p2.18.m8.1.1.4.cmml">l</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p2.18.m8.1.1.1b" xref="S3.SS1.p2.18.m8.1.1.1.cmml">​</mo><mi id="S3.SS1.p2.18.m8.1.1.5" xref="S3.SS1.p2.18.m8.1.1.5.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p2.18.m8.1.1.1c" xref="S3.SS1.p2.18.m8.1.1.1.cmml">​</mo><mi id="S3.SS1.p2.18.m8.1.1.6" xref="S3.SS1.p2.18.m8.1.1.6.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p2.18.m8.1.1.1d" xref="S3.SS1.p2.18.m8.1.1.1.cmml">​</mo><mi id="S3.SS1.p2.18.m8.1.1.7" xref="S3.SS1.p2.18.m8.1.1.7.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p2.18.m8.1.1.1e" xref="S3.SS1.p2.18.m8.1.1.1.cmml">​</mo><mrow id="S3.SS1.p2.18.m8.1.1.8.2" xref="S3.SS1.p2.18.m8.1.1.cmml"><mo stretchy="false" id="S3.SS1.p2.18.m8.1.1.8.2.1" xref="S3.SS1.p2.18.m8.1.1.8.1.cmml">(</mo><mo stretchy="false" id="S3.SS1.p2.18.m8.1.1.8.2.2" xref="S3.SS1.p2.18.m8.1.1.8.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.18.m8.1b"><apply id="S3.SS1.p2.18.m8.1.1.cmml" xref="S3.SS1.p2.18.m8.1.1"><times id="S3.SS1.p2.18.m8.1.1.1.cmml" xref="S3.SS1.p2.18.m8.1.1.1"></times><ci id="S3.SS1.p2.18.m8.1.1.2.cmml" xref="S3.SS1.p2.18.m8.1.1.2">𝑠</ci><ci id="S3.SS1.p2.18.m8.1.1.3.cmml" xref="S3.SS1.p2.18.m8.1.1.3">𝑒</ci><ci id="S3.SS1.p2.18.m8.1.1.4.cmml" xref="S3.SS1.p2.18.m8.1.1.4">𝑙</ci><ci id="S3.SS1.p2.18.m8.1.1.5.cmml" xref="S3.SS1.p2.18.m8.1.1.5">𝑒</ci><ci id="S3.SS1.p2.18.m8.1.1.6.cmml" xref="S3.SS1.p2.18.m8.1.1.6">𝑐</ci><ci id="S3.SS1.p2.18.m8.1.1.7.cmml" xref="S3.SS1.p2.18.m8.1.1.7">𝑡</ci><list id="S3.SS1.p2.18.m8.1.1.8.1.cmml" xref="S3.SS1.p2.18.m8.1.1.8.2.1"></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.18.m8.1c">select()</annotation></semantics></math> function then chooses the top-k rows and top-l columns from the ranked list to form the sub-table <math id="S3.SS1.p2.19.m9.2" class="ltx_Math" alttext="T_{r,c}" display="inline"><semantics id="S3.SS1.p2.19.m9.2a"><msub id="S3.SS1.p2.19.m9.2.3" xref="S3.SS1.p2.19.m9.2.3.cmml"><mi id="S3.SS1.p2.19.m9.2.3.2" xref="S3.SS1.p2.19.m9.2.3.2.cmml">T</mi><mrow id="S3.SS1.p2.19.m9.2.2.2.4" xref="S3.SS1.p2.19.m9.2.2.2.3.cmml"><mi id="S3.SS1.p2.19.m9.1.1.1.1" xref="S3.SS1.p2.19.m9.1.1.1.1.cmml">r</mi><mo id="S3.SS1.p2.19.m9.2.2.2.4.1" xref="S3.SS1.p2.19.m9.2.2.2.3.cmml">,</mo><mi id="S3.SS1.p2.19.m9.2.2.2.2" xref="S3.SS1.p2.19.m9.2.2.2.2.cmml">c</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.19.m9.2b"><apply id="S3.SS1.p2.19.m9.2.3.cmml" xref="S3.SS1.p2.19.m9.2.3"><csymbol cd="ambiguous" id="S3.SS1.p2.19.m9.2.3.1.cmml" xref="S3.SS1.p2.19.m9.2.3">subscript</csymbol><ci id="S3.SS1.p2.19.m9.2.3.2.cmml" xref="S3.SS1.p2.19.m9.2.3.2">𝑇</ci><list id="S3.SS1.p2.19.m9.2.2.2.3.cmml" xref="S3.SS1.p2.19.m9.2.2.2.4"><ci id="S3.SS1.p2.19.m9.1.1.1.1.cmml" xref="S3.SS1.p2.19.m9.1.1.1.1">𝑟</ci><ci id="S3.SS1.p2.19.m9.2.2.2.2.cmml" xref="S3.SS1.p2.19.m9.2.2.2.2">𝑐</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.19.m9.2c">T_{r,c}</annotation></semantics></math>. Note that, in the context of column-based sampling, the term “grounding” is frequently used. Grounding becomes essential when dealing with ambiguous queries. For instance, the term “date” could refer to calendar data, a romantic outing, or the fruit. If a table includes columns like “release date”, “date of birth”, or “date ate”, grounding helps determine which column(s) the query refers to (See the improvement of using column grounding in Table <a href="#S4.T4" title="Table 4 ‣ 4.1.2. Models ‣ 4.1. Experiment Settings ‣ 4. Experiments ‣ TAP4LLM: Table Provider on Sampling, Augmenting, and Packing Semi-structured Data for Large Language Model Reasoning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>).
Specifically, we propose two distinct variants for table sampling as follows:</p>
</div>
<section id="S3.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.1. </span>Rule-based Sampling</h4>

<div id="S3.SS1.SSS1.p1" class="ltx_para">
<p id="S3.SS1.SSS1.p1.1" class="ltx_p">Rule-based sampling refers to table sampling based on predefined criteria or rules. These methods follow the established patterns or criteria for data selection. We consider three common rule-based sampling methods as follows:</p>
</div>
<div id="S3.SS1.SSS1.p2" class="ltx_para">
<p id="S3.SS1.SSS1.p2.1" class="ltx_p">(1) <span id="S3.SS1.SSS1.p2.1.1" class="ltx_text ltx_font_italic">Random Sampling</span>:
Random sampling refers to selecting rows from a table, with each having an equal probability of being selected. This ensures that the sampled subset is diverse and unbiased, as it reflects the characteristics of the table without any distortion. Even though random sampling may not always capture the full diversity or variations in the entire table, it remains a practical choice for table sampling implementation, as directly supported by various statistical tools and software.</p>
</div>
<div id="S3.SS1.SSS1.p3" class="ltx_para">
<p id="S3.SS1.SSS1.p3.5" class="ltx_p">(2) <span id="S3.SS1.SSS1.p3.5.1" class="ltx_text ltx_font_italic">Evenly Sampling</span>:
To avoid overwhelming excessive data while ensuring a balanced and comprehensive subset, we utilize evenly sampling as one of the table sampling variants. It allows for systematic sampling of rows or columns from the table in a specific sequence. Specifically, evenly sampling starts with the topmost field of the table, <math id="S3.SS1.SSS1.p3.1.m1.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S3.SS1.SSS1.p3.1.m1.1a"><mi id="S3.SS1.SSS1.p3.1.m1.1.1" xref="S3.SS1.SSS1.p3.1.m1.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p3.1.m1.1b"><ci id="S3.SS1.SSS1.p3.1.m1.1.1.cmml" xref="S3.SS1.SSS1.p3.1.m1.1.1">𝑇</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p3.1.m1.1c">T</annotation></semantics></math>, and alternates between the beginning (<math id="S3.SS1.SSS1.p3.2.m2.1" class="ltx_Math" alttext="r_{1}" display="inline"><semantics id="S3.SS1.SSS1.p3.2.m2.1a"><msub id="S3.SS1.SSS1.p3.2.m2.1.1" xref="S3.SS1.SSS1.p3.2.m2.1.1.cmml"><mi id="S3.SS1.SSS1.p3.2.m2.1.1.2" xref="S3.SS1.SSS1.p3.2.m2.1.1.2.cmml">r</mi><mn id="S3.SS1.SSS1.p3.2.m2.1.1.3" xref="S3.SS1.SSS1.p3.2.m2.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p3.2.m2.1b"><apply id="S3.SS1.SSS1.p3.2.m2.1.1.cmml" xref="S3.SS1.SSS1.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS1.p3.2.m2.1.1.1.cmml" xref="S3.SS1.SSS1.p3.2.m2.1.1">subscript</csymbol><ci id="S3.SS1.SSS1.p3.2.m2.1.1.2.cmml" xref="S3.SS1.SSS1.p3.2.m2.1.1.2">𝑟</ci><cn type="integer" id="S3.SS1.SSS1.p3.2.m2.1.1.3.cmml" xref="S3.SS1.SSS1.p3.2.m2.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p3.2.m2.1c">r_{1}</annotation></semantics></math>) and the end of the table (<math id="S3.SS1.SSS1.p3.3.m3.1" class="ltx_Math" alttext="r_{n}" display="inline"><semantics id="S3.SS1.SSS1.p3.3.m3.1a"><msub id="S3.SS1.SSS1.p3.3.m3.1.1" xref="S3.SS1.SSS1.p3.3.m3.1.1.cmml"><mi id="S3.SS1.SSS1.p3.3.m3.1.1.2" xref="S3.SS1.SSS1.p3.3.m3.1.1.2.cmml">r</mi><mi id="S3.SS1.SSS1.p3.3.m3.1.1.3" xref="S3.SS1.SSS1.p3.3.m3.1.1.3.cmml">n</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p3.3.m3.1b"><apply id="S3.SS1.SSS1.p3.3.m3.1.1.cmml" xref="S3.SS1.SSS1.p3.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS1.p3.3.m3.1.1.1.cmml" xref="S3.SS1.SSS1.p3.3.m3.1.1">subscript</csymbol><ci id="S3.SS1.SSS1.p3.3.m3.1.1.2.cmml" xref="S3.SS1.SSS1.p3.3.m3.1.1.2">𝑟</ci><ci id="S3.SS1.SSS1.p3.3.m3.1.1.3.cmml" xref="S3.SS1.SSS1.p3.3.m3.1.1.3">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p3.3.m3.1c">r_{n}</annotation></semantics></math>, where the table has <math id="S3.SS1.SSS1.p3.4.m4.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S3.SS1.SSS1.p3.4.m4.1a"><mi id="S3.SS1.SSS1.p3.4.m4.1.1" xref="S3.SS1.SSS1.p3.4.m4.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p3.4.m4.1b"><ci id="S3.SS1.SSS1.p3.4.m4.1.1.cmml" xref="S3.SS1.SSS1.p3.4.m4.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p3.4.m4.1c">n</annotation></semantics></math> rows) to create a subset <math id="S3.SS1.SSS1.p3.5.m5.1" class="ltx_Math" alttext="r\in\mathcal{P}(R_{T})" display="inline"><semantics id="S3.SS1.SSS1.p3.5.m5.1a"><mrow id="S3.SS1.SSS1.p3.5.m5.1.1" xref="S3.SS1.SSS1.p3.5.m5.1.1.cmml"><mi id="S3.SS1.SSS1.p3.5.m5.1.1.3" xref="S3.SS1.SSS1.p3.5.m5.1.1.3.cmml">r</mi><mo id="S3.SS1.SSS1.p3.5.m5.1.1.2" xref="S3.SS1.SSS1.p3.5.m5.1.1.2.cmml">∈</mo><mrow id="S3.SS1.SSS1.p3.5.m5.1.1.1" xref="S3.SS1.SSS1.p3.5.m5.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.SSS1.p3.5.m5.1.1.1.3" xref="S3.SS1.SSS1.p3.5.m5.1.1.1.3.cmml">𝒫</mi><mo lspace="0em" rspace="0em" id="S3.SS1.SSS1.p3.5.m5.1.1.1.2" xref="S3.SS1.SSS1.p3.5.m5.1.1.1.2.cmml">​</mo><mrow id="S3.SS1.SSS1.p3.5.m5.1.1.1.1.1" xref="S3.SS1.SSS1.p3.5.m5.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS1.SSS1.p3.5.m5.1.1.1.1.1.2" xref="S3.SS1.SSS1.p3.5.m5.1.1.1.1.1.1.cmml">(</mo><msub id="S3.SS1.SSS1.p3.5.m5.1.1.1.1.1.1" xref="S3.SS1.SSS1.p3.5.m5.1.1.1.1.1.1.cmml"><mi id="S3.SS1.SSS1.p3.5.m5.1.1.1.1.1.1.2" xref="S3.SS1.SSS1.p3.5.m5.1.1.1.1.1.1.2.cmml">R</mi><mi id="S3.SS1.SSS1.p3.5.m5.1.1.1.1.1.1.3" xref="S3.SS1.SSS1.p3.5.m5.1.1.1.1.1.1.3.cmml">T</mi></msub><mo stretchy="false" id="S3.SS1.SSS1.p3.5.m5.1.1.1.1.1.3" xref="S3.SS1.SSS1.p3.5.m5.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p3.5.m5.1b"><apply id="S3.SS1.SSS1.p3.5.m5.1.1.cmml" xref="S3.SS1.SSS1.p3.5.m5.1.1"><in id="S3.SS1.SSS1.p3.5.m5.1.1.2.cmml" xref="S3.SS1.SSS1.p3.5.m5.1.1.2"></in><ci id="S3.SS1.SSS1.p3.5.m5.1.1.3.cmml" xref="S3.SS1.SSS1.p3.5.m5.1.1.3">𝑟</ci><apply id="S3.SS1.SSS1.p3.5.m5.1.1.1.cmml" xref="S3.SS1.SSS1.p3.5.m5.1.1.1"><times id="S3.SS1.SSS1.p3.5.m5.1.1.1.2.cmml" xref="S3.SS1.SSS1.p3.5.m5.1.1.1.2"></times><ci id="S3.SS1.SSS1.p3.5.m5.1.1.1.3.cmml" xref="S3.SS1.SSS1.p3.5.m5.1.1.1.3">𝒫</ci><apply id="S3.SS1.SSS1.p3.5.m5.1.1.1.1.1.1.cmml" xref="S3.SS1.SSS1.p3.5.m5.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS1.p3.5.m5.1.1.1.1.1.1.1.cmml" xref="S3.SS1.SSS1.p3.5.m5.1.1.1.1.1">subscript</csymbol><ci id="S3.SS1.SSS1.p3.5.m5.1.1.1.1.1.1.2.cmml" xref="S3.SS1.SSS1.p3.5.m5.1.1.1.1.1.1.2">𝑅</ci><ci id="S3.SS1.SSS1.p3.5.m5.1.1.1.1.1.1.3.cmml" xref="S3.SS1.SSS1.p3.5.m5.1.1.1.1.1.1.3">𝑇</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p3.5.m5.1c">r\in\mathcal{P}(R_{T})</annotation></semantics></math>. This alternating pattern continues from the outermost rows towards the middle until the aggregated number of tokens from the selected rows reaches a pre-defined token threshold.</p>
</div>
<div id="S3.SS1.SSS1.p4" class="ltx_para">
<p id="S3.SS1.SSS1.p4.6" class="ltx_p">(3) <span id="S3.SS1.SSS1.p4.6.1" class="ltx_text ltx_font_italic">Content Snapshot &amp; Synthetically Sampling</span>: Table contents provide more details about the semantics than column headers themselves. When taking the utterance into consideration, the most relevant cell values to answer the utterance might come from multiple rows. we follow this work <cite class="ltx_cite ltx_citemacro_citep">(Yin et al<span class="ltx_text">.</span>, <a href="#bib.bib66" title="" class="ltx_ref">2020</a>)</cite> to create the method of content snapshots for table <math id="S3.SS1.SSS1.p4.1.m1.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S3.SS1.SSS1.p4.1.m1.1a"><mi id="S3.SS1.SSS1.p4.1.m1.1.1" xref="S3.SS1.SSS1.p4.1.m1.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p4.1.m1.1b"><ci id="S3.SS1.SSS1.p4.1.m1.1.1.cmml" xref="S3.SS1.SSS1.p4.1.m1.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p4.1.m1.1c">K</annotation></semantics></math> rows based on their relevance to the utterance along with a synthetic strategy. Specifically, for <math id="S3.SS1.SSS1.p4.2.m2.1" class="ltx_Math" alttext="K&gt;1" display="inline"><semantics id="S3.SS1.SSS1.p4.2.m2.1a"><mrow id="S3.SS1.SSS1.p4.2.m2.1.1" xref="S3.SS1.SSS1.p4.2.m2.1.1.cmml"><mi id="S3.SS1.SSS1.p4.2.m2.1.1.2" xref="S3.SS1.SSS1.p4.2.m2.1.1.2.cmml">K</mi><mo id="S3.SS1.SSS1.p4.2.m2.1.1.1" xref="S3.SS1.SSS1.p4.2.m2.1.1.1.cmml">&gt;</mo><mn id="S3.SS1.SSS1.p4.2.m2.1.1.3" xref="S3.SS1.SSS1.p4.2.m2.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p4.2.m2.1b"><apply id="S3.SS1.SSS1.p4.2.m2.1.1.cmml" xref="S3.SS1.SSS1.p4.2.m2.1.1"><gt id="S3.SS1.SSS1.p4.2.m2.1.1.1.cmml" xref="S3.SS1.SSS1.p4.2.m2.1.1.1"></gt><ci id="S3.SS1.SSS1.p4.2.m2.1.1.2.cmml" xref="S3.SS1.SSS1.p4.2.m2.1.1.2">𝐾</ci><cn type="integer" id="S3.SS1.SSS1.p4.2.m2.1.1.3.cmml" xref="S3.SS1.SSS1.p4.2.m2.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p4.2.m2.1c">K&gt;1</annotation></semantics></math>, top-<math id="S3.SS1.SSS1.p4.3.m3.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S3.SS1.SSS1.p4.3.m3.1a"><mi id="S3.SS1.SSS1.p4.3.m3.1.1" xref="S3.SS1.SSS1.p4.3.m3.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p4.3.m3.1b"><ci id="S3.SS1.SSS1.p4.3.m3.1.1.cmml" xref="S3.SS1.SSS1.p4.3.m3.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p4.3.m3.1c">K</annotation></semantics></math> rows are selected based on the highest <math id="S3.SS1.SSS1.p4.4.m4.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S3.SS1.SSS1.p4.4.m4.1a"><mi id="S3.SS1.SSS1.p4.4.m4.1.1" xref="S3.SS1.SSS1.p4.4.m4.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p4.4.m4.1b"><ci id="S3.SS1.SSS1.p4.4.m4.1.1.cmml" xref="S3.SS1.SSS1.p4.4.m4.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p4.4.m4.1c">n</annotation></semantics></math>-gram overlap ratio with the utterance. For <math id="S3.SS1.SSS1.p4.5.m5.1" class="ltx_Math" alttext="K=1" display="inline"><semantics id="S3.SS1.SSS1.p4.5.m5.1a"><mrow id="S3.SS1.SSS1.p4.5.m5.1.1" xref="S3.SS1.SSS1.p4.5.m5.1.1.cmml"><mi id="S3.SS1.SSS1.p4.5.m5.1.1.2" xref="S3.SS1.SSS1.p4.5.m5.1.1.2.cmml">K</mi><mo id="S3.SS1.SSS1.p4.5.m5.1.1.1" xref="S3.SS1.SSS1.p4.5.m5.1.1.1.cmml">=</mo><mn id="S3.SS1.SSS1.p4.5.m5.1.1.3" xref="S3.SS1.SSS1.p4.5.m5.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p4.5.m5.1b"><apply id="S3.SS1.SSS1.p4.5.m5.1.1.cmml" xref="S3.SS1.SSS1.p4.5.m5.1.1"><eq id="S3.SS1.SSS1.p4.5.m5.1.1.1.cmml" xref="S3.SS1.SSS1.p4.5.m5.1.1.1"></eq><ci id="S3.SS1.SSS1.p4.5.m5.1.1.2.cmml" xref="S3.SS1.SSS1.p4.5.m5.1.1.2">𝐾</ci><cn type="integer" id="S3.SS1.SSS1.p4.5.m5.1.1.3.cmml" xref="S3.SS1.SSS1.p4.5.m5.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p4.5.m5.1c">K=1</annotation></semantics></math>, a synthetic row is composed by selecting the cell values from each column with the highest <math id="S3.SS1.SSS1.p4.6.m6.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S3.SS1.SSS1.p4.6.m6.1a"><mi id="S3.SS1.SSS1.p4.6.m6.1.1" xref="S3.SS1.SSS1.p4.6.m6.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p4.6.m6.1b"><ci id="S3.SS1.SSS1.p4.6.m6.1.1.cmml" xref="S3.SS1.SSS1.p4.6.m6.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p4.6.m6.1c">n</annotation></semantics></math>-gram overlap with the utterance.
For instance, consider the utterance ”How many more participants were there in 2008 than in the London Olympics?”, and an associating table with column names “Year”, “Host City”, and “Number of Participants”. The most relevant cells to the utterance, “2008 (from Year)” and “London (from Host City)”, come from different rows. Through the synthetic strategy, these insightful contents can be combined into one single synthetic row and encoded as a subset of table content most relevant to the utterance.</p>
</div>
<figure id="S3.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1. </span>Different kinds of table augmentation.</figcaption>
<div id="S3.T1.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:155.6pt;vertical-align:-0.7pt;"><span class="ltx_transformed_inner" style="transform:translate(-96.2pt,34.4pt) scale(0.692645694002457,0.692645694002457) ;">
<table id="S3.T1.1.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T1.1.1.1" class="ltx_tr">
<td id="S3.T1.1.1.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S3.T1.1.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.1.1.1.1" class="ltx_p" style="width:133.4pt;"><span id="S3.T1.1.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Knowledge Aspect</span></span>
</span>
</td>
<td id="S3.T1.1.1.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S3.T1.1.1.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.1.2.1.1" class="ltx_p" style="width:140.0pt;"><span id="S3.T1.1.1.1.2.1.1.1" class="ltx_text ltx_font_bold">Categories</span></span>
</span>
</td>
<td id="S3.T1.1.1.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S3.T1.1.1.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.1.3.1.1" class="ltx_p" style="width:313.4pt;"><span id="S3.T1.1.1.1.3.1.1.1" class="ltx_text ltx_font_bold">Definition</span></span>
</span>
</td>
</tr>
<tr id="S3.T1.1.1.2" class="ltx_tr">
<td id="S3.T1.1.1.2.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T1.1.1.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.2.1.1.1" class="ltx_p" style="width:133.4pt;">Dimension/Measure</span>
</span>
</td>
<td id="S3.T1.1.1.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T1.1.1.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.2.2.1.1" class="ltx_p" style="width:140.0pt;">Metadata-based</span>
</span>
</td>
<td id="S3.T1.1.1.2.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T1.1.1.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.2.3.1.1" class="ltx_p" style="width:313.4pt;">Distinguish each element in a table as either dimension field or measure field.</span>
</span>
</td>
</tr>
<tr id="S3.T1.1.1.3" class="ltx_tr">
<td id="S3.T1.1.1.3.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T1.1.1.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.3.1.1.1" class="ltx_p" style="width:133.4pt;">Semantic Field Type</span>
</span>
</td>
<td id="S3.T1.1.1.3.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T1.1.1.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.3.2.1.1" class="ltx_p" style="width:140.0pt;">Metadata-based</span>
</span>
</td>
<td id="S3.T1.1.1.3.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T1.1.1.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.3.3.1.1" class="ltx_p" style="width:313.4pt;">Classify the meaning and format of the data within each field based on knowledge graphs.</span>
</span>
</td>
</tr>
<tr id="S3.T1.1.1.4" class="ltx_tr">
<td id="S3.T1.1.1.4.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T1.1.1.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.4.1.1.1" class="ltx_p" style="width:133.4pt;">Table Size</span>
</span>
</td>
<td id="S3.T1.1.1.4.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T1.1.1.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.4.2.1.1" class="ltx_p" style="width:140.0pt;">Metadata-based</span>
</span>
</td>
<td id="S3.T1.1.1.4.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T1.1.1.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.4.3.1.1" class="ltx_p" style="width:313.4pt;">Basic information of a table including numbers of rows and columns.</span>
</span>
</td>
</tr>
<tr id="S3.T1.1.1.5" class="ltx_tr">
<td id="S3.T1.1.1.5.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T1.1.1.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.5.1.1.1" class="ltx_p" style="width:133.4pt;">Statistics Feature</span>
</span>
</td>
<td id="S3.T1.1.1.5.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T1.1.1.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.5.2.1.1" class="ltx_p" style="width:140.0pt;">Metadata-based</span>
</span>
</td>
<td id="S3.T1.1.1.5.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T1.1.1.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.5.3.1.1" class="ltx_p" style="width:313.4pt;">Statistics features such as change rate, numerical distribution, range of data.</span>
</span>
</td>
</tr>
<tr id="S3.T1.1.1.6" class="ltx_tr">
<td id="S3.T1.1.1.6.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T1.1.1.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.6.1.1.1" class="ltx_p" style="width:133.4pt;">Header Hierarchy</span>
</span>
</td>
<td id="S3.T1.1.1.6.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T1.1.1.6.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.6.2.1.1" class="ltx_p" style="width:140.0pt;">Metadata-based</span>
</span>
</td>
<td id="S3.T1.1.1.6.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T1.1.1.6.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.6.3.1.1" class="ltx_p" style="width:313.4pt;">The organization and structure of header elements within a table.</span>
</span>
</td>
</tr>
<tr id="S3.T1.1.1.7" class="ltx_tr">
<td id="S3.T1.1.1.7.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T1.1.1.7.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.7.1.1.1" class="ltx_p" style="width:133.4pt;">Docs References</span>
</span>
</td>
<td id="S3.T1.1.1.7.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T1.1.1.7.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.7.2.1.1" class="ltx_p" style="width:140.0pt;">Retrieval-based</span>
</span>
</td>
<td id="S3.T1.1.1.7.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T1.1.1.7.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.7.3.1.1" class="ltx_p" style="width:313.4pt;">External domain knowledge from reliable webpages (<span id="S3.T1.1.1.7.3.1.1.1" class="ltx_text ltx_font_italic">e.g.</span>, wikipedia, Wolfram Alpha, <span id="S3.T1.1.1.7.3.1.1.2" class="ltx_text ltx_font_italic">etc</span>.) which are similar to the given context.</span>
</span>
</td>
</tr>
<tr id="S3.T1.1.1.8" class="ltx_tr">
<td id="S3.T1.1.1.8.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T1.1.1.8.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.8.1.1.1" class="ltx_p" style="width:133.4pt;">Term Explanation</span>
</span>
</td>
<td id="S3.T1.1.1.8.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T1.1.1.8.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.8.2.1.1" class="ltx_p" style="width:140.0pt;">Retrieval-based</span>
</span>
</td>
<td id="S3.T1.1.1.8.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T1.1.1.8.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.8.3.1.1" class="ltx_p" style="width:313.4pt;">External domain knowledge such as term and metric definitions (formulas, relevant documents/sources, search results, etc.)</span>
</span>
</td>
</tr>
<tr id="S3.T1.1.1.9" class="ltx_tr">
<td id="S3.T1.1.1.9.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S3.T1.1.1.9.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.9.1.1.1" class="ltx_p" style="width:133.4pt;">Self Prompting</span>
</span>
</td>
<td id="S3.T1.1.1.9.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S3.T1.1.1.9.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.9.2.1.1" class="ltx_p" style="width:140.0pt;">Self-consistency-based</span>
</span>
</td>
<td id="S3.T1.1.1.9.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S3.T1.1.1.9.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.9.3.1.1" class="ltx_p" style="width:313.4pt;">Leverage LLMs to generate some reasoning thoughts as supplementary for table augmentation (self-augmented prompting, chain-of-thoughts, <span id="S3.T1.1.1.9.3.1.1.1" class="ltx_text ltx_font_italic">etc</span>.)</span>
</span>
</td>
</tr>
</table>
</span></div>
</figure>
</section>
<section id="S3.SS1.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.2. </span>Embedding-based Sampling</h4>

<div id="S3.SS1.SSS2.p1" class="ltx_para">
<p id="S3.SS1.SSS2.p1.1" class="ltx_p">Embedding-based sampling is an advanced approach to table sampling based on high-dimensional vector embeddings. Instead of adhering to strict rules or criteria in rule-based sampling, embedding-based methods leverage the semantic and contextual representation of each row and column. By mapping each row or column to vectors, this method harnesses the power of spatial relationships within the embedding space to guide sampling decisions. Specifically, we propose two embedding-based sampling methods as follows:</p>
</div>
<div id="S3.SS1.SSS2.p2" class="ltx_para">
<p id="S3.SS1.SSS2.p2.1" class="ltx_p">(1) <span id="S3.SS1.SSS2.p2.1.1" class="ltx_text ltx_font_italic">Query-based Sampling</span>:
Query-based Sampling is a tailored approach emphasizing the semantics relevance of table cells to the utterance. The process is exactly illustrated in Eq. <a href="#S3.E1" title="In 3.1. Table Sampling ‣ 3. TAP4LLM: Table Provider for LLMs ‣ TAP4LLM: Table Provider on Sampling, Augmenting, and Packing Semi-structured Data for Large Language Model Reasoning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. Note that the default query-based sampling is the row-based method. We also study the significance of column grounding in table sampling by testing query-based sampling in conjunction with column grounding, as shown in Table <a href="#S3.SS1" title="3.1. Table Sampling ‣ 3. TAP4LLM: Table Provider for LLMs ‣ TAP4LLM: Table Provider on Sampling, Augmenting, and Packing Semi-structured Data for Large Language Model Reasoning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.1</span></a>. By incorporating column grounding, the sampling process revolves around both rows and columns, offering a dynamic table subset where both rows and columns are susceptible to change based on the user query.</p>
</div>
<div id="S3.SS1.SSS2.p3" class="ltx_para">
<p id="S3.SS1.SSS2.p3.15" class="ltx_p">(2) <span id="S3.SS1.SSS2.p3.15.1" class="ltx_text ltx_font_italic">Clustering-based Sampling</span>:
In Clustering-based Sampling, the core principle is to group similar rows or columns based on their embedding representation.
Specifically, let <math id="S3.SS1.SSS2.p3.1.m1.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S3.SS1.SSS2.p3.1.m1.1a"><mi id="S3.SS1.SSS2.p3.1.m1.1.1" xref="S3.SS1.SSS2.p3.1.m1.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p3.1.m1.1b"><ci id="S3.SS1.SSS2.p3.1.m1.1.1.cmml" xref="S3.SS1.SSS2.p3.1.m1.1.1">𝑇</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p3.1.m1.1c">T</annotation></semantics></math> be a table where <math id="S3.SS1.SSS2.p3.2.m2.1" class="ltx_Math" alttext="R_{T}" display="inline"><semantics id="S3.SS1.SSS2.p3.2.m2.1a"><msub id="S3.SS1.SSS2.p3.2.m2.1.1" xref="S3.SS1.SSS2.p3.2.m2.1.1.cmml"><mi id="S3.SS1.SSS2.p3.2.m2.1.1.2" xref="S3.SS1.SSS2.p3.2.m2.1.1.2.cmml">R</mi><mi id="S3.SS1.SSS2.p3.2.m2.1.1.3" xref="S3.SS1.SSS2.p3.2.m2.1.1.3.cmml">T</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p3.2.m2.1b"><apply id="S3.SS1.SSS2.p3.2.m2.1.1.cmml" xref="S3.SS1.SSS2.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p3.2.m2.1.1.1.cmml" xref="S3.SS1.SSS2.p3.2.m2.1.1">subscript</csymbol><ci id="S3.SS1.SSS2.p3.2.m2.1.1.2.cmml" xref="S3.SS1.SSS2.p3.2.m2.1.1.2">𝑅</ci><ci id="S3.SS1.SSS2.p3.2.m2.1.1.3.cmml" xref="S3.SS1.SSS2.p3.2.m2.1.1.3">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p3.2.m2.1c">R_{T}</annotation></semantics></math> is the set of rows and <math id="S3.SS1.SSS2.p3.3.m3.1" class="ltx_Math" alttext="C_{T}" display="inline"><semantics id="S3.SS1.SSS2.p3.3.m3.1a"><msub id="S3.SS1.SSS2.p3.3.m3.1.1" xref="S3.SS1.SSS2.p3.3.m3.1.1.cmml"><mi id="S3.SS1.SSS2.p3.3.m3.1.1.2" xref="S3.SS1.SSS2.p3.3.m3.1.1.2.cmml">C</mi><mi id="S3.SS1.SSS2.p3.3.m3.1.1.3" xref="S3.SS1.SSS2.p3.3.m3.1.1.3.cmml">T</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p3.3.m3.1b"><apply id="S3.SS1.SSS2.p3.3.m3.1.1.cmml" xref="S3.SS1.SSS2.p3.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p3.3.m3.1.1.1.cmml" xref="S3.SS1.SSS2.p3.3.m3.1.1">subscript</csymbol><ci id="S3.SS1.SSS2.p3.3.m3.1.1.2.cmml" xref="S3.SS1.SSS2.p3.3.m3.1.1.2">𝐶</ci><ci id="S3.SS1.SSS2.p3.3.m3.1.1.3.cmml" xref="S3.SS1.SSS2.p3.3.m3.1.1.3">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p3.3.m3.1c">C_{T}</annotation></semantics></math> is the set of columns. Let <math id="S3.SS1.SSS2.p3.4.m4.1" class="ltx_Math" alttext="E:R_{T}\cup C_{T}\rightarrow\mathbb{R}^{d}" display="inline"><semantics id="S3.SS1.SSS2.p3.4.m4.1a"><mrow id="S3.SS1.SSS2.p3.4.m4.1.1" xref="S3.SS1.SSS2.p3.4.m4.1.1.cmml"><mi id="S3.SS1.SSS2.p3.4.m4.1.1.2" xref="S3.SS1.SSS2.p3.4.m4.1.1.2.cmml">E</mi><mo lspace="0.278em" rspace="0.278em" id="S3.SS1.SSS2.p3.4.m4.1.1.1" xref="S3.SS1.SSS2.p3.4.m4.1.1.1.cmml">:</mo><mrow id="S3.SS1.SSS2.p3.4.m4.1.1.3" xref="S3.SS1.SSS2.p3.4.m4.1.1.3.cmml"><mrow id="S3.SS1.SSS2.p3.4.m4.1.1.3.2" xref="S3.SS1.SSS2.p3.4.m4.1.1.3.2.cmml"><msub id="S3.SS1.SSS2.p3.4.m4.1.1.3.2.2" xref="S3.SS1.SSS2.p3.4.m4.1.1.3.2.2.cmml"><mi id="S3.SS1.SSS2.p3.4.m4.1.1.3.2.2.2" xref="S3.SS1.SSS2.p3.4.m4.1.1.3.2.2.2.cmml">R</mi><mi id="S3.SS1.SSS2.p3.4.m4.1.1.3.2.2.3" xref="S3.SS1.SSS2.p3.4.m4.1.1.3.2.2.3.cmml">T</mi></msub><mo id="S3.SS1.SSS2.p3.4.m4.1.1.3.2.1" xref="S3.SS1.SSS2.p3.4.m4.1.1.3.2.1.cmml">∪</mo><msub id="S3.SS1.SSS2.p3.4.m4.1.1.3.2.3" xref="S3.SS1.SSS2.p3.4.m4.1.1.3.2.3.cmml"><mi id="S3.SS1.SSS2.p3.4.m4.1.1.3.2.3.2" xref="S3.SS1.SSS2.p3.4.m4.1.1.3.2.3.2.cmml">C</mi><mi id="S3.SS1.SSS2.p3.4.m4.1.1.3.2.3.3" xref="S3.SS1.SSS2.p3.4.m4.1.1.3.2.3.3.cmml">T</mi></msub></mrow><mo stretchy="false" id="S3.SS1.SSS2.p3.4.m4.1.1.3.1" xref="S3.SS1.SSS2.p3.4.m4.1.1.3.1.cmml">→</mo><msup id="S3.SS1.SSS2.p3.4.m4.1.1.3.3" xref="S3.SS1.SSS2.p3.4.m4.1.1.3.3.cmml"><mi id="S3.SS1.SSS2.p3.4.m4.1.1.3.3.2" xref="S3.SS1.SSS2.p3.4.m4.1.1.3.3.2.cmml">ℝ</mi><mi id="S3.SS1.SSS2.p3.4.m4.1.1.3.3.3" xref="S3.SS1.SSS2.p3.4.m4.1.1.3.3.3.cmml">d</mi></msup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p3.4.m4.1b"><apply id="S3.SS1.SSS2.p3.4.m4.1.1.cmml" xref="S3.SS1.SSS2.p3.4.m4.1.1"><ci id="S3.SS1.SSS2.p3.4.m4.1.1.1.cmml" xref="S3.SS1.SSS2.p3.4.m4.1.1.1">:</ci><ci id="S3.SS1.SSS2.p3.4.m4.1.1.2.cmml" xref="S3.SS1.SSS2.p3.4.m4.1.1.2">𝐸</ci><apply id="S3.SS1.SSS2.p3.4.m4.1.1.3.cmml" xref="S3.SS1.SSS2.p3.4.m4.1.1.3"><ci id="S3.SS1.SSS2.p3.4.m4.1.1.3.1.cmml" xref="S3.SS1.SSS2.p3.4.m4.1.1.3.1">→</ci><apply id="S3.SS1.SSS2.p3.4.m4.1.1.3.2.cmml" xref="S3.SS1.SSS2.p3.4.m4.1.1.3.2"><union id="S3.SS1.SSS2.p3.4.m4.1.1.3.2.1.cmml" xref="S3.SS1.SSS2.p3.4.m4.1.1.3.2.1"></union><apply id="S3.SS1.SSS2.p3.4.m4.1.1.3.2.2.cmml" xref="S3.SS1.SSS2.p3.4.m4.1.1.3.2.2"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p3.4.m4.1.1.3.2.2.1.cmml" xref="S3.SS1.SSS2.p3.4.m4.1.1.3.2.2">subscript</csymbol><ci id="S3.SS1.SSS2.p3.4.m4.1.1.3.2.2.2.cmml" xref="S3.SS1.SSS2.p3.4.m4.1.1.3.2.2.2">𝑅</ci><ci id="S3.SS1.SSS2.p3.4.m4.1.1.3.2.2.3.cmml" xref="S3.SS1.SSS2.p3.4.m4.1.1.3.2.2.3">𝑇</ci></apply><apply id="S3.SS1.SSS2.p3.4.m4.1.1.3.2.3.cmml" xref="S3.SS1.SSS2.p3.4.m4.1.1.3.2.3"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p3.4.m4.1.1.3.2.3.1.cmml" xref="S3.SS1.SSS2.p3.4.m4.1.1.3.2.3">subscript</csymbol><ci id="S3.SS1.SSS2.p3.4.m4.1.1.3.2.3.2.cmml" xref="S3.SS1.SSS2.p3.4.m4.1.1.3.2.3.2">𝐶</ci><ci id="S3.SS1.SSS2.p3.4.m4.1.1.3.2.3.3.cmml" xref="S3.SS1.SSS2.p3.4.m4.1.1.3.2.3.3">𝑇</ci></apply></apply><apply id="S3.SS1.SSS2.p3.4.m4.1.1.3.3.cmml" xref="S3.SS1.SSS2.p3.4.m4.1.1.3.3"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p3.4.m4.1.1.3.3.1.cmml" xref="S3.SS1.SSS2.p3.4.m4.1.1.3.3">superscript</csymbol><ci id="S3.SS1.SSS2.p3.4.m4.1.1.3.3.2.cmml" xref="S3.SS1.SSS2.p3.4.m4.1.1.3.3.2">ℝ</ci><ci id="S3.SS1.SSS2.p3.4.m4.1.1.3.3.3.cmml" xref="S3.SS1.SSS2.p3.4.m4.1.1.3.3.3">𝑑</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p3.4.m4.1c">E:R_{T}\cup C_{T}\rightarrow\mathbb{R}^{d}</annotation></semantics></math> be an embedding function that maps each row or column to a <math id="S3.SS1.SSS2.p3.5.m5.1" class="ltx_Math" alttext="d" display="inline"><semantics id="S3.SS1.SSS2.p3.5.m5.1a"><mi id="S3.SS1.SSS2.p3.5.m5.1.1" xref="S3.SS1.SSS2.p3.5.m5.1.1.cmml">d</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p3.5.m5.1b"><ci id="S3.SS1.SSS2.p3.5.m5.1.1.cmml" xref="S3.SS1.SSS2.p3.5.m5.1.1">𝑑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p3.5.m5.1c">d</annotation></semantics></math>-dimensional vector by capturing its semantic content. The goal of clustering-based sampling is to extract a sub-table <math id="S3.SS1.SSS2.p3.6.m6.1" class="ltx_Math" alttext="T^{\prime}\subseteq T" display="inline"><semantics id="S3.SS1.SSS2.p3.6.m6.1a"><mrow id="S3.SS1.SSS2.p3.6.m6.1.1" xref="S3.SS1.SSS2.p3.6.m6.1.1.cmml"><msup id="S3.SS1.SSS2.p3.6.m6.1.1.2" xref="S3.SS1.SSS2.p3.6.m6.1.1.2.cmml"><mi id="S3.SS1.SSS2.p3.6.m6.1.1.2.2" xref="S3.SS1.SSS2.p3.6.m6.1.1.2.2.cmml">T</mi><mo id="S3.SS1.SSS2.p3.6.m6.1.1.2.3" xref="S3.SS1.SSS2.p3.6.m6.1.1.2.3.cmml">′</mo></msup><mo id="S3.SS1.SSS2.p3.6.m6.1.1.1" xref="S3.SS1.SSS2.p3.6.m6.1.1.1.cmml">⊆</mo><mi id="S3.SS1.SSS2.p3.6.m6.1.1.3" xref="S3.SS1.SSS2.p3.6.m6.1.1.3.cmml">T</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p3.6.m6.1b"><apply id="S3.SS1.SSS2.p3.6.m6.1.1.cmml" xref="S3.SS1.SSS2.p3.6.m6.1.1"><subset id="S3.SS1.SSS2.p3.6.m6.1.1.1.cmml" xref="S3.SS1.SSS2.p3.6.m6.1.1.1"></subset><apply id="S3.SS1.SSS2.p3.6.m6.1.1.2.cmml" xref="S3.SS1.SSS2.p3.6.m6.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p3.6.m6.1.1.2.1.cmml" xref="S3.SS1.SSS2.p3.6.m6.1.1.2">superscript</csymbol><ci id="S3.SS1.SSS2.p3.6.m6.1.1.2.2.cmml" xref="S3.SS1.SSS2.p3.6.m6.1.1.2.2">𝑇</ci><ci id="S3.SS1.SSS2.p3.6.m6.1.1.2.3.cmml" xref="S3.SS1.SSS2.p3.6.m6.1.1.2.3">′</ci></apply><ci id="S3.SS1.SSS2.p3.6.m6.1.1.3.cmml" xref="S3.SS1.SSS2.p3.6.m6.1.1.3">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p3.6.m6.1c">T^{\prime}\subseteq T</annotation></semantics></math> and ensure the preservation of data diversity.
We use <span id="S3.SS1.SSS2.p3.15.2" class="ltx_text ltx_font_italic">K-Means</span> <cite class="ltx_cite ltx_citemacro_citep">(MacQueen et al<span class="ltx_text">.</span>, <a href="#bib.bib42" title="" class="ltx_ref">1967</a>)</cite> as our clustering-method backbone. Specifically, for each <math id="S3.SS1.SSS2.p3.7.m7.1" class="ltx_Math" alttext="r\in R_{T}" display="inline"><semantics id="S3.SS1.SSS2.p3.7.m7.1a"><mrow id="S3.SS1.SSS2.p3.7.m7.1.1" xref="S3.SS1.SSS2.p3.7.m7.1.1.cmml"><mi id="S3.SS1.SSS2.p3.7.m7.1.1.2" xref="S3.SS1.SSS2.p3.7.m7.1.1.2.cmml">r</mi><mo id="S3.SS1.SSS2.p3.7.m7.1.1.1" xref="S3.SS1.SSS2.p3.7.m7.1.1.1.cmml">∈</mo><msub id="S3.SS1.SSS2.p3.7.m7.1.1.3" xref="S3.SS1.SSS2.p3.7.m7.1.1.3.cmml"><mi id="S3.SS1.SSS2.p3.7.m7.1.1.3.2" xref="S3.SS1.SSS2.p3.7.m7.1.1.3.2.cmml">R</mi><mi id="S3.SS1.SSS2.p3.7.m7.1.1.3.3" xref="S3.SS1.SSS2.p3.7.m7.1.1.3.3.cmml">T</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p3.7.m7.1b"><apply id="S3.SS1.SSS2.p3.7.m7.1.1.cmml" xref="S3.SS1.SSS2.p3.7.m7.1.1"><in id="S3.SS1.SSS2.p3.7.m7.1.1.1.cmml" xref="S3.SS1.SSS2.p3.7.m7.1.1.1"></in><ci id="S3.SS1.SSS2.p3.7.m7.1.1.2.cmml" xref="S3.SS1.SSS2.p3.7.m7.1.1.2">𝑟</ci><apply id="S3.SS1.SSS2.p3.7.m7.1.1.3.cmml" xref="S3.SS1.SSS2.p3.7.m7.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p3.7.m7.1.1.3.1.cmml" xref="S3.SS1.SSS2.p3.7.m7.1.1.3">subscript</csymbol><ci id="S3.SS1.SSS2.p3.7.m7.1.1.3.2.cmml" xref="S3.SS1.SSS2.p3.7.m7.1.1.3.2">𝑅</ci><ci id="S3.SS1.SSS2.p3.7.m7.1.1.3.3.cmml" xref="S3.SS1.SSS2.p3.7.m7.1.1.3.3">𝑇</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p3.7.m7.1c">r\in R_{T}</annotation></semantics></math> or <math id="S3.SS1.SSS2.p3.8.m8.1" class="ltx_Math" alttext="c\in C_{T}" display="inline"><semantics id="S3.SS1.SSS2.p3.8.m8.1a"><mrow id="S3.SS1.SSS2.p3.8.m8.1.1" xref="S3.SS1.SSS2.p3.8.m8.1.1.cmml"><mi id="S3.SS1.SSS2.p3.8.m8.1.1.2" xref="S3.SS1.SSS2.p3.8.m8.1.1.2.cmml">c</mi><mo id="S3.SS1.SSS2.p3.8.m8.1.1.1" xref="S3.SS1.SSS2.p3.8.m8.1.1.1.cmml">∈</mo><msub id="S3.SS1.SSS2.p3.8.m8.1.1.3" xref="S3.SS1.SSS2.p3.8.m8.1.1.3.cmml"><mi id="S3.SS1.SSS2.p3.8.m8.1.1.3.2" xref="S3.SS1.SSS2.p3.8.m8.1.1.3.2.cmml">C</mi><mi id="S3.SS1.SSS2.p3.8.m8.1.1.3.3" xref="S3.SS1.SSS2.p3.8.m8.1.1.3.3.cmml">T</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p3.8.m8.1b"><apply id="S3.SS1.SSS2.p3.8.m8.1.1.cmml" xref="S3.SS1.SSS2.p3.8.m8.1.1"><in id="S3.SS1.SSS2.p3.8.m8.1.1.1.cmml" xref="S3.SS1.SSS2.p3.8.m8.1.1.1"></in><ci id="S3.SS1.SSS2.p3.8.m8.1.1.2.cmml" xref="S3.SS1.SSS2.p3.8.m8.1.1.2">𝑐</ci><apply id="S3.SS1.SSS2.p3.8.m8.1.1.3.cmml" xref="S3.SS1.SSS2.p3.8.m8.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p3.8.m8.1.1.3.1.cmml" xref="S3.SS1.SSS2.p3.8.m8.1.1.3">subscript</csymbol><ci id="S3.SS1.SSS2.p3.8.m8.1.1.3.2.cmml" xref="S3.SS1.SSS2.p3.8.m8.1.1.3.2">𝐶</ci><ci id="S3.SS1.SSS2.p3.8.m8.1.1.3.3.cmml" xref="S3.SS1.SSS2.p3.8.m8.1.1.3.3">𝑇</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p3.8.m8.1c">c\in C_{T}</annotation></semantics></math>, compute its embedding as <math id="S3.SS1.SSS2.p3.9.m9.1" class="ltx_Math" alttext="e=E(r)" display="inline"><semantics id="S3.SS1.SSS2.p3.9.m9.1a"><mrow id="S3.SS1.SSS2.p3.9.m9.1.2" xref="S3.SS1.SSS2.p3.9.m9.1.2.cmml"><mi id="S3.SS1.SSS2.p3.9.m9.1.2.2" xref="S3.SS1.SSS2.p3.9.m9.1.2.2.cmml">e</mi><mo id="S3.SS1.SSS2.p3.9.m9.1.2.1" xref="S3.SS1.SSS2.p3.9.m9.1.2.1.cmml">=</mo><mrow id="S3.SS1.SSS2.p3.9.m9.1.2.3" xref="S3.SS1.SSS2.p3.9.m9.1.2.3.cmml"><mi id="S3.SS1.SSS2.p3.9.m9.1.2.3.2" xref="S3.SS1.SSS2.p3.9.m9.1.2.3.2.cmml">E</mi><mo lspace="0em" rspace="0em" id="S3.SS1.SSS2.p3.9.m9.1.2.3.1" xref="S3.SS1.SSS2.p3.9.m9.1.2.3.1.cmml">​</mo><mrow id="S3.SS1.SSS2.p3.9.m9.1.2.3.3.2" xref="S3.SS1.SSS2.p3.9.m9.1.2.3.cmml"><mo stretchy="false" id="S3.SS1.SSS2.p3.9.m9.1.2.3.3.2.1" xref="S3.SS1.SSS2.p3.9.m9.1.2.3.cmml">(</mo><mi id="S3.SS1.SSS2.p3.9.m9.1.1" xref="S3.SS1.SSS2.p3.9.m9.1.1.cmml">r</mi><mo stretchy="false" id="S3.SS1.SSS2.p3.9.m9.1.2.3.3.2.2" xref="S3.SS1.SSS2.p3.9.m9.1.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p3.9.m9.1b"><apply id="S3.SS1.SSS2.p3.9.m9.1.2.cmml" xref="S3.SS1.SSS2.p3.9.m9.1.2"><eq id="S3.SS1.SSS2.p3.9.m9.1.2.1.cmml" xref="S3.SS1.SSS2.p3.9.m9.1.2.1"></eq><ci id="S3.SS1.SSS2.p3.9.m9.1.2.2.cmml" xref="S3.SS1.SSS2.p3.9.m9.1.2.2">𝑒</ci><apply id="S3.SS1.SSS2.p3.9.m9.1.2.3.cmml" xref="S3.SS1.SSS2.p3.9.m9.1.2.3"><times id="S3.SS1.SSS2.p3.9.m9.1.2.3.1.cmml" xref="S3.SS1.SSS2.p3.9.m9.1.2.3.1"></times><ci id="S3.SS1.SSS2.p3.9.m9.1.2.3.2.cmml" xref="S3.SS1.SSS2.p3.9.m9.1.2.3.2">𝐸</ci><ci id="S3.SS1.SSS2.p3.9.m9.1.1.cmml" xref="S3.SS1.SSS2.p3.9.m9.1.1">𝑟</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p3.9.m9.1c">e=E(r)</annotation></semantics></math> or <math id="S3.SS1.SSS2.p3.10.m10.1" class="ltx_Math" alttext="e=E(c)" display="inline"><semantics id="S3.SS1.SSS2.p3.10.m10.1a"><mrow id="S3.SS1.SSS2.p3.10.m10.1.2" xref="S3.SS1.SSS2.p3.10.m10.1.2.cmml"><mi id="S3.SS1.SSS2.p3.10.m10.1.2.2" xref="S3.SS1.SSS2.p3.10.m10.1.2.2.cmml">e</mi><mo id="S3.SS1.SSS2.p3.10.m10.1.2.1" xref="S3.SS1.SSS2.p3.10.m10.1.2.1.cmml">=</mo><mrow id="S3.SS1.SSS2.p3.10.m10.1.2.3" xref="S3.SS1.SSS2.p3.10.m10.1.2.3.cmml"><mi id="S3.SS1.SSS2.p3.10.m10.1.2.3.2" xref="S3.SS1.SSS2.p3.10.m10.1.2.3.2.cmml">E</mi><mo lspace="0em" rspace="0em" id="S3.SS1.SSS2.p3.10.m10.1.2.3.1" xref="S3.SS1.SSS2.p3.10.m10.1.2.3.1.cmml">​</mo><mrow id="S3.SS1.SSS2.p3.10.m10.1.2.3.3.2" xref="S3.SS1.SSS2.p3.10.m10.1.2.3.cmml"><mo stretchy="false" id="S3.SS1.SSS2.p3.10.m10.1.2.3.3.2.1" xref="S3.SS1.SSS2.p3.10.m10.1.2.3.cmml">(</mo><mi id="S3.SS1.SSS2.p3.10.m10.1.1" xref="S3.SS1.SSS2.p3.10.m10.1.1.cmml">c</mi><mo stretchy="false" id="S3.SS1.SSS2.p3.10.m10.1.2.3.3.2.2" xref="S3.SS1.SSS2.p3.10.m10.1.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p3.10.m10.1b"><apply id="S3.SS1.SSS2.p3.10.m10.1.2.cmml" xref="S3.SS1.SSS2.p3.10.m10.1.2"><eq id="S3.SS1.SSS2.p3.10.m10.1.2.1.cmml" xref="S3.SS1.SSS2.p3.10.m10.1.2.1"></eq><ci id="S3.SS1.SSS2.p3.10.m10.1.2.2.cmml" xref="S3.SS1.SSS2.p3.10.m10.1.2.2">𝑒</ci><apply id="S3.SS1.SSS2.p3.10.m10.1.2.3.cmml" xref="S3.SS1.SSS2.p3.10.m10.1.2.3"><times id="S3.SS1.SSS2.p3.10.m10.1.2.3.1.cmml" xref="S3.SS1.SSS2.p3.10.m10.1.2.3.1"></times><ci id="S3.SS1.SSS2.p3.10.m10.1.2.3.2.cmml" xref="S3.SS1.SSS2.p3.10.m10.1.2.3.2">𝐸</ci><ci id="S3.SS1.SSS2.p3.10.m10.1.1.cmml" xref="S3.SS1.SSS2.p3.10.m10.1.1">𝑐</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p3.10.m10.1c">e=E(c)</annotation></semantics></math>. Then, utilize the K-Means algorithm, and partition the set of embeddings into <math id="S3.SS1.SSS2.p3.11.m11.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S3.SS1.SSS2.p3.11.m11.1a"><mi id="S3.SS1.SSS2.p3.11.m11.1.1" xref="S3.SS1.SSS2.p3.11.m11.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p3.11.m11.1b"><ci id="S3.SS1.SSS2.p3.11.m11.1.1.cmml" xref="S3.SS1.SSS2.p3.11.m11.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p3.11.m11.1c">n</annotation></semantics></math> clusters: <math id="S3.SS1.SSS2.p3.12.m12.4" class="ltx_Math" alttext="\{C_{1},C_{2},\ldots,C_{n}\}" display="inline"><semantics id="S3.SS1.SSS2.p3.12.m12.4a"><mrow id="S3.SS1.SSS2.p3.12.m12.4.4.3" xref="S3.SS1.SSS2.p3.12.m12.4.4.4.cmml"><mo stretchy="false" id="S3.SS1.SSS2.p3.12.m12.4.4.3.4" xref="S3.SS1.SSS2.p3.12.m12.4.4.4.cmml">{</mo><msub id="S3.SS1.SSS2.p3.12.m12.2.2.1.1" xref="S3.SS1.SSS2.p3.12.m12.2.2.1.1.cmml"><mi id="S3.SS1.SSS2.p3.12.m12.2.2.1.1.2" xref="S3.SS1.SSS2.p3.12.m12.2.2.1.1.2.cmml">C</mi><mn id="S3.SS1.SSS2.p3.12.m12.2.2.1.1.3" xref="S3.SS1.SSS2.p3.12.m12.2.2.1.1.3.cmml">1</mn></msub><mo id="S3.SS1.SSS2.p3.12.m12.4.4.3.5" xref="S3.SS1.SSS2.p3.12.m12.4.4.4.cmml">,</mo><msub id="S3.SS1.SSS2.p3.12.m12.3.3.2.2" xref="S3.SS1.SSS2.p3.12.m12.3.3.2.2.cmml"><mi id="S3.SS1.SSS2.p3.12.m12.3.3.2.2.2" xref="S3.SS1.SSS2.p3.12.m12.3.3.2.2.2.cmml">C</mi><mn id="S3.SS1.SSS2.p3.12.m12.3.3.2.2.3" xref="S3.SS1.SSS2.p3.12.m12.3.3.2.2.3.cmml">2</mn></msub><mo id="S3.SS1.SSS2.p3.12.m12.4.4.3.6" xref="S3.SS1.SSS2.p3.12.m12.4.4.4.cmml">,</mo><mi mathvariant="normal" id="S3.SS1.SSS2.p3.12.m12.1.1" xref="S3.SS1.SSS2.p3.12.m12.1.1.cmml">…</mi><mo id="S3.SS1.SSS2.p3.12.m12.4.4.3.7" xref="S3.SS1.SSS2.p3.12.m12.4.4.4.cmml">,</mo><msub id="S3.SS1.SSS2.p3.12.m12.4.4.3.3" xref="S3.SS1.SSS2.p3.12.m12.4.4.3.3.cmml"><mi id="S3.SS1.SSS2.p3.12.m12.4.4.3.3.2" xref="S3.SS1.SSS2.p3.12.m12.4.4.3.3.2.cmml">C</mi><mi id="S3.SS1.SSS2.p3.12.m12.4.4.3.3.3" xref="S3.SS1.SSS2.p3.12.m12.4.4.3.3.3.cmml">n</mi></msub><mo stretchy="false" id="S3.SS1.SSS2.p3.12.m12.4.4.3.8" xref="S3.SS1.SSS2.p3.12.m12.4.4.4.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p3.12.m12.4b"><set id="S3.SS1.SSS2.p3.12.m12.4.4.4.cmml" xref="S3.SS1.SSS2.p3.12.m12.4.4.3"><apply id="S3.SS1.SSS2.p3.12.m12.2.2.1.1.cmml" xref="S3.SS1.SSS2.p3.12.m12.2.2.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p3.12.m12.2.2.1.1.1.cmml" xref="S3.SS1.SSS2.p3.12.m12.2.2.1.1">subscript</csymbol><ci id="S3.SS1.SSS2.p3.12.m12.2.2.1.1.2.cmml" xref="S3.SS1.SSS2.p3.12.m12.2.2.1.1.2">𝐶</ci><cn type="integer" id="S3.SS1.SSS2.p3.12.m12.2.2.1.1.3.cmml" xref="S3.SS1.SSS2.p3.12.m12.2.2.1.1.3">1</cn></apply><apply id="S3.SS1.SSS2.p3.12.m12.3.3.2.2.cmml" xref="S3.SS1.SSS2.p3.12.m12.3.3.2.2"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p3.12.m12.3.3.2.2.1.cmml" xref="S3.SS1.SSS2.p3.12.m12.3.3.2.2">subscript</csymbol><ci id="S3.SS1.SSS2.p3.12.m12.3.3.2.2.2.cmml" xref="S3.SS1.SSS2.p3.12.m12.3.3.2.2.2">𝐶</ci><cn type="integer" id="S3.SS1.SSS2.p3.12.m12.3.3.2.2.3.cmml" xref="S3.SS1.SSS2.p3.12.m12.3.3.2.2.3">2</cn></apply><ci id="S3.SS1.SSS2.p3.12.m12.1.1.cmml" xref="S3.SS1.SSS2.p3.12.m12.1.1">…</ci><apply id="S3.SS1.SSS2.p3.12.m12.4.4.3.3.cmml" xref="S3.SS1.SSS2.p3.12.m12.4.4.3.3"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p3.12.m12.4.4.3.3.1.cmml" xref="S3.SS1.SSS2.p3.12.m12.4.4.3.3">subscript</csymbol><ci id="S3.SS1.SSS2.p3.12.m12.4.4.3.3.2.cmml" xref="S3.SS1.SSS2.p3.12.m12.4.4.3.3.2">𝐶</ci><ci id="S3.SS1.SSS2.p3.12.m12.4.4.3.3.3.cmml" xref="S3.SS1.SSS2.p3.12.m12.4.4.3.3.3">𝑛</ci></apply></set></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p3.12.m12.4c">\{C_{1},C_{2},\ldots,C_{n}\}</annotation></semantics></math>. For each cluster, <math id="S3.SS1.SSS2.p3.13.m13.1" class="ltx_Math" alttext="C_{i}" display="inline"><semantics id="S3.SS1.SSS2.p3.13.m13.1a"><msub id="S3.SS1.SSS2.p3.13.m13.1.1" xref="S3.SS1.SSS2.p3.13.m13.1.1.cmml"><mi id="S3.SS1.SSS2.p3.13.m13.1.1.2" xref="S3.SS1.SSS2.p3.13.m13.1.1.2.cmml">C</mi><mi id="S3.SS1.SSS2.p3.13.m13.1.1.3" xref="S3.SS1.SSS2.p3.13.m13.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p3.13.m13.1b"><apply id="S3.SS1.SSS2.p3.13.m13.1.1.cmml" xref="S3.SS1.SSS2.p3.13.m13.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p3.13.m13.1.1.1.cmml" xref="S3.SS1.SSS2.p3.13.m13.1.1">subscript</csymbol><ci id="S3.SS1.SSS2.p3.13.m13.1.1.2.cmml" xref="S3.SS1.SSS2.p3.13.m13.1.1.2">𝐶</ci><ci id="S3.SS1.SSS2.p3.13.m13.1.1.3.cmml" xref="S3.SS1.SSS2.p3.13.m13.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p3.13.m13.1c">C_{i}</annotation></semantics></math>, select the top-<math id="S3.SS1.SSS2.p3.14.m14.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S3.SS1.SSS2.p3.14.m14.1a"><mi id="S3.SS1.SSS2.p3.14.m14.1.1" xref="S3.SS1.SSS2.p3.14.m14.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p3.14.m14.1b"><ci id="S3.SS1.SSS2.p3.14.m14.1.1.cmml" xref="S3.SS1.SSS2.p3.14.m14.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p3.14.m14.1c">K</annotation></semantics></math> rows or columns based on a specified criterion (<span id="S3.SS1.SSS2.p3.15.3" class="ltx_text ltx_font_italic">e.g.</span>, closeness to centroid). At last, aggregate the chosen rows or columns from all clusters to form <math id="S3.SS1.SSS2.p3.15.m15.1" class="ltx_Math" alttext="T^{\prime}" display="inline"><semantics id="S3.SS1.SSS2.p3.15.m15.1a"><msup id="S3.SS1.SSS2.p3.15.m15.1.1" xref="S3.SS1.SSS2.p3.15.m15.1.1.cmml"><mi id="S3.SS1.SSS2.p3.15.m15.1.1.2" xref="S3.SS1.SSS2.p3.15.m15.1.1.2.cmml">T</mi><mo id="S3.SS1.SSS2.p3.15.m15.1.1.3" xref="S3.SS1.SSS2.p3.15.m15.1.1.3.cmml">′</mo></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p3.15.m15.1b"><apply id="S3.SS1.SSS2.p3.15.m15.1.1.cmml" xref="S3.SS1.SSS2.p3.15.m15.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p3.15.m15.1.1.1.cmml" xref="S3.SS1.SSS2.p3.15.m15.1.1">superscript</csymbol><ci id="S3.SS1.SSS2.p3.15.m15.1.1.2.cmml" xref="S3.SS1.SSS2.p3.15.m15.1.1.2">𝑇</ci><ci id="S3.SS1.SSS2.p3.15.m15.1.1.3.cmml" xref="S3.SS1.SSS2.p3.15.m15.1.1.3">′</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p3.15.m15.1c">T^{\prime}</annotation></semantics></math>.</p>
</div>
</section>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2. </span>Table Augmentation</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">Table augmentation has emerged as a crucial approach in navigating the challenges associated with the intricate and varied nature of tabular data. Two primary benefits arise from this approach. <span id="S3.SS2.p1.1.1" class="ltx_text ltx_font_bold">Firstly</span>,
<span id="S3.SS2.p1.1.2" class="ltx_text ltx_font_italic">Enhanced Contextual Understanding</span>: Raw tables often come without ample context or explicit metadata, such as distribution or dimension/measure categorizations for columns. By supplementing tables with metadata and attributes, we can achieve a more profound grasp of the table’s intrinsic structure and semantics and further enrich the tabular data. <span id="S3.SS2.p1.1.3" class="ltx_text ltx_font_bold">Secondly</span>, <span id="S3.SS2.p1.1.4" class="ltx_text ltx_font_italic">Bridging External Knowledge Gaps</span>: tables alone might not encompass all the required information to provide comprehensive answers to certain queries. By retrieving external knowledge from reliable sources, <span id="S3.SS2.p1.1.5" class="ltx_text ltx_font_italic">e.g.</span>, Wikipedia, we can aid the language models in understanding the broader context of the query, leading to more informed and nuanced responses.
(See the various knowledge aspects used in TAP4LLM from Table <a href="#S3.T1" title="Table 1 ‣ 3.1.1. Rule-based Sampling ‣ 3.1. Table Sampling ‣ 3. TAP4LLM: Table Provider for LLMs ‣ TAP4LLM: Table Provider on Sampling, Augmenting, and Packing Semi-structured Data for Large Language Model Reasoning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.)</p>
</div>
<section id="S3.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.1. </span>Metadata-based Augmentation</h4>

<div id="S3.SS2.SSS1.p1" class="ltx_para">
<p id="S3.SS2.SSS1.p1.1" class="ltx_p">Metadata is defined as a form of background knowledge to understand the field semantics for correctly operating on table fields (or columns) and to further find common patterns in daily analysis <cite class="ltx_cite ltx_citemacro_citep">(He et al<span class="ltx_text">.</span>, <a href="#bib.bib20" title="" class="ltx_ref">2023</a>)</cite>. This analytical knowledge, particularly of field semantics, is able to increase the applicability across various tasks. Specifically, we consider the following metadata-based augmentation types:</p>
</div>
<div id="S3.SS2.SSS1.p2" class="ltx_para">
<p id="S3.SS2.SSS1.p2.1" class="ltx_p">(1) <span id="S3.SS2.SSS1.p2.1.1" class="ltx_text ltx_font_italic">Dimension / Measure</span>: This is one type of metadata used in Tableau <cite class="ltx_cite ltx_citemacro_citep">(Hoelscher and Mortimer, <a href="#bib.bib23" title="" class="ltx_ref">2018</a>)</cite> and Excel <cite class="ltx_cite ltx_citemacro_citep">(Ding et al<span class="ltx_text">.</span>, <a href="#bib.bib14" title="" class="ltx_ref">2019</a>)</cite> across diverse features. As the name suggests, the method involves categorizing each field in a table as either measure or dimension.
The measure contains numerical data that can be subjected to calculations, such as the “Price” and “Discount”. The dimension provides categorical information used for filtering, grouping, and labeling, such as the “Product Name” and “Category”. Correctly classifying fields as either a measure or a dimension is crucial to determining feasible operations on the data and influences the accuracy and relevance of data analysis.</p>
</div>
<div id="S3.SS2.SSS1.p3" class="ltx_para">
<p id="S3.SS2.SSS1.p3.1" class="ltx_p">(2) <span id="S3.SS2.SSS1.p3.1.1" class="ltx_text ltx_font_italic">Semantic Field Type</span>:
Besides identifying whether a field is a measure or a dimension, semantic field type specifies the meaning and format of the data within each field based on knowledge graphs. For example, the dimension field includes semantic field types such as “Consumer Product” and “Category”, <span id="S3.SS2.SSS1.p3.1.2" class="ltx_text ltx_font_italic">etc</span>. Measure field includes semantic field types such as “Money” and “Ratio”, etc. We follow the work  <cite class="ltx_cite ltx_citemacro_citep">(He et al<span class="ltx_text">.</span>, <a href="#bib.bib20" title="" class="ltx_ref">2023</a>)</cite> as a reference to this term.</p>
</div>
<div id="S3.SS2.SSS1.p4" class="ltx_para">
<p id="S3.SS2.SSS1.p4.1" class="ltx_p">(3) <span id="S3.SS2.SSS1.p4.1.1" class="ltx_text ltx_font_italic">Table Size</span>: The size of a table is defined by its number of rows and columns. It provides essential context when determining the computational complexity of operations or understanding data density and granularity.</p>
</div>
<div id="S3.SS2.SSS1.p5" class="ltx_para">
<p id="S3.SS2.SSS1.p5.1" class="ltx_p">(4) <span id="S3.SS2.SSS1.p5.1.1" class="ltx_text ltx_font_italic">Statistics Feature</span>: Statistics feature provides a quantitative representation of the tabular data. These features serve as numerical descriptors that summarize key aspects of the table datasets, aiding LLMs in understanding the overall characteristics and tendencies. Generally, statistics features include four categories <cite class="ltx_cite ltx_citemacro_citep">(He et al<span class="ltx_text">.</span>, <a href="#bib.bib20" title="" class="ltx_ref">2023</a>)</cite>: (a) Progression features (b) String features (c) Number range features (d) Distribution features, discussed in Section §<a href="#S6" title="6. Related Work ‣ TAP4LLM: Table Provider on Sampling, Augmenting, and Packing Semi-structured Data for Large Language Model Reasoning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>. We conducted empirical studies on common statistical features to identify the most appropriate combination for optimal utilization of  TAP4LLM.</p>
</div>
<div id="S3.SS2.SSS1.p6" class="ltx_para">
<p id="S3.SS2.SSS1.p6.1" class="ltx_p">(5) <span id="S3.SS2.SSS1.p6.1.1" class="ltx_text ltx_font_italic">Header Hierarchy</span>: Tables are often used to present data in a structured format, and headers play a crucial role in defining the meaning and context of the data in each column or row. The header hierarchy typically includes different levels of headers, each providing a level of organization and categorization for the data.</p>
</div>
</section>
<section id="S3.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.2. </span>Retrieval-based Augmentation</h4>

<div id="S3.SS2.SSS2.p1" class="ltx_para">
<p id="S3.SS2.SSS2.p1.1" class="ltx_p">Large Language Models have occasionally been observed to generate hallucinated or factually inaccurate text <cite class="ltx_cite ltx_citemacro_citep">(Zhou et al<span class="ltx_text">.</span>, <a href="#bib.bib73" title="" class="ltx_ref">2021</a>; Zhao et al<span class="ltx_text">.</span>, <a href="#bib.bib71" title="" class="ltx_ref">2023</a>)</cite>. To mitigate these issues, several works have proposed to strengthen LLMs with information retrieval systems (retrieval-augmented LLMs) <cite class="ltx_cite ltx_citemacro_citep">(Shi et al<span class="ltx_text">.</span>, <a href="#bib.bib54" title="" class="ltx_ref">2023</a>; Jiang et al<span class="ltx_text">.</span>, <a href="#bib.bib32" title="" class="ltx_ref">2023</a>; Nakano et al<span class="ltx_text">.</span>, <a href="#bib.bib44" title="" class="ltx_ref">2022</a>)</cite>, which enables LLMs to retrieve relevant contents from an external repository (knowledge corpus). It has been verified that retrieval-augmented LLMs can generate texts in response to user input with fewer hallucinations <cite class="ltx_cite ltx_citemacro_citep">(Nakano et al<span class="ltx_text">.</span>, <a href="#bib.bib44" title="" class="ltx_ref">2022</a>)</cite>. Furthermore, by incorporating customized private data resources, retrieval-augmented LLMs can respond to in-domain queries that cannot be answered by LLMs trained with public data. As previous works <cite class="ltx_cite ltx_citemacro_citep">(Nakano et al<span class="ltx_text">.</span>, <a href="#bib.bib44" title="" class="ltx_ref">2022</a>; Shi et al<span class="ltx_text">.</span>, <a href="#bib.bib54" title="" class="ltx_ref">2023</a>; Jiang et al<span class="ltx_text">.</span>, <a href="#bib.bib32" title="" class="ltx_ref">2023</a>)</cite> suggest, LLMs can generate more factual answers by feeding the references retrieved from the external corpus.
In TAP4LLM, we have fortified the document retrieval capabilities of LLMs and consider two components: <span id="S3.SS2.SSS2.p1.1.1" class="ltx_text ltx_font_bold">(i) document references</span>: to provide supplemental relevant web pages as the references for the given table; <span id="S3.SS2.SSS2.p1.1.2" class="ltx_text ltx_font_bold">(ii) term explanation</span>: to explain strange/ambiguous term in the given table. We utilize technologies like vector databases <cite class="ltx_cite ltx_citemacro_citep">(Wang et al<span class="ltx_text">.</span>, <a href="#bib.bib60" title="" class="ltx_ref">2021b</a>)</cite> and LangChain <cite class="ltx_cite ltx_citemacro_citep">(LangChain, <a href="#bib.bib36" title="" class="ltx_ref">2022</a>)</cite> to facilitate the retrieval of pertinent information from Wikipedia<span id="footnote3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span><a target="_blank" href="https://www.wikipedia.org/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.wikipedia.org/</a></span></span></span>.</p>
</div>
<figure id="S3.T2" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2. </span>LLM-based Cell Selection Criteria and Exact Prompt Template.</figcaption>
<div id="S3.T2.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:510.4pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(61.5pt,-72.3pt) scale(1.39569551044071,1.39569551044071) ;">
<table id="S3.T2.1.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T2.1.1.1" class="ltx_tr">
<td id="S3.T2.1.1.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S3.T2.1.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.1.1.1.1.1" class="ltx_p" style="width:65.0pt;">Criteria</span>
</span>
</td>
<td id="S3.T2.1.1.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S3.T2.1.1.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.1.1.2.1.1" class="ltx_p" style="width:218.4pt;">Description</span>
</span>
</td>
</tr>
<tr id="S3.T2.1.1.2" class="ltx_tr">
<td id="S3.T2.1.1.2.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T2.1.1.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.1.2.1.1.1" class="ltx_p" style="width:65.0pt;">Cell Position</span>
</span>
</td>
<td id="S3.T2.1.1.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T2.1.1.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.1.2.2.1.1" class="ltx_p" style="width:218.4pt;">Specify the range or position of the cells you want to search. For example, you may want to search for explanations only in the cells of a specific column, row, or a particular section of the table.</span>
</span>
</td>
</tr>
<tr id="S3.T2.1.1.3" class="ltx_tr">
<td id="S3.T2.1.1.3.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T2.1.1.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.1.3.1.1.1" class="ltx_p" style="width:65.0pt;">Cell Content</span>
</span>
</td>
<td id="S3.T2.1.1.3.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T2.1.1.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.1.3.2.1.1" class="ltx_p" style="width:218.4pt;">Define the specific content or data type within the cells you want to search. For instance, you may want to search for explanations in cells containing numerical values, dates, specific keywords, or a combination of certain words.</span>
</span>
</td>
</tr>
<tr id="S3.T2.1.1.4" class="ltx_tr">
<td id="S3.T2.1.1.4.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T2.1.1.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.1.4.1.1.1" class="ltx_p" style="width:65.0pt;">Cell Formatting</span>
</span>
</td>
<td id="S3.T2.1.1.4.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T2.1.1.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.1.4.2.1.1" class="ltx_p" style="width:218.4pt;">Consider the formatting or styling applied to the cells. This could include searching for explanations in cells with bold or italic text, specific background colors, or cells that are merged or highlighted in a certain way.</span>
</span>
</td>
</tr>
<tr id="S3.T2.1.1.5" class="ltx_tr">
<td id="S3.T2.1.1.5.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T2.1.1.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.1.5.1.1.1" class="ltx_p" style="width:65.0pt;">Cell Context</span>
</span>
</td>
<td id="S3.T2.1.1.5.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T2.1.1.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.1.5.2.1.1" class="ltx_p" style="width:218.4pt;">Take into account the context surrounding the cells. You can search for explanations in cells that are adjacent to certain labels, headings, or identifiers, or within a specific context provided by other cells in the same row or column.</span>
</span>
</td>
</tr>
<tr id="S3.T2.1.1.6" class="ltx_tr">
<td id="S3.T2.1.1.6.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T2.1.1.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.1.6.1.1.1" class="ltx_p" style="width:65.0pt;">Cell Properties</span>
</span>
</td>
<td id="S3.T2.1.1.6.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T2.1.1.6.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.1.6.2.1.1" class="ltx_p" style="width:218.4pt;">Consider any specific properties associated with the cells. This might include searching for explanations in cells that have formulas, links, or other data validation rules applied to them.</span>
</span>
</td>
</tr>
<tr id="S3.T2.1.1.7" class="ltx_tr">
<td id="S3.T2.1.1.7.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S3.T2.1.1.7.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.1.7.1.1.1" class="ltx_p" style="width:65.0pt;"><span id="S3.T2.1.1.7.1.1.1.1" class="ltx_text ltx_font_bold">Prompt</span></span>
</span>
</td>
<td id="S3.T2.1.1.7.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t" style="background-color:#D8E1F3;">
<span id="S3.T2.1.1.7.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.1.7.2.1.1" class="ltx_p" style="width:218.4pt;"><span id="S3.T2.1.1.7.2.1.1.1" class="ltx_text" style="background-color:#D8E1F3;">You will be given a parsed table <span id="S3.T2.1.1.7.2.1.1.1.1" class="ltx_text ltx_font_bold">{Table}</span> in python dictionary format, extract the cells that need to be explained. The extraction rule should be based on the following criteria: <span id="S3.T2.1.1.7.2.1.1.1.2" class="ltx_text ltx_font_bold">{Criteria}</span>. Only return the cells name in a python List[str].</span></span>
</span>
</td>
</tr>
</table>
</span></div>
</figure>
<div id="S3.SS2.SSS2.p2" class="ltx_para">
<p id="S3.SS2.SSS2.p2.1" class="ltx_p">(1) <span id="S3.SS2.SSS2.p2.1.1" class="ltx_text ltx_font_italic">Docs References</span>:
This process involves associating tables with relevant documents or sources for in-depth insights or references.
For example, suppose we have a table titled “2023 Fortune 500 Companies”. This table contains various information about the top 500 companies as ranked by Fortune in 2023, including their revenue, number of employees, and market capitalization. Docs references could fetch the actual 2023 Fortune 500 list from the Fortune website, Wikipedia pages discussing the Fortune 500 concept and its criteria, or analytical articles discussing the companies on the 2023 list.
In our setting, we leverage Langchain <cite class="ltx_cite ltx_citemacro_citep">(LangChain, <a href="#bib.bib36" title="" class="ltx_ref">2022</a>)</cite> to retrieve wiki pages from wikipedia.org. We craft queries by concatenating the table header and the table’s title into a single string. These queries are then used to identify and fetch the relevant Wikipedia pages, which act as informative document references in our study.</p>
</div>
<div id="S3.SS2.SSS2.p3" class="ltx_para">
<p id="S3.SS2.SSS2.p3.1" class="ltx_p">(2) <span id="S3.SS2.SSS2.p3.1.1" class="ltx_text ltx_font_italic">Term Explanation</span>:
Compared to the docs references, term explanation focuses on providing definitions and explanations for specific strange terms or values in the table cells. For example, if a cell mentions a technical term or an acronym, the term explanation module could source a brief definition or background from reliable web sources (such as Wikipedia, wolfram,<span id="S3.SS2.SSS2.p3.1.2" class="ltx_text ltx_font_italic">etc</span>) on that term, ensuring that the strange term will not be forwarded to LLMs. To ensure the efficacy and accuracy of term explanations, we introduce two distinct approaches for selecting the cell that is required to be explained:
<span id="S3.SS2.SSS2.p3.1.3" class="ltx_text ltx_font_italic">i) LLM-based Cell Selection Module</span>:
To pinpoint the exact cell warranting explanation, we harness the capabilities of LLMs. The selection prompt is meticulously constructed, taking into account various factors including:
(1) Cell Position;
(2) Cell Content;
(3) Cell Formatting;
(4) Cell Context;
(5) Cell Properties.
A detailed description and the specific prompt utilized to determine which cells require explanation can be found in Table <a href="#S3.T2" title="Table 2 ‣ 3.2.2. Retrieval-based Augmentation ‣ 3.2. Table Augmentation ‣ 3. TAP4LLM: Table Provider for LLMs ‣ TAP4LLM: Table Provider on Sampling, Augmenting, and Packing Semi-structured Data for Large Language Model Reasoning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.
<span id="S3.SS2.SSS2.p3.1.4" class="ltx_text ltx_font_italic">ii) Heuristics-based Cell Selection</span>:
Inspired by the methodology presented in <cite class="ltx_cite ltx_citemacro_citep">(Herzig et al<span class="ltx_text">.</span>, <a href="#bib.bib21" title="" class="ltx_ref">2020</a>)</cite>, we introduce a heuristics-based cell selection, which is predicated upon the following criteria:
(1) Explicit Mention: whether the cell’s value is explicitly referenced in the query.
(2) Comparative Value: whether the cell’s value is greater or less than a value mentioned in the query.
(3) Superlative Value: whether the cell’s value represents a maximum or minimum across the entire column, especially when the query incorporates superlative terms.
The comparative experiment results of these two variants can be found in Table <a href="#S4.T6" title="Table 6 ‣ 4.3. Comparison Results of Table Augmentation. ‣ 4. Experiments ‣ TAP4LLM: Table Provider on Sampling, Augmenting, and Packing Semi-structured Data for Large Language Model Reasoning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>.</p>
</div>
</section>
<section id="S3.SS2.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.3. </span>Self-consistency-based Augmentation</h4>

<div id="S3.SS2.SSS3.p1" class="ltx_para">
<p id="S3.SS2.SSS3.p1.1" class="ltx_p">We follow <cite class="ltx_cite ltx_citemacro_citep">(Sui et al<span class="ltx_text">.</span>, <a href="#bib.bib55" title="" class="ltx_ref">2023</a>)</cite> to provide the self-consistency-based augmentation approach. First, we append the instruction “Identify critical values and ranges of the last table related to the statement” to the initial prompt, and then forward this prompt to the LLM. The output generated from this instruction is then incorporated back into the prompt. Following this, we reintroduce the enriched prompt, now containing both the initial query and the newly generated insights, to the LLM along with the task-specific instructions for further processing. This iterative approach, namely <span id="S3.SS2.SSS3.p1.1.1" class="ltx_text ltx_font_italic">self Prompting</span>, allows for a deeper contextual understanding and analysis by LLMs.
Formally, self-prompting is a simple idea that utilizes prompting twice to leverage the capabilities of LLMs in understanding structured data. In essence, through this self-consistency-based augmentation, we seek to harness and amplify the latent structured data reasoning prowess of LLMs.</p>
</div>
</section>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3. </span>Table Packing</h3>

<figure id="S3.T3" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3. </span>The distribution of the used datasets.</figcaption>
<table id="S3.T3.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S3.T3.1.1" class="ltx_tr">
<td id="S3.T3.1.1.1" class="ltx_td ltx_align_left ltx_border_tt">Property</td>
<td id="S3.T3.1.1.2" class="ltx_td ltx_align_center ltx_border_tt">SQA</td>
<td id="S3.T3.1.1.3" class="ltx_td ltx_align_center ltx_border_tt">FEVEROUS</td>
<td id="S3.T3.1.1.4" class="ltx_td ltx_align_center ltx_border_tt">TabFact</td>
<td id="S3.T3.1.1.5" class="ltx_td ltx_align_center ltx_border_tt">HybridQA</td>
<td id="S3.T3.1.1.6" class="ltx_td ltx_align_center ltx_border_tt">ToTTo</td>
<td id="S3.T3.1.1.7" class="ltx_td ltx_align_center ltx_border_tt">Spider</td>
</tr>
<tr id="S3.T3.1.2" class="ltx_tr">
<td id="S3.T3.1.2.1" class="ltx_td ltx_align_left ltx_border_t">Unique Query (Set Size)</td>
<td id="S3.T3.1.2.2" class="ltx_td ltx_align_center ltx_border_t">1,228</td>
<td id="S3.T3.1.2.3" class="ltx_td ltx_align_center ltx_border_t">1,322</td>
<td id="S3.T3.1.2.4" class="ltx_td ltx_align_center ltx_border_t">9,228</td>
<td id="S3.T3.1.2.5" class="ltx_td ltx_align_center ltx_border_t">6,268</td>
<td id="S3.T3.1.2.6" class="ltx_td ltx_align_center ltx_border_t">8,026</td>
<td id="S3.T3.1.2.7" class="ltx_td ltx_align_center ltx_border_t">10,181</td>
</tr>
<tr id="S3.T3.1.3" class="ltx_tr">
<td id="S3.T3.1.3.1" class="ltx_td ltx_align_left">Unique Table</td>
<td id="S3.T3.1.3.2" class="ltx_td ltx_align_center">432</td>
<td id="S3.T3.1.3.3" class="ltx_td ltx_align_center">942</td>
<td id="S3.T3.1.3.4" class="ltx_td ltx_align_center">1,342</td>
<td id="S3.T3.1.3.5" class="ltx_td ltx_align_center">4,364</td>
<td id="S3.T3.1.3.6" class="ltx_td ltx_align_center">5,934</td>
<td id="S3.T3.1.3.7" class="ltx_td ltx_align_center">500</td>
</tr>
<tr id="S3.T3.1.4" class="ltx_tr">
<td id="S3.T3.1.4.1" class="ltx_td ltx_align_left">SQL Query</td>
<td id="S3.T3.1.4.2" class="ltx_td ltx_align_center">-</td>
<td id="S3.T3.1.4.3" class="ltx_td ltx_align_center">-</td>
<td id="S3.T3.1.4.4" class="ltx_td ltx_align_center">-</td>
<td id="S3.T3.1.4.5" class="ltx_td ltx_align_center">-</td>
<td id="S3.T3.1.4.6" class="ltx_td ltx_align_center">-</td>
<td id="S3.T3.1.4.7" class="ltx_td ltx_align_center">5,693</td>
</tr>
<tr id="S3.T3.1.5" class="ltx_tr">
<td id="S3.T3.1.5.1" class="ltx_td ltx_align_left">Rows per tables (Median/Avg)</td>
<td id="S3.T3.1.5.2" class="ltx_td ltx_align_center">12 / 18.5</td>
<td id="S3.T3.1.5.3" class="ltx_td ltx_align_center">14 / 26.3</td>
<td id="S3.T3.1.5.4" class="ltx_td ltx_align_center">8 / 14.0</td>
<td id="S3.T3.1.5.5" class="ltx_td ltx_align_center">8 / 15.7</td>
<td id="S3.T3.1.5.6" class="ltx_td ltx_align_center">16 / 28.4</td>
<td id="S3.T3.1.5.7" class="ltx_td ltx_align_center">10 / 16.1</td>
</tr>
<tr id="S3.T3.1.6" class="ltx_tr">
<td id="S3.T3.1.6.1" class="ltx_td ltx_align_left">Columns per tables (Median/Avg)</td>
<td id="S3.T3.1.6.2" class="ltx_td ltx_align_center">4 / 6.4</td>
<td id="S3.T3.1.6.3" class="ltx_td ltx_align_center">4 / 5.5</td>
<td id="S3.T3.1.6.4" class="ltx_td ltx_align_center">4 / 5.5</td>
<td id="S3.T3.1.6.5" class="ltx_td ltx_align_center">4 / 4.3</td>
<td id="S3.T3.1.6.6" class="ltx_td ltx_align_center">6 / 8.8</td>
<td id="S3.T3.1.6.7" class="ltx_td ltx_align_center">4 / 4.5</td>
</tr>
<tr id="S3.T3.1.7" class="ltx_tr">
<td id="S3.T3.1.7.1" class="ltx_td ltx_align_left">Cells per tables (Median/Avg)</td>
<td id="S3.T3.1.7.2" class="ltx_td ltx_align_center">78 / 180.4</td>
<td id="S3.T3.1.7.3" class="ltx_td ltx_align_center">77 / 190.3</td>
<td id="S3.T3.1.7.4" class="ltx_td ltx_align_center">80 / 150.3</td>
<td id="S3.T3.1.7.5" class="ltx_td ltx_align_center">70 / 143.9</td>
<td id="S3.T3.1.7.6" class="ltx_td ltx_align_center">87 / 212.6</td>
<td id="S3.T3.1.7.7" class="ltx_td ltx_align_center">-</td>
</tr>
<tr id="S3.T3.1.8" class="ltx_tr">
<td id="S3.T3.1.8.1" class="ltx_td ltx_align_left ltx_border_t">Domain</td>
<td id="S3.T3.1.8.2" class="ltx_td ltx_align_center ltx_border_t">Wikipedia</td>
<td id="S3.T3.1.8.3" class="ltx_td ltx_align_center ltx_border_t">Wikipedia</td>
<td id="S3.T3.1.8.4" class="ltx_td ltx_align_center ltx_border_t">Wikipedia</td>
<td id="S3.T3.1.8.5" class="ltx_td ltx_align_center ltx_border_t">Wikipedia</td>
<td id="S3.T3.1.8.6" class="ltx_td ltx_align_center ltx_border_t">Wikipedia</td>
<td id="S3.T3.1.8.7" class="ltx_td ltx_align_center ltx_border_t">Wikipedia</td>
</tr>
<tr id="S3.T3.1.9" class="ltx_tr">
<td id="S3.T3.1.9.1" class="ltx_td ltx_align_left ltx_border_bb">Evaluation Metric</td>
<td id="S3.T3.1.9.2" class="ltx_td ltx_align_center ltx_border_bb">Exact Match</td>
<td id="S3.T3.1.9.3" class="ltx_td ltx_align_center ltx_border_bb">Exact Match</td>
<td id="S3.T3.1.9.4" class="ltx_td ltx_align_center ltx_border_bb">Exact Match</td>
<td id="S3.T3.1.9.5" class="ltx_td ltx_align_center ltx_border_bb">Exact Match</td>
<td id="S3.T3.1.9.6" class="ltx_td ltx_align_center ltx_border_bb">BLEU-4</td>
<td id="S3.T3.1.9.7" class="ltx_td ltx_align_center ltx_border_bb">Exact Match</td>
</tr>
</table>
</figure>
<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.4" class="ltx_p">Table Packing takes the pre-processed table <math id="S3.SS3.p1.1.m1.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S3.SS3.p1.1.m1.1a"><mi id="S3.SS3.p1.1.m1.1.1" xref="S3.SS3.p1.1.m1.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.1.m1.1b"><ci id="S3.SS3.p1.1.m1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1">𝑇</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.1.m1.1c">T</annotation></semantics></math> as the input and returns table serialization and packing function to convert a table into a sequence.
One of the significant limitations of current LLMs, besides, hallucination and instability, is their severe input limits. Most LLMs can only handle 4<math id="S3.SS3.p1.2.m2.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S3.SS3.p1.2.m2.1a"><mi id="S3.SS3.p1.2.m2.1.1" xref="S3.SS3.p1.2.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.2.m2.1b"><ci id="S3.SS3.p1.2.m2.1.1.cmml" xref="S3.SS3.p1.2.m2.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.2.m2.1c">k</annotation></semantics></math>~16<math id="S3.SS3.p1.3.m3.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S3.SS3.p1.3.m3.1a"><mi id="S3.SS3.p1.3.m3.1.1" xref="S3.SS3.p1.3.m3.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.3.m3.1b"><ci id="S3.SS3.p1.3.m3.1.1.cmml" xref="S3.SS3.p1.3.m3.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.3.m3.1c">k</annotation></semantics></math> tokens, as seen in models like GPT-3.5 <cite class="ltx_cite ltx_citemacro_citep">(Brown et al<span class="ltx_text">.</span>, <a href="#bib.bib7" title="" class="ltx_ref">2020</a>)</cite>. Some selected LLMs like GPT-4 <cite class="ltx_cite ltx_citemacro_citep">(OpenAI, <a href="#bib.bib47" title="" class="ltx_ref">2023</a>)</cite> can process up to 32<math id="S3.SS3.p1.4.m4.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S3.SS3.p1.4.m4.1a"><mi id="S3.SS3.p1.4.m4.1.1" xref="S3.SS3.p1.4.m4.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.4.m4.1b"><ci id="S3.SS3.p1.4.m4.1.1.cmml" xref="S3.SS3.p1.4.m4.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.4.m4.1c">k</annotation></semantics></math> tokens input. However, this limitation becomes apparent when processing large tables, which often exceeds these token limitations by a substantial margin.
Recently, Anthropic’s Claude 2<span id="footnote4" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span><a target="_blank" href="https://www.anthropic.com/index/claude-2" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.anthropic.com/index/claude-2</a></span></span></span>, a newer generation of LLMs, boasts significantly higher token limitations of up to 100,000 tokens. The advancement allows up to input the entire table to the LLM all at once. However, the performance of these models scales inversely with prompt size and happens across most LLMs architectures.
The desire to maintain efficient reasoning without changing the LLMs architecture motivates us to propose the <span id="S3.SS3.p1.4.1" class="ltx_text ltx_font_italic">token allocations</span> module.
The packing component supports token-limit allocation for table sampling and augmentation. We conduct an empirical study to determine the proper proportion of the sub-table length and augmentation information length, as shown in Figure <a href="#S4.F3" title="Figure 3 ‣ 4.6. Trade-offs between token allocation ‣ 4. Experiments ‣ TAP4LLM: Table Provider on Sampling, Augmenting, and Packing Semi-structured Data for Large Language Model Reasoning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>. The packing process is controlled by a user-defined parameter token limit, which determines the maximum truncate token length.</p>
</div>
<div id="S3.SS3.p2" class="ltx_para">
<p id="S3.SS3.p2.1" class="ltx_p">Moreover, our empirical study <cite class="ltx_cite ltx_citemacro_citep">(Sui et al<span class="ltx_text">.</span>, <a href="#bib.bib55" title="" class="ltx_ref">2023</a>)</cite> emphasizes a noteworthy observation regarding using markup languages like <span id="S3.SS3.p2.1.1" class="ltx_text ltx_font_italic">HTML</span> or <span id="S3.SS3.p2.1.2" class="ltx_text ltx_font_italic">XML</span> leads to much better generation quality by LLMs over TQA and TFV.
In this pattern, TAP4LLM support multiple serialization functions, <span id="S3.SS3.p2.1.3" class="ltx_text ltx_font_italic">e.g.</span>, HTML, XML, JSON, CSV, NL+Sep (one of the typical options, <span id="S3.SS3.p2.1.4" class="ltx_text ltx_font_italic">e.g.</span>, using ‘<math id="S3.SS3.p2.1.m1.1" class="ltx_Math" alttext="|" display="inline"><semantics id="S3.SS3.p2.1.m1.1a"><mo fence="false" stretchy="false" id="S3.SS3.p2.1.m1.1.1" xref="S3.SS3.p2.1.m1.1.1.cmml">|</mo><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.1.m1.1b"><ci id="S3.SS3.p2.1.m1.1.1.cmml" xref="S3.SS3.p2.1.m1.1.1">|</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.1.m1.1c">|</annotation></semantics></math>’ as cell/column separator) and Markdown,<span id="S3.SS3.p2.1.5" class="ltx_text ltx_font_italic">etc</span>.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4. </span>Experiments</h2>

<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1. </span>Experiment Settings</h3>

<section id="S4.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.1. </span>Downstream Tasks and Datasets</h4>

<div id="S4.SS1.SSS1.p1" class="ltx_para">
<p id="S4.SS1.SSS1.p1.1" class="ltx_p">In this paper, we mainly focus on tabular reasoning with two major tasks: TQA &amp; TFV. We conduct experiments on five typical datasets and the distribution of the datasets can be found in Table <a href="#S3.T3" title="Table 3 ‣ 3.3. Table Packing ‣ 3. TAP4LLM: Table Provider for LLMs ‣ TAP4LLM: Table Provider on Sampling, Augmenting, and Packing Semi-structured Data for Large Language Model Reasoning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>. In addition, to extend our work to databases containing table structures, we also set up  TAP4LLM on Spider  <cite class="ltx_cite ltx_citemacro_citep">(Yu et al<span class="ltx_text">.</span>, <a href="#bib.bib67" title="" class="ltx_ref">2018</a>)</cite> dataset.
Specifically, we use:
(1) <span id="S4.SS1.SSS1.p1.1.1" class="ltx_text ltx_font_bold">SQA</span>, which is constructed by decomposing a subset of a highly compositional dataset, WTQ <cite class="ltx_cite ltx_citemacro_citep">(Pasupat and Liang, <a href="#bib.bib49" title="" class="ltx_ref">2015</a>)</cite>. The dataset consists of 1,288 unique queries corresponding to 432 tables, with each table having 18.5 rows and 6.4 columns on average;
(2) <span id="S4.SS1.SSS1.p1.1.2" class="ltx_text ltx_font_bold">HybridQA</span>, which is designed as a large-scale multi-hop question-answering dataset over heterogeneous information of both structured tabular and unstructured textual forms. The dataset consists of 6,268 unique questions and each question is aligned with a Wikipedia table. Compared to the SQA dataset, HybridQA has shorter column numbers, which facilitates the understanding of the table’s structure boundaries.
(3) <span id="S4.SS1.SSS1.p1.1.3" class="ltx_text ltx_font_bold">ToTTo</span> is a high-quality English table-to-text dataset.
It proposes a controlled generation task that involves synthesizing a one-sentence description given a Wikipedia table and a set of highlighted table cells. The dataset contains 8,026 samples, each comprising a Wikipedia table with highlighted cells. Each table contains 16 rows and 6 columns on average.
(4) <span id="S4.SS1.SSS1.p1.1.4" class="ltx_text ltx_font_bold">FEVEROUS</span> is a fact verification dataset over structured information. The dataset consists of 1,322 verified claims. Each claim is annotated with evidence in the form of sentences and cells from tables in Wikipedia. Each annotation also includes a label indicating whether the evidence supports, refutes, or does not provide enough information to make a decision. Each table contains 26.3 rows and 5.5 columns on average.
(5) <span id="S4.SS1.SSS1.p1.1.5" class="ltx_text ltx_font_bold">TabFact</span> is another fact verification dataset where the tables are extracted from Wikipedia and the sentences are composed by crowd workers. Compared to the FEVEROUS dataset, TabFact encompasses a larger number of samples and each table has fewer rows, has 14 rows per table on average.
(6) <span id="S4.SS1.SSS1.p1.1.6" class="ltx_text ltx_font_bold">Spider</span> is a semantic parsing text-to-SQL dataset across multiple domains. The dataset consists of 10,181 questions and 5,693 unique complex SQL queries on 200 databases with multiple tables.</p>
</div>
</section>
<section id="S4.SS1.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.2. </span>Models</h4>

<div id="S4.SS1.SSS2.p1" class="ltx_para">
<p id="S4.SS1.SSS2.p1.1" class="ltx_p">In this study, we evaluate the performance of the recent dominant LLM models, 1) Instruct-GPT-3.5 <cite class="ltx_cite ltx_citemacro_citep">(Ouyang et al<span class="ltx_text">.</span>, <a href="#bib.bib48" title="" class="ltx_ref">2022</a>)</cite>, using versions gpt-3.5-turbo, gpt-3.5-turbo-16k; 2) GPT-4, using the latest version of gpt-4 model. Unless otherwise specified, we utilize <span id="S4.SS1.SSS2.p1.1.1" class="ltx_text ltx_font_bold">gpt-3.5-turbo</span> in all experiments.
In the sampling methods, we use text-embedding-ada-002 <cite class="ltx_cite ltx_citemacro_citep">(ope, <a href="#bib.bib2" title="" class="ltx_ref">[n.d.]</a>)</cite> for row and query embedding generation.
The comparison experiments using other embeddings models, such as, text-search-ada-doc-001, bge-largen-en <cite class="ltx_cite ltx_citemacro_citep">(Xiao et al<span class="ltx_text">.</span>, <a href="#bib.bib63" title="" class="ltx_ref">2023</a>)</cite>, all-MinLM-L6-v2 <cite class="ltx_cite ltx_citemacro_citep">(Reimers and Gurevych, <a href="#bib.bib52" title="" class="ltx_ref">2019</a>)</cite> can be found in Table <a href="#S4.T7" title="Table 7 ‣ 4.4. Comparison Results of Embedding Type. ‣ 4. Experiments ‣ TAP4LLM: Table Provider on Sampling, Augmenting, and Packing Semi-structured Data for Large Language Model Reasoning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>.
The development of TAP4LLM begins with the foundation provided by LLMs. In designing our framework, we opt to use OpenAI models as our base model due to their excellent capabilities in language reasoning. However, the choice is not exclusive. Since TAP4LLM use natural language as an intermediary for interactive communication between the table and LLMs, it can also support other outstanding open-sourced models using natural language as input, such as LLaMa <cite class="ltx_cite ltx_citemacro_citep">(Touvron et al<span class="ltx_text">.</span>, <a href="#bib.bib57" title="" class="ltx_ref">2023</a>)</cite>, Phoenix <cite class="ltx_cite ltx_citemacro_citep">(Chen et al<span class="ltx_text">.</span>, <a href="#bib.bib11" title="" class="ltx_ref">2023</a>)</cite>, ChatGLM <cite class="ltx_cite ltx_citemacro_citep">(Zeng et al<span class="ltx_text">.</span>, <a href="#bib.bib68" title="" class="ltx_ref">2022</a>)</cite>, Ziya <cite class="ltx_cite ltx_citemacro_citep">(IDEA-CCNL, <a href="#bib.bib27" title="" class="ltx_ref">2023</a>)</cite>, and Baichuan <cite class="ltx_cite ltx_citemacro_citep">(Intelligence, <a href="#bib.bib29" title="" class="ltx_ref">2023</a>)</cite>. This design provides versatility and flexibility in TAP4LLM implementation.</p>
</div>
<figure id="S4.T4" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 4. </span>Comparative results of the table sampling methods. The term “w/ Column Grounding” refers to the method consider both row-based and column-based sampling (sometimes referred to as “grounding”). “GPT-3.5” refers to the OpenAI released model gpt-3.5-turbo-32k, with 32k token-sized context window; In contrast, “GPT-3.5 truncated” refers to gpt-3.5-turbo, with 4k token-sized context window, where most tables will be truncated according to this token limitation. The top-3 performances on each dataset are highlighted in green, with the best performance being both bold and underlined.
</figcaption>
<table id="S4.T4.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S4.T4.1.1" class="ltx_tr">
<td id="S4.T4.1.1.1" class="ltx_td ltx_align_center ltx_border_tt">Table Samping Methods</td>
<td id="S4.T4.1.1.2" class="ltx_td ltx_align_center ltx_border_tt">SQA</td>
<td id="S4.T4.1.1.3" class="ltx_td ltx_align_center ltx_border_tt">FEVEROUS</td>
<td id="S4.T4.1.1.4" class="ltx_td ltx_align_center ltx_border_tt">TabFact</td>
<td id="S4.T4.1.1.5" class="ltx_td ltx_align_center ltx_border_tt">HybridQA</td>
<td id="S4.T4.1.1.6" class="ltx_td ltx_align_center ltx_border_tt">ToTTo</td>
<td id="S4.T4.1.1.7" class="ltx_td ltx_align_center ltx_border_tt">Spider</td>
</tr>
<tr id="S4.T4.1.2" class="ltx_tr">
<td id="S4.T4.1.2.1" class="ltx_td ltx_align_left ltx_border_t">Clustering-based Sampling</td>
<td id="S4.T4.1.2.2" class="ltx_td ltx_align_center ltx_border_t">28.10%</td>
<td id="S4.T4.1.2.3" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#C6EFCE;"><span id="S4.T4.1.2.3.1" class="ltx_text" style="color:#006100;background-color:#C6EFCE;">63.50%</span></td>
<td id="S4.T4.1.2.4" class="ltx_td ltx_align_center ltx_border_t">55.40%</td>
<td id="S4.T4.1.2.5" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#C6EFCE;"><span id="S4.T4.1.2.5.1" class="ltx_text" style="color:#006100;background-color:#C6EFCE;">24.03%</span></td>
<td id="S4.T4.1.2.6" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#C6EFCE;"><span id="S4.T4.1.2.6.1" class="ltx_text" style="color:#006100;background-color:#C6EFCE;">48.30%</span></td>
<td id="S4.T4.1.2.7" class="ltx_td ltx_align_center ltx_border_t">77.43%</td>
</tr>
<tr id="S4.T4.1.3" class="ltx_tr">
<td id="S4.T4.1.3.1" class="ltx_td ltx_align_left">Query-based Sampling</td>
<td id="S4.T4.1.3.2" class="ltx_td ltx_align_center" style="background-color:#C6EFCE;"><span id="S4.T4.1.3.2.1" class="ltx_text" style="color:#006100;background-color:#C6EFCE;">28.32%</span></td>
<td id="S4.T4.1.3.3" class="ltx_td ltx_align_center" style="background-color:#C6EFCE;"><span id="S4.T4.1.3.3.1" class="ltx_text" style="color:#006100;background-color:#C6EFCE;">63.32%</span></td>
<td id="S4.T4.1.3.4" class="ltx_td ltx_align_center" style="background-color:#C6EFCE;"><span id="S4.T4.1.3.4.1" class="ltx_text" style="color:#006100;background-color:#C6EFCE;">59.80%</span></td>
<td id="S4.T4.1.3.5" class="ltx_td ltx_align_center" style="background-color:#C6EFCE;"><span id="S4.T4.1.3.5.1" class="ltx_text" style="color:#006100;background-color:#C6EFCE;">24.32%</span></td>
<td id="S4.T4.1.3.6" class="ltx_td ltx_align_center" style="background-color:#C6EFCE;"><span id="S4.T4.1.3.6.1" class="ltx_text" style="color:#006100;background-color:#C6EFCE;">49.14%</span></td>
<td id="S4.T4.1.3.7" class="ltx_td ltx_align_center" style="background-color:#C6EFCE;"><span id="S4.T4.1.3.7.1" class="ltx_text" style="color:#006100;background-color:#C6EFCE;">80.27%</span></td>
</tr>
<tr id="S4.T4.1.4" class="ltx_tr">
<td id="S4.T4.1.4.1" class="ltx_td ltx_align_left">    w/ Column Grounding</td>
<td id="S4.T4.1.4.2" class="ltx_td ltx_align_center" style="background-color:#C6EFCE;"><span id="S4.T4.1.4.2.1" class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" style="color:#006100;background-color:#C6EFCE;">29.12%</span></td>
<td id="S4.T4.1.4.3" class="ltx_td ltx_align_center" style="background-color:#C6EFCE;"><span id="S4.T4.1.4.3.1" class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" style="color:#006100;background-color:#C6EFCE;">64.74%</span></td>
<td id="S4.T4.1.4.4" class="ltx_td ltx_align_center" style="background-color:#C6EFCE;"><span id="S4.T4.1.4.4.1" class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" style="color:#006100;background-color:#C6EFCE;">60.23%</span></td>
<td id="S4.T4.1.4.5" class="ltx_td ltx_align_center" style="background-color:#C6EFCE;"><span id="S4.T4.1.4.5.1" class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" style="color:#006100;background-color:#C6EFCE;">25.14%</span></td>
<td id="S4.T4.1.4.6" class="ltx_td ltx_align_center" style="background-color:#C6EFCE;"><span id="S4.T4.1.4.6.1" class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" style="color:#006100;background-color:#C6EFCE;">53.42%</span></td>
<td id="S4.T4.1.4.7" class="ltx_td ltx_align_center" style="background-color:#C6EFCE;"><span id="S4.T4.1.4.7.1" class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" style="color:#006100;background-color:#C6EFCE;">81.03%</span></td>
</tr>
<tr id="S4.T4.1.5" class="ltx_tr">
<td id="S4.T4.1.5.1" class="ltx_td ltx_align_left">Random Sampling</td>
<td id="S4.T4.1.5.2" class="ltx_td ltx_align_center">27.30%</td>
<td id="S4.T4.1.5.3" class="ltx_td ltx_align_center">60.30%</td>
<td id="S4.T4.1.5.4" class="ltx_td ltx_align_center">55.17%</td>
<td id="S4.T4.1.5.5" class="ltx_td ltx_align_center">23.60%</td>
<td id="S4.T4.1.5.6" class="ltx_td ltx_align_center">40.12%</td>
<td id="S4.T4.1.5.7" class="ltx_td ltx_align_center">74.58%</td>
</tr>
<tr id="S4.T4.1.6" class="ltx_tr">
<td id="S4.T4.1.6.1" class="ltx_td ltx_align_left">Evenly Sampling</td>
<td id="S4.T4.1.6.2" class="ltx_td ltx_align_center">26.72%</td>
<td id="S4.T4.1.6.3" class="ltx_td ltx_align_center">61.87%</td>
<td id="S4.T4.1.6.4" class="ltx_td ltx_align_center">54.63%</td>
<td id="S4.T4.1.6.5" class="ltx_td ltx_align_center">5.32%</td>
<td id="S4.T4.1.6.6" class="ltx_td ltx_align_center">29.41%</td>
<td id="S4.T4.1.6.7" class="ltx_td ltx_align_center">72.03%</td>
</tr>
<tr id="S4.T4.1.7" class="ltx_tr">
<td id="S4.T4.1.7.1" class="ltx_td ltx_align_left">Content Snapshot</td>
<td id="S4.T4.1.7.2" class="ltx_td ltx_align_center" style="background-color:#C6EFCE;"><span id="S4.T4.1.7.2.1" class="ltx_text" style="color:#006100;background-color:#C6EFCE;">28.24%</span></td>
<td id="S4.T4.1.7.3" class="ltx_td ltx_align_center">63.10%</td>
<td id="S4.T4.1.7.4" class="ltx_td ltx_align_center" style="background-color:#C6EFCE;"><span id="S4.T4.1.7.4.1" class="ltx_text" style="color:#006100;background-color:#C6EFCE;">56.92%</span></td>
<td id="S4.T4.1.7.5" class="ltx_td ltx_align_center">23.40%</td>
<td id="S4.T4.1.7.6" class="ltx_td ltx_align_center">47.51%</td>
<td id="S4.T4.1.7.7" class="ltx_td ltx_align_center" style="background-color:#C6EFCE;"><span id="S4.T4.1.7.7.1" class="ltx_text" style="color:#006100;background-color:#C6EFCE;">78.93%</span></td>
</tr>
<tr id="S4.T4.1.8" class="ltx_tr">
<td id="S4.T4.1.8.1" class="ltx_td ltx_align_left ltx_border_t">No sampling (GPT-3.5)</td>
<td id="S4.T4.1.8.2" class="ltx_td ltx_align_center ltx_border_t">27.60%</td>
<td id="S4.T4.1.8.3" class="ltx_td ltx_align_center ltx_border_t">60.12%</td>
<td id="S4.T4.1.8.4" class="ltx_td ltx_align_center ltx_border_t">56.20%</td>
<td id="S4.T4.1.8.5" class="ltx_td ltx_align_center ltx_border_t">14.10%</td>
<td id="S4.T4.1.8.6" class="ltx_td ltx_align_center ltx_border_t">47.42%</td>
<td id="S4.T4.1.8.7" class="ltx_td ltx_align_center ltx_border_t">72.15%</td>
</tr>
<tr id="S4.T4.1.9" class="ltx_tr">
<td id="S4.T4.1.9.1" class="ltx_td ltx_align_left ltx_border_bb">No sampling (GPT-3.5, truncated)</td>
<td id="S4.T4.1.9.2" class="ltx_td ltx_align_center ltx_border_bb">23.54%</td>
<td id="S4.T4.1.9.3" class="ltx_td ltx_align_center ltx_border_bb">43.54%</td>
<td id="S4.T4.1.9.4" class="ltx_td ltx_align_center ltx_border_bb">52.12%</td>
<td id="S4.T4.1.9.5" class="ltx_td ltx_align_center ltx_border_bb">23.12%</td>
<td id="S4.T4.1.9.6" class="ltx_td ltx_align_center ltx_border_bb">30.42%</td>
<td id="S4.T4.1.9.7" class="ltx_td ltx_align_center ltx_border_bb">68.47%</td>
</tr>
</table>
</figure>
<figure id="S4.T5" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 5. </span>Comparative results of the table augmentation methods. We use query-based sampling method (no augmentation) as the baseline. The term “Delta” refers to the performance gap between each method and the baseline. The top-3 performance gap on each dataset are highlighted in green, with the best performance being underlined. Noted that since only the Totto dataset contains hierarchical headers, we only provide the “header hierarchy” method on this dataset.</figcaption>
<div id="S4.T5.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:110.4pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-136.7pt,34.8pt) scale(0.613226329053525,0.613226329053525) ;">
<table id="S4.T5.1.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T5.1.1.1" class="ltx_tr">
<td id="S4.T5.1.1.1.1" class="ltx_td ltx_align_center ltx_border_tt" rowspan="2"><span id="S4.T5.1.1.1.1.1" class="ltx_text">Table Augmentation Methods</span></td>
<td id="S4.T5.1.1.1.2" class="ltx_td ltx_align_center ltx_border_tt" colspan="2">SQA</td>
<td id="S4.T5.1.1.1.3" class="ltx_td ltx_align_center ltx_border_tt" colspan="2">FEVEROUS</td>
<td id="S4.T5.1.1.1.4" class="ltx_td ltx_align_center ltx_border_tt" colspan="2">TabFact</td>
<td id="S4.T5.1.1.1.5" class="ltx_td ltx_align_center ltx_border_tt" colspan="2">HybridQA</td>
<td id="S4.T5.1.1.1.6" class="ltx_td ltx_align_center ltx_border_tt" colspan="2">ToTTo</td>
<td id="S4.T5.1.1.1.7" class="ltx_td ltx_align_center ltx_border_tt" colspan="2">Spider</td>
</tr>
<tr id="S4.T5.1.1.2" class="ltx_tr">
<td id="S4.T5.1.1.2.1" class="ltx_td ltx_align_center ltx_border_t">Acc</td>
<td id="S4.T5.1.1.2.2" class="ltx_td ltx_align_center ltx_border_t">Delta</td>
<td id="S4.T5.1.1.2.3" class="ltx_td ltx_align_center ltx_border_t">Acc</td>
<td id="S4.T5.1.1.2.4" class="ltx_td ltx_align_center ltx_border_t">Delta</td>
<td id="S4.T5.1.1.2.5" class="ltx_td ltx_align_center ltx_border_t">Acc</td>
<td id="S4.T5.1.1.2.6" class="ltx_td ltx_align_center ltx_border_t">Delta</td>
<td id="S4.T5.1.1.2.7" class="ltx_td ltx_align_center ltx_border_t">Acc</td>
<td id="S4.T5.1.1.2.8" class="ltx_td ltx_align_center ltx_border_t">Delta</td>
<td id="S4.T5.1.1.2.9" class="ltx_td ltx_align_center ltx_border_t">BLEU-4</td>
<td id="S4.T5.1.1.2.10" class="ltx_td ltx_align_center ltx_border_t">Delta</td>
<td id="S4.T5.1.1.2.11" class="ltx_td ltx_align_center ltx_border_t">Acc</td>
<td id="S4.T5.1.1.2.12" class="ltx_td ltx_align_center ltx_border_t">Delta</td>
</tr>
<tr id="S4.T5.1.1.3" class="ltx_tr">
<td id="S4.T5.1.1.3.1" class="ltx_td ltx_align_center ltx_border_t">baseline</td>
<td id="S4.T5.1.1.3.2" class="ltx_td ltx_align_center ltx_border_t">28.32%</td>
<td id="S4.T5.1.1.3.3" class="ltx_td ltx_align_center ltx_border_t">0.00%</td>
<td id="S4.T5.1.1.3.4" class="ltx_td ltx_align_center ltx_border_t">63.32%</td>
<td id="S4.T5.1.1.3.5" class="ltx_td ltx_align_center ltx_border_t">0.00%</td>
<td id="S4.T5.1.1.3.6" class="ltx_td ltx_align_center ltx_border_t">59.80%</td>
<td id="S4.T5.1.1.3.7" class="ltx_td ltx_align_center ltx_border_t">0.00%</td>
<td id="S4.T5.1.1.3.8" class="ltx_td ltx_align_center ltx_border_t">24.32%</td>
<td id="S4.T5.1.1.3.9" class="ltx_td ltx_align_center ltx_border_t">0.00%</td>
<td id="S4.T5.1.1.3.10" class="ltx_td ltx_align_center ltx_border_t">49.14%</td>
<td id="S4.T5.1.1.3.11" class="ltx_td ltx_align_center ltx_border_t">0.00%</td>
<td id="S4.T5.1.1.3.12" class="ltx_td ltx_align_center ltx_border_t">80.27%</td>
<td id="S4.T5.1.1.3.13" class="ltx_td ltx_align_center ltx_border_t">0.00%</td>
</tr>
<tr id="S4.T5.1.1.4" class="ltx_tr">
<td id="S4.T5.1.1.4.1" class="ltx_td ltx_align_center ltx_border_t">Dimension/Measure+ Semantic Field Type</td>
<td id="S4.T5.1.1.4.2" class="ltx_td ltx_align_center ltx_border_t">30.12%</td>
<td id="S4.T5.1.1.4.3" class="ltx_td ltx_align_center ltx_border_t">1.80%</td>
<td id="S4.T5.1.1.4.4" class="ltx_td ltx_align_center ltx_border_t">65.72%</td>
<td id="S4.T5.1.1.4.5" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#C6EFCE;"><span id="S4.T5.1.1.4.5.1" class="ltx_text" style="color:#006100;background-color:#C6EFCE;">2.40%</span></td>
<td id="S4.T5.1.1.4.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T5.1.1.4.6.1" class="ltx_text ltx_font_bold">62.67%</span></td>
<td id="S4.T5.1.1.4.7" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#C6EFCE;"><span id="S4.T5.1.1.4.7.1" class="ltx_text ltx_framed ltx_framed_underline" style="color:#006100;background-color:#C6EFCE;">2.87%</span></td>
<td id="S4.T5.1.1.4.8" class="ltx_td ltx_align_center ltx_border_t">26.12%</td>
<td id="S4.T5.1.1.4.9" class="ltx_td ltx_align_center ltx_border_t">1.80%</td>
<td id="S4.T5.1.1.4.10" class="ltx_td ltx_align_center ltx_border_t">51.25%</td>
<td id="S4.T5.1.1.4.11" class="ltx_td ltx_align_center ltx_border_t">2.11%</td>
<td id="S4.T5.1.1.4.12" class="ltx_td ltx_align_center ltx_border_t">
<span id="S4.T5.1.1.4.12.1" class="ltx_text ltx_font_bold">82.45</span>%</td>
<td id="S4.T5.1.1.4.13" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#C6EFCE;"><span id="S4.T5.1.1.4.13.1" class="ltx_text ltx_framed ltx_framed_underline" style="color:#006100;background-color:#C6EFCE;">2.18%</span></td>
</tr>
<tr id="S4.T5.1.1.5" class="ltx_tr">
<td id="S4.T5.1.1.5.1" class="ltx_td ltx_align_center">Table Size</td>
<td id="S4.T5.1.1.5.2" class="ltx_td ltx_align_center">28.85%</td>
<td id="S4.T5.1.1.5.3" class="ltx_td ltx_align_center">0.53%</td>
<td id="S4.T5.1.1.5.4" class="ltx_td ltx_align_center">63.40%</td>
<td id="S4.T5.1.1.5.5" class="ltx_td ltx_align_center">0.08%</td>
<td id="S4.T5.1.1.5.6" class="ltx_td ltx_align_center">60.30%</td>
<td id="S4.T5.1.1.5.7" class="ltx_td ltx_align_center">0.50%</td>
<td id="S4.T5.1.1.5.8" class="ltx_td ltx_align_center">24.94%</td>
<td id="S4.T5.1.1.5.9" class="ltx_td ltx_align_center">0.62%</td>
<td id="S4.T5.1.1.5.10" class="ltx_td ltx_align_center">49.03%</td>
<td id="S4.T5.1.1.5.11" class="ltx_td ltx_align_center">-0.11%</td>
<td id="S4.T5.1.1.5.12" class="ltx_td ltx_align_center">79.86%</td>
<td id="S4.T5.1.1.5.13" class="ltx_td ltx_align_center">-0.41%</td>
</tr>
<tr id="S4.T5.1.1.6" class="ltx_tr">
<td id="S4.T5.1.1.6.1" class="ltx_td ltx_align_center">Statistics Feature</td>
<td id="S4.T5.1.1.6.2" class="ltx_td ltx_align_center">31.22%</td>
<td id="S4.T5.1.1.6.3" class="ltx_td ltx_align_center" style="background-color:#C6EFCE;"><span id="S4.T5.1.1.6.3.1" class="ltx_text" style="color:#006100;background-color:#C6EFCE;">2.90%</span></td>
<td id="S4.T5.1.1.6.4" class="ltx_td ltx_align_center"><span id="S4.T5.1.1.6.4.1" class="ltx_text ltx_font_bold">66.51%</span></td>
<td id="S4.T5.1.1.6.5" class="ltx_td ltx_align_center" style="background-color:#C6EFCE;"><span id="S4.T5.1.1.6.5.1" class="ltx_text ltx_framed ltx_framed_underline" style="color:#006100;background-color:#C6EFCE;">3.19%</span></td>
<td id="S4.T5.1.1.6.6" class="ltx_td ltx_align_center">62.33%</td>
<td id="S4.T5.1.1.6.7" class="ltx_td ltx_align_center" style="background-color:#C6EFCE;"><span id="S4.T5.1.1.6.7.1" class="ltx_text" style="color:#006100;background-color:#C6EFCE;">2.53%</span></td>
<td id="S4.T5.1.1.6.8" class="ltx_td ltx_align_center">26.13%</td>
<td id="S4.T5.1.1.6.9" class="ltx_td ltx_align_center" style="background-color:#C6EFCE;"><span id="S4.T5.1.1.6.9.1" class="ltx_text" style="color:#006100;background-color:#C6EFCE;">1.81%</span></td>
<td id="S4.T5.1.1.6.10" class="ltx_td ltx_align_center">50.57%</td>
<td id="S4.T5.1.1.6.11" class="ltx_td ltx_align_center">1.43%</td>
<td id="S4.T5.1.1.6.12" class="ltx_td ltx_align_center">80.94%</td>
<td id="S4.T5.1.1.6.13" class="ltx_td ltx_align_center" style="background-color:#C6EFCE;"><span id="S4.T5.1.1.6.13.1" class="ltx_text" style="color:#006100;background-color:#C6EFCE;">0.67%</span></td>
</tr>
<tr id="S4.T5.1.1.7" class="ltx_tr">
<td id="S4.T5.1.1.7.1" class="ltx_td ltx_align_center">Header Hierarchy</td>
<td id="S4.T5.1.1.7.2" class="ltx_td ltx_align_center">-</td>
<td id="S4.T5.1.1.7.3" class="ltx_td ltx_align_center">-</td>
<td id="S4.T5.1.1.7.4" class="ltx_td ltx_align_center">-</td>
<td id="S4.T5.1.1.7.5" class="ltx_td ltx_align_center">-</td>
<td id="S4.T5.1.1.7.6" class="ltx_td ltx_align_center">-</td>
<td id="S4.T5.1.1.7.7" class="ltx_td ltx_align_center">-</td>
<td id="S4.T5.1.1.7.8" class="ltx_td ltx_align_center">-</td>
<td id="S4.T5.1.1.7.9" class="ltx_td ltx_align_center">-</td>
<td id="S4.T5.1.1.7.10" class="ltx_td ltx_align_center">48.64%</td>
<td id="S4.T5.1.1.7.11" class="ltx_td ltx_align_center">-0.50%</td>
<td id="S4.T5.1.1.7.12" class="ltx_td ltx_align_center">-</td>
<td id="S4.T5.1.1.7.13" class="ltx_td ltx_align_center">-</td>
</tr>
<tr id="S4.T5.1.1.8" class="ltx_tr">
<td id="S4.T5.1.1.8.1" class="ltx_td ltx_align_center ltx_border_t">Docs References</td>
<td id="S4.T5.1.1.8.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T5.1.1.8.2.1" class="ltx_text ltx_font_bold">33.45%</span></td>
<td id="S4.T5.1.1.8.3" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#C6EFCE;"><span id="S4.T5.1.1.8.3.1" class="ltx_text ltx_framed ltx_framed_underline" style="color:#006100;background-color:#C6EFCE;">5.13%</span></td>
<td id="S4.T5.1.1.8.4" class="ltx_td ltx_align_center ltx_border_t">63.13%</td>
<td id="S4.T5.1.1.8.5" class="ltx_td ltx_align_center ltx_border_t">-0.19%</td>
<td id="S4.T5.1.1.8.6" class="ltx_td ltx_align_center ltx_border_t">61.32%</td>
<td id="S4.T5.1.1.8.7" class="ltx_td ltx_align_center ltx_border_t">1.52%</td>
<td id="S4.T5.1.1.8.8" class="ltx_td ltx_align_center ltx_border_t">25.12%</td>
<td id="S4.T5.1.1.8.9" class="ltx_td ltx_align_center ltx_border_t">0.80%</td>
<td id="S4.T5.1.1.8.10" class="ltx_td ltx_align_center ltx_border_t">52.74%</td>
<td id="S4.T5.1.1.8.11" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#C6EFCE;"><span id="S4.T5.1.1.8.11.1" class="ltx_text" style="color:#006100;background-color:#C6EFCE;">3.60%</span></td>
<td id="S4.T5.1.1.8.12" class="ltx_td ltx_align_center ltx_border_t">77.65%</td>
<td id="S4.T5.1.1.8.13" class="ltx_td ltx_align_center ltx_border_t">-2.62%</td>
</tr>
<tr id="S4.T5.1.1.9" class="ltx_tr">
<td id="S4.T5.1.1.9.1" class="ltx_td ltx_align_center">Term Explanations</td>
<td id="S4.T5.1.1.9.2" class="ltx_td ltx_align_center">31.59%</td>
<td id="S4.T5.1.1.9.3" class="ltx_td ltx_align_center" style="background-color:#C6EFCE;"><span id="S4.T5.1.1.9.3.1" class="ltx_text" style="color:#006100;background-color:#C6EFCE;">3.27%</span></td>
<td id="S4.T5.1.1.9.4" class="ltx_td ltx_align_center">64.12%</td>
<td id="S4.T5.1.1.9.5" class="ltx_td ltx_align_center">0.80%</td>
<td id="S4.T5.1.1.9.6" class="ltx_td ltx_align_center">62.32%</td>
<td id="S4.T5.1.1.9.7" class="ltx_td ltx_align_center" style="background-color:#C6EFCE;"><span id="S4.T5.1.1.9.7.1" class="ltx_text" style="color:#006100;background-color:#C6EFCE;">2.52%</span></td>
<td id="S4.T5.1.1.9.8" class="ltx_td ltx_align_center">26.24%</td>
<td id="S4.T5.1.1.9.9" class="ltx_td ltx_align_center" style="background-color:#C6EFCE;"><span id="S4.T5.1.1.9.9.1" class="ltx_text" style="color:#006100;background-color:#C6EFCE;">1.92%</span></td>
<td id="S4.T5.1.1.9.10" class="ltx_td ltx_align_center"><span id="S4.T5.1.1.9.10.1" class="ltx_text ltx_font_bold">53.21%</span></td>
<td id="S4.T5.1.1.9.11" class="ltx_td ltx_align_center" style="background-color:#C6EFCE;"><span id="S4.T5.1.1.9.11.1" class="ltx_text ltx_framed ltx_framed_underline" style="color:#006100;background-color:#C6EFCE;">4.07%</span></td>
<td id="S4.T5.1.1.9.12" class="ltx_td ltx_align_center">80.48%</td>
<td id="S4.T5.1.1.9.13" class="ltx_td ltx_align_center" style="background-color:#C6EFCE;"><span id="S4.T5.1.1.9.13.1" class="ltx_text" style="color:#006100;background-color:#C6EFCE;">0.21%</span></td>
</tr>
<tr id="S4.T5.1.1.10" class="ltx_tr">
<td id="S4.T5.1.1.10.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">Self Prompting</td>
<td id="S4.T5.1.1.10.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">30.45%</td>
<td id="S4.T5.1.1.10.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">2.13%</td>
<td id="S4.T5.1.1.10.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">65.24%</td>
<td id="S4.T5.1.1.10.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="background-color:#C6EFCE;"><span id="S4.T5.1.1.10.5.1" class="ltx_text" style="color:#006100;background-color:#C6EFCE;">1.92%</span></td>
<td id="S4.T5.1.1.10.6" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">62.32%</td>
<td id="S4.T5.1.1.10.7" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="background-color:#C6EFCE;"><span id="S4.T5.1.1.10.7.1" class="ltx_text" style="color:#006100;background-color:#C6EFCE;">2.52%</span></td>
<td id="S4.T5.1.1.10.8" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S4.T5.1.1.10.8.1" class="ltx_text ltx_font_bold">26.64%</span></td>
<td id="S4.T5.1.1.10.9" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="background-color:#C6EFCE;"><span id="S4.T5.1.1.10.9.1" class="ltx_text ltx_framed ltx_framed_underline" style="color:#006100;background-color:#C6EFCE;">2.32%</span></td>
<td id="S4.T5.1.1.10.10" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">52.36%</td>
<td id="S4.T5.1.1.10.11" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="background-color:#C6EFCE;"><span id="S4.T5.1.1.10.11.1" class="ltx_text" style="color:#006100;background-color:#C6EFCE;">3.22%</span></td>
<td id="S4.T5.1.1.10.12" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">-</td>
<td id="S4.T5.1.1.10.13" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">-</td>
</tr>
</table>
</span></div>
</figure>
</section>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2. </span>Comparison Results of Table Sampling</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">According to Table <a href="#S4.T4" title="Table 4 ‣ 4.1.2. Models ‣ 4.1. Experiment Settings ‣ 4. Experiments ‣ TAP4LLM: Table Provider on Sampling, Augmenting, and Packing Semi-structured Data for Large Language Model Reasoning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, we conduct the comparative experiments on multiple table sampling methods and make several observations as follows:</p>
</div>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.1" class="ltx_p">(1) <span id="S4.SS2.p2.1.1" class="ltx_text ltx_font_italic">Effectiveness of query-based and clustering-based Sampling</span>:
The query-based sampling method, combined with column grounding, achieves the best performance over all datasets.
It indicates that sampling specific, relevant parts of the table that are relevant to the query can enhance LLMs’ capability to produce more accurate results. Additionally, the use of both row-based and column-based sampling can provide a fine-grained subset of the table that covers the most essential information for the reasoning process.
Similarly, the clustering-based sampling method demonstrates satisfactory performance. This method uses the patterns and similarities within the data point in each table to create the clusters that guide the sampling process. It doesn’t consider the relevance between the table and the query. Instead, it mainly focuses on the inner information of the table across different clusters.</p>
</div>
<div id="S4.SS2.p3" class="ltx_para">
<p id="S4.SS2.p3.1" class="ltx_p">(2) <span id="S4.SS2.p3.1.1" class="ltx_text ltx_font_italic">Potential of Content Snapshot</span>: “Content Snapshot <cite class="ltx_cite ltx_citemacro_citep">(Yin et al<span class="ltx_text">.</span>, <a href="#bib.bib66" title="" class="ltx_ref">2020</a>)</cite>” shows result that is relatively close to “Clustering-based Sampling” and “Query-based Sampling”. It indicates that capturing a snapshot of essential information from the table can provide a useful cross-section for the LLMs to learn from. Even though it might not always capture the most relevant or critical information that is needed for table reasoning, it demonstrates its potential as a viable sampling technique. Furthermore, compared to the query-based or clustering-based sampling, this method doesn’t require time-consuming embedding generation. Instead, it calculates the <math id="S4.SS2.p3.1.m1.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S4.SS2.p3.1.m1.1a"><mi id="S4.SS2.p3.1.m1.1.1" xref="S4.SS2.p3.1.m1.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.1.m1.1b"><ci id="S4.SS2.p3.1.m1.1.1.cmml" xref="S4.SS2.p3.1.m1.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.1.m1.1c">n</annotation></semantics></math>-gram overlap with the utterance and the process is linear with the number of rows.</p>
</div>
<div id="S4.SS2.p4" class="ltx_para">
<p id="S4.SS2.p4.1" class="ltx_p">(3) <span id="S4.SS2.p4.1.1" class="ltx_text ltx_font_italic">Table Sampling vs. Direct Encoding (Truncation)</span>:
Directly leveraging the GPT-3.5-turbo model with 32k tokens limitation shows worse performance compared to using table sampling methods. Even though it can cover more information on the table, however, the results demonstrate that encoding much of the table information might introduce noise and disrupt the table reasoning process.
Furthermore, using a 4K token-sized context window model with truncation results in even poorer performance compared to the model with a 32k token limitation. It indicates that truncating the table could lead to the loss of vital context or information, potentially restricting the model’s capability to fully understand the table and generate comprehensive answers.</p>
</div>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3. </span>Comparison Results of Table Augmentation.</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">For the comparative experiments of table augmentation methods, we use the query-based sampling method as the baseline method and report the performance gap between each augmentation method and the baseline.
According to Table <a href="#S4.T5" title="Table 5 ‣ 4.1.2. Models ‣ 4.1. Experiment Settings ‣ 4. Experiments ‣ TAP4LLM: Table Provider on Sampling, Augmenting, and Packing Semi-structured Data for Large Language Model Reasoning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>, several insights can be found as follows:</p>
</div>
<figure id="S4.T6" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 6. </span>Comparative results of cell selection functions. We use query-based sampling as the baseline.</figcaption>
<div id="S4.T6.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:54pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-72.5pt,9.0pt) scale(0.749485755344583,0.749485755344583) ;">
<table id="S4.T6.1.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T6.1.1.1" class="ltx_tr">
<td id="S4.T6.1.1.1.1" class="ltx_td ltx_align_center ltx_border_tt" rowspan="2"><span id="S4.T6.1.1.1.1.1" class="ltx_text">Methods</span></td>
<td id="S4.T6.1.1.1.2" class="ltx_td ltx_align_center ltx_border_tt" colspan="2">SQA</td>
<td id="S4.T6.1.1.1.3" class="ltx_td ltx_align_center ltx_border_tt" colspan="2">FEVEROUS</td>
<td id="S4.T6.1.1.1.4" class="ltx_td ltx_align_center ltx_border_tt" colspan="2">TabFact</td>
<td id="S4.T6.1.1.1.5" class="ltx_td ltx_align_center ltx_border_tt" colspan="2">HybridQA</td>
<td id="S4.T6.1.1.1.6" class="ltx_td ltx_align_center ltx_border_tt" colspan="2">ToTTo</td>
<td id="S4.T6.1.1.1.7" class="ltx_td ltx_align_center ltx_border_tt" colspan="2">Spider</td>
</tr>
<tr id="S4.T6.1.1.2" class="ltx_tr">
<td id="S4.T6.1.1.2.1" class="ltx_td ltx_align_center ltx_border_t">Acc</td>
<td id="S4.T6.1.1.2.2" class="ltx_td ltx_align_center ltx_border_t">Delta</td>
<td id="S4.T6.1.1.2.3" class="ltx_td ltx_align_center ltx_border_t">Acc</td>
<td id="S4.T6.1.1.2.4" class="ltx_td ltx_align_center ltx_border_t">Delta</td>
<td id="S4.T6.1.1.2.5" class="ltx_td ltx_align_center ltx_border_t">Acc</td>
<td id="S4.T6.1.1.2.6" class="ltx_td ltx_align_center ltx_border_t">Delta</td>
<td id="S4.T6.1.1.2.7" class="ltx_td ltx_align_center ltx_border_t">Acc</td>
<td id="S4.T6.1.1.2.8" class="ltx_td ltx_align_center ltx_border_t">Delta</td>
<td id="S4.T6.1.1.2.9" class="ltx_td ltx_align_center ltx_border_t">BLEU-4</td>
<td id="S4.T6.1.1.2.10" class="ltx_td ltx_align_center ltx_border_t">Delta</td>
<td id="S4.T6.1.1.2.11" class="ltx_td ltx_align_center ltx_border_t">Acc</td>
<td id="S4.T6.1.1.2.12" class="ltx_td ltx_align_center ltx_border_t">Delta</td>
</tr>
<tr id="S4.T6.1.1.3" class="ltx_tr">
<td id="S4.T6.1.1.3.1" class="ltx_td ltx_align_center ltx_border_t">LLM-based</td>
<td id="S4.T6.1.1.3.2" class="ltx_td ltx_align_center ltx_border_t">31.59%</td>
<td id="S4.T6.1.1.3.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T6.1.1.3.3.1" class="ltx_text ltx_font_bold">3.27%</span></td>
<td id="S4.T6.1.1.3.4" class="ltx_td ltx_align_center ltx_border_t">64.12%</td>
<td id="S4.T6.1.1.3.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T6.1.1.3.5.1" class="ltx_text ltx_font_bold">0.80%</span></td>
<td id="S4.T6.1.1.3.6" class="ltx_td ltx_align_center ltx_border_t">62.32%</td>
<td id="S4.T6.1.1.3.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T6.1.1.3.7.1" class="ltx_text ltx_font_bold">2.52%</span></td>
<td id="S4.T6.1.1.3.8" class="ltx_td ltx_align_center ltx_border_t">26.24%</td>
<td id="S4.T6.1.1.3.9" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T6.1.1.3.9.1" class="ltx_text ltx_font_bold">1.92%</span></td>
<td id="S4.T6.1.1.3.10" class="ltx_td ltx_align_center ltx_border_t">53.21%</td>
<td id="S4.T6.1.1.3.11" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T6.1.1.3.11.1" class="ltx_text ltx_font_bold">4.07%</span></td>
<td id="S4.T6.1.1.3.12" class="ltx_td ltx_align_center ltx_border_t">80.48%</td>
<td id="S4.T6.1.1.3.13" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T6.1.1.3.13.1" class="ltx_text ltx_font_bold">0.21%</span></td>
</tr>
<tr id="S4.T6.1.1.4" class="ltx_tr">
<td id="S4.T6.1.1.4.1" class="ltx_td ltx_align_center ltx_border_bb">Heuristics-based</td>
<td id="S4.T6.1.1.4.2" class="ltx_td ltx_align_center ltx_border_bb">29.59%</td>
<td id="S4.T6.1.1.4.3" class="ltx_td ltx_align_center ltx_border_bb">1.27%</td>
<td id="S4.T6.1.1.4.4" class="ltx_td ltx_align_center ltx_border_bb">63.72%</td>
<td id="S4.T6.1.1.4.5" class="ltx_td ltx_align_center ltx_border_bb">0.40%</td>
<td id="S4.T6.1.1.4.6" class="ltx_td ltx_align_center ltx_border_bb">61.58%</td>
<td id="S4.T6.1.1.4.7" class="ltx_td ltx_align_center ltx_border_bb">1.78%</td>
<td id="S4.T6.1.1.4.8" class="ltx_td ltx_align_center ltx_border_bb">25.24%</td>
<td id="S4.T6.1.1.4.9" class="ltx_td ltx_align_center ltx_border_bb">0.92%</td>
<td id="S4.T6.1.1.4.10" class="ltx_td ltx_align_center ltx_border_bb">51.21%</td>
<td id="S4.T6.1.1.4.11" class="ltx_td ltx_align_center ltx_border_bb">2.07%</td>
<td id="S4.T6.1.1.4.12" class="ltx_td ltx_align_center ltx_border_bb">80.33%</td>
<td id="S4.T6.1.1.4.13" class="ltx_td ltx_align_center ltx_border_bb">0.06%</td>
</tr>
</table>
</span></div>
</figure>
<div id="S4.SS3.p2" class="ltx_para">
<p id="S4.SS3.p2.1" class="ltx_p">(1) <span id="S4.SS3.p2.1.1" class="ltx_text ltx_font_italic">Effectiveness of table augmentation:</span> From the experimental results, we found that table augmentation methods further improve LLM’s reasoning ability after sampling. For example, ”Dimension/Measure + Semantic Field Type” achieves higher accuracy across all six datasets (most significant increase on TabFact +2.87%). ”Statistics Feature” performs effectively on datasets that include a higher proportion of statistical cell contents (FEVEROUS +3.19% ). ”Docs References” and ”Term Explanations” add meaningful context and semantic understanding to the model’s processing of tables, with (SQA +5.13%, ToTTo +4.07% ). Also, ”self-prompting” helps the model generate better queries or responses by encouraging it to use its own outputs as a guide for further response generation (ToTTo +3.22%). We also found some methods might not improve the model’s performance by adding extra information. According to the result, the model performance with ”Table Size” is minimal, suggesting little help in adding substantial semantic information. In addition, the result of ”Header Hierarchy” shows that introducing a hierarchy may complicate the model’s ability to process the tabular information in some contexts, possibly by adding unnecessary complexity.</p>
</div>
<div id="S4.SS3.p3" class="ltx_para">
<p id="S4.SS3.p3.1" class="ltx_p">(2) <span id="S4.SS3.p3.1.1" class="ltx_text ltx_font_italic">Comparison of different cell selection methods:</span> For the ”Term Explanations” method, we compare two distinct cell selection functions as shown in Table <a href="#S4.T6" title="Table 6 ‣ 4.3. Comparison Results of Table Augmentation. ‣ 4. Experiments ‣ TAP4LLM: Table Provider on Sampling, Augmenting, and Packing Semi-structured Data for Large Language Model Reasoning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>. We find that LLM-based cell selection outperforms the heuristics-based cell selection with improvements in “Delta” ranging from 0.80% to 4.07%. While achieving higher performance, the LLM-based method also increases the calling budget as it requires additional LLM calls. These results indicate that the method’s effectiveness varies with the dataset. i.e. It’s beneficial for datasets requiring complex text understanding and generation (SQA and ToTTo). However, its impact is less distinct or even slightly negative in datasets involving different types of data or nuanced tasks (FEVEROUS and HybridQA).</p>
</div>
<div id="S4.SS3.p4" class="ltx_para">
<p id="S4.SS3.p4.1" class="ltx_p">(3) <span id="S4.SS3.p4.1.1" class="ltx_text ltx_font_italic">Combination of augmentation methods:</span> Through the experiment results, we have investigated the best combination of single sampling method and augmentation method on each dataset. We also observe that different methods perform well on the same dataset. For example, ”Dimension/Measure + Field Type”, ”Statistics Feature”, ”Term Explanation” and ”Self Prompting” all show significant improvement on the TabFact dataset. This suggests additional research on the superposable effects through combining multiple augmentation methods. We leave this work for future investigation.</p>
</div>
</section>
<section id="S4.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4. </span>Comparison Results of Embedding Type.</h3>

<div id="S4.SS4.p1" class="ltx_para">
<p id="S4.SS4.p1.1" class="ltx_p">Based on the results from Table <a href="#S4.T7" title="Table 7 ‣ 4.4. Comparison Results of Embedding Type. ‣ 4. Experiments ‣ TAP4LLM: Table Provider on Sampling, Augmenting, and Packing Semi-structured Data for Large Language Model Reasoning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>, we observe that:
(1) <span id="S4.SS4.p1.1.1" class="ltx_text ltx_font_italic">Superiority of “text-embedding-ada-002”</span>: “text-embedding-ada-002” consistently offers the best performance across the datasets. It suggests that for tasks similar to table reasoning, this embedding type might be the most suitable choice.
(2) <span id="S4.SS4.p1.1.2" class="ltx_text ltx_font_italic">Potential of “sentence-transformer”</span>: The “sentence-transformer” embedding type provides competitive results, especially in the ToTTo dataset. This suggests that it might be particularly suitable for certain tasks or datasets and is worth considering alongside “text-embedding-ada-002”.</p>
</div>
<figure id="S4.T7" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 7. </span>Comparative results of different embedding models on query-based sampling method without any augmentation method. We use all-MinLM-L6-v2 for the sentence-transformer. The highest performance of each dataset is bold.</figcaption>
<div id="S4.T7.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:62.4pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-95.9pt,13.8pt) scale(0.693332320983676,0.693332320983676) ;">
<table id="S4.T7.1.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T7.1.1.1" class="ltx_tr">
<td id="S4.T7.1.1.1.1" class="ltx_td ltx_align_center ltx_border_tt">Embedding Type</td>
<td id="S4.T7.1.1.1.2" class="ltx_td ltx_align_center ltx_border_tt">SQA</td>
<td id="S4.T7.1.1.1.3" class="ltx_td ltx_align_center ltx_border_tt">FEVEROUS</td>
<td id="S4.T7.1.1.1.4" class="ltx_td ltx_align_center ltx_border_tt">TabFact</td>
<td id="S4.T7.1.1.1.5" class="ltx_td ltx_align_center ltx_border_tt">HybridQA</td>
<td id="S4.T7.1.1.1.6" class="ltx_td ltx_align_center ltx_border_tt">ToTTo</td>
<td id="S4.T7.1.1.1.7" class="ltx_td ltx_align_center ltx_border_tt">Spider</td>
</tr>
<tr id="S4.T7.1.1.2" class="ltx_tr">
<td id="S4.T7.1.1.2.1" class="ltx_td ltx_align_center ltx_border_t">text-embedding-ada-002</td>
<td id="S4.T7.1.1.2.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T7.1.1.2.2.1" class="ltx_text ltx_font_bold">28.32%</span></td>
<td id="S4.T7.1.1.2.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T7.1.1.2.3.1" class="ltx_text ltx_font_bold">63.32%</span></td>
<td id="S4.T7.1.1.2.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T7.1.1.2.4.1" class="ltx_text ltx_font_bold">59.80%</span></td>
<td id="S4.T7.1.1.2.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T7.1.1.2.5.1" class="ltx_text ltx_font_bold">24.32%</span></td>
<td id="S4.T7.1.1.2.6" class="ltx_td ltx_align_center ltx_border_t">49.14%</td>
<td id="S4.T7.1.1.2.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T7.1.1.2.7.1" class="ltx_text ltx_font_bold">80.27%</span></td>
</tr>
<tr id="S4.T7.1.1.3" class="ltx_tr">
<td id="S4.T7.1.1.3.1" class="ltx_td ltx_align_center">text-embedding-ada-001</td>
<td id="S4.T7.1.1.3.2" class="ltx_td ltx_align_center">27.12%</td>
<td id="S4.T7.1.1.3.3" class="ltx_td ltx_align_center">62.24%</td>
<td id="S4.T7.1.1.3.4" class="ltx_td ltx_align_center">57.32%</td>
<td id="S4.T7.1.1.3.5" class="ltx_td ltx_align_center">23.14%</td>
<td id="S4.T7.1.1.3.6" class="ltx_td ltx_align_center">48.21%</td>
<td id="S4.T7.1.1.3.7" class="ltx_td ltx_align_center">79.34%</td>
</tr>
<tr id="S4.T7.1.1.4" class="ltx_tr">
<td id="S4.T7.1.1.4.1" class="ltx_td ltx_align_center">bge-large-en <cite class="ltx_cite ltx_citemacro_citep">(Xiao et al<span class="ltx_text">.</span>, <a href="#bib.bib63" title="" class="ltx_ref">2023</a>)</cite>
</td>
<td id="S4.T7.1.1.4.2" class="ltx_td ltx_align_center">26.76%</td>
<td id="S4.T7.1.1.4.3" class="ltx_td ltx_align_center">62.87%</td>
<td id="S4.T7.1.1.4.4" class="ltx_td ltx_align_center">56.31%</td>
<td id="S4.T7.1.1.4.5" class="ltx_td ltx_align_center">22.65%</td>
<td id="S4.T7.1.1.4.6" class="ltx_td ltx_align_center">47.32%</td>
<td id="S4.T7.1.1.4.7" class="ltx_td ltx_align_center">78.25%</td>
</tr>
<tr id="S4.T7.1.1.5" class="ltx_tr">
<td id="S4.T7.1.1.5.1" class="ltx_td ltx_align_center ltx_border_bb">sentence-transformer <cite class="ltx_cite ltx_citemacro_citep">(Reimers and Gurevych, <a href="#bib.bib52" title="" class="ltx_ref">2019</a>)</cite>
</td>
<td id="S4.T7.1.1.5.2" class="ltx_td ltx_align_center ltx_border_bb">26.32%</td>
<td id="S4.T7.1.1.5.3" class="ltx_td ltx_align_center ltx_border_bb">63.31%</td>
<td id="S4.T7.1.1.5.4" class="ltx_td ltx_align_center ltx_border_bb">58.94%</td>
<td id="S4.T7.1.1.5.5" class="ltx_td ltx_align_center ltx_border_bb">23.78%</td>
<td id="S4.T7.1.1.5.6" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T7.1.1.5.6.1" class="ltx_text ltx_font_bold">50.12%</span></td>
<td id="S4.T7.1.1.5.7" class="ltx_td ltx_align_center ltx_border_bb">80.05%</td>
</tr>
</table>
</span></div>
</figure>
<div id="S4.SS4.p2" class="ltx_para">
<p id="S4.SS4.p2.1" class="ltx_p">While “text-embedding-ada-001” and “bge-large-en” don’t lead to the highest performance, they still provide competitive performance. This suggests that the choice of embedding can affect the overall performance, but the differences might not always be significant. The choice between these embeddings would likely depend on specific use cases, computational costs, and other practical considerations.</p>
</div>
<figure id="S4.T8" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 8. </span>Comparative results of various types of statistical features. The experiment setting is the same as Section <a href="#S4.T5" title="Table 5 ‣ 4.1.2. Models ‣ 4.1. Experiment Settings ‣ 4. Experiments ‣ TAP4LLM: Table Provider on Sampling, Augmenting, and Packing Semi-structured Data for Large Language Model Reasoning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>. The highest performance of each dataset is bold.</figcaption>
<div id="S4.T8.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:110.4pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(4.7pt,-1.2pt) scale(1.0221510567685,1.0221510567685) ;">
<table id="S4.T8.1.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T8.1.1.1" class="ltx_tr">
<td id="S4.T8.1.1.1.1" class="ltx_td ltx_align_center ltx_border_tt">Statistics Features Type</td>
<td id="S4.T8.1.1.1.2" class="ltx_td ltx_align_center ltx_border_tt">SQA</td>
<td id="S4.T8.1.1.1.3" class="ltx_td ltx_align_center ltx_border_tt">FEVEROUS</td>
<td id="S4.T8.1.1.1.4" class="ltx_td ltx_align_center ltx_border_tt">TabFact</td>
<td id="S4.T8.1.1.1.5" class="ltx_td ltx_align_center ltx_border_tt">HybridQA</td>
<td id="S4.T8.1.1.1.6" class="ltx_td ltx_align_center ltx_border_tt">ToTTo</td>
<td id="S4.T8.1.1.1.7" class="ltx_td ltx_align_center ltx_border_tt">Spider</td>
</tr>
<tr id="S4.T8.1.1.2" class="ltx_tr">
<td id="S4.T8.1.1.2.1" class="ltx_td ltx_align_center ltx_border_t">Progression features</td>
<td id="S4.T8.1.1.2.2" class="ltx_td ltx_align_center ltx_border_t">29.20%</td>
<td id="S4.T8.1.1.2.3" class="ltx_td ltx_align_center ltx_border_t">64.26%</td>
<td id="S4.T8.1.1.2.4" class="ltx_td ltx_align_center ltx_border_t">60.45%</td>
<td id="S4.T8.1.1.2.5" class="ltx_td ltx_align_center ltx_border_t">25.11%</td>
<td id="S4.T8.1.1.2.6" class="ltx_td ltx_align_center ltx_border_t">49.53%</td>
<td id="S4.T8.1.1.2.7" class="ltx_td ltx_align_center ltx_border_t">77.47%</td>
</tr>
<tr id="S4.T8.1.1.3" class="ltx_tr">
<td id="S4.T8.1.1.3.1" class="ltx_td ltx_align_center">String features</td>
<td id="S4.T8.1.1.3.2" class="ltx_td ltx_align_center">28.56%</td>
<td id="S4.T8.1.1.3.3" class="ltx_td ltx_align_center">63.13%</td>
<td id="S4.T8.1.1.3.4" class="ltx_td ltx_align_center">61.38%</td>
<td id="S4.T8.1.1.3.5" class="ltx_td ltx_align_center">24.83%</td>
<td id="S4.T8.1.1.3.6" class="ltx_td ltx_align_center">48.29%</td>
<td id="S4.T8.1.1.3.7" class="ltx_td ltx_align_center">73.56%</td>
</tr>
<tr id="S4.T8.1.1.4" class="ltx_tr">
<td id="S4.T8.1.1.4.1" class="ltx_td ltx_align_center">Number range features</td>
<td id="S4.T8.1.1.4.2" class="ltx_td ltx_align_center">29.13%</td>
<td id="S4.T8.1.1.4.3" class="ltx_td ltx_align_center">62.18%</td>
<td id="S4.T8.1.1.4.4" class="ltx_td ltx_align_center">59.03%</td>
<td id="S4.T8.1.1.4.5" class="ltx_td ltx_align_center">24.53%</td>
<td id="S4.T8.1.1.4.6" class="ltx_td ltx_align_center">49.68%</td>
<td id="S4.T8.1.1.4.7" class="ltx_td ltx_align_center">76.32%</td>
</tr>
<tr id="S4.T8.1.1.5" class="ltx_tr">
<td id="S4.T8.1.1.5.1" class="ltx_td ltx_align_center">Distribution features</td>
<td id="S4.T8.1.1.5.2" class="ltx_td ltx_align_center">30.28%</td>
<td id="S4.T8.1.1.5.3" class="ltx_td ltx_align_center">66.34%</td>
<td id="S4.T8.1.1.5.4" class="ltx_td ltx_align_center">62.18%</td>
<td id="S4.T8.1.1.5.5" class="ltx_td ltx_align_center">24.76%</td>
<td id="S4.T8.1.1.5.6" class="ltx_td ltx_align_center">49.34%</td>
<td id="S4.T8.1.1.5.7" class="ltx_td ltx_align_center">79.14%</td>
</tr>
<tr id="S4.T8.1.1.6" class="ltx_tr">
<td id="S4.T8.1.1.6.1" class="ltx_td ltx_align_center ltx_border_bb">Statistics features</td>
<td id="S4.T8.1.1.6.2" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T8.1.1.6.2.1" class="ltx_text ltx_font_bold">31.22%</span></td>
<td id="S4.T8.1.1.6.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T8.1.1.6.3.1" class="ltx_text ltx_font_bold">66.51%</span></td>
<td id="S4.T8.1.1.6.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T8.1.1.6.4.1" class="ltx_text ltx_font_bold">62.33%</span></td>
<td id="S4.T8.1.1.6.5" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T8.1.1.6.5.1" class="ltx_text ltx_font_bold">26.13%</span></td>
<td id="S4.T8.1.1.6.6" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T8.1.1.6.6.1" class="ltx_text ltx_font_bold">50.57%</span></td>
<td id="S4.T8.1.1.6.7" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T8.1.1.6.7.1" class="ltx_text ltx_font_bold">80.94%</span></td>
</tr>
</table>
</span></div>
</figure>
</section>
<section id="S4.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.5. </span>Comparison Results of Statistics Features</h3>

<div id="S4.SS5.p1" class="ltx_para">
<p id="S4.SS5.p1.1" class="ltx_p">The accuracy of each dataset for four groups of statistics features reveals that the distribution features overall performed well in capturing the nuances and variations within specific tabular data entries. Based on this, we further propose a combination including the most practical features across these four categories and carry out an empirical study to examine its performance. Specifically, this combination contains variance, range, cardinality, major, and change rate. with each term’s definition listed in Table <a href="#S6.T10" title="Table 10 ‣ 6. Related Work ‣ TAP4LLM: Table Provider on Sampling, Augmenting, and Packing Semi-structured Data for Large Language Model Reasoning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10</span></a>. The experiment result, displayed in Table <a href="#S4.T8" title="Table 8 ‣ 4.4. Comparison Results of Embedding Type. ‣ 4. Experiments ‣ TAP4LLM: Table Provider on Sampling, Augmenting, and Packing Semi-structured Data for Large Language Model Reasoning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a>, demonstrates that our proposed combination surpasses the previous four feature sets across all six datasets.</p>
</div>
</section>
<section id="S4.SS6" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.6. </span>Trade-offs between token allocation</h3>

<div id="S4.SS6.p1" class="ltx_para">
<p id="S4.SS6.p1.1" class="ltx_p">We use five table datasets to find the trade-off between token allocation for table sampling and table augmentation, as demonstrated in Figure <a href="#S4.F3" title="Figure 3 ‣ 4.6. Trade-offs between token allocation ‣ 4. Experiments ‣ TAP4LLM: Table Provider on Sampling, Augmenting, and Packing Semi-structured Data for Large Language Model Reasoning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>.
We find that:</p>
</div>
<div id="S4.SS6.p2" class="ltx_para">
<p id="S4.SS6.p2.1" class="ltx_p">(1) A balanced token distribution between the table and augmentation (around the 5:5 and 4:6 ratios, also known as a <span id="S4.SS6.p2.1.1" class="ltx_text ltx_font_bold">balanced T:A Ratio</span>) generally yields the best performance for all five datasets. In indicates that properly controlling the token allocation can help LLMs achieve better performance.</p>
</div>
<figure id="S4.T9" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 9. </span>Ablation results on five table datasets using gpt-3.5-turbo model. Similar to Table 5, the lowest accuracy on each dataset is bold. The top-3 decreasing gap (delta) on each dataset are highlighted in red, with the lowest performance being underlined.</figcaption>
<div id="S4.T9.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:99.6pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-96.8pt,22.2pt) scale(0.691363207583204,0.691363207583204) ;">
<table id="S4.T9.1.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T9.1.1.1" class="ltx_tr">
<td id="S4.T9.1.1.1.1" class="ltx_td ltx_align_center ltx_border_tt" rowspan="2"><span id="S4.T9.1.1.1.1.1" class="ltx_text">Components of TAP4LLM</span></td>
<td id="S4.T9.1.1.1.2" class="ltx_td ltx_align_center ltx_border_tt" colspan="2">SQA</td>
<td id="S4.T9.1.1.1.3" class="ltx_td ltx_align_center ltx_border_tt" colspan="2">FEVEROUS</td>
<td id="S4.T9.1.1.1.4" class="ltx_td ltx_align_center ltx_border_tt" colspan="2">TabFact</td>
<td id="S4.T9.1.1.1.5" class="ltx_td ltx_align_center ltx_border_tt" colspan="2">HybridQA</td>
<td id="S4.T9.1.1.1.6" class="ltx_td ltx_align_center ltx_border_tt" colspan="2">ToTTo</td>
</tr>
<tr id="S4.T9.1.1.2" class="ltx_tr">
<td id="S4.T9.1.1.2.1" class="ltx_td ltx_align_center ltx_border_t">Acc</td>
<td id="S4.T9.1.1.2.2" class="ltx_td ltx_align_center ltx_border_t">Delta</td>
<td id="S4.T9.1.1.2.3" class="ltx_td ltx_align_center ltx_border_t">Acc</td>
<td id="S4.T9.1.1.2.4" class="ltx_td ltx_align_center ltx_border_t">Delta</td>
<td id="S4.T9.1.1.2.5" class="ltx_td ltx_align_center ltx_border_t">Acc</td>
<td id="S4.T9.1.1.2.6" class="ltx_td ltx_align_center ltx_border_t">Delta</td>
<td id="S4.T9.1.1.2.7" class="ltx_td ltx_align_center ltx_border_t">Acc</td>
<td id="S4.T9.1.1.2.8" class="ltx_td ltx_align_center ltx_border_t">Delta</td>
<td id="S4.T9.1.1.2.9" class="ltx_td ltx_align_center ltx_border_t">BLEU-4</td>
<td id="S4.T9.1.1.2.10" class="ltx_td ltx_align_center ltx_border_t">Delta</td>
</tr>
<tr id="S4.T9.1.1.3" class="ltx_tr">
<td id="S4.T9.1.1.3.1" class="ltx_td ltx_align_center ltx_border_t">All</td>
<td id="S4.T9.1.1.3.2" class="ltx_td ltx_align_center ltx_border_t">34.12%</td>
<td id="S4.T9.1.1.3.3" class="ltx_td ltx_align_center ltx_border_t">0.00%</td>
<td id="S4.T9.1.1.3.4" class="ltx_td ltx_align_center ltx_border_t">68.32%</td>
<td id="S4.T9.1.1.3.5" class="ltx_td ltx_align_center ltx_border_t">0.00%</td>
<td id="S4.T9.1.1.3.6" class="ltx_td ltx_align_center ltx_border_t">64.78%</td>
<td id="S4.T9.1.1.3.7" class="ltx_td ltx_align_center ltx_border_t">0.00%</td>
<td id="S4.T9.1.1.3.8" class="ltx_td ltx_align_center ltx_border_t">27.87%</td>
<td id="S4.T9.1.1.3.9" class="ltx_td ltx_align_center ltx_border_t">0.00%</td>
<td id="S4.T9.1.1.3.10" class="ltx_td ltx_align_center ltx_border_t">54.93%</td>
<td id="S4.T9.1.1.3.11" class="ltx_td ltx_align_center ltx_border_t">0.00%</td>
</tr>
<tr id="S4.T9.1.1.4" class="ltx_tr">
<td id="S4.T9.1.1.4.1" class="ltx_td ltx_align_center ltx_border_t">w/o table sampling</td>
<td id="S4.T9.1.1.4.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T9.1.1.4.2.1" class="ltx_text ltx_font_bold">26.54%</span></td>
<td id="S4.T9.1.1.4.3" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FF9999;"><span id="S4.T9.1.1.4.3.1" class="ltx_text ltx_framed ltx_framed_underline" style="color:#660000;background-color:#FF9999;">-7.58%</span></td>
<td id="S4.T9.1.1.4.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T9.1.1.4.4.1" class="ltx_text ltx_font_bold">61.54%</span></td>
<td id="S4.T9.1.1.4.5" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FF9999;"><span id="S4.T9.1.1.4.5.1" class="ltx_text ltx_framed ltx_framed_underline" style="color:#660000;background-color:#FF9999;">-6.78%</span></td>
<td id="S4.T9.1.1.4.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T9.1.1.4.6.1" class="ltx_text ltx_font_bold">58.12%</span></td>
<td id="S4.T9.1.1.4.7" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FF9999;"><span id="S4.T9.1.1.4.7.1" class="ltx_text ltx_framed ltx_framed_underline" style="color:#660000;background-color:#FF9999;">-6.66%</span></td>
<td id="S4.T9.1.1.4.8" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T9.1.1.4.8.1" class="ltx_text ltx_font_bold">24.12%</span></td>
<td id="S4.T9.1.1.4.9" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FF9999;"><span id="S4.T9.1.1.4.9.1" class="ltx_text ltx_framed ltx_framed_underline" style="color:#660000;background-color:#FF9999;">-3.75%</span></td>
<td id="S4.T9.1.1.4.10" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T9.1.1.4.10.1" class="ltx_text ltx_font_bold">48.47%</span></td>
<td id="S4.T9.1.1.4.11" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FF9999;"><span id="S4.T9.1.1.4.11.1" class="ltx_text ltx_framed ltx_framed_underline" style="color:#660000;background-color:#FF9999;">-6.46%</span></td>
</tr>
<tr id="S4.T9.1.1.5" class="ltx_tr">
<td id="S4.T9.1.1.5.1" class="ltx_td ltx_align_center">w/o table augmentation - all</td>
<td id="S4.T9.1.1.5.2" class="ltx_td ltx_align_center">29.12%</td>
<td id="S4.T9.1.1.5.3" class="ltx_td ltx_align_center" style="background-color:#FF9999;"><span id="S4.T9.1.1.5.3.1" class="ltx_text" style="color:#660000;background-color:#FF9999;">-5.00%</span></td>
<td id="S4.T9.1.1.5.4" class="ltx_td ltx_align_center">63.74%</td>
<td id="S4.T9.1.1.5.5" class="ltx_td ltx_align_center" style="background-color:#FF9999;"><span id="S4.T9.1.1.5.5.1" class="ltx_text" style="color:#660000;background-color:#FF9999;">-4.58%</span></td>
<td id="S4.T9.1.1.5.6" class="ltx_td ltx_align_center">60.23%</td>
<td id="S4.T9.1.1.5.7" class="ltx_td ltx_align_center" style="background-color:#FF9999;"><span id="S4.T9.1.1.5.7.1" class="ltx_text" style="color:#660000;background-color:#FF9999;">-4.55%</span></td>
<td id="S4.T9.1.1.5.8" class="ltx_td ltx_align_center">25.14%</td>
<td id="S4.T9.1.1.5.9" class="ltx_td ltx_align_center" style="background-color:#FF9999;"><span id="S4.T9.1.1.5.9.1" class="ltx_text" style="color:#660000;background-color:#FF9999;">-2.73%</span></td>
<td id="S4.T9.1.1.5.10" class="ltx_td ltx_align_center">53.42%</td>
<td id="S4.T9.1.1.5.11" class="ltx_td ltx_align_center">-1.51%</td>
</tr>
<tr id="S4.T9.1.1.6" class="ltx_tr">
<td id="S4.T9.1.1.6.1" class="ltx_td ltx_align_center">w/o table augmentation - metadata-based</td>
<td id="S4.T9.1.1.6.2" class="ltx_td ltx_align_center">33.87%</td>
<td id="S4.T9.1.1.6.3" class="ltx_td ltx_align_center">-0.25%</td>
<td id="S4.T9.1.1.6.4" class="ltx_td ltx_align_center">64.38%</td>
<td id="S4.T9.1.1.6.5" class="ltx_td ltx_align_center" style="background-color:#FF9999;"><span id="S4.T9.1.1.6.5.1" class="ltx_text" style="color:#660000;background-color:#FF9999;">-3.94<span id="S4.T9.1.1.6.5.1.1" class="ltx_text" style="color:#000000;background-color:#FF9999;">%</span></span></td>
<td id="S4.T9.1.1.6.6" class="ltx_td ltx_align_center">62.78%</td>
<td id="S4.T9.1.1.6.7" class="ltx_td ltx_align_center" style="background-color:#FF9999;"><span id="S4.T9.1.1.6.7.1" class="ltx_text" style="color:#660000;background-color:#FF9999;">-2.00%</span></td>
<td id="S4.T9.1.1.6.8" class="ltx_td ltx_align_center">26.98%</td>
<td id="S4.T9.1.1.6.9" class="ltx_td ltx_align_center">-0.89%</td>
<td id="S4.T9.1.1.6.10" class="ltx_td ltx_align_center">53.42%</td>
<td id="S4.T9.1.1.6.11" class="ltx_td ltx_align_center">-1.51%</td>
</tr>
<tr id="S4.T9.1.1.7" class="ltx_tr">
<td id="S4.T9.1.1.7.1" class="ltx_td ltx_align_center">w/o table augmentation - retrieval-based</td>
<td id="S4.T9.1.1.7.2" class="ltx_td ltx_align_center">31.42%</td>
<td id="S4.T9.1.1.7.3" class="ltx_td ltx_align_center" style="background-color:#FF9999;"><span id="S4.T9.1.1.7.3.1" class="ltx_text" style="color:#660000;background-color:#FF9999;">-2.7<span id="S4.T9.1.1.7.3.1.1" class="ltx_text" style="color:#000000;background-color:#FF9999;">%</span></span></td>
<td id="S4.T9.1.1.7.4" class="ltx_td ltx_align_center">66.23%</td>
<td id="S4.T9.1.1.7.5" class="ltx_td ltx_align_center">-2.09%</td>
<td id="S4.T9.1.1.7.6" class="ltx_td ltx_align_center">62.97%</td>
<td id="S4.T9.1.1.7.7" class="ltx_td ltx_align_center">-1.81%</td>
<td id="S4.T9.1.1.7.8" class="ltx_td ltx_align_center">26.33%</td>
<td id="S4.T9.1.1.7.9" class="ltx_td ltx_align_center">-1.54%</td>
<td id="S4.T9.1.1.7.10" class="ltx_td ltx_align_center">52.67%</td>
<td id="S4.T9.1.1.7.11" class="ltx_td ltx_align_center" style="background-color:#FF9999;"><span id="S4.T9.1.1.7.11.1" class="ltx_text" style="color:#660000;background-color:#FF9999;">-2.26%</span></td>
</tr>
<tr id="S4.T9.1.1.8" class="ltx_tr">
<td id="S4.T9.1.1.8.1" class="ltx_td ltx_align_center ltx_border_bb">w/o table packing</td>
<td id="S4.T9.1.1.8.2" class="ltx_td ltx_align_center ltx_border_bb">31.87%</td>
<td id="S4.T9.1.1.8.3" class="ltx_td ltx_align_center ltx_border_bb">-2.25%</td>
<td id="S4.T9.1.1.8.4" class="ltx_td ltx_align_center ltx_border_bb">67.42%</td>
<td id="S4.T9.1.1.8.5" class="ltx_td ltx_align_center ltx_border_bb">-0.90%</td>
<td id="S4.T9.1.1.8.6" class="ltx_td ltx_align_center ltx_border_bb">63.28%</td>
<td id="S4.T9.1.1.8.7" class="ltx_td ltx_align_center ltx_border_bb">-1.50%</td>
<td id="S4.T9.1.1.8.8" class="ltx_td ltx_align_center ltx_border_bb">26.32%</td>
<td id="S4.T9.1.1.8.9" class="ltx_td ltx_align_center ltx_border_bb" style="background-color:#FF9999;"><span id="S4.T9.1.1.8.9.1" class="ltx_text" style="color:#660000;background-color:#FF9999;">-1.55%</span></td>
<td id="S4.T9.1.1.8.10" class="ltx_td ltx_align_center ltx_border_bb">52.87%</td>
<td id="S4.T9.1.1.8.11" class="ltx_td ltx_align_center ltx_border_bb" style="background-color:#FF9999;"><span id="S4.T9.1.1.8.11.1" class="ltx_text" style="color:#660000;background-color:#FF9999;">-2.06%</span></td>
</tr>
</table>
</span></div>
</figure>
<figure id="S4.F3" class="ltx_figure"><img src="/html/2312.09039/assets/x3.png" id="S4.F3.g1" class="ltx_graphics ltx_centering ltx_img_square" width="461" height="397" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3. </span>Token Allocation. T:A refers to the ratio of upper #token limitations of sampled table <span id="S4.F3.2.1" class="ltx_text ltx_font_italic">vs.</span> augment info.</figcaption>
</figure>
<div id="S4.SS6.p3" class="ltx_para">
<p id="S4.SS6.p3.1" class="ltx_p">(2) Diminishing returns are observed when too many tokens are allocated to the augmentation information (as in the 3:7 ratio). This leads to a decrease in performance, suggesting that beyond a certain point, additional augmentation tokens may not be beneficial and could potentially detract from the main table content.</p>
</div>
<div id="S4.SS6.p4" class="ltx_para">
<p id="S4.SS6.p4.1" class="ltx_p">This trade-off highlights a broader concept in data processing and machine learning: the balance between <span id="S4.SS6.p4.1.1" class="ltx_text ltx_font_italic">information overload</span> and <span id="S4.SS6.p4.1.2" class="ltx_text ltx_font_italic">information scarcity</span>. Over-augmentation can lead to confusion and difficulty in discerning key patterns or insights. On the other hand, excessive sampling could result in an incomplete or biased understanding of the data. Note that the optimal T: A Ratio may vary across different datasets, as each may have unique characteristics making certain ratios more effective.</p>
</div>
</section>
<section id="S4.SS7" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.7. </span>Ablation Study of TAP4LLM</h3>

<div id="S4.SS7.p1" class="ltx_para">
<p id="S4.SS7.p1.1" class="ltx_p">As indicated in Table <a href="#S4.T9" title="Table 9 ‣ 4.6. Trade-offs between token allocation ‣ 4. Experiments ‣ TAP4LLM: Table Provider on Sampling, Augmenting, and Packing Semi-structured Data for Large Language Model Reasoning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a>, we conduct an ablation study to assess the impact of various components on the performance of TAP4LLM. Each row represents the method performance without a certain component. We find that each component contributes to the model’s effectiveness. The study demonstrates that certain components, such as table sampling and table augmentation, are more crucial. Each dataset reacts differently to the removal of features, which highlights the necessity of a customized design when optimizing for particular datasets.</p>
</div>
<figure id="S4.F4" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2312.09039/assets/x4.png" id="S4.F4.g1" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="368" height="288" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4. </span>Comparative Analysis of Model Performance Across Four Datasets: FEVEROUS, HybridQA, TabFact, and SQA.
The series of graphs illustrates the frequency distribution of token lengths alongside the LLM performance (%) for three distinct methods: only sampling, only augmentation, and the hybrid method. Each subplot corresponds to a different dataset, depicting how table token length impacts model accuracy for various data augmentation and sampling strategies</figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<p id="S4.F4.1" class="ltx_p ltx_figure_panel ltx_align_center">.</p>
</div>
</div>
</figure>
</section>
<section id="S4.SS8" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.8. </span>Large Table Analysis</h3>

<div id="S4.SS8.p1" class="ltx_para">
<p id="S4.SS8.p1.1" class="ltx_p">Compared to the smaller-sized table, large table can grow to immense sizes, which make it more difficult to efficiently maintain, and reason over the tables. In designing TAP4LLM, performance optimization in this scenario is critical.
We plot the distribution regarding the token numbers from the table across the five datasets in Figure <a href="#S4.F4" title="Figure 4 ‣ 4.7. Ablation Study of TAP4LLM ‣ 4. Experiments ‣ TAP4LLM: Table Provider on Sampling, Augmenting, and Packing Semi-structured Data for Large Language Model Reasoning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, and also illustrate the impact of token numbers on LLM performance for three distinct methods: “only sampling”, “only augmentation”, and the “hybrid method”. Note that the “only sampling” method refers to using only the sampling method, without any augmentation methods. Specifically, we use query-based sampling with column grounding for this method. The “only augmentation” method refers to adding only the augmentation information to the prompt, without using any sampling method. In this method, all the augmentation information is simply combined. For the hybrid method, both table sampling and table augmentation methods are used to produce a unified framework.
We can observe that:</p>
</div>
<div id="S4.SS8.p2" class="ltx_para">
<p id="S4.SS8.p2.1" class="ltx_p">(1) Data Concentration at Shorter Token Lengths: All datasets show that a majority of the data samples contain a smaller number of tokens, indicated by the frequency distribution that skews towards the left of the graph. This trend suggests that most of the text entries in these datasets are relatively brief.</p>
</div>
<div id="S4.SS8.p3" class="ltx_para">
<p id="S4.SS8.p3.1" class="ltx_p">(2) Performance with Only Augmentation: The method involving only augmentation seems to yield better accuracy at shorter token lengths. This could imply that augmentation techniques are more effective for smaller tables, which may be due to a more focused and less noisy dataset enabling the model to learn and generalize better from less complex input.</p>
</div>
<div id="S4.SS8.p4" class="ltx_para">
<p id="S4.SS8.p4.1" class="ltx_p">(3) Performance with Only Sampling: In contrast, the method that relies only on sampling appears to be more effective for longer token lengths, which correspond to larger tables. This may be because sampling allows the model to handle a greater diversity of data and to process on more informed, longer sequences, thus enhancing its ability to understand and generate correct answers from larger table bodies.</p>
</div>
<div id="S4.SS8.p5" class="ltx_para">
<p id="S4.SS8.p5.1" class="ltx_p">(4) Performance with the Hybrid Method: The hybrid method, which combines both augmentation and sampling techniques, shows a more consistent and stable accuracy across different token lengths. Notably, there’s a slight increase in accuracy for larger tables with longer token lengths. This suggests that the hybrid method benefits from the strengths of both augmentation and sampling, providing a balanced approach that ensures stable performance across varying text lengths and complexities.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5. </span>Implementation Details</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">To achieve the interactive table reasoning,

TAP4LLM proposes the “table sync” to ensure that applications, such as Excel Copilot, maintain their table data in synchronization with the table manager. The table manager acts as a go-between, managing the data that is either stored locally in a cache or accessed through a database connection. Specifically, when changes are made to the data within the application, those changes must be reflected in the table manager for any operation performance, such as sampling, augmentation, and packing. Conversely, if changes are made within the table manager, the changed data should be updated in the application as well.</p>
</div>
<div id="S5.p2" class="ltx_para">
<p id="S5.p2.1" class="ltx_p">This syncing process is essential for maintaining data integrity and ensuring that all components of the system are kept up-to-date. This is especially beneficial when the data is being used to generate prompts for a large language model, as it allows for accurate data processing, querying, and analysis. By having the most current and relevant information, the model can provide accurate and reliable responses.</p>
</div>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6. </span>Related Work</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p"><span id="S6.p1.1.1" class="ltx_text ltx_font_bold">Large Language Models Usage Paradigms</span>.
With the development of Generative Pre-trained Transformers (GPTs) <cite class="ltx_cite ltx_citemacro_citep">(Radford et al<span class="ltx_text">.</span>, <a href="#bib.bib50" title="" class="ltx_ref">2018</a>, <a href="#bib.bib51" title="" class="ltx_ref">2019</a>; Brown et al<span class="ltx_text">.</span>, <a href="#bib.bib7" title="" class="ltx_ref">2020</a>; OpenAI, <a href="#bib.bib47" title="" class="ltx_ref">2023</a>, <a href="#bib.bib46" title="" class="ltx_ref">2022</a>)</cite> and other common LLMs <cite class="ltx_cite ltx_citemacro_citep">(Chen et al<span class="ltx_text">.</span>, <a href="#bib.bib11" title="" class="ltx_ref">2023</a>; Zeng et al<span class="ltx_text">.</span>, <a href="#bib.bib68" title="" class="ltx_ref">2022</a>; Touvron et al<span class="ltx_text">.</span>, <a href="#bib.bib57" title="" class="ltx_ref">2023</a>; Zhang et al<span class="ltx_text">.</span>, <a href="#bib.bib69" title="" class="ltx_ref">2022</a>)</cite>, many creative ways are proposed: End-to-End, Chain-of-Thought, and Semantic Parsing/Code Generation. Specifically, End-to-End <cite class="ltx_cite ltx_citemacro_citep">(Chen, <a href="#bib.bib8" title="" class="ltx_ref">2022</a>; Hoffmann et al<span class="ltx_text">.</span>, <a href="#bib.bib24" title="" class="ltx_ref">2022</a>)</cite> aims to leverage LLMs to generate final answers directly, often done by providing a task description with a few examples for in-context learning. While convenient to use, this approach has the disadvantage of being uninterpretable and relying solely on the LLMs’ training data, which can lead to a lack of robustness and sensitivity to slight input variations.
Chain-of-Thought  <cite class="ltx_cite ltx_citemacro_citep">(Wei et al<span class="ltx_text">.</span>, <a href="#bib.bib62" title="" class="ltx_ref">2022</a>; Kojima et al<span class="ltx_text">.</span>, <a href="#bib.bib35" title="" class="ltx_ref">2022b</a>; Gong et al<span class="ltx_text">.</span>, <a href="#bib.bib16" title="" class="ltx_ref">2020</a>)</cite> emphasizes breaking down complex reasoning into a series of intermediate steps. However, this method is unreliable and uncontrollable due to the potential for generated reasoning steps to be misaligned with the intended logical progression, or for incorrect or inconsistent answers to be produced when multiple questions are asked consecutively. Semantic Parsing/Code Generation <cite class="ltx_cite ltx_citemacro_citep">(Cheng et al<span class="ltx_text">.</span>, <a href="#bib.bib12" title="" class="ltx_ref">2023</a>; Ye et al<span class="ltx_text">.</span>, <a href="#bib.bib65" title="" class="ltx_ref">2023</a>; Gemmell and Dalton, <a href="#bib.bib15" title="" class="ltx_ref">2023</a>)</cite> leverages LLMs to convert natural language queries into executable code or structured representations. This approach enables more precise control over the generated output and facilitates better interpretability. Despite its advantages, this approach has several shortcomings, such as the limited coverage of programming language grammar and semantics. This restricts the model’s capacity to handle complex programming tasks and may necessitate the use of additional techniques to effectively process out-of-domain queries. Zhoujun Cheng et al. <cite class="ltx_cite ltx_citemacro_citep">(Cheng et al<span class="ltx_text">.</span>, <a href="#bib.bib12" title="" class="ltx_ref">2023</a>)</cite> propose one way to bridge the out-of-domain queries through LLMs. However, how to inject knowledge still lacks a thorough exploration and the trigger functions are still naive for complex queries.</p>
</div>
<div id="S6.p2" class="ltx_para">
<p id="S6.p2.1" class="ltx_p"><span id="S6.p2.1.1" class="ltx_text ltx_font_bold">Large Language Models for Tabular Data</span>.
Following the line of LLMs in natural language processing, researchers have also explored large models for various modalities like vision <cite class="ltx_cite ltx_citemacro_citep">(Gong et al<span class="ltx_text">.</span>, <a href="#bib.bib17" title="" class="ltx_ref">2023</a>; Kirillov et al<span class="ltx_text">.</span>, <a href="#bib.bib33" title="" class="ltx_ref">2023</a>)</cite> and speech <cite class="ltx_cite ltx_citemacro_citep">(Huang et al<span class="ltx_text">.</span>, <a href="#bib.bib26" title="" class="ltx_ref">2023</a>)</cite>. From a technical standpoint, their ability to generate human-like text has opened new vistas of possibilities for processing tabular data. Nevertheless, it is non-trivial to directly employ the vanilla ChatGPT model in the tabular area for two reasons: (i)-Global Table Understanding: the GPTs are known to suffer from the limited token length and thus, they can not read a whole large table, making them hard to understand the global tabular information. (ii)-Generalized to Tabular Domain: Second, their training processes are tailored for natural languages and thus, they are less generalizable when handling tabular data.</p>
</div>
<div id="S6.p3" class="ltx_para">
<p id="S6.p3.1" class="ltx_p">There have been several works <cite class="ltx_cite ltx_citemacro_citep">(Hu et al<span class="ltx_text">.</span>, <a href="#bib.bib25" title="" class="ltx_ref">2023</a>; Zhong et al<span class="ltx_text">.</span>, <a href="#bib.bib72" title="" class="ltx_ref">2017</a>; Li et al<span class="ltx_text">.</span>, <a href="#bib.bib38" title="" class="ltx_ref">2023a</a>, <a href="#bib.bib37" title="" class="ltx_ref">b</a>)</cite> developed to integrate natural language for tabular data analysis. NL2SQL (Nature language to SQL) <cite class="ltx_cite ltx_citemacro_citep">(Hu et al<span class="ltx_text">.</span>, <a href="#bib.bib25" title="" class="ltx_ref">2023</a>; Zhong et al<span class="ltx_text">.</span>, <a href="#bib.bib72" title="" class="ltx_ref">2017</a>; Li et al<span class="ltx_text">.</span>, <a href="#bib.bib38" title="" class="ltx_ref">2023a</a>)</cite> is a long-standing research topic that converts natural language to SQL commands that manipulate the relational database. Recently, SheetCopilot <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a href="#bib.bib37" title="" class="ltx_ref">2023b</a>)</cite> explored languages to VBA (Visual Basic for Applications, an embedded script language for Microsoft Excel) command to benefit from a rich set of spreadsheet software functionalities.
Compared to previous works, TAP4LLM acts as a dedicated pre-processor designed specifically to improve the efficiency and effectiveness of LLMs for tabular reasoning tasks. We examine the considerable influence of pre-processing on the LLMs’ performance when dealing with tabular data. We particularly emphasize the potential of table sampling to extract essential information from the original table, table augmentation to incorporate existing symbolic models and world knowledge, and table packing to manage token allocation for ICL. Our experiment results show that TAP4LLM significantly outperforms the baselines for table reasoning tasks. Beyond its remarkable performance, our system also offers a systematic framework to spur further research into the interpretation of structured data in LLMs.</p>
</div>
<div id="S6.p4" class="ltx_para">
<p id="S6.p4.1" class="ltx_p"><span id="S6.p4.1.1" class="ltx_text ltx_font_bold">Table Augmentation</span>.
Table augmentation is a technique used to improve the generalization performance and robustness of machine learning models.
To enhance the performance and capabilities of LLMs in various domains, various explorations have been done to augment their knowledge grounding. It involves incorporating structured knowledge <cite class="ltx_cite ltx_citemacro_citep">(Sui et al<span class="ltx_text">.</span>, <a href="#bib.bib55" title="" class="ltx_ref">2023</a>; Xie et al<span class="ltx_text">.</span>, <a href="#bib.bib64" title="" class="ltx_ref">2022</a>)</cite>, commonsense knowledge <cite class="ltx_cite ltx_citemacro_citep">(Bian et al<span class="ltx_text">.</span>, <a href="#bib.bib6" title="" class="ltx_ref">2023</a>; Ogundare and Araya, <a href="#bib.bib45" title="" class="ltx_ref">2023</a>; Shen et al<span class="ltx_text">.</span>, <a href="#bib.bib53" title="" class="ltx_ref">2023</a>; Guo et al<span class="ltx_text">.</span>, <a href="#bib.bib19" title="" class="ltx_ref">2023</a>)</cite>, and analytical knowledge <cite class="ltx_cite ltx_citemacro_citep">(He et al<span class="ltx_text">.</span>, <a href="#bib.bib20" title="" class="ltx_ref">2023</a>; Jena et al<span class="ltx_text">.</span>, <a href="#bib.bib31" title="" class="ltx_ref">2022</a>)</cite> into the pre-training and inference processes.
For example, <cite class="ltx_cite ltx_citemacro_citep">(Jena et al<span class="ltx_text">.</span>, <a href="#bib.bib31" title="" class="ltx_ref">2022</a>)</cite> proposes to semi-automatically transform existing tabular data to create diverse/inventive natural language inference instances for better zero-shot performance.
<cite class="ltx_cite ltx_citemacro_citep">(He et al<span class="ltx_text">.</span>, <a href="#bib.bib20" title="" class="ltx_ref">2023</a>)</cite> proposes a multi-tasking Metadata model that leverages field distribution and knowledge graph information to accurately infer analysis metadata for tables, and then demonstrates its deployment in a data analysis product for intelligent features. We follow the definition of statistical features from <cite class="ltx_cite ltx_citemacro_citep">(He et al<span class="ltx_text">.</span>, <a href="#bib.bib20" title="" class="ltx_ref">2023</a>)</cite>. Each term with the corresponding definition is shown in Table <a href="#S6.T10" title="Table 10 ‣ 6. Related Work ‣ TAP4LLM: Table Provider on Sampling, Augmenting, and Packing Semi-structured Data for Large Language Model Reasoning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10</span></a>.
TAP4LLM crowd-source previous table augmentation methods and integrate them for empirical study. This helps us understand which type of knowledge is essential for table reasoning in Language Models (LLMs). We consider this unified knowledge scope to extend the knowledge and reasoning capabilities of LLMs, which enables LLMs to handle a more extensive range of complex tasks with improved accuracy and enhanced contextual understanding.</p>
</div>
<figure id="S6.T10" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 10. </span>Detailed definition of statistics features.</figcaption>
<div id="S6.T10.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:451.4pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(9.3pt,-9.7pt) scale(1.04500547329675,1.04500547329675) ;">
<table id="S6.T10.1.1" class="ltx_tabular ltx_align_middle">
<tr id="S6.T10.1.1.1" class="ltx_tr">
<td id="S6.T10.1.1.1.1" class="ltx_td ltx_align_left ltx_border_tt"><span id="S6.T10.1.1.1.1.1" class="ltx_text ltx_font_bold">Features</span></td>
<td id="S6.T10.1.1.1.2" class="ltx_td ltx_align_left ltx_border_tt"><span id="S6.T10.1.1.1.2.1" class="ltx_text ltx_font_bold">Definition</span></td>
</tr>
<tr id="S6.T10.1.1.2" class="ltx_tr">
<td id="S6.T10.1.1.2.1" class="ltx_td ltx_align_left ltx_border_t"><span id="S6.T10.1.1.2.1.1" class="ltx_text ltx_font_bold">Progression Type:</span></td>
<td id="S6.T10.1.1.2.2" class="ltx_td ltx_border_t"></td>
</tr>
<tr id="S6.T10.1.1.3" class="ltx_tr">
<td id="S6.T10.1.1.3.1" class="ltx_td ltx_align_left">ChangeRate</td>
<td id="S6.T10.1.1.3.2" class="ltx_td ltx_align_left">Proportion of different adjacent values</td>
</tr>
<tr id="S6.T10.1.1.4" class="ltx_tr">
<td id="S6.T10.1.1.4.1" class="ltx_td ltx_align_left">PartialOrdered</td>
<td id="S6.T10.1.1.4.2" class="ltx_td ltx_align_left">Maximum proportion of increasing / decreasing adjacent values</td>
</tr>
<tr id="S6.T10.1.1.5" class="ltx_tr">
<td id="S6.T10.1.1.5.1" class="ltx_td ltx_align_left">OrderedConfidence</td>
<td id="S6.T10.1.1.5.2" class="ltx_td ltx_align_left">Indicator of sequentiality</td>
</tr>
<tr id="S6.T10.1.1.6" class="ltx_tr">
<td id="S6.T10.1.1.6.1" class="ltx_td ltx_align_left"><span id="S6.T10.1.1.6.1.1" class="ltx_text ltx_font_bold">String Features:</span></td>
<td id="S6.T10.1.1.6.2" class="ltx_td"></td>
</tr>
<tr id="S6.T10.1.1.7" class="ltx_tr">
<td id="S6.T10.1.1.7.1" class="ltx_td ltx_align_left">AggrPercentFormatted</td>
<td id="S6.T10.1.1.7.2" class="ltx_td ltx_align_left">Proportion of cells having percent format</td>
</tr>
<tr id="S6.T10.1.1.8" class="ltx_tr">
<td id="S6.T10.1.1.8.1" class="ltx_td ltx_align_left">CommonPrefix</td>
<td id="S6.T10.1.1.8.2" class="ltx_td ltx_align_left">Proportion of most common prefix digit</td>
</tr>
<tr id="S6.T10.1.1.9" class="ltx_tr">
<td id="S6.T10.1.1.9.1" class="ltx_td ltx_align_left">CommonSuffix</td>
<td id="S6.T10.1.1.9.2" class="ltx_td ltx_align_left">Proportion of most common suffix digit</td>
</tr>
<tr id="S6.T10.1.1.10" class="ltx_tr">
<td id="S6.T10.1.1.10.1" class="ltx_td ltx_align_left"><span id="S6.T10.1.1.10.1.1" class="ltx_text ltx_font_bold">Number Range Features:</span></td>
<td id="S6.T10.1.1.10.2" class="ltx_td"></td>
</tr>
<tr id="S6.T10.1.1.11" class="ltx_tr">
<td id="S6.T10.1.1.11.1" class="ltx_td ltx_align_left">Aggr01Ranged</td>
<td id="S6.T10.1.1.11.2" class="ltx_td ltx_align_left">Proportion of values ranged in 0-1</td>
</tr>
<tr id="S6.T10.1.1.12" class="ltx_tr">
<td id="S6.T10.1.1.12.1" class="ltx_td ltx_align_left">Aggr0100Ranged</td>
<td id="S6.T10.1.1.12.2" class="ltx_td ltx_align_left">Proportion of values ranged in 0-100</td>
</tr>
<tr id="S6.T10.1.1.13" class="ltx_tr">
<td id="S6.T10.1.1.13.1" class="ltx_td ltx_align_left">AggrIntegers</td>
<td id="S6.T10.1.1.13.2" class="ltx_td ltx_align_left">Proportion of integer values</td>
</tr>
<tr id="S6.T10.1.1.14" class="ltx_tr">
<td id="S6.T10.1.1.14.1" class="ltx_td ltx_align_left">AggrNegative</td>
<td id="S6.T10.1.1.14.2" class="ltx_td ltx_align_left">Proportion of negative values</td>
</tr>
<tr id="S6.T10.1.1.15" class="ltx_tr">
<td id="S6.T10.1.1.15.1" class="ltx_td ltx_align_left"><span id="S6.T10.1.1.15.1.1" class="ltx_text ltx_font_bold">Distribution features:</span></td>
<td id="S6.T10.1.1.15.2" class="ltx_td"></td>
</tr>
<tr id="S6.T10.1.1.16" class="ltx_tr">
<td id="S6.T10.1.1.16.1" class="ltx_td ltx_align_left">Variance</td>
<td id="S6.T10.1.1.16.2" class="ltx_td ltx_align_left">Standard deviation of a given series of data</td>
</tr>
<tr id="S6.T10.1.1.17" class="ltx_tr">
<td id="S6.T10.1.1.17.1" class="ltx_td ltx_align_left">Range</td>
<td id="S6.T10.1.1.17.2" class="ltx_td ltx_align_left">Values range</td>
</tr>
<tr id="S6.T10.1.1.18" class="ltx_tr">
<td id="S6.T10.1.1.18.1" class="ltx_td ltx_align_left">Cardinality</td>
<td id="S6.T10.1.1.18.2" class="ltx_td ltx_align_left">Proportion of distinct values</td>
</tr>
<tr id="S6.T10.1.1.19" class="ltx_tr">
<td id="S6.T10.1.1.19.1" class="ltx_td ltx_align_left">Spread</td>
<td id="S6.T10.1.1.19.2" class="ltx_td ltx_align_left">Cardinality divided by range</td>
</tr>
<tr id="S6.T10.1.1.20" class="ltx_tr">
<td id="S6.T10.1.1.20.1" class="ltx_td ltx_align_left">Major</td>
<td id="S6.T10.1.1.20.2" class="ltx_td ltx_align_left">Proportion of the most frequent value</td>
</tr>
<tr id="S6.T10.1.1.21" class="ltx_tr">
<td id="S6.T10.1.1.21.1" class="ltx_td ltx_align_left">Benford</td>
<td id="S6.T10.1.1.21.2" class="ltx_td ltx_align_left">Distance of the first digit distribution to real-life average</td>
</tr>
<tr id="S6.T10.1.1.22" class="ltx_tr">
<td id="S6.T10.1.1.22.1" class="ltx_td ltx_align_left">Skewness</td>
<td id="S6.T10.1.1.22.2" class="ltx_td ltx_align_left">Skewness of numeric values</td>
</tr>
<tr id="S6.T10.1.1.23" class="ltx_tr">
<td id="S6.T10.1.1.23.1" class="ltx_td ltx_align_left">Kurtosis</td>
<td id="S6.T10.1.1.23.2" class="ltx_td ltx_align_left">Kurtosis of numeric values</td>
</tr>
<tr id="S6.T10.1.1.24" class="ltx_tr">
<td id="S6.T10.1.1.24.1" class="ltx_td ltx_align_left ltx_border_bb">Gini</td>
<td id="S6.T10.1.1.24.2" class="ltx_td ltx_align_left ltx_border_bb">Gini coefficient of numeric values</td>
</tr>
</table>
</span></div>
</figure>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7. </span>Conclusion</h2>

<div id="S7.p1" class="ltx_para">
<p id="S7.p1.1" class="ltx_p">We present TAP4LLM, a pre-processor designed to enhance the effectiveness of LLMs in tabular reasoning tasks.
Technically, our method paves the way for interactive table reasoning as a natural language-driven framework, allowing for different components as plugins. Through three core components: table sampling, table augmentation, and table packing &amp; serialization, we address several major challenges in comprehensive table understanding.
We believe that TAP4LLM has the potential to revolutionize table reasoning by enhancing table modeling and exploratory data analysis (EDA) and enabling various domains such as finance, transportation, scientific research,<span id="S7.p1.1.1" class="ltx_text ltx_font_italic">etc</span>. Our study will be beneficial for table-based research and serve as an auxiliary tool to help better utilize LLMs on tabular-based/structured data-based tasks.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(1)</span>
<span class="ltx_bibblock">        




</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">ope ([n.d.])</span>
<span class="ltx_bibblock">
[n.d.].

</span>
<span class="ltx_bibblock">New and Improved Embedding Model.

</span>
<span class="ltx_bibblock">https://openai.com/blog/new-and-improved-embedding-model.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">zot ([n.d.])</span>
<span class="ltx_bibblock">
[n.d.].

</span>
<span class="ltx_bibblock">OpenAI Platform.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://platform.openai.com" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://platform.openai.com</a>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Aghajanyan et al<span id="bib.bib4.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Armen Aghajanyan, Dmytro Okhonko, Mike Lewis, Mandar Joshi, Hu Xu, Gargi Ghosh, and Luke Zettlemoyer. 2021.

</span>
<span class="ltx_bibblock">HTLM: Hyper-Text Pre-Training and Prompting of Language Models.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:2107.06955 [cs]

<a target="_blank" href="http://arxiv.org/abs/2107.06955" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://arxiv.org/abs/2107.06955</a>

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Babaev et al<span id="bib.bib5.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Dmitrii Babaev, Maxim Savchenko, Alexander Tuzhilin, and Dmitrii Umerenkov. 2019.

</span>
<span class="ltx_bibblock">E.T.-RNN: Applying Deep Learning to Credit Loan Applications. In <em id="bib.bib5.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</em> <em id="bib.bib5.4.2" class="ltx_emph ltx_font_italic">(KDD ’19)</em>. Association for Computing Machinery, New York, NY, USA, 2183–2190.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/3292500.3330693" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3292500.3330693</a>

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bian et al<span id="bib.bib6.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Ning Bian, Xianpei Han, Le Sun, Hongyu Lin, Yaojie Lu, and Ben He. 2023.

</span>
<span class="ltx_bibblock">ChatGPT Is a Knowledgeable but Inexperienced Solver: An Investigation of Commonsense Problem in Large Language Models.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.48550/arXiv.2303.16421" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.48550/arXiv.2303.16421</a>
arXiv:2303.16421 [cs]

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brown et al<span id="bib.bib7.3.3.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al<span id="bib.bib7.4.1" class="ltx_text">.</span> 2020.

</span>
<span class="ltx_bibblock">Language models are few-shot learners.

</span>
<span class="ltx_bibblock"><em id="bib.bib7.5.1" class="ltx_emph ltx_font_italic">Advances in neural information processing systems</em> 33 (2020), 1877–1901.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen (2022)</span>
<span class="ltx_bibblock">
Wenhu Chen. 2022.

</span>
<span class="ltx_bibblock">Large Language Models Are Few(1)-Shot Table Reasoners.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.48550/arXiv.2210.06710" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.48550/arXiv.2210.06710</a>
arXiv:2210.06710 [cs]

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al<span id="bib.bib9.2.2.1" class="ltx_text">.</span> (2020a)</span>
<span class="ltx_bibblock">
Wenhu Chen, Hongmin Wang, Jianshu Chen, Yunkai Zhang, Hong Wang, Shiyang Li, Xiyou Zhou, and William Yang Wang. 2020a.

</span>
<span class="ltx_bibblock">TabFact: A Large-Scale Dataset for Table-Based Fact Verification.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.48550/arXiv.1909.02164" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.48550/arXiv.1909.02164</a>
arXiv:1909.02164 [cs]

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al<span id="bib.bib10.2.2.1" class="ltx_text">.</span> (2020b)</span>
<span class="ltx_bibblock">
Wenhu Chen, Hanwen Zha, Zhiyu Chen, Wenhan Xiong, Hong Wang, and William Yang Wang. 2020b.

</span>
<span class="ltx_bibblock">HybridQA: A Dataset of Multi-Hop Question Answering over Tabular and Textual Data. In <em id="bib.bib10.3.1" class="ltx_emph ltx_font_italic">Findings of the Association for Computational Linguistics: EMNLP 2020</em>. Association for Computational Linguistics, Online, 1026–1036.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.18653/v1/2020.findings-emnlp.91" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.18653/v1/2020.findings-emnlp.91</a>

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al<span id="bib.bib11.3.3.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Zhihong Chen, Feng Jiang, Junying Chen, Tiannan Wang, Fei Yu, Guiming Chen, Hongbo Zhang, Juhao Liang, Chen Zhang, Zhiyi Zhang, et al<span id="bib.bib11.4.1" class="ltx_text">.</span> 2023.

</span>
<span class="ltx_bibblock">Phoenix: Democratizing chatgpt across languages.

</span>
<span class="ltx_bibblock"><em id="bib.bib11.5.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2304.10453</em> (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cheng et al<span id="bib.bib12.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Zhoujun Cheng, Tianbao Xie, Peng Shi, Chengzu Li, Rahul Nadkarni, Yushi Hu, Caiming Xiong, Dragomir Radev, Mari Ostendorf, Luke Zettlemoyer, Noah A. Smith, and Tao Yu. 2023.

</span>
<span class="ltx_bibblock">Binding Language Models in Symbolic Languages.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.48550/arXiv.2210.02875" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.48550/arXiv.2210.02875</a>
arXiv:2210.02875 [cs]

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Deng et al<span id="bib.bib13.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Xiang Deng, Huan Sun, Alyssa Lees, You Wu, and Cong Yu. 2020.

</span>
<span class="ltx_bibblock">TURL: Table Understanding through Representation Learning.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.48550/arXiv.2006.14806" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.48550/arXiv.2006.14806</a>
arXiv:2006.14806 [cs]

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ding et al<span id="bib.bib14.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Rui Ding, Shi Han, Yong Xu, Haidong Zhang, and Dongmei Zhang. 2019.

</span>
<span class="ltx_bibblock">QuickInsights: Quick and Automatic Discovery of Insights from Multi-Dimensional Data. In <em id="bib.bib14.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 2019 International Conference on Management of Data</em> <em id="bib.bib14.4.2" class="ltx_emph ltx_font_italic">(SIGMOD ’19)</em>. Association for Computing Machinery, New York, NY, USA, 317–332.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/3299869.3314037" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3299869.3314037</a>

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gemmell and Dalton (2023)</span>
<span class="ltx_bibblock">
Carlos Gemmell and Jeffrey Dalton. 2023.

</span>
<span class="ltx_bibblock">Generate, Transform, Answer: Question Specific Tool Synthesis for Tabular Data.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.48550/arXiv.2303.10138" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.48550/arXiv.2303.10138</a>
arXiv:2303.10138 [cs]

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gong et al<span id="bib.bib16.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Heng Gong, Yawei Sun, Xiaocheng Feng, Bing Qin, Wei Bi, Xiaojiang Liu, and Ting Liu. 2020.

</span>
<span class="ltx_bibblock">TableGPT: Few-Shot Table-to-Text Generation with Table Structure Reconstruction and Content Matching. In <em id="bib.bib16.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 28th International Conference on Computational Linguistics</em>. International Committee on Computational Linguistics, Barcelona, Spain (Online), 1978–1988.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.18653/v1/2020.coling-main.179" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.18653/v1/2020.coling-main.179</a>

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gong et al<span id="bib.bib17.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Tao Gong, Chengqi Lyu, Shilong Zhang, Yudong Wang, Miao Zheng, Qian Zhao, Kuikun Liu, Wenwei Zhang, Ping Luo, and Kai Chen. 2023.

</span>
<span class="ltx_bibblock">Multimodal-gpt: A vision and language model for dialogue with humans.

</span>
<span class="ltx_bibblock"><em id="bib.bib17.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2305.04790</em> (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Günther et al<span id="bib.bib18.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Michael Günther, Maik Thiele, Julius Gonsior, and Wolfgang Lehner. 2021.

</span>
<span class="ltx_bibblock">Pre-Trained Web Table Embeddings for Table Discovery. In <em id="bib.bib18.3.1" class="ltx_emph ltx_font_italic">Fourth Workshop in Exploiting AI Techniques for Data Management</em>. 24–31.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Guo et al<span id="bib.bib19.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Biyang Guo, Xin Zhang, Ziyuan Wang, Minqi Jiang, Jinran Nie, Yuxuan Ding, Jianwei Yue, and Yupeng Wu. 2023.

</span>
<span class="ltx_bibblock">How Close Is ChatGPT to Human Experts? Comparison Corpus, Evaluation, and Detection.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.48550/arXiv.2301.07597" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.48550/arXiv.2301.07597</a>
arXiv:2301.07597 [cs]

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He et al<span id="bib.bib20.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Xinyi He, Mengyu Zhou, Mingjie Zhou, Jialiang Xu, Xiao Lv, Tianle Li, Yijia Shao, Shi Han, Zejian Yuan, and Dongmei Zhang. 2023.

</span>
<span class="ltx_bibblock">AnaMeta: A Table Understanding Dataset of Field Metadata Knowledge Shared by Multi-dimensional Data Analysis Tasks. In <em id="bib.bib20.3.1" class="ltx_emph ltx_font_italic">Findings of the Association for Computational Linguistics: ACL 2023</em>. 9471–9492.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Herzig et al<span id="bib.bib21.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Jonathan Herzig, Pawel Krzysztof Nowak, Thomas Müller, Francesco Piccinno, and Julian Eisenschlos. 2020.

</span>
<span class="ltx_bibblock">TaPas: Weakly Supervised Table Parsing via Pre-Training. In <em id="bib.bib21.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</em>. Association for Computational Linguistics, Online, 4320–4333.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.18653/v1/2020.acl-main.398" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.18653/v1/2020.acl-main.398</a>

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hitzler et al<span id="bib.bib22.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Pascal Hitzler, Aaron Eberhart, Monireh Ebrahimi, Md Kamruzzaman Sarker, and Lu Zhou. 2022.

</span>
<span class="ltx_bibblock">Neuro-Symbolic Approaches in Artificial Intelligence.

</span>
<span class="ltx_bibblock"><em id="bib.bib22.3.1" class="ltx_emph ltx_font_italic">National Science Review</em> 9, 6 (2022), nwac035.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1093/nsr/nwac035" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1093/nsr/nwac035</a>

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hoelscher and Mortimer (2018)</span>
<span class="ltx_bibblock">
Jamie Hoelscher and Amanda Mortimer. 2018.

</span>
<span class="ltx_bibblock">Using Tableau to Visualize Data and Drive Decision-Making.

</span>
<span class="ltx_bibblock"><em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">Journal of Accounting Education</em> 44 (2018), 49–59.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1016/j.jaccedu.2018.05.002" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1016/j.jaccedu.2018.05.002</a>

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hoffmann et al<span id="bib.bib24.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Jordan Hoffmann, Sebastian Borgeaud, Arthur Mensch, Elena Buchatskaya, Trevor Cai, Eliza Rutherford, Diego de Las Casas, Lisa Anne Hendricks, Johannes Welbl, Aidan Clark, Tom Hennigan, Eric Noland, Katie Millican, George van den Driessche, Bogdan Damoc, Aurelia Guy, Simon Osindero, Karen Simonyan, Erich Elsen, Jack W. Rae, Oriol Vinyals, and Laurent Sifre. 2022.

</span>
<span class="ltx_bibblock">Training Compute-Optimal Large Language Models.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:2203.15556 [cs.CL]

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hu et al<span id="bib.bib25.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Chenxu Hu, Jie Fu, Chenzhuang Du, Simian Luo, Junbo Zhao, and Hang Zhao. 2023.

</span>
<span class="ltx_bibblock">ChatDB: Augmenting LLMs with Databases as Their Symbolic Memory.

</span>
<span class="ltx_bibblock"><em id="bib.bib25.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2306.03901</em> (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang et al<span id="bib.bib26.3.3.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Rongjie Huang, Mingze Li, Dongchao Yang, Jiatong Shi, Xuankai Chang, Zhenhui Ye, Yuning Wu, Zhiqing Hong, Jiawei Huang, Jinglin Liu, et al<span id="bib.bib26.4.1" class="ltx_text">.</span> 2023.

</span>
<span class="ltx_bibblock">Audiogpt: Understanding and generating speech, music, sound, and talking head.

</span>
<span class="ltx_bibblock"><em id="bib.bib26.5.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2304.12995</em> (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">IDEA-CCNL (2023)</span>
<span class="ltx_bibblock">
IDEA-CCNL. 2023.

</span>
<span class="ltx_bibblock">Fengshenbang-LM.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://github.com/IDEA-CCNL/Fengshenbang-LM" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/IDEA-CCNL/Fengshenbang-LM</a>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Iida et al<span id="bib.bib28.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Hiroshi Iida, Dung Thai, Varun Manjunatha, and Mohit Iyyer. 2021.

</span>
<span class="ltx_bibblock">TABBIE: Pretrained Representations of Tabular Data.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.48550/arXiv.2105.02584" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.48550/arXiv.2105.02584</a>
arXiv:2105.02584 [cs]

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Intelligence (2023)</span>
<span class="ltx_bibblock">
Baichuan Intelligence. 2023.

</span>
<span class="ltx_bibblock">Baichuan-7B.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://github.com/baichuan-inc/baichuan-7B" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/baichuan-inc/baichuan-7B</a>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Iyyer et al<span id="bib.bib30.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Mohit Iyyer, Wen-tau Yih, and Ming-Wei Chang. 2017.

</span>
<span class="ltx_bibblock">Search-Based Neural Structured Learning for Sequential Question Answering. In <em id="bib.bib30.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em>. Association for Computational Linguistics, Vancouver, Canada, 1821–1831.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.18653/v1/P17-1167" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.18653/v1/P17-1167</a>

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jena et al<span id="bib.bib31.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Aashna Jena, Vivek Gupta, Manish Shrivastava, and Julian Martin Eisenschlos. 2022.

</span>
<span class="ltx_bibblock">Leveraging Data Recasting to Enhance Tabular Reasoning.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.48550/arXiv.2211.12641" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.48550/arXiv.2211.12641</a>
arXiv:2211.12641 [cs]

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jiang et al<span id="bib.bib32.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Zhengbao Jiang, Frank F. Xu, Luyu Gao, Zhiqing Sun, Qian Liu, Jane Dwivedi-Yu, Yiming Yang, Jamie Callan, and Graham Neubig. 2023.

</span>
<span class="ltx_bibblock">Active Retrieval Augmented Generation.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:2305.06983 [cs.CL]

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kirillov et al<span id="bib.bib33.3.3.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Alexander Kirillov, Eric Mintun, Nikhila Ravi, Hanzi Mao, Chloe Rolland, Laura Gustafson, Tete Xiao, Spencer Whitehead, Alexander C Berg, Wan-Yen Lo, et al<span id="bib.bib33.4.1" class="ltx_text">.</span> 2023.

</span>
<span class="ltx_bibblock">Segment anything.

</span>
<span class="ltx_bibblock"><em id="bib.bib33.5.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2304.02643</em> (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kojima et al<span id="bib.bib34.2.2.1" class="ltx_text">.</span> (2022a)</span>
<span class="ltx_bibblock">
Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa. 2022a.

</span>
<span class="ltx_bibblock">Large language models are zero-shot reasoners.

</span>
<span class="ltx_bibblock"><em id="bib.bib34.3.1" class="ltx_emph ltx_font_italic">Advances in neural information processing systems</em> 35 (2022), 22199–22213.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kojima et al<span id="bib.bib35.2.2.1" class="ltx_text">.</span> (2022b)</span>
<span class="ltx_bibblock">
Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa. 2022b.

</span>
<span class="ltx_bibblock">Large Language Models Are Zero-Shot Reasoners.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.48550/arXiv.2205.11916" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.48550/arXiv.2205.11916</a>
arXiv:2205.11916 [cs]

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">LangChain (2022)</span>
<span class="ltx_bibblock">
LangChain. 2022.

</span>
<span class="ltx_bibblock">LangChain.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://blog.langchain.dev/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://blog.langchain.dev/</a>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al<span id="bib.bib37.2.2.1" class="ltx_text">.</span> (2023b)</span>
<span class="ltx_bibblock">
Hongxin Li, Jingran Su, Yuntao Chen, Qing Li, and Zhaoxiang Zhang. 2023b.

</span>
<span class="ltx_bibblock">SheetCopilot: Bringing Software Productivity to the Next Level through Large Language Models.

</span>
<span class="ltx_bibblock"><em id="bib.bib37.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2305.19308</em> (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al<span id="bib.bib38.2.2.1" class="ltx_text">.</span> (2023a)</span>
<span class="ltx_bibblock">
Jinyang Li, Binyuan Hui, Reynold Cheng, Bowen Qin, Chenhao Ma, Nan Huo, Fei Huang, Wenyu Du, Luo Si, and Yongbin Li. 2023a.

</span>
<span class="ltx_bibblock">Graphix-t5: Mixing pre-trained transformers with graph-aware layers for text-to-sql parsing.

</span>
<span class="ltx_bibblock"><em id="bib.bib38.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2301.07507</em> (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al<span id="bib.bib39.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Liyao Li, Haobo Wang, Liangyu Zha, Qingyi Huang, Sai Wu, Gang Chen, and Junbo Zhao. 2022.

</span>
<span class="ltx_bibblock">Learning a Data-Driven Policy Network for Pre-Training Automated Feature Engineering. In <em id="bib.bib39.3.1" class="ltx_emph ltx_font_italic">The Eleventh International Conference on Learning Representations</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al<span id="bib.bib40.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Qian Liu, Bei Chen, Jiaqi Guo, Morteza Ziyadi, Zeqi Lin, Weizhu Chen, and Jian-Guang Lou. 2022.

</span>
<span class="ltx_bibblock">TAPEX: Table Pre-Training via Learning a Neural SQL Executor.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.48550/arXiv.2107.07653" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.48550/arXiv.2107.07653</a>
arXiv:2107.07653 [cs]

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al<span id="bib.bib41.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Yiheng Liu, Tianle Han, Siyuan Ma, Jiayue Zhang, Yuanyuan Yang, Jiaming Tian, Hao He, Antong Li, Mengshen He, Zhengliang Liu, Zihao Wu, Dajiang Zhu, Xiang Li, Ning Qiang, Dingang Shen, Tianming Liu, and Bao Ge. 2023.

</span>
<span class="ltx_bibblock">Summary of ChatGPT/GPT-4 Research and Perspective Towards the Future of Large Language Models.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.48550/arXiv.2304.01852" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.48550/arXiv.2304.01852</a>
arXiv:2304.01852 [cs]

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">MacQueen et al<span id="bib.bib42.3.3.1" class="ltx_text">.</span> (1967)</span>
<span class="ltx_bibblock">
James MacQueen et al<span id="bib.bib42.4.1" class="ltx_text">.</span> 1967.

</span>
<span class="ltx_bibblock">Some methods for classification and analysis of multivariate observations. In <em id="bib.bib42.5.1" class="ltx_emph ltx_font_italic">Proceedings of the fifth Berkeley symposium on mathematical statistics and probability</em>, Vol. 1. Oakland, CA, USA, 281–297.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">matthewbolanos (2023)</span>
<span class="ltx_bibblock">
matthewbolanos. 2023.

</span>
<span class="ltx_bibblock">Orchestrate Your AI with Semantic Kernel.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://learn.microsoft.com/en-us/semantic-kernel/overview/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://learn.microsoft.com/en-us/semantic-kernel/overview/</a>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nakano et al<span id="bib.bib44.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Reiichiro Nakano, Jacob Hilton, Suchir Balaji, Jeff Wu, Long Ouyang, Christina Kim, Christopher Hesse, Shantanu Jain, Vineet Kosaraju, William Saunders, Xu Jiang, Karl Cobbe, Tyna Eloundou, Gretchen Krueger, Kevin Button, Matthew Knight, Benjamin Chess, and John Schulman. 2022.

</span>
<span class="ltx_bibblock">WebGPT: Browser-assisted question-answering with human feedback.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:2112.09332 [cs.CL]

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ogundare and Araya (2023)</span>
<span class="ltx_bibblock">
Oluwatosin Ogundare and Gustavo Quiros Araya. 2023.

</span>
<span class="ltx_bibblock">Comparative Analysis of CHATGPT and the Evolution of Language Models.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.48550/arXiv.2304.02468" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.48550/arXiv.2304.02468</a>
arXiv:2304.02468 [cs]

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">OpenAI (2022)</span>
<span class="ltx_bibblock">
OpenAI. 2022.

</span>
<span class="ltx_bibblock">ChatGPT.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://openai.com/blog/chatgpt" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://openai.com/blog/chatgpt</a>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">OpenAI (2023)</span>
<span class="ltx_bibblock">
OpenAI. 2023.

</span>
<span class="ltx_bibblock">GPT-4 Technical Report.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:2303.08774 [cs.CL]

</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ouyang et al<span id="bib.bib48.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Long Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L. Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, John Schulman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda Askell, Peter Welinder, Paul Christiano, Jan Leike, and Ryan Lowe. 2022.

</span>
<span class="ltx_bibblock">Training Language Models to Follow Instructions with Human Feedback.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.48550/arXiv.2203.02155" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.48550/arXiv.2203.02155</a>
arXiv:2203.02155 [cs]

</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pasupat and Liang (2015)</span>
<span class="ltx_bibblock">
Panupong Pasupat and Percy Liang. 2015.

</span>
<span class="ltx_bibblock">Compositional Semantic Parsing on Semi-Structured Tables.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:1508.00305 [cs.CL]

</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Radford et al<span id="bib.bib50.3.3.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Alec Radford, Karthik Narasimhan, Tim Salimans, Ilya Sutskever, et al<span id="bib.bib50.4.1" class="ltx_text">.</span> 2018.

</span>
<span class="ltx_bibblock">Improving language understanding by generative pre-training.

</span>
<span class="ltx_bibblock">(2018).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Radford et al<span id="bib.bib51.3.3.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et al<span id="bib.bib51.4.1" class="ltx_text">.</span> 2019.

</span>
<span class="ltx_bibblock">Language models are unsupervised multitask learners.

</span>
<span class="ltx_bibblock"><em id="bib.bib51.5.1" class="ltx_emph ltx_font_italic">OpenAI blog</em> 1, 8 (2019), 9.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Reimers and Gurevych (2019)</span>
<span class="ltx_bibblock">
Nils Reimers and Iryna Gurevych. 2019.

</span>
<span class="ltx_bibblock">Sentence-bert: Sentence embeddings using siamese bert-networks.

</span>
<span class="ltx_bibblock"><em id="bib.bib52.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1908.10084</em> (2019).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shen et al<span id="bib.bib53.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Xinyue Shen, Zeyuan Chen, Michael Backes, and Yang Zhang. 2023.

</span>
<span class="ltx_bibblock">In ChatGPT We Trust? Measuring and Characterizing the Reliability of ChatGPT.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.48550/arXiv.2304.08979" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.48550/arXiv.2304.08979</a>
arXiv:2304.08979 [cs]

</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shi et al<span id="bib.bib54.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Weijia Shi, Sewon Min, Michihiro Yasunaga, Minjoon Seo, Rich James, Mike Lewis, Luke Zettlemoyer, and Wen-tau Yih. 2023.

</span>
<span class="ltx_bibblock">REPLUG: Retrieval-Augmented Black-Box Language Models.

</span>
<span class="ltx_bibblock"><em id="bib.bib54.3.1" class="ltx_emph ltx_font_italic">CoRR</em> abs/2301.12652 (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sui et al<span id="bib.bib55.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Yuan Sui, Mengyu Zhou, Mingjie Zhou, Shi Han, and Dongmei Zhang. 2023.

</span>
<span class="ltx_bibblock">Evaluating and Enhancing Structural Understanding Capabilities of Large Language Models on Tables via Input Designs.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:2305.13062 [cs.CL]

</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tay et al<span id="bib.bib56.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Yi Tay, Mostafa Dehghani, Dara Bahri, and Donald Metzler. 2022.

</span>
<span class="ltx_bibblock">Efficient Transformers: A Survey.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.48550/arXiv.2009.06732" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.48550/arXiv.2009.06732</a>
arXiv:2009.06732 [cs]

</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Touvron et al<span id="bib.bib57.3.3.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, et al<span id="bib.bib57.4.1" class="ltx_text">.</span> 2023.

</span>
<span class="ltx_bibblock">Llama: Open and efficient foundation language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib57.5.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2302.13971</em> (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vamathevan et al<span id="bib.bib58.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Jessica Vamathevan, Dominic Clark, Paul Czodrowski, Ian Dunham, Edgardo Ferran, George Lee, Bin Li, Anant Madabhushi, Parantu Shah, Michaela Spitzer, and Shanrong Zhao. 2019.

</span>
<span class="ltx_bibblock">Applications of Machine Learning in Drug Discovery and Development.

</span>
<span class="ltx_bibblock"><em id="bib.bib58.3.1" class="ltx_emph ltx_font_italic">Nat Rev Drug Discov</em> 18, 6 (2019), 463–477.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1038/s41573-019-0024-5" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1038/s41573-019-0024-5</a>

</span>
</li>
<li id="bib.bib59" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vaswani et al<span id="bib.bib59.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. 2017.

</span>
<span class="ltx_bibblock">Attention Is All You Need. In <em id="bib.bib59.3.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>, Vol. 30. Curran Associates, Inc.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://proceedings.neurips.cc/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://proceedings.neurips.cc/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html</a>

</span>
</li>
<li id="bib.bib60" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al<span id="bib.bib60.3.3.1" class="ltx_text">.</span> (2021b)</span>
<span class="ltx_bibblock">
Jianguo Wang, Xiaomeng Yi, Rentong Guo, Hai Jin, Peng Xu, Shengjun Li, Xiangyu Wang, Xiangzhou Guo, Chengming Li, Xiaohai Xu, et al<span id="bib.bib60.4.1" class="ltx_text">.</span> 2021b.

</span>
<span class="ltx_bibblock">Milvus: A purpose-built vector data management system. In <em id="bib.bib60.5.1" class="ltx_emph ltx_font_italic">Proceedings of the 2021 International Conference on Management of Data</em>. 2614–2627.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib61" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al<span id="bib.bib61.2.2.1" class="ltx_text">.</span> (2021a)</span>
<span class="ltx_bibblock">
Zhiruo Wang, Haoyu Dong, Ran Jia, Jia Li, Zhiyi Fu, Shi Han, and Dongmei Zhang. 2021a.

</span>
<span class="ltx_bibblock">TUTA: Tree-Based Transformers for Generally Structured Table Pre-Training. In <em id="bib.bib61.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining</em>. 1780–1790.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1145/3447548.3467434" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3447548.3467434</a>
arXiv:2010.12537 [cs]

</span>
</li>
<li id="bib.bib62" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wei et al<span id="bib.bib62.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed Chi, Quoc Le, and Denny Zhou. 2022.

</span>
<span class="ltx_bibblock">Chain of Thought Prompting Elicits Reasoning in Large Language Models.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.48550/arXiv.2201.11903" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.48550/arXiv.2201.11903</a>
arXiv:2201.11903 [cs]

</span>
</li>
<li id="bib.bib63" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xiao et al<span id="bib.bib63.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Shitao Xiao, Zheng Liu, Peitian Zhang, and Niklas Muennighoff. 2023.

</span>
<span class="ltx_bibblock">C-Pack: Packaged Resources To Advance General Chinese Embedding.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:2309.07597 [cs.CL]

</span>
</li>
<li id="bib.bib64" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xie et al<span id="bib.bib64.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Tianbao Xie, Chen Henry Wu, Peng Shi, Ruiqi Zhong, Torsten Scholak, Michihiro Yasunaga, Chien-Sheng Wu, Ming Zhong, Pengcheng Yin, Sida I. Wang, Victor Zhong, Bailin Wang, Chengzu Li, Connor Boyle, Ansong Ni, Ziyu Yao, Dragomir Radev, Caiming Xiong, Lingpeng Kong, Rui Zhang, Noah A. Smith, Luke Zettlemoyer, and Tao Yu. 2022.

</span>
<span class="ltx_bibblock">UnifiedSKG: Unifying and Multi-Tasking Structured Knowledge Grounding with Text-to-Text Language Models.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.48550/arXiv.2201.05966" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.48550/arXiv.2201.05966</a>
arXiv:2201.05966 [cs]

</span>
</li>
<li id="bib.bib65" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ye et al<span id="bib.bib65.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Yunhu Ye, Binyuan Hui, Min Yang, Binhua Li, Fei Huang, and Yongbin Li. 2023.

</span>
<span class="ltx_bibblock">Large Language Models Are Versatile Decomposers: Decompose Evidence and Questions for Table-based Reasoning.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.48550/arXiv.2301.13808" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.48550/arXiv.2301.13808</a>
arXiv:2301.13808 [cs]

</span>
</li>
<li id="bib.bib66" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yin et al<span id="bib.bib66.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Pengcheng Yin, Graham Neubig, Wen-tau Yih, and Sebastian Riedel. 2020.

</span>
<span class="ltx_bibblock">TaBERT: Pretraining for Joint Understanding of Textual and Tabular Data. In <em id="bib.bib66.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</em>. Association for Computational Linguistics, Online, 8413–8426.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.18653/v1/2020.acl-main.745" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.18653/v1/2020.acl-main.745</a>

</span>
</li>
<li id="bib.bib67" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu et al<span id="bib.bib67.3.3.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Tao Yu, Rui Zhang, Kai Yang, Michihiro Yasunaga, Dongxu Wang, Zifan Li, James Ma, Irene Li, Qingning Yao, Shanelle Roman, et al<span id="bib.bib67.4.1" class="ltx_text">.</span> 2018.

</span>
<span class="ltx_bibblock">Spider: A large-scale human-labeled dataset for complex and cross-domain semantic parsing and text-to-sql task.

</span>
<span class="ltx_bibblock"><em id="bib.bib67.5.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1809.08887</em> (2018).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib68" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zeng et al<span id="bib.bib68.3.3.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Aohan Zeng, Xiao Liu, Zhengxiao Du, Zihan Wang, Hanyu Lai, Ming Ding, Zhuoyi Yang, Yifan Xu, Wendi Zheng, Xiao Xia, et al<span id="bib.bib68.4.1" class="ltx_text">.</span> 2022.

</span>
<span class="ltx_bibblock">GLM-130B: An Open Bilingual Pre-trained Model. In <em id="bib.bib68.5.1" class="ltx_emph ltx_font_italic">The Eleventh International Conference on Learning Representations</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib69" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al<span id="bib.bib69.3.3.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Susan Zhang, Stephen Roller, Naman Goyal, Mikel Artetxe, Moya Chen, Shuohui Chen, Christopher Dewan, Mona Diab, Xian Li, Xi Victoria Lin, et al<span id="bib.bib69.4.1" class="ltx_text">.</span> 2022.

</span>
<span class="ltx_bibblock">Opt: Open pre-trained transformer language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib69.5.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2205.01068</em> (2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib70" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al<span id="bib.bib70.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Tianping Zhang, Yuanqi Li, Yifei Jin, and Jian Li. 2020.

</span>
<span class="ltx_bibblock">AutoAlpha: An Efficient Hierarchical Evolutionary Algorithm for Mining Alpha Factors in Quantitative Investment.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.48550/arXiv.2002.08245" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.48550/arXiv.2002.08245</a>
arXiv:2002.08245 [q-fin]

</span>
</li>
<li id="bib.bib71" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao et al<span id="bib.bib71.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, Yingqian Min, Beichen Zhang, Junjie Zhang, Zican Dong, Yifan Du, Chen Yang, Yushuo Chen, Zhipeng Chen, Jinhao Jiang, Ruiyang Ren, Yifan Li, Xinyu Tang, Zikang Liu, Peiyu Liu, Jian-Yun Nie, and Ji-Rong Wen. 2023.

</span>
<span class="ltx_bibblock">A Survey of Large Language Models.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:2303.18223 [cs.CL]

</span>
</li>
<li id="bib.bib72" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhong et al<span id="bib.bib72.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Victor Zhong, Caiming Xiong, and Richard Socher. 2017.

</span>
<span class="ltx_bibblock">Seq2sql: Generating structured queries from natural language using reinforcement learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib72.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1709.00103</em> (2017).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib73" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou et al<span id="bib.bib73.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Chunting Zhou, Graham Neubig, Jiatao Gu, Mona Diab, Francisco Guzmán, Luke Zettlemoyer, and Marjan Ghazvininejad. 2021.

</span>
<span class="ltx_bibblock">Detecting Hallucinated Content in Conditional Neural Sequence Generation. In <em id="bib.bib73.3.1" class="ltx_emph ltx_font_italic">Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021</em>. Association for Computational Linguistics, Online, 1393–1404.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.18653/v1/2021.findings-acl.120" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.18653/v1/2021.findings-acl.120</a>

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2312.09038" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2312.09039" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2312.09039">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2312.09039" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2312.09040" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Tue Feb 27 14:12:03 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
