<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>MASSW: A New Dataset and Benchmark Tasks for AI-Assisted Scientific Workflows</title>
<!--Generated on Mon Jun 10 15:20:38 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2406.06357v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2406.06357v1#S1" title="In MASSW: A New Dataset and Benchmark Tasks for AI-Assisted Scientific Workflows"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2406.06357v1#S2" title="In MASSW: A New Dataset and Benchmark Tasks for AI-Assisted Scientific Workflows"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Dataset Overview</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2406.06357v1#S2.SS1" title="In 2 Dataset Overview ‣ MASSW: A New Dataset and Benchmark Tasks for AI-Assisted Scientific Workflows"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>Core Aspects of Scientific Workflows</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2406.06357v1#S2.SS1.SSS0.Px1" title="In 2.1 Core Aspects of Scientific Workflows ‣ 2 Dataset Overview ‣ MASSW: A New Dataset and Benchmark Tasks for AI-Assisted Scientific Workflows"><span class="ltx_text ltx_ref_title">Context</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2406.06357v1#S2.SS1.SSS0.Px2" title="In 2.1 Core Aspects of Scientific Workflows ‣ 2 Dataset Overview ‣ MASSW: A New Dataset and Benchmark Tasks for AI-Assisted Scientific Workflows"><span class="ltx_text ltx_ref_title">Key Idea</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2406.06357v1#S2.SS1.SSS0.Px3" title="In 2.1 Core Aspects of Scientific Workflows ‣ 2 Dataset Overview ‣ MASSW: A New Dataset and Benchmark Tasks for AI-Assisted Scientific Workflows"><span class="ltx_text ltx_ref_title">Method</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2406.06357v1#S2.SS1.SSS0.Px4" title="In 2.1 Core Aspects of Scientific Workflows ‣ 2 Dataset Overview ‣ MASSW: A New Dataset and Benchmark Tasks for AI-Assisted Scientific Workflows"><span class="ltx_text ltx_ref_title">Outcome</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2406.06357v1#S2.SS1.SSS0.Px5" title="In 2.1 Core Aspects of Scientific Workflows ‣ 2 Dataset Overview ‣ MASSW: A New Dataset and Benchmark Tasks for AI-Assisted Scientific Workflows"><span class="ltx_text ltx_ref_title">Projected Impact</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2406.06357v1#S2.SS2" title="In 2 Dataset Overview ‣ MASSW: A New Dataset and Benchmark Tasks for AI-Assisted Scientific Workflows"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>Data Curation and Aspect Summarization</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph">
<a class="ltx_ref" href="https://arxiv.org/html/2406.06357v1#S2.SS2.SSS0.Px1" title="In 2.2 Data Curation and Aspect Summarization ‣ 2 Dataset Overview ‣ MASSW: A New Dataset and Benchmark Tasks for AI-Assisted Scientific Workflows"><span class="ltx_text ltx_ref_title">Large-scale scientific publication collection.</span></a>
<ol class="ltx_toclist ltx_toclist_paragraph">
<li class="ltx_tocentry ltx_tocentry_paragraph">
<a class="ltx_ref" href="https://arxiv.org/html/2406.06357v1#S2.SS2.SSS0.Px2" title="In Large-scale scientific publication collection. ‣ 2.2 Data Curation and Aspect Summarization ‣ 2 Dataset Overview ‣ MASSW: A New Dataset and Benchmark Tasks for AI-Assisted Scientific Workflows"><span class="ltx_text ltx_ref_title">Automatic aspect summarization with LLMs.</span></a>
<ol class="ltx_toclist ltx_toclist_paragraph">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2406.06357v1#S2.SS3" title="In Automatic aspect summarization with LLMs. ‣ Large-scale scientific publication collection. ‣ 2.2 Data Curation and Aspect Summarization ‣ 2 Dataset Overview ‣ MASSW: A New Dataset and Benchmark Tasks for AI-Assisted Scientific Workflows"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.3 </span>Dataset Statistics and Visualization</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2406.06357v1#S3" title="In 2.3 Dataset Statistics and Visualization ‣ Automatic aspect summarization with LLMs. ‣ Large-scale scientific publication collection. ‣ 2.2 Data Curation and Aspect Summarization ‣ 2 Dataset Overview ‣ MASSW: A New Dataset and Benchmark Tasks for AI-Assisted Scientific Workflows"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Dataset Validation</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.06357v1#S3.SS1" title="In 3 Dataset Validation ‣ 2.3 Dataset Statistics and Visualization ‣ Automatic aspect summarization with LLMs. ‣ Large-scale scientific publication collection. ‣ 2.2 Data Curation and Aspect Summarization ‣ 2 Dataset Overview ‣ MASSW: A New Dataset and Benchmark Tasks for AI-Assisted Scientific Workflows"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Evaluation Metric</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.06357v1#S3.SS2" title="In 3 Dataset Validation ‣ 2.3 Dataset Statistics and Visualization ‣ Automatic aspect summarization with LLMs. ‣ Large-scale scientific publication collection. ‣ 2.2 Data Curation and Aspect Summarization ‣ 2 Dataset Overview ‣ MASSW: A New Dataset and Benchmark Tasks for AI-Assisted Scientific Workflows"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Human Annotation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.06357v1#A2.SS5" title="In 3 Dataset Validation ‣ 2.3 Dataset Statistics and Visualization ‣ Automatic aspect summarization with LLMs. ‣ Large-scale scientific publication collection. ‣ 2.2 Data Curation and Aspect Summarization ‣ 2 Dataset Overview ‣ MASSW: A New Dataset and Benchmark Tasks for AI-Assisted Scientific Workflows"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B.5 </span>Implementation Details of Semantic-Based Evaluation Metrics</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.06357v1#A2.SS6" title="In 3 Dataset Validation ‣ 2.3 Dataset Statistics and Visualization ‣ Automatic aspect summarization with LLMs. ‣ Large-scale scientific publication collection. ‣ 2.2 Data Curation and Aspect Summarization ‣ 2 Dataset Overview ‣ MASSW: A New Dataset and Benchmark Tasks for AI-Assisted Scientific Workflows"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B.6 </span>Examples of Texts for Different Similarity Levels</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2406.06357v1#A2.SS7" title="In 3 Dataset Validation ‣ 2.3 Dataset Statistics and Visualization ‣ Automatic aspect summarization with LLMs. ‣ Large-scale scientific publication collection. ‣ 2.2 Data Curation and Aspect Summarization ‣ 2 Dataset Overview ‣ MASSW: A New Dataset and Benchmark Tasks for AI-Assisted Scientific Workflows"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B.7 </span>Experiment Details</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2406.06357v1#A2.SS7.SSS0.Px1" title="In B.7 Experiment Details ‣ 3 Dataset Validation ‣ 2.3 Dataset Statistics and Visualization ‣ Automatic aspect summarization with LLMs. ‣ Large-scale scientific publication collection. ‣ 2.2 Data Curation and Aspect Summarization ‣ 2 Dataset Overview ‣ MASSW: A New Dataset and Benchmark Tasks for AI-Assisted Scientific Workflows"><span class="ltx_text ltx_ref_title">Test set sampling.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2406.06357v1#A2.SS7.SSS0.Px2" title="In B.7 Experiment Details ‣ 3 Dataset Validation ‣ 2.3 Dataset Statistics and Visualization ‣ Automatic aspect summarization with LLMs. ‣ Large-scale scientific publication collection. ‣ 2.2 Data Curation and Aspect Summarization ‣ 2 Dataset Overview ‣ MASSW: A New Dataset and Benchmark Tasks for AI-Assisted Scientific Workflows"><span class="ltx_text ltx_ref_title">Prompting templates.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2406.06357v1#A2.SS7.SSS0.Px3" title="In B.7 Experiment Details ‣ 3 Dataset Validation ‣ 2.3 Dataset Statistics and Visualization ‣ Automatic aspect summarization with LLMs. ‣ Large-scale scientific publication collection. ‣ 2.2 Data Curation and Aspect Summarization ‣ 2 Dataset Overview ‣ MASSW: A New Dataset and Benchmark Tasks for AI-Assisted Scientific Workflows"><span class="ltx_text ltx_ref_title">Details about prompting methods.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2406.06357v1#A2.SS7.SSS0.Px4" title="In B.7 Experiment Details ‣ 3 Dataset Validation ‣ 2.3 Dataset Statistics and Visualization ‣ Automatic aspect summarization with LLMs. ‣ Large-scale scientific publication collection. ‣ 2.2 Data Curation and Aspect Summarization ‣ 2 Dataset Overview ‣ MASSW: A New Dataset and Benchmark Tasks for AI-Assisted Scientific Workflows"><span class="ltx_text ltx_ref_title">Details about baseline LLMs.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2406.06357v1#A2.SS7.SSS0.Px5" title="In B.7 Experiment Details ‣ 3 Dataset Validation ‣ 2.3 Dataset Statistics and Visualization ‣ Automatic aspect summarization with LLMs. ‣ Large-scale scientific publication collection. ‣ 2.2 Data Curation and Aspect Summarization ‣ 2 Dataset Overview ‣ MASSW: A New Dataset and Benchmark Tasks for AI-Assisted Scientific Workflows"><span class="ltx_text ltx_ref_title">Example model outputs.</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.06357v1#A2.SS8" title="In 3 Dataset Validation ‣ 2.3 Dataset Statistics and Visualization ‣ Automatic aspect summarization with LLMs. ‣ Large-scale scientific publication collection. ‣ 2.2 Data Curation and Aspect Summarization ‣ 2 Dataset Overview ‣ MASSW: A New Dataset and Benchmark Tasks for AI-Assisted Scientific Workflows"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B.8 </span>Supplementary Tables</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.06357v1#A2.SS9" title="In 3 Dataset Validation ‣ 2.3 Dataset Statistics and Visualization ‣ Automatic aspect summarization with LLMs. ‣ Large-scale scientific publication collection. ‣ 2.2 Data Curation and Aspect Summarization ‣ 2 Dataset Overview ‣ MASSW: A New Dataset and Benchmark Tasks for AI-Assisted Scientific Workflows"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B.9 </span>URL for Dataset</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.06357v1#A2.SS10" title="In 3 Dataset Validation ‣ 2.3 Dataset Statistics and Visualization ‣ Automatic aspect summarization with LLMs. ‣ Large-scale scientific publication collection. ‣ 2.2 Data Curation and Aspect Summarization ‣ 2 Dataset Overview ‣ MASSW: A New Dataset and Benchmark Tasks for AI-Assisted Scientific Workflows"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B.10 </span>Dataset Documentation and Indended Uses</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.06357v1#A2.SS11" title="In 3 Dataset Validation ‣ 2.3 Dataset Statistics and Visualization ‣ Automatic aspect summarization with LLMs. ‣ Large-scale scientific publication collection. ‣ 2.2 Data Curation and Aspect Summarization ‣ 2 Dataset Overview ‣ MASSW: A New Dataset and Benchmark Tasks for AI-Assisted Scientific Workflows"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B.11 </span>Author Statement</span></a></li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">MASSW: A New Dataset and Benchmark Tasks for AI-Assisted Scientific Workflows</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Xingjian Zhang
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Yutong Xie
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Jin Huang
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_font_typewriter" id="id1.1.id1">{jimmyzxj,yutxie,huangjin,ponypony,xziyang,qmei}@umich.edu honglak@eecs.umich.edu</span>
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Jinge Ma
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_font_typewriter" id="id2.1.id1">{ma859, pan433}@purdue.edu</span>
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Zhaoying Pan
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_font_typewriter" id="id3.1.id1">{ma859, pan433}@purdue.edu</span>
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Qijia Liu
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_font_typewriter" id="id4.1.id1">{jimmyzxj,yutxie,huangjin,ponypony,xziyang,qmei}@umich.edu honglak@eecs.umich.edu</span>
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Ziyang Xiong
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_font_typewriter" id="id5.1.id1">{jimmyzxj,yutxie,huangjin,ponypony,xziyang,qmei}@umich.edu honglak@eecs.umich.edu</span>
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Tolga Ergen
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_font_typewriter" id="id6.1.id1">{tergen, dongsub.shim}@lgresearch.ai</span>
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Dongsub Shim
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_font_typewriter" id="id7.1.id1">{tergen, dongsub.shim}@lgresearch.ai</span>
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Honglak Lee
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_font_typewriter" id="id8.1.id1">{jimmyzxj,yutxie,huangjin,ponypony,xziyang,qmei}@umich.edu honglak@eecs.umich.edu</span>
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Qiaozhu Mei
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_font_typewriter" id="id9.1.id1">{jimmyzxj,yutxie,huangjin,ponypony,xziyang,qmei}@umich.edu honglak@eecs.umich.edu</span>
</span></span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id10.id1">Scientific innovation relies on detailed workflows, which include critical steps such as analyzing literature, generating ideas, validating these ideas, interpreting results, and inspiring follow-up research. However, scientific publications that document these workflows are extensive and unstructured. This makes it difficult for both human researchers and AI systems to effectively navigate and explore the space of scientific innovation. To address this issue, we introduce <span class="ltx_text ltx_font_bold" id="id10.id1.1">MASSW</span>, a comprehensive text dataset on <span class="ltx_text ltx_font_bold" id="id10.id1.2">M</span>ulti-<span class="ltx_text ltx_font_bold" id="id10.id1.3">A</span>spect <span class="ltx_text ltx_font_bold" id="id10.id1.4">S</span>ummarization of <span class="ltx_text ltx_font_bold" id="id10.id1.5">S</span>cientific <span class="ltx_text ltx_font_bold" id="id10.id1.6">W</span>orkflows. MASSW includes more than 152,000 peer-reviewed publications from 17 leading computer science conferences spanning the past 50 years. Using Large Language Models (LLMs), we automatically extract five core aspects from these publications – <em class="ltx_emph ltx_font_italic" id="id10.id1.7">context</em>, <em class="ltx_emph ltx_font_italic" id="id10.id1.8">key idea</em>, <em class="ltx_emph ltx_font_italic" id="id10.id1.9">method</em>, <em class="ltx_emph ltx_font_italic" id="id10.id1.10">outcome</em>, and <em class="ltx_emph ltx_font_italic" id="id10.id1.11">projected impact</em> – which correspond to five key steps in the research workflow. These structured summaries facilitate a variety of downstream tasks and analyses. The quality of the LLM-extracted summaries is validated by comparing them with human annotations. We demonstrate the utility of MASSW through
multiple novel machine-learning tasks that can be benchmarked using this new dataset, which make various types of predictions and recommendations along the scientific workflow. MASSW holds significant potential for researchers to create and benchmark new AI methods for optimizing scientific workflows and fostering scientific innovation in the field. Our dataset is openly available at <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/xingjian-zhang/massw" title="">https://github.com/xingjian-zhang/massw</a>.</p>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para ltx_noindent" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Can AI be a capable copilot for scientific research? Scientific innovation is driven by complex and detailed workflows, also referred to as scientific methods at a coarse level <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">ayala2009darwin</span>; <span class="ltx_ref ltx_missing_citation ltx_ref_self">voit2019perspective</span>)</cite>. These workflows typically involve critical steps such as analyzing existing literature, generating novel ideas, validating these ideas through analyses and experiments, interpreting experimental results, and ultimately inspiring future research inquiries. To navigate and explore the space of innovations, both the pilot and the copilot have to understand, plan, and optimize the scientific workflows <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">wang2023scientific</span>)</cite>. These workflows are often documented in scientific publications, which are crucial for scientists to understand and reproduce existing research, as well as plan and accelerate new research. However, the traditional format of these publications is unstructured and complex, which does not readily facilitate efficiently tracing scientific workflows and extending them towards new scientific research. To assist researchers in better navigating and exploring the scientific innovation space, it is essential to develop new datasets that document scientific workflows in a more structured way, along with new tools to reason through and evolve these workflows.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">Developing scientific workflow datasets is challenging. While human experts are skilled at deciphering complex scientific publications, their highly personalized interpretations, if not sufficiently aligned, often lead to inconsistent and heterogeneous annotations and predictions <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">Beck2020-dh</span>)</cite>.
Furthermore, annotations by highly specialized researchers are inherently expensive, limiting their applicability in building large datasets at the scale and scope of a scientific field <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">Takeshita2024-sv</span>; <span class="ltx_ref ltx_missing_citation ltx_ref_self">Fisas2015-ai</span>; <span class="ltx_ref ltx_missing_citation ltx_ref_self">Cachola2020-dg</span>; <span class="ltx_ref ltx_missing_citation ltx_ref_self">mei2008generating</span>)</cite>.
These challenges highlight the need for an automated, scalable, and consistent solution to annotate structured scientific workflows, a task well-suited for an AI. Indeed, the advent of large language models (LLMs) has demonstrated promising performance in reasoning through natural language <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">10.5555/3600270.3602070</span>)</cite>, positioning them as a viable candidate for automating the annotation of scientific workflows, even though it remains to be seen whether they can match the accuracy of human experts.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">Addressing these challenges, we present <span class="ltx_text ltx_font_bold" id="S1.p3.1.1">MASSW</span>, a novel and large-scale dataset that provides a comprehensive and structured <span class="ltx_text ltx_font_bold" id="S1.p3.1.2">M</span>ulti-<span class="ltx_text ltx_font_bold" id="S1.p3.1.3">A</span>spect <span class="ltx_text ltx_font_bold" id="S1.p3.1.4">S</span>ummarization of <span class="ltx_text ltx_font_bold" id="S1.p3.1.5">S</span>cientific <span class="ltx_text ltx_font_bold" id="S1.p3.1.6">W</span>orkflows. The key features of MASSW include</p>
<ul class="ltx_itemize" id="S1.I1">
<li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i1.p1">
<p class="ltx_p" id="S1.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S1.I1.i1.p1.1.1">Structured scientific workflows</span>. MASSW defines five core aspects of a scientific workflow – <em class="ltx_emph ltx_font_italic" id="S1.I1.i1.p1.1.2">context</em>, <em class="ltx_emph ltx_font_italic" id="S1.I1.i1.p1.1.3">key idea</em>, <em class="ltx_emph ltx_font_italic" id="S1.I1.i1.p1.1.4">method</em>, <em class="ltx_emph ltx_font_italic" id="S1.I1.i1.p1.1.5">outcome</em>, and <em class="ltx_emph ltx_font_italic" id="S1.I1.i1.p1.1.6">projected impact</em>. These aspects align with the typical stages in general scientific workflows that can be identified in the literature. Utilizing LLMs, we are able to extract and structure these five aspects from each publication with consistency.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i2.p1">
<p class="ltx_p" id="S1.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S1.I1.i2.p1.1.1">Large scale</span>. MASSW contains the structured scientific workflows and meta-information from over 152,000 peer-reviewed publications, across 17 leading computer science conferences, and spanning the past 50 years.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i3.p1">
<p class="ltx_p" id="S1.I1.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S1.I1.i3.p1.1.1">Accuracy</span>. The coverage and accuracy of MASSW have been validated through comprehensive inspections and comparisons with human annotations and alternative methods.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para ltx_noindent" id="S1.I1.i4.p1">
<p class="ltx_p" id="S1.I1.i4.p1.1"><span class="ltx_text ltx_font_bold" id="S1.I1.i4.p1.1.1">Rich benchmark tasks</span>. MASSW facilitates multiple novel and benchmarkable machine-learning tasks, such as idea generation and outcome prediction. It supports diverse tasks centered on predicting, recommending, and expanding key elements of a scientific workflow, serving as a benchmark for evaluating LLM agents’ ability to navigate scientific research.</p>
</div>
</li>
</ul>
<p class="ltx_p" id="S1.p3.2">By providing a large-scale, structured, and accurate resource, MASSW opens new avenues for researchers to develop and evaluate innovative AI methods that facilitate more effective scientific workflows, fostering greater and faster innovations within the field.</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Dataset Overview</h2>
<div class="ltx_para ltx_noindent" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">MASSW is a <span class="ltx_text ltx_font_italic" id="S2.p1.1.1">structured</span> and <span class="ltx_text ltx_font_italic" id="S2.p1.1.2">large-scale</span> dataset designed to enhance the exploration and analysis of scientific workflows.
In Section <a class="ltx_ref" href="https://arxiv.org/html/2406.06357v1#S2.SS1" title="2.1 Core Aspects of Scientific Workflows ‣ 2 Dataset Overview ‣ MASSW: A New Dataset and Benchmark Tasks for AI-Assisted Scientific Workflows"><span class="ltx_text ltx_ref_tag">2.1</span></a>, we first discuss how to structure a scientific publication into five core aspects, corresponding to five key steps in a general scientific research workflow.
In Section <a class="ltx_ref" href="https://arxiv.org/html/2406.06357v1#S2.SS2" title="2.2 Data Curation and Aspect Summarization ‣ 2 Dataset Overview ‣ MASSW: A New Dataset and Benchmark Tasks for AI-Assisted Scientific Workflows"><span class="ltx_text ltx_ref_tag">2.2</span></a>, we describe the curation of scientific publication data and an automated procedure that summarizes these core aspects with LLMs.
Lastly, we present basic statistics about the constructed MASSW dataset and a multi-view visualization of these aspects in Section <a class="ltx_ref" href="https://arxiv.org/html/2406.06357v1#S2.SS3" title="2.3 Dataset Statistics and Visualization ‣ Automatic aspect summarization with LLMs. ‣ Large-scale scientific publication collection. ‣ 2.2 Data Curation and Aspect Summarization ‣ 2 Dataset Overview ‣ MASSW: A New Dataset and Benchmark Tasks for AI-Assisted Scientific Workflows"><span class="ltx_text ltx_ref_tag">2.3</span></a>.</p>
</div>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Core Aspects of Scientific Workflows</h3>
<figure class="ltx_table" id="S2.T1">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S2.T1.1">
<tr class="ltx_tr" id="S2.T1.1.1">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" id="S2.T1.1.1.1" style="padding-top:5pt;padding-bottom:5pt;">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.1.1.1">
<span class="ltx_p" id="S2.T1.1.1.1.1.1" style="width:59.8pt;"><span class="ltx_text ltx_font_bold" id="S2.T1.1.1.1.1.1.1">Aspect</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" id="S2.T1.1.1.2" style="padding-top:5pt;padding-bottom:5pt;">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.1.2.1">
<span class="ltx_p" id="S2.T1.1.1.2.1.1" style="width:156.5pt;"><span class="ltx_text ltx_font_bold" id="S2.T1.1.1.2.1.1.1">Definition</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" id="S2.T1.1.1.3" style="padding-top:5pt;padding-bottom:5pt;">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.1.3.1">
<span class="ltx_p" id="S2.T1.1.1.3.1.1" style="width:142.3pt;"><span class="ltx_text ltx_font_bold" id="S2.T1.1.1.3.1.1.1">Example</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S2.T1.1.2">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S2.T1.1.2.1" style="padding-top:5pt;padding-bottom:5pt;">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.2.1.1">
<span class="ltx_p" id="S2.T1.1.2.1.1.1" style="width:59.8pt;"><span class="ltx_text ltx_font_bold" id="S2.T1.1.2.1.1.1.1">Context</span>
<br class="ltx_break"/><span class="ltx_text ltx_font_italic" id="S2.T1.1.2.1.1.1.2">Ask questions, review literature 
<br class="ltx_break"/>(prior to study)</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S2.T1.1.2.2" style="padding-top:5pt;padding-bottom:5pt;">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.2.2.1">
<span class="ltx_p" id="S2.T1.1.2.2.1.1" style="width:156.5pt;">The status quo of related literature or reality which motivated this study. This could normally be a problem, a research question, or a research gap that has not been successfully addressed by previous work.</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S2.T1.1.2.3" style="padding-top:5pt;padding-bottom:5pt;">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.2.3.1">
<span class="ltx_p" id="S2.T1.1.2.3.1.1" style="width:142.3pt;"><span class="ltx_text ltx_font_italic" id="S2.T1.1.2.3.1.1.1">Making language models bigger does not inherently make them better at following a user’s intent, as large models can generate outputs that are untruthful, toxic, or not helpful.</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S2.T1.1.3">
<td class="ltx_td ltx_align_justify ltx_align_top" id="S2.T1.1.3.1" style="padding-top:5pt;padding-bottom:5pt;">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.3.1.1">
<span class="ltx_p" id="S2.T1.1.3.1.1.1" style="width:59.8pt;"><span class="ltx_text ltx_font_bold" id="S2.T1.1.3.1.1.1.1">Key Idea</span>
<br class="ltx_break"/><span class="ltx_text ltx_font_italic" id="S2.T1.1.3.1.1.1.2"> Construct hypothesis (proposed in this study)</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S2.T1.1.3.2" style="padding-top:5pt;padding-bottom:5pt;">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.3.2.1">
<span class="ltx_p" id="S2.T1.1.3.2.1.1" style="width:156.5pt;">The main intellectual merit of this paper, often in comparison to the context. This could normally be a novel idea or solution proposed in this paper that distincts it from what’s already done in literature.</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S2.T1.1.3.3" style="padding-top:5pt;padding-bottom:5pt;">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.3.3.1">
<span class="ltx_p" id="S2.T1.1.3.3.1.1" style="width:142.3pt;"><span class="ltx_text ltx_font_italic" id="S2.T1.1.3.3.1.1.1">The authors propose InstructGPT, a method to align language models with user intent by fine-tuning GPT-3 using a combination of supervised learning with labeler demonstrations and reinforcement learning from human feedback.</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S2.T1.1.4">
<td class="ltx_td ltx_align_justify ltx_align_top" id="S2.T1.1.4.1" style="padding-top:5pt;padding-bottom:5pt;">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.4.1.1">
<span class="ltx_p" id="S2.T1.1.4.1.1.1" style="width:59.8pt;"><span class="ltx_text ltx_font_bold" id="S2.T1.1.4.1.1.1.1">Method</span>
<br class="ltx_break"/><span class="ltx_text ltx_font_italic" id="S2.T1.1.4.1.1.1.2">Test hypothesis 
<br class="ltx_break"/>(after hypothesis construction)</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S2.T1.1.4.2" style="padding-top:5pt;padding-bottom:5pt;">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.4.2.1">
<span class="ltx_p" id="S2.T1.1.4.2.1.1" style="width:156.5pt;">The specific research method that investigates and validates the key idea. This could be an experimental setup, a theoretical framework, or other necessary validation methodology to implement and/or evaluate the key idea.</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S2.T1.1.4.3" style="padding-top:5pt;padding-bottom:5pt;">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.4.3.1">
<span class="ltx_p" id="S2.T1.1.4.3.1.1" style="width:142.3pt;"><span class="ltx_text ltx_font_italic" id="S2.T1.1.4.3.1.1.1">The authors evaluate the performance of InstructGPT by humans on a given prompt distribution and compare it with a much larger model GPT-3.</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S2.T1.1.5">
<td class="ltx_td ltx_align_justify ltx_align_top" id="S2.T1.1.5.1" style="padding-top:5pt;padding-bottom:5pt;">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.5.1.1">
<span class="ltx_p" id="S2.T1.1.5.1.1.1" style="width:59.8pt;"><span class="ltx_text ltx_font_bold" id="S2.T1.1.5.1.1.1.1">Outcome</span>
<br class="ltx_break"/><span class="ltx_text ltx_font_italic" id="S2.T1.1.5.1.1.1.2">Interpret results, draw conclusion 
<br class="ltx_break"/>(after testing hypothesis)</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S2.T1.1.5.2" style="padding-top:5pt;padding-bottom:5pt;">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.5.2.1">
<span class="ltx_p" id="S2.T1.1.5.2.1.1" style="width:156.5pt;">The factual statement about the study output. This could be the experiment results and any other measurable outcome that has occurred. It marks whether the key hypothesis is testified or not.</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S2.T1.1.5.3" style="padding-top:5pt;padding-bottom:5pt;">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.5.3.1">
<span class="ltx_p" id="S2.T1.1.5.3.1.1" style="width:142.3pt;"><span class="ltx_text ltx_font_italic" id="S2.T1.1.5.3.1.1.1">InstructGPT, even with 100x fewer parameters, is preferred over GPT-3 in human evaluations. It shows improvements in truthfulness and reductions in toxic outputs with minimal performance regressions on public NLP datasets.</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S2.T1.1.6">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" id="S2.T1.1.6.1" style="padding-top:5pt;padding-bottom:5pt;">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.6.1.1">
<span class="ltx_p" id="S2.T1.1.6.1.1.1" style="width:59.8pt;"><span class="ltx_text ltx_font_bold" id="S2.T1.1.6.1.1.1.1">Projected 
<br class="ltx_break"/>Impact</span>
<br class="ltx_break"/><span class="ltx_text ltx_font_italic" id="S2.T1.1.6.1.1.1.2">Future work 
<br class="ltx_break"/>(anticipated but not yet done)</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" id="S2.T1.1.6.2" style="padding-top:5pt;padding-bottom:5pt;">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.6.2.1">
<span class="ltx_p" id="S2.T1.1.6.2.1.1" style="width:156.5pt;">The author-anticipated impact of the work on the field, and potential further research identified by the author that may improve or extend this study.</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" id="S2.T1.1.6.3" style="padding-top:5pt;padding-bottom:5pt;">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.6.3.1">
<span class="ltx_p" id="S2.T1.1.6.3.1.1" style="width:142.3pt;"><span class="ltx_text ltx_font_italic" id="S2.T1.1.6.3.1.1.1">Fine-tuning with human feedback is a promising direction for aligning language models with human intent.</span></span>
</span>
</td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Core aspects in the MASSW dataset that correspond to key steps (<span class="ltx_text ltx_font_italic" id="S2.T1.3.1">in italic</span>) in a general scientific workflow. The example is based on the paper “Training Language Models to Follow Instructions with Human Feedback.” <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">Ouyang2022-hl</span>)</cite> More examples of MASSW are provided in Appendix <span class="ltx_ref ltx_missing_label ltx_ref_self">LABEL:sec:example-aspects</span>.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.1">A typical workflow of scientific research often involves common steps: asking a general research question and reviewing existing literature, formulating a hypothesis or research idea, validating the hypothesis, interpreting the results and drawing conclusions, reporting the findings, and planning follow-up research <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">ayala2009darwin</span>; <span class="ltx_ref ltx_missing_citation ltx_ref_self">voit2019perspective</span>)</cite>. A scientific publication often describes some or all of these steps with corresponding narrative aspects. For example, the authors often motivate their study within the <em class="ltx_emph ltx_font_italic" id="S2.SS1.p1.1.1">context</em> of existing research, highlight the <em class="ltx_emph ltx_font_italic" id="S2.SS1.p1.1.2">key idea</em> of the study, describe the <em class="ltx_emph ltx_font_italic" id="S2.SS1.p1.1.3">method</em> used to validate their idea, discuss the <em class="ltx_emph ltx_font_italic" id="S2.SS1.p1.1.4">outcome</em> of the validation, and articulate the <em class="ltx_emph ltx_font_italic" id="S2.SS1.p1.1.5">potential impact</em> of the study from the author’s perspective.
In Table <a class="ltx_ref" href="https://arxiv.org/html/2406.06357v1#S2.T1" title="Table 1 ‣ 2.1 Core Aspects of Scientific Workflows ‣ 2 Dataset Overview ‣ MASSW: A New Dataset and Benchmark Tasks for AI-Assisted Scientific Workflows"><span class="ltx_text ltx_ref_tag">1</span></a>, we define these core aspects more formally.</p>
</div>
<section class="ltx_paragraph" id="S2.SS1.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Context</h4>
<div class="ltx_para ltx_noindent" id="S2.SS1.SSS0.Px1.p1">
<p class="ltx_p" id="S2.SS1.SSS0.Px1.p1.1">The context of a study summarizes the status quo of the research field or the broader reality before the study is presented.
This aspect is often related to analyzing relevant literature, identifying the gap and unresolved challenges, and motivating new research ideas to fill the gap.
In a scientific publication, this key aspect is often described as <em class="ltx_emph ltx_font_italic" id="S2.SS1.SSS0.Px1.p1.1.1">background</em>, <em class="ltx_emph ltx_font_italic" id="S2.SS1.SSS0.Px1.p1.1.2">challenges</em>, or <em class="ltx_emph ltx_font_italic" id="S2.SS1.SSS0.Px1.p1.1.3">literature review</em>, as approached by previous work of publication summarization <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">Fisas2015-ai</span>; <span class="ltx_ref ltx_missing_citation ltx_ref_self">Takeshita2024-sv</span>)</cite>.</p>
</div>
</section>
<section class="ltx_paragraph" id="S2.SS1.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Key Idea</h4>
<div class="ltx_para ltx_noindent" id="S2.SS1.SSS0.Px2.p1">
<p class="ltx_p" id="S2.SS1.SSS0.Px2.p1.1">The key idea represents the central hypothesis or novel contribution proposed in the study. This is the key aspect that distinguishes the current work from the context of existing work. It is a product of idea generation, a critical step in the scientific workflow where new concepts are formed, new connections are made, and new solutions are proposed to address particular challenges in research. In previous work of text summarization, it is sometimes related to the <em class="ltx_emph ltx_font_italic" id="S2.SS1.SSS0.Px2.p1.1.1">approach</em> described in a paper, which only partially reflects its key ideas <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">Fisas2015-ai</span>; <span class="ltx_ref ltx_missing_citation ltx_ref_self">Takeshita2024-sv</span>)</cite>.</p>
</div>
</section>
<section class="ltx_paragraph" id="S2.SS1.SSS0.Px3">
<h4 class="ltx_title ltx_title_paragraph">Method</h4>
<div class="ltx_para ltx_noindent" id="S2.SS1.SSS0.Px3.p1">
<p class="ltx_p" id="S2.SS1.SSS0.Px3.p1.1">The method of a study details the procedures and techniques used to validate the key idea or hypothesis. In other words, the method is not a part of the hypothesis itself, but rather the procedure used to prove or reject the hypothesis. In previous work of text summarization, <span class="ltx_text ltx_font_italic" id="S2.SS1.SSS0.Px3.p1.1.1">method</span> is sometimes confused with the <span class="ltx_text ltx_font_italic" id="S2.SS1.SSS0.Px3.p1.1.2">key idea</span> (both referred to as part of the <em class="ltx_emph ltx_font_italic" id="S2.SS1.SSS0.Px3.p1.1.3">approach</em> <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">Fisas2015-ai</span>; <span class="ltx_ref ltx_missing_citation ltx_ref_self">Takeshita2024-sv</span>)</cite>), especially when the main subject of the research is a “method.” We explicitly distinguish <span class="ltx_text ltx_font_italic" id="S2.SS1.SSS0.Px3.p1.1.4">method</span> from the <span class="ltx_text ltx_font_italic" id="S2.SS1.SSS0.Px3.p1.1.5">key idea</span> as they refer to different steps in the scientific workflow (generating ideas v.s. validating ideas).</p>
</div>
</section>
<section class="ltx_paragraph" id="S2.SS1.SSS0.Px4">
<h4 class="ltx_title ltx_title_paragraph">Outcome</h4>
<div class="ltx_para ltx_noindent" id="S2.SS1.SSS0.Px4.p1">
<p class="ltx_p" id="S2.SS1.SSS0.Px4.p1.1">The outcome includes the results and findings as a product of the <span class="ltx_text ltx_font_italic" id="S2.SS1.SSS0.Px4.p1.1.1">method</span> in the study.
This aspect corresponds to the measurable results, the interpretation of these results, and other type of impact of the work that has already happened by the time of publication. This concept is also mentioned in previous work of text summarization, as “outcome” or “result” <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">Fisas2015-ai</span>; <span class="ltx_ref ltx_missing_citation ltx_ref_self">Takeshita2024-sv</span>)</cite>.</p>
</div>
</section>
<section class="ltx_paragraph" id="S2.SS1.SSS0.Px5">
<h4 class="ltx_title ltx_title_paragraph">Projected Impact</h4>
<div class="ltx_para ltx_noindent" id="S2.SS1.SSS0.Px5.p1">
<p class="ltx_p" id="S2.SS1.SSS0.Px5.p1.1">The projected impact outlines the potential future implications of the research that has not happened at the time of publication. This aspect is often an ex-ante prediction of how the results of the work would inspire follow-up research or deployment, from the author’s point of view. It discusses how the findings can contribute to the field, suggest new research directions, and potentially lead to societal or technological advancements. Previous work often simply uses the concept of <em class="ltx_emph ltx_font_italic" id="S2.SS1.SSS0.Px5.p1.1.1">future work</em>, while ignoring the broader impact of the study <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">Fisas2015-ai</span>; <span class="ltx_ref ltx_missing_citation ltx_ref_self">Takeshita2024-sv</span>)</cite>.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Data Curation and Aspect Summarization</h3>
<div class="ltx_para ltx_noindent" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.1">Advancing AI’s understanding and ability to improve scientific workflows requires large-scale and high-quality data. To address this challenge, we curate a collection of scientific publications and structure it into the above-defined core aspects at scale.</p>
</div>
<section class="ltx_paragraph" id="S2.SS2.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Large-scale scientific publication collection. </h4>
<div class="ltx_para ltx_noindent" id="S2.SS2.SSS0.Px1.p1">
<p class="ltx_p" id="S2.SS2.SSS0.Px1.p1.1">To build this initial version of the MASSW dataset, we focus on Computer Science publications from 17 top-tier conferences listed in <a class="ltx_ref ltx_href" href="CSRankings.org" title="">CSRankings.org</a>, which we identify as relevant to the broader field of AI.
We access the publications through Open Academic Graph (OAG)<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>The OAG dataset is publicly released under the ODC-BY license.</span></span></span>, a linked graph database for academic entities including publications, venues, affiliations, and authors
<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">zhang2022oag</span>; <span class="ltx_ref ltx_missing_citation ltx_ref_self">zhang2019oag</span>)</cite>.
In total, 191,055 papers are collected that span from 1969 to 2024, among which, 152,027 contain both a title and an abstract.
More details about data curation can be found in Appendix <span class="ltx_ref ltx_missing_label ltx_ref_self">LABEL:app:data-curation</span>.</p>
</div>
<figure class="ltx_table ltx_align_floatright" id="S2.SS2.SSS0.Px1.tab1">
<div class="ltx_flex_figure ltx_flex_table">
<div class="ltx_flex_cell ltx_flex_size_1">
<table class="ltx_tabular ltx_figure_panel ltx_align_middle" id="S2.SS2.SSS0.Px1.tab1.1">
<tr class="ltx_tr" id="S2.SS2.SSS0.Px1.tab1.1.1">
<td class="ltx_td ltx_border_tt" id="S2.SS2.SSS0.Px1.tab1.1.1.1"></td>
<td class="ltx_td ltx_align_right ltx_border_tt" id="S2.SS2.SSS0.Px1.tab1.1.1.2">#Papers with</td>
<td class="ltx_td ltx_align_right ltx_border_tt" id="S2.SS2.SSS0.Px1.tab1.1.1.3">Avg. #Tokens</td>
</tr>
<tr class="ltx_tr" id="S2.SS2.SSS0.Px1.tab1.1.2">
<td class="ltx_td ltx_align_right ltx_border_t" id="S2.SS2.SSS0.Px1.tab1.1.2.1">Abstract</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S2.SS2.SSS0.Px1.tab1.1.2.2">152,027</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S2.SS2.SSS0.Px1.tab1.1.2.3">145.3</td>
</tr>
<tr class="ltx_tr" id="S2.SS2.SSS0.Px1.tab1.1.3">
<td class="ltx_td ltx_align_right" id="S2.SS2.SSS0.Px1.tab1.1.3.1">
<span class="ltx_ERROR undefined" id="S2.SS2.SSS0.Px1.tab1.1.3.1.1">\hdashline</span>
Context</td>
<td class="ltx_td ltx_align_right" id="S2.SS2.SSS0.Px1.tab1.1.3.2">149,849</td>
<td class="ltx_td ltx_align_right" id="S2.SS2.SSS0.Px1.tab1.1.3.3">34.8</td>
</tr>
<tr class="ltx_tr" id="S2.SS2.SSS0.Px1.tab1.1.4">
<td class="ltx_td ltx_align_right" id="S2.SS2.SSS0.Px1.tab1.1.4.1">Key Idea</td>
<td class="ltx_td ltx_align_right" id="S2.SS2.SSS0.Px1.tab1.1.4.2">149,411</td>
<td class="ltx_td ltx_align_right" id="S2.SS2.SSS0.Px1.tab1.1.4.3">35.1</td>
</tr>
<tr class="ltx_tr" id="S2.SS2.SSS0.Px1.tab1.1.5">
<td class="ltx_td ltx_align_right" id="S2.SS2.SSS0.Px1.tab1.1.5.1">Method</td>
<td class="ltx_td ltx_align_right" id="S2.SS2.SSS0.Px1.tab1.1.5.2">142,241</td>
<td class="ltx_td ltx_align_right" id="S2.SS2.SSS0.Px1.tab1.1.5.3">30.7</td>
</tr>
<tr class="ltx_tr" id="S2.SS2.SSS0.Px1.tab1.1.6">
<td class="ltx_td ltx_align_right" id="S2.SS2.SSS0.Px1.tab1.1.6.1">Outcome</td>
<td class="ltx_td ltx_align_right" id="S2.SS2.SSS0.Px1.tab1.1.6.2">132,614</td>
<td class="ltx_td ltx_align_right" id="S2.SS2.SSS0.Px1.tab1.1.6.3">27.6</td>
</tr>
<tr class="ltx_tr" id="S2.SS2.SSS0.Px1.tab1.1.7">
<td class="ltx_td ltx_align_right" id="S2.SS2.SSS0.Px1.tab1.1.7.1">Projected Impact</td>
<td class="ltx_td ltx_align_right" id="S2.SS2.SSS0.Px1.tab1.1.7.2">72,983</td>
<td class="ltx_td ltx_align_right" id="S2.SS2.SSS0.Px1.tab1.1.7.3">27.2</td>
</tr>
<tr class="ltx_tr" id="S2.SS2.SSS0.Px1.tab1.1.8">
<td class="ltx_td ltx_align_right ltx_border_bb" id="S2.SS2.SSS0.Px1.tab1.1.8.1">
<span class="ltx_ERROR undefined" id="S2.SS2.SSS0.Px1.tab1.1.8.1.1">\hdashline</span>
All Aspects</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S2.SS2.SSS0.Px1.tab1.1.8.2">62,506</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S2.SS2.SSS0.Px1.tab1.1.8.3">N/A</td>
</tr>
</table>
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 2: </span>Basic statistics of MASSW. </figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<section class="ltx_paragraph ltx_figure_panel" id="S2.SS2.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Automatic aspect summarization with LLMs. </h4>
<div class="ltx_para ltx_noindent" id="S2.SS2.SSS0.Px2.p1">
<p class="ltx_p" id="S2.SS2.SSS0.Px2.p1.1">Most relevant datasets on structured summary of publications were created using human annotations, which only cover tens to thousands of papers <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">mei2008generating</span>; <span class="ltx_ref ltx_missing_citation ltx_ref_self">Fisas2015-ai</span>; <span class="ltx_ref ltx_missing_citation ltx_ref_self">cachola-etal-2020-tldr</span>; <span class="ltx_ref ltx_missing_citation ltx_ref_self">wang-etal-2022-squality</span>; <span class="ltx_ref ltx_missing_citation ltx_ref_self">Takeshita2024-sv</span>)</cite>. For MASSW, we leverage the power of LLMs (e.g., GPT-4) to automatically summarize the five core aspects of the entire set of collected papers that have a title and an abstract.
More details of LLM-based summarization, including the prompts used, are described in Appendix <span class="ltx_ref ltx_missing_label ltx_ref_self">LABEL:app:aspect-summ</span>.</p>
</div>
<section class="ltx_subsection" id="S2.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Dataset Statistics and Visualization</h3>
<div class="ltx_para ltx_noindent" id="S2.SS3.p1">
<p class="ltx_p" id="S2.SS3.p1.1">Table <a class="ltx_ref" href="https://arxiv.org/html/2406.06357v1#S2.SS2.SSS0.Px1" title="Large-scale scientific publication collection. ‣ 2.2 Data Curation and Aspect Summarization ‣ 2 Dataset Overview ‣ MASSW: A New Dataset and Benchmark Tasks for AI-Assisted Scientific Workflows"><span class="ltx_text ltx_ref_tag">2.2</span></a> reports basic statistics of the MASSW dataset and per-aspect summaries. We also include a multiview visualization in Figure <span class="ltx_ref ltx_missing_label ltx_ref_self">LABEL:fig:largevis-aspects</span> in Appendix <span class="ltx_ref ltx_missing_label ltx_ref_self">LABEL:app:data-vis</span> to give an overview of the core aspects.</p>
</div>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Dataset Validation</h2>
<div class="ltx_para ltx_noindent" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">Are LLM-generated summaries trustfully describing the core aspects of the scientific workflow? We validate the structured summaries in the MASSW dataset by comparing them with human-generated summaries. We have curated a small-scale subset of publications and solicited the summaries of the same five aspects from human annotators. This subset demonstrates the alignment between the LLMs and human experts in generating the multi-aspect summary of scientific workflows.</p>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Evaluation Metric</h3>
<div class="ltx_para ltx_noindent" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">We employ two categories of similarity evaluation metrics: lexical-level and semantic-based. Lexical-level metrics, such as <span class="ltx_text ltx_font_italic" id="S3.SS1.p1.1.1">BLEU</span> <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">Papineni2002-ab</span>)</cite> and <span class="ltx_text ltx_font_italic" id="S3.SS1.p1.1.2">ROUGE<span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note"><span class="ltx_text ltx_font_upright" id="footnote2.1.1.1">2</span></span><span class="ltx_text ltx_font_upright" id="footnote2.5">We report ROUGE-1 that evaluates on unigram.</span></span></span></span></span> <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">Lin2004-yl</span>)</cite>, are prevalent across various natural language generation tasks. However, numerous studies <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">Sellam2020-en</span>; <span class="ltx_ref ltx_missing_citation ltx_ref_self">Callison-Burch2006-xd</span>; <span class="ltx_ref ltx_missing_citation ltx_ref_self">Ananthakrishnan2006-sd</span>; <span class="ltx_ref ltx_missing_citation ltx_ref_self">Sai2022-hy</span>)</cite> indicate their limited alignment with human judgments, primarily due to their reliance on exact word matches. Conversely, semantic-based metrics represent a more advanced approach, assessing the similarity in meaning or content through the use of pre-trained language models. For semantic evaluation, we utilize three metrics: <span class="ltx_text ltx_font_italic" id="S3.SS1.p1.1.3">BERTScore (BS)</span> <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">Zhang2019-ir</span>)</cite>, which compares token-wise contextual embeddings, <span class="ltx_text ltx_font_italic" id="S3.SS1.p1.1.4">cosine similarity (CS)</span>, derived from embeddings generated by <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">Wang2024-nf</span>)</cite>, and <span class="ltx_text ltx_font_italic" id="S3.SS1.p1.1.5">BLEURT</span> <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">Sellam2020-en</span>)</cite>, which is fine-tuned to reflect human judgment. Their implementation details can be found in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2406.06357v1#A2.SS5" title="B.5 Implementation Details of Semantic-Based Evaluation Metrics ‣ 3 Dataset Validation ‣ 2.3 Dataset Statistics and Visualization ‣ Automatic aspect summarization with LLMs. ‣ Large-scale scientific publication collection. ‣ 2.2 Data Curation and Aspect Summarization ‣ 2 Dataset Overview ‣ MASSW: A New Dataset and Benchmark Tasks for AI-Assisted Scientific Workflows"><span class="ltx_text ltx_ref_tag">B.5</span></a>.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Human Annotation</h3>
<div class="ltx_para ltx_noindent" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">We use a proportionate stratified sampling method on different venues and publication times to select the annotation subset. Specifically, we sample 7 papers from each of the venues in different times, resulting in a total of 126 papers for annotation. This strategy ensures a representative sample across the broad spectrum of AI research. The complete annotation process is detailed in Appendix <span class="ltx_ref ltx_missing_label ltx_ref_self">LABEL:sec:annotation</span>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.p2">
<p class="ltx_p" id="S3.SS2.p2.1">Two trained human experts who are familiar with reading scientific literature are assigned to annotate the aspects of each paper, based on the title and abstract, following a carefully designed codebook. Table <span class="ltx_ref ltx_missing_label ltx_ref_self">LABEL:table:eval</span> (top) illustrates the agreement between human experts by treating one annotation as the reference and the other as the prediction for each paper. <span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>To help understand the scale of these metrics, we include a range of examples with varying levels of similarity in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2406.06357v1#A2.SS6" title="B.6 Examples of Texts for Different Similarity Levels ‣ 3 Dataset Validation ‣ 2.3 Dataset Statistics and Visualization ‣ Automatic aspect summarization with LLMs. ‣ Large-scale scientific publication collection. ‣ 2.2 Data Curation and Aspect Summarization ‣ 2 Dataset Overview ‣ MASSW: A New Dataset and Benchmark Tasks for AI-Assisted Scientific Workflows"><span class="ltx_text ltx_ref_tag">B.6</span></a></span></span></span> In general, there is a high level of agreement across all aspects of scientific workflow, suggesting that the proposed five aspects are well-defined and the annotations do not have obvious individual bias.</p>
</div>
<figure class="ltx_table" id="S3.SS2.tab1">
</figure>
<div class="ltx_para ltx_noindent" id="S3.SS2.p3">
<p class="ltx_p" id="S3.SS2.p3.1"><span class="ltx_text ltx_font_bold" id="S3.SS2.p3.1.1">A:</span> Yes, it is fine to include them.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.p4">
<p class="ltx_p" id="S3.SS2.p4.1"><span class="ltx_text ltx_font_bold" id="S3.SS2.p4.1.1">Q:</span> If the problem definition is novel (i.e. proposing a new task), should it be a key idea or context? 
<span class="ltx_text ltx_font_bold" id="S3.SS2.p4.1.2">A:</span> Key idea.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.p5">
<p class="ltx_p" id="S3.SS2.p5.1"><span class="ltx_text ltx_font_bold" id="S3.SS2.p5.1.1">Q:</span> If the concept is not mentioned at all in the abstract, what should I do? 
<span class="ltx_text ltx_font_bold" id="S3.SS2.p5.1.2">A:</span> Mark it as “N/A” (not applicable).</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.p6">
<p class="ltx_p" id="S3.SS2.p6.1"><span class="ltx_text ltx_font_bold" id="S3.SS2.p6.1.1">Q:</span> If the author claims a non-measurable outcome, should it be considered as an Outcome or Future Impact? 
<span class="ltx_text ltx_font_bold" id="S3.SS2.p6.1.2">A:</span> Future Impact.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.p7">
<p class="ltx_p" id="S3.SS2.p7.1"><span class="ltx_text ltx_font_bold" id="S3.SS2.p7.1.1">Q:</span> If the author mentions an impact that has happened (e.g. the first work to …), should it be considered as an Outcome or Future Impact? 
<span class="ltx_text ltx_font_bold" id="S3.SS2.p7.1.2">A:</span> Outcome.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.p8">
<p class="ltx_p" id="S3.SS2.p8.1"><span class="ltx_text ltx_font_bold" id="S3.SS2.p8.1.1">Q:</span> If the author mentions a new observation that motivates them to propose the key idea, should it be considered as context or key idea? 
<span class="ltx_text ltx_font_bold" id="S3.SS2.p8.1.2">A:</span> Key idea.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.p9">
<p class="ltx_p" id="S3.SS2.p9.1"><span class="ltx_text ltx_font_bold" id="S3.SS2.p9.1.1">Q:</span> Should future impact consider its real impact? For example, a paper gains a lot of citations. 
<span class="ltx_text ltx_font_bold" id="S3.SS2.p9.1.2">A:</span> Future Impact should not consider other papers.</p>
</div>
</section>
<section class="ltx_subsection" id="A2.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.5 </span>Implementation Details of Semantic-Based Evaluation Metrics</h3>
<div class="ltx_para ltx_noindent" id="A2.SS5.p1">
<ul class="ltx_itemize" id="A2.I4">
<li class="ltx_item" id="A2.I4.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A2.I4.i1.p1">
<p class="ltx_p" id="A2.I4.i1.p1.1"><span class="ltx_text ltx_font_italic" id="A2.I4.i1.p1.1.1">Cosine Similarity</span>: We compute the cosine similarity between sentence embeddings generated by <span class="ltx_text ltx_font_typewriter" id="A2.I4.i1.p1.1.2">intfloat/multilingual-e5-large-instruct</span> from HuggingFace.</p>
</div>
</li>
<li class="ltx_item" id="A2.I4.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A2.I4.i2.p1">
<p class="ltx_p" id="A2.I4.i2.p1.1"><span class="ltx_text ltx_font_italic" id="A2.I4.i2.p1.1.1">BLEURT</span>: We use the pre-trained checkpoint <span class="ltx_text ltx_font_typewriter" id="A2.I4.i2.p1.1.2">BLEURT-20-D12</span>.</p>
</div>
</li>
<li class="ltx_item" id="A2.I4.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para ltx_noindent" id="A2.I4.i3.p1">
<p class="ltx_p" id="A2.I4.i3.p1.1"><span class="ltx_text ltx_font_italic" id="A2.I4.i3.p1.1.1">BERTScore</span>: We use the pre-trained checkpoint from HuggingFace <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://huggingface.co/spaces/evaluate-metric/bertscore" title="">https://huggingface.co/spaces/evaluate-metric/bertscore</a>.</p>
</div>
</li>
</ul>
<p class="ltx_p" id="A2.SS5.p1.1">We follow the implementation of ROUGE to select the maximum score when there are multiple references.</p>
</div>
</section>
<section class="ltx_subsection" id="A2.SS6">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.6 </span>Examples of Texts for Different Similarity Levels</h3>
<div class="ltx_para ltx_noindent" id="A2.SS6.p1">
<p class="ltx_p" id="A2.SS6.p1.1">We provide two examples of texts to illustrate how the evaluation metrics could be interpreted. The evaluation results can be found at Table <a class="ltx_ref" href="https://arxiv.org/html/2406.06357v1#A2.T7" title="Table 7 ‣ B.6 Examples of Texts for Different Similarity Levels ‣ 3 Dataset Validation ‣ 2.3 Dataset Statistics and Visualization ‣ Automatic aspect summarization with LLMs. ‣ Large-scale scientific publication collection. ‣ 2.2 Data Curation and Aspect Summarization ‣ 2 Dataset Overview ‣ MASSW: A New Dataset and Benchmark Tasks for AI-Assisted Scientific Workflows"><span class="ltx_text ltx_ref_tag">7</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2406.06357v1#A2.T8" title="Table 8 ‣ B.6 Examples of Texts for Different Similarity Levels ‣ 3 Dataset Validation ‣ 2.3 Dataset Statistics and Visualization ‣ Automatic aspect summarization with LLMs. ‣ Large-scale scientific publication collection. ‣ 2.2 Data Curation and Aspect Summarization ‣ 2 Dataset Overview ‣ MASSW: A New Dataset and Benchmark Tasks for AI-Assisted Scientific Workflows"><span class="ltx_text ltx_ref_tag">8</span></a>.</p>
<ul class="ltx_itemize" id="A2.I5">
<li class="ltx_item" id="A2.I5.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A2.I5.i1.p1">
<p class="ltx_p" id="A2.I5.i1.p1.1"><span class="ltx_text ltx_font_bold" id="A2.I5.i1.p1.1.1">Reference 1:</span> InstructGPT, even with 100x fewer parameters, is preferred over GPT-3 in human evaluations. It shows improvements in truthfulness and reductions in toxic outputs with minimal performance regressions on public NLP datasets.</p>
</div>
</li>
<li class="ltx_item" id="A2.I5.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A2.I5.i2.p1">
<p class="ltx_p" id="A2.I5.i2.p1.1"><span class="ltx_text ltx_font_bold" id="A2.I5.i2.p1.1.1">Example 1a:</span> InstructGPT, despite having 100x fewer parameters, is preferred over the larger GPT-3 according to human evaluations, demonstrating better truthfulness and fewer toxic outputs with only minimal regressions in performance on public NLP benchmarks.</p>
</div>
</li>
<li class="ltx_item" id="A2.I5.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A2.I5.i3.p1">
<p class="ltx_p" id="A2.I5.i3.p1.1"><span class="ltx_text ltx_font_bold" id="A2.I5.i3.p1.1.1">Example 1b:</span> Human evaluations favor the 1.3B parameter InstructGPT model over the 175B GPT-3 model, even though it has significantly fewer parameters. It also shows enhanced truthfulness and reduced generation of toxic content, with negligible declines in performance across standard NLP datasets.</p>
</div>
</li>
<li class="ltx_item" id="A2.I5.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A2.I5.i4.p1">
<p class="ltx_p" id="A2.I5.i4.p1.1"><span class="ltx_text ltx_font_bold" id="A2.I5.i4.p1.1.1">Example 1c:</span> In human assessments, the smaller InstructGPT model, which has far fewer parameters, outperforms GPT-3, showing not only increased accuracy but also less toxic output, with only slight performance downturns on widely recognized NLP tests.</p>
</div>
</li>
<li class="ltx_item" id="A2.I5.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A2.I5.i5.p1">
<p class="ltx_p" id="A2.I5.i5.p1.1"><span class="ltx_text ltx_font_bold" id="A2.I5.i5.p1.1.1">Example 1d:</span> This paper explores the enhancement of language model alignment with human intent through fine-tuning methods using labeler feedback and reinforcement learning, resulting in a smaller, more efficient model that surpasses a much larger baseline in both user satisfaction and safety metrics.</p>
</div>
</li>
<li class="ltx_item" id="A2.I5.i6" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para ltx_noindent" id="A2.I5.i6.p1">
<p class="ltx_p" id="A2.I5.i6.p1.1"><span class="ltx_text ltx_font_bold" id="A2.I5.i6.p1.1.1">Example 1e:</span> Effective communication is not about speaking more; it’s about achieving more with fewer words.</p>
</div>
</li>
</ul>
</div>
<figure class="ltx_table" id="A2.T7">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="A2.T7.1">
<tr class="ltx_tr" id="A2.T7.1.1">
<td class="ltx_td ltx_align_center ltx_border_tt" id="A2.T7.1.1.1"><span class="ltx_text ltx_font_bold" id="A2.T7.1.1.1.1">Example</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A2.T7.1.1.2"><span class="ltx_text ltx_font_bold" id="A2.T7.1.1.2.1">CS</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A2.T7.1.1.3"><span class="ltx_text ltx_font_bold" id="A2.T7.1.1.3.1">BLEURT</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A2.T7.1.1.4"><span class="ltx_text ltx_font_bold" id="A2.T7.1.1.4.1">BS</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A2.T7.1.1.5"><span class="ltx_text ltx_font_bold" id="A2.T7.1.1.5.1">BLEU</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A2.T7.1.1.6"><span class="ltx_text ltx_font_bold" id="A2.T7.1.1.6.1">ROUGE-1</span></td>
</tr>
<tr class="ltx_tr" id="A2.T7.1.2">
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T7.1.2.1">1a</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T7.1.2.2">0.9500</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T7.1.2.3">0.7185</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T7.1.2.4">0.9589</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T7.1.2.5">0.2753</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T7.1.2.6">0.6970</td>
</tr>
<tr class="ltx_tr" id="A2.T7.1.3">
<td class="ltx_td ltx_align_center" id="A2.T7.1.3.1">1b</td>
<td class="ltx_td ltx_align_center" id="A2.T7.1.3.2">0.9366</td>
<td class="ltx_td ltx_align_center" id="A2.T7.1.3.3">0.6202</td>
<td class="ltx_td ltx_align_center" id="A2.T7.1.3.4">0.9188</td>
<td class="ltx_td ltx_align_center" id="A2.T7.1.3.5">0.0000</td>
<td class="ltx_td ltx_align_center" id="A2.T7.1.3.6">0.5135</td>
</tr>
<tr class="ltx_tr" id="A2.T7.1.4">
<td class="ltx_td ltx_align_center" id="A2.T7.1.4.1">1c</td>
<td class="ltx_td ltx_align_center" id="A2.T7.1.4.2">0.9326</td>
<td class="ltx_td ltx_align_center" id="A2.T7.1.4.3">0.5572</td>
<td class="ltx_td ltx_align_center" id="A2.T7.1.4.4">0.9109</td>
<td class="ltx_td ltx_align_center" id="A2.T7.1.4.5">0.0000</td>
<td class="ltx_td ltx_align_center" id="A2.T7.1.4.6">0.3582</td>
</tr>
<tr class="ltx_tr" id="A2.T7.1.5">
<td class="ltx_td ltx_align_center" id="A2.T7.1.5.1">1d</td>
<td class="ltx_td ltx_align_center" id="A2.T7.1.5.2">0.8384</td>
<td class="ltx_td ltx_align_center" id="A2.T7.1.5.3">0.3119</td>
<td class="ltx_td ltx_align_center" id="A2.T7.1.5.4">0.8504</td>
<td class="ltx_td ltx_align_center" id="A2.T7.1.5.5">0.0000</td>
<td class="ltx_td ltx_align_center" id="A2.T7.1.5.6">0.1351</td>
</tr>
<tr class="ltx_tr" id="A2.T7.1.6">
<td class="ltx_td ltx_align_center ltx_border_bb" id="A2.T7.1.6.1">1e</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A2.T7.1.6.2">0.7594</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A2.T7.1.6.3">0.1953</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A2.T7.1.6.4">0.8396</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A2.T7.1.6.5">0.0000</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A2.T7.1.6.6">0.1702</td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 7: </span>Evaluation of similarity between examples and Reference 1 using various metrics.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="A2.SS6.p2">
<ul class="ltx_itemize" id="A2.I6">
<li class="ltx_item" id="A2.I6.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A2.I6.i1.p1">
<p class="ltx_p" id="A2.I6.i1.p1.1"><span class="ltx_text ltx_font_bold" id="A2.I6.i1.p1.1.1">Reference 2:</span> The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing sequence transduction models connect the encoder and decoder through an attention mechanism.</p>
</div>
</li>
<li class="ltx_item" id="A2.I6.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A2.I6.i2.p1">
<p class="ltx_p" id="A2.I6.i2.p1.1"><span class="ltx_text ltx_font_bold" id="A2.I6.i2.p1.1.1">Example 2a:</span> The leading sequence transduction models utilize complex recurrent or convolutional neural networks in an encoder-decoder framework, with the most effective models incorporating an attention mechanism between the encoder and decoder.</p>
</div>
</li>
<li class="ltx_item" id="A2.I6.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A2.I6.i3.p1">
<p class="ltx_p" id="A2.I6.i3.p1.1"><span class="ltx_text ltx_font_bold" id="A2.I6.i3.p1.1.1">Example 2b:</span> Traditional sequence transduction models rely on sophisticated recurrent or convolutional neural networks arranged in an encoder-decoder setup, where top-performing models are distinguished by the use of an attention mechanism linking the encoder and decoder.</p>
</div>
</li>
<li class="ltx_item" id="A2.I6.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A2.I6.i4.p1">
<p class="ltx_p" id="A2.I6.i4.p1.1"><span class="ltx_text ltx_font_bold" id="A2.I6.i4.p1.1.1">Example 2c:</span> Existing high-performing sequence transduction models typically feature either recurrent or convolutional neural networks configured in an encoder-decoder structure, often enhanced with an attention mechanism to improve performance.</p>
</div>
</li>
<li class="ltx_item" id="A2.I6.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A2.I6.i5.p1">
<p class="ltx_p" id="A2.I6.i5.p1.1"><span class="ltx_text ltx_font_bold" id="A2.I6.i5.p1.1.1">Example 2d:</span> The paper introduces the Transformer, a novel network architecture that eschews recurrent and convolutional structures in favor of a design entirely based on attention mechanisms, aiming to enhance parallelizability and reduce training time.</p>
</div>
</li>
<li class="ltx_item" id="A2.I6.i6" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para ltx_noindent" id="A2.I6.i6.p1">
<p class="ltx_p" id="A2.I6.i6.p1.1"><span class="ltx_text ltx_font_bold" id="A2.I6.i6.p1.1.1">Example 2e:</span> "Simplicity is the ultimate sophistication." - Leonardo da Vinci</p>
</div>
</li>
</ul>
</div>
<figure class="ltx_table" id="A2.T8">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="A2.T8.1">
<tr class="ltx_tr" id="A2.T8.1.1">
<td class="ltx_td ltx_align_center ltx_border_tt" id="A2.T8.1.1.1"><span class="ltx_text ltx_font_bold" id="A2.T8.1.1.1.1">Example</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A2.T8.1.1.2"><span class="ltx_text ltx_font_bold" id="A2.T8.1.1.2.1">CS</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A2.T8.1.1.3"><span class="ltx_text ltx_font_bold" id="A2.T8.1.1.3.1">BLEURT</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A2.T8.1.1.4"><span class="ltx_text ltx_font_bold" id="A2.T8.1.1.4.1">BS</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A2.T8.1.1.5"><span class="ltx_text ltx_font_bold" id="A2.T8.1.1.5.1">BLEU</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A2.T8.1.1.6"><span class="ltx_text ltx_font_bold" id="A2.T8.1.1.6.1">ROUGE-1</span></td>
</tr>
<tr class="ltx_tr" id="A2.T8.1.2">
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T8.1.2.1">2a</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T8.1.2.2">0.9572</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T8.1.2.3">0.7256</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T8.1.2.4">0.9613</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T8.1.2.5">0.3772</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T8.1.2.6">0.7077</td>
</tr>
<tr class="ltx_tr" id="A2.T8.1.3">
<td class="ltx_td ltx_align_center" id="A2.T8.1.3.1">2b</td>
<td class="ltx_td ltx_align_center" id="A2.T8.1.3.2">0.9516</td>
<td class="ltx_td ltx_align_center" id="A2.T8.1.3.3">0.6781</td>
<td class="ltx_td ltx_align_center" id="A2.T8.1.3.4">0.9494</td>
<td class="ltx_td ltx_align_center" id="A2.T8.1.3.5">0.2689</td>
<td class="ltx_td ltx_align_center" id="A2.T8.1.3.6">0.6857</td>
</tr>
<tr class="ltx_tr" id="A2.T8.1.4">
<td class="ltx_td ltx_align_center" id="A2.T8.1.4.1">2c</td>
<td class="ltx_td ltx_align_center" id="A2.T8.1.4.2">0.9381</td>
<td class="ltx_td ltx_align_center" id="A2.T8.1.4.3">0.5660</td>
<td class="ltx_td ltx_align_center" id="A2.T8.1.4.4">0.9289</td>
<td class="ltx_td ltx_align_center" id="A2.T8.1.4.5">0.1927</td>
<td class="ltx_td ltx_align_center" id="A2.T8.1.4.6">0.5079</td>
</tr>
<tr class="ltx_tr" id="A2.T8.1.5">
<td class="ltx_td ltx_align_center" id="A2.T8.1.5.1">2d</td>
<td class="ltx_td ltx_align_center" id="A2.T8.1.5.2">0.8355</td>
<td class="ltx_td ltx_align_center" id="A2.T8.1.5.3">0.3598</td>
<td class="ltx_td ltx_align_center" id="A2.T8.1.5.4">0.8645</td>
<td class="ltx_td ltx_align_center" id="A2.T8.1.5.5">0.0000</td>
<td class="ltx_td ltx_align_center" id="A2.T8.1.5.6">0.2687</td>
</tr>
<tr class="ltx_tr" id="A2.T8.1.6">
<td class="ltx_td ltx_align_center ltx_border_bb" id="A2.T8.1.6.1">2e</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A2.T8.1.6.2">0.7108</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A2.T8.1.6.3">0.1728</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A2.T8.1.6.4">0.8095</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A2.T8.1.6.5">0.0000</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A2.T8.1.6.6">0.0476</td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 8: </span>Evaluation of similarity between examples and Reference 2 using various metrics.</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="A2.SS7">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.7 </span>Experiment Details</h3>
<section class="ltx_paragraph" id="A2.SS7.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Test set sampling.</h4>
<div class="ltx_para ltx_noindent" id="A2.SS7.SSS0.Px1.p1">
<p class="ltx_p" id="A2.SS7.SSS0.Px1.p1.1">In the benchmark section, We use proportionate stratified sampling to construct the test set. According to publication year, we separate the year range into at most 10 strata (i.e. groups). Each group covers approximately the same number of years. The we sample from each strata proportionally to the number of papers in that strata. The number of samples for each venue is 60, which results in 1020 papers in total.</p>
</div>
</section>
<section class="ltx_paragraph" id="A2.SS7.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Prompting templates.</h4>
<div class="ltx_para ltx_noindent" id="A2.SS7.SSS0.Px2.p1">
<p class="ltx_p" id="A2.SS7.SSS0.Px2.p1.1">We recall that the model will take in three part of information:
(i) definitions of all five aspects, (ii) all necessary aspects for each task, and (iii) a specific task instruction. We include the prompts for all tasks below.</p>
</div>
<div class="ltx_para ltx_noindent" id="A2.SS7.SSS0.Px2.p2">
<svg class="ltx_picture" height="352.22" id="A2.SS7.SSS0.Px2.p2.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,352.22) matrix(1 0 0 -1 0 0)"><g fill="#000000" fill-opacity="1.0"><path d="M 0 12.5 L 0 339.71 C 0 346.62 5.6 352.22 12.5 352.22 L 587.5 352.22 C 594.4 352.22 600 346.62 600 339.71 L 600 12.5 C 600 5.6 594.4 0 587.5 0 L 12.5 0 C 5.6 0 0 5.6 0 12.5 Z" style="stroke:none"></path></g><g fill="#E6E6E6" fill-opacity="1.0"><path d="M 0.69 12.5 L 0.69 324.85 L 599.31 324.85 L 599.31 12.5 C 599.31 5.98 594.02 0.69 587.5 0.69 L 12.5 0.69 C 5.98 0.69 0.69 5.98 0.69 12.5 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.45 332.46)"><foreignobject color="#FFFFFF" height="12.15" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="557.11">
<span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="A2.SS7.SSS0.Px2.p2.pic1.1.1.1.1.1" style="width:402.6pt;">
<span class="ltx_p" id="A2.SS7.SSS0.Px2.p2.pic1.1.1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="A2.SS7.SSS0.Px2.p2.pic1.1.1.1.1.1.1.1">Prompt</span></span>
</span></foreignobject></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.45 15.48)"><foreignobject color="#000000" height="294.57" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="557.11">
<span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="A2.SS7.SSS0.Px2.p2.pic1.2.2.2.1.1" style="width:402.6pt;">
<span class="ltx_p" id="A2.SS7.SSS0.Px2.p2.pic1.2.2.2.1.1.1"><span class="ltx_text ltx_font_bold" id="A2.SS7.SSS0.Px2.p2.pic1.2.2.2.1.1.1.1">System message:</span></span>
<span class="ltx_p" id="A2.SS7.SSS0.Px2.p2.pic1.2.2.2.1.1.2">You are an expert in research tasked with generating detailed prompts for various aspects of academic research papers. Each task involves creating a specific type of prompt based on the provided information. Here are the definitions of each part you will work with:</span>
<span class="ltx_p" id="A2.SS7.SSS0.Px2.p2.pic1.2.2.2.1.1.3">- Concept</span>
<span class="ltx_p" id="A2.SS7.SSS0.Px2.p2.pic1.2.2.2.1.1.4">- Definition</span>
<span class="ltx_p" id="A2.SS7.SSS0.Px2.p2.pic1.2.2.2.1.1.5">- Relative Time</span>
<span class="ltx_p" id="A2.SS7.SSS0.Px2.p2.pic1.2.2.2.1.1.6">- Context: The status quo of related literature or reality which motivated this study. This could normally be a problem, a research question, or a research gap that has not been successfully addressed by previous work. This is anything that happened before this study.</span>
<span class="ltx_p" id="A2.SS7.SSS0.Px2.p2.pic1.2.2.2.1.1.7">- Key Idea: The main intellectual merit of this paper, often in comparison to the context. This could normally be a novel idea or solution proposed in this paper that distinguishes it from what’s already done in literature. This is proposed in this study.</span>
<span class="ltx_p" id="A2.SS7.SSS0.Px2.p2.pic1.2.2.2.1.1.8">- Method: The specific research method that investigates and validates the key idea. This could be an experimental setup, a theoretical framework, or other necessary methodology to implement and/or evaluate the key idea. This is performed in this study.</span>
<span class="ltx_p" id="A2.SS7.SSS0.Px2.p2.pic1.2.2.2.1.1.9">- Outcome: The factual statement about the study output. This could be the experiment results and any other measurable outcome that has occurred. It marks whether the key hypothesis is testified or not. This is produced in this study.</span>
<span class="ltx_p" id="A2.SS7.SSS0.Px2.p2.pic1.2.2.2.1.1.10">- Projected Impact: The author-anticipated impact of the work on the field, and potential further research identified by the author that may improve or extend this study. This is anything being anticipated but has not happened yet.</span>
</span></foreignobject></g></g></svg>
</div>
<div class="ltx_para ltx_noindent" id="A2.SS7.SSS0.Px2.p3">
<svg class="ltx_picture" height="351.12" id="A2.SS7.SSS0.Px2.p3.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,351.12) matrix(1 0 0 -1 0 0)"><g fill="#000000" fill-opacity="1.0"><path d="M 0 12.5 L 0 338.62 C 0 345.52 5.6 351.12 12.5 351.12 L 587.5 351.12 C 594.4 351.12 600 345.52 600 338.62 L 600 12.5 C 600 5.6 594.4 0 587.5 0 L 12.5 0 C 5.6 0 0 5.6 0 12.5 Z" style="stroke:none"></path></g><g fill="#E6E6E6" fill-opacity="1.0"><path d="M 0.69 12.5 L 0.69 323.75 L 599.31 323.75 L 599.31 12.5 C 599.31 5.98 594.02 0.69 587.5 0.69 L 12.5 0.69 C 5.98 0.69 0.69 5.98 0.69 12.5 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.45 331.36)"><foreignobject color="#FFFFFF" height="12.15" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="557.11">
<span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="A2.SS7.SSS0.Px2.p3.pic1.1.1.1.1.1" style="width:402.6pt;">
<span class="ltx_p" id="A2.SS7.SSS0.Px2.p3.pic1.1.1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="A2.SS7.SSS0.Px2.p3.pic1.1.1.1.1.1.1.1">Prompt</span></span>
</span></foreignobject></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.45 15.48)"><foreignobject color="#000000" height="293.48" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="557.11">
<span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="A2.SS7.SSS0.Px2.p3.pic1.2.2.2.1.1" style="width:402.6pt;">
<span class="ltx_p" id="A2.SS7.SSS0.Px2.p3.pic1.2.2.2.1.1.1"><span class="ltx_text ltx_font_bold" id="A2.SS7.SSS0.Px2.p3.pic1.2.2.2.1.1.1.1">Template for idea generation:</span></span>
<span class="ltx_p" id="A2.SS7.SSS0.Px2.p3.pic1.2.2.2.1.1.2">Given the context: ’{context}’, generate key ideas that could advance this area of study.</span>
<span class="ltx_p" id="A2.SS7.SSS0.Px2.p3.pic1.2.2.2.1.1.3"><span class="ltx_text ltx_font_bold" id="A2.SS7.SSS0.Px2.p3.pic1.2.2.2.1.1.3.1">Template for method recommendation:</span></span>
<span class="ltx_p" id="A2.SS7.SSS0.Px2.p3.pic1.2.2.2.1.1.4">Given the context: ’{context}’ and the key idea: ’{key_idea}’, recommend the most suitable method to validate this idea.</span>
<span class="ltx_p" id="A2.SS7.SSS0.Px2.p3.pic1.2.2.2.1.1.5"><span class="ltx_text ltx_font_bold" id="A2.SS7.SSS0.Px2.p3.pic1.2.2.2.1.1.5.1">Template for outcome prediction:</span></span>
<span class="ltx_p" id="A2.SS7.SSS0.Px2.p3.pic1.2.2.2.1.1.6">Based on the context: ’{context}’, the key idea: ’{key_idea}’, and the recommended method: ’{method}’, predict the potential outcome of this research.</span>
<span class="ltx_p" id="A2.SS7.SSS0.Px2.p3.pic1.2.2.2.1.1.7"><span class="ltx_text ltx_font_bold" id="A2.SS7.SSS0.Px2.p3.pic1.2.2.2.1.1.7.1">Template for impact prediction:</span></span>
<span class="ltx_p" id="A2.SS7.SSS0.Px2.p3.pic1.2.2.2.1.1.8">Based on the context: ’{context}’, the key idea: ’{key_idea}’, the method: ’{method}’, and the outcome: ’{outcome}’, suggest projected Impact for this research.</span>
<span class="ltx_p" id="A2.SS7.SSS0.Px2.p3.pic1.2.2.2.1.1.9"><span class="ltx_text ltx_font_bold" id="A2.SS7.SSS0.Px2.p3.pic1.2.2.2.1.1.9.1">Template for title prediction:</span></span>
<span class="ltx_p" id="A2.SS7.SSS0.Px2.p3.pic1.2.2.2.1.1.10">Given the context: ’{context}’, the key idea: ’{key_idea}’, the method: ’{method}’, the outcome: ’{outcome}’, and the future impact: ’{future_impact}’, predict the title of this research paper. The title should be concise and reflective of the core aspects.</span>
</span></foreignobject></g></g></svg>
</div>
</section>
<section class="ltx_paragraph" id="A2.SS7.SSS0.Px3">
<h4 class="ltx_title ltx_title_paragraph">Details about prompting methods.</h4>
<div class="ltx_para ltx_noindent" id="A2.SS7.SSS0.Px3.p1">
<p class="ltx_p" id="A2.SS7.SSS0.Px3.p1.1">For the zero shot prediction, model will take in the system prompt and user prompt. For the few shot prompting, we add two fixed round of conversation before the actual user request. The few-shot examples can be found in the code-base under the data folder. For chain of thought prompts, we add the sentence “Let’s think step by step. The final prediction should start after the marker ’Prediction:’.” at the end of zero-shot prompts. After LLMs produce the output, we extract the content after the word “Prediction” as the final prediction.</p>
</div>
</section>
<section class="ltx_paragraph" id="A2.SS7.SSS0.Px4">
<h4 class="ltx_title ltx_title_paragraph">Details about baseline LLMs.</h4>
<div class="ltx_para ltx_noindent" id="A2.SS7.SSS0.Px4.p1">
<p class="ltx_p" id="A2.SS7.SSS0.Px4.p1.1">We use Azure platform for all baseline models. The model id used in this study are <span class="ltx_text ltx_font_typewriter" id="A2.SS7.SSS0.Px4.p1.1.1">gpt-35-turbo (0125)<span class="ltx_note ltx_role_footnote" id="footnote10"><sup class="ltx_note_mark">10</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">10</sup><span class="ltx_tag ltx_tag_note"><span class="ltx_text ltx_font_serif" id="footnote10.1.1.1">10</span></span><a class="ltx_ref ltx_url" href="https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models" title="">https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models</a></span></span></span></span>, <span class="ltx_text ltx_font_typewriter" id="A2.SS7.SSS0.Px4.p1.1.2">gpt-4 (turbo-2024-04-09)</span> and <span class="ltx_text ltx_font_typewriter" id="A2.SS7.SSS0.Px4.p1.1.3">mistralai-mixtral-8x7b-instru-7<span class="ltx_note ltx_role_footnote" id="footnote11"><sup class="ltx_note_mark">11</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">11</sup><span class="ltx_tag ltx_tag_note"><span class="ltx_text ltx_font_serif" id="footnote11.1.1.1">11</span></span><a class="ltx_ref ltx_url" href="https://learn.microsoft.com/en-us/azure/machine-learning/how-to-deploy-models-mistral?view=azureml-api-2&amp;tabs=mistral-large" title="">https://learn.microsoft.com/en-us/azure/machine-learning/how-to-deploy-models-mistral?view=azureml-api-2&amp;tabs=mistral-large</a></span></span></span></span>. For the mistral model, as the model does not take in system prompt, we replace it with one round of conversation (user: <span class="ltx_text ltx_font_typewriter" id="A2.SS7.SSS0.Px4.p1.1.4">&lt;system prompt&gt;</span>, assistant: <span class="ltx_text ltx_font_typewriter" id="A2.SS7.SSS0.Px4.p1.1.5">I got it. Please give me further instructions!</span>).</p>
</div>
</section>
<section class="ltx_paragraph" id="A2.SS7.SSS0.Px5">
<h4 class="ltx_title ltx_title_paragraph">Example model outputs.</h4>
<div class="ltx_para ltx_noindent" id="A2.SS7.SSS0.Px5.p1">
<p class="ltx_p" id="A2.SS7.SSS0.Px5.p1.1">We include an example output for all the prompting methods in Table <a class="ltx_ref" href="https://arxiv.org/html/2406.06357v1#A2.T9" title="Table 9 ‣ Example model outputs. ‣ B.7 Experiment Details ‣ 3 Dataset Validation ‣ 2.3 Dataset Statistics and Visualization ‣ Automatic aspect summarization with LLMs. ‣ Large-scale scientific publication collection. ‣ 2.2 Data Curation and Aspect Summarization ‣ 2 Dataset Overview ‣ MASSW: A New Dataset and Benchmark Tasks for AI-Assisted Scientific Workflows"><span class="ltx_text ltx_ref_tag">9</span></a>.</p>
</div>
<figure class="ltx_table" id="A2.T9">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="A2.T9.1">
<tr class="ltx_tr" id="A2.T9.1.1">
<td class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r" id="A2.T9.1.1.1" style="width:43.4pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.T9.1.1.1.1">
<span class="ltx_p" id="A2.T9.1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="A2.T9.1.1.1.1.1.1">Prompt Type</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_middle" id="A2.T9.1.1.2" style="width:368.6pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.T9.1.1.2.1">
<span class="ltx_p" id="A2.T9.1.1.2.1.1"><span class="ltx_text ltx_font_bold" id="A2.T9.1.1.2.1.1.1">Model Output/Ground Truth</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A2.T9.1.2">
<td class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" id="A2.T9.1.2.1" style="width:43.4pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.T9.1.2.1.1">
<span class="ltx_p" id="A2.T9.1.2.1.1.1"><span class="ltx_text ltx_font_bold" id="A2.T9.1.2.1.1.1.1">Ground Truth</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" id="A2.T9.1.2.2" style="width:368.6pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.T9.1.2.2.1">
<span class="ltx_p" id="A2.T9.1.2.2.1.1">This paper introduces the concept of co-space applications, which provide opportunities unavailable in separate physical or virtual spaces, and posit that the database community can significantly contribute to this emerging field.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A2.T9.1.3">
<td class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" id="A2.T9.1.3.1" style="width:43.4pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.T9.1.3.1.1">
<span class="ltx_p" id="A2.T9.1.3.1.1.1"><span class="ltx_text ltx_font_bold" id="A2.T9.1.3.1.1.1.1">0-shot</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" id="A2.T9.1.3.2" style="width:368.6pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.T9.1.3.2.1">
<span class="ltx_p" id="A2.T9.1.3.2.1.1">**Key Idea 1: Development of a Unified Interaction Framework**</span>
<span class="ltx_p" id="A2.T9.1.3.2.1.2">- **Concept:** This key idea proposes creating a unified interaction framework that enables users to interact with both physical and virtual elements through a single interface or set of interaction gestures. This framework integrates sensory feedback mechanisms (e.g., haptic, auditory, visual cues) that are context-aware and adapt based on the user’s actions and environmental conditions.</span>
<span class="ltx_p" id="A2.T9.1.3.2.1.3">- **Relative Time:** Proposed in this study.</span>
<span class="ltx_p" id="A2.T9.1.3.2.1.4">**Key Idea 2: Hybrid Space Adaptation Engine**</span>
<span class="ltx_p" id="A2.T9.1.3.2.1.5">- **Concept:** The introduction of a hybrid space adaptation engine designed to dynamically modify the virtual space in response to changes in the physical environment and vice versa. This engine uses real-time data analytics and machine learning algorithms to predict and adapt to user needs and environmental shifts, ensuring a consistent and immersive experience across both domains.</span>
<span class="ltx_p" id="A2.T9.1.3.2.1.6">- **Relative Time:** Proposed in this study.</span>
<span class="ltx_p" id="A2.T9.1.3.2.1.7">&lt;Some other key ideas.&gt;</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A2.T9.1.4">
<td class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" id="A2.T9.1.4.1" style="width:43.4pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.T9.1.4.1.1">
<span class="ltx_p" id="A2.T9.1.4.1.1.1"><span class="ltx_text ltx_font_bold" id="A2.T9.1.4.1.1.1.1">2-shot</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" id="A2.T9.1.4.2" style="width:368.6pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.T9.1.4.2.1">
<span class="ltx_p" id="A2.T9.1.4.2.1.1">The researchers propose the development of an intuitive Mixed Reality (MR) interface that leverages advancements in augmented reality (AR) and virtual reality (VR), combined with real-time spatial computing and machine learning algorithms. This interface is designed to enable more seamless and intuitive user control and interaction between physical and virtual spaces, enhancing the co-space experience by making digital manipulations feel as tangible as physical ones.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A2.T9.1.5">
<td class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" id="A2.T9.1.5.1" style="width:43.4pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.T9.1.5.1.1">
<span class="ltx_p" id="A2.T9.1.5.1.1.1"><span class="ltx_text ltx_font_bold" id="A2.T9.1.5.1.1.1.1">CoT</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" id="A2.T9.1.5.2" style="width:368.6pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.T9.1.5.2.1">
<span class="ltx_p" id="A2.T9.1.5.2.1.1">To address the context effectively, a detailed step-by-step approach will be taken to generate key ideas that could significantly advance the study of co-space environments, where the integration and interaction between physical and virtual spaces present both challenges and opportunities for technological innovation. These key ideas are crafted to facilitate a seamless manipulation of real and digital spaces by users.</span>
<span class="ltx_p" id="A2.T9.1.5.2.1.2">### Concept:
- **Definition**: Co-space environments are settings in which physical and digital realms are intertwined, allowing for continuous interaction and manipulation across these domains.
- **Relative Time**: This concept is becoming increasingly relevant with the advances in augmented reality (AR), virtual reality (VR), mixed reality (MR), and Internet of Things (IoT) technologies.</span>
<span class="ltx_p" id="A2.T9.1.5.2.1.3">### Key Ideas:</span>
<span class="ltx_p" id="A2.T9.1.5.2.1.4">1. **Development of a Unified Interaction Protocol (UIP)**
- This protocol would standardize the way in which interactions occur between the physical and virtual components of a co-space environment. The UIP would ensure that devices, regardless of their operational technology (OT) or information technology (IT) origins, can communicate and interact seamlessly in a common language.</span>
<span class="ltx_p" id="A2.T9.1.5.2.1.5">2. **Real-time Spatial Mapping and Augmentation Technology**
- An advanced spatial mapping technology that dynamically captures the physical environment and accurately overlays digital information in real-time. This would not only facilitate seamless user manipulation of digital objects in real spaces but also enhance the realism and interactiveness of the virtual space.</span>
<span class="ltx_p" id="A2.T9.1.5.2.1.6">&lt;Some other key ideas.&gt;</span>
<span class="ltx_p" id="A2.T9.1.5.2.1.7">### Prediction:
- The aforementioned key ideas, if successfully implemented, are poised to revolutionize the co-space environment by breaking down the barriers between the physical and virtual realms. These innovations would not only facilitate seamless manipulation of spaces by users but would also set a new standard for interactive technologies, significantly enhancing user experiences while addressing privacy and security concerns. Moreover, the advancement in such areas could pave the way for novel applications ranging from immersive education and remote collaboration to advanced urban planning and beyond.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A2.T9.1.6">
<td class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" id="A2.T9.1.6.1" style="width:43.4pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.T9.1.6.1.1">
<span class="ltx_p" id="A2.T9.1.6.1.1.1"><span class="ltx_text ltx_font_bold" id="A2.T9.1.6.1.1.1.1">2-shot CoT</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" id="A2.T9.1.6.2" style="width:368.6pt;">
<span class="ltx_inline-block ltx_align_top" id="A2.T9.1.6.2.1">
<span class="ltx_p" id="A2.T9.1.6.2.1.1">Integrating physical and virtual realms in co-space environments poses technical and usability challenges, necessitating novel solutions for seamless interaction. One way forward is to bridge the gap between these spaces with technologies that can intuitively understand and manipulate both contexts in real-time.</span>
<span class="ltx_p" id="A2.T9.1.6.2.1.2">Prediction: The authors propose an innovative interaction framework that blends Augmented Reality (AR) and Internet of Things (IoT) technologies. This framework enables users to manipulate objects in both the physical and the virtual spaces through natural gestures and commands, leveraging AR for visual integration and IoT devices for physical state changes.</span>
</span>
</td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 9: </span>Comparison of Zero-shot, Few-shot, and Chain of Thought outputs for a single example by GPT-4.</figcaption>
</figure>
</section>
</section>
<section class="ltx_subsection" id="A2.SS8">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.8 </span>Supplementary Tables</h3>
<div class="ltx_para ltx_noindent" id="A2.SS8.p1">
<p class="ltx_p" id="A2.SS8.p1.1">We include the benchmark results for Cosine Similarity (CS), BERTScore (BS) and BLEU in Table <a class="ltx_ref" href="https://arxiv.org/html/2406.06357v1#A2.T10" title="Table 10 ‣ B.8 Supplementary Tables ‣ 3 Dataset Validation ‣ 2.3 Dataset Statistics and Visualization ‣ Automatic aspect summarization with LLMs. ‣ Large-scale scientific publication collection. ‣ 2.2 Data Curation and Aspect Summarization ‣ 2 Dataset Overview ‣ MASSW: A New Dataset and Benchmark Tasks for AI-Assisted Scientific Workflows"><span class="ltx_text ltx_ref_tag">10</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06357v1#A2.T11" title="Table 11 ‣ B.8 Supplementary Tables ‣ 3 Dataset Validation ‣ 2.3 Dataset Statistics and Visualization ‣ Automatic aspect summarization with LLMs. ‣ Large-scale scientific publication collection. ‣ 2.2 Data Curation and Aspect Summarization ‣ 2 Dataset Overview ‣ MASSW: A New Dataset and Benchmark Tasks for AI-Assisted Scientific Workflows"><span class="ltx_text ltx_ref_tag">11</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.06357v1#A2.T12" title="Table 12 ‣ B.8 Supplementary Tables ‣ 3 Dataset Validation ‣ 2.3 Dataset Statistics and Visualization ‣ Automatic aspect summarization with LLMs. ‣ Large-scale scientific publication collection. ‣ 2.2 Data Curation and Aspect Summarization ‣ 2 Dataset Overview ‣ MASSW: A New Dataset and Benchmark Tasks for AI-Assisted Scientific Workflows"><span class="ltx_text ltx_ref_tag">12</span></a> respectively.</p>
</div>
<figure class="ltx_table" id="A2.T10">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="A2.T10.1">
<tr class="ltx_tr" id="A2.T10.1.1">
<td class="ltx_td ltx_align_left" id="A2.T10.1.1.1">Model</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A2.T10.1.1.2">Prompt</td>
<td class="ltx_td ltx_align_center" colspan="4" id="A2.T10.1.1.3">Aspect Prediction</td>
<td class="ltx_td ltx_align_center" id="A2.T10.1.1.4">Title Prediction</td>
</tr>
<tr class="ltx_tr" id="A2.T10.1.2">
<td class="ltx_td" id="A2.T10.1.2.1"></td>
<td class="ltx_td ltx_border_r" id="A2.T10.1.2.2"></td>
<td class="ltx_td ltx_align_center" id="A2.T10.1.2.3">Idea</td>
<td class="ltx_td ltx_align_center" id="A2.T10.1.2.4">Method</td>
<td class="ltx_td ltx_align_center" id="A2.T10.1.2.5">Outcome</td>
<td class="ltx_td ltx_align_center" id="A2.T10.1.2.6">Future</td>
<td class="ltx_td ltx_align_center" id="A2.T10.1.2.7">Title</td>
</tr>
<tr class="ltx_tr" id="A2.T10.1.3">
<td class="ltx_td ltx_align_left ltx_border_t" id="A2.T10.1.3.1" rowspan="4"><span class="ltx_text" id="A2.T10.1.3.1.1">GPT-3.5</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="A2.T10.1.3.2">0-Shot</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T10.1.3.3">0.869</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T10.1.3.4">0.859</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T10.1.3.5">0.873</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T10.1.3.6">0.881</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T10.1.3.7">0.896</td>
</tr>
<tr class="ltx_tr" id="A2.T10.1.4">
<td class="ltx_td ltx_align_left ltx_border_r" id="A2.T10.1.4.1">2-Shot</td>
<td class="ltx_td ltx_align_center" id="A2.T10.1.4.2">0.874</td>
<td class="ltx_td ltx_align_center" id="A2.T10.1.4.3">0.870</td>
<td class="ltx_td ltx_align_center" id="A2.T10.1.4.4">0.875</td>
<td class="ltx_td ltx_align_center" id="A2.T10.1.4.5">0.879</td>
<td class="ltx_td ltx_align_center" id="A2.T10.1.4.6"><span class="ltx_text ltx_font_bold" id="A2.T10.1.4.6.1">0.913</span></td>
</tr>
<tr class="ltx_tr" id="A2.T10.1.5">
<td class="ltx_td ltx_align_left ltx_border_r" id="A2.T10.1.5.1">CoT</td>
<td class="ltx_td ltx_align_center" id="A2.T10.1.5.2">0.835</td>
<td class="ltx_td ltx_align_center" id="A2.T10.1.5.3">0.850</td>
<td class="ltx_td ltx_align_center" id="A2.T10.1.5.4">0.857</td>
<td class="ltx_td ltx_align_center" id="A2.T10.1.5.5">0.864</td>
<td class="ltx_td ltx_align_center" id="A2.T10.1.5.6">0.893</td>
</tr>
<tr class="ltx_tr" id="A2.T10.1.6">
<td class="ltx_td ltx_align_left ltx_border_r" id="A2.T10.1.6.1">Few-Shot CoT</td>
<td class="ltx_td ltx_align_center" id="A2.T10.1.6.2">0.866</td>
<td class="ltx_td ltx_align_center" id="A2.T10.1.6.3">0.856</td>
<td class="ltx_td ltx_align_center" id="A2.T10.1.6.4">0.862</td>
<td class="ltx_td ltx_align_center" id="A2.T10.1.6.5">0.872</td>
<td class="ltx_td ltx_align_center" id="A2.T10.1.6.6">0.904</td>
</tr>
<tr class="ltx_tr" id="A2.T10.1.7">
<td class="ltx_td ltx_align_left ltx_border_t" id="A2.T10.1.7.1" rowspan="4"><span class="ltx_text" id="A2.T10.1.7.1.1">GPT-4</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="A2.T10.1.7.2">0-Shot</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T10.1.7.3">0.871</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T10.1.7.4"><span class="ltx_text ltx_font_bold" id="A2.T10.1.7.4.1">0.872</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T10.1.7.5">0.875</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T10.1.7.6">0.880</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T10.1.7.7">0.892</td>
</tr>
<tr class="ltx_tr" id="A2.T10.1.8">
<td class="ltx_td ltx_align_left ltx_border_r" id="A2.T10.1.8.1">2-Shot</td>
<td class="ltx_td ltx_align_center" id="A2.T10.1.8.2">0.872</td>
<td class="ltx_td ltx_align_center" id="A2.T10.1.8.3">0.870</td>
<td class="ltx_td ltx_align_center" id="A2.T10.1.8.4">0.875</td>
<td class="ltx_td ltx_align_center" id="A2.T10.1.8.5">0.874</td>
<td class="ltx_td ltx_align_center" id="A2.T10.1.8.6">0.910</td>
</tr>
<tr class="ltx_tr" id="A2.T10.1.9">
<td class="ltx_td ltx_align_left ltx_border_r" id="A2.T10.1.9.1">CoT</td>
<td class="ltx_td ltx_align_center" id="A2.T10.1.9.2">0.869</td>
<td class="ltx_td ltx_align_center" id="A2.T10.1.9.3">0.865</td>
<td class="ltx_td ltx_align_center" id="A2.T10.1.9.4"><span class="ltx_text ltx_font_bold" id="A2.T10.1.9.4.1">0.877</span></td>
<td class="ltx_td ltx_align_center" id="A2.T10.1.9.5">0.878</td>
<td class="ltx_td ltx_align_center" id="A2.T10.1.9.6">0.893</td>
</tr>
<tr class="ltx_tr" id="A2.T10.1.10">
<td class="ltx_td ltx_align_left ltx_border_r" id="A2.T10.1.10.1">Few-Shot CoT</td>
<td class="ltx_td ltx_align_center" id="A2.T10.1.10.2">0.869</td>
<td class="ltx_td ltx_align_center" id="A2.T10.1.10.3">0.865</td>
<td class="ltx_td ltx_align_center" id="A2.T10.1.10.4">0.874</td>
<td class="ltx_td ltx_align_center" id="A2.T10.1.10.5">0.869</td>
<td class="ltx_td ltx_align_center" id="A2.T10.1.10.6">0.902</td>
</tr>
<tr class="ltx_tr" id="A2.T10.1.11">
<td class="ltx_td ltx_align_left ltx_border_t" id="A2.T10.1.11.1" rowspan="4"><span class="ltx_text" id="A2.T10.1.11.1.1">Mistral 8x7B</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="A2.T10.1.11.2">0-Shot</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T10.1.11.3">0.869</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T10.1.11.4">0.869</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T10.1.11.5">0.875</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T10.1.11.6">0.881</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T10.1.11.7">0.884</td>
</tr>
<tr class="ltx_tr" id="A2.T10.1.12">
<td class="ltx_td ltx_align_left ltx_border_r" id="A2.T10.1.12.1">2-Shot</td>
<td class="ltx_td ltx_align_center" id="A2.T10.1.12.2"><span class="ltx_text ltx_font_bold" id="A2.T10.1.12.2.1">0.876</span></td>
<td class="ltx_td ltx_align_center" id="A2.T10.1.12.3">0.868</td>
<td class="ltx_td ltx_align_center" id="A2.T10.1.12.4">0.875</td>
<td class="ltx_td ltx_align_center" id="A2.T10.1.12.5"><span class="ltx_text ltx_font_bold" id="A2.T10.1.12.5.1">0.882</span></td>
<td class="ltx_td ltx_align_center" id="A2.T10.1.12.6">0.897</td>
</tr>
<tr class="ltx_tr" id="A2.T10.1.13">
<td class="ltx_td ltx_align_left ltx_border_r" id="A2.T10.1.13.1">CoT</td>
<td class="ltx_td ltx_align_center" id="A2.T10.1.13.2">0.857</td>
<td class="ltx_td ltx_align_center" id="A2.T10.1.13.3">0.866</td>
<td class="ltx_td ltx_align_center" id="A2.T10.1.13.4">0.858</td>
<td class="ltx_td ltx_align_center" id="A2.T10.1.13.5">0.870</td>
<td class="ltx_td ltx_align_center" id="A2.T10.1.13.6">0.884</td>
</tr>
<tr class="ltx_tr" id="A2.T10.1.14">
<td class="ltx_td ltx_align_left ltx_border_r" id="A2.T10.1.14.1">Few-Shot CoT</td>
<td class="ltx_td ltx_align_center" id="A2.T10.1.14.2">0.872</td>
<td class="ltx_td ltx_align_center" id="A2.T10.1.14.3">0.858</td>
<td class="ltx_td ltx_align_center" id="A2.T10.1.14.4">0.869</td>
<td class="ltx_td ltx_align_center" id="A2.T10.1.14.5">0.875</td>
<td class="ltx_td ltx_align_center" id="A2.T10.1.14.6">0.902</td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 10: </span>Benchmark Results Measured by Cosine Similarity.</figcaption>
</figure>
<figure class="ltx_table" id="A2.T11">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="A2.T11.1">
<tr class="ltx_tr" id="A2.T11.1.1">
<td class="ltx_td ltx_align_left" id="A2.T11.1.1.1">Model</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A2.T11.1.1.2">Prompt</td>
<td class="ltx_td ltx_align_center" colspan="4" id="A2.T11.1.1.3">Aspect Prediction</td>
<td class="ltx_td ltx_align_center" id="A2.T11.1.1.4">Title Prediction</td>
</tr>
<tr class="ltx_tr" id="A2.T11.1.2">
<td class="ltx_td" id="A2.T11.1.2.1"></td>
<td class="ltx_td ltx_border_r" id="A2.T11.1.2.2"></td>
<td class="ltx_td ltx_align_center" id="A2.T11.1.2.3">Idea</td>
<td class="ltx_td ltx_align_center" id="A2.T11.1.2.4">Method</td>
<td class="ltx_td ltx_align_center" id="A2.T11.1.2.5">Outcome</td>
<td class="ltx_td ltx_align_center" id="A2.T11.1.2.6">Future</td>
<td class="ltx_td ltx_align_center" id="A2.T11.1.2.7">Title</td>
</tr>
<tr class="ltx_tr" id="A2.T11.1.3">
<td class="ltx_td ltx_align_left ltx_border_t" id="A2.T11.1.3.1" rowspan="4"><span class="ltx_text" id="A2.T11.1.3.1.1">GPT-3.5</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="A2.T11.1.3.2">0-Shot</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T11.1.3.3">0.839</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T11.1.3.4">0.845</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T11.1.3.5">0.855</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T11.1.3.6">0.860</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T11.1.3.7">0.875</td>
</tr>
<tr class="ltx_tr" id="A2.T11.1.4">
<td class="ltx_td ltx_align_left ltx_border_r" id="A2.T11.1.4.1">2-Shot</td>
<td class="ltx_td ltx_align_center" id="A2.T11.1.4.2"><span class="ltx_text ltx_font_bold" id="A2.T11.1.4.2.1">0.872</span></td>
<td class="ltx_td ltx_align_center" id="A2.T11.1.4.3">0.869</td>
<td class="ltx_td ltx_align_center" id="A2.T11.1.4.4">0.880</td>
<td class="ltx_td ltx_align_center" id="A2.T11.1.4.5">0.875</td>
<td class="ltx_td ltx_align_center" id="A2.T11.1.4.6"><span class="ltx_text ltx_font_bold" id="A2.T11.1.4.6.1">0.892</span></td>
</tr>
<tr class="ltx_tr" id="A2.T11.1.5">
<td class="ltx_td ltx_align_left ltx_border_r" id="A2.T11.1.5.1">CoT</td>
<td class="ltx_td ltx_align_center" id="A2.T11.1.5.2">0.860</td>
<td class="ltx_td ltx_align_center" id="A2.T11.1.5.3">0.858</td>
<td class="ltx_td ltx_align_center" id="A2.T11.1.5.4">0.852</td>
<td class="ltx_td ltx_align_center" id="A2.T11.1.5.5">0.875</td>
<td class="ltx_td ltx_align_center" id="A2.T11.1.5.6">0.870</td>
</tr>
<tr class="ltx_tr" id="A2.T11.1.6">
<td class="ltx_td ltx_align_left ltx_border_r" id="A2.T11.1.6.1">2-Shot CoT</td>
<td class="ltx_td ltx_align_center" id="A2.T11.1.6.2">0.867</td>
<td class="ltx_td ltx_align_center" id="A2.T11.1.6.3"><span class="ltx_text ltx_font_bold" id="A2.T11.1.6.3.1">0.875</span></td>
<td class="ltx_td ltx_align_center" id="A2.T11.1.6.4">0.878</td>
<td class="ltx_td ltx_align_center" id="A2.T11.1.6.5"><span class="ltx_text ltx_font_bold" id="A2.T11.1.6.5.1">0.880</span></td>
<td class="ltx_td ltx_align_center" id="A2.T11.1.6.6">0.891</td>
</tr>
<tr class="ltx_tr" id="A2.T11.1.7">
<td class="ltx_td ltx_align_left ltx_border_t" id="A2.T11.1.7.1" rowspan="4"><span class="ltx_text" id="A2.T11.1.7.1.1">GPT-4</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="A2.T11.1.7.2">0-Shot</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T11.1.7.3">0.815</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T11.1.7.4">0.783</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T11.1.7.5">0.812</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T11.1.7.6">0.814</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T11.1.7.7">0.869</td>
</tr>
<tr class="ltx_tr" id="A2.T11.1.8">
<td class="ltx_td ltx_align_left ltx_border_r" id="A2.T11.1.8.1">2-Shot</td>
<td class="ltx_td ltx_align_center" id="A2.T11.1.8.2">0.869</td>
<td class="ltx_td ltx_align_center" id="A2.T11.1.8.3">0.810</td>
<td class="ltx_td ltx_align_center" id="A2.T11.1.8.4"><span class="ltx_text ltx_font_bold" id="A2.T11.1.8.4.1">0.886</span></td>
<td class="ltx_td ltx_align_center" id="A2.T11.1.8.5">0.854</td>
<td class="ltx_td ltx_align_center" id="A2.T11.1.8.6">0.883</td>
</tr>
<tr class="ltx_tr" id="A2.T11.1.9">
<td class="ltx_td ltx_align_left ltx_border_r" id="A2.T11.1.9.1">CoT</td>
<td class="ltx_td ltx_align_center" id="A2.T11.1.9.2">0.829</td>
<td class="ltx_td ltx_align_center" id="A2.T11.1.9.3">0.806</td>
<td class="ltx_td ltx_align_center" id="A2.T11.1.9.4">0.841</td>
<td class="ltx_td ltx_align_center" id="A2.T11.1.9.5">0.837</td>
<td class="ltx_td ltx_align_center" id="A2.T11.1.9.6">0.869</td>
</tr>
<tr class="ltx_tr" id="A2.T11.1.10">
<td class="ltx_td ltx_align_left ltx_border_r" id="A2.T11.1.10.1">2-Shot CoT</td>
<td class="ltx_td ltx_align_center" id="A2.T11.1.10.2">0.868</td>
<td class="ltx_td ltx_align_center" id="A2.T11.1.10.3">0.858</td>
<td class="ltx_td ltx_align_center" id="A2.T11.1.10.4">0.880</td>
<td class="ltx_td ltx_align_center" id="A2.T11.1.10.5">0.863</td>
<td class="ltx_td ltx_align_center" id="A2.T11.1.10.6">0.884</td>
</tr>
<tr class="ltx_tr" id="A2.T11.1.11">
<td class="ltx_td ltx_align_left ltx_border_t" id="A2.T11.1.11.1" rowspan="4"><span class="ltx_text" id="A2.T11.1.11.1.1">Mistral 8x7B</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="A2.T11.1.11.2">0-Shot</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T11.1.11.3">0.823</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T11.1.11.4">0.822</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T11.1.11.5">0.840</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T11.1.11.6">0.838</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T11.1.11.7">0.822</td>
</tr>
<tr class="ltx_tr" id="A2.T11.1.12">
<td class="ltx_td ltx_align_left ltx_border_r" id="A2.T11.1.12.1">2-Shot</td>
<td class="ltx_td ltx_align_center" id="A2.T11.1.12.2">0.862</td>
<td class="ltx_td ltx_align_center" id="A2.T11.1.12.3">0.855</td>
<td class="ltx_td ltx_align_center" id="A2.T11.1.12.4">0.860</td>
<td class="ltx_td ltx_align_center" id="A2.T11.1.12.5">0.865</td>
<td class="ltx_td ltx_align_center" id="A2.T11.1.12.6">0.847</td>
</tr>
<tr class="ltx_tr" id="A2.T11.1.13">
<td class="ltx_td ltx_align_left ltx_border_r" id="A2.T11.1.13.1">CoT</td>
<td class="ltx_td ltx_align_center" id="A2.T11.1.13.2">0.829</td>
<td class="ltx_td ltx_align_center" id="A2.T11.1.13.3">0.821</td>
<td class="ltx_td ltx_align_center" id="A2.T11.1.13.4">0.839</td>
<td class="ltx_td ltx_align_center" id="A2.T11.1.13.5">0.850</td>
<td class="ltx_td ltx_align_center" id="A2.T11.1.13.6">0.828</td>
</tr>
<tr class="ltx_tr" id="A2.T11.1.14">
<td class="ltx_td ltx_align_left ltx_border_r" id="A2.T11.1.14.1">2-Shot CoT</td>
<td class="ltx_td ltx_align_center" id="A2.T11.1.14.2">0.870</td>
<td class="ltx_td ltx_align_center" id="A2.T11.1.14.3">0.866</td>
<td class="ltx_td ltx_align_center" id="A2.T11.1.14.4">0.875</td>
<td class="ltx_td ltx_align_center" id="A2.T11.1.14.5">0.877</td>
<td class="ltx_td ltx_align_center" id="A2.T11.1.14.6">0.862</td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 11: </span>Benchmark Results Measured by BERTScore.</figcaption>
</figure>
<figure class="ltx_table" id="A2.T12">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="A2.T12.1">
<tr class="ltx_tr" id="A2.T12.1.1">
<td class="ltx_td ltx_align_left" id="A2.T12.1.1.1">Model</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A2.T12.1.1.2">Prompt</td>
<td class="ltx_td ltx_align_center" colspan="4" id="A2.T12.1.1.3">Aspect Prediction</td>
<td class="ltx_td ltx_align_center" id="A2.T12.1.1.4">Title Prediction</td>
</tr>
<tr class="ltx_tr" id="A2.T12.1.2">
<td class="ltx_td" id="A2.T12.1.2.1"></td>
<td class="ltx_td ltx_border_r" id="A2.T12.1.2.2"></td>
<td class="ltx_td ltx_align_center" id="A2.T12.1.2.3">Idea</td>
<td class="ltx_td ltx_align_center" id="A2.T12.1.2.4">Method</td>
<td class="ltx_td ltx_align_center" id="A2.T12.1.2.5">Outcome</td>
<td class="ltx_td ltx_align_center" id="A2.T12.1.2.6">Future</td>
<td class="ltx_td ltx_align_center" id="A2.T12.1.2.7">Title</td>
</tr>
<tr class="ltx_tr" id="A2.T12.1.3">
<td class="ltx_td ltx_align_left ltx_border_t" id="A2.T12.1.3.1" rowspan="4"><span class="ltx_text" id="A2.T12.1.3.1.1">GPT-3.5</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="A2.T12.1.3.2">0-Shot</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T12.1.3.3">0.014</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T12.1.3.4">0.017</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T12.1.3.5">0.032</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T12.1.3.6">0.027</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T12.1.3.7">0.068</td>
</tr>
<tr class="ltx_tr" id="A2.T12.1.4">
<td class="ltx_td ltx_align_left ltx_border_r" id="A2.T12.1.4.1">2-Shot</td>
<td class="ltx_td ltx_align_center" id="A2.T12.1.4.2">0.034</td>
<td class="ltx_td ltx_align_center" id="A2.T12.1.4.3"><span class="ltx_text ltx_font_bold" id="A2.T12.1.4.3.1">0.029</span></td>
<td class="ltx_td ltx_align_center" id="A2.T12.1.4.4">0.042</td>
<td class="ltx_td ltx_align_center" id="A2.T12.1.4.5">0.033</td>
<td class="ltx_td ltx_align_center" id="A2.T12.1.4.6"><span class="ltx_text ltx_font_bold" id="A2.T12.1.4.6.1">0.101</span></td>
</tr>
<tr class="ltx_tr" id="A2.T12.1.5">
<td class="ltx_td ltx_align_left ltx_border_r" id="A2.T12.1.5.1">CoT</td>
<td class="ltx_td ltx_align_center" id="A2.T12.1.5.2">0.015</td>
<td class="ltx_td ltx_align_center" id="A2.T12.1.5.3">0.018</td>
<td class="ltx_td ltx_align_center" id="A2.T12.1.5.4">0.020</td>
<td class="ltx_td ltx_align_center" id="A2.T12.1.5.5">0.023</td>
<td class="ltx_td ltx_align_center" id="A2.T12.1.5.6">0.050</td>
</tr>
<tr class="ltx_tr" id="A2.T12.1.6">
<td class="ltx_td ltx_align_left ltx_border_r" id="A2.T12.1.6.1">2-Shot CoT</td>
<td class="ltx_td ltx_align_center" id="A2.T12.1.6.2">0.026</td>
<td class="ltx_td ltx_align_center" id="A2.T12.1.6.3">0.025</td>
<td class="ltx_td ltx_align_center" id="A2.T12.1.6.4">0.031</td>
<td class="ltx_td ltx_align_center" id="A2.T12.1.6.5">0.027</td>
<td class="ltx_td ltx_align_center" id="A2.T12.1.6.6">0.079</td>
</tr>
<tr class="ltx_tr" id="A2.T12.1.7">
<td class="ltx_td ltx_align_left ltx_border_t" id="A2.T12.1.7.1" rowspan="4"><span class="ltx_text" id="A2.T12.1.7.1.1">GPT-4</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="A2.T12.1.7.2">0-Shot</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T12.1.7.3">0.008</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T12.1.7.4">0.006</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T12.1.7.5">0.012</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T12.1.7.6">0.009</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T12.1.7.7">0.049</td>
</tr>
<tr class="ltx_tr" id="A2.T12.1.8">
<td class="ltx_td ltx_align_left ltx_border_r" id="A2.T12.1.8.1">2-Shot</td>
<td class="ltx_td ltx_align_center" id="A2.T12.1.8.2">0.028</td>
<td class="ltx_td ltx_align_center" id="A2.T12.1.8.3">0.008</td>
<td class="ltx_td ltx_align_center" id="A2.T12.1.8.4">0.050</td>
<td class="ltx_td ltx_align_center" id="A2.T12.1.8.5">0.017</td>
<td class="ltx_td ltx_align_center" id="A2.T12.1.8.6">0.081</td>
</tr>
<tr class="ltx_tr" id="A2.T12.1.9">
<td class="ltx_td ltx_align_left ltx_border_r" id="A2.T12.1.9.1">CoT</td>
<td class="ltx_td ltx_align_center" id="A2.T12.1.9.2">0.010</td>
<td class="ltx_td ltx_align_center" id="A2.T12.1.9.3">0.007</td>
<td class="ltx_td ltx_align_center" id="A2.T12.1.9.4">0.021</td>
<td class="ltx_td ltx_align_center" id="A2.T12.1.9.5">0.013</td>
<td class="ltx_td ltx_align_center" id="A2.T12.1.9.6">0.052</td>
</tr>
<tr class="ltx_tr" id="A2.T12.1.10">
<td class="ltx_td ltx_align_left ltx_border_r" id="A2.T12.1.10.1">2-Shot CoT</td>
<td class="ltx_td ltx_align_center" id="A2.T12.1.10.2">0.025</td>
<td class="ltx_td ltx_align_center" id="A2.T12.1.10.3">0.019</td>
<td class="ltx_td ltx_align_center" id="A2.T12.1.10.4">0.041</td>
<td class="ltx_td ltx_align_center" id="A2.T12.1.10.5">0.016</td>
<td class="ltx_td ltx_align_center" id="A2.T12.1.10.6">0.064</td>
</tr>
<tr class="ltx_tr" id="A2.T12.1.11">
<td class="ltx_td ltx_align_left ltx_border_t" id="A2.T12.1.11.1" rowspan="4"><span class="ltx_text" id="A2.T12.1.11.1.1">Mistral 8x7B</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="A2.T12.1.11.2">0-Shot</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T12.1.11.3">0.014</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T12.1.11.4">0.014</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T12.1.11.5">0.027</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T12.1.11.6">0.020</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T12.1.11.7">0.020</td>
</tr>
<tr class="ltx_tr" id="A2.T12.1.12">
<td class="ltx_td ltx_align_left ltx_border_r" id="A2.T12.1.12.1">2-Shot</td>
<td class="ltx_td ltx_align_center" id="A2.T12.1.12.2">0.036</td>
<td class="ltx_td ltx_align_center" id="A2.T12.1.12.3">0.023</td>
<td class="ltx_td ltx_align_center" id="A2.T12.1.12.4">0.044</td>
<td class="ltx_td ltx_align_center" id="A2.T12.1.12.5">0.033</td>
<td class="ltx_td ltx_align_center" id="A2.T12.1.12.6">0.048</td>
</tr>
<tr class="ltx_tr" id="A2.T12.1.13">
<td class="ltx_td ltx_align_left ltx_border_r" id="A2.T12.1.13.1">CoT</td>
<td class="ltx_td ltx_align_center" id="A2.T12.1.13.2">0.014</td>
<td class="ltx_td ltx_align_center" id="A2.T12.1.13.3">0.014</td>
<td class="ltx_td ltx_align_center" id="A2.T12.1.13.4">0.023</td>
<td class="ltx_td ltx_align_center" id="A2.T12.1.13.5">0.020</td>
<td class="ltx_td ltx_align_center" id="A2.T12.1.13.6">0.011</td>
</tr>
<tr class="ltx_tr" id="A2.T12.1.14">
<td class="ltx_td ltx_align_left ltx_border_r" id="A2.T12.1.14.1">2-Shot CoT</td>
<td class="ltx_td ltx_align_center" id="A2.T12.1.14.2"><span class="ltx_text ltx_font_bold" id="A2.T12.1.14.2.1">0.039</span></td>
<td class="ltx_td ltx_align_center" id="A2.T12.1.14.3">0.026</td>
<td class="ltx_td ltx_align_center" id="A2.T12.1.14.4"><span class="ltx_text ltx_font_bold" id="A2.T12.1.14.4.1">0.056</span></td>
<td class="ltx_td ltx_align_center" id="A2.T12.1.14.5"><span class="ltx_text ltx_font_bold" id="A2.T12.1.14.5.1">0.035</span></td>
<td class="ltx_td ltx_align_center" id="A2.T12.1.14.6">0.060</td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 12: </span>Benchmark Results Measured by BLEU.</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="A2.SS9">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.9 </span>URL for Dataset</h3>
<div class="ltx_para ltx_noindent" id="A2.SS9.p1">
<ul class="ltx_itemize" id="A2.I7">
<li class="ltx_item" id="A2.I7.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A2.I7.i1.p1">
<p class="ltx_p" id="A2.I7.i1.p1.1">GitHub Repo (for reproducible results): <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/xingjian-zhang/massw" title="">https://github.com/xingjian-zhang/massw</a></p>
</div>
</li>
<li class="ltx_item" id="A2.I7.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A2.I7.i2.p1">
<p class="ltx_p" id="A2.I7.i2.p1.1">Download link for dataset: The download script is provided in the GitHub Repo above. Readers can also download through these links manually.</p>
</div>
</li>
</ul>
<p class="ltx_p" id="A2.SS9.p1.1"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.dropbox.com/scl/fi/ykkrpf269fikuchy429l7/massw_v1.tsv?rlkey=mssrbgz3k8adij1moxqtj34ie&amp;dl=1" title="">https://www.dropbox.com/scl/fi/ykkrpf269fikuchy429l7/massw_v1.tsv?rlkey=mssrbgz3k8adij1moxqtj34ie&amp;dl=1</a>
<span class="ltx_item" id="A2.I7.i2.I1.i2" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item"><span class="ltx_text ltx_font_bold" id="A2.I7.i2.I1.i2.1.1.1">–</span></span>
<span class="ltx_para ltx_noindent" id="A2.I7.i2.I1.i2.p1">
<span class="ltx_p" id="A2.I7.i2.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="A2.I7.i2.I1.i2.p1.1.1">MASSW Metadata</span>:
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.dropbox.com/scl/fi/r2jlil9lj0ypo2fpl3fxa/massw_metadata_v1.jsonl?rlkey=ohnriak63x4ekyli25naajp0q&amp;dl=1" title="">https://www.dropbox.com/scl/fi/r2jlil9lj0ypo2fpl3fxa/massw_metadata_v1.jsonl?rlkey=ohnriak63x4ekyli25naajp0q&amp;dl=1</a></span>
</span></span></p>
</div>
</section>
<section class="ltx_subsection" id="A2.SS10">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.10 </span>Dataset Documentation and Indended Uses</h3>
<div class="ltx_para ltx_noindent" id="A2.SS10.p1">
<p class="ltx_p" id="A2.SS10.p1.1">We use the Data Cards recommended by the submission guideline.
Please see <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://xingjian-zhang.github.io/massw/" title="">https://xingjian-zhang.github.io/massw/</a>.</p>
</div>
</section>
<section class="ltx_subsection" id="A2.SS11">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.11 </span>Author Statement</h3>
<div class="ltx_para ltx_noindent" id="A2.SS11.p1">
<p class="ltx_p" id="A2.SS11.p1.1">All the authors bear all responsibility in case of violation of rights, etc., and we confirm the data license.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
</section>
</section>
</div>
</div>
</figure>
</section>
</section>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Mon Jun 10 15:20:38 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
