<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2409.11585] Advances in Appfl: A Comprehensive and Extensible Federated Learning Framework</title><meta property="og:description" content="Federated learning (FL) is a distributed machine learning paradigm enabling collaborative model training while preserving data privacy. In today’s landscape, where most data is proprietary, confidential, and distribute…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Advances in Appfl: A Comprehensive and Extensible Federated Learning Framework">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Advances in Appfl: A Comprehensive and Extensible Federated Learning Framework">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2409.11585">

<!--Generated on Sat Oct  5 21:04:24 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content="
Federated Learning,  Distributed Computing,  Benchmarking,  Privacy Preservation,  Scheduling Algorithms
">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Advances in <span id="id1.id1" class="ltx_text ltx_font_smallcaps">Appfl</span>: A Comprehensive and Extensible Federated Learning Framework
<br class="ltx_break">
</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Zilinghan Li1,
Shilan He2,
Ze Yang2,
Minseok Ryu3,
Kibaek Kim1,
Ravi Madduri1
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">
1Argonne National Laboratory
2University of Illinois at Urbana-Champaign
3Arizona State University

</span>
<span class="ltx_contact ltx_role_affiliation">
{zilinghan.li, kimk, madduri}@anl.gov, {shilanh2, zeyang2}@illinois.edu, minseok.ryu@asu.edu

</span></span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id2.id1" class="ltx_p">Federated learning (FL) is a distributed machine learning paradigm enabling collaborative model training while preserving data privacy. In today’s landscape, where most data is proprietary, confidential, and distributed, FL has become a promising approach to leverage such data effectively, particularly in sensitive domains such as medicine and the electric grid. Heterogeneity and security are the key challenges in FL, however; most existing FL frameworks either fail to address these challenges adequately or lack the flexibility to incorporate new solutions. To this end, we present the recent advances in developing <span id="id2.id1.1" class="ltx_text ltx_font_smallcaps">Appfl</span>, an extensible framework and benchmarking suite for federated learning, which offers comprehensive solutions for heterogeneity and security concerns, as well as user-friendly interfaces for integrating new algorithms or adapting to new applications. We demonstrate the capabilities of <span id="id2.id1.2" class="ltx_text ltx_font_smallcaps">Appfl</span> through extensive experiments evaluating various aspects of FL, including communication efficiency, privacy preservation, computational performance, and resource utilization. We further highlight the extensibility of <span id="id2.id1.3" class="ltx_text ltx_font_smallcaps">Appfl</span> through case studies in vertical, hierarchical, and decentralized FL. <span id="id2.id1.4" class="ltx_text ltx_font_smallcaps">Appfl</span> is open-sourced at <a target="_blank" href="https://github.com/APPFL/APPFL" title="" class="ltx_ref ltx_href">https://github.com/APPFL/APPFL</a>.</p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Index Terms: </h6>
Federated Learning, Distributed Computing, Benchmarking, Privacy Preservation, Scheduling Algorithms

</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">I </span><span id="S1.1.1" class="ltx_text ltx_font_smallcaps">Introduction</span>
</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Availability of extensive training data is becoming increasingly crucial for developing more capable machine learning (ML) models, especially as these models continue to grow in size and complexity. Nonetheless, most of the data in today’s landscape is confidential and distributed across various data silos <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>. This distribution makes it difficult to collect the data for centralized model training, posing significant challenges in fully leveraging the existing data to train more powerful ML models. In this context, federated learning (FL), a distributed ML paradigm, offers a promising solution to utilize data from multiple data owners without direct data sharing <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>, <a href="#bib.bib3" title="" class="ltx_ref">3</a>, <a href="#bib.bib4" title="" class="ltx_ref">4</a>, <a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">In FL, multiple data owners, referred to as clients, collaborate under a central server to train a shared ML model by iterating the following two steps: (1) each client trains an ML model using its local dataset and submits the updated model to the server, and (2) the server aggregates these local models to update the global model and then sends it back to the clients for further local training. In this way, FL leverages data from multiple data sources to build a more powerful and robust model without requiring data centralization, thereby protecting data privacy. Consequently, FL has been widely adopted in domains such as medicine <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>, <a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>, finance <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>, <a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>, and electric grid <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>, where data privacy is paramount. Depending on the amount, capability, and availability of client devices, FL is broadly categorized into two types, cross-device FL and cross-silo FL <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>. In cross-device FL, numerous mobile or IoT devices with limited computing power and intermittent availability collaboratively train relatively small models such as keyboard suggestion and hot word detection models <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>, <a href="#bib.bib13" title="" class="ltx_ref">13</a>, <a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>. In contrast, cross-silo FL involves fewer but more reliable and powerful clients, typically represented by large data silos and institutions, to develop more complex ML models with extensive parameters.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">While FL can be conceptually simplified to traditional machine learning with an additional global aggregation operation, its distributed nature introduces significant challenges in terms of heterogeneity and security when adopted for real-world applications. Data heterogeneity, stemming from the unbalanced, and non-independent and identically distributed (non-IID) nature of client local datasets, can lead to varied local training objectives across clients and potentially degrade the performance of the global model <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>. Additionally, the heterogeneity in computation and communication, caused by diverse computing capabilities and network connectivity of client devices, can severely impact the efficiency of FL training <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>, <a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>. This is particularly problematic in synchronous FL algorithms, where the server has to wait for all clients to submit their local models before global aggregation. With regard to security, FL is vulnerable to various attacks. Untrusted clients might maliciously attack FL experiments by submitting corrupted local models, and there is also a risk that training data could be reconstructed from the model updates sent by clients, thereby compromising data privacy <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>, <a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">Most existing FL frameworks, such as <span id="S1.p4.1.1" class="ltx_text ltx_font_smallcaps">Flower</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>, <span id="S1.p4.1.2" class="ltx_text ltx_font_smallcaps">FedML</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>, and <span id="S1.p4.1.3" class="ltx_text ltx_font_smallcaps">FedScale</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>, do not adequately address the full spectrum of challenges inherent in FL. For example, some frameworks do not support asynchronous aggregation that could improve training efficiency, lack implementations of robust authentication and privacy preservation algorithms, or fail to offer user-friendly interfaces for developers to easily integrate new solutions or algorithms.
To bridge these gaps, we developed the Advanced Privacy-Preserving Federated Learning (<span id="S1.p4.1.4" class="ltx_text ltx_font_smallcaps">Appfl</span>) framework, a comprehensive and extensible FL framework that builds on and improves the work presented in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>. <span id="S1.p4.1.5" class="ltx_text ltx_font_smallcaps">Appfl</span> supports both single-node and multi-node simulations, as well as distributed deployment of FL experiments. It features advanced aggregation strategies to address data heterogeneity <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite> and various asynchronous aggregation strategies to boost training efficiency in environments with computation heterogeneity <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>. Additionally, <span id="S1.p4.1.6" class="ltx_text ltx_font_smallcaps">Appfl</span> incorporates versatile communication protocols <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>, data transfer methods <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>, and compression strategies to meet different communication requirements and enhance communication efficiency <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite>. It also includes robust authentication via Globus <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>, <a href="#bib.bib28" title="" class="ltx_ref">28</a>, <a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>, along with plugins for adding new authentication methods, and implements privacy preservation strategies to prevent the reconstruction of training data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite>. Moreover, <span id="S1.p4.1.7" class="ltx_text ltx_font_smallcaps">Appfl</span> is extensible; it follows a modular design that enables users and developers to seamlessly adapt the framework for different use cases and integrate custom algorithmic solutions to tackle various FL challenges.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">The contributions of this work are outlined as follows:</p>
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">Advance <span id="S1.I1.i1.p1.1.1" class="ltx_text ltx_font_smallcaps">Appfl</span>, an open-source FL framework for both FL users and developers that provides established solutions to common FL challenges for FL users and offers flexible and modular interfaces that facilitate easy integration of new algorithmic solutions for FL developers</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">Conduct comprehensive evaluations of various aspects of FL using <span id="S1.I1.i2.p1.1.1" class="ltx_text ltx_font_smallcaps">Appfl</span>, including the efficiency of the versatile communication protocols, data transfer methods, and compression strategies, as well as the performance of privacy preservation strategies and training effectiveness of different FL aggregation algorithms</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p">Provide case studies in vertical, hierarchical, decentralized FL to highlight the extensibility and adaptability of the <span id="S1.I1.i3.p1.1.1" class="ltx_text ltx_font_smallcaps">Appfl</span> framework in diverse FL scenarios</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">II </span><span id="S2.1.1" class="ltx_text ltx_font_smallcaps">Background and Related Work</span>
</h2>

<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS1.5.1.1" class="ltx_text">II-A</span> </span><span id="S2.SS1.6.2" class="ltx_text ltx_font_italic">Heterogeneity in Federated Learning</span>
</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">Heterogeneity is one of the significant challenges in FL due to its distributed nature across multiple clients <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>, <a href="#bib.bib31" title="" class="ltx_ref">31</a>, <a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite>. This heterogeneity can be categorized into three primary types: data heterogeneity, computation heterogeneity, and communication heterogeneity.</p>
</div>
<div id="S2.SS1.p2" class="ltx_para">
<p id="S2.SS1.p2.1" class="ltx_p"><span id="S2.SS1.p2.1.1" class="ltx_text ltx_font_italic">Data heterogeneity</span> arises from the fact that client datasets are often unbalanced and non-IID, meaning they may not be representative of the overall population distribution. This discrepancy leads to varying local training objectives among clients, causing their locally trained models to diverge from one another, a phenomenon known as client drift <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref">33</a>]</cite>. As a result, simple weighted averaging of local models, as in the <span id="S2.SS1.p2.1.2" class="ltx_text ltx_font_typewriter">FedAvg</span> strategy <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>, may degrade the performance of the global model as data heterogeneity increases <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>. Several solutions have been proposed to address this issue on both the server and client sides. For instance, server-side optimizations such as <span id="S2.SS1.p2.1.3" class="ltx_text ltx_font_typewriter">FedAvgM</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>, <span id="S2.SS1.p2.1.4" class="ltx_text ltx_font_typewriter">FedAdam</span>, <span id="S2.SS1.p2.1.5" class="ltx_text ltx_font_typewriter">FedAdagrad</span>, and <span id="S2.SS1.p2.1.6" class="ltx_text ltx_font_typewriter">FedYogi</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite> have been introduced to enhance FL performance on non-IID data. Client-side approaches such as <span id="S2.SS1.p2.1.7" class="ltx_text ltx_font_typewriter">FedProx</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite> and <span id="S2.SS1.p2.1.8" class="ltx_text ltx_font_typewriter">SCAFFOLD</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref">33</a>]</cite> incorporate correction terms into the client’s local objective function to reduce excessive drift between local and global models.</p>
</div>
<div id="S2.SS1.p3" class="ltx_para">
<p id="S2.SS1.p3.1" class="ltx_p"><span id="S2.SS1.p3.1.1" class="ltx_text ltx_font_italic">Computation heterogeneity</span> occurs when the computing devices of FL clients have varying computing power, resulting in large variants in the local training times <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite>. This variance poses challenges for synchronous FL strategies, where the server must wait for all clients to submit their local models before proceeding with global aggregation. Such delays from slower clients can reduce training efficiency and lead to underutilization of computing resources. In order to address this issue, various asynchronous aggregation strategies have been proposed. These strategies, including <span id="S2.SS1.p3.1.2" class="ltx_text ltx_font_typewriter">FedAsync</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite>, <span id="S2.SS1.p3.1.3" class="ltx_text ltx_font_typewriter">FedASO</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite>, <span id="S2.SS1.p3.1.4" class="ltx_text ltx_font_typewriter">FedBuff</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib38" title="" class="ltx_ref">38</a>]</cite>, <span id="S2.SS1.p3.1.5" class="ltx_text ltx_font_typewriter">AREA</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref">39</a>]</cite>, and <span id="S2.SS1.p3.1.6" class="ltx_text ltx_font_typewriter">FedCompass</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>, update the global model immediately upon receiving models from one or a few clients. These methods are particularly beneficial in environments with heterogeneous computing capabilities because they minimize client idle time and enhance resource utilization. Other approaches include disregarding contributions from straggler clients <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite> or explicitly selecting clients for local training based on their computing capabilities <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib41" title="" class="ltx_ref">41</a>, <a href="#bib.bib42" title="" class="ltx_ref">42</a>, <a href="#bib.bib43" title="" class="ltx_ref">43</a>]</cite>. Nonetheless, these methods are best suited for cross-device FL, where only a subset of clients participates in each training round. They do not align well with cross-silo FL where there are only a few FL clients and ensuring the participation of every client is usually vital for maintaining the robustness of the global model.</p>
</div>
<div id="S2.SS1.p4" class="ltx_para">
<p id="S2.SS1.p4.1" class="ltx_p"><span id="S2.SS1.p4.1.1" class="ltx_text ltx_font_italic">Communication heterogeneity</span> is originally rooted in the intermittent availability of client devices due to the limited power and bandwidth in cross-device FL settings, which is less of an issue in cross-silo FL. However, as foundation models increasingly dominate various domains and applications, the interest in using FL to train or fine-tune these models has surged. This surge has led to a substantial increase in communication costs, which become a critical factor affecting the efficiency of FL training <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib44" title="" class="ltx_ref">44</a>, <a href="#bib.bib45" title="" class="ltx_ref">45</a>, <a href="#bib.bib46" title="" class="ltx_ref">46</a>]</cite>. Consequently, improving the efficiency and robustness of transferring large model parameters has become critically important as well<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib47" title="" class="ltx_ref">47</a>]</cite>. To address this situation, some client selection methods have been proposed to mitigate communication issues in cross-device FL by strategically selecting clients based on their availability, data quality, and performance <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib48" title="" class="ltx_ref">48</a>, <a href="#bib.bib49" title="" class="ltx_ref">49</a>, <a href="#bib.bib50" title="" class="ltx_ref">50</a>, <a href="#bib.bib51" title="" class="ltx_ref">51</a>]</cite>. Other approaches focus on generic FL settings by applying compression techniques to large model parameters, thereby reducing the overall communication workload <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib52" title="" class="ltx_ref">52</a>, <a href="#bib.bib53" title="" class="ltx_ref">53</a>, <a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite>.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS2.5.1.1" class="ltx_text">II-B</span> </span><span id="S2.SS2.6.2" class="ltx_text ltx_font_italic">Attacks and Security Concerns in Federated Learning</span>
</h3>

<figure id="S2.T1" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S2.T1.2.1.1" class="ltx_text" style="font-size:90%;">TABLE I</span>: </span><span id="S2.T1.3.2" class="ltx_text" style="font-size:90%;">Comparison of popular open-source federated learning frameworks.</span></figcaption>
<div id="S2.T1.4" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:138.7pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-149.0pt,47.7pt) scale(0.592623370019427,0.592623370019427) ;">
<table id="S2.T1.4.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S2.T1.4.1.1.1" class="ltx_tr">
<th id="S2.T1.4.1.1.1.1" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_th_row ltx_border_tt" style="padding-left:2.7pt;padding-right:2.7pt;">Framework</th>
<th id="S2.T1.4.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:2.7pt;padding-right:2.7pt;">Data Hetero.</th>
<th id="S2.T1.4.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:2.7pt;padding-right:2.7pt;">Sync. FL</th>
<th id="S2.T1.4.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:2.7pt;padding-right:2.7pt;">Async. FL</th>
<th id="S2.T1.4.1.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:2.7pt;padding-right:2.7pt;">Compression</th>
<th id="S2.T1.4.1.1.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:2.7pt;padding-right:2.7pt;">Versatile Comm.</th>
<th id="S2.T1.4.1.1.1.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:2.7pt;padding-right:2.7pt;">Privacy</th>
<th id="S2.T1.4.1.1.1.8" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:2.7pt;padding-right:2.7pt;">Auth.</th>
<th id="S2.T1.4.1.1.1.9" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:2.7pt;padding-right:2.7pt;">Real Deployment</th>
<th id="S2.T1.4.1.1.1.10" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:2.7pt;padding-right:2.7pt;">FL Variants</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S2.T1.4.1.2.1" class="ltx_tr">
<th id="S2.T1.4.1.2.1.1" class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_t" style="padding-left:2.7pt;padding-right:2.7pt;">
<span id="S2.T1.4.1.2.1.1.1" class="ltx_text ltx_font_smallcaps">LEAF</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib54" title="" class="ltx_ref">54</a>]</cite>
</th>
<td id="S2.T1.4.1.2.1.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S2.T1.4.1.2.1.2.1" class="ltx_text" style="color:#E64D4D;">✗</span></td>
<td id="S2.T1.4.1.2.1.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S2.T1.4.1.2.1.3.1" class="ltx_text" style="color:#4DB34D;">✓</span></td>
<td id="S2.T1.4.1.2.1.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S2.T1.4.1.2.1.4.1" class="ltx_text" style="color:#E64D4D;">✗</span></td>
<td id="S2.T1.4.1.2.1.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S2.T1.4.1.2.1.5.1" class="ltx_text" style="color:#E64D4D;">✗</span></td>
<td id="S2.T1.4.1.2.1.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S2.T1.4.1.2.1.6.1" class="ltx_text" style="color:#E64D4D;">✗</span></td>
<td id="S2.T1.4.1.2.1.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S2.T1.4.1.2.1.7.1" class="ltx_text" style="color:#E64D4D;">✗</span></td>
<td id="S2.T1.4.1.2.1.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S2.T1.4.1.2.1.8.1" class="ltx_text" style="color:#E64D4D;">✗</span></td>
<td id="S2.T1.4.1.2.1.9" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S2.T1.4.1.2.1.9.1" class="ltx_text" style="color:#E64D4D;">✗</span></td>
<td id="S2.T1.4.1.2.1.10" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S2.T1.4.1.2.1.10.1" class="ltx_text" style="color:#E64D4D;">✗</span></td>
</tr>
<tr id="S2.T1.4.1.3.2" class="ltx_tr">
<th id="S2.T1.4.1.3.2.1" class="ltx_td ltx_align_right ltx_th ltx_th_row" style="padding-left:2.7pt;padding-right:2.7pt;">
<span id="S2.T1.4.1.3.2.1.1" class="ltx_text ltx_font_smallcaps">TFF</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite>
</th>
<td id="S2.T1.4.1.3.2.2" class="ltx_td ltx_align_center" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S2.T1.4.1.3.2.2.1" class="ltx_text" style="color:#4DB34D;">✓</span></td>
<td id="S2.T1.4.1.3.2.3" class="ltx_td ltx_align_center" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S2.T1.4.1.3.2.3.1" class="ltx_text" style="color:#4DB34D;">✓</span></td>
<td id="S2.T1.4.1.3.2.4" class="ltx_td ltx_align_center" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S2.T1.4.1.3.2.4.1" class="ltx_text" style="color:#E64D4D;">✗</span></td>
<td id="S2.T1.4.1.3.2.5" class="ltx_td ltx_align_center" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S2.T1.4.1.3.2.5.1" class="ltx_text" style="color:#E64D4D;">✗</span></td>
<td id="S2.T1.4.1.3.2.6" class="ltx_td ltx_align_center" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S2.T1.4.1.3.2.6.1" class="ltx_text" style="color:#E64D4D;">✗</span></td>
<td id="S2.T1.4.1.3.2.7" class="ltx_td ltx_align_center" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S2.T1.4.1.3.2.7.1" class="ltx_text" style="color:#4DB34D;">✓</span></td>
<td id="S2.T1.4.1.3.2.8" class="ltx_td ltx_align_center" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S2.T1.4.1.3.2.8.1" class="ltx_text" style="color:#E64D4D;">✗</span></td>
<td id="S2.T1.4.1.3.2.9" class="ltx_td ltx_align_center" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S2.T1.4.1.3.2.9.1" class="ltx_text" style="color:#E64D4D;">✗</span></td>
<td id="S2.T1.4.1.3.2.10" class="ltx_td ltx_align_center" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S2.T1.4.1.3.2.10.1" class="ltx_text" style="color:#E64D4D;">✗</span></td>
</tr>
<tr id="S2.T1.4.1.4.3" class="ltx_tr">
<th id="S2.T1.4.1.4.3.1" class="ltx_td ltx_align_right ltx_th ltx_th_row" style="padding-left:2.7pt;padding-right:2.7pt;">
<span id="S2.T1.4.1.4.3.1.1" class="ltx_text ltx_font_smallcaps">Appfl-v0</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>
</th>
<td id="S2.T1.4.1.4.3.2" class="ltx_td ltx_align_center" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S2.T1.4.1.4.3.2.1" class="ltx_text" style="color:#4DB34D;">✓</span></td>
<td id="S2.T1.4.1.4.3.3" class="ltx_td ltx_align_center" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S2.T1.4.1.4.3.3.1" class="ltx_text" style="color:#4DB34D;">✓</span></td>
<td id="S2.T1.4.1.4.3.4" class="ltx_td ltx_align_center" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S2.T1.4.1.4.3.4.1" class="ltx_text" style="color:#E64D4D;">✗</span></td>
<td id="S2.T1.4.1.4.3.5" class="ltx_td ltx_align_center" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S2.T1.4.1.4.3.5.1" class="ltx_text" style="color:#E64D4D;">✗</span></td>
<td id="S2.T1.4.1.4.3.6" class="ltx_td ltx_align_center" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S2.T1.4.1.4.3.6.1" class="ltx_text" style="color:#E64D4D;">✗</span></td>
<td id="S2.T1.4.1.4.3.7" class="ltx_td ltx_align_center" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S2.T1.4.1.4.3.7.1" class="ltx_text" style="color:#4DB34D;">✓</span></td>
<td id="S2.T1.4.1.4.3.8" class="ltx_td ltx_align_center" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S2.T1.4.1.4.3.8.1" class="ltx_text" style="color:#E64D4D;">✗</span></td>
<td id="S2.T1.4.1.4.3.9" class="ltx_td ltx_align_center" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S2.T1.4.1.4.3.9.1" class="ltx_text" style="color:#4DB34D;">✓</span></td>
<td id="S2.T1.4.1.4.3.10" class="ltx_td ltx_align_center" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S2.T1.4.1.4.3.10.1" class="ltx_text" style="color:#E64D4D;">✗</span></td>
</tr>
<tr id="S2.T1.4.1.5.4" class="ltx_tr">
<th id="S2.T1.4.1.5.4.1" class="ltx_td ltx_align_right ltx_th ltx_th_row" style="padding-left:2.7pt;padding-right:2.7pt;">
<span id="S2.T1.4.1.5.4.1.1" class="ltx_text ltx_font_smallcaps">FederatedScope</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib55" title="" class="ltx_ref">55</a>]</cite>
</th>
<td id="S2.T1.4.1.5.4.2" class="ltx_td ltx_align_center" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S2.T1.4.1.5.4.2.1" class="ltx_text" style="color:#4DB34D;">✓</span></td>
<td id="S2.T1.4.1.5.4.3" class="ltx_td ltx_align_center" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S2.T1.4.1.5.4.3.1" class="ltx_text" style="color:#4DB34D;">✓</span></td>
<td id="S2.T1.4.1.5.4.4" class="ltx_td ltx_align_center" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S2.T1.4.1.5.4.4.1" class="ltx_text" style="color:#E64D4D;">✗</span></td>
<td id="S2.T1.4.1.5.4.5" class="ltx_td ltx_align_center" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S2.T1.4.1.5.4.5.1" class="ltx_text" style="color:#E64D4D;">✗</span></td>
<td id="S2.T1.4.1.5.4.6" class="ltx_td ltx_align_center" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S2.T1.4.1.5.4.6.1" class="ltx_text" style="color:#E64D4D;">✗</span></td>
<td id="S2.T1.4.1.5.4.7" class="ltx_td ltx_align_center" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S2.T1.4.1.5.4.7.1" class="ltx_text" style="color:#4DB34D;">✓</span></td>
<td id="S2.T1.4.1.5.4.8" class="ltx_td ltx_align_center" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S2.T1.4.1.5.4.8.1" class="ltx_text" style="color:#E64D4D;">✗</span></td>
<td id="S2.T1.4.1.5.4.9" class="ltx_td ltx_align_center" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S2.T1.4.1.5.4.9.1" class="ltx_text" style="color:#4DB34D;">✓</span></td>
<td id="S2.T1.4.1.5.4.10" class="ltx_td ltx_align_center" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S2.T1.4.1.5.4.10.1" class="ltx_text ltx_font_bold ltx_font_italic" style="color:#4DB34D;">VFL</span></td>
</tr>
<tr id="S2.T1.4.1.6.5" class="ltx_tr">
<th id="S2.T1.4.1.6.5.1" class="ltx_td ltx_align_right ltx_th ltx_th_row" style="padding-left:2.7pt;padding-right:2.7pt;">
<span id="S2.T1.4.1.6.5.1.1" class="ltx_text ltx_font_smallcaps">FLARE</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib56" title="" class="ltx_ref">56</a>]</cite>
</th>
<td id="S2.T1.4.1.6.5.2" class="ltx_td ltx_align_center" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S2.T1.4.1.6.5.2.1" class="ltx_text" style="color:#4DB34D;">✓</span></td>
<td id="S2.T1.4.1.6.5.3" class="ltx_td ltx_align_center" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S2.T1.4.1.6.5.3.1" class="ltx_text" style="color:#4DB34D;">✓</span></td>
<td id="S2.T1.4.1.6.5.4" class="ltx_td ltx_align_center" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S2.T1.4.1.6.5.4.1" class="ltx_text" style="color:#E64D4D;">✗</span></td>
<td id="S2.T1.4.1.6.5.5" class="ltx_td ltx_align_center" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S2.T1.4.1.6.5.5.1" class="ltx_text" style="color:#E64D4D;">✗</span></td>
<td id="S2.T1.4.1.6.5.6" class="ltx_td ltx_align_center" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S2.T1.4.1.6.5.6.1" class="ltx_text" style="color:#E64D4D;">✗</span></td>
<td id="S2.T1.4.1.6.5.7" class="ltx_td ltx_align_center" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S2.T1.4.1.6.5.7.1" class="ltx_text" style="color:#4DB34D;">✓</span></td>
<td id="S2.T1.4.1.6.5.8" class="ltx_td ltx_align_center" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S2.T1.4.1.6.5.8.1" class="ltx_text" style="color:#4DB34D;">✓</span></td>
<td id="S2.T1.4.1.6.5.9" class="ltx_td ltx_align_center" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S2.T1.4.1.6.5.9.1" class="ltx_text" style="color:#4DB34D;">✓</span></td>
<td id="S2.T1.4.1.6.5.10" class="ltx_td ltx_align_center" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S2.T1.4.1.6.5.10.1" class="ltx_text ltx_font_bold ltx_font_italic" style="color:#4DB34D;">VFL</span></td>
</tr>
<tr id="S2.T1.4.1.7.6" class="ltx_tr">
<th id="S2.T1.4.1.7.6.1" class="ltx_td ltx_align_right ltx_th ltx_th_row" style="padding-left:2.7pt;padding-right:2.7pt;">
<span id="S2.T1.4.1.7.6.1.1" class="ltx_text ltx_font_smallcaps">OpenFL</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib57" title="" class="ltx_ref">57</a>]</cite>
</th>
<td id="S2.T1.4.1.7.6.2" class="ltx_td ltx_align_center" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S2.T1.4.1.7.6.2.1" class="ltx_text" style="color:#4DB34D;">✓</span></td>
<td id="S2.T1.4.1.7.6.3" class="ltx_td ltx_align_center" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S2.T1.4.1.7.6.3.1" class="ltx_text" style="color:#4DB34D;">✓</span></td>
<td id="S2.T1.4.1.7.6.4" class="ltx_td ltx_align_center" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S2.T1.4.1.7.6.4.1" class="ltx_text" style="color:#E64D4D;">✗</span></td>
<td id="S2.T1.4.1.7.6.5" class="ltx_td ltx_align_center" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S2.T1.4.1.7.6.5.1" class="ltx_text" style="color:#4DB34D;">✓</span></td>
<td id="S2.T1.4.1.7.6.6" class="ltx_td ltx_align_center" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S2.T1.4.1.7.6.6.1" class="ltx_text" style="color:#E64D4D;">✗</span></td>
<td id="S2.T1.4.1.7.6.7" class="ltx_td ltx_align_center" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S2.T1.4.1.7.6.7.1" class="ltx_text" style="color:#4DB34D;">✓</span></td>
<td id="S2.T1.4.1.7.6.8" class="ltx_td ltx_align_center" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S2.T1.4.1.7.6.8.1" class="ltx_text" style="color:#4DB34D;">✓</span></td>
<td id="S2.T1.4.1.7.6.9" class="ltx_td ltx_align_center" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S2.T1.4.1.7.6.9.1" class="ltx_text" style="color:#4DB34D;">✓</span></td>
<td id="S2.T1.4.1.7.6.10" class="ltx_td ltx_align_center" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S2.T1.4.1.7.6.10.1" class="ltx_text ltx_font_bold ltx_font_italic" style="color:#4DB34D;">VFL</span></td>
</tr>
<tr id="S2.T1.4.1.8.7" class="ltx_tr">
<th id="S2.T1.4.1.8.7.1" class="ltx_td ltx_align_right ltx_th ltx_th_row" style="padding-left:2.7pt;padding-right:2.7pt;">
<span id="S2.T1.4.1.8.7.1.1" class="ltx_text ltx_font_smallcaps">FedScale</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>
</th>
<td id="S2.T1.4.1.8.7.2" class="ltx_td ltx_align_center" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S2.T1.4.1.8.7.2.1" class="ltx_text" style="color:#4DB34D;">✓</span></td>
<td id="S2.T1.4.1.8.7.3" class="ltx_td ltx_align_center" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S2.T1.4.1.8.7.3.1" class="ltx_text" style="color:#4DB34D;">✓</span></td>
<td id="S2.T1.4.1.8.7.4" class="ltx_td ltx_align_center" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S2.T1.4.1.8.7.4.1" class="ltx_text" style="color:#4DB34D;">✓</span></td>
<td id="S2.T1.4.1.8.7.5" class="ltx_td ltx_align_center" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S2.T1.4.1.8.7.5.1" class="ltx_text" style="color:#4DB34D;">✓</span></td>
<td id="S2.T1.4.1.8.7.6" class="ltx_td ltx_align_center" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S2.T1.4.1.8.7.6.1" class="ltx_text" style="color:#E64D4D;">✗</span></td>
<td id="S2.T1.4.1.8.7.7" class="ltx_td ltx_align_center" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S2.T1.4.1.8.7.7.1" class="ltx_text" style="color:#4DB34D;">✓</span></td>
<td id="S2.T1.4.1.8.7.8" class="ltx_td ltx_align_center" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S2.T1.4.1.8.7.8.1" class="ltx_text" style="color:#E64D4D;">✗</span></td>
<td id="S2.T1.4.1.8.7.9" class="ltx_td ltx_align_center" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S2.T1.4.1.8.7.9.1" class="ltx_text" style="color:#4DB34D;">✓</span></td>
<td id="S2.T1.4.1.8.7.10" class="ltx_td ltx_align_center" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S2.T1.4.1.8.7.10.1" class="ltx_text" style="color:#E64D4D;">✗</span></td>
</tr>
<tr id="S2.T1.4.1.9.8" class="ltx_tr">
<th id="S2.T1.4.1.9.8.1" class="ltx_td ltx_align_right ltx_th ltx_th_row" style="padding-left:2.7pt;padding-right:2.7pt;">
<span id="S2.T1.4.1.9.8.1.1" class="ltx_text ltx_font_smallcaps">FLGo</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib58" title="" class="ltx_ref">58</a>]</cite>
</th>
<td id="S2.T1.4.1.9.8.2" class="ltx_td ltx_align_center" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S2.T1.4.1.9.8.2.1" class="ltx_text" style="color:#4DB34D;">✓</span></td>
<td id="S2.T1.4.1.9.8.3" class="ltx_td ltx_align_center" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S2.T1.4.1.9.8.3.1" class="ltx_text" style="color:#4DB34D;">✓</span></td>
<td id="S2.T1.4.1.9.8.4" class="ltx_td ltx_align_center" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S2.T1.4.1.9.8.4.1" class="ltx_text" style="color:#4DB34D;">✓</span></td>
<td id="S2.T1.4.1.9.8.5" class="ltx_td ltx_align_center" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S2.T1.4.1.9.8.5.1" class="ltx_text" style="color:#E64D4D;">✗</span></td>
<td id="S2.T1.4.1.9.8.6" class="ltx_td ltx_align_center" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S2.T1.4.1.9.8.6.1" class="ltx_text" style="color:#E64D4D;">✗</span></td>
<td id="S2.T1.4.1.9.8.7" class="ltx_td ltx_align_center" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S2.T1.4.1.9.8.7.1" class="ltx_text" style="color:#E64D4D;">✗</span></td>
<td id="S2.T1.4.1.9.8.8" class="ltx_td ltx_align_center" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S2.T1.4.1.9.8.8.1" class="ltx_text" style="color:#E64D4D;">✗</span></td>
<td id="S2.T1.4.1.9.8.9" class="ltx_td ltx_align_center" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S2.T1.4.1.9.8.9.1" class="ltx_text" style="color:#4DB34D;">✓</span></td>
<td id="S2.T1.4.1.9.8.10" class="ltx_td ltx_align_center" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S2.T1.4.1.9.8.10.1" class="ltx_text ltx_font_bold ltx_font_italic" style="color:#4DB34D;">VFL</span></td>
</tr>
<tr id="S2.T1.4.1.10.9" class="ltx_tr">
<th id="S2.T1.4.1.10.9.1" class="ltx_td ltx_align_right ltx_th ltx_th_row" style="padding-left:2.7pt;padding-right:2.7pt;">
<span id="S2.T1.4.1.10.9.1.1" class="ltx_text ltx_font_smallcaps">FedLab</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib59" title="" class="ltx_ref">59</a>]</cite>
</th>
<td id="S2.T1.4.1.10.9.2" class="ltx_td ltx_align_center" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S2.T1.4.1.10.9.2.1" class="ltx_text" style="color:#4DB34D;">✓</span></td>
<td id="S2.T1.4.1.10.9.3" class="ltx_td ltx_align_center" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S2.T1.4.1.10.9.3.1" class="ltx_text" style="color:#4DB34D;">✓</span></td>
<td id="S2.T1.4.1.10.9.4" class="ltx_td ltx_align_center" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S2.T1.4.1.10.9.4.1" class="ltx_text" style="color:#4DB34D;">✓</span></td>
<td id="S2.T1.4.1.10.9.5" class="ltx_td ltx_align_center" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S2.T1.4.1.10.9.5.1" class="ltx_text" style="color:#4DB34D;">✓</span></td>
<td id="S2.T1.4.1.10.9.6" class="ltx_td ltx_align_center" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S2.T1.4.1.10.9.6.1" class="ltx_text" style="color:#E64D4D;">✗</span></td>
<td id="S2.T1.4.1.10.9.7" class="ltx_td ltx_align_center" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S2.T1.4.1.10.9.7.1" class="ltx_text" style="color:#E64D4D;">✗</span></td>
<td id="S2.T1.4.1.10.9.8" class="ltx_td ltx_align_center" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S2.T1.4.1.10.9.8.1" class="ltx_text" style="color:#E64D4D;">✗</span></td>
<td id="S2.T1.4.1.10.9.9" class="ltx_td ltx_align_center" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S2.T1.4.1.10.9.9.1" class="ltx_text" style="color:#4DB34D;">✓</span></td>
<td id="S2.T1.4.1.10.9.10" class="ltx_td ltx_align_center" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S2.T1.4.1.10.9.10.1" class="ltx_text" style="color:#E64D4D;">✗</span></td>
</tr>
<tr id="S2.T1.4.1.11.10" class="ltx_tr">
<th id="S2.T1.4.1.11.10.1" class="ltx_td ltx_align_right ltx_th ltx_th_row" style="padding-left:2.7pt;padding-right:2.7pt;">
<span id="S2.T1.4.1.11.10.1.1" class="ltx_text ltx_font_smallcaps">Flower</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>
</th>
<td id="S2.T1.4.1.11.10.2" class="ltx_td ltx_align_center" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S2.T1.4.1.11.10.2.1" class="ltx_text" style="color:#4DB34D;">✓</span></td>
<td id="S2.T1.4.1.11.10.3" class="ltx_td ltx_align_center" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S2.T1.4.1.11.10.3.1" class="ltx_text" style="color:#4DB34D;">✓</span></td>
<td id="S2.T1.4.1.11.10.4" class="ltx_td ltx_align_center" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S2.T1.4.1.11.10.4.1" class="ltx_text" style="color:#E64D4D;">✗</span></td>
<td id="S2.T1.4.1.11.10.5" class="ltx_td ltx_align_center" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S2.T1.4.1.11.10.5.1" class="ltx_text" style="color:#E64D4D;">✗</span></td>
<td id="S2.T1.4.1.11.10.6" class="ltx_td ltx_align_center" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S2.T1.4.1.11.10.6.1" class="ltx_text" style="color:#4DB34D;">✓</span></td>
<td id="S2.T1.4.1.11.10.7" class="ltx_td ltx_align_center" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S2.T1.4.1.11.10.7.1" class="ltx_text" style="color:#4DB34D;">✓</span></td>
<td id="S2.T1.4.1.11.10.8" class="ltx_td ltx_align_center" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S2.T1.4.1.11.10.8.1" class="ltx_text" style="color:#4DB34D;">✓</span></td>
<td id="S2.T1.4.1.11.10.9" class="ltx_td ltx_align_center" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S2.T1.4.1.11.10.9.1" class="ltx_text" style="color:#4DB34D;">✓</span></td>
<td id="S2.T1.4.1.11.10.10" class="ltx_td ltx_align_center" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S2.T1.4.1.11.10.10.1" class="ltx_text ltx_font_bold ltx_font_italic" style="color:#4DB34D;">VFL</span></td>
</tr>
<tr id="S2.T1.4.1.12.11" class="ltx_tr">
<th id="S2.T1.4.1.12.11.1" class="ltx_td ltx_align_right ltx_th ltx_th_row" style="padding-left:2.7pt;padding-right:2.7pt;">
<span id="S2.T1.4.1.12.11.1.1" class="ltx_text ltx_font_smallcaps">FedML</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>
</th>
<td id="S2.T1.4.1.12.11.2" class="ltx_td ltx_align_center" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S2.T1.4.1.12.11.2.1" class="ltx_text" style="color:#4DB34D;">✓</span></td>
<td id="S2.T1.4.1.12.11.3" class="ltx_td ltx_align_center" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S2.T1.4.1.12.11.3.1" class="ltx_text" style="color:#4DB34D;">✓</span></td>
<td id="S2.T1.4.1.12.11.4" class="ltx_td ltx_align_center" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S2.T1.4.1.12.11.4.1" class="ltx_text" style="color:#E64D4D;">✗</span></td>
<td id="S2.T1.4.1.12.11.5" class="ltx_td ltx_align_center" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S2.T1.4.1.12.11.5.1" class="ltx_text" style="color:#E64D4D;">✗</span></td>
<td id="S2.T1.4.1.12.11.6" class="ltx_td ltx_align_center" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S2.T1.4.1.12.11.6.1" class="ltx_text" style="color:#4DB34D;">✓</span></td>
<td id="S2.T1.4.1.12.11.7" class="ltx_td ltx_align_center" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S2.T1.4.1.12.11.7.1" class="ltx_text" style="color:#4DB34D;">✓</span></td>
<td id="S2.T1.4.1.12.11.8" class="ltx_td ltx_align_center" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S2.T1.4.1.12.11.8.1" class="ltx_text" style="color:#4DB34D;">✓</span></td>
<td id="S2.T1.4.1.12.11.9" class="ltx_td ltx_align_center" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S2.T1.4.1.12.11.9.1" class="ltx_text" style="color:#4DB34D;">✓</span></td>
<td id="S2.T1.4.1.12.11.10" class="ltx_td ltx_align_center" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S2.T1.4.1.12.11.10.1" class="ltx_text ltx_font_bold ltx_font_italic" style="color:#4DB34D;">VFL, HierFL, DFL</span></td>
</tr>
<tr id="S2.T1.4.1.13.12" class="ltx_tr">
<th id="S2.T1.4.1.13.12.1" class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_bb" style="padding-left:2.7pt;padding-right:2.7pt;">
<span id="S2.T1.4.1.13.12.1.1" class="ltx_text ltx_font_smallcaps">Appfl</span> (this work)</th>
<td id="S2.T1.4.1.13.12.2" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S2.T1.4.1.13.12.2.1" class="ltx_text" style="color:#4DB34D;">✓</span></td>
<td id="S2.T1.4.1.13.12.3" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S2.T1.4.1.13.12.3.1" class="ltx_text" style="color:#4DB34D;">✓</span></td>
<td id="S2.T1.4.1.13.12.4" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S2.T1.4.1.13.12.4.1" class="ltx_text" style="color:#4DB34D;">✓</span></td>
<td id="S2.T1.4.1.13.12.5" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S2.T1.4.1.13.12.5.1" class="ltx_text" style="color:#4DB34D;">✓</span></td>
<td id="S2.T1.4.1.13.12.6" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S2.T1.4.1.13.12.6.1" class="ltx_text" style="color:#4DB34D;">✓</span></td>
<td id="S2.T1.4.1.13.12.7" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S2.T1.4.1.13.12.7.1" class="ltx_text" style="color:#4DB34D;">✓</span></td>
<td id="S2.T1.4.1.13.12.8" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S2.T1.4.1.13.12.8.1" class="ltx_text" style="color:#4DB34D;">✓</span></td>
<td id="S2.T1.4.1.13.12.9" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S2.T1.4.1.13.12.9.1" class="ltx_text" style="color:#4DB34D;">✓</span></td>
<td id="S2.T1.4.1.13.12.10" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:2.7pt;padding-right:2.7pt;"><span id="S2.T1.4.1.13.12.10.1" class="ltx_text ltx_font_bold ltx_font_italic" style="color:#4DB34D;">VFL, HierFL, DFL</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">The distributed and uninspectable nature of FL exposes it to various adversarial attacks and security risks. These attacks generally fall into two broad categories: (1) inferring clients’ confidential training data from the model gradients and (2) degrading the performance of the trained global model <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>.</p>
</div>
<div id="S2.SS2.p2" class="ltx_para">
<p id="S2.SS2.p2.1" class="ltx_p">Gradient inversion algorithms, for example, can reveal information about the private training data by iteratively updating a randomly initialized sample to match its gradient update with the actual model gradient. These algorithms are particularly effective in the early stages of training where the gradients contain more information about the training data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib60" title="" class="ltx_ref">60</a>, <a href="#bib.bib61" title="" class="ltx_ref">61</a>, <a href="#bib.bib62" title="" class="ltx_ref">62</a>, <a href="#bib.bib63" title="" class="ltx_ref">63</a>]</cite>. Countermeasures to these inversion attacks include increasing training batch sizes <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib62" title="" class="ltx_ref">62</a>]</cite>, implementing differential privacy techniques to add noise to model gradients <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>, compressing model gradients <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib64" title="" class="ltx_ref">64</a>, <a href="#bib.bib65" title="" class="ltx_ref">65</a>]</cite>, and employing cryptographic strategies such as homomorphic encryption to secure the gradients <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib66" title="" class="ltx_ref">66</a>]</cite>.</p>
</div>
<div id="S2.SS2.p3" class="ltx_para">
<p id="S2.SS2.p3.1" class="ltx_p">Since the FL server cannot access and inspect the client training data, FL is also vulnerable to attacks from Byzantine clients <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib67" title="" class="ltx_ref">67</a>]</cite>, which may either submit corrupted model parameters (model poisoning) or use tampered data for training (data poisoning) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib68" title="" class="ltx_ref">68</a>, <a href="#bib.bib69" title="" class="ltx_ref">69</a>, <a href="#bib.bib70" title="" class="ltx_ref">70</a>, <a href="#bib.bib71" title="" class="ltx_ref">71</a>, <a href="#bib.bib72" title="" class="ltx_ref">72</a>, <a href="#bib.bib73" title="" class="ltx_ref">73</a>]</cite>. To counter these, several algorithms have been developed to exclude models whose parameters significantly deviate from the norm <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib74" title="" class="ltx_ref">74</a>, <a href="#bib.bib75" title="" class="ltx_ref">75</a>, <a href="#bib.bib70" title="" class="ltx_ref">70</a>]</cite>. Other approaches use the client models to inversely derive training data and then exclude models if their derived data significantly diverges from other models. Alternatively, some solutions assume that the FL server holds a clean and secret validation dataset to evaluate and potentially exclude poorly performing client models from the aggregation process <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib76" title="" class="ltx_ref">76</a>, <a href="#bib.bib77" title="" class="ltx_ref">77</a>]</cite>.</p>
</div>
<div id="S2.SS2.p4" class="ltx_para">
<p id="S2.SS2.p4.1" class="ltx_p">Beyond algorithmic defenses, addressing malicious attacks in FL can also be achieved through system-level enhancements, particularly by integrating with identity and access management (IAM) services <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib78" title="" class="ltx_ref">78</a>]</cite>. Such integration enables the creation of secure federations that permit only trusted and known clients to participate in FL experiments, thus fundamentally resolving security concerns at their root.</p>
</div>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS3.5.1.1" class="ltx_text">II-C</span> </span><span id="S2.SS3.6.2" class="ltx_text ltx_font_italic">Existing Federated Learning Frameworks</span>
</h3>

<div id="S2.SS3.p1" class="ltx_para">
<p id="S2.SS3.p1.1" class="ltx_p">We conduct a brief survey of twelve popular open-source federated learning frameworks, including the previous version of <span id="S2.SS3.p1.1.1" class="ltx_text ltx_font_smallcaps">Appfl</span> without advancements <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite> (<span id="S2.SS3.p1.1.2" class="ltx_text ltx_font_smallcaps">Appfl-v0</span>), focusing on their approaches to heterogeneity and security challenges, usability, and extensibility for various application scenarios. The results are summarized in Table <a href="#S2.T1" title="TABLE I ‣ II-B Attacks and Security Concerns in Federated Learning ‣ II Background and Related Work ‣ Advances in Appfl: A Comprehensive and Extensible Federated Learning Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag">I</span></a>.</p>
</div>
<div id="S2.SS3.p2" class="ltx_para">
<p id="S2.SS3.p2.1" class="ltx_p">In addressing data heterogeneity, most frameworks implement advanced client training and server aggregation strategies to mitigate the client drift issue, with the exception of <span id="S2.SS3.p2.1.1" class="ltx_text ltx_font_smallcaps">LEAF</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib54" title="" class="ltx_ref">54</a>]</cite>, one of the earliest FL frameworks. Regarding computation heterogeneity, while all frameworks include synchronous FL algorithms, only <span id="S2.SS3.p2.1.2" class="ltx_text ltx_font_smallcaps">FedScale</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>, <span id="S2.SS3.p2.1.3" class="ltx_text ltx_font_smallcaps">FLGo</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib58" title="" class="ltx_ref">58</a>]</cite>, <span id="S2.SS3.p2.1.4" class="ltx_text ltx_font_smallcaps">FedLab</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib59" title="" class="ltx_ref">59</a>]</cite>, and <span id="S2.SS3.p2.1.5" class="ltx_text ltx_font_smallcaps">Appfl</span> offer asynchronous communication stack and the corresponding asynchronous aggregation strategies. For communication heterogeneity concerns, we evaluate whether the frameworks feature lossless or lossy compression algorithms to reduce the communication loads and whether they provide versatile communication stacks that support multiple protocols, enhancing efficiency and adaptability to different deployment requirements and scenarios.</p>
</div>
<div id="S2.SS3.p3" class="ltx_para">
<p id="S2.SS3.p3.1" class="ltx_p">In terms of the privacy and security challenges, our investigation focuses on whether the frameworks incorporate privacy preservation algorithms such as differential privacy, and integrate IAM services for user authentication and authorization. Most existing frameworks support privacy preservation to some extent, with <span id="S2.SS3.p3.1.1" class="ltx_text ltx_font_smallcaps">FLARE</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib56" title="" class="ltx_ref">56</a>]</cite>, <span id="S2.SS3.p3.1.2" class="ltx_text ltx_font_smallcaps">OpenFL</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib57" title="" class="ltx_ref">57</a>]</cite>, <span id="S2.SS3.p3.1.3" class="ltx_text ltx_font_smallcaps">Flower</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>, <span id="S2.SS3.p3.1.4" class="ltx_text ltx_font_smallcaps">FedML</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>, and <span id="S2.SS3.p3.1.5" class="ltx_text ltx_font_smallcaps">Appfl</span> featuring IAM integration for verifying user identities and managing access to specific FL experiments.</p>
</div>
<div id="S2.SS3.p4" class="ltx_para">
<p id="S2.SS3.p4.1" class="ltx_p">As for the usability, most of the frameworks facilitate both the simulation of FL experiments within the same machine or cluster and the real deployment among distributed clients. However, <span id="S2.SS3.p4.1.1" class="ltx_text ltx_font_smallcaps">LEAF</span> and <span id="S2.SS3.p4.1.2" class="ltx_text ltx_font_smallcaps">TFF</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite> are limited to simulation environments only. To evaluate the extensibility and customization capabilities of the frameworks, we access their support for different FL variants beyond the traditional federated learning, specifically vertical federated learning (VFL) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib79" title="" class="ltx_ref">79</a>]</cite>, hierarchical federated learning (HierFL) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib80" title="" class="ltx_ref">80</a>]</cite>, and decentralized federated learning (DFL) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib81" title="" class="ltx_ref">81</a>]</cite>. <span id="S2.SS3.p4.1.3" class="ltx_text ltx_font_smallcaps">FederatedScope</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib55" title="" class="ltx_ref">55</a>]</cite>, <span id="S2.SS3.p4.1.4" class="ltx_text ltx_font_smallcaps">FLARE</span>, <span id="S2.SS3.p4.1.5" class="ltx_text ltx_font_smallcaps">OpenFL</span>, <span id="S2.SS3.p4.1.6" class="ltx_text ltx_font_smallcaps">FLGo</span>, and <span id="S2.SS3.p4.1.7" class="ltx_text ltx_font_smallcaps">Flower</span> provide use cases in VFL settings, and <span id="S2.SS3.p4.1.8" class="ltx_text ltx_font_smallcaps">FedML</span> and <span id="S2.SS3.p4.1.9" class="ltx_text ltx_font_smallcaps">Appfl</span> extend support to all three variants.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">III </span><span id="S3.1.1" class="ltx_text ltx_font_smallcaps">Architecture and Implementation</span>
</h2>

<figure id="S3.F1" class="ltx_figure">
<p id="S3.F1.1" class="ltx_p ltx_align_center"><span id="S3.F1.1.1" class="ltx_text"><img src="/html/2409.11585/assets/x1.png" id="S3.F1.1.1.g1" class="ltx_graphics ltx_img_landscape" width="461" height="165" alt="Refer to caption"></span></p>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S3.F1.7.1.1" class="ltx_text" style="font-size:90%;">Figure 1</span>: </span><span id="S3.F1.8.2" class="ltx_text" style="font-size:90%;">Overview of the <span id="S3.F1.8.2.1" class="ltx_text ltx_font_smallcaps">Appfl</span> framework’s new software architecture design. <span id="S3.F1.8.2.2" class="ltx_text ltx_font_italic">Server agent</span> and <span id="S3.F1.8.2.3" class="ltx_text ltx_font_italic">client agent</span> act on behalf of the FL server and client, respectively, to fulfill various tasks for FL experiments. <span id="S3.F1.8.2.4" class="ltx_text ltx_font_italic">Communicator</span> exchanges task control signals and model parameters between the server and client.</span></figcaption>
</figure>
<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">The <span id="S3.p1.1.1" class="ltx_text ltx_font_smallcaps">Appfl</span> framework is a Python package available on <span id="S3.p1.1.2" class="ltx_text ltx_font_typewriter">PyPI</span>. Figure <a href="#S3.F1" title="Figure 1 ‣ III Architecture and Implementation ‣ Advances in Appfl: A Comprehensive and Extensible Federated Learning Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> provides an overview of its new software architecture. <span id="S3.p1.1.3" class="ltx_text ltx_font_smallcaps">Appfl</span> defines a <span id="S3.p1.1.4" class="ltx_text ltx_font_italic">server agent</span> and a <span id="S3.p1.1.5" class="ltx_text ltx_font_italic">client agent</span>, connected by the <span id="S3.p1.1.6" class="ltx_text ltx_font_italic">communicator</span>, to represent the FL server and clients in performing the primary aggregation task and other necessary tasks for running FL experiments. The <span id="S3.p1.1.7" class="ltx_text ltx_font_italic">server agent</span> is mainly composed of a scheduler module that orchestrates the aggregation of client local models under various synchronicity settings, an aggregator module that aggregates the local models passed from the scheduler to update global model, and a privacy module for additional privacy protection. The <span id="S3.p1.1.8" class="ltx_text ltx_font_italic">client agent</span> consists of a trainer module responsible for training the ML model using the confidential local dataset and a privacy module for the privacy preservation algorithms. The <span id="S3.p1.1.9" class="ltx_text ltx_font_italic">communicator</span> facilitates robust communication between the server and clients, supporting multiple communication protocols for exchanging task control signals and data, with an option to separate the transmission of control signals and data via a data connector. Additionally, the communicator incorporates several compressors for improved efficiency and authenticators for securing the FL experiments. Overall, <span id="S3.p1.1.10" class="ltx_text ltx_font_smallcaps">Appfl</span> incorporates solutions for various challenges in FL and is designed to be modular and extensible, facilitating easy integration of new algorithms and strategies to address FL challenges. The following subsections detail the key components of <span id="S3.p1.1.11" class="ltx_text ltx_font_smallcaps">Appfl</span>.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS1.5.1.1" class="ltx_text">III-A</span> </span><span id="S3.SS1.6.2" class="ltx_text ltx_font_italic">FL Experiment Configuration</span>
</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p"><span id="S3.SS1.p1.1.1" class="ltx_text ltx_font_smallcaps">Appfl</span> provides a straightforward way to configure FL experiments: each experiment utilizes a configuration YAML file for the FL server and individual YAML files for each FL client. Listing <a href="#LST1" title="Listing 1 ‣ III-A FL Experiment Configuration ‣ III Architecture and Implementation ‣ Advances in Appfl: A Comprehensive and Extensible Federated Learning Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> presents an example of the server configuration file, which includes server-specific settings, such as the aggregation algorithm and the number of global epochs, along with general configurations for the clients like the trainer and compressor types. These general configurations are distributed to all clients at the beginning of each FL experiment, simplifying the setup by ensuring that shared configuration fields do not need to be individually set by each client. In addition to the configurations shared by the server, each client possesses its own YAML configuration file that defines client-specific settings, as shown in Listing <a href="#LST2" title="Listing 2 ‣ III-A FL Experiment Configuration ‣ III Architecture and Implementation ‣ Advances in Appfl: A Comprehensive and Extensible Federated Learning Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. The client-specific settings include a Python loader file, which defines a function for loading the client’s local datasets, and some training-related configurations such as the device to use and directories for logging and checkpoints.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.1" class="ltx_p">This configuration also facilitates integration of new algorithms by allowing developers to directly add necessary settings to the relevant configuration files and use them in their respective module blocks. For instance, to create a trainer for a particular application, a developer simply needs to define a new trainer within the <span id="S3.SS1.p2.1.1" class="ltx_text ltx_font_smallcaps">Appfl</span> trainer module and include all necessary arguments in the <span id="S3.SS1.p2.1.2" class="ltx_text ltx_font_italic">client_configs.train_configs</span> section of the configuration file.</p>
</div>
<figure id="LST1" class="ltx_float ltx_lstlisting">
<div id="LST1.1" class="ltx_listing ltx_lst_numbers_left ltx_lstlisting ltx_listing" style="background-color:#F2F2EB;">
<div class="ltx_listing_data"><a href="data:text/plain;base64,IyBTZXJ2ZXIgY29uZmlndXJhdGlvbnMKc2VydmVyX2NvbmZpZ3M6CiAgYWdncmVnYXRvcjogRmVkQXZnQWdncmVnYXRvcgogIG51bV9nbG9iYWxfZXBvY2hzOiAxMAogIC4uLgojIEdlbmVyYWwgY2xpZW50IGNvbmZpZ3VyYXRpb25zIGZvciBhbGwgY2xpZW50cwpjbGllbnRfY29uZmlnczoKICB0cmFpbl9jb25maWdzOgogICAgdHJhaW5lcjogVmFuaWxsYVRyYWluZXIKICAgIGxyOiAwLjAwMQogICAgLi4uCiAgY29tbV9jb25maWdzOgogICAgY29tcHJlc3Nvcl9jb25maWdzOgogICAgICAgIGxvc3N5X2NvbXByZXNzb3I6IFNaMkNvbXByZXNzb3IKICAgICAgICAuLi4=" download="">⬇</a></div>
<div id="lstnumberx1" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">1</span><span id="lstnumberx1.1" class="ltx_text ltx_font_typewriter" style="font-size:80%;">#</span><span id="lstnumberx1.2" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:80%;"> </span><span id="lstnumberx1.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:80%;">Server</span><span id="lstnumberx1.4" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:80%;"> </span><span id="lstnumberx1.5" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:80%;">configurations</span>
</div>
<div id="lstnumberx2" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">2</span><span id="lstnumberx2.1" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:80%;">server_configs</span><span id="lstnumberx2.2" class="ltx_text ltx_font_typewriter" style="font-size:80%;">:</span>
</div>
<div id="lstnumberx3" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">3</span><span id="lstnumberx3.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:80%;">  </span><span id="lstnumberx3.2" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:80%;">aggregator</span><span id="lstnumberx3.3" class="ltx_text ltx_font_typewriter" style="font-size:80%;">:</span><span id="lstnumberx3.4" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:80%;"> </span><span id="lstnumberx3.5" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:80%;">FedAvgAggregator</span>
</div>
<div id="lstnumberx4" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">4</span><span id="lstnumberx4.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:80%;">  </span><span id="lstnumberx4.2" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:80%;">num_global_epochs</span><span id="lstnumberx4.3" class="ltx_text ltx_font_typewriter" style="font-size:80%;">:</span><span id="lstnumberx4.4" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:80%;"> </span><span id="lstnumberx4.5" class="ltx_text ltx_font_typewriter" style="font-size:80%;">10</span>
</div>
<div id="lstnumberx5" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">5</span><span id="lstnumberx5.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:80%;">  </span><span id="lstnumberx5.2" class="ltx_text ltx_font_typewriter" style="font-size:80%;">...</span>
</div>
<div id="lstnumberx6" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">6</span><span id="lstnumberx6.1" class="ltx_text ltx_font_typewriter" style="font-size:80%;">#</span><span id="lstnumberx6.2" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:80%;"> </span><span id="lstnumberx6.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:80%;">General</span><span id="lstnumberx6.4" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:80%;"> </span><span id="lstnumberx6.5" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:80%;">client</span><span id="lstnumberx6.6" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:80%;"> </span><span id="lstnumberx6.7" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:80%;">configurations</span><span id="lstnumberx6.8" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:80%;"> </span><span id="lstnumberx6.9" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:80%;">for</span><span id="lstnumberx6.10" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:80%;"> </span><span id="lstnumberx6.11" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:80%;">all</span><span id="lstnumberx6.12" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:80%;"> </span><span id="lstnumberx6.13" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:80%;">clients</span>
</div>
<div id="lstnumberx7" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">7</span><span id="lstnumberx7.1" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:80%;">client_configs</span><span id="lstnumberx7.2" class="ltx_text ltx_font_typewriter" style="font-size:80%;">:</span>
</div>
<div id="lstnumberx8" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">8</span><span id="lstnumberx8.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:80%;">  </span><span id="lstnumberx8.2" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:80%;">train_configs</span><span id="lstnumberx8.3" class="ltx_text ltx_font_typewriter" style="font-size:80%;">:</span>
</div>
<div id="lstnumberx9" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">9</span><span id="lstnumberx9.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:80%;">    </span><span id="lstnumberx9.2" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:80%;">trainer</span><span id="lstnumberx9.3" class="ltx_text ltx_font_typewriter" style="font-size:80%;">:</span><span id="lstnumberx9.4" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:80%;"> </span><span id="lstnumberx9.5" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:80%;">VanillaTrainer</span>
</div>
<div id="lstnumberx10" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">10</span><span id="lstnumberx10.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:80%;">    </span><span id="lstnumberx10.2" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:80%;">lr</span><span id="lstnumberx10.3" class="ltx_text ltx_font_typewriter" style="font-size:80%;">:</span><span id="lstnumberx10.4" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:80%;"> </span><span id="lstnumberx10.5" class="ltx_text ltx_font_typewriter" style="font-size:80%;">0.001</span>
</div>
<div id="lstnumberx11" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">11</span><span id="lstnumberx11.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:80%;">    </span><span id="lstnumberx11.2" class="ltx_text ltx_font_typewriter" style="font-size:80%;">...</span>
</div>
<div id="lstnumberx12" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">12</span><span id="lstnumberx12.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:80%;">  </span><span id="lstnumberx12.2" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:80%;">comm_configs</span><span id="lstnumberx12.3" class="ltx_text ltx_font_typewriter" style="font-size:80%;">:</span>
</div>
<div id="lstnumberx13" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">13</span><span id="lstnumberx13.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:80%;">    </span><span id="lstnumberx13.2" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:80%;">compressor_configs</span><span id="lstnumberx13.3" class="ltx_text ltx_font_typewriter" style="font-size:80%;">:</span>
</div>
<div id="lstnumberx14" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">14</span><span id="lstnumberx14.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:80%;">        </span><span id="lstnumberx14.2" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:80%;">lossy_compressor</span><span id="lstnumberx14.3" class="ltx_text ltx_font_typewriter" style="font-size:80%;">:</span><span id="lstnumberx14.4" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:80%;"> </span><span id="lstnumberx14.5" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:80%;">SZ2Compressor</span>
</div>
<div id="lstnumberx15" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">15</span><span id="lstnumberx15.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:80%;">        </span><span id="lstnumberx15.2" class="ltx_text ltx_font_typewriter" style="font-size:80%;">...</span>
</div>
</div>
<figcaption class="ltx_caption" style="background-color:#F2F2EB;"><span class="ltx_tag ltx_tag_float">Listing 1: </span>An example server configuration YAML file, containing both server configurations and general client configurations to be shared among all clients. </figcaption>
</figure>
<figure id="LST2" class="ltx_float ltx_lstlisting">
<div id="LST2.1" class="ltx_listing ltx_lst_numbers_left ltx_lstlisting ltx_listing" style="background-color:#F2F2EB;">
<div class="ltx_listing_data"><a href="data:text/plain;base64,IyBJbmZvcm1hdGlvbiBuZWVkZWQgdG8gbG9hZCBsb2NhbCBkYXRhCmRhdGFfY29uZmlnczoKICBkYXRhc2V0X3BhdGg6IC4vZGF0YXNldC9jb3ZpZF9kYXRhc2V0LnB5CiAgZGF0YXNldF9uYW1lOiBnZXRfY292aWQgI2Z1bmN0aW9uIHRvIGxvYWQgZGF0YQogIGRhdGFzZXRfa3dhcmdzOiAjb3B0aW9uYWwgZnVuY3Rpb24gYXJndW1lbnRzCiAgICAuLi4KIyBDbGllbnQtc3BlY2lmaWMgdHJhaW5pbmcgc2V0dGluZ3MKdHJhaW5fY29uZmlnczoKICBkZXZpY2U6IGNwdQogIGxvZ2dpbmdfZGlyOiAuL2FwcGZsX2xvZ2dpbmcKICBjaGVja3BvaW50X2RpcjogLi9hcHBmbF9jaGVja3BvaW50CiAgLi4u" download="">⬇</a></div>
<div id="lstnumberx16" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">1</span><span id="lstnumberx16.1" class="ltx_text ltx_font_typewriter" style="font-size:80%;">#</span><span id="lstnumberx16.2" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:80%;"> </span><span id="lstnumberx16.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:80%;">Information</span><span id="lstnumberx16.4" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:80%;"> </span><span id="lstnumberx16.5" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:80%;">needed</span><span id="lstnumberx16.6" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:80%;"> </span><span id="lstnumberx16.7" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:80%;">to</span><span id="lstnumberx16.8" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:80%;"> </span><span id="lstnumberx16.9" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:80%;">load</span><span id="lstnumberx16.10" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:80%;"> </span><span id="lstnumberx16.11" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:80%;">local</span><span id="lstnumberx16.12" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:80%;"> </span><span id="lstnumberx16.13" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:80%;">data</span>
</div>
<div id="lstnumberx17" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">2</span><span id="lstnumberx17.1" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:80%;">data_configs</span><span id="lstnumberx17.2" class="ltx_text ltx_font_typewriter" style="font-size:80%;">:</span>
</div>
<div id="lstnumberx18" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">3</span><span id="lstnumberx18.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:80%;">  </span><span id="lstnumberx18.2" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:80%;">dataset_path</span><span id="lstnumberx18.3" class="ltx_text ltx_font_typewriter" style="font-size:80%;">:</span><span id="lstnumberx18.4" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:80%;"> </span><span id="lstnumberx18.5" class="ltx_text ltx_font_typewriter" style="font-size:80%;">./</span><span id="lstnumberx18.6" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:80%;">dataset</span><span id="lstnumberx18.7" class="ltx_text ltx_font_typewriter" style="font-size:80%;">/</span><span id="lstnumberx18.8" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:80%;">covid_dataset</span><span id="lstnumberx18.9" class="ltx_text ltx_font_typewriter" style="font-size:80%;">.</span><span id="lstnumberx18.10" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:80%;">py</span>
</div>
<div id="lstnumberx19" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">4</span><span id="lstnumberx19.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:80%;">  </span><span id="lstnumberx19.2" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:80%;">dataset_name</span><span id="lstnumberx19.3" class="ltx_text ltx_font_typewriter" style="font-size:80%;">:</span><span id="lstnumberx19.4" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:80%;"> </span><span id="lstnumberx19.5" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:80%;">get_covid</span><span id="lstnumberx19.6" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:80%;"> </span><span id="lstnumberx19.7" class="ltx_text ltx_font_typewriter" style="font-size:80%;">#</span><span id="lstnumberx19.8" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:80%;">function</span><span id="lstnumberx19.9" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:80%;"> </span><span id="lstnumberx19.10" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:80%;">to</span><span id="lstnumberx19.11" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:80%;"> </span><span id="lstnumberx19.12" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:80%;">load</span><span id="lstnumberx19.13" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:80%;"> </span><span id="lstnumberx19.14" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:80%;">data</span>
</div>
<div id="lstnumberx20" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">5</span><span id="lstnumberx20.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:80%;">  </span><span id="lstnumberx20.2" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:80%;">dataset_kwargs</span><span id="lstnumberx20.3" class="ltx_text ltx_font_typewriter" style="font-size:80%;">:</span><span id="lstnumberx20.4" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:80%;"> </span><span id="lstnumberx20.5" class="ltx_text ltx_font_typewriter" style="font-size:80%;">#</span><span id="lstnumberx20.6" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:80%;">optional</span><span id="lstnumberx20.7" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:80%;"> </span><span id="lstnumberx20.8" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:80%;">function</span><span id="lstnumberx20.9" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:80%;"> </span><span id="lstnumberx20.10" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:80%;">arguments</span>
</div>
<div id="lstnumberx21" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">6</span><span id="lstnumberx21.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:80%;">    </span><span id="lstnumberx21.2" class="ltx_text ltx_font_typewriter" style="font-size:80%;">...</span>
</div>
<div id="lstnumberx22" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">7</span><span id="lstnumberx22.1" class="ltx_text ltx_font_typewriter" style="font-size:80%;">#</span><span id="lstnumberx22.2" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:80%;"> </span><span id="lstnumberx22.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:80%;">Client</span><span id="lstnumberx22.4" class="ltx_text ltx_font_typewriter" style="font-size:80%;">-</span><span id="lstnumberx22.5" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:80%;">specific</span><span id="lstnumberx22.6" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:80%;"> </span><span id="lstnumberx22.7" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:80%;">training</span><span id="lstnumberx22.8" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:80%;"> </span><span id="lstnumberx22.9" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:80%;">settings</span>
</div>
<div id="lstnumberx23" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">8</span><span id="lstnumberx23.1" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:80%;">train_configs</span><span id="lstnumberx23.2" class="ltx_text ltx_font_typewriter" style="font-size:80%;">:</span>
</div>
<div id="lstnumberx24" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">9</span><span id="lstnumberx24.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:80%;">  </span><span id="lstnumberx24.2" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:80%;">device</span><span id="lstnumberx24.3" class="ltx_text ltx_font_typewriter" style="font-size:80%;">:</span><span id="lstnumberx24.4" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:80%;"> </span><span id="lstnumberx24.5" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:80%;">cpu</span>
</div>
<div id="lstnumberx25" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">10</span><span id="lstnumberx25.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:80%;">  </span><span id="lstnumberx25.2" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:80%;">logging_dir</span><span id="lstnumberx25.3" class="ltx_text ltx_font_typewriter" style="font-size:80%;">:</span><span id="lstnumberx25.4" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:80%;"> </span><span id="lstnumberx25.5" class="ltx_text ltx_font_typewriter" style="font-size:80%;">./</span><span id="lstnumberx25.6" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:80%;">appfl_logging</span>
</div>
<div id="lstnumberx26" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">11</span><span id="lstnumberx26.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:80%;">  </span><span id="lstnumberx26.2" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:80%;">checkpoint_dir</span><span id="lstnumberx26.3" class="ltx_text ltx_font_typewriter" style="font-size:80%;">:</span><span id="lstnumberx26.4" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:80%;"> </span><span id="lstnumberx26.5" class="ltx_text ltx_font_typewriter" style="font-size:80%;">./</span><span id="lstnumberx26.6" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:80%;">appfl_checkpoint</span>
</div>
<div id="lstnumberx27" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">12</span><span id="lstnumberx27.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:80%;">  </span><span id="lstnumberx27.2" class="ltx_text ltx_font_typewriter" style="font-size:80%;">...</span>
</div>
</div>
<figcaption class="ltx_caption" style="background-color:#F2F2EB;"><span class="ltx_tag ltx_tag_float">Listing 2: </span>An example client configuration YAML file, containing client-specific configurations such as the data loader file.</figcaption>
</figure>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS2.5.1.1" class="ltx_text">III-B</span> </span><span id="S3.SS2.6.2" class="ltx_text ltx_font_italic">Communication Stack</span>
</h3>

<figure id="S3.F2" class="ltx_figure">
<p id="S3.F2.1" class="ltx_p ltx_align_center"><span id="S3.F2.1.1" class="ltx_text"><img src="/html/2409.11585/assets/x2.png" id="S3.F2.1.1.g1" class="ltx_graphics ltx_img_landscape" width="461" height="273" alt="Refer to caption"></span></p>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S3.F2.3.1.1" class="ltx_text" style="font-size:90%;">Figure 2</span>: </span><span id="S3.F2.4.2" class="ltx_text" style="font-size:90%;">Running one local training and global aggregation iteration using (a) client-driven and (b) server-driven communication protocols.</span></figcaption>
</figure>
<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">In FL, communication protocols can be broadly classified into two types based on the driven side of the FL process: (1) <span id="S3.SS2.p1.1.1" class="ltx_text ltx_font_italic">client-driven</span>: the clients control the FL process and interact with the server for aggregation and other tasks by sending various requests and (2) <span id="S3.SS2.p1.1.2" class="ltx_text ltx_font_italic">server-driven</span>: the server controls the FL process by dispatching various types of tasks to the clients. Figure <a href="#S3.F2" title="Figure 2 ‣ III-B Communication Stack ‣ III Architecture and Implementation ‣ Advances in Appfl: A Comprehensive and Extensible Federated Learning Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> illustrates the differences between these two types of communication protocols during a local training and global aggregation FL iteration. Client-driven protocols offer clients greater autonomy over the FL process, whereas server-driven protocols simplify the coordination of FL experiments, with the central server itself managing the whole distributed training process. The <span id="S3.SS2.p1.1.3" class="ltx_text ltx_font_smallcaps">Appfl</span> communicator supports MPI and gRPC as client-driven communication protocols and Globus Compute <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite> as the server-driven protocol. Specifically, MPI is for simulation purposes only, while gRPC and Globus Compute can be used for real deployments. Notably, gRPC requires the server to open a specific port for inbound TCP connections, which is typically restricted in high-performance computing environments and institutional computing facilities. Conversely, Globus Compute only necessitates outbound connections to the Globus service, thus enabling a broader range of computing resources to serve as the FL server. The versatile communication protocols supported by <span id="S3.SS2.p1.1.4" class="ltx_text ltx_font_smallcaps">Appfl</span> make it capable of meeting diverse communication needs in FL deployments.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.1" class="ltx_p">For client-driven communication protocols, the <span id="S3.SS2.p2.1.1" class="ltx_text ltx_font_smallcaps">Appfl</span> communicator provides a server communicator that defines handlers for various types of requests, such as sending general client configurations and performing global aggregation, by interacting with the server agent. Additionally, a client communicator assists the client agents in sending requests to the server. As for Globus Compute, the server-driven communication protocol, it is a distributed function-as-a-service platform that can dispatch Python functions to run on remote machines. The <span id="S3.SS2.p2.1.2" class="ltx_text ltx_font_smallcaps">Appfl</span> communicator provides a Globus Compute server communicator to send various tasks, such as local training, to run on the remote client machines and collect results back for conducting FL experiments. Overall, <span id="S3.SS2.p2.1.3" class="ltx_text ltx_font_smallcaps">Appfl</span> supports commonly used server request handlers and client task implementations and provides a user-friendly interface that enables developers to easily define new request handlers or tasks without in-depth knowledge of the underlying communication protocol.</p>
</div>
<div id="S3.SS2.p3" class="ltx_para">
<p id="S3.SS2.p3.1" class="ltx_p">While the communication protocols can transfer the task control signals (i.e., requests in client-driven and tasks in server-driven protocols) along with the associated data, <span id="S3.SS2.p3.1.1" class="ltx_text ltx_font_smallcaps">Appfl</span> provides an option to separate the transfer of task controls from the associated model parameters through the integration with ProxyStore <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>. ProxyStore can create a <span id="S3.SS2.p3.1.2" class="ltx_text ltx_font_italic">proxy</span> for any target Python object, providing a lightweight reference that can remotely resolve the target object when used. When the <span id="S3.SS2.p3.1.3" class="ltx_text ltx_font_italic">proxy</span> is resolved, the object is transferred via an underlying data connector. <span id="S3.SS2.p3.1.4" class="ltx_text ltx_font_smallcaps">Appfl</span> currently supports two connectors: an S3 connector, which uses AWS S3 buckets for data transfer, and a ProxyStore endpoint connector, which employs the ProxyStore-hosted relay server. The integration with ProxyStore offers two main benefits: (1) it prevents exceeding the maximum data size limits imposed by certain communication protocols (e.g., Globus Compute restricts task arguments and result sizes to 10 MB to reduce server load, thus making data transfer separation a must when exchanging large model parameters), and (2) it offers users a variety of data transmission options for different communication scenarios and facilitates easy integration of other efficient data transmission methods suitable for their specific use cases to accelerate the FL communication, regardless of the communication protocol in use.</p>
</div>
<div id="S3.SS2.p4" class="ltx_para">
<p id="S3.SS2.p4.1" class="ltx_p">Furthermore, <span id="S3.SS2.p4.1.1" class="ltx_text ltx_font_smallcaps">Appfl</span> incorporates a range of data compressors to enhance communication efficiency, crucial for transferring parameters of large models or operating in environments with limited network bandwidth. It supports various lossless compressors including zstd <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib82" title="" class="ltx_ref">82</a>]</cite>, gzip <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib83" title="" class="ltx_ref">83</a>]</cite>, and blosc <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib84" title="" class="ltx_ref">84</a>]</cite>, as well as lossy data compressors including SZ2 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib85" title="" class="ltx_ref">85</a>]</cite>, SZ3 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib86" title="" class="ltx_ref">86</a>]</cite>, and ZFP <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib87" title="" class="ltx_ref">87</a>]</cite>. These compressors can help reduce the communication load, enabling faster data transfer between the server and clients.</p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS3.5.1.1" class="ltx_text">III-C</span> </span><span id="S3.SS3.6.2" class="ltx_text ltx_font_italic">Server Scheduling and Aggregation</span>
</h3>

<figure id="S3.F3" class="ltx_figure">
<p id="S3.F3.1" class="ltx_p ltx_align_center"><span id="S3.F3.1.1" class="ltx_text"><img src="/html/2409.11585/assets/x3.png" id="S3.F3.1.1.g1" class="ltx_graphics ltx_img_landscape" width="461" height="150" alt="Refer to caption"></span></p>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S3.F3.3.1.1" class="ltx_text" style="font-size:90%;">Figure 3</span>: </span><span id="S3.F3.4.2" class="ltx_text" style="font-size:90%;">Scheduling of the aggregation for client local models under three schedulers with different synchronicity settings.</span></figcaption>
</figure>
<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">In order to tackle the computation heterogeneity in FL where clients have varying computing capabilities, many asynchronous aggregation algorithms have been proposed to reduce client idle times and enhance resource utilization. To support aggregation with different synchronicity settings, <span id="S3.SS3.p1.1.1" class="ltx_text ltx_font_smallcaps">Appfl</span> introduces a server-side scheduler that acts as an interface between the communicator and the aggregator. Upon receiving a local model from a client, the communicator forwards it to the scheduler, which determines the appropriate time to pass the local model(s) to the aggregator for updating the global model. For synchronous aggregation strategies, such as <span id="S3.SS3.p1.1.2" class="ltx_text ltx_font_typewriter">FedAvg</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>, a synchronous scheduler buffers each client’s local model until all models are received, at which point it forwards them to the aggregator to update the global model. Conversely, for asynchronous strategies like <span id="S3.SS3.p1.1.3" class="ltx_text ltx_font_typewriter">FedAsync</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite>, a vanilla asynchronous scheduler immediately sends the client model to the aggregator and returns the updated global model back to the communicator. Additionally, the scheduler module is designed to be extensible for the incorporation of more advanced scheduling algorithms. Specifically, <span id="S3.SS3.p1.1.4" class="ltx_text ltx_font_smallcaps">Appfl</span> supports the state-of-the-art <span id="S3.SS3.p1.1.5" class="ltx_text ltx_font_typewriter">Compass</span> asynchronous scheduler <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>, aiming to alleviate the drift of the global model toward faster clients. Such drift is prevalent in other asynchronous FL algorithms, where faster clients update the global model more frequently and the models from slower clients become stale. The <span id="S3.SS3.p1.1.6" class="ltx_text ltx_font_typewriter">Compass</span> scheduler synchronizes the arrival of a group of client local models by assigning different amounts of local training tasks to different clients to enable a grouped global aggregation and avoid stale local models, mitigating the client drift issue. Figure <a href="#S3.F3" title="Figure 3 ‣ III-C Server Scheduling and Aggregation ‣ III Architecture and Implementation ‣ Advances in Appfl: A Comprehensive and Extensible Federated Learning Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> illustrates the scheduling processes under the three different schedulers.</p>
</div>
<div id="S3.SS3.p2" class="ltx_para">
<p id="S3.SS3.p2.1" class="ltx_p">As for the aggregator module, <span id="S3.SS3.p2.1.1" class="ltx_text ltx_font_smallcaps">Appfl</span> supports a broad range of aggregation strategies, going beyond the widely used <span id="S3.SS3.p2.1.2" class="ltx_text ltx_font_typewriter">FedAvg</span>. These include <span id="S3.SS3.p2.1.3" class="ltx_text ltx_font_typewriter">FedAvgM</span>, <span id="S3.SS3.p2.1.4" class="ltx_text ltx_font_typewriter">FedAdam</span>, and <span id="S3.SS3.p2.1.5" class="ltx_text ltx_font_typewriter">FedYogi</span>, which address data heterogeneity, <span id="S3.SS3.p2.1.6" class="ltx_text ltx_font_typewriter">PLFL</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib88" title="" class="ltx_ref">88</a>]</cite> for personalized FL, as well as <span id="S3.SS3.p2.1.7" class="ltx_text ltx_font_typewriter">ICEADMM</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib89" title="" class="ltx_ref">89</a>]</cite> and <span id="S3.SS3.p2.1.8" class="ltx_text ltx_font_typewriter">IIADMM</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>, which focus on efficient privacy preservation. Additionally, for asynchronous aggregation, <span id="S3.SS3.p2.1.9" class="ltx_text ltx_font_smallcaps">Appfl</span> includes strategies such as <span id="S3.SS3.p2.1.10" class="ltx_text ltx_font_typewriter">FedAsync</span>, <span id="S3.SS3.p2.1.11" class="ltx_text ltx_font_typewriter">FedBuff</span>, <span id="S3.SS3.p2.1.12" class="ltx_text ltx_font_typewriter">AREA</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref">39</a>]</cite>, and <span id="S3.SS3.p2.1.13" class="ltx_text ltx_font_typewriter">FedCompass</span>. This diverse suite of options ensures that <span id="S3.SS3.p2.1.14" class="ltx_text ltx_font_smallcaps">Appfl</span> can accommodate a variety of needs and scenarios in FL, illustrating its adaptability and comprehensive approach to FL challenges.</p>
</div>
</section>
<section id="S3.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS4.5.1.1" class="ltx_text">III-D</span> </span><span id="S3.SS4.6.2" class="ltx_text ltx_font_italic">Privacy Preservation and Authentication</span>
</h3>

<div id="S3.SS4.p1" class="ltx_para">
<p id="S3.SS4.p1.1" class="ltx_p">To tackle security and privacy concerns in FL, <span id="S3.SS4.p1.1.1" class="ltx_text ltx_font_smallcaps">Appfl</span> offers solutions that span both algorithmic and system-level measures. Algorithmically, <span id="S3.SS4.p1.1.2" class="ltx_text ltx_font_smallcaps">Appfl</span> incorporates the differential privacy (DP) algorithms <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite> into the FL process that perturbs the client model parameters with noises before sending to the server, protecting against the reconstruction of confidential training data. A study utilizing <span id="S3.SS4.p1.1.3" class="ltx_text ltx_font_smallcaps">Appfl</span> showcases that the usage of DP in FL can effectively mitigate the risk of data reconstruction <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>.</p>
</div>
<div id="S3.SS4.p2" class="ltx_para">
<p id="S3.SS4.p2.1" class="ltx_p">At the system level, <span id="S3.SS4.p2.1.1" class="ltx_text ltx_font_smallcaps">Appfl</span> enhances security through the integration of identity and access management (IAM) services into its communication stack for user authentication and access control for FL experiments. Specifically, Globus Compute itself is already integrated with the Globus authentication service, ensuring that the server dispatches training functions only to clients within a specified Globus group. This setup helps create a secure federation of trusted collaborators, authenticated via institutional emails linked to Globus accounts.</p>
</div>
<div id="S3.SS4.p3" class="ltx_para">
<p id="S3.SS4.p3.1" class="ltx_p">As for gRPC, <span id="S3.SS4.p3.1.1" class="ltx_text ltx_font_smallcaps">Appfl</span> utilizes token-based authenticators to verify users. Clients have to attach an access token to each remote procedure call (RPC) request over an SSL-encrypted channel, allowing the server to confirm the user’s identity before processing the request. The token-based authenticator consists of two primary functions: one invoked by the client to generate the token prior to sending the RPC request and another invoked by the server to verify the validity of the token upon receipt. This straightforward interface allows developers to effortlessly integrate their own authentication methods tailored to specific use cases and applications. Currently, <span id="S3.SS4.p3.1.2" class="ltx_text ltx_font_smallcaps">Appfl</span> supports a Globus authenticator, with its login flow depicted in Figure <a href="#S3.F4" title="Figure 4 ‣ III-D Privacy Preservation and Authentication ‣ III Architecture and Implementation ‣ Advances in Appfl: A Comprehensive and Extensible Federated Learning Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>. Users can employ <span id="S3.SS4.p3.1.3" class="ltx_text ltx_font_smallcaps">Appfl</span>’s command line interface (CLI), <span id="S3.SS4.p3.1.4" class="ltx_text ltx_font_typewriter">appfl-auth</span>, to perform a one-time login. Depending on the selected role during login, either as an FL server or client, the appropriate Globus access token (Group Service or Identity Service) is requested. The access tokens, along with the corresponding refresh tokens, are securely stored in the client’s local token storage. Whenever an FL client makes an RPC request, it attaches its Globus Identity Service token. The FL server uses this token to retrieve the client’s Globus ID and, leveraging its Globus Group Service token, verifies whether the client belongs to the specified Globus group. This robust authentication process ensures a secure and controlled federation for FL experiments.</p>
</div>
<figure id="S3.F4" class="ltx_figure">
<p id="S3.F4.1" class="ltx_p ltx_align_center"><span id="S3.F4.1.1" class="ltx_text"><img src="/html/2409.11585/assets/x4.png" id="S3.F4.1.1.g1" class="ltx_graphics ltx_img_landscape" width="415" height="132" alt="Refer to caption"></span></p>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S3.F4.3.1.1" class="ltx_text" style="font-size:90%;">Figure 4</span>: </span><span id="S3.F4.4.2" class="ltx_text" style="font-size:90%;">Login flow for the Globus authenticator.</span></figcaption>
</figure>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">IV </span><span id="S4.1.1" class="ltx_text ltx_font_smallcaps">Performance Evaluation</span>
</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">In this section, we employ <span id="S4.p1.1.1" class="ltx_text ltx_font_smallcaps">Appfl</span> to comprehensively benchmark a broad spectrum of aspects within FL to highlight the capabilities of its new software design. Specifically, we utilize <span id="S4.p1.1.2" class="ltx_text ltx_font_smallcaps">Appfl</span> to evaluate the communication efficiency of different communication protocols, data transfer methods, and compression algorithms. We also explore the impacts of privacy preservation algorithms on the performance of FL-trained models, as well as the training efficiency and resource utilization of various FL strategies under different synchronicity settings. These comprehensive assessments highlight the capabilities of the newly designed <span id="S4.p1.1.3" class="ltx_text ltx_font_smallcaps">Appfl</span> framework in benchmarking a broad spectrum of aspects within FL.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS1.5.1.1" class="ltx_text">IV-A</span> </span><span id="S4.SS1.6.2" class="ltx_text ltx_font_italic">Communication Efficiency</span>
</h3>

<figure id="S4.F5" class="ltx_figure">
<p id="S4.F5.1" class="ltx_p ltx_align_center"><span id="S4.F5.1.1" class="ltx_text"><img src="/html/2409.11585/assets/x5.png" id="S4.F5.1.1.g1" class="ltx_graphics ltx_img_landscape" width="387" height="200" alt="Refer to caption"></span></p>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F5.3.1.1" class="ltx_text" style="font-size:90%;">Figure 5</span>: </span><span id="S4.F5.4.2" class="ltx_text" style="font-size:90%;">Efficiency comparison of communication and data transfer protocols: Average two-way communication time per global epoch and the corresponding standard deviation as the number of clients increases exponentially across various models.</span></figcaption>
</figure>
<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">We evaluate the communication efficiency for different communication and data transfer protocols across different numbers of clients and various model sizes, ranging from a few-byte 1<math id="S4.SS1.p1.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.SS1.p1.1.m1.1a"><mo id="S4.SS1.p1.1.m1.1.1" xref="S4.SS1.p1.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.1.m1.1b"><times id="S4.SS1.p1.1.m1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.1.m1.1c">\times</annotation></semantics></math>1 fully connected (FC) layer to a Vision Transformer (ViT) with hundreds of megabytes. Table <a href="#S4.T2" title="TABLE II ‣ IV-A Communication Efficiency ‣ IV Performance Evaluation ‣ Advances in Appfl: A Comprehensive and Extensible Federated Learning Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag">II</span></a> details the sizes of all models used in our experiments.</p>
</div>
<figure id="S4.T2" class="ltx_table">
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">TABLE II: </span>Sizes of the models used in the experiments.</figcaption>
<table id="S4.T2.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T2.1.2.1" class="ltx_tr">
<th id="S4.T2.1.2.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S4.T2.1.2.1.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Model</span></th>
<th id="S4.T2.1.2.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S4.T2.1.2.1.2.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Params</span></th>
<th id="S4.T2.1.2.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S4.T2.1.2.1.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Size</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T2.1.1" class="ltx_tr">
<td id="S4.T2.1.1.1" class="ltx_td ltx_align_center ltx_border_t">
<span id="S4.T2.1.1.1.1" class="ltx_text" style="font-size:90%;">1</span><math id="S4.T2.1.1.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.T2.1.1.1.m1.1a"><mo mathsize="90%" id="S4.T2.1.1.1.m1.1.1" xref="S4.T2.1.1.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.T2.1.1.1.m1.1b"><times id="S4.T2.1.1.1.m1.1.1.cmml" xref="S4.T2.1.1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.1.1.1.m1.1c">\times</annotation></semantics></math><span id="S4.T2.1.1.1.2" class="ltx_text" style="font-size:90%;">1 FC</span>
</td>
<td id="S4.T2.1.1.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.1.1.2.1" class="ltx_text" style="font-size:90%;">2</span></td>
<td id="S4.T2.1.1.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.1.1.3.1" class="ltx_text" style="font-size:90%;">8 B</span></td>
</tr>
<tr id="S4.T2.1.3.1" class="ltx_tr">
<td id="S4.T2.1.3.1.1" class="ltx_td ltx_align_center">
<span id="S4.T2.1.3.1.1.1" class="ltx_text" style="font-size:90%;">CNN </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T2.1.3.1.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib90" title="" class="ltx_ref">90</a><span id="S4.T2.1.3.1.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite>
</td>
<td id="S4.T2.1.3.1.2" class="ltx_td ltx_align_center"><span id="S4.T2.1.3.1.2.1" class="ltx_text" style="font-size:90%;">1.20M</span></td>
<td id="S4.T2.1.3.1.3" class="ltx_td ltx_align_center"><span id="S4.T2.1.3.1.3.1" class="ltx_text" style="font-size:90%;">4.58 MB</span></td>
</tr>
<tr id="S4.T2.1.4.2" class="ltx_tr">
<td id="S4.T2.1.4.2.1" class="ltx_td ltx_align_center">
<span id="S4.T2.1.4.2.1.1" class="ltx_text" style="font-size:90%;">ResNet18 </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T2.1.4.2.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib91" title="" class="ltx_ref">91</a><span id="S4.T2.1.4.2.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite>
</td>
<td id="S4.T2.1.4.2.2" class="ltx_td ltx_align_center"><span id="S4.T2.1.4.2.2.1" class="ltx_text" style="font-size:90%;">11.17M</span></td>
<td id="S4.T2.1.4.2.3" class="ltx_td ltx_align_center"><span id="S4.T2.1.4.2.3.1" class="ltx_text" style="font-size:90%;">42.66 MB</span></td>
</tr>
<tr id="S4.T2.1.5.3" class="ltx_tr">
<td id="S4.T2.1.5.3.1" class="ltx_td ltx_align_center">
<span id="S4.T2.1.5.3.1.1" class="ltx_text" style="font-size:90%;">ResNet50 </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T2.1.5.3.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib91" title="" class="ltx_ref">91</a><span id="S4.T2.1.5.3.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite>
</td>
<td id="S4.T2.1.5.3.2" class="ltx_td ltx_align_center"><span id="S4.T2.1.5.3.2.1" class="ltx_text" style="font-size:90%;">23.52M</span></td>
<td id="S4.T2.1.5.3.3" class="ltx_td ltx_align_center"><span id="S4.T2.1.5.3.3.1" class="ltx_text" style="font-size:90%;">89.93 MB</span></td>
</tr>
<tr id="S4.T2.1.6.4" class="ltx_tr">
<td id="S4.T2.1.6.4.1" class="ltx_td ltx_align_center">
<span id="S4.T2.1.6.4.1.1" class="ltx_text" style="font-size:90%;">ResNet101 </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T2.1.6.4.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib91" title="" class="ltx_ref">91</a><span id="S4.T2.1.6.4.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite>
</td>
<td id="S4.T2.1.6.4.2" class="ltx_td ltx_align_center"><span id="S4.T2.1.6.4.2.1" class="ltx_text" style="font-size:90%;">42.51M</span></td>
<td id="S4.T2.1.6.4.3" class="ltx_td ltx_align_center"><span id="S4.T2.1.6.4.3.1" class="ltx_text" style="font-size:90%;">162.58 MB</span></td>
</tr>
<tr id="S4.T2.1.7.5" class="ltx_tr">
<td id="S4.T2.1.7.5.1" class="ltx_td ltx_align_center ltx_border_bb">
<span id="S4.T2.1.7.5.1.1" class="ltx_text" style="font-size:90%;">Vision Transformer </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T2.1.7.5.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib92" title="" class="ltx_ref">92</a><span id="S4.T2.1.7.5.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite>
</td>
<td id="S4.T2.1.7.5.2" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T2.1.7.5.2.1" class="ltx_text" style="font-size:90%;">88.22M</span></td>
<td id="S4.T2.1.7.5.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T2.1.7.5.3.1" class="ltx_text" style="font-size:90%;">336.55 MB</span></td>
</tr>
</tbody>
</table>
</figure>
<div id="S4.SS1.p2" class="ltx_para">
<p id="S4.SS1.p2.1" class="ltx_p">In the experiments, each FL client runs on a single core of the CPU-only compute nodes of the Delta supercomputer at the National Center for Supercomputing Applications. Each CPU node contains two 64-core AMD EPYC 7763 “Milan” CPUs with PCIe Gen4 interfaces and 256 GB of RAM. Delta is connected to the NPCF core router and exit infrastructure via two 100 gigabits per second (Gbps) connections. The FL server is hosted on an AWS EC2 x2iedn.2xlarge instance, equipped with 8 virtual CPUs, 256 GB of RAM, and up to 25 Gbps connections. We exponentially increase the number of clients from 2 to 128 across all models, except for the ViT model, which scales only from 2 to 64 because of memory constraints on the client and server hardware. We evaluate gRPC and Globus Compute communication protocols as well as two data transfer methods, AWS S3 buckets and ProxyStore endpoints. Because of the 10 MB data transfer limit with Globus Compute, it is integrated with other data transfer protocols rather than being tested in isolation, resulting in five distinct communication pattern combinations.</p>
</div>
<div id="S4.SS1.p3" class="ltx_para">
<p id="S4.SS1.p3.1" class="ltx_p">Figure <a href="#S4.F5" title="Figure 5 ‣ IV-A Communication Efficiency ‣ IV Performance Evaluation ‣ Advances in Appfl: A Comprehensive and Extensible Federated Learning Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> shows the epoch-wise two-way communication time in seconds for various models using different communication and data transfer protocols. From the plots, we note the following key points: (1) Separating the transmission of data (i.e. model parameters) from task control signals helps communication protocols exceed their maximum data size limitations. (2) Globus Compute consistently incurs longer overheads than does gRPC in transmitting control signals, which is a significant factor when the FL model size is small. (3) While data transfer via ProxyStore endpoints generally results in longer communication times, it offers a free and straightforward solution for protocols such as Globus Compute that have message size restrictions. (4) Data transfer through S3 features relatively low latency and also provides a secure, reliable means to store model checkpoints during training, although it incurs some costs.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS2.5.1.1" class="ltx_text">IV-B</span> </span><span id="S4.SS2.6.2" class="ltx_text ltx_font_italic">Compression Efficiency</span>
</h3>

<figure id="S4.F6" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F6.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2409.11585/assets/x6.png" id="S4.F6.sf1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="358" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F6.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F6.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2409.11585/assets/x7.png" id="S4.F6.sf2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="220" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F6.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F6.2.1.1" class="ltx_text" style="font-size:90%;">Figure 6</span>: </span><span id="S4.F6.3.2" class="ltx_text" style="font-size:90%;">(a) Model sizes for ResNet-50 and ResNet-101 using different lossy compression methods with a relative error bound of 0.01. (b) gRPC two-way communication time for ResNet-50 and ResNet-101 using different lossy compressors, with and without the compression and decompression overhead.</span></figcaption>
</figure>
<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">We assess the efficiency of various data compression algorithms integrated within the <span id="S4.SS2.p1.1.1" class="ltx_text ltx_font_smallcaps">Appfl</span> framework. Specifically, we utilize the lossless compressor blosc <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib84" title="" class="ltx_ref">84</a>]</cite> for tensors with less than 1,024 parameters and lossy compressors SZ2 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib85" title="" class="ltx_ref">85</a>]</cite>, SZ3 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib86" title="" class="ltx_ref">86</a>]</cite>, and ZFP <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib87" title="" class="ltx_ref">87</a>]</cite>, each with a relative error bound of 0.01, for larger tensors. The experiments adhere to the same hardware configurations described in Subsection <a href="#S4.SS1" title="IV-A Communication Efficiency ‣ IV Performance Evaluation ‣ Advances in Appfl: A Comprehensive and Extensible Federated Learning Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">IV-A</span></span></a>, with clients running on Delta and the server on an AWS EC2 instance. We conduct experiments on ResNet-50 and ResNet-101 models, scaling client numbers from 2 to 128. Figure <a href="#S4.F6.sf1" title="In Figure 6 ‣ IV-B Compression Efficiency ‣ IV Performance Evaluation ‣ Advances in Appfl: A Comprehensive and Extensible Federated Learning Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6(a)</span></a> illustrates the reduction in model sizes by 3 to 5 times using different lossy compressors. Notably, previous studies have shown that such levels of lossy compression can preserve model accuracy within a 0.5% margin of uncompressed results <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite>. Figure <a href="#S4.F6.sf2" title="In Figure 6 ‣ IV-B Compression Efficiency ‣ IV Performance Evaluation ‣ Advances in Appfl: A Comprehensive and Extensible Federated Learning Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6(b)</span></a> presents the two-way communication times via gRPC for the two models using various compressors. Solid lines represent times with compression and decompression overheads, whereas dotted lines depict times without. The comparison reveals significant overhead, particularly with SZ2 and SZ3. Despite this, the use of compressors notably reduces communication costs and overall two-way communication times, even under high-bandwidth conditions for both clients and the server.</p>
</div>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS3.5.1.1" class="ltx_text">IV-C</span> </span><span id="S4.SS3.6.2" class="ltx_text ltx_font_italic">Privacy Preservation</span>
</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.4" class="ltx_p">In this subsection we study the impact of differential privacy (DP) techniques on the performance of models trained via FL. We select four tasks in medical domains, where data privacy is paramount, from the FLamby benchmark containing naturally split medical datasets <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib93" title="" class="ltx_ref">93</a>]</cite>. Table <a href="#S4.T3" title="TABLE III ‣ IV-C Privacy Preservation ‣ IV Performance Evaluation ‣ Advances in Appfl: A Comprehensive and Extensible Federated Learning Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag">III</span></a> provides an overview of these tasks. We assess model performance across varying values of privacy loss parameter <math id="S4.SS3.p1.1.m1.1" class="ltx_Math" alttext="\epsilon" display="inline"><semantics id="S4.SS3.p1.1.m1.1a"><mi id="S4.SS3.p1.1.m1.1.1" xref="S4.SS3.p1.1.m1.1.1.cmml">ϵ</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.1.m1.1b"><ci id="S4.SS3.p1.1.m1.1.1.cmml" xref="S4.SS3.p1.1.m1.1.1">italic-ϵ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.1.m1.1c">\epsilon</annotation></semantics></math>, a measure of how much privacy is lost when using DP algorithms, with lower <math id="S4.SS3.p1.2.m2.1" class="ltx_Math" alttext="\epsilon" display="inline"><semantics id="S4.SS3.p1.2.m2.1a"><mi id="S4.SS3.p1.2.m2.1.1" xref="S4.SS3.p1.2.m2.1.1.cmml">ϵ</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.2.m2.1b"><ci id="S4.SS3.p1.2.m2.1.1.cmml" xref="S4.SS3.p1.2.m2.1.1">italic-ϵ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.2.m2.1c">\epsilon</annotation></semantics></math> values signifying larger added noises and enhanced privacy. Figure <a href="#S4.F7" title="Figure 7 ‣ IV-C Privacy Preservation ‣ IV Performance Evaluation ‣ Advances in Appfl: A Comprehensive and Extensible Federated Learning Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> shows the change of model performance throughout the FL training process for these tasks at different <math id="S4.SS3.p1.3.m3.1" class="ltx_Math" alttext="\epsilon" display="inline"><semantics id="S4.SS3.p1.3.m3.1a"><mi id="S4.SS3.p1.3.m3.1.1" xref="S4.SS3.p1.3.m3.1.1.cmml">ϵ</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.3.m3.1b"><ci id="S4.SS3.p1.3.m3.1.1.cmml" xref="S4.SS3.p1.3.m3.1.1">italic-ϵ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.3.m3.1c">\epsilon</annotation></semantics></math> values. The performance metrics represent the average outcomes of five independent trials with different random seeds. The results indicate that a decrease in <math id="S4.SS3.p1.4.m4.1" class="ltx_Math" alttext="\epsilon" display="inline"><semantics id="S4.SS3.p1.4.m4.1a"><mi id="S4.SS3.p1.4.m4.1.1" xref="S4.SS3.p1.4.m4.1.1.cmml">ϵ</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.4.m4.1b"><ci id="S4.SS3.p1.4.m4.1.1.cmml" xref="S4.SS3.p1.4.m4.1.1">italic-ϵ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.4.m4.1c">\epsilon</annotation></semantics></math> values, corresponding to increased privacy preservation, leads to varying degrees of performance degradation across various models and training tasks.</p>
</div>
<figure id="S4.T3" class="ltx_table">
<figcaption class="ltx_caption ltx_centering" style="font-size:70%;"><span class="ltx_tag ltx_tag_table"><span id="S4.T3.4.1.1" class="ltx_text" style="font-size:129%;">TABLE III</span>: </span><span id="S4.T3.5.2" class="ltx_text" style="font-size:129%;">Overview of selected tasks from FLamby.</span></figcaption>
<table id="S4.T3.6" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T3.6.1.1" class="ltx_tr">
<th id="S4.T3.6.1.1.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_th ltx_th_row ltx_border_tt" style="padding-left:1.9pt;padding-right:1.9pt;"></th>
<td id="S4.T3.6.1.1.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_tt" style="padding-left:1.9pt;padding-right:1.9pt;"><span id="S4.T3.6.1.1.2.1" class="ltx_text" style="font-size:70%;">Fed-TCGA-BRCA</span></td>
<td id="S4.T3.6.1.1.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_tt" style="padding-left:1.9pt;padding-right:1.9pt;"><span id="S4.T3.6.1.1.3.1" class="ltx_text" style="font-size:70%;">Fed-Heart-Disease</span></td>
<td id="S4.T3.6.1.1.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_tt" style="padding-left:1.9pt;padding-right:1.9pt;"><span id="S4.T3.6.1.1.4.1" class="ltx_text" style="font-size:70%;">Fed-IXI</span></td>
<td id="S4.T3.6.1.1.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_tt" style="padding-left:1.9pt;padding-right:1.9pt;"><span id="S4.T3.6.1.1.5.1" class="ltx_text" style="font-size:70%;">Fed-ISIC2019</span></td>
</tr>
<tr id="S4.T3.6.2.2" class="ltx_tr">
<th id="S4.T3.6.2.2.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_th ltx_th_row ltx_border_t" style="padding-left:1.9pt;padding-right:1.9pt;"><span id="S4.T3.6.2.2.1.1" class="ltx_text" style="font-size:70%;">Input</span></th>
<td id="S4.T3.6.2.2.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:1.9pt;padding-right:1.9pt;"><span id="S4.T3.6.2.2.2.1" class="ltx_text" style="font-size:70%;">Patient info</span></td>
<td id="S4.T3.6.2.2.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:1.9pt;padding-right:1.9pt;"><span id="S4.T3.6.2.2.3.1" class="ltx_text" style="font-size:70%;">Patient info</span></td>
<td id="S4.T3.6.2.2.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:1.9pt;padding-right:1.9pt;"><span id="S4.T3.6.2.2.4.1" class="ltx_text" style="font-size:70%;">T1WI</span></td>
<td id="S4.T3.6.2.2.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:1.9pt;padding-right:1.9pt;"><span id="S4.T3.6.2.2.5.1" class="ltx_text" style="font-size:70%;">Dermoscopy</span></td>
</tr>
<tr id="S4.T3.6.3.3" class="ltx_tr">
<th id="S4.T3.6.3.3.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_th ltx_th_row" style="padding-left:1.9pt;padding-right:1.9pt;"><span id="S4.T3.6.3.3.1.1" class="ltx_text" style="font-size:70%;">Prediction</span></th>
<td id="S4.T3.6.3.3.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.9pt;padding-right:1.9pt;"><span id="S4.T3.6.3.3.2.1" class="ltx_text" style="font-size:70%;">Risk of death</span></td>
<td id="S4.T3.6.3.3.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.9pt;padding-right:1.9pt;"><span id="S4.T3.6.3.3.3.1" class="ltx_text" style="font-size:70%;">Heart disease</span></td>
<td id="S4.T3.6.3.3.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.9pt;padding-right:1.9pt;"><span id="S4.T3.6.3.3.4.1" class="ltx_text" style="font-size:70%;">Brain mask</span></td>
<td id="S4.T3.6.3.3.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.9pt;padding-right:1.9pt;"><span id="S4.T3.6.3.3.5.1" class="ltx_text" style="font-size:70%;">Melanoma class</span></td>
</tr>
<tr id="S4.T3.6.4.4" class="ltx_tr">
<th id="S4.T3.6.4.4.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_th ltx_th_row" style="padding-left:1.9pt;padding-right:1.9pt;"><span id="S4.T3.6.4.4.1.1" class="ltx_text" style="font-size:70%;">Task type</span></th>
<td id="S4.T3.6.4.4.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.9pt;padding-right:1.9pt;"><span id="S4.T3.6.4.4.2.1" class="ltx_text" style="font-size:70%;">Regression</span></td>
<td id="S4.T3.6.4.4.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.9pt;padding-right:1.9pt;"><span id="S4.T3.6.4.4.3.1" class="ltx_text" style="font-size:70%;">Classification</span></td>
<td id="S4.T3.6.4.4.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.9pt;padding-right:1.9pt;"><span id="S4.T3.6.4.4.4.1" class="ltx_text" style="font-size:70%;">3D Segmentation</span></td>
<td id="S4.T3.6.4.4.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.9pt;padding-right:1.9pt;"><span id="S4.T3.6.4.4.5.1" class="ltx_text" style="font-size:70%;">Classification</span></td>
</tr>
<tr id="S4.T3.6.5.5" class="ltx_tr">
<th id="S4.T3.6.5.5.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_th ltx_th_row" style="padding-left:1.9pt;padding-right:1.9pt;"><span id="S4.T3.6.5.5.1.1" class="ltx_text" style="font-size:70%;">Model</span></th>
<td id="S4.T3.6.5.5.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.9pt;padding-right:1.9pt;">
<span id="S4.T3.6.5.5.2.1" class="ltx_text" style="font-size:70%;">Cox model </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T3.6.5.5.2.2.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib94" title="" class="ltx_ref">94</a><span id="S4.T3.6.5.5.2.3.2" class="ltx_text" style="font-size:70%;">]</span></cite>
</td>
<td id="S4.T3.6.5.5.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.9pt;padding-right:1.9pt;"><span id="S4.T3.6.5.5.3.1" class="ltx_text" style="font-size:70%;">Logistic Reg.</span></td>
<td id="S4.T3.6.5.5.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.9pt;padding-right:1.9pt;">
<span id="S4.T3.6.5.5.4.1" class="ltx_text" style="font-size:70%;">3D U-Net </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T3.6.5.5.4.2.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib95" title="" class="ltx_ref">95</a><span id="S4.T3.6.5.5.4.3.2" class="ltx_text" style="font-size:70%;">]</span></cite>
</td>
<td id="S4.T3.6.5.5.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.9pt;padding-right:1.9pt;">
<span id="S4.T3.6.5.5.5.1" class="ltx_text" style="font-size:70%;">EfficientNet </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T3.6.5.5.5.2.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib96" title="" class="ltx_ref">96</a><span id="S4.T3.6.5.5.5.3.2" class="ltx_text" style="font-size:70%;">]</span></cite>
</td>
</tr>
<tr id="S4.T3.6.6.6" class="ltx_tr">
<th id="S4.T3.6.6.6.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_th ltx_th_row" style="padding-left:1.9pt;padding-right:1.9pt;"><span id="S4.T3.6.6.6.1.1" class="ltx_text" style="font-size:70%;">Metric</span></th>
<td id="S4.T3.6.6.6.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.9pt;padding-right:1.9pt;"><span id="S4.T3.6.6.6.2.1" class="ltx_text" style="font-size:70%;">C-index</span></td>
<td id="S4.T3.6.6.6.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.9pt;padding-right:1.9pt;"><span id="S4.T3.6.6.6.3.1" class="ltx_text" style="font-size:70%;">Accuracy</span></td>
<td id="S4.T3.6.6.6.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.9pt;padding-right:1.9pt;">
<span id="S4.T3.6.6.6.4.1" class="ltx_text" style="font-size:70%;">DICE </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T3.6.6.6.4.2.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib97" title="" class="ltx_ref">97</a><span id="S4.T3.6.6.6.4.3.2" class="ltx_text" style="font-size:70%;">]</span></cite>
</td>
<td id="S4.T3.6.6.6.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.9pt;padding-right:1.9pt;"><span id="S4.T3.6.6.6.5.1" class="ltx_text" style="font-size:70%;">Balanced Acc.</span></td>
</tr>
<tr id="S4.T3.6.7.7" class="ltx_tr">
<th id="S4.T3.6.7.7.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_th ltx_th_row ltx_border_bb" style="padding-left:1.9pt;padding-right:1.9pt;"><span id="S4.T3.6.7.7.1.1" class="ltx_text" style="font-size:70%;"># Clients</span></th>
<td id="S4.T3.6.7.7.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:1.9pt;padding-right:1.9pt;"><span id="S4.T3.6.7.7.2.1" class="ltx_text" style="font-size:70%;">6</span></td>
<td id="S4.T3.6.7.7.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:1.9pt;padding-right:1.9pt;"><span id="S4.T3.6.7.7.3.1" class="ltx_text" style="font-size:70%;">4</span></td>
<td id="S4.T3.6.7.7.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:1.9pt;padding-right:1.9pt;"><span id="S4.T3.6.7.7.4.1" class="ltx_text" style="font-size:70%;">3</span></td>
<td id="S4.T3.6.7.7.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:1.9pt;padding-right:1.9pt;"><span id="S4.T3.6.7.7.5.1" class="ltx_text" style="font-size:70%;">6</span></td>
</tr>
</tbody>
</table>
</figure>
<figure id="S4.F7" class="ltx_figure">
<p id="S4.F7.1" class="ltx_p ltx_align_center"><span id="S4.F7.1.1" class="ltx_text"><img src="/html/2409.11585/assets/x8.png" id="S4.F7.1.1.g1" class="ltx_graphics ltx_img_square" width="461" height="414" alt="Refer to caption"></span></p>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F7.5.2.1" class="ltx_text" style="font-size:90%;">Figure 7</span>: </span><span id="S4.F7.3.1" class="ltx_text" style="font-size:90%;">Change of model performance throughout the FL training on the selected FLamby tasks at different <math id="S4.F7.3.1.m1.1" class="ltx_Math" alttext="\epsilon" display="inline"><semantics id="S4.F7.3.1.m1.1b"><mi id="S4.F7.3.1.m1.1.1" xref="S4.F7.3.1.m1.1.1.cmml">ϵ</mi><annotation-xml encoding="MathML-Content" id="S4.F7.3.1.m1.1c"><ci id="S4.F7.3.1.m1.1.1.cmml" xref="S4.F7.3.1.m1.1.1">italic-ϵ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.F7.3.1.m1.1d">\epsilon</annotation></semantics></math> values.</span></figcaption>
</figure>
</section>
<section id="S4.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS4.5.1.1" class="ltx_text">IV-D</span> </span><span id="S4.SS4.6.2" class="ltx_text ltx_font_italic">Addressing Heterogeneous Clients</span>
</h3>

<figure id="S4.F8" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S4.F8.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2409.11585/assets/x9.png" id="S4.F8.sf1.g1" class="ltx_graphics ltx_centering ltx_img_square" width="461" height="410" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F8.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S4.F8.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2409.11585/assets/x10.png" id="S4.F8.sf2.g1" class="ltx_graphics ltx_centering ltx_img_square" width="461" height="410" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F8.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S4.F8.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2409.11585/assets/x11.png" id="S4.F8.sf3.g1" class="ltx_graphics ltx_centering ltx_img_square" width="461" height="411" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F8.sf3.2.1.1" class="ltx_text" style="font-size:90%;">(c)</span> </span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F8.2.1.1" class="ltx_text" style="font-size:90%;">Figure 8</span>: </span><span id="S4.F8.3.2" class="ltx_text" style="font-size:90%;">(a) Average validation accuracy and the corresponding standard deviation on the partitioned CIFAR-10 dataset for different FL algorithms during the training process. (b) Client resource utilization for algorithms using different schedulers and the average training time per batch for different clients. (c) Visualization of computing resource utilization for three clients under different schedulers, where colored bar represents the computing period and the blank places means idle times.</span></figcaption>
</figure>
<div id="S4.SS4.p1" class="ltx_para">
<p id="S4.SS4.p1.1" class="ltx_p">In this subsection we evaluate the performance and efficiency of different FL algorithms under various synchronicity settings. Specifically, we benchmark five FL algorithms: (1) <span id="S4.SS4.p1.1.1" class="ltx_text ltx_font_typewriter">FedAvg</span>, a widely used synchronous algorithm that updates the global model by averaging all client local models; (2) <span id="S4.SS4.p1.1.2" class="ltx_text ltx_font_typewriter">FedAvgM</span>, another synchronous algorithm, which incorporates momentum on top of <span id="S4.SS4.p1.1.3" class="ltx_text ltx_font_typewriter">FedAvg</span>; (3) <span id="S4.SS4.p1.1.4" class="ltx_text ltx_font_typewriter">FedAsync</span>, which asynchronously updates the global model upon receipt of any local model; (4) <span id="S4.SS4.p1.1.5" class="ltx_text ltx_font_typewriter">FedBuff</span>, which is similar to <span id="S4.SS4.p1.1.6" class="ltx_text ltx_font_typewriter">FedAsync</span> but buffers multiple local models before updating the global model; and (5) <span id="S4.SS4.p1.1.7" class="ltx_text ltx_font_typewriter">FedCompass</span>, which introduces a <span id="S4.SS4.p1.1.8" class="ltx_text ltx_font_italic">COMputing Power AwarenesS Scheduler</span> (<span id="S4.SS4.p1.1.9" class="ltx_text ltx_font_typewriter">Compass</span>) that dynamically adjusts the number of client local training steps based on real-time estimates of client computing power to synchronize the training completion for groups of clients. As for the datasets, we partition the CIFAR-10 dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib98" title="" class="ltx_ref">98</a>]</cite>, one of the most commonly used datasets in evaluating FL algorithms <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib99" title="" class="ltx_ref">99</a>]</cite>, into ten client splits in a non-IID manner, with each client holding data from five to seven classes out of ten classes. All clients use Nvidia A100 GPUs for training, and we simulate a group of heterogeneous clients by assigning different average batch processing times from an exponential distribution.</p>
</div>
<div id="S4.SS4.p2" class="ltx_para">
<p id="S4.SS4.p2.1" class="ltx_p">Figure <a href="#S4.F8.sf1" title="In Figure 8 ‣ IV-D Addressing Heterogeneous Clients ‣ IV Performance Evaluation ‣ Advances in Appfl: A Comprehensive and Extensible Federated Learning Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8(a)</span></a> presents the average validation accuracy and the corresponding standard deviation across five independent runs for each FL algorithm during training. Key observations from the figure include the following. (1) Asynchronous FL algorithms like <span id="S4.SS4.p2.1.1" class="ltx_text ltx_font_typewriter">FedAsync</span> and <span id="S4.SS4.p2.1.2" class="ltx_text ltx_font_typewriter">FedBuff</span>, which use the vanilla asynchronous scheduler, converge to significantly lower global model accuracy compared with synchronous methods, primarily due to the drifting toward faster clients, as the global model gets more updates from faster clients and slower clients’ models become stale. (2) Synchronous algorithms exhibit slower convergence as the server has to wait for the slow clients for aggregation. (3) <span id="S4.SS4.p2.1.3" class="ltx_text ltx_font_typewriter">FedCompass</span> effectively addresses substantial client drift issues and attains high global model accuracy by ensuring nearly simultaneous model arrivals for grouped aggregation. It also achieves quicker convergence than synchronous methods without extensive waiting.</p>
</div>
<div id="S4.SS4.p3" class="ltx_para">
<p id="S4.SS4.p3.1" class="ltx_p">Figure <a href="#S4.F8.sf2" title="In Figure 8 ‣ IV-D Addressing Heterogeneous Clients ‣ IV Performance Evaluation ‣ Advances in Appfl: A Comprehensive and Extensible Federated Learning Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8(b)</span></a> shows the average training time per batch for the ten clients involved in the FL training, as well as the resource utilization, calculated as the ratio of client compute time to total training time, for algorithms using the synchronous, vanilla asynchronous, and <span id="S4.SS4.p3.1.1" class="ltx_text ltx_font_typewriter">Compass</span> asynchronous scheduler. The synchronous scheduler shows the lowest client resource utilization, correlating with training time per batch: the quicker the client, the lower the rutilization. In contrast, the vanilla asynchronous scheduler, which immediately sends any received local model for aggregation and returns the updated global model, allows client resource utilization to approach 100%. Despite full utilization, however, this method results in poorly performing models due to client drift. The <span id="S4.SS4.p3.1.2" class="ltx_text ltx_font_typewriter">Compass</span> scheduler, by estimating client speeds and adjusting training steps accordingly, maintains approximately 90% resource utilization and reduces client drift through timely grouped aggregations. Figure <a href="#S4.F8.sf3" title="In Figure 8 ‣ IV-D Addressing Heterogeneous Clients ‣ IV Performance Evaluation ‣ Advances in Appfl: A Comprehensive and Extensible Federated Learning Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8(c)</span></a> visualizes the resource utilization for three clients under different scheduling scenarios, highlighting the significant resource underutilization of the synchronous scheduler compared with the asynchronous alternatives when client computing resources vary widely.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">V </span><span id="S5.1.1" class="ltx_text ltx_font_smallcaps">Case Study: Extensibility Demonstration</span>
</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">To highlight the versatility and extensibility of the <span id="S5.p1.1.1" class="ltx_text ltx_font_smallcaps">Appfl</span> framework across various FL applications, we present case studies on three distinct FL variants: vertical FL, hierarchical FL, and decentralized FL, all built upon the <span id="S5.p1.1.2" class="ltx_text ltx_font_smallcaps">Appfl</span> framework, illustrating how it can be adapted to different FL paradigms.</p>
</div>
<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S5.SS1.5.1.1" class="ltx_text">V-A</span> </span><span id="S5.SS1.6.2" class="ltx_text ltx_font_italic">Vertical Federated Learning</span>
</h3>

<figure id="S5.F9" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S5.F9.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2409.11585/assets/x12.png" id="S5.F9.sf1.g1" class="ltx_graphics ltx_centering ltx_img_square" width="461" height="411" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F9.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S5.F9.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2409.11585/assets/x13.png" id="S5.F9.sf2.g1" class="ltx_graphics ltx_centering ltx_img_square" width="461" height="419" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F9.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F9.2.1.1" class="ltx_text" style="font-size:90%;">Figure 9</span>: </span><span id="S5.F9.3.2" class="ltx_text" style="font-size:90%;">(a) Comparison of client training data distribution in HFL and VFL. (b) Overview of the VFL process. </span></figcaption>
</figure>
<figure id="S5.F10" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S5.F10.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2409.11585/assets/x14.png" id="S5.F10.sf1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="313" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F10.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S5.F10.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2409.11585/assets/x15.png" id="S5.F10.sf2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="349" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F10.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F10.2.1.1" class="ltx_text" style="font-size:90%;">Figure 10</span>: </span><span id="S5.F10.3.2" class="ltx_text" style="font-size:90%;">(a) Input, hidden, and output dimensions of two-layer perceptrons for the VFL clients and server. (b) Training and validation MSE during the VFL training process.</span></figcaption>
</figure>
<div id="S5.SS1.p1" class="ltx_para">
<p id="S5.SS1.p1.1" class="ltx_p">Vertical federated learning (VFL) is a specialized paradigm of FL where different clients hold distinct features from the same dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib79" title="" class="ltx_ref">79</a>]</cite>. Unlike traditional FL (i.e., horizontal FL) dealing with the same feature space across diverse data samples, VFL enables collaboration among clients that have partially overlapping or non-overlapping features but share the same sample IDs, as illustrated in Figure <a href="#S5.F9.sf1" title="In Figure 9 ‣ V-A Vertical Federated Learning ‣ V Case Study: Extensibility Demonstration ‣ Advances in Appfl: A Comprehensive and Extensible Federated Learning Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9(a)</span></a>. Figure <a href="#S5.F9.sf2" title="In Figure 9 ‣ V-A Vertical Federated Learning ‣ V Case Study: Extensibility Demonstration ‣ Advances in Appfl: A Comprehensive and Extensible Federated Learning Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9(b)</span></a> depicts a typical VFL process. In VFL, rather than training the same model architecture and sharing model parameters, each client possesses its embedding model to process its local data sample features and then sends their embeddings to the server. The server, holding the labels of the client data samples, concatenates the received embeddings to train a central model. It then sends the gradients of the feature embeddings back to the corresponding clients, enabling them to update their local embedding models accordingly.</p>
</div>
<div id="S5.SS1.p2" class="ltx_para">
<p id="S5.SS1.p2.1" class="ltx_p"><span id="S5.SS1.p2.1.1" class="ltx_text ltx_font_smallcaps">Appfl</span> seamlessly supports VFL by providing the VFL trainer and aggregator in the corresponding modules. In this case study, we use the diabetes datasets <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib100" title="" class="ltx_ref">100</a>]</cite> from the <span id="S5.SS1.p2.1.2" class="ltx_text ltx_font_typewriter">scikit-learn</span> library, which contains ten features of 442 data samples. The labels, ranging from 25 to 346, are the responses of interest that quantitatively measure the disease progression. We split the dataset into 80% for training and 20% for validation and use three VFL clients, where clients 1 and 2 possess three patient features and client 3 possesses four. Each of the three clients as well as the server employs a two-layer perceptron with ReLU nonlinear activation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib101" title="" class="ltx_ref">101</a>]</cite> as their embedding models. Figure <a href="#S5.F10.sf1" title="In Figure 10 ‣ V-A Vertical Federated Learning ‣ V Case Study: Extensibility Demonstration ‣ Advances in Appfl: A Comprehensive and Extensible Federated Learning Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10(a)</span></a> presents the input, hidden, and output dimensions of these models. During the training, the server model is updated based on the mean squared error (MSE) loss between the labels and predictions, using the Adam optimizer <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib102" title="" class="ltx_ref">102</a>]</cite> with a learning rate of 0.01. Figure <a href="#S5.F10.sf2" title="In Figure 10 ‣ V-A Vertical Federated Learning ‣ V Case Study: Extensibility Demonstration ‣ Advances in Appfl: A Comprehensive and Extensible Federated Learning Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10(b)</span></a> shows the training and validation MSE throughout the training.</p>
</div>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S5.SS2.5.1.1" class="ltx_text">V-B</span> </span><span id="S5.SS2.6.2" class="ltx_text ltx_font_italic">Hierarchical Federated Learning</span>
</h3>

<figure id="S5.F11" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S5.F11.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2409.11585/assets/x16.png" id="S5.F11.sf1.g1" class="ltx_graphics ltx_centering ltx_img_square" width="461" height="545" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F11.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S5.F11.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2409.11585/assets/x17.png" id="S5.F11.sf2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="355" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F11.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F11.2.1.1" class="ltx_text" style="font-size:90%;">Figure 11</span>: </span><span id="S5.F11.3.2" class="ltx_text" style="font-size:90%;">(a) Topology of the multi-layer HierFL experiments with nine clients, five intermediate servers, and one root server. (b) HierFL validation accuracy for the server and client models, where the accuracy of client models is evaluated after each local training step. </span></figcaption>
</figure>
<div id="S5.SS2.p1" class="ltx_para">
<p id="S5.SS2.p1.1" class="ltx_p">Hierarchical federated learning (HierFL) is also a special type of FL that introduces an additional role, the intermediate server (edge server). This server first aggregates local model parameters from connected clients or child intermediate servers and then forwards the aggregated model to the parent server for further aggregation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib80" title="" class="ltx_ref">80</a>]</cite>. HierFL is particularly beneficial when FL clients are geographically clustered, since placing an intermediate server for these clusters can significantly improve overall communication efficiency. To support HierFL in <span id="S5.SS2.p1.1.1" class="ltx_text ltx_font_smallcaps">Appfl</span>, in addition to the general server agent for the root server and the client agent for the clients, we define an intermediate server agent, similar to the server agent, which handles FL-related requests from connected clients or child intermediate servers by interacting with its parent server.</p>
</div>
<div id="S5.SS2.p2" class="ltx_para">
<p id="S5.SS2.p2.1" class="ltx_p">In this case study we conduct four-tier HierFL experiments involving nine clients, five intermediate servers, and one root server. The MNIST training dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib103" title="" class="ltx_ref">103</a>]</cite> is partitioned into nine heterogeneous client splits, with each client containing training data for only three to five classes. Figure <a href="#S5.F11.sf1" title="In Figure 11 ‣ V-B Hierarchical Federated Learning ‣ V Case Study: Extensibility Demonstration ‣ Advances in Appfl: A Comprehensive and Extensible Federated Learning Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag">11(a)</span></a> illustrates the topology of the HierFL experiments and the client data distribution. Training is conducted over 20 global epochs, with each client performing 100 local steps per epoch using a batch size of 64 and the Adam optimizer with a learning rate of 0.001. The experiments are repeated five times with different random seeds. Figure <a href="#S5.F11.sf2" title="In Figure 11 ‣ V-B Hierarchical Federated Learning ‣ V Case Study: Extensibility Demonstration ‣ Advances in Appfl: A Comprehensive and Extensible Federated Learning Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag">11(b)</span></a> presents the average validation accuracy and standard deviation for both the server model and each client’s local model on the MNIST validation set. We note that the client models are evaluated after local training. Since each client has data for only three to five classes, their local models perform significantly worse than the global model, highlighting the advantages of federated learning in leveraging data from distributed clients to train a more robust ML model.</p>
</div>
</section>
<section id="S5.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S5.SS3.5.1.1" class="ltx_text">V-C</span> </span><span id="S5.SS3.6.2" class="ltx_text ltx_font_italic">Decentralized Federated Learning</span>
</h3>

<div id="S5.SS3.p1" class="ltx_para">
<p id="S5.SS3.p1.1" class="ltx_p">Decentralized federated learning (DFL) is yet another variant of FL that eliminates the need for a central server to aggregate models. Instead, each node trains its local model using its own data, requests model parameters from neighboring clients, and aggregates these with its local model <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib81" title="" class="ltx_ref">81</a>, <a href="#bib.bib104" title="" class="ltx_ref">104</a>]</cite>. <span id="S5.SS3.p1.1.1" class="ltx_text ltx_font_smallcaps">Appfl</span> supports DFL by implementing a DFL node agent that inherits most functionalities of both an FL client and server, enabling it to train local models and handle requests from neighboring clients. In this case study we set up DFL experiments with six nodes, where each node has three neighbors, as shown in Figure <a href="#S5.F12.sf1" title="In Figure 12 ‣ V-C Decentralized Federated Learning ‣ V Case Study: Extensibility Demonstration ‣ Advances in Appfl: A Comprehensive and Extensible Federated Learning Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag">12(a)</span></a>. Each node holds a heterogeneously partitioned MNIST dataset with six to eight classes and trains the model for 20 epochs. During each epoch, the node updates its model for 100 steps with a batch size of 64 using the Adam optimizer with a learning rate of 0.001, then aggregates its local model with those of its three neighbors. The experiment is repeated five times with different random seeds. Figure <a href="#S5.F12.sf2" title="In Figure 12 ‣ V-C Decentralized Federated Learning ‣ V Case Study: Extensibility Demonstration ‣ Advances in Appfl: A Comprehensive and Extensible Federated Learning Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag">12(b)</span></a> presents the average validation accuracy and its standard deviation on the MNIST validation set across the training process for the six DFL nodes.</p>
</div>
<figure id="S5.F12" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S5.F12.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2409.11585/assets/x18.png" id="S5.F12.sf1.g1" class="ltx_graphics ltx_centering ltx_img_square" width="461" height="535" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F12.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S5.F12.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2409.11585/assets/x19.png" id="S5.F12.sf2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="337" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F12.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F12.2.1.1" class="ltx_text" style="font-size:90%;">Figure 12</span>: </span><span id="S5.F12.3.2" class="ltx_text" style="font-size:90%;">(a) Topology of the DFL experiments. (b) DFL validation accuracy for the DFL nodes, where the accuracy is evaluated after aggregating the local models of the neighbor DFL nodes.</span></figcaption>
</figure>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VI </span><span id="S6.1.1" class="ltx_text ltx_font_smallcaps">Conclusion</span>
</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">In this paper we present the recent advancements in <span id="S6.p1.1.1" class="ltx_text ltx_font_smallcaps">Appfl</span>, a redesigned federated learning framework to simplify FL usage by offering comprehensive solutions to various challenges and to advance FL research through an easy-to-use, modular interface that facilitates the seamless integration of new algorithms. We demonstrate the capability and extensibility of <span id="S6.p1.1.2" class="ltx_text ltx_font_smallcaps">Appfl</span> by employing it to benchmark various FL aspects and provide case studies across different FL variants. <span id="S6.p1.1.3" class="ltx_text ltx_font_smallcaps">Appfl</span> is open-sourced under the MIT License, and we actively encourage contributions from the community.</p>
</div>
<div id="S6.p2" class="ltx_para">
<p id="S6.p2.1" class="ltx_p">In our future work we plan to incorporate more advanced privacy-enhancing technologies into the framework, such as secure multi-party computation, homomorphic encryption, and trusted execution environments, to further ensure the security of FL experiments. We will also focus on secure storage and deployment of the FL-trained models, enabling involved clients to efficiently and safely access the trained models for inference. Furthermore, <span id="S6.p2.1.1" class="ltx_text ltx_font_smallcaps">Appfl</span> will be used to backend a web platform that aims to provide federated learning as a service, streamlining the end-to-end process of AI model development for domain scientists, from data preparation through model training to model deployment.</p>
</div>
</section>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_font_smallcaps ltx_title_section">Acknowledgment</h2>

<div id="Sx1.p1" class="ltx_para">
<p id="Sx1.p1.1" class="ltx_p">This research utilizes computing resources provided by the National Artificial Intelligence Research Resource (NAIRR) Pilot, supported by award NAIRR240008. We also gratefully acknowledge Amazon Web Services (AWS) for providing cloud computing credits that were used to assist with benchmarking efforts for this paper.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
K. Crawford, <em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">The atlas of AI: Power, politics, and the planetary costs of artificial intelligence</em>.   Yale University Press, 2021.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
J. Konečnỳ, H. B. McMahan, F. X. Yu, P. Richtárik, A. T. Suresh, and D. Bacon, “Federated learning: Strategies for improving communication efficiency,” <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1610.05492</em>, 2016.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
B. McMahan, E. Moore, D. Ramage, S. Hampson, and B. A. y Arcas, “Communication-efficient learning of deep networks from decentralized data,” in <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">Artificial intelligence and statistics</em>.   PMLR, 2017, pp. 1273–1282.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
Q. Yang, Y. Liu, T. Chen, and Y. Tong, “Federated machine learning: Concept and applications,” <em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">ACM Transactions on Intelligent Systems and Technology (TIST)</em>, vol. 10, no. 2, pp. 1–19, 2019.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
P. Kairouz, H. B. McMahan, B. Avent, A. Bellet, M. Bennis, A. N. Bhagoji, K. Bonawitz, Z. Charles, G. Cormode, R. Cummings <em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Advances and open problems in federated learning,” <em id="bib.bib5.2.2" class="ltx_emph ltx_font_italic">Foundations and Trends® in Machine Learning</em>, vol. 14, no. 1–2, pp. 1–210, 2021.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
S. Pati, U. Baid, B. Edwards, M. Sheller, S.-H. Wang, G. A. Reina, P. Foley, A. Gruzdev, D. Karkada, C. Davatzikos <em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Federated learning enables big data for rare cancer boundary detection,” <em id="bib.bib6.2.2" class="ltx_emph ltx_font_italic">Nature Communications</em>, vol. 13, no. 1, p. 7346, 2022.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
G. Kaissis, A. Ziller, J. Passerat-Palmbach, T. Ryffel, D. Usynin, A. Trask, I. Lima Jr, J. Mancuso, F. Jungmann, M.-M. Steinborn <em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “End-to-end privacy preserving deep learning on multi-institutional medical imaging,” <em id="bib.bib7.2.2" class="ltx_emph ltx_font_italic">Nature Machine Intelligence</em>, vol. 3, no. 6, pp. 473–484, 2021.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
T.-H. Hoang, J. Fuhrman, R. Madduri, M. Li, P. Chaturvedi, Z. Li, K. Kim, M. Ryu, R. Chard, E. Huerta <em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Enabling end-to-end secure federated learning in biomedical research on heterogeneous computing environments with APPFLx,” <em id="bib.bib8.2.2" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2312.08701</em>, 2023.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
G. Wang, C. X. Dang, and Z. Zhou, “Measure contribution of participants in federated learning,” in <em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">2019 IEEE international conference on Big Data (Big Data)</em>.   IEEE, 2019, pp. 2597–2604.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
G. Wang, “Interpret federated learning with shapley values,” <em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1905.04519</em>, 2019.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
S. Bose and K. Kim, “Federated short-term load forecasting with personalization layers for heterogeneous clients,” <em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2309.13194</em>, 2023.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
A. Hard, K. Rao, R. Mathews, S. Ramaswamy, F. Beaufays, S. Augenstein, H. Eichner, C. Kiddon, and D. Ramage, “Federated learning for mobile keyboard prediction,” <em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1811.03604</em>, 2018.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
S. Ramaswamy, R. Mathews, K. Rao, and F. Beaufays, “Federated learning for emoji prediction in a mobile keyboard,” <em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1906.04329</em>, 2019.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
D. Leroy, A. Coucke, T. Lavril, T. Gisselbrecht, and J. Dureau, “Federated learning for keyword spotting,” in <em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">ICASSP 2019-2019 IEEE international conference on acoustics, speech and signal processing (ICASSP)</em>.   IEEE, 2019, pp. 6341–6345.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
T.-M. H. Hsu, H. Qi, and M. Brown, “Measuring the effects of non-identical data distribution for federated visual classification,” <em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1909.06335</em>, 2019.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
T. Li, A. K. Sahu, A. Talwalkar, and V. Smith, “Federated learning: Challenges, methods, and future directions,” <em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">IEEE Signal Processing Magazine</em>, vol. 37, no. 3, pp. 50–60, 2020.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
C. Xu, Y. Qu, Y. Xiang, and L. Gao, “Asynchronous federated learning on heterogeneous devices: A survey,” <em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2109.04269</em>, 2021.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
G. Kaissis, A. Ziller, J. Passerat-Palmbach, T. Ryffel, D. Usynin, A. Trask, I. Lima Jr, J. Mancuso, F. Jungmann, M.-M. Steinborn <em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “End-to-end privacy preserving deep learning on multi-institutional medical imaging,” <em id="bib.bib18.2.2" class="ltx_emph ltx_font_italic">Nature Machine Intelligence</em>, vol. 3, no. 6, pp. 473–484, 2021.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
D. J. Beutel, T. Topal, A. Mathur, X. Qiu, J. Fernandez-Marques, Y. Gao, L. Sani, K. H. Li, T. Parcollet, P. P. B. de Gusmão <em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Flower: A friendly federated learning research framework,” <em id="bib.bib19.2.2" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2007.14390</em>, 2020.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
C. He, S. Li, J. So, X. Zeng, M. Zhang, H. Wang, X. Wang, P. Vepakomma, A. Singh, H. Qiu <em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “FedML: A research library and benchmark for federated machine learning,” <em id="bib.bib20.2.2" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2007.13518</em>, 2020.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
F. Lai, Y. Dai, S. Singapuram, J. Liu, X. Zhu, H. Madhyastha, and M. Chowdhury, “Fedscale: Benchmarking model and system performance of federated learning at scale,” in <em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">International conference on machine learning</em>.   PMLR, 2022, pp. 11 814–11 827.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
M. Ryu, Y. Kim, K. Kim, and R. K. Madduri, “APPFL: open-source software framework for privacy-preserving federated learning,” in <em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">2022 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)</em>.   IEEE, 2022, pp. 1074–1083.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
Z. Li, P. Chaturvedi, S. He, H. Chen, G. Singh, V. Kindratenko, E. A. Huerta, K. Kim, and R. Madduri, “FedCompass: efficient cross-silo federated learning on heterogeneous client devices using a computing power aware scheduler,” <em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2309.14675</em>, 2023.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
R. Chard, Y. Babuji, Z. Li, T. Skluzacek, A. Woodard, B. Blaiszik, I. Foster, and K. Chard, “Funcx: A federated function serving fabric for science,” in <em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 29th International symposium on high-performance parallel and distributed computing</em>, 2020, pp. 65–76.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
J. G. Pauloski, V. Hayot-Sasson, L. Ward, N. Hudson, C. Sabino, M. Baughman, K. Chard, and I. Foster, “Accelerating communications in federated applications with transparent object proxies,” in <em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis</em>, 2023, pp. 1–15.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
G. Wilkins, S. Di, J. C. Calhoun, Z. Li, K. Kim, R. Underwood, R. Mortier, and F. Cappello, “FedSZ: Leveraging error-bounded lossy compression for federated learning communications,” in <em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">2024 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)</em>.   IEEE, 2024, pp. 1187–1188.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
I. Foster, “Globus Online: Accelerating and democratizing science through cloud-based services,” <em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">IEEE Internet Computing</em>, vol. 15, no. 3, pp. 70–73, 2011.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
B. Allen, J. Bresnahan, L. Childers, I. Foster, G. Kandaswamy, R. Kettimuthu, J. Kordas, M. Link, S. Martin, K. Pickett <em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Software as a service for data scientists,” <em id="bib.bib28.2.2" class="ltx_emph ltx_font_italic">Communications of the ACM</em>, vol. 55, no. 2, pp. 81–88, 2012.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
S. Tuecke, R. Ananthakrishnan, K. Chard, M. Lidman, B. McCollam, S. Rosen, and I. Foster, “Globus Auth: A research identity and access management platform,” in <em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">2016 IEEE 12th International Conference on e-Science (e-Science)</em>.   IEEE, 2016, pp. 203–212.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
C. Dwork, “Differential privacy,” in <em id="bib.bib30.1.1" class="ltx_emph ltx_font_italic">International colloquium on automata, languages, and programming</em>.   Springer, 2006, pp. 1–12.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
A. Ghosh, J. Hong, D. Yin, and K. Ramchandran, “Robust federated learning in a heterogeneous environment,” <em id="bib.bib31.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1906.06629</em>, 2019.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
J. Wang, Z. Charles, Z. Xu, G. Joshi, H. B. McMahan, M. Al-Shedivat, G. Andrew, S. Avestimehr, K. Daly, D. Data <em id="bib.bib32.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “A field guide to federated optimization,” <em id="bib.bib32.2.2" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2107.06917</em>, 2021.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
S. P. Karimireddy, S. Kale, M. Mohri, S. Reddi, S. Stich, and A. T. Suresh, “Scaffold: Stochastic controlled averaging for federated learning,” in <em id="bib.bib33.1.1" class="ltx_emph ltx_font_italic">International conference on machine learning</em>.   PMLR, 2020, pp. 5132–5143.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
S. Reddi, Z. Charles, M. Zaheer, Z. Garrett, K. Rush, J. Konečnỳ, S. Kumar, and H. B. McMahan, “Adaptive federated optimization,” <em id="bib.bib34.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2003.00295</em>, 2020.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
C. Xu, Y. Qu, Y. Xiang, and L. Gao, “Asynchronous federated learning on heterogeneous devices: A survey,” <em id="bib.bib35.1.1" class="ltx_emph ltx_font_italic">Computer Science Review</em>, vol. 50, p. 100595, 2023.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock">
C. Xie, S. Koyejo, and I. Gupta, “Asynchronous federated optimization,” <em id="bib.bib36.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1903.03934</em>, 2019.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock">
Y. Chen, Y. Ning, M. Slawski, and H. Rangwala, “Asynchronous online federated learning for edge devices with non-iid data,” in <em id="bib.bib37.1.1" class="ltx_emph ltx_font_italic">2020 IEEE International Conference on Big Data (Big Data)</em>.   IEEE, 2020, pp. 15–24.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock">
J. Nguyen, K. Malik, H. Zhan, A. Yousefpour, M. Rabbat, M. Malek, and D. Huba, “Federated learning with buffered asynchronous aggregation,” in <em id="bib.bib38.1.1" class="ltx_emph ltx_font_italic">International Conference on Artificial Intelligence and Statistics</em>.   PMLR, 2022, pp. 3581–3607.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock">
C. Iakovidou and K. Kim, “Asynchronous federated stochastic optimization with exact averaging for heterogeneous local objectives,” <em id="bib.bib39.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2405.10123</em>, 2024.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock">
K. Bonawitz, H. Eichner, W. Grieskamp, D. Huba, A. Ingerman, V. Ivanov, C. Kiddon, J. Konečnỳ, S. Mazzocchi, B. McMahan <em id="bib.bib40.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Towards federated learning at scale: System design,” <em id="bib.bib40.2.2" class="ltx_emph ltx_font_italic">Proceedings of Machine Learning and Systems</em>, vol. 1, pp. 374–388, 2019.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock">
T. Nishio and R. Yonetani, “Client selection for federated learning with heterogeneous resources in mobile edge,” in <em id="bib.bib41.1.1" class="ltx_emph ltx_font_italic">ICC 2019-2019 IEEE international conference on communications (ICC)</em>.   IEEE, 2019, pp. 1–7.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock">
J. Hao, Y. Zhao, and J. Zhang, “Time efficient federated learning with semi-asynchronous communication,” in <em id="bib.bib42.1.1" class="ltx_emph ltx_font_italic">2020 IEEE 26th International Conference on Parallel and Distributed Systems (ICPADS)</em>.   IEEE, 2020, pp. 156–163.

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock">
Z. Chen, W. Liao, K. Hua, C. Lu, and W. Yu, “Towards asynchronous federated learning for heterogeneous edge-powered Internet of Things,” <em id="bib.bib43.1.1" class="ltx_emph ltx_font_italic">Digital Communications and Networks</em>, vol. 7, no. 3, pp. 317–326, 2021.

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[44]</span>
<span class="ltx_bibblock">
W. Zhuang, C. Chen, and L. Lyu, “When foundation model meets federated learning: Motivations, challenges, and future directions,” <em id="bib.bib44.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2306.15546</em>, 2023.

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[45]</span>
<span class="ltx_bibblock">
W. Kuang, B. Qian, Z. Li, D. Chen, D. Gao, X. Pan, Y. Xie, Y. Li, B. Ding, and J. Zhou, “FederatedScope-LLM: a comprehensive package for fine-tuning large language models in federated learning,” <em id="bib.bib45.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2309.00363</em>, 2023.

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[46]</span>
<span class="ltx_bibblock">
Z. Li, S. He, P. Chaturvedi, V. Kindratenko, E. A. Huerta, K. Kim, and R. Madduri, “Secure federated learning across heterogeneous cloud and high-performance computing resources – a case study on federated fine-tuning of LLaMA 2,” <em id="bib.bib46.1.1" class="ltx_emph ltx_font_italic">Computing in Science &amp; Engineering</em>, 2024.

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[47]</span>
<span class="ltx_bibblock">
C. Chen, X. Feng, J. Zhou, J. Yin, and X. Zheng, “Federated large language model: A position paper,” <em id="bib.bib47.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2307.08925</em>, 2023.

</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[48]</span>
<span class="ltx_bibblock">
Y. J. Cho, J. Wang, and G. Joshi, “Client selection in federated learning: Convergence analysis and power-of-choice selection strategies,” <em id="bib.bib48.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2010.01243</em>, 2020.

</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[49]</span>
<span class="ltx_bibblock">
Y. J. Cho, D. Jhunjhunwala, T. Li, V. Smith, and G. Joshi, “To federate or not to federate: Incentivizing client participation in federated learning,” <em id="bib.bib49.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2205.14840</em>, 2022.

</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[50]</span>
<span class="ltx_bibblock">
D. Jhunjhunwala, P. Sharma, A. Nagarkatti, and G. Joshi, “FedVARP: Tackling the variance due to partial client participation in federated learning,” in <em id="bib.bib50.1.1" class="ltx_emph ltx_font_italic">Uncertainty in Artificial Intelligence</em>.   PMLR, 2022, pp. 906–916.

</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[51]</span>
<span class="ltx_bibblock">
Y. J. Cho, J. Wang, and G. Joshi, “Towards understanding biased client selection in federated learning,” in <em id="bib.bib51.1.1" class="ltx_emph ltx_font_italic">International Conference on Artificial Intelligence and Statistics</em>.   PMLR, 2022, pp. 10 351–10 375.

</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[52]</span>
<span class="ltx_bibblock">
F. Sattler, S. Wiedemann, K.-R. Müller, and W. Samek, “Robust and communication-efficient federated learning from non-iid data,” <em id="bib.bib52.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Neural Networks and Learning Systems</em>, vol. 31, no. 9, pp. 3400–3413, 2019.

</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[53]</span>
<span class="ltx_bibblock">
F. Haddadpour, M. M. Kamani, A. Mokhtari, and M. Mahdavi, “Federated learning with compression: Unified analysis and sharp guarantees,” in <em id="bib.bib53.1.1" class="ltx_emph ltx_font_italic">International Conference on Artificial Intelligence and Statistics</em>.   PMLR, 2021, pp. 2350–2358.

</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[54]</span>
<span class="ltx_bibblock">
S. Caldas, S. M. K. Duddu, P. Wu, T. Li, J. Konečnỳ, H. B. McMahan, V. Smith, and A. Talwalkar, “Leaf: A benchmark for federated settings,” <em id="bib.bib54.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1812.01097</em>, 2018.

</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[55]</span>
<span class="ltx_bibblock">
Y. Xie, Z. Wang, D. Gao, D. Chen, L. Yao, W. Kuang, Y. Li, B. Ding, and J. Zhou, “FederatedScope: A flexible federated learning platform for heterogeneity,” <em id="bib.bib55.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2204.05011</em>, 2022.

</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[56]</span>
<span class="ltx_bibblock">
H. R. Roth, Y. Cheng, Y. Wen, I. Yang, Z. Xu, Y.-T. Hsieh, K. Kersten, A. Harouni, C. Zhao, K. Lu <em id="bib.bib56.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “NVIDIA FLARE: Federated learning from simulation to real-world,” <em id="bib.bib56.2.2" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2210.13291</em>, 2022.

</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[57]</span>
<span class="ltx_bibblock">
P. Foley, M. J. Sheller, B. Edwards, S. Pati, W. Riviera, M. Sharma, P. N. Moorthy, S.-h. Wang, J. Martin, P. Mirhaji <em id="bib.bib57.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “OpenFL: the open federated learning library,” <em id="bib.bib57.2.2" class="ltx_emph ltx_font_italic">Physics in Medicine &amp; Biology</em>, vol. 67, no. 21, p. 214001, 2022.

</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[58]</span>
<span class="ltx_bibblock">
Z. Wang, X. Fan, Z. Peng, X. Li, Z. Yang, M. Feng, Z. Yang, X. Liu, and C. Wang, “LGo: A fully customizable federated learning platform,” <em id="bib.bib58.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2306.12079</em>, 2023.

</span>
</li>
<li id="bib.bib59" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[59]</span>
<span class="ltx_bibblock">
D. Zeng, S. Liang, X. Hu, H. Wang, and Z. Xu, “FedLab: a flexible federated learning framework,” <em id="bib.bib59.1.1" class="ltx_emph ltx_font_italic">Journal of Machine Learning Research</em>, vol. 24, no. 100, pp. 1–7, 2023.

</span>
</li>
<li id="bib.bib60" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[60]</span>
<span class="ltx_bibblock">
B. Zhao, K. R. Mopuri, and H. Bilen, “idlg: Improved deep leakage from gradients,” <em id="bib.bib60.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2001.02610</em>, 2020.

</span>
</li>
<li id="bib.bib61" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[61]</span>
<span class="ltx_bibblock">
J. Geiping, H. Bauermeister, H. Dröge, and M. Moeller, “Inverting gradients-how easy is it to break privacy in federated learning?” <em id="bib.bib61.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>, vol. 33, pp. 16 937–16 947, 2020.

</span>
</li>
<li id="bib.bib62" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[62]</span>
<span class="ltx_bibblock">
H. Yin, A. Mallya, A. Vahdat, J. M. Alvarez, J. Kautz, and P. Molchanov, “See through gradients: Image batch recovery via gradinversion,” in <em id="bib.bib62.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</em>, 2021, pp. 16 337–16 346.

</span>
</li>
<li id="bib.bib63" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[63]</span>
<span class="ltx_bibblock">
A. Hatamizadeh, H. Yin, P. Molchanov, A. Myronenko, W. Li, P. Dogra, A. Feng, M. G. Flores, J. Kautz, D. Xu <em id="bib.bib63.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Do gradient inversion attacks make federated learning unsafe?” <em id="bib.bib63.2.2" class="ltx_emph ltx_font_italic">IEEE Transactions on Medical Imaging</em>, vol. 42, no. 7, pp. 2044–2056, 2023.

</span>
</li>
<li id="bib.bib64" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[64]</span>
<span class="ltx_bibblock">
Y. Lin, S. Han, H. Mao, Y. Wang, and W. J. Dally, “Deep gradient compression: Reducing the communication bandwidth for distributed training,” <em id="bib.bib64.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1712.01887</em>, 2017.

</span>
</li>
<li id="bib.bib65" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[65]</span>
<span class="ltx_bibblock">
Y. Tsuzuku, H. Imachi, and T. Akiba, “Variance-based gradient compression for efficient distributed deep learning,” <em id="bib.bib65.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1802.06058</em>, 2018.

</span>
</li>
<li id="bib.bib66" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[66]</span>
<span class="ltx_bibblock">
Y. Aono, T. Hayashi, L. Wang, S. Moriai <em id="bib.bib66.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Privacy-preserving deep learning via additively homomorphic encryption,” <em id="bib.bib66.2.2" class="ltx_emph ltx_font_italic">IEEE Transactions on Information Forensics and Security</em>, vol. 13, no. 5, pp. 1333–1345, 2017.

</span>
</li>
<li id="bib.bib67" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[67]</span>
<span class="ltx_bibblock">
L. Lamport, R. Shostak, and M. Pease, “The Byzantine generals problem,” in <em id="bib.bib67.1.1" class="ltx_emph ltx_font_italic">Concurrency: the works of Leslie Lamport</em>.   Machinery, 2019, pp. 203–226.

</span>
</li>
<li id="bib.bib68" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[68]</span>
<span class="ltx_bibblock">
V. Shejwalkar and A. Houmansadr, “Manipulating the byzantine: Optimizing model poisoning attacks and defenses for federated learning,” in <em id="bib.bib68.1.1" class="ltx_emph ltx_font_italic">NDSS</em>, 2021.

</span>
</li>
<li id="bib.bib69" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[69]</span>
<span class="ltx_bibblock">
E. Bagdasaryan, A. Veit, Y. Hua, D. Estrin, and V. Shmatikov, “How to backdoor federated learning,” in <em id="bib.bib69.1.1" class="ltx_emph ltx_font_italic">International conference on artificial intelligence and statistics</em>.   PMLR, 2020, pp. 2938–2948.

</span>
</li>
<li id="bib.bib70" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[70]</span>
<span class="ltx_bibblock">
X. Cao, M. Fang, J. Liu, and N. Z. Gong, “FLTrust: Byzantine-robust federated learning via trust bootstrapping,” <em id="bib.bib70.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2012.13995</em>, 2020.

</span>
</li>
<li id="bib.bib71" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[71]</span>
<span class="ltx_bibblock">
X. Zhou, M. Xu, Y. Wu, and N. Zheng, “Deep model poisoning attack on federated learning,” <em id="bib.bib71.1.1" class="ltx_emph ltx_font_italic">Future Internet</em>, vol. 13, no. 3, p. 73, 2021.

</span>
</li>
<li id="bib.bib72" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[72]</span>
<span class="ltx_bibblock">
V. Tolpegin, S. Truex, M. E. Gursoy, and L. Liu, “Data poisoning attacks against federated learning systems,” in <em id="bib.bib72.1.1" class="ltx_emph ltx_font_italic">Computer security–ESORICs 2020: 25th European symposium on research in computer security, ESORICs 2020, guildford, UK, September 14–18, 2020, proceedings, part i 25</em>.   Springer, 2020, pp. 480–501.

</span>
</li>
<li id="bib.bib73" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[73]</span>
<span class="ltx_bibblock">
M. Fang, X. Cao, J. Jia, and N. Gong, “Local model poisoning attacks to <math id="bib.bib73.1.m1.1" class="ltx_Math" alttext="\{" display="inline"><semantics id="bib.bib73.1.m1.1a"><mo stretchy="false" id="bib.bib73.1.m1.1.1" xref="bib.bib73.1.m1.1.1.cmml">{</mo><annotation-xml encoding="MathML-Content" id="bib.bib73.1.m1.1b"><ci id="bib.bib73.1.m1.1.1.cmml" xref="bib.bib73.1.m1.1.1">{</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib73.1.m1.1c">\{</annotation></semantics></math>Byzantine-Robust<math id="bib.bib73.2.m2.1" class="ltx_Math" alttext="\}" display="inline"><semantics id="bib.bib73.2.m2.1a"><mo stretchy="false" id="bib.bib73.2.m2.1.1" xref="bib.bib73.2.m2.1.1.cmml">}</mo><annotation-xml encoding="MathML-Content" id="bib.bib73.2.m2.1b"><ci id="bib.bib73.2.m2.1.1.cmml" xref="bib.bib73.2.m2.1.1">}</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib73.2.m2.1c">\}</annotation></semantics></math> federated learning,” in <em id="bib.bib73.3.1" class="ltx_emph ltx_font_italic">29th USENIX security symposium (USENIX Security 20)</em>, 2020, pp. 1605–1622.

</span>
</li>
<li id="bib.bib74" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[74]</span>
<span class="ltx_bibblock">
P. Blanchard, E. M. El Mhamdi, R. Guerraoui, and J. Stainer, “Machine learning with adversaries: Byzantine tolerant gradient descent,” <em id="bib.bib74.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>, vol. 30, 2017.

</span>
</li>
<li id="bib.bib75" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[75]</span>
<span class="ltx_bibblock">
D. Yin, Y. Chen, R. Kannan, and P. Bartlett, “Byzantine-robust distributed learning: Towards optimal statistical rates,” in <em id="bib.bib75.1.1" class="ltx_emph ltx_font_italic">International conference on machine learning</em>.   Pmlr, 2018, pp. 5650–5659.

</span>
</li>
<li id="bib.bib76" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[76]</span>
<span class="ltx_bibblock">
C. Xie, S. Koyejo, and I. Gupta, “Zeno: Distributed stochastic gradient descent with suspicion-based fault-tolerance,” in <em id="bib.bib76.1.1" class="ltx_emph ltx_font_italic">International Conference on Machine Learning</em>.   PMLR, 2019, pp. 6893–6901.

</span>
</li>
<li id="bib.bib77" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[77]</span>
<span class="ltx_bibblock">
S. Prakash and A. S. Avestimehr, “Mitigating Byzantine attacks in federated learning,” <em id="bib.bib77.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2010.07541</em>, 2020.

</span>
</li>
<li id="bib.bib78" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[78]</span>
<span class="ltx_bibblock">
Z. Li, S. He, P. Chaturvedi, T.-H. Hoang, M. Ryu, E. Huerta, V. Kindratenko, J. Fuhrman, M. Giger, R. Chard <em id="bib.bib78.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “APPFLx: providing privacy-preserving cross-silo federated learning as a service,” in <em id="bib.bib78.2.2" class="ltx_emph ltx_font_italic">2023 IEEE 19th International Conference on e-Science (e-Science)</em>.   IEEE, 2023, pp. 1–4.

</span>
</li>
<li id="bib.bib79" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[79]</span>
<span class="ltx_bibblock">
Y. Liu, Y. Kang, T. Zou, Y. Pu, Y. He, X. Ye, Y. Ouyang, Y.-Q. Zhang, and Q. Yang, “Vertical federated learning: Concepts, advances, and challenges,” <em id="bib.bib79.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Knowledge and Data Engineering</em>, 2024.

</span>
</li>
<li id="bib.bib80" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[80]</span>
<span class="ltx_bibblock">
M. S. H. Abad, E. Ozfatura, D. Gunduz, and O. Ercetin, “Hierarchical federated learning across heterogeneous cellular networks,” in <em id="bib.bib80.1.1" class="ltx_emph ltx_font_italic">ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>.   IEEE, 2020, pp. 8866–8870.

</span>
</li>
<li id="bib.bib81" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[81]</span>
<span class="ltx_bibblock">
A. Lalitha, S. Shekhar, T. Javidi, and F. Koushanfar, “Fully decentralized federated learning,” in <em id="bib.bib81.1.1" class="ltx_emph ltx_font_italic">Third workshop on bayesian deep learning (NeurIPS)</em>, vol. 2, 2018.

</span>
</li>
<li id="bib.bib82" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[82]</span>
<span class="ltx_bibblock">
Y. Collet and M. Kucherawy, “Zstandard compression and the application/zstd media type,” Tech. Rep., 2018.

</span>
</li>
<li id="bib.bib83" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[83]</span>
<span class="ltx_bibblock">
P. Deutsch, “GZIP file format specification version 4.3,” Tech. Rep., 1996.

</span>
</li>
<li id="bib.bib84" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[84]</span>
<span class="ltx_bibblock">
Blosc Development Team. (2009-2023) A fast, compressed and persistent data store library. Https://blosc.org.

</span>
</li>
<li id="bib.bib85" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[85]</span>
<span class="ltx_bibblock">
X. Liang, S. Di, D. Tao, S. Li, S. Li, H. Guo, Z. Chen, and F. Cappello, “Error-controlled lossy compression optimized for high compression ratios of scientific datasets,” in <em id="bib.bib85.1.1" class="ltx_emph ltx_font_italic">2018 IEEE International Conference on Big Data (Big Data)</em>.   IEEE, 2018, pp. 438–447.

</span>
</li>
<li id="bib.bib86" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[86]</span>
<span class="ltx_bibblock">
“SZ—3: A modular framework for composing prediction-based error-bounded lossy compressors, author=Liang, Xin and Zhao, Kai and Di, Sheng and Li, Sihuan and Underwood, Robert and Gok, Ali M and Tian, Jiannan and Deng, Junjing and Calhoun, Jon C and Tao, Dingwen and others, journal=IEEE Transactions on Big Data, volume=9, number=2, pages=485–498, year=2022, publisher=IEEE.”

</span>
</li>
<li id="bib.bib87" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[87]</span>
<span class="ltx_bibblock">
P. Lindstrom, “Fixed-rate compressed floating-point arrays,” <em id="bib.bib87.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Visualization and Computer Graphics</em>, vol. 20, no. 12, pp. 2674–2683, 2014.

</span>
</li>
<li id="bib.bib88" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[88]</span>
<span class="ltx_bibblock">
S. Bose, Y. Zhang, and K. Kim, “Addressing heterogeneity in federated load forecasting with personalization layers,” <em id="bib.bib88.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2404.01517</em>, 2024.

</span>
</li>
<li id="bib.bib89" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[89]</span>
<span class="ltx_bibblock">
S. Zhou and G. Y. Li, “Communication-efficient ADMM-based federated learning,” <em id="bib.bib89.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2110.15318</em>, 2021.

</span>
</li>
<li id="bib.bib90" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[90]</span>
<span class="ltx_bibblock">
Y. LeCun, B. Boser, J. S. Denker, D. Henderson, R. E. Howard, W. Hubbard, and L. D. Jackel, “Backpropagation applied to handwritten zip code recognition,” <em id="bib.bib90.1.1" class="ltx_emph ltx_font_italic">Neural Computation</em>, vol. 1, no. 4, pp. 541–551, 1989.

</span>
</li>
<li id="bib.bib91" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[91]</span>
<span class="ltx_bibblock">
K. He, X. Zhang, S. Ren, and J. Sun, “Deep residual learning for image recognition,” in <em id="bib.bib91.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE conference on computer vision and pattern recognition</em>, 2016, pp. 770–778.

</span>
</li>
<li id="bib.bib92" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[92]</span>
<span class="ltx_bibblock">
A. Dosovitskiy, L. Beyer, A. Kolesnikov, D. Weissenborn, X. Zhai, T. Unterthiner, M. Dehghani, M. Minderer, G. Heigold, S. Gelly <em id="bib.bib92.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “An image is worth 16x16 words: Transformers for image recognition at scale,” <em id="bib.bib92.2.2" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2010.11929</em>, 2020.

</span>
</li>
<li id="bib.bib93" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[93]</span>
<span class="ltx_bibblock">
J. Ogier du Terrail, S.-S. Ayed, E. Cyffers, F. Grimberg, C. He, R. Loeb, P. Mangold, T. Marchand, O. Marfoq, E. Mushtaq <em id="bib.bib93.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “FLamby: Datasets and benchmarks for cross-silo federated learning in realistic healthcare settings,” <em id="bib.bib93.2.2" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>, vol. 35, pp. 5315–5334, 2022.

</span>
</li>
<li id="bib.bib94" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[94]</span>
<span class="ltx_bibblock">
D. R. Cox, “Regression models and life-tables,” <em id="bib.bib94.1.1" class="ltx_emph ltx_font_italic">Journal of the Royal Statistical Society: Series B (Methodological)</em>, vol. 34, no. 2, pp. 187–202, 1972.

</span>
</li>
<li id="bib.bib95" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[95]</span>
<span class="ltx_bibblock">
Ö. Çiçek, A. Abdulkadir, S. S. Lienkamp, T. Brox, and O. Ronneberger, “3D U-Net: learning dense volumetric segmentation from sparse annotation,” in <em id="bib.bib95.1.1" class="ltx_emph ltx_font_italic">Medical Image Computing and Computer-Assisted Intervention–MICCAI 2016: 19th International Conference, Athens, Greece, October 17-21, 2016, Proceedings, Part II 19</em>.   Springer, 2016, pp. 424–432.

</span>
</li>
<li id="bib.bib96" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[96]</span>
<span class="ltx_bibblock">
M. Tan and Q. Le, “EfficientNet: Rethinking model scaling for convolutional neural networks,” in <em id="bib.bib96.1.1" class="ltx_emph ltx_font_italic">International conference on machine learning</em>.   PMLR, 2019, pp. 6105–6114.

</span>
</li>
<li id="bib.bib97" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[97]</span>
<span class="ltx_bibblock">
L. R. Dice, “Measures of the amount of ecologic association between species,” <em id="bib.bib97.1.1" class="ltx_emph ltx_font_italic">Ecology</em>, vol. 26, no. 3, pp. 297–302, 1945.

</span>
</li>
<li id="bib.bib98" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[98]</span>
<span class="ltx_bibblock">
A. Krizhevsky, G. Hinton <em id="bib.bib98.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Learning multiple layers of features from tiny images,” 2009.

</span>
</li>
<li id="bib.bib99" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[99]</span>
<span class="ltx_bibblock">
X. Ma, J. Zhu, Z. Lin, S. Chen, and Y. Qin, “A state-of-the-art survey on solving non-iid data in federated learning,” <em id="bib.bib99.1.1" class="ltx_emph ltx_font_italic">Future Generation Computer Systems</em>, vol. 135, pp. 244–258, 2022.

</span>
</li>
<li id="bib.bib100" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[100]</span>
<span class="ltx_bibblock">
B. Efron, T. Hastie, I. Johnstone, and R. Tibshirani, “Least angle regression,” <em id="bib.bib100.1.1" class="ltx_emph ltx_font_italic">Ann. Statist.</em>, vol. 32, no. 2, pp. 407–499, 2004.

</span>
</li>
<li id="bib.bib101" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[101]</span>
<span class="ltx_bibblock">
V. Nair and G. E. Hinton, “Rectified linear units improve restricted Boltzmann machines,” in <em id="bib.bib101.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 27th international conference on machine learning (ICML-10)</em>, 2010, pp. 807–814.

</span>
</li>
<li id="bib.bib102" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[102]</span>
<span class="ltx_bibblock">
D. P. Kingma and J. Ba, “Adam: A method for stochastic optimization,” <em id="bib.bib102.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1412.6980</em>, 2014.

</span>
</li>
<li id="bib.bib103" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[103]</span>
<span class="ltx_bibblock">
Y. LeCun, “The MNIST database of handwritten digits,” <em id="bib.bib103.1.1" class="ltx_emph ltx_font_italic">http://yann. lecun. com/exdb/mnist/</em>, 1998.

</span>
</li>
<li id="bib.bib104" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[104]</span>
<span class="ltx_bibblock">
T. Sun, D. Li, and B. Wang, “Decentralized federated averaging,” <em id="bib.bib104.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Pattern Analysis and Machine Intelligence</em>, vol. 45, no. 4, pp. 4289–4301, 2022.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2409.11584" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2409.11585" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2409.11585">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2409.11585" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2409.11586" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Sat Oct  5 21:04:24 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
