<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Green Recommender Systems: Optimizing Dataset Size for Energy-Efficient Algorithm Performance</title>
<!--Generated on Sat Oct 12 03:53:32 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2410.09359v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.09359v1#S1" title="In Green Recommender Systems: Optimizing Dataset Size for Energy-Efficient Algorithm Performance"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.09359v1#S2" title="In Green Recommender Systems: Optimizing Dataset Size for Energy-Efficient Algorithm Performance"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Related Work</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.09359v1#S3" title="In Green Recommender Systems: Optimizing Dataset Size for Energy-Efficient Algorithm Performance"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Methodology</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.09359v1#S3.SS1" title="In 3 Methodology ‣ Green Recommender Systems: Optimizing Dataset Size for Energy-Efficient Algorithm Performance"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Datasets &amp; Preprocessing</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.09359v1#S3.SS2" title="In 3 Methodology ‣ Green Recommender Systems: Optimizing Dataset Size for Energy-Efficient Algorithm Performance"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Data Splitting and Downsampling</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.09359v1#S3.SS3" title="In 3 Methodology ‣ Green Recommender Systems: Optimizing Dataset Size for Energy-Efficient Algorithm Performance"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>Algorithms and Evaluation</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.09359v1#S4" title="In Green Recommender Systems: Optimizing Dataset Size for Energy-Efficient Algorithm Performance"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Results &amp; Conclusion</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.09359v1#S4.SS0.SSS1" title="In 4 Results &amp; Conclusion ‣ Green Recommender Systems: Optimizing Dataset Size for Energy-Efficient Algorithm Performance"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.0.1 </span><span class="ltx_text ltx_font_bold">Observations</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.09359v1#S4.SS0.SSS2" title="In 4 Results &amp; Conclusion ‣ Green Recommender Systems: Optimizing Dataset Size for Energy-Efficient Algorithm Performance"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.0.2 </span><span class="ltx_text ltx_font_bold">Interpretation</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.09359v1#S4.SS0.SSS3" title="In 4 Results &amp; Conclusion ‣ Green Recommender Systems: Optimizing Dataset Size for Energy-Efficient Algorithm Performance"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.0.3 </span><span class="ltx_text ltx_font_bold">Conclusion</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.09359v1#S4.SS0.SSS4" title="In 4 Results &amp; Conclusion ‣ Green Recommender Systems: Optimizing Dataset Size for Energy-Efficient Algorithm Performance"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.0.4 </span><span class="ltx_text ltx_font_bold">Acknowledgment</span></span></a></li>
</ol>
</li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line"><span class="ltx_note ltx_role_institutetext" id="id1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">institutetext: </span>University of Siegen, Department of Electrical Engineering and Computer Science, Germany </span></span></span><span class="ltx_note ltx_role_institutetext" id="id2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_note_type">institutetext: </span>Recommender-Systems.com, Siegen, Germany
<br class="ltx_break"/><span class="ltx_note ltx_role_email" id="id2.1"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_note_type">email: </span>joeran.beel@uni-siegen.de</span></span></span>
<br class="ltx_break"/><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.recommender-systems.com" title="">https://www.recommender-systems.com</a> </span></span></span>
<h1 class="ltx_title ltx_title_document">Green Recommender Systems: Optimizing Dataset Size for Energy-Efficient Algorithm Performance</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Ardalan Arabzadeh
</span><span class="ltx_author_notes">11</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Tobias Vente
</span><span class="ltx_author_notes">11</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Joeran Beel
</span><span class="ltx_author_notes">1122</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id1.1">As recommender systems become increasingly prevalent, the environmental impact and energy efficiency of training these large-scale models have come under scrutiny. This paper investigates the potential for energy-efficient algorithm performance by optimizing dataset sizes through downsampling techniques. We conducted experiments on the MovieLens 100K, 1M, 10M and Amazon Toys and Games datasets, analyzing the performance of various recommender algorithms under different portions of dataset size. Our results indicate that while more training data generally leads to higher performance in algorithms, certain algorithms, such as FunkSVD and BiasedMF, particularly in cases involving more unbalanced and sparse dataset like Amazon Toys and Games, maintain high-quality recommendations with up to 50% reduction in training data, achieving nDCG@10 scores within <math alttext="\sim" class="ltx_Math" display="inline" id="id1.1.m1.1"><semantics id="id1.1.m1.1a"><mo id="id1.1.m1.1.1" xref="id1.1.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="id1.1.m1.1b"><csymbol cd="latexml" id="id1.1.m1.1.1.cmml" xref="id1.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="id1.1.m1.1c">\sim</annotation><annotation encoding="application/x-llamapun" id="id1.1.m1.1d">∼</annotation></semantics></math>13% of their full dataset performance. These findings suggest that strategic dataset reduction can decrease computational and environmental costs without substantially compromising recommendation quality. This study advances sustainable and green recommender systems by providing actionable insights for reducing energy consumption while maintaining effectiveness.
<br class="ltx_break"/></p>
<p class="ltx_p" id="id2.id1"><span class="ltx_text ltx_font_bold" id="id2.id1.1">Keywords</span>: Sustainability, Green RecSys, Dataset Downsampling, Energy Efficiency, Environmental Impact.

<br class="ltx_break"/></p>
<p class="ltx_p" id="id3.id2"><span class="ltx_text ltx_font_bold" id="id3.id2.1">Reference</span>: Arabzadeh, Ardalan; Vente, Tobias; Beel, Joeran. 2024. Green Recommender Systems: Optimizing Dataset Size for Energy-Efficient Algorithm Performance. In: <span class="ltx_text ltx_font_italic" id="id3.id2.2">International Workshop on Recommender Systems for Sustainability and Social Good (RecSoGood) at the 18th ACM Conference on Recommender Systems (ACM RecSys)</span>.</p>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Advancements in recommender systems have enhanced user experience. However, these advancements came at a substantial computational and energy cost <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09359v1#bib.bib35" title="">35</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.09359v1#bib.bib30" title="">30</a>]</cite>. Large datasets do not only increase operational expenses but also result in higher energy consumption and carbon emissions, contributing to a more significant environmental impact <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09359v1#bib.bib30" title="">30</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.09359v1#bib.bib35" title="">35</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.09359v1#bib.bib1" title="">1</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.09359v1#bib.bib16" title="">16</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.09359v1#bib.bib31" title="">31</a>]</cite>. In extreme cases, energy consumption between datasets differs by factor 1,444, such as between LastFM vs. Yelp with the DGCF algorithm <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09359v1#bib.bib35" title="">35</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">Given the environmental and computational challenges associated with large datasets, it’s important to question whether using the entire datasets is always necessary. For instance, datasets like MovieLens 10M are frequently employed in training recommender systems. But is it necessary to use 10 million instances, especially with simple baseline algorithms? Or would downsampling the dataset to e.g. 10% suffices, which, in turn, might save 90% of energy? Similarly, dataset size might be an important factor when choosing datasets for recommender-system experiments <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09359v1#bib.bib10" title="">10</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">In our work, we investigate whether downsampling the dataset can lead to an acceptable trade-off between energy efficiency and the performance of recommender algorithms. We see our work in the context of "Green Recommender Systems" as defined by Beel et al. as follows <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09359v1#bib.bib9" title="">9</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S1.p4">
<blockquote class="ltx_quote" id="S1.p4.1">
<p class="ltx_p" id="S1.p4.1.1"><span class="ltx_text ltx_font_italic" id="S1.p4.1.1.1">“Green Recommender Systems” are recommender systems designed to minimize their environmental impact throughout their life cycle - from research and design to implementation and operation. Green Recommender Systems typically aim to match the performance of traditional systems but may also accept trade-offs in accuracy or other metrics to prioritize sustainability. Minimizing environmental impact typically but not necessarily means minimizing energy consumption and CO<sub class="ltx_sub" id="S1.p4.1.1.1.1">2</sub> emissions.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09359v1#bib.bib9" title="">9</a>]</cite></p>
</blockquote>
</div>
<div class="ltx_para ltx_noindent" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">For our current work, we hypothesize that by downsampling recommender system datasets, we can save time, energy, and CO2 emissions, while obtaining nearly the same performance as with the full datasets.</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">The field of green recommender systems has only started evolving recently <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09359v1#bib.bib30" title="">30</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.09359v1#bib.bib35" title="">35</a>]</cite>. We also recently proposed "e-fold cross-validation", an energy-efficient alternative to k-fold cross-validation <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09359v1#bib.bib11" title="">11</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.09359v1#bib.bib23" title="">23</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.09359v1#bib.bib5" title="">5</a>]</cite>. Wegmeth et al. introduced EMERS, a tool to measure the electricity consumption of recommender system experiments <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09359v1#bib.bib36" title="">36</a>]</cite>. Also, judging on the "accepted papers" list of the RecSoGood workshop, more related work is to be published very soon <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09359v1#bib.bib26" title="">26</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.09359v1#bib.bib32" title="">32</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S2.p2">
<p class="ltx_p" id="S2.p2.1">While the "green" concept in recommender systems is new, other disciplines, like Automated Machine Learning, explore options to save energy for a longer time <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09359v1#bib.bib27" title="">27</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.09359v1#bib.bib2" title="">2</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.09359v1#bib.bib13" title="">13</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.09359v1#bib.bib20" title="">20</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.09359v1#bib.bib33" title="">33</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.09359v1#bib.bib14" title="">14</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.09359v1#bib.bib29" title="">29</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S2.p3">
<p class="ltx_p" id="S2.p3.1">In the domain of recommender systems, several studies have explored the impact of dataset size on the efficiency of algorithmic performance, which aligns the key focus of this study. Notably, Bentzer and Thulin explore the trade-off between accuracy and computational efficiency in collaborative filtering algorithms under limited data conditions <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09359v1#bib.bib12" title="">12</a>]</cite>. They found that IBCF algorithm performs better in terms of accuracy with smaller datasets compared to SVD algorithm, while SVD outperforms IBCF in terms of speed and scalability with larger datasets. Their study highlights the performance differences between these two algorithms but does not address how other algorithms perform under similar constraints. This gap is relevant to our research, which seeks to evaluate a wider range of algorithms for optimizing both energy efficiency and performance.</p>
</div>
<div class="ltx_para" id="S2.p4">
<p class="ltx_p" id="S2.p4.1">Additionally, Jain and Jindal’s review emphasizes that strategic sampling and filtering can enhance recommendation efficiency by improving computational speed and accuracy<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09359v1#bib.bib21" title="">21</a>]</cite>. However, their review lacks experimental validation of how these techniques impact algorithm performance with varying dataset sizes. Our study addresses this gap by empirically evaluating these effects on recommender systems. Judging based on the paper’s title and abstract, Spillo et al. appear to have conducted research similar to ours <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09359v1#bib.bib31" title="">31</a>]</cite>. However, at the time of conducting our research and writing our manuscript, the work of Spillo et al. was not yet publicly available but only announced on the ACM Recommender Systems conference website as an accepted paper.</p>
</div>
<div class="ltx_para" id="S2.p5">
<p class="ltx_p" id="S2.p5.1">It is worth mentioning that most papers and experiments focusing on downsampling and data efficiency are predominantly conducted in domains like (automated) machine learning, AI and computer vision <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09359v1#bib.bib27" title="">27</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.09359v1#bib.bib2" title="">2</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.09359v1#bib.bib13" title="">13</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.09359v1#bib.bib20" title="">20</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.09359v1#bib.bib33" title="">33</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.09359v1#bib.bib14" title="">14</a>]</cite>, with more extensive research compared to the recommender systems domain. Moreover, studies within this broader field also corroborate the potential benefits of downsampling. Research by Zogaj et al. demonstrates that reducing dataset sizes can enhance both computational efficiency and predictive accuracy in genetic programming-based AutoML systems<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09359v1#bib.bib37" title="">37</a>]</cite>. Their experiments show that downsampling large datasets can even in some cases result in better performance than using the full dataset, with shorter search times.</p>
</div>
<div class="ltx_para" id="S2.p6">
<p class="ltx_p" id="S2.p6.1">These studies underscore and evaluate the potential benefits of downsampling and its impact on model performance, but are not directly applicable to traditional recommender system algorithms, where such effects remain underexplored. Especially when thinking of automated recommender systems (AutoRecSys <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09359v1#bib.bib19" title="">19</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.09359v1#bib.bib3" title="">3</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.09359v1#bib.bib34" title="">34</a>]</cite>), where large spaces of configurations must be searched, energy efficiency is fundamentally important.</p>
</div>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Methodology</h2>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Datasets &amp; Preprocessing</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">We used four datasets for our experiment: <span class="ltx_text ltx_font_bold" id="S3.SS1.p1.1.1">MovieLens 100K</span>, <span class="ltx_text ltx_font_bold" id="S3.SS1.p1.1.2">MovieLens 1M</span>, <span class="ltx_text ltx_font_bold" id="S3.SS1.p1.1.3">MovieLens 10M</span>, and <span class="ltx_text ltx_font_bold" id="S3.SS1.p1.1.4">Amazon Toys and Games</span>.
The MovieLens datasets feature relatively balanced ratings across a scale from 1 to 5. In contrast, the Amazon Toys and Games dataset exhibits a skewed distribution, with <math alttext="\sim" class="ltx_Math" display="inline" id="S3.SS1.p1.1.m1.1"><semantics id="S3.SS1.p1.1.m1.1a"><mo id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.1b"><csymbol cd="latexml" id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.1c">\sim</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.1.m1.1d">∼</annotation></semantics></math>90% of ratings concentrated in the 4 and 5 ranges.
The following preprocessing steps were applied to the datasets:
removal of duplicate rows, averaging duplicate ratings, and applying 10-core pruning to retain users and items with at least 10 interactions.</p>
</div>
<div class="ltx_para" id="S3.SS1.p2">
<p class="ltx_p" id="S3.SS1.p2.1">The dataset details before and after preprocessing are in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.09359v1#S3.T1" title="Table 1 ‣ 3.1 Datasets &amp; Preprocessing ‣ 3 Methodology ‣ Green Recommender Systems: Optimizing Dataset Size for Energy-Efficient Algorithm Performance"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
<figure class="ltx_table" id="S3.T1">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Basic information of datasets before and after preprocessing</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S3.T1.1" style="width:433.6pt;height:91.2pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-138.4pt,29.1pt) scale(0.610456891465225,0.610456891465225) ;">
<table class="ltx_tabular ltx_align_middle" id="S3.T1.1.1">
<tr class="ltx_tr" id="S3.T1.1.1.1">
<td class="ltx_td ltx_border_l ltx_border_r ltx_border_t" id="S3.T1.1.1.1.1"></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="5" id="S3.T1.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.1.2.1">Before Preprocessing</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="5" id="S3.T1.1.1.1.3"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.1.3.1">After Preprocessing</span></td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.1.2">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="S3.T1.1.1.2.1"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.2.1.1">Dataset</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.2.2"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.2.2.1">#Users</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.2.3"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.2.3.1">#Items</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.2.4"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.2.4.1">#Interactions</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.2.5">
<span class="ltx_text" id="S3.T1.1.1.2.5.1"></span> <span class="ltx_text" id="S3.T1.1.1.2.5.2">
<span class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.2.5.2.1">
<span class="ltx_tr" id="S3.T1.1.1.2.5.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.2.5.2.1.1.1"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.2.5.2.1.1.1.1">Avg.</span></span></span>
<span class="ltx_tr" id="S3.T1.1.1.2.5.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.2.5.2.1.2.1"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.2.5.2.1.2.1.1">#Int. per</span></span></span>
<span class="ltx_tr" id="S3.T1.1.1.2.5.2.1.3">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.2.5.2.1.3.1"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.2.5.2.1.3.1.1">user</span></span></span>
</span></span><span class="ltx_text" id="S3.T1.1.1.2.5.3"></span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.2.6">
<span class="ltx_text" id="S3.T1.1.1.2.6.1"></span> <span class="ltx_text" id="S3.T1.1.1.2.6.2">
<span class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.2.6.2.1">
<span class="ltx_tr" id="S3.T1.1.1.2.6.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.2.6.2.1.1.1"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.2.6.2.1.1.1.1">Avg.</span></span></span>
<span class="ltx_tr" id="S3.T1.1.1.2.6.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.2.6.2.1.2.1"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.2.6.2.1.2.1.1">#Int. per</span></span></span>
<span class="ltx_tr" id="S3.T1.1.1.2.6.2.1.3">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.2.6.2.1.3.1"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.2.6.2.1.3.1.1">item</span></span></span>
</span></span><span class="ltx_text" id="S3.T1.1.1.2.6.3"></span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.2.7"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.2.7.1">#Users</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.2.8"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.2.8.1">#Items</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.2.9"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.2.9.1">#Interactions</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.2.10">
<span class="ltx_text" id="S3.T1.1.1.2.10.1"></span> <span class="ltx_text" id="S3.T1.1.1.2.10.2">
<span class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.2.10.2.1">
<span class="ltx_tr" id="S3.T1.1.1.2.10.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.2.10.2.1.1.1"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.2.10.2.1.1.1.1">Avg.</span></span></span>
<span class="ltx_tr" id="S3.T1.1.1.2.10.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.2.10.2.1.2.1"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.2.10.2.1.2.1.1">#Int. per</span></span></span>
<span class="ltx_tr" id="S3.T1.1.1.2.10.2.1.3">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.2.10.2.1.3.1"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.2.10.2.1.3.1.1">user</span></span></span>
</span></span><span class="ltx_text" id="S3.T1.1.1.2.10.3"></span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.2.11">
<span class="ltx_text" id="S3.T1.1.1.2.11.1"></span> <span class="ltx_text" id="S3.T1.1.1.2.11.2">
<span class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.2.11.2.1">
<span class="ltx_tr" id="S3.T1.1.1.2.11.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.2.11.2.1.1.1"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.2.11.2.1.1.1.1">Avg.</span></span></span>
<span class="ltx_tr" id="S3.T1.1.1.2.11.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.2.11.2.1.2.1"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.2.11.2.1.2.1.1">#Int. per</span></span></span>
<span class="ltx_tr" id="S3.T1.1.1.2.11.2.1.3">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.2.11.2.1.3.1"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.2.11.2.1.3.1.1">item</span></span></span>
</span></span><span class="ltx_text" id="S3.T1.1.1.2.11.3"></span></td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.1.3">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="S3.T1.1.1.3.1">MovieLens 100K</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.3.2">943</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.3.3">1,682</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.3.4">100,000</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.3.5">106</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.3.6">59</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.3.7">943</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.3.8">1,152</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.3.9">97,953</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.3.10">103</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.3.11">85</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.1.4">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="S3.T1.1.1.4.1">MovieLens 1M</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.1.1.4.2">6,040</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.1.1.4.3">3,706</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.1.1.4.4">1,000,209</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.1.1.4.5">165</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.1.1.4.6">269</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.1.1.4.7">6,040</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.1.1.4.8">3,260</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.1.1.4.9">998,539</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.1.1.4.10">165</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.1.1.4.11">306</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.1.5">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="S3.T1.1.1.5.1">MovieLens 10M</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.1.1.5.2">69,878</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.1.1.5.3">10,677</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.1.1.5.4">10,000,054</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.1.1.5.5">143</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.1.1.5.6">936</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.1.1.5.7">69,878</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.1.1.5.8">9708</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.1.1.5.9">9,995,471</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.1.1.5.10">143</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.1.1.5.11">1029</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.1.6">
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r" id="S3.T1.1.1.6.1">Amazon Toys and Games</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r" id="S3.T1.1.1.6.2">208,180</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r" id="S3.T1.1.1.6.3">78,772</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r" id="S3.T1.1.1.6.4">1,828,971</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r" id="S3.T1.1.1.6.5">8</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r" id="S3.T1.1.1.6.6">23</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r" id="S3.T1.1.1.6.7">11,609</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r" id="S3.T1.1.1.6.8">8,443</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r" id="S3.T1.1.1.6.9">202,721</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r" id="S3.T1.1.1.6.10">17</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r" id="S3.T1.1.1.6.11">24</td>
</tr>
</table>
</span></div>
</figure>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Data Splitting and Downsampling</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">We applied a User-Based Split<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09359v1#bib.bib24" title="">24</a>]</cite>, with 10% of each user’s interactions randomly selected for the test set, 10% for validation, and 80% for training. The validation set was used for hyperparameter tuning, maintaining a comparable size between the validation and test sets to account for the impact of the training-to-validation/test ratio on results, as highlighted in prior research<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09359v1#bib.bib15" title="">15</a>]</cite>. The training set was downsampled to various proportions (10%, 20%, 30%, up to 100%) by randomly selecting different portions of each user’s interactions. This approach ensures consistency in user representation across all sets while varying the number of interactions in the training set.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Algorithms and Evaluation</h3>
<div class="ltx_para" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.1">We trained the following algorithms on the downsampled training sets using the LensKit <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09359v1#bib.bib17" title="">17</a>]</cite> and RecPack <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09359v1#bib.bib25" title="">25</a>]</cite> libraries:</p>
</div>
<figure class="ltx_table" id="S3.T2">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Information of algorithms used in our experiment</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S3.T2.1" style="width:433.6pt;height:55.8pt;vertical-align:-1.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-8.9pt,1.1pt) scale(0.960693561460805,0.960693561460805) ;">
<table class="ltx_tabular ltx_align_middle" id="S3.T2.1.1">
<tr class="ltx_tr" id="S3.T2.1.1.1">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="S3.T2.1.1.1.1" style="padding:0.9pt 2.0pt;"><span class="ltx_text ltx_font_bold" id="S3.T2.1.1.1.1.1" style="font-size:90%;">Algorithms</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.1.2" style="padding:0.9pt 2.0pt;">
<div class="ltx_inline-block ltx_transformed_outer" id="S3.T2.1.1.1.2.1" style="width:16.3pt;height:16.3pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="width:16.9pt;transform:translate(-0.3pt,-5.08pt) rotate(-45deg) ;">
<p class="ltx_p" id="S3.T2.1.1.1.2.1.1"><span class="ltx_text" id="S3.T2.1.1.1.2.1.1.1" style="font-size:90%;">Bias</span></p>
</span></div>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.1.3" style="padding:0.9pt 2.0pt;">
<div class="ltx_inline-block ltx_transformed_outer" id="S3.T2.1.1.1.3.1" style="width:27.5pt;height:27.5pt;vertical-align:-1.2pt;"><span class="ltx_transformed_inner" style="width:30.9pt;transform:translate(-1.7pt,-7.64pt) rotate(-45deg) ;">
<p class="ltx_p" id="S3.T2.1.1.1.3.1.1"><span class="ltx_text" id="S3.T2.1.1.1.3.1.1.1" style="font-size:90%;">Popular</span></p>
</span></div>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.1.4" style="padding:0.9pt 2.0pt;">
<div class="ltx_inline-block ltx_transformed_outer" id="S3.T2.1.1.1.4.1" style="width:27.8pt;height:27.8pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="width:33.1pt;transform:translate(-2.64pt,-10.8pt) rotate(-45deg) ;">
<p class="ltx_p" id="S3.T2.1.1.1.4.1.1"><span class="ltx_text" id="S3.T2.1.1.1.4.1.1.1" style="font-size:90%;">Random</span></p>
</span></div>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.1.5" style="padding:0.9pt 2.0pt;">
<div class="ltx_inline-block ltx_transformed_outer" id="S3.T2.1.1.1.5.1" style="width:31.4pt;height:31.4pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="width:38.3pt;transform:translate(-3.44pt,-12.65pt) rotate(-45deg) ;">
<p class="ltx_p" id="S3.T2.1.1.1.5.1.1"><span class="ltx_text" id="S3.T2.1.1.1.5.1.1.1" style="font-size:90%;">UserKNN</span></p>
</span></div>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.1.6" style="padding:0.9pt 2.0pt;">
<div class="ltx_inline-block ltx_transformed_outer" id="S3.T2.1.1.1.6.1" style="width:31.7pt;height:31.7pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="width:38.8pt;transform:translate(-3.5pt,-12.8pt) rotate(-45deg) ;">
<p class="ltx_p" id="S3.T2.1.1.1.6.1.1"><span class="ltx_text" id="S3.T2.1.1.1.6.1.1.1" style="font-size:90%;">ItemKNN</span></p>
</span></div>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.1.7" style="padding:0.9pt 2.0pt;">
<div class="ltx_inline-block ltx_transformed_outer" id="S3.T2.1.1.1.7.1" style="width:32.7pt;height:32.7pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="width:40.1pt;transform:translate(-3.66pt,-13.24pt) rotate(-45deg) ;">
<p class="ltx_p" id="S3.T2.1.1.1.7.1.1"><span class="ltx_text" id="S3.T2.1.1.1.7.1.1.1" style="font-size:90%;">BiasedMF</span></p>
</span></div>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.1.8" style="padding:0.9pt 2.0pt;">
<div class="ltx_inline-block ltx_transformed_outer" id="S3.T2.1.1.1.8.1" style="width:31.6pt;height:31.6pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="width:38.5pt;transform:translate(-3.43pt,-12.7pt) rotate(-45deg) ;">
<p class="ltx_p" id="S3.T2.1.1.1.8.1.1"><span class="ltx_text" id="S3.T2.1.1.1.8.1.1.1" style="font-size:90%;">FunkSVD</span></p>
</span></div>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.1.9" style="padding:0.9pt 2.0pt;">
<div class="ltx_inline-block ltx_transformed_outer" id="S3.T2.1.1.1.9.1" style="width:34.9pt;height:34.9pt;vertical-align:-1.2pt;"><span class="ltx_transformed_inner" style="width:41.4pt;transform:translate(-3.23pt,-11.35pt) rotate(-45deg) ;">
<p class="ltx_p" id="S3.T2.1.1.1.9.1.1"><span class="ltx_text" id="S3.T2.1.1.1.9.1.1.1" style="font-size:90%;">Popularity</span></p>
</span></div>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.1.10" style="padding:0.9pt 2.0pt;">
<div class="ltx_inline-block ltx_transformed_outer" id="S3.T2.1.1.1.10.1" style="width:31.7pt;height:31.7pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="width:38.8pt;transform:translate(-3.5pt,-12.8pt) rotate(-45deg) ;">
<p class="ltx_p" id="S3.T2.1.1.1.10.1.1"><span class="ltx_text" id="S3.T2.1.1.1.10.1.1.1" style="font-size:90%;">ItemKNN</span></p>
</span></div>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.1.11" style="padding:0.9pt 2.0pt;">
<div class="ltx_inline-block ltx_transformed_outer" id="S3.T2.1.1.1.11.1" style="width:17.5pt;height:17.5pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="width:18.6pt;transform:translate(-0.55pt,-5.68pt) rotate(-45deg) ;">
<p class="ltx_p" id="S3.T2.1.1.1.11.1.1"><span class="ltx_text" id="S3.T2.1.1.1.11.1.1.1" style="font-size:90%;">SVD</span></p>
</span></div>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.1.12" style="padding:0.9pt 2.0pt;">
<div class="ltx_inline-block ltx_transformed_outer" id="S3.T2.1.1.1.12.1" style="width:19.1pt;height:19.1pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="width:20.9pt;transform:translate(-0.88pt,-6.48pt) rotate(-45deg) ;">
<p class="ltx_p" id="S3.T2.1.1.1.12.1.1"><span class="ltx_text" id="S3.T2.1.1.1.12.1.1.1" style="font-size:90%;">NMF</span></p>
</span></div>
</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.1.2">
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r ltx_border_t" id="S3.T2.1.1.2.1" style="padding:0.9pt 2.0pt;"><span class="ltx_text ltx_font_bold" id="S3.T2.1.1.2.1.1" style="font-size:90%;">Library</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S3.T2.1.1.2.2" style="padding:0.9pt 2.0pt;"><span class="ltx_text" id="S3.T2.1.1.2.2.1" style="font-size:90%;">LensKit</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S3.T2.1.1.2.3" style="padding:0.9pt 2.0pt;"><span class="ltx_text" id="S3.T2.1.1.2.3.1" style="font-size:90%;">LensKit</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S3.T2.1.1.2.4" style="padding:0.9pt 2.0pt;"><span class="ltx_text" id="S3.T2.1.1.2.4.1" style="font-size:90%;">LensKit</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S3.T2.1.1.2.5" style="padding:0.9pt 2.0pt;"><span class="ltx_text" id="S3.T2.1.1.2.5.1" style="font-size:90%;">LensKit</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S3.T2.1.1.2.6" style="padding:0.9pt 2.0pt;"><span class="ltx_text" id="S3.T2.1.1.2.6.1" style="font-size:90%;">LensKit</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S3.T2.1.1.2.7" style="padding:0.9pt 2.0pt;"><span class="ltx_text" id="S3.T2.1.1.2.7.1" style="font-size:90%;">LensKit</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S3.T2.1.1.2.8" style="padding:0.9pt 2.0pt;"><span class="ltx_text" id="S3.T2.1.1.2.8.1" style="font-size:90%;">LensKit</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S3.T2.1.1.2.9" style="padding:0.9pt 2.0pt;"><span class="ltx_text" id="S3.T2.1.1.2.9.1" style="font-size:90%;">RecPack</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S3.T2.1.1.2.10" style="padding:0.9pt 2.0pt;"><span class="ltx_text" id="S3.T2.1.1.2.10.1" style="font-size:90%;">RecPack</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S3.T2.1.1.2.11" style="padding:0.9pt 2.0pt;"><span class="ltx_text" id="S3.T2.1.1.2.11.1" style="font-size:90%;">RecPack</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S3.T2.1.1.2.12" style="padding:0.9pt 2.0pt;"><span class="ltx_text" id="S3.T2.1.1.2.12.1" style="font-size:90%;">RecPack</span></td>
</tr>
</table>
</span></div>
</figure>
<div class="ltx_para" id="S3.SS3.p2">
<p class="ltx_p" id="S3.SS3.p2.1">Performance was evaluated using the nDCG@10 metric, ensuring that all libraries adhered to an identical standard calculation logic to facilitate a fair comparison of results across algorithms<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09359v1#bib.bib28" title="">28</a>]</cite>.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Results &amp; Conclusion</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">Our research investigated the impact of downsampling on the efficiency of recommender system algorithms by analyzing performance metrics and dataset characteristics. Variations in user/item interaction densities and rating distributions, as discussed in subsection 3.1, impact algorithm performance. Preprocessing facilitated consistent evaluations across varying dataset sizes. Before presenting the experimental results (Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.09359v1#S4.F1" title="Figure 1 ‣ 4.0.1 Observations ‣ 4 Results &amp; Conclusion ‣ Green Recommender Systems: Optimizing Dataset Size for Energy-Efficient Algorithm Performance"><span class="ltx_text ltx_ref_tag">1</span></a>), it is useful to estimate the potential environmental benefits of the downsampling strategy proposed in this work, specifically in terms of reducing carbon footprint and CO2e emissions, with a calculation example where the training set is downsampled to 50% of its original size.</p>
</div>
<div class="ltx_para" id="S4.p2">
<p class="ltx_p" id="S4.p2.1">Based on our observations and calculations, downsampling the training data to 50% reduces the runtime for training and evaluation phases to <math alttext="\sim" class="ltx_Math" display="inline" id="S4.p2.1.m1.1"><semantics id="S4.p2.1.m1.1a"><mo id="S4.p2.1.m1.1.1" xref="S4.p2.1.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S4.p2.1.m1.1b"><csymbol cd="latexml" id="S4.p2.1.m1.1.1.cmml" xref="S4.p2.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.1.m1.1c">\sim</annotation><annotation encoding="application/x-llamapun" id="S4.p2.1.m1.1d">∼</annotation></semantics></math>72% of the runtime required for the full dataset, on average. Furthermore, the energy consumption for a single run of a recommender algorithm on one dataset is estimated at 0.51 kWh<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09359v1#bib.bib35" title="">35</a>]</cite>. Assuming 10 hyperparameter configurations per algorithm and using the global average conversion factor of 481 gCO2e per kWh<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09359v1#bib.bib18" title="">18</a>]</cite>, and accounting for a potential increase by a factor of 40 to consider preliminary tasks such as algorithm prototyping, initial tests, debugging, and re-runs<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09359v1#bib.bib35" title="">35</a>]</cite>, we estimate the potential carbon equivalent emissions savings from downsampling the training set to 50% compared to the full set per algorithm per dataset as follows:</p>
<table class="ltx_equation ltx_eqn_table" id="S4.Ex1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="(100\%-72\%)\times 0.51\,\text{kWh}\times 10\times 481\,\text{gCO2e/kWh}\times
4%
0\approx 27.4\,\text{KgCO2e}." class="ltx_Math" display="block" id="S4.Ex1.m1.1"><semantics id="S4.Ex1.m1.1a"><mrow id="S4.Ex1.m1.1.1.1" xref="S4.Ex1.m1.1.1.1.1.cmml"><mrow id="S4.Ex1.m1.1.1.1.1" xref="S4.Ex1.m1.1.1.1.1.cmml"><mrow id="S4.Ex1.m1.1.1.1.1.1" xref="S4.Ex1.m1.1.1.1.1.1.cmml"><mrow id="S4.Ex1.m1.1.1.1.1.1.1" xref="S4.Ex1.m1.1.1.1.1.1.1.cmml"><mrow id="S4.Ex1.m1.1.1.1.1.1.1.1" xref="S4.Ex1.m1.1.1.1.1.1.1.1.cmml"><mrow id="S4.Ex1.m1.1.1.1.1.1.1.1.1" xref="S4.Ex1.m1.1.1.1.1.1.1.1.1.cmml"><mrow id="S4.Ex1.m1.1.1.1.1.1.1.1.1.1" xref="S4.Ex1.m1.1.1.1.1.1.1.1.1.1.cmml"><mrow id="S4.Ex1.m1.1.1.1.1.1.1.1.1.1.1.1" xref="S4.Ex1.m1.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mo id="S4.Ex1.m1.1.1.1.1.1.1.1.1.1.1.1.2" stretchy="false" xref="S4.Ex1.m1.1.1.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S4.Ex1.m1.1.1.1.1.1.1.1.1.1.1.1.1" xref="S4.Ex1.m1.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mrow id="S4.Ex1.m1.1.1.1.1.1.1.1.1.1.1.1.1.2" xref="S4.Ex1.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml"><mn id="S4.Ex1.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.2" xref="S4.Ex1.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.2.cmml">100</mn><mo id="S4.Ex1.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.1" xref="S4.Ex1.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.1.cmml">%</mo></mrow><mo id="S4.Ex1.m1.1.1.1.1.1.1.1.1.1.1.1.1.1" xref="S4.Ex1.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml">−</mo><mrow id="S4.Ex1.m1.1.1.1.1.1.1.1.1.1.1.1.1.3" xref="S4.Ex1.m1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml"><mn id="S4.Ex1.m1.1.1.1.1.1.1.1.1.1.1.1.1.3.2" xref="S4.Ex1.m1.1.1.1.1.1.1.1.1.1.1.1.1.3.2.cmml">72</mn><mo id="S4.Ex1.m1.1.1.1.1.1.1.1.1.1.1.1.1.3.1" xref="S4.Ex1.m1.1.1.1.1.1.1.1.1.1.1.1.1.3.1.cmml">%</mo></mrow></mrow><mo id="S4.Ex1.m1.1.1.1.1.1.1.1.1.1.1.1.3" rspace="0.055em" stretchy="false" xref="S4.Ex1.m1.1.1.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow><mo id="S4.Ex1.m1.1.1.1.1.1.1.1.1.1.2" rspace="0.222em" xref="S4.Ex1.m1.1.1.1.1.1.1.1.1.1.2.cmml">×</mo><mn id="S4.Ex1.m1.1.1.1.1.1.1.1.1.1.3" xref="S4.Ex1.m1.1.1.1.1.1.1.1.1.1.3.cmml">0.51</mn></mrow><mo id="S4.Ex1.m1.1.1.1.1.1.1.1.1.2" lspace="0.170em" xref="S4.Ex1.m1.1.1.1.1.1.1.1.1.2.cmml">⁢</mo><mtext id="S4.Ex1.m1.1.1.1.1.1.1.1.1.3" xref="S4.Ex1.m1.1.1.1.1.1.1.1.1.3a.cmml">kWh</mtext></mrow><mo id="S4.Ex1.m1.1.1.1.1.1.1.1.2" lspace="0.222em" rspace="0.222em" xref="S4.Ex1.m1.1.1.1.1.1.1.1.2.cmml">×</mo><mn id="S4.Ex1.m1.1.1.1.1.1.1.1.3" xref="S4.Ex1.m1.1.1.1.1.1.1.1.3.cmml">10</mn><mo id="S4.Ex1.m1.1.1.1.1.1.1.1.2a" lspace="0.222em" rspace="0.222em" xref="S4.Ex1.m1.1.1.1.1.1.1.1.2.cmml">×</mo><mn id="S4.Ex1.m1.1.1.1.1.1.1.1.4" xref="S4.Ex1.m1.1.1.1.1.1.1.1.4.cmml">481</mn></mrow><mo id="S4.Ex1.m1.1.1.1.1.1.1.2" lspace="0.170em" xref="S4.Ex1.m1.1.1.1.1.1.1.2.cmml">⁢</mo><mtext id="S4.Ex1.m1.1.1.1.1.1.1.3" xref="S4.Ex1.m1.1.1.1.1.1.1.3a.cmml">gCO2e/kWh</mtext></mrow><mo id="S4.Ex1.m1.1.1.1.1.1.2" lspace="0.222em" rspace="0.222em" xref="S4.Ex1.m1.1.1.1.1.1.2.cmml">×</mo><mn id="S4.Ex1.m1.1.1.1.1.1.3" xref="S4.Ex1.m1.1.1.1.1.1.3.cmml">40</mn></mrow><mo id="S4.Ex1.m1.1.1.1.1.2" xref="S4.Ex1.m1.1.1.1.1.2.cmml">≈</mo><mrow id="S4.Ex1.m1.1.1.1.1.3" xref="S4.Ex1.m1.1.1.1.1.3.cmml"><mn id="S4.Ex1.m1.1.1.1.1.3.2" xref="S4.Ex1.m1.1.1.1.1.3.2.cmml">27.4</mn><mo id="S4.Ex1.m1.1.1.1.1.3.1" lspace="0.170em" xref="S4.Ex1.m1.1.1.1.1.3.1.cmml">⁢</mo><mtext id="S4.Ex1.m1.1.1.1.1.3.3" xref="S4.Ex1.m1.1.1.1.1.3.3a.cmml">KgCO2e</mtext></mrow></mrow><mo id="S4.Ex1.m1.1.1.1.2" lspace="0em" xref="S4.Ex1.m1.1.1.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.Ex1.m1.1b"><apply id="S4.Ex1.m1.1.1.1.1.cmml" xref="S4.Ex1.m1.1.1.1"><approx id="S4.Ex1.m1.1.1.1.1.2.cmml" xref="S4.Ex1.m1.1.1.1.1.2"></approx><apply id="S4.Ex1.m1.1.1.1.1.1.cmml" xref="S4.Ex1.m1.1.1.1.1.1"><times id="S4.Ex1.m1.1.1.1.1.1.2.cmml" xref="S4.Ex1.m1.1.1.1.1.1.2"></times><apply id="S4.Ex1.m1.1.1.1.1.1.1.cmml" xref="S4.Ex1.m1.1.1.1.1.1.1"><times id="S4.Ex1.m1.1.1.1.1.1.1.2.cmml" xref="S4.Ex1.m1.1.1.1.1.1.1.2"></times><apply id="S4.Ex1.m1.1.1.1.1.1.1.1.cmml" xref="S4.Ex1.m1.1.1.1.1.1.1.1"><times id="S4.Ex1.m1.1.1.1.1.1.1.1.2.cmml" xref="S4.Ex1.m1.1.1.1.1.1.1.1.2"></times><apply id="S4.Ex1.m1.1.1.1.1.1.1.1.1.cmml" xref="S4.Ex1.m1.1.1.1.1.1.1.1.1"><times id="S4.Ex1.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S4.Ex1.m1.1.1.1.1.1.1.1.1.2"></times><apply id="S4.Ex1.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S4.Ex1.m1.1.1.1.1.1.1.1.1.1"><times id="S4.Ex1.m1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S4.Ex1.m1.1.1.1.1.1.1.1.1.1.2"></times><apply id="S4.Ex1.m1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S4.Ex1.m1.1.1.1.1.1.1.1.1.1.1.1"><minus id="S4.Ex1.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S4.Ex1.m1.1.1.1.1.1.1.1.1.1.1.1.1.1"></minus><apply id="S4.Ex1.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S4.Ex1.m1.1.1.1.1.1.1.1.1.1.1.1.1.2"><csymbol cd="latexml" id="S4.Ex1.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S4.Ex1.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.1">percent</csymbol><cn id="S4.Ex1.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.2.cmml" type="integer" xref="S4.Ex1.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.2">100</cn></apply><apply id="S4.Ex1.m1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S4.Ex1.m1.1.1.1.1.1.1.1.1.1.1.1.1.3"><csymbol cd="latexml" id="S4.Ex1.m1.1.1.1.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S4.Ex1.m1.1.1.1.1.1.1.1.1.1.1.1.1.3.1">percent</csymbol><cn id="S4.Ex1.m1.1.1.1.1.1.1.1.1.1.1.1.1.3.2.cmml" type="integer" xref="S4.Ex1.m1.1.1.1.1.1.1.1.1.1.1.1.1.3.2">72</cn></apply></apply><cn id="S4.Ex1.m1.1.1.1.1.1.1.1.1.1.3.cmml" type="float" xref="S4.Ex1.m1.1.1.1.1.1.1.1.1.1.3">0.51</cn></apply><ci id="S4.Ex1.m1.1.1.1.1.1.1.1.1.3a.cmml" xref="S4.Ex1.m1.1.1.1.1.1.1.1.1.3"><mtext id="S4.Ex1.m1.1.1.1.1.1.1.1.1.3.cmml" xref="S4.Ex1.m1.1.1.1.1.1.1.1.1.3">kWh</mtext></ci></apply><cn id="S4.Ex1.m1.1.1.1.1.1.1.1.3.cmml" type="integer" xref="S4.Ex1.m1.1.1.1.1.1.1.1.3">10</cn><cn id="S4.Ex1.m1.1.1.1.1.1.1.1.4.cmml" type="integer" xref="S4.Ex1.m1.1.1.1.1.1.1.1.4">481</cn></apply><ci id="S4.Ex1.m1.1.1.1.1.1.1.3a.cmml" xref="S4.Ex1.m1.1.1.1.1.1.1.3"><mtext id="S4.Ex1.m1.1.1.1.1.1.1.3.cmml" xref="S4.Ex1.m1.1.1.1.1.1.1.3">gCO2e/kWh</mtext></ci></apply><cn id="S4.Ex1.m1.1.1.1.1.1.3.cmml" type="integer" xref="S4.Ex1.m1.1.1.1.1.1.3">40</cn></apply><apply id="S4.Ex1.m1.1.1.1.1.3.cmml" xref="S4.Ex1.m1.1.1.1.1.3"><times id="S4.Ex1.m1.1.1.1.1.3.1.cmml" xref="S4.Ex1.m1.1.1.1.1.3.1"></times><cn id="S4.Ex1.m1.1.1.1.1.3.2.cmml" type="float" xref="S4.Ex1.m1.1.1.1.1.3.2">27.4</cn><ci id="S4.Ex1.m1.1.1.1.1.3.3a.cmml" xref="S4.Ex1.m1.1.1.1.1.3.3"><mtext id="S4.Ex1.m1.1.1.1.1.3.3.cmml" xref="S4.Ex1.m1.1.1.1.1.3.3">KgCO2e</mtext></ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.Ex1.m1.1c">(100\%-72\%)\times 0.51\,\text{kWh}\times 10\times 481\,\text{gCO2e/kWh}\times
4%
0\approx 27.4\,\text{KgCO2e}.</annotation><annotation encoding="application/x-llamapun" id="S4.Ex1.m1.1d">( 100 % - 72 % ) × 0.51 kWh × 10 × 481 gCO2e/kWh × 40 ≈ 27.4 KgCO2e .</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S4.p2.2">This estimation roughly quantifies the reduction in CO2e emissions resulting from the training of a single algorithm on a single dataset, based solely on the reduction in runtime following downsampling. It assumes that the hardware used for the full dataset will also be employed for the downsampled dataset and that a nearly linear relationship exists between runtime, energy consumption, and carbon emissions, as supported by the ML CO2 Impact calculator tool<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09359v1#bib.bib22" title="">22</a>]</cite>.
In the upcoming sections, we detail the principal observations derived from our results and delve into how they inform the objectives of our research. For simplicity in discussing the algorithms examined in this study, we have categorized the algorithms into two groups. This division reflects the observed similarities in performance and results within each group, with distinct behaviors compared to the other group as shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.09359v1#S4.F1" title="Figure 1 ‣ 4.0.1 Observations ‣ 4 Results &amp; Conclusion ‣ Green Recommender Systems: Optimizing Dataset Size for Energy-Efficient Algorithm Performance"><span class="ltx_text ltx_ref_tag">1</span></a>, facilitating clearer analysis of their comparative effectiveness. The Random algorithm serves as a baseline for comparison but is not included in the statistics of either group. Table <a class="ltx_ref" href="https://arxiv.org/html/2410.09359v1#S4.T3" title="Table 3 ‣ 4 Results &amp; Conclusion ‣ Green Recommender Systems: Optimizing Dataset Size for Energy-Efficient Algorithm Performance"><span class="ltx_text ltx_ref_tag">3</span></a> provides an overview of these categorizations.
<br class="ltx_break"/></p>
</div>
<figure class="ltx_table" id="S4.T3">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>Categorization of Examined Algorithms</figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S4.T3.1">
<tr class="ltx_tr" id="S4.T3.1.1">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="S4.T3.1.1.1"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.1.1">Group</span></td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S4.T3.1.1.2">
<span class="ltx_inline-block ltx_align_top" id="S4.T3.1.1.2.1">
<span class="ltx_p" id="S4.T3.1.1.2.1.1" style="width:284.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.2.1.1.1">Algorithms included</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.2">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="S4.T3.1.2.1">Group 1</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S4.T3.1.2.2">
<span class="ltx_inline-block ltx_align_top" id="S4.T3.1.2.2.1">
<span class="ltx_p" id="S4.T3.1.2.2.1.1" style="width:284.5pt;">UserKNN, SVD, ItemKNN (both LensKit and RecPack version), NMF</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.3">
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t" id="S4.T3.1.3.1">Group 2</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r ltx_border_t" id="S4.T3.1.3.2">
<span class="ltx_inline-block ltx_align_top" id="S4.T3.1.3.2.1">
<span class="ltx_p" id="S4.T3.1.3.2.1.1" style="width:284.5pt;">Bias, Popularity, FunkSVD, BiasedMF, Popular</span>
</span>
</td>
</tr>
</table>
</figure>
<section class="ltx_subsubsection" id="S4.SS0.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.0.1 </span><span class="ltx_text ltx_font_bold" id="S4.SS0.SSS1.1.1">Observations</span>
</h4>
<div class="ltx_para" id="S4.SS0.SSS1.p1">
<p class="ltx_p" id="S4.SS0.SSS1.p1.13">Several key observations can be outlined from our analysis of recommender system algorithms across different datasets, each numbered for easy reference. (1) larger datasets consistently resulted in improved performance across all algorithms, with Group 1 algorithms benefiting significantly from increased data availability. (2) In examining the performance metrics, we observed that Group 1 algorithms displayed significant improvements when the dataset used for training exceeded <math alttext="\sim" class="ltx_Math" display="inline" id="S4.SS0.SSS1.p1.1.m1.1"><semantics id="S4.SS0.SSS1.p1.1.m1.1a"><mo id="S4.SS0.SSS1.p1.1.m1.1.1" xref="S4.SS0.SSS1.p1.1.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS1.p1.1.m1.1b"><csymbol cd="latexml" id="S4.SS0.SSS1.p1.1.m1.1.1.cmml" xref="S4.SS0.SSS1.p1.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS1.p1.1.m1.1c">\sim</annotation><annotation encoding="application/x-llamapun" id="S4.SS0.SSS1.p1.1.m1.1d">∼</annotation></semantics></math>30% of the total data. Specifically, downsampling the MovieLens 100K dataset to <math alttext="\sim" class="ltx_Math" display="inline" id="S4.SS0.SSS1.p1.2.m2.1"><semantics id="S4.SS0.SSS1.p1.2.m2.1a"><mo id="S4.SS0.SSS1.p1.2.m2.1.1" xref="S4.SS0.SSS1.p1.2.m2.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS1.p1.2.m2.1b"><csymbol cd="latexml" id="S4.SS0.SSS1.p1.2.m2.1.1.cmml" xref="S4.SS0.SSS1.p1.2.m2.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS1.p1.2.m2.1c">\sim</annotation><annotation encoding="application/x-llamapun" id="S4.SS0.SSS1.p1.2.m2.1d">∼</annotation></semantics></math>50% resulted in a <math alttext="\sim" class="ltx_Math" display="inline" id="S4.SS0.SSS1.p1.3.m3.1"><semantics id="S4.SS0.SSS1.p1.3.m3.1a"><mo id="S4.SS0.SSS1.p1.3.m3.1.1" xref="S4.SS0.SSS1.p1.3.m3.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS1.p1.3.m3.1b"><csymbol cd="latexml" id="S4.SS0.SSS1.p1.3.m3.1.1.cmml" xref="S4.SS0.SSS1.p1.3.m3.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS1.p1.3.m3.1c">\sim</annotation><annotation encoding="application/x-llamapun" id="S4.SS0.SSS1.p1.3.m3.1d">∼</annotation></semantics></math>50% decrease in average nDCG@10 values of this group’s algorithms, while reducing to <math alttext="\sim" class="ltx_Math" display="inline" id="S4.SS0.SSS1.p1.4.m4.1"><semantics id="S4.SS0.SSS1.p1.4.m4.1a"><mo id="S4.SS0.SSS1.p1.4.m4.1.1" xref="S4.SS0.SSS1.p1.4.m4.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS1.p1.4.m4.1b"><csymbol cd="latexml" id="S4.SS0.SSS1.p1.4.m4.1.1.cmml" xref="S4.SS0.SSS1.p1.4.m4.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS1.p1.4.m4.1c">\sim</annotation><annotation encoding="application/x-llamapun" id="S4.SS0.SSS1.p1.4.m4.1d">∼</annotation></semantics></math>30% led to a <math alttext="\sim" class="ltx_Math" display="inline" id="S4.SS0.SSS1.p1.5.m5.1"><semantics id="S4.SS0.SSS1.p1.5.m5.1a"><mo id="S4.SS0.SSS1.p1.5.m5.1.1" xref="S4.SS0.SSS1.p1.5.m5.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS1.p1.5.m5.1b"><csymbol cd="latexml" id="S4.SS0.SSS1.p1.5.m5.1.1.cmml" xref="S4.SS0.SSS1.p1.5.m5.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS1.p1.5.m5.1c">\sim</annotation><annotation encoding="application/x-llamapun" id="S4.SS0.SSS1.p1.5.m5.1d">∼</annotation></semantics></math>65% decrease, highlighting a near-linear relationship between dataset size and performance. (3) Conversely, Group 2 algorithms demonstrated more gradual performance improvements, with nDCG@10 values decreasing by <math alttext="\sim" class="ltx_Math" display="inline" id="S4.SS0.SSS1.p1.6.m6.1"><semantics id="S4.SS0.SSS1.p1.6.m6.1a"><mo id="S4.SS0.SSS1.p1.6.m6.1.1" xref="S4.SS0.SSS1.p1.6.m6.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS1.p1.6.m6.1b"><csymbol cd="latexml" id="S4.SS0.SSS1.p1.6.m6.1.1.cmml" xref="S4.SS0.SSS1.p1.6.m6.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS1.p1.6.m6.1c">\sim</annotation><annotation encoding="application/x-llamapun" id="S4.SS0.SSS1.p1.6.m6.1d">∼</annotation></semantics></math>23% and <math alttext="\sim" class="ltx_Math" display="inline" id="S4.SS0.SSS1.p1.7.m7.1"><semantics id="S4.SS0.SSS1.p1.7.m7.1a"><mo id="S4.SS0.SSS1.p1.7.m7.1.1" xref="S4.SS0.SSS1.p1.7.m7.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS1.p1.7.m7.1b"><csymbol cd="latexml" id="S4.SS0.SSS1.p1.7.m7.1.1.cmml" xref="S4.SS0.SSS1.p1.7.m7.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS1.p1.7.m7.1c">\sim</annotation><annotation encoding="application/x-llamapun" id="S4.SS0.SSS1.p1.7.m7.1d">∼</annotation></semantics></math>29% in average when the dataset was downsampled to <math alttext="\sim" class="ltx_Math" display="inline" id="S4.SS0.SSS1.p1.8.m8.1"><semantics id="S4.SS0.SSS1.p1.8.m8.1a"><mo id="S4.SS0.SSS1.p1.8.m8.1.1" xref="S4.SS0.SSS1.p1.8.m8.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS1.p1.8.m8.1b"><csymbol cd="latexml" id="S4.SS0.SSS1.p1.8.m8.1.1.cmml" xref="S4.SS0.SSS1.p1.8.m8.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS1.p1.8.m8.1c">\sim</annotation><annotation encoding="application/x-llamapun" id="S4.SS0.SSS1.p1.8.m8.1d">∼</annotation></semantics></math>50% and <math alttext="\sim" class="ltx_Math" display="inline" id="S4.SS0.SSS1.p1.9.m9.1"><semantics id="S4.SS0.SSS1.p1.9.m9.1a"><mo id="S4.SS0.SSS1.p1.9.m9.1.1" xref="S4.SS0.SSS1.p1.9.m9.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS1.p1.9.m9.1b"><csymbol cd="latexml" id="S4.SS0.SSS1.p1.9.m9.1.1.cmml" xref="S4.SS0.SSS1.p1.9.m9.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS1.p1.9.m9.1c">\sim</annotation><annotation encoding="application/x-llamapun" id="S4.SS0.SSS1.p1.9.m9.1d">∼</annotation></semantics></math>30%, respectively. (4) The sparse Amazon Toys and Games dataset particularly illustrated a more pronounced performance gap between these two groups of algorithms. When downsampling to <math alttext="\sim" class="ltx_Math" display="inline" id="S4.SS0.SSS1.p1.10.m10.1"><semantics id="S4.SS0.SSS1.p1.10.m10.1a"><mo id="S4.SS0.SSS1.p1.10.m10.1.1" xref="S4.SS0.SSS1.p1.10.m10.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS1.p1.10.m10.1b"><csymbol cd="latexml" id="S4.SS0.SSS1.p1.10.m10.1.1.cmml" xref="S4.SS0.SSS1.p1.10.m10.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS1.p1.10.m10.1c">\sim</annotation><annotation encoding="application/x-llamapun" id="S4.SS0.SSS1.p1.10.m10.1d">∼</annotation></semantics></math>50% and <math alttext="\sim" class="ltx_Math" display="inline" id="S4.SS0.SSS1.p1.11.m11.1"><semantics id="S4.SS0.SSS1.p1.11.m11.1a"><mo id="S4.SS0.SSS1.p1.11.m11.1.1" xref="S4.SS0.SSS1.p1.11.m11.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS1.p1.11.m11.1b"><csymbol cd="latexml" id="S4.SS0.SSS1.p1.11.m11.1.1.cmml" xref="S4.SS0.SSS1.p1.11.m11.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS1.p1.11.m11.1c">\sim</annotation><annotation encoding="application/x-llamapun" id="S4.SS0.SSS1.p1.11.m11.1d">∼</annotation></semantics></math>30%, Group 2 algorithms experienced only <math alttext="\sim" class="ltx_Math" display="inline" id="S4.SS0.SSS1.p1.12.m12.1"><semantics id="S4.SS0.SSS1.p1.12.m12.1a"><mo id="S4.SS0.SSS1.p1.12.m12.1.1" xref="S4.SS0.SSS1.p1.12.m12.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS1.p1.12.m12.1b"><csymbol cd="latexml" id="S4.SS0.SSS1.p1.12.m12.1.1.cmml" xref="S4.SS0.SSS1.p1.12.m12.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS1.p1.12.m12.1c">\sim</annotation><annotation encoding="application/x-llamapun" id="S4.SS0.SSS1.p1.12.m12.1d">∼</annotation></semantics></math>13% and <math alttext="\sim" class="ltx_Math" display="inline" id="S4.SS0.SSS1.p1.13.m13.1"><semantics id="S4.SS0.SSS1.p1.13.m13.1a"><mo id="S4.SS0.SSS1.p1.13.m13.1.1" xref="S4.SS0.SSS1.p1.13.m13.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS1.p1.13.m13.1b"><csymbol cd="latexml" id="S4.SS0.SSS1.p1.13.m13.1.1.cmml" xref="S4.SS0.SSS1.p1.13.m13.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS1.p1.13.m13.1c">\sim</annotation><annotation encoding="application/x-llamapun" id="S4.SS0.SSS1.p1.13.m13.1d">∼</annotation></semantics></math>17% average drops in performance, respectively, which is less severe compared to the denser MovieLens datasets.
<br class="ltx_break"/></p>
</div>
<figure class="ltx_figure" id="S4.F1">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<div class="ltx_block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_bottom" id="S4.F1.1" style="width:208.1pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="355" id="S4.F1.1.g1" src="extracted/5921170/ML100K-Plot.png" width="598"/>
</div>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<div class="ltx_block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_bottom" id="S4.F1.2" style="width:208.1pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="351" id="S4.F1.2.g1" src="extracted/5921170/ML1M-Plot.png" width="598"/>
</div>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_2">
<div class="ltx_block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_bottom" id="S4.F1.3" style="width:208.1pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="353" id="S4.F1.3.g1" src="extracted/5921170/ML10M-Plot.png" width="598"/>
</div>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<div class="ltx_block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_bottom" id="S4.F1.4" style="width:208.1pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="352" id="S4.F1.4.g1" src="extracted/5921170/AmazonToysGames-Plot.png" width="598"/>
</div>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>nDCG@10 scores for each algorithm trained on varying portions of the datasets. The horizontal axis shows the percentage of the full training set, where 100% equals 80% of the total dataset, with other percentages relative to this.</figcaption>
</figure>
<figure class="ltx_figure" id="S4.F2">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_4">
<div class="ltx_block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_bottom" id="S4.F2.1" style="width:104.1pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="384" id="S4.F2.1.g1" src="extracted/5921170/ML100k-GP1.png" width="598"/>
</div>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<div class="ltx_block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_bottom" id="S4.F2.2" style="width:104.1pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="389" id="S4.F2.2.g1" src="extracted/5921170/ML1M-GP1.png" width="598"/>
</div>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<div class="ltx_block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_bottom" id="S4.F2.3" style="width:104.1pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="380" id="S4.F2.3.g1" src="extracted/5921170/ML10M-GP1.png" width="598"/>
</div>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<div class="ltx_block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_bottom" id="S4.F2.4" style="width:104.1pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="373" id="S4.F2.4.g1" src="extracted/5921170/Amazon-GP1.png" width="598"/>
</div>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_4">
<div class="ltx_block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_bottom" id="S4.F2.5" style="width:104.1pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="381" id="S4.F2.5.g1" src="extracted/5921170/ML100K-GP2.png" width="598"/>
</div>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<div class="ltx_block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_bottom" id="S4.F2.6" style="width:104.1pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="378" id="S4.F2.6.g1" src="extracted/5921170/ML1M-GP2.png" width="598"/>
</div>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<div class="ltx_block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_bottom" id="S4.F2.7" style="width:104.1pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="384" id="S4.F2.7.g1" src="extracted/5921170/ML10M-GP2.png" width="598"/>
</div>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<div class="ltx_block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_bottom" id="S4.F2.8" style="width:104.1pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="380" id="S4.F2.8.g1" src="extracted/5921170/Amazon-GP2.png" width="598"/>
</div>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Distribution of nDCG@10 Scores Across Four examined Datasets for Two Distinct Algorithm Groups at 50% and 100% Dataset Utilization.</figcaption>
</figure>
</section>
<section class="ltx_subsubsection" id="S4.SS0.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.0.2 </span><span class="ltx_text ltx_font_bold" id="S4.SS0.SSS2.1.1">Interpretation</span>
</h4>
<div class="ltx_para" id="S4.SS0.SSS2.p1">
<p class="ltx_p" id="S4.SS0.SSS2.p1.1">From these observations, it appears that the size and sparsity of datasets significantly influence the performance of recommender system algorithms. Observation (1) highlights that contrary to our expectations, larger data volumes, including those from extensive datasets like MovieLens 10M, generally lead to better algorithm performance. However, the extent of improvement depends on the specific algorithm and the characteristics of the dataset. Observations (2) and (3) highlight that Group 1 algorithms are highly dependent on larger datasets to perform optimally. In contrast, Group 2 algorithms maintain relatively stable performance even with reduced data, striking a balance between performance and computational efficiency. This observation is evident from the narrower gap in the nDCG@10 scores distribution box plot between 50% and 100% dataset utilization for algorithms in Group 2, compared to the larger gap seen in Group 1, as shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.09359v1#S4.F2" title="Figure 2 ‣ 4.0.1 Observations ‣ 4 Results &amp; Conclusion ‣ Green Recommender Systems: Optimizing Dataset Size for Energy-Efficient Algorithm Performance"><span class="ltx_text ltx_ref_tag">2</span></a>. The detailed analysis in observation (4) shows that in sparse environments, such as the Amazon Toys and Games dataset, downsampling effectively reduces computational demands with only minimal performance loss. This indicates that strategic downsampling can be a viable method especially in contexts where energy optimization is crucial without significantly compromising accuracy.
<br class="ltx_break"/></p>
</div>
</section>
<section class="ltx_subsubsection" id="S4.SS0.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.0.3 </span><span class="ltx_text ltx_font_bold" id="S4.SS0.SSS3.1.1">Conclusion</span>
</h4>
<div class="ltx_para" id="S4.SS0.SSS3.p1">
<p class="ltx_p" id="S4.SS0.SSS3.p1.1">This study underscores the potential for optimizing recommender systems through dataset size reduction. Although most algorithms demonstrate enhanced performance with larger training datasets, our analysis has pinpointed specific scenarios where the trade-off between energy efficiency and accuracy favors efficiency. In these cases, significant savings are achieved with minimal detriment to accuracy. Some algorithms consistently maintain high performance even with reduced data volumes, highlighting their potential for energy-efficient AI development.</p>
</div>
<div class="ltx_para" id="S4.SS0.SSS3.p2">
<p class="ltx_p" id="S4.SS0.SSS3.p2.1">Therefore, we answer our research question by affirming that it can be possible to identify an optimal trade-off between maintaining algorithmic performance and reducing dataset size. Specifically, our analysis shows that strategic downsampling may improve energy efficiency while maintaining performance comparable to the original dataset size, thereby supporting the optimization of AI systems and recommenders. However, more research is necessary to find out when exactly downsampling is a sensible approach, as sometimes, performance varies notably. We hope that in the long term, downsampling datasets becomes an accepted best-practice <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09359v1#bib.bib8" title="">8</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.09359v1#bib.bib7" title="">7</a>]</cite>, for the recommender-system community that helps contributing to green and sustainable recommender systems. 
<br class="ltx_break"/></p>
</div>
</section>
<section class="ltx_subsubsection" id="S4.SS0.SSS4">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.0.4 </span><span class="ltx_text ltx_font_bold" id="S4.SS0.SSS4.1.1">Acknowledgment</span>
</h4>
<div class="ltx_para" id="S4.SS0.SSS4.p1">
<p class="ltx_p" id="S4.SS0.SSS4.p1.1">This paper benefited from ChatGPT for grammar and wording improvements<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09359v1#bib.bib6" title="">6</a>]</cite>. The code used for conducting the experiments is publicly available on GitHub<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09359v1#bib.bib4" title="">4</a>]</cite>.</p>
</div>
</section>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
Al-Jarrah, O., Yoob, P., Muhaidat, S., Karagiannidis, G., Taha, K.: Efficient machine learning for big data: A review. Big Data Research <span class="ltx_text ltx_font_bold" id="bib.bib1.1.1">2</span>(3), 87–99 (2015). https://doi.org/10.1016/j.bdr.2015.04.002

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
Alzoubi, Y.I., Mishra, A.: Green artificial intelligence initiatives: Potentials and challenges. Journal of Cleaner Production <span class="ltx_text ltx_font_bold" id="bib.bib2.1.1">468</span>, 143090 (2024). https://doi.org/https://doi.org/10.1016/j.jclepro.2024.143090, <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.sciencedirect.com/science/article/pii/S0959652624025393" title="">https://www.sciencedirect.com/science/article/pii/S0959652624025393</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
Anand, R., Beel, J.: Auto-surprise: An automated recommender-system (autorecsys) library with tree of parzens estimator (tpe) optimization. In: 14th ACM Conference on Recommender Systems (RecSys). pp. 1–4 (2020), <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2008.13532" title="">https://arxiv.org/abs/2008.13532</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
Arabzadeh, A.: Green recsys github repository (2024), <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/Ardalan224/RecSoGood2024/" title="">https://github.com/Ardalan224/RecSoGood2024/</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
Baumgart, M., Wegmeth, L., Vente, T., Beel, J.: e-fold cross-validation for recommender-system evaluation. In: International Workshop on Recommender Systems for Sustainability and Social Good (RecSoGood) at the 18th ACM Conference on Recommender Systems (ACM RecSys) (2024)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
Beel, J.: Our use of ai-tools for writing research papers (2024), <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://isg.beel.org/blog/2024/08/19/our-use-of-ai-tools-for-writing-research-papers/" title="">https://isg.beel.org/blog/2024/08/19/our-use-of-ai-tools-for-writing-research-papers/</a>, in: Intelligent Systems Group, Blog

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
Beel, J.: A call for evidence-based best-practices for recommender systems evaluations. In: Bauer, C., Said, A., Zangerle, E. (eds.) Report from Dagstuhl Seminar 24211: Evaluation Perspectives of Recommender Systems: Driving Research and Education (2024). https://doi.org/10.31219/osf.io/djuac, <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://isg.beel.org/pubs/2024_Call_for_Evidence_Based_RecSys_Evaluation__Pre_Print_.pdf" title="">https://isg.beel.org/pubs/2024_Call_for_Evidence_Based_RecSys_Evaluation__Pre_Print_.pdf</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
Beel, J., Jannach, D., Said, A., Shani, G., Vente, T., Wegmeth, L.: Best-practices for offline evaluations of recommender systems. In: Bauer, C., Said, A., Zangerle, E. (eds.) Report from Dagstuhl Seminar 24211 – Evaluation Perspectives of Recommender Systems: Driving Research and Education (2024)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
Beel, J., Said, A., Vente, T., Wegmeth, L.: Green recommender systems – a call for attention. Recommender-Systems.com Blog (2024). https://doi.org/10.31219/osf.io/5ru2g, <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://isg.beel.org/pubs/2024_Green_Recommender_Systems-A_Call_for_Attention.pdf" title="">https://isg.beel.org/pubs/2024_Green_Recommender_Systems-A_Call_for_Attention.pdf</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
Beel, J., Wegmeth, L., Michiels, L., Schulz, S.: Informed dataset-selection with algorithm performance spaces. In: 18th ACM Conference on Recommender Systems (ACM RecSys) (2024)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
Beel, J., Wegmeth, L., Vente, T.: E-fold cross-validation: A computing and energy-efficient alternative to k-fold cross-validation with adaptive folds [proposal]. OSF Preprints (2024). https://doi.org/10.31219/osf.io/exw3j, <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://osf.io/preprints/osf/exw3j" title="">https://osf.io/preprints/osf/exw3j</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
Bentzer, C., Thulin, H.: Recommender systems using limited dataset sizes (June 8 2023), degree Project in Computer Science and Engineering, First cycle, 15 credits, KTH Royal Institute of Technology

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
Castellanos-Nieves, D., García-Forte, L.: Strategies of automated machine learning for energy sustainability in green artificial intelligence. Applied Sciences (2076-3417) <span class="ltx_text ltx_font_bold" id="bib.bib13.1.1">14</span>(14) (2024)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
Castellanos-Nieves, D., García-Forte, L.: Improving automated machine-learning systems through green ai. Applied Sciences <span class="ltx_text ltx_font_bold" id="bib.bib14.1.1">13</span>(20) (2023). https://doi.org/10.3390/app132011583, <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.mdpi.com/2076-3417/13/20/11583" title="">https://www.mdpi.com/2076-3417/13/20/11583</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
Cañamares, R., Castells, P., Moffat, A.: Offline evaluation options for recommender systems. Information Retrieval Journal <span class="ltx_text ltx_font_bold" id="bib.bib15.1.1">23</span>(4), 387–410 (2020). https://doi.org/10.1007/s10791-020-09371-3

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
Chen, C., Zhang, P., Zhang, H., Dai, J., Yi, Y., Zhang, H., Zhang, Y.: Deep learning on computational-resource-limited platforms: A survey. Advances in Artificial Intelligence (2020). https://doi.org/10.1155/2020/8454327, first published: 01 March 2020

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
Ekstrand, M.: Lenskit for python: Next-generation software for recommender systems experiments. In: Proceedings of the 29th ACM International Conference on Information &amp; Knowledge Management. pp. 2999–3006. Virtual Event, Ireland (2020). https://doi.org/10.1145/3340531.3412778

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
Ember: Carbon intensity of electricity generation – ember and energy institute (2024), <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://ourworldindata.org/grapher/carbon-intensity-electricity" title="">https://ourworldindata.org/grapher/carbon-intensity-electricity</a>, yearly Electricity Data by Ember; Statistical Review of World Energy by Energy Institute. Dataset processed by Our World in Data

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
Gupta, S., Beel, J.: Auto-caserec: Automatically selecting and optimizing recommendation-systems algorithms. OSF Preprints DOI:10.31219/osf.io/4znmd, (2020). https://doi.org/10.31219/osf.io/4znmd

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
Hennig, L., Tornede, T., Lindauer, M.: Towards leveraging automl for sustainable deep learning: A multi-objective hpo approach on deep shift neural networks. In: arXiv (2024), <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2404.01965" title="">https://arxiv.org/abs/2404.01965</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
Jain, K., Jindal, R.: Sampling and noise filtering methods for recommender systems: A literature review. Engineering Applications of Artificial Intelligence <span class="ltx_text ltx_font_bold" id="bib.bib21.1.1">122</span>, 106129 (2023)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
Lacoste, A., Luccioni, A., Schmidt, V., Dandres, T.: Quantifying the carbon emissions of machine learning. arXiv preprint (2019), <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://mlco2.github.io/impact/" title="">https://mlco2.github.io/impact/</a>, arXiv:1910.09700 [cs.CY]

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
Mahlich, C., Vente, T., Beel, J.: From theory to practice: Implementing and evaluating e-fold cross-validation. In: International Conference on Artificial Intelligence and Machine Learning Research (CAIMLR) (2024), <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://isg.beel.org/blog/2024/09/16/e-fold-cross-validation/" title="">https://isg.beel.org/blog/2024/09/16/e-fold-cross-validation/</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
Meng, Z., McCreadie, R., Macdonald, C., Ounis, I.: Exploring data splitting strategies for the evaluation of recommendation models. In: Proceedings of RecSys ’20: The 14th ACM Recommender Systems Conference (RecSys ’20). p. 8. ACM, New York, NY, USA (2020). https://doi.org/10.1145/1122445.1122456

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
Michiels, L., Verachtert, R., Goethals, B.: Recpack: An(other) experimentation toolkit for top-n recommendation using implicit feedback data. In: Proceedings of the 16th ACM Conference on Recommender Systems. p. 648–651. RecSys ’22, Association for Computing Machinery, New York, NY, USA (2022). https://doi.org/10.1145/3523227.3551472, <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3523227.3551472" title="">https://doi.org/10.1145/3523227.3551472</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
Plaza, A., Gil, J., Parra Santander, D.: 14 kg of co2: Analyzing the carbon footprint and performance of session-based recommendation algorithms. In: RecSoGood Workshop (2024)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
Santos, S.O.S., Skiarski, A., García-Núñez, D., Lazzarini, V., De Andrade Moral, R., Galvan, E., Ottoni, A.L.C., Nepomuceno, E.: Green machine learning: Analysing the energy efficiency of machine learning models. In: 2024 35th Irish Signals and Systems Conference (ISSC). pp. 1–6 (2024). https://doi.org/10.1109/ISSC61953.2024.10603302

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
Schmidt, M., Prinz, T., Nitschke, J.: Evaluating the performance-deviation of itemknn in recbole and lenskit. arXiv preprint (2024), <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2407.13531" title="">https://arxiv.org/abs/2407.13531</a>, arXiv:2407.13531v1 [cs.LG]

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
Schwartz, R., Dodge, J., Smith, N.A., Etzioni, O.: Green ai. Commun. ACM <span class="ltx_text ltx_font_bold" id="bib.bib29.1.1">63</span>(12), 54–63 (Nov 2020). https://doi.org/10.1145/3381831, <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3381831" title="">https://doi.org/10.1145/3381831</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
Spillo, G., De Filippo, A., Milano, M., Musto, C., Semeraro, G.: Towards sustainability-aware recommender systems: Analyzing the trade-off between algorithms performance and carbon footprint. In: Proceedings of the ACM Conference. p. 7. Singapore, Singapore (2023). https://doi.org/10.1145/3604915.3608840

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
Spillo, G., De Filippo, A., Musto, C., Milano, M., Semeraro, G.: Towards green recommender systems: Investigating the impact of data reduction on carbon footprint and algorithm performances. In: 18th ACM Conference on Recommender Systems (2024)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
Spillo, G., Valerio, A.G., Franchini, F., De Filippo, A., Musto, C., Milano, M., Semeraro, G.: Recsys carbonator: Predicting carbon footprint of recommendation system models. In: RecSoGood Workshop (2024)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
Tornede, T., Tornede, A., Hanselle, J., Mohr, F., Wever, M., Hüllermeier, E.: Towards green automated machine learning: Status quo and future directions. arXiv / Journal of Artificial Intelligence Research <span class="ltx_text ltx_font_bold" id="bib.bib33.1.1">77</span>, 427–457 (2021 / 2023)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
Vente, T., Ekstrand, M., Beel, J.: Introducing lenskit-auto, an experimental automated recommender system (autorecsys) toolkit. In: Proceedings of the 17th ACM Conference on Recommender Systems. pp. 1212–1216 (2023), <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://dl.acm.org/doi/10.1145/3604915.3610656" title="">https://dl.acm.org/doi/10.1145/3604915.3610656</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
Vente, T., Wegmeth, L., Said, A., Beel, J.: From clicks to carbon: The environmental toll of recommender systems. In: Proceedings of the 18th ACM Conference on Recommender Systems. p. 580–590. RecSys ’24, Association for Computing Machinery, New York, NY, USA (2024). https://doi.org/10.1145/3640457.3688074, <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2408.08203" title="">https://arxiv.org/abs/2408.08203</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock">
Wegmeth, L., Vente, T., Said, A., Beel, J.: Emers: Energy meter for recommender systems. In: International Workshop on Recommender Systems for Sustainability and Social Good (RecSoGood) at the 18th ACM Conference on Recommender Systems (ACM RecSys) (2024), <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/pdf/2409.15060" title="">https://arxiv.org/pdf/2409.15060</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock">
Zogaj, F., Cambronero, J., Rinard, M., Cito, J.: Doing more with less: Characterizing dataset downsampling for automl. Proceedings of the VLDB Endowment (PVLDB) <span class="ltx_text ltx_font_bold" id="bib.bib37.1.1">14</span>(11), 2059–2072 (2021). https://doi.org/10.14778/3476249.3476262

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Sat Oct 12 03:53:32 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
